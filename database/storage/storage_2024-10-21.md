# arxiv-daily
 Automated deployment @ 2024-10-21 20:37:23 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-18**|**Less is More: Selective Reduction of CT Data for Self-Supervised Pre-Training of Deep Learning Models with Contrastive Learning Improves Downstream Classification Performance**|Daniel Wolf et.al.|[2410.14524v1](http://arxiv.org/abs/2410.14524v1)|[link](https://github.com/Wolfda95/Less_is_More)|
|**2024-10-18**|**A Scientific Machine Learning Approach for Predicting and Forecasting Battery Degradation in Electric Vehicles**|Sharv Murgai et.al.|[2410.14347v1](http://arxiv.org/abs/2410.14347v1)|null|
|**2024-10-18**|**Deep Learning Applications in Medical Image Analysis: Advancements, Challenges, and Future Directions**|Aimina Ali Eli et.al.|[2410.14131v1](http://arxiv.org/abs/2410.14131v1)|null|
|**2024-10-17**|**Identifying High Consideration E-Commerce Search Queries**|Zhiyu Chen et.al.|[2410.13951v1](http://arxiv.org/abs/2410.13951v1)|null|
|**2024-10-17**|**The KnowWhereGraph Ontology**|Cogan Shimizu et.al.|[2410.13948v1](http://arxiv.org/abs/2410.13948v1)|null|
|**2024-10-17**|**The Disparate Benefits of Deep Ensembles**|Kajetan Schweighofer et.al.|[2410.13831v1](http://arxiv.org/abs/2410.13831v1)|[link](https://github.com/ml-jku/disparate-benefits)|
|**2024-10-17**|**Scaling Wearable Foundation Models**|Girish Narayanswamy et.al.|[2410.13638v1](http://arxiv.org/abs/2410.13638v1)|null|
|**2024-10-17**|**MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling**|Yakun Zhu et.al.|[2410.13610v1](http://arxiv.org/abs/2410.13610v1)|null|
|**2024-10-17**|**OAH-Net: A Deep Neural Network for Hologram Reconstruction of Off-axis Digital Holographic Microscope**|Wei Liu et.al.|[2410.13592v1](http://arxiv.org/abs/2410.13592v1)|null|
|**2024-10-17**|**RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical Imaging**|Tobias Czempiel et.al.|[2410.13570v1](http://arxiv.org/abs/2410.13570v1)|null|
|**2024-10-17**|**Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?**|Che Liu et.al.|[2410.13523v1](http://arxiv.org/abs/2410.13523v1)|null|
|**2024-10-17**|**Representation Learning of Structured Data for Medical Foundation Models**|Vijay Prakash Dwivedi et.al.|[2410.13351v1](http://arxiv.org/abs/2410.13351v1)|null|
|**2024-10-17**|**Active inference and deep generative modeling for cognitive ultrasound**|Ruud JG van Sloun et.al.|[2410.13310v1](http://arxiv.org/abs/2410.13310v1)|null|
|**2024-10-17**|**Hiformer: Hybrid Frequency Feature Enhancement Inverted Transformer for Long-Term Wind Power Prediction**|Chongyang Wan et.al.|[2410.13303v1](http://arxiv.org/abs/2410.13303v1)|null|
|**2024-10-17**|**CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy**|Mian Zhang et.al.|[2410.13218v1](http://arxiv.org/abs/2410.13218v1)|null|
|**2024-10-17**|**MixEHR-Nest: Identifying Subphenotypes within Electronic Health Records through Hierarchical Guided-Topic Modeling**|Ruohan Wang et.al.|[2410.13217v1](http://arxiv.org/abs/2410.13217v1)|null|
|**2024-10-17**|**LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch**|Caigao Jiang et.al.|[2410.13213v1](http://arxiv.org/abs/2410.13213v1)|[link](https://github.com/caigaojiang/llmopt)|
|**2024-10-17**|**MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback**|Zonghai Yao et.al.|[2410.13191v2](http://arxiv.org/abs/2410.13191v2)|null|
|**2024-10-16**|**Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information**|Yingya Li et.al.|[2410.12774v1](http://arxiv.org/abs/2410.12774v1)|null|
|**2024-10-16**|**FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**|Zhenheng Tang et.al.|[2410.12707v1](http://arxiv.org/abs/2410.12707v1)|null|
|**2024-10-16**|**Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2**|Mohamad Abdi et.al.|[2410.12686v2](http://arxiv.org/abs/2410.12686v2)|null|
|**2024-10-16**|**Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans**|Luca Marsilio et.al.|[2410.12641v1](http://arxiv.org/abs/2410.12641v1)|null|
|**2024-10-16**|**NSSI-Net: Multi-Concept Generative Adversarial Network for Non-Suicidal Self-Injury Detection Using High-Dimensional EEG Signals in a Semi-Supervised Learning Framework**|Zhen Liang et.al.|[2410.12159v1](http://arxiv.org/abs/2410.12159v1)|[link](https://github.com/Vesan-yws/NSSINet)|
|**2024-10-15**|**SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding**|Ying Chen et.al.|[2410.11761v1](http://arxiv.org/abs/2410.11761v1)|null|
|**2024-10-15**|**RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping**|Chiyi Huang et.al.|[2410.11651v1](http://arxiv.org/abs/2410.11651v1)|null|
|**2024-10-15**|**Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development**|Tengfei Ma et.al.|[2410.11550v1](http://arxiv.org/abs/2410.11550v1)|null|
|**2024-10-15**|**AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data**|Xinjie Zhao et.al.|[2410.11531v1](http://arxiv.org/abs/2410.11531v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-15**|**HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications**|Weijie Xu et.al.|[2410.11239v1](http://arxiv.org/abs/2410.11239v1)|null|
|**2024-10-15**|**SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning**|Rikuto Kotoge et.al.|[2410.11200v1](http://arxiv.org/abs/2410.11200v1)|null|
|**2024-10-14**|**EchoApex: A General-Purpose Vision Foundation Model for Echocardiography**|Abdoul Aziz Amadou et.al.|[2410.11092v2](http://arxiv.org/abs/2410.11092v2)|null|
|**2024-10-14**|**Parsing altered brain connectivity in neurodevelopmental disorders by integrating graph-based normative modeling and deep generative networks**|Rui Sherry Shen et.al.|[2410.11064v1](http://arxiv.org/abs/2410.11064v1)|null|
|**2024-10-14**|**Deep Learning Based XIoT Malware Analysis: A Comprehensive Survey, Taxonomy, and Research Challenges**|Rami Darwish et.al.|[2410.13894v1](http://arxiv.org/abs/2410.13894v1)|null|
|**2024-10-14**|**Thinking LLMs: General Instruction Following with Thought Generation**|Tianhao Wu et.al.|[2410.10630v1](http://arxiv.org/abs/2410.10630v1)|null|
|**2024-10-14**|**BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI**|Shaohao Rui et.al.|[2410.10604v1](http://arxiv.org/abs/2410.10604v1)|null|
|**2024-10-14**|**Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature**|Jan Vrba et.al.|[2410.10537v1](http://arxiv.org/abs/2410.10537v1)|[link](https://github.com/aailab-uct/automated-robust-and-reproducible-voice-pathology-detection)|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-14**|**Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization**|Jorge Garc√≠a-Torres et.al.|[2410.10483v1](http://arxiv.org/abs/2410.10483v1)|[link](https://github.com/jtorres258/image-based-tob)|
|**2024-10-14**|**Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation**|Zehua Cheng et.al.|[2410.10366v1](http://arxiv.org/abs/2410.10366v1)|null|
|**2024-10-14**|**Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning**|Hongyi Yuan et.al.|[2410.10144v1](http://arxiv.org/abs/2410.10144v1)|null|
|**2024-10-14**|**REHRSeg: Unleashing the Power of Self-Supervised Super-Resolution for Resource-Efficient 3D MRI Segmentation**|Zhiyun Song et.al.|[2410.10097v1](http://arxiv.org/abs/2410.10097v1)|null|
|**2024-10-13**|**IMAS: A Comprehensive Agentic Approach to Rural Healthcare Delivery**|Agasthya Gangavarapu et.al.|[2410.12868v1](http://arxiv.org/abs/2410.12868v1)|[link](https://github.com/uheal/imas)|
|**2024-10-13**|**Adaptive Reasoning and Acting in Medical Language Agents**|Abhishek Dutta et.al.|[2410.10020v1](http://arxiv.org/abs/2410.10020v1)|null|
|**2024-10-13**|**Improving 3D Few-Shot Segmentation with Inference-Time Pseudo-Labeling**|Mohammad Mozafari et.al.|[2410.09967v1](http://arxiv.org/abs/2410.09967v1)|null|
|**2024-10-13**|**Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning**|Pengfei Jin et.al.|[2410.09908v1](http://arxiv.org/abs/2410.09908v1)|null|
|**2024-10-13**|**Equitable Access to Justice: Logical LLMs Show Promise**|Manuj Kant et.al.|[2410.09904v1](http://arxiv.org/abs/2410.09904v1)|null|
|**2024-10-13**|**Large-Scale 3D Medical Image Pre-training with Geometric Context Priors**|Linshan Wu et.al.|[2410.09890v1](http://arxiv.org/abs/2410.09890v1)|[link](https://github.com/luffy03/large-scale-medical)|
|**2024-10-13**|**HypomimiaCoach: An AU-based Digital Therapy System for Hypomimia Detection & Rehabilitation with Parkinson's Disease**|Yingjing Xu et.al.|[2410.09772v1](http://arxiv.org/abs/2410.09772v1)|null|
|**2024-10-13**|**STA-Unet: Rethink the semantic redundant for Medical Imaging Segmentation**|Vamsi Krishna Vasa et.al.|[2410.11578v1](http://arxiv.org/abs/2410.11578v1)|[link](https://github.com/retinal-research/sta-unet)|
|**2024-10-13**|**MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions**|Tavish Mankash et.al.|[2410.09729v1](http://arxiv.org/abs/2410.09729v1)|null|
|**2024-10-13**|**3DS: Decomposed Difficulty Data Selection's Case Study on LLM Medical Domain Adaptation**|Hongxin Ding et.al.|[2410.10901v1](http://arxiv.org/abs/2410.10901v1)|null|
|**2024-10-12**|**Multimodal Physical Activity Forecasting in Free-Living Clinical Settings: Hunting Opportunities for Just-in-Time Interventions**|Abdullah Mamun et.al.|[2410.09643v1](http://arxiv.org/abs/2410.09643v1)|[link](https://github.com/ab9mamun/movesense)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-11**|**AuD-Former: A Hierarchical Transformer Network for Multimodal Audio-Based Disease Prediction**|Jinjin Cai et.al.|[2410.09289v1](http://arxiv.org/abs/2410.09289v1)|null|
|**2024-10-11**|**LLMD: A Large Language Model for Interpreting Longitudinal Medical Records**|Robert Porter et.al.|[2410.12860v1](http://arxiv.org/abs/2410.12860v1)|null|
|**2024-10-11**|**Large Language Models for Medical OSCE Assessment: A Novel Approach to Transcript Analysis**|Ameer Hamza Shakur et.al.|[2410.12858v1](http://arxiv.org/abs/2410.12858v1)|null|
|**2024-10-11**|**Optimized Biomedical Question-Answering Services with LLM and Multi-BERT Integration**|Cheng Qian et.al.|[2410.12856v1](http://arxiv.org/abs/2410.12856v1)|null|
|**2024-10-11**|**Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models**|Yeeun Kim et.al.|[2410.08731v1](http://arxiv.org/abs/2410.08731v1)|[link](https://github.com/lbox-kr/kbl)|
|**2024-10-11**|**ViT3D Alignment of LLaMA3: 3D Medical Image Report Generation**|Siyou Li et.al.|[2410.08588v1](http://arxiv.org/abs/2410.08588v1)|null|
|**2024-10-11**|**oRetrieval Augmented Generation for 10 Large Language Models and its Generalizability in Assessing Medical Fitness**|Yu He Ke et.al.|[2410.08431v1](http://arxiv.org/abs/2410.08431v1)|null|
|**2024-10-10**|**VoxelPrompt: A Vision-Language Agent for Grounded Medical Image Analysis**|Andrew Hoopes et.al.|[2410.08397v1](http://arxiv.org/abs/2410.08397v1)|null|
|**2024-10-10**|**Optimizing Vital Sign Monitoring in Resource-Constrained Maternal Care: An RL-Based Restless Bandit Approach**|Niclas Boehmer et.al.|[2410.08377v1](http://arxiv.org/abs/2410.08377v1)|null|
|**2024-10-10**|**ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation**|L√©o Machado et.al.|[2410.07908v2](http://arxiv.org/abs/2410.07908v2)|null|
|**2024-10-10**|**Exploring ASR-Based Wav2Vec2 for Automated Speech Disorder Assessment: Insights and Analysis**|Tuan Nguyen et.al.|[2410.08250v1](http://arxiv.org/abs/2410.08250v1)|null|
|**2024-10-10**|**Forecasting mortality associated emergency department crowding**|Jalmari Nevanlinna et.al.|[2410.08247v1](http://arxiv.org/abs/2410.08247v1)|null|
|**2024-10-10**|**Prompt Engineering a Schizophrenia Chatbot: Utilizing a Multi-Agent Approach for Enhanced Compliance with Prompt Instructions**|Per Niklas Waaler et.al.|[2410.12848v1](http://arxiv.org/abs/2410.12848v1)|null|
|**2024-10-10**|**Flex-MoE: Modeling Arbitrary Modality Combination via the Flexible Mixture-of-Experts**|Sukwon Yun et.al.|[2410.08245v1](http://arxiv.org/abs/2410.08245v1)|[link](https://github.com/unites-lab/flex-moe)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-10**|**Toward Relieving Clinician Burden by Automatically Generating Progress Notes using Interim Hospital Data**|Sarvesh Soni et.al.|[2410.12845v1](http://arxiv.org/abs/2410.12845v1)|null|
|**2024-10-10**|**Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare**|Nan Fang et.al.|[2410.07525v2](http://arxiv.org/abs/2410.07525v2)|null|
|**2024-10-09**|**A Two-Model Approach for Humour Style Recognition**|Mary Ogbuka Kenneth et.al.|[2410.12842v1](http://arxiv.org/abs/2410.12842v1)|[link](https://github.com/MaryKenneth/Two_Model_Humour_Style)|
|**2024-10-09**|**Unlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing**|Ismail Erbas et.al.|[2410.07364v1](http://arxiv.org/abs/2410.07364v1)|null|
|**2024-10-09**|**Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy**|Vivian Nguyen et.al.|[2410.07147v1](http://arxiv.org/abs/2410.07147v1)|null|
|**2024-10-09**|**Mental Disorders Detection in the Era of Large Language Models**|Gleb Kuzmin et.al.|[2410.07129v2](http://arxiv.org/abs/2410.07129v2)|null|
|**2024-10-09**|**MentalArena: Self-play Training of Language Models for Diagnosis and Treatment of Mental Health Disorders**|Cheng Li et.al.|[2410.06845v1](http://arxiv.org/abs/2410.06845v1)|[link](https://github.com/scarelette/mentalarena)|
|**2024-10-09**|**An Improved Approach for Cardiac MRI Segmentation based on 3D UNet Combined with Papillary Muscle Exclusion**|Narjes Benameur et.al.|[2410.06818v1](http://arxiv.org/abs/2410.06818v1)|null|
|**2024-10-09**|**Deep Learning for Surgical Instrument Recognition and Segmentation in Robotic-Assisted Surgeries: A Systematic Review**|Fatimaelzahraa Ali Ahmed et.al.|[2410.07269v1](http://arxiv.org/abs/2410.07269v1)|null|
|**2024-10-08**|**Multimodal Representation Learning using Adaptive Graph Construction**|Weichen Huang et.al.|[2410.06395v1](http://arxiv.org/abs/2410.06395v1)|null|
|**2024-10-08**|**Skin Cancer Machine Learning Model Tone Bias**|James Pope et.al.|[2410.06385v1](http://arxiv.org/abs/2410.06385v1)|null|
|**2024-10-08**|**HumVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid**|Hemank Lamba et.al.|[2410.06370v2](http://arxiv.org/abs/2410.06370v2)|[link](https://github.com/dataminr-ai/humvi-dataset)|
|**2024-10-08**|**A Comparative Study of Hybrid Models in Health Misinformation Text Classification**|Mkululi Sikosana et.al.|[2410.06311v1](http://arxiv.org/abs/2410.06311v1)|null|
|**2024-10-08**|**Application of NotebookLM, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging**|Ryota Tozuka et.al.|[2410.10869v1](http://arxiv.org/abs/2410.10869v1)|null|
|**2024-10-08**|**CodeUnlearn: Amortized Zero-Shot Machine Unlearning in Language Models Using Discrete Concept**|YuXuan Wu et.al.|[2410.10866v1](http://arxiv.org/abs/2410.10866v1)|null|
|**2024-10-08**|**KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server**|Wenhao Wang et.al.|[2410.05725v2](http://arxiv.org/abs/2410.05725v2)|[link](https://github.com/wwh0411/knowledgesg)|
|**2024-10-08**|**Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs**|Yi Jiang et.al.|[2410.05684v2](http://arxiv.org/abs/2410.05684v2)|null|
|**2024-10-08**|**NegMerge: Consensual Weight Negation for Strong Machine Unlearning**|Hyoseo Kim et.al.|[2410.05583v1](http://arxiv.org/abs/2410.05583v1)|[link](https://github.com/naver-ai/negmerge)|
|**2024-10-07**|**AI-Driven Early Mental Health Screening with Limited Data: Analyzing Selfies of Pregnant Women**|Gustavo A. Bas√≠lio et.al.|[2410.05450v1](http://arxiv.org/abs/2410.05450v1)|null|
|**2024-10-07**|**Improving Predictor Reliability with Selective Recalibration**|Thomas P. Zollo et.al.|[2410.05407v1](http://arxiv.org/abs/2410.05407v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|null|
|**2024-10-07**|**RespLLM: Unifying Audio and Text with Multimodal LLMs for Generalized Respiratory Health Prediction**|Yuwei Zhang et.al.|[2410.05361v1](http://arxiv.org/abs/2410.05361v1)|null|
|**2024-10-07**|**Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization**|Rohan Reddy Mekala et.al.|[2410.05114v1](http://arxiv.org/abs/2410.05114v1)|null|
|**2024-10-07**|**Named Clinical Entity Recognition Benchmark**|Wadood M Abdul et.al.|[2410.05046v1](http://arxiv.org/abs/2410.05046v1)|[link](https://github.com/wadoodabdul/clinical_ner_benchmark)|
|**2024-10-07**|**Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data**|Manuel Brenner et.al.|[2410.04814v1](http://arxiv.org/abs/2410.04814v1)|null|
|**2024-10-07**|**$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization**|Dylan Zhang et.al.|[2410.04717v3](http://arxiv.org/abs/2410.04717v3)|null|
|**2024-10-07**|**Rule-based Data Selection for Large Language Models**|Xiaomin Li et.al.|[2410.04715v1](http://arxiv.org/abs/2410.04715v1)|null|
|**2024-10-07**|**Knowledge Graph Based Agent for Complex, Knowledge-Intensive QA in Medicine**|Xiaorui Su et.al.|[2410.04660v1](http://arxiv.org/abs/2410.04660v1)|null|
|**2024-10-06**|**Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task**|Chengyuan Xu et.al.|[2410.11860v1](http://arxiv.org/abs/2410.11860v1)|null|
|**2024-10-06**|**Multi-Tiered Self-Contrastive Learning for Medical Microwave Radiometry (MWR) Breast Cancer Detection**|Christoforos Galazis et.al.|[2410.04636v1](http://arxiv.org/abs/2410.04636v1)|[link](https://github.com/cgalaz01/self_contrastive_mwr)|
|**2024-10-06**|**Semi-Markovian Planning to Coordinate Aerial and Maritime Medical Evacuation Platforms**|Mahdi Al-Husseini et.al.|[2410.04523v1](http://arxiv.org/abs/2410.04523v1)|null|
|**2024-10-06**|**Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Support**|Abdul Muqtadir et.al.|[2410.10853v1](http://arxiv.org/abs/2410.10853v1)|null|

#### Abstracts
##### **Less is More: Selective Reduction of CT Data for Self-Supervised Pre-Training of Deep Learning Models with Contrastive Learning Improves Downstream Classification Performance**
2410.14524v1 by Daniel Wolf, Tristan Payer, Catharina Silvia Lisson, Christoph Gerhard Lisson, Meinrad Beer, Michael G√∂tz, Timo Ropinski

Self-supervised pre-training of deep learning models with contrastive
learning is a widely used technique in image analysis. Current findings
indicate a strong potential for contrastive pre-training on medical images.
However, further research is necessary to incorporate the particular
characteristics of these images. We hypothesize that the similarity of medical
images hinders the success of contrastive learning in the medical imaging
domain. To this end, we investigate different strategies based on deep
embedding, information theory, and hashing in order to identify and reduce
redundancy in medical pre-training datasets. The effect of these different
reduction strategies on contrastive learning is evaluated on two pre-training
datasets and several downstream classification tasks. In all of our
experiments, dataset reduction leads to a considerable performance gain in
downstream tasks, e.g., an AUC score improvement from 0.78 to 0.83 for the
COVID CT Classification Grand Challenge, 0.97 to 0.98 for the OrganSMNIST
Classification Challenge and 0.73 to 0.83 for a brain hemorrhage classification
task. Furthermore, pre-training is up to nine times faster due to the dataset
reduction. In conclusion, the proposed approach highlights the importance of
dataset quality and provides a transferable approach to improve contrastive
pre-training for classification downstream tasks on medical images.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÂ∞çÊØîÂ≠∏ÁøíËá™Áõ£Áù£È†êË®ìÁ∑¥ÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÁî®ÊñºÂΩ±ÂÉèÂàÜÊûêÁöÑÊäÄË°ì„ÄÇÁõÆÂâçÁöÑÁôºÁèæÈ°ØÁ§∫Â∞çÊØîÈ†êË®ìÁ∑¥Âú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏äÂÖ∑ÊúâÂº∑Â§ßÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂Â∞çÊñºÁ¥çÂÖ•ÈÄô‰∫õÂΩ±ÂÉèÁöÑÁâπÂÆöÁâπÂæµÊòØÂøÖË¶ÅÁöÑ„ÄÇÊàëÂÄëÂÅáË®≠ÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÁõ∏‰ººÊÄßÈòªÁ§ô‰∫ÜÂ∞çÊØîÂ≠∏ÁøíÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüüÁöÑÊàêÂäü„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÁ†îÁ©∂‰∫ÜÂü∫ÊñºÊ∑±Â∫¶ÂµåÂÖ•„ÄÅË≥áË®äÁêÜË´ñÂíåÈõúÊπäÁöÑ‰∏çÂêåÁ≠ñÁï•Ôºå‰ª•Ë≠òÂà•ÂíåÊ∏õÂ∞ëÈÜ´Â≠∏È†êË®ìÁ∑¥Ë≥áÊñôÈõÜ‰∏≠ÁöÑÂÜóÈ§ò„ÄÇÈÄô‰∫õ‰∏çÂêåÁöÑÁ∞°ÂåñÁ≠ñÁï•Â∞çÊØîÂ≠∏ÁøíÁöÑÂΩ±ÈüøÂú®ÂÖ©ÂÄãÈ†êË®ìÁ∑¥Ë≥áÊñôÈõÜÂíåÂπæÂÄã‰∏ãÊ∏∏ÂàÜÈ°û‰ªªÂãô‰∏≠ÈÄ≤Ë°åË©ï‰º∞„ÄÇÂú®ÊàëÂÄëÊâÄÊúâÁöÑÂØ¶È©ó‰∏≠ÔºåË≥áÊñôÈõÜÁ∞°ÂåñÈÉΩÂ∞éËá¥‰∫Ü‰∏ãÊ∏∏‰ªªÂãôÁöÑÈ°ØËëóÊïàËÉΩÊèêÂçáÔºå‰æãÂ¶ÇÔºåCOVID CT ÂàÜÈ°ûÂ§ßÊåëÊà∞ÁöÑ AUC ÂàÜÊï∏Âæû 0.78 ÊèêÂçáËá≥ 0.83ÔºåOrganSMNIST ÂàÜÈ°ûÊåëÊà∞Âæû 0.97 ÊèêÂçáËá≥ 0.98ÔºåËÖ¶Âá∫Ë°ÄÂàÜÈ°û‰ªªÂãôÂæû 0.73 ÊèêÂçáËá≥ 0.83„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºË≥áÊñôÈõÜÁ∞°ÂåñÔºåÈ†êË®ìÁ∑¥ÈÄüÂ∫¶ÊúÄÈ´òÂèØÊèêÂçá‰πùÂÄç„ÄÇÁ∏Ω‰πãÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁ™ÅÈ°Ø‰∫ÜË≥áÊñôÈõÜÂìÅË≥™ÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØËΩâÁßªÁöÑÊñπÊ≥ï‰æÜÊîπÂñÑÈÜ´Â≠∏ÂΩ±ÂÉè‰∏äÂàÜÈ°û‰∏ãÊ∏∏‰ªªÂãôÁöÑÂ∞çÊØîÈ†êË®ìÁ∑¥„ÄÇ

##### **A Scientific Machine Learning Approach for Predicting and Forecasting Battery Degradation in Electric Vehicles**
2410.14347v1 by Sharv Murgai, Hrishikesh Bhagwat, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat

Carbon emissions are rising at an alarming rate, posing a significant threat
to global efforts to mitigate climate change. Electric vehicles have emerged as
a promising solution, but their reliance on lithium-ion batteries introduces
the critical challenge of battery degradation. Accurate prediction and
forecasting of battery degradation over both short and long time spans are
essential for optimizing performance, extending battery life, and ensuring
effective long-term energy management. This directly influences the
reliability, safety, and sustainability of EVs, supporting their widespread
adoption and aligning with key UN SDGs. In this paper, we present a novel
approach to the prediction and long-term forecasting of battery degradation
using Scientific Machine Learning framework which integrates domain knowledge
with neural networks, offering more interpretable and scientifically grounded
solutions for both predicting short-term battery health and forecasting
degradation over extended periods. This hybrid approach captures both known and
unknown degradation dynamics, improving predictive accuracy while reducing data
requirements. We incorporate ground-truth data to inform our models, ensuring
that both the predictions and forecasts reflect practical conditions. The model
achieved MSE of 9.90 with the UDE and 11.55 with the NeuralODE, in experimental
data, a loss of 1.6986 with the UDE, and a MSE of 2.49 in the NeuralODE,
demonstrating the enhanced precision of our approach. This integration of
data-driven insights with SciML's strengths in interpretability and scalability
allows for robust battery management. By enhancing battery longevity and
minimizing waste, our approach contributes to the sustainability of energy
systems and accelerates the global transition toward cleaner, more responsible
energy solutions, aligning with the UN's SDG agenda.

ÊëòË¶ÅÔºöÁ¢≥ÊéíÊîæÈáèÊ≠£‰ª•È©ö‰∫∫ÁöÑÈÄüÂ∫¶‰∏äÂçáÔºåÂ∞çÂÖ®ÁêÉÊ∏õÁ∑©Ê∞£ÂÄôËÆäÈÅ∑ÁöÑÂä™ÂäõÊßãÊàêÈáçÂ§ßÂ®ÅËÑÖ„ÄÇÈõªÂãïËªäÂ∑≤ÊàêÁÇ∫‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ΩÜÂÆÉÂÄë‰æùË≥¥Èã∞Èõ¢Â≠êÈõªÊ±†ÔºåÂºïÂÖ•‰∫ÜÈõªÊ±†Âä£ÂåñÈÄôÂÄãÂö¥Â≥ªÁöÑÊåëÊà∞„ÄÇÊ∫ñÁ¢∫È†êÊ∏¨ÂíåÈ†êÊ∏¨ÈõªÊ±†Âú®Áü≠ÊúüÂíåÈï∑ÊúüÂÖßÁöÑÂä£ÂåñÂ∞çÊñºÊúÄ‰Ω≥ÂåñÊïàËÉΩ„ÄÅÂª∂Èï∑ÈõªÊ±†Â£ΩÂëΩ‰ª•ÂèäÁ¢∫‰øùÊúâÊïàÁöÑÈï∑ÊúüËÉΩÊ∫êÁÆ°ÁêÜËá≥ÈóúÈáçË¶Å„ÄÇÈÄôÁõ¥Êé•ÂΩ±ÈüøÈõªÂãïËªäÁöÑÂèØÈù†ÊÄß„ÄÅÂÆâÂÖ®ÊÄßËàáÊ∞∏Á∫åÊÄßÔºåÊîØÊåÅÂÆÉÂÄëÁöÑÂª£Ê≥õÊé°Áî®Ôºå‰∏¶ËàáËÅØÂêàÂúãÊ∞∏Á∫åÁôºÂ±ïÁõÆÊ®ô‰øùÊåÅ‰∏ÄËá¥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºå‰ΩøÁî®ÁßëÂ≠∏Ê©üÂô®Â≠∏ÁøíÊ°ÜÊû∂‰æÜÈ†êÊ∏¨ÂíåÈï∑ÊúüÈ†êÊ∏¨ÈõªÊ±†Âä£ÂåñÔºåË©≤Ê°ÜÊû∂Â∞áÈ†òÂüüÁü•Ë≠òËàáÁ•ûÁ∂ìÁ∂≤Ë∑ØÊï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÁÇ∫È†êÊ∏¨Áü≠ÊúüÈõªÊ±†ÂÅ•Â∫∑ÁãÄÊ≥ÅÂíåÈ†êÊ∏¨Èï∑ÊúüÂä£ÂåñÊèê‰æõÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÂíåÁßëÂ≠∏‰æùÊìöÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÈÄôÁ®ÆÊ∑∑ÂêàÊñπÊ≥ïÊçïÊçâÂ∑≤Áü•ÂíåÊú™Áü•ÁöÑÂä£ÂåñÂãïÊÖãÔºåÂú®Ê∏õÂ∞ëË≥áÊñôÈúÄÊ±ÇÁöÑÂêåÊôÇÊèêÈ´òÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁ¥çÂÖ•ÁúüÂØ¶Ë≥áÊñô‰æÜÂëäÁü•ÊàëÂÄëÁöÑÊ®°ÂûãÔºåÁ¢∫‰øùÈ†êÊ∏¨ÂíåÈ†êÊ∏¨ÈÉΩÂèçÊò†ÂØ¶ÈöõÊÉÖÊ≥Å„ÄÇË©≤Ê®°ÂûãÂú®ÂØ¶È©óË≥áÊñô‰∏≠‰ΩøÁî® UDE ÈÅîÂà∞ 9.90 ÁöÑ MSEÔºå‰ΩøÁî® NeuralODE ÈÅîÂà∞ 11.55Ôºå‰ΩøÁî® UDE ÊêçÂ§± 1.6986Ôºå‰ΩøÁî® NeuralODE ÈÅîÂà∞ 2.49 ÁöÑ MSEÔºåË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÁ≤æÁ¢∫Â∫¶ÊúâÊâÄÊèêÂçá„ÄÇÂ∞áË≥áÊñôÈ©ÖÂãïÁöÑÊ¥ûÂØüËàá SciML Âú®ÂèØËß£ÈáãÊÄßÂíåÂèØÊì¥ÂÖÖÊÄßÊñπÈù¢ÁöÑÂÑ™Âã¢Áõ∏ÁµêÂêàÔºåÂèØ‰ª•ÂØ¶ÁèæÂº∑Â§ßÁöÑÈõªÊ±†ÁÆ°ÁêÜ„ÄÇÈÄèÈÅéÊèêÂçáÈõªÊ±†Â£ΩÂëΩÂíåÊ∏õÂ∞ëÊµ™Ë≤ªÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÂä©ÊñºËÉΩÊ∫êÁ≥ªÁµ±Ê∞∏Á∫åÁôºÂ±ïÔºå‰∏¶Âä†ÈÄüÂÖ®ÁêÉÊúùÂêëÊõ¥Ê∏ÖÊΩî„ÄÅÊõ¥Ë≤†Ë≤¨‰ªªÁöÑËÉΩÊ∫êËß£Ê±∫ÊñπÊ°àÈÅéÊ∏°ÔºåËàáËÅØÂêàÂúãÊ∞∏Á∫åÁôºÂ±ïÁõÆÊ®ôË≠∞Á®ã‰øùÊåÅ‰∏ÄËá¥„ÄÇ

##### **Deep Learning Applications in Medical Image Analysis: Advancements, Challenges, and Future Directions**
2410.14131v1 by Aimina Ali Eli, Abida Ali

Medical image analysis has emerged as an essential element of contemporary
healthcare, facilitating physicians in achieving expedited and precise
diagnosis. Recent breakthroughs in deep learning, a subset of artificial
intelligence, have markedly revolutionized the analysis of medical pictures,
improving the accuracy and efficiency of clinical procedures. Deep learning
algorithms, especially convolutional neural networks (CNNs), have demonstrated
remarkable proficiency in autonomously learning features from multidimensional
medical pictures, including MRI, CT, and X-ray scans, without the necessity for
manual feature extraction. These models have been utilized across multiple
medical disciplines, including pathology, radiology, ophthalmology, and
cardiology, where they aid in illness detection, classification, and
segmentation tasks......

ÊëòË¶ÅÔºöÈÜ´ÁôÇÂΩ±ÂÉèÂàÜÊûêÂ∑≤ÊàêÁÇ∫Áèæ‰ª£ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÂÖÉÁ¥†ÔºåÂçîÂä©ÈÜ´Â∏´Âø´ÈÄü‰∏îÁ≤æÁ¢∫Âú∞ÈÄ≤Ë°åË®∫Êñ∑„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÔºà‰∫∫Â∑•Êô∫ÊÖßÁöÑÂ≠êÈõÜÔºâÁöÑÊúÄÊñ∞Á™ÅÁ†¥È°ØËëóÂú∞Èù©Êñ∞‰∫ÜÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÂàÜÊûêÔºåÊèêÂçáËá®Â∫äÁ®ãÂ∫èÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéá„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºàCNNÔºâÔºåÂ∑≤Â±ïÁèæÂá∫ÂæûÂ§öÁ∂≠Â∫¶ÈÜ´Â≠∏ÂΩ±ÂÉèÔºàÂåÖÊã¨ MRI„ÄÅCT Âíå X ÂÖâÊéÉÊèèÔºâ‰∏≠Ëá™‰∏ªÂ≠∏ÁøíÁâπÂæµÁöÑÂçìË∂äËÉΩÂäõÔºåÁÑ°ÈúÄÊâãÂãïÁâπÂæµËêÉÂèñ„ÄÇÈÄô‰∫õÊ®°ÂûãÂ∑≤ÊáâÁî®ÊñºÂ§öÁ®ÆÈÜ´Â≠∏È†òÂüüÔºåÂåÖÊã¨ÁóÖÁêÜÂ≠∏„ÄÅÊîæÂ∞ÑÂ≠∏„ÄÅÁúºÁßëÂ≠∏ÂíåÂøÉËáüÁóÖÂ≠∏ÔºåÂçîÂä©ÁñæÁóÖÂÅµÊ∏¨„ÄÅÂàÜÈ°ûÂíåÂàÜÂâ≤‰ªªÂãô......

##### **Identifying High Consideration E-Commerce Search Queries**
2410.13951v1 by Zhiyu Chen, Jason Choi, Besnik Fetahu, Shervin Malmasi

In e-commerce, high consideration search missions typically require careful
and elaborate decision making, and involve a substantial research investment
from customers. We consider the task of identifying High Consideration (HC)
queries. Identifying such queries enables e-commerce sites to better serve user
needs using targeted experiences such as curated QA widgets that help users
reach purchase decisions. We explore the task by proposing an Engagement-based
Query Ranking (EQR) approach, focusing on query ranking to indicate potential
engagement levels with query-related shopping knowledge content during product
search. Unlike previous studies on predicting trends, EQR prioritizes
query-level features related to customer behavior, finance, and catalog
information rather than popularity signals. We introduce an accurate and
scalable method for EQR and present experimental results demonstrating its
effectiveness. Offline experiments show strong ranking performance. Human
evaluation shows a precision of 96% for HC queries identified by our model. The
model was commercially deployed, and shown to outperform human-selected queries
in terms of downstream customer impact, as measured through engagement.

ÊëòË¶ÅÔºöÂú®ÈõªÂ≠êÂïÜÂãô‰∏≠ÔºåÈ´òËÄÉÊÖÆÊêúÂ∞ã‰ªªÂãôÈÄöÂ∏∏ÈúÄË¶ÅË¨πÊÖéËÄåÁ≤æÁ¥∞ÁöÑÊ±∫Á≠ñÂà∂ÂÆöÔºå‰∏¶Ê∂âÂèäÂÆ¢Êà∂Â§ßÈáèÁöÑÁ†îÁ©∂ÊäïË≥á„ÄÇÊàëÂÄëËÄÉÊÖÆ‰∫ÜË≠òÂà•È´òËÄÉÊÖÆ (HC) Êü•Ë©¢ÁöÑ‰ªªÂãô„ÄÇË≠òÂà•Ê≠§È°ûÊü•Ë©¢ËÉΩ‰ΩøÈõªÂ≠êÂïÜÂãôÁ∂≤Á´ô‰ΩøÁî®ÁõÆÊ®ôÈ´îÈ©óÔºà‰æãÂ¶ÇÂçîÂä©‰ΩøÁî®ËÄÖÂÅöÂá∫Ë≥ºË≤∑Ê±∫Á≠ñÁöÑÁ≤æÈÅ∏ÂïèÁ≠îÂ∞èÂ∑•ÂÖ∑Ôºâ‰æÜÊõ¥Â•ΩÂú∞ÊªøË∂≥‰ΩøÁî®ËÄÖÈúÄÊ±Ç„ÄÇÊàëÂÄëÈÄèÈÅéÊèêÂá∫‰ª•ÂèÉËàáÁÇ∫Âü∫Á§éÁöÑÊü•Ë©¢ÊéíÂêç (EQR) ÊñπÊ≥ï‰æÜÊé¢Á¥¢Ê≠§‰ªªÂãôÔºåÂ∞àÊ≥®ÊñºÊü•Ë©¢ÊéíÂêç‰ª•ÊåáÂá∫Âú®Áî¢ÂìÅÊêúÂ∞ãÊúüÈñìËàáÊü•Ë©¢Áõ∏ÈóúÁöÑË≥ºÁâ©Áü•Ë≠òÂÖßÂÆπÁöÑÊΩõÂú®ÂèÉËàáÂ±§Á¥ö„ÄÇËàáÂÖàÂâçÈ†êÊ∏¨Ë∂®Âã¢ÁöÑÁ†îÁ©∂‰∏çÂêåÔºåEQR ÂÑ™ÂÖàËÄÉÊÖÆËàáÂÆ¢Êà∂Ë°åÁÇ∫„ÄÅË≤°ÂãôÂíåÁõÆÈåÑË≥áË®äÁõ∏ÈóúÁöÑÊü•Ë©¢Â±§Á¥öÂäüËÉΩÔºåËÄå‰∏çÊòØÁÜ±ÈñÄÂ∫¶Ë®äËôü„ÄÇÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊ∫ñÁ¢∫‰∏îÂèØÊì¥ÂÖÖÁöÑ EQR ÊñπÊ≥ïÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂÖ∂ÊúâÊïàÊÄßÁöÑÂØ¶È©óÁµêÊûú„ÄÇÈõ¢Á∑öÂØ¶È©óÈ°ØÁ§∫Âá∫Âº∑Â§ßÁöÑÊéíÂêçÊïàËÉΩ„ÄÇ‰∫∫Â∑•Ë©ï‰º∞È°ØÁ§∫ÊàëÂÄëÁöÑÊ®°ÂûãË≠òÂà•Âá∫ÁöÑ HC Êü•Ë©¢Êúâ 96% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇË©≤Ê®°ÂûãÂ∑≤ÂïÜÊ•≠ÂåñÈÉ®ÁΩ≤Ôºå‰∏¶È°ØÁ§∫Âú®ÂèÉËàáÂ∫¶Ë°°ÈáèÊ®ôÊ∫ñ‰∏ãÔºåÂÖ∂ÊïàËÉΩÂÑ™Êñº‰∫∫Â∑•ÈÅ∏ÂèñÁöÑÊü•Ë©¢Ôºå‰ª•ÂΩ±Èüø‰∏ãÊ∏∏ÂÆ¢Êà∂„ÄÇ

##### **The KnowWhereGraph Ontology**
2410.13948v1 by Cogan Shimizu, Shirly Stephe, Adrita Barua, Ling Cai, Antrea Christou, Kitty Currier, Abhilekha Dalal, Colby K. Fisher, Pascal Hitzler, Krzysztof Janowicz, Wenwen Li, Zilong Liu, Mohammad Saeid Mahdavinejad, Gengchen Mai, Dean Rehberger, Mark Schildhauer, Meilin Shi, Sanaz Saki Norouzi, Yuanyuan Tian, Sizhe Wang, Zhangyu Wang, Joseph Zalewski, Lu Zhou, Rui Zhu

KnowWhereGraph is one of the largest fully publicly available geospatial
knowledge graphs. It includes data from 30 layers on natural hazards (e.g.,
hurricanes, wildfires), climate variables (e.g., air temperature,
precipitation), soil properties, crop and land-cover types, demographics, and
human health, various place and region identifiers, among other themes. These
have been leveraged through the graph by a variety of applications to address
challenges in food security and agricultural supply chains; sustainability
related to soil conservation practices and farm labor; and delivery of
emergency humanitarian aid following a disaster. In this paper, we introduce
the ontology that acts as the schema for KnowWhereGraph. This broad overview
provides insight into the requirements and design specifications for the graph
and its schema, including the development methodology (modular ontology
modeling) and the resources utilized to implement, materialize, and deploy
KnowWhereGraph with its end-user interfaces and public query SPARQL endpoint.

ÊëòË¶ÅÔºöKnowWhereGraph ÊòØÊúÄÂ§ßÁöÑÂÆåÂÖ®ÂÖ¨ÈñãÂèØÁî®ÁöÑÂú∞ÁêÜÁ©∫ÈñìÁü•Ë≠òÂúñË≠ú‰πã‰∏Ä„ÄÇÂÆÉÂåÖÂê´‰æÜËá™ 30 Â±§ÁöÑËá™ÁÑ∂ÁÅΩÂÆ≥Ôºà‰æãÂ¶ÇÈ¢∂È¢®„ÄÅÈáéÁÅ´Ôºâ„ÄÅÊ∞£ÂÄôËÆäÈáèÔºà‰æãÂ¶ÇÊ∞£Ê∫´„ÄÅÈôçÊ∞¥Ôºâ„ÄÅÂúüÂ£§ÁâπÊÄß„ÄÅ‰ΩúÁâ©ÂíåÂúüÂú∞Ë¶ÜËìãÈ°ûÂûã„ÄÅ‰∫∫Âè£Áµ±Ë®àÂíå‰∫∫È°ûÂÅ•Â∫∑„ÄÅÂêÑÁ®ÆÂú∞ÊñπÂíåÂçÄÂüüË≠òÂà•Á¨¶Á≠â‰∏ªÈ°åÁöÑÊï∏Êìö„ÄÇÈÄô‰∫õÊï∏ÊìöÂ∑≤ÈÄöÈÅéÂúñË°®Ë¢´ÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÂà©Áî®Ôºå‰ª•ÊáâÂ∞çÁ≥ßÈ£üÂÆâÂÖ®ÂíåËæ≤Ê•≠‰æõÊáâÈèà‰∏≠ÁöÑÊåëÊà∞ÔºõËàáÂúüÂ£§‰øùËÇ≤Êé™ÊñΩÂíåËæ≤Â†¥ÂãûÂãïÂäõÁõ∏ÈóúÁöÑÂèØÊåÅÁ∫åÊÄßÔºõ‰ª•ÂèäÂú®ÁÅΩÂÆ≥ÁôºÁîüÂæåÊèê‰æõÁ∑äÊÄ•‰∫∫ÈÅì‰∏ªÁæ©Êè¥Âä©„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰ΩúÁÇ∫ KnowWhereGraph Êû∂ÊßãÁöÑÊú¨‰Ωì„ÄÇÈÄôÂÄãÂª£Ê≥õÁöÑÊ¶ÇËø∞Êèê‰æõ‰∫ÜÂ∞çÂúñË°®ÂèäÂÖ∂Êû∂ÊßãÁöÑË¶ÅÊ±ÇÂíåË®≠Ë®àË¶èÁØÑÁöÑË¶ãËß£ÔºåÂåÖÊã¨ÈñãÁôºÊñπÊ≥ïÔºàÊ®°ÁµÑÂåñÊú¨‰ΩìÂª∫Ê®°ÔºâÂíåÁî®ÊñºÂØ¶‰Ωú„ÄÅÂÖ∑È´îÂåñÂíåÈÉ®ÁΩ≤ KnowWhereGraph ÂèäÂÖ∂ÊúÄÁµÇ‰ΩøÁî®ËÄÖ‰ªãÈù¢ÂíåÂÖ¨ÈñãÊü•Ë©¢ SPARQL Á´ØÈªûÁöÑË≥áÊ∫ê„ÄÇ

##### **The Disparate Benefits of Deep Ensembles**
2410.13831v1 by Kajetan Schweighofer, Adrian Arnaiz-Rodriguez, Sepp Hochreiter, Nuria Oliver

Ensembles of Deep Neural Networks, Deep Ensembles, are widely used as a
simple way to boost predictive performance. However, their impact on
algorithmic fairness is not well understood yet. Algorithmic fairness
investigates how a model's performance varies across different groups,
typically defined by protected attributes such as age, gender, or race. In this
work, we investigate the interplay between the performance gains from Deep
Ensembles and fairness. Our analysis reveals that they unevenly favor different
groups in what we refer to as a disparate benefits effect. We empirically
investigate this effect with Deep Ensembles applied to popular facial analysis
and medical imaging datasets, where protected group attributes are given and
find that it occurs for multiple established group fairness metrics, including
statistical parity and equal opportunity. Furthermore, we identify the
per-group difference in predictive diversity of ensemble members as the
potential cause of the disparate benefits effect. Finally, we evaluate
different approaches to reduce unfairness due to the disparate benefits effect.
Our findings show that post-processing is an effective method to mitigate this
unfairness while preserving the improved performance of Deep Ensembles.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Á•ûÁªèÁ∂≤Ë∑ØÁöÑÈõÜÂêàÔºåÊ∑±Â∫¶ÈõÜÂêàÔºåË¢´Âª£Ê≥õÁî®‰ΩúÊèêÂçáÈ†êÊ∏¨ÊïàËÉΩÁöÑÁ∞°ÂñÆÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂ∞çÊºîÁÆóÊ≥ïÂÖ¨Âπ≥ÊÄßÁöÑÂΩ±ÈüøÂ∞öÊú™Ë¢´ÂÖÖÂàÜÁêÜËß£„ÄÇÊºîÁÆóÊ≥ïÂÖ¨Âπ≥ÊÄßÊé¢Ë®éÊ®°ÂûãÁöÑÊïàËÉΩÂ¶Ç‰ΩïÂõ†‰∏çÂêåÁæ§ÁµÑËÄåÁï∞ÔºåÈÄô‰∫õÁæ§ÁµÑÈÄöÂ∏∏Áî±Âèó‰øùË≠∑ÁöÑÂ±¨ÊÄßÔºà‰æãÂ¶ÇÂπ¥ÈΩ°„ÄÅÊÄßÂà•ÊàñÁ®ÆÊóèÔºâÂÆöÁæ©„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÊ∑±Â∫¶ÈõÜÂêàÁöÑÊïàËÉΩÊèêÂçáËàáÂÖ¨Âπ≥ÊÄß‰πãÈñìÁöÑ‰∫§‰∫í‰ΩúÁî®„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂÆÉÂÄë‰∏çÂùáÂãªÂú∞ÂÅèÂ•Ω‰∏çÂêåÁæ§ÁµÑÔºåÊàëÂÄëÁ®±‰πãÁÇ∫‰∏çÂêåÁöÑÂ•ΩËôïÊïàÊáâ„ÄÇÊàëÂÄë‰ª•ÊáâÁî®ÊñºÊµÅË°åÈù¢ÈÉ®ÂàÜÊûêÂíåÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜÁöÑÊ∑±Â∫¶ÈõÜÂêàÔºåÂ∞çÊ≠§ÊïàÊáâÈÄ≤Ë°åÂØ¶Ë≠âÊé¢Ë®éÔºåÂÖ∂‰∏≠Êèê‰æõ‰∫ÜÂèó‰øùË≠∑Áæ§ÁµÑÂ±¨ÊÄßÔºå‰∏¶ÁôºÁèæÂÆÉÁôºÁîüÂú®Â§öÂÄãÂ∑≤Âª∫Á´ãÁöÑÁæ§ÁµÑÂÖ¨Âπ≥ÊÄßÊåáÊ®ô‰∏≠ÔºåÂåÖÊã¨Áµ±Ë®àÂêåÁ≠âÊÄßÂíåÊ©üÊúÉÂùáÁ≠â„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞áÈ†êÊ∏¨Â§öÊ®£ÊÄßÂú®ÈõÜÂêàÊàêÂì°‰∏≠ÁöÑÁæ§ÁµÑÂ∑ÆÁï∞ÔºåË¶ñÁÇ∫‰∏çÂêåÁöÑÂ•ΩËôïÊïàÊáâÁöÑÊΩõÂú®ÂéüÂõ†„ÄÇÊúÄÂæåÔºåÊàëÂÄëË©ï‰º∞‰∫Ü‰∏çÂêåÁöÑÊñπÊ≥ïÔºå‰ª•Ê∏õÂ∞ëÁî±Êñº‰∏çÂêåÁöÑÂ•ΩËôïÊïàÊáâËÄåÂ∞éËá¥ÁöÑ‰∏çÂÖ¨Âπ≥ÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂæåËôïÁêÜÊòØ‰∏ÄÁ®ÆÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Ê∏õËºïÈÄôÁ®Æ‰∏çÂÖ¨Âπ≥ÊÄßÔºåÂêåÊôÇ‰øùÁïôÊ∑±Â∫¶ÈõÜÂêàÁöÑÊïàËÉΩÊèêÂçá„ÄÇ

##### **Scaling Wearable Foundation Models**
2410.13638v1 by Girish Narayanswamy, Xin Liu, Kumar Ayush, Yuzhe Yang, Xuhai Xu, Shun Liao, Jake Garrison, Shyam Tailor, Jake Sunshine, Yun Liu, Tim Althoff, Shrikanth Narayanan, Pushmeet Kohli, Jiening Zhan, Mark Malhotra, Shwetak Patel, Samy Abdel-Ghaffar, Daniel McDuff

Wearable sensors have become ubiquitous thanks to a variety of health
tracking features. The resulting continuous and longitudinal measurements from
everyday life generate large volumes of data; however, making sense of these
observations for scientific and actionable insights is non-trivial. Inspired by
the empirical success of generative modeling, where large neural networks learn
powerful representations from vast amounts of text, image, video, or audio
data, we investigate the scaling properties of sensor foundation models across
compute, data, and model size. Using a dataset of up to 40 million hours of
in-situ heart rate, heart rate variability, electrodermal activity,
accelerometer, skin temperature, and altimeter per-minute data from over
165,000 people, we create LSM, a multimodal foundation model built on the
largest wearable-signals dataset with the most extensive range of sensor
modalities to date. Our results establish the scaling laws of LSM for tasks
such as imputation, interpolation and extrapolation, both across time and
sensor modalities. Moreover, we highlight how LSM enables sample-efficient
downstream learning for tasks like exercise and activity recognition.

ÊëòË¶ÅÔºö<paragraph>Á©øÊà¥ÂºèÊÑüÊ∏¨Âô®Â∑≤ËÆäÂæóÁÑ°ÊâÄ‰∏çÂú®ÔºåÈÄôË¶ÅÊ≠∏ÂäüÊñºÂêÑÁ®ÆÂÅ•Â∫∑ËøΩËπ§ÂäüËÉΩ„ÄÇÂæûÊó•Â∏∏ÁîüÊ¥ª‰∏≠Áî¢ÁîüÁöÑÈÄ£Á∫å‰∏îÈï∑ÊúüÁöÑÊ∏¨ÈáèÊúÉÁî¢ÁîüÂ§ßÈáèÁöÑË≥áÊñôÔºõÁÑ∂ËÄåÔºåË¶ÅËÆìÈÄô‰∫õËßÄÂØüÁµêÊûúÁî¢ÁîüÁßëÂ≠∏‰∏îÂèØË°åÁöÑË¶ãËß£‰∏¶ÈùûÊòì‰∫ã„ÄÇÂèóÂà∞ÁîüÊàêÂºèÂª∫Ê®°ÁöÑÁ∂ìÈ©óÊàêÂäüÂïüÁôºÔºåÂÖ∂‰∏≠Â§ßÂûãÁ•ûÁ∂ìÁ∂≤Ë∑ØÂæûÂ§ßÈáèÁöÑÊñáÂ≠ó„ÄÅÂΩ±ÂÉè„ÄÅÂΩ±ÁâáÊàñÈü≥Ë®äË≥áÊñô‰∏≠Â≠∏ÁøíÂº∑Â§ßÁöÑË°®ÂæµÔºåÊàëÂÄëÁ†îÁ©∂‰∫ÜÊÑüÊ∏¨Âô®Âü∫Á§éÊ®°ÂûãÂú®ÈÅãÁÆó„ÄÅË≥áÊñôÂíåÊ®°ÂûãÂ§ßÂ∞èÊñπÈù¢ÁöÑË¶èÊ®°ÂåñÂ±¨ÊÄß„ÄÇÊàëÂÄë‰ΩøÁî®‰∏ÄÂÄãË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™Ë∂ÖÈÅé 165,000 ‰∫∫ÁöÑÈï∑ÈÅî 4,000 Ëê¨Â∞èÊôÇÁöÑÁèæÂ†¥ÂøÉÁéá„ÄÅÂøÉÁéáËÆäÁï∞ÊÄß„ÄÅÁöÆËÜöÈõªÊ¥ªÂãï„ÄÅÂä†ÈÄüÂ∫¶Ë®à„ÄÅÁöÆËÜöÊ∫´Â∫¶ÂíåÊØèÂàÜÈêòÈ´òÂ∫¶Ë®àË≥áÊñôÔºåÂª∫Á´ã‰∫Ü LSMÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öÊ®°ÊÖãÂü∫Á§éÊ®°ÂûãÔºåÂª∫ÊßãÂú®ËøÑ‰ªäÁÇ∫Ê≠¢ÂÖ∑ÊúâÊúÄÂª£Ê≥õÊÑüÊ∏¨Âô®Ê®°ÂºèÁöÑÊúÄÂ§ßÁ©øÊà¥ÂºèË®äËôüË≥áÊñôÈõÜ‰∏ä„ÄÇÊàëÂÄëÁöÑÁµêÊûúÂª∫Á´ã‰∫Ü LSM ÁöÑË¶èÊ®°ÂåñÂÆöÂæãÔºåÈÅ©Áî®ÊñºÊôÇÈñìÂíåÊÑüÊ∏¨Âô®Ê®°ÂºèÁöÑ‰ªªÂãôÔºå‰æãÂ¶ÇÂ°´Ë£ú„ÄÅÂÖßÊèíÂíåÂ§ñÊèí„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂº∑Ë™ø‰∫Ü LSM Â¶Ç‰ΩïÁÇ∫ÈÅãÂãïÂíåÊ¥ªÂãïËæ®Ë≠òÁ≠â‰ªªÂãôÂïüÁî®Ê®£Êú¨ÊúâÊïàÁéáÁöÑ‰∏ãÊ∏∏Â≠∏Áøí„ÄÇ</paragraph>

##### **MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling**
2410.13610v1 by Yakun Zhu, Shaohang Wei, Xu Wang, Kui Xue, Xiaofan Zhang, Shaoting Zhang

Integrating tools into Large Language Models (LLMs) has facilitated the
widespread application. Despite this, in specialized downstream task contexts,
reliance solely on tools is insufficient to fully address the complexities of
the real world. This particularly restricts the effective deployment of LLMs in
fields such as medicine. In this paper, we focus on the downstream tasks of
medical calculators, which use standardized tests to assess an individual's
health status. We introduce MeNTi, a universal agent architecture for LLMs.
MeNTi integrates a specialized medical toolkit and employs meta-tool and nested
calling mechanisms to enhance LLM tool utilization. Specifically, it achieves
flexible tool selection and nested tool calling to address practical issues
faced in intricate medical scenarios, including calculator selection, slot
filling, and unit conversion. To assess the capabilities of LLMs for
quantitative assessment throughout the clinical process of calculator
scenarios, we introduce CalcQA. This benchmark requires LLMs to use medical
calculators to perform calculations and assess patient health status. CalcQA is
constructed by professional physicians and includes 100 case-calculator pairs,
complemented by a toolkit of 281 medical tools. The experimental results
demonstrate significant performance improvements with our framework. This
research paves new directions for applying LLMs in demanding scenarios of
medicine.

ÊëòË¶ÅÔºöÂ∞áÂ∑•ÂÖ∑Êï¥ÂêàÂà∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠‰øÉËøõ‰∫ÜÂª£Ê≥õÁöÑÊáâÁî®„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂú®Â∞àÊ•≠ÁöÑ‰∏ãÊ∏∏‰ªªÂãôÊÉÖÂ¢É‰∏≠ÔºåÂñÆÁç®‰æùË≥¥Â∑•ÂÖ∑‰∏çË∂≥‰ª•ÂÖÖÂàÜËß£Ê±∫ÁèæÂØ¶‰∏ñÁïåÁöÑË§áÈõúÊÄß„ÄÇÈÄôÁâπÂà•ÈôêÂà∂‰∫Ü LLM Âú®ÈÜ´Â≠∏Á≠âÈ†òÂüüÁöÑÊúâÊïàÈÉ®ÁΩ≤„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÈÜ´ÁôÇË®àÁÆóÂô®ÁöÑ‰∏ãÊ∏∏‰ªªÂãôÔºåÂÆÉ‰ΩøÁî®Ê®ôÊ∫ñÂåñÊ∏¨Ë©¶‰æÜË©ï‰º∞ÂÄã‰∫∫ÁöÑÂÅ•Â∫∑ÁãÄÊ≥Å„ÄÇÊàëÂÄë‰ªãÁ¥π MeNTiÔºå‰∏ÄÁ®ÆÈÅ©Áî®Êñº LLM ÁöÑÈÄöÁî®‰ª£ÁêÜÊû∂Êßã„ÄÇMeNTi Êï¥Âêà‰∫Ü‰∏ÄÂÄãÂ∞àÊ•≠ÁöÑÈÜ´ÁôÇÂ∑•ÂÖ∑ÂåÖÔºå‰∏¶Êé°Áî®ÂÖÉÂ∑•ÂÖ∑ÂíåÂµåÂ•óÂëºÂè´Ê©üÂà∂‰æÜÂ¢ûÂº∑ LLM Â∑•ÂÖ∑ÁöÑÂà©Áî®Áéá„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂÆÉÂØ¶Áèæ‰∫ÜÈùàÊ¥ªÁöÑÂ∑•ÂÖ∑ÈÅ∏ÊìáÂíåÂµåÂ•óÂ∑•ÂÖ∑ÂëºÂè´Ôºå‰ª•Ëß£Ê±∫Ë§áÈõúÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠Èù¢Ëá®ÁöÑÂØ¶ÈöõÂïèÈ°åÔºåÂåÖÊã¨Ë®àÁÆóÂô®ÈÅ∏Êìá„ÄÅÊèíÊßΩÂ°´ÂÖÖÂíåÂñÆ‰ΩçËΩâÊèõ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ LLM Âú®Ë®àÁÆóÂô®Â†¥ÊôØÁöÑÊï¥ÂÄãËá®Â∫äÈÅéÁ®ã‰∏≠ÈÄ≤Ë°åÈáèÂåñË©ï‰º∞ÁöÑËÉΩÂäõÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü CalcQA„ÄÇÊ≠§Âü∫Ê∫ñË¶ÅÊ±Ç LLM ‰ΩøÁî®ÈÜ´ÁôÇË®àÁÆóÂô®ÈÄ≤Ë°åË®àÁÆó‰∏¶Ë©ï‰º∞ÊÇ£ËÄÖÁöÑÂÅ•Â∫∑ÁãÄÊ≥Å„ÄÇCalcQA Áî±Â∞àÊ•≠ÈÜ´ÁîüÁ∑®Âà∂ÔºåÂåÖÊã¨ 100 ÂÄãÊ°à‰æãË®àÁÆóÂô®Â∞çÔºå‰∏¶Ëºî‰ª• 281 ÂÄãÈÜ´ÁôÇÂ∑•ÂÖ∑ÁöÑÂ∑•ÂÖ∑ÂåÖ„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊ°ÜÊû∂ÁöÑÈ°ØËëóÊïàËÉΩÊèêÂçá„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁÇ∫Âú®Ë¶ÅÊ±ÇÂö¥Ê†ºÁöÑÈÜ´Â≠∏Â†¥ÊôØ‰∏≠ÊáâÁî® LLM Èã™Âπ≥‰∫ÜÊñ∞ÁöÑÈÅìË∑Ø„ÄÇ

##### **OAH-Net: A Deep Neural Network for Hologram Reconstruction of Off-axis Digital Holographic Microscope**
2410.13592v1 by Wei Liu, Kerem Delikoyun, Qianyu Chen, Alperen Yildiz, Si Ko Myo, Win Sen Kuan, John Tshon Yit Soong, Matthew Edward Cove, Oliver Hayden, Hweekuan Lee

Off-axis digital holographic microscopy is a high-throughput, label-free
imaging technology that provides three-dimensional, high-resolution information
about samples, particularly useful in large-scale cellular imaging. However,
the hologram reconstruction process poses a significant bottleneck for timely
data analysis. To address this challenge, we propose a novel reconstruction
approach that integrates deep learning with the physical principles of off-axis
holography. We initialized part of the network weights based on the physical
principle and then fine-tuned them via weakly supersized learning. Our off-axis
hologram network (OAH-Net) retrieves phase and amplitude images with errors
that fall within the measurement error range attributable to hardware, and its
reconstruction speed significantly surpasses the microscope's acquisition rate.
Crucially, OAH-Net demonstrates remarkable external generalization capabilities
on unseen samples with distinct patterns and can be seamlessly integrated with
other models for downstream tasks to achieve end-to-end real-time hologram
analysis. This capability further expands off-axis holography's applications in
both biological and medical studies.

ÊëòË¶ÅÔºöÈõ¢Ëª∏Êï∏‰ΩçÂÖ®ÂÉèÈ°ØÂæÆÈè°ÊòØ‰∏ÄÁ®ÆÈ´òÈÄöÈáè„ÄÅÁÑ°Ê®ôÁ±§ÁöÑÂΩ±ÂÉèÊäÄË°ìÔºåÂèØÊèê‰æõÁ´ãÈ´î„ÄÅÈ´òËß£ÊûêÂ∫¶ÁöÑÊ®£ÂìÅË≥áË®äÔºåÁâπÂà•ÈÅ©Áî®ÊñºÂ§ßË¶èÊ®°Á¥∞ËÉûÂΩ±ÂÉè„ÄÇÁÑ∂ËÄåÔºåÂÖ®ÂÉèÈáçÂª∫ÈÅéÁ®ãÂ∞çÂèäÊôÇÁöÑË≥áÊñôÂàÜÊûêÊßãÊàêÈáçÂ§ßÁöÑÁì∂È†∏„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÈ†ÖÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÈáçÂª∫ÊñπÊ≥ïÔºåÂ∞áÊ∑±Â∫¶Â≠∏ÁøíËàáÈõ¢Ëª∏ÂÖ®ÂÉèÁöÑÁâ©ÁêÜÂéüÁêÜÊï¥ÂêàÂú®‰∏ÄËµ∑„ÄÇÊàëÂÄëÊ†πÊìöÁâ©ÁêÜÂéüÁêÜÂàùÂßãÂåñÈÉ®ÂàÜÁ∂≤Ë∑ØÊ¨äÈáçÔºåÁÑ∂ÂæåÈÄèÈÅéÂº±Áõ£Áù£Â≠∏ÁøíÂæÆË™øÂÆÉÂÄë„ÄÇÊàëÂÄëÁöÑÈõ¢Ëª∏ÂÖ®ÂÉèÁ∂≤Ë∑Ø (OAH-Net) Êì∑ÂèñÁõ∏‰ΩçÂíåÊåØÂπÖÂΩ±ÂÉèÔºåÂÖ∂Ë™§Â∑ÆËêΩÂú®Ê≠∏Âõ†ÊñºÁ°¨È´îÁöÑÈáèÊ∏¨Ë™§Â∑ÆÁØÑÂúçÂÖßÔºåËÄå‰∏îÂÖ∂ÈáçÂª∫ÈÄüÂ∫¶È°ØËëóË∂ÖË∂äÈ°ØÂæÆÈè°ÁöÑÊì∑ÂèñÁéá„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåOAH-Net Âú®ÂÖ∑Êúâ‰∏çÂêåÊ®°ÂºèÁöÑÊú™Ë¶ãÊ®£Êú¨‰∏äÂ±ïÁèæÂá∫ÂçìË∂äÁöÑÂ§ñÂú®Ê≥õÂåñËÉΩÂäõÔºåËÄå‰∏îÂèØ‰ª•ËàáÂÖ∂‰ªñÊ®°ÂûãÁÑ°Á∏´Êï¥ÂêàÔºå‰ª•Âü∑Ë°å‰∏ãÊ∏∏‰ªªÂãôÔºå‰ª•ÈÅîÊàêÁ´ØÂ∞çÁ´ØÁöÑÂç≥ÊôÇÂÖ®ÂÉèÂàÜÊûê„ÄÇÊ≠§ËÉΩÂäõÈÄ≤‰∏ÄÊ≠•Êì¥Â±ï‰∫ÜÈõ¢Ëª∏ÂÖ®ÂÉèÂú®ÁîüÁâ©ÂíåÈÜ´Â≠∏Á†îÁ©∂‰∏≠ÁöÑÊáâÁî®„ÄÇ

##### **RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical Imaging**
2410.13570v1 by Tobias Czempiel, Alfie Roddan, Maria Leiloglou, Zepeng Hu, Kevin O'Neill, Giulio Anichini, Danail Stoyanov, Daniel Elson

This study investigates the reconstruction of hyperspectral signatures from
RGB data to enhance surgical imaging, utilizing the publicly available
HeiPorSPECTRAL dataset from porcine surgery and an in-house neurosurgery
dataset. Various architectures based on convolutional neural networks (CNNs)
and transformer models are evaluated using comprehensive metrics. Transformer
models exhibit superior performance in terms of RMSE, SAM, PSNR and SSIM by
effectively integrating spatial information to predict accurate spectral
profiles, encompassing both visible and extended spectral ranges. Qualitative
assessments demonstrate the capability to predict spectral profiles critical
for informed surgical decision-making during procedures. Challenges associated
with capturing both the visible and extended hyperspectral ranges are
highlighted using the MAE, emphasizing the complexities involved. The findings
open up the new research direction of hyperspectral reconstruction for surgical
applications and clinical use cases in real-time surgical environments.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂæû RGB Ë≥áÊñôÈáçÂª∫È´òÂÖâË≠úÁâπÂæµÔºå‰ª•Â¢ûÂº∑ÊâãË°ìÂΩ±ÂÉèÔºå‰∏¶Âà©Áî®‰æÜËá™Ë±¨ÈöªÊâãË°ìÁöÑÂÖ¨Èñã HeiPorSPECTRAL Ë≥áÊñôÈõÜÂíåÈô¢ÂÖßÁ•ûÁ∂ìÂ§ñÁßëË≥áÊñôÈõÜ„ÄÇ‰ΩøÁî®Á∂úÂêàË©ïÈáèÊåáÊ®ôË©ï‰º∞‰∫ÜÂü∫ÊñºÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) Âíå Transformer Ê®°ÂûãÁöÑÂêÑÁ®ÆÊû∂Êßã„ÄÇTransformer Ê®°ÂûãÂú® RMSE„ÄÅSAM„ÄÅPSNR Âíå SSIM ÊñπÈù¢Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÂõ†ÁÇ∫ÂÆÉÊúâÊïàÂú∞Êï¥Âêà‰∫ÜÁ©∫ÈñìË≥áË®ä‰ª•È†êÊ∏¨Ê∫ñÁ¢∫ÁöÑÂÖâË≠úËº™ÂªìÔºåÊ∂µËìã‰∫ÜÂèØË¶ãÂÖâÂíåÂª∂‰º∏ÂÖâË≠úÁØÑÂúç„ÄÇÂÆöÊÄßË©ï‰º∞Ë≠âÊòé‰∫ÜÂú®ÊâãË°ìÈÅéÁ®ã‰∏≠È†êÊ∏¨ÂÖâË≠úËº™ÂªìÁöÑËÉΩÂäõÔºåÂ∞çÊñºÊòéÊô∫ÁöÑÊâãË°ìÊ±∫Á≠ñÂà∂ÂÆöËá≥ÈóúÈáçË¶Å„ÄÇ‰ΩøÁî® MAE Âº∑Ë™ø‰∫ÜËàáÊì∑ÂèñÂèØË¶ãÂÖâÂíåÂª∂‰º∏È´òÂÖâË≠úÁØÑÂúçÁõ∏ÈóúÁöÑÊåëÊà∞ÔºåÂº∑Ë™ø‰∫ÜÊâÄÊ∂âÂèäÁöÑË§áÈõúÊÄß„ÄÇÈÄô‰∫õÁôºÁèæÈñãÂïü‰∫ÜÈ´òÂÖâË≠úÈáçÂª∫Âú®ÊâãË°ìÊáâÁî®ÂíåÂØ¶ÈöõÊâãË°ìÁí∞Â¢É‰∏≠Ëá®Â∫ä‰ΩøÁî®Ê°à‰æãÁöÑÊñ∞Á†îÁ©∂ÊñπÂêë„ÄÇ

##### **Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?**
2410.13523v1 by Che Liu, Zhongwei Wan, Haozhe Wang, Yinda Chen, Talha Qaiser, Chen Jin, Fariba Yousefi, Nikolay Burlutskiy, Rossella Arcucci

Medical Vision-Language Pre-training (MedVLP) has made significant progress
in enabling zero-shot tasks for medical image understanding. However, training
MedVLP models typically requires large-scale datasets with paired, high-quality
image-text data, which are scarce in the medical domain. Recent advancements in
Large Language Models (LLMs) and diffusion models have made it possible to
generate large-scale synthetic image-text pairs. This raises the question: *Can
MedVLP succeed using purely synthetic data?* To address this, we use
off-the-shelf generative models to create synthetic radiology reports and
paired Chest X-ray (CXR) images, and propose an automated pipeline to build a
diverse, high-quality synthetic dataset, enabling a rigorous study that
isolates model and training settings, focusing entirely from the data
perspective. Our results show that MedVLP models trained *exclusively on
synthetic data* outperform those trained on real data by **3.8%** in averaged
AUC on zero-shot classification. Moreover, using a combination of synthetic and
real data leads to a further improvement of **9.07%**. Additionally, MedVLP
models trained on synthetic or mixed data consistently outperform those trained
on real data in zero-shot grounding, as well as in fine-tuned classification
and segmentation tasks. Our analysis suggests MedVLP trained on well-designed
synthetic data can outperform models trained on real datasets, which may be
limited by low-quality samples and long-tailed distributions.

ÊëòË¶ÅÔºö<paragraph>ÈÜ´ÁôÇË¶ñË¶∫Ë™ûË®ÄÈ†êË®ìÁ∑¥ (MedVLP) Âú®ÊîØÊè¥ÈÜ´Â≠∏ÂΩ±ÂÉèÁêÜËß£ÁöÑÈõ∂Ê¨°Â≠∏Áøí‰ªªÂãôÊñπÈù¢ÂèñÂæóÈáçÂ§ßÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºåË®ìÁ∑¥ MedVLP Ê®°ÂûãÈÄöÂ∏∏ÈúÄË¶ÅÂÖ∑ÂÇôÈÖçÂ∞ç„ÄÅÈ´òÂìÅË≥™ÂΩ±ÂÉèÊñáÂ≠óË≥áÊñôÁöÑÂ§ßË¶èÊ®°Ë≥áÊñôÈõÜÔºåËÄåÈÄôÂú®ÈÜ´ÁôÇÈ†òÂüü‰∏≠ÂçÅÂàÜÁ®ÄÂ∞ë„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÊì¥Êï£Ê®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ï‰ΩøÂæóÁî¢ÁîüÂ§ßË¶èÊ®°ÁöÑÂêàÊàêÂΩ±ÂÉèÊñáÂ≠óÈÖçÂ∞çÊàêÁÇ∫ÂèØËÉΩ„ÄÇÈÄôÂºïÁôº‰∫Ü‰∏ÄÂÄãÂïèÈ°åÔºö*MedVLP ËÉΩÂÉÖ‰ΩøÁî®ÂêàÊàêË≥áÊñôÊàêÂäüÂóéÔºü*ÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄë‰ΩøÁî®ÁèæÊàêÁöÑÁîüÊàêÊ®°Âûã‰æÜÂª∫Á´ãÂêàÊàêÊîæÂ∞ÑÂ†±ÂëäÂíåÈÖçÂ∞çÁöÑËÉ∏ÈÉ® X ÂÖâ (CXR) ÂΩ±ÂÉèÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãËá™ÂãïÂåñÁöÑÊµÅÁ®ã‰æÜÂª∫Êßã‰∏ÄÂÄãÂ§öÂÖÉ„ÄÅÈ´òÂìÅË≥™ÁöÑÂêàÊàêË≥áÊñôÈõÜÔºåÈÄô‰ΩøÂæó‰∏ÄÈ†ÖÂö¥Ë¨πÁöÑÁ†îÁ©∂Âæó‰ª•Â∞àÊ≥®ÊñºË≥áÊñôËßÄÈªûÔºå‰∏¶ÂÆåÂÖ®ÈöîÈõ¢Ê®°ÂûãÂíåË®ìÁ∑¥Ë®≠ÂÆö„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫Ôºå*ÂÉÖ‰ΩøÁî®ÂêàÊàêË≥áÊñôË®ìÁ∑¥ÁöÑ* MedVLP Ê®°ÂûãÂú®Èõ∂Ê¨°ÂàÜÈ°ûÁöÑÂπ≥Âùá AUC ‰∏äÔºåÊØîÂú®ÁúüÂØ¶Ë≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÈ´òÂá∫ **3.8%**„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî®ÂêàÊàêË≥áÊñôÂíåÁúüÂØ¶Ë≥áÊñôÁöÑÁµÑÂêàÔºåÂèØÈÄ≤‰∏ÄÊ≠•ÊèêÂçá **9.07%**„ÄÇÊ≠§Â§ñÔºåÂú®ÂêàÊàêÊàñÊ∑∑ÂêàË≥áÊñô‰∏äË®ìÁ∑¥ÁöÑ MedVLP Ê®°ÂûãÔºåÂú®Èõ∂Ê¨°ÂÆö‰Ωç„ÄÅÂæÆË™øÂàÜÈ°ûÂíåÂàÜÂâ≤‰ªªÂãô‰∏≠ÔºåÂßãÁµÇÂÑ™ÊñºÂú®ÁúüÂØ¶Ë≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂú®Ë®≠Ë®àËâØÂ•ΩÁöÑÂêàÊàêË≥áÊñô‰∏äË®ìÁ∑¥ÁöÑ MedVLP ÂèØ‰ª•ÂÑ™ÊñºÂú®ÁúüÂØ¶Ë≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºåËÄåÁúüÂØ¶Ë≥áÊñôÈõÜÂèØËÉΩÂèóÂà∞‰ΩéÂìÅË≥™Ê®£Êú¨ÂíåÈï∑Â∞æÂàÜ‰ΩàÁöÑÈôêÂà∂„ÄÇ</paragraph>

##### **Representation Learning of Structured Data for Medical Foundation Models**
2410.13351v1 by Vijay Prakash Dwivedi, Viktor Schlegel, Andy T. Liu, Thanh-Tung Nguyen, Abhinav Ramesh Kashyap, Jeng Wei, Wei-Hsian Yin, Stefan Winkler, Robby T. Tan

Large Language Models (LLMs) have demonstrated remarkable performance across
various domains, including healthcare. However, their ability to effectively
represent structured non-textual data, such as the alphanumeric medical codes
used in records like ICD-10 or SNOMED-CT, is limited and has been particularly
exposed in recent research. This paper examines the challenges LLMs face in
processing medical codes due to the shortcomings of current tokenization
methods. As a result, we introduce the UniStruct architecture to design a
multimodal medical foundation model of unstructured text and structured data,
which addresses these challenges by adapting subword tokenization techniques
specifically for the structured medical codes. Our approach is validated
through model pre-training on both an extensive internal medical database and a
public repository of structured medical records. Trained on over 1 billion
tokens on the internal medical database, the proposed model achieves up to a
23% improvement in evaluation metrics, with around 2% gain attributed to our
proposed tokenization. Additionally, when evaluated on the EHRSHOT public
benchmark with a 1/1000 fraction of the pre-training data, the UniStruct model
improves performance on over 42% of the downstream tasks. Our approach not only
enhances the representation and generalization capabilities of patient-centric
models but also bridges a critical gap in representation learning models'
ability to handle complex structured medical data, alongside unstructured text.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®ÆÈ†òÂüüÂ±ïÁèæÂá∫ÂçìË∂äÁöÑÊïàËÉΩÔºåÂåÖÊã¨ÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÊúâÊïàË°®Á§∫ÁµêÊßãÂåñÈùûÊñáÂ≠óË≥áÊñôÁöÑËÉΩÂäõÔºå‰æãÂ¶ÇÁóÖÊ≠∑‰∏≠‰ΩøÁî®ÁöÑÂ≠óÊØçÊï∏Â≠óÈÜ´ÁôÇÁ¢ºÔºå‰æãÂ¶Ç ICD-10 Êàñ SNOMED-CTÔºåÂèóÂà∞ÈôêÂà∂Ôºå‰∏¶‰∏îÂú®ÊúÄËøëÁöÑÁ†îÁ©∂‰∏≠ÁâπÂà•ÊòéÈ°Ø„ÄÇÊú¨ÊñáÊé¢Ë®éÁî±ÊñºÁï∂ÂâçÊ®ôË®òÂåñÊñπÊ≥ïÁöÑÁº∫ÈªûÔºåLLM Âú®ËôïÁêÜÈÜ´ÁôÇÁ¢ºÊôÇÈù¢Ëá®ÁöÑÊåëÊà∞„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü UniStruct Êû∂Êßã‰æÜË®≠Ë®àÈùûÁµêÊßãÂåñÊñáÂ≠óÂíåÁµêÊßãÂåñË≥áÊñôÁöÑÂ§öÊ®°ÊÖãÈÜ´ÁôÇÂü∫Á§éÊ®°ÂûãÔºåÂÆÉÈÄèÈÅéÁâπÂà•ÈáùÂ∞çÁµêÊßãÂåñÈÜ´ÁôÇÁ¢ºË™øÊï¥Ê¨°Â≠óÊ®ôË®òÂåñÊäÄË°ì‰æÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÄèÈÅéÂú®Âª£Ê≥õÁöÑÂÖßÈÉ®ÈÜ´ÁôÇË≥áÊñôÂ∫´ÂíåÁµêÊßãÂåñÈÜ´ÁôÇË®òÈåÑÁöÑÂÖ¨ÈñãÂÑ≤Â≠òÂ∫´‰∏äÈÄ≤Ë°åÊ®°ÂûãÈ†êË®ìÁ∑¥‰æÜÈ©óË≠â„ÄÇÂú®ÂÖßÈÉ®ÈÜ´ÁôÇË≥áÊñôÂ∫´‰∏äË®ìÁ∑¥Ë∂ÖÈÅé 10 ÂÑÑÂÄãÊ®ôË®òÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®Ë©ï‰º∞ÊåáÊ®ô‰∏≠Áç≤ÂæóÈ´òÈÅî 23% ÁöÑÊîπÈÄ≤ÔºåÂÖ∂‰∏≠Á¥Ñ 2% ÁöÑÊî∂ÁõäÊ≠∏ÂäüÊñºÊàëÂÄëÊèêÂá∫ÁöÑÊ®ôË®òÂåñ„ÄÇÊ≠§Â§ñÔºåÂú®‰ΩøÁî® 1/1000 ÁöÑÈ†êË®ìÁ∑¥Ë≥áÊñôÂ∞ç EHRSHOT ÂÖ¨ÈñãÂü∫Ê∫ñÈÄ≤Ë°åË©ï‰º∞ÊôÇÔºåUniStruct Ê®°ÂûãÂú®Ë∂ÖÈÅé 42% ÁöÑ‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÊèêÂçá‰∫ÜÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÂÉÖÂ¢ûÂº∑‰∫Ü‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÊ®°ÂûãÁöÑË°®Á§∫ÂíåÊ¶ÇÂåñËÉΩÂäõÔºåÈÇÑÂΩåË£ú‰∫ÜË°®Á§∫Â≠∏ÁøíÊ®°ÂûãËôïÁêÜË§áÈõúÁµêÊßãÂåñÈÜ´ÁôÇË≥áÊñôÁöÑËÉΩÂäõËàáÈùûÁµêÊßãÂåñÊñáÂ≠ó‰πãÈñìÁöÑÈóúÈçµÂ∑ÆË∑ù„ÄÇ

##### **Active inference and deep generative modeling for cognitive ultrasound**
2410.13310v1 by Ruud JG van Sloun

Ultrasound (US) has the unique potential to offer access to medical imaging
to anyone, everywhere. Devices have become ultra-portable and cost-effective,
akin to the stethoscope. Nevertheless US image quality and diagnostic efficacy
are still highly operator- and patient-dependent. In difficult-to-image
patients, image quality is often insufficient for reliable diagnosis. In this
paper, we put forth that US imaging systems can be recast as
information-seeking agents that engage in reciprocal interactions with their
anatomical environment. Such agents autonomously adapt their transmit-receive
sequences to fully personalize imaging and actively maximize information gain
in-situ. To that end, we will show that the sequence of pulse-echo experiments
that a US system performs can be interpreted as a perception-action loop: the
action is the data acquisition, probing tissue with acoustic waves and
recording reflections at the detection array, and perception is the inference
of the anatomical and or functional state, potentially including associated
diagnostic quantities. We then equip systems with a mechanism to actively
reduce uncertainty and maximize diagnostic value across a sequence of
experiments, treating action and perception jointly using Bayesian inference
given generative models of the environment and action-conditional pulse-echo
observations. Since the representation capacity of the generative models
dictates both the quality of inferred anatomical states and the effectiveness
of inferred sequences of future imaging actions, we will be greatly leveraging
the enormous advances in deep generative modelling that are currently
disrupting many fields and society at large. Finally, we show some examples of
cognitive, closed-loop, US systems that perform active beamsteering and
adaptive scanline selection, based on deep generative models that track
anatomical belief states.

ÊëòË¶ÅÔºöË∂ÖÈü≥Ê≥¢ (US) ÂÖ∑ÊúâÊèê‰æõÈÜ´ÁôÇÂΩ±ÂÉèÁöÑÁç®ÁâπÊΩõÂäõÔºåÂèØ‰æõ‰ªª‰Ωï‰∫∫Âú®‰ªª‰ΩïÂú∞Êñπ‰ΩøÁî®„ÄÇË£ùÁΩÆÂ∑≤ËÆäÂæóÊ•µÁÇ∫‰æøÊîú‰∏îÁ∂ìÊøüÂØ¶ÊÉ†ÔºåÈ°û‰ººÊñºËÅΩË®∫Âô®„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂìÅË≥™ÂíåË®∫Êñ∑ÊïàËÉΩ‰ªçÁÑ∂È´òÂ∫¶‰æùË≥¥Êìç‰ΩúËÄÖÂíåÊÇ£ËÄÖ„ÄÇÂú®Èõ£‰ª•ÊàêÂÉèÁöÑÊÇ£ËÄÖ‰∏≠ÔºåÂΩ±ÂÉèÂìÅË≥™ÈÄöÂ∏∏‰∏çË∂≥‰ª•ÈÄ≤Ë°åÂèØÈù†ÁöÑË®∫Êñ∑„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁ≥ªÁµ±ÂèØ‰ª•ÈáçÊñ∞ÂÆöÁæ©ÁÇ∫Ë≥áË®äÂ∞ãÊ±Ç‰ª£ÁêÜÔºåËàáÂÖ∂Ëß£ÂâñÁí∞Â¢ÉÈÄ≤Ë°å‰∫§‰∫í‰ΩúÁî®„ÄÇÊ≠§È°û‰ª£ÁêÜÊúÉËá™‰∏ªË™øÊï¥ÂÖ∂ÂÇ≥Ëº∏Êé•Êî∂Â∫èÂàóÔºå‰ª•ÂÆåÂÖ®ÂÄã‰∫∫ÂåñÂΩ±ÂÉè‰∏¶Á©çÊ•µÊúÄÂ§ßÂåñÁèæÂ†¥Ë≥áË®äÁç≤Âèñ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂ∞áÂ±ïÁ§∫Ë∂ÖÈü≥Ê≥¢Á≥ªÁµ±Âü∑Ë°åÁöÑËÑàË°ùÂõûÊ≥¢ÂØ¶È©óÂ∫èÂàóÂèØ‰ª•Ëß£ÈáãÁÇ∫ÊÑüÁü•Âãï‰ΩúËø¥ÂúàÔºöÂãï‰ΩúÊòØË≥áÊñôÊì∑ÂèñÔºå‰ΩøÁî®ËÅ≤Ê≥¢Êé¢Ê∏¨ÁµÑÁπî‰∏¶Ë®òÈåÑÂÅµÊ∏¨Èô£ÂàóÁöÑÂèçÂ∞ÑÔºåËÄåÊÑüÁü•ÊòØËß£ÂâñÂíåÂäüËÉΩÁãÄÊÖãÁöÑÊé®Ë´ñÔºåÂèØËÉΩÂåÖÊã¨Áõ∏ÈóúÁöÑË®∫Êñ∑Èáè„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÁÇ∫Á≥ªÁµ±ÈÖçÂÇô‰∏ÄÁ®ÆÊ©üÂà∂Ôºå‰ª•Á©çÊ•µÊ∏õÂ∞ë‰∏çÁ¢∫ÂÆöÊÄß‰∏¶Âú®ÂØ¶È©óÂ∫èÂàó‰∏≠ÊúÄÂ§ßÂåñË®∫Êñ∑ÂÉπÂÄºÔºå‰ΩøÁî®Ë≤ùÊ∞èÊé®Ë´ñÂÖ±ÂêåËôïÁêÜÂãï‰ΩúÂíåÊÑüÁü•Ôºå‰∏¶Êèê‰æõÁí∞Â¢ÉÁöÑÁîüÊàêÊ®°ÂûãÂíåÂãï‰ΩúÊ¢ù‰ª∂ËÑàË°ùÂõûÊ≥¢ËßÄÊ∏¨„ÄÇÁî±ÊñºÁîüÊàêÊ®°ÂûãÁöÑË°®Á§∫ËÉΩÂäõÊ±∫ÂÆö‰∫ÜÊé®Ë´ñËß£ÂâñÁãÄÊÖãÁöÑÂìÅË≥™ÂíåÊé®Ë´ñÊú™‰æÜÂΩ±ÂÉèÂãï‰ΩúÂ∫èÂàóÁöÑÊúâÊïàÊÄßÔºåÊàëÂÄëÂ∞áÂ§ßÂäõÂà©Áî®Ê∑±Â∫¶ÁîüÊàêÊ®°ÂûãÁöÑÂ∑®Â§ßÈÄ≤Â±ïÔºåÈÄô‰∫õÈÄ≤Â±ïÁõÆÂâçÊ≠£Âú®È°õË¶ÜË®±Â§öÈ†òÂüüÂíåÊï¥ÂÄãÁ§æÊúÉ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏Ä‰∫õË™çÁü•„ÄÅÈñâËø¥Ë∑ØË∂ÖÈü≥Ê≥¢Á≥ªÁµ±ÁöÑÁØÑ‰æãÔºåÈÄô‰∫õÁ≥ªÁµ±Âü∑Ë°å‰∏ªÂãïÊ≥¢ÊùüÂ∞éÂºïÂíåËá™ÈÅ©ÊáâÊéÉÊèèÁ∑öÈÅ∏ÂèñÔºåÂü∫ÊñºËøΩËπ§Ëß£Ââñ‰ø°ÂøµÁãÄÊÖãÁöÑÊ∑±Â∫¶ÁîüÊàêÊ®°Âûã„ÄÇ

##### **Hiformer: Hybrid Frequency Feature Enhancement Inverted Transformer for Long-Term Wind Power Prediction**
2410.13303v1 by Chongyang Wan, Shunbo Lei, Yuan Luo

The increasing severity of climate change necessitates an urgent transition
to renewable energy sources, making the large-scale adoption of wind energy
crucial for mitigating environmental impact. However, the inherent uncertainty
of wind power poses challenges for grid stability, underscoring the need for
accurate wind energy prediction models to enable effective power system
planning and operation. While many existing studies on wind power prediction
focus on short-term forecasting, they often overlook the importance of
long-term predictions. Long-term wind power forecasting is essential for
effective power grid dispatch and market transactions, as it requires careful
consideration of weather features such as wind speed and direction, which
directly influence power output. Consequently, methods designed for short-term
predictions may lead to inaccurate results and high computational costs in
long-term settings. To adress these limitations, we propose a novel approach
called Hybrid Frequency Feature Enhancement Inverted Transformer (Hiformer).
Hiformer introduces a unique structure that integrates signal decomposition
technology with weather feature extraction technique to enhance the modeling of
correlations between meteorological conditions and wind power generation.
Additionally, Hiformer employs an encoder-only architecture, which reduces the
computational complexity associated with long-term wind power forecasting.
Compared to the state-of-the-art methods, Hiformer: (i) can improve the
prediction accuracy by up to 52.5\%; and (ii) can reduce computational time by
up to 68.5\%.

ÊëòË¶ÅÔºöÊ∞£ÂÄôËÆäÈÅ∑Êó•ÁõäÂö¥ÈáçÔºåËø´ÂàáÈúÄË¶ÅËΩâÂêëÂÜçÁîüËÉΩÊ∫êÔºåÂõ†Ê≠§Â§ßË¶èÊ®°Êé°Áî®È¢®ËÉΩÂ∞çÊñºÊ∏õÁ∑©Áí∞Â¢ÉÂΩ±ÈüøËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÈ¢®ËÉΩÁöÑÂÖßÂú®‰∏çÁ¢∫ÂÆöÊÄßÂ∞çÈõªÁ∂≤Á©©ÂÆöÊÄßÊßãÊàêÊåëÊà∞ÔºåÈÄôÁ™ÅÈ°Ø‰∫ÜÂ∞çÊ∫ñÁ¢∫È¢®ËÉΩÈ†êÊ∏¨Ê®°ÂûãÁöÑÈúÄÊ±ÇÔºå‰ª•ÂØ¶ÁèæÊúâÊïàÁöÑÈõªÂäõÁ≥ªÁµ±Ë¶èÂäÉÂíåÈÅã‰Ωú„ÄÇÈõñÁÑ∂Ë®±Â§öÁèæÊúâÁöÑÈ¢®ËÉΩÈ†êÊ∏¨Á†îÁ©∂ÈÉΩÂ∞àÊ≥®ÊñºÁü≠ÊúüÈ†êÊ∏¨Ôºå‰ΩÜÂÆÉÂÄëÂ∏∏Â∏∏ÂøΩÁï•Èï∑ÊúüÈ†êÊ∏¨ÁöÑÈáçË¶ÅÊÄß„ÄÇÈï∑ÊúüÈ¢®ËÉΩÈ†êÊ∏¨Â∞çÊñºÊúâÊïàÁöÑÈõªÁ∂≤Ë™øÂ∫¶ÂíåÂ∏ÇÂ†¥‰∫§ÊòìËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÈúÄË¶Å‰ªîÁ¥∞ËÄÉÊÖÆÂ§©Ê∞£ÁâπÂæµÔºå‰æãÂ¶ÇÈ¢®ÈÄüÂíåÈ¢®ÂêëÔºåÈÄô‰∫õÁâπÂæµÊúÉÁõ¥Êé•ÂΩ±ÈüøÈõªÂäõËº∏Âá∫„ÄÇÂõ†Ê≠§ÔºåÂ∞àÁÇ∫Áü≠ÊúüÈ†êÊ∏¨ËÄåË®≠Ë®àÁöÑÊñπÊ≥ïÂú®Èï∑ÊúüË®≠ÁΩÆ‰∏≠ÂèØËÉΩÊúÉÂ∞éËá¥‰∏çÊ∫ñÁ¢∫ÁöÑÁµêÊûúÂíåÈ´òË®àÁÆóÊàêÊú¨„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫Ê∑∑ÂêàÈ†ªÁéáÁâπÂæµÂ¢ûÂº∑ÂèçËΩâTransformer (Hiformer) ÁöÑÊñ∞ÊñπÊ≥ï„ÄÇHiformer ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁç®ÁâπÁöÑÁµêÊßãÔºåÂ∞á‰ø°ËôüÂàÜËß£ÊäÄË°ìËàáÂ§©Ê∞£ÁâπÂæµÊèêÂèñÊäÄË°ìÁõ∏ÁµêÂêàÔºå‰ª•Â¢ûÂº∑Ê∞£Ë±°Ê¢ù‰ª∂ËàáÈ¢®ÂäõÁôºÈõª‰πãÈñìÁõ∏ÈóúÊÄßÁöÑÂª∫Ê®°„ÄÇÊ≠§Â§ñÔºåHiformer Êé°Áî®ÂÉÖÁ∑®Á¢ºÂô®Êû∂ÊßãÔºåÈÄôÈôç‰Ωé‰∫ÜËàáÈï∑ÊúüÈ¢®ËÉΩÈ†êÊ∏¨Áõ∏ÈóúÁöÑË®àÁÆóË§áÈõúÂ∫¶„ÄÇËàáÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåHiformerÔºö(i) ÂèØ‰ª•Â∞áÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÊèêÈ´òÂ§öÈÅî 52.5%Ôºõ(ii) ÂèØ‰ª•Â∞áË®àÁÆóÊôÇÈñìÊ∏õÂ∞ëÂ§öÈÅî 68.5%„ÄÇ

##### **CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy**
2410.13218v1 by Mian Zhang, Xianjun Yang, Xinlu Zhang, Travis Labrum, Jamie C. Chiu, Shaun M. Eack, Fei Fang, William Yang Wang, Zhiyu Zoey Chen

There is a significant gap between patient needs and available mental health
support today. In this paper, we aim to thoroughly examine the potential of
using Large Language Models (LLMs) to assist professional psychotherapy. To
this end, we propose a new benchmark, CBT-BENCH, for the systematic evaluation
of cognitive behavioral therapy (CBT) assistance. We include three levels of
tasks in CBT-BENCH: I: Basic CBT knowledge acquisition, with the task of
multiple-choice questions; II: Cognitive model understanding, with the tasks of
cognitive distortion classification, primary core belief classification, and
fine-grained core belief classification; III: Therapeutic response generation,
with the task of generating responses to patient speech in CBT therapy
sessions. These tasks encompass key aspects of CBT that could potentially be
enhanced through AI assistance, while also outlining a hierarchy of capability
requirements, ranging from basic knowledge recitation to engaging in real
therapeutic conversations. We evaluated representative LLMs on our benchmark.
Experimental results indicate that while LLMs perform well in reciting CBT
knowledge, they fall short in complex real-world scenarios requiring deep
analysis of patients' cognitive structures and generating effective responses,
suggesting potential future work.

ÊëòË¶ÅÔºöÁèæ‰ªäÁóÖÊÇ£ÈúÄÊ±ÇËàáÂèØÂèñÂæóÁöÑÂøÉÁêÜÂÅ•Â∫∑ÊîØÊè¥‰πãÈñìÂ≠òÂú®ËëóÈ°ØËëóÁöÑÂ∑ÆË∑ù„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊó®Âú®ÂæπÂ∫ïÊé¢Ë®é‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÂçîÂä©Â∞àÊ•≠ÂøÉÁêÜÊ≤ªÁôÇÁöÑÂèØËÉΩÊÄß„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü CBT-BENCHÔºå‰∏ÄÂÄãÁî®ÊñºÁ≥ªÁµ±ÊÄßË©ï‰º∞Ë™çÁü•Ë°åÁÇ∫ÁôÇÊ≥ï (CBT) ÂçîÂä©ÁöÑÊñ∞Âü∫Ê∫ñ„ÄÇÊàëÂÄëÂú® CBT-BENCH ‰∏≠ÂåÖÂê´‰∏âÁ¥ö‰ªªÂãôÔºöIÔºöÂü∫Êú¨ CBT Áü•Ë≠òÁøíÂæóÔºå‰ªªÂãôÁÇ∫Â§öÈÅ∏È°åÔºõIIÔºöË™çÁü•Ê®°ÂûãÁêÜËß£Ôºå‰ªªÂãôÁÇ∫Ë™çÁü•Êâ≠Êõ≤ÂàÜÈ°û„ÄÅ‰∏ªË¶ÅÊ†∏ÂøÉ‰ø°ÂøµÂàÜÈ°ûÂíåÁ¥∞Á≤íÂ∫¶Ê†∏ÂøÉ‰ø°ÂøµÂàÜÈ°ûÔºõIIIÔºöÊ≤ªÁôÇÂèçÊáâÁîüÊàêÔºå‰ªªÂãôÁÇ∫Âú® CBT Ê≤ªÁôÇÊúÉË´á‰∏≠Â∞çÁóÖÊÇ£ÁöÑË®ÄË™ûÁî¢ÁîüÂèçÊáâ„ÄÇÈÄô‰∫õ‰ªªÂãôÊ∂µËìã‰∫Ü CBT ÁöÑÈóúÈçµÈù¢ÂêëÔºåÈÄô‰∫õÈù¢ÂêëÊúâÂèØËÉΩÈÄèÈÅé AI ÂçîÂä©ËÄåÂæóÂà∞Âº∑ÂåñÔºåÂêåÊôÇ‰πüÊ¶ÇËø∞‰∫ÜËÉΩÂäõÈúÄÊ±ÇÁöÑÂ±§Á¥öÔºåÂæûÂü∫Êú¨ÁöÑÁü•Ë≠òËÉåË™¶Âà∞ÂèÉËàáÁúüÊ≠£ÁöÑÊ≤ªÁôÇÂ∞çË©±„ÄÇÊàëÂÄëÂú®Âü∫Ê∫ñ‰∏äË©ï‰º∞‰∫ÜÂÖ∑‰ª£Ë°®ÊÄßÁöÑ LLM„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÂÑòÁÆ° LLM Âú®ËÉåË™¶ CBT Áü•Ë≠òÊñπÈù¢Ë°®ÁèæËâØÂ•ΩÔºå‰ΩÜÂú®ÈúÄË¶ÅÊ∑±ÂÖ•ÂàÜÊûêÁóÖÊÇ£Ë™çÁü•ÁµêÊßãÂíåÁî¢ÁîüÊúâÊïàÂèçÊáâÁöÑË§áÈõúÁèæÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠Ë°®Áèæ‰∏ç‰Ω≥ÔºåÈÄôË°®Á§∫Êú™‰æÜÊúâÊΩõÂú®ÁöÑÂ∑•‰ΩúÊ©üÊúÉ„ÄÇ

##### **MixEHR-Nest: Identifying Subphenotypes within Electronic Health Records through Hierarchical Guided-Topic Modeling**
2410.13217v1 by Ruohan Wang, Zilong Wang, Ziyang Song, David Buckeridge, Yue Li

Automatic subphenotyping from electronic health records (EHRs)provides
numerous opportunities to understand diseases with unique subgroups and enhance
personalized medicine for patients. However, existing machine learning
algorithms either focus on specific diseases for better interpretability or
produce coarse-grained phenotype topics without considering nuanced disease
patterns. In this study, we propose a guided topic model, MixEHR-Nest, to infer
sub-phenotype topics from thousands of disease using multi-modal EHR data.
Specifically, MixEHR-Nest detects multiple subtopics from each phenotype topic,
whose prior is guided by the expert-curated phenotype concepts such as
Phenotype Codes (PheCodes) or Clinical Classification Software (CCS) codes. We
evaluated MixEHR-Nest on two EHR datasets: (1) the MIMIC-III dataset consisting
of over 38 thousand patients from intensive care unit (ICU) from Beth Israel
Deaconess Medical Center (BIDMC) in Boston, USA; (2) the healthcare
administrative database PopHR, comprising 1.3 million patients from Montreal,
Canada. Experimental results demonstrate that MixEHR-Nest can identify
subphenotypes with distinct patterns within each phenotype, which are
predictive for disease progression and severity. Consequently, MixEHR-Nest
distinguishes between type 1 and type 2 diabetes by inferring subphenotypes
using CCS codes, which do not differentiate these two subtype concepts.
Additionally, MixEHR-Nest not only improved the prediction accuracy of
short-term mortality of ICU patients and initial insulin treatment in diabetic
patients but also revealed the contributions of subphenotypes. For longitudinal
analysis, MixEHR-Nest identified subphenotypes of distinct age prevalence under
the same phenotypes, such as asthma, leukemia, epilepsy, and depression. The
MixEHR-Nest software is available at GitHub:
https://github.com/li-lab-mcgill/MixEHR-Nest.

ÊëòË¶ÅÔºö<paragraph>ÂæûÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) Ëá™ÂãïÈÄ≤Ë°å‰∫ûÂàÜÂûãÔºåÊèê‰æõ‰∫ÜË®±Â§ö‰∫ÜËß£ÂÖ∑ÊúâÁç®Áâπ‰∫ûÁæ§ÁöÑÁñæÁóÖ‰∏¶Â¢ûÂº∑ÊÇ£ËÄÖÂÄã‰∫∫ÂåñÈÜ´ÁôÇÁöÑÊ©üÊúÉ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ï‰∏çÊòØÂ∞àÊ≥®ÊñºÁâπÂÆöÁñæÁóÖ‰ª•Áç≤ÂæóÊõ¥Â•ΩÁöÑÂèØËß£ÈáãÊÄßÔºåÂ∞±ÊòØÁî¢ÁîüÁ≤óÁï•ÁöÑÂàÜÂûã‰∏ªÈ°åÔºåËÄå‰∏çËÄÉÊÖÆÁ¥∞ÂæÆÁöÑÁñæÁóÖÊ®°Âºè„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂºïÂ∞éÂºè‰∏ªÈ°åÊ®°Âûã MixEHR-NestÔºå‰ª•‰ΩøÁî®Â§öÊ®°Âºè EHR Ë≥áÊñôÂæûÊï∏ÂçÉÁ®ÆÁñæÁóÖ‰∏≠Êé®Ë´ñÂá∫‰∫ûÂàÜÂûã‰∏ªÈ°å„ÄÇÂÖ∑È´î‰æÜË™™ÔºåMixEHR-Nest ÂæûÊØèÂÄãÂàÜÂûã‰∏ªÈ°å‰∏≠ÂÅµÊ∏¨Âá∫Â§öÂÄãÂ≠ê‰∏ªÈ°åÔºåÂÖ∂‰∫ãÂâçÊ©üÁéáÁî±Â∞àÂÆ∂Á≠ñÂäÉÁöÑÂàÜÂûãÊ¶ÇÂøµÔºà‰æãÂ¶ÇÂàÜÂûã‰ª£Á¢º (PheCodes) ÊàñËá®Â∫äÂàÜÈ°ûËªüÈ´î (CCS) ‰ª£Á¢ºÔºâÂºïÂ∞é„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄã EHR Ë≥áÊñôÈõÜ‰∏äË©ï‰º∞‰∫Ü MixEHR-NestÔºö(1) MIMIC-III Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™ÁæéÂúãÊ≥¢Â£´È†ìË≤ùÊñØ‰ª•Ëâ≤ÂàóÂ•≥Âü∑‰∫ãÈÜ´ÁôÇ‰∏≠ÂøÉ (BIDMC) ÈáçÁóáÁõ£Ë≠∑ÁóÖÊàø (ICU) ÁöÑ 38,000 Â§öÂêçÊÇ£ËÄÖÔºõ(2) ÈÜ´ÁôÇË°åÊîøË≥áÊñôÂ∫´ PopHRÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™Âä†ÊãøÂ§ßËíôÁâπÂ©ÅÁöÑ 130 Ëê¨ÂêçÊÇ£ËÄÖ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåMixEHR-Nest ÂèØ‰ª•Ë≠òÂà•ÊØèÂÄãÂàÜÂûã‰∏≠ÂÖ∑Êúâ‰∏çÂêåÊ®°ÂºèÁöÑ‰∫ûÂàÜÂûãÔºåÈÄô‰∫õÊ®°ÂºèÂ∞çÊñºÁñæÁóÖÈÄ≤Â±ïÂíåÂö¥ÈáçÁ®ãÂ∫¶ÂÖ∑ÊúâÈ†êÊ∏¨ÊÄß„ÄÇÂõ†Ê≠§ÔºåMixEHR-Nest ÈÄöÈÅé‰ΩøÁî® CCS ‰ª£Á¢ºÊé®Ë´ñ‰∫ûÂàÜÂûã‰æÜÂçÄÂàÜ 1 ÂûãÂíå 2 ÂûãÁ≥ñÂ∞øÁóÖÔºåËÄå CCS ‰ª£Á¢º‰∏¶Êú™ÂçÄÂàÜÈÄôÂÖ©ÂÄã‰∫ûÂûãÊ¶ÇÂøµ„ÄÇÊ≠§Â§ñÔºåMixEHR-Nest ‰∏çÂÉÖÊèêÈ´ò‰∫Ü ICU ÊÇ£ËÄÖÁü≠ÊúüÊ≠ª‰∫°ÁéáÂíåÁ≥ñÂ∞øÁóÖÊÇ£ËÄÖÂàùÂßãËÉ∞Â≥∂Á¥†Ê≤ªÁôÇÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÔºåÈÇÑÊè≠Á§∫‰∫Ü‰∫ûÂàÜÂûãÁöÑË≤¢Áçª„ÄÇÂ∞çÊñºÁ∏±ÂêëÂàÜÊûêÔºåMixEHR-Nest Ë≠òÂà•Âá∫Âú®Áõ∏ÂêåÂàÜÂûã‰∏ãÁöÑ‰∏çÂêåÂπ¥ÈΩ°ÊÇ£ÁóÖÁéáÁöÑ‰∫ûÂàÜÂûãÔºå‰æãÂ¶ÇÂìÆÂñò„ÄÅÁôΩË°ÄÁóÖ„ÄÅÁô≤ÁôáÂíåÊÜÇÈ¨±Áóá„ÄÇMixEHR-Nest ËªüÈ´îÂèØÂú® GitHub ‰∏äÂèñÂæóÔºöhttps://github.com/li-lab-mcgill/MixEHR-Nest„ÄÇ</paragraph>

##### **LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch**
2410.13213v1 by Caigao Jiang, Xiang Shu, Hong Qian, Xingyu Lu, Jun Zhou, Aimin Zhou, Yang Yu

Optimization problems are prevalent across various scenarios. Formulating and
then solving optimization problems described by natural language often requires
highly specialized human expertise, which could block the widespread
application of optimization-based decision making. To make problem formulating
and solving automated, leveraging large language models (LLMs) has emerged as a
potential way. However, this kind of way suffers from the issue of optimization
generalization. Namely, the accuracy of most current LLM-based methods and the
generality of optimization problem types that they can model are still limited.
In this paper, we propose a unified learning-based framework called LLMOPT to
boost optimization generalization. Starting from the natural language
descriptions of optimization problems and a pre-trained LLM, LLMOPT constructs
the introduced five-element formulation as a universal model for learning to
define diverse optimization problem types. Then, LLMOPT employs the
multi-instruction tuning to enhance both problem formalization and solver code
generation accuracy and generality. After that, to prevent hallucinations in
LLMs, such as sacrificing solving accuracy to avoid execution errors, model
alignment and self-correction mechanism are adopted in LLMOPT. We evaluate the
optimization generalization ability of LLMOPT and compared methods across six
real-world datasets covering roughly 20 fields such as health, environment,
energy and manufacturing, etc. Extensive experiment results show that LLMOPT is
able to model various optimization problem types such as linear/nonlinear
programming, mixed integer programming and combinatorial optimization, and
achieves a notable 11.08% average solving accuracy improvement compared with
the state-of-the-art methods. The code is available at
https://github.com/caigaojiang/LLMOPT.

ÊëòË¶ÅÔºö<paragraph>ÂÑ™ÂåñÂïèÈ°åÊôÆÈÅçÂ≠òÂú®ÊñºÂêÑÁ®ÆÂ†¥ÊôØ‰∏≠„ÄÇÂà∂ÂÆö‰∏¶Ëß£Ê±∫Ëá™ÁÑ∂Ë™ûË®ÄÊèèËø∞ÁöÑÂÑ™ÂåñÂïèÈ°åÈÄöÂ∏∏ÈúÄË¶ÅÈ´òÂ∫¶Â∞àÊ•≠ÁöÑ‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠òÔºåÈÄôÂèØËÉΩÊúÉÈòªÁ§ôÂü∫ÊñºÂÑ™ÂåñÁöÑÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂª£Ê≥õÊáâÁî®„ÄÇÁÇ∫‰∫Ü‰ΩøÂïèÈ°åÂà∂ÂÆöÂíåÊ±ÇËß£Ëá™ÂãïÂåñÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÊΩõÂú®ÁöÑÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÊñπÂºèÂ≠òÂú®ÂÑ™ÂåñÊ≥õÂåñÂïèÈ°å„ÄÇ‰πüÂ∞±ÊòØË™™ÔºåÁï∂ÂâçÂ§ßÂ§öÊï∏Âü∫Êñº LLM ÁöÑÊñπÊ≥ïÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂÆÉÂÄëÂèØ‰ª•Âª∫Ê®°ÁöÑÂÑ™ÂåñÂïèÈ°åÈ°ûÂûãÁöÑÊôÆÈÅçÊÄß‰ªçÁÑ∂ÊúâÈôê„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ LLMOPT ÁöÑÁµ±‰∏ÄÂü∫ÊñºÂ≠∏ÁøíÁöÑÊ°ÜÊû∂Ôºå‰ª•ÊèêÈ´òÂÑ™ÂåñÊ≥õÂåñËÉΩÂäõ„ÄÇÂæûÂÑ™ÂåñÂïèÈ°åÁöÑËá™ÁÑ∂Ë™ûË®ÄÊèèËø∞ÂíåÈ†êË®ìÁ∑¥ÁöÑ LLM ÈñãÂßãÔºåLLMOPT Â∞áÂºïÂÖ•ÁöÑ‰∫îË¶ÅÁ¥†Ë°®Ëø∞ÊßãÂª∫ÁÇ∫Â≠∏ÁøíÂÆöÁæ©ÂêÑÁ®ÆÂÑ™ÂåñÂïèÈ°åÈ°ûÂûãÁöÑÈÄöÁî®Ê®°Âûã„ÄÇÁÑ∂ÂæåÔºåLLMOPT Êé°Áî®Â§öÊåá‰ª§Ë™øÊï¥‰æÜÂ¢ûÂº∑ÂïèÈ°åÂΩ¢ÂºèÂåñÂíåÊ±ÇËß£Âô®‰ª£Á¢ºÁîüÊàêÊ∫ñÁ¢∫ÊÄßÂíåÊôÆÈÅçÊÄß„ÄÇÂú®ÈÇ£‰πãÂæåÔºåÁÇ∫‰∫ÜÈò≤Ê≠¢ LLM ‰∏≠ÁöÑÂπªË¶∫Ôºå‰æãÂ¶ÇÁäßÁâ≤Ê±ÇËß£Ê∫ñÁ¢∫ÊÄß‰ª•ÈÅøÂÖçÂü∑Ë°åÈåØË™§ÔºåÂú® LLMOPT ‰∏≠Êé°Áî®‰∫ÜÊ®°ÂûãÂ∞çÈΩäÂíåËá™Ê†°Ê≠£Ê©üÂà∂„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü LLMOPT ÁöÑÂÑ™ÂåñÊ≥õÂåñËÉΩÂäõÔºå‰∏¶ÊØîËºÉ‰∫ÜÂÖ≠ÂÄãÊ∂µËìãÂÅ•Â∫∑„ÄÅÁí∞Â¢É„ÄÅËÉΩÊ∫êÂíåË£ΩÈÄ†Á≠âÁ¥Ñ 20 ÂÄãÈ†òÂüüÁöÑÁúüÂØ¶‰∏ñÁïåÊï∏ÊìöÈõÜ‰∏≠ÁöÑÊñπÊ≥ï„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåLLMOPT ËÉΩÂ§†Â∞çÂêÑÁ®ÆÂÑ™ÂåñÂïèÈ°åÈ°ûÂûãÂª∫Ê®°Ôºå‰æãÂ¶ÇÁ∑öÊÄß/ÈùûÁ∑öÊÄßË¶èÂäÉ„ÄÅÊ∑∑ÂêàÊï¥Êï∏Ë¶èÂäÉÂíåÁµÑÂêàÂÑ™ÂåñÔºå‰∏¶ËàáÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÂèñÂæó‰∫ÜÈ°ØËëóÁöÑ 11.08% Âπ≥ÂùáÊ±ÇËß£Ê∫ñÁ¢∫Â∫¶ÊèêÂçá„ÄÇ‰ª£Á¢ºÂèØÂú® https://github.com/caigaojiang/LLMOPT Áç≤Âæó„ÄÇ</paragraph>

##### **MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback**
2410.13191v2 by Zonghai Yao, Aditya Parashar, Huixue Zhou, Won Seok Jang, Feiyun Ouyang, Zhichao Yang, Hong Yu

Automatic question generation (QG) is essential for AI and NLP, particularly
in intelligent tutoring, dialogue systems, and fact verification. Generating
multiple-choice questions (MCQG) for professional exams, like the United States
Medical Licensing Examination (USMLE), is particularly challenging, requiring
domain expertise and complex multi-hop reasoning for high-quality questions.
However, current large language models (LLMs) like GPT-4 struggle with
professional MCQG due to outdated knowledge, hallucination issues, and prompt
sensitivity, resulting in unsatisfactory quality and difficulty. To address
these challenges, we propose MCQG-SRefine, an LLM self-refine-based (Critique
and Correction) framework for converting medical cases into high-quality
USMLE-style questions. By integrating expert-driven prompt engineering with
iterative self-critique and self-correction feedback, MCQG-SRefine
significantly enhances human expert satisfaction regarding both the quality and
difficulty of the questions. Furthermore, we introduce an LLM-as-Judge-based
automatic metric to replace the complex and costly expert evaluation process,
ensuring reliable and expert-aligned assessments.

ÊëòË¶ÅÔºöËá™ÂãïÈ°åÁõÆÁîüÊàê (QG) Â∞çÊñº AI Âíå NLP Ëá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®Êô∫ÊÖßÊïôÂ≠∏„ÄÅÂ∞çË©±Á≥ªÁµ±Âíå‰∫ãÂØ¶Êü•Ê†∏‰∏≠„ÄÇÁÇ∫Â∞àÊ•≠ËÄÉË©¶ÔºàÂ¶ÇÁæéÂúãÂü∑ÁÖßÈÜ´Â∏´ËÄÉË©¶ (USMLE)ÔºâÁîüÊàêÂ§öÈÅ∏È°å (MCQG) ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÈúÄË¶ÅÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠òÂíåË§áÈõúÁöÑÂ§öË∑≥Êé®ÁêÜÊâçËÉΩÁî¢ÁîüÈ´òÂìÅË≥™ÁöÑÈ°åÁõÆ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑ GPT-4 Á≠âÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî±ÊñºÁü•Ë≠òÈÅéÊôÇ„ÄÅÂπªË¶∫ÂïèÈ°åÂíåÊèêÁ§∫ÊïèÊÑüÊÄßÔºåÂú®Â∞àÊ•≠ MCQG ÊñπÈù¢ÈÅáÂà∞Âõ∞Èõ£ÔºåÂ∞éËá¥ÂìÅË≥™ÂíåÈõ£Â∫¶‰∏ç‰Ω≥„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ MCQG-SRefineÔºå‰∏ÄÁ®ÆÂü∫Êñº LLM Ëá™ÊàëÂÑ™ÂåñÁöÑÔºàÊâπÂà§ÂíåÊõ¥Ê≠£ÔºâÊû∂ÊßãÔºåÁî®ÊñºÂ∞áÈÜ´ÁôÇÊ°à‰æãËΩâÊèõÁÇ∫È´òÂìÅË≥™ÁöÑ USMLE È¢®Ê†ºÈ°åÁõÆ„ÄÇÈÄèÈÅéÊï¥ÂêàÂ∞àÂÆ∂È©ÖÂãïÁöÑÊèêÁ§∫Â∑•Á®ãËàáÂèçË¶ÜËá™ÊàëÊâπÂà§ÂíåËá™ÊàëÊõ¥Ê≠£ÂõûÈ•ãÔºåMCQG-SRefine Â§ßÂπÖÊèêÂçá‰∫Ü‰∫∫È°ûÂ∞àÂÆ∂Â∞çÈ°åÁõÆÂìÅË≥™ÂíåÈõ£Â∫¶ÁöÑÊªøÊÑèÂ∫¶„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂü∫Êñº LLM-as-Judge ÁöÑËá™ÂãïÂåñÊåáÊ®ô‰æÜÂèñ‰ª£Ë§áÈõú‰∏îÊòÇË≤¥ÁöÑÂ∞àÂÆ∂Ë©ï‰º∞ÈÅéÁ®ãÔºåÁ¢∫‰øùÂèØÈù†‰∏îËàáÂ∞àÂÆ∂‰∏ÄËá¥ÁöÑË©ï‰º∞„ÄÇ

##### **Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information**
2410.12774v1 by Yingya Li, Timothy Miller, Steven Bethard, Guergana Savova

The success of multi-task learning can depend heavily on which tasks are
grouped together. Naively grouping all tasks or a random set of tasks can
result in negative transfer, with the multi-task models performing worse than
single-task models. Though many efforts have been made to identify task
groupings and to measure the relatedness among different tasks, it remains a
challenging research topic to define a metric to identify the best task
grouping out of a pool of many potential task combinations. We propose a metric
of task relatedness based on task difficulty measured by pointwise V-usable
information (PVI). PVI is a recently proposed metric to estimate how much
usable information a dataset contains given a model. We hypothesize that tasks
with not statistically different PVI estimates are similar enough to benefit
from the joint learning process. We conduct comprehensive experiments to
evaluate the feasibility of this metric for task grouping on 15 NLP datasets in
the general, biomedical, and clinical domains. We compare the results of the
joint learners against single learners, existing baseline methods, and recent
large language models, including Llama 2 and GPT-4. The results show that by
grouping tasks with similar PVI estimates, the joint learners yielded
competitive results with fewer total parameters, with consistent performance
across domains.

ÊëòË¶ÅÔºöÂ§ö‰ªªÂãôÂ≠∏ÁøíÁöÑÊàêÂäüÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÊ±∫ÊñºÂ∞áÂì™‰∫õ‰ªªÂãôÂàÜÁµÑÂú®‰∏ÄËµ∑„ÄÇÂ§©ÁúüÂú∞Â∞áÊâÄÊúâ‰ªªÂãôÊàñ‰∏ÄÁµÑÈö®Ê©ü‰ªªÂãôÂàÜÁµÑÂèØËÉΩÊúÉÂ∞éËá¥Ë≤†ÂêëÈÅ∑ÁßªÔºåÂ§ö‰ªªÂãôÊ®°ÂûãÁöÑË°®ÁèæÊúÉÊØîÂñÆ‰ªªÂãôÊ®°ÂûãÂ∑Æ„ÄÇÂÑòÁÆ°Â∑≤ÂÅöÂá∫Ë®±Â§öÂä™Âäõ‰æÜË≠òÂà•‰ªªÂãôÂàÜÁµÑ‰∏¶Ë°°Èáè‰∏çÂêå‰ªªÂãô‰πãÈñìÁöÑÈóúËÅØÊÄßÔºå‰ΩÜÂÆöÁæ©‰∏ÄÂÄãÊåáÊ®ô‰ª•ÂæûË®±Â§öÊΩõÂú®‰ªªÂãôÁµÑÂêà‰∏≠Ë≠òÂà•Âá∫ÊúÄ‰Ω≥‰ªªÂãôÂàÜÁµÑ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁ†îÁ©∂Ë™≤È°å„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÈªûÂºè V ÂèØÁî®Ë≥áË®ä (PVI) Ë°°ÈáèÁöÑ‰ªªÂãôÈõ£Â∫¶‰æÜË°°Èáè‰ªªÂãôÁõ∏ÈóúÊÄßÁöÑÊåáÊ®ô„ÄÇPVI ÊòØ‰∏ÄÂÄãÊúÄËøëÊèêÂá∫ÁöÑÊåáÊ®ôÔºåÁî®Êñº‰º∞Ë®àÁµ¶ÂÆöÊ®°ÂûãË≥áÊñôÈõÜÂåÖÂê´Â§öÂ∞ëÂèØÁî®Ë≥áË®ä„ÄÇÊàëÂÄëÂÅáË®≠ PVI ‰º∞Ë®àÂú®Áµ±Ë®à‰∏äÊ≤íÊúâÂ∑ÆÁï∞ÁöÑ‰ªªÂãôË∂≥Â§†Áõ∏‰ººÔºåÂèØ‰ª•ÂæûËÅØÂêàÂ≠∏ÁøíÈÅéÁ®ã‰∏≠ÂèóÁõä„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂØ¶È©óÔºå‰ª•Ë©ï‰º∞Ê≠§ÊåáÊ®ôÂú® 15 ÂÄã‰∏ÄËà¨„ÄÅÁîüÁâ©ÈÜ´Â≠∏ÂíåËá®Â∫äÈ†òÂüüÁöÑ NLP Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰ªªÂãôÂàÜÁµÑÁöÑÂèØË°åÊÄß„ÄÇÊàëÂÄëÂ∞áËÅØÂêàÂ≠∏ÁøíËÄÖÁöÑÁµêÊûúËàáÂñÆ‰∏ÄÂ≠∏ÁøíËÄÖ„ÄÅÁèæÊúâÁöÑÂü∫Ê∫ñÊñπÊ≥ïÂíåÊúÄËøëÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÔºàÂåÖÊã¨ Llama 2 Âíå GPT-4ÔºâÈÄ≤Ë°åÊØîËºÉ„ÄÇÁµêÊûúË°®ÊòéÔºåÈÄöÈÅéÂ∞áÂÖ∑ÊúâÁõ∏‰ºº PVI ‰º∞Ë®àÂÄºÁöÑ‰ªªÂãôÂàÜÁµÑÔºåËÅØÂêàÂ≠∏ÁøíËÄÖ‰ª•ËºÉÂ∞ëÁöÑÁ∏ΩÂèÉÊï∏Áî¢Áîü‰∫ÜÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÁµêÊûúÔºå‰∏¶‰∏îÂú®ÂêÑÂÄãÈ†òÂüü‰∏≠Ë°®Áèæ‰∏ÄËá¥„ÄÇ

##### **FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**
2410.12707v1 by Zhenheng Tang, Xueze Kang, Yiming Yin, Xinglin Pan, Yuxin Wang, Xin He, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Amelie Chi Zhou, Bo Li, Bingsheng He, Xiaowen Chu

To alleviate hardware scarcity in training large deep neural networks (DNNs),
particularly large language models (LLMs), we present FusionLLM, a
decentralized training system designed and implemented for training DNNs using
geo-distributed GPUs across different computing clusters or individual devices.
Decentralized training faces significant challenges regarding system design and
efficiency, including: 1) the need for remote automatic differentiation (RAD),
2) support for flexible model definitions and heterogeneous software, 3)
heterogeneous hardware leading to low resource utilization or the straggler
problem, and 4) slow network communication. To address these challenges, in the
system design, we represent the model as a directed acyclic graph of operators
(OP-DAG). Each node in the DAG represents the operator in the DNNs, while the
edge represents the data dependency between operators. Based on this design, 1)
users are allowed to customize any DNN without caring low-level operator
implementation; 2) we enable the task scheduling with the more fine-grained
sub-tasks, offering more optimization space; 3) a DAG runtime executor can
implement RAD withour requiring the consistent low-level ML framework versions.
  To enhance system efficiency, we implement a workload estimator and design an
OP-Fence scheduler to cluster devices with similar bandwidths together and
partition the DAG to increase throughput. Additionally, we propose an AdaTopK
compressor to adaptively compress intermediate activations and gradients at the
slowest communication links. To evaluate the convergence and efficiency of our
system and algorithms, we train ResNet-101 and GPT-2 on three real-world
testbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental
results demonstrate that our system and method can achieve 1.45 - 9.39x speedup
compared to baseline methods while ensuring convergence.

ÊëòË¶ÅÔºö<paragraph>ÁÇ∫‰∫ÜÊ∏õËºïË®ìÁ∑¥Â§ßÂûãÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) ÁöÑÁ°¨È´îÁü≠Áº∫ÂïèÈ°åÔºåÂ∞§ÂÖ∂ÊòØÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü FusionLLMÔºå‰∏ÄÂÄãÂàÜÊï£ÂºèË®ìÁ∑¥Á≥ªÁµ±ÔºåÂÖ∂Ë®≠Ë®àÂíåÂØ¶‰ΩúÊòØÁî®ÊñºË®ìÁ∑¥Ë∑®‰∏çÂêåÈÅãÁÆóÂè¢ÈõÜÊàñÂÄãÂà•Ë£ùÁΩÆÁöÑÂú∞ÁêÜÂàÜÊï£Âºè GPU ÁöÑ DNN„ÄÇÂàÜÊï£ÂºèË®ìÁ∑¥Âú®Á≥ªÁµ±Ë®≠Ë®àÂíåÊïàÁéáÊñπÈù¢Èù¢Ëá®ÈáçÂ§ßÊåëÊà∞ÔºåÂåÖÊã¨Ôºö1) ÈúÄË¶ÅÈÅ†Á´ØËá™ÂãïÂæÆÂàÜ (RAD)Ôºå2) ÊîØÊè¥ÂΩàÊÄßÁöÑÊ®°ÂûãÂÆöÁæ©ÂíåÁï∞Ë≥™ËªüÈ´îÔºå3) Áï∞Ë≥™Á°¨È´îÂ∞éËá¥Ë≥áÊ∫êÂà©Áî®Áéá‰ΩéÊàñËêΩÂæåÂïèÈ°åÔºå‰ª•Âèä 4) Á∂≤Ë∑ØÈÄöË®äÈÄüÂ∫¶ÊÖ¢„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÂú®Á≥ªÁµ±Ë®≠Ë®à‰∏≠ÔºåÊàëÂÄëÂ∞áÊ®°ÂûãË°®Á§∫ÁÇ∫‰∏ÄÂÄãÊúâÂêëÈùûÂæ™Áí∞Âúñ (OP-DAG) ÁöÑÈÅãÁÆóÂ≠ê„ÄÇDAG ‰∏≠ÁöÑÊØèÂÄãÁØÄÈªû‰ª£Ë°® DNN ‰∏≠ÁöÑÈÅãÁÆóÂ≠êÔºåËÄåÈÇäÁ∑£‰ª£Ë°®ÈÅãÁÆóÂ≠ê‰πãÈñìÁöÑË≥áÊñô‰æùË≥¥ÊÄß„ÄÇÂü∫ÊñºÊ≠§Ë®≠Ë®àÔºå1) ‰ΩøÁî®ËÄÖÂèØ‰ª•Ëá™Ë®Ç‰ªª‰Ωï DNNÔºåËÄå‰∏çÁî®ËÄÉÊÖÆ‰ΩéÈöéÈÅãÁÆóÂ≠êÂØ¶‰ΩúÔºõ2) ÊàëÂÄëÂïüÁî®‰ªªÂãôÊéíÁ®ãÔºå‰∏¶‰ΩøÁî®Êõ¥Á¥∞Á∑ªÁöÑÂ≠ê‰ªªÂãôÔºåÊèê‰æõÊõ¥Â§öÊúÄ‰Ω≥ÂåñÁ©∫ÈñìÔºõ3) DAG Âü∑Ë°åÊôÇÈñìÂü∑Ë°åÂô®ÂèØ‰ª•ÂØ¶‰Ωú RADÔºåËÄå‰∏çÈúÄË¶Å‰∏ÄËá¥ÁöÑ‰ΩéÈöé ML Êû∂ÊßãÁâàÊú¨„ÄÇÁÇ∫‰∫ÜÊèêÂçáÁ≥ªÁµ±ÊïàÁéáÔºåÊàëÂÄëÂØ¶‰Ωú‰∏ÄÂÄãÂ∑•‰ΩúË≤†Ëºâ‰º∞Ë®àÂô®Ôºå‰∏¶Ë®≠Ë®à‰∏ÄÂÄã OP-Fence ÊéíÁ®ãÂô®ÔºåÂ∞áÈ†ªÂØ¨È°û‰ººÁöÑË£ùÁΩÆÂàÜÁµÑÂú®‰∏ÄËµ∑Ôºå‰∏¶ÂàÜÂâ≤ DAG ‰ª•Â¢ûÂä†ËôïÁêÜÈáè„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã AdaTopK Â£ìÁ∏ÆÂô®Ôºå‰ª•Ëá™ÈÅ©ÊáâÊñπÂºèÂ£ìÁ∏ÆÊúÄÊÖ¢ÈÄöË®äÈÄ£Áµê‰∏äÁöÑ‰∏≠ÈñìÂïüÂãïÂíåÊ¢ØÂ∫¶„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÊàëÂÄëÁ≥ªÁµ±ÂíåÊºîÁÆóÊ≥ïÁöÑÊî∂ÊñÇÊÄßÂíåÊïàÁéáÔºåÊàëÂÄëÂú®‰∏âÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑÊ∏¨Ë©¶Âπ≥Âè∞‰∏äË®ìÁ∑¥ ResNet-101 Âíå GPT-2Ôºå‰ΩøÁî® 48 ÂÄã GPU ÈÄ£Êé•Âà∞ 8 Mbps~10 Gbps Á∂≤Ë∑Ø„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±ÂíåÊñπÊ≥ïÂèØ‰ª•ÊØîÂü∫Ê∫ñÊñπÊ≥ïÂø´ 1.45 - 9.39 ÂÄçÔºåÂêåÊôÇÁ¢∫‰øùÊî∂ÊñÇ„ÄÇ</paragraph>

##### **Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2**
2410.12686v2 by Mohamad Abdi, Gerardo Hermosillo Valadez, Halid Ziya Yerebakan

Anatomical landmarks are vital in medical imaging for navigation and anomaly
detection. Modern large language models (LLMs), like Llama-2, offer promise for
automating the mapping of these landmarks in free-text radiology reports to
corresponding positions in image data. Recent studies propose LLMs may develop
coherent representations of generative processes. Motivated by these insights,
we investigated whether LLMs accurately represent the spatial positions of
anatomical landmarks. Through experiments with Llama-2 models, we found that
they can linearly represent anatomical landmarks in space with considerable
robustness to different prompts. These results underscore the potential of LLMs
to enhance the efficiency and accuracy of medical imaging workflows.

ÊëòË¶ÅÔºöËß£ÂâñÂú∞Ê®ôÂú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠Â∞çÊñºÂ∞éËà™ÂíåÁï∞Â∏∏ÂÅµÊ∏¨Ëá≥ÈóúÈáçË¶Å„ÄÇÂÉè Llama-2 ÈÄôÊ®£ÁöÑÁèæ‰ª£Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúâÊúõËá™ÂãïÂ∞áÈÄô‰∫õÂú∞Ê®ôÂ∞çÊáâÂà∞ÂΩ±ÂÉèË≥áÊñô‰∏≠ÁöÑ‰ΩçÁΩÆÔºå‰∏¶Áπ™Ë£ΩÂú®Ëá™Áî±Ê†ºÂºèÁöÑÊîæÂ∞ÑÁßëÂ†±Âëä‰∏≠„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÊèêÂá∫ LLM ÂèØËÉΩÈñãÁôºÂá∫ÁîüÊàêÂºèÈÅéÁ®ãÁöÑÁõ∏Âπ≤Ë°®Âæµ„ÄÇÂèóÂà∞ÈÄô‰∫õË¶ãËß£ÁöÑÂïüÁôºÔºåÊàëÂÄëË™øÊü•‰∫Ü LLM ÊòØÂê¶ËÉΩÊ∫ñÁ¢∫Ë°®Á§∫Ëß£ÂâñÂú∞Ê®ôÁöÑÁ©∫Èñì‰ΩçÁΩÆ„ÄÇÈÄèÈÅé‰ΩøÁî® Llama-2 Ê®°ÂûãÈÄ≤Ë°åÂØ¶È©óÔºåÊàëÂÄëÁôºÁèæÂÆÉÂÄëÂèØ‰ª•Á∑öÊÄßË°®Á§∫Á©∫Èñì‰∏≠ÁöÑËß£ÂâñÂú∞Ê®ôÔºå‰∏¶‰∏îÂ∞çÊñº‰∏çÂêåÁöÑÊèêÁ§∫ÂÖ∑ÊúâÁõ∏Áï∂ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÈÄô‰∫õÁµêÊûúÂº∑Ë™ø‰∫Ü LLM ÊèêÂçáÈÜ´Â≠∏ÂΩ±ÂÉèÂ∑•‰ΩúÊµÅÁ®ãÊïàÁéáÂíåÊ∫ñÁ¢∫ÊÄßÁöÑÊΩõÂäõ„ÄÇ

##### **Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans**
2410.12641v1 by Luca Marsilio, Davide Marzorati, Matteo Rossi, Andrea Moglia, Luca Mainardi, Alfonso Manzotti, Pietro Cerveri

Osteoarthritis is a degenerative condition affecting bones and cartilage,
often leading to osteophyte formation, bone density loss, and joint space
narrowing. Treatment options to restore normal joint function vary depending on
the severity of the condition. This work introduces an innovative deep-learning
framework processing shoulder CT scans. It features the semantic segmentation
of the proximal humerus and scapula, the 3D reconstruction of bone surfaces,
the identification of the glenohumeral (GH) joint region, and the staging of
three common osteoarthritic-related pathologies: osteophyte formation (OS), GH
space reduction (JS), and humeroscapular alignment (HSA). The pipeline
comprises two cascaded CNN architectures: 3D CEL-UNet for segmentation and 3D
Arthro-Net for threefold classification. A retrospective dataset of 571 CT
scans featuring patients with various degrees of GH osteoarthritic-related
pathologies was used to train, validate, and test the pipeline. Root mean
squared error and Hausdorff distance median values for 3D reconstruction were
0.22mm and 1.48mm for the humerus and 0.24mm and 1.48mm for the scapula,
outperforming state-of-the-art architectures and making it potentially suitable
for a PSI-based shoulder arthroplasty preoperative plan context. The
classification accuracy for OS, JS, and HSA consistently reached around 90%
across all three categories. The computational time for the inference pipeline
was less than 15s, showcasing the framework's efficiency and compatibility with
orthopedic radiology practice. The outcomes represent a promising advancement
toward the medical translation of artificial intelligence tools. This progress
aims to streamline the preoperative planning pipeline delivering high-quality
bone surfaces and supporting surgeons in selecting the most suitable surgical
approach according to the unique patient joint conditions.

ÊëòË¶ÅÔºöÈ™®ÈóúÁØÄÁÇéÊòØ‰∏ÄÁ®ÆÈÄÄÂåñÊÄßÁñæÁóÖÔºåÊúÉÂΩ±ÈüøÈ™®È™ºÂíåËªüÈ™®Ôºå
ÈÄöÂ∏∏ÊúÉÂ∞éËá¥È™®Ë¥ÖÂΩ¢Êàê„ÄÅÈ™®ÂØÜÂ∫¶ÊµÅÂ§±ÂíåÈóúÁØÄÈñìÈöôËÆäÁ™Ñ„ÄÇÊ≤ªÁôÇÈÅ∏È†ÖÊúÉÊ†πÊìöÁóÖÊÉÖÁöÑÂö¥ÈáçÁ®ãÂ∫¶ËÄåÊúâÊâÄ‰∏çÂêåÔºå‰ª•ÊÅ¢Âæ©Ê≠£Â∏∏ÁöÑÈóúÁØÄÂäüËÉΩ„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÔºåÁî®ÊñºËôïÁêÜËÇ©ÈÉ® CT ÊéÉÊèè„ÄÇÂÆÉÁöÑÁâπÈªûÊòØËøëÁ´ØËÇ±È™®ÂíåËÇ©ËÉõÈ™®ÁöÑË™ûÁæ©ÂàÜÂâ≤„ÄÅÈ™®Ë°®Èù¢ÁöÑ 3D ÈáçÂª∫„ÄÅÁõÇËÇ± (GH) ÈóúÁØÄÂçÄÂüüÁöÑË≠òÂà•Ôºå‰ª•Âèä‰∏âÁ®ÆÂ∏∏Ë¶ãÈ™®ÈóúÁØÄÁÇéÁõ∏ÈóúÁóÖÁêÜÁöÑÂàÜÈ°ûÔºöÈ™®Ë¥ÖÂΩ¢Êàê (OS)„ÄÅGH ÈñìÈöôÁ∏ÆÂ∞è (JS) ÂíåËÇ±È™®ËÇ©ËÉõÈ™®Â∞çÈΩä (HSA)„ÄÇË©≤ÁÆ°ÈÅìÂåÖÂê´ÂÖ©ÂÄã‰∏≤ËÅØÁöÑ CNN Êû∂ÊßãÔºöÁî®ÊñºÂàÜÂâ≤ÁöÑ 3D CEL-UNet ÂíåÁî®Êñº‰∏âÂàÜÈ°ûÁöÑ 3D Arthro-Net„ÄÇ‰∏ÄÂÄãÂåÖÂê´ 571 ‰æã CT ÊéÉÊèèÁöÑÂõûÈ°ßÊÄßÊï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÊÇ£Êúâ‰∏çÂêåÁ®ãÂ∫¶ GH È™®ÈóúÁØÄÁÇéÁõ∏ÈóúÁóÖÁêÜÁöÑÊÇ£ËÄÖÔºåÁî®ÊñºË®ìÁ∑¥„ÄÅÈ©óË≠âÂíåÊ∏¨Ë©¶Ë©≤ÁÆ°ÈÅì„ÄÇËÇ±È™®ÁöÑ 3D ÈáçÂª∫ÁöÑÂùáÊñπÊ†πË™§Â∑ÆÂíå Hausdorff Ë∑ùÈõ¢‰∏≠ÂÄºÁÇ∫ 0.22mm Âíå 1.48mmÔºåËÇ©ËÉõÈ™®ÁöÑÂùáÊñπÊ†πË™§Â∑ÆÂíå Hausdorff Ë∑ùÈõ¢‰∏≠ÂÄºÁÇ∫ 0.24mm Âíå 1.48mmÔºåÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊû∂ÊßãÔºå‰ΩøÂÖ∂ÊΩõÂú®Âú∞ÈÅ©Áî®ÊñºÂü∫Êñº PSI ÁöÑËÇ©ÈÉ®ÈóúÁØÄÁΩÆÊèõË°ìË°ìÂâçË®àÂäÉËÉåÊôØ„ÄÇOS„ÄÅJS Âíå HSA ÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫ÁéáÂú®ÊâÄÊúâ‰∏âÈ°û‰∏≠ÂßãÁµÇÈÅîÂà∞Á¥Ñ 90%„ÄÇÊé®ÁêÜÁÆ°ÈÅìÁöÑË®àÁÆóÊôÇÈñì‰∏çÂà∞ 15 ÁßíÔºåÂ±ïÁ§∫‰∫ÜË©≤Ê°ÜÊû∂ÁöÑÊïàÁéáÂíåËàáÈ™®ÁßëÊîæÂ∞ÑÂ≠∏ÂØ¶Ë∏êÁöÑÁõ∏ÂÆπÊÄß„ÄÇÁµêÊûú‰ª£Ë°®‰∫Ü‰∫∫Â∑•Êô∫ÊÖßÂ∑•ÂÖ∑ÈÜ´Â≠∏ËΩâÂåñÁöÑÊúâÂ∏åÊúõÁöÑÈÄ≤Â±ï„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïÊó®Âú®Á∞°ÂåñË°ìÂâçË®àÂäÉÁÆ°ÈÅìÔºåÊèê‰æõÈ´òÂìÅË≥™ÁöÑÈ™®Ë°®Èù¢Ôºå‰∏¶ÊîØÊåÅÂ§ñÁßëÈÜ´ÁîüÊ†πÊìöÊÇ£ËÄÖÁç®ÁâπÁöÑÈóúÁØÄÁãÄÊ≥ÅÈÅ∏ÊìáÊúÄÂêàÈÅ©ÁöÑÊâãË°ìÊñπÊ≥ï„ÄÇ

##### **NSSI-Net: Multi-Concept Generative Adversarial Network for Non-Suicidal Self-Injury Detection Using High-Dimensional EEG Signals in a Semi-Supervised Learning Framework**
2410.12159v1 by Zhen Liang, Weishan Ye, Qile Liu, Li Zhang, Gan Huang, Yongjie Zhou

Non-suicidal self-injury (NSSI) is a serious threat to the physical and
mental health of adolescents, significantly increasing the risk of suicide and
attracting widespread public concern. Electroencephalography (EEG), as an
objective tool for identifying brain disorders, holds great promise. However,
extracting meaningful and reliable features from high-dimensional EEG data,
especially by integrating spatiotemporal brain dynamics into informative
representations, remains a major challenge. In this study, we introduce an
advanced semi-supervised adversarial network, NSSI-Net, to effectively model
EEG features related to NSSI. NSSI-Net consists of two key modules: a
spatial-temporal feature extraction module and a multi-concept discriminator.
In the spatial-temporal feature extraction module, an integrated 2D
convolutional neural network (2D-CNN) and a bi-directional Gated Recurrent Unit
(BiGRU) are used to capture both spatial and temporal dynamics in EEG data. In
the multi-concept discriminator, signal, gender, domain, and disease levels are
fully explored to extract meaningful EEG features, considering individual,
demographic, disease variations across a diverse population. Based on
self-collected NSSI data (n=114), the model's effectiveness and reliability are
demonstrated, with a 7.44% improvement in performance compared to existing
machine learning and deep learning methods. This study advances the
understanding and early diagnosis of NSSI in adolescents with depression,
enabling timely intervention. The source code is available at
https://github.com/Vesan-yws/NSSINet.

ÊëòË¶ÅÔºöÈùûËá™ÊùÄÊÄßËá™‰º§ (NSSI) ÂØπÈùíÂ∞ëÂπ¥ÁöÑË∫´ÂøÉÂÅ•Â∫∑ÊûÑÊàê‰∏•ÈáçÂ®ÅËÉÅÔºåÊòæËëóÂ¢ûÂä†‰∫ÜËá™ÊùÄÈ£éÈô©ÔºåÂπ∂ÂºïËµ∑‰∫ÜÂπøÊ≥õÁöÑÂÖ¨‰ºóÂÖ≥Ê≥®„ÄÇËÑëÁîµÂõæ (EEG) ‰Ωú‰∏∫‰∏ÄÁßçËØÜÂà´ËÑëÈÉ®ÁñæÁóÖÁöÑÂÆ¢ËßÇÂ∑•ÂÖ∑ÔºåÂÖ∑ÊúâÂπøÈòîÁöÑÂâçÊôØ„ÄÇÁÑ∂ËÄåÔºå‰ªéÈ´òÁª¥ EEG Êï∞ÊçÆ‰∏≠ÊèêÂèñÊúâÊÑè‰πâ‰∏îÂèØÈù†ÁöÑÁâπÂæÅÔºåÁâπÂà´ÊòØÈÄöËøáÂ∞ÜÊó∂Á©∫ËÑëÂä®ÊÄÅÊï¥ÂêàÂà∞‰ø°ÊÅØË°®Á§∫‰∏≠Ôºå‰ªçÁÑ∂ÊòØ‰∏ÄÈ°πÈáçÂ§ßÊåëÊàò„ÄÇÂú®ËøôÈ°πÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨‰ªãÁªç‰∫Ü‰∏Ä‰∏™ÂÖàËøõÁöÑÂçäÁõëÁù£ÂØπÊäóÁΩëÁªú NSSI-NetÔºå‰ª•ÊúâÊïàÂª∫Ê®°‰∏é NSSI Áõ∏ÂÖ≥ÁöÑ EEG ÁâπÂæÅ„ÄÇNSSI-Net Áî±‰∏§‰∏™ÂÖ≥ÈîÆÊ®°ÂùóÁªÑÊàêÔºöÊó∂Á©∫ÁâπÂæÅÊèêÂèñÊ®°ÂùóÂíåÂ§öÊ¶ÇÂøµÂà§Âà´Âô®„ÄÇÂú®Êó∂Á©∫ÁâπÂæÅÊèêÂèñÊ®°Âùó‰∏≠ÔºåÈõÜÊàêÁöÑ‰∫åÁª¥Âç∑ÁßØÁ•ûÁªèÁΩëÁªú (2D-CNN) ÂíåÂèåÂêëÈó®ÊéßÂæ™ÁéØÂçïÂÖÉ (BiGRU) Áî®‰∫éÊçïÊçâ EEG Êï∞ÊçÆ‰∏≠ÁöÑÁ©∫Èó¥ÂíåÊó∂Èó¥Âä®ÊÄÅ„ÄÇÂú®Â§öÊ¶ÇÂøµÂà§Âà´Âô®‰∏≠ÔºåÂÖÖÂàÜÊé¢Á¥¢‰ø°Âè∑„ÄÅÊÄßÂà´„ÄÅÂüüÂíåÁñæÁóÖÊ∞¥Âπ≥Ôºå‰ª•ÊèêÂèñÊúâÊÑè‰πâÁöÑ EEG ÁâπÂæÅÔºåËÄÉËôë‰∏çÂêå‰∫∫Áæ§‰∏≠ÁöÑ‰∏™‰Ωì„ÄÅ‰∫∫Âè£ÁªüËÆ°Â≠¶„ÄÅÁñæÁóÖÂèòÂºÇ„ÄÇÂü∫‰∫éËá™Êî∂ÈõÜÁöÑ NSSI Êï∞ÊçÆ (n=114)ÔºåËØ•Ê®°ÂûãÁöÑÊúâÊïàÊÄßÂíåÂèØÈù†ÊÄßÂæóÂà∞ËØÅÂÆûÔºå‰∏éÁé∞ÊúâÁöÑÊú∫Âô®Â≠¶‰π†ÂíåÊ∑±Â∫¶Â≠¶‰π†ÊñπÊ≥ïÁõ∏ÊØîÔºåÊÄßËÉΩÊèêÈ´ò‰∫Ü 7.44%„ÄÇËøôÈ°πÁ†îÁ©∂‰øÉËøõ‰∫ÜÂØπÊÇ£ÊúâÊäëÈÉÅÁóáÁöÑÈùíÂ∞ëÂπ¥ NSSI ÁöÑÁêÜËß£ÂíåÊó©ÊúüËØäÊñ≠ÔºåÂÆûÁé∞‰∫ÜÂèäÊó∂ÁöÑÂπ≤È¢Ñ„ÄÇÊ∫ê‰ª£Á†ÅÂèØÂú® https://github.com/Vesan-yws/NSSINet Ëé∑Âæó„ÄÇ

##### **SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding**
2410.11761v1 by Ying Chen, Guoan Wang, Yuanfeng Ji, Yanjun Li, Jin Ye, Tianbin Li, Bin Zhang, Nana Pei, Rongshan Yu, Yu Qiao, Junjun He

Despite the progress made by multimodal large language models (MLLMs) in
computational pathology, they remain limited by a predominant focus on
patch-level analysis, missing essential contextual information at the
whole-slide level. The lack of large-scale instruction datasets and the
gigapixel scale of whole slide images (WSIs) pose significant developmental
challenges. In this paper, we present SlideChat, the first vision-language
assistant capable of understanding gigapixel whole-slide images, exhibiting
excellent multimodal conversational capability and response complex instruction
across diverse pathology scenarios. To support its development, we created
SlideInstruction, the largest instruction-following dataset for WSIs consisting
of 4.2K WSI captions and 176K VQA pairs with multiple categories. Furthermore,
we propose SlideBench, a multimodal benchmark that incorporates captioning and
VQA tasks to assess SlideChat's capabilities in varied clinical settings such
as microscopy, diagnosis. Compared to both general and specialized MLLMs,
SlideChat exhibits exceptional capabilities achieving state-of-the-art
performance on 18 of 22 tasks. For example, it achieved an overall accuracy of
81.17% on SlideBench-VQA (TCGA), and 54.15% on SlideBench-VQA (BCNB). We will
fully release SlideChat, SlideInstruction and SlideBench as open-source
resources to facilitate research and development in computational pathology.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) Âú®Ë®àÁÆóÁóÖÁêÜÂ≠∏ÊñπÈù¢ÂèñÂæó‰∫ÜÈÄ≤Â±ïÔºå‰ΩÜÂÆÉÂÄë‰ªçÁÑ∂ÂèóÈôêÊñºÂ∞çÂçÄÂ°äÁ¥öÂàÜÊûêÁöÑÈóúÊ≥®ÔºåÈåØÂ§±‰∫ÜÂÖ®ÂπªÁáàÁâáÁ¥öÂà•ÁöÑÂøÖË¶ÅËÑàÁµ°Ë≥áË®ä„ÄÇÁº∫‰πèÂ§ßË¶èÊ®°ÁöÑÊåá‰ª§Ë≥áÊñôÈõÜÂíåÂÖ®ÂπªÁáàÁâáÂΩ±ÂÉè (WSI) ÁöÑÂêâÂÉèÁ¥†Ë¶èÊ®°ÔºåÊßãÊàê‰∫ÜÈáçÂ§ßÁöÑÈñãÁôºÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü SlideChatÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãËÉΩÂ§†ÁêÜËß£ÂêâÂÉèÁ¥†ÂÖ®ÂπªÁáàÁâáÂΩ±ÂÉèÁöÑË¶ñË¶∫Ë™ûË®ÄÂä©ÁêÜÔºåÂ±ïÁèæÂá∫ÂÑ™ÁßÄÁöÑÂ§öÊ®°ÊÖãÂ∞çË©±ËÉΩÂäõÂíåÂ∞çÂêÑÁ®ÆÁóÖÁêÜÊÉÖÂ¢ÉÁöÑË§áÈõúÊåá‰ª§ÂõûÊáâ„ÄÇÁÇ∫‰∫ÜÊîØÊè¥ÂÖ∂ÈñãÁôºÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü SlideInstructionÔºåÈÄôÊòØÊúÄÂ§ßÁöÑ WSI Êåá‰ª§ÈÅµÂæ™Ë≥áÊñôÈõÜÔºåÂåÖÂê´ 4.2K WSI Ê®ôÈ°åÂíå 176K ÂÄãÂÖ∑ÊúâÂ§öÂÄãÈ°ûÂà•ÁöÑ VQA ÈÖçÂ∞ç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü SlideBenchÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öÊ®°ÊÖãÂü∫Ê∫ñÔºåÁµêÂêà‰∫ÜÊ®ôÈ°åÂíå VQA ‰ªªÂãôÔºå‰ª•Ë©ï‰º∞ SlideChat Âú®È°ØÂæÆÈè°Ê™¢Êü•„ÄÅË®∫Êñ∑Á≠â‰∏çÂêåËá®Â∫äË®≠ÂÆö‰∏≠ÁöÑËÉΩÂäõ„ÄÇËàá‰∏ÄËà¨ÂíåÂ∞àÈñÄÁöÑ MLLM Áõ∏ÊØîÔºåSlideChat Â±ïÁèæ‰∫ÜÂçìË∂äÁöÑËÉΩÂäõÔºåÂú® 22 ÂÄã‰ªªÂãô‰∏≠ÁöÑ 18 ÂÄã‰ªªÂãô‰∏≠ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ‰æãÂ¶ÇÔºåÂÆÉÂú® SlideBench-VQA (TCGA) ‰∏äÈÅîÂà∞‰∫Ü 81.17% ÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶ÔºåÂú® SlideBench-VQA (BCNB) ‰∏äÈÅîÂà∞‰∫Ü 54.15%„ÄÇÊàëÂÄëÂ∞áÂÖ®Èù¢ÈáãÂá∫ SlideChat„ÄÅSlideInstruction Âíå SlideBench ‰ΩúÁÇ∫ÈñãÊîæÂéüÂßãÁ¢ºË≥áÊ∫êÔºå‰ª•‰øÉÈÄ≤Ë®àÁÆóÁóÖÁêÜÂ≠∏ÁöÑÁ†îÁ©∂ÂíåÈñãÁôº„ÄÇ

##### **RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping**
2410.11651v1 by Chiyi Huang, Longwei Sun, Dong Liang, Haifeng Liang, Hongwu Zeng, Yanjie Zhu

Cardiac T1 mapping can evaluate various clinical symptoms of myocardial
tissue. However, there is currently a lack of effective, robust, and efficient
methods for motion correction in cardiac T1 mapping. In this paper, we propose
a deep learning-based and topology-preserving image registration framework for
motion correction in cardiac T1 mapping. Notably, our proposed implicit
consistency constraint dubbed BLOC, to some extent preserves the image topology
in registration by bidirectional consistency constraint and local anti-folding
constraint. To address the contrast variation issue, we introduce a weighted
image similarity metric for multimodal registration of cardiac T1-weighted
images. Besides, a semi-supervised myocardium segmentation network and a
dual-domain attention module are integrated into the framework to further
improve the performance of the registration. Numerous comparative experiments,
as well as ablation studies, demonstrated the effectiveness and high robustness
of our method. The results also indicate that the proposed weighted image
similarity metric, specifically crafted for our network, contributes a lot to
the enhancement of the motion correction efficacy, while the bidirectional
consistency constraint combined with the local anti-folding constraint ensures
a more desirable topology-preserving registration mapping.

ÊëòË¶ÅÔºöÂøÉËÇå T1 Â∞çÊØîÂ∫¶ÊàêÂÉèÂèØË©ï‰º∞ÂøÉËÇåÁµÑÁπîÁöÑÂêÑÁ®ÆËá®Â∫äË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÂú®ÂøÉËÇå T1 Â∞çÊØîÂ∫¶ÊàêÂÉè‰∏≠ÔºåÁº∫‰πèÊúâÊïà„ÄÅÁ©©ÂÅ•‰∏îÈ´òÊïàÁöÑÈÅãÂãïÊ†°Ê≠£ÊñπÊ≥ï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÊ∑±Â∫¶Â≠∏Áøí‰∏î‰øùÁïôÊãìÊí≤ÁöÑÂΩ±ÂÉèÈÖçÊ∫ñÊû∂ÊßãÔºåÁî®ÊñºÂøÉËÇå T1 Â∞çÊØîÂ∫¶ÊàêÂÉè‰∏≠ÁöÑÈÅãÂãïÊ†°Ê≠£„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÊèêÂá∫ÁöÑÈö±Âºè‰∏ÄËá¥ÊÄßÁ¥ÑÊùüÁ®±ÁÇ∫ BLOCÔºåÂú®ÊüêÁ®ÆÁ®ãÂ∫¶‰∏äÈÄèÈÅéÈõôÂêë‰∏ÄËá¥ÊÄßÁ¥ÑÊùüÂíåÂ±ÄÈÉ®ÊäóÊë∫ÁñäÁ¥ÑÊùüÔºåÂú®ÈÖçÊ∫ñ‰∏≠‰øùÁïôÂΩ±ÂÉèÊãìÊí≤„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Â∞çÊØîÂ∫¶ËÆäÂåñÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•Âä†Ê¨äÂΩ±ÂÉèÁõ∏‰ººÊÄßÂ∫¶ÈáèÔºåÁî®ÊñºÂøÉËÇå T1 Âä†Ê¨äÂΩ±ÂÉèÁöÑÂ§öÊ®°ÂºèÈÖçÊ∫ñ„ÄÇÊ≠§Â§ñÔºå‰∏ÄÂÄãÂçäÁõ£Áù£ÂøÉËÇåÂàÜÂâ≤Á∂≤Ë∑ØÂíå‰∏ÄÂÄãÈõôÂüüÊ≥®ÊÑèÂäõÊ®°ÁµÑË¢´Êï¥ÂêàÂà∞Êû∂Êßã‰∏≠Ôºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÈÖçÊ∫ñÊïàËÉΩ„ÄÇÂ§ßÈáèÁöÑÊØîËºÉÂØ¶È©óÂíåÊ∂àËûçÁ†îÁ©∂Ë≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂíåÈ´òÁ©©ÂÅ•ÊÄß„ÄÇÁµêÊûú‰πüË°®ÊòéÔºåÂ∞àÈñÄÁÇ∫ÊàëÂÄëÁöÑÁ∂≤Ë∑ØË®≠Ë®àÁöÑÊèêÂá∫ÁöÑÂä†Ê¨äÂΩ±ÂÉèÁõ∏‰ººÊÄßÂ∫¶ÈáèÔºåÂ∞çÈÅãÂãïÊ†°Ê≠£ÊïàËÉΩÁöÑÊèêÂçáÊúâÂæàÂ§ßË≤¢ÁçªÔºåËÄåÈõôÂêë‰∏ÄËá¥ÊÄßÁ¥ÑÊùüÁµêÂêàÂ±ÄÈÉ®ÊäóÊë∫ÁñäÁ¥ÑÊùüÔºåÂèØÁ¢∫‰øùÊõ¥ÁêÜÊÉ≥ÁöÑ‰øùÁïôÊãìÊí≤ÈÖçÊ∫ñÂ∞çÊáâ„ÄÇ

##### **Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development**
2410.11550v1 by Tengfei Ma, Xuan Lin, Tianle Li, Chaoyi Li, Long Chen, Peng Zhou, Xibao Cai, Xinyu Yang, Daojian Zeng, Dongsheng Cao, Xiangxiang Zeng

Large Language Models (LLMs) have recently demonstrated remarkable
performance in general tasks across various fields. However, their
effectiveness within specific domains such as drug development remains
challenges. To solve these challenges, we introduce \textbf{Y-Mol}, forming a
well-established LLM paradigm for the flow of drug development. Y-Mol is a
multiscale biomedical knowledge-guided LLM designed to accomplish tasks across
lead compound discovery, pre-clinic, and clinic prediction. By integrating
millions of multiscale biomedical knowledge and using LLaMA2 as the base LLM,
Y-Mol augments the reasoning capability in the biomedical domain by learning
from a corpus of publications, knowledge graphs, and expert-designed synthetic
data. The capability is further enriched with three types of drug-oriented
instructions: description-based prompts from processed publications,
semantic-based prompts for extracting associations from knowledge graphs, and
template-based prompts for understanding expert knowledge from biomedical
tools. Besides, Y-Mol offers a set of LLM paradigms that can autonomously
execute the downstream tasks across the entire process of drug development,
including virtual screening, drug design, pharmacological properties
prediction, and drug-related interaction prediction. Our extensive evaluations
of various biomedical sources demonstrate that Y-Mol significantly outperforms
general-purpose LLMs in discovering lead compounds, predicting molecular
properties, and identifying drug interaction events.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËøëÊúüÂú®ÂêÑÂÄãÈ†òÂüüÁöÑÈÄöÁî®‰ªªÂãô‰∏≠Â±ïÁ§∫Âá∫È°ØËëóÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®ÁâπÂÆöÈ†òÂüüÔºà‰æãÂ¶ÇËó•Áâ©ÈñãÁôºÔºâ‰∏≠ÁöÑÊïàËÉΩ‰ªçÊúâÂæÖÂä†Âº∑„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü **Y-Mol**ÔºåÂΩ¢Êàê‰∫Ü‰∏ÄÂÄãÂÆåÂñÑÁöÑ LLM ÂÖ∏ÁØÑÔºåÁî®ÊñºËó•Áâ©ÈñãÁôºÊµÅÁ®ã„ÄÇY-Mol ÊòØ‰∏ÄÂÄãÂ§öÂ∞∫Â∫¶ÁöÑÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÂºïÂ∞é LLMÔºåÊó®Âú®ÂÆåÊàêÂÖàÂ∞éÂåñÂêàÁâ©ÁôºÁèæ„ÄÅËá®Â∫äÂâçÂíåËá®Â∫äÈ†êÊ∏¨Á≠â‰ªªÂãô„ÄÇÈÄèÈÅéÊï¥ÂêàÊï∏ÁôæËê¨ÂÄãÂ§öÂ∞∫Â∫¶ÁöÑÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÔºå‰∏¶‰ΩøÁî® LLaMA2 ‰ΩúÁÇ∫Âü∫Á§é LLMÔºåY-Mol ÂæûÂá∫ÁâàÁâ©„ÄÅÁü•Ë≠òÂúñË≠úÂíåÂ∞àÂÆ∂Ë®≠Ë®àÁöÑÂêàÊàêË≥áÊñô‰∏≠Â≠∏ÁøíÔºåÂ¢ûÂº∑‰∫ÜÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÂÖ∂ËÉΩÂäõÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅé‰∏âÁ®ÆÈ°ûÂûãÁöÑËó•Áâ©Â∞éÂêëÊåá‰ª§ÂæóÂà∞Ë±êÂØåÔºöÂ∑≤ËôïÁêÜÂá∫ÁâàÁâ©ÁöÑÂü∫ÊñºÊèèËø∞ÁöÑÊèêÁ§∫„ÄÅÁî®ÊñºÂæûÁü•Ë≠òÂúñË≠ú‰∏≠ÊèêÂèñÈóúËÅØÁöÑÂü∫ÊñºË™ûÁæ©ÁöÑÊèêÁ§∫Ôºå‰ª•ÂèäÁî®ÊñºÁêÜËß£ÁîüÁâ©ÈÜ´Â≠∏Â∑•ÂÖ∑‰∏≠Â∞àÂÆ∂Áü•Ë≠òÁöÑÂü∫ÊñºÁØÑÊú¨ÁöÑÊèêÁ§∫„ÄÇÊ≠§Â§ñÔºåY-Mol Êèê‰æõ‰∫Ü‰∏ÄÁµÑ LLM ÂÖ∏ÁØÑÔºåÂèØ‰ª•Âú®Êï¥ÂÄãËó•Áâ©ÈñãÁôºÈÅéÁ®ã‰∏≠Ëá™‰∏ªÂü∑Ë°å‰∏ãÊ∏∏‰ªªÂãôÔºåÂåÖÊã¨ËôõÊì¨ÁØ©ÈÅ∏„ÄÅËó•Áâ©Ë®≠Ë®à„ÄÅËó•ÁêÜÁâπÊÄßÈ†êÊ∏¨ÂíåËó•Áâ©Áõ∏Èóú‰∫§‰∫íÈ†êÊ∏¨„ÄÇÊàëÂÄëÂ∞çÂêÑÁ®ÆÁîüÁâ©ÈÜ´Â≠∏‰æÜÊ∫êÁöÑÂª£Ê≥õË©ï‰º∞Ë°®ÊòéÔºåY-Mol Âú®ÁôºÁèæÂÖàÂ∞éÂåñÂêàÁâ©„ÄÅÈ†êÊ∏¨ÂàÜÂ≠êÁâπÊÄßÂíåË≠òÂà•Ëó•Áâ©‰∫§‰∫í‰∫ã‰ª∂ÊñπÈù¢È°ØËëóÂÑ™ÊñºÈÄöÁî® LLM„ÄÇ

##### **AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data**
2410.11531v1 by Xinjie Zhao, Moritz Blum, Rui Yang, Boming Yang, Luis M√°rquez Carpintero, M√≥nica Pina-Navarro, Tony Wang, Xin Li, Huitao Li, Yanran Fu, Rongrong Wang, Juntao Zhang, Irene Li

Large Language Models~(LLMs) have demonstrated capabilities across various
applications but face challenges such as hallucination, limited reasoning
abilities, and factual inconsistencies, especially when tackling complex,
domain-specific tasks like question answering~(QA). While Knowledge
Graphs~(KGs) have been shown to help mitigate these issues, research on the
integration of LLMs with background KGs remains limited. In particular, user
accessibility and the flexibility of the underlying KG have not been thoroughly
explored. We introduce AGENTiGraph (Adaptive Generative ENgine for Task-based
Interaction and Graphical Representation), a platform for knowledge management
through natural language interaction. It integrates knowledge extraction,
integration, and real-time visualization. AGENTiGraph employs a multi-agent
architecture to dynamically interpret user intents, manage tasks, and integrate
new knowledge, ensuring adaptability to evolving user requirements and data
contexts. Our approach demonstrates superior performance in knowledge graph
interactions, particularly for complex domain-specific tasks. Experimental
results on a dataset of 3,500 test cases show AGENTiGraph significantly
outperforms state-of-the-art zero-shot baselines, achieving 95.12\% accuracy in
task classification and 90.45\% success rate in task execution. User studies
corroborate its effectiveness in real-world scenarios. To showcase versatility,
we extended AGENTiGraph to legislation and healthcare domains, constructing
specialized KGs capable of answering complex queries in legal and medical
contexts.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®ÆÊáâÁî®‰∏≠Â±ïÁèæÂÖ∂ËÉΩÂäõÔºå‰ΩÜ‰ªçÈù¢Ëá®ÂπªË¶∫„ÄÅÊé®ÁêÜËÉΩÂäõÊúâÈôêÂíå‰∫ãÂØ¶‰∏ç‰∏ÄËá¥Á≠âÊåëÊà∞ÔºåÂ∞§ÂÖ∂ÊòØÂú®ËôïÁêÜË§áÈõúÁöÑÁâπÂÆöÈ†òÂüü‰ªªÂãôÔºå‰æãÂ¶ÇÂïèÁ≠î (QA) ÊôÇ„ÄÇÈõñÁÑ∂Áü•Ë≠òÂúñË≠ú (KG) Â∑≤Ë¢´Ë≠âÊòéÊúâÂä©ÊñºÁ∑©Ëß£ÈÄô‰∫õÂïèÈ°åÔºå‰ΩÜ LLM ËàáËÉåÊôØ KG Êï¥ÂêàÁöÑÁ†îÁ©∂‰ªçÁÑ∂ÊúâÈôê„ÄÇÁâπÂà•ÊòØÔºå‰ΩøÁî®ËÄÖÁöÑÂèØÂèäÊÄßÂíåÂ∫ïÂ±§ KG ÁöÑÈùàÊ¥ªÊÄßÂ∞öÊú™ÂæóÂà∞ÂæπÂ∫ïÊé¢Ë®é„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü AGENTiGraphÔºàÁî®Êñº‰ªªÂãôÂûã‰∫íÂãïÂíåÂúñÂΩ¢Ë°®Á§∫ÁöÑËá™ÈÅ©ÊáâÁîüÊàêÂºïÊìéÔºâÔºå‰∏ÄÂÄãÈÄèÈÅéËá™ÁÑ∂Ë™ûË®Ä‰∫íÂãïÈÄ≤Ë°åÁü•Ë≠òÁÆ°ÁêÜÁöÑÂπ≥Âè∞„ÄÇÂÆÉÊï¥Âêà‰∫ÜÁü•Ë≠òËêÉÂèñ„ÄÅÊï¥ÂêàÂíåÂç≥ÊôÇË¶ñË¶∫Âåñ„ÄÇAGENTiGraph Êé°Áî®Â§ö‰ª£ÁêÜÊû∂ÊßãÔºå‰ª•ÂãïÊÖãËß£ËÆÄ‰ΩøÁî®ËÄÖÁöÑÊÑèÂúñ„ÄÅÁÆ°ÁêÜ‰ªªÂãô‰∏¶Êï¥ÂêàÊñ∞Áü•Ë≠òÔºåÁ¢∫‰øùÈÅ©Êáâ‰∏çÊñ∑ËÆäÂåñÁöÑ‰ΩøÁî®ËÄÖÈúÄÊ±ÇÂíåË≥áÊñôËÑàÁµ°„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Áü•Ë≠òÂúñË≠ú‰∫íÂãï‰∏≠Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂ∞çÊñºË§áÈõúÁöÑÁâπÂÆöÈ†òÂüü‰ªªÂãô„ÄÇÂú® 3,500 ÂÄãÊ∏¨Ë©¶Ê°à‰æãÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåAGENTiGraph ÊòéÈ°ØÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÈõ∂Ê¨°Â≠∏ÁøíÂü∫Ê∫ñÔºåÂú®‰ªªÂãôÂàÜÈ°û‰∏≠ÈÅîÂà∞ 95.12% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂú®‰ªªÂãôÂü∑Ë°å‰∏≠ÈÅîÂà∞ 90.45% ÁöÑÊàêÂäüÁéá„ÄÇ‰ΩøÁî®ËÄÖÁ†îÁ©∂Ë≠âÂØ¶‰∫ÜÂÆÉÂú®ÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÁÇ∫‰∫ÜÂ±ïÁ§∫ÂÖ∂Â§öÂäüËÉΩÊÄßÔºåÊàëÂÄëÂ∞á AGENTiGraph Âª∂‰º∏Âà∞Ê≥ïÂæãÂíåÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÂª∫Êßã‰∫ÜËÉΩÂ§†ÂõûÁ≠îÊ≥ïÂæãÂíåÈÜ´ÁôÇËÑàÁµ°‰∏≠Ë§áÈõúÊü•Ë©¢ÁöÑÂ∞àÊ•≠Áü•Ë≠òÂúñË≠ú„ÄÇ

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

ÊëòË¶ÅÔºöÈ´òÈÄöÈáèÊäÄË°ìÁöÑÈÄ≤Ê≠•Â∞éËá¥ÂæûÂÇ≥Áµ±ÁöÑÂÅáË®≠È©ÖÂãïÊñπÊ≥ïËΩâËÆäÁÇ∫Ë≥áÊñôÈ©ÖÂãïÁöÑÊñπÊ≥ï„ÄÇÂ§öÁµÑÂ≠∏ÊòØÊåáÊï¥ÂêàÂàÜÊûê‰æÜËá™Â§öÂÄã„ÄåÁµÑÂ≠∏„ÄçÁöÑË≥áÊñôÔºå‰æãÂ¶ÇÂü∫Âõ†ÁµÑÂ≠∏„ÄÅËõãÁôΩË≥™ÁµÑÂ≠∏„ÄÅËΩâÈåÑÁµÑÂ≠∏„ÄÅ‰ª£Ë¨ùÁµÑÂ≠∏ÂíåÂæÆÁîüÁâ©ÁµÑÂ≠∏„ÄÇÊ≠§ÊñπÊ≥ïÈÄèÈÅéÊì∑ÂèñÁîüÁâ©Ë≥áË®äÁöÑ‰∏çÂêåÂ±§Èù¢ÔºåËÉΩÂÖ®Èù¢‰∫ÜËß£ÁîüÁâ©Á≥ªÁµ±„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÊÑà‰æÜÊÑàÂ∏∏Ë¢´Áî®ÊñºÊï¥ÂêàÂ§öÁµÑÂ≠∏Ë≥áÊñôÔºåÊèê‰æõÂàÜÂ≠ê‰∫§‰∫í‰ΩúÁî®ÁöÑÊ¥ûÂØüÂäõÔºå‰∏¶Âä†Âº∑Â∞çË§áÈõúÁñæÁóÖÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂÖ∑ÊúâË®±Â§öÁõ∏‰∫íÈÄ£Êé•ÁöÑÂ±§Á¥öÂíåÈùûÁ∑öÊÄßÈóú‰øÇÔºåÈÄöÂ∏∏ÊúÉÂÉèÈªëÁõíÂ≠ê‰∏ÄÊ®£ÈÅã‰ΩúÔºåÁº∫‰πèÊ±∫Á≠ñÈÅéÁ®ãÁöÑÈÄèÊòéÂ∫¶„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÊ≠§ÊåëÊà∞ÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (xAI) ÊñπÊ≥ïÂ∞çÊñºÂª∫Á´ãÈÄèÊòéÊ®°ÂûãËá≥ÈóúÈáçË¶ÅÔºåËÆìËá®Â∫äÈÜ´ÁîüÂèØ‰ª•Êõ¥ÊúâÊïàÂú∞Ëß£ÈáãÂíåËôïÁêÜË§áÈõúË≥áÊñô„ÄÇÊ≠§Ë©ïË´ñÊé¢Ë®é xAI Â¶Ç‰ΩïËÉΩÊîπÂñÑÂ§öÁµÑÂ≠∏Á†îÁ©∂‰∏≠Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºåÂº∑Ë™øÂÖ∂Êèê‰æõËá®Â∫äÈÜ´ÁîüÊòéÁ¢∫Ë¶ãËß£ÁöÑÊΩõÂäõÔºåÈÄ≤ËÄå‰øÉÈÄ≤Ê≠§È°ûÊ®°ÂûãÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊúâÊïàÊáâÁî®„ÄÇ

##### **HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications**
2410.11239v1 by Weijie Xu, Jay Desai, Fanyou Wu, Josef Valvoda, Srinivasan H. Sengamedu

Recent LLM (Large Language Models) advancements benefit many fields such as
education and finance, but HR has hundreds of repetitive processes, such as
access requests, medical claim filing and time-off submissions, which are
unaddressed. We relate these tasks to the LLM agent, which has addressed tasks
such as writing assisting and customer support. We present HR-Agent, an
efficient, confidential, and HR-specific LLM-based task-oriented dialogue
system tailored for automating repetitive HR processes such as medical claims
and access requests. Since conversation data is not sent to an LLM during
inference, it preserves confidentiality required in HR-related tasks.

ÊëòË¶ÅÔºöËøëÊúüÁöÑ LLMÔºàÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºâËøõÊ≠•ÊÉ†Âèä‰∫ÜËÆ∏Â§öÈ¢ÜÂüüÔºå‰æãÂ¶ÇÊïôËÇ≤ÂíåÈáëËûçÔºå‰ΩÜ‰∫∫ÂäõËµÑÊ∫êÊúâÊï∞Áôæ‰∏™ÈáçÂ§çÊÄßÁöÑÊµÅÁ®ãÔºå‰æãÂ¶ÇÂ≠òÂèñË¶ÅÊ±Ç„ÄÅÂåªÁñóÁ¥¢ËµîÁî≥Êä•Âíå‰ºëÂÅáÊèê‰∫§ÔºåËøô‰∫õÈóÆÈ¢òÂ∞öÊú™Ëß£ÂÜ≥„ÄÇÊàë‰ª¨Â∞ÜËøô‰∫õ‰ªªÂä°‰∏é LLM ‰ª£ÁêÜËÅîÁ≥ªËµ∑Êù•ÔºåËØ•‰ª£ÁêÜÂ∑≤Ëß£ÂÜ≥ËØ∏Â¶ÇÂÜô‰ΩúËæÖÂä©ÂíåÂÆ¢Êà∑ÊîØÊåÅ‰πãÁ±ªÁöÑ‰ªªÂä°„ÄÇÊàë‰ª¨ÊèêÂá∫ HR-AgentÔºåËøôÊòØ‰∏Ä‰∏™È´òÊïà„ÄÅ‰øùÂØÜ‰∏îÈíàÂØπ‰∫∫ÂäõËµÑÊ∫êÁöÑÁâπÂÆö LLM ‰∏∫Âü∫Á°ÄÁöÑ‰ªªÂä°ÂØºÂêëÂØπËØùÁ≥ªÁªüÔºå‰∏ì‰∏∫Ëá™Âä®ÂåñÈáçÂ§çÊÄß‰∫∫ÂäõËµÑÊ∫êÊµÅÁ®ãÔºà‰æãÂ¶ÇÂåªÁñóÁ¥¢ËµîÂíåÂ≠òÂèñËØ∑Ê±ÇÔºâËÄåËÆæËÆ°„ÄÇÁî±‰∫éÂØπËØùÊï∞ÊçÆÂú®Êé®ÁêÜËøáÁ®ã‰∏≠‰∏ç‰ºöÂèëÈÄÅÂà∞ LLMÔºåÂõ†Ê≠§ÂÆÉ‰øùÁïô‰∫Ü‰∫∫ÂäõËµÑÊ∫êÁõ∏ÂÖ≥‰ªªÂä°ÊâÄÈúÄÁöÑÊú∫ÂØÜÊÄß„ÄÇ

##### **SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning**
2410.11200v1 by Rikuto Kotoge, Zheng Chen, Tasuku Kimura, Yasuko Matsubara, Takufumi Yanagisawa, Haruhiko Kishima, Yasushi Sakurai

While end-to-end multi-channel electroencephalography (EEG) learning
approaches have shown significant promise, their applicability is often
constrained in neurological diagnostics, such as intracranial EEG resources.
When provided with a single-channel EEG, how can we learn representations that
are robust to multi-channels and scalable across varied tasks, such as seizure
prediction? In this paper, we present SplitSEE, a structurally splittable
framework designed for effective temporal-frequency representation learning in
single-channel EEG. The key concept of SplitSEE is a self-supervised framework
incorporating a deep clustering task. Given an EEG, we argue that the time and
frequency domains are two distinct perspectives, and hence, learned
representations should share the same cluster assignment. To this end, we first
propose two domain-specific modules that independently learn domain-specific
representation and address the temporal-frequency tradeoff issue in
conventional spectrogram-based methods. Then, we introduce a novel clustering
loss to measure the information similarity. This encourages representations
from both domains to coherently describe the same input by assigning them a
consistent cluster. SplitSEE leverages a pre-training-to-fine-tuning framework
within a splittable architecture and has following properties: (a)
Effectiveness: it learns representations solely from single-channel EEG but has
even outperformed multi-channel baselines. (b) Robustness: it shows the
capacity to adapt across different channels with low performance variance.
Superior performance is also achieved with our collected clinical dataset. (c)
Scalability: With just one fine-tuning epoch, SplitSEE achieves high and stable
performance using partial model layers.

ÊëòË¶ÅÔºö<paragraph>ÈõñÁÑ∂Á´ØÂà∞Á´ØÂ§öÈÄöÈÅìËÖ¶ÈõªÂúñ (EEG) Â≠∏ÁøíÊñπÊ≥ïÂ∑≤Â±ïÁèæÂá∫È°ØËëóÁöÑÂ∏åÊúõÔºå‰ΩÜÂÖ∂ÈÅ©Áî®ÊÄßÂú®Á•ûÁ∂ìË®∫Êñ∑Ôºå‰æãÂ¶ÇÈ°±ÂÖß EEG Ë≥áÊ∫ê‰∏≠ÔºåÈÄöÂ∏∏ÂèóÂà∞ÈôêÂà∂„ÄÇÁï∂Êèê‰æõÂñÆÈÄöÈÅì EEG ÊôÇÔºåÊàëÂÄëÂ¶Ç‰ΩïÂ≠∏ÁøíÂ∞çÂ§öÈÄöÈÅìÁ©©ÂÅ•‰∏îÂèØÊì¥Â±ïÂà∞ÂêÑÁ®Æ‰ªªÂãôÔºà‰æãÂ¶ÇÁô≤ÁôáÈ†êÊ∏¨ÔºâÁöÑË°®ÂæµÔºüÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ SplitSEEÔºå‰∏ÄÂÄãÁµêÊßãÂèØÂàÜÂâ≤ÁöÑÊ°ÜÊû∂ÔºåÂ∞àÁÇ∫Âú®ÂñÆÈÄöÈÅì EEG ‰∏≠ÈÄ≤Ë°åÊúâÊïàÁöÑÊôÇÈ†ªË°®ÂæµÂ≠∏ÁøíËÄåË®≠Ë®à„ÄÇSplitSEE ÁöÑÈóúÈçµÊ¶ÇÂøµÊòØ‰∏ÄÂÄãËá™Áõ£Áù£ÁöÑÊ°ÜÊû∂ÔºåÁµêÂêà‰∫Ü‰∏ÄÂÄãÊ∑±Â∫¶ËÅöÈ°û‰ªªÂãô„ÄÇÁµ¶ÂÆö‰∏ÄÂÄã EEGÔºåÊàëÂÄëË™çÁÇ∫ÊôÇÈñìÂíåÈ†ªÁéáÂüüÊòØÂÖ©ÂÄã‰∏çÂêåÁöÑËßÄÈªûÔºåÂõ†Ê≠§ÔºåÂ≠∏ÁøíÂà∞ÁöÑË°®ÂæµÊáâË©≤ÂÖ±‰∫´Áõ∏ÂêåÁöÑÂè¢ÈõÜÂàÜÈÖç„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫ÂÖ©ÂÄãÁâπÂÆöÊñºÈ†òÂüüÁöÑÊ®°ÁµÑÔºåÂÆÉÂÄëÁç®Á´ãÂ≠∏ÁøíÁâπÂÆöÊñºÈ†òÂüüÁöÑË°®ÂæµÔºå‰∏¶Ëß£Ê±∫ÂÇ≥Áµ±Âü∫ÊñºÊôÇË≠úÂúñÁöÑÊñπÊ≥ï‰∏≠ÁöÑÊôÇÈ†ªÊ¨äË°°ÂïèÈ°å„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÊñ∞ÁöÑËÅöÈ°ûÊêçÂ§±‰æÜË°°ÈáèË≥áË®äÁõ∏‰ººÊÄß„ÄÇÈÄôÈºìÂãµ‰æÜËá™ÂÖ©ÂÄãÈ†òÂüüÁöÑË°®ÂæµÈÄöÈÅéÂ∞áÂÆÉÂÄëÂàÜÈÖçÂà∞‰∏ÄËá¥ÁöÑÂè¢ÈõÜ‰æÜ‰∏ÄËá¥Âú∞ÊèèËø∞Áõ∏ÂêåÁöÑËº∏ÂÖ•„ÄÇSplitSEE Âú®ÂèØÂàÜÂâ≤ÁöÑÊû∂Êßã‰∏≠Âà©Áî®È†êË®ìÁ∑¥Âà∞ÂæÆË™øÁöÑÊ°ÜÊû∂Ôºå‰∏¶ÂÖ∑Êúâ‰ª•‰∏ãÁâπÊÄßÔºö(a) ÊúâÊïàÊÄßÔºöÂÆÉÂÉÖÂæûÂñÆÈÄöÈÅì EEG Â≠∏ÁøíË°®ÂæµÔºå‰ΩÜÁîöËá≥ÂÑ™ÊñºÂ§öÈÄöÈÅìÂü∫Ê∫ñ„ÄÇ (b) Á©©ÂÅ•ÊÄßÔºöÂÆÉÈ°ØÁ§∫Âá∫‰ª•‰ΩéÊïàËÉΩËÆäÁï∞ÈÅ©Êáâ‰∏çÂêåÈÄöÈÅìÁöÑËÉΩÂäõ„ÄÇ‰ΩøÁî®ÊàëÂÄëÊî∂ÈõÜÁöÑËá®Â∫äË≥áÊñôÈõÜ‰πüÁç≤Âæó‰∫ÜÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇ (c) ÂèØÊì¥Â±ïÊÄßÔºöÂè™‰ΩøÁî®‰∏ÄÂÄãÂæÆË™øÊôÇÊúüÔºåSplitSEE ‰ΩøÁî®ÈÉ®ÂàÜÊ®°ÂûãÂ±§Âç≥ÂèØÈÅîÂà∞È´ò‰∏îÁ©©ÂÆöÁöÑÊïàËÉΩ„ÄÇ</paragraph>

##### **EchoApex: A General-Purpose Vision Foundation Model for Echocardiography**
2410.11092v2 by Abdoul Aziz Amadou, Yue Zhang, Sebastien Piat, Paul Klein, Ingo Schmuecking, Tiziano Passerini, Puneet Sharma

Quantitative evaluation of echocardiography is essential for precise
assessment of cardiac condition, monitoring disease progression, and guiding
treatment decisions. The diverse nature of echo images, including variations in
probe types, manufacturers, and pathologies, poses challenges for developing
artificial intelligent models that can generalize across different clinical
practice. We introduce EchoApex, the first general-purpose vision foundation
model echocardiography with applications on a variety of clinical practice.
Leveraging self-supervised learning, EchoApex is pretrained on over 20 million
echo images from 11 clinical centres. By incorporating task-specific decoders
and adapter modules, we demonstrate the effectiveness of EchoApex on 4
different kind of clinical applications with 28 sub-tasks, including view
classification, interactive structure segmentation, left ventricle hypertrophy
detection and automated ejection fraction estimation from view sequences.
Compared to state-of-the-art task-specific models, EchoApex attains improved
performance with a unified image encoding architecture, demonstrating the
benefits of model pretraining at scale with in-domain data. Furthermore,
EchoApex illustrates the potential for developing a general-purpose vision
foundation model tailored specifically for echocardiography, capable of
addressing a diverse range of clinical applications with high efficiency and
efficacy.

ÊëòË¶ÅÔºöÂÆöÈáèË©ï‰º∞Ë∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÂ∞çÊñºÁ≤æÊ∫ñË©ï‰º∞ÂøÉËáüÁãÄÊ≥Å„ÄÅÁõ£ÊéßÁñæÁóÖÈÄ≤Á®ãÂíåÊåáÂ∞éÊ≤ªÁôÇÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑÂ§öÊ®£ÊÄßÔºåÂåÖÊã¨Êé¢È†≠È°ûÂûã„ÄÅË£ΩÈÄ†ÂïÜÂíåÁóÖÁêÜÁöÑËÆäÂåñÔºåÂ∞çÈñãÁôºËÉΩÂ§†Âú®‰∏çÂêåËá®Â∫äÂØ¶Âãô‰∏≠ÈÄöÁî®ÁöÑ AI Ê®°ÂûãÊßãÊàê‰∫ÜÊåëÊà∞„ÄÇÊàëÂÄë‰ªãÁ¥π‰∫Ü EchoApexÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÈÄöÁî®Ë¶ñË¶∫Âü∫Á§éÊ®°ÂûãË∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÔºåÂèØÊáâÁî®ÊñºÂêÑÁ®ÆËá®Â∫äÂØ¶Âãô„ÄÇÂà©Áî®Ëá™ÊàëÁõ£Áù£Â≠∏ÁøíÔºåEchoApex Âú®‰æÜËá™ 11 ÂÄãËá®Â∫ä‰∏≠ÂøÉÁöÑË∂ÖÈÅé 2000 Ëê¨ÂºµË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉè‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥„ÄÇÈÄèÈÅéÊï¥ÂêàÁâπÂÆöÊñº‰ªªÂãôÁöÑËß£Á¢ºÂô®ÂíåÈÅ©ÈÖçÂô®Ê®°ÁµÑÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü EchoApex Âú® 4 Á®Æ‰∏çÂêåÈ°ûÂûãÁöÑËá®Â∫äÊáâÁî®‰∏≠ÔºåÂåÖÂê´ 28 ÂÄãÂ≠ê‰ªªÂãôÁöÑÊúâÊïàÊÄßÔºåÂåÖÊã¨ÂΩ±ÂÉèÂàÜÈ°û„ÄÅ‰∫íÂãïÁµêÊßãÂàÜÂâ≤„ÄÅÂ∑¶ÂøÉÂÆ§ËÇ•ÂéöÂÅµÊ∏¨ÂíåÂæûÂΩ±ÂÉèÂ∫èÂàó‰∏≠Ëá™Âãï‰º∞Ë®àÂ∞ÑË°ÄÂàÜÊï∏„ÄÇËàáÊúÄÂÖàÈÄ≤ÁöÑÁâπÂÆöÊñº‰ªªÂãôÁöÑÊ®°ÂûãÁõ∏ÊØîÔºåEchoApex ‰ª•Áµ±‰∏ÄÁöÑÂΩ±ÂÉèÁ∑®Á¢ºÊû∂ÊßãÁç≤Âæó‰∫ÜÊõ¥Â•ΩÁöÑÊïàËÉΩÔºåË≠âÊòé‰∫Ü‰ΩøÁî®È†òÂüüÂÖßË≥áÊñôÈÄ≤Ë°åÂ§ßË¶èÊ®°Ê®°ÂûãÈ†êË®ìÁ∑¥ÁöÑÂ•ΩËôï„ÄÇÊ≠§Â§ñÔºåEchoApex Ë™™Êòé‰∫ÜÈñãÁôºÂ∞àÈñÄÈáùÂ∞çË∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñÁöÑÈÄöÁî®Ë¶ñË¶∫Âü∫Á§éÊ®°ÂûãÁöÑÊΩõÂäõÔºåËÉΩÂ§†‰ª•È´òÊïàÁéáÂíåÊïàËÉΩËß£Ê±∫ÂêÑÁ®ÆËá®Â∫äÊáâÁî®„ÄÇ

##### **Parsing altered brain connectivity in neurodevelopmental disorders by integrating graph-based normative modeling and deep generative networks**
2410.11064v1 by Rui Sherry Shen, Yusuf Osmanlƒ±oƒülu, Drew Parker, Darien Aunapu, Benjamin E. Yerys, Birkan Tun√ß, Ragini Verma

Many neurodevelopmental disorders can be understood as divergent patterns of
neural interactions during brain development. Advances in neuroimaging have
illuminated these patterns by modeling the brain as a network structure using
diffution MRI tractography. However, characterizing and quantifying individual
heterogeneity in neurodevelopmental disorders within these highly complex brain
networks remains a significant challenge. In this paper, we present for the
first time, a framework that integrates deep generative models with graph-based
normative modeling to characterize brain network development in the
neurotypical population, which can then be used to quantify the
individual-level neurodivergence associated with disorders. Our deep generative
model incorporates bio-inspired wiring constraints to effectively capture the
developmental trajectories of neurotypical brain networks. Neurodivergence is
quantified by comparing individuals to this neurotypical trajectory, enabling
the creation of region-wise divergence maps that reveal latent developmental
differences at each brain regions, along with overall neurodivergence scores
based on predicted brain age gaps. We demonstrate the clinical utility of this
framework by applying it to a large sample of children with autism spectrum
disorders, showing that the individualized region-wise maps help parse the
heterogeneity in autism, and the neurodivergence scores correlate with clinical
assessments. Together, we provide powerful tools for quantifying
neurodevelopmental divergence in brain networks, paying the way for developing
imaging markers that will support disorder stratification, monitor progression,
and evaluate therapeutic effectiveness.

ÊëòË¶ÅÔºöË®±Â§öÁ•ûÁ∂ìÁôºËÇ≤ÈöúÁ§ôÂèØ‰ª•ÁêÜËß£ÁÇ∫Â§ßËÖ¶ÁôºËÇ≤ÈÅéÁ®ã‰∏≠Á•ûÁ∂ì‰∫§‰∫í‰ΩúÁî®Ê®°ÂºèÁöÑÂ∑ÆÁï∞„ÄÇÁ•ûÁ∂ìÂΩ±ÂÉèÂ≠∏ÁöÑÈÄ≤Ê≠•ÈÄöÈÅé‰ΩøÁî®Êì¥Êï£Á£ÅÊåØÈÄ†ÂΩ±Á∫ñÁ∂≠ÊùüÊîùÂΩ±Ë°ìÂ∞áÂ§ßËÖ¶Âª∫Ê®°ÁÇ∫Á∂≤Ë∑ØÁµêÊßãÔºåÈó°Êòé‰∫ÜÈÄô‰∫õÊ®°Âºè„ÄÇÁÑ∂ËÄåÔºåÂú®ÈÄô‰∫õÈ´òÂ∫¶Ë§áÈõúÁöÑÂ§ßËÖ¶Á∂≤Ë∑Ø‰∏≠ÔºåÊèèËø∞ÂíåÈáèÂåñÁ•ûÁ∂ìÁôºËÇ≤ÈöúÁ§ôÁöÑÂÄãÈ´îÁï∞Ë≥™ÊÄß‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÊ¨°ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊ°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂Â∞áÊ∑±Â∫¶ÁîüÊàêÊ®°ÂûãËàáÂü∫ÊñºÂúñÂΩ¢ÁöÑË¶èÁØÑÊ®°ÂûãÁõ∏ÁµêÂêàÔºå‰ª•ÊèèËø∞Á•ûÁ∂ìÂÖ∏Âûã‰∫∫Áæ§‰∏≠ÁöÑÂ§ßËÖ¶Á∂≤Ë∑ØÁôºÂ±ïÔºåÁÑ∂ÂæåÂèØ‰ª•Áî®ÊñºÈáèÂåñËàáÈöúÁ§ôÁõ∏ÈóúÁöÑÂÄãÈ´îÁ•ûÁ∂ìÂàÜÊ≠ß„ÄÇÊàëÂÄëÁöÑÊ∑±Â∫¶ÁîüÊàêÊ®°ÂûãÁµêÂêà‰∫ÜÂèóÁîüÁâ©ÂïüÁôºÁöÑÊé•Á∑öÁ¥ÑÊùüÔºå‰ª•ÊúâÊïàÊçïÊçâÁ•ûÁ∂ìÂÖ∏ÂûãÂ§ßËÖ¶Á∂≤Ë∑ØÁöÑÁôºÂ±ïËªåË∑°„ÄÇÁ•ûÁ∂ìÂàÜÊ≠ßÈÄöÈÅéÂ∞áÂÄãÈ´îËàáÈÄôÁ®ÆÁ•ûÁ∂ìÂÖ∏ÂûãËªåË∑°ÈÄ≤Ë°åÊØîËºÉ‰æÜÈáèÂåñÔºåÂæûËÄåËÉΩÂ§†ÂâµÂª∫ÂçÄÂüüÂàÜÊ≠ßÂúñÔºåÊè≠Á§∫ÊØèÂÄãÂ§ßËÖ¶ÂçÄÂüüÁöÑÊΩõÂú®ÁôºËÇ≤Â∑ÆÁï∞Ôºå‰ª•ÂèäÂü∫ÊñºÈ†êÊ∏¨ËÖ¶ÈΩ°Â∑ÆË∑ùÁöÑÊï¥È´îÁ•ûÁ∂ìÂàÜÊ≠ßÂæóÂàÜ„ÄÇÊàëÂÄëÈÄöÈÅéÂ∞áÊ≠§Ê°ÜÊû∂ÊáâÁî®ÊñºÂ§ßÈáèËá™ÈñâÁóáË≠úÁ≥ªÈöúÁ§ôÂÖíÁ´•Ê®£Êú¨ÔºåÂ±ïÁ§∫‰∫ÜÈÄôÁ®ÆËá®Â∫äÊïàÁî®ÔºåË°®ÊòéÂÄãÊÄßÂåñÁöÑÂçÄÂüüÂàÜÊ≠ßÂúñÊúâÂä©ÊñºËß£ÊûêËá™ÈñâÁóáÁöÑÁï∞Ë≥™ÊÄßÔºå‰∏¶‰∏îÁ•ûÁ∂ìÂàÜÊ≠ßÂæóÂàÜËàáËá®Â∫äË©ï‰º∞Áõ∏Èóú„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂº∑Â§ßÁöÑÂ∑•ÂÖ∑‰æÜÈáèÂåñÂ§ßËÖ¶Á∂≤Ë∑Ø‰∏≠ÁöÑÁ•ûÁ∂ìÁôºËÇ≤ÂàÜÊ≠ßÔºåÁÇ∫ÈñãÁôºÊàêÂÉèÊ®ôË®òÈã™Âπ≥‰∫ÜÈÅìË∑ØÔºåÈÄô‰∫õÊ®ôË®òÂ∞áÊîØÊåÅÈöúÁ§ôÂàÜÂ±§„ÄÅÁõ£ÊéßÈÄ≤Â±ïÂíåË©ï‰º∞Ê≤ªÁôÇÊïàÊûú„ÄÇ

##### **Deep Learning Based XIoT Malware Analysis: A Comprehensive Survey, Taxonomy, and Research Challenges**
2410.13894v1 by Rami Darwish, Mahmoud Abdelsalam, Sajad Khorsandroo

The Internet of Things (IoT) is one of the fastest-growing computing
industries. By the end of 2027, more than 29 billion devices are expected to be
connected. These smart devices can communicate with each other with and without
human intervention. This rapid growth has led to the emergence of new types of
malware. However, traditional malware detection methods, such as
signature-based and heuristic-based techniques, are becoming increasingly
ineffective against these new types of malware. Therefore, it has become
indispensable to find practical solutions for detecting IoT malware. Machine
Learning (ML) and Deep Learning (DL) approaches have proven effective in
dealing with these new IoT malware variants, exhibiting high detection rates.
In this paper, we bridge the gap in research between the IoT malware analysis
and the wide adoption of deep learning in tackling the problems in this domain.
As such, we provide a comprehensive review on deep learning based malware
analysis across various categories of the IoT domain (i.e. Extended Internet of
Things (XIoT)), including Industrial IoT (IIoT), Internet of Medical Things
(IoMT), Internet of Vehicles (IoV), and Internet of Battlefield Things (IoBT).

ÊëòË¶ÅÔºöÁâ©ËÅîÁΩë (IoT) ÊòØÊàêÈïøÊúÄÂø´ÈÄüÁöÑËøêÁÆó‰∫ß‰∏ö‰πã‰∏Ä„ÄÇÂú® 2027 Âπ¥Â∫ï‰πãÂâçÔºåÈ¢ÑËÆ°Â∞ÜÊúâË∂ÖËøá 290 ‰∫øÂè∞Ë£ÖÁΩÆËøûÊé•„ÄÇËøô‰∫õÊô∫ÊÖßË£ÖÁΩÆÂèØ‰ª•ÂΩºÊ≠§Ê≤üÈÄöÔºå‰∏çËÆ∫ÊòØÂê¶Êúâ‰∫∫‰∏∫‰ªãÂÖ•„ÄÇËøôÁßçÂø´ÈÄüÁöÑÊàêÈïøÂØºËá¥Âá∫Áé∞Êñ∞ÂûãÊÄÅÁöÑÊÅ∂ÊÑèËΩØ‰Ωì„ÄÇÁÑ∂ËÄåÔºå‰º†ÁªüÁöÑÊÅ∂ÊÑèËΩØ‰Ωì‰æ¶ÊµãÊñπÊ≥ïÔºå‰æãÂ¶ÇÂü∫‰∫éÁâπÂæÅÁ†ÅÂíåÂü∫‰∫éÂêØÂèëÊ≥ïÁöÑÊäÄÊúØÔºåÂØπ‰∫éËøô‰∫õÊñ∞ÂûãÊÄÅÁöÑÊÅ∂ÊÑèËΩØ‰ΩìÂèòÂæóË∂äÊù•Ë∂äÊó†Êïà„ÄÇÂõ†Ê≠§ÔºåÂØªÊâæ‰æ¶Êµã IoT ÊÅ∂ÊÑèËΩØ‰ΩìÁöÑÂÆûÁî®Ëß£ÂÜ≥ÊñπÊ°àÂ∑≤ÂèòÂæó‰∏çÂèØÊàñÁº∫„ÄÇÊú∫Âô®Â≠¶‰π† (ML) ÂíåÊ∑±Â∫¶Â≠¶‰π† (DL) ÊñπÊ≥ïÂ∑≤Ë¢´ËØÅÊòéÂú®Â§ÑÁêÜËøô‰∫õÊñ∞ÂûãÊÄÅ IoT ÊÅ∂ÊÑèËΩØ‰ΩìÂèòÁßçÊñπÈù¢ÂæàÊúâÊïàÔºåÂ±ïÁé∞Âá∫ÂæàÈ´òÁöÑ‰æ¶ÊµãÁéá„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Âº•Âêà‰∫Ü IoT ÊÅ∂ÊÑèËΩØ‰ΩìÂàÜÊûê‰∏éÂπøÊ≥õÈááÁî®Ê∑±Â∫¶Â≠¶‰π†Êù•Ëß£ÂÜ≥Ê≠§È¢ÜÂüüÈóÆÈ¢ò‰πãÈó¥ÁöÑÁ†îÁ©∂Â∑ÆË∑ù„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÈíàÂØπÂêÑÁßçÁ±ªÂà´ÁöÑ IoT È¢ÜÂüüÔºàÂç≥Êâ©Â±ïÁâ©ËÅîÁΩë (XIoT)ÔºâÔºåÂåÖÊã¨Â∑•‰∏öÁâ©ËÅîÁΩë (IIoT)„ÄÅÂåªÁñóÁâ©ËÅîÁΩë (IoMT)„ÄÅËΩ¶ËÅîÁΩë (IoV) ÂíåÊàòÂú∫Áâ©ËÅîÁΩë (IoBT) Êèê‰æõ‰∏Ä‰ªΩÂü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÊÅ∂ÊÑèËΩØ‰ΩìÂàÜÊûêÁöÑÁªºÂêàËØÑËÆ∫„ÄÇ

##### **Thinking LLMs: General Instruction Following with Thought Generation**
2410.10630v1 by Tianhao Wu, Janice Lan, Weizhe Yuan, Jiantao Jiao, Jason Weston, Sainbayar Sukhbaatar

LLMs are typically trained to answer user questions or follow instructions
similarly to how human experts respond. However, in the standard alignment
framework they lack the basic ability of explicit thinking before answering.
Thinking is important for complex questions that require reasoning and planning
-- but can be applied to any task. We propose a training method for equipping
existing LLMs with such thinking abilities for general instruction following
without use of additional human data. We achieve this by an iterative search
and optimization procedure that explores the space of possible thought
generations, allowing the model to learn how to think without direct
supervision. For each instruction, the thought candidates are scored using a
judge model to evaluate their responses only, and then optimized via preference
optimization. We show that this procedure leads to superior performance on
AlpacaEval and Arena-Hard, and shows gains from thinking on non-reasoning
categories such as marketing, health and general knowledge, in addition to more
traditional reasoning & problem-solving tasks.

ÊëòË¶ÅÔºöLLM ÈÄöÂ∏∏Ë¢´ËÆ≠ÁªÉÊàêÂõûÁ≠îÁî®Êà∑ÁöÑÊèêÈóÆÊàñÈÅµÂæ™Êåá‰ª§ÔºåÁ±ª‰ºº‰∫é‰∫∫Á±ª‰∏ìÂÆ∂Â¶Ç‰ΩïÂõûÂ∫î„ÄÇÁÑ∂ËÄåÔºåÂú®Ê†áÂáÜÂØπÈΩêÊ°ÜÊû∂‰∏≠ÔºåÂÆÉ‰ª¨Áº∫‰πèÂú®ÂõûÁ≠î‰πãÂâçËøõË°åÊòéÁ°ÆÊÄùËÄÉÁöÑÂü∫Êú¨ËÉΩÂäõ„ÄÇÊÄùËÄÉÂØπ‰∫éÈúÄË¶ÅÊé®ÁêÜÂíåËßÑÂàíÁöÑÂ§çÊùÇÈóÆÈ¢òÈùûÂ∏∏ÈáçË¶ÅÔºå‰ΩÜÂÆÉÂèØ‰ª•Â∫îÁî®‰∫é‰ªª‰Ωï‰ªªÂä°„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçËÆ≠ÁªÉÊñπÊ≥ïÔºå‰∏∫Áé∞ÊúâÁöÑ LLM Êèê‰æõËøôÁßçÊÄùËÄÉËÉΩÂäõÔºå‰ª•‰æøÂú®Ê≤°Êúâ‰ΩøÁî®È¢ùÂ§ñ‰∫∫Á±ªÊï∞ÊçÆÁöÑÊÉÖÂÜµ‰∏ãÈÅµÂæ™‰∏ÄËà¨Êåá‰ª§„ÄÇÊàë‰ª¨ÈÄöËøá‰∏ÄÁßçËø≠‰ª£ÊêúÁ¥¢Âíå‰ºòÂåñÁ®ãÂ∫èÊù•ÂÆûÁé∞Ëøô‰∏ÄÁÇπÔºåËØ•Á®ãÂ∫èÊé¢Á¥¢ÂèØËÉΩÁöÑÊÄùÊÉ≥ÁîüÊàêÁ©∫Èó¥ÔºåÂÖÅËÆ∏Ê®°ÂûãÂ≠¶‰π†Â¶Ç‰ΩïÂú®Ê≤°ÊúâÁõ¥Êé•ÁõëÁù£ÁöÑÊÉÖÂÜµ‰∏ãËøõË°åÊÄùËÄÉ„ÄÇÂØπ‰∫éÊØèÊù°Êåá‰ª§ÔºåÊÄùÊÉ≥ÂÄôÈÄâËÄÖ‰ΩøÁî®ËØÑÂà§Ê®°ÂûãËøõË°åËØÑÂàÜÔºå‰ªÖËØÑ‰º∞ÂÖ∂ÂìçÂ∫îÔºåÁÑ∂ÂêéÈÄöËøáÂÅèÂ•Ω‰ºòÂåñËøõË°å‰ºòÂåñ„ÄÇÊàë‰ª¨Ë°®ÊòéÔºåÊ≠§Á®ãÂ∫èÂú® AlpacaEval Âíå Arena-Hard ‰∏äË°®Áé∞Âá∫ÂçìË∂äÁöÑÊÄßËÉΩÔºåÂπ∂‰∏îÈô§‰∫ÜÊõ¥‰º†ÁªüÁöÑÊé®ÁêÜÂíåËß£ÂÜ≥ÈóÆÈ¢ò‰ªªÂä°‰πãÂ§ñÔºåËøòÂ±ïÁ§∫‰∫ÜÂú®ÈùûÊé®ÁêÜÁ±ªÂà´Ôºà‰æãÂ¶ÇËê•ÈîÄ„ÄÅÂÅ•Â∫∑Âíå‰∏ÄËà¨Áü•ËØÜÔºâ‰∏äÁöÑÊÄùËÄÉÊî∂Áõä„ÄÇ

##### **BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI**
2410.10604v1 by Shaohao Rui, Lingzhi Chen, Zhenyu Tang, Lilong Wang, Mianxin Liu, Shaoting Zhang, Xiaosong Wang

Accurate diagnosis of brain abnormalities is greatly enhanced by the
inclusion of complementary multi-parametric MRI imaging data. There is
significant potential to develop a universal pre-training model that can be
quickly adapted for image modalities and various clinical scenarios. However,
current models often rely on uni-modal image data, neglecting the cross-modal
correlations among different image modalities or struggling to scale up
pre-training in the presence of missing modality data. In this paper, we
propose BrainMVP, a multi-modal vision pre-training framework for brain image
analysis using multi-parametric MRI scans. First, we collect 16,022 brain MRI
scans (over 2.4 million images), encompassing eight MRI modalities sourced from
a diverse range of centers and devices. Then, a novel pre-training paradigm is
proposed for the multi-modal MRI data, addressing the issue of missing
modalities and achieving multi-modal information fusion. Cross-modal
reconstruction is explored to learn distinctive brain image embeddings and
efficient modality fusion capabilities. A modality-wise data distillation
module is proposed to extract the essence representation of each MR image
modality for both the pre-training and downstream application purposes.
Furthermore, we introduce a modality-aware contrastive learning module to
enhance the cross-modality association within a study. Extensive experiments on
downstream tasks demonstrate superior performance compared to state-of-the-art
pre-training methods in the medical domain, with Dice Score improvement of
0.28%-14.47% across six segmentation benchmarks and a consistent accuracy
improvement of 0.65%-18.07% in four individual classification tasks.

ÊëòË¶ÅÔºö<paragraph>Ê∫ñÁ¢∫Ë®∫Êñ∑ËÖ¶ÈÉ®Áï∞Â∏∏ÊúÉÈÄèÈÅéÂä†ÂÖ•‰∫íË£úÁöÑÂ§öÂèÉÊï∏ MRI ÂΩ±ÂÉèË≥áÊñôËÄåÂ§ßÂπÖÊèêÂçá„ÄÇÈñãÁôº‰∏ÄÂÄãÈÄöÁî®È†êË®ìÁ∑¥Ê®°ÂûãÂÖ∑ÊúâÁõ∏Áï∂Â§ßÁöÑÊΩõÂäõÔºåËÄåÊ≠§Ê®°ÂûãÂèØ‰ª•Âø´ÈÄüË™øÊï¥‰ª•Á¨¶ÂêàÂΩ±ÂÉèÂΩ¢ÂºèÂíåÂêÑÁ®ÆËá®Â∫äÂ†¥ÊôØ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÊ®°ÂûãÈÄöÂ∏∏‰ª∞Ë≥¥ÂñÆ‰∏ÄÂΩ¢ÂºèÁöÑÂΩ±ÂÉèË≥áÊñôÔºåÂøΩÁï•‰∫Ü‰∏çÂêåÂΩ±ÂÉèÂΩ¢Âºè‰πãÈñìÁöÑË∑®ÂΩ¢ÂºèÈóúËÅØÊÄßÔºåÊàñÊòØÈõ£‰ª•Âú®Áº∫‰πèÂΩ¢ÂºèË≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÊì¥Â±ïÈ†êË®ìÁ∑¥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ BrainMVPÔºå‰∏ÄÂÄãÁî®ÊñºËÖ¶ÈÉ®ÂΩ±ÂÉèÂàÜÊûêÁöÑÂ§öÂΩ¢ÂºèË¶ñË¶∫È†êË®ìÁ∑¥Êû∂ÊßãÔºå‰ΩøÁî®Â§öÂèÉÊï∏ MRI ÊéÉÊèè„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÊî∂ÈõÜ‰∫Ü 16,022 ÂÄãËÖ¶ÈÉ® MRI ÊéÉÊèèÔºàË∂ÖÈÅé 240 Ëê¨ÂºµÂΩ±ÂÉèÔºâÔºåÊ∂µËìã‰∫ÜÂÖ´Á®Æ MRI ÂΩ¢ÂºèÔºåÈÄô‰∫õÂΩ¢Âºè‰æÜËá™ÊñºÂêÑÁ®Æ‰∏çÂêåÁöÑ‰∏≠ÂøÉÂíåË£ùÁΩÆ„ÄÇÊé•ËëóÔºåÈáùÂ∞çÂ§öÂΩ¢Âºè MRI Ë≥áÊñôÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÈ†êË®ìÁ∑¥ÁØÑ‰æãÔºåËß£Ê±∫‰∫ÜÁº∫‰πèÂΩ¢ÂºèÁöÑÂïèÈ°åÔºå‰∏¶ÈÅîÂà∞‰∫ÜÂ§öÂΩ¢ÂºèË≥áË®äËûçÂêà„ÄÇÊé¢Á¥¢‰∫ÜË∑®ÂΩ¢ÂºèÈáçÂª∫Ôºå‰ª•Â≠∏ÁøíÁç®ÁâπÁöÑËÖ¶ÈÉ®ÂΩ±ÂÉèÂµåÂÖ•ÂíåÊúâÊïàÁéáÁöÑÂΩ¢ÂºèËûçÂêàËÉΩÂäõ„ÄÇÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂΩ¢ÂºèÊòéÊô∫ÁöÑË≥áÊñôËêÉÂèñÊ®°ÁµÑÔºåÁî®ÊñºËêÉÂèñÊØèÂÄã MR ÂΩ±ÂÉèÂΩ¢ÂºèÁöÑÊú¨Ë≥™Ë°®ÂæµÔºå‰ª•Á¨¶ÂêàÈ†êË®ìÁ∑¥Âíå‰∏ãÊ∏∏ÊáâÁî®ÁõÆÁöÑ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂΩ¢ÂºèÊÑüÁü•Â∞çÊØîÂ≠∏ÁøíÊ®°ÁµÑÔºå‰ª•Âä†Âº∑Á†îÁ©∂‰∏≠ÁöÑË∑®ÂΩ¢ÂºèÈóúËÅØÊÄß„ÄÇÈáùÂ∞ç‰∏ãÊ∏∏‰ªªÂãôÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜËàáÈÜ´ÁôÇÈ†òÂüü‰∏≠ÁèæÊúâÊúÄÂÖàÈÄ≤ÁöÑÈ†êË®ìÁ∑¥ÊñπÊ≥ïÁõ∏ÊØîÔºåÂÖ∂ÂÖ∑ÊúâÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÂú®ÂÖ≠ÂÄãÂàÜÂâ≤Âü∫Ê∫ñ‰∏≠È™∞Â≠êÂàÜÊï∏ÊèêÂçá‰∫Ü 0.28%-14.47%ÔºåÂú®ÂõõÂÄãÂÄãÂà•ÂàÜÈ°û‰ªªÂãô‰∏≠Á≤æÁ¢∫Â∫¶‰∏ÄËá¥ÊèêÂçá‰∫Ü 0.65%-18.07%„ÄÇ</paragraph>

##### **Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature**
2410.10537v1 by Jan Vrba, Jakub Steinbach, Tom√°≈° Jirsa, Laura Verde, Roberta De Fazio, Noriyasu Homma, Yuwen Zeng, Key Ichiji, Luk√°≈° H√°jek, Zuzana Sedl√°kov√°, Jan Mare≈°

In this study, we propose a robust set of features derived from a thorough
research of contemporary practices in voice pathology detection. The feature
set is based on the combination of acoustic handcrafted features. Additionally,
we introduce pitch difference as a novel feature. We combine this feature set,
containing data from the publicly available Saarbr\"ucken Voice Database (SVD),
with preprocessing using the K-Means Synthetic Minority Over-Sampling Technique
algorithm to address class imbalance.
  Moreover, we applied multiple ML models as binary classifiers. We utilized
support vector machine, k-nearest neighbors, naive Bayes, decision tree, random
forest and AdaBoost classifiers. To determine the best classification approach,
we performed grid search on feasible hyperparameters of respective classifiers
and subsections of features.
  Our approach has achieved the state-of-the-art performance, measured by
unweighted average recall in voice pathology detection on SVD database. We
intentionally omit accuracy as it is highly biased metric in case of unbalanced
data compared to aforementioned metrics. The results are further enhanced by
eliminating the potential overestimation of the results with repeated
stratified cross-validation. This advancement demonstrates significant
potential for the clinical deployment of ML methods, offering a valuable tool
for an objective examination of voice pathologies. To support our claims, we
provide a publicly available GitHub repository with DOI
10.5281/zenodo.13771573. Finally, we provide REFORMS checklist.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁµÑÁ©©ÂÅ•ÁöÑÂäüËÉΩÔºåÈÄô‰∫õÂäüËÉΩÊ∫êËá™Â∞çÁï∂‰ª£Ë™ûÈü≥ÁóÖÁêÜÊ™¢Ê∏¨ÂØ¶ÂãôÁöÑÈÄèÂæπÁ†îÁ©∂„ÄÇÈÄôÁµÑÂäüËÉΩÂü∫ÊñºËÅ≤Â≠∏ÊâãÂ∑•ÁâπÂæµÁöÑÁµÑÂêà„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞áÈü≥È´òÂ∑ÆÂºïÂÖ•‰ΩúÁÇ∫‰∏ÄÈ†ÖÊñ∞Á©éÁöÑÂäüËÉΩ„ÄÇÊàëÂÄëÂ∞áÈÄôÁµÑÂäüËÉΩÔºàÂåÖÂê´‰æÜËá™ÂÖ¨ÈñãÁöÑËñ©ÁàæÂ∏ÉÂëÇËÇØË™ûÈü≥Ë≥áÊñôÂ∫´ (SVD) ÁöÑË≥áÊñôÔºâËàá‰ΩøÁî® K-Means ÂêàÊàêÂ∞ëÊï∏ÈÅéÊé°Ê®£ÊäÄË°ìÊºîÁÆóÊ≥ïÈÄ≤Ë°åÈ†êËôïÁêÜÁµêÂêàÔºå‰ª•Ëß£Ê±∫È°ûÂà•‰∏çÂπ≥Ë°°ÁöÑÂïèÈ°å„ÄÇ
  Ê≠§Â§ñÔºåÊàëÂÄëÂ∞áÂ§öÂÄã ML Ê®°ÂûãÊáâÁî®ÁÇ∫‰∫åÂÖÉÂàÜÈ°ûÂô®„ÄÇÊàëÂÄëÂà©Áî®ÊîØÊè¥ÂêëÈáèÊ©ü„ÄÅk-ÊúÄËøëÈÑ∞„ÄÅÊ®∏Á¥†Ë≤ùÊ∞è„ÄÅÊ±∫Á≠ñÊ®π„ÄÅÈö®Ê©üÊ£ÆÊûóÂíå AdaBoost ÂàÜÈ°ûÂô®„ÄÇÁÇ∫‰∫ÜÁ¢∫ÂÆöÊúÄ‰Ω≥ÂàÜÈ°ûÊñπÊ≥ïÔºåÊàëÂÄëÂ∞çÂêÑÂÄãÂàÜÈ°ûÂô®ÁöÑÂèØË°åË∂ÖÂèÉÊï∏ÂíåÂäüËÉΩÂ≠êÈõÜÂü∑Ë°åÁ∂≤Ê†ºÊêúÂ∞ã„ÄÇ
  ÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∑≤ÈÅîÊàêÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÁî± SVD Ë≥áÊñôÂ∫´‰∏≠Ë™ûÈü≥ÁóÖÁêÜÊ™¢Ê∏¨ÁöÑÊú™Âä†Ê¨äÂπ≥ÂùáÂè¨ÂõûÁéáÊ∏¨Èáè„ÄÇÊàëÂÄëÊïÖÊÑèÁúÅÁï•Ê∫ñÁ¢∫Â∫¶ÔºåÂõ†ÁÇ∫Ëàá‰∏äËø∞ÊåáÊ®ôÁõ∏ÊØîÔºåÂú®Ë≥áÊñô‰∏çÂπ≥Ë°°ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊ∫ñÁ¢∫Â∫¶ÊòØ‰∏ÄÂÄãÈ´òÂ∫¶ÂÅèÈ†óÁöÑÊåáÊ®ô„ÄÇÈÄèÈÅéÈáçË§áÂàÜÂ±§‰∫§ÂèâÈ©óË≠âÊ∂àÈô§ÁµêÊûúÁöÑÊΩõÂú®È´ò‰º∞ÔºåÈÄ≤‰∏ÄÊ≠•ÊîπÂñÑ‰∫ÜÁµêÊûú„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïÂ±ïÁ§∫‰∫Ü ML ÊñπÊ≥ïÂú®Ëá®Â∫äÈÉ®ÁΩ≤‰∏äÁöÑÂ∑®Â§ßÊΩõÂäõÔºåÁÇ∫ÂÆ¢ËßÄÊ™¢Êü•Ë™ûÈü≥ÁóÖÁêÜÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑÂ∑•ÂÖ∑„ÄÇÁÇ∫‰∫ÜÊîØÊåÅÊàëÂÄëÁöÑË™™Ê≥ïÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ¨ÈñãÁöÑ GitHub ÂÑ≤Â≠òÂ∫´ÔºåÂÖ∂ DOI ÁÇ∫ 10.5281/zenodo.13771573„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèê‰æõ‰∫Ü REFORMS Ê†∏Â∞çÊ∏ÖÂñÆ„ÄÇ</paragraph>

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Gei√üler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∞çÊñºÂª∫ÊßãÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÈ©ÖÂãïÊáâÁî®Á®ãÂºèËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇË®∫Êñ∑ÊàñËá™ÂãïÈßïÈßõÁ≠âÈóúÈçµÈ†òÂüü„ÄÇÊ≥ïÂæã„ÄÅÂïÜÊ•≠ÂíåÂÄ´ÁêÜË¶ÅÊ±Ç‰øÉ‰Ωø‰ΩøÁî®ÊúâÊïàÁöÑ XAIÔºå‰ΩÜÊï∏ÈáèÊó•ÁõäÂ¢ûÂä†ÁöÑ‰∏çÂêåÊñπÊ≥ï‰ΩøÂæóÊåëÈÅ∏Ê≠£Á¢∫ÁöÑÊñπÊ≥ïÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºËß£ÈáãÈ´òÂ∫¶‰æùË≥¥ÊñºËÉåÊôØÔºåÂú®Ê≤íÊúâ‰ΩøÁî®ËÄÖÁöÑÊÉÖÊ≥Å‰∏ãË°°Èáè XAI ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂè™ËÉΩÊè≠Á§∫ÊúâÈôêÁöÑË≥áË®äÔºåÊéíÈô§‰∫∫È°ûÂõ†Á¥†Ôºå‰æãÂ¶ÇÁêÜËß£ÂÆÉÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂª∫Ë≠∞ÈÄèÈÅé‰ΩøÁî®ËÄÖÊàêÂäüÂü∑Ë°å‰ª£ÁêÜ‰ªªÂãôÁöÑËÉΩÂäõ‰æÜË©ï‰º∞ XAI ÊñπÊ≥ïÔºåË®≠Ë®à‰ΩøÂæóËâØÂ•ΩÁöÑÂü∑Ë°åË°®ÁèæÊòØËß£ÈáãÊèê‰æõÊúâÁî®Ë≥áË®äÁöÑÊåáÊ®ô„ÄÇÊèõÂè•Ë©±Ë™™ÔºåÊàëÂÄëÊé¢Ë®é XAI Â∞ç‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂπ´Âä©„ÄÇÊ≠§Â§ñÔºåÂ∞çÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÈÄ≤Ë°å‰ΩøÁî®ËÄÖÁ†îÁ©∂ÔºåÈ°ØÁ§∫Âá∫ÂÆÉÂÄëÂú®Áî¢Áîü‰ø°‰ªªÂíåÊá∑ÁñëÁöÑËÉΩÂäõ‰ª•ÂèäÊ≠£Á¢∫Âà§Êñ∑ AI Ê±∫Á≠ñÊòØÂê¶Ê≠£Á¢∫ÁöÑËÉΩÂäõÊñπÈù¢Â≠òÂú®Â∑ÆÁï∞„ÄÇÊ†πÊìöÁµêÊûúÔºåÊàëÂÄëÂº∑ÁÉàÂª∫Ë≠∞‰ΩøÁî®ÂíåÊì¥ÂÖÖÈÄôÁ®ÆÊñπÊ≥ïÔºå‰ª•ÈÄ≤Ë°åÊõ¥Â§ö‰ª•ÁõÆÊ®ôÁÇ∫Âü∫Á§éÁöÑ‰∫∫ÁÇ∫‰∏≠ÂøÉ‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•ÁµÇÁ´ØÂà∞ÁµÇÁ´ØÁöÑÊñπÂºèË°°Èáè XAI ÊïàËÉΩ„ÄÇ

##### **Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization**
2410.10483v1 by Jorge Garc√≠a-Torres, √òyvind Meinich-Bache, Anders Johannessen, Siren Rettedal, Vilde Kolstad, Kjersti Engan

Around 5-10\% of newborns need assistance to start breathing. Currently,
there is a lack of evidence-based research, objective data collection, and
opportunities for learning from real newborn resuscitation emergency events.
Generating and evaluating automated newborn resuscitation algorithm activity
timelines relative to the Time of Birth (ToB) offers a promising opportunity to
enhance newborn care practices. Given the importance of prompt resuscitation
interventions within the "golden minute" after birth, having an accurate ToB
with second precision is essential for effective subsequent analysis of newborn
resuscitation episodes. Instead, ToB is generally registered manually, often
with minute precision, making the process inefficient and susceptible to error
and imprecision. In this work, we explore the fusion of Artificial Intelligence
(AI) and thermal imaging to develop the first AI-driven ToB detector. The use
of temperature information offers a promising alternative to detect the newborn
while respecting the privacy of healthcare providers and mothers. However, the
frequent inconsistencies in thermal measurements, especially in a multi-camera
setup, make normalization strategies critical. Our methodology involves a
three-step process: first, we propose an adaptive normalization method based on
Gaussian mixture models (GMM) to mitigate issues related to temperature
variations; second, we implement and deploy an AI model to detect the presence
of the newborn within the thermal video frames; and third, we evaluate and
post-process the model's predictions to estimate the ToB. A precision of 88.1\%
and a recall of 89.3\% are reported in the detection of the newborn within
thermal frames during performance evaluation. Our approach achieves an absolute
median deviation of 2.7 seconds in estimating the ToB relative to the manual
annotations.

ÊëòË¶ÅÔºö<paragraph>Á¥Ñ 5-10% ÁöÑÊñ∞ÁîüÂÖíÈúÄË¶ÅÂçîÂä©ÊâçËÉΩÈñãÂßãÂëºÂê∏„ÄÇÁõÆÂâçÔºåÁº∫‰πèÂü∫ÊñºË≠âÊìöÁöÑÁ†îÁ©∂„ÄÅÂÆ¢ËßÄÁöÑË≥áÊñôËíêÈõÜÔºå‰ª•ÂèäÂæûÂØ¶ÈöõÊñ∞ÁîüÂÖíÂæ©Áî¶Á∑äÊÄ•‰∫ã‰ª∂‰∏≠Â≠∏ÁøíÁöÑÊ©üÊúÉ„ÄÇÁîüÊàê‰∏¶Ë©ï‰º∞Ëá™ÂãïÊñ∞ÁîüÂÖíÂæ©Áî¶ÊºîÁÆóÊ≥ïÊ¥ªÂãïÊôÇÈñìË°®ÔºåÁõ∏Â∞çÊñºÂá∫ÁîüÊôÇÈñì (ToB)ÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊ©üÊúÉÔºåÂèØ‰ª•Â¢ûÂº∑Êñ∞ÁîüÂÖíÁÖßË≠∑ÂØ¶Âãô„ÄÇÈëëÊñºÂú®Âá∫ÁîüÂæåÁöÑ„ÄåÈªÉÈáë‰∏ÄÂàÜÈêò„ÄçÂÖßÈÄ≤Ë°åÁ´ãÂç≥Âæ©Áî¶Âπ≤È†êÁöÑÈáçË¶ÅÊÄßÔºåÊìÅÊúâÊ∫ñÁ¢∫Âà∞ÁßíÁöÑ ToB Â∞çÊñºÊúâÊïàÂàÜÊûêÊñ∞ÁîüÂÖíÂæ©Áî¶‰∫ã‰ª∂Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåToB ÈÄöÂ∏∏ÊòØÊâãÂãïË®òÈåÑÁöÑÔºåÈÄöÂ∏∏Âè™ÊúâÂàÜÈêòÁöÑÁ≤æÁ¢∫Â∫¶ÔºåÈÄô‰ΩøÂæóÈÄôÂÄãÈÅéÁ®ãÊïàÁéá‰Ωé‰∏ãÔºåÂÆπÊòìÂá∫ÈåØ‰∏î‰∏çÁ≤æÁ¢∫„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåÁÜ±ÂΩ±ÂÉèËûçÂêàÔºå‰ª•ÈñãÁôºÁ¨¨‰∏ÄÂÄãÁî± AI È©ÖÂãïÁöÑ ToB ÂÅµÊ∏¨Âô®„ÄÇÊ∫´Â∫¶Ë≥áË®äÁöÑ‰ΩøÁî®Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊõø‰ª£ÊñπÊ°àÔºåÂèØ‰ª•Âú®Â∞äÈáçÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖÂíåÊØçË¶™Èö±ÁßÅÁöÑÂêåÊôÇÂÅµÊ∏¨Êñ∞ÁîüÂÖí„ÄÇÁÑ∂ËÄåÔºåÁÜ±ÈáèÊ∏¨Èáè‰∏≠ÁöÑÈ†ªÁπÅ‰∏ç‰∏ÄËá¥ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§öÈè°È†≠Ë®≠ÂÆö‰∏≠Ôºå‰ΩøÂæóÊ≠£Ë¶èÂåñÁ≠ñÁï•Ëá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÊã¨‰∏ÄÂÄã‰∏âÊ≠•È©üÊµÅÁ®ãÔºöÈ¶ñÂÖàÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÈ´òÊñØÊ∑∑ÂêàÊ®°Âûã (GMM) ÁöÑËá™ÈÅ©ÊáâÊ≠£Ë¶èÂåñÊñπÊ≥ïÔºå‰ª•Ê∏õËºïËàáÊ∫´Â∫¶ËÆäÂåñÁõ∏ÈóúÁöÑÂïèÈ°åÔºõÂÖ∂Ê¨°ÔºåÊàëÂÄëÂØ¶‰Ωú‰∏¶ÈÉ®ÁΩ≤‰∏ÄÂÄã AI Ê®°ÂûãÔºå‰ª•ÂÅµÊ∏¨Êñ∞ÁîüÂÖíÂú®ÁÜ±ÂΩ±ÂÉèÊ°Ü‰∏≠ÁöÑÂ≠òÂú®ÔºõÁ¨¨‰∏âÔºåÊàëÂÄëË©ï‰º∞‰∏¶ÂæåËôïÁêÜÊ®°ÂûãÁöÑÈ†êÊ∏¨Ôºå‰ª•‰º∞Ë®à ToB„ÄÇÂú®ÊïàËÉΩË©ï‰º∞ÊúüÈñìÔºåÂú®ÁÜ±ÂΩ±ÂÉèÊ°Ü‰∏≠ÂÅµÊ∏¨Êñ∞ÁîüÂÖíÊôÇÔºåÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 88.1%ÔºåÂè¨ÂõûÁéáÁÇ∫ 89.3%„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®‰º∞Ë®àÁõ∏Â∞çÊñºÊâãÂãïË®ªËß£ÁöÑ ToB ÊôÇÔºåÈÅîÂà∞ 2.7 ÁßíÁöÑÁµïÂ∞ç‰∏≠‰ΩçÊï∏ÂÅèÂ∑Æ„ÄÇ</paragraph>

##### **Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation**
2410.10366v1 by Zehua Cheng, Di Yuan, Thomas Lukasiewicz

The combination of semi-supervised learning (SemiSL) and contrastive learning
(CL) has been successful in medical image segmentation with limited
annotations. However, these works often rely on pretext tasks that lack the
specificity required for pixel-level segmentation, and still face overfitting
issues due to insufficient supervision signals resulting from too few
annotations. Therefore, this paper proposes an affinity-graph-guided
semi-supervised contrastive learning framework (Semi-AGCL) by establishing
additional affinity-graph-based supervision signals between the student and
teacher network, to achieve medical image segmentation with minimal annotations
without pretext. The framework first designs an average-patch-entropy-driven
inter-patch sampling method, which can provide a robust initial feature space
without relying on pretext tasks. Furthermore, the framework designs an
affinity-graph-guided loss function, which can improve the quality of the
learned representation and the model generalization ability by exploiting the
inherent structure of the data, thus mitigating overfitting. Our experiments
indicate that with merely 10% of the complete annotation set, our model
approaches the accuracy of the fully annotated baseline, manifesting a marginal
deviation of only 2.52%. Under the stringent conditions where only 5% of the
annotations are employed, our model exhibits a significant enhancement in
performance surpassing the second best baseline by 23.09% on the dice metric
and achieving an improvement of 26.57% on the notably arduous CRAG and ACDC
datasets.

ÊëòË¶ÅÔºöÂçäÁõëÁù£Â≠¶‰π† (SemiSL) ÂíåÂØπÊØîÂ≠¶‰π† (CL) ÁöÑÁªìÂêàÂ∑≤ÊàêÂäüÁî®‰∫éÂåªÁñóÂõæÂÉèÂàÜÂâ≤Ôºå‰∏îÊ†áÊ≥®ÊúâÈôê„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÂ∑•‰ΩúÈÄöÂ∏∏‰æùËµñ‰∫éÁº∫‰πèÂÉèÁ¥†Á∫ßÂàÜÂâ≤ÊâÄÈúÄÁâπÂºÇÊÄßÁöÑÂÄüÂè£‰ªªÂä°ÔºåÂπ∂‰∏îÁî±‰∫éÊ†áÊ≥®Â§™Â∞ëÂØºËá¥ÁõëÁù£‰ø°Âè∑‰∏çË∂≥Ôºå‰ªçÁÑ∂Èù¢‰∏¥ËøáÂ∫¶ÊãüÂêàÈóÆÈ¢ò„ÄÇÂõ†Ê≠§ÔºåÊú¨ÊñáÈÄöËøáÂú®Â≠¶ÁîüÁΩëÁªúÂíåÊïôÂ∏àÁΩëÁªú‰πãÈó¥Âª∫Á´ãÂü∫‰∫é‰∫≤ÂíåÂõæÁöÑÈôÑÂä†ÁõëÁù£‰ø°Âè∑ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßç‰∫≤ÂíåÂõæÂºïÂØºÁöÑÂçäÁõëÁù£ÂØπÊØîÂ≠¶‰π†Ê°ÜÊû∂ (Semi-AGCL)Ôºå‰ª•Âú®Ê≤°ÊúâÂÄüÂè£ÁöÑÊÉÖÂÜµ‰∏ãÂÆûÁé∞ÂåªÁñóÂõæÂÉèÂàÜÂâ≤Ôºå‰∏îÊ†áÊ≥®ÊúÄÂ∞ë„ÄÇËØ•Ê°ÜÊû∂È¶ñÂÖàËÆæËÆ°‰∫Ü‰∏ÄÁßçÂπ≥ÂùáË°•‰∏ÅÁÜµÈ©±Âä®ÁöÑË°•‰∏ÅÈó¥ÈááÊ†∑ÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÂèØ‰ª•Âú®‰∏ç‰æùËµñÂÄüÂè£‰ªªÂä°ÁöÑÊÉÖÂÜµ‰∏ãÊèê‰æõÈ≤ÅÊ£íÁöÑÂàùÂßãÁâπÂæÅÁ©∫Èó¥„ÄÇÊ≠§Â§ñÔºåËØ•Ê°ÜÊû∂ËÆæËÆ°‰∫Ü‰∏Ä‰∏™‰∫≤ÂíåÂõæÂºïÂØºÁöÑÊçüÂ§±ÂáΩÊï∞ÔºåËØ•ÂáΩÊï∞ÂèØ‰ª•ÈÄöËøáÂà©Áî®Êï∞ÊçÆÁöÑÂõ∫ÊúâÁªìÊûÑÊù•ÊèêÈ´òÂ≠¶‰π†Ë°®Á§∫ÂíåÊ®°ÂûãÊ≥õÂåñËÉΩÂäõÔºå‰ªéËÄåÂáèËΩªËøáÂ∫¶ÊãüÂêà„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊ®°Âûã‰ªÖ‰ΩøÁî® 10% ÁöÑÂÆåÊï¥Ê†áÊ≥®ÈõÜÔºåÂ∞±Êé•Ëøë‰∫ÜÂÆåÂÖ®Ê†áÊ≥®Âü∫ÂáÜÁöÑÂáÜÁ°ÆÂ∫¶Ôºå‰ªÖÊúâ 2.52% ÁöÑËæπÈôÖÂÅèÂ∑Æ„ÄÇÂú®‰ªÖ‰ΩøÁî® 5% Ê†áÊ≥®ÁöÑ‰∏•Ê†ºÊù°‰ª∂‰∏ãÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÂú®ÊÄßËÉΩ‰∏äË°®Áé∞Âá∫ÊòæÁùÄÊèêÂçáÔºåÂú®È™∞Â≠êÊåáÊ†á‰∏äÊØîÁ¨¨‰∫åÂ•ΩÁöÑÂü∫ÂáÜÈ´òÂá∫ 23.09%ÔºåÂπ∂Âú®ÈùûÂ∏∏Ëâ∞Â∑®ÁöÑ CRAG Âíå ACDC Êï∞ÊçÆÈõÜ‰∏äÊèêÈ´ò‰∫Ü 26.57%„ÄÇ

##### **Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning**
2410.10144v1 by Hongyi Yuan, Suqi Liu, Kelly Cho, Katherine Liao, Alexandre Pereira, Tianxi Cai

We introduce GENomic Encoding REpresentation with Language Model (GENEREL), a
framework designed to bridge genetic and biomedical knowledge bases. What sets
GENEREL apart is its ability to fine-tune language models to infuse biological
knowledge behind clinical concepts such as diseases and medications. This
fine-tuning enables the model to capture complex biomedical relationships more
effectively, enriching the understanding of how genomic data connects to
clinical outcomes. By constructing a unified embedding space for biomedical
concepts and a wide range of common SNPs from sources such as patient-level
data, biomedical knowledge graphs, and GWAS summaries, GENEREL aligns the
embeddings of SNPs and clinical concepts through multi-task contrastive
learning. This allows the model to adapt to diverse natural language
representations of biomedical concepts while bypassing the limitations of
traditional code mapping systems across different data sources. Our experiments
demonstrate GENEREL's ability to effectively capture the nuanced relationships
between SNPs and clinical concepts. GENEREL also emerges to discern the degree
of relatedness, potentially allowing for a more refined identification of
concepts. This pioneering approach in constructing a unified embedding system
for both SNPs and biomedical concepts enhances the potential for data
integration and discovery in biomedical research.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄë‰ªãÁ¥π GENomic Encoding REpresentation with Language Model (GENEREL)Ôºå‰∏ÄÂÄãÊó®Âú®Ê©ãÊé•ÈÅ∫ÂÇ≥ÂíåÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÂ∫´ÁöÑÊ°ÜÊû∂„ÄÇGENEREL ÁöÑÁç®Áâπ‰πãËôïÂú®ÊñºÂÆÉÂæÆË™øË™ûË®ÄÊ®°ÂûãÔºå‰ª•ÁÅåËº∏ÁñæÁóÖÂíåËó•Áâ©Á≠âËá®Â∫äÊ¶ÇÂøµËÉåÂæåÁöÑÁîüÁâ©Áü•Ë≠ò„ÄÇÈÄôÁ®ÆÂæÆË™ø‰ΩøÊ®°ÂûãËÉΩÂ§†Êõ¥ÊúâÊïàÂú∞ÊçïÊçâË§áÈõúÁöÑÁîüÁâ©ÈÜ´Â≠∏Èóú‰øÇÔºåË±êÂØåÂ∞çÂü∫Âõ†ÁµÑÊï∏ÊìöÂ¶Ç‰ΩïÈÄ£Êé•Ëá®Â∫äÁµêÊûúÁöÑÁêÜËß£„ÄÇÈÄöÈÅéÊßãÂª∫‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÁîüÁâ©ÈÜ´Â≠∏Ê¶ÇÂøµÂµåÂÖ•Á©∫ÈñìÂíå‰æÜËá™ÊÇ£ËÄÖÁ¥öÂà•Êï∏Êìö„ÄÅÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÂúñË≠úÂíå GWAS Á∏ΩÁµêÁ≠â‰æÜÊ∫êÁöÑÂª£Ê≥õÂ∏∏Ë¶ã SNPÔºåGENEREL ÈÄöÈÅéÂ§ö‰ªªÂãôÂ∞çÊØîÂ≠∏ÁøíÂ∞çÈΩä SNP ÂíåËá®Â∫äÊ¶ÇÂøµÁöÑÂµåÂÖ•„ÄÇÈÄôÂÖÅË®±Ê®°ÂûãÈÅ©ÊáâÁîüÁâ©ÈÜ´Â≠∏Ê¶ÇÂøµÁöÑÂ§öÂÖÉËá™ÁÑ∂Ë™ûË®ÄË°®Á§∫ÔºåÂêåÊôÇÁπûÈÅé‰∏çÂêåÊï∏ÊìöÊ∫ê‰∏≠ÂÇ≥Áµ±‰ª£Á¢ºÊò†Â∞ÑÁ≥ªÁµ±ÁöÑÈôêÂà∂„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòé‰∫Ü GENEREL ÊúâÊïàÊçïÊçâ SNP ÂíåËá®Â∫äÊ¶ÇÂøµ‰πãÈñìÁ¥∞ÂæÆÈóú‰øÇÁöÑËÉΩÂäõ„ÄÇGENEREL ‰πüÂá∫Áèæ‰∫ÜËæ®Âà•Áõ∏ÈóúÁ®ãÂ∫¶ÔºåÊΩõÂú®Âú∞ÂÖÅË®±Êõ¥Á≤æÁ¢∫Âú∞Ë≠òÂà•Ê¶ÇÂøµ„ÄÇÈÄôÁ®ÆÊßãÂª∫ SNP ÂíåÁîüÁâ©ÈÜ´Â≠∏Ê¶ÇÂøµÁµ±‰∏ÄÂµåÂÖ•Á≥ªÁµ±ÁöÑÂÖàÈ©ÖÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜÁîüÁâ©ÈÜ´Â≠∏Á†îÁ©∂‰∏≠Êï∏ÊìöÊï¥ÂêàÂíåÁôºÁèæÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **REHRSeg: Unleashing the Power of Self-Supervised Super-Resolution for Resource-Efficient 3D MRI Segmentation**
2410.10097v1 by Zhiyun Song, Yinjie Zhao, Xiaomin Li, Manman Fei, Xiangyu Zhao, Mengjun Liu, Cunjian Chen, Chung-Hsing Yeh, Qian Wang, Guoyan Zheng, Songtao Ai, Lichi Zhang

High-resolution (HR) 3D magnetic resonance imaging (MRI) can provide detailed
anatomical structural information, enabling precise segmentation of regions of
interest for various medical image analysis tasks. Due to the high demands of
acquisition device, collection of HR images with their annotations is always
impractical in clinical scenarios. Consequently, segmentation results based on
low-resolution (LR) images with large slice thickness are often unsatisfactory
for subsequent tasks. In this paper, we propose a novel Resource-Efficient
High-Resolution Segmentation framework (REHRSeg) to address the above-mentioned
challenges in real-world applications, which can achieve HR segmentation while
only employing the LR images as input. REHRSeg is designed to leverage
self-supervised super-resolution (self-SR) to provide pseudo supervision,
therefore the relatively easier-to-acquire LR annotated images generated by 2D
scanning protocols can be directly used for model training. The main
contribution to ensure the effectiveness in self-SR for enhancing segmentation
is three-fold: (1) We mitigate the data scarcity problem in the medical field
by using pseudo-data for training the segmentation model. (2) We design an
uncertainty-aware super-resolution (UASR) head in self-SR to raise the
awareness of segmentation uncertainty as commonly appeared on the ROI
boundaries. (3) We align the spatial features for self-SR and segmentation
through structural knowledge distillation to enable a better capture of region
correlations. Experimental results demonstrate that REHRSeg achieves
high-quality HR segmentation without intensive supervision, while also
significantly improving the baseline performance for LR segmentation.

ÊëòË¶ÅÔºöÈ´òËß£ÊûêÂ∫¶ (HR) 3D Á£ÅÂÖ±ÊåØÈÄ†ÂΩ± (MRI) ÂèØÊèê‰æõË©≥Á¥∞ÁöÑËß£ÂâñÁµêÊßãË≥áË®äÔºåËÉΩÈáùÂ∞çÂêÑÁ®ÆÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰ªªÂãôÁ≤æÁ¢∫ÂàÜÂâ≤ÊÑüËààË∂£ÁöÑÂçÄÂüü„ÄÇÁî±ÊñºÂèñÂæóË®≠ÂÇôË¶ÅÊ±ÇÈ´òÔºåÂú®Ëá®Â∫äÂ†¥ÊôØ‰∏≠Á∏ΩÊòØÈõ£‰ª•Êî∂ÈõÜÂ∏∂ÊúâË®ªËß£ÁöÑ HR ÂΩ±ÂÉè„ÄÇÂõ†Ê≠§ÔºåÂü∫ÊñºÂàáÁâáÂéöÂ∫¶Â§ßÁöÑ‰ΩéËß£ÊûêÂ∫¶ (LR) ÂΩ±ÂÉèÁöÑÂàÜÂâ≤ÁµêÊûúÂæÄÂæÄÁÑ°Ê≥ï‰ª§‰∫∫ÊªøÊÑèÔºåÁÑ°Ê≥ïÁî®ÊñºÂæåÁ∫å‰ªªÂãô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑË≥áÊ∫êÊúâÊïàÈ´òËß£ÊûêÂ∫¶ÂàÜÂâ≤Êû∂Êßã (REHRSeg)Ôºå‰ª•Ëß£Ê±∫ÂØ¶ÈöõÊáâÁî®‰∏≠‰∏äËø∞ÊåëÊà∞ÔºåË©≤Êû∂ÊßãÂÉÖ‰ΩøÁî® LR ÂΩ±ÂÉè‰ΩúÁÇ∫Ëº∏ÂÖ•Â∞±ËÉΩÂØ¶Áèæ HR ÂàÜÂâ≤„ÄÇREHRSeg Ë¢´Ë®≠Ë®àÁÇ∫Âà©Áî®Ëá™Áõ£Áù£Ë∂ÖËß£ÊûêÂ∫¶ (self-SR) ‰æÜÊèê‰æõÂÅΩÁõ£Áù£ÔºåÂõ†Ê≠§ÂèØ‰ª•Áõ¥Êé•‰ΩøÁî® 2D ÊéÉÊèèÂçîË≠∞Áî¢ÁîüÁöÑÁõ∏Â∞çÂÆπÊòìÂèñÂæóÁöÑ LR Ë®ªËß£ÂΩ±ÂÉè‰æÜÈÄ≤Ë°åÊ®°ÂûãË®ìÁ∑¥„ÄÇÁ¢∫‰øùËá™Áõ£Áù£Ë∂ÖËß£ÊûêÂ∫¶ (self-SR) Âú®Â¢ûÂº∑ÂàÜÂâ≤‰∏≠ÊúâÊïàÊÄßÁöÑ‰∏ªË¶ÅË≤¢ÁçªÊúâ‰∏âÈªûÔºö(1) ÊàëÂÄëÈÄèÈÅé‰ΩøÁî®ÂÅΩË≥áÊñô‰æÜË®ìÁ∑¥ÂàÜÂâ≤Ê®°ÂûãÔºå‰ª•Á∑©Ëß£ÈÜ´ÁôÇÈ†òÂüü‰∏≠ÁöÑË≥áÊñôÁ®ÄÂ∞ëÂïèÈ°å„ÄÇ(2) ÊàëÂÄëÂú®Ëá™Áõ£Áù£Ë∂ÖËß£ÊûêÂ∫¶ (self-SR) ‰∏≠Ë®≠Ë®à‰∫Ü‰∏ÄÂÄã‰∏çÁ¢∫ÂÆöÊÄßÊÑüÁü•Ë∂ÖËß£ÊûêÂ∫¶ (UASR) È†≠Ôºå‰ª•ÊèêÈ´òÂ∞çÂàÜÂâ≤‰∏çÁ¢∫ÂÆöÊÄßÁöÑÊÑüÁü•ÔºåÈÄôÁ®Æ‰∏çÁ¢∫ÂÆöÊÄßÈÄöÂ∏∏Âá∫ÁèæÂú®ÊÑüËààË∂£ÂçÄÂüü (ROI) ÈÇäÁïå‰∏ä„ÄÇ(3) ÊàëÂÄëÈÄèÈÅéÁµêÊßãÁü•Ë≠òËí∏È§æÂ∞áËá™Áõ£Áù£Ë∂ÖËß£ÊûêÂ∫¶ (self-SR) ÂíåÂàÜÂâ≤ÁöÑÁ©∫ÈñìÁâπÂæµÂ∞çÈΩäÔºå‰ª•Êõ¥Â•ΩÂú∞ÊçïÊçâÂçÄÂüüÈóúËÅØÊÄß„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåREHRSeg Âú®Ê≤íÊúâÂØÜÈõÜÁõ£Áù£ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶Áèæ‰∫ÜÈ´òÂìÅË≥™ÁöÑ HR ÂàÜÂâ≤ÔºåÂêåÊôÇ‰πüÈ°ØËëóÊèêÈ´ò‰∫Ü LR ÂàÜÂâ≤ÁöÑÂü∫Ê∫ñÊïàËÉΩ„ÄÇ

##### **IMAS: A Comprehensive Agentic Approach to Rural Healthcare Delivery**
2410.12868v1 by Agasthya Gangavarapu, Ananya Gangavarapu

Since the onset of COVID-19, rural communities worldwide have faced
significant challenges in accessing healthcare due to the migration of
experienced medical professionals to urban centers. Semi-trained caregivers,
such as Community Health Workers (CHWs) and Registered Medical Practitioners
(RMPs), have stepped in to fill this gap, but often lack formal training. This
paper proposes an advanced agentic medical assistant system designed to improve
healthcare delivery in rural areas by utilizing Large Language Models (LLMs)
and agentic approaches. The system is composed of five crucial components:
translation, medical complexity assessment, expert network integration, final
medical advice generation, and response simplification. Our innovative
framework ensures context-sensitive, adaptive, and reliable medical assistance,
capable of clinical triaging, diagnostics, and identifying cases requiring
specialist intervention. The system is designed to handle cultural nuances and
varying literacy levels, providing clear and actionable medical advice in local
languages. Evaluation results using the MedQA, PubMedQA, and JAMA datasets
demonstrate that this integrated approach significantly enhances the
effectiveness of rural healthcare workers, making healthcare more accessible
and understandable for underserved populations. All code and supplemental
materials associated with the paper and IMAS are available at
https://github.com/uheal/imas.

ÊëòË¶ÅÔºöËá™ COVID-19 Áñ´ÊÉÖÁàÜÂèë‰ª•Êù•ÔºåÂÖ®ÁêÉÂÜúÊùëÁ§æÂå∫Âú®Ëé∑ÂæóÂåªÁñó‰øùÂÅ•ÊñπÈù¢Èù¢‰∏¥ÈáçÂ§ßÊåëÊàòÔºåÂéüÂõ†ÊòØÁªèÈ™å‰∏∞ÂØåÁöÑÂåªÁñó‰∏ì‰∏ö‰∫∫ÂëòÁ∫∑Á∫∑ËøÅÂæÄÂüéÂ∏Ç‰∏≠ÂøÉ„ÄÇÂçäËÆ≠ÁªÉÊúâÁ¥†ÁöÑÁÖßÊä§ËÄÖÔºå‰æãÂ¶ÇÁ§æÂå∫Âç´ÁîüÂ∑•‰ΩúËÄÖ (CHW) ÂíåÊ≥®ÂÜåÂåªÁñó‰ªé‰∏öËÄÖ (RMP)ÔºåÂ∑≤Áªè‰ªãÂÖ•Â°´Ë°•Ëøô‰∏ÄÁ©∫ÁôΩÔºå‰ΩÜÂæÄÂæÄÁº∫‰πèÊ≠£ÂºèÂüπËÆ≠„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂÖàËøõÁöÑ‰ª£ÁêÜÂåªÁñóÂä©ÁêÜÁ≥ªÁªüÔºåÊó®Âú®ÈÄöËøáÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Âíå‰ª£ÁêÜÊñπÊ≥ïÊù•ÊîπÂñÑÂÜúÊùëÂú∞Âå∫ÁöÑÂåªÁñó‰øùÂÅ•ÊúçÂä°„ÄÇËØ•Á≥ªÁªüÁî±‰∫î‰∏™ÂÖ≥ÈîÆÁªÑ‰ª∂ÁªÑÊàêÔºöÁøªËØë„ÄÅÂåªÁñóÂ§çÊùÇÊÄßËØÑ‰º∞„ÄÅ‰∏ìÂÆ∂ÁΩëÁªúÈõÜÊàê„ÄÅÊúÄÁªàÂåªÁñóÂª∫ËÆÆÁîüÊàêÂíåÂìçÂ∫îÁÆÄÂåñ„ÄÇÊàë‰ª¨ÂàõÊñ∞ÁöÑÊ°ÜÊû∂Á°Æ‰øù‰∫ÜÊÉÖÂ¢ÉÊïèÊÑü„ÄÅÈÄÇÂ∫îÊÄßÂíåÂèØÈù†ÁöÑÂåªÁñóÊè¥Âä©ÔºåËÉΩÂ§üËøõË°å‰∏¥Â∫äÂàÜËØä„ÄÅËØäÊñ≠ÂíåËØÜÂà´ÈúÄË¶Å‰∏ìÂÆ∂Âπ≤È¢ÑÁöÑÁóÖ‰æã„ÄÇËØ•Á≥ªÁªüÊó®Âú®Â§ÑÁêÜÊñáÂåñÂ∑ÆÂºÇÂíå‰∏çÂêåÁöÑËØÜÂ≠óÊ∞¥Âπ≥ÔºåÁî®ÂΩìÂú∞ËØ≠Ë®ÄÊèê‰æõÊ∏ÖÊô∞‰∏îÂèØÊìç‰ΩúÁöÑÂåªÁñóÂª∫ËÆÆ„ÄÇ‰ΩøÁî® MedQA„ÄÅPubMedQA Âíå JAMA Êï∞ÊçÆÈõÜËøõË°åÁöÑËØÑ‰º∞ÁªìÊûúË°®ÊòéÔºåËøôÁßçÁªºÂêàÊñπÊ≥ïÊòæÁùÄÊèêÈ´ò‰∫ÜÂÜúÊùëÂåªÁñó‰øùÂÅ•Â∑•‰ΩúËÄÖÁöÑÊúâÊïàÊÄßÔºå‰ΩøÂåªÁñó‰øùÂÅ•ÊúçÂä°ÂØπÊúçÂä°‰∏çË∂≥ÁöÑ‰∫∫Áæ§Êù•ËØ¥Êõ¥Êòì‰∫éËé∑ÂæóÂíåÁêÜËß£„ÄÇ‰∏éËÆ∫ÊñáÂíå IMAS Áõ∏ÂÖ≥ÁöÑÊâÄÊúâ‰ª£Á†ÅÂíåË°•ÂÖÖÊùêÊñôÂùáÂèØÂú® https://github.com/uheal/imas Ëé∑Âæó„ÄÇ

##### **Adaptive Reasoning and Acting in Medical Language Agents**
2410.10020v1 by Abhishek Dutta, Yen-Che Hsiao

This paper presents an innovative large language model (LLM) agent framework
for enhancing diagnostic accuracy in simulated clinical environments using the
AgentClinic benchmark. The proposed automatic correction enables doctor agents
to iteratively refine their reasoning and actions following incorrect
diagnoses, fostering improved decision-making over time. Experiments show that
the implementation of the adaptive LLM-based doctor agents achieve correct
diagnoses through dynamic interactions with simulated patients. The evaluations
highlight the capacity of autonomous agents to adapt and improve in complex
medical scenarios. Future enhancements will focus on refining the algorithm and
expanding its applicability across a wider range of tasks and different large
language models.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ª£ÁêÜÊû∂ÊßãÔºåÁî®Êñº‰ΩøÁî® AgentClinic Âü∫Ê∫ñÊèêÈ´òÊ®°Êì¨Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑË®∫Êñ∑Ê∫ñÁ¢∫Â∫¶„ÄÇÂª∫Ë≠∞ÁöÑËá™ÂãïÊ†°Ê≠£‰ΩøÈÜ´Áîü‰ª£ÁêÜËÉΩÂ§†Âú®‰∏çÊ≠£Á¢∫ÁöÑË®∫Êñ∑ÂæåÂèçË¶ÜË™øÊï¥ÂÖ∂Êé®ÁêÜÂíåË°åÂãïÔºåÂæûËÄåÈö®ËëóÊôÇÈñìÁöÑÊé®Áßª‰øÉÈÄ≤ÊîπÂñÑÊ±∫Á≠ñ„ÄÇÂØ¶È©óË°®ÊòéÔºåÂü∫ÊñºËá™ÈÅ©Êáâ LLM ÁöÑÈÜ´Áîü‰ª£ÁêÜÁöÑÂØ¶ÊñΩÈÄöÈÅéËàáÊ®°Êì¨ÊÇ£ËÄÖÁöÑÂãïÊÖã‰∫íÂãïÂØ¶Áèæ‰∫ÜÊ≠£Á¢∫ÁöÑË®∫Êñ∑„ÄÇË©ï‰º∞Âº∑Ë™ø‰∫ÜËá™‰∏ª‰ª£ÁêÜÂú®Ë§áÈõúÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÈÅ©ÊáâÂíåÊîπÈÄ≤ÁöÑËÉΩÂäõ„ÄÇÊú™‰æÜÁöÑÊîπÈÄ≤Â∞áÈáçÈªûÊîæÂú®Ë™øÊï¥ÁÆóÊ≥ïÂíåÊì¥Â±ïÂÖ∂Âú®Êõ¥Âª£Ê≥õÁöÑ‰ªªÂãôÂíå‰∏çÂêåÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÈÅ©Áî®ÊÄß‰∏ä„ÄÇ

##### **Improving 3D Few-Shot Segmentation with Inference-Time Pseudo-Labeling**
2410.09967v1 by Mohammad Mozafari, Hosein Hasani, Reza Vahidimajd, Mohamadreza Fereydooni, Mahdieh Soleymani Baghshah

In recent years, few-shot segmentation (FSS) models have emerged as a
promising approach in medical imaging analysis, offering remarkable
adaptability to segment novel classes with limited annotated data. Existing
approaches to few-shot segmentation have often overlooked the potential of the
query itself, failing to fully utilize the valuable information it contains.
However, treating the query as unlabeled data provides an opportunity to
enhance prediction accuracy. Specifically in the domain of medical imaging, the
volumetric structure of queries offers a considerable source of valuable
information that can be used to improve the target slice segmentation. In this
work, we present a novel strategy to efficiently leverage the intrinsic
information of the query sample for final segmentation during inference. First,
we use the support slices from a reference volume to generate an initial
segmentation score for the query slices through a prototypical approach.
Subsequently, we apply a confidence-aware pseudo-labeling procedure to transfer
the most informative parts of query slices to the support set. The final
prediction is performed based on the new expanded support set, enabling the
prediction of a more accurate segmentation mask for the query volume. Extensive
experiments show that the proposed method can effectively boost performance
across diverse settings and datasets.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂ∞èÊ®£Êú¨ÂàÜÂâ≤ (FSS) Ê®°ÂûãÂ∑≤ÊàêÁÇ∫ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠‰∏ÄÁ®ÆÂâçÊôØÁúãÂ•ΩÁöÑÊñπÊ≥ïÔºåÂÆÉÁÇ∫‰ΩøÁî®ÊúâÈôêÊ®ôË®ªË≥áÊñôÂàÜÂâ≤Êñ∞È°ûÂà•Êèê‰æõ‰∫ÜÈ°ØËëóÁöÑÈÅ©ÊáâÊÄß„ÄÇÁèæÊúâÁöÑÂ∞èÊ®£Êú¨ÂàÜÂâ≤ÊñπÊ≥ïÈÄöÂ∏∏ÂøΩÁï•‰∫ÜÊü•Ë©¢Êú¨Ë∫´ÁöÑÊΩõÂäõÔºåÊú™ËÉΩÂÖÖÂàÜÂà©Áî®ÂÖ∂‰∏≠ÂåÖÂê´ÁöÑÂØ∂Ë≤¥Ë≥áË®ä„ÄÇÁÑ∂ËÄåÔºåÂ∞áÊü•Ë©¢Ë¶ñÁÇ∫Êú™Ê®ôË®ªË≥áÊñôÊèê‰æõ‰∫ÜÂ¢ûÂº∑È†êÊ∏¨Á≤æÁ¢∫Â∫¶ÁöÑÊ©üÊúÉ„ÄÇÁâπÂà•ÊòØÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüüÔºåÊü•Ë©¢ÁöÑÈ´îÁ©çÁµêÊßãÊèê‰æõ‰∫ÜÂ§ßÈáèÁöÑÂØ∂Ë≤¥Ë≥áË®ä‰æÜÊ∫êÔºåÂèØÁî®ÊñºÊîπÂñÑÁõÆÊ®ôÂàáÁâáÂàÜÂâ≤„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á≠ñÁï•ÔºåÂú®Êé®Ë´ñÊúüÈñìÊúâÊïàÂà©Áî®Êü•Ë©¢Ê®£Êú¨ÁöÑÂÖßÂú®Ë≥áË®äÈÄ≤Ë°åÊúÄÁµÇÂàÜÂâ≤„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄë‰ΩøÁî®ÂèÉËÄÉÈ´îÁ©ç‰∏≠ÁöÑÊîØÊè¥ÂàáÁâáÔºåÈÄèÈÅéÂéüÂûãÂåñÊñπÊ≥ïÁÇ∫Êü•Ë©¢ÂàáÁâáÁî¢ÁîüÂàùÂßãÂàÜÂâ≤ÂàÜÊï∏„ÄÇÈö®ÂæåÔºåÊàëÂÄëÊáâÁî®‰∏ÄÂÄãÂÖ∑ÂÇôË≠òÂà•ËÉΩÂäõÁöÑÂÅΩÊ®ôÁ±§Á®ãÂ∫èÔºåÂ∞áÊü•Ë©¢ÂàáÁâá‰∏≠ÊúÄÂÖ∑Ë≥áË®äÊÄßÁöÑÈÉ®ÂàÜËΩâÁßªÂà∞ÊîØÊè¥ÈõÜ‰∏≠„ÄÇÊúÄÁµÇÈ†êÊ∏¨ÊòØÊ†πÊìöÊñ∞ÁöÑÊì¥ÂÖÖÊîØÊè¥ÈõÜÈÄ≤Ë°åÁöÑÔºåÈÄô‰ΩøÂæóËÉΩÂ§†ÁÇ∫Êü•Ë©¢È´îÁ©çÈ†êÊ∏¨Âá∫Êõ¥Ê∫ñÁ¢∫ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂèØ‰ª•Âú®‰∏çÂêåÁöÑË®≠ÂÆöÂíåË≥áÊñôÈõÜ‰∏äÊúâÊïàÊèêÂçáÊïàËÉΩ„ÄÇ

##### **Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning**
2410.09908v1 by Pengfei Jin, Peng Shu, Sekeun Kim, Qing Xiao, Sifan Song, Cheng Chen, Tianming Liu, Xiang Li, Quanzheng Li

Foundation models have become a cornerstone in deep learning, with techniques
like Low-Rank Adaptation (LoRA) offering efficient fine-tuning of large models.
Similarly, methods such as Retrieval-Augmented Generation (RAG), which leverage
vectorized databases, have further improved model performance by grounding
outputs in external information. While these approaches have demonstrated
notable success, they often require extensive training or labeled data, which
can limit their adaptability in resource-constrained environments. To address
these challenges, we introduce Retrieval-based Parameter Ensemble (RPE), a new
method that creates a vectorized database of LoRAs, enabling efficient
retrieval and application of model adaptations to new tasks. RPE minimizes the
need for extensive training and eliminates the requirement for labeled data,
making it particularly effective for zero-shot learning. Additionally, RPE is
well-suited for privacy-sensitive domains like healthcare, as it modifies model
parameters without accessing raw data. When applied to tasks such as medical
report generation and image segmentation, RPE not only proved effective but
also surpassed supervised fine-tuning methods in certain cases, highlighting
its potential to enhance both computational efficiency and privacy in deep
learning applications.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°ÂûãÂ∑≤ÊàêÁÇ∫Ê∑±Â∫¶Â≠∏ÁøíÁöÑÂü∫Áü≥ÔºåÂÖ∂‰∏≠‰ΩéÁß©ÈÅ©Êáâ (LoRA) Á≠âÊäÄË°ìÊèê‰æõÂ§ßÂûãÊ®°ÂûãÁöÑÊúâÊïàÂæÆË™ø„ÄÇ
È°û‰ººÂú∞ÔºåÂà©Áî®ÂêëÈáèÂåñË≥áÊñôÂ∫´ÁöÑÊ™¢Á¥¢Êì¥ÂÖÖÁîüÊàê (RAG) Á≠âÊñπÊ≥ïÔºåÈÄèÈÅéÂú®Â§ñÈÉ®Ë≥áË®ä‰∏≠Âª∫Á´ãËº∏Âá∫ÔºåÈÄ≤‰∏ÄÊ≠•ÊîπÂñÑÊ®°ÂûãÊïàËÉΩ„ÄÇÈõñÁÑ∂ÈÄô‰∫õÊñπÊ≥ïÂ∑≤Â±ïÁèæÈ°ØËëóÁöÑÊàêÂäüÔºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑË®ìÁ∑¥ÊàñÊ®ôË®òË≥áÊñôÔºåÈÄôÂèØËÉΩÊúÉÈôêÂà∂ÂÆÉÂÄëÂú®Ë≥áÊ∫êÂèóÈôêÁí∞Â¢É‰∏≠ÁöÑÈÅ©ÊáâÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÈÄ≤Âü∫ÊñºÊ™¢Á¥¢ÁöÑÂèÉÊï∏ÈõÜÂêà (RPE)Ôºå‰∏ÄÁ®ÆÂª∫Á´ã LoRA ÂêëÈáèÂåñË≥áÊñôÂ∫´ÁöÑÊñ∞ÊñπÊ≥ïÔºåËÉΩÊúâÊïàÂú∞Ê™¢Á¥¢ÂíåÂ∞áÊ®°ÂûãÊîπÁ∑®ÊáâÁî®ÊñºÊñ∞‰ªªÂãô„ÄÇRPE Â∞áÂ§ßÈáèË®ìÁ∑¥ÁöÑÈúÄÊ±ÇÈôçËá≥ÊúÄ‰ΩéÔºå‰∏¶Ê∂àÈô§‰∫ÜÂ∞çÊ®ôË®òË≥áÊñôÁöÑÈúÄÊ±ÇÔºå‰ΩøÂÖ∂Âú®Èõ∂Ê¨°Â≠∏Áøí‰∏≠ÁâπÂà•ÊúâÊïà„ÄÇÊ≠§Â§ñÔºåRPE ÈùûÂ∏∏ÈÅ©ÂêàÈÜ´ÁôÇ‰øùÂÅ•Á≠âÊ≥®ÈáçÈö±ÁßÅÁöÑÈ†òÂüüÔºåÂõ†ÁÇ∫ÂÆÉ‰øÆÊîπÊ®°ÂûãÂèÉÊï∏ËÄå‰∏çÊúÉÂ≠òÂèñÂéüÂßãË≥áÊñô„ÄÇÁï∂ÊáâÁî®ÊñºÈÜ´ÁôÇÂ†±ÂëäÁîüÊàêÂíåÂΩ±ÂÉèÂàÜÂâ≤Á≠â‰ªªÂãôÊôÇÔºåRPE ‰∏çÂÉÖË¢´Ë≠âÊòéÊúâÊïàÔºåÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÈÇÑË∂ÖË∂ä‰∫ÜÊúâÁõ£Áù£ÁöÑÂæÆË™øÊñπÊ≥ïÔºåÁ™ÅÈ°ØÂá∫ÂÆÉÂú®Ê∑±Â∫¶Â≠∏ÁøíÊáâÁî®‰∏≠ÊèêÂçáÈÅãÁÆóÊïàÁéáÂíåÈö±ÁßÅÁöÑÊΩõÂäõ„ÄÇ

##### **Equitable Access to Justice: Logical LLMs Show Promise**
2410.09904v1 by Manuj Kant, Manav Kant, Marzieh Nabi, Preston Carlson, Megan Ma

The costs and complexity of the American judicial system limit access to
legal solutions for many Americans. Large language models (LLMs) hold great
potential to improve access to justice. However, a major challenge in applying
AI and LLMs in legal contexts, where consistency and reliability are crucial,
is the need for System 2 reasoning. In this paper, we explore the integration
of LLMs with logic programming to enhance their ability to reason, bringing
their strategic capabilities closer to that of a skilled lawyer. Our objective
is to translate laws and contracts into logic programs that can be applied to
specific legal cases, with a focus on insurance contracts. We demonstrate that
while GPT-4o fails to encode a simple health insurance contract into logical
code, the recently released OpenAI o1-preview model succeeds, exemplifying how
LLMs with advanced System 2 reasoning capabilities can expand access to
justice.

ÊëòË¶ÅÔºöÁæéÂúãÂè∏Ê≥ïÈ´îÁ≥ªÁöÑÊàêÊú¨ÂíåË§áÈõúÊÄßÈôêÂà∂‰∫ÜË®±Â§öÁæéÂúã‰∫∫Áç≤ÂæóÊ≥ïÂæãËß£Ê±∫ÊñπÊ°àÁöÑÊ©üÊúÉ„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÖ∑ÊúâÊîπÂñÑÂè∏Ê≥ïÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅìÂèñÂæóÁÆ°ÈÅìÁÆ°ÈÅìÁÆ°ÈÅì

##### **Large-Scale 3D Medical Image Pre-training with Geometric Context Priors**
2410.09890v1 by Linshan Wu, Jiaxin Zhuang, Hao Chen

The scarcity of annotations poses a significant challenge in medical image
analysis. Large-scale pre-training has emerged as a promising label-efficient
solution, owing to the utilization of large-scale data, large models, and
advanced pre-training techniques. However, its development in medical images
remains underexplored. The primary challenge lies in harnessing large-scale
unlabeled data and learning high-level semantics without annotations. We
observe that 3D medical images exhibit consistent geometric context, i.e.,
consistent geometric relations between different organs, which leads to a
promising way for learning consistent representations. Motivated by this, we
introduce a simple-yet-effective Volume Contrast (VoCo) framework to leverage
geometric context priors for self-supervision. Given an input volume, we
extract base crops from different regions to construct positive and negative
pairs for contrastive learning. Then we predict the contextual position of a
random crop by contrasting its similarity to the base crops. In this way, VoCo
encodes the inherent geometric context into model representations, facilitating
high-level semantic learning without annotations. Specifically, we (1)
introduce the largest medical pre-training dataset PreCT-160K; (2) investigate
scaling laws and propose guidelines for tailoring different model sizes to
various medical tasks; (3) build a benchmark encompassing 48 medical tasks.
Extensive experiments highlight the superiority of VoCo. Codes at
https://github.com/Luffy03/Large-Scale-Medical.

ÊëòË¶ÅÔºö<paragraph>Ê®ôË®ªÁöÑÁ®ÄÁº∫ÊÄßÂ∞çÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÁî±ÊñºÂà©Áî®Â§ßË¶èÊ®°Êï∏Êìö„ÄÅÂ§ßÂûãÊ®°ÂûãÂíåÂÖàÈÄ≤ÁöÑÈ†êË®ìÁ∑¥ÊäÄË°ìÔºåÂ§ßË¶èÊ®°È†êË®ìÁ∑¥Â∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊ®ôÁ±§ÊïàÁéáËß£Ê±∫ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÂÖ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÁôºÂ±ï‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇ‰∏ªË¶ÅÁöÑÊåëÊà∞Âú®ÊñºÂà©Áî®Â§ßË¶èÊ®°Êú™Ê®ôË®ªÊï∏Êìö‰∏¶Âú®Ê≤íÊúâÊ®ôË®ªÁöÑÊÉÖÊ≥Å‰∏ãÂ≠∏ÁøíÈ´òÁ¥öË™ûÁæ©„ÄÇÊàëÂÄëËßÄÂØüÂà∞ 3D ÈÜ´Â≠∏ÂΩ±ÂÉèË°®ÁèæÂá∫‰∏ÄËá¥ÁöÑÂπæ‰ΩïËÉåÊôØÔºåÂç≥‰∏çÂêåÂô®ÂÆò‰πãÈñìÁöÑ‰∏ÄËá¥Âπæ‰ΩïÈóú‰øÇÔºåÈÄôÁÇ∫Â≠∏Áøí‰∏ÄËá¥ÁöÑË°®Á§∫Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ï„ÄÇÂèóÊ≠§ÂïüÁôºÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆËÄåÊúâÊïàÁöÑÈ´îÁ©çÂ∞çÊØî (VoCo) Ê°ÜÊû∂Ôºå‰ª•Âà©Áî®Âπæ‰ΩïËÉåÊôØÂÖàÈ©óÈÄ≤Ë°åËá™ÊàëÁõ£Áù£„ÄÇÁµ¶ÂÆö‰∏ÄÂÄãËº∏ÂÖ•È´îÁ©çÔºåÊàëÂÄëÂæû‰∏çÂêåÁöÑÂçÄÂüüÊèêÂèñÂü∫Á§éË£ÅÂâ™Ôºå‰ª•ÊßãÈÄ†Â∞çÊØîÂ≠∏ÁøíÁöÑÊ≠£Ë≤†Â∞ç„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÈÄöÈÅéÂ∞çÊØîÂÖ∂ËàáÂü∫Á§éË£ÅÂâ™ÁöÑÁõ∏‰ººÊÄß‰æÜÈ†êÊ∏¨Èö®Ê©üË£ÅÂâ™ÁöÑ‰∏ä‰∏ãÊñá‰ΩçÁΩÆ„ÄÇÈÄöÈÅéÈÄôÁ®ÆÊñπÂºèÔºåVoCo Â∞áÂõ∫ÊúâÁöÑÂπæ‰ΩïËÉåÊôØÁ∑®Á¢ºÂà∞Ê®°ÂûãË°®Á§∫‰∏≠ÔºåÂæûËÄå‰øÉÈÄ≤‰∫ÜÂú®Ê≤íÊúâÊ®ôË®ªÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÈ´òÁ¥öË™ûÁæ©Â≠∏Áøí„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë (1) ÂºïÂÖ•‰∫ÜÊúÄÂ§ßÁöÑÈÜ´Â≠∏È†êË®ìÁ∑¥Êï∏ÊìöÈõÜ PreCT-160KÔºõ(2) Ë™øÊü•Á∏ÆÊîæÂÆöÂæã‰∏¶ÊèêÂá∫ÊåáÂ∞éÊñπÈáùÔºå‰ª•Ê†πÊìö‰∏çÂêåÁöÑÈÜ´ÁôÇ‰ªªÂãôË™øÊï¥‰∏çÂêåÁöÑÊ®°ÂûãÂ§ßÂ∞èÔºõ(3) ÊßãÂª∫‰∫Ü‰∏ÄÂÄãÊ∂µËìã 48 ÂÄãÈÜ´ÁôÇ‰ªªÂãôÁöÑÂü∫Ê∫ñ„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óÁ™ÅÂá∫‰∫Ü VoCo ÁöÑÂÑ™Ë∂äÊÄß„ÄÇ‰ª£Á¢ºË¶ã https://github.com/Luffy03/Large-Scale-Medical„ÄÇ</paragraph>

##### **HypomimiaCoach: An AU-based Digital Therapy System for Hypomimia Detection & Rehabilitation with Parkinson's Disease**
2410.09772v1 by Yingjing Xu, Xueyan Cai, Zihong Zhou, Mengru Xue, Bo Wang, Haotian Wang, Zhengke Li, Chentian Weng, Wei Luo, Cheng Yao, Bo Lin, Jianwei Yin

Hypomimia is a non-motor symptom of Parkinson's disease that manifests as
delayed facial movements and expressions, along with challenges in articulation
and emotion. Currently, subjective evaluation by neurologists is the primary
method for hypomimia detection, and conventional rehabilitation approaches
heavily rely on verbal prompts from rehabilitation physicians. There remains a
deficiency in accessible, user-friendly and scientifically rigorous assistive
tools for hypomimia treatments. To investigate this, we developed
HypomimaCoach, an Action Unit (AU)-based digital therapy system for hypomimia
detection and rehabilitation in Parkinson's disease. The HypomimaCoach system
was designed to facilitate engagement through the incorporation of both relaxed
and controlled rehabilitation exercises, while also stimulating initiative
through the integration of digital therapies that incorporated traditional face
training methods. We extract action unit(AU) features and their relationship
for hypomimia detection. In order to facilitate rehabilitation, a series of
training programmes have been devised based on the Action Units (AUs) and
patients are provided with real-time feedback through an additional AU
recognition model, which guides them through their training routines. A pilot
study was conducted with seven participants in China, all of whom exhibited
symptoms of Parkinson's disease hypomimia. The results of the pilot study
demonstrated a positive impact on participants' self-efficacy, with favourable
feedback received. Furthermore, physician evaluations validated the system's
applicability in a therapeutic setting for patients with Parkinson's disease,
as well as its potential value in clinical applications.

ÊëòË¶ÅÔºö<paragraph>È°èÈù¢Ë°®ÊÉÖÊ∏õÂ∞ëÁóáÊòØÂ∏ïÈáëÊ£ÆÊ∞èÁóáÁöÑ‰∏ÄÁ®ÆÈùûÈÅãÂãïÁóáÁãÄÔºåË°®ÁèæÁÇ∫Èù¢ÈÉ®Âãï‰ΩúÂíåË°®ÊÉÖÈÅ≤Á∑©Ôºå‰ª•ÂèäË®ÄË™ûË°®ÈÅîÂíåÊÉÖÁ∑íË°®ÈÅîÂõ∞Èõ£„ÄÇÁõÆÂâçÔºåÁ•ûÁ∂ìÁßëÈÜ´Â∏´ÁöÑ‰∏ªËßÄË©ï‰º∞ÊòØÈ°èÈù¢Ë°®ÊÉÖÊ∏õÂ∞ëÁóáÊ™¢Ê∏¨ÁöÑ‰∏ªË¶ÅÊñπÊ≥ïÔºåÂÇ≥Áµ±ÁöÑÂæ©ÂÅ•ÊñπÊ≥ïÈ´òÂ∫¶‰æùË≥¥Âæ©ÂÅ•ÈÜ´Â∏´ÁöÑË®ÄË™ûÊèêÁ§∫„ÄÇÈ°èÈù¢Ë°®ÊÉÖÊ∏õÂ∞ëÁóáÊ≤ªÁôÇ‰∏≠‰ªçÁÑ∂Áº∫‰πèÂèØÂèñÂæó„ÄÅ‰ΩøÁî®ËÄÖÂèãÂñÑ‰∏îÁßëÂ≠∏Âö¥Ë¨πÁöÑËºîÂä©Â∑•ÂÖ∑„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈñãÁôº‰∫Ü HypomimaCoachÔºå‰∏ÄÁ®ÆÂü∫ÊñºÂãï‰ΩúÂñÆÂÖÉ (AU) ÁöÑÊï∏‰ΩçÊ≤ªÁôÇÁ≥ªÁµ±ÔºåÁî®ÊñºÂ∏ïÈáëÊ£ÆÊ∞èÁóáÁöÑÈ°èÈù¢Ë°®ÊÉÖÊ∏õÂ∞ëÁóáÊ™¢Ê∏¨ÂíåÂæ©ÂÅ•„ÄÇHypomimaCoach Á≥ªÁµ±Êó®Âú®ÈÄèÈÅéÊï¥ÂêàÊîæÈ¨ÜÂíåÊéßÂà∂ÁöÑÂæ©ÂÅ•ÈÅãÂãï‰æÜ‰øÉÈÄ≤ÂèÉËàáÔºåÂêåÊôÇÈÄèÈÅéÊï¥ÂêàÂÇ≥Áµ±Èù¢ÈÉ®Ë®ìÁ∑¥ÊñπÊ≥ïÁöÑÊï∏‰ΩçÊ≤ªÁôÇ‰æÜÊøÄÂãµ‰∏ªÂãïÊÄß„ÄÇÊàëÂÄëËêÉÂèñÂãï‰ΩúÂñÆÂÖÉ (AU) ÁâπÂæµÂèäÂÖ∂ËàáÈ°èÈù¢Ë°®ÊÉÖÊ∏õÂ∞ëÁóáÊ™¢Ê∏¨ÁöÑÈóú‰øÇ„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Âæ©ÂÅ•ÔºåÊàëÂÄëÊ†πÊìöÂãï‰ΩúÂñÆÂÖÉ (AU) Ë®≠Ë®à‰∫Ü‰∏ÄÁ≥ªÂàóË®ìÁ∑¥Ë®àÁï´Ôºå‰∏¶ÈÄèÈÅé‰∏ÄÂÄãÈ°çÂ§ñÁöÑ AU Ëæ®Ë≠òÊ®°ÂûãÊèê‰æõÊÇ£ËÄÖÂç≥ÊôÇÂõûÈ•ãÔºåÂºïÂ∞é‰ªñÂÄëÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÊàëÂÄëÂú®‰∏≠ÂúãÂ∞ç‰∏É‰ΩçÂèÉËàáËÄÖÈÄ≤Ë°å‰∫ÜË©¶È©óÁ†îÁ©∂ÔºåÊâÄÊúâÂèÉËàáËÄÖÂùáË°®ÁèæÂá∫Â∏ïÈáëÊ£ÆÊ∞èÁóáÈ°èÈù¢Ë°®ÊÉÖÊ∏õÂ∞ëÁóáÁöÑÁóáÁãÄ„ÄÇË©¶È©óÁ†îÁ©∂ÁöÑÁµêÊûúÈ°ØÁ§∫Â∞çÂèÉËàáËÄÖÁöÑËá™ÊàëÊïàËÉΩÁî¢Áîü‰∫ÜÊ≠£Èù¢ÁöÑÂΩ±ÈüøÔºå‰∏¶Áç≤Âæó‰∫ÜÊ≠£Èù¢ÁöÑÂõûÈ•ã„ÄÇÊ≠§Â§ñÔºåÈÜ´Â∏´Ë©ï‰º∞È©óË≠â‰∫ÜË©≤Á≥ªÁµ±Âú®Â∏ïÈáëÊ£ÆÊ∞èÁóáÊÇ£ËÄÖÊ≤ªÁôÇÁí∞Â¢É‰∏≠ÁöÑÈÅ©Áî®ÊÄßÔºå‰ª•ÂèäÂÖ∂Âú®Ëá®Â∫äÊáâÁî®‰∏≠ÁöÑÊΩõÂú®ÂÉπÂÄº„ÄÇ</paragraph>

##### **STA-Unet: Rethink the semantic redundant for Medical Imaging Segmentation**
2410.11578v1 by Vamsi Krishna Vasa, Wenhui Zhu, Xiwen Chen, Peijie Qiu, Xuanzhao Dong, Yalin Wang

In recent years, significant progress has been made in the medical image
analysis domain using convolutional neural networks (CNNs). In particular, deep
neural networks based on a U-shaped architecture (UNet) with skip connections
have been adopted for several medical imaging tasks, including organ
segmentation. Despite their great success, CNNs are not good at learning global
or semantic features. Especially ones that require human-like reasoning to
understand the context. Many UNet architectures attempted to adjust with the
introduction of Transformer-based self-attention mechanisms, and notable gains
in performance have been noted. However, the transformers are inherently flawed
with redundancy to learn at shallow layers, which often leads to an increase in
the computation of attention from the nearby pixels offering limited
information. The recently introduced Super Token Attention (STA) mechanism
adapts the concept of superpixels from pixel space to token space, using super
tokens as compact visual representations. This approach tackles the redundancy
by learning efficient global representations in vision transformers, especially
for the shallow layers. In this work, we introduce the STA module in the UNet
architecture (STA-UNet), to limit redundancy without losing rich information.
Experimental results on four publicly available datasets demonstrate the
superiority of STA-UNet over existing state-of-the-art architectures in terms
of Dice score and IOU for organ segmentation tasks. The code is available at
\url{https://github.com/Retinal-Research/STA-UNet}.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºå‰ΩøÁî®Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÈ†òÂüü‰∏≠ÂèñÂæóÈ°ØËëóÈÄ≤Â±ï„ÄÇÁâπÂà•ÊòØÔºåÂü∫Êñº U ÂΩ¢Êû∂Êßã (UNet) ÁöÑÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÔºåÂÖ∑ÊúâË∑≥Ë∫çÈÄ£Êé•ÔºåÂ∑≤Ë¢´Êé°Áî®ÊñºÂ§öÈ†ÖÈÜ´Â≠∏ÂΩ±ÂÉè‰ªªÂãôÔºåÂåÖÊã¨Âô®ÂÆòÂàÜÂâ≤„ÄÇÂÑòÁÆ° CNN Áç≤ÂæóÂ∑®Â§ßÁöÑÊàêÂäüÔºå‰ΩÜÂÆÉÂÄë‰∏¶‰∏çÊìÖÈï∑Â≠∏ÁøíÂÖ®Â±ÄÊàñË™ûÁæ©ÁâπÂæµ„ÄÇÂ∞§ÂÖ∂ÊòØÈÇ£‰∫õÈúÄË¶ÅÈ°û‰ºº‰∫∫È°ûÁöÑÊé®ÁêÜÊâçËÉΩÁêÜËß£ËÑàÁµ°ÁöÑÁâπÂæµ„ÄÇË®±Â§ö UNet Êû∂ÊßãÂòóË©¶ÈÄèÈÅéÂ∞éÂÖ•Âü∫Êñº Transformer ÁöÑËá™ÊàëÊ≥®ÊÑèÊ©üÂà∂ÈÄ≤Ë°åË™øÊï¥Ôºå‰∏¶Â∑≤Ê≥®ÊÑèÂà∞ÊïàËÉΩÁöÑÈ°ØËëóÊèêÂçá„ÄÇÁÑ∂ËÄåÔºåTransformer Âú®Êú¨Ë≥™‰∏äÂ≠òÂú®Â≠∏ÁøíÊ∑∫Â±§ÁöÑÂÜóÈ§òÁº∫Èô∑ÔºåÈÄôÈÄöÂ∏∏ÊúÉÂ∞éËá¥Ë®àÁÆó‰æÜËá™ÈôÑËøëÂÉèÁ¥†ÁöÑÊ≥®ÊÑèÔºåËÄåÈÄô‰∫õÂÉèÁ¥†Êèê‰æõÁöÑË≥áË®äÊúâÈôê„ÄÇÊúÄËøëÊé®Âá∫ÁöÑË∂ÖÊ®ôË®òÊ≥®ÊÑè (STA) Ê©üÂà∂Â∞áË∂ÖÂÉèÁ¥†ÁöÑÊ¶ÇÂøµÂæûÂÉèÁ¥†Á©∫ÈñìË™øÊï¥Âà∞Ê®ôË®òÁ©∫ÈñìÔºå‰ΩøÁî®Ë∂ÖÊ®ôË®ò‰ΩúÁÇ∫Á∑äÊπäÁöÑË¶ñË¶∫Ë°®Á§∫„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈÄèÈÅéÂ≠∏ÁøíË¶ñË¶∫ Transformer ‰∏≠ÊúâÊïàÁéáÁöÑÂÖ®Â±ÄË°®Á§∫ÔºåÁâπÂà•ÊòØÂ∞çÊñºÊ∑∫Â±§Ôºå‰æÜËß£Ê±∫ÂÜóÈ§òÂïèÈ°å„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂú® UNet Êû∂Êßã (STA-UNet) ‰∏≠Â∞éÂÖ• STA Ê®°ÁµÑÔºå‰ª•ÈôêÂà∂ÂÜóÈ§òÔºåÂêåÊôÇ‰∏çÈÅ∫Â§±Ë±êÂØåÁöÑË≥áË®ä„ÄÇÂú®ÂõõÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü STA-UNet Âú®Âô®ÂÆòÂàÜÂâ≤‰ªªÂãôÁöÑ Dice ÂàÜÊï∏Âíå IOU ÊñπÈù¢ÂÑ™ÊñºÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤Êû∂Êßã„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® \url{https://github.com/Retinal-Research/STA-UNet} ÂèñÂæó„ÄÇ</paragraph>

##### **MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions**
2410.09729v1 by Tavish Mankash, V. S. Chaithanya Kota, Anish De, Praveen Prakash, Kshitij Jadhav

Hospitals generate thousands of handwritten prescriptions, a practice that
remains prevalent despite the availability of Electronic Medical Records (EMR).
This method of record-keeping hinders the examination of long-term medication
effects, impedes statistical analysis, and makes the retrieval of records
challenging. Handwritten prescriptions pose a unique challenge, requiring
specialized data for training models to recognize medications and their
patterns of recommendation. While current handwriting recognition approaches
typically employ 2-D LSTMs, recent studies have explored the use of Large
Language Models (LLMs) for Optical Character Recognition (OCR). Building on
this approach, we focus on extracting medication names from medical records.
Our methodology MIRAGE (Multimodal Identification and Recognition of
Annotations in indian GEneral prescriptions) involves fine-tuning the LLaVA 1.6
and Idefics2 models. Our research utilizes a dataset provided by Medyug
Technology, consisting of 743,118 fully annotated high-resolution simulated
medical records from 1,133 doctors across India. We demonstrate that our
methodology exhibits 82% accuracy in medication name and dosage extraction. We
provide a detailed account of our research methodology and results, notes about
HWR with Multimodal LLMs, and release a small dataset of 100 medical records
with labels.

ÊëòË¶ÅÔºöÈÜ´Èô¢ÊúÉÁî¢ÁîüÊï∏ÂçÉ‰ªΩÊâãÂØ´ËôïÊñπÔºåÂÑòÁÆ°ÊúâÈõªÂ≠êÁóÖÊ≠∑ (EMR) ÂèØÁî®Ôºå‰ΩÜÈÄôÁ®ÆÂÅöÊ≥ï‰ªçÁÑ∂ÂæàÊôÆÈÅç„ÄÇÈÄôÁ®ÆË®òÈåÑ‰øùÂ≠òÊñπÂºèÊúÉÈòªÁ§ôÈï∑ÊúüËó•Áâ©ÊïàÊûúÁöÑÊ™¢Êü•ÔºåÂ¶®Á§ôÁµ±Ë®àÂàÜÊûêÔºå‰∏¶ËÆìË®òÈåÑÁöÑÊ™¢Á¥¢ËÆäÂæóÂõ∞Èõ£„ÄÇÊâãÂØ´ËôïÊñπÊßãÊàê‰∫Ü‰∏ÄÈ†ÖÁç®ÁâπÁöÑÊåëÊà∞ÔºåÈúÄË¶ÅÂ∞àÊ•≠ÁöÑË≥áÊñô‰æÜË®ìÁ∑¥Ê®°Âûã‰ª•Ëæ®Ë≠òËó•Áâ©ÂèäÂÖ∂Êé®Ëñ¶Ê®°Âºè„ÄÇÈõñÁÑ∂ÁõÆÂâçÁöÑËæ®Ë≠òÊâãÂØ´Â≠óÊñπÊ≥ïÈÄöÂ∏∏Êé°Áî® 2-D LSTMÔºå‰ΩÜÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Êé¢Ë®é‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÂÖâÂ≠∏Â≠óÂÖÉËæ®Ë≠ò (OCR)„ÄÇÊ†πÊìöÊ≠§ÊñπÊ≥ïÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂæûÁóÖÊ≠∑‰∏≠Êì∑ÂèñËó•Áâ©ÂêçÁ®±„ÄÇÊàëÂÄëÁöÑ MIRAGE ÊñπÊ≥ïÔºàÂç∞Â∫¶‰∏ÄËà¨ËôïÊñπ‰∏≠ÁöÑÂ§öÊ®°ÂºèË®ªËß£Ëæ®Ë≠òËàáËæ®Ë≠òÔºâÊ∂âÂèäÂæÆË™ø LLaVA 1.6 Âíå Idefics2 Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰ΩøÁî® Medyug Technology Êèê‰æõÁöÑË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™Âç∞Â∫¶ 1,133 ‰ΩçÈÜ´ÁîüÁöÑ 743,118 ‰ªΩÁ∂ìÈÅéÂÆåÊï¥Ë®ªËß£ÁöÑÈ´òËß£ÊûêÂ∫¶Ê®°Êì¨ÁóÖÊ≠∑„ÄÇÊàëÂÄëË≠âÊòéÊàëÂÄëÁöÑÊäÄË°ìÂú®Ëó•Áâ©ÂêçÁ®±ÂíåÂäëÈáèÊì∑ÂèñÊñπÈù¢Â±ïÁèæÂá∫ 82% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëË©≥Á¥∞Ë™™Êòé‰∫ÜÊàëÂÄëÁöÑÁ†îÁ©∂ÊñπÊ≥ïÂíåÁµêÊûúÔºå‰ª•ÂèäÊúâÈóú‰ΩøÁî®Â§öÊ®°Âºè LLM ÁöÑ HWR ÁöÑÊ≥®ÊÑè‰∫ãÈ†ÖÔºå‰∏¶ÁôºÂ∏É‰∫Ü‰∏ÄÂ∞èÈÉ®ÂàÜÂåÖÂê´Ê®ôÁ±§ÁöÑ 100 ‰ªΩÁóÖÊ≠∑Ë≥áÊñôÈõÜ„ÄÇ

##### **3DS: Decomposed Difficulty Data Selection's Case Study on LLM Medical Domain Adaptation**
2410.10901v1 by Hongxin Ding, Yue Fang, Runchuan Zhu, Xinke Jiang, Jinyang Zhang, Yongxin Xu, Xu Chu, Junfeng Zhao, Yasha Wang

Large Language Models(LLMs) excel in general tasks but struggle in
specialized domains like healthcare due to limited domain-specific
knowledge.Supervised Fine-Tuning(SFT) data construction for domain adaptation
often relies on heuristic methods, such as GPT-4 annotation or manual data
selection, with a data-centric focus on presumed diverse, high-quality
datasets. However, these methods overlook the model's inherent knowledge
distribution, introducing noise, redundancy, and irrelevant data, leading to a
mismatch between the selected data and the model's learning task, resulting in
suboptimal performance. To address this, we propose a two-stage model-centric
data selection framework, Decomposed Difficulty Data Selection (3DS), which
aligns data with the model's knowledge distribution for optimized adaptation.
In Stage1, we apply Prompt-Driven Data Selection via Explicit Alignment, where
the the model filters irrelevant or redundant data based on its internal
knowledge. In Stage2, we perform Decomposed Difficulty Data Selection, where
data selection is guided by our defined difficulty decomposition, using three
metrics: Instruction Understanding, Response Confidence, and Response
Correctness. Additionally, an attention-based importance weighting mechanism
captures token importance for more accurate difficulty calibration. This
two-stage approach ensures the selected data is not only aligned with the
model's knowledge and preferences but also appropriately challenging for the
model to learn, leading to more effective and targeted domain adaptation. In
the case study of the medical domain, our extensive experiments on real-world
healthcare datasets demonstrate the superiority of 3DS over exisiting methods
in accuracy by over 5.29%. Our dataset and code will be open-sourced at
https://anonymous.4open.science/r/3DS-E67F.

ÊëòË¶ÅÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Âú®‰∏ÄËà¨‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÂú®ÂåªÁñó‰øùÂÅ•Á≠â‰∏ì‰∏öÈ¢ÜÂüü‰∏≠Âç¥Ë°®Áé∞‰∏ç‰Ω≥ÔºåÂõ†‰∏∫Áº∫‰πèÁâπÂÆöÈ¢ÜÂüüÁöÑÁü•ËØÜ„ÄÇÈ¢ÜÂüüÈÄÇÂ∫îÁöÑÁõëÁù£ÂæÆË∞É (SFT) Êï∞ÊçÆÊûÑÂª∫ÈÄöÂ∏∏‰æùËµñÂêØÂèëÂºèÊñπÊ≥ïÔºå‰æãÂ¶Ç GPT-4 Ê≥®ÈáäÊàñÊâãÂä®Êï∞ÊçÆÈÄâÊã©ÔºåÂÖ∂Êï∞ÊçÆ‰∏≠ÂøÉÂåñÈáçÁÇπÂú®‰∫éÂÅáÂÆöÁöÑÂ§öÊ†∑Âåñ„ÄÅÈ´òË¥®ÈáèÊï∞ÊçÆÈõÜ„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÊñπÊ≥ïÂøΩÁï•‰∫ÜÊ®°ÂûãÂõ∫ÊúâÁöÑÁü•ËØÜÂàÜÂ∏ÉÔºåÂºïÂÖ•‰∫ÜÂô™Èü≥„ÄÅÂÜó‰ΩôÂíåÊó†ÂÖ≥Êï∞ÊçÆÔºåÂØºËá¥ÊâÄÈÄâÊï∞ÊçÆ‰∏éÊ®°ÂûãÁöÑÂ≠¶‰π†‰ªªÂä°‰∏çÂåπÈÖçÔºå‰ªéËÄåÂØºËá¥ÊÄßËÉΩ‰∏ç‰Ω≥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßç‰∏§Èò∂ÊÆµ‰ª•Ê®°Âûã‰∏∫‰∏≠ÂøÉÁöÑÊï∞ÊçÆÈÄâÊã©Ê°ÜÊû∂ÔºåÂç≥ÂàÜËß£ÈöæÂ∫¶Êï∞ÊçÆÈÄâÊã© (3DS)ÔºåÂÆÉ‰ΩøÊï∞ÊçÆ‰∏éÊ®°ÂûãÁöÑÁü•ËØÜÂàÜÂ∏É‰øùÊåÅ‰∏ÄËá¥Ôºå‰ª•ËøõË°å‰ºòÂåñÈÄÇÂ∫î„ÄÇÂú®Á¨¨ 1 Èò∂ÊÆµÔºåÊàë‰ª¨ÈÄöËøáÊòæÂºèÂØπÈΩêÂ∫îÁî®ÊèêÁ§∫È©±Âä®ÁöÑÂü∫‰∫éÊï∞ÊçÆÁöÑÈÄâÊã©ÔºåÂÖ∂‰∏≠Ê®°ÂûãÊ†πÊçÆÂÖ∂ÂÜÖÈÉ®Áü•ËØÜËøáÊª§Êó†ÂÖ≥ÊàñÂÜó‰ΩôÁöÑÊï∞ÊçÆ„ÄÇÂú®Á¨¨ 2 Èò∂ÊÆµÔºåÊàë‰ª¨ÊâßË°åÂàÜËß£ÈöæÂ∫¶Êï∞ÊçÆÈÄâÊã©ÔºåÂÖ∂‰∏≠Êï∞ÊçÆÈÄâÊã©Áî±Êàë‰ª¨ÂÆö‰πâÁöÑÈöæÂ∫¶ÂàÜËß£ÊåáÂØºÔºå‰ΩøÁî®‰∏â‰∏™ÊåáÊ†áÔºöÊåá‰ª§ÁêÜËß£„ÄÅÂìçÂ∫îÁΩÆ‰ø°Â∫¶ÂíåÂìçÂ∫îÊ≠£Á°ÆÊÄß„ÄÇÊ≠§Â§ñÔºåÂü∫‰∫éÊ≥®ÊÑèÂäõÁöÑÈáçË¶ÅÊÄßÂä†ÊùÉÊú∫Âà∂ÊçïËé∑Ê†áËÆ∞ÈáçË¶ÅÊÄßÔºå‰ª•‰æøÊõ¥ÂáÜÁ°ÆÂú∞Ê†°ÂáÜÈöæÂ∫¶„ÄÇËøôÁßç‰∏§Èò∂ÊÆµÊñπÊ≥ïÁ°Æ‰øùÊâÄÈÄâÊï∞ÊçÆ‰∏ç‰ªÖ‰∏éÊ®°ÂûãÁöÑÁü•ËØÜÂíåÂÅèÂ•Ω‰øùÊåÅ‰∏ÄËá¥ÔºåËÄå‰∏îÂØπÊ®°ÂûãÂ≠¶‰π†ËÄåË®Ä‰πüÂÖ∑ÊúâÈÄÇÂΩìÁöÑÊåëÊàòÊÄßÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÊúâÊïàÂíåÊõ¥ÊúâÈíàÂØπÊÄßÁöÑÈ¢ÜÂüüÈÄÇÂ∫î„ÄÇÂú®ÂåªÂ≠¶È¢ÜÂüüÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨Âú®ÁúüÂÆû‰∏ñÁïåÂåªÁñó‰øùÂÅ•Êï∞ÊçÆÈõÜ‰∏äËøõË°åÁöÑÂπøÊ≥õÂÆûÈ™åË°®ÊòéÔºå3DS Âú®ÂáÜÁ°ÆÊÄßÊñπÈù¢ÊØîÁé∞ÊúâÊñπÊ≥ïÈ´òÂá∫ 5.29%„ÄÇÊàë‰ª¨ÁöÑÊï∞ÊçÆÈõÜÂíå‰ª£Á†ÅÂ∞ÜÂú® https://anonymous.4open.science/r/3DS-E67F ÂºÄÊ∫ê„ÄÇ

##### **Multimodal Physical Activity Forecasting in Free-Living Clinical Settings: Hunting Opportunities for Just-in-Time Interventions**
2410.09643v1 by Abdullah Mamun, Krista S. Leonard, Megan E. Petrov, Matthew P. Buman, Hassan Ghasemzadeh

Objective: This research aims to develop a lifestyle intervention system,
called MoveSense, that forecasts a patient's activity behavior to allow for
early and personalized interventions in real-world clinical environments.
Methods: We conducted two clinical studies involving 58 prediabetic veterans
and 60 patients with obstructive sleep apnea to gather multimodal behavioral
data using wearable devices. We develop multimodal long short-term memory
(LSTM) network models, which are capable of forecasting the number of step
counts of a patient up to 24 hours in advance by examining data from activity
and engagement modalities. Furthermore, we design goal-based forecasting models
to predict whether a person's next-day steps will be over a certain threshold.
Results: Multimodal LSTM with early fusion achieves 33% and 37% lower mean
absolute errors than linear regression and ARIMA respectively on the
prediabetes dataset. LSTM also outperforms linear regression and ARIMA with a
margin of 13% and 32% on the sleep dataset. Multimodal forecasting models also
perform with 72% and 79% accuracy on the prediabetes dataset and sleep dataset
respectively on goal-based forecasting. Conclusion: Our experiments conclude
that multimodal LSTM models with early fusion are better than multimodal LSTM
with late fusion and unimodal LSTM models and also than ARIMA and linear
regression models. Significance: We address an important and challenging task
of time-series forecasting in uncontrolled environments. Effective forecasting
of a person's physical activity can aid in designing adaptive behavioral
interventions to keep the user engaged and adherent to a prescribed routine.

ÊëòË¶ÅÔºöÁõÆÊ®ôÔºöÊú¨Á†îÁ©∂Êó®Âú®ÈñãÁôº‰∏ÄÁ®ÆÁîüÊ¥ªÂûãÊÖã‰ªãÂÖ•Á≥ªÁµ±ÔºåÁ®±ÁÇ∫ MoveSenseÔºåÂèØÈ†êÊ∏¨ÁóÖÊÇ£ÁöÑÊ¥ªÂãïË°åÁÇ∫Ôºå‰ª•‰æøÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÊó©Êúü‰∏îÂÄã‰∫∫ÂåñÁöÑ‰ªãÂÖ•„ÄÇ
ÊñπÊ≥ïÔºöÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÖ©È†ÖËá®Â∫äÁ†îÁ©∂ÔºåÊ∂âÂèä 58 ‰ΩçÁ≥ñÂ∞øÁóÖÂâçÊúüÈÄÄ‰ºçËªç‰∫∫Âíå 60 ‰ΩçÈòªÂ°ûÊÄßÁù°Áú†ÂëºÂê∏‰∏≠Ê≠¢ÁóáÊÇ£ËÄÖÔºå‰ª•‰ΩøÁî®Á©øÊà¥ÂºèË£ùÁΩÆÊî∂ÈõÜÂ§öÊ®°ÂºèË°åÁÇ∫Êï∏Êìö„ÄÇÊàëÂÄëÈñãÁôº‰∫ÜÂ§öÊ®°ÂºèÈï∑Áü≠ÊúüË®òÊÜ∂ (LSTM) Á∂≤Ë∑ØÊ®°ÂûãÔºåÂÆÉËÉΩÂ§†ÈÄèÈÅéÊ™¢Êü•Ê¥ªÂãïÂíåÂèÉËàáÊ®°ÂºèÁöÑÊï∏ÊìöÔºåÈ†êÊ∏¨ÁóÖÊÇ£Âú® 24 Â∞èÊôÇÂÖßË∏èÂá∫ÁöÑÊ≠•Êï∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∫ÜÂü∫ÊñºÁõÆÊ®ôÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºå‰ª•È†êÊ∏¨Êüê‰∫∫ÁöÑÈöîÊó•Ê≠•Êï∏ÊòØÂê¶ÊúÉË∂ÖÈÅéÊüêÂÄãÈñæÂÄº„ÄÇ
ÁµêÊûúÔºöÂ§öÊ®°Âºè LSTM ËàáÊó©ÊúüËûçÂêàÂú®Á≥ñÂ∞øÁóÖÂâçÊúüÊï∏ÊìöÈõÜ‰∏äÂØ¶ÁèæÁöÑÂπ≥ÂùáÁµïÂ∞çË™§Â∑ÆÊØîÁ∑öÊÄßÂõûÊ≠∏Âíå ARIMA ÂàÜÂà•‰Ωé 33% Âíå 37%„ÄÇLSTM Âú®Áù°Áú†Êï∏ÊìöÈõÜ‰∏ä‰πü‰ª• 13% Âíå 32% ÁöÑÂπÖÂ∫¶ÂÑ™ÊñºÁ∑öÊÄßÂõûÊ≠∏Âíå ARIMA„ÄÇÂ§öÊ®°ÂºèÈ†êÊ∏¨Ê®°ÂûãÂú®Á≥ñÂ∞øÁóÖÂâçÊúüÊï∏ÊìöÈõÜÂíåÁù°Áú†Êï∏ÊìöÈõÜ‰∏ä‰πüÂàÜÂà•‰ª• 72% Âíå 79% ÁöÑÊ∫ñÁ¢∫Â∫¶Âü∑Ë°åÂü∫ÊñºÁõÆÊ®ôÁöÑÈ†êÊ∏¨„ÄÇÁµêË´ñÔºöÊàëÂÄëÁöÑÂØ¶È©óÂæóÂá∫ÁµêË´ñÔºåÂÖ∑ÊúâÊó©ÊúüËûçÂêàÁöÑÂ§öÊ®°Âºè LSTM Ê®°ÂûãÊØîÂÖ∑ÊúâÂæåÊúüËûçÂêàÁöÑÂ§öÊ®°Âºè LSTM Ê®°ÂûãÂíåÂñÆÊ®°Âºè LSTM Ê®°ÂûãÊõ¥Â•ΩÔºå‰πüÊØî ARIMA ÂíåÁ∑öÊÄßÂõûÊ≠∏Ê®°ÂûãÊõ¥Â•Ω„ÄÇÊÑèÁæ©ÔºöÊàëÂÄëËß£Ê±∫‰∫ÜÂú®‰∏çÂèóÊéßÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨ÁöÑ‰∏ÄÈ†ÖÈáçË¶Å‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÊúâÊïàÈ†êÊ∏¨ÂÄã‰∫∫ÁöÑË∫´È´îÊ¥ªÂãïÊúâÂä©ÊñºË®≠Ë®àÈÅ©ÊáâÊÄßË°åÁÇ∫‰ªãÂÖ•Êé™ÊñΩÔºå‰ª•‰øùÊåÅ‰ΩøÁî®ËÄÖÂèÉËàá‰∏¶ÈÅµÂÆàË¶èÂÆöÁöÑ‰æãË°åÂÖ¨‰∫ã„ÄÇ

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

ÊëòË¶ÅÔºöÁî¢Á®ã‰∏≠È¢®Èö™ÁöÑÊó©ÊúüÂÅµÊ∏¨ÊúâÂä©ÊñºÈÄ≤Ë°åÂπ≤È†êÊé™ÊñΩÔºå‰ª•È†êÈò≤ÊàñÊ∏õËºï‰∏çÂà©ÁöÑÁîüÁî¢ÁµêÊûúÔºå‰æãÂ¶ÇËÖ¶ÊÄßÈ∫ªÁó∫„ÄÇÁõÆÂâçÔºåÊ≤íÊúâÊ∫ñÁ¢∫ÁöÑËá™ÂãïÂåñÁ≥ªÁµ±ÂèØ‰ª•È†êÊ∏¨Ê≠§È°û‰∫ã‰ª∂Ôºå‰ª•ÂçîÂä©Ëá®Â∫äÊ±∫Á≠ñ„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩÔºåÊàëÂÄëÊèêÂá∫„ÄåÁî®ÊñºÂª∫Ê®°ÂíåËß£ÈáãÊñ∞ÁîüÂÖíÂÅ•Â∫∑ÁöÑ‰∫∫Â∑•Êô∫ÊÖß„Äç(AIMEN)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÔºåÂÆÉ‰∏çÂÉÖÂèØ‰ª•Ê†πÊìöÂ≠ïÁî¢Â©¶„ÄÅËÉéÂÖí„ÄÅÁî¢ÁßëÂíåÁî¢Á®ãÈ¢®Èö™Âõ†Á¥†È†êÊ∏¨‰∏çÂà©ÁöÑÁîüÁî¢ÁµêÊûúÔºåÈÇÑËÉΩÊèê‰æõÊ®°ÂûãÂÅöÂá∫È†êÊ∏¨ËÉåÂæåÁöÑÂéüÂõ†„ÄÇÂæåËÄÖÂèØ‰ª•Êèê‰æõË¶ãËß£ÔºåË™™ÊòéÊ®°ÂûãËº∏ÂÖ•ËÆäÊï∏‰∏≠ÁöÑÂì™‰∫õ‰øÆÊîπÂèØËÉΩÊúÉÊîπËÆäÈ†êÊ∏¨ÁµêÊûú„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî®ÈÅ©ÊáâÊÄßÂêàÊàêÊäΩÊ®£ (ADASYN) ÂíåÊ¢ù‰ª∂Ë°®Ê†ºÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (CTGAN) ‰æÜÂêàÊàêÈ°çÂ§ñÁöÑË®ìÁ∑¥Ë≥áÊñôÔºå‰ª•Ëß£Ê±∫‰∏çÂπ≥Ë°°ÂíåÂ∞èÂûãË≥áÊñôÈõÜÁöÑÊåëÊà∞„ÄÇAIMEN ‰ΩøÁî®ÂÖ®ÈÄ£Êé•Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÈõÜÂêà‰ΩúÁÇ∫ÂÖ∂ÂàÜÈ°ûÁöÑÈ™®ÂππÔºå‰∏¶ÈÄèÈÅé ADASYN Êàñ CTGAN ÊîØÊè¥Ë≥áÊñôÊì¥ÂÖÖ„ÄÇÁî± CTGAN ÊîØÊè¥ÁöÑ AIMEN Âú®ÂàÜÈ°ûÊñπÈù¢ÂÑ™ÊñºÁî± ADASYN ÊîØÊè¥ÁöÑ AIMEN„ÄÇAIMEN ÂèØ‰ª•È†êÊ∏¨‰∏çÂà©ÁöÑÁîüÁî¢ÁµêÊûúÁöÑÈ´òÈ¢®Èö™ÔºåÂπ≥Âùá F1 ÂàÜÊï∏ÁÇ∫ 0.784„ÄÇÂÆÉÈÇÑÊèê‰æõÂèç‰∫ãÂØ¶Ëß£ÈáãÔºåÂèØÈÄèÈÅéÂπ≥ÂùáËÆäÊõ¥ 2 Ëá≥ 3 ÂÄãÂ±¨ÊÄß‰æÜÈÅîÊàê„ÄÇÂèØÁî®Ë≥áÊ∫êÔºöhttps://github.com/ab9mamun/AIMEN„ÄÇ

##### **AuD-Former: A Hierarchical Transformer Network for Multimodal Audio-Based Disease Prediction**
2410.09289v1 by Jinjin Cai, Ruiqi Wang, Dezhong Zhao, Ziqin Yuan, Victoria McKenna, Aaron Friedman, Rachel Foot, Susan Storey, Ryan Boente, Sudip Vhaduri, Byung-Cheol Min

Audio-based disease prediction is emerging as a promising supplement to
traditional medical diagnosis methods, facilitating early, convenient, and
non-invasive disease detection and prevention. Multimodal fusion, which
integrates features from various domains within or across bio-acoustic
modalities, has proven effective in enhancing diagnostic performance. However,
most existing methods in the field employ unilateral fusion strategies that
focus solely on either intra-modal or inter-modal fusion. This approach limits
the full exploitation of the complementary nature of diverse acoustic feature
domains and bio-acoustic modalities. Additionally, the inadequate and isolated
exploration of latent dependencies within modality-specific and modality-shared
spaces curtails their capacity to manage the inherent heterogeneity in
multimodal data. To fill these gaps, we propose AuD-Former, a hierarchical
transformer network designed for general multimodal audio-based disease
prediction. Specifically, we seamlessly integrate intra-modal and inter-modal
fusion in a hierarchical manner and proficiently encode the necessary
intra-modal and inter-modal complementary correlations, respectively.
Comprehensive experiments demonstrate that AuD-Former achieves state-of-the-art
performance in predicting three diseases: COVID-19, Parkinson's disease, and
pathological dysarthria, showcasing its promising potential in a broad context
of audio-based disease prediction tasks. Additionally, extensive ablation
studies and qualitative analyses highlight the significant benefits of each
main component within our model.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÈü≥Ë®äÁöÑÁñæÁóÖÈ†êÊ∏¨Ê≠£ÈÄêÊº∏ÊàêÁÇ∫ÂÇ≥Áµ±ÈÜ´ÁôÇË®∫Êñ∑ÊñπÊ≥ïÁöÑÊúâÂäõË£úÂÖÖÔºåÊúâÂä©ÊñºÊó©Êúü„ÄÅ‰æøÂà©‰∏îÈùû‰æµÂÖ•ÂºèÂú∞ÂÅµÊ∏¨ÂíåÈ†êÈò≤ÁñæÁóÖ„ÄÇÂ§öÊ®°ÊÖãËûçÂêàÊï¥Âêà‰æÜËá™ÁîüÁâ©ËÅ≤Â≠∏Ê®°ÂºèÂÖßÈÉ®ÊàñË∑®Ê®°ÂºèÁöÑÂêÑÁ®ÆÈ†òÂüüÁöÑÁâπÂæµÔºåÂ∑≤Ë¢´Ë≠âÂØ¶ËÉΩÊúâÊïàÊèêÂçáË®∫Êñ∑ÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÂ§ßÂ§öÊï∏ÊñπÊ≥ïÊé°Áî®ÂñÆÈÇäËûçÂêàÁ≠ñÁï•ÔºåÂÉÖÂ∞àÊ≥®ÊñºÊ®°ÂºèÂÖßÊàñÊ®°ÂºèÈñìËûçÂêà„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈôêÂà∂‰∫ÜÂ∞ç‰∏çÂêåËÅ≤Â≠∏ÁâπÂæµÈ†òÂüüÂíåÁîüÁâ©ËÅ≤Â≠∏Ê®°ÂºèÁöÑ‰∫íË£úÁâπÊÄßÁöÑÂÖÖÂàÜÂà©Áî®„ÄÇÊ≠§Â§ñÔºåÂ∞çÊ®°ÂºèÁâπÂÆöÂíåÊ®°ÂºèÂÖ±‰∫´Á©∫ÈñìÂÖßÊΩõÂú®‰æùË≥¥ÊÄß‰∏çË∂≥‰∏îÂ≠§Á´ãÁöÑÊé¢Á¥¢Ôºå‰πüÈôêÂà∂‰∫ÜÂÖ∂ÁÆ°ÁêÜÂ§öÊ®°ÊÖãË≥áÊñô‰∏≠Âõ∫ÊúâÁï∞Ë≥™ÊÄßÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄô‰∫õÁ©∫ÁôΩÔºåÊàëÂÄëÊèêÂá∫ AuD-FormerÔºå‰∏ÄÂÄãÈöéÂ±§ÂºèTransformerÁ∂≤Ë∑ØÔºåÂ∞àÁÇ∫‰∏ÄËà¨Â§öÊ®°ÊÖãÂü∫ÊñºÈü≥Ë®äÁöÑÁñæÁóÖÈ†êÊ∏¨ËÄåË®≠Ë®à„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ª•ÈöéÂ±§ÊñπÂºèÁÑ°Á∏´Êï¥ÂêàÊ®°ÂºèÂÖßÂíåÊ®°ÂºèÈñìËûçÂêàÔºå‰∏¶ÂàÜÂà•ÁÜüÁ∑¥Âú∞Á∑®Á¢ºÂøÖË¶ÅÁöÑÊ®°ÂºèÂÖßÂíåÊ®°ÂºèÈñì‰∫íË£úÈóúËÅØ„ÄÇÂÖ®Èù¢ÁöÑÂØ¶È©óË≠âÊòéÔºåAuD-Former Âú®È†êÊ∏¨‰∏âÁ®ÆÁñæÁóÖÔºàCOVID-19„ÄÅÂ∏ïÈáëÊ£ÆÊ∞èÁóáÂíåÁóÖÁêÜÊÄßÊßãÈü≥ÈöúÁ§ôÔºâÊñπÈù¢ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®Âª£Ê≥õÁöÑÂü∫ÊñºÈü≥Ë®äÁöÑÁñæÁóÖÈ†êÊ∏¨‰ªªÂãô‰∏≠ÁöÑÊΩõÂäõ„ÄÇÊ≠§Â§ñÔºåÂª£Ê≥õÁöÑÊ∂àËûçÁ†îÁ©∂ÂíåÂÆöÊÄßÂàÜÊûêÁ™ÅÂá∫‰∫ÜÊàëÂÄëÊ®°Âûã‰∏≠ÊØèÂÄã‰∏ªË¶ÅÁµÑÊàêÁöÑÈ°ØËëóÂÑ™Èªû„ÄÇ</paragraph>

##### **LLMD: A Large Language Model for Interpreting Longitudinal Medical Records**
2410.12860v1 by Robert Porter, Adam Diehl, Benjamin Pastel, J. Henry Hinnefeld, Lawson Nerenberg, Pye Maung, Sebastien Kerbrat, Gillian Hanson, Troy Astorino, Stephen J. Tarsa

We introduce LLMD, a large language model designed to analyze a patient's
medical history based on their medical records. Along with domain knowledge,
LLMD is trained on a large corpus of records collected over time and across
facilities, as well as tasks and labels that make nuanced connections among
them. This approach is critical to an accurate picture of patient health, and
has distinctive advantages over models trained on knowledge alone, unlabeled
records, structured EHR data, or records from a single health system.
  The recipe for LLMD continues pretraining a foundational model on both domain
knowledge and the contents of millions of records. These span an average of 10
years of care and as many as 140 care sites per patient. LLMD is then
instruction fine-tuned on structuring and abstraction tasks. The former jointly
identify and normalize document metadata, provenance information, clinical
named-entities, and ontology mappings, while the latter roll these into
higher-level representations, such a continuous era of time a patient was on a
medication. LLMD is deployed within a layered validation system that includes
continual random audits and review by experts, e.g. based on uncertainty,
disease-specific rules, or use-case.
  LLMD exhibits large gains over both more-powerful generalized models and
domain-specific models. On medical knowledge benchmarks, LLMD-8B achieves state
of the art accuracy on PubMedQA text responses, besting orders-of-magnitude
larger models. On production tasks, we show that LLMD significantly outperforms
all other models evaluated, and among alternatives, large general purpose LLMs
like GPT-4o are more accurate than models emphasizing medical knowledge. We
find strong evidence that accuracy on today's medical benchmarks is not the
most significant factor when analyzing real-world patient data, an insight with
implications for future medical LLMs.'

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÂºïÂÖ•‰∫Ü LLMDÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÊó®Âú®Ê†πÊìöÁóÖÊ≠∑ÂàÜÊûêÊÇ£ËÄÖÁöÑÁóÖÂè≤„ÄÇÈô§‰∫ÜÈ†òÂüüÁü•Ë≠òÂ§ñÔºåLLMD ÈÇÑÊé•Âèó‰∫ÜÂ§ßÈáèÈö®ËëóÊôÇÈñìÊé®ÁßªÂíåË∑®Ë®≠ÊñΩÊî∂ÈõÜÁöÑË®òÈåÑÁöÑË®ìÁ∑¥Ôºå‰ª•ÂèäÂú®ÂÆÉÂÄë‰πãÈñìÂª∫Á´ãÁ¥∞ÂæÆËÅØÁπ´ÁöÑ‰ªªÂãôÂíåÊ®ôÁ±§„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∞çÊñºÊ∫ñÁ¢∫ÊèèÁπ™ÊÇ£ËÄÖÂÅ•Â∫∑ÁãÄÊ≥ÅËá≥ÈóúÈáçË¶ÅÔºå‰∏¶‰∏îËàáÂÉÖÊé•ÂèóÁü•Ë≠òË®ìÁ∑¥ÁöÑÊ®°Âûã„ÄÅÊú™Ê®ôË®òË®òÈåÑ„ÄÅÁµêÊßãÂåñÁöÑ EHR Êï∏ÊìöÊàñ‰æÜËá™ÂñÆ‰∏ÄÂÅ•Â∫∑Á≥ªÁµ±ÁöÑË®òÈåÑÁõ∏ÊØîÔºåÂÖ∑ÊúâÈ°ØËëóÂÑ™Âã¢„ÄÇ
LLMD ÁöÑÁßòË®£ÊòØÂ∞çÂü∫Á§éÊ®°ÂûãÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÔºåÊó¢ÂåÖÊã¨È†òÂüüÁü•Ë≠òÔºå‰πüÂåÖÊã¨Êï∏ÁôæËê¨Ê¢ùË®òÈåÑÁöÑÂÖßÂÆπ„ÄÇÈÄô‰∫õË®òÈåÑÂπ≥ÂùáÊ∂µËìã‰∫ÜÊØè‰ΩçÊÇ£ËÄÖ 10 Âπ¥ÁöÑË≠∑ÁêÜÊôÇÈñìÂíåÂ§öÈÅî 140 ÂÄãË≠∑ÁêÜÂú∞Èªû„ÄÇÁÑ∂ÂæåÂ∞ç LLMD ÈÄ≤Ë°åÁµêÊßãÂåñÂíåÊäΩË±°‰ªªÂãôÁöÑÊåá‰ª§ÂæÆË™ø„ÄÇÂâçËÄÖÂÖ±ÂêåË≠òÂà•ÂíåÊ®ôÊ∫ñÂåñÊñáÊ™îÂÖÉÊï∏Êìö„ÄÅ‰æÜÊ∫ê‰ø°ÊÅØ„ÄÅËá®Â∫äÂëΩÂêçÂØ¶È´îÂíåÊú¨‰ΩìÊò†Â∞ÑÔºåËÄåÂæåËÄÖÂ∞áÈÄô‰∫õÂÖßÂÆπËΩâÊèõÁÇ∫Êõ¥È´òÁ¥öÂà•ÁöÑË°®Á§∫Ôºå‰æãÂ¶ÇÊÇ£ËÄÖÊúçËó•ÁöÑÈÄ£Á∫åÊôÇÈñìÊÆµ„ÄÇLLMD Âú®‰∏ÄÂÄãÂàÜÂ±§È©óË≠âÁ≥ªÁµ±‰∏≠ÈÉ®ÁΩ≤ÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÊåÅÁ∫åÁöÑÈö®Ê©üÂØ©Ê†∏ÂíåÂ∞àÂÆ∂ÂØ©Êü•Ôºå‰æãÂ¶ÇÂü∫Êñº‰∏çÁ¢∫ÂÆöÊÄß„ÄÅÁâπÂÆöÁñæÁóÖË¶èÂâáÊàñÁî®‰æã„ÄÇ
LLMD Âú®ÂäüËÉΩÊõ¥Âº∑Â§ßÁöÑÈÄöÁî®Ê®°ÂûãÂíåÁâπÂÆöÈ†òÂüüÊ®°ÂûãÊñπÈù¢ÈÉΩË°®ÁèæÂá∫Â∑®Â§ßÁöÑÂÑ™Âã¢„ÄÇÂú®ÈÜ´Â≠∏Áü•Ë≠òÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÔºåLLMD-8B Âú® PubMedQA ÊñáÊú¨ÈüøÊáâÊñπÈù¢ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÂÑ™ÊñºÊï∏ÈáèÁ¥öÊõ¥Â§ßÁöÑÊ®°Âûã„ÄÇÂú®ÁîüÁî¢‰ªªÂãô‰∏≠ÔºåÊàëÂÄëË°®Êòé LLMD ÊòéÈ°ØÂÑ™ÊñºÊâÄÊúâÂÖ∂‰ªñË©ï‰º∞Ê®°ÂûãÔºå‰∏¶‰∏îÂú®Êõø‰ª£ÊñπÊ°à‰∏≠ÔºåÂÉè GPT-4o ÈÄôÊ®£ÁöÑÂ§ßÂûãÈÄöÁî® LLM ÊØîÂº∑Ë™øÈÜ´Â≠∏Áü•Ë≠òÁöÑÊ®°ÂûãÊõ¥Ê∫ñÁ¢∫„ÄÇÊàëÂÄëÁôºÁèæÂº∑ÊúâÂäõÁöÑË≠âÊìöË°®ÊòéÔºåÂú®ÂàÜÊûêÁèæÂØ¶‰∏ñÁïåÁöÑÊÇ£ËÄÖÊï∏ÊìöÊôÇÔºåÁï∂‰ªäÈÜ´Â≠∏Âü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÊ∫ñÁ¢∫ÊÄß‰∏¶ÈùûÊúÄÈáçË¶ÅÁöÑÂõ†Á¥†ÔºåÈÄôÂ∞çÊú™‰æÜÁöÑÈÜ´Â≠∏ LLM ‰πüÊúâÂΩ±Èüø„ÄÇ</paragraph>

##### **Large Language Models for Medical OSCE Assessment: A Novel Approach to Transcript Analysis**
2410.12858v1 by Ameer Hamza Shakur, Michael J. Holcomb, David Hein, Shinyoung Kang, Thomas O. Dalton, Krystle K. Campbell, Daniel J. Scott, Andrew R. Jamieson

Grading Objective Structured Clinical Examinations (OSCEs) is a
time-consuming and expensive process, traditionally requiring extensive manual
effort from human experts. In this study, we explore the potential of Large
Language Models (LLMs) to assess skills related to medical student
communication. We analyzed 2,027 video-recorded OSCE examinations from the
University of Texas Southwestern Medical Center (UTSW), spanning four years
(2019-2022), and several different medical cases or "stations." Specifically,
our focus was on evaluating students' ability to summarize patients' medical
history: we targeted the rubric item 'did the student summarize the patients'
medical history?' from the communication skills rubric. After transcribing
speech audio captured by OSCE videos using Whisper-v3, we studied the
performance of various LLM-based approaches for grading students on this
summarization task based on their examination transcripts. Using various
frontier-level open-source and proprietary LLMs, we evaluated different
techniques such as zero-shot chain-of-thought prompting, retrieval augmented
generation, and multi-model ensemble methods. Our results show that frontier
LLM models like GPT-4 achieved remarkable alignment with human graders,
demonstrating a Cohen's kappa agreement of 0.88 and indicating strong potential
for LLM-based OSCE grading to augment the current grading process. Open-source
models also showed promising results, suggesting potential for widespread,
cost-effective deployment. Further, we present a failure analysis identifying
conditions where LLM grading may be less reliable in this context and recommend
best practices for deploying LLMs in medical education settings.

ÊëòË¶ÅÔºöË©ïÂàÜÂÆ¢ËßÄÁµêÊßãÂºèËá®Â∫äËÄÉË©¶ (OSCE) ÊòØÂÄãËÄóÊôÇÂèàÊòÇË≤¥ÁöÑÈÅéÁ®ãÔºåÂÇ≥Áµ±‰∏äÈúÄË¶Å‰∫∫È°ûÂ∞àÂÆ∂Â§ßÈáèÊâãÂãïÂ∑•‰Ωú„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ë©ï‰º∞ËàáÈÜ´Â≠∏ÁîüÊ∫ùÈÄöÁõ∏ÈóúÊäÄËÉΩÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÂàÜÊûê‰∫ÜÂæ∑ÂÖãËñ©ÊñØÂ§ßÂ≠∏Ë•øÂçóÈÜ´Â≠∏‰∏≠ÂøÉ (UTSW) 2,027 Â†¥ÈåÑË£ΩÁöÑ OSCE ËÄÉË©¶ÔºåÊôÇÈñìË∑®Â∫¶ÁÇ∫ÂõõÂπ¥ (2019-2022)ÔºåÊ∂µËìã‰∫ÜÊï∏ÂÄã‰∏çÂêåÁöÑÈÜ´ÁôÇÊ°à‰æãÊàñ„ÄåÁ´ô„Äç„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºË©ï‰º∞Â≠∏ÁîüÁ∏ΩÁµêÁóÖÊ≠∑ÁöÑËÉΩÂäõÔºöÊàëÂÄë‰ª•Ê∫ùÈÄöÊäÄËÉΩË©ïÂàÜÊ®ôÊ∫ñ‰∏≠ÁöÑË©ïÂàÜÈ†ÖÁõÆ„ÄåÂ≠∏ÁîüÊòØÂê¶Á∏ΩÁµê‰∫ÜÁóÖ‰∫∫ÁöÑÁóÖÊ≠∑Ôºü„ÄçÁÇ∫ÁõÆÊ®ô„ÄÇÂú®‰ΩøÁî® Whisper-v3 ËΩâÈåÑ OSCE ÂΩ±ÁâáÊâÄÊì∑ÂèñÁöÑË™ûÈü≥Èü≥Ë®äÂæåÔºåÊàëÂÄëÁ†îÁ©∂‰∫ÜÂêÑÁ®ÆÂü∫Êñº LLM ÁöÑÊñπÊ≥ïÂú®Ë©ïÂàÜÂ≠∏ÁîüÊ≠§È†ÖÊëòË¶Å‰ªªÂãôÔºàÊ†πÊìöÂÖ∂ËÄÉË©¶ÊàêÁ∏æÂñÆÔºâÊñπÈù¢ÁöÑË°®Áèæ„ÄÇÊàëÂÄë‰ΩøÁî®ÂêÑÁ®ÆÂâçÊ≤øÁöÑÈñãÊ∫êÂíåÂ∞àÊúâ LLMÔºåË©ï‰º∞‰∫Ü‰∏çÂêåÁöÑÊäÄË°ìÔºå‰æãÂ¶ÇÈõ∂Ê¨°Â≠∏ÁøíÊÄùËÄÉÈèàÊèêÁ§∫„ÄÅÊ™¢Á¥¢Âº∑ÂåñÁîüÊàêÂíåÂ§öÊ®°ÂûãÈõÜÊàêÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåGPT-4 Á≠âÂâçÊ≤ø LLM Ê®°ÂûãËàá‰∫∫È°ûË©ïÂàÜËÄÖÈÅîÊàê‰∫ÜÈ°ØËëóÁöÑ‰∏ÄËá¥ÊÄßÔºåÂ±ïÁ§∫‰∫Ü 0.88 ÁöÑ Cohen kappa ‰∏ÄËá¥ÊÄßÔºå‰∏¶È°ØÁ§∫‰∫ÜÂü∫Êñº LLM ÁöÑ OSCE Ë©ïÂàÜÂú®Êì¥ÂÖÖÁèæË°åË©ïÂàÜÊµÅÁ®ãÊñπÈù¢ÂÖ∑ÊúâÂº∑Â§ßÁöÑÊΩõÂäõ„ÄÇÈñãÊ∫êÊ®°Âûã‰πüÈ°ØÁ§∫‰∫ÜÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÈ°ØÁ§∫‰∫ÜÂª£Ê≥õ„ÄÅÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÈÉ®ÁΩ≤ÊΩõÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ§±ÊïóÂàÜÊûêÔºåË≠òÂà•Âá∫ LLM Ë©ïÂàÜÂú®Ê≠§ÊÉÖÊ≥Å‰∏ãÂèØËÉΩËºÉ‰∏çÂèØÈù†ÁöÑÊ¢ù‰ª∂Ôºå‰∏¶Âª∫Ë≠∞Âú®ÈÜ´Â≠∏ÊïôËÇ≤Áí∞Â¢É‰∏≠ÈÉ®ÁΩ≤ LLM ÁöÑÊúÄ‰Ω≥ÂØ¶Âãô„ÄÇ

##### **Optimized Biomedical Question-Answering Services with LLM and Multi-BERT Integration**
2410.12856v1 by Cheng Qian, Xianglong Shi, Shanshan Yao, Yichen Liu, Fengming Zhou, Zishu Zhang, Junaid Akram, Ali Braytee, Ali Anaissi

We present a refined approach to biomedical question-answering (QA) services
by integrating large language models (LLMs) with Multi-BERT configurations. By
enhancing the ability to process and prioritize vast amounts of complex
biomedical data, this system aims to support healthcare professionals in
delivering better patient outcomes and informed decision-making. Through
innovative use of BERT and BioBERT models, combined with a multi-layer
perceptron (MLP) layer, we enable more specialized and efficient responses to
the growing demands of the healthcare sector. Our approach not only addresses
the challenge of overfitting by freezing one BERT model while training another
but also improves the overall adaptability of QA services. The use of extensive
datasets, such as BioASQ and BioMRC, demonstrates the system's ability to
synthesize critical information. This work highlights how advanced language
models can make a tangible difference in healthcare, providing reliable and
responsive tools for professionals to manage complex information, ultimately
serving the broader goal of improved care and data-driven insights.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ≤æÈÄ≤ÁöÑÊñπÊ≥ï‰æÜÈÄ≤Ë°åÁîüÁâ©ÈÜ´Â≠∏ÂïèÈ°åËß£Á≠î (QA) ÊúçÂãôÔºåÊñπÊ≥ïÊòØÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëàá Multi-BERT ÁµÑÊÖãÊï¥ÂêàÂú®‰∏ÄËµ∑„ÄÇÈÄèÈÅéÂä†Âº∑ËôïÁêÜÂíåÂÑ™ÂÖàËôïÁêÜÂ§ßÈáèË§áÈõúÁîüÁâ©ÈÜ´Â≠∏Ë≥áÊñôÁöÑËÉΩÂäõÔºåÊ≠§Á≥ªÁµ±Êó®Âú®ÂçîÂä©ÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°Êèê‰æõÊõ¥Â•ΩÁöÑÊÇ£ËÄÖÁµêÊûúÂíåÊòéÊô∫ÁöÑÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÈÄèÈÅéÂâµÊñ∞‰ΩøÁî® BERT Âíå BioBERT Ê®°ÂûãÔºå‰∏¶ÁµêÂêàÂ§öÂ±§ÊÑüÁü•Âô® (MLP) Â±§ÔºåÊàëÂÄëËÉΩÂ§†ÈáùÂ∞çÈÜ´ÁôÇ‰øùÂÅ•ÈÉ®ÈñÄÊó•ÁõäÂ¢ûÈï∑ÁöÑÈúÄÊ±ÇÊèê‰æõÊõ¥Â∞àÊ•≠‰∏îÊõ¥ÊúâÊïàÁéáÁöÑÂõûÊáâ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÂÉÖÈÄèÈÅéÂáçÁµê‰∏ÄÂÄã BERT Ê®°Âûã‰∏¶Ë®ìÁ∑¥Âè¶‰∏ÄÂÄãÊ®°Âûã‰æÜËß£Ê±∫ÈÅéÂ∫¶Êì¨ÂêàÁöÑÊåëÊà∞ÔºåÂêåÊôÇ‰πüÊîπÂñÑ‰∫Ü QA ÊúçÂãôÁöÑÊï¥È´îÈÅ©ÊáâÊÄß„ÄÇ‰ΩøÁî®Âª£Ê≥õÁöÑË≥áÊñôÈõÜÔºå‰æãÂ¶Ç BioASQ Âíå BioMRCÔºåË≠âÊòé‰∫ÜË©≤Á≥ªÁµ±Á∂úÂêàÈáçË¶ÅË≥áË®äÁöÑËÉΩÂäõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂº∑Ë™ø‰∫ÜÈÄ≤ÈöéË™ûË®ÄÊ®°ÂûãÂ¶Ç‰ΩïËÉΩÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠Áî¢ÁîüÂÖ∑È´îÂ∑ÆÁï∞ÔºåÁÇ∫Â∞àÊ•≠‰∫∫Âì°Êèê‰æõÂèØÈù†‰∏îÂÖ∑ÂõûÊáâÊÄßÁöÑÂ∑•ÂÖ∑‰æÜÁÆ°ÁêÜË§áÈõúË≥áË®äÔºåÊúÄÁµÇÊúçÂãôÊñºÊîπÂñÑÁÖßË≠∑ÂíåË≥áÊñôÈ©ÖÂãïË¶ãËß£ÁöÑÊõ¥Âª£Ê≥õÁõÆÊ®ô„ÄÇ

##### **Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models**
2410.08731v1 by Yeeun Kim, Young Rok Choi, Eunkyung Choi, Jinhwan Choi, Hai Jin Park, Wonseok Hwang

Large language models (LLMs) have demonstrated remarkable performance in the
legal domain, with GPT-4 even passing the Uniform Bar Exam in the U.S. However
their efficacy remains limited for non-standardized tasks and tasks in
languages other than English. This underscores the need for careful evaluation
of LLMs within each legal system before application. Here, we introduce KBL, a
benchmark for assessing the Korean legal language understanding of LLMs,
consisting of (1) 7 legal knowledge tasks (510 examples), (2) 4 legal reasoning
tasks (288 examples), and (3) the Korean bar exam (4 domains, 53 tasks, 2,510
examples). First two datasets were developed in close collaboration with
lawyers to evaluate LLMs in practical scenarios in a certified manner.
Furthermore, considering legal practitioners' frequent use of extensive legal
documents for research, we assess LLMs in both a closed book setting, where
they rely solely on internal knowledge, and a retrieval-augmented generation
(RAG) setting, using a corpus of Korean statutes and precedents. The results
indicate substantial room and opportunities for improvement.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®Ê≥ïÂæãÈ†òÂüüÂ±ïÁèæÂá∫ÂçìË∂äÁöÑË°®ÁèæÔºåGPT-4 ÁîöËá≥ÈÄöÈÅé‰∫ÜÁæéÂúãÁöÑÁµ±‰∏ÄÂæãÂ∏´ËÄÉË©¶„ÄÇÁÑ∂ËÄåÔºåÂÖ∂ÊïàËÉΩÂ∞çÊñºÈùûÊ®ôÊ∫ñÂåñ‰ªªÂãôÂíåÈùûËã±Ë™ûË™ûË®Ä‰ªªÂãô‰ªçÁÑ∂ÊúâÈôê„ÄÇÈÄôÂá∏È°Ø‰∫ÜÂú®ÊáâÁî® LLM ‰πãÂâçÔºåÈúÄË¶Å‰ªîÁ¥∞Ë©ï‰º∞ÊØèÂÄãÊ≥ïÂæãÂà∂Â∫¶ÁöÑÂøÖË¶ÅÊÄß„ÄÇÂú®Ê≠§ÔºåÊàëÂÄë‰ªãÁ¥π KBLÔºå‰∏ÄÂÄãÁî®ÊñºË©ï‰º∞ LLM ÈüìË™ûÊ≥ïÂæãË™ûË®ÄÁêÜËß£ÂäõÁöÑÂü∫Ê∫ñÔºåÂåÖÂê´ (1) 7 È†ÖÊ≥ïÂæãÁü•Ë≠ò‰ªªÂãôÔºà510 ÂÄãÁØÑ‰æãÔºâ„ÄÅ(2) 4 È†ÖÊ≥ïÂæãÊé®ÁêÜ‰ªªÂãôÔºà288 ÂÄãÁØÑ‰æãÔºâÂíå (3) ÈüìÂúãÂæãÂ∏´ËÄÉË©¶Ôºà4 ÂÄãÈ†òÂüüÔºå53 È†Ö‰ªªÂãôÔºå2,510 ÂÄãÁØÑ‰æãÔºâ„ÄÇÂâçÂÖ©ÂÄãË≥áÊñôÈõÜÊòØËàáÂæãÂ∏´ÂØÜÂàáÂêà‰ΩúÈñãÁôºÔºå‰ª•Ë™çË≠âÁöÑÊñπÂºèË©ï‰º∞ LLM Âú®ÂØ¶ÈöõÊÉÖÂ¢É‰∏≠ÁöÑË°®Áèæ„ÄÇÊ≠§Â§ñÔºåËÄÉÈáèÂà∞Ê≥ïÂæãÂæûÊ•≠‰∫∫Âì°Á∂ìÂ∏∏‰ΩøÁî®Â§ßÈáèÁöÑÊ≥ïÂæãÊñá‰ª∂ÈÄ≤Ë°åÁ†îÁ©∂ÔºåÊàëÂÄëÂú®Â∞ÅÈñâÂºèË®≠ÂÆö‰∏≠Ë©ï‰º∞ LLMÔºåÂÖ∂‰∏≠‰ªñÂÄëÂÉÖ‰æùË≥¥ÂÖßÈÉ®Áü•Ë≠òÔºå‰ª•Âèä‰ΩøÁî®ÈüìÂúãÊ≥ïË¶èÂíåÂà§‰æãË™ûÊñôÂ∫´ÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Ë®≠ÂÆö„ÄÇÁµêÊûúÈ°ØÁ§∫‰ªçÊúâÂ§ßÂπÖÈÄ≤Ê≠•ÁöÑÁ©∫ÈñìÂíåÊ©üÊúÉ„ÄÇ

##### **ViT3D Alignment of LLaMA3: 3D Medical Image Report Generation**
2410.08588v1 by Siyou Li, Beining Xu, Yihao Luo, Dong Nie, Le Zhang

Automatic medical report generation (MRG), which aims to produce detailed
text reports from medical images, has emerged as a critical task in this
domain. MRG systems can enhance radiological workflows by reducing the time and
effort required for report writing, thereby improving diagnostic efficiency. In
this work, we present a novel approach for automatic MRG utilizing a multimodal
large language model. Specifically, we employed the 3D Vision Transformer
(ViT3D) image encoder introduced from M3D-CLIP to process 3D scans and use the
Asclepius-Llama3-8B as the language model to generate the text reports by
auto-regressive decoding. The experiment shows our model achieved an average
Green score of 0.3 on the MRG task validation set and an average accuracy of
0.61 on the visual question answering (VQA) task validation set, outperforming
the baseline model. Our approach demonstrates the effectiveness of the ViT3D
alignment of LLaMA3 for automatic MRG and VQA tasks by tuning the model on a
small dataset.

ÊëòË¶ÅÔºöËá™ÂãïÂåñÈÜ´ÁôÇÂ†±ÂëäÁîüÊàê (MRG) ÁöÑÁõÆÊ®ôÊòØÊ†πÊìöÈÜ´Â≠∏ÂΩ±ÂÉèÁî¢ÁîüË©≥Á¥∞ÁöÑÊñáÂ≠óÂ†±ÂëäÔºåÂ∑≤ÊàêÁÇ∫Ê≠§È†òÂüüÁöÑ‰∏ÄÈ†ÖÈáçË¶Å‰ªªÂãô„ÄÇMRG Á≥ªÁµ±ÂèØ‰ª•Ê∏õÂ∞ëÊí∞ÂØ´Â†±ÂëäÊâÄÈúÄÁöÑÊôÇÈñìÂíåÁ≤æÂäõÔºåÂæûËÄåÊèêÂçáÊîæÂ∞ÑÁßëÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºåÈÄ≤ËÄåÊîπÂñÑË®∫Êñ∑ÊïàÁéá„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂà©Áî®Â§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åËá™ÂãïÂåñ MRG ÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊé°Áî®‰∫ÜÂæû M3D-CLIP ÂºïÂÖ•ÁöÑ 3D Ë¶ñË¶∫Transformer (ViT3D) ÂΩ±ÂÉèÁ∑®Á¢ºÂô®‰æÜËôïÁêÜ 3D ÊéÉÊèèÔºå‰∏¶‰ΩøÁî® Asclepius-Llama3-8B ‰ΩúÁÇ∫Ë™ûË®ÄÊ®°ÂûãÔºåÈÄèÈÅéËá™Ëø¥Ê≠∏Ëß£Á¢º‰æÜÁî¢ÁîüÊñáÂ≠óÂ†±Âëä„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú® MRG ‰ªªÂãôÈ©óË≠âÈõÜ‰∏äÈÅîÂà∞‰∫ÜÂπ≥Âùá 0.3 ÁöÑ Green ÂàÜÊï∏ÔºåÂú®Ë¶ñË¶∫ÂïèÁ≠î (VQA) ‰ªªÂãôÈ©óË≠âÈõÜ‰∏äÈÅîÂà∞‰∫ÜÂπ≥Âùá 0.61 ÁöÑÊ∫ñÁ¢∫ÁéáÔºåÂÑ™ÊñºÂü∫Á∑öÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïË≠âÊòé‰∫Ü ViT3D Â∞çÈΩä LLaMA3 Âú®Ëá™ÂãïÂåñ MRG Âíå VQA ‰ªªÂãô‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÊñπÊ≥ïÊòØÂú®Â∞èÂûãË≥áÊñôÈõÜ‰∏äË™øÊï¥Ê®°Âûã„ÄÇ

##### **oRetrieval Augmented Generation for 10 Large Language Models and its Generalizability in Assessing Medical Fitness**
2410.08431v1 by Yu He Ke, Liyuan Jin, Kabilan Elangovan, Hairil Rizal Abdullah, Nan Liu, Alex Tiong Heng Sia, Chai Rick Soh, Joshua Yi Min Tung, Jasmine Chiat Ling Ong, Chang-Fu Kuo, Shao-Chun Wu, Vesela P. Kovacheva, Daniel Shu Wei Ting

Large Language Models (LLMs) show potential for medical applications but
often lack specialized clinical knowledge. Retrieval Augmented Generation (RAG)
allows customization with domain-specific information, making it suitable for
healthcare. This study evaluates the accuracy, consistency, and safety of RAG
models in determining fitness for surgery and providing preoperative
instructions. We developed LLM-RAG models using 35 local and 23 international
preoperative guidelines and tested them against human-generated responses. A
total of 3,682 responses were evaluated. Clinical documents were processed
using Llamaindex, and 10 LLMs, including GPT3.5, GPT4, and Claude-3, were
assessed. Fourteen clinical scenarios were analyzed, focusing on seven aspects
of preoperative instructions. Established guidelines and expert judgment were
used to determine correct responses, with human-generated answers serving as
comparisons. The LLM-RAG models generated responses within 20 seconds,
significantly faster than clinicians (10 minutes). The GPT4 LLM-RAG model
achieved the highest accuracy (96.4% vs. 86.6%, p=0.016), with no
hallucinations and producing correct instructions comparable to clinicians.
Results were consistent across both local and international guidelines. This
study demonstrates the potential of LLM-RAG models for preoperative healthcare
tasks, highlighting their efficiency, scalability, and reliability.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) È°ØÁ§∫Âá∫Âú®ÈÜ´ÁôÇÊáâÁî®ÊñπÈù¢ÁöÑÊΩõÂäõÔºå‰ΩÜÈÄöÂ∏∏Áº∫‰πèÂ∞àÊ•≠ÁöÑËá®Â∫äÁü•Ë≠ò„ÄÇÊ™¢Á¥¢Êì¥ÂÖÖÁîüÊàê (RAG) ÂÖÅË®±‰ΩøÁî®ÁâπÂÆöÈ†òÂüüÁöÑË≥áË®äÈÄ≤Ë°åËá™Ë®ÇÔºå‰ΩøÂÖ∂ÈÅ©Áî®ÊñºÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÊú¨Á†îÁ©∂Ë©ï‰º∞ RAG Ê®°ÂûãÂú®Á¢∫ÂÆöÊâãË°ìÈÅ©ÊáâÁóáÂíåÊèê‰æõË°ìÂâçË™™ÊòéÊñπÈù¢ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅ‰∏ÄËá¥ÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇÊàëÂÄë‰ΩøÁî® 35 ‰ªΩÁï∂Âú∞Âíå 23 ‰ªΩÂúãÈöõË°ìÂâçÊåáÂçóÈñãÁôº‰∫Ü LLM-RAG Ê®°ÂûãÔºå‰∏¶Â∞áÂÆÉÂÄëËàá‰∫∫ÁÇ∫Áî¢ÁîüÁöÑÂõûÊáâÈÄ≤Ë°å‰∫ÜÊ∏¨Ë©¶„ÄÇÁ∏ΩÂÖ±Ë©ï‰º∞‰∫Ü 3,682 ‰ªΩÂõûÊáâ„ÄÇËá®Â∫äÊñá‰ª∂‰ΩøÁî® Llamaindex ËôïÁêÜÔºå‰∏¶Ë©ï‰º∞‰∫Ü 10 ÂÄã LLMÔºåÂåÖÊã¨ GPT3.5„ÄÅGPT4 Âíå Claude-3„ÄÇÂàÜÊûê‰∫Ü 14 ÂÄãËá®Â∫äÂ†¥ÊôØÔºåÈáçÈªûÈóúÊ≥®Ë°ìÂâçË™™ÊòéÁöÑ‰∏ÉÂÄãÊñπÈù¢„ÄÇ‰ΩøÁî®Êó¢ÂÆöÁöÑÊåáÂçóÂíåÂ∞àÂÆ∂Âà§Êñ∑‰æÜÁ¢∫ÂÆöÊ≠£Á¢∫ÁöÑÂõûÊáâÔºå‰∏¶‰ª•‰∫∫ÁÇ∫Áî¢ÁîüÁöÑÁ≠îÊ°à‰ΩúÁÇ∫ÊØîËºÉ„ÄÇLLM-RAG Ê®°ÂûãÂú® 20 ÁßíÂÖßÁî¢ÁîüÂõûÊáâÔºåÈ°ØËëóÂø´ÊñºËá®Â∫äÈÜ´Áîü (10 ÂàÜÈêò)„ÄÇGPT4 LLM-RAG Ê®°ÂûãÈÅîÂà∞‰∫ÜÊúÄÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶ (96.4% Â∞çÊØî 86.6%Ôºåp=0.016)ÔºåÊ≤íÊúâÂá∫ÁèæÂπªË¶∫Ôºå‰∏¶Áî¢Áîü‰∫ÜËàáËá®Â∫äÈÜ´ÁîüÁõ∏Áï∂ÁöÑÊ≠£Á¢∫Ë™™Êòé„ÄÇÁµêÊûúÂú®Áï∂Âú∞ÂíåÂúãÈöõÊåáÂçó‰∏≠ÊòØ‰∏ÄËá¥ÁöÑ„ÄÇÊú¨Á†îÁ©∂Â±ïÁ§∫‰∫Ü LLM-RAG Ê®°ÂûãÂú®Ë°ìÂâçÈÜ´ÁôÇ‰øùÂÅ•‰ªªÂãô‰∏≠ÁöÑÊΩõÂäõÔºåÁ™ÅÂá∫‰∫ÜÂÆÉÂÄëÁöÑÊïàÁéá„ÄÅÂèØÊì¥ÂÖÖÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

##### **VoxelPrompt: A Vision-Language Agent for Grounded Medical Image Analysis**
2410.08397v1 by Andrew Hoopes, Victor Ion Butoi, John V. Guttag, Adrian V. Dalca

We present VoxelPrompt, an agent-driven vision-language framework that
tackles diverse radiological tasks through joint modeling of natural language,
image volumes, and analytical metrics. VoxelPrompt is multi-modal and
versatile, leveraging the flexibility of language interaction while providing
quantitatively grounded image analysis. Given a variable number of 3D medical
volumes, such as MRI and CT scans, VoxelPrompt employs a language agent that
iteratively predicts executable instructions to solve a task specified by an
input prompt. These instructions communicate with a vision network to encode
image features and generate volumetric outputs (e.g., segmentations).
VoxelPrompt interprets the results of intermediate instructions and plans
further actions to compute discrete measures (e.g., tumor growth across a
series of scans) and present relevant outputs to the user. We evaluate this
framework in a sandbox of diverse neuroimaging tasks, and we show that the
single VoxelPrompt model can delineate hundreds of anatomical and pathological
features, measure many complex morphological properties, and perform
open-language analysis of lesion characteristics. VoxelPrompt carries out these
objectives with accuracy similar to that of fine-tuned, single-task models for
segmentation and visual question-answering, while facilitating a much larger
range of tasks. Therefore, by supporting accurate image processing with
language interaction, VoxelPrompt provides comprehensive utility for numerous
imaging tasks that traditionally require specialized models to address.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊèêÂá∫ VoxelPromptÔºå‰∏ÄÁ®ÆÁî±‰ª£ÁêÜÈ©ÖÂãïÁöÑË¶ñË¶∫Ë™ûË®ÄÊ°ÜÊû∂ÔºåÂÆÉÈÄèÈÅéËá™ÁÑ∂Ë™ûË®Ä„ÄÅÂΩ±ÂÉèÈ´îÁ©çÂíåÂàÜÊûêÊåáÊ®ôÁöÑËÅØÂêàÂª∫Ê®°Ôºå‰æÜËôïÁêÜÂ§öÊ®£ÁöÑÊîæÂ∞ÑÂ≠∏‰ªªÂãô„ÄÇVoxelPrompt ÊòØÂ§öÊ®°ÊÖã‰∏îÂ§öÂäüËÉΩÁöÑÔºåÂÆÉÂà©Áî®Ë™ûË®Ä‰∫íÂãïÁöÑÈùàÊ¥ªÊÄßÔºåÂêåÊôÇÊèê‰æõÈáèÂåñÂü∫Á§éÁöÑÂΩ±ÂÉèÂàÜÊûê„ÄÇÁµ¶ÂÆöÂèØËÆäÊï∏ÈáèÁöÑ 3D ÈÜ´Â≠∏È´îÁ©çÔºå‰æãÂ¶Ç MRI Âíå CT ÊéÉÊèèÔºåVoxelPrompt ‰ΩøÁî®Ë™ûË®Ä‰ª£ÁêÜÔºåÂèçË¶ÜÈ†êÊ∏¨ÂèØÂü∑Ë°åÊåá‰ª§Ôºå‰ª•Ëß£Ê±∫Áî±Ëº∏ÂÖ•ÊèêÁ§∫ÊåáÂÆöÁöÑ‰ªªÂãô„ÄÇÈÄô‰∫õÊåá‰ª§ËàáË¶ñË¶∫Á∂≤Ë∑ØÊ∫ùÈÄöÔºå‰ª•Á∑®Á¢ºÂΩ±ÂÉèÁâπÂæµ‰∏¶Áî¢ÁîüÈ´îÁ©çËº∏Âá∫Ôºà‰æãÂ¶ÇÔºåÂàÜÂâ≤Ôºâ„ÄÇVoxelPrompt Ëß£Èáã‰∏≠ÈñìÊåá‰ª§ÁöÑÁµêÊûúÔºå‰∏¶Ë¶èÂäÉÈÄ≤‰∏ÄÊ≠•ÁöÑÂãï‰ΩúÔºå‰ª•Ë®àÁÆóÈõ¢Êï£Ê∏¨ÈáèÔºà‰æãÂ¶ÇÔºå‰∏ÄÁ≥ªÂàóÊéÉÊèè‰∏≠ÁöÑËÖ´Áò§ÁîüÈï∑ÔºâÔºå‰∏¶Âêë‰ΩøÁî®ËÄÖÊèê‰æõÁõ∏ÈóúËº∏Âá∫„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄãÂ§öÊ®£ÂåñÁöÑÁ•ûÁ∂ìÂΩ±ÂÉè‰ªªÂãôÊ≤ôÁõí‰∏≠Ë©ï‰º∞ÈÄôÂÄãÊ°ÜÊû∂ÔºåÊàëÂÄëË°®ÊòéÂñÆ‰∏ÄÁöÑ VoxelPrompt Ê®°ÂûãÂèØ‰ª•ÊèèËø∞Êï∏ÁôæÂÄãËß£ÂâñÂíåÁóÖÁêÜÁâπÂæµÔºåÊ∏¨ÈáèË®±Â§öË§áÈõúÁöÑÂΩ¢ÊÖãÂ±¨ÊÄßÔºå‰∏¶Âü∑Ë°åÁóÖÁÅ∂ÁâπÂæµÁöÑÈñãÊîæË™ûË®ÄÂàÜÊûê„ÄÇVoxelPrompt Âü∑Ë°åÈÄô‰∫õÁõÆÊ®ôÁöÑÊ∫ñÁ¢∫Â∫¶ËàáÈáùÂ∞çÂàÜÂâ≤ÂíåË¶ñË¶∫ÂïèÁ≠îÈÄ≤Ë°åÂæÆË™øÁöÑÂñÆ‰∏Ä‰ªªÂãôÊ®°ÂûãÈ°û‰ººÔºåÂêåÊôÇ‰øÉÈÄ≤‰∫ÜÊõ¥Â§ßÁöÑ‰ªªÂãôÁØÑÂúç„ÄÇÂõ†Ê≠§ÔºåÈÄèÈÅéÊîØÊè¥‰ΩøÁî®Ë™ûË®Ä‰∫íÂãïÁöÑÊ∫ñÁ¢∫ÂΩ±ÂÉèËôïÁêÜÔºåVoxelPrompt ÁÇ∫ÂÇ≥Áµ±‰∏äÈúÄË¶ÅÂ∞àÈñÄÊ®°Âûã‰æÜËôïÁêÜÁöÑÁúæÂ§öÂΩ±ÂÉè‰ªªÂãôÊèê‰æõ‰∫ÜÂÖ®Èù¢ÁöÑÂØ¶Áî®ÊÄß„ÄÇ</paragraph>

##### **Optimizing Vital Sign Monitoring in Resource-Constrained Maternal Care: An RL-Based Restless Bandit Approach**
2410.08377v1 by Niclas Boehmer, Yunfan Zhao, Guojun Xiong, Paula Rodriguez-Diaz, Paola Del Cueto Cibrian, Joseph Ngonzi, Adeline Boatin, Milind Tambe

Maternal mortality remains a significant global public health challenge. One
promising approach to reducing maternal deaths occurring during facility-based
childbirth is through early warning systems, which require the consistent
monitoring of mothers' vital signs after giving birth. Wireless vital sign
monitoring devices offer a labor-efficient solution for continuous monitoring,
but their scarcity raises the critical question of how to allocate them most
effectively. We devise an allocation algorithm for this problem by modeling it
as a variant of the popular Restless Multi-Armed Bandit (RMAB) paradigm. In
doing so, we identify and address novel, previously unstudied constraints
unique to this domain, which render previous approaches for RMABs unsuitable
and significantly increase the complexity of the learning and planning problem.
To overcome these challenges, we adopt the popular Proximal Policy Optimization
(PPO) algorithm from reinforcement learning to learn an allocation policy by
training a policy and value function network. We demonstrate in simulations
that our approach outperforms the best heuristic baseline by up to a factor of
$4$.

ÊëòË¶ÅÔºöÁî¢Â©¶Ê≠ª‰∫°Áéá‰ªçÁÑ∂ÊòØÂÖ®ÁêÉÂÖ¨ÂÖ±Ë°õÁîüÁöÑÈáçÂ§ßÊåëÊà∞„ÄÇ‰∏ÄÁ®ÆÊúâÊúõÊ∏õÂ∞ëÂú®ÈÜ´ÁôÇÊ©üÊßãÁîüÁî¢ÈÅéÁ®ã‰∏≠Áî¢Â©¶Ê≠ª‰∫°ÁöÑÊñπÊ≥ïÊòØÈÄèÈÅéÈ†êË≠¶Á≥ªÁµ±ÔºåÈÄôÈúÄË¶ÅÂú®Áî¢ÂæåÊåÅÁ∫åÁõ£Ê∏¨Áî¢Â©¶ÁöÑÁîüÂëΩÂæµË±°„ÄÇÁÑ°Á∑öÁîüÂëΩÂæµË±°Áõ£Ê∏¨Ë£ùÁΩÆÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÁúÅÂäõÁöÑÈÄ£Á∫åÁõ£Ê∏¨Ëß£Ê±∫ÊñπÊ°àÔºå‰ΩÜÂÖ∂Á®ÄÁº∫ÊÄßÂºïÁôº‰∫Ü‰∏ÄÂÄãÈóúÈçµÂïèÈ°åÔºåÂç≥Â¶Ç‰ΩïÊúÄÊúâÊïàÂú∞ÂàÜÈÖçÈÄô‰∫õË£ùÁΩÆ„ÄÇÊàëÂÄëÁÇ∫ÈÄôÂÄãÂïèÈ°åË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂàÜÈÖçÊºîÁÆóÊ≥ïÔºåÂ∞áÂÖ∂Âª∫Ê®°ÁÇ∫ÊµÅË°åÁöÑ‰∏çËÄêÁÖ©Â§öËáÇË≥≠Âæí (RMAB) ÁØÑ‰æãÁöÑËÆäÈ´î„ÄÇÂú®ÈÄôÊ®£ÂÅöÁöÑÈÅéÁ®ã‰∏≠ÔºåÊàëÂÄëË≠òÂà•‰∏¶Ëß£Ê±∫‰∫ÜÈÄôÂÄãÈ†òÂüüÁç®ÊúâÁöÑ„ÄÅ‰ª•ÂâçÊú™Á†îÁ©∂ÈÅéÁöÑÊñ∞Á¥ÑÊùüÔºåÈÄô‰∫õÁ¥ÑÊùüËÆìÂÖàÂâçÈáùÂ∞ç RMAB ÁöÑÊñπÊ≥ïËÆäÂæó‰∏çÈÅ©Áî®Ôºå‰∏¶È°ØËëóÂ¢ûÂä†‰∫ÜÂ≠∏ÁøíÂíåË¶èÂäÉÂïèÈ°åÁöÑË§áÈõúÊÄß„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊé°Áî®‰∫ÜÂº∑ÂåñÂ≠∏Áøí‰∏≠ÊµÅË°åÁöÑËøëÁ´ØÁ≠ñÁï•ÊúÄ‰Ω≥Âåñ (PPO) ÊºîÁÆóÊ≥ïÔºåÈÄèÈÅéË®ìÁ∑¥Á≠ñÁï•ÂíåÂÉπÂÄºÂáΩÊï∏Á∂≤Ë∑Ø‰æÜÂ≠∏ÁøíÂàÜÈÖçÁ≠ñÁï•„ÄÇÊàëÂÄëÂú®Ê®°Êì¨‰∏≠Ë≠âÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊØîÊúÄ‰Ω≥ÂïüÁôºÂºèÂü∫Ê∫ñÈ´òÂá∫ $4$ ÂÄç„ÄÇ

##### **ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation**
2410.07908v2 by L√©o Machado, H√©l√®ne Philippe, √âlodie Ferreres, Julien Khlaut, Julie Dupuis, Korentin Le Floch, Denis Habip Gatenyo, Pascal Roux, Jules Gr√©gory, Maxime Ronot, Corentin Dancette, Daniel Tordjman, Pierre Manceron, Paul H√©rent

Carcinogenesis is a proteiform phenomenon, with tumors emerging in various
locations and displaying complex, diverse shapes. At the crucial intersection
of research and clinical practice, it demands precise and flexible assessment.
However, current biomarkers, such as RECIST 1.1's long and short axis
measurements, fall short of capturing this complexity, offering an approximate
estimate of tumor burden and a simplistic representation of a more intricate
process. Additionally, existing supervised AI models face challenges in
addressing the variability in tumor presentations, limiting their clinical
utility. These limitations arise from the scarcity of annotations and the
models' focus on narrowly defined tasks.
  To address these challenges, we developed ONCOPILOT, an interactive
radiological foundation model trained on approximately 7,500 CT scans covering
the whole body, from both normal anatomy and a wide range of oncological cases.
ONCOPILOT performs 3D tumor segmentation using visual prompts like point-click
and bounding boxes, outperforming state-of-the-art models (e.g., nnUnet) and
achieving radiologist-level accuracy in RECIST 1.1 measurements. The key
advantage of this foundation model is its ability to surpass state-of-the-art
performance while keeping the radiologist in the loop, a capability that
previous models could not achieve. When radiologists interactively refine the
segmentations, accuracy improves further. ONCOPILOT also accelerates
measurement processes and reduces inter-reader variability, facilitating
volumetric analysis and unlocking new biomarkers for deeper insights.
  This AI assistant is expected to enhance the precision of RECIST 1.1
measurements, unlock the potential of volumetric biomarkers, and improve
patient stratification and clinical care, while seamlessly integrating into the
radiological workflow.

ÊëòË¶ÅÔºö<paragraph>Ëá¥Áôå‰ΩúÁî®ÊòØ‰∏ÄÁ®ÆËÆäÂΩ¢ÁèæË±°ÔºåËÖ´Áò§Âá∫ÁèæÂú®‰∏çÂêå‰ΩçÁΩÆÔºå‰∏¶ÂëàÁèæÂá∫Ë§áÈõú„ÄÅÂ§öÊ®£ÁöÑÂΩ¢ÁãÄ„ÄÇÂú®Á†îÁ©∂ÂíåËá®Â∫äÂØ¶ÂãôÁöÑÈáçË¶Å‰∫§ÊúÉÈªûÔºåÂÆÉÈúÄË¶ÅÁ≤æÁ¢∫‰∏îÈùàÊ¥ªÁöÑË©ï‰º∞„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÁîüÁâ©Ê®ôË®òÔºå‰æãÂ¶Ç RECIST 1.1 ÁöÑÈï∑Ëª∏ÂíåÁü≠Ëª∏Ê∏¨ÈáèÔºåÊú™ËÉΩÊçïÊçâÂà∞ÈÄôÁ®ÆË§áÈõúÊÄßÔºåÂÉÖÊèê‰æõËÖ´Áò§Ë≤†ÊìîÁöÑËøë‰ºº‰º∞Ë®àÂÄºÔºå‰ª•ÂèäÂ∞çÊõ¥Ë§áÈõúÈÅéÁ®ãÁöÑÁ∞°ÂåñË°®Á§∫„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÁöÑÁõ£Áù£Âºè AI Ê®°ÂûãÂú®ËôïÁêÜËÖ´Áò§Ë°®ÁèæÁöÑËÆäÁï∞ÊÄßÊôÇÈù¢Ëá®ÊåëÊà∞ÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑËá®Â∫äÊïàÁî®„ÄÇÈÄô‰∫õÈôêÂà∂‰æÜËá™ÊñºÊ®ôË®ªÁöÑÁ®ÄÂ∞ëÊÄßÔºå‰ª•ÂèäÊ®°ÂûãÂ∞àÊ≥®ÊñºÁãπÁæ©ÂÆöÁæ©ÁöÑ‰ªªÂãô„ÄÇ
ÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÈñãÁôº‰∫Ü ONCOPILOTÔºåÈÄôÊòØ‰∏ÄÂÄã‰∫íÂãïÂºèÊîæÂ∞ÑÂ≠∏Âü∫Á§éÊ®°ÂûãÔºåË®ìÁ∑¥ÊñºÂ§ßÁ¥Ñ 7,500 ÂÄãÊ∂µËìãÂÖ®Ë∫´ÁöÑ CT ÊéÉÊèèÔºåÂåÖÊã¨Ê≠£Â∏∏Ëß£ÂâñÁµêÊßãÂíåÂêÑÁ®ÆËÖ´Áò§ÁóÖ‰æã„ÄÇONCOPILOT ‰ΩøÁî®Ë¶ñË¶∫ÊèêÁ§∫Ôºà‰æãÂ¶ÇÈªûÈÅ∏ÂíåÈÇäÁïåÊ°ÜÔºâÂü∑Ë°å 3D ËÖ´Áò§ÂàÜÂâ≤ÔºåÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºà‰æãÂ¶Ç nnUnetÔºâÔºå‰∏¶Âú® RECIST 1.1 Ê∏¨Èáè‰∏≠ÈÅîÂà∞ÊîæÂ∞ÑÁßëÈÜ´Â∏´Á≠âÁ¥öÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÈÄôÂÄãÂü∫Á§éÊ®°ÂûãÁöÑ‰∏ªË¶ÅÂÑ™ÈªûÊòØÂÆÉËÉΩÂ§†Ë∂ÖË∂äÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂêåÊôÇËÆìÊîæÂ∞ÑÁßëÈÜ´Â∏´ÂèÉËàáÂÖ∂‰∏≠ÔºåÈÄôÊòØ‰ª•ÂâçÁöÑÊ®°ÂûãÁÑ°Ê≥ïÈÅîÂà∞ÁöÑËÉΩÂäõ„ÄÇÁï∂ÊîæÂ∞ÑÁßëÈÜ´Â∏´‰∫íÂãïÂºèÂú∞Ë™øÊï¥ÂàÜÂâ≤ÊôÇÔºåÊ∫ñÁ¢∫Â∫¶ÊúÉÈÄ≤‰∏ÄÊ≠•ÊèêÈ´ò„ÄÇONCOPILOT ‰πüÂä†ÈÄü‰∫ÜÊ∏¨ÈáèÈÅéÁ®ã‰∏¶Ê∏õÂ∞ë‰∫ÜËÆÄËÄÖÈñìÁöÑËÆäÁï∞ÊÄßÔºå‰øÉÈÄ≤‰∫ÜÈ´îÁ©çÂàÜÊûêÔºå‰∏¶Ëß£Èéñ‰∫ÜÊñ∞ÁöÑÁîüÁâ©Ê®ôË®òÔºå‰ª•Áç≤ÂæóÊõ¥Ê∑±ÂÖ•ÁöÑË¶ãËß£„ÄÇ
È†êË®àÈÄôÂÄã AI Âä©ÁêÜÂ∞áÊèêÈ´ò RECIST 1.1 Ê∏¨ÈáèÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÈáãÊîæÈ´îÁ©çÁîüÁâ©Ê®ôË®òÁöÑÊΩõÂäõÔºå‰∏¶ÊîπÂñÑÊÇ£ËÄÖÂàÜÂ±§ÂíåËá®Â∫äÁÖßË≠∑ÔºåÂêåÊôÇÁÑ°Á∏´Êï¥ÂêàÂà∞ÊîæÂ∞ÑÂ≠∏Â∑•‰ΩúÊµÅÁ®ã‰∏≠„ÄÇ</paragraph>

##### **Exploring ASR-Based Wav2Vec2 for Automated Speech Disorder Assessment: Insights and Analysis**
2410.08250v1 by Tuan Nguyen, Corinne Fredouille, Alain Ghio, Mathieu Balaguer, Virginie Woisard

With the rise of SSL and ASR technologies, the Wav2Vec2 ASR-based model has
been fine-tuned for automated speech disorder quality assessment tasks,
yielding impressive results and setting a new baseline for Head and Neck Cancer
speech contexts. This demonstrates that the ASR dimension from Wav2Vec2 closely
aligns with assessment dimensions. Despite its effectiveness, this system
remains a black box with no clear interpretation of the connection between the
model ASR dimension and clinical assessments. This paper presents the first
analysis of this baseline model for speech quality assessment, focusing on
intelligibility and severity tasks. We conduct a layer-wise analysis to
identify key layers and compare different SSL and ASR Wav2Vec2 models based on
pre-trained data. Additionally, post-hoc XAI methods, including Canonical
Correlation Analysis (CCA) and visualization techniques, are used to track
model evolution and visualize embeddings for enhanced interpretability.

ÊëòË¶ÅÔºöÈö®Ëëó SSL Âíå ASR ÊäÄË°ìÁöÑËààËµ∑ÔºåÂü∫Êñº Wav2Vec2 ÁöÑ ASR Ê®°ÂûãÂ∑≤ÈáùÂ∞çËá™ÂãïÂåñË™ûË®ÄÈöúÁ§ôÂìÅË≥™Ë©ï‰º∞‰ªªÂãôÈÄ≤Ë°åÂæÆË™øÔºåÁî¢Áîü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÁµêÊûúÔºå‰∏¶ÁÇ∫È†≠È†∏ÁôåË™ûÈü≥Áí∞Â¢ÉË®≠ÂÆöÊñ∞ÁöÑÂü∫Ê∫ñ„ÄÇÈÄôË≠âÊòé‰∫Ü Wav2Vec2 ÁöÑ ASR Á∂≠Â∫¶ËàáË©ï‰º∞Á∂≠Â∫¶Á∑äÂØÜÂ∞çÈΩä„ÄÇÂÑòÁÆ°ÈÄôÂÄãÁ≥ªÁµ±ÂæàÊúâÊïàÔºå‰ΩÜÂÆÉ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈªëÁõíÂ≠êÔºåÁÑ°Ê≥ïÊ∏ÖÊ•öËß£ÈáãÊ®°Âûã ASR Á∂≠Â∫¶ËàáËá®Â∫äË©ï‰º∞‰πãÈñìÁöÑÈóúËÅØ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜÁ¨¨‰∏ÄÂÄãÈáùÂ∞çË™ûÈü≥ÂìÅË≥™Ë©ï‰º∞ÁöÑÂü∫Ê∫ñÊ®°ÂûãÂàÜÊûêÔºåÈáçÈªûÊîæÂú®Ê∏ÖÊô∞Â∫¶ÂíåÂö¥ÈáçÊÄß‰ªªÂãô‰∏ä„ÄÇÊàëÂÄëÈÄ≤Ë°åÈÄêÂ±§ÂàÜÊûêÔºå‰ª•Ë≠òÂà•ÈóúÈçµÂ±§Ôºå‰∏¶Ê†πÊìöÈ†êË®ìÁ∑¥Êï∏ÊìöÊØîËºÉ‰∏çÂêåÁöÑ SSL Âíå ASR Wav2Vec2 Ê®°Âûã„ÄÇÊ≠§Â§ñÔºå‰∫ãÂæå XAI ÊñπÊ≥ïÔºàÂåÖÊã¨ÂÖ∏ÂûãÁõ∏ÈóúÂàÜÊûê (CCA) ÂíåË¶ñË¶∫ÂåñÊäÄË°ìÔºâÁî®ÊñºËøΩËπ§Ê®°ÂûãÊºîÂåñÔºå‰∏¶Ë¶ñË¶∫ÂåñÂµåÂÖ•‰ª•Â¢ûÂº∑ÂèØËß£ÈáãÊÄß„ÄÇ

##### **Forecasting mortality associated emergency department crowding**
2410.08247v1 by Jalmari Nevanlinna, Anna Eidst√∏, Jari Yl√§-Mattila, Teemu Koivistoinen, Niku Oksala, Juho Kanniainen, Ari Palom√§ki, Antti Roine

Emergency department (ED) crowding is a global public health issue that has
been repeatedly associated with increased mortality. Predicting future service
demand would enable preventative measures aiming to eliminate crowding along
with it's detrimental effects. Recent findings in our ED indicate that
occupancy ratios exceeding 90% are associated with increased 10-day mortality.
In this paper, we aim to predict these crisis periods using retrospective data
from a large Nordic ED with a LightGBM model. We provide predictions for the
whole ED and individually for it's different operational sections. We
demonstrate that afternoon crowding can be predicted at 11 a.m. with an AUC of
0.82 (95% CI 0.78-0.86) and at 8 a.m. with an AUC up to 0.79 (95% CI
0.75-0.83). Consequently we show that forecasting mortality-associated crowding
using anonymous administrative data is feasible.

ÊëòË¶ÅÔºöÊÄ•Ë®∫ÂÆ§ÔºàEDÔºâÊìÅÊì†ÊòØÂÖ®ÁêÉÂÖ¨ÂÖ±Ë°õÁîüÂïèÈ°åÔºåÂ∑≤ÂèçË¶ÜËàáÊ≠ª‰∫°Áéá‰∏äÂçáÁõ∏Èóú„ÄÇÈ†êÊ∏¨Êú™‰æÜÁöÑÊúçÂãôÈúÄÊ±ÇÂ∞áÊúâÂä©ÊñºÊé°ÂèñÈ†êÈò≤Êé™ÊñΩÔºå‰ª•Ê∂àÈô§ÊìÅÊì†ÂèäÂÖ∂‰∏çÂà©ÂΩ±Èüø„ÄÇÊàëÂÄëÊÄ•Ë®∫ÂÆ§ÁöÑÊúÄÊñ∞ÁôºÁèæË°®ÊòéÔºåÂÖ•‰ΩèÁéáË∂ÖÈÅé 90% Ëàá 10 Â§©Ê≠ª‰∫°ÁéáÂ¢ûÂä†Áõ∏Èóú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊó®Âú®‰ΩøÁî®‰æÜËá™Â§ßÂûãÂåóÊ≠êÊÄ•Ë®∫ÂÆ§ÁöÑÂõûÈ°ßÊÄßÊï∏ÊìöÂíå LightGBM Ê®°Âûã‰æÜÈ†êÊ∏¨ÈÄô‰∫õÂç±Ê©üÊôÇÊúü„ÄÇÊàëÂÄëÊèê‰æõÊï¥ÂÄãÊÄ•Ë®∫ÂÆ§ÁöÑÈ†êÊ∏¨Ôºå‰∏¶ÂàÜÂà•ÈáùÂ∞çÂÖ∂‰∏çÂêåÁöÑÈÅã‰ΩúÈÉ®ÈñÄÈÄ≤Ë°åÈ†êÊ∏¨„ÄÇÊàëÂÄëË≠âÊòé‰∏ãÂçàÊìÅÊì†ÂèØ‰ª•Âú®‰∏äÂçà 11 ÈªûÈ†êÊ∏¨ÔºåAUC ÁÇ∫ 0.82Ôºà95% CI 0.78-0.86ÔºâÔºåÂú®‰∏äÂçà 8 ÈªûÈ†êÊ∏¨ÔºåAUC È´òÈÅî 0.79Ôºà95% CI 0.75-0.83Ôºâ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëË°®Êòé‰ΩøÁî®ÂåøÂêçÁÆ°ÁêÜÊï∏ÊìöÈ†êÊ∏¨ËàáÊ≠ª‰∫°ÁéáÁõ∏ÈóúÁöÑÊìÅÊì†ÊòØÂèØË°åÁöÑ„ÄÇ

##### **Prompt Engineering a Schizophrenia Chatbot: Utilizing a Multi-Agent Approach for Enhanced Compliance with Prompt Instructions**
2410.12848v1 by Per Niklas Waaler, Musarrat Hussain, Igor Molchanov, Lars Ailo Bongo, Brita Elvev√•g

Patients with schizophrenia often present with cognitive impairments that may
hinder their ability to learn about their condition. These individuals could
benefit greatly from education platforms that leverage the adaptability of
Large Language Models (LLMs) such as GPT-4. While LLMs have the potential to
make topical mental health information more accessible and engaging, their
black-box nature raises concerns about ethics and safety. Prompting offers a
way to produce semi-scripted chatbots with responses anchored in instructions
and validated information, but prompt-engineered chatbots may drift from their
intended identity as the conversation progresses. We propose a Critical
Analysis Filter for achieving better control over chatbot behavior. In this
system, a team of prompted LLM agents are prompt-engineered to critically
analyze and refine the chatbot's response and deliver real-time feedback to the
chatbot. To test this approach, we develop an informational schizophrenia
chatbot and converse with it (with the filter deactivated) until it oversteps
its scope. Once drift has been observed, AI-agents are used to automatically
generate sample conversations in which the chatbot is being enticed to talk
about out-of-bounds topics. We manually assign to each response a compliance
score that quantifies the chatbot's compliance to its instructions;
specifically the rules about accurately conveying sources and being transparent
about limitations. Activating the Critical Analysis Filter resulted in an
acceptable compliance score (>=2) in 67.0% of responses, compared to only 8.7%
when the filter was deactivated. These results suggest that a self-reflection
layer could enable LLMs to be used effectively and safely in mental health
platforms, maintaining adaptability while reliably limiting their scope to
appropriate use cases.

ÊëòË¶ÅÔºö<paragraph>Á≤æÁ•ûÂàÜË£ÇÁóáÊÇ£ËÄÖÂ∏∏Âá∫ÁèæË™çÁü•ÈöúÁ§ôÔºåÈÄôÂèØËÉΩÊúÉÈòªÁ§ô‰ªñÂÄëÂ≠∏ÁøíËá™Â∑±ÁóÖÊÉÖÁöÑËÉΩÂäõ„ÄÇÈÄô‰∫õ‰∫∫ÂèØ‰ª•ÂæûÊïôËÇ≤Âπ≥Âè∞‰∏≠ÂèóÁõäËâØÂ§öÔºåÈÄô‰∫õÂπ≥Âè∞Âà©Áî®‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºà‰æãÂ¶Ç GPT-4ÔºâÁöÑÈÅ©ÊáâÊÄß„ÄÇÂÑòÁÆ° LLM ÊúâÂèØËÉΩ‰Ωø‰∏ªÈ°åÂøÉÁêÜÂÅ•Â∫∑‰ø°ÊÅØÊõ¥ÊòìÊñºË®™ÂïèÂíåÊõ¥ÂÖ∑Âê∏ÂºïÂäõÔºå‰ΩÜÂÆÉÂÄëÁöÑÈªëÁÆ±ÊÄßË≥™ÂºïËµ∑‰∫Ü‰∫∫ÂÄëÂ∞çÈÅìÂæ∑ÂíåÂÆâÂÖ®ÁöÑÊìîÊÜÇ„ÄÇÊèêÁ§∫Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ï‰æÜÁîüÊàêÂçäËÖ≥Êú¨ÁöÑËÅäÂ§©Ê©üÂô®‰∫∫ÔºåÂÖ∂ÈüøÊáâÊ§çÊ†πÊñºÊåá‰ª§ÂíåÁ∂ìÈÅéÈ©óË≠âÁöÑ‰ø°ÊÅØ‰∏≠Ôºå‰ΩÜÊèêÁ§∫Â∑•Á®ãËÅäÂ§©Ê©üÂô®‰∫∫ÂèØËÉΩÊúÉÈö®ËëóÂ∞çË©±ÁöÑÈÄ≤Ë°åËÄåÂÅèÈõ¢ÂÖ∂Êó¢ÂÆöÁöÑË∫´‰ªΩ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊâπÂà§ÊÄßÂàÜÊûêÈÅéÊøæÂô®Ôºå‰ª•Êõ¥Â•ΩÂú∞ÊéßÂà∂ËÅäÂ§©Ê©üÂô®‰∫∫ÁöÑË°åÁÇ∫„ÄÇÂú®ÈÄôÂÄãÁ≥ªÁµ±‰∏≠Ôºå‰∏ÄÂÄãÁî±ÊèêÁ§∫ÁöÑ LLM ‰ª£ÁêÜÁµÑÊàêÁöÑÂúòÈöäË¢´ÊèêÁ§∫Â∑•Á®ãÂåñÔºå‰ª•ÊâπÂà§ÊÄßÂú∞ÂàÜÊûêÂíåÂÑ™ÂåñËÅäÂ§©Ê©üÂô®‰∫∫ÁöÑÈüøÊáâÔºå‰∏¶ÂêëËÅäÂ§©Ê©üÂô®‰∫∫Êèê‰æõÂØ¶ÊôÇÂèçÈ•ã„ÄÇÁÇ∫‰∫ÜÊ∏¨Ë©¶ÈÄôÁ®ÆÊñπÊ≥ïÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄã‰ø°ÊÅØÊÄßÁ≤æÁ•ûÂàÜË£ÇÁóáËÅäÂ§©Ê©üÂô®‰∫∫Ôºå‰∏¶ËàáÂÆÉ‰∫§Ë´áÔºàÂú®ÈÅéÊøæÂô®ÂÅúÁî®ÁöÑÊÉÖÊ≥Å‰∏ãÔºâÔºåÁõ¥Âà∞ÂÆÉË∂ÖÂá∫ÂÖ∂ÁØÑÂúç„ÄÇ‰∏ÄÊó¶ËßÄÂØüÂà∞ÊºÇÁßªÔºåAI ‰ª£ÁêÜÂ∞±ÊúÉÁî®ÊñºËá™ÂãïÁîüÊàêÁ§∫‰æãÂ∞çË©±ÔºåÂÖ∂‰∏≠ËÅäÂ§©Ê©üÂô®‰∫∫Ë¢´Ë™òÂ∞éË´áË´ñË∂ÖÂá∫ÁïåÈôêÁöÑË©±È°å„ÄÇÊàëÂÄëÊâãÂãïÁÇ∫ÊØèÂÄãÈüøÊáâÂàÜÈÖç‰∏ÄÂÄãÂêàË¶èÂàÜÊï∏ÔºåË©≤ÂàÜÊï∏ÈáèÂåñ‰∫ÜËÅäÂ§©Ê©üÂô®‰∫∫Â∞çÂÖ∂Êåá‰ª§ÁöÑÂêàË¶èÊÄßÔºõÂÖ∑È´î‰æÜË™™ÔºåÂ∞±ÊòØÊ∫ñÁ¢∫ÂÇ≥ÈÅî‰æÜÊ∫êÂíåÂ∞çÈôêÂà∂‰øùÊåÅÈÄèÊòéÁöÑË¶èÂâá„ÄÇÊøÄÊ¥ªÊâπÂà§ÊÄßÂàÜÊûêÈÅéÊøæÂô®ÂæåÔºå67.0% ÁöÑÈüøÊáâÁç≤Âæó‰∫ÜÂèØÊé•ÂèóÁöÑÂêàË¶èÂàÜÊï∏Ôºà>=2ÔºâÔºåËÄåÈÅéÊøæÂô®ÂÅúÁî®ÊôÇÂè™Êúâ 8.7%„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºå‰∏ÄÂÄãËá™ÊàëÂèçÁúÅÂ±§ÂèØ‰ª•‰Ωø LLM Âú®ÂøÉÁêÜÂÅ•Â∫∑Âπ≥Âè∞‰∏≠ÂæóÂà∞ÊúâÊïàÂíåÂÆâÂÖ®ÁöÑÂà©Áî®ÔºåÂú®‰øùÊåÅÈÅ©ÊáâÊÄßÁöÑÂêåÊôÇÔºåÂèØÈù†Âú∞Â∞áÂÖ∂ÁØÑÂúçÈôêÂà∂Âú®ÈÅ©Áï∂ÁöÑÁî®‰æã‰∏≠„ÄÇ</paragraph>

##### **Flex-MoE: Modeling Arbitrary Modality Combination via the Flexible Mixture-of-Experts**
2410.08245v1 by Sukwon Yun, Inyoung Choi, Jie Peng, Yangfan Wu, Jingxuan Bao, Qiyiwen Zhang, Jiayi Xin, Qi Long, Tianlong Chen

Multimodal learning has gained increasing importance across various fields,
offering the ability to integrate data from diverse sources such as images,
text, and personalized records, which are frequently observed in medical
domains. However, in scenarios where some modalities are missing, many existing
frameworks struggle to accommodate arbitrary modality combinations, often
relying heavily on a single modality or complete data. This oversight of
potential modality combinations limits their applicability in real-world
situations. To address this challenge, we propose Flex-MoE (Flexible
Mixture-of-Experts), a new framework designed to flexibly incorporate arbitrary
modality combinations while maintaining robustness to missing data. The core
idea of Flex-MoE is to first address missing modalities using a new missing
modality bank that integrates observed modality combinations with the
corresponding missing ones. This is followed by a uniquely designed Sparse MoE
framework. Specifically, Flex-MoE first trains experts using samples with all
modalities to inject generalized knowledge through the generalized router
($\mathcal{G}$-Router). The $\mathcal{S}$-Router then specializes in handling
fewer modality combinations by assigning the top-1 gate to the expert
corresponding to the observed modality combination. We evaluate Flex-MoE on the
ADNI dataset, which encompasses four modalities in the Alzheimer's Disease
domain, as well as on the MIMIC-IV dataset. The results demonstrate the
effectiveness of Flex-MoE highlighting its ability to model arbitrary modality
combinations in diverse missing modality scenarios. Code is available at
https://github.com/UNITES-Lab/flex-moe.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÂ≠¶‰π†Âú®ÂêÑ‰∏™È¢ÜÂüü‰∏≠Ëé∑ÂæóË∂äÊù•Ë∂äÂ§öÁöÑÈáçËßÜÔºå
ÂÆÉÊèê‰æõ‰∫ÜÊï¥ÂêàÊù•Ëá™ÂõæÂÉè„ÄÅ
ÊñáÊú¨Âíå‰∏™ÊÄßÂåñËÆ∞ÂΩïÁ≠â‰∏çÂêåÊù•Ê∫êÁöÑÊï∞ÊçÆÁöÑËÉΩÂäõÔºåËøô‰∫õÊï∞ÊçÆÈÄöÂ∏∏Âú®ÂåªÂ≠¶
È¢ÜÂüü‰∏≠ËßÇÂØüÂà∞„ÄÇÁÑ∂ËÄåÔºåÂú®Êüê‰∫õÊ®°ÊÄÅÁº∫Â§±ÁöÑÊÉÖÂÜµ‰∏ãÔºåËÆ∏Â§öÁé∞ÊúâÁöÑ
Ê°ÜÊû∂Èöæ‰ª•ÈÄÇÂ∫î‰ªªÊÑèÊ®°ÊÄÅÁªÑÂêàÔºåÈÄöÂ∏∏‰∏•Èáç‰æùËµñ‰∫éÂçï‰∏ÄÊ®°ÊÄÅÊàñÂÆåÊï¥Êï∞ÊçÆ„ÄÇËøôÁßçÂØπ
ÊΩúÂú®Ê®°ÊÄÅÁªÑÂêàÁöÑÂøΩËßÜÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®Áé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑÈÄÇÁî®ÊÄß
ÊÉÖÂÜµ„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∏ÄÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü Flex-MoEÔºàÁÅµÊ¥ª
‰∏ìÂÆ∂Ê∑∑ÂêàÔºâÔºå‰∏Ä‰∏™Êó®Âú®ÁÅµÊ¥ªÂú∞Á∫≥ÂÖ•‰ªªÊÑè
Ê®°ÊÄÅÁªÑÂêàÔºåÂêåÊó∂‰øùÊåÅÂØπÁº∫Â§±Êï∞ÊçÆÁöÑÈ≤ÅÊ£íÊÄß„ÄÇFlex-MoE ÁöÑÊ†∏ÂøÉ
ÊÄùÊÉ≥ÊòØÈ¶ñÂÖà‰ΩøÁî®Êñ∞ÁöÑÁº∫Â§±Ê®°ÊÄÅÂ∫ìÊù•Ëß£ÂÜ≥Áº∫Â§±Ê®°ÊÄÅÔºåËØ•Â∫ìÂ∞ÜËßÇÂØüÂà∞ÁöÑÊ®°ÊÄÅÁªÑÂêà‰∏é
Áõ∏Â∫îÁöÑÁº∫Â§±Ê®°ÊÄÅÁõ∏ÁªìÂêà„ÄÇÊé•‰∏ãÊù•ÊòØ‰∏Ä‰∏™Áã¨ÁâπËÆæËÆ°ÁöÑÁ®ÄÁñè MoE
Ê°ÜÊû∂„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåFlex-MoE È¶ñÂÖà‰ΩøÁî®ÂÖ∑ÊúâÊâÄÊúâ
Ê®°ÊÄÅÁöÑÊ†∑Êú¨ËÆ≠ÁªÉ‰∏ìÂÆ∂Ôºå‰ª•ÈÄöËøáÂπø‰πâË∑ØÁî±Âô®Ê≥®ÂÖ•Âπø‰πâÁü•ËØÜ
Ôºà$\mathcal{G}$-RouterÔºâ„ÄÇÁÑ∂ÂêéÔºå$\mathcal{S}$-Router ÈÄöËøáÂ∞Ü top-1 Èó®ÂàÜÈÖçÁªô‰∏ìÂÆ∂Êù•‰∏ìÈó®Â§ÑÁêÜËæÉÂ∞ëÁöÑÊ®°ÊÄÅÁªÑÂêà
ÂØπÂ∫î‰∫éËßÇÂØüÂà∞ÁöÑÊ®°ÊÄÅÁªÑÂêà„ÄÇÊàë‰ª¨Âú®
ADNI Êï∞ÊçÆÈõÜ‰∏äËØÑ‰º∞ Flex-MoEÔºåËØ•Êï∞ÊçÆÈõÜÂåÖÂê´ÈòøÂ∞îËå®Êµ∑ÈªòÁóÖ‰∏≠ÁöÑÂõõÁßçÊ®°ÊÄÅ
È¢ÜÂüüÔºå‰ª•Âèä MIMIC-IV Êï∞ÊçÆÈõÜ„ÄÇÁªìÊûúËØÅÊòé‰∫Ü
Flex-MoE ÁöÑÊúâÊïàÊÄßÔºåÁ™ÅÂá∫‰∫ÜÂÖ∂Âú®‰∏çÂêåÁº∫Â§±Ê®°ÊÄÅÂú∫ÊôØ‰∏≠ÂØπ‰ªªÊÑèÊ®°ÊÄÅÁªÑÂêàËøõË°åÂª∫Ê®°ÁöÑËÉΩÂäõ„ÄÇ‰ª£Á†ÅÂèØÂú®
https://github.com/UNITES-Lab/flex-moe Ëé∑Âæó„ÄÇ

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

ÊëòË¶ÅÔºöÈÅ∫ÂÇ≥ÊÄßË¶ñÁ∂≤ËÜúÁñæÁóÖ (IRD) ÊòØ‰∏ÄÁµÑÂ§öÊ®£ÂåñÁöÑÈÅ∫ÂÇ≥ÁñæÁóÖÔºå
ÊúÉÂ∞éËá¥Ë¶ñÂäõÈÄêÊº∏Âñ™Â§±ÔºåÊòØÂ∑•‰ΩúÂπ¥ÈΩ°Êàê‰∫∫Â§±ÊòéÁöÑ‰∏ªË¶ÅÂéüÂõ†„ÄÇIRD ÁöÑË§áÈõúÊÄßÂíåÁï∞Ë≥™ÊÄßÂ∞çË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁÆ°ÁêÜÊèêÂá∫‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÊúÄËøë‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÈÄ≤Ê≠•ÁÇ∫ÈÄô‰∫õÊåëÊà∞Êèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ
ÁÑ∂ËÄåÔºåAI ÊäÄË°ìÁöÑÂø´ÈÄüÁôºÂ±ïÂèäÂÖ∂Â§öÁ®ÆÊáâÁî®Â∞éËá¥‰∫ÜË©≤È†òÂüüÁöÑÁü•Ë≠òÂàÜÊï£„ÄÇÊú¨Á∂úËø∞Êï¥Âêà‰∫ÜÁèæÊúâÁ†îÁ©∂ÔºåÊâæÂá∫Â∑ÆË∑ùÔºå‰∏¶Ê¶ÇËø∞‰∫Ü AI Âú®Ë®∫Êñ∑ÂíåÁÆ°ÁêÜ IRD ‰∏≠ÁöÑÊΩõÂäõ„ÄÇÂÆÉÊó®Âú®ÈÄöÈÅéÊé¢Á¥¢Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÁ≠â AI ÊäÄË°ìÔºåÁâπÂà•ÊòØÂú®ÁñæÁóÖÊ™¢Ê∏¨„ÄÅÈÄ≤Á®ãÈ†êÊ∏¨ÂíåÂÄãÊÄßÂåñÊ≤ªÁôÇË®àÂäÉ‰∏≠ÔºåÁÇ∫Êé®ÈÄ≤Ëá®Â∫äÊáâÁî®ÊßãÂª∫ÈÄîÂæë„ÄÇÁâπÂà•ÈóúÊ≥®ÈÄô‰∫õÈ†òÂüü‰∏≠Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåË®éË´ñ‰∫ÜÂèØËß£Èáã AI ÁöÑÊï¥ÂêàÔºåÂº∑Ë™ø‰∫ÜÂÖ∂Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÊèêÈ´òÈÄèÊòéÂ∫¶ÂíåÂ∞çÂü∫Êñº AI ÁöÑÁ≥ªÁµ±ÁöÑ‰ø°‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇË©≤Á∂úËø∞Ëß£Ê±∫‰∫ÜÂΩåÂêà AI Âú® IRD ‰∏≠‰ΩúÁî®ÁöÑÈáçÈªûÁ†îÁ©∂‰∏≠ÁèæÊúâÂ∑ÆË∑ùÁöÑÂøÖË¶ÅÊÄßÔºåÊèê‰æõ‰∫ÜÂ∞çÁï∂Ââç AI ÊäÄË°ìÁöÑÁµêÊßãÂåñÂàÜÊûêÔºå‰∏¶Ê¶ÇËø∞‰∫ÜÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇÊúÄÂæåÊ¶ÇËø∞‰∫ÜÂú® IRD ‰∏≠ÈÉ®ÁΩ≤ AI ÁöÑÊåëÊà∞ÂíåÊ©üÈÅáÔºåÂº∑Ë™ø‰∫ÜË∑®Â≠∏ÁßëÂêà‰ΩúÂíåÊåÅÁ∫åÈñãÁôºÂº∑Â§ß„ÄÅÂèØËß£ÈáãÁöÑ AI Ê®°Âûã‰ª•Êé®ÈÄ≤Ëá®Â∫äÊáâÁî®ÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Toward Relieving Clinician Burden by Automatically Generating Progress Notes using Interim Hospital Data**
2410.12845v1 by Sarvesh Soni, Dina Demner-Fushman

Regular documentation of progress notes is one of the main contributors to
clinician burden. The abundance of structured chart information in medical
records further exacerbates the burden, however, it also presents an
opportunity to automate the generation of progress notes. In this paper, we
propose a task to automate progress note generation using structured or tabular
information present in electronic health records. To this end, we present a
novel framework and a large dataset, ChartPNG, for the task which contains
$7089$ annotation instances (each having a pair of progress notes and interim
structured chart data) across $1616$ patients. We establish baselines on the
dataset using large language models from general and biomedical domains. We
perform both automated (where the best performing Biomistral model achieved a
BERTScore F1 of $80.53$ and MEDCON score of $19.61$) and manual (where we found
that the model was able to leverage relevant structured data with $76.9\%$
accuracy) analyses to identify the challenges with the proposed task and
opportunities for future research.

ÊëòË¶ÅÔºöÂÆöÊúüËÆ∞ÂΩïÈÄ≤Â∫¶Á≠ÜË®òÊòØÈÄ†ÊàêËá®Â∫äÈÜ´Â∏´Ë≤†ÊìîÁöÑ‰∏ªË¶ÅÂéüÂõ†‰πã‰∏Ä„ÄÇÁóÖÊ≠∑‰∏≠Ë±êÂØåÁöÑÁµêÊßãÂåñÂúñË°®Ë≥áË®äÈÄ≤‰∏ÄÊ≠•Âä†Âäá‰∫ÜË≤†ÊìîÔºå‰ΩÜÂÆÉ‰πüÊèê‰æõ‰∫ÜËá™ÂãïÂåñÁîüÊàêÈÄ≤Â∫¶Á≠ÜË®òÁöÑÊ©üÊúÉ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰ΩøÁî®ÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ‰∏≠Â≠òÂú®ÁöÑÁµêÊßãÂåñÊàñË°®Ê†ºË≥áË®äËá™ÂãïÂåñÁîüÊàêÈÄ≤Â∫¶Á≠ÜË®òÁöÑ‰ªªÂãô„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü ChartPNG ÁöÑ‰∏ÄÂÄãÊñ∞Ê°ÜÊû∂Âíå‰∏ÄÂÄãÂ§ßÂûãË≥áÊñôÈõÜÔºåË©≤‰ªªÂãôÂåÖÂê´ 1616 ‰ΩçÊÇ£ËÄÖÁöÑ 7089 ÂÄãË®ªËß£ÂØ¶‰æãÔºàÊØèÂÄãÂØ¶‰æãÈÉΩÊúâ‰∏ÄÂ∞çÈÄ≤Â∫¶Á≠ÜË®òÂíåËá®ÊôÇÁµêÊßãÂåñÂúñË°®Ë≥áÊñôÔºâ„ÄÇÊàëÂÄë‰ΩøÁî®‰æÜËá™‰∏ÄËà¨ÂíåÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Ë≥áÊñôÈõÜ‰∏äÂª∫Á´ãÂü∫Á∑ö„ÄÇÊàëÂÄëÂü∑Ë°åËá™ÂãïÂåñÔºàË°®ÁèæÊúÄ‰Ω≥ÁöÑ Biomistral Ê®°ÂûãÈÅîÂà∞ BERTScore F1 ÁÇ∫ 80.53 Âíå MEDCON ÂàÜÊï∏ÁÇ∫ 19.61ÔºâÂíåÊâãÂãïÔºàÊàëÂÄëÁôºÁèæË©≤Ê®°ÂûãËÉΩÂ§†‰ª• 76.9% ÁöÑÊ∫ñÁ¢∫Â∫¶Âà©Áî®Áõ∏ÈóúÁµêÊßãÂåñË≥áÊñôÔºâÂàÜÊûêÔºå‰ª•ÊâæÂá∫ÊâÄÊèêÂá∫‰ªªÂãôÁöÑÊåëÊà∞ÂíåÊú™‰æÜÁ†îÁ©∂ÁöÑÊ©üÊúÉ„ÄÇ

##### **Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare**
2410.07525v2 by Nan Fang, Guiliang Liu, Wei Gong

Reinforcement Learning (RL) applied in healthcare can lead to unsafe medical
decisions and treatment, such as excessive dosages or abrupt changes, often due
to agents overlooking common-sense constraints. Consequently, Constrained
Reinforcement Learning (CRL) is a natural choice for safe decisions. However,
specifying the exact cost function is inherently difficult in healthcare.
Recent Inverse Constrained Reinforcement Learning (ICRL) is a promising
approach that infers constraints from expert demonstrations. ICRL algorithms
model Markovian decisions in an interactive environment. These settings do not
align with the practical requirement of a decision-making system in healthcare,
where decisions rely on historical treatment recorded in an offline dataset. To
tackle these issues, we propose the Constraint Transformer (CT). Specifically,
1) we utilize a causal attention mechanism to incorporate historical decisions
and observations into the constraint modeling, while employing a Non-Markovian
layer for weighted constraints to capture critical states. 2) A generative
world model is used to perform exploratory data augmentation, enabling offline
RL methods to simulate unsafe decision sequences. In multiple medical
scenarios, empirical results demonstrate that CT can capture unsafe states and
achieve strategies that approximate lower mortality rates, reducing the
occurrence probability of unsafe behaviors.

ÊëòË¶ÅÔºöÂº∑ÂåñÂ≠∏Áøí (RL) ÊáâÁî®ÊñºÈÜ´ÁôÇ‰øùÂÅ•ÂèØËÉΩÊúÉÂ∞éËá¥‰∏çÂÆâÂÖ®ÁöÑÈÜ´ÁôÇÊ±∫Á≠ñÂíåÊ≤ªÁôÇÔºå‰æãÂ¶ÇÈÅéÈáèÂäëÈáèÊàñÁ™ÅÁÑ∂ÊîπËÆäÔºåÈÄöÂ∏∏ÊòØÂõ†ÁÇ∫‰ª£ÁêÜ‰∫∫ÂøΩË¶ñÂ∏∏Ë≠òÈôêÂà∂„ÄÇÂõ†Ê≠§ÔºåÂèóÁ¥ÑÊùüÂº∑ÂåñÂ≠∏Áøí (CRL) ÊòØÂÆâÂÖ®Ê±∫Á≠ñÁöÑËá™ÁÑ∂ÈÅ∏Êìá„ÄÇÁÑ∂ËÄåÔºåÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÊòéÁ¢∫ÊåáÂÆöÁ¢∫ÂàáÁöÑÊàêÊú¨ÂáΩÊï∏Êú¨Ë≥™‰∏äÂæàÂõ∞Èõ£„ÄÇÊúÄËøëÁöÑÂèçÂêëÂèóÁ¥ÑÊùüÂº∑ÂåñÂ≠∏Áøí (ICRL) ÊòØ‰∏ÄÁ®ÆÊúâÂâçÊôØÁöÑÊñπÊ≥ïÔºåÂÆÉÂæûÂ∞àÂÆ∂Á§∫ÁØÑ‰∏≠Êé®Êñ∑Âá∫Á¥ÑÊùü„ÄÇICRL ÊºîÁÆóÊ≥ïÂú®‰∫íÂãïÁí∞Â¢É‰∏≠Âª∫ÊßãÈ¶¨ÂèØÂ§´Ê±∫Á≠ñ„ÄÇÈÄô‰∫õË®≠ÂÆöËàáÈÜ´ÁôÇ‰øùÂÅ•‰∏≠Ê±∫Á≠ñÁ≥ªÁµ±ÁöÑÂØ¶ÈöõË¶ÅÊ±Ç‰∏çÁ¨¶ÔºåÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÔºåÊ±∫Á≠ñ‰æùË≥¥ÊñºÈõ¢Á∑öË≥áÊñôÈõÜ‰∏≠Ë®òÈåÑÁöÑÊ≠∑Âè≤Ê≤ªÁôÇ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁ¥ÑÊùüËΩâÊèõÂô® (CT)„ÄÇÂÖ∑È´î‰æÜË™™Ôºå1) ÊàëÂÄëÂà©Áî®Âõ†ÊûúÊ≥®ÊÑèÊ©üÂà∂Â∞áÊ≠∑Âè≤Ê±∫Á≠ñÂíåËßÄÂØüÁ¥çÂÖ•Á¥ÑÊùüÂª∫Ê®°ÔºåÂêåÊôÇÊé°Áî®ÈùûÈ¶¨ÂèØÂ§´Â±§Ôºå‰ª•Âä†Ê¨äÁ¥ÑÊùü‰æÜÊçïÊçâÈóúÈçµÁãÄÊÖã„ÄÇ2) ÁîüÊàêÂºè‰∏ñÁïåÊ®°ÂûãÁî®ÊñºÂü∑Ë°åÊé¢Á¥¢ÊÄßË≥áÊñôÊì¥ÂÖÖÔºå‰ΩøÈõ¢Á∑ö RL ÊñπÊ≥ïËÉΩÂ§†Ê®°Êì¨‰∏çÂÆâÂÖ®ÁöÑÊ±∫Á≠ñÂ∫èÂàó„ÄÇÂú®Â§öÁ®ÆÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÔºåÂØ¶Ë≠âÁµêÊûúË°®ÊòéÔºåCT ÂèØ‰ª•ÊçïÊçâ‰∏çÂÆâÂÖ®ÁöÑÁãÄÊÖãÔºå‰∏¶ÂØ¶ÁèæËøë‰ººÈôç‰ΩéÊ≠ª‰∫°ÁéáÁöÑÁ≠ñÁï•ÔºåÂæûËÄåÈôç‰Ωé‰∏çÂÆâÂÖ®Ë°åÁÇ∫ÁôºÁîüÁöÑÊ©üÁéá„ÄÇ

##### **A Two-Model Approach for Humour Style Recognition**
2410.12842v1 by Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat

Humour, a fundamental aspect of human communication, manifests itself in
various styles that significantly impact social interactions and mental health.
Recognising different humour styles poses challenges due to the lack of
established datasets and machine learning (ML) models. To address this gap, we
present a new text dataset for humour style recognition, comprising 1463
instances across four styles (self-enhancing, self-deprecating, affiliative,
and aggressive) and non-humorous text, with lengths ranging from 4 to 229
words. Our research employs various computational methods, including classic
machine learning classifiers, text embedding models, and DistilBERT, to
establish baseline performance. Additionally, we propose a two-model approach
to enhance humour style recognition, particularly in distinguishing between
affiliative and aggressive styles. Our method demonstrates an 11.61%
improvement in f1-score for affiliative humour classification, with consistent
improvements in the 14 models tested. Our findings contribute to the
computational analysis of humour in text, offering new tools for studying
humour in literature, social media, and other textual sources.

ÊëòË¶ÅÔºöÂπΩÈªòÔºåÊòØ‰∫∫È°ûÊ∫ùÈÄö‰∏≠‰∏ÄÂÄãÂü∫Êú¨ÁöÑÈù¢ÂêëÔºåÂÆÉ‰ª•ÂêÑÁ®Æ‰∏çÂêåÁöÑÈ¢®Ê†ºÂ±ïÁèæÔºåÂ∞çÁ§æÊúÉ‰∫íÂãïÂíåÂøÉÁêÜÂÅ•Â∫∑ÊúâÈ°ØËëóÁöÑÂΩ±Èüø„ÄÇÁî±ÊñºÁº∫‰πèÊó¢ÂÆöÁöÑË≥áÊñôÈõÜÂíåÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÔºåËæ®Ë≠ò‰∏çÂêåÁöÑÂπΩÈªòÈ¢®Ê†ºÊúÉÂ∏∂‰æÜÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊñ∞ÁöÑÊñáÊú¨Ë≥áÊñôÈõÜÔºåÁî®ÊñºÂπΩÈªòÈ¢®Ê†ºËæ®Ë≠òÔºåÂåÖÂê´ 1463 ÂÄãÂØ¶‰æãÔºåÊ©´Ë∑®ÂõõÁ®ÆÈ¢®Ê†ºÔºàËá™ÊàëÂ¢ûÂº∑„ÄÅËá™ÊàëË≤∂Êäë„ÄÅË¶™ÂíåÂíåÊîªÊìäÔºâÔºå‰ª•ÂèäÈùûÂπΩÈªòÊñáÊú¨ÔºåÈï∑Â∫¶Âæû 4 Âà∞ 229 ÂÄãÂ≠ó‰∏çÁ≠â„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êé°Áî®‰∫ÜÂêÑÁ®ÆË®àÁÆóÊñπÊ≥ïÔºåÂåÖÊã¨Á∂ìÂÖ∏Ê©üÂô®Â≠∏ÁøíÂàÜÈ°ûÂô®„ÄÅÊñáÊú¨ÂµåÂÖ•Ê®°ÂûãÂíå DistilBERTÔºå‰ª•Âª∫Á´ãÂü∫Ê∫ñÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈõôÊ®°ÂûãÊñπÊ≥ïÔºå‰ª•Â¢ûÂº∑ÂπΩÈªòÈ¢®Ê†ºËæ®Ë≠òÔºåÁâπÂà•ÊòØÂú®ÂçÄÂàÜË¶™ÂíåÂíåÊîªÊìäÈ¢®Ê†ºÊñπÈù¢„ÄÇÊàëÂÄëÁöÑÈÄôÂÄãÊñπÊ≥ïÂú®Ë¶™ÂíåÂπΩÈªòÂàÜÈ°ûÁöÑ f1 ÂàÜÊï∏‰∏äÂ±ïÁèæ‰∫Ü 11.61% ÁöÑÈÄ≤Ê≠•ÔºåÂú®Ê∏¨Ë©¶ÁöÑ 14 ÂÄãÊ®°Âûã‰∏≠ÈÉΩÊúâÁ©©ÂÆöÁöÑÈÄ≤Ê≠•„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊúâÂä©ÊñºÂ∞çÊñáÊú¨‰∏≠ÁöÑÂπΩÈªòÈÄ≤Ë°åË®àÁÆóÂàÜÊûêÔºåÁÇ∫Á†îÁ©∂ÊñáÂ≠∏„ÄÅÁ§æÁæ§Â™íÈ´îÂíåÂÖ∂‰ªñÊñáÊú¨‰æÜÊ∫ê‰∏≠ÁöÑÂπΩÈªòÊèê‰æõ‰∫ÜÊñ∞ÁöÑÂ∑•ÂÖ∑„ÄÇ

##### **Unlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing**
2410.07364v1 by Ismail Erbas, Aporva Amarnath, Vikas Pandey, Karthik Swaminathan, Naigang Wang, Xavier Intes

Fluorescence lifetime imaging (FLI) is a widely used technique in the
biomedical field for measuring the decay times of fluorescent molecules,
providing insights into metabolic states, protein interactions, and
ligand-receptor bindings. However, its broader application in fast biological
processes, such as dynamic activity monitoring, and clinical use, such as in
guided surgery, is limited by long data acquisition times and computationally
demanding data processing. While deep learning has reduced post-processing
times, time-resolved data acquisition remains a bottleneck for real-time
applications. To address this, we propose a method to achieve real-time FLI
using an FPGA-based hardware accelerator. Specifically, we implemented a
GRU-based sequence-to-sequence (Seq2Seq) model on an FPGA board compatible with
time-resolved cameras. The GRU model balances accurate processing with the
resource constraints of FPGAs, which have limited DSP units and BRAM. The
limited memory and computational resources on the FPGA require efficient
scheduling of operations and memory allocation to deploy deep learning models
for low-latency applications. We address these challenges by using STOMP, a
queue-based discrete-event simulator that automates and optimizes task
scheduling and memory management on hardware. By integrating a GRU-based
Seq2Seq model and its compressed version, called Seq2SeqLite, generated through
knowledge distillation, we were able to process multiple pixels in parallel,
reducing latency compared to sequential processing. We explore various levels
of parallelism to achieve an optimal balance between performance and resource
utilization. Our results indicate that the proposed techniques achieved a 17.7x
and 52.0x speedup over manual scheduling for the Seq2Seq model and the
Seq2SeqLite model, respectively.

ÊëòË¶ÅÔºöËû¢ÂÖâÁîüÂëΩÈÄ±ÊúüÂΩ±ÂÉè (FLI) ÊòØÁîüÁâ©ÈÜ´Â≠∏È†òÂüü‰∏≠Âª£Ê≥õ‰ΩøÁî®ÁöÑÊäÄË°ìÔºåÁî®ÊñºÊ∏¨ÈáèËû¢ÂÖâÂàÜÂ≠êÁöÑË°∞ËÆäÊôÇÈñìÔºåÊèê‰æõ‰ª£Ë¨ùÁãÄÊÖã„ÄÅËõãÁôΩË≥™‰∫§‰∫í‰ΩúÁî®ÂíåÈÖçÈ´îÂèóÈ´îÁµêÂêàÁöÑË¶ãËß£„ÄÇÁÑ∂ËÄåÔºåÂÖ∂Âú®Âø´ÈÄüÁîüÁâ©ÈÅéÁ®ãÔºà‰æãÂ¶ÇÂãïÊÖãÊ¥ªÂãïÁõ£Ê∏¨ÔºâÂíåËá®Â∫äÁî®ÈÄîÔºà‰æãÂ¶ÇÂºïÂ∞éÂºèÊâãË°ìÔºâ‰∏≠ÁöÑÂª£Ê≥õÊáâÁî®ÂèóÂà∞Èï∑ÊôÇÈñìË≥áÊñôÊì∑ÂèñÂíåË®àÁÆóÈúÄÊ±ÇÈ´òÁöÑË≥áÊñôËôïÁêÜÁöÑÈôêÂà∂„ÄÇÂÑòÁÆ°Ê∑±Â∫¶Â≠∏ÁøíÊ∏õÂ∞ë‰∫ÜÂæåËôïÁêÜÊôÇÈñìÔºå‰ΩÜÊôÇÈñìËß£ÊûêË≥áÊñôÊì∑Âèñ‰ªçÁÑ∂ÊòØÂç≥ÊôÇÊáâÁî®Á®ãÂºèÁöÑÁì∂È†∏„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®Âü∫Êñº FPGA ÁöÑÁ°¨È´îÂä†ÈÄüÂô®‰æÜÂØ¶ÁèæÂç≥ÊôÇ FLI ÁöÑÊñπÊ≥ï„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂú®ËàáÊôÇÈñìËß£ÊûêÁõ∏Ê©üÁõ∏ÂÆπÁöÑ FPGA Êùø‰∏äÂØ¶‰Ωú‰∫ÜÂü∫Êñº GRU ÁöÑÂ∫èÂàóÂ∞çÂ∫èÂàó (Seq2Seq) Ê®°Âûã„ÄÇGRU Ê®°ÂûãÂπ≥Ë°°‰∫ÜÊ∫ñÁ¢∫ÁöÑËôïÁêÜËàá FPGA ÁöÑË≥áÊ∫êÈôêÂà∂ÔºåFPGA ÁöÑ DSP ÂñÆÂÖÉÂíå BRAM ÊúâÈôê„ÄÇFPGA ‰∏äÊúâÈôêÁöÑË®òÊÜ∂È´îÂíåË®àÁÆóË≥áÊ∫êÈúÄË¶ÅÊúâÊïàÂú∞ÊéíÁ®ã‰ΩúÊ•≠ÂíåË®òÊÜ∂È´îÈÖçÁΩÆÔºåÊâçËÉΩÈÉ®ÁΩ≤Ê∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰ª•ÈÄ≤Ë°å‰ΩéÂª∂ÈÅ≤ÊáâÁî®Á®ãÂºè„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî® STOMP ‰æÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫Êñº‰ΩáÂàóÁöÑÈõ¢Êï£‰∫ã‰ª∂Ê®°Êì¨Âô®ÔºåÂèØËá™ÂãïÂåñÂíåÊúÄ‰Ω≥ÂåñÁ°¨È´î‰∏äÁöÑ‰ªªÂãôÊéíÁ®ãÂíåË®òÊÜ∂È´îÁÆ°ÁêÜ„ÄÇÈÄèÈÅéÊï¥ÂêàÂü∫Êñº GRU ÁöÑ Seq2Seq Ê®°ÂûãÂèäÂÖ∂Â£ìÁ∏ÆÁâàÊú¨ Seq2SeqLiteÔºàÈÄèÈÅéÁü•Ë≠òËêÉÂèñÁî¢ÁîüÔºâÔºåÊàëÂÄëËÉΩÂ§†Âπ≥Ë°åËôïÁêÜÂ§öÂÄãÂÉèÁ¥†ÔºåËàáÈ†ÜÂ∫èËôïÁêÜÁõ∏ÊØîÔºåÂèØÊ∏õÂ∞ëÂª∂ÈÅ≤„ÄÇÊàëÂÄëÊé¢Á¥¢‰∫ÜÂêÑÁ®ÆÂπ≥Ë°åÂ±§Á¥öÔºå‰ª•Âú®ÊïàËÉΩÂíåË≥áÊ∫êÂà©Áî®Áéá‰πãÈñìÂèñÂæóÊúÄ‰Ω≥Âπ≥Ë°°„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåËàá Seq2Seq Ê®°ÂûãÂíå Seq2SeqLite Ê®°ÂûãÁöÑÊâãÂãïÊéíÁ®ãÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÊäÄË°ìÂàÜÂà•ÈÅîÂà∞‰∫Ü 17.7 ÂÄçÂíå 52.0 ÂÄçÁöÑÂä†ÈÄü„ÄÇ

##### **Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy**
2410.07147v1 by Vivian Nguyen, Sang Min Jung, Lillian Lee, Thomas D. Hull, Cristian Danescu-Niculescu-Mizil

Mental-health therapy involves a complex conversation flow in which patients
and therapists continuously negotiate what should be talked about next. For
example, therapists might try to shift the conversation's direction to keep the
therapeutic process on track and avoid stagnation, or patients might push the
discussion towards issues they want to focus on.
  How do such patient and therapist redirections relate to the development and
quality of their relationship? To answer this question, we introduce a
probabilistic measure of the extent to which a certain utterance immediately
redirects the flow of the conversation, accounting for both the intention and
the actual realization of such a change. We apply this new measure to
characterize the development of patient-therapist relationships over multiple
sessions in a very large, widely-used online therapy platform. Our analysis
reveals that (1) patient control of the conversation's direction generally
increases relative to that of the therapist as their relationship progresses;
and (2) patients who have less control in the first few sessions are
significantly more likely to eventually express dissatisfaction with their
therapist and terminate the relationship.

ÊëòË¶ÅÔºöÂøÉÁêÜÂÅ•Â∫∑Ê≤ªÁôÇÊ∂âÂèäË§áÈõúÁöÑÂ∞çË©±ÊµÅÁ®ãÔºåÂÖ∂‰∏≠ÊÇ£ËÄÖÂíåÊ≤ªÁôÇÂ∏´ÊåÅÁ∫åÂçîÂïÜÊé•‰∏ã‰æÜÊáâË®éË´ñ‰ªÄÈ∫º„ÄÇ‰æãÂ¶ÇÔºåÊ≤ªÁôÇÂ∏´ÂèØËÉΩÊúÉÂòóË©¶ÊîπËÆäÂ∞çË©±ÊñπÂêëÔºå‰ª•‰ΩøÊ≤ªÁôÇÈÅéÁ®ã‰øùÊåÅÂú®Ê≠£Ëªå‰∏¶ÈÅøÂÖçÂÅúÊªØÔºåÊàñËÄÖÊÇ£ËÄÖÂèØËÉΩÊúÉÂ∞áË®éË´ñÂºïÂêë‰ªñÂÄëÊÉ≥ÈóúÊ≥®ÁöÑÂïèÈ°å„ÄÇ
ÊÇ£ËÄÖÂíåÊ≤ªÁôÇÂ∏´ÁöÑÈÄôÁ®ÆÈáçÊñ∞ÂÆöÂêëËàá‰ªñÂÄëÈóú‰øÇÁöÑÁôºÂ±ïÂíåÂìÅË≥™Êúâ‰ΩïÈóú‰øÇÔºüÁÇ∫‰∫ÜÂõûÁ≠îÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊ©üÁéáÊ∏¨ÈáèÔºåÁî®ÊñºË°°ÈáèÊüêÂÄãË©±Ë™ûÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÁ´ãÂç≥ÈáçÊñ∞ÂÆöÂêëÂ∞çË©±ÊµÅÁ®ãÔºåÂêåÊôÇËÄÉÈáèÊ≠§È°ûËÆäÂåñÁöÑÊÑèÂúñÂíåÂØ¶ÈöõÂØ¶Áèæ„ÄÇÊàëÂÄëÂ∞áÊ≠§Êñ∞Ê∏¨ÈáèÊáâÁî®ÊñºÊèèËø∞ÊÇ£ËÄÖ-Ê≤ªÁôÇÂ∏´Èóú‰øÇÂú®‰∏ÄÂÄãÈùûÂ∏∏ÈæêÂ§ß„ÄÅÂª£Ê≥õ‰ΩøÁî®ÁöÑÁ∑ö‰∏äÊ≤ªÁôÇÂπ≥Âè∞‰∏äÔºåÂú®Â§öÂÄãÁôÇÁ®ã‰∏≠ÁöÑÁôºÂ±ï„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫Ôºå(1) Èö®ËëóÊÇ£ËÄÖËàáÊ≤ªÁôÇÂ∏´Èóú‰øÇÁöÑÈÄ≤Â±ïÔºåÊÇ£ËÄÖÂ∞çÂ∞çË©±ÊñπÂêëÁöÑÊéßÂà∂ÈÄöÂ∏∏ÊúÉÁõ∏Â∞çÊñºÊ≤ªÁôÇÂ∏´ËÄåÂ¢ûÂä†Ôºõ(2) Âú®ÊúÄÂàùÂπæÊ¨°ÁôÇÁ®ã‰∏≠ÊéßÂà∂ËºÉÂ∞ëÁöÑÊÇ£ËÄÖÔºåÊúÄÁµÇÈ°ØËëóÊõ¥ÊúâÂèØËÉΩÂ∞çÂÖ∂Ê≤ªÁôÇÂ∏´Ë°®ÈÅî‰∏çÊªø‰∏¶ÁµÇÊ≠¢Èóú‰øÇ„ÄÇ

##### **Mental Disorders Detection in the Era of Large Language Models**
2410.07129v2 by Gleb Kuzmin, Petr Strepetov, Maksim Stankevich, Artem Shelmanov, Ivan Smirnov

This paper compares the effectiveness of traditional machine learning
methods, encoder-based models, and large language models (LLMs) on the task of
detecting depression and anxiety. Five datasets were considered, each differing
in format and the method used to define the target pathology class. We tested
AutoML models based on linguistic features, several variations of encoder-based
Transformers such as BERT, and state-of-the-art LLMs as pathology
classification models. The results demonstrated that LLMs outperform
traditional methods, particularly on noisy and small datasets where training
examples vary significantly in text length and genre. However, psycholinguistic
features and encoder-based models can achieve performance comparable to
language models when trained on texts from individuals with clinically
confirmed depression, highlighting their potential effectiveness in targeted
clinical applications.

ÊëòË¶ÅÔºöÊú¨ÊñáÊØîËºÉ‰∫ÜÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ï„ÄÅÁ∑®Á¢ºÂô®Ê®°ÂûãÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂÅµÊ∏¨ÊÜÇÈ¨±ÁóáÂíåÁÑ¶ÊÖÆÁóá‰ªªÂãô‰∏äÁöÑÊúâÊïàÊÄß„ÄÇËÄÉÊÖÆ‰∫Ü‰∫îÂÄãË≥áÊñôÈõÜÔºåÊØèÂÄãË≥áÊñôÈõÜÂú®Ê†ºÂºèÂíåÁî®ÊñºÂÆöÁæ©ÁõÆÊ®ôÁóÖÁêÜÈ°ûÂà•ÁöÑÊñπÊ≥ï‰∏äÈÉΩ‰∏çÂêå„ÄÇÊàëÂÄëÊ∏¨Ë©¶‰∫ÜÂü∫ÊñºË™ûË®ÄÁâπÂæµÁöÑ AutoML Ê®°Âûã„ÄÅÂ§öÁ®ÆÁ∑®Á¢ºÂô®Ê®°ÂûãÁöÑËÆäÈ´îÔºå‰æãÂ¶Ç BERTÔºå‰ª•Âèä‰ΩúÁÇ∫ÁóÖÁêÜÂàÜÈ°ûÊ®°ÂûãÁöÑÊúÄÊñ∞ LLM„ÄÇÁµêÊûúË°®ÊòéÔºåLLM ÂÑ™ÊñºÂÇ≥Áµ±ÊñπÊ≥ïÔºåÁâπÂà•ÊòØÂú®Ë®ìÁ∑¥ÁØÑ‰æãÂú®ÊñáÂ≠óÈï∑Â∫¶ÂíåÈ°ûÂûã‰∏äÂ∑ÆÁï∞ÂæàÂ§ßÁöÑÂòàÈõú‰∏îÂ∞èÂûãË≥áÊñôÈõÜ‰∏ä„ÄÇÁÑ∂ËÄåÔºåÁï∂Âú®Ëá®Â∫ä‰∏äÁ¢∫Ë®∫ÁΩπÊÇ£ÊÜÇÈ¨±ÁóáÁöÑÂÄãÈ´îÁöÑÊñáÂ≠ó‰∏äÈÄ≤Ë°åË®ìÁ∑¥ÊôÇÔºåÂøÉÁêÜË™ûË®ÄÂ≠∏ÁâπÂæµÂíåÁ∑®Á¢ºÂô®Ê®°ÂûãÂèØ‰ª•ÈÅîÂà∞ËàáË™ûË®ÄÊ®°ÂûãÁõ∏Áï∂ÁöÑÊïàËÉΩÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂Âú®ÁõÆÊ®ôËá®Â∫äÊáâÁî®‰∏≠ÁöÑÊΩõÂú®ÊúâÊïàÊÄß„ÄÇ

##### **MentalArena: Self-play Training of Language Models for Diagnosis and Treatment of Mental Health Disorders**
2410.06845v1 by Cheng Li, May Fung, Qingyun Wang, Chi Han, Manling Li, Jindong Wang, Heng Ji

Mental health disorders are one of the most serious diseases in the world.
Most people with such a disease lack access to adequate care, which highlights
the importance of training models for the diagnosis and treatment of mental
health disorders. However, in the mental health domain, privacy concerns limit
the accessibility of personalized treatment data, making it challenging to
build powerful models. In this paper, we introduce MentalArena, a self-play
framework to train language models by generating domain-specific personalized
data, where we obtain a better model capable of making a personalized diagnosis
and treatment (as a therapist) and providing information (as a patient). To
accurately model human-like mental health patients, we devise Symptom Encoder,
which simulates a real patient from both cognition and behavior perspectives.
To address intent bias during patient-therapist interactions, we propose
Symptom Decoder to compare diagnosed symptoms with encoded symptoms, and
dynamically manage the dialogue between patient and therapist according to the
identified deviations. We evaluated MentalArena against 6 benchmarks, including
biomedicalQA and mental health tasks, compared to 6 advanced models. Our
models, fine-tuned on both GPT-3.5 and Llama-3-8b, significantly outperform
their counterparts, including GPT-4o. We hope that our work can inspire future
research on personalized care. Code is available in
https://github.com/Scarelette/MentalArena/tree/main

ÊëòË¶ÅÔºöÂøÉÁêÜÂÅ•Â∫∑ÈöúÁ§ôÊòØ‰∏ñÁïå‰∏äÊúÄÂö¥ÈáçÁöÑÁñæÁóÖ‰πã‰∏Ä„ÄÇ
Â§ßÂ§öÊï∏ÊÇ£ÊúâÈÄôÁ®ÆÁñæÁóÖÁöÑ‰∫∫ÁÑ°Ê≥ïÁç≤ÂæóÈÅ©Áï∂ÁöÑÁÖßË≠∑ÔºåÈÄôÂá∏È°Ø‰∫ÜË®ìÁ∑¥Ê®°Âûã‰ª•Ë®∫Êñ∑ÂíåÊ≤ªÁôÇÂøÉÁêÜÂÅ•Â∫∑ÈöúÁ§ôÁöÑÈáçË¶ÅÊÄß„ÄÇÁÑ∂ËÄåÔºåÂú®ÂøÉÁêÜÂÅ•Â∫∑È†òÂüüÔºåÈö±ÁßÅÂïèÈ°åÈôêÂà∂‰∫ÜÂÄã‰∫∫ÂåñÊ≤ªÁôÇË≥áÊñôÁöÑÂèØÂèäÊÄßÔºåÈÄô‰ΩøÂæóÂª∫Á´ãÂº∑Â§ßÁöÑÊ®°ÂûãËÆäÂæóÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü MentalArenaÔºå‰∏ÄÂÄãËá™Áé©Ê°ÜÊû∂ÔºåÈÄöÈÅéÁîüÊàêÁâπÂÆöÈ†òÂüüÁöÑÂÄã‰∫∫ÂåñË≥áÊñô‰æÜË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÔºåÂú®ÂÖ∂‰∏≠ÊàëÂÄëÁç≤Âæó‰∫Ü‰∏ÄÂÄãÊõ¥Â•ΩÁöÑÊ®°ÂûãÔºåËÉΩÂ§†ÈÄ≤Ë°åÂÄã‰∫∫ÂåñË®∫Êñ∑ÂíåÊ≤ªÁôÇÔºà‰ΩúÁÇ∫Ê≤ªÁôÇÂ∏´Ôºâ‰∏¶Êèê‰æõË≥áË®äÔºà‰ΩúÁÇ∫ÊÇ£ËÄÖÔºâ„ÄÇÁÇ∫‰∫ÜÊ∫ñÁ¢∫Ê®°Êì¨È°û‰ºº‰∫∫È°ûÁöÑÂøÉÁêÜÂÅ•Â∫∑ÊÇ£ËÄÖÔºåÊàëÂÄëË®≠Ë®à‰∫ÜÁóáÁãÄÁ∑®Á¢ºÂô®ÔºåÂÆÉÂæûË™çÁü•ÂíåË°åÁÇ∫ÁöÑËßíÂ∫¶Ê®°Êì¨‰∏ÄÂÄãÁúüÂØ¶ÁöÑÊÇ£ËÄÖ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÊÇ£ËÄÖËàáÊ≤ªÁôÇÂ∏´‰∫íÂãïÊúüÈñìÁöÑÊÑèÂúñÂÅèÂ∑ÆÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁóáÁãÄËß£Á¢ºÂô®ÔºåÂ∞áË®∫Êñ∑Âá∫ÁöÑÁóáÁãÄËàáÁ∑®Á¢ºÁóáÁãÄÈÄ≤Ë°åÊØîËºÉÔºå‰∏¶Ê†πÊìöË≠òÂà•Âá∫ÁöÑÂÅèÂ∑ÆÂãïÊÖãÁÆ°ÁêÜÊÇ£ËÄÖËàáÊ≤ªÁôÇÂ∏´‰πãÈñìÁöÑÂ∞çË©±„ÄÇÊàëÂÄëÈáùÂ∞ç 6 ÂÄãÂü∫Ê∫ñÂ∞ç MentalArena ÈÄ≤Ë°å‰∫ÜË©ï‰º∞ÔºåÂåÖÊã¨ÁîüÁâ©ÈÜ´Â≠∏ÂïèÁ≠îÂíåÂøÉÁêÜÂÅ•Â∫∑‰ªªÂãôÔºå‰∏¶Ëàá 6 ÂÄãÂÖàÈÄ≤Ê®°ÂûãÈÄ≤Ë°å‰∫ÜÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú® GPT-3.5 Âíå Llama-3-8b ‰∏äÈÉΩÈÄ≤Ë°å‰∫ÜÂæÆË™øÔºåÈ°ØËëóÂÑ™ÊñºÂÖ∂Â∞çÊáâÊ®°ÂûãÔºåÂåÖÊã¨ GPT-4o„ÄÇÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑÁ†îÁ©∂ËÉΩÊøÄÂãµÊú™‰æÜÂ∞çÂÄã‰∫∫ÂåñÁÖßË≠∑ÁöÑÁ†îÁ©∂„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Scarelette/MentalArena/tree/main ‰∏≠Áç≤Âæó

##### **An Improved Approach for Cardiac MRI Segmentation based on 3D UNet Combined with Papillary Muscle Exclusion**
2410.06818v1 by Narjes Benameur, Ramzi Mahmoudi, Mohamed Deriche, Amira fayouka, Imene Masmoudi, Nessrine Zoghlami

Left ventricular ejection fraction (LVEF) is the most important clinical
parameter of cardiovascular function. The accuracy in estimating this parameter
is highly dependent upon the precise segmentation of the left ventricle (LV)
structure at the end diastole and systole phases. Therefore, it is crucial to
develop robust algorithms for the precise segmentation of the heart structure
during different phases. Methodology: In this work, an improved 3D UNet model
is introduced to segment the myocardium and LV, while excluding papillary
muscles, as per the recommendation of the Society for Cardiovascular Magnetic
Resonance. For the practical testing of the proposed framework, a total of
8,400 cardiac MRI images were collected and analysed from the military hospital
in Tunis (HMPIT), as well as the popular ACDC public dataset. As performance
metrics, we used the Dice coefficient and the F1 score for validation/testing
of the LV and the myocardium segmentation. Results: The data was split into
70%, 10%, and 20% for training, validation, and testing, respectively. It is
worth noting that the proposed segmentation model was tested across three axis
views: basal, medio basal and apical at two different cardiac phases: end
diastole and end systole instances. The experimental results showed a Dice
index of 0.965 and 0.945, and an F1 score of 0.801 and 0.799, at the end
diastolic and systolic phases, respectively. Additionally, clinical evaluation
outcomes revealed a significant difference in the LVEF and other clinical
parameters when the papillary muscles were included or excluded.

ÊëòË¶ÅÔºöÂ∑¶ÂøÉÂÆ§Â∞ÑË°ÄÂàÜÊï∏ (LVEF) ÊòØÂøÉË°ÄÁÆ°ÂäüËÉΩÊúÄÈáçË¶ÅÁöÑËá®Â∫äÂèÉÊï∏„ÄÇ‰º∞Ë®àÊ≠§ÂèÉÊï∏ÁöÑÊ∫ñÁ¢∫ÊÄßÈ´òÂ∫¶‰æùË≥¥ÊñºÂ∑¶ÂøÉÂÆ§ (LV) ÁµêÊßãÂú®ËàíÂºµÊú´ÊúüÂíåÊî∂Á∏ÆÊúüÁöÑÁ≤æÁ¢∫ÂàÜÂâ≤„ÄÇÂõ†Ê≠§ÔºåÈñãÁôºÁî®ÊñºÁ≤æÁ¢∫ÂàÜÂâ≤‰∏çÂêåÊôÇÊúüÂøÉËáüÁµêÊßãÁöÑÂº∑ÂÅ•ÊºîÁÆóÊ≥ïËá≥ÈóúÈáçË¶Å„ÄÇÊñπÊ≥ïÔºöÂú®Ê≠§Â∑•‰Ωú‰∏≠ÔºåÂºïÈÄ≤‰∫Ü‰∏ÄÂÄãÊîπËâØÁöÑ 3D UNet Ê®°Âûã‰æÜÂàÜÂâ≤ÂøÉËÇåÂíåÂ∑¶ÂøÉÂÆ§ÔºåÂêåÊôÇÊ†πÊìöÂøÉË°ÄÁÆ°Á£ÅÂÖ±ÊåØÂ≠∏ÊúÉÁöÑÂª∫Ë≠∞ÊéíÈô§‰π≥È†≠ËÇå„ÄÇÁÇ∫‰∫ÜÂ∞çÊèêÂá∫ÁöÑÊû∂ÊßãÈÄ≤Ë°åÂØ¶ÈöõÊ∏¨Ë©¶ÔºåÂæûÁ™ÅÂ∞ºÊñØÁöÑËªç‰∫ãÈÜ´Èô¢ (HMPIT) ÂíåÊµÅË°åÁöÑ ACDC ÂÖ¨ÂÖ±Ë≥áÊñôÈõÜÊî∂ÈõÜ‰∏¶ÂàÜÊûê‰∫ÜÁ∏ΩÂÖ± 8,400 ÂºµÂøÉËáü MRI ÂΩ±ÂÉè„ÄÇ‰ΩúÁÇ∫ÊïàËÉΩÊåáÊ®ôÔºåÊàëÂÄë‰ΩøÁî® Dice ‰øÇÊï∏Âíå F1 ÂàÜÊï∏‰æÜÈ©óË≠â/Ê∏¨Ë©¶Â∑¶ÂøÉÂÆ§ÂíåÂøÉËÇåÂàÜÂâ≤„ÄÇÁµêÊûúÔºöË≥áÊñôË¢´ÂàÜÊàê 70%„ÄÅ10% Âíå 20% ÂàÜÂà•Áî®ÊñºË®ìÁ∑¥„ÄÅÈ©óË≠âÂíåÊ∏¨Ë©¶„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊâÄÊèêÂá∫ÁöÑÂàÜÂâ≤Ê®°ÂûãÂú®‰∏âÂÄãËª∏ÂêëË¶ñÂúñ‰∏≠ÈÄ≤Ë°å‰∫ÜÊ∏¨Ë©¶ÔºöÂü∫Â∫ï„ÄÅ‰∏≠Âü∫Â∫ïÂíåÂøÉÂ∞ñÔºåÂú®ÂÖ©ÂÄã‰∏çÂêåÁöÑÂøÉËáüÊôÇÊúüÔºöËàíÂºµÊú´ÊúüÂíåÊî∂Á∏ÆÊú´Êúü„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÂú®ËàíÂºµÊú´ÊúüÂíåÊî∂Á∏ÆÊúüÔºåDice ÊåáÊï∏ÂàÜÂà•ÁÇ∫ 0.965 Âíå 0.945ÔºåF1 ÂàÜÊï∏ÂàÜÂà•ÁÇ∫ 0.801 Âíå 0.799„ÄÇÊ≠§Â§ñÔºåËá®Â∫äË©ï‰º∞ÁµêÊûúÈ°ØÁ§∫ÔºåÁï∂‰π≥È†≠ËÇåË¢´Á¥çÂÖ•ÊàñÊéíÈô§ÊôÇÔºåLVEF ÂíåÂÖ∂‰ªñËá®Â∫äÂèÉÊï∏Â≠òÂú®È°ØËëóÂ∑ÆÁï∞„ÄÇ

##### **Deep Learning for Surgical Instrument Recognition and Segmentation in Robotic-Assisted Surgeries: A Systematic Review**
2410.07269v1 by Fatimaelzahraa Ali Ahmed, Mahmoud Yousef, Mariam Ali Ahmed, Hasan Omar Ali, Anns Mahboob, Hazrat Ali, Zubair Shah, Omar Aboumarzouk, Abdulla Al Ansari, Shidin Balakrishnan

Applying deep learning (DL) for annotating surgical instruments in
robot-assisted minimally invasive surgeries (MIS) represents a significant
advancement in surgical technology. This systematic review examines 48 studies
that and advanced DL methods and architectures. These sophisticated DL models
have shown notable improvements in the precision and efficiency of detecting
and segmenting surgical tools. The enhanced capabilities of these models
support various clinical applications, including real-time intraoperative
guidance, comprehensive postoperative evaluations, and objective assessments of
surgical skills. By accurately identifying and segmenting surgical instruments
in video data, DL models provide detailed feedback to surgeons, thereby
improving surgical outcomes and reducing complication risks. Furthermore, the
application of DL in surgical education is transformative. The review
underscores the significant impact of DL on improving the accuracy of skill
assessments and the overall quality of surgical training programs. However,
implementing DL in surgical tool detection and segmentation faces challenges,
such as the need for large, accurately annotated datasets to train these models
effectively. The manual annotation process is labor-intensive and
time-consuming, posing a significant bottleneck. Future research should focus
on automating the detection and segmentation process and enhancing the
robustness of DL models against environmental variations. Expanding the
application of DL models across various surgical specialties will be essential
to fully realize this technology's potential. Integrating DL with other
emerging technologies, such as augmented reality (AR), also offers promising
opportunities to further enhance the precision and efficacy of surgical
procedures.

ÊëòË¶ÅÔºöÊáâÁî®Ê∑±Â∫¶Â≠∏Áøí (DL) ‰æÜË®ªËß£Ê©üÂô®‰∫∫ËºîÂä©ÂæÆÂâµÊâãË°ì (MIS) ‰∏≠ÁöÑÂ§ñÁßëÂô®Ê¢∞‰ª£Ë°®‰∫ÜÂ§ñÁßëÊäÄË°ìÁöÑÈáçÂ§ßÈÄ≤Ê≠•„ÄÇÈÄôÈ†ÖÁ≥ªÁµ±ÊÄßÂõûÈ°ßÂØ©Êü•‰∫Ü 48 È†ÖÁ†îÁ©∂ÔºåÈÄô‰∫õÁ†îÁ©∂Êé°Áî®ÂÖàÈÄ≤ÁöÑ DL ÊñπÊ≥ïÂíåÊû∂Êßã„ÄÇÈÄô‰∫õË§áÈõúÁöÑ DL Ê®°ÂûãÂú®ÂÅµÊ∏¨ÂíåÂàÜÂâ≤Â§ñÁßëÊâãË°ìÂ∑•ÂÖ∑ÁöÑÁ≤æÊ∫ñÂ∫¶ÂíåÊïàÁéáÊñπÈù¢Â∑≤Â±ïÁèæÂá∫È°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÈÄô‰∫õÊ®°ÂûãÂ¢ûÂº∑ÁöÑÂäüËÉΩÊîØÊè¥ÂêÑÁ®ÆËá®Â∫äÊáâÁî®ÔºåÂåÖÊã¨Âç≥ÊôÇË°ì‰∏≠ÂºïÂ∞é„ÄÅÂÖ®Èù¢ÁöÑË°ìÂæåË©ï‰º∞ÂíåÂ§ñÁßëÊäÄË°ìÁöÑÂÆ¢ËßÄË©ï‰º∞„ÄÇÈÄèÈÅéÂú®ÂΩ±ÁâáË≥áÊñô‰∏≠Á≤æÁ¢∫Ë≠òÂà•ÂíåÂàÜÂâ≤Â§ñÁßëÂô®Ê¢∞ÔºåDL Ê®°ÂûãËÉΩÊèê‰æõË©≥Á¥∞ÁöÑÂõûÈ•ãÁµ¶Â§ñÁßëÈÜ´ÁîüÔºåÈÄ≤ËÄåÊîπÂñÑÊâãË°ìÁµêÊûú‰∏¶Èôç‰Ωé‰ΩµÁôºÁóáÈ¢®Èö™„ÄÇÊ≠§Â§ñÔºåDL Âú®Â§ñÁßëÊïôËÇ≤‰∏≠ÁöÑÊáâÁî®ÂÖ∑ÊúâËÆäÈù©ÊÄß„ÄÇÈÄôÈ†ÖÂõûÈ°ßÂº∑Ë™ø‰∫Ü DL Âú®ÊîπÂñÑÊäÄËÉΩË©ï‰º∞Ê∫ñÁ¢∫Â∫¶ÂíåÊï¥È´îÂ§ñÁßëË®ìÁ∑¥Ë®àÁï´ÂìÅË≥™ÊñπÈù¢ÁöÑÈáçÂ§ßÂΩ±Èüø„ÄÇÁÑ∂ËÄåÔºåÂú®Â§ñÁßëÂ∑•ÂÖ∑ÂÅµÊ∏¨ÂíåÂàÜÂâ≤‰∏≠ÂØ¶ÊñΩ DL Èù¢Ëá®ÊåëÊà∞Ôºå‰æãÂ¶ÇÈúÄË¶ÅÂ§ßÈáèÊ∫ñÁ¢∫Ë®ªËß£ÁöÑË≥áÊñôÈõÜÊâçËÉΩÊúâÊïàË®ìÁ∑¥ÈÄô‰∫õÊ®°Âûã„ÄÇÊâãÂãïË®ªËß£ÈÅéÁ®ãËÄóÊôÇ‰∏îË≤ªÂäõÔºåÊßãÊàê‰∫Ü‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÁì∂È†∏„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÊáâÂ∞àÊ≥®ÊñºËá™ÂãïÂåñÂÅµÊ∏¨ÂíåÂàÜÂâ≤ÊµÅÁ®ãÔºå‰∏¶Â¢ûÂº∑ DL Ê®°ÂûãÂ∞çÁí∞Â¢ÉËÆäÂåñÁöÑÈ≠ØÊ£íÊÄß„ÄÇÊì¥Â±ï DL Ê®°ÂûãÂú®ÂêÑÁ®ÆÂ§ñÁßëÂ∞àÁßëÁöÑÊáâÁî®Â∞çÊñºÂÖÖÂàÜÂØ¶ÁèæÈÄôÈ†ÖÊäÄË°ìÁöÑÊΩõÂäõËá≥ÈóúÈáçË¶Å„ÄÇÂ∞á DL ËàáÂÖ∂‰ªñÊñ∞ËààÊäÄË°ìÔºà‰æãÂ¶ÇÊì¥Â¢ûÂØ¶Â¢É (AR)ÔºâÊï¥Âêà‰πüÊèê‰æõ‰∫ÜÊúâÊúõÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑Â§ñÁßëÊâãË°ìÁ≤æÊ∫ñÂ∫¶ÂíåÊïàÁéáÁöÑÊ©üÊúÉ„ÄÇ

##### **Multimodal Representation Learning using Adaptive Graph Construction**
2410.06395v1 by Weichen Huang

Multimodal contrastive learning train neural networks by levergaing data from
heterogeneous sources such as images and text. Yet, many current multimodal
learning architectures cannot generalize to an arbitrary number of modalities
and need to be hand-constructed. We propose AutoBIND, a novel contrastive
learning framework that can learn representations from an arbitrary number of
modalites through graph optimization. We evaluate AutoBIND on Alzhiemer's
disease detection because it has real-world medical applicability and it
contains a broad range of data modalities. We show that AutoBIND outperforms
previous methods on this task, highlighting the generalizablility of the
approach.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÖãÂ∞çÊØîÂ≠∏ÁøíÈÄèÈÅéÂà©Áî®‰æÜËá™Áï∞Ë≥™‰æÜÊ∫êÔºà‰æãÂ¶ÇÂúñÂÉèÂíåÊñáÂ≠óÔºâÁöÑË≥áÊñô‰æÜË®ìÁ∑¥Á•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÇÁÑ∂ËÄåÔºåË®±Â§öÁõÆÂâçÁöÑÂ§öÊ®°ÊÖãÂ≠∏ÁøíÊû∂ÊßãÁÑ°Ê≥ïÊé®Âª£Âà∞‰ªªÊÑèÊï∏ÈáèÁöÑÊ®°ÊÖãÔºå‰∏¶‰∏îÈúÄË¶ÅÊâãÂãïÂª∫Êßã„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü AutoBINDÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ∞çÊØîÂ≠∏ÁøíÊû∂ÊßãÔºåÂÆÉÂèØ‰ª•ÈÄèÈÅéÂúñÂΩ¢ÊúÄ‰Ω≥ÂåñÂæû‰ªªÊÑèÊï∏ÈáèÁöÑÊ®°ÊÖã‰∏≠Â≠∏ÁøíË°®Âæµ„ÄÇÊàëÂÄëÂú®ÈòøËå≤Êµ∑ÈªòÁóáÁöÑÂÅµÊ∏¨‰∏äË©ï‰º∞ AutoBINDÔºåÂõ†ÁÇ∫ÂÆÉÂÖ∑ÊúâÂØ¶ÈöõÁöÑÈÜ´ÁôÇÊáâÁî®ÊÄßÔºåËÄå‰∏îÂÆÉÂåÖÂê´Âª£Ê≥õÁöÑË≥áÊñôÊ®°ÊÖã„ÄÇÊàëÂÄëÂ±ïÁ§∫ AutoBIND Âú®ÈÄôÈ†Ö‰ªªÂãô‰∏äÂÑ™ÊñºÂÖàÂâçÁöÑÂêÑÁ®ÆÊñπÊ≥ïÔºåÁ™ÅÈ°Ø‰∫ÜÊ≠§ÊñπÊ≥ïÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

##### **Skin Cancer Machine Learning Model Tone Bias**
2410.06385v1 by James Pope, Md Hassanuzzaman, Mingmar Sherpa, Omar Emara, Ayush Joshi, Nirmala Adhikari

Background: Many open-source skin cancer image datasets are the result of
clinical trials conducted in countries with lighter skin tones. Due to this
tone imbalance, machine learning models derived from these datasets can perform
well at detecting skin cancer for lighter skin tones. Any tone bias in these
models could introduce fairness concerns and reduce public trust in the
artificial intelligence health field.
  Methods: We examine a subset of images from the International Skin Imaging
Collaboration (ISIC) archive that provide tone information. The subset has a
significant tone imbalance. These imbalances could explain a model's tone bias.
To address this, we train models using the imbalanced dataset and a balanced
dataset to compare against. The datasets are used to train a deep convolutional
neural network model to classify the images as malignant or benign. We then
evaluate the models' disparate impact, based on selection rate, relative to
dark or light skin tone.
  Results: Using the imbalanced dataset, we found that the model is
significantly better at detecting malignant images in lighter tone resulting in
a disparate impact of 0.577. Using the balanced dataset, we found that the
model is also significantly better at detecting malignant images in lighter
versus darker tones with a disparate impact of 0.684. Using the imbalanced or
balanced dataset to train the model still results in a disparate impact well
below the standard threshold of 0.80 which suggests the model is biased with
respect to skin tone.
  Conclusion: The results show that typical skin cancer machine learning models
can be tone biased. These results provide evidence that diagnosis or tone
imbalance is not the cause of the bias. Other techniques will be necessary to
identify and address the bias in these models, an area of future investigation.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÔºöË®±Â§öÈñãÊîæÂéüÂßãÁ¢ºÁöÆËÜöÁôåÂúñÂÉèË≥áÊñôÈõÜÊòØÊ†πÊìöÂú®ËÜöËâ≤ËºÉÊ∑∫ÁöÑÂúãÂÆ∂ÈÄ≤Ë°åÁöÑËá®Â∫äË©¶È©óÁöÑÁµêÊûú„ÄÇÁî±ÊñºÈÄôÁ®ÆËâ≤Ë™ø‰∏çÂπ≥Ë°°ÔºåÂæûÈÄô‰∫õË≥áÊñôÈõÜÊ¥æÁîüÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®Ê™¢Ê∏¨ËÜöËâ≤ËºÉÊ∑∫ÁöÑÁöÆËÜöÁôåÊñπÈù¢Ë°®ÁèæËâØÂ•Ω„ÄÇÈÄô‰∫õÊ®°Âûã‰∏≠ÁöÑ‰ªª‰ΩïËâ≤Ë™øÂÅèÂ∑ÆÈÉΩÂèØËÉΩÂºïÁôºÂÖ¨Âπ≥ÊÄßÁöÑÂïèÈ°åÔºå‰∏¶Èôç‰ΩéÂÖ¨ÁúæÂ∞ç‰∫∫Â∑•Êô∫ÊÖßÂÅ•Â∫∑È†òÂüüÁöÑ‰ø°‰ªª„ÄÇ
ÊñπÊ≥ïÔºöÊàëÂÄëÊ™¢Êü•‰∫ÜÂúãÈöõÁöÆËÜöÂΩ±ÂÉèÂêà‰ΩúÁµÑÁπî (ISIC) Ê™îÊ°àÂ∫´‰∏≠Êèê‰æõËâ≤Ë™øË≥áË®äÁöÑÂúñÂÉèÂ≠êÈõÜ„ÄÇË©≤Â≠êÈõÜÂÖ∑ÊúâÈ°ØËëóÁöÑËâ≤Ë™ø‰∏çÂπ≥Ë°°„ÄÇÈÄô‰∫õ‰∏çÂπ≥Ë°°ÂèØËÉΩËß£Èáã‰∫ÜÊ®°ÂûãÁöÑËâ≤Ë™øÂÅèÂ∑Æ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄë‰ΩøÁî®‰∏çÂπ≥Ë°°ÁöÑË≥áÊñôÈõÜÂíåÂπ≥Ë°°ÁöÑË≥áÊñôÈõÜË®ìÁ∑¥Ê®°ÂûãÔºå‰ª•‰æøÈÄ≤Ë°åÊØîËºÉ„ÄÇÈÄô‰∫õË≥áÊñôÈõÜÁî®ÊñºË®ìÁ∑¥Ê∑±Â∫¶Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÔºåÂ∞áÂΩ±ÂÉèÂàÜÈ°ûÁÇ∫ÊÉ°ÊÄßÊàñËâØÊÄß„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊ†πÊìöÈÅ∏ÊìáÁéáË©ï‰º∞Ê®°ÂûãÁöÑ‰∏çÂêåÂΩ±ÈüøÔºåÁõ∏Â∞çÊñºÊ∑±Ëâ≤ÊàñÊ∑∫Ëâ≤ËÜöËâ≤„ÄÇ
ÁµêÊûúÔºö‰ΩøÁî®‰∏çÂπ≥Ë°°ÁöÑË≥áÊñôÈõÜÔºåÊàëÂÄëÁôºÁèæË©≤Ê®°ÂûãÂú®Ê™¢Ê∏¨Ê∑∫Ëâ≤Ëâ≤Ë™ø‰∏≠ÁöÑÊÉ°ÊÄßÂΩ±ÂÉèÊñπÈù¢È°ØËëóÂÑ™ÊñºÂú®Ê∑±Ëâ≤Ëâ≤Ë™ø‰∏≠Ê™¢Ê∏¨ÊÉ°ÊÄßÂΩ±ÂÉèÔºåÂ∞éËá¥ 0.577 ÁöÑ‰∏çÂêåÂΩ±Èüø„ÄÇ‰ΩøÁî®Âπ≥Ë°°ÁöÑË≥áÊñôÈõÜÔºåÊàëÂÄëÁôºÁèæË©≤Ê®°ÂûãÂú®Ê™¢Ê∏¨Ê∑∫Ëâ≤Ëâ≤Ë™ø‰∏≠ÁöÑÊÉ°ÊÄßÂΩ±ÂÉèÊñπÈù¢‰πüÈ°ØËëóÂÑ™ÊñºÊ∑±Ëâ≤Ëâ≤Ë™øÔºå‰∏çÂêåÂΩ±ÈüøÁÇ∫ 0.684„ÄÇ‰ΩøÁî®‰∏çÂπ≥Ë°°ÊàñÂπ≥Ë°°ÁöÑË≥áÊñôÈõÜË®ìÁ∑¥Ê®°Âûã‰ªçÁÑ∂ÊúÉÂ∞éËá¥‰∏çÂêåÂΩ±ÈüøÔºåÈÅ†‰ΩéÊñº 0.80 ÁöÑÊ®ôÊ∫ñÈñæÂÄºÔºåÈÄôË°®ÊòéÊ®°ÂûãÂú®ËÜöËâ≤ÊñπÈù¢ÊúâÂÅèÂ∑Æ„ÄÇ
ÁµêË´ñÔºöÁµêÊûúË°®ÊòéÔºåÂÖ∏ÂûãÁöÑÁöÆËÜöÁôåÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂèØËÉΩÊúÉÁî¢ÁîüËâ≤Ë™øÂÅèÂ∑Æ„ÄÇÈÄô‰∫õÁµêÊûúÊèê‰æõ‰∫ÜË≠âÊìöË°®ÊòéÔºåË®∫Êñ∑ÊàñËâ≤Ë™ø‰∏çÂπ≥Ë°°‰∏¶ÈùûÈÄ†ÊàêÂÅèÂ∑ÆÁöÑÂéüÂõ†„ÄÇÈúÄË¶ÅÂÖ∂‰ªñÊäÄË°ì‰æÜË≠òÂà•ÂíåËß£Ê±∫ÈÄô‰∫õÊ®°Âûã‰∏≠ÁöÑÂÅèÂ∑ÆÔºåÈÄôÊòØÊú™‰æÜÁ†îÁ©∂ÁöÑ‰∏ÄÂÄãÈ†òÂüü„ÄÇ</paragraph>

##### **HumVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid**
2410.06370v2 by Hemank Lamba, Anton Abilov, Ke Zhang, Elizabeth M. Olson, Henry k. Dambanemuya, Jo√£o c. B√°rcia, David S. Batista, Christina Wille, Aoife Cahill, Joel Tetreault, Alex Jaimes

Humanitarian organizations can enhance their effectiveness by analyzing data
to discover trends, gather aggregated insights, manage their security risks,
support decision-making, and inform advocacy and funding proposals. However,
data about violent incidents with direct impact and relevance for humanitarian
aid operations is not readily available. An automatic data collection and
NLP-backed classification framework aligned with humanitarian perspectives can
help bridge this gap. In this paper, we present HumVI - a dataset comprising
news articles in three languages (English, French, Arabic) containing instances
of different types of violent incidents categorized by the humanitarian sector
they impact, e.g., aid security, education, food security, health, and
protection. Reliable labels were obtained for the dataset by partnering with a
data-backed humanitarian organization, Insecurity Insight. We provide multiple
benchmarks for the dataset, employing various deep learning architectures and
techniques, including data augmentation and mask loss, to address different
task-related challenges, e.g., domain expansion. The dataset is publicly
available at https://github.com/dataminr-ai/humvi-dataset.

ÊëòË¶ÅÔºö‰∫∫ÈÅì‰∏ªÁæ©ÁµÑÁπîÂèØÈÄèÈÅéÂàÜÊûêË≥áÊñô‰æÜÊèêÂçáÂÖ∂ÊàêÊïàÔºå‰ª•ÊâæÂá∫Ë∂®Âã¢„ÄÅÊî∂ÈõÜÂΩôÊï¥ÁöÑË¶ãËß£„ÄÅÁÆ°ÁêÜÂÖ∂ÂÆâÂÖ®È¢®Èö™„ÄÅÊîØÊè¥Ê±∫Á≠ñÂà∂ÂÆöÔºå‰ª•ÂèäÂëäÁü•ÂÄ°Ë≠∞ÂíåÂãüÊ¨æÊèêÊ°à„ÄÇ‰∏çÈÅéÔºåËàá‰∫∫ÈÅì‰∏ªÁæ©Êè¥Âä©Ë°åÂãïÁõ¥Êé•Áõ∏Èóú‰∏îÂÖ∑ÂΩ±ÈüøÂäõÁöÑÊö¥Âäõ‰∫ã‰ª∂Ë≥áÊñô‰∏¶‰∏çÂÆπÊòìÂèñÂæó„ÄÇ‰∏ÄÂÄãËàá‰∫∫ÈÅì‰∏ªÁæ©ËßÄÈªû‰∏ÄËá¥ÁöÑËá™ÂãïË≥áÊñôÊî∂ÈõÜÂíå NLP ÊîØÊè¥ÂàÜÈ°ûÊû∂ÊßãÔºåÊúâÂä©ÊñºÂΩåË£úÈÄôÂÄãÂ∑ÆË∑ù„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ HumVI - ‰∏ÄÂÄãÂåÖÂê´‰∏âÁ®ÆË™ûË®ÄÔºàËã±Ë™û„ÄÅÊ≥ïË™û„ÄÅÈòøÊãâ‰ºØË™ûÔºâÊñ∞ËÅûÊñáÁ´†ÁöÑË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫∫ÈÅì‰∏ªÁæ©ÈÉ®ÈñÄÂàÜÈ°ûÁöÑ‰∏çÂêåÈ°ûÂûãÊö¥Âäõ‰∫ã‰ª∂ÂØ¶‰æãÔºå‰æãÂ¶ÇÊè¥Âä©ÂÆâÂÖ®„ÄÅÊïôËÇ≤„ÄÅÁ≥ßÈ£üÂÆâÂÖ®„ÄÅÂÅ•Â∫∑Âíå‰øùË≠∑„ÄÇÊàëÂÄëÈÄèÈÅéËàáË≥áÊñôÊîØÊè¥ÁöÑ‰∫∫ÈÅì‰∏ªÁæ©ÁµÑÁπî Insecurity Insight Âêà‰ΩúÔºåÂèñÂæóË≥áÊñôÈõÜÁöÑÂèØÈù†Ê®ôÁ±§„ÄÇÊàëÂÄëÁÇ∫Ë≥áÊñôÈõÜÊèê‰æõÂ§öÂÄãÂü∫Ê∫ñÔºåÊé°Áî®ÂêÑÁ®ÆÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÂíåÊäÄË°ìÔºåÂåÖÊã¨Ë≥áÊñôÊì¥ÂÖÖÂíåÈÅÆÁΩ©ÊêçÂ§±Ôºå‰ª•ÊáâÂ∞ç‰∏çÂêåÁöÑ‰ªªÂãôÁõ∏ÈóúÊåëÊà∞Ôºå‰æãÂ¶ÇÈ†òÂüüÊì¥ÂÖÖ„ÄÇË≥áÊñôÈõÜÂ∑≤Êñº https://github.com/dataminr-ai/humvi-dataset ÂÖ¨Èñã„ÄÇ

##### **A Comparative Study of Hybrid Models in Health Misinformation Text Classification**
2410.06311v1 by Mkululi Sikosana, Oluwaseun Ajao, Sean Maudsley-Barton

This study evaluates the effectiveness of machine learning (ML) and deep
learning (DL) models in detecting COVID-19-related misinformation on online
social networks (OSNs), aiming to develop more effective tools for countering
the spread of health misinformation during the pan-demic. The study trained and
tested various ML classifiers (Naive Bayes, SVM, Random Forest, etc.), DL
models (CNN, LSTM, hybrid CNN+LSTM), and pretrained language models
(DistilBERT, RoBERTa) on the "COVID19-FNIR DATASET". These models were
evaluated for accuracy, F1 score, recall, precision, and ROC, and used
preprocessing techniques like stemming and lemmatization. The results showed
SVM performed well, achieving a 94.41% F1-score. DL models with Word2Vec
embeddings exceeded 98% in all performance metrics (accuracy, F1 score, recall,
precision & ROC). The CNN+LSTM hybrid models also exceeded 98% across
performance metrics, outperforming pretrained models like DistilBERT and
RoBERTa. Our study concludes that DL and hybrid DL models are more effective
than conventional ML algorithms for detecting COVID-19 misinformation on OSNs.
The findings highlight the importance of advanced neural network approaches and
large-scale pretraining in misinformation detection. Future research should
optimize these models for various misinformation types and adapt to changing
OSNs, aiding in combating health misinformation.

ÊëòË¶ÅÔºöÈÄôÈ†ÖÁ†îÁ©∂Ë©ï‰º∞Ê©üÂô®Â≠∏Áøí (ML) ÂíåÊ∑±Â∫¶Â≠∏Áøí (DL) Ê®°ÂûãÂú®ÂÅµÊ∏¨Á∑ö‰∏äÁ§æÁæ§Á∂≤Ë∑Ø (OSN) ‰∏äËàá COVID-19 Áõ∏ÈóúÁöÑÈåØË™§Ë®äÊÅØÁöÑÊúâÊïàÊÄßÔºåÁõÆÊ®ôÊòØÈñãÁôºÊõ¥ÊúâÊïàÁöÑÂ∑•ÂÖ∑‰æÜÂ∞çÊäóÂ§ßÊµÅË°åÊúüÈñìÂÅ•Â∫∑ÈåØË™§Ë®äÊÅØÁöÑÊï£Â∏É„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Ë®ìÁ∑¥‰∏¶Ê∏¨Ë©¶‰∫ÜÂêÑÁ®Æ ML ÂàÜÈ°ûÂô®ÔºàÊ®∏Á¥†Ë≤ùÊ∞è„ÄÅSVM„ÄÅÈö®Ê©üÊ£ÆÊûóÁ≠âÔºâ„ÄÅDL Ê®°ÂûãÔºàCNN„ÄÅLSTM„ÄÅÊ∑∑Âêà CNN+LSTMÔºâÂíåÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÔºàDistilBERT„ÄÅRoBERTaÔºâÂú®„ÄåCOVID19-FNIR Ë≥áÊñôÈõÜ„Äç‰∏ä„ÄÇÈÄô‰∫õÊ®°ÂûãÁ∂ìÈÅéË©ï‰º∞ÔºåÊ®ôÊ∫ñÁÇ∫Ê∫ñÁ¢∫Â∫¶„ÄÅF1 ÂàÜÊï∏„ÄÅÂè¨ÂõûÁéá„ÄÅÁ≤æÁ¢∫Â∫¶Âíå ROCÔºå‰∏¶‰ΩøÁî®‰∫ÜË©ûÂππÂåñÂíåË©ûÂΩ¢ÈÇÑÂéüÁ≠âÂâçËôïÁêÜÊäÄË°ì„ÄÇÁµêÊûúÈ°ØÁ§∫ SVM Ë°®ÁèæËâØÂ•ΩÔºåÈÅîÂà∞ 94.41% ÁöÑ F1 ÂàÜÊï∏„ÄÇ‰ΩøÁî® Word2Vec ÂµåÂÖ•ÁöÑ DL Ê®°ÂûãÂú®ÊâÄÊúâÊïàËÉΩÊåáÊ®ôÔºàÊ∫ñÁ¢∫Â∫¶„ÄÅF1 ÂàÜÊï∏„ÄÅÂè¨ÂõûÁéá„ÄÅÁ≤æÁ¢∫Â∫¶Âíå ROCÔºâ‰∏≠ÈÉΩË∂ÖÈÅé 98%„ÄÇCNN+LSTM Ê∑∑ÂêàÊ®°ÂûãÂú®ÊâÄÊúâÊïàËÉΩÊåáÊ®ô‰∏≠‰πüË∂ÖÈÅé 98%ÔºåÂÑ™Êñº DistilBERT Âíå RoBERTa Á≠âÈ†êË®ìÁ∑¥Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêË´ñÊòØÔºåDL ÂíåÊ∑∑Âêà DL Ê®°ÂûãÊØîÂÇ≥Áµ± ML ÊºîÁÆóÊ≥ïÊõ¥ËÉΩÊúâÊïàÂÅµÊ∏¨ OSN ‰∏äÁöÑ COVID-19 ÈåØË™§Ë®äÊÅØ„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÈÄ≤ÈöéÁ•ûÁ∂ìÁ∂≤Ë∑ØÊñπÊ≥ïÂíåÈåØË™§Ë®äÊÅØÂÅµÊ∏¨‰∏≠Â§ßË¶èÊ®°È†êË®ìÁ∑¥ÁöÑÈáçË¶ÅÊÄß„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÊáâÈáùÂ∞çÂêÑÁ®ÆÈåØË™§Ë®äÊÅØÈ°ûÂûãÊúÄ‰Ω≥ÂåñÈÄô‰∫õÊ®°ÂûãÔºå‰∏¶ÈÅ©Êáâ‰∏çÊñ∑ËÆäÂåñÁöÑ OSNÔºåÂçîÂä©ÊâìÊìäÂÅ•Â∫∑ÈåØË™§Ë®äÊÅØ„ÄÇ

##### **Application of NotebookLM, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging**
2410.10869v1 by Ryota Tozuka, Hisashi Johno, Akitomo Amakawa, Junichi Sato, Mizuki Muto, Shoichiro Seki, Atsushi Komaba, Hiroshi Onishi

Purpose: In radiology, large language models (LLMs), including ChatGPT, have
recently gained attention, and their utility is being rapidly evaluated.
However, concerns have emerged regarding their reliability in clinical
applications due to limitations such as hallucinations and insufficient
referencing. To address these issues, we focus on the latest technology,
retrieval-augmented generation (RAG), which enables LLMs to reference reliable
external knowledge (REK). Specifically, this study examines the utility and
reliability of a recently released RAG-equipped LLM (RAG-LLM), NotebookLM, for
staging lung cancer.
  Materials and methods: We summarized the current lung cancer staging
guideline in Japan and provided this as REK to NotebookLM. We then tasked
NotebookLM with staging 100 fictional lung cancer cases based on CT findings
and evaluated its accuracy. For comparison, we performed the same task using a
gold-standard LLM, GPT-4 Omni (GPT-4o), both with and without the REK.
  Results: NotebookLM achieved 86% diagnostic accuracy in the lung cancer
staging experiment, outperforming GPT-4o, which recorded 39% accuracy with the
REK and 25% without it. Moreover, NotebookLM demonstrated 95% accuracy in
searching reference locations within the REK.
  Conclusion: NotebookLM successfully performed lung cancer staging by
utilizing the REK, demonstrating superior performance compared to GPT-4o.
Additionally, it provided highly accurate reference locations within the REK,
allowing radiologists to efficiently evaluate the reliability of NotebookLM's
responses and detect possible hallucinations. Overall, this study highlights
the potential of NotebookLM, a RAG-LLM, in image diagnosis.

ÊëòË¶ÅÔºö<paragraph>ÁõÆÁöÑÔºöÂú®ÊîæÂ∞ÑÂ≠∏‰∏≠ÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂåÖÊã¨ ChatGPTÔºåÊúÄËøëÂèóÂà∞ÈóúÊ≥®Ôºå‰∏¶‰∏îÂÆÉÂÄëÁöÑÊïàÁî®Ê≠£Ë¢´ËøÖÈÄüË©ï‰º∞„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂπªË¶∫ÂíåÂèÉËÄÉ‰∏çË∂≥Á≠âÈôêÂà∂Ôºå‰∫∫ÂÄëÈñãÂßãÈóúÊ≥®ÂÆÉÂÄëÂú®Ëá®Â∫äÊáâÁî®‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÊúÄÊñ∞ÁöÑÊäÄË°ìÔºåÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG)ÔºåÂÆÉ‰Ωø LLM ËÉΩÂ§†ÂèÉËÄÉÂèØÈù†ÁöÑÂ§ñÈÉ®Áü•Ë≠ò (REK)„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÈÄôÈ†ÖÁ†îÁ©∂Êé¢Ë®é‰∫ÜÊúÄËøëÁôºÂ∏ÉÁöÑÈÖçÂÇô RAG ÁöÑ LLM (RAG-LLM)ÔºåNotebookLMÔºåÂú®ËÇ∫ÁôåÂàÜÊúüÁöÑÊïàÁî®ÂíåÂèØÈù†ÊÄß„ÄÇÊùêÊñôÂíåÊñπÊ≥ïÔºöÊàëÂÄëÁ∏ΩÁµê‰∫ÜÊó•Êú¨Áï∂ÂâçÁöÑËÇ∫ÁôåÂàÜÊúüÊåáÂçóÔºå‰∏¶Â∞áÂÖ∂‰ΩúÁÇ∫ REK Êèê‰æõÁµ¶ NotebookLM„ÄÇÁÑ∂ÂæåÊàëÂÄëËÆì NotebookLM Ê†πÊìö CT ÁµêÊûúÂ∞ç 100 ÂÄãËôõÊßãÁöÑËÇ∫ÁôåÁóÖ‰æãÈÄ≤Ë°åÂàÜÊúüÔºå‰∏¶Ë©ï‰º∞ÂÖ∂Ê∫ñÁ¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜÈÄ≤Ë°åÊØîËºÉÔºåÊàëÂÄë‰ΩøÁî®ÈªÉÈáëÊ®ôÊ∫ñ LLMÔºåGPT-4 Omni (GPT-4o) Âü∑Ë°åÁõ∏ÂêåÁöÑ‰ªªÂãôÔºåÊúâÂíåÊ≤íÊúâ REK ÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇÁµêÊûúÔºöNotebookLM Âú®ËÇ∫ÁôåÂàÜÊúüÂØ¶È©ó‰∏≠ÂØ¶Áèæ‰∫Ü 86% ÁöÑË®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÔºåÂÑ™Êñº GPT-4oÔºåÂæåËÄÖÂú®Êúâ REK ÁöÑÊÉÖÊ≥Å‰∏ãÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 39%ÔºåÊ≤íÊúâ REK ÁöÑÊÉÖÊ≥Å‰∏ãÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 25%„ÄÇÊ≠§Â§ñÔºåNotebookLM Âú® REK ‰∏≠ÊêúÁ¥¢ÂèÉËÄÉ‰ΩçÁΩÆÁöÑÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 95%„ÄÇÁµêË´ñÔºöNotebookLM ÈÄöÈÅéÂà©Áî® REK ÊàêÂäüÂú∞ÈÄ≤Ë°å‰∫ÜËÇ∫ÁôåÂàÜÊúüÔºåËàá GPT-4o Áõ∏ÊØîË°®ÁèæÂá∫ÂÑ™Ë∂äÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÂÆÉÂú® REK ‰∏≠Êèê‰æõ‰∫ÜÈ´òÂ∫¶Ê∫ñÁ¢∫ÁöÑÂèÉËÄÉ‰ΩçÁΩÆÔºå‰ΩøÊîæÂ∞ÑÁßëÈÜ´ÁîüËÉΩÂ§†ÊúâÊïàÂú∞Ë©ï‰º∞ NotebookLM ÁöÑÈüøÊáâÁöÑÂèØÈù†ÊÄß‰∏¶Ê™¢Ê∏¨ÂèØËÉΩÁöÑÂπªË¶∫„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÈÄôÈ†ÖÁ†îÁ©∂Á™ÅÂá∫‰∫Ü NotebookLMÔºå‰∏ÄÁ®Æ RAG-LLMÔºåÂú®ÂΩ±ÂÉèË®∫Êñ∑‰∏≠ÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **CodeUnlearn: Amortized Zero-Shot Machine Unlearning in Language Models Using Discrete Concept**
2410.10866v1 by YuXuan Wu, Bonaventure F. P. Dossou, Dianbo Liu

Large Language Models (LLMs) offer extensive knowledge across various
domains, but they may inadvertently memorize sensitive, unauthorized, or
malicious data, such as personal information in the medical and financial
sectors. Machine unlearning methods aim to remove specific information from
models after training to address this. However, current approaches require
additional model training or struggle to effectively erase particular data
points and their associated context due to LLMs' complex, dense, and continuous
nature. In this study, we propose a novel amortized unlearning approach using
codebook features and Sparse Autoencoders (SAEs). By leveraging a bottleneck to
decompose the activation space and regulate information flow, our method
efficiently unlearns targeted information while preserving the model's
performance on unrelated data. To the best of our knowledge, this is the first
work that successfully enables unlearning specific topics with contextual
relevance in an LLM, marking a significant step towards real-world applications
of machine unlearning.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØÊèê‰æõË∑®‰∏çÂêåÈ†òÂüüÁöÑÂª£Ê≥õÁü•Ë≠òÔºå‰ΩÜÂÆÉÂÄëÂèØËÉΩÊúÉ‰∏çÁ∂ìÊÑèÂú∞Ë®ò‰ΩèÊïèÊÑü„ÄÅÊú™Á∂ìÊéàÊ¨äÊàñÊÉ°ÊÑèÁöÑË≥áÊñôÔºå‰æãÂ¶ÇÈÜ´ÁôÇÂíåÈáëËûçÈ†òÂüüÁöÑÂÄã‰∫∫Ë≥áË®ä„ÄÇÊ©üÂô®ÂèñÊ∂àÂ≠∏ÁøíÊñπÊ≥ïÊó®Âú®ÈÄèÈÅéÂú®Ë®ìÁ∑¥ÂæåÂæûÊ®°Âûã‰∏≠ÁßªÈô§ÁâπÂÆöË≥áË®ä‰æÜËß£Ê±∫Ê≠§ÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑ‰ΩúÊ≥ïÈúÄË¶ÅÈ°çÂ§ñÊ®°ÂûãË®ìÁ∑¥ÔºåÊàñÂõ† LLM Ë§áÈõú„ÄÅÂØÜÈõÜ‰∏îÊåÅÁ∫åÁöÑÁâπÊÄßËÄåÈõ£‰ª•ÊúâÊïàÂú∞Ê∏ÖÈô§ÁâπÂÆöË≥áÊñôÈªûÂèäÂÖ∂ÈóúËÅØËÑàÁµ°„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊî§Èä∑ÂèñÊ∂àÂ≠∏ÁøíÊñπÊ≥ïÔºå‰ΩøÁî®Á¢ºÊú¨ÁâπÂæµÂíåÁ®ÄÁñèËá™ÂãïÁ∑®Á¢ºÂô® (SAE)„ÄÇÈÄèÈÅéÂà©Áî®Áì∂È†∏‰æÜÂàÜËß£ÂïüÁî®Á©∫ÈñìÂíåË¶èÁØÑË≥áË®äÊµÅÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•ÊúâÊïàÂú∞ÂèñÊ∂àÂ≠∏ÁøíÁõÆÊ®ôË≥áË®äÔºåÂêåÊôÇ‰øùÁïôÊ®°ÂûãÂú®‰∏çÁõ∏ÈóúË≥áÊñô‰∏äÁöÑÊïàËÉΩ„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊàêÂäüËÆì LLM ÂèñÊ∂àÂ≠∏ÁøíÁâπÂÆö‰∏ªÈ°åÂèäÂÖ∂ËÑàÁµ°Áõ∏ÈóúÊÄßÁöÑ‰ΩúÂìÅÔºåÁÇ∫Ê©üÂô®ÂèñÊ∂àÂ≠∏ÁøíÁöÑÂØ¶ÈöõÊáâÁî®ÈÇÅÂá∫‰∏ÄÂ§ßÊ≠•„ÄÇ

##### **KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server**
2410.05725v2 by Wenhao Wang, Xiaoyu Liang, Rui Ye, Jingyi Chai, Siheng Chen, Yanfeng Wang

The success of large language models (LLMs) facilitate many parties to
fine-tune LLMs on their own private data. However, this practice raises privacy
concerns due to the memorization of LLMs. Existing solutions, such as utilizing
synthetic data for substitution, struggle to simultaneously improve performance
and preserve privacy. They either rely on a local model for generation,
resulting in a performance decline, or take advantage of APIs, directly
exposing the data to API servers. To address this issue, we propose
KnowledgeSG, a novel client-server framework which enhances synthetic data
quality and improves model performance while ensuring privacy. We achieve this
by learning local knowledge from the private data with differential privacy
(DP) and distilling professional knowledge from the server. Additionally,
inspired by federated learning, we transmit models rather than data between the
client and server to prevent privacy leakage. Extensive experiments in medical
and financial domains demonstrate the effectiveness of KnowledgeSG. Our code is
now publicly available at https://github.com/wwh0411/KnowledgeSG.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊàêÂäüËÆìË®±Â§ö‰∫∫ÂèØ‰ª•ÂæÆË™ø LLM ‰ª•Á¨¶Âêà‰ªñÂÄëÁöÑÁßÅ‰∫∫Ë≥áÊñô„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº LLM ÁöÑË®òÊÜ∂ÂäüËÉΩÔºåÊ≠§ÂÅöÊ≥ïÂºïÁôº‰∫ÜÈö±ÁßÅÂïèÈ°å„ÄÇÁèæÊúâÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰æãÂ¶Ç‰ΩøÁî®ÂêàÊàêË≥áÊñôÈÄ≤Ë°åÊõøÊèõÔºåÈõ£‰ª•ÂêåÊôÇÊîπÂñÑÊïàËÉΩ‰∏¶Á∂≠Ë≠∑Èö±ÁßÅ„ÄÇÂÆÉÂÄë‰æùË≥¥ÊñºÂçÄÂüüÊ®°ÂûãÈÄ≤Ë°åÁî¢ÁîüÔºåÂ∞éËá¥ÊïàËÉΩ‰∏ãÈôçÔºåÊàñÂà©Áî® APIÔºåÁõ¥Êé•Â∞áË≥áÊñôÂÖ¨ÈñãÁµ¶ API ‰º∫ÊúçÂô®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ KnowledgeSGÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂÆ¢Êà∂Á´Ø‰º∫ÊúçÂô®Êû∂ÊßãÔºåÂÆÉËÉΩÊèêÂçáÂêàÊàêË≥áÊñôÂìÅË≥™‰∏¶ÊîπÂñÑÊ®°ÂûãÊïàËÉΩÔºåÂêåÊôÇÁ¢∫‰øùÈö±ÁßÅ„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî®Â∑ÆÂàÜÈö±ÁßÅ (DP) ÂæûÁßÅ‰∫∫Ë≥áÊñô‰∏≠Â≠∏ÁøíÂçÄÂüüÁü•Ë≠òÔºå‰∏¶Âæû‰º∫ÊúçÂô®‰∏≠ËêÉÂèñÂ∞àÊ•≠Áü•Ë≠ò‰æÜÈÅîÊàêÊ≠§ÁõÆÊ®ô„ÄÇÊ≠§Â§ñÔºåÂèóÂà∞ËÅØÈÇ¶Â≠∏ÁøíÁöÑÂïüÁôºÔºåÊàëÂÄëÂÇ≥Ëº∏Ê®°ÂûãËÄåÈùûË≥áÊñôÂú®ÂÆ¢Êà∂Á´ØÂíå‰º∫ÊúçÂô®‰πãÈñìÔºå‰ª•Èò≤Ê≠¢Èö±ÁßÅÂ§ñÊ¥©„ÄÇÂú®ÈÜ´ÁôÇÂíåÈáëËûçÈ†òÂüüÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫Ü KnowledgeSG ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÁèæÂú®ÂÖ¨ÈñãÊñº https://github.com/wwh0411/KnowledgeSG„ÄÇ

##### **Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs**
2410.05684v2 by Yi Jiang, Qingyang Shen, Shuzhong Lai, Shunyu Qi, Qian Zheng, Lin Yao, Yueming Wang, Gang Pan

Autism spectrum disorder(ASD) is a pervasive developmental disorder that
significantly impacts the daily functioning and social participation of
individuals. Despite the abundance of research focused on supporting the
clinical diagnosis of ASD, there is still a lack of systematic and
comprehensive exploration in the field of methods based on Large Language
Models (LLMs), particularly regarding the real-world clinical diagnostic
scenarios based on Autism Diagnostic Observation Schedule, Second Edition
(ADOS-2). Therefore, we have proposed a framework called ADOS-Copilot, which
strikes a balance between scoring and explanation and explored the factors that
influence the performance of LLMs in this task. The experimental results
indicate that our proposed framework is competitive with the diagnostic results
of clinicians, with a minimum MAE of 0.4643, binary classification F1-score of
81.79\%, and ternary classification F1-score of 78.37\%. Furthermore, we have
systematically elucidated the strengths and limitations of current LLMs in this
task from the perspectives of ADOS-2, LLMs' capabilities, language, and model
scale aiming to inspire and guide the future application of LLMs in a broader
fields of mental health disorders. We hope for more research to be transferred
into real clinical practice, opening a window of kindness to the world for
eccentric children.

ÊëòË¶ÅÔºöËá™ÈñâÁóáË≠úÁ≥ªÈöúÁ§ô (ASD) ÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÁöÑÁôºÂ±ïÈöúÁ§ôÔºåÊúÉÈ°ØËëóÂΩ±ÈüøÂÄãÈ´îÁöÑÊó•Â∏∏ÁîüÊ¥ªÂäüËÉΩÂíåÁ§æ‰∫§ÂèÉËàá„ÄÇÂÑòÁÆ°ÊúâÂ§ßÈáèÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºÊîØÊåÅ ASD ÁöÑËá®Â∫äË®∫Êñ∑Ôºå‰ΩÜÂú®Âü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊñπÊ≥ïÈ†òÂüü‰∏≠Ôºå‰ªçÁÑ∂Áº∫‰πèÁ≥ªÁµ±‰∏îÂÖ®Èù¢ÁöÑÊé¢Á¥¢ÔºåÁâπÂà•ÊòØÈóúÊñºÂü∫ÊñºËá™ÈñâÁóáË®∫Êñ∑ËßÄÂØüÈáèË°®Á¨¨‰∫åÁâàÁöÑÁúüÂØ¶‰∏ñÁïåËá®Â∫äË®∫Êñ∑ÊÉÖÂ¢É (ADOS-2)„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ ADOS-Copilot ÁöÑÊ°ÜÊû∂ÔºåÂÆÉÂú®Ë©ïÂàÜÂíåËß£Èáã‰πãÈñìÂèñÂæóÂπ≥Ë°°Ôºå‰∏¶Êé¢Ë®é‰∫ÜÂΩ±Èüø LLM Âú®Ê≠§‰ªªÂãô‰∏≠Ë°®ÁèæÁöÑÂõ†Á¥†„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊ°ÜÊû∂ËàáËá®Â∫äÈÜ´ÁîüÁöÑË®∫Êñ∑ÁµêÊûúÂÖ∑ÊúâÁ´∂Áà≠ÂäõÔºåMAE ÊúÄÂ∞èÁÇ∫ 0.4643Ôºå‰∫åÂÖÉÂàÜÈ°û F1 ÂàÜÊï∏ÁÇ∫ 81.79%Ôºå‰∏âÂÖÉÂàÜÈ°û F1 ÂàÜÊï∏ÁÇ∫ 78.37%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂæû ADOS-2„ÄÅLLM ÁöÑËÉΩÂäõ„ÄÅË™ûË®ÄÂíåÊ®°ÂûãË¶èÊ®°ÁöÑËßíÂ∫¶Á≥ªÁµ±Âú∞Èó°Êòé‰∫ÜÁï∂Ââç LLM Âú®Ê≠§‰ªªÂãô‰∏≠ÁöÑÂÑ™Âã¢ÂíåÂ±ÄÈôêÊÄßÔºåÊó®Âú®ÊøÄÂãµÂíåÊåáÂ∞é LLM Âú®Êõ¥Âª£Ê≥õÁöÑÁ≤æÁ•ûÁñæÁóÖÈ†òÂüü‰∏≠ÁöÑÊú™‰æÜÊáâÁî®„ÄÇÊàëÂÄëÂ∏åÊúõÊõ¥Â§öÁöÑÁ†îÁ©∂ËÉΩËΩâÂåñÁÇ∫ÁúüÊ≠£ÁöÑËá®Â∫äÂØ¶Ë∏êÔºåÁÇ∫Âè§ÊÄ™ÁöÑÂ≠©Â≠êÂÄëÊâìÈñã‰∏ÄÊâáÈÄöÂæÄ‰∏ñÁïåÁöÑÂñÑÊÑè‰πãÁ™ó„ÄÇ

##### **NegMerge: Consensual Weight Negation for Strong Machine Unlearning**
2410.05583v1 by Hyoseo Kim, Dongyoon Han, Junsuk Choe

Machine unlearning aims to selectively remove specific knowledge from a
model. Current methods, such as task arithmetic, rely on fine-tuning models on
the forget set, generating a task vector, and subtracting it from the original
model. However, we argue the effectiveness of this approach is highly sensitive
to hyperparameter selection, necessitating careful validation to identify the
best model among many fine-tuned candidates. In this paper, we propose a novel
method that leverages all given fine-tuned models rather than selecting a
single one. By constructing task vectors from models trained with varied
hyperparameters and merging only the components of the task vectors with
consistent signs, we perform unlearning by negating the merged task vector from
the original model. Given that existing methods also utilize multiple
fine-tuned models, our approach delivers more effective unlearning without
incurring additional computational costs. We demonstrate the effectiveness of
our method on both vision-language models and standard image classification
models, showing improved unlearning performance with minimal degradation on the
retain set, outperforming state-of-the-art techniques.

ÊëòË¶ÅÔºöÊ©üÂô®ÂéªÂ≠∏ÁøíÊó®Âú®ÈÅ∏ÊìáÊÄßÂú∞ÂæûÊ®°Âûã‰∏≠ÁßªÈô§ÁâπÂÆöÁü•Ë≠ò„ÄÇÁõÆÂâçÁöÑÊñπÊ≥ïÔºå‰æãÂ¶Ç‰ªªÂãôÁÆóË°ìÔºå‰æùË≥¥ÊñºÂú®ÈÅ∫ÂøòÈõÜ‰∏äÂæÆË™øÊ®°ÂûãÔºåÁîüÊàê‰ªªÂãôÂêëÈáèÔºå‰∏¶ÂæûÂéüÂßãÊ®°Âûã‰∏≠Ê∏õÂéªÂÆÉ„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëË™çÁÇ∫ÈÄôÁ®ÆÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂ∞çË∂ÖÂèÉÊï∏ÈÅ∏ÊìáÈ´òÂ∫¶ÊïèÊÑüÔºåÈúÄË¶Å‰ªîÁ¥∞È©óË≠â‰ª•Âú®Ë®±Â§öÂæÆË™øÂÄôÈÅ∏ËÄÖ‰∏≠ÊâæÂá∫ÊúÄ‰Ω≥Ê®°Âûã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂà©Áî®ÊâÄÊúâÁµ¶ÂÆöÁöÑÂæÆË™øÊ®°ÂûãÔºåËÄå‰∏çÊòØÈÅ∏Êìá‰∏ÄÂÄã„ÄÇÈÄöÈÅé‰ΩøÁî®ÂÖ∑Êúâ‰∏çÂêåË∂ÖÂèÉÊï∏Ë®ìÁ∑¥ÁöÑÊ®°ÂûãÊßãÂª∫‰ªªÂãôÂêëÈáèÔºå‰∏¶ÂÉÖÂêà‰ΩµÂÖ∑ÊúâÁõ∏ÂêåÁ¨¶ËôüÁöÑ‰ªªÂãôÂêëÈáèÁöÑÁµÑÊàêÈÉ®ÂàÜÔºåÊàëÂÄëÈÄöÈÅéÂæûÂéüÂßãÊ®°Âûã‰∏≠Âê¶ÂÆöÂêà‰ΩµÁöÑ‰ªªÂãôÂêëÈáè‰æÜÂü∑Ë°åÂéªÂ≠∏Áøí„ÄÇÈëëÊñºÁèæÊúâÊñπÊ≥ï‰πüÂà©Áî®Â§öÂÄãÂæÆË™øÊ®°ÂûãÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®‰∏çÁî¢ÁîüÈ°çÂ§ñË®àÁÆóÊàêÊú¨ÁöÑÊÉÖÊ≥Å‰∏ãÊèê‰æõ‰∫ÜÊõ¥ÊúâÊïàÁöÑÂéªÂ≠∏Áøí„ÄÇÊàëÂÄëÂú®Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÂíåÊ®ôÊ∫ñÂúñÂÉèÂàÜÈ°ûÊ®°Âûã‰∏äÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÈ°ØÁ§∫Âá∫ÊîπÈÄ≤ÁöÑÂéªÂ≠∏ÁøíÊÄßËÉΩÔºåÂêåÊôÇÂ∞ç‰øùÁïôÈõÜÁöÑ‰∏ãÈôçÂπÖÂ∫¶ÊúÄÂ∞èÔºåÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊäÄË°ì„ÄÇ

##### **AI-Driven Early Mental Health Screening with Limited Data: Analyzing Selfies of Pregnant Women**
2410.05450v1 by Gustavo A. Bas√≠lio, Thiago B. Pereira, Alessandro L. Koerich, Ludmila Dias, Maria das Gra√ßas da S. Teixeira, Rafael T. Sousa, Wilian H. Hisatugu, Amanda S. Mota, Anilton S. Garcia, Marco Aur√©lio K. Galletta, Hermano Tavares, Thiago M. Paix√£o

Major Depressive Disorder and anxiety disorders affect millions globally,
contributing significantly to the burden of mental health issues. Early
screening is crucial for effective intervention, as timely identification of
mental health issues can significantly improve treatment outcomes. Artificial
intelligence (AI) can be valuable for improving the screening of mental
disorders, enabling early intervention and better treatment outcomes. AI-driven
screening can leverage the analysis of multiple data sources, including facial
features in digital images. However, existing methods often rely on controlled
environments or specialized equipment, limiting their broad applicability. This
study explores the potential of AI models for ubiquitous depression-anxiety
screening given face-centric selfies. The investigation focuses on high-risk
pregnant patients, a population that is particularly vulnerable to mental
health issues. To cope with limited training data resulting from our clinical
setup, pre-trained models were utilized in two different approaches:
fine-tuning convolutional neural networks (CNNs) originally designed for facial
expression recognition and employing vision-language models (VLMs) for
zero-shot analysis of facial expressions. Experimental results indicate that
the proposed VLM-based method significantly outperforms CNNs, achieving an
accuracy of 77.6% and an F1-score of 56.0%. Although there is significant room
for improvement, the results suggest that VLMs can be a promising approach for
mental health screening, especially in scenarios with limited data.

ÊëòË¶ÅÔºöÈáçÂ∫¶ÊÜÇÈ¨±ÁóáÂíåÁÑ¶ÊÖÆÁóáÂΩ±ÈüøÂÖ®ÁêÉÊï∏ÁôæËê¨‰∫∫Ôºå
Â∞çÂøÉÁêÜÂÅ•Â∫∑ÂïèÈ°åÁöÑË≤†ÊìîÊúâÈ°ØËëóÁöÑÂΩ±Èüø„ÄÇÊó©Êúü
ÁØ©Ê™¢Â∞çÊñºÊúâÊïàÂπ≤È†êËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂèäÊôÇË≠òÂà•
ÂøÉÁêÜÂÅ•Â∫∑ÂïèÈ°åÂèØ‰ª•È°ØËëóÊîπÂñÑÊ≤ªÁôÇÁµêÊûú„ÄÇ‰∫∫Â∑•
Êô∫ÊÖß (AI) ÂèØ‰ª•ÁÇ∫ÊîπÂñÑÂøÉÁêÜÁñæÁóÖÁöÑÁØ©Ê™¢Êèê‰æõÊúâÂÉπÂÄºÁöÑÂπ´Âä©Ôºå
ÂØ¶ÁèæÊó©ÊúüÂπ≤È†êÂíåÊõ¥Â•ΩÁöÑÊ≤ªÁôÇÁµêÊûú„ÄÇAI È©ÖÂãïÁöÑ
ÁØ©Ê™¢ÂèØ‰ª•Âà©Áî®Â§öÂÄãÊï∏Êìö‰æÜÊ∫êÁöÑÂàÜÊûêÔºåÂåÖÊã¨Êï∏‰ΩçÂΩ±ÂÉè‰∏≠ÁöÑËáâÈÉ®
ÁâπÂæµ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥ÂèóÊéß
Áí∞Â¢ÉÊàñÂ∞àÊ•≠Ë®≠ÂÇôÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑÂª£Ê≥õÈÅ©Áî®ÊÄß„ÄÇÊú¨
Á†îÁ©∂Êé¢Ë®é AI Ê®°ÂûãÂú®ÁÑ°ÊâÄ‰∏çÂú®ÁöÑÊÜÇÈ¨±ÁóáÁÑ¶ÊÖÆÁóá
ÁØ©Ê™¢‰∏≠Ôºå‰ª•ËáâÈÉ®ÁÇ∫‰∏≠ÂøÉÁöÑËá™ÊãçÁöÑÊΩõÂäõ„ÄÇË™øÊü•ÈáçÈªûÈóúÊ≥®È´òÈ¢®Èö™
Â≠ïÂ©¶ÔºåÈÄôÊòØ‰∏ÄÂÄãÁâπÂà•ÂÆπÊòìÂèóÂà∞ÂøÉÁêÜÂÅ•Â∫∑ÂïèÈ°åÂΩ±ÈüøÁöÑ‰∫∫Áæ§„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÂõ†ÊàëÂÄëÁöÑËá®Â∫ä
Ë®≠ÁΩÆËÄåÁî¢ÁîüÁöÑÊúâÈôêË®ìÁ∑¥Ë≥áÊñôÔºåÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãË¢´Áî®ÊñºÂÖ©Á®Æ‰∏çÂêåÁöÑÊñπÊ≥ïÔºö
ÂæÆË™øÂéüÊú¨Ë®≠Ë®àÁî®ÊñºËáâÈÉ®Ë°®ÊÉÖËæ®Ë≠òÁöÑÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN)Ôºå‰∏¶Êé°Áî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ÈÄ≤Ë°å
Èõ∂Ê¨°Â≠∏ÁøíÁöÑËáâÈÉ®Ë°®ÊÉÖÂàÜÊûê„ÄÇÂØ¶È©óÁµêÊûúË°®Êòé
ÊèêÂá∫ÁöÑÂü∫Êñº VLM ÁöÑÊñπÊ≥ïÈ°ØËëóÂÑ™Êñº CNNÔºåÈÅîÂà∞ 77.6% ÁöÑÊ∫ñÁ¢∫ÁéáÂíå 56.0% ÁöÑ F1 ÂàÜÊï∏„ÄÇÂÑòÁÆ°ÊúâÈ°ØËëóÁöÑÊîπÈÄ≤Á©∫ÈñìÔºå
ÁµêÊûúË°®Êòé VLM ÂèØ‰ª•ÊàêÁÇ∫ÂøÉÁêÜÂÅ•Â∫∑ÁØ©Ê™¢ÁöÑ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÔºåÁâπÂà•ÊòØÂú®Ë≥áÊñôÊúâÈôêÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇ

##### **Improving Predictor Reliability with Selective Recalibration**
2410.05407v1 by Thomas P. Zollo, Zhun Deng, Jake C. Snell, Toniann Pitassi, Richard Zemel

A reliable deep learning system should be able to accurately express its
confidence with respect to its predictions, a quality known as calibration. One
of the most effective ways to produce reliable confidence estimates with a
pre-trained model is by applying a post-hoc recalibration method. Popular
recalibration methods like temperature scaling are typically fit on a small
amount of data and work in the model's output space, as opposed to the more
expressive feature embedding space, and thus usually have only one or a handful
of parameters. However, the target distribution to which they are applied is
often complex and difficult to fit well with such a function. To this end we
propose \textit{selective recalibration}, where a selection model learns to
reject some user-chosen proportion of the data in order to allow the
recalibrator to focus on regions of the input space that can be well-captured
by such a model. We provide theoretical analysis to motivate our algorithm, and
test our method through comprehensive experiments on difficult medical imaging
and zero-shot classification tasks. Our results show that selective
recalibration consistently leads to significantly lower calibration error than
a wide range of selection and recalibration baselines.

ÊëòË¶ÅÔºö‰∏ÄÂÄãÂèØÈù†ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÁ≥ªÁµ±ÊáâË©≤ËÉΩÂ§†Ê∫ñÁ¢∫Âú∞Ë°®ÈÅîÂÖ∂Â∞çÈ†êÊ∏¨ÁöÑ‰ø°ÂøÉÔºåÈÄôÈ†ÖÂìÅË≥™Á®±ÁÇ∫Ê†°Ê∫ñ„ÄÇ‰ΩøÁî®È†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãÁî¢ÁîüÂèØÈù†ÁöÑ‰ø°ÂøÉ‰º∞Ë®àÂÄºÊúÄÊúâÊïàÁöÑÊñπÊ≥ï‰πã‰∏ÄÊòØÊáâÁî®‰∫ãÂæåÈáçÊñ∞Ê†°Ê∫ñÊñπÊ≥ï„ÄÇÁÜ±ÈñÄÁöÑÈáçÊñ∞Ê†°Ê∫ñÊñπÊ≥ïÔºà‰æãÂ¶ÇÊ∫´Â∫¶Á∏ÆÊîæÔºâÈÄöÂ∏∏ÈÅ©Áî®ÊñºÂ∞ëÈáèË≥áÊñôÔºå‰∏¶Âú®Ê®°ÂûãÁöÑËº∏Âá∫Á©∫Èñì‰∏≠ÈÅã‰ΩúÔºåËÄå‰∏çÊòØÊõ¥ÂÖ∑Ë°®ÁèæÂäõÁöÑÁâπÂæµÂµåÂÖ•Á©∫ÈñìÔºåÂõ†Ê≠§ÈÄöÂ∏∏Âè™Êúâ‰∏ÄÂÄãÊàñÂ∞ëÊï∏ÂπæÂÄãÂèÉÊï∏„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÊâÄÊáâÁî®ÁöÑÁõÆÊ®ôÂàÜ‰ΩàÈÄöÂ∏∏ÂæàË§áÈõúÔºå‰∏îÈõ£‰ª•Áî®Ê≠§È°ûÂáΩÊï∏ÂÅöËâØÂ•ΩÁöÑÊì¨Âêà„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫„ÄåÈÅ∏ÊìáÊÄßÈáçÊñ∞Ê†°Ê∫ñ„ÄçÔºåÂÖ∂‰∏≠ÈÅ∏ÊìáÊ®°ÂûãÊúÉÂ≠∏ÁøíÊãíÁµï‰ΩøÁî®ËÄÖÈÅ∏ÊìáÁöÑÊüê‰∫õË≥áÊñôÊØî‰æãÔºå‰ª•ÂÖÅË®±ÈáçÊñ∞Ê†°Ê∫ñÂô®Â∞àÊ≥®ÊñºËº∏ÂÖ•Á©∫Èñì‰∏≠ËÉΩË¢´Ê≠§È°ûÊ®°ÂûãËâØÂ•ΩÊçïÊçâÂà∞ÁöÑÂçÄÂüü„ÄÇÊàëÂÄëÊèê‰æõÁêÜË´ñÂàÜÊûê‰æÜÊøÄÂãµÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÔºå‰∏¶ÈÄèÈÅéÂú®Âõ∞Èõ£ÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÈõ∂Ê¨°ÂàÜÈ°û‰ªªÂãô‰∏≠ÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÂØ¶È©ó‰æÜÊ∏¨Ë©¶ÊàëÂÄëÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÈÅ∏ÊìáÊÄßÈáçÊñ∞Ê†°Ê∫ñÊåÅÁ∫åÂ∞éËá¥Ê†°Ê∫ñË™§Â∑ÆÈ°ØËëó‰ΩéÊñºÂêÑÁ®ÆÈÅ∏ÊìáÂíåÈáçÊñ∞Ê†°Ê∫ñÂü∫Á∑ö„ÄÇ

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

ÊëòË¶ÅÔºöËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊ±∫Á≠ñÊòØÁèæÂú® AI ÁöÑ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞ÔºåÁâπÂà•ÊòØÊáâÁî®ÊñºÂÉèÈÜ´Â≠∏ÂíåÊ≥ïÂæãÁ≠âÊïèÊÑüÊÉÖÂ¢ÉÊôÇ„ÄÇÁÑ∂ËÄåÔºåËß£ÈáãÊ±∫Á≠ñËÉåÂæåÁêÜÁî±ÁöÑÈúÄÊ±Ç‰πüÊòØÂü∫Êñº‰∫∫È°ûÁöÑËÄÉÈáèÁöÑ‰∏ÄÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÂõ†ÁÇ∫ÊúâÂøÖË¶ÅË≠âÊòéÁÇ∫‰ªÄÈ∫ºÂÅöÂá∫ÊüêÂÄãÊ±∫Á≠ñ„ÄÇ‰æãÂ¶ÇÔºå‰ΩèÈô¢ÈÜ´Â∏´‰∏çÂÉÖÈúÄË¶ÅÊèê‰æõÔºàÂèØËÉΩÊòØÊ≠£Á¢∫ÁöÑÔºâË®∫Êñ∑ÔºåÈÇÑÈúÄË¶ÅËß£Èáã‰ªñÂÄëÂ¶Ç‰ΩïÈÅîÊàêÊüêÂÄãÁµêË´ñ„ÄÇÂõ†Ê≠§ÔºåÈñãÁôºÊñ∞ÁöÑÂ∑•ÂÖ∑‰æÜÂπ´Âä©‰ΩèÈô¢ÈÜ´Â∏´Ë®ìÁ∑¥‰ªñÂÄëÁöÑËß£ÈáãÊäÄÂ∑ßÊòØÊïôËÇ≤‰∏≠ AI ÁöÑ‰∏ÄÈ†ÖÊ†∏ÂøÉÁõÆÊ®ô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÅµÂæ™ÈÄôÂÄãÊñπÂêëÔºå‰∏¶‰∏îÊ†πÊìöÊàëÂÄëÁöÑ‰∫ÜËß£ÔºåÊèêÂá∫Á¨¨‰∏ÄÂÄãÂ§öË™ûË®ÄÈÜ´Â≠∏ÂïèÁ≠îË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠Ëá®Â∫äÁóÖ‰æãÁöÑÊ≠£Á¢∫Âíå‰∏çÊ≠£Á¢∫Ë®∫Êñ∑ÈÉΩÈôÑÊúâÁî±ÈÜ´ÁîüÊí∞ÂØ´ÁöÑËá™ÁÑ∂Ë™ûË®ÄËß£Èáã„ÄÇÈÄô‰∫õËß£ÈáãÂ∑≤‰ΩøÁî®Ë´ñË≠âÁµÑÊàêÔºàÂç≥ÂâçÊèê„ÄÅ‰∏ªÂºµÔºâÂíåË´ñË≠âÈóú‰øÇÔºàÂç≥ÊîªÊìä„ÄÅÊîØÊåÅÔºâÈÄ≤Ë°åÊâãÂãïË®ªËß£ÔºåÁî¢ÁîüÂ§öË™ûË®Ä CasiMedicos-Arg Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ 558 ÂÄãÂÖ∑ÊúâËß£ÈáãÁöÑÂõõÁ®ÆË™ûË®ÄÔºàËã±Ë™û„ÄÅË•øÁè≠ÁâôË™û„ÄÅÊ≥ïË™û„ÄÅÁæ©Â§ßÂà©Ë™ûÔºâÁöÑËá®Â∫äÁóÖ‰æãÔºåÊàëÂÄëË®ªËß£‰∫Ü 5021 ÂÄã‰∏ªÂºµ„ÄÅ2313 ÂÄãÂâçÊèê„ÄÅ2431 ÂÄãÊîØÊåÅÈóú‰øÇÂíå 1106 ÂÄãÊîªÊìäÈóú‰øÇ„ÄÇÊàëÂÄëÊúÄÂæåÂ±ïÁ§∫‰∫ÜÁ´∂Áà≠Âü∫Ê∫ñÂ¶Ç‰ΩïÈáùÂ∞çË´ñË≠âÊé¢Âãò‰ªªÂãôÂü∑Ë°åÊ≠§ÂÖ∑ÊåëÊà∞ÊÄßÁöÑË≥áÊñôÈõÜ„ÄÇ

##### **RespLLM: Unifying Audio and Text with Multimodal LLMs for Generalized Respiratory Health Prediction**
2410.05361v1 by Yuwei Zhang, Tong Xia, Aaqib Saeed, Cecilia Mascolo

The high incidence and mortality rates associated with respiratory diseases
underscores the importance of early screening. Machine learning models can
automate clinical consultations and auscultation, offering vital support in
this area. However, the data involved, spanning demographics, medical history,
symptoms, and respiratory audio, are heterogeneous and complex. Existing
approaches are insufficient and lack generalizability, as they typically rely
on limited training data, basic fusion techniques, and task-specific models. In
this paper, we propose RespLLM, a novel multimodal large language model (LLM)
framework that unifies text and audio representations for respiratory health
prediction. RespLLM leverages the extensive prior knowledge of pretrained LLMs
and enables effective audio-text fusion through cross-modal attentions.
Instruction tuning is employed to integrate diverse data from multiple sources,
ensuring generalizability and versatility of the model. Experiments on five
real-world datasets demonstrate that RespLLM outperforms leading baselines by
an average of 4.6% on trained tasks, 7.9% on unseen datasets, and facilitates
zero-shot predictions for new tasks. Our work lays the foundation for
multimodal models that can perceive, listen to, and understand heterogeneous
data, paving the way for scalable respiratory health diagnosis.

ÊëòË¶ÅÔºöÈ´òÁôºÁîüÁéáÂíåÊ≠ª‰∫°ÁéáÁöÑÂëºÂê∏ÈÅìÁñæÁóÖÁ™ÅÈ°Ø‰∫ÜÊó©ÊúüÁØ©Ê™¢ÁöÑÈáçË¶ÅÊÄß„ÄÇÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂèØ‰ª•Ëá™ÂãïÂåñËá®Â∫äË´ÆË©¢ÂíåËÅΩË®∫ÔºåÂú®Ê≠§È†òÂüüÊèê‰æõÈáçË¶ÅÁöÑÊîØÊè¥„ÄÇÁÑ∂ËÄåÔºåÊâÄÊ∂âÂèäÁöÑË≥áÊñôÊ∂µËìã‰∫∫Âè£Áµ±Ë®à„ÄÅÁóÖÂè≤„ÄÅÁóáÁãÄÂíåÂëºÂê∏Èü≥Ë®äÔºåÊó¢Áï∞Ë≥™ÂèàË§áÈõú„ÄÇÁèæÊúâÁöÑÊñπÊ≥ï‰∏çË∂≥‰∏îÁº∫‰πèÊ¶ÇÊã¨ÊÄßÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÈÄöÂ∏∏‰æùË≥¥ÊñºÊúâÈôêÁöÑË®ìÁ∑¥Ë≥áÊñô„ÄÅÂü∫Êú¨ÁöÑËûçÂêàÊäÄË°ìÂíåÁâπÂÆöÊñº‰ªªÂãôÁöÑÊ®°Âûã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ RespLLMÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ê°ÜÊû∂ÔºåÂÆÉÁµ±‰∏Ä‰∫ÜÊñáÊú¨ÂíåÈü≥Ë®äË°®Á§∫Ôºå‰ª•ÈÄ≤Ë°åÂëºÂê∏ÈÅìÂÅ•Â∫∑È†êÊ∏¨„ÄÇRespLLM Âà©Áî®È†êË®ìÁ∑¥ LLM ÁöÑÂª£Ê≥õÂÖàÈ©óÁü•Ë≠òÔºå‰∏¶ÈÄèÈÅéË∑®Ê®°ÊÖãÊ≥®ÊÑèÂäõÂØ¶ÁèæÊúâÊïàÁöÑÈü≥Ë®äÊñáÊú¨ËûçÂêà„ÄÇÊåáÁ§∫Ë™øÊï¥Áî®ÊñºÊï¥Âêà‰æÜËá™Â§öÂÄã‰æÜÊ∫êÁöÑ‰∏çÂêåË≥áÊñôÔºåÁ¢∫‰øùÊ®°ÂûãÁöÑÊ¶ÇÊã¨ÊÄßÂíåÂ§öÂäüËÉΩÊÄß„ÄÇÂú®‰∫îÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåRespLLM Âú®Ë®ìÁ∑¥‰ªªÂãô‰∏äÊØîÈ†òÂÖàÁöÑÂü∫Ê∫ñÈ´òÂá∫Âπ≥Âùá 4.6%ÔºåÂú®Êú™Ë¶ãË≥áÊñôÈõÜ‰∏äÈ´òÂá∫ 7.9%Ôºå‰∏¶‰øÉÈÄ≤Êñ∞‰ªªÂãôÁöÑÈõ∂Ê¨°Â≠∏ÁøíÈ†êÊ∏¨„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁÇ∫Â§öÊ®°ÊÖãÊ®°ÂûãÂ•†ÂÆö‰∫ÜÂü∫Á§éÔºåÈÄô‰∫õÊ®°ÂûãÂèØ‰ª•ÊÑüÁü•„ÄÅËÅÜËÅΩÂíåÁêÜËß£Áï∞Ë≥™Ë≥áÊñôÔºåÁÇ∫ÂèØÊì¥ÂÖÖÁöÑÂëºÂê∏ÈÅìÂÅ•Â∫∑Ë®∫Êñ∑Èã™Âπ≥ÈÅìË∑Ø„ÄÇ

##### **Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization**
2410.05114v1 by Rohan Reddy Mekala, Frederik Pahde, Simon Baur, Sneha Chandrashekar, Madeline Diep, Markus Wenzel, Eric L. Wisotzky, Galip √úmit Yolcu, Sebastian Lapuschkin, Jackie Ma, Peter Eisert, Mikael Lindvall, Adam Porter, Wojciech Samek

In the realm of dermatological diagnoses, where the analysis of dermatoscopic
and microscopic skin lesion images is pivotal for the accurate and early
detection of various medical conditions, the costs associated with creating
diverse and high-quality annotated datasets have hampered the accuracy and
generalizability of machine learning models. We propose an innovative
unsupervised augmentation solution that harnesses Generative Adversarial
Network (GAN) based models and associated techniques over their latent space to
generate controlled semiautomatically-discovered semantic variations in
dermatoscopic images. We created synthetic images to incorporate the semantic
variations and augmented the training data with these images. With this
approach, we were able to increase the performance of machine learning models
and set a new benchmark amongst non-ensemble based models in skin lesion
classification on the HAM10000 dataset; and used the observed analytics and
generated models for detailed studies on model explainability, affirming the
effectiveness of our solution.

ÊëòË¶ÅÔºöÂú®ÁöÆËÜöÁßëË®∫Êñ∑È†òÂüüÔºåÁöÆËÜöÈè°Ê™¢Êü•ÂíåÈ°ØÂæÆÈè°ÁöÆËÜöÁóÖËÆäÂΩ±ÂÉèÁöÑÂàÜÊûêÂ∞çÊñºÊ∫ñÁ¢∫‰∏îÊó©ÊúüÂÅµÊ∏¨ÂêÑÁ®ÆÈÜ´ÁôÇÁãÄÊ≥ÅËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂª∫Á´ãÂ§öÊ®£Âåñ‰∏îÈ´òÂìÅË≥™ÁöÑÊ®ôË®òË≥áÊñôÈõÜÁõ∏ÈóúÊàêÊú¨Â∑≤ÈòªÁ§ôÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊôÆÈÅçÊÄß„ÄÇÊàëÂÄëÊèêÂá∫ÂâµÊñ∞ÁöÑÈùûÁõ£Áù£ÂºèÊì¥ÂÖÖËß£Ê±∫ÊñπÊ°àÔºåÂà©Áî®ÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (GAN) Âü∫Á§éÊ®°ÂûãÂèäÂÖ∂Âú®ÊΩõÂú®Á©∫Èñì‰∏äÁöÑÁõ∏ÈóúÊäÄË°ìÔºå‰ª•Âú®ÁöÆËÜöÈè°ÂΩ±ÂÉè‰∏≠Áî¢ÁîüÂèóÊéßÁöÑÂçäËá™ÂãïÁôºÁèæË™ûÁæ©ËÆäÂåñ„ÄÇÊàëÂÄëÂª∫Á´ãÂêàÊàêÂΩ±ÂÉè‰ª•Á¥çÂÖ•Ë™ûÁæ©ËÆäÂåñÔºå‰∏¶‰ΩøÁî®ÈÄô‰∫õÂΩ±ÂÉèÊì¥ÂÖÖË®ìÁ∑¥Ë≥áÊñô„ÄÇÈÄèÈÅéÊ≠§ÊñπÊ≥ïÔºåÊàëÂÄëÂæó‰ª•ÊèêÂçáÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩÔºå‰∏¶Âú® HAM10000 Ë≥áÊñôÈõÜÁöÑÁöÆËÜöÁóÖËÆäÂàÜÈ°û‰∏≠Ë®≠ÂÆöÈùûÊï¥È´îÂºèÊ®°ÂûãÁöÑÊñ∞Âü∫Ê∫ñÔºõ‰∏¶‰ΩøÁî®ËßÄÂØüÂà∞ÁöÑÂàÜÊûêÂíåÂª∫Á´ãÁöÑÊ®°ÂûãÈÄ≤Ë°åÊ®°ÂûãÂèØËß£ÈáãÊÄßÁöÑË©≥Á¥∞Á†îÁ©∂ÔºåÁ¢∫Ë™çÊàëÂÄëËß£Ê±∫ÊñπÊ°àÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Named Clinical Entity Recognition Benchmark**
2410.05046v1 by Wadood M Abdul, Marco AF Pimentel, Muhammad Umar Salman, Tathagata Raha, Cl√©ment Christophe, Praveen K Kanithi, Nasir Hayat, Ronnie Rajan, Shadab Khan

This technical report introduces a Named Clinical Entity Recognition
Benchmark for evaluating language models in healthcare, addressing the crucial
natural language processing (NLP) task of extracting structured information
from clinical narratives to support applications like automated coding,
clinical trial cohort identification, and clinical decision support.
  The leaderboard provides a standardized platform for assessing diverse
language models, including encoder and decoder architectures, on their ability
to identify and classify clinical entities across multiple medical domains. A
curated collection of openly available clinical datasets is utilized,
encompassing entities such as diseases, symptoms, medications, procedures, and
laboratory measurements. Importantly, these entities are standardized according
to the Observational Medical Outcomes Partnership (OMOP) Common Data Model,
ensuring consistency and interoperability across different healthcare systems
and datasets, and a comprehensive evaluation of model performance. Performance
of models is primarily assessed using the F1-score, and it is complemented by
various assessment modes to provide comprehensive insights into model
performance. The report also includes a brief analysis of models evaluated to
date, highlighting observed trends and limitations.
  By establishing this benchmarking framework, the leaderboard aims to promote
transparency, facilitate comparative analyses, and drive innovation in clinical
entity recognition tasks, addressing the need for robust evaluation methods in
healthcare NLP.

ÊëòË¶ÅÔºöÈÄô‰ªΩÊäÄË°ìÂ†±Âëä‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂëΩÂêçËá®Â∫äÂØ¶È´îËæ®Ë≠òÂü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑË™ûË®ÄÊ®°ÂûãÔºåËß£Ê±∫ÂæûËá®Â∫äÊïòËø∞‰∏≠ËêÉÂèñÁµêÊßãÂåñË≥áË®äÁöÑÈóúÈçµËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãôÔºå‰ª•ÊîØÊè¥Ëá™ÂãïÁ∑®Á¢º„ÄÅËá®Â∫äË©¶È©óÁæ§ÁµÑË≠òÂà•ÂíåËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≠âÊáâÁî®Á®ãÂºè„ÄÇ
ÊéíË°åÊ¶úÊèê‰æõ‰∏ÄÂÄãÊ®ôÊ∫ñÂåñÂπ≥Âè∞ÔºåÁî®ÊñºË©ï‰º∞ÂêÑÁ®ÆË™ûË®ÄÊ®°ÂûãÔºåÂåÖÊã¨Á∑®Á¢ºÂô®ÂíåËß£Á¢ºÂô®Êû∂ÊßãÔºå‰ª•ÂèäÂÆÉÂÄëË∑®Â§öÂÄãÈÜ´ÁôÇÈ†òÂüüË≠òÂà•ÂíåÂàÜÈ°ûËá®Â∫äÂØ¶È´îÁöÑËÉΩÂäõ„ÄÇÂà©Áî®Á≤æÂøÉÊï¥ÁêÜÁöÑÂÖ¨ÈñãËá®Â∫äË≥áÊñôÈõÜÔºåÊ∂µËìãÁñæÁóÖ„ÄÅÁóáÁãÄ„ÄÅËó•Áâ©„ÄÅÁ®ãÂ∫èÂíåÂØ¶È©óÂÆ§Ê∏¨ÈáèÁ≠âÂØ¶È´î„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÈÄô‰∫õÂØ¶È´îÊ†πÊìöËßÄÂØüÊÄßÈÜ´ÁôÇÁµêÊûúÂêà‰ΩúÂ§•‰º¥Èóú‰øÇ (OMOP) Â∏∏Ë¶ãË≥áÊñôÊ®°ÂûãÊ®ôÊ∫ñÂåñÔºåÁ¢∫‰øù‰∏çÂêåÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÂíåË≥áÊñôÈõÜ‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄßÂíå‰∫íÈÄöÊÄßÔºå‰ª•ÂèäÊ®°ÂûãÊïàËÉΩÁöÑÂÖ®Èù¢Ë©ï‰º∞„ÄÇÊ®°ÂûãÊïàËÉΩ‰∏ªË¶Å‰ΩøÁî® F1 ÂàÜÊï∏Ë©ï‰º∞Ôºå‰∏¶Ëºî‰ª•ÂêÑÁ®ÆË©ï‰º∞Ê®°ÂºèÔºåÊèê‰æõÂ∞çÊ®°ÂûãÊïàËÉΩÁöÑÂÖ®Èù¢Ë¶ãËß£„ÄÇÂ†±ÂëäÈÇÑÂåÖÊã¨Â∞çËøÑ‰ªäË©ï‰º∞Ê®°ÂûãÁöÑÁ∞°Ë¶ÅÂàÜÊûêÔºåÈáçÈªûË™™ÊòéËßÄÂØüÂà∞ÁöÑË∂®Âã¢ÂíåÈôêÂà∂„ÄÇ
ÈÄèÈÅéÂª∫Á´ãÊ≠§Âü∫Ê∫ñÊû∂ÊßãÔºåÊéíË°åÊ¶úÊó®Âú®‰øÉÈÄ≤ÈÄèÊòéÂ∫¶„ÄÅ‰øÉÈÄ≤ÊØîËºÉÂàÜÊûêÔºå‰∏¶Êé®ÂãïËá®Â∫äÂØ¶È´îËæ®Ë≠ò‰ªªÂãôÁöÑÂâµÊñ∞ÔºåÊªøË∂≥ÈÜ´ÁôÇ‰øùÂÅ• NLP ‰∏≠Â∞çÂÅ•ÂÖ®Ë©ï‰º∞ÊñπÊ≥ïÁöÑÈúÄÊ±Ç„ÄÇ

##### **Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data**
2410.04814v1 by Manuel Brenner, Elias Weber, Georgia Koppe, Daniel Durstewitz

In science, we are often interested in obtaining a generative model of the
underlying system dynamics from observed time series. While powerful methods
for dynamical systems reconstruction (DSR) exist when data come from a single
domain, how to best integrate data from multiple dynamical regimes and leverage
it for generalization is still an open question. This becomes particularly
important when individual time series are short, and group-level information
may help to fill in for gaps in single-domain data. At the same time, averaging
is not an option in DSR, as it will wipe out crucial dynamical properties
(e.g., limit cycles in one domain vs. chaos in another). Hence, a framework is
needed that enables to efficiently harvest group-level (multi-domain)
information while retaining all single-domain dynamical characteristics. Here
we provide such a hierarchical approach and showcase it on popular DSR
benchmarks, as well as on neuroscientific and medical time series. In addition
to faithful reconstruction of all individual dynamical regimes, our
unsupervised methodology discovers common low-dimensional feature spaces in
which datasets with similar dynamics cluster. The features spanning these
spaces were further dynamically highly interpretable, surprisingly in often
linear relation to control parameters that govern the dynamics of the
underlying system. Finally, we illustrate transfer learning and generalization
to new parameter regimes.

ÊëòË¶ÅÔºöÂú®ÁßëÂ≠∏‰∏≠ÔºåÊàëÂÄëÂ∏∏Â∏∏ÊúâËààË∂£ÂæûËßÄÂØüÂà∞ÁöÑÊôÇÈñìÂ∫èÂàó‰∏≠Áç≤ÂæóÂü∫Á§éÁ≥ªÁµ±ÂãïÊÖãÁöÑÁîüÊàêÊ®°Âûã„ÄÇÈõñÁÑ∂Áï∂Ë≥áÊñô‰æÜËá™ÂñÆ‰∏ÄÈ†òÂüüÊôÇÔºåÂº∑Â§ßÁöÑÂãïÊÖãÁ≥ªÁµ±ÈáçÂª∫ (DSR) ÊñπÊ≥ïÂ∑≤Á∂ìÂ≠òÂú®Ôºå‰ΩÜÂ¶Ç‰ΩïÊúÄ‰Ω≥Êï¥Âêà‰æÜËá™Â§öÂÄãÂãïÊÖãÊ©üÂà∂ÁöÑË≥áÊñô‰∏¶Âà©Áî®ÂÆÉÈÄ≤Ë°åÊ¶ÇÊã¨‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈñãÊîæÁöÑÂïèÈ°å„ÄÇÁï∂ÂÄãÂà•ÊôÇÈñìÂ∫èÂàóÂæàÁü≠ÊôÇÔºåÈÄô‰∏ÄÈªûÂ∞§ÂÖ∂ÈáçË¶ÅÔºåËÄå‰∏îÁæ§ÁµÑÂ±§Á¥öÁöÑË≥áË®äÂèØËÉΩÊúâÂä©ÊñºÂ°´Ë£úÂñÆ‰∏ÄÈ†òÂüüË≥áÊñô‰∏≠ÁöÑÁ©∫ÁôΩ„ÄÇÂêåÊôÇÔºåÂπ≥ÂùáÂåñ‰∏¶Èùû DSR ‰∏≠ÁöÑÈÅ∏È†ÖÔºåÂõ†ÁÇ∫ÂÆÉÊúÉÊ∂àÈô§ÈóúÈçµÁöÑÂãïÊÖãÁâπÊÄßÔºà‰æãÂ¶ÇÔºå‰∏ÄÂÄãÈ†òÂüü‰∏≠ÁöÑÊ•µÈôêÈÄ±ÊúüÁõ∏Â∞çÊñºÂè¶‰∏ÄÂÄãÈ†òÂüü‰∏≠ÁöÑÊ∑∑‰∫ÇÔºâ„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶Å‰∏ÄÂÄãÊ°ÜÊû∂ÔºåËÉΩÂ§†ÊúâÊïàÊî∂ÈõÜÁæ§ÁµÑÂ±§Á¥öÔºàÂ§öÈ†òÂüüÔºâË≥áË®äÔºåÂêåÊôÇ‰øùÁïôÊâÄÊúâÂñÆ‰∏ÄÈ†òÂüüÂãïÊÖãÁâπÊÄß„ÄÇÂú®ÈÄôË£°ÔºåÊàëÂÄëÊèê‰æõÈÄôÁ®ÆÈöéÂ±§ÂºèÊñπÊ≥ïÔºå‰∏¶Âú®ÊµÅË°åÁöÑ DSR Âü∫Ê∫ñ‰ª•ÂèäÁ•ûÁ∂ìÁßëÂ≠∏ÂíåÈÜ´Â≠∏ÊôÇÈñìÂ∫èÂàó‰∏≠Â±ïÁ§∫ÂÆÉ„ÄÇÈô§‰∫ÜÂø†ÂØ¶ÈáçÂª∫ÊâÄÊúâÂÄãÂà•ÂãïÊÖãÊ©üÂà∂‰πãÂ§ñÔºåÊàëÂÄëÁöÑÈùûÁõ£Áù£ÊñπÊ≥ïÈÇÑÁôºÁèæ‰∫ÜÂ∏∏Ë¶ãÁöÑ‰ΩéÁ∂≠ÁâπÂæµÁ©∫ÈñìÔºåÂÖ∂‰∏≠ÂÖ∑ÊúâÁõ∏‰ººÂãïÊÖãÁöÑË≥áÊñôÈõÜÊúÉÊàêÁæ§„ÄÇË∑®Ë∂äÈÄô‰∫õÁ©∫ÈñìÁöÑÁâπÂæµÂú®ÂãïÊÖã‰∏äÈÄ≤‰∏ÄÊ≠•ÂÖ∑ÊúâÈ´òÂ∫¶ÂèØËß£ÈáãÊÄßÔºå‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÂÆÉÂÄëÈÄöÂ∏∏ËàáÊéßÂà∂Âü∫Á§éÁ≥ªÁµ±ÂãïÊÖãÁöÑÊéßÂà∂ÂèÉÊï∏ÂëàÁ∑öÊÄßÈóú‰øÇ„ÄÇÊúÄÂæåÔºåÊàëÂÄëË™™Êòé‰∫ÜÈÅ∑ÁßªÂºèÂ≠∏ÁøíÂíåÂ∞çÊñ∞ÂèÉÊï∏Ê©üÂà∂ÁöÑÊ¶ÇÊã¨„ÄÇ

##### **$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization**
2410.04717v3 by Dylan Zhang, Justin Wang, Francois Charton

Understanding and accurately following instructions is critical for large
language models (LLMs) to be effective across diverse tasks. In this work, we
rigorously examine the key factors that enable models to generalize to unseen
instructions, providing insights to guide the collection of data for
instruction-tuning. Through controlled experiments, inspired by the
Turing-complete Markov algorithm, we demonstrate that such generalization
$\textbf{only emerges}$ when training data is diversified enough across
semantic domains. Our findings also reveal that merely diversifying within
limited domains fails to ensure robust generalization. In contrast,
cross-domain data diversification, even under constrained data budgets,
significantly enhances a model's adaptability. We further extend our analysis
to real-world scenarios, including fine-tuning of
$\textit{$\textbf{specialist}$}$ and $\textit{$\textbf{generalist}$}$ models.
In both cases, we demonstrate that 1) better performance can be achieved by
increasing the diversity of an established dataset while keeping the data size
constant, and 2) when scaling up the data, diversifying the semantics of
instructions is more effective than simply increasing the quantity of similar
data. Our research provides important insights for dataset collation,
particularly when optimizing model performance by expanding training data for
both specialist and generalist scenarios. We show that careful consideration of
data diversification is key: training specialist models with data extending
beyond their core domain leads to significant performance improvements, while
generalist models benefit from diverse data mixtures that enhance their overall
instruction-following capabilities across a wide range of applications. Our
results highlight the critical role of strategic diversification and offer
clear guidelines for improving data quality.

ÊëòË¶ÅÔºö<paragraph>Â∞çÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜË™™ÔºåÁêÜËß£‰∏¶Ê∫ñÁ¢∫ÈÅµÂæ™Êåá‰ª§Â∞çÊñºÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÁôºÊèÆ‰ΩúÁî®Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂö¥Ë¨πÂú∞Êé¢Ë®é‰∫Ü‰ΩøÊ®°ÂûãËÉΩÂ§†Ê¶ÇÊã¨Âà∞Êú™Ë¶ãÈÅéÊåá‰ª§ÁöÑ‰∏ªË¶ÅÂõ†Á¥†Ôºå‰∏¶Êèê‰æõË¶ãËß£‰ª•ÊåáÂ∞éÊî∂ÈõÜË≥áÊñô‰ª•ÈÄ≤Ë°åÊåá‰ª§ÂæÆË™ø„ÄÇÈÄèÈÅéÂèóÂúñÈùàÂÆåÂÇôÈ¶¨ÂèØÂ§´ÊºîÁÆóÊ≥ïÂïüÁôºÁöÑÂèóÊéßÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé‰∫ÜÈÄôÁ®ÆÊ¶ÇÊã¨ÂÉÖÂú®Ë®ìÁ∑¥Ë≥áÊñôÂú®Ë™ûÁæ©È†òÂüü‰∏≠Ë∂≥Â§†Â§öÂÖÉÂåñÊôÇÊâçÊúÉÂá∫Áèæ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈÇÑË°®ÊòéÔºåÂÉÖÂú®ÊúâÈôêÁöÑÈ†òÂüüÂÖßÈÄ≤Ë°åÂ§öÊ®£Âåñ‰∏¶‰∏çËÉΩÁ¢∫‰øùÁ©©ÂÅ•ÁöÑÊ¶ÇÊã¨„ÄÇÁõ∏ÂèçÔºåÂç≥‰ΩøÂú®ÂèóÈôêÁöÑË≥áÊñôÈ†êÁÆó‰∏ãÔºåË∑®È†òÂüüË≥áÊñôÂ§öÊ®£Âåñ‰πüËÉΩÈ°ØËëóÂ¢ûÂº∑Ê®°ÂûãÁöÑÈÅ©ÊáâÊÄß„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â∞áÂàÜÊûêÊì¥Â±ïÂà∞ÁúüÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØÔºåÂåÖÊã¨ÂæÆË™øÂ∞àÂÆ∂ÂíåÈÄöÊâçÊ®°Âûã„ÄÇÂú®ÂÖ©Á®ÆÊÉÖÊ≥Å‰∏ãÔºåÊàëÂÄëÈÉΩË≠âÊòé‰∫Ü 1) ÈÄèÈÅéÂ¢ûÂä†Êó¢ÊúâË≥áÊñôÈõÜÁöÑÂ§öÊ®£ÊÄßÔºåÂêåÊôÇ‰øùÊåÅË≥áÊñôÂ§ßÂ∞è‰∏çËÆäÔºåÂèØ‰ª•Áç≤ÂæóÊõ¥Â•ΩÁöÑÊïàËÉΩÔºå‰ª•Âèä 2) Âú®Êì¥ÂÖÖË≥áÊñôÊôÇÔºåÂ§öÊ®£ÂåñÊåá‰ª§ÁöÑË™ûÁæ©ÊØîÂÉÖÂ¢ûÂä†È°û‰ººË≥áÊñôÁöÑÊï∏ÈáèÊõ¥ÊúâÊïà„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁÇ∫Ë≥áÊñôÈõÜÊï¥ÁêÜÊèê‰æõ‰∫ÜÈáçË¶ÅÁöÑË¶ãËß£ÔºåÁâπÂà•ÊòØÂú®ÈÄèÈÅéÊì¥ÂÖÖÂ∞àÂÆ∂ÂíåÈÄöÊâçÂ†¥ÊôØÁöÑË®ìÁ∑¥Ë≥áÊñô‰æÜÊúÄ‰Ω≥ÂåñÊ®°ÂûãÊïàËÉΩÊôÇ„ÄÇÊàëÂÄëË°®Êòé‰ªîÁ¥∞ËÄÉÈáèË≥áÊñôÂ§öÊ®£ÂåñÊòØÈóúÈçµÔºö‰ΩøÁî®Êì¥ÂÖÖÂà∞ÂÖ∂Ê†∏ÂøÉÈ†òÂüü‰ª•Â§ñÁöÑË≥áÊñô‰æÜË®ìÁ∑¥Â∞àÂÆ∂Ê®°ÂûãÔºåÊúÉÂ∏∂‰æÜÈ°ØËëóÁöÑÊïàËÉΩÊèêÂçáÔºåËÄåÈÄöÊâçÊ®°ÂûãÂâáÂèóÁõäÊñºÂ§öÊ®£ÂåñÁöÑË≥áÊñôÁµÑÂêàÔºåÈÄô‰∫õÁµÑÂêàÊúÉÂ¢ûÂº∑ÂÖ∂Âú®Âª£Ê≥õÊáâÁî®‰∏≠ÁöÑÊï¥È´îÊåá‰ª§ÈÅµÂæ™ËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÁ™ÅÂá∫‰∫ÜÁ≠ñÁï•ÊÄßÂ§öÊ®£ÂåñÁöÑÈóúÈçµ‰ΩúÁî®Ôºå‰∏¶Êèê‰æõ‰∫ÜÊîπÂñÑË≥áÊñôÂìÅË≥™ÁöÑÊòéÁ¢∫Ê∫ñÂâá„ÄÇ</paragraph>

##### **Rule-based Data Selection for Large Language Models**
2410.04715v1 by Xiaomin Li, Mingye Gao, Zhiwei Zhang, Chang Yue, Hong Hu

The quality of training data significantly impacts the performance of large
language models (LLMs). There are increasing studies using LLMs to rate and
select data based on several human-crafted metrics (rules). However, these
conventional rule-based approaches often depend too heavily on human
heuristics, lack effective metrics for assessing rules, and exhibit limited
adaptability to new tasks. In our study, we introduce an innovative rule-based
framework that utilizes the orthogonality of score vectors associated with
rules as a novel metric for rule evaluations. Our approach includes an
automated pipeline that first uses LLMs to generate a diverse set of rules,
encompassing various rating dimensions to evaluate data quality. Then it rates
a batch of data based on these rules and uses the determinantal point process
(DPP) from random matrix theory to select the most orthogonal score vectors,
thereby identifying a set of independent rules. These rules are subsequently
used to evaluate all data, selecting samples with the highest average scores
for downstream tasks such as LLM training. We verify the effectiveness of our
method through two experimental setups: 1) comparisons with ground truth
ratings and 2) benchmarking LLMs trained with the chosen data. Our
comprehensive experiments cover a range of scenarios, including general
pre-training and domain-specific fine-tuning in areas such as IMDB, Medical,
Math, and Code. The outcomes demonstrate that our DPP-based rule rating method
consistently outperforms other approaches, including rule-free rating, uniform
sampling, importance resampling, and QuRating, in terms of both rating
precision and model performance.

ÊëòË¶ÅÔºöË®ìÁ∑¥Ë≥áÊñôÁöÑÂìÅË≥™ÊúÉÈ°ØËëóÂΩ±ÈüøÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊïàËÉΩ„ÄÇÊúâÊÑà‰æÜÊÑàÂ§öÁ†îÁ©∂‰ΩøÁî® LLM ‰æÜË©ïÂàÜ‰∏¶Ê†πÊìöÂ§öÈ†Ö‰∫∫ÁÇ∫Âª∫Á´ãÁöÑÊåáÊ®ô (Ë¶èÂâá) ÈÅ∏ÊìáË≥áÊñô„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂÇ≥Áµ±ÁöÑÂü∫ÊñºË¶èÂâáÁöÑÊñπÊ≥ïÈÄöÂ∏∏ÈÅéÂ∫¶‰æùË≥¥‰∫∫È°ûÁöÑÂïüÁôºÊ≥ïÔºåÁº∫‰πèË©ï‰º∞Ë¶èÂâáÁöÑÊúâÊïàÊåáÊ®ôÔºå‰∏îÂú®ÈÅ©ÊáâÊñ∞‰ªªÂãôÊñπÈù¢Â±ïÁèæÂá∫ÊúâÈôêÁöÑÈùàÊ¥ªÊÄß„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÈÄ≤‰∏ÄÂÄãÂâµÊñ∞ÁöÑÂü∫ÊñºË¶èÂâáÁöÑÊû∂ÊßãÔºåÂÆÉÂà©Áî®ËàáË¶èÂâáÁõ∏ÈóúËÅØÁöÑÂàÜÊï∏ÂêëÈáèÁöÑÊ≠£‰∫§ÊÄß‰ΩúÁÇ∫Ë¶èÂâáË©ï‰º∞ÁöÑÊñ∞ÊåáÊ®ô„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÊã¨‰∏ÄÂÄãËá™ÂãïÂåñÊµÅÁ®ãÔºåË©≤ÊµÅÁ®ãÈ¶ñÂÖà‰ΩøÁî® LLM Áî¢Áîü‰∏ÄÁµÑÂ§öÊ®£ÂåñÁöÑË¶èÂâáÔºåÊ∂µËìãÂêÑÁ®ÆË©ïÂàÜÈù¢Âêë‰ª•Ë©ï‰º∞Ë≥áÊñôÂìÅË≥™„ÄÇÊé•ËëóÔºåÂÆÉÊ†πÊìöÈÄô‰∫õË¶èÂâáË©ïÂàÜ‰∏ÄÊâπË≥áÊñôÔºå‰∏¶‰ΩøÁî®Èö®Ê©üÁü©Èô£ÁêÜË´ñ‰∏≠ÁöÑË°åÂàóÂºèÈªûÈÅéÁ®ã (DPP) ‰æÜÈÅ∏Âá∫ÊúÄÊ≠£‰∫§ÁöÑÂàÜÊï∏ÂêëÈáèÔºåÂæûËÄåÊâæÂá∫Áç®Á´ãË¶èÂâáÁöÑÈõÜÂêà„ÄÇÈÄô‰∫õË¶èÂâáÈö®ÂæåÁî®ÊñºË©ï‰º∞ÊâÄÊúâË≥áÊñôÔºåÈáùÂ∞ç‰∏ãÊ∏∏‰ªªÂãôÔºà‰æãÂ¶Ç LLM Ë®ìÁ∑¥ÔºâÈÅ∏Âá∫Âπ≥ÂùáÂàÜÊï∏ÊúÄÈ´òÁöÑÊ®£Êú¨„ÄÇÊàëÂÄëÈÄèÈÅéÂÖ©ÂÄãÂØ¶È©óË®≠ÂÆöÈ©óË≠âÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºö1) ËàáÁúüÂØ¶Ë©ïÂàÜÈÄ≤Ë°åÊØîËºÉÔºå‰ª•Âèä 2) Â∞ç‰ΩøÁî®ÊâÄÈÅ∏Ë≥áÊñôË®ìÁ∑¥ÁöÑ LLM ÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇÊàëÂÄëÂÖ®Èù¢ÁöÑÂØ¶È©óÊ∂µËìã‰∏ÄÁ≥ªÂàóÊÉÖÂ¢ÉÔºåÂåÖÊã¨Âú® IMDB„ÄÅÈÜ´Â≠∏„ÄÅÊï∏Â≠∏ÂíåÁ®ãÂºèÁ¢ºÁ≠âÈ†òÂüüÁöÑ‰∏ÄËà¨È†êË®ìÁ∑¥ÂíåÁâπÂÆöÈ†òÂüüÁöÑÂæÆË™ø„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÂü∫Êñº DPP ÁöÑË¶èÂâáË©ïÂàÜÊñπÊ≥ïÂú®Ë©ïÂàÜÁ≤æÊ∫ñÂ∫¶ÂíåÊ®°ÂûãÊïàËÉΩÊñπÈù¢ÂßãÁµÇÂÑ™ÊñºÂÖ∂‰ªñÊñπÊ≥ïÔºåÂåÖÊã¨ÁÑ°Ë¶èÂâáË©ïÂàÜ„ÄÅÂùáÂãªÊäΩÊ®£„ÄÅÈáçË¶ÅÊÄßÂÜçÊäΩÊ®£Âíå QuRating„ÄÇ

##### **Knowledge Graph Based Agent for Complex, Knowledge-Intensive QA in Medicine**
2410.04660v1 by Xiaorui Su, Yibo Wang, Shanghua Gao, Xiaolong Liu, Valentina Giunchiglia, Djork-Arn√© Clevert, Marinka Zitnik

Biomedical knowledge is uniquely complex and structured, requiring distinct
reasoning strategies compared to other scientific disciplines like physics or
chemistry. Biomedical scientists do not rely on a single approach to reasoning;
instead, they use various strategies, including rule-based, prototype-based,
and case-based reasoning. This diversity calls for flexible approaches that
accommodate multiple reasoning strategies while leveraging in-domain knowledge.
We introduce KGARevion, a knowledge graph (KG) based agent designed to address
the complexity of knowledge-intensive medical queries. Upon receiving a query,
KGARevion generates relevant triplets by using the knowledge base of the LLM.
These triplets are then verified against a grounded KG to filter out erroneous
information and ensure that only accurate, relevant data contribute to the
final answer. Unlike RAG-based models, this multi-step process ensures
robustness in reasoning while adapting to different models of medical
reasoning. Evaluations on four gold-standard medical QA datasets show that
KGARevion improves accuracy by over 5.2%, outperforming 15 models in handling
complex medical questions. To test its capabilities, we curated three new
medical QA datasets with varying levels of semantic complexity, where KGARevion
achieved a 10.4% improvement in accuracy.

ÊëòË¶ÅÔºöÁîüÁâ©ÂåªÂ≠¶Áü•Ë≠òÁç®ÁâπÂú∞Ë§áÈõú‰∏îÁµêÊßãÂåñÔºåÈúÄË¶ÅËàáÂÖ∂‰ªñÁßëÂ≠∏È†òÂüüÔºàÂ¶ÇÁâ©ÁêÜÊàñÂåñÂ≠∏Ôºâ‰∏çÂêåÁöÑÊé®ÁêÜÁ≠ñÁï•„ÄÇÁîüÁâ©ÈÜ´Â≠∏ÁßëÂ≠∏ÂÆ∂‰∏ç‰æùË≥¥ÂñÆ‰∏ÄÁöÑÊé®ÁêÜÊñπÊ≥ïÔºõÁõ∏ÂèçÔºå‰ªñÂÄë‰ΩøÁî®ÂêÑÁ®ÆÁ≠ñÁï•ÔºåÂåÖÊã¨Âü∫ÊñºË¶èÂâá„ÄÅÂü∫ÊñºÂéüÂûãÂíåÂü∫ÊñºÊ°à‰æãÁöÑÊé®ÁêÜ„ÄÇÈÄôÁ®ÆÂ§öÊ®£ÊÄßÈúÄË¶ÅÈùàÊ¥ªÁöÑÊñπÊ≥ïÔºåÂêåÊôÇÂà©Áî®È†òÂüüÁü•Ë≠ò‰æÜÈÅ©ÊáâÂ§öÁ®ÆÊé®ÁêÜÁ≠ñÁï•„ÄÇÊàëÂÄë‰ªãÁ¥π‰∫Ü KGARevionÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫ÊñºÁü•Ë≠òÂúñË≠ú (KG) ÁöÑ‰ª£ÁêÜÔºåÊó®Âú®Ëß£Ê±∫Áü•Ë≠òÂØÜÈõÜÂûãÈÜ´ÁôÇÊü•Ë©¢ÁöÑË§áÈõúÊÄß„ÄÇÂú®Êî∂Âà∞Êü•Ë©¢ÂæåÔºåKGARevion ‰ΩøÁî® LLM ÁöÑÁü•Ë≠òÂ∫´ÁîüÊàêÁõ∏ÈóúÁöÑ‰∏âÂÖÉÁµÑ„ÄÇÁÑ∂ÂæåÂ∞áÈÄô‰∫õ‰∏âÂÖÉÁµÑËàáÂü∫Á§é KG ÈÄ≤Ë°åÈ©óË≠âÔºå‰ª•ÈÅéÊøæÊéâÈåØË™§‰ø°ÊÅØ‰∏¶Á¢∫‰øùÂè™ÊúâÊ∫ñÁ¢∫„ÄÅÁõ∏ÈóúÁöÑÊï∏ÊìöÊúâÂä©ÊñºÊúÄÁµÇÁ≠îÊ°à„ÄÇËàáÂü∫Êñº RAG ÁöÑÊ®°Âûã‰∏çÂêåÔºåÈÄôÁ®ÆÂ§öÊ≠•È©üÈÅéÁ®ãÁ¢∫‰øù‰∫ÜÊé®ÁêÜÁöÑÁ©©ÂÅ•ÊÄßÔºåÂêåÊôÇÈÅ©Êáâ‰∏çÂêåÁöÑÈÜ´ÁôÇÊé®ÁêÜÊ®°Âûã„ÄÇÂ∞çÂõõÂÄãÈªÉÈáëÊ®ôÊ∫ñÈÜ´ÁôÇ QA Êï∏ÊìöÈõÜÁöÑË©ï‰º∞Ë°®ÊòéÔºåKGARevion Â∞áÊ∫ñÁ¢∫ÁéáÊèêÈ´ò‰∫Ü 5.2%ÔºåÂú®ËôïÁêÜË§áÈõúÁöÑÈÜ´ÁôÇÂïèÈ°åÊñπÈù¢ÂÑ™Êñº 15 ÂÄãÊ®°Âûã„ÄÇÁÇ∫‰∫ÜÊ∏¨Ë©¶ÂÖ∂ËÉΩÂäõÔºåÊàëÂÄëÁ≠ñÂäÉ‰∫Ü‰∏âÂÄãÊñ∞ÁöÑÈÜ´ÁôÇ QA Êï∏ÊìöÈõÜÔºåÂÖ∑Êúâ‰∏çÂêåÁöÑË™ûÁæ©Ë§áÈõúÊÄßÔºåÂÖ∂‰∏≠ KGARevion Âú®Ê∫ñÁ¢∫Áéá‰∏äÊèêÈ´ò‰∫Ü 10.4%„ÄÇ

##### **Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task**
2410.11860v1 by Chengyuan Xu, Kuo-Chin Lien, Tobias H√∂llerer

When designing an AI-assisted decision-making system, there is often a
tradeoff between precision and recall in the AI's recommendations. We argue
that careful exploitation of this tradeoff can harness the complementary
strengths in the human-AI collaboration to significantly improve team
performance. We investigate a real-world video anonymization task for which
recall is paramount and more costly to improve. We analyze the performance of
78 professional annotators working with a) no AI assistance, b) a
high-precision "restrained" AI, and c) a high-recall "zealous" AI in over 3,466
person-hours of annotation work. In comparison, the zealous AI helps human
teammates achieve significantly shorter task completion time and higher recall.
In a follow-up study, we remove AI assistance for everyone and find negative
training effects on annotators trained with the restrained AI. These findings
and our analysis point to important implications for the design of AI
assistance in recall-demanding scenarios.

ÊëòË¶ÅÔºöÂú®Ë®≠Ë®à AI ËºîÂä©Ê±∫Á≠ñÁ≥ªÁµ±ÊôÇÔºåAI Âª∫Ë≠∞‰∏≠ÁöÑÁ≤æÊ∫ñÂ∫¶ËàáÂè¨ÂõûÁéá‰πãÈñìÈÄöÂ∏∏Â≠òÂú®ÂèñÊç®„ÄÇÊàëÂÄë‰∏ªÂºµÔºåÂ∞èÂøÉÂà©Áî®ÈÄôÁ®ÆÂèñÊç®ÂèØ‰ª•Âà©Áî®‰∫∫Ê©üÂçî‰Ωú‰∏≠ÁöÑ‰∫íË£úÂÑ™Âã¢ÔºåÈ°ØËëóÊèêÂçáÂúòÈöäÁ∏æÊïà„ÄÇÊàëÂÄëÁ†îÁ©∂‰∫Ü‰∏ÄÈ†ÖÁúüÂØ¶‰∏ñÁïåÁöÑÂΩ±ÁâáÂåøÂêçÂåñ‰ªªÂãôÔºåÂè¨ÂõûÁéáËá≥ÈóúÈáçË¶Å‰∏îÊõ¥Èõ£‰ª•ÊèêÂçá„ÄÇÊàëÂÄëÂàÜÊûê‰∫Ü 78 ‰ΩçÂ∞àÊ•≠Ë®ªËß£Âì°ÁöÑË°®ÁèæÔºå‰ªñÂÄëÂàÜÂà•‰ΩøÁî® a) Ê≤íÊúâ AI ÂçîÂä©„ÄÅb) È´òÁ≤æÊ∫ñÂ∫¶ÁöÑ„ÄåÁ¥ÑÊùü„ÄçAIÔºå‰ª•Âèä c) È´òÂè¨ÂõûÁéáÁöÑ„ÄåÁÜ±ÂøÉ„ÄçAIÔºåÈÄ≤Ë°åË∂ÖÈÅé 3,466 ‰∫∫Â∞èÊôÇÁöÑË®ªËß£Â∑•‰Ωú„ÄÇÁõ∏ËºÉ‰πã‰∏ãÔºåÁÜ±ÂøÉ AI ËÉΩÂπ´Âä©‰∫∫È°ûÈöäÂèãÈ°ØËëóÁ∏ÆÁü≠‰ªªÂãôÂÆåÊàêÊôÇÈñìÔºå‰∏¶ÊèêÈ´òÂè¨ÂõûÁéá„ÄÇÂú®ÂæåÁ∫åÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÁßªÈô§ÊâÄÊúâ‰∫∫ÁöÑ AI ÂçîÂä©ÔºåÁôºÁèæÂ∞ç‰ΩøÁî®Á¥ÑÊùü AI ÈÄ≤Ë°åË®ìÁ∑¥ÁöÑË®ªËß£Âì°Áî¢ÁîüË≤†Èù¢ÁöÑË®ìÁ∑¥ÊïàÊûú„ÄÇÈÄô‰∫õÁôºÁèæÂíåÊàëÂÄëÁöÑÂàÜÊûêÊåáÂá∫ÔºåÂú®Ë¶ÅÊ±ÇÂè¨ÂõûÁéáÁöÑÊÉÖÂ¢É‰∏≠Ë®≠Ë®à AI ÂçîÂä©ÂÖ∑ÊúâÈáçË¶ÅÁöÑÊÑèÁæ©„ÄÇ

##### **Multi-Tiered Self-Contrastive Learning for Medical Microwave Radiometry (MWR) Breast Cancer Detection**
2410.04636v1 by Christoforos Galazis, Huiyi Wu, Igor Goryanin

The pursuit of enhanced breast cancer detection and monitoring techniques is
a paramount healthcare objective, driving the need for innovative imaging
technologies and diagnostic approaches. This study introduces a novel
multi-tiered self-contrastive model tailored for the application of microwave
radiometry (MWR) breast cancer detection. Our approach encompasses three
distinct models: Local-MWR (L-MWR), Regional-MWR (R-MWR), and Global-MWR
(G-MWR), each engineered to analyze varying sub-regional comparisons within the
breasts. These models are cohesively integrated through the Joint-MWR (J-MWR)
network, which leverages the self-contrastive data generated at each analytical
level to enhance detection capabilities. Employing a dataset comprising 4,932
cases of female patients, our research showcases the effectiveness of our
proposed models. Notably, the J-MWR model distinguishes itself by achieving a
Matthews correlation coefficient of 0.74 $\pm$ 0.018, surpassing existing MWR
neural networks and contrastive methods. These results highlight the
significant potential of self-contrastive learning techniques in improving both
the diagnostic accuracy and generalizability of MWR-based breast cancer
detection processes. Such advancements hold considerable promise for further
investigative and clinical endeavors. The source code is available at:
https://github.com/cgalaz01/self_contrastive_mwr

ÊëòË¶ÅÔºöËøΩÊ±ÇÂ¢ûÂº∑‰π≥ÁôåÊ™¢Ê∏¨ÂíåÁõ£Ê∏¨ÊäÄË°ìÊòØ‰∏ÄÈ†ÖËá≥ÈóúÈáçË¶ÅÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÁõÆÊ®ôÔºåÊé®Âãï‰∫ÜÂâµÊñ∞ÂΩ±ÂÉèÊäÄË°ìÂíåË®∫Êñ∑ÊñπÊ≥ïÁöÑÈúÄÊ±Ç„ÄÇÊú¨Á†îÁ©∂‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§öÂ±§Ëá™Â∞çÊØîÊ®°ÂûãÔºåÂ∞àÈñÄÁî®ÊñºÂæÆÊ≥¢ËºªÂ∞ÑÊ∏¨Èáè (MWR) ‰π≥ÁôåÊ™¢Ê∏¨„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÂê´‰∏âÂÄã‰∏çÂêåÁöÑÊ®°ÂûãÔºöÂ±ÄÈÉ® MWR (L-MWR)„ÄÅÂçÄÂüü MWR (R-MWR) ÂíåÂÖ®Â±Ä MWR (G-MWR)ÔºåÊØèÂÄãÊ®°ÂûãÈÉΩË®≠Ë®àÁî®ÊñºÂàÜÊûê‰π≥ÊàøÂÖß‰∏çÂêåÁöÑÊ¨°ÂçÄÂüüÊØîËºÉ„ÄÇÈÄô‰∫õÊ®°ÂûãÈÄöÈÅéËÅØÂêà MWR (J-MWR) Á∂≤Ë∑ØÁ∑äÂØÜÊï¥ÂêàÔºåÂà©Áî®Âú®ÊØèÂÄãÂàÜÊûêÂ±§Á¥öÁî¢ÁîüÁöÑËá™Â∞çÊØîË≥áÊñô‰æÜÂ¢ûÂº∑Ê™¢Ê∏¨ËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êé°Áî®ÂåÖÂê´ 4,932 ‰æãÂ•≥ÊÄßÊÇ£ËÄÖÁöÑË≥áÊñôÈõÜÔºåÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÁöÑÊúâÊïàÊÄß„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåJ-MWR Ê®°Âûã‰ª•ÈÅîÂà∞ 0.74 ¬± 0.018 ÁöÑÈ¶¨‰øÆÊñØÁõ∏Èóú‰øÇÊï∏ËÄåÂçÄÂà•ÊñºÂÖ∂‰ªñÊ®°ÂûãÔºåË∂ÖË∂ä‰∫ÜÁèæÊúâÁöÑ MWR Á•ûÁ∂ìÁ∂≤Ë∑ØÂíåÂ∞çÊØîÊñπÊ≥ï„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫ÜËá™Â∞çÊØîÂ≠∏ÁøíÊäÄË°ìÂú®ÊîπÂñÑÂü∫Êñº MWR ÁöÑ‰π≥ÁôåÊ™¢Ê∏¨Á®ãÂ∫èÁöÑË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÊ¶ÇÊã¨ÊÄßÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõ„ÄÇÈÄô‰∫õÈÄ≤Â±ïÁÇ∫ÈÄ≤‰∏ÄÊ≠•ÁöÑË™øÊü•ÂíåËá®Â∫äÂ∑•‰ΩúÊèê‰æõ‰∫ÜÁõ∏Áï∂Â§ßÁöÑÂ∏åÊúõ„ÄÇÂéüÂßãÁ¢ºÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºöhttps://github.com/cgalaz01/self_contrastive_mwr

##### **Semi-Markovian Planning to Coordinate Aerial and Maritime Medical Evacuation Platforms**
2410.04523v1 by Mahdi Al-Husseini, Kyle H. Wray, Mykel J. Kochenderfer

The transfer of patients between two aircraft using an underway watercraft
increases medical evacuation reach and flexibility in maritime environments.
The selection of any one of multiple underway watercraft for patient exchange
is complicated by participating aircraft utilization history and a
participating watercraft position and velocity. The selection problem is
modeled as a semi-Markov decision process with an action space including both
fixed land and moving watercraft exchange points. Monte Carlo tree search with
root parallelization is used to select optimal exchange points and determine
aircraft dispatch times. Model parameters are varied in simulation to identify
representative scenarios where watercraft exchange points reduce incident
response times. We find that an optimal policy with watercraft exchange points
outperforms an optimal policy without watercraft exchange points and a greedy
policy by 35% and 40%, respectively. In partnership with the United States
Army, we deploy for the first time the watercraft exchange point by executing a
mock patient transfer with a manikin between two HH-60M medical evacuation
helicopters and an underway Army Logistic Support Vessel south of the Hawaiian
island of Oahu. Both helicopters were dispatched in accordance with our
optimized decision strategy.

ÊëòË¶ÅÔºö‰ΩøÁî®Ëà™Ë°å‰∏≠ÁöÑÊ∞¥‰∏ä‰∫§ÈÄöÂ∑•ÂÖ∑Âú®‰∏§Êû∂È£ûÊú∫‰πãÈó¥ËΩ¨ËøêÊÇ£ËÄÖÔºåÂèØÂ¢ûÂä†Êµ∑‰∏äÁéØÂ¢É‰∏≠ÁöÑÂåªÁñóÂêéÈÄÅËåÉÂõ¥ÂíåÁÅµÊ¥ªÊÄß„ÄÇ
Áî±‰∫éÂèÇ‰∏éÈ£ûÊú∫ÁöÑ‰ΩøÁî®ÂéÜÂè≤‰ª•ÂèäÂèÇ‰∏éÊ∞¥‰∏ä‰∫§ÈÄöÂ∑•ÂÖ∑ÁöÑ‰ΩçÁΩÆÂíåÈÄüÂ∫¶ÔºåÈÄâÊã©Â§ö‰∏™Ëà™Ë°å‰∏≠ÁöÑÊ∞¥‰∏ä‰∫§ÈÄöÂ∑•ÂÖ∑‰∏≠ÁöÑ‰ªª‰Ωï‰∏Ä‰∏™ËøõË°åÊÇ£ËÄÖ‰∫§Êç¢ÂèòÂæóÂ§çÊùÇ„ÄÇÈÄâÊã©ÈóÆÈ¢òË¢´Âª∫Ê®°‰∏∫ÂçäÈ©¨Â∞îÂèØÂ§´ÂÜ≥Á≠ñËøáÁ®ãÔºåÂÖ∂Âä®‰ΩúÁ©∫Èó¥ÂåÖÊã¨Âõ∫ÂÆöÈôÜÂú∞ÂíåÁßªÂä®Ê∞¥‰∏ä‰∫§ÈÄöÂ∑•ÂÖ∑‰∫§Êç¢ÁÇπ„ÄÇ‰ΩøÁî®Ê†πÂπ∂Ë°åÂåñÁöÑËíôÁâπÂç°ÁΩóÊ†ëÊêúÁ¥¢Êù•ÈÄâÊã©ÊúÄ‰Ω≥‰∫§Êç¢ÁÇπÂπ∂Á°ÆÂÆöÈ£ûÊú∫Ë∞ÉÂ∫¶Êó∂Èó¥„ÄÇÂú®‰ªøÁúü‰∏≠ÊîπÂèòÊ®°ÂûãÂèÇÊï∞Ôºå‰ª•ËØÜÂà´Ê∞¥‰∏ä‰∫§ÈÄöÂ∑•ÂÖ∑‰∫§Êç¢ÁÇπÂáèÂ∞ë‰∫ã‰ª∂ÂìçÂ∫îÊó∂Èó¥ÁöÑ‰ª£Ë°®ÊÄßÂú∫ÊôØ„ÄÇÊàë‰ª¨ÂèëÁé∞ÔºåÂÖ∑ÊúâÊ∞¥‰∏ä‰∫§ÈÄöÂ∑•ÂÖ∑‰∫§Êç¢ÁÇπÁöÑÊúÄ‰ºòÁ≠ñÁï•ÊØîÊ≤°ÊúâÊ∞¥‰∏ä‰∫§ÈÄöÂ∑•ÂÖ∑‰∫§Êç¢ÁÇπÁöÑÊúÄ‰ºòÁ≠ñÁï•ÂíåË¥™Â©™Á≠ñÁï•ÂàÜÂà´È´òÂá∫ 35% Âíå 40%„ÄÇ‰∏éÁæéÂõΩÈôÜÂÜõÂêà‰ΩúÔºåÊàë‰ª¨È¶ñÊ¨°ÈÄöËøáÂú®‰∏§Êû∂ HH-60M ÂåªÁñóÂêéÈÄÅÁõ¥ÂçáÊú∫ÂíåÂ§èÂ®ÅÂ§∑Ê¨ßËÉ°Â≤õÂçóÈÉ®Ëà™Ë°å‰∏≠ÁöÑÈôÜÂÜõÂêéÂã§ÊîØÊè¥Ëàπ‰πãÈó¥ÊâßË°åÊ®°ÊãüÊÇ£ËÄÖËΩ¨ËøêÔºåÈÉ®ÁΩ≤‰∫ÜÊ∞¥‰∏ä‰∫§ÈÄöÂ∑•ÂÖ∑‰∫§Êç¢ÁÇπ„ÄÇ‰∏§Êû∂Áõ¥ÂçáÊú∫ÂùáÊåâÁÖßÊàë‰ª¨‰ºòÂåñÁöÑÂÜ≥Á≠ñÁ≠ñÁï•ËøõË°åË∞ÉÂ∫¶„ÄÇ

##### **Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Support**
2410.10853v1 by Abdul Muqtadir, Hafiz Syed Muhammad Bilal, Ayesha Yousaf, Hafiz Farooq Ahmed, Jamil Hussain

This research work delves into the manifestation of hallucination within
Large Language Models (LLMs) and its consequential impacts on applications
within the domain of mental health. The primary objective is to discern
effective strategies for curtailing hallucinatory occurrences, thereby
bolstering the dependability and security of LLMs in facilitating mental health
interventions such as therapy, counseling, and the dissemination of pertinent
information. Through rigorous investigation and analysis, this study seeks to
elucidate the underlying mechanisms precipitating hallucinations in LLMs and
subsequently propose targeted interventions to alleviate their occurrence. By
addressing this critical issue, the research endeavors to foster a more robust
framework for the utilization of LLMs within mental health contexts, ensuring
their efficacy and reliability in aiding therapeutic processes and delivering
accurate information to individuals seeking mental health support.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÂπªË¶∫ÁöÑË°®ÁèæÔºåÂèäÂÖ∂Â∞çÂøÉÁêÜÂÅ•Â∫∑È†òÂüüÊáâÁî®Áî¢ÁîüÁöÑÂæåÁ∫åÂΩ±Èüø„ÄÇ‰∏ªË¶ÅÁõÆÊ®ôÊòØËæ®Âà•ÈÅèÂà∂ÂπªË¶∫ÁôºÁîüÁöÑÊúâÊïàÁ≠ñÁï•ÔºåÂæûËÄåÂä†Âº∑ LLM Âú®‰øÉÈÄ≤ÂøÉÁêÜÂÅ•Â∫∑Âπ≤È†êÊé™ÊñΩÔºà‰æãÂ¶ÇÊ≤ªÁôÇ„ÄÅË´ÆË©¢ÂíåÂÇ≥Êí≠Áõ∏ÈóúË≥áË®äÔºâÊñπÈù¢ÁöÑÂèØÈù†ÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇÈÄèÈÅéÂö¥Ë¨πÁöÑË™øÊü•ÂíåÂàÜÊûêÔºåÊú¨Á†îÁ©∂Ë©¶ÂúñÈó°ÊòéÂ∞éËá¥ LLM Áî¢ÁîüÂπªË¶∫ÁöÑÊΩõÂú®Ê©üÂà∂Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫ÊúâÈáùÂ∞çÊÄßÁöÑÂπ≤È†êÊé™ÊñΩ‰æÜÊ∏õËºïÂÖ∂ÁôºÁîü„ÄÇÈÄèÈÅéËß£Ê±∫ÈÄôÂÄãÈóúÈçµÂïèÈ°åÔºåÊú¨Á†îÁ©∂Ëá¥ÂäõÊñºÂª∫Á´ã‰∏ÄÂÄãÊõ¥Á©©ÂÅ•ÁöÑÊû∂ÊßãÔºå‰ª•‰æøÂú®ÂøÉÁêÜÂÅ•Â∫∑ÊÉÖÂ¢É‰∏≠‰ΩøÁî® LLMÔºåÁ¢∫‰øùÂÖ∂Âú®ÂçîÂä©Ê≤ªÁôÇÈÅéÁ®ãÂíåÂêëÂ∞ãÊ±ÇÂøÉÁêÜÂÅ•Â∫∑ÊîØÊåÅÁöÑÂÄã‰∫∫Êèê‰æõÊ∫ñÁ¢∫Ë≥áË®äÊñπÈù¢ÁöÑÊïàËÉΩÂíåÂèØÈù†ÊÄß„ÄÇ


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-18**|**TransBox: EL++-closed Ontology Embedding**|Hui Yang et.al.|[2410.14571v1](http://arxiv.org/abs/2410.14571v1)|null|
|**2024-10-18**|**Paths-over-Graph: Knowledge Graph Enpowered Large Language Model Reasoning**|Xingyu Tan et.al.|[2410.14211v1](http://arxiv.org/abs/2410.14211v1)|null|
|**2024-10-18**|**Supervised Chain of Thought**|Xiang Zhang et.al.|[2410.14198v1](http://arxiv.org/abs/2410.14198v1)|null|
|**2024-10-17**|**Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs**|Simone Conia et.al.|[2410.14057v1](http://arxiv.org/abs/2410.14057v1)|null|
|**2024-10-17**|**RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs**|Jiatan Huang et.al.|[2410.13987v1](http://arxiv.org/abs/2410.13987v1)|null|
|**2024-10-17**|**The Mystery of the Pathological Path-star Task for Language Models**|Arvid Frydenlund et.al.|[2410.13779v1](http://arxiv.org/abs/2410.13779v1)|null|
|**2024-10-17**|**Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval**|Yu Xia et.al.|[2410.13765v1](http://arxiv.org/abs/2410.13765v1)|null|
|**2024-10-17**|**LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models**|David Hoffmann et.al.|[2410.13299v1](http://arxiv.org/abs/2410.13299v1)|null|
|**2024-10-17**|**Trust but Verify: Programmatic VLM Evaluation in the Wild**|Viraj Prabhu et.al.|[2410.13121v1](http://arxiv.org/abs/2410.13121v1)|null|
|**2024-10-16**|**Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models**|Linhao Luo et.al.|[2410.13080v1](http://arxiv.org/abs/2410.13080v1)|[link](https://github.com/RManLuo/graph-constrained-reasoning)|
|**2024-10-16**|**Supply Chain Network Extraction and Entity Classification Leveraging Large Language Models**|Tong Liu et.al.|[2410.13051v1](http://arxiv.org/abs/2410.13051v1)|null|
|**2024-10-16**|**Learning Representations for Reasoning: Generalizing Across Diverse Structures**|Zhaocheng Zhu et.al.|[2410.13018v1](http://arxiv.org/abs/2410.13018v1)|null|
|**2024-10-16**|**Large Language Models as a Tool for Mining Object Knowledge**|Hannah YoungEun An et.al.|[2410.12959v1](http://arxiv.org/abs/2410.12959v1)|null|
|**2024-10-16**|**FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**|Zhenheng Tang et.al.|[2410.12707v1](http://arxiv.org/abs/2410.12707v1)|null|
|**2024-10-16**|**The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph**|Minghao Wu et.al.|[2410.12458v1](http://arxiv.org/abs/2410.12458v1)|null|
|**2024-10-16**|**PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking**|Markus J. Buehler et.al.|[2410.12375v1](http://arxiv.org/abs/2410.12375v1)|[link](https://github.com/lamm-mit/PRefLexOR)|
|**2024-10-16**|**Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs**|Lei Sun et.al.|[2410.12298v2](http://arxiv.org/abs/2410.12298v2)|null|
|**2024-10-16**|**LLM-based Cognitive Models of Students with Misconceptions**|Shashank Sonkar et.al.|[2410.12294v2](http://arxiv.org/abs/2410.12294v2)|null|
|**2024-10-16**|**Comprehending Knowledge Graphs with Large Language Models for Recommender Systems**|Ziqiang Cui et.al.|[2410.12229v1](http://arxiv.org/abs/2410.12229v1)|null|
|**2024-10-16**|**Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations**|Luyi Ma et.al.|[2410.12228v1](http://arxiv.org/abs/2410.12228v1)|null|
|**2024-10-16**|**Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning**|Huiwen Wu et.al.|[2410.12130v1](http://arxiv.org/abs/2410.12130v1)|null|
|**2024-10-15**|**Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning**|Guangxin Su et.al.|[2410.12096v1](http://arxiv.org/abs/2410.12096v1)|null|
|**2024-10-15**|**A Survey on Deep Tabular Learning**|Shriyank Somvanshi et.al.|[2410.12034v1](http://arxiv.org/abs/2410.12034v1)|null|
|**2024-10-15**|**Causal Reasoning in Large Language Models: A Knowledge Graph Approach**|Yejin Kim et.al.|[2410.11588v1](http://arxiv.org/abs/2410.11588v1)|null|
|**2024-10-15**|**Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development**|Tengfei Ma et.al.|[2410.11550v1](http://arxiv.org/abs/2410.11550v1)|null|
|**2024-10-15**|**AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data**|Xinjie Zhao et.al.|[2410.11531v1](http://arxiv.org/abs/2410.11531v1)|null|
|**2024-10-15**|**Do LLMs Have the Generalization Ability in Conducting Causal Inference?**|Chen Wang et.al.|[2410.11385v1](http://arxiv.org/abs/2410.11385v1)|[link](https://github.com/prayingsociety/ci_bench)|
|**2024-10-15**|**Enhance Graph Alignment for Large Language Models**|Haitong Luo et.al.|[2410.11370v1](http://arxiv.org/abs/2410.11370v1)|null|
|**2024-10-15**|**Unleashing the Power of LLMs as Multi-Modal Encoders for Text and Graph-Structured Data**|Jiacheng Lin et.al.|[2410.11235v1](http://arxiv.org/abs/2410.11235v1)|null|
|**2024-10-15**|**Tree of Attributes Prompt Learning for Vision-Language Models**|Tong Ding et.al.|[2410.11201v1](http://arxiv.org/abs/2410.11201v1)|null|
|**2024-10-14**|**Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs**|Haozhen Zhang et.al.|[2410.11001v1](http://arxiv.org/abs/2410.11001v1)|[link](https://github.com/ulab-uiuc/gor)|
|**2024-10-14**|**NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models**|Yanbiao Ji et.al.|[2410.10743v1](http://arxiv.org/abs/2410.10743v1)|null|
|**2024-10-14**|**GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs**|Yun Zhu et.al.|[2410.10329v2](http://arxiv.org/abs/2410.10329v2)|[link](https://github.com/zhuyun97/graphclip)|
|**2024-10-14**|**Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning**|Hongyi Yuan et.al.|[2410.10144v1](http://arxiv.org/abs/2410.10144v1)|null|
|**2024-10-14**|**Language Model Preference Evaluation with Multiple Weak Evaluators**|Zhengyu Hu et.al.|[2410.12869v1](http://arxiv.org/abs/2410.12869v1)|null|
|**2024-10-14**|**Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?**|Yifan Feng et.al.|[2410.10083v2](http://arxiv.org/abs/2410.10083v2)|[link](https://github.com/imoonlab/llm4hypergraph)|
|**2024-10-13**|**Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation**|Jiarui Ji et.al.|[2410.09824v1](http://arxiv.org/abs/2410.09824v1)|null|
|**2024-10-13**|**A Mixed-Language Multi-Document News Summarization Dataset and a Graphs-Based Extract-Generate Model**|Shengxiang Gao et.al.|[2410.09773v1](http://arxiv.org/abs/2410.09773v1)|null|
|**2024-10-13**|**Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG**|Xinxi Chen et.al.|[2410.09699v1](http://arxiv.org/abs/2410.09699v1)|null|
|**2024-10-12**|**LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning**|Jiachun Li et.al.|[2410.09541v1](http://arxiv.org/abs/2410.09541v1)|[link](https://github.com/bugmakerzzz/linked_code)|
|**2024-10-12**|**Text Classification using Graph Convolutional Networks: A Comprehensive Survey**|Syed Mustafa Haider Rizvi et.al.|[2410.09399v1](http://arxiv.org/abs/2410.09399v1)|null|
|**2024-10-12**|**Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation**|Jinyoung Park et.al.|[2410.09350v1](http://arxiv.org/abs/2410.09350v1)|null|
|**2024-10-11**|**Natural Language Counterfactual Explanations for Graphs Using Large Language Models**|Flavio Giorgi et.al.|[2410.09295v1](http://arxiv.org/abs/2410.09295v1)|[link](https://github.com/flaat/llm-graph-cf)|
|**2024-10-11**|**ReasonPlanner: Enhancing Autonomous Planning in Dynamic Environments with Temporal Knowledge Graphs and LLMs**|Minh Pham Dinh et.al.|[2410.09252v1](http://arxiv.org/abs/2410.09252v1)|null|
|**2024-10-11**|**Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective**|Bo Ni et.al.|[2410.08985v1](http://arxiv.org/abs/2410.08985v1)|null|
|**2024-10-11**|**When Graph meets Multimodal: Benchmarking on Multimodal Attributed Graphs Learning**|Hao Yan et.al.|[2410.09132v1](http://arxiv.org/abs/2410.09132v1)|[link](https://github.com/sktsherlock/atg)|
|**2024-10-11**|**GIVE: Structured Reasoning with Knowledge Graph Inspired Veracity Extrapolation**|Jiashu He et.al.|[2410.08475v1](http://arxiv.org/abs/2410.08475v1)|null|
|**2024-10-10**|**Privately Learning from Graphs with Applications in Fine-tuning Large Language Models**|Haoteng Yin et.al.|[2410.08299v1](http://arxiv.org/abs/2410.08299v1)|[link](https://github.com/graph-com/pvgalm)|
|**2024-10-10**|**Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study over Open-ended Question Answering**|Yuan Sui et.al.|[2410.08085v1](http://arxiv.org/abs/2410.08085v1)|null|
|**2024-10-10**|**Disease Entity Recognition and Normalization is Improved with Large Language Model Derived Synthetic Normalized Mentions**|Kuleen Sasse et.al.|[2410.07951v1](http://arxiv.org/abs/2410.07951v1)|null|
|**2024-10-10**|**Benchmarking Agentic Workflow Generation**|Shuofei Qiao et.al.|[2410.07869v1](http://arxiv.org/abs/2410.07869v1)|[link](https://github.com/zjunlp/worfbench)|
|**2024-10-10**|**KRAG Framework for Enhancing LLMs in the Legal Domain**|Nguyen Ha Thanh et.al.|[2410.07551v1](http://arxiv.org/abs/2410.07551v1)|null|
|**2024-10-10**|**MKGL: Mastery of a Three-Word Language**|Lingbing Guo et.al.|[2410.07526v1](http://arxiv.org/abs/2410.07526v1)|null|
|**2024-10-09**|**InstructG2I: Synthesizing Images from Multimodal Attributed Graphs**|Bowen Jin et.al.|[2410.07157v1](http://arxiv.org/abs/2410.07157v1)|[link](https://github.com/PeterGriffinJin/InstructG2I)|
|**2024-10-09**|**CSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free Word Ordered and Morphologically Rich Low Resource Languages**|Pretam Ray et.al.|[2410.06944v1](http://arxiv.org/abs/2410.06944v1)|null|
|**2024-10-09**|**Tree of Problems: Improving structured problem solving with compositionality**|Armel Zebaze et.al.|[2410.06634v1](http://arxiv.org/abs/2410.06634v1)|null|
|**2024-10-09**|**Multi-Task Program Error Repair and Explanatory Diagnosis**|Zhenyu Xu et.al.|[2410.07271v1](http://arxiv.org/abs/2410.07271v1)|null|
|**2024-10-08**|**Counterfactual Causal Inference in Natural Language with Large Language Models**|Ga√´l Gendron et.al.|[2410.06392v1](http://arxiv.org/abs/2410.06392v1)|[link](https://github.com/strong-ai-lab/counterfactual-llm-inference)|
|**2024-10-08**|**Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA**|Wenyu Huang et.al.|[2410.06121v1](http://arxiv.org/abs/2410.06121v1)|null|
|**2024-10-08**|**LLM-based SPARQL Query Generation from Natural Language over Federated Knowledge Graphs**|Vincent Emonet et.al.|[2410.06062v2](http://arxiv.org/abs/2410.06062v2)|null|
|**2024-10-08**|**Jet Expansions of Residual Computation**|Yihong Chen et.al.|[2410.06024v1](http://arxiv.org/abs/2410.06024v1)|null|
|**2024-10-08**|**A large collection of bioinformatics question-query pairs over federated knowledge graphs: methodology and applications**|Jerven Bolleman et.al.|[2410.06010v1](http://arxiv.org/abs/2410.06010v1)|null|
|**2024-10-08**|**LightRAG: Simple and Fast Retrieval-Augmented Generation**|Zirui Guo et.al.|[2410.05779v1](http://arxiv.org/abs/2410.05779v1)|[link](https://github.com/hkuds/lightrag)|
|**2024-10-08**|**Information Discovery in e-Commerce**|Zhaochun Ren et.al.|[2410.05763v2](http://arxiv.org/abs/2410.05763v2)|null|
|**2024-10-08**|**Vector-ICL: In-context Learning with Continuous Vector Representations**|Yufan Zhuang et.al.|[2410.05629v1](http://arxiv.org/abs/2410.05629v1)|[link](https://github.com/EvanZhuang/vector-icl)|
|**2024-10-07**|**Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives**|Xinliang Frederick Zhang et.al.|[2410.05558v1](http://arxiv.org/abs/2410.05558v1)|null|
|**2024-10-07**|**Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents**|Yuwei Hu et.al.|[2410.05130v1](http://arxiv.org/abs/2410.05130v1)|null|
|**2024-10-07**|**Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law**|Yongming Chen et.al.|[2410.04949v1](http://arxiv.org/abs/2410.04949v1)|null|
|**2024-10-07**|**GARLIC: LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph for Long Document QA**|Xinyu Wang et.al.|[2410.04790v1](http://arxiv.org/abs/2410.04790v1)|null|
|**2024-10-06**|**Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval**|Pengcheng Jiang et.al.|[2410.04585v1](http://arxiv.org/abs/2410.04585v1)|[link](https://github.com/pat-jj/KARE)|
|**2024-10-06**|**Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Support**|Abdul Muqtadir et.al.|[2410.10853v1](http://arxiv.org/abs/2410.10853v1)|null|
|**2024-10-04**|**Leveraging Social Determinants of Health in Alzheimer's Research Using LLM-Augmented Literature Mining and Knowledge Graphs**|Tianqi Shang et.al.|[2410.09080v1](http://arxiv.org/abs/2410.09080v1)|[link](https://github.com/hwq0726/sdohenpkg)|
|**2024-10-04**|**Empowering Domain-Specific Language Models with Graph-Oriented Databases: A Paradigm Shift in Performance and Model Maintenance**|Ricardo Di Pasquale et.al.|[2410.03867v1](http://arxiv.org/abs/2410.03867v1)|null|
|**2024-10-04**|**GraphRouter: A Graph-based Router for LLM Selections**|Tao Feng et.al.|[2410.03834v1](http://arxiv.org/abs/2410.03834v1)|null|
|**2024-10-04**|**Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing**|Jeongwoo Kang et.al.|[2410.03357v1](http://arxiv.org/abs/2410.03357v1)|[link](https://github.com/Emvista/Meta-XAMR-2024)|
|**2024-10-04**|**Enriching Ontologies with Disjointness Axioms using Large Language Models**|Elias Crum et.al.|[2410.03235v1](http://arxiv.org/abs/2410.03235v1)|[link](https://github.com/n28div/llm-disjointness)|
|**2024-10-04**|**How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension**|Xinnan Dai et.al.|[2410.05298v1](http://arxiv.org/abs/2410.05298v1)|null|
|**2024-10-03**|**LLMCO2: Advancing Accurate Carbon Footprint Prediction for LLM Inferences**|Zhenxiao Fu et.al.|[2410.02950v1](http://arxiv.org/abs/2410.02950v1)|null|
|**2024-10-03**|**EditRoom: LLM-parameterized Graph Diffusion for Composable 3D Room Layout Editing**|Kaizhi Zheng et.al.|[2410.12836v1](http://arxiv.org/abs/2410.12836v1)|null|
|**2024-10-03**|**Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization**|Ryan C. Barron et.al.|[2410.02721v1](http://arxiv.org/abs/2410.02721v1)|null|
|**2024-10-03**|**A Schema-aware Logic Reformulation for Graph Reachability**|Davide Di Pierro et.al.|[2410.02533v1](http://arxiv.org/abs/2410.02533v1)|null|
|**2024-10-03**|**Language Models are Graph Learners**|Zhe Xu et.al.|[2410.02296v1](http://arxiv.org/abs/2410.02296v1)|null|
|**2024-10-03**|**GraphIC: A Graph-Based In-Context Example Retrieval Model for Multi-Step Reasoning**|Jiale Fu et.al.|[2410.02203v1](http://arxiv.org/abs/2410.02203v1)|null|
|**2024-10-03**|**G2T-LLM: Graph-to-Tree Text Encoding for Molecule Generation with Fine-Tuned Large Language Models**|Zhaoning Yu et.al.|[2410.02198v1](http://arxiv.org/abs/2410.02198v1)|null|
|**2024-10-02**|**FLAG: Financial Long Document Classification via AMR-based GNN**|Bolun "Namir" Xia et.al.|[2410.02024v2](http://arxiv.org/abs/2410.02024v2)|[link](https://github.com/namir0806/flag)|
|**2024-10-02**|**Lost-in-Distance: Impact of Contextual Proximity on LLM Performance in Graph Tasks**|Hamed Firooz et.al.|[2410.01985v1](http://arxiv.org/abs/2410.01985v1)|null|
|**2024-10-02**|**LLM+KG@VLDB'24 Workshop Summary**|Arijit Khan et.al.|[2410.01978v1](http://arxiv.org/abs/2410.01978v1)|null|
|**2024-10-02**|**Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering**|Klaus-Rudolf Kladny et.al.|[2410.01660v1](http://arxiv.org/abs/2410.01660v1)|null|
|**2024-10-02**|**HiReview: Hierarchical Taxonomy-Driven Automatic Literature Review Generation**|Yuntong Hu et.al.|[2410.03761v1](http://arxiv.org/abs/2410.03761v1)|null|
|**2024-10-02**|**LEGO: Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion**|Dexuan Ding et.al.|[2410.01506v2](http://arxiv.org/abs/2410.01506v2)|null|
|**2024-10-02**|**Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering**|Yu Zhang et.al.|[2410.01401v1](http://arxiv.org/abs/2410.01401v1)|[link](https://github.com/EchoDreamer/Q-KGR)|
|**2024-10-02**|**Unveiling Language Skills under Circuits**|Hang Chen et.al.|[2410.01334v1](http://arxiv.org/abs/2410.01334v1)|[link](https://github.com/zodiark-ch/language-skill-of-llms)|
|**2024-10-01**|**From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems**|Ali Mohammadjafari et.al.|[2410.01066v1](http://arxiv.org/abs/2410.01066v1)|null|
|**2024-09-30**|**GUNDAM: Aligning Large Language Models with Graph Understanding**|Sheng Ouyang et.al.|[2409.20053v2](http://arxiv.org/abs/2409.20053v2)|null|
|**2024-09-30**|**Enhancing High-order Interaction Awareness in LLM-based Recommender Model**|Xinfeng Wang et.al.|[2409.19979v2](http://arxiv.org/abs/2409.19979v2)|[link](https://github.com/WangXFng/ELMRec)|
|**2024-09-29**|**CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering**|Yike Wu et.al.|[2409.19753v2](http://arxiv.org/abs/2409.19753v2)|[link](https://github.com/wuyike2000/CoTKR)|
|**2024-09-29**|**Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models**|Xin Li et.al.|[2409.19667v1](http://arxiv.org/abs/2409.19667v1)|[link](https://github.com/bupt-gamma/prograph)|
|**2024-09-28**|**Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs**|Zheng Wang et.al.|[2409.19401v1](http://arxiv.org/abs/2409.19401v1)|null|
|**2024-09-27**|**CLLMate: A Multimodal LLM for Weather and Climate Events Forecasting**|Haobo Li et.al.|[2409.19058v1](http://arxiv.org/abs/2409.19058v1)|null|
|**2024-09-27**|**AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**|Huizi Yu et.al.|[2409.18924v2](http://arxiv.org/abs/2409.18924v2)|null|

#### Abstracts
##### **TransBox: EL++-closed Ontology Embedding**
2410.14571v1 by Hui Yang, Jiaoyan Chen, Uli Sattler

OWL (Web Ontology Language) ontologies, which are able to represent both
relational and type facts as standard knowledge graphs and complex domain
knowledge in Description Logic (DL) axioms, are widely adopted in domains such
as healthcare and bioinformatics. Inspired by the success of knowledge graph
embeddings, embedding OWL ontologies has gained significant attention in recent
years. Current methods primarily focus on learning embeddings for atomic
concepts and roles, enabling the evaluation based on normalized axioms through
specially designed score functions. However, they often neglect the embedding
of complex concepts, making it difficult to infer with more intricate axioms.
This limitation reduces their effectiveness in advanced reasoning tasks, such
as Ontology Learning and ontology-mediated Query Answering. In this paper, we
propose EL++-closed ontology embeddings which are able to represent any logical
expressions in DL via composition. Furthermore, we develop TransBox, an
effective EL++-closed ontology embedding method that can handle many-to-one,
one-to-many and many-to-many relations. Our extensive experiments demonstrate
that TransBox often achieves state-of-the-art performance across various
real-world datasets for predicting complex axioms.

ÊëòË¶ÅÔºöOWLÔºàWeb Ontology LanguageÔºâÊú¨‰ΩìÔºåËÉΩÂ§üÂ∞ÜÂÖ≥Á≥ªÂíåÁ±ªÂûã‰∫ãÂÆûË°®Á§∫‰∏∫Ê†áÂáÜÁü•ËØÜÂõæÂíåÊèèËø∞ÈÄªËæë (DL) ÂÖ¨ÁêÜ‰∏≠ÁöÑÂ§çÊùÇÈ¢ÜÂüüÁü•ËØÜÔºåÂú®ÂåªÁñó‰øùÂÅ•ÂíåÁîüÁâ©‰ø°ÊÅØÂ≠¶Á≠âÈ¢ÜÂüüÂæóÂà∞ÂπøÊ≥õÈááÁî®„ÄÇÂèóÁü•ËØÜÂõæÂµåÂÖ•ÁöÑÊàêÂäüÂêØÂèëÔºåÂµåÂÖ• OWL Êú¨‰ΩìËøëÂπ¥Êù•Â§áÂèóÂÖ≥Ê≥®„ÄÇÂΩìÂâçÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®Â≠¶‰π†ÂéüÂ≠êÊ¶ÇÂøµÂíåËßíËâ≤ÁöÑÂµåÂÖ•ÔºåÈÄöËøá‰∏ìÈó®ËÆæËÆ°ÁöÑËØÑÂàÜÂáΩÊï∞ÔºåÊîØÊåÅÂü∫‰∫éÂΩí‰∏ÄÂåñÂÖ¨ÁêÜÁöÑËØÑ‰º∞„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨ÁªèÂ∏∏ÂøΩÁï•Â§çÊùÇÊ¶ÇÂøµÁöÑÂµåÂÖ•ÔºåËøô‰ΩøÂæóÈöæ‰ª•Êé®Êñ≠Âá∫Êõ¥Â§çÊùÇÁöÑÂÖ¨ÁêÜ„ÄÇËøôÁßçÈôêÂà∂Èôç‰Ωé‰∫ÜÂÆÉ‰ª¨Âú®È´òÁ∫ßÊé®ÁêÜ‰ªªÂä°Ôºà‰æãÂ¶ÇÊú¨‰ΩìÂ≠¶‰π†ÂíåÊú¨‰Ωì‰ªãÂØºÊü•ËØ¢Â∫îÁ≠îÔºâ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü EL++ Â∞ÅÈó≠Êú¨‰ΩìÂµåÂÖ•ÔºåÂÆÉËÉΩÂ§üÈÄöËøáÁªÑÂêàÊù•Ë°®Á§∫ DL ‰∏≠ÁöÑ‰ªª‰ΩïÈÄªËæëË°®ËææÂºè„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü TransBoxÔºå‰∏ÄÁßçÊúâÊïàÁöÑ EL++ Â∞ÅÈó≠Êú¨‰ΩìÂµåÂÖ•ÊñπÊ≥ïÔºåÂèØ‰ª•Â§ÑÁêÜÂ§öÂØπ‰∏Ä„ÄÅ‰∏ÄÂØπÂ§öÂíåÂ§öÂØπÂ§öÂÖ≥Á≥ª„ÄÇÊàë‰ª¨ÂπøÊ≥õÁöÑÂÆûÈ™åË°®ÊòéÔºåTransBox Âú®È¢ÑÊµãÂ§çÊùÇÂÖ¨ÁêÜÁöÑÂêÑÁßçÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆÈõÜ‰∏äÈÄöÂ∏∏ÈÉΩËÉΩËææÂà∞ÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

##### **Paths-over-Graph: Knowledge Graph Enpowered Large Language Model Reasoning**
2410.14211v1 by Xingyu Tan, Xiaoyang Wang, Qing Liu, Xiwei Xu, Xin Yuan, Wenjie Zhang

Large Language Models (LLMs) have achieved impressive results in various
tasks but struggle with hallucination problems and lack of relevant knowledge,
especially in deep complex reasoning and knowledge-intensive tasks. Knowledge
Graphs (KGs), which capture vast amounts of facts in a structured format, offer
a reliable source of knowledge for reasoning. However, existing KG-based LLM
reasoning methods face challenges like handling multi-hop reasoning,
multi-entity questions, and effectively utilizing graph structures. To address
these issues, we propose Paths-over-Graph (PoG), a novel method that enhances
LLM reasoning by integrating knowledge reasoning paths from KGs, improving the
interpretability and faithfulness of LLM outputs. PoG tackles multi-hop and
multi-entity questions through a three-phase dynamic multi-hop path
exploration, which combines the inherent knowledge of LLMs with factual
knowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant
information from the graph exploration first and introduces efficient
three-step pruning techniques that incorporate graph structures, LLM prompting,
and a pre-trained language model (e.g., SBERT) to effectively narrow down the
explored candidate paths. This ensures all reasoning paths contain highly
relevant information captured from KGs, making the reasoning faithful and
interpretable in problem-solving. PoG innovatively utilizes graph structure to
prune the irrelevant noise and represents the first method to implement
multi-entity deep path detection on KGs for LLM reasoning tasks. Comprehensive
experiments on five benchmark KGQA datasets demonstrate PoG outperforms the
state-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an
average accuracy improvement of 18.9%. Notably, PoG with GPT-3.5-Turbo
surpasses ToG with GPT-4 by up to 23.9%.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÂèñÂæó‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÊûúÔºå‰ΩÜÂçªÈõ£‰ª•ÂÖãÊúçÂπªË¶∫ÂïèÈ°åÔºå‰∏îÁº∫‰πèÁõ∏ÈóúÁü•Ë≠òÔºåÂ∞§ÂÖ∂ÊòØÂú®Ê∑±ÂÖ•Ë§áÈõúÁöÑÊé®ÁêÜÂíåÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãô‰∏≠„ÄÇÁü•Ë≠òÂúñË≠ú (KG) ‰ª•ÁµêÊßãÂåñÊ†ºÂºèÊì∑ÂèñÂ§ßÈáè‰∫ãÂØ¶ÔºåÁÇ∫Êé®ÁêÜÊèê‰æõÂèØÈù†ÁöÑÁü•Ë≠ò‰æÜÊ∫ê„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂü∫Êñº KG ÁöÑ LLM Êé®ÁêÜÊñπÊ≥ïÈù¢Ëá®ËôïÁêÜÂ§öË∑≥Êé®ÁêÜ„ÄÅÂ§öÂØ¶È´îÂïèÈ°åÂíåÊúâÊïàÂà©Áî®ÂúñÂΩ¢ÁµêÊßãÁ≠âÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ÂúñÂΩ¢Ë∑ØÂæë (PoG)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéÊï¥Âêà‰æÜËá™ KG ÁöÑÁü•Ë≠òÊé®ÁêÜË∑ØÂæë‰æÜÂ¢ûÂº∑ LLM Êé®ÁêÜÔºåÈÄ≤ËÄåÊèêÂçá LLM Ëº∏Âá∫ÁöÑÂèØËß£ÈáãÊÄßÂíåÁúüÂØ¶ÊÄß„ÄÇPoG ÈÄèÈÅé‰∏âÈöéÊÆµÂãïÊÖãÂ§öË∑≥Ë∑ØÂæëÊé¢Á¥¢‰æÜËôïÁêÜÂ§öË∑≥ÂíåÂ§öÂØ¶È´îÂïèÈ°åÔºåÂ∞á LLM ÁöÑÂÖßÂú®Áü•Ë≠òËàá‰æÜËá™ KG ÁöÑ‰∫ãÂØ¶Áü•Ë≠òÁµêÂêàËµ∑‰æÜ„ÄÇÁÇ∫‰∫ÜÊèêÈ´òÊïàÁéáÔºåPoG È¶ñÂÖàÂæûÂúñÂΩ¢Êé¢Á¥¢‰∏≠‰øÆÂâ™‰∏çÁõ∏ÈóúÁöÑË≥áË®äÔºå‰∏¶ÂºïÂÖ•ÊúâÊïàÁöÑ‰∏âÊ≠•È©ü‰øÆÂâ™ÊäÄË°ìÔºåÁµêÂêàÂúñÂΩ¢ÁµêÊßã„ÄÅLLM ÊèêÁ§∫ÂíåÈ†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°Âûã (‰æãÂ¶Ç SBERT)Ôºå‰ª•ÊúâÊïàÁ∏ÆÂ∞èÊé¢Á¥¢ÁöÑÂÄôÈÅ∏Ë∑ØÂæë„ÄÇÈÄôÁ¢∫‰øùÊâÄÊúâÊé®ÁêÜË∑ØÂæëÈÉΩÂåÖÂê´Âæû KG ‰∏≠Êì∑ÂèñÁöÑÈ´òÂ∫¶Áõ∏ÈóúË≥áË®äÔºå‰ΩøÊé®ÁêÜÂú®ÂïèÈ°åËß£Ê±∫‰∏≠‰øùÊåÅÁúüÂØ¶‰∏îÂèØËß£Èáã„ÄÇPoG ÂâµÊñ∞Âú∞Âà©Áî®ÂúñÂΩ¢ÁµêÊßã‰æÜ‰øÆÂâ™ÁÑ°ÈóúÁöÑÈõúË®äÔºå‰∏¶È¶ñÊ¨°ÂØ¶‰ΩúÂú® KG ‰∏äÈáùÂ∞ç LLM Êé®ÁêÜ‰ªªÂãôÈÄ≤Ë°åÂ§öÂØ¶È´îÊ∑±Â∫¶Ë∑ØÂæëÂÅµÊ∏¨ÁöÑÊñπÊ≥ï„ÄÇÂú®‰∫îÂÄãÂü∫Ê∫ñ KGQA Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂÖ®Èù¢ÂØ¶È©óË≠âÊòéÔºåPoG Âú® GPT-3.5-Turbo Âíå GPT-4 ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï ToGÔºåÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ÊèêÂçá 18.9%„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊê≠Ëºâ GPT-3.5-Turbo ÁöÑ PoG ÊØîÊê≠Ëºâ GPT-4 ÁöÑ ToG È´òÂá∫ 23.9%„ÄÇ

##### **Supervised Chain of Thought**
2410.14198v1 by Xiang Zhang, Dujian Ding

Large Language Models (LLMs) have revolutionized natural language processing
and hold immense potential for advancing Artificial Intelligence. However, the
core architecture of most mainstream LLMs -- the Transformer -- has inherent
limitations in computational depth, rendering them theoretically incapable of
solving many reasoning tasks that demand increasingly deep computations. Chain
of Thought (CoT) prompting has emerged as a technique to address these
architectural limitations, as evidenced by several theoretical studies. It
offers a promising approach to solving complex reasoning tasks that were
previously beyond the capabilities of these models. Despite its successes, CoT
and its variants (such as Tree of Thought, Graph of Thought, etc.) rely on a
"one-prompt-for-all" approach, using a single prompt structure (e.g., "think
step by step") for a wide range of tasks -- from counting and sorting to
solving mathematical and algorithmic problems. This approach poses significant
challenges for models to generate the correct reasoning steps, as the model
must navigate through a vast prompt template space to find the appropriate
template for each task. In this work, we build upon previous theoretical
analyses of CoT to demonstrate how the one-prompt-for-all approach can
negatively affect the computability of LLMs. We partition the solution search
space into two: the prompt space and the answer space. Our findings show that
task-specific supervision is essential for navigating the prompt space
accurately and achieving optimal performance. Through experiments with
state-of-the-art LLMs, we reveal a gap in reasoning performance when
supervision is applied versus when it is not.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæπÂ∫ïÊîπËÆä‰∫ÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÔºå‰∏¶ÂÖ∑ÂÇô‰øÉÈÄ≤‰∫∫Â∑•Êô∫ÊÖßÁôºÂ±ïÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏‰∏ªÊµÅ LLM ÁöÑÊ†∏ÂøÉÊû∂ÊßãÔºàTransformerÔºâÂú®Ë®àÁÆóÊ∑±Â∫¶ÊñπÈù¢ÊúâÂÖ∂ÂÖßÂú®ÈôêÂà∂ÔºåÁêÜË´ñ‰∏äÁÑ°Ê≥ïËß£Ê±∫Ë®±Â§öÈúÄË¶ÅË∂ä‰æÜË∂äÊ∑±ÂÖ•Ë®àÁÆóÁöÑÊé®ÁêÜ‰ªªÂãô„ÄÇÊÄùÁ∂≠Èèà (CoT) ÊèêÁ§∫Â∑≤ÊàêÁÇ∫Ëß£Ê±∫ÈÄô‰∫õÊû∂ÊßãÈôêÂà∂ÁöÑ‰∏ÄÁ®ÆÊäÄË°ìÔºåÈÄôÂ∑≤Áî±ÂπæÈ†ÖÁêÜË´ñÁ†îÁ©∂Ë≠âÂØ¶„ÄÇÂÆÉÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊñπÊ≥ï‰æÜËß£Ê±∫Ë§áÈõúÁöÑÊé®ÁêÜ‰ªªÂãôÔºåÈÄô‰∫õ‰ªªÂãô‰ª•ÂâçË∂ÖÂá∫‰∫ÜÈÄô‰∫õÊ®°ÂûãÁöÑËÉΩÂäõ„ÄÇÂÑòÁÆ°ÂèñÂæó‰∫ÜÊàêÂäüÔºåCoT ÂèäÂÖ∂ËÆäÈ´îÔºà‰æãÂ¶ÇÊÄùÁ∂≠Ê®π„ÄÅÊÄùÁ∂≠ÂúñÁ≠âÔºâ‰æùË≥¥Êñº„Äå‰∏ÄÊèêÁ§∫ÈÅ©Áî®ÊâÄÊúâ„ÄçÁöÑÊñπÊ≥ïÔºåÂ∞çÂêÑÁ®Æ‰ªªÂãôÔºàÂæûË®àÊï∏ÂíåÊéíÂ∫èÂà∞Ëß£Ê±∫Êï∏Â≠∏ÂíåÊºîÁÆóÊ≥ïÂïèÈ°åÔºâ‰ΩøÁî®ÂñÆ‰∏ÄÁöÑÊèêÁ§∫ÁµêÊßãÔºà‰æãÂ¶ÇÔºå„ÄåÈÄêÊ≠•ÊÄùËÄÉ„ÄçÔºâ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∞çÊ®°ÂûãÁî¢ÁîüÊ≠£Á¢∫ÁöÑÊé®ÁêÜÊ≠•È©üÊßãÊàê‰∫ÜÈáçÂ§ßÊåëÊà∞ÔºåÂõ†ÁÇ∫Ê®°ÂûãÂøÖÈ†àÂú®Âª£Ê≥õÁöÑÊèêÁ§∫ÁØÑÊú¨Á©∫Èñì‰∏≠Â∞éËà™ÔºåÊâçËÉΩÁÇ∫ÊØèÂÄã‰ªªÂãôÊâæÂà∞ÈÅ©Áï∂ÁöÑÁØÑÊú¨„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂª∫Á´ãÂú® CoT ÂÖàÂâçÁöÑÁêÜË´ñÂàÜÊûê‰πã‰∏äÔºåË™™Êòé„Äå‰∏ÄÊèêÁ§∫ÈÅ©Áî®ÊâÄÊúâ„ÄçÁöÑÊñπÊ≥ïÂ¶Ç‰ΩïÂ∞ç LLM ÁöÑÂèØË®àÁÆóÊÄßÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÊàëÂÄëÂ∞áËß£ÁöÑÊêúÂ∞ãÁ©∫ÈñìÂàÜÁÇ∫ÂÖ©ÈÉ®ÂàÜÔºöÊèêÁ§∫Á©∫ÈñìÂíåÁ≠îÊ°àÁ©∫Èñì„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÁâπÂÆöÊñº‰ªªÂãôÁöÑÁõ£Áù£Â∞çÊñºÊ∫ñÁ¢∫Â∞éËà™ÊèêÁ§∫Á©∫Èñì‰∏¶ÂØ¶ÁèæÊúÄ‰Ω≥ÊïàËÉΩËá≥ÈóúÈáçË¶Å„ÄÇÈÄèÈÅé‰ΩøÁî®ÊúÄÂÖàÈÄ≤ÁöÑ LLM ÈÄ≤Ë°åÂØ¶È©óÔºåÊàëÂÄëÊè≠Á§∫‰∫ÜÂú®ÊáâÁî®Áõ£Áù£ËàáÊú™ÊáâÁî®Áõ£Áù£ÊôÇÊé®ÁêÜÊïàËÉΩÁöÑÂ∑ÆË∑ù„ÄÇ

##### **Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs**
2410.14057v1 by Simone Conia, Daniel Lee, Min Li, Umar Farooq Minhas, Saloni Potdar, Yunyao Li

Translating text that contains entity names is a challenging task, as
cultural-related references can vary significantly across languages. These
variations may also be caused by transcreation, an adaptation process that
entails more than transliteration and word-for-word translation. In this paper,
we address the problem of cross-cultural translation on two fronts: (i) we
introduce XC-Translate, the first large-scale, manually-created benchmark for
machine translation that focuses on text that contains potentially
culturally-nuanced entity names, and (ii) we propose KG-MT, a novel end-to-end
method to integrate information from a multilingual knowledge graph into a
neural machine translation model by leveraging a dense retrieval mechanism. Our
experiments and analyses show that current machine translation systems and
large language models still struggle to translate texts containing entity
names, whereas KG-MT outperforms state-of-the-art approaches by a large margin,
obtaining a 129% and 62% relative improvement compared to NLLB-200 and GPT-4,
respectively.

ÊëòË¶ÅÔºöÁøªË≠ØÂåÖÂê´ÂØ¶È´îÂêçÁ®±ÁöÑÊñáÂ≠óÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÔºåÂõ†ÁÇ∫ËàáÊñáÂåñÁõ∏ÈóúÁöÑÂèÉËÄÉÂú®‰∏çÂêåË™ûË®Ä‰∏≠ÂèØËÉΩÊúÉÊúâÂæàÂ§ßÂ∑ÆÁï∞„ÄÇÈÄô‰∫õÂ∑ÆÁï∞‰πüÂèØËÉΩÊòØÁî±ËΩâË≠ØÈÄ†ÊàêÁöÑÔºåËΩâË≠ØÊòØ‰∏ÄÁ®ÆÊîπÁ∑®ÈÅéÁ®ãÔºå‰∏çÂÉÖÊ∂âÂèäÈü≥Ë≠ØÂíåÈÄêÂ≠óÁøªË≠Ø„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂæûÂÖ©ÂÄãÊñπÈù¢Ëß£Ê±∫Ë∑®ÊñáÂåñÁøªË≠ØÁöÑÂïèÈ°åÔºö(i) ÊàëÂÄë‰ªãÁ¥π XC-TranslateÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÈáùÂ∞çÂåÖÂê´ÊΩõÂú®ÊñáÂåñÁ¥∞ÂæÆÂ∑ÆÂà•ÂØ¶È´îÂêçÁ®±ÁöÑÊñáÂ≠óÁöÑÂ§ßË¶èÊ®°„ÄÅ‰∫∫Â∑•Âª∫Á´ãÁöÑÊ©üÂô®ÁøªË≠ØÂü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰ª•Âèä (ii) ÊàëÂÄëÊèêÂá∫ KG-MTÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÁöÑÁ´ØÂà∞Á´ØÊñπÊ≥ïÔºåÈÄöÈÅéÂà©Áî®ÂØÜÈõÜÊ™¢Á¥¢Ê©üÂà∂Â∞á‰æÜËá™Â§öË™ûË®ÄÁü•Ë≠òÂúñË≠úÁöÑË≥áË®äÊï¥ÂêàÂà∞Á•ûÁ∂ìÊ©üÂô®ÁøªË≠ØÊ®°Âûã‰∏≠„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÂíåÂàÜÊûêË°®ÊòéÔºåÁõÆÂâçÁöÑÊ©üÂô®ÁøªË≠ØÁ≥ªÁµ±ÂíåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÁøªË≠ØÂåÖÂê´ÂØ¶È´îÂêçÁ®±ÁöÑÊñáÂ≠óÊôÇ‰ªçÂ≠òÂú®Âõ∞Èõ£ÔºåËÄå KG-MT Ââá‰ª•Â§ßÂπÖÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁöÑÂÑ™Âã¢ÂãùÂá∫ÔºåËàá NLLB-200 Âíå GPT-4 Áõ∏ÊØîÔºåÂàÜÂà•Áç≤Âæó‰∫Ü 129% Âíå 62% ÁöÑÁõ∏Â∞çÊîπÈÄ≤„ÄÇ

##### **RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs**
2410.13987v1 by Jiatan Huang, Mingchen Li, Zonghai Yao, Zhichao Yang, Yongkang Xiao, Feiyun Ouyang, Xiaohan Li, Shuo Han, Hong Yu

Answering complex real-world questions often requires accurate retrieval from
textual knowledge graphs (TKGs). The scarcity of annotated data, along with
intricate topological structures, makes this task particularly challenging. As
the nature of relational path information could enhance the inference ability
of Large Language Models (LLMs), efficiently retrieving more complex relational
path information from TKGs presents another key challenge. To tackle these
challenges, we first develop a Dataset for LLMs Complex Reasoning over Textual
Knowledge Graphs (RiTeK) with a broad topological structure coverage.We
synthesize realistic user queries that integrate diverse topological
structures, relational information, and complex textual descriptions. We
conduct rigorous expert evaluation to validate the quality of our synthesized
queries. And then, we introduce an enhanced Monte Carlo Tree Search (MCTS)
method, Relational MCTS, to automatically extract relational path information
from textual graphs for specific queries. Our dataset mainly covers the medical
domain as the relation types and entity are complex and publicly available.
Experimental results indicate that RiTeK poses significant challenges for
current retrieval and LLM systems, while the proposed Relational MCTS method
enhances LLM inference ability and achieves state-of-the-art performance on
RiTeK.

ÊëòË¶ÅÔºöÂõûÁ≠îË§áÈõúÁöÑÁèæÂØ¶‰∏ñÁïåÂïèÈ°åÈÄöÂ∏∏ÈúÄË¶ÅÂæûÊñáÊú¨Áü•Ë≠òÂúñ (TKG) ‰∏≠Ê∫ñÁ¢∫Êì∑Âèñ„ÄÇÊ®ôË®ªË≥áÊñôÁöÑÁ®ÄÂ∞ëÔºåÂä†‰∏äË§áÈõúÁöÑÊãìÊí≤ÁµêÊßãÔºå‰ΩøÂæóÈÄôÈ†Ö‰ªªÂãôÁâπÂà•ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁî±ÊñºÈóú‰øÇË∑ØÂæëË≥áË®äÁöÑÊÄßË≥™ÂèØ‰ª•Â¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊé®Ë´ñËÉΩÂäõÔºåÂæû TKG ÊúâÊïàÂú∞Êì∑ÂèñÊõ¥Ë§áÈõúÁöÑÈóú‰øÇË∑ØÂæëË≥áË®äÊèêÂá∫‰∫ÜÂè¶‰∏ÄÂÄãÈóúÈçµÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÈ¶ñÂÖàÈñãÁôº‰∫Ü‰∏ÄÂÄãÂÖ∑ÊúâÂª£Ê≥õÊãìÊí≤ÁµêÊßãÊ∂µËìãÁØÑÂúçÁöÑÊñáÊú¨Áü•Ë≠òÂúñ (RiTeK) ‰∏äÁöÑ LLM Ë§áÈõúÊé®ÁêÜË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁ∂úÂêà‰∫ÜÊï¥Âêà‰∫ÜÂ§öÊ®£ÂåñÊãìÊí≤ÁµêÊßã„ÄÅÈóú‰øÇË≥áË®äÂíåË§áÈõúÊñáÊú¨ÊèèËø∞ÁöÑÁèæÂØ¶‰ΩøÁî®ËÄÖÊü•Ë©¢„ÄÇÊàëÂÄëÈÄ≤Ë°åÂö¥Ê†ºÁöÑÂ∞àÂÆ∂Ë©ï‰º∞Ôºå‰ª•È©óË≠âÊàëÂÄëÁ∂úÂêàÊü•Ë©¢ÁöÑÂìÅË≥™„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÂ¢ûÂº∑ÁöÑËíôÂú∞Âç°ÁæÖÊ®πÊêúÂ∞ã (MCTS) ÊñπÊ≥ïÔºåÂç≥Èóú‰øÇ MCTSÔºå‰ª•Ëá™ÂãïÂæûÊñáÊú¨Âúñ‰∏≠Êì∑ÂèñÁâπÂÆöÊü•Ë©¢ÁöÑÈóú‰øÇË∑ØÂæëË≥áË®ä„ÄÇÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏ªË¶ÅÊ∂µËìãÈÜ´ÁôÇÈ†òÂüüÔºåÂõ†ÁÇ∫Èóú‰øÇÈ°ûÂûãÂíåÂØ¶È´îÂæàË§áÈõú‰∏îÂÖ¨ÈñãÂèØÁî®„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåRiTeK Â∞çÁõÆÂâçÁöÑÊì∑ÂèñÂíå LLM Á≥ªÁµ±ÊèêÂá∫‰∫ÜÈáçÂ§ßÊåëÊà∞ÔºåËÄåÊâÄÊèêÂá∫ÁöÑÈóú‰øÇ MCTS ÊñπÊ≥ïÂ¢ûÂº∑‰∫Ü LLM Êé®Ë´ñËÉΩÂäõÔºå‰∏¶Âú® RiTeK ‰∏äÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **The Mystery of the Pathological Path-star Task for Language Models**
2410.13779v1 by Arvid Frydenlund

The recently introduced path-star task is a minimal task designed to
exemplify limitations to the abilities of language models (Bachmann and
Nagarajan, 2024). It involves a path-star graph where multiple arms radiate
from a single starting node and each node is unique. Given the start node and a
specified target node that ends an arm, the task is to generate the arm
containing that target node. This is straightforward for a human but
surprisingly difficult for language models, which did not outperform the random
baseline. The authors hypothesized this is due to a deficiency in
teacher-forcing and the next-token prediction paradigm.
  We demonstrate the task is learnable using teacher-forcing in alternative
settings and that the issue is partially due to representation. We introduce a
regularization method using structured samples of the same graph but with
differing target nodes, improving results across a variety of model types. We
provide RASP proofs showing the task is theoretically solvable. Finally, we
find settings where an encoder-only model can consistently solve the task.

ÊëòË¶ÅÔºöÊúÄËøëÊé®Âá∫ÁöÑË∑ØÂæëÊòüÂΩ¢‰ªªÂãôÊòØ‰∏ÄÂÄãÊ•µÁ∞°‰ªªÂãôÔºåÊó®Âú®Ë™™ÊòéË™ûË®ÄÊ®°ÂûãËÉΩÂäõÁöÑÈôêÂà∂ÔºàBachmann Âíå NagarajanÔºå2024 Âπ¥Ôºâ„ÄÇÂÆÉÊ∂âÂèä‰∏ÄÂÄãË∑ØÂæëÊòüÂΩ¢ÂúñÔºåÂÖ∂‰∏≠Â§öÂÄãÂàÜÊîØÂæû‰∏ÄÂÄãËµ∑ÂßãÁØÄÈªûËºªÂ∞ÑÂá∫ÂéªÔºåÊØèÂÄãÁØÄÈªûÈÉΩÊòØÂîØ‰∏ÄÁöÑ„ÄÇÁµ¶ÂÆöËµ∑ÂßãÁØÄÈªûÂíåÁµêÊùü‰∏ÄÂÄãÂàÜÊîØÁöÑÊåáÂÆöÁõÆÊ®ôÁØÄÈªûÔºå‰ªªÂãôÊòØÁîüÊàêÂåÖÂê´Ë©≤ÁõÆÊ®ôÁØÄÈªûÁöÑÂàÜÊîØ„ÄÇÈÄôÂ∞ç‰∫∫È°û‰æÜË™™ÂæàÁ∞°ÂñÆÔºå‰ΩÜÂ∞çË™ûË®ÄÊ®°Âûã‰æÜË™™ÂçªÁï∞‰πéÂ∞ãÂ∏∏Âú∞Âõ∞Èõ£ÔºåÂõ†ÁÇ∫Ë™ûË®ÄÊ®°Âûã‰∏¶Êú™ÂÑ™ÊñºÈö®Ê©üÂü∫Ê∫ñÁ∑ö„ÄÇ‰ΩúËÄÖÂÅáË®≠ÈÄôÊòØÁî±ÊñºÊïôÂ∏´Âº∑Âà∂Âíå‰∏ã‰∏ÄÂÄãÁ¨¶ËôüÈ†êÊ∏¨ÁØÑ‰æãÁöÑ‰∏çË∂≥„ÄÇ
ÊàëÂÄëÂ±ïÁ§∫‰∫ÜË©≤‰ªªÂãôÂèØ‰ª•‰ΩøÁî®Êõø‰ª£Ë®≠ÁΩÆ‰∏≠ÁöÑÊïôÂ∏´Âº∑Âà∂‰æÜÂ≠∏ÁøíÔºå‰∏¶‰∏îÂïèÈ°åÈÉ®ÂàÜÊòØÁî±ÊñºË°®Á§∫„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊ≠£ÂâáÂåñÊñπÊ≥ïÔºå‰ΩøÁî®Âêå‰∏ÄÂúñÂΩ¢ÁöÑÁµêÊßãÂåñÊ®£Êú¨Ôºå‰ΩÜÁõÆÊ®ôÁØÄÈªû‰∏çÂêåÔºåÂæûËÄåÊîπÈÄ≤‰∫ÜÂêÑÁ®ÆÊ®°ÂûãÈ°ûÂûãÁöÑÁµêÊûú„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü RASP Ë≠âÊòéÔºåË°®ÊòéË©≤‰ªªÂãôÂú®ÁêÜË´ñ‰∏äÊòØÂèØ‰ª•Ëß£Ê±∫ÁöÑ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊâæÂà∞‰∫ÜÂÉÖÁ∑®Á¢ºÂô®Ê®°ÂûãÂèØ‰ª•ÊåÅÁ∫åËß£Ê±∫‰ªªÂãôÁöÑË®≠ÁΩÆ„ÄÇ

##### **Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval**
2410.13765v1 by Yu Xia, Junda Wu, Sungchul Kim, Tong Yu, Ryan A. Rossi, Haoliang Wang, Julian McAuley

Large language models (LLMs) have been used to generate query expansions
augmenting original queries for improving information search. Recent studies
also explore providing LLMs with initial retrieval results to generate query
expansions more grounded to document corpus. However, these methods mostly
focus on enhancing textual similarities between search queries and target
documents, overlooking document relations. For queries like "Find me a highly
rated camera for wildlife photography compatible with my Nikon F-Mount lenses",
existing methods may generate expansions that are semantically similar but
structurally unrelated to user intents. To handle such semi-structured queries
with both textual and relational requirements, in this paper we propose a
knowledge-aware query expansion framework, augmenting LLMs with structured
document relations from knowledge graph (KG). To further address the limitation
of entity-based scoring in existing KG-based methods, we leverage document
texts as rich KG node representations and use document-based relation filtering
for our Knowledge-Aware Retrieval (KAR). Extensive experiments on three
datasets of diverse domains show the advantages of our method compared against
state-of-the-art baselines on textual and relational semi-structured retrieval.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Áî®ÊñºÁî¢ÁîüÊü•Ë©¢Êì¥ÂÖÖÔºåËóâ‰ª•Êì¥ÂÖÖÂéüÂßãÊü•Ë©¢Ôºå‰ª•ÊîπÂñÑË≥áË®äÊêúÂ∞ã„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂‰πüÊé¢Ë®éÊèê‰æõ LLM ÂàùÂßãÊ™¢Á¥¢ÁµêÊûúÔºå‰ª•Áî¢ÁîüÊõ¥Ë≤ºËøëÊñá‰ª∂Ë™ûÊñôÂ∫´ÁöÑÊü•Ë©¢Êì¥ÂÖÖ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÂ§ßÂ§öËëóÈáçÊñºÂä†Âº∑ÊêúÂ∞ãÊü•Ë©¢ËàáÁõÆÊ®ôÊñá‰ª∂‰πãÈñìÁöÑÊñáÂ≠óÁõ∏‰ººÊÄßÔºåËÄåÂøΩÁï•‰∫ÜÊñá‰ª∂Èóú‰øÇ„ÄÇÂ∞çÊñº„ÄåÂπ´ÊàëÊâæ‰∏ÄÂè∞ËàáÊàëÁöÑ Nikon F-Mount Èè°È†≠Áõ∏ÂÆπ„ÄÅË©ïÂÉπÂæàÈ´òÁöÑÈáéÁîüÂãïÁâ©ÊîùÂΩ±Áõ∏Ê©ü„ÄçÁ≠âÊü•Ë©¢ÔºåÁèæÊúâÊñπÊ≥ïÂèØËÉΩÊúÉÁî¢ÁîüË™ûÁæ©‰∏äÁõ∏‰ºº‰ΩÜÁµêÊßã‰∏äËàá‰ΩøÁî®ËÄÖÊÑèÂúñÁÑ°ÈóúÁöÑÊì¥ÂÖÖ„ÄÇÁÇ∫‰∫ÜËôïÁêÜÂÖ∑ÊúâÊñáÂ≠óÂíåÈóú‰øÇÈúÄÊ±ÇÁöÑÊ≠§È°ûÂçäÁµêÊßãÂåñÊü•Ë©¢ÔºåÊàëÂÄëÂú®Êú¨Êñá‰∏≠ÊèêÂá∫‰∏ÄÂÄãÁü•Ë≠òÊÑüÁü•Êü•Ë©¢Êì¥ÂÖÖÊû∂ÊßãÔºåÂà©Áî®Áü•Ë≠òÂúñË≠ú (KG) ‰∏≠ÁöÑÁµêÊßãÂåñÊñá‰ª∂Èóú‰øÇÊì¥ÂÖÖ LLM„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•Ëß£Ê±∫ÁèæÊúâÂü∫Êñº KG ÁöÑÊñπÊ≥ï‰∏≠Âü∫ÊñºÂØ¶È´îÁöÑË©ïÂàÜÈôêÂà∂ÔºåÊàëÂÄëÂà©Áî®Êñá‰ª∂ÊñáÂ≠ó‰ΩúÁÇ∫Ë±êÂØåÁöÑ KG ÁØÄÈªûË°®ÂæµÔºå‰∏¶‰ΩøÁî®Âü∫ÊñºÊñá‰ª∂ÁöÑÈóú‰øÇÁØ©ÈÅ∏ÔºåÈÄ≤Ë°åÊàëÂÄëÁöÑÁü•Ë≠òÊÑüÁü•Ê™¢Á¥¢ (KAR)„ÄÇÈáùÂ∞ç‰∏âÂÄã‰∏çÂêåÈ†òÂüüË≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÊ®°ÂûãËàáÊñáÂ≠óÂíåÈóú‰øÇÂçäÁµêÊßãÂåñÊ™¢Á¥¢ÁöÑÊúÄÊñ∞Âü∫Ê∫ñÁõ∏ÊØîÔºåÂÖ∑ÊúâÂÑ™Âã¢„ÄÇ

##### **LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models**
2410.13299v1 by David Hoffmann, Kailash Budhathoki, Matthaeus Kleindessner

The evolving capabilities of large language models are accompanied by growing
sizes and deployment costs, necessitating effective inference optimisation
techniques. We propose a novel pruning method utilising centrality measures
from graph theory, reducing both the computational requirements and the memory
footprint of these models. Specifically, we devise a method for creating a
weighted directed acyclical graph representation of multilayer perceptrons to
which we apply a modified version of the weighted PageRank centrality measure
to compute node importance scores. In combination with uniform pruning this
leads to structured sparsity. We call this pruning method MLPRank. Furthermore
we introduce an extension to decoder-only transformer models and call it
LLMRank. For both variants we demonstrate a strong performance. With MLPRank on
average leading to 6.09 % higher accuracy retention than three popular
baselines and 13.42 % with LLMRank compared to two popular baselines.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂäüËÉΩÁöÑÊºîÈÄ≤ÔºåÊ®°ÂûãË¶èÊ®°ËàáÈÉ®ÁΩ≤ÊàêÊú¨‰πüÈö®‰πãÂ¢ûÂä†ÔºåÂõ†Ê≠§ÈúÄË¶ÅÊúâÊïàÁöÑÊé®Ë´ñÊúÄ‰Ω≥ÂåñÊäÄË°ì„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑ‰øÆÂâ™ÊñπÊ≥ïÔºåÂà©Áî®ÂúñË´ñ‰∏≠ÁöÑ‰∏≠ÂøÉÊÄßÊ∏¨ÈáèÔºåÂêåÊôÇÊ∏õÂ∞ëÈÄô‰∫õÊ®°ÂûãÁöÑÈÅãÁÆóÈúÄÊ±ÇÂíåË®òÊÜ∂È´î‰ΩøÁî®Èáè„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÁî®ÊñºÂª∫Á´ãÂ§öÂ±§ÊÑüÁü•Âô®ÁöÑÂä†Ê¨äÊúâÂêëÁÑ°Áí∞ÂúñË°®Á§∫Ôºå‰∏¶Â∞çÂÖ∂Â•óÁî®Âä†Ê¨ä PageRank ‰∏≠ÂøÉÊÄßÊ∏¨ÈáèÁöÑ‰øÆÊîπÁâàÊú¨Ôºå‰ª•Ë®àÁÆóÁØÄÈªûÈáçË¶ÅÊÄßÂàÜÊï∏„ÄÇÁµêÂêàÂùáÂãª‰øÆÂâ™ÔºåÈÄôÂ∞áÂ∞éËá¥ÁµêÊßãÂåñÁ®ÄÁñèÊÄß„ÄÇÊàëÂÄëÁ®±ÈÄôÁ®Æ‰øÆÂâ™ÊñπÊ≥ïÁÇ∫ MLPRank„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫ÜÂÉÖËß£Á¢ºÂô®TransformerÊ®°ÂûãÁöÑÂª∂‰º∏Ôºå‰∏¶Á®±‰πãÁÇ∫ LLMRank„ÄÇÂ∞çÊñºÈÄôÂÖ©Á®ÆËÆäÈ´îÔºåÊàëÂÄëÈÉΩÂ±ïÁ§∫‰∫ÜÂº∑Â§ßÁöÑÊïàËÉΩ„ÄÇMLPRank Âπ≥ÂùáÊØî‰∏âÁ®ÆÊµÅË°åÂü∫Ê∫ñÈ´òÂá∫ 6.09% ÁöÑÊ∫ñÁ¢∫ÊÄß‰øùÁïôÁéáÔºåËÄå LLMRank ÂâáÊØîÂÖ©Á®ÆÊµÅË°åÂü∫Ê∫ñÈ´òÂá∫ 13.42%„ÄÇ

##### **Trust but Verify: Programmatic VLM Evaluation in the Wild**
2410.13121v1 by Viraj Prabhu, Senthil Purushwalkam, An Yan, Caiming Xiong, Ran Xu

Vision-Language Models (VLMs) often generate plausible but incorrect
responses to visual queries. However, reliably quantifying the effect of such
hallucinations in free-form responses to open-ended queries is challenging as
it requires visually verifying each claim within the response. We propose
Programmatic VLM Evaluation (PROVE), a new benchmarking paradigm for evaluating
VLM responses to open-ended queries. To construct PROVE, we provide a large
language model (LLM) with a high-fidelity scene-graph representation
constructed from a hyper-detailed image caption, and prompt it to generate
diverse question-answer (QA) pairs, as well as programs that can be executed
over the scene graph object to verify each QA pair. We thus construct a
benchmark of 10.5k challenging but visually grounded QA pairs. Next, to
evaluate free-form model responses to queries in PROVE, we propose a
programmatic evaluation strategy that measures both the helpfulness and
truthfulness of a response within a unified scene graph-based framework. We
benchmark the helpfulness-truthfulness trade-offs of a range of VLMs on PROVE,
finding that very few are in-fact able to achieve a good balance between the
two. Project page: \url{https://prove-explorer.netlify.app/}.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Á∂ìÂ∏∏Â∞çË¶ñË¶∫Êü•Ë©¢Áî¢ÁîüÁúã‰ººÂêàÁêÜ‰ΩÜÈåØË™§ÁöÑÂõûÊáâ„ÄÇÁÑ∂ËÄåÔºåÂèØÈù†Âú∞ÈáèÂåñÊ≠§È°ûÂπªË¶∫Âú®ÈñãÊîæÂºèÊü•Ë©¢ÁöÑËá™Áî±ÂΩ¢ÂºèÂõûÊáâ‰∏≠ÁöÑÂΩ±ÈüøÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫ÈÄôÈúÄË¶ÅË¶ñË¶∫È©óË≠âÂõûÊáâ‰∏≠ÁöÑÊØèÂÄãË™™Ê≥ï„ÄÇÊàëÂÄëÊèêÂá∫Á®ãÂºèÂåñ VLM Ë©ï‰º∞ (PROVE)Ôºå‰∏ÄÁ®ÆÁî®ÊñºË©ï‰º∞ VLM Â∞çÈñãÊîæÂºèÊü•Ë©¢ÁöÑÂõûÊáâÁöÑÊñ∞Âü∫Ê∫ñÁØÑ‰æã„ÄÇÁÇ∫‰∫ÜÂª∫Êßã PROVEÔºåÊàëÂÄëÊèê‰æõ‰∏ÄÂÄãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏ÄÂÄãÁî±Ë∂ÖË©≥Á¥∞ÂΩ±ÂÉèÊ®ôÈ°åÂª∫ÊßãÁöÑÈ´ò‰øùÁúüÂ†¥ÊôØÂúñË°®Á§∫Ôºå‰∏¶ÊèêÁ§∫ÂÆÉÁî¢ÁîüÂ§öÊ®£ÂåñÁöÑÂïèÁ≠î (QA) ÈÖçÂ∞çÔºå‰ª•ÂèäÂèØ‰ª•Âú®Â†¥ÊôØÂúñÁâ©‰ª∂‰∏äÂü∑Ë°åÁöÑÁ®ãÂºèÔºå‰ª•È©óË≠âÊØèÂÄã QA ÈÖçÂ∞ç„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãÁî± 10.5k ÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄß‰ΩÜË¶ñË¶∫‰∏äÂêàÁêÜÁöÑ QA ÈÖçÂ∞çÁµÑÊàêÁöÑÂü∫Ê∫ñ„ÄÇÊé•‰∏ã‰æÜÔºåÁÇ∫‰∫ÜË©ï‰º∞ PROVE ‰∏≠ÁöÑÊü•Ë©¢ÁöÑËá™Áî±ÂΩ¢ÂºèÊ®°ÂûãÂõûÊáâÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ®ãÂºèÂåñË©ï‰º∞Á≠ñÁï•ÔºåË©≤Á≠ñÁï•Âú®‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÂü∫ÊñºÂ†¥ÊôØÂúñÁöÑÊ°ÜÊû∂‰∏≠Ë°°ÈáèÂõûÊáâÁöÑÊúâÁî®ÊÄßÂíåÁúüÂØ¶ÊÄß„ÄÇÊàëÂÄëÂú® PROVE ‰∏äÂ∞ç‰∏ÄÁ≥ªÂàó VLM ÁöÑÊúâÁî®ÊÄß-ÁúüÂØ¶ÊÄßÊ¨äË°°ÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÁôºÁèæ‰∫ãÂØ¶‰∏äÂæàÂ∞ëÊúâ VLM ËÉΩÂú®ÂÖ©ËÄÖ‰πãÈñìÂèñÂæóËâØÂ•ΩÁöÑÂπ≥Ë°°„ÄÇÂ∞àÊ°àÈ†ÅÈù¢Ôºö\url{https://prove-explorer.netlify.app/}„ÄÇ

##### **Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models**
2410.13080v1 by Linhao Luo, Zicheng Zhao, Chen Gong, Gholamreza Haffari, Shirui Pan

Large language models (LLMs) have demonstrated impressive reasoning
abilities, but they still struggle with faithful reasoning due to knowledge
gaps and hallucinations. To address these issues, knowledge graphs (KGs) have
been utilized to enhance LLM reasoning through their structured knowledge.
However, existing KG-enhanced methods, either retrieval-based or agent-based,
encounter difficulties in accurately retrieving knowledge and efficiently
traversing KGs at scale. In this work, we introduce graph-constrained reasoning
(GCR), a novel framework that bridges structured knowledge in KGs with
unstructured reasoning in LLMs. To eliminate hallucinations, GCR ensures
faithful KG-grounded reasoning by integrating KG structure into the LLM
decoding process through KG-Trie, a trie-based index that encodes KG reasoning
paths. KG-Trie constrains the decoding process, allowing LLMs to directly
reason on graphs and generate faithful reasoning paths grounded in KGs.
Additionally, GCR leverages a lightweight KG-specialized LLM for
graph-constrained reasoning alongside a powerful general LLM for inductive
reasoning over multiple reasoning paths, resulting in accurate reasoning with
zero reasoning hallucination. Extensive experiments on several KGQA benchmarks
demonstrate that GCR achieves state-of-the-art performance and exhibits strong
zero-shot generalizability to unseen KGs without additional training.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂ∑≤Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ΩÜÁî±ÊñºÁü•Ë≠òÂ∑ÆË∑ùÂíåÂπªË¶∫ÔºåÂÆÉÂÄëÂú®Âø†ÂØ¶Êé®ÁêÜÊñπÈù¢‰ªçÂ≠òÂú®Âõ∞Èõ£„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÁü•Ë≠òÂúñË≠úÔºàKGÔºâÂ∑≤Ë¢´Áî®ÊñºÈÄèÈÅéÂÖ∂ÁµêÊßãÂåñÁü•Ë≠òÂ¢ûÂº∑ LLM Êé®ÁêÜ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ KG Â¢ûÂº∑ÊñπÊ≥ïÔºåÁÑ°Ë´ñÊòØÂü∫ÊñºÊ™¢Á¥¢ÊàñÂü∫Êñº‰ª£ÁêÜÔºåÂú®Ê∫ñÁ¢∫Ê™¢Á¥¢Áü•Ë≠òÂíåÊúâÊïàÈÅçÊ≠∑Â§ßË¶èÊ®° KG ÊôÇÈÉΩÊúÉÈÅáÂà∞Âõ∞Èõ£„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂúñÁ¥ÑÊùüÊé®ÁêÜÔºàGCRÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÂÆÉÂ∞á KG ‰∏≠ÁöÑÁµêÊßãÂåñÁü•Ë≠òËàá LLM ‰∏≠ÁöÑÈùûÁµêÊßãÂåñÊé®ÁêÜËÅØÁπ´Ëµ∑‰æÜ„ÄÇÁÇ∫‰∫ÜÊ∂àÈô§ÂπªË¶∫ÔºåGCR ÈÄèÈÅéÂ∞á KG ÁµêÊßãÊï¥ÂêàÂà∞ LLM Ëß£Á¢ºÈÅéÁ®ã‰∏≠ÔºåÈÄèÈÅé KG-TrieÔºà‰∏ÄÁ®ÆÁ∑®Á¢º KG Êé®ÁêÜË∑ØÂæëÁöÑÂü∫Êñº Trie ÁöÑÁ¥¢ÂºïÔºâ‰æÜÁ¢∫‰øùÂø†ÂØ¶ÁöÑÂü∫Êñº KG ÁöÑÊé®ÁêÜ„ÄÇKG-Trie Á¥ÑÊùü‰∫ÜËß£Á¢ºÈÅéÁ®ãÔºåÂÖÅË®± LLM Áõ¥Êé•Âú®ÂúñÂΩ¢‰∏äÊé®ÁêÜÔºå‰∏¶ÁîüÊàêÂü∫Êñº KG ÁöÑÂø†ÂØ¶Êé®ÁêÜË∑ØÂæë„ÄÇÊ≠§Â§ñÔºåGCR Èô§‰∫ÜÂà©Áî®‰∏ÄÂÄãÂäüËÉΩÂº∑Â§ßÁöÑÈÄöÁî® LLM ÈÄ≤Ë°åÂ§öÈáçÊé®ÁêÜË∑ØÂæëÁöÑÊ≠∏Á¥çÊé®ÁêÜ‰πãÂ§ñÔºåÈÇÑÂà©Áî®‰∫Ü‰∏ÄÂÄãËºïÈáèÁ¥öÁöÑ KG Â∞àÁî® LLM ÈÄ≤Ë°åÂúñÁ¥ÑÊùüÊé®ÁêÜÔºåÂæûËÄåÂØ¶Áèæ‰∫ÜÊ∫ñÁ¢∫Êé®ÁêÜÔºå‰∏îÈõ∂Êé®ÁêÜÂπªË¶∫„ÄÇÂú®ÂπæÂÄã KGQA Âü∫Ê∫ñ‰∏äÈÄ≤Ë°åÁöÑÂ§ßÈáèÂØ¶È©óË≠âÊòéÔºåGCR ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰∏¶Âú®Ê≤íÊúâÈ°çÂ§ñË®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÂ∞çÊú™Ë¶ãÈÅéÁöÑ KG Ë°®ÁèæÂá∫Âº∑Â§ßÁöÑÈõ∂Ê¨°ÊñπÊ≥õÂåñËÉΩÂäõ„ÄÇ

##### **Supply Chain Network Extraction and Entity Classification Leveraging Large Language Models**
2410.13051v1 by Tong Liu, Hadi Meidani

Supply chain networks are critical to the operational efficiency of
industries, yet their increasing complexity presents significant challenges in
mapping relationships and identifying the roles of various entities.
Traditional methods for constructing supply chain networks rely heavily on
structured datasets and manual data collection, limiting their scope and
efficiency. In contrast, recent advancements in Natural Language Processing
(NLP) and large language models (LLMs) offer new opportunities for discovering
and analyzing supply chain networks using unstructured text data. This paper
proposes a novel approach that leverages LLMs to extract and process raw
textual information from publicly available sources to construct a
comprehensive supply chain graph. We focus on the civil engineering sector as a
case study, demonstrating how LLMs can uncover hidden relationships among
companies, projects, and other entities. Additionally, we fine-tune an LLM to
classify entities within the supply chain graph, providing detailed insights
into their roles and relationships. The results show that domain-specific
fine-tuning improves classification accuracy, highlighting the potential of
LLMs for industry-specific supply chain analysis. Our contributions include the
development of a supply chain graph for the civil engineering sector, as well
as a fine-tuned LLM model that enhances entity classification and understanding
of supply chain networks.

ÊëòË¶ÅÔºö‰æõÊáâÈèàÁ∂≤Ë∑ØÂ∞çÊñºÁî¢Ê•≠ÁöÑÁáüÈÅãÊïàÁéáËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂÆÉÂÄëÊó•ÁõäÂ¢ûÂä†ÁöÑË§áÈõúÊÄßÂú®Áπ™Ë£ΩÈóú‰øÇÂúñÂíåÊâæÂá∫ÂêÑÂÄãÂØ¶È´îÁöÑËßíËâ≤ÊñπÈù¢Â∏∂‰æÜ‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇ
Âª∫Êßã‰æõÊáâÈèàÁ∂≤Ë∑ØÁöÑÂÇ≥Áµ±ÊñπÊ≥ïÊ•µÂ∫¶‰ª∞Ë≥¥ÁµêÊßãÂåñË≥áÊñôÈõÜÂíåÊâãÂãïË≥áÊñôÊî∂ÈõÜÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑÁØÑÂúçÂíåÊïàÁéá„ÄÇÁõ∏ÂèçÂú∞ÔºåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËøëÊúüÈÄ≤Â±ïÁÇ∫‰ΩøÁî®ÈùûÁµêÊßãÂåñÊñáÂ≠óË≥áÊñôÁôºÁèæÂíåÂàÜÊûê‰æõÊáâÈèàÁ∂≤Ë∑ØÊèê‰æõ‰∫ÜÊñ∞ÁöÑÊ©üÊúÉ„ÄÇÈÄôÁØáË´ñÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂÆÉÈÅãÁî® LLM ÂæûÂÖ¨ÈñãÂèØÂæóÁöÑ‰æÜÊ∫ê‰∏≠ËêÉÂèñÂíåËôïÁêÜÂéüÂßãÊñáÂ≠óË≥áË®äÔºå‰ª•Âª∫Êßã‰∏ÄÂÄãÂÖ®Èù¢ÁöÑ‰æõÊáâÈèàÂúñ„ÄÇÊàëÂÄëÂ∞àÊ≥®ÊñºÂúüÊú®Â∑•Á®ãÈÉ®ÈñÄ‰ΩúÁÇ∫‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåÂ±ïÁ§∫ LLM Â¶Ç‰ΩïÊè≠Á§∫ÂÖ¨Âè∏„ÄÅÂ∞àÊ°àÂíåÂÖ∂‰ªñÂØ¶È´î‰πãÈñìÁöÑÈö±ËóèÈóú‰øÇ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂæÆË™ø‰∏ÄÂÄã LLM ‰ª•ÂàÜÈ°û‰æõÊáâÈèàÂúñ‰∏≠ÁöÑÂØ¶È´îÔºåÊèê‰æõÊ∑±ÂÖ•ÁöÑË¶ãËß£Ôºå‰∫ÜËß£ÂÆÉÂÄëÁöÑËßíËâ≤ÂíåÈóú‰øÇ„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÁâπÂÆöÈ†òÂüüÁöÑÂæÆË™øÊîπÈÄ≤‰∫ÜÂàÜÈ°ûÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÁ™ÅÈ°Ø‰∫Ü LLM Âú®Áî¢Ê•≠ÁâπÂÆö‰æõÊáâÈèàÂàÜÊûê‰∏≠ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÂåÖÊã¨ÈñãÁôº‰∫Ü‰∏ÄÂÄãÈáùÂ∞çÂúüÊú®Â∑•Á®ãÈÉ®ÈñÄÁöÑ‰æõÊáâÈèàÂúñÔºå‰ª•Âèä‰∏ÄÂÄãÂæÆË™øÈÅéÁöÑ LLM Ê®°ÂûãÔºåÂÆÉÂ¢ûÂº∑‰∫ÜÂØ¶È´îÂàÜÈ°ûÂíåÂ∞ç‰æõÊáâÈèàÁ∂≤Ë∑ØÁöÑ‰∫ÜËß£„ÄÇ

##### **Learning Representations for Reasoning: Generalizing Across Diverse Structures**
2410.13018v1 by Zhaocheng Zhu

Reasoning, the ability to logically draw conclusions from existing knowledge,
is a hallmark of human. Together with perception, they constitute the two major
themes of artificial intelligence. While deep learning has pushed the limit of
perception beyond human-level performance, the progress in reasoning domains is
way behind. One fundamental reason is that reasoning problems usually have
flexible structures for both knowledge and queries, and many existing models
only perform well on structures seen during training. Here we aim to push the
boundary of reasoning models by devising algorithms that generalize across
knowledge and query structures, as well as systems that accelerate development
on structured data. This thesis consists of three parts. In Part I, we study
models that can inductively generalize to unseen knowledge graphs with new
entity and relation vocabularies. For new entities, we propose a framework that
learns neural operators in a dynamic programming algorithm computing path
representations. For relations, we construct a relation graph to capture the
interactions between relations, thereby converting new relations into new
entities. In Part II, we propose two solutions for generalizing across
multi-step queries on knowledge graphs and text respectively. For knowledge
graphs, we show that multi-step queries can be solved by multiple calls of
graph neural networks and fuzzy logic operations. For text, we devise an
algorithm to learn explicit knowledge as textual rules to improve large
language models on multi-step queries. In Part III, we propose two systems to
facilitate machine learning development on structured data. Our library treats
structured data as first-class citizens and removes the barrier for developing
algorithms on structured data. Our node embedding system solves the GPU memory
bottleneck of embedding matrices and scales to graphs with billion nodes.

ÊëòË¶ÅÔºö<paragraph>Êé®ÁêÜÔºåÂæûÁèæÊúâÁü•Ë≠ò‰∏≠ÈÇèËºØÂú∞ÂæóÂá∫ÁµêË´ñÁöÑËÉΩÂäõÔºåÊòØ‰∫∫È°ûÁöÑÊ®ôË™å„ÄÇÂÆÉÂÄëËàáÊÑüÁü•‰∏ÄËµ∑ÊßãÊàê‰∫∫Â∑•Êô∫ÊÖßÁöÑÂÖ©ÂÄã‰∏ªË¶Å‰∏ªÈ°å„ÄÇÂÑòÁÆ°Ê∑±Â∫¶Â≠∏ÁøíÂ∑≤Â∞áÊÑüÁü•ÁöÑÊ•µÈôêÊé®Ëá≥Ë∂ÖË∂ä‰∫∫È°ûÂ±§Á¥öÁöÑË°®ÁèæÔºå‰ΩÜÊé®ÁêÜÈ†òÂüüÁöÑÈÄ≤Â±ïÂçªÈÅ†ÈÅ†ËêΩÂæå„ÄÇ‰∏ÄÂÄãÂü∫Êú¨ÂéüÂõ†ÊòØÊé®ÁêÜÂïèÈ°åÈÄöÂ∏∏Â∞çÁü•Ë≠òÂíåÊü•Ë©¢ÈÉΩÊúâÈùàÊ¥ªÁöÑÁµêÊßãÔºåËÄåË®±Â§öÁèæÊúâÊ®°ÂûãÂè™Âú®Ë®ìÁ∑¥ÊúüÈñìÁúãÂà∞ÁöÑÁµêÊßã‰∏≠Ë°®ÁèæËâØÂ•Ω„ÄÇÂú®ÈÄôË£°ÔºåÊàëÂÄëÊó®Âú®ÈÄöÈÅéË®≠Ë®àË∑®Áü•Ë≠òÂíåÊü•Ë©¢ÁµêÊßãÈÄ≤Ë°åÊ¶ÇÊã¨ÁöÑÊºîÁÆóÊ≥ïÔºå‰ª•ÂèäÂä†ÈÄüÁµêÊßãÂåñË≥áÊñôÈñãÁôºÁöÑÁ≥ªÁµ±Ôºå‰æÜÊé®ÂãïÊé®ÁêÜÊ®°ÂûãÁöÑÁïåÈôê„ÄÇÊú¨Ë´ñÊñáÂàÜÁÇ∫‰∏âÈÉ®ÂàÜ„ÄÇÂú®Á¨¨‰∏ÄÈÉ®ÂàÜÔºåÊàëÂÄëÁ†îÁ©∂ÂèØ‰ª•Ê≠∏Á¥çÊ¶ÇÊã¨Âà∞ÂÖ∑ÊúâÊñ∞ÂØ¶È´îÂíåÈóú‰øÇË©ûÂΩôÁöÑÊñ∞Áü•Ë≠òÂúñË°®ÁöÑÊ®°Âûã„ÄÇÂ∞çÊñºÊñ∞ÂØ¶È´îÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂú®ÂãïÊÖãË¶èÂäÉÊºîÁÆóÊ≥ï‰∏≠Â≠∏ÁøíÁ•ûÁ∂ìÈÅãÁÆóÂ≠êÁöÑÊ°ÜÊû∂ÔºåË®àÁÆóË∑ØÂæëË°®Á§∫„ÄÇÂ∞çÊñºÈóú‰øÇÔºåÊàëÂÄëÊßãÂª∫‰∏ÄÂÄãÈóú‰øÇÂúñ‰æÜÊçïÊçâÈóú‰øÇ‰πãÈñìÁöÑ‰∫íÂãïÔºåÂæûËÄåÂ∞áÊñ∞Èóú‰øÇËΩâÊèõÁÇ∫Êñ∞ÂØ¶È´î„ÄÇÂú®Á¨¨‰∫åÈÉ®ÂàÜÔºåÊàëÂÄëÊèêÂá∫ÂÖ©ÂÄãËß£Ê±∫ÊñπÊ°àÔºåÂàÜÂà•ÈáùÂ∞çÁü•Ë≠òÂúñË°®ÂíåÊñáÊú¨‰∏äÁöÑÂ§öÊ≠•È©üÊü•Ë©¢ÈÄ≤Ë°åÊ¶ÇÊã¨„ÄÇÂ∞çÊñºÁü•Ë≠òÂúñË°®ÔºåÊàëÂÄëË°®ÊòéÂ§öÊ≠•È©üÊü•Ë©¢ÂèØ‰ª•ÈÄöÈÅéÂ§öÊ¨°ÂëºÂè´ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÂíåÊ®°Á≥äÈÇèËºØÈÅãÁÆó‰æÜËß£Ê±∫„ÄÇÂ∞çÊñºÊñáÊú¨ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÁ®ÆÊºîÁÆóÊ≥ï‰æÜÂ≠∏ÁøíÊòéÁ¢∫ÁöÑÁü•Ë≠ò‰ΩúÁÇ∫ÊñáÊú¨Ë¶èÂâáÔºå‰ª•ÊîπÂñÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Â§öÊ≠•È©üÊü•Ë©¢‰∏äÁöÑË°®Áèæ„ÄÇÂú®Á¨¨‰∏âÈÉ®ÂàÜÔºåÊàëÂÄëÊèêÂá∫ÂÖ©ÂÄãÁ≥ªÁµ±Ôºå‰ª•‰øÉÈÄ≤ÁµêÊßãÂåñË≥áÊñô‰∏äÁöÑÊ©üÂô®Â≠∏ÁøíÈñãÁôº„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÂ∫´Â∞áÁµêÊßãÂåñË≥áÊñôË¶ñÁÇ∫‰∏ÄÁ¥öÂÖ¨Ê∞ëÔºå‰∏¶Ê∂àÈô§‰∫ÜÂú®ÁµêÊßãÂåñË≥áÊñô‰∏äÈñãÁôºÊºîÁÆóÊ≥ïÁöÑÈöúÁ§ô„ÄÇÊàëÂÄëÁöÑÁØÄÈªûÂµåÂÖ•Á≥ªÁµ±Ëß£Ê±∫‰∫ÜÂµåÂÖ•Áü©Èô£ÁöÑ GPU Ë®òÊÜ∂È´îÁì∂È†∏Ôºå‰∏¶Êì¥ÂÖÖÂà∞ÂÖ∑ÊúâÂçÅÂÑÑÂÄãÁØÄÈªûÁöÑÂúñË°®„ÄÇ</paragraph>

##### **Large Language Models as a Tool for Mining Object Knowledge**
2410.12959v1 by Hannah YoungEun An, Lenhart K. Schubert

Commonsense knowledge is essential for machines to reason about the world.
Large language models (LLMs) have demonstrated their ability to perform almost
human-like text generation. Despite this success, they fall short as
trustworthy intelligent systems, due to the opacity of the basis for their
answers and a tendency to confabulate facts when questioned about obscure
entities or technical domains. We hypothesize, however, that their general
knowledge about objects in the everyday world is largely sound. Based on that
hypothesis, this paper investigates LLMs' ability to formulate explicit
knowledge about common physical artifacts, focusing on their parts and
materials. Our work distinguishes between the substances that comprise an
entire object and those that constitute its parts$\unicode{x2014}$a previously
underexplored distinction in knowledge base construction. Using few-shot with
five in-context examples and zero-shot multi-step prompting, we produce a
repository of data on the parts and materials of about 2,300 objects and their
subtypes. Our evaluation demonstrates LLMs' coverage and soundness in
extracting knowledge. This contribution to knowledge mining should prove useful
to AI research on reasoning about object structure and composition and serve as
an explicit knowledge source (analogous to knowledge graphs) for LLMs
performing multi-hop question answering.

ÊëòË¶ÅÔºöÂ∏∏Ë≠òÁü•Ë≠òÂ∞çÊñºÊ©üÂô®Êé®ÁêÜ‰∏ñÁïåÊòØ‰∏çÂèØÊàñÁº∫ÁöÑ„ÄÇ
Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Á∂ìÂ±ïÁ§∫Âá∫ÂÆÉÂÄëÂü∑Ë°åÂπæ‰πéÂÉè‰∫∫È°û‰∏ÄÊ®£ÁöÑÊñáÂ≠óÁî¢ÁîüÁöÑËÉΩÂäõ„ÄÇÂÑòÁÆ°ÊúâÈÄôÊ®£ÁöÑÊàêÂäüÔºåÂÆÉÂÄë‰ΩúÁÇ∫ÂèØ‰ø°Ë≥¥ÁöÑÊô∫ÊÖßÁ≥ªÁµ±‰ªçÁÑ∂ÊúâÊâÄ‰∏çË∂≥ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁöÑÁ≠îÊ°àÂü∫Á§é‰∏çÈÄèÊòéÔºåËÄå‰∏îÂú®Ë¢´ÂïèÂèäÊ®°Á≥äÂØ¶È´îÊàñÊäÄË°ìÈ†òÂüüÊôÇÔºåÂÆÉÂÄëÊúâÊçèÈÄ†‰∫ãÂØ¶ÁöÑÂÇæÂêë„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÂÅáË®≠ÂÆÉÂÄëÂ∞çÊñºÊó•Â∏∏‰∏ñÁïå‰∏≠Áâ©È´îÁöÑ‰∏ÄËà¨Áü•Ë≠òÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊòØÂêàÁêÜÁöÑ„ÄÇÂü∫ÊñºË©≤ÂÅáË®≠ÔºåÊú¨ÊñáÊé¢Ë®é‰∫Ü LLM Â∞áÊó•Â∏∏Áâ©ÁêÜË£ΩÂìÅÁöÑÊòéÁ¢∫Áü•Ë≠òÂÖ¨ÂºèÂåñÁöÑËÉΩÂäõÔºåÈáçÈªûÈóúÊ≥®ÂÆÉÂÄëÁöÑÈõ∂‰ª∂ÂíåÊùêÊñô„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂçÄÂàÜ‰∫ÜÊßãÊàêÊï¥ÂÄãÁâ©È´îÁöÑÁâ©Ë≥™ÂíåÊßãÊàêÂÖ∂Èõ∂‰ª∂ÁöÑÁâ©Ë≥™ÔºåÈÄôÊòØ‰∏ÄÂÄãÁü•Ë≠òÂ∫´Âª∫Êßã‰∏≠‰ª•ÂâçÊú™ÊõæÊé¢Ë®éÈÅéÁöÑÂçÄÂà•„ÄÇ‰ΩøÁî®Â∞ëÊ¨°Â≠∏ÁøíÔºåÂåÖÊã¨‰∫îÂÄãÊÉÖÂ¢ÉÁØÑ‰æãÂíåÈõ∂Ê¨°Â≠∏ÁøíÂ§öÊ≠•È©üÊèêÁ§∫ÔºåÊàëÂÄëÁî¢Áîü‰∫Ü‰∏ÄÂÄãË≥áÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´Á¥Ñ 2,300 ÂÄãÁâ©È´îÂèäÂÖ∂Â≠êÈ°ûÂûãÁöÑÈõ∂‰ª∂ÂíåÊùêÊñô„ÄÇÊàëÂÄëÁöÑË©ï‰º∞Â±ïÁ§∫‰∫Ü LLM Âú®ÊèêÂèñÁü•Ë≠òÊñπÈù¢ÁöÑÊ∂µËìãÁØÑÂúçÂíåÂÅ•ÂÖ®ÊÄß„ÄÇÈÄôÂÄãÁü•Ë≠òÊåñÊéòÁöÑË≤¢ÁçªÂ∞çÊñº AI Á†îÁ©∂Êé®ÁêÜÁâ©È´îÁµêÊßãÂíåÁµÑÊàêÊáâË©≤ÊòØÊúâÁî®ÁöÑÔºå‰∏¶‰ΩúÁÇ∫ LLM Âü∑Ë°åÂ§öË∑≥ÂïèÈ°åËß£Á≠îÁöÑÊòéÁ¢∫Áü•Ë≠ò‰æÜÊ∫êÔºàÈ°û‰ººÊñºÁü•Ë≠òÂúñË≠úÔºâ„ÄÇ

##### **FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**
2410.12707v1 by Zhenheng Tang, Xueze Kang, Yiming Yin, Xinglin Pan, Yuxin Wang, Xin He, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Amelie Chi Zhou, Bo Li, Bingsheng He, Xiaowen Chu

To alleviate hardware scarcity in training large deep neural networks (DNNs),
particularly large language models (LLMs), we present FusionLLM, a
decentralized training system designed and implemented for training DNNs using
geo-distributed GPUs across different computing clusters or individual devices.
Decentralized training faces significant challenges regarding system design and
efficiency, including: 1) the need for remote automatic differentiation (RAD),
2) support for flexible model definitions and heterogeneous software, 3)
heterogeneous hardware leading to low resource utilization or the straggler
problem, and 4) slow network communication. To address these challenges, in the
system design, we represent the model as a directed acyclic graph of operators
(OP-DAG). Each node in the DAG represents the operator in the DNNs, while the
edge represents the data dependency between operators. Based on this design, 1)
users are allowed to customize any DNN without caring low-level operator
implementation; 2) we enable the task scheduling with the more fine-grained
sub-tasks, offering more optimization space; 3) a DAG runtime executor can
implement RAD withour requiring the consistent low-level ML framework versions.
  To enhance system efficiency, we implement a workload estimator and design an
OP-Fence scheduler to cluster devices with similar bandwidths together and
partition the DAG to increase throughput. Additionally, we propose an AdaTopK
compressor to adaptively compress intermediate activations and gradients at the
slowest communication links. To evaluate the convergence and efficiency of our
system and algorithms, we train ResNet-101 and GPT-2 on three real-world
testbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental
results demonstrate that our system and method can achieve 1.45 - 9.39x speedup
compared to baseline methods while ensuring convergence.

ÊëòË¶ÅÔºö<paragraph>ÁÇ∫‰∫ÜÊ∏õËºïË®ìÁ∑¥Â§ßÂûãÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) ÁöÑÁ°¨È´îÁü≠Áº∫ÂïèÈ°åÔºåÂ∞§ÂÖ∂ÊòØÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü FusionLLMÔºå‰∏ÄÂÄãÂàÜÊï£ÂºèË®ìÁ∑¥Á≥ªÁµ±ÔºåÂÖ∂Ë®≠Ë®àÂíåÂØ¶‰ΩúÊòØÁî®ÊñºË®ìÁ∑¥Ë∑®‰∏çÂêåÈÅãÁÆóÂè¢ÈõÜÊàñÂÄãÂà•Ë£ùÁΩÆÁöÑÂú∞ÁêÜÂàÜÊï£Âºè GPU ÁöÑ DNN„ÄÇÂàÜÊï£ÂºèË®ìÁ∑¥Âú®Á≥ªÁµ±Ë®≠Ë®àÂíåÊïàÁéáÊñπÈù¢Èù¢Ëá®ÈáçÂ§ßÊåëÊà∞ÔºåÂåÖÊã¨Ôºö1) ÈúÄË¶ÅÈÅ†Á´ØËá™ÂãïÂæÆÂàÜ (RAD)Ôºå2) ÊîØÊè¥ÂΩàÊÄßÁöÑÊ®°ÂûãÂÆöÁæ©ÂíåÁï∞Ë≥™ËªüÈ´îÔºå3) Áï∞Ë≥™Á°¨È´îÂ∞éËá¥Ë≥áÊ∫êÂà©Áî®Áéá‰ΩéÊàñËêΩÂæåÂïèÈ°åÔºå‰ª•Âèä 4) Á∂≤Ë∑ØÈÄöË®äÈÄüÂ∫¶ÊÖ¢„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÂú®Á≥ªÁµ±Ë®≠Ë®à‰∏≠ÔºåÊàëÂÄëÂ∞áÊ®°ÂûãË°®Á§∫ÁÇ∫‰∏ÄÂÄãÊúâÂêëÈùûÂæ™Áí∞Âúñ (OP-DAG) ÁöÑÈÅãÁÆóÂ≠ê„ÄÇDAG ‰∏≠ÁöÑÊØèÂÄãÁØÄÈªû‰ª£Ë°® DNN ‰∏≠ÁöÑÈÅãÁÆóÂ≠êÔºåËÄåÈÇäÁ∑£‰ª£Ë°®ÈÅãÁÆóÂ≠ê‰πãÈñìÁöÑË≥áÊñô‰æùË≥¥ÊÄß„ÄÇÂü∫ÊñºÊ≠§Ë®≠Ë®àÔºå1) ‰ΩøÁî®ËÄÖÂèØ‰ª•Ëá™Ë®Ç‰ªª‰Ωï DNNÔºåËÄå‰∏çÁî®ËÄÉÊÖÆ‰ΩéÈöéÈÅãÁÆóÂ≠êÂØ¶‰ΩúÔºõ2) ÊàëÂÄëÂïüÁî®‰ªªÂãôÊéíÁ®ãÔºå‰∏¶‰ΩøÁî®Êõ¥Á¥∞Á∑ªÁöÑÂ≠ê‰ªªÂãôÔºåÊèê‰æõÊõ¥Â§öÊúÄ‰Ω≥ÂåñÁ©∫ÈñìÔºõ3) DAG Âü∑Ë°åÊôÇÈñìÂü∑Ë°åÂô®ÂèØ‰ª•ÂØ¶‰Ωú RADÔºåËÄå‰∏çÈúÄË¶Å‰∏ÄËá¥ÁöÑ‰ΩéÈöé ML Êû∂ÊßãÁâàÊú¨„ÄÇÁÇ∫‰∫ÜÊèêÂçáÁ≥ªÁµ±ÊïàÁéáÔºåÊàëÂÄëÂØ¶‰Ωú‰∏ÄÂÄãÂ∑•‰ΩúË≤†Ëºâ‰º∞Ë®àÂô®Ôºå‰∏¶Ë®≠Ë®à‰∏ÄÂÄã OP-Fence ÊéíÁ®ãÂô®ÔºåÂ∞áÈ†ªÂØ¨È°û‰ººÁöÑË£ùÁΩÆÂàÜÁµÑÂú®‰∏ÄËµ∑Ôºå‰∏¶ÂàÜÂâ≤ DAG ‰ª•Â¢ûÂä†ËôïÁêÜÈáè„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã AdaTopK Â£ìÁ∏ÆÂô®Ôºå‰ª•Ëá™ÈÅ©ÊáâÊñπÂºèÂ£ìÁ∏ÆÊúÄÊÖ¢ÈÄöË®äÈÄ£Áµê‰∏äÁöÑ‰∏≠ÈñìÂïüÂãïÂíåÊ¢ØÂ∫¶„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÊàëÂÄëÁ≥ªÁµ±ÂíåÊºîÁÆóÊ≥ïÁöÑÊî∂ÊñÇÊÄßÂíåÊïàÁéáÔºåÊàëÂÄëÂú®‰∏âÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑÊ∏¨Ë©¶Âπ≥Âè∞‰∏äË®ìÁ∑¥ ResNet-101 Âíå GPT-2Ôºå‰ΩøÁî® 48 ÂÄã GPU ÈÄ£Êé•Âà∞ 8 Mbps~10 Gbps Á∂≤Ë∑Ø„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±ÂíåÊñπÊ≥ïÂèØ‰ª•ÊØîÂü∫Ê∫ñÊñπÊ≥ïÂø´ 1.45 - 9.39 ÂÄçÔºåÂêåÊôÇÁ¢∫‰øùÊî∂ÊñÇ„ÄÇ</paragraph>

##### **The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph**
2410.12458v1 by Minghao Wu, Thuy-Trang Vu, Lizhen Qu, Gholamreza Haffari

The performance of large language models (LLMs) in natural language
processing (NLP) tasks is significantly influenced by the quality and diversity
of data used for supervised fine-tuning (SFT). Current data selection methods
often focus solely on quality or diversity, leading to underperforming models
due to suboptimal training data. In this paper, we introduce GraphFilter, a
novel method that represents the dataset as a bipartite graph, linking
sentences to their constituent n-grams. This representation effectively
captures the relationships between sentences and linguistic patterns,
facilitating the selection of sentences that enhance n-gram diversity. To
balance quality and diversity during selection, we propose a priority function
that combines the quality metric with the diversity metric in a multiplicative
manner. GraphFilter iteratively selects high-priority sentences, updates the
bipartite graph by removing covered n-grams, and re-calculates priorities to
reflect the evolving data landscape. We conduct extensive experiments using
three model backbones across six widely used benchmarks. The results
demonstrate that GraphFilter outperforms all nine baseline approaches,
achieving superior model performance and computational efficiency. Our analyses
validate the effectiveness of our design choices, examine the subsets selected
by GraphFilter and other methods, highlight the importance of instruction
diversity, and explore the role of quality and diversity in relation to subset
sizes. GraphFilter establishes a new foundation for effective data selection
strategies, encouraging further research in data selection for LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãô‰∏≠ÁöÑË°®ÁèæÔºåÂèóÂà∞Áî®ÊñºÁõ£Áù£ÂæÆË™ø (SFT) ÁöÑË≥áÊñôÂìÅË≥™ÂíåÂ§öÊ®£ÊÄßÈ°ØËëóÂΩ±Èüø„ÄÇÁõÆÂâçÁöÑË≥áÊñôÈÅ∏ÂèñÊñπÊ≥ïÈÄöÂ∏∏Âè™ÈóúÊ≥®ÂìÅË≥™ÊàñÂ§öÊ®£ÊÄßÔºåÂ∞éËá¥Ë®ìÁ∑¥Ë≥áÊñôÊ¨°‰Ω≥ÔºåÈÄ≤ËÄåÈÄ†ÊàêÊ®°ÂûãË°®Áèæ‰∏ç‰Ω≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π GraphFilterÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂÆÉÂ∞áË≥áÊñôÈõÜË°®Á§∫ÁÇ∫‰∫åÈÉ®ÂúñÔºåÂ∞áÂè•Â≠êÈÄ£ÁµêÂà∞ÂÖ∂ÁµÑÊàê n-gram„ÄÇÈÄôÁ®ÆË°®Á§∫ÊñπÂºèÊúâÊïàÊçïÊçâÂè•Â≠êÂíåË™ûË®ÄÊ®°Âºè‰πãÈñìÁöÑÈóú‰øÇÔºåÊúâÂä©ÊñºÈÅ∏ÊìáËÉΩÊèêÂçá n-gram Â§öÊ®£ÊÄßÁöÑÂè•Â≠ê„ÄÇÁÇ∫‰∫ÜÂú®ÈÅ∏ÂèñÈÅéÁ®ã‰∏≠Âπ≥Ë°°ÂìÅË≥™ÂíåÂ§öÊ®£ÊÄßÔºåÊàëÂÄëÊèêÂá∫ÂÑ™ÂÖàÂáΩÊï∏Ôºå‰ª•‰πòÊ≥ïÊñπÂºèÁµêÂêàÂìÅË≥™ÊåáÊ®ôÂíåÂ§öÊ®£ÊÄßÊåáÊ®ô„ÄÇGraphFilter Ëø≠‰ª£ÈÅ∏ÂèñÈ´òÂÑ™ÂÖàÁ¥öÂè•Â≠êÔºåÈÄèÈÅéÁßªÈô§Â∑≤Ê∂µËìã n-gram ‰æÜÊõ¥Êñ∞‰∫åÈÉ®ÂúñÔºå‰∏¶ÈáçÊñ∞Ë®àÁÆóÂÑ™ÂÖàÁ¥ö‰ª•ÂèçÊò†‰∏çÊñ∑ËÆäÂåñÁöÑË≥áÊñôÊ®£Ë≤å„ÄÇÊàëÂÄë‰ΩøÁî®‰∏âÂÄãÊ®°Âûã‰∏ªÂππÂú®ÂÖ≠ÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑÂü∫Ê∫ñ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©ó„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåGraphFilter ÂÑ™ÊñºÊâÄÊúâ‰πùÁ®ÆÂü∫Á∑öÊñπÊ≥ïÔºåÈÅîÂà∞ÂçìË∂äÁöÑÊ®°ÂûãÊïàËÉΩÂíåÈÅãÁÆóÊïàÁéá„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ©óË≠â‰∫ÜÊàëÂÄëË®≠Ë®àÈÅ∏ÊìáÁöÑÊúâÊïàÊÄßÔºåÊ™¢È©ó GraphFilter ÂíåÂÖ∂‰ªñÊñπÊ≥ïÈÅ∏ÂèñÁöÑÂ≠êÈõÜÔºåÂº∑Ë™øÊåá‰ª§Â§öÊ®£ÊÄßÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶Êé¢Ë®éÂìÅË≥™ÂíåÂ§öÊ®£ÊÄßËàáÂ≠êÈõÜÂ§ßÂ∞èÁöÑÈóú‰øÇ„ÄÇGraphFilter ÁÇ∫ÊúâÊïàÁöÑË≥áÊñôÈÅ∏ÂèñÁ≠ñÁï•Â•†ÂÆöÊñ∞ÁöÑÂü∫Á§éÔºåÈºìÂãµÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ LLM ÁöÑË≥áÊñôÈÅ∏Âèñ„ÄÇ

##### **PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking**
2410.12375v1 by Markus J. Buehler

PRefLexOR (Preference-based Recursive Language Modeling for Exploratory
Optimization of Reasoning) combines preference optimization with concepts from
Reinforcement Learning to enable models to self-teach through iterative
reasoning improvements. We propose a recursive learning approach that engages
the model in multi-step reasoning, revisiting, and refining intermediate steps
before producing a final output in training and inference phases. Through
multiple training stages, the model first learns to align its reasoning with
accurate decision paths by optimizing the log odds between preferred and
non-preferred responses. During this process, PRefLexOR builds a dynamic
knowledge graph by generating questions from random text chunks and
retrieval-augmentation to contextualize relevant details from the entire
training corpus. In the second stage, preference optimization enhances model
performance by using rejection sampling to fine-tune reasoning quality by
continually producing in-situ training data while masking the reasoning steps.
Recursive optimization within a thinking token framework introduces iterative
feedback loops, where the model refines reasoning, achieving deeper coherence,
consistency, and adaptability. Implemented in small language models with only 3
billion parameters, we should that even tiny models can iteratively teach
themselves to reason with greater depth and reflectivity. Our implementation is
straightforward and can be incorporated into any existing pretrained LLM. We
focus our examples on applications in biological materials science and
demonstrate the method in a variety of case studies that range from in-domain
to cross-domain applications. Using reasoning strategies that include thinking
and reflection modalities we build a multi-agent recursive self-improving
inference approach to successively improve responses via repeated sampling in
inference time.

ÊëòË¶ÅÔºöPRefLexORÔºàÁî®ÊñºÊé¢Á¥¢ÊÄßÊé®ÁêÜÂÑ™ÂåñÁöÑÂü∫ÊñºÂÅèÂ•ΩÁöÑÈÅûËø¥Ë™ûË®ÄÂª∫Ê®°ÔºâÂ∞áÂÅèÂ•ΩÂÑ™ÂåñËàáÂº∑ÂåñÂ≠∏Áøí‰∏≠ÁöÑÊ¶ÇÂøµÁõ∏ÁµêÂêàÔºå‰ΩøÊ®°ÂûãËÉΩÂ§†ÈÄöÈÅéÂèçË¶ÜÊé®ÁêÜÊîπÈÄ≤‰æÜËá™ÊàëÊïôÂ≠∏„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈÅûËø¥Â≠∏ÁøíÊñπÊ≥ïÔºåËÆìÊ®°ÂûãÂèÉËàáÂ§öÊ≠•È©üÊé®ÁêÜ„ÄÅÈáçÊñ∞ÂØ©Ë¶ñÂíåÊîπÈÄ≤‰∏≠ÈñìÊ≠•È©üÔºåÁÑ∂ÂæåÂú®Ë®ìÁ∑¥ÂíåÊé®ÁêÜÈöéÊÆµÁî¢ÁîüÊúÄÁµÇËº∏Âá∫„ÄÇÈÄöÈÅéÂ§öÂÄãË®ìÁ∑¥ÈöéÊÆµÔºåÊ®°ÂûãÈ¶ñÂÖàÂ≠∏ÁøíÈÄöÈÅéÂÑ™ÂåñÈ¶ñÈÅ∏ÂíåÈùûÈ¶ñÈÅ∏ÈüøÊáâ‰πãÈñìÁöÑÂ∞çÊï∏ÂπæÁéáÔºå‰ΩøÂÖ∂Êé®ÁêÜËàáÊ∫ñÁ¢∫ÁöÑÊ±∫Á≠ñË∑ØÂæë‰øùÊåÅ‰∏ÄËá¥„ÄÇÂú®Ê≠§ÈÅéÁ®ã‰∏≠ÔºåPRefLexOR ÈÄöÈÅéÂæûÈö®Ê©üÊñáÊú¨Â°äÁîüÊàêÂïèÈ°åÂíåÊ™¢Á¥¢Â¢ûÂº∑‰æÜÊßãÂª∫‰∏ÄÂÄãÂãïÊÖãÁü•Ë≠òÂúñÔºåÂæûÊï¥ÂÄãË®ìÁ∑¥Ë™ûÊñôÂ∫´‰∏≠ÊèêÂèñÁõ∏ÈóúÁ¥∞ÁØÄ‰ª•ÈÄ≤Ë°åË™ûÂ¢ÉÂåñ„ÄÇÂú®Á¨¨‰∫åÈöéÊÆµÔºåÂÅèÂ•ΩÂÑ™ÂåñÈÄöÈÅé‰ΩøÁî®ÊãíÁµïÊé°Ê®£‰æÜÂæÆË™øÊé®ÁêÜË≥™ÈáèÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÊÄßËÉΩÔºåÂêåÊôÇÈÄ£Á∫åÁî¢ÁîüÂéü‰ΩçË®ìÁ∑¥Êï∏ÊìöÔºåÂêåÊôÇÊé©ËìãÊé®ÁêÜÊ≠•È©ü„ÄÇÂú®ÊÄùËÄÉ‰ª§ÁâåÊ°ÜÊû∂ÂÖßÈÄ≤Ë°åÈÅûËø¥ÂÑ™ÂåñÊúÉÂºïÂÖ•Ëø≠‰ª£ÂèçÈ•ãËø¥Ë∑ØÔºåÂÖ∂‰∏≠Ê®°ÂûãÊúÉÊîπÈÄ≤Êé®ÁêÜÔºåÂæûËÄåÂØ¶ÁèæÊõ¥Ê∑±ÂÖ•ÁöÑÈÄ£Ë≤´ÊÄß„ÄÅ‰∏ÄËá¥ÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇÂú®Âè™Êúâ 30 ÂÑÑÂÄãÂèÉÊï∏ÁöÑÂ∞èË™ûË®ÄÊ®°Âûã‰∏≠ÂØ¶ÁèæÔºåÊàëÂÄëÊáâË©≤ËÆìÂç≥‰ΩøÊòØÂæàÂ∞èÁöÑÊ®°Âûã‰πüËÉΩÈÄöÈÅéËø≠‰ª£ÁöÑÊñπÂºèÊïôÊúÉËá™Â∑±‰ª•Êõ¥Â§ßÁöÑÊ∑±Â∫¶ÂíåÂèçÊÄùËÉΩÂäõÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÊàëÂÄëÁöÑÂØ¶ÁèæÈùûÂ∏∏Áõ¥Êé•ÔºåÂèØ‰ª•Êï¥ÂêàÂà∞‰ªª‰ΩïÁèæÊúâÁöÑÈ†êË®ìÁ∑¥ LLM ‰∏≠„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÁ§∫‰æãÈáçÈªûÊîæÂú®ÁîüÁâ©ÊùêÊñôÁßëÂ≠∏ÊáâÁî®‰∏äÔºå‰∏¶Âú®ÂæûÂüüÂÖßÂà∞Ë∑®ÂüüÊáâÁî®Á≠âÂêÑÁ®ÆÊ°à‰æãÁ†îÁ©∂‰∏≠ÊºîÁ§∫‰∫ÜË©≤ÊñπÊ≥ï„ÄÇ‰ΩøÁî®ÂåÖÊã¨ÊÄùËÄÉÂíåÂèçÊÄùÊ®°ÂºèÂú®ÂÖßÁöÑÊé®ÁêÜÁ≠ñÁï•ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂ§ö‰ª£ÁêÜÈÅûËø¥Ëá™ÊàëÊîπÈÄ≤Êé®ÁêÜÊñπÊ≥ïÔºå‰ª•ÈÄöÈÅéÂú®Êé®ÁêÜÊôÇÈñìÈáçË§áÊé°Ê®£‰æÜÈÄ£Á∫åÊîπÈÄ≤ÈüøÊáâ„ÄÇ

##### **Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs**
2410.12298v2 by Lei Sun, Xinchen Wang, Youdi Li

Large Language Models (LLMs) possess impressive reasoning abilities but are
prone to generating incorrect information, often referred to as hallucinations.
While incorporating external Knowledge Graphs (KGs) can partially mitigate this
issue, existing methods primarily treat KGs as static knowledge repositories,
overlooking the critical disparity between KG and LLM knowledge, and failing to
fully exploit the reasoning capabilities inherent in KGs. To address these
limitations, we propose Pyramid-Driven Alignment (PDA), a novel framework for
seamlessly integrating LLMs with KGs. PDA utilizes Pyramid Principle analysis
to construct a hierarchical pyramid structure. This structure is designed to
reflect the input question and generate more validated deductive knowledge,
thereby enhancing the alignment of LLMs and KGs and ensuring more cohesive
integration. Furthermore, PDA employs a recursive mechanism to harness the
underlying reasoning abilities of KGs, resulting in more accurate knowledge
retrieval for question-answering tasks. Our experimental results reveal a
substantial performance advantage of PDA over state-of-the-art baselines, with
improvements reaching 26.70% and 26.78%.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊìÅÊúâ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ΩÜÂÆπÊòìÁî¢Áîü‰∏çÊ≠£Á¢∫ÁöÑË≥áË®äÔºåÈÄöÂ∏∏Á®±ÁÇ∫ÂπªË¶∫„ÄÇ
ÂÑòÁÆ°ÁµêÂêàÂ§ñÈÉ®Áü•Ë≠òÂúñË≠ú (KG) ÂèØ‰ª•ÈÉ®ÂàÜÁ∑©Ëß£ÈÄôÂÄãÂïèÈ°åÔºå‰ΩÜÁèæÊúâÊñπÊ≥ï‰∏ªË¶ÅÂ∞á KG Ë¶ñÁÇ∫ÈùúÊÖãÁü•Ë≠òÂÑ≤Â≠òÂ∫´ÔºåÂøΩË¶ñ KG Âíå LLM Áü•Ë≠ò‰πãÈñìÁöÑÈóúÈçµÂ∑ÆÁï∞Ôºå‰∏¶‰∏îÊú™ËÉΩÂÖÖÂàÜÂà©Áî® KG ‰∏≠Âõ∫ÊúâÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫ÈáëÂ≠óÂ°îÈ©ÖÂãïÂ∞çÈΩä (PDA)ÔºåÈÄôÊòØ‰∏ÄÂÄãÂ∞á LLM Ëàá KG ÁÑ°Á∏´Êï¥ÂêàÁöÑÊñ∞Á©éÊû∂Êßã„ÄÇPDA Âà©Áî®ÈáëÂ≠óÂ°îÂéüÂâáÂàÜÊûê‰æÜÂª∫Êßã‰∏ÄÂÄãÈöéÂ±§ÂºèÈáëÂ≠óÂ°îÁµêÊßã„ÄÇÊ≠§ÁµêÊßãÊó®Âú®ÂèçÊò†Ëº∏ÂÖ•ÂïèÈ°å‰∏¶Áî¢ÁîüÊõ¥Â§öÁ∂ìÈÅéÈ©óË≠âÁöÑÊºîÁππÁü•Ë≠òÔºåÂæûËÄåÂ¢ûÂº∑ LLM Âíå KG ÁöÑÂ∞çÈΩäÔºå‰∏¶Á¢∫‰øùÊõ¥Á∑äÂØÜÁöÑÊï¥Âêà„ÄÇÊ≠§Â§ñÔºåPDA Êé°Áî®ÈÅûËø¥Ê©üÂà∂‰æÜÂà©Áî® KG ÁöÑÂ∫ïÂ±§Êé®ÁêÜËÉΩÂäõÔºåÂæûËÄåÊõ¥Ê∫ñÁ¢∫Âú∞Ê™¢Á¥¢Áü•Ë≠ò‰ª•ÈÄ≤Ë°åÂïèÁ≠î‰ªªÂãô„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåPDA Áõ∏ËºÉÊñºÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÔºåÂÖ∑ÊúâÈ°ØËëóÁöÑÊïàËÉΩÂÑ™Âã¢ÔºåÊîπÈÄ≤ÂπÖÂ∫¶ÈÅîÂà∞ 26.70% Âíå 26.78%„ÄÇ

##### **LLM-based Cognitive Models of Students with Misconceptions**
2410.12294v2 by Shashank Sonkar, Xinghe Chen, Naiming Liu, Richard G. Baraniuk, Mrinmaya Sachan

Accurately modeling student cognition is crucial for developing effective
AI-driven educational technologies. A key challenge is creating realistic
student models that satisfy two essential properties: (1) accurately
replicating specific misconceptions, and (2) correctly solving problems where
these misconceptions are not applicable. This dual requirement reflects the
complex nature of student understanding, where misconceptions coexist with
correct knowledge. This paper investigates whether Large Language Models (LLMs)
can be instruction-tuned to meet this dual requirement and effectively simulate
student thinking in algebra. We introduce MalAlgoPy, a novel Python library
that generates datasets reflecting authentic student solution patterns through
a graph-based representation of algebraic problem-solving. Utilizing MalAlgoPy,
we define and examine Cognitive Student Models (CSMs) - LLMs instruction tuned
to faithfully emulate realistic student behavior. Our findings reveal that LLMs
trained on misconception examples can efficiently learn to replicate errors.
However, the training diminishes the model's ability to solve problems
correctly, particularly for problem types where the misconceptions are not
applicable, thus failing to satisfy second property of CSMs. We demonstrate
that by carefully calibrating the ratio of correct to misconception examples in
the training data - sometimes as low as 0.25 - it is possible to develop CSMs
that satisfy both properties. Our insights enhance our understanding of
AI-based student models and pave the way for effective adaptive learning
systems.

ÊëòË¶ÅÔºöÊ∫ñÁ¢∫Âú∞Ê®°Êì¨Â≠∏ÁîüÁöÑË™çÁü•Â∞çÊñºÈñãÁôºÊúâÊïàÁöÑ AI È©ÖÂãïÊïôËÇ≤ÊäÄË°ìËá≥ÈóúÈáçË¶Å„ÄÇ‰∏ÄÂÄã‰∏ªË¶ÅÁöÑÊåëÊà∞ÊòØÂª∫Á´ãÁ¨¶ÂêàÂÖ©ÂÄãÂü∫Êú¨Â±¨ÊÄßÁöÑÈÄºÁúüÁöÑÂ≠∏ÁîüÊ®°ÂûãÔºö(1) Ê∫ñÁ¢∫Âú∞Ë§áË£ΩÁâπÂÆöÁöÑÈåØË™§ËßÄÂøµÔºå‰ª•Âèä (2) Ê≠£Á¢∫Ëß£Ê±∫ÈÄô‰∫õÈåØË™§ËßÄÂøµ‰∏çÈÅ©Áî®ÁöÑÂïèÈ°å„ÄÇÈÄôÂÄãÈõôÈáçÈúÄÊ±ÇÂèçÊò†‰∫ÜÂ≠∏ÁîüÁêÜËß£ÁöÑË§áÈõúÊÄßÔºåÂÖ∂‰∏≠ÈåØË™§ËßÄÂøµËàáÊ≠£Á¢∫Áü•Ë≠ò‰∏¶Â≠ò„ÄÇÊú¨ÊñáÊé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊòØÂê¶ÂèØ‰ª•ÈáùÂ∞çÊåá‰ª§ÈÄ≤Ë°åË™øÊï¥‰ª•ÊªøË∂≥ÈÄôÂÄãÈõôÈáçÈúÄÊ±ÇÔºå‰∏¶ÊúâÊïàÂú∞Ê®°Êì¨Â≠∏ÁîüÂú®‰ª£Êï∏‰∏≠ÁöÑÊÄùËÄÉ„ÄÇÊàëÂÄë‰ªãÁ¥π MalAlgoPyÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑ Python ÂáΩÂºèÂ∫´ÔºåÂÆÉÈÄèÈÅé‰ª£Êï∏ÂïèÈ°åËß£Ê±∫ÁöÑÂúñÂΩ¢ÂåñË°®Á§∫Ê≥ïÁîüÊàêÂèçÊò†ÁúüÂØ¶Â≠∏ÁîüËß£È°åÊ®°ÂºèÁöÑË≥áÊñôÈõÜ„ÄÇÂà©Áî® MalAlgoPyÔºåÊàëÂÄëÂÆöÁæ©‰∏¶Ê™¢Ë¶ñË™çÁü•Â≠∏ÁîüÊ®°Âûã (CSM) - ÈáùÂ∞çÊåá‰ª§Ë™øÊï¥ÁöÑ LLMÔºå‰ª•Âø†ÂØ¶Âú∞Ê®°Êì¨ÁèæÂØ¶Â≠∏ÁîüÁöÑË°åÁÇ∫„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÈáùÂ∞çÈåØË™§ËßÄÂøµÁØÑ‰æãË®ìÁ∑¥ÁöÑ LLM ÂèØ‰ª•ÊúâÊïàÂú∞Â≠∏ÁøíË§áË£ΩÈåØË™§„ÄÇÁÑ∂ËÄåÔºåË®ìÁ∑¥ÊúÉÈôç‰ΩéÊ®°ÂûãÊ≠£Á¢∫Ëß£Ê±∫ÂïèÈ°åÁöÑËÉΩÂäõÔºåÁâπÂà•ÊòØÂ∞çÊñºÈåØË™§ËßÄÂøµ‰∏çÈÅ©Áî®ÁöÑÂïèÈ°åÈ°ûÂûãÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÊªøË∂≥ CSM ÁöÑÁ¨¨‰∫åÂÄãÂ±¨ÊÄß„ÄÇÊàëÂÄëË≠âÊòéÔºåÈÄèÈÅé‰ªîÁ¥∞Ê†°Ê∫ñË®ìÁ∑¥Ë≥áÊñô‰∏≠Ê≠£Á¢∫ÁØÑ‰æãËàáÈåØË™§ËßÄÂøµÁØÑ‰æãÁöÑÊØî‰æã - ÊúâÊôÇ‰ΩéËá≥ 0.25 - ÂèØ‰ª•ÈñãÁôºÂêåÊôÇÊªøË∂≥ÂÖ©ÂÄãÂ±¨ÊÄßÁöÑ CSM„ÄÇÊàëÂÄëÁöÑË¶ãËß£Â¢ûÈÄ≤‰∫ÜÊàëÂÄëÂ∞çÂü∫Êñº AI ÁöÑÂ≠∏ÁîüÊ®°ÂûãÁöÑÁêÜËß£Ôºå‰∏¶ÁÇ∫ÊúâÊïàÁöÑËá™ÈÅ©ÊáâÂ≠∏ÁøíÁ≥ªÁµ±Èã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

##### **Comprehending Knowledge Graphs with Large Language Models for Recommender Systems**
2410.12229v1 by Ziqiang Cui, Yunpeng Weng, Xing Tang, Fuyuan Lyu, Dugang Liu, Xiuqiang He, Chen Ma

Recently, the introduction of knowledge graphs (KGs) has significantly
advanced recommender systems by facilitating the discovery of potential
associations between items. However, existing methods still face several
limitations. First, most KGs suffer from missing facts or limited scopes. This
can lead to biased knowledge representations, thereby constraining the model's
performance. Second, existing methods typically convert textual information
into IDs, resulting in the loss of natural semantic connections between
different items. Third, existing methods struggle to capture high-order
relationships in global KGs due to their inefficient layer-by-layer information
propagation mechanisms, which are prone to introducing significant noise. To
address these limitations, we propose a novel method called CoLaKG, which
leverages large language models (LLMs) for knowledge-aware recommendation. The
extensive world knowledge and remarkable reasoning capabilities of LLMs enable
them to supplement KGs. Additionally, the strong text comprehension abilities
of LLMs allow for a better understanding of semantic information. Based on
this, we first extract subgraphs centered on each item from the KG and convert
them into textual inputs for the LLM. The LLM then outputs its comprehension of
these item-centered subgraphs, which are subsequently transformed into semantic
embeddings. Furthermore, to utilize the global information of the KG, we
construct an item-item graph using these semantic embeddings, which can
directly capture higher-order associations between items. Both the semantic
embeddings and the structural information from the item-item graph are
effectively integrated into the recommendation model through our designed
representation alignment and neighbor augmentation modules. Extensive
experiments on four real-world datasets demonstrate the superiority of our
method.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÔºåÁü•Ë≠òÂúñË≠ú (KG) ÁöÑÂºïÂÖ•ÈÄèÈÅé‰øÉÈÄ≤È†ÖÁõÆ‰πãÈñìÊΩõÂú®ÈóúËÅØÁöÑÁôºÁèæÔºåÈ°ØËëóÊèêÂçáÊé®Ëñ¶Á≥ªÁµ±„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ï‰ªçÈù¢Ëá®ÂπæÂÄãÈôêÂà∂„ÄÇÈ¶ñÂÖàÔºåÂ§ßÂ§öÊï∏ KG ÈÉΩÂ≠òÂú®‰∫ãÂØ¶Áº∫Â§±ÊàñÁØÑÂúçÂèóÈôêÁöÑÂïèÈ°å„ÄÇÈÄôÂèØËÉΩÂ∞éËá¥ÊúâÂÅèÂ∑ÆÁöÑÁü•Ë≠òË°®ÂæµÔºåÈÄ≤ËÄåÈôêÂà∂Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇÂÖ∂Ê¨°ÔºåÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏ÊúÉÂ∞áÊñáÂ≠óË≥áË®äËΩâÊèõÁÇ∫ IDÔºåÂ∞éËá¥‰∏çÂêåÈ†ÖÁõÆ‰πãÈñìËá™ÁÑ∂Ë™ûÁæ©ÈÄ£ÁµêÁöÑÈÅ∫Â§±„ÄÇÁ¨¨‰∏âÔºåÁèæÊúâÊñπÊ≥ïÈõ£‰ª•ÊçïÊçâÂÖ®ÁêÉ KG ‰∏≠ÁöÑÈ´òÈöéÈóú‰øÇÔºåÂéüÂõ†Âú®ÊñºÂÖ∂‰ΩéÊïàÁéáÁöÑÈÄêÂ±§Ë≥áË®äÂÇ≥Êí≠Ê©üÂà∂ÂÆπÊòìÂºïÂÖ•È°ØËëóÈõúË®ä„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ CoLaKG ÁöÑÊñ∞ÊñπÊ≥ïÔºåÂÆÉÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÁü•Ë≠òÊÑüÁü•Êé®Ëñ¶„ÄÇLLM Âª£Ê≥õÁöÑ‰∏ñÁïåÁü•Ë≠òÂíåÂçìË∂äÁöÑÊé®ÁêÜËÉΩÂäõ‰ΩøÂÆÉÂÄëËÉΩÂ§†Ë£úÂÖÖ KG„ÄÇÊ≠§Â§ñÔºåLLM Âº∑Â§ßÁöÑÊñáÂ≠óÁêÜËß£ËÉΩÂäõÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞ÁêÜËß£Ë™ûÁæ©Ë≥áË®ä„ÄÇÂü∫ÊñºÊ≠§ÔºåÊàëÂÄëÈ¶ñÂÖàÂæû KG ‰∏≠Êì∑Âèñ‰ª•ÊØèÂÄãÈ†ÖÁõÆÁÇ∫‰∏≠ÂøÉÁöÑÂ≠êÂúñÔºå‰∏¶Â∞áÂÆÉÂÄëËΩâÊèõÁÇ∫ LLM ÁöÑÊñáÂ≠óËº∏ÂÖ•„ÄÇÁÑ∂ÂæåÔºåLLM ÊúÉËº∏Âá∫ÂÖ∂Â∞çÈÄô‰∫õ‰ª•È†ÖÁõÆÁÇ∫‰∏≠ÂøÉÁöÑÂ≠êÂúñÁöÑÁêÜËß£ÔºåÈÄô‰∫õÁêÜËß£Êé•ËëóÊúÉËΩâÊèõÁÇ∫Ë™ûÁæ©ÂµåÂÖ•„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÂà©Áî® KG ÁöÑÂÖ®ÁêÉË≥áË®äÔºåÊàëÂÄë‰ΩøÁî®ÈÄô‰∫õË™ûÁæ©ÂµåÂÖ•Âª∫Êßã‰∏ÄÂÄãÈ†ÖÁõÆ-È†ÖÁõÆÂúñÔºåÂÆÉÂèØ‰ª•Áõ¥Êé•ÊçïÊçâÈ†ÖÁõÆ‰πãÈñìÁöÑÈ´òÈöéÈóúËÅØ„ÄÇË™ûÁæ©ÂµåÂÖ•Âíå‰æÜËá™È†ÖÁõÆ-È†ÖÁõÆÂúñÁöÑÁµêÊßãË≥áË®äÈÉΩÊúÉÈÄèÈÅéÊàëÂÄëË®≠Ë®àÁöÑË°®ÂæµÊØîÂ∞çÂíåÈÑ∞ÂüüÊì¥ÂÖÖÊ®°ÁµÑÊúâÊïàÂú∞Êï¥ÂêàÂà∞Êé®Ëñ¶Ê®°Âûã‰∏≠„ÄÇÂú®ÂõõÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄß„ÄÇ</paragraph>

##### **Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations**
2410.12228v1 by Luyi Ma, Xiaohan Li, Zezhong Fan, Jianpeng Xu, Jason Cho, Praveen Kanumala, Kaushiki Nag, Sushant Kumar, Kannan Achan

Integrating diverse data modalities is crucial for enhancing the performance
of personalized recommendation systems. Traditional models, which often rely on
singular data sources, lack the depth needed to accurately capture the
multifaceted nature of item features and user behaviors. This paper introduces
a novel framework for multi-behavior recommendations, leveraging the fusion of
triple-modality, which is visual, textual, and graph data through alignment
with large language models (LLMs). By incorporating visual information, we
capture contextual and aesthetic item characteristics; textual data provides
insights into user interests and item features in detail; and graph data
elucidates relationships within the item-behavior heterogeneous graphs. Our
proposed model called Triple Modality Fusion (TMF) utilizes the power of LLMs
to align and integrate these three modalities, achieving a comprehensive
representation of user behaviors. The LLM models the user's interactions
including behaviors and item features in natural languages. Initially, the LLM
is warmed up using only natural language-based prompts. We then devise the
modality fusion module based on cross-attention and self-attention mechanisms
to integrate different modalities from other models into the same embedding
space and incorporate them into an LLM. Extensive experiments demonstrate the
effectiveness of our approach in improving recommendation accuracy. Further
ablation studies validate the effectiveness of our model design and benefits of
the TMF.

ÊëòË¶ÅÔºöÊï¥ÂêàÂêÑÁ®ÆË≥áÊñôÂûãÊÖãÂ∞çÊñºÊèêÂçáÂÄã‰∫∫ÂåñÊé®Ëñ¶Á≥ªÁµ±ÁöÑÊïàËÉΩËá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±Ê®°ÂûãÁ∂ìÂ∏∏‰æùË≥¥ÂñÆ‰∏ÄË≥áÊñô‰æÜÊ∫êÔºåÁº∫‰πèÊçïÊçâÈ†ÖÁõÆÁâπÂæµÂíå‰ΩøÁî®ËÄÖË°åÁÇ∫Â§öÈù¢ÂêëÊú¨Ë≥™ÊâÄÈúÄÁöÑÊ∑±Â∫¶„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÂ§öË°åÁÇ∫Êé®Ëñ¶Êû∂ÊßãÔºåÂà©Áî®Ë¶ñË¶∫„ÄÅÊñáÂ≠óÂíåÂúñÂΩ¢Ë≥áÊñôÁöÑ‰∏âÈáçÂûãÊÖãËûçÂêàÔºåÈÄèÈÅéËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞çÈΩä‰æÜÂØ¶Áèæ„ÄÇÈÄèÈÅéÁ¥çÂÖ•Ë¶ñË¶∫Ë≥áË®äÔºåÊàëÂÄëÊçïÊçâËÑàÁµ°ÂíåÁæéÂ≠∏È†ÖÁõÆÁâπÂæµÔºõÊñáÂ≠óË≥áÊñôË©≥Á¥∞Êèê‰æõ‰ΩøÁî®ËÄÖËààË∂£ÂíåÈ†ÖÁõÆÁâπÂæµÁöÑË¶ãËß£ÔºõÂúñÂΩ¢Ë≥áÊñôÈó°ÊòéÈ†ÖÁõÆË°åÁÇ∫Áï∞Ë≥™ÂúñÂΩ¢‰∏≠ÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÁ®±ÁÇ∫‰∏âÈáçÂûãÊÖãËûçÂêà (TMF)ÔºåÂà©Áî® LLM ÁöÑÂäõÈáè‰æÜÂ∞çÈΩäÂíåÊï¥ÂêàÈÄô‰∏âÁ®ÆÂûãÊÖãÔºåÈÅîÊàê‰ΩøÁî®ËÄÖË°åÁÇ∫ÁöÑÂÖ®Èù¢Ë°®Âæµ„ÄÇLLM ‰ª•Ëá™ÁÑ∂Ë™ûË®ÄÂª∫Ê®°‰ΩøÁî®ËÄÖÁöÑ‰∫íÂãïÔºåÂåÖÊã¨Ë°åÁÇ∫ÂíåÈ†ÖÁõÆÁâπÂæµ„ÄÇÊúÄÂàùÔºåLLM ÂÉÖ‰ΩøÁî®Âü∫ÊñºËá™ÁÑ∂Ë™ûË®ÄÁöÑÊèêÁ§∫ÈÄ≤Ë°åÁÜ±Ë∫´„ÄÇÁÑ∂ÂæåÊàëÂÄëÊ†πÊìö‰∫§ÂèâÊ≥®ÊÑèÂäõÂíåËá™ÊàëÊ≥®ÊÑèÂäõÊ©üÂà∂Ë®≠Ë®àÂûãÊÖãËûçÂêàÊ®°ÁµÑÔºåÂ∞á‰æÜËá™ÂÖ∂‰ªñÊ®°ÂûãÁöÑ‰∏çÂêåÂûãÊÖãÊï¥ÂêàÂà∞Áõ∏ÂêåÁöÑÂµåÂÖ•Á©∫ÈñìÔºå‰∏¶Â∞áÂÆÉÂÄëÁ¥çÂÖ• LLM„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÊèêÂçáÊé®Ëñ¶Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÊ∂àËûçÁ†îÁ©∂È©óË≠â‰∫ÜÊàëÂÄëÊ®°ÂûãË®≠Ë®àÁöÑÊúâÊïàÊÄß‰ª•Âèä TMF ÁöÑÂ•ΩËôï„ÄÇ

##### **Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning**
2410.12130v1 by Huiwen Wu, Xiaohan Li, Xiaogang Xu, Jiafei Wu, Deyi Zhang, Zhe Liu

The development of Large Language Models (LLMs) has significantly advanced
various AI applications in commercial and scientific research fields, such as
scientific literature summarization, writing assistance, and knowledge graph
construction. However, a significant challenge is the high risk of
hallucination during LLM inference, which can lead to security concerns like
factual inaccuracies, inconsistent information, and fabricated content. To
tackle this issue, it is essential to develop effective methods for reducing
hallucination while maintaining the original capabilities of the LLM. This
paper introduces a novel approach called Iterative Model-level Contrastive
Learning (Iter-AHMCL) to address hallucination. This method modifies the
representation layers of pre-trained LLMs by using contrastive `positive' and
`negative' models, trained on data with and without hallucinations. By
leveraging the differences between these two models, we create a more
straightforward pathway to eliminate hallucinations, and the iterative nature
of contrastive learning further enhances performance. Experimental validation
on four pre-trained foundation LLMs (LLaMA2, Alpaca, LLaMA3, and Qwen)
finetuning with a specially designed dataset shows that our approach achieves
an average improvement of 10.1 points on the TruthfulQA benchmark.
Comprehensive experiments demonstrate the effectiveness of Iter-AHMCL in
reducing hallucination while maintaining the general capabilities of LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁôºÂ±ïÂú®ÂïÜÊ•≠ÂíåÁßëÂ≠∏Á†îÁ©∂È†òÂüüÈ°ØËëóÊé®Âãï‰∫ÜÂêÑÁ®Æ AI ÊáâÁî®Ôºå‰æãÂ¶ÇÁßëÂ≠∏ÊñáÁçªÊëòË¶Å„ÄÅÂØ´‰ΩúËºîÂä©ÂíåÁü•Ë≠òÂúñË≠úÂª∫Êßã„ÄÇÁÑ∂ËÄåÔºå‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞ÊòØ LLM Êé®Ë´ñ‰∏≠ÂπªË¶∫ÁöÑÈ´òÈ¢®Èö™ÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥ÂÆâÂÖ®ÂïèÈ°åÔºå‰æãÂ¶Ç‰∫ãÂØ¶‰∏çÊ≠£Á¢∫„ÄÅË≥áË®ä‰∏ç‰∏ÄËá¥ÂíåÊçèÈÄ†ÂÖßÂÆπ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈñãÁôºÊúâÊïàÁöÑÊñπÊ≥ï‰æÜÊ∏õÂ∞ëÂπªË¶∫ÔºåÂêåÊôÇ‰øùÊåÅ LLM ÁöÑÂéüÂßãÂäüËÉΩËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ÂèçË¶ÜÊ®°ÂûãÂ±§Á¥öÂ∞çÊØîÂ≠∏Áøí (Iter-AHMCL) ÁöÑÊñ∞ÊñπÊ≥ï‰æÜËß£Ê±∫ÂπªË¶∫„ÄÇÊ≠§ÊñπÊ≥ïÈÄèÈÅé‰ΩøÁî®Â∞çÊØîÁöÑ„ÄåÊ≠£Âêë„ÄçÂíå„ÄåË≤†Âêë„ÄçÊ®°Âûã‰æÜ‰øÆÊîπÈ†êÂÖàË®ìÁ∑¥ÁöÑ LLM ÁöÑË°®Á§∫Â±§ÔºåÈÄô‰∫õÊ®°ÂûãÊòØÂú®ÊúâÂíåÊ≤íÊúâÂπªË¶∫ÁöÑË≥áÊñô‰∏äË®ìÁ∑¥ÁöÑ„ÄÇÈÄèÈÅéÂà©Áî®ÈÄôÂÖ©ÂÄãÊ®°Âûã‰πãÈñìÁöÑÂ∑ÆÁï∞ÔºåÊàëÂÄëÂâµÈÄ†‰∫Ü‰∏ÄÊ¢ùÊõ¥Áõ¥Êé•ÁöÑÈÄîÂæë‰æÜÊ∂àÈô§ÂπªË¶∫ÔºåËÄåÂ∞çÊØîÂ≠∏ÁøíÁöÑËø≠‰ª£ÊÄßË≥™ÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑‰∫ÜÊïàËÉΩ„ÄÇÂú®ÂõõÂÄãÈ†êÂÖàË®ìÁ∑¥ÁöÑÂü∫Á§é LLM (LLaMA2„ÄÅAlpaca„ÄÅLLaMA3 Âíå Qwen) ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÈ©óË≠âÔºå‰ΩøÁî®ÁâπÂà•Ë®≠Ë®àÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åÂæÆË™øÔºåÈ°ØÁ§∫ÊàëÂÄëÁöÑÂÅöÊ≥ïÂú® TruthfulQA Âü∫Ê∫ñ‰∏äÂπ≥ÂùáÊèêÂçá‰∫Ü 10.1 ÂàÜ„ÄÇÂÖ®Èù¢ÁöÑÂØ¶È©óË≠âÊòé‰∫Ü Iter-AHMCL Âú®Ê∏õÂ∞ëÂπªË¶∫ÁöÑÂêåÊôÇÔºåÁ∂≠ÊåÅ LLM ‰∏ÄËà¨ÂäüËÉΩÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning**
2410.12096v1 by Guangxin Su, Yifan Zhu, Wenjie Zhang, Hanchen Wang, Ying Zhang

Graph representation learning, involving both node features and graph
structures, is crucial for real-world applications but often encounters
pervasive noise. State-of-the-art methods typically address noise by focusing
separately on node features with large language models (LLMs) and on graph
structures with graph structure learning models (GSLMs). In this paper, we
introduce LangGSL, a robust framework that integrates the complementary
strengths of pre-trained language models and GSLMs to jointly enhance both node
feature and graph structure learning. In LangGSL, we first leverage LLMs to
filter noise in the raw data and extract valuable cleaned information as
features, enhancing the synergy of downstream models. During the mutual
learning phase in LangGSL, the core idea is to leverage the relatively small
language model (LM) to process local attributes and generate reliable
pseudo-labels and informative node embeddings, which are then integrated into
the GSLM's prediction phase. This approach enriches the global context and
enhances overall performance. Meanwhile, GSLM refines the evolving graph
structure constructed from the LM's output, offering updated labels back to the
LM as additional guidance, thus facilitating a more effective mutual learning
process. The LM and GSLM work synergistically, complementing each other's
strengths and offsetting weaknesses within a variational information-maximizing
framework, resulting in enhanced node features and a more robust graph
structure. Extensive experiments on diverse graph datasets of varying scales
and across different task scenarios demonstrate the scalability and
effectiveness of the proposed approach.

ÊëòË¶ÅÔºöÂúñË°®Ë°®Á§∫Â≠∏ÁøíÊó¢Ê∂âÂèäÁØÄÈªûÁâπÂæµÂèàÊ∂âÂèäÂúñÂΩ¢ÁµêÊßãÔºåÂ∞çÊñºÁèæÂØ¶‰∏ñÁïåÁöÑÊáâÁî®Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁ∂ìÂ∏∏ÊúÉÈÅáÂà∞ÊôÆÈÅçÁöÑÂô™Èü≥„ÄÇÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÈÄöÂ∏∏ÈÄöÈÅéÂàÜÂà•ÈóúÊ≥®ÂÖ∑ÊúâÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁØÄÈªûÁâπÂæµÂíåÂÖ∑ÊúâÂúñÂΩ¢ÁµêÊßãÂ≠∏ÁøíÊ®°Âûã (GSLM) ÁöÑÂúñÂΩ¢ÁµêÊßã‰æÜËß£Ê±∫Âô™Èü≥ÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü LangGSLÔºåÈÄôÊòØ‰∏ÄÂÄãÂº∑Â§ßÁöÑÊ°ÜÊû∂ÔºåÂÆÉÊï¥Âêà‰∫ÜÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÂíå GSLM ÁöÑ‰∫íË£úÂÑ™Âã¢Ôºå‰ª•ÂÖ±ÂêåÂ¢ûÂº∑ÁØÄÈªûÁâπÂæµÂíåÂúñÂΩ¢ÁµêÊßãÂ≠∏Áøí„ÄÇÂú® LangGSL ‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÂà©Áî® LLM ‰æÜÈÅéÊøæÂéüÂßãÊï∏Êìö‰∏≠ÁöÑÂô™Èü≥Ôºå‰∏¶ÊèêÂèñÊúâÂÉπÂÄºÁöÑÂ∑≤Ê∏ÖÁêÜ‰ø°ÊÅØ‰ΩúÁÇ∫ÁâπÂæµÔºåÂ¢ûÂº∑‰∏ãÊ∏∏Ê®°ÂûãÁöÑÂçîÂêå‰ΩúÁî®„ÄÇÂú® LangGSL ‰∏≠ÁöÑÁõ∏‰∫íÂ≠∏ÁøíÈöéÊÆµÔºåÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂà©Áî®Áõ∏Â∞çËºÉÂ∞èÁöÑË™ûË®ÄÊ®°Âûã (LM) ‰æÜËôïÁêÜÂ±ÄÈÉ®Â±¨ÊÄß‰∏¶ÁîüÊàêÂèØÈù†ÁöÑÂÅΩÊ®ôÁ±§Âíå‰ø°ÊÅØË±êÂØåÁöÑÁØÄÈªûÂµåÂÖ•ÔºåÁÑ∂ÂæåÂ∞áÂÆÉÂÄëÈõÜÊàêÂà∞ GSLM ÁöÑÈ†êÊ∏¨ÈöéÊÆµ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïË±êÂØå‰∫ÜÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰∏¶Â¢ûÂº∑‰∫ÜÊï¥È´îÊÄßËÉΩ„ÄÇÂêåÊôÇÔºåGSLM ÂÑ™Âåñ‰∫ÜÂæû LM Ëº∏Âá∫ÊßãÂª∫ÁöÑÊºîÂåñÂúñÂΩ¢ÁµêÊßãÔºåÂ∞áÊõ¥Êñ∞ÁöÑÊ®ôÁ±§‰ΩúÁÇ∫ÈôÑÂä†ÊåáÂ∞éÂèçÈ•ãÁµ¶ LMÔºåÂæûËÄå‰øÉÈÄ≤Êõ¥ÊúâÊïàÁöÑÁõ∏‰∫íÂ≠∏ÁøíÈÅéÁ®ã„ÄÇLM Âíå GSLM ÂçîÂêåÂ∑•‰ΩúÔºåÂú®ËÆäÂàÜ‰ø°ÊÅØÊúÄÂ§ßÂåñÊ°ÜÊû∂ÂÖß‰∫íË£úÂêÑËá™ÁöÑÂÑ™Âã¢‰∏¶ÂΩåË£úÂº±ÈªûÔºåÂæûËÄåÂ¢ûÂº∑ÁØÄÈªûÁâπÂæµ‰∏¶ÂΩ¢ÊàêÊõ¥Âº∑Â§ßÁöÑÂúñÂΩ¢ÁµêÊßã„ÄÇÂú®‰∏çÂêåË¶èÊ®°Âíå‰∏çÂêå‰ªªÂãôÂ†¥ÊôØÁöÑÂ§öÊ®£ÂåñÂúñÂΩ¢Êï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÂèØÊì¥Â±ïÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

##### **A Survey on Deep Tabular Learning**
2410.12034v1 by Shriyank Somvanshi, Subasish Das, Syed Aaqib Javed, Gian Antariksa, Ahmed Hossain

Tabular data, widely used in industries like healthcare, finance, and
transportation, presents unique challenges for deep learning due to its
heterogeneous nature and lack of spatial structure. This survey reviews the
evolution of deep learning models for tabular data, from early fully connected
networks (FCNs) to advanced architectures like TabNet, SAINT, TabTranSELU, and
MambaNet. These models incorporate attention mechanisms, feature embeddings,
and hybrid architectures to address tabular data complexities. TabNet uses
sequential attention for instance-wise feature selection, improving
interpretability, while SAINT combines self-attention and intersample attention
to capture complex interactions across features and data points, both advancing
scalability and reducing computational overhead. Hybrid architectures such as
TabTransformer and FT-Transformer integrate attention mechanisms with
multi-layer perceptrons (MLPs) to handle categorical and numerical data, with
FT-Transformer adapting transformers for tabular datasets. Research continues
to balance performance and efficiency for large datasets. Graph-based models
like GNN4TDL and GANDALF combine neural networks with decision trees or graph
structures, enhancing feature representation and mitigating overfitting in
small datasets through advanced regularization techniques. Diffusion-based
models like the Tabular Denoising Diffusion Probabilistic Model (TabDDPM)
generate synthetic data to address data scarcity, improving model robustness.
Similarly, models like TabPFN and Ptab leverage pre-trained language models,
incorporating transfer learning and self-supervised techniques into tabular
tasks. This survey highlights key advancements and outlines future research
directions on scalability, generalization, and interpretability in diverse
tabular data applications.

ÊëòË¶ÅÔºö<paragraph>Ë°®Ê†ºË≥áÊñôÂª£Ê≥õÊáâÁî®ÊñºÈÜ´ÁôÇ‰øùÂÅ•„ÄÅÈáëËûçÂíåÈÅãËº∏Á≠âÁî¢Ê•≠ÔºåÁî±ÊñºÂÖ∂Áï∞Ë≥™ÊÄß‰∏îÁº∫‰πèÁ©∫ÈñìÁµêÊßãÔºåÂõ†Ê≠§Â∞çÊ∑±Â∫¶Â≠∏ÁøíÊèêÂá∫‰∫ÜÁç®ÁâπÁöÑÊåëÊà∞„ÄÇÈÄôÈ†ÖË™øÊü•ÂõûÈ°ß‰∫ÜË°®Ê†ºË≥áÊñôÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊºîÈÄ≤ÔºåÂæûÊó©ÊúüÁöÑÂÖ®ÈÄ£Êé•Á∂≤Ë∑Ø (FCN) Âà∞ TabNet„ÄÅSAINT„ÄÅTabTranSELU Âíå MambaNet Á≠âÂÖàÈÄ≤Êû∂Êßã„ÄÇÈÄô‰∫õÊ®°ÂûãÁµêÂêà‰∫ÜÊ≥®ÊÑèÂäõÊ©üÂà∂„ÄÅÁâπÂæµÂµåÂÖ•ÂíåÊ∑∑ÂêàÊû∂ÊßãÔºå‰ª•Ëß£Ê±∫Ë°®Ê†ºË≥áÊñôÁöÑË§áÈõúÊÄß„ÄÇTabNet ‰ΩøÁî®Â∫èÂàóÊ≥®ÊÑèÂäõÈÄ≤Ë°åÈÄê‰æãÁâπÂæµÈÅ∏ÂèñÔºåÊèêÂçáÂèØËß£ÈáãÊÄßÔºåËÄå SAINT ÁµêÂêà‰∫ÜËá™ÊàëÊ≥®ÊÑèÂäõÂíåË∑®Ê®£Êú¨Ê≥®ÊÑèÂäõÔºå‰ª•ÊçïÊçâÁâπÂæµÂíåË≥áÊñôÈªû‰πãÈñìÁöÑË§áÈõú‰∫íÂãïÔºåÂêåÊôÇÊèêÂçáÂèØÊì¥ÂÖÖÊÄß‰∏¶Ê∏õÂ∞ëÈÅãÁÆóË≤†Êìî„ÄÇTabTransformer Âíå FT-Transformer Á≠âÊ∑∑ÂêàÊû∂ÊßãÂ∞áÊ≥®ÊÑèÂäõÊ©üÂà∂ËàáÂ§öÂ±§ÊÑüÁü•Âô® (MLP) Êï¥ÂêàÔºå‰ª•ËôïÁêÜÈ°ûÂà•Ë≥áÊñôÂíåÊï∏ÂÄºË≥áÊñôÔºåÂÖ∂‰∏≠ FT-Transformer Â∞á transformer ÈÅ©ÊáâÂà∞Ë°®Ê†ºË≥áÊñôÈõÜ„ÄÇÁ†îÁ©∂ÊåÅÁ∫åÂú®Â§ßÂûãË≥áÊñôÈõÜÁöÑÊïàËÉΩÂíåÊïàÁéá‰πãÈñìÂèñÂæóÂπ≥Ë°°„ÄÇÂü∫ÊñºÂúñÂΩ¢ÁöÑÊ®°ÂûãÔºå‰æãÂ¶Ç GNN4TDL Âíå GANDALFÔºåÂ∞áÁ•ûÁ∂ìÁ∂≤Ë∑ØËàáÊ±∫Á≠ñÊ®πÊàñÂúñÂΩ¢ÁµêÊßãÁµêÂêàÔºåÈÄèÈÅéÂÖàÈÄ≤ÁöÑÊ≠£ÂâáÂåñÊäÄË°ìÂ¢ûÂº∑ÁâπÂæµË°®Á§∫‰∏¶Ê∏õËºïÂ∞èË≥áÊñôÈõÜ‰∏≠ÁöÑÈÅéÂ∫¶Êì¨Âêà„ÄÇÂü∫ÊñºÊì¥Êï£ÁöÑÊ®°ÂûãÔºå‰æãÂ¶ÇË°®Ê†ºÂéªÂô™Êì¥Êï£Ê©üÁéáÊ®°Âûã (TabDDPM)ÔºåÊúÉÁî¢ÁîüÂêàÊàêË≥áÊñô‰ª•Ëß£Ê±∫Ë≥áÊñôÁ®ÄÂ∞ëÁöÑÂïèÈ°åÔºåÈÄ≤ËÄåÊèêÂçáÊ®°ÂûãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÈ°û‰ººÂú∞ÔºåTabPFN Âíå Ptab Á≠âÊ®°ÂûãÂà©Áî®È†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°ÂûãÔºåÂ∞áÈÅ∑ÁßªÂ≠∏ÁøíÂíåËá™ÊàëÁõ£Áù£ÊäÄË°ìËûçÂÖ•Ë°®Ê†º‰ªªÂãô‰∏≠„ÄÇÈÄôÈ†ÖË™øÊü•ÈáçÈªûË™™Êòé‰∫ÜÈóúÈçµÈÄ≤Â±ïÔºå‰∏¶Ê¶ÇËø∞‰∫ÜÂú®ÂêÑÁ®ÆË°®Ê†ºË≥áÊñôÊáâÁî®‰∏≠ÂèØÊì¥ÂÖÖÊÄß„ÄÅÊ¶ÇÊã¨ÊÄßÂíåÂèØËß£ÈáãÊÄßÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêë„ÄÇ</paragraph>

##### **Causal Reasoning in Large Language Models: A Knowledge Graph Approach**
2410.11588v1 by Yejin Kim, Eojin Kang, Juae Kim, H. Howie Huang

Large language models (LLMs) typically improve performance by either
retrieving semantically similar information, or enhancing reasoning abilities
through structured prompts like chain-of-thought. While both strategies are
considered crucial, it remains unclear which has a greater impact on model
performance or whether a combination of both is necessary. This paper answers
this question by proposing a knowledge graph (KG)-based random-walk reasoning
approach that leverages causal relationships. We conduct experiments on the
commonsense question answering task that is based on a KG. The KG inherently
provides both relevant information, such as related entity keywords, and a
reasoning structure through the connections between nodes. Experimental results
show that the proposed KG-based random-walk reasoning method improves the
reasoning ability and performance of LLMs. Interestingly, incorporating three
seemingly irrelevant sentences into the query using KG-based random-walk
reasoning enhances LLM performance, contrary to conventional wisdom. These
findings suggest that integrating causal structures into prompts can
significantly improve reasoning capabilities, providing new insights into the
role of causality in optimizing LLM performance.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄöÂ∏∏ÈÄèÈÅéÊì∑ÂèñË™ûÊÑè‰∏äÁõ∏‰ººÁöÑË≥áË®äÔºåÊàñÈÄèÈÅéÈèàÂºèÊÄùËÄÉÁ≠âÁµêÊßãÂåñÊèêÁ§∫Â¢ûÂº∑Êé®ÁêÜËÉΩÂäõÔºå‰æÜÊèêÂçáÊïàËÉΩ„ÄÇÂÑòÁÆ°ÈÄôÂÖ©Á®ÆÁ≠ñÁï•ÈÉΩË¢´Ë™çÁÇ∫Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁõÆÂâç‰ªç‰∏çÊ∏ÖÊ•öÂì™‰∏ÄÁ®ÆÂ∞çÊ®°ÂûãÊïàËÉΩÂΩ±ÈüøËºÉÂ§ßÔºåÊàñÊòØÂê¶ÈúÄË¶ÅÁµêÂêàÂÖ©ËÄÖ„ÄÇÊú¨ÊñáÈÄèÈÅéÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÁü•Ë≠òÂúñË≠ú (KG) ÁöÑÈö®Ê©üÊº´Ê≠•Êé®ÁêÜÊñπÊ≥ïÔºå‰æÜÂõûÁ≠îÈÄôÂÄãÂïèÈ°åÔºåÈÄôÂÄãÊñπÊ≥ïÂà©Áî®‰∫ÜÂõ†ÊûúÈóú‰øÇ„ÄÇÊàëÂÄëÂú®Âü∫Êñº KG ÁöÑÂ∏∏Ë≠òÂïèÁ≠î‰ªªÂãô‰∏äÈÄ≤Ë°åÂØ¶È©ó„ÄÇKG Êú¨Ë∫´Â∞±Êèê‰æõ‰∫ÜÁõ∏ÈóúË≥áË®äÔºå‰æãÂ¶ÇÁõ∏ÈóúÂØ¶È´îÈóúÈçµÂ≠óÔºå‰ª•ÂèäÈÄèÈÅéÁØÄÈªû‰πãÈñìÁöÑÈÄ£ÁµêÊèê‰æõÁöÑÊé®ÁêÜÁµêÊßã„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊèêÂá∫ÁöÑÂü∫Êñº KG ÁöÑÈö®Ê©üÊº´Ê≠•Êé®ÁêÜÊñπÊ≥ïÊîπÂñÑ‰∫Ü LLM ÁöÑÊé®ÁêÜËÉΩÂäõÂíåÊïàËÉΩ„ÄÇÊúâË∂£ÁöÑÊòØÔºåËàáÂÇ≥Áµ±ËßÄÂøµÁõ∏ÂèçÔºå‰ΩøÁî®Âü∫Êñº KG ÁöÑÈö®Ê©üÊº´Ê≠•Êé®ÁêÜÂ∞á‰∏âÂÄãÁúã‰ººÁÑ°ÈóúÁöÑÂè•Â≠êÁ¥çÂÖ•Êü•Ë©¢‰∏≠ÔºåÂèØ‰ª•ÊèêÂçá LLM ÁöÑÊïàËÉΩ„ÄÇÈÄô‰∫õÁôºÁèæË°®ÊòéÔºåÂ∞áÂõ†ÊûúÁµêÊßãÊï¥ÂêàÂà∞ÊèêÁ§∫‰∏≠ÂèØ‰ª•È°ØËëóÊèêÂçáÊé®ÁêÜËÉΩÂäõÔºå‰∏¶ÁÇ∫Âõ†ÊûúÈóú‰øÇÂú®ÊúÄ‰Ω≥Âåñ LLM ÊïàËÉΩ‰∏≠ÊâÄÊâÆÊºîÁöÑËßíËâ≤Êèê‰æõÊñ∞ÁöÑË¶ãËß£„ÄÇ

##### **Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development**
2410.11550v1 by Tengfei Ma, Xuan Lin, Tianle Li, Chaoyi Li, Long Chen, Peng Zhou, Xibao Cai, Xinyu Yang, Daojian Zeng, Dongsheng Cao, Xiangxiang Zeng

Large Language Models (LLMs) have recently demonstrated remarkable
performance in general tasks across various fields. However, their
effectiveness within specific domains such as drug development remains
challenges. To solve these challenges, we introduce \textbf{Y-Mol}, forming a
well-established LLM paradigm for the flow of drug development. Y-Mol is a
multiscale biomedical knowledge-guided LLM designed to accomplish tasks across
lead compound discovery, pre-clinic, and clinic prediction. By integrating
millions of multiscale biomedical knowledge and using LLaMA2 as the base LLM,
Y-Mol augments the reasoning capability in the biomedical domain by learning
from a corpus of publications, knowledge graphs, and expert-designed synthetic
data. The capability is further enriched with three types of drug-oriented
instructions: description-based prompts from processed publications,
semantic-based prompts for extracting associations from knowledge graphs, and
template-based prompts for understanding expert knowledge from biomedical
tools. Besides, Y-Mol offers a set of LLM paradigms that can autonomously
execute the downstream tasks across the entire process of drug development,
including virtual screening, drug design, pharmacological properties
prediction, and drug-related interaction prediction. Our extensive evaluations
of various biomedical sources demonstrate that Y-Mol significantly outperforms
general-purpose LLMs in discovering lead compounds, predicting molecular
properties, and identifying drug interaction events.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËøëÊúüÂú®ÂêÑÂÄãÈ†òÂüüÁöÑÈÄöÁî®‰ªªÂãô‰∏≠Â±ïÁ§∫Âá∫È°ØËëóÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®ÁâπÂÆöÈ†òÂüüÔºà‰æãÂ¶ÇËó•Áâ©ÈñãÁôºÔºâ‰∏≠ÁöÑÊïàËÉΩ‰ªçÊúâÂæÖÂä†Âº∑„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü **Y-Mol**ÔºåÂΩ¢Êàê‰∫Ü‰∏ÄÂÄãÂÆåÂñÑÁöÑ LLM ÂÖ∏ÁØÑÔºåÁî®ÊñºËó•Áâ©ÈñãÁôºÊµÅÁ®ã„ÄÇY-Mol ÊòØ‰∏ÄÂÄãÂ§öÂ∞∫Â∫¶ÁöÑÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÂºïÂ∞é LLMÔºåÊó®Âú®ÂÆåÊàêÂÖàÂ∞éÂåñÂêàÁâ©ÁôºÁèæ„ÄÅËá®Â∫äÂâçÂíåËá®Â∫äÈ†êÊ∏¨Á≠â‰ªªÂãô„ÄÇÈÄèÈÅéÊï¥ÂêàÊï∏ÁôæËê¨ÂÄãÂ§öÂ∞∫Â∫¶ÁöÑÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÔºå‰∏¶‰ΩøÁî® LLaMA2 ‰ΩúÁÇ∫Âü∫Á§é LLMÔºåY-Mol ÂæûÂá∫ÁâàÁâ©„ÄÅÁü•Ë≠òÂúñË≠úÂíåÂ∞àÂÆ∂Ë®≠Ë®àÁöÑÂêàÊàêË≥áÊñô‰∏≠Â≠∏ÁøíÔºåÂ¢ûÂº∑‰∫ÜÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÂÖ∂ËÉΩÂäõÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅé‰∏âÁ®ÆÈ°ûÂûãÁöÑËó•Áâ©Â∞éÂêëÊåá‰ª§ÂæóÂà∞Ë±êÂØåÔºöÂ∑≤ËôïÁêÜÂá∫ÁâàÁâ©ÁöÑÂü∫ÊñºÊèèËø∞ÁöÑÊèêÁ§∫„ÄÅÁî®ÊñºÂæûÁü•Ë≠òÂúñË≠ú‰∏≠ÊèêÂèñÈóúËÅØÁöÑÂü∫ÊñºË™ûÁæ©ÁöÑÊèêÁ§∫Ôºå‰ª•ÂèäÁî®ÊñºÁêÜËß£ÁîüÁâ©ÈÜ´Â≠∏Â∑•ÂÖ∑‰∏≠Â∞àÂÆ∂Áü•Ë≠òÁöÑÂü∫ÊñºÁØÑÊú¨ÁöÑÊèêÁ§∫„ÄÇÊ≠§Â§ñÔºåY-Mol Êèê‰æõ‰∫Ü‰∏ÄÁµÑ LLM ÂÖ∏ÁØÑÔºåÂèØ‰ª•Âú®Êï¥ÂÄãËó•Áâ©ÈñãÁôºÈÅéÁ®ã‰∏≠Ëá™‰∏ªÂü∑Ë°å‰∏ãÊ∏∏‰ªªÂãôÔºåÂåÖÊã¨ËôõÊì¨ÁØ©ÈÅ∏„ÄÅËó•Áâ©Ë®≠Ë®à„ÄÅËó•ÁêÜÁâπÊÄßÈ†êÊ∏¨ÂíåËó•Áâ©Áõ∏Èóú‰∫§‰∫íÈ†êÊ∏¨„ÄÇÊàëÂÄëÂ∞çÂêÑÁ®ÆÁîüÁâ©ÈÜ´Â≠∏‰æÜÊ∫êÁöÑÂª£Ê≥õË©ï‰º∞Ë°®ÊòéÔºåY-Mol Âú®ÁôºÁèæÂÖàÂ∞éÂåñÂêàÁâ©„ÄÅÈ†êÊ∏¨ÂàÜÂ≠êÁâπÊÄßÂíåË≠òÂà•Ëó•Áâ©‰∫§‰∫í‰∫ã‰ª∂ÊñπÈù¢È°ØËëóÂÑ™ÊñºÈÄöÁî® LLM„ÄÇ

##### **AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data**
2410.11531v1 by Xinjie Zhao, Moritz Blum, Rui Yang, Boming Yang, Luis M√°rquez Carpintero, M√≥nica Pina-Navarro, Tony Wang, Xin Li, Huitao Li, Yanran Fu, Rongrong Wang, Juntao Zhang, Irene Li

Large Language Models~(LLMs) have demonstrated capabilities across various
applications but face challenges such as hallucination, limited reasoning
abilities, and factual inconsistencies, especially when tackling complex,
domain-specific tasks like question answering~(QA). While Knowledge
Graphs~(KGs) have been shown to help mitigate these issues, research on the
integration of LLMs with background KGs remains limited. In particular, user
accessibility and the flexibility of the underlying KG have not been thoroughly
explored. We introduce AGENTiGraph (Adaptive Generative ENgine for Task-based
Interaction and Graphical Representation), a platform for knowledge management
through natural language interaction. It integrates knowledge extraction,
integration, and real-time visualization. AGENTiGraph employs a multi-agent
architecture to dynamically interpret user intents, manage tasks, and integrate
new knowledge, ensuring adaptability to evolving user requirements and data
contexts. Our approach demonstrates superior performance in knowledge graph
interactions, particularly for complex domain-specific tasks. Experimental
results on a dataset of 3,500 test cases show AGENTiGraph significantly
outperforms state-of-the-art zero-shot baselines, achieving 95.12\% accuracy in
task classification and 90.45\% success rate in task execution. User studies
corroborate its effectiveness in real-world scenarios. To showcase versatility,
we extended AGENTiGraph to legislation and healthcare domains, constructing
specialized KGs capable of answering complex queries in legal and medical
contexts.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®ÆÊáâÁî®‰∏≠Â±ïÁèæÂÖ∂ËÉΩÂäõÔºå‰ΩÜ‰ªçÈù¢Ëá®ÂπªË¶∫„ÄÅÊé®ÁêÜËÉΩÂäõÊúâÈôêÂíå‰∫ãÂØ¶‰∏ç‰∏ÄËá¥Á≠âÊåëÊà∞ÔºåÂ∞§ÂÖ∂ÊòØÂú®ËôïÁêÜË§áÈõúÁöÑÁâπÂÆöÈ†òÂüü‰ªªÂãôÔºå‰æãÂ¶ÇÂïèÁ≠î (QA) ÊôÇ„ÄÇÈõñÁÑ∂Áü•Ë≠òÂúñË≠ú (KG) Â∑≤Ë¢´Ë≠âÊòéÊúâÂä©ÊñºÁ∑©Ëß£ÈÄô‰∫õÂïèÈ°åÔºå‰ΩÜ LLM ËàáËÉåÊôØ KG Êï¥ÂêàÁöÑÁ†îÁ©∂‰ªçÁÑ∂ÊúâÈôê„ÄÇÁâπÂà•ÊòØÔºå‰ΩøÁî®ËÄÖÁöÑÂèØÂèäÊÄßÂíåÂ∫ïÂ±§ KG ÁöÑÈùàÊ¥ªÊÄßÂ∞öÊú™ÂæóÂà∞ÂæπÂ∫ïÊé¢Ë®é„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü AGENTiGraphÔºàÁî®Êñº‰ªªÂãôÂûã‰∫íÂãïÂíåÂúñÂΩ¢Ë°®Á§∫ÁöÑËá™ÈÅ©ÊáâÁîüÊàêÂºïÊìéÔºâÔºå‰∏ÄÂÄãÈÄèÈÅéËá™ÁÑ∂Ë™ûË®Ä‰∫íÂãïÈÄ≤Ë°åÁü•Ë≠òÁÆ°ÁêÜÁöÑÂπ≥Âè∞„ÄÇÂÆÉÊï¥Âêà‰∫ÜÁü•Ë≠òËêÉÂèñ„ÄÅÊï¥ÂêàÂíåÂç≥ÊôÇË¶ñË¶∫Âåñ„ÄÇAGENTiGraph Êé°Áî®Â§ö‰ª£ÁêÜÊû∂ÊßãÔºå‰ª•ÂãïÊÖãËß£ËÆÄ‰ΩøÁî®ËÄÖÁöÑÊÑèÂúñ„ÄÅÁÆ°ÁêÜ‰ªªÂãô‰∏¶Êï¥ÂêàÊñ∞Áü•Ë≠òÔºåÁ¢∫‰øùÈÅ©Êáâ‰∏çÊñ∑ËÆäÂåñÁöÑ‰ΩøÁî®ËÄÖÈúÄÊ±ÇÂíåË≥áÊñôËÑàÁµ°„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Áü•Ë≠òÂúñË≠ú‰∫íÂãï‰∏≠Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂ∞çÊñºË§áÈõúÁöÑÁâπÂÆöÈ†òÂüü‰ªªÂãô„ÄÇÂú® 3,500 ÂÄãÊ∏¨Ë©¶Ê°à‰æãÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåAGENTiGraph ÊòéÈ°ØÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÈõ∂Ê¨°Â≠∏ÁøíÂü∫Ê∫ñÔºåÂú®‰ªªÂãôÂàÜÈ°û‰∏≠ÈÅîÂà∞ 95.12% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂú®‰ªªÂãôÂü∑Ë°å‰∏≠ÈÅîÂà∞ 90.45% ÁöÑÊàêÂäüÁéá„ÄÇ‰ΩøÁî®ËÄÖÁ†îÁ©∂Ë≠âÂØ¶‰∫ÜÂÆÉÂú®ÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÁÇ∫‰∫ÜÂ±ïÁ§∫ÂÖ∂Â§öÂäüËÉΩÊÄßÔºåÊàëÂÄëÂ∞á AGENTiGraph Âª∂‰º∏Âà∞Ê≥ïÂæãÂíåÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÂª∫Êßã‰∫ÜËÉΩÂ§†ÂõûÁ≠îÊ≥ïÂæãÂíåÈÜ´ÁôÇËÑàÁµ°‰∏≠Ë§áÈõúÊü•Ë©¢ÁöÑÂ∞àÊ•≠Áü•Ë≠òÂúñË≠ú„ÄÇ

##### **Do LLMs Have the Generalization Ability in Conducting Causal Inference?**
2410.11385v1 by Chen Wang, Dongming Zhao, Bo Wang, Ruifang He, Yuexian Hou

In causal inference, generalization capability refers to the ability to
conduct causal inference methods on new data to estimate the causal-effect
between unknown phenomenon, which is crucial for expanding the boundaries of
knowledge. Studies have evaluated the causal inference capabilities of Large
Language Models (LLMs) concerning known phenomena, yet the generalization
capabilities of LLMs concerning unseen phenomena remain unexplored. In this
paper, we selected four tasks: Causal Path Discovery (CP), Backdoor Adjustment
(BA), Factual Inference (FI), and Counterfactual Inference (CI) as
representatives of causal inference tasks. To generate evaluation questions
about previously unseen phenomena in new data on the four tasks, we propose a
benchmark generation framework, which employs randomly generated graphs and
node names to formulate questions within hypothetical new causal scenarios.
Based on this framework, we compile a benchmark dataset of varying levels of
question complexity. We extensively tested the generalization capabilities of
five leading LLMs across four tasks. Experiment results reveal that while LLMs
exhibit good generalization performance in solving simple CP, FI, and complex
CI questions, they encounter difficulties when tackling BA questions and face
obvious performance fluctuations as the problem complexity changes.
Furthermore, when the names of phenomena incorporate existing terms, even if
these names are entirely novel, their generalization performance can still be
hindered by interference from familiar terms.

ÊëòË¶ÅÔºöÂú®Âõ†ÊûúÊé®Ë´ñ‰∏≠ÔºåÊ≥õÂåñËÉΩÂäõÊòØÊåáÂú®Êñ∞ÁöÑË≥áÊñô‰∏äÂü∑Ë°åÂõ†ÊûúÊé®Ë´ñÊñπÊ≥ï‰ª•‰º∞Ë®àÊú™Áü•ÁèæË±°‰πãÈñìÁöÑÂõ†ÊûúÈóú‰øÇÁöÑËÉΩÂäõÔºåÈÄôÂ∞çÊñºÊì¥Â±ïÁü•Ë≠òÁöÑÁïåÈôêËá≥ÈóúÈáçË¶Å„ÄÇÁ†îÁ©∂Â∑≤Á∂ìË©ï‰º∞‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈóúÊñºÂ∑≤Áü•ÁèæË±°ÁöÑÂõ†ÊûúÊé®Ë´ñËÉΩÂäõÔºå‰ΩÜ LLM ÈóúÊñºÊú™Áü•ÁèæË±°ÁöÑÊ≥õÂåñËÉΩÂäõ‰ªçÊú™Ë¢´Êé¢Ë®é„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÅ∏Êìá‰∫ÜÂõõÂÄã‰ªªÂãôÔºöÂõ†ÊûúË∑ØÂæëÁôºÁèæ (CP)„ÄÅÂæåÈñÄË™øÊï¥ (BA)„ÄÅ‰∫ãÂØ¶Êé®Ë´ñ (FI) ÂíåÂèç‰∫ãÂØ¶Êé®Ë´ñ (CI) ‰ΩúÁÇ∫Âõ†ÊûúÊé®Ë´ñ‰ªªÂãôÁöÑ‰ª£Ë°®„ÄÇÁÇ∫‰∫ÜÁî¢ÁîüÈóúÊñºÊñ∞Ë≥áÊñô‰∏≠‰ª•ÂâçÊú™Ë¶ãÁèæË±°ÁöÑË©ï‰º∞ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂü∫Ê∫ñÁîüÊàêÊ°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂Êé°Áî®Èö®Ê©üÁîüÊàêÁöÑÂúñÂΩ¢ÂíåÁØÄÈªûÂêçÁ®±Âú®ÂÅáË®≠ÁöÑÊñ∞Âõ†ÊûúÂ†¥ÊôØ‰∏≠Âà∂ÂÆöÂïèÈ°å„ÄÇÂü∫ÊñºÊ≠§Ê°ÜÊû∂ÔºåÊàëÂÄëÁ∑®Âà∂‰∫Ü‰∏ÄÂÄãÂïèÈ°åË§áÈõúÁ®ãÂ∫¶‰∏çÂêåÁöÑÂü∫Ê∫ñÊï∏ÊìöÈõÜ„ÄÇÊàëÂÄëÂª£Ê≥õÊ∏¨Ë©¶‰∫Ü‰∫îÂÄãÈ†òÂÖàÁöÑ LLM Âú®ÂõõÂÄã‰ªªÂãô‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÈõñÁÑ∂ LLM Âú®Ëß£Ê±∫Á∞°ÂñÆÁöÑ CP„ÄÅFI ÂíåË§áÈõúÁöÑ CI ÂïèÈ°åÊôÇË°®ÁèæÂá∫ËâØÂ•ΩÁöÑÊ≥õÂåñÊÄßËÉΩÔºå‰ΩÜÂú®Ëß£Ê±∫ BA ÂïèÈ°åÊôÇÈÅáÂà∞Âõ∞Èõ£Ôºå‰∏¶‰∏îÈö®ËëóÂïèÈ°åË§áÈõúÊÄßÁöÑËÆäÂåñËÄåÈù¢Ëá®ÊòéÈ°ØÁöÑÊÄßËÉΩÊ≥¢Âãï„ÄÇÊ≠§Â§ñÔºåÁï∂ÁèæË±°ÁöÑÂêçÁ®±ÂåÖÂê´ÁèæÊúâË°ìË™ûÊôÇÔºåÂç≥‰ΩøÈÄô‰∫õÂêçÁ®±ÊòØÂÆåÂÖ®Êñ∞Á©éÁöÑÔºåÂÖ∂Ê≥õÂåñÊÄßËÉΩ‰ªçÁÑ∂ÊúÉÂèóÂà∞ÁÜüÊÇâË°ìË™ûÁöÑÂπ≤Êìæ„ÄÇ

##### **Enhance Graph Alignment for Large Language Models**
2410.11370v1 by Haitong Luo, Xuying Meng, Suhang Wang, Tianxiang Zhao, Fali Wang, Hanyun Cao, Yujun Zhang

Graph-structured data is prevalent in the real world. Recently, due to the
powerful emergent capabilities, Large Language Models (LLMs) have shown
promising performance in modeling graphs. The key to effectively applying LLMs
on graphs is converting graph data into a format LLMs can comprehend.
Graph-to-token approaches are popular in enabling LLMs to process graph
information. They transform graphs into sequences of tokens and align them with
text tokens through instruction tuning, where self-supervised instruction
tuning helps LLMs acquire general knowledge about graphs, and supervised
fine-tuning specializes LLMs for the downstream tasks on graphs. Despite their
initial success, we find that existing methods have a misalignment between
self-supervised tasks and supervised downstream tasks, resulting in negative
transfer from self-supervised fine-tuning to downstream tasks. To address these
issues, we propose Graph Alignment Large Language Models (GALLM) to benefit
from aligned task templates. In the self-supervised tuning stage, we introduce
a novel text matching task using templates aligned with downstream tasks. In
the task-specific tuning stage, we propose two category prompt methods that
learn supervision information from additional explanation with further aligned
templates. Experimental evaluations on four datasets demonstrate substantial
improvements in supervised learning, multi-dataset generalizability, and
particularly in zero-shot capability, highlighting the model's potential as a
graph foundation model.

ÊëòË¶ÅÔºöÂúñÂΩ¢ÁµêÊßãÁöÑË≥áÊñôÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠ÂæàÂ∏∏Ë¶ã„ÄÇÊúÄËøëÔºåÁî±ÊñºÂº∑Â§ßÁöÑÊñ∞ËààËÉΩÂäõÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂúñÂΩ¢Âª∫Ê®°ÊñπÈù¢Â±ïÁèæÂá∫‰ª§‰∫∫ÊªøÊÑèÁöÑÊïàËÉΩ„ÄÇÊúâÊïàÂ∞á LLM ÊáâÁî®ÊñºÂúñÂΩ¢ÁöÑÈóúÈçµÊòØÂ∞áÂúñÂΩ¢Ë≥áÊñôËΩâÊèõÊàê LLM ÂèØ‰ª•ÁêÜËß£ÁöÑÊ†ºÂºè„ÄÇÂúñÂΩ¢Âà∞Ê®ôË®òÁöÑÊñπÊ≥ïÂæàÊµÅË°åÔºåËÆì LLM ÂèØ‰ª•ËôïÁêÜÂúñÂΩ¢Ë≥áË®ä„ÄÇÂÆÉÂÄëÂ∞áÂúñÂΩ¢ËΩâÊèõÊàêÊ®ôË®òÂ∫èÂàóÔºå‰∏¶ÈÄèÈÅéÊåá‰ª§Ë™øÊï¥ËàáÊñáÂ≠óÊ®ôË®òÂ∞çÈΩäÔºåÂÖ∂‰∏≠Ëá™ÊàëÁõ£Áù£ÁöÑÊåá‰ª§Ë™øÊï¥ÊúâÂä©Êñº LLM Áç≤ÂæóÈóúÊñºÂúñÂΩ¢ÁöÑÂ∏∏Ë≠òÔºåËÄåÁõ£Áù£ÂæÆË™øÂâáÂ∞àÈñÄÈáùÂ∞çÂúñÂΩ¢‰∏äÁöÑ‰∏ãÊ∏∏‰ªªÂãôË™øÊï¥ LLM„ÄÇÂÑòÁÆ°ÂÆÉÂÄëÊúÄÂàùÂæàÊàêÂäüÔºåÊàëÂÄëÁôºÁèæÁèæÊúâÊñπÊ≥ïÂú®Ëá™ÊàëÁõ£Áù£‰ªªÂãôÂíåÁõ£Áù£‰∏ãÊ∏∏‰ªªÂãô‰πãÈñìÂ≠òÂú®ÈåØ‰ΩçÔºåÂ∞éËá¥Ëá™ÊàëÁõ£Áù£ÂæÆË™øÂ∞ç‰∏ãÊ∏∏‰ªªÂãôÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ÂúñÂΩ¢Â∞çÈΩäÂ§ßÂûãË™ûË®ÄÊ®°Âûã (GALLM) ‰ª•ÂæûÂ∞çÈΩäÁöÑ‰ªªÂãôÁØÑÊú¨‰∏≠ÂèóÁõä„ÄÇÂú®Ëá™ÊàëÁõ£Áù£Ë™øÊï¥ÈöéÊÆµÔºåÊàëÂÄë‰ΩøÁî®Ëàá‰∏ãÊ∏∏‰ªªÂãôÂ∞çÈΩäÁöÑÁØÑÊú¨ÔºåÂºïÂÖ•‰∏ÄÂÄãÊñ∞Á©éÁöÑÊñáÂ≠óÊØîÂ∞ç‰ªªÂãô„ÄÇÂú®ÁâπÂÆö‰ªªÂãôÁöÑË™øÊï¥ÈöéÊÆµÔºåÊàëÂÄëÊèêÂá∫ÂÖ©Á®ÆÈ°ûÂà•ÊèêÁ§∫ÊñπÊ≥ïÔºåÂæûÈÄ≤‰∏ÄÊ≠•Â∞çÈΩäÁØÑÊú¨ÁöÑÈ°çÂ§ñË™™Êòé‰∏≠Â≠∏ÁøíÁõ£Áù£Ë≥áË®ä„ÄÇÂú®ÂõõÂÄãË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË©ï‰º∞Ë≠âÊòé‰∫ÜÁõ£Áù£ÂºèÂ≠∏Áøí„ÄÅÂ§öË≥áÊñôÈõÜÁöÑÊ¶ÇÊã¨ÊÄßÔºåÁâπÂà•ÊòØÂú®Èõ∂Ê¨°Â≠∏ÁøíËÉΩÂäõÊñπÈù¢ÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÁ™ÅÈ°Ø‰∫ÜË©≤Ê®°Âûã‰ΩúÁÇ∫ÂúñÂΩ¢Âü∫Á§éÊ®°ÂûãÁöÑÊΩõÂäõ„ÄÇ

##### **Unleashing the Power of LLMs as Multi-Modal Encoders for Text and Graph-Structured Data**
2410.11235v1 by Jiacheng Lin, Kun Qian, Haoyu Han, Nurendra Choudhary, Tianxin Wei, Zhongruo Wang, Sahika Genc, Edward W Huang, Sheng Wang, Karthik Subbian, Danai Koutra, Jimeng Sun

Graph-structured information offers rich contextual information that can
enhance language models by providing structured relationships and hierarchies,
leading to more expressive embeddings for various applications such as
retrieval, question answering, and classification. However, existing methods
for integrating graph and text embeddings, often based on Multi-layer
Perceptrons (MLPs) or shallow transformers, are limited in their ability to
fully exploit the heterogeneous nature of these modalities. To overcome this,
we propose Janus, a simple yet effective framework that leverages Large
Language Models (LLMs) to jointly encode text and graph data. Specifically,
Janus employs an MLP adapter to project graph embeddings into the same space as
text embeddings, allowing the LLM to process both modalities jointly. Unlike
prior work, we also introduce contrastive learning to align the graph and text
spaces more effectively, thereby improving the quality of learned joint
embeddings. Empirical results across six datasets spanning three tasks,
knowledge graph-contextualized question answering, graph-text pair
classification, and retrieval, demonstrate that Janus consistently outperforms
existing baselines, achieving significant improvements across multiple
datasets, with gains of up to 11.4% in QA tasks. These results highlight
Janus's effectiveness in integrating graph and text data. Ablation studies
further validate the effectiveness of our method.

ÊëòË¶ÅÔºöÂúñÂΩ¢ÁµêÊßãÂåñË≥áË®äÊèê‰æõË±êÂØåÁöÑËÑàÁµ°Ë≥áË®äÔºåÂèØ‰ª•ÈÄèÈÅéÊèê‰æõÁµêÊßãÂåñÁöÑÈóú‰øÇÂíåÈöéÂ±§‰æÜÂ¢ûÂº∑Ë™ûË®ÄÊ®°ÂûãÔºåÈÄ≤ËÄåÁÇ∫ÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÔºà‰æãÂ¶ÇÊ™¢Á¥¢„ÄÅÂïèÁ≠îÂíåÂàÜÈ°ûÔºâÁî¢ÁîüÊõ¥ÂÖ∑Ë°®ÁèæÂäõÁöÑÂµåÂÖ•„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂúñÂΩ¢ÂíåÊñáÂ≠óÂµåÂÖ•Êï¥ÂêàÊñπÊ≥ïÔºåÈÄöÂ∏∏Âü∫ÊñºÂ§öÂ±§ÊÑüÁü•Âô® (MLP) ÊàñÊ∑∫Â±§ËΩâÊèõÂô®ÔºåÂú®ÂÖÖÂàÜÂà©Áî®ÈÄô‰∫õÊ®°ÊÖãÁöÑÁï∞Ë≥™ÊÄßÊñπÈù¢ËÉΩÂäõÊúâÈôê„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∏ÄÈªûÔºåÊàëÂÄëÊèêÂá∫‰∫Ü JanusÔºå‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊ°ÜÊû∂ÔºåÂÆÉÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜËÅØÂêàÁ∑®Á¢ºÊñáÂ≠óÂíåÂúñÂΩ¢Ë≥áÊñô„ÄÇÂÖ∑È´î‰æÜË™™ÔºåJanus ‰ΩøÁî® MLP ÈÅ©ÈÖçÂô®Â∞áÂúñÂΩ¢ÂµåÂÖ•ÊäïÂΩ±Âà∞ËàáÊñáÂ≠óÂµåÂÖ•Áõ∏ÂêåÁöÑÁ©∫ÈñìÔºåÂÖÅË®± LLM ËÅØÂêàËôïÁêÜÈÄôÂÖ©Á®ÆÊ®°ÊÖã„ÄÇËàáÂÖàÂâçÁöÑÁ†îÁ©∂‰∏çÂêåÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫ÜÂ∞çÊØîÂ≠∏ÁøíÔºå‰ª•Êõ¥ÊúâÊïàÂú∞Â∞çÈΩäÂúñÂΩ¢ÂíåÊñáÂ≠óÁ©∫ÈñìÔºåÂæûËÄåÊèêÈ´òÂ≠∏ÁøíÂà∞ÁöÑËÅØÂêàÂµåÂÖ•ÁöÑÂìÅË≥™„ÄÇË∑®Ë∂äÂÖ≠ÂÄãË≥áÊñôÈõÜÁöÑÂØ¶Ë≠âÁµêÊûúÊ∂µËìã‰∫Ü‰∏âÂÄã‰ªªÂãôÔºåÁü•Ë≠òÂúñË≠úËÑàÁµ°ÂåñÂïèÁ≠î„ÄÅÂúñÂΩ¢ÊñáÂ≠óÂ∞çÂàÜÈ°ûÂíåÊ™¢Á¥¢ÔºåË≠âÊòé Janus ÊåÅÁ∫åÂÑ™ÊñºÁèæÊúâÂü∫Ê∫ñÔºåÂú®Â§öÂÄãË≥áÊñôÈõÜ‰∏äÂèñÂæóÈ°ØËëóÈÄ≤Ê≠•ÔºåÂú® QA ‰ªªÂãô‰∏≠Áç≤ÂæóÈ´òÈÅî 11.4% ÁöÑÊèêÂçá„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫Ü Janus Âú®Êï¥ÂêàÂúñÂΩ¢ÂíåÊñáÂ≠óË≥áÊñôÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊ∂àËûçÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•È©óË≠â‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Tree of Attributes Prompt Learning for Vision-Language Models**
2410.11201v1 by Tong Ding, Wanhua Li, Zhongqi Miao, Hanspeter Pfister

Prompt learning has proven effective in adapting vision language models for
downstream tasks. However, existing methods usually append learnable prompt
tokens solely with the category names to obtain textual features, which fails
to fully leverage the rich context indicated in the category name. To address
this issue, we propose the Tree of Attributes Prompt learning (TAP), which
first instructs LLMs to generate a tree of attributes with a "concept -
attribute - description" structure for each category, and then learn the
hierarchy with vision and text prompt tokens. Unlike existing methods that
merely augment category names with a set of unstructured descriptions, our
approach essentially distills structured knowledge graphs associated with class
names from LLMs. Furthermore, our approach introduces text and vision prompts
designed to explicitly learn the corresponding visual attributes, effectively
serving as domain experts. Additionally, the general and diverse descriptions
generated based on the class names may be wrong or absent in the specific given
images. To address this misalignment, we further introduce a vision-conditional
pooling module to extract instance-specific text features. Extensive
experimental results demonstrate that our approach outperforms state-of-the-art
methods on the zero-shot base-to-novel generalization, cross-dataset transfer,
as well as few-shot classification across 11 diverse datasets.

ÊëòË¶ÅÔºöÊèêÁ§∫Â≠∏ÁøíÂ∑≤Ë¢´Ë≠âÊòéÊúâÊïàÂú∞Â∞áË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÈÅ©ÊáâÊñº‰∏ãÊ∏∏‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏ÂÉÖÂ∞áÂèØÂ≠∏ÁøíÁöÑÊèêÁ§∫‰ª§ÁâåÈôÑÂä†Âà∞È°ûÂà•ÂêçÁ®±‰ª•Áç≤ÂèñÊñáÊú¨ÁâπÂæµÔºåÈÄôÊú™ËÉΩÂÖÖÂàÜÂà©Áî®È°ûÂà•ÂêçÁ®±‰∏≠ÊåáÁ§∫ÁöÑË±êÂØå‰∏ä‰∏ãÊñá„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ±¨ÊÄßÊèêÁ§∫Â≠∏ÁøíÊ®π (TAP)ÔºåÂÆÉÈ¶ñÂÖàÊåáÁ§∫ LLM ÁÇ∫ÊØèÂÄãÈ°ûÂà•ÁîüÊàê‰∏ÄÂÄãÂÖ∑Êúâ„ÄåÊ¶ÇÂøµ - Â±¨ÊÄß - ÊèèËø∞„ÄçÁµêÊßãÁöÑÂ±¨ÊÄßÊ®πÔºåÁÑ∂Âæå‰ΩøÁî®Ë¶ñË¶∫ÂíåÊñáÊú¨ÊèêÁ§∫‰ª§ÁâåÂ≠∏ÁøíÂ±§Ê¨°ÁµêÊßã„ÄÇËàáÂÉÖ‰ΩøÁî®‰∏ÄÁµÑÈùûÁµêÊßãÂåñÊèèËø∞‰æÜÊì¥ÂÖÖÈ°ûÂà•ÂêçÁ®±ÁöÑÁèæÊúâÊñπÊ≥ï‰∏çÂêåÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂØ¶Ë≥™‰∏äÂæû LLM ‰∏≠ÊèêÁÖâÂá∫ËàáÈ°ûÂà•ÂêçÁ®±Áõ∏ÈóúÁöÑÁµêÊßãÂåñÁü•Ë≠òÂúñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂºïÂÖ•‰∫ÜÊñáÊú¨ÂíåË¶ñË¶∫ÊèêÁ§∫ÔºåÊó®Âú®ÊòéÁ¢∫Â≠∏ÁøíÂ∞çÊáâÁöÑË¶ñË¶∫Â±¨ÊÄßÔºåÊúâÊïàÂú∞ÂÖÖÁï∂È†òÂüüÂ∞àÂÆ∂„ÄÇÊ≠§Â§ñÔºåÊ†πÊìöÈ°ûÂà•ÂêçÁ®±ÁîüÊàêÁöÑÈÄöÁî®‰∏îÂ§öÊ®£ÁöÑÊèèËø∞Âú®Áµ¶ÂÆöÁöÑÁâπÂÆöÂΩ±ÂÉè‰∏≠ÂèØËÉΩÊòØÈåØË™§ÁöÑÊàñ‰∏çÂ≠òÂú®ÁöÑ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÁ®ÆÈåØ‰ΩçÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãË¶ñË¶∫Ê¢ù‰ª∂Ê±†ÂåñÊ®°ÁµÑ‰æÜÊèêÂèñÁâπÂÆöÊñºÂØ¶‰æãÁöÑÊñáÊú¨ÁâπÂæµ„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Èõ∂Ê¨°Â≠∏ÁøíÂü∫Á§éÂà∞Êñ∞Á©éÁöÑÊ¶ÇÂåñ„ÄÅË∑®Ë≥áÊñôÈõÜÂÇ≥Ëº∏‰ª•Âèä 11 ÂÄã‰∏çÂêåË≥áÊñôÈõÜÁöÑÂ∞ëÊ¨°Â≠∏ÁøíÂàÜÈ°û‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇ

##### **Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs**
2410.11001v1 by Haozhen Zhang, Tao Feng, Jiaxuan You

Retrieval-augmented generation (RAG) has revitalized Large Language Models
(LLMs) by injecting non-parametric factual knowledge. Compared with
long-context LLMs, RAG is considered an effective summarization tool in a more
concise and lightweight manner, which can interact with LLMs multiple times
using diverse queries to get comprehensive responses. However, the
LLM-generated historical responses, which contain potentially insightful
information, are largely neglected and discarded by existing approaches,
leading to suboptimal results. In this paper, we propose \textit{graph of
records} (\textbf{GoR}), which leverages historical responses generated by LLMs
to enhance RAG for long-context global summarization. Inspired by the
\textit{retrieve-then-generate} paradigm of RAG, we construct a graph by
establishing an edge between the retrieved text chunks and the corresponding
LLM-generated response. To further uncover the intricate correlations between
them, GoR further features a \textit{graph neural network} and an elaborately
designed \textit{BERTScore}-based objective for self-supervised model training,
enabling seamless supervision signal backpropagation between reference
summaries and node embeddings. We comprehensively compare GoR with 12 baselines
across four long-context summarization datasets, and the results indicate that
our proposed method reaches the best performance e.g., 15\%, 8\%, and 19\%
improvement over retrievers w.r.t. Rouge-L, Rouge-1, and Rouge-2 on the WCEP
dataset). Extensive experiments further demonstrate the effectiveness of GoR.
Code is available at https://github.com/ulab-uiuc/GoR

ÊëòË¶ÅÔºöÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG) ÈÄèËøáÊ≥®ÂÖ•ÈùûÂèÇÊï∞‰∫ãÂÆûÁü•ËØÜÔºåËÆ©Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÈáçËé∑ÁîüÊú∫„ÄÇ‰∏éÈïøÊñáÊú¨ LLM Áõ∏ÊØîÔºåRAG Ë¢´ËßÜ‰∏∫‰∏ÄÁßçÊõ¥ÁÆÄÊ¥Å„ÄÅËΩªÈáèÁ∫ßÁöÑÊúâÊïàÊëòË¶ÅÂ∑•ÂÖ∑ÔºåÂÆÉÂèØ‰ª•‰ΩøÁî®‰∏çÂêåÁöÑÊü•ËØ¢‰∏é LLM Â§öÊ¨°‰∫íÂä®Ôºå‰ª•Ëé∑ÂæóÂÖ®Èù¢ÁöÑÂìçÂ∫î„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÊñπÊ≥ïÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂøΩÁï•Âπ∂ËàçÂºÉ‰∫Ü LLM ÁîüÊàêÁöÑÂéÜÂè≤ÂìçÂ∫îÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊΩúÂú®ÁöÑÊúâËßÅËß£ÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÂØºËá¥Ê¨°‰ºòÁöÑÁªìÊûú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü„ÄåËÆ∞ÂΩïÂõæ„Äç(**GoR**)ÔºåÂÆÉÂà©Áî® LLM ÁîüÊàêÁöÑÂéÜÂè≤ÂìçÂ∫îÊù•Â¢ûÂº∫ RAGÔºå‰ª•ËøõË°åÈïøÊñáÊú¨ÂÖ®Â±ÄÊëòË¶Å„ÄÇÂèó RAG ÁöÑ„ÄåÂÖàÊ£ÄÁ¥¢ÂêéÁîüÊàê„ÄçËåÉ‰æãÂêØÂèëÔºåÊàë‰ª¨ÈÄöËøáÂú®Ê£ÄÁ¥¢Âà∞ÁöÑÊñáÊú¨ÂùóÂíåÁõ∏Â∫îÁöÑ LLM ÁîüÊàêÁöÑÂìçÂ∫î‰πãÈó¥Âª∫Á´ãËæπÊù•ÊûÑÂª∫Âõæ„ÄÇ‰∏∫‰∫ÜËøõ‰∏ÄÊ≠•Êè≠Á§∫ÂÆÉ‰ª¨‰πãÈó¥ÁöÑÂ§çÊùÇÁõ∏ÂÖ≥ÊÄßÔºåGoR Ëøõ‰∏ÄÊ≠•ÈááÁî®‰∫Ü„ÄåÂõæÁ•ûÁªèÁΩëÁªú„ÄçÂíåÁ≤æÂøÉËÆæËÆ°ÁöÑÂü∫‰∫é„ÄåBERTScore„ÄçÁöÑÁõÆÊ†áÔºåÁî®‰∫éËá™ÊàëÁõëÁù£Ê®°ÂûãËÆ≠ÁªÉÔºå‰ªéËÄåÂú®ÂèÇËÄÉÊëòË¶ÅÂíåËäÇÁÇπÂµåÂÖ•‰πãÈó¥ÂÆûÁé∞Êó†ÁºùÁöÑÁõëÁù£‰ø°Âè∑ÂèçÂêë‰º†Êí≠„ÄÇÊàë‰ª¨ÂØπ GoR ‰∏é 12 ‰∏™Âü∫ÂáÜËøõË°å‰∫ÜÂÖ®Èù¢ÊØîËæÉÔºåÊ∂µÁõñ‰∫ÜÂõõ‰∏™ÈïøÊñáÊú¨ÊëòË¶ÅÊï∞ÊçÆÈõÜÔºåÁªìÊûúË°®ÊòéÊàë‰ª¨ÊèêÂá∫ÁöÑÊñπÊ≥ïËææÂà∞‰∫ÜÊúÄ‰Ω≥ÊÄßËÉΩÔºå‰æãÂ¶ÇÔºåÂú® WCEP Êï∞ÊçÆÈõÜ‰∏äÔºåÁõ∏ÂØπ‰∫éÊ£ÄÁ¥¢Âô®ÔºåRouge-L„ÄÅRouge-1 Âíå Rouge-2 ÂàÜÂà´ÊèêÈ´ò‰∫Ü 15%„ÄÅ8% Âíå 19%„ÄÇÂπøÊ≥õÁöÑÂÆûÈ™åËøõ‰∏ÄÊ≠•ËØÅÊòé‰∫Ü GoR ÁöÑÊúâÊïàÊÄß„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/ulab-uiuc/GoR Ëé∑Âæó

##### **NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models**
2410.10743v1 by Yanbiao Ji, Chang Liu, Xin Chen, Yue Ding, Dan Luo, Mei Li, Wenqing Lin, Hongtao Lu

Graphs are a fundamental data structure for representing relationships in
real-world scenarios. With the success of Large Language Models (LLMs) across
various natural language processing (NLP) tasks, there has been growing
interest in integrating LLMs for graph learning. However, applying LLMs to
graph-related tasks poses significant challenges, as these models are not
inherently designed to capture the complex structural information present in
graphs. Existing approaches address this challenge through two strategies: the
chain of tasks approach, which uses Graph Neural Networks (GNNs) to encode the
graph structure so that LLMs are relieved from understanding spatial positions;
and Graph-to-Text Conversion, which translates graph structures into semantic
text representations that LLMs can process. Despite their progress, these
methods often struggle to fully preserve the topological information of graphs
or require extensive computational resources, limiting their practical
applicability.
  In this work, we introduce Node Tokenizer for Large Language Models (NT-LLM),
a novel framework that efficiently encodes graph structures by selecting key
nodes as anchors and representing each node based on its relative distance to
these anchors. This position-anchored encoding effectively captures the graph
topology, enabling enhanced reasoning capabilities in LLMs over graph data.
Additionally, we implement a task-specific tuning procedure to further improve
structural understanding within LLMs. Through extensive empirical evaluations,
NT-LLM demonstrates significant performance improvements across a variety of
graph-related tasks.

ÊëòË¶ÅÔºöÂúñÂΩ¢ÊòØ‰∏ÄÁ®ÆÂü∫Êú¨Ë≥áÊñôÁµêÊßãÔºåÁî®ÊñºË°®Á§∫ÁèæÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÁöÑÈóú‰øÇ„ÄÇÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãô‰∏≠ÁöÑÊàêÂäüÔºåÊï¥Âêà LLM ‰ª•ÈÄ≤Ë°åÂúñÂΩ¢Â≠∏ÁøíÁöÑËààË∂£Êó•ÁõäÊøÉÂéö„ÄÇÁÑ∂ËÄåÔºåÂ∞á LLM ÊáâÁî®ÊñºËàáÂúñÂΩ¢Áõ∏ÈóúÁöÑ‰ªªÂãôÊúÉÂ∏∂‰æÜÈáçÂ§ßÊåëÊà∞ÔºåÂõ†ÁÇ∫ÈÄô‰∫õÊ®°Âûã‰∏¶ÈùûÂ§©ÁîüÂ∞±Ë®≠Ë®àÊàêÁî®‰æÜÊì∑ÂèñÂúñÂΩ¢‰∏≠Â≠òÂú®ÁöÑË§áÈõúÁµêÊßãË≥áË®ä„ÄÇÁèæÊúâÊñπÊ≥ïÈÄèÈÅéÂÖ©Á®ÆÁ≠ñÁï•‰æÜÊáâÂ∞çÊ≠§ÊåëÊà∞Ôºö‰ªªÂãôÈèàÊñπÊ≥ïÔºåÂÆÉ‰ΩøÁî®ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Á∑®Á¢ºÂúñÂΩ¢ÁµêÊßãÔºå‰ª•‰æøÊ∏õËºï LLM ÁêÜËß£Á©∫Èñì‰ΩçÁΩÆÁöÑË≤†ÊìîÔºõ‰ª•ÂèäÂúñÂΩ¢ËΩâÊñáÂ≠óËΩâÊèõÔºåÂÆÉÂ∞áÂúñÂΩ¢ÁµêÊßãËΩâÊèõÊàê LLM ÂèØ‰ª•ËôïÁêÜÁöÑË™ûÊÑèÊñáÂ≠óË°®Á§∫„ÄÇÂÑòÁÆ°ÈÄô‰∫õÊñπÊ≥ïÂèñÂæó‰∫ÜÈÄ≤Â±ïÔºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏Èõ£‰ª•ÂÆåÂÖ®‰øùÁïôÂúñÂΩ¢ÁöÑÊãìÊí≤Ë≥áË®äÔºåÊàñËÄÖÈúÄË¶ÅÂ§ßÈáèÁöÑÈÅãÁÆóË≥áÊ∫êÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑÂØ¶ÈöõÊáâÁî®ÊÄß„ÄÇ
Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁØÄÈªûÊ®ôË®òÂô® (NT-LLM)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÂÆÉÈÄèÈÅéÈÅ∏ÊìáÈóúÈçµÁØÄÈªû‰ΩúÁÇ∫Èå®ÈªûÔºå‰∏¶Ê†πÊìöÊØèÂÄãÁØÄÈªûËàáÈÄô‰∫õÈå®ÈªûÁöÑÁõ∏Â∞çË∑ùÈõ¢‰æÜË°®Á§∫ÊØèÂÄãÁØÄÈªûÔºåÂæûËÄåÊúâÊïàÂú∞Á∑®Á¢ºÂúñÂΩ¢ÁµêÊßã„ÄÇÈÄôÁ®ÆÂü∫Êñº‰ΩçÁΩÆÁöÑÈå®ÈªûÁ∑®Á¢ºÊúâÊïàÂú∞Êì∑Âèñ‰∫ÜÂúñÂΩ¢ÊãìÊí≤ÔºåËÆì LLM ËÉΩÂ§†Â∞çÂúñÂΩ¢Ë≥áÊñôÈÄ≤Ë°åÂ¢ûÂº∑ÁöÑÊé®ÁêÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂØ¶‰Ωú‰∫Ü‰∏ÄÂÄãÁâπÂÆöÊñº‰ªªÂãôÁöÑË™øÊï¥Á®ãÂ∫èÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÊîπÂñÑ LLM ‰∏≠ÁöÑÁµêÊßãÁêÜËß£„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶Ë≠âË©ï‰º∞ÔºåNT-LLM Âú®ÂêÑÁ®ÆËàáÂúñÂΩ¢Áõ∏ÈóúÁöÑ‰ªªÂãô‰∏≠ÈÉΩÂ±ïÁ§∫Âá∫È°ØËëóÁöÑÊïàËÉΩÊèêÂçá„ÄÇ

##### **GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs**
2410.10329v2 by Yun Zhu, Haizhou Shi, Xiaotang Wang, Yongchao Liu, Yaoke Wang, Boci Peng, Chuntao Hong, Siliang Tang

Recently, research on Text-Attributed Graphs (TAGs) has gained significant
attention due to the prevalence of free-text node features in real-world
applications and the advancements in Large Language Models (LLMs) that bolster
TAG methodologies. However, current TAG approaches face two primary challenges:
(i) Heavy reliance on label information and (ii) Limited cross-domain
zero/few-shot transferability. These issues constrain the scaling of both data
and model size, owing to high labor costs and scaling laws, complicating the
development of graph foundation models with strong transferability. In this
work, we propose the GraphCLIP framework to address these challenges by
learning graph foundation models with strong cross-domain zero/few-shot
transferability through a self-supervised contrastive graph-summary pretraining
method. Specifically, we generate and curate large-scale graph-summary pair
data with the assistance of LLMs, and introduce a novel graph-summary
pretraining method, combined with invariant learning, to enhance graph
foundation models with strong cross-domain zero-shot transferability. For
few-shot learning, we propose a novel graph prompt tuning technique aligned
with our pretraining objective to mitigate catastrophic forgetting and minimize
learning costs. Extensive experiments show the superiority of GraphCLIP in both
zero-shot and few-shot settings, while evaluations across various downstream
tasks confirm the versatility of GraphCLIP. Our code is available at:
https://github.com/ZhuYun97/GraphCLIP

ÊëòË¶ÅÔºöÊúÄËøëÔºåÊñáÊú¨Â±ûÊÄßÂõæÔºàTAGÔºâÁöÑÁ†îÁ©∂Áî±‰∫éÁé∞ÂÆû‰∏ñÁïåÂ∫îÁî®‰∏≠Ëá™Áî±ÊñáÊú¨ËäÇÁÇπÁâπÂæÅÁöÑÊôÆÈÅçÊÄß‰ª•ÂèäÊîØÊåÅ TAG ÊñπÊ≥ïÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑËøõÊ≠•ËÄåÂ§áÂèóÂÖ≥Ê≥®„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÁöÑ TAG ÊñπÊ≥ïÈù¢‰∏¥‰∏§Â§ß‰∏ªË¶ÅÊåëÊàòÔºö(i) ÂØπÊ†áÁ≠æ‰ø°ÊÅØÁöÑ‰∏•Èáç‰æùËµñÔºå‰ª•Âèä (ii) Ë∑®ÂüüÈõ∂/Â∞èÊ†∑Êú¨ÂèØËøÅÁßªÊÄßÁöÑÂèóÈôê„ÄÇÁî±‰∫éÈ´òÊòÇÁöÑ‰∫∫ÂäõÊàêÊú¨ÂíåËßÑÊ®°ÂåñÂÆöÂæãÔºåËøô‰∫õÈóÆÈ¢òÈôêÂà∂‰∫ÜÊï∞ÊçÆÂíåÊ®°ÂûãËßÑÊ®°ÁöÑÊâ©Â±ïÔºå‰ΩøÂæóÂÖ∑ÊúâÂº∫Â§ßÂèØËøÅÁßªÊÄßÁöÑÂõæÂü∫Á°ÄÊ®°ÂûãÁöÑÂºÄÂèëÂèòÂæóÂ§çÊùÇ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü GraphCLIP Ê°ÜÊû∂ÔºåÈÄöËøáËá™ÁõëÁù£ÂØπÊØîÂõæÊëòË¶ÅÈ¢ÑËÆ≠ÁªÉÊñπÊ≥ïÊù•Â≠¶‰π†ÂÖ∑ÊúâÂº∫Â§ßË∑®ÂüüÈõ∂/Â∞èÊ†∑Êú¨ÂèØËøÅÁßªÊÄßÁöÑÂõæÂü∫Á°ÄÊ®°ÂûãÔºå‰ª•Â∫îÂØπËøô‰∫õÊåëÊàò„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÂÄüÂä© LLM ÁîüÊàêÂπ∂Êï¥ÁêÜ‰∫ÜÂ§ßËßÑÊ®°ÂõæÊëòË¶ÅÂØπÊï∞ÊçÆÔºåÂπ∂ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂõæÊëòË¶ÅÈ¢ÑËÆ≠ÁªÉÊñπÊ≥ïÔºåÁªìÂêà‰∏çÂèòÊÄßÂ≠¶‰π†Ôºå‰ª•Â¢ûÂº∫ÂÖ∑ÊúâÂº∫Â§ßË∑®ÂüüÈõ∂Ê†∑Êú¨ÂèØËøÅÁßªÊÄßÁöÑÂõæÂü∫Á°ÄÊ®°Âûã„ÄÇÂØπ‰∫éÂ∞èÊ†∑Êú¨Â≠¶‰π†ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂõæÊèêÁ§∫Ë∞ÉÊï¥ÊäÄÊúØÔºåËØ•ÊäÄÊúØ‰∏éÊàë‰ª¨ÁöÑÈ¢ÑËÆ≠ÁªÉÁõÆÊ†á‰∏ÄËá¥Ôºå‰ª•ÂáèËΩªÁÅæÈöæÊÄßÈÅóÂøòÂπ∂ÊúÄÂ§ßÁ®ãÂ∫¶Âú∞Èôç‰ΩéÂ≠¶‰π†ÊàêÊú¨„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åË°®ÊòéÔºåGraphCLIP Âú®Èõ∂Ê†∑Êú¨ÂíåÂ∞èÊ†∑Êú¨ËÆæÁΩÆ‰∏≠ÈÉΩÂÖ∑Êúâ‰ºòË∂äÊÄßÔºåÂêåÊó∂ÂØπÂêÑÁßç‰∏ãÊ∏∏‰ªªÂä°ÁöÑËØÑ‰º∞ËØÅÂÆû‰∫Ü GraphCLIP ÁöÑÂ§öÂäüËÉΩÊÄß„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂèØÂú®‰ª•‰∏ã‰ΩçÁΩÆËé∑ÂæóÔºö
https://github.com/ZhuYun97/GraphCLIP

##### **Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning**
2410.10144v1 by Hongyi Yuan, Suqi Liu, Kelly Cho, Katherine Liao, Alexandre Pereira, Tianxi Cai

We introduce GENomic Encoding REpresentation with Language Model (GENEREL), a
framework designed to bridge genetic and biomedical knowledge bases. What sets
GENEREL apart is its ability to fine-tune language models to infuse biological
knowledge behind clinical concepts such as diseases and medications. This
fine-tuning enables the model to capture complex biomedical relationships more
effectively, enriching the understanding of how genomic data connects to
clinical outcomes. By constructing a unified embedding space for biomedical
concepts and a wide range of common SNPs from sources such as patient-level
data, biomedical knowledge graphs, and GWAS summaries, GENEREL aligns the
embeddings of SNPs and clinical concepts through multi-task contrastive
learning. This allows the model to adapt to diverse natural language
representations of biomedical concepts while bypassing the limitations of
traditional code mapping systems across different data sources. Our experiments
demonstrate GENEREL's ability to effectively capture the nuanced relationships
between SNPs and clinical concepts. GENEREL also emerges to discern the degree
of relatedness, potentially allowing for a more refined identification of
concepts. This pioneering approach in constructing a unified embedding system
for both SNPs and biomedical concepts enhances the potential for data
integration and discovery in biomedical research.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄë‰ªãÁ¥π GENomic Encoding REpresentation with Language Model (GENEREL)Ôºå‰∏ÄÂÄãÊó®Âú®Ê©ãÊé•ÈÅ∫ÂÇ≥ÂíåÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÂ∫´ÁöÑÊ°ÜÊû∂„ÄÇGENEREL ÁöÑÁç®Áâπ‰πãËôïÂú®ÊñºÂÆÉÂæÆË™øË™ûË®ÄÊ®°ÂûãÔºå‰ª•ÁÅåËº∏ÁñæÁóÖÂíåËó•Áâ©Á≠âËá®Â∫äÊ¶ÇÂøµËÉåÂæåÁöÑÁîüÁâ©Áü•Ë≠ò„ÄÇÈÄôÁ®ÆÂæÆË™ø‰ΩøÊ®°ÂûãËÉΩÂ§†Êõ¥ÊúâÊïàÂú∞ÊçïÊçâË§áÈõúÁöÑÁîüÁâ©ÈÜ´Â≠∏Èóú‰øÇÔºåË±êÂØåÂ∞çÂü∫Âõ†ÁµÑÊï∏ÊìöÂ¶Ç‰ΩïÈÄ£Êé•Ëá®Â∫äÁµêÊûúÁöÑÁêÜËß£„ÄÇÈÄöÈÅéÊßãÂª∫‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÁîüÁâ©ÈÜ´Â≠∏Ê¶ÇÂøµÂµåÂÖ•Á©∫ÈñìÂíå‰æÜËá™ÊÇ£ËÄÖÁ¥öÂà•Êï∏Êìö„ÄÅÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÂúñË≠úÂíå GWAS Á∏ΩÁµêÁ≠â‰æÜÊ∫êÁöÑÂª£Ê≥õÂ∏∏Ë¶ã SNPÔºåGENEREL ÈÄöÈÅéÂ§ö‰ªªÂãôÂ∞çÊØîÂ≠∏ÁøíÂ∞çÈΩä SNP ÂíåËá®Â∫äÊ¶ÇÂøµÁöÑÂµåÂÖ•„ÄÇÈÄôÂÖÅË®±Ê®°ÂûãÈÅ©ÊáâÁîüÁâ©ÈÜ´Â≠∏Ê¶ÇÂøµÁöÑÂ§öÂÖÉËá™ÁÑ∂Ë™ûË®ÄË°®Á§∫ÔºåÂêåÊôÇÁπûÈÅé‰∏çÂêåÊï∏ÊìöÊ∫ê‰∏≠ÂÇ≥Áµ±‰ª£Á¢ºÊò†Â∞ÑÁ≥ªÁµ±ÁöÑÈôêÂà∂„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòé‰∫Ü GENEREL ÊúâÊïàÊçïÊçâ SNP ÂíåËá®Â∫äÊ¶ÇÂøµ‰πãÈñìÁ¥∞ÂæÆÈóú‰øÇÁöÑËÉΩÂäõ„ÄÇGENEREL ‰πüÂá∫Áèæ‰∫ÜËæ®Âà•Áõ∏ÈóúÁ®ãÂ∫¶ÔºåÊΩõÂú®Âú∞ÂÖÅË®±Êõ¥Á≤æÁ¢∫Âú∞Ë≠òÂà•Ê¶ÇÂøµ„ÄÇÈÄôÁ®ÆÊßãÂª∫ SNP ÂíåÁîüÁâ©ÈÜ´Â≠∏Ê¶ÇÂøµÁµ±‰∏ÄÂµåÂÖ•Á≥ªÁµ±ÁöÑÂÖàÈ©ÖÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜÁîüÁâ©ÈÜ´Â≠∏Á†îÁ©∂‰∏≠Êï∏ÊìöÊï¥ÂêàÂíåÁôºÁèæÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **Language Model Preference Evaluation with Multiple Weak Evaluators**
2410.12869v1 by Zhengyu Hu, Jieyu Zhang, Zhihan Xiong, Alexander Ratner, Hui Xiong, Ranjay Krishna

Despite the remarkable success of Large Language Models (LLMs), evaluating
their outputs' quality regarding preference remains a critical challenge.
Existing works usually leverage a powerful LLM (e.g., GPT4) as the judge for
comparing LLMs' output pairwisely, yet such model-based evaluator is vulnerable
to conflicting preference, i.e., output A is better than B, B than C, but C
than A, causing contradictory evaluation results. To improve model-based
preference evaluation, we introduce GED (Preference Graph Ensemble and
Denoise), a novel approach that leverages multiple model-based evaluators to
construct preference graphs, and then ensemble and denoise these graphs for
better, non-contradictory evaluation results. In particular, our method
consists of two primary stages: aggregating evaluations into a unified graph
and applying a denoising process to eliminate cyclic inconsistencies, ensuring
a directed acyclic graph (DAG) structure. We provide theoretical guarantees for
our framework, demonstrating its efficacy in recovering the ground truth
preference structure. Extensive experiments across ten benchmark datasets show
that GED outperforms baseline methods in model ranking, response selection, and
model alignment tasks. Notably, GED combines weaker evaluators like Llama3-8B,
Mistral-7B, and Qwen2-7B to surpass the performance of stronger evaluators like
Qwen2-72B, highlighting its ability to enhance evaluation reliability and
improve model performance.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁç≤Âæó‰∫ÜÈ°ØËëóÁöÑÊàêÂäüÔºå‰ΩÜË©ï‰º∞ÂÖ∂Áî¢Âá∫ÁöÑÂìÅË≥™‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈóúÈçµÁöÑÊåëÊà∞„ÄÇÁèæÊúâÁöÑ‰ΩúÂìÅÈÄöÂ∏∏Âà©Áî®Âº∑Â§ßÁöÑ LLMÔºà‰æãÂ¶Ç GPT4Ôºâ‰ΩúÁÇ∫Ë©ïÂØ©ÔºåÊàêÂ∞çÊØîËºÉ LLM ÁöÑÁî¢Âá∫ÔºåÁÑ∂ËÄåÈÄôÁ®ÆÂü∫ÊñºÊ®°ÂûãÁöÑË©ï‰º∞Âô®ÂÆπÊòìÂèóÂà∞Ë°ùÁ™ÅÂÅèÂ•ΩÁöÑÂΩ±ÈüøÔºåÂç≥Ëº∏Âá∫ A ÂÑ™Êñº BÔºåB ÂÑ™Êñº CÔºå‰ΩÜ C ÂÑ™Êñº AÔºåÂ∞éËá¥ÁüõÁõæÁöÑË©ï‰º∞ÁµêÊûú„ÄÇÁÇ∫‰∫ÜÊîπÈÄ≤Âü∫ÊñºÊ®°ÂûãÁöÑÂÅèÂ•ΩË©ï‰º∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü GEDÔºàÂÅèÂ•ΩÂúñÂΩ¢ÈõÜÊàêÂíåÂéªÂô™ÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂÆÉÂà©Áî®Â§öÂÄãÂü∫ÊñºÊ®°ÂûãÁöÑË©ï‰º∞Âô®‰æÜÊßãÂª∫ÂÅèÂ•ΩÂúñÂΩ¢ÔºåÁÑ∂ÂæåÈõÜÊàê‰∏¶Â∞çÈÄô‰∫õÂúñÂΩ¢ÈÄ≤Ë°åÂéªÂô™Ôºå‰ª•Áç≤ÂæóÊõ¥Â•Ω„ÄÅÁÑ°ÁüõÁõæÁöÑË©ï‰º∞ÁµêÊûú„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂåÖÂê´ÂÖ©ÂÄã‰∏ªË¶ÅÈöéÊÆµÔºöÂ∞áË©ï‰º∞ËÅöÂêàÂà∞‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÂúñÂΩ¢‰∏≠Ôºå‰∏¶ÊáâÁî®ÂéªÂô™Á®ãÂ∫è‰ª•Ê∂àÈô§Âæ™Áí∞‰∏ç‰∏ÄËá¥ÊÄßÔºåÁ¢∫‰øùÊúâÂêëÁÑ°Áí∞Âúñ (DAG) ÁµêÊßã„ÄÇÊàëÂÄëÁÇ∫ÊàëÂÄëÁöÑÊ°ÜÊû∂Êèê‰æõ‰∫ÜÁêÜË´ñ‰øùË≠âÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®ÊÅ¢Âæ©ÁúüÂØ¶ÂÅèÂ•ΩÁµêÊßãÊñπÈù¢ÁöÑÊïàÂäõ„ÄÇË∑®Ë∂äÂçÅÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåGED Âú®Ê®°ÂûãÊéíÂêç„ÄÅÂõûÊáâÈÅ∏ÊìáÂíåÊ®°ÂûãÂ∞çÈΩä‰ªªÂãô‰∏≠ÂÑ™ÊñºÂü∫Á∑öÊñπÊ≥ï„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåGED ÁµêÂêà‰∫Ü Llama3-8B„ÄÅMistral-7B Âíå Qwen2-7B Á≠âËºÉÂº±ÁöÑË©ï‰º∞Âô®Ôºå‰ª•Ë∂ÖË∂ä Qwen2-72B Á≠âËºÉÂº∑Ë©ï‰º∞Âô®ÁöÑÊÄßËÉΩÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂Â¢ûÂº∑Ë©ï‰º∞ÂèØÈù†ÊÄßÂíåÊîπÂñÑÊ®°ÂûãÊÄßËÉΩÁöÑËÉΩÂäõ„ÄÇ

##### **Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?**
2410.10083v2 by Yifan Feng, Chengwu Yang, Xingliang Hou, Shaoyi Du, Shihui Ying, Zongze Wu, Yue Gao

Existing benchmarks like NLGraph and GraphQA evaluate LLMs on graphs by
focusing mainly on pairwise relationships, overlooking the high-order
correlations found in real-world data. Hypergraphs, which can model complex
beyond-pairwise relationships, offer a more robust framework but are still
underexplored in the context of LLMs. To address this gap, we introduce
LLM4Hypergraph, the first comprehensive benchmark comprising 21,500 problems
across eight low-order, five high-order, and two isomorphism tasks, utilizing
both synthetic and real-world hypergraphs from citation networks and protein
structures. We evaluate six prominent LLMs, including GPT-4o, demonstrating our
benchmark's effectiveness in identifying model strengths and weaknesses. Our
specialized prompting framework incorporates seven hypergraph languages and
introduces two novel techniques, Hyper-BAG and Hyper-COT, which enhance
high-order reasoning and achieve an average 4% (up to 9%) performance
improvement on structure classification tasks. This work establishes a
foundational testbed for integrating hypergraph computational capabilities into
LLMs, advancing their comprehension. The source codes are at
https://github.com/iMoonLab/LLM4Hypergraph.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑ NLGraph Âíå GraphQA Á≠âÂü∫Ê∫ñ‰∏ªË¶ÅÈóúÊ≥®ÊàêÂ∞çÈóú‰øÇÔºåËÄåÂøΩÁï•‰∫ÜÂú®ÁèæÂØ¶‰∏ñÁïåË≥áÊñô‰∏≠ÁôºÁèæÁöÑÈ´òÈöéÁõ∏ÈóúÊÄßÔºåÂæûËÄåÂ∞çÂúñÂΩ¢‰∏≠ÁöÑ LLM ÈÄ≤Ë°åË©ï‰º∞„ÄÇË∂ÖÂúñÂèØ‰ª•Âª∫Ê®°Ë§áÈõúÁöÑË∂ÖË∂äÊàêÂ∞çÈóú‰øÇÔºåÊèê‰æõÊõ¥Âº∑Â§ßÁöÑÊ°ÜÊû∂Ôºå‰ΩÜÂú® LLM ÁöÑËÉåÊôØ‰∏ã‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü LLM4HypergraphÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÁ∂úÂêàÂü∫Ê∫ñÔºåÂåÖÂê´ 21,500 ÂÄãÂïèÈ°åÔºåÊ∂µËìãÂÖ´ÂÄã‰ΩéÈöé„ÄÅ‰∫îÂÄãÈ´òÈöéÂíåÂÖ©ÂÄãÂêåÊßã‰ªªÂãôÔºåÂà©Áî®‰æÜËá™ÂºïÊñáÁ∂≤Ë∑ØÂíåËõãÁôΩË≥™ÁµêÊßãÁöÑÂêàÊàêÂíåÁúüÂØ¶‰∏ñÁïåË∂ÖÂúñ„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÂÖ≠ÂÄãËëóÂêçÁöÑ LLMÔºåÂåÖÊã¨ GPT-4oÔºåË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÂü∫Ê∫ñÂú®Ë≠òÂà•Ê®°ÂûãÂÑ™Âã¢ÂíåÂä£Âã¢ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÂ∞àÊ•≠ÁöÑÊèêÁ§∫Ê°ÜÊû∂ÂåÖÂê´‰∏ÉÁ®ÆË∂ÖÂúñË™ûË®ÄÔºå‰∏¶ÂºïÂÖ•‰∫ÜÂÖ©Á®ÆÊñ∞ÊäÄË°ì Hyper-BAG Âíå Hyper-COTÔºåÂÆÉÂÄëÂ¢ûÂº∑‰∫ÜÈ´òÈöéÊé®ÁêÜÔºå‰∏¶Âú®ÁµêÊßãÂàÜÈ°û‰ªªÂãô‰∏äÂØ¶Áèæ‰∫ÜÂπ≥Âùá 4%ÔºàÊúÄÈ´ò 9%ÔºâÁöÑÊÄßËÉΩÊîπÈÄ≤„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Â∞áË∂ÖÂúñË®àÁÆóËÉΩÂäõÊï¥ÂêàÂà∞ LLM ‰∏≠Âª∫Á´ã‰∫Ü‰∏ÄÂÄãÂü∫Á§éÊ∏¨Ë©¶Âπ≥Âè∞ÔºåÂæûËÄåÊèêÂçá‰∫ÜÂÆÉÂÄëÁöÑÁêÜËß£Âäõ„ÄÇÊ∫ê‰ª£Á¢º‰ΩçÊñº https://github.com/iMoonLab/LLM4Hypergraph„ÄÇ

##### **Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation**
2410.09824v1 by Jiarui Ji, Runlin Lei, Jialing Bi, Zhewei Wei, Yankai Lin, Xuchen Pan, Yaliang Li, Bolin Ding

Graph generation is a fundamental task that has been extensively studied in
social, technological, and scientific analysis. For modeling the dynamic graph
evolution process, traditional rule-based methods struggle to capture community
structures within graphs, while deep learning methods only focus on fitting
training graphs. This limits existing graph generators to producing graphs that
adhere to predefined rules or closely resemble training datasets, achieving
poor performance in dynamic graph generation. Given that graphs are abstract
representations arising from pairwise interactions in human activities, a
realistic simulation of human-wise interaction could provide deeper insights
into the graph evolution mechanism. With the increasing recognition of large
language models (LLMs) in simulating human behavior, we introduce
GraphAgent-Generator (GAG), a novel simulation-based framework for dynamic
graph generation. Without training or fine-tuning process of LLM, our framework
effectively replicates seven macro-level structural characteristics in
established network science theories while surpassing existing baselines in
graph expansion tasks by 31\% on specific evaluation metrics. Through node
classification task, we validate GAG effectively preserves characteristics of
real-world network for node-wise textual features in generated text-rich graph.
Furthermore, by incorporating parallel acceleration, GAG supports generating
graphs with up to nearly 100,000 nodes or 10 million edges through large-scale
LLM-based agent simulation, with a minimum speed-up of 90.4\%. The source code
is available at https://anonymous.4open.science/r/GraphAgent-2206.

ÊëòË¶ÅÔºöÂúñË°®ÁîüÊàêÊòØ‰∏ÄÈ†ÖÂü∫Êú¨‰ªªÂãôÔºåÂ∑≤Âú®Á§æÊúÉ„ÄÅÊäÄË°ìÂíåÁßëÂ≠∏ÂàÜÊûê‰∏≠Âª£Ê≥õÁ†îÁ©∂„ÄÇÂ∞çÊñºÂª∫Ê®°ÂãïÊÖãÂúñË°®ÊºîÂåñÈÅéÁ®ãÔºåÂÇ≥Áµ±Âü∫ÊñºË¶èÂâáÁöÑÊñπÊ≥ïÈõ£‰ª•ÊçïÊçâÂúñË°®‰∏≠ÁöÑÁ§æÁæ§ÁµêÊßãÔºåËÄåÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÂÉÖÂ∞àÊ≥®ÊñºÊì¨ÂêàË®ìÁ∑¥ÂúñË°®„ÄÇÈÄôÈôêÂà∂‰∫ÜÁèæÊúâÁöÑÂúñË°®ÁîüÊàêÂô®Áî¢ÁîüÁ¨¶ÂêàÈ†êÂÆöÁæ©Ë¶èÂâáÊàñËàáË®ìÁ∑¥Ë≥áÊñôÈõÜÈùûÂ∏∏Áõ∏‰ººÁöÑÂúñË°®ÔºåÂú®ÂãïÊÖãÂúñË°®ÁîüÊàê‰∏≠Ë°®Áèæ‰∏ç‰Ω≥„ÄÇÁî±ÊñºÂúñË°®ÊòØÊ∫êËá™‰∫∫È°ûÊ¥ªÂãï‰∏≠ÊàêÂ∞ç‰∫íÂãïÁöÑÊäΩË±°Ë°®Á§∫ÔºåÂõ†Ê≠§Â∞ç‰∫∫È°û‰∫íÂãïÁöÑÈÄºÁúüÊ®°Êì¨ÂèØ‰ª•Êèê‰æõÂ∞çÂúñË°®ÊºîÂåñÊ©üÂà∂ÁöÑÊõ¥Ê∑±ÂÖ•Ë¶ãËß£„ÄÇÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ê®°Êì¨‰∫∫È°ûË°åÁÇ∫ÊñπÈù¢Áç≤ÂæóË∂ä‰æÜË∂äÂ§öÁöÑË™çÂèØÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü GraphAgent-Generator (GAG)ÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÂãïÊÖãÂúñË°®ÁîüÊàêÁöÑÂâµÊñ∞Âü∫ÊñºÊ®°Êì¨ÁöÑÊ°ÜÊû∂„ÄÇÂú®Ê≤íÊúâ LLM ÁöÑË®ìÁ∑¥ÊàñÂæÆË™øÈÅéÁ®ã‰∏≠ÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂ÊúâÊïàÂú∞Ë§áË£Ω‰∫ÜÂ∑≤Âª∫Á´ãÁöÑÁ∂≤Ë∑ØÁßëÂ≠∏ÁêÜË´ñ‰∏≠ÁöÑ‰∏ÉÂÄãÂ∑®ËßÄÂ±§Á¥öÁµêÊßãÁâπÂæµÔºåÂêåÊôÇÂú®ÂÖ∑È´îË©ï‰º∞ÊåáÊ®ô‰∏äË∂ÖË∂ä‰∫ÜÁèæÊúâÁöÑÂü∫Ê∫ñÔºåÂúñË°®Êì¥ÂÖÖ‰ªªÂãôÊèêÈ´ò‰∫Ü 31%„ÄÇÈÄèÈÅéÁØÄÈªûÂàÜÈ°û‰ªªÂãôÔºåÊàëÂÄëÈ©óË≠â GAG ÊúâÊïàÂú∞‰øùÁïô‰∫ÜÁîüÊàêÊñáÂ≠óË±êÂØåÂúñË°®‰∏≠ÁØÄÈªûÊñáÂ≠óÁâπÂæµÁöÑÁúüÂØ¶‰∏ñÁïåÁ∂≤Ë∑ØÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÈÄèÈÅéÁµêÂêà‰∏¶Ë°åÂä†ÈÄüÔºåGAG ÊîØÊè¥ÈÄèÈÅéÂ§ßË¶èÊ®° LLM Âü∫Êñº‰ª£ÁêÜÁöÑÊ®°Êì¨ÁîüÊàêÂ§öÈÅîËøë 100,000 ÂÄãÁØÄÈªûÊàñ 1,000 Ëê¨Ê¢ùÈÇäÁöÑÂúñË°®ÔºåÈÄüÂ∫¶ÊèêÂçáËá≥Â∞ë 90.4%„ÄÇÂéüÂßãÁ¢ºÂèØÂú® https://anonymous.4open.science/r/GraphAgent-2206 ÂèñÂæó„ÄÇ

##### **A Mixed-Language Multi-Document News Summarization Dataset and a Graphs-Based Extract-Generate Model**
2410.09773v1 by Shengxiang Gao, Fang nan, Yongbing Zhang, Yuxin Huang, Kaiwen Tan, Zhengtao Yu

Existing research on news summarization primarily focuses on single-language
single-document (SLSD), single-language multi-document (SLMD) or cross-language
single-document (CLSD). However, in real-world scenarios, news about a
international event often involves multiple documents in different languages,
i.e., mixed-language multi-document (MLMD). Therefore, summarizing MLMD news is
of great significance. However, the lack of datasets for MLMD news
summarization has constrained the development of research in this area. To fill
this gap, we construct a mixed-language multi-document news summarization
dataset (MLMD-news), which contains four different languages and 10,992 source
document cluster and target summary pairs. Additionally, we propose a
graph-based extract-generate model and benchmark various methods on the
MLMD-news dataset and publicly release our dataset and
code\footnote[1]{https://github.com/Southnf9/MLMD-news}, aiming to advance
research in summarization within MLMD scenarios.

ÊëòË¶ÅÔºöÁèæÊúâÊñ∞ËÅûÊëòË¶ÅÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÂñÆË™ûË®ÄÂñÆÊñá‰ª∂ (SLSD)„ÄÅÂñÆË™ûË®ÄÂ§öÊñá‰ª∂ (SLMD) ÊàñË∑®Ë™ûË®ÄÂñÆÊñá‰ª∂ (CLSD)„ÄÇÁÑ∂ËÄåÔºåÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØ‰∏≠ÔºåÂúãÈöõ‰∫ã‰ª∂ÁöÑÊñ∞ËÅûÈÄöÂ∏∏Ê∂âÂèä‰∏çÂêåË™ûË®ÄÁöÑÂ§öÂÄãÊñá‰ª∂ÔºåÂç≥Ê∑∑ÂêàË™ûË®ÄÂ§öÊñá‰ª∂ (MLMD)„ÄÇÂõ†Ê≠§ÔºåÂ∞ç MLMD Êñ∞ËÅûÈÄ≤Ë°åÊëòË¶ÅÂÖ∑ÊúâÈáçÂ§ßÊÑèÁæ©„ÄÇÁÑ∂ËÄåÔºåÁº∫‰πè MLMD Êñ∞ËÅûÊëòË¶ÅÁöÑÊï∏ÊìöÈõÜÈôêÂà∂‰∫ÜÈÄô‰∏ÄÈ†òÂüüÁöÑÁ†îÁ©∂ÁôºÂ±ï„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÊ∑∑ÂêàË™ûË®ÄÂ§öÊñá‰ª∂Êñ∞ËÅûÊëòË¶ÅÊï∏ÊìöÈõÜ (MLMD-news)ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂõõÁ®Æ‰∏çÂêåÁöÑË™ûË®ÄÂíå 10,992 ÂÄãÊ∫êÊñá‰ª∂Áæ§ÈõÜÂíåÁõÆÊ®ôÊëòË¶ÅÂ∞ç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂúñÁöÑÊèêÂèñÁîüÊàêÊ®°ÂûãÔºå‰∏¶Âú® MLMD-news Êï∏ÊìöÈõÜ‰∏äÂ∞çÂêÑÁ®ÆÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÂü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰∏¶ÂÖ¨ÈñãÁôºÂ∏ÉÊàëÂÄëÁöÑÊï∏ÊìöÈõÜÂíå‰ª£Á¢º\footnote[1]{https://github.com/Southnf9/MLMD-news}ÔºåÊó®Âú®Êé®ÈÄ≤ MLMD Â†¥ÊôØ‰∏≠ÁöÑÊëòË¶ÅÁ†îÁ©∂„ÄÇ

##### **Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG**
2410.09699v1 by Xinxi Chen, Li Wang, Wei Wu, Qi Tang, Yiyao Liu

Hallucination is a key roadblock for applications of Large Language Models
(LLMs), particularly for enterprise applications that are sensitive to
information accuracy. To address this issue, two general approaches have been
explored: Retrieval-Augmented Generation (RAG) to supply LLMs with updated
information as context, and fine-tuning the LLMs with new information and
desired output styles. In this paper, we propose Honest AI: a novel strategy to
fine-tune "small" language models to say "I don't know" to reduce
hallucination, along with several alternative RAG approaches. The solution
ranked 1st in Task 2 for the false premise question. The alternative approaches
include using RAG with search engine and knowledge graph results, fine-tuning
base LLMs with new information and combinations of both approaches. Although
all approaches improve the performance of the LLMs, RAG alone does not
significantly improve the performance and fine-tuning is needed for better
results. Finally, the hybrid approach achieved the highest score in the CRAG
benchmark. In addition, our approach emphasizes the use of relatively small
models with fewer than 10 billion parameters, promoting resource efficiency.

ÊëòË¶ÅÔºöÂπªË¶∫ÊòØÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊáâÁî®Á®ãÂºèÁöÑ‰∏ÄÂ§ßÈöúÁ§ôÔºåÁâπÂà•ÊòØÂ∞çË≥áË®äÊ∫ñÁ¢∫Â∫¶ÊïèÊÑüÁöÑ‰ºÅÊ•≠ÊáâÁî®Á®ãÂºè„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÂ∑≤Êé¢Ë®éÂÖ©Á®Æ‰∏ÄËà¨ÊñπÊ≥ïÔºöÊ™¢Á¥¢Êì¥ÂÖÖÁîüÊàê (RAG) ‰ª•Êèê‰æõ LLM Êõ¥Êñ∞ÁöÑË≥áË®ä‰ΩúÁÇ∫ËÉåÊôØÔºå‰ª•ÂèäÂæÆË™ø LLM ‰ª•Áç≤ÂæóÊñ∞ÁöÑË≥áË®äÂíåÊúüÊúõÁöÑËº∏Âá∫Ê®£Âºè„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ Honest AIÔºö‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁ≠ñÁï•ÔºåÂæÆË™ø„ÄåÂ∞èÂûã„ÄçË™ûË®ÄÊ®°Âûã‰ª•Ë°®ÈÅî„ÄåÊàë‰∏çÁü•ÈÅì„Äç‰ª•Ê∏õÂ∞ëÂπªË¶∫Ôºå‰ª•ÂèäÂÖ∂‰ªñÂπæÁ®ÆÊõø‰ª£ÁöÑ RAG ÊñπÊ≥ï„ÄÇË©≤Ëß£Ê±∫ÊñπÊ°àÂú®ËôõÂÅáÂâçÊèêÂïèÈ°åÁöÑ‰ªªÂãô 2 ‰∏≠ÊéíÂêçÁ¨¨ 1„ÄÇÊõø‰ª£ÊñπÊ≥ïÂåÖÊã¨‰ΩøÁî® RAG Êê≠ÈÖçÊêúÂ∞ãÂºïÊìéÂíåÁü•Ë≠òÂúñË≠úÁµêÊûú„ÄÅÂæÆË™øÂü∫Á§é LLM ‰ª•Áç≤ÂæóÊñ∞ÁöÑË≥áË®äÔºå‰ª•ÂèäÁµêÂêàÈÄôÂÖ©Á®ÆÊñπÊ≥ï„ÄÇÈõñÁÑ∂ÊâÄÊúâÊñπÊ≥ïÈÉΩÊîπÂñÑ‰∫Ü LLM ÁöÑÊïàËÉΩÔºå‰ΩÜÂÉÖ‰ΩøÁî® RAG ÁÑ°Ê≥ïÈ°ØËëóÊîπÂñÑÊïàËÉΩÔºåÈúÄË¶ÅÂæÆË™øÊâçËÉΩÁç≤ÂæóÊõ¥Â•ΩÁöÑÁµêÊûú„ÄÇÊúÄÂæåÔºåÊ∑∑ÂêàÊñπÊ≥ïÂú® CRAG Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Áç≤ÂæóÊúÄÈ´òÂàÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂº∑Ë™ø‰ΩøÁî®ÂèÉÊï∏Â∞ëÊñº 100 ÂÑÑÁöÑÂ∞èÂûãÊ®°ÂûãÔºå‰ª•‰øÉÈÄ≤Ë≥áÊ∫êÊïàÁéá„ÄÇ

##### **LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning**
2410.09541v1 by Jiachun Li, Pengfei Cao, Chenhao Wang, Zhuoran Jin, Yubo Chen, Kang Liu, Xiaojian Jiang, Jiexin Xu, Jun Zhao

Large language models (LLMs) sometimes demonstrate poor performance on
knowledge-intensive tasks, commonsense reasoning is one of them. Researchers
typically address these issues by retrieving related knowledge from knowledge
graphs or employing self-enhancement methods to elicit knowledge in LLMs.
However, noisy knowledge and invalid reasoning issues hamper their ability to
answer questions accurately. To this end, we propose a novel method named
eliciting, filtering and integrating knowledge in large language model
(LINKED). In it, we design a reward model to filter out the noisy knowledge and
take the marginal consistent reasoning module to reduce invalid reasoning. With
our comprehensive experiments on two complex commonsense reasoning benchmarks,
our method outperforms SOTA baselines (up to 9.0% improvement of accuracy).
Besides, to measure the positive and negative impact of the injected knowledge,
we propose a new metric called effectiveness-preservation score for the
knowledge enhancement works. Finally, through extensive experiments, we conduct
an in-depth analysis and find many meaningful conclusions about LLMs in
commonsense reasoning tasks.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊúâÊôÇÂú®Áü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãô‰∏äË°®Áèæ‰∏ç‰Ω≥ÔºåÂ∏∏Ë≠òÊé®ÁêÜÂ∞±ÊòØÂÖ∂‰∏≠‰πã‰∏Ä„ÄÇÁ†îÁ©∂‰∫∫Âì°ÈÄöÂ∏∏ÈÄöÈÅéÂæûÁü•Ë≠òÂúñË≠ú‰∏≠Ê™¢Á¥¢Áõ∏ÈóúÁü•Ë≠òÊàñÊé°Áî®Ëá™ÊàëÂ¢ûÂº∑ÊñπÊ≥ï‰æÜÂºïÁôº LLM ‰∏≠ÁöÑÁü•Ë≠ò‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÂòàÈõúÁöÑÁü•Ë≠òÂíåÁÑ°ÊïàÁöÑÊé®ÁêÜÂïèÈ°åÈòªÁ§ô‰∫ÜÂÆÉÂÄëÊ∫ñÁ¢∫ÂõûÁ≠îÂïèÈ°åÁöÑËÉΩÂäõ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫Â§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠Áü•Ë≠òÁöÑÂºïÂá∫„ÄÅÈÅéÊøæÂíåÊï¥ÂêàÔºàLINKEDÔºâÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÂú®ÂÖ∂‰∏≠ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÁçéÂãµÊ®°Âûã‰æÜÈÅéÊøæÊéâÂòàÈõúÁöÑÁü•Ë≠òÔºå‰∏¶Êé°Áî®ÈÇäÈöõ‰∏ÄËá¥Êé®ÁêÜÊ®°ÁµÑ‰æÜÊ∏õÂ∞ëÁÑ°ÊïàÊé®ÁêÜ„ÄÇÈÄöÈÅéÊàëÂÄëÂú®ÂÖ©ÂÄãË§áÈõúÁöÑÂ∏∏Ë≠òÊé®ÁêÜÂü∫Ê∫ñ‰∏äÁöÑÂÖ®Èù¢ÂØ¶È©óÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™Êñº SOTA Âü∫Ê∫ñÔºàÊ∫ñÁ¢∫ÁéáÊèêÈ´ò‰∫Ü 9.0%Ôºâ„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜË°°ÈáèÊ≥®ÂÖ•Áü•Ë≠òÁöÑÊ≠£Èù¢ÂíåË≤†Èù¢ÂΩ±ÈüøÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊåáÊ®ôÔºåÁ®±ÁÇ∫Áü•Ë≠òÂ¢ûÂº∑Â∑•‰ΩúÁöÑÊúâÊïàÊÄß‰øùÁïôÂàÜÊï∏„ÄÇÊúÄÂæåÔºåÈÄöÈÅéÂ§ßÈáèÁöÑÂØ¶È©óÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÊ∑±ÂÖ•ÁöÑÂàÜÊûêÔºå‰∏¶Âú®Â∏∏Ë≠òÊé®ÁêÜ‰ªªÂãô‰∏≠ÁôºÁèæ‰∫ÜË®±Â§öÈóúÊñº LLM ÁöÑÊúâÊÑèÁæ©ÁöÑÁµêË´ñ„ÄÇ

##### **Text Classification using Graph Convolutional Networks: A Comprehensive Survey**
2410.09399v1 by Syed Mustafa Haider Rizvi, Ramsha Imran, Arif Mahmood

Text classification is a quintessential and practical problem in natural
language processing with applications in diverse domains such as sentiment
analysis, fake news detection, medical diagnosis, and document classification.
A sizable body of recent works exists where researchers have studied and
tackled text classification from different angles with varying degrees of
success. Graph convolution network (GCN)-based approaches have gained a lot of
traction in this domain over the last decade with many implementations
achieving state-of-the-art performance in more recent literature and thus,
warranting the need for an updated survey. This work aims to summarize and
categorize various GCN-based Text Classification approaches with regard to the
architecture and mode of supervision. It identifies their strengths and
limitations and compares their performance on various benchmark datasets. We
also discuss future research directions and the challenges that exist in this
domain.

ÊëòË¶ÅÔºöÊñáÊú¨ÂàÜÈ°ûÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠‰∏ÄÂÄãÁ∂ìÂÖ∏‰∏îÂØ¶Áî®ÁöÑÂïèÈ°åÔºåÂú®ÊÉÖÁ∑íÂàÜÊûê„ÄÅÂÅáÊñ∞ËÅûÂÅµÊ∏¨„ÄÅÈÜ´ÁôÇË®∫Êñ∑ÂíåÊñá‰ª∂ÂàÜÈ°ûÁ≠âÈ†òÂüü‰∏≠ÈÉΩÊúâÊáâÁî®„ÄÇÊúÄËøëÊúâÂ§ßÈáèÁöÑÁ†îÁ©∂Êé¢Ë®éÊñáÊú¨ÂàÜÈ°ûÔºå‰∏¶Âæû‰∏çÂêåÁöÑËßíÂ∫¶ËëóÊâãÔºåÁç≤Âæó‰∫Ü‰∏çÂêåÁ®ãÂ∫¶ÁöÑÊàêÂäü„ÄÇÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑Ø (GCN) ÊñπÊ≥ïÂú®ÈÅéÂéªÂçÅÂπ¥‰∏≠Âú®ÈÄôÈ†òÂüüÁç≤Âæó‰∫ÜË®±Â§öÈóúÊ≥®ÔºåË®±Â§öÂØ¶‰ΩúÂú®ÊúÄËøëÁöÑÊñáÁçª‰∏≠ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂõ†Ê≠§ÊúâÂøÖË¶ÅÈÄ≤Ë°åÊõ¥Êñ∞ÁöÑË™øÊü•„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊó®Âú®ÈáùÂ∞çÊû∂ÊßãÂíåÁõ£Áù£Ê®°ÂºèÔºåÁ∏ΩÁµêÂíåÂàÜÈ°ûÂêÑÁ®ÆÂü∫Êñº GCN ÁöÑÊñáÊú¨ÂàÜÈ°ûÊñπÊ≥ï„ÄÇÂÆÉÊâæÂá∫ÂÆÉÂÄëÁöÑÂÑ™Áº∫ÈªûÔºå‰∏¶ÊØîËºÉÂÆÉÂÄëÂú®ÂêÑÁ®ÆÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÊïàËÉΩ„ÄÇÊàëÂÄë‰πüË®éË´ñ‰∫ÜÊú™‰æÜÁ†îÁ©∂ÊñπÂêëÂíåÈÄôÂÄãÈ†òÂüü‰∏≠Â≠òÂú®ÁöÑÊåëÊà∞„ÄÇ

##### **Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation**
2410.09350v1 by Jinyoung Park, Minseok Joo, Joo-Kyung Kim, Hyunwoo J. Kim

Knowledge graph-grounded dialog generation requires retrieving a
dialog-relevant subgraph from the given knowledge base graph and integrating it
with the dialog history. Previous works typically represent the graph using an
external encoder, such as graph neural networks, and retrieve relevant triplets
based on the similarity between single-vector representations of triplets and
the dialog history. However, these external encoders fail to leverage the rich
knowledge of pretrained language models, and the retrieval process is also
suboptimal due to the information bottleneck caused by the single-vector
abstraction of the dialog history. In this work, we propose Dialog generation
with Generative Subgraph Retrieval (DialogGSR), which retrieves relevant
knowledge subgraphs by directly generating their token sequences on top of
language models. For effective generative subgraph retrieval, we introduce two
key methods: (i) structure-aware knowledge graph linearization with
self-supervised graph-specific tokens and (ii) graph-constrained decoding
utilizing graph structural proximity-based entity informativeness scores for
valid and relevant generative retrieval. DialogGSR achieves state-of-the-art
performance in knowledge graph-grounded dialog generation, as demonstrated on
OpenDialKG and KOMODIS datasets.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠úÂ∞çË©±ÁîüÊàêÈúÄË¶ÅÂæûÁµ¶ÂÆöÁöÑÁü•Ë≠òÂ∫´ÂúñË≠ú‰∏≠Êì∑ÂèñËàáÂ∞çË©±Áõ∏ÈóúÁöÑÂ≠êÂúñÔºå‰∏¶Â∞áÂÖ∂ËàáÂ∞çË©±Ë®òÈåÑÊï¥Âêà„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ÈÄöÂ∏∏‰ΩøÁî®Â§ñÈÉ®Á∑®Á¢ºÂô®Ôºà‰æãÂ¶ÇÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÔºâ‰æÜË°®Á§∫ÂúñÂΩ¢Ôºå‰∏¶Ê†πÊìö‰∏âÂÖÉÁµÑÁöÑÂñÆÂêëÈáèË°®Á§∫ËàáÂ∞çË©±Ë®òÈåÑ‰πãÈñìÁöÑÁõ∏‰ººÊÄß‰æÜÊì∑ÂèñÁõ∏ÈóúÁöÑ‰∏âÂÖÉÁµÑ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂ§ñÈÉ®Á∑®Á¢ºÂô®ÁÑ°Ê≥ïÂà©Áî®È†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÁöÑË±êÂØåÁü•Ë≠òÔºåËÄåÊì∑ÂèñÈÅéÁ®ã‰πüÂõ†Â∞çË©±Ë®òÈåÑÁöÑÂñÆÂêëÈáèÊäΩË±°ÂåñÈÄ†ÊàêÁöÑË≥áË®äÁì∂È†∏ËÄåÊ¨°ÊñºÊúÄ‰Ω≥„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Â∏∂ÊúâÁîüÊàêÂ≠êÂúñÊì∑ÂèñÁöÑÂ∞çË©±ÁîüÊàêÔºàDialogGSRÔºâÔºåÂÆÉÁõ¥Êé•Âú®Ë™ûË®ÄÊ®°Âûã‰πã‰∏äÁîüÊàêÂÖ∂Ê®ôË®òÂ∫èÂàó‰æÜÊì∑ÂèñÁõ∏ÈóúÁöÑÁü•Ë≠òÂ≠êÂúñ„ÄÇÁÇ∫‰∫ÜÊúâÊïàÂú∞ÁîüÊàêÂ≠êÂúñÊì∑ÂèñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖ©Á®ÆÈóúÈçµÊñπÊ≥ïÔºöÔºà‰∏ÄÔºâÂÖ∑ÊúâËá™ÊàëÁõ£Áù£ÂúñÂΩ¢ÁâπÂÆöÊ®ôË®òÁöÑÁµêÊßãÊÑüÁü•Áü•Ë≠òÂúñÂΩ¢Á∑öÊÄßÂåñÔºå‰ª•ÂèäÔºà‰∫åÔºâÂà©Áî®ÂúñÂΩ¢ÁµêÊßãÈÑ∞ËøëÂ∫¶ÁÇ∫Âü∫Á§éÁöÑÂØ¶È´îË≥áË®äÊÄßÂàÜÊï∏ÈÄ≤Ë°åÂúñÂΩ¢Á¥ÑÊùüËß£Á¢ºÔºå‰ª•ÈÄ≤Ë°åÊúâÊïà‰∏îÁõ∏ÈóúÁöÑÁîüÊàêÊÄßÊì∑Âèñ„ÄÇDialogGSR Âú®Áü•Ë≠òÂúñË≠úÂ∞çË©±ÁîüÊàê‰∏≠ÂØ¶Áèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂ¶Ç OpenDialKG Âíå KOMODIS Ë≥áÊñôÈõÜÊâÄÁ§∫„ÄÇ

##### **Natural Language Counterfactual Explanations for Graphs Using Large Language Models**
2410.09295v1 by Flavio Giorgi, Cesare Campagnano, Fabrizio Silvestri, Gabriele Tolomei

Explainable Artificial Intelligence (XAI) has emerged as a critical area of
research to unravel the opaque inner logic of (deep) machine learning models.
Among the various XAI techniques proposed in the literature, counterfactual
explanations stand out as one of the most promising approaches. However, these
``what-if'' explanations are frequently complex and technical, making them
difficult for non-experts to understand and, more broadly, challenging for
humans to interpret. To bridge this gap, in this work, we exploit the power of
open-source Large Language Models to generate natural language explanations
when prompted with valid counterfactual instances produced by state-of-the-art
explainers for graph-based models. Experiments across several graph datasets
and counterfactual explainers show that our approach effectively produces
accurate natural language representations of counterfactual instances, as
demonstrated by key performance metrics.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∑≤ÊàêÁÇ∫Á†îÁ©∂È†òÂüü‰∏≠‰∏ÄÂÄãÈáçË¶ÅÁöÑÈ†òÂüüÔºåÁî®‰ª•Ëß£ÈñãÔºàÊ∑±Â∫¶ÔºâÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÂÖßÈÉ®ÈÇèËºØ„ÄÇÂú®ÊñáÁçª‰∏≠ÊèêÂá∫ÁöÑÂêÑÁ®Æ XAI ÊäÄË°ì‰∏≠ÔºåÂèç‰∫ãÂØ¶Ëß£ÈáãË¢´Ë™çÁÇ∫ÊòØÊúÄÊúâÂâçÈÄîÁöÑÊñπÊ≥ï‰πã‰∏Ä„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ„ÄåÂÅáË®≠ÊÄß„ÄçËß£ÈáãÈÄöÂ∏∏Ë§áÈõú‰∏îÊäÄË°ìÊÄßÔºåÈÄô‰ΩøÂæóÈùûÂ∞àÂÆ∂Èõ£‰ª•ÁêÜËß£ÔºåÊõ¥Âª£Ê≥õÂú∞Ë™™Ôºå‰∫∫È°ûÈõ£‰ª•Ëß£Èáã„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄôÂÄãÂ∑ÆË∑ùÔºåÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂà©Áî®ÈñãÊ∫êÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂäõÈáèÔºåÂú®ÊèêÁ§∫Áî±ÊúÄÂÖàÈÄ≤ÁöÑÂúñÂΩ¢Ê®°ÂûãËß£ÈáãÂô®Áî¢ÁîüÁöÑÊúâÊïàÂèç‰∫ãÂØ¶ÂØ¶‰æãÊôÇÔºåÁî¢ÁîüËá™ÁÑ∂Ë™ûË®ÄËß£Èáã„ÄÇË∑®Ë∂äÂπæÂÄãÂúñÂΩ¢Ë≥áÊñôÈõÜÂíåÂèç‰∫ãÂØ¶Ëß£ÈáãÂô®ÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÊïàÂú∞Áî¢ÁîüÂèç‰∫ãÂØ¶ÂØ¶‰æãÁöÑÊ∫ñÁ¢∫Ëá™ÁÑ∂Ë™ûË®ÄË°®Á§∫ÔºåÈÄôÁî±ÈóúÈçµÊïàËÉΩÊåáÊ®ôÊâÄË≠âÊòé„ÄÇ

##### **ReasonPlanner: Enhancing Autonomous Planning in Dynamic Environments with Temporal Knowledge Graphs and LLMs**
2410.09252v1 by Minh Pham Dinh, Munira Syed, Michael G Yankoski, Trenton W. Ford

Planning and performing interactive tasks, such as conducting experiments to
determine the melting point of an unknown substance, is straightforward for
humans but poses significant challenges for autonomous agents. We introduce
ReasonPlanner, a novel generalist agent designed for reflective thinking,
planning, and interactive reasoning. This agent leverages LLMs to plan
hypothetical trajectories by building a World Model based on a Temporal
Knowledge Graph. The agent interacts with the environment using a natural
language actor-critic module, where the actor translates the imagined
trajectory into a sequence of actionable steps, and the critic determines if
replanning is necessary. ReasonPlanner significantly outperforms previous
state-of-the-art prompting-based methods on the ScienceWorld benchmark by more
than 1.8 times, while being more sample-efficient and interpretable. It relies
solely on frozen weights thus requiring no gradient updates. ReasonPlanner can
be deployed and utilized without specialized knowledge of Machine Learning,
making it accessible to a wide range of users.

ÊëòË¶ÅÔºöË¶èÂäÉÂíåÂü∑Ë°å‰∫íÂãï‰ªªÂãôÔºå‰æãÂ¶ÇÈÄ≤Ë°åÂØ¶È©ó‰ª•Á¢∫ÂÆöÊú™Áü•Áâ©Ë≥™ÁöÑÁÜîÈªûÔºåÂ∞ç‰∫∫È°û‰æÜË™™ÂæàÁ∞°ÂñÆÔºå‰ΩÜÂ∞çËá™‰∏ª‰ª£ÁêÜ‰æÜË™™ÂçªÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü ReasonPlannerÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÈÄöÊâç‰ª£ÁêÜÔºåÂ∞àÈñÄÁî®ÊñºÂèçÊÄùÊÄßÊÄùËÄÉ„ÄÅË¶èÂäÉÂíå‰∫íÂãïÊé®ÁêÜ„ÄÇÊ≠§‰ª£ÁêÜÂà©Áî® LLM ÈÄèÈÅéÂª∫Á´ãÂü∫ÊñºÊôÇÂ∫èÁü•Ë≠òÂúñË°®ÁöÑ World Model ‰æÜË¶èÂäÉÂÅáË®≠ÊÄßËªåË∑°„ÄÇ‰ª£ÁêÜ‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄÁöÑÂãï‰Ωú-Ë©ïË´ñÊ®°ÁµÑËàáÁí∞Â¢É‰∫íÂãïÔºåÂÖ∂‰∏≠Âãï‰ΩúÂ∞áÊÉ≥ÂÉèÁöÑËªåË∑°ËΩâÊèõÁÇ∫‰∏ÄÁ≥ªÂàóÂèØÊìç‰ΩúÁöÑÊ≠•È©üÔºåËÄåË©ïË´ñÂâáÁ¢∫ÂÆöÊòØÂê¶ÈúÄË¶ÅÈáçÊñ∞Ë¶èÂäÉ„ÄÇReasonPlanner Âú® ScienceWorld Âü∫Ê∫ñ‰∏äÂ§ßÂπÖÂÑ™ÊñºÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤ÊèêÁ§∫ÂºèÊñπÊ≥ïÔºåÂÑ™Êñº 1.8 ÂÄçÔºåÂêåÊôÇÊõ¥ÂÖ∑Ê®£Êú¨ÊïàÁéáÂíåÂèØËß£ÈáãÊÄß„ÄÇÂÆÉÂÉÖ‰æùË≥¥ÂáçÁµêÊ¨äÈáçÔºåÂõ†Ê≠§‰∏çÈúÄË¶ÅÊ¢ØÂ∫¶Êõ¥Êñ∞„ÄÇReasonPlanner ÂèØ‰ª•ÈÉ®ÁΩ≤Âíå‰ΩøÁî®ÔºåËÄåÁÑ°ÈúÄÊ©üÂô®Â≠∏ÁøíÁöÑÂ∞àÊ•≠Áü•Ë≠òÔºåËÆìÂª£Ê≥õÁöÑ‰ΩøÁî®ËÄÖÈÉΩËÉΩ‰ΩøÁî®„ÄÇ

##### **Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective**
2410.08985v1 by Bo Ni, Yu Wang, Lu Cheng, Erik Blasch, Tyler Derr

Recently, Knowledge Graphs (KGs) have been successfully coupled with Large
Language Models (LLMs) to mitigate their hallucinations and enhance their
reasoning capability, such as in KG-based retrieval-augmented frameworks.
However, current KG-LLM frameworks lack rigorous uncertainty estimation,
limiting their reliable deployment in high-stakes applications. Directly
incorporating uncertainty quantification into KG-LLM frameworks presents
challenges due to their complex architectures and the intricate interactions
between the knowledge graph and language model components. To address this gap,
we propose a new trustworthy KG-LLM framework, Uncertainty Aware
Knowledge-Graph Reasoning (UAG), which incorporates uncertainty quantification
into the KG-LLM framework. We design an uncertainty-aware multi-step reasoning
framework that leverages conformal prediction to provide a theoretical
guarantee on the prediction set. To manage the error rate of the multi-step
process, we additionally introduce an error rate control module to adjust the
error rate within the individual components. Extensive experiments show that
our proposed UAG can achieve any pre-defined coverage rate while reducing the
prediction set/interval size by 40% on average over the baselines.

ÊëòË¶ÅÔºöÊúÄËøëÔºåÁü•ËØÜÂõæË∞± (KG) Â∑≤ÊàêÂäü‰∏éÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁªìÂêàÔºå‰ª•ÂáèËΩªÂÖ∂ÂπªËßâÂπ∂Â¢ûÂº∫ÂÖ∂Êé®ÁêÜËÉΩÂäõÔºå‰æãÂ¶ÇÂü∫‰∫é KG ÁöÑÊ£ÄÁ¥¢Â¢ûÂº∫Ê°ÜÊû∂„ÄÇ
ÁÑ∂ËÄåÔºåÂΩìÂâçÁöÑ KG-LLM Ê°ÜÊû∂Áº∫‰πè‰∏•Ê†ºÁöÑ‰∏çÁ°ÆÂÆöÊÄß‰º∞ËÆ°ÔºåÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®È´òÈ£éÈô©Â∫îÁî®Á®ãÂ∫è‰∏≠ÁöÑÂèØÈù†ÈÉ®ÁΩ≤„ÄÇÁî±‰∫éÂÖ∂Â§çÊùÇÁöÑÊû∂ÊûÑ‰ª•ÂèäÁü•ËØÜÂõæË∞±‰∏éËØ≠Ë®ÄÊ®°ÂûãÁªÑ‰ª∂‰πãÈó¥ÁöÑÂ§çÊùÇ‰∫§‰∫íÔºåÂ∞Ü‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñÁõ¥Êé•Á∫≥ÂÖ• KG-LLM Ê°ÜÊû∂ÊèêÂá∫‰∫ÜÊåëÊàò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂèØ‰ø°Ëµñ KG-LLM Ê°ÜÊû∂ÔºåÂç≥‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•Áü•ËØÜÂõæÊé®ÁêÜ (UAG)ÔºåÂÆÉÂ∞Ü‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñÁ∫≥ÂÖ• KG-LLM Ê°ÜÊû∂„ÄÇÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏Ä‰∏™‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•Â§öÊ≠•È™§Êé®ÁêÜÊ°ÜÊû∂ÔºåÂÆÉÂà©Áî®ÂÖ±ÂΩ¢È¢ÑÊµã‰∏∫È¢ÑÊµãÈõÜÊèê‰æõÁêÜËÆ∫‰øùËØÅ„ÄÇ‰∏∫‰∫ÜÁÆ°ÁêÜÂ§öÊ≠•È™§ËøáÁ®ãÁöÑÈîôËØØÁéáÔºåÊàë‰ª¨Âè¶Â§ñÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ÈîôËØØÁéáÊéßÂà∂Ê®°ÂùóÔºå‰ª•Ë∞ÉÊï¥ÂêÑ‰∏™ÁªÑ‰ª∂ÂÜÖÁöÑÈîôËØØÁéá„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑ UAG ÂèØ‰ª•ËææÂà∞‰ªª‰ΩïÈ¢ÑÂÆö‰πâÁöÑË¶ÜÁõñÁéáÔºåÂêåÊó∂Â∞ÜÈ¢ÑÊµãÈõÜ/Âå∫Èó¥Â§ßÂ∞èÂπ≥ÂùáÂáèÂ∞ë 40%ÔºåÈ´ò‰∫éÂü∫Á∫ø„ÄÇ

##### **When Graph meets Multimodal: Benchmarking on Multimodal Attributed Graphs Learning**
2410.09132v1 by Hao Yan, Chaozhuo Li, Zhigang Yu, Jun Yin, Ruochen Liu, Peiyan Zhang, Weihao Han, Mingzheng Li, Zhengxin Zeng, Hao Sun, Weiwei Deng, Feng Sun, Qi Zhang, Senzhang Wang

Multimodal attributed graphs (MAGs) are prevalent in various real-world
scenarios and generally contain two kinds of knowledge: (a) Attribute knowledge
is mainly supported by the attributes of different modalities contained in
nodes (entities) themselves, such as texts and images. (b) Topology knowledge,
on the other hand, is provided by the complex interactions posed between nodes.
The cornerstone of MAG representation learning lies in the seamless integration
of multimodal attributes and topology. Recent advancements in Pre-trained
Language/Vision models (PLMs/PVMs) and Graph neural networks (GNNs) have
facilitated effective learning on MAGs, garnering increased research interest.
However, the absence of meaningful benchmark datasets and standardized
evaluation procedures for MAG representation learning has impeded progress in
this field. In this paper, we propose Multimodal Attribute Graph Benchmark
(MAGB)}, a comprehensive and diverse collection of challenging benchmark
datasets for MAGs. The MAGB datasets are notably large in scale and encompass a
wide range of domains, spanning from e-commerce networks to social networks. In
addition to the brand-new datasets, we conduct extensive benchmark experiments
over MAGB with various learning paradigms, ranging from GNN-based and PLM-based
methods, to explore the necessity and feasibility of integrating multimodal
attributes and graph topology. In a nutshell, we provide an overview of the MAG
datasets, standardized evaluation procedures, and present baseline experiments.
The entire MAGB project is publicly accessible at
https://github.com/sktsherlock/ATG.

ÊëòË¶ÅÔºö<paragraph>Â§öÊ®°ÊÖãÂ±¨ÊÄßÂúñ (MAG) Âú®ÂêÑÁ®ÆÁúüÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØ‰∏≠ÂæàÂ∏∏Ë¶ãÔºåÈÄöÂ∏∏ÂåÖÂê´ÂÖ©Á®ÆÈ°ûÂûãÁöÑÁü•Ë≠òÔºö(a) Â±¨ÊÄßÁü•Ë≠ò‰∏ªË¶ÅÁî±ÁØÄÈªûÔºàÂØ¶È´îÔºâÊú¨Ë∫´ÊâÄÂåÖÂê´ÁöÑ‰∏çÂêåÊ®°ÊÖãÁöÑÂ±¨ÊÄßÊèê‰æõÊîØÊè¥Ôºå‰æãÂ¶ÇÊñáÂ≠óÂíåÂúñÂÉè„ÄÇ(b) Âè¶‰∏ÄÊñπÈù¢ÔºåÊãìÊí≤Áü•Ë≠òÂâáÊòØÁî±ÁØÄÈªû‰πãÈñìÊèêÂá∫ÁöÑË§áÈõú‰∫íÂãïÊèê‰æõ„ÄÇMAG Ë°®Á§∫ÂºèÂ≠∏ÁøíÁöÑÂü∫Áü≥Âú®ÊñºÂ§öÊ®°ÊÖãÂ±¨ÊÄßÂíåÊãìÊí≤ÁöÑÁÑ°Á∏´Êï¥Âêà„ÄÇÈ†êË®ìÁ∑¥Ë™ûË®Ä/Ë¶ñË¶∫Ê®°Âûã (PLM/PVM) ÂíåÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ï‰øÉÈÄ≤‰∫ÜÂ∞ç MAG ÁöÑÊúâÊïàÂ≠∏ÁøíÔºåÂºïËµ∑‰∫ÜË∂ä‰æÜË∂äÂ§öÁöÑÁ†îÁ©∂ËààË∂£„ÄÇÁÑ∂ËÄåÔºåÁº∫‰πèÊúâÊÑèÁæ©ÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜÂíåÊ®ôÊ∫ñÂåñÁöÑ MAG Ë°®Á§∫ÂºèÂ≠∏ÁøíË©ï‰º∞Á®ãÂ∫èÈòªÁ§ô‰∫ÜË©≤È†òÂüüÁöÑÈÄ≤Â±ï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ§öÊ®°ÊÖãÂ±¨ÊÄßÂúñÂü∫Ê∫ñ (MAGB)ÔºåÈÄôÊòØÈáùÂ∞ç MAG ÁöÑÂÖ®Èù¢‰∏îÂ§öÊ®£ÂåñÁöÑÊåëÊà∞ÊÄßÂü∫Ê∫ñË≥áÊñôÈõÜÈõÜÂêà„ÄÇMAGB Ë≥áÊñôÈõÜÁöÑË¶èÊ®°È°ØËëóÈæêÂ§ßÔºåÊ∂µËìã‰∫ÜÂæûÈõªÂ≠êÂïÜÂãôÁ∂≤Ë∑ØÂà∞Á§æ‰∫§Á∂≤Ë∑ØÁöÑÂª£Ê≥õÈ†òÂüü„ÄÇÈô§‰∫ÜÂÖ®Êñ∞ÁöÑË≥áÊñôÈõÜÂ§ñÔºåÊàëÂÄëÈÇÑ‰ΩøÁî®ÂêÑÁ®ÆÂ≠∏ÁøíÁØÑ‰æãÂ∞ç MAGB ÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂü∫Ê∫ñÂØ¶È©óÔºåÂæûÂü∫Êñº GNN ÂíåÂü∫Êñº PLM ÁöÑÊñπÊ≥ïÔºå‰ª•Êé¢Á¥¢Êï¥ÂêàÂ§öÊ®°ÊÖãÂ±¨ÊÄßÂíåÂúñÂΩ¢ÊãìÊí≤ÁöÑÂøÖË¶ÅÊÄßÂíåÂèØË°åÊÄß„ÄÇÁ∞°ËÄåË®Ä‰πãÔºåÊàëÂÄëÊèê‰æõ‰∫Ü MAG Ë≥áÊñôÈõÜ„ÄÅÊ®ôÊ∫ñÂåñË©ï‰º∞Á®ãÂ∫èÁöÑÊ¶ÇËø∞Ôºå‰∏¶ÊèêÂá∫‰∫ÜÂü∫Ê∫ñÂØ¶È©ó„ÄÇÊï¥ÂÄã MAGB Â∞àÊ°àÂèØÂú® https://github.com/sktsherlock/ATG ÂÖ¨ÈñãÂèñÂæó„ÄÇ</paragraph>

##### **GIVE: Structured Reasoning with Knowledge Graph Inspired Veracity Extrapolation**
2410.08475v1 by Jiashu He, Mingyu Derek Ma, Jinxuan Fan, Dan Roth, Wei Wang, Alejandro Ribeiro

Existing retrieval-based reasoning approaches for large language models
(LLMs) heavily rely on the density and quality of the non-parametric knowledge
source to provide domain knowledge and explicit reasoning chain. However,
inclusive knowledge sources are expensive and sometimes infeasible to build for
scientific or corner domains. To tackle the challenges, we introduce Graph
Inspired Veracity Extrapolation (GIVE), a novel reasoning framework that
integrates the parametric and non-parametric memories to enhance both knowledge
retrieval and faithful reasoning processes on very sparse knowledge graphs. By
leveraging the external structured knowledge to inspire LLM to model the
interconnections among relevant concepts, our method facilitates a more logical
and step-wise reasoning approach akin to experts' problem-solving, rather than
gold answer retrieval. Specifically, the framework prompts LLMs to decompose
the query into crucial concepts and attributes, construct entity groups with
relevant entities, and build an augmented reasoning chain by probing potential
relationships among node pairs across these entity groups. Our method
incorporates both factual and extrapolated linkages to enable comprehensive
understanding and response generation. Extensive experiments on
reasoning-intense benchmarks on biomedical and commonsense QA demonstrate the
effectiveness of our proposed method. Specifically, GIVE enables GPT3.5-turbo
to outperform advanced models like GPT4 without any additional training cost,
thereby underscoring the efficacy of integrating structured information and
internal reasoning ability of LLMs for tackling specialized tasks with limited
external resources.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂü∫ÊñºÊ™¢Á¥¢ÁöÑÊé®ÁêÜÊñπÊ≥ïÂ∞çÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âö¥Èáç‰æùË≥¥ÈùûÂèÉÊï∏Áü•Ë≠ò‰æÜÊ∫êÁöÑÂØÜÂ∫¶ÂíåÂìÅË≥™Ôºå‰ª•Êèê‰æõÈ†òÂüüÁü•Ë≠òÂíåÊòéÁ¢∫ÁöÑÊé®ÁêÜÈèà„ÄÇÁÑ∂ËÄåÔºåÂåÖÂÆπÊÄßÁöÑÁü•Ë≠ò‰æÜÊ∫êÂæàÊòÇË≤¥ÔºåÊúâÊôÇÂ∞çÊñºÁßëÂ≠∏ÊàñËßíËêΩÈ†òÂüü‰æÜË™™ÔºåÂª∫Á´ãËµ∑‰æÜ‰πü‰∏çÂèØË°å„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂúñÂΩ¢ÂïüÁôºÁúüÂØ¶Êé®Êñ∑ (GIVE)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊé®ÁêÜÊû∂ÊßãÔºåÂÆÉÊï¥Âêà‰∫ÜÂèÉÊï∏ÂíåÈùûÂèÉÊï∏Ë®òÊÜ∂È´îÔºå‰ª•Â¢ûÂº∑Âú®ÈùûÂ∏∏Á®ÄÁñèÁöÑÁü•Ë≠òÂúñË≠ú‰∏äÈÄ≤Ë°åÁü•Ë≠òÊ™¢Á¥¢ÂíåÂø†ÂØ¶Êé®ÁêÜÈÅéÁ®ã„ÄÇÈÄèÈÅéÂà©Áî®Â§ñÈÉ®ÁµêÊßãÂåñÁü•Ë≠ò‰æÜÊøÄÂãµ LLM Ê®°Êì¨Áõ∏ÈóúÊ¶ÇÂøµ‰πãÈñìÁöÑÁõ∏‰∫íÈóúËÅØÔºåÊàëÂÄëÁöÑÊäÄË°ì‰øÉÈÄ≤‰∫Ü‰∏ÄÁ®ÆÊõ¥Âêà‰πéÈÇèËºØ‰∏îÂæ™Â∫èÊº∏ÈÄ≤ÁöÑÊé®ÁêÜÊñπÊ≥ïÔºåÈ°û‰ººÊñºÂ∞àÂÆ∂ÁöÑÂïèÈ°åËß£Ê±∫ÔºåËÄå‰∏çÊòØÈªÉÈáëÁ≠îÊ°àÊ™¢Á¥¢„ÄÇÂÖ∑È´î‰æÜË™™ÔºåË©≤Êû∂ÊßãÊèêÁ§∫ LLM Â∞áÊü•Ë©¢ÂàÜËß£ÁÇ∫ÈóúÈçµÊ¶ÇÂøµÂíåÂ±¨ÊÄßÔºå‰ΩøÁî®Áõ∏ÈóúÂØ¶È´îÂª∫ÊßãÂØ¶È´îÁæ§ÁµÑÔºå‰∏¶ÈÄèÈÅéÊé¢Êü•ÈÄô‰∫õÂØ¶È´îÁæ§ÁµÑ‰∏≠ÁØÄÈªûÂ∞ç‰πãÈñìÁöÑÊΩõÂú®Èóú‰øÇ‰æÜÂª∫Á´ãÂ¢ûÂº∑ÁöÑÊé®ÁêÜÈèà„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÁµêÂêà‰∫Ü‰∫ãÂØ¶ÂíåÂ§ñÊé®ÈóúËÅØÔºå‰ª•ÂØ¶ÁèæÂÖ®Èù¢ÁöÑÁêÜËß£ÂíåÂõûÊáâÁî¢Áîü„ÄÇÂú®ÁîüÁâ©ÈÜ´Â≠∏ÂíåÂ∏∏Ë≠òÂïèÁ≠î‰∏äÂ∞çÊé®ÁêÜÂØÜÈõÜÂü∫Ê∫ñÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∑È´î‰æÜË™™ÔºåGIVE ‰Ωø GPT3.5-turbo ËÉΩÂ§†Âú®Ê≤íÊúâ‰ªª‰ΩïÈ°çÂ§ñË®ìÁ∑¥ÊàêÊú¨ÁöÑÊÉÖÊ≥Å‰∏ãÂÑ™Êñº GPT4 Á≠âÈÄ≤ÈöéÊ®°ÂûãÔºåÂæûËÄåÂº∑Ë™ø‰∫ÜÊï¥ÂêàÁµêÊßãÂåñË≥áË®äÂíå LLM ÂÖßÈÉ®Êé®ÁêÜËÉΩÂäõÂ∞çÊñºËôïÁêÜÂÖ∑ÊúâÊúâÈôêÂ§ñÈÉ®Ë≥áÊ∫êÁöÑÂ∞àÊ•≠‰ªªÂãôÁöÑÊïàËÉΩ„ÄÇ

##### **Privately Learning from Graphs with Applications in Fine-tuning Large Language Models**
2410.08299v1 by Haoteng Yin, Rongzhe Wei, Eli Chien, Pan Li

Graphs offer unique insights into relationships and interactions between
entities, complementing data modalities like text, images, and videos. By
incorporating relational information from graph data, AI models can extend
their capabilities beyond traditional tasks. However, relational data in
sensitive domains such as finance and healthcare often contain private
information, making privacy preservation crucial. Existing privacy-preserving
methods, such as DP-SGD, which rely on gradient decoupling assumptions, are not
well-suited for relational learning due to the inherent dependencies between
coupled training samples. To address this challenge, we propose a
privacy-preserving relational learning pipeline that decouples dependencies in
sampled relations during training, ensuring differential privacy through a
tailored application of DP-SGD. We apply this method to fine-tune large
language models (LLMs) on sensitive graph data, and tackle the associated
computational complexities. Our approach is evaluated on LLMs of varying sizes
(e.g., BERT, Llama2) using real-world relational data from four text-attributed
graphs. The results demonstrate significant improvements in relational learning
tasks, all while maintaining robust privacy guarantees during training.
Additionally, we explore the trade-offs between privacy, utility, and
computational efficiency, offering insights into the practical deployment of
our approach. Code is available at https://github.com/Graph-COM/PvGaLM.

ÊëòË¶ÅÔºöÂúñË°®Êèê‰æõÈóúÊñºÂØ¶È´î‰πãÈñìÈóú‰øÇÂíå‰∫íÂãïÁöÑÁç®ÁâπË¶ãËß£ÔºåË£úÂÖÖ‰∫ÜÊñáÊú¨„ÄÅÂΩ±ÂÉèÂíåÂΩ±ÁâáÁ≠âË≥áÊñôÊ®°Âºè„ÄÇÈÄèÈÅéÁ¥çÂÖ•‰æÜËá™ÂúñË°®Ë≥áÊñôÁöÑÈóú‰øÇË≥áË®äÔºåAI Ê®°ÂûãÂèØ‰ª•Â∞áÂÖ∂ÂäüËÉΩÂª∂‰º∏Âà∞ÂÇ≥Áµ±‰ªªÂãô‰πãÂ§ñ„ÄÇÁÑ∂ËÄåÔºåÊïèÊÑüÈ†òÂüüÔºà‰æãÂ¶ÇÈáëËûçÂíåÈÜ´ÁôÇ‰øùÂÅ•Ôºâ‰∏≠ÁöÑÈóú‰øÇË≥áÊñôÈÄöÂ∏∏ÂåÖÂê´ÁßÅ‰∫∫Ë≥áË®äÔºåÂõ†Ê≠§Èö±ÁßÅ‰øùË≠∑Ëá≥ÈóúÈáçË¶Å„ÄÇÁèæÊúâÁöÑÈö±ÁßÅ‰øùË≠∑ÊñπÊ≥ïÔºà‰æãÂ¶Ç DP-SGDÔºâÔºå‰æùË≥¥ÊñºÊ¢ØÂ∫¶Ëß£ËÄ¶ÂÅáË®≠ÔºåÁî±ÊñºËÄ¶ÂêàË®ìÁ∑¥Ê®£Êú¨‰πãÈñìÁöÑÂÖßÂú®‰æùË≥¥ÊÄßÔºå‰∏¶‰∏çÈÅ©ÂêàÈóú‰øÇÂ≠∏Áøí„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÈö±ÁßÅ‰øùË≠∑Èóú‰øÇÂ≠∏ÁøíÁÆ°ÈÅìÔºåÂú®Ë®ìÁ∑¥ÊúüÈñìËß£ËÄ¶ÂèñÊ®£Èóú‰øÇ‰∏≠ÁöÑ‰æùË≥¥ÊÄßÔºåÈÄèÈÅéÂÆ¢Ë£ΩÂåñÊáâÁî® DP-SGD ‰æÜÁ¢∫‰øùÂ∑ÆÁï∞Èö±ÁßÅ„ÄÇÊàëÂÄëÂ∞áÊ≠§ÊñπÊ≥ïÊáâÁî®ÊñºÊïèÊÑüÂúñË°®Ë≥áÊñô‰∏äÂæÆË™øÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºå‰∏¶Ëß£Ê±∫Áõ∏ÈóúÁöÑË®àÁÆóË§áÈõúÊÄß„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂú®‰∏çÂêåÂ§ßÂ∞èÁöÑ LLMÔºà‰æãÂ¶Ç BERT„ÄÅLlama2Ôºâ‰∏äÈÄ≤Ë°åË©ï‰º∞Ôºå‰ΩøÁî®‰æÜËá™ÂõõÂÄãÊñáÂ≠óÂ±¨ÊÄßÂúñË°®ÁöÑÁúüÂØ¶‰∏ñÁïåÈóú‰øÇË≥áÊñô„ÄÇÁµêÊûúË≠âÊòéÈóú‰øÇÂ≠∏Áøí‰ªªÂãôÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÂêåÊôÇÂú®Ë®ìÁ∑¥ÊúüÈñìÁ∂≠ÊåÅÂº∑Â§ßÁöÑÈö±ÁßÅ‰øùË≠â„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®éÈö±ÁßÅ„ÄÅÊïàÁî®ÂíåË®àÁÆóÊïàÁéá‰πãÈñìÁöÑÊ¨äË°°ÔºåÊèê‰æõÂ∞çÊàëÂÄëÊñπÊ≥ïÂØ¶ÈöõÈÉ®ÁΩ≤ÁöÑË¶ãËß£„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Graph-COM/PvGaLM ÂèñÂæó„ÄÇ

##### **Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study over Open-ended Question Answering**
2410.08085v1 by Yuan Sui, Bryan Hooi

Recent works integrating Knowledge Graphs (KGs) have led to promising
improvements in enhancing reasoning accuracy of Large Language Models (LLMs).
However, current benchmarks mainly focus on closed tasks, leaving a gap in the
assessment of more complex, real-world scenarios. This gap has also obscured
the evaluation of KGs' potential to mitigate the problem of hallucination in
LLMs. To fill the gap, we introduce OKGQA, a new benchmark specifically
designed to assess LLMs enhanced with KGs under open-ended, real-world question
answering scenarios. OKGQA is designed to closely reflect the complexities of
practical applications using questions from different types, and incorporates
specific metrics to measure both the reduction in hallucinations and the
enhancement in reasoning capabilities. To consider the scenario in which KGs
may have varying levels of mistakes, we further propose another experiment
setting OKGQA-P to assess model performance when the semantics and structure of
KGs are deliberately perturbed and contaminated. OKGQA aims to (1) explore
whether KGs can make LLMs more trustworthy in an open-ended setting, and (2)
conduct a comparative analysis to shed light on methods and future directions
for leveraging KGs to reduce LLMs' hallucination. We believe that this study
can facilitate a more complete performance comparison and encourage continuous
improvement in integrating KGs with LLMs.

ÊëòË¶ÅÔºöËøëÊúüÁöÑÁü•ËØÜÂõæË∞± (KG) Êï¥ÂêàÁ†îÁ©∂ÔºåÂ∑≤ÊèêÂçáÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Êé®ÁêÜÂáÜÁ°ÆÂ∫¶ÁöÑË°®Áé∞„ÄÇ
ÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÂü∫ÂáÜÊµãËØï‰∏ªË¶ÅÁùÄÈáç‰∫éÂ∞ÅÈó≠Âºè‰ªªÂä°ÔºåÂú®ËØÑ‰º∞Êõ¥Â§çÊùÇ„ÄÅÊõ¥ÂÆûÈôÖÁöÑÂú∫ÊôØÊó∂Â≠òÂú®Áº∫Âè£„ÄÇÊ≠§Áº∫Âè£‰πüÊ®°Á≥ä‰∫ÜÁü•ËØÜÂõæË∞±Âú®ÂáèËΩª LLM ÂπªËßâÈóÆÈ¢ò‰∏äÁöÑÊΩúÂäõËØÑ‰º∞„ÄÇ‰∏∫‰∫ÜÂ°´Ë°•Ê≠§Áº∫Âè£ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü OKGQAÔºåËøôÊòØ‰∏Ä‰∏™‰∏ìÈó®ËÆæËÆ°Áî®Êù•ËØÑ‰º∞Âú®ÂºÄÊîæÂºè„ÄÅÂÆûÈôÖÈóÆÁ≠îÂú∫ÊôØ‰∏≠ÔºåÂ¢ûÂº∫‰∫ÜÁü•ËØÜÂõæË∞±ÁöÑ LLM ÁöÑÊñ∞Âü∫ÂáÜÊµãËØï„ÄÇOKGQA Êó®Âú®Á¥ßÂØÜÂèçÊò†ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂ§çÊùÇÊÄßÔºå‰ΩøÁî®‰∏çÂêåÁ±ªÂûãÁöÑÈ¢òÁõÆÔºåÂπ∂Á∫≥ÂÖ•ÁâπÂÆöÊåáÊ†áÊù•Ë°°ÈáèÂπªËßâÁöÑÂáèÂ∞ëÂíåÊé®ÁêÜËÉΩÂäõÁöÑÂ¢ûÂº∫„ÄÇ‰∏∫‰∫ÜËÄÉËôëÁü•ËØÜÂõæË∞±ÂèØËÉΩÂ≠òÂú®‰∏çÂêåÁ®ãÂ∫¶ÈîôËØØÁöÑÂú∫ÊôØÔºåÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ÊèêÂá∫‰∫ÜÂè¶‰∏Ä‰∏™ÂÆûÈ™åËÆæÁΩÆ OKGQA-PÔºå‰ª•ËØÑ‰º∞ÂΩìÁü•ËØÜÂõæË∞±ÁöÑËØ≠‰πâÂíåÁªìÊûÑË¢´ÊïÖÊÑèÊâ∞Âä®ÂíåÊ±°ÊüìÊó∂ÁöÑÊ®°ÂûãÊÄßËÉΩ„ÄÇOKGQA Êó®Âú® (1) Êé¢Á¥¢Áü•ËØÜÂõæË∞±ÊòØÂê¶ËÉΩ‰Ωø LLM Âú®ÂºÄÊîæÂºèËÆæÁΩÆ‰∏≠Êõ¥ÂÄºÂæó‰ø°ËµñÔºå‰ª•Âèä (2) ËøõË°åÊØîËæÉÂàÜÊûêÔºå‰ª•ÈòêÊòéÂà©Áî®Áü•ËØÜÂõæË∞±Êù•ÂáèÂ∞ë LLM ÂπªËßâÁöÑÊñπÊ≥ïÂíåÊú™Êù•ÊñπÂêë„ÄÇÊàë‰ª¨Áõ∏‰ø°ËøôÈ°πÁ†îÁ©∂ÂèØ‰ª•‰øÉËøõÊõ¥ÂÆåÊï¥ÁöÑÊÄßËÉΩÊØîËæÉÔºåÂπ∂ÈºìÂä±ÊåÅÁª≠ÊîπËøõÁü•ËØÜÂõæË∞±‰∏é LLM ÁöÑÊï¥Âêà„ÄÇ

##### **Disease Entity Recognition and Normalization is Improved with Large Language Model Derived Synthetic Normalized Mentions**
2410.07951v1 by Kuleen Sasse, Shinjitha Vadlakonda, Richard E. Kennedy, John D. Osborne

Background: Machine learning methods for clinical named entity recognition
and entity normalization systems can utilize both labeled corpora and Knowledge
Graphs (KGs) for learning. However, infrequently occurring concepts may have
few mentions in training corpora and lack detailed descriptions or synonyms,
even in large KGs. For Disease Entity Recognition (DER) and Disease Entity
Normalization (DEN), this can result in fewer high quality training examples
relative to the number of known diseases. Large Language Model (LLM) generation
of synthetic training examples could improve performance in these information
extraction tasks.
  Methods: We fine-tuned a LLaMa-2 13B Chat LLM to generate a synthetic corpus
containing normalized mentions of concepts from the Unified Medical Language
System (UMLS) Disease Semantic Group. We measured overall and Out of
Distribution (OOD) performance for DER and DEN, with and without synthetic data
augmentation. We evaluated performance on 3 different disease corpora using 4
different data augmentation strategies, assessed using BioBERT for DER and
SapBERT and KrissBERT for DEN.
  Results: Our synthetic data yielded a substantial improvement for DEN, in all
3 training corpora the top 1 accuracy of both SapBERT and KrissBERT improved by
3-9 points in overall performance and by 20-55 points in OOD data. A small
improvement (1-2 points) was also seen for DER in overall performance, but only
one dataset showed OOD improvement.
  Conclusion: LLM generation of normalized disease mentions can improve DEN
relative to normalization approaches that do not utilize LLMs to augment data
with synthetic mentions. Ablation studies indicate that performance gains for
DEN were only partially attributable to improvements in OOD performance. The
same approach has only a limited ability to improve DER. We make our software
and dataset publicly available.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÔºöËá®Â∫äÂëΩÂêçÂØ¶È´îË≠òÂà•ÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÂíåÂØ¶È´îÊ≠£Ë¶èÂåñÁ≥ªÁµ±ÂèØ‰ª•Âà©Áî®Ê®ôË®òË™ûÊñôÂ∫´ÂíåÁü•Ë≠òÂúñË≠ú (KG) ‰æÜÂ≠∏Áøí„ÄÇÁÑ∂ËÄåÔºåÂú®Ë®ìÁ∑¥Ë™ûÊñôÂ∫´‰∏≠ÂæàÂ∞ëÂá∫ÁèæÁöÑÊ¶ÇÂøµÂèØËÉΩÂè™ÊúâÂ∞ëÊï∏ÊèêÂèäÔºåÂç≥‰ΩøÂú®Â§ßÂûãÁü•Ë≠òÂúñË≠ú‰∏≠‰πüÁº∫‰πèË©≥Á¥∞ÁöÑÊèèËø∞ÊàñÂêåÁæ©Ë©û„ÄÇÂ∞çÊñºÁñæÁóÖÂØ¶È´îË≠òÂà• (DER) ÂíåÁñæÁóÖÂØ¶È´îÊ≠£Ë¶èÂåñ (DEN)ÔºåÁõ∏Â∞çÊñºÂ∑≤Áü•ÁñæÁóÖÁöÑÊï∏ÈáèÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥ËºÉÂ∞ëÁöÑÈ´òÂìÅË≥™Ë®ìÁ∑¥ÁØÑ‰æã„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁîüÊàêÁöÑÂêàÊàêË®ìÁ∑¥ÁØÑ‰æãÂèØ‰ª•ÊèêÂçáÈÄô‰∫õË≥áË®äÊì∑Âèñ‰ªªÂãôÁöÑÊïàËÉΩ„ÄÇ
ÊñπÊ≥ïÔºöÊàëÂÄëÂæÆË™ø‰∫Ü‰∏ÄÂÄã LLaMa-2 13B ËÅäÂ§© LLMÔºå‰ª•Áî¢Áîü‰∏ÄÂÄãÂêàÊàêË™ûÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™Áµ±‰∏ÄÈÜ´Â≠∏Ë™ûË®ÄÁ≥ªÁµ± (UMLS) ÁñæÁóÖË™ûÁæ©Áæ§ÁöÑÊ®ôÊ∫ñÂåñÊ¶ÇÂøµÊèêÂèä„ÄÇÊàëÂÄëË°°Èáè‰∫Ü DER Âíå DEN ÁöÑÊï¥È´îÂíåÂàÜÂ∏ÉÂ§ñ (OOD) ÊïàËÉΩÔºåÊúâÂíåÊ≤íÊúâÂêàÊàêË≥áÊñôÊì¥ÂÖÖ„ÄÇÊàëÂÄë‰ΩøÁî® 4 Á®Æ‰∏çÂêåÁöÑË≥áÊñôÊì¥ÂÖÖÁ≠ñÁï•Ë©ï‰º∞‰∫Ü 3 ÂÄã‰∏çÂêåÁñæÁóÖË™ûÊñôÂ∫´ÁöÑÊïàËÉΩÔºå‰ΩøÁî® BioBERT Ë©ï‰º∞ DERÔºå‰ΩøÁî® SapBERT Âíå KrissBERT Ë©ï‰º∞ DEN„ÄÇ
ÁµêÊûúÔºöÊàëÂÄëÁöÑÂêàÊàêË≥áÊñôÂ∞ç DEN Áî¢Áîü‰∫ÜÈ°ØËëóÁöÑÊîπÂñÑÔºåÂú®ÊâÄÊúâ 3 ÂÄãË®ìÁ∑¥Ë™ûÊñôÂ∫´‰∏≠ÔºåSapBERT Âíå KrissBERT ÁöÑÂâç 1 ÂêçÊ∫ñÁ¢∫ÁéáÂú®Êï¥È´îÊïàËÉΩ‰∏äÊèêÈ´ò‰∫Ü 3-9 ÂÄãÁôæÂàÜÈªûÔºåÂú® OOD Ë≥áÊñô‰∏≠ÊèêÈ´ò‰∫Ü 20-55 ÂÄãÁôæÂàÜÈªû„ÄÇÂú® DER ÁöÑÊï¥È´îÊïàËÉΩ‰∏ä‰πüÁúãÂà∞‰∫ÜÂæÆÂ∞èÁöÑÊîπÂñÑÔºà1-2 ÂÄãÁôæÂàÜÈªûÔºâÔºå‰ΩÜÂè™Êúâ‰∏ÄÁµÑË≥áÊñôÈ°ØÁ§∫Âá∫ OOD ÊîπÂñÑ„ÄÇ
ÁµêË´ñÔºöËàá‰∏çÂà©Áî® LLM Êì¥ÂÖÖË≥áÊñô‰ª•ÂêàÊàêÊèêÂèäÁöÑÊ≠£Ë¶èÂåñÊñπÊ≥ïÁõ∏ÊØîÔºåLLM ÁîüÊàêÁöÑÊ®ôÊ∫ñÂåñÁñæÁóÖÊèêÂèäÂèØ‰ª•ÊîπÂñÑ DEN„ÄÇÊ∂àËûçÁ†îÁ©∂Ë°®ÊòéÔºåDEN ÁöÑÊïàËÉΩÊèêÂçáÂÉÖÈÉ®ÂàÜÊ≠∏Âõ†Êñº OOD ÊïàËÉΩÁöÑÊîπÂñÑ„ÄÇÁõ∏ÂêåÁöÑÊñπÊ≥ïÂ∞çÊñºÊîπÂñÑ DER ÁöÑËÉΩÂäõÊúâÈôê„ÄÇÊàëÂÄëÂÖ¨ÈñãÊàëÂÄëÁöÑËªüÈ´îÂíåË≥áÊñôÈõÜ„ÄÇ</paragraph>

##### **Benchmarking Agentic Workflow Generation**
2410.07869v1 by Shuofei Qiao, Runnan Fang, Zhisong Qiu, Xiaobin Wang, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen

Large Language Models (LLMs), with their exceptional ability to handle a wide
range of tasks, have driven significant advancements in tackling reasoning and
planning tasks, wherein decomposing complex problems into executable workflows
is a crucial step in this process. Existing workflow evaluation frameworks
either focus solely on holistic performance or suffer from limitations such as
restricted scenario coverage, simplistic workflow structures, and lax
evaluation standards. To this end, we introduce WorFBench, a unified workflow
generation benchmark with multi-faceted scenarios and intricate graph workflow
structures. Additionally, we present WorFEval, a systemic evaluation protocol
utilizing subsequence and subgraph matching algorithms to accurately quantify
the LLM agent's workflow generation capabilities. Through comprehensive
evaluations across different types of LLMs, we discover distinct gaps between
the sequence planning capabilities and graph planning capabilities of LLM
agents, with even GPT-4 exhibiting a gap of around 15%. We also train two
open-source models and evaluate their generalization abilities on held-out
tasks. Furthermore, we observe that the generated workflows can enhance
downstream tasks, enabling them to achieve superior performance with less time
during inference. Code and dataset will be available at
https://github.com/zjunlp/WorFBench.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊìÅÊúâËôïÁêÜÂêÑÁ®Æ‰ªªÂãôÁöÑÈùûÂá°ËÉΩÂäõÔºåÊé®Âãï‰∫ÜËß£Ê±∫Êé®ÁêÜÂíåË¶èÂäÉ‰ªªÂãôÁöÑÈ°ØËëóÈÄ≤Â±ïÔºåÂÖ∂‰∏≠Â∞áË§áÈõúÂïèÈ°åÂàÜËß£ÁÇ∫ÂèØÂü∑Ë°åÂ∑•‰ΩúÊµÅÁ®ãÊòØÊ≠§ÈÅéÁ®ã‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑ‰∏ÄÊ≠•„ÄÇÁèæÊúâÁöÑÂ∑•‰ΩúÊµÅÁ®ãË©ï‰º∞Ê°ÜÊû∂Âè™Â∞àÊ≥®ÊñºÊï¥È´îÊïàËÉΩÔºåÊàñÂèóÂà∞ÊÉÖÂ¢ÉÊ∂µËìãÁØÑÂúçÂèóÈôê„ÄÅÂ∑•‰ΩúÊµÅÁ®ãÁµêÊßãÁ∞°ÂåñÂíåË©ï‰º∞Ê®ôÊ∫ñÂØ¨È¨ÜÁ≠âÈôêÂà∂„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü WorFBenchÔºå‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÂ∑•‰ΩúÊµÅÁ®ãÁîüÊàêÂü∫Ê∫ñÔºåÂÖ∑ÊúâÂ§öÊñπÈù¢ÁöÑÂ†¥ÊôØÂíåË§áÈõúÁöÑÂúñÂΩ¢Â∑•‰ΩúÊµÅÁ®ãÁµêÊßã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü WorFEvalÔºå‰∏ÄÂÄãÂà©Áî®Â≠êÂ∫èÂàóÂíåÂ≠êÂúñÂåπÈÖçÊºîÁÆóÊ≥ï‰æÜÊ∫ñÁ¢∫ÈáèÂåñ LLM ‰ª£ÁêÜÂ∑•‰ΩúÊµÅÁ®ãÁîüÊàêËÉΩÂäõÁöÑÁ≥ªÁµ±ÊÄßË©ï‰º∞ÂçîÂÆö„ÄÇÈÄèÈÅéÂ∞ç‰∏çÂêåÈ°ûÂûã LLM ÁöÑÂÖ®Èù¢Ë©ï‰º∞ÔºåÊàëÂÄëÁôºÁèæ LLM ‰ª£ÁêÜÁöÑÂ∫èÂàóË¶èÂäÉËÉΩÂäõÂíåÂúñÂΩ¢Ë¶èÂäÉËÉΩÂäõ‰πãÈñìÂ≠òÂú®ÊòéÈ°ØÁöÑÂ∑ÆË∑ùÔºåÂç≥‰ΩøÊòØ GPT-4 ‰πüË°®ÁèæÂá∫Á¥Ñ 15% ÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÈÇÑË®ìÁ∑¥‰∫ÜÂÖ©ÂÄãÈñãÊ∫êÊ®°ÂûãÔºå‰∏¶Ë©ï‰º∞‰∫ÜÂÆÉÂÄëÂú®‰øùÁïô‰ªªÂãô‰∏äÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëËßÄÂØüÂà∞ÁîüÊàêÁöÑÁöÑÂ∑•‰ΩúÊµÅÁ®ãÂèØ‰ª•Â¢ûÂº∑‰∏ãÊ∏∏‰ªªÂãôÔºåËÆìÂÆÉÂÄëÂú®Êé®ÁêÜÊúüÈñì‰ª•Êõ¥Â∞ëÁöÑÊôÇÈñìÁç≤ÂæóÊõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂ∞áÂú® https://github.com/zjunlp/WorFBench ‰∏äÊèê‰æõ„ÄÇ

##### **KRAG Framework for Enhancing LLMs in the Legal Domain**
2410.07551v1 by Nguyen Ha Thanh, Ken Satoh

This paper introduces Knowledge Representation Augmented Generation (KRAG), a
novel framework designed to enhance the capabilities of Large Language Models
(LLMs) within domain-specific applications. KRAG points to the strategic
inclusion of critical knowledge entities and relationships that are typically
absent in standard data sets and which LLMs do not inherently learn. In the
context of legal applications, we present Soft PROLEG, an implementation model
under KRAG, which uses inference graphs to aid LLMs in delivering structured
legal reasoning, argumentation, and explanations tailored to user inquiries.
The integration of KRAG, either as a standalone framework or in tandem with
retrieval augmented generation (RAG), markedly improves the ability of language
models to navigate and solve the intricate challenges posed by legal texts and
terminologies. This paper details KRAG's methodology, its implementation
through Soft PROLEG, and potential broader applications, underscoring its
significant role in advancing natural language understanding and processing in
specialized knowledge domains.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥πÁü•Ë≠òË°®ÂæµÂ¢ûÂº∑ÁîüÊàê (KRAG)Ôºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÊó®Âú®Â¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÁâπÂÆöÈ†òÂüüÊáâÁî®‰∏≠ÁöÑËÉΩÂäõ„ÄÇKRAG ÊåáÂá∫Á≠ñÁï•ÊÄßÂú∞Á¥çÂÖ•ÈóúÈçµÁü•Ë≠òÂØ¶È´îÂíåÈóú‰øÇÔºåÈÄô‰∫õÂØ¶È´îÂíåÈóú‰øÇÈÄöÂ∏∏‰∏çÂ≠òÂú®ÊñºÊ®ôÊ∫ñË≥áÊñôÈõÜ‰∏≠ÔºåËÄå LLM ‰πüÁÑ°Ê≥ïÂõ∫ÊúâÂú∞Â≠∏Áøí„ÄÇÂú®Ê≥ïÂæãÊáâÁî®ÊñπÈù¢ÔºåÊàëÂÄëÊèêÂá∫ Soft PROLEGÔºåÈÄôÊòØ‰∏ÄÂÄãÂú® KRAG ‰∏ãÁöÑÂØ¶‰ΩúÊ®°ÂûãÔºåÂÆÉ‰ΩøÁî®Êé®ÁêÜÂúñ‰æÜÂçîÂä© LLM Êèê‰æõÁµêÊßãÂåñÁöÑÊ≥ïÂæãÊé®ÁêÜ„ÄÅË´ñË≠âÂíåËß£ÈáãÔºå‰ª•ÊªøË∂≥‰ΩøÁî®ËÄÖÁöÑË©¢Âïè„ÄÇÊï¥Âêà KRAGÔºåÁÑ°Ë´ñÊòØ‰ΩúÁÇ∫Áç®Á´ãÊû∂ÊßãÊàñËàáÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÁµêÂêà‰ΩøÁî®ÔºåÈÉΩËÉΩÈ°ØËëóÊèêÂçáË™ûË®ÄÊ®°ÂûãÂ∞éËà™ÂíåËß£Ê±∫Ê≥ïÂæãÊñáÊú¨ÂíåË°ìË™ûÊâÄÂ∏∂‰æÜÁöÑË§áÈõúÊåëÊà∞ÁöÑËÉΩÂäõ„ÄÇÊú¨ÊñáË©≥Ëø∞ KRAG ÁöÑÊñπÊ≥ïË´ñ„ÄÅÈÄèÈÅé Soft PROLEG ÁöÑÂØ¶‰ΩúÔºå‰ª•ÂèäÊΩõÂú®ÁöÑÊõ¥Âª£Ê≥õÊáâÁî®ÔºåÂº∑Ë™øÂÖ∂Âú®Êé®ÈÄ≤Â∞àÊ•≠Áü•Ë≠òÈ†òÂüüÁöÑËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÂíåËôïÁêÜ‰∏≠ÊâÆÊºîÁöÑÈáçË¶ÅËßíËâ≤„ÄÇ

##### **MKGL: Mastery of a Three-Word Language**
2410.07526v1 by Lingbing Guo, Zhongpu Bo, Zhuo Chen, Yichi Zhang, Jiaoyan Chen, Yarong Lan, Mengshu Sun, Zhiqiang Zhang, Yangyifei Luo, Qian Li, Qiang Zhang, Wen Zhang, Huajun Chen

Large language models (LLMs) have significantly advanced performance across a
spectrum of natural language processing (NLP) tasks. Yet, their application to
knowledge graphs (KGs), which describe facts in the form of triplets and allow
minimal hallucinations, remains an underexplored frontier. In this paper, we
investigate the integration of LLMs with KGs by introducing a specialized KG
Language (KGL), where a sentence precisely consists of an entity noun, a
relation verb, and ends with another entity noun. Despite KGL's unfamiliar
vocabulary to the LLM, we facilitate its learning through a tailored dictionary
and illustrative sentences, and enhance context understanding via real-time KG
context retrieval and KGL token embedding augmentation. Our results reveal that
LLMs can achieve fluency in KGL, drastically reducing errors compared to
conventional KG embedding methods on KG completion. Furthermore, our enhanced
LLM shows exceptional competence in generating accurate three-word sentences
from an initial entity and interpreting new unseen terms out of KGs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â§ßÂπÖÊèêÂçáÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãôÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®Áü•Ë≠òÂúñË≠ú (KG) ÁöÑÊáâÁî®‰∏ä‰ªçÊúâÂæÖÈñãÁôºÔºåÁü•Ë≠òÂúñË≠ú‰ª•‰∏âÂÖÉÁµÑÂΩ¢ÂºèÊèèËø∞‰∫ãÂØ¶Ôºå‰∏¶ÂÖÅË®±ÊúÄÂ∞èÁöÑÂπªË¶∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂºïÂÖ•‰∏ÄÁ®ÆÂ∞àÊ•≠ÁöÑ KG Ë™ûË®Ä (KGL) ‰æÜÊé¢Ë®é LLM Ëàá KG ÁöÑÊï¥ÂêàÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÂè•Â≠êÁ≤æÁ¢∫Âú∞ÂåÖÂê´‰∏ÄÂÄãÂØ¶È´îÂêçË©û„ÄÅ‰∏ÄÂÄãÈóú‰øÇÂãïË©ûÔºå‰∏¶‰ª•Âè¶‰∏ÄÂÄãÂØ¶È´îÂêçË©ûÁµêÂ∞æ„ÄÇÂÑòÁÆ° LLM Â∞ç KGL ÁöÑË©ûÂΩô‰∏çÁÜüÊÇâÔºå‰ΩÜÊàëÂÄëÈÄèÈÅéÈáèË∫´ÊâìÈÄ†ÁöÑÂ≠óÂÖ∏ÂíåË™™ÊòéÊÄßÂè•Â≠ê‰æÜ‰øÉÈÄ≤ÂÆÉÁöÑÂ≠∏ÁøíÔºå‰∏¶ÈÄèÈÅéÂç≥ÊôÇ KG ËÉåÊôØÊì∑ÂèñÂíå KGL ‰ª£Âπ£ÂµåÂÖ•Âº∑Âåñ‰æÜÊèêÂçáËÉåÊôØÁêÜËß£„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåLLM ËÉΩÂ§†ÊµÅÊö¢‰ΩøÁî® KGLÔºåÂ§ßÂπÖÊ∏õÂ∞ëÈåØË™§ÔºåÂÑ™Êñº KG ÂÆåÊàê‰∏≠ÂÇ≥Áµ±ÁöÑ KG ÂµåÂÖ•ÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ¢ûÂº∑ÁöÑ LLM Âú®ÂæûÂàùÂßãÂØ¶È´îÁîüÊàêÊ∫ñÁ¢∫ÁöÑ‰∏âÂ≠óË©ûÂè•Â≠êÔºå‰ª•ÂèäÂæû KG Ëß£ÈáãÊñ∞ÁöÑÊú™Ë¶ãË°ìË™ûÊñπÈù¢Â±ïÁèæÂá∫ÂçìË∂äÁöÑËÉΩÂäõ„ÄÇ

##### **InstructG2I: Synthesizing Images from Multimodal Attributed Graphs**
2410.07157v1 by Bowen Jin, Ziqi Pang, Bingjun Guo, Yu-Xiong Wang, Jiaxuan You, Jiawei Han

In this paper, we approach an overlooked yet critical task Graph2Image:
generating images from multimodal attributed graphs (MMAGs). This task poses
significant challenges due to the explosion in graph size, dependencies among
graph entities, and the need for controllability in graph conditions. To
address these challenges, we propose a graph context-conditioned diffusion
model called InstructG2I. InstructG2I first exploits the graph structure and
multimodal information to conduct informative neighbor sampling by combining
personalized page rank and re-ranking based on vision-language features. Then,
a Graph-QFormer encoder adaptively encodes the graph nodes into an auxiliary
set of graph prompts to guide the denoising process of diffusion. Finally, we
propose graph classifier-free guidance, enabling controllable generation by
varying the strength of graph guidance and multiple connected edges to a node.
Extensive experiments conducted on three datasets from different domains
demonstrate the effectiveness and controllability of our approach. The code is
available at https://github.com/PeterGriffinJin/InstructG2I.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Êé¢ËÆ®‰∏ÄÈ°πË¢´ÂøΩËßÜ‰ΩÜËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ªªÂä° Graph2ImageÔºö
‰ªéÂ§öÊ®°ÊÄÅÂ±ûÊÄßÂõæ (MMAG) ÁîüÊàêÂõæÂÉè„ÄÇÁî±‰∫éÂõæÂ§ßÂ∞èÊøÄÂ¢û„ÄÅÂõæÂÆû‰Ωì‰πãÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ª‰ª•ÂèäÂØπÂõæÊù°‰ª∂ÁöÑÂèØÊéßÊÄßÈúÄÊ±ÇÔºåÊ≠§‰ªªÂä°Â∏¶Êù•‰∫ÜÈáçÂ§ßÊåëÊàò„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∫õÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÁß∞‰∏∫ InstructG2I ÁöÑÂõæ‰∏ä‰∏ãÊñáÊù°‰ª∂Êâ©Êï£Ê®°Âûã„ÄÇInstructG2I È¶ñÂÖàÂà©Áî®ÂõæÁªìÊûÑÂíåÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÔºåÈÄöËøáÁªìÂêà‰∏™ÊÄßÂåñÈ°µÈù¢ÊéíÂêçÂíåÂü∫‰∫éËßÜËßâËØ≠Ë®ÄÁâπÂæÅÁöÑÈáçÊñ∞ÊéíÂêçÊù•ÊâßË°å‰ø°ÊÅØ‰∏∞ÂØåÁöÑÈÇªÂ±ÖÈááÊ†∑„ÄÇÁÑ∂ÂêéÔºåGraph-QFormer ÁºñÁ†ÅÂô®Â∞ÜÂõæËäÇÁÇπËá™ÈÄÇÂ∫îÂú∞ÁºñÁ†Å‰∏∫‰∏ÄÁªÑËæÖÂä©ÂõæÊèêÁ§∫Ôºå‰ª•ÊåáÂØºÊâ©Êï£ÁöÑÂéªÂô™ËøáÁ®ã„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÊó†ÂõæÂàÜÁ±ªÂô®ÊåáÂØºÔºåÈÄöËøáÊîπÂèòÂõæÊåáÂØºÁöÑÂº∫Â∫¶Âíå‰∏éËäÇÁÇπÁöÑÂ§ö‰∏™ËøûÊé•ËæπÊù•ÂÆûÁé∞ÂèØÊéßÁîüÊàê„ÄÇÂú®Êù•Ëá™‰∏çÂêåÈ¢ÜÂüüÁöÑ‰∏âÁªÑÊï∞ÊçÆÈõÜ‰∏äËøõË°åÁöÑÂπøÊ≥õÂÆûÈ™åËØÅÊòé‰∫ÜÊàë‰ª¨ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂíåÂèØÊéßÊÄß„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/PeterGriffinJin/InstructG2I Ëé∑Âæó„ÄÇ

##### **CSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free Word Ordered and Morphologically Rich Low Resource Languages**
2410.06944v1 by Pretam Ray, Jivnesh Sandhan, Amrith Krishna, Pawan Goyal

Neural dependency parsing has achieved remarkable performance for low
resource morphologically rich languages. It has also been well-studied that
morphologically rich languages exhibit relatively free word order. This prompts
a fundamental investigation: Is there a way to enhance dependency parsing
performance, making the model robust to word order variations utilizing the
relatively free word order nature of morphologically rich languages? In this
work, we examine the robustness of graph-based parsing architectures on 7
relatively free word order languages. We focus on scrutinizing essential
modifications such as data augmentation and the removal of position encoding
required to adapt these architectures accordingly. To this end, we propose a
contrastive self-supervised learning method to make the model robust to word
order variations. Furthermore, our proposed modification demonstrates a
substantial average gain of 3.03/2.95 points in 7 relatively free word order
languages, as measured by the UAS/LAS Score metric when compared to the best
performing baseline.

ÊëòË¶ÅÔºöÁ•ûÁ∂ì‰æùË≥¥Ëß£ÊûêÂ∞çÊñºË≥áÊ∫êËºÉÂ∞ëÁöÑÂΩ¢ÊÖãË±êÂØåË™ûË®ÄÂ∑≤ÈÅîÂà∞È°ØËëóÁöÑÊïàËÉΩ„ÄÇÂΩ¢ÊÖãË±êÂØåË™ûË®ÄÂ±ïÁèæÁõ∏Â∞çËá™Áî±ÁöÑË™ûÂ∫èÔºåÈÄôÈªû‰πüÂ∑≤Áç≤ÂæóÊ∑±ÂÖ•Êé¢Ë®é„ÄÇÈÄôÂºïÁôº‰∫Ü‰∏ÄÈ†ÖÂü∫Á§éË™øÊü•ÔºöÊòØÂê¶ÊúâÊñπÊ≥ïÂèØ‰ª•ÊèêÂçá‰æùË≥¥Ëß£ÊûêÊïàËÉΩÔºåËÆìÊ®°ÂûãËÉΩÈÄèÈÅéÈÅãÁî®ÂΩ¢ÊÖãË±êÂØåË™ûË®ÄÁõ∏Â∞çËá™Áî±ÁöÑË™ûÂ∫èÁâπË≥™ÔºåÂ∞çË™ûÂ∫èËÆäÂåñÂÖ∑ÊúâÁ©©ÂÅ•ÊÄßÔºüÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊ™¢Ë¶ñ‰∫Ü 7 Á®ÆÁõ∏Â∞çËá™Áî±Ë™ûÂ∫èË™ûË®Ä‰∏≠Âü∫ÊñºÂúñË°®ÁöÑËß£ÊûêÊû∂ÊßãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÂ∞àÊ≥®ÊñºÂØ©Ë¶ñÂøÖË¶ÅÁöÑ‰øÆÊîπÔºå‰æãÂ¶ÇË≥áÊñôÊì¥ÂÖÖÂíåÁßªÈô§‰ΩçÁΩÆÁ∑®Á¢ºÔºå‰ª•ÈÅ©Áï∂Âú∞Ë™øÊï¥ÈÄô‰∫õÊû∂Êßã„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫Â∞çÊØîËá™ÊàëÁõ£Áù£Â≠∏ÁøíÊñπÊ≥ïÔºåËÆìÊ®°ÂûãÂ∞çË™ûÂ∫èËÆäÂåñÂÖ∑ÊúâÁ©©ÂÅ•ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫ÁöÑ‰øÆÊîπÂú® 7 Á®ÆÁõ∏Â∞çËá™Áî±Ë™ûÂ∫èË™ûË®Ä‰∏≠Â±ïÁèæ‰∫Ü 3.03/2.95 ÈªûÁöÑÈ°ØËëóÂπ≥ÂùáÂ¢ûÁõäÔºåÈÄôÊòØÊ†πÊìö UAS/LAS ÂàÜÊï∏ÊåáÊ®ôÔºåËàáÊïàËÉΩÊúÄ‰Ω≥ÁöÑÂü∫Ê∫ñÁ∑öÈÄ≤Ë°åÊØîËºÉÂæåÂæóÂá∫ÁöÑÁµêÊûú„ÄÇ

##### **Tree of Problems: Improving structured problem solving with compositionality**
2410.06634v1 by Armel Zebaze, Beno√Æt Sagot, Rachel Bawden

Large Language Models (LLMs) have demonstrated remarkable performance across
multiple tasks through in-context learning. For complex reasoning tasks that
require step-by-step thinking, Chain-of-Thought (CoT) prompting has given
impressive results, especially when combined with self-consistency.
Nonetheless, some tasks remain particularly difficult for LLMs to solve. Tree
of Thoughts (ToT) and Graph of Thoughts (GoT) emerged as alternatives, dividing
the complex problem into paths of subproblems. In this paper, we propose Tree
of Problems (ToP), a simpler version of ToT, which we hypothesise can work
better for complex tasks that can be divided into identical subtasks. Our
empirical results show that our approach outperforms ToT and GoT, and in
addition performs better than CoT on complex reasoning tasks. All code for this
paper is publicly available here:
https://github.com/ArmelRandy/tree-of-problems.

ÊëòË¶ÅÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Â∑≤ÈÄöËøáÊÉÖÂ¢ÉÂ≠¶‰π†Âú®Â§öÈ°π‰ªªÂä°‰∏≠Â±ïÁ§∫Âá∫ÈùûÂá°ÁöÑÊÄßËÉΩ„ÄÇÂØπ‰∫éÈúÄË¶ÅÂæ™Â∫èÊ∏êËøõÊÄùËÄÉÁöÑÂ§çÊùÇÊé®ÁêÜ‰ªªÂä°ÔºåÊÄùÁª¥Èìæ (CoT) ÊèêÁ§∫Â∑≤ÂèñÂæó‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÁªìÊûúÔºåÂ∞§ÂÖ∂ÊòØÂú®‰∏éËá™Ê¥ΩÊÄßÁõ∏ÁªìÂêàÊó∂„ÄÇÂ∞ΩÁÆ°Â¶ÇÊ≠§ÔºåLLM ‰ªçÁÑ∂Èöæ‰ª•Ëß£ÂÜ≥Êüê‰∫õ‰ªªÂä°„ÄÇÊÄùÁª¥Ê†ë (ToT) ÂíåÊÄùÁª¥Âõæ (GoT) ‰Ωú‰∏∫Êõø‰ª£ÊñπÊ°àÂá∫Áé∞ÔºåÂ∞ÜÂ§çÊùÇÈóÆÈ¢òÂàíÂàÜ‰∏∫Â≠êÈóÆÈ¢òÁöÑË∑ØÂæÑ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÊÄùÁª¥Ê†ë (ToP)ÔºåÂÆÉÊòØ ToT ÁöÑ‰∏Ä‰∏™Êõ¥ÁÆÄÂçïÁöÑÁâàÊú¨ÔºåÊàë‰ª¨ÂÅáËÆæÂÆÉÂèØ‰ª•Êõ¥Â•ΩÂú∞ÈÄÇÁî®‰∫éÂèØ‰ª•ÂàíÂàÜ‰∏∫Áõ∏ÂêåÂ≠ê‰ªªÂä°ÁöÑÂ§çÊùÇ‰ªªÂä°„ÄÇÊàë‰ª¨ÁöÑÂÆûËØÅÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ï‰ºò‰∫é ToT Âíå GoTÔºåÂπ∂‰∏îÂú®Â§çÊùÇÊé®ÁêÜ‰ªªÂä°‰∏äÁöÑË°®Áé∞‰πü‰ºò‰∫é CoT„ÄÇÊú¨ÊñáÁöÑÊâÄÊúâ‰ª£Á†ÅÂú®Ê≠§ÂÖ¨ÂºÄÊèê‰æõÔºö
https://github.com/ArmelRandy/tree-of-problems„ÄÇ

##### **Multi-Task Program Error Repair and Explanatory Diagnosis**
2410.07271v1 by Zhenyu Xu, Victor S. Sheng

Program errors can occur in any type of programming, and can manifest in a
variety of ways, such as unexpected output, crashes, or performance issues. And
program error diagnosis can often be too abstract or technical for developers
to understand, especially for beginners. The goal of this paper is to present a
novel machine-learning approach for Multi-task Program Error Repair and
Explanatory Diagnosis (mPRED). A pre-trained language model is used to encode
the source code, and a downstream model is specifically designed to identify
and repair errors. Programs and test cases will be augmented and optimized from
several perspectives. Additionally, our approach incorporates a "chain of
thoughts" method, which enables the models to produce intermediate reasoning
explanations before providing the final correction. To aid in visualizing and
analyzing the program structure, we use a graph neural network for program
structure visualization. Overall, our approach offers a promising approach for
repairing program errors across different programming languages and providing
helpful explanations to programmers.

ÊëòË¶ÅÔºöÁ®ãÂºèÈåØË™§ÂèØËÉΩÁôºÁîüÂú®‰ªª‰ΩïÈ°ûÂûãÁöÑÁ®ãÂºèË®≠Ë®à‰∏≠Ôºå‰∏¶ÂèØËÉΩ‰ª•ÂêÑÁ®ÆÊñπÂºèÂëàÁèæÔºå‰æãÂ¶ÇÊÑèÂ§ñËº∏Âá∫„ÄÅÁï∂Ê©üÊàñÊïàËÉΩÂïèÈ°å„ÄÇÁ®ãÂºèÈåØË™§Ë®∫Êñ∑ÈÄöÂ∏∏Â∞çÈñãÁôº‰∫∫Âì°‰æÜË™™ÈÅéÊñºÊäΩË±°ÊàñÊäÄË°ìÊÄßÔºåÁâπÂà•ÊòØÂ∞çÊñºÂàùÂ≠∏ËÄÖËÄåË®Ä„ÄÇÊú¨ÊñáÁöÑÁõÆÁöÑÊòØÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§ö‰ªªÂãôÁ®ãÂºèÈåØË™§‰øÆÂæ©ËàáËß£ÈáãÊÄßË®∫Êñ∑ (mPRED) Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ï„ÄÇÈ†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°ÂûãÁî®ÊñºÁ∑®Á¢ºÂéüÂßãÁ¢ºÔºåËÄå‰∏ãÊ∏∏Ê®°ÂûãÂâáÂ∞àÈñÄË®≠Ë®àÁî®ÊñºË≠òÂà•Âíå‰øÆÂæ©ÈåØË™§„ÄÇÁ®ãÂºèÂíåÊ∏¨Ë©¶Ê°à‰æãÂ∞áÂæûÂ§öÂÄãËßíÂ∫¶ÈÄ≤Ë°åÊì¥ÂÖÖÂíåÊúÄ‰Ω≥Âåñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÂê´„ÄåÊÄùËÄÉÈèà„ÄçÊñπÊ≥ïÔºå‰ΩøÊ®°ÂûãËÉΩÂ§†Âú®Êèê‰æõÊúÄÁµÇ‰øÆÊ≠£‰πãÂâçÁî¢Áîü‰∏≠ÈñìÊé®ÁêÜË™™Êòé„ÄÇÁÇ∫‰∫ÜÂπ´Âä©Ë¶ñË¶∫ÂåñÂíåÂàÜÊûêÁ®ãÂºèÁµêÊßãÔºåÊàëÂÄë‰ΩøÁî®ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÈÄ≤Ë°åÁ®ãÂºèÁµêÊßãË¶ñË¶∫Âåñ„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Áî®Êñº‰øÆÂæ©‰∏çÂêåÁ®ãÂºèË™ûË®Ä‰∏≠ÁöÑÁ®ãÂºèÈåØË™§Ôºå‰∏¶ÂêëÁ®ãÂºèË®≠Ë®àÂ∏´Êèê‰æõÊúâÁî®ÁöÑË™™Êòé„ÄÇ

##### **Counterfactual Causal Inference in Natural Language with Large Language Models**
2410.06392v1 by Ga√´l Gendron, Jo≈æe M. Ro≈æanec, Michael Witbrock, Gillian Dobbie

Causal structure discovery methods are commonly applied to structured data
where the causal variables are known and where statistical testing can be used
to assess the causal relationships. By contrast, recovering a causal structure
from unstructured natural language data such as news articles contains numerous
challenges due to the absence of known variables or counterfactual data to
estimate the causal links. Large Language Models (LLMs) have shown promising
results in this direction but also exhibit limitations. This work investigates
LLM's abilities to build causal graphs from text documents and perform
counterfactual causal inference. We propose an end-to-end causal structure
discovery and causal inference method from natural language: we first use an
LLM to extract the instantiated causal variables from text data and build a
causal graph. We merge causal graphs from multiple data sources to represent
the most exhaustive set of causes possible. We then conduct counterfactual
inference on the estimated graph. The causal graph conditioning allows
reduction of LLM biases and better represents the causal estimands. We use our
method to show that the limitations of LLMs in counterfactual causal reasoning
come from prediction errors and propose directions to mitigate them. We
demonstrate the applicability of our method on real-world news articles.

ÊëòË¶ÅÔºöÂõ†ÊûúÁªìÊûÑÂèëÁé∞ÊñπÊ≥ïÈÄöÂ∏∏Â∫îÁî®‰∫éÁªìÊûÑÂåñÊï∞ÊçÆÔºåÂÖ∂‰∏≠Âõ†ÊûúÂèòÈáèÊòØÂ∑≤Áü•ÁöÑÔºåÂπ∂‰∏îÂèØ‰ª•‰ΩøÁî®ÁªüËÆ°Ê£ÄÈ™åÊù•ËØÑ‰º∞Âõ†ÊûúÂÖ≥Á≥ª„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºå‰ªéÊñ∞ÈóªÊñáÁ´†Á≠âÈùûÁªìÊûÑÂåñÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÊï∞ÊçÆ‰∏≠ÊÅ¢Â§çÂõ†ÊûúÁªìÊûÑÁî±‰∫éÁº∫Â∞ëÂ∑≤Áü•ÂèòÈáèÊàñÂèç‰∫ãÂÆûÊï∞ÊçÆÊù•‰º∞ËÆ°Âõ†ÊûúÂÖ≥Á≥ªËÄåÂåÖÂê´‰ºóÂ§öÊåëÊàò„ÄÇÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Âú®Ëøô‰∏™ÊñπÂêë‰∏äÊòæÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁªìÊûúÔºå‰ΩÜ‰πüË°®Áé∞Âá∫Â±ÄÈôêÊÄß„ÄÇËøôÈ°πÂ∑•‰ΩúË∞ÉÊü•‰∫Ü LLM ‰ªéÊñáÊú¨ÊñáÊ°£ÊûÑÂª∫Âõ†ÊûúÂõæÂíåÊâßË°åÂèç‰∫ãÂÆûÂõ†ÊûúÊé®ÁêÜÁöÑËÉΩÂäõ„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßç‰ªéËá™ÁÑ∂ËØ≠Ë®Ä‰∏≠ËøõË°åÁ´ØÂà∞Á´ØÂõ†ÊûúÁªìÊûÑÂèëÁé∞ÂíåÂõ†ÊûúÊé®ÁêÜÁöÑÊñπÊ≥ïÔºöÊàë‰ª¨È¶ñÂÖà‰ΩøÁî® LLM ‰ªéÊñáÊú¨Êï∞ÊçÆ‰∏≠ÊèêÂèñÂÆû‰æãÂåñÁöÑÂõ†ÊûúÂèòÈáèÂπ∂ÊûÑÂª∫Âõ†ÊûúÂõæ„ÄÇÊàë‰ª¨ÂêàÂπ∂Êù•Ëá™Â§ö‰∏™Êï∞ÊçÆÊ∫êÁöÑÂõ†ÊûúÂõæÔºå‰ª•Ë°®Á§∫ÂèØËÉΩÁöÑÊúÄËØ¶Â∞ΩÁöÑÂõ†ÊûúÈõÜ„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨ÂØπ‰º∞ËÆ°ÂõæËøõË°åÂèç‰∫ãÂÆûÊé®ÁêÜ„ÄÇÂõ†ÊûúÂõæÊù°‰ª∂ÂÖÅËÆ∏ÂáèÂ∞ë LLM ÂÅèÂ∑ÆÂπ∂Êõ¥Â•ΩÂú∞Ë°®Á§∫Âõ†Êûú‰º∞ËÆ°Èáè„ÄÇÊàë‰ª¨‰ΩøÁî®Êàë‰ª¨ÁöÑÊñπÊ≥ïË°®Êòé LLM Âú®Âèç‰∫ãÂÆûÂõ†ÊûúÊé®ÁêÜ‰∏≠ÁöÑÂ±ÄÈôêÊÄßÊù•Ëá™È¢ÑÊµãËØØÂ∑ÆÔºåÂπ∂ÊèêÂá∫ÂáèËΩªÂÆÉ‰ª¨ÁöÑÊé™ÊñΩ„ÄÇÊàë‰ª¨Âú®Áé∞ÂÆû‰∏ñÁïåÁöÑÊñ∞ÈóªÊñáÁ´†‰∏≠Â±ïÁ§∫‰∫ÜÊàë‰ª¨ÊñπÊ≥ïÁöÑÈÄÇÁî®ÊÄß„ÄÇ

##### **Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA**
2410.06121v1 by Wenyu Huang, Guancheng Zhou, Hongru Wang, Pavlos Vougiouklis, Mirella Lapata, Jeff Z. Pan

Retrieval-Augmented Generation (RAG) is widely used to inject external
non-parametric knowledge into large language models (LLMs). Recent works
suggest that Knowledge Graphs (KGs) contain valuable external knowledge for
LLMs. Retrieving information from KGs differs from extracting it from document
sets. Most existing approaches seek to directly retrieve relevant subgraphs,
thereby eliminating the need for extensive SPARQL annotations, traditionally
required by semantic parsing methods. In this paper, we model the subgraph
retrieval task as a conditional generation task handled by small language
models. Specifically, we define a subgraph identifier as a sequence of
relations, each represented as a special token stored in the language models.
Our base generative subgraph retrieval model, consisting of only 220M
parameters, achieves competitive retrieval performance compared to
state-of-the-art models relying on 7B parameters, demonstrating that small
language models are capable of performing the subgraph retrieval task.
Furthermore, our largest 3B model, when plugged with an LLM reader, sets new
SOTA end-to-end performance on both the WebQSP and CWQ benchmarks. Our model
and data will be made available online: https://github.com/hwy9855/GSR.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Âª£Ê≥õÁî®ÊñºÂ∞áÂ§ñÈÉ®ÈùûÂèÉÊï∏Áü•Ë≠òÊ≥®ÂÖ•Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÁü•Ë≠òÂúñ (KG) ÂåÖÂê´Â∞ç LLM ÊúâÂÉπÂÄºÁöÑÂ§ñÈÉ®Áü•Ë≠ò„ÄÇÂæû KG ‰∏≠Êì∑ÂèñË≥áË®äËàáÂæûÊñá‰ª∂ÈõÜ‰∏≠Êì∑ÂèñË≥áË®ä‰∏çÂêå„ÄÇÂ§ßÂ§öÊï∏ÁèæÊúâÊñπÊ≥ïÂ∞ãÊ±ÇÁõ¥Êé•Êì∑ÂèñÁõ∏ÈóúÂ≠êÂúñÔºåÂæûËÄåÊ∂àÈô§‰∫ÜÂ∞çË™ûÁæ©Ëß£ÊûêÊñπÊ≥ïÂÇ≥Áµ±‰∏äÊâÄÈúÄÁöÑÂª£Ê≥õ SPARQL Ë®ªËß£ÁöÑÈúÄÊ±Ç„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞áÂ≠êÂúñÊì∑Âèñ‰ªªÂãôÂª∫Ê®°ÁÇ∫Áî±Â∞èÂûãË™ûË®ÄÊ®°ÂûãËôïÁêÜÁöÑÊ¢ù‰ª∂ÁîüÊàê‰ªªÂãô„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞áÂ≠êÂúñË≠òÂà•Á¨¶ÂÆöÁæ©ÁÇ∫Èóú‰øÇÂ∫èÂàóÔºåÊØèÂÄãÈóú‰øÇÈÉΩË°®Á§∫ÁÇ∫ÂÑ≤Â≠òÂú®Ë™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÁâπÊÆäÊ®ôË®ò„ÄÇÊàëÂÄëÁöÑÂü∫Á§éÁîüÊàêÂºèÂ≠êÂúñÊì∑ÂèñÊ®°ÂûãÂÉÖÂåÖÂê´ 220M ÂèÉÊï∏ÔºåËàá‰æùË≥¥ 7B ÂèÉÊï∏ÁöÑÊúÄÊñ∞Ê®°ÂûãÁõ∏ÊØîÔºåÈÅîÂà∞‰∫ÜÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊì∑ÂèñÊïàËÉΩÔºåË≠âÊòéÂ∞èÂûãË™ûË®ÄÊ®°ÂûãËÉΩÂ§†Âü∑Ë°åÂ≠êÂúñÊì∑Âèñ‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåÁï∂ÊàëÂÄëÊúÄÂ§ßÁöÑ 3B Ê®°ÂûãËàá LLM Èñ±ËÆÄÂô®ÁµêÂêà‰ΩøÁî®ÊôÇÔºåÂú® WebQSP Âíå CWQ Âü∫Ê∫ñ‰∏äË®≠ÂÆö‰∫ÜÊñ∞ÁöÑÁ´ØÂà∞Á´ØÊïàËÉΩ SOTA„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂíåË≥áÊñôÂ∞áÂú®Á∑ö‰∏äÂÖ¨ÈñãÔºöhttps://github.com/hwy9855/GSR„ÄÇ

##### **LLM-based SPARQL Query Generation from Natural Language over Federated Knowledge Graphs**
2410.06062v2 by Vincent Emonet, Jerven Bolleman, Severine Duvaud, Tarcisio Mendes de Farias, Ana Claudia Sima

We introduce a Retrieval-Augmented Generation (RAG) system for translating
user questions into accurate federated SPARQL queries over bioinformatics
knowledge graphs (KGs) leveraging Large Language Models (LLMs). To enhance
accuracy and reduce hallucinations in query generation, our system utilises
metadata from the KGs, including query examples and schema information, and
incorporates a validation step to correct generated queries. The system is
available online at chat.expasy.org.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÂÖ•Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Á≥ªÁµ±ÔºåÁî®ÊñºÂ∞á‰ΩøÁî®ËÄÖÂïèÈ°åÁøªË≠ØÊàêÊ∫ñÁ¢∫ÁöÑËÅØÂêà SPARQL Êü•Ë©¢Ôºå‰ª•Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÁîüÁâ©Ë≥áË®äÂ≠∏Áü•Ë≠òÂúñ (KG)„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑Ê∫ñÁ¢∫ÊÄß‰∏¶Ê∏õÂ∞ëÊü•Ë©¢ÁîüÊàê‰∏≠ÁöÑÂπªË¶∫ÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±Âà©Áî®‰æÜËá™ KG ÁöÑÂÖÉË≥áÊñôÔºåÂåÖÊã¨Êü•Ë©¢ÁØÑ‰æãÂíåÊû∂ÊßãË≥áË®äÔºå‰∏¶ÁµêÂêàÈ©óË≠âÊ≠•È©ü‰æÜ‰øÆÊ≠£Â∑≤ÁîüÊàêÁöÑÊü•Ë©¢„ÄÇË©≤Á≥ªÁµ±ÂèØÂú® chat.expasy.org ‰∏äÁ∑ö‰ΩøÁî®„ÄÇ

##### **Jet Expansions of Residual Computation**
2410.06024v1 by Yihong Chen, Xiangxiang Xu, Yao Lu, Pontus Stenetorp, Luca Franceschi

We introduce a framework for expanding residual computational graphs using
jets, operators that generalize truncated Taylor series. Our method provides a
systematic approach to disentangle contributions of different computational
paths to model predictions. In contrast to existing techniques such as
distillation, probing, or early decoding, our expansions rely solely on the
model itself and requires no data, training, or sampling from the model. We
demonstrate how our framework grounds and subsumes logit lens, reveals a
(super-)exponential path structure in the recursive residual depth and opens up
several applications. These include sketching a transformer large language
model with $n$-gram statistics extracted from its computations, and indexing
the models' levels of toxicity knowledge. Our approach enables data-free
analysis of residual computation for model interpretability, development, and
evaluation.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊ°ÜÊû∂ÔºåÁî®Âô¥Â∞ÑÊµÅÊì¥Â±ïÊÆòÂ∑ÆË®àÁÆóÂúñÔºåÂô¥Â∞ÑÊµÅÊòØ‰∏ÄÁ®ÆÂ∞áÊà™Êñ∑ÁöÑÊ≥∞ÂãíÁ¥öÊï∏Ê≥õÂåñÁöÑÈÅãÁÆóÂ≠ê„ÄÇÊàëÂÄëÁöÑÈÄôÂÄãÊñπÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁ≥ªÁµ±ÂåñÁöÑÈÄîÂæëÔºåÁî®‰æÜËß£Èñã‰∏çÂêåË®àÁÆóË∑ØÂæëÂ∞çÊ®°ÂûãÈ†êÊ∏¨ÁöÑË≤¢Áçª„ÄÇËàáÁèæÊúâÁöÑÊäÄË°ìÔºà‰æãÂ¶ÇËí∏È§æ„ÄÅÊé¢Ê∏¨ÊàñÊó©ÊúüËß£Á¢ºÔºâÁõ∏ÂèçÔºåÊàëÂÄëÁöÑÊì¥Â±ïÂÉÖ‰æùË≥¥ÊñºÊ®°ÂûãÊú¨Ë∫´Ôºå‰∏çÈúÄË¶ÅÂæûÊ®°Âûã‰∏≠Áç≤ÂèñÊï∏Êìö„ÄÅË®ìÁ∑¥ÊàñÂèñÊ®£„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊ°ÜÊû∂Â¶Ç‰ΩïÂ•†ÂÆöÂíåÊ¶ÇÊã¨ÈÇèËºØÈÄèÈè°ÔºåÊè≠Á§∫‰∫ÜÈÅûÊ≠∏ÊÆòÂ∑ÆÊ∑±Â∫¶‰∏≠ÁöÑÔºàË∂ÖÔºâÊåáÊï∏Ë∑ØÂæëÁµêÊßãÔºå‰∏¶ÊâìÈñã‰∫ÜÂπæÂÄãÊáâÁî®„ÄÇÈÄô‰∫õÊáâÁî®ÂåÖÊã¨Áî®ÂæûÂÖ∂Ë®àÁÆó‰∏≠ÊèêÂèñÁöÑ n-gram Áµ±Ë®àÊï∏ÊìöÁπ™Ë£Ω‰∏ÄÂÄãTransformerÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºå‰∏¶Á¥¢ÂºïÊ®°ÂûãÁöÑÊØíÊÄßÁü•Ë≠òÁ¥öÂà•„ÄÇÊàëÂÄëÁöÑÈÄôÁ®ÆÊñπÊ≥ïËÉΩÂ§†Â∞çÊÆòÂ∑ÆË®àÁÆóÈÄ≤Ë°åÁÑ°Êï∏ÊìöÂàÜÊûêÔºåÁî®ÊñºÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÅÈñãÁôºÂíåË©ï‰º∞„ÄÇ

##### **A large collection of bioinformatics question-query pairs over federated knowledge graphs: methodology and applications**
2410.06010v1 by Jerven Bolleman, Vincent Emonet, Adrian Altenhoff, Amos Bairoch, Marie-Claude Blatter, Alan Bridge, Severine Duvaud, Elisabeth Gasteiger, Dmitry Kuznetsov, Sebastien Moretti, Pierre-Andre Michel, Anne Morgat, Marco Pagni, Nicole Redaschi, Monique Zahn-Zabal, Tarcisio Mendes de Farias, Ana Claudia Sima

Background. In the last decades, several life science resources have
structured data using the same framework and made these accessible using the
same query language to facilitate interoperability. Knowledge graphs have seen
increased adoption in bioinformatics due to their advantages for representing
data in a generic graph format. For example, yummydata.org catalogs more than
60 knowledge graphs accessible through SPARQL, a technical query language.
Although SPARQL allows powerful, expressive queries, even across physically
distributed knowledge graphs, formulating such queries is a challenge for most
users. Therefore, to guide users in retrieving the relevant data, many of these
resources provide representative examples. These examples can also be an
important source of information for machine learning, if a sufficiently large
number of examples are provided and published in a common, machine-readable and
standardized format across different resources.
  Findings. We introduce a large collection of human-written natural language
questions and their corresponding SPARQL queries over federated bioinformatics
knowledge graphs (KGs) collected for several years across different research
groups at the SIB Swiss Institute of Bioinformatics. The collection comprises
more than 1000 example questions and queries, including 65 federated queries.
We propose a methodology to uniformly represent the examples with minimal
metadata, based on existing standards. Furthermore, we introduce an extensive
set of open-source applications, including query graph visualizations and smart
query editors, easily reusable by KG maintainers who adopt the proposed
methodology.
  Conclusions. We encourage the community to adopt and extend the proposed
methodology, towards richer KG metadata and improved Semantic Web services.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØ„ÄÇÂú®ÈÅéÂéªÂπæÂçÅÂπ¥ÔºåË®±Â§öÁîüÂëΩÁßëÂ≠∏Ë≥áÊ∫ê‰ΩøÁî®Áõ∏ÂêåÁöÑÊû∂Êßã‰æÜÂª∫ÊßãË≥áÊñôÔºå‰∏¶‰ΩøÁî®Áõ∏ÂêåÁöÑÊü•Ë©¢Ë™ûË®Ä‰æÜÂ≠òÂèñÈÄô‰∫õË≥áÊñôÔºå‰ª•‰øÉÈÄ≤‰∫íÊìç‰ΩúÊÄß„ÄÇÁü•Ë≠òÂúñË≠úÁî±ÊñºÂÖ∂‰ª•ÈÄöÁî®ÂúñÂΩ¢Ê†ºÂºèË°®Á§∫Ë≥áÊñôÁöÑÂÑ™ÈªûÔºåÂõ†Ê≠§Âú®ÁîüÁâ©Ë≥áË®äÂ≠∏‰∏≠Áç≤Âæó‰∫ÜË∂ä‰æÜË∂äÂª£Ê≥õÁöÑÊé°Áî®„ÄÇ‰æãÂ¶ÇÔºåyummydata.org Á∑®ÈåÑ‰∫ÜË∂ÖÈÅé 60 ÂÄãÂèØÈÄèÈÅéÊäÄË°ìÊü•Ë©¢Ë™ûË®Ä SPARQL Â≠òÂèñÁöÑÁü•Ë≠òÂúñË≠ú„ÄÇÂÑòÁÆ° SPARQL ÂÖÅË®±ÈÄ≤Ë°åÂº∑Â§ß‰∏îÂÖ∑Ë°®ÈÅîÂäõÁöÑÊü•Ë©¢ÔºåÁîöËá≥Ë∑®Ë∂äÂØ¶È´îÂàÜÂ∏ÉÁöÑÁü•Ë≠òÂúñË≠úÔºå‰ΩÜÂ∞çÂ§ßÂ§öÊï∏‰ΩøÁî®ËÄÖ‰æÜË™™ÔºåÂà∂ÂÆöÊ≠§È°ûÊü•Ë©¢ÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÂõ†Ê≠§ÔºåÁÇ∫‰∫ÜÊåáÂ∞é‰ΩøÁî®ËÄÖÊì∑ÂèñÁõ∏ÈóúË≥áÊñôÔºåÂÖ∂‰∏≠Ë®±Â§öË≥áÊ∫êÊèê‰æõ‰∫ÜÂÖ∑‰ª£Ë°®ÊÄßÁöÑÁØÑ‰æã„ÄÇÂ¶ÇÊûúÊèê‰æõ‰∫ÜË∂≥Â§†Â§ßÈáèÁöÑÁØÑ‰æãÔºå‰∏¶‰ª•Ë∑®‰∏çÂêåË≥áÊ∫êÁöÑÈÄöÁî®„ÄÅÊ©üÂô®ÂèØËÆÄ‰∏îÊ®ôÊ∫ñÂåñÁöÑÊ†ºÂºèÁôºÂ∏ÉÔºåÈÄô‰∫õÁØÑ‰æã‰πüÂèØ‰ª•ÊàêÁÇ∫Ê©üÂô®Â≠∏ÁøíÁöÑÈáçË¶ÅË≥áË®ä‰æÜÊ∫ê„ÄÇ
  ÁôºÁèæ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫ÜÂ§ßÈáèÁî±‰∫∫È°ûÊí∞ÂØ´ÁöÑËá™ÁÑ∂Ë™ûË®ÄÂïèÈ°åÂèäÂÖ∂Â∞çÊáâÁöÑ SPARQL Êü•Ë©¢ÔºåÈÄô‰∫õÊü•Ë©¢ÊòØÂ§öÂπ¥‰æÜÂú® SIB ÁëûÂ£´ÁîüÁâ©Ë≥áË®äÂ≠∏Á†îÁ©∂ÊâÄÁöÑ‰∏çÂêåÁ†îÁ©∂Â∞èÁµÑ‰∏≠Êî∂ÈõÜÁöÑÔºåÊ∂µËìã‰∫ÜËÅØÈÇ¶ÁîüÁâ©Ë≥áË®äÂ≠∏Áü•Ë≠òÂúñË≠ú (KG)„ÄÇË©≤ÈõÜÂêàÂåÖÂê´ 1000 Â§öÂÄãÁØÑ‰æãÂïèÈ°åÂíåÊü•Ë©¢ÔºåÂåÖÊã¨ 65 ÂÄãËÅØÈÇ¶Êü•Ë©¢„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂü∫ÊñºÁèæÊúâÊ®ôÊ∫ñÔºå‰ª•ÊúÄÂ∞ëÁöÑÂÖÉË≥áÊñôÁµ±‰∏ÄË°®Á§∫ÈÄô‰∫õÁØÑ‰æã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÂ•óÂª£Ê≥õÁöÑÈñãÊ∫êÊáâÁî®Á®ãÂºèÔºåÂåÖÊã¨Êü•Ë©¢ÂúñÂΩ¢Ë¶ñË¶∫ÂåñÂíåÊô∫ÊÖßÊü•Ë©¢Á∑®ËºØÂô®ÔºåÈÄô‰∫õÊáâÁî®Á®ãÂºèÂæàÂÆπÊòìË¢´Êé°Áî®ÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑ KG Á∂≠Ë≠∑‰∫∫Âì°ÈáçË§á‰ΩøÁî®„ÄÇ
  ÁµêË´ñ„ÄÇÊàëÂÄëÈºìÂãµÁ§æÁæ§Êé°Áî®‰∏¶Êì¥ÂÖÖÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÔºå‰ª•Áç≤ÂæóÊõ¥Ë±êÂØåÁöÑ KG ÂÖÉË≥áÊñôÂíåÊîπÂñÑÁöÑË™ûÊÑèÁ∂≤Ë∑ØÊúçÂãô„ÄÇ</paragraph>

##### **LightRAG: Simple and Fast Retrieval-Augmented Generation**
2410.05779v1 by Zirui Guo, Lianghao Xia, Yanhua Yu, Tu Ao, Chao Huang

Retrieval-Augmented Generation (RAG) systems enhance large language models
(LLMs) by integrating external knowledge sources, enabling more accurate and
contextually relevant responses tailored to user needs. However, existing RAG
systems have significant limitations, including reliance on flat data
representations and inadequate contextual awareness, which can lead to
fragmented answers that fail to capture complex inter-dependencies. To address
these challenges, we propose LightRAG, which incorporates graph structures into
text indexing and retrieval processes. This innovative framework employs a
dual-level retrieval system that enhances comprehensive information retrieval
from both low-level and high-level knowledge discovery. Additionally, the
integration of graph structures with vector representations facilitates
efficient retrieval of related entities and their relationships, significantly
improving response times while maintaining contextual relevance. This
capability is further enhanced by an incremental update algorithm that ensures
the timely integration of new data, allowing the system to remain effective and
responsive in rapidly changing data environments. Extensive experimental
validation demonstrates considerable improvements in retrieval accuracy and
efficiency compared to existing approaches. We have made our LightRAG
open-source and available at the link: https://github.com/HKUDS/LightRAG.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Á≥ªÁµ±ÈÄèÈÅéÊï¥ÂêàÂ§ñÈÉ®Áü•Ë≠ò‰æÜÊ∫ê‰æÜÂ¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåËÉΩÈáùÂ∞ç‰ΩøÁî®ËÄÖÈúÄÊ±ÇÊèê‰æõÊõ¥Ê∫ñÁ¢∫‰∏îËàáËÑàÁµ°Áõ∏ÈóúÁöÑÂõûÊáâ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ RAG Á≥ªÁµ±ÊúâÂæàÂ§ßÁöÑÈôêÂà∂ÔºåÂåÖÊã¨‰æùË≥¥Âπ≥Èù¢Ë≥áÊñôË°®Á§∫Âíå‰∏çË∂≥ÁöÑËÑàÁµ°ÊÑüÁü•ÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥ÁÑ°Ê≥ïÊçïÊçâË§áÈõúÁõ∏‰∫í‰æùË≥¥ÊÄßÁöÑÁâáÊÆµÂºèÁ≠îÊ°à„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ LightRAGÔºåÂÆÉÂ∞áÂúñÂΩ¢ÁµêÊßãÁ¥çÂÖ•ÊñáÂ≠óÁ¥¢ÂºïÂíåÊ™¢Á¥¢ÊµÅÁ®ã‰∏≠„ÄÇÈÄôÂÄãÂâµÊñ∞Êû∂ÊßãÊé°Áî®ÈõôÂ±§Ê™¢Á¥¢Á≥ªÁµ±ÔºåËÉΩÂæû‰ΩéÂ±§Á¥öÂíåÈ´òÂ±§Á¥öÁü•Ë≠òÁôºÁèæ‰∏≠Â¢ûÂº∑ÂÖ®Èù¢ÁöÑË≥áË®äÊ™¢Á¥¢„ÄÇÊ≠§Â§ñÔºåÂ∞áÂúñÂΩ¢ÁµêÊßãËàáÂêëÈáèË°®Á§∫Êï¥ÂêàÔºåÊúâÂä©ÊñºÊúâÊïàÊ™¢Á¥¢Áõ∏ÈóúÂØ¶È´îÂèäÂÖ∂Èóú‰øÇÔºåÂ§ßÂπÖÊîπÂñÑÂõûÊáâÊôÇÈñìÔºåÂêåÊôÇÁ∂≠ÊåÅËÑàÁµ°Áõ∏ÈóúÊÄß„ÄÇÊ≠§ÂäüËÉΩÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéÂ¢ûÈáèÊõ¥Êñ∞ÊºîÁÆóÊ≥ïÂ¢ûÂº∑ÔºåÂèØÁ¢∫‰øùÂèäÊôÇÊï¥ÂêàÊñ∞Ë≥áÊñôÔºåËÆìÁ≥ªÁµ±Âú®Âø´ÈÄüËÆäÂåñÁöÑË≥áÊñôÁí∞Â¢É‰∏≠‰øùÊåÅÊúâÊïà‰∏îÂç≥ÊôÇÂõûÊáâ„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÈ©óË≠âÈ°ØÁ§∫ÔºåËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊ™¢Á¥¢Ê∫ñÁ¢∫Â∫¶ÂíåÊïàÁéáÈÉΩÊúâÈ°ØËëóÁöÑÊîπÂñÑ„ÄÇÊàëÂÄëÂ∑≤ÈñãÊîæ LightRAG ÂéüÂßãÁ¢ºÔºå‰∏¶Êèê‰æõ‰ª•‰∏ãÈÄ£ÁµêÔºöhttps://github.com/HKUDS/LightRAG„ÄÇ

##### **Information Discovery in e-Commerce**
2410.05763v2 by Zhaochun Ren, Xiangnan He, Dawei Yin, Maarten de Rijke

Electronic commerce, or e-commerce, is the buying and selling of goods and
services, or the transmitting of funds or data online. E-commerce platforms
come in many kinds, with global players such as Amazon, Airbnb, Alibaba, eBay
and platforms targeting specific geographic regions. Information retrieval has
a natural role to play in e-commerce, especially in connecting people to goods
and services. Information discovery in e-commerce concerns different types of
search (e.g., exploratory search vs. lookup tasks), recommender systems, and
natural language processing in e-commerce portals. The rise in popularity of
e-commerce sites has made research on information discovery in e-commerce an
increasingly active research area. This is witnessed by an increase in
publications and dedicated workshops in this space. Methods for information
discovery in e-commerce largely focus on improving the effectiveness of
e-commerce search and recommender systems, on enriching and using knowledge
graphs to support e-commerce, and on developing innovative question answering
and bot-based solutions that help to connect people to goods and services. In
this survey, an overview is given of the fundamental infrastructure,
algorithms, and technical solutions for information discovery in e-commerce.
The topics covered include user behavior and profiling, search, recommendation,
and language technology in e-commerce.

ÊëòË¶ÅÔºöÈõªÂ≠êÂïÜÂãôÔºåÊàñÁ®±ÈõªÂ≠êÂïÜÂãôÔºåÊòØË≤∑Ë≥£ÂïÜÂìÅÂíåÊúçÂãôÔºåÊàñÂú®Á∑ö‰∏äÂÇ≥Ëº∏Ë≥áÈáëÊàñË≥áÊñô„ÄÇÈõªÂ≠êÂïÜÂãôÂπ≥Âè∞Á®ÆÈ°ûÁπÅÂ§öÔºåÂåÖÊã¨ Amazon„ÄÅAirbnb„ÄÅAlibaba„ÄÅeBay Á≠âÂÖ®ÁêÉÊÄßÊ•≠ËÄÖÔºå‰ª•ÂèäÈéñÂÆöÁâπÂÆöÂú∞ÁêÜÂçÄÂüüÁöÑÂπ≥Âè∞„ÄÇË≥áË®äÊ™¢Á¥¢Âú®ÈõªÂ≠êÂïÜÂãô‰∏≠ÊâÆÊºîËá™ÁÑ∂ÁöÑËßíËâ≤ÔºåÁâπÂà•ÊòØÂú®Â∞á‰∫∫ÂÄëËàáÂïÜÂìÅÂíåÊúçÂãôÈÄ£ÁµêËµ∑‰æÜÊñπÈù¢„ÄÇÈõªÂ≠êÂïÜÂãô‰∏≠ÁöÑË≥áË®äÁôºÁèæÊ∂âÂèä‰∏çÂêåÈ°ûÂûãÁöÑÊêúÂ∞ãÔºà‰æãÂ¶ÇÊé¢Á¥¢ÊÄßÊêúÂ∞ãËàáÊü•Ë©¢‰ªªÂãôÔºâ„ÄÅÊé®Ëñ¶Á≥ªÁµ±Ôºå‰ª•ÂèäÈõªÂ≠êÂïÜÂãôÂÖ•Âè£Á∂≤Á´ô‰∏≠ÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÇÈõªÂ≠êÂïÜÂãôÁ∂≤Á´ôÁöÑÊôÆÂèä‰ΩøÈõªÂ≠êÂïÜÂãô‰∏≠ÁöÑË≥áË®äÁôºÁèæÁ†îÁ©∂ÊàêÁÇ∫‰∏ÄÂÄãË∂ä‰æÜË∂äÊ¥ªË∫çÁöÑÁ†îÁ©∂È†òÂüü„ÄÇÈÄôÈªûÂèØ‰ª•ÂæûÈÄôÊñπÈù¢ÁöÑÂá∫ÁâàÂìÅÂíåÂ∞àÈñÄÁ†îË®éÊúÉÁöÑÂ¢ûÂä†ÁúãÂá∫„ÄÇÈõªÂ≠êÂïÜÂãô‰∏≠ÁöÑË≥áË®äÁôºÁèæÊñπÊ≥ï‰∏ªË¶ÅËëóÈáçÊñºÊîπÂñÑÈõªÂ≠êÂïÜÂãôÊêúÂ∞ãÂíåÊé®Ëñ¶Á≥ªÁµ±ÁöÑÊïàËÉΩÔºåË±êÂØå‰∏¶‰ΩøÁî®Áü•Ë≠òÂúñË°®‰æÜÊîØÊè¥ÈõªÂ≠êÂïÜÂãôÔºå‰ª•ÂèäÈñãÁôºÂâµÊñ∞ÁöÑÂïèÈ°åËß£Á≠îÂíåÊ©üÂô®‰∫∫Ëß£Ê±∫ÊñπÊ°àÔºå‰ª•ÂçîÂä©Â∞á‰∫∫ÂÄëËàáÂïÜÂìÅÂíåÊúçÂãôÈÄ£ÁµêËµ∑‰æÜ„ÄÇÂú®ÈÄôÈ†ÖË™øÊü•‰∏≠ÔºåÊ¶ÇËø∞‰∫ÜÈõªÂ≠êÂïÜÂãô‰∏≠Ë≥áË®äÁôºÁèæÁöÑÂü∫Êú¨Êû∂Êßã„ÄÅÊºîÁÆóÊ≥ïÂíåÊäÄË°ìËß£Ê±∫ÊñπÊ°à„ÄÇÊâÄÊ∂µËìãÁöÑ‰∏ªÈ°åÂåÖÊã¨ÈõªÂ≠êÂïÜÂãô‰∏≠ÁöÑ‰ΩøÁî®ËÄÖË°åÁÇ∫ÂíåË®≠ÂÆöÊ™î„ÄÅÊêúÂ∞ã„ÄÅÊé®Ëñ¶ÂíåË™ûË®ÄÊäÄË°ì„ÄÇ

##### **Vector-ICL: In-context Learning with Continuous Vector Representations**
2410.05629v1 by Yufan Zhuang, Chandan Singh, Liyuan Liu, Jingbo Shang, Jianfeng Gao

Large language models (LLMs) have shown remarkable in-context learning (ICL)
capabilities on textual data. We explore whether these capabilities can be
extended to continuous vectors from diverse domains, obtained from black-box
pretrained encoders. By aligning input data with an LLM's embedding space
through lightweight projectors, we observe that LLMs can effectively process
and learn from these projected vectors, which we term Vector-ICL. In
particular, we find that pretraining projectors with general language modeling
objectives enables Vector-ICL, while task-specific finetuning further enhances
performance. In our experiments across various tasks and modalities, including
text reconstruction, numerical function regression, text classification,
summarization, molecule captioning, time-series classification, graph
classification, and fMRI decoding, Vector-ICL often surpasses both few-shot ICL
and domain-specific model or tuning. We further conduct analyses and case
studies, indicating the potential of LLMs to process vector representations
beyond traditional token-based paradigms.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÊñáÊú¨Ë≥áÊñô‰∏äÂ±ïÁèæÂá∫È°ØËëóÁöÑË™ûÂ¢ÉÂ≠∏Áøí (ICL) ËÉΩÂäõ„ÄÇÊàëÂÄëÊé¢Ë®éÈÄô‰∫õËÉΩÂäõÊòØÂê¶ÂèØ‰ª•Êì¥Â±ïÂà∞Âæû‰∏çÂêåÈ†òÂüüÂèñÂæóÔºå‰∏¶Áî±ÈªëÁÆ±È†êË®ìÁ∑¥Á∑®Á¢ºÂô®Áç≤ÂæóÁöÑÈÄ£Á∫åÂêëÈáè„ÄÇÈÄèÈÅéËºïÈáèÁ¥öÊäïÂΩ±Âô®Â∞áËº∏ÂÖ•Ë≥áÊñôËàá LLM ÁöÑÂµåÂÖ•Á©∫ÈñìÂ∞çÈΩäÔºåÊàëÂÄëËßÄÂØüÂà∞ LLM ÂèØ‰ª•ÊúâÊïàÂú∞ËôïÁêÜÂíåÂ≠∏ÁøíÈÄô‰∫õÊäïÂΩ±ÂêëÈáèÔºåÊàëÂÄëÁ®±‰πãÁÇ∫ Vector-ICL„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁôºÁèæ‰ΩøÁî®‰∏ÄËà¨Ë™ûË®ÄÂª∫Ê®°ÁõÆÊ®ôÈ†êË®ìÁ∑¥ÊäïÂΩ±Âô®ÂèØ‰ª•ÂïüÁî® Vector-ICLÔºåËÄåÁâπÂÆö‰ªªÂãôÁöÑÂæÆË™øÈÄ≤‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊïàËÉΩ„ÄÇÂú®ÊàëÂÄëË∑®Ë∂äÂêÑÁ®Æ‰ªªÂãôÂíåÊ®°ÊÖãÁöÑÂØ¶È©ó‰∏≠ÔºåÂåÖÊã¨ÊñáÂ≠óÈáçÂª∫„ÄÅÊï∏ÂÄºÂáΩÊï∏ÂõûÊ≠∏„ÄÅÊñáÂ≠óÂàÜÈ°û„ÄÅÊëòË¶Å„ÄÅÂàÜÂ≠êÊ®ôÈ°å„ÄÅÊôÇÈñìÂ∫èÂàóÂàÜÈ°û„ÄÅÂúñÂΩ¢ÂàÜÈ°ûÂíå fMRI Ëß£Á¢ºÔºåVector-ICL ÈÄöÂ∏∏ÈÉΩÂÑ™ÊñºÂ∞ëÊ¨°Êï∏ ICL ÂíåÁâπÂÆöÈ†òÂüüÊ®°ÂûãÊàñË™øÊï¥„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄ≤Ë°åÂàÜÊûêÂíåÊ°à‰æãÁ†îÁ©∂ÔºåÊåáÂá∫ LLM ËôïÁêÜÂêëÈáèË°®Á§∫ÁöÑÊΩõÂäõÔºåË∂ÖË∂äÂÇ≥Áµ±ÁöÑÂü∫ÊñºÊ®ôË®òÁöÑÁØÑ‰æã„ÄÇ

##### **Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives**
2410.05558v1 by Xinliang Frederick Zhang, Nick Beauchamp, Lu Wang

Reasoning about time and temporal relations is an integral aspect of human
cognition, essential for perceiving the world and navigating our experiences.
Though large language models (LLMs) have demonstrated impressive performance in
many reasoning tasks, temporal reasoning remains challenging due to its
intrinsic complexity. In this work, we first study an essential task of
temporal reasoning -- temporal graph generation, to unveil LLMs' inherent,
global reasoning capabilities. We show that this task presents great challenges
even for the most powerful LLMs, such as GPT-3.5/4. We also notice a
significant performance gap by small models (<10B) that lag behind LLMs by 50%.
Next, we study how to close this gap with a budget constraint, e.g., not using
model finetuning. We propose a new prompting technique tailored for temporal
reasoning, Narrative-of-Thought (NoT), that first converts the events set to a
Python class, then prompts a small model to generate a temporally grounded
narrative, guiding the final generation of a temporal graph. Extensive
experiments showcase the efficacy of NoT in improving various metrics. Notably,
NoT attains the highest F1 on the Schema-11 evaluation set, while securing an
overall F1 on par with GPT-3.5. NoT also achieves the best structural
similarity across the board, even compared with GPT-3.5/4. Our code is
available at https://github.com/launchnlp/NoT.

ÊëòË¶ÅÔºöÊé®ÁêÜÊôÇÈñìÂíåÊôÇÈñìÈóú‰øÇÊòØ‰∫∫È°ûË™çÁü•‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑ‰∏ÄÁí∞ÔºåÂ∞çÊñºÊÑüÁü•‰∏ñÁïåÂíåÂ∞éËà™ÊàëÂÄëÁöÑÁ∂ìÈ©óËá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ë®±Â§öÊé®ÁêÜ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÁî±ÊñºÊôÇÈñìÊé®ÁêÜÁöÑÂÖßÂú®Ë§áÈõúÊÄßÔºåÂõ†Ê≠§‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÁ†îÁ©∂ÊôÇÈñìÊé®ÁêÜÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨‰ªªÂãô‚Äî‚ÄîÊôÇÈñìÂúñË°®ÁîüÊàêÔºå‰ª•Êè≠Á§∫ LLM Âõ∫ÊúâÁöÑÂÖ®Â±ÄÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëË°®ÊòéÔºåÂç≥‰ΩøÂ∞çÊñºÂäüËÉΩÊúÄÂº∫Â§ßÁöÑ LLMÔºå‰æãÂ¶Ç GPT-3.5/4ÔºåÊ≠§‰ªªÂãô‰πüÊèêÂá∫‰∫ÜÂ∑®Â§ßÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÈÇÑÊ≥®ÊÑèÂà∞ÔºåËêΩÂæåÊñº LLM 50% ÁöÑÂ∞èÂûãÊ®°Âûã (<10B) Â≠òÂú®È°ØËëóÁöÑÊÄßËÉΩÂ∑ÆË∑ù„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÁ†îÁ©∂Â¶Ç‰ΩïÂú®È†êÁÆóÁ¥ÑÊùü‰∏ãÁ∏ÆÂ∞èÈÄôÁ®ÆÂ∑ÆË∑ùÔºå‰æãÂ¶Ç‰∏ç‰ΩøÁî®Ê®°ÂûãÂæÆË™ø„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈáùÂ∞çÊôÇÈñìÊé®ÁêÜÈáèË∫´ÂÆöÂà∂ÁöÑÊñ∞ÊèêÁ§∫ÊäÄË°ìÔºåÂç≥ÊÄùËÄÉÊïò‰∫ã (NoT)ÔºåÂÆÉÈ¶ñÂÖàÂ∞á‰∫ã‰ª∂ÈõÜËΩâÊèõÁÇ∫ Python È°ûÔºåÁÑ∂ÂæåÊèêÁ§∫‰∏ÄÂÄãÂ∞èÂûãÊ®°ÂûãÁîüÊàê‰∏ÄÂÄãÊôÇÈñì‰æùÊìöÁöÑÊïò‰∫ãÔºåÊåáÂ∞éÊôÇÈñìÂúñË°®ÁöÑÊúÄÁµÇÁîüÊàê„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óÂ±ïÁ§∫‰∫Ü NoT Âú®ÊîπÂñÑÂêÑÁ®ÆÊåáÊ®ôÊñπÈù¢ÁöÑÂäüÊïà„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåNoT Âú® Schema-11 Ë©ï‰º∞ÈõÜ‰∏≠Áç≤Âæó‰∫ÜÊúÄÈ´òÁöÑ F1ÔºåÂêåÊôÇÁ¢∫‰øù‰∫ÜËàá GPT-3.5 Áõ∏Áï∂ÁöÑÊï¥È´î F1„ÄÇÂç≥‰ΩøËàá GPT-3.5/4 Áõ∏ÊØîÔºåNoT ‰πüÂú®ÂêÑÊñπÈù¢ÂØ¶Áèæ‰∫ÜÊúÄ‰Ω≥ÁµêÊßãÁõ∏‰ººÊÄß„ÄÇÊàëÂÄëÁöÑ‰ª£Á¢ºÂèØÂú® https://github.com/launchnlp/NoT ‰∏≠Áç≤Âæó„ÄÇ

##### **Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents**
2410.05130v1 by Yuwei Hu, Runlin Lei, Xinyi Huang, Zhewei Wei, Yongchao Liu

Recent research has explored the use of Large Language Models (LLMs) for
tackling complex graph reasoning tasks. However, due to the intricacies of
graph structures and the inherent limitations of LLMs in handling long text,
current approaches often fail to deliver satisfactory accuracy, even on
small-scale graphs and simple tasks. To address these challenges, we introduce
GraphAgent-Reasoner, a fine-tuning-free framework that utilizes a multi-agent
collaboration strategy for explicit and precise graph reasoning. Inspired by
distributed graph computation theory, our framework decomposes graph problems
into smaller, node-centric tasks that are distributed among multiple agents.
The agents collaborate to solve the overall problem, significantly reducing the
amount of information and complexity handled by a single LLM, thus enhancing
the accuracy of graph reasoning. By simply increasing the number of agents,
GraphAgent-Reasoner can efficiently scale to accommodate larger graphs with
over 1,000 nodes. Evaluated on the GraphInstruct dataset, our framework
demonstrates near-perfect accuracy on polynomial-time graph reasoning tasks,
significantly outperforming the best available models, both closed-source and
fine-tuned open-source variants. Our framework also demonstrates the capability
to handle real-world graph reasoning applications such as webpage importance
analysis.

ÊëòË¶ÅÔºöËøëÊúüÁ†îÁ©∂Â∑≤Êé¢Ë®é‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜËôïÁêÜË§áÈõúÁöÑÂúñÂΩ¢Êé®ÁêÜ‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂúñÂΩ¢ÁµêÊßãÁöÑË§áÈõúÊÄßÂíå LLM Âú®ËôïÁêÜÈï∑ÊñáÊú¨ÊôÇÂõ∫ÊúâÁöÑÈôêÂà∂ÔºåÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏ÁÑ°Ê≥ïÊèê‰æõ‰ª§‰∫∫ÊªøÊÑèÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÂç≥‰ΩøÊòØÂú®Â∞èË¶èÊ®°ÂúñÂΩ¢ÂíåÁ∞°ÂñÆ‰ªªÂãô‰∏ä„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü GraphAgent-ReasonerÔºåÈÄôÊòØ‰∏ÄÂÄãÁÑ°ÈúÄÂæÆË™øÁöÑÊ°ÜÊû∂ÔºåÂÆÉÂà©Áî®Â§ö‰∏ªÈ´îÂçî‰ΩúÁ≠ñÁï•ÈÄ≤Ë°åÊòéÁ¢∫‰∏îÁ≤æÁ¢∫ÁöÑÂúñÂΩ¢Êé®ÁêÜ„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂ÂèóÂà∞ÂàÜÊï£ÂºèÂúñÂΩ¢Ë®àÁÆóÁêÜË´ñÁöÑÂïüÁôºÔºåÂ∞áÂúñÂΩ¢ÂïèÈ°åÂàÜËß£ÊàêÊõ¥Â∞èÁöÑ‰ª•ÁØÄÈªûÁÇ∫‰∏≠ÂøÉÁöÑ‰ªªÂãôÔºå‰∏¶Â∞áÈÄô‰∫õ‰ªªÂãôÂàÜÈÖçÁµ¶Â§öÂÄã‰∏ªÈ´î„ÄÇÈÄô‰∫õ‰∏ªÈ´îÂçî‰ΩúËß£Ê±∫Êï¥È´îÂïèÈ°åÔºåÂ§ßÂπÖÊ∏õÂ∞ëÂñÆÂÄã LLM ËôïÁêÜÁöÑË≥áË®äÈáèÂíåË§áÈõúÂ∫¶ÔºåÂæûËÄåÊèêÂçáÂúñÂΩ¢Êé®ÁêÜÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÈÄèÈÅéÂñÆÁ¥îÂ¢ûÂä†‰∏ªÈ´îÊï∏ÈáèÔºåGraphAgent-Reasoner ÂèØ‰ª•ÊúâÊïàÊì¥ÂÖÖ‰ª•ÂÆπÁ¥çÁØÄÈªûË∂ÖÈÅé 1,000 ÂÄãÁöÑÂ§ßÂûãÂúñÂΩ¢„ÄÇÂú® GraphInstruct Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞ÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂Âú®Â§öÈ†ÖÂºèÊôÇÈñìÂúñÂΩ¢Êé®ÁêÜ‰ªªÂãô‰∏äÂ±ïÁèæÂá∫Ëøë‰πéÂÆåÁæéÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÂ§ßÂπÖÂÑ™ÊñºÂ∏ÇÈù¢‰∏äÊúÄÂ•ΩÁöÑÊ®°ÂûãÔºåÂåÖÂê´ÈñâÊ∫êÂíåÂæÆË™øÈñãÊ∫êÁâàÊú¨„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂‰πüÂ±ïÁèæÂá∫ËôïÁêÜÁúüÂØ¶‰∏ñÁïåÂúñÂΩ¢Êé®ÁêÜÊáâÁî®Á®ãÂºèÁöÑËÉΩÂäõÔºå‰æãÂ¶ÇÁ∂≤È†ÅÈáçË¶ÅÊÄßÂàÜÊûê„ÄÇ

##### **Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law**
2410.04949v1 by Yongming Chen, Miner Chen, Ye Zhu, Juan Pei, Siyu Chen, Yu Zhou, Yi Wang, Yifan Zhou, Hao Li, Songan Zhang

Court efficiency is vital for social stability. However, in most countries
around the world, the grassroots courts face case backlogs, with decisions
relying heavily on judicial personnel's cognitive labor, lacking intelligent
tools to improve efficiency. To address this issue, we propose an efficient law
article recommendation approach utilizing a Knowledge Graph (KG) and a Large
Language Model (LLM). Firstly, we propose a Case-Enhanced Law Article Knowledge
Graph (CLAKG) as a database to store current law statutes, historical case
information, and correspondence between law articles and historical cases.
Additionally, we introduce an automated CLAKG construction method based on LLM.
On this basis, we propose a closed-loop law article recommendation method.
Finally, through a series of experiments using judgment documents from the
website "China Judgements Online", we have improved the accuracy of law article
recommendation in cases from 0.549 to 0.694, demonstrating that our proposed
method significantly outperforms baseline approaches.

ÊëòË¶ÅÔºöÊ≥ïÈô¢ÊïàÁéáÂ∞çÊñºÁ§æÊúÉÁ©©ÂÆöËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÂú®‰∏ñÁïåÂ§ßÂ§öÊï∏ÂúãÂÆ∂‰∏≠ÔºåÂü∫Â±§Ê≥ïÈô¢Èù¢Ëá®Ê°à‰ª∂Á©çÂ£ìÔºåÂà§Ê±∫Âö¥Èáç‰æùË≥¥Âè∏Ê≥ï‰∫∫Âì°ÁöÑË™çÁü•ÂãûÂãïÔºåÁº∫‰πèÊèêÈ´òÊïàÁéáÁöÑÊô∫ËÉΩÂ∑•ÂÖ∑„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂà©Áî®Áü•Ë≠òÂúñË≠ú (KG) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈ´òÊïàÊ≥ïÂæãÊ¢ùÊñáÊé®Ëñ¶ÊñπÊ≥ï„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊ°à‰æãÂ¢ûÂº∑Ê≥ïÂæãÊ¢ùÊñáÁü•Ë≠òÂúñË≠ú (CLAKG) ‰ΩúÁÇ∫‰∏ÄÂÄãË≥áÊñôÂ∫´ÔºåÁî®ÊñºÂÑ≤Â≠òÁèæË°åÊ≥ïÂæãÊ≥ïË¶è„ÄÅÊ≠∑Âè≤Ê°à‰æãË≥áË®äÂíåÊ≥ïÂæãÊ¢ùÊñáËàáÊ≠∑Âè≤Ê°à‰æã‰πãÈñìÁöÑÂ∞çÊáâÈóú‰øÇ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÂü∫Êñº LLM ÁöÑËá™ÂãïÂåñ CLAKG ÊßãÂª∫ÊñπÊ≥ï„ÄÇÂú®Ê≠§Âü∫Á§é‰∏äÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈñâÁí∞Ê≥ïÂæãÊ¢ùÊñáÊé®Ëñ¶ÊñπÊ≥ï„ÄÇÊúÄÂæåÔºåÈÄèÈÅé‰∏ÄÈÄ£‰∏≤‰ΩøÁî®‰æÜËá™Á∂≤Á´ô„Äå‰∏≠ÂúãË£ÅÂà§ÊñáÊõ∏Á∂≤„ÄçÁöÑË£ÅÂà§ÊñáÊõ∏ÁöÑÂØ¶È©óÔºåÊàëÂÄëÂ∞áÊ°à‰ª∂‰∏≠Ê≥ïÂæãÊ¢ùÊñáÊé®Ëñ¶ÁöÑÊ∫ñÁ¢∫ÁéáÂæû 0.549 ÊèêÂçáËá≥ 0.694ÔºåË≠âÊòéÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÈ°ØËëóÂÑ™ÊñºÂü∫Ê∫ñÊñπÊ≥ï„ÄÇ

##### **GARLIC: LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph for Long Document QA**
2410.04790v1 by Xinyu Wang, Yanzheng Xiang, Lin Gui, Yulan He

In the past, Retrieval-Augmented Generation (RAG) methods split text into
chunks to enable language models to handle long documents. Recent tree-based
RAG methods are able to retrieve detailed information while preserving global
context. However, with the advent of more powerful LLMs, such as Llama 3.1,
which offer better comprehension and support for longer inputs, we found that
even recent tree-based RAG methods perform worse than directly feeding the
entire document into Llama 3.1, although RAG methods still hold an advantage in
reducing computational costs. In this paper, we propose a new retrieval method,
called LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph
(GARLIC), which outperforms previous state-of-the-art baselines, including
Llama 3.1, while retaining the computational efficiency of RAG methods. Our
method introduces several improvements: (1) Rather than using a tree structure,
we construct a Hierarchical Weighted Directed Acyclic Graph with many-to-many
summarization, where the graph edges are derived from attention mechanisms, and
each node focuses on a single event or very few events. (2) We introduce a
novel retrieval method that leverages the attention weights of LLMs rather than
dense embedding similarity. Our method allows for searching the graph along
multiple paths and can terminate at any depth. (3) We use the LLM to control
the retrieval process, enabling it to dynamically adjust the amount and depth
of information retrieved for different queries. Experimental results show that
our method outperforms previous state-of-the-art baselines, including Llama
3.1, on two single-document and two multi-document QA datasets, while
maintaining similar computational complexity to traditional RAG methods.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈÅéÂéªÔºåÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÊñπÊ≥ïÊúÉÂ∞áÊñáÂ≠óÂàáÂâ≤ÊàêÂ°äÔºå‰ª•‰ΩøË™ûË®ÄÊ®°ÂûãËÉΩÂ§†ËôïÁêÜÈï∑ÁØáÊñá‰ª∂„ÄÇÊúÄËøëÁöÑÂü∫ÊñºÊ®πÁöÑ RAG ÊñπÊ≥ïËÉΩÂ§†Âú®‰øùÁïôÊï¥È´îËÑàÁµ°ÁöÑÂêåÊôÇÊ™¢Á¥¢Ë©≥Á¥∞Ë≥áË®ä„ÄÇÁÑ∂ËÄåÔºåÈö®ËëóÂäüËÉΩÊõ¥Âº∑Â§ßÁöÑ LLMÔºà‰æãÂ¶Ç Llama 3.1ÔºâÁöÑÂá∫ÁèæÔºåÈÄô‰∫õ LLM Êèê‰æõ‰∫ÜÊõ¥Â•ΩÁöÑÁêÜËß£ÂäõÂíåÂ∞çÊõ¥Èï∑Ëº∏ÂÖ•ÁöÑÊîØÊè¥ÔºåÊàëÂÄëÁôºÁèæÂç≥‰ΩøÊòØÊúÄËøëÁöÑÂü∫ÊñºÊ®πÁöÑ RAG ÊñπÊ≥ï‰πüÊØîÁõ¥Êé•Â∞áÊï¥ÂÄãÊñá‰ª∂Ëº∏ÂÖ• Llama 3.1 ÁöÑË°®ÁèæÊõ¥Â∑ÆÔºåÂÑòÁÆ° RAG ÊñπÊ≥ïÂú®Èôç‰ΩéÈÅãÁÆóÊàêÊú¨ÊñπÈù¢‰ªçÂÖ∑ÂÇôÂÑ™Âã¢„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊ™¢Á¥¢ÊñπÊ≥ïÔºåÁ®±ÁÇ∫ÂÖ∑ÊúâÂàÜÂ±§Âä†Ê¨äÂúñÁöÑ LLM ÂºïÂ∞éÂãïÊÖãÈÄ≤Â∫¶ÊéßÂà∂ (GARLIC)ÔºåÂÆÉÂÑ™ÊñºÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤Âü∫Ê∫ñÔºåÂåÖÊã¨ Llama 3.1ÔºåÂêåÊôÇ‰øùÁïô‰∫Ü RAG ÊñπÊ≥ïÁöÑÈÅãÁÆóÊïàÁéá„ÄÇÊàëÂÄëÁöÑÊîπÈÄ≤ÊñπÊ≥ïÂºïÂÖ•‰∫ÜÂ§öÈ†ÖÊîπÈÄ≤Ôºö(1) ÊàëÂÄëÊ≤íÊúâ‰ΩøÁî®Ê®πÁãÄÁµêÊßãÔºåËÄåÊòØÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂÖ∑ÊúâÂ§öÂ∞çÂ§öÊëòË¶ÅÁöÑÂàÜÂ±§Âä†Ê¨äÊúâÂêëÁÑ°Áí∞ÂúñÔºåÂÖ∂‰∏≠ÂúñÈÇäÁ∑£Ê∫êËá™Ê≥®ÊÑèÂäõÊ©üÂà∂ÔºåÊØèÂÄãÁØÄÈªûÈÉΩÂ∞àÊ≥®ÊñºÂñÆ‰∏Ä‰∫ã‰ª∂ÊàñÊ•µÂ∞ëÊï∏‰∫ã‰ª∂„ÄÇ(2) ÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ™¢Á¥¢ÊñπÊ≥ïÔºåÂÆÉÂà©Áî® LLM ÁöÑÊ≥®ÊÑèÂäõÊ¨äÈáçÔºåËÄå‰∏çÊòØÂØÜÈõÜÂµåÂÖ•Áõ∏‰ººÊÄß„ÄÇÊàëÂÄëÁöÑÊîπÈÄ≤ÊñπÊ≥ïÂÖÅË®±Ê≤øÂ§öÂÄãË∑ØÂæëÊêúÂ∞ãÂúñÔºå‰∏¶‰∏îÂèØ‰ª•Âú®‰ªª‰ΩïÊ∑±Â∫¶ÁµÇÊ≠¢„ÄÇ(3) ÊàëÂÄë‰ΩøÁî® LLM ‰æÜÊéßÂà∂Ê™¢Á¥¢ÈÅéÁ®ãÔºå‰ΩøÂÖ∂ËÉΩÂ§†ÂãïÊÖãË™øÊï¥ÁÇ∫‰∏çÂêåÊü•Ë©¢Ê™¢Á¥¢ÁöÑË≥áË®äÈáèÂíåÊ∑±Â∫¶„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊîπÈÄ≤ÊñπÊ≥ïÂú®ÂÖ©ÂÄãÂñÆÊñá‰ª∂ÂíåÂÖ©ÂÄãÂ§öÊñá‰ª∂ÂïèÁ≠îË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤Âü∫Ê∫ñÔºåÂåÖÊã¨ Llama 3.1ÔºåÂêåÊôÇÁ∂≠ÊåÅËàáÂÇ≥Áµ± RAG ÊñπÊ≥ïÈ°û‰ººÁöÑÈÅãÁÆóË§áÈõúÂ∫¶„ÄÇ</paragraph>

##### **Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval**
2410.04585v1 by Pengcheng Jiang, Cao Xiao, Minhao Jiang, Parminder Bhatia, Taha Kass-Hout, Jimeng Sun, Jiawei Han

Large language models (LLMs) have demonstrated significant potential in
clinical decision support. Yet LLMs still suffer from hallucinations and lack
fine-grained contextual medical knowledge, limiting their high-stake healthcare
applications such as clinical diagnosis. Traditional retrieval-augmented
generation (RAG) methods attempt to address these limitations but frequently
retrieve sparse or irrelevant information, undermining prediction accuracy. We
introduce KARE, a novel framework that integrates knowledge graph (KG)
community-level retrieval with LLM reasoning to enhance healthcare predictions.
KARE constructs a comprehensive multi-source KG by integrating biomedical
databases, clinical literature, and LLM-generated insights, and organizes it
using hierarchical graph community detection and summarization for precise and
contextually relevant information retrieval. Our key innovations include: (1) a
dense medical knowledge structuring approach enabling accurate retrieval of
relevant information; (2) a dynamic knowledge retrieval mechanism that enriches
patient contexts with focused, multi-faceted medical insights; and (3) a
reasoning-enhanced prediction framework that leverages these enriched contexts
to produce both accurate and interpretable clinical predictions. Extensive
experiments demonstrate that KARE outperforms leading models by up to
10.8-15.0% on MIMIC-III and 12.6-12.7% on MIMIC-IV for mortality and
readmission predictions. In addition to its impressive prediction accuracy, our
framework leverages the reasoning capabilities of LLMs, enhancing the
trustworthiness of clinical predictions.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®Ëá®Â∫äÊ±∫Á≠ñÊîØÊè¥‰∏≠Â±ïÁèæÂá∫È°ØËëóÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåLLM ‰ªçÊúâÂπªË¶∫‰∏îÁº∫‰πèÁ¥∞Á∑ªÁöÑËÉåÊôØÈÜ´ÁôÇÁü•Ë≠òÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®È´òÈ¢®Èö™ÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠ÁöÑ‰ΩøÁî®Ôºå‰æãÂ¶ÇËá®Â∫äË®∫Êñ∑„ÄÇÂÇ≥Áµ±ÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÊñπÊ≥ïË©¶ÂúñËß£Ê±∫ÈÄô‰∫õÈôêÂà∂Ôºå‰ΩÜÁ∂ìÂ∏∏Ê™¢Á¥¢Á®ÄÁñèÊàñÁÑ°ÈóúÁöÑË≥áË®äÔºåÊêçÂÆ≥È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü KAREÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÊï¥Âêà‰∫ÜÁü•Ë≠òÂúñË≠ú (KG) Á§æÁæ§Â±§Á¥öÊ™¢Á¥¢Ëàá LLM Êé®ÁêÜÔºå‰ª•Â¢ûÂº∑ÈÜ´ÁôÇ‰øùÂÅ•È†êÊ∏¨„ÄÇKARE ÈÄèÈÅéÊï¥ÂêàÁîüÁâ©ÈÜ´Â≠∏Ë≥áÊñôÂ∫´„ÄÅËá®Â∫äÊñáÁçªÂíå LLM ÁîüÊàêÁöÑË¶ãËß£ÔºåÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂ§ö‰æÜÊ∫ê KGÔºå‰∏¶‰ΩøÁî®ÈöéÂ±§ÂºèÂúñÂΩ¢Á§æÁæ§ÂÅµÊ∏¨ÂíåÊëòË¶ÅÈÄ≤Ë°åÁµÑÁπîÔºå‰ª•ÈÄ≤Ë°åÁ≤æÁ¢∫‰∏îËàáËÉåÊôØÁõ∏ÈóúÁöÑË≥áË®äÊ™¢Á¥¢„ÄÇÊàëÂÄëÁöÑÈóúÈçµÂâµÊñ∞ÂåÖÊã¨Ôºö(1) ‰∏ÄÁ®ÆÂØÜÈõÜÁöÑÈÜ´ÁôÇÁü•Ë≠òÁµêÊßãÂåñÊñπÊ≥ïÔºåËÉΩÂ§†Ê∫ñÁ¢∫Ê™¢Á¥¢Áõ∏ÈóúË≥áË®äÔºõ(2) ‰∏ÄÁ®ÆÂãïÊÖãÁü•Ë≠òÊ™¢Á¥¢Ê©üÂà∂ÔºåÂÆÉ‰ΩøÁî®ÊúâÁÑ¶Èªû„ÄÅÂ§öÈù¢ÂêëÁöÑÈÜ´ÁôÇË¶ãËß£‰æÜË±êÂØåÊÇ£ËÄÖËÉåÊôØÔºõ‰ª•Âèä (3) ‰∏ÄÂÄãÊé®ÁêÜÂ¢ûÂº∑È†êÊ∏¨Êû∂ÊßãÔºåÂÆÉÂà©Áî®ÈÄô‰∫õË±êÂØåÁöÑËÉåÊôØ‰æÜÁî¢ÁîüÊ∫ñÁ¢∫‰∏îÂèØËß£ÈáãÁöÑËá®Â∫äÈ†êÊ∏¨„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåKARE Âú® MIMIC-III ‰∏äÁöÑÊ≠ª‰∫°ÁéáÂíåÂÜçÂÖ•Èô¢È†êÊ∏¨‰∏≠ÊØîÈ†òÂÖàÊ®°ÂûãÈ´òÂá∫ 10.8-15.0%ÔºåÂú® MIMIC-IV ‰∏äÈ´òÂá∫ 12.6-12.7%„ÄÇÈô§‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶Â§ñÔºåÊàëÂÄëÁöÑÊû∂ÊßãÈÇÑÂà©Áî®‰∫Ü LLM ÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂ¢ûÂº∑‰∫ÜËá®Â∫äÈ†êÊ∏¨ÁöÑÂèØ‰ø°Â∫¶„ÄÇ

##### **Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Support**
2410.10853v1 by Abdul Muqtadir, Hafiz Syed Muhammad Bilal, Ayesha Yousaf, Hafiz Farooq Ahmed, Jamil Hussain

This research work delves into the manifestation of hallucination within
Large Language Models (LLMs) and its consequential impacts on applications
within the domain of mental health. The primary objective is to discern
effective strategies for curtailing hallucinatory occurrences, thereby
bolstering the dependability and security of LLMs in facilitating mental health
interventions such as therapy, counseling, and the dissemination of pertinent
information. Through rigorous investigation and analysis, this study seeks to
elucidate the underlying mechanisms precipitating hallucinations in LLMs and
subsequently propose targeted interventions to alleviate their occurrence. By
addressing this critical issue, the research endeavors to foster a more robust
framework for the utilization of LLMs within mental health contexts, ensuring
their efficacy and reliability in aiding therapeutic processes and delivering
accurate information to individuals seeking mental health support.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÂπªË¶∫ÁöÑË°®ÁèæÔºåÂèäÂÖ∂Â∞çÂøÉÁêÜÂÅ•Â∫∑È†òÂüüÊáâÁî®Áî¢ÁîüÁöÑÂæåÁ∫åÂΩ±Èüø„ÄÇ‰∏ªË¶ÅÁõÆÊ®ôÊòØËæ®Âà•ÈÅèÂà∂ÂπªË¶∫ÁôºÁîüÁöÑÊúâÊïàÁ≠ñÁï•ÔºåÂæûËÄåÂä†Âº∑ LLM Âú®‰øÉÈÄ≤ÂøÉÁêÜÂÅ•Â∫∑Âπ≤È†êÊé™ÊñΩÔºà‰æãÂ¶ÇÊ≤ªÁôÇ„ÄÅË´ÆË©¢ÂíåÂÇ≥Êí≠Áõ∏ÈóúË≥áË®äÔºâÊñπÈù¢ÁöÑÂèØÈù†ÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇÈÄèÈÅéÂö¥Ë¨πÁöÑË™øÊü•ÂíåÂàÜÊûêÔºåÊú¨Á†îÁ©∂Ë©¶ÂúñÈó°ÊòéÂ∞éËá¥ LLM Áî¢ÁîüÂπªË¶∫ÁöÑÊΩõÂú®Ê©üÂà∂Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫ÊúâÈáùÂ∞çÊÄßÁöÑÂπ≤È†êÊé™ÊñΩ‰æÜÊ∏õËºïÂÖ∂ÁôºÁîü„ÄÇÈÄèÈÅéËß£Ê±∫ÈÄôÂÄãÈóúÈçµÂïèÈ°åÔºåÊú¨Á†îÁ©∂Ëá¥ÂäõÊñºÂª∫Á´ã‰∏ÄÂÄãÊõ¥Á©©ÂÅ•ÁöÑÊû∂ÊßãÔºå‰ª•‰æøÂú®ÂøÉÁêÜÂÅ•Â∫∑ÊÉÖÂ¢É‰∏≠‰ΩøÁî® LLMÔºåÁ¢∫‰øùÂÖ∂Âú®ÂçîÂä©Ê≤ªÁôÇÈÅéÁ®ãÂíåÂêëÂ∞ãÊ±ÇÂøÉÁêÜÂÅ•Â∫∑ÊîØÊåÅÁöÑÂÄã‰∫∫Êèê‰æõÊ∫ñÁ¢∫Ë≥áË®äÊñπÈù¢ÁöÑÊïàËÉΩÂíåÂèØÈù†ÊÄß„ÄÇ

##### **Leveraging Social Determinants of Health in Alzheimer's Research Using LLM-Augmented Literature Mining and Knowledge Graphs**
2410.09080v1 by Tianqi Shang, Shu Yang, Weiqing He, Tianhua Zhai, Dawei Li, Bojian Hou, Tianlong Chen, Jason H. Moore, Marylyn D. Ritchie, Li Shen

Growing evidence suggests that social determinants of health (SDoH), a set of
nonmedical factors, affect individuals' risks of developing Alzheimer's disease
(AD) and related dementias. Nevertheless, the etiological mechanisms underlying
such relationships remain largely unclear, mainly due to difficulties in
collecting relevant information. This study presents a novel, automated
framework that leverages recent advancements of large language model (LLM) and
natural language processing techniques to mine SDoH knowledge from extensive
literature and integrate it with AD-related biological entities extracted from
the general-purpose knowledge graph PrimeKG. Utilizing graph neural networks,
we performed link prediction tasks to evaluate the resultant SDoH-augmented
knowledge graph. Our framework shows promise for enhancing knowledge discovery
in AD and can be generalized to other SDoH-related research areas, offering a
new tool for exploring the impact of social determinants on health outcomes.
Our code is available at: https://github.com/hwq0726/SDoHenPKG

ÊëòË¶ÅÔºöË∂ä‰æÜË∂äÂ§öÁöÑË≠âÊìöË°®ÊòéÔºåÁ§æÊúÉÂÅ•Â∫∑Ê±∫ÂÆöÂõ†Á¥† (SDoH) ÊòØ‰∏ÄÁµÑÈùûÈÜ´ÁôÇÂõ†Á¥†ÔºåÊúÉÂΩ±ÈüøÂÄã‰∫∫ÁΩπÊÇ£ÈòøËå≤Êµ∑ÈªòÁóá (AD) ÂíåÁõ∏ÈóúÂ§±Êô∫ÁóáÁöÑÈ¢®Èö™„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÈóú‰øÇËÉåÂæåÁöÑÂü∫Êú¨Ê©üÂà∂Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªç‰∏çÊ∏ÖÊ•öÔºå‰∏ªË¶ÅÊòØÂõ†ÁÇ∫Èõ£‰ª•Êî∂ÈõÜÁõ∏ÈóúË≥áË®ä„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑËá™ÂãïÂåñÊû∂ÊßãÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊäÄË°ìÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂæûÂª£Ê≥õÁöÑÊñáÁçª‰∏≠ÊåñÊéò SDoH Áü•Ë≠òÔºå‰∏¶Â∞áÂÖ∂ËàáÂæûÈÄöÁî®Áü•Ë≠òÂúñ PrimeKG ‰∏≠ÊèêÂèñÁöÑ AD Áõ∏ÈóúÁîüÁâ©ÂØ¶È´îÊï¥ÂêàÂú®‰∏ÄËµ∑„ÄÇÂà©Áî®ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÊàëÂÄëÂü∑Ë°åÈÄ£ÁµêÈ†êÊ∏¨‰ªªÂãôÔºå‰ª•Ë©ï‰º∞ÁîüÊàêÁöÑ SDoH Êì¥ÂÖÖÁü•Ë≠òÂúñ„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÈ°ØÁ§∫Âá∫Â¢ûÂº∑ AD ‰∏≠Áü•Ë≠òÁôºÁèæÁöÑÂ∏åÊúõÔºå‰∏¶‰∏îÂèØ‰ª•Êé®Âª£Âà∞ÂÖ∂‰ªñËàá SDoH Áõ∏ÈóúÁöÑÁ†îÁ©∂È†òÂüüÔºåÊèê‰æõ‰∏ÄÂÄãÊé¢Á¥¢Á§æÊúÉÊ±∫ÂÆöÂõ†Á¥†Â∞çÂÅ•Â∫∑ÁµêÊûúÂΩ±ÈüøÁöÑÊñ∞Â∑•ÂÖ∑„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/hwq0726/SDoHenPKG ÂèñÂæó

##### **Empowering Domain-Specific Language Models with Graph-Oriented Databases: A Paradigm Shift in Performance and Model Maintenance**
2410.03867v1 by Ricardo Di Pasquale, Soledad Represa

In an era dominated by data, the management and utilization of
domain-specific language have emerged as critical challenges in various
application domains, particularly those with industry-specific requirements.
Our work is driven by the need to effectively manage and process large volumes
of short text documents inherent in specific application domains. By leveraging
domain-specific knowledge and expertise, our approach aims to shape factual
data within these domains, thereby facilitating enhanced utilization and
understanding by end-users. Central to our methodology is the integration of
domain-specific language models with graph-oriented databases, facilitating
seamless processing, analysis, and utilization of textual data within targeted
domains. Our work underscores the transformative potential of the partnership
of domain-specific language models and graph-oriented databases. This
cooperation aims to assist researchers and engineers in metric usage,
mitigation of latency issues, boosting explainability, enhancing debug and
improving overall model performance. Moving forward, we envision our work as a
guide AI engineers, providing valuable insights for the implementation of
domain-specific language models in conjunction with graph-oriented databases,
and additionally provide valuable experience in full-life cycle maintenance of
this kind of products.

ÊëòË¶ÅÔºöÂú®Ë≥áÊñôÁï∂ÈÅìÁöÑÊôÇ‰ª£ÔºåÁâπÂÆöÈ†òÂüüË™ûË®ÄÁöÑÁÆ°ÁêÜÂíåÊáâÁî®Â∑≤ÊàêÁÇ∫ÂêÑÊáâÁî®È†òÂüü‰∏≠ÁöÑÈóúÈçµÊåëÊà∞ÔºåÂ∞§ÂÖ∂ÊòØÈÇ£‰∫õÂÖ∑ÊúâÁî¢Ê•≠ÁâπÂÆöÈúÄÊ±ÇÁöÑÈ†òÂüü„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂãïÊ©üÊòØÊúâÊïàÁÆ°ÁêÜÂíåËôïÁêÜÁâπÂÆöÊáâÁî®È†òÂüü‰∏≠Âõ∫ÊúâÁöÑÊµ∑ÈáèÁ∞°Áü≠ÊñáÊú¨Êñá‰ª∂„ÄÇÈÄèÈÅéÈÅãÁî®ÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠òÂíåÂ∞àÊ•≠Áü•Ë≠òÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊó®Âú®ÂΩ¢Â°ëÈÄô‰∫õÈ†òÂüü‰∏≠ÁöÑ‰∫ãÂØ¶Ë≥áÊñôÔºåÈÄ≤ËÄå‰øÉÈÄ≤ÊúÄÁµÇ‰ΩøÁî®ËÄÖÂ¢ûÂº∑Âà©Áî®ÂíåÁêÜËß£„ÄÇÊàëÂÄëÊñπÊ≥ïÁöÑÊ†∏ÂøÉÊòØÂ∞áÁâπÂÆöÈ†òÂüüÁöÑË™ûË®ÄÊ®°ÂûãËàáÂúñÂΩ¢Â∞éÂêëË≥áÊñôÂ∫´Êï¥ÂêàÔºå‰øÉÈÄ≤ÁõÆÊ®ôÈ†òÂüü‰∏≠ÊñáÂ≠óË≥áÊñôÁöÑÁÑ°Á∏´ËôïÁêÜ„ÄÅÂàÜÊûêÂíåÂà©Áî®„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÁâπÂÆöÈ†òÂüüË™ûË®ÄÊ®°ÂûãËàáÂúñÂΩ¢Â∞éÂêëË≥áÊñôÂ∫´Âêà‰ΩúÁöÑËΩâÂûãÊΩõÂäõ„ÄÇÈÄôÁ®ÆÂêà‰ΩúÊó®Âú®ÂçîÂä©Á†îÁ©∂‰∫∫Âì°ÂíåÂ∑•Á®ãÂ∏´ÈÄ≤Ë°åÊåáÊ®ô‰ΩøÁî®„ÄÅÊ∏õËºïÂª∂ÈÅ≤ÂïèÈ°å„ÄÅÊèêÂçáÂèØËß£ÈáãÊÄß„ÄÅÂ¢ûÂº∑Èô§ÈåØÔºå‰∏¶ÊîπÂñÑÊï¥È´îÊ®°ÂûãÊïàËÉΩ„ÄÇÂ±ïÊúõÊú™‰æÜÔºåÊàëÂÄëÈ†êÊúüÊàëÂÄëÁöÑÁ†îÁ©∂Â∞áÊàêÁÇ∫‰∫∫Â∑•Êô∫ÊÖßÂ∑•Á®ãÂ∏´ÁöÑÊåáÂçóÔºåÊèê‰æõÊúâÂÉπÂÄºÁöÑË¶ãËß£Ôºå‰æõ‰ªñÂÄëÂ∞áÁâπÂÆöÈ†òÂüüË™ûË®ÄÊ®°ÂûãËàáÂúñÂΩ¢Â∞éÂêëË≥áÊñôÂ∫´ÁµêÂêàÂØ¶‰ΩúÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Êèê‰æõÊ≠§È°ûÁî¢ÂìÅÂÖ®ÁîüÂëΩÈÄ±ÊúüÁ∂≠Ë≠∑ÁöÑÂØ∂Ë≤¥Á∂ìÈ©ó„ÄÇ

##### **GraphRouter: A Graph-based Router for LLM Selections**
2410.03834v1 by Tao Feng, Yanzhen Shen, Jiaxuan You

The rapidly growing number and variety of Large Language Models (LLMs)
present significant challenges in efficiently selecting the appropriate LLM for
a given query, especially considering the trade-offs between performance and
computational cost. Current LLM selection methods often struggle to generalize
across new LLMs and different tasks because of their limited ability to
leverage contextual interactions among tasks, queries, and LLMs, as well as
their dependence on a transductive learning framework. To address these
shortcomings, we introduce a novel inductive graph framework, named as
GraphRouter, which fully utilizes the contextual information among tasks,
queries, and LLMs to enhance the LLM selection process. GraphRouter constructs
a heterogeneous graph comprising task, query, and LLM nodes, with interactions
represented as edges, which efficiently captures the contextual information
between the query's requirements and the LLM's capabilities. Through an
innovative edge prediction mechanism, GraphRouter is able to predict attributes
(the effect and cost of LLM response) of potential edges, allowing for
optimized recommendations that adapt to both existing and newly introduced LLMs
without requiring retraining. Comprehensive experiments across three distinct
effect-cost weight scenarios have shown that GraphRouter substantially
surpasses existing routers, delivering a minimum performance improvement of
12.3%. In addition, it achieves enhanced generalization across new LLMs
settings and supports diverse tasks with at least a 9.5% boost in effect and a
significant reduction in computational demands. This work endeavors to apply a
graph-based approach for the contextual and adaptive selection of LLMs,
offering insights for real-world applications. Our codes for GraphRouter will
soon be released at https://github.com/ulab-uiuc/GraphRouter.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊï∏ÈáèÂíåÁ®ÆÈ°ûÂø´ÈÄüÂ¢ûÈï∑ÔºåÂú®ÊúâÊïàÂú∞ÈáùÂ∞çÁâπÂÆöÊü•Ë©¢ÈÅ∏ÊìáÈÅ©Áï∂ÁöÑ LLM ÊôÇÊúÉÂ∏∂‰æÜÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØËÄÉÊÖÆÂà∞ÊïàËÉΩÂíåÈÅãÁÆóÊàêÊú¨‰πãÈñìÁöÑÊ¨äË°°„ÄÇÁõÆÂâçÁöÑ LLM ÈÅ∏ÊìáÊñπÊ≥ïÈÄöÂ∏∏Èõ£‰ª•Ê¶ÇÊã¨Âà∞Êñ∞ÁöÑ LLM Âíå‰∏çÂêåÁöÑ‰ªªÂãôÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂú®Âà©Áî®‰ªªÂãô„ÄÅÊü•Ë©¢Âíå LLM ‰πãÈñìÁöÑËÑàÁµ°‰∫íÂãïÊñπÈù¢ÁöÑËÉΩÂäõÊúâÈôêÔºåËÄå‰∏î‰æùË≥¥ÊñºËΩâÂ∞éÂ≠∏ÁøíÊû∂Êßã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÁº∫ÈªûÔºåÊàëÂÄëÂºïÈÄ≤‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ GraphRouter ÁöÑÊñ∞Ê≠∏Á¥çÂúñÂΩ¢Êû∂ÊßãÔºåÂÆÉÂÖÖÂàÜÂà©Áî®‰ªªÂãô„ÄÅÊü•Ë©¢Âíå LLM ‰πãÈñìÁöÑËÑàÁµ°Ë≥áË®ä‰æÜÂ¢ûÂº∑ LLM ÈÅ∏ÊìáÊµÅÁ®ã„ÄÇGraphRouter ÊßãÂª∫‰∫Ü‰∏ÄÂÄãÁï∞Ë≥™ÂúñÂΩ¢ÔºåÂåÖÂê´‰ªªÂãô„ÄÅÊü•Ë©¢Âíå LLM ÁØÄÈªûÔºå‰∏¶Â∞á‰∫íÂãïË°®Á§∫ÁÇ∫ÈÇäÁ∑£ÔºåÊúâÊïàÂú∞Êì∑ÂèñÊü•Ë©¢ÈúÄÊ±ÇÂíå LLM ËÉΩÂäõ‰πãÈñìÁöÑËÑàÁµ°Ë≥áË®ä„ÄÇÈÄèÈÅéÂâµÊñ∞ÁöÑÈÇäÁ∑£È†êÊ∏¨Ê©üÂà∂ÔºåGraphRouter ËÉΩÂ§†È†êÊ∏¨ÊΩõÂú®ÈÇäÁ∑£ÁöÑÂ±¨ÊÄßÔºàLLM ÂõûÊáâÁöÑÊïàÊûúÂíåÊàêÊú¨ÔºâÔºåÂÖÅË®±ÊúÄ‰Ω≥ÂåñÂª∫Ë≠∞Ôºå‰ª•ÈÅ©ÊáâÁèæÊúâÂíåÊñ∞Êé®Âá∫ÁöÑ LLMÔºåËÄåÁÑ°ÈúÄÈáçÊñ∞Ë®ìÁ∑¥„ÄÇÂú®‰∏âÂÄã‰∏çÂêåÁöÑÊïàÊûúÊàêÊú¨Ê¨äÈáçÊÉÖÂ¢É‰∏≠ÈÄ≤Ë°åÁöÑÂÖ®Èù¢ÂØ¶È©óÈ°ØÁ§∫ÔºåGraphRouter ÊòéÈ°ØË∂ÖË∂äÁèæÊúâÁöÑË∑ØÁî±Âô®ÔºåÊïàËÉΩËá≥Â∞ëÊèêÂçá 12.3%„ÄÇÊ≠§Â§ñÔºåÂÆÉÂú®Êñ∞ÁöÑ LLM Ë®≠ÂÆö‰∏≠ÂØ¶Áèæ‰∫ÜÂ¢ûÂº∑ÁöÑÊ¶ÇÊã¨ÊÄßÔºå‰∏¶ÊîØÊè¥Â§öÊ®£ÂåñÁöÑ‰ªªÂãôÔºåÊïàÊûúËá≥Â∞ëÊèêÂçá 9.5%Ôºå‰∏¶Â§ßÂπÖÈôç‰ΩéÈÅãÁÆóÈúÄÊ±Ç„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúËá¥ÂäõÊñºÊáâÁî®Âü∫ÊñºÂúñÂΩ¢ÁöÑÊñπÊ≥ïÔºå‰ª•ÈÄ≤Ë°å LLM ÁöÑËÑàÁµ°ÂíåÈÅ©ÊáâÊÄßÈÅ∏ÊìáÔºåÁÇ∫ÁúüÂØ¶‰∏ñÁïåÁöÑÊáâÁî®Êèê‰æõË¶ãËß£„ÄÇÊàëÂÄëÁöÑ GraphRouter Á®ãÂºèÁ¢ºÂ∞áÂæàÂø´Âú® https://github.com/ulab-uiuc/GraphRouter ÁôºÂ∏É„ÄÇ</paragraph>

##### **Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing**
2410.03357v1 by Jeongwoo Kang, Maximin Coavoux, C√©dric Lopez, Didier Schwab

Cross-lingual AMR parsing is the task of predicting AMR graphs in a target
language when training data is available only in a source language. Due to the
small size of AMR training data and evaluation data, cross-lingual AMR parsing
has only been explored in a small set of languages such as English, Spanish,
German, Chinese, and Italian. Taking inspiration from Langedijk et al. (2022),
who apply meta-learning to tackle cross-lingual syntactic parsing, we
investigate the use of meta-learning for cross-lingual AMR parsing. We evaluate
our models in $k$-shot scenarios (including 0-shot) and assess their
effectiveness in Croatian, Farsi, Korean, Chinese, and French. Notably, Korean
and Croatian test sets are developed as part of our work, based on the existing
The Little Prince English AMR corpus, and made publicly available. We
empirically study our method by comparing it to classical joint learning. Our
findings suggest that while the meta-learning model performs slightly better in
0-shot evaluation for certain languages, the performance gain is minimal or
absent when $k$ is higher than 0.

ÊëòË¶ÅÔºöË∑®Ë™ûË®Ä AMR Ëß£ÊûêÊòØ‰∏ÄÈ†Ö‰ªªÂãôÔºåÂú®ÂÉÖÂú®Ê∫êË™ûË®Ä‰∏≠Êèê‰æõË®ìÁ∑¥Ë≥áÊñôÊôÇÔºåÈ†êÊ∏¨ÁõÆÊ®ôË™ûË®Ä‰∏≠ÁöÑ AMR ÂúñÂΩ¢„ÄÇÁî±Êñº AMR Ë®ìÁ∑¥Ë≥áÊñôÂíåË©ï‰º∞Ë≥áÊñôÁöÑË¶èÊ®°ÂæàÂ∞èÔºåÂõ†Ê≠§Ë∑®Ë™ûË®Ä AMR Ëß£ÊûêÂÉÖÂú®Â∞ëÊï∏Ë™ûË®Ä‰∏≠ÈÄ≤Ë°åÈÅéÊé¢Á¥¢Ôºå‰æãÂ¶ÇËã±Ë™û„ÄÅË•øÁè≠ÁâôË™û„ÄÅÂæ∑Ë™û„ÄÅ‰∏≠ÊñáÂíåÁæ©Â§ßÂà©Ë™û„ÄÇÂèóÂà∞ Langedijk Á≠â‰∫∫ (2022) ÁöÑÂïüÁôºÔºå‰ªñÂÄëÊáâÁî®ÂÖÉÂ≠∏Áøí‰æÜËôïÁêÜË∑®Ë™ûË®ÄÂè•Ê≥ïËß£ÊûêÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü‰ΩøÁî®ÂÖÉÂ≠∏ÁøíÈÄ≤Ë°åË∑®Ë™ûË®Ä AMR Ëß£Êûê„ÄÇÊàëÂÄëÂú® $k$-shot Â†¥ÊôØÔºàÂåÖÊã¨ 0-shotÔºâ‰∏≠Ë©ï‰º∞ÊàëÂÄëÁöÑÊ®°ÂûãÔºå‰∏¶Ë©ï‰º∞ÂÆÉÂÄëÂú®ÂÖãÁæÖÂüÉË•ø‰∫ûË™û„ÄÅÊ≥¢ÊñØË™û„ÄÅÈüìË™û„ÄÅ‰∏≠ÊñáÂíåÊ≥ïË™û‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÈüìË™ûÂíåÂÖãÁæÖÂüÉË•ø‰∫ûË™ûÊ∏¨Ë©¶ÈõÜÊòØÊ†πÊìöÁèæÊúâÁöÑ„ÄäÂ∞èÁéãÂ≠ê„ÄãËã±Ë™û AMR Ë™ûÊñôÂ∫´ÈñãÁôºÁöÑÔºå‰∏¶ÂÖ¨ÈñãÊèê‰æõ„ÄÇÊàëÂÄëÈÄöÈÅéÂ∞áÊàëÂÄëÁöÑÊ®°ÂûãËàáÂÇ≥Áµ±ËÅØÂêàÂ≠∏ÁøíÈÄ≤Ë°åÊØîËºÉÔºåÂ∞çÊàëÂÄëÁöÑÊ®°ÂûãÈÄ≤Ë°åÂØ¶Ë≠âÁ†îÁ©∂„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈõñÁÑ∂ÂÖÉÂ≠∏ÁøíÊ®°ÂûãÂú®Êüê‰∫õË™ûË®ÄÁöÑ 0-shot Ë©ï‰º∞‰∏≠Ë°®ÁèæÁï•Â•ΩÔºå‰ΩÜÊòØÁï∂ $k$ È´òÊñº 0 ÊôÇÔºåÊïàËÉΩÊèêÂçáÂæàÂ∞èÊàñÊ≤íÊúâ„ÄÇ

##### **Enriching Ontologies with Disjointness Axioms using Large Language Models**
2410.03235v1 by Elias Crum, Antonio De Santis, Manon Ovide, Jiaxin Pan, Alessia Pisu, Nicolas Lazzari, Sebastian Rudolph

Ontologies often lack explicit disjointness declarations between classes,
despite their usefulness for sophisticated reasoning and consistency checking
in Knowledge Graphs. In this study, we explore the potential of Large Language
Models (LLMs) to enrich ontologies by identifying and asserting class
disjointness axioms. Our approach aims at leveraging the implicit knowledge
embedded in LLMs, using prompt engineering to elicit this knowledge for
classifying ontological disjointness. We validate our methodology on the
DBpedia ontology, focusing on open-source LLMs. Our findings suggest that LLMs,
when guided by effective prompt strategies, can reliably identify disjoint
class relationships, thus streamlining the process of ontology completion
without extensive manual input. For comprehensive disjointness enrichment, we
propose a process that takes logical relationships between disjointness and
subclass statements into account in order to maintain satisfiability and reduce
the number of calls to the LLM. This work provides a foundation for future
applications of LLMs in automated ontology enhancement and offers insights into
optimizing LLM performance through strategic prompt design. Our code is
publicly available on GitHub at https://github.com/n28div/llm-disjointness.

ÊëòË¶ÅÔºöÊú¨‰ΩìË´ñÈÄöÂ∏∏Áº∫‰πèÈ°ûÂà•‰πãÈñìÊòéÁ¢∫ÁöÑ‰∏çÁõ∏‰∫§ËÅ≤ÊòéÔºåÂÑòÁÆ°ÂÆÉÂÄëÂ∞çÊñºÁü•Ë≠òÂúñË≠ú‰∏≠ÁöÑÁ≤æÂØÜÊé®ÁêÜÂíå‰∏ÄËá¥ÊÄßÊ™¢Êü•ÂæàÊúâÁî®„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊΩõÂäõÔºåÈÄöÈÅéË≠òÂà•ÂíåÊñ∑Ë®ÄÈ°ûÂà•‰∏çÁõ∏‰∫§ÂÖ¨ÁêÜ‰æÜË±êÂØåÊú¨‰ΩìË´ñ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊó®Âú®Âà©Áî®ÂµåÂÖ•Âú® LLM ‰∏≠ÁöÑÈö±ÂºèÁü•Ë≠òÔºåÂà©Áî®ÊèêÁ§∫Â∑•Á®ã‰æÜÂºïÂá∫ÈÄôÁ®ÆÁü•Ë≠ò‰ª•ÂàÜÈ°ûÊú¨‰ΩìË´ñ‰∏çÁõ∏‰∫§„ÄÇÊàëÂÄëÂú® DBpedia Êú¨‰ΩìË´ñ‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºåÈáçÈªûÈóúÊ≥®ÈñãÊ∫ê LLM„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåLLM Âú®ÊúâÊïàÊèêÁ§∫Á≠ñÁï•ÁöÑÊåáÂ∞é‰∏ãÔºåÂèØ‰ª•ÂèØÈù†Âú∞Ë≠òÂà•‰∏çÁõ∏‰∫§È°ûÂà•Èóú‰øÇÔºåÂæûËÄåÁ∞°ÂåñÊú¨‰ΩìË´ñÂÆåÊàêÈÅéÁ®ãÔºåËÄåÁÑ°ÈúÄÂ§ßÈáèÊâãÂãïËº∏ÂÖ•„ÄÇÂ∞çÊñºÂÖ®Èù¢ÁöÑ‰∏çÁõ∏‰∫§Ë±êÂØåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈÅéÁ®ãÔºåË©≤ÈÅéÁ®ãËÄÉÊÖÆ‰∫Ü‰∏çÁõ∏‰∫§ÂíåÂ≠êÈ°ûÂà•Èô≥Ëø∞‰πãÈñìÁöÑÈÇèËºØÈóú‰øÇÔºå‰ª•Á∂≠ÊåÅÂèØÊªøË∂≥ÊÄß‰∏¶Ê∏õÂ∞ëÂ∞ç LLM ÁöÑË™øÁî®Ê¨°Êï∏„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ LLM Âú®Ëá™ÂãïÊú¨‰ΩìË´ñÂ¢ûÂº∑‰∏≠ÁöÑÊú™‰æÜÊáâÁî®Â•†ÂÆö‰∫ÜÂü∫Á§éÔºå‰∏¶Êèê‰æõ‰∫ÜÈÄöÈÅéÁ≠ñÁï•ÊèêÁ§∫Ë®≠Ë®àÂÑ™Âåñ LLM ÊÄßËÉΩÁöÑË¶ãËß£„ÄÇÊàëÂÄëÁöÑ‰ª£Á¢ºÂú® GitHub ‰∏äÂÖ¨ÈñãÔºåÁ∂≤ÂùÄÁÇ∫ https://github.com/n28div/llm-disjointness„ÄÇ

##### **How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension**
2410.05298v1 by Xinnan Dai, Haohao Qu, Yifen Shen, Bohang Zhang, Qihao Wen, Wenqi Fan, Dongsheng Li, Jiliang Tang, Caihua Shan

Benchmarking the capabilities and limitations of large language models (LLMs)
in graph-related tasks is becoming an increasingly popular and crucial area of
research. Recent studies have shown that LLMs exhibit a preliminary ability to
understand graph structures and node features. However, the potential of LLMs
in graph pattern mining remains largely unexplored. This is a key component in
fields such as computational chemistry, biology, and social network analysis.
To bridge this gap, this work introduces a comprehensive benchmark to assess
LLMs' capabilities in graph pattern tasks. We have developed a benchmark that
evaluates whether LLMs can understand graph patterns based on either
terminological or topological descriptions. Additionally, our benchmark tests
the LLMs' capacity to autonomously discover graph patterns from data. The
benchmark encompasses both synthetic and real datasets, and a variety of
models, with a total of 11 tasks and 7 models. Our experimental framework is
designed for easy expansion to accommodate new models and datasets. Our
findings reveal that: (1) LLMs have preliminary abilities to understand graph
patterns, with O1-mini outperforming in the majority of tasks; (2) Formatting
input data to align with the knowledge acquired during pretraining can enhance
performance; (3) The strategies employed by LLMs may differ from those used in
conventional algorithms.

ÊëòË¶ÅÔºöË©ïÈáèÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂúñÂΩ¢Áõ∏Èóú‰ªªÂãô‰∏≠ÁöÑËÉΩÂäõÂíåÈôêÂà∂ÔºåÊ≠£ÊàêÁÇ∫‰∏ÄÂÄãË∂ä‰æÜË∂äÂèóÊ≠°Ëøé‰∏îËá≥ÈóúÈáçË¶ÅÁöÑÁ†îÁ©∂È†òÂüü„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåLLM Â±ïÁèæÂá∫ÂàùÊ≠•ÁêÜËß£ÂúñÂΩ¢ÁµêÊßãÂíåÁØÄÈªûÁâπÂæµÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåLLM Âú®ÂúñÂΩ¢Ê®°ÂºèÊåñÊéò‰∏≠ÁöÑÊΩõÂäõ‰ªçÊú™Ë¢´Âª£Ê≥õÊé¢Á¥¢„ÄÇÈÄôÊòØË®àÁÆóÂåñÂ≠∏„ÄÅÁîüÁâ©Â≠∏ÂíåÁ§æ‰∫§Á∂≤Ë∑ØÂàÜÊûêÁ≠âÈ†òÂüüÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄôÂÄãÂ∑ÆË∑ùÔºåÈÄôÈ†ÖÂ∑•‰ΩúÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂü∫Ê∫ñ‰æÜË©ï‰º∞ LLM Âú®ÂúñÂΩ¢Ê®°Âºè‰ªªÂãô‰∏≠ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂü∫Ê∫ñÔºåÁî®‰æÜË©ï‰º∞ LLM ËÉΩÂê¶Ê†πÊìöË°ìË™ûÊàñÊãìÊí≤ÊèèËø∞‰æÜÁêÜËß£ÂúñÂΩ¢Ê®°Âºè„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶ LLM ÂæûË≥áÊñô‰∏≠Ëá™‰∏ªÁôºÁèæÂúñÂΩ¢Ê®°ÂºèÁöÑËÉΩÂäõ„ÄÇË©≤Âü∫Ê∫ñÊ∂µËìã‰∫ÜÂêàÊàêÂíåÁúüÂØ¶Ë≥áÊñôÈõÜÔºå‰ª•ÂèäÂêÑÁ®ÆÊ®°ÂûãÔºåÁ∏ΩÂÖ±Êúâ 11 È†Ö‰ªªÂãôÂíå 7 ÂÄãÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊû∂ÊßãË®≠Ë®àÁÇ∫ÊòìÊñºÊì¥ÂÖÖÔºå‰ª•ÂÆπÁ¥çÊñ∞ÁöÑÊ®°ÂûãÂíåË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫Ôºö(1) LLM ÂÖ∑ÊúâÂàùÊ≠•ÁêÜËß£ÂúñÂΩ¢Ê®°ÂºèÁöÑËÉΩÂäõÔºåÂÖ∂‰∏≠ O1-mini Âú®Â§ßÂ§öÊï∏‰ªªÂãô‰∏≠Ë°®ÁèæÂÑ™Áï∞Ôºõ(2) Â∞áËº∏ÂÖ•Ë≥áÊñôÊ†ºÂºèÂåñÁÇ∫ËàáÈ†êË®ìÁ∑¥ÊúüÈñìÁøíÂæóÁöÑÁü•Ë≠ò‰∏ÄËá¥ÔºåÂèØ‰ª•Â¢ûÂº∑ÊïàËÉΩÔºõ(3) LLM ‰ΩøÁî®ÁöÑÁ≠ñÁï•ÂèØËÉΩËàáÂÇ≥Áµ±ÊºîÁÆóÊ≥ï‰∏≠‰ΩøÁî®ÁöÑÁ≠ñÁï•‰∏çÂêå„ÄÇ

##### **LLMCO2: Advancing Accurate Carbon Footprint Prediction for LLM Inferences**
2410.02950v1 by Zhenxiao Fu, Fan Chen, Shan Zhou, Haitong Li, Lei Jiang

Throughout its lifecycle, a large language model (LLM) generates a
substantially larger carbon footprint during inference than training. LLM
inference requests vary in batch size, prompt length, and token generation
number, while cloud providers employ different GPU types and quantities to meet
diverse service-level objectives for accuracy and latency. It is crucial for
both users and cloud providers to have a tool that quickly and accurately
estimates the carbon impact of LLM inferences based on a combination of
inference request and hardware configurations before execution. Estimating the
carbon footprint of LLM inferences is more complex than training due to lower
and highly variable model FLOPS utilization, rendering previous equation-based
models inaccurate. Additionally, existing machine learning (ML) prediction
methods either lack accuracy or demand extensive training data, as they
inadequately handle the distinct prefill and decode phases, overlook
hardware-specific features, and inefficiently sample uncommon inference
configurations. We introduce \coo, a graph neural network (GNN)-based model
that greatly improves the accuracy of LLM inference carbon footprint
predictions compared to previous methods.

ÊëòË¶ÅÔºöÂú®Êï¥ÂÄãÁîüÂëΩÈÄ±Êúü‰∏≠ÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Êé®ÁêÜÊúüÈñìÁî¢ÁîüÁöÑÁ¢≥Ë∂≥Ë∑°ÈÅ†Â§ßÊñºË®ìÁ∑¥ÊúüÈñì„ÄÇLLM Êé®ÁêÜË´ãÊ±ÇÂú®ÊâπÊ¨°Â§ßÂ∞è„ÄÅÊèêÁ§∫Èï∑Â∫¶ÂíåÊ¨äÊùñÁîüÊàêÊï∏ÈáèÊñπÈù¢ÊúâÊâÄ‰∏çÂêåÔºåËÄåÈõ≤Á´Ø‰æõÊáâÂïÜÊé°Áî®‰∏çÂêåÁöÑ GPU È°ûÂûãÂíåÊï∏Èáè‰æÜÊªøË∂≥Ê∫ñÁ¢∫ÊÄßÂíåÂª∂ÈÅ≤ÁöÑÂêÑÁ®ÆÊúçÂãôÂ±§Á¥öÁõÆÊ®ô„ÄÇÂ∞çÊñº‰ΩøÁî®ËÄÖÂíåÈõ≤Á´Ø‰æõÊáâÂïÜ‰æÜË™™ÔºåÂú®Âü∑Ë°åÂâçÊ†πÊìöÊé®ÁêÜË´ãÊ±ÇÂíåÁ°¨È´îÈÖçÁΩÆÁµÑÂêàÂø´ÈÄü‰∏îÊ∫ñÁ¢∫Âú∞‰º∞Ë®à LLM Êé®ÁêÜÁöÑÁ¢≥ÂΩ±ÈüøËá≥ÈóúÈáçË¶Å„ÄÇ‰º∞Ë®à LLM Êé®ÁêÜÁöÑÁ¢≥Ë∂≥Ë∑°ÊØîË®ìÁ∑¥Êõ¥Ë§áÈõúÔºåÂõ†ÁÇ∫Ê®°Âûã FLOPS Âà©Áî®ÁéáËºÉ‰Ωé‰∏îËÆäÂåñÂæàÂ§ßÔºåÂ∞éËá¥ÂÖàÂâçÁöÑÂü∫ÊñºÊñπÁ®ãÂºèÁöÑÊ®°Âûã‰∏çÊ∫ñÁ¢∫„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÁöÑÊ©üÂô®Â≠∏Áøí (ML) È†êÊ∏¨ÊñπÊ≥ïË¶Å‰πàÁº∫‰πèÊ∫ñÁ¢∫ÊÄßÔºåË¶Å‰πàÈúÄË¶ÅÂ§ßÈáèÁöÑË®ìÁ∑¥Ë≥áÊñôÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁÑ°Ê≥ïÂÖÖÂàÜËôïÁêÜ‰∏çÂêåÁöÑÈ†êÂ°´ÂÖÖÂíåËß£Á¢ºÈöéÊÆµÔºåÂøΩÁï•Á°¨È´îÁâπÂÆöÁöÑÂäüËÉΩÔºå‰∏¶‰∏î‰ΩéÊïàÁéáÂú∞ÂèñÊ®£‰∏çÂ∏∏Ë¶ãÁöÑÊé®ÁêÜÈÖçÁΩÆ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü \cooÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫ÊñºÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÊ®°ÂûãÔºåËàáÂÖàÂâçÁöÑÊ®°ÂûãÁõ∏ÊØîÔºåÂÆÉÂ§ßÂ§ßÊèêÈ´ò‰∫Ü LLM Êé®ÁêÜÁ¢≥Ë∂≥Ë∑°È†êÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇ

##### **EditRoom: LLM-parameterized Graph Diffusion for Composable 3D Room Layout Editing**
2410.12836v1 by Kaizhi Zheng, Xiaotong Chen, Xuehai He, Jing Gu, Linjie Li, Zhengyuan Yang, Kevin Lin, Jianfeng Wang, Lijuan Wang, Xin Eric Wang

Given the steep learning curve of professional 3D software and the
time-consuming process of managing large 3D assets, language-guided 3D scene
editing has significant potential in fields such as virtual reality, augmented
reality, and gaming. However, recent approaches to language-guided 3D scene
editing either require manual interventions or focus only on appearance
modifications without supporting comprehensive scene layout changes. In
response, we propose Edit-Room, a unified framework capable of executing a
variety of layout edits through natural language commands, without requiring
manual intervention. Specifically, EditRoom leverages Large Language Models
(LLMs) for command planning and generates target scenes using a diffusion-based
method, enabling six types of edits: rotate, translate, scale, replace, add,
and remove. To address the lack of data for language-guided 3D scene editing,
we have developed an automatic pipeline to augment existing 3D scene synthesis
datasets and introduced EditRoom-DB, a large-scale dataset with 83k editing
pairs, for training and evaluation. Our experiments demonstrate that our
approach consistently outperforms other baselines across all metrics,
indicating higher accuracy and coherence in language-guided scene layout
editing.

ÊëòË¶ÅÔºöÁî±ÊñºÂ∞àÊ•≠ 3D ËªüÈ´îÁöÑÂ≠∏ÁøíÊõ≤Á∑öÈô°Â≥≠Ôºå‰ª•ÂèäÁÆ°ÁêÜÂ§ßÂûã 3D Ë≥áÁî¢ÁöÑËÄóÊôÇÁ®ãÂ∫èÔºåË™ûË®ÄÂ∞éÂêëÁöÑ 3D Â†¥ÊôØÁ∑®ËºØÂú®ËôõÊì¨ÂØ¶Â¢É„ÄÅÊì¥Â¢ûÂØ¶Â¢ÉÂíåÈÅäÊà≤Á≠âÈ†òÂüüÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÂ∞çË™ûË®ÄÂ∞éÂêëÁöÑ 3D Â†¥ÊôØÁ∑®ËºØÊñπÊ≥ïÔºåË¶Å‰∏çÊòØÈúÄË¶ÅÊâãÂãïÂπ≤È†êÔºåÂ∞±ÊòØÂè™Â∞àÊ≥®ÊñºÂ§ñËßÄ‰øÆÊîπÔºåËÄå‰∏çÊîØÊè¥ÂÖ®Èù¢ÁöÑÂ†¥ÊôØ‰ΩàÂ±ÄËÆäÊõ¥„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ Edit-RoomÔºå‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊû∂ÊßãÔºåËÉΩÂ§†ÈÄèÈÅéËá™ÁÑ∂Ë™ûË®ÄÊåá‰ª§Âü∑Ë°åÂêÑÁ®Æ‰ΩàÂ±ÄÁ∑®ËºØÔºåËÄå‰∏çÈúÄË¶ÅÊâãÂãïÂπ≤È†ê„ÄÇÂÖ∑È´î‰æÜË™™ÔºåEditRoom Êé°Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÊåá‰ª§Ë¶èÂäÉÔºå‰∏¶‰ΩøÁî®Âü∫ÊñºÊì¥Êï£ÁöÑÊñπÊ≥ïÁî¢ÁîüÁõÆÊ®ôÂ†¥ÊôØÔºåÊîØÊè¥ÂÖ≠Á®ÆÈ°ûÂûãÁöÑÁ∑®ËºØÔºöÊóãËΩâ„ÄÅÂπ≥Áßª„ÄÅÁ∏ÆÊîæ„ÄÅÊõøÊèõ„ÄÅÊñ∞Â¢ûÂíåÁßªÈô§„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ë™ûË®ÄÂ∞éÂêëÁöÑ 3D Â†¥ÊôØÁ∑®ËºØÁº∫‰πèË≥áÊñôÁöÑÂïèÈ°åÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãËá™ÂãïÂåñÁÆ°ÈÅìÔºå‰ª•Êì¥ÂÖÖÁèæÊúâÁöÑ 3D Â†¥ÊôØÂêàÊàêË≥áÊñôÈõÜÔºå‰∏¶ÂºïÂÖ•‰∫Ü EditRoom-DBÔºå‰∏ÄÂÄãÂåÖÂê´ 83k Á∑®ËºØÂ∞çÁöÑÂ§ßË¶èÊ®°Ë≥áÊñôÈõÜÔºåÁî®ÊñºË®ìÁ∑¥ÂíåË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®ÊâÄÊúâÊåáÊ®ô‰∏äÈÉΩÊåÅÁ∫åÂÑ™ÊñºÂÖ∂‰ªñÂü∫Ê∫ñÔºåË°®Á§∫Âú®Ë™ûË®ÄÂ∞éÂêëÁöÑÂ†¥ÊôØ‰ΩàÂ±ÄÁ∑®ËºØ‰∏≠ÂÖ∑ÊúâÊõ¥È´òÁöÑÊ∫ñÁ¢∫ÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇ

##### **Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization**
2410.02721v1 by Ryan C. Barron, Ves Grantcharov, Selma Wanna, Maksim E. Eren, Manish Bhattarai, Nicholas Solovyev, George Tompkins, Charles Nicholas, Kim √ò. Rasmussen, Cynthia Matuszek, Boian S. Alexandrov

Large Language Models (LLMs) are pre-trained on large-scale corpora and excel
in numerous general natural language processing (NLP) tasks, such as question
answering (QA). Despite their advanced language capabilities, when it comes to
domain-specific and knowledge-intensive tasks, LLMs suffer from hallucinations,
knowledge cut-offs, and lack of knowledge attributions. Additionally, fine
tuning LLMs' intrinsic knowledge to highly specific domains is an expensive and
time consuming process. The retrieval-augmented generation (RAG) process has
recently emerged as a method capable of optimization of LLM responses, by
referencing them to a predetermined ontology. It was shown that using a
Knowledge Graph (KG) ontology for RAG improves the QA accuracy, by taking into
account relevant sub-graphs that preserve the information in a structured
manner. In this paper, we introduce SMART-SLIC, a highly domain-specific LLM
framework, that integrates RAG with KG and a vector store (VS) that store
factual domain specific information. Importantly, to avoid hallucinations in
the KG, we build these highly domain-specific KGs and VSs without the use of
LLMs, but via NLP, data mining, and nonnegative tensor factorization with
automatic model selection. Pairing our RAG with a domain-specific: (i) KG
(containing structured information), and (ii) VS (containing unstructured
information) enables the development of domain-specific chat-bots that
attribute the source of information, mitigate hallucinations, lessen the need
for fine-tuning, and excel in highly domain-specific question answering tasks.
We pair SMART-SLIC with chain-of-thought prompting agents. The framework is
designed to be generalizable to adapt to any specific or specialized domain. In
this paper, we demonstrate the question answering capabilities of our framework
on a corpus of scientific publications on malware analysis and anomaly
detection.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Á∂ìÈÅéÂ§ßÈáèË™ûÊñôÂ∫´ÁöÑÈ†êÂÖàË®ìÁ∑¥ÔºåÂú®Ë®±Â§ö‰∏ÄËà¨Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰æãÂ¶ÇÂïèÈ°åËß£Á≠î (QA)„ÄÇÂÑòÁÆ°ÂÆÉÂÄëÂÖ∑ÊúâÂÖàÈÄ≤ÁöÑË™ûË®ÄËÉΩÂäõÔºå‰ΩÜ LLM Âú®ÁâπÂÆöÈ†òÂüüÂíåÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãôÊñπÈù¢ÊúÉÂá∫ÁèæÂπªË¶∫„ÄÅÁü•Ë≠òÊñ∑Â±§ÂíåÁº∫‰πèÁü•Ë≠òÊ≠∏Âõ†„ÄÇÊ≠§Â§ñÔºåÂæÆË™ø LLM ÁöÑÂÖßÂú®Áü•Ë≠ò‰ª•ÈÅ©ÊáâÈ´òÂ∫¶ÁâπÂÆöÈ†òÂüüÊòØ‰∏ÄÂÄãÊòÇË≤¥‰∏îËÄóÊôÇÁöÑÈÅéÁ®ã„ÄÇÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÊµÅÁ®ãÊúÄËøëÂ∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÂÑ™Âåñ LLM ÂõûÊáâÁöÑÊñπÊ≥ïÔºåÊñπÊ≥ïÊòØÂ∞áÂÆÉÂÄëÂèÉÁÖßÈ†êÂÖàÁ¢∫ÂÆöÁöÑÊú¨‰Ωì„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÂ∞áÁü•Ë≠òÂúñË≠ú (KG) Êú¨‰ΩìÁî®Êñº RAG ÂèØÈÄèÈÅéËÄÉÊÖÆ‰ª•ÁµêÊßãÂåñÊñπÂºè‰øùÁïôË≥áË®äÁöÑÁõ∏ÈóúÂ≠êÂúñÔºå‰æÜÊèêÈ´ò QA ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü SMART-SLICÔºåÈÄôÊòØ‰∏ÄÂÄãÈ´òÂ∫¶ÁâπÂÆöÈ†òÂüüÁöÑ LLM Ê°ÜÊû∂ÔºåÂÆÉÂ∞á RAG Ëàá KG Âíå‰∏ÄÂÄãÂÑ≤Â≠ò‰∫ãÂØ¶ÁâπÂÆöÈ†òÂüüË≥áË®äÁöÑÂêëÈáèÂÑ≤Â≠ò (VS) Êï¥ÂêàÂú®‰∏ÄËµ∑„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÁÇ∫‰∫ÜÈÅøÂÖç KG ‰∏≠ÁöÑÂπªË¶∫ÔºåÊàëÂÄëÂú®‰∏ç‰ΩøÁî® LLM ÁöÑÊÉÖÊ≥Å‰∏ãÂª∫Á´ã‰∫ÜÈÄô‰∫õÈ´òÂ∫¶ÁâπÂÆöÈ†òÂüüÁöÑ KG Âíå VSÔºåËÄåÊòØÈÄèÈÅé NLP„ÄÅË≥áÊñôÊé¢ÂãòÂíåÂÖ∑ÊúâËá™ÂãïÊ®°ÂûãÈÅ∏ÊìáÁöÑÈùûË≤†ÂºµÈáèÂàÜËß£„ÄÇÂ∞áÊàëÂÄëÁöÑ RAG ËàáÁâπÂÆöÈ†òÂüüÈÖçÂ∞çÔºö(i) KGÔºàÂåÖÂê´ÁµêÊßãÂåñË≥áË®äÔºâÔºåÂíå (ii) VSÔºàÂåÖÂê´ÈùûÁµêÊßãÂåñË≥áË®äÔºâËÉΩÂ§†ÈñãÁôºÁâπÂÆöÈ†òÂüüÁöÑËÅäÂ§©Ê©üÂô®‰∫∫ÔºåÈÄô‰∫õËÅäÂ§©Ê©üÂô®‰∫∫ÊúÉÊ≠∏Âõ†ÊñºË≥áË®ä‰æÜÊ∫ê„ÄÅÊ∏õËºïÂπªË¶∫„ÄÅÊ∏õÂ∞ëÂæÆË™øÁöÑÈúÄË¶ÅÔºå‰∏¶Âú®È´òÂ∫¶ÁâπÂÆöÈ†òÂüüÁöÑÂïèÈ°åËß£Á≠î‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇÊàëÂÄëÂ∞á SMART-SLIC ËàáÊÄùËÄÉÈèàÊèêÁ§∫‰ª£ÁêÜÈÖçÂ∞ç„ÄÇË©≤Ê°ÜÊû∂Ë¢´Ë®≠Ë®àÊàêÂèØÊ¶ÇÊã¨‰ª•ÈÅ©Êáâ‰ªª‰ΩïÁâπÂÆöÊàñÂ∞àÊ•≠È†òÂüü„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂú®ÊÉ°ÊÑèËªüÈ´îÂàÜÊûêÂíåÁï∞Â∏∏ÂÅµÊ∏¨ÁöÑÁßëÂ≠∏Âá∫ÁâàÁâ©Ë™ûÊñôÂ∫´‰∏äÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊ°ÜÊû∂ÁöÑÂïèÈ°åËß£Á≠îËÉΩÂäõ„ÄÇ

##### **A Schema-aware Logic Reformulation for Graph Reachability**
2410.02533v1 by Davide Di Pierro, Stefano Ferilli

Graph reachability is the task of understanding whether two distinct points
in a graph are interconnected by arcs to which in general a semantic is
attached. Reachability has plenty of applications, ranging from motion planning
to routing. Improving reachability requires structural knowledge of relations
so as to avoid the complexity of traditional depth-first and breadth-first
strategies, implemented in logic languages. In some contexts, graphs are
enriched with their schema definitions establishing domain and range for every
arc. The introduction of a schema-aware formalization for guiding the search
may result in a sensitive improvement by cutting out unuseful paths and
prioritising those that, in principle, reach the target earlier. In this work,
we propose a strategy to automatically exclude and sort certain graph paths by
exploiting the higher-level conceptualization of instances. The aim is to
obtain a new first-order logic reformulation of the graph reachability
scenario, capable of improving the traditional algorithms in terms of time,
space requirements, and number of backtracks. The experiments exhibit the
expected advantages of the approach in reducing the number of backtracks during
the search strategy, resulting in saving time and space as well.

ÊëòË¶ÅÔºöÂúñÂΩ¢ÂèØÈÅîÊÄßÊòØ‰∫ÜËß£ÂúñÂΩ¢‰∏≠ÂÖ©ÂÄã‰∏çÂêåÈªûÊòØÂê¶Áî±ÂºßÁ∑öÁõ∏‰∫íÈÄ£Êé•ÁöÑ‰ªªÂãôÔºåÈÄô‰∫õÂºßÁ∑öÈÄöÂ∏∏ÈôÑÂ∏∂Ë™ûÁæ©„ÄÇÂèØÈÅîÊÄßÊúâÂæàÂ§öÊáâÁî®ÔºåÂæûÈÅãÂãïË¶èÂäÉÂà∞Ë∑ØÁî±„ÄÇÊèêÈ´òÂèØÈÅîÊÄßÈúÄË¶ÅÁµêÊßãÈóú‰øÇÁü•Ë≠òÔºå‰ª•ÈÅøÂÖçÈÇèËºØË™ûË®Ä‰∏≠ÂØ¶ÁèæÁöÑÂÇ≥Áµ±Ê∑±Â∫¶ÂÑ™ÂÖàÂíåÂª£Â∫¶ÂÑ™ÂÖàÁ≠ñÁï•ÁöÑË§áÈõúÊÄß„ÄÇÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÔºåÂúñÂΩ¢ÊúÉÈÄöÈÅéÂÖ∂Êû∂ÊßãÂÆöÁæ©ÂæóÂà∞Ë±êÂØåÔºåÁÇ∫ÊØèÂÄãÂºßÁ∑öÂª∫Á´ãÂüüÂíåÁØÑÂúç„ÄÇÂºïÂÖ•Êû∂ÊßãÊÑüÁü•ÂΩ¢ÂºèÂåñ‰ª•ÊåáÂ∞éÊêúÂ∞ãÂèØËÉΩÊúÉÈÄöÈÅéÂàáÊñ∑ÁÑ°Áî®ÁöÑË∑ØÂæëÂíåÂÑ™ÂÖàËÄÉÊÖÆÂéüÂâá‰∏äËºÉÊó©Âà∞ÈÅîÁõÆÊ®ôÁöÑË∑ØÂæëËÄåÁî¢ÁîüÈ°ØËëóÁöÑÊîπÈÄ≤„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ≠ñÁï•ÔºåÈÄöÈÅéÂà©Áî®ÂØ¶‰æãÁöÑÈ´òÈöéÊ¶ÇÂøµÂåñ‰æÜËá™ÂãïÊéíÈô§ÂíåÊéíÂ∫èÊüê‰∫õÂúñÂΩ¢Ë∑ØÂæë„ÄÇÁõÆÁöÑÊòØÁç≤ÂæóÂúñÂΩ¢ÂèØÈÅîÊÄßÂ†¥ÊôØÁöÑÊñ∞‰∏ÄÈöéÈÇèËºØÈáçÊñ∞Ë°®Ëø∞ÔºåËÉΩÂ§†Âú®ÊôÇÈñì„ÄÅÁ©∫ÈñìÈúÄÊ±ÇÂíåÂõûÊ∫ØÊ¨°Êï∏ÊñπÈù¢ÊîπÈÄ≤ÂÇ≥Áµ±ÊºîÁÆóÊ≥ï„ÄÇÂØ¶È©óÂ±ïÁ§∫‰∫ÜË©≤ÊñπÊ≥ïÂú®Ê∏õÂ∞ëÊêúÂ∞ãÁ≠ñÁï•ÊúüÈñìÂõûÊ∫ØÊ¨°Êï∏ÊñπÈù¢ÁöÑÈ†êÊúüÂÑ™ÈªûÔºåÂæûËÄåÁØÄÁúÅ‰∫ÜÊôÇÈñìÂíåÁ©∫Èñì„ÄÇ

##### **Language Models are Graph Learners**
2410.02296v1 by Zhe Xu, Kaveh Hassani, Si Zhang, Hanqing Zeng, Michihiro Yasunaga, Limei Wang, Dongqi Fu, Ning Yao, Bo Long, Hanghang Tong

Language Models (LMs) are increasingly challenging the dominance of
domain-specific models, including Graph Neural Networks (GNNs) and Graph
Transformers (GTs), in graph learning tasks. Following this trend, we propose a
novel approach that empowers off-the-shelf LMs to achieve performance
comparable to state-of-the-art GNNs on node classification tasks, without
requiring any architectural modification. By preserving the LM's original
architecture, our approach retains a key benefit of LM instruction tuning: the
ability to jointly train on diverse datasets, fostering greater flexibility and
efficiency. To achieve this, we introduce two key augmentation strategies: (1)
Enriching LMs' input using topological and semantic retrieval methods, which
provide richer contextual information, and (2) guiding the LMs' classification
process through a lightweight GNN classifier that effectively prunes class
candidates. Our experiments on real-world datasets show that backbone Flan-T5
models equipped with these augmentation strategies outperform state-of-the-art
text-output node classifiers and are comparable to top-performing vector-output
node classifiers. By bridging the gap between specialized task-specific node
classifiers and general LMs, this work paves the way for more versatile and
widely applicable graph learning models. We will open-source the code upon
publication.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°ÂûãÔºàLMÔºâÊ≠£Êó•ÁõäÊåëÊà∞ÁâπÂÆöÈ†òÂüüÊ®°ÂûãÂú®ÂúñÂΩ¢Â≠∏Áøí‰ªªÂãô‰∏≠ÁöÑ‰∏ªÂ∞éÂú∞‰ΩçÔºåÂåÖÊã¨ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÔºàGNNÔºâÂíåÂúñÂΩ¢ËΩâÊèõÂô®ÔºàGTÔºâ„ÄÇÈÅµÂæ™Ê≠§Ë∂®Âã¢ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÊñπÊ≥ïÔºå‰ΩøÁèæÊàêÁöÑ LM ËÉΩÂ§†Âú®ÁØÄÈªûÂàÜÈ°û‰ªªÂãô‰∏≠ÂØ¶ÁèæËàáÊúÄÂÖàÈÄ≤ÁöÑ GNN Áõ∏Áï∂ÁöÑÊïàËÉΩÔºåËÄåÁÑ°ÈúÄ‰ªª‰ΩïÊû∂Êßã‰øÆÊîπ„ÄÇÈÄèÈÅé‰øùÁïô LM ÁöÑÂéüÂßãÊû∂ÊßãÔºåÊàëÂÄëÁöÑÂÅöÊ≥ï‰øùÁïô‰∫Ü LM Êåá‰ª§Ë™øÊï¥ÁöÑ‰∏ÄÈ†Ö‰∏ªË¶ÅÂÑ™ÈªûÔºöËÉΩÂ§†Âú®‰∏çÂêåÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åËÅØÂêàË®ìÁ∑¥Ôºå‰øÉÈÄ≤Êõ¥Â§ßÁöÑÈùàÊ¥ªÊÄßÂíåÊïàÁéá„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖ©ÂÄã‰∏ªË¶ÅÁöÑÊì¥ÂÖÖÁ≠ñÁï•Ôºö(1) ‰ΩøÁî®ÊãìÊí≤ÂíåË™ûÁæ©Ê™¢Á¥¢ÊñπÊ≥ïË±êÂØå LM ÁöÑËº∏ÂÖ•ÔºåÊèê‰æõÊõ¥Ë±êÂØåÁöÑ‰∏ä‰∏ãÊñáË≥áË®äÔºå‰ª•Âèä (2) ÈÄèÈÅéËºïÈáèÁ¥ö GNN ÂàÜÈ°ûÂô®ÂºïÂ∞é LM ÁöÑÂàÜÈ°ûÈÅéÁ®ãÔºåÊúâÊïàÂú∞‰øÆÂâ™È°ûÂà•ÂÄôÈÅ∏„ÄÇÊàëÂÄëÂú®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåÈÖçÂÇôÈÄô‰∫õÊì¥ÂÖÖÁ≠ñÁï•ÁöÑ‰∏ªÂππ Flan-T5 Ê®°ÂûãÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñáÂ≠óËº∏Âá∫ÁØÄÈªûÂàÜÈ°ûÂô®Ôºå‰∏¶‰∏îËàáÊïàËÉΩÊúÄ‰Ω≥ÁöÑÂêëÈáèËº∏Âá∫ÁØÄÈªûÂàÜÈ°ûÂô®Áõ∏Áï∂„ÄÇÈÄèÈÅéÁ∏ÆÂ∞èÂ∞àÈñÄÁöÑÁâπÂÆö‰ªªÂãôÁØÄÈªûÂàÜÈ°ûÂô®Âíå‰∏ÄËà¨ LM ‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Êõ¥Â§öÂÖÉÂåñ‰∏îÂª£Ê≥õÈÅ©Áî®ÁöÑÂúñÂΩ¢Â≠∏ÁøíÊ®°ÂûãÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇÊàëÂÄëÂ∞áÂú®Âá∫ÁâàÂæåÈñãÊ∫êÁ®ãÂºèÁ¢º„ÄÇ

##### **GraphIC: A Graph-Based In-Context Example Retrieval Model for Multi-Step Reasoning**
2410.02203v1 by Jiale Fu, Yaqing Wang, Simeng Han, Jiaming Fan, Chen Si, Xu Yang

In-context learning (ICL) enables large language models (LLMs) to generalize
to new tasks by incorporating a few in-context examples (ICEs) directly in the
input, without updating parameters. However, the effectiveness of ICL heavily
relies on the selection of ICEs, and conventional text-based embedding methods
are often inadequate for tasks that require multi-step reasoning, such as
mathematical and logical problem solving. This is due to the bias introduced by
shallow semantic similarities that fail to capture the deeper reasoning
structures required for these tasks. We present GraphIC, a novel approach that
leverages graph-based representations of reasoning processes, coupled with
Bayesian Networks (BNs) to select ICEs. Graph structures inherently filter out
shallow semantics while preserving the core reasoning structure. Importantly,
BNs capture the dependency of a node's attributes on its parent nodes, closely
mirroring the hierarchical nature of human cognition-where each thought is
shaped by preceding ones. This makes BNs particularly well-suited for
multi-step reasoning tasks, aligning the process more closely with human-like
reasoning. Extensive experiments across three types of reasoning tasks
(mathematical reasoning, code generation, and logical reasoning) demonstrate
that GraphIC outperforms both training-free and training-based models in
selecting ICEs, excelling in terms of both effectiveness and efficiency. We
show that GraphIC enhances ICL's performance and interoperability,
significantly advancing ICE selection for multi-step reasoning tasks.

ÊëòË¶ÅÔºö<paragraph>ÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) ËÆìÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÂ§†ÈÄèÈÅéÁõ¥Êé•Âú®Ëº∏ÂÖ•‰∏≠Âä†ÂÖ•Â∞ëÊï∏ÊÉÖÂ¢ÉÁØÑ‰æã (ICE)ÔºåËÄåÁÑ°ÈúÄÊõ¥Êñ∞ÂèÉÊï∏Ôºå‰æÜÊ¶ÇÂåñÂà∞Êñ∞ÁöÑ‰ªªÂãô‰∏≠„ÄÇÁÑ∂ËÄåÔºåICL ÁöÑÊúâÊïàÊÄßÊ•µÂ∫¶‰ª∞Ë≥¥ ICE ÁöÑÈÅ∏ÊìáÔºåËÄåÂÇ≥Áµ±ÁöÑÂü∫ÊñºÊñáÂ≠óÁöÑÂµåÂÖ•ÊñπÊ≥ïÈÄöÂ∏∏‰∏çË∂≥‰ª•Êáâ‰ªòÈúÄË¶ÅÂ§öÊ≠•È©üÊé®ÁêÜÁöÑ‰ªªÂãôÔºå‰æãÂ¶ÇÊï∏Â≠∏ÂíåÈÇèËºØÂïèÈ°åËß£Ê±∫„ÄÇÈÄôÊòØÁî±ÊñºÊ∑∫Â±§Ë™ûÊÑèÁõ∏‰ººÊÄßÂ∏∂‰æÜÁöÑÂÅèÂ∑ÆÔºåËÄåÈÄôÁ®ÆÂÅèÂ∑ÆÁÑ°Ê≥ïÊçïÊçâÈÄô‰∫õ‰ªªÂãôÊâÄÈúÄÁöÑÊõ¥Ê∑±ÂÖ•Êé®ÁêÜÁµêÊßã„ÄÇÊàëÂÄëÊèêÂá∫ GraphICÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÂÆÉÂà©Áî®Êé®ÁêÜÈÅéÁ®ãÁöÑÂúñÂΩ¢ÂåñË°®ÂæµÔºåÁµêÂêàË≤ùÊ∞èÁ∂≤Ë∑Ø (BN) ‰æÜÈÅ∏Êìá ICE„ÄÇÂúñÂΩ¢ÁµêÊßãÊúÉÂõ∫ÊúâÂú∞ÊøæÈô§Ê∑∫Â±§Ë™ûÊÑèÔºåÂêåÊôÇ‰øùÁïôÊ†∏ÂøÉÊé®ÁêÜÁµêÊßã„ÄÇÈáçË¶ÅÁöÑÊòØÔºåBN ÊçïÊçâÁØÄÈªûÂ±¨ÊÄßÂ∞çÂÖ∂Áà∂ÁØÄÈªûÁöÑ‰æùË≥¥ÊÄßÔºåÁ∑äÂØÜÂèçÊò†‰∫∫È°ûË™çÁü•ÁöÑÈöéÂ±§ÊÄßË≥™ÔºåÂÖ∂‰∏≠ÊØèÂÄãÊÉ≥Ê≥ïÈÉΩÊòØÁî±Ââç‰∏ÄÂÄãÊÉ≥Ê≥ïÊâÄÂΩ¢Â°ë„ÄÇÈÄô‰ΩøÂæó BN ÁâπÂà•ÈÅ©ÂêàÂ§öÊ≠•È©üÊé®ÁêÜ‰ªªÂãôÔºåËÆìÊµÅÁ®ãÊõ¥Ë≤ºËøëÈ°û‰ºº‰∫∫È°ûÁöÑÊé®ÁêÜ„ÄÇÊ©´Ë∑®‰∏âÁ®ÆÈ°ûÂûãÁöÑÊé®ÁêÜ‰ªªÂãôÔºàÊï∏Â≠∏Êé®ÁêÜ„ÄÅÁ®ãÂºèÁ¢ºÁî¢ÁîüÂíåÈÇèËºØÊé®ÁêÜÔºâÁöÑÂ§ßÈáèÂØ¶È©óË≠âÊòéÔºåGraphIC Âú®ÈÅ∏Êìá ICE ÊôÇÂÑ™ÊñºÁÑ°Ë®ìÁ∑¥ÂíåÂü∫ÊñºË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºåÂú®ÊúâÊïàÊÄßÂíåÊïàÁéáÊñπÈù¢ÈÉΩË°®ÁèæÂá∫Ëâ≤„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü GraphIC Â¢ûÂº∑‰∫Ü ICL ÁöÑÊïàËÉΩÂíå‰∫íÊìç‰ΩúÊÄßÔºåÈ°ØËëóÂú∞Êé®ÈÄ≤‰∫ÜÂ§öÊ≠•È©üÊé®ÁêÜ‰ªªÂãôÁöÑ ICE ÈÅ∏Êìá„ÄÇ</paragraph>

##### **G2T-LLM: Graph-to-Tree Text Encoding for Molecule Generation with Fine-Tuned Large Language Models**
2410.02198v1 by Zhaoning Yu, Xiangyang Xu, Hongyang Gao

We introduce G2T-LLM, a novel approach for molecule generation that uses
graph-to-tree text encoding to transform graph-based molecular structures into
a hierarchical text format optimized for large language models (LLMs). This
encoding converts complex molecular graphs into tree-structured formats, such
as JSON and XML, which LLMs are particularly adept at processing due to their
extensive pre-training on these types of data. By leveraging the flexibility of
LLMs, our approach allows for intuitive interaction using natural language
prompts, providing a more accessible interface for molecular design. Through
supervised fine-tuning, G2T-LLM generates valid and coherent chemical
structures, addressing common challenges like invalid outputs seen in
traditional graph-based methods. While LLMs are computationally intensive, they
offer superior generalization and adaptability, enabling the generation of
diverse molecular structures with minimal task-specific customization. The
proposed approach achieved comparable performances with state-of-the-art
methods on various benchmark molecular generation datasets, demonstrating its
potential as a flexible and innovative tool for AI-driven molecular design.

ÊëòË¶ÅÔºöÊàëÂÄë‰ªãÁ¥π G2T-LLMÔºå‰∏ÄÁ®ÆÈáùÂ∞çÂàÜÂ≠êÁîüÊàêÁöÑÂâµÊñ∞ÊñπÊ≥ïÔºåÂÆÉ‰ΩøÁî®ÂúñÂΩ¢ËΩâÊ®πÁãÄÊñáÂ≠óÁ∑®Á¢ºÔºåÂ∞áÂü∫ÊñºÂúñÂΩ¢ÁöÑÂàÜÂ≠êÁµêÊßãËΩâÊèõÁÇ∫ÈöéÂ±§ÂºèÊñáÂ≠óÊ†ºÂºèÔºåÈáùÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÊúÄ‰Ω≥Âåñ„ÄÇÊ≠§Á∑®Á¢ºÊúÉÂ∞áË§áÈõúÁöÑÂàÜÂ≠êÂúñÂΩ¢ËΩâÊèõÁÇ∫Ê®πÁãÄÁµêÊßãÊ†ºÂºèÔºå‰æãÂ¶Ç JSON Âíå XMLÔºåÁî±Êñº LLM Âú®ÈÄô‰∫õÈ°ûÂûãË≥áÊñôÁöÑÂª£Ê≥õÈ†êÂÖàË®ìÁ∑¥ÔºåÂõ†Ê≠§ÁâπÂà•ÊìÖÈï∑ËôïÁêÜÈÄô‰∫õÊ†ºÂºè„ÄÇÈÄèÈÅéÂà©Áî® LLM ÁöÑÈùàÊ¥ªÊÄßÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂÖÅË®±‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄÊèêÁ§∫ÈÄ≤Ë°åÁõ¥Ë¶∫Âºè‰∫íÂãïÔºåÊèê‰æõ‰∏ÄÂÄãÊõ¥ÂÆπÊòìÂ≠òÂèñÁöÑÂàÜÂ≠êË®≠Ë®à‰ªãÈù¢„ÄÇÈÄèÈÅéÁõ£Áù£ÂæÆË™øÔºåG2T-LLM ÊúÉÁî¢ÁîüÊúâÊïà‰∏îÈÄ£Ë≤´ÁöÑÂåñÂ≠∏ÁµêÊßãÔºåËß£Ê±∫ÂÇ≥Áµ±Âü∫ÊñºÂúñÂΩ¢ÊñπÊ≥ï‰∏≠Â∏∏Ë¶ãÁöÑÁÑ°ÊïàËº∏Âá∫Á≠âÊåëÊà∞„ÄÇÈõñÁÑ∂ LLM Âú®Ë®àÁÆó‰∏äÂæàÂØÜÈõÜÔºå‰ΩÜÂÆÉÂÄëÊèê‰æõÂÑ™Áï∞ÁöÑÊ¶ÇÊã¨ÊÄßÂíåÈÅ©ÊáâÊÄßÔºåËÉΩÂ§†Áî¢ÁîüÂ§öÊ®£ÂåñÁöÑÂàÜÂ≠êÁµêÊßãÔºå‰∏î‰ªªÂãôÁâπÂÆöËá™Ë®ÇÂåñÈúÄÊ±ÇÊ•µ‰Ωé„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÂêÑÁ®ÆÂü∫Ê∫ñÂàÜÂ≠êÁîüÊàêË≥áÊñôÈõÜ‰∏äÈÅîÂà∞‰∫ÜËàáÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁõ∏Áï∂ÁöÑÊïàËÉΩÔºåË≠âÊòé‰∫ÜÂÖ∂‰ΩúÁÇ∫ AI È©ÖÂãïÂàÜÂ≠êË®≠Ë®àÁöÑÈùàÊ¥ª‰∏îÂâµÊñ∞ÁöÑÂ∑•ÂÖ∑ÁöÑÊΩõÂäõ„ÄÇ

##### **FLAG: Financial Long Document Classification via AMR-based GNN**
2410.02024v2 by Bolun "Namir" Xia, Mohammed J. Zaki, Aparna Gupta

The advent of large language models (LLMs) has initiated much research into
their various financial applications. However, in applying LLMs on long
documents, semantic relations are not explicitly incorporated, and a full or
arbitrarily sparse attention operation is employed. In recent years, progress
has been made in Abstract Meaning Representation (AMR), which is a graph-based
representation of text to preserve its semantic relations. Since AMR can
represent semantic relationships at a deeper level, it can be beneficially
utilized by graph neural networks (GNNs) for constructing effective
document-level graph representations built upon LLM embeddings to predict
target metrics in the financial domain. We propose FLAG: Financial Long
document classification via AMR-based GNN, an AMR graph based framework to
generate document-level embeddings for long financial document classification.
We construct document-level graphs from sentence-level AMR graphs, endow them
with specialized LLM word embeddings in the financial domain, apply a deep
learning mechanism that utilizes a GNN, and examine the efficacy of our
AMR-based approach in predicting labeled target data from long financial
documents. Extensive experiments are conducted on a dataset of quarterly
earnings calls transcripts of companies in various sectors of the economy, as
well as on a corpus of more recent earnings calls of companies in the S&P 1500
Composite Index. We find that our AMR-based approach outperforms fine-tuning
LLMs directly on text in predicting stock price movement trends at different
time horizons in both datasets. Our work also outperforms previous work
utilizing document graphs and GNNs for text classification.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂá∫ÁèæÔºåÈñãÂïü‰∫ÜÂ∞çÂÖ∂ÂêÑÁ®ÆË≤°ÂãôÊáâÁî®ÁöÑÂ§ßÈáèÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÂú®Èï∑ÁØáÊñá‰ª∂‰∏≠ÊáâÁî® LLM ÊôÇÔºåË™ûÁæ©Èóú‰øÇ‰∏¶Êú™Ë¢´ÊòéÁ¢∫Á¥çÂÖ•Ôºå‰∏¶‰∏îÊé°Áî®‰∫ÜÂÆåÂÖ®Êàñ‰ªªÊÑèÁ®ÄÁñèÁöÑÊ≥®ÊÑèÊìç‰Ωú„ÄÇËøëÂπ¥‰æÜÔºåÊäΩË±°ÊÑèÁæ©Ë°®Á§∫ (AMR) Â∑≤ÂèñÂæóÈÄ≤Â±ïÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºÂúñË°®ÁöÑÊñáÂ≠óË°®Á§∫ÂΩ¢ÂºèÔºåÁî®Êñº‰øùÁïôÂÖ∂Ë™ûÁæ©Èóú‰øÇ„ÄÇÁî±Êñº AMR ËÉΩÂú®Êõ¥Ê∑±Â±§Ê¨°Ë°®Á§∫Ë™ûÁæ©Èóú‰øÇÔºåÂõ†Ê≠§ÂèØ‰ª•Áî±ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÊúâÊïàÂú∞Âà©Áî®ÔºåÁî®ÊñºÂª∫ÊßãÂª∫Á´ãÂú® LLM ÂµåÂÖ•‰∏äÁöÑÊúâÊïàÊñá‰ª∂Á¥öÂúñÂΩ¢Ë°®Á§∫Ôºå‰ª•È†êÊ∏¨Ë≤°ÂãôÈ†òÂüüÁöÑÁõÆÊ®ôÊåáÊ®ô„ÄÇÊàëÂÄëÊèêÂá∫ FLAGÔºöÈÄèÈÅéÂü∫Êñº AMR ÁöÑ GNN ÈÄ≤Ë°åË≤°ÂãôÈï∑Êñá‰ª∂ÂàÜÈ°ûÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫Êñº AMR ÂúñË°®ÁöÑÊû∂ÊßãÔºåÁî®ÊñºÁÇ∫Èï∑ÁØáË≤°ÂãôÊñá‰ª∂ÂàÜÈ°ûÁî¢ÁîüÊñá‰ª∂Á¥öÂµåÂÖ•„ÄÇÊàëÂÄëÂæûÂè•Â≠êÁ¥ö AMR ÂúñË°®Âª∫ÊßãÊñá‰ª∂Á¥öÂúñË°®ÔºåÂú®Ë≤°ÂãôÈ†òÂüüË≥¶‰∫àÂÆÉÂÄëÂ∞àÊ•≠ÁöÑ LLM Â≠óË©ûÂµåÂÖ•ÔºåÊáâÁî®Âà©Áî® GNN ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ©üÂà∂Ôºå‰∏¶Ê™¢È©óÊàëÂÄëÂü∫Êñº AMR ÁöÑÊñπÊ≥ïÂú®È†êÊ∏¨Èï∑ÁØáË≤°ÂãôÊñá‰ª∂Ê®ôË®òÁõÆÊ®ôË≥áÊñôÊñπÈù¢ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåË©≤Ë≥áÊñôÈõÜÂåÖÂê´ÂêÑÂÄãÁ∂ìÊøüÈÉ®ÈñÄÂÖ¨Âè∏ÁöÑÊØèÂ≠£Êî∂ÁõäÈõªË©±ÊúÉË≠∞Ë®òÈåÑÔºå‰ª•ÂèäÊ®ôÊôÆ 1500 Á∂úÂêàÊåáÊï∏ÂÖ¨Âè∏ÊúÄËøëÊî∂ÁõäÈõªË©±ÊúÉË≠∞ÁöÑË™ûÊñôÂ∫´„ÄÇÊàëÂÄëÁôºÁèæÔºåÊàëÂÄëÁöÑÂü∫Êñº AMR ÁöÑÊñπÊ≥ïÂú®È†êÊ∏¨ÂÖ©ÂÄãË≥áÊñôÈõÜ‰∏≠ÁöÑ‰∏çÂêåÊôÇÈñìÁØÑÂúçÂÖßÁöÑËÇ°ÂÉπËÆäÂãïË∂®Âã¢ÊñπÈù¢ÔºåÂÑ™ÊñºÁõ¥Êé•Â∞çÊñáÂ≠óÈÄ≤Ë°åÂæÆË™øÁöÑ LLM„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰πüÂÑ™ÊñºÂÖàÂâçÂà©Áî®Êñá‰ª∂ÂúñË°®Âíå GNN ÈÄ≤Ë°åÊñáÂ≠óÂàÜÈ°ûÁöÑÁ†îÁ©∂„ÄÇ

##### **Lost-in-Distance: Impact of Contextual Proximity on LLM Performance in Graph Tasks**
2410.01985v1 by Hamed Firooz, Maziar Sanjabi, Wenlong Jiang, Xiaoling Zhai

Despite significant advancements, Large Language Models (LLMs) exhibit blind
spots that impair their ability to retrieve and process relevant contextual
data effectively. We demonstrate that LLM performance in graph tasks with
complexities beyond the "needle-in-a-haystack" scenario-where solving the
problem requires cross-referencing and reasoning across multiple subproblems
jointly-is influenced by the proximity of relevant information within the
context, a phenomenon we term "lost-in-distance". We examine two fundamental
graph tasks: identifying common connections between two nodes and assessing
similarity among three nodes, and show that the model's performance in these
tasks significantly depends on the relative positioning of common edges. We
evaluate three publicly available LLMs-Llama-3-8B, Llama-3-70B, and GPT-4-using
various graph encoding techniques that represent graph structures for LLM
input. We propose a formulation for the lost-in-distance phenomenon and
demonstrate that lost-in-distance and lost-in-the middle phenomenas occur
independently. Results indicate that model accuracy can decline by up to 6x as
the distance between node connections increases, independent of graph encoding
and model size.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÊúâÈ°ØËëóÁöÑÈÄ≤Â±ïÔºåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ‰ªçÂ≠òÂú®Áõ≤ÈªûÔºåÊúÉÊêçÂÆ≥ÂÆÉÂÄëÊúâÊïàÊì∑ÂèñÂíåËôïÁêÜÁõ∏ÈóúËÑàÁµ°Ë≥áÊñôÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëË≠âÊòé‰∫Ü LLM Âú®ÂúñÂΩ¢‰ªªÂãô‰∏≠ÁöÑË°®ÁèæÔºåÂÖ∂Ë§áÈõúÂ∫¶Ë∂ÖÂá∫‰∫Ü„ÄåÂ§ßÊµ∑ÊíàÈáù„ÄçÊÉÖÂ¢ÉÔºåÂÖ∂‰∏≠Ëß£Ê±∫ÂïèÈ°åÈúÄË¶ÅË∑®Â§öÂÄãÂ≠êÂïèÈ°åÈÄ≤Ë°å‰∫§ÂèâÂèÉÁÖßÂíåÊé®ÁêÜÔºå‰∏¶ÂèóÂà∞ËÑàÁµ°‰∏≠Áõ∏ÈóúË≥áË®äÁöÑÊé•ËøëÁ®ãÂ∫¶ÂΩ±ÈüøÔºåÊàëÂÄëÂ∞áÊ≠§ÁèæË±°Á®±ÁÇ∫„ÄåÂ§±‰πãË∑ùÈõ¢„Äç„ÄÇÊàëÂÄëÊ™¢È©ó‰∫ÜÂÖ©ÂÄãÂü∫Êú¨ÁöÑÂúñÂΩ¢‰ªªÂãôÔºöË≠òÂà•ÂÖ©ÂÄãÁØÄÈªû‰πãÈñìÁöÑÂÖ±ÂêåÈÄ£Êé•Ôºå‰ª•ÂèäË©ï‰º∞‰∏âÂÄãÁØÄÈªû‰πãÈñìÁöÑÁõ∏‰ººÊÄßÔºå‰∏¶È°ØÁ§∫Ê®°ÂûãÂú®ÈÄô‰∫õ‰ªªÂãô‰∏≠ÁöÑË°®ÁèæÈ°ØËëóÂú∞ÂèñÊ±∫ÊñºÂÖ±ÂêåÈÇäÁ∑£ÁöÑÁõ∏Â∞ç‰ΩçÁΩÆ„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü‰∏âÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑ LLMÔºåÂàÜÂà•ÁÇ∫ Llama-3-8B„ÄÅLlama-3-70B Âíå GPT-4Ôºå‰ΩøÁî®ÂêÑÁ®ÆÂúñÂΩ¢Á∑®Á¢ºÊäÄË°ìÔºåÈÄô‰∫õÊäÄË°ìË°®Á§∫ LLM Ëº∏ÂÖ•ÁöÑÂúñÂΩ¢ÁµêÊßã„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂ§±‰πãË∑ùÈõ¢ÁèæË±°ÁöÑÂÖ¨ÂºèÔºå‰∏¶Ë≠âÊòé‰∫ÜÂ§±‰πãË∑ùÈõ¢ÂíåÂ§±‰πãÊñº‰∏≠ÈñìÁèæË±°ÊúÉÁç®Á´ãÁôºÁîü„ÄÇÁµêÊûúË°®ÊòéÔºåÈö®ËëóÁØÄÈªûÈÄ£Êé•‰πãÈñìÁöÑË∑ùÈõ¢Â¢ûÂä†ÔºåÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÊúÄÂ§öÂèØËÉΩÊúÉ‰∏ãÈôç 6 ÂÄçÔºåËàáÂúñÂΩ¢Á∑®Á¢ºÂíåÊ®°ÂûãÂ§ßÂ∞èÁÑ°Èóú„ÄÇ

##### **LLM+KG@VLDB'24 Workshop Summary**
2410.01978v1 by Arijit Khan, Tianxing Wu, Xi Chen

The unification of large language models (LLMs) and knowledge graphs (KGs)
has emerged as a hot topic. At the LLM+KG'24 workshop, held in conjunction with
VLDB 2024 in Guangzhou, China, one of the key themes explored was important
data management challenges and opportunities due to the effective interaction
between LLMs and KGs. This report outlines the major directions and approaches
presented by various speakers during the LLM+KG'24 workshop.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁü•Ë≠òÂúñË≠ú (KG) ÁöÑÁµ±‰∏ÄÂ∑≤ÊàêÁÇ∫ÁÜ±ÈñÄË©±È°å„ÄÇÂú®‰∏≠ÂúãÂª£Â∑ûËàâË°åÁöÑ 2024 Âπ¥ VLDB ÊúÉË≠∞ÊúüÈñìËàâËæ¶ÁöÑ LLM+KG'24 Á†îË®éÊúÉ‰∏äÔºåÊé¢Á¥¢ÁöÑ‰∏ÄÂÄãÈóúÈçµ‰∏ªÈ°åÊòØ LLM Âíå KG ‰πãÈñìÁöÑÊúâÊïà‰∫íÂãïÊâÄÂ∏∂‰æÜÁöÑÈáçË¶ÅÁöÑÊï∏ÊìöÁÆ°ÁêÜÊåëÊà∞ÂíåÊ©üÈÅá„ÄÇÊú¨Â†±ÂëäÊ¶ÇËø∞‰∫Ü LLM+KG'24 Á†îË®éÊúÉÊúüÈñìÂêÑÊºîË¨õËÄÖÊèêÂá∫ÁöÑ‰∏ªË¶ÅÊñπÂêëÂíåÊñπÊ≥ï„ÄÇ

##### **Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering**
2410.01660v1 by Klaus-Rudolf Kladny, Bernhard Sch√∂lkopf, Michael Muehlebach

Generative models lack rigorous statistical guarantees for their outputs and
are therefore unreliable in safety-critical applications. In this work, we
propose Sequential Conformal Prediction for Generative Models (SCOPE-Gen), a
sequential conformal prediction method producing prediction sets that satisfy a
rigorous statistical guarantee called conformal admissibility control. This
guarantee states that with high probability, the prediction sets contain at
least one admissible (or valid) example. To this end, our method first samples
an initial set of i.i.d. examples from a black box generative model. Then, this
set is iteratively pruned via so-called greedy filters. As a consequence of the
iterative generation procedure, admissibility of the final prediction set
factorizes as a Markov chain. This factorization is crucial, because it allows
to control each factor separately, using conformal prediction. In comparison to
prior work, our method demonstrates a large reduction in the number of
admissibility evaluations during calibration. This reduction is important in
safety-critical applications, where these evaluations must be conducted
manually by domain experts and are therefore costly and time consuming. We
highlight the advantages of our method in terms of admissibility evaluations
and cardinality of the prediction sets through experiments in natural language
generation and molecular graph extension tasks.

ÊëòË¶ÅÔºöÁîüÊàêÊ®°ÂûãÁº∫‰πèÂ∞çÂÖ∂Ëº∏Âá∫ÈÄ≤Ë°åÂö¥Ê†ºÁöÑÁµ±Ë®à‰øùË≠âÔºåÂõ†Ê≠§Âú®ÂÆâÂÖ®ÈóúÈçµÊáâÁî®‰∏≠‰∏çÂèØÈù†„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁîüÊàêÊ®°ÂûãÁöÑÈ†ÜÂ∫èÂÖ±ÂΩ¢È†êÊ∏¨ (SCOPE-Gen)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÈ†ÜÂ∫èÂÖ±ÂΩ¢È†êÊ∏¨ÊñπÊ≥ïÔºåÁî¢ÁîüÊªøË∂≥Á®±ÁÇ∫ÂÖ±ÂΩ¢ÂèØÊé°ÊÄßÊéßÂà∂ÁöÑÂö¥Ê†ºÁµ±Ë®à‰øùË≠âÁöÑÈ†êÊ∏¨ÈõÜ„ÄÇÊ≠§‰øùË≠âË°®Á§∫ÔºåÈ†êÊ∏¨ÈõÜÂú®È´òÊ©üÁéá‰∏ãËá≥Â∞ëÂåÖÂê´‰∏ÄÂÄãÂèØÊé° (ÊàñÊúâÊïà) ÁöÑÁØÑ‰æã„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈ¶ñÂÖàÂæûÈªëÁõíÁîüÊàêÊ®°Âûã‰∏≠ÊäΩÂèñ‰∏ÄÁµÑ i.i.d. ÁØÑ‰æã„ÄÇÁÑ∂ÂæåÔºåÈÄèÈÅéÊâÄË¨ÇÁöÑË≤™Â©™ÈÅéÊøæÂô®ÂèçË¶Ü‰øÆÂâ™Ê≠§ÁµÑ„ÄÇ‰ΩúÁÇ∫ÂèçË¶ÜÁîüÊàêÁ®ãÂ∫èÁöÑÁµêÊûúÔºåÊúÄÁµÇÈ†êÊ∏¨ÈõÜÁöÑÂèØÊé°ÊÄßÂàÜËß£ÁÇ∫È¶¨ÂèØÂ§´Èèà„ÄÇÊ≠§ÂàÜËß£Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÂÖÅË®±‰ΩøÁî®ÂÖ±ÂΩ¢È†êÊ∏¨ÂàÜÂà•ÊéßÂà∂ÊØèÂÄãÂõ†Â≠ê„ÄÇËàáÂÖàÂâçÁöÑÂ∑•‰ΩúÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈ°ØÁ§∫Âú®Ê†°Ê∫ñÈÅéÁ®ã‰∏≠ÂèØÂ§ßÂπÖÊ∏õÂ∞ëÂèØÊé°ÊÄßË©ï‰º∞ÁöÑÊï∏Èáè„ÄÇÊ≠§Ê∏õÂ∞ëÂú®ÂÆâÂÖ®ÈóúÈçµÊáâÁî®‰∏≠ÂæàÈáçË¶ÅÔºåÂú®ÈÄô‰∫õÊáâÁî®‰∏≠ÔºåÈÄô‰∫õË©ï‰º∞ÂøÖÈ†àÁî±È†òÂüüÂ∞àÂÆ∂ÊâãÂãïÈÄ≤Ë°åÔºåÂõ†Ê≠§ÊàêÊú¨È´òÊòÇ‰∏îËÄóÊôÇ„ÄÇÊàëÂÄëÈÄèÈÅéËá™ÁÑ∂Ë™ûË®ÄÁîüÊàêÂíåÂàÜÂ≠êÂúñÂΩ¢Âª∂‰º∏‰ªªÂãô‰∏≠ÁöÑÂØ¶È©óÔºåÁ™ÅÈ°ØÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂèØÊé°ÊÄßË©ï‰º∞ÂíåÈ†êÊ∏¨ÈõÜÂü∫Êï∏ÊñπÈù¢ÁöÑÂÑ™Èªû„ÄÇ

##### **HiReview: Hierarchical Taxonomy-Driven Automatic Literature Review Generation**
2410.03761v1 by Yuntong Hu, Zhuofeng Li, Zheng Zhang, Chen Ling, Raasikh Kanjiani, Boxin Zhao, Liang Zhao

In this work, we present HiReview, a novel framework for hierarchical
taxonomy-driven automatic literature review generation. With the exponential
growth of academic documents, manual literature reviews have become
increasingly labor-intensive and time-consuming, while traditional
summarization models struggle to generate comprehensive document reviews
effectively. Large language models (LLMs), with their powerful text processing
capabilities, offer a potential solution; however, research on incorporating
LLMs for automatic document generation remains limited. To address key
challenges in large-scale automatic literature review generation (LRG), we
propose a two-stage taxonomy-then-generation approach that combines graph-based
hierarchical clustering with retrieval-augmented LLMs. First, we retrieve the
most relevant sub-community within the citation network, then generate a
hierarchical taxonomy tree by clustering papers based on both textual content
and citation relationships. In the second stage, an LLM generates coherent and
contextually accurate summaries for clusters or topics at each hierarchical
level, ensuring comprehensive coverage and logical organization of the
literature. Extensive experiments demonstrate that HiReview significantly
outperforms state-of-the-art methods, achieving superior hierarchical
organization, content relevance, and factual accuracy in automatic literature
review generation tasks.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü HiReviewÔºå‰∏ÄÂÄãÁî®ÊñºÂàÜÂ±§ÂàÜÈ°ûÈ©ÖÂãïÁöÑËá™ÂãïÊñáÁçªÂõûÈ°ßÁîüÊàêÁöÑÂÖ®Êñ∞Ê°ÜÊû∂„ÄÇÈö®ËëóÂ≠∏Ë°ìÊñáÁçªÁöÑÊåáÊï∏Á¥öÂ¢ûÈï∑ÔºåÊâãÂãïÊñáÁçªÂõûÈ°ßËÆäÂæóË∂ä‰æÜË∂äÂãûÂãïÂØÜÈõÜ‰∏îËÄóÊôÇÔºåËÄåÂÇ≥Áµ±ÁöÑÊëòË¶ÅÊ®°ÂûãÈõ£‰ª•ÊúâÊïàÂú∞ÁîüÊàêÂÖ®Èù¢ÁöÑÊñá‰ª∂ÂõûÈ°ß„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊÜëËóâÂÖ∂Âº∑Â§ßÁöÑÊñáÊú¨ËôïÁêÜËÉΩÂäõÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊΩõÂú®ÁöÑËß£Ê±∫ÊñπÊ°àÔºõÁÑ∂ËÄåÔºåÂ∞á LLM Á¥çÂÖ•Ëá™ÂãïÊñá‰ª∂ÁîüÊàêÁöÑÁ†îÁ©∂‰ªçÁÑ∂ÊúâÈôê„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÂ§ßË¶èÊ®°Ëá™ÂãïÊñáÁçªÂõûÈ°ßÁîüÊàê (LRG) ‰∏≠ÁöÑ‰∏ªË¶ÅÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂÖ©ÈöéÊÆµÁöÑÂàÜÈ°ûÂÜçÁîüÊàêÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂ∞áÂü∫ÊñºÂúñÂΩ¢ÁöÑÂ±§Ê¨°ËÅöÈ°ûËàáÊ™¢Á¥¢Â¢ûÂº∑ÁöÑ LLM Áõ∏ÁµêÂêà„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÊ™¢Á¥¢ÂºïÊñáÁ∂≤Ë∑Ø‰∏≠ÊúÄÁõ∏ÈóúÁöÑÂ≠êÁ§æÁæ§ÔºåÁÑ∂ÂæåÊ†πÊìöÊñáÊú¨ÂÖßÂÆπÂíåÂºïÊñáÈóú‰øÇÂ∞çË´ñÊñáÈÄ≤Ë°åËÅöÈ°ûÔºåÁîüÊàê‰∏ÄÂÄãÂàÜÂ±§ÂàÜÈ°ûÊ®π„ÄÇÂú®Á¨¨‰∫åÈöéÊÆµÔºåLLM ÁÇ∫ÊØèÂÄãÂ±§Á¥öÁöÑÁæ§ÈõÜÊàñ‰∏ªÈ°åÁîüÊàêÈÄ£Ë≤´‰∏îÂú®Ë™ûÂ¢É‰∏äÊ∫ñÁ¢∫ÁöÑÊëòË¶ÅÔºåÁ¢∫‰øùÊñáÁçªÁöÑÂÖ®Èù¢Ë¶ÜËìãÂíåÈÇèËºØÁµÑÁπî„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË°®ÊòéÔºåHiReview ÊòéÈ°ØÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºåÂú®Ëá™ÂãïÊñáÁçªÂõûÈ°ßÁîüÊàê‰ªªÂãô‰∏≠ÂØ¶Áèæ‰∫ÜÂá∫Ëâ≤ÁöÑÂ±§Ê¨°ÁµÑÁπî„ÄÅÂÖßÂÆπÁõ∏ÈóúÊÄßÂíå‰∫ãÂØ¶Ê∫ñÁ¢∫ÊÄß„ÄÇ

##### **LEGO: Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion**
2410.01506v2 by Dexuan Ding, Lei Wang, Liyun Zhu, Tom Gedeon, Piotr Koniusz

In computer vision tasks, features often come from diverse representations,
domains, and modalities, such as text, images, and videos. Effectively fusing
these features is essential for robust performance, especially with the
availability of powerful pre-trained models like vision-language models.
However, common fusion methods, such as concatenation, element-wise operations,
and non-linear techniques, often fail to capture structural relationships, deep
feature interactions, and suffer from inefficiency or misalignment of features
across domains. In this paper, we shift from high-dimensional feature space to
a lower-dimensional, interpretable graph space by constructing similarity
graphs that encode feature relationships at different levels, e.g., clip,
frame, patch, token, etc. To capture deeper interactions, we use graph power
expansions and introduce a learnable graph fusion operator to combine these
graph powers for more effective fusion. Our approach is relationship-centric,
operates in a homogeneous space, and is mathematically principled, resembling
element-wise similarity score aggregation via multilinear polynomials. We
demonstrate the effectiveness of our graph-based fusion method on video anomaly
detection, showing strong performance across multi-representational,
multi-modal, and multi-domain feature fusion tasks.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈõªËÖ¶Ë¶ñË¶∫‰ªªÂãô‰∏≠ÔºåÁâπÂæµÈÄöÂ∏∏‰æÜËá™‰∏çÂêåÁöÑË°®Á§∫„ÄÅ
È†òÂüüÂíåÊ®°ÂºèÔºå‰æãÂ¶ÇÊñáÂ≠ó„ÄÅÂΩ±ÂÉèÂíåÂΩ±Áâá„ÄÇÊúâÊïàËûçÂêà
ÈÄô‰∫õÁâπÂæµÂ∞çÊñºÂº∑ÂÅ•ÁöÑÊïàËÉΩËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®
ÂÖ∑ÂÇôÂº∑Â§ßÈ†êË®ìÁ∑¥Ê®°ÂûãÔºà‰æãÂ¶ÇË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÔºâÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇ
ÁÑ∂ËÄåÔºåÂ∏∏Ë¶ãÁöÑËûçÂêàÊñπÊ≥ïÔºå‰æãÂ¶Ç‰∏≤Êé•„ÄÅÈÄêÂÖÉÁ¥†ÈÅãÁÆóÔºå
ÂíåÈùûÁ∑öÊÄßÊäÄË°ìÔºåÈÄöÂ∏∏ÁÑ°Ê≥ïÊçïÊçâÁµêÊßãÈóú‰øÇ„ÄÅÊ∑±Â∫¶
ÁâπÂæµ‰∫íÂãïÔºå‰∏¶‰∏îÊúÉÂèóÂà∞ÈùûÊïàÁéáÊàñÁâπÂæµÂú®‰∏çÂêåÈ†òÂüü‰∏≠Êú™Â∞çÈΩäÁöÑÂΩ±Èüø„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂæûÈ´òÁ∂≠ÁâπÂæµÁ©∫ÈñìËΩâÁßªÂà∞
‰ΩéÁ∂≠„ÄÅÂèØËß£ÈáãÁöÑÂúñÂΩ¢Á©∫ÈñìÔºåÈÄèÈÅéÂª∫ÊßãÁõ∏‰ººÊÄß
ÂúñÂΩ¢‰æÜÁ∑®Á¢º‰∏çÂêåÂ±§Á¥öÁöÑÁâπÂæµÈóú‰øÇÔºå‰æãÂ¶ÇÂâ™ËºØ„ÄÅ
ÂΩ±Ê†º„ÄÅË≤ºÁâá„ÄÅÊ®ôË®òÁ≠â„ÄÇÁÇ∫‰∫ÜÊçïÊçâÊõ¥Ê∑±ÂÖ•ÁöÑ‰∫íÂãïÔºåÊàëÂÄë‰ΩøÁî®ÂúñÂΩ¢ÂÜ™
Â±ïÈñãÔºå‰∏¶ÂºïÂÖ•ÂèØÂ≠∏ÁøíÁöÑÂúñÂΩ¢ËûçÂêàÈÅãÁÆóÂ≠êÔºå‰ª•ÁµêÂêàÈÄô‰∫õ
ÂúñÂΩ¢ÂÜ™Ôºå‰ª•ÂØ¶ÁèæÊõ¥ÊúâÊïàÁöÑËûçÂêà„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ª•Èóú‰øÇÁÇ∫‰∏≠ÂøÉÔºå
Âú®ÂêåË≥™Á©∫Èñì‰∏≠ÈÅã‰ΩúÔºå‰∏¶‰∏îÂÖ∑ÊúâÊï∏Â≠∏ÂéüÁêÜÔºåÈ°û‰ººÊñº
ÈÄèÈÅéÂ§öÁ∑öÊÄßÂ§öÈ†ÖÂºèÈÄ≤Ë°åÈÄêÂÖÉÁ¥†Áõ∏‰ººÂ∫¶ÂàÜÊï∏ËÅöÂêà„ÄÇÊàëÂÄë
Âú®ÂΩ±ÁâáÁï∞Â∏∏ÂÅµÊ∏¨‰∏≠Â±ïÁ§∫‰∫ÜÂü∫ÊñºÂúñÂΩ¢ÁöÑËûçÂêàÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÂú®Â§öË°®Á§∫„ÄÅ
Â§öÊ®°ÂºèÂíåÂ§öÈ†òÂüüÁâπÂæµËûçÂêà‰ªªÂãô‰∏≠Â±ïÁèæÂº∑Â§ßÁöÑÊïàËÉΩ„ÄÇ</paragraph>

##### **Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering**
2410.01401v1 by Yu Zhang, Kehai Chen, Xuefeng Bai, zhao kang, Quanjiang Guo, Min Zhang

Knowledge graph question answering (KGQA) involves answering natural language
questions by leveraging structured information stored in a knowledge graph.
Typically, KGQA initially retrieve a targeted subgraph from a large-scale
knowledge graph, which serves as the basis for reasoning models to address
queries. However, the retrieved subgraph inevitably brings distraction
information for knowledge utilization, impeding the model's ability to perform
accurate reasoning. To address this issue, we propose a Question-guided
Knowledge Graph Re-scoring method (Q-KGR) to eliminate noisy pathways for the
input question, thereby focusing specifically on pertinent factual knowledge.
Moreover, we introduce Knowformer, a parameter-efficient method for injecting
the re-scored knowledge graph into large language models to enhance their
ability to perform factual reasoning. Extensive experiments on multiple KGQA
benchmarks demonstrate the superiority of our method over existing systems.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË°®ÂïèÁ≠î (KGQA) Ê∂âÂèäÂà©Áî®ÂÑ≤Â≠òÂú®Áü•Ë≠òÂúñË°®‰∏≠ÁöÑÁµêÊßãÂåñË≥áË®ä‰æÜÂõûÁ≠îËá™ÁÑ∂Ë™ûË®ÄÂïèÈ°å„ÄÇÈÄöÂ∏∏ÔºåKGQA ÊúÄÂàùÊúÉÂæûÂ§ßË¶èÊ®°Áü•Ë≠òÂúñË°®‰∏≠Êì∑ÂèñÁõÆÊ®ôÂ≠êÂúñÔºå‰ΩúÁÇ∫Êé®ÁêÜÊ®°ÂûãËôïÁêÜÊü•Ë©¢ÁöÑÂü∫Á§é„ÄÇÁÑ∂ËÄåÔºåÊì∑ÂèñÁöÑÂ≠êÂúñÈõ£ÂÖçÊúÉÂ∏∂‰æÜÈõúË®äË≥áË®äÔºåÈòªÁ§ôÊ®°ÂûãÂü∑Ë°åÁ≤æÁ¢∫Êé®ÁêÜÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂïèÈ°åÂ∞éÂêëÁü•Ë≠òÂúñË°®ÈáçÊñ∞Ë©ïÂàÜÊñπÊ≥ï (Q-KGR)Ôºå‰ª•Ê∂àÈô§Ëº∏ÂÖ•ÂïèÈ°åÁöÑÈõúË®äË∑ØÂæëÔºåÂæûËÄåÂ∞àÊ≥®ÊñºÁõ∏ÈóúÁöÑ‰∫ãÂØ¶Áü•Ë≠ò„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü KnowformerÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂèÉÊï∏ÊïàÁéáÈ´òÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂ∞áÈáçÊñ∞Ë©ïÂàÜÁöÑÁü•Ë≠òÂúñË°®Ê≥®ÂÖ•Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºå‰ª•Â¢ûÂº∑ÂÆÉÂÄëÂü∑Ë°å‰∫ãÂØ¶Êé®ÁêÜÁöÑËÉΩÂäõ„ÄÇÂú®Â§öÂÄã KGQA Âü∫Ê∫ñ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂÑ™ÊñºÁèæÊúâÁ≥ªÁµ±„ÄÇ

##### **Unveiling Language Skills under Circuits**
2410.01334v1 by Hang Chen, Jiaying Zhu, Xinyu Yang, Wenya Wang

The exploration of language skills in language models (LMs) has always been
one of the central goals in mechanistic interpretability. However, existing
circuit analyses often fall short in representing the full functional scope of
these models, primarily due to the exclusion of Feed-Forward layers.
Additionally, isolating the effect of a single language skill from a text,
which inherently involves multiple entangled skills, poses a significant
challenge. To address these gaps, we introduce a novel concept, Memory Circuit,
a minimum unit that fully and independently manipulates the memory-reading
functionality of a language model, and disentangle the transformer model
precisely into a circuit graph which is an ensemble of paths connecting
different memory circuits. Based on this disentanglement, we identify salient
circuit paths, named as skill paths, responsible for three crucial language
skills, i.e., the Previous Token Skill, Induction Skill and In-Context Learning
(ICL) Skill, leveraging causal effect estimation through interventions and
counterfactuals. Our experiments on various datasets confirm the correspondence
between our identified skill paths and language skills, and validate three
longstanding hypotheses: 1) Language skills are identifiable through circuit
dissection; 2) Simple language skills reside in shallow layers, whereas complex
language skills are found in deeper layers; 3) Complex language skills are
formed on top of simpler language skills. Our codes are available at:
https://github.com/Zodiark-ch/Language-Skill-of-LLMs.

ÊëòË¶ÅÔºö<paragraph>Âú®Ë™ûË®ÄÊ®°Âûã (LM) ‰∏≠Êé¢Á¥¢Ë™ûË®ÄÊäÄËÉΩ‰∏ÄÁõ¥ÊòØÊ©üÊ¢∞ÂèØËß£ÈáãÊÄßÁöÑÊ†∏ÂøÉÁõÆÊ®ô‰πã‰∏Ä„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÈõªË∑ØÂàÜÊûêÂæÄÂæÄÁÑ°Ê≥ïË°®Á§∫ÈÄô‰∫õÊ®°ÂûãÁöÑÂÖ®ÈÉ®ÂäüËÉΩÁØÑÂúçÔºå‰∏ªË¶ÅÊòØÁî±ÊñºÊéíÈô§‰∫ÜÂâçÈ•ãÂ±§„ÄÇÊ≠§Â§ñÔºåÂæûÊñáÊú¨‰∏≠ÂàÜÈõ¢Âá∫ÂñÆ‰∏ÄË™ûË®ÄÊäÄËÉΩÁöÑÂΩ±ÈüøÔºàÈÄôÊú¨Ë≥™‰∏äÊ∂âÂèäÂ§öÁ®ÆÁ≥æÁ∫èÁöÑÊäÄËÉΩÔºâÊßãÊàê‰∫Ü‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü Memory CircuitÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ¶ÇÂøµÔºåÂÆÉÊòØ‰∏ÄÂÄãÊúÄÂ∞èÂñÆÂÖÉÔºåÂèØ‰ª•ÂÆåÊï¥‰∏îÁç®Á´ãÂú∞Êìç‰ΩúË™ûË®ÄÊ®°ÂûãÁöÑË®òÊÜ∂È´îËÆÄÂèñÂäüËÉΩÔºå‰∏¶Â∞á Transformer Ê®°ÂûãÁ≤æÁ¢∫Âú∞Ëß£ÈñãÊàê‰∏ÄÂÄãÈõªË∑ØÂúñÔºåÂÆÉÊòØ‰∏ÄÂÄãÈÄ£Êé•‰∏çÂêåË®òÊÜ∂È´îÈõªË∑ØÁöÑË∑ØÂæëÈõÜÂêà„ÄÇÂü∫ÊñºÈÄôÁ®ÆËß£ÈñãÔºåÊàëÂÄëË≠òÂà•Âá∫È°ØËëóÁöÑÈõªË∑ØË∑ØÂæëÔºåÁ®±ÁÇ∫ÊäÄËÉΩË∑ØÂæëÔºåÂÆÉË≤†Ë≤¨‰∏âÈ†ÖÈóúÈçµÁöÑË™ûË®ÄÊäÄËÉΩÔºåÂç≥Ââç‰∏ÄÂÄãÁ¨¶ËôüÊäÄËÉΩ„ÄÅÊ≠∏Á¥çÊäÄËÉΩÂíåË™ûÂ¢ÉÂ≠∏Áøí (ICL) ÊäÄËÉΩÔºåÂà©Áî®Âõ†ÊûúÊïàÊáâ‰º∞Ë®àÈÄöÈÅéÂπ≤È†êÂíåÂèç‰∫ãÂØ¶„ÄÇÊàëÂÄëÂú®ÂêÑÁ®ÆË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË≠âÂØ¶‰∫ÜÊàëÂÄëË≠òÂà•Âá∫ÁöÑÊäÄËÉΩË∑ØÂæëËàáË™ûË®ÄÊäÄËÉΩ‰πãÈñìÁöÑÂ∞çÊáâÈóú‰øÇÔºå‰∏¶È©óË≠â‰∫Ü‰∏âÂÄãÈï∑ÊúüÁöÑÂÅáË®≠Ôºö1) Ë™ûË®ÄÊäÄËÉΩÂèØ‰ª•ÈÄèÈÅéÈõªË∑ØËß£Ââñ‰æÜË≠òÂà•Ôºõ2) Á∞°ÂñÆÁöÑË™ûË®ÄÊäÄËÉΩÂ≠òÂú®ÊñºÊ∑∫Â±§‰∏≠ÔºåËÄåË§áÈõúÁöÑË™ûË®ÄÊäÄËÉΩÂâáÂ≠òÂú®ÊñºÊ∑±Â±§‰∏≠Ôºõ3) Ë§áÈõúÁöÑË™ûË®ÄÊäÄËÉΩÂª∫Á´ãÂú®Êõ¥Á∞°ÂñÆÁöÑË™ûË®ÄÊäÄËÉΩ‰πã‰∏ä„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Zodiark-ch/Language-Skill-of-LLMs ÂèñÂæó„ÄÇ</paragraph>

##### **From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems**
2410.01066v1 by Ali Mohammadjafari, Anthony S. Maida, Raju Gottumukkala

Since the onset of LLMs, translating natural language queries to structured
SQL commands is assuming increasing. Unlike the previous reviews, this survey
provides a comprehensive study of the evolution of LLM-based text-to-SQL
systems, from early rule-based models to advanced LLM approaches, and how LLMs
impacted this field. We discuss benchmarks, evaluation methods and evaluation
metrics. Also, we uniquely study the role of integration of knowledge graphs
for better contextual accuracy and schema linking in these systems. The current
techniques fall into two categories: in-context learning of corpus and
fine-tuning, which then leads to approaches such as zero-shot, few-shot
learning from the end, and data augmentation. Finally, we highlight key
challenges such as computational efficiency, model robustness, and data privacy
with perspectives toward their development and improvements in potential areas
for future of LLM-based text-to-SQL system.

ÊëòË¶ÅÔºöËá™ LLM Âá∫Áèæ‰ª•‰æÜÔºåÂ∞áËá™ÁÑ∂Ë™ûË®ÄÊü•Ë©¢ËΩâÊèõÁÇ∫ÁµêÊßãÂåñ SQL Êåá‰ª§Ê≠£ËÆäÂæóË∂ä‰æÜË∂äÊôÆÈÅç„ÄÇËàáÂÖàÂâçÁöÑË©ïË´ñ‰∏çÂêåÔºåÊú¨Ë™øÊü•Â∞çÂü∫Êñº LLM ÁöÑÊñáÂ≠óËΩâ SQL Á≥ªÁµ±ÁöÑÊºîËÆäÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÁ†îÁ©∂ÔºåÂæûÊó©ÊúüÁöÑÂü∫ÊñºË¶èÂâáÁöÑÊ®°ÂûãÂà∞ÂÖàÈÄ≤ÁöÑ LLM ÊñπÊ≥ïÔºå‰ª•Âèä LLM Â¶Ç‰ΩïÂΩ±ÈüøÈÄôÂÄãÈ†òÂüü„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÂü∫Ê∫ñ„ÄÅË©ï‰º∞ÊñπÊ≥ïÂíåË©ï‰º∞ÊåáÊ®ô„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÁç®ÁâπÂú∞Á†îÁ©∂‰∫ÜÁü•Ë≠òÂúñË≠úÊï¥ÂêàÂú®ÈÄô‰∫õÁ≥ªÁµ±‰∏≠ÁôºÊèÆÁöÑ‰ΩúÁî®Ôºå‰ª•ÊèêÈ´òË™ûÂ¢ÉÊ∫ñÁ¢∫ÊÄßÂíåÊ®°ÂºèÈÄ£Áµê„ÄÇÁõÆÂâçÁöÑÊäÄË°ìÂàÜÁÇ∫ÂÖ©È°ûÔºöË™ûÊñôÂ∫´ÁöÑË™ûÂ¢ÉÂ≠∏ÁøíÂíåÂæÆË™øÔºåÈÄôÈÄ≤ËÄåÂ∞éËá¥‰∫ÜÈõ∂Ê¨°Â≠∏Áøí„ÄÅÂ∞ëÊ¨°Â≠∏ÁøíÁ≠âÊñπÊ≥ïÔºåÊúÄÂæåÊòØË≥áÊñôÊì¥ÂÖÖ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈáçÈªû‰ªãÁ¥π‰∫ÜË®àÁÆóÊïàÁéá„ÄÅÊ®°ÂûãÁ©©ÂÅ•ÊÄßÂíåË≥áÊñôÈö±ÁßÅÁ≠âÈóúÈçµÊåëÊà∞Ôºå‰∏¶Â±ïÊúõ‰∫ÜÂÆÉÂÄëÂú®Êú™‰æÜÂü∫Êñº LLM ÁöÑÊñáÂ≠óËΩâ SQL Á≥ªÁµ±ÁöÑÁôºÂ±ïÂíåÊîπÈÄ≤ÁöÑÊΩõÂú®È†òÂüü„ÄÇ

##### **GUNDAM: Aligning Large Language Models with Graph Understanding**
2409.20053v2 by Sheng Ouyang, Yulan Hu, Ge Chen, Yong Liu

Large Language Models (LLMs) have achieved impressive results in processing
text data, which has sparked interest in applying these models beyond textual
data, such as graphs. In the field of graph learning, there is a growing
interest in harnessing LLMs to comprehend and manipulate graph-structured data.
Existing research predominantly focuses on graphs with rich textual features,
such as knowledge graphs or text attribute graphs, leveraging LLMs' ability to
process text but inadequately addressing graph structure. This work
specifically aims to assess and enhance LLMs' abilities to comprehend and
utilize the structural knowledge inherent in graph data itself, rather than
focusing solely on graphs rich in textual content. To achieve this, we
introduce the \textbf{G}raph \textbf{U}nderstanding for \textbf{N}atural
Language \textbf{D}riven \textbf{A}nalytical \textbf{M}odel (\model). This
model adapts LLMs to better understand and engage with the structure of graph
data, enabling them to perform complex reasoning tasks by leveraging the
graph's structure itself. Our experimental evaluations on graph reasoning
benchmarks not only substantiate that \model~ outperforms the SOTA baselines
for comparisons. But also reveals key factors affecting the graph reasoning
capabilities of LLMs. Moreover, we provide a theoretical analysis illustrating
how reasoning paths can enhance LLMs' reasoning capabilities.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ËôïÁêÜÊñáÂ≠óË≥áÊñôÊñπÈù¢ÂèñÂæó‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÊûúÔºåÈÄôÊøÄÁôº‰∫ÜÂ∞áÈÄô‰∫õÊ®°ÂûãÊáâÁî®ÊñºÊñáÂ≠óË≥áÊñô‰ª•Â§ñÈ†òÂüüÁöÑËààË∂£Ôºå‰æãÂ¶ÇÂúñË°®„ÄÇÂú®ÂúñË°®Â≠∏ÁøíÈ†òÂüüÔºåÂà©Áî® LLM ‰æÜÁêÜËß£ÂíåËôïÁêÜÂúñÂΩ¢ÁµêÊßãË≥áÊñôÁöÑËààË∂£ËàáÊó•‰ø±Â¢û„ÄÇÁèæÊúâÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÂÖ∑ÊúâË±êÂØåÊñáÂ≠óÁâπÂæµÁöÑÂúñË°®Ôºå‰æãÂ¶ÇÁü•Ë≠òÂúñË°®ÊàñÊñáÂ≠óÂ±¨ÊÄßÂúñË°®ÔºåÂà©Áî® LLM ËôïÁêÜÊñáÂ≠óÁöÑËÉΩÂäõÔºå‰ΩÜÊú™ËÉΩÂÖÖÂàÜËß£Ê±∫ÂúñË°®ÁµêÊßã„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁâπÂà•Êó®Âú®Ë©ï‰º∞ÂíåÂ¢ûÂº∑ LLM ÁêÜËß£ÂíåÂà©Áî®ÂúñË°®Ë≥áÊñôÊú¨Ë∫´Âõ∫ÊúâÁµêÊßãÁü•Ë≠òÁöÑËÉΩÂäõÔºåËÄå‰∏çÊòØÂÉÖÂ∞àÊ≥®ÊñºÂØåÂê´ÊñáÂ≠óÂÖßÂÆπÁöÑÂúñË°®„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜËá™ÁÑ∂Ë™ûË®ÄÈ©ÖÂãïÂàÜÊûêÊ®°Âûã (\model) ÁöÑÂúñË°®ÁêÜËß£„ÄÇÊ≠§Ê®°ÂûãË™øÊï¥ LLM ‰ª•‰æøÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÂèÉËàáÂúñË°®Ë≥áÊñôÁöÑÁµêÊßãÔºå‰ΩøÂÆÉÂÄëËÉΩÂ§†ÈÄöÈÅéÂà©Áî®ÂúñË°®ÁöÑÁµêÊßãÊú¨Ë∫´‰æÜÂü∑Ë°åË§áÈõúÁöÑÊé®ÁêÜ‰ªªÂãô„ÄÇÊàëÂÄëÂú®ÂúñË°®Êé®ÁêÜÂü∫Ê∫ñ‰∏äÁöÑÂØ¶È©óË©ï‰º∞‰∏çÂÉÖË≠âÂØ¶ \model~ ÂÑ™ÊñºÊØîËºÉ‰∏≠ÁöÑ SOTA Âü∫Ê∫ñ„ÄÇÈÇÑÊè≠Á§∫‰∫ÜÂΩ±Èüø LLM ÂúñË°®Êé®ÁêÜËÉΩÂäõÁöÑ‰∏ªË¶ÅÂõ†Á¥†„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÁêÜË´ñÂàÜÊûêÔºåË™™ÊòéÊé®ÁêÜË∑ØÂæëÂ¶Ç‰ΩïÂ¢ûÂº∑ LLM ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ

##### **Enhancing High-order Interaction Awareness in LLM-based Recommender Model**
2409.19979v2 by Xinfeng Wang, Jin Cui, Fumiyo Fukumoto, Yoshimi Suzuki

Large language models (LLMs) have demonstrated prominent reasoning
capabilities in recommendation tasks by transforming them into text-generation
tasks. However, existing approaches either disregard or ineffectively model the
user-item high-order interactions. To this end, this paper presents an enhanced
LLM-based recommender (ELMRec). We enhance whole-word embeddings to
substantially enhance LLMs' interpretation of graph-constructed interactions
for recommendations, without requiring graph pre-training. This finding may
inspire endeavors to incorporate rich knowledge graphs into LLM-based
recommenders via whole-word embedding. We also found that LLMs often recommend
items based on users' earlier interactions rather than recent ones, and present
a reranking solution. Our ELMRec outperforms state-of-the-art (SOTA) methods in
both direct and sequential recommendations.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Ë≠âÊòéÂú®Êé®Ëñ¶‰ªªÂãô‰∏≠ÂÖ∑ÊúâÈ°ØËëóÁöÑÊé®ÁêÜËÉΩÂäõÔºåÊñπÊ≥ïÊòØÂ∞áÂÖ∂ËΩâÊèõÁÇ∫ÊñáÊú¨ÁîüÊàê‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ï‰∏çÊòØÂøΩÁï•Áî®Êà∂È†ÖÁõÆÈ´òÈöé‰∫íÂãïÔºåÂ∞±ÊòØÂ∞çÂÖ∂Âª∫Ê®°ÊïàÊûú‰∏ç‰Ω≥„ÄÇÁÇ∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂ¢ûÂº∑ÁöÑÂü∫Êñº LLM ÁöÑÊé®Ëñ¶Âô® (ELMRec)„ÄÇÊàëÂÄëÂ¢ûÂº∑‰∫ÜÂÖ®Ë©ûÂµåÂÖ•Ôºå‰ª•Â§ßÂπÖÂ¢ûÂº∑ LLM Â∞çÂúñÂΩ¢ÊßãÂª∫‰∫íÂãïÁöÑËß£ËÆÄÔºåÁî®ÊñºÊé®Ëñ¶ÔºåËÄå‰∏çÈúÄË¶ÅÂúñÂΩ¢È†êË®ìÁ∑¥„ÄÇÈÄô‰∏ÄÁôºÁèæÂèØËÉΩÊúÉÊøÄÂãµÂ∞áË±êÂØåÁöÑÁü•Ë≠òÂúñË≠úÈÄöÈÅéÂÖ®Ë©ûÂµåÂÖ•Êï¥ÂêàÂà∞Âü∫Êñº LLM ÁöÑÊé®Ëñ¶Âô®‰∏≠ÁöÑÂä™Âäõ„ÄÇÊàëÂÄëÈÇÑÁôºÁèæÔºåLLM ÈÄöÂ∏∏Ê†πÊìöÁî®Êà∂Êó©ÊúüÁöÑ‰∫íÂãïËÄåÈùûÊúÄËøëÁöÑ‰∫íÂãï‰æÜÊé®Ëñ¶È†ÖÁõÆÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈáçÊñ∞ÊéíÂ∫èÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊàëÂÄëÁöÑ ELMRec Âú®Áõ¥Êé•ÂíåÈ†ÜÂ∫èÊé®Ëñ¶‰∏≠ÈÉΩÂÑ™ÊñºÊúÄÂÖàÈÄ≤ (SOTA) ÊñπÊ≥ï„ÄÇ

##### **CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering**
2409.19753v2 by Yike Wu, Yi Huang, Nan Hu, Yuncheng Hua, Guilin Qi, Jiaoyan Chen, Jeff Z. Pan

Recent studies have explored the use of Large Language Models (LLMs) with
Retrieval Augmented Generation (RAG) for Knowledge Graph Question Answering
(KGQA). They typically require rewriting retrieved subgraphs into natural
language formats comprehensible to LLMs. However, when tackling complex
questions, the knowledge rewritten by existing methods may include irrelevant
information, omit crucial details, or fail to align with the question's
semantics. To address them, we propose a novel rewriting method CoTKR,
Chain-of-Thought Enhanced Knowledge Rewriting, for generating reasoning traces
and corresponding knowledge in an interleaved manner, thereby mitigating the
limitations of single-step knowledge rewriting. Additionally, to bridge the
preference gap between the knowledge rewriter and the question answering (QA)
model, we propose a training strategy PAQAF, Preference Alignment from Question
Answering Feedback, for leveraging feedback from the QA model to further
optimize the knowledge rewriter. We conduct experiments using various LLMs
across several KGQA benchmarks. Experimental results demonstrate that, compared
with previous knowledge rewriting methods, CoTKR generates the most beneficial
knowledge representation for QA models, which significantly improves the
performance of LLMs in KGQA.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂Êé¢Á¥¢‰∫ÜÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÊ™¢Á¥¢Êì¥Â¢ûÁîüÊàê (RAG) ÁµêÂêàÁî®ÊñºÁü•Ë≠òÂúñË°®ÂïèÁ≠î (KGQA)„ÄÇÂÆÉÂÄëÈÄöÂ∏∏ÈúÄË¶ÅÂ∞áÊ™¢Á¥¢Âà∞ÁöÑÂ≠êÂúñÊîπÂØ´Êàê LLM ÂèØ‰ª•ÁêÜËß£ÁöÑËá™ÁÑ∂Ë™ûË®ÄÊ†ºÂºè„ÄÇÁÑ∂ËÄåÔºåÂú®ËôïÁêÜË§áÈõúÂïèÈ°åÊôÇÔºåÁèæÊúâÊñπÊ≥ïÊîπÂØ´ÁöÑÁü•Ë≠òÂèØËÉΩÂåÖÂê´‰∏çÁõ∏ÈóúÁöÑË≥áË®ä„ÄÅÈÅ∫ÊºèÈóúÈçµÁ¥∞ÁØÄÔºåÊàñÁÑ°Ê≥ïËàáÂïèÈ°åÁöÑË™ûÁæ©Â∞çÈΩä„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊîπÂØ´ÊñπÊ≥ï CoTKRÔºåÂç≥Âü∫ÊñºÊÄùËÄÉÈèàÁöÑÁü•Ë≠òÂ¢ûÂº∑ÊîπÂØ´ÔºåÁî®Êñº‰∫§ÈåØÁîüÊàêÊé®ÁêÜËªåË∑°ÂíåÂ∞çÊáâÁöÑÁü•Ë≠òÔºåÂæûËÄåÊ∏õËºïÂñÆÊ≠•Áü•Ë≠òÊîπÂØ´ÁöÑÈôêÂà∂„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÂΩåÂêàÁü•Ë≠òÊîπÂØ´Âô®ÂíåÂïèÁ≠î (QA) Ê®°Âûã‰πãÈñìÁöÑÂÅèÂ•ΩÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË®ìÁ∑¥Á≠ñÁï• PAQAFÔºåÂç≥Âü∫ÊñºÂïèÁ≠îÂõûÈ•ãÁöÑÂÅèÂ•ΩÂ∞çÈΩäÔºåÁî®ÊñºÂà©Áî® QA Ê®°ÂûãÁöÑÂõûÈ•ãÈÄ≤‰∏ÄÊ≠•ÊúÄ‰Ω≥ÂåñÁü•Ë≠òÊîπÂØ´Âô®„ÄÇÊàëÂÄë‰ΩøÁî®ÂêÑÁ®Æ LLM Âú®Â§öÂÄã KGQA Âü∫Ê∫ñ‰∏äÈÄ≤Ë°å‰∫ÜÂØ¶È©ó„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÂÖàÂâçÁöÑÁü•Ë≠òÊîπÂØ´ÊñπÊ≥ïÁõ∏ÊØîÔºåCoTKR ÁÇ∫ QA Ê®°ÂûãÁîüÊàê‰∫ÜÊúÄÊúâÁõäÁöÑÁü•Ë≠òË°®Á§∫ÔºåÈÄôÈ°ØËëóÊèêÈ´ò‰∫Ü LLM Âú® KGQA ‰∏≠ÁöÑÊïàËÉΩ„ÄÇ

##### **Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models**
2409.19667v1 by Xin Li, Weize Chen, Qizhi Chu, Haopeng Li, Zhaojun Sun, Ran Li, Chen Qian, Yiwei Wei, Zhiyuan Liu, Chuan Shi, Maosong Sun, Cheng Yang

The need to analyze graphs is ubiquitous across various fields, from social
networks to biological research and recommendation systems. Therefore, enabling
the ability of large language models (LLMs) to process graphs is an important
step toward more advanced general intelligence. However, current LLM benchmarks
on graph analysis require models to directly reason over the prompts describing
graph topology, and are thus limited to small graphs with only a few dozens of
nodes. In contrast, human experts typically write programs based on popular
libraries for task solving, and can thus handle graphs with different scales.
To this end, a question naturally arises: can LLMs analyze graphs like
professionals? In this paper, we introduce ProGraph, a manually crafted
benchmark containing 3 categories of graph tasks. The benchmark expects
solutions based on programming instead of directly reasoning over raw inputs.
Our findings reveal that the performance of current LLMs is unsatisfactory,
with the best model achieving only 36% accuracy. To bridge this gap, we propose
LLM4Graph datasets, which include crawled documents and auto-generated codes
based on 6 widely used graph libraries. By augmenting closed-source LLMs with
document retrieval and fine-tuning open-source ones on the codes, we show
11-32% absolute improvements in their accuracies. Our results underscore that
the capabilities of LLMs in handling structured data are still under-explored,
and show the effectiveness of LLM4Graph in enhancing LLMs' proficiency of graph
analysis. The benchmark, datasets and enhanced open-source models are available
at https://github.com/BUPT-GAMMA/ProGraph.

ÊëòË¶ÅÔºö<paragraph>Âú®ÂæûÁ§æ‰∫§Á∂≤Ë∑ØÂà∞ÁîüÁâ©Á†îÁ©∂ÂíåÊé®Ëñ¶Á≥ªÁµ±ÁöÑÂêÑÁ®ÆÈ†òÂüü‰∏≠ÔºåÂàÜÊûêÂúñÂΩ¢ÁöÑÈúÄÊ±ÇÁÑ°Ëôï‰∏çÂú®„ÄÇÂõ†Ê≠§ÔºåË≥¶‰∫àÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËôïÁêÜÂúñÂΩ¢ÁöÑËÉΩÂäõÔºåÊòØÈÇÅÂêëÊõ¥ÂÖàÈÄ≤ÁöÑÈÄöÁî®Êô∫ÊÖßÁöÑÈáçË¶Å‰∏ÄÊ≠•„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÂúñÂΩ¢ÂàÜÊûê‰∏äÁöÑ LLM Âü∫Ê∫ñË¶ÅÊ±ÇÊ®°ÂûãÁõ¥Êé•Â∞çÊèèËø∞ÂúñÂΩ¢ÊãìÊí≤ÁµêÊßãÁöÑÊèêÁ§∫ÈÄ≤Ë°åÊé®ÁêÜÔºåÂõ†Ê≠§ÂÉÖÈôêÊñºÂè™ÊúâÊï∏ÂçÅÂÄãÁØÄÈªûÁöÑÂ∞èÂûãÂúñÂΩ¢„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºå‰∫∫È°ûÂ∞àÂÆ∂ÈÄöÂ∏∏ÊúÉÊ†πÊìöÊµÅË°åÁöÑÂáΩÂºèÂ∫´Êí∞ÂØ´Á®ãÂºè‰æÜËß£Ê±∫‰ªªÂãôÔºåÂõ†Ê≠§ÂèØ‰ª•ËôïÁêÜ‰∏çÂêåË¶èÊ®°ÁöÑÂúñÂΩ¢„ÄÇÁÇ∫Ê≠§ÔºåËá™ÁÑ∂ÊúÉÁî¢Áîü‰∏ÄÂÄãÂïèÈ°åÔºöLLM ËÉΩÂÉèÂ∞àÊ•≠‰∫∫Â£´‰∏ÄÊ®£ÂàÜÊûêÂúñÂΩ¢ÂóéÔºüÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π ProGraphÔºå‰∏ÄÂÄãÂåÖÂê´ 3 È°ûÂúñÂΩ¢‰ªªÂãôÁöÑÊâãÂ∑•Ë£Ω‰ΩúÂü∫Ê∫ñ„ÄÇË©≤Âü∫Ê∫ñÈ†êÊúüËß£Ê±∫ÊñπÊ°àÊòØÂü∫ÊñºÁ®ãÂºèË®≠Ë®àÔºåËÄå‰∏çÊòØÁõ¥Êé•Â∞çÂéüÂßãËº∏ÂÖ•ÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈ°ØÁ§∫ÔºåÁõÆÂâç LLM ÁöÑÊïàËÉΩ‰∏¶‰∏ç‰ª§‰∫∫ÊªøÊÑèÔºåÊúÄ‰Ω≥Ê®°ÂûãÂÉÖÈÅîÂà∞ 36% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LLM4Graph Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Ê†πÊìö 6 ÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑÂúñÂΩ¢ÂáΩÂºèÂ∫´Áà¨ÂèñÁöÑÁöÑÊñá‰ª∂ÂíåËá™ÂãïÁîüÊàêÁöÑÁ®ãÂºèÁ¢º„ÄÇÈÄèÈÅé‰ΩøÁî®Êñá‰ª∂Ê™¢Á¥¢‰æÜÊì¥ÂÖÖÈñâÊ∫ê LLMÔºå‰∏¶ÈáùÂ∞çÁ®ãÂºèÁ¢ºÂæÆË™øÈñãÊ∫ê LLMÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊ∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 11-32%„ÄÇÊàëÂÄëÁöÑÁµêÊûúÂº∑Ë™øÔºåLLM Âú®ËôïÁêÜÁµêÊßãÂåñË≥áÊñôÊñπÈù¢ÁöÑËÉΩÂäõ‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢Ôºå‰∏¶È°ØÁ§∫‰∫Ü LLM4Graph Âú®ÊèêÂçá LLM ÂúñÂΩ¢ÂàÜÊûêËÉΩÂäõÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÂü∫Ê∫ñ„ÄÅË≥áÊñôÈõÜÂíåÂ¢ûÂº∑ÁöÑÈñãÊ∫êÊ®°ÂûãÂèØÂú® https://github.com/BUPT-GAMMA/ProGraph ÂèñÂæó„ÄÇ</paragraph>

##### **Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs**
2409.19401v1 by Zheng Wang, Zhongyang Li, Zeren Jiang, Dandan Tu, Wei Shi

In the age of mobile internet, user data, often referred to as memories, is
continuously generated on personal devices. Effectively managing and utilizing
this data to deliver services to users is a compelling research topic. In this
paper, we introduce a novel task of crafting personalized agents powered by
large language models (LLMs), which utilize a user's smartphone memories to
enhance downstream applications with advanced LLM capabilities. To achieve this
goal, we introduce EMG-RAG, a solution that combines Retrieval-Augmented
Generation (RAG) techniques with an Editable Memory Graph (EMG). This approach
is further optimized using Reinforcement Learning to address three distinct
challenges: data collection, editability, and selectability. Extensive
experiments on a real-world dataset validate the effectiveness of EMG-RAG,
achieving an improvement of approximately 10% over the best existing approach.
Additionally, the personalized agents have been transferred into a real
smartphone AI assistant, which leads to enhanced usability.

ÊëòË¶ÅÔºöÂú®Ë°åÂãïÁ∂≤Ë∑ØÊôÇ‰ª£Ôºå‰ΩøÁî®ËÄÖË≥áÊñôÔºàÂ∏∏Á®±ÁÇ∫Ë®òÊÜ∂ÔºâÊúÉÊåÅÁ∫åÂú®ÂÄã‰∫∫Ë£ùÁΩÆ‰∏äÁî¢Áîü„ÄÇÊúâÊïàÁÆ°ÁêÜ‰∏¶Âà©Áî®ÈÄô‰∫õË≥áÊñôÔºåÁÇ∫‰ΩøÁî®ËÄÖÊèê‰æõÊúçÂãôÔºåÊòØ‰∏ÄÂÄãÂºï‰∫∫ÂÖ•ÂãùÁöÑÁ†îÁ©∂‰∏ªÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÈ†ÖÂâµÊñ∞ÁöÑ‰ªªÂãôÔºåÂç≥Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊâìÈÄ†ÂÄã‰∫∫Âåñ‰ª£ÁêÜÔºåÂà©Áî®‰ΩøÁî®ËÄÖÁöÑÊô∫ÊÖßÂûãÊâãÊ©üË®òÊÜ∂È´îÔºå‰ª•ÈÄ≤Èöé LLM ÂäüËÉΩÂº∑Âåñ‰∏ãÊ∏∏ÊáâÁî®Á®ãÂºè„ÄÇÁÇ∫‰∫ÜÈÅîÊàêÈÄôÂÄãÁõÆÊ®ôÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü EMG-RAGÔºå‰∏ÄÁ®ÆÁµêÂêàÊ™¢Á¥¢Êì¥ÂÖÖÁîüÊàêÔºàRAGÔºâÊäÄË°ìËàáÂèØÁ∑®ËºØË®òÊÜ∂ÂúñÔºàEMGÔºâÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéÂº∑ÂåñÂ≠∏ÁøíÈÄ≤Ë°åÊúÄ‰Ω≥ÂåñÔºå‰ª•Ëß£Ê±∫‰∏âÂÄã‰∏çÂêåÁöÑÊåëÊà∞ÔºöË≥áÊñôÊî∂ÈõÜ„ÄÅÂèØÁ∑®ËºØÊÄßËàáÂèØÈÅ∏ÊìáÊÄß„ÄÇÂú®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÈ©óË≠â‰∫Ü EMG-RAG ÁöÑÊúâÊïàÊÄßÔºåÊØîÁèæÊúâÊúÄ‰Ω≥ÊñπÊ≥ïÊèêÂçá‰∫ÜÁ¥Ñ 10%„ÄÇÊ≠§Â§ñÔºåÂÄã‰∫∫Âåñ‰ª£ÁêÜÂ∑≤ËΩâÁßªÂà∞ÁúüÊ≠£ÁöÑÊô∫ÊÖßÂûãÊâãÊ©ü AI Âä©ÁêÜ‰∏≠ÔºåÈÄôÊèêÂçá‰∫ÜÂèØÁî®ÊÄß„ÄÇ

##### **CLLMate: A Multimodal LLM for Weather and Climate Events Forecasting**
2409.19058v1 by Haobo Li, Zhaowei Wang, Jiachen Wang, Alexis Kai Hon Lau, Huamin Qu

Forecasting weather and climate events is crucial for making appropriate
measures to mitigate environmental hazards and minimize associated losses.
Previous research on environmental forecasting focuses on predicting numerical
meteorological variables related to closed-set events rather than forecasting
open-set events directly, which limits the comprehensiveness of event
forecasting. We propose Weather and Climate Event Forecasting (WCEF), a new
task that leverages meteorological raster data and textual event data to
predict potential weather and climate events. However, due to difficulties in
aligning multimodal data and the lack of sufficient supervised datasets, this
task is challenging to accomplish. Therefore, we first propose a framework to
align historical meteorological data with past weather and climate events using
the large language model (LLM). In this framework, we construct a knowledge
graph by using LLM to extract information about weather and climate events from
a corpus of over 41k highly environment-focused news articles. Subsequently, we
mapped these events with meteorological raster data, creating a supervised
dataset, which is the largest and most novel for LLM tuning on the WCEF task.
Finally, we introduced our aligned models, CLLMate (LLM for climate), a
multimodal LLM to forecast weather and climate events using meteorological
raster data. In evaluating CLLMate, we conducted extensive experiments. The
results indicate that CLLMate surpasses both the baselines and other multimodal
LLMs, showcasing the potential of utilizing LLM to align weather and climate
events with meteorological data and highlighting the promising future for
research on the WCEF task.

ÊëòË¶ÅÔºöÈ†êÊ∏¨Â§©Ê∞£ÂíåÊ∞£ÂÄô‰∫ã‰ª∂Â∞çÊñºÊé°ÂèñÈÅ©Áï∂Êé™ÊñΩÊ∏õËºïÁí∞Â¢ÉÂç±ÂÆ≥ÂíåÂ∞áÁõ∏ÈóúÊêçÂ§±ÈôçËá≥ÊúÄ‰ΩéËá≥ÈóúÈáçË¶Å„ÄÇ
ÂÖàÂâçÊúâÈóúÁí∞Â¢ÉÈ†êÊ∏¨ÁöÑÁ†îÁ©∂ËëóÈáçÊñºÈ†êÊ∏¨ËàáÂ∞ÅÈñâÈõÜ‰∫ã‰ª∂Áõ∏ÈóúÁöÑÊï∏ÂÄºÊ∞£Ë±°ËÆäÊï∏ÔºåËÄåÈùûÁõ¥Êé•È†êÊ∏¨ÈñãÊîæÈõÜ‰∫ã‰ª∂ÔºåÈÄôÈôêÂà∂‰∫Ü‰∫ã‰ª∂È†êÊ∏¨ÁöÑÂÖ®Èù¢ÊÄß„ÄÇ
ÊàëÂÄëÊèêÂá∫Â§©Ê∞£ÂíåÊ∞£ÂÄô‰∫ã‰ª∂È†êÊ∏¨ (WCEF)ÔºåÈÄôÊòØ‰∏ÄÈ†ÖÂà©Áî®Ê∞£Ë±°ÊüµÊ†ºË≥áÊñôÂíåÊñáÂ≠ó‰∫ã‰ª∂Ë≥áÊñô‰æÜÈ†êÊ∏¨ÊΩõÂú®Â§©Ê∞£ÂíåÊ∞£ÂÄô‰∫ã‰ª∂ÁöÑÊñ∞‰ªªÂãô„ÄÇ
ÁÑ∂ËÄåÔºåÁî±ÊñºÂ§öÊ®°ÊÖãË≥áÊñôÂ∞çÈΩäÁöÑÂõ∞Èõ£‰ª•ÂèäÁº∫‰πèË∂≥Â§†ÁöÑÁõ£Áù£ÂºèË≥áÊñôÈõÜÔºåÂõ†Ê≠§Ê≠§‰ªªÂãôÈõ£‰ª•ÈÅîÊàê„ÄÇ
Âõ†Ê≠§ÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫‰∏ÄÂÄãÊû∂ÊßãÔºå‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞áÊ≠∑Âè≤Ê∞£Ë±°Ë≥áÊñôËàáÈÅéÂéªÁöÑÂ§©Ê∞£ÂíåÊ∞£ÂÄô‰∫ã‰ª∂Â∞çÈΩä„ÄÇ
Âú®Ê≠§Êû∂Êßã‰∏≠ÔºåÊàëÂÄëÈÄèÈÅé‰ΩøÁî® LLM ÂæûË∂ÖÈÅé 41,000 ÁØáÈ´òÂ∫¶ÈóúÊ≥®Áí∞Â¢ÉÁöÑÊñ∞ËÅûÊñáÁ´†‰∏≠Êì∑ÂèñÊúâÈóúÂ§©Ê∞£ÂíåÊ∞£ÂÄô‰∫ã‰ª∂ÁöÑË≥áË®ä‰æÜÂª∫ÊßãÁü•Ë≠òÂúñË≠ú„ÄÇ
Èö®ÂæåÔºåÊàëÂÄëÂ∞áÈÄô‰∫õ‰∫ã‰ª∂Â∞çÊáâÂà∞Ê∞£Ë±°ÊüµÊ†ºË≥áÊñôÔºåÂª∫Á´ã‰∏ÄÂÄãÁõ£Áù£ÂºèË≥áÊñôÈõÜÔºåÈÄôÊòØ LLM Âú® WCEF ‰ªªÂãô‰∏äË™øÊï¥‰∏≠ÊúÄÂ§ß‰∏îÊúÄÊñ∞Á©éÁöÑË≥áÊñôÈõÜ„ÄÇ
ÊúÄÂæåÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÊàëÂÄëÁöÑÂ∞çÈΩäÊ®°ÂûãÔºåCLLMateÔºàÊ∞£ÂÄôÁöÑ LLMÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öÊ®°ÊÖã LLMÔºå‰ΩøÁî®Ê∞£Ë±°ÊüµÊ†ºË≥áÊñô‰æÜÈ†êÊ∏¨Â§©Ê∞£ÂíåÊ∞£ÂÄô‰∫ã‰ª∂„ÄÇ
Âú®Ë©ï‰º∞ CLLMate ÊôÇÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂ§ßÈáèÁöÑÂØ¶È©ó„ÄÇ
ÁµêÊûúË°®ÊòéÔºåCLLMate Ë∂ÖË∂ä‰∫ÜÂü∫Ê∫ñÂíåÂÖ∂‰ªñÁöÑÂ§öÊ®°ÊÖã LLMÔºåÂ±ïÁ§∫‰∫ÜÂà©Áî® LLM Â∞áÂ§©Ê∞£ÂíåÊ∞£ÂÄô‰∫ã‰ª∂ËàáÊ∞£Ë±°Ë≥áÊñôÂ∞çÈΩäÁöÑÊΩõÂäõÔºå‰∏¶Âº∑Ë™ø‰∫Ü WCEF ‰ªªÂãôÁ†îÁ©∂ÁöÑÊú™‰æÜÂâçÊôØ„ÄÇ

##### **AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**
2409.18924v2 by Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Themistocles L. Assimes, Xin Ma, Danielle S. Bitterman, Lin Lu, Lizhou Fan

Simulated patient systems play a crucial role in modern medical education and
research, providing safe, integrative learning environments and enabling
clinical decision-making simulations. Large Language Models (LLM) could advance
simulated patient systems by replicating medical conditions and patient-doctor
interactions with high fidelity and low cost. However, ensuring the
effectiveness and trustworthiness of these systems remains a challenge, as they
require a large, diverse, and precise patient knowledgebase, along with a
robust and stable knowledge diffusion to users. Here, we developed AIPatient,
an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient
KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning
RAG) agentic workflow as the generation backbone. AIPatient KG samples data
from Electronic Health Records (EHRs) in the Medical Information Mart for
Intensive Care (MIMIC)-III database, producing a clinically diverse and
relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).
Reasoning RAG leverages six LLM powered agents spanning tasks including
retrieval, KG query generation, abstraction, checker, rewrite, and
summarization. This agentic framework reaches an overall accuracy of 94.15% in
EHR-based medical Question Answering (QA), outperforming benchmarks that use
either no agent or only partial agent integration. Our system also presents
high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade
5.6), robustness (ANOVA F-value 0.6126, p>0.1), and stability (ANOVA F-value
0.782, p>0.1). The promising performance of the AIPatient system highlights its
potential to support a wide range of applications, including medical education,
model evaluation, and system integration.

ÊëòË¶ÅÔºöÊ®°Êì¨ÁóÖ‰∫∫Á≥ªÁµ±Âú®Áèæ‰ª£ÈÜ´Â≠∏ÊïôËÇ≤ÂíåÁ†îÁ©∂‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÊèê‰æõÂÆâÂÖ®„ÄÅÊï¥ÂêàÁöÑÂ≠∏ÁøíÁí∞Â¢ÉÔºå‰∏¶ËÉΩÈÄ≤Ë°åËá®Â∫äÊ±∫Á≠ñÊ®°Êì¨„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÈÄèÈÅéÈ´ò‰øùÁúüÂ∫¶Âíå‰ΩéÊàêÊú¨Ë§áË£ΩÈÜ´ÁôÇÁãÄÊ≥ÅÂíåÈÜ´ÁóÖ‰∫íÂãïÔºåÈÄ≤ËÄåÊèêÂçáÊ®°Êì¨ÁóÖ‰∫∫Á≥ªÁµ±„ÄÇÁÑ∂ËÄåÔºåÁ¢∫‰øùÈÄô‰∫õÁ≥ªÁµ±ÁöÑÊúâÊïàÊÄßÂíåÂèØ‰ø°Â∫¶‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÊåëÊà∞ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÈúÄË¶Å‰∏ÄÂÄãÈæêÂ§ß„ÄÅÂ§öÂÖÉ‰∏îÁ≤æÁ¢∫ÁöÑÁóÖ‰∫∫Áü•Ë≠òÂ∫´Ôºå‰ª•ÂèäÁ©©ÂÅ•‰∏îÁ©©ÂÆöÁöÑÁü•Ë≠òÂÇ≥Êí≠Áµ¶‰ΩøÁî®ËÄÖ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÈñãÁôº‰∫Ü AIPatientÔºå‰∏ÄÂÄãÈÄ≤ÈöéÁöÑÊ®°Êì¨ÁóÖ‰∫∫Á≥ªÁµ±Ôºå‰ª• AIPatient Áü•Ë≠òÂúñË≠ú (AIPatient KG) ‰ΩúÁÇ∫Ëº∏ÂÖ•Ôºå‰∏¶‰ª•Êé®ÁêÜÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (Reasoning RAG) ‰ª£ÁêÜÂ∑•‰ΩúÊµÅÁ®ã‰ΩúÁÇ∫ÁîüÊàê‰∏ªÂππ„ÄÇAIPatient KG ÂæûÈáçÁóáÁõ£Ë≠∑ÈÜ´Â≠∏Ë≥áË®ä‰∏≠ÂøÉ (MIMIC)-III Ë≥áÊñôÂ∫´‰∏≠ÁöÑÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰∏≠ÊäΩÂèñË≥áÊñôÔºåÁî¢Áîü‰∏ÄÂÄãËá®Â∫äÂ§öÊ®£‰∏îÁõ∏ÈóúÁöÑ 1,495 ÂêçÁóÖÊÇ£Áæ§ÁµÑÔºåÂÖ∑ÊúâÂæàÈ´òÁöÑÁü•Ë≠òÂ∫´ÊïàÂ∫¶ (F1 0.89)„ÄÇÊé®ÁêÜ RAG ÊßìÊ°ø‰∫ÜÂÖ≠ÂÄã LLM È©ÖÂãïÁöÑ‰ª£ÁêÜÔºåË∑®Ë∂äÊ™¢Á¥¢„ÄÅKG Êü•Ë©¢Áî¢Áîü„ÄÅÊäΩË±°„ÄÅÊ™¢Êü•Âô®„ÄÅÈáçÂØ´ÂíåÊëòË¶ÅÁ≠â‰ªªÂãô„ÄÇÈÄôÂÄã‰ª£ÁêÜÊ°ÜÊû∂Âú®Âü∫Êñº EHR ÁöÑÈÜ´ÁôÇÂïèÁ≠î (QA) ‰∏≠ÈÅîÂà∞‰∫Ü 94.15% ÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶ÔºåÂÑ™Êñº‰∏ç‰ΩøÁî®‰ª£ÁêÜÊàñÂÉÖÈÉ®ÂàÜ‰ª£ÁêÜÊï¥ÂêàÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±ÈÇÑÂÖ∑ÊúâÂæàÈ´òÁöÑÂèØËÆÄÊÄß (Flesch Èñ±ËÆÄÁ∞°‰æøÊÄß‰∏≠‰ΩçÊï∏ 77.23ÔºõFlesch Kincaid Á≠âÁ¥ö‰∏≠‰ΩçÊï∏ 5.6)„ÄÅÁ©©ÂÅ•ÊÄß (ANOVA F ÂÄº 0.6126Ôºåp>0.1) ÂíåÁ©©ÂÆöÊÄß (ANOVA F ÂÄº 0.782Ôºåp>0.1)„ÄÇAIPatient Á≥ªÁµ±ÁöÑÂá∫Ëâ≤Ë°®ÁèæÁ™ÅÈ°Ø‰∫ÜÂÆÉÂú®ÊîØÊè¥ÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÁöÑÊΩõÂäõÔºåÂåÖÊã¨ÈÜ´Â≠∏ÊïôËÇ≤„ÄÅÊ®°ÂûãË©ï‰º∞ÂíåÁ≥ªÁµ±Êï¥Âêà„ÄÇ


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|null|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v2](http://arxiv.org/abs/2409.12087v2)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Œ¥-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajƒÖc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Mir√≥-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|S√©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timoth√©e Schmude et.al.|[2401.13324v5](http://arxiv.org/abs/2401.13324v5)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. Garc√≠a-G√≥mez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|

#### Abstracts
##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

ÊëòË¶ÅÔºöÈ´òÈÄöÈáèÊäÄË°ìÁöÑÈÄ≤Ê≠•Â∞éËá¥ÂæûÂÇ≥Áµ±ÁöÑÂÅáË®≠È©ÖÂãïÊñπÊ≥ïËΩâËÆäÁÇ∫Ë≥áÊñôÈ©ÖÂãïÁöÑÊñπÊ≥ï„ÄÇÂ§öÁµÑÂ≠∏ÊòØÊåáÊï¥ÂêàÂàÜÊûê‰æÜËá™Â§öÂÄã„ÄåÁµÑÂ≠∏„ÄçÁöÑË≥áÊñôÔºå‰æãÂ¶ÇÂü∫Âõ†ÁµÑÂ≠∏„ÄÅËõãÁôΩË≥™ÁµÑÂ≠∏„ÄÅËΩâÈåÑÁµÑÂ≠∏„ÄÅ‰ª£Ë¨ùÁµÑÂ≠∏ÂíåÂæÆÁîüÁâ©ÁµÑÂ≠∏„ÄÇÊ≠§ÊñπÊ≥ïÈÄèÈÅéÊì∑ÂèñÁîüÁâ©Ë≥áË®äÁöÑ‰∏çÂêåÂ±§Èù¢ÔºåËÉΩÂÖ®Èù¢‰∫ÜËß£ÁîüÁâ©Á≥ªÁµ±„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÊÑà‰æÜÊÑàÂ∏∏Ë¢´Áî®ÊñºÊï¥ÂêàÂ§öÁµÑÂ≠∏Ë≥áÊñôÔºåÊèê‰æõÂàÜÂ≠ê‰∫§‰∫í‰ΩúÁî®ÁöÑÊ¥ûÂØüÂäõÔºå‰∏¶Âä†Âº∑Â∞çË§áÈõúÁñæÁóÖÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂÖ∑ÊúâË®±Â§öÁõ∏‰∫íÈÄ£Êé•ÁöÑÂ±§Á¥öÂíåÈùûÁ∑öÊÄßÈóú‰øÇÔºåÈÄöÂ∏∏ÊúÉÂÉèÈªëÁõíÂ≠ê‰∏ÄÊ®£ÈÅã‰ΩúÔºåÁº∫‰πèÊ±∫Á≠ñÈÅéÁ®ãÁöÑÈÄèÊòéÂ∫¶„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÊ≠§ÊåëÊà∞ÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (xAI) ÊñπÊ≥ïÂ∞çÊñºÂª∫Á´ãÈÄèÊòéÊ®°ÂûãËá≥ÈóúÈáçË¶ÅÔºåËÆìËá®Â∫äÈÜ´ÁîüÂèØ‰ª•Êõ¥ÊúâÊïàÂú∞Ëß£ÈáãÂíåËôïÁêÜË§áÈõúË≥áÊñô„ÄÇÊ≠§Ë©ïË´ñÊé¢Ë®é xAI Â¶Ç‰ΩïËÉΩÊîπÂñÑÂ§öÁµÑÂ≠∏Á†îÁ©∂‰∏≠Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºåÂº∑Ë™øÂÖ∂Êèê‰æõËá®Â∫äÈÜ´ÁîüÊòéÁ¢∫Ë¶ãËß£ÁöÑÊΩõÂäõÔºåÈÄ≤ËÄå‰øÉÈÄ≤Ê≠§È°ûÊ®°ÂûãÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊúâÊïàÊáâÁî®„ÄÇ

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Gei√üler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∞çÊñºÂª∫ÊßãÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÈ©ÖÂãïÊáâÁî®Á®ãÂºèËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇË®∫Êñ∑ÊàñËá™ÂãïÈßïÈßõÁ≠âÈóúÈçµÈ†òÂüü„ÄÇÊ≥ïÂæã„ÄÅÂïÜÊ•≠ÂíåÂÄ´ÁêÜË¶ÅÊ±Ç‰øÉ‰Ωø‰ΩøÁî®ÊúâÊïàÁöÑ XAIÔºå‰ΩÜÊï∏ÈáèÊó•ÁõäÂ¢ûÂä†ÁöÑ‰∏çÂêåÊñπÊ≥ï‰ΩøÂæóÊåëÈÅ∏Ê≠£Á¢∫ÁöÑÊñπÊ≥ïÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºËß£ÈáãÈ´òÂ∫¶‰æùË≥¥ÊñºËÉåÊôØÔºåÂú®Ê≤íÊúâ‰ΩøÁî®ËÄÖÁöÑÊÉÖÊ≥Å‰∏ãË°°Èáè XAI ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂè™ËÉΩÊè≠Á§∫ÊúâÈôêÁöÑË≥áË®äÔºåÊéíÈô§‰∫∫È°ûÂõ†Á¥†Ôºå‰æãÂ¶ÇÁêÜËß£ÂÆÉÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂª∫Ë≠∞ÈÄèÈÅé‰ΩøÁî®ËÄÖÊàêÂäüÂü∑Ë°å‰ª£ÁêÜ‰ªªÂãôÁöÑËÉΩÂäõ‰æÜË©ï‰º∞ XAI ÊñπÊ≥ïÔºåË®≠Ë®à‰ΩøÂæóËâØÂ•ΩÁöÑÂü∑Ë°åË°®ÁèæÊòØËß£ÈáãÊèê‰æõÊúâÁî®Ë≥áË®äÁöÑÊåáÊ®ô„ÄÇÊèõÂè•Ë©±Ë™™ÔºåÊàëÂÄëÊé¢Ë®é XAI Â∞ç‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂπ´Âä©„ÄÇÊ≠§Â§ñÔºåÂ∞çÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÈÄ≤Ë°å‰ΩøÁî®ËÄÖÁ†îÁ©∂ÔºåÈ°ØÁ§∫Âá∫ÂÆÉÂÄëÂú®Áî¢Áîü‰ø°‰ªªÂíåÊá∑ÁñëÁöÑËÉΩÂäõ‰ª•ÂèäÊ≠£Á¢∫Âà§Êñ∑ AI Ê±∫Á≠ñÊòØÂê¶Ê≠£Á¢∫ÁöÑËÉΩÂäõÊñπÈù¢Â≠òÂú®Â∑ÆÁï∞„ÄÇÊ†πÊìöÁµêÊûúÔºåÊàëÂÄëÂº∑ÁÉàÂª∫Ë≠∞‰ΩøÁî®ÂíåÊì¥ÂÖÖÈÄôÁ®ÆÊñπÊ≥ïÔºå‰ª•ÈÄ≤Ë°åÊõ¥Â§ö‰ª•ÁõÆÊ®ôÁÇ∫Âü∫Á§éÁöÑ‰∫∫ÁÇ∫‰∏≠ÂøÉ‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•ÁµÇÁ´ØÂà∞ÁµÇÁ´ØÁöÑÊñπÂºèË°°Èáè XAI ÊïàËÉΩ„ÄÇ

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

ÊëòË¶ÅÔºöÁî¢Á®ã‰∏≠È¢®Èö™ÁöÑÊó©ÊúüÂÅµÊ∏¨ÊúâÂä©ÊñºÈÄ≤Ë°åÂπ≤È†êÊé™ÊñΩÔºå‰ª•È†êÈò≤ÊàñÊ∏õËºï‰∏çÂà©ÁöÑÁîüÁî¢ÁµêÊûúÔºå‰æãÂ¶ÇËÖ¶ÊÄßÈ∫ªÁó∫„ÄÇÁõÆÂâçÔºåÊ≤íÊúâÊ∫ñÁ¢∫ÁöÑËá™ÂãïÂåñÁ≥ªÁµ±ÂèØ‰ª•È†êÊ∏¨Ê≠§È°û‰∫ã‰ª∂Ôºå‰ª•ÂçîÂä©Ëá®Â∫äÊ±∫Á≠ñ„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩÔºåÊàëÂÄëÊèêÂá∫„ÄåÁî®ÊñºÂª∫Ê®°ÂíåËß£ÈáãÊñ∞ÁîüÂÖíÂÅ•Â∫∑ÁöÑ‰∫∫Â∑•Êô∫ÊÖß„Äç(AIMEN)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÔºåÂÆÉ‰∏çÂÉÖÂèØ‰ª•Ê†πÊìöÂ≠ïÁî¢Â©¶„ÄÅËÉéÂÖí„ÄÅÁî¢ÁßëÂíåÁî¢Á®ãÈ¢®Èö™Âõ†Á¥†È†êÊ∏¨‰∏çÂà©ÁöÑÁîüÁî¢ÁµêÊûúÔºåÈÇÑËÉΩÊèê‰æõÊ®°ÂûãÂÅöÂá∫È†êÊ∏¨ËÉåÂæåÁöÑÂéüÂõ†„ÄÇÂæåËÄÖÂèØ‰ª•Êèê‰æõË¶ãËß£ÔºåË™™ÊòéÊ®°ÂûãËº∏ÂÖ•ËÆäÊï∏‰∏≠ÁöÑÂì™‰∫õ‰øÆÊîπÂèØËÉΩÊúÉÊîπËÆäÈ†êÊ∏¨ÁµêÊûú„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî®ÈÅ©ÊáâÊÄßÂêàÊàêÊäΩÊ®£ (ADASYN) ÂíåÊ¢ù‰ª∂Ë°®Ê†ºÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (CTGAN) ‰æÜÂêàÊàêÈ°çÂ§ñÁöÑË®ìÁ∑¥Ë≥áÊñôÔºå‰ª•Ëß£Ê±∫‰∏çÂπ≥Ë°°ÂíåÂ∞èÂûãË≥áÊñôÈõÜÁöÑÊåëÊà∞„ÄÇAIMEN ‰ΩøÁî®ÂÖ®ÈÄ£Êé•Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÈõÜÂêà‰ΩúÁÇ∫ÂÖ∂ÂàÜÈ°ûÁöÑÈ™®ÂππÔºå‰∏¶ÈÄèÈÅé ADASYN Êàñ CTGAN ÊîØÊè¥Ë≥áÊñôÊì¥ÂÖÖ„ÄÇÁî± CTGAN ÊîØÊè¥ÁöÑ AIMEN Âú®ÂàÜÈ°ûÊñπÈù¢ÂÑ™ÊñºÁî± ADASYN ÊîØÊè¥ÁöÑ AIMEN„ÄÇAIMEN ÂèØ‰ª•È†êÊ∏¨‰∏çÂà©ÁöÑÁîüÁî¢ÁµêÊûúÁöÑÈ´òÈ¢®Èö™ÔºåÂπ≥Âùá F1 ÂàÜÊï∏ÁÇ∫ 0.784„ÄÇÂÆÉÈÇÑÊèê‰æõÂèç‰∫ãÂØ¶Ëß£ÈáãÔºåÂèØÈÄèÈÅéÂπ≥ÂùáËÆäÊõ¥ 2 Ëá≥ 3 ÂÄãÂ±¨ÊÄß‰æÜÈÅîÊàê„ÄÇÂèØÁî®Ë≥áÊ∫êÔºöhttps://github.com/ab9mamun/AIMEN„ÄÇ

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

ÊëòË¶ÅÔºöÈÅ∫ÂÇ≥ÊÄßË¶ñÁ∂≤ËÜúÁñæÁóÖ (IRD) ÊòØ‰∏ÄÁµÑÂ§öÊ®£ÂåñÁöÑÈÅ∫ÂÇ≥ÁñæÁóÖÔºå
ÊúÉÂ∞éËá¥Ë¶ñÂäõÈÄêÊº∏Âñ™Â§±ÔºåÊòØÂ∑•‰ΩúÂπ¥ÈΩ°Êàê‰∫∫Â§±ÊòéÁöÑ‰∏ªË¶ÅÂéüÂõ†„ÄÇIRD ÁöÑË§áÈõúÊÄßÂíåÁï∞Ë≥™ÊÄßÂ∞çË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁÆ°ÁêÜÊèêÂá∫‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÊúÄËøë‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÈÄ≤Ê≠•ÁÇ∫ÈÄô‰∫õÊåëÊà∞Êèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ
ÁÑ∂ËÄåÔºåAI ÊäÄË°ìÁöÑÂø´ÈÄüÁôºÂ±ïÂèäÂÖ∂Â§öÁ®ÆÊáâÁî®Â∞éËá¥‰∫ÜË©≤È†òÂüüÁöÑÁü•Ë≠òÂàÜÊï£„ÄÇÊú¨Á∂úËø∞Êï¥Âêà‰∫ÜÁèæÊúâÁ†îÁ©∂ÔºåÊâæÂá∫Â∑ÆË∑ùÔºå‰∏¶Ê¶ÇËø∞‰∫Ü AI Âú®Ë®∫Êñ∑ÂíåÁÆ°ÁêÜ IRD ‰∏≠ÁöÑÊΩõÂäõ„ÄÇÂÆÉÊó®Âú®ÈÄöÈÅéÊé¢Á¥¢Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÁ≠â AI ÊäÄË°ìÔºåÁâπÂà•ÊòØÂú®ÁñæÁóÖÊ™¢Ê∏¨„ÄÅÈÄ≤Á®ãÈ†êÊ∏¨ÂíåÂÄãÊÄßÂåñÊ≤ªÁôÇË®àÂäÉ‰∏≠ÔºåÁÇ∫Êé®ÈÄ≤Ëá®Â∫äÊáâÁî®ÊßãÂª∫ÈÄîÂæë„ÄÇÁâπÂà•ÈóúÊ≥®ÈÄô‰∫õÈ†òÂüü‰∏≠Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåË®éË´ñ‰∫ÜÂèØËß£Èáã AI ÁöÑÊï¥ÂêàÔºåÂº∑Ë™ø‰∫ÜÂÖ∂Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÊèêÈ´òÈÄèÊòéÂ∫¶ÂíåÂ∞çÂü∫Êñº AI ÁöÑÁ≥ªÁµ±ÁöÑ‰ø°‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇË©≤Á∂úËø∞Ëß£Ê±∫‰∫ÜÂΩåÂêà AI Âú® IRD ‰∏≠‰ΩúÁî®ÁöÑÈáçÈªûÁ†îÁ©∂‰∏≠ÁèæÊúâÂ∑ÆË∑ùÁöÑÂøÖË¶ÅÊÄßÔºåÊèê‰æõ‰∫ÜÂ∞çÁï∂Ââç AI ÊäÄË°ìÁöÑÁµêÊßãÂåñÂàÜÊûêÔºå‰∏¶Ê¶ÇËø∞‰∫ÜÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇÊúÄÂæåÊ¶ÇËø∞‰∫ÜÂú® IRD ‰∏≠ÈÉ®ÁΩ≤ AI ÁöÑÊåëÊà∞ÂíåÊ©üÈÅáÔºåÂº∑Ë™ø‰∫ÜË∑®Â≠∏ÁßëÂêà‰ΩúÂíåÊåÅÁ∫åÈñãÁôºÂº∑Â§ß„ÄÅÂèØËß£ÈáãÁöÑ AI Ê®°Âûã‰ª•Êé®ÈÄ≤Ëá®Â∫äÊáâÁî®ÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

ÊëòË¶ÅÔºöËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊ±∫Á≠ñÊòØÁèæÂú® AI ÁöÑ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞ÔºåÁâπÂà•ÊòØÊáâÁî®ÊñºÂÉèÈÜ´Â≠∏ÂíåÊ≥ïÂæãÁ≠âÊïèÊÑüÊÉÖÂ¢ÉÊôÇ„ÄÇÁÑ∂ËÄåÔºåËß£ÈáãÊ±∫Á≠ñËÉåÂæåÁêÜÁî±ÁöÑÈúÄÊ±Ç‰πüÊòØÂü∫Êñº‰∫∫È°ûÁöÑËÄÉÈáèÁöÑ‰∏ÄÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÂõ†ÁÇ∫ÊúâÂøÖË¶ÅË≠âÊòéÁÇ∫‰ªÄÈ∫ºÂÅöÂá∫ÊüêÂÄãÊ±∫Á≠ñ„ÄÇ‰æãÂ¶ÇÔºå‰ΩèÈô¢ÈÜ´Â∏´‰∏çÂÉÖÈúÄË¶ÅÊèê‰æõÔºàÂèØËÉΩÊòØÊ≠£Á¢∫ÁöÑÔºâË®∫Êñ∑ÔºåÈÇÑÈúÄË¶ÅËß£Èáã‰ªñÂÄëÂ¶Ç‰ΩïÈÅîÊàêÊüêÂÄãÁµêË´ñ„ÄÇÂõ†Ê≠§ÔºåÈñãÁôºÊñ∞ÁöÑÂ∑•ÂÖ∑‰æÜÂπ´Âä©‰ΩèÈô¢ÈÜ´Â∏´Ë®ìÁ∑¥‰ªñÂÄëÁöÑËß£ÈáãÊäÄÂ∑ßÊòØÊïôËÇ≤‰∏≠ AI ÁöÑ‰∏ÄÈ†ÖÊ†∏ÂøÉÁõÆÊ®ô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÅµÂæ™ÈÄôÂÄãÊñπÂêëÔºå‰∏¶‰∏îÊ†πÊìöÊàëÂÄëÁöÑ‰∫ÜËß£ÔºåÊèêÂá∫Á¨¨‰∏ÄÂÄãÂ§öË™ûË®ÄÈÜ´Â≠∏ÂïèÁ≠îË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠Ëá®Â∫äÁóÖ‰æãÁöÑÊ≠£Á¢∫Âíå‰∏çÊ≠£Á¢∫Ë®∫Êñ∑ÈÉΩÈôÑÊúâÁî±ÈÜ´ÁîüÊí∞ÂØ´ÁöÑËá™ÁÑ∂Ë™ûË®ÄËß£Èáã„ÄÇÈÄô‰∫õËß£ÈáãÂ∑≤‰ΩøÁî®Ë´ñË≠âÁµÑÊàêÔºàÂç≥ÂâçÊèê„ÄÅ‰∏ªÂºµÔºâÂíåË´ñË≠âÈóú‰øÇÔºàÂç≥ÊîªÊìä„ÄÅÊîØÊåÅÔºâÈÄ≤Ë°åÊâãÂãïË®ªËß£ÔºåÁî¢ÁîüÂ§öË™ûË®Ä CasiMedicos-Arg Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ 558 ÂÄãÂÖ∑ÊúâËß£ÈáãÁöÑÂõõÁ®ÆË™ûË®ÄÔºàËã±Ë™û„ÄÅË•øÁè≠ÁâôË™û„ÄÅÊ≥ïË™û„ÄÅÁæ©Â§ßÂà©Ë™ûÔºâÁöÑËá®Â∫äÁóÖ‰æãÔºåÊàëÂÄëË®ªËß£‰∫Ü 5021 ÂÄã‰∏ªÂºµ„ÄÅ2313 ÂÄãÂâçÊèê„ÄÅ2431 ÂÄãÊîØÊåÅÈóú‰øÇÂíå 1106 ÂÄãÊîªÊìäÈóú‰øÇ„ÄÇÊàëÂÄëÊúÄÂæåÂ±ïÁ§∫‰∫ÜÁ´∂Áà≠Âü∫Ê∫ñÂ¶Ç‰ΩïÈáùÂ∞çË´ñË≠âÊé¢Âãò‰ªªÂãôÂü∑Ë°åÊ≠§ÂÖ∑ÊåëÊà∞ÊÄßÁöÑË≥áÊñôÈõÜ„ÄÇ

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

ÊëòË¶ÅÔºöË®∫Êñ∑È†êÊ∏¨ÊòØÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ‰∏ÄÈ†ÖÈóúÈçµ‰ªªÂãôÔºåÂèäÊôÇ‰∏îÊ∫ñÁ¢∫Âú∞Ë≠òÂà•ÈÜ´ÁôÇÁãÄÊ≥ÅÊúÉÂ∞çÊÇ£ËÄÖÁöÑÁµêÊûúÁî¢ÁîüÈáçÂ§ßÂΩ±Èüø„ÄÇÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂ∑≤Âú®Ê≠§È†òÂüüÂèñÂæóÈ°ØËëóÊàêÂäüÔºå‰ΩÜÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºåÈÄôÊòØËá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÈóúÈçµË¶ÅÊ±Ç„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÔºåÁâπÂà•ÊòØÈÇèËºØÁ•ûÁ∂ìÁ∂≤Ë∑Ø (LNN)Ôºå‰ª•ÈñãÁôºÂèØËß£ÈáãÁöÑË®∫Êñ∑È†êÊ∏¨Ê®°Âûã„ÄÇÂü∫Êú¨‰∏äÔºåÊàëÂÄëË®≠Ë®à‰∏¶ÂØ¶‰Ωú‰∫ÜÂü∫Êñº LNN ÁöÑÊ®°ÂûãÔºåË©≤Ê®°ÂûãÈÄèÈÅéÈÇèËºØË¶èÂâáÂíåÂèØÂ≠∏ÁøíÁöÑÈñæÂÄºÊï¥ÂêàÈ†òÂüüÁâπÂÆöÁöÑÁü•Ë≠ò„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÔºåÁâπÂà•ÊòØ $M_{\text{multi-pathway}}$ Âíå $M_{\text{comprehensive}}$ÔºåË°®ÁèæÂá∫ÂÑ™ÊñºÂÇ≥Áµ±Ê®°ÂûãÔºàÂ¶ÇÈÇèËºØËø¥Ê≠∏„ÄÅSVM ÂíåÈö®Ê©üÊ£ÆÊûóÔºâÁöÑÂçìË∂äÊïàËÉΩÔºåÂú®Á≥ñÂ∞øÁóÖÈ†êÊ∏¨ÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÔºåÈÅîÂà∞‰∫ÜÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶ÔºàÈ´òÈÅî 80.52%ÔºâÂíå AUROC ÂàÜÊï∏ÔºàÈ´òÈÅî 0.8457Ôºâ„ÄÇLNN Ê®°Âûã‰∏≠Â≠∏ÁøíÁöÑÊ¨äÈáçÂíåÈñæÂÄºÊèê‰æõ‰∫ÜÂ∞çÁâπÂæµË≤¢ÁçªÁöÑÁõ¥Êé•Ë¶ãËß£ÔºåÂ¢ûÂº∑‰∫ÜÂèØËß£ÈáãÊÄßÔºåÂêåÊôÇ‰∏çÊêçÂÆ≥È†êÊ∏¨ËÉΩÂäõ„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÂú®ÂΩåÂêàÈÜ´ÁôÇ‰øùÂÅ• AI ÊáâÁî®‰∏≠Ê∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄßÂ∑ÆË∑ùÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÈÄèÈÅéÊèê‰æõÈÄèÊòé‰∏îÈÅ©ÊáâÊÄßÂº∑ÁöÑË®∫Êñ∑Ê®°ÂûãÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÊúâÂä©ÊñºÁ≤æÊ∫ñÈÜ´ÁôÇÁöÑÈÄ≤Ê≠•Ôºå‰∏¶ÊîØÊè¥ÂÖ¨Âπ≥ÈÜ´ÁôÇ‰øùÂÅ•Ëß£Ê±∫ÊñπÊ°àÁöÑÈñãÁôº„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂Â∞áÂ∞àÊ≥®ÊñºÂ∞áÈÄô‰∫õÊñπÊ≥ïÊì¥Â±ïÂà∞Êõ¥Â§ß‰∏îÊõ¥Â§öÊ®£ÂåñÁöÑË≥áÊñôÈõÜÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•È©óË≠âÂÖ∂Âú®‰∏çÂêåÈÜ´ÁôÇÁãÄÊ≥ÅÂíå‰∫∫Áæ§‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇ

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂø´ÈÄüÈÄ≤Â±ïÂæπÂ∫ïÊîπËÆä‰∫ÜÊô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•ÔºåÊé®Âãï‰∫ÜÂèØÁ©øÊà¥ÊäÄË°ì„ÄÅÊåÅÁ∫åÁõ£ÊéßË£ùÁΩÆÂíåÊô∫ÊÖßË®∫Êñ∑Á≥ªÁµ±ÁöÑÂâµÊñ∞„ÄÇÁÑ∂ËÄåÔºåÂÆâÂÖ®ÊÄß„ÄÅÂèØËß£ÈáãÊÄß„ÄÅÁ©©ÂÅ•ÊÄßÂíåÊïàËÉΩÊúÄ‰Ω≥ÂåñÊåëÊà∞‰ªçÁÑ∂ÊòØËá®Â∫äÁí∞Â¢É‰∏≠Âª£Ê≥õÊé°Áî®ÁöÑÈóúÈçµÈöúÁ§ô„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊºîÁÆóÊ≥ïÊñπÊ≥ïÔºå‰ΩøÁî®Ëá™ÈÅ©ÊáâÁâπÂæµË©ï‰º∞Âô® (AFE) ÊºîÁÆóÊ≥ï‰æÜÊîπÂñÑÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÈõÜ‰∏≠ÁöÑÁâπÂæµÈÅ∏Âèñ‰∏¶ÂÖãÊúçÂïèÈ°å„ÄÇAFE Êï¥Âêà‰∫ÜÈÅ∫ÂÇ≥ÊºîÁÆóÊ≥ï (GA)„ÄÅÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÂíåÊéíÂàóÁµÑÂêàÊäÄË°ì (PCT)ÔºåË©≤ÊºîÁÆóÊ≥ïÊúÄ‰Ω≥Âåñ‰∫ÜËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ± (CDSS)ÔºåÂæûËÄåÊèêÈ´ò‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï‰ΩøÁî®ÂÖ≠Á®Æ‰∏çÂêåÁöÑÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÈ©óË≠â‰∫Ü‰∏âÂÄã‰∏çÂêåÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÈõÜÔºåË≠âÊòé‰∫ÜÂÖ∂Á©©ÂÅ•ÊÄßÂíåÂÑ™ÊñºÂÇ≥Áµ±ÁâπÂæµÈÅ∏ÂèñÊäÄË°ì„ÄÇÁµêÊûúÂº∑Ë™ø‰∫Ü AFE Âú®Êô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑËΩâËÆäÊΩõÂäõÔºåÂØ¶Áèæ‰∫ÜÂÄã‰∫∫ÂåñÂíåÈÄèÊòéÁöÑÊÇ£ËÄÖÁÖßË≠∑„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåAFE ÊºîÁÆóÊ≥ïËàáÂ§öÂ±§ÊÑüÁü•Âô® (MLP) ÁµêÂêà‰ΩøÁî®ÊôÇÔºåÊ∫ñÁ¢∫Â∫¶È´òÈÅî 98.5%ÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂ÊîπÂñÑÂØ¶ÈöõÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÊµÅÁ®ãÁöÑËÉΩÂäõ„ÄÇ

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) Á≥ªÁµ±Â∑≤Â§ßÂπÖÊîπÂñÑÁöÆËÜöÁßëÈÜ´Â∏´Â∞çÈªëËâ≤Á¥†Áò§ÁöÑË®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÔºåËÄåÂèØËß£Èáã AI (XAI) Á≥ªÁµ±ÈÄ≤‰∏ÄÊ≠•ÊèêÂçáËá®Â∫äÈÜ´Â∏´Â∞ç AI È©ÖÂãïÊ±∫Á≠ñÁöÑ‰ø°ÂøÉËàá‰ø°Ë≥¥„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÈÄ≤Â±ïÔºåÂ∞çÊñºÁöÆËÜöÁßëÈÜ´Â∏´Â¶Ç‰Ωï‰ΩøÁî® AI Âíå XAI Â∑•ÂÖ∑Ôºå‰ªçÊúâÂÆ¢ËßÄË©ï‰º∞ÁöÑËø´ÂàáÈúÄÊ±Ç„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠Ôºå76 ‰ΩçÁöÆËÜöÁßëÈÜ´Â∏´ÂèÉËàá‰∫Ü‰∏ÄÈ†ÖËÆÄËÄÖÁ†îÁ©∂Ôºå‰ΩøÁî® XAI Á≥ªÁµ±Ë®∫Êñ∑ 16 ÂºµÈªëËâ≤Á¥†Áò§ÂíåÁó£ÁöÑÁöÆËÜöÈè°ÂΩ±ÂÉèÔºåË©≤Á≥ªÁµ±Êèê‰æõË©≥Á¥∞ÁöÑÈ†òÂüüÁâπÂÆöË™™Êòé„ÄÇÊé°Áî®ÁúºÁêÉËøΩËπ§ÊäÄË°ì‰æÜË©ï‰º∞‰ªñÂÄëÁöÑ‰∫íÂãï„ÄÇÂ∞áË®∫Êñ∑Ë°®ÁèæËàáÁº∫‰πèË™™ÊòéÂäüËÉΩÁöÑÊ®ôÊ∫ñ AI Á≥ªÁµ±ÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåXAI Á≥ªÁµ±Áõ∏ËºÉÊñºÊ®ôÊ∫ñ AIÔºåÂ∞áÂπ≥Ë°°Ë®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 2.8 ÂÄãÁôæÂàÜÈªû„ÄÇÊ≠§Â§ñÔºåËàá AI/XAI Á≥ªÁµ±ÁöÑË®∫Êñ∑ÂàÜÊ≠ßÂíåË§áÈõúÁöÑÁóÖÁÅ∂ËàáË™çÁü•Ë≤†ÊìîÂçáÈ´òÊúâÈóúÔºåÈÄôÁî±Â¢ûÂä†ÁöÑÁúºÁùõÊ≥®Ë¶ñÊ¨°Êï∏ÊâÄË≠âÂØ¶„ÄÇÈÄô‰∫õË¶ãËß£Â∞çËá®Â∫äÂØ¶Âãô„ÄÅË¶ñË¶∫‰ªªÂãô AI Â∑•ÂÖ∑ÁöÑË®≠Ë®àÂíåÈÜ´Â≠∏Ë®∫Êñ∑‰∏≠ XAI ÁöÑÂª£Ê≥õÁôºÂ±ïÂÖ∑ÊúâÈáçÂ§ßÊÑèÁæ©„ÄÇ

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

ÊëòË¶ÅÔºöËá™ÈñâÁóáË≠úÁ≥ªÈöúÁ§ô (ASD) ÁöÑÊó©ÊúüË®∫Êñ∑Âíå‰ªãÂÖ•Â∑≤Ë¢´Ë≠âÂØ¶ËÉΩÈ°ØËëóÊîπÂñÑËá™ÈñâÁóáÊÇ£ËÄÖÁöÑÁîüÊ¥ªÂìÅË≥™„ÄÇÁÑ∂ËÄåÔºåASD ÁöÑË®∫Êñ∑ÊñπÊ≥ï‰æùË≥¥ÊñºÂü∫ÊñºËá®Â∫äË°®ÁèæÁöÑË©ï‰º∞ÔºåÂÆπÊòìÁî¢ÁîüÂÅèË¶ãÔºå‰∏îÂèØËÉΩÈõ£‰ª•ÂÅöÂá∫Êó©ÊúüË®∫Êñ∑„ÄÇÊúâÂøÖË¶ÅÊâæÂá∫ ASD ÁöÑÂÆ¢ËßÄÁîüÁâ©Ê®ôË®òÔºå‰ª•Âπ´Âä©ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄß„ÄÇÊ∑±Â∫¶Â≠∏Áøí (DL) Âú®ÂæûÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôË®∫Êñ∑ÁñæÁóÖÂíåÁóÖÁóáÊñπÈù¢ÂèñÂæóÂÇëÂá∫ÁöÑË°®Áèæ„ÄÇÂ∑≤Á∂ìÈáùÂ∞çÂª∫Á´ã‰ΩøÁî®ÈùúÊÖãÂäüËÉΩÊÄßÁ£ÅÊåØÈÄ†ÂΩ± (fMRI) Ë≥áÊñôÂ∞ç ASD ÈÄ≤Ë°åÂàÜÈ°ûÁöÑÊ®°ÂûãÈÄ≤Ë°åÂª£Ê≥õÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄß„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÈÄèÈÅéÂª∫Á´ã‰∏ÄÂÄã‰∏çÂÉÖËÉΩÊ∫ñÁ¢∫ÂàÜÈ°û ASDÔºåÈÇÑËÉΩÊèê‰æõÂèØËß£ÈáãË¶ãËß£Ë™™ÊòéÂÖ∂ÈÅã‰ΩúÂéüÁêÜÁöÑ DL Ê®°ÂûãÔºå‰æÜÊîπÂñÑ ASD Ë®∫Êñ∑ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÊâÄ‰ΩøÁî®ÁöÑË≥áÊñôÈõÜÊòØËá™ÈñâÁóáÂ§ßËÖ¶ÂΩ±ÂÉèË≥áÊñô‰∫§Êèõ (ABIDE) ÁöÑÈ†êËôïÁêÜÁâàÊú¨ÔºåÂåÖÂê´ 884 ÂÄãÊ®£Êú¨„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåË©≤Ê®°ÂûãËÉΩÊ∫ñÁ¢∫ÂàÜÈ°û ASDÔºå‰∏¶Âº∑Ë™ø ASD ËàáÂÖ∏ÂûãÂ∞çÁÖßÁµÑ‰πãÈñìÂ≠òÂú®Â∑ÆÁï∞ÁöÑÈóúÈçµËÖ¶ÂçÄÔºåÂ∞çÊñº ASD ÁöÑÊó©ÊúüË®∫Êñ∑ÂíåÁ•ûÁ∂ìÂü∫Á§éÁöÑÁêÜËß£ÂÖ∑ÊúâÊΩõÂú®ÁöÑÊÑèÁæ©„ÄÇÈÄô‰∫õÁ†îÁ©∂ÁµêÊûúÂ∑≤Áî±‰ΩøÁî®‰∏çÂêåË≥áÊñôÈõÜÂíåÊñπÂºèÁöÑÊñáÁçªÁ†îÁ©∂È©óË≠âÔºåË≠âÂØ¶Ë©≤Ê®°ÂûãÂØ¶Èöõ‰∏äÂ≠∏Áøí‰∫Ü ASD ÁöÑÁâπÂæµÔºåËÄå‰∏çÂÉÖÂÉÖÊòØË≥áÊñôÈõÜ„ÄÇÊú¨Á†îÁ©∂ÈÄèÈÅéÊèê‰æõ‰∏ÄÂÄãÂº∑ÂÅ•‰∏îÂèØËß£ÈáãÁöÑÊ®°ÂûãÔºåÊé®Âãï‰∫ÜÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÂèØËß£Èáã AI ÁöÑÈ†òÂüüÔºåÂæûËÄåÁÇ∫Êú™‰æÜÊèê‰æõÂÆ¢ËßÄ‰∏îÂèØÈù†ÁöÑ ASD Ë®∫Êñ∑ÂÅöÂá∫Ë≤¢Áçª„ÄÇ

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Cl√©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

ÊëòË¶ÅÔºöÂ∞øË∑ØÈè°Ê™¢Êü•‰∏≠ËÖéÁµêÁü≥È°ûÂûãÁöÑÈ´îÂÖßË≠òÂà•Â∞áÊòØÊ≥åÂ∞øÁßëÁöÑ‰∏ÄÈ†ÖÈáçÂ§ßÈÄ≤Â±ïÔºåÂõ†ÁÇ∫ÂÆÉÂèØ‰ª•Ê∏õÂ∞ëÁπÅÁë£ÁöÑËÖéÁµêÁü≥ÂèñÂá∫ÈÅéÁ®ãÁöÑÊôÇÈñìÔºåÂêåÊôÇÈôç‰ΩéÊÑüÊüìÈ¢®Èö™„ÄÇÊ≠§Â§ñÔºåÈÄôÁ®ÆËá™ÂãïÂåñÁ®ãÂ∫èÂ∞á‰ΩøÁ´ãÂç≥ÈñãÁ´ãÊäóÂæ©ÁôºÊ≤ªÁôÇÊàêÁÇ∫ÂèØËÉΩ„ÄÇÂ¶Ç‰ªäÔºåÂè™ÊúâÂ∞ëÊï∏Á∂ìÈ©óË±êÂØåÁöÑÊ≥åÂ∞øÁßëÈÜ´ÁîüËÉΩÂ§†Âú®ÂÖßË¶ñÈè°Ê™¢Êü•ÊúüÈñìÂ±èÂπï‰∏äÈ°ØÁ§∫ÁöÑË¶ñÈ†ªÂúñÂÉè‰∏≠Ë≠òÂà•ËÖéÁµêÁü≥È°ûÂûã„ÄÇÂõ†Ê≠§ÔºåÊúÄËøëÂ∑≤ÊèêÂá∫Â§öÁ®ÆÊ∑±Â∫¶Â≠∏Áøí (DL) Ê®°ÂûãÔºå‰ª•‰ΩøÁî®Ëº∏Â∞øÁÆ°Èè°ÂúñÂÉèËá™ÂãïË≠òÂà•ËÖéÁµêÁü≥È°ûÂûã„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ DL Ê®°ÂûãÊú¨Ë≥™‰∏äÊòØÈªëÁõíÂ≠êÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊáâÁî®ÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÊ°à‰æãÊé®ÁêÜÁöÑ DL Ê®°ÂûãÔºåÂÆÉ‰ΩøÁî®ÂéüÂûãÈÉ®ÂàÜ (PP) ‰∏¶ÁîüÊàêÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄÊèèËø∞Á¨¶„ÄÇPP ÁÇ∫ÊØèÁ®ÆÈ°ûÂûãÔºàÂç≥ËÖéÁµêÁü≥È°ûÂûãÔºâÁ∑®Á¢ºË¶ñË¶∫ÁâπÂæµ‰ø°ÊÅØÔºàËâ≤Ë™ø„ÄÅÈ£ΩÂíåÂ∫¶„ÄÅÂº∑Â∫¶ÂíåÁ¥ãÁêÜÔºâÔºåÈ°û‰ººÊñºÁîüÁâ©Â≠∏ÂÆ∂‰ΩøÁî®ÁöÑ‰ø°ÊÅØ„ÄÇÁî±ÊñºÂú®Ê®°ÂûãË®ìÁ∑¥ÊúüÈñì‰ΩøÁî®ÁöÑÊñ∞ÊêçÂ§±ÂáΩÊï∏ÔºåPP ÂæóÂà∞‰∫ÜÊúÄ‰Ω≥ÁîüÊàê„ÄÇÊ≠§Â§ñÔºåPP ÁöÑÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄÊèèËø∞Á¨¶ÂÖÅË®±‰ª•ÁîüÁâ©Â≠∏ÂÆ∂ÂíåÊ≥åÂ∞øÁßëÈÜ´ÁîüÂèØ‰ª•ÁêÜËß£ÁöÑÊñπÂºèËß£ÈáãÊ±∫Á≠ñÔºà‚Äú‰ªÄÈ∫º‚Äù‰ø°ÊÅØÔºå‚ÄúÂúñÂÉè‰∏≠ÁöÑ‰ªÄÈ∫º‰ΩçÁΩÆ‚ÄùÔºâ„ÄÇÊâÄÊèêÂá∫ÁöÑ DL Ê®°ÂûãÂ∑≤Âú®‰∏ÄÂÄãÂåÖÂê´ÂÖ≠Á®ÆÊúÄÂª£Ê≥õÁöÑËÖéÁµêÁü≥È°ûÂûãÂúñÂÉèÁöÑÊï∏ÊìöÂ∫´‰∏äÈÄ≤Ë°å‰∫ÜÊ∏¨Ë©¶„ÄÇÁ∏ΩÈ´îÂπ≥ÂùáÂàÜÈ°ûÊ∫ñÁ¢∫ÁéáÁÇ∫ 90.37„ÄÇÂ∞áÊ≠§ÁµêÊûúËàáËÖéÁµêÁü≥ÊúÄÂÖàÈÄ≤ÁöÑÂÖ´ÂÄãÂÖ∂‰ªñ DL Ê®°ÂûãÁöÑÁµêÊûúÈÄ≤Ë°åÊØîËºÉÊôÇÔºåÂèØ‰ª•ÁúãÂá∫ÔºåÂèØËß£ÈáãÊÄßÁöÑÂØ∂Ë≤¥Â¢ûÁõä‰∏¶Êú™‰ª•Ê∫ñÁ¢∫ÊÄßÁÇ∫‰ª£ÂÉπÔºåÁîöËá≥Áï•ÊúâÂ¢ûÂä†ËàáÊñáÁçª‰∏≠ÊúÄÂ•ΩÁöÑÊñπÊ≥ï (88.2) Áõ∏ÊØî„ÄÇÈÄô‰∫õÊúâÂ∏åÊúõ‰∏îÂèØËß£ÈáãÁöÑÁµêÊûú‰πüÈºìÂãµÊ≥åÂ∞øÁßëÈÜ´ÁîüÁõ∏‰ø°Âü∫Êñº‰∫∫Â∑•Êô∫ËÉΩÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v2 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÂà©Áî®Ë°åÊîøÁî≥Â†±Êï∏ÊìöÁöÑÊΩõÂäõÔºåÁµêÂêàÈÄ≤ÈöéÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÔºå‰ª•È†êÊ∏¨ÊÖ¢ÊÄßËÖéËáüÁñæÁóÖ (CKD) ÈÄ≤Â±ïËá≥Êú´ÊúüËÖéËáüÁñæÁóÖ (ESRD)„ÄÇÊàëÂÄëÂàÜÊûê‰∏ÄÂÆ∂Â§ßÂûãÂÅ•Â∫∑‰øùÈö™ÁµÑÁπîÊèê‰æõÁöÑ 10 Âπ¥Á∂úÂêàÊï∏ÊìöÈõÜÔºå‰ª•ÈñãÁôº‰ΩøÁî®ÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºà‰æãÂ¶ÇÈö®Ê©üÊ£ÆÊûóÂíå XGBoostÔºâ‰ª•ÂèäÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºà‰æãÂ¶ÇÈï∑Áü≠ÊúüË®òÊÜ∂ (LSTM) Á∂≤Ë∑ØÔºâÁöÑÂ§öÂÄãËßÄÂØüÁ™óÂè£ÁöÑÈ†êÊ∏¨Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåLSTM Ê®°ÂûãÔºåÁâπÂà•ÊòØÂú® 24 ÂÄãÊúàÁöÑËßÄÂØüÁ™óÂè£‰∏≠ÔºåÂú®È†êÊ∏¨ ESRD ÈÄ≤Â±ïÊñπÈù¢Ë°®ÁèæÂÑ™Áï∞ÔºåÂÑ™ÊñºÊñáÁçª‰∏≠ÁöÑÁèæÊúâÊ®°Âûã„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊáâÁî® SHapley Additive exPlanations (SHAP) ÂàÜÊûê‰æÜÂ¢ûÂº∑ÂèØËß£ÈáãÊÄßÔºåÊèê‰æõÂ∞çÂÄãÂà•ÁâπÂæµÂ∞çÂÄãÂà•ÊÇ£ËÄÖÂ±§Á¥öÈ†êÊ∏¨ÂΩ±ÈüøÁöÑË¶ãËß£„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÂà©Áî®Ë°åÊîøÁî≥Â†±Êï∏ÊìöÈÄ≤Ë°å CKD ÁÆ°ÁêÜÂíåÈ†êÊ∏¨ ESRD ÈÄ≤Â±ïÁöÑÂÉπÂÄº„ÄÇ

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

ÊëòË¶ÅÔºöÈö®ËëóË∂ä‰æÜË∂äË§áÈõú‰∏îÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÂü∫Êñº‰∫∫Â∑•Êô∫ÊÖß (AI) Ëß£Ê±∫ÊñπÊ°àÁöÑÊèêÊ°àÂú®Ë®±Â§öÈ†òÂüü‰∏≠ËÆäÂæóÁÑ°Ëôï‰∏çÂú®„ÄÇÈö®ËëóÈÄô‰∫õÊ®°ÂûãË§áÈõúÊÄßÁöÑÂ¢ûÂä†ÔºåÈÄèÊòéÂ∫¶Âíå‰ΩøÁî®ËÄÖÁöÑÁêÜËß£ÂäõÂæÄÂæÄÊúÉÈôç‰Ωé„ÄÇÈÄôË°®Á§∫ÂÉÖÊúâÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨‰∏¶‰∏çË∂≥‰ª•ËÆì AI Ëß£Ê±∫ÊñπÊ°àÁúüÊ≠£ÊúâÁî®„ÄÇÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÈñãÁôº‰∏≠ÔºåÈÄôÂºïÂÖ•‰∫ÜËàáÂïèË≤¨Âà∂ÂíåÂÆâÂÖ®ÊÄßÁõ∏ÈóúÁöÑÊñ∞ÂïèÈ°å„ÄÇÁû≠Ëß£ AI Á≥ªÁµ±Â¶Ç‰Ωï‰ª•ÂèäÁÇ∫‰ΩïÊèêÂá∫Âª∫Ë≠∞ÂèØËÉΩÈúÄË¶ÅÂ∞çÂÖ∂ÂÖßÈÉ®ÈÅã‰ΩúÂíåÊé®ÁêÜÈÅéÁ®ãÈÄ≤Ë°åË§áÈõúÁöÑË™™Êòé„ÄÇÂÑòÁÆ°ËøëÂπ¥‰æÜÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂Â∑≤Â§ßÂπÖÂ¢ûÂä†Ôºå‰∏îÈÜ´Â≠∏È†òÂüüÂ∞ç XAI ÊúâÂæàÈ´òÁöÑÈúÄÊ±ÇÔºå‰ΩÜÂÆöÁæ©‰ªÄÈ∫ºÊßãÊàê‰∏ÄÂÄãÂ•ΩÁöÑËß£Èáã‰ªçÊòØËá®ÊôÇÊÄßÁöÑÔºåËÄåÊèê‰æõÈÅ©Áï∂ÁöÑËß£Èáã‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁÇ∫‰∫ÜÂÖÖÂàÜÁôºÊèÆ AI ÁöÑÊΩõÂäõÔºåÂ∞çÊñºÂÆâÂÖ®ÈóúÈçµÂûã AI ÊáâÁî®Ôºà‰æãÂ¶ÇÂÅ•Â∫∑ AIÔºâÁöÑËß£ÈáãÔºåÊé¢Ë®éÂÖ©ÂÄãÂü∫Êú¨ÂïèÈ°åËá≥ÈóúÈáçË¶ÅÔºö(1) ‰ªÄÈ∫ºÊòØÂÅ•Â∫∑ AI ‰∏≠ÁöÑËß£ÈáãÔºü‰ª•Âèä (2) ÂÅ•Â∫∑ AI ‰∏≠‰∏ÄÂÄãÂ•ΩÁöÑËß£ÈáãÊúâÂì™‰∫õÂ±¨ÊÄßÔºüÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊ™¢Ë¶ñ‰∫ÜÂ∑≤ÁôºË°®ÁöÑÊñáÁçªÔºå‰∏¶ÈÄèÈÅéÂÖ©Ëº™Âæ∑ÁàæËè≤Á†îÁ©∂Êî∂ÈõÜ‰∫ÜÂ∞àÂÆ∂ÊÑèË¶ã„ÄÇÁ†îÁ©∂ÊàêÊûúÂåÖÊã¨Ôºö(1) ÂÅ•Â∫∑ AI ‰∏≠‰ªÄÈ∫ºÊßãÊàêËß£ÈáãÁöÑÂÆöÁæ©Ôºå‰ª•Âèä (2) ÂÅ•Â∫∑ AI ‰∏≠‰∏ÄÂÄãÂ•ΩËß£ÈáãÁöÑÂ±¨ÊÄßÊ∏ÖÂñÆ„ÄÇ

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºåÂ∑≤Á∂ìÂºïÈÄ≤ÂêÑÁ®ÆÊñπÊ≥ï‰æÜËß£Èáã„ÄåÈªëÁÆ±„ÄçAI Ê®°ÂûãÁöÑËº∏Âá∫„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâç‰∏¶‰∏çÊ∏ÖÊ•ö‰ΩøÁî®ËÄÖÊòØÂê¶ÂØ¶ÈöõÁêÜËß£Âíå‰ø°‰ªªÈÄô‰∫õËß£Èáã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºË©ï‰º∞ÁôåÁóáÈ¢®Èö™ÁöÑÂõûÊ≠∏Â∑•ÂÖ∑ÁöÑËß£ÈáãÔºå‰∏¶Êé¢Ë®éËß£ÈáãÁöÑÂÖßÂÆπÂíåÊ†ºÂºèÂ∞ç‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÁêÜËß£Âíå‰ø°‰ªªÊåáÊ®ôÁöÑÂΩ±Èüø„ÄÇÈóúÊñºÂÖßÂÆπÔºåÊàëÂÄëÂØ¶È©ó‰∫ÜÂÖ©Á®ÆËß£ÈáãÊñπÊ≥ïÔºöÊµÅË°åÁöÑ SHAPÔºåÂü∫ÊñºÂçöÂºàË´ñÊ¶ÇÂøµÔºåÂõ†Ê≠§Â∞çÊñºÊó•Â∏∏‰ΩøÁî®ËÄÖ‰æÜË™™ÂèØËÉΩÂæàË§áÈõúÔºå‰ª•ÂèäÂü∫ÊñºÁâπÂæµÈÅÆËîΩÁöÑ occlusion-1ÔºåÂèØËÉΩÊõ¥ÊòìÊñºÁêÜËß£„ÄÇÈóúÊñºÊ†ºÂºèÔºåÊàëÂÄëÂ∞á SHAP Ëß£ÈáãÂëàÁèæÁÇ∫ÂúñË°® (SC)ÔºåÈÄôÊòØÊÖ£‰æãÔºåËÄåÂ∞á occlusion-1 Ëß£ÈáãÂëàÁèæÁÇ∫ÂúñË°® (OC) ‰ª•ÂèäÊñáÂ≠ó (OT)ÔºåÂÖ∂ËºÉÁÇ∫Á∞°ÂñÆÁöÑÊÄßË≥™‰πüÈÅ©Áî®ÊñºÊ≠§„ÄÇÈÄô‰∫õÂØ¶È©óÁ≠âÂêåÊñº‰ΩøÁî®ËÄÖÁ†îÁ©∂ÔºåË©¢ÂïèÂèÉËàáËÄÖÔºåÂÖ∑ÊúâÂÖ©Á®Æ‰∏çÂêåÁ®ãÂ∫¶ÁöÑÂ∞àÊ•≠Áü•Ë≠òÔºà‰∏ÄËà¨Ê∞ëÁúæÂíåÂÖ∑ÂÇô‰∏Ä‰∫õÈÜ´Â≠∏Ë®ìÁ∑¥ÁöÑ‰∫∫ÔºâÔºå‰ªñÂÄëÂ∞çÂõûÊ≠∏Â∑•ÂÖ∑Ëº∏Âá∫Ëß£ÈáãÁöÑ‰∏ªËßÄÂíåÂÆ¢ËßÄÁêÜËß£Âíå‰ø°‰ªª„ÄÇÂú®ÂÖ©È†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÁôºÁèæÔºåÂú®Âü∫ÊñºÂÖßÂÆπÈÄ≤Ë°åÊØîËºÉÊôÇÔºå‰∏ÄËà¨‰æÜË™™Ôºåocclusion-1 ÂÑ™Êñº SHAP Ëß£ÈáãÔºåÂú®‰∏ªËßÄÁêÜËß£Âíå‰ø°‰ªªÊñπÈù¢ÊúâÊòéÈ°ØÁöÑÂÅèÂ•Ω„ÄÇÁÑ∂ËÄåÔºåÂú®ÂÉÖÊéßÂà∂Ê†ºÂºèÁöÑÊÉÖÊ≥Å‰∏ãÁõ¥Êé•ÊØîËºÉËß£ÈáãÔºåÂú®Â§ßÂ§öÊï∏ÊÉÖÊ≥Å‰∏ãÂè™È°ØÁ§∫ OT ÂÑ™Êñº SC Ëß£ÈáãÁöÑË≠âÊìöÔºåÈÄôË°®Êòé occlusion-1 ÂÑ™Êñº SHAP Ëß£ÈáãÁöÑ‰∏ªÂ∞éÂú∞‰ΩçÂèØËÉΩÊòØÁî±ÂÅèÂ•ΩÊñáÂ≠óËÄåÈùûÂúñË°®‰ΩúÁÇ∫Ëß£ÈáãÊâÄÈ©ÖÂãïÁöÑ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ≤íÊúâÁôºÁèæËß£ÈáãÈ°ûÂûãÂú®ÂÆ¢ËßÄÁêÜËß£ÊñπÈù¢ÁöÑÂ∑ÆÁï∞Ë≠âÊìö„ÄÇÂõ†Ê≠§ÔºåÁ∏ΩÈ´îËÄåË®ÄÔºåÂ∞çËß£ÈáãÁöÑÂÖßÂÆπÂíåÊ†ºÂºèÁöÑÈÅ∏ÊìáÈúÄË¶Å‰ªîÁ¥∞Ê≥®ÊÑèÔºåÂõ†ÁÇ∫Âú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÔºåÊ†ºÂºèËÄåÈùûÂÖßÂÆπÔºåÂèØËÉΩÂú®ÊîπÂñÑ‰ΩøÁî®ËÄÖÈ´îÈ©óÊñπÈù¢ÁôºÊèÆÈóúÈçµ‰ΩúÁî®„ÄÇ</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Li√≤, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞Á™ÅÁ†¥Êèê‰æõ‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÈóúÊñºÁîüÁâ©ÈÜ´Â≠∏‰∏≠ LLM ÁöÑË™øÊü•ÈÄöÂ∏∏Â∞àÊ≥®ÊñºÁâπÂÆöÊáâÁî®ÊàñÊ®°ÂûãÊû∂ÊßãÔºåÁº∫‰πèÊï¥ÂêàÂêÑÁ®ÆÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÊúÄÊñ∞ÈÄ≤Â±ïÁöÑÂÖ®Èù¢ÂàÜÊûê„ÄÇÊú¨Á∂úËø∞Âü∫ÊñºÂ∞ç‰æÜËá™ PubMed„ÄÅWeb of Science Âíå arXiv Á≠âÊï∏ÊìöÂ∫´ÁöÑ 484 ÁØáÂá∫ÁâàÁâ©ÁöÑÂàÜÊûêÔºåÊ∑±ÂÖ•Êé¢Ë®é‰∫ÜÁîüÁâ©ÈÜ´Â≠∏‰∏≠ LLM ÁöÑÁï∂ÂâçÁèæÊ≥Å„ÄÅÊáâÁî®„ÄÅÊåëÊà∞ÂíåÂâçÊôØÔºåÂÖ∂ÁâπÈªûÊòØÈóúÊ≥®ÈÄô‰∫õÊ®°ÂûãÂú®ÁèæÂØ¶‰∏ñÁïåÁîüÁâ©ÈÜ´Â≠∏ËÉåÊôØ‰∏≠ÁöÑÂØ¶ÈöõÊáâÁî®„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü LLM Âú®Âª£Ê≥õÁöÑÁîüÁâ©ÈÜ´Â≠∏‰ªªÂãô‰∏≠ÁöÑÈõ∂Ê¨°Â≠∏ÁøíËÉΩÂäõÔºåÂåÖÊã¨Ë®∫Êñ∑ËºîÂä©„ÄÅËó•Áâ©ÁôºÁèæÂíåÂÄãÊÄßÂåñÈÜ´ÁôÇÁ≠âÔºå‰∏¶Âæû 137 È†ÖÈóúÈçµÁ†îÁ©∂‰∏≠Ê±≤ÂèñË¶ãËß£„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË®éË´ñ‰∫Ü LLM ÁöÑÈÅ©ÊáâÁ≠ñÁï•ÔºåÂåÖÊã¨ÂñÆÊ®°ÊÖãÂíåÂ§öÊ®°ÊÖã LLM ÁöÑÂæÆË™øÊñπÊ≥ïÔºå‰ª•Â¢ûÂº∑ÂÆÉÂÄëÂú®Èõ∂Ê¨°Â≠∏ÁøíÁÑ°Ê≥ïÂØ¶ÁèæÁöÑÂ∞àÊ•≠ÁîüÁâ©ÈÜ´Â≠∏ËÉåÊôØ‰∏≠ÁöÑÊÄßËÉΩÔºå‰æãÂ¶ÇÈÜ´ÁôÇÂïèÈ°åËß£Á≠îÂíåÁîüÁâ©ÈÜ´Â≠∏ÊñáÁçªÁöÑÊúâÊïàËôïÁêÜ„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫Ü LLM Âú®ÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÈù¢Ëá®ÁöÑÊåëÊà∞ÔºåÂåÖÊã¨Êï∏ÊìöÈö±ÁßÅÂïèÈ°å„ÄÅÊ®°ÂûãÂèØËß£ÈáãÊÄßÊúâÈôê„ÄÅÊï∏ÊìöÈõÜË≥™ÈáèÂïèÈ°å‰ª•ÂèäÁî±ÊñºÁîüÁâ©ÈÜ´Â≠∏Êï∏ÊìöÁöÑÊïèÊÑüÊÄß„ÄÅÂ∞çÈ´òÂ∫¶ÂèØÈù†Ê®°ÂûãËº∏Âá∫ÁöÑÈúÄÊ±Ç‰ª•ÂèäÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÈÉ®ÁΩ≤ AI ÁöÑÂÄ´ÁêÜÂΩ±ÈüøËÄåÁî¢ÁîüÁöÑÂÄ´ÁêÜÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÈÇÑÁ¢∫ÂÆö‰∫ÜÁîüÁâ©ÈÜ´Â≠∏‰∏≠ LLM Êú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÂåÖÊã¨Áî®Êñº‰øùË≠∑Êï∏ÊìöÈö±ÁßÅÁöÑËÅØÂêàÂ≠∏ÁøíÊñπÊ≥ï‰ª•ÂèäÊï¥ÂêàÂèØËß£Èáã AI ÊñπÊ≥ï‰ª•Â¢ûÂº∑ LLM ÁöÑÈÄèÊòéÂ∫¶„ÄÇ

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂú®ÈÜ´ÁôÇÂíå‰øùÂÅ•ÊáâÁî®‰∏≠ÊäïÂÖ•‰∫ÜÂ§ßÈáèÁöÑÊäïË≥áÂíåÈñãÁôºÔºåÈÄ≤ËÄåÂ∞éËá¥ÈÜ´ÁôÇÊäÄË°ì‰∏≠ÁöÑÂÖàÈÄ≤ÊéßÂà∂Á≥ªÁµ±„ÄÇÁÑ∂ËÄåÔºåAI Á≥ªÁµ±ÁöÑ‰∏çÈÄèÊòéÊÄßÂºïÁôº‰∫ÜÂ∞çÊ≠§È°ûÊïèÊÑüÊáâÁî®‰∏≠ÊâÄÈúÄÂü∫Êú¨ÁâπÊÄßÁöÑÊìîÊÜÇÔºå‰æãÂ¶ÇÈÄèÊòéÂ∫¶ÂíåÂèØ‰ø°Â∫¶„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄèÈÅéË™øÊü•‰∏ÄÂÄãÁ®ãÂ∫è‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÁî®ÊñºÈÅ∏ÊìáÊúÄÂÖÖÂàÜÁöÑÂèØËß£Èáã AIÔºàXAIÔºâÊñπÊ≥ïÔºå‰ª•Á¨¶ÂêàÊ≠êÁõüÊ≥ïË¶èÂú®ÈÜ´ÁôÇÂô®ÊùêÁöÑÊô∫ÊÖßÂûãÁîüÁâ©ÈõªÂ≠êÂ≠∏‰∏≠ÁöÑË™™ÊòéË¶ÅÊ±Ç„ÄÇÊé°Áî®ÁöÑÊñπÊ≥ïÂæûÈÄèÈÅéÂÖ∂ÊéßÂà∂Ê©üÂà∂ÔºàÈñãËø¥Ë∑Ø„ÄÅÈñâËø¥Ë∑ØÂíåÂçäÈñâËø¥Ë∑ØÁ≥ªÁµ±ÔºâÂ∞çÊô∫ÊÖßÂûãË£ùÁΩÆÈÄ≤Ë°åÂàÜÈ°ûÔºå‰∏¶Ê∑±ÂÖ•Êé¢Ë®éÂÖ∂ÊäÄË°ìÈñãÂßã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂàÜÊûêÈÄô‰∫õÊ≥ïË¶è‰ª•ÂÆöÁæ©ÂÖ∂Â∞çÂêÑÁ®ÆË£ùÁΩÆÂíåÁõ∏ÈóúÁõÆÊ®ôÁöÑÂèØËß£ÈáãÊÄßË¶ÅÊ±Ç„ÄÇÂêåÊôÇÔºåÊàëÂÄëÈÄèÈÅéÂÖ∂Ë™™ÊòéÁõÆÊ®ôÂ∞ç XAI ÊñπÊ≥ïÈÄ≤Ë°åÂàÜÈ°û„ÄÇÈÄôÂÖÅË®±Â∞áÊ≥ïÂæãÂèØËß£ÈáãÊÄßË¶ÅÊ±ÇËàá XAI Ë™™ÊòéÁõÆÊ®ôÁõ∏ÂåπÈÖçÔºå‰∏¶Á¢∫ÂÆöÈÅ©Áï∂ÁöÑ XAI ÊºîÁÆóÊ≥ï‰æÜÈÅîÊàêÂÆÉÂÄë„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊèê‰æõ‰∫ÜÂ∞çÂì™‰∫õ XAI ÊºîÁÆóÊ≥ïÊõ¥Á¨¶ÂêàÊ≠êÁõüÊ≥ïË¶è‰ª•ÈÅ©Áî®Êñº‰∏çÂêåÈ°ûÂûãÁöÑÈÜ´ÁôÇÂô®ÊùêÁöÑÁ¥∞Á∑ªÁêÜËß£„ÄÇÊàëÂÄëÈÄèÈÅé‰∏çÂêåÁ•ûÁ∂ìÊ§çÂÖ•Áâ©ÁöÑÂØ¶ÈöõÊ°à‰æãÁ†îÁ©∂‰æÜË≠âÊòéÈÄô‰∏ÄÈªûÔºåÂæûÊÖ¢ÊÄßÁñæÁóÖÁÆ°ÁêÜÂà∞ÂÖàÈÄ≤ÁöÑÁæ©ËÇ¢„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Â°´Ë£ú‰∫ÜÂ∞áÁîüÁâ©ÈõªÂ≠êÂ≠∏‰∏≠ÁöÑ XAI ÊáâÁî®ËàáÊ≠êÁõüÊ≥ïË¶èÁöÑÂö¥Ê†ºË¶èÂÆöÁõ∏Á¨¶ÁöÑÈáçË¶ÅÁ©∫ÁôΩ„ÄÇÂÆÉÁÇ∫ÈñãÁôº‰∫∫Âì°ÂíåÁ†îÁ©∂‰∫∫Âì°Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂØ¶Áî®ÁöÑÊû∂ÊßãÔºåÁ¢∫‰øùÂÖ∂ AI ÂâµÊñ∞ËÉΩ‰øÉÈÄ≤ÈÜ´ÁôÇÊäÄË°ì‰∏¶ÈÅµÂÆàÊ≥ïÂæãÂíåÈÅìÂæ∑Ê®ôÊ∫ñ„ÄÇ

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

ÊëòË¶ÅÔºöÊàëÂÄëÊé¢Á¥¢Ê∑±Â∫¶ÁîüÊàêÊ®°ÂûãÔºåÂú®ÈÜ´ÁôÇËÅØÈÇ¶Â≠∏ÁøíË®≠ÁΩÆ‰∏≠ÁîüÊàêÂü∫ÊñºÊ°à‰æãÁöÑË™™Êòé„ÄÇÈÄèÈÅéÂü∫ÊñºÊ°à‰æãÁöÑÂèØËß£ÈáãÊÄß‰æÜËß£Èáã AI Ê®°ÂûãÊ±∫Á≠ñÔºåÂ∞çÊñºÂ¢ûÂä†‰ø°‰ªª‰∏¶ÂÖÅË®± AI Âú®Ëá®Â∫äÂØ¶Âãô‰∏≠Âª£Ê≥õÊé°Áî®Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÈÜ´ÁôÇ AI Ë®ìÁ∑¥ÁØÑ‰æãÊ≠£ËΩâÂêëËÅØÈÇ¶Â≠∏ÁøíË®≠ÁΩÆÔºå‰ª•Á¨¶ÂêàË≥áÊñô‰øùË≠∑Ê≥ïË¶è„ÄÇÂú®ËÅØÈÇ¶ÊÉÖÂ¢É‰∏≠ÔºåÈÅéÂéªÁöÑË≥áÊñôÂ∞çÁõÆÂâçÁöÑ‰ΩøÁî®ËÄÖËÄåË®ÄÊòØÁÑ°Ê≥ïÂèñÂæóÁöÑ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄë‰ΩøÁî®Ê∑±Â∫¶ÁîüÊàêÊ®°Âûã‰æÜÁî¢Áîü‰øùË≠∑Èö±ÁßÅÂíåËß£ÈáãÊ±∫Á≠ñÁöÑÂêàÊàêÁØÑ‰æã„ÄÇÊàëÂÄëÁöÑÊ¶ÇÂøµÈ©óË≠âËëóÈáçÊñºËÉ∏ËÖîÁ©çÊ∂≤Ë®∫Êñ∑Ôºå‰∏¶‰ΩøÁî®ÂÖ¨ÈñãÂèØÂèñÂæóÁöÑËÉ∏ÈÉ® X ÂÖâË≥áÊñô„ÄÇ

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gru√ºhagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

ÊëòË¶ÅÔºöËªüÁµÑÁπîÂíåÈ™®È™ºËÖ´Áò§ÔºàSTBTÔºâÊòØÁΩïË¶ã„ÄÅË®∫Êñ∑ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁóÖÁÅ∂ÔºåÂÖ∂Ëá®Â∫äË°åÁÇ∫ÂíåÊ≤ªÁôÇÊñπÊ≥ïÂêÑ‰∏çÁõ∏Âêå„ÄÇÈÄôÁØáÁ≥ªÁµ±ÊÄßÂõûÈ°ßÊèê‰æõ‰∫Ü‰ΩøÁî®ÊîæÂ∞ÑÂΩ±ÂÉèÈÄ≤Ë°åË®∫Êñ∑ÂíåÈ†êÂæåÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÁöÑÊ¶ÇËßÄÔºåÈáçÈªûË™™Êòé‰∫ÜËá®Â∫äËΩâË≠ØÁöÑÊåëÊà∞Ôºå‰∏¶Ë©ï‰º∞Á†îÁ©∂ËàáÈÜ´ÁôÇÂΩ±ÂÉè AI Ê†∏Êü•Ë°® (CLAIM) Âíå FUTURE-AI ÂèØ‰ø°Ë≥¥‰∏îÂèØÈÉ®ÁΩ≤ AI ÁöÑÂúãÈöõÂÖ±Ë≠òÊ∫ñÂâáÁöÑ‰∏ÄËá¥ÊÄßÔºå‰ª•‰øÉÈÄ≤ AI ÊñπÊ≥ïÁöÑËá®Â∫äËΩâË≠Ø„ÄÇÈÄôÁØáÂõûÈ°ßÊ∂µËìã‰∫ÜÂπæÂÄãÊõ∏ÁõÆË≥áÊñôÂ∫´‰∏≠ÁöÑÊñáÁçªÔºåÂåÖÊã¨Âú® 2024 Âπ¥ 7 Êúà 17 Êó•‰πãÂâçÁôºË°®ÁöÑË´ñÊñá„ÄÇÁ¥çÂÖ•‰∫Ü‰ª•ÊîæÂ∞ÑÁÇ∫Âü∫Á§éÁöÑ AI Ë®∫Êñ∑ÊàñÈ†êÂæåÂéüÁôºÊÄß STBT ÁöÑÂêåË°åË©ïÂØ©ÊúüÂàä‰∏≠ÁöÑÂéüÂßãÁ†îÁ©∂„ÄÇÊéíÈô§Ê®ôÊ∫ñÊòØÂãïÁâ©„ÄÅÂ±çÈ´îÊàñÂØ¶È©óÂÆ§Á†îÁ©∂Ôºå‰ª•ÂèäÈùûËã±ÊñáË´ñÊñá„ÄÇÊëòË¶ÅÁî±‰∏â‰ΩçÁç®Á´ãÂØ©Êü•Âì°‰∏≠ÁöÑÂÖ©‰ΩçÁØ©ÈÅ∏Ë≥áÊ†º„ÄÇÂêàÊ†ºÁöÑË´ñÊñáÁî±‰∏â‰ΩçÁç®Á´ãÂØ©Êü•Âì°‰∏≠ÁöÑ‰∏Ä‰ΩçÊ†πÊìöÊ∫ñÂâáÈÄ≤Ë°åË©ï‰º∞„ÄÇÊêúÁ¥¢Ë≠òÂà•Âá∫ 15,015 ÁØáÊëòË¶ÅÔºåÂÖ∂‰∏≠ 325 ÁØáÊñáÁ´†Ë¢´Á¥çÂÖ•Ë©ï‰º∞„ÄÇÂ§ßÂ§öÊï∏Á†îÁ©∂Âú® CLAIM ‰∏≠Ë°®Áèæ‰∏≠Á≠âÔºåÂπ≥ÂùáÂæóÂàÜÁÇ∫ 53 ÂàÜ‰∏≠ÁöÑ 28.9¬±7.5 ÂàÜÔºå‰ΩÜÂú® FUTURE-AI ‰∏≠Ë°®Áèæ‰∏ç‰Ω≥ÔºåÂπ≥ÂùáÂæóÂàÜÁÇ∫ 30 ÂàÜ‰∏≠ÁöÑ 5.1¬±2.1 ÂàÜ„ÄÇSTBT ÁöÑÂΩ±ÂÉè AI Â∑•ÂÖ∑‰ªçËôïÊñºÊ¶ÇÂøµÈ©óË≠âÈöéÊÆµÔºåË°®ÊòéÊúâÈ°ØËëóÁöÑÊîπÈÄ≤Á©∫Èñì„ÄÇAI ÈñãÁôº‰∫∫Âì°Êú™‰æÜÁöÑÂä™ÂäõÊáâÈõÜ‰∏≠Âú®Ë®≠Ë®àÔºà‰æãÂ¶ÇÂÆöÁæ©Êú™ÊªøË∂≥ÁöÑËá®Â∫äÈúÄÊ±Ç„ÄÅÈ†êÊúüÁöÑËá®Â∫äÁí∞Â¢É‰ª•Âèä AI Â¶Ç‰ΩïÊï¥ÂêàÂà∞Ëá®Â∫äÂ∑•‰ΩúÊµÅÁ®ã‰∏≠Ôºâ„ÄÅÈñãÁôºÔºà‰æãÂ¶ÇÂª∫Á´ãÂú®ÂÖàÂâçÁöÑÂ∑•‰Ωú„ÄÅÂèØËß£ÈáãÊÄßÔºâ„ÄÅË©ï‰º∞Ôºà‰æãÂ¶ÇË©ï‰º∞ÂíåËß£Ê±∫ÂÅèÂ∑Æ„ÄÅË©ï‰º∞ AI ËàáÊúÄ‰Ω≥ÂØ¶ÂãôÔºâ„ÄÅ‰ª•ÂèäÊï∏ÊìöÂèØË§áË£ΩÊÄßÂíåÂèØÁî®ÊÄßÔºàÂÖ¨ÈñãÊèê‰æõÊñá‰ª∂ÂåñÁöÑ‰ª£Á¢ºÂíåÊï∏ÊìöÔºâ„ÄÇÈÅµÂæ™ÈÄô‰∫õÂª∫Ë≠∞ÂèØ‰ª•ÊîπÂñÑ AI ÊñπÊ≥ïÁöÑËá®Â∫äËΩâË≠Ø„ÄÇ

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Str√ºmke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

ÊëòË¶ÅÔºöËÖ¶ÊÄßÈ∫ªÁó∫ (CP) ÁöÑÊó©ÊúüÂÅµÊ∏¨Â∞çÊñºÊúâÊïàÁöÑ‰ªãÂÖ•ÂíåÁõ£Ê∏¨Ëá≥ÈóúÈáçË¶Å„ÄÇÊú¨ÊñáÊ∏¨Ë©¶‰∫ÜÂèØËß£Èáã AI (XAI) ÊñπÊ≥ïÁöÑÂèØÈù†ÊÄßÂíåÈÅ©Áî®ÊÄßÔºå‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºåÈÄèÈÅéÂàÜÊûêÂæûÂ¨∞ÂÖíÂãï‰ΩúÂΩ±ÁâáË®òÈåÑ‰∏≠ÊèêÂèñÁöÑÈ™®È™ºË≥áÊñô‰æÜÈ†êÊ∏¨ CP„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ΩøÁî® XAI Ë©ï‰º∞ÊåáÊ®ôÔºàÂç≥Âø†ÂØ¶Â∫¶ÂíåÁ©©ÂÆöÊÄßÔºâ‰æÜÈáèÂåñË©ï‰º∞È°ûÂà•ÊøÄÊ¥ªÊò†Â∞Ñ (CAM) ÂíåÊ¢ØÂ∫¶Âä†Ê¨äÈ°ûÂà•ÊøÄÊ¥ªÊò†Â∞Ñ (Grad-CAM) Âú®ÈÄôÂÄãÁâπÂÆöÈÜ´ÁôÇÊáâÁî®‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇÊàëÂÄëÂà©Áî®‰∏ÄÂÄãÁç®ÁâπÁöÑÂ¨∞ÂÖíÂãï‰ΩúË≥áÊñôÈõÜÔºå‰∏¶ÊáâÁî®È™®È™ºË≥áÊñôÊìæÂãïÔºåËÄå‰∏çÊúÉÊâ≠Êõ≤Â¨∞ÂÖíÂãï‰ΩúÁöÑÂéüÂßãÂãïÂäõ„ÄÇÊàëÂÄëÁöÑ CP È†êÊ∏¨Ê®°ÂûãÂà©Áî®Êï¥È´îÊñπÊ≥ïÔºåÂõ†Ê≠§ÊàëÂÄëË©ï‰º∞‰∫ÜÊï¥È´îÊï¥È´îÂíåÂÄãÂà•Ê®°ÂûãÁöÑ XAI ÊåáÊ®ôË°®Áèæ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂÖ©Á®Æ XAI ÊñπÊ≥ïÈÉΩËÉΩÊúâÊïàË≠òÂà•ÂΩ±Èüø CP È†êÊ∏¨ÁöÑÈóúÈçµË∫´È´îÈÉ®‰ΩçÔºå‰∏¶‰∏îÈÄô‰∫õËß£ÈáãÂ∞çÊñºÂæÆÂ∞èÁöÑË≥áÊñôÊìæÂãïÂÖ∑ÊúâÈ≠ØÊ£íÊÄß„ÄÇGrad-CAM Âú® RISv ÊåáÊ®ô‰∏≠È°ØËëóÂÑ™Êñº CAMÔºåË©≤ÊåáÊ®ôË°°ÈáèÈÄüÂ∫¶ÊñπÈù¢ÁöÑÁ©©ÂÆöÊÄß„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåCAM Âú® RISb ÊåáÊ®ô‰∏≠Ë°®ÁèæÂæóÊõ¥Â•ΩÔºåË©≤ÊåáÊ®ôËàáÈ™®È™ºÁ©©ÂÆöÊÄßÊúâÈóúÔºåËÄå RRS ÊåáÊ®ôÂâáË©ï‰º∞ÂÖßÈÉ®Ë°®Á§∫ÁöÑÈ≠ØÊ£íÊÄß„ÄÇÊï¥È´î‰∏≠ÁöÑÂÄãÂà•Ê®°ÂûãÈ°ØÁ§∫Âá∫‰∏çÂêåÁöÑÁµêÊûúÔºåCAM Âíå Grad-CAM ÈÉΩ‰∏ç‰∏ÄËá¥Âú∞ÂÑ™ÊñºÂè¶‰∏ÄÁ®ÆÔºåÊï¥È´îÊñπÊ≥ïÊèê‰æõ‰∫ÜÂÖ∂ÁµÑÊàêÊ®°ÂûãÁµêÊûúÁöÑË°®Á§∫„ÄÇ

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÂÖ®ÁêÉ‰º∞Ë®àË°®ÊòéÔºåÂ§öÈÅî 24.1 ÂÑÑ‰∫∫Êúâ
ÂÅ•Â∫∑ÁãÄÊ≥ÅÂèØÂæûÂæ©ÂÅ•ÊúçÂãô‰∏≠ÂèóÁõä„ÄÇÂ±ÖÂÆ∂
Áâ©ÁêÜÊ≤ªÁôÇ (PT) Âú®Êèê‰æõ‰∫íÂãïÂºè
ÂõûÈ•ãÂíåÊúâÊÑèÁæ©ÁöÑËßÄÂØüÊñπÈù¢Èù¢Ëá®ÈáçÂ§ßÊåëÊà∞Ôºå‰æõÊ≤ªÁôÇÂ∏´ÂíåÊÇ£ËÄÖ‰ΩøÁî®„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄô
ÂÄãÁº∫Âè£ÔºåÊàëÂÄëÊèêÂá∫ MicroXerciseÔºåÂÆÉÂ∞áÂæÆÂãï‰ΩúÂàÜÊûêËàá
ÂèØÁ©øÊà¥ÂºèÊÑüÊ∏¨Âô®Êï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÁÇ∫Ê≤ªÁôÇÂ∏´ÂíåÊÇ£ËÄÖÊèê‰æõ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑ
ÂõûÈ•ã‰ªãÈù¢ÔºåÂåÖÊã¨ÂΩ±Áâá„ÄÅÊñáÂ≠óÂíåÂàÜÊï∏„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÂÆÉÊé°Áî®
Â§öÁ∂≠ÂãïÊÖãÊôÇÈñìË¶èÊï¥ (DTW) ÂíåÂü∫ÊñºÊ≠∏Âõ†ÁöÑÂèØËß£Èáã
ÊñπÊ≥ï‰æÜÂàÜÊûêÁõ£ÊéßÈÅãÂãï‰∏≠ÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÂ∞àÊ≥®ÊñºÈÅãÂãïÁöÑÈ´òÁ≤íÂ∫¶„ÄÇÈÄôÁ®ÆÂçîÂêå
ÊñπÊ≥ïËá≥ÈóúÈáçË¶ÅÔºåÊèê‰æõËàáËº∏ÂÖ•Â§ßÂ∞èÂåπÈÖçÁöÑËº∏Âá∫Ôºå‰ª•Á≤æÁ¢∫Âú∞
Á™ÅÂá∫ PT ‰∏≠ÈóúÈçµÁöÑÁ¥∞ÂæÆÂ∑ÆÂà•ÂíåÂãï‰ΩúÔºåÂæûËÄåÂ∞áË§áÈõúÁöÑ AI
ÂàÜÊûêËΩâÊèõÁÇ∫Ê∏ÖÊô∞„ÄÅÂèØÊìç‰ΩúÁöÑÂõûÈ•ã„ÄÇÈÄèÈÅéÂú®‰∏çÂêåÊåáÊ®ô‰∏≠Á™ÅÈ°ØÈÄô‰∫õÂæÆÂãï‰ΩúÔºå‰æãÂ¶ÇÁ©©ÂÆöÊÄßÂíåÂãï‰ΩúÁØÑÂúçÔºåMicroXercise
È°ØËëóÊèêÂçáÊúÄÁµÇ‰ΩøÁî®ËÄÖÂ∞çÂõûÈ•ãÁöÑÁêÜËß£ÂíåÁõ∏ÈóúÊÄß„ÄÇÊØîËºÉÊïàËÉΩÊåáÊ®ôÂº∑Ë™øÂÖ∂ÂÑ™Êñº
ÂÇ≥Áµ±ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºå‰æãÂ¶ÇÁâπÂæµ‰∫íÊÉ†Ë≥áË®ä (FMI) ÂíåÈÄ£Á∫åÊÄßÂàÜÂà•ÊèêÂçá‰∫Ü 39% Âíå 42%„ÄÇMicroXercise Âú®Â±ÖÂÆ∂
Áâ©ÁêÜÊ≤ªÁôÇÊñπÈù¢Êõ¥ÈÄ≤‰∏ÄÊ≠•ÔºåÊèê‰æõÊäÄË°ìÂÖàÈÄ≤‰∏îÁõ¥Ë¶∫ÊúâÁî®ÁöÑ
Ëß£Ê±∫ÊñπÊ°àÔºå‰ª•ÊèêÂçáÊÇ£ËÄÖÁÖßË≠∑ÂíåÁµêÊûú„ÄÇ

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah R√∂sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

ÊëòË¶ÅÔºöÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ßÊòØÁ†îÁ©∂‰∏≠Ë≠âÊìöÂìÅË≥™ÊúÄÈ´òÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂõûÈ°ßÈÅéÁ®ãÂèóÂà∞È°ØËëóË≥áÊ∫êÂíåË≥áÊñôÈôêÂà∂ÁöÑÈòªÁ§ô„ÄÇÊñáÁçªÂõûÈ°ßÁ∂≤Ë∑Ø (LRN) ÊòØÁ¨¨‰∏ÄÂÄãÈÅµÂæ™ PRISMA 2020 Ê®ôÊ∫ñÁöÑÂèØËß£Èáã AI Âπ≥Âè∞ÔºåÊó®Âú®Ëá™ÂãïÂåñÊï¥ÂÄãÊñáÁçªÂõûÈ°ßÈÅéÁ®ã„ÄÇLRN Âú®Â§ñÁßëÊâãÂ•óÂØ¶ÂãôÈ†òÂüü‰∏≠ÈÄ≤Ë°åË©ï‰º∞Ôºå‰ΩøÁî®Â∞àÂÆ∂ÈñãÁôºÁöÑ 3 ÂÄãÊêúÂ∞ãÂ≠ó‰∏≤‰æÜÊü•Ë©¢ PubMed„ÄÇÈùûÂ∞àÂÆ∂Ë®ìÁ∑¥ÊâÄÊúâ LRN Ê®°Âûã„ÄÇÊïàËÉΩ‰ª•Â∞àÂÆ∂ÊâãÂãïÂõûÈ°ß‰ΩúÁÇ∫Âü∫Ê∫ñ„ÄÇÂèØËß£ÈáãÊÄßÂíåÊïàËÉΩÊåáÊ®ôË©ï‰º∞ LRN Ë§áË£ΩÂ∞àÂÆ∂ÂõûÈ°ßÁöÑËÉΩÂäõ„ÄÇ‰∏ÄËá¥ÊÄß‰ª• Jaccard ÊåáÊï∏ÂíåÊ∑∑Ê∑ÜÁü©Èô£Ê∏¨Èáè„ÄÇÁ†îÁ©∂‰∫∫Âì°Âú®Á†îÁ©∂ÂÆåÊàêÂâçÂ∞çÂΩºÊ≠§ÁöÑÁµêÊûú‰øùÂØÜ„ÄÇÈáçÁñäÁöÑÁ†îÁ©∂Êï¥ÂêàÂà∞ LRN ÁîüÊàêÁöÑÁ≥ªÁµ±ÊÄßÂõûÈ°ß‰∏≠„ÄÇLRN Ê®°ÂûãÂú®Ê≤íÊúâÂ∞àÂÆ∂Ë®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫ÁéáÔºåÈÅîÂà∞ 84.78% Âíå 85.71% ÁöÑÊ∫ñÁ¢∫Áéá„ÄÇÊïàËÉΩÊúÄÈ´òÁöÑÊ®°ÂûãÈÅîÂà∞‰∫ÜÈ´òË©ïÂàÜËÄÖÈñì‰ø°Ë≥¥Â∫¶ (k = 0.4953) ÂíåÂèØËß£ÈáãÊÄßÊåáÊ®ôÔºåÂ∞á„ÄåÊ∏õÂ∞ë„Äç„ÄÅ„ÄåÊÑèÂ§ñ„ÄçÂíå„ÄåÈä≥Âà©„ÄçËàá„ÄåÈõôÈáçÊà¥ÊâãÂ•ó„ÄçÈÄ£ÁµêÂú®‰∏ÄËµ∑„ÄÇÂè¶‰∏ÄÂÄã LRN Ê®°ÂûãÊ∂µËìã‰∫Ü 91.51% ÁöÑÁõ∏ÈóúÊñáÁçªÔºåÂÑòÁÆ°ËàáÈùûÂ∞àÂÆ∂ÁöÑÂà§Êñ∑‰∏çÂêå (k = 0.2174)Ôºå‰ΩÜÂåÖÂê´‰∫Ü„Äå‰π≥ËÜ†„Äç„ÄÅ„ÄåÈõôÈáç„ÄçÔºàÊâãÂ•óÔºâÂíå„ÄåÈÅ©ÊáâÁóá„ÄçÁ≠âË©ûÂΩô„ÄÇLRN ÂÑ™ÊñºÊâãÂãïÂõûÈ°ßÔºà11 ÂÄãÊúàË∂ÖÈÅé 19,920 ÂàÜÈêòÔºâÔºåÂ∞áÊï¥ÂÄãÈÅéÁ®ãÁ∏ÆÁü≠ÁÇ∫ 5 Â§©Ë∂ÖÈÅé 288.6 ÂàÜÈêò„ÄÇÈÄôÈ†ÖÁ†îÁ©∂È°ØÁ§∫ÔºåÂèØËß£ÈáãÁöÑ AI ‰∏çÈúÄË¶ÅÂ∞àÂÆ∂Ë®ìÁ∑¥Âç≥ÂèØÊàêÂäüÈÄ≤Ë°åÂ∞àÂÆ∂Á≠âÁ¥öÁöÑ PRISMA Áõ∏ÂÆπÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ß„ÄÇLRN Á∏ΩÁµê‰∫ÜÂ§ñÁßëÊâãÂ•óÁ†îÁ©∂ÁöÑÁµêÊûúÔºå‰∏¶ÊâæÂá∫ËàáËá®Â∫äÁ†îÁ©∂‰∫∫Âì°ÁôºÁèæÂπæ‰πéÁõ∏ÂêåÁöÑ‰∏ªÈ¢ò„ÄÇÂèØËß£ÈáãÁöÑ AI ÂèØ‰ª•Ê∫ñÁ¢∫Âú∞Âä†Âø´ÊàëÂÄëÂ∞çËá®Â∫äÂØ¶ÂãôÁöÑÁêÜËß£ÔºåÊúâÊΩõÂäõÈù©Êñ∞ÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂„ÄÇ

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ΩøÁî®ÁõíÂ≠êÂ≠∏Ê°ÜÊû∂ÂàÜÊûêÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÁöÑË®≠Ë®àÊ®°ÂºèÂèäÂÖ∂Âú®Ëá®Â∫äÊ±∫Á≠ñ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÂÆÉÂàÜÈ°û‰∏¶ÊØîËºÉÁµêÂêàÊ©üÂô®Â≠∏ÁøíÂíåÂü∫ÊñºË¶èÂâáÁöÑÊé®ÁêÜÁöÑÂêÑÁ®ÆÊû∂ÊßãÔºå‰ª•Ê∑±ÂÖ•‰∫ÜËß£ÂÖ∂ÁµêÊßãÂü∫Á§éÂíåÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®„ÄÇÈáùÂ∞çÂÖ©ÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÂ¶Ç‰ΩïÊ†πÊìöÊó¢ÂÆöÁöÑË®≠Ë®àÊ®°ÂºèÂ∞çÈÄô‰∫õÁ≥ªÁµ±ÈÄ≤Ë°åÂàÜÈ°ûÔºå‰ª•ÂèäÂ¶Ç‰ΩïÈÄöÈÅéÊØîËºÉÂàÜÊûêÊèêÂèñË¶ãËß£ÔºåÊú¨Á†îÁ©∂‰ΩøÁî®ËªüÈ´îÂ∑•Á®ã‰∏≠ÁöÑË®≠Ë®àÊ®°Âºè‰æÜ‰∫ÜËß£ÂíåÂÑ™ÂåñÈÜ´ÁôÇ‰øùÂÅ•‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±„ÄÇÁõíÂ≠êÂ≠∏ÊúâÂä©ÊñºË≠òÂà•ÂÖ±ÊÄß‰∏¶Âª∫Á´ãÂèØÈáçË§á‰ΩøÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂæûËÄåÂ¢ûÂº∑ÈÄô‰∫õÁ≥ªÁµ±ÁöÑÂèØÊì¥ÂÖÖÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÊïàËÉΩ„ÄÇÊ™¢Êü•‰∫Ü‰∫îÁ®Æ‰∏ªË¶ÅÁöÑÊû∂ÊßãÔºöREML„ÄÅMLRB„ÄÅRBML„ÄÅRMLT Âíå PERML„ÄÇÊØèÁ®ÆÊû∂ÊßãÈÉΩÊúâÁç®ÁâπÁöÑÂÑ™Áº∫ÈªûÔºåÂº∑Ë™ø‰∫ÜÂú®Ëá®Â∫ä‰ªªÂãô‰∏≠ÈúÄË¶ÅÈáèË∫´ÊâìÈÄ†ÁöÑÊñπÊ≥ï„ÄÇREML Âú®Ë≥áÊñôÊúâÈôêÁöÑË≥áÊñôÈõÜ‰∏≠Ë°®ÁèæÂá∫È´òÁ≤æÂ∫¶ÁöÑÈ†êÊ∏¨ÔºõMLRB Âú®ËôïÁêÜÂ§ßÂûãË≥áÊñôÈõÜÂíåË§áÈõúË≥áÊñôÊï¥ÂêàÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõRBML Âú®ÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõRMLT Âú®ÁÆ°ÁêÜÈ´òÁ∂≠Ë≥áÊñôÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõËÄå PERML ÂÑòÁÆ°Âú®ÂàÜÊûêÊñπÈù¢ÊúâÈôêÔºå‰ΩÜÂú®Á∑äÊÄ•ÁÖßË≠∑Â†¥ÊôØ‰∏≠Ë°®ÁèæÂá∫ÊΩõÂäõ„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜÂõõÁ®ÆÊñ∞Ê®°ÂºèÔºåÂª∫Á´ã‰∫Ü‰∫îÁ®ÆÊäΩË±°ÂàÜÈ°ûÊ®°ÂºèÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Â∞áÈÄô‰∫îÁ®ÆÊ®°ÂºèÁ¥∞ÂåñÁÇ∫ÂÖ∑È´îÁöÑÁ≥ªÁµ±„ÄÇÈÄô‰∫õË≤¢ÁçªÂ¢ûÂº∑‰∫ÜÁõíÂ≠êÂ≠∏ÁöÑÂàÜÈ°ûÁµÑÁπîÔºå‰∏¶Êèê‰æõ‰∫ÜÂ∞áÂ∞àÂÆ∂Áü•Ë≠òËàáÊ©üÂô®Â≠∏ÁøíÊï¥ÂêàÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÁõíÂ≠êÂ≠∏ÁöÑÁµêÊßãÂåñ„ÄÅÊ®°ÁµÑÂåñÊñπÊ≥ïÂú®ÈñãÁôºÂíåÂàÜÊûêÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±„ÄÅÊè≠Á§∫ÂÖ±ÊÄß‰ª•ÂèäÊé®Âª£ÂèØÈáçË§á‰ΩøÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÂÑ™Âã¢„ÄÇÁ∏Ω‰πãÔºåÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±Âú®Êé®ÈÄ≤ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈóúÈçµ‰ΩúÁî®Ôºå‰ª•ÂèäÁõíÂ≠êÂ≠∏Âú®Êé®Âãï‰∫∫Â∑•Êô∫ÊÖßÊï¥ÂêàÈÄ≤‰∏ÄÊ≠•ÂâµÊñ∞ÊñπÈù¢ÁöÑÊΩõÂäõÔºåÊúÄÁµÇÊîπÂñÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥ÂíåÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÊàêÊûú„ÄÇ

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

ÊëòË¶ÅÔºöÁî±ÊñºÂÖ∂Âº∑Â§ßÁöÑÈ†êÊ∏¨ËÉΩÂäõÔºåÊ∑±Â∫¶Â≠∏ÁøíÂ∑≤ÊàêÁÇ∫Ë®±Â§öÁî¢Ê•≠‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÂ∑•ÂÖ∑ÔºåÂåÖÊã¨ÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏îÂøΩÁï•‰∫ÜÂ∞áÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßÁ¥çÂÖ•ËÄÉÈáèÔºåËÄåÈÄôÂÖ©ÂÄãÂõ†Á¥†ÊòØËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÁÇ∫‰∫ÜÁî¢ÁîüÂèØËß£Èáã‰∏îÂÖ∑Êúâ‰∏çÁ¢∫ÂÆöÊÄßÊÑèË≠òÁöÑÈ†êÊ∏¨ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫Ë≤ùÊ∞èÊüØÁàæËé´Âì•Ê¥õÂ§´ÈòøË´æÂæ∑Á∂≤Ë∑Ø (BKAN) ÁöÑÊñ∞Êû∂ÊßãÔºåÂÆÉÁµêÂêà‰∫ÜÊüØÁàæËé´Âì•Ê¥õÂ§´ÈòøË´æÂæ∑Á∂≤Ë∑ØÁöÑË°®ÈÅîËÉΩÂäõËàáË≤ùÊ∞èÊé®Ë´ñ„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÈÜ´Â≠∏Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî® BKANÔºåÈÄô‰∫õË≥áÊñôÈõÜÊòØË©ï‰º∞Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®ÈÜ´Â≠∏Ë®∫Êñ∑‰∏≠ÁöÑÂª£Ê≥õ‰ΩøÁî®Âü∫Ê∫ñÔºöÁöÆÈ¶¨Âç∞Á¨¨ÂÆâ‰∫∫Á≥ñÂ∞øÁóÖË≥áÊñôÈõÜÂíåÂÖãÈáåÂ§´Ëò≠ÂøÉËáüÁóÖË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊèê‰æõ‰∫ÜÂ∞çÈ†êÊ∏¨‰ø°ÂøÉÂíåÊ±∫Á≠ñÈÇäÁïåÁöÑÊúâÁõäË¶ãËß£Ôºå‰∏¶‰∏îÂú®È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢ÂÑ™ÊñºÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåBKAN Ë°®ÁèæÈö®Ê©üÂíåË™çË≠ò‰∏çÁ¢∫ÂÆöÊÄßÁöÑËÉΩÂäõÔºåÂèØÁ¢∫‰øùÈÜ´ÁîüÁç≤ÂæóÊõ¥ÂèØÈù†‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÊ±∫Á≠ñÊîØÊè¥„ÄÇÊ†πÊìöÂØ¶È©óÁµêÊûúÔºåÊàëÂÄëÁöÑË≤ùÊ∞èÁ≠ñÁï•ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰∏¶Â§ßÂπÖÊ∏õÂ∞ë‰∫ÜÈÅéÂ∫¶Êì¨ÂêàÔºåÈÄôÂ∞çÊñºÂ∞èÂûã‰∏î‰∏çÂπ≥Ë°°ÁöÑÈÜ´Â≠∏Ë≥áÊñôÈõÜÈùûÂ∏∏ÈáçË¶Å„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂèØËÉΩÁöÑÊì¥ÂÖÖÂäüËÉΩÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Â∞á BKAN Áî®ÊñºÊõ¥Ë§áÈõúÁöÑÂ§öÊ®°ÂºèË≥áÊñôÈõÜÔºå‰∏¶Êé¢Ë®éÈÄô‰∫õÁôºÁèæÂ∞çÊñºÊú™‰æÜÂª∫Á´ãÂèØÈù†ÁöÑÈÜ´ÁôÇ‰øùÂÅ• AI Á≥ªÁµ±Á†îÁ©∂ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÉ®ÁΩ≤Âú®ÈÄèÊòéÂ∫¶ÂíåÂèØÈù†ÊÄßËá≥ÈóúÈáçË¶ÅÁöÑÈáçË¶ÅÈ†òÂüü‰∏≠ÈñãÂïü‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂÖ∏ÁØÑ„ÄÇ

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

ÊëòË¶ÅÔºöÂú®Áèæ‰ª£ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÔºåËß£Ê±∫Ê∫ñÁ¢∫ÁñæÁóÖÈ†êÊ∏¨ÂíåÂÄãÊÄßÂåñÂª∫Ë≠∞ÁöÑË§áÈõúÊÄßÊó¢Ëá≥ÈóúÈáçË¶ÅÂèàÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü MLtoGAIÔºåÂÆÉÂ∞áË™ûÁæ©Á∂≤Ë∑ØÊäÄË°ìËàáÊ©üÂô®Â≠∏Áøí (ML) Áõ∏ÁµêÂêàÔºå‰ª•Â¢ûÂº∑ÁñæÁóÖÈ†êÊ∏¨‰∏¶ÈÄèÈÅé ChatGPT Êèê‰æõ‰ΩøÁî®ËÄÖÂèãÂñÑÁöÑË™™Êòé„ÄÇË©≤Á≥ªÁµ±ÂåÖÂê´‰∏âÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºö‰∏ÄÂÄãÂèØÈáçË§á‰ΩøÁî®ÁöÑÁñæÁóÖÊú¨‰ΩìÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊúâÈóúÂêÑÁ®ÆÁñæÁóÖÁöÑË©≥Á¥∞Áü•Ë≠òÔºõ‰∏ÄÂÄãË®∫Êñ∑ÂàÜÈ°ûÊ®°ÂûãÔºåÂÆÉ‰ΩøÁî®ÊÇ£ËÄÖÁóáÁãÄ‰æÜÊ∫ñÁ¢∫Ê™¢Ê∏¨ÁâπÂÆöÁñæÁóÖÔºõ‰ª•ÂèäË™ûÁæ©Á∂≤Ë∑ØË¶èÂâáË™ûË®Ä (SWRL) ËàáÊú¨‰ΩìÂíå ChatGPT ÁöÑÊï¥ÂêàÔºå‰ª•Áî¢ÁîüÊ∏ÖÊô∞„ÄÅÂÄãÊÄßÂåñÁöÑÂÅ•Â∫∑Âª∫Ë≠∞„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈ°ØËëóÊèêÈ´ò‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÔºå‰∏¶Á¢∫‰øù‰∫ÜÊòìÊñºÁêÜËß£ÁöÑÁµêÊûúÔºåËß£Ê±∫‰∫ÜÁñæÁóÖÂíå‰∏çÂêåÁóáÁãÄÁöÑË§áÈõúÊÄß„ÄÇMLtoGAI Á≥ªÁµ±Â±ïÁ§∫‰∫ÜÊ∫ñÁ¢∫ÊÄßÂíå‰ΩøÁî®ËÄÖÊªøÊÑèÂ∫¶ÁöÑÂØ¶Ë≥™ÊÄßÈÄ≤Ê≠•ÔºåÊúâÂä©ÊñºÈñãÁôºÊõ¥Êô∫ÊÖß‰∏îÊõ¥ÊòìÊñºÂèñÂæóÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ëß£Ê±∫ÊñπÊ°à„ÄÇÈÄôÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÁµêÂêà‰∫Ü ML ÊºîÁÆóÊ≥ïÁöÑÂÑ™ÈªûÔºå‰ª•ÂèäÈÄèÈÅé ChatGPT Êèê‰æõÈÄèÊòé‰∏î‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑË™™ÊòéÁöÑËÉΩÂäõÔºåÂú®È†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÂíå‰ΩøÁî®ËÄÖÁêÜËß£ÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÈÄèÈÅéÂà©Áî®Ë™ûÁæ©ÊäÄË°ìÂíåÂèØËß£ÈáãÁöÑ AIÔºåË©≤Á≥ªÁµ±ÊèêÈ´ò‰∫ÜÁñæÁóÖÈ†êÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄßÔºå‰∏¶Á¢∫‰øù‰∫ÜÂª∫Ë≠∞ËàáÂÄãÂà•ÊÇ£ËÄÖÁõ∏Èóú‰∏îÊòìÊñºÁêÜËß£„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÊï¥ÂêàÂÖàÈÄ≤ÊäÄË°ì‰ª•ÂÖãÊúçÈÜ´ÁôÇË®∫Êñ∑‰∏≠ÁèæÊúâÊåëÊà∞ÁöÑÊΩõÂäõÔºåÁÇ∫Êô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÊú™‰æÜÁôºÂ±ïÈã™Ë∑Ø„ÄÇÊ≠§Â§ñÔºåË©≤Á≥ªÁµ±‰ΩøÁî® 200 ÂÄãÂêàÊàêÊÇ£ËÄÖË≥áÊñôË®òÈåÑÈÄ≤Ë°åÈ©óË≠âÔºåÁ¢∫‰øù‰∫ÜÁ©©ÂÅ•ÁöÑÊïàËÉΩÂíåÂèØÈù†ÊÄß„ÄÇ

##### **Introducing Œ¥-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊòØÂ∞á‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåÊ©üÂô®Â≠∏Áøí (ML) ÊºîÁÆóÊ≥ïÊï¥ÂêàÂà∞Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑËæØË´ñÊ†∏ÂøÉ„ÄÇÈ´òÂü∑Ë°åÊïàËÉΩÁöÑ AI/ML Ê®°ÂûãÔºå‰æãÂ¶ÇÊï¥È´îÂ≠∏ÁøíÂô®ÂíåÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÔºåÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºåÈòªÁ§ôËá®Â∫äÈÜ´ÁîüÂ∞çÂÖ∂È†êÊ∏¨ÁöÑ‰ø°‰ªª„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊ≠£Âú®ÈñãÁôº XAI ÊäÄË°ìÔºå‰ª•‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑË°ìË™ûÊèèËø∞ AI/ML È†êÊ∏¨„ÄÇ‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊñπÂêëÊòØÊé°Áî®ÊïèÊÑüÂ∫¶ÂàÜÊûê (SA) ÂíåÂÖ®ÁêÉÊïèÊÑüÂ∫¶ÂàÜÊûê (GSA)ÔºåÂÆÉÂÄëÊú¨Ë≥™‰∏äÊúÉ‰æùÊìöÊ®°ÂûãËº∏ÂÖ•Â∞çÈ†êÊ∏¨ÁöÑÂΩ±Èüø‰æÜÂ∞çÂÖ∂ÈÄ≤Ë°åÊéíÂêç„ÄÇÂú®Ê≠§ÔºåÊàëÂÄë‰ªãÁ¥π‰∏ÄÁ®ÆÊñ∞ÁöÑ delta-XAI ÊñπÊ≥ïÔºåÈÄèÈÅéÊì¥ÂÖÖ GSA ÊåáÊ®ô delta ÊåáÊï∏‰æÜÊèê‰æõ ML Ê®°ÂûãÈ†êÊ∏¨ÁöÑÂ±ÄÈÉ®Ëß£Èáã„ÄÇdelta-XAI ÊåáÊï∏Ë©ï‰º∞ÊØèÂÄãÁâπÂæµÂÄºÂ∞çÂõûÊ≠∏ÂíåÂàÜÈ°ûÂïèÈ°å‰∏≠ÂÄãÂà•‰æãÈ†ÖÁöÑÈ†êÊ∏¨Ëº∏Âá∫‰πãÂΩ±Èüø„ÄÇÊàëÂÄëÂ∞á delta-XAI ÊåáÊï∏ÂΩ¢ÂºèÂåñÔºå‰∏¶Êèê‰æõÂÖ∂ÂØ¶‰ΩúÁöÑÁ®ãÂºèÁ¢º„ÄÇ‰ΩøÁî®Á∑öÊÄßÂõûÊ≠∏Ê®°ÂûãÂ∞çÊ®°Êì¨ÊÉÖÂ¢ÉË©ï‰º∞ delta-XAI ÊñπÊ≥ïÔºå‰∏¶‰ª• Shapley ÂÄº‰ΩúÁÇ∫Âü∫Ê∫ñ„ÄÇÁµêÊûúÈ°ØÁ§∫ delta-XAI ÊåáÊï∏ÈÄöÂ∏∏Ëàá Shapley ÂÄº‰∏ÄËá¥Ôºå‰ΩÜÂú®ÂÖ∑ÊúâÈ´òÂ∫¶ÂΩ±ÈüøÂäõÊàñÊ•µÁ´ØÁâπÂæµÂÄºÁöÑÊ®°Âûã‰∏≠Â≠òÂú®È°ØËëóÂ∑ÆÁï∞„ÄÇdelta-XAI ÊåáÊï∏Âú®ÂÅµÊ∏¨‰∏ªË¶ÅÁâπÂæµÂíåËôïÁêÜÊ•µÁ´ØÁâπÂæµÂÄºÊñπÈù¢Ë°®ÁèæÂá∫Êõ¥È´òÁöÑÊïèÊÑüÂ∫¶„ÄÇÂÆöÊÄßÂú∞‰æÜË™™Ôºådelta-XAI ÈÄèÈÅéÂà©Áî®Ê©üÁéáÂØÜÂ∫¶ÂáΩÊï∏Êèê‰æõÁõ¥ËßÄÁöÑËß£ÈáãÔºå‰ΩøÁâπÂæµÊéíÂêçÊõ¥Ê∏ÖÊô∞‰∏îÂ∞çÂæûÊ•≠‰∫∫Âì°‰æÜË™™Êõ¥ÂÖ∑ÂèØËß£ÈáãÊÄß„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºådelta-XAI ÊñπÊ≥ïÂ∞çÊñºÁ©©ÂÅ•Âú∞ÂèñÂæó ML Ê®°ÂûãÈ†êÊ∏¨ÁöÑÂ±ÄÈÉ®Ëß£Èáã‰ºº‰πéÂæàÊúâÂ∏åÊúõ„ÄÇÂ∞áÂú®ÁúüÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÈÄ≤‰∏ÄÊ≠•Ë™øÊü•Ôºå‰ª•Ë©ï‰º∞ÂÖ∂Â∞ç AI ËºîÂä©Ëá®Â∫äÂ∑•‰ΩúÊµÅÁ®ãÁöÑÂΩ±Èüø„ÄÇ

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

ÊëòË¶ÅÔºöÂ§±Êô∫ÁóáÊòØ‰∏ÄÁ®ÆÂΩ±ÈüøÂÖ®ÁêÉÊï∏ÁôæËê¨‰∫∫ÁöÑË°∞Âº±ÊÄßÁ•ûÁ∂ìÁñæÁóÖÔºåÂú®Ë®∫Êñ∑‰∏äÂÖ∑ÊúâÈáçÂ§ßÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂ∞çÂ§±Êô∫ÂíåÈùûÂ§±Êô∫ËÄÅÂπ¥ÊÇ£ËÄÖÈÄ≤Ë°åÂàÜÈ°ûÔºå‰ΩøÁî® 3D Â§ßËÖ¶Á£ÅÊåØÈÄ†ÂΩ± (MRI) ÊéÉÊèè„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊé°Áî®‰∫Ü‰∏ÄÁ®ÆÁç®ÁâπÊäÄË°ìÔºåÁî®ÊñºÈÅ∏ÊìáÊÄßËôïÁêÜ MRI ÂàáÁâáÔºåÈáçÈªûÈóúÊ≥®ÊúÄÁõ∏ÈóúÁöÑÂ§ßËÖ¶ÂçÄÂüüÔºå‰∏¶ÊéíÈô§‰ø°ÊÅØÈáèËºÉÂ∞ëÁöÑÈÉ®ÂàÜ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÁî±‰∏ÄÂÄãÂü∫Êñº‰ø°ÂøÉÁöÑÂàÜÈ°ûÂßîÂì°ÊúÉË£úÂÖÖÔºåË©≤ÂßîÂì°ÊúÉÁî±‰∏âÂÄãËá™ÂÆöÁæ©Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁµÑÊàêÔºöDem3D ResNet„ÄÅDem3D CNN Âíå Dem3D EfficientNet„ÄÇÈÄô‰∫õÊ®°ÂûãÂçîÂêåÂ∑•‰Ωú‰ª•Â¢ûÂº∑Ê±∫Á≠ñÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÂà©Áî®ÂÆÉÂÄëÁöÑÈõÜÈ´îÂÑ™Âã¢„ÄÇÂú®ÂΩ±ÂÉèÁ†îÁ©∂ÈñãÊîæÂ≠òÂèñÁ≥ªÂàó (OASIS) Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈÅîÂà∞‰∫Ü 94.12% ÁöÑÈ©ö‰∫∫Ê∫ñÁ¢∫Â∫¶ÔºåË∂ÖÈÅé‰∫ÜÁèæÊúâÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÂú®ÈòøËå≤Êµ∑ÈªòÁóáÁ•ûÁ∂ìÂΩ±ÂÉèÂÄ°Ë≠∞ (ADNI) Ë≥áÊñôÈõÜ‰∏äÁöÑÈ©óË≠âË≠âÂØ¶‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÁ©©ÂÅ•ÊÄßÂíåÊôÆÈÅçÊÄß„ÄÇÂèØËß£Èáã AI (XAI) ÊäÄË°ìÂíåÂÖ®Èù¢ÁöÑÊ∂àËûçÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Ë≠âÂØ¶‰∫ÜÊàëÂÄëÊäÄË°ìÁöÑÊúâÊïàÊÄßÔºåÊèê‰æõ‰∫ÜÂ∞çÊ±∫Á≠ñÈÅéÁ®ãÂíåÊàëÂÄëÊñπÊ≥ïÈáçË¶ÅÊÄßÁöÑË¶ãËß£„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁÇ∫Â§±Êô∫ÁóáË®∫Êñ∑Êèê‰æõ‰∫ÜÈáçÂ§ßÈÄ≤Â±ïÔºåÁÇ∫Ëá®Â∫äÊáâÁî®Êèê‰æõ‰∫Ü‰∏ÄÂÄãÈ´òÂ∫¶Ê∫ñÁ¢∫‰∏îÈ´òÊïàÁöÑÂ∑•ÂÖ∑„ÄÇ

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

ÊëòË¶ÅÔºöËóâÁî±Êô∫ÊÖßÁí∞Â¢É‰∏≠‰∏çÂºï‰∫∫Ê≥®ÁõÆÁöÑÊÑüÊ∏¨Âô®Ëæ®Ë≠òÊó•Â∏∏Ê¥ªÂãïÔºåËÉΩÂïüÁî®ÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®„ÄÇÁõ£ÊéßÂèóË©¶ËÄÖÂú®ÂÆ∂‰∏≠Â¶Ç‰ΩïÂü∑Ë°åÊ¥ªÂãïÔºå‰ª•ÂèäÂÖ∂Èö®ËëóÊôÇÈñìÁöÑËÆäÂåñÔºåÂèØ‰ª•Êè≠Á§∫ÂÅ•Â∫∑ÂïèÈ°åÁöÑÊó©ÊúüÁóáÁãÄÔºå‰æãÂ¶ÇË™çÁü•ËÉΩÂäõ‰∏ãÈôç„ÄÇÊ≠§È†òÂüü‰∏≠ÁöÑÂ§ßÂ§öÊï∏ÊñπÊ≥ïÈÉΩ‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏Ë¢´Ë¶ñÁÇ∫Â∞áÊÑüÊ∏¨Âô®Ë≥áÊñôÂ∞çÊáâËá≥Ê¥ªÂãïÁöÑÈªëÁõíÂ≠ê„ÄÇÁÑ∂ËÄåÔºåÈùûÂ∞àÂÆ∂‰ΩøÁî®ËÄÖÔºà‰æãÂ¶ÇËá®Â∫äÈÜ´Â∏´ÔºâÈúÄË¶Å‰ø°‰ªª‰∏¶‰∫ÜËß£ÈÄô‰∫õÊ®°ÂûãÁöÑËº∏Âá∫„ÄÇÂõ†Ê≠§Ôºå‰∫∫È°ûÊ¥ªÂãïËæ®Ë≠òÁöÑÂèØËß£Èáã AI (XAI) ÊñπÊ≥ïÊáâÈÅãËÄåÁîüÔºå‰ª•Êèê‰æõ‰æÜËá™ÈÄô‰∫õÊ®°ÂûãÁöÑÁõ¥Ë¶∫Ëá™ÁÑ∂Ë™ûË®ÄË™™Êòé„ÄÇ‰∏çÂêåÁöÑ XAI ÊñπÊ≥ïÊúÉÁî¢Áîü‰∏çÂêåÁöÑË™™ÊòéÔºåËÄåÂÖ∂ÊúâÊïàÊÄßÈÄöÂ∏∏ÈÄèÈÅé‰ΩøÁî®ËÄÖË™øÊü•‰æÜË©ï‰º∞ÔºåÈÄôÂú®ÊàêÊú¨ÂíåÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÈÄöÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËá™ÂãïË©ï‰º∞ÊñπÊ≥ïÔºå‰ª•Âú®ÂÄôÈÅ∏ËÄÖ‰∏≠ÊâæÂá∫ÊúÄÈÅ©ÂêàÈùûÂ∞àÂÆ∂‰ΩøÁî®ËÄÖÁöÑ XAI ÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÂàùÊ≠•ÁµêÊûúË°®ÊòéÔºåLLM Ë©ï‰º∞Ëàá‰ΩøÁî®ËÄÖË™øÊü•‰∏ÄËá¥„ÄÇ

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

ÊëòË¶ÅÔºöÂ∑•Ê•≠ 5.0 ËëóÈáçÊñº‰∫∫È°ûËàá‰∫∫Â∑•Êô∫ÊÖß (AI) Âêà‰ΩúÂü∑Ë°åË£ΩÈÄ†‰∏≠ÁöÑ‰∏çÂêå‰ªªÂãôÔºåÊ∂âÂèäÊõ¥Â§öÊ©üÂô®‰∫∫„ÄÅÁâ©ËÅØÁ∂≤ (IoT) Ë£ùÁΩÆÂíå‰∫íÈÄ£„ÄÅÊì¥Â¢û/ËôõÊì¨ÂØ¶Â¢É (AR) ÂíåÂÖ∂‰ªñÊô∫ÊÖßË£ùÁΩÆ„ÄÇÈÄô‰∫õË£ùÁΩÆÂíå‰∫íÈÄ£Âú®Á∂ìÊøü„ÄÅÈÜ´ÁôÇ‰øùÂÅ•„ÄÅÊïôËÇ≤ÂíåÂúãÈò≤Á≥ªÁµ±Á≠âÂêÑÁ®ÆÈóúÈçµÈ†òÂüüÁöÑÂª£Ê≥õÂèÉËàáÔºåÂºïÁôº‰∫ÜÂ§öÁ®ÆÈ°ûÂûãÁöÑÊΩõÂú®ÂÆâÂÖ®ÊºèÊ¥û„ÄÇAI Êú¨Ë∫´Â∑≤Ë¢´Ë≠âÊòéÊòØÁ∂≤Ë∑ØÂÆâÂÖ®‰∏çÂêåÈ†òÂüü‰∏≠ÈùûÂ∏∏ÊúâÊïà‰∏îÂº∑Â§ßÁöÑÂ∑•ÂÖ∑Ôºå‰æãÂ¶ÇÂÖ•‰æµÂÅµÊ∏¨„ÄÅÊÉ°ÊÑèËªüÈ´îÂÅµÊ∏¨ÂíåÁ∂≤Ë∑ØÈá£È≠öÂÅµÊ∏¨Á≠â„ÄÇÂ∞±ÂÉèÂú®Ë®±Â§öÊáâÁî®È†òÂüü‰∏ÄÊ®£ÔºåÁ∂≤Ë∑ØÂÆâÂÖ®Â∞àÊ•≠‰∫∫Âì°‰∏çÈ°òÊÑèÊé•ÂèóÈªëÁõí ML Ëß£Ê±∫ÊñπÊ°à‰æÜÊáâÁî®ÊñºÁ∂≤Ë∑ØÂÆâÂÖ®„ÄÇÈÄôÁ®Æ‰∏çÈ°òÊÑè‰øÉ‰ΩøÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ‰ΩúÁÇ∫‰∏ÄÁ®ÆÂ∑•ÂÖ∑Ë¢´Êé°Áî®ÔºåÊúâÂä©ÊñºË™™ÊòéÂú®Âü∫Êñº ML ÁöÑÁ≥ªÁµ±‰∏≠Â¶Ç‰ΩïÂÅöÂá∫Ê±∫Á≠ñ„ÄÇÂú®ÈÄôÈ†ÖË™øÊü•‰∏≠ÔºåÊàëÂÄëÂ∞çÂ∑•Ê•≠ 5.0 ÁöÑ‰∏çÂêåÂü∫Êñº XAI ÁöÑÂÖ•‰æµÂÅµÊ∏¨Á≥ªÁµ±ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÁ†îÁ©∂Ôºå‰∏¶‰∏îÊàëÂÄë‰πüÈÄèÈÅéÂ∞çÊäóÂºè XIDS (Adv-XIDS) ÊñπÊ≥ïÁöÑËßÄÈªû‰æÜÊé¢Ë®éÂèØËß£ÈáãÊÄßÂíåÂèØË©ÆÈáãÊÄßÂ∞çÁ∂≤Ë∑ØÂÆâÂÖ®ÂØ¶ÂãôÁöÑÂΩ±Èüø„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÂ∑•Ê•≠ 5.0 ÁöÑ XAI Á∂≤Ë∑ØÂÆâÂÖ®Á≥ªÁµ±‰∏≠ÂèØËÉΩÂ≠òÂú®ÁöÑÊ©üÊúÉÂíåÊåëÊà∞ÔºåÂºïÁôº‰∫ÜÊú™‰æÜÈáùÂ∞ç XAI Âü∫Á§éËß£Ê±∫ÊñπÊ°àÁöÑÁ†îÁ©∂Ôºå‰ª•‰æõÈ´òÈ¢®Èö™ÁöÑÂ∑•Ê•≠ 5.0 ÊáâÁî®Êé°Áî®„ÄÇÊàëÂÄëÁõ∏‰ø°ÈÄôÈ†ÖÂö¥Ë¨πÁöÑÂàÜÊûêÂ∞áÁÇ∫ÊåáÂÆöÈ†òÂüüÂÖßÁöÑÂæåÁ∫åÁ†îÁ©∂Â∑•‰ΩúÂª∫Á´ãÂü∫Á§éÊû∂Êßã„ÄÇ

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êó®Âú®Êé¢Ë®éÂ∞áËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂíåÊ©üÂô®Â≠∏Áøí (ML) ÊäÄË°ìÂØ¶‰ΩúÊñºÈÜ´ÁôÇ‰ø°ÂáΩÁ∑®Á¢ºËá™ÂãïÂåñÔºå‰∏¶ÂÖ∑ÂÇôË¶ñË¶∫ÂåñË™™ÊòéËÉΩÂäõÂíåËºïÈáèÂåñÁöÑÊú¨Âú∞ÈõªËÖ¶Ë®≠ÂÆö„ÄÇÁõÆÂâçÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÔºåÁ∑®Á¢ºÊòØ‰∏ÄÁ®ÆÊâãÂãïÊµÅÁ®ãÔºåÊ∂âÂèäÁÇ∫ÁóÖÊÇ£Êñá‰ª∂‰∏≠ÁöÑÊØèÈ†ÖÁóÖÁóá„ÄÅÁ®ãÂ∫èÂíåËó•Áâ©ÊåáÊ¥æ‰ª£Á¢º (‰æãÂ¶ÇÔºå‰ΩøÁî® SNOMED CT ‰ª£Á¢º 56265001 Ë°®Á§∫ÂøÉËáüÁóÖ)„ÄÇÊ≠§È†òÂüüÊúâ‰ΩøÁî®ÊúÄÊñ∞ ML Ê®°ÂûãÈÄ≤Ë°åËá™ÂãïÁ∑®Á¢ºÁöÑÂàùÊ≠•Á†îÁ©∂ÔºõÁÑ∂ËÄåÔºåÁî±ÊñºÊ®°ÂûãÁöÑË§áÈõúÊÄßÂíåÂ§ßÂ∞èÔºå‰∏¶Êú™ÂØ¶ÁèæÂØ¶ÈöõÈÉ®ÁΩ≤„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•‰øÉÈÄ≤Ëá™ÂãïÁ∑®Á¢ºÂØ¶ÂãôÁöÑÂèØËÉΩÊÄßÔºåÊàëÂÄëÂú®Êú¨Âú∞ÈõªËÖ¶Ë®≠ÂÆö‰∏≠Êé¢Ë®é‰∫Ü‰∏Ä‰∫õËß£Ê±∫ÊñπÊ°àÔºõÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜË™™ÊòéÂäüËÉΩÂú® AI Ê®°ÂûãÈÄèÊòéÂ∫¶‰∏≠ÁöÑÂäüËÉΩ„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ¨ÈñãÁöÑ MIMIC-III Ë≥áÊñôÂ∫´Âíå HAN/HLAN Á∂≤Ë∑ØÊ®°ÂûãÈÄ≤Ë°å ICD ‰ª£Á¢ºÈ†êÊ∏¨„ÄÇÊàëÂÄëÈÇÑË©¶È©ó‰∫Ü ICD Âíå SNOMED CT Áü•Ë≠òÂ∫´‰πãÈñìÁöÑÂ∞çÊáâ„ÄÇÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåÈÄô‰∫õÊ®°ÂûãÊèê‰æõ‰∫Ü 97.98% ‰ª£Á¢ºÁöÑÊúâÁî®Ë≥áË®ä„ÄÇÈÄôÈ†ÖË™øÊü•ÁµêÊûúÂèØ‰ª•ÁÇ∫ÂØ¶Âãô‰∏≠ÁöÑËá™ÂãïËá®Â∫äÁ∑®Á¢ºÂØ¶‰ΩúÊèê‰æõ‰∏Ä‰∫õË¶ãËß£Ôºå‰æãÂ¶ÇÂú®ÈÜ´Èô¢Áí∞Â¢É‰∏≠ÔºåÁî±Ëá®Â∫äÈÜ´Áîü‰ΩøÁî®ÁöÑÊú¨Âú∞ÈõªËÖ¶ÔºåÂ∞àÊ°àÈ†ÅÈù¢ \url{https://github.com/Glenj01/Medical-Coding}„ÄÇ

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩ (AI) ÊîØÊåÅÁöÑÊ±∫Á≠ñÂà∂ÂÆöÊòØÊú™‰æÜ 6G Á∂≤Ë∑Ø‰∏≠ÁöÑÈóúÈçµÂÖÉÁ¥†ÔºåÂÖ∂‰∏≠Â∞áÂºïÂÖ•ÂéüÁîü AI ÁöÑÊ¶ÇÂøµ„ÄÇÊ≠§Â§ñÔºåAI Âª£Ê≥õÁî®Êñº‰∏çÂêåÁöÑÈóúÈçµÊáâÁî®‰∏≠Ôºå‰æãÂ¶ÇËá™ÂãïÈßïÈßõÂíåÈÜ´ÁôÇË®∫Êñ∑„ÄÇÂú®ÈÄô‰∫õÊáâÁî®‰∏≠Ôºå‰ΩøÁî® AI ‰ΩúÁÇ∫ÈªëÁõíÊ®°ÂûãÊòØÊúâÈ¢®Èö™‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ„ÄÇÂõ†Ê≠§ÔºåÁêÜËß£Âíå‰ø°‰ªªÈÄô‰∫õÊ®°ÂûãÂÅöÂá∫ÁöÑÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇËß£Ê±∫Ê≠§ÂïèÈ°åÁöÑÊñπÊ≥ïÊòØÈñãÁôºÂèØËß£Èáã AI (XAI) Êû∂ÊßãÔºåÊó®Âú®Ëß£ÈáãÈªëÁõíÊ®°ÂûãË°åÁÇ∫ËÉåÂæåÁöÑÈÇèËºØÔºåÂæûËÄåÁ¢∫‰øùÂÖ∂ÊúâÊïà‰∏îÂÆâÂÖ®ÁöÑÈÉ®ÁΩ≤„ÄÇÊúÄËøëÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂü∫ÊñºÊìæÂãïÁöÑ XAI-CHEST Ê°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂Èù¢ÂêëÁÑ°Á∑öÈÄö‰ø°‰∏≠ÁöÑ‰ø°ÈÅì‰º∞Ë®à„ÄÇXAI-CHEST Ê°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÈÄöÈÅéÂú®ÁÑ°ÈóúËº∏ÂÖ•‰∏äÂºïÂÖ•È´òÂô™ËÅ≤‰æÜË≠òÂà•Áõ∏ÈóúÊ®°ÂûãËº∏ÂÖ•„ÄÇÈÄô‰ªΩÊâãÁ®øÊèê‰æõ‰∫Ü XAI-CHEST Ê°ÜÊû∂ÁöÑË©≥Á¥∞ÁêÜË´ñÂü∫Á§é„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÊé®Â∞é‰∫Ü XAI-CHEST ÊêçÂ§±ÂáΩÊï∏ÂíåÂô™ËÅ≤ÈñæÂÄºÂæÆË™øÂÑ™ÂåñÂïèÈ°åÁöÑËß£ÊûêË°®ÈÅîÂºè„ÄÇÂõ†Ê≠§ÔºåË®≠Ë®àÁöÑ XAI-CHEST Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊô∫ËÉΩËº∏ÂÖ•ÁâπÂæµÈÅ∏ÊìáÊñπÊ≥ïÔºåÂèØ‰ª•Âú®ÂÑ™ÂåñÊâÄÁî®Ê®°ÂûãÁöÑÊû∂ÊßãÁöÑÂêåÊôÇÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òÊï¥È´îÊÄßËÉΩ„ÄÇÊ®°Êì¨ÁµêÊûúË°®ÊòéÔºåXAI-CHEST Ê°ÜÊû∂Êèê‰æõ‰∫ÜÊúâÊïàÁöÑËß£ÈáãÔºåÂú®Èôç‰ΩéÊâÄÈúÄÁöÑË®àÁÆóË§áÈõúÂ∫¶ÁöÑÂêåÊôÇÔºåÊèê‰æõ‰∫ÜÊîπÈÄ≤ÁöÑÊØîÁâπÈåØË™§ÁéáÊÄßËÉΩÔºåËÄåÈÄôËàáÂü∫ÊñºÂÇ≥Áµ± DL ÁöÑ‰ø°ÈÅì‰º∞Ë®àÁõ∏ÊØî„ÄÇ

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

ÊëòË¶ÅÔºöËøôÁØáËÆ∫ÊñáÊèêÂá∫‰∫ÜÁî®‰∫é‰ªéËßÜÁΩëËÜúÁúºÂ∫ïÂõæÂÉèËøõË°åÁñæÁóÖÂàÜÁ±ªÁöÑÊâ©Âº†ÊÆãÂ∑ÆÁΩëÁªú (ResNet) Ê®°Âûã„ÄÇÊâ©Âº†Âç∑ÁßØÊª§Ê≥¢Âô®Áî®‰∫éÊõøÊç¢ ResNet Ê®°ÂûãËæÉÈ´òÂ±Ç‰∏≠ÁöÑÊ≠£Â∏∏Âç∑ÁßØÊª§Ê≥¢Âô®ÔºàÊâ©Âº† ResNetÔºâÔºå‰ª•ÊîπÂñÑÊÑüÁü•Âú∫Ôºå‰ªéËÄåÈíàÂØπÁñæÁóÖÂàÜÁ±ªÂØπÊ≠£Â∏∏ ResNet Ê®°ÂûãËøõË°åÊîπËøõ„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜÈááÁî®Ê∑±Â∫¶Â≠¶‰π†ÁöÑËÆ°ÁÆóÊú∫ËæÖÂä©ËØäÊñ≠Â∑•ÂÖ∑ÔºåÂπ∂ÈÄöËøáÂèØËß£ÈáäÁöÑ AI ÊäÄÊúØËøõË°å‰∫ÜÂ¢ûÂº∫„ÄÇËøô‰∫õÊäÄÊúØÊó®Âú®‰ΩøËØ•Â∑•ÂÖ∑ÁöÑÂÜ≥Á≠ñËøáÁ®ãÈÄèÊòéÂåñÔºå‰ªéËÄå‰ΩøÂåªÂ≠¶‰∏ì‰∏ö‰∫∫Â£´ËÉΩÂ§üÁêÜËß£Âíå‰ø°‰ªª AI ÁöÑËØäÊñ≠ÂÜ≥Á≠ñ„ÄÇÂÆÉ‰ª¨‰∏éÂΩì‰ªäÁöÑÂåªÁñó‰øùÂÅ•È¢ÜÂüüÂ∞§‰∏∫Áõ∏ÂÖ≥ÔºåÂú®ËØ•È¢ÜÂüüÔºåÂØπ AI Â∫îÁî®ÁöÑÈÄèÊòéÂ∫¶ÈúÄÊ±Ç‰∏çÊñ≠Â¢ûÈïøÔºå‰ª•Á°Æ‰øùÂÖ∂ÂèØÈù†ÊÄßÂíåÂêà‰πéÈÅìÂæ∑ÁöÑ‰ΩøÁî®„ÄÇÊâ©Âº† ResNet Áî®‰ΩúÊ≠£Â∏∏ ResNet ÁöÑÊõø‰ª£ÂìÅÔºå‰ª•ÊèêÈ´òËßÜÁΩëËÜúÁúºÈÉ®ÁñæÁóÖÁöÑÂàÜÁ±ªÂáÜÁ°ÆÊÄßÂπ∂ÂáèÂ∞ëÊâÄÈúÄÁöÑËÆ°ÁÆóÊó∂Èó¥„ÄÇÊú¨Â∑•‰Ωú‰∏≠‰ΩøÁî®ÁöÑÊï∞ÊçÆÈõÜÊòØÁúºÁßëÁñæÁóÖÊô∫ËÉΩËØÜÂà´ (ODIR) Êï∞ÊçÆÈõÜÔºåËøôÊòØ‰∏Ä‰∏™ÁªìÊûÑÂåñÁöÑÁúºÁßëÊï∞ÊçÆÂ∫ìÔºåÂåÖÂê´ÂÖ´Á±ªÊ∂µÁõñÂ§ßÂ§öÊï∞Â∏∏ËßÅËßÜÁΩëËÜúÁúºÈÉ®ÁñæÁóÖ„ÄÇÊú¨Â∑•‰Ωú‰∏≠‰ΩøÁî®ÁöÑËØÑ‰º∞ÊåáÊ†áÂåÖÊã¨Á≤æÁ°ÆÂ∫¶„ÄÅÂè¨ÂõûÁéá„ÄÅÂáÜÁ°ÆÂ∫¶Âíå F1 ÂæóÂàÜ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÂØπ ResNet-18„ÄÅResNet-34„ÄÅResNet-50„ÄÅResNet-101 Âíå ResNet-152 ‰∫î‰∏™Âèò‰ΩìÁöÑÊ≠£Â∏∏ ResNet Ê®°ÂûãÂíåÊâ©Âº† ResNet Ê®°ÂûãËøõË°å‰∫ÜÊØîËæÉÁ†îÁ©∂„ÄÇ‰∏éÊ≠£Â∏∏ ResNet Áõ∏ÊØîÔºåÊâ©Âº† ResNet Ê®°ÂûãÊòæÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁªìÊûúÔºåÂú® ODIR Â§öÁ±ªÁñæÁóÖÂàÜÁ±ª‰∏≠Ôºå‰∏äËø∞ÂêÑ‰∏™Âèò‰ΩìÁöÑÂπ≥Âùá F1 ÂæóÂàÜ‰∏∫ 0.71„ÄÅ0.70„ÄÅ0.69„ÄÅ0.67 Âíå 0.70„ÄÇ

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°ÂûãÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÊñπÈù¢ÁöÑÂø´ÈÄüÈÄ≤Â±ïÔºå‰ª£Ë°®ËëóÂú®Âä†Âº∑Ë®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÂÄã‰∫∫ÂåñÊ≤ªÁôÇÊñπÈù¢ÈÇÅÂá∫‰∏ÄÂ§ßÊ≠•„ÄÇÁÑ∂ËÄåÔºåÂü∫Á§éÊ®°ÂûãÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈÉ®ÁΩ≤ÈúÄË¶ÅÂ∞çÂÖ∂ÂèØ‰ø°Â∫¶ÈÄ≤Ë°åÂö¥Ê†ºÁöÑÂØ©Êü•ÔºåÂåÖÊã¨Èö±ÁßÅ„ÄÅÁ©©ÂÅ•ÊÄß„ÄÅÂèØÈù†ÊÄß„ÄÅÂèØËß£ÈáãÊÄßÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÁõÆÂâçÈóúÊñºÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠Âü∫Á§éÊ®°ÂûãÁöÑË™øÊü•ÊñáÁçª‰∏≠È°ØÁ§∫Âá∫Áõ∏Áï∂Â§ßÁöÑÂ∑ÆË∑ùÔºåÁâπÂà•ÊòØÂú®ÂèØ‰ø°Â∫¶ÊñπÈù¢„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÈóúÊñºÂü∫Á§éÊ®°ÂûãÂèØ‰ø°Â∫¶ÁöÑË™øÊü•‰∏¶Êú™ÂÖÖÂàÜËß£Ê±∫ÂÖ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüü‰∏≠ÁöÑÁâπÂÆöËÆäÂåñÂíåÊáâÁî®„ÄÇÊú¨Ë™øÊü•Êó®Âú®ÈÄöÈÅéÊèêÂá∫ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠‰ΩøÁî®ÁöÑÂü∫Á§éÊ®°ÂûãÁöÑÊñ∞ÂàÜÈ°ûÊ≥ï‰∏¶ÂàÜÊûêÁ¢∫‰øùÂÖ∂ÂèØ‰ø°Â∫¶ÁöÑÈóúÈçµÂãïÊ©üÔºå‰æÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩ„ÄÇÊàëÂÄëÂõûÈ°ß‰∫ÜÂü∫Á§éÊ®°ÂûãÂú®‰∏ªË¶ÅÈÜ´Â≠∏ÂΩ±ÂÉèÊáâÁî®‰∏≠ÁöÑÁï∂ÂâçÁ†îÁ©∂ÔºåÈáçÈªûÈóúÊ≥®ÂàÜÂâ≤„ÄÅÈÜ´ÁôÇÂ†±ÂëäÁîüÊàê„ÄÅÈÜ´ÁôÇÂïèÈ°åÂíåÂõûÁ≠î (Q&A) ‰ª•ÂèäÁñæÁóÖË®∫Êñ∑„ÄÇÈÄô‰∫õÈ†òÂüü‰πãÊâÄ‰ª•Ë¢´Âº∑Ë™øÔºåÊòØÂõ†ÁÇ∫ËàáÂÖ∂‰ªñÊáâÁî®Áõ∏ÊØîÔºåÂÆÉÂÄëÂ∑≤Á∂ìÁúãÂà∞Áõ∏Â∞çÊàêÁÜü‰∏îÂ§ßÈáèÁöÑÂü∫Á§éÊ®°Âûã„ÄÇÊàëÂÄëÂ∞àÊ≥®ÊñºÊé¢Ë®éÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÊâãÁ®ø‰∏≠ÂèØ‰ø°Â∫¶ÁöÑÊñáÁçª„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÁÇ∫ÊØèÂÄãÊáâÁî®ÊßãÂª∫ÂèØ‰ø°Âü∫Á§éÊ®°ÂûãÁöÑË§áÈõúÊåëÊà∞ÔºåÁ∏ΩÁµê‰∫ÜÁï∂ÂâçÈóúÊ≥®ÈªûÂíåÂ¢ûÂº∑ÂèØ‰ø°Â∫¶ÁöÑÁ≠ñÁï•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄô‰∫õÊ®°ÂûãÂú®Èù©Êñ∞ÊÇ£ËÄÖË≠∑ÁêÜÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÂº∑Ë™ø‰∫ÜÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠ÊúùËëóÂèØ‰ø°Ë≥¥ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈÇÅÈÄ≤ÁöÑÂøÖË¶ÅÊÄßÔºå‰∏¶ÂÄ°Â∞é‰∏ÄÁ®ÆÂπ≥Ë°°ÁöÑÊñπÊ≥ïÔºåÊó¢ËÉΩ‰øÉÈÄ≤ÂâµÊñ∞ÔºåÂèàËÉΩÁ¢∫‰øùÈÅìÂæ∑ÂíåÂÖ¨Âπ≥ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô„ÄÇ

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

ÊëòË¶ÅÔºöÂ∫äÈÇäË∂ÖÈü≥Ê≥¢ (POCUS) ÊòØËá®Â∫äÈÜ´Â∏´Âú®ÊÇ£ËÄÖÂ∫äÈÇäÈÄ≤Ë°åÂíåËß£ËÆÄË∂ÖÈü≥Ê≥¢ÊéÉÊèèÁöÑÂØ¶Âãô„ÄÇÁÑ∂ËÄåÔºåËß£ËÆÄÈÄô‰∫õÂΩ±ÂÉèÊâÄÈúÄÁöÑÂ∞àÊ•≠Áü•Ë≠òÁõ∏Áï∂ÂèØËßÄÔºåËÄå‰∏îÂú®Á∑äÊÄ•ÊÉÖÊ≥Å‰∏ãÂèØËÉΩ‰∏¶ÈùûÈö®ÊôÇÂÖ∑ÂÇô„ÄÇÈÄôÁ®ÆÁèæÂØ¶ÊÉÖÊ≥Å‰ΩøÂæóÊ©üÂô®Â≠∏ÁøíÂàÜÈ°ûÂô®Á≠âÊºîÁÆóÊ≥ïÂ∞çÊñºÂä†Âº∑‰∫∫È°ûÊ±∫Á≠ñËÆäÂæóÊ•µÁÇ∫ÊúâÂÉπÂÄº„ÄÇPOCUS Ë£ùÁΩÆÊ≠£‰ª•ÂêàÁêÜÊàêÊú¨Êé®Âá∫ÔºåÂ∞∫ÂØ∏ÁÇ∫ÊâãÊ©üÂ§ßÂ∞è„ÄÇÂ∞á POCUS Ë£ùÁΩÆËΩâËÆäÁÇ∫ÊïëÁîüÂ∑•ÂÖ∑ÁöÑÊåëÊà∞Âú®ÊñºÔºåËß£ËÆÄË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÈúÄË¶ÅÂ∞àÈñÄË®ìÁ∑¥ÂíåÁ∂ìÈ©ó„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÂèñÂæóÊ≠£ÂêëË®ìÁ∑¥ÂΩ±ÂÉèÁöÑÂõ∞Èõ£Â∫¶‰ª£Ë°®ËëóÂª∫ÁΩÆÊúâÊïàÁéá‰∏îÊ∫ñÁ¢∫ÁöÑÂàÜÈ°ûÂô®ÁöÑ‰∏ÄÂ§ßÈöúÁ§ô„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂòóË©¶Êé¢Ë®éÁöÑÂïèÈ°åÊòØÂ¶Ç‰ΩïÊé¢Á¥¢Á≠ñÁï•Ôºå‰ª•ÊèêÈ´ò‰ΩøÁî®Á®ÄÁñèË≥áÊñôË®ìÁ∑¥ÁöÑÂàÜÈ°ûÂô®ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÂÅáË®≠‰ΩøÁî®Â∞ëÊï∏Ë≥áÊñôÂØ¶‰æãÈÄ≤Ë°åË®ìÁ∑¥ÂèØËÉΩ‰∏çË∂≥‰ª•ËÆìÂàÜÈ°ûÂô®Ê¶ÇÊã¨ÔºåÂ∞éËá¥ÂÆÉÂÄëÈÅéÂ∫¶Êì¨Âêà„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ΩøÁî®ÂèØËß£Èáã AI Â¢ûÂº∑ÊñπÊ≥ïÔºå‰ª•ÂçîÂä©ÊºîÁÆóÊ≥ïÂæûËºÉÂ∞ëÁöÑË≥áÊñô‰∏≠Â≠∏ÁøíÊõ¥Â§öÔºå‰∏¶ÊΩõÂú®ÂçîÂä©ÂàÜÈ°ûÂô®Êõ¥Â•ΩÂú∞Ê¶ÇÊã¨„ÄÇ

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÁæéÂúãË¶ãË≠â‰∫ÜÈõªÂ≠êÁÖôÊàñÈõªÂ≠êÈ¶ôËè∏‰ΩøÁî®ÁéáÂ§ßÂπÖÊøÄÂ¢ûÔºåÂ∞éËá¥ÈõªÂ≠êÁÖôÂíåÈõªÂ≠êÁÖô‰ΩøÁî®Áõ∏ÈóúËÇ∫ÊêçÂÇ∑ (EVALI) ÁóÖ‰æãÈ°ØËëóÂ¢ûÂä†ÔºåÂú® 2019 Âπ¥ EVALI ÁàÜÁôºÊúüÈñìÈÄ†Êàê‰ΩèÈô¢ÂíåÊ≠ª‰∫°ÔºåÂá∏È°Ø‰∫ÜÁêÜËß£ÈõªÂ≠êÁÖôË°åÁÇ∫ÂíåÂà∂ÂÆöÊúâÊïàÊàíËè∏Á≠ñÁï•ÁöÑËø´ÂàáÊÄß„ÄÇÁî±ÊñºÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞ÁöÑÊôÆÂèäÔºåÂÖ®ÁêÉË∂ÖÈÅé 47 ÂÑÑ‰ΩøÁî®ËÄÖ‰ΩøÁî®ÂÆÉÂÄëÈÄ≤Ë°åÈÄ£Áµê„ÄÅÊ∫ùÈÄö„ÄÅÊñ∞ËÅûÂíåÂ®õÊ®ÇÔºåÂÖ∂‰∏≠ÂæàÂ§ß‰∏ÄÈÉ®ÂàÜËàáÂÅ•Â∫∑Áõ∏ÈóúÔºåÂõ†Ê≠§Â∞áÁ§æÁæ§Â™íÈ´îË≥áÊñôÂª∫Á´ãÁÇ∫ÂÖ¨ÂÖ±Ë°õÁîüÁ†îÁ©∂‰∏≠ÁÑ°ÂÉπÁöÑÊúâÊ©üË≥áÊñôË≥áÊ∫ê„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂæû Reddit ‰∏ä‰∏ÄÂÄãÈõªÂ≠êÁÖôÂ≠êÁ§æÁæ§‰∏≠ÊèêÂèñ‰∏ÄÂÄãÁØÑ‰æãË≥áÊñôÈõÜÔºå‰ª•ÂàÜÊûê‰ΩøÁî®ËÄÖÁöÑÊàíÈõªÂ≠êÁÖôÊÑèÂúñ„ÄÇÂà©Áî® OpenAI ÊúÄÊñ∞ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã GPT-4 ÈÄ≤Ë°åÂè•Â≠êÂ±§Á¥öÁöÑÊàíÈõªÂ≠êÁÖôÊÑèÂúñÂÅµÊ∏¨ÔºåÊú¨Á†îÁ©∂ÊØîËºÉ‰∫ÜÊ≠§Ê®°ÂûãÁöÑÁµêÊûúËàáÂ§ñË°å‰∫∫ÂíåËá®Â∫äÂ∞àÂÆ∂Ë®ªËß£„ÄÇ‰ΩøÁî®‰∏çÂêåÁöÑÊèêÁ§∫Á≠ñÁï•Ôºå‰æãÂ¶ÇÈõ∂Ê¨°Â≠∏Áøí„ÄÅ‰∏ÄÊ¨°Â≠∏Áøí„ÄÅÂ∞ëÊ¨°Â≠∏ÁøíÂíåÊÄùËÄÉÈèàÊèêÁ§∫ÔºåÊàëÂÄëÈñãÁôº‰∫Ü 8 ÂÄãÊèêÁ§∫ÔºåË©≥Á¥∞Á®ãÂ∫¶‰∏çÂêåÔºåÂêë GPT-4 Ëß£Èáã‰ªªÂãôÔºå‰∏¶Ë©ï‰º∞ÈÄô‰∫õÁ≠ñÁï•ÂΩºÊ≠§‰πãÈñìÁöÑÊïàËÉΩ„ÄÇÈÄô‰∫õÂàùÊ≠•ÁôºÁèæÂº∑Ë™ø‰∫Ü GPT-4 Âú®Á§æÁæ§Â™íÈ´îË≥áÊñôÂàÜÊûê‰∏≠ÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÂú®Ë≠òÂà•‰∫∫È°ûÂÅµÊ∏¨ÂèØËÉΩÁÑ°Ê≥ïÂØüË¶∫ÁöÑ‰ΩøÁî®ËÄÖÂæÆÂ¶ôÊÑèÂúñÊñπÈù¢„ÄÇ

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

ÊëòË¶ÅÔºö<paragraph>‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÁõÆÂâçÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰æùË≥¥ÊñºÁº∫‰πèÂèØËß£ÈáãÊÄßÁöÑÈªëÁõíÊ©üÂô®Â≠∏ÁøíÊ®°Âûã„ÄÇÂèØËß£ÈáãÊÄß‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÈ†òÂüüËá¥ÂäõÊñºËß£Ê±∫ÈÄôÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÈÄôÂú®ÈáëËûç„ÄÅÊ≥ïÂæãÂíåÂÅ•Â∫∑Á≠âÈ´òÈ¢®Èö™È†òÂüüËá≥ÈóúÈáçË¶Å„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÁØÑÁñáË´ñÂÆöÁæ© AI Ê®°ÂûãÂèäÂÖ∂ÂèØËß£ÈáãÊÄßÁöÑÊñπÊ≥ï„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊé°Áî®ÁµÑÂêàÊ®°ÂûãÁöÑÊ¶ÇÂøµÔºåÂÆÉ‰ª•ÂΩ¢ÂºèÂº¶ÂúñÁöÑÂΩ¢ÂºèÁúãÂæÖÊ®°ÂûãÔºåÈÄô‰∫õÂº¶ÂúñÊçïÁç≤‰∫ÜÊ®°ÂûãÁöÑÊäΩË±°ÁµêÊßãÂèäÂÖ∂ÂÖ∑È´îÂØ¶Áèæ„ÄÇÈÄôÁ®ÆÁ∂úÂêàËßÄÈªûÂåÖÂê´‰∫ÜÁ¢∫ÂÆöÊÄß„ÄÅÊ¶ÇÁéáÊÄßÂíåÈáèÂ≠êÊ®°Âûã„ÄÇÊàëÂÄëÂ∞áÂêÑÁ®Æ AI Ê®°Âûã‰ΩúÁÇ∫ÁµÑÂêàÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºåÂåÖÊã¨Á∑öÊÄßÂíåÂü∫ÊñºË¶èÂâáÁöÑÊ®°Âûã„ÄÅÔºàÈÅûËø¥ÔºâÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅTransformer„ÄÅVAEÔºå‰ª•ÂèäÂõ†ÊûúÂíå DisCoCirc Ê®°Âûã„ÄÇ
Êé•‰∏ã‰æÜÔºåÊàëÂÄëÊ†πÊìöÊ®°ÂûãÁöÑÁµÑÂêàÁµêÊßãÁµ¶Âá∫Ê®°ÂûãËß£ÈáãÁöÑÂÆöÁæ©ÔºåÂ±ïÁ§∫Â¶Ç‰ΩïÂàÜÊûêÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰∏¶‰ΩøÁî®ÂÆÉ‰æÜÊæÑÊ∏Ö XAI ‰∏≠ÁöÑÂ∏∏Ë¶ã‰∏ªÈ°å„ÄÇÊàëÂÄëÁôºÁèæÔºåËÆìÊ®ôÊ∫ñÁöÑ„ÄåÂÖßÂú®ÂèØËß£Èáã„ÄçÊ®°ÂûãÂ¶ÇÊ≠§ÈÄèÊòéÁöÑÂéüÂõ†Âú®ÂúñË°®‰∏≠Ë°®ÁèæÂæóÊúÄÁÇ∫Ê∏ÖÊ•ö„ÄÇÈÄôÂºïÂ∞éÊàëÂÄëÂæóÂá∫Êõ¥‰∏ÄËà¨ÁöÑÁµÑÂêàÂèØËß£ÈáãÔºàCIÔºâÊ®°ÂûãÊ¶ÇÂøµÔºåÂÆÉÂè¶Â§ñÈÇÑÂåÖÊã¨Âõ†Êûú„ÄÅÊ¶ÇÂøµÁ©∫ÈñìÂíå DisCoCirc Ê®°Âûã„ÄÇ
Êé•‰∏ã‰æÜÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü CI Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÂÑ™Âã¢„ÄÇÈ¶ñÂÖàÔºåÂÆÉÂÄëÁöÑÁµÑÂêàÁµêÊßãÂÖÅË®±Ë®àÁÆóÂÖ∂‰ªñÊÑüËààË∂£ÁöÑÈáèÔºå‰∏¶ÂèØËÉΩÈÄöÈÅéÂåπÈÖçÊ®°ÂûãÁöÑÁµêÊßã‰æÜ‰øÉÈÄ≤ÂæûÊ®°ÂûãÂà∞Ë¢´Âª∫Ê®°ÁèæË±°ÁöÑÊé®ÁêÜ„ÄÇÂÖ∂Ê¨°ÔºåÂÆÉÂÄëÂÖÅË®±Â∞çÂÖ∂Ë°åÁÇ∫ÈÄ≤Ë°åÂúñËß£Ë™™ÊòéÔºåÈÄô‰∫õË™™ÊòéÂü∫ÊñºÂΩ±ÈüøÁ¥ÑÊùü„ÄÅÂúñËß£ÊâãË°ìÂíåÈáçÂØ´Ë™™Êòé„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑË®±Â§öÊú™‰æÜÊñπÂêëÔºåÊèêÂá∫‰∫ÜÂ¶Ç‰ΩïÂú®ÂØ¶Ë∏ê‰∏≠Â≠∏ÁøíÈÄôÁ®ÆÊúâÊÑèÁæ©ÁöÑÁµêÊßãÂåñÊ®°ÂûãÁöÑÂïèÈ°å„ÄÇ</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

ÊëòË¶ÅÔºöÂÖÉÂÆáÂÆôÁöÑÊ¶ÇÂøµÂú®ÂêÑÂÄãÈ†òÂüüÈÉΩÂÇôÂèóÈóúÊ≥®ÔºåÂÖ∂ÈáçË¶ÅÊáâÁî®‰πã‰∏Ä‰æøÊòØÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÂÖÉÂÆáÂÆôÊúâÂ∑®Â§ßÁöÑÊΩõÂäõÈÄèÈÅéÊîπËÆäÁóÖÊÇ£ÁÖßË≠∑„ÄÅÈÜ´Â≠∏ÊïôËÇ≤Ôºå‰ª•ÂèäÊïôÂ≠∏/Â≠∏ÁøíÂíåÁ†îÁ©∂ÁöÑÊñπÂºè‰æÜËΩâÂûãÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÊú¨Á†îÁ©∂ÁöÑÁõÆÁöÑÊòØÊèê‰æõÂÖÉÂÆáÂÆôÂü∫Êú¨Ê¶ÇÂøµÂíåÂü∫Á§éÊäÄË°ìÁöÑ‰ªãÁ¥π„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂÖÉÂÆáÂÆôÂú®ÈÜ´ÁôÇ‰øùÂÅ•ËÉåÊôØ‰∏ãÁöÑÂÑ™Áº∫ÈªûÔºå‰∏¶ÂæûÊäÄË°ìÂíå AI ÁöÑËßíÂ∫¶ÂàÜÊûêÂÖ∂ÊΩõÂäõ„ÄÇÁâπÂà•ÊòØÔºåË®éË´ñ‰∫ÜÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁöÑËßíËâ≤ÔºõÊàëÂÄëÂ∞áË™™ÊòéÂ¶Ç‰ΩïÂ∞áÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÊáâÁî®ÊñºÂÖÉÂÆáÂÆôÁî¢ÁîüÁöÑË≥áÊñôÔºå‰ª•Áç≤ÂæóÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®ÊñπÈù¢ÁöÑÊõ¥‰Ω≥Ë¶ãËß£„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄèÈÅéÊé¢Ë®éÂçÄÂ°äÈèàÁ≠âÊñ∞ËààÊäÄË°ìÔºå‰∏¶Ëß£Ê±∫Èö±ÁßÅÂïèÈ°åÔºå‰æÜÊé¢Ë®éÂÖÉÂÆáÂÆôÂú®ÈÜ´ÁôÇ‰øùÂÅ•ÊñπÈù¢ÁöÑÊú™‰æÜÈ°òÊôØ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁôºÁèæÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÂÖÉÂÆáÂÆôÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊáâÁî®Ôºå‰ª•ÂèäÂÖ∂Âú®ÈÜ´ÁôÇÊúçÂãôÊèê‰æõÊñπÈù¢ÁôºÊèÆÈù©ÂëΩÊÄßËÆäÈù©ÁöÑÊΩõÂäõ„ÄÇ

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

ÊëòË¶ÅÔºöÊÖ¢ÊÄßËÖéËáüÁóÖÔºàCKDÔºâÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÁöÑÊÖ¢ÊÄßÁñæÁóÖÔºåÊ≤íÊúâÂ∑≤Áü•ÁöÑÊúÄÁµÇÁôÇÊ≥ï‰∏îÁôºÁóÖÁéáÂæàÈ´ò„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÈÄ≤Ë°åÊÄßÊÖ¢ÊÄßËÖéËáüÁóÖÔºàCKDÔºâÊòØ‰∏ÄÁ®ÆÁï∞Ë≥™ÊÄßÁñæÁóÖÔºåÊúÉÈ°ØËëóÂΩ±ÈüøËÖéËáüÁµêÊßãÂíåÂäüËÉΩÔºåÊúÄÁµÇÂ∞éËá¥ËÖéË°∞Á´≠„ÄÇÈö®ËëóÊôÇÈñìÁöÑÊé®ÁßªÔºåÊÖ¢ÊÄßËÖéËáüÁóÖÂ∑≤ÂæûÂΩ±ÈüøÂ∞ëÊï∏‰∫∫ÁöÑËá¥ÂëΩÁñæÁóÖËΩâËÆäÁÇ∫‰∏ÄÁ®ÆÂö¥ÈáçÁ®ãÂ∫¶‰∏çÂêåÁöÑÂ∏∏Ë¶ãÁñæÁóÖ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁõÆÊ®ôÊòØ‰ΩøÁî®ÈõÜÊàêÂ≠∏ÁøíÂíåÂèØËß£ÈáãÁöÑ AI ÈÄ≤Ë°åÊó©ÊúüÈ†êÂæåÂíå CKD Ê™¢Ê∏¨Ôºå‰∏¶Ë¶ñË¶∫Âåñ‰∏ªÂ∞éÁâπÂæµ„ÄÅÁâπÂæµÂàÜÊï∏ÂíåË°®ÁèæÂá∫ÁöÑÂÄº„ÄÇÁÇ∫Ê≠§ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ AI È©ÖÂãïÁöÑÈ†êÊ∏¨ÂàÜÊûêÊñπÊ≥ïÔºå‰ª•Âπ´Âä©Ëá®Â∫äÈÜ´ÁîüÁÇ∫ÂÄãÂà•ÊÇ£ËÄÖÈñãÂÖ∑ÁîüÊ¥ªÊñπÂºè‰øÆÊîπÂª∫Ë≠∞Ôºå‰ª•Èôç‰ΩéÈÄôÁ®ÆÁñæÁóÖÁöÑÈÄ≤Â±ïÈÄüÂ∫¶„ÄÇÊàëÂÄëÁöÑÊï∏ÊìöÈõÜÊòØÂæû CKD ÊÇ£ËÄÖÂíåÂÅ•Â∫∑ÂèóË©¶ËÄÖÁöÑË∫´È´îÁîüÂëΩÈ´îÂæµ‰∏≠Êî∂ÈõÜÁöÑÔºå‰ª•Ê∫ñÁ¢∫ÈñãÁôºÊàëÂÄëÊèêÂá∫ÁöÑ AI È©ÖÂãïÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÂú®ÈÄôÊñπÈù¢ÔºåÊèê‰æõ‰∫ÜË°ÄÊ∂≤ÂíåÂ∞øÊ∂≤Ê™¢Ê∏¨ÁµêÊûúÔºå‰∏¶ÊáâÁî®Âü∫ÊñºÈõÜÊàêÊ®πÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÈ†êÊ∏¨Êú™ÁôºÁèæÁöÑ CKD ÁóÖ‰æã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ∂ìÈÅéËàáËÖéËáüÁßëÈÜ´ÁîüÁöÑÈï∑ÊúüË´ÆË©¢ÂæåÂæóÂà∞È©óË≠â„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÂíåËß£ÈáãÁµêÊûúËàáÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠ÁèæÊúâÁöÑÂèØËß£Èáã AI ÊáâÁî®ÈÄ≤Ë°å‰∫ÜÊØîËºÉÔºåÂåÖÊã¨ CKD„ÄÇÊØîËºÉË°®ÊòéÔºåÊàëÂÄëÈñãÁôºÁöÑ AI Ê®°ÂûãÔºåÁâπÂà•ÊòØÈö®Ê©üÊ£ÆÊûóÊ®°ÂûãÔºåÂ∑≤Á∂ìÁ¢∫ÂÆö‰∫ÜÊØî XgBoost Êõ¥Â§ö‰ΩúÁÇ∫ÈáçË¶ÅË≤¢ÁçªËÄÖÁöÑÁâπÂæµ„ÄÇÂèØËß£ÈáãÊÄß (I) Ë°°ÈáèÈáçË¶ÅÁâπÂæµËàáÊé©ËìãÁâπÂæµÁöÑÊØîÁéáÔºåË°®ÊòéÊàëÂÄëÁöÑ XgBoost Ê®°ÂûãÂú®ÈÄôÂÄãÊåáÊ®ô‰∏≠Áç≤Âæó‰∫ÜÊõ¥È´òÁöÑÂàÜÊï∏ÔºåÁâπÂà•ÊòØ 98% ÁöÑ‰øùÁúüÂ∫¶Ôºå‰∏¶‰∏îÂú® FII ÊåáÊï∏‰∏≠Ëá™ÁÑ∂È´òÊñºÁ´∂Áà≠Ê®°Âûã„ÄÇ

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

ÊëòË¶ÅÔºöÂøÉÁêÜÂÅ•Â∫∑ÊßãÊàê‰∫Ü‰∏ÄÈ†ÖË§áÈõú‰∏îÊôÆÈÅçÁöÑÂÖ®ÁêÉÊåëÊà∞ÔºåÂΩ±Èüø‰∫ÜÊï∏ÁôæËê¨‰∫∫ÁöÑÁîüÊ¥ªÔºå‰∏¶Á∂ìÂ∏∏Â∞éËá¥Âö¥ÈáçÁöÑÂæåÊûú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂæπÂ∫ïÁöÑË™øÊü•Ôºå‰ª•Êé¢Á¥¢Êï∏ÊìöÁßëÂ≠∏„ÄÅ‰∫∫Â∑•Êô∫ÊÖßÂíåÂøÉÁêÜ‰øùÂÅ•ÁöÑ‰∫§ÈõÜÔºåÈáçÈªûÈóúÊ≥®ÈÄöÈÅéÁ∑ö‰∏äÁ§æ‰∫§Â™íÈ´î (OSM) ÈÄ≤Ë°åÂøÉÁêÜÁñæÁóÖÊ™¢Ê∏¨ÁöÑÊúÄÊñ∞ÁôºÂ±ï„ÄÇÂæàÂ§ß‰∏ÄÈÉ®ÂàÜ‰∫∫Âè£Á©çÊ•µÂèÉËàá OSM Âπ≥Âè∞ÔºåÂâµÈÄ†‰∫Ü‰∏ÄÂÄãÈæêÂ§ßÁöÑ‰∫∫Âì°Ë≥áÊñôÂ∫´ÔºåÂ∞çÂøÉÁêÜÂÅ•Â∫∑ÂàÜÊûêÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂÇ≥Áµ±ÁöÑË®∫Êñ∑ÊñπÊ≥ï„ÄÅÊúÄÂÖàÈÄ≤ÁöÑË≥áÊñôÂíå AI È©ÖÂãïÁöÑÁ†îÁ©∂Ôºå‰ª•ÂèäÂøÉÁêÜ‰øùÂÅ•‰∏≠ÂèØËß£Èáã AI (XAI) Ê®°ÂûãÁöÑÂá∫Áèæ„ÄÇÊàëÂÄëÂõûÈ°ß‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºåÁâπÂà•ÊòØÈÇ£‰∫õÂü∫ÊñºÁèæ‰ª£Ê∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÔºåÂêåÊôÇÂº∑Ë™ø‰∫ÜÈÜ´ÁôÇ‰øùÂÅ• AI Ê®°Âûã‰∏≠ÂèØËß£ÈáãÊÄßÁöÑÂøÖË¶ÅÊÄß„ÄÇÂØ¶È©óË®≠Ë®àÈÉ®ÂàÜÊèê‰æõ‰∫ÜÂ∞çÊôÆÈÅçÂÅöÊ≥ïÁöÑË¶ãËß£ÔºåÂåÖÊã¨ÂèØÁî®ÁöÑË≥áÊñôÈõÜÂíåË©ï‰º∞ÊñπÊ≥ï„ÄÇÊàëÂÄëÈÇÑÊâæÂá∫Ë©≤È†òÂüüÁöÑ‰∏ªË¶ÅÂïèÈ°åÂíåÊåëÊà∞Ôºå‰∏¶ÊèêÂá∫‰∫ÜÊúâÂ∏åÊúõÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêë„ÄÇÁî±ÊñºÂøÉÁêÜÂÅ•Â∫∑Ê±∫Á≠ñÈúÄË¶ÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÈÅìÂæ∑ËÄÉÈáèÔºåÊú¨ÊñáÊúâÂä©ÊñºÊé®ÈÄ≤ÂøÉÁêÜ‰øùÂÅ•‰∏≠ÈÄèÈÅéÁ§æ‰∫§Â™íÈ´îÊé®ÈÄ≤ XAI ÁöÑÊåÅÁ∫åË®éË´ñ„ÄÇÈÄôË£°ÊèêÂá∫ÁöÑÂÖ®Èù¢Ê¶ÇËø∞Êó®Âú®ÂºïÂ∞éÁ†îÁ©∂‰∫∫Âì°„ÄÅÂæûÊ•≠‰∫∫Âì°ÂíåÊîøÁ≠ñÂà∂ÂÆöËÄÖÁôºÂ±ïÂøÉÁêÜÁñæÁóÖÊ™¢Ê∏¨È†òÂüü„ÄÇ

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

ÊëòË¶ÅÔºö<paragraph>ÈÜ´ÁôÇÁÖßË≠∑‰∏≠ÈúÄË¶Å AI ËºîÂä©ÁöÑËá®Â∫äË®∫Êñ∑„ÄÇÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏î‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂΩ±ÂÉèÂàÜÊûê„ÄÇÊúÄËøëÈñãÁôºÁöÑÂãïÊÖã‰∏çÁ¢∫ÂÆöÂõ†ÊûúÈóú‰øÇÂúñ (DUCG) ÊñπÊ≥ïÊòØÂõ†ÊûúÈ©ÖÂãïÁöÑ„ÄÅÂèØËß£ÈáãÁöÑÔºå‰∏¶‰∏îÂú®‰∏çÂêåÁöÑÊáâÁî®Â†¥ÊôØ‰∏≠ÊòØ‰∏çËÆäÁöÑÔºåÊ≤íÊúâË≥áÊñôÊî∂ÈõÜ„ÄÅÊ®ôË®ò„ÄÅÊì¨Âêà„ÄÅÈö±ÁßÅ„ÄÅÂÅèË¶ã„ÄÅÊ¶ÇÂåñ„ÄÅÈ´òÊàêÊú¨ÂíåÈ´òËÉΩËÄóÁöÑÂïèÈ°å„ÄÇÈÄöÈÅéËá®Â∫äÂ∞àÂÆ∂Âíå DUCG ÊäÄË°ì‰∫∫Âì°‰πãÈñìÁöÑÂØÜÂàáÂêà‰ΩúÔºåÊßãÂª∫‰∫ÜÊ∂µËìã 54 ÂÄã‰∏ªË®¥ÁöÑ 46 ÂÄã DUCG Ê®°Âûã„ÄÇÂèØ‰ª•Âú®Ê≤íÊúâÂàÜÊµÅÁöÑÊÉÖÊ≥Å‰∏ãË®∫Êñ∑Âá∫ 1,000 Â§öÁ®ÆÁñæÁóÖ„ÄÇÂú®ÊáâÁî®ÊñºÂØ¶Èöõ‰∏ñÁïå‰πãÂâçÔºå46 ÂÄã DUCG Ê®°ÂûãÂ∑≤Áî±Á¨¨‰∏âÊñπÈÜ´Èô¢ÂõûÊ∫ØÊÄßÈ©óË≠â„ÄÇÈ©óË≠âÁöÑË®∫Êñ∑Á≤æÂ∫¶‰∏ç‰ΩéÊñº 95%ÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÁΩïË¶ãÁñæÁóÖÂú®ÂÖßÁöÑÊØèÁ®ÆÁñæÁóÖÁöÑË®∫Êñ∑Á≤æÂ∫¶‰∏ç‰ΩéÊñº 80%„ÄÇÈ©óË≠âÂæåÔºå46 ÂÄã DUCG Ê®°ÂûãÂ∑≤Âú®‰∏≠ÂúãÂØ¶ÈöõÊáâÁî®„ÄÇÂ∑≤Á∂ìÂü∑Ë°å‰∫ÜË∂ÖÈÅé‰∏ÄÁôæËê¨ÂÄãÁúüÂØ¶Ë®∫Êñ∑Ê°à‰æãÔºåÂÉÖÁôºÁèæ 17 ÂÄã‰∏çÊ≠£Á¢∫ÁöÑË®∫Êñ∑„ÄÇÁî±Êñº DUCG ÁöÑÈÄèÊòéÊÄßÔºåÁôºÁèæ‰∏¶Á≥æÊ≠£‰∫ÜÂ∞éËá¥‰∏çÊ≠£Á¢∫Ë®∫Êñ∑ÁöÑÈåØË™§„ÄÇÈ†ªÁπÅÊáâÁî® DUCG ÁöÑËá®Â∫äÈÜ´ÁîüÁöÑË®∫Êñ∑ËÉΩÂäõÂæóÂà∞‰∫ÜÈ°ØËëóÊèêÈ´ò„ÄÇÂú®‰ªãÁ¥π‰∫ÜÂâçÈù¢ÊèêÂá∫ÁöÑ DUCG ÊñπÊ≥ïË´ñ‰πãÂæåÔºåÊèêÂá∫‰∫ÜÊΩõÂú®ÂÅ•Â∫∑Ê™¢Êü•ÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÔºå‰∏¶ÊèêÂèñ‰∫Ü DUCG ÁöÑÈóúÈçµÊÄùÊÉ≥„ÄÇ</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

ÊëòË¶ÅÔºöÁ≤æÁ¢∫‰∏îÂèäÊôÇÂú∞ÂÅµÊ∏¨‰π≥ÁôåÂ∞çÊñºÊîπÂñÑÊÇ£ËÄÖÈ†êÂæåËá≥ÈóúÈáçË¶Å„ÄÇË®∫Êñ∑ÊñπÊ≥ïÂÇ≥Áµ±‰∏ä‰æùË≥¥ÊñºÂñÆ‰∏ÄÊ®°ÂºèÊñπÊ≥ïÔºõÁÑ∂ËÄåÔºåÈÜ´ÁôÇË≥áÊñôÂàÜÊûêÊ≠£Âú®Êï¥ÂêàË∂ÖË∂äÂÇ≥Áµ±ÂΩ±ÂÉèÁöÑÂêÑÁ®ÆË≥áÊñô‰æÜÊ∫ê„ÄÇ‰ΩøÁî®Êï¥ÂêàÂΩ±ÂÉèÂíåÈùûÂΩ±ÂÉèË≥áÊñôÁöÑÂ§öÊ®°ÂºèÊäÄË°ìÔºåÊ®ôË™åËëó‰π≥ÁôåË®∫Êñ∑ÁöÑËÆäÈù©ÊÄßÈÄ≤Â±ï„ÄÇÊú¨ÁØáÁ∂úËø∞ÁöÑÁõÆÁöÑÊòØÊé¢Ë®éÂ§öÊ®°ÂºèÊäÄË°ìÁöÑÊñ∞ËààÈ†òÂüüÔºåÁâπÂà•ÊòØÂ∞áÁµÑÁπîÁóÖÁêÜÂ≠∏ÂΩ±ÂÉèËàáÈùûÂΩ±ÂÉèË≥áÊñôËûçÂêà„ÄÇÊ≠§Â§ñÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∞áÁî®ÊñºÈó°ÊòéË§áÈõúÊºîÁÆóÊ≥ïÁöÑÊ±∫Á≠ñÈÅéÁ®ãÔºåÂº∑Ë™øË®∫Êñ∑ÈÅéÁ®ã‰∏≠ÂèØËß£ÈáãÊÄßÁöÑÂøÖË¶ÅÊÄß„ÄÇÊú¨Á∂úËø∞Âà©Áî®Â§öÊ®°ÂºèË≥áÊñô‰∏¶Âº∑Ë™øÂèØËß£ÈáãÊÄßÔºå‰ª•ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄß„ÄÅËá®Â∫äÈÜ´Â∏´ÁöÑ‰ø°ÂøÉÂíåÊÇ£ËÄÖÂèÉËàáÂ∫¶ÔºåÊúÄÁµÇ‰øÉÈÄ≤‰π≥ÁôåÊõ¥ÂÄã‰∫∫ÂåñÁöÑÊ≤ªÁôÇÁ≠ñÁï•ÔºåÂêåÊôÇ‰πüÊâæÂá∫Â§öÊ®°ÂºèÂíåÂèØËß£ÈáãÊÄßÁöÑÁ†îÁ©∂Â∑ÆË∑ùÔºåÂºïÂ∞éÊú™‰æÜÁöÑÁ†îÁ©∂Ôºå‰∏¶ÁÇ∫Ë©≤È†òÂüüÁöÑÁ≠ñÁï•ÊñπÂêëÂÅöÂá∫Ë≤¢Áçª„ÄÇ

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

ÊëòË¶ÅÔºöËá™Ê≥®ÊÑèÂäõÊ©üÂà∂Â∑≤Ë¢´Êé°Áî®ÊñºÂ§öÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑË®äÊÅØÂÇ≥ÈÅûÁ•ûÁ∂ìÁ∂≤Ë∑Ø (MPNN)Ôºà‰æãÂ¶Ç GATÔºâÔºåÂÆÉÂèØ‰ª•Ëá™ÈÅ©ÊáâÂú∞ÊéßÂà∂Ê≤øËëóÂ∫ïÂ±§ÂúñÂΩ¢ÈÇäÁ∑£ÊµÅÂãïÁöÑË≥áË®äÈáè„ÄÇÈÄôÁ®ÆÊ≥®ÊÑèÂäõÁöÑ‰ΩøÁî®‰ΩøÂæóÊ≠§È°ûÊ®°ÂûãÊàêÁÇ∫ÂèØËß£Èáã AI (XAI) Á†îÁ©∂ÁöÑÂü∫Á∑öÔºåÂõ†ÁÇ∫ÈÄèÈÅéÊ≥®ÊÑèÂäõÁöÑË©ÆÈáãÂ∑≤Âú®ÂêÑÁ®ÆÈ†òÂüüÔºà‰æãÂ¶ÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂíåÈõªËÖ¶Ë¶ñË¶∫Ôºâ‰∏≠ÊôÆÂèä„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁ†îÁ©∂ÈÄöÂ∏∏‰ΩøÁî®Â§©ÁúüÁöÑË®àÁÆóÊñπÊ≥ïÂæûÊ≥®ÊÑèÂäõ‰∏≠Êé®Â∞éÂá∫Ê≠∏Âõ†ÂàÜÊï∏Ôºå‰∏¶‰∏îÊ≤íÊúâËÄÉÊÖÆÂà∞ÈÇäÁ∑£Ê≠∏Âõ†ÁöÑÁ≤æÁ¢∫‰∏î‰ªîÁ¥∞ÁöÑË®àÁÆó„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊó®Âú®Â°´Ë£úÊ≥®ÊÑèÂäõÂïüÁî® MPNN ÁöÑÂª£Ê≥õ‰ΩøÁî®ËàáÂÆÉÂÄëÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢ÁöÑÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÈÄôÂÄã‰∏ªÈ°åÂ∑≤Âú®ÂÖ∂‰ªñÈ†òÂüüÁ©çÊ•µÁ†îÁ©∂„ÄÇÁÇ∫Ê≠§Ôºå‰ΩúÁÇ∫Á¨¨‰∏ÄÊ¨°ÂòóË©¶ÔºåÊàëÂÄëÂ∞á GNN ‰∏≠Ê≥®ÊÑèÂäõÊ¨äÈáçÁöÑÈÇäÁ∑£Ê≠∏Âõ†ÂïèÈ°åÂΩ¢ÂºèÂåñ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫ GATTÔºå‰∏ÄÁ®ÆÂª∫Á´ãÂú®Ë®àÁÆóÊ®π‰∏äÁöÑÈÇäÁ∑£Ê≠∏Âõ†Ë®àÁÆóÊñπÊ≥ï„ÄÇÈÄèÈÅéÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Ë©ï‰º∞ GAT ÁöÑÊ≠∏Âõ†ÊôÇÊâÄÂÖ∑ÊúâÁöÑÊïàÊûú„ÄÇÁõ∏ÂèçÂú∞ÔºåÊàëÂÄëÊÜëÁ∂ìÈ©óÈ©óË≠â‰∫ÜÂÉÖÂ∞çÂúñÊ≥®ÊÑèÂäõÂ±§‰∏äÁöÑÊ≥®ÊÑèÂäõÊ¨äÈáçÂèñÂπ≥ÂùáÂÄº‰∏çË∂≥‰ª•Ë©ÆÈáã GAT Ê®°ÂûãÁöÑË°åÁÇ∫„ÄÇÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÊñº https://github.com/jordan7186/GAtt/tree/main„ÄÇ

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

ÊëòË¶ÅÔºöÊñ∞ÁîüÂÖíÊúüÊòØÂ§ßËÖ¶ÁôºËÇ≤ÊúÄËÑÜÂº±ÁöÑÊôÇÊúüÔºåÂÆπÊòìÂá∫ÁèæÁô≤ÁôáÁôº‰Ωú„ÄÇÂ§ßËÖ¶ÁôºËÇ≤‰∏çÊàêÁÜüÊôÇÂá∫ÁèæÁô≤ÁôáÁôº‰ΩúÊúÉÈÄ†Êàê‰∏çËâØÂæåÊûúÔºåÂõ†Ê≠§ÈúÄË¶ÅÂèäÊó©Ë®∫Êñ∑„ÄÇÁõÆÂâçÊñ∞ÁîüÂÖíÁô≤ÁôáÁôº‰ΩúÁöÑÈªÉÈáëÊ®ôÊ∫ñ‰æùË≥¥ÊñºÈÄ£Á∫åÁöÑË¶ñË®äËÖ¶ÈõªÂúñ (EEG) Áõ£Ê∏¨ÔºõÂÖ∂‰∏≠ÂåÖÊã¨Âú®Êñ∞ÁîüÂÖíÂä†Ë≠∑ÁóÖÊàø (NICU) ÂÖßÂêåÊôÇÈÄ≤Ë°åÂ§öÈ†ªÈÅìËÖ¶ÈõªÂúñ (EEG) Ë®òÈåÑÂíåÂç≥ÊôÇË¶ñË®äÁõ£Êéß„ÄÇÁÑ∂ËÄåÔºåË¶ñË®äËÖ¶ÈõªÂúñÁõ£ÊéßÊäÄË°ìÈúÄË¶ÅËá®Â∫äÂ∞àÊ•≠Áü•Ë≠òÔºåËÄå‰∏îÈÄöÂ∏∏ÂÉÖÈôêÊñºÊäÄË°ìÂÖàÈÄ≤‰∏îË≥áÊ∫êË±êÂØåÁöÑÁí∞Â¢É„ÄÇÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊñ∞ÊäÄË°ìÂèØ‰ª•Âπ´Âä©ÈÜ´ÁôÇÁïåÊ∫ñÁ¢∫Ë®∫Êñ∑‰∏¶Á´ãÂç≥ÊèêÂÄ°Ê≤ªÁôÇ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂèØËß£ÈáãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•Ëá™ÂãïÂåñÊñ∞ÁîüÂÖíÁô≤ÁôáÁôº‰ΩúÂÅµÊ∏¨ÈÅéÁ®ãÔºå‰∏¶Êé°Áî®Ê∏õÂ∞ëÁöÑËÖ¶ÈõªÂúñË£ùÁΩÆÔºåÂÖ∂‰∏≠Êé°Áî®‰∫ÜÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅÂúñÂΩ¢Ê≥®ÊÑèÂäõÂ±§ÂíåÂÖ®ÈÄ£Êé•Â±§„ÄÇÈô§‰∫ÜËÉΩÂ§†‰ΩøÁî®Ê∏õÂ∞ëÁöÑË£ùÁΩÆÂç≥ÊôÇÂÅµÊ∏¨Áô≤ÁôáÁôº‰ΩúÂ§ñÔºåÊ≠§Ê®°ÂûãÈÇÑÊèê‰æõ‰∫ÜÂç≥ÊôÇÂèØËß£ÈáãÊÄßÁöÑÁç®ÁâπÂÑ™Âã¢„ÄÇÈÄèÈÅéÂú® Zenodo Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî® 10 ÂÄç‰∫§ÂèâÈ©óË≠âË©ï‰º∞ÊïàËÉΩÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®Êõ≤Á∑ö‰∏ãÈù¢Á©ç (AUC) ÂíåÂè¨ÂõûÁéáÊñπÈù¢ÂàÜÂà•ÈÅîÂà∞‰∫Ü 8.31% Âíå 42.86% ÁöÑÁµïÂ∞çÊîπÂñÑ„ÄÇ

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

ÊëòË¶ÅÔºö‰π≥Áôå (BC) ÊòØÂΩ±ÈüøÂÖ®ÁêÉÂ•≥ÊÄßÊúÄÂ∏∏Ë¶ãÁöÑÊÉ°ÊÄßËÖ´Áò§‰πã‰∏ÄÔºåÂõ†Ê≠§ÈúÄË¶ÅÈÄ≤Ê≠•ÁöÑË®∫Êñ∑ÊñπÊ≥ïÔºå‰ª•ÊîπÂñÑËá®Â∫äÁµêÊûú„ÄÇÊú¨ÊñáÂÖ®Èù¢Êé¢Ë®é‰∫ÜÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ìÂú®‰π≥ÁôåÂÅµÊ∏¨ÂíåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÊäÄË°ìÊåÅÁ∫åÊª≤ÈÄèÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÁâπÂà•ÊòØÂú®ËÖ´Áò§Â≠∏‰∏≠ÔºåÈÄèÊòé‰∏îÂèØËß£ÈáãÁöÑÊ®°ÂûãÈúÄÊ±ÇËÆäÂæóÂã¢Âú®ÂøÖË°åÔºå‰ª•Â¢ûÂº∑Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂíåÊÇ£ËÄÖÁÖßË≠∑„ÄÇÊ≠§ÁØáË©ïË´ñÊé¢Ë®é‰∫ÜÂêÑÁ®Æ XAI ÊñπÊ≥ïÁöÑÊï¥ÂêàÔºå‰æãÂ¶Ç SHAP„ÄÅLIME„ÄÅGrad-CAM Á≠âÔºå‰ª•ÂèäÁî®Êñº‰π≥ÁôåÂÅµÊ∏¨ÂíåÂàÜÈ°ûÁöÑÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÈÄèÈÅéÊé¢Ë®é‰π≥ÁôåË≥áÊñôÈõÜÁöÑÊ®°ÂºèÔºåÂåÖÊã¨‰π≥ÊàøÊîùÂΩ±„ÄÅË∂ÖÈü≥Ê≥¢ÂèäÂÖ∂Âú® AI ‰∏≠ÁöÑËôïÁêÜÔºåÊú¨ÊñáÈáçÈªûË™™Êòé XAI Â¶Ç‰ΩïËÉΩÂ∞éËá¥Êõ¥Ê∫ñÁ¢∫ÁöÑË®∫Êñ∑ÂíåÂÄã‰∫∫ÂåñÊ≤ªÁôÇË®àÁï´„ÄÇÂÆÉ‰πüÊé¢Ë®é‰∫ÜÂØ¶ÊñΩÈÄô‰∫õÊäÄË°ìÁöÑÊåëÊà∞Ôºå‰ª•ÂèäÂà∂ÂÆöÊ®ôÊ∫ñÂåñË©ïÈáèÊåáÊ®ô‰ª•Ë©ï‰º∞ XAI Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊúâÊïàÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄèÈÅéË©≥Á¥∞ÁöÑÂàÜÊûêÂíåË®éË´ñÔºåÊú¨ÊñáÊó®Âú®Âº∑Ë™ø XAI Âú®Á∏ÆÂ∞èË§áÈõú AI Ê®°ÂûãËàáÂØ¶ÂãôÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰πãÈñìÂ∑ÆË∑ùÁöÑÊΩõÂäõÔºåÈÄ≤ËÄå‰øÉÈÄ≤ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°‰πãÈñìÁöÑ‰ø°‰ªªËàáÁêÜËß£Ôºå‰∏¶ÊîπÂñÑÊÇ£ËÄÖÁöÑÁµêÊûú„ÄÇ

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

ÊëòË¶ÅÔºöË™ûÈü≥ÊÉÖÁ∑íËæ®Ë≠ò (SER) Áî±ÊñºÂÖ∂Âú®ÂøÉÁêÜÂÅ•Â∫∑„ÄÅÊïôËÇ≤Âíå‰∫∫Ê©ü‰∫íÂãïÁ≠âÂ§öÂÄãÊáâÁî®È†òÂüüËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåSER Á≥ªÁµ±ÁöÑÊ∫ñÁ¢∫ÊÄßÂèóÂà∞È´òÁ∂≠ÁâπÂæµÈõÜÁöÑÈòªÁ§ôÔºåÈÄô‰∫õÁâπÂæµÈõÜÂèØËÉΩÂåÖÂê´‰∏çÁõ∏ÈóúÂíåÂÜóÈ§òÁöÑË≥áË®ä„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÊåëÊà∞ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁî®Êñº SER ÁöÑËø≠‰ª£ÁâπÂæµÊèêÂçáÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂº∑Ë™øÁâπÂæµÁõ∏ÈóúÊÄßÂíåÂèØËß£ÈáãÊÄßÔºå‰ª•Â¢ûÂº∑Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊ∂âÂèä‰ªîÁ¥∞ÁöÑÁâπÂæµÈÅ∏ÊìáÂíåÂàÜÊûêÔºå‰ª•Âª∫Á´ãÈ´òÊïàÁöÑ SER Á≥ªÁµ±„ÄÇÁÇ∫‰∫ÜÈÄèÈÅéÊ®°ÂûãÂèØËß£ÈáãÊÄßËß£Ê±∫ÊàëÂÄëÁöÑÊ†∏ÂøÉÂïèÈ°åÔºåÊàëÂÄëÊé°Áî®‰∫ÜÂÖ∑Êúâ Shapley ÂÄºÁöÑÁâπÂæµË©ï‰º∞Ëø¥ÂúàÔºå‰ª•ÂèçË¶ÜÊîπÂñÑÁâπÂæµÈõÜ„ÄÇÈÄôÂÄãÈÅéÁ®ãÂú®Ê®°ÂûãÊïàËÉΩÂíåÈÄèÊòéÂ∫¶‰πãÈñìÂèñÂæóÂπ≥Ë°°ÔºåÈÄô‰ΩøÂæóÊàëÂÄëËÉΩÂ§†ÂÖ®Èù¢‰∫ÜËß£Ê®°ÂûãÁöÑÈ†êÊ∏¨„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜÂ§öÈ†ÖÂÑ™ÈªûÔºåÂåÖÊã¨Ë≠òÂà•ÂíåÁßªÈô§‰∏çÁõ∏ÈóúÂíåÂÜóÈ§òÁöÑÁâπÂæµÔºåÂæûËÄåÂª∫Á´ãÊõ¥ÊúâÊïàÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÂÆÉ‰øÉÈÄ≤‰∫ÜÂèØËß£ÈáãÊÄßÔºåÊúâÂä©ÊñºÁêÜËß£Ê®°ÂûãÁöÑÈ†êÊ∏¨‰ª•ÂèäË≠òÂà•ÊÉÖÁ∑íÊ±∫ÂÆöÁöÑÈóúÈçµÁâπÂæµ„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂ∑≤Âú®Â§öÂÄ´Â§öÊÉÖÁ∑íË™ûÈü≥ÈõÜ (TESS)„ÄÅÊüèÊûóÊÉÖÁ∑íË™ûÈü≥Ë≥áÊñôÂ∫´ (EMO-DB)„ÄÅË≥¥ÁàæÊ£ÆÈü≥Ë®äË¶ñË¶∫ÊÉÖÁ∑íË™ûÈü≥ÂíåÊ≠åÊõ≤Ë≥áÊñôÂ∫´ (RAVDESS) ÂíåËñ©ÈáåÈü≥Ë®äË¶ñË¶∫Ë°®ÈÅîÊÉÖÁ∑í (SAVEE) Ë≥áÊñôÈõÜÁöÑ SER Âü∫Ê∫ñ‰∏äÂæóÂà∞È©óË≠âÔºåÂÖ∂ÊïàËÉΩÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞áÊ®°ÂûãÂèØËß£ÈáãÊÄßÁ¥çÂÖ• SER Êû∂ÊßãÁöÑÁ†îÁ©∂„ÄÇÊú¨ÊñáÁöÑÂéüÂßãÁ¢ºÂèØÈÄèÈÅéÊ≠§ÈÄ£ÁµêÂÖ¨ÈñãÂèñÂæóÔºöhttps://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition„ÄÇ

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, H√©lo√Øse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

ÊëòË¶ÅÔºöÂèØËß£ÈáäÊÄßÈÄöÂ∏∏ÂØπ‰∫é‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÂèØÊé•ÂèóÂÆûÊñΩËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®ÂåªÁñó‰øùÂÅ•È¢ÜÂüüÔºåËøô‰∏ÄÁÇπÂ∞§‰∏∫ÈáçË¶ÅÔºåÂõ†‰∏∫ÂÜ≥Á≠ñÁõ¥Êé•ÂΩ±ÂìçÊÇ£ËÄÖÔºåÂπ∂‰∏îÂØπ AI Á≥ªÁªüÁöÑ‰ø°‰ªªËá≥ÂÖ≥ÈáçË¶Å„ÄÇËøôÁßç‰ø°‰ªªÈÄöÂ∏∏Âª∫Á´ãÂú® AI Êèê‰æõÁöÑËß£ÈáäÂíåËØ†Èáä‰πã‰∏ä„ÄÇÂ∞ΩÁÆ° AI ÂèØËß£ÈáäÊÄßÂèñÂæó‰∫ÜÈáçÂ§ßËøõÂ±ïÔºå‰ΩÜ‰ªçÁÑ∂ÈúÄË¶ÅÊòéÁ°ÆÁöÑÊåáÂØºÊñπÈíàÔºåËØ¥ÊòéÂú®ÂåªÁñóÁéØÂ¢É‰∏≠‰ΩïÊó∂‰ª•ÂèäÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÈúÄË¶ÅËß£Èáä„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂàÜÁ±ªÁ≥ªÁªüÔºåËØ•Á≥ªÁªüÂÖ∑ÊúâÂõõÁßç‰∏çÂêåÁöÑËß£ÈáäÂøÖË¶ÅÊÄßÁ±ªÂà´ÔºåÊåáÂØºÊâÄÈúÄÁöÑËß£ÈáäÁ∫ßÂà´ÔºöÊÇ£ËÄÖÊàñÊ†∑Êú¨ÔºàÂ±ÄÈÉ®ÔºâÁ∫ßÂà´„ÄÅÈòüÂàóÊàñÊï∞ÊçÆÈõÜÔºàÂÖ®Â±ÄÔºâÁ∫ßÂà´ÔºåÊàñ‰∏§‰∏™Á∫ßÂà´„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Êï∞Â≠¶ÂÖ¨ÂºèÔºåËØ•ÂÖ¨ÂºèÂå∫ÂàÜ‰∫ÜËøô‰∫õÁ±ªÂà´ÔºåÂπ∂‰∏∫Á†îÁ©∂‰∫∫ÂëòÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂÆûÁî®Ê°ÜÊû∂Ôºå‰ª•Á°ÆÂÆöÂåªÁñó AI Â∫îÁî®‰∏≠ÊâÄÈúÄÁöÑËß£ÈáäÁöÑÂøÖË¶ÅÊÄßÂíåÊ∑±Â∫¶„ÄÇËÄÉËôë‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÂõ†Á¥†ÔºöËØÑ‰º∞ÂçèËÆÆÁöÑÁ®≥ÂÅ•ÊÄß„ÄÅ‰∏ìÂÆ∂ËßÇÂØüÁöÑÂèØÂèòÊÄß‰ª•ÂèäÂ∫îÁî®Á®ãÂ∫èÁöÑË°®Á§∫Áª¥Êï∞„ÄÇ‰ªéËøô‰∏™ËßíÂ∫¶Êù•ÁúãÔºåÊàë‰ª¨Ëß£ÂÜ≥‰∫ÜËøô‰∏™ÈóÆÈ¢òÔºöAI ÂåªÁñóÂ∫îÁî®‰ΩïÊó∂ÈúÄË¶ÅËß£ÈáäÔºå‰ª•ÂèäÈúÄË¶ÅËß£ÈáäÂà∞‰ΩïÁßçÁ®ãÂ∫¶Ôºü

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) È†òÂüüÊ≠£Âø´ÈÄüÂΩ±ÈüøËëóÂÅ•Â∫∑ËàáÈÜ´ÁôÇ‰øùÂÅ•Ôºå‰ΩÜÂ∞çÊñºÈù¢Ëá®Âª£Ê≥õÁµêÊßãÊÄßÂ£ìËø´ÁöÑ‰∫∫Áæ§‰æÜË™™ÔºåÂÅèË¶ãÂíå‰∏çËâØË°®Áèæ‰æùÁÑ∂Â≠òÂú®„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤Ê∏ÖÊ•öË™™ÊòéÔºåÈúÄË¶ÅÊõ¥Âö¥Ê†ºÂú∞Ê≥®ÊÑèË≥áÊñô‰ª£Ë°®ÊÄßÂíåÊ®°ÂûãÊïàËÉΩÔºå‰ª•‰øÉÈÄ≤ÂÖ¨Âπ≥ÊÄß‰∏¶Ê∏õÂ∞ëÂÅèË¶ã„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÊúâÊ©üÊúÉÈÄèÈÅéÈÅãÁî®Á§æÊúÉÊµÅË°åÁóÖÂ≠∏ÂíåÂÅ•Â∫∑ÂÖ¨Âπ≥ÁöÑÊúÄ‰Ω≥ÂØ¶ÂãôÔºå‰æÜÊîπÂñÑ AI ÁöÑÂèØËß£ÈáãÊÄßÔºå‰ª•Âπ´Âä©ÊàëÂÄëÈáùÂ∞çÁôºÁèæÁöÑÈóúËÅØÊÄßÔºåÁôºÂ±ïÂÅáË®≠„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂèØËß£Èáã AI (XAI)Ôºå‰∏¶ÊèèËø∞‰∏ÄÂÄãË∑®È†òÂüüÂ∞àÂÆ∂Â∞èÁµÑÂØ©Êü•Êû∂ÊßãÔºå‰ª•ÂæûÂ§öÈáçËßÄÈªûË®éË´ñÂíåÊâπÂà§ÊÄßË©ï‰º∞ AI Ê®°ÂûãÁöÑËß£ÈáãÔºå‰∏¶ÊâæÂá∫ÂÅèË¶ãÈ†òÂüüÂíåÊú™‰æÜÁ†îÁ©∂ÁöÑÊñπÂêë„ÄÇÊàëÂÄëÂº∑Ë™øË∑®È†òÂüüÂ∞àÂÆ∂Â∞èÁµÑÂ∞çÊñºÁî¢ÁîüÊõ¥Ê∫ñÁ¢∫„ÄÅÂÖ¨Âπ≥ÁöÑË©ÆÈáãËá≥ÈóúÈáçË¶ÅÔºåËÄåÈÄô‰∫õË©ÆÈáãÊòØÊ†πÊìöÊ≠∑Âè≤ÂíåËÑàÁµ°ËÄå‰æÜÁöÑ„ÄÇË∑®È†òÂüüÂ∞èÁµÑË®éË´ñÊúâÂä©ÊñºÊ∏õÂ∞ëÂÅèË¶ã„ÄÅÊâæÂá∫ÊΩõÂú®ÁöÑÊ∑∑Ê∑ÜÂõ†Á¥†Ôºå‰∏¶Âú®ÊñáÁçª‰∏≠ÊúâÁº∫Âè£ÊôÇÊâæÂá∫È°çÂ§ñÁ†îÁ©∂ÁöÑÊ©üÊúÉ„ÄÇÂèçÈÅé‰æÜÔºåÈÄô‰∫õË¶ãËß£ÂèØ‰ª•Âª∫Ë≠∞ AI Ê®°ÂûãÊîπÈÄ≤ÁöÑÊ©üÊúÉ„ÄÇ

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajƒÖc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂú®ÂØ¶È©óÂÆ§ÂØ¶È©ó‰∏≠‰∏çÊñ∑Âú∞ËàáÊîæÂ∞ÑÁßëÈÜ´Â∏´ÂåπÊïµÊàñË°®ÁèæÂæóÊõ¥Âá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåÁôºÁèæÊîæÂ∞ÑÁßë AI ÁÇ∫Âü∫Á§éÁ≥ªÁµ±ÁöÑÂØ¶ÈöõÂü∑Ë°åÂπæ‰πéÊ≤íÊúâÊèê‰æõËá®Â∫äÂÉπÂÄº„ÄÇÊú¨ÊñáÊé¢Ë®éÂ¶Ç‰ΩïÁÇ∫ AI Ë®≠Ë®àÂú®‰∏çÂêåÊÉÖÂ¢É‰∏≠Ëá®Â∫ä‰∏äÁöÑÊïàÁî®„ÄÇÊàëÂÄëÊ†πÊìöÂäüËÉΩÊÄß AI ÁÇ∫Âü∫Á§éÂéüÂûãÁöÑ‰∏âÊ¨°Ëø≠‰ª£ÔºåÂú®‰∏πÈ∫•ÂíåËÇØ‰∫ûÁöÑ 7 ÂÄãËá®Â∫äÂ†¥ÂüüËàá 13 ‰ΩçÊîæÂ∞ÑÁßëÈÜ´Â∏´ÈÄ≤Ë°å‰∫Ü 19 Ê¨°Ë®≠Ë®àÊúÉË≠∞ÂíåË®≠Ë®à‰ªãÂÖ•„ÄÇÂçÅÂÄãÁ§æÊúÉÊäÄË°ì‰æùË≥¥Èóú‰øÇË¢´Ë™çÁÇ∫Â∞çÊñºÊîæÂ∞ÑÁßë‰∏≠ AI ÁöÑË®≠Ë®àËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÊ¶ÇÂøµÂåñ‰∫ÜÂõõÂÄãÊäÄË°ìÈù¢ÂêëÔºåÂøÖÈ†àÊ†πÊìöÈ†êÊúüÁöÑËá®Â∫ä‰ΩøÁî®ÊÉÖÂ¢ÉÈÄ≤Ë°åË®≠ÂÆöÔºöAI ÂäüËÉΩ„ÄÅAI ÈÜ´ÁôÇÈáçÈªû„ÄÅAI Ê±∫Á≠ñÈñÄÊ™ªÔºå‰ª•Âèä AI ÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÊèêÂá∫ÂõõÈ†ÖË®≠Ë®àÂª∫Ë≠∞ÔºåË™™ÊòéÂ¶Ç‰ΩïËôïÁêÜËàáÈÜ´ÁôÇÁü•Ë≠ò„ÄÅË®∫ÊâÄÈ°ûÂûã„ÄÅ‰ΩøÁî®ËÄÖÂ∞àÊ•≠Áü•Ë≠òÁ≠âÁ¥ö„ÄÅÊÇ£ËÄÖÊÉÖÂ¢ÉÔºå‰ª•ÂèäÂΩ±ÈüøÈÄô‰∫õÊäÄË°ìÈù¢ÂêëË®≠ÂÆöÁöÑ‰ΩøÁî®ËÄÖÊÉÖÂ¢ÉÁõ∏ÈóúÁöÑ‰æùË≥¥Èóú‰øÇ„ÄÇ

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

ÊëòË¶ÅÔºöÈö®ËëóÂÖàÈÄ≤ÁöÑ AI/MLÔºåÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂‰∏çÊñ∑Â¢ûÂä†Ôºå‰ª•ÂèäÈóúÊñº‰∫∫È°ûÂ¶Ç‰ΩïËàá AI Âíå XAI ‰∫íÂãï‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ‰∫∫Â∑•Êô∫ÊÖßÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄë‰ªçÁÑ∂Áº∫‰πèÂ∞ç AI Á≥ªÁµ±Âíå XAI ÊáâÂ¶Ç‰ΩïÈ¶ñÂÖàÂëàÁèæÁµ¶Ê≤íÊúâÊäÄË°ìËÉåÊôØÁöÑÁî®Êà∂ÁöÑ‰∫ÜËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì° (n=12) Âíå‰∏ª‰øÆÈÜ´Â≠∏ÂíåÂÅ•Â∫∑ÁöÑÂ≠∏Áîü (n=4) ÈÄ≤Ë°åÂçäÁµêÊßãÂåñË®™Ë´áÁöÑÁµêÊûúÔºå‰ª•Á†îÁ©∂Â¶Ç‰ΩïÊîπÂñÑ AI Âíå XAI ÁöÑÂÖ•ÈñÄ„ÄÇÂ∞çÊñºË®™Ë´áÔºåÊàëÂÄëÂª∫Á´ãÂú®‰∫∫Ê©ü‰∫íÂãïÊ∫ñÂâá‰πã‰∏äÔºåÁÇ∫‰∏≠È¢®Â∫∑Âæ©Ë©ï‰º∞Âíå AI Ëß£ÈáãÁöÑ AI Á≥ªÁµ±ÂâµÂª∫ÂÖ•ÈñÄÊùêÊñôÔºå‰∏¶Â∞áÂÆÉÂÄë‰ªãÁ¥πÁµ¶ÂèÉËàáËÄÖ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈô§‰∫ÜÂëàÁèæÂÇ≥Áµ±ÁöÑ AI ÊÄßËÉΩÊåáÊ®ôÂ§ñÔºåÂèÉËàáËÄÖÈÇÑÂ∏åÊúõÂü∫ÂáÜ‰ø°ÊÅØ„ÄÅAI ÁöÑÂØ¶ÈöõÂ•ΩËôï‰ª•Âèä‰∫§‰∫íË©¶È©óÔºå‰ª•Êõ¥Â•ΩÂú∞Â∞á AI ÊÄßËÉΩÊÉÖÂ¢ÉÂåñÔºå‰∏¶ÂÆåÂñÑ AI ÁöÑÁõÆÊ®ôÂíåÊÄßËÉΩ„ÄÇÊ†πÊìöÈÄô‰∫õÁôºÁèæÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÊîπÈÄ≤ AI Âíå XAI ‰ª•Âèä‰∫∫Ê©üÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂÖ•ÈñÄÊñπÂêë„ÄÇ

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

ÊëòË¶ÅÔºöÊú¨Êñá‰ΩøÁî®Ê©üÂô®Â≠∏Áøí (ML) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ì‰æÜÊé¢Ë®éÁáüÈ§äÁãÄÊ≥ÅËàáÈòøËå≤Êµ∑ÈªòÁóá (AD) Áõ∏ÈóúÁöÑÊ≠ª‰∫°Áéá‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊé°Áî®Á¨¨‰∏âÊ¨°ÂÖ®ÂúãÂÅ•Â∫∑ËàáÁáüÈ§äÊ™¢Êü•Ë™øÊü• (NHANES III) Ë≥áÊñôÂ∫´ÈÄ≤Ë°åÂàÜÊûê„ÄÇÈÅ∏ÊìáÈö®Ê©üÊ£ÆÊûóÊ®°Âûã‰ΩúÁÇ∫ XAI ÂàÜÊûêÁöÑÂü∫Á§éÊ®°ÂûãÔºå‰∏¶‰ΩøÁî® Shapley Additive Explanations (SHAP) ÊñπÊ≥ï‰æÜË©ï‰º∞ÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÈáçË¶ÅÁöÑÁáüÈ§äÂõ†Á¥†Ôºå‰æãÂ¶ÇË°ÄÊ∏ÖÁ∂≠ÁîüÁ¥† B12 ÂíåÁ≥ñÂåñË°ÄÁ¥ÖËõãÁôΩ„ÄÇË©≤Á†îÁ©∂Ë≠âÊòé‰∫ÜÈö®Ê©üÊ£ÆÊûóÂú®È†êÊ∏¨ AD Ê≠ª‰∫°ÁéáÊñπÈù¢Áõ∏ËºÉÊñºÂÖ∂‰ªñÁñæÁóÖÁöÑÊúâÊïàÊÄß„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫ÜÁáüÈ§äÂ∞ç AD ÁöÑÂΩ±ÈüøÁöÑË¶ãËß£Ôºå‰∏¶ÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÁñæÁóÖÁöÑÈÄ≤Â±ï„ÄÇ

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

ÊëòË¶ÅÔºö<paragraph>ÂàùÁ¥ö‰øùÂÅ•Êèê‰æõËÄÖÂ∞çÊñºÊúÄÂàùÁöÑÂàÜÊµÅÂíåËΩâË®∫Âà∞Â∞àÁßëÁÖßË≠∑Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®ÈùíÂÖâÁúºÁöÑÊÉÖÊ≥Å‰∏ãÔºåÁÑ°ÁóáÁãÄ‰∏îÂø´ÈÄüÊÉ°ÂåñÂèØËÉΩÂ∞éËá¥Ë¶ñÂäõÂñ™Â§±ÔºåÂõ†Ê≠§ÈúÄË¶ÅÂèäÊôÇËΩâË®∫Áµ¶Â∞àÂÆ∂„ÄÇÁÑ∂ËÄåÔºåÂàùÁ¥öÁúºÁßë‰øùÂÅ•Êèê‰æõËÄÖÂèØËÉΩÁÑ°Ê≥ïË≠òÂà•Á∑äÊÄ•ÊÉÖÊ≥ÅÔºåÂèØËÉΩÊúÉÂª∂Ë™§ÁÖßË≠∑„ÄÇÊèê‰æõËß£ÈáãÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÂèØ‰ª•Âä†Âº∑‰ªñÂÄëÁöÑËΩâË®∫Ê±∫Á≠ñ„ÄÇÊàëÂÄëÁ†îÁ©∂ÂêÑÁ®Æ AI Ëß£ÈáãÂ¶Ç‰ΩïÂπ´Âä©Êèê‰æõËÄÖÂçÄÂàÜÈúÄË¶ÅÁ´ãÂç≥ÊàñÈùûÁ∑äÊÄ•Â∞àÁßëËΩâË®∫ÁöÑÊÇ£ËÄÖ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫ÜËß£ÈáãÊÄß AI ÊºîÁÆóÊ≥ïÔºå‰ª•Âæû‰æãË°åÁúºÁßëË≠∑ÁêÜË≥áÊñôÈ†êÊ∏¨ÈùíÂÖâÁúºÊâãË°ìÈúÄÊ±ÇÔºå‰ΩúÁÇ∫Ë≠òÂà•È´òÈ¢®Èö™ÊÇ£ËÄÖÁöÑ‰ª£ÁêÜ„ÄÇÊàëÂÄëÁ¥çÂÖ•‰∫ÜÂÖßÂú®Âíå‰∫ãÂæåËß£ÈáãÊÄßÔºå‰∏¶ËàáÈ©óÂÖâÂ∏´ÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÁ∑ö‰∏äÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞‰∫∫Ê©üÂúòÈöäÁöÑË°®ÁèæÔºåË°°ÈáèËΩâË®∫Ê∫ñÁ¢∫Â∫¶‰∏¶ÂàÜÊûêËàá AI ÁöÑ‰∫íÂãïÔºåÂåÖÊã¨ÂêåÊÑèÁéá„ÄÅ‰ªªÂãôÊôÇÈñìÂíå‰ΩøÁî®ËÄÖÈ´îÈ©óÊÑüÁü•„ÄÇÂú® 87 ÂêçÂèÉËàáËÄÖ‰∏≠ÔºåAI ÊîØÊè¥ÊèêÈ´ò‰∫ÜËΩâË®∫Ê∫ñÁ¢∫Â∫¶Ôºà‰ΩøÁî® AI/Êú™‰ΩøÁî®ÁöÑÊØî‰æãÁÇ∫ 59.9%/50.8%ÔºâÔºåÂÑòÁÆ°‰∫∫Ê©üÂúòÈöäÁöÑË°®Áèæ‰∏çÂ¶ÇÂñÆÁç®‰ΩøÁî® AI„ÄÇÂèÉËàáËÄÖË™çÁÇ∫‰ªñÂÄëÂú®‰ΩøÁî®ÂÖßÂú®Ê®°ÂûãÊôÇÊõ¥Â§öÂú∞Á¥çÂÖ•‰∫Ü AI Âª∫Ë≠∞Ôºå‰∏¶Ë™çÁÇ∫ÂÆÉÊõ¥ÊúâÁî®‰∏îÊõ¥ÊúâÂ∏åÊúõ„ÄÇÊ≤íÊúâËß£ÈáãÔºåAI Âª∫Ë≠∞ÁöÑÂÅèÂ∑ÆÊúÉÂ¢ûÂä†„ÄÇAI ÊîØÊè¥‰∏¶Êú™Â¢ûÂä†Â∑•‰ΩúÈáè„ÄÅ‰ø°ÂøÉÂíå‰ø°‰ªªÔºå‰ΩÜÊ∏õÂ∞ë‰∫ÜÊåëÊà∞„ÄÇÂú®‰∏ÄÂÄãÂñÆÁç®ÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠ÔºåÊàëÂÄëÁöÑÈªëÁõíÂ≠êÂíåÂÖßÂú®Ê®°ÂûãÂú®È†êÊ∏¨ÊâãË°ìÁµêÊûúÊñπÈù¢ÂàÜÂà•ÈÅîÂà∞‰∫Ü 77% Âíå 71% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÊâæÂá∫Âú®ÂàùÁ¥öÁúºÁßë‰øùÂÅ•‰∏≠Ôºå‰∫∫Ê©üÂúòÈöäÂêà‰ΩúÁÆ°ÁêÜÈùíÂÖâÁúºÁöÑÊ©üÊúÉÔºå‰∏¶Ê≥®ÊÑèÂà∞ÈõñÁÑ∂ AI ÊèêÈ´ò‰∫ÜËΩâË®∫Ê∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÂç≥‰ΩøÊúâËß£ÈáãÔºåÂÆÉ‰πüÈ°ØÁ§∫Âá∫ËàáÂñÆÁç®‰ΩøÁî® AI Áõ∏ÊØîÁöÑÊïàËÉΩÂ∑ÆË∑ù„ÄÇ‰∫∫È°ûÂèÉËàáÂú®ÈÜ´ÁôÇÊ±∫Á≠ñ‰∏≠‰ªçÁÑ∂Ëá≥ÈóúÈáçË¶ÅÔºåÈÄôÂº∑Ë™ø‰∫ÜÊú™‰æÜÁ†îÁ©∂ÂÑ™ÂåñÂçî‰Ωú„ÄÅÁ¢∫‰øùÊ≠£Èù¢Á∂ìÈ©óÂíåÂÆâÂÖ®‰ΩøÁî® AI ÁöÑÂøÖË¶ÅÊÄß„ÄÇ</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

ÊëòË¶ÅÔºöÂú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÔºåÁâπÂà•ÊòØÂú®Êó©ÊúüÁñæÁóÖÊ™¢Ê∏¨ÂíåÈ†êÂæå‰ªªÂãô‰∏≠ÔºåËæ®Âà• AI Ê®°ÂûãÈ†êÊ∏¨ËÉåÂæåÁöÑÂéüÁêÜÂ∞çÊñºË©ï‰º∞ÂÖ∂Ê±∫Á≠ñÁöÑÂèØÈù†ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÁöÑËß£ÈáãÊñπÊ≥ïÂú®Ë≠òÂà•ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰∏≠ÂèØË≠òÂà•ÁöÑÊ±∫ÂÆöÊÄßÁâπÂæµÊôÇÈù¢Ëá®ÊåëÊà∞ÔºåÂÖ∂‰∏≠ÂçÄÂà•ÊÄßÁâπÂæµÂæàÂæÆÂ¶ôÊàñ‰∏¶‰∏çÊòéÈ°Ø„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊ®°ÂûãÔºåË©≤Ê®°ÂûãÂÖ∑ÂÇôÊ±∫Á≠ñÊé®ÁêÜÂíåÁâπÂæµË≠òÂà•ËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÂÉÖÊ™¢Ê∏¨ÊúâÂΩ±ÈüøÂäõÁöÑÂΩ±ÂÉèÊ®°ÂºèÔºåÈÇÑÊè≠Á§∫‰∫ÜÊé®ÂãïÊ®°ÂûãÊúÄÁµÇÈ†êÊ∏¨ÁöÑÊ±∫ÂÆöÊÄßÁâπÂæµ„ÄÇÈÄöÈÅéÂØ¶ÊñΩÊàëÂÄëÁöÑÊ®°ÂûãÔºåÊàëÂÄëÂèØ‰ª•ÊúâÊïàË≠òÂà•ÂíåË¶ñË¶∫ÂåñÁî±Êï∏ÊìöÈ©ÖÂãïÊ®°ÂûãÂà©Áî®ÁöÑÈ°ûÁâπÂÆöÁâπÂæµÔºåÂæûËÄåÊ∑±ÂÖ•‰∫ÜËß£Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊ±∫Á≠ñÈÅéÁ®ã„ÄÇÊàëÂÄëÂú®Ë¶ÅÊ±ÇÂö¥Ê†ºÁöÑÈÜ´Â≠∏È†êÂæå‰ªªÂãôÈ†òÂüüÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÊèêÈ´ò AI Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂèØÈù†ÊÄßÂíåÁôºÁèæÈ†êÂæåÁêÜËß£ÂèóÈôêÁñæÁóÖÁöÑÊñ∞Áü•Ë≠òÊñπÈù¢ÁöÑÂäüÊïàÂíåÊΩõÂäõ„ÄÇ

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÁ∑ö‰∏äÂÅ•Â∫∑Á§æÁæ§‰∏≠Â∞ãÊ±ÇË≥áË®äÊîØÊåÅÁöÑÂïèÈ°å„ÄÅÂõûÊáâÔºå‰ª•ÂèäÊúâÂπ´Âä©ÁöÑË©ïÂàÜ‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÁµÑÊ®ôË®òÁöÑÂïèÁ≠îÈÖçÂ∞çË≥áÊñôÈõÜÔºå‰∏¶ÈñãÁôº‰∫ÜÂ§öÊ®°ÊÖãÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•ÂèØÈù†Âú∞È†êÊ∏¨Ë≥áË®äÊîØÊåÅÂïèÈ°åÂíåÂõûÊáâ„ÄÇÊàëÂÄëÊé°Áî®ÂèØËß£ÈáãÁöÑ AI ‰æÜÊè≠Á§∫Ë≥áË®äÊîØÊåÅ‰∫§ÊµÅ‰∏≠ËòäÂê´ÁöÑÊÉÖÁ∑íÔºåË≠âÊòéÊÉÖÁ∑íÂú®Êèê‰æõË≥áË®äÊîØÊåÅ‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÁ®ÆÊÉÖÁ∑íÊîØÊåÅÂíåË≥áË®äÊîØÊåÅ‰πãÈñìÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®‰ª•Ââç‰∏¶Êú™Ë¢´Á†îÁ©∂ÈÅé„ÄÇÊú¨Á†îÁ©∂ÊîπÈÄ≤‰∫ÜÁ§æÊúÉÊîØÊåÅÁêÜË´ñÔºå‰∏¶ÁÇ∫‰ΩøÁî®ËÄÖÊ±∫Á≠ñËºîÂä©Â∑•ÂÖ∑ÁöÑÈñãÁôºÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇË®éË´ñ‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÂΩ±Èüø„ÄÇ

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

ÊëòË¶ÅÔºöÂú®ÁßëÊäÄÈ£õÈÄüÁôºÂ±ïÁöÑÊôÇ‰ª£Ôºå‰∏Ä‰ΩçÊÑèÂ§ñÁöÑË®™ÂÆ¢Â∑≤Âú®ÂÖ®ÁêÉÊïôÂÆ§‰∏≠‰ΩîÊúâ‰∏ÄÂ∏≠‰πãÂú∞ÔºåÈÇ£Â∞±ÊòØ‰∫∫Â∑•Êô∫ÊÖß„ÄÇÁîüÊàêÂºè AIÔºå‰æãÂ¶Ç ChatGPTÔºåÊâøË´æÂú®ÊïôËÇ≤È†òÂüüÊéÄËµ∑‰∏ÄÂ†¥Èù©ÂëΩÔºå‰ΩÜÂÆÉÂçªÊòØ‰∏ÄÊääÈõôÈù¢ÂàÉ„ÄÇÂÆÉÂú®ÂÄã‰∫∫ÂåñÂ≠∏ÁøíÊñπÈù¢ÁöÑÊΩõÂäõÔºåÂçªÂõ†‰ΩúÂºä„ÄÅ‰∏çÊ∫ñÁ¢∫‰ª•ÂèäÊïôËÇ≤Â∑•‰ΩúËÄÖÈõ£‰ª•Â∞áÂÖ∂ÊúâÊïàËûçÂÖ•ÊïôÂ≠∏Ë®≠Ë®àÁ≠âÂïèÈ°åËÄåÊäµÈä∑„ÄÇÊàëÂÄëÊ≠£Á´ôÂú®ÈÄôÊïôËÇ≤ÂâçÊ≤øÁöÑÈÇäÁ∑£ÔºåÈ°ØÁÑ∂ÊàëÂÄëÈúÄË¶ÅÈùûÂ∏∏Â∞èÂøÉÂú∞Êé¢Á¥¢ÈÄôÁâáÈ†òÂüü„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂèØËÉΩÊúÉÊêçÂÆ≥ÊàëÂÄëÊïôËÇ≤ÈÅéÁ®ãÁöÑÂÆåÊï¥ÊÄßÂíåÂÉπÂÄº„ÄÇÈÇ£È∫ºÔºåÊàëÂÄëÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÊåëÊà∞ËΩâÂåñÁÇ∫Ê©üÈÅáÔºüÁï∂‰∏çÈÅ©Áï∂Âú∞‰ΩøÁî®ÊôÇÔºåAI Â∑•ÂÖ∑ÂèØËÉΩÊúÉÊàêÁÇ∫Ë§áË£ΩË≤º‰∏äÂøÉÊÖãÁöÑÂÆåÁæéÂ∑•ÂÖ∑Ôºå‰∏¶ËøÖÈÄüËÖêËùïÊâπÂà§ÊÄßÊÄùÁ∂≠„ÄÅÂâµÈÄ†ÂäõÂíåÊ∑±ÂÖ•ÁêÜËß£ÔºåÈÄô‰∫õÈÉΩÊòØÊàëÂÄëÂø´ÈÄüËÆäÂåñÁöÑ‰∏ñÁïå‰∏≠ÊúÄÈáçË¶ÅÁöÑÊäÄËÉΩ„ÄÇÊïôÂ∏´ÂÄëË¶∫Âæó‰ªñÂÄëÊ≤íÊúâËÉΩÂäõÂà©Áî®ÈÄôÈ†ÖÊäÄË°ìÔºåÈÄôÊì¥Â§ß‰∫ÜÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÊ©üÊßã‰πãÈñìÁöÑÊï∏‰ΩçÈ¥ªÊ∫ù„ÄÇËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑÁ†îÁ©∂ÊñπÊ≥ï„ÄÇÊàëÂÄëÂ∞áÊé°Áî®ÂØ¶Ë≠âÁ†îÁ©∂ÔºåÂÄüÈëëÊäÄË°ìÊé•ÂèóÊ®°ÂûãÔºå‰æÜË©ï‰º∞ÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÂ≠∏ÁîüÂ∞çÁîüÊàêÂºè AI ÁöÑÊÖãÂ∫¶„ÄÇ‰∫ÜËß£‰ªñÂÄëÁöÑÁúãÊ≥ï„ÄÅ‰ΩøÁî®Ê®°ÂºèÂíåÈöúÁ§ôÊòØÂâµÈÄ†ÊúâÊïàËß£Ê±∫ÊñπÊ°àÁöÑÁ¨¨‰∏ÄÂÄãÈóúÈçµÊ≠•È©ü„ÄÇÊú¨Á†îÁ©∂Â∞á‰ΩúÁÇ∫Êú™‰æÜÁ†îÁ©∂‰∫∫Âì°ÊáâÁî®ÁöÑÊµÅÁ®ãÊâãÂÜäÔºåÊ†πÊìöÊ≠§ËôïË™™ÊòéÁöÑÊ≠•È©üÈÅãË°å‰ªñÂÄëËá™Â∑±ÁöÑÊï∏Êìö

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Gr√ºne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, Andr√© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

ÊëòË¶ÅÔºöÈö®ËëóÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÊï∏‰ΩçÂåñÔºå‰∫∫Â∑•Êô∫ÊÖßÂú®ÈÜ´Â≠∏È†òÂüü‰∏≠ËÆäÂæóÊõ¥Âä†ÊôÆÂèä„ÄÇÁâπÂà•ÊòØÊ©üÂô®Â≠∏ÁøíÂú®ÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûÁ≠âË§áÈõú‰ªªÂãô‰∏≠Â±ïÁèæÂá∫Ê•µÂ§ßÁöÑÊΩõÂäõÔºå‰ΩÜÈÄöÂ∏∏ÊòØ‰ª•ÈÄèÊòéÂ∫¶ÂíåÂèØÁêÜËß£ÊÄßÁÇ∫‰ª£ÂÉπ„ÄÇÈÄôÂ∞éËá¥‰∫∫È°ûÁº∫‰πè‰ø°‰ªªÔºåÂæûËÄåÈòªÁ§ô‰∫ÜÂÖ∂Á©çÊ•µ‰ΩøÁî®„ÄÇÂèØËß£ÈáãÁöÑ‰∫∫Â∑•Êô∫ÊÖßË©¶ÂúñÈÄöÈÅéÊèê‰æõÂ∞çÊ±∫Á≠ñÈÅéÁ®ãÁöÑÊ¥ûÂØü‰æÜÂΩåË£úÈÄô‰∏ÄÂ∑ÆË∑ùÔºå‰ΩÜÂÖ∂‰∏çÂêåÊñπÊ≥ïÁöÑÂØ¶ÈöõÊïàÁî®Â∞ö‰∏çÊ∏ÖÊ•ö„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫Êñº‰ΩøÁî®ËÄÖÁ†îÁ©∂ÁöÑË©ï‰º∞ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫Ü Grad-CAM Ëß£ÈáãÊñπÊ≥ïÔºå‰∏¶Â∞áÂÖ∂ÊáâÁî®ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰ª•ÂàÜÈ°ûÊôÇÈñìÂ∫èÂàóÊñ∞ÁîüÂÖíÂëºÂê∏Êï∏Êìö‰∏≠ÁöÑÂëºÂê∏„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏çÂêåÂà©ÁõäÁõ∏ÈóúËÄÖÂ∞çÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÊÑüÁü•ÊïàÁî®ÔºåÊè≠Á§∫‰∫ÜÂØ¶ÁèæÂØ¶ÈöõÈÄèÊòéÂ∫¶ÁöÑÈõ£Â∫¶Ôºå‰ª•ÂèäË®±Â§öÂèÉËàáËÄÖÂ∏åÊúõÁç≤ÂæóÊõ¥Ê∑±ÂÖ•ÁöÑËß£Èáã„ÄÇ

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÈÜ´ÁôÇË®∫Êñ∑Êï¥Âêà
ÁÇ∫Ëá®Â∫äÊ±∫Á≠ñÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÈÄîÂæë„ÄÇÊú¨Á†îÁ©∂Ê¶ÇËø∞‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÊñπÊ≥ïÁöÑÈñãÁôºÔºåÁî®ÊñºÈõ∂Ê¨°Â≠∏Áøí/Â∞ëÈáèÂ≠∏ÁøíÊÉÖÂ¢ÉÂ≠∏Áøí (ICL)ÔºåÊñπÊ≥ïÊòØ‰ΩøÁî®Â§öÂ±§ÁµêÊßãÂåñÊèêÁ§∫Êï¥ÂêàÈÜ´ÁôÇÈ†òÂüüÁü•Ë≠ò„ÄÇÊàëÂÄëÈÇÑÊé¢Ë®é‰∫Ü‰ΩøÁî®ËÄÖËàá LLM ‰πãÈñìÂÖ©Á®ÆÊ∫ùÈÄöÊñπÂºèÁöÑÂäüÊïàÔºöÊï∏ÂÄºÂ∞çË©± (NC) ÊñπÂºèÔºåÂÆÉÊúÉÈÄêÊ≠•ËôïÁêÜË≥áÊñôÔºå‰ª•ÂèäËá™ÁÑ∂Ë™ûË®ÄÂñÆÂõûÂêà (NL-ST) ÊñπÂºèÔºåÂÆÉÊúÉ‰ΩøÁî®Èï∑ÁØáÊïò‰∫ãÊèêÁ§∫„ÄÇ
ÊàëÂÄëÁöÑÁ†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞‰∫ÜË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÈ¢®Èö™Âõ†Â≠êÔºåÂåÖÊã¨ÊÄßÂà•ÂÅèË¶ãÂíåÂÅáÈô∞ÊÄßÁéáÔºå‰ΩøÁî®‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 920 ÂÄãÊÇ£ËÄÖË®òÈåÑÁöÑË≥áÊñôÈõÜÔºåÊé°Áî®ÂêÑÁ®ÆÂ∞ëÈáèÂ≠∏ÁøíÊÉÖÂ¢É„ÄÇÁµêÊûúË°®ÊòéÔºåÂÇ≥Áµ±ÁöÑËá®Â∫äÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÈÄöÂ∏∏Âú®Èõ∂Ê¨°Â≠∏ÁøíÂíåÂ∞ëÈáèÂ≠∏ÁøíË®≠ÂÆö‰∏≠Ë°®ÁèæÂÑ™Êñº LLM„ÄÇÁÑ∂ËÄåÔºåÁï∂‰ΩøÁî®Â∞ëÈáèÂ≠∏ÁøíÁØÑ‰æã‰ª•ÂèäÊúâÊïàÁöÑÂèØËß£Èáã AI (XAI) ÊñπÊ≥ï‰ΩúÁÇ∫È†òÂüüÁü•Ë≠ò‰æÜÊ∫êÊôÇÔºåÊïàËÉΩÂ∑ÆË∑ùÊúÉÈ°ØËëóÁ∏ÆÂ∞è„ÄÇÊ≠§Â§ñÔºåÈö®ËëóÊôÇÈñìÂÖÖË∂≥ÂíåÁØÑ‰æãÊï∏ÈáèÂ¢ûÂä†ÔºåÂ∞çË©±ÊñπÂºè (NC) Âπæ‰πéÂèØ‰ª•Â™≤Áæé ML Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊúÄÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåLLM Áõ∏Â∞çÊñº ML Ê®°ÂûãÂ±ïÁèæÂá∫Áõ∏Áï∂ÊàñÊõ¥‰Ω≥ÁöÑÊàêÊú¨ÊïèÊÑüÊ∫ñÁ¢∫Â∫¶„ÄÇ
Êú¨Á†îÁ©∂Ë≠âÂØ¶ÔºåÈÄèÈÅéÈÅ©Áï∂ÁöÑÈ†òÂüüÁü•Ë≠òÂíåÈáèË∫´ÊâìÈÄ†ÁöÑÊ∫ùÈÄöÁ≠ñÁï•ÔºåLLM ÂèØ‰ª•È°ØËëóÂ¢ûÂº∑Ë®∫Êñ∑Á®ãÂ∫è„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÊúÄ‰Ω≥ÂåñË®ìÁ∑¥ÁØÑ‰æãÊï∏ÈáèÂíåÊ∫ùÈÄöÊñπÂºèÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÊèêÈ´òÊ∫ñÁ¢∫Â∫¶‰∏¶Ê∏õÂ∞ë LLM ÊáâÁî®‰∏≠ÁöÑÂÅèÂ∑Æ„ÄÇ

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Mir√≥-Nicolau, Gabriel Moy√†-Alcover, Antoni Jaume-i-Cap√≥, Manuel Gonz√°lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

ÊëòË¶ÅÔºöÈö®ËëóÂ∞çÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰æùË≥¥ÊÄßÁöÑÂ¢ûÂä†ÔºåÂä†‰∏äÂÖ∂Âõ∫ÊúâÁöÑÈÄèÊòéÂ∫¶‰∏çË∂≥Ôºå‰øÉ‰Ωø‰∏ÄÂÄãÊñ∞ÁöÑÁ†îÁ©∂È†òÂüüÁôºÂ±ïÔºåÁ®±ÁÇ∫ÂèØËß£Èáã AI (XAI) ÊñπÊ≥ï„ÄÇÈÄô‰∫õÊñπÊ≥ïÊó®Âú®ÈÄèÈÅéÊ∑±ÂÖ•‰∫ÜËß£Ê±∫Á≠ñËÉåÂæåÁöÑÂéüÁêÜÔºå‰æÜÊèêÂçáÊúÄÁµÇ‰ΩøÁî®ËÄÖÂ∞çËá™ÂãïÂåñÁ≥ªÁµ±ÁöÑ‰ø°Ë≥¥„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË°°Èáè‰ΩøÁî®ËÄÖÂ∞ç XAI Á≥ªÁµ±‰ø°Ë≥¥Â∫¶ÁöÑÊñ∞Á©éÊñπÊ≥ïÔºåÂÖÅË®±Â∞çÂÖ∂ÈÄ≤Ë°åÊîπÈÄ≤„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊåáÊ®ôÁµêÂêà‰∫ÜÂÆ¢ËßÄËßÄÈªû‰∏ãÁöÑÊïàËÉΩÊåáÊ®ôÂíå‰ø°Ë≥¥ÊåáÊ®ô„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÈÄôÂÄãÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÂú®‰∏ÄÂÄãÁúüÂØ¶ÁöÑÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÈÄ≤Ë°å‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂Ôºö‰ΩøÁî® XAI Á≥ªÁµ±Âæû X ÂÖâÂΩ±ÂÉè‰∏≠ÂÅµÊ∏¨ËÇ∫ÁÇé„ÄÇ

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

ÊëòË¶ÅÔºöCOVID-19 Áñ´ÊÉÖÂ∞çÂÖ®ÁêÉÂÖ¨ÂÖ±Ë°õÁîüÈÄ†ÊàêÂ£ìÂäõÔºåÂøÖÈ†àÈÄ≤Ë°åÊ∫ñÁ¢∫ÁöÑË®∫Êñ∑ÂíåÂπ≤È†êÔºå‰ª•ÊéßÂà∂ÁñæÁóÖÂÇ≥Êí≠‰∏¶Èôç‰ΩéÊ≠ª‰∫°Áéá„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊ∑±Â∫¶ÁîüÂ≠òÈ†êÊ∏¨Ê®°ÂûãÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÈÄèÈÅéËÉ∏ÈÉ® X ÂÖâ (CXR) ÂΩ±ÂÉèÊîπÂñÑÂ∞ç COVID-19 È†êÂæåÁöÑÁêÜËß£Âíå‰ø°Ë≥¥„ÄÇÈÄèÈÅéÊï¥ÂêàÂ§ßË¶èÊ®°È†êË®ìÁ∑¥ÂΩ±ÂÉèÁ∑®Á¢ºÂô®„ÄÅÈ¢®Èö™ÁâπÂÆö Grad-CAM ÂíåËß£ÂâñÂçÄÂüüÂÅµÊ∏¨ÊäÄË°ìÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁî¢ÁîüÂçÄÂüüÂèØËß£ÈáãÁöÑÁµêÊûúÔºåÊúâÊïàÊçïÊçâÂøÖË¶ÅÁöÑÁñæÁóÖÁâπÂæµÔºåÂêåÊôÇÂ∞àÊ≥®ÊñºÁΩïË¶ã‰ΩÜÈóúÈçµÁöÑÁï∞Â∏∏ÂçÄÂüü„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈ†êÊ∏¨ÁµêÊûúÈÄèÈÅéÈ¢®Èö™ÂçÄÂüüÂÆö‰ΩçÊèê‰æõÂ¢ûÂº∑ÁöÑÊ∏ÖÊô∞Â∫¶ÂíåÈÄèÊòéÂ∫¶ÔºåËÆìËá®Â∫äÈÜ´ÁîüËÉΩÂ§†Âú®Êõ¥‰∫ÜËß£È†êÂæåË¶ãËß£ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞± COVID-19 Ë®∫Êñ∑ÂÅöÂá∫ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇÊàëÂÄëÂú®Â§ö‰∏≠ÂøÉÁîüÂ≠òË≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÔºå‰∏¶ÈÄèÈÅéÈáèÂåñÂíåË≥™ÂåñË©ï‰º∞Ë≠âÊòéÂÖ∂ÊúâÊïàÊÄßÔºåÈÅîÂà∞ÂÑ™Áï∞ÁöÑ C ÊåáÊï∏Ôºà0.764 Âíå 0.727ÔºâÂíåÊôÇÈñìÁõ∏Èóú AUCÔºà0.799 Âíå 0.691Ôºâ„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÂèØËß£ÈáãÁöÑÊ∑±Â∫¶ÁîüÂ≠òÈ†êÊ∏¨Ê®°ÂûãÂú®È¢®Èö™È†êÊ∏¨ÊñπÈù¢Ë∂ÖË∂äÂÇ≥Áµ±ÁöÑÁîüÂ≠òÂàÜÊûêÊñπÊ≥ïÔºåÊèêÂçáËá®Â∫äÊ±∫Á≠ñÁöÑËß£ÈáãÊÄßÔºå‰∏¶Â¢ûÂº∑ AI Á≥ªÁµ±ÁöÑ‰ø°Ë≥¥Â∫¶„ÄÇ

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈÅéÂéªÂπæÂπ¥ÔºåËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ± (CDSS) ‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®Âà©Áî®Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÊñπÈù¢ÁôºÊèÆ‰∫ÜÈóúÈçµ‰ΩúÁî®„ÄÇÂÑòÁÆ° AI Ê®°ÂûãÂÖ∑Êúâ‰ª§‰∫∫ÊªøÊÑèÁöÑËÉΩÂäõÔºå‰ΩÜÁº∫‰πèÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÔºåÁâπÂà•ÊòØÂú®ÂèØÈù†ÊÄßÁÇ∫ÂøÖË¶ÅËÄÉÈáèÁöÑÈÜ´ÁôÇËÉåÊôØ‰∏ãÔºåÈÄôÂ∏∂‰æÜ‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂú®‰∏çÂΩ±ÈüøÈ†êÊ∏¨Á≤æÊ∫ñÂ∫¶ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶ÁèæÈÄèÊòéÂ∫¶‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂç≥ Rad4XCNNÔºå‰ª•Â¢ûÂº∑ CNN Ë°çÁîüÁâπÂæµÁöÑÈ†êÊ∏¨ËÉΩÂäõÔºåÂêåÊôÇÂÖ∑ÂÇôÊîæÂ∞ÑÁâπÂæµÂõ∫ÊúâÁöÑÂèØËß£ÈáãÊÄß„ÄÇRad4XCNN ‰∏çÂêåÊñºÂü∫ÊñºÈ°ØËëóÊÄßÂúñÁöÑÂÇ≥Áµ±ÊñπÊ≥ïÔºåÂÆÉÈÄöÈÅéÊîæÂ∞ÑÁµÑÂ≠∏Â∞áÂèØÁêÜËß£ÁöÑÂê´Áæ©Ëàá CNN Ë°çÁîüÁâπÂæµÈóúËÅØËµ∑‰æÜÔºåÁÇ∫Ë∂ÖË∂äË¶ñË¶∫ÂåñÂúñË°®ÁöÑËß£ÈáãÊñπÊ≥ïÊèê‰æõ‰∫ÜÊñ∞ÁöÑËßÄÈªû„ÄÇÊàëÂÄë‰ª•‰π≥ÁôåÂàÜÈ°û‰ªªÂãô‰ΩúÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåÂú®Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏äË©ï‰º∞ Rad4XCNNÔºåÂåÖÊã¨‰∏ÄÂÄãÁ∑ö‰∏äË≥áÊñôÈõÜÂíåÂÖ©ÂÄãÁî®ÊñºÂÖßÈÉ®ÂíåÂ§ñÈÉ®È©óË≠âÁöÑÂÖßÈÉ®Ë≥áÊñôÈõÜ„ÄÇ‰∏Ä‰∫õÈóúÈçµÁµêÊûúÂ¶Ç‰∏ãÔºöi) Ëàá ViT Ë°çÁîüÁâπÂæµÂíåÊîæÂ∞ÑÁâπÂæµÁõ∏ÊØîÔºåCNN Ë°çÁîüÁâπÂæµ‰øùË≠â‰∫ÜÊõ¥Á©©ÂÅ•ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºõii) ÂÇ≥Áµ±ÁöÑË¶ñË¶∫ÂåñÂúñËß£ÈáãÊñπÊ≥ïÂ≠òÂú®‰∏Ä‰∫õÁº∫Èô∑Ôºõiii) Rad4XCNN Ê≤íÊúâÁäßÁâ≤Ê®°ÂûãÊ∫ñÁ¢∫Â∫¶‰æÜÊèõÂèñÂÖ∂ÂèØËß£ÈáãÊÄßÔºõiv) Rad4XCNN Êèê‰æõ‰∫ÜÂÖ®Â±ÄËß£ÈáãË¶ãËß£Ôºå‰ΩøÈÜ´Â∏´ËÉΩÂ§†ÂàÜÊûêÊ®°ÂûãËº∏Âá∫ÂíåÁôºÁèæ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂº∑Ë™øÂ∞áÂèØËß£ÈáãÊÄßÊï¥ÂêàÂà∞ AI Ê®°Âûã‰∏≠Â∞çÊñºÂ¢ûÂº∑Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑ‰ø°‰ªªÂíåÊé°Áî®Ëá≥ÈóúÈáçË¶ÅÔºå‰∏¶Âº∑Ë™ø‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂ¶Ç‰ΩïËÉΩÁ∑©Ëß£ËàáÂèØËß£Èáã AI ÊñπÊ≥ïÁõ∏ÈóúÁöÑ‰∏Ä‰∫õÁñëÊÖÆ„ÄÇ</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

ÊëòË¶ÅÔºöÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊôÆÂèäÊï¥ÂêàÔºåÂú®Ê∂âÂèä AI È©ÖÂãïÁ≥ªÁµ±ÁöÑ‰∫ãÊïÖ‰∏≠ÔºåË≤¨‰ªªÂíåÁæ©ÂãôÊ≠∏Â±¨Áî¢Áîü‰∫ÜË§áÈõúÁöÑÊåëÊà∞„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÁöÑ‰∫íÈÄ£ÊÄß„ÄÅAI ÂºïÁôº‰∫ãÊïÖÁöÑÂÄ´ÁêÜÂïèÈ°åÔºåÂä†‰∏ä AI ÊäÄË°ìÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂíåÁº∫‰πèÁõ∏ÊáâÊ≥ïË¶èÔºå‰ΩøÂæóÂÇ≥Áµ±Ë≤¨‰ªªÊ≠∏Â±¨Èù¢Ëá®ÊåëÊà∞„ÄÇÁÇ∫Ê≠§ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË®àÁÆóÂèçÊÄùÂùáË°° (CRE) ÊñπÊ≥ïÔºå‰ª•Âª∫Á´ã‰∏ÄÂÄãÈÄ£Ë≤´‰∏îÂú®ÂÄ´ÁêÜ‰∏äÂèØÊé•ÂèóÁöÑË≤¨‰ªªÊ≠∏Â±¨Êû∂ÊßãÔºåÈÅ©Áî®ÊñºÊâÄÊúâÂà©ÂÆ≥Èóú‰øÇ‰∫∫„ÄÇË®àÁÆóÊñπÊ≥ïÊèê‰æõ‰∫ÜÁµêÊßãÂåñÁöÑÂàÜÊûêÔºåÂÖãÊúç‰∫ÜÊ¶ÇÂøµÊñπÊ≥ïÂú®ËôïÁêÜÂãïÊÖã‰∏îÂ§öÈù¢ÂêëÊÉÖÂ¢ÉÊôÇÁöÑÈôêÂà∂ÔºåÂ±ïÁ§∫‰∫ÜË©≤Êû∂ÊßãÂú®Ë≤¨‰ªªÊ≠∏Â±¨ÈÅéÁ®ã‰∏≠ÂÖ∑ÂÇôÁöÑÂèØËß£ÈáãÊÄß„ÄÅÈÄ£Ë≤´ÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜËàáÂùáË°°Ë®àÁÆó‰∏≠Á¥¢Ë≥†Áõ∏ÈóúÁöÑÂàùÂßãÂïüÂãïÂ±§Á¥öÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇÊàëÂÄë‰ª• AI ËºîÂä©ÈÜ´ÁôÇÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåË™™Êòé‰∏çÂêåÁöÑÂàùÂßãÂåñÂ¶Ç‰ΩïÂ∞éËá¥‰∏çÂêåÁöÑË≤¨‰ªªÂàÜÈÖç„ÄÇË©≤Êû∂ÊßãÊèê‰æõ‰∫ÜÂ∞ç AI ÂºïÁôº‰∫ãÊïÖ‰∏≠ÂïèË≤¨Âà∂ÁöÑÂØ∂Ë≤¥Ë¶ãËß£ÔºåÈÄèÈÅéÊåÅÁ∫åÁõ£Êéß„ÄÅ‰øÆË®ÇÂíåÂèçÊÄùÔºå‰øÉÈÄ≤‰∫ÜÊ∞∏Á∫å‰∏îÊúâÈüåÊÄßÁöÑÁ≥ªÁµ±ÁôºÂ±ï„ÄÇ

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÈÄèÈÅéÈ†êÊ∏¨Ê®°ÂûãÂçîÂä©ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÔºåÂ§ßÂπÖËΩâËÆä‰∫ÜËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®Á®ãÂºèÊôÇÂÖ¨Âπ≥ÊÄßÂíåÂèØËß£ÈáãÊÄßÁöÑÈóúÈçµÈúÄÊ±ÇÔºå‰ª•Á¢∫‰øùÂú®‰∏çÂêåÁöÑÊÇ£ËÄÖ‰∫∫Âè£Áµ±Ë®àË≥áÊñô‰∏≠Áç≤ÂæóÂÖ¨Âπ≥ÁöÑÁµêÊûú„ÄÇÈÄèÈÅéÂ∞àÊ≥®ÊñºÊïóË°ÄÁóáÁõ∏ÈóúÊ≠ª‰∫°ÁéáÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÊúÉÂ≠∏Áøí‰∏ÄÂÄãÊïàËÉΩÊúÄ‰Ω≥ÂåñÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÁÑ∂ÂæåÊé°Áî®ËΩâÁßªÂ≠∏ÁøíÈÅéÁ®ã‰æÜÁî¢Áîü‰∏ÄÂÄãÂÖ∑ÊúâÊõ¥Â•ΩÂÖ¨Âπ≥ÊÄßÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂü∫ÊñºÊéíÂàóÁöÑÁâπÂæµÈáçË¶ÅÊÄßÊºîÁÆóÊ≥ïÔºåÊó®Âú®Èó°ÊòéÊØèÂÄãÁâπÂæµÂú®Â¢ûÂº∑È†êÊ∏¨ÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÁöÑË≤¢Áçª„ÄÇËàáÁèæÊúâÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÂ∞àÊ≥®ÊñºËß£ÈáãÁâπÂæµÂ∞çÈ†êÊ∏¨ÊïàËÉΩÁöÑË≤¢Áçª‰∏çÂêåÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁç®ÁâπÂú∞ÂΩåË£ú‰∫ÜÁêÜËß£ÊØèÂÄãÁâπÂæµÂ¶Ç‰ΩïÊúâÂä©ÊñºÂÖ¨Âπ≥ÊÄßÁöÑÂ∑ÆË∑ù„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÊïóË°ÄÁóáÁöÑÊ≠ª‰∫°ÁéáÂæàÈ´òÔºå‰∏îÂú®‰∏âÂàÜ‰πã‰∏ÄÁöÑÈÜ´Èô¢Ê≠ª‰∫°‰∏≠ÊâÆÊºîËëóËßíËâ≤„ÄÇÊàëÂÄëÁöÑÊ®°Âûã‰∏çÂÉÖÊúâÂä©ÊñºË≠òÂà•ÂíåÊ∏õËºïÈ†êÊ∏¨Ê®°Âûã‰∏≠ÁöÑÂÅèÂ∑ÆÔºåÈÇÑËÉΩÈÄèÈÅéÊèêÈ´òÊ®°ÂûãÈ†êÊ∏¨ÁöÑÈÄèÊòéÂ∫¶ÂíåÂÖ¨Âπ≥ÊÄß‰æÜÂüπÈ§äÈÜ´ÁôÇ‰øùÂÅ•Âà©ÁõäÁõ∏ÈóúËÄÖ‰πãÈñìÁöÑ‰ø°‰ªªÔºåÈÄ≤ËÄåÊúâÂä©ÊñºÊèê‰æõÊõ¥ÂÖ¨Âπ≥‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô„ÄÇ

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

ÊëòË¶ÅÔºöÁèæ‰ªäÔºåÊÜÇÈ¨±ÁóáÊòØ‰∏ÄÂÄãÈáçË¶ÅÁöÑË≠∞È°å„ÄÇÊ†πÊìö‰∏ñÁïåË°õÁîüÁµÑÁπî (WHO) ÁöÑË≥áÊñôÔºåÂú® 2023 Âπ¥ÔºåË∂ÖÈÅé 2.8 ÂÑÑ‰∫∫Ê≠£Âú®ËàáÊÜÇÈ¨±ÁóáÊêèÈ¨•„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈæêÂ§ßÁöÑÊï∏Â≠óÔºõÂ¶ÇÊûú‰∏çË™çÁúüÁúãÂæÖÔºåÈÄô‰∫õÊï∏Â≠óÂ∞áÊúÉÂø´ÈÄüÂ¢ûÂä†„ÄÇÂ§ßÁ¥ÑÊúâ 48.9 ÂÑÑ‰∫∫ÊòØÁ§æÁæ§Â™íÈ´î‰ΩøÁî®ËÄÖ„ÄÇ‰∫∫ÂÄëÂú® Twitter„ÄÅFacebook„ÄÅReddit„ÄÅInstagram Á≠âÂπ≥Âè∞‰∏äË°®ÈÅîËá™Â∑±ÁöÑÊÑüÂèóÂíåÊÉÖÁ∑í„ÄÇÈÄô‰∫õÂπ≥Âè∞ÂåÖÂê´ÊúâÂÉπÂÄºÁöÑË≥áË®äÔºåÂèØÁî®ÊñºÁ†îÁ©∂ÁõÆÁöÑ„ÄÇÂ∑≤Á∂ìÂú®ÂêÑÁ®ÆÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞‰∏äÈÄ≤Ë°å‰∫ÜÂ§ßÈáèÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂä™Âäõ‰ªçÂ≠òÂú®Êüê‰∫õÈôêÂà∂„ÄÇÁâπÂà•ÊòØÔºåÂÖàÂâçÁöÑÁ†îÁ©∂ÂÉÖÂ∞àÊ≥®ÊñºÂÅµÊ∏¨Êé®Êñá‰∏≠ÁöÑÊÜÇÈ¨±ÁóáÂíåÊÜÇÈ¨±ÁóáÁöÑÂº∑Â∫¶„ÄÇÊ≠§Â§ñÔºåË≥áÊñôÈõÜÊ®ôÁ±§‰∏≠Â≠òÂú®‰∏çÊ∫ñÁ¢∫ÁöÑÊÉÖÊ≥Å„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂Â∑•‰Ωú‰∏≠Ôºå‰ΩøÁî®Âü∫ÊñºË©ûÂΩôÊ®ôÁ±§ÁöÑ Twitter Ë≥áÊñôÂ∫´‰∏≠ÁöÑÊé®ÊñáÈ†êÊ∏¨‰∫Ü‰∫îÁ®ÆÈ°ûÂûãÁöÑÊÜÇÈ¨±ÁóáÔºàÈõôÊ•µÂûã„ÄÅÈáçÂ∫¶„ÄÅÁ≤æÁ•ûÁóÖÂûã„ÄÅÈùûÂÖ∏ÂûãÂíåÁî¢ÂæåÔºâ„ÄÇÂèØËß£ÈáãÁöÑ AI Áî®ÊñºÈÄèÈÅéÂº∑Ë™ø‰ª£Ë°®ÊÜÇÈ¨±ÁóáÈ°ûÂûãÁöÑÊé®ÊñáÈÉ®ÂàÜ‰æÜÊèê‰æõÊé®ÁêÜ„ÄÇÂæû TransformersÔºàBERTÔºâ‰∏≠ÊèêÂèñÁöÑÈõôÂêëÁ∑®Á¢ºÂô®Ë°®Á§∫Áî®ÊñºÁâπÂæµÊèêÂèñÂíåË®ìÁ∑¥„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÁî®ÊñºË®ìÁ∑¥Ê®°Âûã„ÄÇBERT Ê®°ÂûãÂëàÁèæÂá∫ÊúÄÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÈÅîÂà∞ 0.96 ÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠¶‰π†Ê≠£Â§ßÂπÖËΩâËÆäÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÊîæÂ∞ÑÁ∑öÂ≠∏È†òÂüüÔºåËÉΩËæ®Ë≠òÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÁóÖÁêÜÔºåÂåÖÊã¨ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT) Âíå X ÂÖâÊéÉÊèè„ÄÇÁÑ∂ËÄåÔºåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®ÂàÜÂâ≤‰ªªÂãô‰∏≠ÔºåÂ∏∏Â∏∏ÂèóÂà∞Âª£Ê≥õË®ªËß£Ë≥áÊñôÈõÜÈúÄÊ±ÇÁöÑÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊ≠§ÊåëÊà∞ÔºåÈÄèÈÅéÂèØËß£Èáã AI ÂíåÂèç‰∫ãÂØ¶Ëß£ÈáãÁöÑÁî¢ÁîüÔºåÊé¢Á¥¢Âº±Áõ£Áù£Ë™ûÊÑèÂàÜÂâ≤ÁöÑËÉΩÂäõ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁØÑÂúçÊòØÈñãÁôº‰∏ÄÁ®ÆÊñ∞ÁöÑÂèç‰∫ãÂØ¶ÂÖßÊèíÊñπÊ≥ï (COIN)ÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®ÁîüÊàêÊ®°ÂûãÂ∞áÈ†êÊ∏¨ÁöÑÂàÜÈ°ûÊ®ôÁ±§ÂæûÁï∞Â∏∏ÁøªËΩâÁÇ∫Ê≠£Â∏∏„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÂàÜÈ°ûÂô®Â∞áËº∏ÂÖ•ÁöÑÈÜ´Â≠∏ÂΩ±ÂÉè X Ë¶ñÁÇ∫Áï∞Â∏∏ÔºåË°®Á§∫Â≠òÂú®ÁóÖÁêÜÔºåÂâáÁîüÊàêÊ®°ÂûãÊó®Âú®ÂÖßÊèíÁï∞Â∏∏ÂçÄÂüüÔºåÂæûËÄåÈÄÜËΩâÂàÜÈ°ûÂô®ÁöÑÂéüÂßãÈ†êÊ∏¨Ê®ôÁ±§„ÄÇÊ≠§ÊñπÊ≥ï‰ΩøÊàëÂÄëËÉΩÂ§†Áî¢ÁîüÁóÖÁêÜÁöÑÁ≤æÁ¢∫ÂàÜÂâ≤ÔºåËÄåÁÑ°ÈúÄ‰æùË≥¥ÊñºÈ†êÂÖàÂ≠òÂú®ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÂà©Áî®ÂΩ±ÂÉèÂ±§Á¥öÊ®ôÁ±§ÔºåÈÄôÊØîÂª∫Á´ãË©≥Á¥∞ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©ÂÆπÊòìÂèñÂæó„ÄÇË©≤ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÈÄèÈÅéÂàÜÂâ≤ÂêàÊàêÁõÆÊ®ôÂíåÂæûÊÑõÊ≤ôÂ∞º‰∫ûÂ°îÁàæÂúñÂ§ßÂ≠∏ÈÜ´Èô¢ÂèñÂæóÁöÑ CT ÂΩ±ÂÉè‰∏≠ÁöÑÂØ¶ÈöõËÖéËáüËÖ´Áò§‰æÜË≠âÊòé„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåCOIN ÈÅ†ÈÅ†Ë∂ÖÈÅéÂ∑≤Âª∫Á´ãÁöÑÊ≠∏Âõ†ÊñπÊ≥ïÔºå‰æãÂ¶Ç RISE„ÄÅScoreCAM Âíå LayerCAMÔºå‰ª•Âèä Singla Á≠â‰∫∫ÊèêÂá∫ÁöÑÂè¶‰∏ÄÁ®ÆÂèç‰∫ãÂØ¶Ëß£ÈáãÊñπÊ≥ï„ÄÇÊ≠§Ë≠âÊìöË°®ÊòéÔºåCOIN ÊòØ‰∏ÄÁ®ÆÂæàÊúâÂâçÈÄîÁöÑ CT ÂΩ±ÂÉè‰∏≠ËÖ´Áò§Ë™ûÊÑèÂàÜÂâ≤ÊñπÊ≥ïÔºå‰∏¶Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ËÆìÊ∑±Â∫¶Â≠∏ÁøíÊáâÁî®Êõ¥ÊòìÊñºÂèñÂæóÂíåÊõ¥ÊúâÊïàÁéáÈÇÅÈÄ≤‰∏ÄÊ≠•ÔºåÂÖ∂‰∏≠Ë®ªËß£Ë≥áÊñôÂæàÁ®ÄÂ∞ë„ÄÇ

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÊï∏‰Ωç‰∫∫ÊñáÂ≠∏Áßë (DH) ‰ΩúÁÇ∫‰∏ÄÈñÄÂ≠∏ÁßëËàáÊ∑∑ÂêàÊô∫ËÉΩ (HI) ‰ΩúÁÇ∫‰∏ÄÂÄãÁ†îÁ©∂ÂÖ∏ÁØÑ‰πãÈñìÁöÑÂçîÂêå‰ΩúÁî®„ÄÇÂú® DH Á†îÁ©∂‰∏≠ÔºåÊï∏‰ΩçÊñπÊ≥ïÁöÑ‰ΩøÁî®ÔºåÁâπÂà•ÊòØ‰∫∫Â∑•Êô∫ÊÖßÁöÑ‰ΩøÁî®ÔºåÂèóÂà∞‰∏ÄÁ≥ªÂàóË¶ÅÊ±ÇÂíåÈôêÂà∂„ÄÇÊàëÂÄëË™çÁÇ∫ÈÄô‰∫õË¶ÅÊ±ÇÂíåÈôêÂà∂Áç≤Âæó HI ÁöÑËÉΩÂäõÂíåÁõÆÊ®ôÁöÑÂÖÖÂàÜÊîØÊåÅ„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÂåÖÊã¨ÊâæÂá∫‰∫îÂÄãÈÄôÊ®£ÁöÑ DH Ë¶ÅÊ±ÇÔºöÊàêÂäüÁöÑ AI Á≥ªÁµ±ÈúÄË¶ÅËÉΩÂ§† 1) ËàáÔºà‰∫∫È°ûÔºâÂ≠∏ËÄÖÂêà‰ΩúÔºõ2) ÊîØÊè¥Ë≥áÊñôÊâπË©ïÔºõ3) ÊîØÊè¥Â∑•ÂÖ∑ÊâπË©ïÔºõ4) ÂØüË¶∫‰∏¶ËøéÂêàÂêÑÁ®ÆËßÄÈªûÔºõ5) ÊîØÊè¥ÈÅ†Ë∑ùÂíåËøëË∑ùÈõ¢Èñ±ËÆÄ„ÄÇÊàëÂÄëÂ∞áÊ∑∑ÂêàÊô∫ËÉΩÁöÑ CARE ÂéüÂâáÔºàÂçî‰Ωú„ÄÅÈÅ©Êáâ„ÄÅË≤†Ë≤¨ÂíåÂèØËß£ÈáãÔºâ‰ΩúÁÇ∫ÁêÜË´ñÊû∂ÊßãÔºå‰∏¶Â∞áÈÄô‰∫õÂéüÂâáÂ∞çÊáâÂà∞ DH Ë¶ÅÊ±Ç„ÄÇÂú®Ê≠§Â∞çÊáâ‰∏≠ÔºåÊàëÂÄëÁ¥çÂÖ•ÁØÑ‰æãÁ†îÁ©∂Â∞àÊ°à„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé¢Ë®éÂ¶Ç‰ΩïÂ∞á DH ÁöÑË¶ãËß£ÊáâÁî®Êñº HIÔºå‰∏¶Ë®éË´ñÁµêÂêàÈÄôÂÖ©ÂÄãÂ≠∏ÁßëÁöÑÈñãÊîæÊåëÊà∞„ÄÇ

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°Âûã (FM) ÂÖ∑ÊúâÂæπÂ∫ïÊîπËÆäÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®ÁèæÂØ¶‰∏ñÁïåËá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÈÉ®ÁΩ≤ÈúÄË¶ÅÂª£Ê≥õÁöÑÂÄ´ÁêÜËÄÉÈáè„ÄÇÊú¨ÊñáÊó®Âú®Âº∑Ë™øËàá FM Áõ∏ÈóúÁöÑÂÄ´ÁêÜÂïèÈ°åÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÊ°ÜÊû∂‰æÜÊåáÂ∞éÂÆÉÂÄëÂú®ÈÜ´Â≠∏‰∏≠ÁöÑË≤†Ë≤¨‰ªªÈñãÁôºÂíåÂØ¶ÊñΩ„ÄÇÊàëÂÄë‰ªîÁ¥∞ÂØ©Êü•‰∫ÜÂÄ´ÁêÜÂïèÈ°åÔºå‰æãÂ¶ÇÊÇ£ËÄÖÊï∏ÊìöÈö±ÁßÅ„ÄÅÂÅèÂ∑ÆÁ∑©Ëß£„ÄÅÊºîÁÆóÊ≥ïÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÂïèË≤¨Âà∂„ÄÇÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂Êó®Âú®ÂÑ™ÂÖàËÄÉÊÖÆÊÇ£ËÄÖÁ¶èÂà©„ÄÅÊ∏õËºïÊΩõÂú®È¢®Èö™Ôºå‰∏¶ÂüπÈ§äÂ∞ç AI ËºîÂä©ÈÜ´ÁôÇ‰øùÂÅ•ÁöÑ‰ø°‰ªª„ÄÇ

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

ÊëòË¶ÅÔºöÁî≤ÁãÄËÖ∫ÁôåÊòØ‰∏ÄÁ®ÆÊó•ÁõäÂö¥ÈáçÁöÑÂÖ®ÁêÉÂÅ•Â∫∑ÂïèÈ°åÔºåÈúÄË¶ÅÂÖàÈÄ≤ÁöÑË®∫Êñ∑ÊñπÊ≥ï„ÄÇÊú¨ÁØáË©ïË´ñÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ËÉΩËàáÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÂú®Áî≤ÁãÄËÖ∫ÁôåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÂú®Á¨¶Âêà PRISMA ÊåáÂçóÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞çÂ§öÂÄãË≥áÊñôÂ∫´ÈÄ≤Ë°å‰∫ÜÂõûÈ°ßÔºåÁõ¥Âà∞ 2023 Âπ¥ 10 Êúà„ÄÇÈÄöÈÅéÁµêÂêàÈóúÈçµÂ≠óÔºåÁôºÁèæ‰∫Ü‰∏ÄÁØáÈóúÊñºÁî≤ÁãÄËÖ∫ÁôåÂíåÁõ∏Èóú‰∏ªÈ°åÁöÑËã±ÊñáÂ≠∏Ë°ìÂá∫ÁâàÁâ©„ÄÇÂú®ÁßªÈô§ 109 ÁØáÈáçË§áÊñáÁçªÂæåÔºåÂéüÂßãÊêúÂ∞ãÂÖ±ÂõûÂÇ≥ 267 ÁØáË´ñÊñá„ÄÇÂú®Ê†πÊìöÈ†êÂÖàÁ¢∫ÂÆöÁöÑÊ®ôÊ∫ñÔºåÊ∑òÊ±∞‰∫Ü 124 ÁØáÊñáÁ´†ÁöÑÊëòË¶ÅÂíåÊ®ôÈ°åÂæåÔºåÈÅ∏Âá∫‰∫ÜÁõ∏ÈóúÁ†îÁ©∂„ÄÇÂú®ÈÄ≤Ë°åÂÖ®Èù¢ÂàÜÊûêÂæåÔºåÈ°çÂ§ñÊéíÈô§‰∫ÜÂÖ≠È†ÖÁ†îÁ©∂„ÄÇÂú®Á¥çÂÖ•ÁöÑ 28 È†ÖÁ†îÁ©∂‰∏≠ÔºåÁµêÂêàË∂ÖÈü≥Ê≥¢ (US) ÂΩ±ÂÉèÁöÑÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®Ë®∫Êñ∑Áî≤ÁãÄËÖ∫ÁôåÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÁ†îÁ©∂ÁµêÊûú‰∏ç‰∏ÄÔºåÊúâ‰∫õÁ†îÁ©∂ÊèêÂá∫‰∫ÜÂÑ™ÊñºÁèæÁãÄÁöÑÊñ∞Á≠ñÁï•„ÄÇÊñáÁçªÂº∑Ë™ø‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÈù¢Ëá®ÁöÑÂêÑÁ®ÆÊåëÊà∞ÔºåÂåÖÊã¨ÂèØËß£ÈáãÊÄßÂïèÈ°å„ÄÅË≥áÊñôÈõÜÈôêÂà∂ÂíåÊìç‰ΩúÂì°‰æùË≥¥ÊÄß„ÄÇ28 È†ÖÁ¥çÂÖ•Á†îÁ©∂ÁöÑÁ∂úÂêàÁôºÁèæÊèêÂà∞ÔºåÈúÄË¶ÅÊ®ôÊ∫ñÂåñÂ∑•‰ΩúÂíåÂâçÁûªÊÄßÂ§ö‰∏≠ÂøÉÁ†îÁ©∂‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÈÇÑÁ¢∫ÂÆö‰∫ÜÂÖãÊúçÈÄô‰∫õÈöúÁ§ôÁöÑÊñπÊ≥ïÔºå‰æãÂ¶ÇÂèØËß£Èáã‰∫∫Â∑•Êô∫ËÉΩÊäÄË°ìÂíåÂÄã‰∫∫ÂåñÈÜ´ÁôÇÊäÄË°ìÁöÑÈÄ≤Ê≠•„ÄÇÊú¨ÁØáË©ïË´ñÈáçÈªûÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÂíåÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÂ¶Ç‰ΩïËΩâËÆäÁî≤ÁãÄËÖ∫ÁôåÁöÑË®∫Êñ∑ÂíåÊ≤ªÁôÇ„ÄÇÂÑòÁÆ°Â≠òÂú®ÊåëÊà∞Ôºå‰ΩÜÊú™‰æÜÂ∞çÂ§öÂ≠∏ÁßëÂêà‰Ωú„ÄÅËá®Â∫äÈÅ©Áî®ÊÄßÈ©óË≠âÂíåÊºîÁÆóÊ≥ïÊîπÈÄ≤ÁöÑÁ†îÁ©∂Ôºå‰ªçÊúâÊΩõÂäõÊîπÂñÑÁî≤ÁãÄËÖ∫ÁôåÊ≤ªÁôÇ‰∏≠ÁöÑÊÇ£ËÄÖÈ†êÂæåÂíåË®∫Êñ∑Á≤æÊ∫ñÂ∫¶„ÄÇ

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºå‰π≥ÁôåÁöÑÁõõË°åÁéáËøÖÈÄüÂ¢ûÂä†Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂÖ®ÁêÉ‰∏ªË¶ÅÁöÑÊ≠ª‰∫°ÂéüÂõ†‰πã‰∏Ä„ÄÇÂú®ÊâÄÊúâÁôåÁóá‰∏≠Ôºå‰π≥ÁôåËøÑ‰ªäÁÇ∫Ê≠¢ÊòØÊúÄÂ∏∏Ë¶ãÁöÑ„ÄÇÊâãÂãïË®∫Êñ∑Ê≠§ÁñæÁóÖÈúÄË¶ÅÂ§ßÈáèÁöÑÊôÇÈñìÂíåÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÁî±Êñº‰π≥ÁôåÁöÑÊ™¢Ê∏¨ÈÅéÁ®ãËÄóÊôÇÔºåÂõ†Ê≠§ÈÄèÈÅéÂª∫Á´ãÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÈ†êÊ∏¨ÔºåÊúâÂä©ÊñºÈò≤Ê≠¢ÂÖ∂ÈÄ≤‰∏ÄÊ≠•Êì¥Êï£„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÂèØËß£Èáã AI Âú®ÂàÜÈ°û‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÂÄë‰∏çÂÉÖÂèØ‰ª•Êèê‰æõÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨ÔºåÈÇÑÂèØ‰ª•Ê∑±ÂÖ•‰∫ÜËß£Ê®°ÂûãÂ¶Ç‰ΩïÂÅöÂá∫Ê±∫Á≠ñÔºåÊúâÂä©ÊñºÁêÜËß£Âíå‰ø°Ë≥¥ÂàÜÈ°ûÁµêÊûú„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∏¶ÊØîËºÉ‰∫Ü‰∫îÁ®Æ‰∏çÂêåÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏Ôºå‰ΩøÁî®‰∫Ü‰∏ÄÂÄã‰∏ªË¶ÅÁöÑË≥áÊñôÈõÜÔºàÈÅîÂç°ÈÜ´Â≠∏Èô¢ÈÜ´Èô¢ÁöÑ 500 ÂêçÊÇ£ËÄÖÔºâ„ÄÇ‰∫îÁ®Æ‰∏çÂêåÁöÑÁõ£Áù£ÂºèÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÔºåÂåÖÊã¨Ê±∫Á≠ñÊ®π„ÄÅÈö®Ê©üÊ£ÆÊûó„ÄÅÈÇèËºØËø¥Ê≠∏„ÄÅÊú¥Á¥†Ë≤ùÊ∞èÂíå XGBoostÔºåÂ∑≤Áî®ÊñºÂú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏äÂèñÂæóÊúÄ‰Ω≥ÁµêÊûú„ÄÇÊ≠§Â§ñÔºåÊú¨Á†îÁ©∂Â∞á SHAP ÂàÜÊûêÊáâÁî®Êñº XGBoost Ê®°ÂûãÔºå‰ª•Ëß£ÈáãÊ®°ÂûãÁöÑÈ†êÊ∏¨‰∏¶‰∫ÜËß£ÊØèÂÄãÁâπÂæµÂ∞çÊ®°ÂûãËº∏Âá∫ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜÂπæÁ®ÆÊºîÁÆóÊ≥ïÂ∞çË≥áÊñôÈÄ≤Ë°åÂàÜÈ°ûÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶ËàáË©≤È†òÂüüÁöÑÂÖ∂‰ªñÊñáÁçªÈÄ≤Ë°åÂ∞çÊØî„ÄÇÂú®ÊúÄÂæåË©ï‰º∞ÂæåÔºåÊú¨Á†îÁ©∂ÁôºÁèæ XGBoost ÈÅîÂà∞‰∫ÜÊúÄ‰Ω≥ÁöÑÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÔºåÁÇ∫ 97%„ÄÇ</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) Áî®ÊñºÂæû‰π≥ÊàøÊîùÂΩ±Ë°ìÂΩ±ÂÉèË®∫Êñ∑‰π≥ÁôåÁöÑÊ®°ÂûãÈÄöÂ∏∏‰ª•„ÄåÈªëÁõíÂ≠ê„ÄçÊñπÂºèÈÅã‰ΩúÔºåÈÄô‰ΩøÂæóÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°Èõ£‰ª•‰ø°‰ªªÂíåÁêÜËß£ÂÖ∂Ê±∫Á≠ñÈÅéÁ®ã„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊï¥ÂêàÊû∂ÊßãÔºåÁµêÂêàÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI)Ôºå‰ª•‰ΩøÁî® CBIS-DDSM Ë≥áÊñôÈõÜÂ¢ûÂº∑‰π≥ÁôåÁöÑË®∫Êñ∑„ÄÇÊñπÊ≥ïÂåÖÂê´‰∏ÄÂÄãÁ≤æÁ¥∞ÁöÑË≥áÊñôÂâçËôïÁêÜÁÆ°Á∑öÂíåÈÄ≤ÈöéË≥áÊñôÊì¥ÂÖÖÊäÄË°ìÔºå‰ª•Â∞çÊäóË≥áÊñôÈõÜÈôêÂà∂Ôºå‰∏¶Êé°Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÁ∂≤Ë∑ØÔºà‰æãÂ¶Ç VGG-16„ÄÅInception-V3 Âíå ResNetÔºâÈÄ≤Ë°åÈÅ∑ÁßªÂ≠∏Áøí„ÄÇÊàëÂÄëÁ†îÁ©∂ÁöÑÈáçÈªûÊòØË©ï‰º∞ XAI Âú®Ëß£ÈáãÊ®°ÂûãÈ†êÊ∏¨‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÈáçÈªûÂà©Áî®Ë±™ÊñØÂ§öÂ§´Ê∏¨Â∫¶ÈáèÂåñË©ï‰º∞ AI ÁîüÊàêÁöÑËß£ÈáãÂíåÂ∞àÂÆ∂Ë®ªËß£‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∞çÊñº XAI Âú®‰øÉÈÄ≤ AI ËºîÂä©Ë®∫Êñ∑‰∏≠ÁöÑÂèØ‰ø°Â∫¶ÂíåÂÄ´ÁêÜÂÖ¨Âπ≥ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÁ†îÁ©∂ÁöÑÁôºÁèæË™™Êòé‰∫Ü CNN Âíå XAI Âú®Êé®ÈÄ≤‰π≥ÁôåË®∫Êñ∑ÊñπÊ≥ï‰∏≠ÁöÑÊúâÊïàÂçî‰ΩúÔºåÂæûËÄå‰øÉÈÄ≤‰∫ÜÂÖàÈÄ≤ AI ÊäÄË°ìÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊõ¥È†ÜÊö¢Êï¥Âêà„ÄÇÈÄèÈÅéÂ¢ûÂº∑ AI È©ÖÂãïÊ±∫Á≠ñÁöÑÂèØËß£ÈáãÊÄßÔºåÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ AI Á≥ªÁµ±ÂíåÈÜ´ÁôÇÂæûÊ•≠‰∫∫Âì°‰πãÈñìÁöÑÊîπÂñÑÂçî‰ΩúÂ•†ÂÆö‰∫ÜÂü∫Á§éÔºåÊúÄÁµÇË±êÂØå‰∫ÜÊÇ£ËÄÖÁÖßË≠∑„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂ÁöÑÂΩ±ÈüøÈÅ†ÈÅ†Ë∂ÖÂá∫‰∫ÜÁõÆÂâçÁöÑÊäÄË°ì„ÄÇÂÆÉÈºìÂãµÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂Â¶Ç‰ΩïÁµêÂêàÂ§öÊ®°ÂºèË≥áÊñô‰∏¶ÊîπÂñÑ AI Ëß£ÈáãÔºå‰ª•ÊªøË∂≥Ëá®Â∫äÂØ¶ÂãôÁöÑÈúÄÊ±Ç„ÄÇ

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÂ§öÊ®°ÊÖãÊï∏ÊìöËûçÂêàÊñπÊ≥ïÔºåÁî®ÊñºÁñºÁóõË°åÁÇ∫Ë≠òÂà•ÔºåÂ∞áÁµ±Ë®àÁõ∏ÈóúÂàÜÊûêËàá‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑË¶ãËß£Áõ∏ÁµêÂêà„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂºïÂÖ•‰∫ÜÂÖ©È†ÖÈóúÈçµÂâµÊñ∞Ôºö1) Â∞áÊï∏ÊìöÈ©ÖÂãïÁöÑÁµ±Ë®àÁõ∏ÈóúÊ¨äÈáçÊï¥ÂêàÂà∞ËûçÂêàÁ≠ñÁï•‰∏≠Ôºå‰ª•ÊúâÊïàÂà©Áî®‰æÜËá™Áï∞Ë≥™Ê®°ÊÖãÁöÑË£úÂÖÖ‰ø°ÊÅØÔºå‰ª•Âèä 2) Â∞á‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑÈÅãÂãïÁâπÂæµÁ¥çÂÖ•Â§öÊ®°ÊÖãË°®Á§∫Â≠∏Áøí‰∏≠Ôºå‰ª•Ë©≥Á¥∞Âª∫Ê®°ÁñºÁóõË°åÁÇ∫„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂêÑÁ®ÆÊ∑±Â∫¶Â≠∏ÁøíÊû∂Êßã‰∏≠ÂæóÂà∞È©óË≠âÔºåÂ±ïÁ§∫‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩÂíåÂª£Ê≥õÁöÑÈÅ©Áî®ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËá™ÂÆöÁæ©ÁöÑÊ°ÜÊû∂ÔºåÊ†πÊìöÁµ±Ë®àÈ°ØËëóÊÄßÂ∞áÊØèÂÄãÊ®°ÊÖãËàáÂêàÈÅ©ÁöÑÂàÜÈ°ûÂô®Â∞çÈΩäÔºåÊé®ÈÄ≤ÂÄãÊÄßÂåñÂíåÊúâÊïàÁöÑÂ§öÊ®°ÊÖãËûçÂêà„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊèê‰æõÂ∞çÂ§öÊ®°ÊÖãÊï∏ÊìöÁöÑÂèØËß£ÈáãÂàÜÊûêÔºåÊúâÂä©ÊñºÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂèØËß£ÈáãÂíåÂèØËß£Èáã AI„ÄÇÈÄöÈÅéÂº∑Ë™øÊï∏ÊìöÂ§öÊ®£ÊÄßÂíåÊ®°ÊÖãÁâπÂÆöË°®Á§∫ÁöÑÈáçË¶ÅÊÄßÔºåÊàëÂÄëÂ¢ûÂº∑‰∫ÜÂÇ≥Áµ±ÁöÑËûçÂêàÊäÄË°ìÔºå‰∏¶ÁÇ∫Ë≠òÂà•Ë§áÈõúÁöÑÁñºÁóõË°åÁÇ∫Ë®≠ÂÆö‰∫ÜÊñ∞ÁöÑÊ®ôÊ∫ñ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂ∞ç‰øÉÈÄ≤‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÈÜ´ÁôÇ‰øùÂÅ•Âπ≤È†êÂíåÊîØÊåÅÂèØËß£ÈáãÁöÑËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂÖ∑ÊúâÈáçË¶ÅÊÑèÁæ©„ÄÇ

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

ÊëòË¶ÅÔºö‰ª•‰∫∫‰∏∫Êú¨ÁöÑÂèØËß£Èáä AI (HCXAI) ÂÄ°ÂØºÂ∞ÜÁ§æ‰ºöÂ±ÇÈù¢Êï¥ÂêàÂà∞ AI Ëß£Èáä‰∏≠„ÄÇHCXAI ËØùËØ≠ÁöÑÊ†∏ÂøÉÊòØÁ§æ‰ºöÈÄèÊòéÂ∫¶ (ST) Ê°ÜÊû∂ÔºåÂÖ∂ÁõÆÊ†áÊòØËÆ© AI Á≥ªÁªüÁöÑÁ§æ‰ºöÁªÑÁªáËÉåÊôØÂØπÁî®Êà∑Êù•ËØ¥ÊòØÂèØÁêÜËß£ÁöÑ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Âª∫ËÆÆÊâ©Â±ï ST Ê°ÜÊû∂‰ª•Ëß£ÂÜ≥Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰∏≠Á§æ‰ºöÈîôËØØÂΩíÂõ†ÁöÑÈ£éÈô©ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂøÉÁêÜÂÅ•Â∫∑Á≠âÊïèÊÑüÈ¢ÜÂüü„ÄÇ‰∫ãÂÆû‰∏äÔºåLLM ËÉΩÂ§üÂá∫Ëâ≤Âú∞Ê®°ÊãüËßíËâ≤Âíå‰∫∫Ê†ºÔºåËøôÂèØËÉΩÂØºËá¥ËÆæËÆ°ËÄÖÁöÑÊÑèÂõæÂíåÁî®Êà∑ÂØπÁ§æ‰ºöÂ±ûÊÄßÁöÑËÆ§Áü•‰πãÈó¥Âá∫Áé∞ÈîôÈÖçÔºå‰ªéËÄåÊúâÈ£éÈô©‰øÉËøõÊÉÖÁª™ÊìçÁ∫µÂíåÂç±Èô©Ë°å‰∏∫„ÄÅËÆ§Áü•‰∏çÂÖ¨Ê≠£Âíå‰∏çÂêàÁêÜÁöÑ‰ø°‰ªª„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨Âª∫ËÆÆÁî®Á¨¨‰∫î‰∏™‚ÄúW ÈóÆÈ¢ò‚ÄùÊù•Â¢ûÂº∫ ST Ê°ÜÊû∂Ôºå‰ª•ÊòéÁ°ÆËÆæËÆ°ËÄÖÂíåÁî®Êà∑Ëµã‰∫à LLM ÁöÑÂÖ∑‰ΩìÁ§æ‰ºöÂ±ûÊÄß„ÄÇÊ≠§Ë°•ÂÖÖÊó®Âú®Âº•Âêà LLM ËÉΩÂäõÂíåÁî®Êà∑ËÆ§Áü•‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºå‰øÉËøõÂü∫‰∫é LLM ÁöÑÊäÄÊúØÂú®ÈÅìÂæ∑‰∏äË¥üË¥£‰ªªÂú∞ÂºÄÂèëÂíå‰ΩøÁî®„ÄÇ

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÔºöÊ∞£ËÉ∏ÊòØ‰∏ÄÁ®ÆÂõ†ËÇ∫ÈÉ®ËàáËÉ∏Â£Å‰πãÈñìÁï∞Â∏∏ÈõÜÊ∞£ÊâÄÂºïËµ∑ÁöÑÊÄ•ÊÄßËÉ∏ËÖîÁñæÁóÖ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê∑±Â∫¶Â≠∏ÁøíÔºàDLÔºâÊ®°ÂûãÁ∂ìÂ∏∏‰º¥Èö®ÁöÑ‰∏çÈÄèÊòéÊÄßÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÊñπÊ≥ïÂ∑≤Ë¢´ÂºïÂÖ•ÔºåÁî®ÊñºÊ¶ÇËø∞Ëàá DL Ê®°ÂûãÂÅöÂá∫ÁöÑÊ∞£ËÉ∏Ë®∫Êñ∑Áõ∏ÈóúÁöÑÂçÄÂüü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õËß£ÈáãÊúâÊôÇÊúÉËàáÂØ¶ÈöõÁóÖÁÅ∂ÂçÄÂüüÊúâÊâÄÂá∫ÂÖ•ÔºåÁ™ÅÈ°ØÂá∫ÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤ÁöÑÂøÖË¶ÅÊÄß„ÄÇÊñπÊ≥ïÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÊùøÂºïÂ∞éÂºèÊñπÊ≥ïÔºåÂ∞áÊ∞£ËÉ∏ÁöÑËá®Â∫äÁü•Ë≠òÁ¥çÂÖ• XAI ÊñπÊ≥ïÁî¢ÁîüÁöÑÊ®°ÂûãËß£Èáã‰∏≠ÔºåÂæûËÄåÊèêÂçáÈÄô‰∫õËß£ÈáãÁöÑÂìÅË≥™„ÄÇÂà©Áî®ÊîæÂ∞ÑÁßëÈÜ´Â∏´Âª∫Á´ãÁöÑÁóÖÁÅ∂ÊèèÁπ™ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈ¶ñÂÖàÁî¢Áîü‰∏ÄÂÄãÊ®°ÊùøÔºåÁî®ÊñºË°®Á§∫Ê∞£ËÉ∏ÂèØËÉΩÁôºÁîüÁöÑÂçÄÂüü„ÄÇÁÑ∂ÂæåÂ∞áÊ≠§Ê®°ÊùøÁñäÂä†Âú®Ê®°ÂûãËß£Èáã‰∏äÔºå‰ª•ÁØ©ÈÅ∏Âá∫Ë∂ÖÂá∫Ê®°ÊùøÈÇäÁïåÁöÑÁÑ°ÈóúËß£Èáã„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÂÖ∂ÊïàÂäõÔºåÊàëÂÄëÂ∞ç‰∏âÁ®Æ XAI ÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÊØîËºÉÂàÜÊûêÔºåÂú®ÂÖ©ÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏≠Ëß£ÈáãÂÖ©ÂÄã DL Ê®°ÂûãÊôÇÔºåÂàÜÂà•Êé°Áî®Âíå‰∏çÊé°Áî®ÊàëÂÄëÁöÑÊ®°ÊùøÂºïÂ∞é„ÄÇÁµêÊûúÔºöÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Âª∫Á´ãÊñº‰∏âÁ®Æ XAI ÊñπÊ≥ï„ÄÅÂÖ©ÂÄã DL Ê®°ÂûãÂíåÂÖ©ÂÄãË≥áÊñôÈõÜÁöÑÂçÅ‰∫åÁ®ÆÂü∫Ê∫ñÊÉÖÂ¢É‰∏≠ÔºåÂßãÁµÇÊîπÂñÑ‰∫ÜÂü∫Ê∫ñ XAI ÊñπÊ≥ï„ÄÇÂú®ÊØîËºÉÊ®°ÂûãËß£ÈáãÂíåÁúüÂØ¶ÁóÖÁÅ∂ÂçÄÂüüÊôÇÔºåÈÄèÈÅéÂü∫Ê∫ñÊïàËÉΩÁöÑÊïàËÉΩÊîπÈÄ≤Ë®àÁÆóÂá∫ÁöÑÂπ≥ÂùáÂ¢ûÈáèÁôæÂàÜÊØîÁÇ∫‰∫§ÈõÜÊØîÔºàIoUÔºâÁöÑ 97.8% ÂíåÈ™∞Â≠êÁõ∏‰ººÊÄß‰øÇÊï∏ÔºàDSCÔºâÁöÑ 94.1%„ÄÇÁµêË´ñÔºöÂú®Ê∞£ËÉ∏Ë®∫Êñ∑ÁöÑËÉåÊôØ‰∏ãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÊùøÂºïÂ∞éÂºèÊñπÊ≥ïÔºåÁî®ÊñºÊîπÂñÑ AI Ëß£Èáã„ÄÇÊàëÂÄëÈ†êÊúüÊàëÂÄëÁöÑÊ®°ÊùøÂºïÂ∞éÂ∞áÈÄèÈÅéÊï¥ÂêàËá®Â∫äÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠òÔºåÁÇ∫Èó°Êòé AI Ê®°ÂûãÂª∫Á´ã‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ï„ÄÇ</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by S√©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

ÊëòË¶ÅÔºö<paragraph>Âú®Áï∂ÂâçÊ©üÂô®ÁøªË≠Ø (MT) È†òÂüü‰∏≠ÔºåTransformer Êû∂ÊßãËÑ´Á©éËÄåÂá∫ÔºåÊàêÁÇ∫ÈªÉÈáëÊ®ôÊ∫ñÔºåÁâπÂà•ÊòØÂ∞çÊñºÈ´òË≥áÊ∫êË™ûË®ÄÂ∞ç„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®éÂÖ∂Â∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÊïàËÉΩÔºåÂåÖÊã¨Ëã±Ë™û‚ÜîÊÑõÁàæËò≠Ë™ûÂíåËã±Ë™û‚ÜîÈ¶¨ÊãâÂú∞Ë™ûË™ûË®ÄÂ∞ç„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊú¨Á†îÁ©∂Ë≠òÂà•Âá∫ÊúÄ‰Ω≥Ë∂ÖÂèÉÊï∏ÂíåÂ≠êË©ûÊ®°ÂûãÈ°ûÂûãÔºå‰ª•È°ØËëóÊèêÈ´ò Transformer Ê®°ÂûãÂ∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÁøªË≠ØÂìÅË≥™„ÄÇ
‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑÂπ≥Ë°åË≥áÊñôÈõÜÁöÑÁ®ÄÁº∫ÊúÉÈòªÁ§ô MT ÁöÑÁôºÂ±ï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈñãÁôº‰∫Ü gaHealthÔºåÈÄôÊòØÊÑõÁàæËò≠Ë™ûÁöÑÁ¨¨‰∏ÄÂÄãÈõôË™ûÂÅ•Â∫∑Ë≥áÊñôË™ûÊñôÂ∫´„ÄÇÂ∞àÊ≥®ÊñºÂÅ•Â∫∑È†òÂüüÔºå‰ΩøÁî®Ê≠§ÂüüÂÖßË≥áÊñôÈõÜÈñãÁôºÁöÑÊ®°ÂûãÂú® BLEU ÂæóÂàÜÊñπÈù¢Ë°®ÁèæÂá∫ÈùûÂ∏∏È°ØËëóÁöÑÈÄ≤Ê≠•ÔºåËàá LoResMT2021 ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁöÑÊ®°ÂûãÁõ∏ÊØî„ÄÇÈö®Âæå‰ΩøÁî®Â§öÁ∂≠ÂìÅË≥™ÊåáÊ®ôÈåØË™§ÂàÜÈ°ûÊ≥ïÈÄ≤Ë°åÁöÑ‰∫∫Â∑•Ë©ï‰º∞È°ØÁ§∫ÔºåËàáÂü∫Êñº RNN ÁöÑÂ∞çÊáâÊ®°ÂûãÁõ∏ÊØîÔºåTransformer Á≥ªÁµ±Âú®Ê∏õÂ∞ëÊ∫ñÁ¢∫ÊÄßÂíåÊµÅÊö¢ÊÄßÈåØË™§ÊñπÈù¢Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊÄßËÉΩ„ÄÇ
Ê≠§Â§ñÔºåÊú¨Ë´ñÊñá‰ªãÁ¥π‰∫Ü adaptNMT Âíå adaptMLLMÔºåÈÄôÂÖ©ÂÄãÈñãÊ∫êÊáâÁî®Á®ãÂºèÁ∞°Âåñ‰∫ÜÁ•ûÁ∂ìÊ©üÂô®ÁøªË≠ØÊ®°ÂûãÁöÑÈñãÁôº„ÄÅÂæÆË™øÂíåÈÉ®ÁΩ≤„ÄÇÈÄô‰∫õÂ∑•ÂÖ∑Â§ßÂπÖÁ∞°Âåñ‰∫ÜË®≠ÂÆöÂíåË©ï‰º∞ÊµÅÁ®ãÔºåËÆì MT Êõ¥ÂÆπÊòìËÆìÈñãÁôº‰∫∫Âì°ÂíåÁøªË≠Ø‰∫∫Âì°‰ΩøÁî®„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåadaptNMT ‰ª• OpenNMT ÁîüÊÖãÁ≥ªÁµ±ÁÇ∫Âü∫Á§éÔºåÈÄöÈÅéÂº∑Ë™øÊ®°ÂûãÈñãÁôºÁöÑÁí∞Â¢ÉË∂≥Ë∑°‰æÜ‰øÉÈÄ≤ÁîüÊÖãÂèãÂ•ΩÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ†îÁ©∂„ÄÇËàá LoResMT2021 ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºåadaptMLLM Â∞ç MLLM ÁöÑÂæÆË™øË≠âÊòé‰∫ÜËã±Ë™û‚ÜîÊÑõÁàæËò≠Ë™ûÂíåËã±Ë™û‚ÜîÈ¶¨ÊãâÂú∞Ë™ûÈÄôÂÖ©ÂÄã‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÁøªË≠ØÊÄßËÉΩÈÄ≤Ê≠•„ÄÇ</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËààËµ∑Ôºå‰∫ÜËß£ÂÆÉÂÄëÂú®Ëß£Á¢ºÂíåËß£ÈáãË™ûË®ÄÊâÄËòäÂê´ÁöÑË§áÈõúÂõ†ÊûúÈóú‰øÇÁ∂≤Ë∑Ø‰∏≠ÁöÑËÉΩÂäõÂíåÈôêÂà∂ËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇÁõÆÂâçÁöÑÊäÄË°ì‰ΩøÁî®ÊòéÁ¢∫ÊàñÈö±Âê´ÁöÑÂõ†ÊûúÊé®ÁêÜÔºå‰ΩÜÂº∑ÁÉàÈúÄË¶Å‰∏ÄÁ®ÆÁµ±‰∏ÄÁöÑÊñπÊ≥ïÔºåÁµêÂêàÂÖ©ËÄÖ‰ª•Êõ¥ÊúâÊïàÂú∞ËôïÁêÜÂª£Ê≥õÁöÑÂõ†ÊûúÈóú‰øÇ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ÊÉÖÂ¢ÉÊÑüÁü•Êé®ÁêÜÂ¢ûÂº∑ËàáÂèç‰∫ãÂØ¶ÂàÜÊûê (CARE CA) Ê°ÜÊû∂ÁöÑÊñ∞Êû∂ÊßãÔºå‰ª•Â¢ûÂº∑Âõ†ÊûúÊé®ÁêÜÂíåÂèØËß£ÈáãÊÄß„ÄÇÊèêÂá∫ÁöÑÊ°ÜÊû∂ÁµêÂêà‰∫Ü‰ΩøÁî® ConceptNet ÂíåÂèç‰∫ãÂØ¶Èô≥Ëø∞ÁöÑÊòéÁ¢∫Âõ†ÊûúÊ™¢Ê∏¨Ê®°ÁµÑÔºå‰ª•ÂèäÈÄèÈÅé LLM ÈÄ≤Ë°åÁöÑÈö±Âê´Âõ†ÊûúÊ™¢Ê∏¨„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂Êõ¥ÈÄ≤‰∏ÄÊ≠•ÔºåÂä†ÂÖ•‰∏ÄÂ±§Âèç‰∫ãÂØ¶Ëß£ÈáãÔºå‰ª•Âº∑Ë™ø LLM Â∞çÂõ†ÊûúÈóú‰øÇÁöÑÁêÜËß£„ÄÇ‰æÜËá™ ConceptNet ÁöÑÁü•Ë≠òÂ¢ûÂº∑‰∫ÜÂ§öÈ†ÖÂõ†ÊûúÊé®ÁêÜ‰ªªÂãôÁöÑÂü∑Ë°åÔºå‰æãÂ¶ÇÂõ†ÊûúÁôºÁèæ„ÄÅÂõ†ÊûúË≠òÂà•ÂíåÂèç‰∫ãÂØ¶Êé®ÁêÜ„ÄÇÂèç‰∫ãÂØ¶Âè•Âä†ÂÖ•‰∫ÜÊú™Áî±ÊÉÖÂ¢ÉÈÄ†ÊàêÁöÑÊòéÁ¢∫Áü•Ë≠ò„ÄÇÈÄèÈÅéÁµêÂêàÈÄô‰∫õÂº∑Â§ßÁöÑÊ®°ÁµÑÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊó®Âú®Êèê‰æõÂ∞çÂõ†ÊûúÈóú‰øÇÊõ¥Ê∑±ÂÖ•ÁöÑÁêÜËß£ÔºåÂØ¶ÁèæÂ¢ûÂº∑ÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂü∫Ê∫ñË≥áÊñôÈõÜÁöÑË©ï‰º∞È°ØÁ§∫Âú®ÊâÄÊúâÊåáÊ®ôÔºà‰æãÂ¶ÇÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏Ôºâ‰∏äÈÉΩÊúâÊâÄÊèêÂçá„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü CausalNetÔºå‰∏ÄÂÄãÊñ∞ÁöÑË≥áÊñôÈõÜÔºå‰∏¶ÈôÑ‰∏ä‰∫ÜÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÔºå‰ª•‰øÉÈÄ≤Âú®ÈÄôÂÄãÈ†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂„ÄÇ

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

ÊëòË¶ÅÔºöÁ≥ñÂ∞øÁóÖÔºàDMÔºâ‰ΩøÊÇ£ËÄÖÂÆπÊòìÂá∫ÁèæË°ÄÁÆ°‰ΩµÁôºÁóá„ÄÇ
Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂíåË°ÄÁÆ°ÂèçÊò†Ë∫´È´îÁöÑÂæÆË°ÄÁÆ°ÂíåÂ∑®Ë°ÄÁÆ°ÂÅ•Â∫∑ÁãÄÊ≥Å„ÄÇÂÆÉÂÄëÂèØÁî®ÊñºË®∫Êñ∑Á≥ñÂ∞øÁóÖ‰ΩµÁôºÁóáÔºåÂåÖÊã¨Á≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÔºàDRÔºâ„ÄÅÁ•ûÁ∂ìÁóÖËÆä„ÄÅËÖéÁóÖÂíåÂãïËÑàÁ≤•Ê®£Á°¨ÂåñÊÄßÂøÉË°ÄÁÆ°ÁñæÁóÖÔºå‰ª•ÂèäÈ†êÊ∏¨ÂøÉË°ÄÁÆ°‰∫ã‰ª∂ÁöÑÈ¢®Èö™„ÄÇÁÇ∫‰ΩøÁî®Êï∏‰ΩçÂåñË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÈÄ≤Ë°åÈ´òÈÄöÈáè DR Ê™¢Ê∏¨ËÄåÈñãÁôºÁöÑ‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂïüÁî®Á≥ªÁµ±Â∑≤Âú®Ëá®Â∫äÊé°Áî®„ÄÇÈô§‰∫Ü DR ÁØ©Ê™¢Â§ñÔºåAI Êï¥Âêà‰πüÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ‰æÜÊáâÂ∞çËàáÁ≥ñÂ∞øÁóÖÊÇ£ËÄÖÊï¥È´îÁÖßË≠∑Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊó®Âú®ÂÖ®Èù¢ÂõûÈ°ßÂü∫ÊñºË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÁöÑ AI ÊáâÁî®Áõ∏ÈóúÁ†îÁ©∂ÁöÑÊñáÁçªÔºåÈÄô‰∫õÁ†îÁ©∂ËàáÁ≥ñÂ∞øÁóÖÁöÑË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁÆ°ÁêÜÊúâÈóú„ÄÇÊàëÂÄëÂ∞áÊèèËø∞Êï¥È´î AI ËºîÂä©Á≥ñÂ∞øÁóÖÁÖßË≠∑ÁöÑÁôºÁèæÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôêÊñº DR ÁØ©Ê™¢Ôºå‰∏¶Ë®éË´ñÂØ¶ÊñΩÊ≠§È°ûÁ≥ªÁµ±ÁöÑÈöúÁ§ôÔºåÂåÖÊã¨ËàáÂÄ´ÁêÜ„ÄÅË≥áÊñôÈö±ÁßÅ„ÄÅÂÖ¨Âπ≥Â≠òÂèñÂíåÂèØËß£ÈáãÊÄßÊúâÈóúÁöÑÂïèÈ°å„ÄÇÈÄèÈÅéË©ï‰º∞ÊÇ£ËÄÖÁöÑÂÅ•Â∫∑ÁãÄÊ≥ÅÔºåÂêåÊôÇËÄÉÈáèÁ≥ñÂ∞øÁóÖ‰ΩµÁôºÁóá‰ª•ÂèäÊú™‰æÜÂøÉË°ÄÁÆ°‰ΩµÁôºÁóáÁöÑÈ¢®Èö™È†êÂæåÔºåAI ËºîÂä©Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂàÜÊûêÊúâÊΩõÂäõÊàêÁÇ∫Á≥ñÂ∞øÁóÖÊÇ£ËÄÖÁèæ‰ª£ÂåñÂÄã‰∫∫ÂåñÈÜ´ÁôÇÁöÑ‰∏≠ÂøÉÂ∑•ÂÖ∑„ÄÇ

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

ÊëòË¶ÅÔºöÈÄôÈ†ÖÁ†îÁ©∂ÂæûÂ§öÂÄãÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑËßíÂ∫¶Êé¢Ë®é‰∏çÂêåÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊáâÁî®Âú®ÊïôËÇ≤‰∏äÁöÑÂèØÊé•ÂèóÊÄßÔºåÂåÖÊã¨Â≠∏Áîü„ÄÅËÄÅÂ∏´ÂíåÂÆ∂Èï∑„ÄÇÊâøË™ç AI Âú®ÊïôËÇ≤‰∏äÁöÑËΩâÂûãÊΩõÂäõÔºåÂÆÉËß£Ê±∫‰∫ÜËàáË≥áÊñôÈö±ÁßÅ„ÄÅAI ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíå AI ÁöÑÈÅìÂæ∑ÈÉ®ÁΩ≤Áõ∏ÈóúÁöÑÁñëÊÖÆ„ÄÇÈÄèÈÅéÂ∞èÊèíÊõ≤ÊñπÊ≥ïÔºåÂèÉËàáËÄÖË¢´ÂëàÁèæ‰∫ÜÂõõÁ®ÆÊÉÖÂ¢ÉÔºåÂÖ∂‰∏≠ AI ÁöÑ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÈö±ÁßÅÂèóÂà∞ÊìçÁ∏±„ÄÇÂú®ÊØèÂÄãÊÉÖÂ¢ÉÂæåÔºåÂèÉËàáËÄÖÂÆåÊàê‰∫Ü‰∏ÄÈ†ÖË™øÊü•ÔºåË©≤Ë™øÊü•ÊçïÊçâ‰∫Ü‰ªñÂÄëÂ∞ç AI ÁöÑÊï¥È´îÊïàÁî®„ÄÅÂÄã‰∫∫ÊïàÁî®„ÄÅÊ≠£Áæ©„ÄÅ‰ø°ÂøÉ„ÄÅÈ¢®Èö™ÂíåÂ¶ÇÊûúÂèØÁî®Ôºå‰ΩøÁî®ÊØèÂÄãÊÉÖÂ¢ÉÁöÑ AI ÁöÑÊÑèÂúñÁöÑÁúãÊ≥ï„ÄÇË≥áÊñôËíêÈõÜÂåÖÂê´‰æÜËá™Âêà‰ΩúÊ©üÊßãÂíåÁ§æÁæ§Â™íÈ´îÊ¥ªÂãïÁöÑ 1198 ‰ΩçÂ§öÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÂèÉËàáËÄÖÁöÑÊúÄÁµÇÊ®£Êú¨Ôºå‰∏¶Â∞àÊ≥®ÊñºÂ∞çÂõõÂÄã AI ‰ΩøÁî®Ê°à‰æãÁöÑÂÄãÂà•ÂõûÊáâ„ÄÇÂ∞çË≥áÊñôÁöÑË™øËß£ÂàÜÊûêË°®ÊòéÔºåÂ∞ç AI ÁöÑÊé•ÂèóÂ∫¶Âíå‰ø°‰ªªÂú®Âà©ÂÆ≥Èóú‰øÇ‰∫∫ÂúòÈ´î‰πãÈñìÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇÊàëÂÄëÁôºÁèæÔºåAI ÁöÑ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÈ´ò‰ΩéÁ®ãÂ∫¶‰πãÈñìÁöÑÈóúÈçµË™øËß£ËÄÖÔºå‰ª•Âèä‰ΩøÁî®‰∏çÂêåÊïôËÇ≤ AI ÁöÑÊÑèÂúñÔºåÂåÖÊã¨ÊÑüÁü•Âà∞ÁöÑÊï¥È´îÊïàÁî®„ÄÅÊ≠£Áæ©Âíå‰ø°ÂøÉ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™øÔºåÊé•Âèó AI Âú®ÊïôËÇ≤‰∏äÁöÑÊáâÁî®ÊòØ‰∏ÄÂÄãÂæÆÂ¶ô‰∏îÂ§öÈù¢ÂêëÁöÑÂïèÈ°åÔºåÈô§‰∫Ü‰∏çÂêåÁöÑÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑÁúãÊ≥ïÂ§ñÔºåÈÇÑÈúÄË¶Å‰ªîÁ¥∞ËÄÉÊÖÆÂÖ∑È´îÁöÑ AI ÊáâÁî®ÂèäÂÖ∂ÁâπÂæµ„ÄÇ

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÂèØÁ©øÊà¥ÂºèÂñÆÂ∞éÁ®ãÂøÉÈõªÂúñ (ECG) Ë£ùÁΩÆÁöÑÈÅ†Á´ØÁóÖÊÇ£Áõ£Ê∏¨Âú®Êó©ÊúüÂÅµÊ∏¨ÂøÉËáüÁñæÁóÖÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØËàáÁî®ÊñºËá™ÂãïÂåñÂøÉËáüÁñæÁóÖÂÅµÊ∏¨ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÁµêÂêà‰ΩøÁî®ÊôÇ„ÄÇÂÖàÂâçÂ∑≤ÊúâÁ†îÁ©∂ÊáâÁî®Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑ AI ÊñπÊ≥ïÈÄ≤Ë°åÂøÉËáüÁñæÁóÖÂÅµÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂ∞öÊú™Ë¢´Âª£Ê≥õÊé•ÂèóÁÇ∫Ëá®Â∫äË®∫Êñ∑ÁöÑÂèØÈù†ËºîÂä©Â∑•ÂÖ∑ÔºåÈÉ®ÂàÜÂéüÂõ†Âú®ÊñºÂúçÁπûË®±Â§ö AI ÊºîÁÆóÊ≥ïÁöÑÁï∂ÂâçÈªëÁÆ±ÊÑüÁü•„ÄÇÁâπÂà•ÊòØÔºåÊúâÂøÖË¶ÅÊâæÂá∫ÊúâÂä©ÊñºÂÅöÂá∫Ê∫ñÁ¢∫Ë®∫Êñ∑ÁöÑ ECG Ë®äËôüÈóúÈçµÁâπÂæµÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆË¶ñË¶∫ËΩâÊèõÂô®ÊñπÊ≥ïÔºå‰ª•Ê†πÊìöÂñÆÂ∞éÁ®ã ECG Ë≥áÊñôÊâæÂá∫ÂøÉÊàøÈ°´Âãï„ÄÇÊÆòÂ∑ÆÁ∂≤Ë∑Ø (ResNet) ÊñπÊ≥ï‰πüÂ∑≤ÈñãÁôºÂá∫‰æÜÔºå‰ª•‰æøËàáË¶ñË¶∫ËΩâÊèõÂô®ÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉ„ÄÇÈÄô‰∫õÊ®°ÂûãÊáâÁî®Êñº Chapman-Shaoxing Ë≥áÊñôÈõÜÔºå‰ª•ÂàÜÈ°ûÂøÉÊàøÈ°´ÂãïÔºå‰ª•ÂèäÂè¶‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÂøÉÂæã‰∏çÊï¥ÔºåÁ´áÊÄßÂøÉÂãïÈÅéÁ∑©ÔºåÂíåÊ≠£Â∏∏Á´áÊÄßÂøÉÂæãÁöÑÂøÉË∑≥„ÄÇÈÄô‰∫õÊ®°ÂûãËÉΩÂ§†ÊâæÂá∫Ê±∫ÂÆöÊúÄÁµÇÂàÜÈ°ûÁöÑÂøÉË∑≥ÈóúÈçµÂçÄÂüüÔºå‰∏¶Âº∑Ë™ø P Ê≥¢Âíå T Ê≥¢Ôºå‰ª•ÂèäÂøÉË∑≥ÊåÅÁ∫åÊôÇÈñìÂíåË®äËôüÊåØÂπÖÂú®ÂçÄÂàÜÊ≠£Â∏∏Á´áÊÄßÂøÉÂæãËàáÂøÉÊàøÈ°´ÂãïÂíåÁ´áÊÄßÂøÉÂãïÈÅéÁ∑©ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®ÂÖàÈÄ≤Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÂíåÊ≤ªÁôÇÁöÑÊñ∞Ê®°ÂºèÔºöÁîüÊàêÂºèÈ†êË®ìÁ∑¥Transformer 4 (GPT-4)„ÄÅLlama 2 ËÅäÂ§©Ê©üÂô®‰∫∫Âíå Gemini„ÄÇÈÄô‰∫õ LLM Á∂ìÈÅéÂæÆË™øÔºåÂÖ∑ÂÇôÂ∞àÊ•≠ÊèêÁ§∫ÔºåÂèØË®∫Êñ∑„ÄÅËß£Èáã‰∏¶Âª∫Ë≠∞ÊÜÇÈ¨±ÁóáÁöÑÊ≤ªÁôÇ‰ªãÂÖ•ÊñπÊ≥ï„ÄÇ‰∏ÄÁ®ÆÁç®ÁâπÁöÑÂ∞ëÊ¨°ÊèêÁ§∫ÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÊ†πÊìö DSM-5 Ê®ôÊ∫ñÂàÜÊûêÂíåËß£ÈáãÊÜÇÈ¨±ÁóáÁãÄÁöÑËÉΩÂäõ„ÄÇÂú®‰∫íÂãïÈöéÊÆµÔºåÈÄô‰∫õÊ®°ÂûãÊúÉÂèÉËàáÂêåÁêÜÂøÉÂ∞çË©±ÁÆ°ÁêÜÔºåÂæû PsychDB ÂíåË™çÁü•Ë°åÁÇ∫ÁôÇÊ≥ï (CBT) ÊåáÂçóÁ≠âË≥áÊ∫ê‰∏≠Ê±≤ÂèñÔºå‰øÉÈÄ≤ËàáÁ∂ìÊ≠∑ÈáçÂ∫¶ÊÜÇÈ¨±ÁóáÁöÑ‰∫∫ÂÄëÁöÑÊîØÊåÅÊÄß‰∫íÂãï„ÄÇÊ≠§Â§ñÔºåÈÄôÈ†ÖÁ†îÁ©∂ÈÇÑ‰ªãÁ¥π‰∫Ü Illuminate Ë≥áÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂêÑÁ®Æ CBT Ê®°ÁµÑÔºåÊúâÂä©ÊñºÂÄãÊÄßÂåñÊ≤ªÁôÇÂª∫Ë≠∞„ÄÇÈÄôÈ†ÖÁ†îÁ©∂‰ΩøÁî® F1 ÂàÜÊï∏„ÄÅÊ∫ñÁ¢∫Áéá„ÄÅÂè¨ÂõûÁéá„ÄÅÈ§òÂº¶Áõ∏‰ººÂ∫¶ÂíåÈù¢ÂêëÂè¨ÂõûÁéáÁöÑ Gisting Ë©ï‰º∞ÊõøË∫´ (ROUGE) Á≠âÊåáÊ®ôÔºåÂú®‰∏çÂêåÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠Ë©ï‰º∞ LLM ÁöÑË°®ÁèæÔºåË≠âÊòé‰∫ÜÂÆÉÂÄëÁöÑÊúâÊïàÊÄß„ÄÇÈÄôÁ®ÆÁ∂úÂêàÊñπÊ≥ïÁµêÂêà‰∫ÜÂ∞ñÁ´ØÁöÑ AI ËàáÊó¢ÂÆöÁöÑÂøÉÁêÜÊñπÊ≥ïÔºåÁÇ∫ÂøÉÁêÜ‰øùÂÅ•Êèê‰æõ‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄßÔºå‰∏¶Â±ïÁ§∫‰∫Ü LLM Âú®Èù©Êñ∞ÊÜÇÈ¨±ÁóáË®∫Êñ∑ÂíåÊ≤ªÁôÇÁ≠ñÁï•ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v5 by Timoth√©e Schmude, Laura Koesten, Torsten M√∂ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

ÊëòË¶ÅÔºö<paragraph>ÊØèÂÄãÂ∞ç‰∫∫ÈÄ≤Ë°åÊ±∫Á≠ñÁöÑ AI Á≥ªÁµ±ÈÉΩÊúâ‰∏ÄÁæ§ÂÄã‰∫∫ÂèóÂà∞ÈÄô‰∫õÊ±∫Á≠ñÂΩ±ÈüøÁöÑÂà©ÁõäÈóú‰øÇ‰∫∫„ÄÇÁÑ∂ËÄåÔºåAI Á≥ªÁµ±ÁöÑË™™ÊòéÂæàÂ∞ëÈáùÂ∞çÈÄôÁæ§Âà©ÁõäÈóú‰øÇ‰∫∫ÁöÑË≥áË®äÈúÄÊ±ÇÔºå‰ªñÂÄëÈÄöÂ∏∏ÊòØ AI Êñ∞Êâã„ÄÇÈÄôÂú®ÂÇ≥ÈÅîÁöÑË≥áË®äÂíåÂ∞çÂèóÁ≥ªÁµ±Ê±∫Á≠ñÂΩ±ÈüøÁöÑ‰∫∫‰æÜË™™ÈáçË¶ÅÁöÑË≥áË®ä‰πãÈñìÔºåÈÄ†Êàê‰∫Ü‰∏ÄÈÅìÈ¥ªÊ∫ùÔºå‰æãÂ¶ÇÈ†òÂüüÂ∞àÂÆ∂ÂíåÊ±∫Á≠ñ‰∏ªÈ´î„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü„ÄåXAI Êñ∞ÊâãÂïèÈ°åÂ∫´„ÄçÔºåÈÄôÊòØ XAI ÂïèÈ°åÂ∫´ÁöÑÂª∂‰º∏ÔºåÂåÖÂê´‰æÜËá™ÂÖ©ÂÄã‰ΩøÁî®Ê°à‰æã‰∏≠ AI Êñ∞ÊâãÁöÑË≥áË®äÈúÄÊ±ÇÁõÆÈåÑÔºöÂ∞±Ê•≠È†êÊ∏¨ÂíåÂÅ•Â∫∑Áõ£Êéß„ÄÇÁõÆÈåÑÊ∂µËìã‰∫ÜË≥áÊñô„ÄÅÁ≥ªÁµ±ËÉåÊôØ„ÄÅÁ≥ªÁµ±‰ΩøÁî®ÂíåÁ≥ªÁµ±Ë¶èÊ†ºÁ≠âÈ°ûÂà•„ÄÇÊàëÂÄëÈÄèÈÅé‰ªªÂãôÂûãË®™Ë´áÊî∂ÈõÜË≥áË®äÈúÄÊ±ÇÔºåÂèÉËàáËÄÖÂú®ÂÖ∂‰∏≠Ë©¢Âïè‰∫ÜÂÖ©ÂÄã AI Á≥ªÁµ±ÁöÑÂïèÈ°åÔºå‰ª•Ê±∫ÂÆöÊé°Áî®ËàáÂê¶Ôºå‰∏¶Êî∂Âà∞Âè£È†≠Ë™™Êòé‰ΩúÁÇ∫ÂõûÊáâ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂèÉËàáËÄÖÂú®Êî∂Âà∞Ë™™ÊòéÂæåÔºå‰ø°ÂøÉÊúâÊâÄÊèêÂçáÔºå‰ΩÜ‰ªñÂÄëÁöÑÁêÜËß£Èù¢Ëá®ÊåëÊà∞„ÄÇÈÄô‰∫õÊåëÊà∞ÂåÖÊã¨Èõ£‰ª•ÊâæÂà∞Ë≥áË®äÂíåË©ï‰º∞Ëá™Â∑±ÁöÑÁêÜËß£Ôºå‰ª•ÂèäË©¶ÂúñÂ§ñÂåÖÁêÜËß£„ÄÇÊ≠§Â§ñÔºåÂèÉËàáËÄÖÂ∞çÁ≥ªÁµ±È¢®Èö™ÂíåÂ•ΩËôïÁöÑÂÖàÂâçË™çÁü•ÂΩ±Èüø‰∫Ü‰ªñÂÄëÁöÑË≥áË®äÈúÄÊ±Ç„ÄÇË™çÁÇ∫È¢®Èö™È´òÁöÑ‰∫∫Â∞ãÊ±ÇÊúâÈóúÁ≥ªÁµ±ÈÉ®ÁΩ≤ËÉåÂæåÊÑèÂúñÁöÑË™™ÊòéÔºåËÄåË™çÁÇ∫È¢®Èö™‰ΩéÁöÑ‰∫∫ÂâáË©¢ÂïèÁ≥ªÁµ±ÁöÑÈÅã‰Ωú„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êó®Âú®ÈÄèÈÅéÂº∑Ë™ø‰ªñÂÄëÁöÑË≥áË®äÈúÄÊ±Ç„ÄÅÁõÆÊ®ôÂíåÊåëÊà∞Ôºå‰æÜÊîØÊåÅÂ∞á AI Êñ∞ÊâãÁ¥çÂÖ•ÂèØËß£ÈáãÊÄßÂ∑•‰Ωú„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ∏ΩÁµêÁÇ∫‰∫îÂÄãÈóúÈçµÂΩ±ÈüøÔºåÈÄô‰∫õÂΩ±ÈüøÂèØ‰ª•ÁÇ∫Êú™‰æÜÈáùÂ∞çÈùûÂ∞àÊ•≠Âà©ÁõäÁõ∏ÈóúËÄÖÂèóÁúæÁöÑË™™ÊòéË®≠Ë®àÊèê‰æõÂèÉËÄÉ„ÄÇ</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet G√ºrkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂø´ÈÄüÊºîÈÄ≤ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁîüÊàêÂºè AI ÁöÑÈ†òÂüüÔºåÁÇ∫ÂêÑÂÄãÈ†òÂüüÁöÑÊáâÁî®ÈñãÂïü‰∫ÜÊñ∞ÈÄîÂæëÔºå‰ΩÜÂÖ∂Âú®ÂïÜÊ•≠ÊïôËÇ≤‰∏≠ÁöÑËßíËâ≤‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊú¨Á†îÁ©∂È¶ñÊ¨°ÂºïÂÖ•‰∫ÜÂü∫Ê∫ñÔºåÁî®‰ª•Ë©ï‰º∞‰∏ÉÂÄã‰∏ªË¶Å LLM ÁöÑÊïàËÉΩÔºåÂåÖÊã¨ OpenAI ÁöÑÊ®°Âûã (GPT-3.5 Turbo„ÄÅGPT-4 Âíå GPT-4 Turbo)„ÄÅGoogle ÁöÑÊ®°Âûã (PaLM 2„ÄÅGemini 1.0 Pro) Âíå Anthropic ÁöÑÊ®°Âûã (Claude 2 Âíå Claude 2.1)ÔºåÈÄô‰∫õÊ®°ÂûãÂ∞áÁî®ÊñºÁ†îÁ©∂ÁîüÂïÜÊ•≠Ë™≤Á®ãÂÖ•Â≠∏Á®ãÂ∫è‰∏≠ÁöÑÈóúÈçµËÄÉË©¶ GMAT„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂ§ßÂ§öÊï∏ LLM ÁöÑË°®ÁèæÈÉΩÂÑ™Êñº‰∫∫È°ûËÄÉÁîüÔºåÂÖ∂‰∏≠ GPT-4 Turbo ‰∏çÂÉÖÂÑ™ÊñºÂÖ∂‰ªñÊ®°ÂûãÔºåÊõ¥Ë∂ÖË∂ä‰∫ÜÈ†ÇÂ∞ñÂïÜÂ≠∏Èô¢ÁöÑÁ†îÁ©∂ÁîüÂπ≥ÂùáÂàÜÊï∏„ÄÇÈÄèÈÅéÊ°à‰æãÁ†îÁ©∂ÔºåÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü GPT-4 Turbo Âú®Ëß£ÈáãÁ≠îÊ°à„ÄÅË©ï‰º∞ÂõûÊáâ„ÄÅËæ®Ë≠òÈåØË™§„ÄÅË™øÊï¥Ë™™ÊòéÂíåÁî¢ÁîüÊõø‰ª£ÊÉÖÂ¢ÉÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇËàáÂâç‰∏Ä‰ª£ÁâàÊú¨Áõ∏ÊØîÔºåÊúÄÊñ∞ÁöÑ LLM ÁâàÊú¨ GPT-4 Turbo„ÄÅClaude 2.1 Âíå Gemini 1.0 Pro Âú®Êé®ÁêÜ‰ªªÂãôÊñπÈù¢ÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÂá∏È°Ø‰∫ÜÂÖ∂Âú®Ëß£Ê±∫Ë§áÈõúÂïèÈ°åÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÂÑòÁÆ° AI Âú®ÊïôËÇ≤„ÄÅË©ïÈáèÂíåËºîÂ∞éÊñπÈù¢ÁöÑÊâøË´æÂæàÊòéÁ¢∫Ôºå‰ΩÜ‰ªçÊúâÊåëÊà∞Â≠òÂú®„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÈó°Êòé‰∫Ü LLM ÁöÑÂ≠∏Ë°ìÊΩõÂäõÔºå‰πüÂº∑Ë™ø‰∫ÜÂú®ÊïôËÇ≤‰∏≠ÂØ©ÊÖéÈñãÁôºÂíåÊáâÁî® AI ÁöÑÂøÖË¶ÅÊÄß„ÄÇÈö®Ëëó AI ÊäÄË°ìÁöÑÈÄ≤Ê≠•ÔºåÂª∫Á´ã AI ‰∫íÂãïÁöÑÊû∂ÊßãÂíåÂçîÂÆö„ÄÅÈ©óË≠â AI ÁîüÊàêÁöÑÂÖßÂÆπÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅÁ¢∫‰øùÂÖ®ÁêÉÂêÑÂú∞Â§öÂÖÉÂ≠∏ÁøíËÄÖÁöÑÂ≠òÂèñÊ¨äÔºå‰ª•ÂèäÂâµÈÄ†‰∏ÄÂÄã AI ÊîØÊåÅ‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠òÁöÑÊïôËÇ≤Áí∞Â¢ÉËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂ÁÇ∫ÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢Ë≤†Ë≤¨‰ªªÂú∞‰ΩøÁî® AI ‰æÜË±êÂØåÊïôËÇ≤È´îÈ©ó‰∏¶ÊîπÂñÑËÄÉË©¶Ê∫ñÂÇôÂíåË©ïÈáèÊñπÊ≥ïÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

ÊëòË¶ÅÔºöÈ†êÊ∏¨Âä†Ë≠∑ÁóÖÊàø (ICU) ÁóÖÊÇ£ÁöÑÈô¢ÂÖßÊ≠ª‰∫°ÁéáÊòØÊúÄÁµÇËá®Â∫äÁµêÊûúÁöÑÈóúÈçµ„ÄÇAI Â∑≤Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÂçªÁº∫‰πèÂèØËß£ÈáãÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÂ§öÊ®°ÂºèÊ≠ª‰∫°ÁéáÈ†êÊ∏¨Âô® (X-MMP)ÔºåÊé°Áî®ÊúâÊïà‰∏îÂèØËß£ÈáãÁöÑ AI ÊñπÂºèÔºåËóâÁî±Â§öÊ®°Âºè ICU Ë≥áÊñô‰æÜÈ†êÊ∏¨Èô¢ÂÖßÊ≠ª‰∫°Áéá„ÄÇÊàëÂÄëÂú®Êû∂Êßã‰∏≠Êé°Áî®Â§öÊ®°ÂºèÂ≠∏ÁøíÔºåÂèØ‰ª•Êé•Êî∂‰æÜËá™Ëá®Â∫äË≥áÊñôÁöÑÁï∞Ë≥™Ëº∏ÂÖ•‰∏¶ÂÅöÂá∫Ê±∫Á≠ñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊñπÊ≥ïÔºå‰πüÂ∞±ÊòØÂàÜÂ±§ÂÇ≥Êí≠Ëá≥ TransformerÔºå‰ΩúÁÇ∫ LRP ÊñπÊ≥ïÈÅ©Áï∂Âú∞Âª∂‰º∏Ëá≥ TransformerÔºåÂ∞çÂ§öÊ®°ÂºèËº∏ÂÖ•Áî¢ÁîüËß£ÈáãÔºå‰∏¶Êè≠Èú≤Ê≠∏Âõ†ÊñºÈ†êÊ∏¨ÁöÑÈ°ØËëóÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊØèÂÄãÊ®°ÂºèÂ∞çËá®Â∫äÁµêÊûúÁöÑË≤¢ÁçªÂèØ‰ª•Ë¶ñË¶∫ÂåñÔºåÂçîÂä©Ëá®Â∫äÈÜ´Â∏´‰∫ÜËß£Ê±∫Á≠ñËÉåÂæåÁöÑÁêÜÁî±„ÄÇÊàëÂÄëÊ†πÊìö MIMIC-III Âíå MIMIC-III Ê≥¢ÂΩ¢Ë≥áÊñôÂ∫´ÊØîÂ∞çÂ≠êÈõÜÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÂºèË≥áÊñôÈõÜ„ÄÇÂú®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂÖ®Èù¢ÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊû∂ÊßãÂèØ‰ª•ÈÅîÊàêÂêàÁêÜÁöÑË©ÆÈáãÔºå‰∏¶ÂÖ∑ÂÇôÁ´∂Áà≠ÂäõÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂèØ‰ª•ËºïÈ¨ÜÂú∞ËΩâÁßªÂà∞ÂÖ∂‰ªñËá®Â∫ä‰ªªÂãôÔºåÈÄôÊúâÂä©ÊñºÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂‰∏≠ÁôºÁèæÈóúÈçµÂõ†Á¥†„ÄÇ

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Gei√üler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Bj√∂rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias K√ºster, Andr√© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

ÊëòË¶ÅÔºöÂú®ÈÅéÂéªÁöÑÂçÅÂπ¥‰∏≠ÔºåÁóÖÁêÜÂ≠∏‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÂ∑≤Â§ßÂπÖÈÄ≤Ê≠•„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË®±Â§öÊåëÊà∞ÔºåÂåÖÊã¨Â∞áÁ†îÁ©∂ÁµêÊûúËΩâÂåñÁÇ∫Ëá®Â∫äË®∫Êñ∑Áî¢ÂìÅÂú®ÊäÄË°ìÂíåÊ≥ïË¶èÊñπÈù¢ÁöÑÈöúÁ§ôÔºå‰ª•ÂèäÁº∫‰πèÊ®ôÊ∫ñÂåñ‰ªãÈù¢ÔºåÂ∞éËá¥Êï¥ÂêàÂà∞Â∏∏Ë¶èËá®Â∫äÂØ¶Âãô‰∏≠ÈÄ≤Â±ïÁ∑©ÊÖ¢„ÄÇÈñãÊîæ‰∏îËàá‰æõÊáâÂïÜÁÑ°ÈóúÁöÑ EMPAIA Ë®àÁï´ÊáâÂ∞ç‰∫ÜÈÄô‰∫õÊåëÊà∞„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèê‰æõ EMPAIA ÁöÑÊàêÂ∞±ÂíåÁ∂ìÈ©óÊïôË®ìÁöÑÊ¶ÇËø∞„ÄÇEMPAIA Êï¥Âêà‰∫ÜÁóÖÁêÜÂ≠∏ AI ÁîüÊÖãÁ≥ªÁµ±ÁöÑÂêÑÂÄãÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÔºåÂç≥ÁóÖÁêÜÂ≠∏ÂÆ∂„ÄÅÈõªËÖ¶ÁßëÂ≠∏ÂÆ∂ÂíåÁî¢Ê•≠„ÄÇÂú®ÂØÜÂàáÂêà‰Ωú‰∏ãÔºåÊàëÂÄëÂà∂ÂÆö‰∫ÜÊäÄË°ì‰∫íÈÄöÊÄßÊ®ôÊ∫ñ„ÄÅAI Ê∏¨Ë©¶ÂíåÁî¢ÂìÅÈñãÁôºÂª∫Ë≠∞Ôºå‰ª•ÂèäÂèØËß£ÈáãÊÄßÊñπÊ≥ï„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∫ÜÊ®°ÁµÑÂåñ‰∏îÈñãÊîæÂéüÂßãÁ¢ºÁöÑ EMPAIA Âπ≥Ëá∫Ôºå‰∏¶ÊàêÂäüÊï¥Âêà‰∫Ü‰æÜËá™ 8 ÂÄã‰∏çÂêå‰æõÊáâÂïÜÁöÑ 14 ÂÄãÂü∫Êñº AI ÁöÑÂΩ±ÂÉèÂàÜÊûêÊáâÁî®Á®ãÂºèÔºåÂ±ïÁ§∫‰∫Ü‰∏çÂêåÁöÑÊáâÁî®Á®ãÂºèÂ¶Ç‰Ωï‰ΩøÁî®ÂñÆ‰∏ÄÁöÑÊ®ôÊ∫ñÂåñ‰ªãÈù¢„ÄÇÊàëÂÄëÂÑ™ÂÖàËÄÉÊÖÆÈúÄÊ±ÇÔºå‰∏¶Ë©ï‰º∞‰∫Ü AI Âú®Ê≠êÊ¥≤Âíå‰∫ûÊ¥≤ÁöÑ 14 ÂÄã‰∏çÂêåÁóÖÁêÜÂØ¶È©óÂÆ§‰∏≠ÁöÑÂØ¶ÈöõËá®Â∫äÊáâÁî®„ÄÇÈô§‰∫ÜÊäÄË°ìÈñãÁôºÂ§ñÔºåÊàëÂÄëÈÇÑÁÇ∫ÊâÄÊúâÂà©ÂÆ≥Èóú‰øÇ‰∫∫Âª∫Á´ã‰∫Ü‰∏ÄÂÄãË´ñÂ£áÔºå‰ª•ÂàÜ‰∫´Êï∏‰ΩçÁóÖÁêÜÂ≠∏Âíå AI ÁöÑË≥áË®äÂíåÁ∂ìÈ©ó„ÄÇÂïÜÊ•≠„ÄÅËá®Â∫äÂíåÂ≠∏Ë°ìÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁèæÂú®ÂèØ‰ª•Êé°Áî® EMPAIA ÁöÑÂ∏∏Ë¶ãÈñãÊîæÂéüÂßãÁ¢º‰ªãÈù¢ÔºåÈÄôÁÇ∫Â§ßË¶èÊ®°Ê®ôÊ∫ñÂåñÂíåÁ∞°ÂåñÊµÅÁ®ãÊèê‰æõ‰∫ÜÁç®ÁâπÁöÑÊ©üÊúÉ„ÄÇÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÂä™ÂäõÊâçËÉΩÊúâÊïà‰∏îÂª£Ê≥õÂú∞Âª∫Á´ã‰æãË°åÂØ¶È©óÂÆ§‰ΩøÁî®‰∏≠ÁöÑ AI ËºîÂä©„ÄÇÁÇ∫Ê≠§ÔºåÂ∑≤ÊàêÁ´ãÈùûÁáüÂà©ÂçîÊúÉ EMPAIA InternationalÔºå‰ª•‰ΩúÁÇ∫Ê∞∏Á∫åÂü∫Á§éÊû∂ÊßãÔºåÁπºÁ∫åÈÄ≤Ë°åÊ®ôÊ∫ñÂåñÔºå‰∏¶ÊîØÊè¥Âª£Ê≥õÂØ¶‰ΩúÂíåÂÄ°Â∞é AI ËºîÂä©Êï∏‰ΩçÁóÖÁêÜÂ≠∏ÁöÑÊú™‰æÜ„ÄÇ

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

ÊëòË¶ÅÔºöÂèç‰∫ãÂØ¶Ëß£Èáã (CE) ÊäÄË°ìÂ∑≤ÂºïËµ∑ÈóúÊ≥®Ôºå‰ΩúÁÇ∫‰∏ÄÁ®ÆÁÇ∫Ëàá AI Á≥ªÁµ±‰∫íÂãïÁöÑ‰ΩøÁî®ËÄÖÊèê‰æõË¶ãËß£ÁöÑÊñπÊ≥ï„ÄÇÈõñÁÑ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂíåËá™ÂãïÈßïÈßõÊ±ΩËªäÁ≠âÈ†òÂüüÂª£Ê≥õÁ†îÁ©∂ÔºåÂúñÂΩ¢Âèç‰∫ãÂØ¶Ëß£Èáã (GCE) ÊñπÊ≥ïÁõ∏Â∞çËºÉÂ∞ëË¢´Êé¢Á¥¢„ÄÇGCE ÊúÉÁî¢Áîü‰∏ÄÂÄãÈ°û‰ººÊñºÂéüÂßãÂúñÂΩ¢ÁöÑÊñ∞ÂúñÂΩ¢Ôºå‰∏¶Ê†πÊìöÂü∫Á§éÈ†êÊ∏¨Ê®°ÂûãÁî¢Áîü‰∏çÂêåÁöÑÁµêÊûú„ÄÇÂú®ÈÄô‰∫õ GCE ÊäÄË°ì‰∏≠ÔºåÂÑòÁÆ°Âú®ÂÖ∂‰ªñÈ†òÂüüÔºà‰æãÂ¶ÇËóùË°ìÈ¢®Ê†ºÂíåËá™ÁÑ∂Ë™ûË®ÄÂª∫Ê®°Ôºâ‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÂ∞±Ôºå‰ΩÜÊ§çÂü∫ÊñºÁîüÊàêÊ©üÂà∂ÁöÑÊäÄË°ìÁç≤ÂæóÁöÑÈóúÊ≥®Áõ∏Â∞çÊúâÈôê„ÄÇÂ∞çÁîüÊàêÂºèËß£ÈáãÂô®ÁöÑÂÅèÂ•ΩÊ∫êÊñºÂÆÉÂÄëÂú®Êé®ÁêÜÊúüÈñìÁî¢ÁîüÂèç‰∫ãÂØ¶ÂØ¶‰æãÁöÑËÉΩÂäõÔºåÂà©Áî®Ëº∏ÂÖ•ÂúñÂΩ¢ÁöÑËá™‰∏ªÁç≤ÂèñÊìæÂãï„ÄÇÂü∫Êñº‰∏äËø∞ÁêÜÁî±ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü RSGG-CEÔºå‰∏ÄÁ®ÆÁî®ÊñºÂèç‰∫ãÂØ¶Ëß£ÈáãÁöÑÊñ∞ÂûãÁ©©ÂÅ•Èö®Ê©üÂúñÂΩ¢ÁîüÊàêÂô®ÔºåËÉΩÂ§†ÂæûÂ≠∏ÁøíÂà∞ÁöÑÊΩõÂú®Á©∫Èñì‰∏≠Áî¢ÁîüÂèç‰∫ãÂØ¶ÁØÑ‰æãÔºåËÄÉÊÖÆÈÉ®ÂàÜÊúâÂ∫èÁöÑÁîüÊàêÂ∫èÂàó„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°åÂÆöÈáèÂíåÂÆöÊÄßÂàÜÊûêÔºå‰ª•ÊØîËºÉ RSGG-CE ÁöÑÊïàËÉΩËàá SoA ÁîüÊàêÂºèËß£ÈáãÂô®ÔºåÂº∑Ë™øÂÖ∂Â¢ûÂº∑‰∫ÜÁî¢ÁîüÂêàÁêÜËß£ÈáãÂÄôÈÅ∏ÁöÑËÉΩÂäõ„ÄÇ

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

ÊëòË¶ÅÔºöÂèØËß£Èáã AI ÁöÑÂãïÊ©ü‰πã‰∏ÄÊòØËÆì‰∫∫ÂÄëÂú®‰ΩøÁî®ÂíåÈÉ®ÁΩ≤ AI Ê®°ÂûãÊôÇÂÅöÂá∫Êõ¥Â•Ω„ÄÅÊõ¥ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇ‰ΩÜÈúÄË¶Å‰ªîÁ¥∞Ë©ï‰º∞‰ª•Ë©ï‰º∞ÊòØÂê¶Â∑≤ÈÅîÂà∞Ê≠§È†êÊúü„ÄÇÁõÆÂâçÁöÑË©ï‰º∞‰∏ªË¶ÅÈõÜ‰∏≠Âú®Ëß£ÈáãÁöÑÊºîÁÆóÊ≥ïÁâπÊÄßÔºåËÄåÊ∂âÂèä‰∫∫È°ûÂèóË©¶ËÄÖÁöÑË©ï‰º∞ÈÄöÂ∏∏Êé°Áî®‰∏ªËßÄÂïèÈ°å‰æÜÊ∏¨Ë©¶‰∫∫È°ûÂ∞çËß£ÈáãÊúâÁî®ÊÄßÁöÑÁúãÊ≥ïÔºåËÄåÊ≤íÊúâÂü∫ÊñºÂÆ¢ËßÄÊåáÊ®ôÂíåÊ∏¨Èáè„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË©ï‰º∞Ëß£ÈáãÊòØÂê¶ÂèØ‰ª•Âú®Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÈñãÁôºÁöÑÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÊîπÂñÑ‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÊ∂âÂèäÂΩ±ÂÉèË≥áÊñôÁöÑÊ∑∑ÂêàÊñπÊ≥ï‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞ SmoothGrad„ÄÅGradCAM ÂíåÈ†êË®ÄËß£ÈáãÂú®ÂÖ©ÂÄã‰ªªÂãô‰∏≠Áî¢ÁîüÁöÑÈ°ØËëóÊÄßÂúñÔºöÊ®°ÂûãÈÅ∏ÊìáÂíåÂèç‰∫ãÂØ¶Ê®°Êì¨„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÊ≤íÊúâÁôºÁèæ‰ªª‰ΩïÈ°ØËëóÊÄßÂúñÔºàÂç≥‰ΩøÊòØË®≠Ë®àÁÇ∫ÊòìÊñºÁêÜËß£‰∏îÈ´òÂ∫¶ÊåáÁ§∫Á≠îÊ°àÁöÑÂêàÊàêÈ†êË®ÄËß£ÈáãÔºâËÉΩËÆì‰ΩøÁî®ËÄÖÂú®ÈÄô‰∫õ‰ªªÂãô‰∏äÈ°ØËëóÊîπÂñÑÁöÑË≠âÊìö„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåËß£ÈáãÁ¢∫ÂØ¶ÊúâÂä©Êñº‰ΩøÁî®ËÄÖÊõ¥Ê∫ñÁ¢∫Âú∞ÊèèËø∞Ê®°Âûã„ÄÇÈÄô‰∫õÁôºÁèæÊèêÁ§∫ÊàëÂÄëË¶ÅÂ∞çÂü∫ÊñºÈ°ØËëóÊÄßÁöÑËß£Èáã‰∏≠ÂèØËÉΩÂ≠òÂú®Ë™§Ëß£ÁöÑÊúâÁî®ÊÄß‰øùÊåÅË¨πÊÖé„ÄÇ

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

ÊëòË¶ÅÔºöÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÂª∫Á´ã‰ø°‰ªª„ÄÇÈÄô‰∫õÈúÄË¶Å‰∏ÄÂÄãÊ®°Âûã‰æÜÂ±ïÁ§∫‰∏ÄËá¥ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÈÄô‰∫õÔºåÊúâÂøÖË¶Å‰ΩøÁî®ÂíåÂàÜÊûêÊï∏ÊìöÂíåÁü•Ë≠òÔºå‰∏¶‰ΩøÁî®Ëàá AI ÊáâÁî®Áõ∏ÈóúÁöÑÁµ±Ë®àÂíåÁ¨¶Ëôü AI ÊñπÊ≥ï - ÂñÆÁç®‰ΩøÁî®‰ªª‰Ωï‰∏ÄÁ®ÆÊñπÊ≥ïÈÉΩ‰∏çÊúÉÂ•èÊïà„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄë‰∏ªÂºµ‰∏¶Ë©¶ÂúñË≠âÊòé NeuroSymbolic AI ÊñπÊ≥ïÊõ¥ÈÅ©ÂêàÊñº‰Ωø AI ÊàêÁÇ∫Âèó‰ø°‰ªªÁöÑ AI Á≥ªÁµ±„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü CREST Ê°ÜÊû∂ÔºåÂ±ïÁ§∫‰∫Ü‰∏ÄËá¥ÊÄß„ÄÅÂèØÈù†ÊÄß„ÄÅ‰ΩøÁî®ËÄÖÂ±§Á¥öÁöÑÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÊòØÂ¶Ç‰ΩïÂª∫Á´ãÂú® NeuroSymbolic ÊñπÊ≥ï‰∏äÁöÑÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Êï∏ÊìöÂíåÁü•Ë≠ò‰æÜÊîØÊåÅÈóúÈçµÊáâÁî®Ôºà‰æãÂ¶ÇÂÅ•Â∫∑ÂíåÁ¶èÁ•âÔºâÁöÑË¶ÅÊ±Ç„ÄÇÊú¨ÊñáÈáçÈªûÈóúÊ≥®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂõ†ÁÇ∫ÂÆÉÊòØ CREST Ê°ÜÊû∂‰∏≠ÈÅ∏ÊìáÁöÑ AI Á≥ªÁµ±„ÄÇLLM Âõ†ÂÖ∂Âú®ËôïÁêÜÂª£Ê≥õÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Â†¥ÊôØÊñπÈù¢ÁöÑÂ§öÂäüËÉΩÊÄßËÄåÂÇôÂèóÁ†îÁ©∂‰∫∫Âì°ÁöÑÈóúÊ≥®„ÄÇ‰æãÂ¶ÇÔºåChatGPT Âíå Google ÁöÑ MedPaLM Â∑≤ÊàêÁÇ∫Êèê‰æõ‰∏ÄËà¨ÂíåÂÅ•Â∫∑Áõ∏ÈóúÊü•Ë©¢‰ø°ÊÅØÁöÑÊ•µÊúâÂ∏åÊúõÁöÑÂπ≥Âè∞„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄô‰∫õÊ®°Âûã‰ªçÁÑ∂ÊòØÈªëÁõíÂ≠êÔºåÂÑòÁÆ°Á¥çÂÖ•‰∫Ü‰∫∫È°ûÂèçÈ•ãÂíåÊåá‰ª§ÂºïÂ∞éÁöÑË™øÊï¥„ÄÇ‰æãÂ¶ÇÔºåÂÑòÁÆ°Âà∂ÂÆö‰∫ÜÂÆâÂÖ®Èò≤Ë≠∑Êé™ÊñΩÔºåChatGPT ‰ªçÂèØËÉΩÁî¢Áîü‰∏çÂÆâÂÖ®ÁöÑÂõûÊáâ„ÄÇCREST ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêàÁêÜÁöÑÊñπÊ≥ïÔºåÂú® NeuroSymbolic Ê°ÜÊû∂‰∏≠Âà©Áî®Á®ãÂ∫èÂíåÂü∫ÊñºÂúñË°®ÁöÑÁü•Ë≠òÔºå‰ª•Èó°ÊòéËàá LLM Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇ

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Ë∞ÉÊü•‰∫ÜÂú® COVID-19 Áñ´ÊÉÖÊúüÈó¥Âèä‰ª•ÂêéÈ¢ÑÊµãÊ≠ª‰∫°ÁéáÊó∂ÔºåÂ∑≤ÈÉ®ÁΩ≤‰∫∫Â∑•Êô∫ËÉΩ (AI) Ê®°ÂûãÁöÑÊÄßËÉΩ„ÄÅÂèØËß£ÈáäÊÄßÂíåÁ®≥ÂÅ•ÊÄß„ÄÇ‰Ωú‰∏∫ÂêåÁ±ªÁ†îÁ©∂‰∏≠ÁöÑÈ¶ñ‰æãÔºåÊàë‰ª¨ÂèëÁé∞Ë¥ùÂè∂ÊñØÁ•ûÁªèÁΩëÁªú (BNN) ÂíåÊô∫ËÉΩËÆ≠ÁªÉÊäÄÊúØËÆ©Êàë‰ª¨ÁöÑÊ®°ÂûãÂú®Êï∞ÊçÆÂèëÁîüÈáçÂ§ßÂèòÂåñÊó∂‰ªçËÉΩ‰øùÊåÅÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúÂº∫Ë∞É‰∫ÜÂºÄÂèëÁ®≥ÂÅ•ÁöÑ AI Ê®°ÂûãÁöÑÈáçË¶ÅÊÄßÔºåÂç≥‰ΩøÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊù°‰ª∂‰∏ãÔºåËøô‰∫õÊ®°Âûã‰πüËÉΩÂåπÈÖçÊàñË∂ÖË∂ä‰∏¥Â∫äÂåªÁîüÁöÑÈ¢ÑÊµã„ÄÇÊàë‰ª¨ÂØπÊ®°ÂûãÂèØËß£ÈáäÊÄßÁöÑÊé¢Á¥¢Ë°®ÊòéÔºåÈöèÊú∫Ê®°Âûã‰ºö‰∫ßÁîüÊõ¥Â§öÊ†∑Âåñ‰∏î‰∏™ÊÄßÂåñÁöÑËß£ÈáäÔºå‰ªéËÄåÁ™ÅÂá∫‰∫ÜÂú®Áé∞ÂÆû‰∏ñÁïåÁöÑ‰∏¥Â∫äÁéØÂ¢É‰∏≠Êèê‰æõËØ¶ÁªÜ‰∏î‰∏™ÊÄßÂåñËßÅËß£ÁöÑ AI Ê®°ÂûãÁöÑÂøÖË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Âº∫Ë∞É‰∫ÜÈáèÂåñ AI Ê®°Âûã‰∏≠‰∏çÁ°ÆÂÆöÊÄßÁöÑÈáçË¶ÅÊÄßÔºåËøô‰Ωø‰∏¥Â∫äÂåªÁîüËÉΩÂ§üÊ†πÊçÆÂèØÈù†ÁöÑÈ¢ÑÊµãÂÅöÂá∫Êõ¥ÊòéÊô∫ÁöÑÂÜ≥Á≠ñ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÊèêÂÄ°Âú®ÂåªÁñó‰øùÂÅ•ÁöÑ AI Á†îÁ©∂‰∏≠‰ºòÂÖàËÄÉËôëÂÆûÊñΩÁßëÂ≠¶ÔºåÂπ∂Á°Æ‰øù AI Ëß£ÂÜ≥ÊñπÊ°àÂú®Áé∞ÂÆû‰∏ñÁïåÁöÑ‰∏¥Â∫äÁéØÂ¢É‰∏≠ÂÆûÁî®„ÄÅÊúâÁõä‰∏îÂèØÊåÅÁª≠„ÄÇÈÄöËøáËß£ÂÜ≥ÂåªÁñó‰øùÂÅ•ÁéØÂ¢É‰∏≠ÁöÑÁã¨ÁâπÊåëÊàòÂíåÂ§çÊùÇÊÄßÔºåÁ†îÁ©∂‰∫∫ÂëòÂèØ‰ª•ÂºÄÂèëÂá∫ÊúâÊïàÊîπÂñÑ‰∏¥Â∫äÂÆûË∑µÂíåÊÇ£ËÄÖÈ¢ÑÂêéÁöÑ AI Ê®°Âûã„ÄÇ

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

ÊëòË¶ÅÔºöËÇ∫ÁôåÂç†Ëã±ÂúãÁôåÁóáÊ≠ª‰∫°‰∫∫Êï∏ÁöÑ 21%Ôºå‰∫îÂπ¥Â≠òÊ¥ªÁéáÂæàÂ§ßÁ®ãÂ∫¶ÂèñÊ±∫ÊñºÁôåÁóáË¢´ÁôºÁèæÁöÑÈöéÊÆµ„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Ë≠âÊòé‰∫∫Â∑•Êô∫ËÉΩÊñπÊ≥ïÂÖ∑ÊúâÂæû‰æãË°åÊéÉÊèè‰∏≠Ê∫ñÁ¢∫ÂèäÊó©Ë®∫Êñ∑ËÇ∫ÁôåÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊ≠§Ë≠âÊìöÂ∞öÊú™ËΩâÂåñÁÇ∫Ëá®Â∫äÂØ¶ÂãôÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÈöúÁ§ôÊòØÁº∫‰πèÂèØËß£ÈáãÁöÑÊ®°Âûã„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÊáâÁî®ËÆäÂàÜËá™ÂãïÁ∑®Á¢ºÂô® (VAE)Ôºå‰∏ÄÁ®ÆÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÔºåÊñºËÇ∫ÁôåÁóÖÁÅ∂„ÄÇÂ∞áÊèêÂá∫ÁöÑÊ®°ÂûãË®ìÁ∑¥ÊñºÂæû LIDC-IDRI ÂÖ¨ÂÖ±Êï∏ÊìöÈõÜ‰∏≠ÊèêÂèñÁöÑ 3D ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÁóÖÁÅ∂„ÄÇÈÄöÈÅéËÅöÈ°ûÊé¢Á¥¢‰∫Ü VAE ÁîüÊàêÁöÑ 2D ÂàáÁâáÁöÑÊΩõÂú®ÂêëÈáèË°®Á§∫Ôºå‰ª•Ë≠âÊòéÂÖ∂ÂìÅË≥™Ôºå‰∏¶Áî®ÊñºËÇ∫ÁôåË®∫Êñ∑ÁöÑ MLP ÂàÜÈ°ûÂô®Ê®°ÂûãÔºåÊúÄ‰Ω≥Ê®°ÂûãÈÅîÂà∞‰∫Ü AUC 0.98 Âíå 93.1% Ê∫ñÁ¢∫Â∫¶ÁöÑÊúÄÂÖàÈÄ≤ÊåáÊ®ô„ÄÇËÅöÈ°ûÂàÜÊûêÈ°ØÁ§∫ÔºåVAE ÊΩõÂú®Á©∫ÈñìÊ†πÊìöÊúâÊÑèÁæ©ÁöÑÁâπÂæµÁµÑÊàêÔºàÂåÖÊã¨ËÖ´Áò§Â§ßÂ∞è„ÄÅÂΩ¢ÁãÄ„ÄÅÊÇ£ËÄÖÂíåÊÉ°ÊÄßÈ°ûÂà•ÔºâÂ∞áÊÉ°ÊÄßÂíåËâØÊÄßÁóÖÁÅ∂ÁöÑÊï∏ÊìöÈõÜÂàÜÈñã„ÄÇÊàëÂÄëÈÇÑÂåÖÊã¨Ê®ôÊ∫ñÈ´òÊñØ VAE (GVAE) ÂíåÊõ¥Êñ∞ÁöÑÁãÑÂà©ÂÖãÈõ∑ VAE (DirVAE) ÁöÑÊØîËºÉÂàÜÊûêÔºåÂæåËÄÖÁî®ÁãÑÂà©ÂÖãÈõ∑ÂàÜ‰ΩàÂèñ‰ª£ÂÖàÈ©óÔºå‰ª•‰øÉÈÄ≤ÂÖ∑ÊúâËß£ÈñãÁâπÂæµË°®Á§∫ÁöÑÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÁöÑÊΩõÂú®Á©∫Èñì„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáËá®Â∫äÊúâÊÑèÁæ©ÁöÑÁâπÂæµËÆäÂåñÁõ∏ÊáâÁöÑÊΩõÂú®Á©∫ÈñìÊ©´Ë∂äÁöÑÊΩõÂäõ„ÄÇ

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂúñÂÉèÂàÜÈ°ûÂô®Ëº∏Âá∫Ëß£ÈáãÂ∑•ÂÖ∑ÂèØÂàÜÁÇ∫‰æùË≥¥ÊñºÊ®°ÂûãÂÖßÈÉ®Â≠òÂèñÊ¨äÈôêÁöÑÁôΩÁõíÔºå‰ª•ÂèäËàáÊ®°ÂûãÁÑ°ÈóúÁöÑÈªëÁõí„ÄÇÈö®Ëëó AI Âú®ÈÜ´ÁôÇÈ†òÂüüÁöÑ‰ΩøÁî®Â¢ûÂä†ÔºåÂèØËß£ÈáãÊÄßÂ∑•ÂÖ∑ÁöÑ‰ΩøÁî®‰πüÈö®‰πãÂ¢ûÂä†„ÄÇÁèæÊúâÈÜ´Â≠∏ÂΩ±ÂÉèËß£ÈáãÁöÑÂ∑•‰ΩúÈáçÈªûÂú®ÊñºÁôΩÁõíÂ∑•ÂÖ∑Ôºå‰æãÂ¶Ç gradcam„ÄÇÁÑ∂ËÄåÔºåÂàáÊèõÂà∞ÈªëÁõíÂ∑•ÂÖ∑ÊúâÊòéÈ°ØÁöÑÂÑ™ÈªûÔºåÂåÖÊã¨ËÉΩÂ§†Ëàá‰ªª‰ΩïÂàÜÈ°ûÂô®‰∏ÄËµ∑‰ΩøÁî®Ôºå‰ª•ÂèäÂª£Ê≥õÁöÑÈªëÁõíÂ∑•ÂÖ∑ÂèØ‰æõÈÅ∏Êìá„ÄÇÂú®Ê®ôÊ∫ñÂΩ±ÂÉè‰∏äÔºåÈªëÁõíÂ∑•ÂÖ∑ËàáÁôΩÁõí‰∏ÄÊ®£Á≤æÁ¢∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊØîËºÉ‰∫ÜÂ§öÁ®ÆÈªëÁõíÊñπÊ≥ïÂú®ËÖ¶Áôå MRI Ë≥áÊñôÈõÜ‰∏äËàá gradcam ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëË≠âÊòéÂ§ßÂ§öÊï∏ÈªëÁõíÂ∑•ÂÖ∑‰∏çÈÅ©ÂêàËß£ÈáãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°ûÔºå‰∏¶Ë©≥Á¥∞ÂàÜÊûêÂÖ∂Áº∫ÈªûÁöÑÂéüÂõ†„ÄÇÊàëÂÄëÈÇÑË°®Êòé‰∏ÄÁ®ÆÈªëÁõíÂ∑•ÂÖ∑ÔºåÂü∫ÊñºÂõ†ÊûúÂèØËß£ÈáãÊÄßÁöÑ rexÔºåË°®ÁèæËàá \gradcam ‰∏ÄÊ®£Â•Ω„ÄÇ

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

ÊëòË¶ÅÔºöAI ÈñãÁôºÁ§æÁæ§Êó•ÁõäÂà©Áî® Hugging Face Á≠âË®óÁÆ°‰∏≠‰ªãÊ©üÊßãÊèê‰æõÁî®Êà∂‰∏äÂÇ≥ÁöÑÊ®°ÂûãÂíåË®ìÁ∑¥Ë≥áÊñôÁöÑÁ∞°ÊòìÂ≠òÂèñÊ¨äÈôê„ÄÇÈÄô‰∫õÊ®°ÂûãÂ∏ÇÈõÜÈôç‰Ωé‰∫ÜÊï∏ÂçÅËê¨ÂêçÁî®Êà∂ÁöÑÊäÄË°ìÈÉ®ÁΩ≤ÈöúÁ§ôÔºå‰ΩÜÂèØËÉΩÊúÉË¢´Áî®ÊñºË®±Â§öÊΩõÂú®ÊúâÂÆ≥ÂíåÈùûÊ≥ïÁöÑÊñπÂºè„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË™™Êòé AI Á≥ªÁµ±Êó¢ÂèØ‰ª•„ÄåÂåÖÂê´„ÄçÂÖßÂÆπÔºåÂèàÂèØ‰ª•‰ΩúÁÇ∫ÈñãÊîæÂºèÂ∑•ÂÖ∑ÔºåÈÄôÊèêÂá∫‰∫ÜËøÑ‰ªäÁÇ∫Ê≠¢ÊúÄÊ£òÊâãÁöÑÂπ≥Âè∞Ê≤ªÁêÜÊåëÊà∞‰πã‰∏Ä„ÄÇÊàëÂÄëÊèê‰æõ Hugging Face„ÄÅGitHub Âíå Civitai Á≠â‰∏âÂÄãË™™ÊòéÊÄßÂπ≥Âè∞‰∏äÊï∏Ëµ∑‰∫ã‰ª∂ÁöÑÊ°à‰æãÁ†îÁ©∂Ôºå‰ª•Ê™¢Ë¶ñÊ®°ÂûãÂ∏ÇÈõÜÂ¶Ç‰ΩïÂØ©Ê†∏Ê®°Âûã„ÄÇÊ†πÊìöÊ≠§ÂàÜÊûêÔºåÊàëÂÄëÊ¶ÇËø∞Áî¢Ê•≠ÁÇ∫ÂõûÊáâÂØ©Ê†∏ÈúÄÊ±ÇËÄåÈñãÁôºÁöÑÈáçË¶ÅÔºà‰ΩÜ‰ªçÊúâÈôêÔºâÂØ¶ÂãôÔºöÊéàÊ¨ä„ÄÅÂ≠òÂèñÂíå‰ΩøÁî®ÈôêÂà∂„ÄÅËá™ÂãïÂåñÂÖßÂÆπÂØ©Ê†∏ÂíåÈñãÊîæÊîøÁ≠ñÂà∂ÂÆö„ÄÇÈõñÁÑ∂Áï∂ÂâçÊîøÁ≠ñÊåëÊà∞Áõ∏Áï∂ÂèØËßÄÔºåÊàëÂÄëÊúÄÂæåÊèêÂá∫‰∏Ä‰∫õÊßãÊÉ≥ÔºåË™™ÊòéÂπ≥Âè∞Â¶Ç‰ΩïËÉΩÊõ¥Â•ΩÂú∞ÂãïÂì°Ë≥áÊ∫êÔºå‰ΩúÁÇ∫Ë¨πÊÖé„ÄÅÂÖ¨Âπ≥‰∏îÈÅ©Â∫¶ÁöÑÊ≥ïË¶èÂ≠òÂèñÈªû„ÄÇ

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÂíåÁõÆÊ®ôÔºöÈÄöÈÅéÊèêÂèñÈÄô‰∫õË≥áË®äÔºåÊ©üÂô®ÊàñÊ∑±Â∫¶Â≠∏Áøí (ML/DL) Âü∫ÊñºËá™‰∏ªÊï∏ÊìöÂàÜÊûêÂ∑•ÂÖ∑ÂèØ‰ª•ÂçîÂä©Ëá®Â∫äÈÜ´ÁîüÂíåÁôåÁóáÁ†îÁ©∂‰∫∫Âì°ÂæûË§áÈõúÁöÑÊï∏ÊìöÈõÜ‰∏≠ÁôºÁèæÊ®°ÂºèÂíåÈóú‰øÇ„ÄÇÊúÄËøëÂ∑≤ÁôºË°®Ë®±Â§öÂü∫Êñº DL ÁöÑÂçµÂ∑¢Áôå (OC) Êï∏ÊìöÂàÜÊûê„ÄÇÈÄô‰∫õÂàÜÊûêÂú®ÁôåÁóáÁöÑÂêÑÂÄãÊñπÈù¢Ôºà‰æãÂ¶ÇÔºåÂÆÉÂÄëÊ∂âÂèäÁöÑÂ≠êÈ†òÂüüÂíåÁôåÁóáÈ°ûÂûãÔºâÂíåÊï∏ÊìöÂàÜÊûêÂäüËÉΩÊñπÈù¢È´òÂ∫¶Â§öÊ®£Âåñ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁº∫‰πèÂ∞çÈÄô‰∫õÂàÜÊûêÂú®ÈÄô‰∫õÁâπÂæµÂíå AI ‰øùË≠â (AIA) ÊñπÈù¢ÁöÑÂÖ®Èù¢ÁêÜËß£„ÄÇÈÄôÁØáÁ≥ªÁµ±ÊÄßÂõûÈ°ßÊó®Âú®ÈÄöÈÅéÊ™¢Ë¶ñÁèæÊúâÊñáÁçª‰∏¶ÊòéÁ¢∫ÈóúÊ≥®ÈóúÈçµÁâπÂæµÂíå AI ‰øùË≠âËßÄÈªûÔºå‰æÜÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩ„ÄÇÊñπÊ≥ïÔºö‰ΩøÁî® PRISMA Êû∂ÊßãÂú®‰∏âÂÄãÊúüÂàäË≥áÊñôÂ∫´‰∏≠ÈÄ≤Ë°åÂÖ®Èù¢ÊêúÂ∞ã„ÄÇÂàÜÊûêÂÉÖÂåÖÊã¨ 2015 Âπ¥Ëá≥ 2023 Âπ¥ÈñìÁôºË°®ÊñºÂêåË°åË©ïÂØ©ÊúüÂàäÁöÑÁ†îÁ©∂„ÄÇÁµêÊûúÔºöÂú®ÂõûÈ°ß‰∏≠ÔºåÁ∏ΩÂÖ±Ê™¢Ë¶ñ‰∫Ü 96 È†ÖÁî± DL È©ÖÂãïÁöÑÂàÜÊûê„ÄÇÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫ÜÂπæÂÄãÈóúÊñºÁî± DL È©ÖÂãïÁöÑÂçµÂ∑¢ÁôåÊï∏ÊìöÂàÜÊûêÁöÑÈáçË¶ÅË¶ãËß£Ôºö- Â§ßÂ§öÊï∏Á†îÁ©∂ 71%Ôºà96 È†Ö‰∏≠Êúâ 68 È†ÖÔºâÂ∞àÊ≥®ÊñºÊ™¢Ê∏¨ÂíåË®∫Êñ∑ÔºåËÄåÊ≤íÊúâÁ†îÁ©∂Êé¢Ë®é OC ÁöÑÈ†êÊ∏¨ÂíåÈ†êÈò≤„ÄÇ- ÈÄô‰∫õÂàÜÊûê‰∏ªË¶ÅÂü∫Êñº‰æÜËá™ÈùûÂ§öÂÖÉÊóèÁæ§ÁöÑÊ®£Êú¨Ôºà75%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 72 È†ÖÔºâÔºâÔºåÂÉÖÈôêÊñºÊüêÂÄãÂú∞ÁêÜ‰ΩçÁΩÆÊàñÂúãÂÆ∂„ÄÇ- Âè™ÊúâÂ∞ëÈÉ®ÂàÜÁ†îÁ©∂ÔºàÂÉÖ 33%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 32 È†ÖÔºâÂü∑Ë°åÊï¥ÂêàÂàÜÊûêÔºåÂÖ∂‰∏≠Â§ßÂ§öÊï∏‰ΩøÁî®ÂêåË≥™Êï∏ÊìöÔºàËá®Â∫äÊàñÁµÑÂ≠∏Ôºâ„ÄÇ- ÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂè™Êúâ 8.3%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 8 È†ÖÔºâ‰ΩøÁî®Â§ñÈÉ®ÂíåÂ§öÂÖÉÊï∏ÊìöÈõÜÈ©óË≠â‰∫ÜÂÖ∂Ê®°ÂûãÔºåÂº∑Ë™ø‰∫ÜÂä†Âº∑Ê®°ÂûãÈ©óË≠âÁöÑÂøÖË¶ÅÊÄßÔºå‰ª•Âèä- Â∞á AIA Á¥çÂÖ•ÁôåÁóáÊï∏ÊìöÂàÜÊûê‰ªçËôïÊñºÈùûÂ∏∏Êó©ÊúüÁöÑÈöéÊÆµÔºõÂè™Êúâ 2.1%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 2 È†ÖÔºâÈÄèÈÅéÂèØËß£ÈáãÊÄßÊòéÁ¢∫Êé¢Ë®é‰∫Ü AIA„ÄÇ</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

ÊëòË¶ÅÔºö<paragraph>Ëß£ÈáãÊÄßÊòØÊ∑±Â∫¶Â≠∏Áøí‰∏≠Èï∑ÊúüÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≠âÈ´òÈ¢®Èö™È†òÂüü„ÄÇÂ∏∏Ë¶ãÁöÑËß£ÈáãÊÄßÊñπÊ≥ïÊúÉÂº∑Ë™øÈ©ÖÂãï AI Ê®°ÂûãÊ±∫Á≠ñÁöÑÂΩ±ÂÉèÂçÄÂüü„ÄÇÁÑ∂ËÄåÔºå‰∫∫È°ûÂæàÂ§ßÁ®ãÂ∫¶‰æùË≥¥Ë™ûË®Ä‰æÜÂÇ≥ÈÅî‰∏çÂÉÖÊòØ„ÄåÂú®Âì™Ë£°„ÄçÔºåÈÇÑÊúâ„ÄåÊòØ‰ªÄÈ∫º„ÄçÁöÑËß£Èáã„ÄÇÊ≠§Â§ñÔºåÂ§ßÂ§öÊï∏Ëß£ÈáãÊÄßÊñπÊ≥ïÈÉΩÂ∞àÊ≥®ÊñºËß£ÈáãÂÄãÂà• AI È†êÊ∏¨ÔºåËÄå‰∏çÊòØÊèèËø∞ AI Ê®°Âûã‰∏ÄËà¨‰ΩøÁî®ÁöÑÁâπÂæµ„ÄÇÂæåËÄÖÂ∞çÊñºÊ®°ÂûãÂíåË≥áÊñôÈõÜÁ®ΩÊ†∏ÁâπÂà•ÊúâÁî®ÔºåÁîöËá≥ÂèØËÉΩÂú® AI ÊÑà‰æÜÊÑàÁî®ÊñºÊñ∞Á©é‰ªªÂãôÊôÇÁî¢ÁîüÁü•Ë≠ò„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã‰æÜËæ®Ë≠òË¶ñË¶∫ÂàÜÈ°û‰ªªÂãôÁöÑË™ûË®ÄÊèèËø∞Á¨¶ÁöÑËß£ÈáãÊÄßÁ≠ñÁï•„ÄÇÈÄèÈÅéÂà©Áî®ÂΩ±ÂÉèÂíåÊñáÂ≠ó‰πãÈñìÈ†êÂÖàË®ìÁ∑¥ÁöÑËÅØÂêàÂµåÂÖ•Á©∫ÈñìÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÊñ∞ÁöÑÂàÜÈ°û‰ªªÂãô‰º∞Ë®àÁÇ∫‰∏ÄÂÄãÁ∑öÊÄßÊñáÂ≠óÁµÑÂêàÔºåÂ∞éËá¥ÊØèÂÄãÊñáÂ≠óÈÉΩÊúâÊ¨äÈáçÔºåË°®Á§∫ÂÆÉËàáÂü∫ÊñºË¶ñË¶∫ÁöÑÂàÜÈ°ûÂô®Â∞çÈΩä„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ©ÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãô‰æÜË©ï‰º∞ÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÊàëÂÄëÁôºÁèæÁî¢ÁîüÁöÑÊèèËø∞Á¨¶Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äËàáËá®Â∫äÁü•Ë≠ò‰∏ÄËá¥ÔºåÂÑòÁÆ°Áº∫‰πèÁâπÂÆöÈ†òÂüüÁöÑË™ûË®ÄË®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁöÑÂÅöÊ≥ï‰πüÁôºÁèæ‰∫ÜÊâÄÁî®ÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏≠ÁöÑ„ÄåÊç∑ÂæëÈÄ£Á∑ö„ÄçÁöÑÂèØËÉΩÊÄß„ÄÇÁÇ∫‰∫ÜÈÅîÂà∞Ëß£ÈáãÊÄßÁöÑÂäüËÉΩÊÄßË°°ÈáèÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖË©¶È©óËÆÄËÄÖÁ†îÁ©∂ÔºåÁôºÁèæ AI Ë≠òÂà•ÁöÑÊñáÂ≠óËÉΩËÆìÈùûÂ∞àÂÆ∂‰∫∫È°ûÂú®ÈùûÂπ≥Âá°ÁöÑÂ±§Á¥öÂü∑Ë°åÂ∞àÊ•≠ÁöÑÈÜ´ÁôÇ‰ªªÂãô„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëÁöÑÁµêÊûúÂº∑Ë™ø‰∫Ü‰ΩøÁî®Â§öÊ®°ÂºèÂü∫Á§éÊ®°Âûã‰æÜÊèê‰æõÁõ¥ËßÄÁöÑ„ÄÅÂü∫ÊñºË™ûË®ÄÁöÑË¶ñË¶∫‰ªªÂãôËß£ÈáãÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

ÊëòË¶ÅÔºö<paragraph>‰ΩøÁî®ÈÜ´ÁôÇÂΩ±ÂÉèË®ìÁ∑¥ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãÔºåÁî®ÊñºËá®Â∫ä‰ªªÂãôÊôÇÔºåÂ∏∏ÊúÉÂú®ÊïàËÉΩ‰∏äÂ±ïÁèæÂá∫Ê¨°Áæ§È´î‰πãÈñìÁöÑÂ∑ÆÁï∞ÔºåÂΩ¢ÊàêÂÅèË¶ã„ÄÇÁî±Êñº‰∏¶ÈùûÊâÄÊúâÁúüÂØ¶‰∏ñÁïåÈÜ´ÁôÇÂΩ±ÂÉèË≥áÊñô‰∏≠ÁöÑÂÅèË¶ã‰æÜÊ∫êÈÉΩÂÆπÊòìËæ®Ë≠òÔºåÂõ†Ê≠§ÂÖ®Èù¢Ë©ï‰º∞ÈÄô‰∫õÂÅèË¶ãÊòØÂ¶Ç‰ΩïÁ∑®Á¢ºÂà∞Ê®°Âûã‰∏≠Ôºå‰ª•ÂèäÂÅèË¶ãÁ∑©Ëß£ÊñπÊ≥ïÂú®ÊîπÂñÑÊïàËÉΩÂ∑ÆÁï∞ÊñπÈù¢ÁöÑËÉΩÂäõÔºåÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂàÜÊûêÊû∂ÊßãÔºåÁî®ÊñºÁ≥ªÁµ±Âåñ‰∏îÂÆ¢ËßÄÂú∞Ë™øÊü•ÈÜ´ÁôÇÂΩ±ÂÉè‰∏≠ÁöÑÂÅèË¶ãÂ∞ç AI Ê®°ÂûãÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈñãÁôº‰∏¶Ê∏¨Ë©¶‰∫ÜÈÄôÂÄãÊû∂ÊßãÔºå‰ª•ÈÄ≤Ë°åÂèóÊéßÁöÑÈõªËÖ¶Ê®°Êì¨Ë©¶È©óÔºå‰ΩøÁî®‰∏ÄÂÄãÂ∑•ÂÖ∑‰æÜË©ï‰º∞ÈÜ´ÁôÇÂΩ±ÂÉè AI ‰∏≠ÁöÑÂÅèË¶ãÔºåË©≤Â∑•ÂÖ∑Áî®ÊñºÁî¢ÁîüÂÖ∑ÊúâÂ∑≤Áü•ÁñæÁóÖÂΩ±ÈüøÂíåÂÅèË¶ã‰æÜÊ∫êÁöÑÂêàÊàêÁ£ÅÂÖ±ÊåØÂΩ±ÂÉè„ÄÇÂèØË°åÊÄßÈÄèÈÅé‰ΩøÁî®‰∏âÂÄãÂèç‰∫ãÂØ¶ÂÅèË¶ãÊÉÖÂ¢É‰æÜË°°ÈáèÊ®°Êì¨ÂÅèË¶ãÊïàÊáâÂ∞çÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂàÜÈ°ûÂô®Âíå‰∏âÂÄãÂÅèË¶ãÁ∑©Ëß£Á≠ñÁï•ÁöÑÂΩ±ÈüøÔºå‰∏¶Â±ïÁ§∫Âá∫‰æÜ„ÄÇÂàÜÊûêÈ°ØÁ§∫ÔºåÁï∂ CNN Âú®ÂêàÊàêË≥áÊñôÈõÜ‰∏äÂèóË®ìÊôÇÔºåÊ®°Êì¨ÂÅèË¶ãÊúÉÂ∞éËá¥È†êÊúüÁöÑÊ¨°Áæ§È´îÊïàËÉΩÂ∑ÆÁï∞„ÄÇÊ≠§Â§ñÔºåÈáçÊñ∞Âä†Ê¨äË¢´Ë™çÁÇ∫ÊòØÊ≠§Ë®≠ÂÆö‰∏≠ÊúÄÊàêÂäüÁöÑÂÅèË¶ãÁ∑©Ëß£Á≠ñÁï•ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËß£ÈáãÊÄß AI ÊñπÊ≥ïÂ¶Ç‰ΩïÂçîÂä©‰ΩøÁî®ÈÄôÂÄãÊû∂ÊßãË™øÊü•Ê®°Âûã‰∏≠ÂÅèË¶ãÁöÑË°®Áèæ„ÄÇÈñãÁôºÂÖ¨Âπ≥ÁöÑ AI Ê®°ÂûãÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂõ†ÁÇ∫ÈÜ´ÁôÇÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏≠ÂèØËÉΩÂ≠òÂú®Ë®±Â§ö‰∏îÁ∂ìÂ∏∏Êú™Áü•ÁöÑÂÅèË¶ã‰æÜÊ∫ê„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂÆ¢ËßÄÂú∞Á†îÁ©∂ÂÅèË¶ãÂíåÁ∑©Ëß£Á≠ñÁï•Â∞çÊ∑±Â∫¶Â≠∏ÁøíÁÆ°Á∑öÁöÑÂΩ±ÈüøÔºåÈÄôÂèØ‰ª•ÊîØÊè¥ÂÅ•ÂÖ®‰∏îË≤†Ë≤¨‰ªªÁöÑËá®Â∫ä AI ÁöÑÈñãÁôº„ÄÇ</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÁÇ∫Ëá™ÂãïÈ†êÊ∏¨‰∏≠È¢®ÂæåÁóáÁãÄÂèäÂÖ∂Â∞çÂæ©ÂÅ•ÁöÑÂèçÊáâÊèê‰æõ‰∫ÜÊ•µÂ§ßÁöÑÊΩõÂäõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁöÑÈáçÂ§ßÊåëÊà∞ÂåÖÊã¨Á•ûÁ∂ìÂΩ±ÂÉèË≥áÊñôÁöÑÁ∂≠Â∫¶ÈùûÂ∏∏È´ò„ÄÅÂèØÁî®ÊñºÂ≠∏ÁøíÁöÑË≥áÊñôÈõÜË¶èÊ®°Áõ∏Â∞çËºÉÂ∞èÔºå‰ª•ÂèäÂ¶Ç‰ΩïÊúâÊïàÁµêÂêàÁ•ûÁ∂ìÂΩ±ÂÉèÂíåË°®Ê†ºË≥áÊñôÔºà‰æãÂ¶Ç‰∫∫Âè£Áµ±Ë®àË≥áË®äÂíåËá®Â∫äÁâπÂæµÔºâ„ÄÇÊú¨ÊñáÊ†πÊìöÂÖ©Á®ÆÁ≠ñÁï•Ë©ï‰º∞‰∫ÜÂ§öÁ®ÆËß£Ê±∫ÊñπÊ°à„ÄÇÁ¨¨‰∏ÄÁ®ÆÊòØ‰ΩøÁî®Á∏ΩÁµê MRI ÊéÉÊèèÁöÑ 2D ÂΩ±ÂÉè„ÄÇÁ¨¨‰∫åÁ®ÆÊòØÈÅ∏ÊìáÊúâÂä©ÊñºÊèêÈ´òÂàÜÈ°ûÁ≤æÁ¢∫Â∫¶ÁöÑÈóúÈçµÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂú®ÁµêÂêàÂæû MRI ‰∏≠ÊèêÂèñÁöÑÊÑüËààË∂£ÂçÄÂüüËàáË°®Ê†ºË≥áÊñôÁöÑÁ¨¶ËôüË°®Á§∫ÁöÑÂΩ±ÂÉè‰∏äË®ìÁ∑¥Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÁöÑÊñ∞Á©éÊñπÊ≥ï„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü‰∏ÄÁ≥ªÂàó CNN Êû∂ÊßãÔºà2D Âíå 3DÔºâÔºåÈÄô‰∫õÊû∂ÊßãÂú® MRI ÂíåË°®Ê†ºË≥áÊñôÁöÑ‰∏çÂêåË°®Á§∫‰∏äÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰ª•È†êÊ∏¨‰∏≠È¢®ÂæåÂè£Ëø∞ÂúñÁâáÊèèËø∞ËÉΩÂäõÁöÑÁ∂úÂêàÊ∏¨ÈáèÊòØÂê¶Âú®Â§±Ë™ûÁóáÊàñÈùûÂ§±Ë™ûÁóáÁØÑÂúçÂÖß„ÄÇMRI ÂíåË°®Ê†ºË≥áÊñô‰æÜËá™ 758 ÂêçÂèÉËàá PLORAS Á†îÁ©∂ÁöÑËã±Ë™û‰∏≠È¢®ÂÄñÂ≠òËÄÖ„ÄÇÂÉÖÈáùÂ∞çÁóÖÁÅ∂Â§ßÂ∞èÁöÑÂü∫Á∑öÈÇèËºØËø¥Ê≠∏ÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 0.678ÔºåÁï∂‰æùÂ∫èÂä†ÂÖ•ÂàùÂßãÁóáÁãÄÂö¥ÈáçÁ®ãÂ∫¶ÂíåÊÅ¢Âæ©ÊôÇÈñìÊôÇÔºå‰∏äÂçáËá≥ 0.757 Âíå 0.813„ÄÇÂú®ÂæûÊØèÂÄã MRI ÊéÉÊèè‰∏≠ÊèêÂèñ 8 ÂÄãÊÑüËààË∂£ÂçÄÂüü‰∏¶Âú® 2D ÊÆòÂ∑ÆÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰∏≠ËàáÁóÖÁÅ∂Â§ßÂ∞è„ÄÅÂàùÂßãÂö¥ÈáçÁ®ãÂ∫¶ÂíåÊÅ¢Âæ©ÊôÇÈñìÁµêÂêàÊôÇÔºåËßÄÂØüÂà∞ÊúÄÈ´òÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ 0.854„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞áÂΩ±ÂÉèÂíåË°®Ê†ºË≥áÊñôÁµêÂêàËµ∑‰æÜ‰ª•Áç≤ÂæóÈ´òÊñº‰∏≠È¢®ÂæåÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÔºåÂç≥‰ΩøÂú®Ê©üÂô®Â≠∏ÁøíË°ìË™û‰∏≠Ë≥áÊñôÈõÜÂæàÂ∞èÁöÑÊÉÖÊ≥Å‰∏ã‰πüÊòØÂ¶ÇÊ≠§„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫Â¶Ç‰ΩïÊîπÈÄ≤ÁõÆÂâçÁöÑÊ®°ÂûãÔºå‰ª•‰ΩøÁî®‰æÜËá™ÈÜ´Èô¢ÊéÉÊèèÂÑÄÁöÑÂΩ±ÂÉè‰æÜÂØ¶ÁèæÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∑≤ÊàêÁÇ∫ËôïÁêÜ‰ªªÂãôÈóúÈçµÊáâÁî®Á®ãÂºèÊôÇÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨ÈúÄÊ±ÇÔºåÁ¢∫‰øùÊé°Áî®ÈªëÁõí AI Ê®°ÂûãÁöÑÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄß„ÄÇXAI ÁöÑÈáçË¶ÅÊÄßÊ∂µËìãÂæûÈÜ´ÁôÇ‰øùÂÅ•Âà∞ÈáëËûçÁöÑÂêÑÁ®ÆÈ†òÂüüÔºåÂú®ÈÄô‰∫õÈ†òÂüü‰∏≠Ôºå‰∫ÜËß£Ê∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÁöÑÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãËá≥ÈóúÈáçË¶Å„ÄÇÂ§ßÂ§öÊï∏Âü∫Êñº AI ÁöÑÈõªËÖ¶Ë¶ñË¶∫Ê®°ÂûãÈÄöÂ∏∏ÊòØÈªëÁõíÂ≠êÔºõÂõ†Ê≠§ÔºåÂú®ÂΩ±ÂÉèËôïÁêÜ‰∏≠Êèê‰æõÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂèØËß£ÈáãÊÄßÂ∞çÊñºÂÖ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê„ÄÅËá™ÂãïÈßïÈßõÂíåÈÅôÊ∏¨ÊáâÁî®‰∏≠ÁöÑÂª£Ê≥õÊé°Áî®ÂíåÈÉ®ÁΩ≤Ëá≥ÈóúÈáçË¶Å„ÄÇÊúÄËøëÔºåÂ∑≤ÈáùÂ∞çÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãôÂºïÂÖ•‰∫ÜÂ§öÁ®Æ XAI ÊñπÊ≥ï„ÄÇÁõ∏ÂèçÂú∞ÔºåÂΩ±ÂÉèÂàÜÂâ≤Âú®ÂèØËß£ÈáãÊÄßÁöÑËÉåÊôØ‰∏ãÂèóÂà∞ÁöÑÈóúÊ≥®Áõ∏Â∞çËºÉÂ∞ëÔºåÂÑòÁÆ°ÂÆÉÊòØÈõªËÖ¶Ë¶ñË¶∫ÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨‰ªªÂãôÔºåÁâπÂà•ÊòØÂú®ÈÅôÊ∏¨‰∏≠„ÄÇÂè™ÊúâÈÉ®ÂàÜÁ†îÁ©∂ÊèêÂá∫Áî®ÊñºÂΩ±ÂÉèÂàÜÂâ≤ÁöÑÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑ XAI ÊºîÁÆóÊ≥ï„ÄÇÊú¨ÊñáÊîπÁ∑®‰∫ÜÊúÄËøëÁöÑÁÑ°Ê¢ØÂ∫¶ Sobol XAI ÊñπÊ≥ï‰ª•ÈÄ≤Ë°åË™ûÊÑèÂàÜÂâ≤„ÄÇÁÇ∫‰∫ÜË°°Èáè Sobol ÊñπÊ≥ïÂú®ÂàÜÂâ≤‰∏≠ÁöÑÊïàËÉΩÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂèØÂ≠∏ÁøíÈõúË®äÊ®°ÂûãÁöÑÂÆöÈáè XAI Ë©ï‰º∞ÊñπÊ≥ï„ÄÇÊ≠§Ê®°ÂûãÁöÑ‰∏ªË¶ÅÁõÆÁöÑÊòØÂú®Ëß£ÈáãÂúñ‰∏äË™òÁôºÈõúË®äÔºåÂÖ∂‰∏≠ËºÉÈ´òÁöÑË™òÁôºÈõúË®äË°®Á§∫ËºÉ‰ΩéÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂèç‰πã‰∫¶ÁÑ∂„ÄÇÈÄ≤Ë°åÂü∫Ê∫ñÂàÜÊûê‰ª•Ë©ï‰º∞ÂíåÊØîËºÉ‰∏âÁ®Æ XAI ÊñπÊ≥ïÁöÑÊïàËÉΩÔºåÂåÖÊã¨ Seg-Grad-CAM„ÄÅSeg-Grad-CAM++ Âíå Seg-SobolÔºå‰∏¶‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÂü∫ÊñºÈõúË®äÁöÑË©ï‰º∞ÊäÄË°ì„ÄÇÈÄôÊßãÊàê‰∫Ü‰ΩøÁî®È´òËß£ÊûêÂ∫¶Ë°õÊòüÂΩ±ÂÉèÂü∑Ë°åÂíåË©ï‰º∞ XAI ÊñπÊ≥ïÁöÑÈ¶ñÊ¨°ÂòóË©¶„ÄÇ

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Áü≠ÊôÇÈñìÂÖßÂ∑≤Âú®Â§öÂÄãÈ†òÂüü‰∏≠Â§ßÈáèÊøÄÂ¢û„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº‰∫ãÂØ¶ÊÄß„ÄÅÈÄ£Ë≤´ÊÄßÂíåÂπªË¶∫Á≠âÂïèÈ°åÔºåÈÜ´ÁôÇÂíå‰øùÂÅ•È†òÂüüÂ∞çÂÖ∂Êé°Áî®Áå∂Ë±´‰∏çÊ±∫„ÄÇÈëëÊñºÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÈ´òÈ¢®Èö™ÊÄßË≥™ÔºåË®±Â§öÁ†îÁ©∂‰∫∫Âì°ÁîöËá≥Ë≠¶Âëä‰∏çË¶Å‰ΩøÁî®ÂÆÉÔºåÁõ¥Âà∞ÈÄô‰∫õÂïèÈ°åÂæóÂà∞Ëß£Ê±∫„ÄÇÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂØ¶ÊñΩÂíåÈÉ®ÁΩ≤ LLM ÁöÑÈóúÈçµÊòØ‰ΩøÈÄô‰∫õÊ®°ÂûãÂÄºÂæó‰ø°Ë≥¥„ÄÅÈÄèÊòéÔºàÁõ°ÂèØËÉΩÂ§öÔºâ‰∏îÂèØËß£Èáã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèèËø∞‰∫ÜÂª∫Á´ãÂèØÈù†„ÄÅÂÄºÂæó‰ø°Ë≥¥ÂíåÁÑ°ÂÅèË¶ãÊ®°ÂûãÁöÑÈóúÈçµË¶ÅÁ¥†Ôºå‰ΩúÁÇ∫ÂÆÉÂÄëÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂæóÂà∞Êé°Áî®ÁöÑÂøÖË¶ÅÊ¢ù‰ª∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂú®ÈÜ´ÁôÇ‰øùÂÅ•ËÉåÊôØ‰∏ãÂ∞çÂπªË¶∫ÈÄ≤Ë°åÈáèÂåñ„ÄÅÈ©óË≠âÂíåÁ∑©Ëß£„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫Ü LLM Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊú™‰æÜÂèØËÉΩÊòØ‰ªÄÈ∫ºÊ®£Â≠ê„ÄÇ

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂ∑≤Âø´ÈÄüÈÄ≤Ê≠•ÔºåÁèæÂ∑≤Ê∫ñÂÇôÈÉ®ÁΩ≤ÊñºÂª£Ê≥õÁöÑÊáâÁî®Á®ãÂºè‰∏≠Ôºå‰æãÂ¶ÇËá™‰∏ªÁ≥ªÁµ±„ÄÅÈÜ´ÁôÇË®∫Êñ∑ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÇÂèäÊó©Êé°Áî® AI ÊäÄË°ìÊñºÂØ¶ÈöõÊáâÁî®Á®ãÂºè‰∏¶ÈùûÊ≤íÊúâÂïèÈ°åÔºåÁâπÂà•ÊòØÂ∞çÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÂÆÉÂèØËÉΩ‰∏çÁ©©ÂÆö‰∏îÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÁØÑ‰æãÁöÑÂΩ±Èüø„ÄÇÂæûÈï∑ÈÅ†‰æÜÁúãÔºåÈúÄË¶ÅÈñãÁôºÈÅ©Áï∂ÁöÑÂÆâÂÖ®‰øùË≠âÊäÄË°ìÔºå‰ª•Ê∏õÂ∞ëÂõ†ÂèØÈÅøÂÖçÁöÑÁ≥ªÁµ±ÊïÖÈöúËÄåÈÄ†ÊàêÁöÑÊΩõÂú®ÂÇ∑ÂÆ≥Ôºå‰∏¶Á¢∫‰øùÂèØ‰ø°Ë≥¥ÊÄß„ÄÇÊú¨ÊñáËëóÈáçÊñºË™çË≠âÂíåÂèØËß£ÈáãÊÄßÔºåÊ¶ÇËø∞‰∫ÜÂ∑≤ÈñãÁôºÁî®ÊñºÁ¢∫‰øù AI Ê±∫Á≠ñÂÆâÂÖ®ÁöÑÊäÄË°ìÔºå‰∏¶Ë®éË´ñÊú™‰æÜÁöÑÊåëÊà∞„ÄÇ

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. Garc√≠a-G√≥mez, Vicent Blanes-Selva, Jos√© Carlos de Bartolom√© Cenzano, Jaime Cebolla-Cornejo, Ascensi√≥n Do√±ate-Mart√≠nez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

ÊëòË¶ÅÔºöÊ≠êÊ¥≤Ë≠∞ÊúÉË≠∞ÊúÉÁ†îÁ©∂ÊúçÂãôÁ∏ΩÂ±ÄÂ∑≤ÁÇ∫Ê≠êÊ¥≤Ë≠∞ÊúÉË≠∞Âì°Ê∫ñÂÇô‰∫Ü‰∏Ä‰ªΩÂ†±ÂëäÔºåÂÖ∂‰∏≠ÂàóËàâ‰∫Ü‰∫∫Â∑•Êô∫ËÉΩ (AI) Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑ‰∏ÉÈ†Ö‰∏ªË¶ÅÈ¢®Èö™ÔºöAI ÈåØË™§Â∞éËá¥ÊÇ£ËÄÖÂèóÂà∞ÂÇ∑ÂÆ≥„ÄÅÈÜ´ÁôÇ AI Â∑•ÂÖ∑Ë¢´Êø´Áî®„ÄÅAI Â≠òÂú®ÂÅèË¶ã‰∏¶Â∞éËá¥ÁèæÊúâ inequities ÊåÅÁ∫åÂ≠òÂú®„ÄÅÁº∫‰πèÈÄèÊòéÂ∫¶„ÄÅÈö±ÁßÅÂíåÂÆâÂÖ®ÂïèÈ°å„ÄÅÂïèË≤¨Â∑ÆË∑ù‰ª•ÂèäÂØ¶ÊñΩÈöúÁ§ô„ÄÇ
  Âú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂçÅÂõõÈ†ÖÂäüËÉΩÊÄßË¶ÅÊ±ÇÔºåAI Á≥ªÁµ±ÂèØ‰ª•ÂØ¶ÊñΩÈÄô‰∫õË¶ÅÊ±Ç‰æÜÈôç‰ΩéËàáÂÖ∂ÈÜ´ÁôÇÁõÆÁöÑÁõ∏ÈóúÁöÑÈ¢®Èö™ÔºöAI Ë≠∑ÁÖß„ÄÅ‰ΩøÁî®ËÄÖÁÆ°ÁêÜ„ÄÅÊ≥ïË¶èÊ™¢Êü•„ÄÅÂÉÖÈôêÂ≠∏Ë°ìÁî®ÈÄîÂÖçË≤¨ËÅ≤Êòé„ÄÅË≥áÊñôÂìÅË≥™Ë©ï‰º∞„ÄÅËá®Â∫äÈÜ´ÁîüÈõôÈáçÊ™¢Êü•„ÄÅÊåÅÁ∫åÊïàËÉΩË©ï‰º∞„ÄÅÁ®ΩÊ†∏ËøΩËπ§„ÄÅÊåÅÁ∫åÂèØÁî®ÊÄßÊ∏¨Ë©¶„ÄÅÂõûÈ°ßÂõûÊ∫Ø/Ê®°Êì¨Ê°à‰æã„ÄÅÂÅèË¶ãÊ™¢Êü•„ÄÅÂèØËß£Èáã AI„ÄÅÂä†ÂØÜÂíå‰ΩøÁî®Á∂ìÈÅéÂØ¶Âú∞Ê∏¨Ë©¶ÁöÑÁ®ãÂºèÂ∫´Ôºå‰ª•ÂèäË™ûÊÑè‰∫íÈÄöÊÄß„ÄÇ
  ÊàëÂÄëÂú®Ê≠§ÁöÑÁõÆÁöÑÊòØÊèê‰æõÊäÄË°ìËß£Ê±∫ÊñπÊ°àÁöÑÁâπÂÆöÈ´òÈöéË¶èÊ†ºÔºå‰ª•Á¢∫‰øùÊåÅÁ∫åËâØÂ•ΩÁöÑÊïàËÉΩÔºå‰∏¶‰ΩøÁî® AI Á≥ªÁµ±Ôºå‰ª•Á¨¶ÂêàÊú™‰æÜÁöÑÊ≠êÁõüÊ≥ïË¶èÊû∂ÊßãÔºåÂæûËÄå‰ΩøÊÇ£ËÄÖÂèóÁõä„ÄÇ

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÂèØÁî®ÊñºÂàÜÈ°ûÁóÖÊÇ£ÁöÑË∫´È´îÊ¥ªÂãï‰∏¶È†êÊ∏¨ÈÅ†Ë∑ùÁóÖÊÇ£Áõ£ÊéßÁöÑÈáçË¶ÅÁîüÂëΩÂæµË±°„ÄÇÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁ≠âÈùûÁ∑öÊÄßÊ®°ÂûãÁöÑÂõûÊ≠∏ÂàÜÊûêÁî±ÊñºÂÖ∂ÈªëÁõíÂ≠êÁöÑÊÄßË≥™ËÄåÂÖ∑ÊúâÊúâÈôêÁöÑÂèØËß£ÈáãÊÄß„ÄÇÈÄôÂèØËÉΩÈúÄË¶ÅÊ±∫Á≠ñËÄÖÊ†πÊìöÈùûÁ∑öÊÄßÊ®°ÂûãÁµêÊûúÂÅöÂá∫Áõ≤ÁõÆÁöÑ‰ø°‰ª∞È£õË∫çÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠„ÄÇÂú®Èùû‰æµÂÖ•ÊÄßÁõ£Êéß‰∏≠Ôºå‰æÜËá™ËøΩËπ§ÊÑüÊ∏¨Âô®ÂíåÂÖ∂ÊòìÊÑüËá®Â∫äÂ±¨ÊÄßÁöÑÁóÖÊÇ£Ë≥áÊñôÂÖÖÁï∂È†êÊ∏¨Êú™‰æÜÁîüÂëΩÂæµË±°ÁöÑËº∏ÂÖ•ÁâπÂæµ„ÄÇËß£ÈáãÂêÑÁ®ÆÁâπÂæµÂ∞çÁõ£ÊéßÊáâÁî®Á®ãÂºèÊï¥È´îËº∏Âá∫ÁöÑË≤¢ÁçªÂ∞çÊñºËá®Â∫äÈÜ´ÁîüÁöÑÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî®ÊñºÈáèÂåñÂàÜÊûêÁöÑÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (QXAI) Êû∂ÊßãÔºåË©≤Êû∂ÊßãÂÖ∑ÊúâÁõ£Áù£ÂºèÂ≠∏ÁøíÊñπÊ≥ï‰∏≠ÂõûÊ≠∏ÂíåÂàÜÈ°û‰ªªÂãôÁöÑ‰∫ãÂæåÊ®°ÂûãÂèØËß£ÈáãÊÄßÂíåÂÖßÂú®ÂèØËß£ÈáãÊÄß„ÄÇÈÄôÈÄèÈÅéÂà©Áî® Shapley ÂÄºÊ¶ÇÂøµ‰∏¶Â∞áÊ≥®ÊÑèÂäõÊ©üÂà∂Á¥çÂÖ•Ê∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰æÜÂØ¶Áèæ„ÄÇÊàëÂÄëÊé°Áî®‰∫∫Â∑•Á•ûÁ∂ìÁ∂≤Ë∑Ø (ANN) ÂíåÂü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÈõôÂêë LSTM (BiLSTM) Ê®°ÂûãÔºåÊ†πÊìöÊÑüÊ∏¨Âô®Ë≥áÊñôÈ†êÊ∏¨ÂøÉÁéáÂíåÂàÜÈ°ûË∫´È´îÊ¥ªÂãï„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®È†êÊ∏¨ÂíåÂàÜÈ°û‰ªªÂãô‰∏≠ÈÉΩÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊàêÊûú„ÄÇÂ∞çËº∏ÂÖ•Ë≥áÊñôÈÄ≤Ë°åÂÖ®Â±ÄËß£ÈáãÂíåÂ±ÄÈÉ®Ëß£ÈáãÔºå‰ª•‰∫ÜËß£ÂêÑÁ®ÆÁóÖÊÇ£Ë≥áÊñôÁöÑÁâπÂæµË≤¢Áçª„ÄÇÊâÄÊèêÂá∫ÁöÑ QXAI Êû∂Êßã‰ΩøÁî® PPG-DaLiA Ë≥áÊñôË©ï‰º∞Ôºå‰ª•È†êÊ∏¨ÂøÉÁéáÔºå‰∏¶‰ΩøÁî®Ë°åÂãïÂÅ•Â∫∑ (MHEALTH) Ë≥áÊñôÊ†πÊìöÊÑüÊ∏¨Âô®Ë≥áÊñôÂ∞çË∫´È´îÊ¥ªÂãïÈÄ≤Ë°åÂàÜÈ°û„ÄÇËíôÂú∞Âç°ÁæÖËøë‰ººÊ≥ïÊáâÁî®ÊñºË©≤Êû∂ÊßãÔºå‰ª•ÂÖãÊúç Shapley ÂÄºË®àÁÆóÊâÄÈúÄÁöÑÊôÇÈñìË§áÈõúÂ∫¶ÂíåÈ´òÈÅãÁÆóËÉΩÂäõÈúÄÊ±Ç„ÄÇ

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

ÊëòË¶ÅÔºöÂú®ÂèØËß£Èáä‰∫∫Â∑•Êô∫ËÉΩ (XAI) Á†îÁ©∂‰∏≠Ôºå‰∏ªË¶ÅÈáçÁÇπÂú®‰∫é‰∏∫‰∏ìÂÆ∂Âíå‰ªé‰∏öËÄÖËß£ÈáäÊ®°Âûã„ÄÇÊ®°Âûã‰∏çÂèØÁü•ÂíåÂ±ÄÈÉ®Ëß£ÈáäÊñπÊ≥ïÂú®ËÆ∏Â§öÂ∫îÁî®‰∏≠Ë¢´ËÆ§‰∏∫ÊòØÂèØËß£Èáä‰∏îË∂≥Â§üÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂú®ÂåªÁñó‰øùÂÅ•Á≠âÈ¢ÜÂüüÔºåÊúÄÁªàÁî®Êà∑ÊòØÁº∫‰πè‰∫∫Â∑•Êô∫ËÉΩÊàñÈ¢ÜÂüü‰∏ì‰∏öÁü•ËØÜÁöÑÊÇ£ËÄÖÔºåÂõ†Ê≠§Ëø´ÂàáÈúÄË¶ÅÊõ¥Êòì‰∫éÁêÜËß£‰∏îËÉΩÊøÄÂèëÂØπÊ®°ÂûãÊìç‰ΩúÁöÑ‰ø°‰ªªÁöÑÊ®°ÂûãËß£Èáä„ÄÇÊàë‰ª¨ÂÅáËÆæÁîüÊàêÂèôËø∞ÊÄß„ÄÅÊÇ£ËÄÖÁâπÂÆö‰∏îÂÖ®Â±ÄÔºàÊ®°ÂûãÊï¥‰ΩìÔºâÁöÑÊ®°ÂûãËß£ÈáäÂ∞ÜËÉΩÂ§üÊèêÈ´òÂèØÁêÜËß£ÊÄßÂπ∂ÊîØÊåÅÂÜ≥Á≠ñÂà∂ÂÆö„ÄÇÊàë‰ª¨‰ΩøÁî®ÂÜ≥Á≠ñÊ†ëÊ®°ÂûãÂØπÊ≠§ËøõË°åÊµãËØïÔºå‰∏∫Ë¢´ËØÜÂà´‰∏∫ÊÇ£ÊúâÂÜ†ÂøÉÁóÖÈ´òÈ£éÈô©ÁöÑÊÇ£ËÄÖÁîüÊàêÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄËß£Èáä„ÄÇËøô‰∫õËß£Èáä‰ºöÂëàÁé∞ÁªôÈùû‰∏ìÂÆ∂Áî®Êà∑„ÄÇÊàë‰ª¨ÂèëÁé∞Áî®Êà∑Âº∫ÁÉàÂÅèÂ•ΩÁâπÂÆöÁ±ªÂûãÁöÑËß£Èáä„ÄÇÂ§ßÂ§öÊï∞ÂèÇ‰∏éËÄÖÂÅèÂ•ΩÂÖ®Â±ÄËß£ÈáäÔºåËÄåËæÉÂ∞èÁöÑ‰∏ÄÁªÑÂèÇ‰∏éËÄÖÂÅèÂ•ΩÂ±ÄÈÉ®Ëß£Èáä„ÄÇÂü∫‰∫é‰ªªÂä°ÁöÑÂøÉÁêÜÊ®°ÂûãËØÑ‰º∞‰∏∫Ëøô‰∫õÂèÇ‰∏éËÄÖÊèê‰æõ‰∫ÜÊúâ‰ª∑ÂÄºÁöÑÂèçÈ¶àÔºå‰ª•Â¢ûÂº∫ÂèôËø∞ÊÄßÂÖ®Â±ÄËß£Èáä„ÄÇËøôÂèçËøáÊù•ÂèàÊåáÂØº‰∫ÜÊó¢ÂÄºÂæó‰ø°ËµñÂèàÂèØÊìç‰ΩúÁöÑÂÅ•Â∫∑‰ø°ÊÅØÂ≠¶Á≥ªÁªüÁöÑËÆæËÆ°„ÄÇ

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

ÊëòË¶ÅÔºöÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) Âíå‰æãË°åÊñá‰ª∂Ë®òÈåÑÂØ¶ÂãôÂú®ÁóÖÊÇ£ÁöÑÊó•Â∏∏ÁÖßË≠∑‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÊèê‰æõÂÅ•Â∫∑„ÄÅË®∫Êñ∑ÂíåÊ≤ªÁôÇÁöÑÊï¥È´îÁ¥ÄÈåÑ„ÄÇÁÑ∂ËÄåÔºåË§áÈõú‰∏îÂÜóÈï∑ÁöÑ EHR ÊïòËø∞ÊúÉËÆìÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖË∂ÖËºâÔºåÊúâË®∫Êñ∑‰∏çÊ∫ñÁ¢∫ÁöÑÈ¢®Èö™„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂÖ∂Âú®ÂêÑÁ®ÆË™ûË®Ä‰ªªÂãô‰∏äÁöÑÊΩõÂäõÔºå‰ΩÜÂÖ∂Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÊáâÁî®ÈúÄË¶ÅÁ¢∫‰øùÂ∞áË®∫Êñ∑ÈåØË™§ÈôçÂà∞ÊúÄ‰ΩéÔºå‰∏¶Èò≤Ê≠¢ÁóÖÊÇ£ÂèóÂà∞ÂÇ∑ÂÆ≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ¶ÇËø∞‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéÊï¥ÂêàÈÜ´Â≠∏Áü•Ë≠òÂúñË≠ú (KG) Âíå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂúñË≠úÊ®°ÂûãÔºöDr.KnowsÔºàÈùàÊÑü‰æÜËá™Ëá®Â∫äË®∫Êñ∑Êé®ÁêÜÈÅéÁ®ãÔºâÔºå‰æÜÂ¢ûÂº∑ LLM Âú®Ëá™ÂãïÂåñË®∫Êñ∑Áî¢ÁîüÈ†òÂüüÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂæûÁæéÂúãÂúãÂÆ∂ÈÜ´Â≠∏ÂúñÊõ∏È§®ÁöÑÁµ±‰∏ÄÈÜ´Â≠∏Ë™ûË®ÄÁ≥ªÁµ± (UMLS) ‰∏≠Ë°çÁîüÂá∫ KGÔºåÈÄôÊòØ‰∏ÄÂÄãÂº∑Â§ßÁöÑÁîüÁâ©ÈÜ´Â≠∏Áü•Ë≠òÂÑ≤Â≠òÂ∫´„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂê¶ÂÆö‰∫ÜÈ†êÂÖàË®ìÁ∑¥ÁöÑÈúÄË¶ÅÔºåËÄåÊòØÂ∞á KG ‰ΩúÁÇ∫ËºîÂä©Â∑•ÂÖ∑ÔºåÂçîÂä©Ëß£ÈáãÂíåÁ∏ΩÁµêË§áÈõúÁöÑÈÜ´Â≠∏Ê¶ÇÂøµ„ÄÇ‰ΩøÁî®ÁúüÂØ¶‰∏ñÁïåÁöÑÈÜ´Èô¢Ë≥áÊñôÈõÜÔºåÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÂ∞á LLM Ëàá KG ÁµêÂêàÁöÑÂª∫Ë≠∞ÊñπÊ≥ïÊúâÊΩõÂäõÊèêÈ´òËá™ÂãïÂåñË®∫Êñ∑Áî¢ÁîüÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÊ¢ùÂèØËß£ÈáãÁöÑË®∫Êñ∑ÈÄîÂæëÔºåËÆìÊàëÂÄëÊõ¥Êé•ËøëÂØ¶Áèæ AI Â¢ûÂº∑ÁöÑË®∫Êñ∑Ê±∫Á≠ñÊîØÊè¥Á≥ªÁµ±„ÄÇ

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÁî®ÊñºË®∫Êñ∑ËÜùÈ™®ÈóúÁØÄÁÇé (OA) ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãÂõ†ÂÖ∂Áº∫‰πèÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßËÄåÂèóÂà∞ÊâπË©ïÔºåÂÑòÁÆ°ÂÆÉÂÄëÈÅîÂà∞‰∫ÜÈ°û‰ººÈÜ´Â≠∏Â∞àÂÆ∂ÁöÑË°®Áèæ„ÄÇÈÄôÁ®Æ‰∏çÈÄèÊòéÊÄß‰ΩøÂæóÂÆÉÂÄëÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠Èõ£‰ª•Ë¢´‰ø°‰ªª„ÄÇÊúÄËøëÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÂ∞àÈñÄÊäÄË°ìÔºåÂÆÉËÉΩÈÄèÈÅéÊè≠Á§∫È†êÊ∏¨ÁöÑÊé®Â∞éÊñπÂºè‰æÜÊèê‰æõÂ∞çÊ®°ÂûãÈ†êÊ∏¨ÁöÑ‰ø°ÂøÉÔºåÂæûËÄå‰øÉÈÄ≤Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰ΩøÁî® AI Á≥ªÁµ±„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜÈáùÂ∞çËÜùÈ™®ÈóúÁØÄÁÇéË®∫Êñ∑ÊâÄ‰ΩøÁî®ÁöÑ XAI ÊäÄË°ìÁöÑÁ¨¨‰∏Ä‰ªΩË™øÊü•„ÄÇXAI ÊäÄË°ìÂæûÂÖ©ÂÄãËßíÂ∫¶ÈÄ≤Ë°åË®éË´ñÔºöË≥áÊñôÂèØËß£ÈáãÊÄßÂíåÊ®°ÂûãÂèØËß£ÈáãÊÄß„ÄÇÊú¨ÊñáÁöÑÁõÆÁöÑÊòØÊèê‰æõÂ∞ç XAI Âú®Êõ¥ÂèØÈù†ÁöÑËÜùÈ™®ÈóúÁØÄÁÇéË®∫Êñ∑ÊñπÊ≥ï‰∏≠ÁöÑÊΩõÂäõÁöÑÂØ∂Ë≤¥Ë¶ãËß£Ôºå‰∏¶ÈºìÂãµÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠Êé°Áî®ÂÆÉ„ÄÇ

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

ÊëòË¶ÅÔºöÊúÄËøëÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®ÈÄ≤Â±ïÈ°ØÁ§∫Âá∫‰ª§‰∫∫Èõ£‰ª•ÁΩÆ‰ø°ÁöÑÊâøË´æÔºåÂú®Ë®∫Êñ∑ÂíåÁñæÁóÖÈ†êÂæåÊñπÈù¢Ë∂ÖË∂ä‰∫∫È°ûË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÈö®Ëëó‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÁöÑÊó•ÁõäË§áÈõúÔºå‰∫∫ÂÄëÂ∞çÂÖ∂‰∏çÈÄèÊòéÊÄß„ÄÅÊΩõÂú®ÂÅèÂ∑ÆÂíåÂ∞çÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±ÇÊÑüÂà∞ÊìîÊÜÇ„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øù‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁµ±ÁöÑ‰ø°‰ªªÂíåÂèØÈù†ÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®Ëá®Â∫äÈ¢®Èö™È†êÊ∏¨Ê®°Âûã‰∏≠ÔºåÂèØËß£ÈáãÊÄßËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇÂèØËß£ÈáãÊÄßÈÄöÂ∏∏Ë¢´Á®±ÁÇ∫‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁµ±Êèê‰æõÂÖ∂Ê±∫Á≠ñÈÇèËºØÊàñÊ±∫Á≠ñÊú¨Ë∫´Â∞ç‰∫∫È°ûÂà©ÁõäÁõ∏ÈóúËÄÖÁöÑÂº∑ÊúâÂäõËß£ÈáãÁöÑËÉΩÂäõ„ÄÇÂú®Ëá®Â∫äÈ¢®Èö™È†êÊ∏¨‰∏≠ÔºåÂèØËß£ÈáãÊÄßÁöÑÂÖ∂‰ªñÊñπÈù¢ÔºåÂ¶ÇÂÖ¨Âπ≥ÊÄß„ÄÅÂÅèË¶ã„ÄÅ‰ø°‰ªªÂíåÈÄèÊòéÂ∫¶Ôºå‰πü‰ª£Ë°®‰∫ÜË∂ÖË∂äÂèØËß£ÈáãÊÄßÁöÑÈáçË¶ÅÊ¶ÇÂøµ„ÄÇÂú®Êú¨Ê¨°ÂØ©Êü•‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄô‰∫õÊ¶ÇÂøµ‰πãÈñìÁöÑÈóú‰øÇÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁ∂ìÂ∏∏‰∏ÄËµ∑Êàñ‰∫íÊèõ‰ΩøÁî®„ÄÇÊú¨ÂØ©Êü•ÈÇÑË®éË´ñ‰∫ÜÁÇ∫Ëá®Â∫äÈ¢®Èö™È†êÊ∏¨ÈñãÁôºÂèØËß£ÈáãÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂº∑Ë™ø‰∫ÜÂú®Ëá®Â∫äÂØ¶Ë∏ê‰∏≠Â∞çÂ§öÁ®ÆÂ∏∏Ë¶ãÊ®°ÂºèÈÄ≤Ë°åÂÆöÈáèÂíåËá®Â∫äË©ï‰º∞ÂíåÈ©óË≠âÁöÑÈáçË¶ÅÊÄß„ÄÇÂÆÉÂº∑Ë™ø‰∫ÜÂ§ñÈÉ®È©óË≠âÂíåÂ§öÊ®£ÂåñÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁõ∏ÁµêÂêàÁöÑÂøÖË¶ÅÊÄßÔºå‰ª•Â¢ûÂº∑‰ø°‰ªªÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÊé°Áî®Âö¥Ê†ºÁöÑÊ∏¨Ë©¶Ôºå‰æãÂ¶Ç‰ΩøÁî®ÂÖ∑ÊúâÂ∑≤Áü•ÁîüÊàêÂõ†Á¥†ÁöÑÂêàÊàêÊï∏ÊìöÈõÜÔºåÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÂèØÈù†ÊÄß„ÄÇÈñãÊîæÁç≤ÂèñÂíå‰ª£Á¢ºÂÖ±‰∫´Ë≥áÊ∫êÂ∞çÊñºÈÄèÊòéÂ∫¶ÂíåÂèØÈáçË§áÊÄßËá≥ÈóúÈáçË¶ÅÔºåÂæûËÄå‰øÉÈÄ≤ÂèØËß£ÈáãÁ†îÁ©∂ÁöÑÂ¢ûÈï∑ÂíåÂèØ‰ø°Â∫¶„ÄÇÂÑòÁÆ°Â≠òÂú®ÊåëÊà∞Ôºå‰ΩÜÂæûËá®Â∫äÈÜ´ÁîüÂà∞ÈñãÁôº‰∫∫Âì°ÔºåÊé°Áî®Á´ØÂà∞Á´ØÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÂ∞çÊñºËá®Â∫äÈ¢®Èö™È†êÊ∏¨ÁöÑÊàêÂäüËá≥ÈóúÈáçË¶Å„ÄÇ

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A Gonz√°lez, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, Ir√®ne Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor Cerd√° Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, Llu√≠s Donoso-Bach, Luis Mart√≠-Bonmat√≠, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, M√≥nica Cano Abad√≠a, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver D√≠az, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna Auss√≥, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, X√®nia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

ÊëòË¶ÅÔºöÂÑòÁÆ°Âú®ÈÜ´Â≠∏ÂíåÈÜ´ÁôÇ‰øùÂÅ•ÊñπÈù¢ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊúâÈáçÂ§ßÁöÑÈÄ≤Â±ïÔºå‰ΩÜ AI ÊäÄË°ìÁöÑÈÉ®ÁΩ≤ÂíåÊé°Áî®Âú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÂØ¶Âãô‰∏≠‰ªçÁÑ∂ÊúâÈôê„ÄÇËøëÂπ¥‰æÜÔºå‰∫∫ÂÄëÂ∞çÊñºËàáÈÜ´ÁôÇ AI Áõ∏ÈóúÁöÑÊäÄË°ì„ÄÅËá®Â∫ä„ÄÅÂÄ´ÁêÜÂíåÊ≥ïÂæãÈ¢®Èö™ÊèêÂá∫‰∫ÜÁñëÊÖÆ„ÄÇÁÇ∫‰∫ÜÂ¢ûÂä†ÁèæÂØ¶‰∏ñÁïåÁöÑÊé°Áî®ÁéáÔºåÈÜ´ÁôÇ AI Â∑•ÂÖ∑ÂøÖÈ†àÁç≤ÂæóÊÇ£ËÄÖ„ÄÅËá®Â∫äÈÜ´Áîü„ÄÅÈÜ´ÁôÇÊ©üÊßãÂíåÁï∂Â±ÄÁöÑ‰ø°‰ªªÂíåÊé•Âèó„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂ∞á FUTURE-AI ÊåáÂçóÊèèËø∞ÁÇ∫ÊåáÂ∞éÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂèØ‰ø°Ë≥¥ AI Â∑•ÂÖ∑ÈñãÁôºÂíåÈÉ®ÁΩ≤ÁöÑÁ¨¨‰∏ÄÂÄãÂúãÈöõÂÖ±Ë≠òÊû∂Êßã„ÄÇFUTURE-AI ËÅØÁõüÊàêÁ´ãÊñº 2021 Âπ¥ÔºåÁõÆÂâçÁî±‰æÜËá™ 51 ÂÄãÂúãÂÆ∂ÁöÑ 118 ‰ΩçË∑®È†òÂüüÂ∞àÂÆ∂ÁµÑÊàêÔºå‰ª£Ë°®ÊâÄÊúâÊ¥≤ÔºåÂåÖÊã¨ AI ÁßëÂ≠∏ÂÆ∂„ÄÅËá®Â∫äÈÜ´Áîü„ÄÅÂÄ´ÁêÜÂ≠∏ÂÆ∂ÂíåÁ§æÊúÉÁßëÂ≠∏ÂÆ∂„ÄÇÂú®ÂÖ©Âπ¥ÁöÑÊôÇÈñìË£°ÔºåË©≤ËÅØÁõüÈÄöÈÅé‰∏ÄÂÄãÂèçË¶ÜÈÅãÁÆóÁöÑÈÅéÁ®ãÂÆöÁæ©‰∫ÜÂèØ‰ø°Ë≥¥ AI ÁöÑÊåáÂ∞éÂéüÂâáÂíåÊúÄ‰Ω≥ÂØ¶ÂãôÔºåÂåÖÊã¨Ê∑±ÂÖ•ÁöÑÊñáÁçªÂõûÈ°ß„ÄÅ‰øÆÊîπÂæåÁöÑÂæ∑ÁàæËè≤Ë™øÊü•ÂíåÁ∑ö‰∏äÂÖ±Ë≠òÊúÉË≠∞„ÄÇFUTURE-AI Êû∂ÊßãÊòØÂü∫ÊñºÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÂèØ‰ø°Ë≥¥ AI ÁöÑ 6 È†ÖÊåáÂ∞éÂéüÂâáÂª∫Á´ãÁöÑÔºåÂç≥ÂÖ¨Âπ≥ÊÄß„ÄÅÊôÆÈÅçÊÄß„ÄÅÂèØËøΩÊ∫ØÊÄß„ÄÅÂèØÁî®ÊÄß„ÄÅÁ©©ÂÅ•ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÈÄöÈÅéÂÖ±Ë≠òÔºåÂÆöÁæ©‰∫Ü‰∏ÄÁµÑ 28 È†ÖÊúÄ‰Ω≥ÂØ¶ÂãôÔºåÊ∂µËìãÊäÄË°ì„ÄÅËá®Â∫ä„ÄÅÊ≥ïÂæãÂíåÁ§æÊúÉÂÄ´ÁêÜÂ±§Èù¢„ÄÇÂª∫Ë≠∞Ê∂µËìã‰∫ÜÈÜ´ÁôÇ AI ÁöÑÊï¥ÂÄãÁîüÂëΩÈÄ±ÊúüÔºåÂæûË®≠Ë®à„ÄÅÈñãÁôºÂíåÈ©óË≠âÂà∞Ê≥ïË¶è„ÄÅÈÉ®ÁΩ≤ÂíåÁõ£Êéß„ÄÇFUTURE-AI ÊòØ‰∏ÄÂÄãÂü∫ÊñºÈ¢®Èö™„ÄÅÁÑ°ÂÅáË®≠ÁöÑÊåáÂçóÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁµêÊßãÂåñÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂª∫ÊßãÂ∞áÂú®ÁèæÂØ¶‰∏ñÁïåÂØ¶Âãô‰∏≠ÂèóÂà∞‰ø°‰ªª„ÄÅÈÉ®ÁΩ≤ÂíåÊé°Áî®ÁöÑÈÜ´ÁôÇ AI Â∑•ÂÖ∑„ÄÇÈºìÂãµÁ†îÁ©∂‰∫∫Âì°Âú®Ê¶ÇÂøµÈ©óË≠âÈöéÊÆµËÄÉÊÖÆÈÄô‰∫õÂª∫Ë≠∞Ôºå‰ª•‰øÉÈÄ≤Êú™‰æÜÂ∞áÈÜ´ÁôÇ AI ËΩâÂåñÁÇ∫Ëá®Â∫äÂØ¶Âãô„ÄÇ


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-18**|**Are AI Detectors Good Enough? A Survey on Quality of Datasets With Machine-Generated Texts**|German Gritsai et.al.|[2410.14677v1](http://arxiv.org/abs/2410.14677v1)|null|
|**2024-10-18**|**SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment**|Qin Liu et.al.|[2410.14676v1](http://arxiv.org/abs/2410.14676v1)|null|
|**2024-10-18**|**Enhancing Large Language Models' Situated Faithfulness to External Contexts**|Yukun Huang et.al.|[2410.14675v1](http://arxiv.org/abs/2410.14675v1)|[link](https://github.com/kkkevinkkkkk/situated_faithfulness)|
|**2024-10-18**|**BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities**|Shaozhe Hao et.al.|[2410.14672v1](http://arxiv.org/abs/2410.14672v1)|[link](https://github.com/haoosz/BiGR)|
|**2024-10-18**|**NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples**|Baiqi Li et.al.|[2410.14669v1](http://arxiv.org/abs/2410.14669v1)|null|
|**2024-10-18**|**MiCEval: Unveiling Multimodal Chain of Thought's Quality via Image Description and Reasoning Steps**|Xiongtao Zhou et.al.|[2410.14668v1](http://arxiv.org/abs/2410.14668v1)|[link](https://github.com/alenai97/miceval)|
|**2024-10-18**|**DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie Character-Aware Discourse Graph**|Maitreya Prafulla Chitale et.al.|[2410.14666v1](http://arxiv.org/abs/2410.14666v1)|null|
|**2024-10-18**|**Real-time Fake News from Adversarial Feedback**|Sanxing Chen et.al.|[2410.14651v1](http://arxiv.org/abs/2410.14651v1)|null|
|**2024-10-18**|**Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs**|Runchu Tian et.al.|[2410.14641v1](http://arxiv.org/abs/2410.14641v1)|[link](https://github.com/Rachum-thu/LongPiBench)|
|**2024-10-18**|**GenEOL: Harnessing the Generative Power of LLMs for Training-Free Sentence Embeddings**|Raghuveer Thirukovalluru et.al.|[2410.14635v1](http://arxiv.org/abs/2410.14635v1)|null|
|**2024-10-18**|**Diverging Preferences: When do Annotators Disagree and do Models Know?**|Michael JQ Zhang et.al.|[2410.14632v1](http://arxiv.org/abs/2410.14632v1)|null|
|**2024-10-18**|**On the Regularization of Learnable Embeddings for Time Series Processing**|Luca Butera et.al.|[2410.14630v1](http://arxiv.org/abs/2410.14630v1)|null|
|**2024-10-18**|**CELI: Controller-Embedded Language Model Interactions**|Jan-Samuel Wagner et.al.|[2410.14627v1](http://arxiv.org/abs/2410.14627v1)|null|
|**2024-10-18**|**You Shall Know a Tool by the Traces it Leaves: The Predictability of Sentiment Analysis Tools**|Daniel Baumartz et.al.|[2410.14626v1](http://arxiv.org/abs/2410.14626v1)|null|
|**2024-10-18**|**Benchmarking Deep Reinforcement Learning for Navigation in Denied Sensor Environments**|Mariusz Wisniewski et.al.|[2410.14616v1](http://arxiv.org/abs/2410.14616v1)|null|
|**2024-10-18**|**Asymptotically Optimal Change Detection for Unnormalized Pre- and Post-Change Distributions**|Arman Adibi et.al.|[2410.14615v1](http://arxiv.org/abs/2410.14615v1)|null|
|**2024-10-18**|**DiSCo Meets LLMs: A Unified Approach for Sparse Retrieval and Contextual Distillation in Conversational Search**|Simon Lupart et.al.|[2410.14609v1](http://arxiv.org/abs/2410.14609v1)|null|
|**2024-10-18**|**Streaming Deep Reinforcement Learning Finally Works**|Mohamed Elsayed et.al.|[2410.14606v1](http://arxiv.org/abs/2410.14606v1)|null|
|**2024-10-18**|**How Does Data Diversity Shape the Weight Landscape of Neural Networks?**|Yang Ba et.al.|[2410.14602v1](http://arxiv.org/abs/2410.14602v1)|null|
|**2024-10-18**|**Teaching Models to Balance Resisting and Accepting Persuasion**|Elias Stengel-Eskin et.al.|[2410.14596v1](http://arxiv.org/abs/2410.14596v1)|[link](https://github.com/esteng/persuasion_balanced_training)|
|**2024-10-18**|**Toolshed: Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and Tool Knowledge Bases**|Elias Lumer et.al.|[2410.14594v1](http://arxiv.org/abs/2410.14594v1)|null|
|**2024-10-18**|**Temporal Fair Division of Indivisible Items**|Edith Elkind et.al.|[2410.14593v1](http://arxiv.org/abs/2410.14593v1)|null|
|**2024-10-18**|**Dialetto, ma Quanto Dialetto? Transcribing and Evaluating Dialects on a Continuum**|Ryan Soh-Eun Shim et.al.|[2410.14589v1](http://arxiv.org/abs/2410.14589v1)|null|
|**2024-10-18**|**Neural Combinatorial Clustered Bandits for Recommendation Systems**|Baran Atalar et.al.|[2410.14586v1](http://arxiv.org/abs/2410.14586v1)|null|
|**2024-10-18**|**Do LLMs estimate uncertainty well in instruction-following?**|Juyeon Heo et.al.|[2410.14582v1](http://arxiv.org/abs/2410.14582v1)|null|
|**2024-10-18**|**Optimizing Attention with Mirror Descent: Generalized Max-Margin Token Selection**|Aaron Alvarado Kristanto Julistiono et.al.|[2410.14581v1](http://arxiv.org/abs/2410.14581v1)|null|
|**2024-10-18**|**Towards Unsupervised Validation of Anomaly-Detection Models**|Lihi Idan et.al.|[2410.14579v1](http://arxiv.org/abs/2410.14579v1)|null|
|**2024-10-18**|**Large Language Models Are Overparameterized Text Encoders**|Thennal D K et.al.|[2410.14578v1](http://arxiv.org/abs/2410.14578v1)|null|
|**2024-10-18**|**MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts**|Rachel S. Y. Teo et.al.|[2410.14574v1](http://arxiv.org/abs/2410.14574v1)|[link](https://github.com/rachtsy/momentumsmoe)|
|**2024-10-18**|**Building Trust in Black-box Optimization: A Comprehensive Framework for Explainability**|Nazanin Nezami et.al.|[2410.14573v1](http://arxiv.org/abs/2410.14573v1)|null|
|**2024-10-18**|**TransBox: EL++-closed Ontology Embedding**|Hui Yang et.al.|[2410.14571v1](http://arxiv.org/abs/2410.14571v1)|null|
|**2024-10-18**|**When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs**|Hanna Kim et.al.|[2410.14569v1](http://arxiv.org/abs/2410.14569v1)|null|
|**2024-10-18**|**RAG-ConfusionQA: A Benchmark for Evaluating LLMs on Confusing Questions**|Zhiyuan Peng et.al.|[2410.14567v1](http://arxiv.org/abs/2410.14567v1)|null|
|**2024-10-18**|**Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization**|Frederic Kirstein et.al.|[2410.14545v1](http://arxiv.org/abs/2410.14545v1)|[link](https://github.com/FKIRSTE/emnlp2024-personalized-meeting-sum)|
|**2024-10-18**|**Less is More: Selective Reduction of CT Data for Self-Supervised Pre-Training of Deep Learning Models with Contrastive Learning Improves Downstream Classification Performance**|Daniel Wolf et.al.|[2410.14524v1](http://arxiv.org/abs/2410.14524v1)|[link](https://github.com/Wolfda95/Less_is_More)|
|**2024-10-18**|**Do LLMs "know" internally when they follow instructions?**|Juyeon Heo et.al.|[2410.14516v1](http://arxiv.org/abs/2410.14516v1)|null|
|**2024-10-18**|**Efficient Annotator Reliability Assessment and Sample Weighting for Knowledge-Based Misinformation Detection on Social Media**|Owen Cook et.al.|[2410.14515v1](http://arxiv.org/abs/2410.14515v1)|[link](https://github.com/minieggz/ruc-misinfo)|
|**2024-10-18**|**LEAD: Latent Realignment for Human Motion Diffusion**|Nefeli Andreou et.al.|[2410.14508v1](http://arxiv.org/abs/2410.14508v1)|null|
|**2024-10-18**|**SignAttention: On the Interpretability of Transformer Models for Sign Language Translation**|Pedro Alejandro Dal Bianco et.al.|[2410.14506v1](http://arxiv.org/abs/2410.14506v1)|null|
|**2024-10-18**|**ANT: Adaptive Noise Schedule for Time Series Diffusion Models**|Seunghan Lee et.al.|[2410.14488v1](http://arxiv.org/abs/2410.14488v1)|[link](https://github.com/seunghan96/ant)|
|**2024-10-18**|**DRL Optimization Trajectory Generation via Wireless Network Intent-Guided Diffusion Models for Optimizing Resource Allocation**|Junjie Wu et.al.|[2410.14481v1](http://arxiv.org/abs/2410.14481v1)|null|
|**2024-10-18**|**Combining Entropy and Matrix Nuclear Norm for Enhanced Evaluation of Language Models**|James Vo et.al.|[2410.14480v1](http://arxiv.org/abs/2410.14480v1)|null|
|**2024-10-18**|**How Do Training Methods Influence the Utilization of Vision Models?**|Paul Gavrikov et.al.|[2410.14470v1](http://arxiv.org/abs/2410.14470v1)|null|
|**2024-10-18**|**The Propensity for Density in Feed-forward Models**|Nandi Schoots et.al.|[2410.14461v1](http://arxiv.org/abs/2410.14461v1)|null|
|**2024-10-18**|**Toward Generalizing Visual Brain Decoding to Unseen Subjects**|Xiangtao Kong et.al.|[2410.14445v1](http://arxiv.org/abs/2410.14445v1)|[link](https://github.com/xiangtaokong/tgbd)|
|**2024-10-18**|**A Systematic Study of Cross-Layer KV Sharing for Efficient LLM Inference**|You Wu et.al.|[2410.14442v1](http://arxiv.org/abs/2410.14442v1)|[link](https://github.com/whyNLP/LCKV)|
|**2024-10-18**|**Learning to refine domain knowledge for biological network inference**|Peiwen Li et.al.|[2410.14436v1](http://arxiv.org/abs/2410.14436v1)|null|
|**2024-10-18**|**FashionR2R: Texture-preserving Rendered-to-Real Image Translation with Diffusion Models**|Rui Hu et.al.|[2410.14429v1](http://arxiv.org/abs/2410.14429v1)|null|
|**2024-10-18**|**Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation**|Shuai Zhao et.al.|[2410.14425v1](http://arxiv.org/abs/2410.14425v1)|[link](https://github.com/shuaizhao95/Unlearning)|
|**2024-10-18**|**Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion**|Denitsa Saynova et.al.|[2410.14405v1](http://arxiv.org/abs/2410.14405v1)|null|
|**2024-10-18**|**SylloBio-NLI: Evaluating Large Language Models on Biomedical Syllogistic Reasoning**|Magdalena Wysocka et.al.|[2410.14399v1](http://arxiv.org/abs/2410.14399v1)|null|
|**2024-10-18**|**Generative AI, Pragmatics, and Authenticity in Second Language Learning**|Robert Godwin-Jones` et.al.|[2410.14395v1](http://arxiv.org/abs/2410.14395v1)|null|
|**2024-10-18**|**Debug Smarter, Not Harder: AI Agents for Error Resolution in Computational Notebooks**|Konstantin Grotov et.al.|[2410.14393v1](http://arxiv.org/abs/2410.14393v1)|null|
|**2024-10-18**|**Analyzing Context Utilization of LLMs in Document-Level Translation**|Wafaa Mohammed et.al.|[2410.14391v1](http://arxiv.org/abs/2410.14391v1)|null|
|**2024-10-18**|**SurgeryV2: Bridging the Gap Between Model Merging and Multi-Task Learning with Deep Representation Surgery**|Enneng Yang et.al.|[2410.14389v1](http://arxiv.org/abs/2410.14389v1)|[link](https://github.com/ennengyang/surgeryv2)|
|**2024-10-18**|**How Do Multilingual Models Remember? Investigating Multilingual Factual Recall Mechanisms**|Constanza Fierro et.al.|[2410.14387v1](http://arxiv.org/abs/2410.14387v1)|null|
|**2024-10-18**|**Fine-Tuning Pre-trained Language Models for Robust Causal Representation Learning**|Jialin Yu et.al.|[2410.14375v1](http://arxiv.org/abs/2410.14375v1)|null|
|**2024-10-18**|**CoMAL: Collaborative Multi-Agent Large Language Models for Mixed-Autonomy Traffic**|Huaiyuan Yao et.al.|[2410.14368v1](http://arxiv.org/abs/2410.14368v1)|[link](https://github.com/hyan-yao/comal)|
|**2024-10-18**|**Efficiently Computing Susceptibility to Context in Language Models**|Tianyu Liu et.al.|[2410.14361v1](http://arxiv.org/abs/2410.14361v1)|null|
|**2024-10-18**|**A Scientific Machine Learning Approach for Predicting and Forecasting Battery Degradation in Electric Vehicles**|Sharv Murgai et.al.|[2410.14347v1](http://arxiv.org/abs/2410.14347v1)|null|
|**2024-10-18**|**Critical Questions Generation: Motivation and Challenges**|Blanca Calvo Figueras et.al.|[2410.14335v1](http://arxiv.org/abs/2410.14335v1)|[link](https://github.com/hitz-zentroa/critical_questions_generation)|
|**2024-10-18**|**LoGU: Long-form Generation with Uncertainty Expressions**|Ruihan Yang et.al.|[2410.14309v1](http://arxiv.org/abs/2410.14309v1)|null|
|**2024-10-18**|**SwaQuAD-24: QA Benchmark Dataset in Swahili**|Alfred Malengo Kondoro et.al.|[2410.14289v1](http://arxiv.org/abs/2410.14289v1)|null|
|**2024-10-18**|**EcomEdit: An Automated E-commerce Knowledge Editing Framework for Enhanced Product and Purchase Intention Understanding**|Ching Ming Samuel Lau et.al.|[2410.14276v1](http://arxiv.org/abs/2410.14276v1)|null|
|**2024-10-18**|**REEF: Representation Encoding Fingerprints for Large Language Models**|Jie Zhang et.al.|[2410.14273v1](http://arxiv.org/abs/2410.14273v1)|[link](https://github.com/tmylla/reef)|
|**2024-10-18**|**MoDification: Mixture of Depths Made Easy**|Chen Zhang et.al.|[2410.14268v1](http://arxiv.org/abs/2410.14268v1)|null|
|**2024-10-18**|**Good Parenting is all you need -- Multi-agentic LLM Hallucination Mitigation**|Edward et.al.|[2410.14262v1](http://arxiv.org/abs/2410.14262v1)|null|
|**2024-10-18**|**Beyond Binary: Towards Fine-Grained LLM-Generated Text Detection via Role Recognition and Involvement Measurement**|Zihao Cheng et.al.|[2410.14259v1](http://arxiv.org/abs/2410.14259v1)|null|
|**2024-10-18**|**Revisiting SLO and Goodput Metrics in LLM Serving**|Zhibin Wang et.al.|[2410.14257v1](http://arxiv.org/abs/2410.14257v1)|null|
|**2024-10-18**|**Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas**|Xiang Hu et.al.|[2410.14255v1](http://arxiv.org/abs/2410.14255v1)|null|
|**2024-10-18**|**Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation**|Shuo Tang et.al.|[2410.14251v1](http://arxiv.org/abs/2410.14251v1)|null|
|**2024-10-18**|**Addressing Blind Guessing: Calibration of Selection Bias in Multiple-Choice Question Answering by Video Language Models**|Olga Loginova et.al.|[2410.14248v1](http://arxiv.org/abs/2410.14248v1)|null|
|**2024-10-18**|**Almost-Linear RNNs Yield Highly Interpretable Symbolic Codes in Dynamical Systems Reconstruction**|Manuel Brenner et.al.|[2410.14240v1](http://arxiv.org/abs/2410.14240v1)|[link](https://github.com/DurstewitzLab/ALRNN-DSR)|
|**2024-10-18**|**A Novel Method to Metigate Demographic and Expert Bias in ICD Coding with Causal Inference**|Bin Zhang et.al.|[2410.14236v1](http://arxiv.org/abs/2410.14236v1)|null|
|**2024-10-18**|**Towards Robust Knowledge Representations in Multilingual LLMs for Equivalence and Inheritance based Consistent Reasoning**|Gaurav Arora et.al.|[2410.14235v1](http://arxiv.org/abs/2410.14235v1)|null|
|**2024-10-18**|**Unveiling Large Language Models Generated Texts: A Multi-Level Fine-Grained Detection Framework**|Zhen Tao et.al.|[2410.14231v1](http://arxiv.org/abs/2410.14231v1)|null|
|**2024-10-18**|**Few-Shot Joint Multimodal Entity-Relation Extraction via Knowledge-Enhanced Cross-modal Prompt Model**|Li Yuan et.al.|[2410.14225v1](http://arxiv.org/abs/2410.14225v1)|null|
|**2024-10-18**|**Formal Explanations for Neuro-Symbolic AI**|Sushmita Paul et.al.|[2410.14219v1](http://arxiv.org/abs/2410.14219v1)|null|
|**2024-10-18**|**Paths-over-Graph: Knowledge Graph Enpowered Large Language Model Reasoning**|Xingyu Tan et.al.|[2410.14211v1](http://arxiv.org/abs/2410.14211v1)|null|
|**2024-10-18**|**Montessori-Instruct: Generate Influential Training Data Tailored for Student Learning**|Xiaochuan Li et.al.|[2410.14208v1](http://arxiv.org/abs/2410.14208v1)|[link](https://github.com/cxcscmu/montessori-instruct)|
|**2024-10-18**|**MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations**|Vishal Vivek Saley et.al.|[2410.14204v1](http://arxiv.org/abs/2410.14204v1)|null|
|**2024-10-18**|**Rationale Behind Essay Scores: Enhancing S-LLM's Multi-Trait Essay Scoring with Rationale Generated by LLMs**|SeongYeub Chu et.al.|[2410.14202v1](http://arxiv.org/abs/2410.14202v1)|null|
|**2024-10-18**|**E3D-GPT: Enhanced 3D Visual Foundation for Medical Vision-Language Model**|Haoran Lai et.al.|[2410.14200v1](http://arxiv.org/abs/2410.14200v1)|null|
|**2024-10-18**|**Supervised Chain of Thought**|Xiang Zhang et.al.|[2410.14198v1](http://arxiv.org/abs/2410.14198v1)|null|
|**2024-10-18**|**Speciesism in Natural Language Processing Research**|Masashi Takeshita et.al.|[2410.14194v1](http://arxiv.org/abs/2410.14194v1)|null|
|**2024-10-18**|**MetaAlign: Align Large Language Models with Diverse Preferences during Inference Time**|Mozhi Zhang et.al.|[2410.14184v1](http://arxiv.org/abs/2410.14184v1)|[link](https://github.com/Jihuai-wpy/MetaAlign)|
|**2024-10-18**|**LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs**|Yujun Zhou et.al.|[2410.14182v1](http://arxiv.org/abs/2410.14182v1)|null|
|**2024-10-18**|**XForecast: Evaluating Natural Language Explanations for Time Series Forecasting**|Taha Aksu et.al.|[2410.14180v1](http://arxiv.org/abs/2410.14180v1)|null|
|**2024-10-18**|**MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart Problems**|Zifeng Zhu et.al.|[2410.14179v1](http://arxiv.org/abs/2410.14179v1)|null|
|**2024-10-18**|**LLM The Genius Paradox: A Linguistic and Math Expert's Struggle with Simple Word-based Counting Problems**|Nan Xu et.al.|[2410.14166v1](http://arxiv.org/abs/2410.14166v1)|null|
|**2024-10-18**|**Automated Genre-Aware Article Scoring and Feedback Using Large Language Models**|Chihang Wang et.al.|[2410.14165v1](http://arxiv.org/abs/2410.14165v1)|null|
|**2024-10-18**|**Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning**|Jiacheng Ye et.al.|[2410.14157v1](http://arxiv.org/abs/2410.14157v1)|null|
|**2024-10-18**|**Towards Faithful Natural Language Explanations: A Study Using Activation Patching in Large Language Models**|Wei Jie Yeo et.al.|[2410.14155v1](http://arxiv.org/abs/2410.14155v1)|[link](https://github.com/wj210/causal-faithfulness)|
|**2024-10-18**|**RA-BLIP: Multimodal Adaptive Retrieval-Augmented Bootstrapping Language-Image Pre-training**|Muhe Ding et.al.|[2410.14154v1](http://arxiv.org/abs/2410.14154v1)|null|
|**2024-10-18**|**SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent**|Jiarui Ji et.al.|[2410.14152v1](http://arxiv.org/abs/2410.14152v1)|null|
|**2024-10-18**|**Utilizing Large Language Models for Event Deconstruction to Enhance Multimodal Aspect-Based Sentiment Analysis**|Xiaoyong Huang et.al.|[2410.14150v1](http://arxiv.org/abs/2410.14150v1)|null|
|**2024-10-18**|**Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in Vision-Language Alignment**|Chenhang Cui et.al.|[2410.14148v1](http://arxiv.org/abs/2410.14148v1)|null|
|**2024-10-18**|**CausalChat: Interactive Causal Model Development and Refinement Using Large Language Models**|Yanming Zhang et.al.|[2410.14146v1](http://arxiv.org/abs/2410.14146v1)|null|
|**2024-10-18**|**CAPE: A Chinese Dataset for Appraisal-based Emotional Generation using Large Language Models**|June M. Liu et.al.|[2410.14145v1](http://arxiv.org/abs/2410.14145v1)|null|
|**2024-10-18**|**A Lightweight Multi Aspect Controlled Text Generation Solution For Large Language Models**|Chenyang Zhang et.al.|[2410.14144v1](http://arxiv.org/abs/2410.14144v1)|null|

#### Abstracts
##### **Are AI Detectors Good Enough? A Survey on Quality of Datasets With Machine-Generated Texts**
2410.14677v1 by German Gritsai, Anastasia Voznyuk, Andrey Grabovoy, Yury Chekhovich

The rapid development of autoregressive Large Language Models (LLMs) has
significantly improved the quality of generated texts, necessitating reliable
machine-generated text detectors. A huge number of detectors and collections
with AI fragments have emerged, and several detection methods even showed
recognition quality up to 99.9% according to the target metrics in such
collections. However, the quality of such detectors tends to drop dramatically
in the wild, posing a question: Are detectors actually highly trustworthy or do
their high benchmark scores come from the poor quality of evaluation datasets?
In this paper, we emphasise the need for robust and qualitative methods for
evaluating generated data to be secure against bias and low generalising
ability of future model. We present a systematic review of datasets from
competitions dedicated to AI-generated content detection and propose methods
for evaluating the quality of datasets containing AI-generated fragments. In
addition, we discuss the possibility of using high-quality generated data to
achieve two goals: improving the training of detection models and improving the
training datasets themselves. Our contribution aims to facilitate a better
understanding of the dynamics between human and machine text, which will
ultimately support the integrity of information in an increasingly automated
world.

ÊëòË¶ÅÔºöÈö®ËëóËá™Ëø¥Ê≠∏Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÁôºÂ±ïÔºåÂ∑≤È°ØËëóÊèêÂçáÁîüÊàêÊñáÂ≠óÁöÑÂìÅË≥™ÔºåÂõ†Ê≠§ÊúâÂøÖË¶Å‰ΩøÁî®ÂèØÈù†ÁöÑÊ©üÂô®Áî¢ÁîüÁöÑÊñáÂ≠óÂÅµÊ∏¨Âô®„ÄÇÂ∑≤Âá∫ÁèæÂ§ßÈáèÂÅµÊ∏¨Âô®ËàáÂåÖÂê´ AI ÁâáÊÆµÁöÑÈõÜÂêàÔºåÊ†πÊìöÈÄô‰∫õÈõÜÂêà‰∏≠ÁöÑÁõÆÊ®ôÊåáÊ®ôÔºåÁîöËá≥ÊúâÂπæÁ®ÆÂÅµÊ∏¨ÊñπÊ≥ïÈ°ØÁ§∫Âá∫È´òÈÅî 99.9% ÁöÑËæ®Ë≠òÂìÅË≥™„ÄÇÁÑ∂ËÄåÔºåÊ≠§È°ûÂÅµÊ∏¨Âô®ÁöÑÂìÅË≥™Âú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÂæÄÂæÄÊúÉÂ§ßÂπÖ‰∏ãÈôçÔºåÈÄôÂºïÁôº‰∫Ü‰∏ÄÂÄãÂïèÈ°åÔºöÂÅµÊ∏¨Âô®ÂØ¶Èöõ‰∏äÊòØÂê¶È´òÂ∫¶ÂèØ‰ø°ÔºåÈÇÑÊòØÂÖ∂È´òÂü∫Ê∫ñÂàÜÊï∏‰æÜËá™ÊñºË©ï‰º∞Ë≥áÊñôÈõÜÁöÑÂìÅË≥™‰∏ç‰Ω≥ÔºüÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂº∑Ë™øÈúÄË¶ÅÁ©©ÂÅ•‰∏îÂÆöÊÄßÁöÑÊñπÊ≥ï‰æÜË©ï‰º∞ÁîüÊàêË≥áÊñôÔºå‰ª•Á¢∫‰øùÊú™‰æÜÊ®°Âûã‰∏çÊúÉÊúâÂÅèÂ∑Æ‰∏îÂÖ∑ÂÇô‰ΩéÊ≥õÂåñËÉΩÂäõ„ÄÇÊàëÂÄëÂ∞çÂ∞àÈñÄÁî®Êñº AI Áî¢ÁîüÁöÑÂÖßÂÆπÂÅµÊ∏¨ÁöÑÁ´∂Ë≥Ω‰∏≠ÊâÄ‰ΩøÁî®ÁöÑË≥áÊñôÈõÜÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÂõûÈ°ßÔºå‰∏¶ÊèêÂá∫Ë©ï‰º∞ÂåÖÂê´ AI Áî¢ÁîüÁöÑÁâáÊÆµÁöÑË≥áÊñôÈõÜÂìÅË≥™ÁöÑÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®éË´ñ‰∫Ü‰ΩøÁî®È´òÂìÅË≥™ÁîüÊàêË≥áÊñô‰æÜÈÅîÊàêÂÖ©ÂÄãÁõÆÊ®ôÁöÑÂèØËÉΩÊÄßÔºöÊîπÂñÑÂÅµÊ∏¨Ê®°ÂûãÁöÑË®ìÁ∑¥‰ª•ÂèäÊîπÂñÑË®ìÁ∑¥Ë≥áÊñôÈõÜÊú¨Ë∫´„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÊó®Âú®‰øÉÈÄ≤Â∞ç‰∫∫È°ûËàáÊ©üÂô®ÊñáÂ≠ó‰πãÈñìÂãïÊÖãÁöÑÊõ¥Ê∑±ÂÖ•‰∫ÜËß£ÔºåÈÄôÊúÄÁµÇÂ∞áÊîØÊåÅÂú®Êó•ÁõäËá™ÂãïÂåñÁöÑ‰∏ñÁïå‰∏≠Ë≥áË®äÁöÑÂÆåÊï¥ÊÄß„ÄÇ

##### **SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment**
2410.14676v1 by Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen

Existing preference alignment is a one-size-fits-all alignment mechanism,
where the part of the large language model (LLM) parametric knowledge with
non-preferred features is uniformly blocked to all the users. However, this
part of knowledge can be useful to advanced users whose expertise qualifies
them to handle these information. The one-size-fits-all alignment mechanism
undermines LLM's utility for these qualified users. To address this problem, we
propose SudoLM, a framework that lets LLMs learn access control over specific
parametric knowledge for users with different credentials via authorization
alignment. SudoLM allows authorized users to unlock their access to all the
parametric knowledge with an assigned SUDO key while blocking access to
non-qualified users. Experiments on two application scenarios demonstrate that
SudoLM effectively controls the user's access to the parametric knowledge and
maintains its general utility.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂÅèÂ•ΩÊØîÂ∞çÊòØ‰∏ÄÁ®Æ‰∏ÄÈ´îÈÅ©Áî®ÁöÑÊØîÂ∞çÊ©üÂà∂Ôºå
ÂÖ∂‰∏≠Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèÉÊï∏Áü•Ë≠òÁöÑÈÉ®ÂàÜÂÖ∑Êúâ
ÈùûÈ¶ñÈÅ∏ÂäüËÉΩÔºåÂ∞çÊâÄÊúâ‰ΩøÁî®ËÄÖÂùá‰∏ÄÂæãÂ∞ÅÈéñ„ÄÇÁÑ∂ËÄåÔºåÈÄô
ÈÉ®ÂàÜÁü•Ë≠òÂ∞çÂ∞àÂÆ∂‰ΩøÁî®ËÄÖ‰æÜË™™ÂèØËÉΩÂæàÊúâÁî®ÔºåÂõ†ÁÇ∫‰ªñÂÄëÁöÑÂ∞àÊ•≠Áü•Ë≠òÊúâË≥áÊ†º
ËôïÁêÜÈÄô‰∫õË≥áË®ä„ÄÇ‰∏ÄÈ´îÈÅ©Áî®ÁöÑÊØîÂ∞çÊ©üÂà∂ÊúÉÁ†¥Â£û LLM Â∞çÈÄô‰∫õÂêàÊ†º‰ΩøÁî®ËÄÖÁöÑÊïàÁî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄë
ÊèêÂá∫ SudoLMÔºå‰∏ÄÂÄãÊ°ÜÊû∂ÔºåËÆì LLM ÈÄèÈÅéÊéàÊ¨äÊØîÂ∞çÂ≠∏ÁøíÂ∞çÂÖ∑Êúâ‰∏çÂêåÊÜëË≠âÁöÑ‰ΩøÁî®ËÄÖÂ≠òÂèñÁâπÂÆö
ÂèÉÊï∏Áü•Ë≠òÁöÑÂ≠òÂèñÊéßÂà∂„ÄÇSudoLM ÂÖÅË®±ÊéàÊ¨ä‰ΩøÁî®ËÄÖ‰ΩøÁî®ÊåáÂÆöÁöÑ SUDO ÈáëÈë∞Ëß£Èéñ‰ªñÂÄëÂ∞çÊâÄÊúâ
ÂèÉÊï∏Áü•Ë≠òÁöÑÂ≠òÂèñÔºåÂêåÊôÇÂ∞ÅÈéñÈùûÂêàÊ†º‰ΩøÁî®ËÄÖÁöÑÂ≠òÂèñ„ÄÇÂú®ÂÖ©ÂÄãÊáâÁî®Â†¥ÊôØÁöÑÂØ¶È©ó‰∏≠Ë≠âÊòéÔºå
SudoLM ÊúâÊïàÂú∞ÊéßÂà∂‰ΩøÁî®ËÄÖÂ∞çÂèÉÊï∏Áü•Ë≠òÁöÑÂ≠òÂèñÔºå‰∏¶Á∂≠ÊåÅÂÖ∂‰∏ÄËà¨ÊïàÁî®„ÄÇ

##### **Enhancing Large Language Models' Situated Faithfulness to External Contexts**
2410.14675v1 by Yukun Huang, Sanxing Chen, Hongyi Cai, Bhuwan Dhingra

Large Language Models (LLMs) are often augmented with external information as
contexts, but this external information can sometimes be inaccurate or even
intentionally misleading. We argue that robust LLMs should demonstrate situated
faithfulness, dynamically calibrating their trust in external information based
on their confidence in the internal knowledge and the external context. To
benchmark this capability, we evaluate LLMs across several QA datasets,
including a newly created dataset called RedditQA featuring in-the-wild
incorrect contexts sourced from Reddit posts. We show that when provided with
both correct and incorrect contexts, both open-source and proprietary models
tend to overly rely on external information, regardless of its factual
accuracy. To enhance situated faithfulness, we propose two approaches:
Self-Guided Confidence Reasoning (SCR) and Rule-Based Confidence Reasoning
(RCR). SCR enables models to self-access the confidence of external information
relative to their own internal knowledge to produce the most accurate answer.
RCR, in contrast, extracts explicit confidence signals from the LLM and
determines the final answer using predefined rules. Our results show that for
LLMs with strong reasoning capabilities, such as GPT-4o and GPT-4o mini, SCR
outperforms RCR, achieving improvements of up to 24.2% over a direct input
augmentation baseline. Conversely, for a smaller model like Llama-3-8B, RCR
outperforms SCR. Fine-tuning SCR with our proposed Confidence Reasoning Direct
Preference Optimization (CR-DPO) method improves performance on both seen and
unseen datasets, yielding an average improvement of 8.9% on Llama-3-8B. In
addition to quantitative results, we offer insights into the relative strengths
of SCR and RCR. Our findings highlight promising avenues for improving situated
faithfulness in LLMs. The data and code are released.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄöÂ∏∏ÊúÉ‰ª•Â§ñÈÉ®Ë≥áË®ä‰ΩúÁÇ∫ÊÉÖÂ¢ÉÈÄ≤Ë°åÊì¥ÂÖÖÔºå‰ΩÜÈÄô‰∫õÂ§ñÈÉ®Ë≥áË®äÊúâÊôÇÂèØËÉΩ‰∏çÊ≠£Á¢∫ÔºåÁîöËá≥ÊïÖÊÑèÂÖ∑ÊúâË™§Â∞éÊÄß„ÄÇÊàëÂÄëË™çÁÇ∫ÔºåÂº∑ÂÅ•ÁöÑ LLM ÊáâÂ±ïÁèæÊÉÖÂ¢ÉÂø†ÂØ¶Â∫¶ÔºåÊ†πÊìöÂÖ∂Â∞çÂÖßÈÉ®Áü•Ë≠òÂíåÂ§ñÈÉ®ÊÉÖÂ¢ÉÁöÑ‰ø°ÂøÉÔºåÂãïÊÖãÊ†°Ê∫ñÂÖ∂Â∞çÂ§ñÈÉ®Ë≥áË®äÁöÑ‰ø°‰ªª„ÄÇÁÇ∫‰∫ÜË©ïÈáèÊ≠§È†ÖËÉΩÂäõÔºåÊàëÂÄëÈáùÂ∞çÂ§öÂÄãÂïèÁ≠îË≥áÊñôÈõÜË©ï‰º∞ LLMÔºåÂåÖÊã¨‰∏ÄÂÄãÊñ∞Âª∫Á´ãÁöÑË≥áÊñôÈõÜ RedditQAÔºåÂÖ∂ÁâπÈªûÊòØÂæû Reddit Ë≤ºÊñá‰∏≠Êì∑ÂèñÁöÑÁúüÂØ¶‰∏çÊ≠£Á¢∫ÊÉÖÂ¢É„ÄÇÊàëÂÄëÁôºÁèæÔºåÁï∂Êèê‰æõÊ≠£Á¢∫Âíå‰∏çÊ≠£Á¢∫ÁöÑÊÉÖÂ¢ÉÊôÇÔºå‰∏çË´ñÊòØÈñãÊîæÂéüÂßãÁ¢ºÊàñÂ∞àÊúâÊ®°ÂûãÔºåÈÉΩÂÇæÂêëÈÅéÂ∫¶‰æùË≥¥Â§ñÈÉ®Ë≥áË®äÔºåËÄå‰∏çÁÆ°ÂÖ∂‰∫ãÂØ¶Ê≠£Á¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑ÊÉÖÂ¢ÉÂø†ÂØ¶Â∫¶ÔºåÊàëÂÄëÊèêÂá∫ÂÖ©Á®ÆÊñπÊ≥ïÔºöËá™Â∞é‰ø°ÂøÉÊé®ÁêÜ (SCR) ÂíåÂü∫ÊñºË¶èÂâáÁöÑ‰ø°ÂøÉÊé®ÁêÜ (RCR)„ÄÇSCR ‰ΩøÊ®°ÂûãËÉΩÂ§†Ëá™Ë°åÂ≠òÂèñÂ§ñÈÉ®Ë≥áË®äÁöÑ‰ø°ÂøÉÔºåÁõ∏Â∞çÊñºÂÖ∂Ëá™Ë∫´ÁöÑÂÖßÈÉ®Áü•Ë≠òÔºå‰ª•Áî¢ÁîüÊúÄÊ∫ñÁ¢∫ÁöÑÁ≠îÊ°à„ÄÇÁõ∏ÂèçÂú∞ÔºåRCR Âæû LLM ‰∏≠Êì∑ÂèñÊòéÁ¢∫ÁöÑ‰ø°ÂøÉË®äËôüÔºå‰∏¶‰ΩøÁî®È†êÂÆöÁæ©ÁöÑË¶èÂâá‰æÜÊ±∫ÂÆöÊúÄÁµÇÁ≠îÊ°à„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÂ∞çÊñºÂÖ∑ÊúâÂº∑Â§ßÊé®ÁêÜËÉΩÂäõÁöÑ LLMÔºå‰æãÂ¶Ç GPT-4o Âíå GPT-4o miniÔºåSCR ÂÑ™Êñº RCRÔºåËàáÁõ¥Êé•Ëº∏ÂÖ•Êì¥ÂÖÖÂü∫Ê∫ñÁõ∏ÊØîÔºåÊîπÈÄ≤ÂπÖÂ∫¶È´òÈÅî 24.2%„ÄÇÁõ∏ÂèçÂú∞ÔºåÂ∞çÊñºËºÉÂ∞èÁöÑÊ®°ÂûãÔºå‰æãÂ¶Ç Llama-3-8BÔºåRCR ÂÑ™Êñº SCR„ÄÇ‰ΩøÁî®ÊàëÂÄëÊèêÂá∫ÁöÑ‰ø°ÂøÉÊé®ÁêÜÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (CR-DPO) ÊñπÊ≥ïÂæÆË™ø SCRÔºåÂèØ‰ª•ÊèêÈ´òÂ∑≤Ë¶ãÂíåÊú™Ë¶ãË≥áÊñôÈõÜÁöÑÊïàËÉΩÔºåÂú® Llama-3-8B ‰∏äÁî¢ÁîüÂπ≥Âùá 8.9% ÁöÑÊîπÈÄ≤„ÄÇÈô§‰∫ÜÈáèÂåñÁµêÊûúÂ§ñÔºåÊàëÂÄëÈÇÑÊèê‰æõ‰∫ÜÂ∞ç SCR Âíå RCR Áõ∏Â∞çÂÑ™Âã¢ÁöÑË¶ãËß£„ÄÇÊàëÂÄëÁöÑÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÊîπÂñÑ LLM ‰∏≠ÊÉÖÂ¢ÉÂø†ÂØ¶Â∫¶ÁöÑÊúâÂâçÊôØÈÄîÂæë„ÄÇË≥áÊñôÂíåÁ®ãÂºèÁ¢ºÂ∑≤ÁôºÂ∏É„ÄÇ

##### **BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities**
2410.14672v1 by Shaozhe Hao, Xuantong Liu, Xianbiao Qi, Shihao Zhao, Bojia Zi, Rong Xiao, Kai Han, Kwan-Yee K. Wong

We introduce BiGR, a novel conditional image generation model using compact
binary latent codes for generative training, focusing on enhancing both
generation and representation capabilities. BiGR is the first conditional
generative model that unifies generation and discrimination within the same
framework. BiGR features a binary tokenizer, a masked modeling mechanism, and a
binary transcoder for binary code prediction. Additionally, we introduce a
novel entropy-ordered sampling method to enable efficient image generation.
Extensive experiments validate BiGR's superior performance in generation
quality, as measured by FID-50k, and representation capabilities, as evidenced
by linear-probe accuracy. Moreover, BiGR showcases zero-shot generalization
across various vision tasks, enabling applications such as image inpainting,
outpainting, editing, interpolation, and enrichment, without the need for
structural modifications. Our findings suggest that BiGR unifies generative and
discriminative tasks effectively, paving the way for further advancements in
the field.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÈÄ≤ BiGRÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ¢ù‰ª∂ÂúñÂÉèÁîüÊàêÊ®°ÂûãÔºå‰ΩøÁî®Á∑äÊπäÁöÑ‰∫åÈÄ≤Âà∂ÊΩõÂú®Á¢ºÈÄ≤Ë°åÁîüÊàêË®ìÁ∑¥ÔºåÂ∞àÊ≥®ÊñºÂ¢ûÂº∑ÁîüÊàêÂíåË°®Á§∫ËÉΩÂäõ„ÄÇBiGR ÊòØÁ¨¨‰∏ÄÂÄãÂú®Âêå‰∏ÄÊû∂ÊßãÂÖßÁµ±‰∏ÄÁîüÊàêÂíåÂà§Âà•ÁöÑÊ¢ù‰ª∂ÁîüÊàêÊ®°Âûã„ÄÇBiGR ÂÖ∑Êúâ‰∫åÈÄ≤Âà∂ÂàÜË©ûÂô®„ÄÅÈÅÆÁΩ©Âª∫Ê®°Ê©üÂà∂Âíå‰∫åÈÄ≤Âà∂ËΩâÁ¢ºÂô®ÔºåÁî®Êñº‰∫åÈÄ≤Âà∂Á¢ºÈ†êÊ∏¨„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁÜµÊéíÂ∫èÊé°Ê®£ÊñπÊ≥ïÔºå‰ª•ÂØ¶ÁèæÈ´òÊïàÁöÑÂúñÂÉèÁîüÊàê„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÈ©óË≠â‰∫Ü BiGR Âú®ÁîüÊàêÂìÅË≥™ÊñπÈù¢ÁöÑÂÑ™Áï∞ÊÄßËÉΩÔºåÂ¶Ç FID-50k ÊâÄÊ∏¨ÈáèÔºå‰ª•ÂèäË°®Á§∫ËÉΩÂäõÔºåÂ¶ÇÁ∑öÊÄßÊé¢Ê∏¨Ê∫ñÁ¢∫Â∫¶ÊâÄË≠âÊòé„ÄÇÊ≠§Â§ñÔºåBiGR Â±ïÁ§∫‰∫ÜË∑®ÂêÑÁ®ÆË¶ñË¶∫‰ªªÂãôÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÔºåÂØ¶Áèæ‰∫ÜÂúñÂÉè‰øÆÂæ©„ÄÅÂ§ñÁπ™„ÄÅÁ∑®ËºØ„ÄÅÊèíÂÄºÂíåË±êÂØåÂåñÁ≠âÊáâÁî®ÔºåËÄåÁÑ°ÈúÄÈÄ≤Ë°åÁµêÊßã‰øÆÊîπ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåBiGR ÊúâÊïàÂú∞Áµ±‰∏Ä‰∫ÜÁîüÊàêÂíåÂà§Âà•‰ªªÂãôÔºåÁÇ∫Ë©≤È†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•ÁôºÂ±ïÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

##### **NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples**
2410.14669v1 by Baiqi Li, Zhiqiu Lin, Wenxuan Peng, Jean de Dieu Nyandwi, Daniel Jiang, Zixian Ma, Simran Khanuja, Ranjay Krishna, Graham Neubig, Deva Ramanan

Vision-language models (VLMs) have made significant progress in recent
visual-question-answering (VQA) benchmarks that evaluate complex
visio-linguistic reasoning. However, are these models truly effective? In this
work, we show that VLMs still struggle with natural images and questions that
humans can easily answer, which we term natural adversarial samples. We also
find it surprisingly easy to generate these VQA samples from natural image-text
corpora using off-the-shelf models like CLIP and ChatGPT. We propose a
semi-automated approach to collect a new benchmark, NaturalBench, for reliably
evaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a
$\textbf{vision-centric}$ design by pairing each question with two images that
yield different answers, preventing blind solutions from answering without
using the images. This makes NaturalBench more challenging than previous
benchmarks that can be solved with commonsense priors. We evaluate 53
state-of-the-art VLMs on NaturalBench, showing that models like
LLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o
lag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is
hard from two angles: (1) Compositionality: Solving NaturalBench requires
diverse visio-linguistic skills, including understanding attribute bindings,
object relationships, and advanced reasoning like logic and counting. To this
end, unlike prior work that uses a single tag per sample, we tag each
NaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)
Biases: NaturalBench exposes severe biases in VLMs, as models often choose the
same answer regardless of the image. Lastly, we apply our benchmark curation
method to diverse data sources, including long captions (over 100 words) and
non-English languages like Chinese and Hindi, highlighting its potential for
dynamic evaluations of VLMs.

ÊëòË¶ÅÔºö<paragraph>Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Âú®ÊúÄËøëÁöÑË¶ñË¶∫ÂïèÁ≠î (VQA) Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºåÈÄô‰∫õÂü∫Ê∫ñÊ∏¨Ë©¶Ë©ï‰º∞‰∫ÜË§áÈõúÁöÑË¶ñË¶∫Ë™ûË®ÄÊé®ÁêÜËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÊòØÂê¶ÁúüÊ≠£ÊúâÊïàÔºüÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü VLM ‰ªçÈõ£‰ª•ËôïÁêÜ‰∫∫È°ûÂèØ‰ª•ËºïÈ¨ÜÂõûÁ≠îÁöÑËá™ÁÑ∂ÂΩ±ÂÉèÂíåÂïèÈ°åÔºåÊàëÂÄëÂ∞áÂÖ∂Á®±ÁÇ∫Ëá™ÁÑ∂Â∞çÊäóÊ®£Êú¨„ÄÇÊàëÂÄëÈÇÑÁôºÁèæÔºå‰ΩøÁî®ÁèæÊàêÁöÑÊ®°ÂûãÔºà‰æãÂ¶Ç CLIP Âíå ChatGPTÔºâÂæûËá™ÁÑ∂ÂΩ±ÂÉèÊñáÂ≠óË™ûÊñôÂ∫´‰∏≠ÁîüÊàêÈÄô‰∫õ VQA Ê®£Êú¨Âá∫Â•áÂú∞ÂÆπÊòì„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂçäËá™ÂãïÂåñÊñπÊ≥ï‰æÜÊî∂ÈõÜ‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶ NaturalBenchÔºå‰ª•‰æø‰ΩøÁî® 10,000 ÂÄãÁ∂ì‰∫∫È°ûÈ©óË≠âÁöÑ VQA Ê®£Êú¨ÂèØÈù†Âú∞Ë©ï‰º∞ VLM„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÊé°Áî®‰∫Ü**‰ª•Ë¶ñË¶∫ÁÇ∫‰∏≠ÂøÉ**ÁöÑË®≠Ë®àÔºåÂ∞áÊØèÂÄãÂïèÈ°åËàáÂÖ©ÂºµÁî¢Áîü‰∏çÂêåÁ≠îÊ°àÁöÑÂΩ±ÂÉèÈÖçÂ∞çÔºåÈò≤Ê≠¢Áõ≤Ëß£Âú®‰∏ç‰ΩøÁî®ÂΩ±ÂÉèÁöÑÊÉÖÊ≥Å‰∏ãÂõûÁ≠îÂïèÈ°å„ÄÇÈÄô‰ΩøÂæó NaturalBench ÊØîÂèØ‰ª•‰ΩøÁî®Â∏∏Ë≠òÂÖàÈ©ó‰æÜËß£Ê±∫ÁöÑÂÖàÂâçÂü∫Ê∫ñÊ∏¨Ë©¶Êõ¥ÂÖ∑ÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëÂú® NaturalBench ‰∏äË©ï‰º∞‰∫Ü 53 ÂÄãÊúÄÂÖàÈÄ≤ÁöÑ VLMÔºåÁµêÊûúÈ°ØÁ§∫ LLaVA-OneVision„ÄÅCambrian-1„ÄÅLlama3.2-Vision„ÄÅMolmo„ÄÅQwen2-VLÔºåÁîöËá≥ GPT-4o Á≠âÊ®°ÂûãËêΩÂæåÊñº‰∫∫È°ûË°®Áèæ (Ë∂ÖÈÅé 90%) 50%-70%„ÄÇÊàëÂÄëÂæûÂÖ©ÂÄãËßíÂ∫¶ÂàÜÊûê‰∫Ü NaturalBench ÁöÑÈõ£ÈªûÔºö(1) ÁµÑÂêàÊÄßÔºöËß£Ê±∫ NaturalBench ÈúÄË¶ÅÂ§öÊ®£ÂåñÁöÑË¶ñË¶∫Ë™ûË®ÄÊäÄËÉΩÔºåÂåÖÊã¨ÁêÜËß£Â±¨ÊÄßÁπ´Áµê„ÄÅÁâ©‰ª∂Èóú‰øÇ‰ª•ÂèäÈ´òÁ¥öÊé®ÁêÜÔºå‰æãÂ¶ÇÈÇèËºØÂíåË®àÊï∏„ÄÇÁÇ∫Ê≠§ÔºåËàáÂÖàÂâç‰ΩøÁî®ÊØèÂÄãÊ®£Êú¨‰∏ÄÂÄãÊ®ôÁ±§ÁöÑÂ∑•‰Ωú‰∏çÂêåÔºåÊàëÂÄë‰ΩøÁî® 1 Âà∞ 8 ÂÄãÊäÄËÉΩÊ®ôÁ±§Ê®ôË®òÊØèÂÄã NaturalBench Ê®£Êú¨Ôºå‰ª•ÈÄ≤Ë°åÁ¥∞ÂæÆÁöÑË©ï‰º∞„ÄÇ(2) ÂÅèÂ∑ÆÔºöNaturalBench Êè≠Èú≤‰∫Ü VLM ‰∏≠Âö¥ÈáçÁöÑÂÅèÂ∑ÆÔºåÂõ†ÁÇ∫Ê®°ÂûãÈÄöÂ∏∏ÊúÉÈÅ∏ÊìáÁõ∏ÂêåÁöÑÁ≠îÊ°àÔºåËÄå‰∏çÁÆ°ÂΩ±ÂÉèÁÇ∫‰Ωï„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞áÂü∫Ê∫ñÁ≠ñÂ±ïÊñπÊ≥ïÊáâÁî®ÊñºÂêÑÁ®ÆÊï∏Êìö‰æÜÊ∫êÔºåÂåÖÊã¨Èï∑Ê®ôÈ°åÔºàË∂ÖÈÅé 100 ÂÄãÂ≠óÔºâÂíåÈùûËã±Ë™ûË™ûË®ÄÔºà‰æãÂ¶Ç‰∏≠ÊñáÂíåÂç∞Âú∞Ë™ûÔºâÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂Â∞ç VLM ÈÄ≤Ë°åÂãïÊÖãË©ï‰º∞ÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **MiCEval: Unveiling Multimodal Chain of Thought's Quality via Image Description and Reasoning Steps**
2410.14668v1 by Xiongtao Zhou, Jie He, Lanyu Chen, jingyu li, Haojing Chen, Victor Gutierrez Basulto, Jeff Z. Pan, Hanjie Chen

Multimodal Chain of Thought (MCoT) is a popular prompting strategy for
improving the performance of multimodal large language models (MLLMs) across a
range of complex reasoning tasks. Despite its popularity, there is a notable
absence of automated methods for evaluating the quality of reasoning steps in
MCoT. To address this gap, we propose Multimodal Chain-of-Thought Evaluation
(MiCEval), a framework designed to assess the correctness of reasoning chains
by evaluating the quality of both the description and each reasoning step. The
evaluation of the description component focuses on the accuracy of the image
descriptions, while the reasoning step evaluates the quality of each step as it
is conditionally generated based on the preceding steps. MiCEval is built upon
a fine-grained dataset with annotations that rate each step according to
correctness, relevance, and informativeness. Extensive experiments on four
state-of-the-art MLLMs show that step-wise evaluations using MiCEval align more
closely with human judgments compared to existing methods based on cosine
similarity or fine-tuning approaches. MiCEval datasets and code can be found in
https://github.com/alenai97/MiCEval.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÖãÊÄùÁ∂≠ÈèàÔºàMCoTÔºâÊòØ‰∏ÄÁ®ÆÊµÅË°åÁöÑÊèêÁ§∫Á≠ñÁï•ÔºåÁî®ÊñºÊèêÂçáÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàMLLMÔºâÂú®ÂêÑÁ®ÆË§áÈõúÊé®ÁêÜ‰ªªÂãô‰∏≠ÁöÑË°®Áèæ„ÄÇÂÑòÁÆ°ÂÆÉÂæàÂèóÊ≠°ËøéÔºå‰ΩÜÂ∞çÊñºË©ï‰º∞ MCoT ‰∏≠Êé®ÁêÜÊ≠•È©üÂìÅË≥™ÁöÑËá™ÂãïÂåñÊñπÊ≥ïÂçªÊòéÈ°Ø‰∏çË∂≥„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ§öÊ®°ÊÖãÊÄùÁ∂≠ÈèàË©ï‰º∞ÔºàMiCEvalÔºâÔºå‰∏ÄÂÄãÊó®Âú®Ë©ï‰º∞Êé®ÁêÜÈèàÊ≠£Á¢∫ÊÄßÁöÑÊ°ÜÊû∂ÔºåÊñπÊ≥ïÊòØË©ï‰º∞ÊèèËø∞ÂíåÊØèÂÄãÊé®ÁêÜÊ≠•È©üÁöÑÂìÅË≥™„ÄÇÊèèËø∞ÁµÑÊàêÁöÑË©ï‰º∞ÈáçÈªûÂú®ÊñºÂΩ±ÂÉèÊèèËø∞ÁöÑÊ∫ñÁ¢∫ÊÄßÔºåËÄåÊé®ÁêÜÊ≠•È©üÂâáË©ï‰º∞ÊØèÂÄãÊ≠•È©üÂú®Ê†πÊìöÂâçÂ∫èÊ≠•È©üÊúâÊ¢ù‰ª∂Áî¢ÁîüÁöÑÂìÅË≥™„ÄÇMiCEval Âª∫Á´ãÂú®‰∏ÄÂÄãÁ¥∞Á∑ªÁöÑË≥áÊñôÈõÜ‰∏äÔºåÂÖ∂‰∏≠ÂåÖÂê´Ê†πÊìöÊ≠£Á¢∫ÊÄß„ÄÅÁõ∏ÈóúÊÄßÂíåË≥áË®äÊÄßÂ∞çÊØèÂÄãÊ≠•È©üÈÄ≤Ë°åË©ïÂàÜÁöÑË®ªËß£„ÄÇÈáùÂ∞çÂõõÂÄãÊúÄÂÖàÈÄ≤ÁöÑ MLLM ÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫Ôºå‰ΩøÁî® MiCEval ÈÄ≤Ë°åÁöÑÈÄêÊ≠•Ë©ï‰º∞Ëàá‰∫∫È°ûÁöÑÂà§Êñ∑Êõ¥ÁÇ∫‰∏ÄËá¥ÔºåËàáÂü∫ÊñºÈ§òÂº¶Áõ∏‰ººÊÄßÊàñÂæÆË™øÊñπÊ≥ïÁöÑÁèæÊúâÊñπÊ≥ïÁõ∏ÊØî„ÄÇMiCEval Ë≥áÊñôÈõÜÂíåÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/alenai97/MiCEval ‰∏≠ÊâæÂà∞„ÄÇ

##### **DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie Character-Aware Discourse Graph**
2410.14666v1 by Maitreya Prafulla Chitale, Uday Bindal, Rajakrishnan Rajkumar, Rahul Mishra

Summarizing movie screenplays presents a unique set of challenges compared to
standard document summarization. Screenplays are not only lengthy, but also
feature a complex interplay of characters, dialogues, and scenes, with numerous
direct and subtle relationships and contextual nuances that are difficult for
machine learning models to accurately capture and comprehend. Recent attempts
at screenplay summarization focus on fine-tuning transformer-based pre-trained
models, but these models often fall short in capturing long-term dependencies
and latent relationships, and frequently encounter the "lost in the middle"
issue. To address these challenges, we introduce DiscoGraMS, a novel resource
that represents movie scripts as a movie character-aware discourse graph (CaD
Graph). This approach is well-suited for various downstream tasks, such as
summarization, question-answering, and salience detection. The model aims to
preserve all salient information, offering a more comprehensive and faithful
representation of the screenplay's content. We further explore a baseline
method that combines the CaD Graph with the corresponding movie script through
a late fusion of graph and text modalities, and we present very initial
promising results.

ÊëòË¶ÅÔºöËàáÊ®ôÊ∫ñÊñá‰ª∂ÊëòË¶ÅÁõ∏ÊØîÔºåÊëòË¶ÅÈõªÂΩ±ÂäáÊú¨ÂëàÁèæÂá∫‰∏ÄÁµÑÁç®ÁâπÁöÑÊåëÊà∞„ÄÇÂäáÊú¨‰∏çÂÉÖÁØáÂπÖÂÜóÈï∑ÔºåËÄå‰∏îÈÇÑÂÖ∑ÊúâËßíËâ≤„ÄÅÂ∞çË©±ÂíåÂ†¥ÊôØÁöÑË§áÈõúÁõ∏‰∫í‰ΩúÁî®ÔºåÂÖ∂‰∏≠ÂåÖÂê´Ë®±Â§öÁõ¥Êé•ÂíåÂæÆÂ¶ôÁöÑÈóú‰øÇ‰ª•ÂèäË™ûÂ¢ÉÁ¥∞ÂæÆÂ∑ÆÂà•ÔºåÈÄôÂ∞çÊñºÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜË™™Èõ£‰ª•Ê∫ñÁ¢∫ÊçïÊçâÂíåÁêÜËß£„ÄÇÊúÄËøëÂ∞çÂäáÊú¨ÊëòË¶ÅÁöÑÂòóË©¶Â∞àÊ≥®ÊñºÂæÆË™øÂü∫ÊñºËΩâÊèõÂô®ÁöÑÈ†êË®ìÁ∑¥Ê®°ÂûãÔºå‰ΩÜÈÄô‰∫õÊ®°ÂûãÂú®ÊçïÊçâÈï∑Êúü‰æùË≥¥ÊÄßÂíåÊΩõÂú®Èóú‰øÇÊñπÈù¢Â∏∏Â∏∏‰∏çË∂≥Ôºå‰∏¶‰∏îÁ∂ìÂ∏∏ÈÅáÂà∞„ÄåÂú®‰∏≠ÈñìËø∑Â§±„ÄçÁöÑÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü DiscoGraMSÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË≥áÊ∫êÔºåÂÆÉÂ∞áÈõªÂΩ±ËÖ≥Êú¨Ë°®Á§∫ÁÇ∫‰∏ÄÂÄãÈõªÂΩ±ËßíËâ≤ÊÑüÁü•Ë©±Ë™ûÂúñÔºàCaD ÂúñÔºâ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈùûÂ∏∏ÈÅ©ÂêàÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãôÔºå‰æãÂ¶ÇÊëòË¶Å„ÄÅÂïèÁ≠îÂíåÈ°ØËëóÊÄßÊ™¢Ê∏¨„ÄÇË©≤Ê®°ÂûãÊó®Âú®‰øùÁïôÊâÄÊúâÈ°ØËëó‰ø°ÊÅØÔºåÊèê‰æõÂ∞çÂäáÊú¨ÂÖßÂÆπÊõ¥ÂÖ®Èù¢„ÄÅÊõ¥Âø†ÂØ¶ÁöÑË°®Á§∫„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é‰∫Ü‰∏ÄÁ®ÆÂü∫Á∑öÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÈÄöÈÅéÂúñÂΩ¢ÂíåÊñáÊú¨Ê®°ÂºèÁöÑÂæåÊúüËûçÂêàÂ∞á CaD ÂúñËàáÂ∞çÊáâÁöÑÈõªÂΩ±ËÖ≥Êú¨ÁµêÂêàËµ∑‰æÜÔºå‰∏¶‰∏îÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈùûÂ∏∏ÊúâÂ∏åÊúõÁöÑÂàùÊ≠•ÁµêÊûú„ÄÇ

##### **Real-time Fake News from Adversarial Feedback**
2410.14651v1 by Sanxing Chen, Yukun Huang, Bhuwan Dhingra

We show that existing evaluations for fake news detection based on
conventional sources, such as claims on fact-checking websites, result in an
increasing accuracy over time for LLM-based detectors -- even after their
knowledge cutoffs. This suggests that recent popular political claims, which
form the majority of fake news on such sources, are easily classified using
surface-level shallow patterns. Instead, we argue that a proper fake news
detection dataset should test a model's ability to reason factually about the
current world by retrieving and reading related evidence. To this end, we
develop a novel pipeline that leverages natural language feedback from a
RAG-based detector to iteratively modify real-time news into deceptive fake
news that challenges LLMs. Our iterative rewrite decreases the binary
classification AUC by an absolute 17.5 percent for a strong RAG GPT-4o
detector. Our experiments reveal the important role of RAG in both detecting
and generating fake news, as retrieval-free LLM detectors are vulnerable to
unseen events and adversarial attacks, while feedback from RAG detection helps
discover more deceitful patterns in fake news.

ÊëòË¶ÅÔºöÊàëÂÄëË≠âÊòéÔºåÂü∫ÊñºÂÇ≥Áµ±‰æÜÊ∫êÔºà‰æãÂ¶Ç‰∫ãÂØ¶Êü•Ê†∏Á∂≤Á´ô‰∏äÁöÑËÅ≤ÊòéÔºâÁöÑÁèæÊúâÂÅáÊñ∞ËÅûÂÅµÊ∏¨Ë©ï‰º∞ÔºåÊúÉÈö®ËëóÊôÇÈñìÊé®ÁßªËÄåÊèêÈ´ò LLM ÁÇ∫Âü∫Á§éÁöÑÂÅµÊ∏¨Âô®ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂç≥‰ΩøÂú®ÂÆÉÂÄëÁöÑÁü•Ë≠òÊà™Ê≠¢‰πãÂæå„ÄÇÈÄôË°®ÊòéÊ≠§È°û‰æÜÊ∫ê‰∏äÁöÑËøëÊúüÁÜ±ÈñÄÊîøÊ≤ªËÅ≤ÊòéÔºåÊßãÊàêÊ≠§È°û‰æÜÊ∫ê‰∏äÂ§ßÂ§öÊï∏ÂÅáÊñ∞ËÅûÔºåÂæàÂÆπÊòì‰ΩøÁî®Ë°®Èù¢Â±§Ê¨°ÁöÑÊ∑∫Â±§Ê®°ÂºèÈÄ≤Ë°åÂàÜÈ°û„ÄÇÁõ∏ÂèçÔºåÊàëÂÄëË™çÁÇ∫ÈÅ©Áï∂ÁöÑÂÅáÊñ∞ËÅûÂÅµÊ∏¨Ë≥áÊñôÈõÜÊáâÊ∏¨Ë©¶Ê®°ÂûãÊ†πÊìöÁõ∏ÈóúË≠âÊìöÊ™¢Á¥¢ÂíåÈñ±ËÆÄÔºåÂ∞çÁï∂Ââç‰∏ñÁïåÈÄ≤Ë°å‰∫ãÂØ¶Êé®ÁêÜÁöÑËÉΩÂäõ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÁÆ°ÈÅìÔºåÂà©Áî®Âü∫Êñº RAG ÁöÑÂÅµÊ∏¨Âô®ÁöÑËá™ÁÑ∂Ë™ûË®ÄÂõûÈ•ãÔºå‰ª•ÂèçË¶Ü‰øÆÊîπÂç≥ÊôÇÊñ∞ËÅûÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÊåëÊà∞ LLM ÁöÑÊ¨∫È®ôÊÄßÂÅáÊñ∞ËÅû„ÄÇÊàëÂÄëÁöÑÂèçË¶ÜÊîπÂØ´Â∞áÂº∑Â§ßÁöÑ RAG GPT-4o ÂÅµÊ∏¨Âô®ÁöÑ‰∫åÂÖÉÂàÜÈ°û AUC ÁµïÂ∞çÈôç‰Ωé‰∫Ü 17.5 ÂÄãÁôæÂàÜÈªû„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊè≠Á§∫‰∫Ü RAG Âú®ÂÅµÊ∏¨ÂíåÁî¢ÁîüÂÅáÊñ∞ËÅû‰∏≠ÊâÆÊºîÁöÑÈáçË¶ÅËßíËâ≤ÔºåÂõ†ÁÇ∫ÁÑ°Ê™¢Á¥¢ÁöÑ LLM ÂÅµÊ∏¨Âô®ÂÆπÊòìÂèóÂà∞Êú™Ë¶ã‰∫ã‰ª∂ÂíåÂ∞çÊäóÊÄßÊîªÊìäÔºåËÄå RAG ÂÅµÊ∏¨ÁöÑÂõûÈ•ãÊúâÂä©ÊñºÁôºÁèæÂÅáÊñ∞ËÅû‰∏≠Êõ¥Â§öÂÖ∑ÊúâÊ¨∫È®ôÊÄßÁöÑÊ®°Âºè„ÄÇ

##### **Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs**
2410.14641v1 by Runchu Tian, Yanghao Li, Yuepeng Fu, Siyang Deng, Qinyu Luo, Cheng Qian, Shuo Wang, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Huadong Wang, Xiaojiang Liu

Positional bias in large language models (LLMs) hinders their ability to
effectively process long inputs. A prominent example is the "lost in the
middle" phenomenon, where LLMs struggle to utilize relevant information
situated in the middle of the input. While prior research primarily focuses on
single pieces of relevant information, real-world applications often involve
multiple relevant information pieces. To bridge this gap, we present
LongPiBench, a benchmark designed to assess positional bias involving multiple
pieces of relevant information. Thorough experiments are conducted with five
commercial and six open-source models. These experiments reveal that while most
current models are robust against the "lost in the middle" issue, there exist
significant biases related to the spacing of relevant information pieces. These
findings highlight the importance of evaluating and reducing positional biases
to advance LLM's capabilities.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑ‰ΩçÁΩÆÂÅèÂ∑ÆÊúÉÈòªÁ§ôÂÖ∂ÊúâÊïàËôïÁêÜÈï∑Ëº∏ÂÖ•ÁöÑËÉΩÂäõ„ÄÇ‰∏ÄÂÄãÈ°ØËëóÁöÑ‰æãÂ≠êÊòØ„ÄåËø∑Â§±Âú®‰∏≠Èñì„ÄçÁèæË±°ÔºåÂÖ∂‰∏≠ LLM Èõ£‰ª•Âà©Áî®‰ΩçÊñºËº∏ÂÖ•‰∏≠ÈñìÁöÑÁõ∏ÂÖ≥Ë≥áË®ä„ÄÇÂÑòÁÆ°ÂÖàÂâçÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈóúÊ≥®ÂñÆ‰∏ÄÁõ∏ÈóúË≥áË®äÔºå‰ΩÜÁèæÂØ¶‰∏ñÁïåÁöÑÊáâÁî®ÈÄöÂ∏∏Ê∂âÂèäÂ§öÂÄãÁõ∏ÈóúË≥áË®ä„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LongPiBenchÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫Ê∫ñÔºåÊó®Âú®Ë©ï‰º∞Ê∂âÂèäÂ§öÂÄãÁõ∏ÈóúË≥áË®äÁöÑ‰ΩçÁΩÆÂÅèÂ∑Æ„ÄÇÂ∞ç‰∫îÂÄãÂïÜÊ•≠ÂíåÂÖ≠ÂÄãÈñãÊ∫êÊ®°ÂûãÈÄ≤Ë°å‰∫ÜÂæπÂ∫ïÁöÑÂØ¶È©ó„ÄÇÈÄô‰∫õÂØ¶È©óË°®ÊòéÔºåÈõñÁÑ∂Â§ßÂ§öÊï∏Áï∂ÂâçÊ®°ÂûãÂ∞ç„ÄåËø∑Â§±Âú®‰∏≠Èñì„ÄçÂïèÈ°åÂÖ∑ÊúâÈ≠ØÊ£íÊÄßÔºå‰ΩÜËàáÁõ∏ÈóúË≥áË®äÈñìË∑ùÁõ∏ÈóúÁöÑÈ°ØËëóÂÅèÂ∑ÆÁ¢∫ÂØ¶Â≠òÂú®„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜË©ï‰º∞ÂíåÊ∏õÂ∞ë‰ΩçÁΩÆÂÅèÂ∑Æ‰ª•ÊèêÂçá LLM ËÉΩÂäõÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **GenEOL: Harnessing the Generative Power of LLMs for Training-Free Sentence Embeddings**
2410.14635v1 by Raghuveer Thirukovalluru, Bhuwan Dhingra

Training-free embedding methods directly leverage pretrained large language
models (LLMs) to embed text, bypassing the costly and complex procedure of
contrastive learning. Previous training-free embedding methods have mainly
focused on optimizing embedding prompts and have overlooked the benefits of
utilizing the generative abilities of LLMs. We propose a novel method, GenEOL,
which uses LLMs to generate diverse transformations of a sentence that preserve
its meaning, and aggregates the resulting embeddings of these transformations
to enhance the overall sentence embedding. GenEOL significantly outperforms the
existing training-free embedding methods by an average of 2.85 points across
several LLMs on the sentence semantic text similarity (STS) benchmark. Our
analysis shows that GenEOL stabilizes representation quality across LLM layers
and is robust to perturbations of embedding prompts. GenEOL also achieves
notable gains on multiple clustering, reranking and pair-classification tasks
from the MTEB benchmark.

ÊëòË¶ÅÔºöÁÑ°ÈúÄË®ìÁ∑¥ÁöÑÂµåÂÖ•ÊñπÊ≥ïÁõ¥Êé•Âà©Áî®È†êÂÖàË®ìÁ∑¥Â•ΩÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÂµåÂÖ•ÊñáÂ≠óÔºåÁπûÈÅéÂ∞çÊØîÂºèÂ≠∏ÁøíÁöÑÊòÇË≤¥‰∏îË§áÈõúÁöÑÁ®ãÂ∫è„ÄÇÂÖàÂâçÁöÑÁÑ°ÈúÄË®ìÁ∑¥ÁöÑÂµåÂÖ•ÊñπÊ≥ï‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÊúÄ‰Ω≥ÂåñÂµåÂÖ•ÊèêÁ§∫Ôºå‰∏îÂøΩÁï•‰∫ÜÂà©Áî® LLM ÁöÑÁîüÊàêËÉΩÂäõÁöÑÂ•ΩËôï„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ï GenEOLÔºåÂÆÉ‰ΩøÁî® LLM ‰æÜÁî¢Áîü‰øùÁïôÂÖ∂Âê´Áæ©ÁöÑÂè•Â≠ê‰πã‰∏çÂêåËΩâÊèõÔºå‰∏¶ËÅöÂêàÈÄô‰∫õËΩâÊèõÁöÑÂµåÂÖ•ÁµêÊûúÔºå‰ª•Â¢ûÂº∑Êï¥È´îÂè•Â≠êÂµåÂÖ•„ÄÇGenEOL Âú®Âè•Â≠êË™ûÁæ©ÊñáÂ≠óÁõ∏‰ººÊÄß (STS) Âü∫Ê∫ñ‰∏äÔºåÈÄèÈÅéÂ§öÂÄã LLMÔºåÂπ≥ÂùáÈ´òÂá∫ÁèæÊúâÁÑ°ÈúÄË®ìÁ∑¥ÁöÑÂµåÂÖ•ÊñπÊ≥ï 2.85 ÂàÜ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåGenEOL Á©©ÂÆö LLM Â±§ÈñìÁöÑË°®Á§∫ÂìÅË≥™Ôºå‰∏îÂ∞çÊñºÂµåÂÖ•ÊèêÁ§∫ÁöÑÊìæÂãïÂÖ∑ÊúâÁ©©ÂÅ•ÊÄß„ÄÇGenEOL ‰πüÂú® MTEB Âü∫Ê∫ñ‰∏≠ÁöÑÂ§öÂÄãÂàÜÁæ§„ÄÅÈáçÊñ∞ÊéíÂ∫èÂíåÊàêÂ∞çÂàÜÈ°û‰ªªÂãô‰∏≠ÂèñÂæóÈ°ØËëóÈÄ≤Â±ï„ÄÇ

##### **Diverging Preferences: When do Annotators Disagree and do Models Know?**
2410.14632v1 by Michael JQ Zhang, Zhilin Wang, Jena D. Hwang, Yi Dong, Olivier Delalleau, Yejin Choi, Eunsol Choi, Xiang Ren, Valentina Pyatkin

We examine diverging preferences in human-labeled preference datasets. We
develop a taxonomy of disagreement sources spanning 10 categories across four
high-level classes -- task underspecification, response style, refusals, and
annotation errors. We find that the majority of disagreements are in opposition
with standard reward modeling approaches, which are designed with the
assumption that annotator disagreement is noise. We then explore how these
findings impact two areas of LLM development: reward modeling and evaluation.
In our experiments, we demonstrate how standard reward modeling methods, like
the Bradley-Terry model, fail to differentiate whether a given preference
judgment is the result of unanimous agreement among annotators or the majority
opinion among diverging user preferences. We also find that these tendencies
are also echoed by popular LLM-as-Judge evaluation methods, which consistently
identify a winning response in cases of diverging preferences. These findings
highlight remaining challenges in LLM evaluations, which are greatly influenced
by divisive features like response style, and in developing pluralistically
aligned LLMs. To address these issues, we develop methods for identifying
diverging preferences to mitigate their influence on evaluation and training.

ÊëòË¶ÅÔºöÊàëÂÄëÊ™¢Ë¶ñ‰∫∫È°ûÊ®ôË®òÂÅèÂ•ΩË≥áÊñôÈõÜ‰∏≠‰∏çÂêåÁöÑÂÅèÂ•Ω„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÊ∂µËìãÂõõÂÄãÈ´òÁ¥öÂà•È°ûÂà•‰∏≠ 10 ÂÄãÈ°ûÂà•ÁöÑÂàÜÊ≠ß‰æÜÊ∫êÂàÜÈ°ûÊ≥ï‚Äî‚Äî‰ªªÂãôÊú™ÊòéÁ¢∫„ÄÅÂõûÊáâÈ¢®Ê†º„ÄÅÊãíÁµïÂíåË®ªËß£ÈåØË™§„ÄÇÊàëÂÄëÁôºÁèæÂ§ßÂ§öÊï∏ÂàÜÊ≠ßËàáÊ®ôÊ∫ñÁçéÂãµÂª∫Ê®°ÊñπÊ≥ïÁõ∏ÂèçÔºåÈÄô‰∫õÊñπÊ≥ïÁöÑË®≠Ë®àÂü∫ÊñºË®ªËß£ËÄÖÁöÑÂàÜÊ≠ßÊòØÈõúË®äÁöÑÂÅáË®≠„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊé¢Ë®éÈÄô‰∫õÁôºÁèæÂ¶Ç‰ΩïÂΩ±Èüø LLM ÈñãÁôºÁöÑÂÖ©ÂÄãÈ†òÂüüÔºöÁçéÂãµÂª∫Ê®°ÂíåË©ï‰º∞„ÄÇÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊ®ôÊ∫ñÁçéÂãµÂª∫Ê®°ÊñπÊ≥ïÔºà‰æãÂ¶Ç Bradley-Terry Ê®°ÂûãÔºâÂ¶Ç‰ΩïÁÑ°Ê≥ïÂçÄÂàÜÁµ¶ÂÆöÁöÑÂÅèÂ•ΩÂà§Êñ∑ÊòØË®ªËß£ËÄÖ‰∏ÄËá¥ÂêåÊÑèÈÇÑÊòØ‰∏çÂêå‰ΩøÁî®ËÄÖÂÅèÂ•Ω‰∏≠ÁöÑÂ§öÊï∏ÊÑèË¶ã„ÄÇÊàëÂÄëÈÇÑÁôºÁèæÈÄô‰∫õË∂®Âã¢‰πüÂèçÊò†Âú®ÊµÅË°åÁöÑ LLM-as-Judge Ë©ï‰º∞ÊñπÊ≥ï‰∏≠ÔºåÈÄô‰∫õÊñπÊ≥ïÂú®‰∏çÂêåÂÅèÂ•ΩÁöÑÊÉÖÊ≥Å‰∏ãÂßãÁµÇÁ¢∫ÂÆöÁç≤ÂãùÁöÑÂõûÊáâ„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÂá∫‰∫Ü LLM Ë©ï‰º∞‰∏≠‰ªçÁÑ∂Â≠òÂú®ÁöÑÊåëÊà∞ÔºåÈÄô‰∫õÊåëÊà∞ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèóÂà∞ÂõûÊáâÈ¢®Ê†ºÁ≠âÂàÜË£ÇÁâπÂæµÁöÑÂΩ±ÈüøÔºå‰∏¶‰∏îÂú®ÈñãÁôºÂ§öÂÖÉÂåñÁöÑ LLM ÊôÇÈÅáÂà∞‰∫ÜÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÈñãÁôº‰∫ÜË≠òÂà•‰∏çÂêåÂÅèÂ•ΩÁöÑÊñπÊ≥ïÔºå‰ª•Ê∏õËºïÂÖ∂Â∞çË©ï‰º∞ÂíåË®ìÁ∑¥ÁöÑÂΩ±Èüø„ÄÇ

##### **On the Regularization of Learnable Embeddings for Time Series Processing**
2410.14630v1 by Luca Butera, Giovanni De Felice, Andrea Cini, Cesare Alippi

In processing multiple time series, accounting for the individual features of
each sequence can be challenging. To address this, modern deep learning methods
for time series analysis combine a shared (global) model with local layers,
specific to each time series, often implemented as learnable embeddings.
Ideally, these local embeddings should encode meaningful representations of the
unique dynamics of each sequence. However, when these are learned end-to-end as
parameters of a forecasting model, they may end up acting as mere sequence
identifiers. Shared processing blocks may then become reliant on such
identifiers, limiting their transferability to new contexts. In this paper, we
address this issue by investigating methods to regularize the learning of local
learnable embeddings for time series processing. Specifically, we perform the
first extensive empirical study on the subject and show how such
regularizations consistently improve performance in widely adopted
architectures. Furthermore, we show that methods preventing the co-adaptation
of local and global parameters are particularly effective in this context. This
hypothesis is validated by comparing several methods preventing the downstream
models from relying on sequence identifiers, going as far as completely
resetting the embeddings during training. The obtained results provide an
important contribution to understanding the interplay between learnable local
parameters and shared processing layers: a key challenge in modern time series
processing models and a step toward developing effective foundation models for
time series.

ÊëòË¶ÅÔºöÂú®ËôïÁêÜÂ§öÂÄãÊôÇÈñìÂ∫èÂàóÊôÇÔºåËÄÉÈáèÊØèÂÄãÂ∫èÂàóÁöÑÂÄãÂà•ÁâπÂæµÂèØËÉΩÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÁî®ÊñºÊôÇÈñìÂ∫èÂàóÂàÜÊûêÁöÑÁèæ‰ª£Ê∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÊúÉÁµêÂêàÂÖ±Áî®ÔºàÂÖ®ÂüüÔºâÊ®°ÂûãËàáÂ±ÄÈÉ®Â±§ÔºåÁâπÂÆöÊñºÊØèÂÄãÊôÇÈñìÂ∫èÂàóÔºåÈÄöÂ∏∏ÂØ¶‰ΩúÁÇ∫ÂèØÂ≠∏ÁøíÁöÑÂµåÂÖ•„ÄÇÁêÜÊÉ≥ÊÉÖÊ≥Å‰∏ãÔºåÈÄô‰∫õÂ±ÄÈÉ®ÂµåÂÖ•ÊáâÁ∑®Á¢ºÊØèÂÄãÂ∫èÂàóÁç®ÁâπÂãïÊÖãÁöÑÊúâÊÑèÁæ©Ë°®Á§∫„ÄÇÁÑ∂ËÄåÔºåÁï∂ÈÄô‰∫õÂãïÊÖã‰ΩúÁÇ∫È†êÊ∏¨Ê®°ÂûãÁöÑÂèÉÊï∏‰ª•Á´ØÂ∞çÁ´ØÁöÑÊñπÂºèÂ≠∏ÁøíÊôÇÔºåÂÆÉÂÄëÂèØËÉΩÊúÉÊúÄÁµÇÂÉÖ‰ΩúÁÇ∫Â∫èÂàóË≠òÂà•Á¢º„ÄÇÂÖ±Áî®ËôïÁêÜÂçÄÂ°äÈö®ÂæåÂèØËÉΩÊúÉ‰æùË≥¥ÊñºÊ≠§È°ûË≠òÂà•Á¢ºÔºåÈôêÂà∂ÂÖ∂ÂèØËΩâÁßªÊÄßËá≥Êñ∞ÁöÑËÑàÁµ°„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÊé¢Ë®éÂ±ÄÈÉ®ÂèØÂ≠∏ÁøíÂµåÂÖ•Â≠∏ÁøíÁöÑÊ≠£ÂâáÂåñÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºå‰ª•ÈÄ≤Ë°åÊôÇÈñìÂ∫èÂàóËôïÁêÜ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈáùÂ∞çÈÄôÂÄã‰∏ªÈ°åÂü∑Ë°åÁ¨¨‰∏ÄÂÄãÂª£Ê≥õÁöÑÂØ¶Ë≠âÁ†îÁ©∂Ôºå‰∏¶Â±ïÁ§∫Ê≠§È°ûÊ≠£ÂâáÂåñÂ¶Ç‰ΩïÊåÅÁ∫åÊîπÂñÑÂª£Ê≥õÊé°Áî®ÁöÑÊû∂Êßã‰∏≠ÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫Èò≤Ê≠¢Â±ÄÈÉ®ÂíåÂÖ®ÂüüÂèÉÊï∏ÂÖ±ÈÅ©ÊáâÁöÑÊñπÊ≥ïÂú®Ê≠§ËÑàÁµ°‰∏≠ÁâπÂà•ÊúâÊïà„ÄÇÊ≠§ÂÅáË®≠ÈÄèÈÅéÊØîËºÉÂ§öÁ®ÆÈò≤Ê≠¢‰∏ãÊ∏∏Ê®°Âûã‰æùË≥¥Â∫èÂàóË≠òÂà•Á¢ºÁöÑÊñπÊ≥ïÁç≤ÂæóÈ©óË≠âÔºåÁîöËá≥Âú®Ë®ìÁ∑¥ÊúüÈñìÂÆåÂÖ®ÈáçË®≠ÂµåÂÖ•„ÄÇÊâÄÁç≤ÂæóÁöÑÁµêÊûúÁÇ∫‰∫ÜËß£ÂèØÂ≠∏ÁøíÂ±ÄÈÉ®ÂèÉÊï∏ËàáÂÖ±Áî®ËôïÁêÜÂ±§‰πãÈñìÁöÑ‰∫§‰∫í‰ΩúÁî®Êèê‰æõ‰∫ÜÈáçË¶ÅÁöÑË≤¢ÁçªÔºöÁèæ‰ª£ÊôÇÈñìÂ∫èÂàóËôïÁêÜÊ®°Âûã‰∏≠ÁöÑÈóúÈçµÊåëÊà∞Ôºå‰ª•ÂèäÈÇÅÂêëÈñãÁôºÊôÇÈñìÂ∫èÂàóÁöÑÊúâÊïàÂü∫Á§éÊ®°ÂûãÁöÑ‰∏ÄÊ≠•„ÄÇ

##### **CELI: Controller-Embedded Language Model Interactions**
2410.14627v1 by Jan-Samuel Wagner, Dave DeCaprio, Abishek Chiffon Muthu Raja, Jonathan M. Holman, Lauren K. Brady, Sky C. Cheung, Hosein Barzekar, Eric Yang, Mark Anthony Martinez II, David Soong, Sriram Sridhar, Han Si, Brandon W. Higgs, Hisham Hamadeh, Scott Ogden

We introduce Controller-Embedded Language Model Interactions (CELI), a
framework that integrates control logic directly within language model (LM)
prompts, facilitating complex, multi-stage task execution. CELI addresses
limitations of existing prompt engineering and workflow optimization techniques
by embedding control logic directly within the operational context of language
models, enabling dynamic adaptation to evolving task requirements. Our
framework transfers control from the traditional programming execution
environment to the LMs, allowing them to autonomously manage computational
workflows while maintaining seamless interaction with external systems and
functions. CELI supports arbitrary function calls with variable arguments,
bridging the gap between LMs' adaptive reasoning capabilities and conventional
software paradigms' structured control mechanisms. To evaluate CELI's
versatility and effectiveness, we conducted case studies in two distinct
domains: code generation (HumanEval benchmark) and multi-stage content
generation (Wikipedia-style articles). The results demonstrate notable
performance improvements across a range of domains. CELI achieved a 4.9
percentage point improvement over the best reported score of the baseline GPT-4
model on the HumanEval code generation benchmark. In multi-stage content
generation, 94.4% of CELI-produced Wikipedia-style articles met or exceeded
first draft quality when optimally configured, with 44.4% achieving high
quality. These outcomes underscore CELI's potential for optimizing AI-driven
workflows across diverse computational domains.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÂºïÂÖ•‰∫ÜÊéßÂà∂Âô®ÂµåÂÖ•ÂºèË™ûË®ÄÊ®°Âûã‰∫íÂãï (CELI)Ôºå‰∏ÄÁ®ÆÂ∞áÊéßÂà∂ÈÇèËºØÁõ¥Êé•Êï¥ÂêàÂà∞Ë™ûË®ÄÊ®°Âûã (LM) ÊèêÁ§∫‰∏≠ÁöÑÊ°ÜÊû∂Ôºå‰øÉÈÄ≤‰∫ÜË§áÈõúÁöÑÂ§öÈöéÊÆµ‰ªªÂãôÂü∑Ë°å„ÄÇCELI ÈÄèÈÅéÂ∞áÊéßÂà∂ÈÇèËºØÁõ¥Êé•ÂµåÂÖ•Ë™ûË®ÄÊ®°ÂûãÁöÑÊìç‰ΩúÁí∞Â¢É‰∏≠ÔºåËß£Ê±∫‰∫ÜÁèæÊúâÊèêÁ§∫Â∑•Á®ãÂíåÂ∑•‰ΩúÊµÅÁ®ãÊúÄ‰Ω≥ÂåñÊäÄË°ìÁöÑÈôêÂà∂ÔºåÂØ¶Áèæ‰∫ÜÂ∞ç‰∏çÊñ∑ËÆäÂåñÁöÑ‰ªªÂãôÈúÄÊ±ÇÁöÑÂãïÊÖãÈÅ©Êáâ„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂Â∞áÊéßÂà∂Ê¨äÂæûÂÇ≥Áµ±ÁöÑÁ®ãÂºèÂü∑Ë°åÁí∞Â¢ÉËΩâÁßªÂà∞ LMÔºåËÆìÂÆÉÂÄëËÉΩÂ§†Ëá™‰∏ªÁÆ°ÁêÜË®àÁÆóÂ∑•‰ΩúÊµÅÁ®ãÔºåÂêåÊôÇËàáÂ§ñÈÉ®Á≥ªÁµ±ÂíåÂäüËÉΩ‰øùÊåÅÁÑ°Á∏´‰∫íÂãï„ÄÇCELI ÊîØÊè¥‰ΩøÁî®ËÆäÊï∏ÂºïÊï∏ÁöÑ‰ªªÊÑèÂáΩÂºèÂëºÂè´ÔºåÂΩåÂêà‰∫Ü LM ÁöÑËá™ÈÅ©ÊáâÊé®ÁêÜËÉΩÂäõËàáÂÇ≥Áµ±ËªüÈ´îÁØÑ‰æãÁöÑÁµêÊßãÂåñÊéßÂà∂Ê©üÂà∂‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ CELI ÁöÑÂ§öÂäüËÉΩÊÄßÂíåÊúâÊïàÊÄßÔºåÊàëÂÄëÂú®ÂÖ©ÂÄã‰∏çÂêåÁöÑÈ†òÂüüÈÄ≤Ë°å‰∫ÜÊ°à‰æãÁ†îÁ©∂ÔºöÁ®ãÂºèÁ¢ºÁîüÊàê (HumanEval Âü∫Ê∫ñ) ÂíåÂ§öÈöéÊÆµÂÖßÂÆπÁîüÊàê (Á∂≠Âü∫ÁôæÁßëÈ¢®Ê†ºÁöÑÊñáÁ´†)„ÄÇÁµêÊûúË≠âÊòéÂú®ÂêÑÁ®ÆÈ†òÂüü‰∏≠ÈÉΩÊúâÈ°ØËëóÁöÑÊïàËÉΩÊèêÂçá„ÄÇÂú® HumanEval Á®ãÂºèÁ¢ºÁîüÊàêÂü∫Ê∫ñ‰∏≠ÔºåCELI ÁöÑË°®ÁèæÊØîÂü∫Á∑ö GPT-4 Ê®°ÂûãÁöÑÊúÄ‰Ω≥Â†±ÂëäÂàÜÊï∏ÊèêÂçá‰∫Ü 4.9 ÂÄãÁôæÂàÜÈªû„ÄÇÂú®Â§öÈöéÊÆµÂÖßÂÆπÁîüÊàê‰∏≠Ôºå94.4% ÁöÑ CELI ÁîüÊàêÁöÑÁ∂≠Âü∫ÁôæÁßëÈ¢®Ê†ºÊñáÁ´†Âú®ÊúÄ‰Ω≥ÈÖçÁΩÆ‰∏ãÈÅîÂà∞ÊàñË∂ÖÈÅéÂàùÁ®øÂìÅË≥™ÔºåÂÖ∂‰∏≠ 44.4% ÈÅîÂà∞È´òÂìÅË≥™„ÄÇÈÄô‰∫õÁµêÊûúÂº∑Ë™ø‰∫Ü CELI Âú®ÂÑ™ÂåñË∑®‰∏çÂêåË®àÁÆóÈ†òÂüüÁöÑ AI È©ÖÂãïÂ∑•‰ΩúÊµÅÁ®ãÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **You Shall Know a Tool by the Traces it Leaves: The Predictability of Sentiment Analysis Tools**
2410.14626v1 by Daniel Baumartz, Mevl√ºt Bagci, Alexander Henlein, Maxim Konca, Andy L√ºcking, Alexander Mehler

If sentiment analysis tools were valid classifiers, one would expect them to
provide comparable results for sentiment classification on different kinds of
corpora and for different languages. In line with results of previous studies
we show that sentiment analysis tools disagree on the same dataset. Going
beyond previous studies we show that the sentiment tool used for sentiment
annotation can even be predicted from its outcome, revealing an algorithmic
bias of sentiment analysis. Based on Twitter, Wikipedia and different news
corpora from the English, German and French languages, our classifiers separate
sentiment tools with an averaged F1-score of 0.89 (for the English corpora). We
therefore warn against taking sentiment annotations as face value and argue for
the need of more and systematic NLP evaluation studies.

ÊëòË¶ÅÔºöÂ¶ÇÊûúÊÉÖÁ∑íÂàÜÊûêÂ∑•ÂÖ∑ÊòØÊúâÊïàÁöÑÂàÜÈ°ûÂô®Ôºå‰∫∫ÂÄëÊúÉÊúüÂæÖÂÆÉÂÄëÂ∞ç‰∏çÂêåÈ°ûÂûãÁöÑË™ûÊñôÂ∫´Âíå‰∏çÂêåË™ûË®ÄÁöÑÊÉÖÁ∑íÂàÜÈ°ûÊèê‰æõÂèØÊØîËºÉÁöÑÁµêÊûú„ÄÇÊ†πÊìöÂÖàÂâçÁöÑÁ†îÁ©∂ÁµêÊûúÔºåÊàëÂÄëË°®ÊòéÊÉÖÁ∑íÂàÜÊûêÂ∑•ÂÖ∑‰∏çÂêåÊÑèÁõ∏ÂêåÁöÑÊï∏ÊìöÈõÜ„ÄÇË∂ÖË∂äÂÖàÂâçÁöÑÁ†îÁ©∂ÔºåÊàëÂÄëË°®ÊòéÁî®ÊñºÊÉÖÁ∑íÊ®ôË®ªÁöÑÊÉÖÁ∑íÂ∑•ÂÖ∑ÁîöËá≥ÂèØ‰ª•ÂæûÂÖ∂ÁµêÊûú‰∏≠È†êÊ∏¨ÔºåÊè≠Á§∫‰∫ÜÊÉÖÁ∑íÂàÜÊûêÁöÑÊºîÁÆóÊ≥ïÂÅèË™§„ÄÇÂü∫Êñº Twitter„ÄÅÁ∂≠Âü∫ÁôæÁßëÂíå‰æÜËá™Ëã±Ë™û„ÄÅÂæ∑Ë™ûÂíåÊ≥ïË™ûÁöÑ‰∏çÂêåÊñ∞ËÅûË™ûÊñôÂ∫´ÔºåÊàëÂÄëÁöÑÂàÜÈ°ûÂô®‰ª•Âπ≥Âùá F1 ÂàÜÊï∏ 0.89ÔºàÂ∞çÊñºËã±Ë™ûË™ûÊñôÂ∫´ÔºâÂçÄÂàÜÊÉÖÁ∑íÂ∑•ÂÖ∑„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëË≠¶Âëä‰∏çË¶ÅÂ∞áÊÉÖÁ∑íÊ®ôË®ªË¶ñÁÇ∫Ë°®Èù¢ÂÉπÂÄºÔºå‰∏¶‰∏ªÂºµÈúÄË¶ÅÊõ¥Â§ö‰∏îÁ≥ªÁµ±ÊÄßÁöÑ NLP Ë©ï‰º∞Á†îÁ©∂„ÄÇ

##### **Benchmarking Deep Reinforcement Learning for Navigation in Denied Sensor Environments**
2410.14616v1 by Mariusz Wisniewski, Paraskevas Chatzithanos, Weisi Guo, Antonios Tsourdos

Deep Reinforcement learning (DRL) is used to enable autonomous navigation in
unknown environments. Most research assume perfect sensor data, but real-world
environments may contain natural and artificial sensor noise and denial. Here,
we present a benchmark of both well-used and emerging DRL algorithms in a
navigation task with configurable sensor denial effects. In particular, we are
interested in comparing how different DRL methods (e.g. model-free PPO vs.
model-based DreamerV3) are affected by sensor denial. We show that DreamerV3
outperforms other methods in the visual end-to-end navigation task with a
dynamic goal - and other methods are not able to learn this. Furthermore,
DreamerV3 generally outperforms other methods in sensor-denied environments. In
order to improve robustness, we use adversarial training and demonstrate an
improved performance in denied environments, although this generally comes with
a performance cost on the vanilla environments. We anticipate this benchmark of
different DRL methods and the usage of adversarial training to be a starting
point for the development of more elaborate navigation strategies that are
capable of dealing with uncertain and denied sensor readings.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Âº∑ÂåñÂ≠∏Áøí (DRL) Áî®ÊñºÂú®Êú™Áü•Áí∞Â¢É‰∏≠ÂØ¶ÁèæËá™‰∏ªÂ∞éËà™„ÄÇÂ§ßÂ§öÊï∏Á†îÁ©∂ÂÅáË®≠ÊÑüÊ∏¨Âô®Ë≥áÊñôÂÆåÁæéÁÑ°Áº∫Ôºå‰ΩÜÁèæÂØ¶‰∏ñÁïåÁöÑÁí∞Â¢ÉÂèØËÉΩÂåÖÂê´Ëá™ÁÑ∂Âíå‰∫∫Â∑•ÊÑüÊ∏¨Âô®ÈõúË®äÂíåÊãíÁµï„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫Ê∫ñÔºåÂú®ÂÖ∑ÊúâÂèØË®≠ÂÆöÊÑüÊ∏¨Âô®ÊãíÁµïÊïàÊûúÁöÑÂ∞éËà™‰ªªÂãô‰∏≠ÔºåÂêåÊôÇ‰ΩøÁî®Âª£Ê≥õ‰ΩøÁî®ÂíåÊñ∞ËààÁöÑ DRL ÊºîÁÆóÊ≥ï„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÊúâËààË∂£ÊØîËºÉ‰∏çÂêåÁöÑ DRL ÊñπÊ≥ïÔºà‰æãÂ¶ÇÁÑ°Ê®°ÂûãÁöÑ PPO ËàáÂü∫ÊñºÊ®°ÂûãÁöÑ DreamerV3ÔºâÂ¶Ç‰ΩïÂèóÂà∞ÊÑüÊ∏¨Âô®ÊãíÁµïÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü DreamerV3 Âú®ÂÖ∑ÊúâÂãïÊÖãÁõÆÊ®ôÁöÑË¶ñË¶∫Á´ØÂà∞Á´ØÂ∞éËà™‰ªªÂãô‰∏≠ÂÑ™ÊñºÂÖ∂‰ªñÊñπÊ≥ïÔºåËÄåÂÖ∂‰ªñÊñπÊ≥ïÁÑ°Ê≥ïÂ≠∏ÁøíÈÄô‰∏ÄÈªû„ÄÇÊ≠§Â§ñÔºåDreamerV3 ÈÄöÂ∏∏Âú®ÊÑüÊ∏¨Âô®ÊãíÁµïÁöÑÁí∞Â¢É‰∏≠ÂÑ™ÊñºÂÖ∂‰ªñÊñπÊ≥ï„ÄÇÁÇ∫‰∫ÜÊèêÈ´òÁ©©ÂÅ•ÊÄßÔºåÊàëÂÄë‰ΩøÁî®Â∞çÊäóË®ìÁ∑¥‰∏¶Â±ïÁ§∫Âú®ÊãíÁµïÁöÑÁí∞Â¢É‰∏≠ÊîπÈÄ≤ÁöÑÊïàËÉΩÔºåÂÑòÁÆ°ÈÄôÈÄöÂ∏∏ÊúÉÂ∞çÈ¶ôËçâÁí∞Â¢ÉÈÄ†ÊàêÊïàËÉΩÊàêÊú¨„ÄÇÊàëÂÄëÈ†êÊúüÈÄôÂÄã‰∏çÂêå DRL ÊñπÊ≥ïÁöÑÂü∫Ê∫ñÂíåÂ∞çÊäóË®ìÁ∑¥ÁöÑ‰ΩøÁî®Â∞áÊàêÁÇ∫ÈñãÁôºÊõ¥Á≤æÁ¥∞Â∞éËà™Á≠ñÁï•ÁöÑËµ∑ÈªûÔºåÈÄô‰∫õÁ≠ñÁï•ËÉΩÂ§†ËôïÁêÜ‰∏çÁ¢∫ÂÆöÁöÑÂíåÊãíÁµïÁöÑÊÑüÊ∏¨Âô®ËÆÄÊï∏„ÄÇ

##### **Asymptotically Optimal Change Detection for Unnormalized Pre- and Post-Change Distributions**
2410.14615v1 by Arman Adibi, Sanjeev Kulkarni, H. Vincent Poor, Taposh Banerjee, Vahid Tarokh

This paper addresses the problem of detecting changes when only unnormalized
pre- and post-change distributions are accessible. This situation happens in
many scenarios in physics such as in ferromagnetism, crystallography,
magneto-hydrodynamics, and thermodynamics, where the energy models are
difficult to normalize.
  Our approach is based on the estimation of the Cumulative Sum (CUSUM)
statistics, which is known to produce optimal performance. We first present an
intuitively appealing approximation method. Unfortunately, this produces a
biased estimator of the CUSUM statistics and may cause performance degradation.
We then propose the Log-Partition Approximation Cumulative Sum (LPA-CUSUM)
algorithm based on thermodynamic integration (TI) in order to estimate the
log-ratio of normalizing constants of pre- and post-change distributions. It is
proved that this approach gives an unbiased estimate of the log-partition
function and the CUSUM statistics, and leads to an asymptotically optimal
performance. Moreover, we derive a relationship between the required sample
size for thermodynamic integration and the desired detection delay performance,
offering guidelines for practical parameter selection. Numerical studies are
provided demonstrating the efficacy of our approach.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢ËÆ®‰∫ÜÂú®Âè™ËÉΩËé∑ÂæóÊú™ÂΩí‰∏ÄÂåñÁöÑÂèòÊõ¥ÂâçÂíåÂèòÊõ¥ÂêéÂàÜÂ∏ÉÊó∂Ê£ÄÊµãÂèòÊõ¥ÁöÑÈóÆÈ¢ò„ÄÇËøôÁßçÊÉÖÂÜµÂú®ËÆ∏Â§öÁâ©ÁêÜÂú∫ÊôØ‰∏≠ÂèëÁîüÔºå‰æãÂ¶ÇÈìÅÁ£ÅÊÄß„ÄÅÊô∂‰ΩìÂ≠¶„ÄÅÁ£ÅÊµÅ‰ΩìÂä®ÂäõÂ≠¶ÂíåÁÉ≠ÂäõÂ≠¶ÔºåÂÖ∂‰∏≠ËÉΩÈáèÊ®°ÂûãÈöæ‰ª•ÂΩí‰∏ÄÂåñ„ÄÇ
Êàë‰ª¨ÁöÑÊñπÊ≥ïÂü∫‰∫éÁ¥ØÁßØÂíåÔºàCUSUMÔºâÁªüËÆ°ÁöÑ‰º∞ËÆ°ÔºåÂ∑≤Áü•ËøôÁßçÊñπÊ≥ïÂèØ‰ª•‰∫ßÁîüÊúÄ‰Ω≥ÊÄßËÉΩ„ÄÇÊàë‰ª¨È¶ñÂÖàÊèêÂá∫‰∏ÄÁßçÁõ¥ËßÇÂê∏Âºï‰∫∫ÁöÑËøë‰ººÊñπÊ≥ï„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåËøô‰ºö‰∫ßÁîü CUSUM ÁªüËÆ°ÁöÑÊúâÂÅè‰º∞ËÆ°ÔºåÂπ∂ÂèØËÉΩÂØºËá¥ÊÄßËÉΩ‰∏ãÈôç„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÂü∫‰∫éÁÉ≠ÂäõÂ≠¶ÁßØÂàÜÔºàTIÔºâÁöÑÂØπÊï∞ÂàÜÈÖçËøë‰ººÁ¥ØÁßØÂíåÔºàLPA-CUSUMÔºâÁÆóÊ≥ïÔºå‰ª•‰º∞ËÆ°ÂèòÊõ¥ÂâçÂíåÂèòÊõ¥ÂêéÂàÜÂ∏ÉÁöÑÂΩí‰∏ÄÂåñÂ∏∏Êï∞ÁöÑÂØπÊï∞ÊØî„ÄÇËØÅÊòé‰∫ÜËØ•ÊñπÊ≥ïÂØπÂØπÊï∞ÂàÜÈÖçÂáΩÊï∞Âíå CUSUM ÁªüËÆ°Êèê‰æõ‰∫ÜÊó†ÂÅè‰º∞ËÆ°ÔºåÂπ∂ÂØºËá¥Ê∏êËøëÊúÄ‰ºòÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Êé®ÂØºÂá∫ÁÉ≠ÂäõÂ≠¶ÁßØÂàÜÊâÄÈúÄÁöÑÊ†∑Êú¨Èáè‰∏éÊâÄÈúÄÁöÑÊ£ÄÊµãÂª∂ËøüÊÄßËÉΩ‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºå‰∏∫ÂÆûÈôÖÂèÇÊï∞ÈÄâÊã©Êèê‰æõ‰∫ÜÊåáÂØº„ÄÇÊèê‰æõÁöÑÊï∞ÂÄºÁ†îÁ©∂ËØÅÊòé‰∫ÜÊàë‰ª¨ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **DiSCo Meets LLMs: A Unified Approach for Sparse Retrieval and Contextual Distillation in Conversational Search**
2410.14609v1 by Simon Lupart, Mohammad Aliannejadi, Evangelos Kanoulas

Conversational Search (CS) is the task of retrieving relevant documents from
a corpus within a conversational context, combining retrieval with
conversational context modeling. With the explosion of Large Language Models
(LLMs), the CS field has seen major improvements with LLMs rewriting user
queries, accounting for conversational context. However, engaging LLMs at
inference time harms efficiency. Current methods address this by distilling
embeddings from human-rewritten queries to learn the context modeling task.
Yet, these approaches predominantly focus on context modeling, and only treat
the contrastive component of the retrieval task within a
distillation-independent loss term. To address these limitations, we propose a
new distillation method, as a relaxation of the previous objective, unifying
retrieval and context modeling. We relax the existing training objectives by
distilling similarity scores between conversations and documents, rather than
relying solely on representation learning. Our proposed distillation objective
allows for more freedom in the representation space and leverages the
contrastive nature of document relevance. Through experiments on Learned Sparse
Retrieval (LSR) across 5 CS datasets, our approach demonstrates substantial
improvements in both in-domain and out-of-domain retrieval performance,
outperforming state-of-the-art with gains of up to 6 points in recall for
out-of-domain datasets. Additionally, through the relaxation of the objective,
we propose a multi-teacher distillation, using multiple LLMs as teachers,
yielding additional gains, and outperforming the teachers themselves in
in-domain experiments. Finally, analysis of the sparsity of the models reveals
that our distillation allows for better control over the sparsity of the
trained models.

ÊëòË¶ÅÔºöÂ∞çË©±ÂºèÊêúÂ∞ã (CS) ÊòØ‰∏ÄÈ†ÖÂæûË™ûÊñôÂ∫´‰∏≠Êì∑ÂèñÁõ∏ÈóúÊñá‰ª∂ÁöÑÂ∑•‰ΩúÔºåÂÆÉÂú®Â∞çË©±ÂºèËÑàÁµ°‰∏≠ÁµêÂêàÊì∑ÂèñÂíåÂ∞çË©±ÂºèËÑàÁµ°Âª∫Ê®°„ÄÇÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁàÜÁÇ∏ÊÄßÁôºÂ±ïÔºåCS È†òÂüüÂú® LLM ÊîπÂØ´‰ΩøÁî®ËÄÖÊü•Ë©¢„ÄÅËÄÉÈáèÂ∞çË©±ÂºèËÑàÁµ°ÊñπÈù¢ÂèñÂæóÈáçÂ§ßÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºåÂú®Êé®Ë´ñÊôÇÈñì‰ΩøÁî® LLM ÊúÉÊêçÂÆ≥ÊïàÁéá„ÄÇÁõÆÂâçÁöÑËß£Ê±∫ÊñπÊ≥ïÊòØÂæû‰∫∫È°ûÊîπÂØ´ÁöÑÊü•Ë©¢‰∏≠ËêÉÂèñÂµåÂÖ•Ôºå‰ª•Â≠∏ÁøíËÑàÁµ°Âª∫Ê®°‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®ËÑàÁµ°Âª∫Ê®°‰∏äÔºåËÄå‰∏îÂÉÖÂú®Áç®Á´ãÊñºËêÉÂèñÁöÑÊêçÂ§±ÂáΩÊï∏‰∏≠ËôïÁêÜÊì∑Âèñ‰ªªÂãôÁöÑÂ∞çÊØîÂÖÉ‰ª∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑËêÉÂèñÊñπÊ≥ïÔºå‰ΩúÁÇ∫ÂÖàÂâçÁõÆÊ®ôÁöÑÊîæÂØ¨ÔºåÁµ±‰∏Ä‰∫ÜÊì∑ÂèñÂíåËÑàÁµ°Âª∫Ê®°„ÄÇÊàëÂÄëÈÄèÈÅéËêÉÂèñÂ∞çË©±ÂíåÊñá‰ª∂‰πãÈñìÁöÑÁõ∏‰ººÂ∫¶ÂàÜÊï∏ÔºåËÄå‰∏çÊòØÂÉÖ‰æùË≥¥ÊñºË°®ÂæµÂ≠∏ÁøíÔºå‰æÜÊîæÂØ¨ÁèæÊúâÁöÑË®ìÁ∑¥ÁõÆÊ®ô„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑËêÉÂèñÁõÆÊ®ôÂÖÅË®±Âú®Ë°®ÂæµÁ©∫Èñì‰∏≠ÊúâÊõ¥Â§ßÁöÑËá™Áî±Â∫¶Ôºå‰∏¶Âà©Áî®Êñá‰ª∂Áõ∏ÈóúÊÄßÁöÑÂ∞çÊØîÊÄßË≥™„ÄÇÈÄèÈÅéÂú® 5 ÂÄã CS Ë≥áÊñôÈõÜ‰∏äÂ∞çÂ≠∏ÁøíÁöÑÁ®ÄÁñèÊì∑Âèñ (LSR) ÈÄ≤Ë°åÂØ¶È©óÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®È†òÂüüÂÖßÂíåÈ†òÂüüÂ§ñÊì∑ÂèñÊïàËÉΩ‰∏äÈÉΩÂ±ïÁèæÂá∫È°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÂú®È†òÂüüÂ§ñË≥áÊñôÈõÜÁöÑÂè¨ÂõûÁéáÊñπÈù¢ÂÑ™ÊñºÁèæÊúâÊäÄË°ìÔºåÂ¢ûÁõäÈ´òÈÅî 6 Èªû„ÄÇÊ≠§Â§ñÔºåÈÄèÈÅéÊîæÂØ¨ÁõÆÊ®ôÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂ§öÊïôÂ∏´ËêÉÂèñÔºå‰ΩøÁî®Â§öÂÄã LLM ‰ΩúÁÇ∫ÊïôÂ∏´ÔºåÁî¢ÁîüÈ°çÂ§ñÁöÑÂ¢ûÁõäÔºå‰∏¶Âú®È†òÂüüÂÖßÂØ¶È©ó‰∏≠ÂÑ™ÊñºÊïôÂ∏´Êú¨Ë∫´„ÄÇÊúÄÂæåÔºåÂ∞çÊ®°ÂûãÁ®ÄÁñèÊÄßÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑËêÉÂèñÂÖÅË®±Êõ¥Â•ΩÂú∞ÊéßÂà∂Ë®ìÁ∑¥Ê®°ÂûãÁöÑÁ®ÄÁñèÊÄß„ÄÇ

##### **Streaming Deep Reinforcement Learning Finally Works**
2410.14606v1 by Mohamed Elsayed, Gautham Vasan, A. Rupam Mahmood

Natural intelligence processes experience as a continuous stream, sensing,
acting, and learning moment-by-moment in real time. Streaming learning, the
modus operandi of classic reinforcement learning (RL) algorithms like
Q-learning and TD, mimics natural learning by using the most recent sample
without storing it. This approach is also ideal for resource-constrained,
communication-limited, and privacy-sensitive applications. However, in deep RL,
learners almost always use batch updates and replay buffers, making them
computationally expensive and incompatible with streaming learning. Although
the prevalence of batch deep RL is often attributed to its sample efficiency, a
more critical reason for the absence of streaming deep RL is its frequent
instability and failure to learn, which we refer to as stream barrier. This
paper introduces the stream-x algorithms, the first class of deep RL algorithms
to overcome stream barrier for both prediction and control and match sample
efficiency of batch RL. Through experiments in Mujoco Gym, DM Control Suite,
and Atari Games, we demonstrate stream barrier in existing algorithms and
successful stable learning with our stream-x algorithms: stream Q, stream AC,
and stream TD, achieving the best model-free performance in DM Control Dog
environments. A set of common techniques underlies the stream-x algorithms,
enabling their success with a single set of hyperparameters and allowing for
easy extension to other algorithms, thereby reviving streaming RL.

ÊëòË¶ÅÔºöËá™ÁÑ∂Êô∫ËÉΩËôïÁêÜÁ∂ìÈ©ó‰ΩúÁÇ∫‰∏ÄÂÄãÈÄ£Á∫åÁöÑ‰∏≤ÊµÅÔºåÂú®ÂØ¶ÊôÇ‰∏≠ÊÑüÊ∏¨„ÄÅË°åÂãïÂíåÂ≠∏Áøí„ÄÇ‰∏≤ÊµÅÂ≠∏ÁøíÔºåÁ∂ìÂÖ∏Âº∑ÂåñÂ≠∏Áøí (RL) ÊºîÁÆóÊ≥ïÁöÑÈÅã‰ΩúÊ®°ÂºèÔºå‰æãÂ¶Ç Q Â≠∏ÁøíÂíå TDÔºåÈÄèÈÅé‰ΩøÁî®ÊúÄÊñ∞ÁöÑÁØÑ‰æãÔºàËÄå‰∏çÂÑ≤Â≠òÂÆÉÔºâ‰æÜÊ®°Êì¨Ëá™ÁÑ∂Â≠∏Áøí„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰πüÈÅ©Áî®ÊñºË≥áÊ∫êÂèóÈôê„ÄÅÈÄöË®äÂèóÈôêÂíåÈö±ÁßÅÊïèÊÑüÁöÑÊáâÁî®Á®ãÂºè„ÄÇÁÑ∂ËÄåÔºåÂú®Ê∑±Â∫¶ RL ‰∏≠ÔºåÂ≠∏ÁøíËÄÖÂπæ‰πéÁ∏ΩÊòØ‰ΩøÁî®ÊâπÊ¨°Êõ¥Êñ∞ÂíåÈáçÊí≠Á∑©Ë°ùÂçÄÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÂú®Ë®àÁÆó‰∏äÂæàÊòÇË≤¥Ôºå‰∏¶‰∏îËàá‰∏≤ÊµÅÂ≠∏Áøí‰∏çÁõ∏ÂÆπ„ÄÇÂÑòÁÆ°ÊâπÊ¨°Ê∑±Â∫¶ RL ÁöÑÁõõË°åÈÄöÂ∏∏Ê≠∏Âõ†ÊñºÂÖ∂ÁØÑ‰æãÊïàÁéáÔºå‰ΩÜÊ∑±Â∫¶‰∏≤ÊµÅ RL Áº∫Â∏≠ÁöÑ‰∏ÄÂÄãÊõ¥ÈáçË¶ÅÁöÑÂéüÂõ†ÊòØÂÖ∂È†ªÁπÅÁöÑ‰∏çÁ©©ÂÆöÊÄßÂíåÂ≠∏ÁøíÂ§±ÊïóÔºåÊàëÂÄëÁ®±‰πãÁÇ∫‰∏≤ÊµÅÂ±èÈöú„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü stream-x ÊºîÁÆóÊ≥ïÔºåÈÄôÊòØÁ¨¨‰∏ÄÈ°ûÂÖãÊúç‰∏≤ÊµÅÂ±èÈöúÁöÑÊ∑±Â∫¶ RL ÊºîÁÆóÊ≥ïÔºåÁî®ÊñºÈ†êÊ∏¨ÂíåÊéßÂà∂Ôºå‰∏¶‰∏îÁ¨¶ÂêàÊâπÊ¨° RL ÁöÑÁØÑ‰æãÊïàÁéá„ÄÇÈÄèÈÅéÂú® Mujoco Gym„ÄÅDM ÊéßÂà∂Â•ó‰ª∂Âíå Atari ÈÅäÊà≤‰∏≠ÁöÑÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÁèæÊúâÊºîÁÆóÊ≥ï‰∏≠ÁöÑ‰∏≤ÊµÅÂ±èÈöúÔºå‰ª•ÂèäÊàëÂÄë stream-x ÊºîÁÆóÊ≥ïÊàêÂäüÁöÑÁ©©ÂÆöÂ≠∏ÁøíÔºö‰∏≤ÊµÅ Q„ÄÅ‰∏≤ÊµÅ AC Âíå‰∏≤ÊµÅ TDÔºåÂú® DM ÊéßÂà∂ÁãóÁí∞Â¢É‰∏≠ÂØ¶ÁèæÊúÄ‰Ω≥ÁöÑÁÑ°Ê®°ÂûãÊïàËÉΩ„ÄÇ‰∏ÄÁµÑÂ∏∏Ë¶ãÁöÑÊäÄË°ìÊòØ stream-x ÊºîÁÆóÊ≥ïÁöÑÂü∫Á§éÔºåËÆìÂÆÉÂÄëËÉΩÂ§†‰ΩøÁî®ÂñÆ‰∏ÄÁµÑË∂ÖÂèÉÊï∏ÊàêÂäüÔºå‰∏¶ÂÖÅË®±ËºïÈ¨ÜÂª∂‰º∏Âà∞ÂÖ∂‰ªñÊºîÁÆóÊ≥ïÔºåÂæûËÄåÊÅ¢Âæ©‰∏≤ÊµÅ RL„ÄÇ

##### **How Does Data Diversity Shape the Weight Landscape of Neural Networks?**
2410.14602v1 by Yang Ba, Michelle V. Mancenido, Rong Pan

To enhance the generalization of machine learning models to unseen data,
techniques such as dropout, weight decay ($L_2$ regularization), and noise
augmentation are commonly employed. While regularization methods (i.e., dropout
and weight decay) are geared toward adjusting model parameters to prevent
overfitting, data augmentation increases the diversity of the input training
set, a method purported to improve accuracy and calibration error. In this
paper, we investigate the impact of each of these techniques on the parameter
space of neural networks, with the goal of understanding how they alter the
weight landscape in transfer learning scenarios. To accomplish this, we employ
Random Matrix Theory to analyze the eigenvalue distributions of pre-trained
models, fine-tuned using these techniques but using different levels of data
diversity, for the same downstream tasks. We observe that diverse data
influences the weight landscape in a similar fashion as dropout. Additionally,
we compare commonly used data augmentation methods with synthetic data created
by generative models. We conclude that synthetic data can bring more diversity
into real input data, resulting in a better performance on out-of-distribution
test instances.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÂ¢ûÂº∑Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÂ∞çÊú™Ë¶ãË≥áÊñôÁöÑÊ¶ÇÂåñËÉΩÂäõÔºåÂ∏∏‰ΩøÁî®Ë´∏Â¶Ç‰∏≠Ëºü„ÄÅÊ¨äÈáçË°∞Ê∏õÔºà$L_2$ Ê≠£ÂâáÂåñÔºâÂíåÈõúË®äÊì¥ÂÖÖÁ≠âÊäÄË°ì„ÄÇÈõñÁÑ∂Ê≠£ÂâáÂåñÊñπÊ≥ïÔºà‰æãÂ¶Ç‰∏≠ËºüÂíåÊ¨äÈáçË°∞Ê∏õÔºâÊó®Âú®Ë™øÊï¥Ê®°ÂûãÂèÉÊï∏‰ª•Èò≤Ê≠¢ÈÅéÂ∫¶Êì¨ÂêàÔºå‰ΩÜË≥áÊñôÊì¥ÂÖÖÂ¢ûÂä†‰∫ÜËº∏ÂÖ•Ë®ìÁ∑¥ÁµÑÁöÑÂ§öÊ®£ÊÄßÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊìöÁ®±ÂèØ‰ª•ÊîπÂñÑÊ∫ñÁ¢∫ÊÄßÂíåÊ†°Ê∫ñË™§Â∑ÆÁöÑÊñπÊ≥ï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄô‰∫õÊäÄË°ìÂ∞çÁ•ûÁ∂ìÁ∂≤Ë∑ØÂèÉÊï∏Á©∫ÈñìÁöÑÂΩ±ÈüøÔºåÁõÆÁöÑÊòØ‰∫ÜËß£ÂÆÉÂÄëÂ¶Ç‰ΩïÂú®ËΩâÁßªÂ≠∏ÁøíÂ†¥ÊôØ‰∏≠ÊîπËÆäÊ¨äÈáçÊôØËßÄ„ÄÇÁÇ∫‰∫ÜÈÅîÊàêÊ≠§ÁõÆÊ®ôÔºåÊàëÂÄëÊé°Áî®Èö®Ê©üÁü©Èô£ÁêÜË´ñ‰æÜÂàÜÊûêÈ†êË®ìÁ∑¥Ê®°ÂûãÁöÑÁâπÂæµÂÄºÂàÜ‰ΩàÔºå‰ΩøÁî®ÈÄô‰∫õÊäÄË°ìÈÄ≤Ë°åÂæÆË™øÔºå‰ΩÜ‰ΩøÁî®‰∏çÂêåÁ®ãÂ∫¶ÁöÑË≥áÊñôÂ§öÊ®£ÊÄßÔºå‰ª•Âü∑Ë°åÁõ∏ÂêåÁöÑ‰∏ãÊ∏∏‰ªªÂãô„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåÂ§öÊ®£ÂåñÁöÑË≥áÊñô‰ª•È°û‰ººÊñº‰∏≠ËºüÁöÑÊñπÂºèÂΩ±ÈüøÊ¨äÈáçÊôØËßÄ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞áÂ∏∏Áî®ÁöÑË≥áÊñôÊì¥ÂÖÖÊñπÊ≥ïËàáÁîüÊàêÊ®°ÂûãÊâÄÂª∫Á´ãÁöÑÂêàÊàêË≥áÊñôÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄëÂæóÂá∫ÁµêË´ñÔºåÂêàÊàêË≥áÊñôÂèØ‰ª•ÁÇ∫ÁúüÂØ¶Ëº∏ÂÖ•Ë≥áÊñôÂ∏∂‰æÜÊõ¥Â§öÊ®£ÊÄßÔºåÂæûËÄåÊèêÈ´òÂ∞çÂàÜÂ∏ÉÂ§ñÊ∏¨Ë©¶‰æãÈ†ÖÁöÑÊïàËÉΩ„ÄÇ

##### **Teaching Models to Balance Resisting and Accepting Persuasion**
2410.14596v1 by Elias Stengel-Eskin, Peter Hase, Mohit Bansal

Large language models (LLMs) are susceptible to persuasion, which can pose
risks when models are faced with an adversarial interlocutor. We take a first
step towards defending models against persuasion while also arguing that
defense against adversarial (i.e. negative) persuasion is only half of the
equation: models should also be able to accept beneficial (i.e. positive)
persuasion to improve their answers. We show that optimizing models for only
one side results in poor performance on the other. In order to balance positive
and negative persuasion, we introduce Persuasion-Balanced Training (or PBT),
which leverages multi-agent recursive dialogue trees to create data and trains
models via preference optimization to accept persuasion when appropriate. PBT
consistently improves resistance to misinformation and resilience to being
challenged while also resulting in the best overall performance on holistic
data containing both positive and negative persuasion. Crucially, we show that
PBT models are better teammates in multi-agent debates. We find that without
PBT, pairs of stronger and weaker models have unstable performance, with the
order in which the models present their answers determining whether the team
obtains the stronger or weaker model's performance. PBT leads to better and
more stable results and less order dependence, with the stronger model
consistently pulling the weaker one up.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂÆπÊòìÂèóÂà∞Ë™™ÊúçÔºåÁï∂Ê®°ÂûãÈù¢Â∞çÂ∞çÊäóÊÄßÂ∞çË©±ËÄÖÊôÇÔºåÈÄôÂèØËÉΩÊúÉÈÄ†ÊàêÈ¢®Èö™„ÄÇÊàëÂÄëÊé°ÂèñÁ¨¨‰∏ÄÊ≠•‰æÜ‰øùË≠∑Ê®°ÂûãÂÖçÊñºË™™ÊúçÔºåÂêåÊôÇ‰πü‰∏ªÂºµÈò≤Á¶¶Â∞çÊäóÊÄßÔºàÂç≥Ë≤†Èù¢ÔºâË™™ÊúçÂÉÖÊòØÁ≠âÂºèÁöÑ‰∏ÄÂçäÔºöÊ®°Âûã‰πüÊáâË©≤ËÉΩÂ§†Êé•ÂèóÊúâÁõäÁöÑÔºàÂç≥Ê≠£Èù¢ÁöÑÔºâË™™Êúç‰æÜÊîπÂñÑÂÖ∂Á≠îÊ°à„ÄÇÊàëÂÄëË°®ÊòéÔºåÂÉÖÈáùÂ∞ç‰∏ÄÊñπÂÑ™ÂåñÊ®°ÂûãÊúÉÂ∞éËá¥Âè¶‰∏ÄÊñπÁöÑÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÁÇ∫‰∫ÜÂπ≥Ë°°Ê≠£Èù¢ÂíåË≤†Èù¢Ë™™ÊúçÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜË™™ÊúçÂπ≥Ë°°Ë®ìÁ∑¥ÔºàÊàñ PBTÔºâÔºåÂÆÉÂà©Áî®Â§ö‰∏ªÈ´îÈÅûËø¥Â∞çË©±Ê®π‰æÜÂª∫Á´ãË≥áÊñôÔºå‰∏¶ÈÄèÈÅéÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ‰æÜË®ìÁ∑¥Ê®°ÂûãÔºå‰ª•‰æøÂú®ÈÅ©Áï∂ÊôÇÊé•ÂèóË™™Êúç„ÄÇPBT ÊåÅÁ∫åÊèêÈ´òÂ∞çÈåØË™§Ë≥áË®äÁöÑÊäµÊäóÂäõÔºå‰∏¶ÊèêÈ´òÊáâÂ∞çÊåëÊà∞ÁöÑÈüåÊÄßÔºåÂêåÊôÇÂú®ÂåÖÂê´Ê≠£Èù¢ÂíåË≤†Èù¢Ë™™ÊúçÁöÑÊï¥È´îË≥áÊñô‰∏≠‰πüÁî¢ÁîüÊúÄ‰Ω≥ÁöÑÊï¥È´îÊïàËÉΩ„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëË°®Êòé PBT Ê®°ÂûãÂú®Â§ö‰∏ªÈ´îËæØË´ñ‰∏≠ÊòØÊõ¥Â•ΩÁöÑÈöäÂèã„ÄÇÊàëÂÄëÁôºÁèæÔºåÊ≤íÊúâ PBTÔºåÊàêÂ∞çÁöÑËºÉÂº∑ÂíåËºÉÂº±Ê®°ÂûãÊïàËÉΩ‰∏çÁ©©ÂÆöÔºåÊ®°ÂûãÂëàÁèæÂÖ∂Á≠îÊ°àÁöÑÈ†ÜÂ∫èÊ±∫ÂÆö‰∫ÜÂúòÈöäÁç≤ÂæóËºÉÂº∑ÊàñËºÉÂº±Ê®°ÂûãÊïàËÉΩ„ÄÇPBT Â∞éÂêëÊõ¥Â•Ω„ÄÅÊõ¥Á©©ÂÆöÁöÑÁµêÊûúÔºå‰ª•ÂèäËºÉÂ∞ëÁöÑÈ†ÜÂ∫è‰æùË≥¥ÊÄßÔºåËºÉÂº∑ÁöÑÊ®°ÂûãÊåÅÁ∫åÊèêÂçáËºÉÂº±ÁöÑÊ®°Âûã„ÄÇ

##### **Toolshed: Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and Tool Knowledge Bases**
2410.14594v1 by Elias Lumer

Recent advancements in tool-equipped Agents (LLMs) have enabled complex tasks
like secure database interactions and multi-agent code development. However,
scaling tool capacity beyond agent reasoning or model limits remains a
challenge. In this paper, we address these challenges by introducing Toolshed
Knowledge Bases, a tool knowledge base (vector database) designed to store
enhanced tool representations and optimize tool selection for large-scale
tool-equipped Agents. Additionally, we propose Advanced RAG-Tool Fusion, a
novel ensemble of tool-applied advanced retrieval-augmented generation (RAG)
techniques across the pre-retrieval, intra-retrieval, and post-retrieval
phases, without requiring model fine-tuning. During pre-retrieval, tool
documents are enhanced with key information and stored in the Toolshed
Knowledge Base. Intra-retrieval focuses on query planning and transformation to
increase retrieval accuracy. Post-retrieval refines the retrieved tool
documents and enables self-reflection. Furthermore, by varying both the total
number of tools (tool-M) an Agent has access to and the tool selection
threshold (top-k), we address trade-offs between retrieval accuracy, agent
performance, and token cost. Our approach achieves 46%, 56%, and 47% absolute
improvements on the ToolE single-tool, ToolE multi-tool and Seal-Tools
benchmark datasets, respectively (Recall@5).

ÊëòË¶ÅÔºöÊúÄËøëÂú®Â∑•ÂÖ∑Âûã‰ª£ÁêÜ (LLM) ‰∏≠ÁöÑÂ∑•ÂÖ∑ÈÖçÂ§á‰∏äÁöÑËøõÊ≠•Â∑≤ÁªèËÉΩÊâßË°åÂ§çÊùÇÁöÑ‰ªªÂä°Ôºå‰æãÂ¶ÇÂÆâÂÖ®ÁöÑÊï∞ÊçÆÂ∫ì‰∫§‰∫íÂíåÂ§ö‰ª£ÁêÜ‰ª£Á†ÅÂºÄÂèë„ÄÇÁÑ∂ËÄåÔºåÂ∞ÜÂ∑•ÂÖ∑ÂÆπÈáèÊâ©Â±ïÂà∞‰ª£ÁêÜÊé®ÁêÜÊàñÊ®°ÂûãÊûÅÈôê‰πãÂ§ñ‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÈÄöËøáÂºïÂÖ•Â∑•ÂÖ∑Â∫ìÁü•ËØÜÂ∫ìÊù•Ëß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåËØ•Â∑•ÂÖ∑Áü•ËØÜÂ∫ìÔºàÂêëÈáèÊï∞ÊçÆÂ∫ìÔºâÊó®Âú®Â≠òÂÇ®Â¢ûÂº∫ÁöÑÂ∑•ÂÖ∑Ë°®Á§∫Âπ∂‰ºòÂåñÂ§ßËßÑÊ®°Â∑•ÂÖ∑Âûã‰ª£ÁêÜÁöÑÂ∑•ÂÖ∑ÈÄâÊã©„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÈ´òÁ∫ß RAG Â∑•ÂÖ∑ËûçÂêàÔºå‰∏ÄÁßçË∑®È¢ÑÊ£ÄÁ¥¢„ÄÅÊ£ÄÁ¥¢ÂÜÖÂíåÊ£ÄÁ¥¢ÂêéÈò∂ÊÆµÁöÑÊñ∞ÂûãÂ∑•ÂÖ∑Â∫îÁî®È´òÁ∫ßÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG) ÊäÄÊúØÁöÑÈõÜÊàêÔºåËÄåÊó†ÈúÄÊ®°ÂûãÂæÆË∞É„ÄÇÂú®È¢ÑÊ£ÄÁ¥¢ÊúüÈó¥ÔºåÂ∑•ÂÖ∑ÊñáÊ°£‰ºöÂæóÂà∞ÂÖ≥ÈîÆ‰ø°ÊÅØÁöÑÂ¢ûÂº∫Âπ∂Â≠òÂÇ®Âú®Â∑•ÂÖ∑Â∫ìÁü•ËØÜÂ∫ì‰∏≠„ÄÇÊ£ÄÁ¥¢ÂÜÖ‰æßÈáç‰∫éÊü•ËØ¢ËßÑÂàíÂíåËΩ¨Êç¢Ôºå‰ª•ÊèêÈ´òÊ£ÄÁ¥¢ÂáÜÁ°ÆÊÄß„ÄÇÊ£ÄÁ¥¢Âêé‰ºö‰ºòÂåñÊ£ÄÁ¥¢Âà∞ÁöÑÂ∑•ÂÖ∑ÊñáÊ°£Âπ∂ÊîØÊåÅËá™ÁúÅ„ÄÇÊ≠§Â§ñÔºåÈÄöËøáÊîπÂèò‰ª£ÁêÜÂèØËÆøÈóÆÁöÑÂ∑•ÂÖ∑ÊÄªÊï∞ÔºàÂ∑•ÂÖ∑ MÔºâÂíåÂ∑•ÂÖ∑ÈÄâÊã©ÈòàÂÄºÔºàtop-kÔºâÔºåÊàë‰ª¨Ëß£ÂÜ≥‰∫ÜÊ£ÄÁ¥¢ÂáÜÁ°ÆÊÄß„ÄÅ‰ª£ÁêÜÊÄßËÉΩÂíåÊ†áËÆ∞ÊàêÊú¨‰πãÈó¥ÁöÑÊùÉË°°„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú® ToolE ÂçïÂ∑•ÂÖ∑„ÄÅToolE Â§öÂ∑•ÂÖ∑Âíå Seal-Tools Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÂàÜÂà´ÂÆûÁé∞‰∫Ü 46%„ÄÅ56% Âíå 47% ÁöÑÁªùÂØπÊîπËøõÔºàÂè¨ÂõûÁéá@5Ôºâ„ÄÇ

##### **Temporal Fair Division of Indivisible Items**
2410.14593v1 by Edith Elkind, Alexander Lam, Mohamad Latifian, Tzeh Yuan Neoh, Nicholas Teh

We study a fair division model where indivisible items arrive sequentially,
and must be allocated immediately and irrevocably. Previous work on online fair
division has shown impossibility results in achieving approximate envy-freeness
under these constraints. In contrast, we consider an informed setting where the
algorithm has complete knowledge of future items, and aim to ensure that the
cumulative allocation at each round satisfies approximate envy-freeness --
which we define as temporal envy-freeness up to one item (TEF1). We focus on
settings where items can be exclusively goods or exclusively chores. For goods,
while TEF1 allocations may not always exist, we identify several special cases
where they do -- two agents, two item types, generalized binary valuations,
unimodal preferences -- and provide polynomial-time algorithms for these cases.
We also prove that determining the existence of a TEF1 allocation is NP-hard.
For chores, we establish analogous results for the special cases, but present a
slightly weaker intractability result. We also establish the incompatibility
between TEF1 and Pareto-optimality, with the implication that it is intractable
to find a TEF1 allocation that maximizes any $p$-mean welfare, even for two
agents.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÁ†îÁ©∂‰∏ÄÂÄãÂÖ¨Âπ≥ÂàÜÈÖçÊ®°ÂûãÔºåÂÖ∂‰∏≠‰∏çÂèØÂàÜÂâ≤ÁöÑÁâ©ÂìÅÊúÉ‰æùÂ∫èÊäµÈÅîÔºå‰∏¶‰∏îÂøÖÈ†àÁ´ãÂç≥‰∏î‰∏çÂèØÊí§Èä∑Âú∞ÂàÜÈÖç„ÄÇÂÖàÂâçÈóúÊñºÁ∑ö‰∏äÂÖ¨Âπ≥ÂàÜÈÖçÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåÂú®ÈÄô‰∫õÈôêÂà∂‰∏ãÔºå‰∏çÂèØËÉΩÂØ¶ÁèæËøë‰ººÁÑ°Â¶í„ÄÇÁõ∏ÂèçÂú∞ÔºåÊàëÂÄëËÄÉÊÖÆ‰∏ÄÂÄãÁü•ÊÉÖË®≠ÂÆöÔºåÂÖ∂‰∏≠ÊºîÁÆóÊ≥ïÂ∞çÊú™‰æÜÁöÑÁâ©ÂìÅÊúâÂÆåÊï¥ÁöÑË™çË≠òÔºå‰∏¶Êó®Âú®Á¢∫‰øùÊØè‰∏ÄËº™ÁöÑÁ¥ØÁ©çÂàÜÈÖçÊªøË∂≥Ëøë‰ººÁÑ°Â¶í‚Äî‚ÄîÊàëÂÄëÂ∞áÂÖ∂ÂÆöÁæ©ÁÇ∫ÊúÄÂ§ö‰∏ÄÈ†ÖÁöÑÊö´ÊôÇÁÑ°Â¶í (TEF1)„ÄÇÊàëÂÄëÂ∞àÊ≥®ÊñºÁâ©ÂìÅÂèØ‰ª•ÊòØÁ¥îÁ≤πÁöÑÁâ©ÂìÅÊàñÁ¥îÁ≤πÁöÑÂÆ∂ÂãôÁöÑË®≠ÂÆö„ÄÇÂ∞çÊñºÁâ©ÂìÅÔºåÂÑòÁÆ° TEF1 ÂàÜÈÖçÂèØËÉΩ‰∏¶‰∏çÁ∏ΩÊòØÂ≠òÂú®Ôºå‰ΩÜÊàëÂÄëÊâæÂá∫ÂÆÉÂÄëÂ≠òÂú®ÁöÑÂπæÂÄãÁâπÊÆäÊÉÖÊ≥Å‚Äî‚ÄîÂÖ©ÂÄã‰ª£ÁêÜ‰∫∫„ÄÅÂÖ©Á®ÆÁâ©ÂìÅÈ°ûÂûã„ÄÅÂª£Áæ©‰∫åÂÖÉ‰º∞ÂÄº„ÄÅÂñÆÂ≥∞ÂÅèÂ•Ω‚Äî‚Äî‰∏¶ÁÇ∫ÈÄô‰∫õÊÉÖÊ≥ÅÊèê‰æõÂ§öÈ†ÖÂºèÊôÇÈñìÊºîÁÆóÊ≥ï„ÄÇÊàëÂÄë‰πüË≠âÊòéÁ¢∫ÂÆö TEF1 ÂàÜÈÖçÁöÑÂ≠òÂú®ÊòØ NP-hard„ÄÇÂ∞çÊñºÂÆ∂ÂãôÔºåÊàëÂÄëÁÇ∫ÁâπÊÆäÊÉÖÊ≥ÅÂª∫Á´ãÈ°û‰ººÁöÑÁµêÊûúÔºå‰ΩÜÊèêÂá∫‰∏ÄÂÄãÁ®çÂæÆÂº±‰∏ÄÈªûÁöÑÈõ£‰ª•ËôïÁêÜÁöÑÁµêÊûú„ÄÇÊàëÂÄë‰πüÂª∫Á´ã TEF1 ÂíåÂ∏ïÁ¥ØÊâòÊúÄÂÑ™‰πãÈñìÁöÑ‰∏çÁõ∏ÂÆπÊÄßÔºåÊöóÁ§∫ÊâæÂá∫‰∏ÄÂÄã TEF1 ÂàÜÈÖç‰ª•ÊúÄÂ§ßÂåñ‰ªª‰Ωï p ÂùáÂÄºÁ¶èÂà©ÔºåÂç≥‰ΩøÂ∞çÊñºÂÖ©ÂÄã‰ª£ÁêÜ‰∫∫Ôºå‰πüÊòØÈõ£‰ª•ËôïÁêÜÁöÑ„ÄÇ</paragraph>

##### **Dialetto, ma Quanto Dialetto? Transcribing and Evaluating Dialects on a Continuum**
2410.14589v1 by Ryan Soh-Eun Shim, Barbara Plank

There is increasing interest in looking at dialects in NLP. However, most
work to date still treats dialects as discrete categories. For instance,
evaluative work in variation-oriented NLP for English often works with Indian
English or African-American Venacular English as homogeneous categories (Faisal
et al., 2024; Ziems et al., 2023), yet even within one variety there is
substantial variation. We examine within-dialect variation and show that
performance critically varies within categories. We measure speech-to-text
performance on Italian dialects, and empirically observe a geographical
performance disparity. This disparity correlates substantially (-0.5) with
linguistic similarity to the highest performing dialect variety. We
cross-examine our results against dialectometry methods, and interpret the
performance disparity to be due to a bias towards dialects that are more
similar to the standard variety in the speech-to-text model examined. We
additionally leverage geostatistical methods to predict zero-shot performance
at unseen sites, and find the incorporation of geographical information to
substantially improve prediction performance, indicating there to be
geographical structure in the performance distribution.

ÊëòË¶ÅÔºöËøë‰æÜÂú® NLP ‰∏≠ËßÄÂØüÊñπË®ÄÁöÑËààË∂£Êó•ÁõäÂ¢ûÂä†„ÄÇÁÑ∂ËÄåÔºåËøÑ‰ªäÁÇ∫Ê≠¢ÔºåÂ§ßÂ§öÊï∏Â∑•‰Ωú‰ªçÂ∞áÊñπË®ÄË¶ñÁÇ∫Èõ¢Êï£È°ûÂà•„ÄÇ‰æãÂ¶ÇÔºåÈáùÂ∞çËã±Ë™ûÁöÑËÆäÁï∞Â∞éÂêë NLP ‰∏≠ÁöÑË©ïÈáèÂ∑•‰ΩúÔºåÈÄöÂ∏∏Â∞áÂç∞Â∫¶Ëã±Ë™ûÊàñÈùûË£îÁæéÂúã‰∫∫ÁôΩË©±Ëã±Ë™ûË¶ñÁÇ∫ÂêåË≥™È°ûÂà•ÔºàFaisal Á≠â‰∫∫Ôºå2024 Âπ¥ÔºõZiems Á≠â‰∫∫Ôºå2023 Âπ¥ÔºâÔºå‰ΩÜÂç≥‰ΩøÂú®‰∏ÄÂÄãËÆäÈ´îÂÖßÈÉ®‰πüÂ≠òÂú®È°ØËëóÁöÑËÆäÁï∞„ÄÇÊàëÂÄëÊé¢Ë®éÊñπË®ÄÂÖßÈÉ®ËÆäÁï∞Ôºå‰∏¶È°ØÁ§∫Âú®È°ûÂà•ÂÖßÈÉ®ÔºåÊïàËÉΩÊúâÈ°ØËëóÁöÑÂ∑ÆÁï∞„ÄÇÊàëÂÄëÊ∏¨ÈáèÁæ©Â§ßÂà©ÊñπË®ÄÁöÑË™ûÈü≥ËΩâÊñáÂ≠óÊïàËÉΩÔºå‰∏¶ÈÄèÈÅéÂØ¶Ë≠âËßÄÂØüÂà∞Âú∞ÁêÜÊïàËÉΩÂ∑ÆÁï∞„ÄÇÈÄôÁ®ÆÂ∑ÆÁï∞ËàáÊïàËÉΩÊúÄÈ´òÁöÑÊñπË®ÄËÆäÈ´îÁöÑË™ûË®ÄÁõ∏‰ººÊÄßÈ°ØËëóÁõ∏ÈóúÔºà-0.5Ôºâ„ÄÇÊàëÂÄëÊ†πÊìöÊñπË®ÄÊ∏¨ÈáèÊ≥ïÊ™¢Ë¶ñÊàëÂÄëÁöÑÁµêÊûúÔºå‰∏¶Â∞áÊïàËÉΩÂ∑ÆÁï∞Ëß£ÈáãÁÇ∫ÂÅèÂêëÂú®ÊâÄÊ™¢Ë¶ñÁöÑË™ûÈü≥ËΩâÊñáÂ≠óÊ®°Âûã‰∏≠Êõ¥È°û‰ººÊ®ôÊ∫ñËÆäÈ´îÁöÑÊñπË®Ä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®Âú∞Áµ±Ë®àÊñπÊ≥ïÈ†êÊ∏¨Êú™Ë¶ãÂú∞ÈªûÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊïàËÉΩÔºå‰∏¶ÁôºÁèæÂú∞ÁêÜË≥áË®äÁöÑÁ¥çÂÖ•È°ØËëóÊîπÂñÑÈ†êÊ∏¨ÊïàËÉΩÔºåÈÄôË°®Á§∫ÊïàËÉΩÂàÜ‰Ωà‰∏≠Â≠òÂú®Âú∞ÁêÜÁµêÊßã„ÄÇ

##### **Neural Combinatorial Clustered Bandits for Recommendation Systems**
2410.14586v1 by Baran Atalar, Carlee Joe-Wong

We consider the contextual combinatorial bandit setting where in each round,
the learning agent, e.g., a recommender system, selects a subset of "arms,"
e.g., products, and observes rewards for both the individual base arms, which
are a function of known features (called "context"), and the super arm (the
subset of arms), which is a function of the base arm rewards. The agent's goal
is to simultaneously learn the unknown reward functions and choose the
highest-reward arms. For example, the "reward" may represent a user's
probability of clicking on one of the recommended products. Conventional bandit
models, however, employ restrictive reward function models in order to obtain
performance guarantees. We make use of deep neural networks to estimate and
learn the unknown reward functions and propose Neural UCB Clustering
(NeUClust), which adopts a clustering approach to select the super arm in every
round by exploiting underlying structure in the context space. Unlike prior
neural bandit works, NeUClust uses a neural network to estimate the super arm
reward and select the super arm, thus eliminating the need for a known
optimization oracle. We non-trivially extend prior neural combinatorial bandit
works to prove that NeUClust achieves
$\widetilde{O}\left(\widetilde{d}\sqrt{T}\right)$ regret, where $\widetilde{d}$
is the effective dimension of a neural tangent kernel matrix, $T$ the number of
rounds. Experiments on real world recommendation datasets show that NeUClust
achieves better regret and reward than other contextual combinatorial and
neural bandit algorithms.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëËÄÉÊÖÆÊÉÖÂ¢ÉÁµÑÂêàÂºèË≥≠ÂæíÂïèÈ°åÔºåÂú®ÊØè‰∏ÄËº™‰∏≠ÔºåÂ≠∏Áøí‰ª£ÁêÜÔºà‰æãÂ¶ÇÊé®Ëñ¶Á≥ªÁµ±ÔºâÊúÉÈÅ∏Êìá‰∏ÄÂÄã„ÄåÊâãËáÇ„ÄçÁöÑÂ≠êÈõÜÔºà‰æãÂ¶ÇÁî¢ÂìÅÔºâÔºå‰∏¶ËßÄÂØüÂÄãÂà•Âü∫Êú¨ÊâãËáÇÁöÑÁçéÂãµÔºåÈÄô‰∫õÁçéÂãµÊòØÂ∑≤Áü•ÁâπÂæµÔºàÁ®±ÁÇ∫„ÄåÊÉÖÂ¢É„ÄçÔºâÁöÑÂáΩÊï∏Ôºå‰ª•ÂèäË∂ÖÁ¥öÊâãËáÇÔºàÊâãËáÇÁöÑÂ≠êÈõÜÔºâÔºåÈÄôÊòØÂü∫Êú¨ÊâãËáÇÁçéÂãµÁöÑÂáΩÊï∏„ÄÇ‰ª£ÁêÜÁöÑÁõÆÊ®ôÊòØÂêåÊôÇÂ≠∏ÁøíÊú™Áü•ÁöÑÁçéÂãµÂáΩÊï∏Ôºå‰∏¶ÈÅ∏ÊìáÊúÄÈ´òÁçéÂãµÁöÑÊâãËáÇ„ÄÇ‰æãÂ¶ÇÔºå„ÄåÁçéÂãµ„ÄçÂèØËÉΩ‰ª£Ë°®‰ΩøÁî®ËÄÖÈªûÊìäÊé®Ëñ¶Áî¢ÂìÅ‰πã‰∏ÄÁöÑÊ©üÁéá„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑË≥≠ÂæíÊ®°ÂûãÊé°Áî®ÈôêÂà∂ÊÄßÁçéÂãµÂáΩÊï∏Ê®°ÂûãÔºå‰ª•Áç≤ÂæóÊïàËÉΩ‰øùË≠â„ÄÇÊàëÂÄëÂà©Áî®Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø‰æÜ‰º∞Ë®àÂíåÂ≠∏ÁøíÊú™Áü•ÁöÑÁçéÂãµÂáΩÊï∏Ôºå‰∏¶ÊèêÂá∫Á•ûÁ∂ì UCB ËÅöÈ°ûÔºàNeUClustÔºâÔºåÂÆÉÊé°Áî®ËÅöÈ°ûÊñπÊ≥ï‰æÜÈÅ∏ÊìáÊØè‰∏ÄËº™ÁöÑË∂ÖÁ¥öÊâãËáÇÔºåËóâÁî±Âà©Áî®ÊÉÖÂ¢ÉÁ©∫Èñì‰∏≠ÁöÑÂ∫ïÂ±§ÁµêÊßã„ÄÇËàáÂÖàÂâçÁöÑÁ•ûÁ∂ìË≥≠ÂæíÂ∑•‰Ωú‰∏çÂêåÔºåNeUClust ‰ΩøÁî®Á•ûÁ∂ìÁ∂≤Ë∑Ø‰æÜ‰º∞Ë®àË∂ÖÁ¥öÊâãËáÇÁçéÂãµ‰∏¶ÈÅ∏ÊìáË∂ÖÁ¥öÊâãËáÇÔºåÂõ†Ê≠§Ê∂àÈô§‰∫ÜÂ∑≤Áü•ÊúÄ‰Ω≥ÂåñÈ†êË®ÄÁöÑÈúÄÊ±Ç„ÄÇÊàëÂÄëÈùûÂπ≥Âá°Âú∞Êì¥Â±ïÂÖàÂâçÁöÑÁ•ûÁ∂ìÁµÑÂêàÂºèË≥≠ÂæíÂ∑•‰ΩúÔºå‰ª•Ë≠âÊòé NeUClust ÈÅîÂà∞
$\widetilde{O}\left(\widetilde{d}\sqrt{T}\right)$ ÂæåÊÇîÔºåÂÖ∂‰∏≠ $\widetilde{d}$
ÊòØÁ•ûÁ∂ìÂàáÁ∑öÊ†∏Áü©Èô£ÁöÑÊúâÊïàÁ∂≠Â∫¶Ôºå$T$ ÊòØËº™Êï∏„ÄÇÂú®ÁúüÂØ¶‰∏ñÁïåÊé®Ëñ¶Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåNeUClust ÊØîÂÖ∂‰ªñÊÉÖÂ¢ÉÁµÑÂêàÂºèÂíåÁ•ûÁ∂ìË≥≠ÂæíÊºîÁÆóÊ≥ïÁç≤ÂæóÊõ¥Â•ΩÁöÑÂæåÊÇîÂíåÁçéÂãµ„ÄÇ</paragraph>

##### **Do LLMs estimate uncertainty well in instruction-following?**
2410.14582v1 by Juyeon Heo, Miao Xiong, Christina Heinze-Deml, Jaya Narain

Large language models (LLMs) could be valuable personal AI agents across
various domains, provided they can precisely follow user instructions. However,
recent studies have shown significant limitations in LLMs'
instruction-following capabilities, raising concerns about their reliability in
high-stakes applications. Accurately estimating LLMs' uncertainty in adhering
to instructions is critical to mitigating deployment risks. We present, to our
knowledge, the first systematic evaluation of the uncertainty estimation
abilities of LLMs in the context of instruction-following. Our study identifies
key challenges with existing instruction-following benchmarks, where multiple
factors are entangled with uncertainty stems from instruction-following,
complicating the isolation and comparison across methods and models. To address
these issues, we introduce a controlled evaluation setup with two benchmark
versions of data, enabling a comprehensive comparison of uncertainty estimation
methods under various conditions. Our findings show that existing uncertainty
methods struggle, particularly when models make subtle errors in instruction
following. While internal model states provide some improvement, they remain
inadequate in more complex scenarios. The insights from our controlled
evaluation setups provide a crucial understanding of LLMs' limitations and
potential for uncertainty estimation in instruction-following tasks, paving the
way for more trustworthy AI agents.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØÊàêÁÇ∫ÂêÑÁ®ÆÈ†òÂüü‰∏≠ÂØ∂Ë≤¥ÁöÑÂÄã‰∫∫ AI ‰ª£ÁêÜÔºåÂè™Ë¶ÅÂÆÉÂÄëËÉΩÁ≤æÁ¢∫ÈÅµÂæ™‰ΩøÁî®ËÄÖÁöÑÊåáÁ§∫„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÁöÑÁ†îÁ©∂È°ØÁ§∫ LLM Âú®ÈÅµÂæ™ÊåáÁ§∫ÁöÑËÉΩÂäõ‰∏äÂ≠òÂú®È°ØËëóÁöÑÈôêÂà∂ÔºåÂºïÁôº‰∫Ü‰∫∫ÂÄëÂ∞çÂÖ∂Âú®È´òÈ¢®Èö™ÊáâÁî®‰∏≠ÂèØÈù†ÊÄßÁöÑÊìîÊÜÇ„ÄÇÁ≤æÁ¢∫‰º∞Ë®à LLM Âú®ÈÅµÂæ™ÊåáÁ§∫ÊôÇÁöÑÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂ∞çÊñºÈôç‰ΩéÈÉ®ÁΩ≤È¢®Èö™Ëá≥ÈóúÈáçË¶Å„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LLM Âú®ÈÅµÂæ™ÊåáÁ§∫ÁöÑËÉåÊôØ‰∏ã‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àËÉΩÂäõÁöÑÁ¨¨‰∏ÄÂÄãÁ≥ªÁµ±Ë©ï‰º∞„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Á¢∫ÂÆö‰∫ÜÁèæÊúâÈÅµÂæ™ÊåáÁ§∫Âü∫Ê∫ñÁöÑÈóúÈçµÊåëÊà∞ÔºåÂÖ∂‰∏≠Â§öÂÄãÂõ†Á¥†Ëàá‰∏çÁ¢∫ÂÆöÊÄßÁ≥æÁ∫èÂú®‰∏ÄËµ∑ÔºåÂ∞éËá¥ÈÅµÂæ™ÊåáÁ§∫ÁöÑË§áÈõúÊÄßÔºå‰ΩøÂæóË∑®ÊñπÊ≥ïÂíåÊ®°ÂûãÁöÑÈöîÈõ¢ÂíåÊØîËºÉËÆäÂæóË§áÈõú„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖ∑ÊúâÂÖ©ÂÄãÂü∫Ê∫ñÁâàÊú¨Ë≥áÊñôÁöÑÂèóÊéßË©ï‰º∞Ë®≠ÂÆöÔºåÂæûËÄåÂèØ‰ª•Âú®ÂêÑÁ®ÆÊ¢ù‰ª∂‰∏ãÂ∞ç‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÊñπÊ≥ïÈÄ≤Ë°åÂÖ®Èù¢ÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÁèæÊúâÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÊñπÊ≥ïÂ≠òÂú®Âõ∞Èõ£ÔºåÁâπÂà•ÊòØÂú®Ê®°ÂûãÂú®ÈÅµÂæ™ÊåáÁ§∫ÊôÇÂá∫ÁèæÁ¥∞ÂæÆÈåØË™§ÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇÈõñÁÑ∂ÂÖßÈÉ®Ê®°ÂûãÁãÄÊÖãÊèê‰æõ‰∫Ü‰∏Ä‰∫õÊîπÈÄ≤Ôºå‰ΩÜÂÆÉÂÄëÂú®Êõ¥Ë§áÈõúÁöÑÂ†¥ÊôØ‰∏≠‰ªçÁÑ∂‰∏çË∂≥„ÄÇÊàëÂÄëÂèóÊéßË©ï‰º∞Ë®≠ÂÆö‰∏≠ÁöÑË¶ãËß£Êèê‰æõ‰∫ÜÂ∞ç LLM Âú®ÈÅµÂæ™ÊåáÁ§∫‰ªªÂãô‰∏≠‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÁöÑÈôêÂà∂ÂíåÊΩõÂäõÁöÑÈóúÈçµÁêÜËß£ÔºåÁÇ∫Êõ¥ÂÄºÂæó‰ø°Ë≥¥ÁöÑ AI ‰ª£ÁêÜÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

##### **Optimizing Attention with Mirror Descent: Generalized Max-Margin Token Selection**
2410.14581v1 by Aaron Alvarado Kristanto Julistiono, Davoud Ataee Tarzanagh, Navid Azizan

Attention mechanisms have revolutionized several domains of artificial
intelligence, such as natural language processing and computer vision, by
enabling models to selectively focus on relevant parts of the input data. While
recent work has characterized the optimization dynamics of gradient descent
(GD) in attention-based models and the structural properties of its preferred
solutions, less is known about more general optimization algorithms such as
mirror descent (MD). In this paper, we investigate the convergence properties
and implicit biases of a family of MD algorithms tailored for softmax attention
mechanisms, with the potential function chosen as the $p$-th power of the
$\ell_p$-norm. Specifically, we show that these algorithms converge in
direction to a generalized hard-margin SVM with an $\ell_p$-norm objective when
applied to a classification problem using a softmax attention model. Notably,
our theoretical results reveal that the convergence rate is comparable to that
of traditional GD in simpler models, despite the highly nonlinear and nonconvex
nature of the present problem. Additionally, we delve into the joint
optimization dynamics of the key-query matrix and the decoder, establishing
conditions under which this complex joint optimization converges to their
respective hard-margin SVM solutions. Lastly, our numerical experiments on real
data demonstrate that MD algorithms improve generalization over standard GD and
excel in optimal token selection.

ÊëòË¶ÅÔºöÊ≥®ÊÑèÂäõÊú∫Âà∂ÈÄöËøáËÆ©Ê®°ÂûãÊúâÈÄâÊã©Âú∞ÂÖ≥Ê≥®ËæìÂÖ•Êï∞ÊçÆ‰∏≠ÁöÑÁõ∏ÂÖ≥ÈÉ®ÂàÜÔºåÂΩªÂ∫ïÊîπÂèò‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÁöÑÂá†‰∏™È¢ÜÂüüÔºå‰æãÂ¶ÇËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåËÆ°ÁÆóÊú∫ËßÜËßâ„ÄÇËôΩÁÑ∂ÊúÄËøëÁöÑÁ†îÁ©∂ÊèèËø∞‰∫ÜÂü∫‰∫éÊ≥®ÊÑèÂäõÁöÑÊ®°Âûã‰∏≠Ê¢ØÂ∫¶‰∏ãÈôç (GD) ÁöÑ‰ºòÂåñÂä®ÊÄÅÂèäÂÖ∂È¶ñÈÄâËß£ÂÜ≥ÊñπÊ°àÁöÑÁªìÊûÑÂ±ûÊÄßÔºå‰ΩÜÂØπ‰∫éÈïúÂÉè‰∏ãÈôç (MD) Á≠âÊõ¥ÈÄöÁî®ÁöÑ‰ºòÂåñÁÆóÊ≥ï‰∫ÜËß£ËæÉÂ∞ë„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Á†îÁ©∂‰∫Ü‰∏ì‰∏∫ softmax Ê≥®ÊÑèÂäõÊú∫Âà∂ËÆæËÆ°ÁöÑ MD ÁÆóÊ≥ïÁ≥ªÂàóÁöÑÊî∂ÊïõÂ±ûÊÄßÂíåÈöêÂºèÂÅèÂ∑ÆÔºåÂÖ∂‰∏≠ÊΩúÂú®ÂáΩÊï∞ÈÄâÊã©‰∏∫ $\ell_p$-ËåÉÊï∞ÁöÑ $p$-Ê¨°ÂπÇ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Ë°®ÊòéÂΩìËøô‰∫õÁÆóÊ≥ïÂ∫îÁî®‰∫é‰ΩøÁî® softmax Ê≥®ÊÑèÂäõÊ®°ÂûãÁöÑÂàÜÁ±ªÈóÆÈ¢òÊó∂ÔºåÂÆÉ‰ª¨Âú®ÊñπÂêë‰∏äÊî∂ÊïõÂà∞ÂÖ∑Êúâ $\ell_p$-ËåÉÊï∞ÁõÆÊ†áÁöÑÂπø‰πâÁ°¨ËæπË∑ù SVM„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàë‰ª¨ÁöÑÁêÜËÆ∫ÁªìÊûúË°®ÊòéÔºåÂ∞ΩÁÆ°ÂΩìÂâçÈóÆÈ¢òÁöÑÈùûÁ∫øÊÄßÂíåÈùûÂá∏ÊÄßÔºåÊî∂ÊïõÈÄüÂ∫¶‰∏éÊõ¥ÁÆÄÂçïÊ®°Âûã‰∏≠ÁöÑ‰º†Áªü GD Áõ∏ÂΩì„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Ê∑±ÂÖ•Á†îÁ©∂‰∫ÜÈîÆÊü•ËØ¢Áü©ÈòµÂíåËß£Á†ÅÂô®ÁöÑËÅîÂêà‰ºòÂåñÂä®ÊÄÅÔºåÂª∫Á´ã‰∫ÜÂ§çÊùÇËÅîÂêà‰ºòÂåñÊî∂ÊïõÂà∞ÂÖ∂ÂêÑËá™ÁöÑÁ°¨ËæπË∑ù SVM Ëß£ÁöÑÊù°‰ª∂„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Âú®ÁúüÂÆûÊï∞ÊçÆ‰∏äÁöÑÊï∞ÂÄºÂÆûÈ™åË°®ÊòéÔºåMD ÁÆóÊ≥ïÊîπËøõ‰∫ÜÂØπÊ†áÂáÜ GD ÁöÑÊ≥õÂåñÔºåÂπ∂Âú®ÊúÄ‰Ω≥Ê†áËÆ∞ÈÄâÊã©‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇ

##### **Towards Unsupervised Validation of Anomaly-Detection Models**
2410.14579v1 by Lihi Idan

Unsupervised validation of anomaly-detection models is a highly challenging
task. While the common practices for model validation involve a labeled
validation set, such validation sets cannot be constructed when the underlying
datasets are unlabeled. The lack of robust and efficient unsupervised
model-validation techniques presents an acute challenge in the implementation
of automated anomaly-detection pipelines, especially when there exists no prior
knowledge of the model's performance on similar datasets. This work presents a
new paradigm to automated validation of anomaly-detection models, inspired by
real-world, collaborative decision-making mechanisms. We focus on two
commonly-used, unsupervised model-validation tasks -- model selection and model
evaluation -- and provide extensive experimental results that demonstrate the
accuracy and robustness of our approach on both tasks.

ÊëòË¶ÅÔºöÁï∞Â∏∏ÂÅµÊ∏¨Ê®°ÂûãÁöÑÁÑ°Áõ£Áù£È©óË≠âÊòØ‰∏ÄÈ†ÖÊ•µÂÖ∑ÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÈõñÁÑ∂Ê®°ÂûãÈ©óË≠âÁöÑÂ∏∏Ë¶ãÂÅöÊ≥ïÊ∂âÂèäÊ®ôË®òÈ©óË≠âÈõÜÔºå‰ΩÜÂú®Âü∫Á§éË≥áÊñôÈõÜÊú™Ê®ôË®òÊôÇÁÑ°Ê≥ïÂª∫ÊßãÊ≠§È°ûÈ©óË≠âÈõÜ„ÄÇÁº∫‰πèÁ©©ÂÅ•‰∏îÊúâÊïàÁöÑÁÑ°Áõ£Áù£Ê®°ÂûãÈ©óË≠âÊäÄË°ìÂú®Ëá™ÂãïÂåñÁï∞Â∏∏ÂÅµÊ∏¨ÁÆ°Á∑öÁöÑÂØ¶‰Ωú‰∏≠ÈÄ†ÊàêÂö¥Â≥ªÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®Â∞çÊ®°ÂûãÂú®È°û‰ººË≥áÊñôÈõÜ‰∏äÁöÑÊïàËÉΩÊ≤íÊúâÂÖàÈ©óÁü•Ë≠òÊôÇ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÁØÑ‰æãÔºåÁî®ÊñºÁï∞Â∏∏ÂÅµÊ∏¨Ê®°ÂûãÁöÑËá™ÂãïÂåñÈ©óË≠âÔºåÂÖ∂ÈùàÊÑü‰æÜËá™ÊñºÁèæÂØ¶‰∏ñÁïåÁöÑÂçî‰ΩúÊ±∫Á≠ñÊ©üÂà∂„ÄÇÊàëÂÄëÂ∞àÊ≥®ÊñºÂÖ©ÂÄãÂ∏∏Ë¶ãÁöÑÁÑ°Áõ£Áù£Ê®°ÂûãÈ©óË≠â‰ªªÂãôÔºöÊ®°ÂûãÈÅ∏ÊìáÂíåÊ®°ÂûãË©ï‰º∞Ôºå‰∏¶Êèê‰æõÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúÔºåË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÂÖ©ÂÄã‰ªªÂãô‰∏äÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÅ•ÊÄß„ÄÇ

##### **Large Language Models Are Overparameterized Text Encoders**
2410.14578v1 by Thennal D K, Tim Fischer, Chris Biemann

Large language models (LLMs) demonstrate strong performance as text embedding
models when finetuned with supervised contrastive training. However, their
large size balloons inference time and memory requirements. In this paper, we
show that by pruning the last $p\%$ layers of an LLM before supervised training
for only 1000 steps, we can achieve a proportional reduction in memory and
inference time. We evaluate four different state-of-the-art LLMs on text
embedding tasks and find that our method can prune up to 30\% of layers with
negligible impact on performance and up to 80\% with only a modest drop. With
only three lines of code, our method is easily implemented in any pipeline for
transforming LLMs to text encoders. We also propose $\text{L}^3 \text{Prune}$,
a novel layer-pruning strategy based on the model's initial loss that provides
two optimal pruning configurations: a large variant with negligible performance
loss and a small variant for resource-constrained settings. On average, the
large variant prunes 21\% of the parameters with a $-0.3$ performance drop, and
the small variant only suffers from a $-5.1$ decrease while pruning 74\% of the
model. We consider these results strong evidence that LLMs are
overparameterized for text embedding tasks, and can be easily pruned.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Á∂ìÈÅéÁõ£Áù£Â∞çÊØîË®ìÁ∑¥ÂæÆË™øÂæåÔºåÂ±ïÁèæÂá∫Âº∑Â§ßÁöÑÊñáÊú¨ÂµåÂÖ•Ê®°ÂûãÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÁöÑÈæêÂ§ßË¶èÊ®°ÊúÉËÜ®ËÑπÊé®Ë´ñÊôÇÈñìÂíåË®òÊÜ∂È´îÈúÄÊ±Ç„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫Âá∫ÈÄèÈÅéÂú®Áõ£Áù£Ë®ìÁ∑¥Ââç‰øÆÂâ™ LLM ÁöÑÊúÄÂæå $p\%$ Â±§ÔºåÂÉÖÈÄ≤Ë°å 1000 ÂÄãÊ≠•È©üÔºåÊàëÂÄëÂèØ‰ª•ÊåâÊØî‰æãÊ∏õÂ∞ëË®òÊÜ∂È´îÂíåÊé®Ë´ñÊôÇÈñì„ÄÇÊàëÂÄëÂú®ÊñáÊú¨ÂµåÂÖ•‰ªªÂãô‰∏≠Ë©ï‰º∞‰∫ÜÂõõÁ®Æ‰∏çÂêåÁöÑÊúÄÂÖàÈÄ≤ LLMÔºå‰∏¶ÁôºÁèæÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•‰øÆÂâ™Â§öÈÅî 30% ÁöÑÂ±§ÔºåÂ∞çÊïàËÉΩÂΩ±ÈüøÂæÆ‰πéÂÖ∂ÂæÆÔºåËÄå‰øÆÂâ™Â§öÈÅî 80% ÊôÇÊïàËÉΩÂÉÖÁï•ÂæÆ‰∏ãÈôç„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂÉÖÈúÄ‰∏âË°åÁ®ãÂºèÁ¢ºÔºå‰æøËÉΩËºïÈ¨ÜÂØ¶‰ΩúÂú®‰ªª‰ΩïÂ∞á LLM ËΩâÊèõÁÇ∫ÊñáÂ≠óÁ∑®Á¢ºÂô®ÁöÑÁÆ°ÈÅì‰∏≠„ÄÇÊàëÂÄë‰πüÊèêÂá∫ $\text{L}^3 \text{Prune}$ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºÊ®°ÂûãÂàùÂßãÊêçÂ§±ÁöÑÊñ∞Á©éÂ±§‰øÆÂâ™Á≠ñÁï•ÔºåÂèØÊèê‰æõÂÖ©Á®ÆÊúÄ‰Ω≥‰øÆÂâ™ÈÖçÁΩÆÔºöÊïàËÉΩÊêçÂ§±ÂæÆ‰πéÂÖ∂ÂæÆÁöÑÂ§ßÂûãËÆäÈ´îÔºå‰ª•ÂèäÈÅ©Áî®ÊñºË≥áÊ∫êÂèóÈôêË®≠ÂÆöÁöÑÂ∞èÂûãËÆäÈ´î„ÄÇÂπ≥ÂùáËÄåË®ÄÔºåÂ§ßÂûãËÆäÈ´î‰øÆÂâ™‰∫Ü 21% ÁöÑÂèÉÊï∏ÔºåÊïàËÉΩ‰∏ãÈôç -0.3ÔºåËÄåÂ∞èÂûãËÆäÈ´îÂÉÖ‰∏ãÈôç -5.1ÔºåÂêåÊôÇ‰øÆÂâ™‰∫ÜÊ®°ÂûãÁöÑ 74%„ÄÇÊàëÂÄëË™çÁÇ∫ÈÄô‰∫õÁµêÊûúÊúâÂäõÂú∞Ë≠âÊòé‰∫Ü LLM Â∞çÊñºÊñáÊú¨ÂµåÂÖ•‰ªªÂãô‰æÜË™™ÈÅéÂ∫¶ÂèÉÊï∏ÂåñÔºå‰∏¶‰∏îÂèØ‰ª•ËºïÈ¨ÜÂú∞ÈÄ≤Ë°å‰øÆÂâ™„ÄÇ

##### **MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts**
2410.14574v1 by Rachel S. Y. Teo, Tan M. Nguyen

Sparse Mixture of Experts (SMoE) has become the key to unlocking unparalleled
scalability in deep learning. SMoE has the potential to exponentially increase
parameter count while maintaining the efficiency of the model by only
activating a small subset of these parameters for a given sample. However, it
has been observed that SMoE suffers from unstable training and has difficulty
adapting to new distributions, leading to the model's lack of robustness to
data contamination. To overcome these limitations, we first establish a
connection between the dynamics of the expert representations in SMoEs and
gradient descent on a multi-objective optimization problem. Leveraging our
framework, we then integrate momentum into SMoE and propose a new family of
SMoEs named MomentumSMoE. We theoretically prove and numerically demonstrate
that MomentumSMoE is more stable and robust than SMoE. In particular, we verify
the advantages of MomentumSMoE over SMoE on a variety of practical tasks
including ImageNet-1K object recognition and WikiText-103 language modeling. We
demonstrate the applicability of MomentumSMoE to many types of SMoE models,
including those in the Sparse MoE model for vision (V-MoE) and the Generalist
Language Model (GLaM). We also show that other advanced momentum-based
optimization methods, such as Adam, can be easily incorporated into the
MomentumSMoE framework for designing new SMoE models with even better
performance, almost negligible additional computation cost, and simple
implementations.

ÊëòË¶ÅÔºöÁ®ÄÁñè‰∏ìÂÆ∂Ê∑∑ÂêàÔºàSMoEÔºâÂ∑≤Êàê‰∏∫Ëß£ÈîÅÊ∑±Â∫¶Â≠¶‰π†‰∏≠Êó†‰∏é‰º¶ÊØîÁöÑÂèØÊâ©Â±ïÊÄßÁöÑÂÖ≥ÈîÆ„ÄÇSMoE ÊúâÂèØËÉΩÂëàÊåáÊï∞Á∫ßÂ¢ûÂä†ÂèÇÊï∞ËÆ°Êï∞ÔºåÂêåÊó∂‰ªÖÈÄöËøáÊøÄÊ¥ªÁªôÂÆöÊ†∑Êú¨‰∏≠Ëøô‰∫õÂèÇÊï∞ÁöÑ‰∏Ä‰∏™Â∞èÂ≠êÈõÜÊù•Áª¥ÊåÅÊ®°ÂûãÁöÑÊïàÁéá„ÄÇÁÑ∂ËÄåÔºåÊçÆËßÇÂØüÔºåSMoE ËÆ≠ÁªÉ‰∏çÁ®≥ÂÆöÔºåÂπ∂‰∏îÈöæ‰ª•ÈÄÇÂ∫îÊñ∞ÁöÑÂàÜÂ∏ÉÔºåÂØºËá¥Ê®°ÂûãÂØπÊï∞ÊçÆÊ±°ÊüìÁº∫‰πèÈ≤ÅÊ£íÊÄß„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∫õÈôêÂà∂ÔºåÊàë‰ª¨È¶ñÂÖàÂú® SMoE ‰∏≠‰∏ìÂÆ∂Ë°®Á§∫ÁöÑÂä®ÊÄÅ‰∏éÂ§öÁõÆÊ†á‰ºòÂåñÈóÆÈ¢òÁöÑÊ¢ØÂ∫¶‰∏ãÈôç‰πãÈó¥Âª∫Á´ã‰∫ÜËÅîÁ≥ª„ÄÇÂà©Áî®Êàë‰ª¨ÁöÑÊ°ÜÊû∂ÔºåÊàë‰ª¨ÈöèÂêéÂ∞ÜÂä®ÈáèÊï¥ÂêàÂà∞ SMoE ‰∏≠ÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁ≥ªÂàóÂêç‰∏∫ MomentumSMoE ÁöÑÊñ∞ SMoE„ÄÇÊàë‰ª¨‰ªéÁêÜËÆ∫‰∏äËØÅÊòéÂπ∂ÈÄöËøáÊï∞Â≠óÊºîÁ§∫‰∫Ü MomentumSMoE ÊØî SMoE Êõ¥Á®≥ÂÆö„ÄÅÊõ¥Á®≥ÂÅ•„ÄÇÁâπÂà´ÊòØÔºåÊàë‰ª¨Âú®ÂêÑÁßçÂÆûÈôÖ‰ªªÂä°‰∏äÈ™åËØÅ‰∫Ü MomentumSMoE Áõ∏ÂØπ‰∫é SMoE ÁöÑ‰ºòÂäøÔºåÂåÖÊã¨ ImageNet-1K ÂØπË±°ËØÜÂà´Âíå WikiText-103 ËØ≠Ë®ÄÂª∫Ê®°„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫Ü MomentumSMoE ÂØπÂ§öÁßçÁ±ªÂûã SMoE Ê®°ÂûãÁöÑÈÄÇÁî®ÊÄßÔºåÂåÖÊã¨ËßÜËßâÁ®ÄÁñè MoE Ê®°Âûã (V-MoE) ÂíåÈÄöÁî®ËØ≠Ë®ÄÊ®°Âûã (GLaM)„ÄÇÊàë‰ª¨ËøòË°®ÊòéÔºåÂÖ∂‰ªñÂü∫‰∫éÂä®ÈáèÁöÑ‰ºòÂåñÊñπÊ≥ïÔºå‰æãÂ¶Ç AdamÔºåÂèØ‰ª•ËΩªÊùæÂú∞Êï¥ÂêàÂà∞ MomentumSMoE Ê°ÜÊû∂‰∏≠ÔºåÁî®‰∫éËÆæËÆ°ÂÖ∑ÊúâÊõ¥Â•ΩÊÄßËÉΩ„ÄÅÂá†‰πéÂèØ‰ª•ÂøΩÁï•‰∏çËÆ°ÁöÑÈ¢ùÂ§ñËÆ°ÁÆóÊàêÊú¨ÂíåÁÆÄÂçïÂÆûÁé∞ÁöÑÊñ∞ SMoE Ê®°Âûã„ÄÇ

##### **Building Trust in Black-box Optimization: A Comprehensive Framework for Explainability**
2410.14573v1 by Nazanin Nezami, Hadis Anahideh

Optimizing costly black-box functions within a constrained evaluation budget
presents significant challenges in many real-world applications. Surrogate
Optimization (SO) is a common resolution, yet its proprietary nature introduced
by the complexity of surrogate models and the sampling core (e.g., acquisition
functions) often leads to a lack of explainability and transparency. While
existing literature has primarily concentrated on enhancing convergence to
global optima, the practical interpretation of newly proposed strategies
remains underexplored, especially in batch evaluation settings. In this paper,
we propose \emph{Inclusive} Explainability Metrics for Surrogate Optimization
(IEMSO), a comprehensive set of model-agnostic metrics designed to enhance the
transparency, trustworthiness, and explainability of the SO approaches. Through
these metrics, we provide both intermediate and post-hoc explanations to
practitioners before and after performing expensive evaluations to gain trust.
We consider four primary categories of metrics, each targeting a specific
aspect of the SO process: Sampling Core Metrics, Batch Properties Metrics,
Optimization Process Metrics, and Feature Importance. Our experimental
evaluations demonstrate the significant potential of the proposed metrics
across different benchmarks.

ÊëòË¶ÅÔºöÂú®ÂèóÈôêÁöÑË©ï‰º∞È†êÁÆó‰∏≠ÊúÄ‰Ω≥ÂåñÈ´òÊàêÊú¨ÁöÑÈªëÁÆ±ÂáΩÊï∏ÔºåÂú®Ë®±Â§öÁèæÂØ¶‰∏ñÁïåÁöÑÊáâÁî®‰∏≠ÊúÉÂ∏∂‰æÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇ‰ª£ÁêÜÊúÄ‰Ω≥Âåñ (SO) ÊòØ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ΩÜ‰ª£ÁêÜÊ®°ÂûãÁöÑË§áÈõúÊÄßÂíåÂèñÊ®£Ê†∏ÂøÉÔºà‰æãÂ¶ÇÔºåÊî∂Ë≥ºÂáΩÊï∏ÔºâÊâÄÂ∏∂‰æÜÁöÑÂ∞àÊúâÁâπÊÄßÔºåÈÄöÂ∏∏ÊúÉÂ∞éËá¥Áº∫‰πèÂèØËß£ÈáãÊÄßÂíåÈÄèÊòéÂ∫¶„ÄÇÈõñÁÑ∂ÁèæÊúâÁöÑÊñáÁçª‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÂ¢ûÂº∑Â∞çÂÖ®Â±ÄÊúÄÂÑ™ÂÄºÁöÑÊî∂ÊñÇÊÄßÔºå‰ΩÜÂ∞çÊñ∞ÊèêÂá∫ÁöÑÁ≠ñÁï•ÁöÑÂØ¶ÈöõËß£Èáã‰ªçÊú™ÂÖÖÂàÜÊé¢Ë®éÔºåÂ∞§ÂÖ∂ÊòØÂú®ÊâπÊ¨°Ë©ï‰º∞Ë®≠ÂÆö‰∏≠„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰ª£ÁêÜÊúÄ‰Ω≥ÂåñÁöÑ„ÄåÂåÖÂÆπÊÄß„ÄçÂèØËß£ÈáãÊÄßÊåáÊ®ô (IEMSO)ÔºåÈÄôÊòØ‰∏ÄÂ•óÂÖ®Èù¢ÁöÑÊ®°Âûã‰∏çÂèØÁü•ÊåáÊ®ôÔºåÊó®Âú®Â¢ûÂº∑ SO ÊñπÊ≥ïÁöÑÈÄèÊòéÂ∫¶„ÄÅÂèØ‰ø°Â∫¶ÂíåÂèØËß£ÈáãÊÄß„ÄÇÈÄèÈÅéÈÄô‰∫õÊåáÊ®ôÔºåÊàëÂÄëÂú®Âü∑Ë°åÊòÇË≤¥ÁöÑË©ï‰º∞‰πãÂâçÂíå‰πãÂæåÔºåÁÇ∫ÂØ¶Âãô‰∫∫Âì°Êèê‰æõ‰∏≠ÈñìÂíå‰∫ãÂæåËß£ÈáãÔºå‰ª•Âª∫Á´ã‰ø°‰ªª„ÄÇÊàëÂÄëËÄÉÊÖÆÂõõÁ®ÆÈ°ûÂà•ÁöÑ‰∏ªË¶ÅÊåáÊ®ôÔºåÊØèÂÄãÊåáÊ®ôÈÉΩÈáùÂ∞ç SO ÊµÅÁ®ãÁöÑÁâπÂÆöÊñπÈù¢ÔºöÂèñÊ®£Ê†∏ÂøÉÊåáÊ®ô„ÄÅÊâπÊ¨°Â±¨ÊÄßÊåáÊ®ô„ÄÅÊúÄ‰Ω≥ÂåñÊµÅÁ®ãÊåáÊ®ôÂíåÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË©ï‰º∞Ë≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊåáÊ®ôÂú®‰∏çÂêåÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÁöÑÈ°ØËëóÊΩõÂäõ„ÄÇ

##### **TransBox: EL++-closed Ontology Embedding**
2410.14571v1 by Hui Yang, Jiaoyan Chen, Uli Sattler

OWL (Web Ontology Language) ontologies, which are able to represent both
relational and type facts as standard knowledge graphs and complex domain
knowledge in Description Logic (DL) axioms, are widely adopted in domains such
as healthcare and bioinformatics. Inspired by the success of knowledge graph
embeddings, embedding OWL ontologies has gained significant attention in recent
years. Current methods primarily focus on learning embeddings for atomic
concepts and roles, enabling the evaluation based on normalized axioms through
specially designed score functions. However, they often neglect the embedding
of complex concepts, making it difficult to infer with more intricate axioms.
This limitation reduces their effectiveness in advanced reasoning tasks, such
as Ontology Learning and ontology-mediated Query Answering. In this paper, we
propose EL++-closed ontology embeddings which are able to represent any logical
expressions in DL via composition. Furthermore, we develop TransBox, an
effective EL++-closed ontology embedding method that can handle many-to-one,
one-to-many and many-to-many relations. Our extensive experiments demonstrate
that TransBox often achieves state-of-the-art performance across various
real-world datasets for predicting complex axioms.

ÊëòË¶ÅÔºöOWLÔºàWeb Ontology LanguageÔºâÊú¨‰ΩìÔºåËÉΩÂ§üÂ∞ÜÂÖ≥Á≥ªÂíåÁ±ªÂûã‰∫ãÂÆûË°®Á§∫‰∏∫Ê†áÂáÜÁü•ËØÜÂõæÂíåÊèèËø∞ÈÄªËæë (DL) ÂÖ¨ÁêÜ‰∏≠ÁöÑÂ§çÊùÇÈ¢ÜÂüüÁü•ËØÜÔºåÂú®ÂåªÁñó‰øùÂÅ•ÂíåÁîüÁâ©‰ø°ÊÅØÂ≠¶Á≠âÈ¢ÜÂüüÂæóÂà∞ÂπøÊ≥õÈááÁî®„ÄÇÂèóÁü•ËØÜÂõæÂµåÂÖ•ÁöÑÊàêÂäüÂêØÂèëÔºåÂµåÂÖ• OWL Êú¨‰ΩìËøëÂπ¥Êù•Â§áÂèóÂÖ≥Ê≥®„ÄÇÂΩìÂâçÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®Â≠¶‰π†ÂéüÂ≠êÊ¶ÇÂøµÂíåËßíËâ≤ÁöÑÂµåÂÖ•ÔºåÈÄöËøá‰∏ìÈó®ËÆæËÆ°ÁöÑËØÑÂàÜÂáΩÊï∞ÔºåÊîØÊåÅÂü∫‰∫éÂΩí‰∏ÄÂåñÂÖ¨ÁêÜÁöÑËØÑ‰º∞„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨ÁªèÂ∏∏ÂøΩÁï•Â§çÊùÇÊ¶ÇÂøµÁöÑÂµåÂÖ•ÔºåËøô‰ΩøÂæóÈöæ‰ª•Êé®Êñ≠Âá∫Êõ¥Â§çÊùÇÁöÑÂÖ¨ÁêÜ„ÄÇËøôÁßçÈôêÂà∂Èôç‰Ωé‰∫ÜÂÆÉ‰ª¨Âú®È´òÁ∫ßÊé®ÁêÜ‰ªªÂä°Ôºà‰æãÂ¶ÇÊú¨‰ΩìÂ≠¶‰π†ÂíåÊú¨‰Ωì‰ªãÂØºÊü•ËØ¢Â∫îÁ≠îÔºâ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü EL++ Â∞ÅÈó≠Êú¨‰ΩìÂµåÂÖ•ÔºåÂÆÉËÉΩÂ§üÈÄöËøáÁªÑÂêàÊù•Ë°®Á§∫ DL ‰∏≠ÁöÑ‰ªª‰ΩïÈÄªËæëË°®ËææÂºè„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü TransBoxÔºå‰∏ÄÁßçÊúâÊïàÁöÑ EL++ Â∞ÅÈó≠Êú¨‰ΩìÂµåÂÖ•ÊñπÊ≥ïÔºåÂèØ‰ª•Â§ÑÁêÜÂ§öÂØπ‰∏Ä„ÄÅ‰∏ÄÂØπÂ§öÂíåÂ§öÂØπÂ§öÂÖ≥Á≥ª„ÄÇÊàë‰ª¨ÂπøÊ≥õÁöÑÂÆûÈ™åË°®ÊòéÔºåTransBox Âú®È¢ÑÊµãÂ§çÊùÇÂÖ¨ÁêÜÁöÑÂêÑÁßçÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆÈõÜ‰∏äÈÄöÂ∏∏ÈÉΩËÉΩËææÂà∞ÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

##### **When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs**
2410.14569v1 by Hanna Kim, Minkyoo Song, Seung Ho Na, Seungwon Shin, Kimin Lee

Recent advancements in Large Language Models (LLMs) have established them as
agentic systems capable of planning and interacting with various tools. These
LLM agents are often paired with web-based tools, enabling access to diverse
sources and real-time information. Although these advancements offer
significant benefits across various applications, they also increase the risk
of malicious use, particularly in cyberattacks involving personal information.
In this work, we investigate the risks associated with misuse of LLM agents in
cyberattacks involving personal data. Specifically, we aim to understand: 1)
how potent LLM agents can be when directed to conduct cyberattacks, 2) how
cyberattacks are enhanced by web-based tools, and 3) how affordable and easy it
becomes to launch cyberattacks using LLM agents. We examine three attack
scenarios: the collection of Personally Identifiable Information (PII), the
generation of impersonation posts, and the creation of spear-phishing emails.
Our experiments reveal the effectiveness of LLM agents in these attacks: LLM
agents achieved a precision of up to 95.9% in collecting PII, up to 93.9% of
impersonation posts created by LLM agents were evaluated as authentic, and the
click rate for links in spear phishing emails created by LLM agents reached up
to 46.67%. Additionally, our findings underscore the limitations of existing
safeguards in contemporary commercial LLMs, emphasizing the urgent need for
more robust security measures to prevent the misuse of LLM agents.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤Â∞áÂÖ∂Á¢∫Á´ãÁÇ∫ËÉΩÂ§†Ë¶èÂäÉÂíåËàáÂêÑÁ®ÆÂ∑•ÂÖ∑‰∫íÂãïÁöÑ‰ª£ÁêÜÁ≥ªÁµ±„ÄÇÈÄô‰∫õ LLM ‰ª£ÁêÜÈÄöÂ∏∏ËàáÂü∫ÊñºÁ∂≤Ë∑ØÁöÑÂ∑•ÂÖ∑ÈÖçÂ∞çÔºåÂèØ‰ª•Â≠òÂèñÂêÑÁ®Æ‰æÜÊ∫êÂíåÂç≥ÊôÇË≥áË®ä„ÄÇÂÑòÁÆ°ÈÄô‰∫õÈÄ≤Â±ïÁÇ∫ÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÊèê‰æõ‰∫ÜÈ°ØËëóÁöÑÂÑ™ÈªûÔºå‰ΩÜÂÆÉÂÄë‰πüÂ¢ûÂä†‰∫ÜÊÉ°ÊÑè‰ΩøÁî®ÁöÑÈ¢®Èö™ÔºåÁâπÂà•ÊòØÂú®Ê∂âÂèäÂÄã‰∫∫Ë≥áË®äÁöÑÁ∂≤Ë∑ØÊîªÊìä‰∏≠„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË™øÊü•‰∫ÜÂú®Á∂≤Ë∑ØÊîªÊìä‰∏≠Ë™§Áî® LLM ‰ª£ÁêÜÊâÄÂ∏∂‰æÜÁöÑÈ¢®Èö™ÔºåÁâπÂà•ÊòØÊ∂âÂèäÂÄã‰∫∫Ë≥áÊñô„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊó®Âú®‰∫ÜËß£Ôºö1) Â∞á LLM ‰ª£ÁêÜÂ∞éÂêëÂü∑Ë°åÁ∂≤Ë∑ØÊîªÊìäÊôÇÔºåÂÆÉÂÄëÁöÑÊΩõÂäõÊúâÂ§öÂ§ßÔºå2) Á∂≤Ë∑ØÊîªÊìäÂ¶Ç‰ΩïÈÄèÈÅéÂü∫ÊñºÁ∂≤Ë∑ØÁöÑÂ∑•ÂÖ∑ÂæóÂà∞Âä†Âº∑Ôºå‰ª•Âèä 3) ‰ΩøÁî® LLM ‰ª£ÁêÜÁôºÂãïÁ∂≤Ë∑ØÊîªÊìäËÆäÂæóÊúâÂ§öÈ∫ºÂÆπÊòì‰∏îÁ∂ìÊøüÂØ¶ÊÉ†„ÄÇÊàëÂÄëÊé¢Ë®é‰∫Ü‰∏âÁ®ÆÊîªÊìäÊÉÖÂ¢ÉÔºöÊî∂ÈõÜÂÄã‰∫∫ÂèØË≠òÂà•Ë≥áË®ä (PII)„ÄÅÁî¢ÁîüÂÜíÂÖÖË≤ºÊñáÔºå‰ª•ÂèäÂª∫Á´ãÈ≠öÂèâÂºèÁ∂≤Ë∑ØÈá£È≠öÈõªÂ≠êÈÉµ‰ª∂„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊè≠Á§∫‰∫Ü LLM ‰ª£ÁêÜÂú®ÈÄô‰∫õÊîªÊìä‰∏≠ÁöÑÊúâÊïàÊÄßÔºöLLM ‰ª£ÁêÜÂú®Êî∂ÈõÜ PII ÊôÇÈÅîÂà∞‰∫ÜÈ´òÈÅî 95.9% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåLLM ‰ª£ÁêÜÂª∫Á´ãÁöÑÂÜíÂÖÖË≤ºÊñá‰∏≠ÊúâÈ´òÈÅî 93.9% Ë¢´Ë©ï‰º∞ÁÇ∫ÁúüÂØ¶ÔºåLLM ‰ª£ÁêÜÂª∫Á´ãÁöÑÈ≠öÂèâÂºèÁ∂≤Ë∑ØÈá£È≠öÈõªÂ≠êÈÉµ‰ª∂‰∏≠ÁöÑÈÄ£ÁµêÈªûÊìäÁéáÈÅîÂà∞ 46.67%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜÁï∂‰ª£ÂïÜÊ•≠ LLM ‰∏≠ÁèæÊúâÈò≤Ë≠∑Êé™ÊñΩÁöÑÈôêÂà∂ÔºåÂº∑Ë™øËø´ÂàáÈúÄË¶ÅÊõ¥Âº∑Â§ßÁöÑÂÆâÂÖ®Êé™ÊñΩ‰æÜÈò≤Ê≠¢ LLM ‰ª£ÁêÜË¢´Êø´Áî®„ÄÇ

##### **RAG-ConfusionQA: A Benchmark for Evaluating LLMs on Confusing Questions**
2410.14567v1 by Zhiyuan Peng, Jinming Nian, Alexandre Evfimievski, Yi Fang

Conversational AI agents use Retrieval Augmented Generation (RAG) to provide
verifiable document-grounded responses to user inquiries. However, many natural
questions do not have good answers: about 25\% contain false
assumptions~\cite{Yu2023:CREPE}, and over 50\% are
ambiguous~\cite{Min2020:AmbigQA}. RAG agents need high-quality data to improve
their responses to confusing questions. This paper presents a novel synthetic
data generation method to efficiently create a diverse set of context-grounded
confusing questions from a given document corpus. We conduct an empirical
comparative evaluation of several large language models as RAG agents to
measure the accuracy of confusion detection and appropriate response
generation. We contribute a benchmark dataset to the public domain.

ÊëòË¶ÅÔºöÂ∞çË©±Âºè AI ‰ª£ÁêÜ‰ΩøÁî®Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ‰æÜÊèê‰æõÂèØÈ©óË≠âÁöÑÂü∫ÊñºÊñá‰ª∂ÂõûÊáâÁµ¶‰ΩøÁî®ËÄÖÁöÑÊü•Ë©¢„ÄÇÁÑ∂ËÄåÔºåË®±Â§öËá™ÁÑ∂ÂïèÈ°åÊ≤íÊúâÂ•ΩÁöÑÁ≠îÊ°àÔºöÁ¥Ñ 25% ÂåÖÂê´ÈåØË™§ÁöÑÂÅáË®≠~\cite{Yu2023:CREPE}ÔºåËÄåË∂ÖÈÅé 50% ÊòØÊ®°Á®úÂÖ©ÂèØÁöÑ~\cite{Min2020:AmbigQA}„ÄÇRAG ‰ª£ÁêÜÈúÄË¶ÅÈ´òÂìÅË≥™ÁöÑË≥áÊñô‰æÜÊîπÂñÑ‰ªñÂÄëÂ∞ç‰ª§‰∫∫Âõ∞ÊÉëÂïèÈ°åÁöÑÂõûÊáâ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂêàÊàêË≥áÊñôÁîüÊàêÊñπÊ≥ïÔºåÂèØ‰ª•ÊúâÊïàÁéáÂú∞ÂæûÁµ¶ÂÆöÁöÑÊñá‰ª∂Ë™ûÊñôÂ∫´‰∏≠Âª∫Á´ã‰∏ÄÁµÑÂ§öÊ®£ÂåñÁöÑÂü∫ÊñºËÉåÊôØÁöÑ‰ª§‰∫∫Âõ∞ÊÉëÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÂ∞çÂπæÂÄãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÂØ¶Ë≠âÊØîËºÉË©ï‰º∞Ôºå‰ΩúÁÇ∫ RAG ‰ª£ÁêÜÔºå‰ª•Ë°°ÈáèÊ∑∑Ê∑ÜÊ™¢Ê∏¨ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÈÅ©Áï∂ÁöÑÂõûÊáâÁîüÊàê„ÄÇÊàëÂÄëÂ∞áÂü∫Ê∫ñË≥áÊñôÈõÜË≤¢ÁçªÁµ¶ÂÖ¨ÊúâÈ†òÂüü„ÄÇ

##### **Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization**
2410.14545v1 by Frederic Kirstein, Terry Ruas, Robert Kratel, Bela Gipp

Meeting summarization is crucial in digital communication, but existing
solutions struggle with salience identification to generate personalized,
workable summaries, and context understanding to fully comprehend the meetings'
content. Previous attempts to address these issues by considering related
supplementary resources (e.g., presentation slides) alongside transcripts are
hindered by models' limited context sizes and handling the additional
complexities of the multi-source tasks, such as identifying relevant
information in additional files and seamlessly aligning it with the meeting
content. This work explores multi-source meeting summarization considering
supplementary materials through a three-stage large language model approach:
identifying transcript passages needing additional context, inferring relevant
details from supplementary materials and inserting them into the transcript,
and generating a summary from this enriched transcript. Our multi-source
approach enhances model understanding, increasing summary relevance by ~9% and
producing more content-rich outputs. We introduce a personalization protocol
that extracts participant characteristics and tailors summaries accordingly,
improving informativeness by ~10%. This work further provides insights on
performance-cost trade-offs across four leading model families, including
edge-device capable options. Our approach can be extended to similar complex
generative tasks benefitting from additional resources and personalization,
such as dialogue systems and action planning.

ÊëòË¶ÅÔºöÊúÉË≠∞ÊëòË¶ÅÂú®Êï∏‰ΩçÊ∫ùÈÄö‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁèæÊúâÁöÑËß£Ê±∫ÊñπÊ°àÂú®ÊâæÂá∫ÈáçÈªû‰ª•Áî¢ÁîüÂÄã‰∫∫Âåñ„ÄÅÂèØË°åÁöÑÊëòË¶ÅÔºå‰ª•ÂèäÁêÜËß£ËÑàÁµ°‰ª•ÂÖÖÂàÜÁêÜËß£ÊúÉË≠∞ÂÖßÂÆπÊñπÈù¢Èù¢Ëá®ÊåëÊà∞„ÄÇÂÖàÂâçÂòóË©¶ÈÄèÈÅéËÄÉÊÖÆËàáÈÄêÂ≠óÁ¥ÄÈåÑ‰∏¶ÂàóÁöÑÁõ∏ÈóúË£úÂÖÖË≥áÊ∫êÔºà‰æãÂ¶ÇÁ∞°Â†±ÊäïÂΩ±ÁâáÔºâ‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºå‰ΩÜÂèóÂà∞Ê®°ÂûãÂèóÈôêÁöÑËÑàÁµ°Â§ßÂ∞è‰ª•ÂèäËôïÁêÜÂ§ö‰æÜÊ∫ê‰ªªÂãôÈ°çÂ§ñË§áÈõúÊÄßÁöÑÈòªÁ§ôÔºå‰æãÂ¶ÇÊâæÂá∫È°çÂ§ñÊ™îÊ°à‰∏≠ÁöÑÁõ∏ÈóúË≥áË®äÔºå‰∏¶Â∞áÂÖ∂ËàáÊúÉË≠∞ÂÖßÂÆπÁÑ°Á∏´Â∞çÈΩä„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Êé¢Ë®éÂ§ö‰æÜÊ∫êÊúÉË≠∞ÊëòË¶ÅÔºåÈÄèÈÅé‰∏âÈöéÊÆµÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊñπÊ≥ï‰æÜËÄÉÈáèË£úÂÖÖË≥áÊñôÔºöÊâæÂá∫ÈúÄË¶ÅÈ°çÂ§ñËÑàÁµ°ÁöÑÈÄêÂ≠óÁ¥ÄÈåÑÊÆµËêΩ„ÄÅÂæûË£úÂÖÖË≥áÊñôÊé®Ë´ñÁõ∏ÈóúÁ¥∞ÁØÄ‰∏¶Â∞áÂÖ∂ÊèíÂÖ•ÈÄêÂ≠óÁ¥ÄÈåÑÔºå‰ª•ÂèäÂæûÈÄô‰ªΩË±êÂØåÁöÑÈÄêÂ≠óÁ¥ÄÈåÑÁî¢ÁîüÊëòË¶Å„ÄÇÊàëÂÄëÁöÑÂ§ö‰æÜÊ∫êÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÁêÜËß£ÔºåÂ∞áÊëòË¶ÅÁõ∏ÈóúÊÄßÊèêÂçáÁ¥Ñ 9%Ôºå‰∏¶Áî¢ÁîüÊõ¥Â§öÂÖßÂÆπË±êÂØåÁöÑËº∏Âá∫„ÄÇÊàëÂÄëÂºïÈÄ≤ÂÄã‰∫∫ÂåñÂçîÂÆöÔºåÁî®‰æÜËêÉÂèñÂèÉËàáËÄÖÁâπÂæµ‰∏¶ÊìöÊ≠§Ë™øÊï¥ÊëòË¶ÅÔºåÂ∞áË≥áË®äÈáèÊèêÂçáÁ¥Ñ 10%„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Êèê‰æõÈóúÊñºÂõõÂÄã‰∏ªË¶ÅÊ®°ÂûãÁ≥ªÂàóÁöÑÊïàËÉΩÊàêÊú¨ÂèñÊç®ÁöÑË¶ãËß£ÔºåÂåÖÊã¨ÈÇäÁ∑£Ë£ùÁΩÆÂèØÁî®ÁöÑÈÅ∏È†Ö„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•Âª∂‰º∏Âà∞ÂæûÈ°çÂ§ñË≥áÊ∫êÂíåÂÄã‰∫∫Âåñ‰∏≠ÂèóÁõäÁöÑÈ°û‰ººË§áÈõúÁîüÊàê‰ªªÂãôÔºå‰æãÂ¶ÇÂ∞çË©±Á≥ªÁµ±ÂíåË°åÂãïË®àÁï´„ÄÇ

##### **Less is More: Selective Reduction of CT Data for Self-Supervised Pre-Training of Deep Learning Models with Contrastive Learning Improves Downstream Classification Performance**
2410.14524v1 by Daniel Wolf, Tristan Payer, Catharina Silvia Lisson, Christoph Gerhard Lisson, Meinrad Beer, Michael G√∂tz, Timo Ropinski

Self-supervised pre-training of deep learning models with contrastive
learning is a widely used technique in image analysis. Current findings
indicate a strong potential for contrastive pre-training on medical images.
However, further research is necessary to incorporate the particular
characteristics of these images. We hypothesize that the similarity of medical
images hinders the success of contrastive learning in the medical imaging
domain. To this end, we investigate different strategies based on deep
embedding, information theory, and hashing in order to identify and reduce
redundancy in medical pre-training datasets. The effect of these different
reduction strategies on contrastive learning is evaluated on two pre-training
datasets and several downstream classification tasks. In all of our
experiments, dataset reduction leads to a considerable performance gain in
downstream tasks, e.g., an AUC score improvement from 0.78 to 0.83 for the
COVID CT Classification Grand Challenge, 0.97 to 0.98 for the OrganSMNIST
Classification Challenge and 0.73 to 0.83 for a brain hemorrhage classification
task. Furthermore, pre-training is up to nine times faster due to the dataset
reduction. In conclusion, the proposed approach highlights the importance of
dataset quality and provides a transferable approach to improve contrastive
pre-training for classification downstream tasks on medical images.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÂ∞çÊØîÂ≠∏ÁøíËá™Áõ£Áù£È†êË®ìÁ∑¥ÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÁî®ÊñºÂΩ±ÂÉèÂàÜÊûêÁöÑÊäÄË°ì„ÄÇÁõÆÂâçÁöÑÁôºÁèæÈ°ØÁ§∫Â∞çÊØîÈ†êË®ìÁ∑¥Âú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏äÂÖ∑ÊúâÂº∑Â§ßÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂Â∞çÊñºÁ¥çÂÖ•ÈÄô‰∫õÂΩ±ÂÉèÁöÑÁâπÂÆöÁâπÂæµÊòØÂøÖË¶ÅÁöÑ„ÄÇÊàëÂÄëÂÅáË®≠ÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÁõ∏‰ººÊÄßÈòªÁ§ô‰∫ÜÂ∞çÊØîÂ≠∏ÁøíÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüüÁöÑÊàêÂäü„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÁ†îÁ©∂‰∫ÜÂü∫ÊñºÊ∑±Â∫¶ÂµåÂÖ•„ÄÅË≥áË®äÁêÜË´ñÂíåÈõúÊπäÁöÑ‰∏çÂêåÁ≠ñÁï•Ôºå‰ª•Ë≠òÂà•ÂíåÊ∏õÂ∞ëÈÜ´Â≠∏È†êË®ìÁ∑¥Ë≥áÊñôÈõÜ‰∏≠ÁöÑÂÜóÈ§ò„ÄÇÈÄô‰∫õ‰∏çÂêåÁöÑÁ∞°ÂåñÁ≠ñÁï•Â∞çÊØîÂ≠∏ÁøíÁöÑÂΩ±ÈüøÂú®ÂÖ©ÂÄãÈ†êË®ìÁ∑¥Ë≥áÊñôÈõÜÂíåÂπæÂÄã‰∏ãÊ∏∏ÂàÜÈ°û‰ªªÂãô‰∏≠ÈÄ≤Ë°åË©ï‰º∞„ÄÇÂú®ÊàëÂÄëÊâÄÊúâÁöÑÂØ¶È©ó‰∏≠ÔºåË≥áÊñôÈõÜÁ∞°ÂåñÈÉΩÂ∞éËá¥‰∫Ü‰∏ãÊ∏∏‰ªªÂãôÁöÑÈ°ØËëóÊïàËÉΩÊèêÂçáÔºå‰æãÂ¶ÇÔºåCOVID CT ÂàÜÈ°ûÂ§ßÊåëÊà∞ÁöÑ AUC ÂàÜÊï∏Âæû 0.78 ÊèêÂçáËá≥ 0.83ÔºåOrganSMNIST ÂàÜÈ°ûÊåëÊà∞Âæû 0.97 ÊèêÂçáËá≥ 0.98ÔºåËÖ¶Âá∫Ë°ÄÂàÜÈ°û‰ªªÂãôÂæû 0.73 ÊèêÂçáËá≥ 0.83„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºË≥áÊñôÈõÜÁ∞°ÂåñÔºåÈ†êË®ìÁ∑¥ÈÄüÂ∫¶ÊúÄÈ´òÂèØÊèêÂçá‰πùÂÄç„ÄÇÁ∏Ω‰πãÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁ™ÅÈ°Ø‰∫ÜË≥áÊñôÈõÜÂìÅË≥™ÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØËΩâÁßªÁöÑÊñπÊ≥ï‰æÜÊîπÂñÑÈÜ´Â≠∏ÂΩ±ÂÉè‰∏äÂàÜÈ°û‰∏ãÊ∏∏‰ªªÂãôÁöÑÂ∞çÊØîÈ†êË®ìÁ∑¥„ÄÇ

##### **Do LLMs "know" internally when they follow instructions?**
2410.14516v1 by Juyeon Heo, Christina Heinze-Deml, Oussama Elachqar, Shirley Ren, Udhay Nallasamy, Andy Miller, Kwan Ho Ryan Chan, Jaya Narain

Instruction-following is crucial for building AI agents with large language
models (LLMs), as these models must adhere strictly to user-provided
constraints and guidelines. However, LLMs often fail to follow even simple and
clear instructions. To improve instruction-following behavior and prevent
undesirable outputs, a deeper understanding of how LLMs' internal states relate
to these outcomes is required. Our analysis of LLM internal states reveal a
dimension in the input embedding space linked to successful
instruction-following. We demonstrate that modifying representations along this
dimension improves instruction-following success rates compared to random
changes, without compromising response quality. Further investigation reveals
that this dimension is more closely related to the phrasing of prompts rather
than the inherent difficulty of the task or instructions. This discovery also
suggests explanations for why LLMs sometimes fail to follow clear instructions
and why prompt engineering is often effective, even when the content remains
largely unchanged. This work provides insight into the internal workings of
LLMs' instruction-following, paving the way for reliable LLM agents.

ÊëòË¶ÅÔºöÂ∞çÊñºÂª∫ÊßãÂÖ∑ÂÇôÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑ AI ‰ª£ÁêÜËÄåË®ÄÔºåÈÅµÂæ™Êåá‰ª§Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÈÄô‰∫õÊ®°ÂûãÂøÖÈ†àÂö¥Ê†ºÈÅµÂÆà‰ΩøÁî®ËÄÖÊèê‰æõÁöÑÁ¥ÑÊùüÂíåÊ∫ñÂâá„ÄÇÁÑ∂ËÄåÔºåLLM Á∂ìÂ∏∏ÁÑ°Ê≥ïÈÅµÂæ™Á∞°ÂñÆ‰∏îÊòéÁ¢∫ÁöÑÊåá‰ª§„ÄÇÁÇ∫‰∫ÜÊîπÂñÑÈÅµÂæ™Êåá‰ª§ÁöÑË°åÁÇ∫‰∏¶Èò≤Ê≠¢Áî¢Áîü‰∏çËâØËº∏Âá∫ÔºåÈúÄË¶ÅÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ LLM ÁöÑÂÖßÈÉ®ÁãÄÊÖãÂ¶Ç‰ΩïËàáÈÄô‰∫õÁµêÊûúÁõ∏Èóú„ÄÇÊàëÂÄëÂ∞ç LLM ÂÖßÈÉ®ÁãÄÊÖãÁöÑÂàÜÊûêÊè≠Á§∫‰∫ÜËº∏ÂÖ•ÂµåÂÖ•Á©∫Èñì‰∏≠ËàáÊàêÂäüÈÅµÂæ™Êåá‰ª§Áõ∏ÈóúÁöÑ‰∏ÄÂÄãÈù¢Âêë„ÄÇÊàëÂÄëË≠âÊòéÔºåËàáÈö®Ê©üËÆäÊõ¥Áõ∏ÊØîÔºåÊ≤øËëóÈÄôÂÄãÈù¢Âêë‰øÆÊîπË°®Á§∫ÂèØ‰ª•ÊèêÈ´òÈÅµÂæ™Êåá‰ª§ÁöÑÊàêÂäüÁéáÔºåËÄå‰∏çÊúÉÊêçÂÆ≥ÂõûÊáâÂìÅË≥™„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑË™øÊü•È°ØÁ§∫ÔºåÈÄôÂÄãÈù¢ÂêëËàáÊèêÁ§∫ÁöÑÊé™Ëæ≠Êõ¥ÁÇ∫Áõ∏ÈóúÔºåËÄåÈùû‰ªªÂãôÊàñÊåá‰ª§ÁöÑÂõ∫ÊúâÈõ£Â∫¶„ÄÇÈÄôÂÄãÁôºÁèæ‰πüËß£Èáã‰∫ÜÁÇ∫‰ªÄÈ∫º LLM ÊúâÊôÇÁÑ°Ê≥ïÈÅµÂæ™ÊòéÁ¢∫ÁöÑÊåá‰ª§Ôºå‰ª•ÂèäÁÇ∫‰ªÄÈ∫ºÊèêÁ§∫Â∑•Á®ãÈÄöÂ∏∏ÂæàÊúâÊïàÔºåÂç≥‰ΩøÂÖßÂÆπÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰øùÊåÅ‰∏çËÆä„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊèê‰æõ‰∫ÜÂ∞ç LLM ÈÅµÂæ™Êåá‰ª§ÁöÑÂÖßÈÉ®ÈÅã‰ΩúÁöÑË¶ãËß£ÔºåÁÇ∫ÂèØÈù†ÁöÑ LLM ‰ª£ÁêÜÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

##### **Efficient Annotator Reliability Assessment and Sample Weighting for Knowledge-Based Misinformation Detection on Social Media**
2410.14515v1 by Owen Cook, Charlie Grimshaw, Ben Wu, Sophie Dillon, Jack Hicks, Luke Jones, Thomas Smith, Matyas Szert, Xingyi Song

Misinformation spreads rapidly on social media, confusing the truth and
targetting potentially vulnerable people. To effectively mitigate the negative
impact of misinformation, it must first be accurately detected before applying
a mitigation strategy, such as X's community notes, which is currently a manual
process. This study takes a knowledge-based approach to misinformation
detection, modelling the problem similarly to one of natural language
inference. The EffiARA annotation framework is introduced, aiming to utilise
inter- and intra-annotator agreement to understand the reliability of each
annotator and influence the training of large language models for
classification based on annotator reliability. In assessing the EffiARA
annotation framework, the Russo-Ukrainian Conflict Knowledge-Based
Misinformation Classification Dataset (RUC-MCD) was developed and made publicly
available. This study finds that sample weighting using annotator reliability
performs the best, utilising both inter- and intra-annotator agreement and
soft-label training. The highest classification performance achieved using
Llama-3.2-1B was a macro-F1 of 0.757 and 0.740 using TwHIN-BERT-large.

ÊëòË¶ÅÔºöÈîôËØØËÆØÊÅØÂú®Á§æ‰∫§Â™í‰Ωì‰∏äÂø´ÈÄüÊï£Êí≠ÔºåÊ∑∑Ê∑Ü‰∫ÜÁúüÁõ∏ÔºåÂπ∂ÈíàÂØπÂèØËÉΩÂÆπÊòìÂèóÈ™óÁöÑ‰∫∫„ÄÇ‰∏∫‰∫ÜÊúâÊïàÂáèËΩªÈîôËØØËÆØÊÅØÁöÑË¥üÈù¢ÂΩ±ÂìçÔºåÂøÖÈ°ªÂÖàÂáÜÁ°ÆÂú∞‰æ¶ÊµãÂá∫ÈîôËØØËÆØÊÅØÔºåÁÑ∂ÂêéÂÜçÂ∫îÁî®ÁºìËß£Á≠ñÁï•Ôºå‰æãÂ¶Ç X ÁöÑÁ§æÁæ§Á¨îËÆ∞ÔºåËøôÁõÆÂâçÊòØ‰∏Ä‰∏™ÊâãÂä®ÁöÑÁ®ãÂ∫è„ÄÇÊú¨Á†îÁ©∂ÈááÂèñÂü∫‰∫éÁü•ËØÜÁöÑÊñπÊ≥ïÊù•‰æ¶ÊµãÈîôËØØËÆØÊÅØÔºåÂ∞ÜÈóÆÈ¢òÂª∫Ê®°‰∏∫Á±ª‰ºº‰∫éËá™ÁÑ∂ËØ≠Ë®ÄÊé®ËÆ∫ÁöÑÈóÆÈ¢ò„ÄÇÂºïÂÖ•‰∫Ü EffiARA Ê†áÊ≥®Ê°ÜÊû∂ÔºåÊó®Âú®Âà©Áî®Ê†áÊ≥®ËÄÖ‰πãÈó¥ÂíåÊ†áÊ≥®ËÄÖÂÜÖÈÉ®ÁöÑ‰∏ÄËá¥ÊÄßÊù•‰∫ÜËß£ÊØè‰∏™Ê†áÊ≥®ËÄÖÁöÑÂèØÈù†ÊÄßÔºåÂπ∂ÂΩ±ÂìçÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑËÆ≠ÁªÉÔºå‰ª•‰æøÊ†πÊçÆÊ†áÊ≥®ËÄÖÁöÑÂèØÈù†ÊÄßËøõË°åÂàÜÁ±ª„ÄÇÂú®ËØÑ‰º∞ EffiARA Ê†áÊ≥®Ê°ÜÊû∂Êó∂ÔºåÂºÄÂèë‰∫Ü‰øÑ‰πåÂÜ≤Á™ÅÁü•ËØÜÂûãÈîôËØØËÆØÊÅØÂàÜÁ±ªÊï∞ÊçÆÈõÜ (RUC-MCD)ÔºåÂπ∂ÂÖ¨ÂºÄÊèê‰æõ„ÄÇÊú¨Á†îÁ©∂ÂèëÁé∞Ôºå‰ΩøÁî®Ê†áÊ≥®ËÄÖÂèØÈù†ÊÄßËøõË°åÊ†∑Êú¨Âä†ÊùÉË°®Áé∞ÊúÄ‰Ω≥ÔºåÂêåÊó∂Âà©Áî®Ê†áÊ≥®ËÄÖ‰πãÈó¥ÂíåÊ†áÊ≥®ËÄÖÂÜÖÈÉ®ÁöÑ‰∏ÄËá¥ÊÄßÔºå‰ª•ÂèäËΩØÊ†áÁ≠æËÆ≠ÁªÉ„ÄÇ‰ΩøÁî® Llama-3.2-1B ËææÂà∞ÁöÑÊúÄÈ´òÂàÜÁ±ªÊïàËÉΩÔºå‰ΩøÁî® TwHIN-BERT-large Êó∂ÔºåÂÆèËßÇ F1 ÂàÜÂà´‰∏∫ 0.757 Âíå 0.740„ÄÇ

##### **LEAD: Latent Realignment for Human Motion Diffusion**
2410.14508v1 by Nefeli Andreou, Xi Wang, Victoria Fern√°ndez Abrevaya, Marie-Paule Cani, Yiorgos Chrysanthou, Vicky Kalogeiton

Our goal is to generate realistic human motion from natural language. Modern
methods often face a trade-off between model expressiveness and text-to-motion
alignment. Some align text and motion latent spaces but sacrifice
expressiveness; others rely on diffusion models producing impressive motions,
but lacking semantic meaning in their latent space. This may compromise
realism, diversity, and applicability. Here, we address this by combining
latent diffusion with a realignment mechanism, producing a novel, semantically
structured space that encodes the semantics of language. Leveraging this
capability, we introduce the task of textual motion inversion to capture novel
motion concepts from a few examples. For motion synthesis, we evaluate LEAD on
HumanML3D and KIT-ML and show comparable performance to the state-of-the-art in
terms of realism, diversity, and text-motion consistency. Our qualitative
analysis and user study reveal that our synthesized motions are sharper, more
human-like and comply better with the text compared to modern methods. For
motion textual inversion, our method demonstrates improved capacity in
capturing out-of-distribution characteristics in comparison to traditional
VAEs.

ÊëòË¶ÅÔºöÊàë‰ª¨ÁöÑÁõÆÊ†áÊòØÊ†πÊçÆËá™ÁÑ∂ËØ≠Ë®ÄÁîüÊàêÈÄºÁúüÁöÑÁúü‰∫∫Âä®‰Ωú„ÄÇÁé∞‰ª£ÊñπÊ≥ïÈÄöÂ∏∏‰ºöÂú®Ê®°ÂûãË°®Áé∞Âäõ‰∏éÊñáÊú¨Âà∞Âä®‰ΩúÁöÑÊØîÂØπ‰πãÈó¥Èù¢‰∏¥ÊùÉË°°„ÄÇ‰∏Ä‰∫õÊñπÊ≥ïÊØîÂØπ‰∫ÜÊñáÊú¨ÂíåÂä®‰ΩúÁöÑÊΩúÂú®Á©∫Èó¥Ôºå‰ΩÜÁâ∫Áâ≤‰∫ÜË°®Áé∞ÂäõÔºõÂÖ∂‰ªñÊñπÊ≥ï‰æùÈù†Êâ©Êï£Ê®°ÂûãÊù•Âà∂‰Ωú‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÂä®‰ΩúÔºå‰ΩÜÂÖ∂ÊΩúÂú®Á©∫Èó¥Áº∫‰πèËØ≠‰πâÂê´‰πâ„ÄÇËøôÂèØËÉΩ‰ºöÊçüÂÆ≥ÁúüÂÆûÊÄß„ÄÅÂ§öÊ†∑ÊÄßÂíåÈÄÇÁî®ÊÄß„ÄÇÂú®ËøôÈáåÔºåÊàë‰ª¨ÈÄöËøáÂ∞ÜÊΩúÂú®Êâ©Êï£‰∏éÈáçÊñ∞ÊØîÂØπÊú∫Âà∂Áõ∏ÁªìÂêàÊù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºå‰ªéËÄåÁîüÊàê‰∏Ä‰∏™Êñ∞È¢ñÁöÑ„ÄÅËØ≠‰πâÁªìÊûÑÂåñÁöÑÁ©∫Èó¥ÔºåÂØπËØ≠Ë®ÄÁöÑËØ≠‰πâËøõË°åÁºñÁ†Å„ÄÇÂà©Áî®ËøôÁßçËÉΩÂäõÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÊñáÊú¨Âä®‰ΩúÂèçÊºî‰ªªÂä°Ôºå‰ª•‰ªéÂá†‰∏™Á§∫‰æã‰∏≠ÊçïÊçâÊñ∞È¢ñÁöÑÂä®‰ΩúÊ¶ÇÂøµ„ÄÇÂØπ‰∫éÂä®‰ΩúÂêàÊàêÔºåÊàë‰ª¨Âú® HumanML3D Âíå KIT-ML ‰∏äËØÑ‰º∞‰∫Ü LEADÔºåÂπ∂Â±ïÁ§∫‰∫Ü‰∏éÊúÄÂÖàËøõÊäÄÊúØÁõ∏ÂΩìÁöÑÊÄßËÉΩÔºåÂåÖÊã¨ÁúüÂÆûÊÄß„ÄÅÂ§öÊ†∑ÊÄßÂíåÊñáÊú¨Âä®‰Ωú‰∏ÄËá¥ÊÄß„ÄÇÊàë‰ª¨ÁöÑÂÆöÊÄßÂàÜÊûêÂíåÁî®Êà∑Á†îÁ©∂Ë°®ÊòéÔºå‰∏éÁé∞‰ª£ÊñπÊ≥ïÁõ∏ÊØîÔºåÊàë‰ª¨ÂêàÊàêÁöÑÂä®‰ΩúÊõ¥Ê∏ÖÊô∞„ÄÅÊõ¥ÂÉèÁúü‰∫∫ÔºåÂπ∂‰∏î‰∏éÊñáÊú¨ÁöÑÂêªÂêàÂ∫¶Êõ¥È´ò„ÄÇÂØπ‰∫éÂä®‰ΩúÊñáÊú¨ÂèçÊºîÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ÊçïÊçâÂàÜÂ∏ÉÂ§ñÁâπÂæÅÊñπÈù¢Â±ïÁ§∫‰∫ÜÊØî‰º†Áªü VAE Êõ¥Âº∫ÁöÑËÉΩÂäõ„ÄÇ

##### **SignAttention: On the Interpretability of Transformer Models for Sign Language Translation**
2410.14506v1 by Pedro Alejandro Dal Bianco, Oscar Agust√≠n Stanchi, Facundo Manuel Quiroga, Franco Ronchetti, Enzo Ferrante

This paper presents the first comprehensive interpretability analysis of a
Transformer-based Sign Language Translation (SLT) model, focusing on the
translation from video-based Greek Sign Language to glosses and text.
Leveraging the Greek Sign Language Dataset, we examine the attention mechanisms
within the model to understand how it processes and aligns visual input with
sequential glosses. Our analysis reveals that the model pays attention to
clusters of frames rather than individual ones, with a diagonal alignment
pattern emerging between poses and glosses, which becomes less distinct as the
number of glosses increases. We also explore the relative contributions of
cross-attention and self-attention at each decoding step, finding that the
model initially relies on video frames but shifts its focus to previously
predicted tokens as the translation progresses. This work contributes to a
deeper understanding of SLT models, paving the way for the development of more
transparent and reliable translation systems essential for real-world
applications.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèê‰æõ‰∫ÜÂü∫Êñº Transformer ÁöÑÊâãË™ûÁøªË≠Ø (SLT) Ê®°ÂûãÁöÑÁ¨¨‰∏ÄÂÄãÂÖ®Èù¢ÂèØËß£ÈáãÊÄßÂàÜÊûêÔºåÈáçÈªûÈóúÊ≥®ÂæûÂΩ±ÁâáÂ∏åËáòÊâãË™ûÁøªË≠ØÊàêÁ¨¶ËôüÂíåÊñáÂ≠ó„ÄÇ
Âà©Áî®Â∏åËáòÊâãË™ûË≥áÊñôÈõÜÔºåÊàëÂÄëÊ™¢Ë¶ñÊ®°Âûã‰∏≠ÁöÑÊ≥®ÊÑèÂäõÊ©üÂà∂Ôºå‰ª•‰∫ÜËß£ÂÆÉÂ¶Ç‰ΩïËôïÁêÜÂíåÂ∞áË¶ñË¶∫Ëº∏ÂÖ•ËàáÈ†ÜÂ∫èÁ¨¶ËôüÂ∞çÈΩä„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÊ®°ÂûãÈóúÊ≥®ÁöÑÊòØÊàêÁæ§ÁöÑÁï´Èù¢ÔºåËÄå‰∏çÊòØÂÄãÂà•Áï´Èù¢ÔºåÂßøÂã¢ÂíåÁ¨¶Ëôü‰πãÈñìÂá∫ÁèæÂ∞çËßíÁ∑öÂ∞çÈΩäÊ®°ÂºèÔºåÈö®ËëóÁ¨¶ËôüÊï∏ÈáèÁöÑÂ¢ûÂä†ÔºåÈÄôÁ®ÆÂ∞çÈΩäÊ®°ÂºèËÆäÂæó‰∏çÈÇ£È∫ºÊòéÈ°Ø„ÄÇÊàëÂÄëÈÇÑÊé¢Ë®é‰∫ÜÂú®ÊØèÂÄãËß£Á¢ºÊ≠•È©ü‰∏≠‰∫§ÂèâÊ≥®ÊÑèÂäõÂíåËá™ÊàëÊ≥®ÊÑèÂäõÁöÑÁõ∏Â∞çË≤¢ÁçªÔºåÁôºÁèæÊ®°ÂûãÊúÄÂàù‰æùË≥¥ÊñºÂΩ±ÁâáÁï´Èù¢Ôºå‰ΩÜÈö®ËëóÁøªË≠ØÁöÑÈÄ≤Ë°åÔºåÂÆÉÂ∞áÈáçÈªûËΩâÁßªÂà∞ÂÖàÂâçÈ†êÊ∏¨ÁöÑÁ¨¶Ëôü‰∏ä„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ SLT Ê®°ÂûãÔºåÁÇ∫ÈñãÁôºÊõ¥ÈÄèÊòé‰∏îÂèØÈù†ÁöÑÁøªË≠ØÁ≥ªÁµ±Èã™Âπ≥ÈÅìË∑ØÔºåÈÄôÂ∞çÊñºÁèæÂØ¶‰∏ñÁïåÁöÑÊáâÁî®Ëá≥ÈóúÈáçË¶Å„ÄÇ

##### **ANT: Adaptive Noise Schedule for Time Series Diffusion Models**
2410.14488v1 by Seunghan Lee, Kibok Lee, Taeyoung Park

Advances in diffusion models for generative artificial intelligence have
recently propagated to the time series (TS) domain, demonstrating
state-of-the-art performance on various tasks. However, prior works on TS
diffusion models often borrow the framework of existing works proposed in other
domains without considering the characteristics of TS data, leading to
suboptimal performance. In this work, we propose Adaptive Noise schedule for
Time series diffusion models (ANT), which automatically predetermines proper
noise schedules for given TS datasets based on their statistics representing
non-stationarity. Our intuition is that an optimal noise schedule should
satisfy the following desiderata: 1) It linearly reduces the non-stationarity
of TS data so that all diffusion steps are equally meaningful, 2) the data is
corrupted to the random noise at the final step, and 3) the number of steps is
sufficiently large. The proposed method is practical for use in that it
eliminates the necessity of finding the optimal noise schedule with a small
additional cost to compute the statistics for given datasets, which can be done
offline before training. We validate the effectiveness of our method across
various tasks, including TS forecasting, refinement, and generation, on
datasets from diverse domains. Code is available at this repository:
https://github.com/seunghan96/ANT.

ÊëòË¶ÅÔºöÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÁöÑÊì¥Êï£Ê®°ÂûãÁöÑÈÄ≤Â±ïÊúÄËøëÂ∑≤ÂÇ≥Êí≠Âà∞ÊôÇÈñìÂ∫èÂàó (TS) È†òÂüüÔºåÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏äÂ±ïÁèæÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÈáùÂ∞ç TS Êì¥Êï£Ê®°ÂûãÁöÑÁ†îÁ©∂ÔºåÁ∂ìÂ∏∏ÂÄüÁî®ÂÖ∂‰ªñÈ†òÂüü‰∏≠Êó¢ÊúâÁ†îÁ©∂ÁöÑÊû∂ÊßãÔºåËÄåÊú™ËÄÉÊÖÆ TS Ë≥áÊñôÁöÑÁâπÊÄßÔºåÂ∞éËá¥ÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÈÅ©Áî®ÊñºÊôÇÈñìÂ∫èÂàóÊì¥Êï£Ê®°ÂûãÁöÑËá™ÈÅ©ÊáâÈõúË®äÊéíÁ®ã (ANT)ÔºåÂÆÉÊúÉÊ†πÊìö‰ª£Ë°®ÈùûÂπ≥Á©©ÊÄßÁöÑÁµ±Ë®àË≥áÊñôÔºåËá™ÂãïÈ†êÂÖàÊ±∫ÂÆöÈÅ©Áï∂ÁöÑÈõúË®äÊéíÁ®ãÔºå‰ª•Êèê‰æõÁµ¶ TS Ë≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÁõ¥Ë¶∫ÊòØÔºåÊúÄ‰Ω≥ÁöÑÈõúË®äÊéíÁ®ãÊáâÊªøË∂≥‰∏ãÂàóÊ¢ù‰ª∂Ôºö1) Á∑öÊÄßÊ∏õÂ∞ë TS Ë≥áÊñôÁöÑÈùûÂπ≥Á©©ÊÄßÔºå‰ª•‰æøÊâÄÊúâÊì¥Êï£Ê≠•È©üÈÉΩÂêåÊ®£ÊúâÊÑèÁæ©Ôºå2) Ë≥áÊñôÂú®ÊúÄÂæå‰∏ÄÂÄãÊ≠•È©üÊúÉÊêçÊØÄÁÇ∫Èö®Ê©üÈõúË®äÔºå‰ª•Âèä 3) Ê≠•È©üÊï∏ÁõÆË∂≥Â§†Â§ö„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÊñºÂÆÉÊ∂àÈô§‰∫ÜÂ∞ãÊâæÊúÄ‰Ω≥ÈõúË®äÊéíÁ®ãÁöÑÂøÖË¶ÅÊÄßÔºåËÄåÂÉÖÈúÄ‰ªòÂá∫Â∞ëÈáèÈ°çÂ§ñÊàêÊú¨‰æÜË®àÁÆóÁµ¶ÂÆöË≥áÊñôÈõÜÁöÑÁµ±Ë®àË≥áÊñôÔºåÈÄôÂèØ‰ª•Âú®Ë®ìÁ∑¥ÂâçÈõ¢Á∑öÂÆåÊàêÔºåÂõ†Ê≠§ÂæàÂØ¶Áî®„ÄÇÊàëÂÄëÂú®ÂêÑÁ®Æ‰ªªÂãôÔºàÂåÖÊã¨ TS È†êÊ∏¨„ÄÅË™øÊï¥ÂíåÁîüÊàêÔºâ‰∏≠È©óË≠â‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåË≥áÊñôÈõÜ‰æÜËá™‰∏çÂêåÁöÑÈ†òÂüü„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú®‰∏ãÂàóÂ≠òÊîæÂ∫´ÂèñÂæóÔºöhttps://github.com/seunghan96/ANT„ÄÇ

##### **DRL Optimization Trajectory Generation via Wireless Network Intent-Guided Diffusion Models for Optimizing Resource Allocation**
2410.14481v1 by Junjie Wu, Xuming Fang, Dusit Niyato, Jiacheng Wang, Jingyu Wang

With the rapid advancements in wireless communication fields, including
low-altitude economies, 6G, and Wi-Fi, the scale of wireless networks continues
to expand, accompanied by increasing service quality demands. Traditional deep
reinforcement learning (DRL)-based optimization models can improve network
performance by solving non-convex optimization problems intelligently. However,
they heavily rely on online deployment and often require extensive initial
training. Online DRL optimization models typically make accurate decisions
based on current channel state distributions. When these distributions change,
their generalization capability diminishes, which hinders the responsiveness
essential for real-time and high-reliability wireless communication networks.
Furthermore, different users have varying quality of service (QoS) requirements
across diverse scenarios, and conventional online DRL methods struggle to
accommodate this variability. Consequently, exploring flexible and customized
AI strategies is critical. We propose a wireless network intent (WNI)-guided
trajectory generation model based on a generative diffusion model (GDM). This
model can be generated and fine-tuned in real time to achieve the objective and
meet the constraints of target intent networks, significantly reducing state
information exposure during wireless communication. Moreover, The WNI-guided
optimization trajectory generation can be customized to address differentiated
QoS requirements, enhancing the overall quality of communication in future
intelligent networks. Extensive simulation results demonstrate that our
approach achieves greater stability in spectral efficiency variations and
outperforms traditional DRL optimization models in dynamic communication
systems.

ÊëòË¶ÅÔºöÈö®ËëóÁÑ°Á∑öÈÄöË®äÈ†òÂüüÁöÑÂø´ÈÄüÈÄ≤Â±ïÔºåÂåÖÊã¨‰ΩéÁ©∫Á∂ìÊøü„ÄÅ6G Âíå Wi-FiÔºåÁÑ°Á∑öÁ∂≤Ë∑ØÁöÑË¶èÊ®°ÊåÅÁ∫åÊì¥Â§ßÔºå‰º¥Èö®ËëóÂ∞çÊúçÂãôÂìÅË≥™ÈúÄÊ±ÇÁöÑÊèêÂçá„ÄÇÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Âº∑ÂåñÂ≠∏Áøí (DRL) ÂÑ™ÂåñÊ®°ÂûãÂèØ‰ª•ÈÄèÈÅéÊô∫ÊÖßÂú∞Ëß£Ê±∫ÈùûÂá∏ÂÑ™ÂåñÂïèÈ°å‰æÜÊèêÂçáÁ∂≤Ë∑ØÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÈ´òÂ∫¶‰æùË≥¥Á∑ö‰∏äÈÉ®ÁΩ≤ÔºåËÄå‰∏îÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑÂàùÂßãË®ìÁ∑¥„ÄÇÁ∑ö‰∏ä DRL ÂÑ™ÂåñÊ®°ÂûãÈÄöÂ∏∏ÊúÉÊ†πÊìöÁõÆÂâçÁöÑÈ†ªÈÅìÁãÄÊÖãÂàÜ‰ΩàÂÅöÂá∫Á≤æÊ∫ñÁöÑÊ±∫Á≠ñ„ÄÇÁï∂ÈÄô‰∫õÂàÜ‰ΩàÊîπËÆäÊôÇÔºåÂÆÉÂÄëÁöÑÊ≥õÂåñËÉΩÂäõÊúÉ‰∏ãÈôçÔºåÈÄôÊúÉÂ¶®Á§ôÂ∞çÂç≥ÊôÇ‰∏îÈ´òÂèØÈù†Â∫¶ÁÑ°Á∑öÈÄöË®äÁ∂≤Ë∑ØËá≥ÈóúÈáçË¶ÅÁöÑÂõûÊáâËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºå‰∏çÂêåÁöÑ‰ΩøÁî®ËÄÖÂú®‰∏çÂêåÁöÑÂ†¥ÊôØ‰∏≠Êúâ‰∏çÂêåÁöÑÊúçÂãôÂìÅË≥™ (QoS) Ë¶ÅÊ±ÇÔºåËÄåÂÇ≥Áµ±ÁöÑÁ∑ö‰∏ä DRL ÊñπÊ≥ïÈõ£‰ª•Âõ†ÊáâÈÄôÁ®ÆËÆäÁï∞ÊÄß„ÄÇÂõ†Ê≠§ÔºåÊé¢Á¥¢ÂΩàÊÄß‰∏îÂÆ¢Ë£ΩÂåñÁöÑ AI Á≠ñÁï•Ëá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÁîüÊàêÊì¥Êï£Ê®°Âûã (GDM) ÁöÑÁÑ°Á∑öÁ∂≤Ë∑ØÊÑèÂúñ (WNI) ÂºïÂ∞éËªåË∑°ÁîüÊàêÊ®°Âûã„ÄÇÈÄôÂÄãÊ®°ÂûãÂèØ‰ª•Âú®Âç≥ÊôÇÁî¢Áîü‰∏¶ÂæÆË™øÔºå‰ª•ÈÅîÊàêÁõÆÊ®ô‰∏¶ÊªøË∂≥ÁõÆÊ®ôÊÑèÂúñÁ∂≤Ë∑ØÁöÑÈôêÂà∂ÔºåÂ§ßÂπÖÊ∏õÂ∞ëÁÑ°Á∑öÈÄöË®ä‰∏≠ÁöÑÁãÄÊÖãË≥áË®äÊö¥Èú≤„ÄÇÊ≠§Â§ñÔºåWNI ÂºïÂ∞éÁöÑÂÑ™ÂåñËªåË∑°ÁîüÊàêÂèØ‰ª•ÂÆ¢Ë£ΩÂåñ‰ª•ÊªøË∂≥‰∏çÂêåÁöÑ QoS Ë¶ÅÊ±ÇÔºåÊèêÂçáÊú™‰æÜÊô∫ÊÖßÁ∂≤Ë∑Ø‰∏≠ÈÄöË®äÁöÑÊï¥È´îÂìÅË≥™„ÄÇÂª£Ê≥õÁöÑÊ®°Êì¨ÁµêÊûúË≠âÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®È†ªË≠úÊïàÁéáËÆäÁï∞‰∏≠ÈÅîÂà∞Êõ¥È´òÁöÑÁ©©ÂÆöÊÄßÔºåËÄå‰∏îÂú®ÂãïÊÖãÈÄöË®äÁ≥ªÁµ±‰∏≠ÂÑ™ÊñºÂÇ≥Áµ±ÁöÑ DRL ÂÑ™ÂåñÊ®°Âûã„ÄÇ

##### **Combining Entropy and Matrix Nuclear Norm for Enhanced Evaluation of Language Models**
2410.14480v1 by James Vo

As large language models (LLMs) continue to advance, the need for precise and
efficient evaluation metrics becomes more pressing. Traditional approaches,
while informative, often face limitations in computational demands and
interpretability. In this paper, we introduce a novel hybrid evaluation method
that integrates two established techniques: entropy derived from covariance
matrices and the Matrix Nuclear Norm (MNN). Our method begins by normalizing
hidden states from LLMs, then computes the covariance matrix and MNN from these
representations. We further calculate the entropy of the covariance matrix to
capture uncertainty and redundancy in the model's outputs. By combining these
metrics into a composite score, we offer a comprehensive evaluation framework
that balances accuracy with computational efficiency. Additionally, our
approach allows for flexibility in adjusting the weightings between entropy and
MNN, tailoring the evaluation for different objectives. Through a series of
experiments on various LLMs, we demonstrate the robustness and efficacy of our
method, offering deeper insights into model performance. This work contributes
to the ongoing development of LLM evaluation and opens avenues for future
innovations in model assessment techniques.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊåÅÁ∫åÈÄ≤Ê≠•ÔºåÂ∞çÁ≤æÁ¢∫‰∏îÊúâÊïàÁéáÁöÑË©ï‰º∞ÊåáÊ®ôÁöÑÈúÄÊ±ÇËÆäÂæóÊõ¥Âä†Ëø´Âàá„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÈõñÁÑ∂ÂÖ∑ÊúâÂèÉËÄÉÂÉπÂÄºÔºå‰ΩÜÈÄöÂ∏∏Âú®ÈÅãÁÆóÈúÄÊ±ÇÂíåÂèØËß£ÈáãÊÄßÊñπÈù¢Èù¢Ëá®ÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ∑∑ÂêàË©ï‰º∞ÊñπÊ≥ïÔºåÂÆÉÊï¥Âêà‰∫ÜÂÖ©Á®ÆÊó¢ÂÆöÁöÑÊäÄË°ìÔºöÂæûÂçîÊñπÂ∑ÆÁü©Èô£‰∏≠ÊèêÂèñÁöÑÁÜµÂíåÁü©Èô£Ê†∏ÁØÑÊï∏ (MNN)„ÄÇÊàëÂÄëÁöÑË©ï‰º∞ÊñπÊ≥ïÈ¶ñÂÖàÂ∞ç LLM ‰∏≠ÁöÑÈö±ËóèÁãÄÊÖãÈÄ≤Ë°åÊ≠£Ë¶èÂåñÔºåÁÑ∂ÂæåÂæûÈÄô‰∫õË°®Á§∫‰∏≠Ë®àÁÆóÂçîÊñπÂ∑ÆÁü©Èô£Âíå MNN„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë®àÁÆóÂçîÊñπÂ∑ÆÁü©Èô£ÁöÑÁÜµÔºå‰ª•ÊçïÊçâÊ®°ÂûãËº∏Âá∫‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂíåÂÜóÈ§ò„ÄÇÈÄöÈÅéÂ∞áÈÄô‰∫õÊåáÊ®ôÁµÑÂêàÊàê‰∏ÄÂÄãÁ∂úÂêàË©ïÂàÜÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑË©ï‰º∞Ê°ÜÊû∂ÔºåÂÆÉÂπ≥Ë°°‰∫ÜÊ∫ñÁ¢∫ÊÄßÂíåÈÅãÁÆóÊïàÁéá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑË©ï‰º∞ÊñπÊ≥ïÂÖÅË®±ÈùàÊ¥ªË™øÊï¥ÁÜµÂíå MNN ‰πãÈñìÁöÑÊ¨äÈáçÔºåÈáùÂ∞ç‰∏çÂêåÁöÑÁõÆÊ®ôË™øÊï¥Ë©ï‰º∞„ÄÇÈÄèÈÅéÂ∞çÂêÑÁ®Æ LLM ÈÄ≤Ë°å‰∏ÄÁ≥ªÂàóÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÁöÑÁ©©ÂÅ•ÊÄßÂíåÊúâÊïàÊÄßÔºåÊèê‰æõ‰∫ÜÂ∞çÊ®°ÂûãÊïàËÉΩÊõ¥Ê∑±ÂÖ•ÁöÑË¶ãËß£„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊúâÂä©Êñº LLM Ë©ï‰º∞ÁöÑÊåÅÁ∫åÁôºÂ±ïÔºå‰∏¶ÁÇ∫Ê®°ÂûãË©ï‰º∞ÊäÄË°ìÁöÑÊú™‰æÜÂâµÊñ∞ÈñãÂïü‰∫ÜÈÅìË∑Ø„ÄÇ

##### **How Do Training Methods Influence the Utilization of Vision Models?**
2410.14470v1 by Paul Gavrikov, Shashank Agnihotri, Margret Keuper, Janis Keuper

Not all learnable parameters (e.g., weights) contribute equally to a neural
network's decision function. In fact, entire layers' parameters can sometimes
be reset to random values with little to no impact on the model's decisions. We
revisit earlier studies that examined how architecture and task complexity
influence this phenomenon and ask: is this phenomenon also affected by how we
train the model? We conducted experimental evaluations on a diverse set of
ImageNet-1k classification models to explore this, keeping the architecture and
training data constant but varying the training pipeline. Our findings reveal
that the training method strongly influences which layers become critical to
the decision function for a given task. For example, improved training regimes
and self-supervised training increase the importance of early layers while
significantly under-utilizing deeper layers. In contrast, methods such as
adversarial training display an opposite trend. Our preliminary results extend
previous findings, offering a more nuanced understanding of the inner mechanics
of neural networks.
  Code: https://github.com/paulgavrikov/layer_criticality

ÊëòË¶ÅÔºö‰∏¶ÈùûÊâÄÊúâÂèØÂ≠∏ÁøíÂèÉÊï∏Ôºà‰æãÂ¶ÇÊ¨äÈáçÔºâÈÉΩËÉΩÂπ≥Á≠âÂú∞‰øÉÊàêÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊ±∫Á≠ñÂáΩÊï∏„ÄÇ‰∫ãÂØ¶‰∏äÔºåÊúâÊôÇÂèØ‰ª•Â∞áÊï¥Â±§ÁöÑÂèÉÊï∏ÈáçÁΩÆÁÇ∫Èö®Ê©üÂÄºÔºåËÄåÂ∞çÊ®°ÂûãÁöÑÊ±∫Á≠ñÂπæ‰πéÊ≤íÊúâÂΩ±Èüø„ÄÇÊàëÂÄëÈáçÊñ∞Êé¢Ë®é‰∫ÜÂÖàÂâçÊé¢Ë®éÊû∂ÊßãÂíå‰ªªÂãôË§áÈõúÂ∫¶Â¶Ç‰ΩïÂΩ±ÈüøÊ≠§ÁèæË±°ÁöÑÁ†îÁ©∂Ôºå‰∏¶ÊèêÂá∫ÂïèÈ°åÔºöÊ≠§ÁèæË±°ÊòØÂê¶‰πüÂèóÊàëÂÄëË®ìÁ∑¥Ê®°ÂûãÁöÑÊñπÂºèÂΩ±ÈüøÔºüÊàëÂÄëÂ∞ç ImageNet-1k ÂàÜÈ°ûÊ®°ÂûãÁöÑÂ§öÊ®£ÂåñÈõÜÂêàÈÄ≤Ë°å‰∫ÜÂØ¶È©óÊÄßË©ï‰º∞Ôºå‰ª•Êé¢Á¥¢ÈÄô‰∏ÄÈªûÔºå‰øùÊåÅÊû∂ÊßãÂíåË®ìÁ∑¥Ë≥áÊñô‰∏çËÆäÔºå‰ΩÜÊîπËÆäË®ìÁ∑¥ÁÆ°ÈÅì„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåË®ìÁ∑¥ÊñπÊ≥ïÂº∑ÁÉàÂΩ±ÈüøÂì™‰∫õÂ±§Â∞çÊñºÁµ¶ÂÆö‰ªªÂãôÁöÑÊ±∫Á≠ñÂáΩÊï∏Ëá≥ÈóúÈáçË¶Å„ÄÇ‰æãÂ¶ÇÔºåÊîπÂñÑÁöÑË®ìÁ∑¥ÊñπÂºèÂíåËá™ÊàëÁõ£Áù£Ë®ìÁ∑¥Â¢ûÂä†‰∫ÜÊó©ÊúüÂ±§ÁöÑÈáçË¶ÅÊÄßÔºåÂêåÊôÇÈ°ØËëóÂú∞Ê∏õÂ∞ë‰∫ÜÊ∑±Â∫¶Â±§ÁöÑÂà©Áî®Áéá„ÄÇÁõ∏ÂèçÔºåÂ∞çÊäóË®ìÁ∑¥Á≠âÊñπÊ≥ïÂâáÂëàÁèæÁõ∏ÂèçÁöÑË∂®Âã¢„ÄÇÊàëÂÄëÁöÑÂàùÊ≠•ÁµêÊûúÊì¥Â±ï‰∫ÜÂÖàÂâçÁöÑÁ†îÁ©∂ÁµêÊûúÔºåÊèê‰æõ‰∫ÜÂ∞çÁ•ûÁ∂ìÁ∂≤Ë∑ØÂÖßÈÉ®Ê©üÂà∂ÁöÑÊõ¥Á¥∞Á∑ªÁêÜËß£„ÄÇ
Á®ãÂºèÁ¢ºÔºöhttps://github.com/paulgavrikov/layer_criticality

##### **The Propensity for Density in Feed-forward Models**
2410.14461v1 by Nandi Schoots, Alex Jackson, Ali Kholmovaia, Peter McBurney, Murray Shanahan

Does the process of training a neural network to solve a task tend to use all
of the available weights even when the task could be solved with fewer weights?
To address this question we study the effects of pruning fully connected,
convolutional and residual models while varying their widths. We find that the
proportion of weights that can be pruned without degrading performance is
largely invariant to model size. Increasing the width of a model has little
effect on the density of the pruned model relative to the increase in absolute
size of the pruned network. In particular, we find substantial prunability
across a large range of model sizes, where our biggest model is 50 times as
wide as our smallest model. We explore three hypotheses that could explain
these findings.

ÊëòË¶ÅÔºöË®ìÁ∑¥Á•ûÁ∂ìÁ∂≤Ë∑Ø‰ª•Ëß£Ê±∫‰ªªÂãôÁöÑÈÅéÁ®ãÊòØÂê¶ÂÇæÂêëÊñº‰ΩøÁî®ÊâÄÊúâÂèØÁî®ÁöÑÊ¨äÈáçÔºåÂç≥‰ΩøË©≤‰ªªÂãôÂèØ‰ª•Áî®Êõ¥Â∞ëÁöÑÊ¨äÈáç‰æÜËß£Ê±∫Ôºü
ÁÇ∫‰∫ÜÂõûÁ≠îÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÁ†îÁ©∂‰∫ÜÂú®ÊîπËÆäÂØ¨Â∫¶ÁöÑÂêåÊôÇÔºå‰øÆÂâ™ÂÖ®ÈÄ£Êé•„ÄÅÂç∑Á©çÂíåÊÆòÂ∑ÆÊ®°ÂûãÁöÑÊïàÊûú„ÄÇÊàëÂÄëÁôºÁèæÔºåÂèØ‰ª•Âú®‰∏çÈôç‰ΩéÊïàËÉΩÁöÑÊÉÖÊ≥Å‰∏ã‰øÆÂâ™ÁöÑÊ¨äÈáçÊØî‰æãÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äËàáÊ®°ÂûãÂ§ßÂ∞èÁÑ°Èóú„ÄÇÂ¢ûÂä†Ê®°ÂûãÁöÑÂØ¨Â∫¶Â∞ç‰øÆÂâ™Ê®°ÂûãÁöÑÂØÜÂ∫¶Âπæ‰πéÊ≤íÊúâÂΩ±ÈüøÔºåÁõ∏Â∞çÊñº‰øÆÂâ™Á∂≤Ë∑ØÁöÑÁµïÂ∞çÂ§ßÂ∞èËÄåË®Ä„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁôºÁèæÂêÑÁ®ÆÊ®°ÂûãÂ§ßÂ∞èÈÉΩÊúâÂ§ßÈáèÁöÑÂèØ‰øÆÂâ™ÊÄßÔºåÂÖ∂‰∏≠ÊàëÂÄëÊúÄÂ§ßÁöÑÊ®°ÂûãÊØîÊàëÂÄëÊúÄÂ∞èÁöÑÊ®°ÂûãÂØ¨ 50 ÂÄç„ÄÇÊàëÂÄëÊé¢Ë®é‰∫Ü‰∏âÁ®ÆÂèØ‰ª•Ëß£ÈáãÈÄô‰∫õÁôºÁèæÁöÑÂÅáË®≠„ÄÇ

##### **Toward Generalizing Visual Brain Decoding to Unseen Subjects**
2410.14445v1 by Xiangtao Kong, Kexin Huang, Ping Li, Lei Zhang

Visual brain decoding aims to decode visual information from human brain
activities. Despite the great progress, one critical limitation of current
brain decoding research lies in the lack of generalization capability to unseen
subjects. Prior works typically focus on decoding brain activity of individuals
based on the observation that different subjects exhibit different brain
activities, while it remains unclear whether brain decoding can be generalized
to unseen subjects. This study aims to answer this question. We first
consolidate an image-fMRI dataset consisting of stimulus-image and
fMRI-response pairs, involving 177 subjects in the movie-viewing task of the
Human Connectome Project (HCP). This dataset allows us to investigate the brain
decoding performance with the increase of participants. We then present a
learning paradigm that applies uniform processing across all subjects, instead
of employing different network heads or tokenizers for individuals as in
previous methods, which can accommodate a large number of subjects to explore
the generalization capability across different subjects. A series of
experiments are conducted and we have the following findings. First, the
network exhibits clear generalization capabilities with the increase of
training subjects. Second, the generalization capability is common to popular
network architectures (MLP, CNN and Transformer). Third, the generalization
performance is affected by the similarity between subjects. Our findings reveal
the inherent similarities in brain activities across individuals. With the
emerging of larger and more comprehensive datasets, it is possible to train a
brain decoding foundation model in the future.Codes and models can be found at
https://github.com/Xiangtaokong/TGBD.

ÊëòË¶ÅÔºöË¶ñË¶∫Â§ßËÖ¶Ëß£Á¢ºÊó®Âú®Âæû‰∫∫ËÖ¶Ê¥ªÂãï‰∏≠Ëß£Á¢ºË¶ñË¶∫Ë≥áË®ä„ÄÇÂÑòÁÆ°ÂèñÂæó‰∫ÜÂ∑®Â§ßÈÄ≤Â±ïÔºå‰ΩÜÁï∂ÂâçÂ§ßËÖ¶Ëß£Á¢ºÁ†îÁ©∂ÁöÑ‰∏ÄÂÄãÈóúÈçµÈôêÂà∂Âú®ÊñºÁº∫‰πèÂ∞çÊú™Ë¶ãÂèóË©¶ËÄÖÁöÑÊ¶ÇÂåñËÉΩÂäõ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ÈÄöÂ∏∏Â∞àÊ≥®ÊñºÊ†πÊìö‰∏çÂêåÂèóË©¶ËÄÖË°®ÁèæÂá∫‰∏çÂêåÁöÑËÖ¶Ê¥ªÂãï‰æÜËß£Á¢ºÂÄãÈ´îÁöÑËÖ¶Ê¥ªÂãïÔºåËÄåÂ§ßËÖ¶Ëß£Á¢ºÊòØÂê¶ËÉΩÊ¶ÇÂåñÂà∞Êú™Ë¶ãÂèóË©¶ËÄÖ‰ªç‰∏çÊ∏ÖÊ•ö„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÂõûÁ≠îÈÄôÂÄãÂïèÈ°å„ÄÇÊàëÂÄëÈ¶ñÂÖàÊï¥Âêà‰∏ÄÂÄãÂΩ±ÂÉè fMRI Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´Âà∫ÊøÄÂΩ±ÂÉèÂíå fMRI ÂèçÊáâÈÖçÂ∞çÔºåÊ∂âÂèäÈõªÂΩ±ËßÄÁúã‰ªªÂãô‰∏≠ÁöÑ‰∫∫È°ûÈÄ£Êé•ÁµÑË®àÁï´ (HCP) ÁöÑ 177 ‰ΩçÂèóË©¶ËÄÖ„ÄÇÊ≠§Ë≥áÊñôÈõÜËÆìÊàëÂÄëËÉΩÂ§†Èö®ËëóÂèÉËàáËÄÖÂ¢ûÂä†‰æÜË™øÊü•Â§ßËÖ¶Ëß£Á¢ºÊïàËÉΩ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂ≠∏ÁøíÁØÑ‰æãÔºåÂ∞çÊâÄÊúâÂèóË©¶ËÄÖÂ•óÁî®‰∏ÄËá¥ÁöÑËôïÁêÜÔºåËÄå‰∏çÊòØÂÉèÂÖàÂâçÊñπÊ≥ïÈÇ£Ê®£ÁÇ∫ÂÄã‰∫∫Êé°Áî®‰∏çÂêåÁöÑÁ∂≤Ë∑ØÂçÄÂ°äÊàñÊ®ôË®òÂåñÂô®ÔºåÈÄôËÉΩÂÆπÁ¥çÂ§ßÈáèÁöÑÂèóË©¶ËÄÖ‰æÜÊé¢Á¥¢‰∏çÂêåÂèóË©¶ËÄÖ‰πãÈñìÁöÑÊ¶ÇÂåñËÉΩÂäõ„ÄÇÈÄ≤Ë°å‰∫Ü‰∏ÄÁ≥ªÂàóÂØ¶È©óÔºåÊàëÂÄëÊúâ‰ª•‰∏ãÁôºÁèæ„ÄÇÈ¶ñÂÖàÔºåÁ∂≤Ë∑ØÈö®ËëóË®ìÁ∑¥ÂèóË©¶ËÄÖÁöÑÂ¢ûÂä†ËÄåË°®ÁèæÂá∫ÊòéÈ°ØÁöÑÊ¶ÇÂåñËÉΩÂäõ„ÄÇÂÖ∂Ê¨°ÔºåÊ¶ÇÂåñËÉΩÂäõÂú®ÊµÅË°åÁöÑÁ∂≤Ë∑ØÊû∂ÊßãÔºàMLP„ÄÅCNN Âíå TransformerÔºâ‰∏≠ÊòØÂ∏∏Ë¶ãÁöÑ„ÄÇÁ¨¨‰∏âÔºåÊ¶ÇÂåñÊïàËÉΩÂèóÂèóË©¶ËÄÖ‰πãÈñìÁõ∏‰ººÊÄßÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁôºÁèæÊè≠Á§∫‰∫ÜÂÄã‰∫∫‰πãÈñìËÖ¶Ê¥ªÂãïÁöÑÂÖßÂú®Áõ∏‰ººÊÄß„ÄÇÈö®ËëóÊõ¥Â§ß„ÄÅÊõ¥ÂÖ®Èù¢ÁöÑË≥áÊñôÈõÜÁöÑÂá∫ÁèæÔºåÊú™‰æÜÊúâÂèØËÉΩË®ìÁ∑¥‰∏ÄÂÄãÂ§ßËÖ¶Ëß£Á¢ºÂü∫Á§éÊ®°Âûã„ÄÇÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂèØ‰ª•Âú® https://github.com/Xiangtaokong/TGBD ‰∏≠ÊâæÂà∞„ÄÇ

##### **A Systematic Study of Cross-Layer KV Sharing for Efficient LLM Inference**
2410.14442v1 by You Wu, Haoyi Wu, Kewei Tu

Recently, sharing key-value (KV) cache across layers has been found effective
in efficient inference of large language models (LLMs). To systematically
investigate different techniques of cross-layer KV sharing, we propose a
unified framework that covers several recent methods and their novel variants.
We conduct comprehensive experiments on all the configurations of the
framework, evaluating their generation throughput and performance in language
modeling and downstream tasks. We find that when reducing the size of the KV
cache by 2x, most configurations can achieve competitive performance to and
higher throughput than standard transformers, but when further reducing the
size of the KV cache, pairing queries of all layers with KVs of upper layers
can better maintain performance, although it also introduces additional
training cost and prefilling latency. We hope that this work will help users
choose the appropriate approach according to their requirements and facilitate
research on the acceleration of LLM inference.

ÊëòË¶ÅÔºöÊúÄËøëÔºåÁôºÁèæË∑®Â±§ÂÖ±‰∫´ÈçµÂÄº (KV) Âø´ÂèñÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈ´òÊïàÊé®ÁêÜ‰∏≠ÂæàÊúâÊïà„ÄÇÁÇ∫‰∫ÜÁ≥ªÁµ±Âú∞Á†îÁ©∂Ë∑®Â±§ KV ÂÖ±‰∫´ÁöÑ‰∏çÂêåÊäÄË°ìÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊ°ÜÊû∂ÔºåÊ∂µËìã‰∫ÜÂπæÁ®ÆÊúÄËøëÁöÑÊñπÊ≥ïÂèäÂÖ∂Êñ∞Á©éÁöÑËÆäÈ´î„ÄÇÊàëÂÄëÂ∞çÊ°ÜÊû∂ÁöÑÊâÄÊúâÈÖçÁΩÆÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåË©ï‰º∞‰∫ÜÂÆÉÂÄëÂú®Ë™ûË®ÄÂª∫Ê®°Âíå‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÁöÑÁîüÊàêÂêûÂêêÈáèÂíåÊïàËÉΩ„ÄÇÊàëÂÄëÁôºÁèæÔºåÁï∂Â∞á KV Âø´ÂèñÁöÑÂ§ßÂ∞èÊ∏õÂ∞ë 2 ÂÄçÊôÇÔºåÂ§ßÂ§öÊï∏ÈÖçÁΩÆÈÉΩÂèØ‰ª•ÈÅîÂà∞ËàáÊ®ôÊ∫ñTransformerÁõ∏Áï∂ÁöÑÊïàËÉΩÂíåÊõ¥È´òÁöÑÂêûÂêêÈáèÔºå‰ΩÜÁï∂ÈÄ≤‰∏ÄÊ≠•Ê∏õÂ∞ë KV Âø´ÂèñÁöÑÂ§ßÂ∞èÊôÇÔºåÂ∞áÊâÄÊúâÂ±§ÁöÑÊü•Ë©¢Ëàá‰∏äÂ±§ÁöÑ KV ÈÖçÂ∞çÂèØ‰ª•Êõ¥Â•ΩÂú∞Á∂≠ÊåÅÊïàËÉΩÔºåÂÑòÁÆ°ÂÆÉ‰πüÊúÉÂºïÂÖ•È°çÂ§ñÁöÑË®ìÁ∑¥ÊàêÊú¨ÂíåÈ†êÂ°´ÂÖÖÂª∂ÈÅ≤„ÄÇÊàëÂÄëÂ∏åÊúõÈÄôÈ†ÖÂ∑•‰ΩúÂ∞áÂπ´Âä©‰ΩøÁî®ËÄÖÊ†πÊìöËá™Â∑±ÁöÑÈúÄÊ±ÇÈÅ∏ÊìáÈÅ©Áï∂ÁöÑÊñπÊ≥ïÔºå‰∏¶‰øÉÈÄ≤Â∞ç LLM Êé®ÁêÜÂä†ÈÄüÁöÑÁ†îÁ©∂„ÄÇ

##### **Learning to refine domain knowledge for biological network inference**
2410.14436v1 by Peiwen Li, Menghua Wu

Perturbation experiments allow biologists to discover causal relationships
between variables of interest, but the sparsity and high dimensionality of
these data pose significant challenges for causal structure learning
algorithms. Biological knowledge graphs can bootstrap the inference of causal
structures in these situations, but since they compile vastly diverse
information, they can bias predictions towards well-studied systems.
Alternatively, amortized causal structure learning algorithms encode inductive
biases through data simulation and train supervised models to recapitulate
these synthetic graphs. However, realistically simulating biology is arguably
even harder than understanding a specific system. In this work, we take
inspiration from both strategies and propose an amortized algorithm for
refining domain knowledge, based on data observations. On real and synthetic
datasets, we show that our approach outperforms baselines in recovering ground
truth causal graphs and identifying errors in the prior knowledge with limited
interventional data.

ÊëòË¶ÅÔºöÊìæÂãïÂØ¶È©óËÆìÁîüÁâ©Â≠∏ÂÆ∂ËÉΩÂ§†ÊâæÂá∫ÊÑüËààË∂£ËÆäÊï∏‰πãÈñìÁöÑÂõ†ÊûúÈóú‰øÇÔºå‰ΩÜÈÄô‰∫õË≥áÊñôÁöÑÁ®ÄÁñèÊÄßÂíåÈ´òÁ∂≠Â∫¶ÊÄßÂ∞çÂõ†ÊûúÁµêÊßãÂ≠∏ÁøíÊºîÁÆóÊ≥ïÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÁîüÁâ©Â≠∏Áü•Ë≠òÂúñË≠úÂèØ‰ª•Âú®ÈÄô‰∫õÊÉÖÊ≥Å‰∏ãÂºïÂ∞éÂõ†ÊûúÁµêÊßãÁöÑÊé®Ë´ñÔºå‰ΩÜÁî±ÊñºÂÆÉÂÄëÁ∑®Ë≠Ø‰∫ÜÈùûÂ∏∏Â§öÊ®£ÂåñÁöÑË≥áË®äÔºåÂõ†Ê≠§ÂèØËÉΩÊúÉÂ∞áÈ†êÊ∏¨ÂÅèÂêëÊñºÁ†îÁ©∂ÂÆåÂñÑÁöÑÁ≥ªÁµ±„ÄÇÊàñËÄÖÔºåÊî§Èä∑Âõ†ÊûúÁµêÊßãÂ≠∏ÁøíÊºîÁÆóÊ≥ïÈÄöÈÅéË≥áÊñôÊ®°Êì¨Á∑®Á¢ºÊ≠∏Á¥çÂÅèÂ∑ÆÔºå‰∏¶Ë®ìÁ∑¥Áõ£Áù£ÂºèÊ®°Âûã‰ª•Ê¶ÇÊã¨ÈÄô‰∫õÂêàÊàêÂúñË≠ú„ÄÇÁÑ∂ËÄåÔºåÁèæÂØ¶Âú∞Ê®°Êì¨ÁîüÁâ©Â≠∏ÂèØ‰ª•Ë™™ÊòØÊØîÁêÜËß£ÁâπÂÆöÁ≥ªÁµ±Êõ¥Âõ∞Èõ£„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂæûÈÄôÂÖ©Á®ÆÁ≠ñÁï•‰∏≠Ê±≤ÂèñÈùàÊÑüÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÊî§Èä∑ÊºîÁÆóÊ≥ïÔºåÁî®ÊñºÊ†πÊìöË≥áÊñôËßÄÂØüÁµêÊûúÁ≤æÁÖâÈ†òÂüüÁü•Ë≠ò„ÄÇÂú®ÁúüÂØ¶ÂíåÂêàÊàêË≥áÊñôÈõÜ‰∏äÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®ÊÅ¢Âæ©ÁúüÂØ¶Âõ†ÊûúÂúñË≠úÂíåË≠òÂà•ÂÖàÈ©óÁü•Ë≠ò‰∏≠ÁöÑÈåØË™§ÊñπÈù¢ÂÑ™ÊñºÂü∫Á∑öÔºå‰∏î‰ªãÂÖ•Ë≥áÊñôÊúâÈôê„ÄÇ

##### **FashionR2R: Texture-preserving Rendered-to-Real Image Translation with Diffusion Models**
2410.14429v1 by Rui Hu, Qian He, Gaofeng He, Jiedong Zhuang, Huang Chen, Huafeng Liu, Huamin Wang

Modeling and producing lifelike clothed human images has attracted
researchers' attention from different areas for decades, with the complexity
from highly articulated and structured content. Rendering algorithms decompose
and simulate the imaging process of a camera, while are limited by the accuracy
of modeled variables and the efficiency of computation. Generative models can
produce impressively vivid human images, however still lacking in
controllability and editability. This paper studies photorealism enhancement of
rendered images, leveraging generative power from diffusion models on the
controlled basis of rendering. We introduce a novel framework to translate
rendered images into their realistic counterparts, which consists of two
stages: Domain Knowledge Injection (DKI) and Realistic Image Generation (RIG).
In DKI, we adopt positive (real) domain finetuning and negative (rendered)
domain embedding to inject knowledge into a pretrained Text-to-image (T2I)
diffusion model. In RIG, we generate the realistic image corresponding to the
input rendered image, with a Texture-preserving Attention Control (TAC) to
preserve fine-grained clothing textures, exploiting the decoupled features
encoded in the UNet structure. Additionally, we introduce SynFashion dataset,
featuring high-quality digital clothing images with diverse textures. Extensive
experimental results demonstrate the superiority and effectiveness of our
method in rendered-to-real image translation.

ÊëòË¶ÅÔºöÊï∏ÂçÅÂπ¥‰æÜÔºåÂª∫Ê®°ÂíåË£Ω‰ΩúÈÄºÁúüÁöÑÁ©øËëó‰∫∫È°ûÂΩ±ÂÉè‰∏ÄÁõ¥Âê∏ÂºïËëó‰∏çÂêåÈ†òÂüüÁöÑÁ†îÁ©∂‰∫∫Âì°ÁöÑÊ≥®ÊÑèÔºåÂÖ∂Ë§áÈõúÊÄß‰æÜËá™ÊñºÈ´òÂ∫¶ÈóúÁØÄÂåñÂíåÁµêÊßãÂåñÁöÑÂÖßÂÆπ„ÄÇÊ∏≤ÊüìÊºîÁÆóÊ≥ïÂàÜËß£‰∏¶Ê®°Êì¨Áõ∏Ê©üÁöÑÊàêÂÉèÈÅéÁ®ãÔºåÂêåÊôÇÂèóÂà∞Âª∫Ê®°ËÆäÊï∏ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÈÅãÁÆóÊïàÁéáÁöÑÈôêÂà∂„ÄÇÁîüÊàêÊ®°ÂûãÂèØ‰ª•Áî¢Áîü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÁîüÂãï‰∫∫È°ûÂΩ±ÂÉèÔºåÁÑ∂ËÄå‰ªçÁÑ∂Áº∫‰πèÂèØÊéßÊÄßÂíåÂèØÁ∑®ËºØÊÄß„ÄÇÊú¨ÊñáÁ†îÁ©∂‰∫ÜÊ∏≤ÊüìÂΩ±ÂÉèÁöÑÂØ´ÂØ¶‰∏ªÁæ©Â¢ûÂº∑ÔºåÂà©Áî®‰∫ÜÊì¥Êï£Ê®°ÂûãÁöÑÁîüÊàêËÉΩÂäõÔºåÂú®Ê∏≤ÊüìÁöÑÂèóÊéßÂü∫Á§é‰∏ä„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÊ°ÜÊû∂ÔºåÂ∞áÊ∏≤ÊüìÂΩ±ÂÉèËΩâÊèõÊàêÂÆÉÂÄëÁöÑÈÄºÁúüÂ∞çÊáâÁâ©ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂÖ©ÂÄãÈöéÊÆµÔºöÈ†òÂüüÁü•Ë≠òÊ≥®ÂÖ• (DKI) ÂíåÈÄºÁúüÂΩ±ÂÉèÁîüÊàê (RIG)„ÄÇÂú® DKI ‰∏≠ÔºåÊàëÂÄëÊé°Áî®Ê≠£ÂêëÔºàÁúüÂØ¶ÔºâÈ†òÂüüÂæÆË™øÂíåË≤†ÂêëÔºàÊ∏≤ÊüìÔºâÈ†òÂüüÂµåÂÖ•ÔºåÂ∞áÁü•Ë≠òÊ≥®ÂÖ•È†êË®ìÁ∑¥ÁöÑÊñáÂ≠óËΩâÂΩ±ÂÉè (T2I) Êì¥Êï£Ê®°Âûã‰∏≠„ÄÇÂú® RIG ‰∏≠ÔºåÊàëÂÄëÁî¢ÁîüËàáËº∏ÂÖ•Ê∏≤ÊüìÂΩ±ÂÉèÂ∞çÊáâÁöÑÈÄºÁúüÂΩ±ÂÉèÔºå‰∏¶‰ΩøÁî®Á¥ãÁêÜ‰øùÁïôÊ≥®ÊÑèÂäõÊéßÂà∂ (TAC) ‰æÜ‰øùÁïôÁ¥∞Á∑ªÁöÑÊúçË£ùÁ¥ãÁêÜÔºåÂà©Áî® UNet ÁµêÊßã‰∏≠Á∑®Á¢ºÁöÑËß£ËÄ¶ÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü SynFashion Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂÖ∑Êúâ‰∏çÂêåÁ¥ãÁêÜÁöÑÈ´òÂìÅË≥™Êï∏‰ΩçÊúçË£ùÂΩ±ÂÉè„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Ê∏≤ÊüìÂà∞ÁúüÂØ¶ÂΩ±ÂÉèËΩâÊèõ‰∏≠ÁöÑÂÑ™Ë∂äÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

##### **Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation**
2410.14425v1 by Shuai Zhao, Xiaobao Wu, Cong-Duy Nguyen, Meihuizi Jia, Yichao Feng, Luu Anh Tuan

Parameter-efficient fine-tuning (PEFT) can bridge the gap between large
language models (LLMs) and downstream tasks. However, PEFT has been proven
vulnerable to malicious attacks. Research indicates that poisoned LLMs, even
after PEFT, retain the capability to activate internalized backdoors when input
samples contain predefined triggers. In this paper, we introduce a novel
weak-to-strong unlearning algorithm to defend against backdoor attacks based on
feature alignment knowledge distillation, named W2SDefense. Specifically, we
first train a small-scale language model through full-parameter fine-tuning to
serve as the clean teacher model. Then, this teacher model guides the
large-scale poisoned student model in unlearning the backdoor, leveraging PEFT.
Theoretical analysis suggests that W2SDefense has the potential to enhance the
student model's ability to unlearn backdoor features, preventing the activation
of the backdoor. We conduct experiments on text classification tasks involving
three state-of-the-art language models and three different backdoor attack
algorithms. Our empirical results demonstrate the outstanding performance of
W2SDefense in defending against backdoor attacks without compromising model
performance.

ÊëòË¶ÅÔºöÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT) ÂèØ‰ª•ÂΩåÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âíå‰∏ãÊ∏∏‰ªªÂãô‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÁÑ∂ËÄåÔºåPEFT Â∑≤Ë¢´Ë≠âÊòéÂÆπÊòìÂèóÂà∞ÊÉ°ÊÑèÊîªÊìä„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºå‰∏≠ÊØíÁöÑ LLMÔºåÂç≥‰ΩøÂú® PEFT ‰πãÂæåÔºå‰ªçÊúâËÉΩÂäõÂú®Ëº∏ÂÖ•ÁØÑ‰æãÂåÖÂê´È†êÂÆöÁæ©Ëß∏ÁôºÂô®ÊôÇÂïüÂãïÂÖßÈÉ®ÂæåÈñÄ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂº±Âà∞Âº∑ÁöÑÈÅ∫ÂøòÊºîÁÆóÊ≥ïÔºå‰ª•Âü∫ÊñºÁâπÂæµÂ∞çÈΩäÁü•Ë≠òËí∏È§æ‰æÜÈò≤Á¶¶ÂæåÈñÄÊîªÊìäÔºåÁ®±ÁÇ∫ W2SDefense„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖàÈÄöÈÅéÂÖ®ÂèÉÊï∏ÂæÆË™øË®ìÁ∑¥‰∏ÄÂÄãÂ∞èË¶èÊ®°Ë™ûË®ÄÊ®°ÂûãÔºå‰ΩúÁÇ∫‰πæÊ∑®ÁöÑÊïôÂ∏´Ê®°Âûã„ÄÇÁÑ∂ÂæåÔºåÈÄôÂÄãÊïôÂ∏´Ê®°ÂûãÊåáÂ∞éÂ§ßË¶èÊ®°‰∏≠ÊØíÁöÑÂ≠∏ÁîüÊ®°ÂûãÂú®Âà©Áî® PEFT ÈÅ∫ÂøòÂæåÈñÄ„ÄÇÁêÜË´ñÂàÜÊûêË°®ÊòéÔºåW2SDefense ÊúâÂèØËÉΩÂ¢ûÂº∑Â≠∏ÁîüÊ®°ÂûãÈÅ∫ÂøòÂæåÈñÄÁâπÂæµÁöÑËÉΩÂäõÔºåÈò≤Ê≠¢ÂæåÈñÄË¢´ÂïüÂãï„ÄÇÊàëÂÄëÂ∞çÊ∂âÂèä‰∏âÂÄãÊúÄÂÖàÈÄ≤Ë™ûË®ÄÊ®°ÂûãÂíå‰∏âÂÄã‰∏çÂêåÂæåÈñÄÊîªÊìäÊºîÁÆóÊ≥ïÁöÑÊñáÊú¨ÂàÜÈ°û‰ªªÂãôÈÄ≤Ë°å‰∫ÜÂØ¶È©ó„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÁµêÊûúË≠âÊòé‰∫Ü W2SDefense Âú®Èò≤Á¶¶ÂæåÈñÄÊîªÊìäÊñπÈù¢ÁöÑÂá∫Ëâ≤Ë°®ÁèæÔºåËÄå‰∏çÊúÉÊêçÂÆ≥Ê®°ÂûãÊÄßËÉΩ„ÄÇ

##### **Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion**
2410.14405v1 by Denitsa Saynova, Lovisa Hagstr√∂m, Moa Johansson, Richard Johansson, Marco Kuhlmann

Previous interpretations of language models (LMs) miss important distinctions
in how these models process factual information. For example, given the query
"Astrid Lindgren was born in" with the corresponding completion "Sweden", no
difference is made between whether the prediction was based on having the exact
knowledge of the birthplace of the Swedish author or assuming that a person
with a Swedish-sounding name was born in Sweden. In this paper, we investigate
four different prediction scenarios for which the LM can be expected to show
distinct behaviors. These scenarios correspond to different levels of model
reliability and types of information being processed - some being less
desirable for factual predictions. To facilitate precise interpretations of LMs
for fact completion, we propose a model-specific recipe called PrISM for
constructing datasets with examples of each scenario based on a set of
diagnostic criteria. We apply a popular interpretability method, causal tracing
(CT), to the four prediction scenarios and find that while CT produces
different results for each scenario, aggregations over a set of mixed examples
may only represent the results from the scenario with the strongest measured
signal. In summary, we contribute tools for a more granular study of fact
completion in language models and analyses that provide a more nuanced
understanding of how LMs process fact-related queries.

ÊëòË¶ÅÔºöÂÖàÂâçÁöÑË™ûË®ÄÊ®°Âûã (LM) Ëß£ÈáãÈÅ∫Êºè‰∫ÜÈÄô‰∫õÊ®°ÂûãÂ¶Ç‰ΩïËôïÁêÜ‰∫ãÂØ¶Ë≥áË®äÁöÑÈáçË¶ÅÂçÄÂà•„ÄÇ‰æãÂ¶ÇÔºåÁµ¶ÂÆöÊü•Ë©¢„ÄåAstrid Lindgren Âá∫ÁîüÊñº„Äç‰∏¶ÂÆåÊàê„ÄåÁëûÂÖ∏„ÄçÔºå‰∏çË´ñÈ†êÊ∏¨ÊòØÂü∫ÊñºÂ∞çÁëûÂÖ∏‰ΩúËÄÖÂá∫ÁîüÂú∞Á¢∫ÂàáÁü•Ë≠òÔºåÈÇÑÊòØÂÅáË®≠ÂêçÂ≠óËÅΩËµ∑‰æÜÂÉèÁëûÂÖ∏‰∫∫ÁöÑÂá∫ÁîüÊñºÁëûÂÖ∏ÔºåÂÖ©ËÄÖ‰πãÈñìÊ≤íÊúâÂçÄÂà•„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂõõÁ®Æ‰∏çÂêåÁöÑÈ†êÊ∏¨ÊÉÖÂ¢ÉÔºåÈ†êË®à LM ÊúÉË°®ÁèæÂá∫‰∏çÂêåÁöÑË°åÁÇ∫„ÄÇÈÄô‰∫õÊÉÖÂ¢ÉÂ∞çÊáâÊñº‰∏çÂêåÁöÑÊ®°ÂûãÂèØÈù†ÊÄßÂ±§Á¥öÂíåÊ≠£Âú®ËôïÁêÜÁöÑË≥áË®äÈ°ûÂûãÔºåÂÖ∂‰∏≠‰∏Ä‰∫õÂ∞çÊñº‰∫ãÂØ¶È†êÊ∏¨ËÄåË®ÄËºÉ‰∏çÁêÜÊÉ≥„ÄÇÁÇ∫‰∫Ü‰æøÊñºÂ∞ç LM ÈÄ≤Ë°åÁ≤æÁ¢∫Ëß£Èáã‰ª•ÂÆåÊàê‰∫ãÂØ¶ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ®±ÁÇ∫ PrISM ÁöÑÁâπÂÆöÊ®°ÂûãÈÖçÊñπÔºåÁî®ÊñºÊ†πÊìö‰∏ÄÁµÑË®∫Êñ∑Ê∫ñÂâáÊßãÂª∫ÂÖ∑ÊúâÊØèÁ®ÆÊÉÖÂ¢ÉÁØÑ‰æãÁöÑË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÂ∞á‰∏ÄÁ®ÆÊµÅË°åÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÂõ†ÊûúËøΩËπ§ (CT) Â•óÁî®Âà∞ÂõõÁ®ÆÈ†êÊ∏¨ÊÉÖÂ¢ÉÔºåÁôºÁèæÂÑòÁÆ° CT ÁÇ∫ÊØèÁ®ÆÊÉÖÂ¢ÉÁî¢Áîü‰∏çÂêåÁöÑÁµêÊûúÔºå‰ΩÜÂ∞ç‰∏ÄÁµÑÊ∑∑ÂêàÁØÑ‰æãÁöÑËÅöÂêàÂèØËÉΩÂè™‰ª£Ë°®Ê∏¨ÈáèË®äËôüÊúÄÂº∑ÁöÑÊÉÖÂ¢ÉÁöÑÁµêÊûú„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëÁÇ∫Êõ¥Á¥∞Á∑ªÂú∞Á†îÁ©∂Ë™ûË®ÄÊ®°Âûã‰∏≠ÁöÑ‰∫ãÂØ¶ÂÆåÊàêÊèê‰æõ‰∫ÜÂ∑•ÂÖ∑Ôºå‰∏¶Êèê‰æõ‰∫ÜÊõ¥Á¥∞Á∑ªÁöÑÂàÜÊûêÔºåË™™Êòé LM Â¶Ç‰ΩïËôïÁêÜËàá‰∫ãÂØ¶Áõ∏ÈóúÁöÑÊü•Ë©¢„ÄÇ

##### **SylloBio-NLI: Evaluating Large Language Models on Biomedical Syllogistic Reasoning**
2410.14399v1 by Magdalena Wysocka, Danilo S. Carvalho, Oskar Wysocki, Marco Valentino, Andre Freitas

Syllogistic reasoning is crucial for Natural Language Inference (NLI). This
capability is particularly significant in specialized domains such as
biomedicine, where it can support automatic evidence interpretation and
scientific discovery. This paper presents SylloBio-NLI, a novel framework that
leverages external ontologies to systematically instantiate diverse syllogistic
arguments for biomedical NLI. We employ SylloBio-NLI to evaluate Large Language
Models (LLMs) on identifying valid conclusions and extracting supporting
evidence across 28 syllogistic schemes instantiated with human genome pathways.
Extensive experiments reveal that biomedical syllogistic reasoning is
particularly challenging for zero-shot LLMs, which achieve an average accuracy
between 70% on generalized modus ponens and 23% on disjunctive syllogism. At
the same time, we found that few-shot prompting can boost the performance of
different LLMs, including Gemma (+14%) and LLama-3 (+43%). However, a deeper
analysis shows that both techniques exhibit high sensitivity to superficial
lexical variations, highlighting a dependency between reliability, models'
architecture, and pre-training regime. Overall, our results indicate that,
while in-context examples have the potential to elicit syllogistic reasoning in
LLMs, existing models are still far from achieving the robustness and
consistency required for safe biomedical NLI applications.

ÊëòË¶ÅÔºö‰∏âÊÆµË´ñÊé®ÁêÜÂ∞çÊñºËá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñ (NLI) Ëá≥ÈóúÈáçË¶Å„ÄÇÊ≠§ËÉΩÂäõÂú®ÁîüÁâ©ÈÜ´Â≠∏Á≠âÂ∞àÊ•≠È†òÂüü‰∏≠ÁâπÂà•ÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÂèØ‰ª•ÊîØÊåÅËá™ÂãïË≠âÊìöËß£ÈáãÂíåÁßëÂ≠∏ÁôºÁèæ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü SylloBio-NLIÔºå‰∏ÄÂÄãÂà©Áî®Â§ñÈÉ®Êú¨‰ΩìË´ñÁ≥ªÁµ±ÂåñÂú∞ÁÇ∫ÁîüÁâ©ÈÜ´Â≠∏ NLI ÂØ¶‰æãÂåñ‰∏çÂêå‰∏âÊÆµË´ñË´ñË≠âÁöÑÊñ∞Ê°ÜÊû∂„ÄÇÊàëÂÄë‰ΩøÁî® SylloBio-NLI ‰æÜË©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ë≠òÂà•ÊúâÊïàÁµêË´ñÂíåÊèêÂèñÊîØÊåÅË≠âÊìöÊñπÈù¢ÁöÑËÉΩÂäõÔºåÈÄô‰∫õË≠âÊìöË∑®Ë∂ä‰∫Ü 28 ÂÄã‰ΩøÁî®‰∫∫È°ûÂü∫Âõ†ÁµÑË∑ØÂæëÂØ¶‰æãÂåñÁöÑ‰∏âÊÆµË´ñÊû∂Êßã„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË°®ÊòéÔºåÁîüÁâ©ÈÜ´Â≠∏‰∏âÊÆµË´ñÊé®ÁêÜÂ∞çÊñºÈõ∂Ê¨°Â≠∏Áøí LLM ‰æÜË™™ÁâπÂà•ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂÆÉÂÄëÂú®Âª£Áæ©ËÇØÂÆöÂºè‰∏≠ÈÅîÂà∞ 70% ÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ÔºåÂú®ÊûêÂèñ‰∏âÊÆµË´ñ‰∏≠ÈÅîÂà∞ 23% ÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶„ÄÇÂêåÊôÇÔºåÊàëÂÄëÁôºÁèæÂ∞ëÊ¨°Â≠∏ÁøíÊèêÁ§∫ÂèØ‰ª•ÊèêÂçá‰∏çÂêå LLM ÁöÑÊÄßËÉΩÔºåÂåÖÊã¨ Gemma (+14%) Âíå LLama-3 (+43%)„ÄÇÁÑ∂ËÄåÔºåÊõ¥Ê∑±ÂÖ•ÁöÑÂàÜÊûêË°®ÊòéÔºåÈÄôÂÖ©Á®ÆÊäÄË°ìÈÉΩÂ∞çË°®Èù¢ÁöÑË©ûÂΩôËÆäÂåñË°®ÁèæÂá∫È´òÂ∫¶ÊïèÊÑüÊÄßÔºåÁ™ÅÂá∫‰∫ÜÂèØÈù†ÊÄß„ÄÅÊ®°ÂûãÊû∂ÊßãÂíåÈ†êË®ìÁ∑¥Ê©üÂà∂‰πãÈñìÁöÑ‰æùË≥¥ÊÄß„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÈõñÁÑ∂‰∏ä‰∏ãÊñáÁØÑ‰æãÊúâÊΩõÂäõÂºïÁôº LLM ‰∏≠ÁöÑ‰∏âÊÆµË´ñÊé®ÁêÜÔºå‰ΩÜÁèæÊúâÊ®°Âûã‰ªçÈÅ†Êú™ÈÅîÂà∞ÂÆâÂÖ®ÁîüÁâ©ÈÜ´Â≠∏ NLI ÊáâÁî®ÊâÄÈúÄÁöÑÁ©©ÂÅ•ÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇ

##### **Generative AI, Pragmatics, and Authenticity in Second Language Learning**
2410.14395v1 by Robert Godwin-Jones`

There are obvious benefits to integrating generative AI (artificial
intelligence) into language learning and teaching. Those include using AI as a
language tutor, creating learning materials, or assessing learner output.
However, due to how AI systems under-stand human language, based on a
mathematical model using statistical probability, they lack the lived
experience to be able to use language with the same social aware-ness as
humans. Additionally, there are built-in linguistic and cultural biases based
on their training data which is mostly in English and predominantly from
Western sources. Those facts limit AI suitability for some language learning
interactions. Stud-ies have clearly shown that systems such as ChatGPT often do
not produce language that is pragmatically appropriate. The lack of linguistic
and cultural authenticity has important implications for how AI is integrated
into second language acquisition as well as in instruction targeting
development of intercultural communication compe-tence.

ÊëòË¶ÅÔºöÂ∞áÁîüÊàêÂºè‰∫∫Â∑•Êô∫ÊÖßÔºà‰∫∫Â∑•Êô∫ÊÖßÔºâÊï¥ÂêàÂà∞Ë™ûË®ÄÂ≠∏ÁøíÂíåÊïôÂ≠∏‰∏≠ÔºåÂÖ∑ÊúâÈ°ØËÄåÊòìË¶ãÁöÑÂ•ΩËôï„ÄÇÈÄô‰∫õÂ•ΩËôïÂåÖÊã¨‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖß‰ΩúÁÇ∫Ë™ûË®ÄÂ∞éÂ∏´„ÄÅÂª∫Á´ãÂ≠∏ÁøíÊùêÊñôÊàñË©ïÈáèÂ≠∏ÁøíËÄÖÁöÑÁî¢Âá∫„ÄÇ
ÁÑ∂ËÄåÔºåÁî±Êñº‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±Â∞ç‰∫∫È°ûË™ûË®ÄÁöÑÁêÜËß£ÔºåÊòØÂü∫Êñº‰ΩøÁî®Áµ±Ë®àÊ©üÁéáÁöÑÊï∏Â≠∏Ê®°ÂûãÔºåÂõ†Ê≠§‰ªñÂÄëÁº∫‰πèÁîüÊ¥ªÁ∂ìÈ©óÔºåÁÑ°Ê≥ïÂÉè‰∫∫È°û‰∏ÄÊ®£Âú®Á§æ‰∫§ÊÑèË≠ò‰∏ä‰ΩøÁî®Ë™ûË®Ä„ÄÇÊ≠§Â§ñÔºåÂü∫Êñº‰∏ªË¶ÅÁÇ∫Ëã±Êñá‰∏îÂ§öÊï∏‰æÜËá™Ë•øÊñπ‰æÜÊ∫êÁöÑË®ìÁ∑¥Ë≥áÊñôÔºåÂ≠òÂú®ÂÖßÂª∫ÁöÑË™ûË®ÄÂíåÊñáÂåñÂÅèË¶ã„ÄÇÈÄô‰∫õ‰∫ãÂØ¶ÈôêÂà∂‰∫Ü‰∫∫Â∑•Êô∫ÊÖßÂ∞çÊüê‰∫õË™ûË®ÄÂ≠∏Áøí‰∫íÂãïÁöÑÈÅ©Áî®ÊÄß„ÄÇÁ†îÁ©∂ÊòéÁ¢∫È°ØÁ§∫Ôºå‰æãÂ¶Ç ChatGPT ÁöÑÁ≥ªÁµ±ÈÄöÂ∏∏‰∏çÊúÉÁî¢ÁîüÂØ¶Áî®ÈÅ©Áï∂ÁöÑË™ûË®Ä„ÄÇË™ûË®ÄÂíåÊñáÂåñÁúüÂØ¶ÊÄßÁöÑÁº∫‰πèÔºåÂ∞ç‰∫∫Â∑•Êô∫ÊÖßÂ¶Ç‰ΩïÊï¥ÂêàÂà∞Á¨¨‰∫åË™ûË®ÄÁøíÂæóÔºå‰ª•ÂèäÈáùÂ∞çÂüπÈ§äË∑®ÊñáÂåñÊ∫ùÈÄöËÉΩÂäõÁöÑÊïôÂ≠∏ÔºåÂÖ∑ÊúâÈáçÂ§ßÁöÑÂΩ±Èüø„ÄÇ

##### **Debug Smarter, Not Harder: AI Agents for Error Resolution in Computational Notebooks**
2410.14393v1 by Konstantin Grotov, Artem Borzilov, Maksim Krivobok, Timofey Bryksin, Yaroslav Zharov

Computational notebooks became indispensable tools for research-related
development, offering unprecedented interactivity and flexibility in the
development process. However, these benefits come at the cost of
reproducibility and an increased potential for bugs. With the rise of
code-fluent Large Language Models empowered with agentic techniques, smart
bug-fixing tools with a high level of autonomy have emerged. However, those
tools are tuned for classical script programming and still struggle with
non-linear computational notebooks. In this paper, we present an AI agent
designed specifically for error resolution in a computational notebook. We have
developed an agentic system capable of exploring a notebook environment by
interacting with it -- similar to how a user would -- and integrated the system
into the JetBrains service for collaborative data science called Datalore. We
evaluate our approach against the pre-existing single-action solution by
comparing costs and conducting a user study. Users rate the error resolution
capabilities of the agentic system higher but experience difficulties with UI.
We share the results of the study and consider them valuable for further
improving user-agent collaboration.

ÊëòË¶ÅÔºöË®àÁÆóÁ≠ÜË®òÊú¨Â∑≤ÊàêÁÇ∫ËàáÁ†îÁ©∂Áõ∏ÈóúÁöÑÈñãÁôº‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÂ∑•ÂÖ∑ÔºåÂú®ÈñãÁôºÈÅéÁ®ã‰∏≠Êèê‰æõ‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑ‰∫íÂãïÊÄßÂíåÈùàÊ¥ªÊÄß„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂ•ΩËôïÊòØ‰ª•ÂèØË§áË£ΩÊÄßÂíåÂ¢ûÂä†ÈåØË™§ÁöÑÊΩõÂäõÁÇ∫‰ª£ÂÉπÁöÑ„ÄÇÈö®ËëóÂÖ∑ÂÇô‰ª£ÁêÜÊäÄË°ìÁöÑ‰ª£Á¢ºÊµÅÊö¢Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑËààËµ∑ÔºåÂÖ∑ÂÇôÈ´òÂ∫¶Ëá™‰∏ªÊÄßÁöÑÊô∫ÊÖßÈåØË™§‰øÆÊ≠£Â∑•ÂÖ∑ÊáâÈÅãËÄåÁîü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂ∑•ÂÖ∑ÊòØÈáùÂ∞çÁ∂ìÂÖ∏ËÖ≥Êú¨Á®ãÂºèË®≠Ë®àÈÄ≤Ë°åË™øÊï¥ÁöÑÔºå‰∏¶‰∏î‰ªçÁÑ∂Èõ£‰ª•Êáâ‰ªòÈùûÁ∑öÊÄßË®àÁÆóÁ≠ÜË®òÊú¨„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ∞àÈñÄÁÇ∫Ë®àÁÆóÁ≠ÜË®òÊú¨‰∏≠ÁöÑÈåØË™§Ëß£ÊûêËÄåË®≠Ë®àÁöÑ‰∫∫Â∑•Êô∫ÊÖß‰ª£ÁêÜ„ÄÇÊàëÂÄëÂ∑≤Á∂ìÈñãÁôº‰∫Ü‰∏ÄÂÄã‰ª£ÁêÜÁ≥ªÁµ±ÔºåÂÆÉËÉΩÂ§†ÈÄèÈÅéËàáÁ≠ÜË®òÊú¨Áí∞Â¢É‰∫íÂãï‰æÜÊé¢Á¥¢Ë©≤Áí∞Â¢É‚Äî‚ÄîÈ°û‰ººÊñº‰ΩøÁî®ËÄÖÁöÑÊñπÂºè‚Äî‚Äî‰∏¶Â∞áË©≤Á≥ªÁµ±Êï¥ÂêàÂà∞ JetBrains ÊúçÂãô‰∏≠Ôºå‰ª•ÈÄ≤Ë°åÂçî‰ΩúË≥áÊñôÁßëÂ≠∏ÔºåÁ®±ÁÇ∫ Datalore„ÄÇÊàëÂÄëÈÄèÈÅéÊØîËºÉÊàêÊú¨‰∏¶ÈÄ≤Ë°å‰ΩøÁî®ËÄÖÁ†îÁ©∂ÔºåÈáùÂ∞çÁèæÊúâÁöÑÂñÆ‰∏ÄÂãï‰ΩúËß£Ê±∫ÊñπÊ°àË©ï‰º∞ÊàëÂÄëÁöÑÂÅöÊ≥ï„ÄÇ‰ΩøÁî®ËÄÖÂ∞ç‰ª£ÁêÜÁ≥ªÁµ±ÁöÑÈåØË™§Ëß£ÊûêÂäüËÉΩË©ïÂÉπËºÉÈ´òÔºå‰ΩÜÂú®‰ΩøÁî®ËÄÖ‰ªãÈù¢‰∏äÈÅáÂà∞Âõ∞Èõ£„ÄÇÊàëÂÄëÂàÜ‰∫´Á†îÁ©∂ÁµêÊûúÔºå‰∏¶Ë™çÁÇ∫ÂÆÉÂÄëÂ∞çÊñºÈÄ≤‰∏ÄÊ≠•ÊîπÂñÑ‰ΩøÁî®ËÄÖ‰ª£ÁêÜÂçî‰ΩúÂæàÊúâÂÉπÂÄº„ÄÇ

##### **Analyzing Context Utilization of LLMs in Document-Level Translation**
2410.14391v1 by Wafaa Mohammed, Vlad Niculae

Large language models (LLM) are increasingly strong contenders in machine
translation. We study document-level translation, where some words cannot be
translated without context from outside the sentence. We investigate the
ability of prominent LLMs to utilize context by analyzing models' robustness to
perturbed and randomized document context. We find that LLMs' improved
document-translation performance is not always reflected in pronoun translation
performance. We highlight the need for context-aware finetuning of LLMs with a
focus on relevant parts of the context to improve their reliability for
document-level translation.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ê©üÂô®ÁøªË≠Ø‰∏≠Ë∂ä‰æÜË∂äÂº∑Â§ß„ÄÇÊàëÂÄëÁ†îÁ©∂Êñá‰ª∂Á¥öÂà•ÁøªË≠ØÔºåÂÖ∂‰∏≠Êüê‰∫õË©ûÂΩôÁÑ°Ê≥ïÂú®Âè•Â≠êÂ§ñÈÉ®ÁöÑË™ûÂ¢É‰∏≠ÁøªË≠Ø„ÄÇÊàëÂÄëË™øÊü•‰∫ÜÂÇëÂá∫ÁöÑ LLM Âà©Áî®Ë™ûÂ¢ÉÁöÑËÉΩ‚Äã‚ÄãÂäõÔºåÊñπÊ≥ïÊòØÂàÜÊûêÊ®°ÂûãÂ∞çÊìæÂãïÂíåÈö®Ê©üÂåñÊñá‰ª∂Ë™ûÂ¢ÉÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁôºÁèæ LLM ÊîπÈÄ≤ÁöÑÊñá‰ª∂ÁøªË≠ØÊÄßËÉΩ‰∏¶ÈùûÁ∏ΩÊòØÂèçÊò†Âú®‰ª£Ë©ûÁøªË≠ØÊÄßËÉΩ‰∏≠„ÄÇÊàëÂÄëÂº∑Ë™øÈúÄË¶ÅÈáùÂ∞ç LLM ÈÄ≤Ë°åË™ûÂ¢ÉÊÑüÁü•ÂæÆË™øÔºåÈáçÈªûÈóúÊ≥®Ë™ûÂ¢ÉÁöÑÁõ∏ÈóúÈÉ®ÂàÜÔºå‰ª•ÊèêÈ´òÂÖ∂Âú®Êñá‰ª∂Á¥öÂà•ÁøªË≠Ø‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇ

##### **SurgeryV2: Bridging the Gap Between Model Merging and Multi-Task Learning with Deep Representation Surgery**
2410.14389v1 by Enneng Yang, Li Shen, Zhenyi Wang, Guibing Guo, Xingwei Wang, Xiaocun Cao, Jie Zhang, Dacheng Tao

Model merging-based multitask learning (MTL) offers a promising approach for
performing MTL by merging multiple expert models without requiring access to
raw training data. However, in this paper, we examine the merged model's
representation distribution and uncover a critical issue of "representation
bias". This bias arises from a significant distribution gap between the
representations of the merged and expert models, leading to the suboptimal
performance of the merged MTL model. To address this challenge, we first
propose a representation surgery solution called Surgery. Surgery is a
lightweight, task-specific module that aligns the final layer representations
of the merged model with those of the expert models, effectively alleviating
bias and improving the merged model's performance. Despite these improvements,
a performance gap remains compared to the traditional MTL method. Further
analysis reveals that representation bias phenomena exist at each layer of the
merged model, and aligning representations only in the last layer is
insufficient for fully reducing systemic bias because biases introduced at each
layer can accumulate and interact in complex ways. To tackle this, we then
propose a more comprehensive solution, deep representation surgery (also called
SurgeryV2), which mitigates representation bias across all layers, and thus
bridges the performance gap between model merging-based MTL and traditional
MTL. Finally, we design an unsupervised optimization objective to optimize both
the Surgery and SurgeryV2 modules. Our experimental results show that
incorporating these modules into state-of-the-art (SOTA) model merging schemes
leads to significant performance gains. Notably, our SurgeryV2 scheme reaches
almost the same level as individual expert models or the traditional MTL model.
The code is available at \url{https://github.com/EnnengYang/SurgeryV2}.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÊ®°ÂûãÂêà‰ΩµÁöÑÂ§ö‰ªªÂãôÂ≠∏Áøí (MTL) Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÔºåÂèØÈÄèÈÅéÂêà‰ΩµÂ§öÂÄãÂ∞àÂÆ∂Ê®°Âûã‰æÜÂü∑Ë°å MTLÔºåËÄåÁÑ°ÈúÄÂ≠òÂèñÂéüÂßãË®ìÁ∑¥Ë≥áÊñô„ÄÇÁÑ∂ËÄåÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ™¢Ë¶ñ‰∫ÜÂêà‰ΩµÊ®°ÂûãÁöÑË°®Á§∫ÂàÜ‰ΩàÔºå‰∏¶ÁôºÁèæ‰∫Ü‰∏ÄÂÄã„ÄåË°®Á§∫ÂÅèÂ∑Æ„ÄçÁöÑÈóúÈçµÂïèÈ°å„ÄÇÊ≠§ÂÅèÂ∑ÆÊ∫êËá™ÊñºÂêà‰ΩµÊ®°ÂûãËàáÂ∞àÂÆ∂Ê®°ÂûãÁöÑË°®Á§∫‰πãÈñìÁöÑÈ°ØËëóÂàÜ‰ΩàÂ∑ÆË∑ùÔºåÂ∞éËá¥Âêà‰Ωµ MTL Ê®°ÂûãÁöÑÊ¨°‰Ω≥ÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ®±ÁÇ∫ Surgery ÁöÑË°®Á§∫ÊâãË°ìËß£Ê±∫ÊñπÊ°à„ÄÇSurgery ÊòØ‰∏ÄÂÄãËºïÈáèÁ¥ö„ÄÅÁâπÂÆöÊñº‰ªªÂãôÁöÑÊ®°ÁµÑÔºåÂÆÉÊúÉÂ∞áÂêà‰ΩµÊ®°ÂûãÁöÑÊúÄÁµÇÂ±§Ë°®Á§∫ËàáÂ∞àÂÆ∂Ê®°ÂûãÁöÑË°®Á§∫Â∞çÈΩäÔºåÊúâÊïàÊ∏õËºïÂÅèÂ∑Æ‰∏¶ÊîπÂñÑÂêà‰ΩµÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÊîπÈÄ≤Ôºå‰ΩÜËàáÂÇ≥Áµ± MTL ÊñπÊ≥ïÁõ∏ÊØîÔºåÊïàËÉΩÂ∑ÆË∑ù‰ªçÁÑ∂Â≠òÂú®„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåË°®Á§∫ÂÅèÂ∑ÆÁèæË±°Â≠òÂú®ÊñºÂêà‰ΩµÊ®°ÂûãÁöÑÊØè‰∏ÄÂ±§ÔºåËÄåÂÉÖÂú®ÊúÄÂæå‰∏ÄÂ±§Â∞çÈΩäË°®Á§∫‰∏çË∂≥‰ª•ÂÆåÂÖ®Ê∏õÂ∞ëÁ≥ªÁµ±ÊÄßÂÅèÂ∑ÆÔºåÂõ†ÁÇ∫Âú®ÊØè‰∏ÄÂ±§ÂºïÂÖ•ÁöÑÂÅèÂ∑ÆÂèØËÉΩÊúÉ‰ª•Ë§áÈõúÁöÑÊñπÂºèÁ¥ØÁ©çÂíå‰∫§‰∫í„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊé•ËëóÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊõ¥ÂÖ®Èù¢ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÊ∑±Â∫¶Ë°®Á§∫ÊâãË°ìÔºà‰πüÁ®±ÁÇ∫ SurgeryV2ÔºâÔºåÂÆÉÂèØ‰ª•Ê∏õËºïÊâÄÊúâÂ±§ÁöÑË°®Á§∫ÂÅèÂ∑ÆÔºåÂæûËÄåÂΩåÂêàÂü∫ÊñºÊ®°ÂûãÂêà‰ΩµÁöÑ MTL ÂíåÂÇ≥Áµ± MTL ‰πãÈñìÁöÑÊïàËÉΩÂ∑ÆË∑ù„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÁÑ°Áõ£Áù£ÁöÑÊúÄ‰Ω≥ÂåñÁõÆÊ®ôÔºå‰ª•ÊúÄ‰Ω≥Âåñ Surgery Âíå SurgeryV2 Ê®°ÁµÑ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÂ∞áÈÄô‰∫õÊ®°ÁµÑÁ¥çÂÖ•ÊúÄÂÖàÈÄ≤ (SOTA) ÁöÑÊ®°ÂûãÂêà‰ΩµÊñπÊ°àÊúÉÂ∏∂‰æÜÈ°ØËëóÁöÑÊïàËÉΩÊèêÂçá„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁöÑ SurgeryV2 ÊñπÊ°àÈÅîÂà∞‰∫ÜËàáÂÄãÂà•Â∞àÂÆ∂Ê®°ÂûãÊàñÂÇ≥Áµ± MTL Ê®°ÂûãÂπæ‰πéÁõ∏ÂêåÁöÑÊ∞¥Ê∫ñ„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® \url{https://github.com/EnnengYang/SurgeryV2} ÂèñÂæó„ÄÇ</paragraph>

##### **How Do Multilingual Models Remember? Investigating Multilingual Factual Recall Mechanisms**
2410.14387v1 by Constanza Fierro, Negar Foroutan, Desmond Elliott, Anders S√∏gaard

Large Language Models (LLMs) store and retrieve vast amounts of factual
knowledge acquired during pre-training. Prior research has localized and
identified mechanisms behind knowledge recall; however, it has primarily
focused on English monolingual models. The question of how these processes
generalize to other languages and multilingual LLMs remains unexplored. In this
paper, we address this gap by conducting a comprehensive analysis of two highly
multilingual LLMs. We assess the extent to which previously identified
components and mechanisms of factual recall in English apply to a multilingual
context. Then, we examine when language plays a role in the recall process,
uncovering evidence of language-independent and language-dependent mechanisms.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúÉÂÑ≤Â≠ò‰∏¶Ê™¢Á¥¢Âú®È†êÂÖàË®ìÁ∑¥ÊúüÈñìÂèñÂæóÁöÑÂ§ßÈáè‰∫ãÂØ¶Áü•Ë≠ò„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤Â∞áÁü•Ë≠òÂõûÊÜ∂ËÉåÂæåÁöÑÊ©üÂà∂Êú¨Âú∞Âåñ‰∏¶Âä†‰ª•Ë≠òÂà•ÔºõÁÑ∂ËÄåÔºåÂÖ∂‰∏ªË¶ÅÈóúÊ≥®ÈªûÂú®ÊñºËã±ÊñáÂñÆË™ûÊ®°Âûã„ÄÇÈÄô‰∫õÁ®ãÂ∫èÂ¶Ç‰ΩïÊé®Âª£Âà∞ÂÖ∂‰ªñË™ûË®ÄÂíåÂ§öË™ûÁ®Æ LLM ÁöÑÂïèÈ°å‰ªçÊú™Êé¢Ë®é„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂ∞çÂÖ©ÂÄãÈ´òÂ∫¶Â§öË™ûÁ®ÆÁöÑ LLM ÈÄ≤Ë°åÂÖ®Èù¢ÂàÜÊûê‰æÜËß£Ê±∫Ê≠§Â∑ÆË∑ù„ÄÇÊàëÂÄëË©ï‰º∞ÂÖàÂâçË≠òÂà•ÁöÑËã±Êñá‰∫ãÂØ¶ÂõûÊÜ∂ÁµÑÊàêÈÉ®ÂàÜÂíåÊ©üÂà∂Âú®Â§öË™ûÁ®ÆÁí∞Â¢É‰∏≠ÈÅ©Áî®ÁöÑÁ®ãÂ∫¶„ÄÇÊé•ËëóÔºåÊàëÂÄëÊ™¢Ë¶ñË™ûË®ÄÂú®ÂõûÊÜ∂Á®ãÂ∫è‰∏≠ÊâÆÊºîÁöÑËßíËâ≤ÔºåÊè≠Èú≤Ë™ûË®ÄÁÑ°ÈóúÂíåË™ûË®ÄÁõ∏ÈóúÊ©üÂà∂ÁöÑË≠âÊìö„ÄÇ

##### **Fine-Tuning Pre-trained Language Models for Robust Causal Representation Learning**
2410.14375v1 by Jialin Yu, Yuxiang Zhou, Yulan He, Nevin L. Zhang, Ricardo Silva

The fine-tuning of pre-trained language models (PLMs) has been shown to be
effective across various domains. By using domain-specific supervised data, the
general-purpose representation derived from PLMs can be transformed into a
domain-specific representation. However, these methods often fail to generalize
to out-of-domain (OOD) data due to their reliance on non-causal
representations, often described as spurious features. Existing methods either
make use of adjustments with strong assumptions about lack of hidden common
causes, or mitigate the effect of spurious features using multi-domain data. In
this work, we investigate how fine-tuned pre-trained language models aid
generalizability from single-domain scenarios under mild assumptions, targeting
more general and practical real-world scenarios. We show that a robust
representation can be derived through a so-called causal front-door adjustment,
based on a decomposition assumption, using fine-tuned representations as a
source of data augmentation. Comprehensive experiments in both synthetic and
real-world settings demonstrate the superior generalizability of the proposed
method compared to existing approaches. Our work thus sheds light on the domain
generalization problem by introducing links between fine-tuning and causal
mechanisms into representation learning.

ÊëòË¶ÅÔºöÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM) ÁöÑÂæÆË™øÂ∑≤Ë¢´Ë≠âÊòéÂú®ÂêÑÁ®ÆÈ†òÂüü‰∏≠ÊúâÊïà„ÄÇÈÄèÈÅé‰ΩøÁî®ÁâπÂÆöÊñºÈ†òÂüüÁöÑÁõ£Áù£Ë≥áÊñôÔºåÂæû PLM Ë°çÁîüÁöÑÈÄöÁî®Ë°®Á§∫ÂèØ‰ª•ËΩâÊèõÁÇ∫ÁâπÂÆöÊñºÈ†òÂüüÁöÑË°®Á§∫„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÁÑ°Ê≥ïÊ¶ÇÊã¨ÁÇ∫ÈùûÈ†òÂüü (OOD) Ë≥áÊñôÔºåÂõ†ÁÇ∫ÂÆÉÂÄë‰æùË≥¥ÊñºÈùûÂõ†ÊûúË°®Á§∫ÔºåÈÄöÂ∏∏Ë¢´ÊèèËø∞ÁÇ∫ËôõÂÅáÁâπÂæµ„ÄÇÁèæÊúâÊñπÊ≥ïÊúÉÂà©Áî®Â∞çÈö±ËóèÂÖ±ÂêåÂéüÂõ†Áº∫‰πèÁöÑÂº∑ÂÅáË®≠ÈÄ≤Ë°åË™øÊï¥ÔºåÊàñ‰ΩøÁî®Â§öÈ†òÂüüË≥áÊñô‰æÜÊ∏õËºïËôõÂÅáÁâπÂæµÁöÑÂΩ±Èüø„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂæÆË™øÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÂ¶Ç‰ΩïÂπ´Âä©Âú®Ê∫´ÂíåÂÅáË®≠‰∏ãÂæûÂñÆ‰∏ÄÈ†òÂüüÂ†¥ÊôØÈÄ≤Ë°åÊ¶ÇÊã¨ÔºåÈáùÂ∞çÊõ¥‰∏ÄËà¨‰∏îÂØ¶Áî®ÁöÑÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂèØ‰ª•ÈÄèÈÅéÊâÄË¨ÇÁöÑÂõ†ÊûúÂâçÈñÄË™øÊï¥‰æÜË°çÁîüÁ©©ÂÅ•ÁöÑË°®Á§∫ÔºåÈÄôÂü∫ÊñºÂàÜËß£ÂÅáË®≠Ôºå‰ΩøÁî®ÂæÆË™øË°®Á§∫‰ΩúÁÇ∫Ë≥áÊñôÊì¥ÂÖÖÁöÑ‰æÜÊ∫ê„ÄÇÂú®ÂêàÊàêÂíåÁúüÂØ¶‰∏ñÁïåË®≠ÂÆö‰∏≠ÁöÑÂÖ®Èù¢ÂØ¶È©óË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÂÖ∑ÊúâÂÑ™Ë∂äÁöÑÊ¶ÇÊã¨ËÉΩÂäõ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄèÈÅéÂú®Ë°®Á§∫Â≠∏Áøí‰∏≠ÂºïÂÖ•ÂæÆË™øÂíåÂõ†ÊûúÊ©üÂà∂‰πãÈñìÁöÑÈÄ£ÁµêÔºå‰æÜÈó°ÊòéÈ†òÂüüÊ¶ÇÊã¨ÂïèÈ°å„ÄÇ

##### **CoMAL: Collaborative Multi-Agent Large Language Models for Mixed-Autonomy Traffic**
2410.14368v1 by Huaiyuan Yao, Longchao Da, Vishnu Nandam, Justin Turnau, Zhiwei Liu, Linsey Pang, Hua Wei

The integration of autonomous vehicles into urban traffic has great potential
to improve efficiency by reducing congestion and optimizing traffic flow
systematically. In this paper, we introduce CoMAL (Collaborative Multi-Agent
LLMs), a framework designed to address the mixed-autonomy traffic problem by
collaboration among autonomous vehicles to optimize traffic flow. CoMAL is
built upon large language models, operating in an interactive traffic
simulation environment. It utilizes a Perception Module to observe surrounding
agents and a Memory Module to store strategies for each agent. The overall
workflow includes a Collaboration Module that encourages autonomous vehicles to
discuss the effective strategy and allocate roles, a reasoning engine to
determine optimal behaviors based on assigned roles, and an Execution Module
that controls vehicle actions using a hybrid approach combining rule-based
models. Experimental results demonstrate that CoMAL achieves superior
performance on the Flow benchmark. Additionally, we evaluate the impact of
different language models and compare our framework with reinforcement learning
approaches. It highlights the strong cooperative capability of LLM agents and
presents a promising solution to the mixed-autonomy traffic challenge. The code
is available at https://github.com/Hyan-Yao/CoMAL.

ÊëòË¶ÅÔºöËá™ÂãïÈßïÈßõËªäËºõÊï¥ÂêàÂà∞ÈÉΩÂ∏Ç‰∫§ÈÄö‰∏≠ÔºåÊúâÂæàÂ§ßÁöÑÊΩõÂäõÂèØ‰ª•ÈÄèÈÅéÊ∏õÂ∞ëÊìÅÂ†µÂíåÁ≥ªÁµ±ÊÄßÂú∞ÊúÄ‰Ω≥Âåñ‰∫§ÈÄöÊµÅÈáè‰æÜÊèêÂçáÊïàÁéá„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π CoMALÔºàÂçî‰ΩúÂ§öÈáç‰ª£ÁêÜ LLMÔºâÔºå‰∏ÄÂÄãÊó®Âú®ÈÄèÈÅéËá™ÂãïÈßïÈßõËªäËºõ‰πãÈñìÁöÑÂçî‰Ωú‰æÜÊúÄ‰Ω≥Âåñ‰∫§ÈÄöÊµÅÈáèÔºå‰ª•Ëß£Ê±∫Ê∑∑ÂêàËá™ÂãïÂåñ‰∫§ÈÄöÂïèÈ°åÁöÑÊû∂Êßã„ÄÇCoMAL Âª∫Á´ãÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã‰πã‰∏äÔºåÂú®‰∫íÂãïÂºè‰∫§ÈÄöÊ®°Êì¨Áí∞Â¢É‰∏≠ÈÅã‰Ωú„ÄÇÂÆÉÂà©Áî®ÊÑüÁü•Ê®°ÁµÑ‰æÜËßÄÂØüÂë®ÂúçÁöÑ‰ª£ÁêÜÔºå‰∏¶Âà©Áî®Ë®òÊÜ∂Ê®°ÁµÑ‰æÜÂÑ≤Â≠òÊØè‰Ωç‰ª£ÁêÜÁöÑÁ≠ñÁï•„ÄÇÊï¥È´îÂ∑•‰ΩúÊµÅÁ®ãÂåÖÂê´‰∏ÄÂÄãÂçî‰ΩúÊ®°ÁµÑÔºåÈºìÂãµËá™ÂãïÈßïÈßõËªäËºõË®éË´ñÊúâÊïàÁöÑÁ≠ñÁï•‰∏¶ÂàÜÈÖçËßíËâ≤Ôºõ‰∏ÄÂÄãÊé®ÁêÜÂºïÊìéÔºåÊ†πÊìöÂàÜÈÖçÁöÑËßíËâ≤‰æÜÊ±∫ÂÆöÊúÄ‰Ω≥Ë°åÁÇ∫Ôºõ‰ª•Âèä‰∏ÄÂÄãÂü∑Ë°åÊ®°ÁµÑÔºå‰ΩøÁî®ÁµêÂêàË¶èÂâáÂºèÊ®°ÂûãÁöÑÊ∑∑ÂêàÊñπÊ≥ï‰æÜÊéßÂà∂ËªäËºõÂãï‰Ωú„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåCoMAL Âú® Flow Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÂèñÂæóÂÑ™Áï∞ÁöÑË°®Áèæ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË©ï‰º∞‰∏çÂêåË™ûË®ÄÊ®°ÂûãÁöÑÂΩ±ÈüøÔºå‰∏¶Â∞áÊàëÂÄëÁöÑÊû∂ÊßãËàáÂº∑ÂåñÂ≠∏ÁøíÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉ„ÄÇÂÆÉÁ™ÅÈ°Ø‰∫Ü LLM ‰ª£ÁêÜÂº∑Â§ßÁöÑÂêà‰ΩúËÉΩÂäõÔºå‰∏¶ÁÇ∫Ê∑∑ÂêàËá™ÂãïÂåñ‰∫§ÈÄöÊåëÊà∞Êèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Hyan-Yao/CoMAL ÂèñÂæó„ÄÇ

##### **Efficiently Computing Susceptibility to Context in Language Models**
2410.14361v1 by Tianyu Liu, Kevin Du, Mrinmaya Sachan, Ryan Cotterell

One strength of modern language models is their ability to incorporate
information from a user-input context when answering queries. However, they are
not equally sensitive to the subtle changes to that context. To quantify this,
Du et al. (2024) gives an information-theoretic metric to measure such
sensitivity. Their metric, susceptibility, is defined as the degree to which
contexts can influence a model's response to a query at a distributional level.
However, exactly computing susceptibility is difficult and, thus, Du et al.
(2024) falls back on a Monte Carlo approximation. Due to the large number of
samples required, the Monte Carlo approximation is inefficient in practice. As
a faster alternative, we propose Fisher susceptibility, an efficient method to
estimate the susceptibility based on Fisher information. Empirically, we
validate that Fisher susceptibility is comparable to Monte Carlo estimated
susceptibility across a diverse set of query domains despite its being
$70\times$ faster. Exploiting the improved efficiency, we apply Fisher
susceptibility to analyze factors affecting the susceptibility of language
models. We observe that larger models are as susceptible as smaller ones.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°ÂûãÁöÑ‰∏ÄÈ†ÖÂÑ™Âã¢ÊòØÔºåÂÆÉÂÄëÂú®ÂõûÁ≠îÊü•Ë©¢ÊôÇÔºåËÉΩÂ§†Á¥çÂÖ•‰ΩøÁî®ËÄÖËº∏ÂÖ•ËÑàÁµ°‰∏≠ÁöÑË≥áË®ä„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂ∞çÊñºËÑàÁµ°‰∏≠ÁöÑÁ¥∞ÂæÆËÆäÂåñ‰∏¶ÈùûÂêåÊ®£ÊïèÊÑü„ÄÇÁÇ∫‰∫ÜÈáèÂåñÈÄô‰∏ÄÈªûÔºåDu et al. (2024) Áµ¶Âá∫‰∫Ü‰∏ÄÁ®ÆË≥áË®äÁêÜË´ñÈáèÂ∫¶‰æÜÊ∏¨ÈáèÈÄôÁ®ÆÊïèÊÑüÂ∫¶„ÄÇ‰ªñÂÄëÁöÑÈáèÂ∫¶ÔºåÂç≥ÊïèÊÑüÂ∫¶ÔºåÂÆöÁæ©ÁÇ∫ËÑàÁµ°Âú®ÂàÜÈÖçÂ±§Á¥ö‰∏äÂΩ±ÈüøÊ®°ÂûãÂ∞çÊü•Ë©¢ÂõûÊáâÁöÑÁ®ãÂ∫¶„ÄÇÁÑ∂ËÄåÔºåÁ≤æÁ¢∫Ë®àÁÆóÊïèÊÑüÂ∫¶ÂæàÂõ∞Èõ£ÔºåÂõ†Ê≠§ Du et al. (2024) ÈÄÄËÄåÊ±ÇÂÖ∂Ê¨°ÔºåÊé°Áî®ËíôÂú∞Âç°ÁæÖËøë‰ººÊ≥ï„ÄÇÁî±ÊñºÈúÄË¶ÅÂ§ßÈáèÁöÑÊ®£Êú¨ÔºåËíôÂú∞Âç°ÁæÖËøë‰ººÊ≥ïÂú®ÂØ¶Âãô‰∏äÊïàÁéá‰∏çÂΩ∞„ÄÇ‰ΩúÁÇ∫‰∏ÄÂÄãËºÉÂø´ÁöÑÊõø‰ª£ÊñπÊ°àÔºåÊàëÂÄëÊèêÂá∫ Fisher ÊïèÊÑüÂ∫¶Ôºå‰∏ÄÁ®ÆÂü∫Êñº Fisher Ë≥áË®ä‰æÜ‰º∞Ë®àÊïèÊÑüÂ∫¶ÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇÊ†πÊìöÁ∂ìÈ©óÔºåÊàëÂÄëÈ©óË≠â‰∫Ü Fisher ÊïèÊÑüÂ∫¶ËàáËíôÂú∞Âç°ÁæÖ‰º∞Ë®àÁöÑÊïèÊÑüÂ∫¶Áõ∏Áï∂ÔºåÂÑòÁÆ°ÂÆÉÂø´‰∫Ü $70\times$Ôºå‰ΩÜÈÅ©Áî®ÊñºÂêÑÁ®Æ‰∏çÂêåÁöÑÊü•Ë©¢È†òÂüü„ÄÇÂà©Áî®ÈÄôÁ®ÆÊèêÂçáÁöÑÊïàÁéáÔºåÊàëÂÄëÊáâÁî® Fisher ÊïèÊÑüÂ∫¶‰æÜÂàÜÊûêÂΩ±ÈüøË™ûË®ÄÊ®°ÂûãÊïèÊÑüÂ∫¶ÁöÑÂõ†Á¥†„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåËºÉÂ§ßÁöÑÊ®°ÂûãËàáËºÉÂ∞èÁöÑÊ®°Âûã‰∏ÄÊ®£ÊïèÊÑü„ÄÇ

##### **A Scientific Machine Learning Approach for Predicting and Forecasting Battery Degradation in Electric Vehicles**
2410.14347v1 by Sharv Murgai, Hrishikesh Bhagwat, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat

Carbon emissions are rising at an alarming rate, posing a significant threat
to global efforts to mitigate climate change. Electric vehicles have emerged as
a promising solution, but their reliance on lithium-ion batteries introduces
the critical challenge of battery degradation. Accurate prediction and
forecasting of battery degradation over both short and long time spans are
essential for optimizing performance, extending battery life, and ensuring
effective long-term energy management. This directly influences the
reliability, safety, and sustainability of EVs, supporting their widespread
adoption and aligning with key UN SDGs. In this paper, we present a novel
approach to the prediction and long-term forecasting of battery degradation
using Scientific Machine Learning framework which integrates domain knowledge
with neural networks, offering more interpretable and scientifically grounded
solutions for both predicting short-term battery health and forecasting
degradation over extended periods. This hybrid approach captures both known and
unknown degradation dynamics, improving predictive accuracy while reducing data
requirements. We incorporate ground-truth data to inform our models, ensuring
that both the predictions and forecasts reflect practical conditions. The model
achieved MSE of 9.90 with the UDE and 11.55 with the NeuralODE, in experimental
data, a loss of 1.6986 with the UDE, and a MSE of 2.49 in the NeuralODE,
demonstrating the enhanced precision of our approach. This integration of
data-driven insights with SciML's strengths in interpretability and scalability
allows for robust battery management. By enhancing battery longevity and
minimizing waste, our approach contributes to the sustainability of energy
systems and accelerates the global transition toward cleaner, more responsible
energy solutions, aligning with the UN's SDG agenda.

ÊëòË¶ÅÔºöÁ¢≥ÊéíÊîæÈáèÊ≠£‰ª•È©ö‰∫∫ÁöÑÈÄüÂ∫¶‰∏äÂçáÔºåÂ∞çÂÖ®ÁêÉÊ∏õÁ∑©Ê∞£ÂÄôËÆäÈÅ∑ÁöÑÂä™ÂäõÊßãÊàêÈáçÂ§ßÂ®ÅËÑÖ„ÄÇÈõªÂãïËªäÂ∑≤ÊàêÁÇ∫‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ΩÜÂÆÉÂÄë‰æùË≥¥Èã∞Èõ¢Â≠êÈõªÊ±†ÔºåÂºïÂÖ•‰∫ÜÈõªÊ±†Âä£ÂåñÈÄôÂÄãÂö¥Â≥ªÁöÑÊåëÊà∞„ÄÇÊ∫ñÁ¢∫È†êÊ∏¨ÂíåÈ†êÊ∏¨ÈõªÊ±†Âú®Áü≠ÊúüÂíåÈï∑ÊúüÂÖßÁöÑÂä£ÂåñÂ∞çÊñºÊúÄ‰Ω≥ÂåñÊïàËÉΩ„ÄÅÂª∂Èï∑ÈõªÊ±†Â£ΩÂëΩ‰ª•ÂèäÁ¢∫‰øùÊúâÊïàÁöÑÈï∑ÊúüËÉΩÊ∫êÁÆ°ÁêÜËá≥ÈóúÈáçË¶Å„ÄÇÈÄôÁõ¥Êé•ÂΩ±ÈüøÈõªÂãïËªäÁöÑÂèØÈù†ÊÄß„ÄÅÂÆâÂÖ®ÊÄßËàáÊ∞∏Á∫åÊÄßÔºåÊîØÊåÅÂÆÉÂÄëÁöÑÂª£Ê≥õÊé°Áî®Ôºå‰∏¶ËàáËÅØÂêàÂúãÊ∞∏Á∫åÁôºÂ±ïÁõÆÊ®ô‰øùÊåÅ‰∏ÄËá¥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºå‰ΩøÁî®ÁßëÂ≠∏Ê©üÂô®Â≠∏ÁøíÊ°ÜÊû∂‰æÜÈ†êÊ∏¨ÂíåÈï∑ÊúüÈ†êÊ∏¨ÈõªÊ±†Âä£ÂåñÔºåË©≤Ê°ÜÊû∂Â∞áÈ†òÂüüÁü•Ë≠òËàáÁ•ûÁ∂ìÁ∂≤Ë∑ØÊï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÁÇ∫È†êÊ∏¨Áü≠ÊúüÈõªÊ±†ÂÅ•Â∫∑ÁãÄÊ≥ÅÂíåÈ†êÊ∏¨Èï∑ÊúüÂä£ÂåñÊèê‰æõÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÂíåÁßëÂ≠∏‰æùÊìöÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÈÄôÁ®ÆÊ∑∑ÂêàÊñπÊ≥ïÊçïÊçâÂ∑≤Áü•ÂíåÊú™Áü•ÁöÑÂä£ÂåñÂãïÊÖãÔºåÂú®Ê∏õÂ∞ëË≥áÊñôÈúÄÊ±ÇÁöÑÂêåÊôÇÊèêÈ´òÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁ¥çÂÖ•ÁúüÂØ¶Ë≥áÊñô‰æÜÂëäÁü•ÊàëÂÄëÁöÑÊ®°ÂûãÔºåÁ¢∫‰øùÈ†êÊ∏¨ÂíåÈ†êÊ∏¨ÈÉΩÂèçÊò†ÂØ¶ÈöõÊÉÖÊ≥Å„ÄÇË©≤Ê®°ÂûãÂú®ÂØ¶È©óË≥áÊñô‰∏≠‰ΩøÁî® UDE ÈÅîÂà∞ 9.90 ÁöÑ MSEÔºå‰ΩøÁî® NeuralODE ÈÅîÂà∞ 11.55Ôºå‰ΩøÁî® UDE ÊêçÂ§± 1.6986Ôºå‰ΩøÁî® NeuralODE ÈÅîÂà∞ 2.49 ÁöÑ MSEÔºåË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÁ≤æÁ¢∫Â∫¶ÊúâÊâÄÊèêÂçá„ÄÇÂ∞áË≥áÊñôÈ©ÖÂãïÁöÑÊ¥ûÂØüËàá SciML Âú®ÂèØËß£ÈáãÊÄßÂíåÂèØÊì¥ÂÖÖÊÄßÊñπÈù¢ÁöÑÂÑ™Âã¢Áõ∏ÁµêÂêàÔºåÂèØ‰ª•ÂØ¶ÁèæÂº∑Â§ßÁöÑÈõªÊ±†ÁÆ°ÁêÜ„ÄÇÈÄèÈÅéÊèêÂçáÈõªÊ±†Â£ΩÂëΩÂíåÊ∏õÂ∞ëÊµ™Ë≤ªÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÂä©ÊñºËÉΩÊ∫êÁ≥ªÁµ±Ê∞∏Á∫åÁôºÂ±ïÔºå‰∏¶Âä†ÈÄüÂÖ®ÁêÉÊúùÂêëÊõ¥Ê∏ÖÊΩî„ÄÅÊõ¥Ë≤†Ë≤¨‰ªªÁöÑËÉΩÊ∫êËß£Ê±∫ÊñπÊ°àÈÅéÊ∏°ÔºåËàáËÅØÂêàÂúãÊ∞∏Á∫åÁôºÂ±ïÁõÆÊ®ôË≠∞Á®ã‰øùÊåÅ‰∏ÄËá¥„ÄÇ

##### **Critical Questions Generation: Motivation and Challenges**
2410.14335v1 by Blanca Calvo Figueras, Rodrigo Agerri

The development of Large Language Models (LLMs) has brought impressive
performances on mitigation strategies against misinformation, such as
counterargument generation. However, LLMs are still seriously hindered by
outdated knowledge and by their tendency to generate hallucinated content. In
order to circumvent these issues, we propose a new task, namely, Critical
Questions Generation, consisting of processing an argumentative text to
generate the critical questions (CQs) raised by it. In argumentation theory CQs
are tools designed to lay bare the blind spots of an argument by pointing at
the information it could be missing. Thus, instead of trying to deploy LLMs to
produce knowledgeable and relevant counterarguments, we use them to question
arguments, without requiring any external knowledge. Research on CQs Generation
using LLMs requires a reference dataset for large scale experimentation. Thus,
in this work we investigate two complementary methods to create such a
resource: (i) instantiating CQs templates as defined by Walton's argumentation
theory and (ii), using LLMs as CQs generators. By doing so, we contribute with
a procedure to establish what is a valid CQ and conclude that, while LLMs are
reasonable CQ generators, they still have a wide margin for improvement in this
task.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁôºÂ±ïÂú®Â∞çÊäóÈåØË™§Ë®äÊÅØÁöÑÁ∑©Ëß£Á≠ñÁï•‰∏äÂ∏∂‰æÜ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑË°®ÁèæÔºå‰æãÂ¶ÇÂèçË´ñÁîüÊàê„ÄÇÁÑ∂ËÄåÔºåLLM ‰ªçÂèóÂà∞ÈÅéÊôÇÁü•Ë≠òÂíåÁîüÊàêÂπªË¶∫ÂÖßÂÆπÁöÑÂÇæÂêëÂö¥ÈáçÈòªÁ§ô„ÄÇÁÇ∫‰∫ÜËø¥ÈÅøÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞‰ªªÂãôÔºåÂç≥ÈóúÈçµÂïèÈ°åÁîüÊàêÔºåÂåÖÊã¨ËôïÁêÜË´ñË≠âÊñáÂ≠ó‰ª•Áî¢ÁîüÂÆÉÊèêÂá∫ÁöÑÈóúÈçµÂïèÈ°å (CQ)„ÄÇÂú®Ë´ñË≠âÁêÜË´ñ‰∏≠ÔºåCQ ÊòØÊó®Âú®ÈÄèÈÅéÊåáÂá∫Ë´ñË≠âÂèØËÉΩÈÅ∫ÊºèÁöÑË≥áË®ä‰æÜÊè≠Èú≤Ë´ñË≠âÁõ≤ÈªûÁöÑÂ∑•ÂÖ∑„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄë‰∏çË©¶ÂúñÈÉ®ÁΩ≤ LLM ‰æÜÁî¢ÁîüÁü•Ë≠òÊ∑µÂçö‰∏îÁõ∏ÈóúÁöÑÂèçË´ñÔºåËÄåÊòØ‰ΩøÁî®ÂÆÉÂÄë‰æÜË≥™ÁñëË´ñË≠âÔºåËÄå‰∏çÈúÄË¶Å‰ªª‰ΩïÂ§ñÈÉ®Áü•Ë≠ò„ÄÇ‰ΩøÁî® LLM ÈÄ≤Ë°å CQ ÁîüÊàêÁöÑÁ†îÁ©∂ÈúÄË¶Å‰∏ÄÂÄãÂèÉËÄÉË≥áÊñôÈõÜÈÄ≤Ë°åÂ§ßË¶èÊ®°ÂØ¶È©ó„ÄÇÂõ†Ê≠§ÔºåÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂÖ©Á®Æ‰∫íË£úÁöÑÊñπÊ≥ï‰æÜÂª∫Á´ãÈÄôÊ®£ÁöÑË≥áÊ∫êÔºö(i) Â∞á CQ Ê®°ÊùøÂØ¶‰æãÂåñÁÇ∫ Walton ÁöÑË´ñË≠âÁêÜË´ñÊâÄÂÆöÁæ©ÁöÑÊ®°ÊùøÔºå‰ª•Âèä (ii) ‰ΩøÁî® LLM ‰ΩúÁÇ∫ CQ ÁîüÊàêÂô®„ÄÇÈÄèÈÅéÈÄôÊ®£ÂÅöÔºåÊàëÂÄëÁÇ∫Âª∫Á´ã‰ªÄÈ∫ºÊòØÊúâÊïà CQ ÁöÑÁ®ãÂ∫èÂÅöÂá∫Ë≤¢ÁçªÔºå‰∏¶ÂæóÂá∫ÁµêË´ñÔºåÈõñÁÑ∂ LLM ÊòØÂêàÁêÜÁöÑ CQ ÁîüÊàêÂô®Ôºå‰ΩÜÂÆÉÂÄëÂú®ÈÄôÂÄã‰ªªÂãô‰∏≠‰ªçÊúâÂæàÂ§ßÁöÑÊîπÈÄ≤Á©∫Èñì„ÄÇ

##### **LoGU: Long-form Generation with Uncertainty Expressions**
2410.14309v1 by Ruihan Yang, Caiqi Zhang, Zhisong Zhang, Xinting Huang, Sen Yang, Nigel Collier, Dong Yu, Deqing Yang

While Large Language Models (LLMs) demonstrate impressive capabilities, they
still struggle with generating factually incorrect content (i.e.,
hallucinations). A promising approach to mitigate this issue is enabling models
to express uncertainty when unsure. Previous research on uncertainty modeling
has primarily focused on short-form QA, but realworld applications often
require much longer responses. In this work, we introduce the task of Long-form
Generation with Uncertainty(LoGU). We identify two key challenges: Uncertainty
Suppression, where models hesitate to express uncertainty, and Uncertainty
Misalignment, where models convey uncertainty inaccurately. To tackle these
challenges, we propose a refinement-based data collection framework and a
two-stage training pipeline. Our framework adopts a divide-and-conquer
strategy, refining uncertainty based on atomic claims. The collected data are
then used in training through supervised fine-tuning (SFT) and direct
preference optimization (DPO) to enhance uncertainty expression. Extensive
experiments on three long-form instruction following datasets show that our
method significantly improves accuracy, reduces hallucinations, and maintains
the comprehensiveness of responses.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºåÂÆÉÂÄëÂú®Áî¢Áîü‰∫ãÂØ¶‰∏çÊ≠£Á¢∫ÁöÑÂÖßÂÆπÔºàÂç≥ÂπªË¶∫ÔºâÊñπÈù¢‰ªçÊúâÂõ∞Èõ£„ÄÇÊ∏õËºïÊ≠§ÂïèÈ°åÁöÑ‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÊòØËÆìÊ®°ÂûãÂú®‰∏çÁ¢∫ÂÆöÊôÇË°®ÈÅî‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÂÖàÂâçÈóúÊñº‰∏çÁ¢∫ÂÆöÊÄßÂª∫Ê®°ÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÁ∞°Áü≠ÂïèÁ≠îÔºå‰ΩÜÁèæÂØ¶‰∏ñÁïåÁöÑÊáâÁî®ÈÄöÂ∏∏ÈúÄË¶ÅÊõ¥Èï∑ÁöÑÂõûÊáâ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏çÁ¢∫ÂÆöÊÄßÈï∑ÁØáÁîüÊàê (LoGU) ÁöÑ‰ªªÂãô„ÄÇÊàëÂÄëÊâæÂá∫ÂÖ©ÂÄãÈóúÈçµÊåëÊà∞Ôºö‰∏çÁ¢∫ÂÆöÊÄßÊäëÂà∂ÔºåÊ®°ÂûãÁå∂Ë±´Ë°®ÈÅî‰∏çÁ¢∫ÂÆöÊÄßÔºå‰ª•Âèä‰∏çÁ¢∫ÂÆöÊÄßÈåØ‰ΩçÔºåÊ®°Âûã‰∏çÊ∫ñÁ¢∫Âú∞ÂÇ≥ÈÅî‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÁ¥∞ÂåñÁöÑË≥áÊñôÊî∂ÈõÜÊû∂ÊßãÂíå‰∏ÄÂÄãÂÖ©ÈöéÊÆµË®ìÁ∑¥ÁÆ°ÈÅì„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÊé°Áî®ÂàÜËÄåÊ≤ª‰πãÁöÑÁ≠ñÁï•ÔºåÊ†πÊìöÂéüÂ≠êÈô≥Ëø∞Á¥∞Âåñ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÁÑ∂ÂæåÂ∞áÊî∂ÈõÜÂà∞ÁöÑË≥áÊñôÁî®ÊñºÈÄèÈÅéÁõ£Áù£ÂæÆË™ø (SFT) ÂíåÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO) ÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰ª•Â¢ûÂº∑‰∏çÁ¢∫ÂÆöÊÄßË°®ÈÅî„ÄÇÂú®‰∏âÂÄãÈï∑ÁØáÊåá‰ª§ÈÅµÂæ™Ë≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈ°ØËëóÊèêÈ´ò‰∫ÜÊ∫ñÁ¢∫ÊÄßÔºåÊ∏õÂ∞ë‰∫ÜÂπªË¶∫Ôºå‰∏¶Á∂≠ÊåÅ‰∫ÜÂõûÊáâÁöÑÂÖ®Èù¢ÊÄß„ÄÇ

##### **SwaQuAD-24: QA Benchmark Dataset in Swahili**
2410.14289v1 by Alfred Malengo Kondoro

This paper proposes the creation of a Swahili Question Answering (QA)
benchmark dataset, aimed at addressing the underrepresentation of Swahili in
natural language processing (NLP). Drawing from established benchmarks like
SQuAD, GLUE, KenSwQuAD, and KLUE, the dataset will focus on providing
high-quality, annotated question-answer pairs that capture the linguistic
diversity and complexity of Swahili. The dataset is designed to support a
variety of applications, including machine translation, information retrieval,
and social services like healthcare chatbots. Ethical considerations, such as
data privacy, bias mitigation, and inclusivity, are central to the dataset
development. Additionally, the paper outlines future expansion plans to include
domain-specific content, multimodal integration, and broader crowdsourcing
efforts. The Swahili QA dataset aims to foster technological innovation in East
Africa and provide an essential resource for NLP research and applications in
low-resource languages.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêË≠∞Âª∫Á´ãÂè≤Áì¶Â∏åÈáåË™ûÂïèÁ≠î (QA) Âü∫Ê∫ñË≥áÊñôÈõÜÔºåÊó®Âú®Ëß£Ê±∫Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠Âè≤Áì¶Â∏åÈáåË™ûÁöÑ‰ª£Ë°®ÊÄß‰∏çË∂≥ÂïèÈ°å„ÄÇÂæû SQuAD„ÄÅGLUE„ÄÅKenSwQuAD Âíå KLUE Á≠âÊó¢ÊúâÂü∫Ê∫ñ‰∏≠Ê±≤ÂèñÈùàÊÑüÔºåË©≤Ë≥áÊñôÈõÜÂ∞áÂ∞àÊ≥®ÊñºÊèê‰æõÈ´òÂìÅË≥™„ÄÅË®ªËß£ÁöÑÂïèÁ≠îÂ∞çÔºå‰ª•ÊçïÊçâÂè≤Áì¶Â∏åÈáåË™ûÁöÑË™ûË®ÄÂ§öÊ®£ÊÄßÂíåË§áÈõúÊÄß„ÄÇË©≤Ë≥áÊñôÈõÜÊó®Âú®ÊîØÊè¥ÂêÑÁ®ÆÊáâÁî®ÔºåÂåÖÊã¨Ê©üÂô®ÁøªË≠Ø„ÄÅË≥áË®äÊ™¢Á¥¢ÂíåÈÜ´ÁôÇËÅäÂ§©Ê©üÂô®‰∫∫Á≠âÁ§æÊúÉÊúçÂãô„ÄÇË≥áÊñôÈõÜÈñãÁôºÁöÑÈáçÈªûÊòØÈÅìÂæ∑ËÄÉÈáèÔºå‰æãÂ¶ÇË≥áÊñôÈö±ÁßÅ„ÄÅÊ∏õËºïÂÅèÂ∑ÆÂíåÂåÖÂÆπÊÄß„ÄÇÊ≠§Â§ñÔºåÊú¨ÊñáÊ¶ÇËø∞‰∫ÜÊú™‰æÜÊì¥ÂÖÖË®àÁï´ÔºåÂåÖÊã¨Á¥çÂÖ•ÁâπÂÆöÈ†òÂüüÁöÑÂÖßÂÆπ„ÄÅÂ§öÊ®°ÊÖãÊï¥ÂêàÂíåÊõ¥Âª£Ê≥õÁöÑÁæ§ÁúæÂ§ñÂåÖÂ∑•‰Ωú„ÄÇÂè≤Áì¶Â∏åÈáåË™ûÂïèÁ≠îË≥áÊñôÈõÜÊó®Âú®‰øÉÈÄ≤Êù±ÈùûÁöÑÊäÄË°ìÂâµÊñ∞Ôºå‰∏¶ÁÇ∫‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑ NLP Á†îÁ©∂ÂíåÊáâÁî®Êèê‰æõÈáçË¶ÅÁöÑË≥áÊ∫ê„ÄÇ

##### **EcomEdit: An Automated E-commerce Knowledge Editing Framework for Enhanced Product and Purchase Intention Understanding**
2410.14276v1 by Ching Ming Samuel Lau, Weiqi Wang, Haochen Shi, Baixuan Xu, Jiaxin Bai, Yangqiu Song

Knowledge Editing (KE) aims to correct and update factual information in
Large Language Models (LLMs) to ensure accuracy and relevance without
computationally expensive fine-tuning. Though it has been proven effective in
several domains, limited work has focused on its application within the
e-commerce sector. However, there are naturally occurring scenarios that make
KE necessary in this domain, such as the timely updating of product features
and trending purchase intentions by customers, which necessitate further
exploration. In this paper, we pioneer the application of KE in the e-commerce
domain by presenting ECOMEDIT, an automated e-commerce knowledge editing
framework tailored for e-commerce-related knowledge and tasks. Our framework
leverages more powerful LLMs as judges to enable automatic knowledge conflict
detection and incorporates conceptualization to enhance the semantic coverage
of the knowledge to be edited. Through extensive experiments, we demonstrate
the effectiveness of ECOMEDIT in improving LLMs' understanding of product
descriptions and purchase intentions. We also show that LLMs, after our
editing, can achieve stronger performance on downstream e-commerce tasks.

ÊëòË¶ÅÔºöÁü•Ë≠òÁ∑®ËºØ (KE) Êó®Âú®‰øÆÊ≠£ÂíåÊõ¥Êñ∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑ‰∫ãÂØ¶Ë≥áË®äÔºå‰ª•Á¢∫‰øùÊ∫ñÁ¢∫ÊÄßÂíåÁõ∏ÈóúÊÄßÔºåÂêåÊôÇÈÅøÂÖçË®àÁÆóÊàêÊú¨È´òÊòÇÁöÑÂæÆË™ø„ÄÇÂÑòÁÆ°Â∑≤Ë≠âÊòéÂÆÉÂú®Â§öÂÄãÈ†òÂüü‰∏≠ÊúâÊïàÔºå‰ΩÜÂ∞àÊ≥®ÊñºÂÖ∂Âú®ÈõªÂ≠êÂïÜÂãôÈ†òÂüü‰∏≠ÊáâÁî®ÁöÑÂ∑•‰ΩúÊúâÈôê„ÄÇÁÑ∂ËÄåÔºåÂú®ÈÄôÂÄãÈ†òÂüü‰∏≠Ëá™ÁÑ∂ÊúÉÂá∫ÁèæÈúÄË¶Å KE ÁöÑÂ†¥ÊôØÔºå‰æãÂ¶ÇÂèäÊôÇÊõ¥Êñ∞Áî¢ÂìÅÂäüËÉΩÂíåÂÆ¢Êà∂ÁöÑË∂®Âã¢Ë≥ºË≤∑ÊÑèÂúñÔºåÈÄôÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁéáÂÖàÂú®ÈõªÂ≠êÂïÜÂãôÈ†òÂüüÊáâÁî® KEÔºåÊèêÂá∫ ECOMEDITÔºå‰∏ÄÂÄãÈáùÂ∞çÈõªÂ≠êÂïÜÂãôÁõ∏ÈóúÁü•Ë≠òÂíå‰ªªÂãôÈáèË∫´ÊâìÈÄ†ÁöÑËá™ÂãïÂåñÈõªÂ≠êÂïÜÂãôÁü•Ë≠òÁ∑®ËºØÊ°ÜÊû∂„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂Âà©Áî®Êõ¥Âº∑Â§ßÁöÑ LLM ‰ΩúÁÇ∫Âà§Êñ∑ËÄÖÔºå‰ª•ÂØ¶ÁèæËá™ÂãïÁü•Ë≠òË°ùÁ™ÅÊ™¢Ê∏¨Ôºå‰∏¶ÁµêÂêàÊ¶ÇÂøµÂåñ‰ª•Â¢ûÂº∑ÂæÖÁ∑®ËºØÁü•Ë≠òÁöÑË™ûÁæ©Ê∂µËìãÁØÑÂúç„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé‰∫Ü ECOMEDIT Âú®ÊîπÂñÑ LLM Â∞çÁî¢ÂìÅÊèèËø∞ÂíåË≥ºË≤∑ÊÑèÂúñÁöÑÁêÜËß£ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÈÇÑË°®ÊòéÔºåÁ∂ìÈÅéÊàëÂÄëÁöÑÁ∑®ËºØÂæåÔºåLLM ÂèØ‰ª•Âú®‰∏ãÊ∏∏ÈõªÂ≠êÂïÜÂãô‰ªªÂãô‰∏≠ÂØ¶ÁèæÊõ¥Âº∑ÁöÑÊïàËÉΩ„ÄÇ

##### **REEF: Representation Encoding Fingerprints for Large Language Models**
2410.14273v1 by Jie Zhang, Dongrui Liu, Chen Qian, Linfeng Zhang, Yong Liu, Yu Qiao, Jing Shao

Protecting the intellectual property of open-source Large Language Models
(LLMs) is very important, because training LLMs costs extensive computational
resources and data. Therefore, model owners and third parties need to identify
whether a suspect model is a subsequent development of the victim model. To
this end, we propose a training-free REEF to identify the relationship between
the suspect and victim models from the perspective of LLMs' feature
representations. Specifically, REEF computes and compares the centered kernel
alignment similarity between the representations of a suspect model and a
victim model on the same samples. This training-free REEF does not impair the
model's general capabilities and is robust to sequential fine-tuning, pruning,
model merging, and permutations. In this way, REEF provides a simple and
effective way for third parties and models' owners to protect LLMs'
intellectual property together. The code is available at
https://github.com/tmylla/REEF.

ÊëòË¶ÅÔºö‰øùË≠∑ÈñãÊ∫êÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊô∫ÊÖßË≤°Áî¢Ê¨äÈùûÂ∏∏ÈáçË¶ÅÔºåÂõ†ÁÇ∫Ë®ìÁ∑¥ LLM ÈúÄË¶ÅÂ§ßÈáèÁöÑÈÅãÁÆóË≥áÊ∫êÂíåË≥áÊñô„ÄÇÂõ†Ê≠§ÔºåÊ®°ÂûãÊâÄÊúâËÄÖÂíåÁ¨¨‰∏âÊñπÈúÄË¶ÅËæ®Ë≠òÂèØÁñëÊ®°ÂûãÊòØÂê¶ÊòØÂèóÂÆ≥Ê®°ÂûãÁöÑÂæåÁ∫åÈñãÁôº„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁÑ°ÈúÄË®ìÁ∑¥ÁöÑ REEFÔºåÂæû LLM ÁâπÂæµË°®Á§∫ÁöÑËßíÂ∫¶‰æÜËæ®Ë≠òÂèØÁñëÊ®°ÂûãÂíåÂèóÂÆ≥Ê®°Âûã‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåREEF Ë®àÁÆó‰∏¶ÊØîËºÉÂèØÁñëÊ®°ÂûãÂíåÂèóÂÆ≥Ê®°ÂûãÂú®Áõ∏ÂêåÊ®£Êú¨‰∏äÁöÑ‰∏≠ÂøÉÂåñÊ†∏Â∞çÈΩäÁõ∏‰ººÊÄß„ÄÇÈÄôÂÄãÁÑ°ÈúÄË®ìÁ∑¥ÁöÑ REEF Ê≤íÊúâÊêçÂÆ≥Ê®°ÂûãÁöÑ‰∏ÄËà¨ÂäüËÉΩÔºå‰∏¶‰∏îÂ∞çÊñºÂæ™Â∫èÊº∏ÈÄ≤ÁöÑÂæÆË™ø„ÄÅÂâ™Êûù„ÄÅÊ®°ÂûãÂêà‰ΩµÂíåÊéíÂàóÁµÑÂêàÂÖ∑ÊúâÁ©©ÂÅ•ÊÄß„ÄÇÈÄôÊ®£ÔºåREEF ÁÇ∫Á¨¨‰∏âÊñπÂíåÊ®°ÂûãÊâÄÊúâËÄÖÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÁ∞°ÂñÆ‰∏îÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•ÂÖ±Âêå‰øùË≠∑ LLM ÁöÑÊô∫ÊÖßË≤°Áî¢Ê¨ä„ÄÇÁ®ãÂºèÁ¢ºÂèØÊñº https://github.com/tmylla/REEF ÂèñÂæó„ÄÇ

##### **MoDification: Mixture of Depths Made Easy**
2410.14268v1 by Chen Zhang, Meizhi Zhong, Qimeng Wang, Xuantao Lu, Zheyu Ye, Chengqiang Lu, Yan Gao, Yao Hu, Kehai Chen, Min Zhang, Dawei Song

Long-context efficiency has recently become a trending topic in serving large
language models (LLMs). And mixture of depths (MoD) is proposed as a perfect
fit to bring down both latency and memory. In this paper, however, we discover
that MoD can barely transform existing LLMs without costly training over an
extensive number of tokens. To enable the transformations from any LLMs to MoD
ones, we showcase top-k operator in MoD should be promoted to threshold-p
operator, and refinement to architecture and data should also be crafted along.
All these designs form our method termed MoDification. Through a comprehensive
set of experiments covering model scales from 3B to 70B, we exhibit
MoDification strikes an excellent balance between efficiency and effectiveness.
MoDification can achieve up to ~1.2x speedup in latency and ~1.8x reduction in
memory compared to original LLMs especially in long-context applications.

ÊëòË¶ÅÔºöÊúÄËøëÔºåÈï∑ÊñáÊú¨ÊïàÁéáÂ∑≤ÊàêÁÇ∫ÊúçÂãôÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁÜ±ÈñÄË©±È°å„ÄÇÊ∑±Â∫¶Ê∑∑Âêà (MoD) Ë¢´ÊèêË≠∞ÁÇ∫Èôç‰ΩéÂª∂ÈÅ≤ÂíåË®òÊÜ∂È´îÁöÑÂÆåÁæéËß£Ê±∫ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁôºÁèæ MoD Âπæ‰πéÁÑ°Ê≥ïËΩâÊèõÁèæÊúâÁöÑ LLMÔºåËÄåÁÑ°ÈúÄÂú®Â§ßÈáè token ‰∏äÈÄ≤Ë°å‰ª£ÂÉπÈ´òÊòÇÁöÑË®ìÁ∑¥„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÂæû‰ªª‰Ωï LLM ËΩâÊèõÁÇ∫ MoDÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü MoD ‰∏≠ÁöÑ top-k ÁÆóÂ≠êÊáâÊèêÂçáÁÇ∫ÈñæÂÄº-p ÁÆóÂ≠êÔºå‰∏¶‰∏îÈÇÑÊáâË™øÊï¥Êû∂ÊßãÂíåÊï∏Êìö„ÄÇÊâÄÊúâÈÄô‰∫õË®≠Ë®àÊßãÊàê‰∫ÜÊàëÂÄëÁ®±ÁÇ∫ MoDification ÁöÑÊñπÊ≥ï„ÄÇÈÄèÈÅéÊ∂µËìãÂæû 3B Âà∞ 70B ÁöÑÊ®°ÂûãË¶èÊ®°ÁöÑÂÖ®Èù¢ÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü MoDification Âú®ÊïàÁéáÂíåÊúâÊïàÊÄß‰πãÈñìÂèñÂæó‰∫ÜÊ•µ‰Ω≥ÁöÑÂπ≥Ë°°„ÄÇËàáÂéüÂßã LLM Áõ∏ÊØîÔºåMoDification ÂèØ‰ª•ÂØ¶ÁèæÂª∂ÈÅ≤ÈÄüÂ∫¶ÊúÄÈ´òÊèêÂçá ~1.2 ÂÄçÔºåË®òÊÜ∂È´îÊ∏õÂ∞ë ~1.8 ÂÄçÔºåÂ∞§ÂÖ∂ÊòØÂú®Èï∑ÊñáÊú¨ÊáâÁî®‰∏≠„ÄÇ

##### **Good Parenting is all you need -- Multi-agentic LLM Hallucination Mitigation**
2410.14262v1 by Edward, Kwartler, Matthew Berman, Alan Aqrawi

This study explores the ability of Large Language Model (LLM) agents to
detect and correct hallucinations in AI-generated content. A primary agent was
tasked with creating a blog about a fictional Danish artist named Flipfloppidy,
which was then reviewed by another agent for factual inaccuracies. Most LLMs
hallucinated the existence of this artist. Across 4,900 test runs involving
various combinations of primary and reviewing agents, advanced AI models such
as Llama3-70b and GPT-4 variants demonstrated near-perfect accuracy in
identifying hallucinations and successfully revised outputs in 85% to 100% of
cases following feedback. These findings underscore the potential of advanced
AI models to significantly enhance the accuracy and reliability of generated
content, providing a promising approach to improving AI workflow orchestration.

ÊëòË¶ÅÔºöÈÄôÈ†ÖÁ†îÁ©∂Êé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ª£ÁêÜÂÅµÊ∏¨Âíå‰øÆÊ≠£ AI ÁîüÊàêÁöÑÂÖßÂÆπ‰∏≠ÂπªË¶∫ÁöÑËÉΩÂäõ„ÄÇ‰∏ªË¶Å‰ª£ÁêÜË¢´Ë≥¶‰∫àÂª∫Á´ã‰∏ÄÂÄãÈóúÊñºËôõÊßã‰∏πÈ∫•ËóùË°ìÂÆ∂ Flipfloppidy ÁöÑÈÉ®ËêΩÊ†ºÔºåÁÑ∂ÂæåÁî±Âè¶‰∏ÄÂÄã‰ª£ÁêÜÂØ©Êü•‰∫ãÂØ¶‰∏çÊ≠£Á¢∫‰πãËôï„ÄÇÂ§ßÂ§öÊï∏ LLM ÂπªË¶∫‰∫ÜÈÄô‰ΩçËóùË°ìÂÆ∂ÁöÑÂ≠òÂú®„ÄÇÂú®Ê∂âÂèä‰∏ªË¶ÅÂíåÂØ©Êü•‰ª£ÁêÜÁöÑÂêÑÁ®ÆÁµÑÂêàÁöÑ 4,900 Ê¨°Ê∏¨Ë©¶ÈÅãË°å‰∏≠ÔºåÈÄ≤Èöé AI Ê®°ÂûãÔºà‰æãÂ¶Ç Llama3-70b Âíå GPT-4 ËÆäÈ´îÔºâÂú®Ëæ®Ë≠òÂπªË¶∫ÊñπÈù¢Ë°®ÁèæÂá∫Ëøë‰πéÂÆåÁæéÁöÑÊ∫ñÁ¢∫ÊÄßÔºå‰∏¶Âú® 85% Âà∞ 100% ÁöÑÊ°à‰æã‰∏≠Ê†πÊìöÂõûÈ•ãÊàêÂäüÂú∞‰øÆÊîπ‰∫ÜËº∏Âá∫„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜÈÄ≤Èöé AI Ê®°ÂûãÂ§ßÂπÖÊèêÂçáÁîüÊàêÂÖßÂÆπÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈù†ÊÄßÁöÑÊΩõÂäõÔºåÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÂ∏åÊúõÁöÑÊñπÊ≥ï‰æÜÊîπÂñÑ AI Â∑•‰ΩúÊµÅÁ®ãÁ∑®Êéí„ÄÇ

##### **Beyond Binary: Towards Fine-Grained LLM-Generated Text Detection via Role Recognition and Involvement Measurement**
2410.14259v1 by Zihao Cheng, Li Zhou, Feng Jiang, Benyou Wang, Haizhou Li

The rapid development of large language models (LLMs), like ChatGPT, has
resulted in the widespread presence of LLM-generated content on social media
platforms, raising concerns about misinformation, data biases, and privacy
violations, which can undermine trust in online discourse. While detecting
LLM-generated content is crucial for mitigating these risks, current methods
often focus on binary classification, failing to address the complexities of
real-world scenarios like human-AI collaboration. To move beyond binary
classification and address these challenges, we propose a new paradigm for
detecting LLM-generated content. This approach introduces two novel tasks: LLM
Role Recognition (LLM-RR), a multi-class classification task that identifies
specific roles of LLM in content generation, and LLM Influence Measurement
(LLM-IM), a regression task that quantifies the extent of LLM involvement in
content creation. To support these tasks, we propose LLMDetect, a benchmark
designed to evaluate detectors' performance on these new tasks. LLMDetect
includes the Hybrid News Detection Corpus (HNDC) for training detectors, as
well as DetectEval, a comprehensive evaluation suite that considers five
distinct cross-context variations and multi-intensity variations within the
same LLM role. This allows for a thorough assessment of detectors'
generalization and robustness across diverse contexts. Our empirical validation
of 10 baseline detection methods demonstrates that fine-tuned PLM-based models
consistently outperform others on both tasks, while advanced LLMs face
challenges in accurately detecting their own generated content. Our
experimental results and analysis offer insights for developing more effective
detection models for LLM-generated content. This research enhances the
understanding of LLM-generated content and establishes a foundation for more
nuanced detection methodologies.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â¶Ç ChatGPT ÁöÑÂø´ÈÄüÁôºÂ±ïÔºåÂ∞éËá¥ LLM ÁîüÊàêÁöÑÂÖßÂÆπÂª£Ê≥õÂá∫ÁèæÂú®Á§æÁæ§Â™íÈ´îÂπ≥Âè∞‰∏äÔºåÂºïÁôº‰∫ÜÈóúÊñºÈåØË™§Ë≥áË®ä„ÄÅË≥áÊñôÂÅèÂ∑ÆÂíåÈö±ÁßÅ‰æµÁäØÁöÑÁñëÊÖÆÔºåÈÄôÂèØËÉΩÁ†¥Â£ûÁ∑ö‰∏äË®éË´ñÁöÑ‰ø°‰ªªÊÑü„ÄÇÂÑòÁÆ°ÂÅµÊ∏¨ LLM ÁîüÊàêÁöÑÂÖßÂÆπÂ∞çÊñºÊ∏õËºïÈÄô‰∫õÈ¢®Èö™Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁõÆÂâçÁöÑÊñπÊ≥ïÈÄöÂ∏∏ËëóÈáçÊñº‰∫åÂÖÉÂàÜÈ°ûÔºåÊú™ËÉΩËß£Ê±∫ÁèæÂØ¶‰∏ñÁïåÊÉÖÂ¢ÉÔºà‰æãÂ¶Ç‰∫∫È°ûËàá AI Âêà‰ΩúÔºâÁöÑË§áÈõúÊÄß„ÄÇÁÇ∫‰∫ÜË∂ÖË∂ä‰∫åÂÖÉÂàÜÈ°û‰∏¶Ëß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÅµÊ∏¨ LLM ÁîüÊàêÁöÑÂÖßÂÆπÁöÑÊñ∞ÁØÑ‰æã„ÄÇÊ≠§ÊñπÊ≥ïÂºïÂÖ•‰∫ÜÂÖ©ÂÄãÊñ∞‰ªªÂãôÔºöLLM ËßíËâ≤Ëæ®Ë≠ò (LLM-RR)Ôºå‰∏ÄÂÄãÂ§öÈ°ûÂà•ÂàÜÈ°û‰ªªÂãôÔºåÁî®ÊñºË≠òÂà• LLM Âú®ÂÖßÂÆπÁî¢Áîü‰∏≠ÁöÑÁâπÂÆöËßíËâ≤Ôºõ‰ª•Âèä LLM ÂΩ±ÈüøÂäõÊ∏¨Èáè (LLM-IM)Ôºå‰∏ÄÂÄãÂõûÊ≠∏‰ªªÂãôÔºåÁî®ÊñºÈáèÂåñ LLM Âú®ÂÖßÂÆπÂâµ‰Ωú‰∏≠ÁöÑÂèÉËàáÁ®ãÂ∫¶„ÄÇÁÇ∫‰∫ÜÊîØÊè¥ÈÄô‰∫õ‰ªªÂãôÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LLMDetectÔºå‰∏ÄÂÄãÂü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞ÂÅµÊ∏¨Âô®Âú®ÈÄô‰∫õÊñ∞‰ªªÂãô‰∏äÁöÑÊïàËÉΩ„ÄÇLLMDetect ÂåÖÂê´‰∫ÜÊ∑∑ÂêàÊñ∞ËÅûÂÅµÊ∏¨Ë™ûÊñôÂ∫´ (HNDC)ÔºåÁî®ÊñºË®ìÁ∑¥ÂÅµÊ∏¨Âô®Ôºå‰ª•Âèä DetectEvalÔºå‰∏ÄÂÄãÂÖ®Èù¢ÁöÑË©ïÈáèÂ•ó‰ª∂ÔºåÂÆÉËÄÉÊÖÆ‰∫ÜÂêå‰∏ÄÂÄã LLM ËßíËâ≤‰∏≠ÁöÑ‰∫îÁ®Æ‰∏çÂêåÁöÑË∑®ÊÉÖÂ¢ÉËÆäÂåñÂíåÂ§öÂº∑Â∫¶ËÆäÂåñ„ÄÇÈÄôÂÖÅË®±Â∞çÂÅµÊ∏¨Âô®ÁöÑÊ≥õÂåñÊÄßÂíåÂú®‰∏çÂêåÊÉÖÂ¢É‰∏≠ÁöÑÁ©©ÂÅ•ÊÄßÈÄ≤Ë°åÂæπÂ∫ïË©ï‰º∞„ÄÇÊàëÂÄëÂ∞ç 10 Á®ÆÂü∫Á∑öÂÅµÊ∏¨ÊñπÊ≥ïÁöÑÂØ¶Ë≠âÈ©óË≠âË°®ÊòéÔºåÁ∂ìÈÅéÂæÆË™øÁöÑÂü∫Êñº PLM ÁöÑÊ®°ÂûãÂú®ÂÖ©ÂÄã‰ªªÂãô‰∏äÈÉΩÊåÅÁ∫åÂÑ™ÊñºÂÖ∂‰ªñÊ®°ÂûãÔºåËÄåÈÄ≤ÈöéÁöÑ LLM Âú®Ê∫ñÁ¢∫ÂÅµÊ∏¨ÂÖ∂Ëá™Â∑±Áî¢ÁîüÁöÑÂÖßÂÆπÊôÇÈù¢Ëá®ÊåëÊà∞„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÂíåÂàÜÊûêÊèê‰æõ‰∫ÜË¶ãËß£ÔºåÁî®ÊñºÈñãÁôºÊõ¥ÊúâÊïàÁöÑ LLM ÁîüÊàêÁöÑÂÖßÂÆπÂÅµÊ∏¨Ê®°Âûã„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Â¢ûÂº∑‰∫ÜÂ∞ç LLM ÁîüÊàêÁöÑÂÖßÂÆπÁöÑÁêÜËß£Ôºå‰∏¶ÁÇ∫Êõ¥Á¥∞Á∑ªÁöÑÂÅµÊ∏¨ÊñπÊ≥ïÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ

##### **Revisiting SLO and Goodput Metrics in LLM Serving**
2410.14257v1 by Zhibin Wang, Shipeng Li, Yuhang Zhou, Xue Li, Rong Gu, Nguyen Cam-Tu, Chen Tian, Sheng Zhong

Large language models (LLMs) have achieved remarkable performance and are
widely deployed in various applications, while the serving of LLM inference has
raised concerns about user experience and serving throughput. Accordingly,
service level objectives (SLOs) and goodput-the number of requests that meet
SLOs per second-are introduced to evaluate the performance of LLM serving.
However, existing metrics fail to capture the nature of user experience. We
observe two ridiculous phenomena in existing metrics: 1) delaying token
delivery can smooth the tail time between tokens (tail TBT) of a request and 2)
dropping the request that fails to meet the SLOs midway can improve goodput.
  In this paper, we revisit SLO and goodput metrics in LLM serving and propose
a unified metric framework smooth goodput including SLOs and goodput to reflect
the nature of user experience in LLM serving. The framework can adapt to
specific goals of different tasks by setting parameters. We re-evaluate the
performance of different LLM serving systems under multiple workloads based on
this unified framework and provide possible directions for future optimization
of existing strategies. We hope that this framework can provide a unified
standard for evaluating LLM serving and foster researches in the field of LLM
serving optimization to move in a cohesive direction.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÂèñÂæóÂçìË∂äÁöÑÊïàËÉΩÔºå‰∏¶Âª£Ê≥õÈÉ®ÁΩ≤ÊñºÂêÑÁ®ÆÊáâÁî®Á®ãÂºè‰∏≠ÔºåËÄå LLM Êé®Ë´ñÁöÑÊúçÂãôÂ∑≤ÂºïÁôºÂ∞ç‰ΩøÁî®ËÄÖÈ´îÈ©óÂíåÊúçÂãôÂÇ≥Ëº∏ÈáèÁöÑÁñëÊÖÆ„ÄÇÂõ†Ê≠§ÔºåÊúçÂãôÁ≠âÁ¥öÁõÆÊ®ô (SLO) ÂíåÂÇ≥Ëº∏ÈáèÔºàÊØèÁßíÁ¨¶Âêà SLO ÁöÑË´ãÊ±ÇÊï∏ÈáèÔºâË¢´ÂºïÂÖ•‰ª•Ë©ï‰º∞ LLM ÊúçÂãôÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊåáÊ®ôÁÑ°Ê≥ïÊçïÊçâ‰ΩøÁî®ËÄÖÈ´îÈ©óÁöÑÊú¨Ë≥™„ÄÇÊàëÂÄëÂú®ÁèæÊúâÁöÑÊåáÊ®ô‰∏≠ËßÄÂØüÂà∞ÂÖ©ÂÄãËçíË¨¨ÁöÑÁèæË±°Ôºö1) Âª∂ÈÅ≤‰ª§ÁâåÂÇ≥ÈÅûÂèØ‰ª•Âπ≥ÊªëË´ãÊ±ÇÁöÑ‰ª§Áâå‰πãÈñìÁöÑÂ∞æÁ´ØÊôÇÈñì (tail TBT)Ôºå2) ÊîæÊ£ÑÁÑ°Ê≥ïÊªøË∂≥ SLO ÁöÑË´ãÊ±ÇÂèØ‰ª•ÊîπÂñÑÂÇ≥Ëº∏Èáè„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈáçÊñ∞Ê™¢Ë¶ñ LLM ÊúçÂãô‰∏≠ÁöÑ SLO ÂíåÂÇ≥Ëº∏ÈáèÊåáÊ®ôÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊåáÊ®ôÊû∂ÊßãÂπ≥ÊªëÂÇ≥Ëº∏ÈáèÔºåÂåÖÊã¨ SLO ÂíåÂÇ≥Ëº∏ÈáèÔºå‰ª•ÂèçÊò† LLM ÊúçÂãô‰∏≠‰ΩøÁî®ËÄÖÈ´îÈ©óÁöÑÊú¨Ë≥™„ÄÇË©≤Êû∂ÊßãÂèØ‰ª•ÈÄèÈÅéË®≠ÂÆöÂèÉÊï∏‰æÜÈÅ©Êáâ‰∏çÂêå‰ªªÂãôÁöÑÁâπÂÆöÁõÆÊ®ô„ÄÇÊàëÂÄëÊ†πÊìöÈÄôÂÄãÁµ±‰∏ÄÁöÑÊû∂ÊßãÔºåÂú®Â§öÂÄãÂ∑•‰ΩúË≤†Ëºâ‰∏ãÈáçÊñ∞Ë©ï‰º∞‰∏çÂêå LLM ÊúçÂãôÁ≥ªÁµ±ÁöÑÊïàËÉΩÔºå‰∏¶ÁÇ∫ÁèæÊúâÁ≠ñÁï•ÁöÑÊú™‰æÜÊúÄ‰Ω≥ÂåñÊèê‰æõÂèØËÉΩÁöÑÊñπÈáù„ÄÇÊàëÂÄëÂ∏åÊúõÈÄôÂÄãÊû∂ÊßãÂèØ‰ª•ÁÇ∫Ë©ï‰º∞ LLM ÊúçÂãôÊèê‰æõ‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊ®ôÊ∫ñÔºå‰∏¶‰øÉÈÄ≤ LLM ÊúçÂãôÊúÄ‰Ω≥ÂåñÈ†òÂüüÁöÑÁ†îÁ©∂ÊúùÂêë‰∏ÄÂÄã‰∏ÄËá¥ÁöÑÊñπÂêëÂâçÈÄ≤„ÄÇ

##### **Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas**
2410.14255v1 by Xiang Hu, Hongyu Fu, Jinge Wang, Yifeng Wang, Zhikun Li, Renjun Xu, Yu Lu, Yaochu Jin, Lili Pan, Zhenzhong Lan

Scientific innovation is pivotal for humanity, and harnessing large language
models (LLMs) to generate research ideas could transform discovery. However,
existing LLMs often produce simplistic and repetitive suggestions due to their
limited ability in acquiring external knowledge for innovation. To address this
problem, we introduce an enhanced planning and search methodology designed to
boost the creative potential of LLM-based systems. Our approach involves an
iterative process to purposely plan the retrieval of external knowledge,
progressively enriching the idea generation with broader and deeper insights.
Validation through automated and human assessments indicates that our framework
substantially elevates the quality of generated ideas, particularly in novelty
and diversity. The number of unique novel ideas produced by our framework is
3.4 times higher than without it. Moreover, our method outperforms the current
state-of-the-art, generating at least 2.5 times more top-rated ideas based on
170 seed papers in a Swiss Tournament evaluation.

ÊëòË¶ÅÔºöÁßëÂ≠∏ÂâµÊñ∞Â∞ç‰∫∫È°ûËá≥ÈóúÈáçË¶ÅÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÁî¢ÁîüÁ†îÁ©∂ÊÉ≥Ê≥ïÂèØ‰ª•ËΩâÂåñÁôºÁèæ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ LLM Áî±ÊñºÁç≤ÂèñÂ§ñÈÉ®Áü•Ë≠ò‰ª•ÈÄ≤Ë°åÂâµÊñ∞ÁöÑËÉΩÂäõÊúâÈôêÔºåÂõ†Ê≠§ÈÄöÂ∏∏ÊúÉÁî¢ÁîüÁ∞°Âåñ‰∏îÈáçË§áÁöÑÂª∫Ë≠∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÂ¢ûÂº∑ÁöÑË¶èÂäÉÂíåÊêúÂ∞ãÊñπÊ≥ïÔºåÊó®Âú®ÊèêÂçáÂü∫Êñº LLM ÁöÑÁ≥ªÁµ±ÁöÑÂâµÈÄ†ÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÊã¨‰∏ÄÂÄãÂèçË¶ÜÁöÑÈÅéÁ®ãÔºå‰ª•ÊúâÁõÆÁöÑÂú∞Ë¶èÂäÉÂ§ñÈÉ®Áü•Ë≠òÁöÑÊì∑ÂèñÔºåÈÄêÊ≠•Áî®Êõ¥Âª£Ê≥õÂíåÊõ¥Ê∑±ÂÖ•ÁöÑË¶ãËß£Ë±êÂØåÊÉ≥Ê≥ïÁöÑÁî¢Áîü„ÄÇÈÄèÈÅéËá™ÂãïÂåñÂíå‰∫∫Â∑•Ë©ï‰º∞È©óË≠âË°®ÊòéÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂Â§ßÂπÖÊèêÂçá‰∫ÜÊâÄÁî¢ÁîüÊÉ≥Ê≥ïÁöÑÂìÅË≥™ÔºåÁâπÂà•ÊòØÂú®Êñ∞Á©éÊÄßÂíåÂ§öÊ®£ÊÄßÊñπÈù¢„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂Áî¢ÁîüÁöÑÁç®ÁâπÊñ∞Á©éÊÉ≥Ê≥ïÊï∏ÈáèÊØîÊ≤íÊúâÊ°ÜÊû∂ÁöÑÊÉÖÊ≥ÅÈ´òÂá∫ 3.4 ÂÄç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™ÊñºÁõÆÂâçÁöÑÊúÄÊñ∞ÊäÄË°ìÔºåÊ†πÊìöÁëûÂ£´Èå¶Ê®ôË≥ΩË©ï‰º∞‰∏≠ÁöÑ 170 ÁØáÁ®ÆÂ≠êË´ñÊñáÔºåËá≥Â∞ëÁî¢Áîü‰∫Ü 2.5 ÂÄç‰ª•‰∏äÁöÑÈ†ÇÁ¥öÊÉ≥Ê≥ï„ÄÇ

##### **Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation**
2410.14251v1 by Shuo Tang, Xianghe Pang, Zexi Liu, Bohan Tang, Rui Ye, Xiaowen Dong, Yanfeng Wang, Siheng Chen

Post-training is essential for enabling large language models (LLMs) to
follow human instructions. Inspired by the recent success of using LLMs to
simulate human society, we leverage multi-agent simulation to automatically
generate diverse text-based scenarios, capturing a wide range of real-world
human needs. We propose MATRIX, a multi-agent simulator that creates realistic
and scalable scenarios. Leveraging these outputs, we introduce a novel
scenario-driven instruction generator MATRIX-Gen for controllable and highly
realistic data synthesis. Extensive experiments demonstrate that our framework
effectively generates both general and domain-specific data. Notably, on
AlpacaEval 2 and Arena-Hard benchmarks, Llama-3-8B-Base, post-trained on
datasets synthesized by MATRIX-Gen with just 20K instruction-response pairs,
outperforms Meta's Llama-3-8B-Instruct model, which was trained on over 10M
pairs; see our project at https://github.com/ShuoTang123/MATRIX-Gen.

ÊëòË¶ÅÔºöË®ìÁ∑¥ÂæåÂ∞çÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜË™™ÈùûÂ∏∏ÈáçË¶ÅÔºåÂèØ‰ª•ËÆìÂÆÉÂÄëÈÅµÂæ™‰∫∫È°ûÁöÑÊåáÁ§∫„ÄÇÂèóÂà∞ÊúÄËøë‰ΩøÁî® LLM Ê®°Êì¨‰∫∫È°ûÁ§æÊúÉÁöÑÊàêÂäüÂïüÁôºÔºåÊàëÂÄëÂà©Áî®Â§öÈáç‰ª£ÁêÜÊ®°Êì¨Ëá™ÂãïÁî¢ÁîüÂ§öÊ®£ÂåñÁöÑÂü∫ÊñºÊñáÂ≠óÁöÑÂ†¥ÊôØÔºåÊçïÊçâÂª£Ê≥õÁöÑÁúüÂØ¶‰∏ñÁïå‰∫∫È°ûÈúÄÊ±Ç„ÄÇÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî® MATRIXÔºå‰∏ÄÁ®ÆÂ§öÈáç‰ª£ÁêÜÊ®°Êì¨Âô®ÔºåÂèØ‰ª•Âª∫Á´ãÂØ´ÂØ¶‰∏îÂÖ∑ÂÇôÊì¥ÂÖÖÊÄßÁöÑÂ†¥ÊôØ„ÄÇÂà©Áî®ÈÄô‰∫õËº∏Âá∫ÔºåÊàëÂÄë‰ªãÁ¥π‰∏ÄÂÄãÊñ∞ÁöÑÂ†¥ÊôØÈ©ÖÂãïÂºèÊåáÁ§∫Áî¢ÁîüÂô® MATRIX-GenÔºåÁî®ÊñºÂèØÊéß‰∏îÈ´òÂ∫¶ÂØ´ÂØ¶ÁöÑË≥áÊñôÂêàÊàê„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÊàëÂÄëÁöÑÊû∂ÊßãÊúâÊïàÂú∞Áî¢Áîü‰∏ÄËà¨ÊÄßÂíåÁâπÂÆöÈ†òÂüüÁöÑË≥áÊñô„ÄÇÁâπÂà•ÊòØÂú® AlpacaEval 2 Âíå Arena-Hard Âü∫Ê∫ñ‰∏äÔºåLlama-3-8B-Base ÂÉÖ‰ΩøÁî® 20K ÊåáÁ§∫ÂõûÊáâÂ∞çÔºåÂú® MATRIX-Gen ÂêàÊàêÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂæåÁ∫åË®ìÁ∑¥ÔºåÂÖ∂ÊïàËÉΩÂÑ™Êñº Meta ÁöÑ Llama-3-8B-Instruct Ê®°ÂûãÔºåËÄåÂæåËÄÖÊòØÂú®Ë∂ÖÈÅé 10M Â∞ç‰∏äÈÄ≤Ë°åË®ìÁ∑¥ÔºõË´ãÂèÉÈñ±ÊàëÂÄëÁöÑÂ∞àÊ°à https://github.com/ShuoTang123/MATRIX-Gen„ÄÇ

##### **Addressing Blind Guessing: Calibration of Selection Bias in Multiple-Choice Question Answering by Video Language Models**
2410.14248v1 by Olga Loginova, Oleksandr Bezrukov, Alexey Kravets

Evaluating Video Language Models (VLMs) is a challenging task. Due to its
transparency, Multiple-Choice Question Answering (MCQA) is widely used to
measure the performance of these models through accuracy. However, existing
MCQA benchmarks fail to capture the full reasoning capabilities of VLMs due to
selection bias, when models disproportionately favor certain answer options
based on positional patterns observed during training. In this work, we conduct
a comprehensive empirical analysis of several VLM architectures across major
datasets designed to assess complex video-focused reasoning. We identify where
the bias is most pronounced and demonstrate to what extent model responses
reflect genuine understanding of video content and related questions, as
opposed to reliance on arbitrary patterns or superficial cues, such as answer
position. By decomposing the MCQA task and adapting fairness bias metrics to
VLMs, we introduce a post-processing calibration technique BOLD to balance this
bias. Our results show that reducing selection bias improves not only debiasing
metrics but also overall model performance, including Accuracy and F1 Mean
score. Our method, by suppressing "blind guessing", offers a more cost- and
time-effective approach to mitigating selection bias compared to existing
techniques. This study represents the first focused investigation of selection
bias in video-to-text LLM-powered models.

ÊëòË¶ÅÔºöË©ï‰º∞ÂΩ±ÁâáË™ûË®ÄÊ®°Âûã (VLM) ÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÁî±ÊñºÂÖ∂ÈÄèÊòéÊÄßÔºåÂ§öÈÅ∏È°åÂïèÁ≠î (MCQA) Âª£Ê≥õÁî®ÊñºÈÄèÈÅéÊ∫ñÁ¢∫Â∫¶‰æÜË°°ÈáèÈÄô‰∫õÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ MCQA Âü∫Ê∫ñÁÑ°Ê≥ïÊçïÊçâÂà∞ VLM ÁöÑÂÆåÊï¥Êé®ÁêÜËÉΩÂäõÔºåÂéüÂõ†Âú®ÊñºÈÅ∏ÊìáÂÅèÂ∑ÆÔºåÁï∂Ê®°ÂûãÂü∫ÊñºË®ìÁ∑¥ÊúüÈñìËßÄÂØüÂà∞ÁöÑ‰ΩçÁΩÆÊ®°ÂºèËÄåÈÅéÂ∫¶ÂÅèÂ•ΩÊüê‰∫õÁ≠îÊ°àÈÅ∏È†ÖÊôÇÔºåÂ∞±ÊúÉÁôºÁîüÈÄôÁ®ÆÊÉÖÊ≥Å„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞çÂ§öÂÄã VLM Êû∂ÊßãÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÁ∂ìÈ©óÂàÜÊûêÔºåÈÄô‰∫õÊû∂ÊßãË∑®Ë∂ä‰∫ÜÊó®Âú®Ë©ï‰º∞Ë§áÈõúÂΩ±ÁâáÁÑ¶ÈªûÊé®ÁêÜÁöÑ‰∏ªË¶ÅË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÊâæÂá∫ÂÅèÂ∑ÆÊúÄÊòéÈ°ØÁöÑÂú∞ÊñπÔºå‰∏¶Â±ïÁ§∫Ê®°ÂûãÂõûÊáâÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÂèçÊò†‰∫ÜÂ∞çÂΩ±ÁâáÂÖßÂÆπÂíåÁõ∏ÈóúÂïèÈ°åÁöÑÁúüÊ≠£ÁêÜËß£ÔºåËÄå‰∏çÊòØ‰æùË≥¥Êñº‰ªªÊÑèÊ®°ÂºèÊàñË°®Èù¢Á∑öÁ¥¢Ôºå‰æãÂ¶ÇÁ≠îÊ°à‰ΩçÁΩÆ„ÄÇÈÄèÈÅéÂàÜËß£ MCQA ‰ªªÂãô‰∏¶Â∞áÂÖ¨Âπ≥ÊÄßÂÅèÂ∑ÆÊåáÊ®ôË™øÊï¥ÁÇ∫ VLMÔºåÊàëÂÄëÂºïÂÖ•ÂæåËôïÁêÜÊ†°Ê≠£ÊäÄË°ì BOLD ‰æÜÂπ≥Ë°°Ê≠§ÂÅèÂ∑Æ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÊ∏õÂ∞ëÈÅ∏ÊìáÂÅèÂ∑Æ‰∏çÂÉÖÊîπÂñÑ‰∫ÜÂéªÂÅèÂ∑ÆÊåáÊ®ôÔºå‰πüÊîπÂñÑ‰∫ÜÊï¥È´îÊ®°ÂûãÊïàËÉΩÔºåÂåÖÊã¨Ê∫ñÁ¢∫Â∫¶Âíå F1 Âπ≥ÂùáÂàÜÊï∏„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÈÄèÈÅéÊäëÂà∂„ÄåÁõ≤Áåú„ÄçÔºåÊèê‰æõ‰∏ÄÁ®ÆËàáÁèæÊúâÊäÄË°ìÁõ∏ÊØîÊõ¥ÂÖ∑ÊàêÊú¨ÊïàÁõäÂíåÊôÇÈñìÊïàÁõäÁöÑÊñπÊ≥ï‰æÜÊ∏õËºïÈÅ∏ÊìáÂÅèÂ∑Æ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂‰ª£Ë°®‰∫ÜÂ∞çÂΩ±ÁâáÂà∞ÊñáÂ≠ó LLM È©ÖÂãïÊ®°Âûã‰∏≠ÈÅ∏ÊìáÂÅèÂ∑ÆÁöÑÈ¶ñÊ¨°ÈáçÈªûË™øÊü•„ÄÇ

##### **Almost-Linear RNNs Yield Highly Interpretable Symbolic Codes in Dynamical Systems Reconstruction**
2410.14240v1 by Manuel Brenner, Christoph J√ºrgen Hemmer, Zahra Monfared, Daniel Durstewitz

Dynamical systems (DS) theory is fundamental for many areas of science and
engineering. It can provide deep insights into the behavior of systems evolving
in time, as typically described by differential or recursive equations. A
common approach to facilitate mathematical tractability and interpretability of
DS models involves decomposing nonlinear DS into multiple linear DS separated
by switching manifolds, i.e. piecewise linear (PWL) systems. PWL models are
popular in engineering and a frequent choice in mathematics for analyzing the
topological properties of DS. However, hand-crafting such models is tedious and
only possible for very low-dimensional scenarios, while inferring them from
data usually gives rise to unnecessarily complex representations with very many
linear subregions. Here we introduce Almost-Linear Recurrent Neural Networks
(AL-RNNs) which automatically and robustly produce most parsimonious PWL
representations of DS from time series data, using as few PWL nonlinearities as
possible. AL-RNNs can be efficiently trained with any SOTA algorithm for
dynamical systems reconstruction (DSR), and naturally give rise to a symbolic
encoding of the underlying DS that provably preserves important topological
properties. We show that for the Lorenz and R\"ossler systems, AL-RNNs
discover, in a purely data-driven way, the known topologically minimal PWL
representations of the corresponding chaotic attractors. We further illustrate
on two challenging empirical datasets that interpretable symbolic encodings of
the dynamics can be achieved, tremendously facilitating mathematical and
computational analysis of the underlying systems.

ÊëòË¶ÅÔºöÂãïÂäõÁ≥ªÁµ± (DS) ÁêÜË´ñÊòØË®±Â§öÁßëÂ≠∏ÂíåÂ∑•Á®ãÈ†òÂüüÁöÑÂü∫Á§é„ÄÇÂÆÉÂèØ‰ª•Ê∑±ÂÖ•‰∫ÜËß£Á≥ªÁµ±Èö®ËëóÊôÇÈñìÊºîËÆäÁöÑË°åÁÇ∫ÔºåÈÄöÂ∏∏Áî®ÂæÆÂàÜÊàñÈÅûËø¥ÊñπÁ®ãÂºèÊèèËø∞„ÄÇ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÊñπÊ≥ïÊòØÈÄèÈÅéÂ∞áÈùûÁ∑öÊÄß DS ÂàÜËß£ÁÇ∫Â§öÂÄãÁ∑öÊÄß DSÔºåÂÜçÁî±ÂàáÊèõÊµÅÂΩ¢ÂàÜÈöîÔºå‰πüÂ∞±ÊòØÂàÜÊÆµÁ∑öÊÄß (PWL) Á≥ªÁµ±Ôºå‰ª•Âà©ÊñºÊï∏Â≠∏‰∏äÁöÑÂèØËøΩËπ§ÊÄßÂíå DS Ê®°ÂûãÁöÑÂèØË©ÆÈáãÊÄß„ÄÇPWL Ê®°ÂûãÂú®Â∑•Á®ã‰∏≠ÂæàÂèóÊ≠°ËøéÔºåËÄå‰∏îÊòØÊï∏Â≠∏‰∏≠Áî®ÊñºÂàÜÊûê DS ÊãìÊí≤ÊÄßË≥™ÁöÑÂ∏∏Ë¶ãÈÅ∏Êìá„ÄÇÁÑ∂ËÄåÔºåÊâãÂ∑•ÊâìÈÄ†Ê≠§È°ûÊ®°ÂûãÂæàÁπÅÁë£ÔºåËÄå‰∏îÂÉÖÈÅ©Áî®ÊñºÈùûÂ∏∏‰ΩéÁ∂≠Â∫¶ÁöÑÂ†¥ÊôØÔºåËÄåÂæûË≥áÊñô‰∏≠Êé®Ë´ñÂÆÉÂÄëÈÄöÂ∏∏ÊúÉÁî¢Áîü‰∏çÂøÖË¶ÅÁöÑË§áÈõúË°®Á§∫ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÈùûÂ∏∏Â§öÁ∑öÊÄßÂ≠êÂçÄÂüü„ÄÇÂú®Ê≠§ÔºåÊàëÂÄë‰ªãÁ¥πÂπæ‰πéÁ∑öÊÄßÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑Ø (AL-RNN)ÔºåÂÆÉÂèØ‰ª•Ëá™Âãï‰∏îÁ©©ÂÅ•Âú∞Áî¢Áîü DS ÁöÑÊúÄÁ∞°Á¥Ñ PWL Ë°®Á§∫Ôºå‰ΩøÁî®ÊúÄÂ∞ëÂèØËÉΩÁöÑ PWL ÈùûÁ∑öÊÄß„ÄÇAL-RNN ÂèØ‰ª•‰ΩøÁî®‰ªª‰Ωï SOTA ÊºîÁÆóÊ≥ïÈÄ≤Ë°åÊúâÊïàË®ìÁ∑¥ÔºåÁî®ÊñºÂãïÊÖãÁ≥ªÁµ±ÈáçÂª∫ (DSR)Ôºå‰∏¶Ëá™ÁÑ∂Áî¢ÁîüÂü∫Á§é DS ÁöÑÁ¨¶ËôüÁ∑®Á¢ºÔºåÂèØË≠âÊòé‰øùÁïôÈáçË¶ÅÁöÑÊãìÊí≤ÊÄßË≥™„ÄÇÊàëÂÄëÈ°ØÁ§∫Â∞çÊñº Lorenz Âíå R\"ossler Á≥ªÁµ±ÔºåAL-RNN ‰ª•Á¥îÁ≤πË≥áÊñôÈ©ÖÂãïÁöÑÊñπÂºèÁôºÁèæÂ∑≤Áü•ÁöÑÂ∞çÊáâÊ∑∑Ê≤åÂê∏ÂºïÂ≠êÁöÑÊãìÊí≤ÊúÄÂ∞è PWL Ë°®Á§∫„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë™™Êòé‰∫ÜÂÖ©ÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁ∂ìÈ©óË≥áÊñôÈõÜÔºåÂèØ‰ª•ÈÅîÊàêÂãïÊÖãÁöÑÂèØË©ÆÈáãÁ¨¶ËôüÁ∑®Á¢ºÔºåÊ•µÂ§ßÂú∞‰øÉÈÄ≤‰∫ÜÂü∫Á§éÁ≥ªÁµ±ÁöÑÊï∏Â≠∏ÂíåË®àÁÆóÂàÜÊûê„ÄÇ

##### **A Novel Method to Metigate Demographic and Expert Bias in ICD Coding with Causal Inference**
2410.14236v1 by Bin Zhang, Junli Wang

ICD(International Classification of Diseases) coding involves assigning ICD
codes to patients visit based on their medical notes. Considering ICD coding as
a multi-label text classification task, researchers have developed
sophisticated methods. Despite progress, these models often suffer from label
imbalance and may develop spurious correlations with demographic factors.
Additionally, while human coders assign ICD codes, the inclusion of irrelevant
information from unrelated experts introduces biases. To combat these issues,
we propose a novel method to mitigate Demographic and Expert biases in ICD
coding through Causal Inference (DECI). We provide a novel causality-based
interpretation in ICD Coding that models make predictions by three distinct
pathways. And based counterfactual reasoning, DECI mitigate demographic and
expert biases. Experimental results show that DECI outperforms state-of-the-art
models, offering a significant advancement in accurate and unbiased ICD coding.

ÊëòË¶ÅÔºöICDÔºàÂúãÈöõÁñæÁóÖÂàÜÈ°ûÔºâÁ∑®Á¢ºÊ∂âÂèäÊ†πÊìöÊÇ£ËÄÖÁöÑÁóÖÊ≠∑ÁÇ∫ÊÇ£ËÄÖÂ∞±Ë®∫ÂàÜÈÖç ICD ‰ª£Á¢º„ÄÇÂ∞á ICD Á∑®Á¢ºË¶ñÁÇ∫Â§öÊ®ôÁ±§ÊñáÊú¨ÂàÜÈ°û‰ªªÂãôÔºåÁ†îÁ©∂‰∫∫Âì°Â∑≤Á∂ìÈñãÁôº‰∫ÜÁ≤æÂØÜÁöÑÊ®°Âûã„ÄÇÂÑòÁÆ°ÂèñÂæó‰∫ÜÈÄ≤Â±ïÔºå‰ΩÜÈÄô‰∫õÊ®°ÂûãÂ∏∏Â∏∏ÊúÉÈÅ≠ÂèóÊ®ôÁ±§‰∏çÂπ≥Ë°°ÁöÑÂõ∞ÊìæÔºå‰∏¶‰∏îÂèØËÉΩÊúÉËàá‰∫∫Âè£Áµ±Ë®àÂõ†Á¥†Áî¢ÁîüËôõÂÅáÁöÑÁõ∏ÈóúÊÄß„ÄÇÊ≠§Â§ñÔºåÈõñÁÑ∂‰∫∫È°ûÁ∑®Á¢ºÂô®ÊúÉÂàÜÈÖç ICD ‰ª£Á¢ºÔºå‰ΩÜÁ¥çÂÖ•‰æÜËá™‰∏çÁõ∏ÈóúÂ∞àÂÆ∂ÁöÑÁÑ°Èóú‰ø°ÊÅØÊúÉÂºïÂÖ•ÂÅèÂ∑Æ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÈÄöÈÅéÂõ†ÊûúÊé®ÁêÜ (DECI) ‰æÜÊ∏õËºï ICD Á∑®Á¢º‰∏≠ÁöÑ‰∫∫Âè£Áµ±Ë®àÂíåÂ∞àÂÆ∂ÂÅèÂ∑Æ„ÄÇÊàëÂÄëÂú® ICD Á∑®Á¢º‰∏≠Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂü∫ÊñºÂõ†ÊûúÈóú‰øÇÁöÑËß£ÈáãÔºåÂç≥Ê®°ÂûãÈÄöÈÅé‰∏âÊ¢ù‰∏çÂêåÁöÑÈÄîÂæëÈÄ≤Ë°åÈ†êÊ∏¨„ÄÇ‰∏¶Âü∫ÊñºÂèç‰∫ãÂØ¶Êé®ÁêÜÔºåDECI Ê∏õËºï‰∫Ü‰∫∫Âè£Áµ±Ë®àÂíåÂ∞àÂÆ∂ÂÅèÂ∑Æ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåDECI ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºåÂú®Ê∫ñÁ¢∫‰∏îÁÑ°ÂÅèÂ∑ÆÁöÑ ICD Á∑®Á¢ºÊñπÈù¢Êèê‰æõ‰∫ÜÈ°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇ

##### **Towards Robust Knowledge Representations in Multilingual LLMs for Equivalence and Inheritance based Consistent Reasoning**
2410.14235v1 by Gaurav Arora, Srujana Merugu, Shreya Jain, Vaibhav Saxena

Reasoning and linguistic skills form the cornerstone of human intelligence,
facilitating problem-solving and decision-making. Recent advances in Large
Language Models (LLMs) have led to impressive linguistic capabilities and
emergent reasoning behaviors, fueling widespread adoption across application
domains. However, LLMs still struggle with complex reasoning tasks,
highlighting their systemic limitations. In this work, we focus on evaluating
whether LLMs have the requisite representations to reason using two
foundational relationships: "equivalence" and "inheritance". We introduce novel
tasks and benchmarks spanning six languages and observe that current SOTA LLMs
often produce conflicting answers to the same questions across languages in
17.3-57.5% of cases and violate inheritance constraints in up to 37.2% cases.
To enhance consistency across languages, we propose novel "Compositional
Representations" where tokens are represented as composition of equivalent
tokens across languages, with resulting conflict reduction (up to -4.7%)
indicating benefits of shared LLM representations.

ÊëòË¶ÅÔºöÊé®ÁêÜÂíåË™ûË®ÄËÉΩÂäõÊòØ‰∫∫È°ûÊô∫ÊÖßÁöÑÂü∫Áü≥Ôºå
‰øÉÈÄ≤‰∫ÜËß£Ê±∫ÂïèÈ°åÂíåÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∏∂‰æÜ‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑË™ûË®ÄËÉΩÂäõÂíå
Êñ∞ËààÁöÑÊé®ÁêÜË°åÁÇ∫ÔºåÊé®Âãï‰∫ÜË∑®ÊáâÁî®È†òÂüüÁöÑÂª£Ê≥õÊé°Áî®„ÄÇÁÑ∂ËÄåÔºåLLM ‰ªçÁÑ∂Èõ£‰ª•Êáâ‰ªòË§áÈõúÁöÑÊé®ÁêÜ‰ªªÂãôÔºå
Á™ÅÈ°Ø‰∫ÜÂÆÉÂÄëÁöÑÁ≥ªÁµ±ÊÄßÈôêÂà∂„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºË©ï‰º∞ LLM ÊòØÂê¶ÂÖ∑Êúâ‰ΩøÁî®ÂÖ©Á®Æ
Âü∫Êú¨Èóú‰øÇÔºö„ÄåÁ≠âÂÉπ„ÄçÂíå„ÄåÁπºÊâø„ÄçÈÄ≤Ë°åÊé®ÁêÜÊâÄÈúÄÁöÑË°®Âæµ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫ÜË∑®Ë∂äÂÖ≠Á®ÆË™ûË®ÄÁöÑÊñ∞‰ªªÂãôÂíåÂü∫Ê∫ñÔºå‰∏¶ËßÄÂØüÂà∞Áï∂ÂâçÁöÑ SOTA LLM
ÈÄöÂ∏∏Âú® 17.3-57.5% ÁöÑÊÉÖÊ≥Å‰∏ãÂ∞çÂêå‰∏ÄÂïèÈ°åÁî¢ÁîüÁõ∏‰∫íÁüõÁõæÁöÑÁ≠îÊ°àÔºå‰∏¶Âú®È´òÈÅî 37.2% ÁöÑÊÉÖÊ≥Å‰∏ãÈÅïÂèçÁπºÊâøÁ¥ÑÊùü„ÄÇ
ÁÇ∫‰∫ÜÂ¢ûÂº∑Ë∑®Ë™ûË®ÄÁöÑ‰∏ÄËá¥ÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊñ∞ÁöÑ„ÄåÁµÑÂêàË°®Âæµ„ÄçÔºåÂÖ∂‰∏≠Á¨¶ËôüË¢´Ë°®Á§∫ÁÇ∫Ë∑®Ë™ûË®ÄÁ≠âÂÉπÁ¨¶ËôüÁöÑÁµÑÂêàÔºåÁµêÊûúË°ùÁ™ÅÊ∏õÂ∞ëÔºàÊúÄÂ§ö -4.7%Ôºâ
Ë°®Á§∫ÂÖ±‰∫´ LLM Ë°®ÂæµÁöÑÂ•ΩËôï„ÄÇ

##### **Unveiling Large Language Models Generated Texts: A Multi-Level Fine-Grained Detection Framework**
2410.14231v1 by Zhen Tao, Zhiyu Li, Runyu Chen, Dinghao Xi, Wei Xu

Large language models (LLMs) have transformed human writing by enhancing
grammar correction, content expansion, and stylistic refinement. However, their
widespread use raises concerns about authorship, originality, and ethics, even
potentially threatening scholarly integrity. Existing detection methods, which
mainly rely on single-feature analysis and binary classification, often fail to
effectively identify LLM-generated text in academic contexts. To address these
challenges, we propose a novel Multi-level Fine-grained Detection (MFD)
framework that detects LLM-generated text by integrating low-level structural,
high-level semantic, and deep-level linguistic features, while conducting
sentence-level evaluations of lexicon, grammar, and syntax for comprehensive
analysis. To improve detection of subtle differences in LLM-generated text and
enhance robustness against paraphrasing, we apply two mainstream evasion
techniques to rewrite the text. These variations, along with original texts,
are used to train a text encoder via contrastive learning, extracting
high-level semantic features of sentence to boost detection generalization.
Furthermore, we leverage advanced LLM to analyze the entire text and extract
deep-level linguistic features, enhancing the model's ability to capture
complex patterns and nuances while effectively incorporating contextual
information. Extensive experiments on public datasets show that the MFD model
outperforms existing methods, achieving an MAE of 0.1346 and an accuracy of
88.56%. Our research provides institutions and publishers with an effective
mechanism to detect LLM-generated text, mitigating risks of compromised
authorship. Educators and editors can use the model's predictions to refine
verification and plagiarism prevention protocols, ensuring adherence to
standards.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄèÈÅéÂ¢ûÂº∑ÊñáÊ≥ï‰øÆÊ≠£„ÄÅÂÖßÂÆπÊì¥ÂÖÖÂíåÊñáÈ´îÊΩ§È£æÔºåËΩâËÆä‰∫Ü‰∫∫È°ûÂØ´‰ΩúÊñπÂºè„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÁöÑÂª£Ê≥õ‰ΩøÁî®ÂºïÁôº‰∫ÜÈóúÊñº‰ΩúËÄÖË∫´‰ªΩ„ÄÅÂéüÂâµÊÄßËàáÈÅìÂæ∑ÁöÑÁñëÊÖÆÔºåÁîöËá≥ÊΩõÂú®Â®ÅËÑÖÂà∞Â≠∏Ë°ìÁöÑÂÆåÊï¥ÊÄß„ÄÇÁèæÊúâÁöÑÂÅµÊ∏¨ÊñπÊ≥ï‰∏ªË¶Å‰æùË≥¥ÊñºÂñÆ‰∏ÄÁâπÂæµÂàÜÊûêÂíå‰∫åÂÖÉÂàÜÈ°ûÔºåÂæÄÂæÄÁÑ°Ê≥ïÂú®Â≠∏Ë°ìËÑàÁµ°‰∏≠ÊúâÊïàË≠òÂà• LLM ÁîüÊàêÁöÑÊñáÂ≠ó„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§öÂ±§Á¥öÁ¥∞Á≤íÂ∫¶ÂÅµÊ∏¨ (MFD) Êû∂ÊßãÔºåÈÄèÈÅéÊï¥Âêà‰ΩéÂ±§Á¥öÁµêÊßã„ÄÅÈ´òÂ±§Á¥öË™ûÊÑèÂíåÊ∑±Â±§Á¥öË™ûË®ÄÁâπÂæµ‰æÜÂÅµÊ∏¨ LLM ÁîüÊàêÁöÑÊñáÂ≠óÔºåÂêåÊôÇÂ∞çË©ûÂΩô„ÄÅÊñáÊ≥ïÂíåÂè•Ê≥ïÈÄ≤Ë°åÂè•Â≠êÂ±§Á¥öÁöÑË©ï‰º∞Ôºå‰ª•ÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÂàÜÊûê„ÄÇÁÇ∫‰∫ÜÊîπÂñÑÂ∞ç LLM ÁîüÊàêÁöÑÊñáÂ≠ó‰∏≠Á¥∞ÂæÆÂ∑ÆÁï∞ÁöÑÂÅµÊ∏¨Ôºå‰∏¶Â¢ûÂº∑Â∞çÊîπÂØ´ÁöÑÂÅ•Â£ØÊÄßÔºåÊàëÂÄëÊé°Áî®‰∫ÜÂÖ©Á®Æ‰∏ªÊµÅÁöÑË¶èÈÅøÊäÄË°ì‰æÜÊîπÂØ´ÊñáÂ≠ó„ÄÇÈÄô‰∫õËÆäÈ´îÈÄ£ÂêåÂéüÂßãÊñáÂ≠óÔºåÁî®ÊñºÈÄèÈÅéÂ∞çÊØîÂ≠∏ÁøíË®ìÁ∑¥ÊñáÂ≠óÁ∑®Á¢ºÂô®ÔºåÊèêÂèñÂè•Â≠êÁöÑÈ´òÂ±§Á¥öË™ûÊÑèÁâπÂæµÔºå‰ª•ÊèêÂçáÂÅµÊ∏¨ÁöÑÊ¶ÇÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®ÂÖàÈÄ≤ÁöÑ LLM ‰æÜÂàÜÊûêÊï¥ÂÄãÊñáÂ≠ó‰∏¶ÊèêÂèñÊ∑±Â±§Á¥öË™ûË®ÄÁâπÂæµÔºåÂ¢ûÂº∑Ê®°ÂûãÊçïÊçâË§áÈõúÊ®°ÂºèÂíåÁ¥∞ÂæÆÂ∑ÆÂà´ÁöÑËÉΩÂäõÔºåÂêåÊôÇÊúâÊïàÂú∞Á¥çÂÖ•‰∏ä‰∏ãÊñáË≥áË®ä„ÄÇÂú®ÂÖ¨ÂÖ±Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåMFD Ê®°ÂûãÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºåMAE ÈÅîÂà∞ 0.1346ÔºåÊ∫ñÁ¢∫ÁéáÈÅîÂà∞ 88.56%„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁÇ∫Ê©üÊßãÂíåÂá∫ÁâàÂïÜÊèê‰æõ‰∫ÜÂÅµÊ∏¨ LLM ÁîüÊàêÁöÑÊñáÂ≠óÁöÑÊúâÊïàÊ©üÂà∂ÔºåÈôç‰Ωé‰∫Ü‰ΩúËÄÖË∫´‰ªΩÂèóÊêçÁöÑÈ¢®Èö™„ÄÇÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÁ∑®ËºØÂèØ‰ª•‰ΩøÁî®Ê®°ÂûãÁöÑÈ†êÊ∏¨‰æÜÊîπÂñÑÈ©óË≠âÂíåÈ†êÈò≤ÊäÑË•≤ÁöÑÂçîÂÆöÔºåÁ¢∫‰øùÈÅµÂÆàÊ®ôÊ∫ñ„ÄÇ

##### **Few-Shot Joint Multimodal Entity-Relation Extraction via Knowledge-Enhanced Cross-modal Prompt Model**
2410.14225v1 by Li Yuan, Yi Cai, Junsheng Huang

Joint Multimodal Entity-Relation Extraction (JMERE) is a challenging task
that aims to extract entities and their relations from text-image pairs in
social media posts. Existing methods for JMERE require large amounts of labeled
data. However, gathering and annotating fine-grained multimodal data for JMERE
poses significant challenges. Initially, we construct diverse and comprehensive
multimodal few-shot datasets fitted to the original data distribution. To
address the insufficient information in the few-shot setting, we introduce the
\textbf{K}nowledge-\textbf{E}nhanced \textbf{C}ross-modal \textbf{P}rompt
\textbf{M}odel (KECPM) for JMERE. This method can effectively address the
problem of insufficient information in the few-shot setting by guiding a large
language model to generate supplementary background knowledge. Our proposed
method comprises two stages: (1) a knowledge ingestion stage that dynamically
formulates prompts based on semantic similarity guide ChatGPT generating
relevant knowledge and employs self-reflection to refine the knowledge; (2) a
knowledge-enhanced language model stage that merges the auxiliary knowledge
with the original input and utilizes a transformer-based model to align with
JMERE's required output format. We extensively evaluate our approach on a
few-shot dataset derived from the JMERE dataset, demonstrating its superiority
over strong baselines in terms of both micro and macro F$_1$ scores.
Additionally, we present qualitative analyses and case studies to elucidate the
effectiveness of our model.

ÊëòË¶ÅÔºö<paragraph>ËÅØÂêàÂ§öÊ®°ÊÖãÂØ¶È´îÈóú‰øÇÊäΩÂèñ (JMERE) ÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÔºåÊó®Âú®ÂæûÁ§æÁæ§Â™íÈ´îÊñáÁ´†‰∏≠ÁöÑÊñáÂ≠óÂΩ±ÂÉèÂ∞ç‰∏≠ÊäΩÂèñÂØ¶È´îÂèäÂÖ∂Èóú‰øÇ„ÄÇÁèæÊúâÁöÑ JMERE ÊñπÊ≥ïÈúÄË¶ÅÂ§ßÈáèÁöÑÊ®ôÁ±§Ë≥áÊñô„ÄÇÁÑ∂ËÄåÔºåÊî∂ÈõÜÂíåÊ®ôË®ª JMERE ÁöÑÁ¥∞Á≤íÂ∫¶Â§öÊ®°ÊÖãË≥áÊñôÊúÉÂ∏∂‰æÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÊúÄÂàùÔºåÊàëÂÄëÊßãÂª∫‰∫ÜÂ§öÊ®£Âåñ‰∏îÂÖ®Èù¢ÁöÑÂ§öÊ®°ÊÖãÂ∞ëÈáèË≥áÊñôÈõÜÔºå‰ª•Á¨¶ÂêàÂéüÂßãË≥áÊñôÂàÜ‰Ωà„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Â∞ëÈáèË≥áÊñôË®≠ÂÆö‰∏≠ÁöÑË≥áË®ä‰∏çË∂≥ÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü\textbf{K}nowledge-\textbf{E}nhanced \textbf{C}ross-modal \textbf{P}rompt \textbf{M}odel (KECPM) for JMERE„ÄÇÊ≠§ÊñπÊ≥ïÂèØ‰ª•ÈÄèÈÅéÂºïÂ∞éÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁî¢ÁîüË£úÂÖÖËÉåÊôØÁü•Ë≠ò‰æÜÊúâÊïàËß£Ê±∫Â∞ëÈáèË≥áÊñôË®≠ÂÆö‰∏≠ÁöÑË≥áË®ä‰∏çË∂≥ÂïèÈ°å„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂåÖÂê´ÂÖ©ÂÄãÈöéÊÆµÔºö(1) Áü•Ë≠òÂê∏Êî∂ÈöéÊÆµÔºåÊ†πÊìöË™ûÁæ©Áõ∏‰ººÊÄßÊåáÂçóÂãïÊÖãÂà∂ÂÆöÊèêÁ§∫ÔºåÂºïÂ∞é ChatGPT Áî¢ÁîüÁõ∏ÈóúÁü•Ë≠òÔºå‰∏¶Âà©Áî®Ëá™ÊàëÂèçÁúÅ‰æÜÁ≤æÈÄ≤Áü•Ë≠òÔºõ(2) Áü•Ë≠òÂ¢ûÂº∑Ë™ûË®ÄÊ®°ÂûãÈöéÊÆµÔºåÂ∞áËºîÂä©Áü•Ë≠òËàáÂéüÂßãËº∏ÂÖ•Âêà‰ΩµÔºå‰∏¶Âà©Áî®Âü∫ÊñºËΩâÊèõÂô®ÁöÑÊ®°ÂûãËàá JMERE ÊâÄÈúÄÁöÑËº∏Âá∫Ê†ºÂºèÂ∞çÈΩä„ÄÇÊàëÂÄëÂª£Ê≥õË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Âæû JMERE Ë≥áÊñôÈõÜË°çÁîüÁöÑÂ∞ëÈáèË≥áÊñôÈõÜ‰∏äÁöÑË°®ÁèæÔºåË≠âÊòéÂÖ∂Âú®ÂæÆËßÄÂíåÂ∑®ËßÄ F$_1$ ÂàÜÊï∏ÊñπÈù¢ÈÉΩÂÑ™ÊñºÂº∑Â§ßÁöÑÂü∫Ê∫ñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫ÂÆöÊÄßÂàÜÊûêÂíåÊ°à‰æãÁ†îÁ©∂Ôºå‰ª•Èó°ÊòéÊàëÂÄëÊ®°ÂûãÁöÑÊúâÊïàÊÄß„ÄÇ</paragraph>

##### **Formal Explanations for Neuro-Symbolic AI**
2410.14219v1 by Sushmita Paul, Jinqiang Yu, Jip J. Dekker, Alexey Ignatiev, Peter J. Stuckey

Despite the practical success of Artificial Intelligence (AI), current neural
AI algorithms face two significant issues. First, the decisions made by neural
architectures are often prone to bias and brittleness. Second, when a chain of
reasoning is required, neural systems often perform poorly. Neuro-symbolic
artificial intelligence is a promising approach that tackles these (and other)
weaknesses by combining the power of neural perception and symbolic reasoning.
Meanwhile, the success of AI has made it critical to understand its behaviour,
leading to the development of explainable artificial intelligence (XAI). While
neuro-symbolic AI systems have important advantages over purely neural AI, we
still need to explain their actions, which are obscured by the interactions of
the neural and symbolic components. To address the issue, this paper proposes a
formal approach to explaining the decisions of neuro-symbolic systems. The
approach hinges on the use of formal abductive explanations and on solving the
neuro-symbolic explainability problem hierarchically. Namely, it first computes
a formal explanation for the symbolic component of the system, which serves to
identify a subset of the individual parts of neural information that needs to
be explained. This is followed by explaining only those individual neural
inputs, independently of each other, which facilitates succinctness of
hierarchical formal explanations and helps to increase the overall performance
of the approach. Experimental results for a few complex reasoning tasks
demonstrate practical efficiency of the proposed approach, in comparison to
purely neural systems, from the perspective of explanation size, explanation
time, training time, model sizes, and the quality of explanations reported.

ÊëòË¶ÅÔºöÂÑòÁÆ°‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®ÂØ¶Âãô‰∏äÁç≤ÂæóÊàêÂäüÔºåÁõÆÂâçÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑Ø AI ÊºîÁÆóÊ≥ïÈù¢Ëá®ÂÖ©ÂÄãÈáçÂ§ßÂïèÈ°å„ÄÇÈ¶ñÂÖàÔºåÁ•ûÁ∂ìÁ∂≤Ë∑ØÊû∂ÊßãÂÅöÂá∫ÁöÑÊ±∫Á≠ñÂ∏∏Â∏∏ÂÆπÊòìÂá∫ÁèæÂÅèÂ∑ÆÂíåËÑÜÂº±ÊÄß„ÄÇÂÖ∂Ê¨°ÔºåÁï∂ÈúÄË¶ÅÊé®ÁêÜÈèàÊôÇÔºåÁ•ûÁ∂ìÁ≥ªÁµ±Â∏∏Â∏∏Ë°®Áèæ‰∏ç‰Ω≥„ÄÇÁ•ûÁ∂ìÁ¨¶Ëôü‰∫∫Â∑•Êô∫ÊÖßÊòØ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÔºåÂÆÉÁµêÂêà‰∫ÜÁ•ûÁ∂ìÊÑüÁü•ÂíåÁ¨¶ËôüÊé®ÁêÜÁöÑÂäõÈáèÔºå‰æÜËß£Ê±∫ÈÄô‰∫õÔºàÂíåÂÖ∂‰ªñÔºâÂº±Èªû„ÄÇÂêåÊôÇÔºåAI ÁöÑÊàêÂäü‰ΩøÂæóÁêÜËß£ÂÖ∂Ë°åÁÇ∫ËÆäÂæóËá≥ÈóúÈáçË¶ÅÔºåÈÄôÂ∞éËá¥‰∫ÜÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÁöÑÁôºÂ±ï„ÄÇÈõñÁÑ∂Á•ûÁ∂ìÁ¨¶Ëôü AI Á≥ªÁµ±ÊØîÁ¥îÁ≤πÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑Ø AI ÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÑ™Âã¢Ôºå‰ΩÜÊàëÂÄë‰ªçÁÑ∂ÈúÄË¶ÅËß£ÈáãÂÖ∂Ë°åÁÇ∫ÔºåËÄåÈÄô‰∫õË°åÁÇ∫Ë¢´Á•ûÁ∂ìÂÖÉÂíåÁ¨¶ËôüÁµÑ‰ª∂ÁöÑ‰∫§‰∫í‰ΩúÁî®ÊâÄÊé©Ëìã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊ≠£ÂºèÁöÑÊñπÊ≥ï‰æÜËß£ÈáãÁ•ûÁ∂ìÁ¨¶ËôüÁ≥ªÁµ±ÁöÑÊ±∫Á≠ñ„ÄÇË©≤ÊñπÊ≥ï‰æùË≥¥ÊñºÂΩ¢ÂºèÁ¥ÑÂåñËß£ÈáãÁöÑ‰ΩøÁî®Ôºå‰∏¶ÂàÜÂ±§Ëß£Ê±∫Á•ûÁ∂ìÁ¨¶ËôüÂèØËß£ÈáãÊÄßÂïèÈ°å„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂÆÉÈ¶ñÂÖàÁÇ∫Á≥ªÁµ±ÁöÑÁ¨¶ËôüÁµÑ‰ª∂Ë®àÁÆó‰∏ÄÂÄãÂΩ¢ÂºèËß£ÈáãÔºåÁî®ÊñºË≠òÂà•ÈúÄË¶ÅËß£ÈáãÁöÑÁ•ûÁ∂ìË≥áË®äÁöÑÂÄãÂà•ÈÉ®ÂàÜÁöÑÂ≠êÈõÜ„ÄÇÊé•ËëóÂè™Ëß£ÈáãÈÇ£‰∫õÂÄãÂà•ÁöÑÁ•ûÁ∂ìËº∏ÂÖ•ÔºåÂÆÉÂÄëÂΩºÊ≠§Áç®Á´ãÔºåÈÄôÊúâÂä©ÊñºÂàÜÂ±§ÂΩ¢ÂºèËß£ÈáãÁöÑÁ∞°ÊΩîÊÄßÔºå‰∏¶ÊúâÂä©ÊñºÊèêÈ´òÊñπÊ≥ïÁöÑÊï¥È´îÊïàËÉΩ„ÄÇÂπæÂÄãË§áÈõúÊé®ÁêÜ‰ªªÂãôÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÂØ¶ÂãôÊïàÁéáÔºåËàáÁ¥îÁ≤πÁöÑÁ•ûÁ∂ìÁ≥ªÁµ±Áõ∏ÊØîÔºåÂæûËß£ÈáãÂ§ßÂ∞è„ÄÅËß£ÈáãÊôÇÈñì„ÄÅË®ìÁ∑¥ÊôÇÈñì„ÄÅÊ®°ÂûãÂ§ßÂ∞èÂíåÂ†±ÂëäÁöÑËß£ÈáãÂìÅË≥™ÁöÑËßíÂ∫¶‰æÜÁúã„ÄÇ

##### **Paths-over-Graph: Knowledge Graph Enpowered Large Language Model Reasoning**
2410.14211v1 by Xingyu Tan, Xiaoyang Wang, Qing Liu, Xiwei Xu, Xin Yuan, Wenjie Zhang

Large Language Models (LLMs) have achieved impressive results in various
tasks but struggle with hallucination problems and lack of relevant knowledge,
especially in deep complex reasoning and knowledge-intensive tasks. Knowledge
Graphs (KGs), which capture vast amounts of facts in a structured format, offer
a reliable source of knowledge for reasoning. However, existing KG-based LLM
reasoning methods face challenges like handling multi-hop reasoning,
multi-entity questions, and effectively utilizing graph structures. To address
these issues, we propose Paths-over-Graph (PoG), a novel method that enhances
LLM reasoning by integrating knowledge reasoning paths from KGs, improving the
interpretability and faithfulness of LLM outputs. PoG tackles multi-hop and
multi-entity questions through a three-phase dynamic multi-hop path
exploration, which combines the inherent knowledge of LLMs with factual
knowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant
information from the graph exploration first and introduces efficient
three-step pruning techniques that incorporate graph structures, LLM prompting,
and a pre-trained language model (e.g., SBERT) to effectively narrow down the
explored candidate paths. This ensures all reasoning paths contain highly
relevant information captured from KGs, making the reasoning faithful and
interpretable in problem-solving. PoG innovatively utilizes graph structure to
prune the irrelevant noise and represents the first method to implement
multi-entity deep path detection on KGs for LLM reasoning tasks. Comprehensive
experiments on five benchmark KGQA datasets demonstrate PoG outperforms the
state-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an
average accuracy improvement of 18.9%. Notably, PoG with GPT-3.5-Turbo
surpasses ToG with GPT-4 by up to 23.9%.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÂèñÂæó‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÊûúÔºå‰ΩÜÂçªÈõ£‰ª•ÂÖãÊúçÂπªË¶∫ÂïèÈ°åÔºå‰∏îÁº∫‰πèÁõ∏ÈóúÁü•Ë≠òÔºåÂ∞§ÂÖ∂ÊòØÂú®Ê∑±ÂÖ•Ë§áÈõúÁöÑÊé®ÁêÜÂíåÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãô‰∏≠„ÄÇÁü•Ë≠òÂúñË≠ú (KG) ‰ª•ÁµêÊßãÂåñÊ†ºÂºèÊì∑ÂèñÂ§ßÈáè‰∫ãÂØ¶ÔºåÁÇ∫Êé®ÁêÜÊèê‰æõÂèØÈù†ÁöÑÁü•Ë≠ò‰æÜÊ∫ê„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂü∫Êñº KG ÁöÑ LLM Êé®ÁêÜÊñπÊ≥ïÈù¢Ëá®ËôïÁêÜÂ§öË∑≥Êé®ÁêÜ„ÄÅÂ§öÂØ¶È´îÂïèÈ°åÂíåÊúâÊïàÂà©Áî®ÂúñÂΩ¢ÁµêÊßãÁ≠âÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ÂúñÂΩ¢Ë∑ØÂæë (PoG)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéÊï¥Âêà‰æÜËá™ KG ÁöÑÁü•Ë≠òÊé®ÁêÜË∑ØÂæë‰æÜÂ¢ûÂº∑ LLM Êé®ÁêÜÔºåÈÄ≤ËÄåÊèêÂçá LLM Ëº∏Âá∫ÁöÑÂèØËß£ÈáãÊÄßÂíåÁúüÂØ¶ÊÄß„ÄÇPoG ÈÄèÈÅé‰∏âÈöéÊÆµÂãïÊÖãÂ§öË∑≥Ë∑ØÂæëÊé¢Á¥¢‰æÜËôïÁêÜÂ§öË∑≥ÂíåÂ§öÂØ¶È´îÂïèÈ°åÔºåÂ∞á LLM ÁöÑÂÖßÂú®Áü•Ë≠òËàá‰æÜËá™ KG ÁöÑ‰∫ãÂØ¶Áü•Ë≠òÁµêÂêàËµ∑‰æÜ„ÄÇÁÇ∫‰∫ÜÊèêÈ´òÊïàÁéáÔºåPoG È¶ñÂÖàÂæûÂúñÂΩ¢Êé¢Á¥¢‰∏≠‰øÆÂâ™‰∏çÁõ∏ÈóúÁöÑË≥áË®äÔºå‰∏¶ÂºïÂÖ•ÊúâÊïàÁöÑ‰∏âÊ≠•È©ü‰øÆÂâ™ÊäÄË°ìÔºåÁµêÂêàÂúñÂΩ¢ÁµêÊßã„ÄÅLLM ÊèêÁ§∫ÂíåÈ†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°Âûã (‰æãÂ¶Ç SBERT)Ôºå‰ª•ÊúâÊïàÁ∏ÆÂ∞èÊé¢Á¥¢ÁöÑÂÄôÈÅ∏Ë∑ØÂæë„ÄÇÈÄôÁ¢∫‰øùÊâÄÊúâÊé®ÁêÜË∑ØÂæëÈÉΩÂåÖÂê´Âæû KG ‰∏≠Êì∑ÂèñÁöÑÈ´òÂ∫¶Áõ∏ÈóúË≥áË®äÔºå‰ΩøÊé®ÁêÜÂú®ÂïèÈ°åËß£Ê±∫‰∏≠‰øùÊåÅÁúüÂØ¶‰∏îÂèØËß£Èáã„ÄÇPoG ÂâµÊñ∞Âú∞Âà©Áî®ÂúñÂΩ¢ÁµêÊßã‰æÜ‰øÆÂâ™ÁÑ°ÈóúÁöÑÈõúË®äÔºå‰∏¶È¶ñÊ¨°ÂØ¶‰ΩúÂú® KG ‰∏äÈáùÂ∞ç LLM Êé®ÁêÜ‰ªªÂãôÈÄ≤Ë°åÂ§öÂØ¶È´îÊ∑±Â∫¶Ë∑ØÂæëÂÅµÊ∏¨ÁöÑÊñπÊ≥ï„ÄÇÂú®‰∫îÂÄãÂü∫Ê∫ñ KGQA Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂÖ®Èù¢ÂØ¶È©óË≠âÊòéÔºåPoG Âú® GPT-3.5-Turbo Âíå GPT-4 ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï ToGÔºåÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ÊèêÂçá 18.9%„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊê≠Ëºâ GPT-3.5-Turbo ÁöÑ PoG ÊØîÊê≠Ëºâ GPT-4 ÁöÑ ToG È´òÂá∫ 23.9%„ÄÇ

##### **Montessori-Instruct: Generate Influential Training Data Tailored for Student Learning**
2410.14208v1 by Xiaochuan Li, Zichun Yu, Chenyan Xiong

Synthetic data has been widely used to train large language models, but their
generative nature inevitably introduces noisy, non-informative, and misleading
learning signals. In this paper, we propose Montessori-Instruct, a novel data
synthesis framework that tailors the data synthesis ability of the teacher
language model toward the student language model's learning process.
Specifically, we utilize local data influence of synthetic training data points
on students to characterize students' learning preferences. Then, we train the
teacher model with Direct Preference Optimization (DPO) to generate synthetic
data tailored toward student learning preferences. Experiments with
Llama3-8B-Instruct (teacher) and Llama3-8B (student) on Alpaca Eval and
MT-Bench demonstrate that Montessori-Instruct significantly outperforms
standard synthesis methods by 18.35\% and 46.24\% relatively. Our method also
beats data synthesized by a stronger teacher model, GPT-4o. Further analysis
confirms the benefits of teacher's learning to generate more influential
training data in the student's improved learning, the advantages of local data
influence in accurately measuring student preferences, and the robustness of
Montessori-Instruct across different student models. Our code and data are
open-sourced at https://github.com/cxcscmu/Montessori-Instruct.

ÊëòË¶ÅÔºöÂêàÊàêÊï∏ÊìöÂ∑≤Ë¢´Âª£Ê≥õÁî®ÊñºË®ìÁ∑¥Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºå‰ΩÜÂÖ∂ÁîüÊàêÊÄßË≥™‰∏çÂèØÈÅøÂÖçÂú∞ÊúÉÂºïÂÖ•ÊúâÈõúË®ä„ÄÅÁÑ°ÊÑèÁæ©‰∏îÂÖ∑ÊúâË™§Â∞éÊÄßÁöÑÂ≠∏ÁøíË®äËôü„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ Montessori-InstructÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÊï∏ÊìöÂêàÊàêÊû∂ÊßãÔºåÂÆÉÂ∞áÊïôÂ∏´Ë™ûË®ÄÊ®°ÂûãÁöÑÊï∏ÊìöÂêàÊàêËÉΩÂäõË™øÊï¥ÁÇ∫Â≠∏ÁîüË™ûË®ÄÊ®°ÂûãÁöÑÂ≠∏ÁøíÈÅéÁ®ã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂà©Áî®ÂêàÊàêË®ìÁ∑¥Êï∏ÊìöÈªûÂ∞çÂ≠∏ÁîüÁöÑÂ±ÄÈÉ®Êï∏ÊìöÂΩ±Èüø‰æÜÊèèËø∞Â≠∏ÁîüÁöÑÂ≠∏ÁøíÂÅèÂ•Ω„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî®Áõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO) Ë®ìÁ∑¥ÊïôÂ∏´Ê®°ÂûãÔºå‰ª•ÁîüÊàêÈáùÂ∞çÂ≠∏ÁîüÂ≠∏ÁøíÂÅèÂ•ΩÈáèË∫´ÊâìÈÄ†ÁöÑÂêàÊàêÊï∏Êìö„ÄÇÂú® Alpaca Eval Âíå MT-Bench ‰∏ä‰ΩøÁî® Llama3-8B-InstructÔºàÊïôÂ∏´ÔºâÂíå Llama3-8BÔºàÂ≠∏ÁîüÔºâÈÄ≤Ë°åÁöÑÂØ¶È©óË°®ÊòéÔºåMontessori-Instruct ÊòéÈ°ØÂÑ™ÊñºÊ®ôÊ∫ñÂêàÊàêÊñπÊ≥ïÔºåÂàÜÂà•È´òÂá∫ 18.35% Âíå 46.24%„ÄÇÊàëÂÄëÁöÑÊ®°Âûã‰πüÂÑ™ÊñºÁî±Êõ¥Âº∑Â§ßÁöÑÊïôÂ∏´Ê®°Âûã GPT-4o ÂêàÊàêÁöÑÊï∏Êìö„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûêË≠âÂØ¶‰∫ÜÊïôÂ∏´Â≠∏ÁøíÂ∞çÁîüÊàêÊõ¥ÊúâÂΩ±ÈüøÂäõÁöÑË®ìÁ∑¥Êï∏Êìö‰ª•ÊîπÂñÑÂ≠∏ÁîüÂ≠∏ÁøíÁöÑÂ•ΩËôï„ÄÅÂ±ÄÈÉ®Êï∏ÊìöÂΩ±ÈüøÂú®Ê∫ñÁ¢∫Ë°°ÈáèÂ≠∏ÁîüÂÅèÂ•ΩÊñπÈù¢ÁöÑÂÑ™ÈªûÔºå‰ª•Âèä Montessori-Instruct Âú®‰∏çÂêåÂ≠∏ÁîüÊ®°Âûã‰∏≠ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÊï∏ÊìöÂú® https://github.com/cxcscmu/Montessori-Instruct ÈñãÊ∫ê„ÄÇ

##### **MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations**
2410.14204v1 by Vishal Vivek Saley, Goonjan Saha, Rocktim Jyoti Das, Dinesh Raghu, Mausam

Medical task-oriented dialogue systems can assist doctors by collecting
patient medical history, aiding in diagnosis, or guiding treatment selection,
thereby reducing doctor burnout and expanding access to medical services.
However, doctor-patient dialogue datasets are not readily available, primarily
due to privacy regulations. Moreover, existing datasets lack comprehensive
annotations involving medical slots and their different attributes, such as
symptoms and their onset, progression, and severity. These comprehensive
annotations are crucial for accurate diagnosis. Finally, most existing datasets
are non-English, limiting their utility for the larger research community.
  In response, we introduce MediTOD, a new dataset of doctor-patient dialogues
in English for the medical history-taking task. Collaborating with doctors, we
devise a questionnaire-based labeling scheme tailored to the medical domain.
Then, medical professionals create the dataset with high-quality comprehensive
annotations, capturing medical slots and their attributes. We establish
benchmarks in supervised and few-shot settings on MediTOD for natural language
understanding, policy learning, and natural language generation subtasks,
evaluating models from both TOD and biomedical domains. We make MediTOD
publicly available for future research.

ÊëòË¶ÅÔºöÈÜ´Â≠∏‰ªªÂãôÂ∞éÂêëÂ∞çË©±Á≥ªÁµ±ÂèØ‰ª•ÂçîÂä©ÈÜ´ÁîüÊî∂ÈõÜÁóÖÊÇ£ÁóÖÊ≠∑„ÄÅÂçîÂä©Ë®∫Êñ∑ÊàñÂºïÂ∞éÊ≤ªÁôÇÈÅ∏ÊìáÔºåÂæûËÄåÊ∏õÂ∞ëÈÜ´ÁîüÁöÑÂÄ¶ÊÄ†ÊÑü‰∏¶Êì¥Â§ßÁç≤ÂæóÈÜ´ÁôÇÊúçÂãôÁöÑÊ©üÊúÉ„ÄÇÁÑ∂ËÄåÔºåÈÜ´ÁîüËàáÁóÖÊÇ£Â∞çË©±ÁöÑË≥áÊñôÈõÜ‰∏¶‰∏çÂÆπÊòìÂèñÂæóÔºåÈÄô‰∏ªË¶ÅÊòØÂõ†ÁÇ∫Èö±ÁßÅÊ≥ïË¶è„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÁöÑË≥áÊñôÈõÜÁº∫‰πèÂåÖÂê´ÈÜ´ÁôÇÊèíÊßΩÂèäÂÖ∂‰∏çÂêåÂ±¨ÊÄßÁöÑÂÖ®Èù¢Ë®ªËß£Ôºå‰æãÂ¶ÇÁóáÁãÄÂèäÂÖ∂Áôº‰Ωú„ÄÅÈÄ≤Â±ïÂíåÂö¥ÈáçÁ®ãÂ∫¶„ÄÇÈÄô‰∫õÂÖ®Èù¢ÁöÑË®ªËß£Â∞çÊñºÊ∫ñÁ¢∫Ë®∫Êñ∑Ëá≥ÈóúÈáçË¶Å„ÄÇÊúÄÂæåÔºåÂ§ßÂ§öÊï∏ÁèæÊúâÁöÑË≥áÊñôÈõÜÈÉΩÊòØÈùûËã±Ë™ûÁöÑÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂ∞çÊõ¥Â§ßÁ†îÁ©∂Á§æÁæ§ÁöÑÊïàÁî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MediTODÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞ÁöÑËã±ÊñáÈÜ´ÁîüËàáÁóÖÊÇ£Â∞çË©±Ë≥áÊñôÈõÜÔºåÁî®ÊñºÁóÖÊ≠∑Êî∂ÈõÜ‰ªªÂãô„ÄÇÊàëÂÄëËàáÈÜ´ÁîüÂêà‰ΩúÔºåË®≠Ë®à‰∫Ü‰∏ÄÂÄãÈáùÂ∞çÈÜ´ÁôÇÈ†òÂüüÈáèË∫´ÊâìÈÄ†ÁöÑÂü∫ÊñºÂïèÂç∑ÁöÑÊ®ôË®òÊñπÊ°à„ÄÇÁÑ∂ÂæåÔºåÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°‰ΩøÁî®È´òÂìÅË≥™ÁöÑÂÖ®Èù¢Ë®ªËß£Âª∫Á´ãË≥áÊñôÈõÜÔºåÊì∑ÂèñÈÜ´ÁôÇÊèíÊßΩÂèäÂÖ∂Â±¨ÊÄß„ÄÇÊàëÂÄëÂú® MediTOD ‰∏äÂª∫Á´ã‰∫ÜÁõ£Áù£ÂºèÂíåÂ∞ëÈáèÊ®£Êú¨Ë®≠ÂÆöÁöÑÂü∫Ê∫ñÔºåÁî®ÊñºËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£„ÄÅÁ≠ñÁï•Â≠∏ÁøíÂíåËá™ÁÑ∂Ë™ûË®ÄÁîüÊàêÂ≠ê‰ªªÂãôÔºåË©ï‰º∞‰æÜËá™ TOD ÂíåÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÂÖ¨Èñã MediTOD ‰ª•‰æõÊú™‰æÜÁ†îÁ©∂‰ΩøÁî®„ÄÇ

##### **Rationale Behind Essay Scores: Enhancing S-LLM's Multi-Trait Essay Scoring with Rationale Generated by LLMs**
2410.14202v1 by SeongYeub Chu, JongWoo Kim, Bryan Wong, MunYong Yi

Existing automated essay scoring (AES) has solely relied on essay text
without using explanatory rationales for the scores, thereby forgoing an
opportunity to capture the specific aspects evaluated by rubric indicators in a
fine-grained manner. This paper introduces Rationale-based Multiple Trait
Scoring (RMTS), a novel approach for multi-trait essay scoring that integrates
prompt-engineering-based large language models (LLMs) with a fine-tuning-based
essay scoring model using a smaller large language model (S-LLM). RMTS uses an
LLM-based trait-wise rationale generation system where a separate LLM agent
generates trait-specific rationales based on rubric guidelines, which the
scoring model uses to accurately predict multi-trait scores. Extensive
experiments on benchmark datasets, including ASAP, ASAP++, and Feedback Prize,
show that RMTS significantly outperforms state-of-the-art models and vanilla
S-LLMs in trait-specific scoring. By assisting quantitative assessment with
fine-grained qualitative rationales, RMTS enhances the trait-wise reliability,
providing partial explanations about essays.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑËá™ÂãïÂåñË´ñÊñáË©ïÂàÜÔºàAESÔºâÂÉÖ‰æùË≥¥Ë´ñÊñáÊñáÊú¨ÔºåËÄå‰∏ç‰ΩøÁî®Ë©ïÂàÜÁöÑË™™ÊòéÊÄß‰æùÊìöÔºåÂæûËÄåÊîæÊ£Ñ‰∫Ü‰ª•Á¥∞Á∑ªÁöÑÊñπÂºèÊì∑ÂèñË©ïÂàÜÊåáÊ®ô‰∏≠Ë©ï‰º∞ÁöÑÁâπÂÆöÈù¢ÂêëÁöÑÊ©üÊúÉ„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫ÜÂü∫Êñº‰æùÊìöÁöÑÂ§öÁâπË≥™Ë©ïÂàÜÔºàRMTSÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂ§öÁâπË≥™Ë´ñÊñáË©ïÂàÜÁöÑÊñ∞ÊñπÊ≥ïÔºåÂÆÉÂ∞áÂü∫ÊñºÊèêÁ§∫Â∑•Á®ãÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâËàá‰ΩøÁî®ËºÉÂ∞èÂûãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàS-LLMÔºâÁöÑÂü∫ÊñºÂæÆË™øÁöÑË´ñÊñáË©ïÂàÜÊ®°ÂûãÊï¥ÂêàÂú®‰∏ÄËµ∑„ÄÇRMTS ‰ΩøÁî®Âü∫Êñº LLM ÁöÑÁâπË≥™ÊòéÊô∫‰æùÊìöÁîüÊàêÁ≥ªÁµ±ÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÁç®Á´ãÁöÑ LLM ‰ª£ÁêÜÊ†πÊìöË©ïÂàÜÊ∫ñÂâáÁîüÊàêÁâπÂÆöÁâπË≥™ÁöÑ‰æùÊìöÔºåË©ïÂàÜÊ®°Âûã‰ΩøÁî®ÈÄô‰∫õ‰æùÊìöÊ∫ñÁ¢∫È†êÊ∏¨Â§öÁâπË≥™Ë©ïÂàÜ„ÄÇÂú®Âü∫Ê∫ñË≥áÊñôÈõÜÔºàÂåÖÊã¨ ASAP„ÄÅASAP++ Âíå Feedback PrizeÔºâ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåRMTS Âú®ÁâπÂÆöÁâπË≥™Ë©ïÂàÜÊñπÈù¢È°ØËëóÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÂíåÈ¶ôËçâ S-LLM„ÄÇÈÄöÈÅé‰ΩøÁî®Á¥∞Á∑ªÁöÑÂÆöÊÄß‰æùÊìöÂçîÂä©ÈáèÂåñË©ï‰º∞ÔºåRMTS Â¢ûÂº∑‰∫ÜÁâπË≥™ÊòéÊô∫ÁöÑÂèØÈù†ÊÄßÔºåÊèê‰æõ‰∫ÜÈóúÊñºË´ñÊñáÁöÑÈÉ®ÂàÜË™™Êòé„ÄÇ

##### **E3D-GPT: Enhanced 3D Visual Foundation for Medical Vision-Language Model**
2410.14200v1 by Haoran Lai, Zihang Jiang, Qingsong Yao, Rongsheng Wang, Zhiyang He, Xiaodong Tao, Wei Wei, Weifu Lv, S. Kevin Zhou

The development of 3D medical vision-language models holds significant
potential for disease diagnosis and patient treatment. However, compared to 2D
medical images, 3D medical images, such as CT scans, face challenges related to
limited training data and high dimension, which severely restrict the progress
of 3D medical vision-language models. To address these issues, we collect a
large amount of unlabeled 3D CT data and utilize self-supervised learning to
construct a 3D visual foundation model for extracting 3D visual features. Then,
we apply 3D spatial convolutions to aggregate and project high-level image
features, reducing computational complexity while preserving spatial
information. We also construct two instruction-tuning datasets based on BIMCV-R
and CT-RATE to fine-tune the 3D vision-language model. Our model demonstrates
superior performance compared to existing methods in report generation, visual
question answering, and disease diagnosis. Code and data will be made publicly
available soon.

ÊëòË¶ÅÔºö3D ÈÜ´Â≠∏Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁöÑÁôºÂ±ïÂ∞çÊñºÁñæÁóÖË®∫Êñ∑ÂíåÊÇ£ËÄÖÊ≤ªÁôÇÂÖ∑ÊúâÈáçË¶ÅÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåËàá 2D ÈÜ´Â≠∏ÂΩ±ÂÉèÁõ∏ÊØîÔºå3D ÈÜ´Â≠∏ÂΩ±ÂÉèÔºà‰æãÂ¶Ç CT ÊéÉÊèèÔºâÈù¢Ëá®ËëóË®ìÁ∑¥Ë≥áÊñôÊúâÈôêÂíåÁ∂≠Â∫¶È´òÁ≠âÊåëÊà∞ÔºåÈÄôÂö¥ÈáçÈôêÂà∂‰∫Ü 3D ÈÜ´Â≠∏Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁöÑÈÄ≤Â±ï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊî∂ÈõÜ‰∫ÜÂ§ßÈáèÁöÑÊú™Ê®ôË®ò 3D CT Ë≥áÊñôÔºå‰∏¶Âà©Áî®Ëá™Áõ£Áù£Â≠∏Áøí‰æÜÊßãÂª∫‰∏ÄÂÄã 3D Ë¶ñË¶∫Âü∫Á§éÊ®°Âûã‰ª•ÊèêÂèñ 3D Ë¶ñË¶∫ÁâπÂæµ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊáâÁî® 3D Á©∫ÈñìÂç∑Á©ç‰æÜÂåØÁ∏ΩÂíåÊäïÂΩ±È´òÈöéÂΩ±ÂÉèÁâπÂæµÔºåÂú®‰øùÁïôÁ©∫ÈñìË≥áË®äÁöÑÂêåÊôÇÈôç‰ΩéÈÅãÁÆóË§áÈõúÂ∫¶„ÄÇÊàëÂÄëÈÇÑÊ†πÊìö BIMCV-R Âíå CT-RATE Âª∫Êßã‰∫ÜÂÖ©ÂÄãÊåá‰ª§Ë™øÊï¥Ë≥áÊñôÈõÜÔºå‰ª•ÂæÆË™ø 3D Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã„ÄÇËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®Â†±ÂëäÁîüÊàê„ÄÅË¶ñË¶∫ÂïèÁ≠îÂíåÁñæÁóÖË®∫Êñ∑ÊñπÈù¢Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂ∞áÂæàÂø´ÂÖ¨Èñã„ÄÇ

##### **Supervised Chain of Thought**
2410.14198v1 by Xiang Zhang, Dujian Ding

Large Language Models (LLMs) have revolutionized natural language processing
and hold immense potential for advancing Artificial Intelligence. However, the
core architecture of most mainstream LLMs -- the Transformer -- has inherent
limitations in computational depth, rendering them theoretically incapable of
solving many reasoning tasks that demand increasingly deep computations. Chain
of Thought (CoT) prompting has emerged as a technique to address these
architectural limitations, as evidenced by several theoretical studies. It
offers a promising approach to solving complex reasoning tasks that were
previously beyond the capabilities of these models. Despite its successes, CoT
and its variants (such as Tree of Thought, Graph of Thought, etc.) rely on a
"one-prompt-for-all" approach, using a single prompt structure (e.g., "think
step by step") for a wide range of tasks -- from counting and sorting to
solving mathematical and algorithmic problems. This approach poses significant
challenges for models to generate the correct reasoning steps, as the model
must navigate through a vast prompt template space to find the appropriate
template for each task. In this work, we build upon previous theoretical
analyses of CoT to demonstrate how the one-prompt-for-all approach can
negatively affect the computability of LLMs. We partition the solution search
space into two: the prompt space and the answer space. Our findings show that
task-specific supervision is essential for navigating the prompt space
accurately and achieving optimal performance. Through experiments with
state-of-the-art LLMs, we reveal a gap in reasoning performance when
supervision is applied versus when it is not.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæπÂ∫ïÊîπËÆä‰∫ÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÔºå‰∏¶ÂÖ∑ÂÇô‰øÉÈÄ≤‰∫∫Â∑•Êô∫ÊÖßÁôºÂ±ïÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏‰∏ªÊµÅ LLM ÁöÑÊ†∏ÂøÉÊû∂ÊßãÔºàTransformerÔºâÂú®Ë®àÁÆóÊ∑±Â∫¶ÊñπÈù¢ÊúâÂÖ∂ÂÖßÂú®ÈôêÂà∂ÔºåÁêÜË´ñ‰∏äÁÑ°Ê≥ïËß£Ê±∫Ë®±Â§öÈúÄË¶ÅË∂ä‰æÜË∂äÊ∑±ÂÖ•Ë®àÁÆóÁöÑÊé®ÁêÜ‰ªªÂãô„ÄÇÊÄùÁ∂≠Èèà (CoT) ÊèêÁ§∫Â∑≤ÊàêÁÇ∫Ëß£Ê±∫ÈÄô‰∫õÊû∂ÊßãÈôêÂà∂ÁöÑ‰∏ÄÁ®ÆÊäÄË°ìÔºåÈÄôÂ∑≤Áî±ÂπæÈ†ÖÁêÜË´ñÁ†îÁ©∂Ë≠âÂØ¶„ÄÇÂÆÉÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊñπÊ≥ï‰æÜËß£Ê±∫Ë§áÈõúÁöÑÊé®ÁêÜ‰ªªÂãôÔºåÈÄô‰∫õ‰ªªÂãô‰ª•ÂâçË∂ÖÂá∫‰∫ÜÈÄô‰∫õÊ®°ÂûãÁöÑËÉΩÂäõ„ÄÇÂÑòÁÆ°ÂèñÂæó‰∫ÜÊàêÂäüÔºåCoT ÂèäÂÖ∂ËÆäÈ´îÔºà‰æãÂ¶ÇÊÄùÁ∂≠Ê®π„ÄÅÊÄùÁ∂≠ÂúñÁ≠âÔºâ‰æùË≥¥Êñº„Äå‰∏ÄÊèêÁ§∫ÈÅ©Áî®ÊâÄÊúâ„ÄçÁöÑÊñπÊ≥ïÔºåÂ∞çÂêÑÁ®Æ‰ªªÂãôÔºàÂæûË®àÊï∏ÂíåÊéíÂ∫èÂà∞Ëß£Ê±∫Êï∏Â≠∏ÂíåÊºîÁÆóÊ≥ïÂïèÈ°åÔºâ‰ΩøÁî®ÂñÆ‰∏ÄÁöÑÊèêÁ§∫ÁµêÊßãÔºà‰æãÂ¶ÇÔºå„ÄåÈÄêÊ≠•ÊÄùËÄÉ„ÄçÔºâ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∞çÊ®°ÂûãÁî¢ÁîüÊ≠£Á¢∫ÁöÑÊé®ÁêÜÊ≠•È©üÊßãÊàê‰∫ÜÈáçÂ§ßÊåëÊà∞ÔºåÂõ†ÁÇ∫Ê®°ÂûãÂøÖÈ†àÂú®Âª£Ê≥õÁöÑÊèêÁ§∫ÁØÑÊú¨Á©∫Èñì‰∏≠Â∞éËà™ÔºåÊâçËÉΩÁÇ∫ÊØèÂÄã‰ªªÂãôÊâæÂà∞ÈÅ©Áï∂ÁöÑÁØÑÊú¨„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂª∫Á´ãÂú® CoT ÂÖàÂâçÁöÑÁêÜË´ñÂàÜÊûê‰πã‰∏äÔºåË™™Êòé„Äå‰∏ÄÊèêÁ§∫ÈÅ©Áî®ÊâÄÊúâ„ÄçÁöÑÊñπÊ≥ïÂ¶Ç‰ΩïÂ∞ç LLM ÁöÑÂèØË®àÁÆóÊÄßÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÊàëÂÄëÂ∞áËß£ÁöÑÊêúÂ∞ãÁ©∫ÈñìÂàÜÁÇ∫ÂÖ©ÈÉ®ÂàÜÔºöÊèêÁ§∫Á©∫ÈñìÂíåÁ≠îÊ°àÁ©∫Èñì„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÁâπÂÆöÊñº‰ªªÂãôÁöÑÁõ£Áù£Â∞çÊñºÊ∫ñÁ¢∫Â∞éËà™ÊèêÁ§∫Á©∫Èñì‰∏¶ÂØ¶ÁèæÊúÄ‰Ω≥ÊïàËÉΩËá≥ÈóúÈáçË¶Å„ÄÇÈÄèÈÅé‰ΩøÁî®ÊúÄÂÖàÈÄ≤ÁöÑ LLM ÈÄ≤Ë°åÂØ¶È©óÔºåÊàëÂÄëÊè≠Á§∫‰∫ÜÂú®ÊáâÁî®Áõ£Áù£ËàáÊú™ÊáâÁî®Áõ£Áù£ÊôÇÊé®ÁêÜÊïàËÉΩÁöÑÂ∑ÆË∑ù„ÄÇ

##### **Speciesism in Natural Language Processing Research**
2410.14194v1 by Masashi Takeshita, Rafal Rzepka

Natural Language Processing (NLP) research on AI Safety and social bias in AI
has focused on safety for humans and social bias against human minorities.
However, some AI ethicists have argued that the moral significance of nonhuman
animals has been ignored in AI research. Therefore, the purpose of this study
is to investigate whether there is speciesism, i.e., discrimination against
nonhuman animals, in NLP research. First, we explain why nonhuman animals are
relevant in NLP research. Next, we survey the findings of existing research on
speciesism in NLP researchers, data, and models and further investigate this
problem in this study. The findings of this study suggest that speciesism
exists within researchers, data, and models, respectively. Specifically, our
survey and experiments show that (a) among NLP researchers, even those who
study social bias in AI, do not recognize speciesism or speciesist bias; (b)
among NLP data, speciesist bias is inherent in the data annotated in the
datasets used to evaluate NLP models; (c) OpenAI GPTs, recent NLP models,
exhibit speciesist bias by default. Finally, we discuss how we can reduce
speciesism in NLP research.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Âú® AI ÂÆâÂÖ®ÊÄßÂíå AI ‰∏≠ÁöÑÁ§æÊúÉÂÅèË¶ãÁöÑÁ†îÁ©∂Ôºå‰∏ÄÁõ¥Â∞àÊ≥®Êñº‰∫∫È°ûÂÆâÂÖ®ÂíåÈáùÂ∞ç‰∫∫È°ûÂ∞ëÊï∏Áæ§È´îÁöÑÁ§æÊúÉÂÅèË¶ã„ÄÇÁÑ∂ËÄåÔºå‰∏Ä‰∫õ AI ÂÄ´ÁêÜÂ≠∏ÂÆ∂Ë™çÁÇ∫ÔºåÂú® AI Á†îÁ©∂‰∏≠ÂøΩË¶ñ‰∫ÜÈùû‰∫∫È°ûÂãïÁâ©ÁöÑÈÅìÂæ∑ÊÑèÁæ©„ÄÇÂõ†Ê≠§ÔºåÊú¨Á†îÁ©∂ÁöÑÁõÆÁöÑÊòØË™øÊü• NLP Á†îÁ©∂‰∏≠ÊòØÂê¶Â≠òÂú®Áâ©Á®ÆÊ≠ßË¶ñÔºåÂç≥Â∞çÈùû‰∫∫È°ûÂãïÁâ©ÁöÑÊ≠ßË¶ñ„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëËß£ÈáãÁÇ∫‰ªÄÈ∫ºÈùû‰∫∫È°ûÂãïÁâ©Ëàá NLP Á†îÁ©∂Áõ∏Èóú„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëË™øÊü•ÁèæÊúâÁ†îÁ©∂Â∞ç NLP Á†îÁ©∂‰∫∫Âì°„ÄÅË≥áÊñôÂíåÊ®°Âûã‰∏≠Áâ©Á®ÆÊ≠ßË¶ñÁöÑÁôºÁèæÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Âú®Êú¨Á†îÁ©∂‰∏≠Ë™øÊü•Ê≠§ÂïèÈ°å„ÄÇÊú¨Á†îÁ©∂ÁöÑÁôºÁèæË°®ÊòéÔºåÁâ©Á®ÆÊ≠ßË¶ñÂ≠òÂú®ÊñºÁ†îÁ©∂‰∫∫Âì°„ÄÅË≥áÊñôÂíåÊ®°Âûã‰∏≠„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁöÑË™øÊü•ÂíåÂØ¶È©óË°®ÊòéÔºö(a) Âú® NLP Á†îÁ©∂‰∫∫Âì°‰∏≠ÔºåÂç≥‰ΩøÊòØÈÇ£‰∫õÁ†îÁ©∂ AI ‰∏≠ÁöÑÁ§æÊúÉÂÅèË¶ãÁöÑ‰∫∫Ôºå‰πü‰∏çÊâøË™çÁâ©Á®ÆÊ≠ßË¶ñÊàñÁâ©Á®ÆÊ≠ßË¶ñÂÅèË¶ãÔºõ(b) Âú® NLP Ë≥áÊñô‰∏≠ÔºåÁâ©Á®ÆÊ≠ßË¶ñÂÅèË¶ãÂ≠òÂú®ÊñºÁî®ÊñºË©ï‰º∞ NLP Ê®°ÂûãÁöÑË≥áÊñôÈõÜ‰∏≠Ê®ôË®ªÁöÑË≥áÊñô‰∏≠Ôºõ(c) OpenAI GPTÔºåÊúÄËøëÁöÑ NLP Ê®°ÂûãÔºåÈ†êË®≠Ë°®ÁèæÂá∫Áâ©Á®ÆÊ≠ßË¶ñÂÅèË¶ã„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñÂ¶Ç‰ΩïÊ∏õÂ∞ë NLP Á†îÁ©∂‰∏≠ÁöÑÁâ©Á®ÆÊ≠ßË¶ñ„ÄÇ

##### **MetaAlign: Align Large Language Models with Diverse Preferences during Inference Time**
2410.14184v1 by Mozhi Zhang, Pengyu Wang, Chenkun Tan, Mianqiu Huang, Dong Zhang, Yaqian Zhou, Xipeng Qiu

Large Language Models (LLMs) acquire extensive knowledge and remarkable
abilities from extensive text corpora, making them powerful tools for various
applications. To make LLMs more usable, aligning them with human preferences is
essential. Existing alignment techniques, such as Reinforcement Learning from
Human Feedback (RLHF) and Direct Preference Optimization (DPO), typically embed
predefined preferences directly within the model's parameters. These methods,
however, often result in a static alignment that can not account for the
diversity of human preferences in practical applications. In response to this
challenge, we propose an effective method, \textbf{MetaAlign}, which aims to
help LLMs dynamically align with various explicit or implicit preferences
specified at inference time. Experimental results show that LLMs optimized on
our meticulously constructed MetaAlign Dataset can effectively align with any
preferences specified at the inference stage, validating the feasibility of
MetaAlign. We hope that our work can provide some insights into the alignment
of language models.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæûÂ§ßÈáèÁöÑÊñáÂ≠óË™ûÊñôÂ∫´‰∏≠Áç≤ÂèñÂª£Ê≥õÁöÑÁü•Ë≠òÂíåÈùûÂá°ÁöÑËÉΩÂäõÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂêÑÁ®ÆÊáâÁî®Á®ãÂ∫èÁöÑÂº∑Â§ßÂ∑•ÂÖ∑„ÄÇÁÇ∫‰∫Ü‰Ωø LLM Êõ¥ÊòìÊñº‰ΩøÁî®ÔºåËÆìÂÆÉÂÄëËàá‰∫∫È°ûÂÅèÂ•Ω‰øùÊåÅ‰∏ÄËá¥Ëá≥ÈóúÈáçË¶Å„ÄÇÁèæÊúâÁöÑÂ∞çÈΩäÊäÄË°ìÔºå‰æãÂ¶Ç‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF) ÂíåÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO)ÔºåÈÄöÂ∏∏ÊúÉÂ∞áÈ†êÂÆöÁæ©ÁöÑÂÅèÂ•ΩÁõ¥Êé•ÂµåÂÖ•Ê®°ÂûãÂèÉÊï∏‰∏≠„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÊúÉÂ∞éËá¥ÈùúÊÖãÂ∞çÈΩäÔºåÁÑ°Ê≥ïË™™ÊòéÂØ¶ÈöõÊáâÁî®‰∏≠‰∫∫È°ûÂÅèÂ•ΩÁöÑÂ§öÊ®£ÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂç≥ \textbf{MetaAlign}ÔºåÊó®Âú®Âπ´Âä© LLM ÂãïÊÖãÂú∞ËàáÂú®Êé®ÁêÜÊôÇÊåáÂÆöÁöÑ‰∏çÂêåÈ°ØÂºèÊàñÈö±ÂºèÂÅèÂ•Ω‰øùÊåÅ‰∏ÄËá¥„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÂú®ÊàëÂÄëÁ≤æÂøÉÊßãÂª∫ÁöÑ MetaAlign Êï∏ÊìöÈõÜ‰∏äÂÑ™ÂåñÁöÑ LLM ÂèØ‰ª•ÊúâÊïàÂú∞ËàáÊé®ÁêÜÈöéÊÆµÊåáÂÆöÁöÑ‰ªª‰ΩïÂÅèÂ•Ω‰øùÊåÅ‰∏ÄËá¥ÔºåÈ©óË≠â‰∫Ü MetaAlign ÁöÑÂèØË°åÊÄß„ÄÇÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑÁ†îÁ©∂ÊàêÊûúËÉΩÁÇ∫Ë™ûË®ÄÊ®°ÂûãÁöÑÂ∞çÈΩäÊèê‰æõ‰∏Ä‰∫õË¶ãËß£„ÄÇ

##### **LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs**
2410.14182v1 by Yujun Zhou, Jingdong Yang, Kehan Guo, Pin-Yu Chen, Tian Gao, Werner Geyer, Nuno Moniz, Nitesh V Chawla, Xiangliang Zhang

Laboratory accidents pose significant risks to human life and property,
underscoring the importance of robust safety protocols. Despite advancements in
safety training, laboratory personnel may still unknowingly engage in unsafe
practices. With the increasing reliance on large language models (LLMs) for
guidance in various fields, including laboratory settings, there is a growing
concern about their reliability in critical safety-related decision-making.
Unlike trained human researchers, LLMs lack formal lab safety education,
raising questions about their ability to provide safe and accurate guidance.
Existing research on LLM trustworthiness primarily focuses on issues such as
ethical compliance, truthfulness, and fairness but fails to fully cover
safety-critical real-world applications, like lab safety. To address this gap,
we propose the Laboratory Safety Benchmark (LabSafety Bench), a comprehensive
evaluation framework based on a new taxonomy aligned with Occupational Safety
and Health Administration (OSHA) protocols. This benchmark includes 765
multiple-choice questions verified by human experts, assessing LLMs and vision
language models (VLMs) performance in lab safety contexts. Our evaluations
demonstrate that while GPT-4o outperforms human participants, it is still prone
to critical errors, highlighting the risks of relying on LLMs in
safety-critical environments. Our findings emphasize the need for specialized
benchmarks to accurately assess the trustworthiness of LLMs in real-world
safety applications.

ÊëòË¶ÅÔºöÂØ¶È©óÂÆ§‰∫ãÊïÖÂ∞ç‰∫∫È°ûÁîüÂëΩÂíåË≤°Áî¢ÊßãÊàêÈáçÂ§ßÈ¢®Èö™Ôºå
Âº∑Ë™ø‰∫ÜÂÅ•ÂÖ®ÂÆâÂÖ®Ë¶èÁ®ãÁöÑÈáçË¶ÅÊÄß„ÄÇÂÑòÁÆ°ÂÆâÂÖ®Ë®ìÁ∑¥ÈÄ≤Ê≠•‰∫ÜÔºå
ÂØ¶È©óÂÆ§‰∫∫Âì°ÂèØËÉΩ‰ªç‰∏çÁü•‰∏çË¶∫Âú∞Âæû‰∫ã‰∏çÂÆâÂÖ®ÁöÑ
ÂØ¶Âãô„ÄÇÈö®ËëóÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑ‰æùË≥¥Êó•ÁõäÂ¢ûÂä†Ôºå
Âú®ÂêÑÁ®ÆÈ†òÂüüÔºàÂåÖÊã¨ÂØ¶È©óÂÆ§Áí∞Â¢ÉÔºâ‰∏≠Â∞ãÊ±ÇÊåáÂ∞éÔºå
‰∫∫ÂÄëË∂ä‰æÜË∂äÊìîÂøÉÂÆÉÂÄëÂú®ÈóúÈçµÂÆâÂÖ®Áõ∏ÈóúÊ±∫Á≠ñÂà∂ÂÆö‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇ
ËàáÂèóÈÅéË®ìÁ∑¥ÁöÑ‰∫∫È°ûÁ†îÁ©∂Âì°‰∏çÂêåÔºåLLM Áº∫‰πèÊ≠£Ë¶èÁöÑÂØ¶È©óÂÆ§ÂÆâÂÖ®ÊïôËÇ≤Ôºå
ÂºïÁôº‰∫Ü‰∫∫ÂÄëÂ∞çÂÆÉÂÄëÊèê‰æõÂÆâÂÖ®‰∏îÊ∫ñÁ¢∫ÊåáÂ∞éÁöÑËÉΩÂäõÁöÑË≥™Áñë„ÄÇ
ÁèæÊúâÁöÑ LLM ÂèØ‰ø°Â∫¶Á†îÁ©∂‰∏ªË¶ÅÈóúÊ≥®ÈÅìÂæ∑ÂêàË¶èÊÄß„ÄÅÁúüÂØ¶ÊÄßÂíåÂÖ¨Âπ≥ÊÄßÁ≠âÂïèÈ°åÔºå
‰ΩÜÊú™ËÉΩÂÆåÂÖ®Ê∂µËìãÂÆâÂÖ®Ëá≥‰∏äÁöÑÂØ¶ÈöõÊáâÁî®Ôºå‰æãÂ¶ÇÂØ¶È©óÂÆ§ÂÆâÂÖ®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºå
ÊàëÂÄëÊèêÂá∫‰∫ÜÂØ¶È©óÂÆ§ÂÆâÂÖ®Âü∫Ê∫ñ (LabSafety Bench)ÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑ
Ë©ï‰º∞Ê°ÜÊû∂ÔºåÂü∫ÊñºËàáËÅ∑Ê•≠ÂÆâÂÖ®ÂíåÂÅ•Â∫∑ÁÆ°ÁêÜÂ±Ä (OSHA) Ë¶èÁ®ãÁõ∏Á¨¶ÁöÑÊñ∞ÂàÜÈ°ûÊ≥ï„ÄÇÈÄôÂÄãÂü∫Ê∫ñÂåÖÊã¨ 765
ÂÄã‰∫∫È°ûÂ∞àÂÆ∂È©óË≠âÁöÑÂ§öÈÅ∏È°åÔºåË©ï‰º∞ LLM ÂíåË¶ñË¶∫
Ë™ûË®ÄÊ®°Âûã (VLM) Âú®ÂØ¶È©óÂÆ§ÂÆâÂÖ®ÊÉÖÂ¢É‰∏≠ÁöÑË°®Áèæ„ÄÇÊàëÂÄëÁöÑË©ï‰º∞
Ë°®ÊòéÔºåÂÑòÁÆ° GPT-4o ÂÑ™Êñº‰∫∫È°ûÂèÉËàáËÄÖÔºå‰ΩÜÂÆÉ‰ªçÁÑ∂ÂÆπÊòìÁôºÁîü
ÈóúÈçµÈåØË™§ÔºåÁ™ÅÈ°Ø‰∫ÜÂú®
ÂÆâÂÖ®Ëá≥‰∏äÁöÑÁí∞Â¢É‰∏≠‰æùË≥¥ LLM ÁöÑÈ¢®Èö™„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫Ü
ÈúÄË¶ÅÂ∞àÈñÄÁöÑÂü∫Ê∫ñ‰æÜÊ∫ñÁ¢∫Ë©ï‰º∞ LLM Âú®ÂØ¶Èöõ
ÂÆâÂÖ®ÊáâÁî®‰∏≠ÁöÑÂèØ‰ø°Â∫¶„ÄÇ

##### **XForecast: Evaluating Natural Language Explanations for Time Series Forecasting**
2410.14180v1 by Taha Aksu, Chenghao Liu, Amrita Saha, Sarah Tan, Caiming Xiong, Doyen Sahoo

Time series forecasting aids decision-making, especially for stakeholders who
rely on accurate predictions, making it very important to understand and
explain these models to ensure informed decisions. Traditional explainable AI
(XAI) methods, which underline feature or temporal importance, often require
expert knowledge. In contrast, natural language explanations (NLEs) are more
accessible to laypeople. However, evaluating forecast NLEs is difficult due to
the complex causal relationships in time series data. To address this, we
introduce two new performance metrics based on simulatability, assessing how
well a human surrogate can predict model forecasts using the explanations.
Experiments show these metrics differentiate good from poor explanations and
align with human judgments. Utilizing these metrics, we further evaluate the
ability of state-of-the-art large language models (LLMs) to generate
explanations for time series data, finding that numerical reasoning, rather
than model size, is the main factor influencing explanation quality.

ÊëòË¶ÅÔºöÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨ÊúâÂä©ÊñºÊ±∫Á≠ñÂà∂ÂÆöÔºåÁâπÂà•ÊòØÂ∞çÊñº‰æùË≥¥Ê∫ñÁ¢∫È†êÊ∏¨ÁöÑÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÔºåÂõ†Ê≠§‰∫ÜËß£ÂíåËß£ÈáãÈÄô‰∫õÊ®°Âûã‰ª•Á¢∫‰øùÊòéÊô∫ÁöÑÊ±∫Á≠ñÈùûÂ∏∏ÈáçË¶Å„ÄÇÂº∑Ë™øÁâπÂæµÊàñÊôÇÈñìÈáçË¶ÅÊÄßÁöÑÂÇ≥Áµ±ÂèØËß£Èáã AI (XAI) ÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂ∞àÂÆ∂Áü•Ë≠ò„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåËá™ÁÑ∂Ë™ûË®ÄËß£Èáã (NLE) Êõ¥ÂÆπÊòìËÆìÂ§ñË°å‰∫∫ÁêÜËß£„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊôÇÈñìÂ∫èÂàóË≥áÊñô‰∏≠Ë§áÈõúÁöÑÂõ†ÊûúÈóú‰øÇÔºåË©ï‰º∞È†êÊ∏¨ NLE ÂæàÂõ∞Èõ£„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖ©ÂÄãÂü∫ÊñºÂèØÊ®°Êì¨ÊÄßÁöÑÊñ∞ÊïàËÉΩÊåáÊ®ôÔºåË©ï‰º∞‰∫∫È°û‰ª£ÁêÜ‰∫∫‰ΩøÁî®Ëß£ÈáãÈ†êÊ∏¨Ê®°ÂûãÈ†êÊ∏¨ÁöÑÁ®ãÂ∫¶„ÄÇÂØ¶È©óË°®ÊòéÔºåÈÄô‰∫õÊåáÊ®ôÂèØ‰ª•ÂçÄÂàÜÂ•ΩËß£ÈáãÂíåÂ∑ÆËß£ÈáãÔºå‰∏¶‰∏îËàá‰∫∫È°ûÁöÑÂà§Êñ∑‰∏ÄËá¥„ÄÇÂà©Áî®ÈÄô‰∫õÊåáÊ®ôÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë©ï‰º∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÂ§ßË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫ÊôÇÈñìÂ∫èÂàóË≥áÊñôÁîüÊàêËß£ÈáãÁöÑËÉΩÂäõÔºåÁôºÁèæÊï∏Â≠óÊé®ÁêÜÔºåËÄå‰∏çÊòØÊ®°ÂûãÂ§ßÂ∞èÔºåÊòØÂΩ±ÈüøËß£ÈáãÂìÅË≥™ÁöÑ‰∏ªË¶ÅÂõ†Á¥†„ÄÇ

##### **MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart Problems**
2410.14179v1 by Zifeng Zhu, Mengzhao Jia, Zhihan Zhang, Lang Li, Meng Jiang

Multimodal Large Language Models (MLLMs) have demonstrated impressive
abilities across various tasks, including visual question answering and chart
comprehension, yet existing benchmarks for chart-related tasks fall short in
capturing the complexity of real-world multi-chart scenarios. Current
benchmarks primarily focus on single-chart tasks, neglecting the multi-hop
reasoning required to extract and integrate information from multiple charts,
which is essential in practical applications. To fill this gap, we introduce
MultiChartQA, a benchmark that evaluates MLLMs' capabilities in four key areas:
direct question answering, parallel question answering, comparative reasoning,
and sequential reasoning. Our evaluation of a wide range of MLLMs reveals
significant performance gaps compared to humans. These results highlight the
challenges in multi-chart comprehension and the potential of MultiChartQA to
drive advancements in this field. Our code and data are available at
https://github.com/Zivenzhu/Multi-chart-QA

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (M L L M) Â∑≤Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºåÂèØÂü∑Ë°åÂêÑÈ†Ö‰ªªÂãôÔºåÂåÖÊã¨Ë¶ñË¶∫ÂïèÁ≠îÂíåÂúñË°®ÁêÜËß£ÔºåÁÑ∂ËÄåÁèæÊúâÁöÑÂúñË°®Áõ∏Èóú‰ªªÂãôÂü∫Ê∫ñ‰∏¶Êú™ÂÆåÂÖ®ÊéåÊè°ÁúüÂØ¶‰∏ñÁïåÂ§öÂúñË°®ÊÉÖÂ¢ÉÁöÑË§áÈõúÊÄß„ÄÇÁõÆÂâçÁöÑÂü∫Ê∫ñ‰∏ªË¶ÅËëóÈáçÊñºÂñÆÂúñË°®‰ªªÂãôÔºåÂøΩÁï•‰∫ÜÂæûÂ§öÂÄãÂúñË°®‰∏≠Êì∑ÂèñÂíåÊï¥ÂêàË≥áË®äÊâÄÈúÄÁöÑÂ§öÈáçË∑≥Ë∫çÊé®ÁêÜÔºåÈÄôÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠Ëá≥ÈóúÈáçË¶Å„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÁº∫Âè£ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MultiChartQAÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞ M L L M Âú®ÂõõÂÄãÈóúÈçµÈ†òÂüüÁöÑËÉΩÂäõÔºöÁõ¥Êé•ÂïèÁ≠î„ÄÅÂπ≥Ë°åÂïèÁ≠î„ÄÅÊØîËºÉÊé®ÁêÜÂíåÈ†ÜÂ∫èÊé®ÁêÜ„ÄÇÊàëÂÄëÂ∞çÂêÑÁ®Æ M L L M ÁöÑË©ï‰º∞È°ØÁ§∫ÔºåËàá‰∫∫È°ûÁõ∏ÊØîÔºåÊïàËÉΩÊúâÈ°ØËëóÂ∑ÆË∑ù„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÂ§öÂúñË°®ÁêÜËß£ÁöÑÊåëÊà∞Ôºå‰ª•Âèä MultiChartQA Êé®ÂãïÊ≠§È†òÂüüÈÄ≤Ê≠•ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÂú® https://github.com/Zivenzhu/Multi-chart-QA ÂèñÂæó

##### **LLM The Genius Paradox: A Linguistic and Math Expert's Struggle with Simple Word-based Counting Problems**
2410.14166v1 by Nan Xu, Xuezhe Ma

Interestingly, LLMs yet struggle with some basic tasks that humans find
trivial to handle, e.g., counting the number of character r's in the word
"strawberry". There are several popular conjectures (e.g., tokenization,
architecture and training data) regarding the reason for deficiency of LLMs in
simple word-based counting problems, sharing the similar belief that such
failure stems from model pretraining hence probably inevitable during
deployment. In this paper, we carefully design multiple evaluation settings to
investigate validity of prevalent conjectures. Meanwhile, we measure
transferability of advanced mathematical and coding reasoning capabilities from
specialized LLMs to simple counting tasks. Although specialized LLMs suffer
from counting problems as well, we find conjectures about inherent deficiency
of LLMs invalid and further seek opportunities to elicit knowledge and
capabilities from LLMs that are beneficial to counting tasks. Compared with
strategies such as finetuning and in-context learning that are commonly adopted
to enhance performance on new or challenging tasks, we show that engaging
reasoning is the most robust and efficient way to help LLMs better perceive
tasks with more accurate responses.
  We hope our conjecture validation design could provide insights into the
study of future critical failure modes of LLMs. Based on challenges in
transferring advanced capabilities to much simpler tasks, we call for more
attention to model capability acquisition and evaluation. We also highlight the
importance of cultivating consciousness of "reasoning before responding" during
model pretraining.

ÊëòË¶ÅÔºöÊúâË∂£ÁöÑÊòØÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®‰∏Ä‰∫õÂØπ‰∫∫Á±ªÊù•ËØ¥ÂæàÂÆπÊòìÂ§ÑÁêÜÁöÑÂü∫Êú¨‰ªªÂä°‰∏ä‰ªçÊúâÂõ∞ÈöæÔºå‰æãÂ¶ÇËÆ°ÁÆóÂçïËØç‚Äústrawberry‚Äù‰∏≠Â≠óÁ¨¶rÁöÑÊï∞Èáè„ÄÇÂØπ‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®ÁÆÄÂçïÁöÑÂü∫‰∫éÂçïËØçÁöÑËÆ°Êï∞ÈóÆÈ¢ò‰∏≠Ë°®Áé∞‰∏ç‰Ω≥ÁöÑÂéüÂõ†ÔºåÊúâÂá†ÁßçÊµÅË°åÁöÑÁåúÊÉ≥Ôºà‰æãÂ¶ÇÔºåÊ†áËÆ∞Âåñ„ÄÅÊû∂ÊûÑÂíåËÆ≠ÁªÉÊï∞ÊçÆÔºâÔºåËøô‰∫õÁåúÊÉ≥ÈÉΩËÆ§‰∏∫ËøôÁßçÂ§±Ë¥•Ê∫ê‰∫éÊ®°ÂûãÈ¢ÑËÆ≠ÁªÉÔºåÂõ†Ê≠§Âú®ÈÉ®ÁΩ≤ËøáÁ®ã‰∏≠ÂèØËÉΩÊòØ‰∏çÂèØÈÅøÂÖçÁöÑ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨‰ªîÁªÜËÆæËÆ°‰∫ÜÂ§ö‰∏™ËØÑ‰º∞ËÆæÁΩÆÊù•Ë∞ÉÊü•ÊµÅË°åÁåúÊÉ≥ÁöÑÊúâÊïàÊÄß„ÄÇÂêåÊó∂ÔºåÊàë‰ª¨ÊµãÈáè‰∫ÜÈ´òÁ∫ßÊï∞Â≠¶ÂíåÁºñÁ†ÅÊé®ÁêÜËÉΩÂäõ‰ªé‰∏ìÈó®ÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂà∞ÁÆÄÂçïËÆ°Êï∞‰ªªÂä°ÁöÑÂèØËøÅÁßªÊÄß„ÄÇÂ∞ΩÁÆ°‰∏ìÈó®ÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰πüÂ≠òÂú®ËÆ°Êï∞ÈóÆÈ¢òÔºå‰ΩÜÊàë‰ª¨ÂèëÁé∞ÂÖ≥‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂõ∫ÊúâÁº∫Èô∑ÁöÑÁåúÊÉ≥ÊòØÊó†ÊïàÁöÑÔºåÂπ∂Ëøõ‰∏ÄÊ≠•ÂØªÊ±ÇÊú∫‰ºö‰ªéÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰∏≠Ëé∑ÂèñÂØπËÆ°Êï∞‰ªªÂä°ÊúâÁõäÁöÑÁü•ËØÜÂíåËÉΩÂäõ„ÄÇ‰∏éÈÄöÂ∏∏ÈááÁî®Êù•Â¢ûÂº∫Êñ∞‰ªªÂä°ÊàñÂÖ∑ÊúâÊåëÊàòÊÄß‰ªªÂä°ÁöÑÊÄßËÉΩÁöÑÂæÆË∞ÉÂíå‰∏ä‰∏ãÊñáÂ≠¶‰π†Á≠âÁ≠ñÁï•Áõ∏ÊØîÔºåÊàë‰ª¨Ë°®ÊòéÔºåÂèÇ‰∏éÊé®ÁêÜÊòØÂ∏ÆÂä©Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊõ¥Â•ΩÂú∞ÊÑüÁü•‰ªªÂä°Âπ∂ÂÅöÂá∫Êõ¥ÂáÜÁ°ÆÂìçÂ∫îÁöÑÊúÄÁ®≥ÂÅ•„ÄÅÊúÄÊúâÊïàÁöÑÊñπÊ≥ï„ÄÇÊàë‰ª¨Â∏åÊúõÊàë‰ª¨ÁöÑÁåúÊÉ≥È™åËØÅËÆæËÆ°ÂèØ‰ª•‰∏∫Á†îÁ©∂Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊú™Êù•ÁöÑÂÖ≥ÈîÆÊïÖÈöúÊ®°ÂºèÊèê‰æõËßÅËß£„ÄÇÂü∫‰∫éÂú®Â∞ÜÈ´òÁ∫ßËÉΩÂäõËΩ¨ÁßªÂà∞Êõ¥ÁÆÄÂçïÁöÑ‰ªªÂä°‰∏≠ÈÅáÂà∞ÁöÑÊåëÊàòÔºåÊàë‰ª¨ÂëºÂêÅÊõ¥Â§öÂú∞ÂÖ≥Ê≥®Ê®°ÂûãËÉΩÂäõÁöÑËé∑ÂèñÂíåËØÑ‰º∞„ÄÇÊàë‰ª¨ËøòÂº∫Ë∞ÉÂú®Ê®°ÂûãÈ¢ÑËÆ≠ÁªÉÊúüÈó¥ÂüπÂÖª‚ÄúÂú®ÂìçÂ∫î‰πãÂâçÊé®ÁêÜ‚ÄùÊÑèËØÜÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Automated Genre-Aware Article Scoring and Feedback Using Large Language Models**
2410.14165v1 by Chihang Wang, Yuxin Dong, Zhenhong Zhang, Ruotong Wang, Shuo Wang, Jiajing Chen

This paper focuses on the development of an advanced intelligent article
scoring system that not only assesses the overall quality of written work but
also offers detailed feature-based scoring tailored to various article genres.
By integrating the pre-trained BERT model with the large language model
Chat-GPT, the system gains a deep understanding of both the content and
structure of the text, enabling it to provide a thorough evaluation along with
targeted suggestions for improvement. Experimental results demonstrate that
this system outperforms traditional scoring methods across multiple public
datasets, particularly in feature-based assessments, offering a more accurate
reflection of the quality of different article types. Moreover, the system
generates personalized feedback to assist users in enhancing their writing
skills, underscoring the potential and practical value of automated scoring
technologies in educational contexts.

ÊëòË¶ÅÔºöÊú¨ÊñáÈáçÈªûÂú®ÊñºÈñãÁôº‰∏ÄÁ®ÆÂÖàÈÄ≤ÁöÑÊô∫ÊÖßÊñáÁ´†Ë©ïÂàÜÁ≥ªÁµ±ÔºåÊ≠§Á≥ªÁµ±‰∏çÂÉÖË©ï‰º∞ÂØ´‰Ωú‰ΩúÂìÅÁöÑÊï¥È´îÂìÅË≥™ÔºåÈÇÑËÉΩÊèê‰æõÈáùÂ∞çÂêÑÁ®ÆÊñáÁ´†È°ûÂûãÈáèË∫´ÊâìÈÄ†ÁöÑ„ÄÅÂü∫ÊñºÁâπËâ≤ÁöÑË©≥Á¥∞Ë©ïÂàÜ„ÄÇÈÄèÈÅéÂ∞áÈ†êÂÖàË®ìÁ∑¥ÁöÑ BERT Ê®°ÂûãËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã Chat-GPT Êï¥ÂêàÔºåÊ≠§Á≥ªÁµ±Ê∑±ÂÖ•‰∫ÜËß£ÊñáÊú¨ÁöÑÂÖßÂÆπËàáÁµêÊßãÔºåËÉΩÊèê‰æõÂÖ®Èù¢ÁöÑË©ï‰º∞Ôºå‰ª•ÂèäÊúâÈáùÂ∞çÊÄßÁöÑÊîπÈÄ≤Âª∫Ë≠∞„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊ≠§Á≥ªÁµ±Âú®Â§öÂÄãÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏≠ÁöÑË°®ÁèæÂÑ™ÊñºÂÇ≥Áµ±Ë©ïÂàÜÊñπÊ≥ïÔºåÁâπÂà•ÊòØÂú®Âü∫ÊñºÁâπËâ≤ÁöÑË©ïÈáè‰∏≠ÔºåËÉΩÊõ¥Ê∫ñÁ¢∫Âú∞ÂèçÊò†‰∏çÂêåÊñáÁ´†È°ûÂûãÁöÑÂìÅË≥™„ÄÇÊ≠§Â§ñÔºåÊ≠§Á≥ªÁµ±ÊúÉÁî¢ÁîüÂÄã‰∫∫ÂåñÁöÑÂõûÈ•ãÔºåÂçîÂä©‰ΩøÁî®ËÄÖÊèêÂçáÂØ´‰ΩúÊäÄÂ∑ßÔºåÂº∑Ë™øËá™ÂãïË©ïÂàÜÊäÄË°ìÂú®ÊïôËÇ≤Áí∞Â¢É‰∏≠ÁöÑÊΩõÂäõÂíåÂØ¶Áî®ÂÉπÂÄº„ÄÇ

##### **Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning**
2410.14157v1 by Jiacheng Ye, Jiahui Gao, Shansan Gong, Lin Zheng, Xin Jiang, Zhenguo Li, Lingpeng Kong

Autoregressive language models, despite their impressive capabilities,
struggle with complex reasoning and long-term planning tasks. We introduce
discrete diffusion models as a novel solution to these challenges. Through the
lens of subgoal imbalance, we demonstrate how diffusion models effectively
learn difficult subgoals that elude autoregressive approaches. We propose
Multi-granularity Diffusion Modeling (MDM), which prioritizes subgoals based on
difficulty during learning. On complex tasks like Countdown, Sudoku, and
Boolean Satisfiability Problems, MDM significantly outperforms autoregressive
models without using search techniques. For instance, MDM achieves 91.5\% and
100\% accuracy on Countdown and Sudoku, respectively, compared to 45.8\% and
20.7\% for autoregressive models. Our work highlights the potential of
diffusion-based approaches in advancing AI capabilities for sophisticated
language understanding and problem-solving tasks.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ëá™Ëø¥Ê≠∏Ë™ûË®ÄÊ®°ÂûãÂäüËÉΩÂº∑Â§ßÔºå
‰ΩÜÂú®Ë§áÈõúÊé®ÁêÜÂíåÈï∑ÊúüË¶èÂäÉ‰ªªÂãô‰∏ä‰ªçÊúâÂõ∞Èõ£„ÄÇÊàëÂÄëÊèêÂá∫Èõ¢Êï£Êì¥Êï£Ê®°Âûã‰ΩúÁÇ∫Ëß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÁöÑÊñ∞Á©éÊñπÊ≥ï„ÄÇÈÄèÈÅéÂ≠êÁõÆÊ®ôÂ§±Ë°°ÁöÑËßÄÈªûÔºåÊàëÂÄëÂ±ïÁ§∫Êì¥Êï£Ê®°ÂûãÂ¶Ç‰ΩïÊúâÊïàÂ≠∏ÁøíËá™Ëø¥Ê≠∏ÊñπÊ≥ïÁÑ°Ê≥ïÈÅîÊàêÁöÑÂõ∞Èõ£Â≠êÁõÆÊ®ô„ÄÇÊàëÂÄëÊèêÂá∫Â§öÁ≤íÂ∫¶Êì¥Êï£Ê®°Âûã (MDM)ÔºåÂú®Â≠∏ÁøíÈÅéÁ®ã‰∏≠Ê†πÊìöÈõ£Â∫¶Â∞çÂ≠êÁõÆÊ®ôÈÄ≤Ë°åÂÑ™ÂÖàÊéíÂ∫è„ÄÇÂú®ÂÄíÊï∏„ÄÅÊï∏Áç®ÂíåÂ∏ÉÊûóÂèØÊªøË∂≥ÊÄßÂïèÈ°åÁ≠âË§áÈõú‰ªªÂãô‰∏≠ÔºåMDM Âú®‰∏ç‰ΩøÁî®ÊêúÂ∞ãÊäÄË°ìÁöÑÊÉÖÊ≥Å‰∏ãÊòéÈ°ØÂÑ™ÊñºËá™Ëø¥Ê≠∏Ê®°Âûã„ÄÇ‰æãÂ¶ÇÔºåMDM Âú®ÂÄíÊï∏ÂíåÊï∏Áç®‰∏≠ÁöÑÊ∫ñÁ¢∫ÁéáÂàÜÂà•ÈÅîÂà∞ 91.5% Âíå 100%ÔºåËÄåËá™Ëø¥Ê≠∏Ê®°ÂûãÁöÑÊ∫ñÁ¢∫ÁéáÂàÜÂà•ÁÇ∫ 45.8% Âíå 20.7%„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Á™ÅÈ°Ø‰∫ÜÂü∫ÊñºÊì¥Êï£ÁöÑÊñπÊ≥ïÂú®ÊèêÂçá AI ËÉΩÂäõ‰ª•ÈÄ≤Ë°åÁ≤æÂØÜÁöÑË™ûË®ÄÁêÜËß£ÂíåÂïèÈ°åËß£Ê±∫‰ªªÂãôÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Towards Faithful Natural Language Explanations: A Study Using Activation Patching in Large Language Models**
2410.14155v1 by Wei Jie Yeo, Ranjan Satapthy, Erik Cambria

Large Language Models (LLMs) are capable of generating persuasive Natural
Language Explanations (NLEs) to justify their answers. However, the
faithfulness of these explanations should not be readily trusted at face value.
Recent studies have proposed various methods to measure the faithfulness of
NLEs, typically by inserting perturbations at the explanation or feature level.
We argue that these approaches are neither comprehensive nor correctly designed
according to the established definition of faithfulness. Moreover, we highlight
the risks of grounding faithfulness findings on out-of-distribution samples. In
this work, we leverage a causal mediation technique called activation patching,
to measure the faithfulness of an explanation towards supporting the explained
answer. Our proposed metric, Causal Faithfulness quantifies the consistency of
causal attributions between explanations and the corresponding model outputs as
the indicator of faithfulness. We experimented across models varying from 2B to
27B parameters and found that models that underwent alignment tuning tend to
produce more faithful and plausible explanations. We find that Causal
Faithfulness is a promising improvement over existing faithfulness tests by
taking into account the model's internal computations and avoiding out of
distribution concerns that could otherwise undermine the validity of
faithfulness assessments. We release the code in
\url{https://github.com/wj210/Causal-Faithfulness}

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÂ§†Áî¢ÁîüÊúâË™™ÊúçÂäõÁöÑËá™ÁÑ∂Ë™ûË®ÄËß£Èáã (NLE) ‰æÜË≠âÊòéÂÖ∂Á≠îÊ°à„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õËß£ÈáãÁöÑÂø†ÂØ¶Â∫¶‰∏çÊáâËºïÊòìÂú∞Ë¢´Ë¶ñÁÇ∫Ë°®Èù¢ÂÉπÂÄº„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÊèêÂá∫‰∫ÜÂêÑÁ®ÆÊñπÊ≥ï‰æÜË°°Èáè NLE ÁöÑÂø†ÂØ¶Â∫¶ÔºåÈÄöÂ∏∏ÊòØÈÄèÈÅéÂú®Ëß£ÈáãÊàñÁâπÂæµÂ±§Á¥öÊèíÂÖ•ÊìæÂãï„ÄÇÊàëÂÄëË™çÁÇ∫ÈÄô‰∫õÊñπÊ≥ïÊó¢‰∏çÂÖ®Èù¢Ôºå‰πü‰∏çÁ¨¶ÂêàÂø†ÂØ¶Â∫¶ÁöÑÊó¢ÂÆöÂÆöÁæ©ËÄåÊ≠£Á¢∫Ë®≠Ë®à„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂº∑Ë™øÂ∞áÂø†ÂØ¶Â∫¶ÁôºÁèæÂª∫Á´ãÂú®ÂàÜÂ∏ÉÂ§ñÊ®£Êú¨‰∏äÁöÑÈ¢®Èö™„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂà©Áî®Âõ†Êûú‰∏≠‰ªãÊäÄË°ìÔºàÁ®±ÁÇ∫ÊøÄÊ¥ª‰øÆË£úÔºâÔºå‰æÜË°°ÈáèËß£ÈáãÂ∞çÊîØÊåÅÊâÄËß£ÈáãÁ≠îÊ°àÁöÑÂø†ÂØ¶Â∫¶„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊåáÊ®ô„ÄåÂõ†ÊûúÂø†ÂØ¶Â∫¶„ÄçÈáèÂåñ‰∫ÜËß£ÈáãËàáÂ∞çÊáâÊ®°ÂûãËº∏Âá∫‰πãÈñìÂõ†ÊûúÊ≠∏Âõ†ÁöÑ‰∏ÄËá¥ÊÄßÔºå‰ΩúÁÇ∫Âø†ÂØ¶Â∫¶ÁöÑÊåáÊ®ô„ÄÇÊàëÂÄëÂú®ÂèÉÊï∏Âæû 2B Âà∞ 27B ËÆäÂåñ‰∏çÂêåÁöÑÊ®°Âûã‰∏≠ÈÄ≤Ë°å‰∫ÜÂØ¶È©óÔºåÁôºÁèæÁ∂ìÈÅéÊØîÂ∞çË™øÊï¥ÁöÑÊ®°ÂûãÂæÄÂæÄÊúÉÁî¢ÁîüÊõ¥Âø†ÂØ¶‰∏îÂêàÁêÜÁöÑËß£Èáã„ÄÇÊàëÂÄëÁôºÁèæÔºåÂõ†ÊûúÂø†ÂØ¶Â∫¶ÈÄèÈÅéËÄÉÈáèÊ®°ÂûãÁöÑÂÖßÈÉ®ÈÅãÁÆó‰∏¶ÈÅøÂÖçÂèØËÉΩÊúÉÊêçÂÆ≥Âø†ÂØ¶Â∫¶Ë©ï‰º∞ÁöÑÊúâÊïàÊÄßÁöÑÂàÜÂ∏ÉÂ§ñÂïèÈ°åÔºåÂ∞çÁèæÊúâÁöÑÂø†ÂØ¶Â∫¶Ê∏¨Ë©¶‰æÜË™™ÊòØ‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊîπÈÄ≤„ÄÇÊàëÂÄëÂú®\url{https://github.com/wj210/Causal-Faithfulness}‰∏≠ÈáãÂá∫Á®ãÂºèÁ¢º

##### **RA-BLIP: Multimodal Adaptive Retrieval-Augmented Bootstrapping Language-Image Pre-training**
2410.14154v1 by Muhe Ding, Yang Ma, Pengda Qin, Jianlong Wu, Yuhong Li, Liqiang Nie

Multimodal Large Language Models (MLLMs) have recently received substantial
interest, which shows their emerging potential as general-purpose models for
various vision-language tasks. MLLMs involve significant external knowledge
within their parameters; however, it is challenging to continually update these
models with the latest knowledge, which involves huge computational costs and
poor interpretability. Retrieval augmentation techniques have proven to be
effective plugins for both LLMs and MLLMs. In this study, we propose multimodal
adaptive Retrieval-Augmented Bootstrapping Language-Image Pre-training
(RA-BLIP), a novel retrieval-augmented framework for various MLLMs. Considering
the redundant information within vision modality, we first leverage the
question to instruct the extraction of visual information through interactions
with one set of learnable queries, minimizing irrelevant interference during
retrieval and generation. Besides, we introduce a pre-trained multimodal
adaptive fusion module to achieve question text-to-multimodal retrieval and
integration of multimodal knowledge by projecting visual and language
modalities into a unified semantic space. Furthermore, we present an Adaptive
Selection Knowledge Generation (ASKG) strategy to train the generator to
autonomously discern the relevance of retrieved knowledge, which realizes
excellent denoising performance. Extensive experiments on open multimodal
question-answering datasets demonstrate that RA-BLIP achieves significant
performance and surpasses the state-of-the-art retrieval-augmented models.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (MLLM) ËøëÊù•Â§áÂèóÂÖ≥Ê≥®ÔºåÊòæÁ§∫ÂÖ∂‰Ωú‰∏∫ÂêÑÁßçËßÜËßâËØ≠Ë®Ä‰ªªÂä°ÈÄöÁî®Ê®°ÂûãÁöÑÊñ∞ÂÖ¥ÊΩúÂäõ„ÄÇMLLM Âú®ÂÖ∂ÂèÇÊï∞‰∏≠ÂåÖÂê´Â§ßÈáèÂ§ñÈÉ®Áü•ËØÜÔºõÁÑ∂ËÄåÔºåÊåÅÁª≠‰ΩøÁî®ÊúÄÊñ∞Áü•ËØÜÊõ¥Êñ∞Ëøô‰∫õÊ®°ÂûãÂÖ∑ÊúâÊåëÊàòÊÄßÔºåËøôÊ∂âÂèäÂ∑®Â§ßÁöÑËÆ°ÁÆóÊàêÊú¨ÂíåËæÉÂ∑ÆÁöÑÂèØËß£ÈáäÊÄß„ÄÇÊ£ÄÁ¥¢Â¢ûÂº∫ÊäÄÊúØÂ∑≤Ë¢´ËØÅÊòéÊòØ LLM Âíå MLLM ÁöÑÊúâÊïàÊèí‰ª∂„ÄÇÂú®ËøôÈ°πÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÂ§öÊ®°ÊÄÅËá™ÈÄÇÂ∫îÊ£ÄÁ¥¢Â¢ûÂº∫ÂºïÂØºËØ≠Ë®ÄÂõæÂÉèÈ¢ÑËÆ≠ÁªÉ (RA-BLIP)Ôºå‰∏Ä‰∏™ÈíàÂØπÂêÑÁßç MLLM ÁöÑÊñ∞È¢ñÊ£ÄÁ¥¢Â¢ûÂº∫Ê°ÜÊû∂„ÄÇËÄÉËôëÂà∞ËßÜËßâÊ®°ÊÄÅ‰∏≠ÁöÑÂÜó‰Ωô‰ø°ÊÅØÔºåÊàë‰ª¨È¶ñÂÖàÂà©Áî®ÈóÆÈ¢òÈÄöËøá‰∏é‰∏ÄÁªÑÂèØÂ≠¶‰π†Êü•ËØ¢ÁöÑ‰∫§‰∫íÊù•ÊåáÂØºËßÜËßâ‰ø°ÊÅØÁöÑÊèêÂèñÔºåÊúÄÂ§ßÁ®ãÂ∫¶ÂáèÂ∞ëÊ£ÄÁ¥¢ÂíåÁîüÊàêËøáÁ®ã‰∏≠ÁöÑÊó†ÂÖ≥Âπ≤Êâ∞„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™È¢ÑËÆ≠ÁªÉÁöÑÂ§öÊ®°ÊÄÅËá™ÈÄÇÂ∫îËûçÂêàÊ®°ÂùóÔºåÈÄöËøáÂ∞ÜËßÜËßâÂíåËØ≠Ë®ÄÊ®°ÊÄÅÊäïÂ∞ÑÂà∞‰∏Ä‰∏™Áªü‰∏ÄËØ≠‰πâÁ©∫Èó¥‰∏≠ÔºåÂÆûÁé∞ÈóÆÈ¢òÊñáÊú¨Âà∞Â§öÊ®°ÊÄÅÊ£ÄÁ¥¢ÂíåÂ§öÊ®°ÊÄÅÁü•ËØÜÁöÑÈõÜÊàê„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Ëá™ÈÄÇÂ∫îÈÄâÊã©Áü•ËØÜÁîüÊàê (ASKG) Á≠ñÁï•Ôºå‰ª•ËÆ≠ÁªÉÁîüÊàêÂô®Ëá™‰∏ªËæ®Âà´Ê£ÄÁ¥¢Áü•ËØÜÁöÑÁõ∏ÂÖ≥ÊÄßÔºå‰ªéËÄåÂÆûÁé∞Âá∫Ëâ≤ÁöÑÂéªÂô™ÊÄßËÉΩ„ÄÇÂú®ÂºÄÊîæÁöÑÂ§öÊ®°ÊÄÅÈóÆÁ≠îÊï∞ÊçÆÈõÜ‰∏äÁöÑÂπøÊ≥õÂÆûÈ™åË°®ÊòéÔºåRA-BLIP ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÔºåÂπ∂Ë∂ÖË∂ä‰∫ÜÊúÄÂÖàËøõÁöÑÊ£ÄÁ¥¢Â¢ûÂº∫Ê®°Âûã„ÄÇ

##### **SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent**
2410.14152v1 by Jiarui Ji, Yang Li, Hongtao Liu, Zhicheng Du, Zhewei Wei, Weiran Shen, Qi Qi, Yankai Lin

Public scarce resource allocation plays a crucial role in economics as it
directly influences the efficiency and equity in society. Traditional studies
including theoretical model-based, empirical study-based and simulation-based
methods encounter limitations due to the idealized assumption of complete
information and individual rationality, as well as constraints posed by limited
available data. In this work, we propose an innovative framework, SRAP-Agent
(Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based
Agent), which integrates Large Language Models (LLMs) into economic
simulations, aiming to bridge the gap between theoretical models and real-world
dynamics. Using public housing allocation scenarios as a case study, we conduct
extensive policy simulation experiments to verify the feasibility and
effectiveness of the SRAP-Agent and employ the Policy Optimization Algorithm
with certain optimization objectives. The source code can be found in
https://github.com/jijiarui-cather/SRAPAgent_Framework

ÊëòË¶ÅÔºöÂÖ¨ÂÖ±Á®ÄÁº∫Ë≥áÊ∫êÈÖçÁΩÆÂú®Á∂ìÊøüÂ≠∏‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÂõ†ÁÇ∫ÂÆÉÁõ¥Êé•ÂΩ±ÈüøËëóÁ§æÊúÉ‰∏≠ÁöÑÊïàÁéáÂíåÂÖ¨Âπ≥„ÄÇÂÇ≥Áµ±ÁöÑÁ†îÁ©∂ÔºåÂåÖÊã¨Âü∫ÊñºÁêÜË´ñÊ®°ÂûãÁöÑÁ†îÁ©∂„ÄÅÂü∫ÊñºÂØ¶Ë≠âÁ†îÁ©∂ÁöÑÁ†îÁ©∂ÂíåÂü∫ÊñºÊ®°Êì¨ÁöÑÁ†îÁ©∂ÊñπÊ≥ïÔºåÁî±ÊñºÂ∞çÂÆåÂÖ®Ë≥áË®äÂíåÂÄã‰∫∫ÁêÜÊÄßÁöÑÁêÜÊÉ≥ÂåñÂÅáË®≠Ôºå‰ª•ÂèäÂèØÁî®Ë≥áÊñôÊúâÈôêÁöÑÈôêÂà∂ÔºåËÄåÈÅáÂà∞‰∫ÜÈôêÂà∂„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊ°ÜÊû∂ÔºåSRAP-AgentÔºà‰ΩøÁî® LLM ÁÇ∫Âü∫Á§éÁöÑ‰ª£ÁêÜÊ®°Êì¨ÂíåÊúÄ‰Ω≥ÂåñÁ®ÄÁº∫Ë≥áÊ∫êÈÖçÁΩÆÊîøÁ≠ñÔºâÔºåÂÆÉÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊï¥ÂêàÂà∞Á∂ìÊøüÊ®°Êì¨‰∏≠ÔºåÊó®Âú®ÂΩåÂêàÁêÜË´ñÊ®°ÂûãËàáÁèæÂØ¶‰∏ñÁïåÂãïÊÖã‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇ‰ΩøÁî®ÂÖ¨ÂÖ±‰ΩèÊàøÈÖçÁΩÆÊÉÖÂ¢É‰ΩúÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÊîøÁ≠ñÊ®°Êì¨ÂØ¶È©óÔºå‰ª•È©óË≠â SRAP-Agent ÁöÑÂèØË°åÊÄßÂíåÊúâÊïàÊÄßÔºå‰∏¶Êé°Áî®ÂÖ∑ÊúâÁâπÂÆöÊúÄ‰Ω≥ÂåñÁõÆÊ®ôÁöÑÊîøÁ≠ñÊúÄ‰Ω≥ÂåñÊºîÁÆóÊ≥ï„ÄÇÂéüÂßãÁ¢ºÂèØ‰ª•Âú® https://github.com/jijiarui-cather/SRAPAgent_Framework ‰∏≠ÊâæÂà∞

##### **Utilizing Large Language Models for Event Deconstruction to Enhance Multimodal Aspect-Based Sentiment Analysis**
2410.14150v1 by Xiaoyong Huang, Heli Sun, Qunshu Gao, Wenjie Huang, Ruichen Cao

With the rapid development of the internet, the richness of User-Generated
Contentcontinues to increase, making Multimodal Aspect-Based Sentiment Analysis
(MABSA) a research hotspot. Existing studies have achieved certain results in
MABSA, but they have not effectively addressed the analytical challenges in
scenarios where multiple entities and sentiments coexist. This paper
innovatively introduces Large Language Models (LLMs) for event decomposition
and proposes a reinforcement learning framework for Multimodal Aspect-based
Sentiment Analysis (MABSA-RL) framework. This framework decomposes the original
text into a set of events using LLMs, reducing the complexity of analysis,
introducing reinforcement learning to optimize model parameters. Experimental
results show that MABSA-RL outperforms existing advanced methods on two
benchmark datasets. This paper provides a new research perspective and method
for multimodal aspect-level sentiment analysis.

ÊëòË¶ÅÔºöÈö®ËëóÁ∂≤Ë∑ØÁöÑÂø´ÈÄüÁôºÂ±ïÔºå‰ΩøÁî®ËÄÖÁî¢Ë£ΩÂÖßÂÆπÁöÑË±êÂØåÂ∫¶ÊåÅÁ∫åÂ¢ûÂä†Ôºå‰ΩøÂæóÂ§öÊ®°ÊÖãÈù¢ÂêëÂü∫Á§éÊÉÖÁ∑íÂàÜÊûêÔºàMABSAÔºâÊàêÁÇ∫Á†îÁ©∂ÁÜ±Èªû„ÄÇÁèæÊúâÁ†îÁ©∂Âú® MABSA ‰∏äÂ∑≤ÂèñÂæó‰∏ÄÂÆöÊàêÊûúÔºå‰ΩÜÂ∞çÊñºÂ§öÂÄãÂØ¶È´îËàáÊÉÖÁ∑íÂÖ±Â≠òÁöÑÂ†¥ÊôØÔºåÂàÜÊûêÊåëÊà∞Â∞öÊú™ÊúâÊïàËß£Ê±∫„ÄÇÊú¨ÊñáÂâµÊñ∞Âú∞ÂºïÂÖ•Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÈÄ≤Ë°å‰∫ã‰ª∂ÂàÜËß£Ôºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÁî®ÊñºÂ§öÊ®°ÊÖãÈù¢ÂêëÂü∫Á§éÊÉÖÁ∑íÂàÜÊûêÔºàMABSA-RLÔºâÊ°ÜÊû∂ÁöÑÂº∑ÂåñÂ≠∏ÁøíÊû∂Êßã„ÄÇÊ≠§Êû∂ÊßãÂà©Áî® LLM Â∞áÂéüÂßãÊñáÂ≠óÂàÜËß£ÁÇ∫‰∏ÄÁµÑ‰∫ã‰ª∂ÔºåÈôç‰ΩéÂàÜÊûêÁöÑË§áÈõúÂ∫¶Ôºå‰∏¶ÂºïÂÖ•Âº∑ÂåñÂ≠∏Áøí‰æÜÂÑ™ÂåñÊ®°ÂûãÂèÉÊï∏„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåMABSA-RL Âú®ÂÖ©ÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÁèæÊúâÁöÑÈÄ≤ÈöéÊñπÊ≥ï„ÄÇÊú¨ÊñáÁÇ∫Â§öÊ®°ÊÖãÈù¢ÂêëÂü∫Á§éÊÉÖÁ∑íÂàÜÊûêÊèê‰æõÊñ∞ÁöÑÁ†îÁ©∂Ë¶ñËßíËàáÊñπÊ≥ï„ÄÇ

##### **Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in Vision-Language Alignment**
2410.14148v1 by Chenhang Cui, An Zhang, Yiyang Zhou, Zhaorun Chen, Gelei Deng, Huaxiu Yao, Tat-Seng Chua

The recent advancements in large language models (LLMs) and pre-trained
vision models have accelerated the development of vision-language large models
(VLLMs), enhancing the interaction between visual and linguistic modalities.
Despite their notable success across various domains, VLLMs face challenges in
modality alignment, which can lead to issues like hallucinations and unsafe
content generation. Current alignment techniques often rely on coarse feedback
and external datasets, limiting scalability and performance. In this paper, we
propose FiSAO (Fine-Grained Self-Alignment Optimization), a novel
self-alignment method that utilizes the model's own visual encoder as a
fine-grained verifier to improve vision-language alignment without the need for
additional data. By leveraging token-level feedback from the vision encoder,
FiSAO significantly improves vision-language alignment, even surpassing
traditional preference tuning methods that require additional data. Through
both theoretical analysis and experimental validation, we demonstrate that
FiSAO effectively addresses the misalignment problem in VLLMs, marking the
first instance of token-level rewards being applied to such models.

ÊëòË¶ÅÔºöËøëÊúüÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÂíåÈ¢ÑËÆ≠ÁªÉËßÜËßâÊ®°ÂûãÁöÑËøõÊ≠•Âä†ÈÄü‰∫ÜËßÜËßâËØ≠Ë®ÄÂ§ßÂûãÊ®°Âûã (VLLM) ÁöÑÂèëÂ±ïÔºåÂ¢ûÂº∫‰∫ÜËßÜËßâÂíåËØ≠Ë®ÄÊ®°ÊÄÅ‰πãÈó¥ÁöÑ‰∫íÂä®„ÄÇÂ∞ΩÁÆ°Âú®ÂêÑ‰∏™È¢ÜÂüüÂèñÂæó‰∫ÜÊòæËëóÊàêÂäüÔºå‰ΩÜ VLLM Âú®Ê®°ÊÄÅÂØπÈΩêÊñπÈù¢Èù¢‰∏¥ÊåëÊàòÔºåËøôÂèØËÉΩÂØºËá¥Âá∫Áé∞ÂπªËßâÂíå‰∏çÂÆâÂÖ®ÁöÑÂÜÖÂÆπÁîüÊàêÁ≠âÈóÆÈ¢ò„ÄÇÂΩìÂâçÁöÑÂØπÈΩêÊäÄÊúØÈÄöÂ∏∏‰æùËµñ‰∫éÁ≤óÁï•ÁöÑÂèçÈ¶àÂíåÂ§ñÈÉ®Êï∞ÊçÆÈõÜÔºåÈôêÂà∂‰∫ÜÂèØÊâ©Â±ïÊÄßÂíåÊÄßËÉΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü FiSAOÔºàÁªÜÁ≤íÂ∫¶Ëá™ÂØπÈΩê‰ºòÂåñÔºâÔºåËøôÊòØ‰∏ÄÁßçÊñ∞È¢ñÁöÑËá™ÂØπÈΩêÊñπÊ≥ïÔºåÂÆÉÂà©Áî®Ê®°ÂûãÊú¨Ë∫´ÁöÑËßÜËßâÁºñÁ†ÅÂô®‰Ωú‰∏∫ÁªÜÁ≤íÂ∫¶È™åËØÅÂô®Êù•ÊîπËøõËßÜËßâËØ≠Ë®ÄÂØπÈΩêÔºåËÄåÊó†ÈúÄÈ¢ùÂ§ñÊï∞ÊçÆ„ÄÇÈÄöËøáÂà©Áî®ËßÜËßâÁºñÁ†ÅÂô®ÁöÑÊ†áËÆ∞Á∫ßÂèçÈ¶àÔºåFiSAO ÊòæÁùÄÊîπËøõ‰∫ÜËßÜËßâËØ≠Ë®ÄÂØπÈΩêÔºåÁîöËá≥Ë∂ÖË∂ä‰∫ÜÈúÄË¶ÅÈ¢ùÂ§ñÊï∞ÊçÆÁöÑ‰º†ÁªüÂÅèÂ•ΩË∞ÉÊï¥ÊñπÊ≥ï„ÄÇÈÄöËøáÁêÜËÆ∫ÂàÜÊûêÂíåÂÆûÈ™åÈ™åËØÅÔºåÊàë‰ª¨ËØÅÊòé‰∫Ü FiSAO ÊúâÊïàÂú∞Ëß£ÂÜ≥‰∫Ü VLLM ‰∏≠ÁöÑÈîô‰ΩçÈóÆÈ¢òÔºåÊ†áÂøóÁùÄÈ¶ñÊ¨°Â∞ÜÊ†áËÆ∞Á∫ßÂ•ñÂä±Â∫îÁî®‰∫éÊ≠§Á±ªÊ®°Âûã„ÄÇ

##### **CausalChat: Interactive Causal Model Development and Refinement Using Large Language Models**
2410.14146v1 by Yanming Zhang, Akshith Kota, Eric Papenhausen, Klaus Mueller

Causal networks are widely used in many fields to model the complex
relationships between variables. A recent approach has sought to construct
causal networks by leveraging the wisdom of crowds through the collective
participation of humans. While this can yield detailed causal networks that
model the underlying phenomena quite well, it requires a large number of
individuals with domain understanding. We adopt a different approach:
leveraging the causal knowledge that large language models, such as OpenAI's
GPT-4, have learned by ingesting massive amounts of literature. Within a
dedicated visual analytics interface, called CausalChat, users explore single
variables or variable pairs recursively to identify causal relations, latent
variables, confounders, and mediators, constructing detailed causal networks
through conversation. Each probing interaction is translated into a tailored
GPT-4 prompt and the response is conveyed through visual representations which
are linked to the generated text for explanations. We demonstrate the
functionality of CausalChat across diverse data contexts and conduct user
studies involving both domain experts and laypersons.

ÊëòË¶ÅÔºöÂõ†ÊûúÁΩëÁªúÂú®ËÆ∏Â§öÈ¢ÜÂüüË¢´ÂπøÊ≥õÁî®‰∫éÂØπÂèòÈáè‰πãÈó¥ÁöÑÂ§çÊùÇÂÖ≥Á≥ªËøõË°åÂª∫Ê®°„ÄÇÊúÄËøë‰∏ÄÁßçÊñπÊ≥ïËØïÂõæÈÄöËøáÈõÜ‰ΩìÂèÇ‰∏é‰∫∫Á±ªÊù•Âà©Áî®Áæ§‰ΩìÊô∫ÊÖßÊûÑÂª∫Âõ†ÊûúÁΩëÁªú„ÄÇËôΩÁÑ∂ËøôÂèØ‰ª•‰∫ßÁîüÈùûÂ∏∏Â•ΩÁöÑÂØπÂ∫ïÂ±ÇÁé∞Ë±°ËøõË°åÂª∫Ê®°ÁöÑËØ¶ÁªÜÂõ†ÊûúÁΩëÁªúÔºå‰ΩÜÂÆÉÈúÄË¶ÅÂ§ßÈáèÂÖ∑ÊúâÈ¢ÜÂüüÁêÜËß£ÂäõÁöÑ‰∫∫Âëò„ÄÇÊàë‰ª¨ÈááÁî®‰∫Ü‰∏ÄÁßç‰∏çÂêåÁöÑÊñπÊ≥ïÔºöÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºà‰æãÂ¶Ç OpenAI ÁöÑ GPT-4ÔºâÈÄöËøáÊëÑÂèñÂ§ßÈáèÊñáÁåÆÊâÄÂ≠¶Âà∞ÁöÑÂõ†ÊûúÁü•ËØÜ„ÄÇÂú®Áß∞‰∏∫ CausalChat ÁöÑ‰∏ìÁî®ÂèØËßÜÂåñÂàÜÊûêÁïåÈù¢‰∏≠ÔºåÁî®Êà∑ÈÄíÂΩíÊé¢Á¥¢Âçï‰∏™ÂèòÈáèÊàñÂèòÈáèÂØπ‰ª•ËØÜÂà´Âõ†ÊûúÂÖ≥Á≥ª„ÄÅÊΩúÂú®ÂèòÈáè„ÄÅÊ∑∑ÊùÇÂõ†Á¥†Âíå‰∏≠‰ªãÔºåÈÄöËøáÂØπËØùÊûÑÂª∫ËØ¶ÁªÜÁöÑÂõ†ÊûúÁΩëÁªú„ÄÇÊØèÊ¨°Êé¢Êü•‰∫§‰∫íÈÉΩ‰ºöË¢´ÁøªËØëÊàê‰∏Ä‰∏™ÂÆöÂà∂ÁöÑ GPT-4 ÊèêÁ§∫ÔºåÂπ∂‰∏îÂìçÂ∫îÈÄöËøáÂèØËßÜÂåñË°®Á§∫‰º†ËææÔºåËøô‰∫õË°®Á§∫ÈìæÊé•Âà∞ÁîüÊàêÁöÑÊñáÊú¨‰ª•ËøõË°åËß£Èáä„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫Ü CausalChat Âú®‰∏çÂêåÊï∞ÊçÆ‰∏ä‰∏ãÊñá‰∏≠ÁöÑÂäüËÉΩÔºåÂπ∂ËøõË°å‰∫ÜÊ∂âÂèäÈ¢ÜÂüü‰∏ìÂÆ∂ÂíåÂ§ñË°å‰∫∫Â£´ÁöÑÁî®Êà∑Á†îÁ©∂„ÄÇ

##### **CAPE: A Chinese Dataset for Appraisal-based Emotional Generation using Large Language Models**
2410.14145v1 by June M. Liu, He Cao, Renliang Sun, Rui Wang, Yu Li, Jiaxing Zhang

Generating emotionally appropriate responses in conversations with large
language models presents a significant challenge due to the complexities of
human emotions and cognitive processes, which remain largely underexplored in
their critical role in social interactions. In this study, we introduce a
two-stage automatic data generation framework to create CAPE, a Chinese dataset
named Cognitive Appraisal theory-based Emotional corpus. This corpus
facilitates the generation of dialogues with contextually appropriate emotional
responses by accounting for diverse personal and situational factors. We
propose two tasks utilizing this dataset: emotion prediction and next utterance
prediction. Both automated and human evaluations demonstrate that agents
trained on our dataset can deliver responses that are more aligned with human
emotional expressions. Our study shows the potential for advancing emotional
expression in conversational agents, paving the way for more nuanced and
meaningful human-computer interactions.

ÊëòË¶ÅÔºöÂú®ËàáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂ∞çË©±‰∏≠Áî¢ÁîüÈÅ©Áï∂ÁöÑÊÉÖÁ∑íÂèçÊáâÔºåÁî±Êñº‰∫∫È°ûÊÉÖÁ∑íÂíåË™çÁü•ÈÅéÁ®ãÁöÑË§áÈõúÊÄßÔºåËÄåÊßãÊàê‰∫Ü‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞ÔºåÈÄô‰∫õË§áÈõúÊÄßÂú®Á§æÊúÉ‰∫íÂãï‰∏≠ÊâÆÊºîËëóÈáçË¶ÅÁöÑËßíËâ≤Ôºå‰ΩÜ‰ªçÊú™ÂèóÂà∞ÂÖÖÂàÜÁöÑÊé¢Ë®é„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂÖ©ÈöéÊÆµËá™ÂãïË≥áÊñôÁî¢ÁîüÊû∂Êßã‰æÜÂª∫Á´ã CAPEÔºå‰∏ÄÂÄãÂêçÁÇ∫„ÄåË™çÁü•Ë©ïÈëëÁêÜË´ñÁÇ∫Âü∫Á§éÁöÑÊÉÖÁ∑íË™ûÊñôÂ∫´„ÄçÁöÑ‰∏≠ÊñáË≥áÊñôÈõÜ„ÄÇÊ≠§Ë™ûÊñôÂ∫´ÈÄèÈÅéËÄÉÈáè‰∏çÂêåÁöÑÂÄã‰∫∫ÂíåÊÉÖÂ¢ÉÂõ†Á¥†Ôºå‰øÉÈÄ≤Áî¢ÁîüÂÖ∑ÊúâÈÅ©Áï∂ÊÉÖÁ∑íÂèçÊáâÁöÑÂ∞çË©±„ÄÇÊàëÂÄëÊèêÂá∫ÂÖ©ÂÄãÂà©Áî®Ê≠§Ë≥áÊñôÈõÜÁöÑ‰ªªÂãôÔºöÊÉÖÁ∑íÈ†êÊ∏¨Âíå‰∏ã‰∏ÄÂÄãË©±Ë™ûÈ†êÊ∏¨„ÄÇËá™ÂãïÂåñÂíå‰∫∫Â∑•Ë©ï‰º∞ÈÉΩÈ°ØÁ§∫ÔºåÂú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑ‰ª£ÁêÜÁ®ãÂºèÔºåÂèØ‰ª•Êèê‰æõËàá‰∫∫È°ûÊÉÖÁ∑íË°®ÈÅîÊõ¥‰∏ÄËá¥ÁöÑÂèçÊáâ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂È°ØÁ§∫‰∫ÜÂú®Â∞çË©±‰ª£ÁêÜÁ®ãÂºè‰∏≠Êé®ÈÄ≤ÊÉÖÁ∑íË°®ÈÅîÁöÑÊΩõÂäõÔºåÁÇ∫Êõ¥Á¥∞Á∑ªÂÖ•ÂæÆ‰∏îÊúâÊÑèÁæ©ÁöÑ‰∫∫Ê©ü‰∫íÂãïÈã™Ë∑Ø„ÄÇ

##### **A Lightweight Multi Aspect Controlled Text Generation Solution For Large Language Models**
2410.14144v1 by Chenyang Zhang, Jiayi Lin, Haibo Tong, Bingxuan Hou, Dongyu Zhang, Jialin Li, Junli Wang

Large language models (LLMs) show remarkable abilities with instruction
tuning. However, they fail to achieve ideal tasks when lacking high-quality
instruction tuning data on target tasks. Multi-Aspect Controllable Text
Generation (MCTG) is a representative task for this dilemma, where aspect
datasets are usually biased and correlated. Existing work exploits additional
model structures and strategies for solutions, limiting adaptability to LLMs.
To activate MCTG ability of LLMs, we propose a lightweight MCTG pipeline based
on data augmentation. We analyze bias and correlations in traditional datasets,
and address these concerns with augmented control attributes and sentences.
Augmented datasets are feasible for instruction tuning. In our experiments,
LLMs perform better in MCTG after data augmentation, with a 20% accuracy rise
and less aspect correlations.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Êåá‰ª§Ë™øÊï¥ÊñπÈù¢Ë°®ÁèæÂá∫ÈùûÂá°ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁï∂Áº∫‰πèÈáùÂ∞çÁõÆÊ®ô‰ªªÂãôÁöÑÈ´òÂìÅË≥™Êåá‰ª§Ë™øÊï¥Êï∏ÊìöÊôÇÔºåÂÆÉÂÄëÁÑ°Ê≥ïÂØ¶ÁèæÁêÜÊÉ≥ÁöÑ‰ªªÂãô„ÄÇÂ§öÊñπÈù¢ÂèØÊéßÊñáÊú¨ÁîüÊàê (MCTG) ÊòØÈÄôÂÄãÂõ∞Â¢ÉÁöÑ‰ª£Ë°®ÊÄß‰ªªÂãôÔºåÂÖ∂‰∏≠ÊñπÈù¢Êï∏ÊìöÈõÜÈÄöÂ∏∏ÊúâÂÅèÂ∑Æ‰∏îÁõ∏Èóú„ÄÇÁèæÊúâÂ∑•‰ΩúÂà©Áî®È°çÂ§ñÁöÑÊ®°ÂûãÁµêÊßãÂíåÁ≠ñÁï•‰æÜËß£Ê±∫ÂïèÈ°åÔºåÈôêÂà∂‰∫ÜÂ∞ç LLM ÁöÑÈÅ©ÊáâÊÄß„ÄÇÁÇ∫‰∫ÜÊøÄÊ¥ª LLM ÁöÑ MCTG ËÉΩÂäõÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÊï∏ÊìöÂ¢ûÂº∑ÁöÑËºïÈáèÁ¥ö MCTG ÁÆ°ÈÅì„ÄÇÊàëÂÄëÂàÜÊûê‰∫ÜÂÇ≥Áµ±Êï∏ÊìöÈõÜ‰∏≠ÁöÑÂÅèÂ∑ÆÂíåÁõ∏ÈóúÊÄßÔºå‰∏¶‰ΩøÁî®Â¢ûÂº∑ÁöÑÊéßÂà∂Â±¨ÊÄßÂíåÂè•Â≠ê‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÂ¢ûÂº∑ÁöÑÊï∏ÊìöÈõÜÈÅ©Áî®ÊñºÊåá‰ª§Ë™øÊï¥„ÄÇÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåLLM Âú®Êï∏ÊìöÂ¢ûÂº∑ÂæåÂú® MCTG ‰∏≠Ë°®ÁèæÂæóÊõ¥Â•ΩÔºåÊ∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 20%ÔºåÊñπÈù¢Áõ∏ÈóúÊÄßÈôç‰Ωé‰∫Ü„ÄÇ

