{"2410.15973": {"publish_time": "2024-10-21", "title": "Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets)", "paper_summary": "This paper presents a novel approach to solving convex optimization problems\nby leveraging the fact that, under certain regularity conditions, any set of\nprimal or dual variables satisfying the Karush-Kuhn-Tucker (KKT) conditions is\nnecessary and sufficient for optimality. Similar to Theory-Trained Neural\nNetworks (TTNNs), the parameters of the convex optimization problem are input\nto the neural network, and the expected outputs are the optimal primal and dual\nvariables. A choice for the loss function in this case is a loss, which we\nrefer to as the KKT Loss, that measures how well the network's outputs satisfy\nthe KKT conditions. We demonstrate the effectiveness of this approach using a\nlinear program as an example. For this problem, we observe that minimizing the\nKKT Loss alone outperforms training the network with a weighted sum of the KKT\nLoss and a Data Loss (the mean-squared error between the ground truth optimal\nsolutions and the network's output). Moreover, minimizing only the Data Loss\nyields inferior results compared to those obtained by minimizing the KKT Loss.\nWhile the approach is promising, the obtained primal and dual solutions are not\nsufficiently close to the ground truth optimal solutions. In the future, we aim\nto develop improved models to obtain solutions closer to the ground truth and\nextend the approach to other problem classes.", "paper_summary_zh": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7a2e\u89e3\u6c7a\u51f8\u512a\u5316\u554f\u984c\u7684\u65b0\u65b9\u6cd5\uff0c\u65b9\u6cd5\u662f\u5229\u7528\u5728\u7279\u5b9a\u898f\u5247\u689d\u4ef6\u4e0b\uff0c\u4efb\u4f55\u6eff\u8db3 Karush-Kuhn-Tucker (KKT) \u689d\u4ef6\u7684\u539f\u59cb\u6216\u5c0d\u5076\u8b8a\u6578\u7d44\u5c0d\u65bc\u6700\u512a\u6027\u800c\u8a00\u662f\u5fc5\u8981\u4e14\u5145\u5206\u7684\u4e8b\u5be6\u3002\u985e\u4f3c\u65bc\u7406\u8ad6\u8a13\u7df4\u795e\u7d93\u7db2\u8def (TTNN)\uff0c\u51f8\u512a\u5316\u554f\u984c\u7684\u53c3\u6578\u6703\u8f38\u5165\u795e\u7d93\u7db2\u8def\uff0c\u800c\u9810\u671f\u7684\u8f38\u51fa\u662f\u6700\u4f73\u539f\u59cb\u548c\u5c0d\u5076\u8b8a\u6578\u3002\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u640d\u5931\u51fd\u6578\u7684\u9078\u64c7\u662f\u4e00\u7a2e\u640d\u5931\uff0c\u6211\u5011\u7a31\u4e4b\u70ba KKT \u640d\u5931\uff0c\u5b83\u8861\u91cf\u7db2\u8def\u8f38\u51fa\u6eff\u8db3 KKT \u689d\u4ef6\u7684\u7a0b\u5ea6\u3002\u6211\u5011\u4ee5\u7dda\u6027\u898f\u5283\u70ba\u4f8b\uff0c\u5c55\u793a\u4e86\u9019\u7a2e\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u5c0d\u65bc\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u50c5\u6700\u5c0f\u5316 KKT \u640d\u5931\u5c31\u512a\u65bc\u4f7f\u7528 KKT \u640d\u5931\u548c\u8cc7\u6599\u640d\u5931\uff08\u5730\u9762\u5be6\u6cc1\u6700\u4f73\u89e3\u8207\u7db2\u8def\u8f38\u51fa\u4e4b\u9593\u7684\u5747\u65b9\u8aa4\u5dee\uff09\u7684\u52a0\u6b0a\u548c\u4f86\u8a13\u7df4\u7db2\u8def\u3002\u6b64\u5916\uff0c\u50c5\u6700\u5c0f\u5316\u8cc7\u6599\u640d\u5931\u6703\u7522\u751f\u52a3\u65bc\u6700\u5c0f\u5316 KKT \u640d\u5931\u7684\u7d50\u679c\u3002\u96d6\u7136\u9019\u7a2e\u65b9\u6cd5\u5f88\u6709\u5e0c\u671b\uff0c\u4f46\u7372\u5f97\u7684\u539f\u59cb\u548c\u5c0d\u5076\u89e3\u4e26\u4e0d\u8db3\u4ee5\u63a5\u8fd1\u5730\u9762\u5be6\u6cc1\u7684\u6700\u4f73\u89e3\u3002\u672a\u4f86\uff0c\u6211\u5011\u65e8\u5728\u958b\u767c\u6539\u9032\u7684\u6a21\u578b\uff0c\u4ee5\u7372\u5f97\u66f4\u63a5\u8fd1\u5730\u9762\u5be6\u6cc1\u7684\u89e3\uff0c\u4e26\u5c07\u9019\u7a2e\u65b9\u6cd5\u64f4\u5c55\u5230\u5176\u4ed6\u554f\u984c\u985e\u5225\u3002", "author": "Shreya Arvind et.al.", "authors": "Shreya Arvind, Rishabh Pomaje, Rajshekhar V Bhat", "id": "2410.15973v1", "paper_url": "http://arxiv.org/abs/2410.15973v1", "repo": "null"}}