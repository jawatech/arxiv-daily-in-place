{"2411.09062": {"publish_time": "2024-11-13", "title": "Multimodal Object Detection using Depth and Image Data for Manufacturing Parts", "paper_summary": "Manufacturing requires reliable object detection methods for precise picking\nand handling of diverse types of manufacturing parts and components.\nTraditional object detection methods utilize either only 2D images from cameras\nor 3D data from lidars or similar 3D sensors. However, each of these sensors\nhave weaknesses and limitations. Cameras do not have depth perception and 3D\nsensors typically do not carry color information. These weaknesses can\nundermine the reliability and robustness of industrial manufacturing systems.\nTo address these challenges, this work proposes a multi-sensor system combining\nan red-green-blue (RGB) camera and a 3D point cloud sensor. The two sensors are\ncalibrated for precise alignment of the multimodal data captured from the two\nhardware devices. A novel multimodal object detection method is developed to\nprocess both RGB and depth data. This object detector is based on the Faster\nR-CNN baseline that was originally designed to process only camera images. The\nresults show that the multimodal model significantly outperforms the depth-only\nand RGB-only baselines on established object detection metrics. More\nspecifically, the multimodal model improves mAP by 13% and raises Mean\nPrecision by 11.8% in comparison to the RGB-only baseline. Compared to the\ndepth-only baseline, it improves mAP by 78% and raises Mean Precision by 57%.\nHence, this method facilitates more reliable and robust object detection in\nservice to smart manufacturing applications.", "paper_summary_zh": "\u88fd\u9020\u696d\u9700\u8981\u53ef\u9760\u7684\u7269\u4ef6\u5075\u6e2c\u65b9\u6cd5\uff0c\u4ee5\u7cbe\u6e96\u5730\u6311\u9078\u548c\u8655\u7406\u7a2e\u985e\u7e41\u591a\u7684\u88fd\u9020\u96f6\u4ef6\u548c\u7d44\u4ef6\u3002\n\u50b3\u7d71\u7684\u7269\u4ef6\u5075\u6e2c\u65b9\u6cd5\u50c5\u4f7f\u7528\u76f8\u6a5f\u7684 2D \u5f71\u50cf\u6216\u96f7\u9054\u6216\u985e\u4f3c 3D \u611f\u6e2c\u5668\u7684 3D \u8cc7\u6599\u3002\u7136\u800c\uff0c\u9019\u4e9b\u611f\u6e2c\u5668\u5404\u81ea\u90fd\u6709\u7f3a\u9ede\u548c\u9650\u5236\u3002\u76f8\u6a5f\u6c92\u6709\u6df1\u5ea6\u611f\u77e5\uff0c\u800c 3D \u611f\u6e2c\u5668\u901a\u5e38\u4e0d\u5177\u5099\u8272\u5f69\u8cc7\u8a0a\u3002\u9019\u4e9b\u7f3a\u9ede\u6703\u640d\u5bb3\u5de5\u696d\u88fd\u9020\u7cfb\u7d71\u7684\u53ef\u9760\u6027\u548c\u7a69\u5065\u6027\u3002\n\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u6311\u6230\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u500b\u591a\u611f\u6e2c\u5668\u7cfb\u7d71\uff0c\u7d50\u5408\u7d05\u7da0\u85cd (RGB) \u76f8\u6a5f\u548c 3D \u9ede\u96f2\u611f\u6e2c\u5668\u3002\u9019\u5169\u500b\u611f\u6e2c\u5668\u7d93\u904e\u6821\u6b63\uff0c\u4ee5\u7cbe\u6e96\u5c0d\u9f4a\u5f9e\u9019\u5169\u500b\u786c\u9ad4\u88dd\u7f6e\u64f7\u53d6\u7684\u591a\u6a21\u5f0f\u8cc7\u6599\u3002\u958b\u767c\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u591a\u6a21\u5f0f\u7269\u4ef6\u5075\u6e2c\u65b9\u6cd5\uff0c\u4ee5\u8655\u7406 RGB \u548c\u6df1\u5ea6\u8cc7\u6599\u3002\u9019\u500b\u7269\u4ef6\u5075\u6e2c\u5668\u57fa\u65bc Faster R-CNN \u57fa\u7dda\uff0c\u800c Faster R-CNN \u57fa\u7dda\u6700\u521d\u662f\u8a2d\u8a08\u4f86\u50c5\u8655\u7406\u76f8\u6a5f\u5f71\u50cf\u3002\n\u7d50\u679c\u986f\u793a\uff0c\u591a\u6a21\u5f0f\u6a21\u578b\u5728\u65e2\u5b9a\u7684\u7269\u4ef6\u5075\u6e2c\u6307\u6a19\u4e0a\u660e\u986f\u512a\u65bc\u50c5\u6df1\u5ea6\u548c\u50c5 RGB \u7684\u57fa\u7dda\u3002\u66f4\u5177\u9ad4\u4f86\u8aaa\uff0c\u8207\u50c5 RGB \u7684\u57fa\u7dda\u76f8\u6bd4\uff0c\u591a\u6a21\u5f0f\u6a21\u578b\u5c07 mAP \u63d0\u5347\u4e86 13%\uff0c\u4e26\u5c07\u5e73\u5747\u6e96\u78ba\u5ea6\u63d0\u9ad8\u4e86 11.8%\u3002\u8207\u50c5\u6df1\u5ea6\u57fa\u7dda\u76f8\u6bd4\uff0c\u5b83\u5c07 mAP \u63d0\u5347\u4e86 78%\uff0c\u4e26\u5c07\u5e73\u5747\u6e96\u78ba\u5ea6\u63d0\u9ad8\u4e86 57%\u3002\n\u56e0\u6b64\uff0c\u6b64\u65b9\u6cd5\u6709\u52a9\u65bc\u5728\u667a\u6167\u88fd\u9020\u61c9\u7528\u4e2d\u5be6\u73fe\u66f4\u53ef\u9760\u548c\u7a69\u5065\u7684\u7269\u4ef6\u5075\u6e2c\u3002", "author": "Nazanin Mahjourian et.al.", "authors": "Nazanin Mahjourian, Vinh Nguyen", "id": "2411.09062v1", "paper_url": "http://arxiv.org/abs/2411.09062v1", "repo": "null"}}