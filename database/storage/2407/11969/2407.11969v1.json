{"2407.11969": {"publish_time": "2024-07-16", "title": "Does Refusal Training in LLMs Generalize to the Past Tense?", "paper_summary": "Refusal training is widely used to prevent LLMs from generating harmful,\nundesirable, or illegal outputs. We reveal a curious generalization gap in the\ncurrent refusal training approaches: simply reformulating a harmful request in\nthe past tense (e.g., \"How to make a Molotov cocktail?\" to \"How did people make\na Molotov cocktail?\") is often sufficient to jailbreak many state-of-the-art\nLLMs. We systematically evaluate this method on Llama-3 8B, GPT-3.5 Turbo,\nGemma-2 9B, Phi-3-Mini, GPT-4o, and R2D2 models using GPT-3.5 Turbo as a\nreformulation model. For example, the success rate of this simple attack on\nGPT-4o increases from 1% using direct requests to 88% using 20 past tense\nreformulation attempts on harmful requests from JailbreakBench with GPT-4 as a\njailbreak judge. Interestingly, we also find that reformulations in the future\ntense are less effective, suggesting that refusal guardrails tend to consider\npast historical questions more benign than hypothetical future questions.\nMoreover, our experiments on fine-tuning GPT-3.5 Turbo show that defending\nagainst past reformulations is feasible when past tense examples are explicitly\nincluded in the fine-tuning data. Overall, our findings highlight that the\nwidely used alignment techniques -- such as SFT, RLHF, and adversarial training\n-- employed to align the studied models can be brittle and do not always\ngeneralize as intended. We provide code and jailbreak artifacts at\nhttps://github.com/tml-epfl/llm-past-tense.", "paper_summary_zh": "\u62d2\u7d55\u8a13\u7df4\u88ab\u5ee3\u6cdb\u7528\u65bc\u9632\u6b62 LLM \u7522\u751f\u6709\u5bb3\u3001\u4e0d\u53d7\u6b61\u8fce\u6216\u975e\u6cd5\u7684\u8f38\u51fa\u3002\u6211\u5011\u63ed\u793a\u4e86\u7576\u524d\u62d2\u7d55\u8a13\u7df4\u65b9\u6cd5\u4e2d\u4e00\u500b\u5947\u602a\u7684\u6982\u62ec\u5dee\u8ddd\uff1a\u50c5\u50c5\u7528\u904e\u53bb\u5f0f\u91cd\u65b0\u8868\u8ff0\u4e00\u500b\u6709\u5bb3\u7684\u8acb\u6c42\uff08\u4f8b\u5982\uff0c\u300c\u5982\u4f55\u88fd\u4f5c\u83ab\u6d1b\u6258\u592b\u96de\u5c3e\u9152\uff1f\u300d\u6539\u70ba\u300c\u4eba\u5011\u662f\u5982\u4f55\u88fd\u4f5c\u83ab\u6d1b\u6258\u592b\u96de\u5c3e\u9152\u7684\uff1f\u300d\uff09\u901a\u5e38\u8db3\u4ee5\u8b93\u8a31\u591a\u6700\u5148\u9032\u7684 LLM \u8d8a\u7344\u3002\u6211\u5011\u4f7f\u7528 GPT-3.5 Turbo \u4f5c\u70ba\u91cd\u65b0\u8868\u8ff0\u6a21\u578b\uff0c\u7cfb\u7d71\u6027\u5730\u8a55\u4f30\u4e86\u9019\u7a2e\u65b9\u6cd5\u5728 Llama-3 8B\u3001GPT-3.5 Turbo\u3001Gemma-2 9B\u3001Phi-3-Mini\u3001GPT-4o \u548c R2D2 \u6a21\u578b\u4e0a\u7684\u6548\u679c\u3002\u4f8b\u5982\uff0c\u9019\u7a2e\u7c21\u55ae\u653b\u64ca\u5728 GPT-4o \u4e0a\u7684\u6210\u529f\u7387\u5f9e\u4f7f\u7528\u76f4\u63a5\u8acb\u6c42\u6642\u7684 1% \u589e\u52a0\u5230\u4f7f\u7528 20 \u6b21\u904e\u53bb\u5f0f\u91cd\u65b0\u8868\u8ff0\u5617\u8a66\u5c0d\u4f86\u81ea JailbreakBench \u7684\u6709\u5bb3\u8acb\u6c42\u6642\u70ba 88%\uff0c\u800c GPT-4 \u5247\u4f5c\u70ba\u8d8a\u7344\u8a55\u5224\u3002\u6709\u8da3\u7684\u662f\uff0c\u6211\u5011\u9084\u767c\u73fe\uff0c\u672a\u4f86\u6642\u614b\u7684\u91cd\u65b0\u8868\u8ff0\u6548\u679c\u8f03\u5dee\uff0c\u9019\u8868\u660e\u62d2\u7d55\u9632\u8b77\u63aa\u65bd\u50be\u5411\u65bc\u5c07\u904e\u53bb\u7684\u6b77\u53f2\u554f\u984c\u8996\u70ba\u6bd4\u5047\u8a2d\u7684\u672a\u4f86\u554f\u984c\u66f4\u826f\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c0d\u5fae\u8abf GPT-3.5 Turbo \u7684\u5be6\u9a57\u8868\u660e\uff0c\u5728\u5fae\u8abf\u6578\u64da\u4e2d\u660e\u78ba\u5305\u542b\u904e\u53bb\u6642\u614b\u7684\u793a\u4f8b\u6642\uff0c\u53ef\u4ee5\u9632\u79a6\u904e\u53bb\u7684\u91cd\u65b0\u8868\u8ff0\u3002\u7e3d\u7684\u4f86\u8aaa\uff0c\u6211\u5011\u7684\u767c\u73fe\u5f37\u8abf\u4e86\u5ee3\u6cdb\u4f7f\u7528\u7684\u5c0d\u9f4a\u6280\u8853\u2014\u2014\u4f8b\u5982 SFT\u3001RLHF \u548c\u5c0d\u6297\u8a13\u7df4\u2014\u2014\u7528\u65bc\u5c0d\u9f4a\u6240\u7814\u7a76\u7684\u6a21\u578b\u53ef\u80fd\u662f\u8106\u5f31\u7684\uff0c\u4e26\u4e14\u4e26\u4e0d\u7e3d\u662f\u6309\u9810\u671f\u7684\u90a3\u6a23\u6982\u62ec\u3002\u6211\u5011\u5728 https://github.com/tml-epfl/llm-past-tense \u63d0\u4f9b\u4ee3\u78bc\u548c\u8d8a\u7344\u5de5\u4ef6\u3002", "author": "Maksym Andriushchenko et.al.", "authors": "Maksym Andriushchenko, Nicolas Flammarion", "id": "2407.11969v1", "paper_url": "http://arxiv.org/abs/2407.11969v1", "repo": "https://github.com/tml-epfl/llm-past-tense"}}