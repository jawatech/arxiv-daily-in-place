{"2503.03340": {"publish_time": "2025-03-05", "title": "EnigmaToM: Improve LLMs' Theory-of-Mind Reasoning Capabilities with Neural Knowledge Base of Entity States", "paper_summary": "Theory-of-Mind (ToM), the ability to infer others' perceptions and mental\nstates, is fundamental to human interaction but remains a challenging task for\nLarge Language Models (LLMs). While existing ToM reasoning methods show promise\nwith reasoning via perceptual perspective-taking, they often rely excessively\non LLMs, reducing their efficiency and limiting their applicability to\nhigh-order ToM reasoning, which requires multi-hop reasoning about characters'\nbeliefs. To address these issues, we present EnigmaToM, a novel neuro-symbolic\nframework that enhances ToM reasoning by integrating a Neural Knowledge Base of\nentity states (Enigma) for (1) a psychology-inspired iterative masking\nmechanism that facilitates accurate perspective-taking and (2) knowledge\ninjection that elicits key entity information. Enigma generates structured\nrepresentations of entity states, which construct spatial scene graphs --\nleveraging spatial information as an inductive bias -- for belief tracking of\nvarious ToM orders and enhancing events with fine-grained entity state details.\nExperimental results on multiple benchmarks, including ToMi, HiToM, and FANToM,\nshow that EnigmaToM significantly improves ToM reasoning across LLMs of varying\nsizes, particularly excelling in high-order reasoning scenarios.", "paper_summary_zh": "<paragraph>\u5fc3\u667a\u7406\u8ad6 (Theory-of-Mind\uff0cToM)\uff0c\u6307\u7684\u662f\u63a8\u65b7\u4ed6\u4eba\u611f\u77e5\u548c\u5fc3\u7406\u72c0\u614b\u7684\u80fd\u529b\uff0c\u662f\u4eba\u985e\u4e92\u52d5\u7684\u57fa\u790e\uff0c\u4f46\u5c0d\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4f86\u8aaa\u4ecd\u7136\u662f\u4e00\u9805\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\u3002\u96d6\u7136\u73fe\u6709\u7684 ToM \u63a8\u7406\u65b9\u6cd5\u5728\u900f\u904e\u611f\u77e5\u8996\u89d2\u9032\u884c\u63a8\u7406\u65b9\u9762\u5c55\u73fe\u51fa\u5e0c\u671b\uff0c\u4f46\u5b83\u5011\u5f80\u5f80\u904e\u5ea6\u4f9d\u8cf4 LLM\uff0c\u964d\u4f4e\u4e86\u6548\u7387\uff0c\u4e26\u9650\u5236\u4e86\u5b83\u5011\u5728\u9ad8\u968e ToM \u63a8\u7406\u4e2d\u7684\u61c9\u7528\uff0c\u56e0\u70ba\u9ad8\u968e ToM \u63a8\u7406\u9700\u8981\u5c0d\u89d2\u8272\u7684\u4fe1\u5ff5\u9032\u884c\u591a\u8df3\u63a8\u7406\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86 EnigmaToM\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u795e\u7d93\u7b26\u865f\u6846\u67b6\uff0c\u5b83\u900f\u904e\u6574\u5408\u4e00\u500b\u5be6\u9ad4\u72c0\u614b\u7684\u795e\u7d93\u77e5\u8b58\u5eab (Enigma) \u4f86\u589e\u5f37 ToM \u63a8\u7406\uff0c\u4ee5\u5be6\u73fe (1) \u4e00\u7a2e\u53d7\u5fc3\u7406\u5b78\u555f\u767c\u7684\u8fed\u4ee3\u906e\u7f69\u6a5f\u5236\uff0c\u4fc3\u9032\u6e96\u78ba\u7684\u8996\u89d2\u8f49\u63db\uff0c\u4ee5\u53ca (2) \u77e5\u8b58\u6ce8\u5165\uff0c\u5f15\u51fa\u95dc\u9375\u7684\u5be6\u9ad4\u8cc7\u8a0a\u3002Enigma \u751f\u6210\u5be6\u9ad4\u72c0\u614b\u7684\u7d50\u69cb\u5316\u8868\u793a\uff0c\u5efa\u69cb\u7a7a\u9593\u5834\u666f\u5716\u2014\u2014\u5229\u7528\u7a7a\u9593\u8cc7\u8a0a\u4f5c\u70ba\u6b78\u7d0d\u504f\u5dee\u2014\u2014\u7528\u65bc\u8ffd\u8e64\u5404\u7a2e ToM \u968e\u7d1a\u7684\u4fe1\u5ff5\uff0c\u4e26\u4f7f\u7528\u7d30\u7c92\u5ea6\u7684\u5be6\u9ad4\u72c0\u614b\u7d30\u7bc0\u4f86\u589e\u5f37\u4e8b\u4ef6\u3002\u5728 ToMi\u3001HiToM \u548c FANToM \u7b49\u591a\u500b\u57fa\u6e96\u6e2c\u8a66\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cEnigmaToM \u986f\u8457\u6539\u5584\u4e86\u5404\u7a2e\u898f\u6a21 LLM \u7684 ToM \u63a8\u7406\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u968e\u63a8\u7406\u5834\u666f\u4e2d\u8868\u73fe\u51fa\u8272\u3002</paragraph>\n", "author": "Hainiu Xu et.al.", "authors": "Hainiu Xu, Siya Qi, Jiazheng Li, Yuxiang Zhou, Jinhua Du, Caroline Catmur, Yulan He", "id": "2503.03340v1", "paper_url": "http://arxiv.org/abs/2503.03340v1", "repo": "null"}}