{"2411.07185": {"publish_time": "2024-11-11", "title": "Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation", "paper_summary": "Multi-source unsupervised domain adaptation aims to leverage labeled data\nfrom multiple source domains for training a machine learning model to\ngeneralize well on a target domain without labels. Source domain selection\nplays a crucial role in determining the model's performance. It relies on the\nsimilarities amongst source and target domains. Nonetheless, existing work for\nsource domain selection often involves heavyweight computational procedures,\nespecially when dealing with numerous source domains and the need to identify\nthe best ones from them. In this paper, we introduce a framework for gradual\nfine tuning (GFT) of machine learning models on multiple source domains. We\nrepresent multiple source domains as an undirected weighted graph. We then give\na new generalization error bound for GFT along any path within the graph, which\nis used to determine the optimal path corresponding to the optimal training\norder. With this formulation, we introduce three lightweight graph-routing\nstrategies which tend to minimize the error bound. Our best strategy improves\n$2.3\\%$ of accuracy over the state-of-the-art on Natural Language Inference\n(NLI) task and achieves competitive performance on Sentiment Analysis (SA)\ntask, especially a $3.9\\%$ improvement on a more diverse subset of data we use\nfor SA.", "paper_summary_zh": "\u591a\u6e90\u65e0\u76d1\u7763\u57df\u81ea\u9002\u5e94\u65e8\u5728\u5229\u7528\u6765\u81ea\u591a\u4e2a\u6e90\u57df\u7684\u6807\u8bb0\u6570\u636e\uff0c\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4ee5\u4fbf\u5728\u6ca1\u6709\u6807\u7b7e\u7684\u76ee\u6807\u57df\u4e0a\u5f88\u597d\u5730\u6cdb\u5316\u3002\u6e90\u57df\u9009\u62e9\u5728\u786e\u5b9a\u6a21\u578b\u6027\u80fd\u65b9\u9762\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\u3002\u5b83\u4f9d\u8d56\u4e8e\u6e90\u57df\u548c\u76ee\u6807\u57df\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u73b0\u6709\u7684\u6e90\u57df\u9009\u62e9\u5de5\u4f5c\u901a\u5e38\u6d89\u53ca\u91cd\u91cf\u7ea7\u8ba1\u7b97\u7a0b\u5e8f\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u4f17\u591a\u6e90\u57df\u4ee5\u53ca\u9700\u8981\u4ece\u4e2d\u8bc6\u522b\u6700\u4f73\u6e90\u57df\u65f6\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5728\u591a\u4e2a\u6e90\u57df\u4e0a\u5bf9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u9010\u6b65\u5fae\u8c03 (GFT) \u7684\u6846\u67b6\u3002\u6211\u4eec\u5c06\u591a\u4e2a\u6e90\u57df\u8868\u793a\u4e3a\u65e0\u5411\u52a0\u6743\u56fe\u3002\u7136\u540e\uff0c\u6211\u4eec\u4e3a\u56fe\u4e2d\u6cbf\u4efb\u4f55\u8def\u5f84\u7684 GFT \u7ed9\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6cdb\u5316\u8bef\u5dee\u754c\uff0c\u7528\u4e8e\u786e\u5b9a\u5bf9\u5e94\u4e8e\u6700\u4f73\u8bad\u7ec3\u987a\u5e8f\u7684\u6700\u4f73\u8def\u5f84\u3002\u901a\u8fc7\u8fd9\u79cd\u8868\u8ff0\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86\u4e09\u79cd\u8f7b\u91cf\u7ea7\u7684\u56fe\u8def\u7531\u7b56\u7565\uff0c\u8fd9\u4e9b\u7b56\u7565\u503e\u5411\u4e8e\u6700\u5c0f\u5316\u8bef\u5dee\u754c\u3002\u6211\u4eec\u6700\u597d\u7684\u7b56\u7565\u5728\u81ea\u7136\u8bed\u8a00\u63a8\u7406 (NLI) \u4efb\u52a1\u4e0a\u6bd4\u6700\u5148\u8fdb\u7684\u6280\u672f\u63d0\u9ad8\u4e86 2.3% \u7684\u51c6\u786e\u7387\uff0c\u5e76\u5728\u60c5\u611f\u5206\u6790 (SA) \u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6211\u4eec\u7528\u4e8e SA \u7684\u66f4\u591a\u6837\u5316\u7684\u6570\u636e\u5b50\u96c6\u4e0a\u63d0\u9ad8\u4e86 3.9%\u3002", "author": "Yao Ma et.al.", "authors": "Yao Ma, Samuel Louvan, Zhunxuan Wang", "id": "2411.07185v1", "paper_url": "http://arxiv.org/abs/2411.07185v1", "repo": "null"}}