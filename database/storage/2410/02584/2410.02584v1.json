{"2410.02584": {"publish_time": "2024-10-03", "title": "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions", "paper_summary": "As Large Language Models (LLMs) continue to evolve, they are increasingly\nbeing employed in numerous studies to simulate societies and execute diverse\nsocial tasks. However, LLMs are susceptible to societal biases due to their\nexposure to human-generated data. Given that LLMs are being used to gain\ninsights into various societal aspects, it is essential to mitigate these\nbiases. To that end, our study investigates the presence of implicit gender\nbiases in multi-agent LLM interactions and proposes two strategies to mitigate\nthese biases. We begin by creating a dataset of scenarios where implicit gender\nbiases might arise, and subsequently develop a metric to assess the presence of\nbiases. Our empirical analysis reveals that LLMs generate outputs characterized\nby strong implicit bias associations (>= 50\\% of the time). Furthermore, these\nbiases tend to escalate following multi-agent interactions. To mitigate them,\nwe propose two strategies: self-reflection with in-context examples (ICE); and\nsupervised fine-tuning. Our research demonstrates that both methods effectively\nmitigate implicit biases, with the ensemble of fine-tuning and self-reflection\nproving to be the most successful.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6301\u7e8c\u767c\u5c55\uff0c\u5b83\u5011\u6b63\u8d8a\u4f86\u8d8a\u591a\u5730\u7528\u65bc\u6a21\u64ec\u793e\u6703\u4e26\u57f7\u884c\u5404\u7a2e\u793e\u6703\u4efb\u52d9\u7684\u7814\u7a76\u4e2d\u3002\u7136\u800c\uff0c\u7531\u65bc LLM \u63a5\u89f8\u4e86\u4eba\u70ba\u751f\u6210\u7684\u8cc7\u6599\uff0c\u56e0\u6b64\u5bb9\u6613\u53d7\u5230\u793e\u6703\u504f\u898b\u7684\u5f71\u97ff\u3002\u9451\u65bc LLM \u88ab\u7528\u65bc\u6df1\u5165\u4e86\u89e3\u5404\u7a2e\u793e\u6703\u5c64\u9762\uff0c\u56e0\u6b64\u6e1b\u8f15\u9019\u4e9b\u504f\u898b\u81f3\u95dc\u91cd\u8981\u3002\u70ba\u6b64\uff0c\u6211\u5011\u7684\u7814\u7a76\u8abf\u67e5\u4e86\u591a\u4e3b\u9ad4 LLM \u4e92\u52d5\u4e2d\u96b1\u542b\u6027\u5225\u504f\u898b\u7684\u5b58\u5728\uff0c\u4e26\u63d0\u51fa\u4e86\u6e1b\u8f15\u9019\u4e9b\u504f\u898b\u7684\u5169\u500b\u7b56\u7565\u3002\u6211\u5011\u9996\u5148\u5efa\u7acb\u4e86\u4e00\u500b\u5834\u666f\u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u53ef\u80fd\u6703\u51fa\u73fe\u96b1\u542b\u7684\u6027\u5225\u504f\u898b\uff0c\u7136\u5f8c\u958b\u767c\u4e00\u500b\u6307\u6a19\u4f86\u8a55\u4f30\u504f\u898b\u7684\u5b58\u5728\u3002\u6211\u5011\u7684\u5be6\u8b49\u5206\u6790\u8868\u660e\uff0cLLM \u751f\u6210\u7684\u8f38\u51fa\u5177\u6709\u5f37\u70c8\u7684\u96b1\u542b\u504f\u898b\u95dc\u806f\uff08>= 50% \u7684\u6642\u9593\uff09\u3002\u6b64\u5916\uff0c\u9019\u4e9b\u504f\u898b\u5f80\u5f80\u6703\u5728\u591a\u4e3b\u9ad4\u4e92\u52d5\u5f8c\u5347\u7d1a\u3002\u70ba\u4e86\u6e1b\u8f15\u5b83\u5011\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u5169\u7a2e\u7b56\u7565\uff1a\u5e36\u6709\u60c5\u5883\u7bc4\u4f8b (ICE) \u7684\u81ea\u6211\u53cd\u7701\uff1b\u4ee5\u53ca\u76e3\u7763\u5fae\u8abf\u3002\u6211\u5011\u7684\u7814\u7a76\u8868\u660e\uff0c\u9019\u5169\u7a2e\u65b9\u6cd5\u90fd\u80fd\u6709\u6548\u6e1b\u8f15\u96b1\u542b\u504f\u898b\uff0c\u5176\u4e2d\u5fae\u8abf\u548c\u81ea\u6211\u53cd\u7701\u7684\u7d44\u5408\u88ab\u8b49\u660e\u662f\u6700\u6210\u529f\u7684\u3002", "author": "Angana Borah et.al.", "authors": "Angana Borah, Rada Mihalcea", "id": "2410.02584v1", "paper_url": "http://arxiv.org/abs/2410.02584v1", "repo": "https://github.com/MichiganNLP/MultiAgent_ImplicitBias"}}