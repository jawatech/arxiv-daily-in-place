{"2501.07146": {"publish_time": "2025-01-13", "title": "TIMRL: A Novel Meta-Reinforcement Learning Framework for Non-Stationary and Multi-Task Environments", "paper_summary": "In recent years, meta-reinforcement learning (meta-RL) algorithm has been\nproposed to improve sample efficiency in the field of decision-making and\ncontrol, enabling agents to learn new knowledge from a small number of samples.\nHowever, most research uses the Gaussian distribution to extract task\nrepresentation, which is poorly adapted to tasks that change in non-stationary\nenvironment. To address this problem, we propose a novel meta-reinforcement\nlearning method by leveraging Gaussian mixture model and the transformer\nnetwork to construct task inference model. The Gaussian mixture model is\nutilized to extend the task representation and conduct explicit encoding of\ntasks. Specifically, the classification of tasks is encoded through transformer\nnetwork to determine the Gaussian component corresponding to the task. By\nleveraging task labels, the transformer network is trained using supervised\nlearning. We validate our method on MuJoCo benchmarks with non-stationary and\nmulti-task environments. Experimental results demonstrate that the proposed\nmethod dramatically improves sample efficiency and accurately recognizes the\nclassification of the tasks, while performing excellently in the environment.", "paper_summary_zh": "\u8fd1\u5e74\u6765\uff0c\u5143\u5f3a\u5316\u5b66\u4e60\uff08\u5143 RL\uff09\u7b97\u6cd5\u88ab\u63d0\u51fa\u4ee5\u63d0\u9ad8\u51b3\u7b56\u548c\u63a7\u5236\u9886\u57df\u7684\u6837\u672c\u6548\u7387\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u4ece\u5c0f\u6837\u672c\u4e2d\u5b66\u4e60\u65b0\u77e5\u8bc6\u3002\u7136\u800c\uff0c\u5927\u591a\u6570\u7814\u7a76\u4f7f\u7528\u9ad8\u65af\u5206\u5e03\u6765\u63d0\u53d6\u4efb\u52a1\u8868\u793a\uff0c\u8fd9\u5f88\u96be\u9002\u5e94\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u53d1\u751f\u53d8\u5316\u7684\u4efb\u52a1\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5143\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u548c transformer \u7f51\u7edc\u6765\u6784\u5efa\u4efb\u52a1\u63a8\u7406\u6a21\u578b\u3002\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u7528\u4e8e\u6269\u5c55\u4efb\u52a1\u8868\u793a\u5e76\u5bf9\u4efb\u52a1\u8fdb\u884c\u663e\u5f0f\u7f16\u7801\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4efb\u52a1\u7684\u5206\u7c7b\u901a\u8fc7 transformer \u7f51\u7edc\u8fdb\u884c\u7f16\u7801\uff0c\u4ee5\u786e\u5b9a\u5bf9\u5e94\u4e8e\u4efb\u52a1\u7684\u9ad8\u65af\u5206\u91cf\u3002\u901a\u8fc7\u5229\u7528\u4efb\u52a1\u6807\u7b7e\uff0ctransformer \u7f51\u7edc\u4f7f\u7528\u76d1\u7763\u5b66\u4e60\u8fdb\u884c\u8bad\u7ec3\u3002\u6211\u4eec\u5728\u5177\u6709\u975e\u5e73\u7a33\u548c\u591a\u4efb\u52a1\u73af\u5883\u7684 MuJoCo \u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6781\u5927\u5730\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\uff0c\u5e76\u51c6\u786e\u8bc6\u522b\u4e86\u4efb\u52a1\u7684\u5206\u7c7b\uff0c\u540c\u65f6\u5728\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "author": "Chenyang Qi et.al.", "authors": "Chenyang Qi, Huiping Li, Panfeng Huang", "id": "2501.07146v1", "paper_url": "http://arxiv.org/abs/2501.07146v1", "repo": "null"}}