{"2411.07773": {"publish_time": "2024-11-12", "title": "Likelihood as a Performance Gauge for Retrieval-Augmented Generation", "paper_summary": "Recent work finds that retrieval-augmented generation with large language\nmodels is prone to be influenced by the order of retrieved documents in the\ncontext. However, the lack of in-depth analysis limits the use of this\nphenomenon for prompt engineering in practice. In this study, we posit that\nlikelihoods serve as an effective gauge for language model performance. Through\nexperiments on two question-answering datasets with a variety of\nstate-of-the-art language models, we reveal correlations between answer\naccuracy and the likelihood of the question at both the corpus level and the\ninstance level. In addition, we find that question likelihood can also indicate\nthe position of the task-relevant information in the context. Based on these\nfindings, we propose two methods that use question likelihood as a gauge for\nselecting and constructing prompts that lead to better performance. We\ndemonstrate their effectiveness with experiments. In addition, our\nlikelihood-based methods are efficient, as they only need to compute the\nlikelihood of the input, requiring much fewer language model passes than\nheuristic prompt engineering methods that require generating responses. Our\nanalysis deepens our understanding of how input prompts affect model\nperformance and provides a promising direction for efficient prompt\noptimization.", "paper_summary_zh": "\u6700\u8fd1\u7684\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5bb9\u6613\u53d7\u5230\u4e0a\u4e0b\u6587\u4e2d\u68c0\u7d22\u5230\u7684\u6587\u6863\u987a\u5e8f\u7684\u5f71\u54cd\u3002\u7136\u800c\uff0c\u7f3a\u4e4f\u6df1\u5165\u7684\u5206\u6790\u9650\u5236\u4e86\u8fd9\u79cd\u73b0\u8c61\u5728\u5b9e\u9645\u63d0\u793a\u5de5\u7a0b\u4e2d\u7684\u4f7f\u7528\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u5047\u8bbe\u4f3c\u7136\u5ea6\u53ef\u4ee5\u4f5c\u4e3a\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u6709\u6548\u8861\u91cf\u6807\u51c6\u3002\u901a\u8fc7\u5bf9\u4e24\u4e2a\u95ee\u7b54\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5176\u4e2d\u5305\u542b\u5404\u79cd\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u6211\u4eec\u63ed\u793a\u4e86\u5728\u8bed\u6599\u5e93\u7ea7\u522b\u548c\u5b9e\u4f8b\u7ea7\u522b\u4e0a\u7b54\u6848\u51c6\u786e\u5ea6\u4e0e\u95ee\u9898\u4f3c\u7136\u5ea6\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u53d1\u73b0\u95ee\u9898\u4f3c\u7136\u5ea6\u8fd8\u53ef\u4ee5\u6307\u793a\u4e0a\u4e0b\u6587\u4e2d\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u4fe1\u606f\u7684\u4f4d\u7f6e\u3002\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff0c\u5b83\u4eec\u4f7f\u7528\u95ee\u9898\u4f3c\u7136\u5ea6\u4f5c\u4e3a\u8861\u91cf\u6807\u51c6\uff0c\u7528\u4e8e\u9009\u62e9\u548c\u6784\u5efa\u63d0\u793a\uff0c\u4ece\u800c\u5e26\u6765\u66f4\u597d\u7684\u6027\u80fd\u3002\u6211\u4eec\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u4e86\u5b83\u4eec\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u57fa\u4e8e\u4f3c\u7136\u5ea6\u7684\u65b9\u6cd5\u975e\u5e38\u6709\u6548\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ea\u9700\u8981\u8ba1\u7b97\u8f93\u5165\u7684\u4f3c\u7136\u5ea6\uff0c\u6bd4\u9700\u8981\u751f\u6210\u54cd\u5e94\u7684\u542f\u53d1\u5f0f\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u9700\u8981\u7684\u8bed\u8a00\u6a21\u578b\u4f20\u9012\u8981\u5c11\u5f97\u591a\u3002\u6211\u4eec\u7684\u5206\u6790\u52a0\u6df1\u4e86\u6211\u4eec\u5bf9\u8f93\u5165\u63d0\u793a\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u9ad8\u6548\u63d0\u793a\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002", "author": "Tianyu Liu et.al.", "authors": "Tianyu Liu, Jirui Qi, Paul He, Arianna Bisazza, Mrinmaya Sachan, Ryan Cotterell", "id": "2411.07773v1", "paper_url": "http://arxiv.org/abs/2411.07773v1", "repo": "https://github.com/lyutyuh/poptimizer"}}