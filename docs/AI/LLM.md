
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702v1](http://arxiv.org/abs/2408.07702v1)|null|
|**2024-08-14**|**Quantifying over Optimum Answer Sets**|Giuseppe Mazzotta et.al.|[2408.07697v1](http://arxiv.org/abs/2408.07697v1)|null|
|**2024-08-14**|**End-to-end Semantic-centric Video-based Multimodal Affective Computing**|Ronghao Lin et.al.|[2408.07694v1](http://arxiv.org/abs/2408.07694v1)|null|
|**2024-08-14**|**A Spitting Image: Modular Superpixel Tokenization in Vision Transformers**|Marius Aasan et.al.|[2408.07680v2](http://arxiv.org/abs/2408.07680v2)|[link](https://github.com/dsb-ifi/spit)|
|**2024-08-14**|**Enhanced Detection of Conversational Mental Manipulation Through Advanced Prompting Techniques**|Ivory Yang et.al.|[2408.07676v1](http://arxiv.org/abs/2408.07676v1)|null|
|**2024-08-14**|**Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data**|Xia Jiang et.al.|[2408.07673v2](http://arxiv.org/abs/2408.07673v2)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666v2](http://arxiv.org/abs/2408.07666v2)|[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665v1](http://arxiv.org/abs/2408.07665v1)|null|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663v1](http://arxiv.org/abs/2408.07663v1)|[link](https://github.com/gigabaozi/aed)|
|**2024-08-14**|**Boosting Unconstrained Face Recognition with Targeted Style Adversary**|Mohammad Saeed Ebrahimi Saadabadi et.al.|[2408.07642v1](http://arxiv.org/abs/2408.07642v1)|null|
|**2024-08-14**|**Hierarchical Working Memory and a New Magic Number**|Weishun Zhong et.al.|[2408.07637v1](http://arxiv.org/abs/2408.07637v1)|null|
|**2024-08-14**|**Drug Discovery SMILES-to-Pharmacokinetics Diffusion Models with Deep Molecular Understanding**|Bing Hu et.al.|[2408.07636v1](http://arxiv.org/abs/2408.07636v1)|null|
|**2024-08-14**|**Battery GraphNets : Relational Learning for Lithium-ion Batteries(LiBs) Life Estimation**|Sakhinana Sagar Srinivas et.al.|[2408.07624v1](http://arxiv.org/abs/2408.07624v1)|null|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611v1](http://arxiv.org/abs/2408.07611v1)|null|
|**2024-08-14**|**Assessing the Role of Lexical Semantics in Cross-lingual Transfer through Controlled Manipulations**|Roy Ilani et.al.|[2408.07599v1](http://arxiv.org/abs/2408.07599v1)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583v1](http://arxiv.org/abs/2408.07583v1)|null|
|**2024-08-14**|**Multi-task Heterogeneous Graph Learning on Electronic Health Records**|Tsai Hor Chan et.al.|[2408.07569v1](http://arxiv.org/abs/2408.07569v1)|null|
|**2024-08-14**|**PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation**|Sang-Hoon Lee et.al.|[2408.07547v1](http://arxiv.org/abs/2408.07547v1)|[link](https://github.com/sh-lee-prml/periodwave)|
|**2024-08-14**|**Planning with OWL-DL Ontologies (Extended Version)**|Tobias John et.al.|[2408.07544v1](http://arxiv.org/abs/2408.07544v1)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543v2](http://arxiv.org/abs/2408.07543v2)|null|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542v1](http://arxiv.org/abs/2408.07542v1)|null|
|**2024-08-14**|**DifuzCam: Replacing Camera Lens with a Mask and a Diffusion Model**|Erez Yosef et.al.|[2408.07541v1](http://arxiv.org/abs/2408.07541v1)|null|
|**2024-08-14**|**Cross-aware Early Fusion with Stage-divided Vision and Language Transformer Encoders for Referring Image Segmentation**|Yubin Cho et.al.|[2408.07539v1](http://arxiv.org/abs/2408.07539v1)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531v1](http://arxiv.org/abs/2408.07531v1)|null|
|**2024-08-14**|**Evidential Graph Contrastive Alignment for Source-Free Blending-Target Domain Adaptation**|Juepeng Zheng et.al.|[2408.07527v1](http://arxiv.org/abs/2408.07527v1)|null|
|**2024-08-14**|**Fast Inference for Probabilistic Answer Set Programs via the Residual Program**|Damiano Azzolini et.al.|[2408.07524v1](http://arxiv.org/abs/2408.07524v1)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505v1](http://arxiv.org/abs/2408.07505v1)|null|
|**2024-08-14**|**Training Overhead Ratio: A Practical Reliability Metric for Large Language Model Training Systems**|Ning Lu et.al.|[2408.07482v1](http://arxiv.org/abs/2408.07482v1)|null|
|**2024-08-14**|**A Study on Bias Detection and Classification in Natural Language Processing**|Ana Sofia Evans et.al.|[2408.07479v1](http://arxiv.org/abs/2408.07479v1)|null|
|**2024-08-14**|**Bridging and Modeling Correlations in Pairwise Data for Direct Preference Optimization**|Yuxin Jiang et.al.|[2408.07471v1](http://arxiv.org/abs/2408.07471v1)|null|
|**2024-08-14**|**Large Language Models Prompting With Episodic Memory**|Dai Do et.al.|[2408.07465v1](http://arxiv.org/abs/2408.07465v1)|null|
|**2024-08-14**|**Problem Solving Through Human-AI Preference-Based Cooperation**|Subhabrata Dutta et.al.|[2408.07461v2](http://arxiv.org/abs/2408.07461v2)|null|
|**2024-08-14**|**From Brazilian Portuguese to European Portuguese**|João Sanches et.al.|[2408.07457v1](http://arxiv.org/abs/2408.07457v1)|null|
|**2024-08-14**|**Fact or Fiction? Improving Fact Verification with Knowledge Graphs through Simplified Subgraph Retrievals**|Tobias A. Opsahl et.al.|[2408.07453v1](http://arxiv.org/abs/2408.07453v1)|null|
|**2024-08-14**|**CMU's IWSLT 2024 Simultaneous Speech Translation System**|Xi Xu et.al.|[2408.07452v1](http://arxiv.org/abs/2408.07452v1)|null|
|**2024-08-14**|**Achieving Data Efficient Neural Networks with Hybrid Concept-based Models**|Tobias A. Opsahl et.al.|[2408.07438v1](http://arxiv.org/abs/2408.07438v1)|[link](https://github.com/tobias-opsahl/hybrid-concept-based-models)|
|**2024-08-14**|**Real-world validation of safe reinforcement learning, model predictive control and decision tree-based home energy management systems**|Julian Ruddick et.al.|[2408.07435v1](http://arxiv.org/abs/2408.07435v1)|null|
|**2024-08-14**|**MagicFace: Training-free Universal-Style Human Image Customized Synthesis**|Yibin Wang et.al.|[2408.07433v2](http://arxiv.org/abs/2408.07433v2)|null|
|**2024-08-14**|**Exploring Retrieval Augmented Generation in Arabic**|Samhaa R. El-Beltagy et.al.|[2408.07425v1](http://arxiv.org/abs/2408.07425v1)|null|
|**2024-08-14**|**LLMI3D: Empowering LLM with 3D Perception from a Single 2D Image**|Fan Yang et.al.|[2408.07422v1](http://arxiv.org/abs/2408.07422v1)|null|
|**2024-08-14**|**The Restaurant Meal Delivery Problem with Ghost Kitchens**|Gal Neria et.al.|[2408.07417v1](http://arxiv.org/abs/2408.07417v1)|null|
|**2024-08-14**|**Knowledge in Superposition: Unveiling the Failures of Lifelong Knowledge Editing for Large Language Models**|Chenhui Hu et.al.|[2408.07413v1](http://arxiv.org/abs/2408.07413v1)|[link](https://github.com/chenhuihu/knowledge_in_superposition)|
|**2024-08-14**|**Aquila2 Technical Report**|Bo-Wen Zhang et.al.|[2408.07410v1](http://arxiv.org/abs/2408.07410v1)|[link](https://github.com/flagai-open/aquila2)|
|**2024-08-14**|**Efficient Edge AI: Deploying Convolutional Neural Networks on FPGA with the Gemmini Accelerator**|Federico Nicolas Peccia et.al.|[2408.07404v1](http://arxiv.org/abs/2408.07404v1)|null|
|**2024-08-14**|**A Quantum-Inspired Analysis of Human Disambiguation Processes**|Daphne Wang et.al.|[2408.07402v1](http://arxiv.org/abs/2408.07402v1)|null|
|**2024-08-14**|**DataVisT5: A Pre-trained Language Model for Jointly Understanding Text and Data Visualization**|Zhuoyue Wan et.al.|[2408.07401v1](http://arxiv.org/abs/2408.07401v1)|null|
|**2024-08-14**|**Sum-Product-Set Networks**|Milan Papež et.al.|[2408.07394v1](http://arxiv.org/abs/2408.07394v1)|[link](https://github.com/aicenter/sumproductset.jl)|
|**2024-08-14**|**Do GPT Language Models Suffer From Split Personality Disorder? The Advent Of Substrate-Free Psychometrics**|Peter Romero et.al.|[2408.07377v2](http://arxiv.org/abs/2408.07377v2)|null|
|**2024-08-14**|**Only One Relation Possible? Modeling the Ambiguity in Event Temporal Relation Extraction**|Yutong Hu et.al.|[2408.07353v1](http://arxiv.org/abs/2408.07353v1)|null|
|**2024-08-14**|**RTAT: A Robust Two-stage Association Tracker for Multi-Object Tracking**|Song Guo et.al.|[2408.07344v1](http://arxiv.org/abs/2408.07344v1)|null|
|**2024-08-14**|**Towards Few-shot Self-explaining Graph Neural Networks**|Jingyu Peng et.al.|[2408.07340v1](http://arxiv.org/abs/2408.07340v1)|[link](https://github.com/jypeng28/mse-gnn)|
|**2024-08-14**|**An Offline Meta Black-box Optimization Framework for Adaptive Design of Urban Traffic Light Management Systems**|Taeyoung Yun et.al.|[2408.07327v1](http://arxiv.org/abs/2408.07327v1)|null|
|**2024-08-14**|**On-the-fly Synthesis for LTL over Finite Traces: An Efficient Approach that Counts**|Shengping Xiao et.al.|[2408.07324v1](http://arxiv.org/abs/2408.07324v1)|null|
|**2024-08-14**|**Kolmogorov-Arnold Networks (KAN) for Time Series Classification and Robust Analysis**|Chang Dong et.al.|[2408.07314v1](http://arxiv.org/abs/2408.07314v1)|null|
|**2024-08-14**|**Enhancing Visual Question Answering through Ranking-Based Hybrid Training and Multimodal Fusion**|Peiyuan Chen et.al.|[2408.07303v1](http://arxiv.org/abs/2408.07303v1)|null|
|**2024-08-14**|**LiPCoT: Linear Predictive Coding based Tokenizer for Self-supervised Learning of Time Series Data via Language Models**|Md Fahim Anjum et.al.|[2408.07292v1](http://arxiv.org/abs/2408.07292v1)|[link](https://github.com/mdfahimanjum/lipcot)|
|**2024-08-14**|**NL2OR: Solve Complex Operations Research Problems Using Natural Language Inputs**|Junxuan Li et.al.|[2408.07272v1](http://arxiv.org/abs/2408.07272v1)|null|
|**2024-08-14**|**Ensemble architecture in polyp segmentation**|Hao-Yun Hsu et.al.|[2408.07262v1](http://arxiv.org/abs/2408.07262v1)|[link](https://github.com/huangdlab/enformer)|
|**2024-08-14**|**GRIF-DM: Generation of Rich Impression Fonts using Diffusion Models**|Lei Kang et.al.|[2408.07259v1](http://arxiv.org/abs/2408.07259v1)|[link](https://github.com/leitro/grif-dm)|
|**2024-08-14**|**Enhancing Autonomous Vehicle Perception in Adverse Weather through Image Augmentation during Semantic Segmentation Training**|Ethan Kou et.al.|[2408.07239v1](http://arxiv.org/abs/2408.07239v1)|null|
|**2024-08-13**|**Using Advanced LLMs to Enhance Smaller LLMs: An Interpretable Knowledge Distillation Approach**|Tong Wang et.al.|[2408.07238v1](http://arxiv.org/abs/2408.07238v1)|null|
|**2024-08-13**|**Neural embedding of beliefs reveals the role of relative dissonance in human decision-making**|Byunghwee Lee et.al.|[2408.07237v1](http://arxiv.org/abs/2408.07237v1)|null|
|**2024-08-13**|**Direction of Arrival Correction through Speech Quality Feedback**|Caleb Rascon et.al.|[2408.07234v1](http://arxiv.org/abs/2408.07234v1)|null|
|**2024-08-13**|**Can Large Language Models Reason? A Characterization via 3-SAT**|Rishi Hazra et.al.|[2408.07215v1](http://arxiv.org/abs/2408.07215v1)|null|
|**2024-08-13**|**Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**|Pranav Putta et.al.|[2408.07199v1](http://arxiv.org/abs/2408.07199v1)|null|
|**2024-08-13**|**Massive Dimensions Reduction and Hybridization with Meta-heuristics in Deep Learning**|Rasa Khosrowshahli et.al.|[2408.07194v1](http://arxiv.org/abs/2408.07194v1)|null|
|**2024-08-13**|**Solving Truly Massive Budgeted Monotonic POMDPs with Oracle-Guided Meta-Reinforcement Learning**|Manav Vora et.al.|[2408.07192v1](http://arxiv.org/abs/2408.07192v1)|null|
|**2024-08-13**|**BERT's Conceptual Cartography: Mapping the Landscapes of Meaning**|Nina Haket et.al.|[2408.07190v1](http://arxiv.org/abs/2408.07190v1)|null|
|**2024-08-13**|**A New Dataset, Notation Software, and Representation for Computational Schenkerian Analysis**|Stephen Ni-Hahn et.al.|[2408.07184v1](http://arxiv.org/abs/2408.07184v1)|null|
|**2024-08-13**|**Unlocking Efficiency: Adaptive Masking for Gene Transformer Models**|Soumyadeep Roy et.al.|[2408.07180v1](http://arxiv.org/abs/2408.07180v1)|[link](https://github.com/roysoumya/curriculum-genemask)|
|**2024-08-13**|**Vision Language Model for Interpretable and Fine-grained Detection of Safety Compliance in Diverse Workplaces**|Zhiling Chen et.al.|[2408.07146v1](http://arxiv.org/abs/2408.07146v1)|null|
|**2024-08-13**|**Language Models as Models of Language**|Raphaël Millière et.al.|[2408.07144v1](http://arxiv.org/abs/2408.07144v1)|null|
|**2024-08-13**|**ELLA: Empowering LLMs for Interpretable, Accurate and Informative Legal Advice**|Yutong Hu et.al.|[2408.07137v1](http://arxiv.org/abs/2408.07137v1)|null|
|**2024-08-13**|**Fingerspelling within Sign Language Translation**|Garrett Tanzer et.al.|[2408.07065v1](http://arxiv.org/abs/2408.07065v1)|null|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060v1](http://arxiv.org/abs/2408.07060v1)|null|
|**2024-08-13**|**Model Counting in the Wild**|Arijit Shaw et.al.|[2408.07059v1](http://arxiv.org/abs/2408.07059v1)|null|
|**2024-08-13**|**A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning**|Prateek Yadav et.al.|[2408.07057v1](http://arxiv.org/abs/2408.07057v1)|null|
|**2024-08-13**|**LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs**|Yushi Bai et.al.|[2408.07055v1](http://arxiv.org/abs/2408.07055v1)|[link](https://github.com/thudm/longwriter)|
|**2024-08-13**|**TableGuard -- Securing Structured & Unstructured Data**|Anantha Sharma et.al.|[2408.07045v1](http://arxiv.org/abs/2408.07045v1)|null|
|**2024-08-13**|**KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation**|Daniele Rege Cambrin et.al.|[2408.07040v1](http://arxiv.org/abs/2408.07040v1)|null|
|**2024-08-13**|**PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology**|Xiaomin Wu et.al.|[2408.07037v1](http://arxiv.org/abs/2408.07037v1)|null|
|**2024-08-13**|**Casper: Prompt Sanitization for Protecting User Privacy in Web-Based Large Language Models**|Chun Jie Chong et.al.|[2408.07004v1](http://arxiv.org/abs/2408.07004v1)|null|
|**2024-08-13**|**Generative AI for automatic topic labelling**|Diego Kozlowski et.al.|[2408.07003v1](http://arxiv.org/abs/2408.07003v1)|null|
|**2024-08-13**|**A Theory-Based Explainable Deep Learning Architecture for Music Emotion**|Hortense Fong et.al.|[2408.07113v1](http://arxiv.org/abs/2408.07113v1)|null|
|**2024-08-13**|**LLMs can Schedule**|Henrik Abgaryan et.al.|[2408.06993v1](http://arxiv.org/abs/2408.06993v1)|[link](https://github.com/starjob42/datasetjsp)|
|**2024-08-13**|**Neural Speech and Audio Coding**|Minje Kim et.al.|[2408.06954v1](http://arxiv.org/abs/2408.06954v1)|null|
|**2024-08-13**|**The advantages of context specific language models: the case of the Erasmian Language Model**|João Gonçalves et.al.|[2408.06931v1](http://arxiv.org/abs/2408.06931v1)|null|
|**2024-08-13**|**Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification**|Bauke Arends et.al.|[2408.06930v2](http://arxiv.org/abs/2408.06930v2)|[link](https://github.com/umcu/echolabeler)|
|**2024-08-13**|**Evaluating Cultural Adaptability of a Large Language Model via Simulation of Synthetic Personas**|Louis Kwok et.al.|[2408.06929v1](http://arxiv.org/abs/2408.06929v1)|null|
|**2024-08-13**|**Heterogeneous Space Fusion and Dual-Dimension Attention: A New Paradigm for Speech Enhancement**|Tao Zheng et.al.|[2408.06911v1](http://arxiv.org/abs/2408.06911v1)|null|
|**2024-08-13**|**VNet: A GAN-based Multi-Tier Discriminator Network for Speech Synthesis Vocoders**|Yubing Cao et.al.|[2408.06906v1](http://arxiv.org/abs/2408.06906v1)|null|
|**2024-08-13**|**Re-TASK: Revisiting LLM Tasks from Capability, Skill, and Knowledge Perspectives**|Zhihu Wang et.al.|[2408.06904v1](http://arxiv.org/abs/2408.06904v1)|null|
|**2024-08-13**|**Entendre, a Social Bot Detection Tool for Niche, Fringe, and Extreme Social Media**|Pranav Venkatesh et.al.|[2408.06900v1](http://arxiv.org/abs/2408.06900v1)|null|
|**2024-08-13**|**Automatic Feature Recognition and Dimensional Attributes Extraction From CAD Models for Hybrid Additive-Subtractive Manufacturing**|Muhammad Tayyab Khan et.al.|[2408.06891v2](http://arxiv.org/abs/2408.06891v2)|null|
|**2024-08-13**|**BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning**|Yuyang Xue et.al.|[2408.06890v1](http://arxiv.org/abs/2408.06890v1)|null|
|**2024-08-13**|**Advancing Interactive Explainable AI via Belief Change Theory**|Antonio Rago et.al.|[2408.06875v2](http://arxiv.org/abs/2408.06875v2)|null|
|**2024-08-13**|**Leveraging Language Models for Emotion and Behavior Analysis in Education**|Kaito Tanaka et.al.|[2408.06874v1](http://arxiv.org/abs/2408.06874v1)|null|
|**2024-08-13**|**LoRA$^2$ : Multi-Scale Low-Rank Approximations for Fine-Tuning Large Language Models**|Jia-Chen Zhang et.al.|[2408.06854v1](http://arxiv.org/abs/2408.06854v1)|null|
|**2024-08-13**|**BSS-CFFMA: Cross-Domain Feature Fusion and Multi-Attention Speech Enhancement Network based on Self-Supervised Embedding**|Alimjan Mattursun et.al.|[2408.06851v1](http://arxiv.org/abs/2408.06851v1)|null|
|**2024-08-13**|**Causal Agent based on Large Language Model**|Kairong Han et.al.|[2408.06849v1](http://arxiv.org/abs/2408.06849v1)|[link](https://github.com/kairong-han/causal_agent)|

#### Abstracts
##### **The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**
2408.07702v1 by Karime Maamari, Fadhil Abubaker, Daniel Jaroslawicz, Amine Mhedhbi

Schema linking is a crucial step in Text-to-SQL pipelines, which translate
natural language queries into SQL. The goal of schema linking is to retrieve
relevant tables and columns (signal) while disregarding irrelevant ones
(noise). However, imperfect schema linking can often exclude essential columns
needed for accurate query generation. In this work, we revisit the need for
schema linking when using the latest generation of large language models
(LLMs). We find empirically that newer models are adept at identifying relevant
schema elements during generation, without the need for explicit schema
linking. This allows Text-to-SQL pipelines to bypass schema linking entirely
and instead pass the full database schema to the LLM, eliminating the risk of
excluding necessary information. Furthermore, as alternatives to schema
linking, we propose techniques that improve Text-to-SQL accuracy without
compromising on essential schema information. Our approach achieves 71.83\%
execution accuracy on the BIRD benchmark, ranking first at the time of
submission.

摘要：模式連結是文字轉 SQL 管線中至關重要的一步，它將自然語言查詢轉換成 SQL。模式連結的目標是擷取相關的表格和欄位（訊號），同時忽略不相關的（雜訊）。然而，不完美的模式連結通常會排除產生精準查詢所需的必要欄位。在這項工作中，我們重新探討在使用最新一代大型語言模型（LLM）時模式連結的必要性。我們在經驗上發現，較新的模型在產生過程中很擅長識別相關的模式元素，而不需要明確的模式連結。這允許文字轉 SQL 管線完全繞過模式連結，而將完整的資料庫模式傳遞給 LLM，消除了排除必要資訊的風險。此外，作為模式連結的替代方案，我們提出了一些技術，可以在不損害必要模式資訊的情況下提高文字轉 SQL 的準確性。我們的做法在 BIRD 基準上達到了 71.83% 的執行準確度，在提交時排名第一。

##### **Quantifying over Optimum Answer Sets**
2408.07697v1 by Giuseppe Mazzotta, Francesco Ricca, Mirek Truszczynski

Answer Set Programming with Quantifiers (ASP(Q)) has been introduced to
provide a natural extension of ASP modeling to problems in the polynomial
hierarchy (PH). However, ASP(Q) lacks a method for encoding in an elegant and
compact way problems requiring a polynomial number of calls to an oracle in
$\Sigma_n^p$ (that is, problems in $\Delta_{n+1}^p$). Such problems include, in
particular, optimization problems. In this paper we propose an extension of
ASP(Q), in which component programs may contain weak constraints. Weak
constraints can be used both for expressing local optimization within
quantified component programs and for modeling global optimization criteria. We
showcase the modeling capabilities of the new formalism through various
application scenarios. Further, we study its computational properties obtaining
complexity results and unveiling non-obvious characteristics of ASP(Q) programs
with weak constraints.

摘要：回答集程式設計與量詞 (ASP(Q)) 已被引入，以提供 ASP 建模到多項式階層 (PH) 問題的自然延伸。然而，ASP(Q) 缺乏一種方法，可以用優雅且簡潔的方式對需要對 $\Sigma_n^p$ 中的預言機進行多項式次數呼叫的問題進行編碼（也就是說，$\Delta_{n+1}^p$ 中的問題）。此類問題特別包括最佳化問題。在本文中，我們提出 ASP(Q) 的延伸，其中組成程式可以包含弱約束。弱約束可以用於表達量化組成程式中的局部最佳化，以及用於建模全域最佳化準則。我們透過各種應用場景展示新形式化的建模能力。此外，我們研究其計算性質，取得複雜度結果，並揭示具有弱約束的 ASP(Q) 程式的非顯著特徵。

##### **End-to-end Semantic-centric Video-based Multimodal Affective Computing**
2408.07694v1 by Ronghao Lin, Ying Zeng, Sijie Mai, Haifeng Hu

In the pathway toward Artificial General Intelligence (AGI), understanding
human's affection is essential to enhance machine's cognition abilities. For
achieving more sensual human-AI interaction, Multimodal Affective Computing
(MAC) in human-spoken videos has attracted increasing attention. However,
previous methods are mainly devoted to designing multimodal fusion algorithms,
suffering from two issues: semantic imbalance caused by diverse pre-processing
operations and semantic mismatch raised by inconsistent affection content
contained in different modalities comparing with the multimodal ground truth.
Besides, the usage of manual features extractors make they fail in building
end-to-end pipeline for multiple MAC downstream tasks. To address above
challenges, we propose a novel end-to-end framework named SemanticMAC to
compute multimodal semantic-centric affection for human-spoken videos. We
firstly employ pre-trained Transformer model in multimodal data pre-processing
and design Affective Perceiver module to capture unimodal affective
information. Moreover, we present a semantic-centric approach to unify
multimodal representation learning in three ways, including gated feature
interaction, multi-task pseudo label generation, and intra-/inter-sample
contrastive learning. Finally, SemanticMAC effectively learn specific- and
shared-semantic representations in the guidance of semantic-centric labels.
Extensive experimental results demonstrate that our approach surpass the
state-of-the-art methods on 7 public datasets in four MAC downstream tasks.

摘要：在通往人工通用智能 (AGI) 的道路上，理解人类的情感对于增强机器的认知能力至关重要。为了实现更感性的的人机交互，人类语音视频中的多模态情感计算 (MAC) 吸引了越来越多的关注。然而，以前的方法主要致力于设计多模态融合算法，存在两个问题：由不同的预处理操作导致的语义不平衡以及与多模态基本事实相比，不同模态中包含的不一致情感内容导致的语义不匹配。此外，手动特征提取器的使用使得它们无法为多个 MAC 下游任务构建端到端管道。为了解决上述挑战，我们提出了一种名为 SemanticMAC 的新颖端到端框架，用于计算人类语音视频的多模态语义中心情感。我们首先在多模态数据预处理中采用预训练的 Transformer 模型，并设计情感感知器模块来捕获单模态情感信息。此外，我们提出了一种语义中心方法，通过门控特征交互、多任务伪标签生成以及样本内/样本间对比学习这三种方式来统一多模态表示学习。最后，SemanticMAC 在语义中心标签的指导下有效地学习特定和共享语义表示。广泛的实验结果表明，我们的方法在四个 MAC 下游任务的 7 个公共数据集上超越了最先进的方法。

##### **A Spitting Image: Modular Superpixel Tokenization in Vision Transformers**
2408.07680v2 by Marius Aasan, Odd Kolbjørnsen, Anne Schistad Solberg, Adín Ramirez Rivera

Vision Transformer (ViT) architectures traditionally employ a grid-based
approach to tokenization independent of the semantic content of an image. We
propose a modular superpixel tokenization strategy which decouples tokenization
and feature extraction; a shift from contemporary approaches where these are
treated as an undifferentiated whole. Using on-line content-aware tokenization
and scale- and shape-invariant positional embeddings, we perform experiments
and ablations that contrast our approach with patch-based tokenization and
randomized partitions as baselines. We show that our method significantly
improves the faithfulness of attributions, gives pixel-level granularity on
zero-shot unsupervised dense prediction tasks, while maintaining predictive
performance in classification tasks. Our approach provides a modular
tokenization framework commensurable with standard architectures, extending the
space of ViTs to a larger class of semantically-rich models.

摘要：視覺轉換器 (ViT) 架構傳統上採用基於網格的方法進行標記化，而與影像的語義內容無關。我們提出一個模組化的超像素標記化策略，它解耦了標記化和特徵萃取；與將這些視為一個未區分的整體的當代方法不同。使用線上內容感知標記化和尺度及形狀不變的位置嵌入，我們執行實驗和消融，將我們的方法與基於修補程式的標記化和隨機分割作為基準進行對比。我們展示了我們的方法顯著提升了歸因的保真度，在零次學習無監督密集預測任務中提供了像素級粒度，同時在分類任務中維持預測效能。我們的方法提供了一個模組化的標記化架構，與標準架構相稱，將 ViT 的空間擴展到一類更大的語義豐富模型。

##### **Enhanced Detection of Conversational Mental Manipulation Through Advanced Prompting Techniques**
2408.07676v1 by Ivory Yang, Xiaobo Guo, Sean Xie, Soroush Vosoughi

This study presents a comprehensive, long-term project to explore the
effectiveness of various prompting techniques in detecting dialogical mental
manipulation. We implement Chain-of-Thought prompting with Zero-Shot and
Few-Shot settings on a binary mental manipulation detection task, building upon
existing work conducted with Zero-Shot and Few- Shot prompting. Our primary
objective is to decipher why certain prompting techniques display superior
performance, so as to craft a novel framework tailored for detection of mental
manipulation. Preliminary findings suggest that advanced prompting techniques
may not be suitable for more complex models, if they are not trained through
example-based learning.

摘要：本研究提出了一個全面、長期的專案，以探討各種提示技術在檢測對話式心理操縱中的有效性。我們在二元心理操縱檢測任務中實作了零次學習和少次學習設定下的思想鏈提示，並建立在使用零次學習和少次學習提示進行的既有工作之上。我們的首要目標是解碼為何某些提示技術表現出優異的效能，以便為檢測心理操縱量身打造一個新穎的架構。初步發現表明，如果進階提示技術未透過基於範例的學習進行訓練，則可能不適合更複雜的模型。

##### **Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data**
2408.07673v2 by Xia Jiang, Yijun Zhou, Chuhan Xu, Adam Brufsky, Alan Wells

A grid search, at the cost of training and testing a large number of models,
is an effective way to optimize the prediction performance of deep learning
models. A challenging task concerning grid search is the time management.
Without a good time management scheme, a grid search can easily be set off as a
mission that will not finish in our lifetime. In this study, we introduce a
heuristic three-stage mechanism for managing the running time of low-budget
grid searches, and the sweet-spot grid search (SSGS) and randomized grid search
(RGS) strategies for improving model prediction performance, in predicting the
5-year, 10-year, and 15-year risk of breast cancer metastasis. We develop deep
feedforward neural network (DFNN) models and optimize them through grid
searches. We conduct eight cycles of grid searches by applying our three-stage
mechanism and SSGS and RGS strategies. We conduct various SHAP analyses
including unique ones that interpret the importance of the DFNN-model
hyperparameters. Our results show that grid search can greatly improve model
prediction. The grid searches we conducted improved the risk prediction of
5-year, 10-year, and 15-year breast cancer metastasis by 18.6%, 16.3%, and
17.3% respectively, over the average performance of all corresponding models we
trained using the RGS strategy. We not only demonstrate best model performance
but also characterize grid searches from various aspects such as their
capabilities of discovering decent models and the unit grid search time. The
three-stage mechanism worked effectively. It made our low-budget grid searches
feasible and manageable, and in the meantime helped improve model prediction
performance. Our SHAP analyses identified both clinical risk factors important
for the prediction of future risk of breast cancer metastasis, and DFNN-model
hyperparameters important to the prediction of performance scores.

摘要：<paragraph>網格搜尋以訓練和測試大量模型為代價，是一種優化深度學習模型預測效能的有效方法。網格搜尋中一項具有挑戰性的任務是時間管理。沒有良好的時間管理機制，網格搜尋很容易被設定為一項在我們有生之年都無法完成的任務。在本研究中，我們介紹了一種啟發式三階段機制，用於管理低預算網格搜尋的執行時間，以及用於改善模型預測效能的最佳點網格搜尋 (SSGS) 和隨機網格搜尋 (RGS) 策略，以預測乳癌轉移的 5 年、10 年和 15 年風險。我們開發了深度前饋神經網路 (DFNN) 模型，並透過網格搜尋對它們進行優化。我們透過應用三階段機制和 SSGS 和 RGS 策略進行了八個週期的網格搜尋。我們進行了各種 SHAP 分析，包括解釋 DFNN 模型超參數重要性的獨特分析。我們的結果顯示網格搜尋可以大幅改善模型預測。我們進行的網格搜尋分別將 5 年、10 年和 15 年乳癌轉移的風險預測改善了 18.6%、16.3% 和 17.3%，優於我們使用 RGS 策略訓練的所有對應模型的平均效能。我們不僅展示了最佳模型效能，還從各種面向描述網格搜尋，例如它們發現良好模型的能力和單元網格搜尋時間。三階段機制有效運作。它使我們的低預算網格搜尋可行且易於管理，同時也有助於改善模型預測效能。我們的 SHAP 分析確定了對預測未來乳癌轉移風險很重要的臨床風險因子，以及對預測效能評分很重要的 DFNN 模型超參數。</paragraph>

##### **Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**
2408.07666v2 by Enneng Yang, Li Shen, Guibing Guo, Xingwei Wang, Xiaochun Cao, Jie Zhang, Dacheng Tao

Model merging is an efficient empowerment technique in the machine learning
community that does not require the collection of raw training data and does
not require expensive computation. As model merging becomes increasingly
prevalent across various fields, it is crucial to understand the available
model merging techniques comprehensively. However, there is a significant gap
in the literature regarding a systematic and thorough review of these
techniques. This survey provides a comprehensive overview of model merging
methods and theories, their applications in various domains and settings, and
future research directions. Specifically, we first propose a new taxonomic
approach that exhaustively discusses existing model merging methods. Secondly,
we discuss the application of model merging techniques in large language
models, multimodal large language models, and 10+ machine learning subfields,
including continual learning, multi-task learning, few-shot learning, etc.
Finally, we highlight the remaining challenges of model merging and discuss
future research directions. A comprehensive list of papers about model merging
is available at
\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}.

摘要：模型合併是一種機器學習社群中有效能的賦能技術，不需要收集原始訓練資料，也不需要昂貴的計算。由於模型合併在各個領域日益盛行，因此全面了解現有的模型合併技術至關重要。然而，在對這些技術進行系統化且徹底的回顧方面，文獻中存在著顯著的空白。本調查提供了模型合併方法和理論的全面概述、它們在各種領域和設定中的應用，以及未來的研究方向。具體來說，我們首先提出了一種新的分類方法，對現有的模型合併方法進行了詳盡的討論。其次，我們討論了模型合併技術在大語言模型、多模態大語言模型和 10 多個機器學習子領域中的應用，包括持續學習、多任務學習、少量學習等。最後，我們強調了模型合併的剩餘挑戰，並討論了未來的研究方向。關於模型合併的論文清單可在以下網址取得：\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。

##### **Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**
2408.07665v1 by Yi-Cheng Lin, Wei-Chih Chen, Hung-yi Lee

Warning: This paper may contain texts with uncomfortable content.
  Large Language Models (LLMs) have achieved remarkable performance in various
tasks, including those involving multimodal data like speech. However, these
models often exhibit biases due to the nature of their training data. Recently,
more Speech Large Language Models (SLLMs) have emerged, underscoring the urgent
need to address these biases. This study introduces Spoken Stereoset, a dataset
specifically designed to evaluate social biases in SLLMs. By examining how
different models respond to speech from diverse demographic groups, we aim to
identify these biases. Our experiments reveal significant insights into their
performance and bias levels. The findings indicate that while most models show
minimal bias, some still exhibit slightly stereotypical or anti-stereotypical
tendencies.

摘要：警告：本文可能包含令人不適的內容。
大型語言模型 (LLM) 在各種任務中取得了顯著的表現，包括涉及多模態數據（例如語音）的任務。然而，這些模型由於其訓練數據的性質，往往會表現出偏見。最近，出現了更多語音大型語言模型 (SLLM)，強調了解決這些偏見的迫切需要。本研究引入了 Spoken Stereoset，這是一個專門設計用於評估 SLLM 中社會偏見的數據集。透過檢視不同模型如何回應來自不同人口群體的語音，我們旨在找出這些偏見。我們的實驗揭示了對其效能和偏見程度的重大見解。研究結果表明，儘管大多數模型顯示出最小的偏見，但有些模型仍然表現出輕微的刻板印象或反刻板印象傾向。

##### **Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**
2408.07663v1 by Quan Liu, Zhenhong Zhou, Longzhu He, Yi Liu, Wei Zhang, Sen Su

Large language models are susceptible to jailbreak attacks, which can result
in the generation of harmful content. While prior defenses mitigate these risks
by perturbing or inspecting inputs, they ignore competing objectives, the
underlying cause of alignment failures. In this paper, we propose
Alignment-Enhanced Decoding (AED), a novel defense that employs adaptive
decoding to address the root causes of jailbreak issues. We first define the
Competitive Index to quantify alignment failures and utilize feedback from
self-evaluation to compute post-alignment logits. Then, AED adaptively combines
AED and post-alignment logits with the original logits to obtain harmless and
helpful distributions. Consequently, our method enhances safety alignment while
maintaining helpfulness. We conduct experiments across five models and four
common jailbreaks, with the results validating the effectiveness of our
approach. Code is available at https://github.com/GIGABaozi/AED.git.

摘要：大型語言模型容易受到越獄攻擊，這可能會導致產生有害內容。雖然先前的防禦措施會透過擾動或檢查輸入來減輕這些風險，但它們會忽略競爭目標，也就是對齊失敗的根本原因。在這篇論文中，我們提出增強對齊解碼 (AED)，這是一種新穎的防禦措施，採用自適應解碼來解決越獄問題的根本原因。我們首先定義競爭指數來量化對齊失敗，並利用自我評估的回饋來計算後對齊 logit。然後，AED 自適應地將 AED 和後對齊 logit 與原始 logit 結合，以獲得無害且有用的分佈。因此，我們的模型增強了安全性對齊，同時保持了有益性。我們針對五個模型和四個常見的越獄進行了實驗，結果驗證了我們方法的有效性。程式碼可在 https://github.com/GIGABaozi/AED.git 取得。

##### **Boosting Unconstrained Face Recognition with Targeted Style Adversary**
2408.07642v1 by Mohammad Saeed Ebrahimi Saadabadi, Sahar Rahimi Malakshan, Seyed Rasoul Hosseini, Nasser M. Nasrabadi

While deep face recognition models have demonstrated remarkable performance,
they often struggle on the inputs from domains beyond their training data.
Recent attempts aim to expand the training set by relying on computationally
expensive and inherently challenging image-space augmentation of image
generation modules. In an orthogonal direction, we present a simple yet
effective method to expand the training data by interpolating between
instance-level feature statistics across labeled and unlabeled sets. Our
method, dubbed Targeted Style Adversary (TSA), is motivated by two
observations: (i) the input domain is reflected in feature statistics, and (ii)
face recognition model performance is influenced by style information. Shifting
towards an unlabeled style implicitly synthesizes challenging training
instances. We devise a recognizability metric to constraint our framework to
preserve the inherent identity-related information of labeled instances. The
efficacy of our method is demonstrated through evaluations on unconstrained
benchmarks, outperforming or being on par with its competitors while offering
nearly a 70\% improvement in training speed and 40\% less memory consumption.

摘要：儘管深度人臉辨識模型已展現出卓越的效能，
但它們在訓練資料以外的領域輸入中往往會遇到困難。
最近的嘗試旨在透過依賴於計算成本高且本質上具有挑戰性的影像空間擴充技術，來擴充訓練組，以擴充影像產生模組。在正交方向上，我們提出了一個簡單但有效的方法，透過插補標籤和未標籤組中的實例層級特徵統計資料，來擴充訓練資料。我們的這個方法稱為目標樣式對抗 (TSA)，其動機來自兩個觀察結果：(i) 輸入領域反映在特徵統計資料中，以及 (ii) 人臉辨識模型效能受到樣式資訊的影響。轉移到未標籤樣式會隱含地合成具有挑戰性的訓練實例。我們設計了一個可辨識度量數，以限制我們的架構，以保留標籤實例中與身分相關的固有資訊。我們的方法的效能透過在不受約束的基準上進行評估，證明了其效能，其效能優於或與競爭者不相上下，同時在訓練速度上提升了近 70%，記憶體消耗減少了 40%。

##### **Hierarchical Working Memory and a New Magic Number**
2408.07637v1 by Weishun Zhong, Mikhail Katkov, Misha Tsodyks

The extremely limited working memory span, typically around four items,
contrasts sharply with our everyday experience of processing much larger
streams of sensory information concurrently. This disparity suggests that
working memory can organize information into compact representations such as
chunks, yet the underlying neural mechanisms remain largely unknown. Here, we
propose a recurrent neural network model for chunking within the framework of
the synaptic theory of working memory. We showed that by selectively
suppressing groups of stimuli, the network can maintain and retrieve the
stimuli in chunks, hence exceeding the basic capacity. Moreover, we show that
our model can dynamically construct hierarchical representations within working
memory through hierarchical chunking. A consequence of this proposed mechanism
is a new limit on the number of items that can be stored and subsequently
retrieved from working memory, depending only on the basic working memory
capacity when chunking is not invoked. Predictions from our model were
confirmed by analyzing single-unit responses in epileptic patients and memory
experiments with verbal material. Our work provides a novel conceptual and
analytical framework for understanding the on-the-fly organization of
information in the brain that is crucial for cognition.

摘要：極度有限的工作記憶範圍，通常約為四個項目，與我們日常處理大量感官資訊流的經驗形成鮮明對比。這種差異表明工作記憶可以將資訊組織成緊湊的表示，例如塊，但其背後的神經機制在很大程度上仍然未知。在這裡，我們提出了一個遞迴神經網路模型，用於在工作記憶突觸理論的框架內進行分塊。我們表明，通過選擇性地抑制刺激組，網路可以維護和檢索塊中的刺激，從而超過基本容量。此外，我們表明我們的模型可以通過分層分塊在工作記憶中動態構建分層表示。這種提議機制的後果是對可以儲存並隨後從工作記憶中檢索的項目數量的新限制，僅取決於在未調用分塊時的基本工作記憶容量。通過分析癲癇患者的單元反應和使用言語材料的記憶實驗，證實了我們模型的預測。我們的研究提供了一個新的概念和分析框架，用於理解大腦中即時組織資訊，這對於認知至關重要。

##### **Drug Discovery SMILES-to-Pharmacokinetics Diffusion Models with Deep Molecular Understanding**
2408.07636v1 by Bing Hu, Anita Layton, Helen Chen

Artificial intelligence (AI) is increasingly used in every stage of drug
development. One challenge facing drug discovery AI is that drug
pharmacokinetic (PK) datasets are often collected independently from each
other, often with limited overlap, creating data overlap sparsity. Data
sparsity makes data curation difficult for researchers looking to answer
research questions in poly-pharmacy, drug combination research, and
high-throughput screening. We propose Imagand, a novel
SMILES-to-Pharmacokinetic (S2PK) diffusion model capable of generating an array
of PK target properties conditioned on SMILES inputs. We show that
Imagand-generated synthetic PK data closely resembles real data univariate and
bivariate distributions, and improves performance for downstream tasks. Imagand
is a promising solution for data overlap sparsity and allows researchers to
efficiently generate ligand PK data for drug discovery research. Code is
available at \url{https://github.com/bing1100/Imagand}.

摘要：人工智慧 (AI) 在藥物開發的每個階段中使用越來越廣泛。藥物發現 AI 面臨的其中一項挑戰是藥物藥物動力學 (PK) 資料集通常獨立收集，且重疊有限，造成資料重疊稀疏。資料稀疏性讓研究人員難以整理資料，以回答多重藥物治療、藥物組合研究和高通量篩選中的研究問題。我們提出 Imagand，這是一種新穎的 SMILES 轉藥物動力學 (S2PK) 擴散模型，能夠根據 SMILES 輸入產生一系列 PK 目標屬性。我們展示 Imagand 生成的合成 PK 資料與真實資料的單變量和雙變量分布非常相似，並改善下游任務的效能。Imagand 是一個有望解決資料重疊稀疏性的解決方案，讓研究人員能夠有效率地產生配體 PK 資料，以進行藥物發現研究。程式碼可在 \url{https://github.com/bing1100/Imagand} 取得。

##### **Battery GraphNets : Relational Learning for Lithium-ion Batteries(LiBs) Life Estimation**
2408.07624v1 by Sakhinana Sagar Srinivas, Rajat Kumar Sarkar, Venkataramana Runkana

Battery life estimation is critical for optimizing battery performance and
guaranteeing minimal degradation for better efficiency and reliability of
battery-powered systems. The existing methods to predict the Remaining Useful
Life(RUL) of Lithium-ion Batteries (LiBs) neglect the relational dependencies
of the battery parameters to model the nonlinear degradation trajectories. We
present the Battery GraphNets framework that jointly learns to incorporate a
discrete dependency graph structure between battery parameters to capture the
complex interactions and the graph-learning algorithm to model the intrinsic
battery degradation for RUL prognosis. The proposed method outperforms several
popular methods by a significant margin on publicly available battery datasets
and achieves SOTA performance. We report the ablation studies to support the
efficacy of our approach.

摘要：電池壽命估計對於最佳化電池效能和確保最低劣化至關重要，以提升電池供電系統的效率和可靠性。現有的方法用於預測鋰離子電池 (LiB) 的剩餘使用壽命 (RUL)，卻忽略了電池參數的關聯性，無法建立非線性劣化軌跡模型。我們提出 Battery GraphNets 框架，可共同學習納入電池參數之間的離散依賴性圖形結構，以擷取複雜的交互作用，以及圖形學習演算法，以建立內在電池劣化模型，用於 RUL 預後。所提出的方法在公開的電池資料集上大幅優於多種常見方法，並達到 SOTA 效能。我們報告了消融研究，以支持我們方法的效能。

##### **WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**
2408.07611v1 by Weijian Xie, Xuefeng Liang, Yuhui Liu, Kaihua Ni, Hong Cheng, Zetian Hu

Large Language Models (LLMs) have greatly contributed to the development of
adaptive intelligent agents and are positioned as an important way to achieve
Artificial General Intelligence (AGI). However, LLMs are prone to produce
factually incorrect information and often produce "phantom" content that
undermines their reliability, which poses a serious challenge for their
deployment in real-world scenarios. Enhancing LLMs by combining external
databases and information retrieval mechanisms is an effective path. To address
the above challenges, we propose a new approach called WeKnow-RAG, which
integrates Web search and Knowledge Graphs into a "Retrieval-Augmented
Generation (RAG)" system. First, the accuracy and reliability of LLM responses
are improved by combining the structured representation of Knowledge Graphs
with the flexibility of dense vector retrieval. WeKnow-RAG then utilizes
domain-specific knowledge graphs to satisfy a variety of queries and domains,
thereby improving performance on factual information and complex reasoning
tasks by employing multi-stage web page retrieval techniques using both sparse
and dense retrieval methods. Our approach effectively balances the efficiency
and accuracy of information retrieval, thus improving the overall retrieval
process. Finally, we also integrate a self-assessment mechanism for the LLM to
evaluate the trustworthiness of the answers it generates. Our approach proves
its outstanding effectiveness in a wide range of offline experiments and online
submissions.

摘要：大型語言模型 (LLM) 對於自適應智慧代理的發展有很大的貢獻，並且被定位為實現人工通用智慧 (AGI) 的重要途徑。然而，LLM 容易產生事實上不正確的資訊，並且經常產生「幻影」內容，這會破壞它們的可靠性，對它們在現實世界場景中的部署構成嚴峻的挑戰。透過結合外部資料庫和資訊檢索機制來增強 LLM 是一條有效的路徑。為了應對上述挑戰，我們提出了一種稱為 WeKnow-RAG 的新方法，它將網路搜尋和知識圖譜整合到「檢索增強產生 (RAG)」系統中。首先，透過結合知識圖譜的結構化表示和密集向量檢索的靈活性，提高了 LLM 回應的準確性和可靠性。WeKnow-RAG 接著利用特定領域的知識圖譜來滿足各種查詢和領域，從而透過使用稀疏和密集檢索方法的多階段網頁檢索技術，改善事實資訊和複雜推理任務的效能。我們的做法有效地平衡了資訊檢索的效率和準確性，從而改善了整體檢索流程。最後，我們也為 LLM 整合了一個自我評估機制，以評估它所產生答案的可信度。我們的做法在廣泛的離線實驗和線上提交中證明了其傑出的有效性。

##### **Assessing the Role of Lexical Semantics in Cross-lingual Transfer through Controlled Manipulations**
2408.07599v1 by Roy Ilani, Taelin Karidi, Omri Abend

While cross-linguistic model transfer is effective in many settings, there is
still limited understanding of the conditions under which it works. In this
paper, we focus on assessing the role of lexical semantics in cross-lingual
transfer, as we compare its impact to that of other language properties.
Examining each language property individually, we systematically analyze how
differences between English and a target language influence the capacity to
align the language with an English pretrained representation space. We do so by
artificially manipulating the English sentences in ways that mimic specific
characteristics of the target language, and reporting the effect of each
manipulation on the quality of alignment with the representation space. We show
that while properties such as the script or word order only have a limited
impact on alignment quality, the degree of lexical matching between the two
languages, which we define using a measure of translation entropy, greatly
affects it.

摘要：儘管跨語言模型轉移在許多情況下有效，但對於其運作條件的了解仍然有限。在本文中，我們專注於評估詞彙語義在跨語言轉移中的作用，並將其影響與其他語言屬性的影響進行比較。單獨檢視各語言屬性，我們系統性地分析英語和目標語言之間的差異如何影響將語言與英語預訓練表示空間對齊的能力。我們透過人為地操縱英語句子，使其模擬目標語言的特定特徵，並報告每個操縱對與表示空間對齊品質的影響。我們表明，儘管腳本或字序等屬性對對齊品質的影響有限，但我們使用轉譯熵度量定義的兩種語言之間的詞彙匹配程度會對其產生很大影響。

##### **Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**
2408.07583v1 by Hamza Kheddar

With significant advancements in Transformers LLMs, NLP has extended its
reach into many research fields due to its enhanced capabilities in text
generation and user interaction. One field benefiting greatly from these
advancements is cybersecurity. In cybersecurity, many parameters that need to
be protected and exchanged between senders and receivers are in the form of
text and tabular data, making NLP a valuable tool in enhancing the security
measures of communication protocols. This survey paper provides a comprehensive
analysis of the utilization of Transformers and LLMs in cyber-threat detection
systems. The methodology of paper selection and bibliometric analysis is
outlined to establish a rigorous framework for evaluating existing research.
The fundamentals of Transformers are discussed, including background
information on various cyber-attacks and datasets commonly used in this field.
The survey explores the application of Transformers in IDSs, focusing on
different architectures such as Attention-based models, LLMs like BERT and GPT,
CNN/LSTM-Transformer hybrids, emerging approaches like ViTs, among others.
Furthermore, it explores the diverse environments and applications where
Transformers and LLMs-based IDS have been implemented, including computer
networks, IoT devices, critical infrastructure protection, cloud computing,
SDN, as well as in autonomous vehicles. The paper also addresses research
challenges and future directions in this area, identifying key issues such as
interpretability, scalability, and adaptability to evolving threats, and more.
Finally, the conclusion summarizes the findings and highlights the significance
of Transformers and LLMs in enhancing cyber-threat detection capabilities,
while also outlining potential avenues for further research and development.

摘要：<paragraph>隨著 Transformers LLM 的顯著進步，NLP 憑藉其在文本生成和使用者互動方面的增強功能，已將其影響力擴展到許多研究領域。受益於這些進展的一個領域是網路安全。在網路安全中，許多需要在發送者和接收者之間保護和交換的參數都是以文字和表格數據的形式存在的，這使得 NLP 成為增強通信協定安全措施的寶貴工具。這篇調查報告全面分析了 Transformer 和 LLM 在網路威脅偵測系統中的應用。概述了論文選擇和書目分析的方法，以建立一個嚴謹的框架來評估現有的研究。討論了 Transformer 的基礎知識，包括關於各種網路攻擊和此領域常用的資料集的背景資訊。這項調查探討了 Transformer 在 IDS 中的應用，重點關注基於注意力的模型、如 BERT 和 GPT 等 LLM、CNN/LSTM-Transformer 混合模型、ViT 等新興方法。此外，它還探討了 Transformer 和基於 LLM 的 IDS 已被實作的不同環境和應用，包括電腦網路、IoT 裝置、關鍵基礎設施保護、雲端運算、SDN，以及自駕車。這篇論文也探討了這個領域的研究挑戰和未來方向，找出關鍵問題，例如可解釋性、可擴充性、對不斷變化的威脅的適應性，等等。最後，結論總結了研究結果，並強調了 Transformer 和 LLM 在增強網路威脅偵測能力方面的意義，同時也概述了進一步研究和開發的潛在途徑。</paragraph>

##### **Multi-task Heterogeneous Graph Learning on Electronic Health Records**
2408.07569v1 by Tsai Hor Chan, Guosheng Yin, Kyongtae Bae, Lequan Yu

Learning electronic health records (EHRs) has received emerging attention
because of its capability to facilitate accurate medical diagnosis. Since the
EHRs contain enriched information specifying complex interactions between
entities, modeling EHRs with graphs is shown to be effective in practice. The
EHRs, however, present a great degree of heterogeneity, sparsity, and
complexity, which hamper the performance of most of the models applied to them.
Moreover, existing approaches modeling EHRs often focus on learning the
representations for a single task, overlooking the multi-task nature of EHR
analysis problems and resulting in limited generalizability across different
tasks. In view of these limitations, we propose a novel framework for EHR
modeling, namely MulT-EHR (Multi-Task EHR), which leverages a heterogeneous
graph to mine the complex relations and model the heterogeneity in the EHRs. To
mitigate the large degree of noise, we introduce a denoising module based on
the causal inference framework to adjust for severe confounding effects and
reduce noise in the EHR data. Additionally, since our model adopts a single
graph neural network for simultaneous multi-task prediction, we design a
multi-task learning module to leverage the inter-task knowledge to regularize
the training process. Extensive empirical studies on MIMIC-III and MIMIC-IV
datasets validate that the proposed method consistently outperforms the
state-of-the-art designs in four popular EHR analysis tasks -- drug
recommendation, and predictions of the length of stay, mortality, and
readmission. Thorough ablation studies demonstrate the robustness of our method
upon variations to key components and hyperparameters.

摘要：<paragraph>學習電子健康紀錄（EHR）由於其促進準確醫療診斷的能力而備受關注。由於 EHR 包含豐富資訊，指定實體之間的複雜互動，因此使用圖形建模 EHR 已被證明在實務上很有效。然而，EHR 呈現出高度的異質性、稀疏性和複雜性，這會阻礙應用於它們的大多數模型的效能。此外，現有的建模 EHR 方法通常專注於學習單一任務的表示，忽略 EHR 分析問題的多任務性質，並導致跨不同任務的概括能力有限。有鑑於這些限制，我們提出了 EHR 建模的新架構，即 MulT-EHR（多任務 EHR），它利用異質圖來挖掘複雜關係並建模 EHR 中的異質性。為了減輕大量的雜訊，我們引入了基於因果推論架構的去雜訊模組，以調整嚴重的混淆效應並減少 EHR 資料中的雜訊。此外，由於我們的模型採用單一圖形神經網路進行同時的多任務預測，因此我們設計了一個多任務學習模組，以利用任務間的知識來規範訓練過程。在 MIMIC-III 和 MIMIC-IV 資料集上的廣泛實證研究驗證了所提出的方法在四項流行的 EHR 分析任務中始終優於最先進的設計——藥物推薦以及預測住院時間、死亡率和再入院率。徹底的消融研究證明了我們的方法在關鍵組成部分和超參數變化上的穩健性。</paragraph>

##### **PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation**
2408.07547v1 by Sang-Hoon Lee, Ha-Yeong Choi, Seong-Whan Lee

Recently, universal waveform generation tasks have been investigated
conditioned on various out-of-distribution scenarios. Although GAN-based
methods have shown their strength in fast waveform generation, they are
vulnerable to train-inference mismatch scenarios such as two-stage
text-to-speech. Meanwhile, diffusion-based models have shown their powerful
generative performance in other domains; however, they stay out of the
limelight due to slow inference speed in waveform generation tasks. Above all,
there is no generator architecture that can explicitly disentangle the natural
periodic features of high-resolution waveform signals. In this paper, we
propose PeriodWave, a novel universal waveform generation model. First, we
introduce a period-aware flow matching estimator that can capture the periodic
features of the waveform signal when estimating the vector fields.
Additionally, we utilize a multi-period estimator that avoids overlaps to
capture different periodic features of waveform signals. Although increasing
the number of periods can improve the performance significantly, this requires
more computational costs. To reduce this issue, we also propose a single
period-conditional universal estimator that can feed-forward parallel by
period-wise batch inference. Additionally, we utilize discrete wavelet
transform to losslessly disentangle the frequency information of waveform
signals for high-frequency modeling, and introduce FreeU to reduce the
high-frequency noise for waveform generation. The experimental results
demonstrated that our model outperforms the previous models both in
Mel-spectrogram reconstruction and text-to-speech tasks. All source code will
be available at \url{https://github.com/sh-lee-prml/PeriodWave}.

摘要：<paragraph>最近，针对各种分布外情境，对通用波形生成任务进行了调查。尽管基于 GAN 的方法在快速波形生成方面显示出其优势，但它们容易受到训练推理不匹配的情况的影响，例如两阶段文本到语音。与此同时，基于扩散的模型在其他领域展示了其强大的生成性能；然而，由于在波形生成任务中的推理速度较慢，它们并未受到关注。最重要的是，没有生成器架构可以明确地区分高分辨率波形信号的自然周期性特征。在本文中，我们提出了 PeriodWave，一种新颖的通用波形生成模型。首先，我们引入了一个周期感知流匹配估计器，它可以在估计矢量场时捕获波形信号的周期性特征。此外，我们利用了一个多周期估计器，避免重叠以捕获波形信号的不同周期性特征。尽管增加周期数可以显着提高性能，但这需要更多的计算成本。为了减少这个问题，我们还提出了一个单周期条件通用估计器，它可以通过周期性批处理推理进行前馈并行。此外，我们利用离散小波变换无损地解开波形信号的频率信息以进行高频建模，并引入 FreeU 以减少波形生成的噪声。实验结果表明，我们的模型在 Mel 谱图重建和文本到语音任务中都优于之前的模型。所有源代码都可以在 \url{https://github.com/sh-lee-prml/PeriodWave} 获得。</paragraph>

##### **Planning with OWL-DL Ontologies (Extended Version)**
2408.07544v1 by Tobias John, Patrick Koopmann

We introduce ontology-mediated planning, in which planning problems are
combined with an ontology. Our formalism differs from existing ones in that we
focus on a strong separation of the formalisms for describing planning problems
and ontologies, which are only losely coupled by an interface. Moreover, we
present a black-box algorithm that supports the full expressive power of OWL
DL. This goes beyond what existing approaches combining automated planning with
ontologies can do, which only support limited description logics such as
DL-Lite and description logics that are Horn. Our main algorithm relies on
rewritings of the ontology-mediated planning specifications into PDDL, so that
existing planning systems can be used to solve them. The algorithm relies on
justifications, which allows for a generic approach that is independent of the
expressivity of the ontology language. However, dedicated optimizations for
computing justifications need to be implemented to enable an efficient
rewriting procedure. We evaluated our implementation on benchmark sets from
several domains. The evaluation shows that our procedure works in practice and
that tailoring the reasoning procedure has significant impact on the
performance.

摘要：<paragraph>我們引入了基於本體的規劃，其中規劃問題與本體相結合。我們的形式主義不同於現有的形式主義，因為我們專注於描述規劃問題和本體的形式主義的強分離，它們僅通過介面鬆散耦合。此外，我們提出了一個黑盒演算法，它支援 OWL DL 的完整表達能力。這超出了將自動規劃與本體相結合的現有方法所能做到的，它僅支援有限的描述邏輯，例如 DL-Lite 和 Horn 描述邏輯。我們的演算法主要依賴於將基於本體的規劃規範重寫為 PDDL，以便現有的規劃系統可以用於解決它們。該演算法依賴於證明，這允許一種通用的方法，該方法獨立於本體語言的表達能力。但是，需要實作專門的最佳化來計算證明，以實現有效的重寫程序。我們在來自多個領域的基準集上評估了我們的實作。評估表明，我們的程序在實務上可行，而且調整推理程序對效能有顯著影響。</paragraph>

##### **MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**
2408.07543v2 by Minxuan Zhou, Hao Liang, Tianpeng Li, Zhiyu Wu, Mingan Lin, Linzhuang Sun, Yaqi Zhou, Yan Zhang, Xiaoqin Huang, Yicong Chen, Yujing Qiao, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou

With the development of Multimodal Large Language Models (MLLMs), the
evaluation of multimodal models in the context of mathematical problems has
become a valuable research field. Multimodal visual-textual mathematical
reasoning serves as a critical indicator for evaluating the comprehension and
complex multi-step quantitative reasoning abilities of MLLMs. However, previous
multimodal math benchmarks have not sufficiently integrated visual and textual
information. To address this gap, we proposed MathScape, a new benchmark that
emphasizes the understanding and application of combined visual and textual
information. MathScape is designed to evaluate photo-based math problem
scenarios, assessing the theoretical understanding and application ability of
MLLMs through a categorical hierarchical approach. We conduct a
multi-dimensional evaluation on 11 advanced MLLMs, revealing that our benchmark
is challenging even for the most sophisticated models. By analyzing the
evaluation results, we identify the limitations of MLLMs, offering valuable
insights for enhancing model performance.

摘要：隨著多模態大型語言模型 (MLLM) 的發展，在數學問題背景下對多模態模型的評估已成為一個有價值的研究領域。多模態視覺文本數學推理作為評估 MLLM 的理解力和複雜的多步驟量化推理能力的重要指標。然而，先前的多模態數學基準並未充分整合視覺和文本資訊。為了解決這個差距，我們提出了 MathScape，一個新的基準，強調理解和應用視覺和文本資訊的結合。MathScape 被設計用來評估基於照片的數學問題場景，透過一個分類的階層式方法評估 MLLM 的理論理解和應用能力。我們對 11 個先進的 MLLM 進行多維評估，揭示我們的基準即使對於最精密的模型來說也是具有挑戰性的。透過分析評估結果，我們找出 MLLM 的限制，為提升模型效能提供有價值的見解。

##### **New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**
2408.07542v1 by Simon Kloker, Herbertson Bukoli, Twaha Kateete

Introduction: Poor educational quality in Secondary Schools is still regarded
as one of the major struggles in 21st century Uganda - especially in rural
areas. Research identifies several problems, including low quality or absent
teacher lesson planning. As the government pushes towards the implementation of
a new curriculum, exiting lesson plans become obsolete and the problem is
worsened. Using a Retrieval Augmented Generation approach, we developed a
prototype that generates customized lesson plans based on the
government-accredited textbooks. This helps teachers create lesson plans more
efficiently and with better quality, ensuring they are fully aligned the new
curriculum and the competence-based learning approach.
  Methods: The prototype was created using Cohere LLM and Sentence Embeddings,
and LangChain Framework - and thereafter made available on a public website.
Vector stores were trained for three new curriculum textbooks (ICT,
Mathematics, History), all at Secondary 1 Level. Twenty-four lessons plans were
generated following a pseudo-random generation protocol, based on the suggested
periods in the textbooks. The lesson plans were analyzed regarding their
technical quality by three independent raters following the Lesson Plan
Analysis Protocol (LPAP) by Ndihokubwayo et al. (2022) that is specifically
designed for East Africa and competence-based curriculums.
  Results: Evaluation of 24 lesson plans using the LPAP resulted in an average
quality of between 75 and 80%, corresponding to "very good lesson plan". None
of the lesson plans scored below 65%, although one lesson plan could be argued
to have been missing the topic. In conclusion, the quality of the generated
lesson plans is at least comparable, if not better, than those created by
humans, as demonstrated in a study in Rwanda, whereby no lesson plan even
reached the benchmark of 50%.

摘要：<paragraph>引言：烏干達 21 世紀的二級學校教育品質不佳，至今仍被視為主要難題之一，尤其是在農村地區。研究指出有許多問題，包含品質不佳或缺乏教學計畫。隨著政府推動實施新課程，現有的教學計畫已過時，問題也隨之惡化。我們使用檢索擴充產生方式，開發了一個原型，可根據政府認可的教科書產生客製化教學計畫。這能協助教師更有效率且品質更好的建立教學計畫，確保與新課程和能力基礎學習方式完全一致。
方法：這個原型使用 Cohere LLM 和句子嵌入，以及 LangChain 架構所建立，之後再公開於網站上。針對三本新的課程教科書（資訊與通訊技術、數學、歷史），全部在中學一年級的程度，訓練了向量儲存。根據教科書中建議的時段，遵循偽隨機產生協定產生了 24 個教學計畫。三個獨立評分員根據 Ndihokubwayo 等人（2022 年）的教學計畫分析協定（LPAP）分析教學計畫的技術品質，該協定特別設計用於東非和能力基礎課程。
結果：使用 LPAP 評估 24 個教學計畫，平均品質介於 75% 到 80%，相當於「非常好的教學計畫」。沒有教學計畫的分數低於 65%，儘管有人認為有一個教學計畫遺漏了主題。結論是，產生的教學計畫品質至少與人類建立的相當，甚至更好，正如盧安達的一項研究所示，沒有任何教學計畫達到 50% 的基準。</paragraph>

##### **DifuzCam: Replacing Camera Lens with a Mask and a Diffusion Model**
2408.07541v1 by Erez Yosef, Raja Giryes

The flat lensless camera design reduces the camera size and weight
significantly. In this design, the camera lens is replaced by another optical
element that interferes with the incoming light. The image is recovered from
the raw sensor measurements using a reconstruction algorithm. Yet, the quality
of the reconstructed images is not satisfactory. To mitigate this, we propose
utilizing a pre-trained diffusion model with a control network and a learned
separable transformation for reconstruction. This allows us to build a
prototype flat camera with high-quality imaging, presenting state-of-the-art
results in both terms of quality and perceptuality. We demonstrate its ability
to leverage also textual descriptions of the captured scene to further enhance
reconstruction. Our reconstruction method which leverages the strong
capabilities of a pre-trained diffusion model can be used in other imaging
systems for improved reconstruction results.

摘要：扁平無鏡頭相機設計可大幅降低相機尺寸和重量。在此設計中，相機鏡頭由另一個會干擾入射光的元件所取代。影像透過使用重建演算法從原始感測器測量值中還原。然而，重建影像的品質並不令人滿意。為了改善這個問題，我們建議利用預先訓練的擴散模型，搭配控制網路和學習的分離轉換進行重建。這讓我們得以建構具備高品質影像的扁平相機原型，在品質和知覺上均呈現最先進的成果。我們展示其利用場景的文字描述進一步增強重建的能力。我們的重建方法利用預先訓練的擴散模型的強大功能，可應用於其他影像系統以改善重建成果。

##### **Cross-aware Early Fusion with Stage-divided Vision and Language Transformer Encoders for Referring Image Segmentation**
2408.07539v1 by Yubin Cho, Hyunwoo Yu, Suk-ju Kang

Referring segmentation aims to segment a target object related to a natural
language expression. Key challenges of this task are understanding the meaning
of complex and ambiguous language expressions and determining the relevant
regions in the image with multiple objects by referring to the expression.
Recent models have focused on the early fusion with the language features at
the intermediate stage of the vision encoder, but these approaches have a
limitation that the language features cannot refer to the visual information.
To address this issue, this paper proposes a novel architecture, Cross-aware
early fusion with stage-divided Vision and Language Transformer encoders
(CrossVLT), which allows both language and vision encoders to perform the early
fusion for improving the ability of the cross-modal context modeling. Unlike
previous methods, our method enables the vision and language features to refer
to each other's information at each stage to mutually enhance the robustness of
both encoders. Furthermore, unlike the conventional scheme that relies solely
on the high-level features for the cross-modal alignment, we introduce a
feature-based alignment scheme that enables the low-level to high-level
features of the vision and language encoders to engage in the cross-modal
alignment. By aligning the intermediate cross-modal features in all encoder
stages, this scheme leads to effective cross-modal fusion. In this way, the
proposed approach is simple but effective for referring image segmentation, and
it outperforms the previous state-of-the-art methods on three public
benchmarks.

摘要：參考分割旨在區隔與自然語言表達相關的目標物件。此任務的主要挑戰在於理解複雜且模稜兩可的語言表達，並根據表達來決定影像中有多個物件時相關區域。最近的模型專注於在視覺編碼器的中間階段與語言特徵進行早期融合，但這些方法有一個限制，即語言特徵無法參考視覺資訊。為了解決這個問題，本文提出了一種新穎的架構，即在階段劃分的視覺和語言轉換器編碼器（CrossVLT）中進行跨感知的早期融合，這允許語言和視覺編碼器執行早期融合以提升跨模態情境建模的能力。與先前的做法不同，我們的做法使視覺和語言特徵能夠在每個階段參考彼此的資訊，以相互提升兩個編碼器的穩健性。此外，與僅依賴高層級特徵進行跨模態對齊的傳統方案不同，我們引入了一個基於特徵的對齊方案，使視覺和語言編碼器的低層級到高層級特徵能夠參與跨模態對齊。透過在所有編碼器階段對齊中間跨模態特徵，此方案可帶來有效的跨模態融合。透過這種方式，所提出的方法對於參考影像分割來說既簡單又有效，而且在三個公開基準上優於先前的最先進方法。

##### **Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**
2408.07531v1 by Seungjun Han, Wongyung Choi

Emergency department (ED) overcrowding and the complexity of rapid
decision-making in critical care settings pose significant challenges to
healthcare systems worldwide. While clinical decision support systems (CDSS)
have shown promise, the integration of large language models (LLMs) offers new
possibilities for enhancing triage accuracy and clinical decision-making. This
study presents an LLM-driven CDSS designed to assist ED physicians and nurses
in patient triage, treatment planning, and overall emergency care management.
  We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM,
orchestrated by CrewAI and Langchain. The system comprises four AI agents
emulating key ED roles: Triage Nurse, Emergency Physician, Pharmacist, and ED
Coordinator. It incorporates the Korean Triage and Acuity Scale (KTAS) for
triage assessment and integrates with the RxNorm API for medication management.
  The model was evaluated using the Asclepius dataset, with performance
assessed by a clinical emergency medicine specialist. The CDSS demonstrated
high accuracy in triage decision-making compared to the baseline of a
single-agent system. Furthermore, the system exhibited strong performance in
critical areas, including primary diagnosis, critical findings identification,
disposition decision-making, treatment planning, and resource allocation.
  Our multi-agent CDSS demonstrates significant potential for supporting
comprehensive emergency care management. By leveraging state-of-the-art AI
technologies, this system offers a scalable and adaptable tool that could
enhance emergency medical care delivery, potentially alleviating ED
overcrowding and improving patient outcomes. This work contributes to the
growing field of AI applications in emergency medicine and offers a promising
direction for future research and clinical implementation.

摘要：<paragraph>急診室（ED）人滿為患，以及在重症照護環境中快速做決定的複雜性對全球的醫療保健系統構成重大挑戰。雖然臨床決策支援系統（CDSS）已展現前景，但大型語言模型（LLM）的整合為提升分流準確度和臨床決策提供了新的可能性。本研究提出一個由 LLM 驅動的 CDSS，旨在協助急診室醫師和護理師進行病人分流、治療計畫和整體緊急照護管理。
  我們開發了一個多重代理 CDSS，利用 Llama-3-70b 作為基礎 LLM，由 CrewAI 和 Langchain 編排。此系統包含四個模擬關鍵急診室角色的 AI 代理：分流護理師、急診醫師、藥師和急診室協調員。它整合韓國分流與嚴重指數量表（KTAS）進行分流評估，並與 RxNorm API 整合進行藥物管理。
  該模型使用 Asclepius 資料集進行評估，由臨床急診醫學專家評估其效能。與單一代理系統的基準相比，CDSS 在分流決策方面展現高準確度。此外，該系統在主要診斷、關鍵發現識別、處置決策、治療計畫和資源分配等關鍵領域表現出色。
  我們的多重代理 CDSS 證明了在支援全面的緊急照護管理方面具有顯著的潛力。透過利用最先進的 AI 技術，此系統提供了一個可擴充且可適應的工具，可以提升緊急醫療照護的提供，進而可能緩解急診室人滿為患的情況並改善病患的預後。這項工作促進了 AI 在急診醫學中的應用領域，並為未來的研究和臨床實作提供了有前景的方向。</paragraph>

##### **Evidential Graph Contrastive Alignment for Source-Free Blending-Target Domain Adaptation**
2408.07527v1 by Juepeng Zheng, Yibin Wen, Jinxiao Zhang, Runmin Dong, Haohuan Fu

In this paper, we firstly tackle a more realistic Domain Adaptation (DA)
setting: Source-Free Blending-Target Domain Adaptation (SF-BTDA), where we can
not access to source domain data while facing mixed multiple target domains
without any domain labels in prior. Compared to existing DA scenarios, SF-BTDA
generally faces the co-existence of different label shifts in different
targets, along with noisy target pseudo labels generated from the source model.
In this paper, we propose a new method called Evidential Contrastive Alignment
(ECA) to decouple the blending target domain and alleviate the effect from
noisy target pseudo labels. First, to improve the quality of pseudo target
labels, we propose a calibrated evidential learning module to iteratively
improve both the accuracy and certainty of the resulting model and adaptively
generate high-quality pseudo target labels. Second, we design a graph
contrastive learning with the domain distance matrix and confidence-uncertainty
criterion, to minimize the distribution gap of samples of a same class in the
blended target domains, which alleviates the co-existence of different label
shifts in blended targets. We conduct a new benchmark based on three standard
DA datasets and ECA outperforms other methods with considerable gains and
achieves comparable results compared with those that have domain labels or
source data in prior.

摘要：在本文中，我们首先解决一个更贴近现实的领域自适应 (DA) 设置：无源混合目标领域自适应 (SF-BTDA)，其中我们无法访问源领域数据，同时面临混合多个目标领域，且事先没有任何领域标签。与现有的 DA 场景相比，SF-BTDA 通常面临不同目标中标签偏移并存的问题，以及从源模型生成的噪声目标伪标签。在本文中，我们提出了一种称为证据对比对齐 (ECA) 的新方法，以解耦混合目标域并减轻噪声目标伪标签的影响。首先，为了提高伪目标标签的质量，我们提出了一种校准的证据学习模块，以迭代方式提高所得模型的准确性和确定性，并自适应地生成高质量的伪目标标签。其次，我们设计了一个具有域距离矩阵和置信度不确定性准则的图对比学习，以最小化混合目标域中同一类样本的分布差距，从而减轻混合目标中不同标签偏移的并存。我们基于三个标准 DA 数据集进行了新的基准测试，ECA 以相当大的增益优于其他方法，并且与事先具有领域标签或源数据的方法相比取得了相当的结果。

##### **Fast Inference for Probabilistic Answer Set Programs via the Residual Program**
2408.07524v1 by Damiano Azzolini, Fabrizio Riguzzi

When we want to compute the probability of a query from a Probabilistic
Answer Set Program, some parts of a program may not influence the probability
of a query, but they impact on the size of the grounding. Identifying and
removing them is crucial to speed up the computation. Algorithms for SLG
resolution offer the possibility of returning the residual program which can be
used for computing answer sets for normal programs that do have a total
well-founded model. The residual program does not contain the parts of the
program that do not influence the probability. In this paper, we propose to
exploit the residual program for performing inference. Empirical results on
graph datasets show that the approach leads to significantly faster inference.

摘要：当我们想要从概率性答案集程序计算查询的概率时，程序的某些部分可能不会影响查询的概率，但它们会影响基础的大小。识别并移除它们对于加快计算至关重要。SLG 分辨率算法提供了返回剩余程序的可能性，该程序可用于计算具有完全良好基础模型的普通程序的答案集。剩余程序不包含不影响概率的程序部分。在本文中，我们建议利用剩余程序来执行推理。在图数据集上的经验结果表明，该方法可以显著加快推理。

##### **Large Language Models Know What Makes Exemplary Contexts**
2408.07505v1 by Quanyu Long, Jianda Chen

In-context learning (ICL) has proven to be a significant capability with the
advancement of Large Language models (LLMs). By instructing LLMs using few-shot
demonstrative examples, ICL enables them to perform a wide range of tasks
without needing to update millions of parameters. This paper presents a unified
framework for LLMs that allows them to self-select influential in-context
examples to compose their contexts; self-rank candidates with different
demonstration compositions; self-optimize the demonstration selection and
ordering through reinforcement learning. Specifically, our method designs a
parameter-efficient retrieval head that generates the optimized demonstration
after training with rewards from LLM's own preference. Experimental results
validate the proposed method's effectiveness in enhancing ICL performance.
Additionally, our approach effectively identifies and selects the most
representative examples for the current task, and includes more diversity in
retrieval.

摘要：情境學習 (ICL) 已被證明是隨著大型語言模型 (LLM) 的進步而具有顯著能力。透過使用少量的示範範例來指導 LLM，ICL 讓它們能夠執行廣泛的任務，而無需更新數百萬個參數。本文針對 LLM 提出一個統一的架構，讓它們能夠自行選擇有影響力的情境範例來組成它們的語境；使用不同的示範組成對候選者進行自我排名；透過強化學習自我最佳化示範選擇和排序。具體來說，我們的模型設計了一個參數高效的檢索頭，在使用 LLM 自身偏好的獎勵進行訓練後，會產生最佳化的示範。實驗結果驗證了所提出的方法在增強 ICL 效能方面的有效性。此外，我們的做法有效地識別並選擇最能代表當前任務的範例，並在檢索中納入更多樣性。

##### **Training Overhead Ratio: A Practical Reliability Metric for Large Language Model Training Systems**
2408.07482v1 by Ning Lu, Qian Xie, Hao Zhang, Wenyi Fang, Yang Zheng, Jiantao Ma

Large Language Models (LLMs) are revolutionizing the AI industry with their
superior capabilities. Training these models requires large-scale GPU clusters
and significant computing time, leading to frequent failures that significantly
increase training costs. Despite its significance, this field lacks a metric
for evaluating reliability. In this work, we introduce a novel reliability
metric called \emph{Training Overhead Ratio} (TOR) to evaluate the reliability
of fault-tolerant LLM training systems. TOR is defined as the ratio of optimal
training time to the observed training time of a system, serving as a practical
tool for users to estimate the actual time required to train an LLM on a given
system. Furthermore, our investigation identifies the key factor for enhancing
reliability and present TOR equations for various types of failures encountered
in practice.

摘要：大型語言模型 (LLM) 以其卓越的能力革新了 AI 產業。訓練這些模型需要大規模的 GPU 集群和大量的運算時間，導致頻繁的故障，大幅增加訓練成本。儘管其重要性，這個領域卻缺乏用於評估可靠性的指標。在這項工作中，我們引入一個名為「訓練開銷比」(TOR) 的新可靠性指標，以評估容錯 LLM 訓練系統的可靠性。TOR 被定義為系統的最佳訓練時間與觀測訓練時間的比率，可作為使用者估計在給定系統上訓練 LLM 所需實際時間的實用工具。此外，我們的調查找出增強可靠性的關鍵因素，並針對實際中遇到的各種故障類型提出 TOR 方程式。

##### **A Study on Bias Detection and Classification in Natural Language Processing**
2408.07479v1 by Ana Sofia Evans, Helena Moniz, Luísa Coheur

Human biases have been shown to influence the performance of models and
algorithms in various fields, including Natural Language Processing. While the
study of this phenomenon is garnering focus in recent years, the available
resources are still relatively scarce, often focusing on different forms or
manifestations of biases. The aim of our work is twofold: 1) gather
publicly-available datasets and determine how to better combine them to
effectively train models in the task of hate speech detection and
classification; 2) analyse the main issues with these datasets, such as
scarcity, skewed resources, and reliance on non-persistent data. We discuss
these issues in tandem with the development of our experiments, in which we
show that the combinations of different datasets greatly impact the models'
performance.

摘要：人類偏見已被證實會影響各種領域的模型和演算法效能，包括自然語言處理。雖然近年來對這項現象的研究備受關注，但現有的資源仍然相對稀少，通常只關注偏見的不同形式或表現。我們工作的目標有兩個：1) 收集公開可用的資料集，並確定如何將它們更好地結合起來，以有效訓練仇恨言論偵測和分類任務中的模型；2) 分析這些資料集的主要問題，例如稀少性、資源傾斜和依賴非持久性資料。我們在討論這些問題的同時，也進行了我們的實驗，我們在其中展示了不同資料集的組合會對模型的效能產生很大的影響。

##### **Bridging and Modeling Correlations in Pairwise Data for Direct Preference Optimization**
2408.07471v1 by Yuxin Jiang, Bo Huang, Yufei Wang, Xingshan Zeng, Liangyou Li, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Wei Wang

Direct preference optimization (DPO), a widely adopted offline preference
optimization algorithm, aims to align large language models (LLMs) with
human-desired behaviors using pairwise preference data. However, the winning
response and the losing response within pairwise data are generated isolatedly,
leading to weak correlations between them as well as suboptimal alignment
performance. To address this issue, we propose an effective framework named
BMC, for bridging and modeling correlations in pairwise data. Firstly, we
increase the consistency and informativeness of the pairwise preference signals
by targeted modifications, synthesizing a pseudo winning response through
improving the losing response based on the winning response. Secondly, we
identify that DPO alone is insufficient to model these correlations and capture
nuanced variations. Therefore, we propose learning token-level correlations by
dynamically leveraging the policy model's confidence during training.
Comprehensive experiments on QA, math, and instruction-following tasks
demonstrate the effectiveness of our approach, significantly surpassing
competitive baselines, including DPO. Additionally, our in-depth quantitative
analysis reveals the reasons behind our method's superior performance over DPO
and showcases its versatility to other DPO variants.

摘要：直接偏好最佳化 (DPO) 是一種廣泛採用的離線偏好最佳化演算法，旨在利用成對偏好資料將大型語言模型 (LLM) 與人類想要的行為對齊。但是，成對資料中的獲勝回應和失敗回應是孤立產生的，導致它們之間產生微弱關聯，以及次佳對齊效能。為了解決這個問題，我們提出一個名為 BMC 的有效架構，用於橋接和建模成對資料中的關聯。首先，我們透過目標修改來增加成對偏好訊號的一致性和資訊性，透過根據獲勝回應改善失敗回應來合成一個偽獲勝回應。其次，我們發現單獨使用 DPO 不足以建模這些關聯並擷取細微變化。因此，我們提出透過在訓練期間動態利用策略模型的信心來學習代幣層級關聯。在問答、數學和遵循指示任務上的全面實驗證明了我們方法的有效性，顯著超越競爭基線，包括 DPO。此外，我們深入的量化分析揭示了我們的方法優於 DPO 的原因，並展示了它對其他 DPO 變體的多功能性。

##### **Large Language Models Prompting With Episodic Memory**
2408.07465v1 by Dai Do, Quan Tran, Svetha Venkatesh, Hung Le

Prompt optimization is essential for enhancing the performance of Large
Language Models (LLMs) in a range of Natural Language Processing (NLP) tasks,
particularly in scenarios of few-shot learning where training examples are
incorporated directly into the prompt. Despite the growing interest in
optimizing prompts with few-shot examples, existing methods for prompt
optimization are often resource-intensive or perform inadequately. In this
work, we propose PrOmpting with Episodic Memory (POEM), a novel prompt
optimization technique that is simple, efficient, and demonstrates strong
generalization capabilities. We approach prompt optimization as a Reinforcement
Learning (RL) challenge, using episodic memory to archive combinations of input
data, permutations of few-shot examples, and the rewards observed during
training. In the testing phase, we optimize the sequence of examples for each
test query by selecting the sequence that yields the highest total rewards from
the top-k most similar training examples in the episodic memory. Our results
show that POEM outperforms recent techniques like TEMPERA and RLPrompt by over
5.3% in various text classification tasks. Furthermore, our approach adapts
well to broader language understanding tasks, consistently outperforming
conventional heuristic methods for ordering examples.

摘要：提示最佳化對於提升大型語言模型 (LLM) 在各種自然語言處理 (NLP) 任務中的效能至關重要，特別是在少樣本學習的情境中，訓練範例直接整合到提示中。儘管對於使用少樣本範例最佳化提示的興趣日益濃厚，現有的提示最佳化方法往往需要大量資源或執行不佳。在這項工作中，我們提出帶有情節記憶的提示 (POEM)，這是一種新穎的提示最佳化技術，簡單、有效，並展現出強大的泛化能力。我們將提示最佳化視為一個強化學習 (RL) 挑戰，使用情節記憶來封存輸入資料的組合、少樣本範例的排列組合，以及在訓練期間觀察到的獎勵。在測試階段，我們透過從情節記憶中前 k 個最相似的訓練範例中選擇產生最高總獎勵的序列，來最佳化每個測試查詢的範例序列。我們的結果顯示，POEM 在各種文字分類任務中，表現優於 TEMPERA 和 RLPrompt 等近期技術，勝出幅度超過 5.3%。此外，我們的做法很適合更廣泛的語言理解任務，始終優於用於排序範例的傳統啟發式方法。

##### **Problem Solving Through Human-AI Preference-Based Cooperation**
2408.07461v2 by Subhabrata Dutta, Timo Kaufmann, Goran Glavaš, Ivan Habernal, Kristian Kersting, Frauke Kreuter, Mira Mezini, Iryna Gurevych, Eyke Hüllermeier, Hinrich Schuetze

While there is a widespread belief that artificial general intelligence (AGI)
-- or even superhuman AI -- is imminent, complex problems in expert domains are
far from being solved. We argue that such problems require human-AI cooperation
and that the current state of the art in generative AI is unable to play the
role of a reliable partner due to a multitude of shortcomings, including
inability to keep track of a complex solution artifact (e.g., a software
program), limited support for versatile human preference expression and lack of
adapting to human preference in an interactive setting. To address these
challenges, we propose HAI-Co2, a novel human-AI co-construction framework. We
formalize HAI-Co2 and discuss the difficult open research problems that it
faces. Finally, we present a case study of HAI-Co2 and demonstrate its efficacy
compared to monolithic generative AI models.

摘要：儘管普遍相信人工通用智慧 (AGI)
-- 甚至是超人類人工智慧 -- 即將出現，專家領域中的複雜問題
仍遠未解決。我們認為此類問題需要人類與人工智慧合作，
而生成式人工智慧的現有技術狀態無法扮演可靠夥伴的角色，
原因在於它有許多缺點，包括無法追蹤複雜的解決方案人工製品（例如，軟體
程式）、對多功能人類偏好表達的支持有限，以及在互動設定中無法適應人類偏好。
為了應對這些挑戰，我們提出 HAI-Co2，這是一種新穎的人類與人工智慧共建架構。我們
將 HAI-Co2 正式化，並討論它面臨的困難開放式研究問題。最後，我們提出 HAI-Co2 的案例研究，
並展示它與單一生成式人工智慧模型相比的功效。

##### **From Brazilian Portuguese to European Portuguese**
2408.07457v1 by João Sanches, Rui Ribeiro, Luísa Coheur

Brazilian Portuguese and European Portuguese are two varieties of the same
language and, despite their close similarities, they exhibit several
differences. However, there is a significant disproportion in the availability
of resources between the two variants, with Brazilian Portuguese having more
abundant resources. This inequity can impact the quality of translation
services accessible to European Portuguese speakers. To address this issue, we
propose the development of a Brazilian Portuguese to European Portuguese
translation system, leveraging recent advancements in neural architectures and
models. To evaluate the performance of such systems, we manually curated a gold
test set comprising 500 sentences across five different topics. Each sentence
in the gold test set has two distinct references, facilitating a
straightforward evaluation of future translation models. We experimented with
various models by fine-tuning existing Large Language Models using parallel
data extracted from movie subtitles and TED Talks transcripts in both Brazilian
and European Portuguese. Our evaluation involved the use of conventional
automatic metrics as well as a human evaluation. In addition, all models were
compared against ChatGPT 3.5 Turbo, which currently yields the best results.

摘要：巴西葡萄牙語和歐洲葡萄牙語是同一語言的兩種變體，儘管它們非常相似，但它們表現出一些差異。然而，這兩種變體之間的資源可用性存在顯著差異，巴西葡萄牙語擁有更豐富的資源。這種不平等會影響歐洲葡萄牙語使用者可以獲得的翻譯服務品質。為了解決這個問題，我們提議開發一個巴西葡萄牙語到歐洲葡萄牙語的翻譯系統，利用神經架構和模型的最新進展。為了評估這些系統的效能，我們手動策劃了一個黃金測試集，其中包含五個不同主題的 500 個句子。黃金測試集中的每個句子都有兩個不同的參考，便於對未來的翻譯模型進行直接評估。我們通過微調現有的大型語言模型，使用從巴西和歐洲葡萄牙語的電影字幕和 TED 演講稿中提取的平行數據，對各種模型進行了實驗。我們的評估包括使用傳統的自動化指標以及人工評估。此外，所有模型都與 ChatGPT 3.5 Turbo 進行了比較，後者目前產生了最好的結果。

##### **Fact or Fiction? Improving Fact Verification with Knowledge Graphs through Simplified Subgraph Retrievals**
2408.07453v1 by Tobias A. Opsahl

Despite recent success in natural language processing (NLP), fact
verification still remains a difficult task. Due to misinformation spreading
increasingly fast, attention has been directed towards automatically verifying
the correctness of claims. In the domain of NLP, this is usually done by
training supervised machine learning models to verify claims by utilizing
evidence from trustworthy corpora. We present efficient methods for verifying
claims on a dataset where the evidence is in the form of structured knowledge
graphs. We use the FactKG dataset, which is constructed from the DBpedia
knowledge graph extracted from Wikipedia. By simplifying the evidence retrieval
process, from fine-tuned language models to simple logical retrievals, we are
able to construct models that both require less computational resources and
achieve better test-set accuracy.

摘要：儘管在自然語言處理 (NLP) 中獲得近期成功，事實驗證仍然是一項艱難的任務。由於錯誤資訊傳播得越來越快，注意力已轉向自動驗證聲明的正確性。在 NLP 領域中，這通常透過訓練監督式機器學習模型來完成，這些模型利用來自可信賴語料庫的證據來驗證聲明。我們提出有效的方法來驗證資料集中的聲明，其中證據是以結構化知識圖表的形式呈現。我們使用 FactKG 資料集，它是由從維基百科中萃取的 DBpedia 知識圖表所建構。透過簡化證據擷取流程，從微調語言模型到簡單的邏輯擷取，我們能夠建構既需要較少計算資源，又能達到較佳測試集準確度的模型。

##### **CMU's IWSLT 2024 Simultaneous Speech Translation System**
2408.07452v1 by Xi Xu, Siqi Ouyang, Brian Yan, Patrick Fernandes, William Chen, Lei Li, Graham Neubig, Shinji Watanabe

This paper describes CMU's submission to the IWSLT 2024 Simultaneous Speech
Translation (SST) task for translating English speech to German text in a
streaming manner. Our end-to-end speech-to-text (ST) system integrates the
WavLM speech encoder, a modality adapter, and the Llama2-7B-Base model as the
decoder. We employ a two-stage training approach: initially, we align the
representations of speech and text, followed by full fine-tuning. Both stages
are trained on MuST-c v2 data with cross-entropy loss. We adapt our offline ST
model for SST using a simple fixed hold-n policy. Experiments show that our
model obtains an offline BLEU score of 31.1 and a BLEU score of 29.5 under 2
seconds latency on the MuST-C-v2 tst-COMMON.

摘要：本文描述了卡內基美隆大學提交給 IWSLT 2024 同步語音翻譯 (SST) 任務的內容，任務是將英語語音串流式翻譯成德語文字。我們的端到端語音轉文字 (ST) 系統整合了 WavLM 語音編碼器、模態適配器和 Llama2-7B-Base 模型作為解碼器。我們採用兩階段訓練方法：首先，我們比對語音和文字的表示，然後進行完整微調。兩個階段都在 MuST-c v2 資料上訓練，並使用交叉熵損失。我們使用簡單的固定保留 n 策略將我們的離線 ST 模型改編為 SST。實驗顯示，我們的模型在 MuST-C-v2 tst-COMMON 上獲得 31.1 的離線 BLEU 分數，以及在 2 秒延遲下的 29.5 BLEU 分數。

##### **Achieving Data Efficient Neural Networks with Hybrid Concept-based Models**
2408.07438v1 by Tobias A. Opsahl, Vegard Antun

Most datasets used for supervised machine learning consist of a single label
per data point. However, in cases where more information than just the class
label is available, would it be possible to train models more efficiently? We
introduce two novel model architectures, which we call hybrid concept-based
models, that train using both class labels and additional information in the
dataset referred to as concepts. In order to thoroughly assess their
performance, we introduce ConceptShapes, an open and flexible class of datasets
with concept labels. We show that the hybrid concept-based models outperform
standard computer vision models and previously proposed concept-based models
with respect to accuracy, especially in sparse data settings. We also introduce
an algorithm for performing adversarial concept attacks, where an image is
perturbed in a way that does not change a concept-based model's concept
predictions, but changes the class prediction. The existence of such
adversarial examples raises questions about the interpretable qualities
promised by concept-based models.

摘要：大多數用於監督式機器學習的資料集包含每個資料點的單一標籤。然而，在有超過類別標籤的資訊可用的情況下，是否可能更有效率地訓練模型？我們介紹兩種新穎的模型架構，我們稱之為混合概念模型，它使用類別標籤和資料集中稱為概念的額外資訊進行訓練。為了徹底評估它們的效能，我們引入了 ConceptShapes，一個具有概念標籤的開放且靈活的資料集類別。我們證明混合概念模型在準確度方面優於標準電腦視覺模型和先前提出的基於概念的模型，特別是在稀疏資料設定中。我們還介紹了一種執行對抗概念攻擊的演算法，其中影像會受到擾動，但不會改變基於概念的模型的概念預測，而是改變類別預測。此類對抗範例的存在引發了關於基於概念的模型所承諾的可解釋品質的問題。

##### **Real-world validation of safe reinforcement learning, model predictive control and decision tree-based home energy management systems**
2408.07435v1 by Julian Ruddick, Glenn Ceusters, Gilles Van Kriekinge, Evgenii Genov, Thierry Coosemans, Maarten Messagie

Recent advancements in machine learning based energy management approaches,
specifically reinforcement learning with a safety layer (OptLayerPolicy) and a
metaheuristic algorithm generating a decision tree control policy (TreeC), have
shown promise. However, their effectiveness has only been demonstrated in
computer simulations. This paper presents the real-world validation of these
methods, comparing against model predictive control and simple rule-based
control benchmark. The experiments were conducted on the electrical
installation of 4 reproductions of residential houses, which all have their own
battery, photovoltaic and dynamic load system emulating a non-controllable
electrical load and a controllable electric vehicle charger. The results show
that the simple rules, TreeC, and model predictive control-based methods
achieved similar costs, with a difference of only 0.6%. The reinforcement
learning based method, still in its training phase, obtained a cost 25.5\%
higher to the other methods. Additional simulations show that the costs can be
further reduced by using a more representative training dataset for TreeC and
addressing errors in the model predictive control implementation caused by its
reliance on accurate data from various sources. The OptLayerPolicy safety layer
allows safe online training of a reinforcement learning agent in the
real-world, given an accurate constraint function formulation. The proposed
safety layer method remains error-prone, nonetheless, it is found beneficial
for all investigated methods. The TreeC method, which does require building a
realistic simulation for training, exhibits the safest operational performance,
exceeding the grid limit by only 27.1 Wh compared to 593.9 Wh for reinforcement
learning.

摘要：<paragraph>最近在基於機器學習的能源管理方法中取得進展，特別是具有安全層（OptLayerPolicy）的強化學習和產生決策樹控制策略（TreeC）的元啟發式演算法，已展現出前景。然而，它們的有效性僅在電腦模擬中得到證明。本文介紹了這些方法的現實世界驗證，並與模型預測控制和基於簡單規則的控制基準進行比較。這些實驗是在 4 個住宅複製品的電氣裝置上進行的，它們都配備自己的電池、光電和動態負載系統，模擬不可控電氣負載和可控電動車充電器。結果顯示，簡單規則、TreeC 和基於模型預測控制的方法達到了相似的成本，差異僅為 0.6%。基於強化學習的方法仍處於訓練階段，獲得的成本比其他方法高出 25.5%。其他模擬顯示，透過使用更具代表性的 TreeC 訓練資料集，以及解決模型預測控制實作中因依賴各種來源的準確資料而產生的錯誤，可以進一步降低成本。OptLayerPolicy 安全層允許在現實世界中安全地線上訓練強化學習代理，前提是提供準確的約束函數公式。所提出的安全層方法仍然容易出錯，儘管如此，發現它對所有研究的方法都有利。TreeC 方法需要建立一個用於訓練的現實模擬，表現出最安全的運作效能，與強化學習的 593.9 Wh 相比，僅超過電網限制 27.1 Wh。</paragraph>

##### **MagicFace: Training-free Universal-Style Human Image Customized Synthesis**
2408.07433v2 by Yibin Wang, Weizhong Zhang, Cheng Jin

Existing human image personalized generation methods often require tedious
training: either fine-tuning with a few images or retraining on large-scale
datasets. In such cases, these methods are prone to overfitting and encounter
difficulties when personalizing individuals of diverse styles. Moreover, these
training-based approaches also struggle with multi-concept human image
customizing. To this end, we propose MagicFace, the first method for
universal-style human image personalized synthesis that enables
single/multi-concept customization for humans of any style in a training-free
manner. MagicFace introduces a coarse-to-fine generation pipeline, involving
two sequential stages: semantic scene construction and concept feature
injection. This is achieved by our Reference-aware Self-Attention (RSA) and
Region-grouped Blend Attention (RBA) mechanisms. Specifically, in the first
stage, RSA enables the latent image to query features from reference concepts
simultaneously, extracting the coarse-grained overall semantic understanding to
facilitate the initial semantic layout establishment. In the second stage, we
employ an attention-based semantic segmentation method to pinpoint the
generated regions of all concepts in the latent image at each step. Following
this, RBA divides the pixels of the latent image into semantic groups, with
each group querying fine-grained features from its reference concept, which
ensures precise attribute alignment and feature injection. Throughout the
two-stage process, a weight mask strategy is employed to ensure the model
focuses more on the reference concepts. Extensive experiments demonstrate our
superiority in both human-centric subject-to-image synthesis and multi-concept
human image customization. Our approach also can be applied to texture
transformation, further enhancing its versatility and applicability.

摘要：現有的個人化生成人像方法通常需要繁瑣的訓練：使用少量影像微調或在大型資料集上重新訓練。在這種情況下，這些方法容易過度擬合，並且在為不同風格的個人進行個人化時遇到困難。此外，這些基於訓練的方法在多概念人像客製化方面也面臨挑戰。為此，我們提出 MagicFace，這是第一個通用風格個人化人像合成方法，能夠以無訓練的方式為任何風格的人類進行單一/多概念客製化。MagicFace 介紹了一個由粗到精的生成管道，包含兩個順序階段：語義場景建構和概念特徵注入。這是通過我們的參考感知自注意力 (RSA) 和區域群組混合注意力 (RBA) 機制實現的。具體來說，在第一階段，RSA 使潛在影像能夠同時從參考概念中查詢特徵，提取粗略的整體語義理解，以促進初始語義佈局建立。在第二階段，我們採用基於注意力的語義分割方法，在每一步準確找出潛在影像中所有概念的生成區域。在此之後，RBA 將潛在影像的像素分為語義群組，每個群組從其參考概念中查詢細粒度的特徵，這確保了精確的屬性對齊和特徵注入。在整個兩個階段的過程中，採用權重遮罩策略來確保模型更專注於參考概念。大量的實驗證明了我們在以人為中心的影像合成和多概念人像客製化方面的優越性。我們的方法也可以應用於紋理轉換，進一步增強其多功能性和適用性。

##### **Exploring Retrieval Augmented Generation in Arabic**
2408.07425v1 by Samhaa R. El-Beltagy, Mohamed A. Abdallah

Recently, Retrieval Augmented Generation (RAG) has emerged as a powerful
technique in natural language processing, combining the strengths of
retrieval-based and generation-based models to enhance text generation tasks.
However, the application of RAG in Arabic, a language with unique
characteristics and resource constraints, remains underexplored. This paper
presents a comprehensive case study on the implementation and evaluation of RAG
for Arabic text. The work focuses on exploring various semantic embedding
models in the retrieval stage and several LLMs in the generation stage, in
order to investigate what works and what doesn't in the context of Arabic. The
work also touches upon the issue of variations between document dialect and
query dialect in the retrieval stage. Results show that existing semantic
embedding models and LLMs can be effectively employed to build Arabic RAG
pipelines.

摘要：最近，检索增强生成（RAG）已成为自然语言处理中一项强大的技术，它结合了基于检索和基于生成的模型的优势来增强文本生成任务。然而，RAG 在阿拉伯语中的应用，一种具有独特特征和资源限制的语言，仍然没有得到充分探索。本文针对阿拉伯语文本的 RAG 实施和评估提供了一个全面的案例研究。这项工作重点在于探索检索阶段的各种语义嵌入模型和生成阶段的几个 LLM，以便研究在阿拉伯语语境中哪些有效，哪些无效。这项工作还涉及检索阶段中文档方言和查询方言之间的差异问题。结果表明，现有的语义嵌入模型和 LLM 可以有效地用于构建阿拉伯语 RAG 管道。

##### **LLMI3D: Empowering LLM with 3D Perception from a Single 2D Image**
2408.07422v1 by Fan Yang, Sicheng Zhao, Yanhao Zhang, Haoxiang Chen, Hui Chen, Wenbo Tang, Haonan Lu, Pengfei Xu, Zhenyu Yang, Jungong Han, Guiguang Ding

Recent advancements in autonomous driving, augmented reality, robotics, and
embodied intelligence have necessitated 3D perception algorithms. However,
current 3D perception methods, particularly small models, struggle with
processing logical reasoning, question-answering, and handling open scenario
categories. On the other hand, generative multimodal large language models
(MLLMs) excel in general capacity but underperform in 3D tasks, due to weak
spatial and local object perception, poor text-based geometric numerical
output, and inability to handle camera focal variations. To address these
challenges, we propose the following solutions: Spatial-Enhanced Local Feature
Mining for better spatial feature extraction, 3D Query Token-Derived Info
Decoding for precise geometric regression, and Geometry Projection-Based 3D
Reasoning for handling camera focal length variations. We employ
parameter-efficient fine-tuning for a pre-trained MLLM and develop LLMI3D, a
powerful 3D perception MLLM. Additionally, we have constructed the IG3D
dataset, which provides fine-grained descriptions and question-answer
annotations. Extensive experiments demonstrate that our LLMI3D achieves
state-of-the-art performance, significantly outperforming existing methods.

摘要：近來在自動駕駛、擴增實境、機器人和具體智能的進展，需要 3D 感知演算法。然而，目前的 3D 感知方法，特別是小模型，在處理邏輯推理、問答和處理開放式場景類別方面有困難。另一方面，生成式多模態大型語言模型 (MLLM) 在一般能力上表現出色，但在 3D 任務中表現不佳，原因是空間和局部物件感知能力弱、文字為基礎的幾何數字輸出不佳，以及無法處理相機焦距變化。為了應對這些挑戰，我們提出以下解決方案：空間增強局部特徵挖掘，以獲得更好的空間特徵提取；3D 查詢代碼衍生資訊解碼，以進行精確的幾何回歸；以及基於幾何投影的 3D 推理，以處理相機焦距變化。我們採用參數有效率的微調，以進行預先訓練的 MLLM，並開發 LLMI3D，一個強大的 3D 感知 MLLM。此外，我們建構了 IG3D 資料集，它提供細粒度的描述和問答註解。大量的實驗證明，我們的 LLMI3D 達到最先進的效能，明顯優於現有的方法。

##### **The Restaurant Meal Delivery Problem with Ghost Kitchens**
2408.07417v1 by Gal Neria, Florentin D Hildebrandt, Michal Tzur, Marlin W Ulmer

Restaurant meal delivery has been rapidly growing in the last few years. The
main challenges in operating it are the temporally and spatially dispersed
stochastic demand that arrives from customers all over town as well as the
customers' expectation of timely and fresh delivery. To overcome these
challenges a new business concept emerged, "Ghost kitchens". This concept
proposes synchronized food preparation of several restaurants in a central
complex, exploiting consolidation benefits. However, dynamically scheduling
food preparation and delivery is challenging and we propose operational
strategies for the effective operations of ghost kitchens. We model the problem
as a sequential decision process. For the complex, combinatorial decision space
of scheduling order preparations, consolidating orders to trips, and scheduling
trip departures, we propose a large neighborhood search procedure based on
partial decisions and driven by analytical properties. Within the large
neighborhood search, decisions are evaluated via a value function
approximation, enabling anticipatory and real-time decision making. We show the
effectiveness of our method and demonstrate the value of ghost kitchens
compared to conventional meal delivery systems. We show that both integrated
optimization of cook scheduling and vehicle dispatching, as well as
anticipation of future demand and decisions, are essential for successful
operations. We further derive several managerial insights, amongst others, that
companies should carefully consider the trade-off between fast delivery and
fresh food.

摘要：近年來，餐廳外送服務快速成長。其經營上的主要挑戰在於來自全鎮顧客的時間和空間分散的隨機需求，以及顧客對及時新鮮送達的期待。為了克服這些挑戰，一個新的商業概念「幽靈廚房」應運而生。這個概念提出在一個中央廚房同步製作多家餐廳的餐點，藉此發揮合併的效益。然而，動態排程餐點製作和配送是一項挑戰，我們提出營運策略以有效營運幽靈廚房。我們將問題建模為一個順序決策程序。對於排程訂單製作、將訂單合併為行程，以及排程行程出發的複雜組合決策空間，我們提出一個基於部分決策並由分析特性驅動的大鄰域搜尋程序。在大鄰域搜尋中，決策會透過價值函數近似來評估，促成預期性和即時決策。我們展示了我們方法的有效性，並證明了幽靈廚房與傳統外送系統相比的價值。我們表明，整合優化廚師排程和車輛調度，以及預測未來需求和決策，對於成功的營運至關重要。我們進一步得出一些管理見解，其中包括公司應仔細考慮快速配送和新鮮餐點之間的取捨。

##### **Knowledge in Superposition: Unveiling the Failures of Lifelong Knowledge Editing for Large Language Models**
2408.07413v1 by Chenhui Hu, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao

Knowledge editing aims to update outdated or incorrect knowledge in large
language models (LLMs). However, current knowledge editing methods have limited
scalability for lifelong editing. This study explores the fundamental reason
why knowledge editing fails in lifelong editing. We begin with the closed-form
solution derived from linear associative memory, which underpins
state-of-the-art knowledge editing methods. We extend the solution from single
editing to lifelong editing, and through rigorous mathematical derivation,
identify an interference term in the final solution, suggesting that editing
knowledge may impact irrelevant knowledge. Further analysis of the interference
term reveals a close relationship with superposition between knowledge
representations. When knowledge superposition does not exist in language
models, the interference term vanishes, allowing for lossless knowledge
editing. Experiments across numerous language models reveal that knowledge
superposition is universal, exhibiting high kurtosis, zero mean, and
heavy-tailed distributions with clear scaling laws. Ultimately, by combining
theory and experiments, we demonstrate that knowledge superposition is the
fundamental reason for the failure of lifelong editing. Moreover, this is the
first study to investigate knowledge editing from the perspective of
superposition and provides a comprehensive observation of superposition across
numerous real-world language models. Code available at
https://github.com/ChenhuiHu/knowledge_in_superposition.

摘要：知識編輯旨在更新大型語言模型 (LLM) 中過時或不正確的知識。然而，當前的知識編輯方法對於終身編輯具有有限的可擴充性。本研究探討了知識編輯在終身編輯中失敗的基本原因。我們從線性聯想記憶中得出的閉合形式解開始，這支撐著最先進的知識編輯方法。我們將解從單一編輯擴展到終身編輯，並通過嚴謹的數學推導，在最終解中識別出一個干擾項，表明編輯知識可能會影響無關知識。對干擾項的進一步分析揭示了知識表徵之間疊加的密切關係。當語言模型中不存在知識疊加時，干擾項就會消失，從而允許無損失的知識編輯。跨越眾多語言模型的實驗表明，知識疊加是普遍存在的，表現出高峰度、零均值和重尾分佈，並具有清晰的縮放定律。最終，通過結合理論和實驗，我們證明了知識疊加是終身編輯失敗的基本原因。此外，這是從疊加的角度研究知識編輯的第一項研究，並提供了跨越眾多現實世界語言模型的疊加的全面觀察。代碼可在 https://github.com/ChenhuiHu/knowledge_in_superposition 獲得。

##### **Aquila2 Technical Report**
2408.07410v1 by Bo-Wen Zhang, Liangdong Wang, Jijie Li, Shuhao Gu, Xinya Wu, Zhengduo Zhang, Boyan Gao, Yulong Ao, Guang Liu

This paper introduces the Aquila2 series, which comprises a wide range of
bilingual models with parameter sizes of 7, 34, and 70 billion. These models
are trained based on an innovative framework named HeuriMentor (HM), which
offers real-time insights into model convergence and enhances the training
process and data management. The HM System, comprising the Adaptive Training
Engine (ATE), Training State Monitor (TSM), and Data Management Unit (DMU),
allows for precise monitoring of the model's training progress and enables
efficient optimization of data distribution, thereby enhancing training
effectiveness. Extensive evaluations show that the Aquila2 model series
performs comparably well on both English and Chinese benchmarks. Specifically,
Aquila2-34B demonstrates only a slight decrease in performance when quantized
to Int4. Furthermore, we have made our training code
(https://github.com/FlagOpen/FlagScale) and model weights
(https://github.com/FlagAI-Open/Aquila2) publicly available to support ongoing
research and the development of applications.

摘要：本文介绍了 Aquila2 系列，其中包含一系列双语模型，参数大小为 70 亿、34 亿和 70 亿。这些模型基于一个名为 HeuriMentor (HM) 的创新框架进行训练，该框架可实时深入了解模型收敛性，并增强训练过程和数据管理。HM 系统由自适应训练引擎 (ATE)、训练状态监视器 (TSM) 和数据管理单元 (DMU) 组成，可以精确监视模型的训练进度，并能够高效优化数据分布，从而提高训练效率。广泛的评估表明，Aquila2 模型系列在英语和中文基准上都表现得相当好。具体来说，Aquila2-34B 在量化为 Int4 时仅表现出轻微的性能下降。此外，我们已将我们的训练代码 (https://github.com/FlagOpen/FlagScale) 和模型权重 (https://github.com/FlagAI-Open/Aquila2) 公开，以支持正在进行的研究和应用程序的开发。

##### **Efficient Edge AI: Deploying Convolutional Neural Networks on FPGA with the Gemmini Accelerator**
2408.07404v1 by Federico Nicolas Peccia, Svetlana Pavlitska, Tobias Fleck, Oliver Bringmann

The growing concerns regarding energy consumption and privacy have prompted
the development of AI solutions deployable on the edge, circumventing the
substantial CO2 emissions associated with cloud servers and mitigating risks
related to sharing sensitive data. But deploying Convolutional Neural Networks
(CNNs) on non-off-the-shelf edge devices remains a complex and labor-intensive
task. In this paper, we present and end-to-end workflow for deployment of CNNs
on Field Programmable Gate Arrays (FPGAs) using the Gemmini accelerator, which
we modified for efficient implementation on FPGAs. We describe how we leverage
the use of open source software on each optimization step of the deployment
process, the customizations we added to them and its impact on the final
system's performance. We were able to achieve real-time performance by
deploying a YOLOv7 model on a Xilinx ZCU102 FPGA with an energy efficiency of
36.5 GOP/s/W. Our FPGA-based solution demonstrates superior power efficiency
compared with other embedded hardware devices, and even outperforms other FPGA
reference implementations. Finally, we present how this kind of solution can be
integrated into a wider system, by testing our proposed platform in a traffic
monitoring scenario.

摘要：考量到能源消耗和隱私的日益增長，促使開發可部署於邊緣的 AI 解決方案，規避與雲端伺服器相關的龐大 CO2 排放，並降低與敏感資料共享相關的風險。但是，在非現成的邊緣裝置上部署卷積神經網路 (CNN) 仍然是一項複雜且勞力密集的任務。在本文中，我們提出一個端到端的流程，使用 Gemmini 加速器在現場可程式閘陣列 (FPGA) 上部署 CNN，我們修改了 Gemmini 以在 FPGA 上有效實作。我們描述如何在部署過程的每個最佳化步驟中利用開源軟體，我們對它們所做的自訂，以及對最終系統效能的影響。我們能夠透過在 Xilinx ZCU102 FPGA 上部署 YOLOv7 模型，以 36.5 GOP/s/W 的能源效率達成即時效能。與其他嵌入式硬體裝置相比，我們的基於 FPGA 的解決方案展現出優異的電力效率，甚至優於其他 FPGA 參考實作。最後，我們提出如何將這種解決方案整合到更廣泛的系統中，透過在交通監控場景中測試我們提出的平台。

##### **A Quantum-Inspired Analysis of Human Disambiguation Processes**
2408.07402v1 by Daphne Wang

Formal languages are essential for computer programming and are constructed
to be easily processed by computers. In contrast, natural languages are much
more challenging and instigated the field of Natural Language Processing (NLP).
One major obstacle is the ubiquity of ambiguities. Recent advances in NLP have
led to the development of large language models, which can resolve ambiguities
with high accuracy. At the same time, quantum computers have gained much
attention in recent years as they can solve some computational problems faster
than classical computers. This new computing paradigm has reached the fields of
machine learning and NLP, where hybrid classical-quantum learning algorithms
have emerged. However, more research is needed to identify which NLP tasks
could benefit from a genuine quantum advantage. In this thesis, we applied
formalisms arising from foundational quantum mechanics, such as contextuality
and causality, to study ambiguities arising from linguistics. By doing so, we
also reproduced psycholinguistic results relating to the human disambiguation
process. These results were subsequently used to predict human behaviour and
outperformed current NLP methods.

摘要：形式語言對於電腦程式設計至關重要，且建構出來後可以讓電腦輕鬆處理。相對地，自然語言更具挑戰性，並促成了自然語言處理 (NLP) 領域。其中一個主要障礙是無所不在的歧義性。NLP 的近期進展促成了大型語言模型的發展，它可以高準確度地解決歧義性。同時，量子電腦在近年來備受關注，因為它們可以比傳統電腦更快地解決一些運算問題。這個新的運算模式已經觸及機器學習和 NLP 領域，其中出現了混合古典量子學習演算法。然而，需要更多研究來找出哪些 NLP 任務可以從真正的量子優勢中受益。在本文中，我們應用源自基礎量子力學的形式主義，例如情境性和因果性，來研究源自語言學的歧義性。透過這麼做，我們也重現了與人類消除歧義過程相關的心理語言學結果。這些結果隨後用於預測人類行為，並且優於目前的 NLP 方法。

##### **DataVisT5: A Pre-trained Language Model for Jointly Understanding Text and Data Visualization**
2408.07401v1 by Zhuoyue Wan, Yuanfeng Song, Shuaimin Li, Chen Jason Zhang, Raymond Chi-Wing Wong

Data visualization (DV) is the fundamental and premise tool to improve the
efficiency in conveying the insights behind the big data, which has been widely
accepted in existing data-driven world. Task automation in DV, such as
converting natural language queries to visualizations (i.e., text-to-vis),
generating explanations from visualizations (i.e., vis-to-text), answering
DV-related questions in free form (i.e. FeVisQA), and explicating tabular data
(i.e., table-to-text), is vital for advancing the field. Despite their
potential, the application of pre-trained language models (PLMs) like T5 and
BERT in DV has been limited by high costs and challenges in handling
cross-modal information, leading to few studies on PLMs for DV. We introduce
\textbf{DataVisT5}, a novel PLM tailored for DV that enhances the T5
architecture through a hybrid objective pre-training and multi-task fine-tuning
strategy, integrating text and DV datasets to effectively interpret cross-modal
semantics. Extensive evaluations on public datasets show that DataVisT5
consistently outperforms current state-of-the-art models on various DV-related
tasks. We anticipate that DataVisT5 will not only inspire further research on
vertical PLMs but also expand the range of applications for PLMs.

摘要：資料視覺化 (DV) 是在現今資料驅動的世界中，廣泛被接受的傳達大數據中見解的基本且前提性的工具，以提升傳達效率。DV 中的任務自動化，例如將自然語言查詢轉換為視覺化（即文字轉視覺化）、從視覺化中產生說明（即視覺化轉文字）、以自由形式回答與 DV 相關的問題（即 FeVisQA）以及闡明表格資料（即表格轉文字），對於推進該領域至關重要。儘管有其潛力，T5 和 BERT 等預先訓練語言模型 (PLM) 在 DV 中的應用受到高成本和處理跨模態資訊的挑戰所限制，導致針對 DV 的 PLM 研究很少。我們介紹了 \textbf{DataVisT5}，這是一個專為 DV 量身打造的新穎 PLM，它透過混合目標預訓練和多任務微調策略來增強 T5 架構，整合文字和 DV 資料集以有效詮釋跨模態語意。對公開資料集的廣泛評估顯示，DataVisT5 在各種與 DV 相關的任務上始終優於當前最先進的模型。我們預期 DataVisT5 不僅將激勵進一步研究垂直 PLM，還將擴展 PLM 的應用範圍。

##### **Sum-Product-Set Networks**
2408.07394v1 by Milan Papež, Martin Rektoris, Tomáš Pevný, Václav Šmídl

Daily internet communication relies heavily on tree-structured graphs,
embodied by popular data formats such as XML and JSON. However, many recent
generative (probabilistic) models utilize neural networks to learn a
probability distribution over undirected cyclic graphs. This assumption of a
generic graph structure brings various computational challenges, and, more
importantly, the presence of non-linearities in neural networks does not permit
tractable probabilistic inference. We address these problems by proposing
sum-product-set networks, an extension of probabilistic circuits from
unstructured tensor data to tree-structured graph data. To this end, we use
random finite sets to reflect a variable number of nodes and edges in the graph
and to allow for exact and efficient inference. We demonstrate that our
tractable model performs comparably to various intractable models based on
neural networks.

摘要：日常網路通訊大量依賴樹狀結構圖形，
體現於 XML 和 JSON 等熱門資料格式。然而，許多最近的產生式（機率）模型利用神經網路學習非導向循環圖形上的機率分布。這種假設會帶來各種運算挑戰，更重要的是，神經網路中的非線性存在不允許可計算的機率推論。我們透過提出和-積-集網路來解決這些問題，這是一種機率電路從非結構張量資料到樹狀結構圖形資料的延伸。為此，我們使用隨機有限集合來反映圖形中變數節點和邊緣的數量，並允許精確且有效的推論。我們證明我們的可計算模型執行效能與各種基於神經網路的難以計算模型相當。

##### **Do GPT Language Models Suffer From Split Personality Disorder? The Advent Of Substrate-Free Psychometrics**
2408.07377v2 by Peter Romero, Stephen Fitz, Teruo Nakatsuma

Previous research on emergence in large language models shows these display
apparent human-like abilities and psychological latent traits. However, results
are partly contradicting in expression and magnitude of these latent traits,
yet agree on the worrisome tendencies to score high on the Dark Triad of
narcissism, psychopathy, and Machiavellianism, which, together with a track
record of derailments, demands more rigorous research on safety of these
models. We provided a state of the art language model with the same personality
questionnaire in nine languages, and performed Bayesian analysis of Gaussian
Mixture Model, finding evidence for a deeper-rooted issue. Our results suggest
both interlingual and intralingual instabilities, which indicate that current
language models do not develop a consistent core personality. This can lead to
unsafe behaviour of artificial intelligence systems that are based on these
foundation models, and are increasingly integrated in human life. We
subsequently discuss the shortcomings of modern psychometrics, abstract it, and
provide a framework for its species-neutral, substrate-free formulation.

摘要：先前針對大型語言模型中出現的研究顯示，這些模型展現出與人類相似的能力和心理潛在特質。然而，這些潛在特質的表現和程度部分矛盾，但都同意在自戀、精神病態和馬基維利主義的黑暗三合會中得分高的令人擔憂的傾向，這與出軌的記錄一起，需要對這些模型的安全進行更嚴謹的研究。我們為一個最先進的語言模型提供了九種語言的相同人格問卷，並對高斯混合模型進行貝氏分析，發現更深層次問題的證據。我們的結果表明，語言間和語言內的兩種不穩定性，這表明當前的語言模型無法發展出一致的核心人格。這可能導致基於這些基礎模型的人工智慧系統出現不安全的行為，並且越來越融入人類的生活。我們隨後討論了現代心理測量的缺點，對其進行抽象，並提供了一個物種中立、無基質配方的框架。

##### **Only One Relation Possible? Modeling the Ambiguity in Event Temporal Relation Extraction**
2408.07353v1 by Yutong Hu, Quzhe Huang, Yansong Feng

Event Temporal Relation Extraction (ETRE) aims to identify the temporal
relationship between two events, which plays an important role in natural
language understanding. Most previous works follow a single-label
classification style, classifying an event pair into either a specific temporal
relation (e.g., \textit{Before}, \textit{After}), or a special label
\textit{Vague} when there may be multiple possible temporal relations between
the pair. In our work, instead of directly making predictions on
\textit{Vague}, we propose a multi-label classification solution for ETRE
(METRE) to infer the possibility of each temporal relation independently, where
we treat \textit{Vague} as the cases when there is more than one possible
relation between two events. We design a speculation mechanism to explore the
possible relations hidden behind \textit{Vague}, which enables the latent
information to be used efficiently. Experiments on TB-Dense, MATRES and UDS-T
show that our method can effectively utilize the \textit{Vague} instances to
improve the recognition for specific temporal relations and outperforms most
state-of-the-art methods.

摘要：事件時間關係抽取（ETRE）旨在找出兩個事件之間的時間關係，這在自然語言理解中扮演著重要的角色。大多數先前的研究採用單標籤分類方式，將事件對分類成特定時間關係（例如：「之前」、「之後」）或特殊標籤「模糊」，表示事件對之間可能有多種可能的時間關係。在我們的研究中，我們並非直接對「模糊」做出預測，而是提出多標籤分類解決方案 ETRE（METRE），以獨立推論每個時間關係的可能性，其中我們將「模糊」視為兩個事件之間存在多種可能關係的情況。我們設計了一個推測機制，探索隱藏在「模糊」背後可能的關係，這使得潛在資訊得以有效利用。在 TB-Dense、MATRES 和 UDS-T 上進行的實驗顯示，我們的模型可以有效利用「模糊」實例，改善對特定時間關係的辨識，並優於大多數最先進的方法。

##### **RTAT: A Robust Two-stage Association Tracker for Multi-Object Tracking**
2408.07344v1 by Song Guo, Rujie Liu, Narishige Abe

Data association is an essential part in the tracking-by-detection based
Multi-Object Tracking (MOT). Most trackers focus on how to design a better data
association strategy to improve the tracking performance. The rule-based
handcrafted association methods are simple and highly efficient but lack
generalization capability to deal with complex scenes. While the learnt
association methods can learn high-order contextual information to deal with
various complex scenes, but they have the limitations of higher complexity and
cost. To address these limitations, we propose a Robust Two-stage Association
Tracker, named RTAT. The first-stage association is performed between tracklets
and detections to generate tracklets with high purity, and the second-stage
association is performed between tracklets to form complete trajectories. For
the first-stage association, we use a simple data association strategy to
generate tracklets with high purity by setting a low threshold for the matching
cost in the assignment process. We conduct the tracklet association in the
second-stage based on the framework of message-passing GNN. Our method models
the tracklet association as a series of edge classification problem in
hierarchical graphs, which can recursively merge short tracklets into longer
ones. Our tracker RTAT ranks first on the test set of MOT17 and MOT20
benchmarks in most of the main MOT metrics: HOTA, IDF1, and AssA. We achieve
67.2 HOTA, 84.7 IDF1, and 69.7 AssA on MOT17, and 66.2 HOTA, 82.5 IDF1, and
68.1 AssA on MOT20.

摘要：資料關聯是基於追蹤偵測的多目標追蹤 (MOT) 中不可或缺的一部分。大多數追蹤器專注於如何設計更好的資料關聯策略來提升追蹤效能。基於規則的手工關聯方法簡單且高效率，但缺乏處理複雜場景的概化能力。雖然學習關聯方法可以學習高階脈絡資訊來處理各種複雜場景，但它們有較高複雜度和成本的限制。為了解決這些限制，我們提出了一個名為 RTAT 的穩健兩階段關聯追蹤器。第一階段關聯在軌跡和偵測之間執行，以產生具有高純度的軌跡，第二階段關聯在軌跡之間執行，以形成完整的軌跡。對於第一階段關聯，我們使用一個簡單的資料關聯策略，透過在指派過程中設定匹配成本的低閾值來產生具有高純度的軌跡。我們在訊息傳遞 GNN 的架構中進行第二階段軌跡關聯。我們的模型將軌跡關聯建模為分層圖中的一系列邊緣分類問題，它可以遞迴地將短軌跡合併為較長的軌跡。我們的追蹤器 RTAT 在 MOT17 和 MOT20 基準測試的測試集中，在大部分 MOT 主要指標：HOTA、IDF1 和 AssA 中排名第一。我們在 MOT17 上達到 67.2 HOTA、84.7 IDF1 和 69.7 AssA，在 MOT20 上達到 66.2 HOTA、82.5 IDF1 和 68.1 AssA。

##### **Towards Few-shot Self-explaining Graph Neural Networks**
2408.07340v1 by Jingyu Peng, Qi Liu, Linan Yue, Zaixi Zhang, Kai Zhang, Yunhao Sha

Recent advancements in Graph Neural Networks (GNNs) have spurred an upsurge
of research dedicated to enhancing the explainability of GNNs, particularly in
critical domains such as medicine. A promising approach is the self-explaining
method, which outputs explanations along with predictions. However, existing
self-explaining models require a large amount of training data, rendering them
unavailable in few-shot scenarios. To address this challenge, in this paper, we
propose a Meta-learned Self-Explaining GNN (MSE-GNN), a novel framework that
generates explanations to support predictions in few-shot settings. MSE-GNN
adopts a two-stage self-explaining structure, consisting of an explainer and a
predictor. Specifically, the explainer first imitates the attention mechanism
of humans to select the explanation subgraph, whereby attention is naturally
paid to regions containing important characteristics. Subsequently, the
predictor mimics the decision-making process, which makes predictions based on
the generated explanation. Moreover, with a novel meta-training process and a
designed mechanism that exploits task information, MSE-GNN can achieve
remarkable performance on new few-shot tasks. Extensive experimental results on
four datasets demonstrate that MSE-GNN can achieve superior performance on
prediction tasks while generating high-quality explanations compared with
existing methods. The code is publicly available at
https://github.com/jypeng28/MSE-GNN.

摘要：圖神經網路 (GNN) 的最新進展激勵了許多專注於增強 GNN 可解釋性的研究，特別是在醫學等關鍵領域。一種有前景的方法是自解釋方法，它會隨著預測結果輸出解釋。然而，現有的自解釋模型需要大量的訓練資料，這使得它們在少樣本場景中無法使用。為了應對這個挑戰，我們在這篇論文中提出了一個元學習自解釋 GNN (MSE-GNN)，這是一個創新的架構，它會產生解釋來支援少樣本設定中的預測。MSE-GNN 採用一個兩階段自解釋結構，包含一個解釋器和一個預測器。具體來說，解釋器會先模仿人類的注意力機制來選擇解釋子圖，從而自然而然地將注意力放在包含重要特徵的區域。隨後，預測器會模擬決策制定過程，根據產生的解釋進行預測。此外，透過一個創新的元訓練過程和一個利用任務資訊的設計機制，MSE-GNN 可以對新的少樣本任務達成顯著的效能。在四個資料集上的廣泛實驗結果證明，與現有方法相比，MSE-GNN 可以對預測任務達成優異的效能，同時產生高品質的解釋。程式碼已公開於 https://github.com/jypeng28/MSE-GNN。

##### **An Offline Meta Black-box Optimization Framework for Adaptive Design of Urban Traffic Light Management Systems**
2408.07327v1 by Taeyoung Yun, Kanghoon Lee, Sujin Yun, Ilmyung Kim, Won-Woo Jung, Min-Cheol Kwon, Kyujin Choi, Yoohyeon Lee, Jinkyoo Park

Complex urban road networks with high vehicle occupancy frequently face
severe traffic congestion. Designing an effective strategy for managing
multiple traffic lights plays a crucial role in managing congestion. However,
most current traffic light management systems rely on human-crafted decisions,
which may not adapt well to diverse traffic patterns. In this paper, we delve
into two pivotal design components of the traffic light management system that
can be dynamically adjusted to various traffic conditions: phase combination
and phase time allocation. While numerous studies have sought an efficient
strategy for managing traffic lights, most of these approaches consider a fixed
traffic pattern and are limited to relatively small road networks. To overcome
these limitations, we introduce a novel and practical framework to formulate
the optimization of such design components using an offline meta black-box
optimization. We then present a simple yet effective method to efficiently find
a solution for the aforementioned problem. In our framework, we first collect
an offline meta dataset consisting of pairs of design choices and corresponding
congestion measures from various traffic patterns. After collecting the
dataset, we employ the Attentive Neural Process (ANP) to predict the impact of
the proposed design on congestion across various traffic patterns with
well-calibrated uncertainty. Finally, Bayesian optimization, with ANP as a
surrogate model, is utilized to find an optimal design for unseen traffic
patterns through limited online simulations. Our experiment results show that
our method outperforms state-of-the-art baselines on complex road networks in
terms of the number of waiting vehicles. Surprisingly, the deployment of our
method into a real-world traffic system was able to improve traffic throughput
by 4.80\% compared to the original strategy.

摘要：<paragraph>具有高车辆占用率的复杂城市道路网络经常面临严重的交通拥堵。设计一种有效的策略来管理多个交通信号灯在管理交通拥堵方面起着至关重要的作用。然而，大多数当前的交通信号灯管理系统依赖于人为制作的决策，这些决策可能无法很好地适应不同的交通模式。在本文中，我们深入研究了交通信号灯管理系统的两个关键设计组件，这些组件可以根据不同的交通状况进行动态调整：相位组合和相位时间分配。虽然许多研究都寻求一种有效的交通信号灯管理策略，但其中大多数方法都考虑了固定的交通模式，并且仅限于相对较小的道路网络。为了克服这些限制，我们引入了一个新颖且实用的框架，使用离线元黑盒优化来制定此类设计组件的优化。然后，我们提出了一种简单但有效的方法来有效地找到上述问题的解决方案。在我们的框架中，我们首先收集一个离线元数据集，其中包含来自各种交通模式的设计选择对和相应的拥堵措施。在收集数据集后，我们采用注意力神经过程 (ANP) 来预测所提出的设计对各种交通模式拥堵的影响，并具有良好的校准不确定性。最后，以 ANP 为替代模型的贝叶斯优化被用来通过有限的在线模拟为看不见的交通模式找到一个最优设计。我们的实验结果表明，我们的方法在等待车辆数量方面优于复杂道路网络上的最先进基线。令人惊讶的是，将我们的方法部署到现实世界的交通系统中，与原来的策略相比，能够将交通吞吐量提高 4.80%。</paragraph>

##### **On-the-fly Synthesis for LTL over Finite Traces: An Efficient Approach that Counts**
2408.07324v1 by Shengping Xiao, Yongkang Li, Shufang Zhu, Jun Sun, Jianwen Li, Geguang Pu, Moshe Y. Vardi

We present an on-the-fly synthesis framework for Linear Temporal Logic over
finite traces (LTLf) based on top-down deterministic automata construction.
Existing approaches rely on constructing a complete Deterministic Finite
Automaton (DFA) corresponding to the LTLf specification, a process with doubly
exponential complexity relative to the formula size in the worst case. In this
case, the synthesis procedure cannot be conducted until the entire DFA is
constructed. This inefficiency is the main bottleneck of existing approaches.
To address this challenge, we first present a method for converting LTLf into
Transition-based DFA (TDFA) by directly leveraging LTLf semantics,
incorporating intermediate results as direct components of the final automaton
to enable parallelized synthesis and automata construction. We then explore the
relationship between LTLf synthesis and TDFA games and subsequently develop an
algorithm for performing LTLf synthesis using on-the-fly TDFA game solving.
This algorithm traverses the state space in a global forward manner combined
with a local backward method, along with the detection of strongly connected
components. Moreover, we introduce two optimization techniques -- model-guided
synthesis and state entailment -- to enhance the practical efficiency of our
approach. Experimental results demonstrate that our on-the-fly approach
achieves the best performance on the tested benchmarks and effectively
complements existing tools and approaches.

摘要：<paragraph>我們提出一個基於自頂向下確定性自動機建構的線性時序邏輯在有限軌跡（LTLf）上的即時合成架構。現有方法依賴於建構一個對應於 LTLf 規範的完整確定性有限自動機（DFA），這個過程在最壞情況下相對於公式大小具有雙重指數複雜度。在這種情況下，合成程序在整個 DFA 建構完成之前無法執行。這種低效率是現有方法的主要瓶頸。為了應對這一挑戰，我們首先提出了一種將 LTLf 轉換為基於轉換的 DFA（TDFA）的方法，通過直接利用 LTLf 語義，將中間結果作為最終自動機的直接組成部分，以實現並行合成和自動機建構。然後，我們探討了 LTLf 合成與 TDFA 遊戲之間的關係，並隨後開發了一種使用即時 TDFA 遊戲求解來執行 LTLf 合成的演算法。此演算法以全局向前的方式與局部向後方法結合的方式遍歷狀態空間，同時檢測強連通組件。此外，我們引入了兩種優化技術——模型引導合成和狀態蘊涵——以增強我們方法的實用效率。實驗結果表明，我們的即時方法在測試基準上實現了最佳性能，並有效地補充了現有工具和方法。</paragraph>

##### **Kolmogorov-Arnold Networks (KAN) for Time Series Classification and Robust Analysis**
2408.07314v1 by Chang Dong, Liangwei Zheng, Weitong Chen

Kolmogorov-Arnold Networks (KAN) has recently attracted significant attention
as a promising alternative to traditional Multi-Layer Perceptrons (MLP).
Despite their theoretical appeal, KAN require validation on large-scale
benchmark datasets. Time series data, which has become increasingly prevalent
in recent years, especially univariate time series are naturally suited for
validating KAN. Therefore, we conducted a fair comparison among KAN, MLP, and
mixed structures. The results indicate that KAN can achieve performance
comparable to, or even slightly better than, MLP across 128 time series
datasets. We also performed an ablation study on KAN, revealing that the output
is primarily determined by the base component instead of b-spline function.
Furthermore, we assessed the robustness of these models and found that KAN and
the hybrid structure MLP\_KAN exhibit significant robustness advantages,
attributed to their lower Lipschitz constants. This suggests that KAN and KAN
layers hold strong potential to be robust models or to improve the adversarial
robustness of other models.

摘要：Kolmogorov-Arnold 網路 (KAN) 近期作為傳統多層感知器 (MLP) 的替代方案備受矚目。
儘管理論上很有吸引力，但 KAN 需要在大型基準資料集上進行驗證。時序資料在近年來越來越普遍，特別是單變量時序資料本來就很適合驗證 KAN。因此，我們在 KAN、MLP 和混合結構之間進行了公平的比較。結果顯示，在 128 個時序資料集中，KAN 可以達到與 MLP 相當甚至略優的效能。我們也對 KAN 進行了消融研究，發現輸出主要由基礎元件決定，而不是 B 樣條函數。此外，我們評估了這些模型的穩健性，發現 KAN 和混合結構 MLP_KAN 展現出顯著的穩健性優勢，這歸因於它們較低的 Lipschitz 常數。這表示 KAN 和 KAN 層具有強大的潛力，可以成為穩健的模型或改善其他模型的對抗性穩健性。

##### **Enhancing Visual Question Answering through Ranking-Based Hybrid Training and Multimodal Fusion**
2408.07303v1 by Peiyuan Chen, Zecheng Zhang, Yiping Dong, Li Zhou, Han Wang

Visual Question Answering (VQA) is a challenging task that requires systems
to provide accurate answers to questions based on image content. Current VQA
models struggle with complex questions due to limitations in capturing and
integrating multimodal information effectively. To address these challenges, we
propose the Rank VQA model, which leverages a ranking-inspired hybrid training
strategy to enhance VQA performance. The Rank VQA model integrates high-quality
visual features extracted using the Faster R-CNN model and rich semantic text
features obtained from a pre-trained BERT model. These features are fused
through a sophisticated multimodal fusion technique employing multi-head
self-attention mechanisms. Additionally, a ranking learning module is
incorporated to optimize the relative ranking of answers, thus improving answer
accuracy. The hybrid training strategy combines classification and ranking
losses, enhancing the model's generalization ability and robustness across
diverse datasets. Experimental results demonstrate the effectiveness of the
Rank VQA model. Our model significantly outperforms existing state-of-the-art
models on standard VQA datasets, including VQA v2.0 and COCO-QA, in terms of
both accuracy and Mean Reciprocal Rank (MRR). The superior performance of Rank
VQA is evident in its ability to handle complex questions that require
understanding nuanced details and making sophisticated inferences from the
image and text. This work highlights the effectiveness of a ranking-based
hybrid training strategy in improving VQA performance and lays the groundwork
for further research in multimodal learning methods.

摘要：視覺問答（VQA）是一項具有挑戰性的任務，它要求系統根據影像內容提供準確的答案。當前的 VQA 模型由於在有效擷取和整合多模態資訊方面的限制，而難以處理複雜的問題。為了應對這些挑戰，我們提出了 Rank VQA 模型，它利用受排名啟發的混合訓練策略來增強 VQA 效能。Rank VQA 模型整合了使用 Faster R-CNN 模型提取的高品質視覺特徵，以及從預先訓練的 BERT 模型中獲得的豐富語意文字特徵。這些特徵透過採用多頭自我注意機制的複雜多模態融合技術進行融合。此外，還加入了一個排名學習模組來最佳化答案的相對排名，從而提高答案的準確度。混合訓練策略結合了分類和排名損失，增強了模型在不同資料集中的泛化能力和穩健性。實驗結果證明了 Rank VQA 模型的有效性。我們的模型在標準 VQA 資料集（包括 VQA v2.0 和 COCO-QA）上，在準確度和平均倒數排名（MRR）方面都明顯優於現有的最先進模型。Rank VQA 的優異效能體現在它處理複雜問題的能力上，這些問題需要理解細微的細節並從影像和文字中做出複雜的推論。這項工作突顯了基於排名的混合訓練策略在改善 VQA 效能方面的有效性，並為多模態學習方法的進一步研究奠定了基礎。

##### **LiPCoT: Linear Predictive Coding based Tokenizer for Self-supervised Learning of Time Series Data via Language Models**
2408.07292v1 by Md Fahim Anjum

Language models have achieved remarkable success in various natural language
processing tasks. However, their application to time series data, a crucial
component in many domains, remains limited. This paper proposes LiPCoT (Linear
Predictive Coding based Tokenizer for time series), a novel tokenizer that
encodes time series data into a sequence of tokens, enabling self-supervised
learning of time series using existing Language model architectures such as
BERT. Unlike traditional time series tokenizers that rely heavily on CNN
encoder for time series feature generation, LiPCoT employs stochastic modeling
through linear predictive coding to create a latent space for time series
providing a compact yet rich representation of the inherent stochastic nature
of the data. Furthermore, LiPCoT is computationally efficient and can
effectively handle time series data with varying sampling rates and lengths,
overcoming common limitations of existing time series tokenizers. In this
proof-of-concept work, we present the effectiveness of LiPCoT in classifying
Parkinson's disease (PD) using an EEG dataset from 46 participants. In
particular, we utilize LiPCoT to encode EEG data into a small vocabulary of
tokens and then use BERT for self-supervised learning and the downstream task
of PD classification. We benchmark our approach against several
state-of-the-art CNN-based deep learning architectures for PD detection. Our
results reveal that BERT models utilizing self-supervised learning outperformed
the best-performing existing method by 7.1% in precision, 2.3% in recall, 5.5%
in accuracy, 4% in AUC, and 5% in F1-score highlighting the potential for
self-supervised learning even on small datasets. Our work will inform future
foundational models for time series, particularly for self-supervised learning.

摘要：語言模型在各種自然語言處理任務中已取得顯著的成功。然而，它們在時間序列資料上的應用，在許多領域中是一個關鍵的組成部分，仍然有限。本文提出了 LiPCoT（基於線性預測編碼的時間序列標記器），這是一種創新的標記器，它將時間序列資料編碼成一系列標記，使用現有的語言模型架構（例如 BERT）進行時間序列的自監督學習。與依賴 CNN 編碼器進行時間序列特徵生成的傳統時間序列標記器不同，LiPCoT 採用透過線性預測編碼進行的隨機建模，為時間序列建立一個潛在空間，提供對資料內在隨機性質的緊湊且豐富的表示。此外，LiPCoT 在計算上很有效率，並且可以有效地處理具有不同採樣率和長度的時間序列資料，克服了現有時間序列標記器的常見限制。在這項概念驗證工作中，我們展示了 LiPCoT 在使用來自 46 位參與者的 EEG 資料集對帕金森氏症 (PD) 進行分類中的有效性。特別是，我們利用 LiPCoT 將 EEG 資料編碼成一個小的標記詞彙，然後使用 BERT 進行自監督學習和 PD 分類的下游任務。我們將我們的方法與幾種用於 PD 檢測的先進 CNN 基於深度學習架構進行基準測試。我們的結果表明，利用自監督學習的 BERT 模型在精確度上優於現有最佳執行方法 7.1%，在召回率上優於 2.3%，在準確度上優於 5.5%，在 AUC 上優於 4%，在 F1 分數上優於 5%，突顯了自監督學習的潛力，即使在小型資料集上也是如此。我們的工作將為時間序列的未來基礎模型提供資訊，特別是自監督學習。

##### **NL2OR: Solve Complex Operations Research Problems Using Natural Language Inputs**
2408.07272v1 by Junxuan Li, Ryan Wickman, Sahil Bhatnagar, Raj Kumar Maity, Arko Mukherjee

Operations research (OR) uses mathematical models to enhance decision-making,
but developing these models requires expert knowledge and can be
time-consuming. Automated mathematical programming (AMP) has emerged to
simplify this process, but existing systems have limitations. This paper
introduces a novel methodology that uses recent advances in Large Language
Model (LLM) to create and edit OR solutions from non-expert user queries
expressed using Natural Language. This reduces the need for domain expertise
and the time to formulate a problem. The paper presents an end-to-end pipeline,
named NL2OR, that generates solutions to OR problems from natural language
input, and shares experimental results on several important OR problems.

摘要：運籌學 (OR) 使用數學模型來增強決策制定，但開發這些模型需要專家知識，而且可能很耗時。自動化數學規劃 (AMP) 已應運而生，以簡化此流程，但現有系統有其限制。本文介紹一種新方法，它利用大型語言模型 (LLM) 的最新進展，使用自然語言表達的非專家使用者查詢來建立和編輯運籌學解法。這減少了對領域專業知識的需求，以及制定問題的時間。本文提出了端到端管道，稱為 NL2OR，它根據自然語言輸入產生運籌學問題的解法，並分享了幾個重要運籌學問題的實驗結果。

##### **Ensemble architecture in polyp segmentation**
2408.07262v1 by Hao-Yun Hsu, Yi-Ching Cheng, Guan-Hua Huang

In this research, we revisit the architecture of semantic segmentation and
evaluate the models excelling in polyp segmentation. We introduce an integrated
framework that harnesses the advantages of different models to attain an
optimal outcome. More specifically, we fuse the learned features from
convolutional and transformer models for prediction, and we view this approach
as an ensemble technique to enhance model performance. Our experiments on polyp
segmentation reveal that the proposed architecture surpasses other top models,
exhibiting improved learning capacity and resilience. The code is available at
https://github.com/HuangDLab/EnFormer.

摘要：在這項研究中，我們重新探討語意分割的架構，並評估在息肉分割中表現出色的模型。我們引入一個整合框架，利用不同模型的優點來達到最佳結果。更具體地說，我們融合了卷積和Transformer模型中學習到的特徵來進行預測，並且我們將這種方法視為一種提升模型效能的整體技術。我們在息肉分割上的實驗顯示，所提出的架構超越了其他頂尖模型，展現出改進的學習能力和韌性。程式碼可在 https://github.com/HuangDLab/EnFormer 取得。

##### **GRIF-DM: Generation of Rich Impression Fonts using Diffusion Models**
2408.07259v1 by Lei Kang, Fei Yang, Kai Wang, Mohamed Ali Souibgui, Lluis Gomez, Alicia Fornés, Ernest Valveny, Dimosthenis Karatzas

Fonts are integral to creative endeavors, design processes, and artistic
productions. The appropriate selection of a font can significantly enhance
artwork and endow advertisements with a higher level of expressivity. Despite
the availability of numerous diverse font designs online, traditional
retrieval-based methods for font selection are increasingly being supplanted by
generation-based approaches. These newer methods offer enhanced flexibility,
catering to specific user preferences and capturing unique stylistic
impressions. However, current impression font techniques based on Generative
Adversarial Networks (GANs) necessitate the utilization of multiple auxiliary
losses to provide guidance during generation. Furthermore, these methods
commonly employ weighted summation for the fusion of impression-related
keywords. This leads to generic vectors with the addition of more impression
keywords, ultimately lacking in detail generation capacity. In this paper, we
introduce a diffusion-based method, termed \ourmethod, to generate fonts that
vividly embody specific impressions, utilizing an input consisting of a single
letter and a set of descriptive impression keywords. The core innovation of
\ourmethod lies in the development of dual cross-attention modules, which
process the characteristics of the letters and impression keywords
independently but synergistically, ensuring effective integration of both types
of information. Our experimental results, conducted on the MyFonts dataset,
affirm that this method is capable of producing realistic, vibrant, and
high-fidelity fonts that are closely aligned with user specifications. This
confirms the potential of our approach to revolutionize font generation by
accommodating a broad spectrum of user-driven design requirements. Our code is
publicly available at \url{https://github.com/leitro/GRIF-DM}.

摘要：<paragraph>字型對於創意、設計流程和藝術創作來說是不可或缺的。適當的字型選擇可以大幅提升藝術作品，並讓廣告擁有更高的表現力。儘管網路上有許多不同的字型設計，但傳統的基於檢索的字型選擇方法正逐漸被基於生成的作法所取代。這些較新的方法提供了更高的彈性，可以滿足特定的使用者偏好並捕捉獨特的風格印象。然而，目前基於生成式對抗網路 (GAN) 的印象字型技術需要利用多個輔助損失來提供生成過程中的指導。此外，這些方法通常採用加權總和來融合與印象相關的關鍵字。這會導致在加入更多印象關鍵字後產生通用的向量，最終缺乏產生細節的能力。在本文中，我們介紹一種基於擴散的方法，稱為 \ourmethod，以產生生動體現特定印象的字型，利用包含單一字母和一組描述性印象關鍵字的輸入。\ourmethod 的核心創新在於開發雙重交叉注意力模組，它可以獨立但協同地處理字母和印象關鍵字的特徵，確保有效整合這兩種資訊。我們在 MyFonts 資料集上進行的實驗結果證實，此方法能夠產生逼真、生動且高保真的字型，這些字型與使用者規格緊密結合。這證實了我們的作法在滿足廣泛使用者驅動的設計需求方面具有革新字型生成技術的潛力。我們的程式碼已公開於 \url{https://github.com/leitro/GRIF-DM}。</paragraph>

##### **Enhancing Autonomous Vehicle Perception in Adverse Weather through Image Augmentation during Semantic Segmentation Training**
2408.07239v1 by Ethan Kou, Noah Curran

Robust perception is crucial in autonomous vehicle navigation and
localization. Visual processing tasks, like semantic segmentation, should work
in varying weather conditions and during different times of day. Semantic
segmentation is where each pixel is assigned a class, which is useful for
locating overall features (1). Training a segmentation model requires large
amounts of data, and the labeling process for segmentation data is especially
tedious. Additionally, many large datasets include only images taken in clear
weather. This is a problem because training a model exclusively on clear
weather data hinders performance in adverse weather conditions like fog or
rain. We hypothesize that given a dataset of only clear days images, applying
image augmentation (such as random rain, fog, and brightness) during training
allows for domain adaptation to diverse weather conditions. We used CARLA, a 3D
realistic autonomous vehicle simulator, to collect 1200 images in clear weather
composed of 29 classes from 10 different towns (2). We also collected 1200
images of random weather effects. We trained encoder-decoder UNet models to
perform semantic segmentation. Applying augmentations significantly improved
segmentation under weathered night conditions (p < 0.001). However, models
trained on weather data have significantly lower losses than those trained on
augmented data in all conditions except for clear days. This shows there is
room for improvement in the domain adaptation approach. Future work should test
more types of augmentations and also use real-life images instead of CARLA.
Ideally, the augmented model meets or exceeds the performance of the weather
model.

摘要：<paragraph>穩健的感知在自動駕駛導航和定位中至關重要。視覺處理任務（例如語義分割）應在不同的天氣條件和一天中的不同時間工作。語義分割是指將每個像素分配一個類別，這對於定位整體特徵很有用 (1)。訓練分割模型需要大量數據，而分割數據的標籤處理過程尤其繁瑣。此外，許多大型數據集僅包含在晴朗天氣下拍攝的圖像。這是一個問題，因為僅使用晴朗天氣數據訓練模型會阻礙在霧或雨等惡劣天氣條件下的性能。我們假設給定僅包含晴天圖像的數據集，在訓練期間應用圖像擴充（例如隨機雨、霧和亮度）允許域適應到不同的天氣條件。我們使用 CARLA，一個 3D 真實自動駕駛車輛模擬器，收集了 1200 張晴天圖像，這些圖像由來自 10 個不同城鎮的 29 個類別組成 (2)。我們還收集了 1200 張隨機天氣效果的圖像。我們訓練編碼器-解碼器 UNet 模型來執行語義分割。應用擴充顯著改善了在有天氣的夜晚條件下的分割（p < 0.001）。然而，在所有條件下，使用天氣數據訓練的模型的損失都顯著低於使用擴充數據訓練的模型，除了晴天。這表明域適應方法仍有改進的空間。未來的研究應測試更多類型的擴充，並使用真實圖像而不是 CARLA。理想情況下，擴充模型的性能達到或超過天氣模型的性能。</paragraph>

##### **Using Advanced LLMs to Enhance Smaller LLMs: An Interpretable Knowledge Distillation Approach**
2408.07238v1 by Tong Wang, K. Sudhir, Dat Hong

Advanced Large language models (LLMs) like GPT-4 or LlaMa 3 provide superior
performance in complex human-like interactions. But they are costly, or too
large for edge devices such as smartphones and harder to self-host, leading to
security and privacy concerns. This paper introduces a novel interpretable
knowledge distillation approach to enhance the performance of smaller, more
economical LLMs that firms can self-host. We study this problem in the context
of building a customer service agent aimed at achieving high customer
satisfaction through goal-oriented dialogues. Unlike traditional knowledge
distillation, where the "student" model learns directly from the "teacher"
model's responses via fine-tuning, our interpretable "strategy" teaching
approach involves the teacher providing strategies to improve the student's
performance in various scenarios. This method alternates between a "scenario
generation" step and a "strategies for improvement" step, creating a customized
library of scenarios and optimized strategies for automated prompting. The
method requires only black-box access to both student and teacher models; hence
it can be used without manipulating model parameters. In our customer service
application, the method improves performance, and the learned strategies are
transferable to other LLMs and scenarios beyond the training set. The method's
interpretabilty helps safeguard against potential harms through human audit.

摘要：進階大型語言模型（LLM），例如 GPT-4 或 LlaMa 3，在複雜的人類互動中提供卓越的效能。但它們的成本高昂，或對於邊緣裝置（例如智慧型手機）而言過於龐大，且更難以自行主機，導致安全性和隱私問題。本文介紹一種新穎的可解釋知識萃取方法，以增強較小、更經濟的 LLM 的效能，而企業可以自行主機。我們在建構客戶服務代理程式的脈絡中研究此問題，旨在透過以目標為導向的對話達成高客戶滿意度。與傳統的知識萃取不同，其中「學生」模型透過微調直接從「老師」模型的回應中學習，我們可解釋的「策略」教學方法涉及老師提供策略以改善學生在各種情境中的表現。此方法在「情境產生」步驟和「改善策略」步驟之間交替進行，建立自訂的情境資料庫和最佳化的策略，以進行自動化提示。此方法僅需要對學生和老師模型進行黑盒存取；因此，可以在不操作模型參數的情況下使用它。在我們的客戶服務應用程式中，此方法改善了效能，且學習到的策略可以轉移到其他 LLM 和訓練集以外的情境。此方法的可解釋性有助於透過人工稽核防止潛在的危害。

##### **Neural embedding of beliefs reveals the role of relative dissonance in human decision-making**
2408.07237v1 by Byunghwee Lee, Rachith Aiyappa, Yong-Yeol Ahn, Haewoon Kwak, Jisun An

Beliefs serve as the foundation for human cognition and decision-making. They
guide individuals in deriving meaning from their lives, shaping their
behaviors, and forming social connections. Therefore, a model that encapsulates
beliefs and their interrelationships is crucial for quantitatively studying the
influence of beliefs on our actions. Despite its importance, research on the
interplay between human beliefs has often been limited to a small set of
beliefs pertaining to specific issues, with a heavy reliance on surveys or
experiments. Here, we propose a method for extracting nuanced relations between
thousands of beliefs by leveraging large-scale user participation data from an
online debate platform and mapping these beliefs to an embedding space using a
fine-tuned large language model (LLM). This belief embedding space effectively
encapsulates the interconnectedness of diverse beliefs as well as polarization
across various social issues. We discover that the positions within this belief
space predict new beliefs of individuals. Furthermore, we find that the
relative distance between one's existing beliefs and new beliefs can serve as a
quantitative estimate of cognitive dissonance, allowing us to predict new
beliefs. Our study highlights how modern LLMs, when combined with collective
online records of human beliefs, can offer insights into the fundamental
principles that govern human belief formation and decision-making processes.

摘要：<paragraph>信念是人类认知和决策的基础。它们
引导个体从生活中获取意义、塑造他们的
行为并形成社会联系。因此，一个包含
信念及其相互关系的模型对于定量研究
信念对我们行为的影响至关重要。尽管其重要性，对
人类信念之间相互作用的研究通常仅限于
与特定问题相关的一小部分信念，并且严重依赖
调查或实验。在这里，我们提出了一种通过利用
在线辩论平台的大规模用户参与数据来提取
数千种信念之间的细微关系的方法，并将这些信念映射到
嵌入空间，使用经过微调的大语言模型 (LLM)。这个信念嵌入空间有效地
概括了不同信念之间的相互联系以及
各种社会问题之间的两极分化。我们发现这个信念
空间中的位置预测了个体的新的信念。此外，我们发现
一个人现有信念和新信念之间的相对距离可以作为
认知失调的定量估计，使我们能够预测新的
信念。我们的研究重点介绍了现代 LLM 如何与人类信念的集体
在线记录相结合，可以深入了解支配人类信念形成和决策过程的基本
原则。</paragraph>

##### **Direction of Arrival Correction through Speech Quality Feedback**
2408.07234v1 by Caleb Rascon

Real-time speech enhancement has began to rise in performance, and the Demucs
Denoiser model has recently demonstrated strong performance in
multiple-speech-source scenarios when accompanied by a location-based speech
target selection strategy. However, it has shown to be sensitive to errors in
the direction-of-arrival (DOA) estimation. In this work, a DOA correction
scheme is proposed that uses the real-time estimated speech quality of its
enhanced output as the observed variable in an Adam-based optimization feedback
loop to find the correct DOA. In spite of the high variability of the speech
quality estimation, the proposed system is able to correct in real-time an
error of up to 15$^o$ using only the speech quality as its guide. Several
insights are provided for future versions of the proposed system to speed up
convergence and further reduce the speech quality estimation variability.

摘要：即時語音增強的效能開始提升，而 Demucs 降噪模型最近在多重語音來源情境中，結合基於定位的語音目標選取策略，展現出強勁的效能。然而，它已顯示出對到達方向 (DOA) 估計誤差很敏感。在這項工作中，提出了一個 DOA 校正方案，它使用其增強輸出的即時估計語音品質，作為 Adam 基於最佳化回饋迴路中的觀察變數，以找出正確的 DOA。儘管語音品質估計有很高的變異性，但所提出的系統能夠即時修正高達 15 度的誤差，僅使用語音品質作為其指南。提供了幾個見解，供未來版本的建議系統使用，以加快收斂速度並進一步降低語音品質估計的變異性。

##### **Can Large Language Models Reason? A Characterization via 3-SAT**
2408.07215v1 by Rishi Hazra, Gabriele Venturato, Pedro Zuidberg Dos Martires, Luc De Raedt

Large Language Models (LLMs) are said to possess advanced reasoning
abilities. However, some skepticism exists as recent works show how LLMs often
bypass true reasoning using shortcuts. Current methods for assessing the
reasoning abilities of LLMs typically rely on open-source benchmarks that may
be overrepresented in LLM training data, potentially skewing performance. We
instead provide a computational theory perspective of reasoning, using 3-SAT --
the prototypical NP-complete problem that lies at the core of logical reasoning
and constraint satisfaction tasks. By examining the phase transitions in 3-SAT,
we empirically characterize the reasoning abilities of LLMs and show how they
vary with the inherent hardness of the problems. Our experimental evidence
shows that LLMs cannot perform true reasoning, as is required for solving 3-SAT
problems.

摘要：大型語言模型 (LLM) 被認為擁有先進的推理能力。然而，一些懷疑論存在，因為最近的研究表明 LLM 如何經常使用捷徑繞過真正的推理。目前評估 LLM 推理能力的方法通常依賴於開源基準，這些基準可能在 LLM 訓練數據中過度表示，從而可能扭曲性能。我們反而提供了一個計算理論的推理觀點，使用 3-SAT —— 邏輯推理和約束滿足任務核心的原型 NP-complete 問題。通過檢查 3-SAT 中的相變，我們憑經驗描述了 LLM 的推理能力，並展示了它們如何隨著問題的固有難度而變化。我們的實驗證據表明，LLM 無法執行真正的推理，因為這對於解決 3-SAT 問題是必需的。

##### **Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**
2408.07199v1 by Pranav Putta, Edmund Mills, Naman Garg, Sumeet Motwani, Chelsea Finn, Divyansh Garg, Rafael Rafailov

Large Language Models (LLMs) have shown remarkable capabilities in natural
language tasks requiring complex reasoning, yet their application in agentic,
multi-step reasoning within interactive environments remains a difficult
challenge. Traditional supervised pre-training on static datasets falls short
in enabling autonomous agent capabilities needed to perform complex
decision-making in dynamic settings like web navigation. Previous attempts to
bridge this ga-through supervised fine-tuning on curated expert
demonstrations-often suffer from compounding errors and limited exploration
data, resulting in sub-optimal policy outcomes. To overcome these challenges,
we propose a framework that combines guided Monte Carlo Tree Search (MCTS)
search with a self-critique mechanism and iterative fine-tuning on agent
interactions using an off-policy variant of the Direct Preference Optimization
(DPO) algorithm. Our method allows LLM agents to learn effectively from both
successful and unsuccessful trajectories, thereby improving their
generalization in complex, multi-step reasoning tasks. We validate our approach
in the WebShop environment-a simulated e-commerce platform where it
consistently outperforms behavior cloning and reinforced fine-tuning baseline,
and beats average human performance when equipped with the capability to do
online search. In real-world booking scenarios, our methodology boosts Llama-3
70B model's zero-shot performance from 18.6% to 81.7% success rate (a 340%
relative increase) after a single day of data collection and further to 95.4%
with online search. We believe this represents a substantial leap forward in
the capabilities of autonomous agents, paving the way for more sophisticated
and reliable decision-making in real-world settings.

摘要：大型語言模型 (LLM) 在需要複雜推理的自然語言任務中展現出非凡的能力，但它們在互動環境中進行代理式、多步驟推理的應用仍是一項艱難的挑戰。傳統的靜態資料集監督預訓練無法提供在動態設定（例如網頁瀏覽）中執行複雜決策所需的自主代理能力。先前嘗試透過在策展的專家示範中進行監督微調來彌合這項差距，但通常會遭受複合錯誤和探索資料有限的困擾，導致次佳的政策結果。為了克服這些挑戰，我們提出一個架構，結合引導蒙地卡羅樹狀搜尋 (MCTS) 搜尋、自我批判機制，以及使用直接偏好最佳化 (DPO) 演算法的非策略變體對代理互動進行反覆微調。我們的模型允許 LLM 代理從成功和失敗的軌跡中有效學習，從而改善它們在複雜的多步驟推理任務中的泛化能力。我們在 WebShop 環境中驗證了我們的做法，WebShop 是一個模擬的電子商務平台，它始終優於行為複製和增強微調基準，並在具備進行線上搜尋的能力時超越了人類的平均表現。在真實世界的預訂情境中，我們的方法在收集資料一天後，將 Llama-3 70B 模型的零次學習表現從 18.6% 提升至 81.7% 的成功率（相對增加 340%），並在進行線上搜尋後進一步提升至 95.4%。我們相信這代表自主代理能力的重大躍進，為在真實世界設定中進行更精緻且可靠的決策鋪路。

##### **Massive Dimensions Reduction and Hybridization with Meta-heuristics in Deep Learning**
2408.07194v1 by Rasa Khosrowshahli, Shahryar Rahnamayan, Beatrice Ombuki-Berman

Deep learning is mainly based on utilizing gradient-based optimization for
training Deep Neural Network (DNN) models. Although robust and widely used,
gradient-based optimization algorithms are prone to getting stuck in local
minima. In this modern deep learning era, the state-of-the-art DNN models have
millions and billions of parameters, including weights and biases, making them
huge-scale optimization problems in terms of search space. Tuning a huge number
of parameters is a challenging task that causes vanishing/exploding gradients
and overfitting; likewise, utilized loss functions do not exactly represent our
targeted performance metrics. A practical solution to exploring large and
complex solution space is meta-heuristic algorithms. Since DNNs exceed
thousands and millions of parameters, even robust meta-heuristic algorithms,
such as Differential Evolution, struggle to efficiently explore and converge in
such huge-dimensional search spaces, leading to very slow convergence and high
memory demand. To tackle the mentioned curse of dimensionality, the concept of
blocking was recently proposed as a technique that reduces the search space
dimensions by grouping them into blocks. In this study, we aim to introduce
Histogram-based Blocking Differential Evolution (HBDE), a novel approach that
hybridizes gradient-based and gradient-free algorithms to optimize parameters.
Experimental results demonstrated that the HBDE could reduce the parameters in
the ResNet-18 model from 11M to 3K during the training/optimizing phase by
metaheuristics, namely, the proposed HBDE, which outperforms baseline
gradient-based and parent gradient-free DE algorithms evaluated on CIFAR-10 and
CIFAR-100 datasets showcasing its effectiveness with reduced computational
demands for the very first time.

摘要：深度學習主要基於利用基於梯度的最佳化來訓練深度神經網路 (DNN) 模型。儘管基於梯度的最佳化演算法強大且廣泛使用，但它們很容易陷入局部最小值。在這個現代深度學習時代，最先進的 DNN 模型擁有數百萬和數十億個參數，包括權重和偏差，這使得它們在搜尋空間方面成為大規模最佳化問題。調整大量的參數是一項具有挑戰性的任務，它會導致梯度消失/爆炸和過度擬合；同樣地，所使用的損失函數並不能準確地表示我們的目標效能指標。探索廣泛而複雜的解空間的實用解決方案是元啟發式演算法。由於 DNN 超過數千個和數百萬個參數，即使是強大的元啟發式演算法，例如差分演化，在探索和收斂於如此巨大的維度搜尋空間時也會遇到困難，導致收斂速度非常慢且記憶體需求很高。為了應對所提到的維度災難，最近提出了封鎖的概念，這是一種通過將搜尋空間分組成區塊來減少搜尋空間維度的技術。在本研究中，我們旨在介紹基於直方圖的封鎖差分演化 (HBDE)，這是一種將基於梯度和無梯度演算法混合起來以最佳化參數的新方法。實驗結果表明，HBDE 可以通過元啟發式演算法（即所提出的 HBDE）將 ResNet-18 模型中的參數從 11M 減少到 3K，而基於梯度的基線和父級無梯度 DE 演算法在 CIFAR-10 和 CIFAR-100 資料集上的評估結果則顯示了其有效性，首次減少了運算需求。

##### **Solving Truly Massive Budgeted Monotonic POMDPs with Oracle-Guided Meta-Reinforcement Learning**
2408.07192v1 by Manav Vora, Michael N Grussing, Melkior Ornik

Monotonic Partially Observable Markov Decision Processes (POMDPs), where the
system state progressively decreases until a restorative action is performed,
can be used to model sequential repair problems effectively. This paper
considers the problem of solving budget-constrained multi-component monotonic
POMDPs, where a finite budget limits the maximal number of restorative actions.
For a large number of components, solving such a POMDP using current methods is
computationally intractable due to the exponential growth in the state space
with an increasing number of components. To address this challenge, we propose
a two-step approach. Since the individual components of a budget-constrained
multi-component monotonic POMDP are only connected via the shared budget, we
first approximate the optimal budget allocation among these components using an
approximation of each component POMDP's optimal value function which is
obtained through a random forest model. Subsequently, we introduce an
oracle-guided meta-trained Proximal Policy Optimization (PPO) algorithm to
solve each of the independent budget-constrained single-component monotonic
POMDPs. The oracle policy is obtained by performing value iteration on the
corresponding monotonic Markov Decision Process (MDP). This two-step method
provides scalability in solving truly massive multi-component monotonic POMDPs.
To demonstrate the efficacy of our approach, we consider a real-world
maintenance scenario that involves inspection and repair of an administrative
building by a team of agents within a maintenance budget. Finally, we perform a
computational complexity analysis for a varying number of components to show
the scalability of the proposed approach.

摘要：單調部分可觀察馬可夫決策過程 (POMDP)，其中系統狀態逐漸降低，直到執行修復動作，可用於有效建模順序修復問題。本文考慮了解決預算受限的多元件單調 POMDP 的問題，其中有限的預算限制了修復動作的最大數量。對於大量的元件，使用當前方法求解這樣的 POMDP 在計算上是難以處理的，因為隨著元件數量的增加，狀態空間呈指數級增長。為了應對這一挑戰，我們提出了一個兩步法。由於預算受限的多元件單調 POMDP 的個別元件僅通過共享預算連接，我們首先使用每個元件 POMDP 的最優值函數的近似值來近似這些元件之間的最佳預算分配，該近似值是通過隨機森林模型獲得的。隨後，我們引入了一個由預言引導的元訓練近端策略優化 (PPO) 演算法，以求解每個獨立的預算受限單元件單調 POMDP。預言策略是通過對應的單調馬可夫決策過程 (MDP) 執行值迭代獲得的。這種兩步法在求解真正龐大的多元件單調 POMDP 時提供了可擴充性。為了證明我們方法的有效性，我們考慮了一個現實世界的維護場景，其中涉及一組代理人在維護預算內檢查和維修行政大樓。最後，我們對不同數量的元件執行計算複雜度分析，以展示所提出方法的可擴充性。

##### **BERT's Conceptual Cartography: Mapping the Landscapes of Meaning**
2408.07190v1 by Nina Haket, Ryan Daniels

Conceptual Engineers want to make words better. However, they often
underestimate how varied our usage of words is. In this paper, we take the
first steps in exploring the contextual nuances of words by creating conceptual
landscapes -- 2D surfaces representing the pragmatic usage of words -- that
conceptual engineers can use to inform their projects. We use the spoken
component of the British National Corpus and BERT to create contextualised word
embeddings, and use Gaussian Mixture Models, a selection of metrics, and
qualitative analysis to visualise and numerically represent lexical landscapes.
Such an approach has not yet been used in the conceptual engineering literature
and provides a detailed examination of how different words manifest in various
contexts that is potentially useful to conceptual engineering projects. Our
findings highlight the inherent complexity of conceptual engineering, revealing
that each word exhibits a unique and intricate landscape. Conceptual Engineers
cannot, therefore, use a one-size-fits-all approach when improving words -- a
task that may be practically intractable at scale.

摘要：概念工程師希望讓詞彙變得更好。然而，他們經常低估我們使用詞彙的多樣性。在本文中，我們踏出探索詞彙脈絡細微差別的第一步，我們創造了概念景觀——代表詞彙語用的 2D 表面——概念工程師可以使用它來通知他們的專案。我們使用英國國家語料庫的口語部分和 BERT 來建立脈絡化詞嵌入，並使用高斯混合模型、一系列指標和定性分析來視覺化和數值化表示詞彙景觀。這種方法尚未用於概念工程文獻中，並提供了對不同詞彙在各種脈絡中如何表現的詳細檢驗，這對於概念工程專案可能很有用。我們的發現突顯了概念工程的內在複雜性，揭示了每個詞彙都展現出獨特且複雜的景觀。因此，概念工程師在改進詞彙時不能採用一刀切的方法——這項任務在規模上可能難以執行。

##### **A New Dataset, Notation Software, and Representation for Computational Schenkerian Analysis**
2408.07184v1 by Stephen Ni-Hahn, Weihan Xu, Jerry Yin, Rico Zhu, Simon Mak, Yue Jiang, Cynthia Rudin

Schenkerian Analysis (SchA) is a uniquely expressive method of music
analysis, combining elements of melody, harmony, counterpoint, and form to
describe the hierarchical structure supporting a work of music. However,
despite its powerful analytical utility and potential to improve music
understanding and generation, SchA has rarely been utilized by the computer
music community. This is in large part due to the paucity of available
high-quality data in a computer-readable format. With a larger corpus of
Schenkerian data, it may be possible to infuse machine learning models with a
deeper understanding of musical structure, thus leading to more "human"
results. To encourage further research in Schenkerian analysis and its
potential benefits for music informatics and generation, this paper presents
three main contributions: 1) a new and growing dataset of SchAs, the largest in
human- and computer-readable formats to date (>140 excerpts), 2) a novel
software for visualization and collection of SchA data, and 3) a novel,
flexible representation of SchA as a heterogeneous-edge graph data structure.

摘要：申克分析（SchA）是一種獨特的音樂分析表達方法，結合旋律、和聲、對位和形式的元素，描述支撐音樂作品的層級結構。然而，儘管其強大的分析效用和提升音樂理解與生成的潛力，電腦音樂社群鮮少使用 SchA。這在很大程度上是因為缺乏可供電腦讀取格式的高品質資料。透過大量的申克資料，我們或許能灌輸機器學習模型更深入的音樂結構理解，進而產生更「人性化」的結果。為了鼓勵進一步研究申克分析及其在音樂資訊學和生成的潛在效益，本文提出三個主要貢獻：1) 一個新的且持續擴充的 SchA 資料集，是迄今為止人機可讀格式中最大的（>140 個摘錄），2) 一個用於 SchA 資料視覺化和收集的新穎軟體，以及 3) 一個新穎且彈性的 SchA 表現形式，作為異質邊緣圖形資料結構。

##### **Unlocking Efficiency: Adaptive Masking for Gene Transformer Models**
2408.07180v1 by Soumyadeep Roy, Shamik Sural, Niloy Ganguly

Gene transformer models such as Nucleotide Transformer, DNABert, and LOGO are
trained to learn optimal gene sequence representations by using the Masked
Language Modeling (MLM) training objective over the complete Human Reference
Genome. However, the typical tokenization methods employ a basic sliding window
of tokens, such as k-mers, that fail to utilize gene-centric semantics. This
could result in the (trivial) masking of easily predictable sequences, leading
to inefficient MLM training. Time-variant training strategies are known to
improve pretraining efficiency in both language and vision tasks. In this work,
we focus on using curriculum masking where we systematically increase the
difficulty of masked token prediction task by using a Pointwise Mutual
Information-based difficulty criterion, as gene sequences lack well-defined
semantic units similar to words or sentences of NLP domain. Our proposed
Curriculum Masking-based Gene Masking Strategy (CM-GEMS) demonstrates superior
representation learning capabilities compared to baseline masking approaches
when evaluated on downstream gene sequence classification tasks. We perform
extensive evaluation in both few-shot (five datasets) and full dataset settings
(Genomic Understanding Evaluation benchmark consisting of 27 tasks). Our
findings reveal that CM-GEMS outperforms state-of-the-art models (DNABert-2,
Nucleotide transformer, DNABert) trained at 120K steps, achieving similar
results in just 10K and 1K steps. We also demonstrate that Curriculum-Learned
LOGO (a 2-layer DNABert-like model) can achieve nearly 90% of the
state-of-the-art model performance of 120K steps. We will make the models and
codes publicly available at https://github.com/roysoumya/curriculum-GeneMask.

摘要：基因轉換器模型，例如 Nucleotide Transformer、DNABert 和 LOGO，
透過使用完整的「人類參考基因組」上的遮蔽語言模型 (MLM) 訓練目標，來學習最佳基因序列表示。然而，典型的標記化方法採用基本標記滑動視窗，例如 k-mers，無法利用以基因為中心的語義。這可能會導致（平凡的）對容易預測的序列進行遮蔽，進而導致低效的 MLM 訓練。已知時變訓練策略可以同時改善語言和視覺任務中的預訓練效率。在這項工作中，我們專注於使用課程遮蔽，其中我們透過使用基於點對互信息難度的標準，系統性地增加遮蔽標記預測任務的難度，因為基因序列缺乏類似於 NLP 領域中單字或句子的明確語義單位。我們提出的基於課程遮蔽的基因遮蔽策略 (CM-GEMS) 在評估下游基因序列分類任務時，展現出優於基線遮蔽方法的卓越表示學習能力。我們在少量樣本（五個資料集）和完整資料集設定（包含 27 個任務的基因體理解評估基準）中執行廣泛評估。我們的發現顯示，CM-GEMS 優於在 120K 步驟中訓練的最新模型（DNABert-2、Nucleotide transformer、DNABert），僅在 10K 和 1K 步驟中就達成類似的結果。我們也證明了課程學習 LOGO（一個 2 層的類似 DNABert 模型）可以達成接近 120K 步驟最新模型效能的 90%。我們將在 https://github.com/roysoumya/curriculum-GeneMask 公開模型和程式碼。

##### **Vision Language Model for Interpretable and Fine-grained Detection of Safety Compliance in Diverse Workplaces**
2408.07146v1 by Zhiling Chen, Hanning Chen, Mohsen Imani, Ruimin Chen, Farhad Imani

Workplace accidents due to personal protective equipment (PPE) non-compliance
raise serious safety concerns and lead to legal liabilities, financial
penalties, and reputational damage. While object detection models have shown
the capability to address this issue by identifying safety items, most existing
models, such as YOLO, Faster R-CNN, and SSD, are limited in verifying the
fine-grained attributes of PPE across diverse workplace scenarios. Vision
language models (VLMs) are gaining traction for detection tasks by leveraging
the synergy between visual and textual information, offering a promising
solution to traditional object detection limitations in PPE recognition.
Nonetheless, VLMs face challenges in consistently verifying PPE attributes due
to the complexity and variability of workplace environments, requiring them to
interpret context-specific language and visual cues simultaneously. We
introduce Clip2Safety, an interpretable detection framework for diverse
workplace safety compliance, which comprises four main modules: scene
recognition, the visual prompt, safety items detection, and fine-grained
verification. The scene recognition identifies the current scenario to
determine the necessary safety gear. The visual prompt formulates the specific
visual prompts needed for the detection process. The safety items detection
identifies whether the required safety gear is being worn according to the
specified scenario. Lastly, the fine-grained verification assesses whether the
worn safety equipment meets the fine-grained attribute requirements. We conduct
real-world case studies across six different scenarios. The results show that
Clip2Safety not only demonstrates an accuracy improvement over state-of-the-art
question-answering based VLMs but also achieves inference times two hundred
times faster.

摘要：<paragraph>由於個人防護設備 (PPE) 未遵守規定而導致的工作場所事故
引發嚴重的安全疑慮，並導致法律責任、財務罰款和聲譽受損。雖然物件偵測模型已展現出透過識別安全物品來解決此問題的能力，但大多數現有的模型，例如 YOLO、Faster R-CNN 和 SSD，在驗證不同工作場所場景中 PPE 的細微屬性方面受到限制。視覺語言模型 (VLM) 透過利用視覺和文本資訊之間的協同作用，在偵測任務中獲得關注，為 PPE 辨識中傳統的物件偵測限制提供了有希望的解決方案。儘管如此，由於工作場所環境的複雜性和變異性，VLM 在持續驗證 PPE 屬性時面臨挑戰，需要它們同時解釋特定於脈絡的語言和視覺線索。我們引入了 Clip2Safety，這是一個可解釋的偵測架構，用於不同的工作場所安全合規性，它包含四個主要模組：場景辨識、視覺提示、安全物品偵測和細微驗證。場景辨識識別當前場景以確定必要的安全裝備。視覺提示制定偵測過程中所需的特定視覺提示。安全物品偵測識別是否根據指定場景配戴所需的防護裝備。最後，細微驗證評估配戴的安全裝備是否符合細微的屬性要求。我們在六種不同的場景中進行了真實世界的案例研究。結果表明，Clip2Safety 不僅證明了比最先進的基於問答的 VLM 準確性有所提升，而且推理時間也快了兩百倍。</paragraph>

##### **Language Models as Models of Language**
2408.07144v1 by Raphaël Millière

This chapter critically examines the potential contributions of modern
language models to theoretical linguistics. Despite their focus on engineering
goals, these models' ability to acquire sophisticated linguistic knowledge from
mere exposure to data warrants a careful reassessment of their relevance to
linguistic theory. I review a growing body of empirical evidence suggesting
that language models can learn hierarchical syntactic structure and exhibit
sensitivity to various linguistic phenomena, even when trained on
developmentally plausible amounts of data. While the competence/performance
distinction has been invoked to dismiss the relevance of such models to
linguistic theory, I argue that this assessment may be premature. By carefully
controlling learning conditions and making use of causal intervention methods,
experiments with language models can potentially constrain hypotheses about
language acquisition and competence. I conclude that closer collaboration
between theoretical linguists and computational researchers could yield
valuable insights, particularly in advancing debates about linguistic nativism.

摘要：本章節批判性地探討了現代語言模型對理論語言學的潛在貢獻。儘管這些模型專注於工程目標，但它們從單純接觸資料就能獲取複雜語言知識的能力，值得仔細重新評估它們與語言理論的相關性。我回顧了越來越多的實證證據，表明語言模型可以學習階層語法結構，並對各種語言現象表現出敏感性，即使是在以發展上合理的資料量進行訓練時。雖然能力/表現區別已被用來否定此類模型與語言理論相關性，但我認為這種評估可能為時過早。通過仔細控制學習條件並利用因果干預方法，使用語言模型進行的實驗有可能約束有關語言習得和能力的假設。我得出結論，理論語言學家和計算研究人員之間的更密切合作可以產生有價值的見解，特別是在推進關於語言天生的辯論方面。

##### **ELLA: Empowering LLMs for Interpretable, Accurate and Informative Legal Advice**
2408.07137v1 by Yutong Hu, Kangcheng Luo, Yansong Feng

Despite remarkable performance in legal consultation exhibited by legal Large
Language Models(LLMs) combined with legal article retrieval components, there
are still cases when the advice given is incorrect or baseless. To alleviate
these problems, we propose {\bf ELLA}, a tool for {\bf E}mpowering {\bf L}LMs
for interpretable, accurate, and informative {\bf L}egal {\bf A}dvice. ELLA
visually presents the correlation between legal articles and LLM's response by
calculating their similarities, providing users with an intuitive legal basis
for the responses. Besides, based on the users' queries, ELLA retrieves
relevant legal articles and displays them to users. Users can interactively
select legal articles for LLM to generate more accurate responses. ELLA also
retrieves relevant legal cases for user reference. Our user study shows that
presenting the legal basis for the response helps users understand better. The
accuracy of LLM's responses also improves when users intervene in selecting
legal articles for LLM. Providing relevant legal cases also aids individuals in
obtaining comprehensive information.

摘要：儘管法律大型語言模型 (LLM) 與法律條文檢索元件結合後在法律諮詢方面表現出色，但有時給出的建議仍不正確或沒有根據。為了緩解這些問題，我們提出了「ELLA」，一個賦能 LLM 以提供可解釋、準確且具參考價值的法律建議的工具。ELLA 透過計算法律條文與 LLM 回應之間的相似性，視覺化呈現兩者之間的關聯性，為使用者提供回應的直觀法律依據。此外，ELLA 會根據使用者的查詢，檢索相關的法律條文並顯示給使用者。使用者可以互動式地選擇法律條文，讓 LLM 產生更準確的回應。ELLA 也會檢索相關的法律案例供使用者參考。我們的使用者研究顯示，呈現回應的法律依據有助於使用者更深入地理解。當使用者介入選擇 LLM 的法律條文時，LLM 回應的準確度也會提高。提供相關的法律案例也有助於個人獲得全面的資訊。

##### **Fingerspelling within Sign Language Translation**
2408.07065v1 by Garrett Tanzer

Fingerspelling poses challenges for sign language processing due to its
high-frequency motion and use for open-vocabulary terms. While prior work has
studied fingerspelling recognition, there has been little attention to
evaluating how well sign language translation models understand fingerspelling
in the context of entire sentences -- and improving this capability. We
manually annotate instances of fingerspelling within FLEURS-ASL and use them to
evaluate the effect of two simple measures to improve fingerspelling
recognition within American Sign Language to English translation: 1) use a
model family (ByT5) with character- rather than subword-level tokenization, and
2) mix fingerspelling recognition data into the translation training mixture.
We find that 1) substantially improves understanding of fingerspelling (and
therefore translation quality overall), but the effect of 2) is mixed.

摘要：手語拼字由於其高頻率動作和用於開放式詞彙術語而對手語處理構成挑戰。雖然先前的研究已經研究了手語拼字識別，但對於評估手語翻譯模型在整個句子中理解手語拼字的能力以及提高這種能力的關注卻很少。我們手動註解了 FLEURS-ASL 中的手語拼字實例，並使用它們來評估兩個簡單措施對提高手語拼字識別的影響，從而將美國手語翻譯成英文：1) 使用具有字元而非子字元級標記化的模型系列 (ByT5)，以及 2) 將手語拼字識別資料混合到翻譯訓練混合中。我們發現 1) 大大提高了對手語拼字的理解（因此整體翻譯品質也提高了），但 2) 的效果卻好壞參半。

##### **Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**
2408.07060v1 by Kexun Zhang, Weiran Yao, Zuxin Liu, Yihao Feng, Zhiwei Liu, Rithesh Murthy, Tian Lan, Lei Li, Renze Lou, Jiacheng Xu, Bo Pang, Yingbo Zhou, Shelby Heinecke, Silvio Savarese, Huan Wang, Caiming Xiong

Large language model (LLM) agents have shown great potential in solving
real-world software engineering (SWE) problems. The most advanced open-source
SWE agent can resolve over 27% of real GitHub issues in SWE-Bench Lite.
However, these sophisticated agent frameworks exhibit varying strengths,
excelling in certain tasks while underperforming in others. To fully harness
the diversity of these agents, we propose DEI (Diversity Empowered
Intelligence), a framework that leverages their unique expertise. DEI functions
as a meta-module atop existing SWE agent frameworks, managing agent collectives
for enhanced problem-solving. Experimental results show that a DEI-guided
committee of agents is able to surpass the best individual agent's performance
by a large margin. For instance, a group of open-source SWE agents, with a
maximum individual resolve rate of 27.3% on SWE-Bench Lite, can achieve a 34.3%
resolve rate with DEI, making a 25% improvement and beating most closed-source
solutions. Our best-performing group excels with a 55% resolve rate, securing
the highest ranking on SWE-Bench Lite. Our findings contribute to the growing
body of research on collaborative AI systems and their potential to solve
complex software engineering challenges.

摘要：大型語言模型 (LLM) 代理在解決現實世界的軟體工程 (SWE) 問題方面展現了極大的潛力。最先進的開源 SWE 代理可以在 SWE-Bench Lite 中解決超過 27% 的實際 GitHub 問題。然而，這些複雜的代理架構表現出不同的優勢，在某些任務中表現出色，而在其他任務中表現不佳。為了充分利用這些代理的多樣性，我們提出了 DEI（Diversity Empowered Intelligence），一個利用其獨特專業知識的框架。DEI 作為一個元模組，位於現有的 SWE 代理架構之上，管理代理集合以增強問題解決能力。實驗結果表明，DEI 指導的代理委員會能夠大幅超越最佳個別代理的表現。例如，一群開源 SWE 代理，在 SWE-Bench Lite 上的最高個別解決率為 27.3%，使用 DEI 可以達到 34.3% 的解決率，改進了 25%，並且勝過大多數閉源解決方案。我們表現最好的組別以 55% 的解決率脫穎而出，在 SWE-Bench Lite 上獲得最高排名。我們的研究結果有助於擴大協作式 AI 系統的研究領域，以及它們解決複雜軟體工程挑戰的潛力。

##### **Model Counting in the Wild**
2408.07059v1 by Arijit Shaw, Kuldeep S. Meel

Model counting is a fundamental problem in automated reasoning with
applications in probabilistic inference, network reliability, neural network
verification, and more. Although model counting is computationally intractable
from a theoretical perspective due to its #P-completeness, the past decade has
seen significant progress in developing state-of-the-art model counters to
address scalability challenges.
  In this work, we conduct a rigorous assessment of the scalability of model
counters in the wild. To this end, we surveyed 11 application domains and
collected an aggregate of 2262 benchmarks from these domains. We then evaluated
six state-of-the-art model counters on these instances to assess scalability
and runtime performance.
  Our empirical evaluation demonstrates that the performance of model counters
varies significantly across different application domains, underscoring the
need for careful selection by the end user. Additionally, we investigated the
behavior of different counters with respect to two parameters suggested by the
model counting community, finding only a weak correlation. Our analysis
highlights the challenges and opportunities for portfolio-based approaches in
model counting.

摘要：模型計數是自動推理中的基本問題，在機率推論、網路可靠度、神經網路驗證等領域有其應用。儘管模型計數在理論上因其 #P-completeness 而在計算上難以處理，過去十年來，在開發最先進的模型計數器以解決可擴充性挑戰方面已取得顯著進展。
在本文中，我們對模型計數器的可擴充性進行了嚴謹的評估。為此，我們調查了 11 個應用領域，並從這些領域收集了 2262 個基準。然後，我們在這些實例上評估了六個最先進的模型計數器，以評估可擴充性和執行時間效能。
我們的實證評估表明，模型計數器的效能因不同的應用領域而異，這凸顯了最終使用者仔細選擇的必要性。此外，我們研究了不同計數器相對於模型計數社群建議的兩個參數的行為，發現只有微弱的相關性。我們的分析重點說明了模型計數中基於投資組合的方法所面臨的挑戰和機會。

##### **A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning**
2408.07057v1 by Prateek Yadav, Colin Raffel, Mohammed Muqeeth, Lucas Caccia, Haokun Liu, Tianlong Chen, Mohit Bansal, Leshem Choshen, Alessandro Sordoni

The availability of performant pre-trained models has led to a proliferation
of fine-tuned expert models that are specialized to a particular domain or
task. Model MoErging methods aim to recycle expert models to create an
aggregate system with improved performance or generalization. A key component
of MoErging methods is the creation of a router that decides which expert
model(s) to use for a particular input or application. The promise,
effectiveness, and large design space of MoErging has spurred the development
of many new methods over the past few years. This rapid pace of development has
made it challenging to compare different MoErging methods, which are rarely
compared to one another and are often validated in different experimental
setups. To remedy such gaps, we present a comprehensive survey of MoErging
methods that includes a novel taxonomy for cataloging key design choices and
clarifying suitable applications for each method. Apart from surveying MoErging
research, we inventory software tools and applications that make use of
MoErging. We additionally discuss related fields of study such as model
merging, multitask learning, and mixture-of-experts models. Taken as a whole,
our survey provides a unified overview of existing MoErging methods and creates
a solid foundation for future work in this burgeoning field.

摘要：<paragraph>高效預訓練模型的可用性導致專門針對特定領域或任務進行微調的專家模型激增。模型合併方法旨在回收專家模型，以建立具有改進性能或泛化的聚合系統。合併方法的一個關鍵組成部分是建立一個路由器，用於決定針對特定輸入或應用程式使用哪個專家模型。合併的承諾、有效性和廣闊的設計空間在過去幾年中刺激了許多新方法的發展。這種快速的發展步伐使得比較不同的合併方法具有挑戰性，這些方法很少相互比較，而且通常在不同的實驗設置中得到驗證。為了彌補這些差距，我們對合併方法進行了全面的調查，其中包括一種新穎的分類法，用於編目關鍵設計選擇並釐清每種方法的合適應用。除了調查合併研究之外，我們還清點了使用合併的軟體工具和應用程式。此外，我們還討論了相關的研究領域，例如模型合併、多任務學習和專家混合模型。總的來說，我們的調查提供了現有合併方法的統一概述，並為這個新興領域的未來工作奠定了堅實的基礎。</paragraph>

##### **LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs**
2408.07055v1 by Yushi Bai, Jiajie Zhang, Xin Lv, Linzhi Zheng, Siqi Zhu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li

Current long context large language models (LLMs) can process inputs up to
100,000 tokens, yet struggle to generate outputs exceeding even a modest length
of 2,000 words. Through controlled experiments, we find that the model's
effective generation length is inherently bounded by the sample it has seen
during supervised fine-tuning (SFT). In other words, their output limitation is
due to the scarcity of long-output examples in existing SFT datasets. To
address this, we introduce AgentWrite, an agent-based pipeline that decomposes
ultra-long generation tasks into subtasks, enabling off-the-shelf LLMs to
generate coherent outputs exceeding 20,000 words. Leveraging AgentWrite, we
construct LongWriter-6k, a dataset containing 6,000 SFT data with output
lengths ranging from 2k to 32k words. By incorporating this dataset into model
training, we successfully scale the output length of existing models to over
10,000 words while maintaining output quality. We also develop LongBench-Write,
a comprehensive benchmark for evaluating ultra-long generation capabilities.
Our 9B parameter model, further improved through DPO, achieves state-of-the-art
performance on this benchmark, surpassing even much larger proprietary models.
In general, our work demonstrates that existing long context LLM already
possesses the potential for a larger output window--all you need is data with
extended output during model alignment to unlock this capability. Our code &
models are at: https://github.com/THUDM/LongWriter.

摘要：<paragraph>現今長語境大型語言模型 (LLM) 能處理多達 100,000 個詞彙的輸入，但仍難以產生超過 2,000 字的適度長度輸出。透過受控實驗，我們發現模型的有效產生長度本質上受到在監督微調 (SFT) 期間所見範例的限制。換句話說，他們的輸出限制是因現有 SFT 資料集中缺乏長輸出範例所致。為了解決此問題，我們引入了 AgentWrite，一個基於代理的管道，將超長產生任務分解成子任務，使現成的 LLM 能夠產生超過 20,000 字的相干輸出。利用 AgentWrite，我們構建了 LongWriter-6k，一個包含 6,000 個 SFT 資料的資料集，輸出長度從 2k 到 32k 字不等。透過將此資料集納入模型訓練中，我們成功地將現有模型的輸出長度擴展到超過 10,000 字，同時維持輸出品質。我們也開發了 LongBench-Write，一個評估超長產生能力的綜合基準。我們透過 DPO 進一步改進的 9B 參數模型，在此基準上達到了最先進的效能，甚至超越了更大規模的專有模型。總體而言，我們的研究證明現有的長語境 LLM 已具備更大輸出視窗的潛力——只要在模型比對期間提供具有延伸輸出的資料，就能解鎖此能力。我們的程式碼和模型位於：https://github.com/THUDM/LongWriter。</paragraph>

##### **TableGuard -- Securing Structured & Unstructured Data**
2408.07045v1 by Anantha Sharma, Ajinkya Deshmukh

With the increasing demand for data sharing across platforms and
organizations, ensuring the privacy and security of sensitive information has
become a critical challenge. This paper introduces "TableGuard". An innovative
approach to data obfuscation tailored for relational databases. Building on the
principles and techniques developed in prior work on context-sensitive
obfuscation, TableGuard applies these methods to ensure that API calls return
only obfuscated data, thereby safeguarding privacy when sharing data with third
parties. TableGuard leverages advanced context-sensitive obfuscation techniques
to replace sensitive data elements with contextually appropriate alternatives.
By maintaining the relational integrity and coherence of the data, our approach
mitigates the risks of cognitive dissonance and data leakage. We demonstrate
the implementation of TableGuard using a BERT based transformer model, which
identifies and obfuscates sensitive entities within relational tables. Our
evaluation shows that TableGuard effectively balances privacy protection with
data utility, minimizing information loss while ensuring that the obfuscated
data remains functionally useful for downstream applications. The results
highlight the importance of domain-specific obfuscation strategies and the role
of context length in preserving data integrity. The implications of this
research are significant for organizations that need to share data securely
with external parties. TableGuard offers a robust framework for implementing
privacy-preserving data sharing mechanisms, thereby contributing to the broader
field of data privacy and security.

摘要：隨著跨平台和組織對資料共享需求的增加，確保敏感資訊的隱私和安全性已成為一項嚴峻的挑戰。本文介紹「TableGuard」。這是一種創新的資料混淆方法，專為關聯式資料庫量身打造。TableGuard 建立在先前關於情境敏感混淆的研究原理和技術之上，將這些方法應用於確保 API 呼叫只會傳回混淆後的資料，從而保護與第三方共享資料時的隱私。TableGuard 採用先進的情境敏感混淆技術，用符合情境的替代方案取代敏感資料元素。透過維持資料的關聯性完整性和一致性，我們的做法減輕了認知失調和資料外洩的風險。我們使用基於 BERT 的Transformer模型來展示 TableGuard 的實作，此模型會識別並混淆關聯式表格中的敏感實體。我們的評估顯示，TableGuard 有效地平衡了隱私保護和資料效用，將資訊損失降至最低，同時確保混淆後的資料對下游應用程式仍具有功能性。結果突顯了特定領域混淆策略的重要性，以及情境長度在維護資料完整性中所扮演的角色。這項研究的影響對需要與外部方安全地共享資料的組織來說意義重大。TableGuard 提供了一個強大的架構來實作保護隱私的資料共享機制，從而為資料隱私和安全更廣泛的領域做出貢獻。

##### **KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation**
2408.07040v1 by Daniele Rege Cambrin, Eleonora Poeta, Eliana Pastor, Tania Cerquitelli, Elena Baralis, Paolo Garza

Segmentation of crop fields is essential for enhancing agricultural
productivity, monitoring crop health, and promoting sustainable practices. Deep
learning models adopted for this task must ensure accurate and reliable
predictions to avoid economic losses and environmental impact. The newly
proposed Kolmogorov-Arnold networks (KANs) offer promising advancements in the
performance of neural networks. This paper analyzes the integration of KAN
layers into the U-Net architecture (U-KAN) to segment crop fields using
Sentinel-2 and Sentinel-1 satellite images and provides an analysis of the
performance and explainability of these networks. Our findings indicate a 2\%
improvement in IoU compared to the traditional full-convolutional U-Net model
in fewer GFLOPs. Furthermore, gradient-based explanation techniques show that
U-KAN predictions are highly plausible and that the network has a very high
ability to focus on the boundaries of cultivated areas rather than on the areas
themselves. The per-channel relevance analysis also reveals that some channels
are irrelevant to this task.

摘要：農作物田區分割對於提升農業生產力、監控作物健康和促進永續實務至關重要。採用於此任務的深度學習模型必須確保準確且可靠的預測，以避免經濟損失和環境影響。新提出的柯爾莫哥洛夫-阿諾德網路 (KAN) 為神經網路的效能提供了有希望的進展。本文分析將 KAN 層整合到 U-Net 架構 (U-KAN) 中，以使用 Sentinel-2 和 Sentinel-1 衛星影像分割農作物田區，並提供對這些網路效能和可解釋性的分析。我們的研究結果顯示，與傳統的全卷積 U-Net 模型相比，IoU 提升了 2%，而 GFLOP 較少。此外，基於梯度的解釋技術顯示 U-KAN 預測非常合理，而且網路非常有能力專注於耕作區域的邊界，而不是區域本身。每個通道關聯性分析也顯示，有些通道與此任務無關。

##### **PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology**
2408.07037v1 by Xiaomin Wu, Rui Xu, Pengchen Wei, Wenkang Qin, Peixiang Huang, Ziheng Li, Lin Luo

Pathological diagnosis remains the definitive standard for identifying
tumors. The rise of multimodal large models has simplified the process of
integrating image analysis with textual descriptions. Despite this advancement,
the substantial costs associated with training and deploying these complex
multimodal models, together with a scarcity of high-quality training datasets,
create a significant divide between cutting-edge technology and its application
in the clinical setting. We had meticulously compiled a dataset of
approximately 45,000 cases, covering over 6 different tasks, including the
classification of organ tissues, generating pathology report descriptions, and
addressing pathology-related questions and answers. We have fine-tuned
multimodal large models, specifically LLaVA, Qwen-VL, InternLM, with this
dataset to enhance instruction-based performance. We conducted a qualitative
assessment of the capabilities of the base model and the fine-tuned model in
performing image captioning and classification tasks on the specific dataset.
The evaluation results demonstrate that the fine-tuned model exhibits
proficiency in addressing typical pathological questions. We hope that by
making both our models and datasets publicly available, they can be valuable to
the medical and research communities.

摘要：病理診斷仍然是識別腫瘤的明確標準。多模態大型模型的興起簡化了將影像分析與文字描述整合的過程。儘管有此進展，但訓練和部署這些複雜的多模態模型相關的龐大成本，以及缺乏高品質的訓練資料集，導致尖端技術與其在臨床環境中的應用之間產生了顯著的差距。我們已細心編制了一個包含約 45,000 個案例的資料集，涵蓋 6 項不同的任務，包括器官組織分類、產生病理報告描述，以及回答與病理相關的問題。我們使用這個資料集微調了多模態大型模型，特別是 LLaVA、Qwen-VL、InternLM，以增強基於指令的效能。我們對基礎模型和微調模型在特定資料集上執行影像標題和分類任務的能力進行了定性評估。評估結果表明，微調模型在回答典型病理問題方面表現出熟練度。我們希望透過公開我們的模型和資料集，它們能對醫療和研究社群有價值。

##### **Casper: Prompt Sanitization for Protecting User Privacy in Web-Based Large Language Models**
2408.07004v1 by Chun Jie Chong, Chenxi Hou, Zhihao Yao, Seyed Mohammadjavad Seyed Talebi

Web-based Large Language Model (LLM) services have been widely adopted and
have become an integral part of our Internet experience. Third-party plugins
enhance the functionalities of LLM by enabling access to real-world data and
services. However, the privacy consequences associated with these services and
their third-party plugins are not well understood. Sensitive prompt data are
stored, processed, and shared by cloud-based LLM providers and third-party
plugins. In this paper, we propose Casper, a prompt sanitization technique that
aims to protect user privacy by detecting and removing sensitive information
from user inputs before sending them to LLM services. Casper runs entirely on
the user's device as a browser extension and does not require any changes to
the online LLM services. At the core of Casper is a three-layered sanitization
mechanism consisting of a rule-based filter, a Machine Learning (ML)-based
named entity recognizer, and a browser-based local LLM topic identifier. We
evaluate Casper on a dataset of 4000 synthesized prompts and show that it can
effectively filter out Personal Identifiable Information (PII) and
privacy-sensitive topics with high accuracy, at 98.5% and 89.9%, respectively.

摘要：基於網路的大型語言模型 (LLM) 服務已被廣泛採用，並已成為我們網路體驗中不可或缺的一部分。第三方外掛程式透過提供存取真實世界資料和服務的功能，來增強 LLM 的功能。然而，與這些服務及其第三方外掛程式相關的隱私後果尚未被充分理解。基於雲端的 LLM 提供者和第三方外掛程式會儲存、處理和分享敏感的提示資料。在本文中，我們提出 Casper，這是一種提示消毒技術，旨在透過在將使用者輸入資料傳送至 LLM 服務之前偵測並移除敏感資訊，來保護使用者隱私。Casper 完全在使用者的裝置上以瀏覽器擴充功能執行，且不需要對線上 LLM 服務進行任何變更。Casper 的核心是一個三層式的消毒機制，包含一個基於規則的篩選器、一個基於機器學習 (ML) 的命名實體辨識器和一個基於瀏覽器的本地 LLM 主題識別器。我們在一個由 4000 個合成提示組成的資料集上評估 Casper，並顯示它可以有效地過濾出個人可識別資訊 (PII) 和隱私敏感主題，且準確度很高，分別為 98.5% 和 89.9%。

##### **Generative AI for automatic topic labelling**
2408.07003v1 by Diego Kozlowski, Carolina Pradier, Pierre Benz

Topic Modeling has become a prominent tool for the study of scientific
fields, as they allow for a large scale interpretation of research trends.
Nevertheless, the output of these models is structured as a list of keywords
which requires a manual interpretation for the labelling. This paper proposes
to assess the reliability of three LLMs, namely flan, GPT-4o, and GPT-4 mini
for topic labelling. Drawing on previous research leveraging BERTopic, we
generate topics from a dataset of all the scientific articles (n=34,797)
authored by all biology professors in Switzerland (n=465) between 2008 and
2020, as recorded in the Web of Science database. We assess the output of the
three models both quantitatively and qualitatively and find that, first, both
GPT models are capable of accurately and precisely label topics from the
models' output keywords. Second, 3-word labels are preferable to grasp the
complexity of research topics.

摘要：主題建模已成為科學領域研究的顯著工具，因為它們允許大規模解釋研究趨勢。儘管如此，這些模型的輸出被結構化為關鍵字列表，需要手動解釋才能標籤。本文提出評估三個 LLM 的可靠性，即 flan、GPT-4o 和 GPT-4 mini，用於主題標籤。利用利用 BERTopic 的先前研究，我們從所有生物學教授在瑞士（n=465）於 2008 年至 2020 年間撰寫的所有科學文章（n=34,797）的數據集中生成主題，如 Web of Science 數據庫中所記錄。我們對這三個模型的輸出進行定量和定性評估，發現首先，兩個 GPT 模型都能够準確且精確地標記模型輸出關鍵字的主題。其次，3 字標籤更適合掌握研究主題的複雜性。

##### **A Theory-Based Explainable Deep Learning Architecture for Music Emotion**
2408.07113v1 by Hortense Fong, Vineet Kumar, K. Sudhir

This paper paper develops a theory-based, explainable deep learning
convolutional neural network (CNN) classifier to predict the time-varying
emotional response to music. We design novel CNN filters that leverage the
frequency harmonics structure from acoustic physics known to impact the
perception of musical features. Our theory-based model is more parsimonious,
but provides comparable predictive performance to atheoretical deep learning
models, while performing better than models using handcrafted features. Our
model can be complemented with handcrafted features, but the performance
improvement is marginal. Importantly, the harmonics-based structure placed on
the CNN filters provides better explainability for how the model predicts
emotional response (valence and arousal), because emotion is closely related to
consonance--a perceptual feature defined by the alignment of harmonics.
Finally, we illustrate the utility of our model with an application involving
digital advertising. Motivated by YouTube mid-roll ads, we conduct a lab
experiment in which we exogenously insert ads at different times within videos.
We find that ads placed in emotionally similar contexts increase ad engagement
(lower skip rates, higher brand recall rates). Ad insertion based on emotional
similarity metrics predicted by our theory-based, explainable model produces
comparable or better engagement relative to atheoretical models.

摘要：本文提出一個基於理論，可解釋深度學習卷積神經網路 (CNN) 分類器，用於預測音樂的時間變動情緒反應。我們設計新的 CNN 濾波器，利用聲學物理中的頻率諧波結構，已知會影響音樂特徵的感知。我們的基於理論的模型較簡約，但提供與非理論深度學習模型相當的預測效能，同時比使用手工特徵的模型表現更好。我們的模型可用手工特徵補充，但效能提升幅度不大。重要的是，置於 CNN 濾波器上的諧波結構，提供更好的解釋性，說明模型如何預測情緒反應（效價和喚醒），因為情緒與協和密切相關，而協和是由諧波對齊定義的感知特徵。最後，我們以涉及數位廣告的應用程式說明我們模型的效用。受到 YouTube 中間穿插廣告的啟發，我們進行一項實驗室實驗，在影片中不同時間點外生插入廣告。我們發現置於情緒相似情境中的廣告，會增加廣告互動（較低的跳過率，較高的品牌回憶率）。基於我們基於理論的可解釋模型所預測的情緒相似度指標插入廣告，會產生與非理論模型相當或更好的互動。

##### **LLMs can Schedule**
2408.06993v1 by Henrik Abgaryan, Ararat Harutyunyan, Tristan Cazenave

The job shop scheduling problem (JSSP) remains a significant hurdle in
optimizing production processes. This challenge involves efficiently allocating
jobs to a limited number of machines while minimizing factors like total
processing time or job delays. While recent advancements in artificial
intelligence have yielded promising solutions, such as reinforcement learning
and graph neural networks, this paper explores the potential of Large Language
Models (LLMs) for JSSP. We introduce the very first supervised 120k dataset
specifically designed to train LLMs for JSSP. Surprisingly, our findings
demonstrate that LLM-based scheduling can achieve performance comparable to
other neural approaches. Furthermore, we propose a sampling method that
enhances the effectiveness of LLMs in tackling JSSP.

摘要：作業車間排程問題 (JSSP) 仍然是最佳化生產流程中的一大障礙。這項挑戰涉及將作業有效分配到數量有限的機器，同時將總處理時間或作業延遲等因素降至最低。儘管人工智慧的最新進展已產生有希望的解決方案，例如強化學習和圖形神經網路，但本文探討了大型語言模型 (LLM) 在 JSSP 中的潛力。我們引入了第一個監督式 120k 資料集，專門用於訓練 JSSP 的 LLM。令人驚訝的是，我們的研究結果表明，基於 LLM 的排程可以達到與其他神經方法相當的效能。此外，我們提出了一種抽樣方法，可增強 LLM 在處理 JSSP 中的有效性。

##### **Neural Speech and Audio Coding**
2408.06954v1 by Minje Kim, Jan Skoglund

This paper explores the integration of model-based and data-driven approaches
within the realm of neural speech and audio coding systems. It highlights the
challenges posed by the subjective evaluation processes of speech and audio
codecs and discusses the limitations of purely data-driven approaches, which
often require inefficiently large architectures to match the performance of
model-based methods. The study presents hybrid systems as a viable solution,
offering significant improvements to the performance of conventional codecs
through meticulously chosen design enhancements. Specifically, it introduces a
neural network-based signal enhancer designed to post-process existing codecs'
output, along with the autoencoder-based end-to-end models and LPCNet--hybrid
systems that combine linear predictive coding (LPC) with neural networks.
Furthermore, the paper delves into predictive models operating within custom
feature spaces (TF-Codec) or predefined transform domains (MDCTNet) and
examines the use of psychoacoustically calibrated loss functions to train
end-to-end neural audio codecs. Through these investigations, the paper
demonstrates the potential of hybrid systems to advance the field of speech and
audio coding by bridging the gap between traditional model-based approaches and
modern data-driven techniques.

摘要：這篇論文探討了基於模型和數據驅動方法在神經語言和音訊編碼系統領域的整合。它強調了語音和音訊編解碼器的主觀評估過程所帶來的挑戰，並討論了純數據驅動方法的局限性，這種方法通常需要低效率的大架構才能與基於模型的方法相匹配。研究提出混合系統作為可行的解決方案，通過精心選擇的設計改進，顯著改善傳統編解碼器的性能。具體來說，它引入了一個基於神經網路的信號增強器，旨在後處理現有編解碼器的輸出，以及基於自動編碼器的端到端模型和 LPCNet——將線性預測編碼 (LPC) 與神經網路相結合的混合系統。此外，本文深入探討了在自定義特徵空間 (TF-Codec) 或預定義變換域 (MDCTNet) 中運作的預測模型，並探討了使用經過心理聲學校準的損失函數來訓練端到端神經音訊編解碼器。通過這些研究，本文展示了混合系統在語言和音訊編碼領域的潛力，通過彌合傳統基於模型的方法和現代數據驅動技術之間的差距。

##### **The advantages of context specific language models: the case of the Erasmian Language Model**
2408.06931v1 by João Gonçalves, Nick Jelicic, Michele Murgia, Evert Stamhuis

The current trend to improve language model performance seems to be based on
scaling up with the number of parameters (e.g. the state of the art GPT4 model
has approximately 1.7 trillion parameters) or the amount of training data fed
into the model. However this comes at significant costs in terms of
computational resources and energy costs that compromise the sustainability of
AI solutions, as well as risk relating to privacy and misuse. In this paper we
present the Erasmian Language Model (ELM) a small context specific, 900 million
parameter model, pre-trained and fine-tuned by and for Erasmus University
Rotterdam. We show how the model performs adequately in a classroom context for
essay writing, and how it achieves superior performance in subjects that are
part of its context. This has implications for a wide range of institutions and
organizations, showing that context specific language models may be a viable
alternative for resource constrained, privacy sensitive use cases.

摘要：目前提升語言模型效能的趨勢似乎是基於參數數量擴充（例如，最先進的 GPT4 模型大約有 1.7 兆個參數）或輸入模型的訓練資料量。然而，這會帶來龐大的運算資源和能源成本，影響 AI 解決方案的可持續性，以及與隱私和濫用相關的風險。在本文中，我們提出伊拉斯謨語言模型 (ELM)，這是一個針對特定脈絡的小型 9 億參數模型，由鹿特丹伊拉斯謨大學預先訓練和微調。我們展示該模型如何在教室環境中適當地撰寫論文，以及如何在屬於其脈絡的科目中取得卓越的表現。這對許多機構和組織具有影響，表明特定脈絡的語言模型可能是資源受限、注重隱私的使用案例的可行替代方案。

##### **Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification**
2408.06930v2 by Bauke Arends, Melle Vessies, Dirk van Osch, Arco Teske, Pim van der Harst, René van Es, Bram van Es

Clinical machine learning research and AI driven clinical decision support
models rely on clinically accurate labels. Manually extracting these labels
with the help of clinical specialists is often time-consuming and expensive.
This study tests the feasibility of automatic span- and document-level
diagnosis extraction from unstructured Dutch echocardiogram reports. We
included 115,692 unstructured echocardiogram reports from the UMCU a large
university hospital in the Netherlands. A randomly selected subset was manually
annotated for the occurrence and severity of eleven commonly described cardiac
characteristics. We developed and tested several automatic labelling techniques
at both span and document levels, using weighted and macro F1-score, precision,
and recall for performance evaluation. We compared the performance of span
labelling against document labelling methods, which included both direct
document classifiers and indirect document classifiers that rely on span
classification results. The SpanCategorizer and MedRoBERTa$.$nl models
outperformed all other span and document classifiers, respectively. The
weighted F1-score varied between characteristics, ranging from 0.60 to 0.93 in
SpanCategorizer and 0.96 to 0.98 in MedRoBERTa$.$nl. Direct document
classification was superior to indirect document classification using span
classifiers. SetFit achieved competitive document classification performance
using only 10% of the training data. Utilizing a reduced label set yielded
near-perfect document classification results. We recommend using our published
SpanCategorizer and MedRoBERTa$.$nl models for span- and document-level
diagnosis extraction from Dutch echocardiography reports. For settings with
limited training data, SetFit may be a promising alternative for document
classification.

摘要：<paragraph>臨床機器學習研究和人工智慧驅動的臨床決策支援
模型依賴於臨床準確的標籤。在臨床專家的協助下，手動提取這些標籤通常既耗時又昂貴。
本研究測試了從非結構化荷蘭超音波心動圖報告中自動提取跨度和文件級別診斷的可行性。我們
納入了來自荷蘭一家大型大學醫院 UMCU 的 115,692 份非結構化超音波心動圖報告。隨機選擇的子集經過手動註解，以了解十一種常見描述的心臟
特徵的發生和嚴重程度。我們開發並測試了跨度和文件級別的幾種自動標籤技術，使用加權和巨集 F1 分數、精確度，
以及召回率進行效能評估。我們比較了跨度
標籤與文件標籤方法的效能，其中包括直接
文件分類器和依賴於跨度
分類結果的間接文件分類器。SpanCategorizer 和 MedRoBERTa$.$nl 模型
分別優於所有其他跨度和文件分類器。
加權 F1 分數因特徵而異，SpanCategorizer 中的範圍從 0.60 到 0.93，MedRoBERTa$.$nl 中的範圍從 0.96 到 0.98。使用跨度
分類器的間接文件分類不如直接文件分類。SetFit 僅使用 10% 的訓練資料就達到了具有競爭力的文件分類效能。利用減少的標籤集產生了近乎完美的文件分類結果。我們建議使用我們發布的 SpanCategorizer 和 MedRoBERTa$.$nl 模型從荷蘭超音波心動圖報告中提取跨度和文件級別診斷。對於訓練資料有限的設定，SetFit 可能是一種有前途的文件
分類替代方案。</paragraph>

##### **Evaluating Cultural Adaptability of a Large Language Model via Simulation of Synthetic Personas**
2408.06929v1 by Louis Kwok, Michal Bravansky, Lewis D. Griffin

The success of Large Language Models (LLMs) in multicultural environments
hinges on their ability to understand users' diverse cultural backgrounds. We
measure this capability by having an LLM simulate human profiles representing
various nationalities within the scope of a questionnaire-style psychological
experiment. Specifically, we employ GPT-3.5 to reproduce reactions to
persuasive news articles of 7,286 participants from 15 countries; comparing the
results with a dataset of real participants sharing the same demographic
traits. Our analysis shows that specifying a person's country of residence
improves GPT-3.5's alignment with their responses. In contrast, using native
language prompting introduces shifts that significantly reduce overall
alignment, with some languages particularly impairing performance. These
findings suggest that while direct nationality information enhances the model's
cultural adaptability, native language cues do not reliably improve simulation
fidelity and can detract from the model's effectiveness.

摘要：大型語言模型 (LLM) 在多元文化環境中的成功取決於它們理解使用者多元文化背景的能力。我們透過讓 LLM 模擬問卷式心理實驗中代表各種國籍的人類特徵來衡量這種能力。具體來說，我們使用 GPT-3.5 來重現來自 15 個國家的 7,286 名參與者對有說服力的新聞文章的反應；將結果與具有相同人口統計特徵的真實參與者資料集進行比較。我們的分析表明，指定個人的居住國家可以改善 GPT-3.5 與其反應的一致性。相反，使用母語提示會引入轉變，顯著降低整體一致性，有些語言特別會損害效能。這些發現表明，雖然直接的國籍資訊可以增強模型的文化適應性，但母語提示並不能可靠地改善模擬保真度，甚至可能降低模型的效能。

##### **Heterogeneous Space Fusion and Dual-Dimension Attention: A New Paradigm for Speech Enhancement**
2408.06911v1 by Tao Zheng, Liejun Wang, Yinfeng Yu

Self-supervised learning has demonstrated impressive performance in speech
tasks, yet there remains ample opportunity for advancement in the realm of
speech enhancement research. In addressing speech tasks, confining the
attention mechanism solely to the temporal dimension poses limitations in
effectively focusing on critical speech features. Considering the
aforementioned issues, our study introduces a novel speech enhancement
framework, HFSDA, which skillfully integrates heterogeneous spatial features
and incorporates a dual-dimension attention mechanism to significantly enhance
speech clarity and quality in noisy environments. By leveraging self-supervised
learning embeddings in tandem with Short-Time Fourier Transform (STFT)
spectrogram features, our model excels at capturing both high-level semantic
information and detailed spectral data, enabling a more thorough analysis and
refinement of speech signals. Furthermore, we employ the innovative
Omni-dimensional Dynamic Convolution (ODConv) technology within the spectrogram
input branch, enabling enhanced extraction and integration of crucial
information across multiple dimensions. Additionally, we refine the Conformer
model by enhancing its feature extraction capabilities not only in the temporal
dimension but also across the spectral domain. Extensive experiments on the
VCTK-DEMAND dataset show that HFSDA is comparable to existing state-of-the-art
models, confirming the validity of our approach.

摘要：自监督学习已在语音任务中表现出令人印象深刻的性能，然而在语音增强研究领域仍有很大的进步空间。在处理语音任务时，仅将注意力机制限制在时间维度上会限制有效关注关键语音特征。考虑到上述问题，我们的研究引入了一个新颖的语音增强框架 HFSDA，它巧妙地集成了异构空间特征，并结合了双维注意力机制，以显着提高噪声环境中的语音清晰度和质量。通过利用自监督学习嵌入与短时傅里叶变换 (STFT) 频谱图特征相结合，我们的模型擅长同时捕获高级语义信息和详细的光谱数据，从而能够更彻底地分析和优化语音信号。此外，我们在频谱图输入分支中采用了创新的全维动态卷积 (ODConv) 技术，从而能够增强跨多个维度提取和集成关键信息。此外，我们通过增强其特征提取能力来改进 Conformer 模型，不仅在时间维度上，而且在频谱域上。在 VCTK-DEMAND 数据集上的大量实验表明，HFSDA 与现有的最先进模型相当，证实了我们方法的有效性。

##### **VNet: A GAN-based Multi-Tier Discriminator Network for Speech Synthesis Vocoders**
2408.06906v1 by Yubing Cao, Yongming Li, Liejun Wang, Yinfeng Yu

Since the introduction of Generative Adversarial Networks (GANs) in speech
synthesis, remarkable achievements have been attained. In a thorough
exploration of vocoders, it has been discovered that audio waveforms can be
generated at speeds exceeding real-time while maintaining high fidelity,
achieved through the utilization of GAN-based models. Typically, the inputs to
the vocoder consist of band-limited spectral information, which inevitably
sacrifices high-frequency details. To address this, we adopt the full-band Mel
spectrogram information as input, aiming to provide the vocoder with the most
comprehensive information possible. However, previous studies have revealed
that the use of full-band spectral information as input can result in the issue
of over-smoothing, compromising the naturalness of the synthesized speech. To
tackle this challenge, we propose VNet, a GAN-based neural vocoder network that
incorporates full-band spectral information and introduces a Multi-Tier
Discriminator (MTD) comprising multiple sub-discriminators to generate
high-resolution signals. Additionally, we introduce an asymptotically
constrained method that modifies the adversarial loss of the generator and
discriminator, enhancing the stability of the training process. Through
rigorous experiments, we demonstrate that the VNet model is capable of
generating high-fidelity speech and significantly improving the performance of
the vocoder.

摘要：自生成对抗網路 (GAN) 引入語音合成以來，已取得顯著的成就。在對語音編碼器進行徹底探討後，發現可以以超過實時的速度生成音訊波形，同時透過利用基於 GAN 的模型維持高保真度。通常，語音編碼器的輸入包含頻帶限制的頻譜資訊，這不可避免地會犧牲高頻細節。為了解決這個問題，我們採用全頻段 Mel 頻譜圖資訊作為輸入，目標是為語音編碼器提供最全面的資訊。然而，先前的研究顯示，使用全頻段頻譜資訊作為輸入可能會導致過度平滑的問題，損害合成語音的自然性。為了應對這個挑戰，我們提出 VNet，一個基於 GAN 的神經語音編碼器網路，它結合了全頻段頻譜資訊，並引入了包含多個子辨別器的多層辨別器 (MTD) 來生成高解析度訊號。此外，我們引入了一個漸近約束方法，修改了生成器和辨別器的對抗損失，增強了訓練過程的穩定性。透過嚴謹的實驗，我們證明 VNet 模型能夠生成高保真度的語音，並顯著提升語音編碼器的效能。

##### **Re-TASK: Revisiting LLM Tasks from Capability, Skill, and Knowledge Perspectives**
2408.06904v1 by Zhihu Wang, Shiwan Zhao, Yu Wang, Heyuan Huang, Jiaxin Shi, Sitao Xie, Zhixing Wang, Yubo Zhang, Hongyan Li, Junchi Yan

As large language models (LLMs) continue to scale, their enhanced performance
often proves insufficient for solving domain-specific tasks. Systematically
analyzing their failures and effectively enhancing their performance remain
significant challenges. This paper introduces the Re-TASK framework, a novel
theoretical model that Revisits LLM Tasks from cApability, Skill, Knowledge
perspectives, guided by the principles of Bloom's Taxonomy and Knowledge Space
Theory. The Re-TASK framework provides a systematic methodology to deepen our
understanding, evaluation, and enhancement of LLMs for domain-specific tasks.
It explores the interplay among an LLM's capabilities, the knowledge it
processes, and the skills it applies, elucidating how these elements are
interconnected and impact task performance. Our application of the Re-TASK
framework reveals that many failures in domain-specific tasks can be attributed
to insufficient knowledge or inadequate skill adaptation. With this insight, we
propose structured strategies for enhancing LLMs through targeted knowledge
injection and skill adaptation. Specifically, we identify key capability items
associated with tasks and employ a deliberately designed prompting strategy to
enhance task performance, thereby reducing the need for extensive fine-tuning.
Alternatively, we fine-tune the LLM using capability-specific instructions,
further validating the efficacy of our framework. Experimental results confirm
the framework's effectiveness, demonstrating substantial improvements in both
the performance and applicability of LLMs.

摘要：隨著大型語言模型 (LLM) 持續擴展，它們增強的效能經常證明不足以解決特定領域的任務。系統性地分析其失敗並有效提升其效能仍然是重大的挑戰。本文介紹 Re-TASK 架構，這是一個創新的理論模型，它從能力、技能和知識的角度重新審視 LLM 任務，並以布魯姆分類法和知識空間理論的原則為指導。Re-TASK 架構提供了一個系統化的方法，以加深我們對 LLM 的理解、評估和增強，以應對特定領域的任務。它探討了 LLM 的能力、它處理的知識和它應用的技能之間的相互作用，闡明了這些元素如何相互關聯並影響任務效能。我們對 Re-TASK 架構的應用揭示，特定領域任務中的許多失敗可以歸因於知識不足或技能適應不足。有了這個見解，我們提出了通過有針對性的知識注入和技能適應來增強 LLM 的結構化策略。具體來說，我們識別與任務相關的主要能力項目，並採用經過精心設計的提示策略來增強任務效能，從而減少對廣泛微調的需求。或者，我們使用特定於能力的說明對 LLM 進行微調，進一步驗證了我們架構的功效。實驗結果證實了該架構的有效性，證明了 LLM 的效能和適用性都有顯著的提升。

##### **Entendre, a Social Bot Detection Tool for Niche, Fringe, and Extreme Social Media**
2408.06900v1 by Pranav Venkatesh, Kami Vinton, Dhiraj Murthy, Kellen Sharp, Akaash Kolluri

Social bots-automated accounts that generate and spread content on social
media-are exploiting vulnerabilities in these platforms to manipulate public
perception and disseminate disinformation. This has prompted the development of
public bot detection services; however, most of these services focus primarily
on Twitter, leaving niche platforms vulnerable. Fringe social media platforms
such as Parler, Gab, and Gettr often have minimal moderation, which facilitates
the spread of hate speech and misinformation. To address this gap, we introduce
Entendre, an open-access, scalable, and platform-agnostic bot detection
framework. Entendre can process a labeled dataset from any social platform to
produce a tailored bot detection model using a random forest classification
approach, ensuring robust social bot detection. We exploit the idea that most
social platforms share a generic template, where users can post content,
approve content, and provide a bio (common data features). By emphasizing
general data features over platform-specific ones, Entendre offers rapid
extensibility at the expense of some accuracy. To demonstrate Entendre's
effectiveness, we used it to explore the presence of bots among accounts
posting racist content on the now-defunct right-wing platform Parler. We
examined 233,000 posts from 38,379 unique users and found that 1,916 unique
users (4.99%) exhibited bot-like behavior. Visualization techniques further
revealed that these bots significantly impacted the network, amplifying
influential rhetoric and hashtags (e.g., #qanon, #trump, #antilgbt). These
preliminary findings underscore the need for tools like Entendre to monitor and
assess bot activity across diverse platforms.

摘要：<paragraph>社交機器人（自動生成內容並在社交媒體上散布內容的自動帳戶）正在利用這些平台中的漏洞來操縱公眾認知並散布錯誤訊息。這促成了公共機器人偵測服務的開發；然而，這些服務大多主要關注 Twitter，讓利基平台容易受到攻擊。邊緣社交媒體平台，例如 Parler、Gab 和 Gettr 通常只有最少的審核，這促成了仇恨言論和錯誤訊息的散布。為了解決這個差距，我們引入了 Entendre，一個開放存取、可擴充且與平台無關的機器人偵測架構。Entendre 可以處理來自任何社交平台的標籤資料集，以使用隨機森林分類方法產生量身打造的機器人偵測模型，確保強大的社交機器人偵測。我們利用了大多數社交平台共用一個通用範本的想法，使用者可以在其中發布內容、核准內容並提供個人簡介（常見資料特徵）。透過強調一般資料特徵而非特定於平台的特徵，Entendre 以犧牲一些準確度為代價提供了快速的擴充性。為了展示 Entendre 的效能，我們使用它來探索現在已不存在的右翼平台 Parler 上發布種族主義內容的帳戶中的機器人存在。我們檢視了 38,379 個唯一使用者的 233,000 則貼文，發現 1,916 個唯一使用者（4.99%）表現出類似機器人的行為。視覺化技術進一步顯示這些機器人對網路產生了重大影響，擴大了有影響力的言論和標籤（例如，#qanon、#trump、#antilgbt）。這些初步發現強調了像 Entendre 這樣的工具在不同平台上監控和評估機器人活動的必要性。</paragraph>

##### **Automatic Feature Recognition and Dimensional Attributes Extraction From CAD Models for Hybrid Additive-Subtractive Manufacturing**
2408.06891v2 by Muhammad Tayyab Khan, Wenhe Feng, Lequn Chen, Ye Han Ng, Nicholas Yew Jin Tan, Seung Ki Moon

The integration of Computer-Aided Design (CAD), Computer-Aided Process
Planning (CAPP), and Computer-Aided Manufacturing (CAM) plays a crucial role in
modern manufacturing, facilitating seamless transitions from digital designs to
physical products. However, a significant challenge within this integration is
the Automatic Feature Recognition (AFR) of CAD models, especially in the
context of hybrid manufacturing that combines subtractive and additive
manufacturing processes. Traditional AFR methods, focused mainly on the
identification of subtractive (machined) features including holes, fillets,
chamfers, pockets, and slots, fail to recognize features pertinent to additive
manufacturing. Furthermore, the traditional methods fall short in accurately
extracting geometric dimensions and orientations, which are also key factors
for effective manufacturing process planning. This paper presents a novel
approach for creating a synthetic CAD dataset that encompasses features
relevant to both additive and subtractive machining through Python Open
Cascade. The Hierarchical Graph Convolutional Neural Network (HGCNN) model is
implemented to accurately identify the composite additive-subtractive features
within the synthetic CAD dataset. The key novelty and contribution of the
proposed methodology lie in its ability to recognize a wide range of
manufacturing features, and precisely extracting their dimensions,
orientations, and stock sizes. The proposed model demonstrates remarkable
feature recognition accuracy exceeding 97% and a dimension extraction accuracy
of 100% for identified features. Therefore, the proposed methodology enhances
the integration of CAD, CAPP, and CAM within hybrid manufacturing by providing
precise feature recognition and dimension extraction. It facilitates improved
manufacturing process planning, by enabling more informed decision-making.

摘要：<paragraph>電腦輔助設計 (CAD)、電腦輔助製程規劃 (CAPP) 和電腦輔助製造 (CAM) 的整合在現代製造業中扮演著至關重要的角色，促使數位設計能順利轉化為實體產品。然而，此整合中一個重大的挑戰是 CAD 模型的自動特徵辨識 (AFR)，特別是在結合減材和增材製造製程的混合製造脈絡下。傳統的 AFR 方法主要著重於辨識減材（機械加工）特徵，包括孔、圓角、倒角、凹槽和槽，無法辨識與增材製造相關的特徵。此外，傳統方法無法準確擷取幾何尺寸和方向，而這也是有效製造製程規劃的關鍵因素。本文提出一個創新的方法，透過 Python Open Cascade 建立一個包含與增材和減材加工相關特徵的合成 CAD 資料集。實作階層式圖形卷積神經網路 (HGCNN) 模型，以準確辨識合成 CAD 資料集中的複合增材減材特徵。所提出的方法論的主要創新和貢獻在於它能辨識廣泛的製造特徵，並精確擷取其尺寸、方向和坯料大小。所提出的模型展現出卓越的特徵辨識準確度，超過 97%，以及對已辨識特徵的尺寸擷取準確度為 100%。因此，所提出的方法論透過提供精確的特徵辨識和尺寸擷取，增強了混合製造中 CAD、CAPP 和 CAM 的整合。它促成改善製造製程規劃，讓決策制定更明智。</paragraph>

##### **BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning**
2408.06890v1 by Yuyang Xue, Junyu Yan, Raman Dutt, Fasih Haider, Jingshuai Liu, Steven McDonagh, Sotirios A. Tsaftaris

Developing models with robust group fairness properties is paramount,
particularly in ethically sensitive domains such as medical diagnosis. Recent
approaches to achieving fairness in machine learning require a substantial
amount of training data and depend on model retraining, which may not be
practical in real-world scenarios. To mitigate these challenges, we propose
Bias-based Weight Masking Fine-Tuning (BMFT), a novel post-processing method
that enhances the fairness of a trained model in significantly fewer epochs
without requiring access to the original training data. BMFT produces a mask
over model parameters, which efficiently identifies the weights contributing
the most towards biased predictions. Furthermore, we propose a two-step
debiasing strategy, wherein the feature extractor undergoes initial fine-tuning
on the identified bias-influenced weights, succeeded by a fine-tuning phase on
a reinitialised classification layer to uphold discriminative performance.
Extensive experiments across four dermatological datasets and two sensitive
attributes demonstrate that BMFT outperforms existing state-of-the-art (SOTA)
techniques in both diagnostic accuracy and fairness metrics. Our findings
underscore the efficacy and robustness of BMFT in advancing fairness across
various out-of-distribution (OOD) settings. Our code is available at:
https://github.com/vios-s/BMFT

摘要：<paragraph>開發具有穩健群組公平性特性的模型至關重要，特別是在醫療診斷等道德敏感領域。最近實現機器學習公平性的方法需要大量的訓練資料，並且依賴於模型再訓練，這在現實情況中可能不切實際。為了緩解這些挑戰，我們提出了基於偏差的權重遮罩微調 (BMFT)，這是一種新穎的後處理方法，可以在顯著更少的輪次中增強訓練模型的公平性，而無需訪問原始訓練資料。BMFT 在模型參數上產生一個遮罩，有效地識別出對偏差預測貢獻最大的權重。此外，我們提出了一種兩步去偏策略，其中特徵提取器對識別出的偏差影響權重進行初始微調，然後在重新初始化的分類層上進行微調階段以維持區分效能。在四個皮膚科資料集和兩個敏感屬性的廣泛實驗中證明，BMFT 在診斷準確性和公平性指標上都優於現有的最先進 (SOTA) 技術。我們的研究結果強調了 BMFT 在推進各種非分佈 (OOD) 設定中的公平性方面的效力和穩健性。我們的程式碼可在以下位置獲得：
https://github.com/vios-s/BMFT</paragraph>

##### **Advancing Interactive Explainable AI via Belief Change Theory**
2408.06875v2 by Antonio Rago, Maria Vanina Martinez

As AI models become ever more complex and intertwined in humans' daily lives,
greater levels of interactivity of explainable AI (XAI) methods are needed. In
this paper, we propose the use of belief change theory as a formal foundation
for operators that model the incorporation of new information, i.e. user
feedback in interactive XAI, to logical representations of data-driven
classifiers. We argue that this type of formalisation provides a framework and
a methodology to develop interactive explanations in a principled manner,
providing warranted behaviour and favouring transparency and accountability of
such interactions. Concretely, we first define a novel, logic-based formalism
to represent explanatory information shared between humans and machines. We
then consider real world scenarios for interactive XAI, with different
prioritisations of new and existing knowledge, where our formalism may be
instantiated. Finally, we analyse a core set of belief change postulates,
discussing their suitability for our real world settings and pointing to
particular challenges that may require the relaxation or reinterpretation of
some of the theoretical assumptions underlying existing operators.

摘要：隨著人工智慧模型在人類的日常生活變得更加複雜且相互交織，
需要更高層次的互動式可解釋人工智慧 (XAI) 方法。在
本文中，我們建議使用信念變更理論作為運算符的形式基礎，
這些運算符模擬了新資訊的整合，即互動式 XAI 中的使用者
回饋，以資料驅動分類器的邏輯表示。我們認為這種類型的形式化
提供了一個架構和方法，可以以有原則的方式開發互動式解釋，
提供合理的行為並支持此類互動的透明度和問責制。具體來說，
我們首先定義一種新穎的、基於邏輯的形式主義，以表示人類和機器之間共享的解釋資訊。我們
然後考慮互動式 XAI 的真實世界場景，其中對新知識和現有知識有不同的優先順序，我們的形式主義可以在其中實例化。最後，我們分析了一組核心的信念變更公設，
討論它們是否適合我們的真實世界設定，並指出可能需要放寬或重新詮釋某些運算符背後理論假設的特定挑戰。

##### **Leveraging Language Models for Emotion and Behavior Analysis in Education**
2408.06874v1 by Kaito Tanaka, Benjamin Tan, Brian Wong

The analysis of students' emotions and behaviors is crucial for enhancing
learning outcomes and personalizing educational experiences. Traditional
methods often rely on intrusive visual and physiological data collection,
posing privacy concerns and scalability issues. This paper proposes a novel
method leveraging large language models (LLMs) and prompt engineering to
analyze textual data from students. Our approach utilizes tailored prompts to
guide LLMs in detecting emotional and engagement states, providing a
non-intrusive and scalable solution. We conducted experiments using Qwen,
ChatGPT, Claude2, and GPT-4, comparing our method against baseline models and
chain-of-thought (CoT) prompting. Results demonstrate that our method
significantly outperforms the baselines in both accuracy and contextual
understanding. This study highlights the potential of LLMs combined with prompt
engineering to offer practical and effective tools for educational emotion and
behavior analysis.

摘要：分析學生的情緒與行為對於增強學習成效和個人化教育體驗至關重要。傳統方法通常依賴於侵入性的視覺和生理數據收集，這會引發隱私問題和可擴充性問題。本文提出了一種新方法，利用大型語言模型 (LLM) 和提示工程來分析學生的文字數據。我們的做法利用量身打造的提示來引導 LLM 偵測情緒和參與狀態，提供非侵入性和可擴充性的解決方案。我們使用 Qwen、ChatGPT、Claude2 和 GPT-4 進行了實驗，將我們的模型與基準模型和思考鏈 (CoT) 提示進行比較。結果表明，我們的模型在準確性和背景理解方面都明顯優於基準模型。這項研究強調了 LLM 結合提示工程在提供實用且有效的教育情緒和行為分析工具方面的潛力。

##### **LoRA$^2$ : Multi-Scale Low-Rank Approximations for Fine-Tuning Large Language Models**
2408.06854v1 by Jia-Chen Zhang, Yu-Jie Xiong, He-Xi Qiu, Dong-Hai Zhu, Chun-Ming Xia

Fine-tuning large language models (LLMs) with high parameter efficiency for
downstream tasks has become a new paradigm. Low-Rank Adaptation (LoRA)
significantly reduces the number of trainable parameters for fine-tuning.
Although it has demonstrated commendable performance, updating parameters
within a single scale may not be the optimal choice for complex downstream
tasks.In this paper, we extend the LoRA to multiple scales, dubbed as LoRA$^2$.
We first combine orthogonal projection theory to train a set of LoRAs in two
mutually orthogonal planes. Then, we improve the importance score algorithm,
which reduce parameter sensitivity score calculations by approximately 98.5\%.
By pruning singular values with lower importance scores, thereby enhancing
adaptability to various downstream tasks. Extensive experiments are conducted
on two widely used pre-trained models to validate the effectiveness of
LoRA$^2$. Results show that it significantly reduces the number of trainable
parameters to just 0.72\% compared to full fine-tuning, while still delivering
highly impressive performance. Even when the parameters are further reduced to
0.17M, it still achieves comparable results to the baseline with 8 times more
parameters. Our code is available here:
https://anonymous.4open.science/r/LoRA-2-5B4C

摘要：微调具有高参数效率的大型语言模型 (LLM) 以用于下游任务已成为一种新范例。低秩自适应 (LoRA) 大幅减少了微调的可训练参数数量。虽然它已展示出值得称道的性能，但在单个尺度内更新参数可能不是复杂下游任务的最佳选择。在本文中，我们将 LoRA 扩展到多个尺度，称为 LoRA^2。我们首先结合正交投影理论，在两个相互正交的平面上训练一组 LoRA。然后，我们改进了重要性评分算法，该算法将参数敏感性评分计算减少了大约 98.5%。通过修剪具有较低重要性评分的奇异值，从而增强了对各种下游任务的适应性。在两个广泛使用的预训练模型上进行了广泛的实验，以验证 LoRA^2 的有效性。结果表明，与完全微调相比，它将可训练参数的数量显着减少到仅 0.72%，同时仍然提供令人印象深刻的性能。即使将参数进一步减少到 0.17M，它仍然可以实现与具有多 8 倍参数的基线相当的结果。我们的代码可在此处获得：https://anonymous.4open.science/r/LoRA-2-5B4C

##### **BSS-CFFMA: Cross-Domain Feature Fusion and Multi-Attention Speech Enhancement Network based on Self-Supervised Embedding**
2408.06851v1 by Alimjan Mattursun, Liejun Wang, Yinfeng Yu

Speech self-supervised learning (SSL) represents has achieved
state-of-the-art (SOTA) performance in multiple downstream tasks. However, its
application in speech enhancement (SE) tasks remains immature, offering
opportunities for improvement. In this study, we introduce a novel cross-domain
feature fusion and multi-attention speech enhancement network, termed
BSS-CFFMA, which leverages self-supervised embeddings. BSS-CFFMA comprises a
multi-scale cross-domain feature fusion (MSCFF) block and a residual hybrid
multi-attention (RHMA) block. The MSCFF block effectively integrates
cross-domain features, facilitating the extraction of rich acoustic
information. The RHMA block, serving as the primary enhancement module,
utilizes three distinct attention modules to capture diverse attention
representations and estimate high-quality speech signals.
  We evaluate the performance of the BSS-CFFMA model through comparative and
ablation studies on the VoiceBank-DEMAND dataset, achieving SOTA results.
Furthermore, we select three types of data from the WHAMR! dataset, a
collection specifically designed for speech enhancement tasks, to assess the
capabilities of BSS-CFFMA in tasks such as denoising only, dereverberation
only, and simultaneous denoising and dereverberation. This study marks the
first attempt to explore the effectiveness of self-supervised embedding-based
speech enhancement methods in complex tasks encompassing dereverberation and
simultaneous denoising and dereverberation. The demo implementation of
BSS-CFFMA is available online\footnote[2]{https://github.com/AlimMat/BSS-CFFMA.
\label{s1}}.

摘要：<paragraph>語音自監督學習 (SSL) 代表已在多項下游任務中達成最先進 (SOTA) 的效能。然而，其在語音增強 (SE) 任務中的應用仍不成熟，提供了改進的機會。在此研究中，我們引入了一個新穎的跨域特徵融合和多注意力語音增強網路，稱為 BSS-CFFMA，它利用自監督嵌入。BSS-CFFMA 包含一個多尺度跨域特徵融合 (MSCFF) 區塊和一個殘差混合多注意力 (RHMA) 區塊。MSCFF 區塊有效地整合跨域特徵，促進了豐富的聲學資訊提取。RHMA 區塊作為主要的增強模組，利用三個不同的注意力模組來擷取多樣化的注意力表示並估計高品質的語音訊號。
我們透過在 VoiceBank-DEMAND 資料集上進行比較和消融研究來評估 BSS-CFFMA 模型的效能，並達成 SOTA 的結果。此外，我們從 WHAMR! 資料集中選取三種類型的資料，這是專門為語音增強任務設計的集合，用來評估 BSS-CFFMA 在僅去噪、僅去混響和同時去噪與去混響等任務中的能力。本研究標誌著首次嘗試探索基於自監督嵌入的語音增強方法在包含去混響和同時去噪與去混響的複雜任務中的有效性。BSS-CFFMA 的示範實作可在線上取得\footnote[2]{https://github.com/AlimMat/BSS-CFFMA.
\label{s1}}。</paragraph>

##### **Causal Agent based on Large Language Model**
2408.06849v1 by Kairong Han, Kun Kuang, Ziyu Zhao, Junjian Ye, Fei Wu

Large language models (LLMs) have achieved significant success across various
domains. However, the inherent complexity of causal problems and causal theory
poses challenges in accurately describing them in natural language, making it
difficult for LLMs to comprehend and use them effectively. Causal methods are
not easily conveyed through natural language, which hinders LLMs' ability to
apply them accurately. Additionally, causal datasets are typically tabular,
while LLMs excel in handling natural language data, creating a structural
mismatch that impedes effective reasoning with tabular data. This lack of
causal reasoning capability limits the development of LLMs. To address these
challenges, we have equipped the LLM with causal tools within an agent
framework, named the Causal Agent, enabling it to tackle causal problems. The
causal agent comprises tools, memory, and reasoning modules. In the tools
module, the causal agent applies causal methods to align tabular data with
natural language. In the reasoning module, the causal agent employs the ReAct
framework to perform reasoning through multiple iterations with the tools. In
the memory module, the causal agent maintains a dictionary instance where the
keys are unique names and the values are causal graphs. To verify the causal
ability of the causal agent, we established a benchmark consisting of four
levels of causal problems: variable level, edge level, causal graph level, and
causal effect level. We generated a test dataset of 1.3K using ChatGPT-3.5 for
these four levels of issues and tested the causal agent on the datasets. Our
methodology demonstrates remarkable efficacy on the four-level causal problems,
with accuracy rates all above 80%. For further insights and implementation
details, our code is accessible via the GitHub repository
https://github.com/Kairong-Han/Causal_Agent.

摘要：大型語言模型 (LLM) 已在各個領域取得重大成功。然而，因果問題和因果理論的內在複雜性，在自然語言中準確描述它們時構成挑戰，這使得 LLM 難以理解並有效使用它們。因果方法不易透過自然語言傳達，這阻礙了 LLM 準確應用它們的能力。此外，因果資料集通常是表格化的，而 LLM 擅長處理自然語言資料，這造成了結構上的不匹配，阻礙了對表格資料進行有效的推理。這種缺乏因果推理能力限制了 LLM 的發展。為了應對這些挑戰，我們在一個代理框架中為 LLM 配備了因果工具，稱為因果代理，使它能夠解決因果問題。因果代理包含工具、記憶體和推理模組。在工具模組中，因果代理應用因果方法將表格資料與自然語言對齊。在推理模組中，因果代理採用 ReAct 框架，透過與工具進行多次反覆運算來執行推理。在記憶體模組中，因果代理維護一個字典實例，其中鍵是唯一名稱，而值是因果圖。為了驗證因果代理的因果能力，我們建立了一個基準，其中包含四個層級的因果問題：變數層級、邊層級、因果圖層級和因果效應層級。我們使用 ChatGPT-3.5 為這四個層級的問題產生了 1.3K 的測試資料集，並在資料集上測試了因果代理。我們的這套方法在四個層級的因果問題上展現了顯著的功效，準確率都高於 80%。有關進一步的見解和實作細節，我們的程式碼可透過 GitHub 儲存庫 https://github.com/Kairong-Han/Causal_Agent 取得。

