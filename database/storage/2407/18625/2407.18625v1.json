{"2407.18625": {"publish_time": "2024-07-26", "title": "Topology Optimization of Random Memristors for Input-Aware Dynamic SNN", "paper_summary": "There is unprecedented development in machine learning, exemplified by recent\nlarge language models and world simulators, which are artificial neural\nnetworks running on digital computers. However, they still cannot parallel\nhuman brains in terms of energy efficiency and the streamlined adaptability to\ninputs of different difficulties, due to differences in signal representation,\noptimization, run-time reconfigurability, and hardware architecture. To address\nthese fundamental challenges, we introduce pruning optimization for input-aware\ndynamic memristive spiking neural network (PRIME). Signal representation-wise,\nPRIME employs leaky integrate-and-fire neurons to emulate the brain's inherent\nspiking mechanism. Drawing inspiration from the brain's structural plasticity,\nPRIME optimizes the topology of a random memristive spiking neural network\nwithout expensive memristor conductance fine-tuning. For runtime\nreconfigurability, inspired by the brain's dynamic adjustment of computational\ndepth, PRIME employs an input-aware dynamic early stop policy to minimize\nlatency during inference, thereby boosting energy efficiency without\ncompromising performance. Architecture-wise, PRIME leverages memristive\nin-memory computing, mirroring the brain and mitigating the von Neumann\nbottleneck. We validated our system using a 40 nm 256 Kb memristor-based\nin-memory computing macro on neuromorphic image classification and image\ninpainting. Our results demonstrate the classification accuracy and Inception\nScore are comparable to the software baseline, while achieving maximal\n62.50-fold improvements in energy efficiency, and maximal 77.0% computational\nload savings. The system also exhibits robustness against stochastic synaptic\nnoise of analogue memristors. Our software-hardware co-designed model paves the\nway to future brain-inspired neuromorphic computing with brain-like energy\nefficiency and adaptivity.", "paper_summary_zh": "\u6a5f\u5668\u5b78\u7fd2\u6709\u7a7a\u524d\u7684\u767c\u5c55\uff0c\u6700\u8fd1\u7684\u5927\u8a9e\u8a00\u6a21\u578b\u548c\u4e16\u754c\u6a21\u64ec\u5668\u5c31\u662f\u4f8b\u8b49\uff0c\u5b83\u5011\u662f\u904b\u4f5c\u65bc\u6578\u4f4d\u96fb\u8166\u4e0a\u7684\u4eba\u5de5\u795e\u7d93\u7db2\u8def\u3002\u7136\u800c\uff0c\u7531\u65bc\u8a0a\u865f\u8868\u5fb5\u3001\u6700\u4f73\u5316\u3001\u57f7\u884c\u6642\u9593\u53ef\u91cd\u65b0\u7d44\u614b\u6027\u8207\u786c\u9ad4\u67b6\u69cb\u7684\u5dee\u7570\uff0c\u5b83\u5011\u5728\u80fd\u6e90\u6548\u7387\u548c\u5c0d\u4e0d\u540c\u96e3\u5ea6\u8f38\u5165\u7684\u7c21\u5316\u9069\u61c9\u6027\u65b9\u9762\uff0c\u4ecd\u7136\u7121\u6cd5\u8207\u4eba\u8166\u4e26\u99d5\u9f4a\u9a45\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u57fa\u672c\u6311\u6230\uff0c\u6211\u5011\u70ba\u8f38\u5165\u611f\u77e5\u52d5\u614b\u8a18\u61b6\u96fb\u963b\u5c16\u5cf0\u795e\u7d93\u7db2\u8def (PRIME) \u5f15\u9032\u4fee\u526a\u6700\u4f73\u5316\u3002\u5728\u8a0a\u865f\u8868\u5fb5\u65b9\u9762\uff0cPRIME \u63a1\u7528\u6f0f\u96fb\u7a4d\u5206\u548c\u767c\u5c04\u795e\u7d93\u5143\uff0c\u6a21\u64ec\u5927\u8166\u56fa\u6709\u7684\u5c16\u5cf0\u6a5f\u5236\u3002PRIME \u5f9e\u5927\u8166\u7684\u7d50\u69cb\u53ef\u5851\u6027\u4e2d\u6c72\u53d6\u9748\u611f\uff0c\u6700\u4f73\u5316\u96a8\u6a5f\u8a18\u61b6\u96fb\u963b\u5c16\u5cf0\u795e\u7d93\u7db2\u8def\u7684\u62d3\u64b2\uff0c\u800c\u7121\u9700\u6602\u8cb4\u7684\u8a18\u61b6\u96fb\u963b\u96fb\u5c0e\u7cbe\u7d30\u8abf\u6574\u3002\u5c0d\u65bc\u57f7\u884c\u6642\u9593\u53ef\u91cd\u65b0\u7d44\u614b\u6027\uff0cPRIME \u53d7\u5230\u5927\u8166\u52d5\u614b\u8abf\u6574\u8a08\u7b97\u6df1\u5ea6\u555f\u767c\uff0c\u63a1\u7528\u8f38\u5165\u611f\u77e5\u52d5\u614b\u65e9\u671f\u505c\u6b62\u7b56\u7565\uff0c\u4ee5\u5728\u63a8\u8ad6\u671f\u9593\u5c07\u5ef6\u9072\u964d\u81f3\u6700\u4f4e\uff0c\u5f9e\u800c\u63d0\u5347\u80fd\u6e90\u6548\u7387\uff0c\u540c\u6642\u4e0d\u640d\u5bb3\u6548\u80fd\u3002\u5728\u67b6\u69cb\u65b9\u9762\uff0cPRIME \u5145\u5206\u5229\u7528\u8a18\u61b6\u96fb\u963b\u5167\u90e8\u8a18\u61b6\u9ad4\u904b\u7b97\uff0c\u53cd\u6620\u5927\u8166\u4e26\u6e1b\u8f15\u99ae\u7d10\u66fc\u74f6\u9838\u3002\u6211\u5011\u4f7f\u7528 40 nm 256 Kb \u57fa\u65bc\u8a18\u61b6\u96fb\u963b\u7684\u5167\u90e8\u8a18\u61b6\u9ad4\u904b\u7b97\u5de8\u96c6\uff0c\u5728\u795e\u7d93\u5f62\u614b\u5f71\u50cf\u5206\u985e\u548c\u5f71\u50cf\u4fee\u5fa9\u4e0a\u9a57\u8b49\u6211\u5011\u7684\u7cfb\u7d71\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u5206\u985e\u6e96\u78ba\u5ea6\u548c Inception \u5206\u6578\u8207\u8edf\u9ad4\u57fa\u6e96\u76f8\u7576\uff0c\u540c\u6642\u5728\u80fd\u6e90\u6548\u7387\u65b9\u9762\u9054\u5230\u6700\u5927\u7684 62.50 \u500d\u63d0\u5347\uff0c\u4e26\u5728\u8a08\u7b97\u8ca0\u8f09\u65b9\u9762\u7bc0\u7701\u6700\u591a 77.0%\u3002\u8a72\u7cfb\u7d71\u9084\u5c55\u73fe\u51fa\u5c0d\u985e\u6bd4\u8a18\u61b6\u96fb\u963b\u7684\u96a8\u6a5f\u7a81\u89f8\u96dc\u8a0a\u7684\u7a69\u5065\u6027\u3002\u6211\u5011\u8edf\u9ad4\u786c\u9ad4\u5171\u540c\u8a2d\u8a08\u7684\u6a21\u578b\uff0c\u70ba\u672a\u4f86\u5177\u5099\u5927\u8166\u822c\u80fd\u6e90\u6548\u7387\u548c\u9069\u61c9\u6027\u7684\u3001\u53d7\u5927\u8166\u555f\u767c\u7684\u795e\u7d93\u5f62\u614b\u904b\u7b97\u92ea\u8def\u3002", "author": "Bo Wang et.al.", "authors": "Bo Wang, Shaocong Wang, Ning Lin, Yi Li, Yifei Yu, Yue Zhang, Jichang Yang, Xiaoshan Wu, Yangu He, Songqi Wang, Rui Chen, Guoqi Li, Xiaojuan Qi, Zhongrui Wang, Dashan Shang", "id": "2407.18625v1", "paper_url": "http://arxiv.org/abs/2407.18625v1", "repo": "null"}}