{"2411.04799": {"publish_time": "2024-11-07", "title": "Kwai-STaR: Transform LLMs into State-Transition Reasoners", "paper_summary": "Mathematical reasoning presents a significant challenge to the cognitive\ncapabilities of LLMs. Various methods have been proposed to enhance the\nmathematical ability of LLMs. However, few recognize the value of state\ntransition for LLM reasoning. In this work, we define mathematical\nproblem-solving as a process of transiting from an initial unsolved state to\nthe final resolved state, and propose Kwai-STaR framework, which transforms\nLLMs into State-Transition Reasoners to improve their intuitive reasoning\ncapabilities. Our approach comprises three main steps: (1) Define the state\nspace tailored to the mathematical reasoning. (2) Generate state-transition\ndata based on the state space. (3) Convert original LLMs into State-Transition\nReasoners via a curricular training strategy. Our experiments validate the\neffectiveness of Kwai-STaR in enhancing mathematical reasoning: After training\non the small-scale Kwai-STaR dataset, general LLMs, including Mistral-7B and\nLLaMA-3, achieve considerable performance gain on the GSM8K and GSM-Hard\ndataset. Additionally, the state transition-based design endows Kwai-STaR with\nremarkable training and inference efficiency. Further experiments are underway\nto establish the generality of Kwai-STaR.", "paper_summary_zh": "\u6578\u5b78\u63a8\u7406\u5c0d LLM \u7684\u8a8d\u77e5\u80fd\u529b\u63d0\u51fa\u91cd\u5927\u6311\u6230\u3002\u5df2\u7d93\u63d0\u51fa\u5404\u7a2e\u65b9\u6cd5\u4f86\u589e\u5f37 LLM \u7684\u6578\u5b78\u80fd\u529b\u3002\u7136\u800c\uff0c\u5f88\u5c11\u6709\u4eba\u8a8d\u8b58\u5230\u72c0\u614b\u8f49\u63db\u5c0d LLM \u63a8\u7406\u7684\u50f9\u503c\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5c07\u6578\u5b78\u554f\u984c\u6c42\u89e3\u5b9a\u7fa9\u70ba\u5f9e\u521d\u59cb\u672a\u89e3\u6c7a\u72c0\u614b\u8f49\u63db\u5230\u6700\u7d42\u5df2\u89e3\u6c7a\u72c0\u614b\u7684\u904e\u7a0b\uff0c\u4e26\u63d0\u51fa Kwai-STaR \u6846\u67b6\uff0c\u5b83\u5c07 LLM \u8f49\u63db\u70ba\u72c0\u614b\u8f49\u63db\u63a8\u7406\u5668\u4ee5\u63d0\u9ad8\u5176\u76f4\u89ba\u63a8\u7406\u80fd\u529b\u3002\u6211\u5011\u7684\u505a\u6cd5\u5305\u542b\u4e09\u500b\u4e3b\u8981\u6b65\u9a5f\uff1a(1) \u5b9a\u7fa9\u9069\u5408\u6578\u5b78\u63a8\u7406\u7684\u72c0\u614b\u7a7a\u9593\u3002(2) \u57fa\u65bc\u72c0\u614b\u7a7a\u9593\u751f\u6210\u72c0\u614b\u8f49\u63db\u6578\u64da\u3002(3) \u901a\u904e\u8ab2\u7a0b\u8a13\u7df4\u7b56\u7565\u5c07\u539f\u59cb LLM \u8f49\u63db\u70ba\u72c0\u614b\u8f49\u63db\u63a8\u7406\u5668\u3002\u6211\u5011\u7684\u5be6\u9a57\u9a57\u8b49\u4e86 Kwai-STaR \u5728\u589e\u5f37\u6578\u5b78\u63a8\u7406\u65b9\u9762\u7684\u6709\u6548\u6027\uff1a\u5728\u5c0f\u898f\u6a21 Kwai-STaR \u6578\u64da\u96c6\u4e0a\u8a13\u7df4\u5f8c\uff0c\u5305\u62ec Mistral-7B \u548c LLaMA-3 \u5728\u5167\u7684\u901a\u7528 LLM \u5728 GSM8K \u548c GSM-Hard \u6578\u64da\u96c6\u4e0a\u53d6\u5f97\u4e86\u986f\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u6b64\u5916\uff0c\u57fa\u65bc\u72c0\u614b\u8f49\u63db\u7684\u8a2d\u8a08\u8ce6\u4e88 Kwai-STaR \u5353\u8d8a\u7684\u8a13\u7df4\u548c\u63a8\u7406\u6548\u7387\u3002\u9032\u4e00\u6b65\u7684\u5be6\u9a57\u6b63\u5728\u9032\u884c\u4e2d\uff0c\u4ee5\u5efa\u7acb Kwai-STaR \u7684\u666e\u904d\u6027\u3002", "author": "Xingyu Lu et.al.", "authors": "Xingyu Lu, Yuhang Hu, Changyi Liu, Tianke Zhang, Zhenyu Yang, Zhixiang Ding, Shengsheng Qian, Meng Du, Ruiwen Kang, Kaiyu Tang, Fan Yang, Tingting Gao, Di Zhang, Hai-Tao Zheng, Bin Wen", "id": "2411.04799v1", "paper_url": "http://arxiv.org/abs/2411.04799v1", "repo": "null"}}