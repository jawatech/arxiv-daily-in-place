{"2408.09734": {"publish_time": "2024-08-19", "title": "Mutually-Aware Feature Learning for Few-Shot Object Counting", "paper_summary": "Few-shot object counting has garnered significant attention for its\npracticality as it aims to count target objects in a query image based on given\nexemplars without the need for additional training. However, there is a\nshortcoming in the prevailing extract-and-match approach: query and exemplar\nfeatures lack interaction during feature extraction since they are extracted\nunaware of each other and later correlated based on similarity. This can lead\nto insufficient target awareness of the extracted features, resulting in target\nconfusion in precisely identifying the actual target when multiple class\nobjects coexist. To address this limitation, we propose a novel framework,\nMutually-Aware FEAture learning(MAFEA), which encodes query and exemplar\nfeatures mutually aware of each other from the outset. By encouraging\ninteraction between query and exemplar features throughout the entire pipeline,\nwe can obtain target-aware features that are robust to a multi-category\nscenario. Furthermore, we introduce a background token to effectively associate\nthe target region of query with exemplars and decouple its background region\nfrom them. Our extensive experiments demonstrate that our model reaches a new\nstate-of-the-art performance on the two challenging benchmarks, FSCD-LVIS and\nFSC-147, with a remarkably reduced degree of the target confusion problem.", "paper_summary_zh": "\u5c0f\u6837\u672c\u76ee\u6807\u8ba1\u6570\u56e0\u5176\u5b9e\u7528\u6027\u800c\u5907\u53d7\u5173\u6ce8\uff0c\u56e0\u4e3a\u5b83\u65e8\u5728\u6839\u636e\u7ed9\u5b9a\u7684\u793a\u4f8b\u5728\u67e5\u8be2\u56fe\u50cf\u4e2d\u8ba1\u6570\u76ee\u6807\u5bf9\u8c61\uff0c\u800c\u65e0\u9700\u8fdb\u884c\u989d\u5916\u7684\u8bad\u7ec3\u3002\u7136\u800c\uff0c\u6d41\u884c\u7684\u63d0\u53d6\u548c\u5339\u914d\u65b9\u6cd5\u5b58\u5728\u4e00\u4e2a\u7f3a\u70b9\uff1a\u67e5\u8be2\u548c\u793a\u4f8b\u7279\u5f81\u5728\u7279\u5f81\u63d0\u53d6\u8fc7\u7a0b\u4e2d\u7f3a\u4e4f\u4ea4\u4e92\uff0c\u56e0\u4e3a\u5b83\u4eec\u5728\u5f7c\u6b64\u4e0d\u77e5\u60c5\u7684\u60c5\u51b5\u4e0b\u88ab\u63d0\u53d6\uff0c\u5e76\u5728\u4e4b\u540e\u6839\u636e\u76f8\u4f3c\u6027\u8fdb\u884c\u5173\u8054\u3002\u8fd9\u4f1a\u5bfc\u81f4\u63d0\u53d6\u7684\u7279\u5f81\u5bf9\u76ee\u6807\u7684\u611f\u77e5\u4e0d\u8db3\uff0c\u4ece\u800c\u5728\u591a\u4e2a\u7c7b\u522b\u5bf9\u8c61\u5171\u5b58\u65f6\u5bfc\u81f4\u5728\u7cbe\u786e\u8bc6\u522b\u5b9e\u9645\u76ee\u6807\u65f6\u51fa\u73b0\u76ee\u6807\u6df7\u6dc6\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5373\u76f8\u4e92\u611f\u77e5\u7279\u5f81\u5b66\u4e60 (MAFEA)\uff0c\u5b83\u4ece\u4e00\u5f00\u59cb\u5c31\u5bf9\u67e5\u8be2\u548c\u793a\u4f8b\u7279\u5f81\u8fdb\u884c\u76f8\u4e92\u611f\u77e5\u7684\u7f16\u7801\u3002\u901a\u8fc7\u5728\u6574\u4e2a\u7ba1\u9053\u4e2d\u9f13\u52b1\u67e5\u8be2\u548c\u793a\u4f8b\u7279\u5f81\u4e4b\u95f4\u7684\u4ea4\u4e92\uff0c\u6211\u4eec\u53ef\u4ee5\u83b7\u5f97\u5bf9\u76ee\u6807\u611f\u77e5\u7684\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u5bf9\u591a\u7c7b\u522b\u573a\u666f\u5177\u6709\u9c81\u68d2\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u80cc\u666f\u4ee4\u724c\uff0c\u4ee5\u6709\u6548\u5730\u5c06\u67e5\u8be2\u7684\u76ee\u6807\u533a\u57df\u4e0e\u793a\u4f8b\u5173\u8054\u8d77\u6765\uff0c\u5e76\u5c06\u5176\u80cc\u666f\u533a\u57df\u4e0e\u793a\u4f8b\u5206\u79bb\u3002\u6211\u4eec\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u5728\u4e24\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6 FSCD-LVIS \u548c FSC-147 \u4e0a\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u4e14\u76ee\u6807\u6df7\u6dc6\u95ee\u9898\u7684\u7a0b\u5ea6\u663e\u8457\u964d\u4f4e\u3002", "author": "Yerim Jeon et.al.", "authors": "Yerim Jeon, Subeen Lee, Jihwan Kim, Jae-Pil Heo", "id": "2408.09734v1", "paper_url": "http://arxiv.org/abs/2408.09734v1", "repo": "null"}}