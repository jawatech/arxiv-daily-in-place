{"2502.03805": {"publish_time": "2025-02-06", "title": "Identify Critical KV Cache in LLM Inference from an Output Perturbation Perspective", "paper_summary": "Large language models have revolutionized natural language processing but\nface significant challenges of high storage and runtime costs, due to the\ntransformer architecture's reliance on self-attention, particularly the large\nKey-Value (KV) cache for long-sequence inference. Recent efforts to reduce KV\ncache size by pruning less critical entries based on attention weights remain\nempirical and lack formal grounding. This paper presents a formal study on\nidentifying critical KV cache entries by analyzing attention output\nperturbation. Our analysis reveals that, beyond attention weights, the value\nstates within KV entries and pretrained parameter matrices are also crucial.\nBased on this, we propose a perturbation-constrained selection algorithm that\noptimizes the worst-case output perturbation to identify critical entries.\nEvaluations on the Needle-in-a-Haystack test and Longbench benchmark show our\nalgorithm enhances state-of-the-art cache eviction methods. Further empirical\nanalysis confirms that our algorithm achieves lower output perturbations in\nover 92% attention heads in Llama model, thereby providing a significant\nimprovement over existing methods.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u5df2\u7d93\u5fb9\u5e95\u6539\u8b8a\u4e86\u81ea\u7136\u8a9e\u8a00\u8655\u7406\uff0c\u4f46\u7531\u65bcTransformer\u67b6\u69cb\u4f9d\u8cf4\u65bc\u81ea\u6211\u6ce8\u610f\uff0c\u7279\u5225\u662f\u9577\u5e8f\u5217\u63a8\u8ad6\u7684\u5927\u578b\u9375\u503c (KV) \u5feb\u53d6\uff0c\u56e0\u6b64\u9762\u81e8\u8457\u5132\u5b58\u548c\u57f7\u884c\u6642\u9593\u6210\u672c\u9ad8\u7684\u91cd\u5927\u6311\u6230\u3002\u6700\u8fd1\u900f\u904e\u6839\u64da\u6ce8\u610f\u529b\u6b0a\u91cd\u4f86\u4fee\u526a\u8f03\u4e0d\u91cd\u8981\u7684\u689d\u76ee\u4ee5\u6e1b\u5c11 KV \u5feb\u53d6\u5927\u5c0f\u7684\u52aa\u529b\u4ecd\u7136\u662f\u7d93\u9a57\u6027\u7684\uff0c\u4e26\u4e14\u7f3a\u4e4f\u6b63\u5f0f\u7684\u4f9d\u64da\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u9805\u6b63\u5f0f\u7684\u7814\u7a76\uff0c\u900f\u904e\u5206\u6790\u6ce8\u610f\u529b\u8f38\u51fa\u64fe\u52d5\u4f86\u8b58\u5225\u91cd\u8981\u7684 KV \u5feb\u53d6\u689d\u76ee\u3002\u6211\u5011\u7684\u5206\u6790\u986f\u793a\uff0c\u9664\u4e86\u6ce8\u610f\u529b\u6b0a\u91cd\u4e4b\u5916\uff0cKV \u689d\u76ee\u4e2d\u7684\u503c\u72c0\u614b\u548c\u9810\u8a13\u7df4\u53c3\u6578\u77e9\u9663\u4e5f\u81f3\u95dc\u91cd\u8981\u3002\u57fa\u65bc\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u64fe\u52d5\u7d04\u675f\u9078\u64c7\u6f14\u7b97\u6cd5\uff0c\u5b83\u6700\u4f73\u5316\u6700\u5dee\u60c5\u6cc1\u7684\u8f38\u51fa\u64fe\u52d5\u4ee5\u8b58\u5225\u91cd\u8981\u7684\u689d\u76ee\u3002\u5728 Needle-in-a-Haystack \u6e2c\u8a66\u548c Longbench \u57fa\u6e96\u4e0a\u7684\u8a55\u4f30\u986f\u793a\uff0c\u6211\u5011\u7684\u6f14\u7b97\u6cd5\u589e\u5f37\u4e86\u6700\u5148\u9032\u7684\u5feb\u53d6\u9a45\u9010\u65b9\u6cd5\u3002\u9032\u4e00\u6b65\u7684\u7d93\u9a57\u5206\u6790\u8b49\u5be6\uff0c\u6211\u5011\u7684\u6f14\u7b97\u6cd5\u5728 Llama \u6a21\u578b\u4e2d\u8d85\u904e 92% \u7684\u6ce8\u610f\u529b\u982d\u4e2d\u9054\u5230\u4e86\u8f03\u4f4e\u7684\u8f38\u51fa\u64fe\u52d5\uff0c\u5f9e\u800c\u63d0\u4f9b\u4e86\u5c0d\u73fe\u6709\u65b9\u6cd5\u7684\u986f\u8457\u6539\u9032\u3002", "author": "Yuan Feng et.al.", "authors": "Yuan Feng, Junlin Lv, Yukun Cao, Xike Xie, S Kevin Zhou", "id": "2502.03805v1", "paper_url": "http://arxiv.org/abs/2502.03805v1", "repo": "null"}}