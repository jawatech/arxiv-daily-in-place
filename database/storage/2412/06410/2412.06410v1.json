{"2412.06410": {"publish_time": "2024-12-09", "title": "BatchTopK Sparse Autoencoders", "paper_summary": "Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting\nlanguage model activations by decomposing them into sparse, interpretable\nfeatures. A popular approach is the TopK SAE, that uses a fixed number of the\nmost active latents per sample to reconstruct the model activations. We\nintroduce BatchTopK SAEs, a training method that improves upon TopK SAEs by\nrelaxing the top-k constraint to the batch-level, allowing for a variable\nnumber of latents to be active per sample. As a result, BatchTopK adaptively\nallocates more or fewer latents depending on the sample, improving\nreconstruction without sacrificing average sparsity. We show that BatchTopK\nSAEs consistently outperform TopK SAEs in reconstructing activations from GPT-2\nSmall and Gemma 2 2B, and achieve comparable performance to state-of-the-art\nJumpReLU SAEs. However, an advantage of BatchTopK is that the average number of\nlatents can be directly specified, rather than approximately tuned through a\ncostly hyperparameter sweep. We provide code for training and evaluating\nBatchTopK SAEs at https://github.com/bartbussmann/BatchTopK", "paper_summary_zh": "\u7a00\u758f\u81ea\u52d5\u7de8\u78bc\u5668 (SAE) \u5df2\u6210\u70ba\u4e00\u7a2e\u5f37\u5927\u7684\u5de5\u5177\uff0c\u53ef\u7528\u65bc\u900f\u904e\u5c07\u8a9e\u8a00\u6a21\u578b\u6fc0\u6d3b\u5206\u89e3\u70ba\u7a00\u758f\u3001\u53ef\u89e3\u91cb\u7684\u529f\u80fd\u4f86\u9032\u884c\u89e3\u91cb\u3002\u4e00\u7a2e\u6d41\u884c\u7684\u65b9\u6cd5\u662f TopK SAE\uff0c\u5b83\u4f7f\u7528\u6bcf\u500b\u6a23\u672c\u4e2d\u6700\u6d3b\u8e8d\u6f5b\u5728\u8b8a\u6578\u7684\u56fa\u5b9a\u6578\u91cf\u4f86\u91cd\u5efa\u6a21\u578b\u6fc0\u6d3b\u3002\u6211\u5011\u5f15\u9032 BatchTopK SAE\uff0c\u9019\u662f\u4e00\u7a2e\u8a13\u7df4\u65b9\u6cd5\uff0c\u900f\u904e\u653e\u5bec\u9802\u90e8 k \u7d04\u675f\u81f3\u6279\u6b21\u5c64\u7d1a\u4f86\u6539\u5584 TopK SAE\uff0c\u5141\u8a31\u6bcf\u500b\u6a23\u672c\u6709\u53ef\u8b8a\u6578\u91cf\u7684\u6f5b\u5728\u8b8a\u6578\u8655\u65bc\u6d3b\u8e8d\u72c0\u614b\u3002\u56e0\u6b64\uff0cBatchTopK \u6703\u6839\u64da\u6a23\u672c\u9069\u61c9\u6027\u5730\u5206\u914d\u66f4\u591a\u6216\u66f4\u5c11\u7684\u6f5b\u5728\u8b8a\u6578\uff0c\u6539\u5584\u91cd\u5efa\u800c\u4e0d\u72a7\u7272\u5e73\u5747\u7a00\u758f\u6027\u3002\u6211\u5011\u5c55\u793a BatchTopK SAE \u5728\u91cd\u5efa GPT-2 Small \u548c Gemma 2 2B \u7684\u6fc0\u6d3b\u65b9\u9762\u59cb\u7d42\u512a\u65bc TopK SAE\uff0c\u4e26\u9054\u5230\u8207\u6700\u5148\u9032\u7684 JumpReLU SAE \u76f8\u7576\u7684\u6548\u80fd\u3002\u7136\u800c\uff0cBatchTopK \u7684\u512a\u9ede\u5728\u65bc\u53ef\u4ee5\u76f4\u63a5\u6307\u5b9a\u6f5b\u5728\u8b8a\u6578\u7684\u5e73\u5747\u6578\u91cf\uff0c\u800c\u4e0d\u662f\u900f\u904e\u4ee3\u50f9\u9ad8\u6602\u7684\u8d85\u53c3\u6578\u6383\u63cf\u4f86\u8fd1\u4f3c\u8abf\u6574\u3002\u6211\u5011\u5728 https://github.com/bartbussmann/BatchTopK \u63d0\u4f9b\u8a13\u7df4\u548c\u8a55\u4f30 BatchTopK SAE \u7684\u7a0b\u5f0f\u78bc", "author": "Bart Bussmann et.al.", "authors": "Bart Bussmann, Patrick Leask, Neel Nanda", "id": "2412.06410v1", "paper_url": "http://arxiv.org/abs/2412.06410v1", "repo": "https://github.com/bartbussmann/batchtopk"}}