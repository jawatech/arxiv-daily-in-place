{"2407.00379": {"publish_time": "2024-06-29", "title": "GraphArena: Benchmarking Large Language Models on Graph Computational Problems", "paper_summary": "The \"arms race\" of Large Language Models (LLMs) demands novel, challenging,\nand diverse benchmarks to faithfully examine their progresses. We introduce\nGraphArena, a benchmarking tool designed to evaluate LLMs on graph\ncomputational problems using million-scale real-world graphs from diverse\nscenarios such as knowledge graphs, social networks, and molecular structures.\nGraphArena offers a suite of 10 computational tasks, encompassing four\npolynomial-time (e.g., Shortest Distance) and six NP-complete challenges (e.g.,\nTravelling Salesman Problem). It features a rigorous evaluation framework that\nclassifies LLM outputs as correct, suboptimal (feasible but not optimal), or\nhallucinatory (properly formatted but infeasible). Evaluation of 10 leading\nLLMs, including GPT-4o and LLaMA3-70B-Instruct, reveals that even\ntop-performing models struggle with larger, more complex graph problems and\nexhibit hallucination issues. Despite the application of strategies such as\nchain-of-thought prompting, these issues remain unresolved. GraphArena\ncontributes a valuable supplement to the existing LLM benchmarks and is\nopen-sourced at https://github.com/squareRoot3/GraphArena.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u300c\u8ecd\u5099\u7af6\u8cfd\u300d\u9700\u8981\u65b0\u7a4e\u3001\u5177\u6311\u6230\u6027\u4e14\u591a\u6a23\u5316\u7684\u57fa\u6e96\u4f86\u5fe0\u5be6\u6aa2\u9a57\u5176\u9032\u5ea6\u3002\u6211\u5011\u63a8\u51fa GraphArena\uff0c\u9019\u662f\u4e00\u500b\u57fa\u6e96\u5de5\u5177\uff0c\u65e8\u5728\u4f7f\u7528\u4f86\u81ea\u77e5\u8b58\u5716\u8b5c\u3001\u793e\u4ea4\u7db2\u8def\u548c\u5206\u5b50\u7d50\u69cb\u7b49\u591a\u6a23\u5316\u60c5\u5883\u7684\u6578\u767e\u842c\u500b\u771f\u5be6\u4e16\u754c\u5716\u5f62\uff0c\u91dd\u5c0d\u5716\u5f62\u8a08\u7b97\u554f\u984c\u8a55\u4f30 LLM\u3002GraphArena \u63d0\u4f9b\u4e00\u7cfb\u5217 10 \u500b\u8a08\u7b97\u4efb\u52d9\uff0c\u5305\u542b\u56db\u500b\u591a\u9805\u5f0f\u6642\u9593\uff08\u4f8b\u5982\uff0c\u6700\u77ed\u8ddd\u96e2\uff09\u548c\u516d\u500b NP \u5b8c\u5168\u6311\u6230\uff08\u4f8b\u5982\uff0c\u65c5\u884c\u63a8\u92b7\u54e1\u554f\u984c\uff09\u3002\u5b83\u5177\u6709\u4e00\u500b\u56b4\u8b39\u7684\u8a55\u4f30\u67b6\u69cb\uff0c\u5c07 LLM \u8f38\u51fa\u5206\u985e\u70ba\u6b63\u78ba\u3001\u6b21\u4f73\uff08\u53ef\u884c\u4f46\u975e\u6700\u4f73\uff09\u6216\u5e7b\u89ba\uff08\u683c\u5f0f\u6b63\u78ba\u4f46\u4e0d\u53ef\u884c\uff09\u3002\u5c0d\u5305\u62ec GPT-4o \u548c LLaMA3-70B-Instruct \u5728\u5167\u7684 10 \u500b\u9818\u5148 LLM \u7684\u8a55\u4f30\u986f\u793a\uff0c\u5373\u4f7f\u662f\u6548\u80fd\u6700\u4f73\u7684\u6a21\u578b\u5728\u8655\u7406\u66f4\u5927\u3001\u66f4\u8907\u96dc\u7684\u5716\u5f62\u554f\u984c\u6642\u4ecd\u6703\u9047\u5230\u56f0\u96e3\uff0c\u4e26\u51fa\u73fe\u5e7b\u89ba\u554f\u984c\u3002\u5118\u7ba1\u61c9\u7528\u4e86\u4e00\u7cfb\u5217\u7b56\u7565\uff0c\u4f8b\u5982\u601d\u8003\u93c8\u63d0\u793a\uff0c\u9019\u4e9b\u554f\u984c\u4ecd\u672a\u89e3\u6c7a\u3002GraphArena \u70ba\u73fe\u6709\u7684 LLM \u57fa\u6e96\u63d0\u4f9b\u4e86\u6709\u50f9\u503c\u7684\u88dc\u5145\uff0c\u4e26\u5728 https://github.com/squareRoot3/GraphArena \u958b\u6e90\u3002", "author": "Jianheng Tang et.al.", "authors": "Jianheng Tang, Qifan Zhang, Yuhan Li, Jia Li", "id": "2407.00379v1", "paper_url": "http://arxiv.org/abs/2407.00379v1", "repo": "https://github.com/squareroot3/grapharena"}}