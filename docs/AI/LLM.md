
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-25**|**Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models**|Matt Deitke et.al.|[2409.17146v1](http://arxiv.org/abs/2409.17146v1)|null|
|**2024-09-25**|**Differential Privacy Regularization: Protecting Training Data Through Loss Function Regularization**|Francisco Aguilera-Martínez et.al.|[2409.17144v1](http://arxiv.org/abs/2409.17144v1)|null|
|**2024-09-25**|**Attention Prompting on Image for Large Vision-Language Models**|Runpeng Yu et.al.|[2409.17143v1](http://arxiv.org/abs/2409.17143v1)|[link](https://github.com/yu-rp/apiprompting)|
|**2024-09-25**|**FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression**|Fazal Mittu et.al.|[2409.17141v1](http://arxiv.org/abs/2409.17141v1)|[link](https://github.com/fazalmittu/finezip)|
|**2024-09-25**|**Turn Every Application into an Agent: Towards Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents**|Junting Lu et.al.|[2409.17140v1](http://arxiv.org/abs/2409.17140v1)|null|
|**2024-09-25**|**Assessing the Level of Toxicity Against Distinct Groups in Bangla Social Media Comments: A Comprehensive Investigation**|Mukaffi Bin Moin et.al.|[2409.17130v1](http://arxiv.org/abs/2409.17130v1)|null|
|**2024-09-25**|**Blox-Net: Generative Design-for-Robot-Assembly Using VLM Supervision, Physics Simulation, and a Robot with Reset**|Andrew Goldberg et.al.|[2409.17126v1](http://arxiv.org/abs/2409.17126v1)|null|
|**2024-09-25**|**On-orbit Servicing for Spacecraft Collision Avoidance With Autonomous Decision Making**|Susmitha Patnala et.al.|[2409.17125v1](http://arxiv.org/abs/2409.17125v1)|null|
|**2024-09-25**|**Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Handy Appetizer**|Benji Peng et.al.|[2409.17120v1](http://arxiv.org/abs/2409.17120v1)|null|
|**2024-09-25**|**Programming Every Example: Lifting Pre-training Data Quality like Experts at Scale**|Fan Zhou et.al.|[2409.17115v1](http://arxiv.org/abs/2409.17115v1)|[link](https://github.com/gair-nlp/prox)|
|**2024-09-25**|**Unveiling Ontological Commitment in Multi-Modal Foundation Models**|Mert Keser et.al.|[2409.17109v1](http://arxiv.org/abs/2409.17109v1)|null|
|**2024-09-25**|**Accumulator-Aware Post-Training Quantization**|Ian Colbert et.al.|[2409.17092v1](http://arxiv.org/abs/2409.17092v1)|null|
|**2024-09-25**|**Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification**|Xinrui Zhou et.al.|[2409.17091v1](http://arxiv.org/abs/2409.17091v1)|null|
|**2024-09-25**|**Can Vision Language Models Learn from Visual Demonstrations of Ambiguous Spatial Reasoning?**|Bowen Zhao et.al.|[2409.17080v1](http://arxiv.org/abs/2409.17080v1)|null|
|**2024-09-25**|**Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition**|Pritika Ramu et.al.|[2409.17073v1](http://arxiv.org/abs/2409.17073v1)|null|
|**2024-09-25**|**The Effect of Perceptual Metrics on Music Representation Learning for Genre Classification**|Tashi Namgyal et.al.|[2409.17069v1](http://arxiv.org/abs/2409.17069v1)|null|
|**2024-09-25**|**VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models**|Yifei Liu et.al.|[2409.17066v1](http://arxiv.org/abs/2409.17066v1)|[link](https://github.com/microsoft/vptq)|
|**2024-09-25**|**Benchmarking Domain Generalization Algorithms in Computational Pathology**|Neda Zamanitajeddin et.al.|[2409.17063v1](http://arxiv.org/abs/2409.17063v1)|null|
|**2024-09-25**|**DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**|Lucas Robinet et.al.|[2409.17055v1](http://arxiv.org/abs/2409.17055v1)|[link](https://github.com/lucas-rbnt/drim)|
|**2024-09-25**|**Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia**|Azmul Asmar Irfan et.al.|[2409.17054v1](http://arxiv.org/abs/2409.17054v1)|null|
|**2024-09-25**|**ControlCity: A Multimodal Diffusion Model Based Approach for Accurate Geospatial Data Generation and Urban Morphology Analysis**|Fangshuo Zhou et.al.|[2409.17049v1](http://arxiv.org/abs/2409.17049v1)|[link](https://github.com/fangshuoz/controlcity)|
|**2024-09-25**|**GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design**|Phillip Mueller et.al.|[2409.17045v1](http://arxiv.org/abs/2409.17045v1)|null|
|**2024-09-25**|**How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does Not**|Francesco Verdini et.al.|[2409.17044v1](http://arxiv.org/abs/2409.17044v1)|null|
|**2024-09-25**|**Counterfactual Token Generation in Large Language Models**|Ivi Chatzi et.al.|[2409.17027v1](http://arxiv.org/abs/2409.17027v1)|null|
|**2024-09-25**|**AI-Driven Risk-Aware Scheduling for Active Debris Removal Missions**|Antoine Poupon et.al.|[2409.17012v1](http://arxiv.org/abs/2409.17012v1)|null|
|**2024-09-25**|**LLM-CARD: Towards a Description and Landscape of Large Language Models**|Shengwei Tian et.al.|[2409.17011v1](http://arxiv.org/abs/2409.17011v1)|null|
|**2024-09-25**|**Models Can and Should Embrace the Communicative Nature of Human-Generated Math**|Sasha Boguraev et.al.|[2409.17005v1](http://arxiv.org/abs/2409.17005v1)|null|
|**2024-09-25**|**INT-FlashAttention: Enabling Flash Attention for INT8 Quantization**|Shimao Chen et.al.|[2409.16997v2](http://arxiv.org/abs/2409.16997v2)|[link](https://github.com/int-flashattention2024/int-flashattention)|
|**2024-09-25**|**Harnessing Diversity for Important Data Selection in Pretraining Large Language Models**|Chi Zhang et.al.|[2409.16986v1](http://arxiv.org/abs/2409.16986v1)|null|
|**2024-09-25**|**AXCEL: Automated eXplainable Consistency Evaluation using LLMs**|P Aditya Sreekar et.al.|[2409.16984v1](http://arxiv.org/abs/2409.16984v1)|null|
|**2024-09-25**|**Decoding Large-Language Models: A Systematic Overview of Socio-Technical Impacts, Constraints, and Emerging Questions**|Zeyneb N. Kaya et.al.|[2409.16974v1](http://arxiv.org/abs/2409.16974v1)|null|
|**2024-09-25**|**Adaptive Self-Supervised Learning Strategies for Dynamic On-Device LLM Personalization**|Rafael Mendoza et.al.|[2409.16973v1](http://arxiv.org/abs/2409.16973v1)|null|
|**2024-09-25**|**Weighted Cross-entropy for Low-Resource Languages in Multilingual Speech Recognition**|Andrés Piñeiro-Martín et.al.|[2409.16954v1](http://arxiv.org/abs/2409.16954v1)|null|
|**2024-09-25**|**Dynamic Obstacle Avoidance through Uncertainty-Based Adaptive Planning with Diffusion**|Vineet Punyamoorty et.al.|[2409.16950v1](http://arxiv.org/abs/2409.16950v1)|null|
|**2024-09-25**|**Go-SLAM: Grounded Object Segmentation and Localization with Gaussian Splatting SLAM**|Phu Pham et.al.|[2409.16944v1](http://arxiv.org/abs/2409.16944v1)|null|
|**2024-09-25**|**Generative Object Insertion in Gaussian Splatting with a Multi-View Diffusion Model**|Hongliang Zhong et.al.|[2409.16938v1](http://arxiv.org/abs/2409.16938v1)|[link](https://github.com/jiutongbro/multiview_inpaint)|
|**2024-09-25**|**Semi-Supervised Cognitive State Classification from Speech with Multi-View Pseudo-Labeling**|Yuanchao Li et.al.|[2409.16937v1](http://arxiv.org/abs/2409.16937v1)|[link](https://github.com/yc-li20/semi-supervised-training)|
|**2024-09-25**|**Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical Documents**|Emanuela Boros et.al.|[2409.16934v2](http://arxiv.org/abs/2409.16934v2)|null|
|**2024-09-25**|**Quantum-Classical Sentiment Analysis**|Mario Bifulco et.al.|[2409.16928v1](http://arxiv.org/abs/2409.16928v1)|null|
|**2024-09-25**|**Cross-lingual Speech Emotion Recognition: Humans vs. Self-Supervised Models**|Zhichen Han et.al.|[2409.16920v1](http://arxiv.org/abs/2409.16920v1)|[link](https://github.com/zhan7721/crosslingual_ser)|
|**2024-09-25**|**Zero-Shot Detection of LLM-Generated Text using Token Cohesiveness**|Shixuan Ma et.al.|[2409.16914v1](http://arxiv.org/abs/2409.16914v1)|[link](https://github.com/shixuan-ma/tocsin)|
|**2024-09-25**|**Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing**|Wenhao Liu et.al.|[2409.16913v1](http://arxiv.org/abs/2409.16913v1)|null|
|**2024-09-25**|**Pruning Multilingual Large Language Models for Multilingual Inference**|Hwichan Kim et.al.|[2409.16911v1](http://arxiv.org/abs/2409.16911v1)|null|
|**2024-09-25**|**Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering**|Wanqi Yang et.al.|[2409.16909v1](http://arxiv.org/abs/2409.16909v1)|null|
|**2024-09-25**|**Discriminative Anchor Learning for Efficient Multi-view Clustering**|Yalan Qin et.al.|[2409.16904v1](http://arxiv.org/abs/2409.16904v1)|null|
|**2024-09-25**|**Towards Underwater Camouflaged Object Tracking: An Experimental Evaluation of SAM and SAM 2**|Chunhui Zhang et.al.|[2409.16902v1](http://arxiv.org/abs/2409.16902v1)|[link](https://github.com/983632847/awesome-multimodal-object-tracking)|
|**2024-09-25**|**A Roadmap for Embodied and Social Grounding in LLMs**|Sara Incao et.al.|[2409.16900v1](http://arxiv.org/abs/2409.16900v1)|null|
|**2024-09-25**|**AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging**|Jaeyoung Huh et.al.|[2409.16898v1](http://arxiv.org/abs/2409.16898v1)|null|
|**2024-09-25**|**Shifting from endangerment to rebirth in the Artificial Intelligence Age: An Ensemble Machine Learning Approach for Hawrami Text Classification**|Aram Khaksar et.al.|[2409.16884v1](http://arxiv.org/abs/2409.16884v1)|null|
|**2024-09-25**|**Revisiting Space Mission Planning: A Reinforcement Learning-Guided Approach for Multi-Debris Rendezvous**|Agni Bandyopadhyay et.al.|[2409.16882v1](http://arxiv.org/abs/2409.16882v1)|null|
|**2024-09-25**|**Automating Traffic Model Enhancement with AI Research Agent**|Xusen Guo et.al.|[2409.16876v1](http://arxiv.org/abs/2409.16876v1)|null|
|**2024-09-25**|**Ethical and Scalable Automation: A Governance and Compliance Framework for Business Applications**|Haocheng Lin et.al.|[2409.16872v1](http://arxiv.org/abs/2409.16872v1)|null|
|**2024-09-25**|**Multi-objective Evolution of Heuristic Using Large Language Model**|Shunyu Yao et.al.|[2409.16867v1](http://arxiv.org/abs/2409.16867v1)|null|
|**2024-09-25**|**The Role of Language Models in Modern Healthcare: A Comprehensive Review**|Amna Khalid et.al.|[2409.16860v1](http://arxiv.org/abs/2409.16860v1)|null|
|**2024-09-25**|**Dispute resolution in legal mediation with quantitative argumentation**|Xiao Chi et.al.|[2409.16854v1](http://arxiv.org/abs/2409.16854v1)|null|
|**2024-09-25**|**Exposing Assumptions in AI Benchmarks through Cognitive Modelling**|Jonathan H. Rystrøm et.al.|[2409.16849v1](http://arxiv.org/abs/2409.16849v1)|null|
|**2024-09-25**|**Uncertainty Representations in State-Space Layers for Deep Reinforcement Learning under Partial Observability**|Carlos E. Luis et.al.|[2409.16824v1](http://arxiv.org/abs/2409.16824v1)|null|
|**2024-09-25**|**XAI-guided Insulator Anomaly Detection for Imbalanced Datasets**|Maximilian Andreas Hoefler et.al.|[2409.16821v1](http://arxiv.org/abs/2409.16821v1)|null|
|**2024-09-25**|**CodeInsight: A Curated Dataset of Practical Coding Solutions from Stack Overflow**|Nathanaël Beau et.al.|[2409.16819v1](http://arxiv.org/abs/2409.16819v1)|[link](https://github.com/nathanaelbeau/codeinsight)|
|**2024-09-25**|**PeerArg: Argumentative Peer Review with LLMs**|Purin Sukpanichnant et.al.|[2409.16813v1](http://arxiv.org/abs/2409.16813v1)|null|
|**2024-09-25**|**A Few Hypocrites: Few-Shot Learning and Subtype Definitions for Detecting Hypocrisy Accusations in Online Climate Change Debates**|Paulina Garcia Corral et.al.|[2409.16807v1](http://arxiv.org/abs/2409.16807v1)|null|
|**2024-09-25**|**Large Language Model Predicts Above Normal All India Summer Monsoon Rainfall in 2024**|Ujjawal Sharma et.al.|[2409.16799v1](http://arxiv.org/abs/2409.16799v1)|null|
|**2024-09-25**|**Scalable Ensemble Diversification for OOD Generalization and Detection**|Alexander Rubinstein et.al.|[2409.16797v1](http://arxiv.org/abs/2409.16797v1)|null|
|**2024-09-25**|**Mitigating the Bias of Large Language Model Evaluation**|Hongli Zhou et.al.|[2409.16788v1](http://arxiv.org/abs/2409.16788v1)|null|
|**2024-09-25**|**Enhancing Feature Selection and Interpretability in AI Regression Tasks Through Feature Attribution**|Alexander Hinterleitner et.al.|[2409.16787v1](http://arxiv.org/abs/2409.16787v1)|null|
|**2024-09-25**|**Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction**|Jinchuan Zhang et.al.|[2409.16783v1](http://arxiv.org/abs/2409.16783v1)|null|
|**2024-09-25**|**LLaMa-SciQ: An Educational Chatbot for Answering Science MCQ**|Marc-Antoine Allard et.al.|[2409.16779v1](http://arxiv.org/abs/2409.16779v1)|null|
|**2024-09-25**|**Offline and Distributional Reinforcement Learning for Radio Resource Management**|Eslam Eldeeb et.al.|[2409.16764v1](http://arxiv.org/abs/2409.16764v1)|null|
|**2024-09-25**|**E-SQL: Direct Schema Linking via Question Enrichment in Text-to-SQL**|Hasan Alp Caferoğlu et.al.|[2409.16751v1](http://arxiv.org/abs/2409.16751v1)|[link](https://github.com/HasanAlpCaferoglu/E-SQL)|
|**2024-09-25**|**GB-RVFL: Fusion of Randomized Neural Network and Granular Ball Computing**|M. Sajid et.al.|[2409.16735v1](http://arxiv.org/abs/2409.16735v1)|null|
|**2024-09-25**|**RoleBreak: Character Hallucination as a Jailbreak Attack in Role-Playing Systems**|Yihong Tang et.al.|[2409.16727v1](http://arxiv.org/abs/2409.16727v1)|null|
|**2024-09-25**|**PMSS: Pretrained Matrices Skeleton Selection for LLM Fine-tuning**|Qibin Wang et.al.|[2409.16722v1](http://arxiv.org/abs/2409.16722v1)|null|
|**2024-09-25**|**A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare**|Syed Mohd Faisal Malik et.al.|[2409.16721v1](http://arxiv.org/abs/2409.16721v1)|null|
|**2024-09-25**|**Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification**|Ming Li et.al.|[2409.16718v1](http://arxiv.org/abs/2409.16718v1)|[link](https://github.com/minglllli/clipfit)|
|**2024-09-25**|**Beyond Turing Test: Can GPT-4 Sway Experts' Decisions?**|Takehiro Takayanagi et.al.|[2409.16710v1](http://arxiv.org/abs/2409.16710v1)|null|
|**2024-09-25**|**Probing Omissions and Distortions in Transformer-based RDF-to-Text Models**|Juliette Faille et.al.|[2409.16707v1](http://arxiv.org/abs/2409.16707v1)|null|
|**2024-09-25**|**Pix2Next: Leveraging Vision Foundation Models for RGB to NIR Image Translation**|Youngwan Jin et.al.|[2409.16706v1](http://arxiv.org/abs/2409.16706v1)|null|
|**2024-09-25**|**A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms**|Ruihao Gong et.al.|[2409.16694v1](http://arxiv.org/abs/2409.16694v1)|null|
|**2024-09-25**|**CaBRNet, an open-source library for developing and evaluating Case-Based Reasoning Models**|Romain Xu-Darme et.al.|[2409.16693v1](http://arxiv.org/abs/2409.16693v1)|[link](https://github.com/aiser-team/cabrnet)|
|**2024-09-25**|**Layout-Corrector: Alleviating Layout Sticking Phenomenon in Discrete Diffusion Model**|Shoma Iwai et.al.|[2409.16689v1](http://arxiv.org/abs/2409.16689v1)|null|
|**2024-09-25**|**MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making**|Dayuan Fu et.al.|[2409.16686v1](http://arxiv.org/abs/2409.16686v1)|null|
|**2024-09-25**|**Erase then Rectify: A Training-Free Parameter Editing Approach for Cost-Effective Graph Unlearning**|Zhe-Rui Yang et.al.|[2409.16684v1](http://arxiv.org/abs/2409.16684v1)|null|
|**2024-09-25**|**SynTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA**|Siyue Zhang et.al.|[2409.16682v1](http://arxiv.org/abs/2409.16682v1)|null|
|**2024-09-25**|**Emotional Dimension Control in Language Model-Based Text-to-Speech: Spanning a Broad Spectrum of Human Emotions**|Kun Zhou et.al.|[2409.16681v1](http://arxiv.org/abs/2409.16681v1)|null|
|**2024-09-25**|**TSBP: Improving Object Detection in Histology Images via Test-time Self-guided Bounding-box Propagation**|Tingting Yang et.al.|[2409.16678v1](http://arxiv.org/abs/2409.16678v1)|[link](https://github.com/jwhgdeu/tsbp)|
|**2024-09-25**|**SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection**|Guanyi Mou et.al.|[2409.16673v1](http://arxiv.org/abs/2409.16673v1)|null|
|**2024-09-25**|**GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning**|Zhe-Rui Yang et.al.|[2409.16670v1](http://arxiv.org/abs/2409.16670v1)|null|
|**2024-09-25**|**Topic-aware Causal Intervention for Counterfactual Detection**|Thong Nguyen et.al.|[2409.16668v1](http://arxiv.org/abs/2409.16668v1)|null|
|**2024-09-25**|**A Character-Centric Creative Story Generation via Imagination**|Kyeongman Park et.al.|[2409.16667v1](http://arxiv.org/abs/2409.16667v1)|null|
|**2024-09-25**|**Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts**|Taehun Cha et.al.|[2409.16658v1](http://arxiv.org/abs/2409.16658v1)|[link](https://github.com/AIML-K/HalluDist)|
|**2024-09-25**|**Speech Recognition Rescoring with Large Speech-Text Foundation Models**|Prashanth Gurunath Shivakumar et.al.|[2409.16654v1](http://arxiv.org/abs/2409.16654v1)|null|
|**2024-09-25**|**Progressive Representation Learning for Real-Time UAV Tracking**|Changhong Fu et.al.|[2409.16652v1](http://arxiv.org/abs/2409.16652v1)|[link](https://github.com/vision4robotics/prl-track)|
|**2024-09-25**|**Domain-Independent Automatic Generation of Descriptive Texts for Time-Series Data**|Kota Dohi et.al.|[2409.16647v1](http://arxiv.org/abs/2409.16647v1)|null|
|**2024-09-25**|**Cross-Lingual and Cross-Cultural Variation in Image Descriptions**|Uri Berger et.al.|[2409.16646v1](http://arxiv.org/abs/2409.16646v1)|null|
|**2024-09-25**|**Task Addition in Multi-Task Learning by Geometrical Alignment**|Soorin Yim et.al.|[2409.16645v1](http://arxiv.org/abs/2409.16645v1)|null|
|**2024-09-25**|**Enabling Auditory Large Language Models for Automatic Speech Quality Evaluation**|Siyin Wang et.al.|[2409.16644v1](http://arxiv.org/abs/2409.16644v1)|null|
|**2024-09-25**|**Training Language Models to Win Debates with Self-Play Improves Judge Accuracy**|Samuel Arnesen et.al.|[2409.16636v1](http://arxiv.org/abs/2409.16636v1)|[link](https://github.com/samuelarnesen/nyu-debate-modeling)|
|**2024-09-25**|**Judgment of Thoughts: Courtroom of the Binary Logical Reasoning in Large Language Models**|Sungjune Park et.al.|[2409.16635v1](http://arxiv.org/abs/2409.16635v1)|null|
|**2024-09-25**|**Stochastic Subsampling With Average Pooling**|Bum Jun Kim et.al.|[2409.16630v1](http://arxiv.org/abs/2409.16630v1)|null|
|**2024-09-25**|**Ascend HiFloat8 Format for Deep Learning**|Yuanyong Luo et.al.|[2409.16626v2](http://arxiv.org/abs/2409.16626v2)|null|

#### Abstracts
##### **Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models**
2409.17146v1 by Matt Deitke, Christopher Clark, Sangho Lee, Rohun Tripathi, Yue Yang, Jae Sung Park, Mohammadreza Salehi, Niklas Muennighoff, Kyle Lo, Luca Soldaini, Jiasen Lu, Taira Anderson, Erin Bransom, Kiana Ehsani, Huong Ngo, YenSung Chen, Ajay Patel, Mark Yatskar, Chris Callison-Burch, Andrew Head, Rose Hendrix, Favyen Bastani, Eli VanderBilt, Nathan Lambert, Yvonne Chou, Arnavi Chheda, Jenna Sparks, Sam Skjonsberg, Michael Schmitz, Aaron Sarnat, Byron Bischoff, Pete Walsh, Chris Newell, Piper Wolters, Tanmay Gupta, Kuo-Hao Zeng, Jon Borchardt, Dirk Groeneveld, Jen Dumas, Crystal Nam, Sophie Lebrecht, Caitlin Wittlif, Carissa Schoenick, Oscar Michel, Ranjay Krishna, Luca Weihs, Noah A. Smith, Hannaneh Hajishirzi, Ross Girshick, Ali Farhadi, Aniruddha Kembhavi

Today's most advanced multimodal models remain proprietary. The strongest
open-weight models rely heavily on synthetic data from proprietary VLMs to
achieve good performance, effectively distilling these closed models into open
ones. As a result, the community is still missing foundational knowledge about
how to build performant VLMs from scratch. We present Molmo, a new family of
VLMs that are state-of-the-art in their class of openness. Our key innovation
is a novel, highly detailed image caption dataset collected entirely from human
annotators using speech-based descriptions. To enable a wide array of user
interactions, we also introduce a diverse dataset mixture for fine-tuning that
includes in-the-wild Q&A and innovative 2D pointing data. The success of our
approach relies on careful choices for the model architecture details, a
well-tuned training pipeline, and, most critically, the quality of our newly
collected datasets, all of which will be released. The best-in-class 72B model
within the Molmo family not only outperforms others in the class of open weight
and data models but also compares favorably against proprietary systems like
GPT-4o, Claude 3.5, and Gemini 1.5 on both academic benchmarks and human
evaluation.
  We will be releasing all of our model weights, captioning and fine-tuning
data, and source code in the near future. Select model weights, inference code,
and demo are available at https://molmo.allenai.org.

摘要：<paragraph>當今最先進的多模式模型仍然是專有的。最強大的開放權重模型極度依賴於來自專有 VLM 的合成資料，才能達到良好的效能，有效地將這些封閉模型提煉成開放模型。因此，社群仍然缺乏如何從頭打造效能良好的 VLM 的基礎知識。我們提出 Molmo，一個新的 VLM 家族，在開放性方面屬於其類別中的最先進技術。我們的關鍵創新是使用語音描述從人類註釋員那裡完全收集而來的一組新穎且極為詳細的影像標題資料集。為了支援各種使用者互動，我們還引進一個多元的資料集混合體進行微調，其中包括實際的問答和創新的 2D 指向資料。我們方法的成功有賴於模型架構細節的仔細選擇、調整良好的訓練管道，以及最關鍵的是我們新收集的資料集的品質，所有這些都將發布。Molmo 家族中最好的 72B 模型不僅優於開放權重和資料模型類別中的其他模型，而且在學術基準和人類評估中，也與 GPT-4o、Claude 3.5 和 Gemini 1.5 等專有系統相比之下毫不遜色。我們將在不久的將來釋出我們所有的模型權重、字幕和微調資料，以及原始程式碼。部分模型權重、推論程式碼和示範可於 https://molmo.allenai.org 取得。</paragraph>

##### **Differential Privacy Regularization: Protecting Training Data Through Loss Function Regularization**
2409.17144v1 by Francisco Aguilera-Martínez, Fernando Berzal

Training machine learning models based on neural networks requires large
datasets, which may contain sensitive information. The models, however, should
not expose private information from these datasets. Differentially private SGD
[DP-SGD] requires the modification of the standard stochastic gradient descent
[SGD] algorithm for training new models. In this short paper, a novel
regularization strategy is proposed to achieve the same goal in a more
efficient manner.

摘要：基於神經網路訓練機器學習模型需要大量資料集，其中可能包含敏感資訊。然而，模型不應公開這些資料集中的私人資訊。差分隱私 SGD [DP-SGD] 需要修改標準隨機梯度下降 [SGD] 演算法才能訓練新模型。在這篇短文中，提出了一種新穎的正規化策略，以更有效率的方式達成相同的目標。

##### **Attention Prompting on Image for Large Vision-Language Models**
2409.17143v1 by Runpeng Yu, Weihao Yu, Xinchao Wang

Compared with Large Language Models (LLMs), Large Vision-Language Models
(LVLMs) can also accept images as input, thus showcasing more interesting
emergent capabilities and demonstrating impressive performance on various
vision-language tasks. Motivated by text prompting in LLMs, visual prompting
has been explored to enhance LVLMs' capabilities of perceiving visual
information. However, previous visual prompting techniques solely process
visual inputs without considering text queries, limiting the models' ability to
follow text instructions to complete tasks. To fill this gap, in this work, we
propose a new prompting technique named Attention Prompting on Image, which
just simply overlays a text-query-guided attention heatmap on the original
input image and effectively enhances LVLM on various tasks. Specifically, we
generate an attention heatmap for the input image dependent on the text query
with an auxiliary model like CLIP. Then the heatmap simply multiplies the pixel
values of the original image to obtain the actual input image for the LVLM.
Extensive experiments on various vison-language benchmarks verify the
effectiveness of our technique. For example, Attention Prompting on Image
improves LLaVA-1.5 by 3.8% and 2.9% on MM-Vet and LLaVA-Wild benchmarks,
respectively.

摘要：與大型語言模型 (LLM) 相比，大型視覺語言模型 (LVLMs) 也可以接受影像作為輸入，因此展示出更有趣的浮現能力，並在各種視覺語言任務上展現出令人印象深刻的效能。受 LLM 中文字提示的啟發，視覺提示已廣泛探索，以增強 LVLMs 感知視覺資訊的能力。然而，先前的視覺提示技術僅處理視覺輸入，而不考慮文字查詢，這限制了模型按照文字指示完成任務的能力。為了填補這個空白，我們在這項工作中提出了一種新的提示技術，稱為影像上的注意力提示，它只是簡單地將文字查詢引導的注意力熱圖疊加在原始輸入影像上，並有效地增強了 LVLM 在各種任務上的能力。具體來說，我們為輸入影像產生一個注意力熱圖，該熱圖取決於文字查詢和 CLIP 等輔助模型。然後，熱圖簡單地將原始影像的像素值相乘，以取得 LVLM 的實際輸入影像。在各種視覺語言基準上的廣泛實驗驗證了我們技術的有效性。例如，影像上的注意力提示分別在 MM-Vet 和 LLaVA-Wild 基準上將 LLaVA-1.5 提升了 3.8% 和 2.9%。

##### **FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression**
2409.17141v1 by Fazal Mittu, Yihuan Bu, Akshat Gupta, Ashok Devireddy, Alp Eren Ozdarendeli, Anant Singh, Gopala Anumanchipalli

While the language modeling objective has been shown to be deeply connected
with compression, it is surprising that modern LLMs are not employed in
practical text compression systems. In this paper, we provide an in-depth
analysis of neural network and transformer-based compression techniques to
answer this question. We compare traditional text compression systems with
neural network and LLM-based text compression methods. Although LLM-based
systems significantly outperform conventional compression methods, they are
highly impractical. Specifically, LLMZip, a recent text compression system
using Llama3-8B requires 9.5 days to compress just 10 MB of text, although with
huge improvements in compression ratios. To overcome this, we present FineZip -
a novel LLM-based text compression system that combines ideas of online
memorization and dynamic context to reduce the compression time immensely.
FineZip can compress the above corpus in approximately 4 hours compared to 9.5
days, a 54 times improvement over LLMZip and comparable performance. FineZip
outperforms traditional algorithmic compression methods with a large margin,
improving compression ratios by approximately 50\%. With this work, we take the
first step towards making lossless text compression with LLMs a reality. While
FineZip presents a significant step in that direction, LLMs are still not a
viable solution for large-scale text compression. We hope our work paves the
way for future research and innovation to solve this problem.

摘要：儘管語言模型目標已被證明與壓縮有密切的關聯，但令人驚訝的是，現代 LLM 並未用於實際的文字壓縮系統中。在本文中，我們提供了神經網路和基於Transformer的壓縮技術的深入分析，以回答這個問題。我們將傳統的文字壓縮系統與基於神經網路和 LLM 的文字壓縮方法進行比較。儘管基於 LLM 的系統明顯優於傳統的壓縮方法，但它們極不切實際。具體來說，LLMZip 是一個最近的文字壓縮系統，使用 Llama3-8B 需要 9.5 天才能壓縮僅 10 MB 的文字，儘管壓縮比有了很大的改進。為了克服這個問題，我們提出了 FineZip - 一個新穎的基於 LLM 的文字壓縮系統，它結合了線上記憶和動態內容的想法，以極大地減少壓縮時間。與 9.5 天相比，FineZip 大約可以在 4 小時內壓縮上述語料庫，比 LLMZip 提高了 54 倍，並且具有相當的效能。FineZip 以很大的差距優於傳統的演算法壓縮方法，將壓縮比提高了大約 50%。透過這項工作，我們邁出了第一步，讓使用 LLM 的無損文字壓縮成為現實。儘管 FineZip 朝著這個方向邁出了重要一步，但 LLM 仍然不是大規模文字壓縮的可行解決方案。我們希望我們的研究為解決這個問題的未來研究和創新鋪平道路。

##### **Turn Every Application into an Agent: Towards Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents**
2409.17140v1 by Junting Lu, Zhiyang Zhang, Fangkai Yang, Jue Zhang, Lu Wang, Chao Du, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

Multimodal large language models (MLLMs) have enabled LLM-based agents to
directly interact with application user interfaces (UIs), enhancing agents'
performance in complex tasks. However, these agents often suffer from high
latency and low reliability due to the extensive sequential UI interactions. To
address this issue, we propose AXIS, a novel LLM-based agents framework
prioritize actions through application programming interfaces (APIs) over UI
actions. This framework also facilitates the creation and expansion of APIs
through automated exploration of applications. Our experiments on Office Word
demonstrate that AXIS reduces task completion time by 65%-70% and cognitive
workload by 38%-53%, while maintaining accuracy of 97%-98% compare to humans.
Our work contributes to a new human-agent-computer interaction (HACI) framework
and a fresh UI design principle for application providers in the era of LLMs.
It also explores the possibility of turning every applications into agents,
paving the way towards an agent-centric operating system (Agent OS).

摘要：多模态大型语言模型 (MLLM) 已让基于 LLM 的代理直接与应用程序用户界面 (UI) 互动，提升了代理在复杂任务中的表现。然而，这些代理经常因为广泛的顺序 UI 互动而遭受高延迟和低可靠性的问题。为了解决这个问题，我们提出 AXIS，一个新颖的基于 LLM 的代理框架，通过应用程序编程接口 (API) 优先执行动作，而不是 UI 动作。此框架还通过自动探索应用程序来促进创建和扩展 API。我们在 Office Word 上的实验表明，AXIS 将任务完成时间减少了 65%-70%，认知工作量减少了 38%-53%，同时将准确性维持在 97%-98%，可与人类相媲美。我们的工作有助于形成一个人机计算机交互 (HACI) 框架，以及在 LLM 时代为应用程序提供者提供一个新的 UI 设计原则。它还探索了将每个应用程序变成代理的可能性，为以代理为中心的作业系统 (Agent OS) 铺平了道路。

##### **Assessing the Level of Toxicity Against Distinct Groups in Bangla Social Media Comments: A Comprehensive Investigation**
2409.17130v1 by Mukaffi Bin Moin, Pronay Debnath, Usafa Akther Rifa, Rijeet Bin Anis

Social media platforms have a vital role in the modern world, serving as
conduits for communication, the exchange of ideas, and the establishment of
networks. However, the misuse of these platforms through toxic comments, which
can range from offensive remarks to hate speech, is a concerning issue. This
study focuses on identifying toxic comments in the Bengali language targeting
three specific groups: transgender people, indigenous people, and migrant
people, from multiple social media sources. The study delves into the intricate
process of identifying and categorizing toxic language while considering the
varying degrees of toxicity: high, medium, and low. The methodology involves
creating a dataset, manual annotation, and employing pre-trained transformer
models like Bangla-BERT, bangla-bert-base, distil-BERT, and
Bert-base-multilingual-cased for classification. Diverse assessment metrics
such as accuracy, recall, precision, and F1-score are employed to evaluate the
model's effectiveness. The experimental findings reveal that Bangla-BERT
surpasses alternative models, achieving an F1-score of 0.8903. This research
exposes the complexity of toxicity in Bangla social media dialogues, revealing
its differing impacts on diverse demographic groups.

摘要：<paragraph>社群媒體平台在現代社會中扮演著至關重要的角色，作為溝通、思想交流和建立人際網絡的管道。然而，這些平台遭到濫用，出現了從攻擊性言論到仇恨言論等各種形式的惡意留言，這是一個令人擔憂的問題。本研究專注於從多個社群媒體來源中找出針對三個特定群體（跨性別者、原住民和移工）的孟加拉語惡意留言。本研究深入探討了識別和分類惡意語言的複雜過程，同時考慮了不同程度的惡意程度：高、中、低。方法包括建立資料集、手動標註，並運用預先訓練好的轉換器模型，例如 Bangla-BERT、bangla-bert-base、distil-BERT 和 Bert-base-multilingual-cased 進行分類。採用多樣化的評估指標，例如準確度、召回率、精確度和 F1 分數，來評估模型的有效性。實驗結果顯示，Bangla-BERT 優於其他模型，達到 0.8903 的 F1 分數。本研究揭露了孟加拉社群媒體對話中惡意言論的複雜性，顯示出它對不同人口群體產生不同的影響。</paragraph>

##### **Blox-Net: Generative Design-for-Robot-Assembly Using VLM Supervision, Physics Simulation, and a Robot with Reset**
2409.17126v1 by Andrew Goldberg, Kavish Kondap, Tianshuang Qiu, Zehan Ma, Letian Fu, Justin Kerr, Huang Huang, Kaiyuan Chen, Kuan Fang, Ken Goldberg

Generative AI systems have shown impressive capabilities in creating text,
code, and images. Inspired by the rich history of research in industrial
''Design for Assembly'', we introduce a novel problem: Generative
Design-for-Robot-Assembly (GDfRA). The task is to generate an assembly based on
a natural language prompt (e.g., ''giraffe'') and an image of available
physical components, such as 3D-printed blocks. The output is an assembly, a
spatial arrangement of these components, and instructions for a robot to build
this assembly. The output must 1) resemble the requested object and 2) be
reliably assembled by a 6 DoF robot arm with a suction gripper. We then present
Blox-Net, a GDfRA system that combines generative vision language models with
well-established methods in computer vision, simulation, perturbation analysis,
motion planning, and physical robot experimentation to solve a class of GDfRA
problems with minimal human supervision. Blox-Net achieved a Top-1 accuracy of
63.5% in the ''recognizability'' of its designed assemblies (eg, resembling
giraffe as judged by a VLM). These designs, after automated perturbation
redesign, were reliably assembled by a robot, achieving near-perfect success
across 10 consecutive assembly iterations with human intervention only during
reset prior to assembly. Surprisingly, this entire design process from textual
word (''giraffe'') to reliable physical assembly is performed with zero human
intervention.

摘要：生成式 AI 系統在建立文字、程式碼和影像方面展現出令人印象深刻的能力。受到工業「組裝設計」研究豐富歷史的啟發，我們提出了一個新的問題：生成式機器人組裝設計 (GDfRA)。這項任務是根據自然語言提示（例如「長頸鹿」）和可用實體元件（例如 3D 列印積木）的影像來產生組裝。輸出是一個組裝，這些元件的空間配置，以及機器人組裝此組裝的說明。輸出必須 1) 類似於請求的物件，且 2) 能夠由具有吸盤夾具的 6 DoF 機器手臂可靠地組裝。接著我們提出 Blox-Net，這是一個 GDfRA 系統，結合了生成式視覺語言模型與電腦視覺、模擬、擾動分析、動作規劃和實體機器人實驗中已建立良好的方法，以解決一類 GDfRA 問題，且只需最少的人工監督。在組裝設計的「可辨識性」方面，Blox-Net 達到了 63.5% 的 Top-1 精確度（例如，經由 VLM 判斷類似於長頸鹿）。這些設計在自動擾動重新設計後，由機器人可靠地組裝，在 10 次連續組裝反覆運算中達到近乎完美的成功率，只有在組裝前重設時才需要人工介入。令人驚訝的是，從文字詞彙（「長頸鹿」）到可靠的實體組裝，整個設計過程完全沒有人工介入。

##### **On-orbit Servicing for Spacecraft Collision Avoidance With Autonomous Decision Making**
2409.17125v1 by Susmitha Patnala, Adam Abdin

This study develops an AI-based implementation of autonomous On-Orbit
Servicing (OOS) mission to assist with spacecraft collision avoidance maneuvers
(CAMs). We propose an autonomous `servicer' trained with Reinforcement Learning
(RL) to autonomously detect potential collisions between a target satellite and
space debris, rendezvous and dock with endangered satellites, and execute
optimal CAM. The RL model integrates collision risk estimates, satellite
specifications, and debris data to generate an optimal maneuver matrix for OOS
rendezvous and collision prevention. We employ the Cross-Entropy algorithm to
find optimal decision policies efficiently. Initial results demonstrate the
feasibility of autonomous robotic OOS for collision avoidance services,
focusing on one servicer spacecraft to one endangered satellite scenario.
However, merging spacecraft rendezvous and optimal CAM presents significant
complexities. We discuss design challenges and critical parameters for the
successful implementation of the framework presented through a case study.

摘要：本研究開發了一種基於 AI 的自主軌道服務 (OOS) 任務實作，用於協助太空船的防撞操作 (CAM)。我們提出一個使用強化學習 (RL) 訓練的自主「服務器」，用於自主偵測目標衛星與太空碎片之間的潛在碰撞，與瀕危衛星會合並對接，並執行最佳化 CAM。RL 模型整合了碰撞風險估計、衛星規格和碎片資料，以產生一個最佳化操作矩陣，用於 OOS 會合和防撞。我們採用交叉熵演算法來有效找出最佳決策策略。初步結果證明了自主機器人 OOS 防撞服務的可行性，專注於一艘服務器太空船對一艘瀕危衛星的場景。然而，整合太空船會合和最佳化 CAM 會產生顯著的複雜性。我們透過一個案例研究討論了成功實作所提出的架構的設計挑戰和關鍵參數。

##### **Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Handy Appetizer**
2409.17120v1 by Benji Peng, Xuanhe Pan, Yizhu Wen, Ziqian Bi, Keyu Chen, Ming Li, Ming Liu, Qian Niu, Junyu Liu, Jinlang Wang, Sen Zhang, Jiawei Xu, Pohsun Feng

This book explores the role of Artificial Intelligence (AI), Machine Learning
(ML), and Deep Learning (DL) in driving the progress of big data analytics and
management. The book focuses on simplifying the complex mathematical concepts
behind deep learning, offering intuitive visualizations and practical case
studies to help readers understand how neural networks and technologies like
Convolutional Neural Networks (CNNs) work. It introduces several classic models
and technologies such as Transformers, GPT, ResNet, BERT, and YOLO,
highlighting their applications in fields like natural language processing,
image recognition, and autonomous driving. The book also emphasizes the
importance of pre-trained models and how they can enhance model performance and
accuracy, with instructions on how to apply these models in various real-world
scenarios. Additionally, it provides an overview of key big data management
technologies like SQL and NoSQL databases, as well as distributed computing
frameworks such as Apache Hadoop and Spark, explaining their importance in
managing and processing vast amounts of data. Ultimately, the book underscores
the value of mastering deep learning and big data management skills as critical
tools for the future workforce, making it an essential resource for both
beginners and experienced professionals.

摘要：本書探討人工智慧 (AI)、機器學習 (ML) 和深度學習 (DL) 在推動大數據分析和管理進步中的角色。本書重點在於簡化深度學習背後複雜的數學概念，提供直觀的視覺化和實用的案例研究，以幫助讀者了解神經網路和卷積神經網路 (CNN) 等技術如何運作。它介紹了幾個經典模型和技術，例如 Transformers、GPT、ResNet、BERT 和 YOLO，重點介紹它們在自然語言處理、影像辨識和自動駕駛等領域的應用。本書也強調預訓練模型的重要性，以及它們如何增強模型效能和準確度，並提供如何將這些模型應用於各種實際場景的說明。此外，它概述了關鍵大數據管理技術，例如 SQL 和 NoSQL 資料庫，以及分散式運算架構，例如 Apache Hadoop 和 Spark，說明它們在管理和處理大量資料中的重要性。最後，本書強調精通深度學習和大數據管理技能的價值，因為它們是未來勞動力必備的重要工具，使其成為初學者和經驗豐富的專業人士的必備資源。

##### **Programming Every Example: Lifting Pre-training Data Quality like Experts at Scale**
2409.17115v1 by Fan Zhou, Zengzhi Wang, Qian Liu, Junlong Li, Pengfei Liu

Large language model pre-training has traditionally relied on human experts
to craft heuristics for improving the corpora quality, resulting in numerous
rules developed to date. However, these rules lack the flexibility to address
the unique characteristics of individual example effectively. Meanwhile,
applying tailored rules to every example is impractical for human experts. In
this paper, we demonstrate that even small language models, with as few as 0.3B
parameters, can exhibit substantial data refining capabilities comparable to
those of human experts. We introduce Programming Every Example (ProX), a novel
framework that treats data refinement as a programming task, enabling models to
refine corpora by generating and executing fine-grained operations, such as
string normalization, for each individual example at scale. Experimental
results show that models pre-trained on ProX-curated data outperform either
original data or data filtered by other selection methods by more than 2%
across various downstream benchmarks. Its effectiveness spans various model
sizes and pre-training corpora, including C4, RedPajama-V2, and FineWeb.
Furthermore, ProX exhibits significant potential in domain-specific continual
pre-training: without domain specific design, models trained on OpenWebMath
refined by ProX outperform human-crafted rule-based methods, improving average
accuracy by 7.6% over Mistral-7B, with 14.6% for Llama-2-7B and 20.3% for
CodeLlama-7B, all within 10B tokens to be comparable to models like Llemma-7B
trained on 200B tokens. Further analysis highlights that ProX significantly
saves training FLOPs, offering a promising path for efficient LLM
pre-training.We are open-sourcing ProX with >100B corpus, models, and sharing
all training and implementation details for reproducible research and future
innovation. Code: https://github.com/GAIR-NLP/ProX

摘要：大型語言模型預訓練傳統上依賴人類專家
制定啟發式方法來改善語料庫品質，導致迄今已開發出許多規則。然而，這些規則缺乏靈活性，無法有效解決個別範例的獨特特性。同時，對每個範例應用量身打造的規則對人類專家來說並不實際。在本文中，我們證明即使是只有 0.3B 參數的小語言模型，也可以展現出與人類專家相當的實質性資料精煉能力。我們引入了「為每個範例編程」（ProX），這是一個新穎的架構，將資料精煉視為一項編程任務，使模型能夠透過為每個個別範例產生並執行細微的運算（例如字串正規化）來精煉語料庫。實驗結果顯示，使用 ProX 整理資料後預先訓練的模型，在各種下游基準中都比原始資料或由其他選擇方法篩選的資料高出 2% 以上。其效能涵蓋各種模型大小和預訓練語料庫，包括 C4、RedPajama-V2 和 FineWeb。此外，ProX 在特定領域的持續預訓練中展現出顯著的潛力：在沒有特定領域設計的情況下，使用 ProX 精煉的 OpenWebMath 訓練模型優於人類編寫的基於規則的方法，平均準確度比 Mistral-7B 提高 7.6%，比 Llama-2-7B 提高 14.6%，比 CodeLlama-7B 提高 20.3%，所有都在 10B 個代幣內，與訓練 200B 個代幣的 Llemma-7B 等模型相當。進一步的分析重點指出，ProX 大幅節省了訓練 FLOP，為高效 LLM 預訓練提供了一條有希望的路徑。我們開放原始碼 ProX，其中包含 >100B 語料庫、模型，並分享所有訓練和實作細節，以利於可重製的研究和未來的創新。程式碼：https://github.com/GAIR-NLP/ProX

##### **Unveiling Ontological Commitment in Multi-Modal Foundation Models**
2409.17109v1 by Mert Keser, Gesina Schwalbe, Niki Amini-Naieni, Matthias Rottmann, Alois Knoll

Ontological commitment, i.e., used concepts, relations, and assumptions, are
a corner stone of qualitative reasoning (QR) models. The state-of-the-art for
processing raw inputs, though, are deep neural networks (DNNs), nowadays often
based off from multimodal foundation models. These automatically learn rich
representations of concepts and respective reasoning. Unfortunately, the
learned qualitative knowledge is opaque, preventing easy inspection,
validation, or adaptation against available QR models. So far, it is possible
to associate pre-defined concepts with latent representations of DNNs, but
extractable relations are mostly limited to semantic similarity. As a next step
towards QR for validation and verification of DNNs: Concretely, we propose a
method that extracts the learned superclass hierarchy from a multimodal DNN for
a given set of leaf concepts. Under the hood we (1) obtain leaf concept
embeddings using the DNN's textual input modality; (2) apply hierarchical
clustering to them, using that DNNs encode semantic similarities via vector
distances; and (3) label the such-obtained parent concepts using search in
available ontologies from QR. An initial evaluation study shows that meaningful
ontological class hierarchies can be extracted from state-of-the-art foundation
models. Furthermore, we demonstrate how to validate and verify a DNN's learned
representations against given ontologies. Lastly, we discuss potential future
applications in the context of QR.

摘要：本体論承諾，即使用概念、關係和假設，是定性推理（QR）模型的基石。然而，處理原始輸入的最新技術是深度神經網路（DNN），現在通常基於多模態基礎模型。這些自動學習概念和各自推理的豐富表示。不幸的是，學習到的定性知識是不透明的，阻止了對可用 QR 模型的輕鬆檢查、驗證或適應。到目前為止，可以將預定義的概念與 DNN 的潛在表示關聯起來，但可提取的關係大多限於語義相似性。作為驗證和驗證 DNN 的 QR 的下一步：具體來說，我們提出了一種方法，該方法從多模態 DNN 中提取學習到的超類別層次結構，用於給定的葉子概念集。在幕後，我們（1）使用 DNN 的文本輸入方式獲取葉子概念嵌入；（2）對它們應用階層聚類，使用 DNN 通過向量距離編碼語義相似性；（3）使用 QR 中可用本体中的搜尋標籤此類獲得的父概念。初步評估研究表明，可以從最先進的基礎模型中提取有意義的本体類別層次結構。此外，我們展示了如何根據給定的本体驗證和驗證 DNN 學習的表示。最後，我們討論了 QR 背景下的潛在未來應用。

##### **Accumulator-Aware Post-Training Quantization**
2409.17092v1 by Ian Colbert, Fabian Grob, Giuseppe Franco, Jinjie Zhang, Rayan Saab

Several recent studies have investigated low-precision accumulation,
reporting improvements in throughput, power, and area across various platforms.
However, the accompanying proposals have only considered the quantization-aware
training (QAT) paradigm, in which models are fine-tuned or trained from scratch
with quantization in the loop. As models continue to grow in size, QAT
techniques become increasingly more expensive, which has motivated the recent
surge in post-training quantization (PTQ) research. To the best of our
knowledge, ours marks the first formal study of accumulator-aware quantization
in the PTQ setting. To bridge this gap, we introduce AXE, a practical framework
of accumulator-aware extensions designed to endow overflow avoidance guarantees
to existing layer-wise PTQ algorithms. We theoretically motivate AXE and
demonstrate its flexibility by implementing it on top of two state-of-the-art
PTQ algorithms: GPFQ and OPTQ. We further generalize AXE to support multi-stage
accumulation for the first time, opening the door for full datapath
optimization and scaling to large language models (LLMs). We evaluate AXE
across image classification and language generation models, and observe
significant improvements in the trade-off between accumulator bit width and
model accuracy over baseline methods.

摘要：最近有许多研究调查了低精度累加，报告了在各种平台上吞吐量、功耗和面积的改进。然而，随附的提案只考虑了量化感知训练 (QAT) 范例，其中模型经过微调或从头开始训练，并且在循环中进行量化。随着模型尺寸持续增长，QAT 技术变得越来越昂贵，这促使训练后量化 (PTQ) 研究最近激增。据我们所知，我们的研究标志着在 PTQ 设置中首次正式研究了累加器感知量化。为了弥补这一差距，我们引入了 AXE，这是一个实用的累加器感知扩展框架，旨在为现有的逐层 PTQ 算法提供溢出避免保证。我们在理论上激发了 AXE，并通过在两种最先进的 PTQ 算法 GPFQ 和 OPTQ 的基础上实现它来证明其灵活性。我们进一步将 AXE 概括为首次支持多级累加，为完全数据路径优化和扩展到大语言模型 (LLM) 打开了大门。我们在图像分类和语言生成模型中评估了 AXE，并观察到在累加器位宽和模型准确性之间的权衡方面，相较于基线方法有显著的改进。

##### **Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification**
2409.17091v1 by Xinrui Zhou, Yuhao Huang, Haoran Dou, Shijing Chen, Ao Chang, Jia Liu, Weiran Long, Jian Zheng, Erjiao Xu, Jie Ren, Ruobing Huang, Jun Cheng, Wufeng Xue, Dong Ni

In the medical field, the limited availability of large-scale datasets and
labor-intensive annotation processes hinder the performance of deep models.
Diffusion-based generative augmentation approaches present a promising solution
to this issue, having been proven effective in advancing downstream medical
recognition tasks. Nevertheless, existing works lack sufficient semantic and
sequential steerability for challenging video/3D sequence generation, and
neglect quality control of noisy synthesized samples, resulting in unreliable
synthetic databases and severely limiting the performance of downstream tasks.
In this work, we present Ctrl-GenAug, a novel and general generative
augmentation framework that enables highly semantic- and sequential-customized
sequence synthesis and suppresses incorrectly synthesized samples, to aid
medical sequence classification. Specifically, we first design a multimodal
conditions-guided sequence generator for controllably synthesizing
diagnosis-promotive samples. A sequential augmentation module is integrated to
enhance the temporal/stereoscopic coherence of generated samples. Then, we
propose a noisy synthetic data filter to suppress unreliable cases at semantic
and sequential levels. Extensive experiments on 3 medical datasets, using 11
networks trained on 3 paradigms, comprehensively analyze the effectiveness and
generality of Ctrl-GenAug, particularly in underrepresented high-risk
populations and out-domain conditions.

摘要：在医学領域中，大規模數據集的可用性有限，且人工標註過程繁瑣，阻礙了深度模型的執行。基於擴散的生成式擴充方法為此問題提供了有前景的解決方案，已被證實能有效推進下游醫療識別任務。儘管如此，現有作品缺乏足夠的語義和序列可控性，難以進行具有挑戰性的視訊/3D 序列生成，且忽略了對有雜訊合成樣本的品質控制，導致合成式資料庫不可靠，並嚴重限制了下游任務的執行。在這項工作中，我們提出了 Ctrl-GenAug，一個新穎且通用的生成式擴充架構，能實現高度語義和序列自訂的序列合成，並抑制錯誤合成的樣本，以協助醫療序列分類。具體來說，我們首先設計了一個多模態條件引導序列生成器，用於可控地合成促進診斷的樣本。整合了一個序列擴充模組，以增強生成樣本的時間/立體一致性。然後，我們提出了一個有雜訊的合成資料濾波器，以抑制語義和序列層級中不可靠的案例。在 3 個醫療數據集上進行的廣泛實驗，使用在 3 個範例中訓練的 11 個網路，全面分析了 Ctrl-GenAug 的有效性和普遍性，特別是在代表性不足的高風險族群和領域外條件中。

##### **Can Vision Language Models Learn from Visual Demonstrations of Ambiguous Spatial Reasoning?**
2409.17080v1 by Bowen Zhao, Leo Parker Dirac, Paulina Varshavskaya

Large vision-language models (VLMs) have become state-of-the-art for many
computer vision tasks, with in-context learning (ICL) as a popular adaptation
strategy for new ones. But can VLMs learn novel concepts purely from visual
demonstrations, or are they limited to adapting to the output format of ICL
examples? We propose a new benchmark we call Spatial Visual Ambiguity Tasks
(SVAT) that challenges state-of-the-art VLMs to learn new visuospatial tasks
in-context. We find that VLMs fail to do this zero-shot, and sometimes continue
to fail after finetuning. However, adding simpler data to the training by
curriculum learning leads to improved ICL performance.

摘要：大型視覺語言模型 (VLM) 已成為許多電腦視覺任務的最新技術，其中情境學習 (ICL) 是一種適用於新任務的熱門改編策略。但 VLM 能否僅從視覺示範中學習新概念，或者它們是否僅限於適應 ICL 範例的輸出格式？我們提出一個新基準，我們稱之為空間視覺模糊任務 (SVAT)，它挑戰最新技術的 VLM 在情境中學習新的視覺空間任務。我們發現 VLM 無法做到這一點，有時在微調後仍會繼續失敗。然而，透過課程學習將更簡單的資料新增到訓練中，可以提升 ICL 的效能。

##### **Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition**
2409.17073v1 by Pritika Ramu, Koustava Goswami, Apoorv Saxena, Balaji Vasan Srinivavsan

Accurately attributing answer text to its source document is crucial for
developing a reliable question-answering system. However, attribution for long
documents remains largely unexplored. Post-hoc attribution systems are designed
to map answer text back to the source document, yet the granularity of this
mapping has not been addressed. Furthermore, a critical question arises: What
precisely should be attributed, with an emphasis on identifying the information
units within an answer that necessitate grounding? In this paper, we propose
and investigate a novel approach to the factual decomposition of generated
answers for attribution, employing template-based in-context learning. To
accomplish this, we utilize the question and integrate negative sampling during
few-shot in-context learning for decomposition. This approach enhances the
semantic understanding of both abstractive and extractive answers. We examine
the impact of answer decomposition by providing a thorough examination of
various attribution approaches, ranging from retrieval-based techniques to
LLM-based attributors.

摘要：準確地將答案文字歸因於其原始文件對於開發可靠的問答系統至關重要。然而，對於長文件的歸因仍然很大程度上未被探索。事後歸因系統旨在將答案文字映射回原始文件，但尚未解決此映射的粒度。此外，一個關鍵問題出現了：應該歸因什麼，重點是識別答案中需要依據的資訊單元？在本文中，我們提出並探討一種新穎的方法來對生成的答案進行事實分解以進行歸因，採用基於模板的上下文學習。為了實現這一點，我們在少次數上下文學習期間利用問題並整合負面抽樣進行分解。這種方法增強了對抽象和抽取答案的語義理解。我們通過提供對各種歸因方法的徹底檢查來檢驗答案分解的影響，範圍從基於檢索的技術到基於 LLM 的歸因器。

##### **The Effect of Perceptual Metrics on Music Representation Learning for Genre Classification**
2409.17069v1 by Tashi Namgyal, Alexander Hepburn, Raul Santos-Rodriguez, Valero Laparra, Jesus Malo

The subjective quality of natural signals can be approximated with objective
perceptual metrics. Designed to approximate the perceptual behaviour of human
observers, perceptual metrics often reflect structures found in natural signals
and neurological pathways. Models trained with perceptual metrics as loss
functions can capture perceptually meaningful features from the structures held
within these metrics. We demonstrate that using features extracted from
autoencoders trained with perceptual losses can improve performance on music
understanding tasks, i.e. genre classification, over using these metrics
directly as distances when learning a classifier. This result suggests improved
generalisation to novel signals when using perceptual metrics as loss functions
for representation learning.

摘要：自然訊號的主觀品質可以用客觀的感知指標來近似。為了近似人類觀察者的感知行為，感知指標通常反映自然訊號和神經路徑中發現的結構。以感知指標作為損失函數訓練的模型可以從這些指標中包含的結構中擷取有感知意義的特徵。我們證明，使用從使用感知損失訓練的自編碼器中提取的特徵可以改善音樂理解任務（例如類型分類）的效能，而不是在學習分類器時直接將這些指標用作距離。此結果表明，在使用感知指標作為表示學習的損失函數時，對新訊號的概化能力會有所提升。

##### **VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models**
2409.17066v1 by Yifei Liu, Jicheng Wen, Yang Wang, Shengyu Ye, Li Lyna Zhang, Ting Cao, Cheng Li, Mao Yang

Scaling model size significantly challenges the deployment and inference of
Large Language Models (LLMs). Due to the redundancy in LLM weights, recent
research has focused on pushing weight-only quantization to extremely low-bit
(even down to 2 bits). It reduces memory requirements, optimizes storage costs,
and decreases memory bandwidth needs during inference. However, due to
numerical representation limitations, traditional scalar-based weight
quantization struggles to achieve such extreme low-bit. Recent research on
Vector Quantization (VQ) for LLMs has demonstrated the potential for extremely
low-bit model quantization by compressing vectors into indices using lookup
tables.
  In this paper, we introduce Vector Post-Training Quantization (VPTQ) for
extremely low-bit quantization of LLMs. We use Second-Order Optimization to
formulate the LLM VQ problem and guide our quantization algorithm design by
solving the optimization. We further refine the weights using
Channel-Independent Second-Order Optimization for a granular VQ. In addition,
by decomposing the optimization problem, we propose a brief and effective
codebook initialization algorithm. We also extend VPTQ to support residual and
outlier quantization, which enhances model accuracy and further compresses the
model. Our experimental results show that VPTQ reduces model quantization
perplexity by $0.01$-$0.34$ on LLaMA-2, $0.38$-$0.68$ on Mistral-7B,
$4.41$-$7.34$ on LLaMA-3 over SOTA at 2-bit, with an average accuracy
improvement of $0.79$-$1.5\%$ on LLaMA-2, $1\%$ on Mistral-7B, $11$-$22\%$ on
LLaMA-3 on QA tasks on average. We only utilize $10.4$-$18.6\%$ of the
quantization algorithm execution time, resulting in a $1.6$-$1.8\times$
increase in inference throughput compared to SOTA.

摘要：<paragraph>大幅縮放模型大小會對大型語言模型 (LLM) 的部署和推論帶來嚴峻挑戰。由於 LLM 權重中的冗餘，最近的研究已專注於將僅權重量化推至極低位元（甚至低至 2 位元）。這減少了記憶體需求，最佳化儲存成本，並在推論期間降低記憶體頻寬需求。然而，由於數值表示限制，傳統的基於純量權重量化難以達到如此極低的位元。最近針對 LLM 的向量量化 (VQ) 研究已證明了極低位元模型量化的潛力，方法是使用查找表將向量壓縮成索引。
本文中，我們介紹了極低位元 LLM 量化的向量後訓練量化 (VPTQ)。我們使用二階最佳化來制定 LLM VQ 問題，並透過求解最佳化來引導我們的量化演算法設計。我們進一步使用通道無關二階最佳化來改善權重，以進行細緻的 VQ。此外，透過分解最佳化問題，我們提出了一個簡短且有效的碼本初始化演算法。我們也擴充 VPTQ 以支援殘差和離群值量化，這能提升模型準確度並進一步壓縮模型。我們的實驗結果顯示，VPTQ 在 2 位元時，將 LLaMA-2 的模型量化困惑度降低了 $0.01$-$0.34$，Mistral-7B 降低了 $0.38$-$0.68$，LLaMA-3 降低了 $4.41$-$7.34$，優於 SOTA，平均準確度提升了 LLaMA-2 的 $0.79$-$1.5\%$，Mistral-7B 的 $1\%$，LLaMA-3 的 $11$-$22\%$（平均而言）。我們僅利用了量化演算法執行時間的 $10.4$-$18.6\%$，與 SOTA 相比，推論吞吐量增加了 $1.6$-$1.8\times$。</paragraph>

##### **Benchmarking Domain Generalization Algorithms in Computational Pathology**
2409.17063v1 by Neda Zamanitajeddin, Mostafa Jahanifar, Kesi Xu, Fouzia Siraj, Nasir Rajpoot

Deep learning models have shown immense promise in computational pathology
(CPath) tasks, but their performance often suffers when applied to unseen data
due to domain shifts. Addressing this requires domain generalization (DG)
algorithms. However, a systematic evaluation of DG algorithms in the CPath
context is lacking. This study aims to benchmark the effectiveness of 30 DG
algorithms on 3 CPath tasks of varying difficulty through 7,560
cross-validation runs. We evaluate these algorithms using a unified and robust
platform, incorporating modality-specific techniques and recent advances like
pretrained foundation models. Our extensive cross-validation experiments
provide insights into the relative performance of various DG strategies. We
observe that self-supervised learning and stain augmentation consistently
outperform other methods, highlighting the potential of pretrained models and
data augmentation. Furthermore, we introduce a new pan-cancer tumor detection
dataset (HISTOPANTUM) as a benchmark for future research. This study offers
valuable guidance to researchers in selecting appropriate DG approaches for
CPath tasks.

摘要：深度學習模型在計算病理學 (CPath) 任務中展現出巨大的前景，但當應用於未見數據時，其效能通常會因領域轉移而下降。解決此問題需要領域泛化 (DG) 演算法。然而，目前缺乏在 CPath 背景下對 DG 演算法的系統性評估。本研究旨在透過 7,560 次交叉驗證執行，對 30 種 DG 演算法在 3 種不同難度的 CPath 任務上的效能進行基準測試。我們使用一個統一且穩健的平台評估這些演算法，並結合特定於方式的技術和預訓練基礎模型等最新進展。我們廣泛的交叉驗證實驗提供了對各種 DG 策略相對效能的見解。我們觀察到自監督式學習和染色增強始終優於其他方法，突顯了預訓練模型和資料增強的潛力。此外，我們引入了一個新的泛癌腫瘤檢測資料集 (HISTOPANTUM) 作為未來研究的基準。本研究為研究人員在選擇適當的 DG 方法以執行 CPath 任務時提供了寶貴的指導。

##### **DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**
2409.17055v1 by Lucas Robinet, Ahmad Berjaoui, Ziad Kheil, Elizabeth Cohen-Jonathan Moyal

Real-life medical data is often multimodal and incomplete, fueling the
growing need for advanced deep learning models capable of integrating them
efficiently. The use of diverse modalities, including histopathology slides,
MRI, and genetic data, offers unprecedented opportunities to improve prognosis
prediction and to unveil new treatment pathways. Contrastive learning, widely
used for deriving representations from paired data in multimodal tasks, assumes
that different views contain the same task-relevant information and leverages
only shared information. This assumption becomes restrictive when handling
medical data since each modality also harbors specific knowledge relevant to
downstream tasks. We introduce DRIM, a new multimodal method for capturing
these shared and unique representations, despite data sparsity. More
specifically, given a set of modalities, we aim to encode a representation for
each one that can be divided into two components: one encapsulating
patient-related information common across modalities and the other,
encapsulating modality-specific details. This is achieved by increasing the
shared information among different patient modalities while minimizing the
overlap between shared and unique components within each modality. Our method
outperforms state-of-the-art algorithms on glioma patients survival prediction
tasks, while being robust to missing modalities. To promote reproducibility,
the code is made publicly available at https://github.com/Lucas-rbnt/DRIM

摘要：真實生活中的醫療數據通常是多模態且不完整的，這使得對能夠有效整合它們的高級深度學習模型的需求不斷增長。使用多種形式，包括組織病理切片、核磁共振和遺傳數據，提供了前所未有的機會來改進預後預測並揭示新的治療途徑。對比學習廣泛用於從多模態任務中的配對數據中推導出表示，它假設不同的觀點包含相同的與任務相關的信息，並且僅利用共享信息。在處理醫療數據時，這一假設變得具有限制性，因為每種形式也包含與下游任務相關的具體知識。我們介紹了 DRIM，這是一種新的多模態方法，用於捕獲這些共享和唯一的表示，儘管數據稀疏。更具體地說，給定一組形式，我們旨在對每個形式編碼一個表示，該表示可以分為兩個組成部分：一個封裝跨形式的患者相關信息，另一個封裝形式特定的細節。這是通過增加不同患者形式之間的共享信息，同時最大程度地減少每個形式中共享和唯一組成部分之間的重疊來實現的。我們的算法在神經膠質瘤患者的生存預測任務中優於最先進的算法，同時對缺失的形式具有魯棒性。為了促進可重複性，代碼已在 https://github.com/Lucas-rbnt/DRIM 上公開。

##### **Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia**
2409.17054v1 by Azmul Asmar Irfan, Nur Ahmad Khatim, Mansur M. Arief

One of the key issues contributing to inefficiency in Puskesmas is the
time-consuming nature of doctor-patient interactions. Doctors need to conduct
thorough consultations, which include diagnosing the patient's condition,
providing treatment advice, and transcribing detailed notes into medical
records. In regions with diverse linguistic backgrounds, doctors often have to
ask clarifying questions, further prolonging the process. While diagnosing is
essential, transcription and summarization can often be automated using AI to
improve time efficiency and help doctors enhance care quality and enable early
diagnosis and intervention. This paper proposes a solution using a localized
large language model (LLM) to transcribe, translate, and summarize
doctor-patient conversations. We utilize the Whisper model for transcription
and GPT-3 to summarize them into the ePuskemas medical records format. This
system is implemented as an add-on to an existing web browser extension,
allowing doctors to fill out patient forms while talking. By leveraging this
solution for real-time transcription, translation, and summarization, doctors
can improve the turnaround time for patient care while enhancing the quality of
records, which become more detailed and insightful for future visits. This
innovation addresses challenges like overcrowded facilities and the
administrative burden on healthcare providers in Indonesia. We believe this
solution will help doctors save time, provide better care, and produce more
accurate medical records, representing a significant step toward modernizing
healthcare and ensuring patients receive timely, high-quality care, even in
resource-constrained settings.

摘要：<paragraph>導致 Puskesmas 效率低下的關鍵問題之一是，醫生和病人互動耗時。醫生需要進行徹底的諮詢，包括診斷病人的病情、提供治療建議，以及將詳細的筆記記錄在醫療記錄中。在語言背景多元的地區，醫生經常必須提出澄清問題，進一步延長流程。雖然診斷至關重要，但使用 AI 進行轉錄和摘要通常可以自動化，以提高時間效率，並幫助醫生提高護理品質，並實現早期診斷和干預。本文提出了一個使用本地化大型語言模型 (LLM) 來轉錄、翻譯和摘要醫生與病人對話的解決方案。我們利用 Whisper 模型進行轉錄，並使用 GPT-3 將其摘要成 ePuskemas 醫療記錄格式。此系統實作為現有網路瀏覽器擴充功能的附加元件，讓醫生可以在交談時填寫病患表單。透過利用此解決方案進行即時轉錄、翻譯和摘要，醫生可以改善病患照護的周轉時間，同時提升記錄品質，讓記錄變得更詳細且更有洞見，以利於後續就診。此創新解決了像醫療機構人滿為患和印尼醫療保健提供者的行政負擔等挑戰。我們相信此解決方案將幫助醫生節省時間、提供更好的照護，並產生更準確的醫療記錄，代表著現代化醫療保健並確保病人即使在資源受限的環境中也能獲得及時、高品質的照護的重要一步。</paragraph>

##### **ControlCity: A Multimodal Diffusion Model Based Approach for Accurate Geospatial Data Generation and Urban Morphology Analysis**
2409.17049v1 by Fangshuo Zhou, Huaxia Li, Rui Hu, Sensen Wu, Hailin Feng, Zhenhong Du, Liuchang Xu

Volunteer Geographic Information (VGI), with its rich variety, large volume,
rapid updates, and diverse sources, has become a critical source of geospatial
data. However, VGI data from platforms like OSM exhibit significant quality
heterogeneity across different data types, particularly with urban building
data. To address this, we propose a multi-source geographic data transformation
solution, utilizing accessible and complete VGI data to assist in generating
urban building footprint data. We also employ a multimodal data generation
framework to improve accuracy. First, we introduce a pipeline for constructing
an 'image-text-metadata-building footprint' dataset, primarily based on road
network data and supplemented by other multimodal data. We then present
ControlCity, a geographic data transformation method based on a multimodal
diffusion model. This method first uses a pre-trained text-to-image model to
align text, metadata, and building footprint data. An improved ControlNet
further integrates road network and land-use imagery, producing refined
building footprint data. Experiments across 22 global cities demonstrate that
ControlCity successfully simulates real urban building patterns, achieving
state-of-the-art performance. Specifically, our method achieves an average FID
score of 50.94, reducing error by 71.01% compared to leading methods, and a
MIoU score of 0.36, an improvement of 38.46%. Additionally, our model excels in
tasks like urban morphology transfer, zero-shot city generation, and spatial
data completeness assessment. In the zero-shot city task, our method accurately
predicts and generates similar urban structures, demonstrating strong
generalization. This study confirms the effectiveness of our approach in
generating urban building footprint data and capturing complex city
characteristics.

摘要：<paragraph>志工地理資訊 (VGI) 擁有豐富多樣性、龐大資料量、快速更新和多元來源，已成為地理空間資料的重要來源。然而，來自 OSM 等平台的 VGI 資料在不同資料類型中展現出顯著的品質異質性，特別是與都市建築資料相關。為了解決這個問題，我們提出一個多來源地理資料轉換解決方案，利用可取得且完整的 VGI 資料來協助產生都市建築足跡資料。我們也採用多模態資料產生架構來提升準確度。首先，我們導入一個用於建構「影像-文字-元資料-建築足跡」資料集的管道，主要基於道路網路資料，並由其他多模態資料補充。然後，我們提出 ControlCity，一種基於多模態擴散模型的地理資料轉換方法。此方法首先使用預先訓練好的文字轉影像模型來比對文字、元資料和建築足跡資料。改良後的 ControlNet 進一步整合道路網路和土地使用影像，產生精緻化的建築足跡資料。在 22 個全球城市進行的實驗證明，ControlCity 成功模擬了真實的都市建築模式，達到最先進的效能。具體來說，我們的模型平均 FID 分數為 50.94，與領先方法相比減少了 71.01% 的誤差，而 MIoU 分數為 0.36，提升了 38.46%。此外，我們的模型在都市形態轉換、零次學習城市產生和空間資料完整性評估等任務中表現出色。在零次學習城市任務中，我們的模型準確預測並產生類似的都市結構，展現出強大的泛化能力。這項研究證實了我們在產生都市建築足跡資料和擷取複雜城市特徵方面的成效。</paragraph>

##### **GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design**
2409.17045v1 by Phillip Mueller, Sebastian Mueller, Lars Mikelsons

We provide a dataset for enabling Deep Generative Models (DGMs) in
engineering design and propose methods to automate data labeling by utilizing
large-scale foundation models. GeoBiked is curated to contain 4 355 bicycle
images, annotated with structural and technical features and is used to
investigate two automated labeling techniques: The utilization of consolidated
latent features (Hyperfeatures) from image-generation models to detect
geometric correspondences (e.g. the position of the wheel center) in structural
images and the generation of diverse text descriptions for structural images.
GPT-4o, a vision-language-model (VLM), is instructed to analyze images and
produce diverse descriptions aligned with the system-prompt. By representing
technical images as Diffusion-Hyperfeatures, drawing geometric correspondences
between them is possible. The detection accuracy of geometric points in unseen
samples is improved by presenting multiple annotated source images. GPT-4o has
sufficient capabilities to generate accurate descriptions of technical images.
Grounding the generation only on images leads to diverse descriptions but
causes hallucinations, while grounding it on categorical labels restricts the
diversity. Using both as input balances creativity and accuracy. Successfully
using Hyperfeatures for geometric correspondence suggests that this approach
can be used for general point-detection and annotation tasks in technical
images. Labeling such images with text descriptions using VLMs is possible, but
dependent on the models detection capabilities, careful prompt-engineering and
the selection of input information. Applying foundation models in engineering
design is largely unexplored. We aim to bridge this gap with a dataset to
explore training, finetuning and conditioning DGMs in this field and suggesting
approaches to bootstrap foundation models to process technical images.

摘要：<paragraph>我們提供了一個資料集，用於在工程設計中啟用深度生成模型 (DGM)，並提出透過利用大規模基礎模型自動化資料標籤的方法。GeoBiked 經過策展，包含 4,355 張自行車影像，並附有結構和技術特徵註解，且用於調查兩種自動化標籤技術：利用影像生成模型的整合潛在特徵（超特徵）來偵測結構影像中的幾何對應（例如車輪中心的位子），以及為結構影像產生多樣化的文字描述。GPT-4o 是一個視覺語言模型 (VLM)，指示要分析影像並產生與系統提示一致的多樣化描述。透過將技術影像表示為擴散超特徵，就可以繪製它們之間的幾何對應。透過呈現多個帶註解的來源影像，可以改善在未見樣本中幾何點的偵測準確度。GPT-4o 具有足夠的能力來產生技術影像的準確描述。僅根據影像進行基礎會產生多樣化的描述，但會產生幻覺，而根據分類標籤進行基礎則會限制多樣性。將兩者都用作輸入，可以平衡創造力和準確性。成功地將超特徵用於幾何對應，表示這種方法可用於技術影像中的一般點偵測和註解任務。使用 VLM 標籤此類影像的文字描述是可行的，但取決於模型的偵測能力、仔細的提示工程和輸入資訊的選擇。在工程設計中應用基礎模型在很大程度上尚未探索。我們旨在透過一個資料集來填補這個空白，以探索在這個領域訓練、微調和調整 DGM，並建議引導基礎模型處理技術影像的方法。</paragraph>

##### **How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does Not**
2409.17044v1 by Francesco Verdini, Pierfrancesco Melucci, Stefano Perna, Francesco Cariaggi, Marco Gaido, Sara Papi, Szymon Mazurek, Marek Kasztelnik, Luisa Bentivogli, Sébastien Bratières, Paolo Merialdo, Simone Scardapane

The remarkable performance achieved by Large Language Models (LLM) has driven
research efforts to leverage them for a wide range of tasks and input
modalities. In speech-to-text (S2T) tasks, the emerging solution consists of
projecting the output of the encoder of a Speech Foundational Model (SFM) into
the LLM embedding space through an adapter module. However, no work has yet
investigated how much the downstream-task performance depends on each component
(SFM, adapter, LLM) nor whether the best design of the adapter depends on the
chosen SFM and LLM. To fill this gap, we evaluate the combination of 5 adapter
modules, 2 LLMs (Mistral and Llama), and 2 SFMs (Whisper and SeamlessM4T) on
two widespread S2T tasks, namely Automatic Speech Recognition and Speech
Translation. Our results demonstrate that the SFM plays a pivotal role in
downstream performance, while the adapter choice has moderate impact and
depends on the SFM and LLM.

摘要：大型語言模型 (LLM) 的卓越表現推動了研究工作，以利用它們來執行各種任務和輸入方式。在語音轉文字 (S2T) 任務中，新興的解決方案包括將語音基礎模型 (SFM) 編碼器的輸出通過適配器模組投影到 LLM 嵌入空間。然而，目前尚未有研究探討下游任務的表現有多依賴於每個元件 (SFM、適配器、LLM)，或適配器的最佳設計是否取決於所選的 SFM 和 LLM。為了填補此空白，我們在兩個廣泛的 S2T 任務上評估了 5 個適配器模組、2 個 LLM（Mistral 和 Llama）和 2 個 SFM（Whisper 和 SeamlessM4T）的組合，即自動語音辨識和語音翻譯。我們的結果表明，SFM 在下游表現中扮演著關鍵角色，而適配器的選擇具有中等影響，且取決於 SFM 和 LLM。

##### **Counterfactual Token Generation in Large Language Models**
2409.17027v1 by Ivi Chatzi, Nina Corvelo Benz, Eleni Straitouri, Stratis Tsirtsis, Manuel Gomez-Rodriguez

"Sure, I am happy to generate a story for you: Captain Lyra stood at the helm
of her trusty ship, the Maelstrom's Fury, gazing out at the endless sea. [...]
Lyra's eyes welled up with tears as she realized the bitter truth - she had
sacrificed everything for fleeting riches, and lost the love of her crew, her
family, and herself." Although this story, generated by a large language model,
is captivating, one may wonder -- how would the story have unfolded if the
model had chosen "Captain Maeve" as the protagonist instead? We cannot know.
State-of-the-art large language models are stateless -- they maintain no
internal memory or state. Given a prompt, they generate a sequence of tokens as
an output using an autoregressive process. As a consequence, they cannot reason
about counterfactual alternatives to tokens they have generated in the past. In
this work, our goal is to enhance them with this functionality. To this end, we
develop a causal model of token generation that builds upon the Gumbel-Max
structural causal model. Our model allows any large language model to perform
counterfactual token generation at almost no cost in comparison with vanilla
token generation, it is embarrassingly simple to implement, and it does not
require any fine-tuning nor prompt engineering. We implement our model on Llama
3 8B-instruct and conduct both qualitative and quantitative analyses of
counterfactually generated text. We conclude with a demonstrative application
of counterfactual token generation for bias detection, unveiling interesting
insights about the model of the world constructed by large language models.

摘要：「當然，我很樂意為您產生一個故事：萊拉船長站在她忠實的船隻，暴風之怒號的舵柄上，凝視著無盡的大海。[...]萊拉的雙眼噙滿淚水，她意識到了一個痛苦的真相——她為了稍縱即逝的財富犧牲了一切，失去了船員、家人和自己的愛。」儘管這個由大型語言模型產生的故事引人入勝，但人們可能會好奇——如果該模型選擇「梅芙船長」作為主角，故事會如何展開？我們不得而知。最先進的大型語言模型是無狀態的——它們不維護任何內部記憶或狀態。給定一個提示，它們會使用自迴歸過程生成一個序列的標記作為輸出。因此，它們無法對過去生成的標記的反事實替代方案進行推理。在這項工作中，我們的目標是增強它們的這項功能。為此，我們開發了一個因果標記生成模型，該模型建立在 Gumbel-Max 結構因果模型之上。我們的模型允許任何大型語言模型以幾乎沒有成本（與香草標記生成相比）執行反事實標記生成，其實現非常簡單，並且不需要任何微調或提示工程。我們在 Llama 3 8B-instruct 上實現了我們的模型，並對反事實生成的文本進行了定性和定量分析。我們以反事實標記生成的一個示範應用來檢測偏差作為結論，揭示了大型語言模型構建的世界模型的有趣見解。

##### **AI-Driven Risk-Aware Scheduling for Active Debris Removal Missions**
2409.17012v1 by Antoine Poupon, Hugo de Rohan Willner, Pierre Nikitits, Adam Abdin

The proliferation of debris in Low Earth Orbit (LEO) represents a significant
threat to space sustainability and spacecraft safety. Active Debris Removal
(ADR) has emerged as a promising approach to address this issue, utilising
Orbital Transfer Vehicles (OTVs) to facilitate debris deorbiting, thereby
reducing future collision risks. However, ADR missions are substantially
complex, necessitating accurate planning to make the missions economically
viable and technically effective. Moreover, these servicing missions require a
high level of autonomous capability to plan under evolving orbital conditions
and changing mission requirements. In this paper, an autonomous
decision-planning model based on Deep Reinforcement Learning (DRL) is developed
to train an OTV to plan optimal debris removal sequencing. It is shown that
using the proposed framework, the agent can find optimal mission plans and
learn to update the planning autonomously to include risk handling of debris
with high collision risk.

摘要：低地球軌道 (LEO) 中的碎片激增對太空永續性和太空船安全構成重大威脅。主動碎片移除 (ADR) 已成為解決此問題的一種有前景的方法，利用軌道轉移載具 (OTV) 促進碎片脫軌，從而降低未來的碰撞風險。然而，ADR 任務相當複雜，需要準確的規劃才能使任務在經濟上可行且在技術上有效。此外，這些維修任務需要高度的自主能力，以便在不斷變化的軌道條件和變化的任務需求下進行規劃。在本文中，開發了一個基於深度強化學習 (DRL) 的自主決策規劃模型，用於訓練 OTV 規劃最佳的碎片移除順序。結果表明，使用所提出的框架，代理可以找到最佳的任務計畫，並學會自主更新計畫，以納入對高碰撞風險碎片的風險處理。

##### **LLM-CARD: Towards a Description and Landscape of Large Language Models**
2409.17011v1 by Shengwei Tian, Lifeng Han, Erick Mendez Guzman, Goran Nenadic

With the rapid growth of the Natural Language Processing (NLP) field, a vast
variety of Large Language Models (LLMs) continue to emerge for diverse NLP
tasks. As an increasing number of papers are presented, researchers and
developers face the challenge of information overload. Thus, it is particularly
important to develop a system that can automatically extract and organise key
information about LLMs from academic papers (\textbf{LLM model card}). This
work is to develop such a pioneer system by using Named Entity Recognition
(\textbf{NER}) and Relation Extraction (\textbf{RE}) methods that automatically
extract key information about large language models from the papers, helping
researchers to efficiently access information about LLMs. These features
include model \textit{licence}, model \textit{name}, and model
\textit{application}. With these features, we can form a model card for each
paper. \textbf{Data-contribution} wise, 106 academic papers were processed by
defining three dictionaries - LLMs name, licence, and application. 11,051
sentences were extracted through dictionary lookup, and the dataset was
constructed through manual review of the final selection of 129 sentences that
have a link between the name and the licence, and 106 sentences that have a
link between the model name and the application.

摘要：隨著自然語言處理 (NLP) 領域的快速發展，各種大型語言模型 (LLM) 持續湧現，以執行多元的 NLP 任務。隨著發表論文數量日增，研究人員和開發人員面臨資訊過載的挑戰。因此，開發一個系統，能自動從學術論文中擷取和組織有關 LLM 的關鍵資訊（**LLM 模型卡**）特別重要。這項工作是要透過使用命名實體辨識（**NER**）和關係擷取（**RE**）方法，開發出這樣的先驅系統，從論文中自動擷取有關大型語言模型的關鍵資訊，協助研究人員有效存取有關 LLM 的資訊。這些功能包括模型**授權**、模型**名稱**和模型**應用**。有了這些功能，我們可以為每篇論文建立模型卡。**資料貢獻**方面，透過定義三個字典（LLM 名稱、授權和應用），處理了 106 篇學術論文。透過字典查詢擷取了 11,051 個句子，並透過手動檢閱最後選出的 129 個句子（名稱與授權之間有連結）和 106 個句子（模型名稱與應用之間有連結）來建構資料集。

##### **Models Can and Should Embrace the Communicative Nature of Human-Generated Math**
2409.17005v1 by Sasha Boguraev, Ben Lipkin, Leonie Weissweiler, Kyle Mahowald

Math is constructed by people for people: just as natural language corpora
reflect not just propositions but the communicative goals of language users,
the math data that models are trained on reflects not just idealized
mathematical entities but rich communicative intentions. While there are
important advantages to treating math in a purely symbolic manner, we here
hypothesize that there are benefits to treating math as situated linguistic
communication and that language models are well suited for this goal, in ways
that are not fully appreciated. We illustrate these points with two case
studies. First, we ran an experiment in which we found that language models
interpret the equals sign in a humanlike way -- generating systematically
different word problems for the same underlying equation arranged in different
ways. Second, we found that language models prefer proofs to be ordered in
naturalistic ways, even though other orders would be logically equivalent. We
advocate for AI systems that learn from and represent the communicative
intentions latent in human-generated math.

摘要：數學是由人為人建構的：就像自然語言語料庫不僅反映命題，也反映語言使用者的溝通目標，模型訓練的數學資料不僅反映理想化的數學實體，也反映豐富的溝通意圖。雖然以純粹的符號方式處理數學具有重要的優點，但我們在此假設將數學視為情境化的語言溝通是有好處的，並且語言模型非常適合這個目標，這點尚未被充分理解。我們用兩個案例研究來說明這些觀點。首先，我們進行了一個實驗，發現語言模型以類似人類的方式詮釋等號，針對以不同方式排列的相同基礎方程式，系統性地產生不同的文字題。其次，我們發現語言模型偏好以自然主義的方式排列證明，即使其他順序在邏輯上是等價的。我們提倡學習並表示人類產生的數學中潛在的溝通意圖的人工智慧系統。

##### **INT-FlashAttention: Enabling Flash Attention for INT8 Quantization**
2409.16997v2 by Shimao Chen, Zirui Liu, Zhiying Wu, Ce Zheng, Peizhuang Cong, Zihan Jiang, Yuhan Wu, Lei Su, Tong Yang

As the foundation of large language models (LLMs), self-attention module
faces the challenge of quadratic time and memory complexity with respect to
sequence length. FlashAttention accelerates attention computation and reduces
its memory usage by leveraging the GPU memory hierarchy. A promising research
direction is to integrate FlashAttention with quantization methods. This paper
introduces INT-FlashAttention, the first INT8 quantization architecture
compatible with the forward workflow of FlashAttention, which significantly
improves the inference speed of FlashAttention on Ampere GPUs. We implement our
INT-FlashAttention prototype with fully INT8 activations and general
matrix-multiplication (GEMM) kernels, making it the first attention operator
with fully INT8 input. As a general token-level post-training quantization
framework, INT-FlashAttention is also compatible with other data formats like
INT4, etc. Experimental results show INT-FlashAttention achieves 72% faster
inference speed and 82% smaller quantization error compared to standard
FlashAttention with FP16 and FP8 data format.

摘要：作為大型語言模型 (LLM) 的基礎，自注意力模組在序列長度方面面臨二次時間和記憶體複雜度的挑戰。FlashAttention 透過利用 GPU 記憶體階層來加速注意力計算並減少其記憶體使用量。一個有前途的研究方向是將 FlashAttention 與量化方法整合在一起。本文介紹 INT-FlashAttention，這是第一個與 FlashAttention 的前向工作流程相容的 INT8 量化架構，它顯著提升了 FlashAttention 在 Ampere GPU 上的推論速度。我們實作了具有完整 INT8 啟用和一般矩陣乘法 (GEMM) 核心之 INT-FlashAttention 原型，使其成為第一個具有完整 INT8 輸入的注意力運算子。作為一個通用的標記層級後訓練量化架構，INT-FlashAttention 也與其他資料格式相容，例如 INT4 等。實驗結果顯示，與具有 FP16 和 FP8 資料格式的標準 FlashAttention 相比，INT-FlashAttention 的推論速度快了 72%，量化誤差小了 82%。

##### **Harnessing Diversity for Important Data Selection in Pretraining Large Language Models**
2409.16986v1 by Chi Zhang, Huaping Zhong, Kuan Zhang, Chengliang Chai, Rui Wang, Xinlin Zhuang, Tianyi Bai, Jiantao Qiu, Lei Cao, Ye Yuan, Guoren Wang, Conghui He

Data selection is of great significance in pre-training large language
models, given the variation in quality within the large-scale available
training corpora. To achieve this, researchers are currently investigating the
use of data influence to measure the importance of data instances, $i.e.,$ a
high influence score indicates that incorporating this instance to the training
set is likely to enhance the model performance. Consequently, they select the
top-$k$ instances with the highest scores. However, this approach has several
limitations. (1) Computing the influence of all available data is
time-consuming. (2) The selected data instances are not diverse enough, which
may hinder the pre-trained model's ability to generalize effectively to various
downstream tasks. In this paper, we introduce \texttt{Quad}, a data selection
approach that considers both quality and diversity by using data influence to
achieve state-of-the-art pre-training results. In particular, noting that
attention layers capture extensive semantic details, we have adapted the
accelerated $iHVP$ computation methods for attention layers, enhancing our
ability to evaluate the influence of data, $i.e.,$ its quality. For the
diversity, \texttt{Quad} clusters the dataset into similar data instances
within each cluster and diverse instances across different clusters. For each
cluster, if we opt to select data from it, we take some samples to evaluate the
influence to prevent processing all instances. To determine which clusters to
select, we utilize the classic Multi-Armed Bandit method, treating each cluster
as an arm. This approach favors clusters with highly influential instances
(ensuring high quality) or clusters that have been selected less frequently
(ensuring diversity), thereby well balancing between quality and diversity.

摘要：<paragraph>在預訓練大型語言模型時，由於大型可用訓練語料庫中的品質差異，資料選擇非常重要。為了達成此目的，研究人員目前正在研究使用資料影響力來衡量資料實例的重要程度，$i.e.,$ 高影響力分數表示將此實例納入訓練集可能會提升模型效能。因此，他們會選出分數最高的前 $k$ 個實例。然而，此方法有幾個限制。(1) 計算所有可用資料的影響力很耗時。(2) 選出的資料實例不夠多元，這可能會妨礙預訓練模型有效地對各種下游任務進行概化。在本文中，我們介紹了 \texttt{Quad}，這是一種資料選擇方法，透過使用資料影響力來兼顧品質和多元性，以達成最先進的預訓練結果。特別要注意的是，注意力層會擷取廣泛的語義細節，我們已針對注意力層調整加速的 $iHVP$ 計算方法，增強我們評估資料影響力（即其品質）的能力。對於多元性，\texttt{Quad} 將資料集分群為每個群集內部相似的資料實例，以及不同群集之間不同的實例。對於每個群集，如果我們選擇從中選取資料，我們會取得一些樣本來評估影響力，以避免處理所有實例。為了決定要選取哪些群集，我們利用經典的多重機率賭徒法，將每個群集視為一個機率。此方法偏好具有高影響力實例的群集（確保高品質）或較少被選取的群集（確保多元性），從而很好地平衡品質和多元性。</paragraph>

##### **AXCEL: Automated eXplainable Consistency Evaluation using LLMs**
2409.16984v1 by P Aditya Sreekar, Sahil Verma, Suransh Chopra, Sarik Ghazarian, Abhishek Persad, Narayanan Sadagopan

Large Language Models (LLMs) are widely used in both industry and academia
for various tasks, yet evaluating the consistency of generated text responses
continues to be a challenge. Traditional metrics like ROUGE and BLEU show a
weak correlation with human judgment. More sophisticated metrics using Natural
Language Inference (NLI) have shown improved correlations but are complex to
implement, require domain-specific training due to poor cross-domain
generalization, and lack explainability. More recently, prompt-based metrics
using LLMs as evaluators have emerged; while they are easier to implement, they
still lack explainability and depend on task-specific prompts, which limits
their generalizability. This work introduces Automated eXplainable Consistency
Evaluation using LLMs (AXCEL), a prompt-based consistency metric which offers
explanations for the consistency scores by providing detailed reasoning and
pinpointing inconsistent text spans. AXCEL is also a generalizable metric which
can be adopted to multiple tasks without changing the prompt. AXCEL outperforms
both non-prompt and prompt-based state-of-the-art (SOTA) metrics in detecting
inconsistencies across summarization by 8.7%, free text generation by 6.2%, and
data-to-text conversion tasks by 29.4%. We also evaluate the influence of
underlying LLMs on prompt based metric performance and recalibrate the SOTA
prompt-based metrics with the latest LLMs for fair comparison. Further, we show
that AXCEL demonstrates strong performance using open source LLMs.

摘要：大型語言模型 (LLM) 廣泛用於產業和學術界
執行各種任務，然而評估所產生文字回應的一致性
仍然是一項挑戰。傳統指標，例如 ROUGE 和 BLEU，顯示出
與人類判斷的相關性較弱。使用自然語言推論 (NLI) 的更精密的指標顯示出改善的相關性，但實作複雜，由於跨領域概化性差，需要特定領域的訓練，並且缺乏可解釋性。最近，使用 LLM 作為評估器的提示式指標已經出現；雖然它們更容易實作，但它們仍然缺乏可解釋性，並且依賴於特定任務的提示，這限制了它們的概化性。這項工作引入了使用 LLM 的自動化可解釋一致性評估 (AXCEL)，這是一個基於提示的一致性指標，它透過提供詳細的推理和精確定位不一致的文字範圍，為一致性評分提供解釋。AXCEL 也是一個可概化的指標，可以在不更改提示的情況下採用於多項任務。AXCEL 在檢測摘要的不一致性方面優於非提示式和提示式最先進 (SOTA) 指標 8.7%，自由文字產生 6.2%，以及資料到文字轉換任務 29.4%。我們也評估了底層 LLM 對基於提示的指標效能的影響，並使用最新的 LLM 重新校準 SOTA 基於提示的指標以進行公平比較。此外，我們展示了 AXCEL 使用開源 LLM 具有強大的效能。

##### **Decoding Large-Language Models: A Systematic Overview of Socio-Technical Impacts, Constraints, and Emerging Questions**
2409.16974v1 by Zeyneb N. Kaya, Souvick Ghosh

There have been rapid advancements in the capabilities of large language
models (LLMs) in recent years, greatly revolutionizing the field of natural
language processing (NLP) and artificial intelligence (AI) to understand and
interact with human language. Therefore, in this work, we conduct a systematic
investigation of the literature to identify the prominent themes and directions
of LLM developments, impacts, and limitations. Our findings illustrate the
aims, methodologies, limitations, and future directions of LLM research. It
includes responsible development considerations, algorithmic improvements,
ethical challenges, and societal implications of LLM development. Overall, this
paper provides a rigorous and comprehensive overview of current research in LLM
and identifies potential directions for future development. The article
highlights the application areas that could have a positive impact on society
along with the ethical considerations.

摘要：近年來，大型語言模型 (LLM) 的能力突飛猛進，極大地革新了自然語言處理 (NLP) 和人工智慧 (AI) 理解和互動人類語言的領域。因此，在本文中，我們對文獻進行系統性的探討，以找出 LLM 發展、影響和限制的顯著主題和方向。我們的研究結果說明了 LLM 研究的目的、方法、限制和未來方向。它包括負責任的開發考量、演算法的改進、倫理挑戰和 LLM 發展的社會影響。總體而言，本文提供了 LLM 當前研究的嚴謹且全面的概述，並找出未來發展的潛在方向。本文重點介紹了可能對社會產生正面影響的應用領域，以及倫理考量。

##### **Adaptive Self-Supervised Learning Strategies for Dynamic On-Device LLM Personalization**
2409.16973v1 by Rafael Mendoza, Isabella Cruz, Richard Liu, Aarav Deshmukh, David Williams, Jesscia Peng, Rohan Iyer

Large language models (LLMs) have revolutionized how we interact with
technology, but their personalization to individual user preferences remains a
significant challenge, particularly in on-device applications. Traditional
methods often depend heavily on labeled datasets and can be resource-intensive.
To address these issues, we present Adaptive Self-Supervised Learning
Strategies (ASLS), which utilizes self-supervised learning techniques to
personalize LLMs dynamically. The framework comprises a user profiling layer
for collecting interaction data and a neural adaptation layer for real-time
model fine-tuning. This innovative approach enables continuous learning from
user feedback, allowing the model to generate responses that align closely with
user-specific contexts. The adaptive mechanisms of ASLS minimize computational
demands and enhance personalization efficiency. Experimental results across
various user scenarios illustrate the superior performance of ASLS in boosting
user engagement and satisfaction, highlighting its potential to redefine LLMs
as highly responsive and context-aware systems on-device.

摘要：大型語言模型 (LLM) 徹底改變了我們與科技互動的方式，但它們的個人化以適應個別使用者的偏好仍然是一項重大的挑戰，特別是在裝置應用程式中。傳統方法通常高度依賴標籤資料集，且可能耗費大量資源。為了解決這些問題，我們提出自適應自我監督學習策略 (ASLS)，它利用自我監督學習技術來動態地個人化 LLM。該架構包含一個用於收集互動資料的使用者設定檔層，以及一個用於即時模型微調的神經適應層。這種創新的方法能從使用者的回饋中持續學習，讓模型能夠產生與使用者特定脈絡緊密結合的回應。ASLS 的自適應機制可將運算需求降到最低，並提升個人化效率。在各種使用者情境中的實驗結果說明了 ASLS 在提升使用者參與度和滿意度方面的卓越效能，突顯了它在將 LLM 重新定義為高度回應且具備脈絡感知能力的裝置系統方面的潛力。

##### **Weighted Cross-entropy for Low-Resource Languages in Multilingual Speech Recognition**
2409.16954v1 by Andrés Piñeiro-Martín, Carmen García-Mateo, Laura Docío-Fernández, María del Carmen López-Pérez, Georg Rehm

This paper addresses the challenge of integrating low-resource languages into
multilingual automatic speech recognition (ASR) systems. We introduce a novel
application of weighted cross-entropy, typically used for unbalanced datasets,
to facilitate the integration of low-resource languages into pre-trained
multilingual ASR models within the context of continual multilingual learning.
We fine-tune the Whisper multilingual ASR model on five high-resource languages
and one low-resource language, employing language-weighted dynamic
cross-entropy and data augmentation. The results show a remarkable 6.69% word
error rate (WER) reduction for the low-resource language compared to the
fine-tuned model without applying our approach, and a 48.86% WER reduction
compared to the original Whisper model. In addition, our approach yields an
average WER reduction of 3.29% across the six languages, showing no degradation
for the high-resource languages.

摘要：本文探討了將低資源語言整合至多語言自動語音辨識 (ASR) 系統的挑戰。我們引進了加權交叉熵的新應用，通常用於不平衡的資料集，以促進在持續多語言學習的脈絡中，將低資源語言整合至預先訓練的多語言 ASR 模型中。我們微調了 Whisper 多語言 ASR 模型，使用五種高資源語言和一種低資源語言，採用語言加權動態交叉熵和資料擴充。結果顯示，與未套用我們方法的微調模型相比，低資源語言的字元錯誤率 (WER) 降低了 6.69%，與原始 Whisper 模型相比，WER 降低了 48.86%。此外，我們的做法對六種語言的平均 WER 降低了 3.29%，顯示對高資源語言沒有造成影響。

##### **Dynamic Obstacle Avoidance through Uncertainty-Based Adaptive Planning with Diffusion**
2409.16950v1 by Vineet Punyamoorty, Pascal Jutras-Dubé, Ruqi Zhang, Vaneet Aggarwal, Damon Conover, Aniket Bera

By framing reinforcement learning as a sequence modeling problem, recent work
has enabled the use of generative models, such as diffusion models, for
planning. While these models are effective in predicting long-horizon state
trajectories in deterministic environments, they face challenges in dynamic
settings with moving obstacles. Effective collision avoidance demands
continuous monitoring and adaptive decision-making. While replanning at every
timestep could ensure safety, it introduces substantial computational overhead
due to the repetitive prediction of overlapping state sequences -- a process
that is particularly costly with diffusion models, known for their intensive
iterative sampling procedure. We propose an adaptive generative planning
approach that dynamically adjusts replanning frequency based on the uncertainty
of action predictions. Our method minimizes the need for frequent,
computationally expensive, and redundant replanning while maintaining robust
collision avoidance performance. In experiments, we obtain a 13.5% increase in
the mean trajectory length and a 12.7% increase in mean reward over
long-horizon planning, indicating a reduction in collision rates and an
improved ability to navigate the environment safely.

摘要：藉由將強化學習建構為序列建模問題，近期研究已能使用生成模型，例如擴散模型，進行規劃。儘管這些模型有效預測確定性環境中的長時程狀態軌跡，但在具有移動障礙物的動態設定中，它們面臨挑戰。有效的碰撞避免需要持續監控和適應性決策制定。儘管在每個時間步長重新規劃可以確保安全性，但由於重複預測重疊的狀態序列，因此會產生大量的運算負擔，而這種程序對於以其密集迭代採樣程序而聞名的擴散模型來說特別昂貴。我們提出了一種適應性生成規劃方法，該方法根據動作預測的不確定性動態調整重新規劃頻率。我們的模型將頻繁、運算成本高且重複的重新規劃需求降至最低，同時維持穩健的碰撞避免效能。在實驗中，我們在長期規劃中獲得平均軌跡長度增加 13.5% 和平均回報增加 12.7%，表示碰撞率降低，以及在環境中安全導航的能力提升。

##### **Go-SLAM: Grounded Object Segmentation and Localization with Gaussian Splatting SLAM**
2409.16944v1 by Phu Pham, Dipam Patel, Damon Conover, Aniket Bera

We introduce Go-SLAM, a novel framework that utilizes 3D Gaussian Splatting
SLAM to reconstruct dynamic environments while embedding object-level
information within the scene representations. This framework employs advanced
object segmentation techniques, assigning a unique identifier to each Gaussian
splat that corresponds to the object it represents. Consequently, our system
facilitates open-vocabulary querying, allowing users to locate objects using
natural language descriptions. Furthermore, the framework features an optimal
path generation module that calculates efficient navigation paths for robots
toward queried objects, considering obstacles and environmental uncertainties.
Comprehensive evaluations in various scene settings demonstrate the
effectiveness of our approach in delivering high-fidelity scene
reconstructions, precise object segmentation, flexible object querying, and
efficient robot path planning. This work represents an additional step forward
in bridging the gap between 3D scene reconstruction, semantic object
understanding, and real-time environment interactions.

摘要：我們介紹 Go-SLAM，一個利用 3D 高斯潑濺 SLAM 重建動態環境，同時將物件層級資訊嵌入場景表示中的新穎架構。此架構採用進階物件分割技術，為每個高斯潑濺分配一個獨特識別碼，對應於它所代表的物件。因此，我們的系統促進開放式詞彙查詢，讓使用者能使用自然語言描述來定位物件。此外，此架構具備最佳路徑產生模組，可計算機器人前往查詢物件的有效導航路徑，考量障礙物和環境不確定性。在各種場景設定中的全面評估證明了我們方法在提供高保真場景重建、精確物件分割、彈性物件查詢和有效機器人路徑規劃方面的效能。這項工作代表了在 3D 場景重建、語意物件理解和即時環境互動之間搭起橋樑的額外進展。

##### **Generative Object Insertion in Gaussian Splatting with a Multi-View Diffusion Model**
2409.16938v1 by Hongliang Zhong, Can Wang, Jingbo Zhang, Jing Liao

Generating and inserting new objects into 3D content is a compelling approach
for achieving versatile scene recreation. Existing methods, which rely on SDS
optimization or single-view inpainting, often struggle to produce high-quality
results. To address this, we propose a novel method for object insertion in 3D
content represented by Gaussian Splatting. Our approach introduces a multi-view
diffusion model, dubbed MVInpainter, which is built upon a pre-trained stable
video diffusion model to facilitate view-consistent object inpainting. Within
MVInpainter, we incorporate a ControlNet-based conditional injection module to
enable controlled and more predictable multi-view generation. After generating
the multi-view inpainted results, we further propose a mask-aware 3D
reconstruction technique to refine Gaussian Splatting reconstruction from these
sparse inpainted views. By leveraging these fabricate techniques, our approach
yields diverse results, ensures view-consistent and harmonious insertions, and
produces better object quality. Extensive experiments demonstrate that our
approach outperforms existing methods.

摘要：生成和插入新物件到 3D 內容中，是達成多功能場景重現的引人入勝方法。現有方法依賴於 SDS 最佳化或單視點繪製，通常難以產生高品質的結果。為了解決這個問題，我們提出一個創新的方法，用於在由高斯噴繪表示的 3D 內容中插入物件。我們的做法引進一個多視點擴散模型，稱為 MVInpainter，它建構於預先訓練的穩定影片擴散模型之上，以促進視點一致的物件繪製。在 MVInpainter 內，我們整合一個基於 ControlNet 的條件式注入模組，以啟用受控且更可預測的多視點生成。在產生多視點繪製結果後，我們進一步提出一個具備遮罩感知的 3D 重建技術，從這些稀疏繪製視點中，改善高斯噴繪重建。透過利用這些製造技術，我們的做法產生多樣化的結果，確保視點一致且和諧的插入，並產生更好的物件品質。廣泛的實驗證明，我們的做法優於現有方法。

##### **Semi-Supervised Cognitive State Classification from Speech with Multi-View Pseudo-Labeling**
2409.16937v1 by Yuanchao Li, Zixing Zhang, Jing Han, Peter Bell, Catherine Lai

The lack of labeled data is a common challenge in speech classification
tasks, particularly those requiring extensive subjective assessment, such as
cognitive state classification. In this work, we propose a Semi-Supervised
Learning (SSL) framework, introducing a novel multi-view pseudo-labeling method
that leverages both acoustic and linguistic characteristics to select the most
confident data for training the classification model. Acoustically, unlabeled
data are compared to labeled data using the Frechet audio distance, calculated
from embeddings generated by multiple audio encoders. Linguistically, large
language models are prompted to revise automatic speech recognition
transcriptions and predict labels based on our proposed task-specific
knowledge. High-confidence data are identified when pseudo-labels from both
sources align, while mismatches are treated as low-confidence data. A bimodal
classifier is then trained to iteratively label the low-confidence data until a
predefined criterion is met. We evaluate our SSL framework on emotion
recognition and dementia detection tasks. Experimental results demonstrate that
our method achieves competitive performance compared to fully supervised
learning using only 30% of the labeled data and significantly outperforms two
selected baselines.

摘要：標籤資料的缺乏是語音分類任務中常見的挑戰，特別是需要廣泛主觀評估的任務，例如認知狀態分類。在這項工作中，我們提出一個半監督式學習 (SSL) 架構，引進一種新穎的多視角偽標籤方法，該方法利用聲學和語言特徵來選擇最可靠的資料以訓練分類模型。在聲學上，使用由多個音訊編碼器產生的嵌入計算的 Frechet 音訊距離，將未標籤資料與標籤資料進行比較。在語言學上，提示大型語言模型修改自動語音辨識轉錄，並根據我們提出的特定任務知識預測標籤。當來自兩個來源的偽標籤對齊時，會識別出高可靠性資料，而錯配則視為低可靠性資料。然後訓練一個雙峰分類器，以反覆標籤低可靠性資料，直到符合預定義的準則。我們在情緒辨識和失智症檢測任務上評估我們的 SSL 架構。實驗結果表明，與僅使用 30% 標籤資料的全監督式學習相比，我們的方法獲得了具有競爭力的效能，並且明顯優於兩個選定的基準。

##### **Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical Documents**
2409.16934v2 by Emanuela Boros, Maud Ehrmann

This paper investigates the presence of OCR-sensitive neurons within the
Transformer architecture and their influence on named entity recognition (NER)
performance on historical documents. By analysing neuron activation patterns in
response to clean and noisy text inputs, we identify and then neutralise
OCR-sensitive neurons to improve model performance. Based on two open access
large language models (Llama2 and Mistral), experiments demonstrate the
existence of OCR-sensitive regions and show improvements in NER performance on
historical newspapers and classical commentaries, highlighting the potential of
targeted neuron modulation to improve models' performance on noisy text.

摘要：本文探討了 Transformer 架構中 OCR 敏感神經元的存在，以及它們對歷史文件中的命名實體辨識 (NER) 效能的影響。透過分析神經元在回應乾淨和有雜訊的文字輸入時的活化模式，我們找出 OCR 敏感神經元，然後將其無效化，以提升模型效能。根據兩個開放取用的大型語言模型 (Llama2 和 Mistral)，實驗證實了 OCR 敏感區域的存在，並顯示了歷史報紙和古典評論中的 NER 效能提升，突顯了目標神經元調變在提升模型對有雜訊文字的效能上的潛力。

##### **Quantum-Classical Sentiment Analysis**
2409.16928v1 by Mario Bifulco, Luca Roversi

In this study, we initially investigate the application of a hybrid
classical-quantum classifier (HCQC) for sentiment analysis, comparing its
performance against the classical CPLEX classifier and the Transformer
architecture. Our findings indicate that while the HCQC underperforms relative
to the Transformer in terms of classification accuracy, but it requires
significantly less time to converge to a reasonably good approximate solution.
This experiment also reveals a critical bottleneck in the HCQC, whose
architecture is partially undisclosed by the D-Wave property. To address this
limitation, we propose a novel algorithm based on the algebraic decomposition
of QUBO models, which enhances the time the quantum processing unit can
allocate to problem-solving tasks.

摘要：在本研究中，我们最初调查了混合经典量子分类器 (HCQC) 在情感分析中的应用，将其性能与经典 CPLEX 分类器和 Transformer 架构进行了比较。我们的研究结果表明，虽然 HCQC 在分类准确性方面不如 Transformer，但它需要花费明显更少的时间来收敛到一个相当好的近似解。此实验还揭示了 HCQC 中的一个关键瓶颈，其架构部分由 D-Wave 属性未公开。为了解决这一限制，我们提出了一种基于 QUBO 模型代数分解的新算法，该算法可以延长量子处理单元分配给问题解决任务的时间。

##### **Cross-lingual Speech Emotion Recognition: Humans vs. Self-Supervised Models**
2409.16920v1 by Zhichen Han, Tianqi Geng, Hui Feng, Jiahong Yuan, Korin Richmond, Yuanchao Li

Utilizing Self-Supervised Learning (SSL) models for Speech Emotion
Recognition (SER) has proven effective, yet limited research has explored
cross-lingual scenarios. This study presents a comparative analysis between
human performance and SSL models, beginning with a layer-wise analysis and an
exploration of parameter-efficient fine-tuning strategies in monolingual,
cross-lingual, and transfer learning contexts. We further compare the SER
ability of models and humans at both utterance- and segment-levels.
Additionally, we investigate the impact of dialect on cross-lingual SER through
human evaluation. Our findings reveal that models, with appropriate knowledge
transfer, can adapt to the target language and achieve performance comparable
to native speakers. We also demonstrate the significant effect of dialect on
SER for individuals without prior linguistic and paralinguistic background.
Moreover, both humans and models exhibit distinct behaviors across different
emotions. These results offer new insights into the cross-lingual SER
capabilities of SSL models, underscoring both their similarities to and
differences from human emotion perception.

摘要：利用自我監督學習 (SSL) 模型進行語音情緒辨識 (SER) 已被證實有效，但對於跨語言情境的探索研究有限。本研究提供人類表現與 SSL 模型之間的比較分析，從逐層分析開始，並探討單語、跨語言和遷移學習情境中的參數有效微調策略。我們進一步比較模型與人類在語句和區段層級的 SER 能力。此外，我們透過人類評估探討方言對跨語言 SER 的影響。我們的發現顯示，具備適當知識轉移的模型可以適應目標語言，並達成與母語人士相當的表現。我們也證實方言對沒有語言學和副語言學背景的個人 SER 有顯著影響。此外，人類和模型在不同情緒中展現出不同的行為。這些結果提供新的見解，了解 SSL 模型的跨語言 SER 能力，強調它們與人類情緒感知的相似性和差異性。

##### **Zero-Shot Detection of LLM-Generated Text using Token Cohesiveness**
2409.16914v1 by Shixuan Ma, Quan Wang

The increasing capability and widespread usage of large language models
(LLMs) highlight the desirability of automatic detection of LLM-generated text.
Zero-shot detectors, due to their training-free nature, have received
considerable attention and notable success. In this paper, we identify a new
feature, token cohesiveness, that is useful for zero-shot detection, and we
demonstrate that LLM-generated text tends to exhibit higher token cohesiveness
than human-written text. Based on this observation, we devise TOCSIN, a generic
dual-channel detection paradigm that uses token cohesiveness as a plug-and-play
module to improve existing zero-shot detectors. To calculate token
cohesiveness, TOCSIN only requires a few rounds of random token deletion and
semantic difference measurement, making it particularly suitable for a
practical black-box setting where the source model used for generation is not
accessible. Extensive experiments with four state-of-the-art base detectors on
various datasets, source models, and evaluation settings demonstrate the
effectiveness and generality of the proposed approach. Code available at:
\url{https://github.com/Shixuan-Ma/TOCSIN}.

摘要：隨著大型語言模型 (LLM) 能力的提升和廣泛使用，自動偵測 LLM 生成的文字的需求也越來越高。零次學習偵測器由於無需訓練，因此備受關注，並取得顯著的成功。在本文中，我們找出了一個新的特徵，即「詞彙凝聚力」，它對於零次學習偵測很有用，並且我們證明了 LLM 生成的文字往往比人類寫的文字展現出更高的詞彙凝聚力。基於這個觀察，我們設計了 TOCSIN，這是一個通用的雙通道偵測範例，它使用詞彙凝聚力作為即插即用的模組，以改善現有的零次學習偵測器。為了計算詞彙凝聚力，TOCSIN 只需要進行幾輪隨機詞彙刪除和語意差異測量，這使得它特別適合在無法取得用於生成的原始模型的實際黑盒設定中使用。在各種資料集、原始模型和評估設定上使用四個最先進的基本偵測器進行的廣泛實驗證明了所提出方法的有效性和普遍性。程式碼可於以下網址取得：\url{https://github.com/Shixuan-Ma/TOCSIN}。

##### **Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing**
2409.16913v1 by Wenhao Liu, Siyu An, Junru Lu, Muling Wu, Tianlong Li, Xiaohua Wang, Xiaoqing Zheng, Di Yin, Xing Sun, Xuanjing Huang

Role-Playing Agents (RPAs) have shown remarkable performance in various
applications, yet they often struggle to recognize and appropriately respond to
hard queries that conflict with their role-play knowledge. To investigate RPAs'
performance when faced with different types of conflicting requests, we develop
an evaluation benchmark that includes contextual knowledge conflicting
requests, parametric knowledge conflicting requests, and non-conflicting
requests to assess RPAs' ability to identify conflicts and refuse to answer
appropriately without over-refusing. Through extensive evaluation, we find that
most RPAs behave significant performance gaps toward different conflict
requests. To elucidate the reasons, we conduct an in-depth representation-level
analysis of RPAs under various conflict scenarios. Our findings reveal the
existence of rejection regions and direct response regions within the model's
forwarding representation, and thus influence the RPA's final response
behavior. Therefore, we introduce a lightweight representation editing approach
that conveniently shifts conflicting requests to the rejection region, thereby
enhancing the model's refusal accuracy. The experimental results validate the
effectiveness of our editing method, improving RPAs' refusal ability of
conflicting requests while maintaining their general role-playing capabilities.

摘要：角色扮演代理（RPA）在各種應用中已展現出卓越的效能，但它們經常難以辨識並適當地回應與其角色扮演知識相衝突的困難查詢。為調查 RPA 在面對不同類型的衝突要求時的效能，我們開發了一個評估基準，其中包括情境知識衝突要求、參數知識衝突要求和非衝突要求，以評估 RPA 辨識衝突並適當地拒絕回答的能力，而不會過度拒絕。透過廣泛的評估，我們發現大多數 RPA 對不同的衝突要求表現出顯著的效能差距。為了闡明原因，我們對 RPA 在各種衝突情境下的表示層級進行深入分析。我們的研究結果揭示了模型轉發表示中拒絕區域和直接回應區域的存在，進而影響 RPA 的最終回應行為。因此，我們引入了一種輕量的表示編輯方法，可便利地將衝突要求轉移到拒絕區域，從而提高模型的拒絕準確度。實驗結果驗證了我們編輯方法的有效性，提升了 RPA 拒絕衝突要求的能力，同時維持其一般角色扮演能力。

##### **Pruning Multilingual Large Language Models for Multilingual Inference**
2409.16911v1 by Hwichan Kim, Jun Suzuki, Tosho Hirasawa, Mamoru Komachi

Multilingual large language models (MLLMs), trained on multilingual balanced
data, demonstrate better zero-shot learning performance in non-English
languages compared to large language models trained on English-dominant data.
However, the disparity in performance between English and non-English languages
remains a challenge yet to be fully addressed. A distinctive characteristic of
MLLMs is their high-quality translation capabilities, indicating an acquired
proficiency in aligning between languages. This study explores how to enhance
the zero-shot performance of MLLMs in non-English languages by leveraging their
alignment capability between English and non-English languages. To achieve
this, we first analyze the behavior of MLLMs when performing translation and
reveal that there are large magnitude features that play a critical role in the
translation process. Inspired by these findings, we retain the weights
associated with operations involving the large magnitude features and prune
other weights to force MLLMs to rely on these features for tasks beyond
translation. We empirically demonstrate that this pruning strategy can enhance
the MLLMs' performance in non-English language.

摘要：多語言大型語言模型 (MLLM) 在多語言平衡資料上訓練，相較於在英語主導資料上訓練的大型語言模型，在非英語語言中展現出更好的零次學習表現。然而，英語與非英語語言之間的表現差異仍是一個尚未完全解決的挑戰。MLLM 的一個顯著特徵是它們的高品質翻譯能力，這表示在語言之間取得一致性的能力。本研究探討如何透過利用 MLLM 在英語和非英語語言之間的一致性能力，來增強 MLLM 在非英語語言中的零次表現。為達成此目標，我們首先分析 MLLM 在執行翻譯時的行為，並揭示出有大量的特徵在翻譯過程中扮演關鍵角色。受到這些發現的啟發，我們保留與涉及大量特徵的操作相關的權重，並剪除其他權重，以強迫 MLLM 在超越翻譯的任務中依賴這些特徵。我們透過實證證明，此剪枝策略可以增強 MLLM 在非英語語言中的表現。

##### **Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering**
2409.16909v1 by Wanqi Yang, Yanda Li, Meng Fang, Ling Chen

Time-Sensitive Question Answering (TSQA) demands the effective utilization of
specific temporal contexts, encompassing multiple time-evolving facts, to
address time-sensitive questions. This necessitates not only the parsing of
temporal information within questions but also the identification and
understanding of time-evolving facts to generate accurate answers. However,
current large language models still have limited sensitivity to temporal
information and their inadequate temporal reasoning capabilities.In this paper,
we propose a novel framework that enhances temporal awareness and reasoning
through Temporal Information-Aware Embedding and Granular Contrastive
Reinforcement Learning. Experimental results on four TSQA datasets demonstrate
that our framework significantly outperforms existing LLMs in TSQA tasks,
marking a step forward in bridging the performance gap between machine and
human temporal understanding and reasoning.

摘要：時敏問題解答 (TSQA) 要求有效利用特定時間背景，包含多重時間演化事實，來回答時敏問題。這不僅需要解析問題中的時間資訊，也需要識別和理解時間演化事實，以產生準確的答案。然而，目前的巨量語言模型對於時間資訊的敏感度仍然有限，且其時間推理能力不足。在本文中，我們提出一個創新的框架，透過時間資訊感知嵌入和細粒對比強化學習來增強時間感知和推理。在四個 TSQA 資料集上的實驗結果顯示，我們的框架在 TSQA 任務中顯著優於現有的 LLM，標誌著在機器和人類時間理解與推理之間的效能差距中向前邁進一步。

##### **Discriminative Anchor Learning for Efficient Multi-view Clustering**
2409.16904v1 by Yalan Qin, Nan Pu, Hanzhou Wu, Nicu Sebe

Multi-view clustering aims to study the complementary information across
views and discover the underlying structure. For solving the relatively high
computational cost for the existing approaches, works based on anchor have been
presented recently. Even with acceptable clustering performance, these methods
tend to map the original representation from multiple views into a fixed shared
graph based on the original dataset. However, most studies ignore the
discriminative property of the learned anchors, which ruin the representation
capability of the built model. Moreover, the complementary information among
anchors across views is neglected to be ensured by simply learning the shared
anchor graph without considering the quality of view-specific anchors. In this
paper, we propose discriminative anchor learning for multi-view clustering
(DALMC) for handling the above issues. We learn discriminative view-specific
feature representations according to the original dataset and build anchors
from different views based on these representations, which increase the quality
of the shared anchor graph. The discriminative feature learning and consensus
anchor graph construction are integrated into a unified framework to improve
each other for realizing the refinement. The optimal anchors from multiple
views and the consensus anchor graph are learned with the orthogonal
constraints. We give an iterative algorithm to deal with the formulated
problem. Extensive experiments on different datasets show the effectiveness and
efficiency of our method compared with other methods.

摘要：多視圖聚類旨在研究跨視圖的互補資訊並發現底層結構。為了解決現有方法相對較高的運算成本，最近提出了基於錨點的運算。即使具有可接受的聚類效能，這些方法傾向於根據原始資料集將來自多個視圖的原始表示映射到一個固定的共享圖形中。然而，大多數研究忽視了學習錨點的判別特性，這會破壞構建模型的表示能力。此外，僅通過學習共享錨點圖形而不考慮特定於視圖的錨點的品質，會忽略跨視圖錨點之間的互補資訊。在本文中，我們提出用於多視圖聚類的判別錨點學習 (DALMC) 來處理上述問題。我們根據原始資料集學習判別的特定於視圖的特徵表示，並根據這些表示從不同的視圖構建錨點，這會提高共享錨點圖形的品質。判別特徵學習和共識錨點圖形構建整合到一個統一的架構中，以相互改進以實現精煉。來自多個視圖的最佳錨點和共識錨點圖形在正交約束下學習。我們給出一個反覆運算演算法來處理公式化的問題。在不同資料集上的大量實驗顯示了我們的方法與其他方法相比的有效性和效率。

##### **Towards Underwater Camouflaged Object Tracking: An Experimental Evaluation of SAM and SAM 2**
2409.16902v1 by Chunhui Zhang, Li Liu, Guanjie Huang, Hao Wen, Xi Zhou, Yanfeng Wang

Over the past decade, significant progress has been made in visual object
tracking, largely due to the availability of large-scale training datasets.
However, existing tracking datasets are primarily focused on open-air
scenarios, which greatly limits the development of object tracking in
underwater environments. To address this issue, we take a step forward by
proposing the first large-scale underwater camouflaged object tracking dataset,
namely UW-COT. Based on the proposed dataset, this paper presents an
experimental evaluation of several advanced visual object tracking methods and
the latest advancements in image and video segmentation. Specifically, we
compare the performance of the Segment Anything Model (SAM) and its updated
version, SAM 2, in challenging underwater environments. Our findings highlight
the improvements in SAM 2 over SAM, demonstrating its enhanced capability to
handle the complexities of underwater camouflaged objects. Compared to current
advanced visual object tracking methods, the latest video segmentation
foundation model SAM 2 also exhibits significant advantages, providing valuable
insights into the development of more effective tracking technologies for
underwater scenarios. The dataset will be accessible at
\color{magenta}{https://github.com/983632847/Awesome-Multimodal-Object-Tracking}.

摘要：在過去十年中，視覺物體追蹤取得了重大的進展，這在很大程度上要歸功於大規模訓練資料集的可用性。
然而，現有的追蹤資料集主要集中在露天場景，這極大地限制了水下環境中物體追蹤的發展。為了解決這個問題，我們提出第一個大規模水下偽裝物體追蹤資料集 UW-COT，向前邁出了一步。基於所提出的資料集，本文對幾種先進的視覺物體追蹤方法和影像和影片分割的最新進展進行了實驗評估。具體來說，我們比較了 Segment Anything Model (SAM) 及其更新版本 SAM 2 在具有挑戰性的水下環境中的效能。我們的研究結果突出了 SAM 2 相較於 SAM 的改進，證明了其增強了處理水下偽裝物體複雜性的能力。與目前先進的視覺物體追蹤方法相比，最新的影片分割基礎模型 SAM 2 也展現出顯著的優勢，為開發更有效的追蹤技術提供了寶貴的見解，以應對水下場景。該資料集可以在
\color{magenta}{https://github.com/983632847/Awesome-Multimodal-Object-Tracking} 取得。

##### **A Roadmap for Embodied and Social Grounding in LLMs**
2409.16900v1 by Sara Incao, Carlo Mazzola, Giulia Belgiovine, Alessandra Sciutti

The fusion of Large Language Models (LLMs) and robotic systems has led to a
transformative paradigm in the robotic field, offering unparalleled
capabilities not only in the communication domain but also in skills like
multimodal input handling, high-level reasoning, and plan generation. The
grounding of LLMs knowledge into the empirical world has been considered a
crucial pathway to exploit the efficiency of LLMs in robotics. Nevertheless,
connecting LLMs' representations to the external world with multimodal
approaches or with robots' bodies is not enough to let them understand the
meaning of the language they are manipulating. Taking inspiration from humans,
this work draws attention to three necessary elements for an agent to grasp and
experience the world. The roadmap for LLMs grounding is envisaged in an active
bodily system as the reference point for experiencing the environment, a
temporally structured experience for a coherent, self-related interaction with
the external world, and social skills to acquire a common-grounded shared
experience.

摘要：大型語言模型 (LLM) 和機器人系統的融合，在機器人領域中帶來了轉型的典範，不僅在溝通領域，在多模態輸入處理、高階推理和計畫生成等技能方面，也提供了無與倫比的能力。將 LLM 知識基礎化到經驗世界中，被認為是利用 LLM 在機器人技術中效率的一條關鍵途徑。儘管如此，將 LLM 的表示與外部世界連接起來，透過多模態方法或機器人的身體，還不足以讓它們理解所操作語言的含義。從人類身上汲取靈感，這項工作提請注意，一個代理人掌握和體驗世界所需的三個必要元素。LLM 基礎的路線圖，被設想在一個活躍的身體系統中，作為體驗環境的參考點，一個時間結構化的體驗，用於與外部世界的連貫、自我相關的互動，以及社會技能，以獲得一個共同基礎的共享體驗。

##### **AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging**
2409.16898v1 by Jaeyoung Huh, Paul Klein, Gareth Funka-Lea, Puneet Sharma, Ankur Kapoor, Young-Ho Kim

Intra-cardiac Echocardiography (ICE) is a crucial imaging modality used in
electrophysiology (EP) and structural heart disease (SHD) interventions,
providing real-time, high-resolution views from within the heart. Despite its
advantages, effective manipulation of the ICE catheter requires significant
expertise, which can lead to inconsistent outcomes, particularly among less
experienced operators. To address this challenge, we propose an AI-driven
closed-loop view guidance system with human-in-the-loop feedback, designed to
assist users in navigating ICE imaging without requiring specialized knowledge.
Our method models the relative position and orientation vectors between
arbitrary views and clinically defined ICE views in a spatial coordinate
system, guiding users on how to manipulate the ICE catheter to transition from
the current view to the desired view over time. Operating in a closed-loop
configuration, the system continuously predicts and updates the necessary
catheter manipulations, ensuring seamless integration into existing clinical
workflows. The effectiveness of the proposed system is demonstrated through a
simulation-based evaluation, achieving an 89% success rate with the 6532 test
dataset, highlighting its potential to improve the accuracy and efficiency of
ICE imaging procedures.

摘要：心內超音波檢查 (ICE) 是一種關鍵的影像模式，用於電生理學 (EP) 和結構性心臟疾病 (SHD) 的介入治療，可從心臟內部提供即時、高解析度的影像。儘管有這些優點，但有效操作 ICE 導管需要相當的專業知識，這可能會導致不一致的結果，尤其是在經驗較少的操作員中。為了應對這個挑戰，我們提出一個以 AI 為驅動的閉環視圖引導系統，並結合人機環回饋，旨在協助使用者在不需要專業知識的情況下導航 ICE 影像。我們的模型模擬了任意視圖和臨床定義的 ICE 視圖之間的相對位置和方向向量，在一個空間座標系統中引導使用者如何操作 ICE 導管，以隨著時間從目前的視圖過渡到期望的視圖。在閉環配置中操作時，系統會持續預測和更新必要的導管操作，確保無縫整合到現有的臨床工作流程中。所提出的系統的有效性透過基於模擬的評估得到證明，在 6532 個測試資料集中達到 89% 的成功率，突顯其改善 ICE 影像程序的準確性和效率的潛力。

##### **Shifting from endangerment to rebirth in the Artificial Intelligence Age: An Ensemble Machine Learning Approach for Hawrami Text Classification**
2409.16884v1 by Aram Khaksar, Hossein Hassani

Hawrami, a dialect of Kurdish, is classified as an endangered language as it
suffers from the scarcity of data and the gradual loss of its speakers. Natural
Language Processing projects can be used to partially compensate for data
availability for endangered languages/dialects through a variety of approaches,
such as machine translation, language model building, and corpora development.
Similarly, NLP projects such as text classification are in language
documentation. Several text classification studies have been conducted for
Kurdish, but they were mainly dedicated to two particular dialects: Sorani
(Central Kurdish) and Kurmanji (Northern Kurdish). In this paper, we introduce
various text classification models using a dataset of 6,854 articles in Hawrami
labeled into 15 categories by two native speakers. We use K-nearest Neighbor
(KNN), Linear Support Vector Machine (Linear SVM), Logistic Regression (LR),
and Decision Tree (DT) to evaluate how well those methods perform the
classification task. The results indicate that the Linear SVM achieves a 96% of
accuracy and outperforms the other approaches.

摘要：霍拉米語是一種庫德語方言，由於資料稀少且講者逐漸減少，被歸類為瀕危語言。自然語言處理專案可透過各種方法，例如機器翻譯、語言模型建構和語料庫開發，來部分彌補瀕危語言/方言的資料取得問題。類似地，自然語言處理專案（例如文字分類）在語言文件編寫中也很重要。庫德語已經進行過多項文字分類研究，但主要針對兩種特定方言：索拉尼語（中央庫德語）和庫爾曼吉語（北庫德語）。在本文中，我們使用由兩位母語人士標記為 15 個類別的 6,854 篇霍拉米語文章的資料集，介紹各種文字分類模型。我們使用 K 最近鄰 (KNN)、線性支援向量機 (線性 SVM)、邏輯迴歸 (LR) 和決策樹 (DT) 來評估這些方法執行分類任務的表現如何。結果顯示線性 SVM 達到 96% 的準確度，並且優於其他方法。

##### **Revisiting Space Mission Planning: A Reinforcement Learning-Guided Approach for Multi-Debris Rendezvous**
2409.16882v1 by Agni Bandyopadhyay, Guenther Waxenegger-Wilfing

This research introduces a novel application of a masked Proximal Policy
Optimization (PPO) algorithm from the field of deep reinforcement learning
(RL), for determining the most efficient sequence of space debris visitation,
utilizing the Lambert solver as per Izzo's adaptation for individual
rendezvous. The aim is to optimize the sequence in which all the given debris
should be visited to get the least total time for rendezvous for the entire
mission. A neural network (NN) policy is developed, trained on simulated space
missions with varying debris fields. After training, the neural network
calculates approximately optimal paths using Izzo's adaptation of Lambert
maneuvers. Performance is evaluated against standard heuristics in mission
planning. The reinforcement learning approach demonstrates a significant
improvement in planning efficiency by optimizing the sequence for debris
rendezvous, reducing the total mission time by an average of approximately
{10.96\%} and {13.66\%} compared to the Genetic and Greedy algorithms,
respectively. The model on average identifies the most time-efficient sequence
for debris visitation across various simulated scenarios with the fastest
computational speed. This approach signifies a step forward in enhancing
mission planning strategies for space debris clearance.

摘要：这项研究引入了深度强化学习（RL）领域中一种掩蔽近端策略优化（PPO）算法的新应用，用于确定空间碎片访问的最有效顺序，利用 Lambert 求解器根据 Izzo 对个别会合的改编。目的是优化访问所有给定碎片的顺序，以获得整个任务会合的最小总时间。开发了一个神经网络（NN）策略，在具有不同碎片场的模拟太空任务中进行训练。训练后，神经网络使用 Izzo 对 Lambert 机动的改编计算近似最优路径。在任务规划中针对标准启发式方法评估性能。强化学习方法通过优化碎片会合的顺序，显着提高了规划效率，与遗传和贪婪算法相比，总任务时间平均减少了大约{10.96%}和{13.66%}。该模型平均确定了在各种模拟场景中碎片访问的最省时顺序，并具有最快的计算速度。这种方法标志着增强空间碎片清除任务规划策略向前迈进了一步。

##### **Automating Traffic Model Enhancement with AI Research Agent**
2409.16876v1 by Xusen Guo, Xinxi Yang, Mingxing Peng, Hongliang Lu, Meixin Zhu, Hai Yang

Developing efficient traffic models is essential for optimizing
transportation systems, yet current approaches remain time-intensive and
susceptible to human errors due to their reliance on manual processes.
Traditional workflows involve exhaustive literature reviews, formula
optimization, and iterative testing, leading to inefficiencies in research. In
response, we introduce the Traffic Research Agent (TR-Agent), an AI-driven
system designed to autonomously develop and refine traffic models through an
iterative, closed-loop process. Specifically, we divide the research pipeline
into four key stages: idea generation, theory formulation, theory evaluation,
and iterative optimization; and construct TR-Agent with four corresponding
modules: Idea Generator, Code Generator, Evaluator, and Analyzer. Working in
synergy, these modules retrieve knowledge from external resources, generate
novel ideas, implement and debug models, and finally assess them on the
evaluation datasets. Furthermore, the system continuously refines these models
based on iterative feedback, enhancing research efficiency and model
performance. Experimental results demonstrate that TR-Agent achieves
significant performance improvements across multiple traffic models, including
the Intelligent Driver Model (IDM) for car following, the MOBIL lane-changing
model, and the Lighthill-Whitham-Richards (LWR) traffic flow model.
Additionally, TR-Agent provides detailed explanations for its optimizations,
allowing researchers to verify and build upon its improvements easily. This
flexibility makes the framework a powerful tool for researchers in
transportation and beyond. To further support research and collaboration, we
have open-sourced both the code and data used in our experiments, facilitating
broader access and enabling continued advancements in the field.

摘要：<paragraph>開發有效的交通模型對於最佳化運輸系統至關重要，然而，目前的方法仍然十分耗時，且由於依賴手動流程，容易產生人為錯誤。傳統的工作流程涉及廣泛的文獻回顧、公式最佳化和反覆測試，導致研究效率低下。為了解決此問題，我們引入了交通研究代理（TR-Agent），這是一個由人工智慧驅動的系統，旨在透過反覆、閉環的流程自主開發和完善交通模型。具體來說，我們將研究流程劃分為四個關鍵階段：構想產生、理論制定、理論評估和反覆最佳化；並使用四個相應的模組構建 TR-Agent：構想產生器、程式碼產生器、評估器和分析器。這些模組協同工作，從外部資源中擷取知識、產生新穎的構想、實作和除錯模型，最後在評估資料集上評估它們。此外，系統會根據反覆的回饋持續精進這些模型，提升研究效率和模型效能。實驗結果證明，TR-Agent 在多個交通模型中均獲得顯著的效能提升，包括用於跟車的智慧駕駛模型（IDM）、MOBIL 變換車道模型和 Lighthill-Whitham-Richards（LWR）交通流模型。此外，TR-Agent 為其最佳化提供了詳細的說明，讓研究人員能夠輕鬆驗證和建構其改進成果。這種靈活性使這個架構成為交通運輸及其他領域研究人員強而有力的工具。為了進一步支持研究和合作，我們已開放我們實驗中使用的程式碼和資料，促進更廣泛的存取，並促成該領域的持續進步。</paragraph>

##### **Ethical and Scalable Automation: A Governance and Compliance Framework for Business Applications**
2409.16872v1 by Haocheng Lin

The popularisation of applying AI in businesses poses significant challenges
relating to ethical principles, governance, and legal compliance. Although
businesses have embedded AI into their day-to-day processes, they lack a
unified approach for mitigating its potential risks. This paper introduces a
framework ensuring that AI must be ethical, controllable, viable, and
desirable. Balancing these factors ensures the design of a framework that
addresses its trade-offs, such as balancing performance against explainability.
A successful framework provides practical advice for businesses to meet
regulatory requirements in sectors such as finance and healthcare, where it is
critical to comply with standards like GPDR and the EU AI Act. Different case
studies validate this framework by integrating AI in both academic and
practical environments. For instance, large language models are cost-effective
alternatives for generating synthetic opinions that emulate attitudes to
environmental issues. These case studies demonstrate how having a structured
framework could enhance transparency and maintain performance levels as shown
from the alignment between synthetic and expected distributions. This alignment
is quantified using metrics like Chi-test scores, normalized mutual
information, and Jaccard indexes. Future research should explore the
framework's empirical validation in diverse industrial settings further,
ensuring the model's scalability and adaptability.

摘要：隨著 AI 在企業中的普及，在道德原則、治理和法律合規方面帶來了重大的挑戰。儘管企業已將 AI 嵌入其日常流程，但他們缺乏統一的方法來減輕其潛在風險。本文介紹了一個框架，確保 AI 必須符合道德、可控、可行且合適。平衡這些因素可確保設計一個框架，以解決其權衡取捨，例如平衡效能和可解釋性。一個成功的框架為企業提供了實用的建議，以滿足金融和醫療保健等行業的法規要求，在這些行業中，遵守 GDPR 和歐盟 AI 法案等標準至關重要。不同的案例研究通過在學術和實務環境中整合 AI 來驗證這個框架。例如，大型語言模型是生成模擬對環境問題態度的合成意見的經濟有效替代方案。這些案例研究展示了擁有結構化框架如何增強透明度並維持效能水準，這從合成分佈和預期分佈之間的一致性中可以看出。這種一致性是使用卡方檢定分數、標準化互信息和傑卡德指數等指標量化的。未來的研究應進一步探討該框架在不同產業環境中的實證驗證，確保模型的可擴充性和適應性。

##### **Multi-objective Evolution of Heuristic Using Large Language Model**
2409.16867v1 by Shunyu Yao, Fei Liu, Xi Lin, Zhichao Lu, Zhenkun Wang, Qingfu Zhang

Heuristics are commonly used to tackle diverse search and optimization
problems. Design heuristics usually require tedious manual crafting with domain
knowledge. Recent works have incorporated large language models (LLMs) into
automatic heuristic search leveraging their powerful language and coding
capacity. However, existing research focuses on the optimal performance on the
target problem as the sole objective, neglecting other criteria such as
efficiency and scalability, which are vital in practice. To tackle this
challenge, we propose to model heuristic search as a multi-objective
optimization problem and consider introducing other practical criteria beyond
optimal performance. Due to the complexity of the search space, conventional
multi-objective optimization methods struggle to effectively handle
multi-objective heuristic search. We propose the first LLM-based
multi-objective heuristic search framework, Multi-objective Evolution of
Heuristic (MEoH), which integrates LLMs in a zero-shot manner to generate a
non-dominated set of heuristics to meet multiple design criteria. We design a
new dominance-dissimilarity mechanism for effective population management and
selection, which incorporates both code dissimilarity in the search space and
dominance in the objective space. MEoH is demonstrated in two well-known
combinatorial optimization problems: the online Bin Packing Problem (BPP) and
the Traveling Salesman Problem (TSP). Results indicate that a variety of elite
heuristics are automatically generated in a single run, offering more trade-off
options than existing methods. It successfully achieves competitive or superior
performance while improving efficiency up to 10 times. Moreover, we also
observe that the multi-objective search introduces novel insights into
heuristic design and leads to the discovery of diverse heuristics.

摘要：啟發式法通常用於解決各種搜尋和最佳化問題。設計啟發式法通常需要使用領域知識進行繁瑣的手動製作。最近的研究已將大型語言模型 (LLM) 納入自動啟發式搜尋中，以利用其強大的語言和編碼能力。然而，現有研究只關注目標問題的最佳效能，而忽略了其他標準，例如效率和可擴充性，這在實務上至關重要。為了應對這個挑戰，我們提出將啟發式搜尋建模為多目標最佳化問題，並考慮在最佳效能之外引入其他實用標準。由於搜尋空間的複雜性，傳統的多目標最佳化方法難以有效處理多目標啟發式搜尋。我們提出了第一個基於 LLM 的多目標啟發式搜尋架構，即啟發式多目標演化 (MEoH)，它以零次學習的方式整合 LLM，以產生一組非支配的啟發式法，以滿足多重設計標準。我們設計了一個新的支配相異性機制，用於有效的人口管理和選擇，它結合了搜尋空間中的程式碼相異性和目標空間中的支配性。MEoH 在兩個著名的組合最佳化問題中得到證明：線上二維 bin 分割問題 (BPP) 和旅行推銷員問題 (TSP)。結果表明，在單次執行中自動產生了各種精英啟發式法，提供了比現有方法更多權衡選項。它成功地達到了競爭性或優越的效能，同時將效率提升了 10 倍。此外，我們還觀察到，多目標搜尋為啟發式設計引入了新的見解，並導致了各種啟發式法的發現。

##### **The Role of Language Models in Modern Healthcare: A Comprehensive Review**
2409.16860v1 by Amna Khalid, Ayma Khalid, Umar Khalid

The application of large language models (LLMs) in healthcare has gained
significant attention due to their ability to process complex medical data and
provide insights for clinical decision-making. These models have demonstrated
substantial capabilities in understanding and generating natural language,
which is crucial for medical documentation, diagnostics, and patient
interaction. This review examines the trajectory of language models from their
early stages to the current state-of-the-art LLMs, highlighting their strengths
in healthcare applications and discussing challenges such as data privacy,
bias, and ethical considerations. The potential of LLMs to enhance healthcare
delivery is explored, alongside the necessary steps to ensure their ethical and
effective integration into medical practice.

摘要：大型語言模型 (LLM) 在醫療保健中的應用已獲得顯著關注，因為它們能夠處理複雜的醫療數據並提供臨床決策的見解。這些模型已展示出在理解和產生自然語言方面的實質能力，這對於醫療文件、診斷和患者互動至關重要。本篇評論探討了語言模型從早期階段到當前最先進的 LLM 的軌跡，重點介紹了它們在醫療保健應用中的優勢，並討論了數據隱私、偏見和道德考量等挑戰。探討了 LLM 提升醫療保健服務的潛力，以及確保它們道德且有效整合到醫療實務中的必要步驟。

##### **Dispute resolution in legal mediation with quantitative argumentation**
2409.16854v1 by Xiao Chi

Mediation is often treated as an extension of negotiation, without taking
into account the unique role that norms and facts play in legal mediation.
Additionally, current approaches for updating argument acceptability in
response to changing variables frequently require the introduction of new
arguments or the removal of existing ones, which can be inefficient and
cumbersome in decision-making processes within legal disputes. In this paper,
our contribution is two-fold. First, we introduce a QuAM (Quantitative
Argumentation Mediate) framework, which integrates the parties' knowledge and
the mediator's knowledge, including facts and legal norms, when determining the
acceptability of a mediation goal. Second, we develop a new formalism to model
the relationship between the acceptability of a goal argument and the values
assigned to a variable associated with the argument. We use a real-world legal
mediation as a running example to illustrate our approach.

摘要：調解通常被視為協商的延伸，卻未考量規範和事實於法律調解中所扮演的獨特角色。此外，當前針對回應變數變更而更新論證可接受性的做法，常需要提出新的論證或移除現有的論證，這在法律爭議中的決策過程中可能低效率且繁瑣。在本文中，我們的貢獻有兩個面向。首先，我們提出一個 QuAM（量化論證調解）架構，在決定調解目標的可接受性時，整合當事人的知識和調解人的知識，包含事實和法律規範。其次，我們發展一種新的形式主義來建構目標論證的可接受性與與論證相關的變數所賦予值的關係。我們使用一個真實世界的法律調解作為一個執行範例來說明我們的做法。

##### **Exposing Assumptions in AI Benchmarks through Cognitive Modelling**
2409.16849v1 by Jonathan H. Rystrøm, Kenneth C. Enevoldsen

Cultural AI benchmarks often rely on implicit assumptions about measured
constructs, leading to vague formulations with poor validity and unclear
interrelations. We propose exposing these assumptions using explicit cognitive
models formulated as Structural Equation Models. Using cross-lingual alignment
transfer as an example, we show how this approach can answer key research
questions and identify missing datasets. This framework grounds benchmark
construction theoretically and guides dataset development to improve construct
measurement. By embracing transparency, we move towards more rigorous,
cumulative AI evaluation science, challenging researchers to critically examine
their assessment foundations.

摘要：文化 AI 基準經常依賴於測量結構的隱含假設，導致模糊的表述、效度不佳和不清晰的相互關係。我們建議使用明確的認知模型（以結構方程模型的形式表述）來揭示這些假設。以跨語言對齊轉移為例，我們展示了這種方法如何回答關鍵的研究問題並識別缺失的數據集。此框架在理論上建立了基準構建，並指導數據集開發以改進結構測量。通過擁抱透明度，我們朝著更嚴謹、累積的 AI 評估科學邁進，挑戰研究人員批判性地審查他們的評估基礎。

##### **Uncertainty Representations in State-Space Layers for Deep Reinforcement Learning under Partial Observability**
2409.16824v1 by Carlos E. Luis, Alessandro G. Bottero, Julia Vinogradska, Felix Berkenkamp, Jan Peters

Optimal decision-making under partial observability requires reasoning about
the uncertainty of the environment's hidden state. However, most reinforcement
learning architectures handle partial observability with sequence models that
have no internal mechanism to incorporate uncertainty in their hidden state
representation, such as recurrent neural networks, deterministic state-space
models and transformers. Inspired by advances in probabilistic world models for
reinforcement learning, we propose a standalone Kalman filter layer that
performs closed-form Gaussian inference in linear state-space models and train
it end-to-end within a model-free architecture to maximize returns. Similar to
efficient linear recurrent layers, the Kalman filter layer processes sequential
data using a parallel scan, which scales logarithmically with the sequence
length. By design, Kalman filter layers are a drop-in replacement for other
recurrent layers in standard model-free architectures, but importantly they
include an explicit mechanism for probabilistic filtering of the latent state
representation. Experiments in a wide variety of tasks with partial
observability show that Kalman filter layers excel in problems where
uncertainty reasoning is key for decision-making, outperforming other stateful
models.

摘要：在部分可观测性下进行最优决策需要对环境的隐藏状态的不确定性进行推理。然而，大多数强化学习架构使用序列模型处理部分可观测性，这些模型没有内部机制来合并其隐藏状态表示中的不确定性，例如循环神经网络、确定性状态空间模型和转换器。受强化学习概率世界模型的进步启发，我们提出了一种独立的卡尔曼滤波层，它在线性状态空间模型中执行闭式高斯推理，并在无模型架构中端到端地对其进行训练，以最大化回报。与高效线性循环层类似，卡尔曼滤波层使用并行扫描处理顺序数据，该扫描与序列长度成对数比例。通过设计，卡尔曼滤波层可以替代标准无模型架构中的其他循环层，但重要的是，它们包括用于概率过滤潜在状态表示的显式机制。在具有部分可观测性的各种任务中的实验表明，卡尔曼滤波层在不确定性推理是决策的关键的问题中表现出色，优于其他有状态模型。

##### **XAI-guided Insulator Anomaly Detection for Imbalanced Datasets**
2409.16821v1 by Maximilian Andreas Hoefler, Karsten Mueller, Wojciech Samek

Power grids serve as a vital component in numerous industries, seamlessly
delivering electrical energy to industrial processes and technologies, making
their safe and reliable operation indispensable. However, powerlines can be
hard to inspect due to difficult terrain or harsh climatic conditions.
Therefore, unmanned aerial vehicles are increasingly deployed to inspect
powerlines, resulting in a substantial stream of visual data which requires
swift and accurate processing. Deep learning methods have become widely popular
for this task, proving to be a valuable asset in fault detection. In
particular, the detection of insulator defects is crucial for predicting
powerline failures, since their malfunction can lead to transmission
disruptions. It is therefore of great interest to continuously maintain and
rigorously inspect insulator components. In this work we propose a novel
pipeline to tackle this task. We utilize state-of-the-art object detection to
detect and subsequently classify individual insulator anomalies. Our approach
addresses dataset challenges such as imbalance and motion-blurred images
through a fine-tuning methodology which allows us to alter the classification
focus of the model by increasing the classification accuracy of anomalous
insulators. In addition, we employ explainable-AI tools for precise
localization and explanation of anomalies. This proposed method contributes to
the field of anomaly detection, particularly vision-based industrial inspection
and predictive maintenance. We significantly improve defect detection accuracy
by up to 13%, while also offering a detailed analysis of model
mis-classifications and localization quality, showcasing the potential of our
method on real-world data.

摘要：電力網路在許多產業中扮演著至關重要的角色，無縫地將電力傳輸到工業流程和技術，使其安全且可靠的運作不可或缺。然而，由於地形崎嶇或氣候條件惡劣，電力線路可能難以檢查。因此，無人機正越來越廣泛地用於檢查電力線路，產生大量的視覺資料，需要快速且準確的處理。深度學習方法已廣泛應用於此任務，證明是故障偵測中寶貴的資產。特別是，絕緣體缺陷的偵測對於預測電力線路故障至關重要，因為其故障可能導致傳輸中斷。因此，持續維護和嚴格檢查絕緣體元件非常重要。在這項工作中，我們提出了一個新的管道來解決這個任務。我們利用最先進的物件偵測來偵測並隨後分類個別絕緣體異常。我們的做法透過微調方法來解決資料集的挑戰，例如不平衡和動態模糊影像，這讓我們能夠透過提高異常絕緣體的分類準確度來改變模型的分類重點。此外，我們採用可解釋的 AI 工具來精確定位和解釋異常。此提議的方法有助於異常偵測領域，特別是基於視覺的工業檢查和預測性維護。我們顯著地將缺陷偵測準確度提高了 13%，同時也提供了模型錯誤分類和定位品質的詳細分析，展示了我們的方法在真實世界資料中的潛力。

##### **CodeInsight: A Curated Dataset of Practical Coding Solutions from Stack Overflow**
2409.16819v1 by Nathanaël Beau, Benoît Crabbé

We introduce a novel dataset tailored for code generation, aimed at aiding
developers in common tasks. Our dataset provides examples that include a
clarified intent, code snippets associated, and an average of three related
unit tests. It encompasses a range of libraries such as \texttt{Pandas},
\texttt{Numpy}, and \texttt{Regex}, along with more than 70 standard libraries
in Python code derived from Stack Overflow. Comprising 3,409 crafted examples
by Python experts, our dataset is designed for both model finetuning and
standalone evaluation. To complete unit tests evaluation, we categorize
examples in order to get more fine grained analysis, enhancing the
understanding of models' strengths and weaknesses in specific coding tasks. The
examples have been refined to reduce data contamination, a process confirmed by
the performance of three leading models: Mistral 7B, CodeLLaMa 13B, and
Starcoder 15B. We further investigate data-contamination testing GPT-4
performance on a part of our dataset. The benchmark can be accessed at
\url{https://github.com/NathanaelBeau/CodeInsight}.

摘要：<paragraph>我們引進一個專門為程式碼產生量身打造的新穎資料集，旨在協助開發人員執行常見任務。我們的資料集提供範例，其中包含明確的意圖、關聯的程式碼片段，以及平均三個相關單元測試。它涵蓋各種函式庫，例如 \texttt{Pandas}、\texttt{Numpy} 和 \texttt{Regex}，以及來自 Stack Overflow 中 Python 程式碼的 70 多個標準函式庫。我們的資料集由 Python 專家精心製作 3,409 個範例，專為模型微調和獨立評估而設計。為了完成單元測試評估，我們對範例進行分類以取得更精細的分析，增強對模型在特定編碼任務中優缺點的理解。這些範例經過精煉以減少資料污染，這個過程由三個領先模型的效能所證實：Mistral 7B、CodeLLaMa 13B 和 Starcoder 15B。我們進一步調查資料污染測試 GPT-4 在我們資料集一部分的效能。基準測試可以在 \url{https://github.com/NathanaelBeau/CodeInsight} 取得。</paragraph>

##### **PeerArg: Argumentative Peer Review with LLMs**
2409.16813v1 by Purin Sukpanichnant, Anna Rapberger, Francesca Toni

Peer review is an essential process to determine the quality of papers
submitted to scientific conferences or journals. However, it is subjective and
prone to biases. Several studies have been conducted to apply techniques from
NLP to support peer review, but they are based on black-box techniques and
their outputs are difficult to interpret and trust. In this paper, we propose a
novel pipeline to support and understand the reviewing and decision-making
processes of peer review: the PeerArg system combining LLMs with methods from
knowledge representation. PeerArg takes in input a set of reviews for a paper
and outputs the paper acceptance prediction. We evaluate the performance of the
PeerArg pipeline on three different datasets, in comparison with a novel
end-2-end LLM that uses few-shot learning to predict paper acceptance given
reviews. The results indicate that the end-2-end LLM is capable of predicting
paper acceptance from reviews, but a variant of the PeerArg pipeline
outperforms this LLM.

摘要：同行評審是決定提交給科學會議或期刊的論文品質的必要程序。然而，它具有主觀性，且容易產生偏見。已經進行了多項研究來應用自然語言處理 (NLP) 的技術來支援同行評審，但它們基於黑盒技術，且其產出難以解釋和信任。在本文中，我們提出了一個新穎的管道來支援和理解同行評審的審查和決策流程：PeerArg 系統，它結合了大型語言模型 (LLM) 和知識表示方法。PeerArg 輸入一組論文評論，並輸出論文接受預測。我們在三個不同的資料集上評估 PeerArg 管道的效能，並與一個新穎的端對端 LLM 進行比較，該 LLM 使用少量學習來預測給定評論的論文接受度。結果表明，端對端 LLM 能夠根據評論預測論文接受度，但 PeerArg 管道的變體優於此 LLM。

##### **A Few Hypocrites: Few-Shot Learning and Subtype Definitions for Detecting Hypocrisy Accusations in Online Climate Change Debates**
2409.16807v1 by Paulina Garcia Corral, Avishai Green, Hendrik Meyer, Anke Stoll, Xiaoyue Yan, Myrthe Reuver

The climate crisis is a salient issue in online discussions, and hypocrisy
accusations are a central rhetorical element in these debates. However, for
large-scale text analysis, hypocrisy accusation detection is an understudied
tool, most often defined as a smaller subtask of fallacious argument detection.
In this paper, we define hypocrisy accusation detection as an independent task
in NLP, and identify different relevant subtypes of hypocrisy accusations. Our
Climate Hypocrisy Accusation Corpus (CHAC) consists of 420 Reddit climate
debate comments, expert-annotated into two different types of hypocrisy
accusations: personal versus political hypocrisy. We evaluate few-shot
in-context learning with 6 shots and 3 instruction-tuned Large Language Models
(LLMs) for detecting hypocrisy accusations in this dataset. Results indicate
that the GPT-4o and Llama-3 models in particular show promise in detecting
hypocrisy accusations (F1 reaching 0.68, while previous work shows F1 of 0.44).
However, context matters for a complex semantic concept such as hypocrisy
accusations, and we find models struggle especially at identifying political
hypocrisy accusations compared to personal moral hypocrisy. Our study
contributes new insights in hypocrisy detection and climate change discourse,
and is a stepping stone for large-scale analysis of hypocrisy accusation in
online climate debates.

摘要：氣候危機是網路討論中一個顯著的問題，而偽善指控是這些辯論中一個主要的修辭元素。然而，對於大規模的文字分析，偽善指控偵測是一個研究不足的工具，最常被定義為謬誤論證偵測的一個較小的子任務。在本文中，我們將偽善指控偵測定義為自然語言處理 (NLP) 中一個獨立的任務，並找出偽善指控的不同相關子類型。我們的氣候偽善指控語料庫 (CHAC) 包含 420 則 Reddit 氣候辯論留言，由專家註釋為兩種不同類型的偽善指控：個人偽善與政治偽善。我們評估了在這個資料集偵測偽善指控的六次小樣本情境學習，以及三個經過指令微調的大型語言模型 (LLM)。結果顯示，GPT-4o 和 Llama-3 模型在偵測偽善指控方面特別有前景（F1 達到 0.68，而先前的研究顯示 F1 為 0.44）。然而，對於偽善指控等複雜的語義概念，背景很重要，我們發現與個人道德偽善相比，模型在辨識政治偽善指控時特別吃力。我們的研究為偽善偵測和氣候變遷論述提供了新的見解，並且是大規模分析網路氣候辯論中偽善指控的踏腳石。

##### **Large Language Model Predicts Above Normal All India Summer Monsoon Rainfall in 2024**
2409.16799v1 by Ujjawal Sharma, Madhav Biyani, Akhil Dev Suresh, Debi Prasad Bhuyan, Saroj Kanta Mishra, Tanmoy Chakraborty

Reliable prediction of the All India Summer Monsoon Rainfall (AISMR) is
pivotal for informed policymaking for the country, impacting the lives of
billions of people. However, accurate simulation of AISMR has been a persistent
challenge due to the complex interplay of various muti-scale factors and the
inherent variability of the monsoon system. This research focuses on adapting
and fine-tuning the latest LLM model, PatchTST, to accurately predict AISMR
with a lead time of three months. The fine-tuned PatchTST model, trained with
historical AISMR data, the Ni\~no3.4 index, and categorical Indian Ocean Dipole
values, outperforms several popular neural network models and statistical
models. This fine-tuned LLM model exhibits an exceptionally low RMSE percentage
of 0.07% and a Spearman correlation of 0.976. This is particularly impressive,
since it is nearly 80% more accurate than the best-performing NN models. The
model predicts an above-normal monsoon for the year 2024, with an accumulated
rainfall of 921.6 mm in the month of June-September for the entire country.

摘要：準確預測全印度夏季季風降雨量 (AISMR) 對於國家明智的政策制定至關重要，影響著數十億人的生活。然而，由於各種多尺度因素的複雜相互作用和季風系統的固有變異性，對 AISMR 的準確模擬一直是一個持續的挑戰。本研究專注於調整和微調最新的 LLM 模型 PatchTST，以準確預測提前三個月到來的 AISMR。經過微調的 PatchTST 模型使用歷史 AISMR 資料、Ni\~no3.4 指數和分類的印度洋偶極值進行訓練，其表現優於幾種流行的神經網路模型和統計模型。經過微調的 LLM 模型展現出極低的 RMSE 百分比 0.07% 和 Spearman 相關性 0.976。這特別令人印象深刻，因為它比效能最好的 NN 模型準確了近 80%。該模型預測 2024 年將出現異常季風，全國 6 月至 9 月的累積降雨量為 921.6 毫米。

##### **Scalable Ensemble Diversification for OOD Generalization and Detection**
2409.16797v1 by Alexander Rubinstein, Luca Scimeca, Damien Teney, Seong Joon Oh

Training a diverse ensemble of models has several practical applications such
as providing candidates for model selection with better out-of-distribution
(OOD) generalization, and enabling the detection of OOD samples via Bayesian
principles. An existing approach to diverse ensemble training encourages the
models to disagree on provided OOD samples. However, the approach is
computationally expensive and it requires well-separated ID and OOD examples,
such that it has only been demonstrated in small-scale settings.
  $\textbf{Method.}$ This work presents a method for Scalable Ensemble
Diversification (SED) applicable to large-scale settings (e.g. ImageNet) that
does not require OOD samples. Instead, SED identifies hard training samples on
the fly and encourages the ensemble members to disagree on these. To improve
scaling, we show how to avoid the expensive computations in existing methods of
exhaustive pairwise disagreements across models.
  $\textbf{Results.}$ We evaluate the benefits of diversification with
experiments on ImageNet. First, for OOD generalization, we observe large
benefits from the diversification in multiple settings including output-space
(classical) ensembles and weight-space ensembles (model soups). Second, for OOD
detection, we turn the diversity of ensemble hypotheses into a novel
uncertainty score estimator that surpasses a large number of OOD detection
baselines.
  Code is available here:
https://github.com/AlexanderRubinstein/diverse-universe-public.

摘要：<paragraph>訓練多元模型集合有多項實際應用，例如提供模型選擇候選，以獲得更好的分布外 (OOD) 概化，並能透過貝氏原理來偵測 OOD 樣本。現有多元集合訓練方法鼓勵模型對提供的 OOD 樣本表示不同意。然而，此方法在運算上很昂貴，而且需要有良好分離的 ID 和 OOD 範例，因此僅在小規模設定中得到驗證。
$\textbf{方法}$。本研究提出適用於大型設定（例如 ImageNet）的可擴充集合多樣化 (SED) 方法，不需要 OOD 樣本。相反地，SED 會在執行中找出困難的訓練樣本，並鼓勵集合成員對這些樣本表示不同意。為了改善擴充性，我們展示如何避免現有方法中跨模型的窮舉成對不同意所產生的昂貴運算。
$\textbf{結果}$。我們在 ImageNet 上的實驗中評估了多樣化的優點。首先，對於 OOD 概化，我們觀察到多樣化在多種設定中帶來極大的好處，包括輸出空間（傳統）集合和權重空間集合（模型湯）。其次，對於 OOD 偵測，我們將集合假設的多樣性轉換為一種新穎的不確定性評分估計器，其優於大量的 OOD 偵測基準。
程式碼可在此取得：
https://github.com/AlexanderRubinstein/diverse-universe-public。</paragraph>

##### **Mitigating the Bias of Large Language Model Evaluation**
2409.16788v1 by Hongli Zhou, Hui Huang, Yunfei Long, Bing Xu, Conghui Zhu, Hailong Cao, Muyun Yang, Tiejun Zhao

Recently, there has been a trend of evaluating the Large Language Model (LLM)
quality in the flavor of LLM-as-a-Judge, namely leveraging another LLM to
evaluate the current output quality. However, existing judges are proven to be
biased, namely they would favor answers which present better superficial
quality (such as verbosity, fluency) while ignoring the instruction following
ability. In this work, we propose systematic research about the bias of
LLM-as-a-Judge. Specifically, for closed-source judge models, we apply
calibration to mitigate the significance of superficial quality, both on
probability level and prompt level. For open-source judge models, we propose to
mitigate the bias by contrastive training, with curated negative samples that
deviate from instruction but present better superficial quality. We apply our
methods on the bias evaluation benchmark, and experiment results show our
methods mitigate the bias by a large margin while maintaining a satisfactory
evaluation accuracy.

摘要：最近，評估大型語言模型 (LLM) 品質的趨勢是 LLM-as-a-Judge，也就是利用另一個 LLM 來評估目前的輸出品質。然而，現有的評審已被證明有偏見，也就是說，他們會偏好呈現較佳表面品質（例如冗長、流暢）的答案，而忽略遵循指令的能力。在這項工作中，我們提出關於 LLM-as-a-Judge 偏見的系統性研究。特別是，對於閉源評審模型，我們應用校準來減輕表面品質的重要性，無論是在機率層級或提示層級。對於開源評審模型，我們建議透過對比訓練來減輕偏見，並使用偏離指令但呈現較佳表面品質的負面樣本。我們在偏見評估基準上套用我們的模型，實驗結果顯示我們的模型在維持滿意評估精準度的同時，大幅減輕了偏見。

##### **Enhancing Feature Selection and Interpretability in AI Regression Tasks Through Feature Attribution**
2409.16787v1 by Alexander Hinterleitner, Thomas Bartz-Beielstein, Richard Schulz, Sebastian Spengler, Thomas Winter, Christoph Leitenmeier

Research in Explainable Artificial Intelligence (XAI) is increasing, aiming
to make deep learning models more transparent. Most XAI methods focus on
justifying the decisions made by Artificial Intelligence (AI) systems in
security-relevant applications. However, relatively little attention has been
given to using these methods to improve the performance and robustness of deep
learning algorithms. Additionally, much of the existing XAI work primarily
addresses classification problems. In this study, we investigate the potential
of feature attribution methods to filter out uninformative features in input
data for regression problems, thereby improving the accuracy and stability of
predictions. We introduce a feature selection pipeline that combines Integrated
Gradients with k-means clustering to select an optimal set of variables from
the initial data space. To validate the effectiveness of this approach, we
apply it to a real-world industrial problem - blade vibration analysis in the
development process of turbo machinery.

摘要：可解釋人工智慧 (XAI) 的研究正在增加，目標是讓深度學習模型更具透明度。大多數 XAI 方法專注於為人工智慧 (AI) 系統在與安全相關的應用程式中所做出的決策辯護。然而，對於使用這些方法來改善深度學習演算法的效能和健壯性，卻相對較少關注。此外，現有許多 XAI 工作主要解決分類問題。在本研究中，我們探討特徵歸因方法的潛力，以在回歸問題的輸入資料中篩選出無意義的特徵，從而提升預測的準確性和穩定性。我們引入了一個特徵選取管線，結合了整合梯度和 k 均值聚類，從初始資料空間中選取一組最佳變數。為了驗證此方法的有效性，我們將其應用於現實世界的產業問題，即渦輪機械開發過程中的葉片振動分析。

##### **Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction**
2409.16783v1 by Jinchuan Zhang, Yan Zhou, Yaxin Liu, Ziming Li, Songlin Hu

Automated red teaming is an effective method for identifying misaligned
behaviors in large language models (LLMs). Existing approaches, however, often
focus primarily on improving attack success rates while overlooking the need
for comprehensive test case coverage. Additionally, most of these methods are
limited to single-turn red teaming, failing to capture the multi-turn dynamics
of real-world human-machine interactions. To overcome these limitations, we
propose HARM (Holistic Automated Red teaMing), which scales up the diversity of
test cases using a top-down approach based on an extensible, fine-grained risk
taxonomy. Our method also leverages a novel fine-tuning strategy and
reinforcement learning techniques to facilitate multi-turn adversarial probing
in a human-like manner. Experimental results demonstrate that our framework
enables a more systematic understanding of model vulnerabilities and offers
more targeted guidance for the alignment process.

摘要：自動化紅隊是一種有效的方法，用於識別大型語言模型 (LLM) 中的錯誤行為。然而，現有的方法通常主要集中於提高攻擊成功率，而忽視了對全面測試用例覆蓋的需求。此外，這些方法中的大多數僅限於單回合紅隊，無法捕捉到現實世界中人機交互的多回合動態。為了克服這些限制，我們提出了 HARM（整體自動紅隊），它使用基於可擴展、細粒度風險分類的自頂向下方法擴大了測試用例的多樣性。我們的模型還利用了一種新穎的微調策略和強化學習技術，以人類的方式促進多回合對抗探測。實驗結果表明，我們的框架可以更系統地了解模型漏洞，並為對齊過程提供更有針對性的指導。

##### **LLaMa-SciQ: An Educational Chatbot for Answering Science MCQ**
2409.16779v1 by Marc-Antoine Allard, Matin Ansaripour, Maria Yuffa, Paul Teiletche

Large Language Models (LLMs) often struggle with tasks requiring mathematical
reasoning, particularly multiple-choice questions (MCQs). To address this
issue, we developed LLaMa-SciQ, an educational chatbot designed to assist
college students in solving and understanding MCQs in STEM fields. We begin by
fine-tuning and aligning the models to human preferences. After comparing the
performance of Mistral-7B and LLaMa-8B, we selected the latter as the base
model due to its higher evaluation accuracy. To further enhance accuracy, we
implement Retrieval-Augmented Generation (RAG) and apply quantization to
compress the model, reducing inference time and increasing accessibility for
students. For mathematical reasoning, LLaMa-SciQ achieved 74.5% accuracy on the
GSM8k dataset and 30% on the MATH dataset. However, RAG does not improve
performance and even reduces it, likely due to retriever issues or the model's
unfamiliarity with context. Despite this, the quantized model shows only a 5%
loss in performance, demonstrating significant efficiency improvements.

摘要：大型語言模型 (LLM) 通常難以執行需要數學推理的任務，特別是多選題 (MCQ)。為了解決這個問題，我們開發了 LLaMa-SciQ，這是一個教育聊天機器人，旨在協助大學生解決和理解 STEM 領域的 MCQ。我們首先微調模型並將其與人類偏好保持一致。在比較了 Mistral-7B 和 LLaMa-8B 的性能後，我們選擇後者作為基礎模型，因為它的評估準確度較高。為了進一步提高準確度，我們實施了檢索增強生成 (RAG) 並應用量化來壓縮模型，從而減少推理時間並增加學生的可及性。對於數學推理，LLaMa-SciQ 在 GSM8k 數據集上達到 74.5% 的準確度，在 MATH 數據集上達到 30%。但是，RAG 沒有提高性能，甚至降低了性能，這可能是由於檢索器問題或模型不熟悉上下文。儘管如此，量化模型僅顯示出 5% 的性能損失，證明了顯著的效率改進。

##### **Offline and Distributional Reinforcement Learning for Radio Resource Management**
2409.16764v1 by Eslam Eldeeb, Hirley Alves

Reinforcement learning (RL) has proved to have a promising role in future
intelligent wireless networks. Online RL has been adopted for radio resource
management (RRM), taking over traditional schemes. However, due to its reliance
on online interaction with the environment, its role becomes limited in
practical, real-world problems where online interaction is not feasible. In
addition, traditional RL stands short in front of the uncertainties and risks
in real-world stochastic environments. In this manner, we propose an offline
and distributional RL scheme for the RRM problem, enabling offline training
using a static dataset without any interaction with the environment and
considering the sources of uncertainties using the distributions of the return.
Simulation results demonstrate that the proposed scheme outperforms
conventional resource management models. In addition, it is the only scheme
that surpasses online RL and achieves a $16 \%$ gain over online RL.

摘要：強化學習 (RL) 已證明在未來的智慧無線網路中具有前景。線上 RL 已被採用於無線資源管理 (RRM)，接管傳統的架構。然而，由於它依賴與環境的線上互動，因此在實際的真實世界問題中，其角色受到限制，因為線上互動不可行。此外，傳統的 RL 在面對真實世界隨機環境中的不確定性和風險時，仍有不足之處。因此，我們提出了一個針對 RRM 問題的離線和分配式 RL 架構，使用靜態資料集進行離線訓練，而無需與環境互動，並使用回報的分配來考量不確定性的來源。模擬結果證明，所提出的架構優於傳統的資源管理模型。此外，它是唯一超越線上 RL 的架構，並在線上 RL 上獲得 16% 的收益。

##### **E-SQL: Direct Schema Linking via Question Enrichment in Text-to-SQL**
2409.16751v1 by Hasan Alp Caferoğlu, Özgür Ulusoy

Translating Natural Language Queries into Structured Query Language
(Text-to-SQL or NLQ-to-SQL) is a critical task extensively studied by both the
natural language processing and database communities, aimed at providing a
natural language interface to databases (NLIDB) and lowering the barrier for
non-experts. Despite recent advancements made through the use of Large Language
Models (LLMs), significant challenges remain. These include handling complex
database schemas, resolving ambiguity in user queries, and generating SQL
queries with intricate structures that accurately reflect the user's intent. In
this work, we introduce E-SQL, a novel pipeline specifically designed to
address these challenges through direct schema linking and candidate predicate
augmentation. E-SQL enhances the natural language query by incorporating
relevant database items (i.e., tables, columns, and values) and conditions
directly into the question, bridging the gap between the query and the database
structure. The pipeline leverages candidate predicate augmentation to mitigate
erroneous or incomplete predicates in generated SQLs. We further investigate
the impact of schema filtering, a technique widely explored in previous work,
and demonstrate its diminishing returns when applied alongside advanced large
language models. Comprehensive evaluations on the BIRD benchmark illustrate
that E-SQL achieves competitive performance, particularly excelling in complex
queries with a 66.29% execution accuracy on the test set. All code required to
reproduce the reported results is publicly available on our GitHub repository.

摘要：將自然語言查詢轉換為結構化查詢語言（文本轉 SQL 或 NLQ 轉 SQL）是一項重要的任務，自然語言處理和資料庫社群廣泛研究，旨在提供資料庫的自然語言介面（NLIDB），並降低非專家的門檻。儘管透過使用大型語言模型（LLM）取得了最近的進展，但仍有重大挑戰。這些挑戰包括處理複雜的資料庫架構、解決使用者查詢中的歧義，以及產生精細結構的 SQL 查詢，以準確反映使用者的意圖。在這項工作中，我們介紹了 E-SQL，這是一個專門設計用於透過直接架構連結和候選謂詞擴充來解決這些挑戰的新穎管道。E-SQL 透過將相關資料庫項目（即表格、欄位和值）和條件直接納入問題中，來增強自然語言查詢，縮小查詢和資料庫結構之間的差距。該管道利用候選謂詞擴充來減輕產生 SQL 中錯誤或不完整的謂詞。我們進一步探討了架構過濾的影響，這是一種在先前工作中廣泛探討的技術，並證明當與先進的大型語言模型一起應用時，它的報酬遞減。在 BIRD 基準上的全面評估表明，E-SQL 達到了競爭力的效能，特別是在複雜查詢中，在測試集中執行準確度為 66.29%。重現報告結果所需的所有程式碼都公開在我們的 GitHub 儲存庫中。

##### **GB-RVFL: Fusion of Randomized Neural Network and Granular Ball Computing**
2409.16735v1 by M. Sajid, A. Quadir, M. Tanveer

The random vector functional link (RVFL) network is a prominent
classification model with strong generalization ability. However, RVFL treats
all samples uniformly, ignoring whether they are pure or noisy, and its
scalability is limited due to the need for inverting the entire training
matrix. To address these issues, we propose granular ball RVFL (GB-RVFL) model,
which uses granular balls (GBs) as inputs instead of training samples. This
approach enhances scalability by requiring only the inverse of the GB center
matrix and improves robustness against noise and outliers through the coarse
granularity of GBs. Furthermore, RVFL overlooks the dataset's geometric
structure. To address this, we propose graph embedding GB-RVFL (GE-GB-RVFL)
model, which fuses granular computing and graph embedding (GE) to preserve the
topological structure of GBs. The proposed GB-RVFL and GE-GB-RVFL models are
evaluated on KEEL, UCI, NDC and biomedical datasets, demonstrating superior
performance compared to baseline models.

摘要：隨機向量函數連結 (RVFL) 網路是一種傑出的分類模型，具有強大的泛化能力。然而，RVFL 一視同仁地對待所有樣本，忽略它們是純淨的還是有雜訊的，而且由於需要對整個訓練矩陣進行反轉，因此其可擴充性受到限制。為了解決這些問題，我們提出了顆粒球 RVFL (GB-RVFL) 模型，它使用顆粒球 (GB) 作為輸入，而不是訓練樣本。這種方法僅需要反轉 GB 中心矩陣，就能增強可擴充性，並且透過 GB 的粗粒度來改善對雜訊和異常值的魯棒性。此外，RVFL 忽略了資料集的幾何結構。為了解決這個問題，我們提出了圖嵌入 GB-RVFL (GE-GB-RVFL) 模型，它融合了顆粒運算和圖嵌入 (GE)，以保留 GB 的拓撲結構。所提出的 GB-RVFL 和 GE-GB-RVFL 模型在 KEEL、UCI、NDC 和生物醫學資料集上進行評估，與基線模型相比，表現出優異的效能。

##### **RoleBreak: Character Hallucination as a Jailbreak Attack in Role-Playing Systems**
2409.16727v1 by Yihong Tang, Bo Wang, Xu Wang, Dongming Zhao, Jing Liu, Jijun Zhang, Ruifang He, Yuexian Hou

Role-playing systems powered by large language models (LLMs) have become
increasingly influential in emotional communication applications. However,
these systems are susceptible to character hallucinations, where the model
deviates from predefined character roles and generates responses that are
inconsistent with the intended persona. This paper presents the first
systematic analysis of character hallucination from an attack perspective,
introducing the RoleBreak framework. Our framework identifies two core
mechanisms-query sparsity and role-query conflict-as key factors driving
character hallucination. Leveraging these insights, we construct a novel
dataset, RoleBreakEval, to evaluate existing hallucination mitigation
techniques. Our experiments reveal that even enhanced models trained to
minimize hallucination remain vulnerable to attacks. To address these
vulnerabilities, we propose a novel defence strategy, the Narrator Mode, which
generates supplemental context through narration to mitigate role-query
conflicts and improve query generalization. Experimental results demonstrate
that Narrator Mode significantly outperforms traditional refusal-based
strategies by reducing hallucinations, enhancing fidelity to character roles
and queries, and improving overall narrative coherence.

摘要：大型语言模型（LLM）驱动的角色扮演系统在情感沟通应用中变得越来越有影响力。然而，这些系统容易出现角色错觉，即模型偏离预定义的角色，并生成与预期角色不一致的反应。本文从攻击的角度对角色错觉进行了首次系统分析，引入了 RoleBreak 框架。我们的框架将两个核心机制（查询稀疏性和角色查询冲突）确定为推动角色错觉的关键因素。利用这些见解，我们构建了一个新数据集 RoleBreakEval，以评估现有的错觉缓解技术。我们的实验表明，即使经过训练以最大程度减少错觉的增强模型仍然容易受到攻击。为了解决这些漏洞，我们提出了一种新颖的防御策略，即叙述者模式，它通过叙述生成补充语境来缓解角色查询冲突并提高查询泛化能力。实验结果表明，叙述者模式通过减少错觉、增强对角色和查询的保真度以及提高整体叙事连贯性，明显优于传统的基于拒绝的策略。

##### **PMSS: Pretrained Matrices Skeleton Selection for LLM Fine-tuning**
2409.16722v1 by Qibin Wang, Xiaolin Hu, Weikai Xu, Wei Liu, Jian Luan, Bin Wang

Low-rank adaptation (LoRA) and its variants have recently gained much
interest due to their ability to avoid excessive inference costs. However, LoRA
still encounters the following challenges: (1) Limitation of low-rank
assumption; and (2) Its initialization method may be suboptimal. To this end,
we propose PMSS(Pre-trained Matrices Skeleton Selection), which enables
high-rank updates with low costs while leveraging semantic and linguistic
information inherent in pre-trained weight. It achieves this by selecting
skeletons from the pre-trained weight matrix and only learning a small matrix
instead. Experiments demonstrate that PMSS outperforms LoRA and other
fine-tuning methods across tasks with much less trainable parameters. We
demonstrate its effectiveness, especially in handling complex tasks such as
DROP benchmark(+3.4%/+5.9% on LLaMA2-7B/13B) and math
reasoning(+12.89%/+5.61%/+3.11% on LLaMA2-7B, Mistral-7B and Gemma-7B of
GSM8K). The code and model will be released soon.

摘要：低秩適應 (LoRA) 及其變體最近因其避免過度推理成本的能力而備受關注。然而，LoRA 仍面臨以下挑戰：(1) 低秩假設的限制；以及 (2) 其初始化方法可能次優。為此，我們提出 PMSS（預訓練矩陣骨架選擇），它能夠以低成本進行高秩更新，同時利用預訓練權重中固有的語義和語言信息。它通過從預訓練權重矩陣中選擇骨架並只學習一個小矩陣來實現這一點。實驗表明，PMSS 在具有更少可訓練參數的任務中優於 LoRA 和其他微調方法。我們證明了它的有效性，特別是在處理複雜任務方面，例如 DROP 基準（在 LLaMA2-7B/13B 上+3.4%/+5.9%）和數學推理（在 GSM8K 的 LLaMA2-7B、Mistral-7B 和 Gemma-7B 上+12.89%/+5.61%/+3.11%）。代碼和模型將很快發布。

##### **A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare**
2409.16721v1 by Syed Mohd Faisal Malik, Md Tabrez Nafis, Mohd Abdul Ahad, Safdar Tanweer

In contemporary healthcare, to protect patient data, electronic health
records have become invaluable repositories, creating vast opportunities to
leverage deep learning techniques for predictive analysis. Retinal fundus
images, cirrhosis stages, and heart disease diagnostic predictions have shown
promising results through the integration of deep learning techniques for
classifying diverse datasets. This study proposes a novel deep learning
predictive analysis framework for classifying multiple datasets by
pre-processing data from three distinct sources. A hybrid deep learning model
combining Residual Networks and Artificial Neural Networks is proposed to
detect acute and chronic diseases such as heart diseases, cirrhosis, and
retinal conditions, outperforming existing models. Dataset preparation involves
aspects such as categorical data transformation, dimensionality reduction, and
missing data synthesis. Feature extraction is effectively performed using
scaler transformation for categorical datasets and ResNet architecture for
image datasets. The resulting features are integrated into a unified
classification model. Rigorous experimentation and evaluation resulted in high
accuracies of 93%, 99%, and 95% for retinal fundus images, cirrhosis stages,
and heart disease diagnostic predictions, respectively. The efficacy of the
proposed method is demonstrated through a detailed analysis of F1-score,
precision, and recall metrics. This study offers a comprehensive exploration of
methodologies and experiments, providing in-depth knowledge of deep learning
predictive analysis in electronic health records.

摘要：<paragraph>在當代醫療保健中，為了保護患者數據，電子健康記錄已成為無價的儲存庫，創造了利用深度學習技術進行預測分析的廣闊機會。視網膜眼底圖像、肝硬化分期和心臟病診斷預測已透過整合深度學習技術來分類不同的數據集，顯示出有希望的結果。本研究提出一個新的深度學習預測分析架構，透過預處理來自三個不同來源的數據來分類多個數據集。提出了一個結合殘差網路和人工神經網路的混合深度學習模型，用於檢測急性病和慢性病，例如心臟病、肝硬化和視網膜疾病，其效能優於現有的模型。數據集準備涉及範疇資料轉換、降維和遺失資料合成等方面。特徵萃取使用範疇資料集的縮放器轉換和影像資料集的 ResNet 架構來有效執行。產生的特徵被整合到一個統一的分類模型中。嚴謹的實驗和評估導致視網膜眼底圖像、肝硬化分期和心臟病診斷預測的準確度分別高達 93%、99% 和 95%。所提出方法的有效性透過對 F1 分數、精確度和召回率指標的詳細分析來證明。本研究提供了方法論和實驗的全面探討，深入了解電子健康記錄中的深度學習預測分析。</paragraph>

##### **Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification**
2409.16718v1 by Ming Li, Jike Zhong, Chenxin Li, Liuzhuozheng Li, Nie Lin, Masashi Sugiyama

Recent advances in fine-tuning Vision-Language Models (VLMs) have witnessed
the success of prompt tuning and adapter tuning, while the classic model
fine-tuning on inherent parameters seems to be overlooked. It is believed that
fine-tuning the parameters of VLMs with few-shot samples corrupts the
pre-trained knowledge since fine-tuning the CLIP model even degrades
performance. In this paper, we revisit this viewpoint, and propose a new
perspective: fine-tuning the specific parameters instead of all will uncover
the power of classic model fine-tuning on VLMs. Through our meticulous study,
we propose ClipFit, a simple yet effective method to fine-tune CLIP without
introducing any overhead of extra parameters. We demonstrate that by only
fine-tuning the specific bias terms and normalization layers, ClipFit can
improve the performance of zero-shot CLIP by 7.27\% average harmonic mean
accuracy. Lastly, to understand how fine-tuning in CLIPFit affects the
pre-trained models, we conducted extensive experimental analyses w.r.t. changes
in internal parameters and representations. We found that low-level text bias
layers and the first layer normalization layer change much more than other
layers. The code is available at \url{https://github.com/minglllli/CLIPFit}.

摘要：最近对视觉语言模型 (VLM) 的微调取得了进展，见证了提示微调和适配器微调的成功，而经典模型对固有参数的微调似乎被忽视了。人们认为，用少量样本微调 VLM 的参数会破坏预训练的知识，因为即使微调 CLIP 模型也会降低性能。在本文中，我们重新审视了这个观点，并提出了一个新的观点：微调特定参数而不是所有参数将揭示经典模型微调在 VLM 上的强大功能。通过我们细致的研究，我们提出了 ClipFit，这是一种简单而有效的方法，可以在不引入任何额外参数开销的情况下对 CLIP 进行微调。我们证明，仅通过微调特定的偏差项和归一化层，ClipFit 可以将零样本 CLIP 的性能提高 7.27% 的平均谐波平均准确率。最后，为了了解 ClipFit 中的微调如何影响预训练模型，我们对内部参数和表示的变化进行了广泛的实验分析。我们发现低级文本偏差层和第一层归一化层比其他层变化更大。代码可在 \url{https://github.com/minglllli/CLIPFit} 获得。

##### **Beyond Turing Test: Can GPT-4 Sway Experts' Decisions?**
2409.16710v1 by Takehiro Takayanagi, Hiroya Takamura, Kiyoshi Izumi, Chung-Chi Chen

In the post-Turing era, evaluating large language models (LLMs) involves
assessing generated text based on readers' reactions rather than merely its
indistinguishability from human-produced content. This paper explores how
LLM-generated text impacts readers' decisions, focusing on both amateur and
expert audiences. Our findings indicate that GPT-4 can generate persuasive
analyses affecting the decisions of both amateurs and professionals.
Furthermore, we evaluate the generated text from the aspects of grammar,
convincingness, logical coherence, and usefulness. The results highlight a high
correlation between real-world evaluation through audience reactions and the
current multi-dimensional evaluators commonly used for generative models.
Overall, this paper shows the potential and risk of using generated text to
sway human decisions and also points out a new direction for evaluating
generated text, i.e., leveraging the reactions and decisions of readers. We
release our dataset to assist future research.

摘要：在後圖靈時代，評估大型語言模型 (LLM) 涉及
根據讀者的反應評估產生的文字，而不是僅僅根據其與人類產生的內容是否難以區分。本文探討
LLM 生成的文字如何影響讀者的決策，同時關注業餘和
專業受眾。我們的研究結果表明，GPT-4 可以產生影響業餘人士和專業人士決策的有說服力的分析。
此外，我們從語法、
說服力、邏輯連貫性和有用性方面評估產生的文字。結果強調了通過受眾反應進行的真實世界評估與
當前通常用於生成模型的多維評估器之間的高度相關性。
總的來說，本文展示了使用生成的文字來影響人類決策的潛力和風險，並指出了評估
生成文本的新方向，即利用讀者的反應和決策。我們發布我們的數據集以協助未來的研究。

##### **Probing Omissions and Distortions in Transformer-based RDF-to-Text Models**
2409.16707v1 by Juliette Faille, Albert Gatt, Claire Gardent

In Natural Language Generation (NLG), important information is sometimes
omitted in the output text. To better understand and analyse how this type of
mistake arises, we focus on RDF-to-Text generation and explore two methods of
probing omissions in the encoder output of BART (Lewis et al, 2020) and of T5
(Raffel et al, 2019): (i) a novel parameter-free probing method based on the
computation of cosine similarity between embeddings of RDF graphs and of RDF
graphs in which we removed some entities and (ii) a parametric probe which
performs binary classification on the encoder embeddings to detect omitted
entities. We also extend our analysis to distorted entities, i.e. entities that
are not fully correctly mentioned in the generated text (e.g. misspelling of
entity, wrong units of measurement). We found that both omitted and distorted
entities can be probed in the encoder's output embeddings. This suggests that
the encoder emits a weaker signal for these entities and therefore is
responsible for some loss of information. This also shows that probing methods
can be used to detect mistakes in the output of NLG models.

摘要：在自然語言生成 (NLG) 中，重要資訊有時會在輸出文字中被省略。為了更了解並分析這類錯誤是如何產生的，我們專注於 RDF 轉文字的生成，並探討兩種探測 BART (Lewis 等人，2020) 和 T5 (Raffel 等人，2019) 的編碼器輸出中遺漏的方法：(i) 一種基於 RDF 圖形嵌入和我們移除一些實體的 RDF 圖形之間的餘弦相似度計算的新型無參數探測方法，以及 (ii) 一種在編碼器嵌入中執行二元分類以偵測遺漏實體的參數化探測。我們也將我們的分析延伸到扭曲的實體，也就是在產生的文字中沒有被完全正確提及的實體 (例如實體拼寫錯誤、測量單位錯誤)。我們發現遺漏和扭曲的實體都可以被探測到在編碼器的輸出嵌入中。這表示編碼器針對這些實體發射較弱的訊號，因此導致一些資訊遺失。這也顯示探測方法可以用於偵測 NLG 模型輸出中的錯誤。

##### **Pix2Next: Leveraging Vision Foundation Models for RGB to NIR Image Translation**
2409.16706v1 by Youngwan Jin, Incheol Park, Hanbin Song, Hyeongjin Ju, Yagiz Nalcakan, Shiho Kim

This paper proposes Pix2Next, a novel image-to-image translation framework
designed to address the challenge of generating high-quality Near-Infrared
(NIR) images from RGB inputs. Our approach leverages a state-of-the-art Vision
Foundation Model (VFM) within an encoder-decoder architecture, incorporating
cross-attention mechanisms to enhance feature integration. This design captures
detailed global representations and preserves essential spectral
characteristics, treating RGB-to-NIR translation as more than a simple domain
transfer problem. A multi-scale PatchGAN discriminator ensures realistic image
generation at various detail levels, while carefully designed loss functions
couple global context understanding with local feature preservation. We
performed experiments on the RANUS dataset to demonstrate Pix2Next's advantages
in quantitative metrics and visual quality, improving the FID score by 34.81%
compared to existing methods. Furthermore, we demonstrate the practical utility
of Pix2Next by showing improved performance on a downstream object detection
task using generated NIR data to augment limited real NIR datasets. The
proposed approach enables the scaling up of NIR datasets without additional
data acquisition or annotation efforts, potentially accelerating advancements
in NIR-based computer vision applications.

摘要：本文提出 Pix2Next，這是一個新穎的影像轉換架構，旨在解決從 RGB 輸入產生高品質近紅外線 (NIR) 影像的挑戰。我們的做法在編碼器解碼器架構中利用最先進的 Vision Foundation Model (VFM)，並結合跨注意力機制來增強特徵整合。這種設計擷取了詳細的全局表示，並保留了必要的頻譜特性，將 RGB 轉 NIR 轉換視為不只是單純的網域轉移問題。多尺度 PatchGAN 辨識器確保在各種細節層級中產生逼真的影像，同時精心設計的損失函數將全局脈絡理解與局部特徵保留結合起來。我們在 RANUS 資料集上進行實驗，以展示 Pix2Next 在定量指標和視覺品質方面的優點，與現有方法相比，將 FID 分數提高了 34.81%。此外，我們展示了 Pix2Next 的實際效用，方法是在下游物件偵測任務中顯示使用產生的 NIR 資料來擴充有限的真實 NIR 資料集，從而提高效能。所提出的方法可以在不額外取得資料或標註的情況下擴充 NIR 資料集，這有可能加速基於 NIR 的電腦視覺應用程式的進展。

##### **A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms**
2409.16694v1 by Ruihao Gong, Yifu Ding, Zining Wang, Chengtao Lv, Xingyu Zheng, Jinyang Du, Haotong Qin, Jinyang Guo, Michele Magno, Xianglong Liu

Large language models (LLMs) have achieved remarkable advancements in natural
language processing, showcasing exceptional performance across various tasks.
However, the expensive memory and computational requirements present
significant challenges for their practical deployment. Low-bit quantization has
emerged as a critical approach to mitigate these challenges by reducing the
bit-width of model parameters, activations, and gradients, thus decreasing
memory usage and computational demands. This paper presents a comprehensive
survey of low-bit quantization methods tailored for LLMs, covering the
fundamental principles, system implementations, and algorithmic strategies. An
overview of basic concepts and new data formats specific to low-bit LLMs is
first introduced, followed by a review of frameworks and systems that
facilitate low-bit LLMs across various hardware platforms. Then, we categorize
and analyze techniques and toolkits for efficient low-bit training and
inference of LLMs. Finally, we conclude with a discussion of future trends and
potential advancements of low-bit LLMs. Our systematic overview from basic,
system, and algorithm perspectives can offer valuable insights and guidelines
for future works to enhance the efficiency and applicability of LLMs through
low-bit quantization.

摘要：大型語言模型 (LLM) 在自然語言處理方面取得了顯著進展，在各種任務中展現出卓越的表現。然而，昂貴的記憶體和運算需求對其實際部署構成了重大挑戰。低位元量化已成為緩解這些挑戰的一種關鍵方法，透過減少模型參數、激活和梯度的位元寬度，從而降低記憶體使用量和運算需求。本文對針對 LLM 量身打造的低位元量化方法進行了全面的調查，涵蓋了基本原理、系統實作和演算法策略。首先介紹了低位元 LLM 的基本概念和新的資料格式概觀，接著回顧了在各種硬體平台上促進低位元 LLM 的框架和系統。然後，我們分類和分析了用於有效低位元訓練和推論 LLM 的技術和工具包。最後，我們以討論低位元 LLM 的未來趨勢和潛在進展作為結論。我們從基本、系統和演算法的角度進行系統性概述，可以為透過低位元量化提升 LLM 的效率和適用性的後續工作提供有價值的見解和指導方針。

##### **CaBRNet, an open-source library for developing and evaluating Case-Based Reasoning Models**
2409.16693v1 by Romain Xu-Darme, Aymeric Varasse, Alban Grastien, Julien Girard, Zakaria Chihani

In the field of explainable AI, a vibrant effort is dedicated to the design
of self-explainable models, as a more principled alternative to post-hoc
methods that attempt to explain the decisions after a model opaquely makes
them. However, this productive line of research suffers from common downsides:
lack of reproducibility, unfeasible comparison, diverging standards. In this
paper, we propose CaBRNet, an open-source, modular, backward-compatible
framework for Case-Based Reasoning Networks:
https://github.com/aiser-team/cabrnet.

摘要：在可解釋 AI 領域中，一項充滿活力的工作專注於設計可自解釋模型，作為一種更具原則性的替代方案，用於事後方法，試圖在模型不透明地做出決策後解釋這些決策。然而，這條富有成效的研究路線存在一些常見的缺點：缺乏可重複性、不可行的比較、標準不一。在本文中，我們提出 CaBRNet，這是一個開源、模組化、向後相容的框架，用於基於案例的推理網路：
https://github.com/aiser-team/cabrnet。

##### **Layout-Corrector: Alleviating Layout Sticking Phenomenon in Discrete Diffusion Model**
2409.16689v1 by Shoma Iwai, Atsuki Osanai, Shunsuke Kitada, Shinichiro Omachi

Layout generation is a task to synthesize a harmonious layout with elements
characterized by attributes such as category, position, and size. Human
designers experiment with the placement and modification of elements to create
aesthetic layouts, however, we observed that current discrete diffusion models
(DDMs) struggle to correct inharmonious layouts after they have been generated.
In this paper, we first provide novel insights into layout sticking phenomenon
in DDMs and then propose a simple yet effective layout-assessment module
Layout-Corrector, which works in conjunction with existing DDMs to address the
layout sticking problem. We present a learning-based module capable of
identifying inharmonious elements within layouts, considering overall layout
harmony characterized by complex composition. During the generation process,
Layout-Corrector evaluates the correctness of each token in the generated
layout, reinitializing those with low scores to the ungenerated state. The DDM
then uses the high-scored tokens as clues to regenerate the harmonized tokens.
Layout-Corrector, tested on common benchmarks, consistently boosts
layout-generation performance when in conjunction with various state-of-the-art
DDMs. Furthermore, our extensive analysis demonstrates that the
Layout-Corrector (1) successfully identifies erroneous tokens, (2) facilitates
control over the fidelity-diversity trade-off, and (3) significantly mitigates
the performance drop associated with fast sampling.

摘要：版面生成是綜合元素的一項任務，這些元素的特徵在於類別、位置和大小等屬性。人類設計師會嘗試元素的擺放和修改，以建立美觀的版面，然而，我們觀察到目前的離散擴散模型 (DDM) 在生成不協調的版面後，難以進行修正。在本文中，我們首先提供對 DDM 中版面黏著現象的新見解，然後提出一個簡單但有效的版面評估模組 Layout-Corrector，它與現有的 DDM 協同運作，以解決版面黏著問題。我們提出一個基於學習的模組，能夠識別版面中的不協調元素，並考量由複雜組合所特徵化的整體版面和諧性。在生成過程中，Layout-Corrector 評估生成版面中每個標記的正確性，將評分較低的標記重新初始化為未生成狀態。然後，DDM 使用高分標記作為線索，重新生成和諧的標記。Layout-Corrector 在常見的基準測試中經過測試，與各種最先進的 DDM 結合使用時，始終提升版面生成效能。此外，我們廣泛的分析證明，Layout-Corrector (1) 成功識別錯誤標記，(2) 促進對保真度和多樣性權衡的控制，以及 (3) 大幅減輕與快速取樣相關的效能下降。

##### **MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making**
2409.16686v1 by Dayuan Fu, Biqing Qi, Yihuai Gao, Che Jiang, Guanting Dong, Bowen Zhou

Long-term memory is significant for agents, in which insights play a crucial
role. However, the emergence of irrelevant insight and the lack of general
insight can greatly undermine the effectiveness of insight. To solve this
problem, in this paper, we introduce Multi-Scale Insight Agent (MSI-Agent), an
embodied agent designed to improve LLMs' planning and decision-making ability
by summarizing and utilizing insight effectively across different scales. MSI
achieves this through the experience selector, insight generator, and insight
selector. Leveraging a three-part pipeline, MSI can generate task-specific and
high-level insight, store it in a database, and then use relevant insight from
it to aid in decision-making. Our experiments show that MSI outperforms another
insight strategy when planning by GPT3.5. Moreover, We delve into the
strategies for selecting seed experience and insight, aiming to provide LLM
with more useful and relevant insight for better decision-making. Our
observations also indicate that MSI exhibits better robustness when facing
domain-shifting scenarios.

摘要：長期記憶對於智能體來說非常重要，其中見解扮演著關鍵角色。然而，無關見解的出現和一般見解的缺乏會極大地損害見解的有效性。為了解決這個問題，在本文中，我們介紹了多尺度見解智能體 (MSI-Agent)，這是一個具象智能體，旨在透過有效地總結和利用不同尺度的見解來改善 LLM 的規劃和決策能力。MSI 透過經驗選擇器、見解產生器和見解選擇器來實現這一點。MSI 利用一個由三部分組成的管線，可以產生特定於任務和高層級的見解，將其儲存在資料庫中，然後從中使用相關見解來協助決策。我們的實驗顯示，MSI 在 GPT3.5 規劃時優於其他見解策略。此外，我們深入探討了選擇種子經驗和見解的策略，旨在為 LLM 提供更有用且相關的見解，以做出更好的決策。我們的觀察結果還表明，MSI 在面對領域轉換場景時表現出更好的穩健性。

##### **Erase then Rectify: A Training-Free Parameter Editing Approach for Cost-Effective Graph Unlearning**
2409.16684v1 by Zhe-Rui Yang, Jindong Han, Chang-Dong Wang, Hao Liu

Graph unlearning, which aims to eliminate the influence of specific nodes,
edges, or attributes from a trained Graph Neural Network (GNN), is essential in
applications where privacy, bias, or data obsolescence is a concern. However,
existing graph unlearning techniques often necessitate additional training on
the remaining data, leading to significant computational costs, particularly
with large-scale graphs. To address these challenges, we propose a two-stage
training-free approach, Erase then Rectify (ETR), designed for efficient and
scalable graph unlearning while preserving the model utility. Specifically, we
first build a theoretical foundation showing that masking parameters critical
for unlearned samples enables effective unlearning. Building on this insight,
the Erase stage strategically edits model parameters to eliminate the impact of
unlearned samples and their propagated influence on intercorrelated nodes. To
further ensure the GNN's utility, the Rectify stage devises a gradient
approximation method to estimate the model's gradient on the remaining dataset,
which is then used to enhance model performance. Overall, ETR achieves graph
unlearning without additional training or full training data access,
significantly reducing computational overhead and preserving data privacy.
Extensive experiments on seven public datasets demonstrate the consistent
superiority of ETR in model utility, unlearning efficiency, and unlearning
effectiveness, establishing it as a promising solution for real-world graph
unlearning challenges.

摘要：圖表反學習旨在消除特定節點、邊緣或屬性對已訓練圖神經網路 (GNN) 的影響，在隱私、偏見或資料過時為問題的應用中至關重要。然而，現有的圖表反學習技術通常需要對剩餘資料進行額外訓練，導致顯著的運算成本，特別是在大型圖表中。為了應對這些挑戰，我們提出了一個兩階段免訓練方法，即先擦除再修正 (ETR)，旨在實現高效且可擴充的圖表反學習，同時保留模型效用。具體來說，我們首先建立一個理論基礎，表明遮罩對未學習樣本至關重要的參數可以實現有效的反學習。根據這個見解，擦除階段策略性地編輯模型參數，以消除未學習樣本及其對相互關聯節點的傳播影響。為了進一步確保 GNN 的效用，修正階段設計了一種梯度近似方法來估計模型在剩餘資料集上的梯度，然後用於增強模型效能。總體而言，ETR 在沒有額外訓練或完全訓練資料存取的情況下實現了圖表反學習，顯著降低了運算負擔並維護了資料隱私。在七個公開資料集上的廣泛實驗證明了 ETR 在模型效用、反學習效率和反學習有效性方面的一致優越性，使其成為解決現實世界圖表反學習挑戰的有希望的解決方案。

##### **SynTQA: Synergistic Table-based Question Answering via Mixture of Text-to-SQL and E2E TQA**
2409.16682v1 by Siyue Zhang, Anh Tuan Luu, Chen Zhao

Text-to-SQL parsing and end-to-end question answering (E2E TQA) are two main
approaches for Table-based Question Answering task. Despite success on multiple
benchmarks, they have yet to be compared and their synergy remains unexplored.
In this paper, we identify different strengths and weaknesses through
evaluating state-of-the-art models on benchmark datasets: Text-to-SQL
demonstrates superiority in handling questions involving arithmetic operations
and long tables; E2E TQA excels in addressing ambiguous questions, non-standard
table schema, and complex table contents. To combine both strengths, we propose
a Synergistic Table-based Question Answering approach that integrate different
models via answer selection, which is agnostic to any model types. Further
experiments validate that ensembling models by either feature-based or
LLM-based answer selector significantly improves the performance over
individual models.

摘要：文本到 SQL 解析和端到端問題解答 (E2E TQA) 是表格問題解答任務的兩種主要方法。儘管在多個基準測試中取得成功，但它們尚未進行比較，而且它們的協同作用仍未得到探索。在本文中，我們通過評估基準數據集上的最先進模型來識別不同的優勢和劣勢：文本到 SQL 在處理涉及算術運算和長表的查詢方面表現出優越性；E2E TQA 在解決模稜兩可的查詢、非標準表格架構和複雜表格內容方面表現出色。為了結合這兩種優勢，我們提出了一種協同表格問題解答方法，該方法通過與任何模型類型無關的答案選擇整合不同的模型。進一步的實驗驗證了通過基於特徵或基於 LLM 的答案選擇器組合模型顯著優於單個模型的性能。

##### **Emotional Dimension Control in Language Model-Based Text-to-Speech: Spanning a Broad Spectrum of Human Emotions**
2409.16681v1 by Kun Zhou, You Zhang, Shengkui Zhao, Hao Wang, Zexu Pan, Dianwen Ng, Chong Zhang, Chongjia Ni, Yukun Ma, Trung Hieu Nguyen, Jia Qi Yip, Bin Ma

Current emotional text-to-speech (TTS) systems face challenges in mimicking a
broad spectrum of human emotions due to the inherent complexity of emotions and
limitations in emotional speech datasets and models. This paper proposes a TTS
framework that facilitates control over pleasure, arousal, and dominance, and
can synthesize a diversity of emotional styles without requiring any emotional
speech data during TTS training. We train an emotional attribute predictor
using only categorical labels from speech data, aligning with psychological
research and incorporating anchored dimensionality reduction on self-supervised
learning (SSL) features. The TTS framework converts text inputs into phonetic
tokens via an autoregressive language model and uses pseudo-emotional
dimensions to guide the parallel prediction of fine-grained acoustic details.
Experiments conducted on the LibriTTS dataset demonstrate that our framework
can synthesize speech with enhanced naturalness and a variety of emotional
styles by effectively controlling emotional dimensions, even without the
inclusion of any emotional speech during TTS training.

摘要：當前的語音合成（TTS）系統在模擬人類廣泛的情緒時會面臨挑戰，原因在於情緒的複雜性以及情緒化語音資料集和模型的限制。本論文提出了一個 TTS 架構，可以輕鬆控制愉悅、激動和支配，且無需在 TTS 訓練期間使用任何情緒化語音資料就能合成各種情緒風格。我們只使用語音資料中的分類標籤訓練情緒屬性預測器，並與心理學研究相符，並將錨定降維納入自監督學習（SSL）功能。TTS 架構透過自迴歸語言模型將文字輸入轉換為音標符號，並使用偽情緒維度來引導對細緻聲學細節的並行預測。在 LibriTTS 資料集上進行的實驗表明，我們的架構可以合成自然度更高的語音和各種情緒風格，即使在 TTS 訓練期間沒有加入任何情緒化語音也能有效控制情緒維度。

##### **TSBP: Improving Object Detection in Histology Images via Test-time Self-guided Bounding-box Propagation**
2409.16678v1 by Tingting Yang, Liang Xiao, Yizhe Zhang

A global threshold (e.g., 0.5) is often applied to determine which bounding
boxes should be included in the final results for an object detection task. A
higher threshold reduces false positives but may result in missing a
significant portion of true positives. A lower threshold can increase detection
recall but may also result in more false positives. Because of this, using a
preset global threshold (e.g., 0.5) applied to all the bounding box candidates
may lead to suboptimal solutions. In this paper, we propose a Test-time
Self-guided Bounding-box Propagation (TSBP) method, leveraging Earth Mover's
Distance (EMD) to enhance object detection in histology images. TSBP utilizes
bounding boxes with high confidence to influence those with low confidence,
leveraging visual similarities between them. This propagation mechanism enables
bounding boxes to be selected in a controllable, explainable, and robust
manner, which surpasses the effectiveness of using simple thresholds and
uncertainty calibration methods. Importantly, TSBP does not necessitate
additional labeled samples for model training or parameter estimation, unlike
calibration methods. We conduct experiments on gland detection and cell
detection tasks in histology images. The results show that our proposed TSBP
significantly improves detection outcomes when working in conjunction with
state-of-the-art deep learning-based detection networks. Compared to other
methods such as uncertainty calibration, TSBP yields more robust and accurate
object detection predictions while using no additional labeled samples. The
code is available at https://github.com/jwhgdeu/TSBP.

摘要：<paragraph>在目標偵測任務中，通常會套用一個全域閾值（例如 0.5）來決定哪些邊界框應包含在最終結果中。較高的閾值會降低誤報，但可能會導致遺漏大量真陽性。較低的閾值會提高偵測召回率，但也可能導致更多誤報。因此，將預設的全域閾值（例如 0.5）套用至所有邊界框候選項可能會導致次佳解。在本文中，我們提出一個測試時間自導邊界框傳播 (TSBP) 方法，利用 Earth Mover's Distance (EMD) 來增強組織學影像中的目標偵測。TSBP 利用高信心的邊界框來影響低信心的邊界框，並利用它們之間的視覺相似性。這種傳播機制讓邊界框能夠以可控、可解釋且穩健的方式進行選擇，這超越了使用簡單閾值和不確定性校正方法的有效性。重要的是，與校正方法不同，TSBP 不需要額外標記樣本進行模型訓練或參數估計。我們針對組織學影像中的腺體偵測和細胞偵測任務進行實驗。結果顯示，我們提出的 TSBP 在與最先進的基於深度學習的偵測網路結合使用時，顯著改善了偵測結果。與其他方法（例如不確定性校正）相比，TSBP 在不使用任何額外標記樣本的情況下，產生更穩健且準確的目標偵測預測。程式碼可於 https://github.com/jwhgdeu/TSBP 取得。</paragraph>

##### **SWE2: SubWord Enriched and Significant Word Emphasized Framework for Hate Speech Detection**
2409.16673v1 by Guanyi Mou, Pengyi Ye, Kyumin Lee

Hate speech detection on online social networks has become one of the
emerging hot topics in recent years. With the broad spread and fast propagation
speed across online social networks, hate speech makes significant impacts on
society by increasing prejudice and hurting people. Therefore, there are
aroused attention and concern from both industry and academia. In this paper,
we address the hate speech problem and propose a novel hate speech detection
framework called SWE2, which only relies on the content of messages and
automatically identifies hate speech. In particular, our framework exploits
both word-level semantic information and sub-word knowledge. It is intuitively
persuasive and also practically performs well under a situation with/without
character-level adversarial attack. Experimental results show that our proposed
model achieves 0.975 accuracy and 0.953 macro F1, outperforming 7
state-of-the-art baselines under no adversarial attack. Our model robustly and
significantly performed well under extreme adversarial attack (manipulation of
50% messages), achieving 0.967 accuracy and 0.934 macro F1.

摘要：近幾年來，在線上社群網路中，仇恨言論偵測已成為新興熱門議題之一。仇恨言論在線上社群網路中廣泛散佈和快速傳播，透過加劇偏見和傷害他人，對社會造成重大影響。因此，無論是業界或學術界都引起了關注和重視。在本文中，我們探討仇恨言論問題，並提出一個名為 SWE2 的全新仇恨言論偵測架構，它僅依賴訊息內容，並自動辨識仇恨言論。特別是，我們的架構同時利用字詞層級的語意資訊和字詞知識。它直觀且具有說服力，在有/無字元層級對抗攻擊的情況下，實際執行效果也很好。實驗結果顯示，我們提出的模型在沒有對抗攻擊的情況下，達到了 0.975 的準確度和 0.953 的巨集 F1，優於 7 個最先進的基準。我們的模型在極端的對抗攻擊（50% 訊息遭竄改）下表現得相當穩健且出色，達到了 0.967 的準確度和 0.934 的巨集 F1。

##### **GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning**
2409.16670v1 by Zhe-Rui Yang, Jindong Han, Chang-Dong Wang, Hao Liu

Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in
handling a range of graph analytical tasks across various domains, such as
e-commerce and social networks. Despite their versatility, GNNs face
significant challenges in transferability, limiting their utility in real-world
applications. Existing research in GNN transfer learning overlooks
discrepancies in distribution among various graph datasets, facing challenges
when transferring across different distributions. How to effectively adopt a
well-trained GNN to new graphs with varying feature and structural
distributions remains an under-explored problem. Taking inspiration from the
success of Low-Rank Adaptation (LoRA) in adapting large language models to
various domains, we propose GraphLoRA, an effective and parameter-efficient
method for transferring well-trained GNNs to diverse graph domains.
Specifically, we first propose a Structure-aware Maximum Mean Discrepancy
(SMMD) to align divergent node feature distributions across source and target
graphs. Moreover, we introduce low-rank adaptation by injecting a small
trainable GNN alongside the pre-trained one, effectively bridging structural
distribution gaps while mitigating the catastrophic forgetting. Additionally, a
structure-aware regularization objective is proposed to enhance the
adaptability of the pre-trained GNN to target graph with scarce supervision
labels. Extensive experiments on six real-world datasets demonstrate the
effectiveness of GraphLoRA against eleven baselines by tuning only 20% of
parameters, even across disparate graph domains. The code is available at
https://anonymous.4open.science/r/GraphLoRA.

摘要：圖形神經網路 (GNN) 已展現出在各種領域處理一系列圖形分析任務的卓越能力，例如電子商務和社群網路。儘管 GNN 具有多功能性，但在可轉移性方面仍面臨重大挑戰，限制了它們在現實世界應用中的效用。現有的 GNN 轉移學習研究忽視了各種圖形資料集之間的分布差異，在跨不同分布轉移時面臨挑戰。如何有效地將訓練良好的 GNN 應用於具有不同特徵和結構分布的新圖形，仍然是一個尚未充分探討的問題。從低秩適應 (LoRA) 在將大型語言模型適應到各種領域方面獲得的成功中汲取靈感，我們提出了 GraphLoRA，這是一種有效且參數效率高的方法，可用於將訓練良好的 GNN 轉移到不同的圖形領域。具體來說，我們首先提出一個結構感知最大平均差異 (SMMD) 來調整來源和目標圖形中的不同節點特徵分布。此外，我們通過在預先訓練的 GNN 旁邊注入一個小的可訓練 GNN 來引入低秩適應，從而有效地彌合結構分布差距，同時減輕災難性遺忘。此外，還提出了結構感知正則化目標，以增強預先訓練的 GNN 對具有稀疏監督標籤的目標圖形的適應性。在六個真實世界資料集上的大量實驗證明了 GraphLoRA 的有效性，它僅調整了 20% 的參數，即使在不同的圖形領域中也能夠勝過十一種基準。程式碼可在 https://anonymous.4open.science/r/GraphLoRA 取得。

##### **Topic-aware Causal Intervention for Counterfactual Detection**
2409.16668v1 by Thong Nguyen, Truc-My Nguyen

Counterfactual statements, which describe events that did not or cannot take
place, are beneficial to numerous NLP applications. Hence, we consider the
problem of counterfactual detection (CFD) and seek to enhance the CFD models.
Previous models are reliant on clue phrases to predict counterfactuality, so
they suffer from significant performance drop when clue phrase hints do not
exist during testing. Moreover, these models tend to predict
non-counterfactuals over counterfactuals. To address these issues, we propose
to integrate neural topic model into the CFD model to capture the global
semantics of the input statement. We continue to causally intervene the hidden
representations of the CFD model to balance the effect of the class labels.
Extensive experiments show that our approach outperforms previous
state-of-the-art CFD and bias-resolving methods in both the CFD and other
bias-sensitive tasks.

摘要：反事實陳述描述了未發生或無法發生的事件，對許多 NLP 應用有益。因此，我們考慮反事實檢測 (CFD) 的問題，並尋求增強 CFD 模型。先前的模型依賴於線索短語來預測反事實，因此在測試期間沒有線索短語提示時，它們的效能會大幅下降。此外，這些模型傾向於預測非反事實而不是反事實。為了解決這些問題，我們建議將神經主題模型整合到 CFD 模型中，以擷取輸入陳述的整體語義。我們繼續因果干預 CFD 模型的隱藏表示，以平衡類別標籤的影響。廣泛的實驗表明，我們的做法在 CFD 和其他偏見敏感任務中都優於先前的最先進 CFD 和偏見解決方法。

##### **A Character-Centric Creative Story Generation via Imagination**
2409.16667v1 by Kyeongman Park, Minbeom Kim, Kyomin Jung

Creative story generation with diverse and detailed story elements is a
long-standing goal for large language models. While existing methodologies
generate long and coherent stories, they fall significantly short of human
capabilities in terms of diversity and character detail. To address this, we
introduce a novel story generation framework called CCI (Character-centric
Creative story generation via Imagination). CCI features two innovative modules
for creative story generation: IG (Image-Guided Imagination) and MW
(Multi-Writer model). In the IG module, we utilize DALL-E 3 to create visual
representations of key story elements. The IG generates more novel and concrete
characters, backgrounds, and main plots than text-only methods. The MW module
uses these story elements created by IG to generate multiple description
candidates for the protagonist and select the best one. This method
incorporates vivid and rich character descriptions into the story. We compared
the stories generated by CCI and baseline models through human evaluation and
statistical analysis. The results showed significant improvements in the
creativity. Furthermore, by enabling interactive multi-modal story generation
with users, we have opened up possibilities for human-LLM integration in
cultural development.

摘要：運用多元且詳細的故事元素進行創意故事生成，一直是大型語言模型的長期目標。儘管現有的方法論可產生長篇且連貫的故事，但在多元性和角色細節方面，卻遠遠不及人類的能力。為了解決這個問題，我們提出一個名為 CCI（以角色為中心，透過想像進行創意故事生成）的新穎故事生成架構。CCI 具備兩個用於創意故事生成的創新模組：IG（影像引導想像）和 MW（多作者模型）。在 IG 模組中，我們利用 DALL-E 3 來建立關鍵故事元素的視覺表示。IG 產生的角色、背景和主線劇情，比純文字方法更新穎且具體。MW 模組使用 IG 建立的這些故事元素，為主角產生多個描述候選，並選出最佳者。此方法將生動且豐富的角色描述納入故事中。我們透過人工評估和統計分析，比較了 CCI 和基準模型所產生的故事。結果顯示在創意方面有顯著的進步。此外，透過啟用與使用者互動的多模態故事生成，我們開啟了人類與大型語言模型在文化發展中整合的可能性。

##### **Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts**
2409.16658v1 by Taehun Cha, Donghun Lee

In this work, we show the pre-trained language models return distinguishable
generation probability and uncertainty distribution to unfaithfully
hallucinated texts, regardless of their size and structure. By examining 24
models on 6 data sets, we find out that 88-98% of cases return statistically
significantly distinguishable generation probability and uncertainty
distributions. Using this general phenomenon, we showcase a
hallucination-reducing training algorithm. Our algorithm outperforms other
baselines by achieving higher faithfulness metrics while maintaining sound
general text quality measures.

摘要：在這項工作中，我們展示了預訓練的語言模型，無論其大小和結構如何，都返回可區分的生成機率和不確定性分佈，以不忠實地虛構文本。透過檢視 6 個資料集上的 24 個模型，我們發現 88-98% 的案例回傳具有統計顯著區別的生成機率和不確定性分佈。使用這個一般現象，我們展示了一個減少虛構的訓練演算法。我們的演算法在維持良好的文字品質測量標準的同時，透過達成更高的忠實度指標，勝過其他基準。

##### **Speech Recognition Rescoring with Large Speech-Text Foundation Models**
2409.16654v1 by Prashanth Gurunath Shivakumar, Jari Kolehmainen, Aditya Gourav, Yi Gu, Ankur Gandhe, Ariya Rastrow, Ivan Bulyko

Large language models (LLM) have demonstrated the ability to understand human
language by leveraging large amount of text data. Automatic speech recognition
(ASR) systems are often limited by available transcribed speech data and
benefit from a second pass rescoring using LLM. Recently multi-modal large
language models, particularly speech and text foundational models have
demonstrated strong spoken language understanding. Speech-Text foundational
models leverage large amounts of unlabelled and labelled data both in speech
and text modalities to model human language. In this work, we propose novel
techniques to use multi-modal LLM for ASR rescoring. We also explore
discriminative training to further improve the foundational model rescoring
performance. We demonstrate cross-modal knowledge transfer in speech-text LLM
can benefit rescoring. Our experiments demonstrate up-to 20% relative
improvements over Whisper large ASR and up-to 15% relative improvements over
text-only LLM.

摘要：大型語言模型 (LLM) 已展現出透過大量文字資料理解人類語言的能力。自動語音辨識 (ASR) 系統通常受到可用轉錄語音資料的限制，並受益於使用 LLM 進行二次評分。最近，多模態大型語言模型，特別是語音和文字基礎模型，已展現出強大的口語理解能力。語音文字基礎模型利用大量未標記和標記資料，在語音和文字模式中建構人類語言模型。在這項工作中，我們提出使用多模態 LLM 進行 ASR 評分的新技術。我們也探討判別訓練，以進一步改善基礎模型的評分表現。我們證明語音文字 LLM 中的跨模態知識轉移可以改善評分。我們的實驗證明，相較於 Whisper 大型 ASR，我們的模型有高達 20% 的相對改善；相較於純文字 LLM，我們的模型有高達 15% 的相對改善。

##### **Progressive Representation Learning for Real-Time UAV Tracking**
2409.16652v1 by Changhong Fu, Xiang Lei, Haobo Zuo, Liangliang Yao, Guangze Zheng, Jia Pan

Visual object tracking has significantly promoted autonomous applications for
unmanned aerial vehicles (UAVs). However, learning robust object
representations for UAV tracking is especially challenging in complex dynamic
environments, when confronted with aspect ratio change and occlusion. These
challenges severely alter the original information of the object. To handle the
above issues, this work proposes a novel progressive representation learning
framework for UAV tracking, i.e., PRL-Track. Specifically, PRL-Track is divided
into coarse representation learning and fine representation learning. For
coarse representation learning, two innovative regulators, which rely on
appearance and semantic information, are designed to mitigate appearance
interference and capture semantic information. Furthermore, for fine
representation learning, a new hierarchical modeling generator is developed to
intertwine coarse object representations. Exhaustive experiments demonstrate
that the proposed PRL-Track delivers exceptional performance on three
authoritative UAV tracking benchmarks. Real-world tests indicate that the
proposed PRL-Track realizes superior tracking performance with 42.6 frames per
second on the typical UAV platform equipped with an edge smart camera. The
code, model, and demo videos are available at
\url{https://github.com/vision4robotics/PRL-Track}.

摘要：視覺物件追蹤已大幅提升無人機 (UAV) 的自主應用。然而，在複雜的動態環境中，學習穩健的物件表示以進行無人機追蹤特別具有挑戰性，特別是在面對長寬比變動和遮擋時。這些挑戰會嚴重改變物件的原始資訊。為了處理上述問題，這項研究提出一個新的漸進式表示學習架構以進行無人機追蹤，亦即 PRL-Track。具體來說，PRL-Track 分為粗略表示學習和精細表示學習。對於粗略表示學習，設計了兩個創新的調節器，它們依賴於外觀和語義資訊，以減輕外觀干擾並擷取語義資訊。此外，對於精細表示學習，開發了一個新的階層式建模產生器，以交織粗略物件表示。詳盡的實驗證明，所提出的 PRL-Track 在三個權威的無人機追蹤基準上提供了非凡的效能。真實世界的測試表明，所提出的 PRL-Track 在配備邊緣智慧相機的典型無人機平台上以每秒 42.6 幀的速度實現了優異的追蹤效能。程式碼、模型和示範影片可在 \url{https://github.com/vision4robotics/PRL-Track} 取得。

##### **Domain-Independent Automatic Generation of Descriptive Texts for Time-Series Data**
2409.16647v1 by Kota Dohi, Aoi Ito, Harsh Purohit, Tomoya Nishida, Takashi Endo, Yohei Kawaguchi

Due to scarcity of time-series data annotated with descriptive texts,
training a model to generate descriptive texts for time-series data is
challenging. In this study, we propose a method to systematically generate
domain-independent descriptive texts from time-series data. We identify two
distinct approaches for creating pairs of time-series data and descriptive
texts: the forward approach and the backward approach. By implementing the
novel backward approach, we create the Temporal Automated Captions for
Observations (TACO) dataset. Experimental results demonstrate that a
contrastive learning based model trained using the TACO dataset is capable of
generating descriptive texts for time-series data in novel domains.

摘要：由於標有描述文字的時間序列資料稀少，訓練模型來為時間序列資料產生描述文字是一項挑戰。在本研究中，我們提出了一種從時間序列資料系統性產生與領域無關的描述文字的方法。我們找出兩種不同的方法來建立時間序列資料和描述文字的配對：正向方法和反向方法。透過實作新穎的反向方法，我們建立了觀測時間自動標題 (TACO) 資料集。實驗結果證明，使用 TACO 資料集訓練的對比學習模型能夠為新領域的時間序列資料產生描述文字。

##### **Cross-Lingual and Cross-Cultural Variation in Image Descriptions**
2409.16646v1 by Uri Berger, Edoardo M. Ponti

Do speakers of different languages talk differently about what they see?
Behavioural and cognitive studies report cultural effects on perception;
however, these are mostly limited in scope and hard to replicate. In this work,
we conduct the first large-scale empirical study of cross-lingual variation in
image descriptions. Using a multimodal dataset with 31 languages and images
from diverse locations, we develop a method to accurately identify entities
mentioned in captions and present in the images, then measure how they vary
across languages. Our analysis reveals that pairs of languages that are
geographically or genetically closer tend to mention the same entities more
frequently. We also identify entity categories whose saliency is universally
high (such as animate beings), low (clothing accessories) or displaying high
variance across languages (landscape). In a case study, we measure the
differences in a specific language pair (e.g., Japanese mentions clothing far
more frequently than English). Furthermore, our method corroborates previous
small-scale studies, including 1) Rosch et al. (1976)'s theory of basic-level
categories, demonstrating a preference for entities that are neither too
generic nor too specific, and 2) Miyamoto et al. (2006)'s hypothesis that
environments afford patterns of perception, such as entity counts. Overall, our
work reveals the presence of both universal and culture-specific patterns in
entity mentions.

摘要：不同語言的說話者，對於他們所看到的事物，是否會有不同的談論方式？
行為和認知研究報告了文化對認知的影響；
然而，這些影響大多範圍有限，且難以複製。在本文中，
我們進行了第一個關於跨語言影像描述變化的廣泛實證研究。使用一個包含 31 種語言和來自不同地點的影像的多模態資料集，我們開發了一個方法來準確識別說明文字中提到的實體，並顯示在影像中，然後測量它們在不同語言中的變化。我們的分析顯示，地理或遺傳上較接近的語言對，傾向於更頻繁地提及相同的實體。我們還識別出顯著性普遍較高（例如有生命的生物）、較低（服裝配件）或在不同語言中顯示出高變異性的實體類別（景觀）。在一個案例研究中，我們測量特定語言對的差異（例如，日文比英文更頻繁地提及服裝）。此外，我們的研究方法證實了先前的中小型研究，包括 1) Rosch et al. (1976) 的基本層級類別理論，證明了對既不太過概括也不太過具體的實體的偏好，以及 2) Miyamoto et al. (2006) 的假設，即環境提供了認知模式，例如實體計數。總的來說，我們的研究揭示了實體提及中普遍和特定於文化的模式的存在。

##### **Task Addition in Multi-Task Learning by Geometrical Alignment**
2409.16645v1 by Soorin Yim, Dae-Woong Jeong, Sung Moon Ko, Sumin Lee, Hyunseung Kim, Chanhui Lee, Sehui Han

Training deep learning models on limited data while maintaining
generalization is one of the fundamental challenges in molecular property
prediction. One effective solution is transferring knowledge extracted from
abundant datasets to those with scarce data. Recently, a novel algorithm called
Geometrically Aligned Transfer Encoder (GATE) has been introduced, which uses
soft parameter sharing by aligning the geometrical shapes of task-specific
latent spaces. However, GATE faces limitations in scaling to multiple tasks due
to computational costs. In this study, we propose a task addition approach for
GATE to improve performance on target tasks with limited data while minimizing
computational complexity. It is achieved through supervised multi-task
pre-training on a large dataset, followed by the addition and training of
task-specific modules for each target task. Our experiments demonstrate the
superior performance of the task addition strategy for GATE over conventional
multi-task methods, with comparable computational costs.

摘要：在保持泛化的同時，使用有限數據訓練深度學習模型是分子性質預測中的基本挑戰之一。一個有效的解決方案是將從豐富的數據集中提取的知識轉移到數據稀缺的數據集中。最近，一種名為幾何對齊傳輸編碼器 (GATE) 的新演算法已經被引入，它通過對齊特定於任務的潛在空間的幾何形狀來使用軟參數共享。然而，GATE 由於計算成本，在擴展到多個任務時面臨限制。在本研究中，我們提出了一種任務添加方法，用於 GATE 以提高目標任務在數據有限的情況下的性能，同時最小化計算複雜度。它是通過在大型數據集上進行監督式多任務預訓練，然後為每個目標任務添加和訓練特定於任務的模組來實現的。我們的實驗證明了任務添加策略對 GATE 的優異性能優於傳統的多任務方法，並且具有可比較的計算成本。

##### **Enabling Auditory Large Language Models for Automatic Speech Quality Evaluation**
2409.16644v1 by Siyin Wang, Wenyi Yu, Yudong Yang, Changli Tang, Yixuan Li, Jimin Zhuang, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Guangzhi Sun, Lu Lu, Chao Zhang

Speech quality assessment typically requires evaluating audio from multiple
aspects, such as mean opinion score (MOS) and speaker similarity (SIM) etc.,
which can be challenging to cover using one small model designed for a single
task. In this paper, we propose leveraging recently introduced auditory large
language models (LLMs) for automatic speech quality assessment. By employing
task-specific prompts, auditory LLMs are finetuned to predict MOS, SIM and A/B
testing results, which are commonly used for evaluating text-to-speech systems.
Additionally, the finetuned auditory LLM is able to generate natural language
descriptions assessing aspects like noisiness, distortion, discontinuity, and
overall quality, providing more interpretable outputs. Extensive experiments
have been performed on the NISQA, BVCC, SOMOS and VoxSim speech quality
datasets, using open-source auditory LLMs such as SALMONN, Qwen-Audio, and
Qwen2-Audio. For the natural language descriptions task, a commercial model
Google Gemini 1.5 Pro is also evaluated. The results demonstrate that auditory
LLMs achieve competitive performance compared to state-of-the-art task-specific
small models in predicting MOS and SIM, while also delivering promising results
in A/B testing and natural language descriptions. Our data processing scripts
and finetuned model checkpoints will be released upon acceptance.

摘要：語音品質評估通常需要從多個面向評估音訊，例如平均意見分數 (MOS) 和說話者相似度 (SIM) 等，而使用針對單一任務設計的小型模型來涵蓋這些面向可能會是一項挑戰。在本文中，我們提議利用最近推出的聽覺大型語言模型 (LLM) 來進行自動語音品質評估。透過採用特定於任務的提示，聽覺 LLM 會經過微調，以預測 MOS、SIM 和 A/B 測試結果，這些結果通常用於評估文字轉語音系統。此外，經過微調的聽覺 LLM 能夠產生自然語言描述，評估雜訊、失真、不連續性以及整體品質等面向，提供更易於理解的輸出。我們已經在 NISQA、BVCC、SOMOS 和 VoxSim 語音品質資料集上執行廣泛的實驗，使用 SALMONN、Qwen-Audio 和 Qwen2-Audio 等開源聽覺 LLM。對於自然語言描述任務，我們也評估了商用模型 Google Gemini 1.5 Pro。結果顯示，與針對特定任務的最新小型模型相比，聽覺 LLM 在預測 MOS 和 SIM 時達到了有競爭力的效能，同時在 A/B 測試和自然語言描述中也提供了有希望的結果。我們的資料處理腳本和經過微調的模型檢查點將在獲得接受後釋出。

##### **Training Language Models to Win Debates with Self-Play Improves Judge Accuracy**
2409.16636v1 by Samuel Arnesen, David Rein, Julian Michael

We test the robustness of debate as a method of scalable oversight by
training models to debate with data generated via self-play. In a long-context
reading comprehension task, we find that language model based evaluators answer
questions more accurately when judging models optimized to win debates. By
contrast, we find no such relationship for consultancy models trained to
persuade a judge without an opposing debater present. In quantitative and
qualitative comparisons between our debate models and novel consultancy
baselines, we find evidence that debate training encourages stronger and more
informative arguments, showing promise that it can help provide high-quality
supervision for tasks that are difficult to directly evaluate.

摘要：我們透過訓練模型與透過自我對戰產生資料來辯論，來測試辯論作為可擴充監督方法的穩健性。在長語境閱讀理解任務中，我們發現基於語言模型的評估者在評斷最佳化以贏得辯論的模型時，能更準確地回答問題。相反地，我們發現對於在沒有反方辯論者的情況下訓練，以說服評審的諮詢模型，並不存在這種關係。在我們的辯論模型和新諮詢基準之間的量化和定性比較中，我們發現證據表明辯論訓練鼓勵更強而有力的論點，顯示它有望為難以直接評估的任務提供高品質的監督。

##### **Judgment of Thoughts: Courtroom of the Binary Logical Reasoning in Large Language Models**
2409.16635v1 by Sungjune Park, Daeseon Choi

This paper proposes a novel prompt engineering technique called Judgment of
Thought (JoT) that is specifically tailored for binary logical reasoning tasks.
JoT employs three roles$\unicode{x2014}$lawyer, prosecutor, and
judge$\unicode{x2014}$to facilitate more reliable and accurate reasoning by the
model. In this framework, the judge utilizes a high$\unicode{x2010}$level
model, while the lawyer and prosecutor utilize low$\unicode{x2010}$level
models. This structure helps the judge better understand the responses from
both the lawyer and prosecutor, enabling a more accurate judgment. Experimental
results on large language model (LLM) benchmark datasets, such as BigBenchHard
and Winogrande, demonstrate that JoT outperforms existing methods, including
Chain of Thought (CoT) and Self$\unicode{x2010}$Consistency (SC), in binary
logical reasoning tasks. Additionally, in real$\unicode{x2010}$world tasks,
such as Fake News Detection and SMS Spam Detection, JoT shows comparable or
improved performance compared to existing techniques. JoT significantly
enhances the accuracy and reliability of models in binary reasoning tasks and
show potential for practical applicability across various domains. Future
research should aim to further broaden the applicability of JoT and optimize
its implementation for real$\unicode{x2010}$world
problem$\unicode{x2010}$solving.

摘要：本文提出了一種名為「思考判斷」(JoT) 的新穎提示工程技術，專門針對二元邏輯推理任務而設計。
JoT 採用了三種角色：律師、檢察官和法官，以促進模型更可靠、更準確的推理。在此架構中，法官使用高層級模型，而律師和檢察官則使用低層級模型。這種結構有助於法官更好地理解律師和檢察官的回應，從而做出更準確的判斷。在大型語言模型 (LLM) 基準數據集（例如 BigBenchHard 和 Winogrande）上的實驗結果表明，JoT 在二元邏輯推理任務中優於現有方法，包括思考鏈 (CoT) 和自我一致性 (SC)。此外，在現實世界任務中，例如假新聞檢測和簡訊垃圾郵件檢測，JoT 與現有技術相比表現相當或有所提升。JoT 大幅提升了模型在二元推理任務中的準確性和可靠性，並顯示出在各種領域中實際應用的潛力。未來的研究應旨在進一步擴展 JoT 的適用性，並針對現實世界的問題解決方案最佳化其實作。

##### **Stochastic Subsampling With Average Pooling**
2409.16630v1 by Bum Jun Kim, Sang Woo Kim

Regularization of deep neural networks has been an important issue to achieve
higher generalization performance without overfitting problems. Although the
popular method of Dropout provides a regularization effect, it causes
inconsistent properties in the output, which may degrade the performance of
deep neural networks. In this study, we propose a new module called stochastic
average pooling, which incorporates Dropout-like stochasticity in pooling. We
describe the properties of stochastic subsampling and average pooling and
leverage them to design a module without any inconsistency problem. The
stochastic average pooling achieves a regularization effect without any
potential performance degradation due to the inconsistency issue and can easily
be plugged into existing architectures of deep neural networks. Experiments
demonstrate that replacing existing average pooling with stochastic average
pooling yields consistent improvements across a variety of tasks, datasets, and
models.

摘要：深度神经网络的正则化一直是实现更高泛化性能而不出现过拟合问题的一个重要课题。尽管流行的 Dropout 方法提供了一种正则化效果，但它会导致输出中的属性不一致，这可能会降低深度神经网络的性能。在本研究中，我们提出了一种称为随机平均池化的全新模块，它在池化中纳入了类似 Dropout 的随机性。我们描述了随机子采样和平均池化的属性，并利用它们设计了一个不存在任何不一致问题的模块。随机平均池化实现了一种正则化效果，不会因不一致问题而导致任何潜在的性能下降，并且可以轻松插入现有深度神经网络架构中。实验表明，用随机平均池化替换现有的平均池化，可以在各种任务、数据集和模型中产生一致的改进。

##### **Ascend HiFloat8 Format for Deep Learning**
2409.16626v2 by Yuanyong Luo, Zhongxing Zhang, Richard Wu, Hu Liu, Ying Jin, Kai Zheng, Minmin Wang, Zhanying He, Guipeng Hu, Luyao Chen, Tianchi Hu, Junsong Wang, Minqi Chen, Mikhaylov Dmitry, Korviakov Vladimir, Bobrin Maxim, Yuhao Hu, Guanfu Chen, Zeyi Huang

This preliminary white paper proposes a novel 8-bit floating-point data
format HiFloat8 (abbreviated as HiF8) for deep learning. HiF8 features tapered
precision. For normal value encoding, it provides 7 exponent values with 3-bit
mantissa, 8 exponent values with 2-bit mantissa, and 16 exponent values with
1-bit mantissa. For denormal value encoding, it extends the dynamic range by 7
extra powers of 2, from 31 to 38 binades (notice that FP16 covers 40 binades).
Meanwhile, HiF8 encodes all the special values except that positive zero and
negative zero are represented by only one bit-pattern. Thanks to the better
balance between precision and dynamic range, HiF8 can be simultaneously used in
both forward and backward passes of AI training. In this paper, we will
describe the definition and rounding methods of HiF8, as well as the tentative
training and inference solutions. To demonstrate the efficacy of HiF8, massive
simulation results on various neural networks, including traditional neural
networks and large language models (LLMs), will also be presented.

摘要：這份初步白皮書提出了一種創新的 8 位元浮點數資料格式 HiFloat8（簡稱 HiF8），用於深度學習。HiF8 具有漸變精度。對於一般數值編碼，它提供 7 個指數值，具有 3 位元尾數，8 個指數值，具有 2 位元尾數，以及 16 個指數值，具有 1 位元尾數。對於非正規數值編碼，它將動態範圍延伸 7 個 2 的次方，從 31 到 38 個二進位（請注意 FP16 涵蓋 40 個二進位）。同時，HiF8 編碼所有特殊值，除了正零和負零僅用一個位元模式表示。由於精度和動態範圍之間取得更好的平衡，因此 HiF8 可同時用於 AI 訓練的前向和後向傳遞。在本文中，我們將說明 HiF8 的定義和捨入方法，以及暫定的訓練和推論解決方案。為了證明 HiF8 的效能，我們還將展示各種神經網路的大量模擬結果，包括傳統神經網路和大型語言模型 (LLM)。

