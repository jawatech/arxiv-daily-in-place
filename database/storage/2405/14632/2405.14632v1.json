{"2405.14632": {"publish_time": "2024-05-23", "title": "Reinforcement Learning for Fine-tuning Text-to-speech Diffusion Models", "paper_summary": "Recent advancements in generative models have sparked significant interest\nwithin the machine learning community. Particularly, diffusion models have\ndemonstrated remarkable capabilities in synthesizing images and speech. Studies\nsuch as those by Lee et al. [19], Black et al. [4], Wang et al. [36], and Fan\net al. [8] illustrate that Reinforcement Learning with Human Feedback (RLHF)\ncan enhance diffusion models for image synthesis. However, due to architectural\ndifferences between these models and those employed in speech synthesis, it\nremains uncertain whether RLHF could similarly benefit speech synthesis models.\nIn this paper, we explore the practical application of RLHF to diffusion-based\ntext-to-speech synthesis, leveraging the mean opinion score (MOS) as predicted\nby UTokyo-SaruLab MOS prediction system [29] as a proxy loss. We introduce\ndiffusion model loss-guided RL policy optimization (DLPO) and compare it\nagainst other RLHF approaches, employing the NISQA speech quality and\nnaturalness assessment model [21] and human preference experiments for further\nevaluation. Our results show that RLHF can enhance diffusion-based\ntext-to-speech synthesis models, and, moreover, DLPO can better improve\ndiffusion models in generating natural and high quality speech audios.", "paper_summary_zh": "<paragraph>\u751f\u6210\u6a21\u578b\u7684\u6700\u65b0\u8fdb\u5c55\u5728\u673a\u5668\u5b66\u4e60\u793e\u533a\u4e2d\u5f15\u8d77\u4e86\u6781\u5927\u7684\u5174\u8da3\u3002\u7279\u522b\u662f\uff0c\u6269\u6563\u6a21\u578b\u5728\u56fe\u50cf\u548c\u8bed\u97f3\u5408\u6210\u65b9\u9762\u8868\u73b0\u51fa\u4e86\u975e\u51e1\u7684\u80fd\u529b\u3002\u674e\u7b49\u4eba[19]\u3001\u5e03\u83b1\u514b\u7b49\u4eba[4]\u3001\u738b\u7b49\u4eba[36]\u548c\u8303\u7b49\u4eba[8]\u7b49\u4eba\u7684\u7814\u7a76\u8868\u660e\uff0c\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u53ef\u4ee5\u589e\u5f3a\u56fe\u50cf\u5408\u6210\u7684\u6269\u6563\u6a21\u578b\u3002\u7136\u800c\uff0c\u7531\u4e8e\u8fd9\u4e9b\u6a21\u578b\u4e0e\u7528\u4e8e\u8bed\u97f3\u5408\u6210\u7684\u6a21\u578b\u5728\u67b6\u6784\u4e0a\u7684\u5dee\u5f02\uff0cRLHF\u662f\u5426\u53ef\u4ee5\u540c\u6837\u6709\u5229\u4e8e\u8bed\u97f3\u5408\u6210\u6a21\u578b\u4ecd\u7136\u4e0d\u786e\u5b9a\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63a2\u8ba8\u4e86RLHF\u5728\u57fa\u4e8e\u6269\u6563\u7684\u6587\u672c\u5230\u8bed\u97f3\u5408\u6210\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u5229\u7528\u4e1c\u4eac\u5927\u5b66SaruLab MOS\u9884\u6d4b\u7cfb\u7edf[29]\u9884\u6d4b\u7684\u5e73\u5747\u610f\u89c1\u5206\uff08MOS\uff09\u4f5c\u4e3a\u4ee3\u7406\u635f\u5931\u3002\u6211\u4eec\u5f15\u5165\u4e86\u6269\u6563\u6a21\u578b\u635f\u5931\u5f15\u5bfc\u7684RL\u7b56\u7565\u4f18\u5316\uff08DLPO\uff09\uff0c\u5e76\u5c06\u5176\u4e0e\u5176\u4ed6RLHF\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u91c7\u7528NISQA\u8bed\u97f3\u8d28\u91cf\u548c\u81ea\u7136\u5ea6\u8bc4\u4f30\u6a21\u578b[21]\u548c\u4eba\u7c7b\u504f\u597d\u5b9e\u9a8c\u8fdb\u884c\u8fdb\u4e00\u6b65\u8bc4\u4f30\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0cRLHF\u53ef\u4ee5\u589e\u5f3a\u57fa\u4e8e\u6269\u6563\u7684\u6587\u672c\u5230\u8bed\u97f3\u5408\u6210\u6a21\u578b\uff0c\u800c\u4e14\uff0cDLPO\u53ef\u4ee5\u66f4\u597d\u5730\u6539\u8fdb\u6269\u6563\u6a21\u578b\uff0c\u751f\u6210\u81ea\u7136\u4e14\u9ad8\u8d28\u91cf\u7684\u8bed\u97f3\u97f3\u9891\u3002</paragraph>", "author": "Jingyi Chen et.al.", "authors": "Jingyi Chen, Ju-Seung Byun, Micha Elsner, Andrew Perrault", "id": "2405.14632v1", "paper_url": "http://arxiv.org/abs/2405.14632v1", "repo": "null"}}