{"2407.20563": {"publish_time": "2024-07-30", "title": "Pyramid Coder: Hierarchical Code Generator for Compositional Visual Question Answering", "paper_summary": "Visual question answering (VQA) is the task of providing accurate answers to\nnatural language questions based on visual input. Programmatic VQA (PVQA)\nmodels have been gaining attention recently. These use large language models\n(LLMs) to formulate executable programs that address questions requiring\ncomplex visual reasoning. However, there are challenges in enabling LLMs to\ncomprehend the usage of image processing modules and generate relevant code. To\novercome these challenges, this paper introduces PyramidCoder, a novel\nprompting framework for PVQA models. PyramidCoder consists of three\nhierarchical levels, each serving a distinct purpose: query rephrasing, code\ngeneration, and answer aggregation. Notably, PyramidCoder utilizes a single\nfrozen LLM and pre-defined prompts at each level, eliminating the need for\nadditional training and ensuring flexibility across various LLM architectures.\nCompared to the state-of-the-art PVQA model, our approach improves accuracy by\nat least 0.5% on the GQA dataset, 1.4% on the VQAv2 dataset, and 2.9% on the\nNLVR2 dataset.", "paper_summary_zh": "\u8996\u89ba\u554f\u7b54 (VQA) \u662f\u4e00\u9805\u4efb\u52d9\uff0c\u5b83\u6839\u64da\u8996\u89ba\u8f38\u5165\u63d0\u4f9b\u81ea\u7136\u8a9e\u8a00\u554f\u984c\u7684\u6e96\u78ba\u7b54\u6848\u3002\u7a0b\u5f0f\u5316 VQA (PVQA) \u6a21\u578b\u6700\u8fd1\u5099\u53d7\u95dc\u6ce8\u3002\u9019\u4e9b\u6a21\u578b\u4f7f\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4f86\u5236\u5b9a\u57f7\u884c\u7a0b\u5f0f\uff0c\u89e3\u6c7a\u9700\u8981\u8907\u96dc\u8996\u89ba\u63a8\u7406\u7684\u554f\u984c\u3002\u7136\u800c\uff0c\u8b93 LLM \u7406\u89e3\u5f71\u50cf\u8655\u7406\u6a21\u7d44\u7684\u4f7f\u7528\u65b9\u5f0f\u4e26\u7522\u751f\u76f8\u95dc\u7a0b\u5f0f\u78bc\u5b58\u5728\u6311\u6230\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u6311\u6230\uff0c\u672c\u6587\u4ecb\u7d39\u4e86 PyramidCoder\uff0c\u9019\u662f\u4e00\u500b\u91dd\u5c0d PVQA \u6a21\u578b\u7684\u65b0\u63d0\u793a\u6846\u67b6\u3002PyramidCoder \u7531\u4e09\u500b\u5c64\u7d1a\u7d44\u6210\uff0c\u6bcf\u500b\u5c64\u7d1a\u90fd\u6709\u4e0d\u540c\u7684\u7528\u9014\uff1a\u67e5\u8a62\u6539\u5beb\u3001\u7a0b\u5f0f\u78bc\u7522\u751f\u548c\u7b54\u6848\u5f59\u7e3d\u3002\u7279\u5225\u662f\uff0cPyramidCoder \u5728\u6bcf\u500b\u5c64\u7d1a\u5229\u7528\u55ae\u4e00\u7684\u51cd\u7d50 LLM \u548c\u9810\u5b9a\u7fa9\u63d0\u793a\uff0c\u6d88\u9664\u4e86\u984d\u5916\u8a13\u7df4\u7684\u9700\u8981\uff0c\u4e26\u78ba\u4fdd\u4e86\u5404\u7a2e LLM \u67b6\u69cb\u7684\u9748\u6d3b\u6027\u3002\u8207\u6700\u5148\u9032\u7684 PVQA \u6a21\u578b\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u505a\u6cd5\u81f3\u5c11\u5728 GQA \u8cc7\u6599\u96c6\u4e0a\u63d0\u9ad8\u4e86 0.5% \u7684\u6e96\u78ba\u5ea6\uff0c\u5728 VQAv2 \u8cc7\u6599\u96c6\u4e0a\u63d0\u9ad8\u4e86 1.4%\uff0c\u5728 NLVR2 \u8cc7\u6599\u96c6\u4e0a\u63d0\u9ad8\u4e86 2.9%\u3002", "author": "Ruoyue Shen et.al.", "authors": "Ruoyue Shen, Nakamasa Inoue, Koichi Shinoda", "id": "2407.20563v1", "paper_url": "http://arxiv.org/abs/2407.20563v1", "repo": "null"}}