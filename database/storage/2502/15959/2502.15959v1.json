{"2502.15959": {"publish_time": "2025-02-21", "title": "A Knowledge Distillation-Based Approach to Enhance Transparency of Classifier Models", "paper_summary": "With the rapid development of artificial intelligence (AI), especially in the\nmedical field, the need for its explainability has grown. In medical image\nanalysis, a high degree of transparency and model interpretability can help\nclinicians better understand and trust the decision-making process of AI\nmodels. In this study, we propose a Knowledge Distillation (KD)-based approach\nthat aims to enhance the transparency of the AI model in medical image\nanalysis. The initial step is to use traditional CNN to obtain a teacher model\nand then use KD to simplify the CNN architecture, retain most of the features\nof the data set, and reduce the number of network layers. It also uses the\nfeature map of the student model to perform hierarchical analysis to identify\nkey features and decision-making processes. This leads to intuitive visual\nexplanations. We selected three public medical data sets (brain tumor, eye\ndisease, and Alzheimer's disease) to test our method. It shows that even when\nthe number of layers is reduced, our model provides a remarkable result in the\ntest set and reduces the time required for the interpretability analysis.", "paper_summary_zh": "\u96a8\u8457\u4eba\u5de5\u667a\u6167 (AI) \u7684\u5feb\u901f\u767c\u5c55\uff0c\u7279\u5225\u662f\u5728\u91ab\u7642\u9818\u57df\u4e2d\uff0c\u5c0d\u65bc\u5176\u53ef\u89e3\u91cb\u6027\u7684\u9700\u6c42\u4e5f\u65e5\u76ca\u589e\u9577\u3002\u5728\u91ab\u5b78\u5f71\u50cf\u5206\u6790\u4e2d\uff0c\u9ad8\u5ea6\u7684\u900f\u660e\u5ea6\u548c\u6a21\u578b\u53ef\u89e3\u91cb\u6027\u53ef\u4ee5\u5e6b\u52a9\u81e8\u5e8a\u91ab\u751f\u66f4\u4e86\u89e3\u4e26\u4fe1\u8cf4 AI \u6a21\u578b\u7684\u6c7a\u7b56\u904e\u7a0b\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u57fa\u65bc\u77e5\u8b58\u84b8\u993e (KD) \u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u589e\u5f37 AI \u6a21\u578b\u5728\u91ab\u5b78\u5f71\u50cf\u5206\u6790\u4e2d\u7684\u900f\u660e\u5ea6\u3002\u7b2c\u4e00\u6b65\u662f\u4f7f\u7528\u50b3\u7d71\u7684 CNN \u4f86\u7372\u5f97\u4e00\u500b\u6559\u5e2b\u6a21\u578b\uff0c\u7136\u5f8c\u4f7f\u7528 KD \u4f86\u7c21\u5316 CNN \u67b6\u69cb\uff0c\u4fdd\u7559\u8cc7\u6599\u96c6\u7684\u5927\u90e8\u5206\u7279\u5fb5\uff0c\u4e26\u6e1b\u5c11\u7db2\u8def\u5c64\u6578\u3002\u5b83\u9084\u4f7f\u7528\u5b78\u751f\u6a21\u578b\u7684\u7279\u5fb5\u5716\u4f86\u57f7\u884c\u968e\u5c64\u5206\u6790\uff0c\u4ee5\u8b58\u5225\u95dc\u9375\u7279\u5fb5\u548c\u6c7a\u7b56\u904e\u7a0b\u3002\u9019\u6703\u7522\u751f\u76f4\u89c0\u7684\u8996\u89ba\u89e3\u91cb\u3002\u6211\u5011\u9078\u64c7\u4e86\u4e09\u500b\u516c\u958b\u7684\u91ab\u5b78\u8cc7\u6599\u96c6\uff08\u8166\u7624\u3001\u773c\u75be\u548c\u963f\u8332\u6d77\u9ed8\u75c7\uff09\u4f86\u6e2c\u8a66\u6211\u5011\u7684\u6a21\u578b\u3002\u7d50\u679c\u986f\u793a\uff0c\u5373\u4f7f\u5728\u6e1b\u5c11\u5c64\u6578\u7684\u60c5\u6cc1\u4e0b\uff0c\u6211\u5011\u7684\u6a21\u578b\u5728\u6e2c\u8a66\u96c6\u4e2d\u4e5f\u63d0\u4f9b\u4e86\u986f\u8457\u7684\u7d50\u679c\uff0c\u4e26\u6e1b\u5c11\u4e86\u53ef\u89e3\u91cb\u6027\u5206\u6790\u6240\u9700\u7684\u6642\u9593\u3002", "author": "Yuchen Jiang et.al.", "authors": "Yuchen Jiang, Xinyuan Zhao, Yihang Wu, Ahmad Chaddad", "id": "2502.15959v1", "paper_url": "http://arxiv.org/abs/2502.15959v1", "repo": "null"}}