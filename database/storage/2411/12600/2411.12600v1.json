{"2411.12600": {"publish_time": "2024-11-19", "title": "Provable unlearning in topic modeling and downstream tasks", "paper_summary": "Machine unlearning algorithms are increasingly important as legal concerns\narise around the provenance of training data, but verifying the success of\nunlearning is often difficult. Provable guarantees for unlearning are often\nlimited to supervised learning settings. In this paper, we provide the first\ntheoretical guarantees for unlearning in the pre-training and fine-tuning\nparadigm by studying topic models, simple bag-of-words language models that can\nbe adapted to solve downstream tasks like retrieval and classification. First,\nwe design a provably effective unlearning algorithm for topic models that\nincurs a computational overhead independent of the size of the original\ndataset. Our analysis additionally quantifies the deletion capacity of the\nmodel -- i.e., the number of examples that can be unlearned without incurring a\nsignificant cost in model performance. Finally, we formally extend our analyses\nto account for adaptation to a given downstream task. In particular, we design\nan efficient algorithm to perform unlearning after fine-tuning the topic model\nvia a linear head. Notably, we show that it is easier to unlearn pre-training\ndata from models that have been fine-tuned to a particular task, and one can\nunlearn this data without modifying the base model.", "paper_summary_zh": "\u673a\u5668\u9057\u5fd8\u7b97\u6cd5\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u56e0\u4e3a\u6cd5\u5f8b\u95ee\u9898\u56f4\u7ed5\u8bad\u7ec3\u6570\u636e\u7684\u51fa\u5904\u800c\u51fa\u73b0\uff0c\u4f46\u9a8c\u8bc1\u9057\u5fd8\u7684\u6210\u529f\u901a\u5e38\u5f88\u56f0\u96be\u3002\u9057\u5fd8\u7684\u53ef\u8bc1\u660e\u4fdd\u8bc1\u901a\u5e38\u4ec5\u9650\u4e8e\u76d1\u7763\u5b66\u4e60\u8bbe\u7f6e\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u7814\u7a76\u4e3b\u9898\u6a21\u578b\uff08\u53ef\u4ee5\u9002\u5e94\u6c42\u89e3\u8bf8\u5982\u68c0\u7d22\u548c\u5206\u7c7b\u4e4b\u7c7b\u7684\u4e0b\u6e38\u4efb\u52a1\u7684\u7b80\u5355\u7684\u8bcd\u888b\u8bed\u8a00\u6a21\u578b\uff09\u63d0\u4f9b\u4e86\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u8303\u5f0f\u4e2d\u9057\u5fd8\u7684\u7b2c\u4e00\u4e2a\u7406\u8bba\u4fdd\u8bc1\u3002\u9996\u5148\uff0c\u6211\u4eec\u4e3a\u4e3b\u9898\u6a21\u578b\u8bbe\u8ba1\u4e86\u4e00\u79cd\u53ef\u8bc1\u660e\u6709\u6548\u7684\u9057\u5fd8\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u4ea7\u751f\u7684\u8ba1\u7b97\u5f00\u9500\u4e0e\u539f\u59cb\u6570\u636e\u96c6\u7684\u5927\u5c0f\u65e0\u5173\u3002\u6211\u4eec\u7684\u5206\u6790\u8fd8\u91cf\u5316\u4e86\u6a21\u578b\u7684\u5220\u9664\u5bb9\u91cf\u2014\u2014\u5373\uff0c\u53ef\u4ee5\u5728\u4e0d\u4ea7\u751f\u6a21\u578b\u6027\u80fd\u663e\u7740\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u9057\u5fd8\u7684\u793a\u4f8b\u6570\u91cf\u3002\u6700\u540e\uff0c\u6211\u4eec\u6b63\u5f0f\u6269\u5c55\u4e86\u6211\u4eec\u7684\u5206\u6790\uff0c\u4ee5\u89e3\u91ca\u5bf9\u7ed9\u5b9a\u4e0b\u6e38\u4efb\u52a1\u7684\u9002\u5e94\u3002\u7279\u522b\u662f\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u901a\u8fc7\u7ebf\u6027\u5934\u90e8\u5fae\u8c03\u4e3b\u9898\u6a21\u578b\u540e\u6267\u884c\u9057\u5fd8\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u4eec\u8868\u660e\u4ece\u5df2\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u5fae\u8c03\u7684\u6a21\u578b\u4e2d\u9057\u5fd8\u9884\u8bad\u7ec3\u6570\u636e\u66f4\u5bb9\u6613\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u4e0d\u4fee\u6539\u57fa\u7840\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u9057\u5fd8\u6b64\u6570\u636e\u3002", "author": "Stanley Wei et.al.", "authors": "Stanley Wei, Sadhika Malladi, Sanjeev Arora, Amartya Sanyal", "id": "2411.12600v1", "paper_url": "http://arxiv.org/abs/2411.12600v1", "repo": "null"}}