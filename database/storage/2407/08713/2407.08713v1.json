{"2407.08713": {"publish_time": "2024-07-11", "title": "GTA: A Benchmark for General Tool Agents", "paper_summary": "Significant focus has been placed on integrating large language models (LLMs)\nwith various tools in developing general-purpose agents. This poses a challenge\nto LLMs' tool-use capabilities. However, there are evident gaps between\nexisting tool-use evaluations and real-world scenarios. Current evaluations\noften use AI-generated queries, single-step tasks, dummy tools, and text-only\ninteractions, failing to reveal the agents' real-world problem-solving\nabilities effectively. To address this, we propose GTA, a benchmark for General\nTool Agents, featuring three main aspects: (i) Real user queries: human-written\nqueries with simple real-world objectives but implicit tool-use, requiring the\nLLM to reason the suitable tools and plan the solution steps. (ii) Real\ndeployed tools: an evaluation platform equipped with tools across perception,\noperation, logic, and creativity categories to evaluate the agents' actual task\nexecution performance. (iii) Real multimodal inputs: authentic image files,\nsuch as spatial scenes, web page screenshots, tables, code snippets, and\nprinted/handwritten materials, used as the query contexts to align with\nreal-world scenarios closely. We design 229 real-world tasks and executable\ntool chains to evaluate mainstream LLMs. Our findings show that real-world user\nqueries are challenging for existing LLMs, with GPT-4 completing less than 50%\nof the tasks and most LLMs achieving below 25%. This evaluation reveals the\nbottlenecks in the tool-use capabilities of current LLMs in real-world\nscenarios, which provides future direction for advancing general-purpose tool\nagents. The code and dataset are available at\nhttps://github.com/open-compass/GTA.", "paper_summary_zh": "<paragraph>\u5728\u958b\u767c\u901a\u7528\u4ee3\u7406\u6642\uff0c\u6574\u5408\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8207\u5404\u7a2e\u5de5\u5177\u5df2\u6210\u70ba\u91cd\u9ede\u3002\u9019\u5c0d LLM \u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u69cb\u6210\u6311\u6230\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u5de5\u5177\u4f7f\u7528\u8a55\u4f30\u8207\u5be6\u969b\u5834\u666f\u4e4b\u9593\u5b58\u5728\u660e\u986f\u5dee\u8ddd\u3002\u76ee\u524d\u7684\u8a55\u4f30\u901a\u5e38\u4f7f\u7528 AI \u751f\u6210\u7684\u67e5\u8a62\u3001\u55ae\u6b65\u4efb\u52d9\u3001\u865b\u64ec\u5de5\u5177\u548c\u7d14\u6587\u5b57\u4e92\u52d5\uff0c\u672a\u80fd\u6709\u6548\u63ed\u793a\u4ee3\u7406\u7684\u5be6\u969b\u554f\u984c\u89e3\u6c7a\u80fd\u529b\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa GTA\uff0c\u4e00\u500b\u901a\u7528\u5de5\u5177\u4ee3\u7406\u7684\u57fa\u6e96\uff0c\u5177\u6709\u4e09\u500b\u4e3b\u8981\u65b9\u9762\uff1a(i) \u771f\u5be6\u4f7f\u7528\u8005\u67e5\u8a62\uff1a\u4eba\u985e\u64b0\u5beb\u7684\u67e5\u8a62\uff0c\u5177\u6709\u7c21\u55ae\u7684\u5be6\u969b\u76ee\u6a19\u4f46\u96b1\u542b\u5de5\u5177\u4f7f\u7528\uff0c\u8981\u6c42 LLM \u63a8\u8ad6\u9069\u7576\u7684\u5de5\u5177\u4e26\u898f\u5283\u89e3\u6c7a\u6b65\u9a5f\u3002(ii) \u771f\u5be6\u90e8\u7f72\u5de5\u5177\uff1a\u4e00\u500b\u8a55\u4f30\u5e73\u53f0\uff0c\u914d\u5099\u611f\u77e5\u3001\u64cd\u4f5c\u3001\u908f\u8f2f\u548c\u5275\u610f\u985e\u5225\u7684\u5de5\u5177\uff0c\u4ee5\u8a55\u4f30\u4ee3\u7406\u7684\u5be6\u969b\u4efb\u52d9\u57f7\u884c\u6548\u80fd\u3002(iii) \u771f\u5be6\u591a\u6a21\u614b\u8f38\u5165\uff1a\u771f\u5be6\u7684\u5f71\u50cf\u6a94\u6848\uff0c\u4f8b\u5982\u7a7a\u9593\u5834\u666f\u3001\u7db2\u9801\u622a\u5716\u3001\u8868\u683c\u3001\u7a0b\u5f0f\u78bc\u7247\u6bb5\uff0c\u4ee5\u53ca\u5370\u5237/\u624b\u5beb\u6750\u6599\uff0c\u7528\u4f5c\u67e5\u8a62\u80cc\u666f\uff0c\u4ee5\u7dca\u5bc6\u914d\u5408\u5be6\u969b\u5834\u666f\u3002\u6211\u5011\u8a2d\u8a08\u4e86 229 \u500b\u771f\u5be6\u4e16\u754c\u7684\u4efb\u52d9\u548c\u53ef\u57f7\u884c\u5de5\u5177\u93c8\uff0c\u4ee5\u8a55\u4f30\u4e3b\u6d41 LLM\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u5be6\u969b\u4e16\u754c\u7684\u4f7f\u7528\u8005\u67e5\u8a62\u5c0d\u73fe\u6709\u7684 LLM \u69cb\u6210\u6311\u6230\uff0cGPT-4 \u5b8c\u6210\u4e0d\u5230 50% \u7684\u4efb\u52d9\uff0c\u800c\u5927\u591a\u6578 LLM \u7684\u5b8c\u6210\u7387\u4f4e\u65bc 25%\u3002\u6b64\u8a55\u4f30\u63ed\u793a\u4e86\u7576\u524d LLM \u5728\u5be6\u969b\u5834\u666f\u4e2d\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684\u74f6\u9838\uff0c\u9019\u70ba\u63a8\u9032\u901a\u7528\u5de5\u5177\u4ee3\u7406\u63d0\u4f9b\u4e86\u672a\u4f86\u7684\u65b9\u5411\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u96c6\u53ef\u5728 https://github.com/open-compass/GTA \u53d6\u5f97\u3002</paragraph>", "author": "Jize Wang et.al.", "authors": "Jize Wang, Zerun Ma, Yining Li, Songyang Zhang, Cailian Chen, Kai Chen, Xinyi Le", "id": "2407.08713v1", "paper_url": "http://arxiv.org/abs/2407.08713v1", "repo": "https://github.com/open-compass/GTA"}}