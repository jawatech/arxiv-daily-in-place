{"2405.19262": {"publish_time": "2024-05-29", "title": "Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models", "paper_summary": "Large language models are usually fine-tuned to align with human preferences.\nHowever, fine-tuning a large language model can be challenging. In this work,\nwe introduce $\\textit{weak-to-strong search}$, framing the alignment of a large\nlanguage model as a test-time greedy search to maximize the log-likelihood\ndifference between small tuned and untuned models while sampling from the\nfrozen large model. This method serves both as (i) a compute-efficient model\nup-scaling strategy that avoids directly tuning the large model and as (ii) an\ninstance of weak-to-strong generalization that enhances a strong model with\nweak test-time guidance. Empirically, we demonstrate the flexibility of\nweak-to-strong search across different tasks. In controlled-sentiment\ngeneration and summarization, we use tuned and untuned $\\texttt{gpt2}$s to\neffectively improve the alignment of large models without additional training.\nCrucially, in a more difficult instruction-following benchmark, AlpacaEval 2.0,\nwe show that reusing off-the-shelf small model pairs (e.g.,\n$\\texttt{zephyr-7b-beta}$ and its untuned version) can significantly improve\nthe length-controlled win rates of both white-box and black-box large models\nagainst $\\texttt{gpt-4-turbo}$ (e.g., $34.4 \\rightarrow 37.9$ for\n$\\texttt{Llama-3-70B-Instruct}$ and $16.0 \\rightarrow 20.1$ for\n$\\texttt{gpt-3.5-turbo-instruct}$), despite the small models' low win rates\n$\\approx 10.0$.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u901a\u5e38\u7d93\u904e\u5fae\u8abf\uff0c\u4ee5\u7b26\u5408\u4eba\u985e\u7684\u504f\u597d\u3002\n\u7136\u800c\uff0c\u5fae\u8abf\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u53ef\u80fd\u5177\u6709\u6311\u6230\u6027\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\n\u6211\u5011\u5f15\u5165\u4e86\u300c\u5f31\u5230\u5f37\u641c\u5c0b\u300d\uff0c\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u5c0d\u9f4a\u8a2d\u5b9a\u70ba\u6e2c\u8a66\u6642\u9593\u8caa\u5a6a\u641c\u5c0b\uff0c\u4ee5\u6700\u5927\u5316\u5c0f\u578b\u7684\u8abf\u6574\u548c\u672a\u8abf\u6574\u6a21\u578b\u4e4b\u9593\u7684\u5c0d\u6578\u4f3c\u7136\u5dee\u7570\uff0c\u540c\u6642\u5f9e\u51cd\u7d50\u7684\u5927\u578b\u6a21\u578b\u4e2d\u53d6\u6a23\u3002\u9019\u7a2e\u65b9\u6cd5\u540c\u6642\u4f5c\u70ba (i) \u4e00\u7a2e\u8a08\u7b97\u6709\u6548\u7387\u7684\u6a21\u578b\u5347\u7d1a\u7b56\u7565\uff0c\u907f\u514d\u76f4\u63a5\u8abf\u6574\u5927\u578b\u6a21\u578b\uff0c\u4ee5\u53ca (ii) \u4e00\u7a2e\u5f31\u5230\u5f37\u6cdb\u5316\u7684\u5be6\u4f8b\uff0c\u5b83\u4f7f\u7528\u5f31\u6e2c\u8a66\u6642\u9593\u6307\u5c0e\u589e\u5f37\u5f37\u6a21\u578b\u3002\u6839\u64da\u7d93\u9a57\uff0c\u6211\u5011\u5c55\u793a\u4e86\u5f31\u5230\u5f37\u641c\u5c0b\u5728\u4e0d\u540c\u4efb\u52d9\u4e2d\u7684\u9748\u6d3b\u6027\u3002\u5728\u53d7\u63a7\u60c5\u7dd2\u751f\u6210\u548c\u6458\u8981\u4e2d\uff0c\u6211\u5011\u4f7f\u7528\u8abf\u6574\u548c\u672a\u8abf\u6574\u7684 $\\texttt{gpt2}$ \u6709\u6548\u5730\u6539\u5584\u4e86\u5927\u578b\u6a21\u578b\u7684\u5c0d\u9f4a\uff0c\u800c\u7121\u9700\u984d\u5916\u7684\u8a13\u7df4\u3002\n\u81f3\u95dc\u91cd\u8981\u7684\u662f\uff0c\u5728\u4e00\u500b\u66f4\u56f0\u96e3\u7684\u6307\u4ee4\u9075\u5faa\u57fa\u6e96 AlpacaEval 2.0 \u4e2d\uff0c\u6211\u5011\u8868\u660e\u91cd\u8907\u4f7f\u7528\u73fe\u6210\u7684\u5c0f\u578b\u6a21\u578b\u5c0d\uff08\u4f8b\u5982\uff0c\n$\\texttt{zephyr-7b-beta}$ \u53ca\u5176\u672a\u8abf\u6574\u7248\u672c\uff09\u53ef\u4ee5\u986f\u8457\u63d0\u9ad8\u767d\u76d2\u548c\u9ed1\u76d2\u5927\u578b\u6a21\u578b\u76f8\u5c0d\u65bc $\\texttt{gpt-4-turbo}$ \u7684\u9577\u5ea6\u63a7\u5236\u7372\u52dd\u7387\uff08\u4f8b\u5982\uff0c$34.4 \\rightarrow 37.9$ \u5c0d\u65bc\n$\\texttt{Llama-3-70B-Instruct}$ \u548c $16.0 \\rightarrow 20.1$ \u5c0d\u65bc\n$\\texttt{gpt-3.5-turbo-instruct}$\uff09\uff0c\u5118\u7ba1\u5c0f\u578b\u6a21\u578b\u7684\u7372\u52dd\u7387\u4f4e\n$\\approx 10.0$\u3002", "author": "Zhanhui Zhou et.al.", "authors": "Zhanhui Zhou, Zhixuan Liu, Jie Liu, Zhichen Dong, Chao Yang, Yu Qiao", "id": "2405.19262v1", "paper_url": "http://arxiv.org/abs/2405.19262v1", "repo": "null"}}