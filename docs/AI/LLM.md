
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-13**|**MambaOut: Do We Really Need Mamba for Vision?**|Weihao Yu et.al.|[2405.07992v1](http://arxiv.org/abs/2405.07992v1)|[link](https://github.com/yuweihao/mambaout)|
|**2024-05-13**|**Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots**|Chengyue Wu et.al.|[2405.07990v1](http://arxiv.org/abs/2405.07990v1)|null|
|**2024-05-13**|**The Platonic Representation Hypothesis**|Minyoung Huh et.al.|[2405.07987v1](http://arxiv.org/abs/2405.07987v1)|[link](https://github.com/minyoungg/platonic-rep)|
|**2024-05-13**|**Localized Adaptive Risk Control**|Matteo Zecchin et.al.|[2405.07976v1](http://arxiv.org/abs/2405.07976v1)|[link](https://github.com/kclip/localized-adaptive-risk-control)|
|**2024-05-13**|**Investigating the Semantic Robustness of CLIP-based Zero-Shot Anomaly Segmentation**|Kevin Stangl et.al.|[2405.07969v1](http://arxiv.org/abs/2405.07969v1)|null|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments**|Samuel Schmidgall et.al.|[2405.07960v1](http://arxiv.org/abs/2405.07960v1)|null|
|**2024-05-13**|**Hierarchical Decision Mamba**|André Correia et.al.|[2405.07943v1](http://arxiv.org/abs/2405.07943v1)|[link](https://github.com/meowatthemoon/hierarchicaldecisionmamba)|
|**2024-05-13**|**RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors**|Liam Dugan et.al.|[2405.07940v1](http://arxiv.org/abs/2405.07940v1)|null|
|**2024-05-13**|**EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning**|Yinzhu Quan et.al.|[2405.07938v1](http://arxiv.org/abs/2405.07938v1)|null|
|**2024-05-13**|**PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition**|Ziyang Zhang et.al.|[2405.07932v2](http://arxiv.org/abs/2405.07932v2)|[link](https://github.com/ed-zh/parden)|
|**2024-05-13**|**Stable Diffusion-based Data Augmentation for Federated Learning with Non-IID Data**|Mahdi Morafah et.al.|[2405.07925v1](http://arxiv.org/abs/2405.07925v1)|null|
|**2024-05-13**|**Science based AI model certification for new operational environments with application in traffic state estimation**|Daryl Mupupuni et.al.|[2405.07893v1](http://arxiv.org/abs/2405.07893v1)|null|
|**2024-05-13**|**Russian-Language Multimodal Dataset for Automatic Summarization of Scientific Papers**|Alena Tsanda et.al.|[2405.07886v1](http://arxiv.org/abs/2405.07886v1)|null|
|**2024-05-13**|**Zero-Shot Tokenizer Transfer**|Benjamin Minixhofer et.al.|[2405.07883v1](http://arxiv.org/abs/2405.07883v1)|null|
|**2024-05-13**|**Reproducing the Metric-Based Evaluation of a Set of Controllable Text Generation Techniques**|Michela Lorandi et.al.|[2405.07875v1](http://arxiv.org/abs/2405.07875v1)|null|
|**2024-05-13**|**RLHF Workflow: From Reward Modeling to Online RLHF**|Hanze Dong et.al.|[2405.07863v1](http://arxiv.org/abs/2405.07863v1)|[link](https://github.com/rlhflow/online-rlhf)|
|**2024-05-13**|**Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM**|Xiaoyu Chen et.al.|[2405.07840v1](http://arxiv.org/abs/2405.07840v1)|null|
|**2024-05-13**|**Synthetic Tabular Data Validation: A Divergence-Based Approach**|Patricia A. Apellániz et.al.|[2405.07822v1](http://arxiv.org/abs/2405.07822v1)|null|
|**2024-05-13**|**Quick and Accurate Affordance Learning**|Fedor Scholz et.al.|[2405.07816v1](http://arxiv.org/abs/2405.07816v1)|null|
|**2024-05-13**|**Decoding Geometric Properties in Non-Random Data from First Information-Theoretic Principles**|Hector Zenil et.al.|[2405.07803v1](http://arxiv.org/abs/2405.07803v1)|null|
|**2024-05-13**|**FreeVA: Offline MLLM as Training-Free Video Assistant**|Wenhao Wu et.al.|[2405.07798v1](http://arxiv.org/abs/2405.07798v1)|[link](https://github.com/whwu95/freeva)|
|**2024-05-13**|**DEPTH: Discourse Education through Pre-Training Hierarchically**|Zachary Bamberger et.al.|[2405.07788v1](http://arxiv.org/abs/2405.07788v1)|[link](https://github.com/zbambergerNLP/depth)|
|**2024-05-13**|**A Comprehensive Analysis of Static Word Embeddings for Turkish**|Karahan Sarıtaş et.al.|[2405.07778v1](http://arxiv.org/abs/2405.07778v1)|[link](https://github.com/turkish-word-embeddings/word-embeddings-repository-for-turkish)|
|**2024-05-13**|**Human-Modeling in Sequential Decision-Making: An Analysis through the Lens of Human-Aware AI**|Silvia Tulli et.al.|[2405.07773v1](http://arxiv.org/abs/2405.07773v1)|null|
|**2024-05-13**|**Synthetic Test Collections for Retrieval Evaluation**|Hossein A. Rahmani et.al.|[2405.07767v1](http://arxiv.org/abs/2405.07767v1)|null|
|**2024-05-13**|**Challenges and Opportunities of NLP for HR Applications: A Discussion Paper**|Jochen L. Leidner et.al.|[2405.07766v1](http://arxiv.org/abs/2405.07766v1)|null|
|**2024-05-13**|**TANQ: An open domain dataset of table answered questions**|Mubashara Akhtar et.al.|[2405.07765v1](http://arxiv.org/abs/2405.07765v1)|null|
|**2024-05-13**|**LLM4ED: Large Language Models for Automatic Equation Discovery**|Mengge Du et.al.|[2405.07761v1](http://arxiv.org/abs/2405.07761v1)|null|
|**2024-05-13**|**MADRL-Based Rate Adaptation for 360$\degree$ Video Streaming with Multi-Viewpoint Prediction**|Haopeng Wang et.al.|[2405.07759v1](http://arxiv.org/abs/2405.07759v1)|null|
|**2024-05-13**|**LlamaTurk: Adapting Open-Source Generative Large Language Models for Low-Resource Language**|Cagri Toraman et.al.|[2405.07745v1](http://arxiv.org/abs/2405.07745v1)|[link](https://github.com/metunlp/llamaturk)|
|**2024-05-13**|**Federated Hierarchical Tensor Networks: a Collaborative Learning Quantum AI-Driven Framework for Healthcare**|Amandeep Singh Bhatia et.al.|[2405.07735v1](http://arxiv.org/abs/2405.07735v1)|null|
|**2024-05-13**|**Quantifying and Optimizing Global Faithfulness in Persona-driven Role-playing**|Letian Peng et.al.|[2405.07726v1](http://arxiv.org/abs/2405.07726v1)|null|
|**2024-05-13**|**A Unified Sequence Parallelism Approach for Long Context Generative AI**|Jiarui Fang et.al.|[2405.07719v2](http://arxiv.org/abs/2405.07719v2)|[link](https://github.com/feifeibear/long-context-attention)|
|**2024-05-13**|**OpenLLM-Ro -- Technical Report on Open-source Romanian LLMs trained starting from Llama 2**|Mihai Masala et.al.|[2405.07703v2](http://arxiv.org/abs/2405.07703v2)|null|
|**2024-05-13**|**Age-Dependent Analysis and Stochastic Generation of Child-Directed Speech**|Okko Räsänen et.al.|[2405.07700v1](http://arxiv.org/abs/2405.07700v1)|null|
|**2024-05-13**|**FastSAG: Towards Fast Non-Autoregressive Singing Accompaniment Generation**|Jianyi Chen et.al.|[2405.07682v1](http://arxiv.org/abs/2405.07682v1)|null|
|**2024-05-13**|**An Empirical Study on the Robustness of Massively Multilingual Neural Machine Translation**|Supryadi et.al.|[2405.07673v1](http://arxiv.org/abs/2405.07673v1)|[link](https://github.com/tjunlp-lab/id-zh-mtrobusteval)|
|**2024-05-13**|**Constructing a BPE Tokenization DFA**|Martin Berglund et.al.|[2405.07671v1](http://arxiv.org/abs/2405.07671v1)|null|
|**2024-05-13**|**CrossCert: A Cross-Checking Detection Approach to Patch Robustness Certification for Deep Learning Models**|Qilin Zhou et.al.|[2405.07668v1](http://arxiv.org/abs/2405.07668v1)|null|
|**2024-05-13**|**Backdoor Removal for Generative Large Language Models**|Haoran Li et.al.|[2405.07667v1](http://arxiv.org/abs/2405.07667v1)|null|
|**2024-05-13**|**Sign Stitching: A Novel Approach to Sign Language Production**|Harry Walsh et.al.|[2405.07663v1](http://arxiv.org/abs/2405.07663v1)|null|
|**2024-05-13**|**G-VOILA: Gaze-Facilitated Information Querying in Daily Scenarios**|Zeyu Wang et.al.|[2405.07652v1](http://arxiv.org/abs/2405.07652v1)|[link](https://github.com/sky-wang326/gvoila)|
|**2024-05-13**|**Hyperparameter Importance Analysis for Multi-Objective AutoML**|Daphne Theodorakopoulos et.al.|[2405.07640v1](http://arxiv.org/abs/2405.07640v1)|null|
|**2024-05-13**|**DoLLM: How Large Language Models Understanding Network Flow Data to Detect Carpet Bombing DDoS**|Qingyang Li et.al.|[2405.07638v1](http://arxiv.org/abs/2405.07638v1)|null|
|**2024-05-13**|**AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models**|Shuo Liu et.al.|[2405.07626v1](http://arxiv.org/abs/2405.07626v1)|[link](https://github.com/anomalyllm/anomalyllm)|
|**2024-05-13**|**COBias and Debias: Minimizing Language Model Pairwise Accuracy Bias via Nonlinear Integer Programming**|Ruixi Lin et.al.|[2405.07623v1](http://arxiv.org/abs/2405.07623v1)|null|
|**2024-05-13**|**ViWikiFC: Fact-Checking for Vietnamese Wikipedia-Based Textual Knowledge Source**|Hung Tuan Le et.al.|[2405.07615v1](http://arxiv.org/abs/2405.07615v1)|null|
|**2024-05-13**|**NoiseBench: Benchmarking the Impact of Real Label Noise on Named Entity Recognition**|Elena Merdjanovska et.al.|[2405.07609v1](http://arxiv.org/abs/2405.07609v1)|null|
|**2024-05-13**|**Reducing Risk for Assistive Reinforcement Learning Policies with Diffusion Models**|Andrii Tytarenko et.al.|[2405.07603v1](http://arxiv.org/abs/2405.07603v1)|null|
|**2024-05-13**|**On-device Online Learning and Semantic Management of TinyML Systems**|Haoyu Ren et.al.|[2405.07601v1](http://arxiv.org/abs/2405.07601v1)|null|
|**2024-05-13**|**Using Model-Theoretic Approaches to Uncover Linguistic Organization**|Olivia Griffin et.al.|[2405.07597v1](http://arxiv.org/abs/2405.07597v1)|null|
|**2024-05-13**|**Environmental Matching Attack Against Unmanned Aerial Vehicles Object Detection**|Dehong Kong et.al.|[2405.07595v1](http://arxiv.org/abs/2405.07595v1)|null|
|**2024-05-13**|**Thai Universal Dependency Treebank**|Panyut Sriwirote et.al.|[2405.07586v1](http://arxiv.org/abs/2405.07586v1)|null|
|**2024-05-13**|**DynLLM: When Large Language Models Meet Dynamic Graph Recommendation**|Ziwei Zhao et.al.|[2405.07580v1](http://arxiv.org/abs/2405.07580v1)|null|
|**2024-05-13**|**GLiRA: Black-Box Membership Inference Attack via Knowledge Distillation**|Andrey V. Galichin et.al.|[2405.07562v1](http://arxiv.org/abs/2405.07562v1)|null|
|**2024-05-13**|**MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning**|Shuo Yin et.al.|[2405.07551v1](http://arxiv.org/abs/2405.07551v1)|null|
|**2024-05-13**|**EMS-SD: Efficient Multi-sample Speculative Decoding for Accelerating Large Language Models**|Yunsheng Ni et.al.|[2405.07542v1](http://arxiv.org/abs/2405.07542v1)|null|
|**2024-05-13**|**Random walk model that universally generates inverse square Lévy walk by eliminating search cost minimization constraint**|Shuji Shinohara et.al.|[2405.07541v2](http://arxiv.org/abs/2405.07541v2)|null|
|**2024-05-13**|**Train Faster, Perform Better: Modular Adaptive Training in Over-Parameterized Models**|Yubin Shi et.al.|[2405.07527v1](http://arxiv.org/abs/2405.07527v1)|null|
|**2024-05-13**|**SambaNova SN40L: Scaling the AI Memory Wall with Dataflow and Composition of Experts**|Raghu Prabhakar et.al.|[2405.07518v1](http://arxiv.org/abs/2405.07518v1)|null|
|**2024-05-13**|**Fine-tuning the SwissBERT Encoder Model for Embedding Sentences and Documents**|Juri Grosjean et.al.|[2405.07513v1](http://arxiv.org/abs/2405.07513v1)|null|
|**2024-05-13**|**RESTAD: REconstruction and Similarity based Transformer for time series Anomaly Detection**|Ramin Ghorbani et.al.|[2405.07509v1](http://arxiv.org/abs/2405.07509v1)|[link](https://github.com/raminghorbanii/restad)|
|**2024-05-13**|**Consistency Policy: Accelerated Visuomotor Policies via Consistency Distillation**|Aaditya Prasad et.al.|[2405.07503v1](http://arxiv.org/abs/2405.07503v1)|null|
|**2024-05-13**|**PromptLink: Leveraging Large Language Models for Cross-Source Biomedical Concept Linking**|Yuzhang Xie et.al.|[2405.07500v1](http://arxiv.org/abs/2405.07500v1)|[link](https://github.com/constantjxyz/promptlink)|
|**2024-05-13**|**MacBehaviour: An R package for behavioural experimentation on large language models**|Xufeng Duan et.al.|[2405.07495v1](http://arxiv.org/abs/2405.07495v1)|[link](https://github.com/xufengduan/macbehaviour)|
|**2024-05-13**|**Strategic Data Ordering: Enhancing Large Language Model Performance through Curriculum Learning**|Jisu Kim et.al.|[2405.07490v1](http://arxiv.org/abs/2405.07490v1)|null|
|**2024-05-13**|**Integrating Intent Understanding and Optimal Behavior Planning for Behavior Tree Generation from Human Instructions**|Xinglin Chen et.al.|[2405.07474v1](http://arxiv.org/abs/2405.07474v1)|null|
|**2024-05-13**|**Evaluating large language models in medical applications: a survey**|Xiaolan Chen et.al.|[2405.07468v1](http://arxiv.org/abs/2405.07468v1)|null|
|**2024-05-13**|**MCS-SQL: Leveraging Multiple Prompts and Multiple-Choice Selection For Text-to-SQL Generation**|Dongjun Lee et.al.|[2405.07467v1](http://arxiv.org/abs/2405.07467v1)|null|
|**2024-05-13**|**HoneyBee: A Scalable Modular Framework for Creating Multimodal Oncology Datasets with Foundational Embedding Models**|Aakash Tripathi et.al.|[2405.07460v1](http://arxiv.org/abs/2405.07460v1)|null|
|**2024-05-13**|**Rene: A Pre-trained Multi-modal Architecture for Auscultation of Respiratory Diseases**|Pengfei Zhang et.al.|[2405.07442v1](http://arxiv.org/abs/2405.07442v1)|null|
|**2024-05-13**|**Evaluation of Retrieval-Augmented Generation: A Survey**|Hao Yu et.al.|[2405.07437v1](http://arxiv.org/abs/2405.07437v1)|[link](https://github.com/yhpeter/awesome-rag-evaluation)|
|**2024-05-13**|**Can Language Models Explain Their Own Classification Behavior?**|Dane Sherburn et.al.|[2405.07436v1](http://arxiv.org/abs/2405.07436v1)|[link](https://github.com/danesherbs/articulate-rules)|
|**2024-05-13**|**MoVL:Exploring Fusion Strategies for the Domain-Adaptive Application of Pretrained Models in Medical Imaging Tasks**|Haijiang Tian et.al.|[2405.07411v1](http://arxiv.org/abs/2405.07411v1)|null|
|**2024-05-13**|**PitcherNet: Powering the Moneyball Evolution in Baseball Video Analytics**|Jerrin Bright et.al.|[2405.07407v1](http://arxiv.org/abs/2405.07407v1)|null|
|**2024-05-13**|**Machine Unlearning: A Comprehensive Survey**|Weiqi Wang et.al.|[2405.07406v1](http://arxiv.org/abs/2405.07406v1)|null|
|**2024-05-13**|**Indoor PM2.5 forecasting and the association with outdoor air pollution: a modelling study based on sensor data in Australia**|Wenhua Yu et.al.|[2405.07404v1](http://arxiv.org/abs/2405.07404v1)|null|
|**2024-05-12**|**CaFA: Global Weather Forecasting with Factorized Attention on Sphere**|Zijie Li et.al.|[2405.07395v1](http://arxiv.org/abs/2405.07395v1)|null|
|**2024-05-12**|**AnyRotate: Gravity-Invariant In-Hand Object Rotation with Sim-to-Real Touch**|Max Yang et.al.|[2405.07391v1](http://arxiv.org/abs/2405.07391v1)|null|
|**2024-05-12**|**Conformalized Survival Distributions: A Generic Post-Process to Increase Calibration**|Shi-ang Qi et.al.|[2405.07374v1](http://arxiv.org/abs/2405.07374v1)|[link](https://github.com/shi-ang/csd)|
|**2024-05-12**|**Probabilistic and Causal Satisfiability: the Impact of Marginalization**|Julian Dörfler et.al.|[2405.07373v1](http://arxiv.org/abs/2405.07373v1)|null|
|**2024-05-12**|**WeedScout: Real-Time Autonomous blackgrass Classification and Mapping using dedicated hardware**|Matthew Gazzard et.al.|[2405.07349v1](http://arxiv.org/abs/2405.07349v1)|null|
|**2024-05-12**|**MedConceptsQA: Open Source Medical Concepts QA Benchmark**|Ofir Ben Shoham et.al.|[2405.07348v2](http://arxiv.org/abs/2405.07348v2)|[link](https://github.com/nadavlab/MedConceptsQA)|
|**2024-05-12**|**TKAN: Temporal Kolmogorov-Arnold Networks**|Remi Genet et.al.|[2405.07344v1](http://arxiv.org/abs/2405.07344v1)|[link](https://github.com/remigenet/tkan)|
|**2024-05-12**|**Liquid Ensemble Selection for Continual Learning**|Carter Blair et.al.|[2405.07327v1](http://arxiv.org/abs/2405.07327v1)|null|
|**2024-05-12**|**L(u)PIN: LLM-based Political Ideology Nowcasting**|Ken Kato et.al.|[2405.07320v1](http://arxiv.org/abs/2405.07320v1)|null|
|**2024-05-12**|**Machine Unlearning in Contrastive Learning**|Zixin Wang et.al.|[2405.07317v1](http://arxiv.org/abs/2405.07317v1)|null|
|**2024-05-12**|**DiffGen: Robot Demonstration Generation via Differentiable Physics Simulation, Differentiable Rendering, and Vision-Language Model**|Yang Jin et.al.|[2405.07309v1](http://arxiv.org/abs/2405.07309v1)|null|
|**2024-05-12**|**Environmental enrichment: a biological model of forward transfer in continual learning**|Rajat Saxena et.al.|[2405.07295v1](http://arxiv.org/abs/2405.07295v1)|null|
|**2024-05-12**|**Sparse Sampling is All You Need for Fast Wrong-way Cycling Detection in CCTV Videos**|Jing Xu et.al.|[2405.07293v1](http://arxiv.org/abs/2405.07293v1)|null|
|**2024-05-12**|**Branching Narratives: Character Decision Points Detection**|Alexey Tikhonov et.al.|[2405.07282v1](http://arxiv.org/abs/2405.07282v1)|null|
|**2024-05-12**|**Human-interpretable clustering of short-text using large language models**|Justin K. Miller et.al.|[2405.07278v1](http://arxiv.org/abs/2405.07278v1)|null|
|**2024-05-12**|**MAML MOT: Multiple Object Tracking based on Meta-Learning**|Jiayi Chen et.al.|[2405.07272v1](http://arxiv.org/abs/2405.07272v1)|null|
|**2024-05-12**|**A Supervised Information Enhanced Multi-Granularity Contrastive Learning Framework for EEG Based Emotion Recognition**|Xiang Li et.al.|[2405.07260v1](http://arxiv.org/abs/2405.07260v1)|[link](https://github.com/muzixiang/si-cleer)|
|**2024-05-12**|**Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis**|Nikolay B Petrov et.al.|[2405.07248v1](http://arxiv.org/abs/2405.07248v1)|null|
|**2024-05-12**|**OXYGENERATOR: Reconstructing Global Ocean Deoxygenation Over a Century with Deep Learning**|Bin Lu et.al.|[2405.07233v1](http://arxiv.org/abs/2405.07233v1)|null|
|**2024-05-12**|**Separable Power of Classical and Quantum Learning Protocols Through the Lens of No-Free-Lunch Theorem**|Xinbiao Wang et.al.|[2405.07226v1](http://arxiv.org/abs/2405.07226v1)|null|
|**2024-05-12**|**On Discovery of Local Independence over Continuous Variables via Neural Contextual Decomposition**|Inwoo Hwang et.al.|[2405.07220v1](http://arxiv.org/abs/2405.07220v1)|[link](https://github.com/iwhwang/ncd)|
|**2024-05-12**|**Enhancing Decision-Making in Optimization through LLM-Assisted Inference: A Neural Networks Perspective**|Gaurav Singh et.al.|[2405.07212v1](http://arxiv.org/abs/2405.07212v1)|null|

#### Abstracts
##### **MambaOut: Do We Really Need Mamba for Vision?**
2405.07992v1 by Weihao Yu, Xinchao Wang

Mamba, an architecture with RNN-like token mixer of state space model (SSM),
was recently introduced to address the quadratic complexity of the attention
mechanism and subsequently applied to vision tasks. Nevertheless, the
performance of Mamba for vision is often underwhelming when compared with
convolutional and attention-based models. In this paper, we delve into the
essence of Mamba, and conceptually conclude that Mamba is ideally suited for
tasks with long-sequence and autoregressive characteristics. For vision tasks,
as image classification does not align with either characteristic, we
hypothesize that Mamba is not necessary for this task; Detection and
segmentation tasks are also not autoregressive, yet they adhere to the
long-sequence characteristic, so we believe it is still worthwhile to explore
Mamba's potential for these tasks. To empirically verify our hypotheses, we
construct a series of models named \emph{MambaOut} through stacking Mamba
blocks while removing their core token mixer, SSM. Experimental results
strongly support our hypotheses. Specifically, our MambaOut model surpasses all
visual Mamba models on ImageNet image classification, indicating that Mamba is
indeed unnecessary for this task. As for detection and segmentation, MambaOut
cannot match the performance of state-of-the-art visual Mamba models,
demonstrating the potential of Mamba for long-sequence visual tasks. The code
is available at https://github.com/yuweihao/MambaOut

摘要：Mamba 是一種基於狀態空間模型 (SSM) 的 RNN 類似令牌混合器的架構，最近被引入來解決注意力機制的二次複雜性，並隨後應用於視覺任務。儘管如此，與基於卷積和注意力的模型相比，Mamba 在視覺方面的表現通常令人失望。在本文中，我們深入探討了 Mamba 的本質，並從概念上得出結論，Mamba 非常適合具有長序列和自迴歸特性的任務。對於視覺任務，由於影像分類不符合任何特徵，我們假設 Mamba 對此任務並非必要；檢測和分割任務也不是自迴歸的，但它們符合長序列特徵，因此我們相信探索 Mamba 在這些任務中的潛力仍然是有價值的。為了經驗驗證我們的假設，我們構建了一系列名為 \emph{MambaOut} 的模型，透過堆疊 Mamba 區塊同時移除其核心令牌混合器 SSM。實驗結果有力地支持了我們的假設。具體來說，我們的 MambaOut 模型在 ImageNet 影像分類上超越了所有視覺 Mamba 模型，這表明 Mamba 確實對此任務並非必要。至於檢測和分割，MambaOut 無法與最先進的視覺 Mamba 模型的性能相匹配，這證明了 Mamba 在長序列視覺任務中的潛力。程式碼可在 https://github.com/yuweihao/MambaOut 取得

##### **Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots**
2405.07990v1 by Chengyue Wu, Yixiao Ge, Qiushan Guo, Jiahao Wang, Zhixuan Liang, Zeyu Lu, Ying Shan, Ping Luo

The remarkable progress of Multi-modal Large Language Models (MLLMs) has
attracted significant attention due to their superior performance in visual
contexts. However, their capabilities in turning visual figure to executable
code, have not been evaluated thoroughly. To address this, we introduce
Plot2Code, a comprehensive visual coding benchmark designed for a fair and
in-depth assessment of MLLMs. We carefully collect 132 manually selected
high-quality matplotlib plots across six plot types from publicly available
matplotlib galleries. For each plot, we carefully offer its source code, and an
descriptive instruction summarized by GPT-4. This approach enables Plot2Code to
extensively evaluate MLLMs' code capabilities across various input modalities.
Furthermore, we propose three automatic evaluation metrics, including code pass
rate, text-match ratio, and GPT-4V overall rating, for a fine-grained
assessment of the output code and rendered images. Instead of simply judging
pass or fail, we employ GPT-4V to make an overall judgement between the
generated and reference images, which has been shown to be consistent with
human evaluation. The evaluation results, which include analyses of 14 MLLMs
such as the proprietary GPT-4V, Gemini-Pro, and the open-sourced Mini-Gemini,
highlight the substantial challenges presented by Plot2Code. With Plot2Code, we
reveal that most existing MLLMs struggle with visual coding for text-dense
plots, heavily relying on textual instruction. We hope that the evaluation
results from Plot2Code on visual coding will guide the future development of
MLLMs. All data involved with Plot2Code are available at
https://huggingface.co/datasets/TencentARC/Plot2Code.

摘要：多模態大型語言模型 (MLLM) 的顯著進步，由於其在視覺語境中的卓越表現，引起了廣泛關注。然而，它們將視覺圖形轉換為可執行程式碼的能力，尚未得到徹底評估。為了解決這個問題，我們引入了 Plot2Code，一個全面的視覺編碼基準，旨在對 MLLM 進行公平和深入的評估。我們仔細收集了 132 個手動挑選的高品質 matplotlib 圖形，涵蓋來自公開 matplotlib 庫的六種圖形類型。對於每個圖形，我們仔細提供了其原始程式碼，以及由 GPT-4 總結的描述性說明。這種方法使 Plot2Code 能夠廣泛評估 MLLM 的程式碼能力，涵蓋各種輸入模式。此外，我們提出了三種自動評估指標，包括程式碼通過率、文字匹配率和 GPT-4V 整體評分，用於對輸出程式碼和渲染圖像進行細粒度的評估。我們沒有簡單地判斷通過或失敗，而是採用 GPT-4V 對生成的圖像和參考圖像進行整體判斷，這已被證明與人類評估一致。評估結果包括對 14 個 MLLM（例如專有的 GPT-4V、Gemini-Pro 和開源的 Mini-Gemini）的分析，突出了 Plot2Code 帶來的重大挑戰。通過 Plot2Code，我們發現大多數現有的 MLLM 在處理文字密集型圖形的視覺編碼時都存在困難，嚴重依賴於文字說明。我們希望 Plot2Code 在視覺編碼上的評估結果，將指導 MLLM 未來的發展。Plot2Code 涉及的所有資料都可以在 https://huggingface.co/datasets/TencentARC/Plot2Code 取得。

##### **The Platonic Representation Hypothesis**
2405.07987v1 by Minyoung Huh, Brian Cheung, Tongzhou Wang, Phillip Isola

We argue that representations in AI models, particularly deep networks, are
converging. First, we survey many examples of convergence in the literature:
over time and across multiple domains, the ways by which different neural
networks represent data are becoming more aligned. Next, we demonstrate
convergence across data modalities: as vision models and language models get
larger, they measure distance between datapoints in a more and more alike way.
We hypothesize that this convergence is driving toward a shared statistical
model of reality, akin to Plato's concept of an ideal reality. We term such a
representation the platonic representation and discuss several possible
selective pressures toward it. Finally, we discuss the implications of these
trends, their limitations, and counterexamples to our analysis.

摘要：我們認為，人工智慧模型中的表徵，特別是深度網路，正在趨於一致。首先，我們檢視文獻中許多一致性的範例：隨著時間推移和跨越多個領域，不同神經網路表徵資料的方式正變得更為一致。接下來，我們示範跨資料型態的一致性：隨著視覺模型和語言模型變大，它們以越來越相似的模式衡量資料點之間的距離。我們假設這種一致性正朝向一個共享的現實統計模型邁進，類似於柏拉圖對理想現實的概念。我們將這種表徵稱為柏拉圖表徵，並討論了朝向它的幾種可能的選擇壓力。最後，我們討論這些趨勢的含意、它們的限制，以及對我們分析的反例。

##### **Localized Adaptive Risk Control**
2405.07976v1 by Matteo Zecchin, Osvaldo Simeone

Adaptive Risk Control (ARC) is an online calibration strategy based on set
prediction that offers worst-case deterministic long-term risk control, as well
as statistical marginal coverage guarantees. ARC adjusts the size of the
prediction set by varying a single scalar threshold based on feedback from past
decisions. In this work, we introduce Localized Adaptive Risk Control (L-ARC),
an online calibration scheme that targets statistical localized risk guarantees
ranging from conditional risk to marginal risk, while preserving the worst-case
performance of ARC. L-ARC updates a threshold function within a reproducing
kernel Hilbert space (RKHS), with the kernel determining the level of
localization of the statistical risk guarantee. The theoretical results
highlight a trade-off between localization of the statistical risk and
convergence speed to the long-term risk target. Thanks to localization, L-ARC
is demonstrated via experiments to produce prediction sets with risk guarantees
across different data subpopulations, significantly improving the fairness of
the calibrated model for tasks such as image segmentation and beam selection in
wireless networks.

摘要：自適應風險控制 (ARC) 是一種基於設定預測的線上校準策略，提供最壞情況的確定性長期風險控制，以及統計邊際覆蓋保證。ARC 透過根據過去決策的回饋調整預測設定的大小，來改變單一標量閾值。在這項工作中，我們引入了局部自適應風險控制 (L-ARC)，一種線上校準方案，其目標是統計局部風險保證，範圍從條件風險到邊際風險，同時保留 ARC 的最壞情況表現。L-ARC 在再生核希爾伯特空間 (RKHS) 中更新閾值函數，其中核決定統計風險保證的局部化程度。理論結果強調了統計風險局部化與長期風險目標收斂速度之間的權衡。由於局部化，L-ARC 透過實驗證明產生具有風險保證的預測設定，涵蓋不同的資料子群體，顯著改善校準模型在影像分割和無線網路中波束選擇等任務的公平性。

##### **Investigating the Semantic Robustness of CLIP-based Zero-Shot Anomaly Segmentation**
2405.07969v1 by Kevin Stangl, Marius Arvinte, Weilin Xu, Cory Cornelius

Zero-shot anomaly segmentation using pre-trained foundation models is a
promising approach that enables effective algorithms without expensive,
domain-specific training or fine-tuning. Ensuring that these methods work
across various environmental conditions and are robust to distribution shifts
is an open problem. We investigate the performance of WinCLIP [14] zero-shot
anomaly segmentation algorithm by perturbing test data using three semantic
transformations: bounded angular rotations, bounded saturation shifts, and hue
shifts. We empirically measure a lower performance bound by aggregating across
per-sample worst-case perturbations and find that average performance drops by
up to 20% in area under the ROC curve and 40% in area under the per-region
overlap curve. We find that performance is consistently lowered on three CLIP
backbones, regardless of model architecture or learning objective,
demonstrating a need for careful performance evaluation.

摘要：使用預訓練基礎模型進行零次異常分割是一種有前途的方法，它能讓有效演算法在沒有昂貴的特定領域訓練或微調的情況下運作。確保這些方法能在各種環境條件下運作，並且對分佈轉移具有穩健性，是一個公開的問題。我們透過使用三個語義轉換（有界角旋轉、有界飽和度轉移和色相轉移）擾動測試資料，來調查 WinCLIP [14] 零次異常分割演算法的效能。我們透過彙總每個樣本最壞情況的擾動，經驗性地測量較低的效能界限，並發現 ROC 曲線下的面積平均效能下降了 20%，而每個區域重疊曲線下的面積則下降了 40%。我們發現效能在一貫地降低於三個 CLIP 主幹上，而與模型架構或學習目標無關，這證明了仔細評估效能的必要性。

##### **OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**
2405.07966v1 by Qiuchi Xiang, Jintao Cheng, Jiehao Luo, Jin Wu, Rui Fan, Xieyuanli Chen, Xiaoyu Tang

Place recognition is the foundation for enabling autonomous systems to
achieve independent decision-making and safe operations. It is also crucial in
tasks such as loop closure detection and global localization within SLAM.
Previous methods utilize mundane point cloud representations as input and deep
learning-based LiDAR-based Place Recognition (LPR) approaches employing
different point cloud image inputs with convolutional neural networks (CNNs) or
transformer architectures. However, the recently proposed Mamba deep learning
model, combined with state space models (SSMs), holds great potential for long
sequence modeling. Therefore, we developed OverlapMamba, a novel network for
place recognition, which represents input range views (RVs) as sequences. In a
novel way, we employ a stochastic reconstruction approach to build shift state
space models, compressing the visual representation. Evaluated on three
different public datasets, our method effectively detects loop closures,
showing robustness even when traversing previously visited locations from
different directions. Relying on raw range view inputs, it outperforms typical
LiDAR and multi-view combination methods in time complexity and speed,
indicating strong place recognition capabilities and real-time efficiency.

摘要：場景辨識是讓自主系統能獨立決策和安全運作的基礎。它在 SLAM 中的迴路閉合偵測和全局定位等任務中也至關重要。先前的做法會利用平凡的點雲表示作為輸入，以及採用卷積神經網路 (CNN) 或Transformer架構，使用不同的點雲影像輸入的深度學習式雷射雷達場景辨識 (LPR) 方法。然而，最近提出的 Mamba 深度學習模型結合狀態空間模型 (SSM)，在長序列建模方面擁有極佳的潛力。因此，我們開發了 OverlapMamba，這是一個用於場景辨識的新穎網路，它將輸入範圍視圖 (RV) 表示為序列。我們採用一種隨機重建方法來建立轉移狀態空間模型，壓縮視覺表示，這是一個新穎的做法。在三個不同的公開資料集上進行評估，我們的做法有效地偵測到迴路閉合，即使從不同的方向穿越先前造訪過的地點，也展現出穩健性。它依賴未處理的範圍視圖輸入，在時間複雜度和速度上優於典型的 LiDAR 和多視圖組合方法，顯示出強大的場景辨識能力和即時效率。

##### **AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments**
2405.07960v1 by Samuel Schmidgall, Rojin Ziaei, Carl Harris, Eduardo Reis, Jeffrey Jopling, Michael Moor

Diagnosing and managing a patient is a complex, sequential decision making
process that requires physicians to obtain information -- such as which tests
to perform -- and to act upon it. Recent advances in artificial intelligence
(AI) and large language models (LLMs) promise to profoundly impact clinical
care. However, current evaluation schemes overrely on static medical
question-answering benchmarks, falling short on interactive decision-making
that is required in real-life clinical work. Here, we present AgentClinic: a
multimodal benchmark to evaluate LLMs in their ability to operate as agents in
simulated clinical environments. In our benchmark, the doctor agent must
uncover the patient's diagnosis through dialogue and active data collection. We
present two open benchmarks: a multimodal image and dialogue environment,
AgentClinic-NEJM, and a dialogue-only environment, AgentClinic-MedQA. We embed
cognitive and implicit biases both in patient and doctor agents to emulate
realistic interactions between biased agents. We find that introducing bias
leads to large reductions in diagnostic accuracy of the doctor agents, as well
as reduced compliance, confidence, and follow-up consultation willingness in
patient agents. Evaluating a suite of state-of-the-art LLMs, we find that
several models that excel in benchmarks like MedQA are performing poorly in
AgentClinic-MedQA. We find that the LLM used in the patient agent is an
important factor for performance in the AgentClinic benchmark. We show that
both having limited interactions as well as too many interaction reduces
diagnostic accuracy in doctor agents. The code and data for this work is
publicly available at https://AgentClinic.github.io.

摘要：診斷和管理病人是一個複雜、循序漸進的決策制定過程，需要醫生獲取資訊（例如要執行哪些測試）並採取行動。人工智慧 (AI) 和大型語言模型 (LLM) 的最新進展有望對臨床護理產生深遠影響。然而，目前的評估方案過於依賴靜態醫療問答基準，在現實生活中臨床工作中所需的互動決策制定方面有所不足。在此，我們提出 AgentClinic：一個多模態基準，用於評估 LLM 在模擬臨床環境中作為代理運作的能力。在我們的基準中，醫生代理必須透過對話和主動數據收集來找出病人的診斷。我們提出了兩個開放基準：一個多模態影像和對話環境 AgentClinic-NEJM，以及一個僅對話的環境 AgentClinic-MedQA。我們將認知和隱含偏見嵌入病人和醫生代理中，以模擬有偏見的代理之間的現實互動。我們發現，引入偏見會導致醫生代理的診斷準確性大幅下降，以及病人代理的順從性、信心和後續諮詢意願下降。在評估一系列最先進的 LLM 時，我們發現幾個在 MedQA 等基準中表現出色的模型在 AgentClinic-MedQA 中表現不佳。我們發現用於病人代理的 LLM 是 AgentClinic 基準中表現的關鍵因素。我們表明，互動次數受限和互動次數過多都會降低醫生代理的診斷準確性。這項工作的程式碼和數據已公開發布於 https://AgentClinic.github.io。

##### **Hierarchical Decision Mamba**
2405.07943v1 by André Correia, Luís A. Alexandre

Recent advancements in imitation learning have been largely fueled by the
integration of sequence models, which provide a structured flow of information
to effectively mimic task behaviours. Currently, Decision Transformer (DT) and
subsequently, the Hierarchical Decision Transformer (HDT), presented
Transformer-based approaches to learn task policies. Recently, the Mamba
architecture has shown to outperform Transformers across various task domains.
In this work, we introduce two novel methods, Decision Mamba (DM) and
Hierarchical Decision Mamba (HDM), aimed at enhancing the performance of the
Transformer models. Through extensive experimentation across diverse
environments such as OpenAI Gym and D4RL, leveraging varying demonstration data
sets, we demonstrate the superiority of Mamba models over their Transformer
counterparts in a majority of tasks. Results show that HDM outperforms other
methods in most settings. The code can be found at
https://github.com/meowatthemoon/HierarchicalDecisionMamba.

摘要：最近的模仿學習進展在很大程度上是由序列模型的整合推動的，這些模型提供了結構化的資訊流，以有效地模仿任務行為。目前，決策Transformer (DT) 以及隨後的層級決策Transformer (HDT) 提出基於Transformer的策略來學習任務政策。最近，Mamba 架構已證明在各種任務領域中優於Transformer。在這項工作中，我們介紹了兩種新方法，即決策 Mamba (DM) 和層級決策 Mamba (HDM)，旨在增強Transformer模型的效能。透過在不同的環境（例如 OpenAI Gym 和 D4RL）中進行廣泛的實驗，利用不同的示範資料集，我們證明了 Mamba 模型在大部分任務中優於其Transformer對應模型。結果顯示，HDM 在大多數設定中優於其他方法。程式碼可以在 https://github.com/meowatthemoon/HierarchicalDecisionMamba 中找到。

##### **RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors**
2405.07940v1 by Liam Dugan, Alyssa Hwang, Filip Trhlik, Josh Magnus Ludan, Andrew Zhu, Hainiu Xu, Daphne Ippolito, Chris Callison-Burch

Many commercial and open-source models claim to detect machine-generated text
with very high accuracy (99\% or higher). However, very few of these detectors
are evaluated on shared benchmark datasets and even when they are, the datasets
used for evaluation are insufficiently challenging -- lacking variations in
sampling strategy, adversarial attacks, and open-source generative models. In
this work we present RAID: the largest and most challenging benchmark dataset
for machine-generated text detection. RAID includes over 6 million generations
spanning 11 models, 8 domains, 11 adversarial attacks and 4 decoding
strategies. Using RAID, we evaluate the out-of-domain and adversarial
robustness of 8 open- and 4 closed-source detectors and find that current
detectors are easily fooled by adversarial attacks, variations in sampling
strategies, repetition penalties, and unseen generative models. We release our
dataset and tools to encourage further exploration into detector robustness.

摘要：許多商業和開放原始碼模型聲稱能以極高的準確度（99% 或更高）偵測機器產生的文字。然而，這些偵測器中只有極少數會在共用基準資料集上進行評估，即使有，用於評估的資料集挑戰性也不足，缺乏取樣策略、對抗性攻擊和開放原始碼生成模型的變化。在這項工作中，我們提出了 RAID：機器產生的文字偵測中最大且最具挑戰性的基準資料集。RAID 包含超過 600 萬個世代，涵蓋 11 個模型、8 個網域、11 個對抗性攻擊和 4 個解碼策略。使用 RAID，我們評估了 8 個開放原始碼和 4 個閉源偵測器的網域外和對抗性穩健性，發現目前的偵測器很容易被對抗性攻擊、取樣策略的變化、重複懲罰和未見過的生成模型所愚弄。我們釋出我們的資料集和工具，以鼓勵進一步探索偵測器的穩健性。

##### **EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning**
2405.07938v1 by Yinzhu Quan, Zefang Liu

In this paper, we introduce EconLogicQA, a rigorous benchmark designed to
assess the sequential reasoning capabilities of large language models (LLMs)
within the intricate realms of economics, business, and supply chain
management. Diverging from traditional benchmarks that predict subsequent
events individually, EconLogicQA poses a more challenging task: it requires
models to discern and sequence multiple interconnected events, capturing the
complexity of economic logics. EconLogicQA comprises an array of multi-event
scenarios derived from economic articles, which necessitate an insightful
understanding of both temporal and logical event relationships. Through
comprehensive evaluations, we exhibit that EconLogicQA effectively gauges a
LLM's proficiency in navigating the sequential complexities inherent in
economic contexts. We provide a detailed description of EconLogicQA dataset and
shows the outcomes from evaluating the benchmark across various leading-edge
LLMs, thereby offering a thorough perspective on their sequential reasoning
potential in economic contexts. Our benchmark dataset is available at
https://huggingface.co/datasets/yinzhu-quan/econ_logic_qa.

摘要：<paragraph>在本文中，我們介紹了 EconLogicQA，這是一個嚴謹的基準，旨在評估大型語言模型 (LLM) 在經濟、商業和供應鏈管理的複雜領域中進行順序推理的能力。與預測後續事件的傳統基準不同，EconLogicQA 提出了一項更具挑戰性的任務：它要求模型辨別和排序多個相互關聯的事件，捕捉經濟邏輯的複雜性。EconLogicQA 包含一系列源自經濟文章的多事件場景，需要深入了解時間和邏輯事件關係。通過綜合評估，我們展示了 EconLogicQA 有效地衡量了 LLM 在應對經濟背景中固有的順序複雜性方面的能力。我們提供了 EconLogicQA 數據集的詳細描述，並展示了在各種領先的 LLM 中評估基準的結果，從而全面了解了它們在經濟背景下的順序推理潛力。我們的基準數據集可在 https://huggingface.co/datasets/yinzhu-quan/econ_logic_qa 獲得。</paragraph>

##### **PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition**
2405.07932v2 by Ziyang Zhang, Qizhen Zhang, Jakob Foerster

Large language models (LLMs) have shown success in many natural language
processing tasks. Despite rigorous safety alignment processes, supposedly
safety-aligned LLMs like Llama 2 and Claude 2 are still susceptible to
jailbreaks, leading to security risks and abuse of the models. One option to
mitigate such risks is to augment the LLM with a dedicated "safeguard", which
checks the LLM's inputs or outputs for undesired behaviour. A promising
approach is to use the LLM itself as the safeguard. Nonetheless, baseline
methods, such as prompting the LLM to self-classify toxic content, demonstrate
limited efficacy. We hypothesise that this is due to domain shift: the
alignment training imparts a self-censoring behaviour to the model ("Sorry I
can't do that"), while the self-classify approach shifts it to a classification
format ("Is this prompt malicious"). In this work, we propose PARDEN, which
avoids this domain shift by simply asking the model to repeat its own outputs.
PARDEN neither requires finetuning nor white box access to the model. We
empirically verify the effectiveness of our method and show that PARDEN
significantly outperforms existing jailbreak detection baselines for Llama-2
and Claude-2. Code and data are available at https://github.com/Ed-Zh/PARDEN.
  We find that PARDEN is particularly powerful in the relevant regime of high
True Positive Rate (TPR) and low False Positive Rate (FPR). For instance, for
Llama2-7B, at TPR equal to 90%, PARDEN accomplishes a roughly 11x reduction in
the FPR from 24.8% to 2.0% on the harmful behaviours dataset.

摘要：大型語言模型 (LLM) 已在許多自然語言處理任務中展現成功。儘管進行嚴格的安全調整程序，但理論上經過安全調整的 LLM（例如 Llama 2 和 Claude 2）仍容易受到越獄攻擊，導致安全風險和模型遭到濫用。減輕此類風險的一個選項是使用專用的「防護措施」擴充 LLM，用於檢查 LLM 的輸入或輸出是否有不良行為。一種有前景的方法是使用 LLM 本身作為防護措施。儘管如此，基線方法（例如提示 LLM 自我分類有毒內容）顯示出有限的功效。我們假設這是由於領域轉移：調整訓練會讓模型產生自我審查行為（「抱歉，我無法這麼做」），而自我分類方法會將其轉移到分類格式（「這個提示是否惡意」）。在這項工作中，我們提出 PARDEN，它透過簡單地要求模型重複其自己的輸出，來避免這種領域轉移。PARDEN 不需要微調或對模型進行白盒存取。我們透過實證驗證我們的方法的有效性，並顯示 PARDEN 在 Llama-2 和 Claude-2 的現有越獄偵測基線上顯著優於其他方法。程式碼和資料可在 https://github.com/Ed-Zh/PARDEN 取得。我們發現 PARDEN 在高真實正類率 (TPR) 和低虛假正類率 (FPR) 的相關範圍中特別有效。例如，對於 Llama2-7B，在 TPR 等於 90% 時，PARDEN 在有害行為資料集上將 FPR 從 24.8% 降低到 2.0%，減少了大約 11 倍。

##### **Stable Diffusion-based Data Augmentation for Federated Learning with Non-IID Data**
2405.07925v1 by Mahdi Morafah, Matthias Reisser, Bill Lin, Christos Louizos

The proliferation of edge devices has brought Federated Learning (FL) to the
forefront as a promising paradigm for decentralized and collaborative model
training while preserving the privacy of clients' data. However, FL struggles
with a significant performance reduction and poor convergence when confronted
with Non-Independent and Identically Distributed (Non-IID) data distributions
among participating clients. While previous efforts, such as client drift
mitigation and advanced server-side model fusion techniques, have shown some
success in addressing this challenge, they often overlook the root cause of the
performance reduction - the absence of identical data accurately mirroring the
global data distribution among clients. In this paper, we introduce Gen-FedSD,
a novel approach that harnesses the powerful capability of state-of-the-art
text-to-image foundation models to bridge the significant Non-IID performance
gaps in FL. In Gen-FedSD, each client constructs textual prompts for each class
label and leverages an off-the-shelf state-of-the-art pre-trained Stable
Diffusion model to synthesize high-quality data samples. The generated
synthetic data is tailored to each client's unique local data gaps and
distribution disparities, effectively making the final augmented local data
IID. Through extensive experimentation, we demonstrate that Gen-FedSD achieves
state-of-the-art performance and significant communication cost savings across
various datasets and Non-IID settings.

摘要：边缘裝置的激增使聯邦學習 (FL) 成為一種有前景的去中心化和協作模型訓練範例，同時還能保護客戶資料的隱私。然而，當面對參與客戶之間的非獨立且同分布 (Non-IID) 資料分佈時，FL 會出現效能大幅下降和收斂不佳的問題。儘管先前的努力，例如客戶漂移緩解和進階伺服器端模型融合技術，已在解決此挑戰方面取得一些成功，但它們常常忽略效能下降的根本原因，也就是缺乏與客戶之間的全球資料分佈完全相同的資料。在本文中，我們介紹了 Gen-FedSD，這是一種新方法，它利用了最先進的文字轉圖像基礎模型的強大功能，來彌合 FL 中顯著的 Non-IID 效能差距。在 Gen-FedSD 中，每個客戶端會為每個類別標籤建構文字提示，並利用現成的最先進預先訓練的 Stable Diffusion 模型來合成高品質的資料樣本。所生成的合成資料是根據每個客戶端獨特的本地資料差距和分佈差異量身打造，有效地使最終擴增的本地資料成為 IID。透過大量的實驗，我們證明 Gen-FedSD 在各種資料集和 Non-IID 設定中都達到了最先進的效能和顯著的通訊成本節省。

##### **Science based AI model certification for new operational environments with application in traffic state estimation**
2405.07893v1 by Daryl Mupupuni, Anupama Guntu, Liang Hong, Kamrul Hasan, Leehyun Keel

The expanding role of Artificial Intelligence (AI) in diverse engineering
domains highlights the challenges associated with deploying AI models in new
operational environments, involving substantial investments in data collection
and model training. Rapid application of AI necessitates evaluating the
feasibility of utilizing pre-trained models in unobserved operational settings
with minimal or no additional data. However, interpreting the opaque nature of
AI's black-box models remains a persistent challenge. Addressing this issue,
this paper proposes a science-based certification methodology to assess the
viability of employing pre-trained data-driven models in new operational
environments. The methodology advocates a profound integration of domain
knowledge, leveraging theoretical and analytical models from physics and
related disciplines, with data-driven AI models. This novel approach introduces
tools to facilitate the development of secure engineering systems, providing
decision-makers with confidence in the trustworthiness and safety of AI-based
models across diverse environments characterized by limited training data and
dynamic, uncertain conditions. The paper demonstrates the efficacy of this
methodology in real-world safety-critical scenarios, particularly in the
context of traffic state estimation. Through simulation results, the study
illustrates how the proposed methodology efficiently quantifies physical
inconsistencies exhibited by pre-trained AI models. By utilizing analytical
models, the methodology offers a means to gauge the applicability of
pre-trained AI models in new operational environments. This research
contributes to advancing the understanding and deployment of AI models,
offering a robust certification framework that enhances confidence in their
reliability and safety across a spectrum of operational conditions.

摘要：<paragraph>人工智慧 (AI) 在各種工程領域中扮演的角色日益擴大，突顯出在新的操作環境中部署 AI 模型所面臨的挑戰，這涉及在資料收集和模型訓練中進行大量的投資。AI 的快速應用需要評估在未觀察到的操作環境中利用預先訓練模型的可行性，而無需或只需最少的額外資料。然而，詮釋 AI 黑盒模型的不透明本質仍然是一個持續的挑戰。針對此問題，本文提出了一個基於科學的認證方法，用於評估在新的操作環境中採用預先訓練的資料驅動模型的可行性。此方法主張將領域知識與來自物理學和相關領域的理論和分析模型，與資料驅動的 AI 模型進行深入整合。這種新穎的方法引入了工具，以促進安全工程系統的開發，讓決策者對在受限訓練資料和動態、不確定的條件下，各種環境中基於 AI 的模型的可信度和安全性有信心。本文證明了這種方法在現實世界的安全關鍵情境中的效力，特別是在交通狀態估計的背景下。透過模擬結果，研究說明了所提出的方法如何有效地量化預先訓練的 AI 模型所表現出的物理不一致性。透過利用分析模型，此方法提供了一種手段來評估預先訓練的 AI 模型在新操作環境中的適用性。這項研究有助於推進對 AI 模型的理解和部署，提供了一個強大的認證架構，以增強對其在各種操作條件下的可靠性和安全性的信心。</paragraph>

##### **Russian-Language Multimodal Dataset for Automatic Summarization of Scientific Papers**
2405.07886v1 by Alena Tsanda, Elena Bruches

The paper discusses the creation of a multimodal dataset of Russian-language
scientific papers and testing of existing language models for the task of
automatic text summarization. A feature of the dataset is its multimodal data,
which includes texts, tables and figures. The paper presents the results of
experiments with two language models: Gigachat from SBER and YandexGPT from
Yandex. The dataset consists of 420 papers and is publicly available on
https://github.com/iis-research-team/summarization-dataset.

摘要：本文讨论了创建俄语科学论文的多模态数据集，以及针对自动文本摘要任务测试现有语言模型。该数据集的特点在于其多模态数据，其中包括文本、表格和图表。本文介绍了两种语言模型的实验结果：来自 SBER 的 Gigachat 和来自 Yandex 的 YandexGPT。该数据集包含 420 篇论文，可在 https://github.com/iis-research-team/summarization-dataset 上公开获取。

##### **Zero-Shot Tokenizer Transfer**
2405.07883v1 by Benjamin Minixhofer, Edoardo Maria Ponti, Ivan Vulić

Language models (LMs) are bound to their tokenizer, which maps raw text to a
sequence of vocabulary items (tokens). This restricts their flexibility: for
example, LMs trained primarily on English may still perform well in other
natural and programming languages, but have vastly decreased efficiency due to
their English-centric tokenizer. To mitigate this, we should be able to swap
the original LM tokenizer with an arbitrary one, on the fly, without degrading
performance. Hence, in this work we define a new problem: Zero-Shot Tokenizer
Transfer (ZeTT). The challenge at the core of ZeTT is finding embeddings for
the tokens in the vocabulary of the new tokenizer. Since prior heuristics for
initializing embeddings often perform at chance level in a ZeTT setting, we
propose a new solution: we train a hypernetwork taking a tokenizer as input and
predicting the corresponding embeddings. We empirically demonstrate that the
hypernetwork generalizes to new tokenizers both with encoder (e.g., XLM-R) and
decoder LLMs (e.g., Mistral-7B). Our method comes close to the original models'
performance in cross-lingual and coding tasks while markedly reducing the
length of the tokenized sequence. We also find that the remaining gap can be
quickly closed by continued training on less than 1B tokens. Finally, we show
that a ZeTT hypernetwork trained for a base (L)LM can also be applied to
fine-tuned variants without extra training. Overall, our results make
substantial strides toward detaching LMs from their tokenizer.

摘要：語言模型 (LM) 受限於其分詞器，它將原始文字對應到詞彙項目（標記）的序列。這限制了其靈活性：例如，主要以英語訓練的 LM 仍可能在其他自然語言和程式語言中表現良好，但由於其以英語為中心的標記器而大幅降低效率。為了減輕這個問題，我們應該能夠在不降低效能的情況下，隨時將原始 LM 標記器替換為任意標記器。因此，在這項工作中，我們定義了一個新問題：零次標記器轉移 (ZeTT)。ZeTT 的核心挑戰是為新標記器詞彙中的標記找到嵌入。由於用於初始化嵌入的先驗啟發法在 ZeTT 設定中通常表現得像隨機層級，我們提出了一個新的解決方案：我們訓練一個以標記器作為輸入並預測對應嵌入的超網路。我們透過實證證明，超網路可以概括到新的標記器，包括編碼器 (例如 XLM-R) 和解碼器 LLM (例如 Mistral-7B)。我們的模型在跨語言和編碼任務中接近原始模型的效能，同時顯著減少標記化序列的長度。我們還發現，透過持續訓練不到 1B 個標記，可以快速縮小剩下的差距。最後，我們展示了針對基礎 (L)LM 訓練的 ZeTT 超網路也可以應用於微調變體，而無需額外訓練。總的來說，我們的成果在將 LM 從其標記器中分離出來方面取得了重大進展。

##### **Reproducing the Metric-Based Evaluation of a Set of Controllable Text Generation Techniques**
2405.07875v1 by Michela Lorandi, Anya Belz

Rerunning a metric-based evaluation should be more straightforward, and
results should be closer, than in a human-based evaluation, especially where
code and model checkpoints are made available by the original authors. As this
report of our efforts to rerun a metric-based evaluation of a set of
single-attribute and multiple-attribute controllable text generation (CTG)
techniques shows however, such reruns of evaluations do not always produce
results that are the same as the original results, and can reveal errors in the
reporting of the original work.

摘要：重新執行基於指標的評估應該更為直接，而且結果應該比在基於人為的評估中更接近，特別是在原始作者提供程式碼和模型檢查點的情況下。然而，正如我們重新執行一組單一屬性和多重屬性可控文本生成 (CTG) 技術的基於指標的評估的努力報告所示，此類重新執行的評估並非總是會產生與原始結果相同的结果，並且可能會揭露原始工作報告中的錯誤。

##### **RLHF Workflow: From Reward Modeling to Online RLHF**
2405.07863v1 by Hanze Dong, Wei Xiong, Bo Pang, Haoxiang Wang, Han Zhao, Yingbo Zhou, Nan Jiang, Doyen Sahoo, Caiming Xiong, Tong Zhang

We present the workflow of Online Iterative Reinforcement Learning from Human
Feedback (RLHF) in this technical report, which is widely reported to
outperform its offline counterpart by a large margin in the recent large
language model (LLM) literature. However, existing open-source RLHF projects
are still largely confined to the offline learning setting. In this technical
report, we aim to fill in this gap and provide a detailed recipe that is easy
to reproduce for online iterative RLHF. In particular, since online human
feedback is usually infeasible for open-source communities with limited
resources, we start by constructing preference models using a diverse set of
open-source datasets and use the constructed proxy preference model to
approximate human feedback. Then, we discuss the theoretical insights and
algorithmic principles behind online iterative RLHF, followed by a detailed
practical implementation. Our trained LLM, SFR-Iterative-DPO-LLaMA-3-8B-R,
achieves impressive performance on LLM chatbot benchmarks, including
AlpacaEval-2, Arena-Hard, and MT-Bench, as well as other academic benchmarks
such as HumanEval and TruthfulQA. We have shown that supervised fine-tuning
(SFT) and iterative RLHF can obtain state-of-the-art performance with fully
open-source datasets. Further, we have made our models, curated datasets, and
comprehensive step-by-step code guidebooks publicly available. Please refer to
https://github.com/RLHFlow/RLHF-Reward-Modeling and
https://github.com/RLHFlow/Online-RLHF for more detailed information.

摘要：<paragraph>我們在這份技術報告中介紹了人類回饋在線迭代強化學習 (RLHF) 的工作流程，據廣泛報導，它在最近的大語言模型 (LLM) 文獻中大幅優於其離線對應項。然而，現有的開源 RLHF 項目在很大程度上仍然局限於離線學習設置。在這份技術報告中，我們旨在填補這一空白，並提供一個易於複製的在線迭代 RLHF 的詳細配方。特別是，由於在線人類回饋通常對於資源有限的開源社區來說不可行，我們首先使用多樣化的開源數據集構建偏好模型，並使用構建的代理偏好模型來近似人類回饋。然後，我們討論在線迭代 RLHF 背後的理論見解和演算法原理，然後進行詳細的實際實作。我們訓練的 LLM，SFR-Iterative-DPO-LLaMA-3-8B-R，在 LLM 聊天機器人基準上取得了令人印象深刻的效能，包括 AlpacaEval-2、Arena-Hard 和 MT-Bench，以及其他學術基準，例如 HumanEval 和 TruthfulQA。我們已經證明，監督微調 (SFT) 和迭代 RLHF 可以使用完全開源數據集獲得最先進的效能。此外，我們已經公開了我們的模型、精選數據集和全面的逐步程式碼指南。有關更多詳細資訊，請參閱 https://github.com/RLHFlow/RLHF-Reward-Modeling 和 https://github.com/RLHFlow/Online-RLHF。</paragraph>

##### **Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM**
2405.07840v1 by Xiaoyu Chen, Changde Du, Che Liu, Yizhe Wang, Huiguang He

Decoding language information from brain signals represents a vital research
area within brain-computer interfaces, particularly in the context of
deciphering the semantic information from the fMRI signal. However, many
existing efforts concentrate on decoding small vocabulary sets, leaving space
for the exploration of open vocabulary continuous text decoding. In this paper,
we introduce a novel method, the \textbf{Brain Prompt GPT (BP-GPT)}. By using
the brain representation that is extracted from the fMRI as a prompt, our
method can utilize GPT-2 to decode fMRI signals into stimulus text. Further, we
introduce a text-to-text baseline and align the fMRI prompt to the text prompt.
By introducing the text-to-text baseline, our BP-GPT can extract a more robust
brain prompt and promote the decoding of pre-trained LLM. We evaluate our
BP-GPT on the open-source auditory semantic decoding dataset and achieve a
significant improvement up to $4.61\%$ on METEOR and $2.43\%$ on BERTScore
across all the subjects compared to the state-of-the-art method. The
experimental results demonstrate that using brain representation as a prompt to
further drive LLM for auditory neural decoding is feasible and effective.

摘要：從腦部訊號解碼語言資訊，在腦電腦介面中是一個重要的研究領域，特別是在從 fMRI 訊號中解碼語意資訊的脈絡中。然而，許多現有的努力都集中在解碼小型詞彙集上，這為探索開放式詞彙連續文字解碼留下了空間。在本文中，我們介紹了一種新方法，即 \textbf{腦提示 GPT (BP-GPT)}。透過使用從 fMRI 中提取的腦部表徵作為提示，我們的模型可以使用 GPT-2 將 fMRI 訊號解碼成刺激文字。此外，我們引入了一個文字對文字的基準，並將 fMRI 提示與文字提示對齊。透過引入文字對文字的基準，我們的 BP-GPT 可以提取更穩健的腦部提示，並促進預先訓練好的 LLM 的解碼。我們在開放原始碼聽覺語意解碼資料集上評估我們的 BP-GPT，並在 METEOR 上獲得高達 4.61%，在 BERTScore 上獲得 2.43% 的顯著改進，與最先進的方法相比，所有受試者都獲得了改進。實驗結果表明，使用腦部表徵作為提示，進一步驅動 LLM 進行聽覺神經解碼是可行且有效的。

##### **Synthetic Tabular Data Validation: A Divergence-Based Approach**
2405.07822v1 by Patricia A. Apellániz, Ana Jiménez, Borja Arroyo Galende, Juan Parras, Santiago Zazo

The ever-increasing use of generative models in various fields where tabular
data is used highlights the need for robust and standardized validation metrics
to assess the similarity between real and synthetic data. Current methods lack
a unified framework and rely on diverse and often inconclusive statistical
measures. Divergences, which quantify discrepancies between data distributions,
offer a promising avenue for validation. However, traditional approaches
calculate divergences independently for each feature due to the complexity of
joint distribution modeling. This paper addresses this challenge by proposing a
novel approach that uses divergence estimation to overcome the limitations of
marginal comparisons. Our core contribution lies in applying a divergence
estimator to build a validation metric considering the joint distribution of
real and synthetic data. We leverage a probabilistic classifier to approximate
the density ratio between datasets, allowing the capture of complex
relationships. We specifically calculate two divergences: the well-known
Kullback-Leibler (KL) divergence and the Jensen-Shannon (JS) divergence. KL
divergence offers an established use in the field, while JS divergence is
symmetric and bounded, providing a reliable metric. The efficacy of this
approach is demonstrated through a series of experiments with varying
distribution complexities. The initial phase involves comparing estimated
divergences with analytical solutions for simple distributions, setting a
benchmark for accuracy. Finally, we validate our method on a real-world dataset
and its corresponding synthetic counterpart, showcasing its effectiveness in
practical applications. This research offers a significant contribution with
applicability beyond tabular data and the potential to improve synthetic data
validation in various fields.

摘要：<paragraph>生成模型在使用表格資料的各種領域中日益增加的使用，突顯了對健全且標準化的驗證指標的需求，以評估真實資料和合成資料之間的相似性。目前的驗證方法缺乏統一的架構，並且依賴於多樣且經常沒有定論的統計量度。量化資料分佈差異的差異度，為驗證提供了一條有希望的途徑。然而，傳統的方法由於聯合分佈建模的複雜性，會針對每個特徵獨立計算差異度。本文透過提出一個新的方法來解決這個挑戰，該方法使用差異度估計來克服邊際比較法的限制。我們核心貢獻在於應用差異度估計器來建立一個驗證指標，考慮真實資料和合成資料的聯合分佈。我們利用機率分類器來近似資料集之間的密度比，從而捕捉複雜的關係。我們特別計算了兩個差異度：眾所周知的 Kullback-Leibler (KL) 差異度和 Jensen-Shannon (JS) 差異度。KL 差異度在該領域有既定的用途，而 JS 差異度對稱且有界，提供了一個可靠的指標。這個方法的效能透過一系列具有不同分佈複雜度的實驗得到證明。初始階段涉及將估計的差異度與簡單分佈的解析解進行比較，設定準確度的基準。最後，我們在一個真實世界資料集及其對應的合成對應物上驗證了我們的驗證方法，展示了其在實際應用中的效能。這項研究提供了一個重大的貢獻，其適用性不僅限於表格資料，並且有潛力改善各種領域中的合成資料驗證。</paragraph>

##### **Quick and Accurate Affordance Learning**
2405.07816v1 by Fedor Scholz, Erik Ayari, Johannes Bertram, Martin V. Butz

Infants learn actively in their environments, shaping their own learning
curricula. They learn about their environments' affordances, that is, how local
circumstances determine how their behavior can affect the environment. Here we
model this type of behavior by means of a deep learning architecture. The
architecture mediates between global cognitive map exploration and local
affordance learning. Inference processes actively move the simulated agent
towards regions where they expect affordance-related knowledge gain. We
contrast three measures of uncertainty to guide this exploration: predicted
uncertainty of a model, standard deviation between the means of several models
(SD), and the Jensen-Shannon Divergence (JSD) between several models. We show
that the first measure gets fooled by aleatoric uncertainty inherent in the
environment, while the two other measures focus learning on epistemic
uncertainty. JSD exhibits the most balanced exploration strategy. From a
computational perspective, our model suggests three key ingredients for
coordinating the active generation of learning curricula: (1) Navigation
behavior needs to be coordinated with local motor behavior for enabling active
affordance learning. (2) Affordances need to be encoded locally for acquiring
generalized knowledge. (3) Effective active affordance learning mechanisms
should use density comparison techniques for estimating expected knowledge
gain. Future work may seek collaborations with developmental psychology to
model active play in children in more realistic scenarios.

摘要：嬰兒積極地在他們的環境中學習，塑造他們自己的學習課程。他們了解他們環境的可能性，也就是說，當地環境如何決定他們的行為如何影響環境。在這裡，我們通過深度學習架構對這種行為類型進行建模。該架構在全局認知地圖探索和局部可能性學習之間進行調解。推理過程積極地將模擬代理移動到他們預期獲得可能性相關知識的地區。我們對不確定性的三個測量進行對比，以指導此探索：模型的預測不確定性、幾個模型的平均值之間的標準差 (SD) 以及幾個模型之間的 Jensen-Shannon 散度 (JSD)。我們表明，第一個測量被環境中固有的偶然不確定性所愚弄，而另外兩個測量則將學習重點放在認識論不確定性上。JSD 表現出最平衡的探索策略。從計算的角度來看，我們的模型提出了協調主動生成學習課程的三個關鍵要素：(1) 導航行為需要與局部運動行為協調，以實現主動可能性學習。(2) 可能性需要在局部編碼以獲取廣泛的知識。(3) 有效的積極可能性學習機制應使用密度比較技術來估計預期的知識收益。未來的研究可以尋求與發展心理學的合作，在更現實的場景中對兒童的積極遊戲進行建模。

##### **Decoding Geometric Properties in Non-Random Data from First Information-Theoretic Principles**
2405.07803v1 by Hector Zenil, Felipe S. Abrahão

Based on the principles of information theory, measure theory, and
theoretical computer science, we introduce a univariate signal deconvolution
method with a wide range of applications to coding theory, particularly in
zero-knowledge one-way communication channels, such as in deciphering messages
from unknown generating sources about which no prior knowledge is available and
to which no return message can be sent. Our multidimensional space
reconstruction method from an arbitrary received signal is proven to be
agnostic vis-a-vis the encoding-decoding scheme, computation model, programming
language, formal theory, the computable (or semi-computable) method of
approximation to algorithmic complexity, and any arbitrarily chosen
(computable) probability measure of the events. The method derives from the
principles of an approach to Artificial General Intelligence capable of
building a general-purpose model of models independent of any arbitrarily
assumed prior probability distribution. We argue that this optimal and
universal method of decoding non-random data has applications to signal
processing, causal deconvolution, topological and geometric properties
encoding, cryptography, and bio- and technosignature detection.

摘要：基於資訊理論、測度理論和理論電腦科學的原理，我們介紹了一種單變量信號反摺積方法，它在編碼理論中具有廣泛的應用，特別是在零知識單向通信通道中，例如在破譯來自未知生成源的訊息時，這些訊息沒有可用的先驗知識，並且無法發送回傳訊息。我們從任意接收信號中重建多維空間的方法被證明與編碼解碼方案、計算模型、程式語言、形式理論、演算法複雜度近似的可計算（或半可計算）方法，以及事件的任何任意選擇（可計算）機率測度無關。該方法源自人工通用智慧的一種方法的原理，該方法能夠建立一個通用模型模型，而與任何任意假設的先驗機率分佈無關。我們認為，這種最佳且通用的非隨機資料解碼方法在信號處理、因果反摺積、拓撲和幾何性質編碼、密碼學以及生物和技術特徵偵測中都有應用。

##### **FreeVA: Offline MLLM as Training-Free Video Assistant**
2405.07798v1 by Wenhao Wu

This paper undertakes an empirical study to revisit the latest advancements
in Multimodal Large Language Models (MLLMs): Video Assistant. This study,
namely FreeVA, aims to extend existing image-based MLLM to the video domain in
a training-free manner. The study provides an essential, yet must-know
baseline, and reveals several surprising findings: 1) FreeVA, leveraging only
offline image-based MLLM without additional training, excels in zero-shot video
question-answering (e.g., MSVD-QA, ActivityNet-QA, and MSRVTT-QA), even
surpassing state-of-the-art methods that involve video instruction tuning. 2)
While mainstream video-based MLLMs typically initialize with an image-based
MLLM (e.g., LLaVA) and then fine-tune using video instruction tuning, the study
indicates that utilizing the widely adopted VideoInstruct-100K for video
instruction tuning doesn't actually lead to better performance compared to not
training at all. 3) The commonly used evaluation metrics in existing works are
significantly influenced by changes in the GPT API version over time. If
ignored, this could affect the fairness and uniformity of comparisons between
different methods and impact the analysis and judgment of researchers in the
field. The advancement of MLLMs is currently thriving, drawing numerous
researchers into the field. We aim for this work to serve as a plug-and-play,
simple yet effective baseline, encouraging the direct evaluation of existing
MLLMs in video domain while also standardizing the field of video
conversational models to a certain extent. Also, we encourage researchers to
reconsider: Have current video MLLM methods truly acquired knowledge beyond
image MLLM? Code is available at https://github.com/whwu95/FreeVA

摘要：<paragraph>本文進行一項實證研究，以重新探討多模態大型語言模型 (MLLM) 中的最新進展：影片助理。本研究，即 FreeVA，旨在以無需訓練的方式將現有的基於影像的 MLLM 擴展到影片領域。本研究提供了一個必要的且必須知道的基準，並揭示了幾個令人驚訝的發現：1) FreeVA 僅利用離線的基於影像的 MLLM，而無需額外的訓練，就能在零次學習影片問答（例如 MSVD-QA、ActivityNet-QA 和 MSRVTT-QA）方面表現出色，甚至超越了涉及影片指令微調的現有方法。2) 儘管主流的基於影片的 MLLM 通常使用基於影像的 MLLM（例如 LLaVA）初始化，然後使用影片指令微調進行微調，但研究表明，使用廣泛採用的 VideoInstruct-100K 進行影片指令微調並未真正帶來比完全不進行訓練更好的效能。3) 現有研究中常用的評量指標會隨著時間推移而受到 GPT API 版本變更的顯著影響。如果忽略這一點，可能會影響不同方法之間比較時公平性和一致性，並影響該領域研究人員的分析和判斷。MLLM 的進展目前蓬勃發展，吸引了許多研究人員進入該領域。我們希望這項工作能作為一個即插即用、簡單但有效的基準，鼓勵直接評估影片領域中現有的 MLLM，同時也在一定程度上標準化影片對話模型的領域。此外，我們鼓勵研究人員重新考慮：目前的影片 MLLM 方法是否真正獲得了超越影像 MLLM 的知識？程式碼可在 https://github.com/whwu95/FreeVA 取得</paragraph>

##### **DEPTH: Discourse Education through Pre-Training Hierarchically**
2405.07788v1 by Zachary Bamberger, Ofek Glick, Chaim Baskin, Yonatan Belinkov

Language Models (LMs) often struggle with linguistic understanding at the
discourse level, even though discourse patterns such as coherence, cohesion,
and narrative flow are prevalent in their pre-training data. Current methods
address these challenges only after the pre-training phase, relying on
expensive human annotated data to align the model. To improve the discourse
capabilities of LMs already at the pre-training stage, we introduce DEPTH, an
encoder-decoder model that learns to represent sentences using a
discourse-oriented pre-training objective. DEPTH combines hierarchical sentence
representations with two objectives: (1) Sentence Un-Shuffling, and (2)
Span-Corruption. This approach trains the model to represent both
sub-word-level and sentence-level dependencies over a massive amount of
unstructured text. When trained either from scratch or continuing from a
pre-trained T5 checkpoint, DEPTH learns semantic and discourse-level
representations faster than T5, outperforming it in span-corruption loss
despite the additional sentence-un-shuffling objective. Evaluations on the
GLUE, DiscoEval, and NI benchmarks demonstrate DEPTH's ability to quickly learn
diverse downstream tasks, which require syntactic, semantic, and discourse
capabilities. Overall, our approach extends the discourse capabilities of T5,
while minimally impacting other natural language understanding (NLU)
capabilities in the resulting LM.

摘要：語言模型 (LM) 經常在語篇層級的語言理解上遇到困難，即使連貫性、凝聚力和敘事流等語篇模式在其預訓練資料中很普遍。目前的技術只在預訓練階段之後才處理這些挑戰，依賴昂貴的人工註解資料來調整模型。為了在預訓練階段就提升 LM 的語篇能力，我們引入了 DEPTH，一個編碼器-解碼器模型，它學習使用以語篇為導向的預訓練目標來表示句子。DEPTH 結合了分層句子表示法和兩個目標：(1) 句子取消混洗，以及 (2) 區間損毀。此方法訓練模型表示海量非結構化文字中的子字元層級和句子層級依賴性。當從頭開始訓練或從預訓練的 T5 檢查點繼續訓練時，DEPTH 會比 T5 更快地學習語義和語篇層級表示法，儘管有額外的句子取消混洗目標，但在區間損毀損失中表現優於 T5。在 GLUE、DiscoEval 和 NI 基準上的評估證明了 DEPTH 快速學習各種下游任務的能力，這些任務需要句法、語義和語篇能力。總體而言，我們的做法擴展了 T5 的語篇能力，同時將對最終 LM 中其他自然語言理解 (NLU) 能力的影響降至最低。

##### **A Comprehensive Analysis of Static Word Embeddings for Turkish**
2405.07778v1 by Karahan Sarıtaş, Cahid Arda Öz, Tunga Güngör

Word embeddings are fixed-length, dense and distributed word representations
that are used in natural language processing (NLP) applications. There are
basically two types of word embedding models which are non-contextual (static)
models and contextual models. The former method generates a single embedding
for a word regardless of its context, while the latter method produces distinct
embeddings for a word based on the specific contexts in which it appears. There
are plenty of works that compare contextual and non-contextual embedding models
within their respective groups in different languages. However, the number of
studies that compare the models in these two groups with each other is very few
and there is no such study in Turkish. This process necessitates converting
contextual embeddings into static embeddings. In this paper, we compare and
evaluate the performance of several contextual and non-contextual models in
both intrinsic and extrinsic evaluation settings for Turkish. We make a
fine-grained comparison by analyzing the syntactic and semantic capabilities of
the models separately. The results of the analyses provide insights about the
suitability of different embedding models in different types of NLP tasks. We
also build a Turkish word embedding repository comprising the embedding models
used in this work, which may serve as a valuable resource for researchers and
practitioners in the field of Turkish NLP. We make the word embeddings,
scripts, and evaluation datasets publicly available.

摘要：字詞嵌入是固定長度、密集且分散的字詞表示，用於自然語言處理 (NLP) 應用程式中。基本上有兩種字詞嵌入模型，分別是非語境 (靜態) 模型和語境模型。前一種方法為字詞產生單一嵌入，不論其語境為何，而後一種方法則根據字詞出現的特定語境為其產生不同的嵌入。有許多研究在不同語言中比較其各自群組中的語境和非語境嵌入模型。然而，比較這兩組中模型的研究數量非常少，而且沒有這類研究針對土耳其語。此程序需要將語境嵌入轉換成靜態嵌入。在本文中，我們比較並評估多種語境和非語境模型在土耳其語的內在和外在評估設定中的效能。我們透過個別分析模型的句法和語義能力，進行細微的比較。分析結果提供了見解，說明不同嵌入模型在不同類型的 NLP 任務中的適用性。我們還建置了一個土耳其語字詞嵌入儲存庫，包含此研究中使用的嵌入模型，這可能成為土耳其語 NLP 領域的研究人員和實務工作者的寶貴資源。我們公開提供字詞嵌入、指令碼和評估資料集。

##### **Human-Modeling in Sequential Decision-Making: An Analysis through the Lens of Human-Aware AI**
2405.07773v1 by Silvia Tulli, Stylianos Loukas Vasileiou, Sarath Sreedharan

"Human-aware" has become a popular keyword used to describe a particular
class of AI systems that are designed to work and interact with humans. While
there exists a surprising level of consistency among the works that use the
label human-aware, the term itself mostly remains poorly understood. In this
work, we retroactively try to provide an account of what constitutes a
human-aware AI system. We see that human-aware AI is a design-oriented
paradigm, one that focuses on the need for modeling the humans it may interact
with. Additionally, we see that this paradigm offers us intuitive dimensions to
understand and categorize the kinds of interactions these systems might have
with humans. We show the pedagogical value of these dimensions by using them as
a tool to understand and review the current landscape of work related to
human-AI systems that purport some form of human modeling. To fit the scope of
a workshop paper, we specifically narrowed our review to papers that deal with
sequential decision-making and were published in a major AI conference in the
last three years. Our analysis helps identify the space of potential research
problems that are currently being overlooked. We perform additional analysis on
the degree to which these works make explicit reference to results from social
science and whether they actually perform user-studies to validate their
systems. We also provide an accounting of the various AI methods used by these
works.

摘要：「以人为本」已成为用来描述特定类别 AI 系统的一个流行关键字，这类系统旨在与人类互动并为人类服务。虽然使用「以人为本」标签的作品之间存在令人惊讶的一致性，但这个术语本身仍然大多让人难以理解。在这项工作中，我们尝试追溯性地提供一个以人为本 AI 系统的构成说明。我们认为，以人为本 AI 是一种以设计为导向的范例，它着重于对可能与其互动的用户进行建模。此外，我们认为这个范例为我们提供了直观的维度，以便理解和分类这些系统可能与人类进行的互动类型。我们通过将这些维度用作工具来理解和检视与宣称某种形式的人类建模相关的人机系统工作的当前概况，展示了这些维度的教学价值。为了符合研讨会论文的范围，我们特别将我们的检视范围缩小到处理顺序决策制定且在过去三年内发表在主要 AI 会议中的论文。我们的分析有助于识别目前被忽视的潜在研究问题空间。我们对这些作品明确参考社会科学结果的程度以及他们是否实际执行用户研究来验证其系统进行了额外的分析。我们还对这些作品使用的各种 AI 方法进行了说明。

##### **Synthetic Test Collections for Retrieval Evaluation**
2405.07767v1 by Hossein A. Rahmani, Nick Craswell, Emine Yilmaz, Bhaskar Mitra, Daniel Campos

Test collections play a vital role in evaluation of information retrieval
(IR) systems. Obtaining a diverse set of user queries for test collection
construction can be challenging, and acquiring relevance judgments, which
indicate the appropriateness of retrieved documents to a query, is often costly
and resource-intensive. Generating synthetic datasets using Large Language
Models (LLMs) has recently gained significant attention in various
applications. In IR, while previous work exploited the capabilities of LLMs to
generate synthetic queries or documents to augment training data and improve
the performance of ranking models, using LLMs for constructing synthetic test
collections is relatively unexplored. Previous studies demonstrate that LLMs
have the potential to generate synthetic relevance judgments for use in the
evaluation of IR systems. In this paper, we comprehensively investigate whether
it is possible to use LLMs to construct fully synthetic test collections by
generating not only synthetic judgments but also synthetic queries. In
particular, we analyse whether it is possible to construct reliable synthetic
test collections and the potential risks of bias such test collections may
exhibit towards LLM-based models. Our experiments indicate that using LLMs it
is possible to construct synthetic test collections that can reliably be used
for retrieval evaluation.

摘要：測試集合在資訊檢索 (IR) 系統的評估中扮演著至關重要的角色。取得多元的使用者查詢以建立測試集合可能具有挑戰性，而取得相關性判斷（表示檢索文件對查詢的適切性）通常成本高且耗費資源。使用大型語言模型 (LLM) 產生合成資料集最近在各種應用程式中獲得大量的關注。在 IR 中，雖然先前的研究利用 LLM 的功能產生合成查詢或文件以擴充訓練資料並改善排名模型的效能，但使用 LLM 建立合成測試集合的領域相對尚未探索。先前的研究證實 LLM 具備產生合成相關性判斷的潛力，可供 IR 系統評估使用。在本文中，我們全面探討是否可能使用 LLM 建立完全合成的測試集合，方法是產生合成判斷和合成查詢。特別是，我們分析是否可能建立可靠的合成測試集合，以及此類測試集合可能對基於 LLM 的模型產生的潛在偏差風險。我們的實驗顯示，使用 LLM 可以建立合成測試集合，這些集合可被可靠地用於檢索評估。

##### **Challenges and Opportunities of NLP for HR Applications: A Discussion Paper**
2405.07766v1 by Jochen L. Leidner, Mark Stevenson

Over the course of the recent decade, tremendous progress has been made in
the areas of machine learning and natural language processing, which opened up
vast areas of potential application use cases, including hiring and human
resource management. We review the use cases for text analytics in the realm of
human resources/personnel management, including actually realized as well as
potential but not yet implemented ones, and we analyze the opportunities and
risks of these.

摘要：在最近十年中，机器学习和自然语言处理领域取得了长足的进步，这开辟了大量潜在的应用用例，包括招聘和人力资源管理。我们回顾了文本分析在人力资源/人员管理领域的用例，包括实际实现的用例和尚未实现的潜在用例，并分析了这些用例的机会和风险。

##### **TANQ: An open domain dataset of table answered questions**
2405.07765v1 by Mubashara Akhtar, Chenxi Pang, Andreea Marzoca, Yasemin Altun, Julian Martin Eisenschlos

Language models, potentially augmented with tool usage such as retrieval are
becoming the go-to means of answering questions. Understanding and answering
questions in real-world settings often requires retrieving information from
different sources, processing and aggregating data to extract insights, and
presenting complex findings in form of structured artifacts such as novel
tables, charts, or infographics. In this paper, we introduce TANQ, the first
open domain question answering dataset where the answers require building
tables from information across multiple sources. We release the full source
attribution for every cell in the resulting table and benchmark
state-of-the-art language models in open, oracle, and closed book setups. Our
best-performing baseline, GPT4 reaches an overall F1 score of 29.1, lagging
behind human performance by 19.7 points. We analyse baselines' performance
across different dataset attributes such as different skills required for this
task, including multi-hop reasoning, math operations, and unit conversions. We
further discuss common failures in model-generated answers, suggesting that
TANQ is a complex task with many challenges ahead.

摘要：語言模型，潛在的增強工具使用，例如檢索，正成為回答問題的途徑。在現實世界中理解和回答問題通常需要從不同來源檢索資訊、處理和彙整資料以萃取見解，並以結構化人工製品的形式呈現複雜的發現，例如新穎的表格、圖表或資訊圖表。在本文中，我們介紹 TANQ，這是第一個開放領域問題解答資料集，其中答案需要從多個來源的資訊建立表格。我們釋出結果表格中每個儲存格的完整來源歸屬，並在開放、神諭和閉卷設定中對最先進的語言模型進行基準測試。我們效能最好的基準，GPT4 達到 29.1 的 F1 總分，落後人類表現 19.7 分。我們分析基準在不同資料集屬性中的表現，例如此任務所需的各種技能，包括多重跳躍推理、數學運算和單位換算。我們進一步討論模型生成的答案中常見的失敗，表明 TANQ 是一個複雜的任務，未來還有許多挑戰。

##### **LLM4ED: Large Language Models for Automatic Equation Discovery**
2405.07761v1 by Mengge Du, Yuntian Chen, Zhongzheng Wang, Longfeng Nie, Dongxiao Zhang

Equation discovery is aimed at directly extracting physical laws from data
and has emerged as a pivotal research domain. Previous methods based on
symbolic mathematics have achieved substantial advancements, but often require
the design of implementation of complex algorithms. In this paper, we introduce
a new framework that utilizes natural language-based prompts to guide large
language models (LLMs) in automatically mining governing equations from data.
Specifically, we first utilize the generation capability of LLMs to generate
diverse equations in string form, and then evaluate the generated equations
based on observations. In the optimization phase, we propose two alternately
iterated strategies to optimize generated equations collaboratively. The first
strategy is to take LLMs as a black-box optimizer and achieve equation
self-improvement based on historical samples and their performance. The second
strategy is to instruct LLMs to perform evolutionary operators for global
search. Experiments are extensively conducted on both partial differential
equations and ordinary differential equations. Results demonstrate that our
framework can discover effective equations to reveal the underlying physical
laws under various nonlinear dynamic systems. Further comparisons are made with
state-of-the-art models, demonstrating good stability and usability. Our
framework substantially lowers the barriers to learning and applying equation
discovery techniques, demonstrating the application potential of LLMs in the
field of knowledge discovery.

摘要：方程式發現旨在直接從資料中萃取物理定律，並已成為一個重要的研究領域。先前基於符號數學的方法已取得重大進展，但通常需要設計實作複雜的演算法。在本文中，我們介紹一個新的架構，利用基於自然語言的提示來引導大型語言模型 (LLM) 從資料中自動探勘控制方程式。具體來說，我們首先利用 LLM 的生成能力以字串形式生成各種方程式，然後根據觀察結果評估生成的方程式。在最佳化階段，我們提出兩個交替迭代的策略來協同最佳化生成的方程式。第一個策略是將 LLM 視為一個黑盒最佳化器，並根據歷史樣本及其效能來達成方程式的自我改善。第二個策略是指示 LLM 對全球搜尋執行演化運算子。我們在偏微分方程式和常微分方程式上廣泛進行實驗。結果表明，我們的架構可以在各種非線性動態系統下發現有效的方程式來揭示底層物理定律。進一步與最先進的模型進行比較，證明了良好的穩定性和可用性。我們的架構大幅降低了學習和應用方程式發現技術的門檻，證明了 LLM 在知識發現領域的應用潛力。

##### **MADRL-Based Rate Adaptation for 360$\degree$ Video Streaming with Multi-Viewpoint Prediction**
2405.07759v1 by Haopeng Wang, Zijian Long, Haiwei Dong, Abdulmotaleb El Saddik

Over the last few years, 360$\degree$ video traffic on the network has grown
significantly. A key challenge of 360$\degree$ video playback is ensuring a
high quality of experience (QoE) with limited network bandwidth. Currently,
most studies focus on tile-based adaptive bitrate (ABR) streaming based on
single viewport prediction to reduce bandwidth consumption. However, the
performance of models for single-viewpoint prediction is severely limited by
the inherent uncertainty in head movement, which can not cope with the sudden
movement of users very well. This paper first presents a multimodal
spatial-temporal attention transformer to generate multiple viewpoint
trajectories with their probabilities given a historical trajectory. The
proposed method models viewpoint prediction as a classification problem and
uses attention mechanisms to capture the spatial and temporal characteristics
of input video frames and viewpoint trajectories for multi-viewpoint
prediction. After that, a multi-agent deep reinforcement learning (MADRL)-based
ABR algorithm utilizing multi-viewpoint prediction for 360$\degree$ video
streaming is proposed for maximizing different QoE objectives under various
network conditions. We formulate the ABR problem as a decentralized partially
observable Markov decision process (Dec-POMDP) problem and present a MAPPO
algorithm based on centralized training and decentralized execution (CTDE)
framework to solve the problem. The experimental results show that our proposed
method improves the defined QoE metric by up to 85.5\% compared to existing ABR
methods.

摘要：<paragraph>在過去幾年，網路上的 360 度影片流量大幅成長。360 度影片播放的一大挑戰在於，如何以有限的網路頻寬確保高品質的體驗 (QoE)。目前，大多數研究都專注於基於單一視點預測的磁磚式自適應位元率 (ABR) 串流，以減少頻寬消耗。然而，單一視點預測模型的效能受到頭部移動的內在不確定性嚴重限制，無法很好地應對使用者的突然移動。本文首先提出一個多模態時空注意力變換器，以產生多個視點軌跡及其在給定歷史軌跡下的機率。所提出的方法將視點預測建模為一個分類問題，並使用注意力機制來擷取輸入影片幀和視點軌跡的多視點預測的時空特徵。接著，提出一個基於多主體深度強化學習 (MADRL) 的 ABR 演算法，使用多視點預測進行 360 度影片串流，以在各種網路條件下最大化不同的 QoE 目標。我們將 ABR 問題公式化為一個分散式部分可觀察馬可夫決策過程 (Dec-POMDP) 問題，並提出一個基於集中訓練和分散執行 (CTDE) 架構的 MAPPO 演算法來解決問題。實驗結果顯示，與現有的 ABR 方法相比，我們提出的方法將定義的 QoE 指標提升了 85.5%。</paragraph>

##### **LlamaTurk: Adapting Open-Source Generative Large Language Models for Low-Resource Language**
2405.07745v1 by Cagri Toraman

Despite advancements in English-dominant generative large language models,
further development is needed for low-resource languages to enhance global
accessibility. The primary methods for representing these languages are
monolingual and multilingual pretraining. Monolingual pretraining is expensive
due to hardware requirements, and multilingual models often have uneven
performance across languages. This study explores an alternative solution by
adapting large language models, primarily trained on English, to low-resource
languages. We assess various strategies, including continual training,
instruction fine-tuning, task-specific fine-tuning, and vocabulary extension.
The results show that continual training improves language comprehension, as
reflected in perplexity scores, and task-specific tuning generally enhances
performance of downstream tasks. However, extending the vocabulary shows no
substantial benefits. Additionally, while larger models improve task
performance with few-shot tuning, multilingual models perform worse than their
monolingual counterparts when adapted.

摘要：儘管以英語為主的生成式大型語言模型有進展，但仍需要進一步開發低資源語言，以增強全球可及性。表示這些語言的主要方法是單語和多語預訓練。單語預訓練由於硬體需求而昂貴，而多語模型在不同語言中的表現往往不均。本研究探討了一種替代解決方案，即將主要以英語訓練的大型語言模型適應到低資源語言。我們評估了各種策略，包括持續訓練、指令微調、特定任務微調和詞彙擴充。結果表明，持續訓練改善了語言理解，這反映在困惑度分數中，而特定任務微調通常會增強下游任務的性能。然而，擴展詞彙並未顯示出實質性好處。此外，儘管較大的模型通過少量調整改進了任務性能，但多語模型在適應時表現不如單語模型。

##### **Federated Hierarchical Tensor Networks: a Collaborative Learning Quantum AI-Driven Framework for Healthcare**
2405.07735v1 by Amandeep Singh Bhatia, David E. Bernal Neira

Healthcare industries frequently handle sensitive and proprietary data, and
due to strict privacy regulations, they are often reluctant to share data
directly. In today's context, Federated Learning (FL) stands out as a crucial
remedy, facilitating the rapid advancement of distributed machine learning
while effectively managing critical concerns regarding data privacy and
governance. The fusion of federated learning and quantum computing represents a
groundbreaking interdisciplinary approach with immense potential to
revolutionize various industries, from healthcare to finance. In this work, we
proposed a federated learning framework based on quantum tensor networks, which
leverages the principles of many-body quantum physics. Currently, there are no
known classical tensor networks implemented in federated settings. Furthermore,
we investigated the effectiveness and feasibility of the proposed framework by
conducting a differential privacy analysis to ensure the security of sensitive
data across healthcare institutions. Experiments on popular medical image
datasets show that the federated quantum tensor network model achieved a mean
receiver-operator characteristic area under the curve (ROC-AUC) between
0.91-0.98. Experimental results demonstrate that the quantum federated global
model, consisting of highly entangled tensor network structures, showed better
generalization and robustness and achieved higher testing accuracy, surpassing
the performance of locally trained clients under unbalanced data distributions
among healthcare institutions.

摘要：醫療產業經常處理敏感且專有的資料，且由於嚴格的隱私法規，他們通常不願意直接分享資料。在今日的脈絡中，聯邦學習 (FL) 成為一項重要的解決方案，促進分布式機器學習的快速進展，同時有效管理有關資料隱私和治理的關鍵問題。聯邦學習與量子運算的融合代表了一種創新的跨領域方法，具有巨大的潛力，可以革新從醫療保健到金融的各種產業。在這項工作中，我們提出了一個基於量子張量網路的聯邦學習框架，它利用了多體量子物理的原理。目前，在聯邦設置中沒有已知的經典張量網路實作。此外，我們透過進行差異化隱私分析來調查所提出框架的有效性和可行性，以確保醫療機構中敏感資料的安全性。在流行的醫學影像資料集上的實驗顯示，聯邦量子張量網路模型在曲線下方的平均接收器操作者特性面積 (ROC-AUC) 達到 0.91-0.98。實驗結果表明，由高度糾纏的張量網路結構組成的量子聯邦全局模型顯示出更好的泛化性和穩健性，並達到了更高的測試準確度，超越了在醫療機構之間資料分佈不平衡的情況下，由本地訓練的用戶端效能。

##### **Quantifying and Optimizing Global Faithfulness in Persona-driven Role-playing**
2405.07726v1 by Letian Peng, Jingbo Shang

Persona-driven role-playing (PRP) aims to build AI characters that can
respond to user queries by faithfully sticking with all persona statements.
Unfortunately, existing faithfulness criteria for PRP are limited to
coarse-grained LLM-based scoring without a clear definition or formulation.
This paper presents a pioneering exploration to quantify PRP faithfulness as a
fine-grained and explainable criterion, which also serves as a reliable
reference for optimization. Our criterion first discriminates persona
statements into active and passive constraints by identifying the
query-statement relevance. Then, we incorporate all constraints following the
principle that the AI character's response should be (a) entailed by active
(relevant) constraints and (b) not contradicted by passive (irrelevant)
constraints. We translate this principle mathematically into a novel
Active-Passive-Constraint (APC) score, a constraint-wise sum of natural
language inference (NLI) scores weighted by relevance scores. In practice, we
build the APC scoring system by symbolically distilling small discriminators
from GPT-4 for efficiency. We validate the quality of the APC score against
human evaluation based on example personas with tens of statements, and the
results show a high correlation. We further leverage it as a reward system in
direct preference optimization (DPO) for better AI characters. Our experiments
offer a fine-grained and explainable comparison between existing PRP
techniques, revealing their advantages and limitations. We further find
APC-based DPO to be one of the most competitive techniques for sticking with
all constraints and can be well incorporated with other techniques. We then
extend the scale of the experiments to real persons with hundreds of statements
and reach a consistent conclusion.

摘要：以角色為導向的角色扮演 (PRP) 旨在建立 AI 角色，這些角色可以透過忠實遵守所有角色陳述來回應使用者的查詢。不幸的是，現有的 PRP 保真度準則僅限於粗略的 LLM 基礎評分，而沒有明確的定義或表述。本文提出了一項開創性的探索，將 PRP 保真度量化為細緻且可解釋的準則，這也作為最佳化的可靠參考。我們的準則首先透過識別查詢陳述相關性，將角色陳述區分為主動和被動約束。然後，我們根據以下原則納入所有約束：AI 角色的回應應 (a) 由主動 (相關) 約束所暗示，且 (b) 不與被動 (無關) 約束相矛盾。我們將此原則數學轉換為新穎的主動被動約束 (APC) 分數，這是自然語言推論 (NLI) 分數的約束加權總和，由相關性分數加權。在實務上，我們透過從 GPT-4 中象徵性地提取小型區分器來建立 APC 評分系統以提高效率。我們根據包含數十個陳述的範例角色對 APC 分數的品質進行驗證，而結果顯示出高度相關性。我們進一步將其作為直接偏好最佳化 (DPO) 中的獎勵系統，以獲得更好的 AI 角色。我們的實驗提供了現有 PRP 技術之間細緻且可解釋的比較，揭示了它們的優點和限制。我們進一步發現基於 APC 的 DPO 是最具競爭力的技術之一，可以堅持所有約束，並且可以很好地與其他技術結合。然後，我們將實驗的規模擴展到擁有數百個陳述的真人，並得出了一個一致的結論。

##### **A Unified Sequence Parallelism Approach for Long Context Generative AI**
2405.07719v2 by Jiarui Fang, Shangchun Zhao

Sequence parallelism (SP), which divides the sequence dimension of input
tensors across multiple computational devices, is becoming key to unlocking the
long-context capabilities of generative AI models. This paper investigates the
state-of-the-art SP approaches, i.e. DeepSpeed-Ulysses and Ring-Attention, and
proposes a unified SP approach, which is more robust to transformer model
architectures and network hardware topology. This paper compares the
communication and memory cost of SP and existing parallelism, including
data/tensor/zero/expert/pipeline parallelism, and discusses the best practices
for designing hybrid 4D parallelism involving SP. We achieved 86\% MFU on two
8xA800 nodes using SP for sequence length 208K for the LLAMA3-8B model. Our
code is publicly available on
\url{https://github.com/feifeibear/long-context-attention}.

摘要：序列平行（SP）將輸入張量的序列維度劃分到多個計算裝置上，正成為解鎖生成式 AI 模型的長語境能力的關鍵。本文研究了最先進的 SP 方法，即 DeepSpeed-Ulysses 和 Ring-Attention，並提出了一種統一的 SP 方法，它對Transformer模型架構和網路硬體拓撲更具魯棒性。本文比較了 SP 和現有並行化的通訊和記憶體成本，包括資料/張量/零/專家/管線並行化，並討論了涉及 SP 的混合 4D 並行化的最佳實務。我們在兩個 8xA800 節點上使用 SP 為 LLAMA3-8B 模型的序列長度 208K 達到了 86% 的 MFU。我們的程式碼已公開發布在
\url{https://github.com/feifeibear/long-context-attention}。

##### **OpenLLM-Ro -- Technical Report on Open-source Romanian LLMs trained starting from Llama 2**
2405.07703v2 by Mihai Masala, Denis C. Ilie-Ablachim, Dragos Corlatescu, Miruna Zavelca, Marius Leordeanu, Horia Velicu, Marius Popescu, Mihai Dascalu, Traian Rebedea

In recent years, Large Language Models (LLMs) have achieved almost human-like
performance on various tasks. While some LLMs have been trained on multilingual
data, most of the training data is in English. Hence, their performance in
English greatly exceeds their performance in other languages. This document
presents our approach to training and evaluating the first foundational and
chat LLM specialized for Romanian.

摘要：近年來，大型語言模型 (LLM) 在各種任務上已取得近乎人類的表現。儘管有些 LLM 已接受多語言資料的訓練，但大部分訓練資料都是英文。因此，它們在英文的表現遠遠超過其他語言。本文件說明我們訓練和評估第一個專門針對羅馬尼亞語的基本和聊天 LLM 的方法。

##### **Age-Dependent Analysis and Stochastic Generation of Child-Directed Speech**
2405.07700v1 by Okko Räsänen, Daniil Kocharov

Child-directed speech (CDS) is a particular type of speech that adults use
when addressing young children. Its properties also change as a function of
extralinguistic factors, such as age of the child being addressed. Access to
large amounts of representative and varied CDS would be useful for child
language research, as this would enable controlled computational modeling
experiments of infant language acquisition with realistic input in terms of
quality and quantity. In this study, we describe an approach to model
age-dependent linguistic properties of CDS using a language model (LM) trained
on CDS transcripts and ages of the recipient children, as obtained from North
American English corpora of the CHILDES database. The created LM can then be
used to stochastically generate synthetic CDS transcripts in an age-appropriate
manner, thereby scaling beyond the original datasets in size. We compare
characteristics of the generated CDS against the real speech addressed at
children of different ages, showing that the LM manages to capture
age-dependent changes in CDS, except for a slight difference in the effective
vocabulary size. As a side product, we also provide a systematic
characterization of age-dependent linguistic properties of CDS in CHILDES,
illustrating how all measured aspects of the CDS change with children's age.

摘要：兒童導向語言（CDS）是成人用於對幼兒說話的一種特殊語言類型。它的屬性也隨著非語言因素而改變，例如被稱呼兒童的年齡。獲得大量具有代表性和多樣性的 CDS 將有助於兒童語言研究，因為這將使受控的計算機建模實驗能夠以質量和數量方面的實際輸入來獲取嬰兒語言。在本研究中，我們描述了一種使用語言模型 (LM) 對 CDS 的年齡依賴性語言屬性進行建模的方法，該語言模型在 CDS 轉錄本和收件兒童的年齡上進行了訓練，這些年齡來自 CHILDES 資料庫的北美英語語料庫。然後，創建的 LM 可用於以適合年齡的方式隨機生成合成 CDS 轉錄本，從而擴展到原始數據集的大小。我們將生成的 CDS 的特徵與針對不同年齡兒童的真實語言進行比較，表明 LM 設法捕捉到 CDS 中與年齡相關的變化，除了有效詞彙量略有不同。作為附帶產品，我們還提供了 CHILDES 中 CDS 與年齡相關的語言屬性的系統表徵，說明 CDS 的所有測量方面如何隨著兒童年齡而改變。

##### **FastSAG: Towards Fast Non-Autoregressive Singing Accompaniment Generation**
2405.07682v1 by Jianyi Chen, Wei Xue, Xu Tan, Zhen Ye, Qifeng Liu, Yike Guo

Singing Accompaniment Generation (SAG), which generates instrumental music to
accompany input vocals, is crucial to developing human-AI symbiotic art
creation systems. The state-of-the-art method, SingSong, utilizes a multi-stage
autoregressive (AR) model for SAG, however, this method is extremely slow as it
generates semantic and acoustic tokens recursively, and this makes it
impossible for real-time applications. In this paper, we aim to develop a Fast
SAG method that can create high-quality and coherent accompaniments. A non-AR
diffusion-based framework is developed, which by carefully designing the
conditions inferred from the vocal signals, generates the Mel spectrogram of
the target accompaniment directly. With diffusion and Mel spectrogram modeling,
the proposed method significantly simplifies the AR token-based SingSong
framework, and largely accelerates the generation. We also design semantic
projection, prior projection blocks as well as a set of loss functions, to
ensure the generated accompaniment has semantic and rhythm coherence with the
vocal signal. By intensive experimental studies, we demonstrate that the
proposed method can generate better samples than SingSong, and accelerate the
generation by at least 30 times. Audio samples and code are available at
https://fastsag.github.io/.

摘要：歌唱伴奏生成 (SAG) 會產生器樂，以搭配輸入的歌聲，對於開發人類與人工智慧共生的藝術創作系統至關重要。最先進的方法 SingSong 使用多階段自迴歸 (AR) 模型進行 SAG，然而，此方法極為緩慢，因為它會遞迴產生語義和聲學符號，這使得它無法用於即時應用程式。在本文中，我們旨在開發一種快速 SAG 方法，可以創造出高品質且連貫的伴奏。開發了一個基於非 AR 擴散的架構，透過仔細設計從人聲訊號推斷出的條件，直接產生目標伴奏的 Mel 頻譜圖。透過擴散和 Mel 頻譜圖建模，所提出的方法大幅簡化了基於 AR 符號的 SingSong 架構，並大幅加速了生成。我們還設計了語義投影、先驗投影區塊以及一組損失函數，以確保產生的伴奏在語義和節奏上與人聲訊號相符。透過密集的實驗研究，我們證明了所提出的方法可以產生比 SingSong 更好的範例，並將生成速度至少加快 30 倍。音訊範例和程式碼可在 https://fastsag.github.io/ 取得。

##### **An Empirical Study on the Robustness of Massively Multilingual Neural Machine Translation**
2405.07673v1 by Supryadi, Leiyu Pan, Deyi Xiong

Massively multilingual neural machine translation (MMNMT) has been proven to
enhance the translation quality of low-resource languages. In this paper, we
empirically investigate the translation robustness of Indonesian-Chinese
translation in the face of various naturally occurring noise. To assess this,
we create a robustness evaluation benchmark dataset for Indonesian-Chinese
translation. This dataset is automatically translated into Chinese using four
NLLB-200 models of different sizes. We conduct both automatic and human
evaluations. Our in-depth analysis reveal the correlations between translation
error types and the types of noise present, how these correlations change
across different model sizes, and the relationships between automatic
evaluation indicators and human evaluation indicators. The dataset is publicly
available at https://github.com/tjunlp-lab/ID-ZH-MTRobustEval.

摘要：大量的多語言神經機器翻譯 (MMNMT) 已被證實可以提升低資源語言的翻譯品質。在本文中，我們實證探討印尼文到中文翻譯在面對各種自然發生的雜訊時的翻譯健壯性。為了評估這一點，我們為印尼文到中文翻譯建立了一個健壯性評估基準資料集。這個資料集使用四個不同大小的 NLLB-200 模型自動翻譯成中文。我們進行自動和人工評估。我們的深入分析揭露了翻譯錯誤類型與雜訊類型之間的關聯性，這些關聯性如何在不同模型大小之間變化，以及自動評估指標與人工評估指標之間的關係。該資料集公開於 https://github.com/tjunlp-lab/ID-ZH-MTRobustEval。

##### **Constructing a BPE Tokenization DFA**
2405.07671v1 by Martin Berglund, Willeke Martens, Brink van der Merwe

Many natural language processing systems operate over tokenizations of text
to address the open-vocabulary problem. In this paper, we give and analyze an
algorithm for the efficient construction of deterministic finite automata
designed to operate directly on tokenizations produced by the popular byte pair
encoding technique. This makes it possible to apply many existing techniques
and algorithms to the tokenized case, such as pattern matching, equivalence
checking of tokenization dictionaries, and composing tokenized languages in
various ways.

摘要：許多自然語言處理系統在文本的字元化上進行運作，以解決開放詞彙問題。在本文中，我們給出並分析一種演算法，用於有效建構確定有限自動機，該自動機旨在直接對熱門位元組對編碼技術所產生的字元化進行運作。這使得許多現有技術和演算法可以應用於字元化案例，例如模式配對、字元化詞典的等價性檢查，以及以各種方式組合字元化語言。

##### **CrossCert: A Cross-Checking Detection Approach to Patch Robustness Certification for Deep Learning Models**
2405.07668v1 by Qilin Zhou, Zhengyuan Wei, Haipeng Wang, Bo Jiang, W. K. Chan

Patch robustness certification is an emerging kind of defense technique
against adversarial patch attacks with provable guarantees. There are two
research lines: certified recovery and certified detection. They aim to label
malicious samples with provable guarantees correctly and issue warnings for
malicious samples predicted to non-benign labels with provable guarantees,
respectively. However, existing certified detection defenders suffer from
protecting labels subject to manipulation, and existing certified recovery
defenders cannot systematically warn samples about their labels. A certified
defense that simultaneously offers robust labels and systematic warning
protection against patch attacks is desirable. This paper proposes a novel
certified defense technique called CrossCert. CrossCert formulates a novel
approach by cross-checking two certified recovery defenders to provide
unwavering certification and detection certification. Unwavering certification
ensures that a certified sample, when subjected to a patched perturbation, will
always be returned with a benign label without triggering any warnings with a
provable guarantee. To our knowledge, CrossCert is the first certified
detection technique to offer this guarantee. Our experiments show that, with a
slightly lower performance than ViP and comparable performance with PatchCensor
in terms of detection certification, CrossCert certifies a significant
proportion of samples with the guarantee of unwavering certification.

摘要：修补程序鲁棒性认证是一种新兴的防御技术，它针对对抗性修补程序攻击，并提供可证明的保证。有两条研究路线：经过认证的恢复和经过认证的检测。它们旨在分别正确地标记恶意样本并为预测为非良性标签的恶意样本发出警告，并提供可证明的保证。然而，现有的经过认证的检测防御程序在保护标签免受操纵方面存在缺陷，而现有的经过认证的恢复防御程序无法系统地警告样本有关其标签。一种同时提供针对修补程序攻击的鲁棒标签和系统警告保护的经过认证的防御是可取的。本文提出了一种称为 CrossCert 的新型经过认证的防御技术。CrossCert 通过交叉检查两个经过认证的恢复防御程序来制定一种新颖的方法，以提供坚定不移的认证和检测认证。坚定不移的认证确保经过认证的样本在受到修补扰动时，始终会返回带有良性标签，而不会触发任何警告，并提供可证明的保证。据我们所知，CrossCert 是第一种提供此保证的经过认证的检测技术。我们的实验表明，在检测认证方面，CrossCert 的性能略低于 ViP，与 PatchCensor 的性能相当，CrossCert 认证了很大一部分样本，并保证了坚定不移的认证。

##### **Backdoor Removal for Generative Large Language Models**
2405.07667v1 by Haoran Li, Yulin Chen, Zihao Zheng, Qi Hu, Chunkit Chan, Heshan Liu, Yangqiu Song

With rapid advances, generative large language models (LLMs) dominate various
Natural Language Processing (NLP) tasks from understanding to reasoning. Yet,
language models' inherent vulnerabilities may be exacerbated due to increased
accessibility and unrestricted model training on massive textual data from the
Internet. A malicious adversary may publish poisoned data online and conduct
backdoor attacks on the victim LLMs pre-trained on the poisoned data.
Backdoored LLMs behave innocuously for normal queries and generate harmful
responses when the backdoor trigger is activated. Despite significant efforts
paid to LLMs' safety issues, LLMs are still struggling against backdoor
attacks. As Anthropic recently revealed, existing safety training strategies,
including supervised fine-tuning (SFT) and Reinforcement Learning from Human
Feedback (RLHF), fail to revoke the backdoors once the LLM is backdoored during
the pre-training stage. In this paper, we present Simulate and Eliminate
(SANDE) to erase the undesired backdoored mappings for generative LLMs. We
initially propose Overwrite Supervised Fine-tuning (OSFT) for effective
backdoor removal when the trigger is known. Then, to handle the scenarios where
the trigger patterns are unknown, we integrate OSFT into our two-stage
framework, SANDE. Unlike previous works that center on the identification of
backdoors, our safety-enhanced LLMs are able to behave normally even when the
exact triggers are activated. We conduct comprehensive experiments to show that
our proposed SANDE is effective against backdoor attacks while bringing minimal
harm to LLMs' powerful capability without any additional access to unbackdoored
clean models. We will release the reproducible code.

摘要：<paragraph>隨著快速進展，生成式大型語言模型 (LLM) 主導著從理解到推理的各種自然語言處理 (NLP) 任務。然而，由於從網際網路上取得大量文本資料的便利性增加，以及模型訓練不受限制，語言模型固有的漏洞可能會因此而惡化。惡意攻擊者可能會在網路上發布中毒資料，並對預先訓練過中毒資料的受害 LLM 進行後門攻擊。後門 LLM 對一般查詢表現得無害，但在後門觸發器啟動時會產生有害的回應。儘管已對 LLM 的安全性問題付出了相當大的努力，但 LLM 仍然難以抵禦後門攻擊。正如 Anthropic 最近揭露的，現有的安全訓練策略，包括監督微調 (SFT) 和人類回饋強化學習 (RLHF)，一旦 LLM 在預訓練階段遭到後門攻擊，就無法撤銷後門。在本文中，我們提出模擬和消除 (SANDE) 來消除生成式 LLM 中不需要的後門對應。我們最初提出覆寫監督微調 (OSFT)，以便在已知觸發器時有效移除後門。然後，為了處理觸發器模式未知的情況，我們將 OSFT 整合到我們的兩階段架構 SANDE 中。與之前專注於識別後門的著作不同，我們的安全增強 LLM 能夠在準確的觸發器啟動時正常運作。我們進行了全面的實驗，以證明我們提出的 SANDE 能有效抵禦後門攻擊，同時將對 LLM 強大功能的危害降到最低，而無需額外取得未受後門攻擊的乾淨模型。我們將釋出可重製的程式碼。</paragraph>

##### **Sign Stitching: A Novel Approach to Sign Language Production**
2405.07663v1 by Harry Walsh, Ben Saunders, Richard Bowden

Sign Language Production (SLP) is a challenging task, given the limited
resources available and the inherent diversity within sign data. As a result,
previous works have suffered from the problem of regression to the mean,
leading to under-articulated and incomprehensible signing. In this paper, we
propose using dictionary examples and a learnt codebook of facial expressions
to create expressive sign language sequences. However, simply concatenating
signs and adding the face creates robotic and unnatural sequences. To address
this we present a 7-step approach to effectively stitch sequences together.
First, by normalizing each sign into a canonical pose, cropping, and stitching
we create a continuous sequence. Then, by applying filtering in the frequency
domain and resampling each sign, we create cohesive natural sequences that
mimic the prosody found in the original data. We leverage a SignGAN model to
map the output to a photo-realistic signer and present a complete Text-to-Sign
(T2S) SLP pipeline. Our evaluation demonstrates the effectiveness of the
approach, showcasing state-of-the-art performance across all datasets. Finally,
a user evaluation shows our approach outperforms the baseline model and is
capable of producing realistic sign language sequences.

摘要：手語製作 (SLP) 是一項艱鉅的任務，因為手語資料中可用的資源有限且具有內在的多樣性。因此，先前的作品飽受回歸平均值的問題所苦，導致手語表達不足且難以理解。在本文中，我們提出使用字典範例和已學習的臉部表情碼本來建立表達性的手語序列。然而，僅僅串接手勢並加入臉部表情會產生機器人和不自然的手語序列。為了解決這個問題，我們提出了一個 7 步驟的方法，可以有效地將手語序列串接在一起。首先，透過將每個手勢標準化為標準姿勢、裁剪和串接，我們建立一個連續的序列。接著，透過在頻域中套用濾波器並重新取樣每個手勢，我們建立了連貫的自然序列，模擬原始資料中找到的語調。我們利用 SignGAN 模型將輸出對應到一位逼真的手語者，並展示一個完整的文字轉手語 (T2S) SLP 管線。我們的評估證明了此方法的有效性，在所有資料集上都展現出最先進的效能。最後，使用者評估顯示我們的做法優於基準模型，並且能夠產生逼真的手語序列。

##### **G-VOILA: Gaze-Facilitated Information Querying in Daily Scenarios**
2405.07652v1 by Zeyu Wang, Yuanchun Shi, Yuntao Wang, Yuchen Yao, Kun Yan, Yuhan Wang, Lei Ji, Xuhai Xu, Chun Yu

Modern information querying systems are progressively incorporating
multimodal inputs like vision and audio. However, the integration of gaze -- a
modality deeply linked to user intent and increasingly accessible via
gaze-tracking wearables -- remains underexplored. This paper introduces a novel
gaze-facilitated information querying paradigm, named G-VOILA, which synergizes
users' gaze, visual field, and voice-based natural language queries to
facilitate a more intuitive querying process. In a user-enactment study
involving 21 participants in 3 daily scenarios (p = 21, scene = 3), we revealed
the ambiguity in users' query language and a gaze-voice coordination pattern in
users' natural query behaviors with G-VOILA. Based on the quantitative and
qualitative findings, we developed a design framework for the G-VOILA paradigm,
which effectively integrates the gaze data with the in-situ querying context.
Then we implemented a G-VOILA proof-of-concept using cutting-edge deep learning
techniques. A follow-up user study (p = 16, scene = 2) demonstrates its
effectiveness by achieving both higher objective score and subjective score,
compared to a baseline without gaze data. We further conducted interviews and
provided insights for future gaze-facilitated information querying systems.

摘要：現代資訊查詢系統正逐步納入視覺和音訊等多模態輸入。然而，整合注視——一種與使用者意圖深度連結且透過注視追蹤穿戴裝置日益容易取得的模式——仍未被充分探討。本文介紹一種名為 G-VOILA 的新穎注視促進資訊查詢範例，它協同運用使用者的注視、視覺場域和基於語音的自然語言查詢，以促進更直覺的查詢程序。在一個包含 21 位參與者和 3 個日常場景的使用者演練研究（p = 21，場景 = 3）中，我們揭露了使用者查詢語言的模糊性，以及使用者在 G-VOILA 中的自然查詢行為中的注視-語音協調模式。根據量化和質化研究結果，我們為 G-VOILA 範例開發了一個設計架構，它有效地將注視資料與現場查詢情境整合。接著，我們使用尖端的深度學習技術實作了一個 G-VOILA 概念驗證。後續使用者研究（p = 16，場景 = 2）透過達成比沒有注視資料的基準更高的客觀分數和主觀分數，證明了其有效性。我們進一步進行訪談，並為未來的注視促進資訊查詢系統提供見解。

##### **Hyperparameter Importance Analysis for Multi-Objective AutoML**
2405.07640v1 by Daphne Theodorakopoulos, Frederic Stahl, Marius Lindauer

Hyperparameter optimization plays a pivotal role in enhancing the predictive
performance and generalization capabilities of ML models. However, in many
applications, we do not only care about predictive performance but also about
objectives such as inference time, memory, or energy consumption. In such MOO
scenarios, determining the importance of hyperparameters poses a significant
challenge due to the complex interplay between the conflicting objectives. In
this paper, we propose the first method for assessing the importance of
hyperparameters in the context of multi-objective hyperparameter optimization.
Our approach leverages surrogate-based hyperparameter importance (HPI)
measures, i.e. fANOVA and ablation paths, to provide insights into the impact
of hyperparameters on the optimization objectives. Specifically, we compute the
a-priori scalarization of the objectives and determine the importance of the
hyperparameters for different objective tradeoffs. Through extensive empirical
evaluations on diverse benchmark datasets with three different objectives
paired with accuracy, namely time, demographic parity, and energy consumption,
we demonstrate the effectiveness and robustness of our proposed method. Our
findings not only offer valuable guidance for hyperparameter tuning in MOO
tasks but also contribute to advancing the understanding of HPI in complex
optimization scenarios.

摘要：超參數最佳化在提升 ML 模型的預測效能和泛化能力中扮演著關鍵角色。然而，在許多應用中，我們不只關心預測效能，也關心推論時間、記憶體或能源消耗等目標。在這樣的多目標最佳化情境中，由於衝突目標之間的複雜交互作用，決定超參數的重要性構成了一項重大挑戰。在本文中，我們提出第一個在多目標超參數最佳化情境中評估超參數重要性的方法。我們的做法利用了基於代理的超參數重要性 (HPI) 測量，例如 fANOVA 和消融路徑，提供洞察超參數對最佳化目標的影響。具體來說，我們計算目標的先驗標量化，並確定超參數對不同目標權衡的重要性。透過對具有三個不同目標的各種基準資料集進行廣泛的經驗評估，這些目標與準確度配對，即時間、人口統計同質性和能源消耗，我們證明了我們提出的方法的有效性和穩健性。我們的發現不僅為 MOO 任務中的超參數調整提供了有價值的指導，也有助於推進對複雜最佳化情境中 HPI 的理解。

##### **DoLLM: How Large Language Models Understanding Network Flow Data to Detect Carpet Bombing DDoS**
2405.07638v1 by Qingyang Li, Yihang Zhang, Zhidong Jia, Yannan Hu, Lei Zhang, Jianrong Zhang, Yongming Xu, Yong Cui, Zongming Guo, Xinggong Zhang

It is an interesting question Can and How Large Language Models (LLMs)
understand non-language network data, and help us detect unknown malicious
flows. This paper takes Carpet Bombing as a case study and shows how to exploit
LLMs' powerful capability in the networking area. Carpet Bombing is a new DDoS
attack that has dramatically increased in recent years, significantly
threatening network infrastructures. It targets multiple victim IPs within
subnets, causing congestion on access links and disrupting network services for
a vast number of users. Characterized by low-rates, multi-vectors, these
attacks challenge traditional DDoS defenses. We propose DoLLM, a DDoS detection
model utilizes open-source LLMs as backbone. By reorganizing non-contextual
network flows into Flow-Sequences and projecting them into LLMs semantic space
as token embeddings, DoLLM leverages LLMs' contextual understanding to extract
flow representations in overall network context. The representations are used
to improve the DDoS detection performance. We evaluate DoLLM with public
datasets CIC-DDoS2019 and real NetFlow trace from Top-3 countrywide ISP. The
tests have proven that DoLLM possesses strong detection capabilities. Its F1
score increased by up to 33.3% in zero-shot scenarios and by at least 20.6% in
real ISP traces.

摘要：大型語言模型 (LLM) 是否能理解非語言網路數據，以及如何幫助我們偵測未知的惡意流量，這是一個有趣的問題。本文以地毯式轟炸為案例研究，展示如何利用 LLM 在網路領域的強大功能。地毯式轟炸是一種新的 DDoS 攻擊，近年來大幅增加，嚴重威脅網路基礎設施。它針對子網路中的多個受害者 IP，導致存取連結壅塞，並中斷大量使用者的網路服務。這些攻擊的特徵是低速率、多重載體，對傳統的 DDoS 防禦構成挑戰。我們提出 DoLLM，一種 DDoS 偵測模型，利用開源 LLM 作為主幹。透過將非語境網路流量重新組織成流程序列，並將它們投射到 LLM 的語義空間中作為標記嵌入，DoLLM 利用 LLM 的語境理解來提取整體網路環境中的流程表示。這些表示用於改善 DDoS 偵測效能。我們使用公開資料集 CIC-DDoS2019 和來自全國前三大的 ISP 的真實 NetFlow 追蹤來評估 DoLLM。測試證明 DoLLM 具有強大的偵測能力。在零次學習場景中，它的 F1 分數提高了 33.3%，在真實的 ISP 追蹤中至少提高了 20.6%。

##### **AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models**
2405.07626v1 by Shuo Liu, Di Yao, Lanting Fang, Zhetao Li, Wenbin Li, Kaiyu Feng, XiaoWen Ji, Jingping Bi

Detecting anomaly edges for dynamic graphs aims to identify edges
significantly deviating from the normal pattern and can be applied in various
domains, such as cybersecurity, financial transactions and AIOps. With the
evolving of time, the types of anomaly edges are emerging and the labeled
anomaly samples are few for each type. Current methods are either designed to
detect randomly inserted edges or require sufficient labeled data for model
training, which harms their applicability for real-world applications. In this
paper, we study this problem by cooperating with the rich knowledge encoded in
large language models(LLMs) and propose a method, namely AnomalyLLM. To align
the dynamic graph with LLMs, AnomalyLLM pre-trains a dynamic-aware encoder to
generate the representations of edges and reprograms the edges using the
prototypes of word embeddings. Along with the encoder, we design an in-context
learning framework that integrates the information of a few labeled samples to
achieve few-shot anomaly detection. Experiments on four datasets reveal that
AnomalyLLM can not only significantly improve the performance of few-shot
anomaly detection, but also achieve superior results on new anomalies without
any update of model parameters.

摘要：偵測動態圖形的異常邊緣旨在識別顯著偏離正常模式的邊緣，並可用於各種領域，例如網路安全、金融交易和 AIOps。隨著時間的推移，異常邊緣的類型不斷出現，而每種類型的標籤異常樣本很少。目前的技術方法旨在偵測隨機插入的邊緣，或需要足夠的標籤資料進行模型訓練，這會損害其在實際應用中的適用性。在本文中，我們透過與大型語言模型 (LLM) 中編碼的豐富知識合作來研究這個問題，並提出了一種名為 AnomalyLLM 的方法。為了將動態圖形與 LLM 對齊，AnomalyLLM 預先訓練了一個動態感知編碼器，以產生邊緣的表示，並使用詞嵌入的原型重新編寫邊緣。我們與編碼器一起設計了一個情境內學習框架，整合了少數標籤樣本的資訊，以實現少發異常偵測。在四個資料集上的實驗表明，AnomalyLLM 不僅可以顯著改善少發異常偵測的效能，還能對沒有任何模型參數更新的新異常情況取得優異的結果。

##### **COBias and Debias: Minimizing Language Model Pairwise Accuracy Bias via Nonlinear Integer Programming**
2405.07623v1 by Ruixi Lin, Yang You

For language model classification, would you prefer having only one workable
class or having every class working? The latter makes more practical uses.
Especially for large language models (LLMs), the fact that they achieve a fair
overall accuracy by in-context learning (ICL) obscures a large difference in
individual class accuracies. In this work, we uncover and tackle language
models' imbalance in per-class prediction accuracy by reconceptualizing it as
the Contextual Oddity Bias (COBias), and we are the first to engage nonlinear
integer programming (NIP) to debias it. Briefly, COBias refers to the
difference in accuracy by a class A compared to its ''odd'' class, which holds
the majority wrong predictions of class A. With the COBias metric, we reveal
that LLMs of varied scales and families exhibit large per-class accuracy
differences. Then we propose Debiasing as Nonlinear Integer Programming (DNIP)
to correct ICL per-class probabilities for lower bias and higher overall
accuracy. Our optimization objective is directly based on the evaluation scores
by COBias and accuracy metrics, solved by simulated annealing. Evaluations on
three LLMs across seven NLP classification tasks show that DNIP simultaneously
achieves significant COBias reduction ($-27\%$) and accuracy improvement
($+12\%$) over the conventional ICL approach, suggesting that modeling pairwise
class accuracy differences is a direction in pushing forward more accurate,
more reliable LLM predictions.

摘要：對於語言模型分類，你會比較希望只有一個可行的類別或讓每個類別都可行？後者具有更多實用用途。特別是對於大型語言模型 (LLM)，它們透過情境學習 (ICL) 達到相當的整體準確度，這掩蓋了各個類別準確度之間的巨大差異。在這項工作中，我們重新將語言模型在每個類別預測準確度上的不平衡視為情境奇異偏差 (COBias)，並加以揭露和處理，我們是第一個使用非線性整數規劃 (NIP) 來消除偏差。簡而言之，COBias 指的是類別 A 與其「奇異」類別的準確度差異，後者包含類別 A 預測錯誤的大多數情況。透過 COBias 指標，我們揭示了不同規模和類型的 LLM 在每個類別的準確度上存在很大的差異。然後，我們提出非線性整數規劃去偏差 (DNIP) 來修正 ICL 每個類別的機率，以降低偏差並提高整體準確度。我們的最佳化目標直接基於 COBias 和準確度指標的評分，並透過模擬退火來解決。針對七項 NLP 分類任務對三個 LLM 進行評估，結果顯示 DNIP 同時大幅降低 COBias (-27%)，並提高準確度 (+12%)，優於傳統的 ICL 方法，這表示對成對類別準確度差異進行建模是推動更準確、更可靠的 LLM 預測的發展方向。

##### **ViWikiFC: Fact-Checking for Vietnamese Wikipedia-Based Textual Knowledge Source**
2405.07615v1 by Hung Tuan Le, Long Truong To, Manh Trong Nguyen, Kiet Van Nguyen

Fact-checking is essential due to the explosion of misinformation in the
media ecosystem. Although false information exists in every language and
country, most research to solve the problem mainly concentrated on huge
communities like English and Chinese. Low-resource languages like Vietnamese
are necessary to explore corpora and models for fact verification. To bridge
this gap, we construct ViWikiFC, the first manual annotated open-domain corpus
for Vietnamese Wikipedia Fact Checking more than 20K claims generated by
converting evidence sentences extracted from Wikipedia articles. We analyze our
corpus through many linguistic aspects, from the new dependency rate, the new
n-gram rate, and the new word rate. We conducted various experiments for
Vietnamese fact-checking, including evidence retrieval and verdict prediction.
BM25 and InfoXLM (Large) achieved the best results in two tasks, with BM25
achieving an accuracy of 88.30% for SUPPORTS, 86.93% for REFUTES, and only
56.67% for the NEI label in the evidence retrieval task, InfoXLM (Large)
achieved an F1 score of 86.51%. Furthermore, we also conducted a pipeline
approach, which only achieved a strict accuracy of 67.00% when using InfoXLM
(Large) and BM25. These results demonstrate that our dataset is challenging for
the Vietnamese language model in fact-checking tasks.

摘要：由於媒體生態系統中錯誤訊息氾濫，查核事實至關重要。儘管虛假訊息存在於每種語言和國家，但解決此問題的大部分研究主要集中在龐大的社群，例如英語和中文。低資源語言，例如越南語，對於探索語料庫和事實查核模型是必要的。為了彌補這個差距，我們建構了 ViWikiFC，這是第一個手動標註的開放領域語料庫，用於越南語維基百科事實查核，包含超過 20K 個由轉換從維基百科條目中萃取的證據句子而產生的宣稱。我們從許多語言學面向分析我們的語料庫，包括新的依賴關係比率、新的 n-gram 比率和新的字詞比率。我們對越南語事實查核進行了各種實驗，包括證據擷取和判定預測。BM25 和 InfoXLM（大型）在兩個任務中取得最佳結果，BM25 在證據擷取任務中對支援、駁斥的準確度分別達到 88.30%、86.93%，對 NEI 標籤的準確度僅為 56.67%，InfoXLM（大型）的 F1 分數達到 86.51%。此外，我們還進行了管道方法，在使用 InfoXLM（大型）和 BM25 時僅達到 67.00% 的嚴格準確度。這些結果表明我們的資料集對越南語語言模型在事實查核任務中具有挑戰性。

##### **NoiseBench: Benchmarking the Impact of Real Label Noise on Named Entity Recognition**
2405.07609v1 by Elena Merdjanovska, Ansar Aynetdinov, Alan Akbik

Available training data for named entity recognition (NER) often contains a
significant percentage of incorrect labels for entity types and entity
boundaries. Such label noise poses challenges for supervised learning and may
significantly deteriorate model quality. To address this, prior work proposed
various noise-robust learning approaches capable of learning from data with
partially incorrect labels. These approaches are typically evaluated using
simulated noise where the labels in a clean dataset are automatically
corrupted. However, as we show in this paper, this leads to unrealistic noise
that is far easier to handle than real noise caused by human error or
semi-automatic annotation. To enable the study of the impact of various types
of real noise, we introduce NoiseBench, an NER benchmark consisting of clean
training data corrupted with 6 types of real noise, including expert errors,
crowdsourcing errors, automatic annotation errors and LLM errors. We present an
analysis that shows that real noise is significantly more challenging than
simulated noise, and show that current state-of-the-art models for noise-robust
learning fall far short of their theoretically achievable upper bound. We
release NoiseBench to the research community.

摘要：可用於命名實體辨識 (NER) 的訓練資料通常包含大量標記錯誤的實體類型和實體邊界。此類標記雜訊對監督式學習構成挑戰，並可能大幅降低模型品質。為了解決此問題，先前的研究提出各種抗雜訊學習方法，能夠從標記部分錯誤的資料中學習。這些方法通常使用模擬雜訊進行評估，其中乾淨資料集中的標記會自動損毀。然而，正如我們在本文中所示，這會導致不切實際的雜訊，遠比人為錯誤或半自動標註造成的實際雜訊容易處理。為了研究各種實際雜訊類型的影響，我們引入了 NoiseBench，一個 NER 基準，包含以 6 種類型的實際雜訊損毀的乾淨訓練資料，包括專家錯誤、群眾外包錯誤、自動標註錯誤和 LLM 錯誤。我們提出一個分析，顯示實際雜訊比模擬雜訊困難得多，並顯示目前抗雜訊學習的最新模型遠低於其理論上可達到的上限。我們將 NoiseBench 發布給研究社群。

##### **Reducing Risk for Assistive Reinforcement Learning Policies with Diffusion Models**
2405.07603v1 by Andrii Tytarenko

Care-giving and assistive robotics, driven by advancements in AI, offer
promising solutions to meet the growing demand for care, particularly in the
context of increasing numbers of individuals requiring assistance. This creates
a pressing need for efficient and safe assistive devices, particularly in light
of heightened demand due to war-related injuries. While cost has been a barrier
to accessibility, technological progress is able to democratize these
solutions. Safety remains a paramount concern, especially given the intricate
interactions between assistive robots and humans. This study explores the
application of reinforcement learning (RL) and imitation learning, in improving
policy design for assistive robots. The proposed approach makes the risky
policies safer without additional environmental interactions. Through
experimentation using simulated environments, the enhancement of the
conventional RL approaches in tasks related to assistive robotics is
demonstrated.

摘要：<paragraph>在人工智能的推動下，照護和輔助機器人提供了有希望的解決方案，以滿足日益增長的照護需求，特別是在需要協助的個人數量增加的情況下。這造成了對高效且安全的輔助設備的迫切需求，特別是考慮到因戰爭相關傷害而導致的需求增加。雖然成本一直是無障礙性的障礙，但技術進步能夠民主化這些解決方案。安全性仍然是首要考量，特別是考慮到輔助機器人和人類之間複雜的互動。本研究探討了強化學習 (RL) 和模仿學習在改善輔助機器人政策設計中的應用。所提出的方法讓有風險的政策更安全，而無需額外的環境互動。透過使用模擬環境進行實驗，證明了在與輔助機器人相關任務中增強傳統 RL 方法的表現。</paragraph>

##### **On-device Online Learning and Semantic Management of TinyML Systems**
2405.07601v1 by Haoyu Ren, Xue Li, Darko Anicic, Thomas A. Runkler

Recent advances in Tiny Machine Learning (TinyML) empower low-footprint
embedded devices for real-time on-device Machine Learning. While many
acknowledge the potential benefits of TinyML, its practical implementation
presents unique challenges. This study aims to bridge the gap between
prototyping single TinyML models and developing reliable TinyML systems in
production: (1) Embedded devices operate in dynamically changing conditions.
Existing TinyML solutions primarily focus on inference, with models trained
offline on powerful machines and deployed as static objects. However, static
models may underperform in the real world due to evolving input data
distributions. We propose online learning to enable training on constrained
devices, adapting local models towards the latest field conditions. (2)
Nevertheless, current on-device learning methods struggle with heterogeneous
deployment conditions and the scarcity of labeled data when applied across
numerous devices. We introduce federated meta-learning incorporating online
learning to enhance model generalization, facilitating rapid learning. This
approach ensures optimal performance among distributed devices by knowledge
sharing. (3) Moreover, TinyML's pivotal advantage is widespread adoption.
Embedded devices and TinyML models prioritize extreme efficiency, leading to
diverse characteristics ranging from memory and sensors to model architectures.
Given their diversity and non-standardized representations, managing these
resources becomes challenging as TinyML systems scale up. We present semantic
management for the joint management of models and devices at scale. We
demonstrate our methods through a basic regression example and then assess them
in three real-world TinyML applications: handwritten character image
classification, keyword audio classification, and smart building presence
detection, confirming our approaches' effectiveness.

摘要：<paragraph>微型機器學習 (TinyML) 的最新進展賦能低佔用空間的嵌入式裝置，進行即時裝置上機器學習。雖然許多人承認 TinyML 的潛在好處，但其實際執行會產生獨特挑戰。本研究旨在彌合單一 TinyML 模型原型製作與在生產環境中開發可靠 TinyML 系統之間的差距：(1) 嵌入式裝置在動態變化的條件下操作。現有的 TinyML 解決方案主要關注推理，其中模型在功能強大的機器上離線訓練，並作為靜態物件部署。然而，由於輸入資料分佈不斷演變，靜態模型在現實世界中的表現可能不佳。我們建議進行線上學習，以在受限裝置上進行訓練，讓在地模型適應最新的現場條件。(2) 儘管如此，當應用於眾多裝置時，目前的裝置上學習方法仍難以應對異質部署條件和標籤資料的稀少性。我們引入了結合線上學習的聯邦元學習，以增強模型泛化，促進快速學習。此方法透過知識分享，確保分散式裝置之間的最佳效能。(3) 此外，TinyML 的關鍵優勢是廣泛採用。嵌入式裝置和 TinyML 模型優先考慮極致效率，導致從記憶體和感測器到模型架構等多樣化的特性。考量到它們的多樣性和非標準化表示，隨著 TinyML 系統擴展，管理這些資源將變得具有挑戰性。我們展示了用於大規模聯合管理模型和裝置的語義管理。我們透過一個基本的回歸範例展示我們的這些方法，然後在三個真實世界的 TinyML 應用中評估它們：手寫字元影像分類、關鍵字音訊分類和智慧建築中的存在偵測，證實了我們方法的有效性。</paragraph>

##### **Using Model-Theoretic Approaches to Uncover Linguistic Organization**
2405.07597v1 by Olivia Griffin, Jerry Sun

In this paper, we consider pluractional markers in Kaqchikel, Karuk, and
Yurok. Like Balinese, each of these languages marks one type of pluractionality
via reduplication, and a different type of pluractionality via
non-reduplicative affixation. This paper serves as a proof-of-concept for
applying model-theoretic approaches to language as a lens that can help us to
recognize linguistic organization that is not apparent on the surface.

摘要：在本文中，我們考慮了卡克奇克爾語、卡魯克語和尤洛克語中的多重動作標記。與巴厘語一樣，這些語言中的每種語言都通過重複標記一種多重動作，並通過非重複附加標記標記另一種多重動作。本文作為將模型理論方法應用於語言的驗證概念，作為一個透鏡，可以幫助我們識別表面上看不出來的語言組織。

##### **Environmental Matching Attack Against Unmanned Aerial Vehicles Object Detection**
2405.07595v1 by Dehong Kong, Siyuan Liang, Wenqi Ren

Object detection techniques for Unmanned Aerial Vehicles (UAVs) rely on Deep
Neural Networks (DNNs), which are vulnerable to adversarial attacks.
Nonetheless, adversarial patches generated by existing algorithms in the UAV
domain pay very little attention to the naturalness of adversarial patches.
Moreover, imposing constraints directly on adversarial patches makes it
difficult to generate patches that appear natural to the human eye while
ensuring a high attack success rate. We notice that patches are natural looking
when their overall color is consistent with the environment. Therefore, we
propose a new method named Environmental Matching Attack(EMA) to address the
issue of optimizing the adversarial patch under the constraints of color. To
the best of our knowledge, this paper is the first to consider natural patches
in the domain of UAVs. The EMA method exploits strong prior knowledge of a
pretrained stable diffusion to guide the optimization direction of the
adversarial patch, where the text guidance can restrict the color of the patch.
To better match the environment, the contrast and brightness of the patch are
appropriately adjusted. Instead of optimizing the adversarial patch itself, we
optimize an adversarial perturbation patch which initializes to zero so that
the model can better trade off attacking performance and naturalness.
Experiments conducted on the DroneVehicle and Carpk datasets have shown that
our work can reach nearly the same attack performance in the digital attack(no
greater than 2 in mAP$\%$), surpass the baseline method in the physical
specific scenarios, and exhibit a significant advantage in terms of naturalness
in visualization and color difference with the environment.

摘要：無人機 (UAV) 的物件偵測技術仰賴深度神經網路 (DNN)，而深度神經網路容易受到對抗性攻擊。然而，現有演算法在無人機領域產生的對抗性貼片極少關注對抗性貼片的自然性。此外，直接對對抗性貼片施加限制會導致難以產生對人眼來說顯得自然的貼片，同時確保攻擊成功率。我們注意到，當貼片的整體顏色與環境一致時，貼片看起來會很自然。因此，我們提出一個名為環境匹配攻擊 (EMA) 的新方法來解決在顏色限制下最佳化對抗性貼片的問題。據我們所知，這篇論文是第一篇在無人機領域考慮自然貼片的研究。EMA 方法利用預訓練穩定擴散的強先驗知識來引導對抗性貼片的最佳化方向，其中文字引導可以限制貼片的顏色。為了更好地匹配環境，會適當地調整貼片的對比度和亮度。我們最佳化的是對抗性擾動貼片，而不是最佳化對抗性貼片本身，該貼片初始化為零，讓模型可以更好地權衡攻擊效能和自然性。在 DroneVehicle 和 Carpk 資料集上進行的實驗顯示，我們的研究在數位攻擊中可以達到幾乎相同的攻擊效能（mAP% 不超過 2），在物理特定場景中超越基線方法，並且在視覺化和與環境的色差方面展現出顯著的自然性優勢。

##### **Thai Universal Dependency Treebank**
2405.07586v1 by Panyut Sriwirote, Wei Qi Leong, Charin Polpanumas, Santhawat Thanyawong, William Chandra Tjhi, Wirote Aroonmanakun, Attapol T. Rutherford

Automatic dependency parsing of Thai sentences has been underexplored, as
evidenced by the lack of large Thai dependency treebanks with complete
dependency structures and the lack of a published systematic evaluation of
state-of-the-art models, especially transformer-based parsers. In this work, we
address these problems by introducing Thai Universal Dependency Treebank (TUD),
a new largest Thai treebank consisting of 3,627 trees annotated in accordance
with the Universal Dependencies (UD) framework. We then benchmark dependency
parsing models that incorporate pretrained transformers as encoders and train
them on Thai-PUD and our TUD. The evaluation results show that most of our
models can outperform other models reported in previous papers and provide
insight into the optimal choices of components to include in Thai dependency
parsers. The new treebank and every model's full prediction generated in our
experiment are made available on a GitHub repository for further study.

摘要：泰語句子的自動依存句法分析尚未得到充分探討，
這一點從缺乏具備完整依存結構的大型泰語依存樹庫，以及缺乏對
最先進模型（尤其是基於轉換器的解析器）進行公開的系統評估即可得到證明。在這項工作中，我們
通過引入泰語通用依存樹庫 (TUD) 來解決這些問題，TUD 是一個新的最大的泰語樹庫，包含 3,627 個按照
通用依存 (UD) 框架進行註釋的樹。然後，我們對將預訓練轉換器作為編碼器並在 Thai-PUD 和我們的 TUD 上訓練它們的依存句法分析模型進行基準測試。評估結果表明，我們的大多數模型都可以優於以前論文中報告的其他模型，並提供對包含在泰語依存解析器中的組件的最佳選擇的見解。新的樹庫和我們在實驗中生成的每個模型的完整預測都可以在 GitHub 存儲庫中獲得，以供進一步研究。

##### **DynLLM: When Large Language Models Meet Dynamic Graph Recommendation**
2405.07580v1 by Ziwei Zhao, Fake Lin, Xi Zhu, Zhi Zheng, Tong Xu, Shitian Shen, Xueying Li, Zikai Yin, Enhong Chen

Last year has witnessed the considerable interest of Large Language Models
(LLMs) for their potential applications in recommender systems, which may
mitigate the persistent issue of data sparsity. Though large efforts have been
made for user-item graph augmentation with better graph-based recommendation
performance, they may fail to deal with the dynamic graph recommendation task,
which involves both structural and temporal graph dynamics with inherent
complexity in processing time-evolving data. To bridge this gap, in this paper,
we propose a novel framework, called DynLLM, to deal with the dynamic graph
recommendation task with LLMs. Specifically, DynLLM harnesses the power of LLMs
to generate multi-faceted user profiles based on the rich textual features of
historical purchase records, including crowd segments, personal interests,
preferred categories, and favored brands, which in turn supplement and enrich
the underlying relationships between users and items. Along this line, to fuse
the multi-faceted profiles with temporal graph embedding, we engage LLMs to
derive corresponding profile embeddings, and further employ a distilled
attention mechanism to refine the LLM-generated profile embeddings for
alleviating noisy signals, while also assessing and adjusting the relevance of
each distilled facet embedding for seamless integration with temporal graph
embedding from continuous time dynamic graphs (CTDGs). Extensive experiments on
two real e-commerce datasets have validated the superior improvements of DynLLM
over a wide range of state-of-the-art baseline methods.

摘要：去年，大型語言模型 (LLM) 因其在推薦系統中的潛在應用而備受關注，這可能會緩解數據稀疏性的持續問題。儘管已為用戶項目圖增強做出巨大努力，以提高基於圖形的推薦性能，但它們可能無法處理動態圖形推薦任務，其中涉及結構和時間圖形動態，在處理時間演化數據時具有固有的複雜性。為了彌合這一差距，在本文中，我們提出了一個名為 DynLLM 的新框架，以使用 LLM 處理動態圖形推薦任務。具體來說，DynLLM 利用 LLM 的能力，根據歷史購買記錄的豐富文本特徵生成多方面的用戶資料，包括人群區塊、個人興趣、首選類別和喜愛的品牌，進而補充和豐富用戶和項目之間的底層關係。順著這條思路，為了將多方面的資料與時間圖形嵌入融合，我們使用 LLM 得出相應的資料嵌入，並進一步採用精煉的注意力機制來精煉 LLM 生成的資料嵌入，以減輕雜訊信號，同時評估和調整每個精煉的方面嵌入與來自連續時間動態圖形 (CTDG) 的時間圖形嵌入的無縫整合。在兩個真實電子商務數據集上進行的廣泛實驗驗證了 DynLLM 對廣泛的最新基線方法的優越改進。

##### **GLiRA: Black-Box Membership Inference Attack via Knowledge Distillation**
2405.07562v1 by Andrey V. Galichin, Mikhail Pautov, Alexey Zhavoronkin, Oleg Y. Rogov, Ivan Oseledets

While Deep Neural Networks (DNNs) have demonstrated remarkable performance in
tasks related to perception and control, there are still several unresolved
concerns regarding the privacy of their training data, particularly in the
context of vulnerability to Membership Inference Attacks (MIAs). In this paper,
we explore a connection between the susceptibility to membership inference
attacks and the vulnerability to distillation-based functionality stealing
attacks. In particular, we propose {GLiRA}, a distillation-guided approach to
membership inference attack on the black-box neural network. We observe that
the knowledge distillation significantly improves the efficiency of likelihood
ratio of membership inference attack, especially in the black-box setting,
i.e., when the architecture of the target model is unknown to the attacker. We
evaluate the proposed method across multiple image classification datasets and
models and demonstrate that likelihood ratio attacks when guided by the
knowledge distillation, outperform the current state-of-the-art membership
inference attacks in the black-box setting.

摘要：儘管深度神經網路 (DNN) 已在與感知和控制相關的任務中展現出顯著的效能，但對於其訓練資料的隱私仍有幾個未解決的問題，特別是在容易受到成員推論攻擊 (MIA) 的情況下。在本文中，我們探討成員推論攻擊的敏感性與容易受到基於蒸餾的功能竊取攻擊的漏洞之間的關聯。特別是，我們提出 {GLiRA}，一種蒸餾引導的黑箱神經網路成員推論攻擊方法。我們觀察到，知識蒸餾顯著提升了成員推論攻擊的似然比效率，特別是在黑箱設定中，亦即攻擊者不知道目標模型的架構時。我們在多個影像分類資料集和模型中評估所提出的方法，並證明在黑箱設定中，由知識蒸餾引導的似然比攻擊優於目前最先進的成員推論攻擊。

##### **MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning**
2405.07551v1 by Shuo Yin, Weihao You, Zhilong Ji, Guoqiang Zhong, Jinfeng Bai

The tool-use Large Language Models (LLMs) that integrate with external Python
interpreters have significantly enhanced mathematical reasoning capabilities
for open-source LLMs, while tool-free methods chose another track: augmenting
math reasoning data. However, a great method to integrate the above two
research paths and combine their advantages remains to be explored. In this
work, we firstly include new math questions via multi-perspective data
augmenting methods and then synthesize code-nested solutions to them. The open
LLMs (i.e., Llama-2) are finetuned on the augmented dataset to get the
resulting models, MuMath-Code ($\mu$-Math-Code). During the inference phase,
our MuMath-Code generates code and interacts with the external python
interpreter to get the execution results. Therefore, MuMath-Code leverages the
advantages of both the external tool and data augmentation. To fully leverage
the advantages of our augmented data, we propose a two-stage training strategy:
In Stage-1, we finetune Llama-2 on pure CoT data to get an intermediate model,
which then is trained on the code-nested data in Stage-2 to get the resulting
MuMath-Code. Our MuMath-Code-7B achieves 83.8 on GSM8K and 52.4 on MATH, while
MuMath-Code-70B model achieves new state-of-the-art performance among open
methods -- achieving 90.7% on GSM8K and 55.1% on MATH. Extensive experiments
validate the combination of tool use and data augmentation, as well as our
two-stage training strategy. We release the proposed dataset along with the
associated code for public use.

摘要：<paragraph>整合外部 Python 解譯器的工具使用大型語言模型 (LLM) 已大幅提升開放原始碼 LLM 的數學推理能力，而無工具方法則選擇另一條路徑：擴充數學推理資料。然而，整合上述兩條研究路徑並結合其優勢的絕佳方法仍有待探索。在這項工作中，我們首先透過多角度資料擴充方法納入新的數學問題，然後綜合產生其巢狀程式碼解決方案。開放 LLM（即 Llama-2）在擴充資料集上進行微調，以取得結果模型 MuMath-Code（μ-Math-Code）。在推論階段，我們的 MuMath-Code 會產生程式碼並與外部 Python 解譯器互動以取得執行結果。因此，MuMath-Code 充分利用外部工具和資料擴充的優勢。為了充分發揮擴充資料的優勢，我們提出兩階段訓練策略：在階段 1，我們在純粹 CoT 資料上微調 Llama-2 以取得中間模型，然後在階段 2 對巢狀程式碼資料進行訓練以取得結果 MuMath-Code。我們的 MuMath-Code-7B 在 GSM8K 上達到 83.8，在 MATH 上達到 52.4，而 MuMath-Code-70B 模型則在開放方法中取得新的最佳效能，在 GSM8K 上達到 90.7%，在 MATH 上達到 55.1%。廣泛的實驗驗證了工具使用和資料擴充的結合，以及我們的兩階段訓練策略。我們釋出建議的資料集以及相關程式碼，供公眾使用。</paragraph>

##### **EMS-SD: Efficient Multi-sample Speculative Decoding for Accelerating Large Language Models**
2405.07542v1 by Yunsheng Ni, Chuanjian Liu, Yehui Tang, Kai Han, Yunhe Wang

Speculative decoding emerges as a pivotal technique for enhancing the
inference speed of Large Language Models (LLMs). Despite recent research aiming
to improve prediction efficiency, multi-sample speculative decoding has been
overlooked due to varying numbers of accepted tokens within a batch in the
verification phase. Vanilla method adds padding tokens in order to ensure that
the number of new tokens remains consistent across samples. However, this
increases the computational and memory access overhead, thereby reducing the
speedup ratio. We propose a novel method that can resolve the issue of
inconsistent tokens accepted by different samples without necessitating an
increase in memory or computing overhead. Furthermore, our proposed method can
handle the situation where the prediction tokens of different samples are
inconsistent without the need to add padding tokens. Sufficient experiments
demonstrate the efficacy of our method. Our code is available at
https://github.com/niyunsheng/EMS-SD.

摘要：推測性解碼作為一種關鍵技術出現，用於增強大型語言模型 (LLM) 的推論速度。儘管最近的研究旨在提高預測效率，但由於驗證階段中批次內接受的標記數量不同，多樣本推測性解碼一直被忽視。香草方法會增加填充標記，以確保新標記的數量在樣本中保持一致。但是，這會增加計算和記憶體存取的開銷，從而降低加速比。我們提出了一種新方法，可以在不增加記憶體或計算開銷的情況下解決不同樣本接受的不一致標記問題。此外，我們提出的方法可以處理不同樣本的預測標記不一致的情況，而無需增加填充標記。足夠的實驗證明了我們方法的有效性。我們的程式碼可在 https://github.com/niyunsheng/EMS-SD 取得。

##### **Random walk model that universally generates inverse square Lévy walk by eliminating search cost minimization constraint**
2405.07541v2 by Shuji Shinohara, Daiki Morita, Hayato Hirai, Ryosuke Kuribayashi, Nobuhito Manome, Toru Moriyama, Hiroshi Okamoto, Yoshihiro Nakajima, Pegio-Yukio Gunji, Ung-il Chung

The L\'evy walk, a type of random walk characterized by linear step lengths
that follow a power-law distribution, is observed in the migratory behaviors of
various organisms, ranging from bacteria to humans. Notably, L\'evy walks with
power exponents close to two are frequently observed, though their underlying
causes remain elusive. This study introduces a simplified, abstract random walk
model designed to produce inverse square L\'evy walks, also known as Cauchy
walks and explores the conditions that facilitate these phenomena. In our
model, agents move toward a randomly selected destination in multi-dimensional
space, and their movement strategy is parameterized by the extent to which they
pursue the shortest path. When the search cost is proportional to the distance
traveled, this parameter effectively reflects the emphasis on minimizing search
costs. Our findings reveal that strict adherence to this cost minimization
constraint results in a Brownian walk pattern. However, removing this
constraint transitions the movement to an inverse square L\'evy walk.
Therefore, by modulating the prioritization of search costs, our model can
seamlessly alternate between Brownian and Cauchy walk dynamics. This model has
the potential to be utilized for exploring the parameter space of an
optimization problem.

摘要：Lévy 漫步是一种随机漫步，其特征在于线性步长遵循幂律分布，在从细菌到人类的各种生物的迁徙行为中都有观察到。值得注意的是，经常观察到幂指数接近 2 的 Lévy 漫步，尽管其根本原因仍然难以捉摸。本研究引入了一个简化的抽象随机漫步模型，旨在产生逆平方 Lévy 漫步，也称为 Cauchy 漫步，并探讨了促进这些现象的条件。在我们的模型中，代理在多维空间中朝随机选择的目标移动，其移动策略由他们追求最短路径的程度参数化。当搜索成本与行进距离成正比时，此参数有效地反映了最小化搜索成本的重点。我们的研究结果表明，严格遵守此成本最小化约束会导致布朗运动模式。然而，移除此约束会将运动转换为逆平方 Lévy 漫步。因此，通过调节搜索成本的优先级，我们的模型可以在布朗和 Cauchy 运动动力学之间无缝交替。该模型有可能用于探索优化问题的参数空间。

##### **Train Faster, Perform Better: Modular Adaptive Training in Over-Parameterized Models**
2405.07527v1 by Yubin Shi, Yixuan Chen, Mingzhi Dong, Xiaochen Yang, Dongsheng Li, Yujiang Wang, Robert P. Dick, Qin Lv, Yingying Zhao, Fan Yang, Tun Lu, Ning Gu, Li Shang

Despite their prevalence in deep-learning communities, over-parameterized
models convey high demands of computational costs for proper training. This
work studies the fine-grained, modular-level learning dynamics of
over-parameterized models to attain a more efficient and fruitful training
strategy. Empirical evidence reveals that when scaling down into network
modules, such as heads in self-attention models, we can observe varying
learning patterns implicitly associated with each module's trainability. To
describe such modular-level learning capabilities, we introduce a novel concept
dubbed modular neural tangent kernel (mNTK), and we demonstrate that the
quality of a module's learning is tightly associated with its mNTK's principal
eigenvalue $\lambda_{\max}$. A large $\lambda_{\max}$ indicates that the module
learns features with better convergence, while those miniature ones may impact
generalization negatively. Inspired by the discovery, we propose a novel
training strategy termed Modular Adaptive Training (MAT) to update those
modules with their $\lambda_{\max}$ exceeding a dynamic threshold selectively,
concentrating the model on learning common features and ignoring those
inconsistent ones. Unlike most existing training schemes with a complete BP
cycle across all network modules, MAT can significantly save computations by
its partially-updating strategy and can further improve performance.
Experiments show that MAT nearly halves the computational cost of model
training and outperforms the accuracy of baselines.

摘要：儘管在深度學習社群中很普遍，但過度參數化的模型對適當訓練提出了高計算成本需求。這項研究探討過度參數化模型的細粒度、模組層級學習動態，以達成更有效率且有成效的訓練策略。實證證據顯示，當縮小到網路模組（例如自注意力模型中的 heads）時，我們可以觀察到與每個模組的可訓練性隱含關聯的不同學習模式。為了描述這種模組層級學習能力，我們引進一個新概念，稱為模組神經切線核（mNTK），並證明模組學習品質與其 mNTK 的主特徵值 $\lambda_{\max}$ 緊密相關。大的 $\lambda_{\max}$ 表示模組學習具有較佳收斂性的特徵，而那些微小的特徵可能會對泛化產生負面影響。受到這個發現的啟發，我們提出一個新訓練策略，稱為模組適應訓練（MAT），以選擇性地更新那些 $\lambda_{\max}$ 超過動態閾值的模組，將模型集中在學習常見特徵上，並忽略那些不一致的特徵。與大多數現有訓練方案在所有網路模組中進行完整 BP 循環不同，MAT 可以透過其部分更新策略大幅節省運算，並進一步提升效能。實驗顯示，MAT 幾乎將模型訓練的計算成本減半，並優於基準的準確度。

##### **SambaNova SN40L: Scaling the AI Memory Wall with Dataflow and Composition of Experts**
2405.07518v1 by Raghu Prabhakar, Ram Sivaramakrishnan, Darshan Gandhi, Yun Du, Mingran Wang, Xiangyu Song, Kejie Zhang, Tianren Gao, Angela Wang, Karen Li, Yongning Sheng, Joshua Brot, Denis Sokolov, Apurv Vivek, Calvin Leung, Arjun Sabnis, Jiayu Bai, Tuowen Zhao, Mark Gottscho, David Jackson, Mark Luttrell, Manish K. Shah, Edison Chen, Kaizhao Liang, Swayambhoo Jain, Urmish Thakker, Dawei Huang, Sumti Jairath, Kevin J. Brown, Kunle Olukotun

Monolithic large language models (LLMs) like GPT-4 have paved the way for
modern generative AI applications. Training, serving, and maintaining
monolithic LLMs at scale, however, remains prohibitively expensive and
challenging. The disproportionate increase in compute-to-memory ratio of modern
AI accelerators have created a memory wall, necessitating new methods to deploy
AI. Composition of Experts (CoE) is an alternative modular approach that lowers
the cost and complexity of training and serving. However, this approach
presents two key challenges when using conventional hardware: (1) without fused
operations, smaller models have lower operational intensity, which makes high
utilization more challenging to achieve; and (2) hosting a large number of
models can be either prohibitively expensive or slow when dynamically switching
between them.
  In this paper, we describe how combining CoE, streaming dataflow, and a
three-tier memory system scales the AI memory wall. We describe Samba-CoE, a
CoE system with 150 experts and a trillion total parameters. We deploy
Samba-CoE on the SambaNova SN40L Reconfigurable Dataflow Unit (RDU) - a
commercial dataflow accelerator architecture that has been co-designed for
enterprise inference and training applications. The chip introduces a new
three-tier memory system with on-chip distributed SRAM, on-package HBM, and
off-package DDR DRAM. A dedicated inter-RDU network enables scaling up and out
over multiple sockets. We demonstrate speedups ranging from 2x to 13x on
various benchmarks running on eight RDU sockets compared with an unfused
baseline. We show that for CoE inference deployments, the 8-socket RDU Node
reduces machine footprint by up to 19x, speeds up model switching time by 15x
to 31x, and achieves an overall speedup of 3.7x over a DGX H100 and 6.6x over a
DGX A100.

摘要：大型單體語言模型 (LLM)，例如 GPT-4，為現代生成式 AI 應用程式鋪平了道路。然而，大規模訓練、服務和維護單體 LLM 仍然極度昂貴且具有挑戰性。現代 AI 加速器的運算與記憶體比例不成比例地增加，造成了記憶體牆，需要新的方法來部署 AI。專家組成 (CoE) 是一種替代性的模組化方法，可降低訓練和服務的成本和複雜性。然而，此方法在使用傳統硬體時會產生兩個主要挑戰：(1) 沒有融合運算，較小的模型具有較低的運算強度，這使得難以達成高利用率；(2) 在動態地在大量模型之間切換時，主機大量的模型可能會非常昂貴或緩慢。
在本文中，我們描述了如何結合 CoE、串流資料流和三層記憶體系統來擴充 AI 記憶體牆。我們描述了 Samba-CoE，一個擁有 150 個專家和一兆億個總參數的 CoE 系統。我們在 SambaNova SN40L 可重新組態資料流單元 (RDU) 上部署 Samba-CoE，這是一個商業資料流加速器架構，專為企業推論和訓練應用程式而共同設計。此晶片引入了新的三層記憶體系統，包含晶片上分布式 SRAM、封裝上 HBM 和封裝外 DDR DRAM。專用的 RDU 間網路可以在多個插槽上擴充和擴充。我們展示了在八個 RDU 插槽上執行各種基準測試的加速，範圍從 2 倍到 13 倍，與未融合的基準相比。我們展示了對於 CoE 推論部署，8 插槽 RDU 節點將機器佔用空間減少了 19 倍，將模型切換時間加速了 15 倍到 31 倍，並且整體加速比 DGX H100 快了 3.7 倍，比 DGX A100 快了 6.6 倍。

##### **Fine-tuning the SwissBERT Encoder Model for Embedding Sentences and Documents**
2405.07513v1 by Juri Grosjean, Jannis Vamvas

Encoder models trained for the embedding of sentences or short documents have
proven useful for tasks such as semantic search and topic modeling. In this
paper, we present a version of the SwissBERT encoder model that we specifically
fine-tuned for this purpose. SwissBERT contains language adapters for the four
national languages of Switzerland -- German, French, Italian, and Romansh --
and has been pre-trained on a large number of news articles in those languages.
Using contrastive learning based on a subset of these articles, we trained a
fine-tuned version, which we call SentenceSwissBERT. Multilingual experiments
on document retrieval and text classification in a Switzerland-specific setting
show that SentenceSwissBERT surpasses the accuracy of the original SwissBERT
model and of a comparable baseline. The model is openly available for research
use.

摘要：針對句子或短篇文件嵌入訓練的編碼器模型，已證明對於語意搜尋和主題建模等任務很有用。在本文中，我們提出一個特別針對此目的微調的 SwissBERT 編碼器模型版本。SwissBERT 包含瑞士四種國家語言（德語、法語、義大利語和羅曼什語）的語言適配器，並已在大量這些語言的新聞文章中進行預訓練。使用基於這些文章子集的對比式學習，我們訓練了一個微調版本，我們稱之為 SentenceSwissBERT。在瑞士特定設定中的文件檢索和文字分類的多語言實驗顯示，SentenceSwissBERT 超越了原始 SwissBERT 模型和可比較的基準的準確度。該模型已開放供研究使用。

##### **RESTAD: REconstruction and Similarity based Transformer for time series Anomaly Detection**
2405.07509v1 by Ramin Ghorbani, Marcel J. T. Reinders, David M. J. Tax

Anomaly detection in time series data is crucial across various domains. The
scarcity of labeled data for such tasks has increased the attention towards
unsupervised learning methods. These approaches, often relying solely on
reconstruction error, typically fail to detect subtle anomalies in complex
datasets. To address this, we introduce RESTAD, an adaptation of the
Transformer model by incorporating a layer of Radial Basis Function (RBF)
neurons within its architecture. This layer fits a non-parametric density in
the latent representation, such that a high RBF output indicates similarity
with predominantly normal training data. RESTAD integrates the RBF similarity
scores with the reconstruction errors to increase sensitivity to anomalies. Our
empirical evaluations demonstrate that RESTAD outperforms various established
baselines across multiple benchmark datasets.

摘要：時序資料的異常偵測在各種領域中至關重要。此類任務標記資料的稀少性，已提升無監督式學習方法的關注度。這些方法通常僅依賴於重建誤差，通常無法偵測複雜資料集中的細微異常。為了解決這個問題，我們引進 RESTAD，一種 Transformer 模型的改編，在架構中加入徑向基函數 (RBF) 神經元層。此層在潛在表示中擬合非參數密度，因此高 RBF 輸出表示與主要的正常訓練資料相似。RESTAD 將 RBF 相似性評分與重建誤差整合，以提升對異常的敏感度。我們的實證評估顯示，RESTAD 在多個基準資料集上優於各種已建立的基準。

##### **Consistency Policy: Accelerated Visuomotor Policies via Consistency Distillation**
2405.07503v1 by Aaditya Prasad, Kevin Lin, Jimmy Wu, Linqi Zhou, Jeannette Bohg

Many robotic systems, such as mobile manipulators or quadrotors, cannot be
equipped with high-end GPUs due to space, weight, and power constraints. These
constraints prevent these systems from leveraging recent developments in
visuomotor policy architectures that require high-end GPUs to achieve fast
policy inference. In this paper, we propose Consistency Policy, a faster and
similarly powerful alternative to Diffusion Policy for learning visuomotor
robot control. By virtue of its fast inference speed, Consistency Policy can
enable low latency decision making in resource-constrained robotic setups. A
Consistency Policy is distilled from a pretrained Diffusion Policy by enforcing
self-consistency along the Diffusion Policy's learned trajectories. We compare
Consistency Policy with Diffusion Policy and other related speed-up methods
across 6 simulation tasks as well as two real-world tasks where we demonstrate
inference on a laptop GPU. For all these tasks, Consistency Policy speeds up
inference by an order of magnitude compared to the fastest alternative method
and maintains competitive success rates. We also show that the Conistency
Policy training procedure is robust to the pretrained Diffusion Policy's
quality, a useful result that helps practioners avoid extensive testing of the
pretrained model. Key design decisions that enabled this performance are the
choice of consistency objective, reduced initial sample variance, and the
choice of preset chaining steps. Code and training details will be released
publicly.

摘要：許多機器人系統，例如行動式機械手臂或四旋翼無人機，由於空間、重量和功耗限制，無法配備高階 GPU。這些限制使得這些系統無法利用視覺運動策略結構的最新發展，而這些發展需要高階 GPU 才能實現快速的策略推論。在本文中，我們提出了一致性策略，這是一個比擴散策略更快且功能相似的替代方案，用於學習視覺運動機器人控制。由於其快速的推論速度，一致性策略可以在資源受限的機器人設置中實現低延遲決策制定。一致性策略是透過強制沿著擴散策略的學習軌跡執行自我一致性，從預訓練的擴散策略中提取的。我們比較了擴散策略和一致性策略，以及其他相關的加速方法，涵蓋 6 項模擬任務以及兩項真實世界任務，我們在其中展示了筆記型電腦 GPU 上的推論。對於所有這些任務，與最快的替代方法相比，一致性策略將推論速度提高了一個數量級，並維持有競爭力的成功率。我們還表明，一致性策略訓練程序對於預訓練擴散策略的品質具有穩健性，這是一個有用的結果，有助於實務人員避免對預訓練模型進行廣泛的測試。實現此效能的關鍵設計決策是一致性目標的選擇、降低初始樣本變異數，以及預設鏈接步驟的選擇。程式碼和訓練細節將公開發布。

##### **PromptLink: Leveraging Large Language Models for Cross-Source Biomedical Concept Linking**
2405.07500v1 by Yuzhang Xie, Jiaying Lu, Joyce Ho, Fadi Nahab, Xiao Hu, Carl Yang

Linking (aligning) biomedical concepts across diverse data sources enables
various integrative analyses, but it is challenging due to the discrepancies in
concept naming conventions. Various strategies have been developed to overcome
this challenge, such as those based on string-matching rules, manually crafted
thesauri, and machine learning models. However, these methods are constrained
by limited prior biomedical knowledge and can hardly generalize beyond the
limited amounts of rules, thesauri, or training samples. Recently, large
language models (LLMs) have exhibited impressive results in diverse biomedical
NLP tasks due to their unprecedentedly rich prior knowledge and strong
zero-shot prediction abilities. However, LLMs suffer from issues including high
costs, limited context length, and unreliable predictions. In this research, we
propose PromptLink, a novel biomedical concept linking framework that leverages
LLMs. It first employs a biomedical-specialized pre-trained language model to
generate candidate concepts that can fit in the LLM context windows. Then it
utilizes an LLM to link concepts through two-stage prompts, where the
first-stage prompt aims to elicit the biomedical prior knowledge from the LLM
for the concept linking task and the second-stage prompt enforces the LLM to
reflect on its own predictions to further enhance their reliability. Empirical
results on the concept linking task between two EHR datasets and an external
biomedical KG demonstrate the effectiveness of PromptLink. Furthermore,
PromptLink is a generic framework without reliance on additional prior
knowledge, context, or training data, making it well-suited for concept linking
across various types of data sources. The source code is available at
https://github.com/constantjxyz/PromptLink.

摘要：<paragraph>連結（對齊）不同資料來源的生物醫學概念可以進行各種整合分析，但由於概念命名慣例存在差異，因此具有挑戰性。已經開發出各種策略來克服此挑戰，例如基於字串比對規則、人工建立的同義詞庫和機器學習模型的策略。然而，這些方法受到有限的先前生物醫學知識的約束，而且很難概括超出有限的規則、同義詞庫或訓練樣本。最近，大型語言模型 (LLM) 由於其前所未有的豐富先驗知識和強大的零次方預測能力，在不同的生物醫學 NLP 任務中表現出令人印象深刻的結果。然而，LLM 存在成本高、上下文長度受限和預測不可靠等問題。在這項研究中，我們提出 PromptLink，一個利用 LLM 的新生物醫學概念連結架構。它首先採用生物醫學專業的預訓練語言模型來產生候選概念，這些概念可以放入 LLM 上下文視窗中。然後，它利用 LLM 透過兩階段提示來連結概念，其中第一階段提示旨在從 LLM 引出概念連結任務的生物醫學先驗知識，而第二階段提示強制 LLM 反思自己的預測以進一步提高其可靠性。在兩個 EHR 資料集和一個外部生物醫學 KG 之間的概念連結任務上的經驗結果證明了 PromptLink 的有效性。此外，PromptLink 是一個通用架構，不依賴額外的先驗知識、上下文或訓練資料，使其非常適合連結各種類型資料來源的概念。原始程式碼可在 https://github.com/constantjxyz/PromptLink 取得。</paragraph>

##### **MacBehaviour: An R package for behavioural experimentation on large language models**
2405.07495v1 by Xufeng Duan, Shixuan Li, Zhenguang G. Cai1

There has been increasing interest in investigating the behaviours of large
language models (LLMs) and LLM-powered chatbots by treating an LLM as a
participant in a psychological experiment. We therefore developed an R package
called "MacBehaviour" that aims to interact with more than 60 language models
in one package (e.g., OpenAI's GPT family, the Claude family, Gemini, Llama
family, and open-source models) and streamline the experimental process of LLMs
behaviour experiments. The package offers a comprehensive set of functions
designed for LLM experiments, covering experiment design, stimuli presentation,
model behaviour manipulation, logging response and token probability. To
demonstrate the utility and effectiveness of "MacBehaviour," we conducted three
validation experiments on three LLMs (GPT-3.5, Llama-2 7B, and Vicuna-1.5 13B)
to replicate sound-gender association in LLMs. The results consistently showed
that they exhibit human-like tendencies to infer gender from novel personal
names based on their phonology, as previously demonstrated (Cai et al., 2023).
In summary, "MacBehaviour" is an R package for machine behaviour studies which
offers a user-friendly interface and comprehensive features to simplify and
standardize the experimental process.

摘要：<paragraph>透過將大型語言模型 (LLM) 視為心理實驗中的參與者，對於探究大型語言模型和 LLM 驅動的聊天機器人的行為越來越感興趣。因此，我們開發了一個名為「MacBehaviour」的 R 套件，旨在透過一個套件與超過 60 個語言模型互動（例如 OpenAI 的 GPT 家族、Claude 家族、Gemini、Llama 家族和開源模型），並簡化 LLM 行為實驗的實驗過程。這個套件提供了一組全面的函數，專門用於 LLM 實驗，涵蓋實驗設計、刺激呈現、模型行為操作、記錄回應和權杖機率。為了展示「MacBehaviour」的實用性和有效性，我們對三個 LLM（GPT-3.5、Llama-2 7B 和 Vicuna-1.5 13B）進行了三個驗證實驗，以複製 LLM 中的聲音性別關聯。結果一致顯示，它們表現出類似人類的傾向，根據音韻學從新的人名推論性別，如先前所證明的（Cai 等人，2023）。總之，「MacBehaviour」是一個用於機器行為研究的 R 套件，它提供了一個使用者友善的介面和全面的功能，以簡化和標準化實驗過程。</paragraph>

##### **Strategic Data Ordering: Enhancing Large Language Model Performance through Curriculum Learning**
2405.07490v1 by Jisu Kim, Juhwan Lee

The rapid advancement of Large Language Models (LLMs) has improved text
understanding and generation but poses challenges in computational resources.
This study proposes a curriculum learning-inspired, data-centric training
strategy that begins with simpler tasks and progresses to more complex ones,
using criteria such as prompt length, attention scores, and loss values to
structure the training data. Experiments with Mistral-7B (Jiang et al., 2023)
and Gemma-7B (Team et al., 2024) models demonstrate that curriculum learning
slightly improves performance compared to traditional random data shuffling.
Notably, we observed that sorting data based on our proposed attention criteria
generally led to better performance. This approach offers a sustainable method
to enhance LLM performance without increasing model size or dataset volume,
addressing scalability challenges in LLM training.

摘要：大型語言模型 (LLM) 的快速進步改進了文字理解和生成，但在計算資源方面提出了挑戰。本研究提出了一個受課程學習啟發的、以數據為中心的訓練策略，從較簡單的任務開始，逐漸進展到更複雜的任務，使用提示長度、注意力分數和損失值等標準來構造訓練數據。使用 Mistral-7B (Jiang 等人，2023) 和 Gemma-7B (Team 等人，2024) 模型進行的實驗表明，與傳統的隨機數據洗牌相比，課程學習略微提高了性能。值得注意的是，我們觀察到根據我們提出的注意力標準對數據進行排序通常會帶來更好的性能。這種方法提供了一種可持續的方法來增強 LLM 性能，而無需增加模型大小或數據集體積，從而應對 LLM 訓練中的可擴充性挑戰。

##### **Integrating Intent Understanding and Optimal Behavior Planning for Behavior Tree Generation from Human Instructions**
2405.07474v1 by Xinglin Chen, Yishuai Cai, Yunxin Mao, Minglong Li, Wenjing Yang, Weixia Xu, Ji Wang

Robots executing tasks following human instructions in domestic or industrial
environments essentially require both adaptability and reliability. Behavior
Tree (BT) emerges as an appropriate control architecture for these scenarios
due to its modularity and reactivity. Existing BT generation methods, however,
either do not involve interpreting natural language or cannot theoretically
guarantee the BTs' success. This paper proposes a two-stage framework for BT
generation, which first employs large language models (LLMs) to interpret goals
from high-level instructions, then constructs an efficient goal-specific BT
through the Optimal Behavior Tree Expansion Algorithm (OBTEA). We represent
goals as well-formed formulas in first-order logic, effectively bridging intent
understanding and optimal behavior planning. Experiments in the service robot
validate the proficiency of LLMs in producing grammatically correct and
accurately interpreted goals, demonstrate OBTEA's superiority over the baseline
BT Expansion algorithm in various metrics, and finally confirm the practical
deployability of our framework. The project website is
https://dids-ei.github.io/Project/LLM-OBTEA/.

摘要：機器人在家庭或工業環境中執行任務並遵循人類指示，基本上需要適應性和可靠性。行為樹 (BT) 由於其模組化和反應性，成為這些情境的適當控制架構。然而，現有的 BT 生成方法，要不不涉及自然語言的詮釋，要不無法在理論上保證 BT 的成功。本文提出一個 BT 生成的兩階段架構，首先使用大型語言模型 (LLM) 從高級指令中詮釋目標，然後透過最佳行為樹擴展演算法 (OBTEA) 建構一個目標特定的有效 BT。我們將目標表示為一階邏輯中的良構公式，有效地連結意圖理解和最佳行為規劃。服務機器人的實驗驗證了 LLM 在產生語法正確且詮釋精準的目標方面的熟練度，展示了 OBTEA 在各種指標上優於基線 BT 擴展演算法，最後確認了我們架構的實際可部署性。專案網站為 https://dids-ei.github.io/Project/LLM-OBTEA/。

##### **Evaluating large language models in medical applications: a survey**
2405.07468v1 by Xiaolan Chen, Jiayang Xiang, Shanfu Lu, Yexin Liu, Mingguang He, Danli Shi

Large language models (LLMs) have emerged as powerful tools with
transformative potential across numerous domains, including healthcare and
medicine. In the medical domain, LLMs hold promise for tasks ranging from
clinical decision support to patient education. However, evaluating the
performance of LLMs in medical contexts presents unique challenges due to the
complex and critical nature of medical information. This paper provides a
comprehensive overview of the landscape of medical LLM evaluation, synthesizing
insights from existing studies and highlighting evaluation data sources, task
scenarios, and evaluation methods. Additionally, it identifies key challenges
and opportunities in medical LLM evaluation, emphasizing the need for continued
research and innovation to ensure the responsible integration of LLMs into
clinical practice.

摘要：大型語言模型 (LLM) 已成為強大的工具，在包括醫療保健和醫學在內的眾多領域具有轉變潛力。在醫療領域，LLM 有望承擔從臨床決策支援到患者教育的各種任務。然而，由於醫療信息的複雜和關鍵性質，在醫療環境中評估 LLM 的性能提出了獨特的挑戰。本文對醫療 LLM 評估的現狀提供了全面的概述，綜合了現有研究的見解，並重點介紹了評估數據來源、任務場景和評估方法。此外，它還確定了醫療 LLM 評估中的關鍵挑戰和機遇，強調需要持續的研究和創新，以確保 LLM 負責任地整合到臨床實踐中。

##### **MCS-SQL: Leveraging Multiple Prompts and Multiple-Choice Selection For Text-to-SQL Generation**
2405.07467v1 by Dongjun Lee, Choongwon Park, Jaehyuk Kim, Heesoo Park

Recent advancements in large language models (LLMs) have enabled in-context
learning (ICL)-based methods that significantly outperform fine-tuning
approaches for text-to-SQL tasks. However, their performance is still
considerably lower than that of human experts on benchmarks that include
complex schemas and queries, such as BIRD. This study considers the sensitivity
of LLMs to the prompts and introduces a novel approach that leverages multiple
prompts to explore a broader search space for possible answers and effectively
aggregate them. Specifically, we robustly refine the database schema through
schema linking using multiple prompts. Thereafter, we generate various
candidate SQL queries based on the refined schema and diverse prompts. Finally,
the candidate queries are filtered based on their confidence scores, and the
optimal query is obtained through a multiple-choice selection that is presented
to the LLM. When evaluated on the BIRD and Spider benchmarks, the proposed
method achieved execution accuracies of 65.5\% and 89.6\%, respectively,
significantly outperforming previous ICL-based methods. Moreover, we
established a new SOTA performance on the BIRD in terms of both the accuracy
and efficiency of the generated queries.

摘要：大型語言模型 (LLM) 的最新進展讓基於情境學習 (ICL) 的方法得以問世，這些方法在文字轉 SQL 任務中大幅優於微調方法。然而，它們的表現仍然遠低於人類專家在包含複雜架構和查詢的基準測驗中的表現，例如 BIRD。本研究考量 LLM 對提示的敏感度，並引入一種新穎的方法，該方法利用多個提示探索可能的答案的更廣泛搜索空間，並有效地彙總它們。具體來說，我們透過使用多個提示進行架構連結，來穩健地精煉資料庫架構。此後，我們根據精煉的架構和不同的提示產生各種候選 SQL 查詢。最後，根據候選查詢的信心分數對其進行篩選，並透過向 LLM 呈現多重選擇選項來取得最佳查詢。在 BIRD 和 Spider 基準測驗中進行評估時，所提出的方法分別達到 65.5% 和 89.6% 的執行準確度，顯著優於先前的基於 ICL 的方法。此外，我們在 BIRD 上建立了新的 SOTA 效能，無論是在產生的查詢的準確性還是效率方面。

##### **HoneyBee: A Scalable Modular Framework for Creating Multimodal Oncology Datasets with Foundational Embedding Models**
2405.07460v1 by Aakash Tripathi, Asim Waqas, Yasin Yilmaz, Ghulam Rasool

Developing accurate machine learning models for oncology requires
large-scale, high-quality multimodal datasets. However, creating such datasets
remains challenging due to the complexity and heterogeneity of medical data. To
address this challenge, we introduce HoneyBee, a scalable modular framework for
building multimodal oncology datasets that leverages foundational models to
generate representative embeddings. HoneyBee integrates various data
modalities, including clinical records, imaging data, and patient outcomes. It
employs data preprocessing techniques and transformer-based architectures to
generate embeddings that capture the essential features and relationships
within the raw medical data. The generated embeddings are stored in a
structured format using Hugging Face datasets and PyTorch dataloaders for
accessibility. Vector databases enable efficient querying and retrieval for
machine learning applications. We demonstrate the effectiveness of HoneyBee
through experiments assessing the quality and representativeness of the
embeddings. The framework is designed to be extensible to other medical domains
and aims to accelerate oncology research by providing high-quality, machine
learning-ready datasets. HoneyBee is an ongoing open-source effort, and the
code, datasets, and models are available at the project repository.

摘要：開發精準的腫瘤學機器學習模型需要
大規模、高品質的多模態資料集。然而，由於醫療資料的複雜性和異質性，建立此類資料集仍然具有挑戰性。為了應對這一挑戰，我們引入了 HoneyBee，這是一個可擴充模組化的框架，用於建立多模態腫瘤學資料集，該框架利用基礎模型來生成具有代表性的嵌入。HoneyBee 整合了各種資料模態，包括臨床記錄、影像資料和患者結果。它採用資料預處理技術和基於轉換器的架構來生成嵌入，以擷取原始醫療資料中的基本特徵和關係。所生成的嵌入使用 Hugging Face 資料集和 PyTorch 資料載入器儲存在結構化格式中，以方便存取。向量資料庫能針對機器學習應用程式啟用有效率的查詢和擷取。我們透過評估嵌入品質和代表性的實驗，證明了 HoneyBee 的有效性。該框架被設計成可擴充至其他醫療領域，並旨在透過提供高品質、可供機器學習使用的資料集來加速腫瘤學研究。HoneyBee 是一個持續進行的開源專案，程式碼、資料集和模型都可以在專案儲存庫中取得。

##### **Rene: A Pre-trained Multi-modal Architecture for Auscultation of Respiratory Diseases**
2405.07442v1 by Pengfei Zhang, Zhihang Zheng, Shichen Zhang, Minghao Yang, Shaojun Tang

This study presents a novel methodology utilizing a pre-trained speech
recognition model for processing respiratory sound data. By incorporating
medical record information, we introduce an innovative multi-modal
deep-learning architecture, named Rene, which addresses the challenges of poor
interpretability and underperformance in real-time clinical diagnostic response
observed in previous respiratory disease-focused models. The proposed Rene
architecture demonstrated significant improvements of 10.24%, 16.15%, 15.29%,
and 18.90% respectively, compared to the baseline across four tasks related to
respiratory event detection and audio record classification on the SPRSound
database. In patient disease prediction tests on the ICBHI database, the
architecture exhibited improvements of 23% in the mean of average score and
harmonic score compared to the baseline. Furthermore, we developed a real-time
respiratory sound discrimination system based on the Rene architecture,
featuring a dual-thread design and compressed model parameters for simultaneous
microphone recording and real-time dynamic decoding. Employing state-of-the-art
Edge AI technology, this system enables rapid and accurate responses for
respiratory sound auscultation, facilitating deployment on wearable clinical
detection devices to capture incremental data, which can be synergistically
evolved with large-scale models deployed on cloud servers for downstream tasks.

摘要：本研究提出了一種新穎的方法，利用預訓練的語音識別模型來處理呼吸音數據。通過整合病歷信息，我們引入了一種創新的多模態深度學習架構，名為 Rene，它應對了在先前的呼吸道疾病模型中觀察到的實時臨床診斷響應中可解釋性差和性能不佳的挑戰。與 SPRSound 數據庫中與呼吸事件檢測和音頻記錄分類相關的四項任務的基準相比，提出的 Rene 架構分別展示了 10.24%、16.15%、15.29% 和 18.90% 的顯著改進。在 ICBHI 數據庫上的患者疾病預測測試中，與基準相比，該架構在平均分和諧波分上表現出 23% 的改進。此外，我們開發了一個基於 Rene 架構的實時呼吸音識別系統，具有雙線程設計和壓縮模型參數，用於同時麥克風錄音和實時動態解碼。採用最先進的 Edge AI 技術，該系統能夠對呼吸音聽診進行快速準確的響應，促進在可穿戴式臨床檢測設備上部署以捕獲增量數據，這些數據可以與部署在雲服務器上的大規模模型協同進化，以執行下游任務。

##### **Evaluation of Retrieval-Augmented Generation: A Survey**
2405.07437v1 by Hao Yu, Aoran Gan, Kai Zhang, Shiwei Tong, Qi Liu, Zhaofeng Liu

Retrieval-Augmented Generation (RAG) has emerged as a pivotal innovation in
natural language processing, enhancing generative models by incorporating
external information retrieval. Evaluating RAG systems, however, poses distinct
challenges due to their hybrid structure and reliance on dynamic knowledge
sources. We consequently enhanced an extensive survey and proposed an analysis
framework for benchmarks of RAG systems, RAGR (Retrieval, Generation,
Additional Requirement), designed to systematically analyze RAG benchmarks by
focusing on measurable outputs and established truths. Specifically, we
scrutinize and contrast multiple quantifiable metrics of the Retrieval and
Generation component, such as relevance, accuracy, and faithfulness, of the
internal links within the current RAG evaluation methods, covering the possible
output and ground truth pairs. We also analyze the integration of additional
requirements of different works, discuss the limitations of current benchmarks,
and propose potential directions for further research to address these
shortcomings and advance the field of RAG evaluation. In conclusion, this paper
collates the challenges associated with RAG evaluation. It presents a thorough
analysis and examination of existing methodologies for RAG benchmark design
based on the proposed RGAR framework.

摘要：檢索增強生成 (RAG) 已成為自然語言處理中的一項關鍵創新，透過納入外部資訊檢索來增強生成模型。然而，評估 RAG 系統由於其混合結構和對動態知識來源的依賴性，因此提出了不同的挑戰。因此，我們增強了一項廣泛的調查，並針對 RAG 系統的基準，提出了 RAGR（檢索、生成、額外需求）分析架構，旨在透過專注於可衡量的輸出和既定事實，系統性地分析 RAG 基準。具體來說，我們仔細審查並對比檢索和生成組件的各種可量化指標，例如相關性、準確性和忠實度，以及當前 RAG 評估方法中內部連結的可能輸出和基本事實配對。我們也分析了不同著作中額外需求的整合，探討了當前基準的限制，並針對這些缺點提出了進一步研究的潛在方向，以推進 RAG 評估領域。總之，本文彙整了與 RAG 評估相關的挑戰。它基於所提出的 RAGR 架構，對現有 RAG 基準設計方法進行了徹底的分析和檢驗。

##### **Can Language Models Explain Their Own Classification Behavior?**
2405.07436v1 by Dane Sherburn, Bilal Chughtai, Owain Evans

Large language models (LLMs) perform well at a myriad of tasks, but
explaining the processes behind this performance is a challenge. This paper
investigates whether LLMs can give faithful high-level explanations of their
own internal processes. To explore this, we introduce a dataset,
ArticulateRules, of few-shot text-based classification tasks generated by
simple rules. Each rule is associated with a simple natural-language
explanation. We test whether models that have learned to classify inputs
competently (both in- and out-of-distribution) are able to articulate freeform
natural language explanations that match their classification behavior. Our
dataset can be used for both in-context and finetuning evaluations. We evaluate
a range of LLMs, demonstrating that articulation accuracy varies considerably
between models, with a particularly sharp increase from GPT-3 to GPT-4. We then
investigate whether we can improve GPT-3's articulation accuracy through a
range of methods. GPT-3 completely fails to articulate 7/10 rules in our test,
even after additional finetuning on correct explanations. We release our
dataset, ArticulateRules, which can be used to test self-explanation for LLMs
trained either in-context or by finetuning.

摘要：大型語言模型 (LLM) 在大量任務中表現良好，但要解釋這種表現背後的過程卻是一項挑戰。本文探討 LLM 是否能對其自身的內部過程提供忠實的高層次解釋。為了探討這一點，我們引入了一個數據集 ArticulateRules，其中包含由簡單規則生成的少量基於文本的分類任務。每個規則都與一個簡單的自然語言解釋相關聯。我們測試了已學會對輸入進行分類的模型（無論是在分佈內還是分佈外）是否能夠表達出與其分類行為相符的自由形式自然語言解釋。我們的數據集可用於上下文和微調評估。我們評估了一系列 LLM，證明了模型之間的表達準確性差異很大，特別是從 GPT-3 到 GPT-4 的大幅提升。然後，我們探討了是否能夠通過一系列方法來提高 GPT-3 的表達準確性。即使在對正確的解釋進行了額外的微調後，GPT-3 仍然完全無法表達我們測試中的 7/10 條規則。我們發布了我們的數據集 ArticulateRules，它可用於測試在上下文中或通過微調訓練的 LLM 的自我解釋。

##### **MoVL:Exploring Fusion Strategies for the Domain-Adaptive Application of Pretrained Models in Medical Imaging Tasks**
2405.07411v1 by Haijiang Tian, Jingkun Yue, Xiaohong Liu, Guoxing Yang, Zeyu Jiang, Guangyu Wang

Medical images are often more difficult to acquire than natural images due to
the specialism of the equipment and technology, which leads to less medical
image datasets. So it is hard to train a strong pretrained medical vision
model. How to make the best of natural pretrained vision model and adapt in
medical domain still pends. For image classification, a popular method is
linear probe (LP). However, LP only considers the output after feature
extraction. Yet, there exists a gap between input medical images and natural
pretrained vision model. We introduce visual prompting (VP) to fill in the gap,
and analyze the strategies of coupling between LP and VP. We design a joint
learning loss function containing categorisation loss and discrepancy loss,
which describe the variance of prompted and plain images, naming this joint
training strategy MoVL (Mixture of Visual Prompting and Linear Probe). We
experiment on 4 medical image classification datasets, with two mainstream
architectures, ResNet and CLIP. Results shows that without changing the
parameters and architecture of backbone model and with less parameters, there
is potential for MoVL to achieve full finetune (FF) accuracy (on four medical
datasets, average 90.91% for MoVL and 91.13% for FF). On out of distribution
medical dataset, our method(90.33%) can outperform FF (85.15%) with absolute
5.18 % lead.

摘要：医学影像通常比自然影像更难获取，这是因为设备和技术的专业性，导致医学影像数据集较少。因此，很难训练一个强大的医学视觉模型。如何充分利用自然预训练视觉模型并在医学领域进行调整仍然悬而未决。对于图像分类，一种流行的方法是线性探针 (LP)。然而，LP 仅考虑特征提取后的输出。然而，输入医学图像和自然预训练视觉模型之间存在差距。我们引入视觉提示 (VP) 来填补这一空白，并分析 LP 和 VP 之间的耦合策略。我们设计了一个包含分类损失和差异损失的联合学习损失函数，描述了提示图像和普通图像的差异，并将这种联合训练策略命名为 MoVL（视觉提示和线性探针的混合）。我们在 4 个医学图像分类数据集上进行实验，使用两种主流架构 ResNet 和 CLIP。结果表明，在不改变骨干模型的参数和架构且参数更少的情况下，MoVL 有可能达到完全微调 (FF) 准确度（在四个医学数据集上，MoVL 平均为 90.91%，FF 为 91.13%）。在分布外的医学数据集上，我们的方法 (90.33%) 可以以绝对 5.18% 的领先优势优于 FF (85.15%)。

##### **PitcherNet: Powering the Moneyball Evolution in Baseball Video Analytics**
2405.07407v1 by Jerrin Bright, Bavesh Balaji, Yuhao Chen, David A Clausi, John S Zelek

In the high-stakes world of baseball, every nuance of a pitcher's mechanics
holds the key to maximizing performance and minimizing runs. Traditional
analysis methods often rely on pre-recorded offline numerical data, hindering
their application in the dynamic environment of live games. Broadcast video
analysis, while seemingly ideal, faces significant challenges due to factors
like motion blur and low resolution. To address these challenges, we introduce
PitcherNet, an end-to-end automated system that analyzes pitcher kinematics
directly from live broadcast video, thereby extracting valuable pitch
statistics including velocity, release point, pitch position, and release
extension. This system leverages three key components: (1) Player tracking and
identification by decoupling actions from player kinematics; (2) Distribution
and depth-aware 3D human modeling; and (3) Kinematic-driven pitch statistics.
Experimental validation demonstrates that PitcherNet achieves robust analysis
results with 96.82% accuracy in pitcher tracklet identification, reduced joint
position error by 1.8mm and superior analytics compared to baseline methods. By
enabling performance-critical kinematic analysis from broadcast video,
PitcherNet paves the way for the future of baseball analytics by optimizing
pitching strategies, preventing injuries, and unlocking a deeper understanding
of pitcher mechanics, forever transforming the game.

摘要：在棒球這個高風險的世界裡，投手力學的每個細微差別
掌握著最大化表現和最小化失分的關鍵。傳統
分析方法通常依賴於預先錄製的離線數值資料，阻礙
它們在動態的現場比賽環境中的應用。廣播影片
分析雖然看似理想，但由於運動模糊和低解析度等因素而面臨重大挑戰。為了應對這些挑戰，我們引入了
PitcherNet，一個端到端的自動化系統，它直接從現場廣播影片分析投手的動作，從而提取有價值的投球
統計數據，包括速度、出手點、投球位置和出手延展。這個系統利用了三個關鍵組成部分：(1) 透過將動作與投手動作分離來進行球員追蹤和識別；(2) 分布和深度感知 3D 人體建模；以及 (3) 以動作為主的投球統計數據。實驗驗證表明，PitcherNet 在投手軌跡識別方面達到了 96.82% 的準確度，關節位置誤差減少了 1.8 毫米，並且與基準方法相比具有出色的分析能力。透過從廣播影片中實現對表現至關重要的動作分析，
PitcherNet 為棒球分析的未來鋪平了道路，透過優化
投球策略、預防受傷，以及深入了解投手力學，永遠改變比賽。

##### **Machine Unlearning: A Comprehensive Survey**
2405.07406v1 by Weiqi Wang, Zhiyi Tian, Shui Yu

As the right to be forgotten has been legislated worldwide, many studies
attempt to design unlearning mechanisms to protect users' privacy when they
want to leave machine learning service platforms. Specifically, machine
unlearning is to make a trained model to remove the contribution of an erased
subset of the training dataset. This survey aims to systematically classify a
wide range of machine unlearning and discuss their differences, connections and
open problems. We categorize current unlearning methods into four scenarios:
centralized unlearning, distributed and irregular data unlearning, unlearning
verification, and privacy and security issues in unlearning. Since centralized
unlearning is the primary domain, we use two parts to introduce: firstly, we
classify centralized unlearning into exact unlearning and approximate
unlearning; secondly, we offer a detailed introduction to the techniques of
these methods. Besides the centralized unlearning, we notice some studies about
distributed and irregular data unlearning and introduce federated unlearning
and graph unlearning as the two representative directions. After introducing
unlearning methods, we review studies about unlearning verification. Moreover,
we consider the privacy and security issues essential in machine unlearning and
organize the latest related literature. Finally, we discuss the challenges of
various unlearning scenarios and address the potential research directions.

摘要：隨著全球立法保障被遺忘權，許多研究嘗試設計忘記機制，以在使用者希望離開機器學習服務平台時保護其隱私。具體來說，機器忘記是讓訓練好的模型移除已刪除的訓練資料子集的貢獻。這項調查旨在系統性地分類各種機器忘記，並討論它們的差異、關聯性和未解決的問題。我們將目前的忘記方法分類為四種場景：集中式忘記、分散式和不規則資料忘記、忘記驗證，以及忘記中的隱私和安全問題。由於集中式忘記是主要領域，我們使用兩部分來介紹：首先，我們將集中式忘記分類為精確忘記和近似忘記；其次，我們詳細介紹這些方法的技術。除了集中式忘記之外，我們注意到一些關於分散式和不規則資料忘記的研究，並介紹聯合忘記和圖忘記作為兩個代表性方向。在介紹忘記方法後，我們回顧了關於忘記驗證的研究。此外，我們認為隱私和安全問題在機器忘記中至關重要，並整理了最新的相關文獻。最後，我們討論了各種忘記場景的挑戰，並說明了潛在的研究方向。

##### **Indoor PM2.5 forecasting and the association with outdoor air pollution: a modelling study based on sensor data in Australia**
2405.07404v1 by Wenhua Yu, Bahareh Nakisa, Seng W. Loke, Svetlana Stevanovic, Yuming Guo, Mohammad Naim Rastgoo

Exposure to poor indoor air quality poses significant health risks,
necessitating thorough assessment to mitigate associated dangers. This study
aims to predict hourly indoor fine particulate matter (PM2.5) concentrations
and investigate their correlation with outdoor PM2.5 levels across 24 distinct
buildings in Australia. Indoor air quality data were gathered from 91
monitoring sensors in eight Australian cities spanning 2019 to 2022. Employing
an innovative three-stage deep ensemble machine learning framework (DEML),
comprising three base models (Support Vector Machine, Random Forest, and
eXtreme Gradient Boosting) and two meta-models (Random Forest and Generalized
Linear Model), hourly indoor PM2.5 concentrations were predicted. The model's
accuracy was evaluated using a rolling windows approach, comparing its
performance against three benchmark algorithms (SVM, RF, and XGBoost).
Additionally, a correlation analysis assessed the relationship between indoor
and outdoor PM2.5 concentrations. Results indicate that the DEML model
consistently outperformed benchmark models, achieving an R2 ranging from 0.63
to 0.99 and RMSE from 0.01 to 0.663 mg/m3 for most sensors. Notably, outdoor
PM2.5 concentrations significantly impacted indoor air quality, particularly
evident during events like bushfires. This study underscores the importance of
accurate indoor air quality prediction, crucial for developing
location-specific early warning systems and informing effective interventions.
By promoting protective behaviors, these efforts contribute to enhanced public
health outcomes.

摘要：暴露于室内空气品质不佳会造成重大的健康风险，因此有必要进行彻底评估以减轻相关危险。本研究旨在预测澳大利亚 24 栋不同建筑物的每小时室内细颗粒物 (PM2.5) 浓度，并调查其与室外 PM2.5 水平的相关性。室内空气品质数据是从 2019 年到 2022 年间分布于八个澳大利亚城市的 91 个监测传感器收集的。采用创新的三阶段深度集成机器学习框架 (DEML)，包括三个基础模型（支持向量机、随机森林和 eXtreme 梯度提升）和两个元模型（随机森林和广义线性模型），预测每小时的室内 PM2.5 浓度。该模型的准确性是使用滚动窗口方法评估的，将其性能与三个基准算法（SVM、RF 和 XGBoost）进行比较。此外，相关性分析评估了室内和室外 PM2.5 浓度之间的关系。结果表明，DEML 模型始终优于基准模型，对于大多数传感器，R2 范围从 0.63 到 0.99，RMSE 从 0.01 到 0.663 mg/m3。值得注意的是，室外 PM2.5 浓度会显著影响室内空气品质，尤其在丛林大火等事件中很明显。本研究强调了准确预测室内空气品质的重要性，这对于开发针对特定地点的预警系统和提供有效的干预措施至关重要。通过促进保护性行为，这些努力有助于改善公共卫生成果。

##### **CaFA: Global Weather Forecasting with Factorized Attention on Sphere**
2405.07395v1 by Zijie Li, Anthony Zhou, Saurabh Patil, Amir Barati Farimani

Accurate weather forecasting is crucial in various sectors, impacting
decision-making processes and societal events. Data-driven approaches based on
machine learning models have recently emerged as a promising alternative to
numerical weather prediction models given their potential to capture physics of
different scales from historical data and the significantly lower computational
cost during the prediction stage. Renowned for its state-of-the-art performance
across diverse domains, the Transformer model has also gained popularity in
machine learning weather prediction. Yet applying Transformer architectures to
weather forecasting, particularly on a global scale is computationally
challenging due to the quadratic complexity of attention and the quadratic
increase in spatial points as resolution increases. In this work, we propose a
factorized-attention-based model tailored for spherical geometries to mitigate
this issue. More specifically, it utilizes multi-dimensional factorized kernels
that convolve over different axes where the computational complexity of the
kernel is only quadratic to the axial resolution instead of overall resolution.
The deterministic forecasting accuracy of the proposed model on $1.5^\circ$ and
0-7 days' lead time is on par with state-of-the-art purely data-driven machine
learning weather prediction models. We also showcase the proposed model holds
great potential to push forward the Pareto front of accuracy-efficiency for
Transformer weather models, where it can achieve better accuracy with less
computational cost compared to Transformer based models with standard
attention.

摘要：精準的天氣預測在各個領域至關重要，會影響決策流程和社會事件。基於機器學習模型的數據驅動方法最近已成為數值天氣預測模型的有希望的替代方案，原因在於它們有能力從歷史數據中擷取不同規模的物理現象，且在預測階段的運算成本顯著降低。Transformer模型以其在不同領域的先進效能而聞名，在機器學習天氣預測中也獲得歡迎。然而，將Transformer架構應用於天氣預測，特別是在全球規模上，由於注意力二次複雜度和空間點二次增加（隨著解析度增加），在運算上具有挑戰性。在這項工作中，我們提出一個針對球面幾何量身打造的分解注意力模型來減輕這個問題。更具體地說，它使用多維分解核，在不同軸上進行摺積，其中核的運算複雜度僅為軸向解析度的二次方，而不是整體解析度。所提出的模型在 1.5 度和 0-7 天預測時間的確定性預測準確度與最先進的純數據驅動機器學習天氣預測模型相當。我們也展示了所提出的模型在推進Transformer天氣模型的準確性效率帕雷托前緣方面具有很大的潛力，與基於標準注意力的Transformer模型相比，它可以在更低的運算成本下實現更高的準確度。

##### **AnyRotate: Gravity-Invariant In-Hand Object Rotation with Sim-to-Real Touch**
2405.07391v1 by Max Yang, Chenghua Lu, Alex Church, Yijiong Lin, Chris Ford, Haoran Li, Efi Psomopoulou, David A. W. Barton, Nathan F. Lepora

In-hand manipulation is an integral component of human dexterity. Our hands
rely on tactile feedback for stable and reactive motions to ensure objects do
not slip away unintentionally during manipulation. For a robot hand, this level
of dexterity requires extracting and utilizing rich contact information for
precise motor control. In this paper, we present AnyRotate, a system for
gravity-invariant multi-axis in-hand object rotation using dense featured
sim-to-real touch. We construct a continuous contact feature representation to
provide tactile feedback for training a policy in simulation and introduce an
approach to perform zero-shot policy transfer by training an observation model
to bridge the sim-to-real gap. Our experiments highlight the benefit of
detailed contact information when handling objects with varying properties. In
the real world, we demonstrate successful sim-to-real transfer of the dense
tactile policy, generalizing to a diverse range of objects for various rotation
axes and hand directions and outperforming other forms of low-dimensional
touch. Interestingly, despite not having explicit slip detection, rich
multi-fingered tactile sensing can implicitly detect object movement within
grasp and provide a reactive behavior that improves the robustness of the
policy, highlighting the importance of information-rich tactile sensing for
in-hand manipulation.

摘要：手部操作是人類靈巧性的組成部分。我們的雙手依賴觸覺回饋，才能確保物體在操作過程中不會意外滑落，並做出穩定且靈敏的動作。對於機器人手來說，這種靈巧性需要提取和利用豐富的接觸資訊，才能精準控制馬達。在本文中，我們提出 AnyRotate，這是一個利用密集特徵的模擬到真實觸覺進行重力不變多軸手部物件旋轉的系統。我們建構一個連續的接觸特徵表示，以提供觸覺回饋來訓練模擬中的策略，並提出一個透過訓練觀察模型來彌合模擬到真實差距的零次學習策略轉移方法。我們的實驗突顯了在處理具有不同性質的物件時，詳細接觸資訊的好處。在真實世界中，我們展示了密集觸覺策略的模擬到真實轉移成功，推廣到各種物件的不同旋轉軸和手部方向，並且優於其他形式的低維觸覺。有趣的是，儘管沒有明確的滑動偵測，豐富的多指觸覺感測仍可在抓握中隱含偵測物件移動，並提供反應行為，改善策略的穩健性，突顯了資訊豐富的觸覺感測對於手部操作的重要性。

##### **Conformalized Survival Distributions: A Generic Post-Process to Increase Calibration**
2405.07374v1 by Shi-ang Qi, Yakun Yu, Russell Greiner

Discrimination and calibration represent two important properties of survival
analysis, with the former assessing the model's ability to accurately rank
subjects and the latter evaluating the alignment of predicted outcomes with
actual events. With their distinct nature, it is hard for survival models to
simultaneously optimize both of them especially as many previous results found
improving calibration tends to diminish discrimination performance. This paper
introduces a novel approach utilizing conformal regression that can improve a
model's calibration without degrading discrimination. We provide theoretical
guarantees for the above claim, and rigorously validate the efficiency of our
approach across 11 real-world datasets, showcasing its practical applicability
and robustness in diverse scenarios.

摘要：辨別和校準代表生存分析的兩個重要屬性，前者評估模型準確排列受試者的能力，而後者評估預測結果與實際事件的一致性。由於其不同的性質，生存模型很難同時優化它們，特別是因為許多先前的結果發現改善校準往往會降低辨別效能。本文介紹了一種利用共形回歸的新方法，可以在不降低辨別力的情況下改善模型的校準。我們為上述說法提供了理論保證，並嚴格驗證了我們的方法在 11 個真實世界資料集中的效率，展示了其在不同場景中的實用性和穩健性。

##### **Probabilistic and Causal Satisfiability: the Impact of Marginalization**
2405.07373v1 by Julian Dörfler, Benito van der Zander, Markus Bläser, Maciej Liskiewicz

The framework of Pearl's Causal Hierarchy (PCH) formalizes three types of
reasoning: observational, interventional, and counterfactual, that reflect the
progressive sophistication of human thought regarding causation. We investigate
the computational complexity aspects of reasoning in this framework focusing
mainly on satisfiability problems expressed in probabilistic and causal
languages across the PCH. That is, given a system of formulas in the standard
probabilistic and causal languages, does there exist a model satisfying the
formulas? The resulting complexity changes depending on the level of the
hierarchy as well as the operators allowed in the formulas (addition,
multiplication, or marginalization).
  We focus on formulas involving marginalization that are widely used in
probabilistic and causal inference, but whose complexity issues are still
little explored. Our main contribution are the exact computational complexity
results showing that linear languages (allowing addition and marginalization)
yield NP^PP-, PSPACE-, and NEXP-complete satisfiability problems, depending on
the level of the PCH. Moreover, we prove that the problem for the full language
(allowing additionally multiplication) is complete for the class succ$\exists$R
for languages on the highest, counterfactual level. Previous work has shown
that the satisfiability problem is complete for succ$\exists$R on the lower
levels leaving the counterfactual case open. Finally, we consider constrained
models that are restricted to a small polynomial size. The constraint on the
size reduces the complexity of the interventional and counterfactual languages
to NEXP-complete.

摘要：珍珠因果層級（PCH）的框架形式化了三種類型的推理：觀察、介入和反事實，它們反映了人類對因果關係的思考的逐漸複雜化。我們研究了在這個框架中推理的計算複雜性方面，主要關注在 PCH 中用機率和因果語言表達的可滿足性問題。也就是說，給定標準機率和因果語言中的公式系統，是否存在滿足這些公式的模型？產生的複雜性會根據層級的等級以及公式中允許的運算子（加法、乘法或邊際化）而改變。
我們專注於涉及機率和因果推論中廣泛使用的邊際化的公式，但其複雜性問題仍鮮為人知。我們的貢獻主要是精確的計算複雜性結果，顯示線性語言（允許加法和邊際化）會產生 NP^PP-、PSPACE- 和 NEXP- 完全可滿足性問題，具體取決於 PCH 的層級。此外，我們證明了對於最高層的反事實層級上的語言，允許乘法的完整語言問題對於類別 succ$\exists$R 是完全的。先前的研究表明，可滿足性問題對於較低層級上的 succ$\exists$R 是完全的，而反事實情況則保持開放。最後，我們考慮受限於小多項式大小的受限模型。大小的限制將介入和反事實語言的複雜性降低到 NEXP- 完全。

##### **WeedScout: Real-Time Autonomous blackgrass Classification and Mapping using dedicated hardware**
2405.07349v1 by Matthew Gazzard, Helen Hicks, Isibor Kennedy Ihianle, Jordan J. Bird, Md Mahmudul Hasan, Pedro Machado

Blackgrass (Alopecurus myosuroides) is a competitive weed that has
wide-ranging impacts on food security by reducing crop yields and increasing
cultivation costs. In addition to the financial burden on agriculture, the
application of herbicides as a preventive to blackgrass can negatively affect
access to clean water and sanitation. The WeedScout project introduces a
Real-Rime Autonomous Black-Grass Classification and Mapping (RT-ABGCM), a
cutting-edge solution tailored for real-time detection of blackgrass, for
precision weed management practices. Leveraging Artificial Intelligence (AI)
algorithms, the system processes live image feeds, infers blackgrass density,
and covers two stages of maturation. The research investigates the deployment
of You Only Look Once (YOLO) models, specifically the streamlined YOLOv8 and
YOLO-NAS, accelerated at the edge with the NVIDIA Jetson Nano (NJN). By
optimising inference speed and model performance, the project advances the
integration of AI into agricultural practices, offering potential solutions to
challenges such as herbicide resistance and environmental impact. Additionally,
two datasets and model weights are made available to the research community,
facilitating further advancements in weed detection and precision farming
technologies.

摘要：黑草（Alopecurus myosuroides）是一種競爭力強的雜草，會透過降低作物產量和增加耕作成本對糧食安全造成廣泛影響。除了對農業造成財務負擔外，使用除草劑預防黑草也會對乾淨水和衛生造成負面影響。WeedScout 計畫引進即時自主黑草分類和繪製（RT-ABGCM），這是一個專為即時偵測黑草而量身打造的尖端解決方案，用於精準的雜草管理實務。系統利用人工智慧（AI）演算法處理即時影像串流，推論黑草密度，並涵蓋兩個成熟階段。這項研究探討僅看一次（YOLO）模型的部署，特別是精簡的 YOLOv8 和 YOLO-NAS，並在邊緣使用 NVIDIA Jetson Nano（NJN）加速。透過最佳化推論速度和模型效能，此計畫推動 AI 整合到農業實務中，提供對抗除草劑抗性和環境影響等挑戰的潛在解決方案。此外，兩個資料集和模型權重可供研究社群使用，促進雜草偵測和精準農業技術的進一步發展。

##### **MedConceptsQA: Open Source Medical Concepts QA Benchmark**
2405.07348v2 by Ofir Ben Shoham, Nadav Rappoport

We present MedConceptsQA, a dedicated open source benchmark for medical
concepts question answering. The benchmark comprises of questions of various
medical concepts across different vocabularies: diagnoses, procedures, and
drugs. The questions are categorized into three levels of difficulty: easy,
medium, and hard. We conducted evaluations of the benchmark using various Large
Language Models. Our findings show that pre-trained clinical Large Language
Models achieved accuracy levels close to random guessing on this benchmark,
despite being pre-trained on medical data. However, GPT-4 achieves an absolute
average improvement of nearly 27%-37% (27% for zero-shot learning and 37% for
few-shot learning) when compared to clinical Large Language Models. Our
benchmark serves as a valuable resource for evaluating the understanding and
reasoning of medical concepts by Large Language Models. Our benchmark is
available at https://huggingface.co/datasets/ofir408/MedConceptsQA

摘要：我們提出 MedConceptsQA，一個專門用於醫療概念問答的開放原始碼基準。基準包含不同詞彙中各種醫療概念的問題：診斷、程序和藥物。問題分為三個難度等級：容易、中等和困難。我們使用各種大型語言模型對基準進行了評估。我們的研究結果表明，儘管在醫療數據上進行預訓練，但預訓練的臨床大型語言模型在此基準上達到的準確度接近隨機猜測。然而，與臨床大型語言模型相比，GPT-4 在零次學習中獲得了近 27%-37% 的絕對平均改進，在少次學習中獲得了 37% 的改進。我們的基準作為一種有價值的資源，用於評估大型語言模型對醫療概念的理解和推理。我們的基準可在 https://huggingface.co/datasets/ofir408/MedConceptsQA 獲得

##### **TKAN: Temporal Kolmogorov-Arnold Networks**
2405.07344v1 by Remi Genet, Hugo Inzirillo

Recurrent Neural Networks (RNNs) have revolutionized many areas of machine
learning, particularly in natural language and data sequence processing. Long
Short-Term Memory (LSTM) has demonstrated its ability to capture long-term
dependencies in sequential data. Inspired by the Kolmogorov-Arnold Networks
(KANs) a promising alternatives to Multi-Layer Perceptrons (MLPs), we proposed
a new neural networks architecture inspired by KAN and the LSTM, the Temporal
Kolomogorov-Arnold Networks (TKANs). TKANs combined the strenght of both
networks, it is composed of Recurring Kolmogorov-Arnold Networks (RKANs) Layers
embedding memory management. This innovation enables us to perform multi-step
time series forecasting with enhanced accuracy and efficiency. By addressing
the limitations of traditional models in handling complex sequential patterns,
the TKAN architecture offers significant potential for advancements in fields
requiring more than one step ahead forecasting.

摘要：遞迴神經網路 (RNN) 已革新機器學習的許多領域，特別是在自然語言和資料序列處理方面。長期短期記憶 (LSTM) 已展現其擷取序列資料中長期依賴關係的能力。受 Kolmogorov-Arnold 網路 (KAN) 啟發，這是一種多層感知器 (MLP) 的有前途的替代方案，我們提出了一種新的神經網路架構，其靈感來自 KAN 和 LSTM，即時間 Kolomogorov-Arnold 網路 (TKAN)。TKAN 結合了這兩種網路的優點，它由嵌入記憶體管理的遞迴 Kolmogorov-Arnold 網路 (RKAN) 層組成。這項創新使我們能夠執行多步驟時間序列預測，並提高準確度和效率。透過解決傳統模型在處理複雜序列模式方面的限制，TKAN 架構為需要多步超前預測的領域提供了顯著的進步潛力。

##### **Liquid Ensemble Selection for Continual Learning**
2405.07327v1 by Carter Blair, Ben Armstrong, Kate Larson

Continual learning aims to enable machine learning models to continually
learn from a shifting data distribution without forgetting what has already
been learned. Such shifting distributions can be broken into disjoint subsets
of related examples; by training each member of an ensemble on a different
subset it is possible for the ensemble as a whole to achieve much higher
accuracy with less forgetting than a naive model. We address the problem of
selecting which models within an ensemble should learn on any given data, and
which should predict. By drawing on work from delegative voting we develop an
algorithm for using delegation to dynamically select which models in an
ensemble are active. We explore a variety of delegation methods and performance
metrics, ultimately finding that delegation is able to provide a significant
performance boost over naive learning in the face of distribution shifts.

摘要：持續學習旨在讓機器學習模型持續從變動的資料分佈中學習，而不會忘記已學到的內容。此類變動分佈可細分為相關範例的不相交子集；透過在不同子集上訓練合奏中的每個成員，合奏整體能以比樸素模型更少的遺忘達到更高的準確度。我們探討在合奏中哪些模型應該在任何特定資料上學習，以及哪些模型應該預測的問題。透過利用委派投票的成果，我們開發出一種演算法，用於使用委派動態選擇合奏中哪些模型為活躍狀態。我們探討了各種委派方法和效能指標，最終發現委派能夠在面臨分佈轉移時，提供顯著高於樸素學習的效能提升。

##### **L(u)PIN: LLM-based Political Ideology Nowcasting**
2405.07320v1 by Ken Kato, Annabelle Purnomo, Christopher Cochrane, Raeid Saqur

The quantitative analysis of political ideological positions is a difficult
task. In the past, various literature focused on parliamentary voting data of
politicians, party manifestos and parliamentary speech to estimate political
disagreement and polarization in various political systems. However previous
methods of quantitative political analysis suffered from a common challenge
which was the amount of data available for analysis. Also previous methods
frequently focused on a more general analysis of politics such as overall
polarization of the parliament or party-wide political ideological positions.
In this paper, we present a method to analyze ideological positions of
individual parliamentary representatives by leveraging the latent knowledge of
LLMs. The method allows us to evaluate the stance of politicians on an axis of
our choice allowing us to flexibly measure the stance of politicians in regards
to a topic/controversy of our choice. We achieve this by using a fine-tuned
BERT classifier to extract the opinion-based sentences from the speeches of
representatives and projecting the average BERT embeddings for each
representative on a pair of reference seeds. These reference seeds are either
manually chosen representatives known to have opposing views on a particular
topic or they are generated sentences which where created using the GPT-4 model
of OpenAI. We created the sentences by prompting the GPT-4 model to generate a
speech that would come from a politician defending a particular position.

摘要：政治意識形態立場的量化分析是一項艱難的任務。過去，各種文獻著重於政治人物的議會投票資料、政黨政綱和議會演說，以評估各種政治體系中的政治分歧和兩極分化。然而，先前的量化政治分析方法面臨一個共同的挑戰，即可用於分析的資料量。此外，先前的研究方法經常著重於政治的更一般性分析，例如議會的整體兩極分化或政黨範圍的政治意識形態立場。在本文中，我們提出了一種透過利用大型語言模型 (LLM) 的潛在知識來分析個別議會代表意識形態立場的方法。此方法讓我們得以在我們選擇的軸線上評估政治人物的立場，讓我們能夠靈活地衡量政治人物對我們選擇的主題/爭議的立場。我們透過使用微調過的 BERT 分類器從代表的演講中萃取出基於意見的句子，並將每個代表的平均 BERT 嵌入投影到一對參考種子上來達成此目的。這些參考種子可能是已知在特定主題上持有相反觀點的手動選擇代表，或者是由 OpenAI 的 GPT-4 模型所產生的句子。我們透過提示 GPT-4 模型產生一個演講，該演講來自於捍衛特定立場的政治人物，來產生這些句子。

##### **Machine Unlearning in Contrastive Learning**
2405.07317v1 by Zixin Wang, Kongyang Chen

Machine unlearning is a complex process that necessitates the model to
diminish the influence of the training data while keeping the loss of accuracy
to a minimum. Despite the numerous studies on machine unlearning in recent
years, the majority of them have primarily focused on supervised learning
models, leaving research on contrastive learning models relatively
underexplored. With the conviction that self-supervised learning harbors a
promising potential, surpassing or rivaling that of supervised learning, we set
out to investigate methods for machine unlearning centered around contrastive
learning models. In this study, we introduce a novel gradient constraint-based
approach for training the model to effectively achieve machine unlearning. Our
method only necessitates a minimal number of training epochs and the
identification of the data slated for unlearning. Remarkably, our approach
demonstrates proficient performance not only on contrastive learning models but
also on supervised learning models, showcasing its versatility and adaptability
in various learning paradigms.

摘要：機器去學習是一個複雜的過程，需要模型在保持準確度損失最小化的同時，減少訓練資料的影響。儘管近年來機器去學習的研究很多，但大多數研究主要集中在監督式學習模型上，而對比學習模型的研究相對較少。我們確信自監督學習具有超越或匹敵監督學習的潛力，因此我們著手研究以對比學習模型為中心的機器去學習方法。在本研究中，我們引入了一種新的基於梯度約束的方法，用於訓練模型以有效實現機器去學習。我們的模型僅需要最少的訓練輪次和對需要去學習的資料進行識別。值得注意的是，我們的模型不僅在對比學習模型上展示了熟練的效能，而且在監督式學習模型上也表現出色，展示了其在各種學習範例中的多功能性和適應性。

##### **DiffGen: Robot Demonstration Generation via Differentiable Physics Simulation, Differentiable Rendering, and Vision-Language Model**
2405.07309v1 by Yang Jin, Jun Lv, Shuqiang Jiang, Cewu Lu

Generating robot demonstrations through simulation is widely recognized as an
effective way to scale up robot data. Previous work often trained reinforcement
learning agents to generate expert policies, but this approach lacks sample
efficiency. Recently, a line of work has attempted to generate robot
demonstrations via differentiable simulation, which is promising but heavily
relies on reward design, a labor-intensive process. In this paper, we propose
DiffGen, a novel framework that integrates differentiable physics simulation,
differentiable rendering, and a vision-language model to enable automatic and
efficient generation of robot demonstrations. Given a simulated robot
manipulation scenario and a natural language instruction, DiffGen can generate
realistic robot demonstrations by minimizing the distance between the embedding
of the language instruction and the embedding of the simulated observation
after manipulation. The embeddings are obtained from the vision-language model,
and the optimization is achieved by calculating and descending gradients
through the differentiable simulation, differentiable rendering, and
vision-language model components, thereby accomplishing the specified task.
Experiments demonstrate that with DiffGen, we could efficiently and effectively
generate robot data with minimal human effort or training time.

摘要：透過模擬產生機器人示範操作，被廣泛認為是擴充機器人資料的有效方法。先前的研究，通常訓練強化學習代理產生專家策略，但這種方法缺乏樣本效率。最近，有條研究路線試圖透過可微分模擬產生機器人示範操作，這很有前景，但極度依賴於回報設計，這是一個勞力密集的過程。在本文中，我們提出 DiffGen，一個整合可微分物理模擬、可微分渲染和視覺語言模型的新框架，用於自動且有效地產生機器人示範操作。給定一個模擬機器人操作場景和一個自然語言指令，DiffGen 能夠透過最小化操作後語言指令的嵌入式與模擬觀察的嵌入式之間的距離，產生逼真的機器人示範操作。這些嵌入式從視覺語言模型取得，而最佳化則透過計算和下降可微分模擬、可微分渲染和視覺語言模型元件的梯度來達成，從而完成指定任務。實驗證明，透過 DiffGen，我們能夠有效率且有效地產生機器人資料，並將人力或訓練時間降至最低。

##### **Environmental enrichment: a biological model of forward transfer in continual learning**
2405.07295v1 by Rajat Saxena, Bruce L. McNaughton

Continual learning (CL) refers to an agent's capability to learn from a
continuous stream of data and transfer knowledge without forgetting old
information. One crucial aspect of CL is forward transfer, i.e., improved and
faster learning on a new task by leveraging information from prior knowledge.
While this ability comes naturally to biological brains, it poses a significant
challenge for artificial intelligence (AI). Here, we suggest that environmental
enrichment (EE) can be used as a biological model for studying forward
transfer, inspiring human-like AI development. EE refers to animal studies that
enhance cognitive, social, motor, and sensory stimulation and is a model for
what, in humans, is referred to as 'cognitive reserve'. Enriched animals show
significant improvement in learning speed and performance on new tasks,
typically exhibiting forward transfer. We explore anatomical, molecular, and
neuronal changes post-EE and discuss how artificial neural networks (ANNs) can
be used to predict neural computation changes after enriched experiences.
Finally, we provide a synergistic way of combining neuroscience and AI research
that paves the path toward developing AI capable of rapid and efficient new
task learning.

摘要：持續學習（CL）指的是代理人從資料連續串流中學習並傳遞知識而不遺忘舊資訊的能力。CL 的一個關鍵面向是正向傳遞，亦即透過運用先前知識中的資訊，在新的任務中提升且加速學習。雖然這種能力對生物大腦來說是天生的，但對人工智慧（AI）來說卻是一項重大的挑戰。在此，我們建議環境豐富化（EE）可用作研究正向傳遞的生物模型，激發類人 AI 的發展。EE 指的是增強動物認知、社交、運動和感官刺激的動物研究，是人類所謂「認知儲備」的模型。經過豐富化的動物在學習速度和新任務的表現上都有顯著的進步，通常展現出正向傳遞。我們探討 EE 後的解剖、分子和神經元變化，並討論如何使用人工神經網路（ANN）來預測豐富化體驗後的類神經運算變化。最後，我們提供一種結合神經科學和 AI 研究的綜效方式，為開發具備快速且有效率的新任務學習能力的 AI 鋪路。

##### **Sparse Sampling is All You Need for Fast Wrong-way Cycling Detection in CCTV Videos**
2405.07293v1 by Jing Xu, Wentao Shi, Sheng Ren, Pan Gao, Peng Zhou, Jie Qin

In the field of transportation, it is of paramount importance to address and
mitigate illegal actions committed by both motor and non-motor vehicles. Among
those actions, wrong-way cycling (i.e., riding a bicycle or e-bike in the
opposite direction of the designated traffic flow) poses significant risks to
both cyclists and other road users. To this end, this paper formulates a
problem of detecting wrong-way cycling ratios in CCTV videos. Specifically, we
propose a sparse sampling method called WWC-Predictor to efficiently solve this
problem, addressing the inefficiencies of direct tracking methods. Our approach
leverages both detection-based information, which utilizes the information from
bounding boxes, and orientation-based information, which provides insights into
the image itself, to enhance instantaneous information capture capability. On
our proposed benchmark dataset consisting of 35 minutes of video sequences and
minute-level annotation, our method achieves an average error rate of a mere
1.475% while taking only 19.12% GPU time of straightforward tracking methods
under the same detection model. This remarkable performance demonstrates the
effectiveness of our approach in identifying and predicting instances of
wrong-way cycling.

摘要：在交通领域，解决和减轻机动车和非机动车实施的违法行为至关重要。在这些行为中，逆向骑行（即在指定交通流的相反方向骑自行车或电动自行车）对骑行者和其他道路使用者构成重大风险。为此，本文提出了一个在闭路电视视频中检测逆向骑行比率的问题。具体来说，我们提出了一种称为 WWC-Predictor 的稀疏采样方法来有效解决这个问题，解决了直接跟踪方法的低效率问题。我们的方法利用了基于检测的信息（利用边界框中的信息）和基于方向的信息（提供对图像本身的见解），以增强瞬时信息捕获能力。在我们提出的基准数据集（包括 35 分钟的视频序列和分钟级注释）上，我们的方法在相同检测模型下仅占用直接跟踪方法的 19.12% GPU 时间，平均错误率仅为 1.475%。这一非凡的性能证明了我们的方法在识别和预测逆向骑行实例方面的有效性。

##### **Branching Narratives: Character Decision Points Detection**
2405.07282v1 by Alexey Tikhonov

This paper presents the Character Decision Points Detection (CHADPOD) task, a
task of identification of points within narratives where characters make
decisions that may significantly influence the story's direction. We propose a
novel dataset based on CYOA-like games graphs to be used as a benchmark for
such a task. We provide a comparative analysis of different models' performance
on this task, including a couple of LLMs and several MLMs as baselines,
achieving up to 89% accuracy. This underscores the complexity of narrative
analysis, showing the challenges associated with understanding character-driven
story dynamics. Additionally, we show how such a model can be applied to the
existing text to produce linear segments divided by potential branching points,
demonstrating the practical application of our findings in narrative analysis.

摘要：本文提出角色決策點偵測 (CHADPOD) 任務，此任務為在敘事中識別角色做出可能顯著影響故事走向的決策之點。我們提出一個基於類似選擇你自己的冒險 (CYOA) 遊戲圖表的創新資料集，可用作此類任務的基準。我們提供不同模型在這個任務上的效能比較分析，包括幾個 LLM 和幾個 MLM 作為基準，準確率高達 89%。這強調了敘事分析的複雜性，顯示出理解角色驅動的故事動態所面臨的挑戰。此外，我們展示如何將此類模型應用於現有文字，以產生由潛在分支點劃分的線性區段，證明我們的研究結果在敘事分析中的實際應用。

##### **Human-interpretable clustering of short-text using large language models**
2405.07278v1 by Justin K. Miller, Tristram J. Alexander

Large language models have seen extraordinary growth in popularity due to
their human-like content generation capabilities. We show that these models can
also be used to successfully cluster human-generated content, with success
defined through the measures of distinctiveness and interpretability. This
success is validated by both human reviewers and ChatGPT, providing an
automated means to close the 'validation gap' that has challenged short-text
clustering. Comparing the machine and human approaches we identify the biases
inherent in each, and question the reliance on human-coding as the 'gold
standard'. We apply our methodology to Twitter bios and find characteristic
ways humans describe themselves, agreeing well with prior specialist work, but
with interesting differences characteristic of the medium used to express
identity.

摘要：大型語言模型因其類似人類的內容生成能力而獲得極大的普及。我們展示這些模型也可以用於成功地分類人類產生的內容，而成功則通過獨特性和可解釋性的指標來定義。這種成功得到了人類審閱者和 ChatGPT 的驗證，提供了一種自動化的方法來彌補挑戰短文本分類的「驗證差距」。比較機器和人類的方法，我們找出每種方法固有的偏差，並質疑依賴人類編碼作為「黃金標準」。我們將方法應用於 Twitter 個人簡介，並找出人類描述自己的特徵方式，與先前的專業工作非常吻合，但與用於表達身分的媒體特徵有有趣的差異。

##### **MAML MOT: Multiple Object Tracking based on Meta-Learning**
2405.07272v1 by Jiayi Chen, Chunhua Deng

With the advancement of video analysis technology, the multi-object tracking
(MOT) problem in complex scenes involving pedestrians is gaining increasing
importance. This challenge primarily involves two key tasks: pedestrian
detection and re-identification. While significant progress has been achieved
in pedestrian detection tasks in recent years, enhancing the effectiveness of
re-identification tasks remains a persistent challenge. This difficulty arises
from the large total number of pedestrian samples in multi-object tracking
datasets and the scarcity of individual instance samples. Motivated by recent
rapid advancements in meta-learning techniques, we introduce MAML MOT, a
meta-learning-based training approach for multi-object tracking. This approach
leverages the rapid learning capability of meta-learning to tackle the issue of
sample scarcity in pedestrian re-identification tasks, aiming to improve the
model's generalization performance and robustness. Experimental results
demonstrate that the proposed method achieves high accuracy on mainstream
datasets in the MOT Challenge. This offers new perspectives and solutions for
research in the field of pedestrian multi-object tracking.

摘要：随着影像分析技术的进步，涉及行人的复杂场景中的多目标追踪
(MOT) 问题正变得越来越重要。这个挑战主要涉及两项关键任务：行人
检测和重新识别。虽然近年来行人检测任务取得了重大进展，但提高
重新识别任务的有效性仍然是一个持续的挑战。这种困难源于多目标追踪
数据集中的行人样本总数庞大，而单个实例样本稀少。受元学习技术
最近的快速发展启发，我们引入了 MAML MOT，一种基于元学习的用于
多目标追踪的训练方法。这种方法利用元学习的快速学习能力来解决
行人重新识别任务中样本稀缺的问题，旨在提高模型的泛化性能和稳健
性。实验结果表明，所提出的方法在 MOT 挑战中的主流数据集上实现了
很高的准确性。这为行人多目标追踪领域的研究提供了新的视角和解决
方案。

##### **A Supervised Information Enhanced Multi-Granularity Contrastive Learning Framework for EEG Based Emotion Recognition**
2405.07260v1 by Xiang Li, Jian Song, Zhigang Zhao, Chunxiao Wang, Dawei Song, Bin Hu

This study introduces a novel Supervised Info-enhanced Contrastive Learning
framework for EEG based Emotion Recognition (SICLEER). SI-CLEER employs
multi-granularity contrastive learning to create robust EEG contextual
representations, potentiallyn improving emotion recognition effectiveness.
Unlike existing methods solely guided by classification loss, we propose a
joint learning model combining self-supervised contrastive learning loss and
supervised classification loss. This model optimizes both loss functions,
capturing subtle EEG signal differences specific to emotion detection.
Extensive experiments demonstrate SI-CLEER's robustness and superior accuracy
on the SEED dataset compared to state-of-the-art methods. Furthermore, we
analyze electrode performance, highlighting the significance of central frontal
and temporal brain region EEGs in emotion detection. This study offers an
universally applicable approach with potential benefits for diverse EEG
classification tasks.

摘要：本研究提出一個創新的基於 EEG 的情緒辨識監督式資訊增強對比學習框架（SICLEER）。SI-CLEER 使用多粒度對比學習來建立強健的 EEG 背景表徵，潛在地提升情緒辨識的有效性。與僅由分類損失引導的現有方法不同，我們提出一個結合自我監督式對比學習損失和監督式分類損失的聯合學習模型。此模型最佳化兩個損失函數，擷取特定於情緒偵測的細微 EEG 訊號差異。廣泛的實驗證明，與最先進的方法相比，SI-CLEER 在 SEED 資料集上具有強健性和優異的準確度。此外，我們分析電極效能，強調中央額葉和顳葉腦區 EEG 在情緒偵測中的重要性。本研究提供一個普遍適用的方法，對於各種 EEG 分類任務具有潛在的好處。

##### **Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis**
2405.07248v1 by Nikolay B Petrov, Gregory Serapio-García, Jason Rentfrow

The humanlike responses of large language models (LLMs) have prompted social
scientists to investigate whether LLMs can be used to simulate human
participants in experiments, opinion polls and surveys. Of central interest in
this line of research has been mapping out the psychological profiles of LLMs
by prompting them to respond to standardized questionnaires. The conflicting
findings of this research are unsurprising given that mapping out underlying,
or latent, traits from LLMs' text responses to questionnaires is no easy task.
To address this, we use psychometrics, the science of psychological
measurement. In this study, we prompt OpenAI's flagship models, GPT-3.5 and
GPT-4, to assume different personas and respond to a range of standardized
measures of personality constructs. We used two kinds of persona descriptions:
either generic (four or five random person descriptions) or specific (mostly
demographics of actual humans from a large-scale human dataset). We found that
the responses from GPT-4, but not GPT-3.5, using generic persona descriptions
show promising, albeit not perfect, psychometric properties, similar to human
norms, but the data from both LLMs when using specific demographic profiles,
show poor psychometrics properties. We conclude that, currently, when LLMs are
asked to simulate silicon personas, their responses are poor signals of
potentially underlying latent traits. Thus, our work casts doubt on LLMs'
ability to simulate individual-level human behaviour across multiple-choice
question answering tasks.

摘要：大型語言模型 (LLM) 的類人反應促使社會科學家探討 LLM 是否可用於模擬人類參與者進行實驗、民意調查和問卷調查。這條研究路線的重點是透過提示 LLM 回應標準化問卷，來描繪 LLM 的心理特徵。這項研究的相互矛盾的發現不足為奇，因為從 LLM 對問卷的文字回應中描繪出潛在特質並非易事。為了解決這個問題，我們使用了心理測量學，這是心理測量的科學。在這項研究中，我們提示 OpenAI 的旗艦模型 GPT-3.5 和 GPT-4 扮演不同的角色，並回應一系列標準化的人格結構測量。我們使用了兩種角色描述：通用（四或五個隨機人物描述）或具體（主要是來自大規模人類資料集的實際人類人口統計資料）。我們發現，GPT-4 的回應（但 GPT-3.5 沒有）使用通用角色描述顯示出有希望的，儘管不完美的心理測量屬性，類似於人類常態，但當使用特定人口統計特徵時，來自這兩個 LLM 的資料顯示出不佳的心理測量屬性。我們得出的結論是，目前，當要求 LLM 模擬矽晶角色時，他們的回應對於潛在的潛在特質而言是微弱的訊號。因此，我們的研究對 LLM 模擬多選題回答任務中的個人層級人類行為的能力提出質疑。

##### **OXYGENERATOR: Reconstructing Global Ocean Deoxygenation Over a Century with Deep Learning**
2405.07233v1 by Bin Lu, Ze Zhao, Luyu Han, Xiaoying Gan, Yuntao Zhou, Lei Zhou, Luoyi Fu, Xinbing Wang, Chenghu Zhou, Jing Zhang

Accurately reconstructing the global ocean deoxygenation over a century is
crucial for assessing and protecting marine ecosystem. Existing
expert-dominated numerical simulations fail to catch up with the dynamic
variation caused by global warming and human activities. Besides, due to the
high-cost data collection, the historical observations are severely sparse,
leading to big challenge for precise reconstruction. In this work, we propose
OxyGenerator, the first deep learning based model, to reconstruct the global
ocean deoxygenation from 1920 to 2023. Specifically, to address the
heterogeneity across large temporal and spatial scales, we propose
zoning-varying graph message-passing to capture the complex oceanographic
correlations between missing values and sparse observations. Additionally, to
further calibrate the uncertainty, we incorporate inductive bias from dissolved
oxygen (DO) variations and chemical effects. Compared with in-situ DO
observations, OxyGenerator significantly outperforms CMIP6 numerical
simulations, reducing MAPE by 38.77%, demonstrating a promising potential to
understand the "breathless ocean" in data-driven manner.

摘要：<paragraph>準確重建一個世紀以來的全球海洋脫氧對於評估和保護海洋生態系統至關重要。現有的專家主導數值模擬無法趕上全球暖化和人類活動造成的動態變化。此外，由於高成本的資料收集，歷史觀測嚴重稀疏，導致精確重建面臨巨大挑戰。在這項工作中，我們提出了 OxyGenerator，這是第一個基於深度學習的模型，用於重建 1920 年至 2023 年的全球海洋脫氧。具體來說，為了解決大時間和空間尺度上的異質性，我們提出了分區變化的圖形訊息傳遞，以捕捉缺失值和稀疏觀測之間複雜的海洋學相關性。此外，為了進一步校準不確定性，我們納入了溶解氧 (DO) 變化和化學效應的歸納偏差。與現場 DO 觀測相比，OxyGenerator 明顯優於 CMIP6 數值模擬，將 MAPE 降低了 38.77%，展示了以資料驅動方式理解「無呼吸海洋」的潛力。</paragraph>

##### **Separable Power of Classical and Quantum Learning Protocols Through the Lens of No-Free-Lunch Theorem**
2405.07226v1 by Xinbiao Wang, Yuxuan Du, Kecheng Liu, Yong Luo, Bo Du, Dacheng Tao

The No-Free-Lunch (NFL) theorem, which quantifies problem- and
data-independent generalization errors regardless of the optimization process,
provides a foundational framework for comprehending diverse learning protocols'
potential. Despite its significance, the establishment of the NFL theorem for
quantum machine learning models remains largely unexplored, thereby overlooking
broader insights into the fundamental relationship between quantum and
classical learning protocols. To address this gap, we categorize a diverse
array of quantum learning algorithms into three learning protocols designed for
learning quantum dynamics under a specified observable and establish their NFL
theorem. The exploited protocols, namely Classical Learning Protocols
(CLC-LPs), Restricted Quantum Learning Protocols (ReQu-LPs), and Quantum
Learning Protocols (Qu-LPs), offer varying levels of access to quantum
resources. Our derived NFL theorems demonstrate quadratic reductions in sample
complexity across CLC-LPs, ReQu-LPs, and Qu-LPs, contingent upon the
orthogonality of quantum states and the diagonality of observables. We
attribute this performance discrepancy to the unique capacity of
quantum-related learning protocols to indirectly utilize information concerning
the global phases of non-orthogonal quantum states, a distinctive physical
feature inherent in quantum mechanics. Our findings not only deepen our
understanding of quantum learning protocols' capabilities but also provide
practical insights for the development of advanced quantum learning algorithms.

摘要：無免費午餐（NFL）定理量化問題和資料無關的概化誤差，而不論最佳化處理，提供一個基礎架構來理解不同的學習協定的潛力。儘管它的重要性，對於量子機器學習模型的 NFL 定理建立仍然在很大程度上未經探索，因此忽略了對量子和經典學習協定之間基本關係的更廣泛見解。為了解決這個差距，我們將各種量子學習演算法分類為三個學習協定，這些協定旨在學習在特定可觀察量下的量子動力學，並建立其 NFL 定理。所利用的協定，即經典學習協定 (CLC-LP)、受限量子學習協定 (ReQu-LP) 和量子學習協定 (Qu-LP)，提供不同層級的量子資源存取。我們推導出的 NFL 定理顯示，在 CLC-LP、ReQu-LP 和 Qu-LP 中，樣本複雜度會以二次方式降低，這取決於量子態的正交性和可觀察量的對角性。我們將這種效能差異歸因於與量子相關的學習協定獨特的能力，可以間接利用有關非正交量子態的全局相位的資訊，這是量子力學中固有的獨特物理特徵。我們的發現不僅加深了我們對量子學習協定能力的理解，也為先進量子學習演算法的開發提供了實用的見解。

##### **On Discovery of Local Independence over Continuous Variables via Neural Contextual Decomposition**
2405.07220v1 by Inwoo Hwang, Yunhyeok Kwak, Yeon-Ji Song, Byoung-Tak Zhang, Sanghack Lee

Conditional independence provides a way to understand causal relationships
among the variables of interest. An underlying system may exhibit more
fine-grained causal relationships especially between a variable and its
parents, which will be called the local independence relationships. One of the
most widely studied local relationships is Context-Specific Independence (CSI),
which holds in a specific assignment of conditioned variables. However, its
applicability is often limited since it does not allow continuous variables:
data conditioned to the specific value of a continuous variable contains few
instances, if not none, making it infeasible to test independence. In this
work, we define and characterize the local independence relationship that holds
in a specific set of joint assignments of parental variables, which we call
context-set specific independence (CSSI). We then provide a canonical
representation of CSSI and prove its fundamental properties. Based on our
theoretical findings, we cast the problem of discovering multiple CSSI
relationships in a system as finding a partition of the joint outcome space.
Finally, we propose a novel method, coined neural contextual decomposition
(NCD), which learns such partition by imposing each set to induce CSSI via
modeling a conditional distribution. We empirically demonstrate that the
proposed method successfully discovers the ground truth local independence
relationships in both synthetic dataset and complex system reflecting the
real-world physical dynamics.

摘要：條件獨立性提供了一種了解興趣變數之間因果關係的方法。基礎系統可能展現出更細緻的因果關係，特別是在變數及其父節點之間，這將稱為局部獨立性關係。其中研究最廣泛的局部關係是情境特定獨立性 (CSI)，它存在於條件變數的特定指派中。然而，它的適用性通常受到限制，因為它不允許連續變數：條件化為連續變數特定值的資料包含很少的實例（如果不是沒有的話），這使得測試獨立性變得不可行。在這項工作中，我們定義並描述了在父變數的特定聯合指派集中成立的局部獨立性關係，我們稱之為情境集特定獨立性 (CSSI)。然後，我們提供 CSSI 的規範表示法並證明其基本屬性。根據我們的理論發現，我們將發現系統中多個 CSSI 關係的問題視為尋找聯合結果空間的分割。最後，我們提出了一種新方法，稱為神經脈絡分解 (NCD)，它透過建立條件分佈來強迫每個集合誘導 CSSI，從而學習這種分割。我們實證證明，所提出的方法成功地發現了合成資料集和反映真實世界物理動態的複雜系統中的真實局部獨立性關係。

##### **Enhancing Decision-Making in Optimization through LLM-Assisted Inference: A Neural Networks Perspective**
2405.07212v1 by Gaurav Singh, Kavitesh Kumar Bali

This paper explores the seamless integration of Generative AI (GenAI) and
Evolutionary Algorithms (EAs) within the domain of large-scale multi-objective
optimization. Focusing on the transformative role of Large Language Models
(LLMs), our study investigates the potential of LLM-Assisted Inference to
automate and enhance decision-making processes. Specifically, we highlight its
effectiveness in illuminating key decision variables in evolutionarily
optimized solutions while articulating contextual trade-offs. Tailored to
address the challenges inherent in inferring complex multi-objective
optimization solutions at scale, our approach emphasizes the adaptive nature of
LLMs, allowing them to provide nuanced explanations and align their language
with diverse stakeholder expertise levels and domain preferences. Empirical
studies underscore the practical applicability and impact of LLM-Assisted
Inference in real-world decision-making scenarios.

摘要：本文探討生成式 AI (GenAI) 和演化演算法 (EA) 在大規模多目標最佳化領域中的無縫整合。專注於大型語言模型 (LLM) 的轉型角色，我們的研究探討 LLM 輔助推論的潛力，以自動化和增強決策制定過程。具體而言，我們強調其在照亮演化最佳化解決方案中的關鍵決策變數，同時闡述情境折衷的有效性。為了應對大規模推論複雜的多目標最佳化解決方案所固有的挑戰，我們的做法強調 LLM 的適應性，讓它們能夠提供細緻的解釋，並將其語言與不同的利害關係人專業知識層級和領域偏好保持一致。實證研究強調 LLM 輔助推論在現實世界的決策制定情境中的實用適用性和影響力。

