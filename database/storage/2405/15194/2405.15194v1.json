{"2405.15194": {"publish_time": "2024-05-24", "title": "Efficient Reinforcement Learning via Large Language Model-based Search", "paper_summary": "Reinforcement Learning (RL) suffers from sample inefficiency in sparse reward\ndomains, and the problem is pronounced if there are stochastic transitions. To\nimprove the sample efficiency, reward shaping is a well-studied approach to\nintroduce intrinsic rewards that can help the RL agent converge to an optimal\npolicy faster. However, designing a useful reward shaping function specific to\neach problem is challenging, even for domain experts. They would either have to\nrely on task-specific domain knowledge or provide an expert demonstration\nindependently for each task. Given, that Large Language Models (LLMs) have\nrapidly gained prominence across a magnitude of natural language tasks, we aim\nto answer the following question: Can we leverage LLMs to construct a reward\nshaping function that can boost the sample efficiency of an RL agent? In this\nwork, we aim to leverage off-the-shelf LLMs to generate a guide policy by\nsolving a simpler deterministic abstraction of the original problem that can\nthen be used to construct the reward shaping function for the downstream RL\nagent. Given the ineffectiveness of directly prompting LLMs, we propose MEDIC:\na framework that augments LLMs with a Model-based feEDback critIC, which\nverifies LLM-generated outputs, to generate a possibly sub-optimal but valid\nplan for the abstract problem. Our experiments across domains from the BabyAI\nenvironment suite show 1) the effectiveness of augmenting LLMs with MEDIC, 2) a\nsignificant improvement in the sample complexity of PPO and A2C-based RL agents\nwhen guided by our LLM-generated plan, and finally, 3) pave the direction for\nfurther explorations of how these models can be used to augment existing RL\npipelines.", "paper_summary_zh": "<paragraph>\u5f37\u5316\u5b78\u7fd2 (RL) \u5728\u7a00\u758f\u734e\u52f5\u9818\u57df\u4e2d\u6703\u9047\u5230\u6a23\u672c\u6548\u7387\u4f4e\u4e0b\u7684\u554f\u984c\uff0c\u800c\u5982\u679c\u5b58\u5728\u96a8\u6a5f\u8f49\u63db\uff0c\u5247\u554f\u984c\u6703\u66f4\u52a0\u56b4\u91cd\u3002\u70ba\u4e86\u63d0\u9ad8\u6a23\u672c\u6548\u7387\uff0c\u734e\u52f5\u6210\u5f62\u662f\u4e00\u7a2e\u7d93\u904e\u5145\u5206\u7814\u7a76\u7684\u65b9\u6cd5\uff0c\u7528\u65bc\u5f15\u5165\u5167\u5728\u734e\u52f5\uff0c\u53ef\u4ee5\u5e6b\u52a9 RL \u4ee3\u7406\u66f4\u5feb\u5730\u6536\u6582\u5230\u6700\u4f73\u7b56\u7565\u3002\u7136\u800c\uff0c\u91dd\u5c0d\u6bcf\u500b\u554f\u984c\u8a2d\u8a08\u4e00\u500b\u6709\u7528\u7684\u734e\u52f5\u6210\u5f62\u51fd\u6578\u662f\u4e00\u9805\u6311\u6230\uff0c\u5373\u4f7f\u5c0d\u65bc\u9818\u57df\u5c08\u5bb6\u800c\u8a00\u4e5f\u662f\u5982\u6b64\u3002\u4ed6\u5011\u5fc5\u9808\u4f9d\u8cf4\u7279\u5b9a\u65bc\u4efb\u52d9\u7684\u9818\u57df\u77e5\u8b58\uff0c\u6216\u8005\u70ba\u6bcf\u500b\u4efb\u52d9\u7368\u7acb\u63d0\u4f9b\u5c08\u5bb6\u793a\u7bc4\u3002\u9451\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u8fc5\u901f\u5728\u5927\u91cf\u81ea\u7136\u8a9e\u8a00\u4efb\u52d9\u4e2d\u7372\u5f97\u7a81\u51fa\u5730\u4f4d\uff0c\u6211\u5011\u65e8\u5728\u56de\u7b54\u4ee5\u4e0b\u554f\u984c\uff1a\u6211\u5011\u80fd\u5229\u7528 LLM \u4f86\u5efa\u69cb\u4e00\u500b\u734e\u52f5\u6210\u5f62\u51fd\u6578\uff0c\u5f9e\u800c\u63d0\u5347 RL \u4ee3\u7406\u7684\u6a23\u672c\u6548\u7387\u55ce\uff1f\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u65e8\u5728\u5229\u7528\u73fe\u6210\u7684 LLM\uff0c\u900f\u904e\u89e3\u6c7a\u539f\u59cb\u554f\u984c\u7684\u4e00\u500b\u66f4\u7c21\u55ae\u7684\u78ba\u5b9a\u6027\u62bd\u8c61\u4f86\u7522\u751f\u4e00\u500b\u5f15\u5c0e\u7b56\u7565\uff0c\u7136\u5f8c\u53ef\u4ee5\u7528\u5b83\u4f86\u70ba\u4e0b\u6e38 RL \u4ee3\u7406\u5efa\u69cb\u734e\u52f5\u6210\u5f62\u51fd\u6578\u3002\u9451\u65bc\u76f4\u63a5\u63d0\u793a LLM \u7684\u7121\u6548\u6027\uff0c\u6211\u5011\u63d0\u51fa\u4e86 MEDIC\uff1a\u4e00\u500b\u4f7f\u7528\u57fa\u65bc\u6a21\u578b\u7684\u56de\u994b\u6279\u8a55\u5668\u4f86\u64f4\u5145 LLM \u7684\u6846\u67b6\uff0c\u5b83\u6703\u9a57\u8b49 LLM \u7522\u751f\u7684\u8f38\u51fa\uff0c\u4ee5\u7522\u751f\u4e00\u500b\u53ef\u80fd\u6b21\u65bc\u6700\u4f73\u4f46\u6709\u6548\u7684\u62bd\u8c61\u554f\u984c\u8a08\u756b\u3002\u6211\u5011\u5728 BabyAI \u74b0\u5883\u5957\u4ef6\u4e2d\u8de8\u9818\u57df\u9032\u884c\u7684\u5be6\u9a57\u986f\u793a 1) \u4f7f\u7528 MEDIC \u64f4\u5145 LLM \u7684\u6709\u6548\u6027\uff0c2) \u5728\u7531\u6211\u5011\u7684 LLM \u7522\u751f\u7684\u8a08\u756b\u5f15\u5c0e\u4e0b\uff0c\u57fa\u65bc PPO \u548c A2C \u7684 RL \u4ee3\u7406\u7684\u6a23\u672c\u8907\u96dc\u5ea6\u6709\u986f\u8457\u6539\u5584\uff0c\u6700\u5f8c\uff0c3) \u70ba\u9032\u4e00\u6b65\u63a2\u7d22\u5982\u4f55\u4f7f\u7528\u9019\u4e9b\u6a21\u578b\u4f86\u64f4\u5145\u73fe\u6709\u7684 RL \u7ba1\u7dda\u92ea\u5e73\u4e86\u9053\u8def\u3002</paragraph>", "author": "Siddhant Bhambri et.al.", "authors": "Siddhant Bhambri, Amrita Bhattacharjee, Huan Liu, Subbarao Kambhampati", "id": "2405.15194v1", "paper_url": "http://arxiv.org/abs/2405.15194v1", "repo": "null"}}