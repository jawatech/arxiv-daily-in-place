{"2406.15966": {"publish_time": "2024-06-23", "title": "Evaluating the Effectiveness of the Foundational Models for Q&A Classification in Mental Health care", "paper_summary": "Pre-trained Language Models (PLMs) have the potential to transform mental\nhealth support by providing accessible and culturally sensitive resources.\nHowever, despite this potential, their effectiveness in mental health care and\nspecifically for the Arabic language has not been extensively explored. To\nbridge this gap, this study evaluates the effectiveness of foundational models\nfor classification of Questions and Answers (Q&A) in the domain of mental\nhealth care. We leverage the MentalQA dataset, an Arabic collection featuring\nQ&A interactions related to mental health. In this study, we conducted\nexperiments using four different types of learning approaches: traditional\nfeature extraction, PLMs as feature extractors, Fine-tuning PLMs and prompting\nlarge language models (GPT-3.5 and GPT-4) in zero-shot and few-shot learning\nsettings. While traditional feature extractors combined with Support Vector\nMachines (SVM) showed promising performance, PLMs exhibited even better results\ndue to their ability to capture semantic meaning. For example, MARBERT achieved\nthe highest performance with a Jaccard Score of 0.80 for question\nclassification and a Jaccard Score of 0.86 for answer classification. We\nfurther conducted an in-depth analysis including examining the effects of\nfine-tuning versus non-fine-tuning, the impact of varying data size, and\nconducting error analysis. Our analysis demonstrates that fine-tuning proved to\nbe beneficial for enhancing the performance of PLMs, and the size of the\ntraining data played a crucial role in achieving high performance. We also\nexplored prompting, where few-shot learning with GPT-3.5 yielded promising\nresults. There was an improvement of 12% for question and classification and\n45% for answer classification. Based on our findings, it can be concluded that\nPLMs and prompt-based approaches hold promise for mental health support in\nArabic.", "paper_summary_zh": "<paragraph>\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b (PLM) \u6709\u6f5b\u529b\u900f\u904e\u63d0\u4f9b\u53ef\u5b58\u53d6\u4e14\u5177\u6587\u5316\u654f\u611f\u5ea6\u7684\u8cc7\u6e90\u4f86\u8f49\u5316\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u3002\n\u7136\u800c\uff0c\u5118\u7ba1\u6709\u6b64\u6f5b\u529b\uff0c\u5b83\u5011\u5728\u5fc3\u7406\u4fdd\u5065\u4e2d\u7684\u6709\u6548\u6027\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u963f\u62c9\u4f2f\u8a9e\uff0c\u5c1a\u672a\u5ee3\u6cdb\u63a2\u8a0e\u3002\u70ba\u4e86\u5f4c\u88dc\u6b64\u5dee\u8ddd\uff0c\u672c\u7814\u7a76\u8a55\u4f30\u57fa\u790e\u6a21\u578b\u5728\u5fc3\u7406\u4fdd\u5065\u9818\u57df\u4e2d\u5c0d\u554f\u984c\u8207\u89e3\u7b54 (Q&A) \u9032\u884c\u5206\u985e\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u5229\u7528 MentalQA \u8cc7\u6599\u96c6\uff0c\u9019\u662f\u4e00\u500b\u4ee5\u963f\u62c9\u4f2f\u8a9e\u70ba\u7279\u8272\u7684\u96c6\u5408\uff0c\u5305\u542b\u8207\u5fc3\u7406\u5065\u5eb7\u76f8\u95dc\u7684 Q&A \u4e92\u52d5\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u4f7f\u7528\u56db\u7a2e\u4e0d\u540c\u985e\u578b\u7684\u5b78\u7fd2\u65b9\u6cd5\u9032\u884c\u5be6\u9a57\uff1a\u50b3\u7d71\u7279\u5fb5\u8403\u53d6\u3001PLM \u4f5c\u70ba\u7279\u5fb5\u8403\u53d6\u5668\u3001\u5fae\u8abf PLM\uff0c\u4ee5\u53ca\u5728\u96f6\u6b21\u5b78\u7fd2\u548c\u5c11\u6b21\u5b78\u7fd2\u8a2d\u5b9a\u4e2d\u63d0\u793a\u5927\u578b\u8a9e\u8a00\u6a21\u578b (GPT-3.5 \u548c GPT-4)\u3002\u96d6\u7136\u50b3\u7d71\u7279\u5fb5\u8403\u53d6\u5668\u7d50\u5408\u652f\u63f4\u5411\u91cf\u6a5f (SVM) \u986f\u793a\u51fa\u6709\u5e0c\u671b\u7684\u6548\u80fd\uff0c\u4f46 PLM \u7531\u65bc\u80fd\u5920\u64f7\u53d6\u8a9e\u7fa9\u610f\u7fa9\uff0c\u56e0\u6b64\u8868\u73fe\u5f97\u66f4\u597d\u3002\u4f8b\u5982\uff0cMARBERT \u5728\u554f\u984c\u5206\u985e\u4e2d\u9054\u5230\u6700\u9ad8\u6548\u80fd\uff0cJaccard \u5f97\u5206\u70ba 0.80\uff0c\u5728\u7b54\u6848\u5206\u985e\u4e2d Jaccard \u5f97\u5206\u70ba 0.86\u3002\u6211\u5011\u9032\u4e00\u6b65\u9032\u884c\u6df1\u5165\u5206\u6790\uff0c\u5305\u62ec\u6aa2\u67e5\u5fae\u8abf\u8207\u975e\u5fae\u8abf\u7684\u5f71\u97ff\u3001\u4e0d\u540c\u8cc7\u6599\u5927\u5c0f\u7684\u5f71\u97ff\uff0c\u4ee5\u53ca\u9032\u884c\u932f\u8aa4\u5206\u6790\u3002\u6211\u5011\u7684\u5206\u6790\u8868\u660e\uff0c\u5fae\u8abf\u88ab\u8b49\u660e\u6709\u52a9\u65bc\u63d0\u5347 PLM \u7684\u6548\u80fd\uff0c\u800c\u8a13\u7df4\u8cc7\u6599\u7684\u5927\u5c0f\u5728\u9054\u6210\u9ad8\u6548\u80fd\u4e2d\u626e\u6f14\u81f3\u95dc\u91cd\u8981\u7684\u89d2\u8272\u3002\u6211\u5011\u4e5f\u63a2\u8a0e\u4e86\u63d0\u793a\uff0c\u5176\u4e2d\u4f7f\u7528 GPT-3.5 \u7684\u5c11\u6b21\u5b78\u7fd2\u7522\u751f\u6709\u5e0c\u671b\u7684\u7d50\u679c\u3002\u554f\u984c\u8207\u5206\u985e\u9032\u6b65\u4e86 12%\uff0c\u7b54\u6848\u5206\u985e\u9032\u6b65\u4e86 45%\u3002\u6839\u64da\u6211\u5011\u7684\u767c\u73fe\uff0c\u53ef\u4ee5\u5f97\u51fa\u7d50\u8ad6\uff0cPLM \u548c\u57fa\u65bc\u63d0\u793a\u7684\u65b9\u6cd5\u6709\u671b\u70ba\u963f\u62c9\u4f2f\u8a9e\u7684\u5fc3\u7406\u5065\u5eb7\u63d0\u4f9b\u652f\u6301\u3002</paragraph>", "author": "Hassan Alhuzali et.al.", "authors": "Hassan Alhuzali, Ashwag Alasmari", "id": "2406.15966v1", "paper_url": "http://arxiv.org/abs/2406.15966v1", "repo": "null"}}