{"2409.02326": {"publish_time": "2024-09-03", "title": "Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining", "paper_summary": "Recent studies have been increasingly demonstrating that high-quality data is\ncrucial for effective pretraining of language models. However, the precise\ndefinition of \"high-quality\" remains underexplored. Focusing on the code\ndomain, we introduce Arctic-SnowCoder-1.3B, a data-efficient base code model\npretrained on 555B tokens through three phases of progressively refined data:\n(1) general pretraining with 500B standard-quality code tokens, preprocessed\nthrough basic filtering, deduplication, and decontamination, (2) continued\npretraining with 50B high-quality tokens, selected from phase one by a\nBERT-style quality annotator trained to distinguish good code from random data,\nusing positive examples drawn from high-quality code files, along with\ninstruction data from Magicoder and StarCoder2-Instruct, and (3) enhanced\npretraining with 5B synthetic data created by Llama-3.1-70B using phase two\ndata as seeds, adapting the Magicoder approach for pretraining. Despite being\ntrained on a limited dataset, Arctic-SnowCoder achieves state-of-the-art\nperformance on BigCodeBench, a coding benchmark focusing on practical and\nchallenging programming tasks, compared to similarly sized models trained on no\nmore than 1T tokens, outperforming Phi-1.5-1.3B by 36%. Across all evaluated\nbenchmarks, Arctic-SnowCoder-1.3B beats StarCoderBase-3B pretrained on 1T\ntokens. Additionally, it matches the performance of leading small base code\nmodels trained on trillions of tokens. For example, Arctic-SnowCoder-1.3B\nsurpasses StarCoder2-3B, pretrained on over 3.3T tokens, on HumanEval+, a\nbenchmark that evaluates function-level code generation, and remains\ncompetitive on BigCodeBench. Our evaluation presents a comprehensive analysis\njustifying various design choices for Arctic-SnowCoder. Most importantly, we\nfind that the key to high-quality data is its alignment with the distribution\nof downstream applications.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u7684\u7814\u7a76\u8d8a\u4f86\u8d8a\u8b49\u660e\uff0c\u9ad8\u54c1\u8cea\u7684\u8cc7\u6599\u5c0d\u65bc\u8a9e\u8a00\u6a21\u578b\u7684\u6709\u6548\u9810\u8a13\u7df4\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u300c\u9ad8\u54c1\u8cea\u300d\u7684\u7cbe\u78ba\u5b9a\u7fa9\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u8a0e\u3002\u5c08\u6ce8\u65bc\u7a0b\u5f0f\u78bc\u9818\u57df\uff0c\u6211\u5011\u5f15\u5165\u4e86 Arctic-SnowCoder-1.3B\uff0c\u9019\u662f\u4e00\u500b\u8cc7\u6599\u6709\u6548\u7387\u7684\u57fa\u672c\u7a0b\u5f0f\u78bc\u6a21\u578b\uff0c\u900f\u904e\u4e09\u500b\u968e\u6bb5\u7684\u6f38\u9032\u5f0f\u7cbe\u7149\u8cc7\u6599\u9032\u884c\u9810\u8a13\u7df4\uff0c\u7e3d\u8a08 555B \u500b\u7b26\u865f\uff1a(1) \u4f7f\u7528 500B \u6a19\u6e96\u54c1\u8cea\u7a0b\u5f0f\u78bc\u7b26\u865f\u9032\u884c\u4e00\u822c\u9810\u8a13\u7df4\uff0c\u900f\u904e\u57fa\u672c\u904e\u6ffe\u3001\u91cd\u8907\u8cc7\u6599\u522a\u9664\u548c\u53bb\u6c59\u67d3\u9032\u884c\u9810\u8655\u7406\uff0c(2) \u7e7c\u7e8c\u4f7f\u7528 50B \u9ad8\u54c1\u8cea\u7b26\u865f\u9032\u884c\u9810\u8a13\u7df4\uff0c\u5f9e\u7b2c\u4e00\u968e\u6bb5\u4e2d\u7531 BERT \u98a8\u683c\u54c1\u8cea\u8a3b\u89e3\u5668\u9078\u51fa\uff0c\u8a72\u8a3b\u89e3\u5668\u7d93\u904e\u8a13\u7df4\uff0c\u53ef\u4ee5\u5340\u5206\u826f\u597d\u7a0b\u5f0f\u78bc\u548c\u96a8\u6a5f\u8cc7\u6599\uff0c\u4f7f\u7528\u5f9e\u9ad8\u54c1\u8cea\u7a0b\u5f0f\u78bc\u6a94\u6848\u4e2d\u64f7\u53d6\u7684\u6b63\u9762\u7bc4\u4f8b\uff0c\u4ee5\u53ca\u4f86\u81ea Magicoder \u548c StarCoder2-Instruct \u7684\u6307\u4ee4\u8cc7\u6599\uff0c(3) \u4f7f\u7528 Llama-3.1-70B \u4f7f\u7528\u7b2c\u4e8c\u968e\u6bb5\u8cc7\u6599\u4f5c\u70ba\u7a2e\u5b50\uff0c\u900f\u904e\u8abf\u6574 Magicoder \u9810\u8a13\u7df4\u65b9\u6cd5\uff0c\u9032\u4e00\u6b65\u4f7f\u7528 5B \u5408\u6210\u8cc7\u6599\u9032\u884c\u9810\u8a13\u7df4\u3002\u5118\u7ba1\u8a13\u7df4\u8cc7\u6599\u96c6\u6709\u9650\uff0c\u4f46\u8207\u8a13\u7df4\u8cc7\u6599\u91cf\u4e0d\u8d85\u904e 1T \u500b\u7b26\u865f\u7684\u985e\u4f3c\u5927\u5c0f\u6a21\u578b\u76f8\u6bd4\uff0cArctic-SnowCoder \u5728 BigCodeBench \u4e0a\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u6bd4 Phi-1.5-1.3B \u9ad8\u51fa 36%\u3002\u5728\u6240\u6709\u8a55\u4f30\u57fa\u6e96\u4e2d\uff0cArctic-SnowCoder-1.3B \u90fd\u52dd\u904e\u5728 1T \u500b\u7b26\u865f\u4e0a\u9032\u884c\u9810\u8a13\u7df4\u7684 StarCoderBase-3B\u3002\u6b64\u5916\uff0c\u5b83\u9084\u8207\u5728\u6578\u5146\u500b\u7b26\u865f\u4e0a\u8a13\u7df4\u7684\u4e3b\u8981\u5c0f\u578b\u57fa\u672c\u7a0b\u5f0f\u78bc\u6a21\u578b\u6548\u80fd\u76f8\u5339\u914d\u3002\u4f8b\u5982\uff0cArctic-SnowCoder-1.3B \u5728 HumanEval+ \u4e0a\u8d85\u8d8a\u4e86\u5728\u8d85\u904e 3.3T \u500b\u7b26\u865f\u4e0a\u9032\u884c\u9810\u8a13\u7df4\u7684 StarCoder2-3B\uff0cHumanEval+ \u662f\u8a55\u4f30\u51fd\u5f0f\u5c64\u7d1a\u7a0b\u5f0f\u78bc\u7522\u751f\u7684\u57fa\u6e96\uff0c\u4e26\u4e14\u5728 BigCodeBench \u4e0a\u4fdd\u6301\u7af6\u722d\u529b\u3002\u6211\u5011\u7684\u8a55\u4f30\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u5206\u6790\uff0c\u8b49\u660e\u4e86 Arctic-SnowCoder \u7684\u5404\u7a2e\u8a2d\u8a08\u9078\u64c7\u3002\u6700\u91cd\u8981\u7684\u662f\uff0c\u6211\u5011\u767c\u73fe\u9ad8\u54c1\u8cea\u8cc7\u6599\u7684\u95dc\u9375\u5728\u65bc\u5b83\u8207\u4e0b\u6e38\u61c9\u7528\u7a0b\u5f0f\u7684\u5206\u4f48\u4e00\u81f4\u3002</paragraph>", "author": "Yuxiang Wei et.al.", "authors": "Yuxiang Wei, Hojae Han, Rajhans Samdani", "id": "2409.02326v1", "paper_url": "http://arxiv.org/abs/2409.02326v1", "repo": "null"}}