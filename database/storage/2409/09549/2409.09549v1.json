{"2409.09549": {"publish_time": "2024-09-14", "title": "COMFORT: A Continual Fine-Tuning Framework for Foundation Models Targeted at Consumer Healthcare", "paper_summary": "Wearable medical sensors (WMSs) are revolutionizing smart healthcare by\nenabling continuous, real-time monitoring of user physiological signals,\nespecially in the field of consumer healthcare. The integration of WMSs and\nmodern machine learning (ML) enables unprecedented solutions to efficient\nearly-stage disease detection. Despite the success of Transformers in various\nfields, their application to sensitive domains, such as smart healthcare,\nremains underexplored due to limited data accessibility and privacy concerns.\nTo bridge the gap between Transformer-based foundation models and WMS-based\ndisease detection, we propose COMFORT, a continual fine-tuning framework for\nfoundation models targeted at consumer healthcare. COMFORT introduces a novel\napproach for pre-training a Transformer-based foundation model on a large\ndataset of physiological signals exclusively collected from healthy individuals\nwith commercially available WMSs. We adopt a masked data modeling (MDM)\nobjective to pre-train this health foundation model. We then fine-tune the\nmodel using various parameter-efficient fine-tuning (PEFT) methods, such as\nlow-rank adaptation (LoRA) and its variants, to adapt it to various downstream\ndisease detection tasks that rely on WMS data. In addition, COMFORT continually\nstores the low-rank decomposition matrices obtained from the PEFT algorithms to\nconstruct a library for multi-disease detection. The COMFORT library enables\nscalable and memory-efficient disease detection on edge devices. Our\nexperimental results demonstrate that COMFORT achieves highly competitive\nperformance while reducing memory overhead by up to 52% relative to\nconventional methods. Thus, COMFORT paves the way for personalized and\nproactive solutions to efficient and effective early-stage disease detection\nfor consumer healthcare.", "paper_summary_zh": "<paragraph>\u53ef\u7a7f\u6234\u5f0f\u91ab\u7642\u611f\u6e2c\u5668 (WMS) \u900f\u904e\u6301\u7e8c\u3001\u5373\u6642\u76e3\u6e2c\u4f7f\u7528\u8005\u7684\u751f\u7406\u8a0a\u865f\uff0c\u7279\u5225\u662f\u5728\u6d88\u8cbb\u8005\u91ab\u7642\u4fdd\u5065\u9818\u57df\uff0c\u9032\u800c\u9769\u65b0\u4e86\u667a\u6167\u91ab\u7642\u4fdd\u5065\u3002WMS \u8207\u73fe\u4ee3\u6a5f\u5668\u5b78\u7fd2 (ML) \u7684\u6574\u5408\uff0c\u8b93\u6709\u6548\u7387\u7684\u65e9\u671f\u75be\u75c5\u5075\u6e2c\u6709\u4e86\u524d\u6240\u672a\u6709\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u5118\u7ba1 Transformer \u5728\u5404\u7a2e\u9818\u57df\u7686\u7372\u5f97\u6210\u529f\uff0c\u4f46\u7531\u65bc\u8cc7\u6599\u53d6\u5f97\u4e0d\u6613\u548c\u96b1\u79c1\u7591\u616e\uff0c\u5176\u5728\u667a\u6167\u91ab\u7642\u4fdd\u5065\u7b49\u654f\u611f\u9818\u57df\u7684\u61c9\u7528\u4ecd\u6709\u5f85\u63a2\u7d22\u3002\u70ba\u4e86\u5f4c\u5408 Transformer \u57fa\u790e\u6a21\u578b\u8207 WMS \u57fa\u790e\u75be\u75c5\u5075\u6e2c\u4e4b\u9593\u7684\u5dee\u8ddd\uff0c\u6211\u5011\u63d0\u51fa\u4e86 COMFORT\uff0c\u4e00\u500b\u91dd\u5c0d\u6d88\u8cbb\u8005\u91ab\u7642\u4fdd\u5065\u800c\u8a2d\u8a08\u7684\u57fa\u790e\u6a21\u578b\u6301\u7e8c\u5fae\u8abf\u67b6\u69cb\u3002COMFORT \u63d0\u51fa\u4e86\u4e00\u7a2e\u5275\u65b0\u7684\u65b9\u6cd5\uff0c\u53ef\u5728\u4e00\u500b\u9f90\u5927\u7684\u751f\u7406\u8a0a\u865f\u8cc7\u6599\u96c6\u4e0a\u9810\u8a13\u7df4 Transformer \u57fa\u790e\u6a21\u578b\uff0c\u800c\u9019\u4e9b\u8cc7\u6599\u7686\u662f\u900f\u904e\u5e02\u552e WMS \u5f9e\u5065\u5eb7\u500b\u4eba\u8eab\u4e0a\u6536\u96c6\u800c\u4f86\u3002\u6211\u5011\u63a1\u7528\u906e\u7f69\u8cc7\u6599\u5efa\u6a21 (MDM) \u76ee\u6a19\u4f86\u9810\u8a13\u7df4\u9019\u500b\u5065\u5eb7\u57fa\u790e\u6a21\u578b\u3002\u63a5\u8457\uff0c\u6211\u5011\u4f7f\u7528\u5404\u7a2e\u53c3\u6578\u6709\u6548\u7387\u7684\u5fae\u8abf (PEFT) \u65b9\u6cd5\uff08\u4f8b\u5982\u4f4e\u79e9\u9069\u61c9 (LoRA) \u53ca\u5176\u8b8a\u9ad4\uff09\u5fae\u8abf\u6a21\u578b\uff0c\u4ee5\u4f7f\u5176\u9069\u61c9\u4f9d\u8cf4 WMS \u8cc7\u6599\u7684\u5404\u7a2e\u4e0b\u6e38\u75be\u75c5\u5075\u6e2c\u4efb\u52d9\u3002\u6b64\u5916\uff0cCOMFORT \u6703\u6301\u7e8c\u5132\u5b58\u5f9e PEFT \u6f14\u7b97\u6cd5\u53d6\u5f97\u7684\u4f4e\u79e9\u5206\u89e3\u77e9\u9663\uff0c\u4ee5\u5efa\u69cb\u4e00\u500b\u591a\u75be\u75c5\u5075\u6e2c\u51fd\u5f0f\u5eab\u3002COMFORT \u51fd\u5f0f\u5eab\u53ef\u5728\u908a\u7de3\u88dd\u7f6e\u4e0a\u9032\u884c\u53ef\u64f4\u5145\u4e14\u8a18\u61b6\u9ad4\u4f7f\u7528\u7387\u4f4e\u4e0b\u7684\u75be\u75c5\u5075\u6e2c\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0cCOMFORT \u9054\u5230\u4e86\u6975\u5177\u7af6\u722d\u529b\u7684\u6548\u80fd\uff0c\u540c\u6642\u5c07\u8a18\u61b6\u9ad4\u958b\u92b7\u76f8\u8f03\u65bc\u50b3\u7d71\u65b9\u6cd5\u964d\u4f4e\u4e86 52%\u3002\u56e0\u6b64\uff0cCOMFORT \u70ba\u6d88\u8cbb\u8005\u91ab\u7642\u4fdd\u5065\u7684\u6709\u6548\u4e14\u9ad8\u6548\u65e9\u671f\u75be\u75c5\u5075\u6e2c\uff0c\u958b\u95e2\u4e86\u500b\u4eba\u5316\u4e14\u4e3b\u52d5\u7684\u89e3\u6c7a\u65b9\u6848\u3002</paragraph>", "author": "Chia-Hao Li et.al.", "authors": "Chia-Hao Li, Niraj K. Jha", "id": "2409.09549v1", "paper_url": "http://arxiv.org/abs/2409.09549v1", "repo": "null"}}