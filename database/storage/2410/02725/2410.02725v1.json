{"2410.02725": {"publish_time": "2024-10-03", "title": "Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation", "paper_summary": "Inference-time computation is a powerful paradigm to enhance the performance\nof large language models (LLMs), with Best-of-N sampling being a widely used\ntechnique. However, this method is computationally expensive, requiring both\n(1) an external reward model and (2) the generation of multiple samples. In\nthis work, we introduce a new generative self-evaluation scheme designed to\nadaptively reduce the number of generated samples while maintaining or even\nimproving performance. We use a generative reward model formulation, allowing\nthe LLM to predict mid-generation the probability that restarting the\ngeneration will yield a better response. These predictions are obtained without\nan external reward model and can be used to decide whether or not to generate\nmore samples, prune unpromising samples early on, or to pick the best sample.\nThis capability is very inexpensive as it involves generating a single\npredefined token. Trained using a dataset constructed with real unfiltered\nLMSYS user prompts, Llama 3.1 8B's win rate against GPT-4 on AlpacaEval\nincreases from 21% to 34% with 16 samples and math performance on GSM8K\nimproves from 84% to 91%. By sampling only when the LLM determines that it is\nbeneficial to do so and adaptively adjusting temperature annealing, we\ndemonstrate that 74% of the improvement from using 16 samples can be achieved\nwith only 1.2 samples on average. We further demonstrate that 50-75% of samples\ncan be pruned early in generation with minimal degradation in performance.\nOverall, our methods enable more efficient and scalable compute utilization\nduring inference for LLMs.", "paper_summary_zh": "\u63a8\u7406\u6642\u9593\u8a08\u7b97\u662f\u4e00\u7a2e\u5f37\u5927\u7684\u7bc4\u4f8b\uff0c\u53ef\u4ee5\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6548\u80fd\uff0c\u5176\u4e2d\u6700\u4f73 N \u53d6\u6a23\u662f\u4e00\u7a2e\u5ee3\u6cdb\u4f7f\u7528\u7684\u6280\u8853\u3002\u7136\u800c\uff0c\u9019\u7a2e\u65b9\u6cd5\u5728\u8a08\u7b97\u4e0a\u5f88\u6602\u8cb4\uff0c\u9700\u8981 (1) \u5916\u90e8\u734e\u52f5\u6a21\u578b\u548c (2) \u7522\u751f\u591a\u500b\u6a23\u672c\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u7684\u751f\u6210\u5f0f\u81ea\u6211\u8a55\u4f30\u65b9\u6848\uff0c\u65e8\u5728\u81ea\u9069\u61c9\u5730\u6e1b\u5c11\u751f\u6210\u7684\u6a23\u672c\u6578\u91cf\uff0c\u540c\u6642\u7dad\u6301\u751a\u81f3\u6539\u5584\u6548\u80fd\u3002\u6211\u5011\u4f7f\u7528\u751f\u6210\u5f0f\u734e\u52f5\u6a21\u578b\u516c\u5f0f\uff0c\u5141\u8a31 LLM \u5728\u751f\u6210\u904e\u7a0b\u4e2d\u9810\u6e2c\u91cd\u65b0\u555f\u52d5\u751f\u6210\u5c07\u7522\u751f\u66f4\u597d\u56de\u61c9\u7684\u6a5f\u7387\u3002\u9019\u4e9b\u9810\u6e2c\u662f\u5728\u6c92\u6709\u5916\u90e8\u734e\u52f5\u6a21\u578b\u7684\u60c5\u6cc1\u4e0b\u7372\u5f97\u7684\uff0c\u53ef\u7528\u65bc\u6c7a\u5b9a\u662f\u5426\u7522\u751f\u66f4\u591a\u6a23\u672c\u3001\u53ca\u65e9\u79fb\u9664\u4e0d\u4f73\u7684\u6a23\u672c\uff0c\u6216\u9078\u64c7\u6700\u4f73\u6a23\u672c\u3002\u9019\u7a2e\u80fd\u529b\u975e\u5e38\u4fbf\u5b9c\uff0c\u56e0\u70ba\u5b83\u6d89\u53ca\u751f\u6210\u55ae\u4e00\u7684\u9810\u5b9a\u7fa9\u6b0a\u6756\u3002\u4f7f\u7528\u7531\u771f\u5be6\u672a\u904e\u6ffe\u7684 LMSYS \u4f7f\u7528\u8005\u63d0\u793a\u6240\u5efa\u69cb\u7684\u8cc7\u6599\u96c6\u9032\u884c\u8a13\u7df4\uff0cLlama 3.1 8B \u5728 AlpacaEval \u4e0a\u5c0d\u6297 GPT-4 \u7684\u7372\u52dd\u7387\u5f9e 21% \u589e\u52a0\u5230 34%\uff0c\u4e14\u5728 GSM8K \u4e0a\u7684\u6578\u5b78\u6548\u80fd\u5f9e 84% \u63d0\u5347\u5230 91%\u3002\u900f\u904e\u50c5\u5728 LLM \u78ba\u5b9a\u9019\u6a23\u505a\u6709\u5229\u6642\u9032\u884c\u53d6\u6a23\uff0c\u4e26\u81ea\u9069\u61c9\u5730\u8abf\u6574\u6eab\u5ea6\u9000\u706b\uff0c\u6211\u5011\u8b49\u660e\u4e86\u4f7f\u7528 16 \u500b\u6a23\u672c\u4e2d 74% \u7684\u6539\u9032\uff0c\u5e73\u5747\u53ea\u9700 1.2 \u500b\u6a23\u672c\u5373\u53ef\u5be6\u73fe\u3002\u6211\u5011\u9032\u4e00\u6b65\u8b49\u660e\uff0c50-75% \u7684\u6a23\u672c\u53ef\u4ee5\u5728\u751f\u6210\u65e9\u671f\u9032\u884c\u79fb\u9664\uff0c\u800c\u6548\u80fd\u4e0b\u964d\u5e45\u5ea6\u5f88\u5c0f\u3002\u7e3d\u7684\u4f86\u8aaa\uff0c\u6211\u5011\u7684\u6280\u8853\u53ef\u4ee5\u5728 LLM \u7684\u63a8\u7406\u904e\u7a0b\u4e2d\u5be6\u73fe\u66f4\u6709\u6548\u7387\u4e14\u53ef\u64f4\u5145\u7684\u904b\u7b97\u4f7f\u7528\u3002", "author": "Rohin Manvi et.al.", "authors": "Rohin Manvi, Anikait Singh, Stefano Ermon", "id": "2410.02725v1", "paper_url": "http://arxiv.org/abs/2410.02725v1", "repo": "null"}}