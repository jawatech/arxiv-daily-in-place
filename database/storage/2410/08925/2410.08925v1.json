{"2410.08925": {"publish_time": "2024-10-11", "title": "HyperPg -- Prototypical Gaussians on the Hypersphere for Interpretable Deep Learning", "paper_summary": "Prototype Learning methods provide an interpretable alternative to black-box\ndeep learning models. Approaches such as ProtoPNet learn, which part of a test\nimage \"look like\" known prototypical parts from training images, combining\npredictive power with the inherent interpretability of case-based reasoning.\nHowever, existing approaches have two main drawbacks: A) They rely solely on\ndeterministic similarity scores without statistical confidence. B) The\nprototypes are learned in a black-box manner without human input. This work\nintroduces HyperPg, a new prototype representation leveraging Gaussian\ndistributions on a hypersphere in latent space, with learnable mean and\nvariance. HyperPg prototypes adapt to the spread of clusters in the latent\nspace and output likelihood scores. The new architecture, HyperPgNet, leverages\nHyperPg to learn prototypes aligned with human concepts from pixel-level\nannotations. Consequently, each prototype represents a specific concept such as\ncolor, image texture, or part of the image subject. A concept extraction\npipeline built on foundation models provides pixel-level annotations,\nsignificantly reducing human labeling effort. Experiments on CUB-200-2011 and\nStanford Cars datasets demonstrate that HyperPgNet outperforms other prototype\nlearning architectures while using fewer parameters and training steps.\nAdditionally, the concept-aligned HyperPg prototypes are learned transparently,\nenhancing model interpretability.", "paper_summary_zh": "\u539f\u578b\u5b78\u7fd2\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u7a2e\u53ef\u89e3\u91cb\u7684\u9ed1\u7bb1\u66ff\u4ee3\u65b9\u6848\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u3002\u4f8b\u5982 ProtoPNet \u7b49\u65b9\u6cd5\u5b78\u7fd2\u6e2c\u8a66\u5716\u50cf\u7684\u54ea\u4e00\u90e8\u5206\u300c\u770b\u8d77\u4f86\u50cf\u300d\u8a13\u7df4\u5716\u50cf\u4e2d\u5df2\u77e5\u7684\u539f\u578b\u90e8\u5206\uff0c\u7d50\u5408\u4e86\u9810\u6e2c\u80fd\u529b\u8207\u57fa\u65bc\u6848\u4f8b\u63a8\u7406\u7684\u5167\u5728\u53ef\u89e3\u91cb\u6027\u3002\u7136\u800c\uff0c\u73fe\u6709\u65b9\u6cd5\u6709\u5169\u500b\u4e3b\u8981\u7f3a\u9ede\uff1aA) \u5b83\u5011\u50c5\u4f9d\u8cf4\u65bc\u78ba\u5b9a\u6027\u7684\u76f8\u4f3c\u5ea6\u5206\u6578\uff0c\u800c\u6c92\u6709\u7d71\u8a08\u4fe1\u5fc3\u3002B) \u539f\u578b\u662f\u4ee5\u9ed1\u7bb1\u65b9\u5f0f\u5b78\u7fd2\u7684\uff0c\u6c92\u6709\u4eba\u985e\u8f38\u5165\u3002\u9019\u9805\u5de5\u4f5c\u5f15\u5165\u4e86 HyperPg\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7684\u539f\u578b\u8868\u793a\uff0c\u5b83\u5229\u7528\u6f5b\u5728\u7a7a\u9593\u4e2d\u8d85\u7403\u9762\u4e0a\u7684\u9ad8\u65af\u5206\u4f48\uff0c\u5177\u6709\u53ef\u5b78\u7fd2\u7684\u5e73\u5747\u503c\u548c\u65b9\u5dee\u3002HyperPg \u539f\u578b\u9069\u61c9\u6f5b\u5728\u7a7a\u9593\u4e2d\u7fa4\u96c6\u7684\u64f4\u6563\u4e26\u8f38\u51fa\u4f3c\u7136\u5206\u6578\u3002\u65b0\u7684\u67b6\u69cb HyperPgNet \u5229\u7528 HyperPg \u5f9e\u50cf\u7d20\u7d1a\u5225\u8a3b\u89e3\u4e2d\u5b78\u7fd2\u8207\u4eba\u985e\u6982\u5ff5\u5c0d\u9f4a\u7684\u539f\u578b\u3002\u56e0\u6b64\uff0c\u6bcf\u500b\u539f\u578b\u90fd\u4ee3\u8868\u4e00\u500b\u5177\u9ad4\u7684\u6982\u5ff5\uff0c\u4f8b\u5982\u984f\u8272\u3001\u5716\u50cf\u7d0b\u7406\u6216\u5716\u50cf\u4e3b\u9ad4\u7684\u4e00\u90e8\u5206\u3002\u5efa\u7acb\u5728\u57fa\u790e\u6a21\u578b\u4e0a\u7684\u6982\u5ff5\u63d0\u53d6\u7ba1\u9053\u63d0\u4f9b\u50cf\u7d20\u7d1a\u5225\u8a3b\u89e3\uff0c\u5927\u5e45\u6e1b\u5c11\u4eba\u985e\u6a19\u8a18\u5de5\u4f5c\u3002\u5728 CUB-200-2011 \u548c Stanford Cars \u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u8868\u660e\uff0cHyperPgNet \u5728\u4f7f\u7528\u8f03\u5c11\u53c3\u6578\u548c\u8a13\u7df4\u6b65\u9a5f\u7684\u540c\u6642\uff0c\u512a\u65bc\u5176\u4ed6\u539f\u578b\u5b78\u7fd2\u67b6\u69cb\u3002\u6b64\u5916\uff0c\u8207\u6982\u5ff5\u5c0d\u9f4a\u7684 HyperPg \u539f\u578b\u662f\u4ee5\u900f\u660e\u7684\u65b9\u5f0f\u5b78\u7fd2\u7684\uff0c\u589e\u5f37\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91cb\u6027\u3002", "author": "Maximilian Xiling Li et.al.", "authors": "Maximilian Xiling Li, Korbinian Franz Rudolf, Nils Blank, Rudolf Lioutikov", "id": "2410.08925v1", "paper_url": "http://arxiv.org/abs/2410.08925v1", "repo": "null"}}