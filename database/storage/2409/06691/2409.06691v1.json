{"2409.06691": {"publish_time": "2024-09-10", "title": "Geometric-Averaged Preference Optimization for Soft Preference Labels", "paper_summary": "Many algorithms for aligning LLMs with human preferences assume that human\npreferences are binary and deterministic. However, it is reasonable to think\nthat they can vary with different individuals, and thus should be\ndistributional to reflect the fine-grained relationship between the responses.\nIn this work, we introduce the distributional soft preference labels and\nimprove Direct Preference Optimization (DPO) with a weighted geometric average\nof the LLM output likelihood in the loss function. In doing so, the scale of\nlearning loss is adjusted based on the soft labels, and the loss with equally\npreferred responses would be close to zero. This simple modification can be\neasily applied to any DPO family and helps the models escape from the\nover-optimization and objective mismatch prior works suffer from. In our\nexperiments, we simulate the soft preference labels with AI feedback from LLMs\nand demonstrate that geometric averaging consistently improves performance on\nstandard benchmarks for alignment research. In particular, we observe more\npreferable responses than binary labels and significant improvements with data\nwhere modestly-confident labels are in the majority.", "paper_summary_zh": "\u8a31\u591a\u7528\u65bc\u5c07 LLM \u8207\u4eba\u985e\u504f\u597d\u5c0d\u9f4a\u7684\u6f14\u7b97\u6cd5\u5047\u8a2d\u4eba\u985e\u504f\u597d\u662f\u4e8c\u5143\u7684\u4e14\u78ba\u5b9a\u7684\u3002\u7136\u800c\uff0c\u53ef\u4ee5\u5408\u7406\u5730\u8a8d\u70ba\u5b83\u5011\u6703\u56e0\u4eba\u800c\u7570\uff0c\u56e0\u6b64\u61c9\u4ee5\u5206\u4f48\u5f0f\u65b9\u5f0f\u53cd\u6620\u56de\u61c9\u4e4b\u9593\u7684\u7d30\u5fae\u95dc\u4fc2\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u5206\u4f48\u5f0f\u8edf\u504f\u597d\u6a19\u7c64\uff0c\u4e26\u4f7f\u7528\u640d\u5931\u51fd\u6578\u4e2d LLM \u8f38\u51fa\u4f3c\u7136\u52a0\u6b0a\u5e7e\u4f55\u5e73\u5747\u503c\u6539\u9032\u4e86\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO)\u3002\u5728\u9019\u6a23\u505a\u7684\u904e\u7a0b\u4e2d\uff0c\u5b78\u7fd2\u640d\u5931\u7684\u898f\u6a21\u6703\u6839\u64da\u8edf\u6a19\u7c64\u9032\u884c\u8abf\u6574\uff0c\u4e26\u4e14\u5177\u6709\u76f8\u540c\u504f\u597d\u56de\u61c9\u7684\u640d\u5931\u5c07\u63a5\u8fd1\u65bc\u96f6\u3002\u9019\u500b\u7c21\u55ae\u7684\u4fee\u6539\u53ef\u4ee5\u8f15\u9b06\u61c9\u7528\u65bc\u4efb\u4f55 DPO \u5bb6\u65cf\uff0c\u4e26\u5e6b\u52a9\u6a21\u578b\u64fa\u812b\u904e\u5ea6\u6700\u4f73\u5316\u548c\u76ee\u6a19\u4e0d\u5339\u914d\u7684\u554f\u984c\u3002\u5728\u6211\u5011\u7684\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u4f7f\u7528\u4f86\u81ea LLM \u7684 AI \u56de\u994b\u6a21\u64ec\u8edf\u504f\u597d\u6a19\u7c64\uff0c\u4e26\u8b49\u660e\u5e7e\u4f55\u5e73\u5747\u59cb\u7d42\u6539\u5584\u5c0d\u9f4a\u7814\u7a76\u7684\u6a19\u6e96\u57fa\u6e96\u7684\u6548\u80fd\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u6bd4\u4e8c\u5143\u6a19\u7c64\u66f4\u7406\u60f3\u7684\u56de\u61c9\uff0c\u4e26\u4e14\u5728\u4e2d\u5ea6\u81ea\u4fe1\u6a19\u7c64\u4f54\u591a\u6578\u7684\u8cc7\u6599\u4e2d\u7372\u5f97\u986f\u8457\u7684\u6539\u9032\u3002", "author": "Hiroki Furuta et.al.", "authors": "Hiroki Furuta, Kuang-Huei Lee, Shixiang Shane Gu, Yutaka Matsuo, Aleksandra Faust, Heiga Zen, Izzeddin Gur", "id": "2409.06691v1", "paper_url": "http://arxiv.org/abs/2409.06691v1", "repo": "null"}}