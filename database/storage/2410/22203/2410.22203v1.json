{"2410.22203": {"publish_time": "2024-10-29", "title": "Democratizing Reward Design for Personal and Representative Value-Alignment", "paper_summary": "Aligning AI agents with human values is challenging due to diverse and\nsubjective notions of values. Standard alignment methods often aggregate crowd\nfeedback, which can result in the suppression of unique or minority\npreferences. We introduce Interactive-Reflective Dialogue Alignment, a method\nthat iteratively engages users in reflecting on and specifying their subjective\nvalue definitions. This system learns individual value definitions through\nlanguage-model-based preference elicitation and constructs personalized reward\nmodels that can be used to align AI behaviour. We evaluated our system through\ntwo studies with 30 participants, one focusing on \"respect\" and the other on\nethical decision-making in autonomous vehicles. Our findings demonstrate\ndiverse definitions of value-aligned behaviour and show that our system can\naccurately capture each person's unique understanding. This approach enables\npersonalized alignment and can inform more representative and interpretable\ncollective alignment strategies.", "paper_summary_zh": "\u7531\u65bc\u50f9\u503c\u89c0\u5ff5\u7684\u591a\u5143\u4e14\u4e3b\u89c0\uff0c\u8b93 AI \u4ee3\u7406\u8207\u4eba\u985e\u50f9\u503c\u89c0\u4fdd\u6301\u4e00\u81f4\u662f\u4e00\u9805\u6311\u6230\u3002\u6a19\u6e96\u6821\u6e96\u65b9\u6cd5\u901a\u5e38\u6703\u5f59\u7e3d\u7fa4\u773e\u56de\u994b\uff0c\u9019\u53ef\u80fd\u6703\u5c0e\u81f4\u7368\u7279\u6216\u5c11\u6578\u504f\u597d\u7684\u58d3\u5236\u3002\u6211\u5011\u5f15\u5165\u4e86\u4e92\u52d5\u5f0f\u53cd\u601d\u5f0f\u5c0d\u8a71\u6821\u6e96\uff0c\u9019\u662f\u4e00\u7a2e\u8b93\u4f7f\u7528\u8005\u53cd\u8986\u53c3\u8207\u53cd\u601d\u4e26\u8aaa\u660e\u5176\u4e3b\u89c0\u50f9\u503c\u5b9a\u7fa9\u7684\u65b9\u6cd5\u3002\u6b64\u7cfb\u7d71\u900f\u904e\u57fa\u65bc\u8a9e\u8a00\u6a21\u578b\u7684\u504f\u597d\u5f15\u5c0e\u4f86\u5b78\u7fd2\u500b\u5225\u50f9\u503c\u5b9a\u7fa9\uff0c\u4e26\u5efa\u69cb\u53ef\u7528\u4e8e\u6821\u6e96 AI \u884c\u70ba\u7684\u500b\u4eba\u5316\u734e\u52f5\u6a21\u578b\u3002\u6211\u5011\u900f\u904e\u5169\u9805\u7814\u7a76\u5c0d\u6211\u5011\u7684\u7cfb\u7d71\u9032\u884c\u4e86\u8a55\u4f30\uff0c\u5171\u6709 30 \u540d\u53c3\u8207\u8005\uff0c\u4e00\u9805\u8457\u91cd\u65bc\u300c\u5c0a\u91cd\u300d\uff0c\u53e6\u4e00\u9805\u8457\u91cd\u65bc\u81ea\u52d5\u99d5\u99db\u8eca\u8f1b\u4e2d\u7684\u9053\u5fb7\u6c7a\u7b56\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8b49\u660e\u4e86\u50f9\u503c\u89c0\u4e00\u81f4\u884c\u70ba\u7684\u591a\u5143\u5b9a\u7fa9\uff0c\u4e26\u986f\u793a\u6211\u5011\u7684\u7cfb\u7d71\u53ef\u4ee5\u6e96\u78ba\u6355\u6349\u6bcf\u500b\u500b\u4eba\u7684\u7368\u7279\u7406\u89e3\u3002\u9019\u7a2e\u65b9\u6cd5\u80fd\u5be6\u73fe\u500b\u4eba\u5316\u6821\u6e96\uff0c\u4e26\u53ef\u4ee5\u70ba\u66f4\u5177\u4ee3\u8868\u6027\u548c\u53ef\u89e3\u91cb\u6027\u7684\u96c6\u9ad4\u6821\u6e96\u7b56\u7565\u63d0\u4f9b\u8cc7\u8a0a\u3002", "author": "Carter Blair et.al.", "authors": "Carter Blair, Kate Larson, Edith Law", "id": "2410.22203v1", "paper_url": "http://arxiv.org/abs/2410.22203v1", "repo": "null"}}