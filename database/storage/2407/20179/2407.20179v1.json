{"2407.20179": {"publish_time": "2024-07-29", "title": "Theia: Distilling Diverse Vision Foundation Models for Robot Learning", "paper_summary": "Vision-based robot policy learning, which maps visual inputs to actions,\nnecessitates a holistic understanding of diverse visual tasks beyond\nsingle-task needs like classification or segmentation. Inspired by this, we\nintroduce Theia, a vision foundation model for robot learning that distills\nmultiple off-the-shelf vision foundation models trained on varied vision tasks.\nTheia's rich visual representations encode diverse visual knowledge, enhancing\ndownstream robot learning. Extensive experiments demonstrate that Theia\noutperforms its teacher models and prior robot learning models using less\ntraining data and smaller model sizes. Additionally, we quantify the quality of\npre-trained visual representations and hypothesize that higher entropy in\nfeature norm distributions leads to improved robot learning performance. Code\nand models are available at https://github.com/bdaiinstitute/theia.", "paper_summary_zh": "\u57fa\u65bc\u8996\u89ba\u7684\u6a5f\u5668\u4eba\u7b56\u7565\u5b78\u7fd2\uff0c\u5c07\u8996\u89ba\u8f38\u5165\u5c0d\u61c9\u5230\u52d5\u4f5c\uff0c\u9700\u8981\u5c0d\u591a\u6a23\u5316\u8996\u89ba\u4efb\u52d9\u6709\u6574\u9ad4\u7684\u7406\u89e3\uff0c\u8d85\u8d8a\u55ae\u4e00\u4efb\u52d9\u9700\u6c42\uff0c\u4f8b\u5982\u5206\u985e\u6216\u5206\u5272\u3002\u53d7\u5230\u6b64\u555f\u767c\uff0c\u6211\u5011\u4ecb\u7d39 Theia\uff0c\u9019\u662f\u4e00\u500b\u6a5f\u5668\u4eba\u5b78\u7fd2\u7684\u8996\u89ba\u57fa\u790e\u6a21\u578b\uff0c\u5b83\u8403\u53d6\u591a\u500b\u91dd\u5c0d\u4e0d\u540c\u8996\u89ba\u4efb\u52d9\u8a13\u7df4\u7684\u73fe\u6210\u8996\u89ba\u57fa\u790e\u6a21\u578b\u3002Theia \u8c50\u5bcc\u7684\u8996\u89ba\u8868\u5fb5\u7de8\u78bc\u591a\u6a23\u5316\u7684\u8996\u89ba\u77e5\u8b58\uff0c\u589e\u5f37\u4e0b\u6e38\u6a5f\u5668\u4eba\u5b78\u7fd2\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\uff0cTheia \u4f7f\u7528\u8f03\u5c11\u7684\u8a13\u7df4\u8cc7\u6599\u548c\u8f03\u5c0f\u7684\u6a21\u578b\u5927\u5c0f\uff0c\u5c31\u80fd\u8d85\u8d8a\u5176\u6559\u5e2b\u6a21\u578b\u548c\u5148\u524d\u7684\u6a5f\u5668\u4eba\u5b78\u7fd2\u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u5011\u91cf\u5316\u9810\u8a13\u7df4\u8996\u89ba\u8868\u5fb5\u7684\u54c1\u8cea\uff0c\u4e26\u5047\u8a2d\u7279\u5fb5\u7bc4\u6578\u5206\u4f48\u4e2d\u8f03\u9ad8\u7684\u71b5\u6703\u5e36\u4f86\u6539\u5584\u7684\u6a5f\u5668\u4eba\u5b78\u7fd2\u6548\u80fd\u3002\u7a0b\u5f0f\u78bc\u548c\u6a21\u578b\u53ef\u5728 https://github.com/bdaiinstitute/theia \u53d6\u5f97\u3002", "author": "Jinghuan Shang et.al.", "authors": "Jinghuan Shang, Karl Schmeckpeper, Brandon B. May, Maria Vittoria Minniti, Tarik Kelestemur, David Watkins, Laura Herlant", "id": "2407.20179v1", "paper_url": "http://arxiv.org/abs/2407.20179v1", "repo": "https://github.com/bdaiinstitute/theia"}}