{"2502.15398": {"publish_time": "2025-02-21", "title": "Enhancing Vehicle Make and Model Recognition with 3D Attention Modules", "paper_summary": "Vehicle make and model recognition (VMMR) is a crucial component of the\nIntelligent Transport System, garnering significant attention in recent years.\nVMMR has been widely utilized for detecting suspicious vehicles, monitoring\nurban traffic, and autonomous driving systems. The complexity of VMMR arises\nfrom the subtle visual distinctions among vehicle models and the wide variety\nof classes produced by manufacturers. Convolutional Neural Networks (CNNs), a\nprominent type of deep learning model, have been extensively employed in\nvarious computer vision tasks, including VMMR, yielding remarkable results. As\nVMMR is a fine-grained classification problem, it primarily faces inter-class\nsimilarity and intra-class variation challenges. In this study, we implement an\nattention module to address these challenges and enhance the model's focus on\ncritical areas containing distinguishing features. This module, which does not\nincrease the parameters of the original model, generates three-dimensional\n(3-D) attention weights to refine the feature map. Our proposed model\nintegrates the attention module into two different locations within the middle\nsection of a convolutional model, where the feature maps from these sections\noffer sufficient information about the input frames without being overly\ndetailed or overly coarse. The performance of our proposed model, along with\nstate-of-the-art (SOTA) convolutional and transformer-based models, was\nevaluated using the Stanford Cars dataset. Our proposed model achieved the\nhighest accuracy, 90.69\\%, among the compared models.", "paper_summary_zh": "\u8eca\u8f1b\u5ee0\u724c\u548c\u578b\u865f\u8fa8\u8b58 (VMMR) \u662f\u667a\u6167\u904b\u8f38\u7cfb\u7d71\u7684\u91cd\u8981\u7d44\u6210\u90e8\u5206\uff0c\u8fd1\u5e74\u4f86\u5099\u53d7\u95dc\u6ce8\u3002VMMR \u5df2\u5ee3\u6cdb\u7528\u65bc\u5075\u6e2c\u53ef\u7591\u8eca\u8f1b\u3001\u76e3\u63a7\u5e02\u5340\u4ea4\u901a\u548c\u81ea\u52d5\u99d5\u99db\u7cfb\u7d71\u3002VMMR \u7684\u8907\u96dc\u6027\u6e90\u65bc\u8eca\u8f1b\u578b\u865f\u9593\u7d30\u5fae\u7684\u8996\u89ba\u5dee\u7570\uff0c\u4ee5\u53ca\u88fd\u9020\u5546\u751f\u7522\u7684\u7a2e\u985e\u7e41\u591a\u3002\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN) \u662f\u4e00\u7a2e\u8457\u540d\u7684\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u985e\u578b\uff0c\u5df2\u5ee3\u6cdb\u7528\u65bc\u5404\u7a2e\u96fb\u8166\u8996\u89ba\u4efb\u52d9\uff0c\u5305\u62ec VMMR\uff0c\u4e26\u53d6\u5f97\u986f\u8457\u6210\u679c\u3002\u7531\u65bc VMMR \u662f\u7d30\u7c92\u5ea6\u5206\u985e\u554f\u984c\uff0c\u56e0\u6b64\u5b83\u4e3b\u8981\u9762\u81e8\u985e\u9593\u76f8\u4f3c\u6027\u548c\u985e\u5167\u5dee\u7570\u7684\u6311\u6230\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u5be6\u4f5c\u4e86\u4e00\u500b\u6ce8\u610f\u529b\u6a21\u7d44\u4f86\u89e3\u6c7a\u9019\u4e9b\u6311\u6230\uff0c\u4e26\u589e\u5f37\u6a21\u578b\u5c0d\u5305\u542b\u5340\u5225\u7279\u5fb5\u7684\u95dc\u9375\u5340\u57df\u7684\u95dc\u6ce8\u3002\u6b64\u6a21\u7d44\u4e0d\u6703\u589e\u52a0\u539f\u59cb\u6a21\u578b\u7684\u53c3\u6578\uff0c\u6703\u7522\u751f\u4e09\u7dad (3-D) \u6ce8\u610f\u529b\u6b0a\u91cd\u4f86\u6539\u5584\u7279\u5fb5\u5716\u3002\u6211\u5011\u63d0\u51fa\u7684\u6a21\u578b\u5c07\u6ce8\u610f\u529b\u6a21\u7d44\u6574\u5408\u5230\u5377\u7a4d\u6a21\u578b\u4e2d\u9593\u90e8\u5206\u7684\u5169\u500b\u4e0d\u540c\u4f4d\u7f6e\uff0c\u9019\u4e9b\u5340\u6bb5\u7684\u7279\u5fb5\u5716\u63d0\u4f9b\u4e86\u8f38\u5165\u5e40\u7684\u5145\u8db3\u8cc7\u8a0a\uff0c\u4e0d\u6703\u904e\u65bc\u8a73\u7d30\u6216\u904e\u65bc\u7c97\u7565\u3002\u6211\u5011\u63d0\u51fa\u7684\u6a21\u578b\u7684\u6548\u80fd\uff0c\u4ee5\u53ca\u6700\u5148\u9032 (SOTA) \u7684\u5377\u7a4d\u548c\u57fa\u65bcTransformer\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u53f2\u4e39\u4f5b\u6c7d\u8eca\u8cc7\u6599\u96c6\u9032\u884c\u8a55\u4f30\u3002\u6211\u5011\u63d0\u51fa\u7684\u6a21\u578b\u5728\u6bd4\u8f03\u6a21\u578b\u4e2d\u9054\u5230\u6700\u9ad8\u7684\u6e96\u78ba\u5ea6\uff0c\u70ba 90.69%\u3002", "author": "Narges Semiromizadeh et.al.", "authors": "Narges Semiromizadeh, Omid Nejati Manzari, Shahriar B. Shokouhi, Sattar Mirzakuchaki", "id": "2502.15398v1", "paper_url": "http://arxiv.org/abs/2502.15398v1", "repo": "null"}}