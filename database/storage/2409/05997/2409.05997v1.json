{"2409.05997": {"publish_time": "2024-09-09", "title": "TransformerRanker: A Tool for Efficiently Finding the Best-Suited Language Models for Downstream Classification Tasks", "paper_summary": "Classification tasks in NLP are typically addressed by selecting a\npre-trained language model (PLM) from a model hub, and fine-tuning it for the\ntask at hand. However, given the very large number of PLMs that are currently\navailable, a practical challenge is to determine which of them will perform\nbest for a specific downstream task. With this paper, we introduce\nTransformerRanker, a lightweight library that efficiently ranks PLMs for\nclassification tasks without the need for computationally costly fine-tuning.\nOur library implements current approaches for transferability estimation\n(LogME, H-Score, kNN), in combination with layer aggregation options, which we\nempirically showed to yield state-of-the-art rankings of PLMs (Garbas et al.,\n2024). We designed the interface to be lightweight and easy to use, allowing\nusers to directly connect to the HuggingFace Transformers and Dataset\nlibraries. Users need only select a downstream classification task and a list\nof PLMs to create a ranking of likely best-suited PLMs for their task. We make\nTransformerRanker available as a pip-installable open-source library\nhttps://github.com/flairNLP/transformer-ranker.", "paper_summary_zh": "NLP \u4e2d\u7684\u5206\u985e\u4efb\u52d9\u901a\u5e38\u900f\u904e\u5f9e\u6a21\u578b\u4e2d\u5fc3\u9078\u64c7\u9810\u5148\u8a13\u7df4\u597d\u7684\u8a9e\u8a00\u6a21\u578b (PLM)\uff0c\u4e26\u91dd\u5c0d\u624b\u908a\u7684\u4efb\u52d9\u9032\u884c\u5fae\u8abf\u4f86\u8655\u7406\u3002\u7136\u800c\uff0c\u8003\u91cf\u5230\u76ee\u524d\u53ef\u7528\u7684 PLM \u6578\u91cf\u9f90\u5927\uff0c\u4e00\u500b\u5be6\u969b\u7684\u6311\u6230\u662f\u8981\u627e\u51fa\u54ea\u500b PLM \u5c0d\u65bc\u7279\u5b9a\u4e0b\u6e38\u4efb\u52d9\u7684\u57f7\u884c\u6210\u6548\u6700\u4f73\u3002\u900f\u904e\u9019\u7bc7\u8ad6\u6587\uff0c\u6211\u5011\u5f15\u5165\u4e86 TransformerRanker\uff0c\u9019\u662f\u4e00\u500b\u8f15\u91cf\u7d1a\u7684\u7a0b\u5f0f\u5eab\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5c0d PLM \u9032\u884c\u5206\u985e\u4efb\u52d9\u6392\u540d\uff0c\u800c\u7121\u9700\u9032\u884c\u8a08\u7b97\u6210\u672c\u9ad8\u6602\u7684\u5fae\u8abf\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u5eab\u5be6\u4f5c\u4e86\u76ee\u524d\u7528\u65bc\u53ef\u8f49\u79fb\u6027\u4f30\u8a08\u7684\u65b9\u6cd5 (LogME\u3001H \u5206\u6578\u3001kNN)\uff0c\u4e26\u7d50\u5408\u4e86\u5c64\u805a\u5408\u9078\u9805\uff0c\u6211\u5011\u900f\u904e\u5be6\u8b49\u8b49\u660e\u53ef\u7522\u751f PLM \u7684\u6700\u5148\u9032\u6392\u540d (Garbas \u7b49\u4eba\uff0c2024)\u3002\u6211\u5011\u8a2d\u8a08\u4e86\u9019\u500b\u4ecb\u9762\uff0c\u4f7f\u5176\u8f15\u91cf\u4e14\u6613\u65bc\u4f7f\u7528\uff0c\u8b93\u4f7f\u7528\u8005\u53ef\u4ee5\u76f4\u63a5\u9023\u63a5\u5230 HuggingFace Transformers \u548c Dataset \u7a0b\u5f0f\u5eab\u3002\u4f7f\u7528\u8005\u53ea\u9700\u9078\u64c7\u4e00\u500b\u4e0b\u6e38\u5206\u985e\u4efb\u52d9\u548c\u4e00\u500b PLM \u6e05\u55ae\uff0c\u5373\u53ef\u70ba\u4efb\u52d9\u5efa\u7acb\u4e00\u500b\u53ef\u80fd\u6700\u9069\u5408\u7684 PLM \u6392\u540d\u3002\u6211\u5011\u5c07 TransformerRanker \u4f5c\u70ba\u4e00\u500b\u53ef\u900f\u904e pip \u5b89\u88dd\u7684\u958b\u6e90\u7a0b\u5f0f\u5eab\u63d0\u4f9b https://github.com/flairNLP/transformer-ranker\u3002", "author": "Lukas Garbas et.al.", "authors": "Lukas Garbas, Max Ploner, Alan Akbik", "id": "2409.05997v1", "paper_url": "http://arxiv.org/abs/2409.05997v1", "repo": "https://github.com/flairnlp/transformer-ranker"}}