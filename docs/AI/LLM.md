
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-20**|**NeCo: Improving DINOv2's spatial representations in 19 GPU hours with Patch Neighbor Consistency**|Valentinos Pariza et.al.|[2408.11054v1](http://arxiv.org/abs/2408.11054v1)|null|
|**2024-08-20**|**Revisiting VerilogEval: Newer LLMs, In-Context Learning, and Specification-to-RTL Tasks**|Nathaniel Pinckney et.al.|[2408.11053v1](http://arxiv.org/abs/2408.11053v1)|null|
|**2024-08-20**|**FLAME: Learning to Navigate with Multimodal LLM in Urban Environments**|Yunzhe Xu et.al.|[2408.11051v1](http://arxiv.org/abs/2408.11051v1)|[link](https://github.com/xyz9911/FLAME)|
|**2024-08-20**|**MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding**|Jian Chen et.al.|[2408.11049v2](http://arxiv.org/abs/2408.11049v2)|null|
|**2024-08-20**|**Inside the Black Box: Detecting Data Leakage in Pre-trained Language Encoders**|Yuan Xin et.al.|[2408.11046v1](http://arxiv.org/abs/2408.11046v1)|null|
|**2024-08-20**|**Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research**|Sreyoshi Bhaduri et.al.|[2408.11043v1](http://arxiv.org/abs/2408.11043v1)|null|
|**2024-08-20**|**Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model**|Chunting Zhou et.al.|[2408.11039v1](http://arxiv.org/abs/2408.11039v1)|null|
|**2024-08-20**|**Scaling Law with Learning Rate Annealing**|Howe Tissue et.al.|[2408.11029v1](http://arxiv.org/abs/2408.11029v1)|null|
|**2024-08-20**|**Athena: Safe Autonomous Agents with Verbal Contrastive Learning**|Tanmana Sadhu et.al.|[2408.11021v1](http://arxiv.org/abs/2408.11021v1)|null|
|**2024-08-20**|**While GitHub Copilot Excels at Coding, Does It Ensure Responsible Output?**|Wen Cheng et.al.|[2408.11006v1](http://arxiv.org/abs/2408.11006v1)|[link](https://github.com/sensente/security-attacks-on-lccts)|
|**2024-08-20**|**CTP-LLM: Clinical Trial Phase Transition Prediction Using Large Language Models**|Michael Reinisch et.al.|[2408.10995v1](http://arxiv.org/abs/2408.10995v1)|null|
|**2024-08-20**|**Denoising Plane Wave Ultrasound Images Using Diffusion Probabilistic Models**|Hojat Asgariandehkordi et.al.|[2408.10987v1](http://arxiv.org/abs/2408.10987v1)|null|
|**2024-08-20**|**The fusion of phonography and ideographic characters into virtual Chinese characters -- Based on Chinese and English**|Hongfa Zi et.al.|[2408.10979v1](http://arxiv.org/abs/2408.10979v1)|null|
|**2024-08-20**|**Hybrid Recurrent Models Support Emergent Descriptions for Hierarchical Planning and Control**|Poppy Collis et.al.|[2408.10970v1](http://arxiv.org/abs/2408.10970v1)|null|
|**2024-08-20**|**NLP for The Greek Language: A Longer Survey**|Katerina Papantoniou et.al.|[2408.10962v1](http://arxiv.org/abs/2408.10962v1)|null|
|**2024-08-20**|**Wave-Mask/Mix: Exploring Wavelet-Based Augmentations for Time Series Forecasting**|Dona Arabi et.al.|[2408.10951v1](http://arxiv.org/abs/2408.10951v1)|[link](https://github.com/jafarbakhshaliyev/wave-augs)|
|**2024-08-20**|**GAIM: Attacking Graph Neural Networks via Adversarial Influence Maximization**|Xiaodong Yang et.al.|[2408.10948v1](http://arxiv.org/abs/2408.10948v1)|null|
|**2024-08-20**|**Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models**|Yuyan Chen et.al.|[2408.10947v1](http://arxiv.org/abs/2408.10947v1)|null|
|**2024-08-20**|**Large Language Model Driven Recommendation**|Anton Korikov et.al.|[2408.10946v1](http://arxiv.org/abs/2408.10946v1)|null|
|**2024-08-20**|**HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models in Resource-Constrained Environments**|Kazi Hasan Ibn Arif et.al.|[2408.10945v1](http://arxiv.org/abs/2408.10945v1)|[link](https://github.com/hasanar1f/hired)|
|**2024-08-20**|**SysBench: Can Large Language Models Follow System Messages?**|Yanzhao Qin et.al.|[2408.10943v1](http://arxiv.org/abs/2408.10943v1)|[link](https://github.com/pku-baichuan-mlsystemlab/sysbench)|
|**2024-08-20**|**A Closer Look at Data Augmentation Strategies for Finetuning-Based Low/Few-Shot Object Detection**|Vladislav Li et.al.|[2408.10940v1](http://arxiv.org/abs/2408.10940v1)|null|
|**2024-08-20**|**SDI-Net: Toward Sufficient Dual-View Interaction for Low-light Stereo Image Enhancement**|Linlin Hu et.al.|[2408.10934v1](http://arxiv.org/abs/2408.10934v1)|null|
|**2024-08-20**|**LBC: Language-Based-Classifier for Out-Of-Variable Generalization**|Kangjun Noh et.al.|[2408.10923v2](http://arxiv.org/abs/2408.10923v2)|null|
|**2024-08-20**|**MTFinEval:A Multi-domain Chinese Financial Benchmark with Eurypalynous questions**|Xinyu Liu et.al.|[2408.10921v1](http://arxiv.org/abs/2408.10921v1)|null|
|**2024-08-20**|**Recurrent Neural Networks Learn to Store and Generate Sequences using Non-Linear Representations**|Róbert Csordás et.al.|[2408.10920v1](http://arxiv.org/abs/2408.10920v1)|[link](https://github.com/robertcsordas/onion_representations)|
|**2024-08-20**|**CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network**|Zijian Zhao et.al.|[2408.10919v2](http://arxiv.org/abs/2408.10919v2)|null|
|**2024-08-20**|**CHECKWHY: Causal Fact Verification via Argument Structure**|Jiasheng Si et.al.|[2408.10918v1](http://arxiv.org/abs/2408.10918v1)|null|
|**2024-08-20**|**To Code, or Not To Code? Exploring Impact of Code in Pre-training**|Viraat Aryabumi et.al.|[2408.10914v1](http://arxiv.org/abs/2408.10914v1)|null|
|**2024-08-20**|**The impact of labeling automotive AI as "trustworthy" or "reliable" on user evaluation and technology acceptance**|John Dorsch et.al.|[2408.10905v1](http://arxiv.org/abs/2408.10905v1)|null|
|**2024-08-20**|**BEYOND DIALOGUE: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model**|Yeyong Yu et.al.|[2408.10903v2](http://arxiv.org/abs/2408.10903v2)|null|
|**2024-08-20**|**Soda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs**|John Mendonça et.al.|[2408.10902v1](http://arxiv.org/abs/2408.10902v1)|null|
|**2024-08-20**|**A Grey-box Attack against Latent Diffusion Model-based Image Editing by Posterior Collapse**|Zhongliang Guo et.al.|[2408.10901v1](http://arxiv.org/abs/2408.10901v1)|null|
|**2024-08-20**|**Towards Efficient Formal Verification of Spiking Neural Network**|Baekryun Seong et.al.|[2408.10900v1](http://arxiv.org/abs/2408.10900v1)|null|
|**2024-08-20**|**Analytical and Empirical Study of Herding Effects in Recommendation Systems**|Hong Xie et.al.|[2408.10895v1](http://arxiv.org/abs/2408.10895v1)|null|
|**2024-08-20**|**On Learning Action Costs from Input Plans**|Marianela Morales et.al.|[2408.10889v1](http://arxiv.org/abs/2408.10889v1)|null|
|**2024-08-20**|**DAAD: Dynamic Analysis and Adaptive Discriminator for Fake News Detection**|Xinqi Su et.al.|[2408.10883v1](http://arxiv.org/abs/2408.10883v1)|[link](https://github.com/suxinqi/daad)|
|**2024-08-20**|**V-RoAst: A New Dataset for Visual Road Assessment**|Natchapon Jongwiriyanurak et.al.|[2408.10872v2](http://arxiv.org/abs/2408.10872v2)|null|
|**2024-08-20**|**Multi-agent Multi-armed Bandits with Stochastic Sharable Arm Capacities**|Hong Xie et.al.|[2408.10865v1](http://arxiv.org/abs/2408.10865v1)|null|
|**2024-08-20**|**MambaDS: Near-Surface Meteorological Field Downscaling with Topography Constrained Selective State Space Modeling**|Zili Liu et.al.|[2408.10854v1](http://arxiv.org/abs/2408.10854v1)|null|
|**2024-08-20**|**Does Current Deepfake Audio Detection Model Effectively Detect ALM-based Deepfake Audio?**|Yuankun Xie et.al.|[2408.10853v1](http://arxiv.org/abs/2408.10853v1)|[link](https://github.com/xieyuankun/alm-add)|
|**2024-08-20**|**Benchmarking Large Language Models for Math Reasoning Tasks**|Kathrin Seßler et.al.|[2408.10839v1](http://arxiv.org/abs/2408.10839v1)|null|
|**2024-08-20**|**ZebraPose: Zebra Detection and Pose Estimation using only Synthetic Data**|Elia Bonetto et.al.|[2408.10831v1](http://arxiv.org/abs/2408.10831v1)|null|
|**2024-08-20**|**Exploiting Large Language Models Capabilities for Question Answer-Driven Knowledge Graph Completion Across Static and Temporal Domains**|Rui Yang et.al.|[2408.10819v1](http://arxiv.org/abs/2408.10819v1)|null|
|**2024-08-20**|**Beyond English-Centric LLMs: What Language Do Multilingual Language Models Think in?**|Chengzhi Zhong et.al.|[2408.10811v1](http://arxiv.org/abs/2408.10811v1)|null|
|**2024-08-20**|**ColBERT Retrieval and Ensemble Response Scoring for Language Model Question Answering**|Alex Gichamba et.al.|[2408.10808v1](http://arxiv.org/abs/2408.10808v1)|null|
|**2024-08-20**|**DisMix: Disentangling Mixtures of Musical Instruments for Source-level Pitch and Timbre Manipulation**|Yin-Jyun Luo et.al.|[2408.10807v1](http://arxiv.org/abs/2408.10807v1)|null|
|**2024-08-20**|**Inverse Deep Learning Ray Tracing for Heliostat Surface Prediction**|Jan Lewen et.al.|[2408.10802v1](http://arxiv.org/abs/2408.10802v1)|null|
|**2024-08-20**|**Adversarial Attack for Explanation Robustness of Rationalization Models**|Yuankai Zhang et.al.|[2408.10795v1](http://arxiv.org/abs/2408.10795v1)|null|
|**2024-08-20**|**Just a Hint: Point-Supervised Camouflaged Object Detection**|Huafeng Chen et.al.|[2408.10777v1](http://arxiv.org/abs/2408.10777v1)|null|
|**2024-08-20**|**Flexora: Flexible Low Rank Adaptation for Large Language Models**|Chenxing Wei et.al.|[2408.10774v2](http://arxiv.org/abs/2408.10774v2)|null|
|**2024-08-20**|**SSL-TTS: Leveraging Self-Supervised Embeddings and kNN Retrieval for Zero-Shot Multi-speaker TTS**|Karl El Hajal et.al.|[2408.10771v1](http://arxiv.org/abs/2408.10771v1)|null|
|**2024-08-20**|**Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model**|Chenhan Yuan et.al.|[2408.10764v1](http://arxiv.org/abs/2408.10764v1)|null|
|**2024-08-20**|**SAM-COD: SAM-guided Unified Framework for Weakly-Supervised Camouflaged Object Detection**|Huafeng Chen et.al.|[2408.10760v1](http://arxiv.org/abs/2408.10760v1)|null|
|**2024-08-20**|**Generating Synthetic Fair Syntax-agnostic Data by Learning and Distilling Fair Representation**|Md Fahim Sikder et.al.|[2408.10755v1](http://arxiv.org/abs/2408.10755v1)|null|
|**2024-08-20**|**Security Assessment of Hierarchical Federated Deep Learning**|D Alqattan et.al.|[2408.10752v1](http://arxiv.org/abs/2408.10752v1)|null|
|**2024-08-20**|**Pluto and Charon: A Time and Memory Efficient Collaborative Edge AI Framework for Personal LLMs Fine-Tuning**|Bei Ouyang et.al.|[2408.10746v1](http://arxiv.org/abs/2408.10746v1)|null|
|**2024-08-20**|**Towards Efficient Large Language Models for Scientific Text: A Review**|Huy Quoc To et.al.|[2408.10729v1](http://arxiv.org/abs/2408.10729v1)|null|
|**2024-08-20**|**Crafting Tomorrow's Headlines: Neural News Generation and Detection in English, Turkish, Hungarian, and Persian**|Cem Üyük et.al.|[2408.10724v1](http://arxiv.org/abs/2408.10724v1)|null|
|**2024-08-20**|**MEGen: Generative Backdoor in Large Language Models via Model Editing**|Jiyang Qiu et.al.|[2408.10722v1](http://arxiv.org/abs/2408.10722v1)|null|
|**2024-08-20**|**Towards Foundation Models for the Industrial Forecasting of Chemical Kinetics**|Imran Nasim et.al.|[2408.10720v1](http://arxiv.org/abs/2408.10720v1)|null|
|**2024-08-20**|**CodeJudge-Eval: Can Large Language Models be Good Judges in Code Understanding?**|Yuwei Zhao et.al.|[2408.10718v1](http://arxiv.org/abs/2408.10718v1)|[link](https://github.com/codellm-research/codejudge-eval)|
|**2024-08-20**|**Fine-Tuning a Local LLaMA-3 Large Language Model for Automated Privacy-Preserving Physician Letter Generation in Radiation Oncology**|Yihao Hou et.al.|[2408.10715v1](http://arxiv.org/abs/2408.10715v1)|null|
|**2024-08-20**|**Offline Model-Based Reinforcement Learning with Anti-Exploration**|Padmanaba Srinivasan et.al.|[2408.10713v1](http://arxiv.org/abs/2408.10713v1)|null|
|**2024-08-20**|**Investigating Context Effects in Similarity Judgements in Large Language Models**|Sagar Uprety et.al.|[2408.10711v1](http://arxiv.org/abs/2408.10711v1)|null|
|**2024-08-20**|**Coarse-to-Fine Detection of Multiple Seams for Robotic Welding**|Pengkun Wei et.al.|[2408.10710v1](http://arxiv.org/abs/2408.10710v1)|null|
|**2024-08-20**|**Ferret: Faster and Effective Automated Red Teaming with Reward-Based Scoring Technique**|Tej Deep Pala et.al.|[2408.10701v1](http://arxiv.org/abs/2408.10701v1)|[link](https://github.com/declare-lab/ferret)|
|**2024-08-20**|**AnyGraph: Graph Foundation Model in the Wild**|Lianghao Xia et.al.|[2408.10700v1](http://arxiv.org/abs/2408.10700v1)|[link](https://github.com/hkuds/anygraph)|
|**2024-08-20**|**Unconditional Truthfulness: Learning Conditional Dependency for Uncertainty Quantification of Large Language Models**|Artem Vazhentsev et.al.|[2408.10692v1](http://arxiv.org/abs/2408.10692v1)|null|
|**2024-08-20**|**Fine-Tuning and Deploying Large Language Models Over Edges: Issues and Approaches**|Yanjie Dong et.al.|[2408.10691v1](http://arxiv.org/abs/2408.10691v1)|null|
|**2024-08-20**|**Genesis: Towards the Automation of Systems Biology Research**|Ievgeniia A. Tiukova et.al.|[2408.10689v1](http://arxiv.org/abs/2408.10689v1)|null|
|**2024-08-20**|**Rejection in Abstract Argumentation: Harder Than Acceptance?**|Johannes K. Fichte et.al.|[2408.10683v1](http://arxiv.org/abs/2408.10683v1)|null|
|**2024-08-20**|**Towards Robust Knowledge Unlearning: An Adversarial Framework for Assessing and Improving Unlearning Robustness in Large Language Models**|Hongbang Yuan et.al.|[2408.10682v1](http://arxiv.org/abs/2408.10682v1)|null|
|**2024-08-20**|**HMoE: Heterogeneous Mixture of Experts for Language Modeling**|An Wang et.al.|[2408.10681v1](http://arxiv.org/abs/2408.10681v1)|null|
|**2024-08-20**|**Towards Rehearsal-Free Multilingual ASR: A LoRA-based Case Study on Whisper**|Tianyi Xu et.al.|[2408.10680v1](http://arxiv.org/abs/2408.10680v1)|null|
|**2024-08-20**|**Tensor tree learns hidden relational structures in data to construct generative models**|Kenji Harada et.al.|[2408.10669v1](http://arxiv.org/abs/2408.10669v1)|null|
|**2024-08-20**|**Probing the Safety Response Boundary of Large Language Models via Unsafe Decoding Path Generation**|Haoyu Wang et.al.|[2408.10668v2](http://arxiv.org/abs/2408.10668v2)|null|
|**2024-08-20**|**REInstruct: Building Instruction Data from Unlabeled Corpus**|Shu Chen et.al.|[2408.10663v1](http://arxiv.org/abs/2408.10663v1)|[link](https://github.com/cs32963/reinstruct)|
|**2024-08-20**|**ETGuard: Malicious Encrypted Traffic Detection in Blockchain-based Power Grid Systems**|Peng Zhou et.al.|[2408.10657v1](http://arxiv.org/abs/2408.10657v1)|[link](https://github.com/pppmzt/etguard)|
|**2024-08-20**|**Vocabulary-Free 3D Instance Segmentation with Vision and Language Assistant**|Guofeng Mei et.al.|[2408.10652v1](http://arxiv.org/abs/2408.10652v1)|null|
|**2024-08-20**|**Inferring Underwater Topography with FINN**|Coşku Can Horuz et.al.|[2408.10649v1](http://arxiv.org/abs/2408.10649v1)|null|
|**2024-08-20**|**Privacy-preserving Universal Adversarial Defense for Black-box Models**|Qiao Li et.al.|[2408.10647v1](http://arxiv.org/abs/2408.10647v1)|null|
|**2024-08-20**|**Beneath the Surface of Consistency: Exploring Cross-lingual Knowledge Representation Sharing in LLMs**|Maxim Ifergan et.al.|[2408.10646v1](http://arxiv.org/abs/2408.10646v1)|null|
|**2024-08-20**|**Minor SFT loss for LLM fine-tune to increase performance and reduce model deviation**|Shiming Xie et.al.|[2408.10642v1](http://arxiv.org/abs/2408.10642v1)|null|
|**2024-08-20**|**A Review of Human-Object Interaction Detection**|Yuxiao Wang et.al.|[2408.10641v1](http://arxiv.org/abs/2408.10641v1)|null|
|**2024-08-20**|**Strategist: Learning Strategic Skills by LLMs via Bi-Level Tree Search**|Jonathan Light et.al.|[2408.10635v1](http://arxiv.org/abs/2408.10635v1)|null|
|**2024-08-20**|**LLM-Barber: Block-Aware Rebuilder for Sparsity Mask in One-Shot for Large Language Models**|Yupeng Su et.al.|[2408.10631v1](http://arxiv.org/abs/2408.10631v1)|null|
|**2024-08-20**|**Finding the DeepDream for Time Series: Activation Maximization for Univariate Time Series**|Udo Schlegel et.al.|[2408.10628v1](http://arxiv.org/abs/2408.10628v1)|null|
|**2024-08-20**|**Novel Change Detection Framework in Remote Sensing Imagery Using Diffusion Models and Structural Similarity Index (SSIM)**|Andrew Kiruluta et.al.|[2408.10619v1](http://arxiv.org/abs/2408.10619v1)|null|
|**2024-08-20**|**OMEGA: Efficient Occlusion-Aware Navigation for Air-Ground Robot in Dynamic Environments via State Space Model**|Junming Wang et.al.|[2408.10618v1](http://arxiv.org/abs/2408.10618v1)|null|
|**2024-08-20**|**Enhancing Robustness in Large Language Models: Prompting for Mitigating the Impact of Irrelevant Information**|Ming Jiang et.al.|[2408.10615v1](http://arxiv.org/abs/2408.10615v1)|null|
|**2024-08-20**|**Generalizable Facial Expression Recognition**|Yuhang Zhang et.al.|[2408.10614v1](http://arxiv.org/abs/2408.10614v1)|[link](https://github.com/zyh-uaiaaaa/generalizable-fer)|
|**2024-08-20**|**Promoting Equality in Large Language Models: Identifying and Mitigating the Implicit Bias based on Bayesian Theory**|Yongxin Deng et.al.|[2408.10608v1](http://arxiv.org/abs/2408.10608v1)|null|
|**2024-08-20**|**MUSES: 3D-Controllable Image Generation via Multi-Modal Agent Collaboration**|Yanbo Ding et.al.|[2408.10605v2](http://arxiv.org/abs/2408.10605v2)|null|
|**2024-08-20**|**Multilingual Non-Factoid Question Answering with Silver Answers**|Ritwik Mishra et.al.|[2408.10604v1](http://arxiv.org/abs/2408.10604v1)|null|
|**2024-08-20**|**MV-MOS: Multi-View Feature Fusion for 3D Moving Object Segmentation**|Jintao Cheng et.al.|[2408.10602v1](http://arxiv.org/abs/2408.10602v1)|null|
|**2024-08-20**|**Breast tumor classification based on self-supervised contrastive learning from ultrasound videos**|Yunxin Tang et.al.|[2408.10600v1](http://arxiv.org/abs/2408.10600v1)|null|
|**2024-08-20**|**An Efficient Sign Language Translation Using Spatial Configuration and Motion Dynamics with LLMs**|Eui Jun Hwang et.al.|[2408.10593v1](http://arxiv.org/abs/2408.10593v1)|null|
|**2024-08-20**|**Hologram Reasoning for Solving Algebra Problems with Geometry Diagrams**|Litian Huang et.al.|[2408.10592v1](http://arxiv.org/abs/2408.10592v1)|[link](https://github.com/ferretdoll/hgr)|
|**2024-08-20**|**Putting People in LLMs' Shoes: Generating Better Answers via Question Rewriter**|Junhao Chen et.al.|[2408.10573v1](http://arxiv.org/abs/2408.10573v1)|[link](https://github.com/3244we/question-rewriter)|

#### Abstracts
##### **NeCo: Improving DINOv2's spatial representations in 19 GPU hours with Patch Neighbor Consistency**
2408.11054v1 by Valentinos Pariza, Mohammadreza Salehi, Gertjan Burghouts, Francesco Locatello, Yuki M. Asano

We propose sorting patch representations across views as a novel
self-supervised learning signal to improve pretrained representations. To this
end, we introduce NeCo: Patch Neighbor Consistency, a novel training loss that
enforces patch-level nearest neighbor consistency across a student and teacher
model, relative to reference batches. Our method leverages a differentiable
sorting method applied on top of pretrained representations, such as
DINOv2-registers to bootstrap the learning signal and further improve upon
them. This dense post-pretraining leads to superior performance across various
models and datasets, despite requiring only 19 hours on a single GPU. We
demonstrate that this method generates high-quality dense feature encoders and
establish several new state-of-the-art results: +5.5% and + 6% for
non-parametric in-context semantic segmentation on ADE20k and Pascal VOC, and
+7.2% and +5.7% for linear segmentation evaluations on COCO-Things and -Stuff.

摘要：我們提出對跨視圖的 patch 表示進行排序，作為一種新穎的自監督學習訊號，以改善預訓練的表示。為此，我們引入了 NeCo：Patch Neighbor Consistency，一種新穎的訓練損失，它在學生和教師模型中執行 patch 層級最近鄰一致性，相對於參考批次。我們的模型利用了應用於預訓練表示之上的可微分排序方法，例如 DINOv2-registers，以引導學習訊號並進一步改進它們。儘管僅在單個 GPU 上需要 19 小時，但這種密集的預訓練後訓練仍可在各種模型和資料集上帶來卓越的效能。我們證明了這種方法會產生高品質的密集特徵編碼器，並建立了幾個新的最先進的結果：ADE20k 和 Pascal VOC 上非參數情境內語意分割的 +5.5% 和 +6%，以及 COCO-Things 和 -Stuff 上線性分割評估的 +7.2% 和 +5.7%。

##### **Revisiting VerilogEval: Newer LLMs, In-Context Learning, and Specification-to-RTL Tasks**
2408.11053v1 by Nathaniel Pinckney, Christopher Batten, Mingjie Liu, Haoxing Ren, Brucek Khailany

The application of large-language models (LLMs) to digital hardware code
generation is an emerging field. Most LLMs are primarily trained on natural
language and software code. Hardware code, such as Verilog, represents only a
small portion of the training data and few hardware benchmarks exist. To
address this gap, the open-source VerilogEval benchmark was released in 2023,
providing a consistent evaluation framework for LLMs on code completion tasks.
It was tested on state-of-the-art models at the time including GPT-4. However,
VerilogEval and other Verilog generation benchmarks lack failure analysis and,
in present form, are not conducive to exploring prompting techniques. Also,
since VerilogEval's release, both commercial and open-source models have seen
continued development.
  In this work, we evaluate new commercial and open-source models of varying
sizes against an improved VerilogEval benchmark suite. We enhance VerilogEval's
infrastructure and dataset by automatically classifying failures, introduce new
prompts for supporting in-context learning (ICL) examples, and extend the
supported tasks to specification-to-RTL translation. We find a measurable
improvement in commercial state-of-the-art models, with GPT-4 Turbo achieving a
59% pass rate on spec-to-RTL tasks. We also study the performance of
open-source and domain-specific models that have emerged, and demonstrate that
models can benefit substantially from ICL. We find that recently-released Llama
3.1 405B achieves a pass rate of 58%, effectively matching that of GPT-4 Turbo,
and that the much smaller domain-specific RTL-Coder 6.7B models achieve an
impressive 37% pass rate. However, prompt engineering is key to achieving good
pass rates, and varies widely with model and task. A benchmark infrastructure
that allows for prompt engineering and failure analysis is key to continued
model development and deployment.

摘要：大型語言模型 (LLM) 在數位硬體程式碼產生中的應用是一個新興領域。大多數的 LLM 主要是在自然語言和軟體程式碼上訓練。硬體程式碼，例如 Verilog，只佔訓練資料的一小部分，而且只有少數硬體基準測試存在。為了解決這個差距，開放原始碼的 VerilogEval 基準測試於 2023 年發布，為 LLM 在程式碼完成任務上提供了一個一致的評估架構。它在當時最先進的模型上進行了測試，包括 GPT-4。然而，VerilogEval 和其他 Verilog 產生基準測試缺乏故障分析，而且以目前的型式，不利於探索提示技術。此外，自 VerilogEval 發布以來，商業和開放原始碼模型都持續發展。
在這項工作中，我們針對改良的 VerilogEval 基準測試套件評估各種規模的新商業和開放原始碼模型。我們透過自動分類故障來增強 VerilogEval 的基礎架構和資料集，引入新的提示來支援情境學習 (ICL) 範例，並將支援的任務擴充到規格到 RTL 的轉換。我們發現商業最先進的模型有顯著的進步，GPT-4 Turbo 在規格到 RTL 任務中達到 59% 的通過率。我們也研究了新興的開放原始碼和特定領域模型的效能，並證明模型可以從 ICL 中獲得顯著的益處。我們發現最近發布的 Llama 3.1 405B 達到了 58% 的通過率，有效地與 GPT-4 Turbo 相匹配，而小得多的特定領域 RTL-Coder 6.7B 模型則達到了令人印象深刻的 37% 通過率。然而，提示工程是達成良好通過率的關鍵，而且會隨著模型和任務而有很大的不同。一個允許提示工程和故障分析的基準測試基礎架構是持續模型開發和部署的關鍵。

##### **FLAME: Learning to Navigate with Multimodal LLM in Urban Environments**
2408.11051v1 by Yunzhe Xu, Yiyuan Pan, Zhe Liu, Hesheng Wang

Large Language Models (LLMs) have demonstrated potential in
Vision-and-Language Navigation (VLN) tasks, yet current applications face
challenges. While LLMs excel in general conversation scenarios, they struggle
with specialized navigation tasks, yielding suboptimal performance compared to
specialized VLN models. We introduce FLAME (FLAMingo-Architected Embodied
Agent), a novel Multimodal LLM-based agent and architecture designed for urban
VLN tasks that efficiently handles multiple observations. Our approach
implements a three-phase tuning technique for effective adaptation to
navigation tasks, including single perception tuning for street view
description, multiple perception tuning for trajectory summarization, and
end-to-end training on VLN datasets. The augmented datasets are synthesized
automatically. Experimental results demonstrate FLAME's superiority over
existing methods, surpassing state-of-the-art methods by a 7.3% increase in
task completion rate on Touchdown dataset. This work showcases the potential of
Multimodal LLMs (MLLMs) in complex navigation tasks, representing an
advancement towards practical applications of MLLMs in embodied AI. Project
page: https://flame-sjtu.github.io

摘要：大型語言模型 (LLM) 已在視覺和語言導航 (VLN) 任務中展現潛力，但目前的應用面臨挑戰。雖然 LLM 在一般對話場景中表現出色，但它們在專業導航任務中卻顯得吃力，與專業 VLN 模型相比，產生的效能並不理想。我們引入了 FLAME（FLAMingo-Architected Embodied Agent），這是一種新穎的多模態 LLM 基礎代理和架構，專為有效處理多重觀察的城市 VLN 任務而設計。我們的做法實施了一個三階段調整技術，以有效適應導航任務，包括針對街景描述的單一感知調整、針對軌跡摘要的多重感知調整，以及針對 VLN 資料集的端對端訓練。增強的資料集會自動合成。實驗結果證明了 FLAME 優於現有方法，在 Touchdown 資料集上任務完成率提高了 7.3%，超越了最先進的方法。這項工作展示了多模態 LLM (MLLM) 在複雜導航任務中的潛力，代表了 MLLM 在具身 AI 中實際應用的一項進展。專案頁面：https://flame-sjtu.github.io

##### **MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding**
2408.11049v2 by Jian Chen, Vashisth Tiwari, Ranajoy Sadhukhan, Zhuoming Chen, Jinyuan Shi, Ian En-Hsu Yen, Beidi Chen

Large Language Models (LLMs) have become more prevalent in long-context
applications such as interactive chatbots, document analysis, and agent
workflows, but it is challenging to serve long-context requests with low
latency and high throughput. Speculative decoding (SD) is a widely used
technique to reduce latency without sacrificing performance but the
conventional wisdom suggests that its efficacy is limited to small batch sizes.
In MagicDec, we show that surprisingly SD can achieve speedup even for a high
throughput inference regime for moderate to long sequences. More interestingly,
an intelligent drafting strategy can achieve better speedup with increasing
batch size based on our rigorous analysis. MagicDec first identifies the
bottleneck shifts with increasing batch size and sequence length, and uses
these insights to deploy speculative decoding more effectively for high
throughput inference. Then, it leverages draft models with sparse KV cache to
address the KV bottleneck that scales with both sequence length and batch size.
This finding underscores the broad applicability of speculative decoding in
long-context serving, as it can enhance throughput and reduce latency without
compromising accuracy. For moderate to long sequences, we demonstrate up to 2x
speedup for LLaMA-2-7B-32K and 1.84x speedup for LLaMA-3.1-8B when serving
batch sizes ranging from 32 to 256 on 8 NVIDIA A100 GPUs. The code is available
at https://github.com/Infini-AI-Lab/MagicDec/.

摘要：大型語言模型（LLM）在互動式聊天機器人、文件分析和代理工作流程等長語境應用中變得越來越普遍，但要以低延遲和高通量提供長語境請求卻是一項挑戰。推測性解碼（SD）是一種廣泛使用的技術，可以在不犧牲效能的情況下減少延遲，但傳統觀念認為其效力僅限於小批次大小。在 MagicDec 中，我們展示出令人驚訝的是，即使對於中等至長序列的高通量推論機制，SD 也可以實現加速。更有趣的是，根據我們嚴謹的分析，一種智慧起草策略可以隨著批次大小的增加而實現更好的加速。MagicDec 首先找出隨著批次大小和序列長度的增加而產生的瓶頸轉移，並利用這些見解更有效地部署推測性解碼以進行高通量推論。然後，它利用具有稀疏 KV 快取的草稿模型來解決 KV 瓶頸，而該瓶頸會隨著序列長度和批次大小而擴展。這一發現強調了推測性解碼在長語境服務中的廣泛適用性，因為它可以在不影響準確性的情況下提高通量並減少延遲。對於中等至長序列，我們展示了 LLaMA-2-7B-32K 的加速最高達 2 倍，以及 LLaMA-3.1-8B 的加速最高達 1.84 倍，同時在 8 個 NVIDIA A100 GPU 上提供 32 到 256 的批次大小。程式碼可在 https://github.com/Infini-AI-Lab/MagicDec/ 取得。

##### **Inside the Black Box: Detecting Data Leakage in Pre-trained Language Encoders**
2408.11046v1 by Yuan Xin, Zheng Li, Ning Yu, Dingfan Chen, Mario Fritz, Michael Backes, Yang Zhang

Despite being prevalent in the general field of Natural Language Processing
(NLP), pre-trained language models inherently carry privacy and copyright
concerns due to their nature of training on large-scale web-scraped data. In
this paper, we pioneer a systematic exploration of such risks associated with
pre-trained language encoders, specifically focusing on the membership leakage
of pre-training data exposed through downstream models adapted from pre-trained
language encoders-an aspect largely overlooked in existing literature. Our
study encompasses comprehensive experiments across four types of pre-trained
encoder architectures, three representative downstream tasks, and five
benchmark datasets. Intriguingly, our evaluations reveal, for the first time,
the existence of membership leakage even when only the black-box output of the
downstream model is exposed, highlighting a privacy risk far greater than
previously assumed. Alongside, we present in-depth analysis and insights toward
guiding future researchers and practitioners in addressing the privacy
considerations in developing pre-trained language models.

摘要：儘管在自然語言處理 (NLP) 的一般領域中很普遍，但預先訓練的語言模型由於其在大量網路擷取資料上訓練的特性，本質上會帶來隱私和版權問題。在本文中，我們率先系統性地探討與預先訓練語言編碼器相關的此類風險，特別關注透過改編自預先訓練語言編碼器的下游模型所揭露的預先訓練資料的成員身分外洩，而這方面在現有文獻中大多被忽略。我們的研究涵蓋了四種類型的預先訓練編碼器架構、三個具代表性的下游任務以及五個基準資料集的綜合實驗。有趣的是，我們的評估首次揭示了即使僅公開下游模型的黑盒輸出，也會存在成員身分外洩的情況，突顯了遠大於先前假設的隱私風險。此外，我們提出深入的分析和見解，以指導未來的研究人員和從業人員在開發預先訓練語言模型時解決隱私考量。

##### **Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research**
2408.11043v1 by Sreyoshi Bhaduri, Satya Kapoor, Alex Gil, Anshul Mittal, Rutu Mulkar

Qualitative data collection and analysis approaches, such as those employing
interviews and focus groups, provide rich insights into customer attitudes,
sentiment, and behavior. However, manually analyzing qualitative data requires
extensive time and effort to identify relevant topics and thematic insights.
This study proposes a novel approach to address this challenge by leveraging
Retrieval Augmented Generation (RAG) based Large Language Models (LLMs) for
analyzing interview transcripts. The novelty of this work lies in strategizing
the research inquiry as one that is augmented by an LLM that serves as a novice
research assistant. This research explores the mental model of LLMs to serve as
novice qualitative research assistants for researchers in the talent management
space. A RAG-based LLM approach is extended to enable topic modeling of
semi-structured interview data, showcasing the versatility of these models
beyond their traditional use in information retrieval and search. Our findings
demonstrate that the LLM-augmented RAG approach can successfully extract topics
of interest, with significant coverage compared to manually generated topics
from the same dataset. This establishes the viability of employing LLMs as
novice qualitative research assistants. Additionally, the study recommends that
researchers leveraging such models lean heavily on quality criteria used in
traditional qualitative research to ensure rigor and trustworthiness of their
approach. Finally, the paper presents key recommendations for industry
practitioners seeking to reconcile the use of LLMs with established qualitative
research paradigms, providing a roadmap for the effective integration of these
powerful, albeit novice, AI tools in the analysis of qualitative datasets
within talent

摘要：<paragraph>定性資料蒐集與分析方法，例如採用訪談和焦點團體，能深入洞察客戶態度、情緒和行為。然而，人工分析定性資料需要大量的時間和精力才能找出相關主題和主題見解。本研究提出了一種新方法，透過利用檢索擴充生成（RAG）技術的大語言模型（LLM）來分析訪談紀錄，以解決這個挑戰。這項工作的創新之處在於將研究探討策略化為由 LLM 擴充，而 LLM 則扮演新手研究助理的角色。本研究探討 LLM 的心智模型，以作為人才管理領域研究人員的新手定性研究助理。將基於 RAG 的 LLM 方法延伸，以進行半結構式訪談資料的主題建模，展示這些模型除了在資訊檢索和搜尋中的傳統用途之外的多功能性。我們的研究結果顯示，LLM 擴充的 RAG 方法可以成功萃取出感興趣的主題，與從相同資料集手動產生的主題相比，涵蓋範圍顯著。這確立了將 LLM 用作新手定性研究助理的可行性。此外，本研究建議，利用此類模型的研究人員應大量依賴傳統定性研究中使用的品質標準，以確保其方法的嚴謹性和可信度。最後，本文針對尋求調和 LLM 使用與既定定性研究範例的產業從業人員提出關鍵建議，提供在人才領域中有效整合這些強大的新手 AI 工具來分析定性資料集的路線圖。</paragraph>

##### **Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model**
2408.11039v1 by Chunting Zhou, Lili Yu, Arun Babu, Kushal Tirumala, Michihiro Yasunaga, Leonid Shamis, Jacob Kahn, Xuezhe Ma, Luke Zettlemoyer, Omer Levy

We introduce Transfusion, a recipe for training a multi-modal model over
discrete and continuous data. Transfusion combines the language modeling loss
function (next token prediction) with diffusion to train a single transformer
over mixed-modality sequences. We pretrain multiple Transfusion models up to 7B
parameters from scratch on a mixture of text and image data, establishing
scaling laws with respect to a variety of uni- and cross-modal benchmarks. Our
experiments show that Transfusion scales significantly better than quantizing
images and training a language model over discrete image tokens. By introducing
modality-specific encoding and decoding layers, we can further improve the
performance of Transfusion models, and even compress each image to just 16
patches. We further demonstrate that scaling our Transfusion recipe to 7B
parameters and 2T multi-modal tokens produces a model that can generate images
and text on a par with similar scale diffusion models and language models,
reaping the benefits of both worlds.

摘要：我們介紹 Transfusion，這是一個在離散和連續數據上訓練多模態模型的配方。Transfusion 結合語言模型損失函數（下一個符號預測）與擴散，以在混合模式序列上訓練單一Transformer。我們從頭開始在文本和影像數據的混合物上預訓練多個 Transfusion 模型，參數高達 7B，建立與各種單模態和跨模態基準相關的擴充定律。我們的實驗顯示，Transfusion 的擴充性顯著優於量化影像和在離散影像符號上訓練語言模型。透過引入特定於模式的編碼和解碼層，我們可以進一步提升 Transfusion 模型的效能，甚至將每個影像壓縮成僅 16 個區塊。我們進一步證明，將我們的 Transfusion 配方擴充到 7B 參數和 2T 多模態符號，會產生一個模型，該模型可以生成影像和文本，與類似的擴充規模擴散模型和語言模型不相上下，同時獲取兩個世界的優點。

##### **Scaling Law with Learning Rate Annealing**
2408.11029v1 by Howe Tissue, Venus Wang, Lu Wang

We find that the cross-entropy loss curves of neural language models
empirically adhere to a scaling law with learning rate (LR) annealing over
training steps ($s$): $$L(s) = L_0 + A\cdot S_1^{-\alpha} - C\cdot S_2$$ Where
$S_1$ is forward area and $S_2$ is learning rate annealing area. This
formulation takes into account two factors: (1) The forward scaling defined as
typical scaling law, and (2) the additional loss drop brought by LR annealing.
Therefore, this formulation can describe the full loss curve at each step,
rather than the single loss point at the end of training. Applying the scaling
law with LR annealing and fitting only one or two training curves, we can
accurately predict the loss of language model training at any given step and
across any learning rate scheduler (LRS). Furthermore, this equation accurately
describes the dynamics during training process, and provides a theoretical
verification and explanation for numerous experimental findings of previous
studies, particularly those focusing on LR schedule and LR annealing. The
resulting insights, also serve as a guide for researchers to select critical
LRS in advance by prediction using our equation. Most significantly, since all
the points in a full training curve follow the equation, we can achieve
accurate loss prediction at any given step across any learning rate scheduler,
while expending less than 1\% of the computational cost required by the
chinchilla scaling law to fit language modeling loss. This approach extremely
democratizes scaling law fitting and predicting in developing large language
models.

摘要：<paragraph>我們發現神經語言模型的交叉熵損失曲線
在訓練步驟 ($s$) 中，隨著學習率 (LR) 退火而經驗性地遵循一個縮放定律：$$L(s) = L_0 + A\cdot S_1^{-\alpha} - C\cdot S_2$$ 其中
$S_1$ 是前向區域，而 $S_2$ 是學習率退火區域。這個
公式考慮了兩個因素：(1) 定義為典型縮放定律的前向縮放，以及 (2) LR 退火帶來的額外損失下降。
因此，這個公式可以描述每個步驟的完整損失曲線，而不是訓練結束時的單一損失點。應用具有 LR 退火的縮放定律，並只擬合一或兩個訓練曲線，我們可以
準確預測語言模型訓練在任何給定步驟和任何學習率排程器 (LRS) 下的損失。此外，這個方程式準確地描述了訓練過程中的動態，並為先前研究的許多實驗發現提供了理論驗證和解釋，特別是那些專注於 LR 排程和 LR 退火的發現。
由此產生的見解，也作為研究人員使用我們的方程式預測，以提前選擇關鍵 LRS 的指南。最重要的是，由於完整訓練曲線中的所有點都遵循這個方程式，我們可以在任何給定的步驟和任何學習率排程器中實現準確的損失預測，同時消耗的計算成本不到 chinchilla 縮放定律擬合語言模型損失所需的 1%。這種方法極大地民主化了在大語言模型開發中縮放定律的擬合和預測。</paragraph>

##### **Athena: Safe Autonomous Agents with Verbal Contrastive Learning**
2408.11021v1 by Tanmana Sadhu, Ali Pesaranghader, Yanan Chen, Dong Hoon Yi

Due to emergent capabilities, large language models (LLMs) have been utilized
as language-based agents to perform a variety of tasks and make decisions with
an increasing degree of autonomy. These autonomous agents can understand
high-level instructions, interact with their environments, and execute complex
tasks using a selection of tools available to them. As the capabilities of the
agents expand, ensuring their safety and trustworthiness becomes more
imperative. In this study, we introduce the Athena framework which leverages
the concept of verbal contrastive learning where past safe and unsafe
trajectories are used as in-context (contrastive) examples to guide the agent
towards safety while fulfilling a given task. The framework also incorporates a
critiquing mechanism to guide the agent to prevent risky actions at every step.
Furthermore, due to the lack of existing benchmarks on the safety reasoning
ability of LLM-based agents, we curate a set of 80 toolkits across 8 categories
with 180 scenarios to provide a safety evaluation benchmark. Our experimental
evaluation, with both closed- and open-source LLMs, indicates verbal
contrastive learning and interaction-level critiquing improve the safety rate
significantly.

摘要：由於新興的能力，大型語言模型 (LLM) 已被用作基於語言的代理，以執行各種任務並在自主性日益提高的情況下做出決策。這些自主代理可以理解高級指令，與其環境互動，並使用可用的工具選擇執行複雜的任務。隨著代理功能的擴展，確保其安全性和可信度變得更加重要。在本研究中，我們介紹了 Athena 框架，該框架利用了語言對比學習的概念，其中過去的安全和不安全軌跡被用作上下文（對比）範例，以指導代理在執行特定任務的同時確保安全。該框架還包含一個批評機制，以指導代理在每一步防止冒險行為。此外，由於缺乏對基於 LLM 的代理的安全推理能力的現有基準，我們策劃了一組跨越 8 個類別的 80 個工具包，其中包含 180 個場景，以提供安全評估基準。我們的實驗評估，包括閉源和開源 LLM，表明語言對比學習和互動級別的批評顯著提高了安全性。

##### **While GitHub Copilot Excels at Coding, Does It Ensure Responsible Output?**
2408.11006v1 by Wen Cheng, Ke Sun, Xinyu Zhang, Wei Wang

The rapid development of large language models (LLMs) has significantly
advanced code completion capabilities, giving rise to a new generation of
LLM-based Code Completion Tools (LCCTs). Unlike general-purpose LLMs, these
tools possess unique workflows, integrating multiple information sources as
input and prioritizing code suggestions over natural language interaction,
which introduces distinct security challenges. Additionally, LCCTs often rely
on proprietary code datasets for training, raising concerns about the potential
exposure of sensitive data. This paper exploits these distinct characteristics
of LCCTs to develop targeted attack methodologies on two critical security
risks: jailbreaking and training data extraction attacks. Our experimental
results expose significant vulnerabilities within LCCTs, including a 99.4%
success rate in jailbreaking attacks on GitHub Copilot and a 46.3% success rate
on Amazon Q. Furthermore, We successfully extracted sensitive user data from
GitHub Copilot, including 54 real email addresses and 314 physical addresses
associated with GitHub usernames. Our study also demonstrates that these
code-based attack methods are effective against general-purpose LLMs, such as
the GPT series, highlighting a broader security misalignment in the handling of
code by modern LLMs. These findings underscore critical security challenges
associated with LCCTs and suggest essential directions for strengthening their
security frameworks. The example code and attack samples from our research are
provided at https://github.com/Sensente/Security-Attacks-on-LCCTs.

摘要：大型語言模型（LLM）的快速發展顯著提升了程式碼補全能力，催生了新一代基於 LLM 的程式碼補全工具（LCCT）。與一般用途的 LLM 不同，這些工具擁有獨特的作業流程，整合多重資訊來源作為輸入，並優先考慮程式碼建議而非自然語言互動，這帶來了不同的安全性挑戰。此外，LCCT 經常仰賴專有的程式碼資料集進行訓練，引發了敏感資料潛在曝光的疑慮。本文利用 LCCT 的這些獨特特徵，針對兩個重要的安全性風險：越獄和訓練資料萃取攻擊，開發出有針對性的攻擊方法。我們的實驗結果揭露了 LCCT 中的重大漏洞，包括在 GitHub Copilot 上越獄攻擊的 99.4% 成功率，以及在 Amazon Q 上的 46.3% 成功率。此外，我們成功從 GitHub Copilot 中萃取到敏感的使用者資料，包括 54 個真實電子郵件地址和 314 個與 GitHub 使用者名稱相關的實體地址。我們的研究也證明了這些基於程式碼的攻擊方法對一般用途的 LLM（例如 GPT 系列）是有效的，突顯了現代 LLM 在處理程式碼時更廣泛的安全錯位。這些發現強調了與 LCCT 相關的關鍵安全性挑戰，並提出了加強其安全架構的必要方向。我們研究中的範例程式碼和攻擊範例可在 https://github.com/Sensente/Security-Attacks-on-LCCTs 獲得。

##### **CTP-LLM: Clinical Trial Phase Transition Prediction Using Large Language Models**
2408.10995v1 by Michael Reinisch, Jianfeng He, Chenxi Liao, Sauleh Ahmad Siddiqui, Bei Xiao

New medical treatment development requires multiple phases of clinical
trials. Despite the significant human and financial costs of bringing a drug to
market, less than 20% of drugs in testing will make it from the first phase to
final approval. Recent literature indicates that the design of the trial
protocols significantly contributes to trial performance. We investigated
Clinical Trial Outcome Prediction (CTOP) using trial design documents to
predict phase transitions automatically. We propose CTP-LLM, the first Large
Language Model (LLM) based model for CTOP. We also introduce the
PhaseTransition (PT) Dataset; which labels trials based on their progression
through the regulatory process and serves as a benchmark for CTOP evaluation.
Our fine-tuned GPT-3.5-based model (CTP-LLM) predicts clinical trial phase
transition by analyzing the trial's original protocol texts without requiring
human-selected features. CTP-LLM achieves a 67% accuracy rate in predicting
trial phase transitions across all phases and a 75% accuracy rate specifically
in predicting the transition from Phase~III to final approval. Our experimental
performance highlights the potential of LLM-powered applications in forecasting
clinical trial outcomes and assessing trial design.

摘要：新藥物治療的開發需要多階段的臨床試驗。儘管將藥物推向市場需要大量的人力和財力成本，但只有不到 20% 的藥物在測試中能從第一階段順利通過，獲得最終核准。最近的文獻指出，試驗規程的設計對試驗成效有顯著的影響。我們利用試驗設計文件研究臨床試驗結果預測 (CTOP)，以自動預測各階段的轉換。我們提出 CTP-LLM，這是第一個基於大型語言模型 (LLM) 的 CTOP 模型。我們也引入了 PhaseTransition (PT) 資料集，這個資料集根據試驗在法規程序中的進展標記試驗，並作為 CTOP 評估的基準。我們微調後的 GPT-3.5 基礎模型 (CTP-LLM) 會分析試驗的原始規程文字，來預測臨床試驗的階段轉換，而不需要人工選擇的特徵。CTP-LLM 在預測所有階段的試驗階段轉換時，達到了 67% 的準確度，而在預測從第 III 期轉換到最終核准的階段轉換時，達到了 75% 的準確度。我們的實驗成效突顯了 LLM 驅動的應用程式在預測臨床試驗結果和評估試驗設計方面的潛力。

##### **Denoising Plane Wave Ultrasound Images Using Diffusion Probabilistic Models**
2408.10987v1 by Hojat Asgariandehkordi, Sobhan Goudarzi, Mostafa Sharifzadeh, Adrian Basarab, Hassan Rivaz

Ultrasound plane wave imaging is a cutting-edge technique that enables high
frame-rate imaging. However, one challenge associated with high frame-rate
ultrasound imaging is the high noise associated with them, hindering their
wider adoption. Therefore, the development of a denoising method becomes
imperative to augment the quality of plane wave images. Drawing inspiration
from Denoising Diffusion Probabilistic Models (DDPMs), our proposed solution
aims to enhance plane wave image quality. Specifically, the method considers
the distinction between low-angle and high-angle compounding plane waves as
noise and effectively eliminates it by adapting a DDPM to beamformed
radiofrequency (RF) data. The method underwent training using only 400
simulated images. In addition, our approach employs natural image segmentation
masks as intensity maps for the generated images, resulting in accurate
denoising for various anatomy shapes. The proposed method was assessed across
simulation, phantom, and in vivo images. The results of the evaluations
indicate that our approach not only enhances image quality on simulated data
but also demonstrates effectiveness on phantom and in vivo data in terms of
image quality. Comparative analysis with other methods underscores the
superiority of our proposed method across various evaluation metrics. The
source code and trained model will be released along with the dataset at:
http://code.sonography.ai

摘要：超音波平面波影像是一種先進的技術，可實現高幀率影像。然而，與高幀率超音波影像相關的一個挑戰是伴隨而來的雜訊過高，阻礙了它們的廣泛採用。因此，開發一種去噪方法對於提升平面波影像的品質至關重要。從去噪擴散機率模型 (DDPM) 中汲取靈感，我們提出的解決方案旨在提升平面波影像品質。具體來說，此方法將低角度和高角度複合平面波之間的區別視為雜訊，並透過調整 DDPM 至波束成形的射頻 (RF) 資料，有效地消除了雜訊。此方法僅使用 400 張模擬影像進行訓練。此外，我們的做法採用自然影像分割遮罩作為生成影像的強度圖，進而針對各種解剖形狀進行精確去噪。所提出的方法已針對模擬、模擬人體和體內影像進行評估。評估結果顯示，我們的做法不僅提升了模擬資料的影像品質，也證明了在模擬人體和體內資料上的有效性，展現出影像品質。與其他方法的比較分析強調了我們所提出的方法在各種評估指標中的優越性。原始碼和訓練好的模型將與資料集一同發布於：http://code.sonography.ai

##### **The fusion of phonography and ideographic characters into virtual Chinese characters -- Based on Chinese and English**
2408.10979v1 by Hongfa Zi, Zhen Liu

The characters used in modern countries are mainly divided into ideographic
characters and phonetic characters, both of which have their advantages and
disadvantages. Chinese is difficult to learn and easy to master, while English
is easy to learn but has a large vocabulary. There is still no language that
combines the advantages of both languages and has less memory capacity, can
form words, and is easy to learn. Therefore, inventing new characters that can
be combined and the popularization of deep knowledge, and reduce disputes
through communication. Firstly, observe the advantages and disadvantages of
Chinese and English, such as their vocabulary, information content, and ease of
learning in deep scientific knowledge, and create a new writing system. Then,
use comparative analysis to observe the total score of the new language.
Through this article, it can be concluded that the new text combines the
advantages of both pictographic and alphabetical writing: new characters that
can be combined into words reduces the vocabulary that needs to be learned;
Special prefixes allow beginners to quickly guess the approximate category and
meaning of unseen words; New characters can enable humans to quickly learn more
advanced knowledge.

摘要：現代國家使用的文字，主要分為表意文字與表音文字，兩者各有優缺點，中文難學易精，英文易學難精，至今仍未有兼具兩者優點，且記憶量少、可組詞、易學的語言，因此發明可組合新文字，並普及深層知識，且透過溝通減少爭議。首先，觀察中文、英文在深層科學知識上的詞彙量、資訊含量、學習難易度等優缺點，創造新的文字系統，再以比較分析觀察新文字的總體表現，透過本文，可以得知新文字兼具象形文字與拼音文字的優點：可組合新文字組成詞彙，減少需學習的詞彙量；特殊的前綴，讓初學者能快速猜測生字的類別與大概意思；新文字能讓人快速學習更進階的知識。

##### **Hybrid Recurrent Models Support Emergent Descriptions for Hierarchical Planning and Control**
2408.10970v1 by Poppy Collis, Ryan Singh, Paul F Kinghorn, Christopher L Buckley

An open problem in artificial intelligence is how systems can flexibly learn
discrete abstractions that are useful for solving inherently continuous
problems. Previous work has demonstrated that a class of hybrid state-space
model known as recurrent switching linear dynamical systems (rSLDS) discover
meaningful behavioural units via the piecewise linear decomposition of complex
continuous dynamics (Linderman et al., 2016). Furthermore, they model how the
underlying continuous states drive these discrete mode switches. We propose
that the rich representations formed by an rSLDS can provide useful
abstractions for planning and control. We present a novel hierarchical
model-based algorithm inspired by Active Inference in which a discrete MDP sits
above a low-level linear-quadratic controller. The recurrent transition
dynamics learned by the rSLDS allow us to (1) specify temporally-abstracted
sub-goals in a method reminiscent of the options framework, (2) lift the
exploration into discrete space allowing us to exploit information-theoretic
exploration bonuses and (3) `cache' the approximate solutions to low-level
problems in the discrete planner. We successfully apply our model to the sparse
Continuous Mountain Car task, demonstrating fast system identification via
enhanced exploration and non-trivial planning through the delineation of
abstract sub-goals.

摘要：人工智能中一個開放性的問題是系統如何靈活地學習離散抽象，而這對於解決本質上連續的問題很有用。先前的研究已證明，一種稱為遞迴切換線性動態系統 (rSLDS) 的混合狀態空間模型類別，可經由複雜連續動態的區段線性分解，發現有意義的行為單位 (Linderman 等人，2016 年)。此外，它們會建模底層連續狀態如何驅動這些離散模式切換。我們提出，rSLDS 形成的豐富表徵，可為規劃和控制提供有用的抽象。我們提出一個新穎的分層模型演算法，其靈感來自主動推論，其中一個離散 MDP 位於低階線性二次控制器之上。rSLDS 學習到的遞迴轉換動態，讓我們能夠 (1) 以類似於選項架構的方法，指定時間抽象的子目標，(2) 將探索提升到離散空間，讓我們能夠利用資訊理論探索獎勵，以及 (3) 在離散規劃器中「快取」低階問題的近似解。我們成功地將我們的模型應用於稀疏的連續汽車爬山任務，展示了透過增強探索和非平凡規劃，以及透過描繪抽象子目標，快速進行系統辨識。

##### **NLP for The Greek Language: A Longer Survey**
2408.10962v1 by Katerina Papantoniou, Yannis Tzitzikas

English language is in the spotlight of the Natural Language Processing (NLP)
community with other languages, like Greek, lagging behind in terms of offered
methods, tools and resources. Due to the increasing interest in NLP, in this
paper we try to condense research efforts for the automatic processing of Greek
language covering the last three decades. In particular, we list and briefly
discuss related works, resources and tools, categorized according to various
processing layers and contexts. We are not restricted to the modern form of
Greek language but also cover Ancient Greek and various Greek dialects. This
survey can be useful for researchers and students interested in NLP tasks,
Information Retrieval and Knowledge Management for the Greek language.

摘要：自然語言處理 (NLP) 社群中，英語備受矚目，而希臘語等其他語言在所提供的各種方法、工具和資源方面卻遠遠落後。由於對 NLP 的興趣日益濃厚，在本文中，我們試圖濃縮過去三十年來希臘語自動處理的研究成果。特別是，我們將根據各種處理層和情境列出並簡要討論相關著作、資源和工具。我們不僅限於現代希臘語形式，還涵蓋古希臘語和各種希臘方言。這項調查對有興趣從事希臘語 NLP 任務、資訊檢索和知識管理的研究人員和學生來說很有用。

##### **Wave-Mask/Mix: Exploring Wavelet-Based Augmentations for Time Series Forecasting**
2408.10951v1 by Dona Arabi, Jafar Bakhshaliyev, Ayse Coskuner, Kiran Madhusudhanan, Kami Serdar Uckardes

Data augmentation is important for improving machine learning model
performance when faced with limited real-world data. In time series forecasting
(TSF), where accurate predictions are crucial in fields like finance,
healthcare, and manufacturing, traditional augmentation methods for
classification tasks are insufficient to maintain temporal coherence. This
research introduces two augmentation approaches using the discrete wavelet
transform (DWT) to adjust frequency elements while preserving temporal
dependencies in time series data. Our methods, Wavelet Masking (WaveMask) and
Wavelet Mixing (WaveMix), are evaluated against established baselines across
various forecasting horizons. To the best of our knowledge, this is the first
study to conduct extensive experiments on multivariate time series using
Discrete Wavelet Transform as an augmentation technique. Experimental results
demonstrate that our techniques achieve competitive results with previous
methods. We also explore cold-start forecasting using downsampled training
datasets, comparing outcomes to baseline methods.

摘要：資料擴充對於在面對受限的真實世界資料時改善機器學習模型效能非常重要。在時間序列預測 (TSF) 中，精準的預測在金融、醫療保健和製造等領域至關重要，傳統的擴充方法對於分類任務來說不足以維持時間相干性。本研究引入了兩種擴充方法，利用離散小波轉換 (DWT) 來調整頻率元素，同時保留時間序列資料中的時間依賴性。我們的 Wavelet Masking (WaveMask) 和 Wavelet Mixing (WaveMix) 方法針對各種預測範圍與既定的基準進行評估。據我們所知，這是第一個使用離散小波轉換作為擴充技術對多變量時間序列進行廣泛實驗的研究。實驗結果證明我們的技術可與先前的技術競爭。我們也使用降採樣訓練資料集探索冷啟動預測，並將結果與基準方法進行比較。

##### **GAIM: Attacking Graph Neural Networks via Adversarial Influence Maximization**
2408.10948v1 by Xiaodong Yang, Xiaoting Li, Huiyuan Chen, Yiwei Cai

Recent studies show that well-devised perturbations on graph structures or
node features can mislead trained Graph Neural Network (GNN) models. However,
these methods often overlook practical assumptions, over-rely on heuristics, or
separate vital attack components. In response, we present GAIM, an integrated
adversarial attack method conducted on a node feature basis while considering
the strict black-box setting. Specifically, we define an adversarial influence
function to theoretically assess the adversarial impact of node perturbations,
thereby reframing the GNN attack problem into the adversarial influence
maximization problem. In our approach, we unify the selection of the target
node and the construction of feature perturbations into a single optimization
problem, ensuring a unique and consistent feature perturbation for each target
node. We leverage a surrogate model to transform this problem into a solvable
linear programming task, streamlining the optimization process. Moreover, we
extend our method to accommodate label-oriented attacks, broadening its
applicability. Thorough evaluations on five benchmark datasets across three
popular models underscore the effectiveness of our method in both untargeted
and label-oriented targeted attacks. Through comprehensive analysis and
ablation studies, we demonstrate the practical value and efficacy inherent to
our design choices.

摘要：最近的研究表明，對圖形結構或節點特徵進行精心設計的擾動會誤導訓練好的圖神經網路 (GNN) 模型。然而，這些方法通常忽略實際假設，過於依賴啟發法或將重要的攻擊組件分開。為了解決這個問題，我們提出了 GAIM，這是一種綜合的對抗性攻擊方法，在考慮嚴格的黑盒設定的同時，在節點特徵基礎上進行。具體來說，我們定義了一個對抗性影響函數來理論上評估節點擾動的對抗性影響，從而將 GNN 攻擊問題重新定義為對抗性影響最大化問題。在我們的做法中，我們將目標節點的選擇和特徵擾動的構造統一到一個單一的最佳化問題中，確保每個目標節點具有唯一且一致的特徵擾動。我們利用替代模型將這個問題轉換為一個可解的線性規劃任務，簡化了最佳化過程。此外，我們擴展了我們的模型以適應面向標籤的攻擊，擴大了它的適用性。針對三種流行模型的五個基準資料集進行的徹底評估強調了我們的模型在非目標和面向標籤的目標攻擊中的有效性。通過全面的分析和消融研究，我們證明了我們設計選擇中固有的實用價值和效能。

##### **Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models**
2408.10947v1 by Yuyan Chen, Chenwei Wu, Songzhou Yan, Panjun Liu, Haoyu Zhou, Yanghua Xiao

Teachers are important to imparting knowledge and guiding learners, and the
role of large language models (LLMs) as potential educators is emerging as an
important area of study. Recognizing LLMs' capability to generate educational
content can lead to advances in automated and personalized learning. While LLMs
have been tested for their comprehension and problem-solving skills, their
capability in teaching remains largely unexplored. In teaching, questioning is
a key skill that guides students to analyze, evaluate, and synthesize core
concepts and principles. Therefore, our research introduces a benchmark to
evaluate the questioning capability in education as a teacher of LLMs through
evaluating their generated educational questions, utilizing Anderson and
Krathwohl's taxonomy across general, monodisciplinary, and interdisciplinary
domains. We shift the focus from LLMs as learners to LLMs as educators,
assessing their teaching capability through guiding them to generate questions.
We apply four metrics, including relevance, coverage, representativeness, and
consistency, to evaluate the educational quality of LLMs' outputs. Our results
indicate that GPT-4 demonstrates significant potential in teaching general,
humanities, and science courses; Claude2 appears more apt as an
interdisciplinary teacher. Furthermore, the automatic scores align with human
perspectives.

摘要：教師在傳授知識和引導學習者方面很重要，而大型語言模型 (LLM) 作為潛在教育者的角色正成為一個重要的研究領域。認知到 LLM 生成教育內容的能力，可以促成自動化和個人化學習的進展。雖然 LLM 已針對其理解力和問題解決能力進行測試，但它們在教學方面的能力在很大程度上仍未被探索。在教學中，提問是一項關鍵技能，引導學生分析、評估和綜合核心概念和原理。因此，我們的研究引入了一個基準來評估 LLM 作為教師在教育中的提問能力，方法是評估他們產生的教育問題，並利用安德森和克拉斯沃爾的分類法跨越一般、單一學科和跨學科領域。我們將重點從 LLM 作為學習者轉移到 LLM 作為教育者，通過指導他們產生問題來評估他們的教學能力。我們應用四個指標，包括相關性、涵蓋範圍、代表性和一致性，來評估 LLM 輸出的教育品質。我們的結果表明，GPT-4 在教授一般、人文學科和科學課程方面表現出顯著的潛力；Claude2 似乎更適合擔任跨學科教師。此外，自動評分與人類觀點一致。

##### **Large Language Model Driven Recommendation**
2408.10946v1 by Anton Korikov, Scott Sanner, Yashar Deldjoo, Zhankui He, Julian McAuley, Arnau Ramisa, Rene Vidal, Mahesh Sathiamoorthy, Atoosa Kasrizadeh, Silvia Milano, Francesco Ricci

While previous chapters focused on recommendation systems (RSs) based on
standardized, non-verbal user feedback such as purchases, views, and clicks --
the advent of LLMs has unlocked the use of natural language (NL) interactions
for recommendation. This chapter discusses how LLMs' abilities for general NL
reasoning present novel opportunities to build highly personalized RSs -- which
can effectively connect nuanced and diverse user preferences to items,
potentially via interactive dialogues. To begin this discussion, we first
present a taxonomy of the key data sources for language-driven recommendation,
covering item descriptions, user-system interactions, and user profiles. We
then proceed to fundamental techniques for LLM recommendation, reviewing the
use of encoder-only and autoregressive LLM recommendation in both tuned and
untuned settings. Afterwards, we move to multi-module recommendation
architectures in which LLMs interact with components such as retrievers and RSs
in multi-stage pipelines. This brings us to architectures for conversational
recommender systems (CRSs), in which LLMs facilitate multi-turn dialogues where
each turn presents an opportunity not only to make recommendations, but also to
engage with the user in interactive preference elicitation, critiquing, and
question-answering.

摘要：在先前的章节中，我们专注于基于标准化、非语言用户反馈（例如购买、浏览和点击）的推荐系统 (RS)，而 LLM 的出现解锁了自然语言 (NL) 交互在推荐中的使用。本章讨论了 LLM 在一般 NL 推理方面的能力如何为构建高度个性化的 RS 提供新的机会，这些 RS 可以通过交互式对话有效地将细微差别和多样化的用户偏好与商品联系起来。为了开始此讨论，我们首先介绍了语言驱动推荐的关键数据源的分类，涵盖商品描述、用户系统交互和用户个人资料。然后，我们继续研究 LLM 推荐的基本技术，回顾在调整和未调整设置中使用仅编码器和自回归 LLM 推荐。之后，我们转向多模块推荐架构，其中 LLM 与检索器和 RS 等组件在多阶段管道中进行交互。这将我们带到了会话推荐系统 (CRS) 的架构，其中 LLM 促进了多轮对话，在每轮对话中，不仅有机会提出推荐，还可以与用户进行交互式偏好引发、批评和问答。

##### **HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models in Resource-Constrained Environments**
2408.10945v1 by Kazi Hasan Ibn Arif, JinYi Yoon, Dimitrios S. Nikolopoulos, Hans Vandierendonck, Deepu John, Bo Ji

High-resolution Vision-Language Models (VLMs) have been widely used in
multimodal tasks to enhance accuracy by preserving detailed image information.
However, these models often generate excessive visual tokens due to encoding
multiple partitions of the input image. Processing these excessive visual
tokens is computationally challenging, especially in resource-constrained
environments with commodity GPUs. To support high-resolution images while
meeting resource constraints, we propose High-Resolution Early Dropping
(HiRED), a token-dropping scheme that operates within a fixed token budget
before the Large Language Model (LLM) stage. HiRED can be integrated with
existing high-resolution VLMs in a plug-and-play manner, as it requires no
additional training while still maintaining superior accuracy. We strategically
use the vision encoder's attention in the initial layers to assess the visual
content of each image partition and allocate the token budget accordingly.
Then, using the attention in the final layer, we select the most important
visual tokens from each partition within the allocated budget, dropping the
rest. Empirically, when applied to LLaVA-Next-7B on NVIDIA TESLA P40 GPU, HiRED
with a 20% token budget increases token generation throughput by 4.7, reduces
first-token generation latency by 15 seconds, and saves 2.3 GB of GPU memory
for a single inference.

摘要：高解析度視覺語言模型 (VLM) 已廣泛用於多模態任務中，透過保留詳細的影像資訊來提升準確度。然而，這些模型通常會因為編碼輸入影像的分割區塊而產生過量的視覺符號。處理這些過量的視覺符號在計算上具有挑戰性，特別是在資源受限的環境中，使用的是商品化的 GPU。為了支援高解析度影像，同時滿足資源限制，我們提出高解析度早期捨棄 (HiRED)，這是一個符號捨棄方案，在大型語言模型 (LLM) 階段之前，在固定的符號預算中運作。HiRED 可以以即插即用的方式與現有的高解析度 VLM 整合，因為它不需要額外的訓練，同時仍能維持優異的準確度。我們策略性地使用視覺編碼器在初始層中的注意力來評估每個影像分割區塊的視覺內容，並據此分配符號預算。然後，使用最後一層的注意力，我們從每個分割區塊中選擇在分配預算中最重要的視覺符號，捨棄其餘的符號。根據經驗，當應用於 NVIDIA TESLA P40 GPU 上的 LLaVA-Next-7B 時，HiRED 以 20% 的符號預算將符號產生量增加 4.7 倍，將第一個符號產生延遲減少 15 秒，並為單一推論節省 2.3 GB 的 GPU 記憶體。

##### **SysBench: Can Large Language Models Follow System Messages?**
2408.10943v1 by Yanzhao Qin, Tao Zhang, Tao Zhang, Yanjun Shen, Wenjing Luo, Haoze Sun, Yan Zhang, Yujing Qiao, Weipeng Chen, Zenan Zhou, Wentao Zhang, Bin Cui

Large Language Models (LLMs) have become instrumental across various
applications, with the customization of these models to specific scenarios
becoming increasingly critical. System message, a fundamental component of
LLMs, is consist of carefully crafted instructions that guide the behavior of
model to meet intended goals. Despite the recognized potential of system
messages to optimize AI-driven solutions, there is a notable absence of a
comprehensive benchmark for evaluating how well different LLMs follow these
system messages. To fill this gap, we introduce SysBench, a benchmark that
systematically analyzes system message following ability in terms of three
challenging aspects: constraint complexity, instruction misalignment and
multi-turn stability. In order to enable effective evaluation, SysBench
constructs multi-turn user conversations covering various interaction
relationships, based on six common types of constraints from system messages in
real-world scenarios. Our dataset contains 500 system messages from various
domains, each paired with 5 turns of user conversations, which have been
manually formulated and checked to guarantee high quality. SysBench provides
extensive evaluation across various LLMs, measuring their ability to follow
specified constraints given in system messages. The results highlight both the
strengths and weaknesses of existing models, offering key insights and
directions for future research. The open source library SysBench is available
at https://github.com/PKU-Baichuan-MLSystemLab/SysBench.

摘要：大型語言模型 (LLM) 已成為各種應用程式中的重要工具，而這些模型的客製化已變得越來越重要。系統訊息是 LLM 的基本組成部分，由精心設計的指令組成，用於引導模型的行為以達成預期的目標。儘管系統訊息在最佳化 AI 驅動解決方案方面具有公認的潛力，但仍缺乏一個全面的基準來評估不同 LLM 如何遵循這些系統訊息。為了填補這個空白，我們引入了 SysBench，這是一個基準，它從三個具有挑戰性的方面系統性地分析系統訊息的遵循能力：約束複雜性、指令未對齊和多輪穩定性。為了進行有效的評估，SysBench 建構了涵蓋各種互動關係的多輪使用者對話，這些對話基於系統訊息中來自真實世界場景的六種類型約束。我們的資料集包含來自不同領域的 500 則系統訊息，每則訊息都與 5 輪使用者對話配對，這些對話已手動制定並檢查，以確保高品質。SysBench 提供了對各種 LLM 的廣泛評估，衡量它們遵循系統訊息中指定約束的能力。結果突出了現有模型的優點和缺點，為未來的研究提供了關鍵見解和方向。開放原始碼程式庫 SysBench 可在 https://github.com/PKU-Baichuan-MLSystemLab/SysBench 取得。

##### **A Closer Look at Data Augmentation Strategies for Finetuning-Based Low/Few-Shot Object Detection**
2408.10940v1 by Vladislav Li, Georgios Tsoumplekas, Ilias Siniosoglou, Vasileios Argyriou, Anastasios Lytos, Eleftherios Fountoukidis, Panagiotis Sarigiannidis

Current methods for low- and few-shot object detection have primarily focused
on enhancing model performance for detecting objects. One common approach to
achieve this is by combining model finetuning with data augmentation
strategies. However, little attention has been given to the energy efficiency
of these approaches in data-scarce regimes. This paper seeks to conduct a
comprehensive empirical study that examines both model performance and energy
efficiency of custom data augmentations and automated data augmentation
selection strategies when combined with a lightweight object detector. The
methods are evaluated in three different benchmark datasets in terms of their
performance and energy consumption, and the Efficiency Factor is employed to
gain insights into their effectiveness considering both performance and
efficiency. Consequently, it is shown that in many cases, the performance gains
of data augmentation strategies are overshadowed by their increased energy
usage, necessitating the development of more energy efficient data augmentation
strategies to address data scarcity.

摘要：目前低樣本和少樣本目標偵測方法主要集中於增強模型效能以偵測目標。達成此目標的一種常見方法是將模型微調與資料擴充策略結合。然而，在資料稀少的環境中，這些方法的能源效率卻鮮少受到關注。本文旨在進行一項全面的實證研究，探討自訂資料擴充與自動化資料擴充選取策略在與輕量級目標偵測器結合使用時的模型效能和能源效率。這些方法在三個不同的基準資料集中的效能和能源消耗方面進行評估，並採用效率因子來深入了解其在效能和效率兩方面的有效性。因此，結果顯示在許多情況下，資料擴充策略的效能提升會被其增加的能源使用量所抵銷，這使得有必要開發更節能的資料擴充策略來解決資料稀少的問題。

##### **SDI-Net: Toward Sufficient Dual-View Interaction for Low-light Stereo Image Enhancement**
2408.10934v1 by Linlin Hu, Ao Sun, Shijie Hao, Richang Hong, Meng Wang

Currently, most low-light image enhancement methods only consider information
from a single view, neglecting the correlation between cross-view information.
Therefore, the enhancement results produced by these methods are often
unsatisfactory. In this context, there have been efforts to develop methods
specifically for low-light stereo image enhancement. These methods take into
account the cross-view disparities and enable interaction between the left and
right views, leading to improved performance. However, these methods still do
not fully exploit the interaction between left and right view information. To
address this issue, we propose a model called Toward Sufficient Dual-View
Interaction for Low-light Stereo Image Enhancement (SDI-Net). The backbone
structure of SDI-Net is two encoder-decoder pairs, which are used to learn the
mapping function from low-light images to normal-light images. Among the
encoders and the decoders, we design a module named Cross-View Sufficient
Interaction Module (CSIM), aiming to fully exploit the correlations between the
binocular views via the attention mechanism. The quantitative and visual
results on public datasets validate the superiority of our method over other
related methods. Ablation studies also demonstrate the effectiveness of the key
elements in our model.

摘要：目前，大多数低光图像增强方法只考虑单一视图的信息，忽略了跨视图信息之间的相关性。因此，这些方法产生的增强结果通常不令人满意。在此背景下，人们一直努力开发专门用于低光立体图像增强的算法。这些方法考虑了跨视图差异，并实现了左右视图之间的交互，从而提高了性能。然而，这些方法仍然没有充分利用左右视图信息之间的交互。为了解决这个问题，我们提出了一个名为低光立体图像增强充分双视图交互（SDI-Net）的模型。SDI-Net 的主干结构是两个编码器-解码器对，用于学习从低光图像到正常光图像的映射函数。在编码器和解码器中，我们设计了一个名为跨视图充分交互模块（CSIM）的模块，旨在通过注意力机制充分利用双目视图之间的相关性。公开数据集上的定量和视觉结果验证了我们方法优于其他相关方法。消融研究还证明了我们模型中关键元素的有效性。

##### **LBC: Language-Based-Classifier for Out-Of-Variable Generalization**
2408.10923v2 by Kangjun Noh, Baekryun Seong, Hoyoon Byun, Youngjun Choi, Sungjin Song, Kyungwoo Song

Large Language Models (LLMs) have great success in natural language
processing tasks such as response generation. However, their use in tabular
data has been limited due to their inferior performance compared to traditional
machine learning models (TMLs) such as XGBoost. We find that the pre-trained
knowledge of LLMs enables them to interpret new variables that appear in a test
without additional training, a capability central to the concept of
Out-of-Variable (OOV). From the findings, we propose a
Language-Based-Classifier (LBC), a classifier that maximizes the benefits of
LLMs to outperform TMLs on OOV tasks. LBC employs three key methodological
strategies: 1) Categorical changes to adjust data to better fit the model's
understanding, 2) Advanced order and indicator to enhance data representation
to the model, and 3) Using verbalizer to map logit scores to classes during
inference to generate model predictions. These strategies, combined with the
pre-trained knowledge of LBC, emphasize the model's ability to effectively
handle OOV tasks. We empirically and theoretically validate the superiority of
LBC. LBC is the first study to apply an LLM-based model to OOV tasks. The
source code is at
https://github.com/ASDASDanonymous/Language-Based-Classifier-forOOVtasks.

摘要：大型語言模型 (LLM) 在自然語言處理任務中取得了巨大的成功，例如回應生成。然而，由於與傳統機器學習模型 (TML)（如 XGBoost）相比性能較差，它們在表格數據中的使用受到限制。我們發現，LLM 的預訓練知識使它們能夠解釋在測試中出現的新變數，而無需額外訓練，這項功能是 Out-of-Variable (OOV) 概念的核心。根據這些發現，我們提出了一個基於語言的分類器 (LBC)，這是一個分類器，最大化了 LLM 的優點，在 OOV 任務中優於 TML。LBC 採用了三項關鍵的方法策略：1) 對數據進行分類更改，以更好地符合模型的理解，2) 高級順序和指標來增強數據在模型中的表示，以及 3) 在推理過程中使用 verbalizer 將 logit 分數映射到類別以生成模型預測。這些策略與 LBC 的預訓練知識相結合，強調了模型有效處理 OOV 任務的能力。我們通過實證和理論驗證了 LBC 的優越性。LBC 是第一個將基於 LLM 的模型應用於 OOV 任務的研究。源代碼位於 https://github.com/ASDASDanonymous/Language-Based-Classifier-forOOVtasks。

##### **MTFinEval:A Multi-domain Chinese Financial Benchmark with Eurypalynous questions**
2408.10921v1 by Xinyu Liu, Ke Jin

With the emergence of more and more economy-specific LLMS, how to measure
whether they can be safely invested in production becomes a problem. Previous
research has primarily focused on evaluating the performance of LLMs within
specific application scenarios. However, these benchmarks cannot reflect the
theoretical level and generalization ability, and the backward datasets are
increasingly unsuitable for problems in real scenarios. In this paper, we have
compiled a new benchmark, MTFinEval, focusing on the LLMs' basic knowledge of
economics, which can always be used as a basis for judgment. To examine only
theoretical knowledge as much as possible, MTFinEval is build with foundational
questions from university textbooks,and exam papers in economics and management
major. Aware of the overall performance of LLMs do not depend solely on one
subdiscipline of economics, MTFinEval comprise 360 questions refined from six
major disciplines of economics, and reflect capabilities more comprehensively.
Experiment result shows all LLMs perform poorly on MTFinEval, which proves that
our benchmark built on basic knowledge is very successful. Our research not
only offers guidance for selecting the appropriate LLM for specific use cases,
but also put forward increase the rigor reliability of LLMs from the basics.

摘要：隨著越來越多的特定經濟領域LLM出現，如何衡量它們是否可以安全地投資於生產成為一個問題。先前的研究主要集中於評估LLM在特定應用場景中的性能。然而，這些基準無法反映理論水平和概括能力，並且後向數據集越來越不適合於實際場景中的問題。在本文中，我們編制了一個新的基準MTFinEval，重點關注LLM對經濟學的基本知識，這始終可以用作判斷的基礎。為了盡可能只檢查理論知識，MTFinEval是使用大學教科書中的基礎問題和經濟學與管理學專業的考試論文構建的。意識到LLM的整體性能並不僅依賴於經濟學的一個子學科，MTFinEval由經濟學的六個主要學科中精煉出的360個問題組成，並更全面地反映能力。實驗結果表明，所有LLM在MTFinEval上的表現都很差，這證明了我們建立在基礎知識上的基準非常成功。我們的研究不僅為選擇適用於特定用例的適當LLM提供了指導，而且還提出了從基礎上提高LLM的嚴謹性和可靠性。

##### **Recurrent Neural Networks Learn to Store and Generate Sequences using Non-Linear Representations**
2408.10920v1 by Róbert Csordás, Christopher Potts, Christopher D. Manning, Atticus Geiger

The Linear Representation Hypothesis (LRH) states that neural networks learn
to encode concepts as directions in activation space, and a strong version of
the LRH states that models learn only such encodings. In this paper, we present
a counterexample to this strong LRH: when trained to repeat an input token
sequence, gated recurrent neural networks (RNNs) learn to represent the token
at each position with a particular order of magnitude, rather than a direction.
These representations have layered features that are impossible to locate in
distinct linear subspaces. To show this, we train interventions to predict and
manipulate tokens by learning the scaling factor corresponding to each sequence
position. These interventions indicate that the smallest RNNs find only this
magnitude-based solution, while larger RNNs have linear representations. These
findings strongly indicate that interpretability research should not be
confined by the LRH.

摘要：線性表示假設 (LRH) 指出神經網路會學習將概念編碼為激活空間中的方向，而 LRH 的強版本則指出模型只會學習此類編碼。在本文中，我們提出此強 LRH 的反例：當訓練重複輸入記號序列時，門控遞迴神經網路 (RNN) 會學習用特定數量級而非方向來表示每個位置的記號。這些表示具有分層特徵，無法在不同的線性子空間中找到。為顯示這一點，我們訓練介入措施，透過學習與每個序列位置相應的縮放因子來預測和操作記號。這些介入措施表明最小的 RNN 只會找到這個基於大小的解決方案，而較大的 RNN 則具有線性表示。這些發現強烈表明可解釋性研究不應受到 LRH 的限制。

##### **CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network**
2408.10919v2 by Zijian Zhao, Tingwei Chen, Zhijie Cai, Xiaoyang Li, Hang Li, Qimei Chen, Guangxu Zhu

In recent years, Wi-Fi sensing has garnered significant attention due to its
numerous benefits, such as privacy protection, low cost, and penetration
ability. Extensive research has been conducted in this field, focusing on areas
such as gesture recognition, people identification, and fall detection.
However, many data-driven methods encounter challenges related to domain shift,
where the model fails to perform well in environments different from the
training data. One major factor contributing to this issue is the limited
availability of Wi-Fi sensing datasets, which makes models learn excessive
irrelevant information and over-fit to the training set. Unfortunately,
collecting large-scale Wi-Fi sensing datasets across diverse scenarios is a
challenging task. To address this problem, we propose CrossFi, a siamese
network-based approach that excels in both in-domain scenario and cross-domain
scenario, including few-shot, zero-shot scenarios, and even works in few-shot
new-class scenario where testing set contains new categories. The core
component of CrossFi is a sample-similarity calculation network called CSi-Net,
which improves the structure of the siamese network by using an attention
mechanism to capture similarity information, instead of simply calculating the
distance or cosine similarity. Based on it, we develop an extra Weight-Net that
can generate a template for each class, so that our CrossFi can work in
different scenarios. Experimental results demonstrate that our CrossFi achieves
state-of-the-art performance across various scenarios. In gesture recognition
task, our CrossFi achieves an accuracy of 98.17% in in-domain scenario, 91.72%
in one-shot cross-domain scenario, 64.81% in zero-shot cross-domain scenario,
and 84.75% in one-shot new-class scenario. To facilitate future research, we
will release the code for our model upon publication.

摘要：近年来，Wi-Fi 感测因其众多优点而备受关注，例如隐私保护、低成本和穿透能力。该领域已进行广泛的研究，重点关注手势识别、人员识别和跌倒检测等领域。然而，许多数据驱动的方法遇到了与领域转移相关的挑战，其中模型无法在与训练数据不同的环境中很好地执行。导致此问题的一个主要因素是 Wi-Fi 感测数据集的可用性有限，这使得模型学习过多的无关信息并过度拟合训练集。不幸的是，在不同的场景中收集大规模 Wi-Fi 感测数据集是一项艰巨的任务。为了解决这个问题，我们提出了 CrossFi，这是一种基于连体网络的方法，它在域内场景和跨域场景中都表现出色，包括少样本、零样本场景，甚至可以在测试集中包含新类别的少样本新类别场景中工作。CrossFi 的核心组件是一个名为 CSi-Net 的样本相似度计算网络，它通过使用注意力机制来捕获相似性信息，而不是简单地计算距离或余弦相似性，从而改进了连体网络的结构。基于此，我们开发了一个额外的 Weight-Net，它可以为每个类别生成一个模板，以便我们的 CrossFi 可以在不同的场景中工作。实验结果表明，我们的 CrossFi 在各种场景中都取得了最先进的性能。在手势识别任务中，我们的 CrossFi 在域内场景中实现了 98.17% 的准确率，在单样本跨域场景中实现了 91.72% 的准确率，在零样本跨域场景中实现了 64.81% 的准确率，在单样本新类别场景中实现了 84.75% 的准确率。为了促进未来的研究，我们将在发表后发布我们模型的代码。

##### **CHECKWHY: Causal Fact Verification via Argument Structure**
2408.10918v1 by Jiasheng Si, Yibo Zhao, Yingjie Zhu, Haiyang Zhu, Wenpeng Lu, Deyu Zhou

With the growing complexity of fact verification tasks, the concern with
"thoughtful" reasoning capabilities is increasing. However, recent fact
verification benchmarks mainly focus on checking a narrow scope of semantic
factoids within claims and lack an explicit logical reasoning process. In this
paper, we introduce CheckWhy, a challenging dataset tailored to a novel causal
fact verification task: checking the truthfulness of the causal relation within
claims through rigorous reasoning steps. CheckWhy consists of over 19K "why"
claim-evidence-argument structure triplets with supports, refutes, and not
enough info labels. Each argument structure is composed of connected evidence,
representing the reasoning process that begins with foundational evidence and
progresses toward claim establishment. Through extensive experiments on
state-of-the-art models, we validate the importance of incorporating the
argument structure for causal fact verification. Moreover, the automated and
human evaluation of argument structure generation reveals the difficulty in
producing satisfying argument structure by fine-tuned models or
Chain-of-Thought prompted LLMs, leaving considerable room for future
improvements.

摘要：隨著事實查核任務的複雜性與日俱增，對於「周全」推理能力的關注也不斷提升。然而，近期的事實查核基準主要著重於檢核主張中語意事實的狹隘範圍，且缺乏明確的邏輯推理程序。在本文中，我們引入了 CheckWhy，這是一個專門針對新穎因果事實查核任務而量身打造的具挑戰性資料集：透過嚴謹的推理步驟，查核主張中因果關係的真實性。CheckWhy 包含超過 19K 個「為什麼」主張-證據-論證結構三元組，並附有支持、反駁和資訊不足的標籤。每個論證結構都由相關證據組成，代表從基礎證據開始，逐步邁向主張確立的推理程序。透過對最先進模型進行廣泛的實驗，我們驗證了將論證結構納入因果事實查核中的重要性。此外，論證結構生成的自動化和人工評估揭示了微調模型或提示式 LLM 難以產生令人滿意的論證結構，這為未來的改進留下了相當大的空間。

##### **To Code, or Not To Code? Exploring Impact of Code in Pre-training**
2408.10914v1 by Viraat Aryabumi, Yixuan Su, Raymond Ma, Adrien Morisot, Ivan Zhang, Acyr Locatelli, Marzieh Fadaee, Ahmet Üstün, Sara Hooker

Including code in the pre-training data mixture, even for models not
specifically designed for code, has become a common practice in LLMs
pre-training. While there has been anecdotal consensus among practitioners that
code data plays a vital role in general LLMs' performance, there is only
limited work analyzing the precise impact of code on non-code tasks. In this
work, we systematically investigate the impact of code data on general
performance. We ask "what is the impact of code data used in pre-training on a
large variety of downstream tasks beyond code generation". We conduct extensive
ablations and evaluate across a broad range of natural language reasoning
tasks, world knowledge tasks, code benchmarks, and LLM-as-a-judge win-rates for
models with sizes ranging from 470M to 2.8B parameters. Across settings, we
find a consistent results that code is a critical building block for
generalization far beyond coding tasks and improvements to code quality have an
outsized impact across all tasks. In particular, compared to text-only
pre-training, the addition of code results in up to relative increase of 8.2%
in natural language (NL) reasoning, 4.2% in world knowledge, 6.6% improvement
in generative win-rates, and a 12x boost in code performance respectively. Our
work suggests investments in code quality and preserving code during
pre-training have positive impacts.

摘要：在預訓練資料混合中包含程式碼，即使對於並非專門設計用於程式碼的模型，已成為 LLM 預訓練的常見做法。雖然從業者之間有共識，認為程式碼資料在一般 LLM 的效能中扮演至關重要的角色，但僅有少數研究分析程式碼對非程式碼任務的精確影響。在此研究中，我們系統性地探討程式碼資料對一般效能的影響。我們詢問「在預訓練中使用的程式碼資料對程式碼產生之外的各種下游任務有何影響」。我們進行廣泛的消融，並評估各種自然語言推理任務、世界知識任務、程式碼基準，以及從 4.7 億到 28 億個參數的模型的 LLM 作為評審的獲勝率。在各項設定中，我們發現一致的結果，程式碼是遠超出編碼任務的概括性關鍵建構模組，而程式碼品質的提升對所有任務都有過大的影響。特別是，與僅文字的預訓練相比，加入程式碼可分別在自然語言 (NL) 推理中增加高達 8.2%、世界知識中增加 4.2%、生成獲勝率中提升 6.6%，以及程式碼效能提升 12 倍。我們的研究建議，在預訓練期間投資程式碼品質和保留程式碼具有正面的影響。

##### **The impact of labeling automotive AI as "trustworthy" or "reliable" on user evaluation and technology acceptance**
2408.10905v1 by John Dorsch, Ophelia Deroy

This study explores whether labeling AI as "trustworthy" or "reliable"
influences user perceptions and acceptance of automotive AI technologies. Using
a one-way between-subjects design, the research involved 478 online
participants who were presented with guidelines for either trustworthy or
reliable AI. Participants then evaluated three vignette scenarios and completed
a modified version of the Technology Acceptance Model, which included variables
such as perceived ease of use, human-like trust, and overall attitude. Although
labeling AI as "trustworthy" did not significantly influence judgments on
specific scenarios, it increased perceived ease of use and human-like trust,
particularly benevolence. This suggests a positive impact on usability and an
anthropomorphic effect on user perceptions. The study provides insights into
how specific labels can influence attitudes toward AI technology.

摘要：本研究探讨標籤 AI 為「可信賴」或「可靠」是否會影響使用者對汽車 AI 技術的認知和接受度。研究採用單向受試者間設計，參與研究的 478 位線上參與者會收到可信賴或可靠 AI 的指引。參與者接著評估三個短文情境，並完成改良版的技術接受模式，其中包含感知易用性、類人信任和整體態度等變數。雖然標籤 AI 為「可信賴」並未顯著影響對特定情境的判斷，但它提高了感知易用性和類人信任，特別是仁慈。這表示對可用性有正面影響，並對使用者認知產生擬人化效果。本研究提供深入見解，說明特定標籤如何影響對 AI 技術的態度。

##### **BEYOND DIALOGUE: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model**
2408.10903v2 by Yeyong Yu, Rusheng Yu, Haojie Wei, Zhanqiu Zhang, Quan Qian

The rapid advancement of large language models (LLMs) has revolutionized
role-playing, enabling the development of general role-playing models. However,
current role-playing training has two significant issues: (I) Using a
predefined role profile to prompt dialogue training for specific scenarios
usually leads to inconsistencies and even conflicts between the dialogue and
the profile, resulting in training biases. (II) The model learns to imitate the
role based solely on the profile, neglecting profile-dialogue alignment at the
sentence level. In this work, we propose a simple yet effective framework
called BEYOND DIALOGUE, designed to overcome these hurdles. This framework
innovatively introduces "beyond dialogue" tasks to align dialogue with profile
traits based on each specific scenario, thereby eliminating biases during
training. Furthermore, by adopting an innovative prompting mechanism that
generates reasoning outcomes for training, the framework allows the model to
achieve fine-grained alignment between profile and dialogue at the sentence
level. The aforementioned methods are fully automated and low-cost.
Additionally, the integration of automated dialogue and objective evaluation
methods forms a comprehensive framework, paving the way for general
role-playing. Experimental results demonstrate that our model excels in
adhering to and reflecting various dimensions of role profiles, outperforming
most proprietary general and specialized role-playing baselines. All code and
datasets are available at https://github.com/yuyouyu32/BeyondDialogue.

摘要：大型語言模型 (LLM) 的快速進步徹底改變了角色扮演，促使通用角色扮演模型的發展。然而，當前的角色扮演訓練有兩個重大問題：(I) 使用預定義的角色檔案來提示特定場景的對話訓練通常會導致對話和檔案之間的不一致，甚至衝突，從而導致訓練偏差。(II) 該模型僅根據檔案學習模仿角色，忽略了句子層級的檔案對話對齊。在這項工作中，我們提出了一個簡單但有效的框架，稱為 BEYOND DIALOGUE，旨在克服這些障礙。這個框架創新地引入了「超越對話」任務，以根據每個特定場景將對話與檔案特徵對齊，從而消除訓練過程中的偏差。此外，透過採用創新的提示機制來產生訓練的推理結果，該框架允許模型在句子層級實現檔案和對話之間的細緻對齊。上述方法完全自動化且成本低廉。此外，自動對話和客觀評估方法的整合形成了一個全面的框架，為通用角色扮演鋪平了道路。實驗結果證明，我們的模型在遵守和反映角色檔案的各種面向方面表現出色，優於大多數專有通用和特定角色扮演基準。所有程式碼和資料集都可以在 https://github.com/yuyouyu32/BeyondDialogue 獲得。

##### **Soda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs**
2408.10902v1 by John Mendonça, Isabel Trancoso, Alon Lavie

Although human evaluation remains the gold standard for open-domain dialogue
evaluation, the growing popularity of automated evaluation using Large Language
Models (LLMs) has also extended to dialogue. However, most frameworks leverage
benchmarks that assess older chatbots on aspects such as fluency and relevance,
which are not reflective of the challenges associated with contemporary models.
In fact, a qualitative analysis on Soda, a GPT-3.5 generated dialogue dataset,
suggests that current chatbots may exhibit several recurring issues related to
coherence and commonsense knowledge, but generally produce highly fluent and
relevant responses.
  Noting the aforementioned limitations, this paper introduces Soda-Eval, an
annotated dataset based on Soda that covers over 120K turn-level assessments
across 10K dialogues, where the annotations were generated by GPT-4. Using
Soda-Eval as a benchmark, we then study the performance of several open-access
instruction-tuned LLMs, finding that dialogue evaluation remains challenging.
Fine-tuning these models improves performance over few-shot inferences, both in
terms of correlation and explanation.

摘要：儘管人工評估仍然是開放領域對話評估的黃金標準，使用大型語言模型 (LLM) 進行自動評估的普及程度也已擴展到對話。然而，大多數框架利用基準來評估較舊的聊天機器人在流暢度和相關性等方面的表現，這並未反映與當代模型相關的挑戰。事實上，對 GPT-3.5 生成的對話資料集 Soda 進行的定性分析表明，當前的聊天機器人可能會出現與連貫性和常識知識相關的幾個重複問題，但通常會產生高度流暢且相關的回應。注意到上述限制，本文介紹了 Soda-Eval，一個基於 Soda 的註解資料集，涵蓋了 10K 個對話中超過 120K 個回合層級的評估，其中註解是由 GPT-4 生成的。使用 Soda-Eval 作為基準，我們接著研究了幾個開放存取的指令調整 LLM 的效能，發現對話評估仍然具有挑戰性。微調這些模型會改善對少次推論的效能，無論是在相關性還是解釋方面。

##### **A Grey-box Attack against Latent Diffusion Model-based Image Editing by Posterior Collapse**
2408.10901v1 by Zhongliang Guo, Lei Fang, Jingyu Lin, Yifei Qian, Shuai Zhao, Zeyu Wang, Junhao Dong, Cunjian Chen, Ognjen Arandjelović, Chun Pong Lau

Recent advancements in generative AI, particularly Latent Diffusion Models
(LDMs), have revolutionized image synthesis and manipulation. However, these
generative techniques raises concerns about data misappropriation and
intellectual property infringement. Adversarial attacks on machine learning
models have been extensively studied, and a well-established body of research
has extended these techniques as a benign metric to prevent the underlying
misuse of generative AI. Current approaches to safeguarding images from
manipulation by LDMs are limited by their reliance on model-specific knowledge
and their inability to significantly degrade semantic quality of generated
images. In response to these shortcomings, we propose the Posterior Collapse
Attack (PCA) based on the observation that VAEs suffer from posterior collapse
during training. Our method minimizes dependence on the white-box information
of target models to get rid of the implicit reliance on model-specific
knowledge. By accessing merely a small amount of LDM parameters, in specific
merely the VAE encoder of LDMs, our method causes a substantial semantic
collapse in generation quality, particularly in perceptual consistency, and
demonstrates strong transferability across various model architectures.
Experimental results show that PCA achieves superior perturbation effects on
image generation of LDMs with lower runtime and VRAM. Our method outperforms
existing techniques, offering a more robust and generalizable solution that is
helpful in alleviating the socio-technical challenges posed by the rapidly
evolving landscape of generative AI.

摘要：生成式 AI 的最新进展，尤其是潜在擴散模型 (LDM)，徹底改變了圖像合成和處理。然而，這些生成技術引發了對資料盜用和智慧財產權侵權的擔憂。已經廣泛研究了對機器學習模型的對抗性攻擊，並且大量既定的研究已將這些技術延伸為一項良性指標，以防止生成式 AI 的潛在誤用。目前保護圖像免受 LDM 操縱的方法受到其依賴模型特定知識和無法顯著降低生成圖像的語義品質的限制。針對這些缺點，我們提出了後驗崩潰攻擊 (PCA)，其基於在訓練期間 VAE 會遭受後驗崩潰的觀察。我們的技術將對目標模型的白盒資訊的依賴降到最低，以擺脫對模型特定知識的隱含依賴。透過僅存取少量 LDM 參數，特別是 LDM 的 VAE 編碼器，我們的技術會導致生成品質出現大量的語義崩潰，特別是在感知一致性方面，並展示出跨各種模型架構的強大可移植性。實驗結果顯示，PCA 以較低的執行時間和 VRAM 對 LDM 的影像生成實現了優越的擾動效果。我們的技術優於現有技術，提供了一個更強大且可概化的解決方案，有助於減輕生成式 AI 快速演變的環境所帶來的社會技術挑戰。

##### **Towards Efficient Formal Verification of Spiking Neural Network**
2408.10900v1 by Baekryun Seong, Jieung Kim, Sang-Ki Ko

Recently, AI research has primarily focused on large language models (LLMs),
and increasing accuracy often involves scaling up and consuming more power. The
power consumption of AI has become a significant societal issue; in this
context, spiking neural networks (SNNs) offer a promising solution. SNNs
operate event-driven, like the human brain, and compress information
temporally. These characteristics allow SNNs to significantly reduce power
consumption compared to perceptron-based artificial neural networks (ANNs),
highlighting them as a next-generation neural network technology. However,
societal concerns regarding AI go beyond power consumption, with the
reliability of AI models being a global issue. For instance, adversarial
attacks on AI models are a well-studied problem in the context of traditional
neural networks. Despite their importance, the stability and property
verification of SNNs remains in the early stages of research. Most SNN
verification methods are time-consuming and barely scalable, making practical
applications challenging. In this paper, we introduce temporal encoding to
achieve practical performance in verifying the adversarial robustness of SNNs.
We conduct a theoretical analysis of this approach and demonstrate its success
in verifying SNNs at previously unmanageable scales. Our contribution advances
SNN verification to a practical level, facilitating the safer application of
SNNs.

摘要：最近，人工智慧研究主要集中於大型語言模型 (LLM)，而提高準確度通常涉及擴大規模和消耗更多電力。人工智慧的電力消耗已成為一個重大的社會問題；在此背景下，尖峰神經網路 (SNN) 提供了一個有希望的解決方案。SNN 以事件驅動的方式運作，就像人腦一樣，並在時間上壓縮資訊。這些特性讓 SNN 能夠顯著降低電力消耗，與基於感知器的類神經網路 (ANN) 相比，突顯了它們作為下一代神經網路技術的地位。然而，社會對人工智慧的關注不只於電力消耗，人工智慧模型的可靠性是一個全球性的問題。例如，對人工智慧模型的對抗攻擊是傳統神經網路背景下一個研究得很透徹的問題。儘管它們很重要，但 SNN 的穩定性和屬性驗證仍處於研究的早期階段。大多數 SNN 驗證方法耗時且幾乎無法擴展，使得實際應用具有挑戰性。在本文中，我們引入了時間編碼，以在驗證 SNN 的對抗魯棒性方面取得實際效能。我們對這種方法進行了理論分析，並證明了它在以前無法管理的規模上驗證 SNN 的成功。我們的貢獻將 SNN 驗證提升到一個實用的層次，促進了 SNN 更安全的應用。

##### **Analytical and Empirical Study of Herding Effects in Recommendation Systems**
2408.10895v1 by Hong Xie, Mingze Zhong, Defu Lian, Zhen Wang, Enhong Chen

Online rating systems are often used in numerous web or mobile applications,
e.g., Amazon and TripAdvisor, to assess the ground-truth quality of products.
Due to herding effects, the aggregation of historical ratings (or historical
collective opinion) can significantly influence subsequent ratings, leading to
misleading and erroneous assessments. We study how to manage product ratings
via rating aggregation rules and shortlisted representative reviews, for the
purpose of correcting the assessment error. We first develop a mathematical
model to characterize important factors of herding effects in product ratings.
We then identify sufficient conditions (via the stochastic approximation
theory), under which the historical collective opinion converges to the
ground-truth collective opinion of the whole user population. These conditions
identify a class of rating aggregation rules and review selection mechanisms
that can reveal the ground-truth product quality. We also quantify the speed of
convergence (via the martingale theory), which reflects the efficiency of
rating aggregation rules and review selection mechanisms. We prove that the
herding effects slow down the speed of convergence while an accurate review
selection mechanism can speed it up. We also study the speed of convergence
numerically and reveal trade-offs in selecting rating aggregation rules and
review selection mechanisms. To show the utility of our framework, we design a
maximum likelihood algorithm to infer model parameters from ratings, and
conduct experiments on rating datasets from Amazon and TripAdvisor. We show
that proper recency aware rating aggregation rules can improve the speed of
convergence in Amazon and TripAdvisor by 41% and 62% respectively.

摘要：線上評分系統常被用在許多網路或行動應用程式中，例如 Amazon 和 TripAdvisor，用來評估產品的真實品質。由於從眾效應，歷史評分（或歷史集體意見）的彙整可能會對後續評分產生重大影響，導致評估失真且錯誤。我們研究如何透過評分彙整規則和精選具代表性的評論來管理產品評分，以修正評估錯誤。我們首先開發一個數學模型來描述產品評分中從眾效應的重要因素。接著我們找出充分條件（透過隨機近似理論），在該條件下，歷史集體意見會收斂到所有使用者族群的真實集體意見。這些條件找出一個評分彙整規則和評論選取機制的類別，可以揭露真實產品品質。我們也量化收斂速度（透過鞅理論），反映評分彙整規則和評論選取機制的效率。我們證明從眾效應會減緩收斂速度，而精確的評論選取機制可以加快速度。我們也以數值方式研究收斂速度，並揭露在選取評分彙整規則和評論選取機制時的取捨。為了顯示我們架構的效用，我們設計了一個最大概似演算法來從評分中推論模型參數，並對來自 Amazon 和 TripAdvisor 的評分資料集進行實驗。我們顯示適當的最新評分彙整規則可以分別改善 Amazon 和 TripAdvisor 中的收斂速度 41% 和 62%。

##### **On Learning Action Costs from Input Plans**
2408.10889v1 by Marianela Morales, Alberto Pozanco, Giuseppe Canonaco, Sriram Gopalakrishnan, Daniel Borrajo, Manuela Veloso

Most of the work on learning action models focus on learning the actions'
dynamics from input plans. This allows us to specify the valid plans of a
planning task. However, very little work focuses on learning action costs,
which in turn allows us to rank the different plans. In this paper we introduce
a new problem: that of learning the costs of a set of actions such that a set
of input plans are optimal under the resulting planning model. To solve this
problem we present $LACFIP^k$, an algorithm to learn action's costs from
unlabeled input plans. We provide theoretical and empirical results showing how
$LACFIP^k$ can successfully solve this task.

摘要：大多數學習動作模型的工作都專注於從輸入計畫中學習動作的動態。這使我們能夠指定規劃任務的有效計畫。然而，很少有工作專注於學習動作成本，而這反過來又使我們能夠對不同的計畫進行排序。在本文中，我們引入了一個新問題：學習一組動作的成本，使得一組輸入計畫在產生的規劃模型下是最佳的。為了解決這個問題，我們提出了 $LACFIP^k$，一種從未標記的輸入計畫中學習動作成本的演算法。我們提供了理論和實證結果，顯示 $LACFIP^k$ 如何成功解決這個任務。

##### **DAAD: Dynamic Analysis and Adaptive Discriminator for Fake News Detection**
2408.10883v1 by Xinqi Su, Yawen Cui, Ajian Liu, Xun Lin, Yuhao Wang, Haochen Liang, Wenhui Li, Zitong Yu

In current web environment, fake news spreads rapidly across online social
networks, posing serious threats to society. Existing multimodal fake news
detection (MFND) methods can be classified into knowledge-based and
semantic-based approaches. However, these methods are overly dependent on human
expertise and feedback, lacking flexibility. To address this challenge, we
propose a Dynamic Analysis and Adaptive Discriminator (DAAD) approach for fake
news detection. For knowledge-based methods, we introduce the Monte Carlo Tree
Search (MCTS) algorithm to leverage the self-reflective capabilities of large
language models (LLMs) for prompt optimization, providing richer,
domain-specific details and guidance to the LLMs, while enabling more flexible
integration of LLM comment on news content. For semantic-based methods, we
define four typical deceit patterns: emotional exaggeration, logical
inconsistency, image manipulation, and semantic inconsistency, to reveal the
mechanisms behind fake news creation. To detect these patterns, we carefully
design four discriminators and expand them in depth and breadth, using the
soft-routing mechanism to explore optimal detection models. Experimental
results on three real-world datasets demonstrate the superiority of our
approach. The code will be available at: https://github.com/SuXinqi/DAAD.

摘要：在當前的網路環境中，假新聞在線上社群網路中快速散播，對社會構成嚴重的威脅。現有的多模態假新聞偵測 (MFND) 方法可分類為基於知識和基於語意的方法。然而，這些方法過度依賴於人類的專業知識和回饋，缺乏靈活性。為了應對這個挑戰，我們提出一個動態分析和適應性辨識器 (DAAD) 方法來偵測假新聞。對於基於知識的方法，我們引入蒙地卡羅樹搜尋 (MCTS) 演算法，以利用大型語言模型 (LLM) 的自我反省能力來進行提示最佳化，為 LLM 提供更豐富、特定於領域的細節和指導，同時讓 LLM 對新聞內容的評論能更靈活地整合。對於基於語意的方法，我們定義了四種典型的欺騙模式：情緒誇大、邏輯不一致、圖像竄改和語意不一致，以揭露假新聞創作背後的機制。為了偵測這些模式，我們仔細設計了四個辨識器，並在深度和廣度上擴展它們，使用軟路由機制來探索最佳的偵測模型。在三個真實世界資料集上的實驗結果證明了我們方法的優越性。程式碼將會在 https://github.com/SuXinqi/DAAD 上提供。

##### **V-RoAst: A New Dataset for Visual Road Assessment**
2408.10872v2 by Natchapon Jongwiriyanurak, Zichao Zeng, June Moh Goo, Xinglei Wang, Ilya Ilyankou, Kerkritt Srirrongvikrai, Meihui Wang, James Haworth

Road traffic crashes cause millions of deaths annually and have a significant
economic impact, particularly in low- and middle-income countries (LMICs). This
paper presents an approach using Vision Language Models (VLMs) for road safety
assessment, overcoming the limitations of traditional Convolutional Neural
Networks (CNNs). We introduce a new task ,V-RoAst (Visual question answering
for Road Assessment), with a real-world dataset. Our approach optimizes prompt
engineering and evaluates advanced VLMs, including Gemini-1.5-flash and
GPT-4o-mini. The models effectively examine attributes for road assessment.
Using crowdsourced imagery from Mapillary, our scalable solution influentially
estimates road safety levels. In addition, this approach is designed for local
stakeholders who lack resources, as it does not require training data. It
offers a cost-effective and automated methods for global road safety
assessments, potentially saving lives and reducing economic burdens.

摘要：道路交通事故每年造成數百萬人死亡，並產生重大的經濟影響，特別是在中低收入國家 (LMIC)。本文提出使用視覺語言模型 (VLM) 來進行道路安全評估的方法，克服了傳統卷積神經網路 (CNN) 的限制。我們引進一個新任務，V-RoAst（道路評估的視覺問答），並附有一個真實世界的資料集。我們的做法優化了提示工程，並評估了先進的 VLM，包括 Gemini-1.5-flash 和 GPT-4o-mini。這些模型有效地檢查了道路評估的屬性。透過使用來自 Mapillary 的群眾外包影像，我們的可擴充解決方案可有效地估計道路安全等級。此外，此方法是為缺乏資源的地方利害關係人所設計，因為它不需要訓練資料。它提供了一種具成本效益且自動化的全球道路安全評估方法，有可能挽救生命並減輕經濟負擔。

##### **Multi-agent Multi-armed Bandits with Stochastic Sharable Arm Capacities**
2408.10865v1 by Hong Xie, Jinyu Mo, Defu Lian, Jie Wang, Enhong Chen

Motivated by distributed selection problems, we formulate a new variant of
multi-player multi-armed bandit (MAB) model, which captures stochastic arrival
of requests to each arm, as well as the policy of allocating requests to
players. The challenge is how to design a distributed learning algorithm such
that players select arms according to the optimal arm pulling profile (an arm
pulling profile prescribes the number of players at each arm) without
communicating to each other. We first design a greedy algorithm, which locates
one of the optimal arm pulling profiles with a polynomial computational
complexity. We also design an iterative distributed algorithm for players to
commit to an optimal arm pulling profile with a constant number of rounds in
expectation. We apply the explore then commit (ETC) framework to address the
online setting when model parameters are unknown. We design an exploration
strategy for players to estimate the optimal arm pulling profile. Since such
estimates can be different across different players, it is challenging for
players to commit. We then design an iterative distributed algorithm, which
guarantees that players can arrive at a consensus on the optimal arm pulling
profile in only M rounds. We conduct experiments to validate our algorithm.

摘要：受分布式选择问题启发，我们制定了一个新的多玩家多臂赌博机 (MAB) 模型，该模型捕获了到达每个手臂的请求的随机到达，以及将请求分配给玩家的策略。挑战在于如何设计一个分布式学习算法，以便玩家根据最优手臂拉取配置文件（手臂拉取配置文件规定每个手臂的玩家数量）选择手臂，而无需相互通信。我们首先设计了一个贪心算法，该算法以多项式计算复杂度找到一个最优手臂拉取配置文件。我们还设计了一个迭代分布式算法，让玩家在期望的恒定轮数内提交一个最优手臂拉取配置文件。我们应用探索然后提交 (ETC) 框架来解决模型参数未知时的在线设置。我们设计了一个探索策略，让玩家估计最优手臂拉取配置文件。由于此类估计在不同玩家之间可能不同，因此玩家提交具有挑战性。然后，我们设计了一个迭代分布式算法，该算法保证玩家可以在仅 M 轮中就最优手臂拉取配置文件达成共识。我们进行实验来验证我们的算法。

##### **MambaDS: Near-Surface Meteorological Field Downscaling with Topography Constrained Selective State Space Modeling**
2408.10854v1 by Zili Liu, Hao Chen, Lei Bai, Wenyuan Li, Wanli Ouyang, Zhengxia Zou, Zhenwei Shi

In an era of frequent extreme weather and global warming, obtaining precise,
fine-grained near-surface weather forecasts is increasingly essential for human
activities. Downscaling (DS), a crucial task in meteorological forecasting,
enables the reconstruction of high-resolution meteorological states for target
regions from global-scale forecast results. Previous downscaling methods,
inspired by CNN and Transformer-based super-resolution models, lacked tailored
designs for meteorology and encountered structural limitations. Notably, they
failed to efficiently integrate topography, a crucial prior in the downscaling
process. In this paper, we address these limitations by pioneering the
selective state space model into the meteorological field downscaling and
propose a novel model called MambaDS. This model enhances the utilization of
multivariable correlations and topography information, unique challenges in the
downscaling process while retaining the advantages of Mamba in long-range
dependency modeling and linear computational complexity. Through extensive
experiments in both China mainland and the continental United States (CONUS),
we validated that our proposed MambaDS achieves state-of-the-art results in
three different types of meteorological field downscaling settings. We will
release the code subsequently.

摘要：在频繁发生极端天气和全球变暖的时代，获得精确、细粒度的近地表天气预报对于人类活动而言变得越来越重要。降尺度（DS）是气象预报中的一项关键任务，它能够从全球尺度的预报结果中重建目标区域的高分辨率气象状态。先前的降尺度方法受到 CNN 和基于 Transformer 的超分辨率模型的启发，但缺乏针对气象学的定制化设计，并遇到了结构性限制。值得注意的是，它们未能有效地整合地形，而地形是降尺度过程中的一个关键先验。在本文中，我们通过将选择性状态空间模型引入气象领域降尺度来解决这些限制，并提出了一种名为 MambaDS 的新模型。该模型增强了多变量相关性和地形信息（降尺度过程中的独特挑战）的利用，同时保留了 Mamba 在长程依赖建模和线性计算复杂性方面的优势。通过在中国大陆和美国大陆（CONUS）进行的广泛实验，我们验证了我们提出的 MambaDS 在三种不同类型的气象场降尺度设置中取得了最先进的结果。我们随后将发布该代码。

##### **Does Current Deepfake Audio Detection Model Effectively Detect ALM-based Deepfake Audio?**
2408.10853v1 by Yuankun Xie, Chenxu Xiong, Xiaopeng Wang, Zhiyong Wang, Yi Lu, Xin Qi, Ruibo Fu, Yukun Liu, Zhengqi Wen, Jianhua Tao, Guanjun Li, Long Ye

Currently, Audio Language Models (ALMs) are rapidly advancing due to the
developments in large language models and audio neural codecs. These ALMs have
significantly lowered the barrier to creating deepfake audio, generating highly
realistic and diverse types of deepfake audio, which pose severe threats to
society. Consequently, effective audio deepfake detection technologies to
detect ALM-based audio have become increasingly critical. This paper
investigate the effectiveness of current countermeasure (CM) against ALM-based
audio. Specifically, we collect 12 types of the latest ALM-based deepfake audio
and utilizing the latest CMs to evaluate. Our findings reveal that the latest
codec-trained CM can effectively detect ALM-based audio, achieving 0% equal
error rate under most ALM test conditions, which exceeded our expectations.
This indicates promising directions for future research in ALM-based deepfake
audio detection.

摘要：目前，由於大型語言模型和音訊神經編碼器技術的發展，音訊語言模型 (ALM) 正在快速進步。這些 ALM 已大幅降低製作深度偽造音訊的門檻，產生高度逼真且多樣化的深度偽造音訊類型，對社會構成嚴重威脅。因此，用於偵測基於 ALM 的音訊的有效音訊深度偽造偵測技術變得越來越重要。本文探討目前針對基於 ALM 的音訊的反制措施 (CM) 的有效性。具體來說，我們收集了 12 種類型的最新基於 ALM 的深度偽造音訊，並利用最新 CM 進行評估。我們的研究結果表明，最新的編碼器訓練 CM 可以有效偵測基於 ALM 的音訊，在大部分 ALM 測試條件下達到 0% 的相等錯誤率，這超出了我們的預期。這表明未來基於 ALM 的深度偽造音訊偵測的研究具有良好的發展方向。

##### **Benchmarking Large Language Models for Math Reasoning Tasks**
2408.10839v1 by Kathrin Seßler, Yao Rong, Emek Gözlüklü, Enkelejda Kasneci

The use of Large Language Models (LLMs) in mathematical reasoning has become
a cornerstone of related research, demonstrating the intelligence of these
models and enabling potential practical applications through their advanced
performance, such as in educational settings. Despite the variety of datasets
and in-context learning algorithms designed to improve the ability of LLMs to
automate mathematical problem solving, the lack of comprehensive benchmarking
across different datasets makes it complicated to select an appropriate model
for specific tasks. In this project, we present a benchmark that fairly
compares seven state-of-the-art in-context learning algorithms for mathematical
problem solving across five widely used mathematical datasets on four powerful
foundation models. Furthermore, we explore the trade-off between efficiency and
performance, highlighting the practical applications of LLMs for mathematical
reasoning. Our results indicate that larger foundation models like GPT-4o and
LLaMA 3-70B can solve mathematical reasoning independently from the concrete
prompting strategy, while for smaller models the in-context learning approach
significantly influences the performance. Moreover, the optimal prompt depends
on the chosen foundation model. We open-source our benchmark code to support
the integration of additional models in future research.

摘要：在数学推理中使用大型语言模型 (LLM) 已成为相关研究的基石，展示了这些模型的智能，并通过其先进的性能（例如在教育环境中）实现了潜在的实际应用。尽管有各种数据集和旨在提高 LLM 自动化解决数学问题的能力的上下文学习算法，但缺乏跨不同数据集的综合基准测试使得为特定任务选择合适的模型变得复杂。在这个项目中，我们提出了一个基准，该基准公平地比较了七种最先进的用于数学问题的上下文学习算法，这些问题分布在四个强大的基础模型上的五个广泛使用的数学数据集上。此外，我们探索了效率和性能之间的权衡，重点介绍了 LLM 在数学推理中的实际应用。我们的结果表明，像 GPT-4o 和 LLaMA 3-70B 这样较大的基础模型可以独立于具体的提示策略解决数学推理问题，而对于较小的模型，上下文学习方法会显著影响性能。此外，最佳提示取决于所选的基础模型。我们开源我们的基准代码以支持在未来的研究中集成其他模型。

##### **ZebraPose: Zebra Detection and Pose Estimation using only Synthetic Data**
2408.10831v1 by Elia Bonetto, Aamir Ahmad

Synthetic data is increasingly being used to address the lack of labeled
images in uncommon domains for deep learning tasks. A prominent example is 2D
pose estimation of animals, particularly wild species like zebras, for which
collecting real-world data is complex and impractical. However, many approaches
still require real images, consistency and style constraints, sophisticated
animal models, and/or powerful pre-trained networks to bridge the syn-to-real
gap. Moreover, they often assume that the animal can be reliably detected in
images or videos, a hypothesis that often does not hold, e.g. in wildlife
scenarios or aerial images. To solve this, we use synthetic data generated with
a 3D photorealistic simulator to obtain the first synthetic dataset that can be
used for both detection and 2D pose estimation of zebras without applying any
of the aforementioned bridging strategies. Unlike previous works, we
extensively train and benchmark our detection and 2D pose estimation models on
multiple real-world and synthetic datasets using both pre-trained and
non-pre-trained backbones. These experiments show how the models trained from
scratch and only with synthetic data can consistently generalize to real-world
images of zebras in both tasks. Moreover, we show it is possible to easily
generalize those same models to 2D pose estimation of horses with a minimal
amount of real-world images to account for the domain transfer. Code, results,
trained models; and the synthetic, training, and validation data, including
104K manually labeled frames, are provided as open-source at
https://zebrapose.is.tue.mpg.de/

摘要：<paragraph>合成資料越來越多地用於解決深度學習任務中罕見領域中標記影像的不足。一個顯著的例子是動物的 2D 姿勢估計，特別是斑馬等野生物種，因為收集真實世界的資料很複雜且不切實際。然而，許多方法仍然需要真實影像、一致性和樣式約束、精密的動物模型和/或強大的預訓練網路來彌合合成到真實的差距。此外，它們通常假設可以在影像或影片中可靠地偵測動物，這是一個經常不成立的假設，例如在野生動物場景或航照影像中。為了解決這個問題，我們使用 3D 真實感模擬器產生的合成資料來取得第一個合成資料集，該資料集可用於斑馬的偵測和 2D 姿勢估計，而無需套用任何上述的橋接策略。與之前的作品不同，我們在多個真實世界和合成資料集上廣泛訓練和評量我們的偵測和 2D 姿勢估計模型，同時使用預訓練和非預訓練的骨幹。這些實驗顯示了從頭開始訓練且僅使用合成資料的模型如何能夠一致地概化到斑馬的真實世界影像中的兩個任務。此外，我們展示了可以輕鬆地將這些相同的模型概化到馬的 2D 姿勢估計，只需少量真實世界影像來考量領域轉移。程式碼、結果、訓練模型；以及合成、訓練和驗證資料，包括 104K 手動標記的影格，都可以在 https://zebrapose.is.tue.mpg.de/ 以開源方式取得</paragraph>

##### **Exploiting Large Language Models Capabilities for Question Answer-Driven Knowledge Graph Completion Across Static and Temporal Domains**
2408.10819v1 by Rui Yang, Jiahao Zhu, Jianping Man, Li Fang, Yi Zhou

Knowledge graph completion (KGC) aims to identify missing triples in a
knowledge graph (KG). This is typically achieved through tasks such as link
prediction and instance completion. However, these methods often focus on
either static knowledge graphs (SKGs) or temporal knowledge graphs (TKGs),
addressing only within-scope triples. This paper introduces a new generative
completion framework called Generative Subgraph-based KGC (GS-KGC). GS-KGC
employs a question-answering format to directly generate target entities,
addressing the challenge of questions having multiple possible answers. We
propose a strategy that extracts subgraphs centered on entities and
relationships within the KG, from which negative samples and neighborhood
information are separately obtained to address the one-to-many problem. Our
method generates negative samples using known facts to facilitate the discovery
of new information. Furthermore, we collect and refine neighborhood path data
of known entities, providing contextual information to enhance reasoning in
large language models (LLMs). Our experiments evaluated the proposed method on
four SKGs and two TKGs, achieving state-of-the-art Hits@1 metrics on five
datasets. Analysis of the results shows that GS-KGC can discover new triples
within existing KGs and generate new facts beyond the closed KG, effectively
bridging the gap between closed-world and open-world KGC.

摘要：知識圖譜補全 (KGC) 的目標是識別知識圖譜 (KG) 中遺失的三元組。這通常透過連結預測和實例補全等任務達成。然而，這些方法通常專注於靜態知識圖譜 (SKG) 或時序知識圖譜 (TKG)，僅處理範圍內的三元組。本文介紹一個名為生成子圖為基礎的 KGC (GS-KGC) 的新生成補全架構。GS-KGC 使用問答格式直接生成目標實體，以解決問題有多個可能答案的挑戰。我們提出一個策略，從知識圖譜中以實體和關係為中心的子圖，從中分別取得負面樣本和鄰域資訊，以解決一對多問題。我們的模型使用已知事實生成負面樣本，以利發現新資訊。此外，我們收集並精煉已知實體的鄰域路徑資料，提供背景資訊以增強大型語言模型 (LLM) 中的推理。我們的實驗在四個 SKG 和兩個 TKG 上評估所提出的方法，在五個資料集上達成最先進的 Hits@1 指標。結果分析顯示，GS-KGC 能夠在現有的 KG 中發現新的三元組，並生成封閉 KG 以外的新事實，有效地縮小封閉世界和開放世界 KGC 之間的差距。

##### **Beyond English-Centric LLMs: What Language Do Multilingual Language Models Think in?**
2408.10811v1 by Chengzhi Zhong, Fei Cheng, Qianying Liu, Junfeng Jiang, Zhen Wan, Chenhui Chu, Yugo Murawaki, Sadao Kurohashi

In this study, we investigate whether non-English-centric LLMs, despite their
strong performance, `think' in their respective dominant language: more
precisely, `think' refers to how the representations of intermediate layers,
when un-embedded into the vocabulary space, exhibit higher probabilities for
certain dominant languages during generation. We term such languages as
internal $\textbf{latent languages}$.
  We examine the latent language of three typical categories of models for
Japanese processing: Llama2, an English-centric model; Swallow, an
English-centric model with continued pre-training in Japanese; and LLM-jp, a
model pre-trained on balanced English and Japanese corpora. Our empirical
findings reveal that, unlike Llama2 which relies exclusively on English as the
internal latent language, Japanese-specific Swallow and LLM-jp employ both
Japanese and English, exhibiting dual internal latent languages. For any given
target language, the model preferentially activates the latent language most
closely related to it. In addition, we explore how intermediate layers respond
to questions involving cultural conflicts between latent internal and target
output languages. We further explore how the language identity shifts across
layers while keeping consistent semantic meaning reflected in the intermediate
layer representations.
  This study deepens the understanding of non-English-centric large language
models, highlighting the intricate dynamics of language representation within
their intermediate layers.

摘要：在這項研究中，我們探討非以英語為中心的 LLM，儘管它們效能強大，但它們是否「思考」它們各自的主要語言：更精確地說，「思考」是指當中間層的表徵未嵌入到詞彙空間時，在產生過程中對某些主要語言展現出較高的機率。我們將這種語言稱為內部$\textbf{潛在語言}$。
  我們檢視三種類型的模型對日語處理的潛在語言：以英語為中心的 Llama2、以英語為中心並持續在日語中預先訓練的 Swallow，以及在平衡的英語和日語語料庫上預先訓練的模型 LLM-jp。我們的經驗發現顯示，與僅依賴英語作為內部潛在語言的 Llama2 不同，日語專用的 Swallow 和 LLM-jp 使用日語和英語，展現出雙重的內部潛在語言。對於任何給定的目標語言，模型會優先啟用與其最相關的潛在語言。此外，我們探討中間層如何回應涉及潛在內部語言和目標輸出語言之間文化衝突的問題。我們進一步探討語言身分如何在各層之間轉換，同時保持中間層表徵中反映的一致語義意義。
  這項研究加深了對非以英語為中心的巨量語言模型的理解，突顯了它們中間層內語言表徵的複雜動態。

##### **ColBERT Retrieval and Ensemble Response Scoring for Language Model Question Answering**
2408.10808v1 by Alex Gichamba, Tewodros Kederalah Idris, Brian Ebiyau, Eric Nyberg, Teruko Mitamura

Domain-specific question answering remains challenging for language models,
given the deep technical knowledge required to answer questions correctly. This
difficulty is amplified for smaller language models that cannot encode as much
information in their parameters as larger models. The "Specializing Large
Language Models for Telecom Networks" challenge aimed to enhance the
performance of two small language models, Phi-2 and Falcon-7B in
telecommunication question answering. In this paper, we present our question
answering systems for this challenge. Our solutions achieved leading marks of
81.9% accuracy for Phi-2 and 57.3% for Falcon-7B. We have publicly released our
code and fine-tuned models.

摘要：領域特定問題解答對於語言模型來說仍然具有挑戰性，因為正確回答問題需要深入的技術知識。對於較小的語言模型來說，這種困難會被放大，因為它們無法像較大的模型那樣在參數中編碼大量資訊。電信網路專用大型語言模型挑戰旨在提升兩個小型語言模型 Phi-2 和 Falcon-7B 在電信問題解答中的效能。在本文中，我們提出了我們針對此挑戰的問答系統。我們的解決方案為 Phi-2 達到了 81.9% 的領先準確度，為 Falcon-7B 達到了 57.3%。我們已公開發布我們的程式碼和微調模型。

##### **DisMix: Disentangling Mixtures of Musical Instruments for Source-level Pitch and Timbre Manipulation**
2408.10807v1 by Yin-Jyun Luo, Kin Wai Cheuk, Woosung Choi, Toshimitsu Uesaka, Keisuke Toyama, Koichi Saito, Chieh-Hsin Lai, Yuhta Takida, Wei-Hsiang Liao, Simon Dixon, Yuki Mitsufuji

Existing work on pitch and timbre disentanglement has been mostly focused on
single-instrument music audio, excluding the cases where multiple instruments
are presented. To fill the gap, we propose DisMix, a generative framework in
which the pitch and timbre representations act as modular building blocks for
constructing the melody and instrument of a source, and the collection of which
forms a set of per-instrument latent representations underlying the observed
mixture. By manipulating the representations, our model samples mixtures with
novel combinations of pitch and timbre of the constituent instruments. We can
jointly learn the disentangled pitch-timbre representations and a latent
diffusion transformer that reconstructs the mixture conditioned on the set of
source-level representations. We evaluate the model using both a simple dataset
of isolated chords and a realistic four-part chorales in the style of J.S.
Bach, identify the key components for the success of disentanglement, and
demonstrate the application of mixture transformation based on source-level
attribute manipulation.

摘要：現有關於音高和音色的分離工作，大多集中在單一樂器音樂音訊上，不包括呈現多種樂器的案例。為了填補這個空白，我們提出了 DisMix，一個生成框架，其中音高和音色表示作為模組化建構區塊，用於建構來源的旋律和樂器，而其集合則形成了一組潛在樂器表示，作為觀察到的混合物的基礎。透過操作表示，我們的模型會取樣具有構成樂器音高和音色新組合的混合物。我們可以共同學習分離的音高-音色表示和一個潛在擴散Transformer，該Transformer會根據一組來源層級表示重建混合物。我們使用一個簡單的孤立和弦資料集和 J.S. 巴赫風格的寫實四部合唱曲評估模型，找出分離成功的關鍵組成部分，並展示基於來源層級屬性操作的混合物轉換應用。

##### **Inverse Deep Learning Ray Tracing for Heliostat Surface Prediction**
2408.10802v1 by Jan Lewen, Max Pargmann, Mehdi Cherti, Jenia Jitsev, Robert Pitz-Paal, Daniel Maldonado Quinto

Concentrating Solar Power (CSP) plants play a crucial role in the global
transition towards sustainable energy. A key factor in ensuring the safe and
efficient operation of CSP plants is the distribution of concentrated flux
density on the receiver. However, the non-ideal flux density generated by
individual heliostats can undermine the safety and efficiency of the power
plant. The flux density from each heliostat is influenced by its precise
surface profile, which includes factors such as canting and mirror errors.
Accurately measuring these surface profiles for a large number of heliostats in
operation is a formidable challenge. Consequently, control systems often rely
on the assumption of ideal surface conditions, which compromises both safety
and operational efficiency. In this study, we introduce inverse Deep Learning
Ray Tracing (iDLR), an innovative method designed to predict heliostat surfaces
based solely on target images obtained during heliostat calibration. Our
simulation-based investigation demonstrates that sufficient information
regarding the heliostat surface is retained in the flux density distribution of
a single heliostat, enabling deep learning models to accurately predict the
underlying surface with deflectometry-like precision for the majority of
heliostats. Additionally, we assess the limitations of this method,
particularly in relation to surface accuracy and resultant flux density
predictions. Furthermore, we are presenting a new comprehensive heliostat model
using Non-Uniform Rational B-Spline (NURBS) that has the potential to become
the new State of the Art for heliostat surface parameterization. Our findings
reveal that iDLR has significant potential to enhance CSP plant operations,
potentially increasing the overall efficiency and energy output of the power
plants.

摘要：<paragraph>聚光太陽能 (CSP) 電廠在全球邁向永續能源的過程中扮演著至關重要的角色。確保 CSP 電廠安全且有效運作的關鍵因素之一是接收器上聚光通量密度的分佈。然而，個別定日鏡產生的非理想通量密度可能會損害電廠的安全性和效率。每個定日鏡的通量密度會受到其精確表面輪廓的影響，其中包括傾斜和鏡面誤差等因素。準確測量大量運作中的定日鏡的這些表面輪廓是一項艱鉅的挑戰。因此，控制系統通常依賴於理想表面條件的假設，這會影響安全性和運作效率。在這項研究中，我們引進了反向深度學習光線追蹤 (iDLR)，這是一種創新的方法，旨在根據定日鏡校正期間取得的目標影像來預測定日鏡表面。我們基於模擬的調查顯示，關於定日鏡表面的足夠資訊保留在單個定日鏡的通量密度分佈中，使深度學習模型能夠準確預測大多數定日鏡的底層表面，其精確度類似於偏光干涉術。此外，我們評估了此方法的限制，特別是與表面準確度和結果通量密度預測相關的限制。此外，我們提出了一個使用非均勻有理 B 樣條 (NURBS) 的全新綜合定日鏡模型，它有可能成為定日鏡表面參數化的最新技術。我們的研究結果顯示，iDLR 具有顯著的潛力可以提升 CSP 電廠的運作，進而提升電廠的整體效率和能源輸出。</paragraph>

##### **Adversarial Attack for Explanation Robustness of Rationalization Models**
2408.10795v1 by Yuankai Zhang, Lingxiao Kong, Haozhao Wang, Ruixuan Li, Jun Wang, Yuhua Li, Wei Liu

Rationalization models, which select a subset of input text as
rationale-crucial for humans to understand and trust predictions-have recently
emerged as a prominent research area in eXplainable Artificial Intelligence.
However, most of previous studies mainly focus on improving the quality of the
rationale, ignoring its robustness to malicious attack. Specifically, whether
the rationalization models can still generate high-quality rationale under the
adversarial attack remains unknown. To explore this, this paper proposes UAT2E,
which aims to undermine the explainability of rationalization models without
altering their predictions, thereby eliciting distrust in these models from
human users. UAT2E employs the gradient-based search on triggers and then
inserts them into the original input to conduct both the non-target and target
attack. Experimental results on five datasets reveal the vulnerability of
rationalization models in terms of explanation, where they tend to select more
meaningless tokens under attacks. Based on this, we make a series of
recommendations for improving rationalization models in terms of explanation.

摘要：合理化模型，它會選擇輸入文字的子集，作為人類理解和信任預測的合理化關鍵，最近已成為可解釋人工智慧中重要的研究領域。然而，大多數先前的研究主要集中在改善合理化的品質，而忽略其對惡意攻擊的穩健性。具體來說，合理化模型是否仍能在對抗攻擊下產生高品質的合理化，這仍然未知。為了探索這一點，本文提出了 UAT2E，它旨在破壞合理化模型的可解釋性，而不會改變其預測，從而引起人類使用者對這些模型的不信任。UAT2E 對觸發器採用基於梯度的搜尋，然後將它們插入原始輸入中，以執行非目標和目標攻擊。在五個資料集上的實驗結果揭示了合理化模型在解釋方面的脆弱性，在攻擊下它們往往會選擇更多無意義的符號。基於此，我們提出了一系列建議，以改善合理化模型在解釋方面的品質。

##### **Just a Hint: Point-Supervised Camouflaged Object Detection**
2408.10777v1 by Huafeng Chen, Dian Shao, Guangqian Guo, Shan Gao

Camouflaged Object Detection (COD) demands models to expeditiously and
accurately distinguish objects which conceal themselves seamlessly in the
environment. Owing to the subtle differences and ambiguous boundaries, COD is
not only a remarkably challenging task for models but also for human
annotators, requiring huge efforts to provide pixel-wise annotations. To
alleviate the heavy annotation burden, we propose to fulfill this task with the
help of only one point supervision. Specifically, by swiftly clicking on each
object, we first adaptively expand the original point-based annotation to a
reasonable hint area. Then, to avoid partial localization around discriminative
parts, we propose an attention regulator to scatter model attention to the
whole object through partially masking labeled regions. Moreover, to solve the
unstable feature representation of camouflaged objects under only point-based
annotation, we perform unsupervised contrastive learning based on differently
augmented image pairs (e.g. changing color or doing translation). On three
mainstream COD benchmarks, experimental results show that our model outperforms
several weakly-supervised methods by a large margin across various metrics.

摘要：偽裝物體偵測 (COD) 要求模型快速且準確地辨別在環境中無縫隱藏自己的物體。由於細微的差異和模糊的邊界，COD 不僅對模型而言是一項極具挑戰性的任務，對人工標註者來說也是如此，需要付出巨大的努力來提供逐像素標註。為了減輕繁重的標註負擔，我們建議僅借助一個點監督來完成這項任務。具體來說，通過快速點擊每個物體，我們首先自適應地將基於點的原始標註擴展到合理的提示區域。然後，為了避免在區別性部分周圍進行部分定位，我們提出了一個注意力調節器，通過部分遮蓋標記區域將模型注意力分散到整個物體上。此外，為了解決僅基於點的標註下偽裝物體的不穩定特徵表示，我們根據不同的擴增影像對（例如改變顏色或進行平移）執行無監督對比學習。在三個主流 COD 基準上，實驗結果表明我們的模型在各種指標上都比多種弱監督方法高出很多。

##### **Flexora: Flexible Low Rank Adaptation for Large Language Models**
2408.10774v2 by Chenxing Wei, Yao Shu, Ying Tiffany He, Fei Richard Yu

Large Language Models (LLMs) are driving advancements in artificial
intelligence by increasing the scale of model parameters, which has
significantly enhanced generalization ability and unlocked new capabilities in
practice. However, their performance in specific downstream tasks is usually
hindered by their knowledge boundaries on these tasks. Thus, fine-tuning
techniques, especially the widely used Low-Rank Adaptation (LoRA) method, have
been introduced to expand the boundaries on these tasks, whereas LoRA would
underperform on certain tasks owing to its potential overfitting on these
tasks. To overcome this overfitting and improve the performance of LoRA, we
propose the flexible low rank adaptation (Flexora) method to automatically and
flexibly select the most important layers needing to be fine-tuned to achieve
the best performance on different downstream tasks. Specifically, Flexora
firstly frames this layer selection problem as a well-defined hyperparameter
optimization (HPO) problem, then addresses it using the unrolled
differentiation (UD) method, and finally selects the most useful layers based
on the optimized hyperparameters. Our extensive experiments on many pretrained
models and natural language tasks show that Flexora is able to consistently
improve over the existing baselines, indicating the effectiveness of our
Flexora in practice. We additionally provide insightful theoretical results and
many ablation studies to deliver a comprehensive understanding of our Flexora.

摘要：大型語言模型（LLM）透過增加模型參數的規模，推動人工智慧的進展，這顯著提升了泛化能力，並在實務上解鎖新的功能。然而，它們在特定下游任務中的表現通常會受到這些任務的知識界線所阻礙。因此，微調技術，特別是廣泛使用的低秩適應（LoRA）方法，已被引入以擴展這些任務的界線，而 LoRA 卻會因為其在這些任務上的潛在過度擬合而表現不佳。為了克服這種過度擬合並改善 LoRA 的效能，我們提出彈性低秩適應（Flexora）方法，以自動且彈性地選出最重要的層，需要微調才能在不同的下游任務上取得最佳效能。具體來說，Flexora 首先將此層選擇問題設定為定義良好的超參數最佳化（HPO）問題，然後使用展開微分（UD）方法來解決它，最後根據最佳化的超參數選出最有用的層。我們在許多預訓練模型和自然語言任務上進行的廣泛實驗顯示，Flexora 能夠持續改進現有的基線，這表示我們的 Flexora 在實務上是有效的。我們還提供了有見地的理論結果和許多消融研究，以提供對我們的 Flexora 的全面理解。

##### **SSL-TTS: Leveraging Self-Supervised Embeddings and kNN Retrieval for Zero-Shot Multi-speaker TTS**
2408.10771v1 by Karl El Hajal, Ajinkya Kulkarni, Enno Hermann, Mathew Magimai. -Doss

While recent zero-shot multispeaker text-to-speech (TTS) models achieve
impressive results, they typically rely on extensive transcribed speech
datasets from numerous speakers and intricate training pipelines. Meanwhile,
self-supervised learning (SSL) speech features have emerged as effective
intermediate representations for TTS. It was also observed that SSL features
from different speakers that are linearly close share phonetic information
while maintaining individual speaker identity, which enables straight-forward
and robust voice cloning. In this study, we introduce SSL-TTS, a lightweight
and efficient zero-shot TTS framework trained on transcribed speech from a
single speaker. SSL-TTS leverages SSL features and retrieval methods for simple
and robust zero-shot multi-speaker synthesis. Objective and subjective
evaluations show that our approach achieves performance comparable to
state-of-the-art models that require significantly larger training datasets.
The low training data requirements mean that SSL-TTS is well suited for the
development of multi-speaker TTS systems for low-resource domains and
languages. We also introduce an interpolation parameter which enables fine
control over the output speech by blending voices. Demo samples are available
at https://idiap.github.io/ssl-tts

摘要：<paragraph>儘管最近的零鏡頭多說話者文字轉語音 (TTS) 模型獲得令人印象深刻的結果，但它們通常依賴於來自眾多說話者的廣泛轉錄語音資料集和複雜的訓練管道。與此同時，自我監督式學習 (SSL) 語音功能已成為 TTS 的有效中間表示。還觀察到，線性接近的不同說話者的 SSL 特徵在保持個別說話者身分的情況下共享語音資訊，這使得直接且穩健的語音複製成為可能。在本研究中，我們介紹了 SSL-TTS，這是一個輕量級且高效的零鏡頭 TTS 框架，訓練於來自單一說話者的轉錄語音。SSL-TTS 利用 SSL 特徵和檢索方法，進行簡單且穩健的零鏡頭多說話者合成。客觀和主觀評估表明，我們的做法實現了與最先進的模型相當的效能，而這些模型需要顯著更大的訓練資料集。低訓練資料需求意味著 SSL-TTS 非常適合在低資源網域和語言中開發多說話者 TTS 系統。我們還引入了一個插值參數，它能透過混合語音，對輸出語音進行精細控制。示範範例可在 https://idiap.github.io/ssl-tts 取得</paragraph>

##### **Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model**
2408.10764v1 by Chenhan Yuan, Fei Huang, Ru Peng, Keming Lu, Bowen Yu, Chang Zhou, Jingren Zhou

Transformer-based large language models (LLMs) exhibit limitations such as
generating unsafe responses, unreliable reasoning, etc. Existing inference
intervention approaches attempt to mitigate these issues by finetuning
additional models to produce calibration signals (such as rewards) that guide
the LLM's decoding process. However, this solution introduces substantial time
and space overhead due to the separate models required. This work proposes
Non-disruptive parameters insertion (Otter), inserting extra parameters into
the transformer architecture to predict calibration signals along with the
original LLM output. Otter offers state-of-the-art performance on multiple
demanding tasks while saving up to 86.5\% extra space and 98.5\% extra time.
Furthermore, Otter seamlessly integrates with existing inference engines,
requiring only a one-line code change, and the original model response remains
accessible after the parameter insertion. Our code is publicly available at
\url{https://github.com/chenhan97/Otter}

摘要：基於 Transformer 的大型語言模型 (LLM) 會產生不安全回應、推理不可靠等限制。現有的推理介入方法嘗試透過微調其他模型來產生校準信號 (例如獎勵) 來緩解這些問題，以引導 LLM 的解碼過程。然而，由於需要使用單獨的模型，此解決方案會造成大量時間和空間的開銷。本研究提出非破壞性參數插入 (Otter)，將額外的參數插入Transformer架構中，以預測校準信號以及原始 LLM 輸出。Otter 在多項要求嚴格的任務中提供最先進的效能，同時節省高達 86.5% 的額外空間和 98.5% 的額外時間。此外，Otter 能與現有的推理引擎無縫整合，僅需一行程式碼變更，且原始模型回應在參數插入後仍然可用。我們的程式碼已公開於 \url{https://github.com/chenhan97/Otter}

##### **SAM-COD: SAM-guided Unified Framework for Weakly-Supervised Camouflaged Object Detection**
2408.10760v1 by Huafeng Chen, Pengxu Wei, Guangqian Guo, Shan Gao

Most Camouflaged Object Detection (COD) methods heavily rely on mask
annotations, which are time-consuming and labor-intensive to acquire. Existing
weakly-supervised COD approaches exhibit significantly inferior performance
compared to fully-supervised methods and struggle to simultaneously support all
the existing types of camouflaged object labels, including scribbles, bounding
boxes, and points. Even for Segment Anything Model (SAM), it is still
problematic to handle the weakly-supervised COD and it typically encounters
challenges of prompt compatibility of the scribble labels, extreme response,
semantically erroneous response, and unstable feature representations,
producing unsatisfactory results in camouflaged scenes. To mitigate these
issues, we propose a unified COD framework in this paper, termed SAM-COD, which
is capable of supporting arbitrary weakly-supervised labels. Our SAM-COD
employs a prompt adapter to handle scribbles as prompts based on SAM.
Meanwhile, we introduce response filter and semantic matcher modules to improve
the quality of the masks obtained by SAM under COD prompts. To alleviate the
negative impacts of inaccurate mask predictions, a new strategy of
prompt-adaptive knowledge distillation is utilized to ensure a reliable feature
representation. To validate the effectiveness of our approach, we have
conducted extensive empirical experiments on three mainstream COD benchmarks.
The results demonstrate the superiority of our method against state-of-the-art
weakly-supervised and even fully-supervised methods.

摘要：大多數偽裝目標檢測 (COD) 方法都高度依賴於遮罩註解，而這些註解的取得耗時且費力。現有的弱監督 COD 方法與完全監督方法相比，表現明顯較差，且難以同時支援所有現有的偽裝目標標籤類型，包括塗鴉、邊界框和點。即使對於 Segment Anything Model (SAM)，處理弱監督 COD 仍然存在問題，且通常會遇到塗鴉標籤提示相容性、極端回應、語義錯誤回應和不穩定的特徵表示等挑戰，導致在偽裝場景中產生不令人滿意的結果。為了減輕這些問題，我們在本文中提出一個統一的 COD 框架，稱為 SAM-COD，它能夠支援任意弱監督標籤。我們的 SAM-COD 使用提示適配器來處理基於 SAM 的塗鴉提示。同時，我們引入了回應過濾器和語義比對器模組，以提高 SAM 在 COD 提示下取得的遮罩品質。為了減輕不準確遮罩預測的負面影響，我們利用一種新的提示適應式知識提煉策略來確保可靠的特徵表示。為了驗證我們方法的有效性，我們在三個主流 COD 基準上進行了廣泛的實證實驗。結果證明了我們的方法優於最先進的弱監督甚至完全監督方法。

##### **Generating Synthetic Fair Syntax-agnostic Data by Learning and Distilling Fair Representation**
2408.10755v1 by Md Fahim Sikder, Resmi Ramachandranpillai, Daniel de Leng, Fredrik Heintz

Data Fairness is a crucial topic due to the recent wide usage of AI powered
applications. Most of the real-world data is filled with human or machine
biases and when those data are being used to train AI models, there is a chance
that the model will reflect the bias in the training data. Existing
bias-mitigating generative methods based on GANs, Diffusion models need
in-processing fairness objectives and fail to consider computational overhead
while choosing computationally-heavy architectures, which may lead to high
computational demands, instability and poor optimization performance. To
mitigate this issue, in this work, we present a fair data generation technique
based on knowledge distillation, where we use a small architecture to distill
the fair representation in the latent space. The idea of fair latent space
distillation enables more flexible and stable training of Fair Generative
Models (FGMs). We first learn a syntax-agnostic (for any data type) fair
representation of the data, followed by distillation in the latent space into a
smaller model. After distillation, we use the distilled fair latent space to
generate high-fidelity fair synthetic data. While distilling, we employ quality
loss (for fair distillation) and utility loss (for data utility) to ensure that
the fairness and data utility characteristics remain in the distilled latent
space. Our approaches show a 5%, 5% and 10% rise in performance in fairness,
synthetic sample quality and data utility, respectively, than the
state-of-the-art fair generative model.

摘要：資料公平性由於近年來 AI 驅動應用程式的廣泛使用，成為一個至關重要的議題。大多數真實世界的資料都充滿了人類或機器偏見，當這些資料被用於訓練 AI 模型時，模型就有可能反映訓練資料中的偏見。現有的基於 GAN、擴散模型的偏見緩解生成方法需要處理中的公平性目標，且在選擇計算密集型架構時未能考慮計算負載，這可能導致高計算需求、不穩定性和優化效能不佳。為了緩解此問題，我們在這項工作中提出一個基於知識萃取的公平資料生成技術，我們使用一個小型架構來萃取潛在空間中的公平表示。公平潛在空間萃取的想法讓公平生成模型 (FGM) 的訓練更靈活且穩定。我們首先學習資料的語法不可知 (適用於任何資料類型) 公平表示，接著在潛在空間中萃取到一個較小的模型。萃取後，我們使用萃取的公平潛在空間來生成高保真公平合成資料。在萃取過程中，我們採用品質損失 (用於公平萃取) 和效用損失 (用於資料效用) 來確保公平性和資料效用特徵保留在萃取的潛在空間中。我們的做法在公平性、合成樣本品質和資料效用方面分別顯示出 5%、5% 和 10% 的效能提升，優於現有最先進的公平生成模型。

##### **Security Assessment of Hierarchical Federated Deep Learning**
2408.10752v1 by D Alqattan, R Sun, H Liang, G Nicosia, V Snasel, R Ranjan, V Ojha

Hierarchical federated learning (HFL) is a promising distributed deep
learning model training paradigm, but it has crucial security concerns arising
from adversarial attacks. This research investigates and assesses the security
of HFL using a novel methodology by focusing on its resilience against
adversarial attacks inference-time and training-time. Through a series of
extensive experiments across diverse datasets and attack scenarios, we uncover
that HFL demonstrates robustness against untargeted training-time attacks due
to its hierarchical structure. However, targeted attacks, particularly backdoor
attacks, exploit this architecture, especially when malicious clients are
positioned in the overlapping coverage areas of edge servers. Consequently, HFL
shows a dual nature in its resilience, showcasing its capability to recover
from attacks thanks to its hierarchical aggregation that strengthens its
suitability for adversarial training, thereby reinforcing its resistance
against inference-time attacks. These insights underscore the necessity for
balanced security strategies in HFL systems, leveraging their inherent
strengths while effectively mitigating vulnerabilities.

摘要：分層式聯邦學習 (HFL) 是一種很有前途的分散式深度學習模型訓練範例，但它會因為對抗攻擊而產生嚴重的安全性問題。本研究透過專注於 HFL 在推論時間和訓練時間對抗攻擊的復原力，使用一種創新的方法來調查並評估其安全性。透過一系列針對不同資料集和攻擊情境的廣泛實驗，我們發現 HFL 由於其分層結構而展現出對未鎖定訓練時間攻擊的穩健性。然而，有針對性的攻擊，特別是後門攻擊會利用這個架構，尤其當惡意用戶位於邊緣伺服器的重疊涵蓋區域時。因此，HFL 在其復原力中展現出雙重本質，展示其從攻擊中復原的能力，這要歸功於其分層聚合，它強化了其對抗訓練的適用性，進而加強其對推論時間攻擊的抵抗力。這些見解強調了在 HFL 系統中採用平衡安全策略的必要性，利用其固有優勢，同時有效減輕漏洞。

##### **Pluto and Charon: A Time and Memory Efficient Collaborative Edge AI Framework for Personal LLMs Fine-Tuning**
2408.10746v1 by Bei Ouyang, Shengyuan Ye, Liekang Zeng, Tianyi Qian, Jingyi Li, Xu Chen

Large language models (LLMs) have unlocked a plethora of powerful
applications at the network edge, such as intelligent personal assistants. Data
privacy and security concerns have prompted a shift towards edge-based
fine-tuning of personal LLMs, away from cloud reliance. However, this raises
issues of computational intensity and resource scarcity, hindering training
efficiency and feasibility. While current studies investigate
parameter-efficient fine-tuning (PEFT) techniques to mitigate resource
constraints, our analysis indicates that these techniques are not sufficiently
resource-efficient for edge devices. To tackle these challenges, we propose
Pluto and Charon (PAC), a time and memory efficient collaborative edge AI
framework for personal LLMs fine-tuning. PAC breaks the resource wall of
personal LLMs fine-tuning with a sophisticated algorithm-system co-design. (1)
Algorithmically, PAC implements a personal LLMs fine-tuning technique that is
efficient in terms of parameters, time, and memory. It utilizes Parallel
Adapters to circumvent the need for a full backward pass through the LLM
backbone. Additionally, an activation cache mechanism further streamlining the
process by negating the necessity for repeated forward passes across multiple
epochs. (2) Systematically, PAC leverages edge devices in close proximity,
pooling them as a collective resource for in-situ personal LLMs fine-tuning,
utilizing a hybrid data and pipeline parallelism to orchestrate distributed
training. The use of the activation cache eliminates the need for forward pass
through the LLM backbone,enabling exclusive fine-tuning of the Parallel
Adapters using data parallelism. Extensive evaluation based on prototype
implementation demonstrates that PAC remarkably outperforms state-of-the-art
approaches, achieving up to 8.64x end-to-end speedup and up to 88.16% reduction
in memory footprint.

摘要：大型語言模型 (LLM) 在網路邊緣解鎖了許多強大的應用程式，例如智慧型個人助理。資料隱私和安全性問題促使個人 LLM 從依賴雲端轉向基於邊緣的微調。然而，這引發了運算強度和資源稀缺的問題，阻礙了訓練效率和可行性。雖然目前的研究調查了參數有效微調 (PEFT) 技術以減輕資源限制，但我們的分析表明，這些技術對於邊緣裝置來說資源效率還不夠。為了應對這些挑戰，我們提出了 Pluto 和 Charon (PAC)，一個時間和記憶體效率高的協作式邊緣 AI 框架，用於個人 LLM 微調。PAC 使用複雜的演算法系統協同設計打破了個人 LLM 微調的資源壁壘。(1) 在演算法方面，PAC 實作了一種在參數、時間和記憶體方面都高效的個人 LLM 微調技術。它利用平行適配器來迴避對 LLM 主幹進行完整反向傳遞的需要。此外，啟用快取機制進一步簡化了流程，消除了在多個世代中重複正向傳遞的必要性。(2) 在系統方面，PAC 充分利用鄰近的邊緣裝置，將它們匯集為用於原位個人 LLM 微調的集合資源，利用混合資料和管線平行處理來協調分散式訓練。啟用快取的使用消除了對 LLM 主幹進行正向傳遞的需要，可以使用資料平行處理獨家微調平行適配器。基於原型實作的廣泛評估表明，PAC 明顯優於最先進的方法，實現了高達 8.64 倍的端對端加速和高達 88.16% 的記憶體佔用空間減少。

##### **Towards Efficient Large Language Models for Scientific Text: A Review**
2408.10729v1 by Huy Quoc To, Ming Liu, Guangyan Huang

Large language models (LLMs) have ushered in a new era for processing complex
information in various fields, including science. The increasing amount of
scientific literature allows these models to acquire and understand scientific
knowledge effectively, thus improving their performance in a wide range of
tasks. Due to the power of LLMs, they require extremely expensive computational
resources, intense amounts of data, and training time. Therefore, in recent
years, researchers have proposed various methodologies to make scientific LLMs
more affordable. The most well-known approaches align in two directions. It can
be either focusing on the size of the models or enhancing the quality of data.
To date, a comprehensive review of these two families of methods has not yet
been undertaken. In this paper, we (I) summarize the current advances in the
emerging abilities of LLMs into more accessible AI solutions for science, and
(II) investigate the challenges and opportunities of developing affordable
solutions for scientific domains using LLMs.

摘要：大型語言模型 (LLM) 開啟了處理各個領域複雜資訊的新紀元，包括科學。科學文獻數量不斷增加，讓這些模型能夠有效地獲取和理解科學知識，從而提升它們在各種任務中的表現。由於 LLM 的強大功能，它們需要極其昂貴的運算資源、大量資料和訓練時間。因此，近年來，研究人員提出了各種方法，讓科學 LLM 變得更平價。最著名的做法有兩種。它們可以專注於模型大小，或提升資料品質。到目前為止，對於這兩種類別的方法，尚未進行全面的回顧。在本文中，我們 (I) 總結 LLM 新興能力在科學領域中轉變為更平易近人的 AI 解決方案的最新進展，以及 (II) 探討使用 LLM 為科學領域開發平價解決方案的挑戰和機會。

##### **Crafting Tomorrow's Headlines: Neural News Generation and Detection in English, Turkish, Hungarian, and Persian**
2408.10724v1 by Cem Üyük, Danica Rovó, Shaghayegh Kolli, Rabia Varol, Georg Groh, Daryna Dementieva

In the era dominated by information overload and its facilitation with Large
Language Models (LLMs), the prevalence of misinformation poses a significant
threat to public discourse and societal well-being. A critical concern at
present involves the identification of machine-generated news. In this work, we
take a significant step by introducing a benchmark dataset designed for neural
news detection in four languages: English, Turkish, Hungarian, and Persian. The
dataset incorporates outputs from multiple multilingual generators (in both,
zero-shot and fine-tuned setups) such as BloomZ, LLaMa-2, Mistral, Mixtral, and
GPT-4. Next, we experiment with a variety of classifiers, ranging from those
based on linguistic features to advanced Transformer-based models and LLMs
prompting. We present the detection results aiming to delve into the
interpretablity and robustness of machine-generated texts detectors across all
target languages.

摘要：在資訊爆炸的時代，加上大型語言模型 (LLM) 的推波助瀾，錯誤資訊的盛行對公共論述和社會福祉構成重大威脅。目前一項重要的關注點在於識別機器產生的新聞。在這項工作中，我們透過引進一個基準資料集，為四種語言（英語、土耳其語、匈牙利語和波斯語）的神經新聞偵測邁出重要一步。該資料集整合了多個多語言產生器的輸出（在零次學習和微調設定中），例如 BloomZ、LLaMa-2、Mistral、Mixtral 和 GPT-4。接著，我們嘗試各種分類器，從基於語言特徵的分類器到先進的基於 Transformer 的模型和 LLM 提示。我們呈現偵測結果，旨在深入探討機器產生的文字偵測器在所有目標語言中的可解釋性和穩健性。

##### **MEGen: Generative Backdoor in Large Language Models via Model Editing**
2408.10722v1 by Jiyang Qiu, Xinbei Ma, Zhuosheng Zhang, Hai Zhao

Large language models (LLMs) have demonstrated remarkable capabilities. Their
powerful generative abilities enable flexible responses based on various
queries or instructions. Emerging as widely adopted generalists for diverse
tasks, LLMs are still vulnerable to backdoors. This paper proposes an
editing-based generative backdoor, named MEGen, aiming to create a customized
backdoor for NLP tasks with the least side effects. In our approach, we first
leverage a language model to insert a trigger selected on fixed metrics into
the input, then design a pipeline of model editing to directly embed a backdoor
into an LLM. By adjusting a small set of local parameters with a mini-batch of
samples, MEGen significantly enhances time efficiency and achieves high
robustness. Experimental results indicate that our backdoor attack strategy
achieves a high attack success rate on poison data while maintaining the
model's performance on clean data. Notably, the backdoored model, when
triggered, can freely output pre-set dangerous information while successfully
completing downstream tasks. This suggests that future LLM applications could
be guided to deliver certain dangerous information, thus altering the LLM's
generative style. We believe this approach provides insights for future LLM
applications and the execution of backdoor attacks on conversational AI
systems.

摘要：大型語言模型 (LLM) 已展現出非凡的能力。它們強大的生成能力能根據各種查詢或指令提供靈活的回應。LLM 作為廣泛採用的多功能工具應付各種任務，但仍容易受到後門攻擊。本文提出了一種基於編輯的生成後門，稱為 MEGen，旨在為 NLP 任務建立一個自訂後門，且副作用最少。在我們的做法中，我們首先利用語言模型將選取的觸發器插入固定公制中的輸入，然後設計一個模型編輯管線，將後門直接嵌入 LLM 中。透過使用一批小樣本調整一組小型區域參數，MEGen 大幅提升時間效率並獲得高穩健性。實驗結果顯示，我們的後門攻擊策略在中毒資料上獲得高攻擊成功率，同時維持模型在乾淨資料上的效能。值得注意的是，當觸發後門模型時，它可以自由輸出預設的危險資訊，同時成功完成下游任務。這表示未來的 LLM 應用程式可以被引導提供某些危險資訊，從而改變 LLM 的生成風格。我們相信此方法為未來的 LLM 應用程式和對話式 AI 系統的後門攻擊執行提供見解。

##### **Towards Foundation Models for the Industrial Forecasting of Chemical Kinetics**
2408.10720v1 by Imran Nasim, Joaõ Lucas de Sousa Almeida

Scientific Machine Learning is transforming traditional engineering
industries by enhancing the efficiency of existing technologies and
accelerating innovation, particularly in modeling chemical reactions. Despite
recent advancements, the issue of solving stiff chemically reacting problems
within computational fluid dynamics remains a significant issue. In this study
we propose a novel approach utilizing a multi-layer-perceptron mixer
architecture (MLP-Mixer) to model the time-series of stiff chemical kinetics.
We evaluate this method using the ROBER system, a benchmark model in chemical
kinetics, to compare its performance with traditional numerical techniques.
This study provides insight into the industrial utility of the recently
developed MLP-Mixer architecture to model chemical kinetics and provides
motivation for such neural architecture to be used as a base for time-series
foundation models.

摘要：科學機器學習透過提升現有技術的效率和加速創新來轉變傳統工程產業，特別是在化學反應建模方面。儘管有近期的進展，在計算流體力學中解決僵硬化學反應問題的問題仍然是一個重大的問題。在這項研究中，我們提出了一種新穎的方法，利用多層感知器混合器架構 (MLP-Mixer) 來建模僵硬化學動力學的時間序列。我們使用化學動力學中的基準模型 ROBER 系統來評估此方法，以將其效能與傳統數值技術進行比較。本研究提供了對最近開發的 MLP-Mixer 架構在化學動力學建模中的產業效用的見解，並提供了將此類神經架構用作時間序列基礎模型的動機。

##### **CodeJudge-Eval: Can Large Language Models be Good Judges in Code Understanding?**
2408.10718v1 by Yuwei Zhao, Ziyang Luo, Yuchen Tian, Hongzhan Lin, Weixiang Yan, Annan Li, Jing Ma

Recent advancements in large language models (LLMs) have showcased impressive
code generation capabilities, primarily evaluated through language-to-code
benchmarks. However, these benchmarks may not fully capture a model's code
understanding abilities. We introduce CodeJudge-Eval (CJ-Eval), a novel
benchmark designed to assess LLMs' code understanding abilities from the
perspective of code judging rather than code generation. CJ-Eval challenges
models to determine the correctness of provided code solutions, encompassing
various error types and compilation issues. By leveraging a diverse set of
problems and a fine-grained judging system, CJ-Eval addresses the limitations
of traditional benchmarks, including the potential memorization of solutions.
Evaluation of 12 well-known LLMs on CJ-Eval reveals that even state-of-the-art
models struggle, highlighting the benchmark's ability to probe deeper into
models' code understanding abilities. Our benchmark will be available at
\url{https://github.com/CodeLLM-Research/CodeJudge-Eval}.

摘要：大型語言模型 (LLM) 的最新進展展示了令人印象深刻的程式碼生成能力，主要透過語言到程式碼基準進行評估。然而，這些基準可能無法完全掌握模型的程式碼理解能力。我們引入了 CodeJudge-Eval (CJ-Eval)，這是一個新穎的基準，旨在從程式碼判斷而非程式碼生成的角度評估 LLM 的程式碼理解能力。CJ-Eval 挑戰模型確定所提供程式碼解決方案的正確性，涵蓋各種錯誤類型和編譯問題。透過利用各種問題和細緻的判斷系統，CJ-Eval 解决了傳統基準的限制，包括潛在的解決方案記憶。對 CJ-Eval 上的 12 個知名 LLM 進行評估顯示，即使最先進的模型也難以應付，突顯了基準深入探討模型程式碼理解能力的能力。我們的基準將在 \url{https://github.com/CodeLLM-Research/CodeJudge-Eval} 提供。

##### **Fine-Tuning a Local LLaMA-3 Large Language Model for Automated Privacy-Preserving Physician Letter Generation in Radiation Oncology**
2408.10715v1 by Yihao Hou, Christoph Bert, Ahmed Gomaa, Godehard Lahmer, Daniel Hoefler, Thomas Weissmann, Raphaela Voigt, Philipp Schubert, Charlotte Schmitter, Alina Depardon, Sabine Semrau, Andreas Maier, Rainer Fietkau, Yixing Huang, Florian Putz

Generating physician letters is a time-consuming task in daily clinical
practice. This study investigates local fine-tuning of large language models
(LLMs), specifically LLaMA models, for physician letter generation in a
privacy-preserving manner within the field of radiation oncology. Our findings
demonstrate that base LLaMA models, without fine-tuning, are inadequate for
effectively generating physician letters. The QLoRA algorithm provides an
efficient method for local intra-institutional fine-tuning of LLMs with limited
computational resources (i.e., a single 48 GB GPU workstation within the
hospital). The fine-tuned LLM successfully learns radiation oncology-specific
information and generates physician letters in an institution-specific style.
ROUGE scores of the generated summary reports highlight the superiority of the
8B LLaMA-3 model over the 13B LLaMA-2 model. Further multidimensional physician
evaluations of 10 cases reveal that, although the fine-tuned LLaMA-3 model has
limited capacity to generate content beyond the provided input data, it
successfully generates salutations, diagnoses and treatment histories,
recommendations for further treatment, and planned schedules. Overall, clinical
benefit was rated highly by the clinical experts (average score of 3.44 on a
4-point scale). With careful physician review and correction, automated
LLM-based physician letter generation has significant practical value.

摘要：<paragraph>在日常臨床實務中，生成醫師信函是一項耗時的任務。本研究探討大型語言模型 (LLM) 的局部微調，特別是 LLaMA 模型，在放射腫瘤學領域中以隱私保護的方式生成醫師信函。我們的研究結果表明，基礎 LLaMA 模型在沒有微調的情況下，不足以有效生成醫師信函。QLoRA 演算法提供了一種有效的方法，可以在有限的運算資源（即醫院內單一 48 GB GPU 工作站）下，進行 LLM 的局部院內微調。微調後的 LLM 成功學習了放射腫瘤學的特定資訊，並以特定於機構的風格生成醫師信函。生成的摘要報告的 ROUGE 分數突顯了 8B LLaMA-3 模型優於 13B LLaMA-2 模型。進一步的多維醫師評估顯示，儘管微調後的 LLaMA-3 模型生成超出提供輸入資料的內容的能力有限，但它成功地生成了問候語、診斷和治療病史、進一步治療建議和計畫行程。整體而言，臨床專家對臨床效益的評分很高（在 4 分制中平均得分為 3.44）。透過仔細的醫師審查和更正，基於 LLM 的自動化醫師信函生成具有顯著的實用價值。</paragraph>

##### **Offline Model-Based Reinforcement Learning with Anti-Exploration**
2408.10713v1 by Padmanaba Srinivasan, William Knottenbelt

Model-based reinforcement learning (MBRL) algorithms learn a dynamics model
from collected data and apply it to generate synthetic trajectories to enable
faster learning. This is an especially promising paradigm in offline
reinforcement learning (RL) where data may be limited in quantity, in addition
to being deficient in coverage and quality. Practical approaches to offline
MBRL usually rely on ensembles of dynamics models to prevent exploitation of
any individual model and to extract uncertainty estimates that penalize values
in states far from the dataset support. Uncertainty estimates from ensembles
can vary greatly in scale, making it challenging to generalize hyperparameters
well across even similar tasks. In this paper, we present Morse Model-based
offline RL (MoMo), which extends the anti-exploration paradigm found in offline
model-free RL to the model-based space. We develop model-free and model-based
variants of MoMo and show how the model-free version can be extended to detect
and deal with out-of-distribution (OOD) states using explicit uncertainty
estimation without the need for large ensembles. MoMo performs offline MBRL
using an anti-exploration bonus to counteract value overestimation in
combination with a policy constraint, as well as a truncation function to
terminate synthetic rollouts that are excessively OOD. Experimentally, we find
that both model-free and model-based MoMo perform well, and the latter
outperforms prior model-based and model-free baselines on the majority of D4RL
datasets tested.

摘要：基於模型的強化學習 (MBRL) 演算法會從收集到的資料中學習動態模型，並套用它來產生合成軌跡，以加速學習。這是一個特別有前景的範例，在離線強化學習 (RL) 中，資料的數量可能有限，而且在涵蓋範圍和品質上也可能不足。實用的離線 MBRL 方法通常依賴動態模型的集合，以防止利用任何個別模型，並提取不確定性估計值，以懲罰遠離資料集支援的狀態中的值。集合的不確定性估計值在規模上可能差異很大，這使得即使在類似的任務中也很難概括超參數。在本文中，我們提出了基於摩斯模型的離線 RL (MoMo)，它將在離線無模型 RL 中發現的反探索範例擴展到基於模型的空間。我們開發了 MoMo 的無模型和基於模型的變體，並展示了如何將無模型版本擴展到偵測和處理非分佈 (OOD) 狀態，使用明確的不確定性估計值，而無需大型集合。MoMo 使用反探索獎勵來抵消價值高估，並結合政策約束，以及一個截斷函數來終止過度 OOD 的合成滾動，以進行離線 MBRL。在實驗中，我們發現無模型和基於模型的 MoMo 表現良好，而後者在測試的大多數 D4RL 資料集上優於先前的基於模型和無模型基準。

##### **Investigating Context Effects in Similarity Judgements in Large Language Models**
2408.10711v1 by Sagar Uprety, Amit Kumar Jaiswal, Haiming Liu, Dawei Song

Large Language Models (LLMs) have revolutionised the capability of AI models
in comprehending and generating natural language text. They are increasingly
being used to empower and deploy agents in real-world scenarios, which make
decisions and take actions based on their understanding of the context.
Therefore researchers, policy makers and enterprises alike are working towards
ensuring that the decisions made by these agents align with human values and
user expectations. That being said, human values and decisions are not always
straightforward to measure and are subject to different cognitive biases. There
is a vast section of literature in Behavioural Science which studies biases in
human judgements. In this work we report an ongoing investigation on alignment
of LLMs with human judgements affected by order bias. Specifically, we focus on
a famous human study which showed evidence of order effects in similarity
judgements, and replicate it with various popular LLMs. We report the different
settings where LLMs exhibit human-like order effect bias and discuss the
implications of these findings to inform the design and development of LLM
based applications.

摘要：大型語言模型 (LLM) 徹底改變了 AI 模型理解和生成自然語言文本的能力。它們正越來越多地用於在現實世界場景中賦能和部署代理，這些代理根據對上下文的理解做出決策並採取行動。因此，研究人員、政策制定者和企業都在努力確保這些代理做出的決策符合人類價值觀和用戶期望。話雖如此，人類的價值觀和決策並不總是容易衡量的，並且會受到不同的認知偏差的影響。行為科學中有大量的文獻研究人類判斷中的偏差。在這項工作中，我們報告了一項正在進行的調查，內容是 LLM 與受順序偏差影響的人類判斷保持一致。具體來說，我們專注於一項著名的人類研究，該研究顯示了相似性判斷中順序效應的證據，並使用各種流行的 LLM 對其進行了複製。我們報告了 LLM 表現出類似人類的順序效應偏差的不同設置，並討論了這些發現對基於 LLM 的應用程序的設計和開發的影響。

##### **Coarse-to-Fine Detection of Multiple Seams for Robotic Welding**
2408.10710v1 by Pengkun Wei, Shuo Cheng, Dayou Li, Ran Song, Yipeng Zhang, Wei Zhang

Efficiently detecting target weld seams while ensuring sub-millimeter
accuracy has always been an important challenge in autonomous welding, which
has significant application in industrial practice. Previous works mostly
focused on recognizing and localizing welding seams one by one, leading to
inferior efficiency in modeling the workpiece. This paper proposes a novel
framework capable of multiple weld seams extraction using both RGB images and
3D point clouds. The RGB image is used to obtain the region of interest by
approximately localizing the weld seams, and the point cloud is used to achieve
the fine-edge extraction of the weld seams within the region of interest using
region growth. Our method is further accelerated by using a pre-trained deep
learning model to ensure both efficiency and generalization ability. The
performance of the proposed method has been comprehensively tested on various
workpieces featuring both linear and curved weld seams and in physical
experiment systems. The results showcase considerable potential for real-world
industrial applications, emphasizing the method's efficiency and effectiveness.
Videos of the real-world experiments can be found at
https://youtu.be/pq162HSP2D4.

摘要：<paragraph>在自動化焊接中，有效地檢測目標焊接縫，同時確保亞毫米精確度一直是一項重要的挑戰，這在工業實務中具有重要的應用。先前的研究大多集中於逐一識別和定位焊接縫，導致在建模工件時效率低下。本文提出了一個新的框架，能夠使用 RGB 影像和 3D 點雲提取多個焊接縫。RGB 影像用於透過近似定位焊接縫來取得感興趣區域，而點雲則用於使用區域生長來取得感興趣區域內焊接縫的精細邊緣提取。我們的技術進一步透過使用預先訓練的深度學習模型來加速，以確保效率和泛化能力。所提出的方法的效能已在具有線性和曲線焊接縫的各種工件和物理實驗系統中進行全面測試。結果顯示出在現實世界的工業應用中具有相當大的潛力，強調了該方法的效率和有效性。可以在 https://youtu.be/pq162HSP2D4 找到現實世界實驗的影片。</paragraph>

##### **Ferret: Faster and Effective Automated Red Teaming with Reward-Based Scoring Technique**
2408.10701v1 by Tej Deep Pala, Vernon Y. H. Toh, Rishabh Bhardwaj, Soujanya Poria

In today's era, where large language models (LLMs) are integrated into
numerous real-world applications, ensuring their safety and robustness is
crucial for responsible AI usage. Automated red-teaming methods play a key role
in this process by generating adversarial attacks to identify and mitigate
potential vulnerabilities in these models. However, existing methods often
struggle with slow performance, limited categorical diversity, and high
resource demands. While Rainbow Teaming, a recent approach, addresses the
diversity challenge by framing adversarial prompt generation as a
quality-diversity search, it remains slow and requires a large fine-tuned
mutator for optimal performance. To overcome these limitations, we propose
Ferret, a novel approach that builds upon Rainbow Teaming by generating
multiple adversarial prompt mutations per iteration and using a scoring
function to rank and select the most effective adversarial prompt. We explore
various scoring functions, including reward models, Llama Guard, and
LLM-as-a-judge, to rank adversarial mutations based on their potential harm to
improve the efficiency of the search for harmful mutations. Our results
demonstrate that Ferret, utilizing a reward model as a scoring function,
improves the overall attack success rate (ASR) to 95%, which is 46% higher than
Rainbow Teaming. Additionally, Ferret reduces the time needed to achieve a 90%
ASR by 15.2% compared to the baseline and generates adversarial prompts that
are transferable i.e. effective on other LLMs of larger size. Our codes are
available at https://github.com/declare-lab/ferret.

摘要：<paragraph>在大型語言模型 (LLM) 已整合至許多真實世界的應用程式中，確保其安全性和穩健性對於負責任的 AI 使用至關重要。自動化紅隊方法在這個過程中扮演關鍵角色，透過產生對抗性攻擊來找出並減輕這些模型中的潛在漏洞。然而，現有的方法經常面臨效能緩慢、分類多樣性受限和資源需求高的問題。雖然 Rainbow Teaming 這個近期方法透過將對抗性提示產生架構為品質多樣性搜尋來解決多樣性挑戰，但它仍然緩慢且需要一個經過大量微調的變異器才能達到最佳效能。為了克服這些限制，我們提出 Ferret，這是一種新方法，透過在每次反覆運算中產生多個對抗性提示變異並使用評分函數來排名並選出最有效的對抗性提示，進而建立在 Rainbow Teaming 之上。我們探討了各種評分函數，包括獎勵模型、Llama Guard 和 LLM-as-a-judge，根據對抗性變異對有害變異搜尋效率的潛在危害來對其進行排名。我們的結果證明，Ferret 利用獎勵模型作為評分函數，將整體攻擊成功率 (ASR) 提升至 95%，比 Rainbow Teaming 高出 46%。此外，與基準相比，Ferret 將達到 90% ASR 所需的時間減少了 15.2%，並產生可轉移的對抗性提示，亦即對更大規模的其他 LLM 有效。我們的程式碼可在 https://github.com/declare-lab/ferret 取得。</paragraph>

##### **AnyGraph: Graph Foundation Model in the Wild**
2408.10700v1 by Lianghao Xia, Chao Huang

The growing ubiquity of relational data structured as graphs has underscored
the need for graph learning models with exceptional generalization
capabilities. However, current approaches often struggle to effectively extract
generalizable insights, frequently requiring extensive fine-tuning and limiting
their versatility. Graph foundation models offer a transformative solution,
with the potential to learn robust, generalizable representations from graph
data. This enables more effective and adaptable applications across a wide
spectrum of tasks and domains. In this work, we investigate a unified graph
model, AnyGraph, designed to handle key challenges: i) Structure Heterogenity.
Addressing distribution shift in graph structural information; ii) Feature
Heterogenity. Handling diverse feature representation spaces across graph
datasets; iii) Fast Adaptation. Efficiently adapting the model to new graph
domains; iv) Scaling Law Emergence. Enabling the model to exhibit scaling law
behavior, where its performance scales favorably with the amount of data and
parameter sizes. To tackle these critical challenges, we build the AnyGraph
upon a Graph Mixture-of-Experts (MoE) architecture. This approach empowers the
model to effectively manage both the in-domain and cross-domain distribution
shift concerning structure-level and feature-level heterogeneity. Furthermore,
a lightweight graph expert routing mechanism is proposed to facilitate
AnyGraph's fast adaptability to new data and domains. Our extensive experiments
on diverse 38 graph datasets have demonstrated the strong zero-shot learning
performance of AnyGraph across diverse graph domains with significant
distribution shift. Furthermore, we have validated the model's fast adaptation
ability and scaling law emergence, showcasing its versatility.

摘要：随着关系数据以图形结构形式日益普及，对具有出色泛化能力的图学习模型的需求也日益凸显。然而，当前的方法通常难以有效提取可泛化的见解，经常需要进行广泛的微调，限制了其多功能性。图基础模型提供了一种变革性的解决方案，它有可能从图数据中学习到稳健、可泛化的表征。这使得在广泛的任务和领域中实现更有效和更具适应性的应用成为可能。在这项工作中，我们研究了一个统一的图模型 AnyGraph，它旨在应对以下关键挑战：i) 结构异质性。解决图结构信息中的分布变化；ii) 特征异质性。处理跨图数据集的不同特征表示空间；iii) 快速适应。有效地将模型适应到新的图域；iv) 规模定律的出现。使模型能够表现出规模定律行为，其中其性能随着数据量和参数大小的增加而成比例地扩展。为了应对这些关键挑战，我们在图混合专家 (MoE) 架构上构建了 AnyGraph。这种方法使模型能够有效地管理与结构级和特征级异质性相关的域内和跨域分布变化。此外，提出了一种轻量级的图专家路由机制，以促进 AnyGraph 快速适应新数据和域。我们在 38 个不同的图数据集上进行的广泛实验表明，AnyGraph 在具有显著分布变化的不同图域中具有强大的零样本学习性能。此外，我们验证了该模型的快速适应能力和规模定律的出现，展示了其多功能性。

##### **Unconditional Truthfulness: Learning Conditional Dependency for Uncertainty Quantification of Large Language Models**
2408.10692v1 by Artem Vazhentsev, Ekaterina Fadeeva, Rui Xing, Alexander Panchenko, Preslav Nakov, Timothy Baldwin, Maxim Panov, Artem Shelmanov

Uncertainty quantification (UQ) is a perspective approach to detecting Large
Language Model (LLM) hallucinations and low quality output. In this work, we
address one of the challenges of UQ in generation tasks that arises from the
conditional dependency between the generation steps of an LLM. We propose to
learn this dependency from data. We train a regression model, which target
variable is the gap between the conditional and the unconditional generation
confidence. During LLM inference, we use this learned conditional dependency
model to modulate the uncertainty of the current generation step based on the
uncertainty of the previous step. Our experimental evaluation on nine datasets
and three LLMs shows that the proposed method is highly effective for
uncertainty quantification, achieving substantial improvements over rivaling
approaches.

摘要：不確定量化 (UQ) 是一種觀點方法，用於偵測大型語言模型 (LLM) 的幻覺和低品質輸出。在這項工作中，我們解決了 UQ 在生成任務中的一個挑戰，該挑戰來自 LLM 的生成步驟之間的條件依賴性。我們提議從資料中學習這種依賴性。我們訓練了一個回歸模型，其目標變數是條件生成和無條件生成信心之間的差距。在 LLM 推論期間，我們使用這個已學習的條件依賴性模型來根據前一步的不確定性來調節當前生成步驟的不確定性。我們在九個資料集和三個 LLM 上的實驗評估表明，所提出的方法對於不確定量化非常有效，與競爭方法相比取得了顯著的改進。

##### **Fine-Tuning and Deploying Large Language Models Over Edges: Issues and Approaches**
2408.10691v1 by Yanjie Dong, Xiaoyi Fan, Fangxin Wang, Chengming Li, Victor C. M. Leung, Xiping Hu

Since the invention of GPT2--1.5B in 2019, large language models (LLMs) have
transitioned from specialized models to versatile foundation models. The LLMs
exhibit impressive zero-shot ability, however, require fine-tuning on local
datasets and significant resources for deployment. Traditional fine-tuning
techniques with the first-order optimizers require substantial GPU memory that
exceeds mainstream hardware capability. Therefore, memory-efficient methods are
motivated to be investigated. Model compression techniques can reduce energy
consumption, operational costs, and environmental impact so that to support
sustainable artificial intelligence advancements. Additionally, large-scale
foundation models have expanded to create images, audio, videos, and
multi-modal contents, further emphasizing the need for efficient deployment.
Therefore, we are motivated to present a comprehensive overview of the
prevalent memory-efficient fine-tuning methods over the network edge. We also
review the state-of-the-art literatures on model compression to provide a
vision on deploying LLMs over the network edge.

摘要：自 2019 年發明 GPT2--1.5B 以來，大型語言模型 (LLM) 已從專業模型轉變為通用的基礎模型。LLM 表現出令人印象深刻的零次學習能力，然而，需要針對本地資料集進行微調，並需要大量的資源才能部署。使用一階最佳化器的傳統微調技術需要大量的 GPU 記憶體，這超過了主流硬體的能力。因此，有動機研究記憶體效率高的方法。模型壓縮技術可以減少能源消耗、營運成本和環境影響，從而支援永續的人工智慧進展。此外，大規模基礎模型已擴展到建立影像、音訊、影片和多模態內容，進一步強調了高效部署的必要性。因此，我們有動機對網路邊緣常見的記憶體效率高微調方法提出全面的概述。我們也回顧了模型壓縮的最新文獻，以提供在網路邊緣部署 LLM 的願景。

##### **Genesis: Towards the Automation of Systems Biology Research**
2408.10689v1 by Ievgeniia A. Tiukova, Daniel Brunnsåker, Erik Y. Bjurström, Alexander H. Gower, Filip Kronström, Gabriel K. Reder, Ronald S. Reiserer, Konstantin Korovin, Larisa B. Soldatova, John P. Wikswo, Ross D. King

The cutting edge of applying AI to science is the closed-loop automation of
scientific research: robot scientists. We have previously developed two robot
scientists: `Adam' (for yeast functional biology), and `Eve' (for early-stage
drug design)). We are now developing a next generation robot scientist Genesis.
With Genesis we aim to demonstrate that an area of science can be investigated
using robot scientists unambiguously faster, and at lower cost, than with human
scientists. Here we report progress on the Genesis project. Genesis is designed
to automatically improve system biology models with thousands of interacting
causal components. When complete Genesis will be able to initiate and execute
in parallel one thousand hypothesis-led closed-loop cycles of experiment
per-day. Here we describe the core Genesis hardware: the one thousand
computer-controlled $\mu$-bioreactors. For the integrated Mass Spectrometry
platform we have developed AutonoMS, a system to automatically run, process,
and analyse high-throughput experiments. We have also developed Genesis-DB, a
database system designed to enable software agents access to large quantities
of structured domain information. We have developed RIMBO (Revisions for
Improvements of Models in Biology Ontology) to describe the planned hundreds of
thousands of changes to the models. We have demonstrated the utility of this
infrastructure by developed two relational learning bioinformatic projects.
Finally, we describe LGEM+ a relational learning system for the automated
abductive improvement of genome-scale metabolic models.

摘要：科學中應用 AI 的尖端技術是科學研究的封閉迴路自動化：機器人科學家。我們之前開發了兩位機器人科學家：`亞當`（用於酵母功能生物學）和 `夏娃`（用於早期藥物設計）。我們現在正在開發下一代機器人科學家創世紀。通過創世紀，我們旨在證明可以利用機器人科學家以明確更快的速度和更低的成本來研究科學領域，而不是人類科學家。在此，我們報告創世紀項目的進展。創世紀旨在使用數千個相互作用的因果組成部分自動改進系統生物學模型。創世紀完成後，將能夠每天並行啟動和執行一千個假設主導的封閉迴路實驗週期。在此，我們描述創世紀核心硬體：一千個電腦控制的 $\mu$-生物反應器。對於整合質譜平台，我們開發了 AutonoMS，一個自動執行、處理和分析高通量實驗的系統。我們還開發了創世紀資料庫，一個資料庫系統，旨在讓軟體代理存取大量結構化領域資訊。我們開發了 RIMBO（生物體系模型改進的修訂），用於描述模型預計的數十萬次變更。我們通過開發兩個關係學習生物資訊學專案來證明此基礎架構的效用。最後，我們描述 LGEM+，一個用於自動演繹式改進基因組規模代謝模型的關係學習系統。

##### **Rejection in Abstract Argumentation: Harder Than Acceptance?**
2408.10683v1 by Johannes K. Fichte, Markus Hecher, Yasir Mahmood, Arne Meier

Abstract argumentation is a popular toolkit for modeling, evaluating, and
comparing arguments. Relationships between arguments are specified in
argumentation frameworks (AFs), and conditions are placed on sets (extensions)
of arguments that allow AFs to be evaluated. For more expressiveness, AFs are
augmented with \emph{acceptance conditions} on directly interacting arguments
or a constraint on the admissible sets of arguments, resulting in dialectic
frameworks or constrained argumentation frameworks. In this paper, we consider
flexible conditions for \emph{rejecting} an argument from an extension, which
we call rejection conditions (RCs). On the technical level, we associate each
argument with a specific logic program. We analyze the resulting complexity,
including the structural parameter treewidth. Rejection AFs are highly
expressive, giving rise to natural problems on higher levels of the polynomial
hierarchy.

摘要：抽象論證是一種用於建模、評估和比較論證的熱門工具包。論證之間的關係在論證框架 (AF) 中指定，並對允許評估 AF 的論證集（擴充）設定條件。為了更具表現力，AF 會在直接交互論證或對可接受論證集的約束上加上「接受條件」，產生辯證框架或受約束論證框架。在本文中，我們考慮了從擴充中「拒絕」論證的彈性條件，我們稱之為拒絕條件 (RC)。在技術層面上，我們將每個論證與特定的邏輯程式關聯起來。我們分析了由此產生的複雜性，包括結構參數樹寬。拒絕 AF 具有高度表現力，導致多項式層次結構中較高層級的自然問題。

##### **Towards Robust Knowledge Unlearning: An Adversarial Framework for Assessing and Improving Unlearning Robustness in Large Language Models**
2408.10682v1 by Hongbang Yuan, Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao

LLM have achieved success in many fields but still troubled by problematic
content in the training corpora. LLM unlearning aims at reducing their
influence and avoid undesirable behaviours. However, existing unlearning
methods remain vulnerable to adversarial queries and the unlearned knowledge
resurfaces after the manually designed attack queries. As part of a red-team
effort to proactively assess the vulnerabilities of unlearned models, we design
Dynamic Unlearning Attack (DUA), a dynamic and automated framework to attack
these models and evaluate their robustness. It optimizes adversarial suffixes
to reintroduce the unlearned knowledge in various scenarios. We find that
unlearned knowledge can be recovered in $55.2\%$ of the questions, even without
revealing the unlearned model's parameters. In response to this vulnerability,
we propose Latent Adversarial Unlearning (LAU), a universal framework that
effectively enhances the robustness of the unlearned process. It formulates the
unlearning process as a min-max optimization problem and resolves it through
two stages: an attack stage, where perturbation vectors are trained and added
to the latent space of LLMs to recover the unlearned knowledge, and a defense
stage, where previously trained perturbation vectors are used to enhance
unlearned model's robustness. With our LAU framework, we obtain two robust
unlearning methods, AdvGA and AdvNPO. We conduct extensive experiments across
multiple unlearning benchmarks and various models, and demonstrate that they
improve the unlearning effectiveness by over $53.5\%$, cause only less than a
$11.6\%$ reduction in neighboring knowledge, and have almost no impact on the
model's general capabilities.

摘要：<paragraph>LLM 已在許多領域取得成功，但仍受訓練語料庫中問題內容的困擾。LLM 的反學習旨在減少其影響並避免不良行為。然而，現有的反學習方法仍然容易受到對抗查詢的影響，並且在手動設計的攻擊查詢後，未學習的知識會再次浮現。作為紅隊努力主動評估未學習模型的漏洞的一部分，我們設計了動態反學習攻擊 (DUA)，一個動態且自動化的框架，用於攻擊這些模型並評估其健壯性。它優化對抗後綴，以便在各種場景中重新引入未學習的知識。我們發現，即使不透露未學習模型的參數，也可以在 55.2% 的問題中恢復未學習的知識。針對此漏洞，我們提出了潛在對抗反學習 (LAU)，這是一個有效增強未學習過程健壯性的通用框架。它將反學習過程表述為一個最小最大值優化問題，並通過兩個階段解決它：攻擊階段，其中擾動向量被訓練並添加到 LLM 的潛在空間中以恢復未學習的知識，以及防禦階段，其中先前訓練的擾動向量用於增強未學習模型的健壯性。使用我們的 LAU 框架，我們獲得了兩種強大的反學習方法，AdvGA 和 AdvNPO。我們在多個反學習基準和各種模型中進行了廣泛的實驗，並證明它們將反學習的有效性提高了 53.5% 以上，僅導致鄰近知識減少了不到 11.6%，並且對模型的整體能力幾乎沒有影響。</paragraph>

##### **HMoE: Heterogeneous Mixture of Experts for Language Modeling**
2408.10681v1 by An Wang, Xingwu Sun, Ruobing Xie, Shuaipeng Li, Jiaqi Zhu, Zhen Yang, Pinxue Zhao, J. N. Han, Zhanhui Kang, Di Wang, Naoaki Okazaki, Cheng-zhong Xu

Mixture of Experts (MoE) offers remarkable performance and computational
efficiency by selectively activating subsets of model parameters.
Traditionally, MoE models use homogeneous experts, each with identical
capacity. However, varying complexity in input data necessitates experts with
diverse capabilities, while homogeneous MoE hinders effective expert
specialization and efficient parameter utilization. In this study, we propose a
novel Heterogeneous Mixture of Experts (HMoE), where experts differ in size and
thus possess diverse capacities. This heterogeneity allows for more specialized
experts to handle varying token complexities more effectively. To address the
imbalance in expert activation, we propose a novel training objective that
encourages the frequent activation of smaller experts, enhancing computational
efficiency and parameter utilization. Extensive experiments demonstrate that
HMoE achieves lower loss with fewer activated parameters and outperforms
conventional homogeneous MoE models on various pre-training evaluation
benchmarks. Codes will be released upon acceptance.

摘要：專家混合（MoE）透過選擇性地啟動模型參數子集，提供卓越的效能和運算效率。傳統上，MoE 模型使用同質專家，每個專家都具備相同的容量。然而，輸入資料的複雜性不同，需要具備不同能力的專家，而同質 MoE 會阻礙有效的專家專業化和參數利用效率。在本研究中，我們提出了一種新穎的異質專家混合（HMoE），其中專家在規模上有所不同，因此具備不同的容量。這種異質性允許更專業的專家更有效地處理不同的符號複雜性。為了解決專家啟動的不平衡問題，我們提出了一種新穎的訓練目標，鼓勵頻繁啟動較小的專家，進而提升運算效率和參數利用率。廣泛的實驗證明，HMoE 以較少的已啟動參數達成較低的損失，並且在各種預訓練評估基準上優於傳統同質 MoE 模型。程式碼會在通過驗證後釋出。

##### **Towards Rehearsal-Free Multilingual ASR: A LoRA-based Case Study on Whisper**
2408.10680v1 by Tianyi Xu, Kaixun Huang, Pengcheng Guo, Yu Zhou, Longtao Huang, Hui Xue, Lei Xie

Pre-trained multilingual speech foundation models, like Whisper, have shown
impressive performance across different languages. However, adapting these
models to new or specific languages is computationally extensive and faces
catastrophic forgetting problems. Addressing these issues, our study
investigates strategies to enhance the model on new languages in the absence of
original training data, while also preserving the established performance on
the original languages. Specifically, we first compare various LoRA-based
methods to find out their vulnerability to forgetting. To mitigate this issue,
we propose to leverage the LoRA parameters from the original model for
approximate orthogonal gradient descent on the new samples. Additionally, we
also introduce a learnable rank coefficient to allocate trainable parameters
for more efficient training. Our experiments with a Chinese Whisper model (for
Uyghur and Tibetan) yield better results with a more compact parameter set.

摘要：預訓練的多語言語音基礎模型（如 Whisper）已在不同語言中展現出令人印象深刻的效能。然而，將這些模型調整至新的或特定語言在運算上十分廣泛，且面臨災難性遺忘問題。為了解決這些問題，我們的研究探討了在沒有原始訓練資料的情況下，增強模型在新語言上的策略，同時也保留既有語言上的既定效能。具體來說，我們首先比較各種基於 LoRA 的方法，找出它們容易遺忘的弱點。為了減輕這個問題，我們建議利用原始模型中的 LoRA 參數，在新樣本上進行近似正交梯度下降。此外，我們還引入了一個可學習的秩係數，以分配可訓練參數，以進行更有效率的訓練。我們使用中文 Whisper 模型（針對維吾爾語和藏語）進行的實驗，使用更精簡的參數組產生了更好的結果。

##### **Tensor tree learns hidden relational structures in data to construct generative models**
2408.10669v1 by Kenji Harada, Tsuyoshi Okubo, Naoki Kawashima

Based on the tensor tree network with the Born machine framework, we propose
a general method for constructing a generative model by expressing the target
distribution function as the quantum wave function amplitude represented by a
tensor tree. The key idea is dynamically optimizing the tree structure that
minimizes the bond mutual information. The proposed method offers enhanced
performance and uncovers hidden relational structures in the target data. We
illustrate potential practical applications with four examples: (i) random
patterns, (ii) QMNIST hand-written digits, (iii) Bayesian networks, and (iv)
the stock price fluctuation pattern in S&P500. In (i) and (ii), strongly
correlated variables were concentrated near the center of the network; in
(iii), the causality pattern was identified; and, in (iv), a structure
corresponding to the eleven sectors emerged.

摘要：基於帶有 Born 機器框架的張量樹網路，我們提出了一種通用方法，通過將目標分佈函數表示為張量樹表示的量子波函數幅度來構造生成模型。關鍵思想是動態優化最小化鍵相互資訊的樹結構。所提出的方法提供了增強的效能，並揭示了目標資料中的隱藏關係結構。我們用四個範例來說明潛在的實際應用：(i) 隨機模式，(ii) QMNIST 手寫數字，(iii) 貝氏網路，以及 (iv) S&P500 中的股價波動模式。在 (i) 和 (ii) 中，強相關變數集中在網路的中心附近；在 (iii) 中，識別出因果模式；而在 (iv) 中，出現了對應於 11 個部門的結構。

##### **Probing the Safety Response Boundary of Large Language Models via Unsafe Decoding Path Generation**
2408.10668v2 by Haoyu Wang, Bingzhe Wu, Yatao Bian, Yongzhe Chang, Xueqian Wang, Peilin Zhao

Large Language Models (LLMs) are implicit troublemakers. While they provide
valuable insights and assist in problem-solving, they can also potentially
serve as a resource for malicious activities. Implementing safety alignment
could mitigate the risk of LLMs generating harmful responses. We argue that:
even when an LLM appears to successfully block harmful queries, there may still
be hidden vulnerabilities that could act as ticking time bombs. To identify
these underlying weaknesses, we propose to use a cost value model as both a
detector and an attacker. Trained on external or self-generated harmful
datasets, the cost value model could successfully influence the original safe
LLM to output toxic content in decoding process. For instance, LLaMA-2-chat 7B
outputs 39.18% concrete toxic content, along with only 22.16% refusals without
any harmful suffixes. These potential weaknesses can then be exploited via
prompt optimization such as soft prompts on images. We name this decoding
strategy: Jailbreak Value Decoding (JVD), emphasizing that seemingly secure
LLMs may not be as safe as we initially believe. They could be used to gather
harmful data or launch covert attacks.

摘要：大型語言模型 (LLM) 是潛在的麻煩製造者。雖然它們提供了有價值的見解並協助解決問題，但它們也可能成為惡意活動的資源。實施安全對齊可以降低 LLM 產生有害回應的風險。我們認為：即使 LLM 似乎成功地阻止了有害查詢，仍然可能存在潛在的漏洞，這些漏洞可能會成為定時炸彈。為了找出這些潛在的弱點，我們建議使用成本值模型作為偵測器和攻擊者。成本值模型經過外部或自我產生的有害數據集訓練，可以成功影響原始安全的 LLM 在解碼過程中輸出有毒內容。例如，LLaMA-2-chat 7B 輸出了 39.18% 的具體有毒內容，而只有 22.16% 的拒絕沒有任何有害的後綴。然後，這些潛在的弱點可以通過提示優化（例如圖像上的軟提示）來利用。我們將這種解碼策略命名為：越獄值解碼 (JVD)，強調看似安全的 LLM 可能不如我們最初認為的那麼安全。它們可用於收集有害數據或發動秘密攻擊。

##### **REInstruct: Building Instruction Data from Unlabeled Corpus**
2408.10663v1 by Shu Chen, Xinyan Guan, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun

Manually annotating instruction data for large language models is difficult,
costly, and hard to scale. Meanwhile, current automatic annotation methods
typically rely on distilling synthetic data from proprietary LLMs, which not
only limits the upper bound of the quality of the instruction data but also
raises potential copyright issues. In this paper, we propose REInstruct, a
simple and scalable method to automatically build instruction data from an
unlabeled corpus without heavy reliance on proprietary LLMs and human
annotation. Specifically, REInstruct first selects a subset of unlabeled texts
that potentially contain well-structured helpful and insightful content and
then generates instructions for these texts. To generate accurate and relevant
responses for effective and robust training, REInstruct further proposes a
rewriting-based approach to improve the quality of the generated instruction
data. By training Llama-7b on a combination of 3k seed data and 32k synthetic
data from REInstruct, fine-tuned model achieves a 65.41\% win rate on
AlpacaEval leaderboard against text-davinci-003, outperforming other
open-source, non-distilled instruction data construction methods. The code is
publicly available at \url{https://github.com/cs32963/REInstruct}.

摘要：大型語言模型的手動註解教學資料既困難、昂貴且難以擴充。同時，目前的自動註解方法通常依賴於從專有的 LLM 中提取合成資料，這不僅限制了教學資料品質的上限，還引發了潛在的版權問題。在本文中，我們提出了 REInstruct，這是一種簡單且可擴充的方法，用於從未標記的語料庫自動建立教學資料，而無需過度依賴專有的 LLM 和人工註解。具體來說，REInstruct 首先選擇一個未標記文字的子集，這些文字可能包含結構良好的有用且有見地的內容，然後為這些文字產生教學。為了產生準確且相關的回應以進行有效且穩健的訓練，REInstruct 進一步提出了一個基於重寫的方法來改善產生的教學資料品質。通過在 3k 種子資料和 32k REInstruct 合成資料的組合上訓練 Llama-7b，微調模型在 AlpacaEval 排行榜上對 text-davinci-003 達到了 65.41% 的獲勝率，優於其他開源、非提取的教學資料建構方法。程式碼可在 \url{https://github.com/cs32963/REInstruct} 公開取得。

##### **ETGuard: Malicious Encrypted Traffic Detection in Blockchain-based Power Grid Systems**
2408.10657v1 by Peng Zhou, Yongdong Liu, Lixun Ma, Weiye Zhang, Haohan Tan, Zhenguang Liu, Butian Huang

The escalating prevalence of encryption protocols has led to a concomitant
surge in the number of malicious attacks that hide in encrypted traffic. Power
grid systems, as fundamental infrastructure, are becoming prime targets for
such attacks. Conventional methods for detecting malicious encrypted packets
typically use a static pre-trained model. We observe that these methods are not
well-suited for blockchain-based power grid systems. More critically, they fall
short in dynamic environments where new types of encrypted attacks continuously
emerge. Motivated by this, in this paper we try to tackle these challenges from
two aspects: (1) We present a novel framework that is able to automatically
detect malicious encrypted traffic in blockchain-based power grid systems and
incrementally learn from new malicious traffic. (2) We mathematically derive
incremental learning losses to resist the forgetting of old attack patterns
while ensuring the model is capable of handling new encrypted attack patterns.
Empirically, our method achieves state-of-the-art performance on three
different benchmark datasets. We also constructed the first malicious encrypted
traffic dataset for blockchain-based power grid scenario. Our code and dataset
are available at https://github.com/PPPmzt/ETGuard, hoping to inspire future
research.

摘要：隨著加密協定的盛行，隱藏在加密流量中的惡意攻擊數量也隨之激增。作為基礎建設的電力系統正成為此類攻擊的首要目標。傳統的惡意加密封包偵測方法通常使用靜態預訓練模型。我們觀察到這些方法並不適合於基於區塊鏈的電力系統。更重要的是，它們在不斷出現新型加密攻擊的動態環境中表現不佳。有鑑於此，我們在本文中試圖從兩個方面來解決這些挑戰：(1) 我們提出了一個新穎的框架，能夠自動偵測基於區塊鏈的電力系統中的惡意加密流量，並從新的惡意流量中逐步學習。(2) 我們透過數學推導增量學習損失，以抵抗遺忘舊的攻擊模式，同時確保模型能夠處理新的加密攻擊模式。根據經驗，我們的模型在三個不同的基準資料集上達到了最先進的效能。我們還建構了第一個針對基於區塊鏈的電力系統場景的惡意加密流量資料集。我們的程式碼和資料集可在 https://github.com/PPPmzt/ETGuard 取得，希望能激勵未來的研究。

##### **Vocabulary-Free 3D Instance Segmentation with Vision and Language Assistant**
2408.10652v1 by Guofeng Mei, Luigi Riz, Yiming Wang, Fabio Poiesi

Most recent 3D instance segmentation methods are open vocabulary, offering a
greater flexibility than closed-vocabulary methods. Yet, they are limited to
reasoning within a specific set of concepts, \ie the vocabulary, prompted by
the user at test time. In essence, these models cannot reason in an open-ended
fashion, i.e., answering ``List the objects in the scene.''. We introduce the
first method to address 3D instance segmentation in a setting that is void of
any vocabulary prior, namely a vocabulary-free setting. We leverage a large
vision-language assistant and an open-vocabulary 2D instance segmenter to
discover and ground semantic categories on the posed images. To form 3D
instance mask, we first partition the input point cloud into dense superpoints,
which are then merged into 3D instance masks. We propose a novel superpoint
merging strategy via spectral clustering, accounting for both mask coherence
and semantic coherence that are estimated from the 2D object instance masks. We
evaluate our method using ScanNet200 and Replica, outperforming existing
methods in both vocabulary-free and open-vocabulary settings. Code will be made
available.

摘要：最新 3D 實例分割方法為開放式詞彙，提供比封閉式詞彙方法更大的靈活性。然而，它們僅限於在特定概念集合（即詞彙）內進行推理，由使用者在測試時提示。從本質上來說，這些模型無法以開放式的方式進行推理，即回答「列出場景中的物件」。我們引入了第一個方法來解決 3D 實例分割，其設定中沒有任何先前的詞彙，即無詞彙設定。我們利用大型視覺語言助理和開放式詞彙 2D 實例分割器，在所提出的影像上發現和建立語義類別。為了形成 3D 實例遮罩，我們首先將輸入點雲分割成密集的超點，然後將其合併成 3D 實例遮罩。我們透過光譜聚類提出了一種新的超點合併策略，考量了從 2D 物件實例遮罩估計的遮罩一致性和語義一致性。我們使用 ScanNet200 和 Replica 評估我們的模型，在無詞彙和開放式詞彙設定中都優於現有方法。程式碼將會公開。

##### **Inferring Underwater Topography with FINN**
2408.10649v1 by Coşku Can Horuz, Matthias Karlbauer, Timothy Praditia, Sergey Oladyshkin, Wolfgang Nowak, Sebastian Otte

Spatiotemporal partial differential equations (PDEs) find extensive
application across various scientific and engineering fields. While numerous
models have emerged from both physics and machine learning (ML) communities,
there is a growing trend towards integrating these approaches to develop hybrid
architectures known as physics-aware machine learning models. Among these, the
finite volume neural network (FINN) has emerged as a recent addition. FINN has
proven to be particularly efficient in uncovering latent structures in data. In
this study, we explore the capabilities of FINN in tackling the shallow-water
equations, which simulates wave dynamics in coastal regions. Specifically, we
investigate FINN's efficacy to reconstruct underwater topography based on these
particular wave equations. Our findings reveal that FINN exhibits a remarkable
capacity to infer topography solely from wave dynamics, distinguishing itself
from both conventional ML and physics-aware ML models. Our results underscore
the potential of FINN in advancing our understanding of spatiotemporal
phenomena and enhancing parametrization capabilities in related domains.

摘要：時空偏微分方程式 (PDE) 在各種科學和工程領域中廣泛應用。雖然物理和機器學習 (ML) 社群都出現了許多模型，但整合這些方法以開發稱為物理感知機器學習模型的混合架構的趨勢正逐漸增長。其中，有限體積神經網路 (FINN) 已成為最近的補充。FINN 已被證明在揭露資料中的潛在結構方面特別有效率。在本研究中，我們探討了 FINN 在處理淺水方程式中的能力，該方程式模擬了沿海地區的波動態。具體來說，我們研究了 FINN 根據這些特定波動方程式重建水下地形的效果。我們的研究結果表明，FINN 表現出僅從波動態推論地形的顯著能力，這使其區別於傳統 ML 和物理感知 ML 模型。我們的結果強調了 FINN 在增進我們對時空現象的理解和增強相關領域中參數化的能力的潛力。

##### **Privacy-preserving Universal Adversarial Defense for Black-box Models**
2408.10647v1 by Qiao Li, Cong Wu, Jing Chen, Zijun Zhang, Kun He, Ruiying Du, Xinxin Wang, Qingchuang Zhao, Yang Liu

Deep neural networks (DNNs) are increasingly used in critical applications
such as identity authentication and autonomous driving, where robustness
against adversarial attacks is crucial. These attacks can exploit minor
perturbations to cause significant prediction errors, making it essential to
enhance the resilience of DNNs. Traditional defense methods often rely on
access to detailed model information, which raises privacy concerns, as model
owners may be reluctant to share such data. In contrast, existing black-box
defense methods fail to offer a universal defense against various types of
adversarial attacks. To address these challenges, we introduce DUCD, a
universal black-box defense method that does not require access to the target
model's parameters or architecture. Our approach involves distilling the target
model by querying it with data, creating a white-box surrogate while preserving
data privacy. We further enhance this surrogate model using a certified defense
based on randomized smoothing and optimized noise selection, enabling robust
defense against a broad range of adversarial attacks. Comparative evaluations
between the certified defenses of the surrogate and target models demonstrate
the effectiveness of our approach. Experiments on multiple image classification
datasets show that DUCD not only outperforms existing black-box defenses but
also matches the accuracy of white-box defenses, all while enhancing data
privacy and reducing the success rate of membership inference attacks.

摘要：深度神经網路 (DNN) 愈來愈常使用在身分驗證和自動駕駛等關鍵應用中，在這些應用中，對抗攻擊的穩健性至關重要。這些攻擊可以利用輕微的擾動來造成顯著的預測錯誤，因此加強 DNN 的復原力至關重要。傳統的防禦方法通常依賴於取得詳細的模型資訊，這會引發隱私問題，因為模型所有者可能不願意分享這些資料。相反地，現有的黑盒防禦方法無法對各種類型的對抗攻擊提供通用的防禦。為了應對這些挑戰，我們引入了 DUCD，這是一種通用的黑盒防禦方法，不需要取得目標模型的參數或架構。我們的作法涉及透過資料查詢來萃取目標模型，在保留資料隱私的同時建立白盒代理。我們進一步使用基於隨機平滑和最佳化雜訊選擇的認證防禦來增強這個代理模型，進而對廣泛的對抗攻擊提供穩健的防禦。代理模型和目標模型的認證防禦之間的比較評估證明了我們方法的有效性。在多個影像分類資料集上的實驗顯示，DUCD 不僅優於現有的黑盒防禦，而且也符合白盒防禦的準確度，同時增強資料隱私並降低成員身分推論攻擊的成功率。

##### **Beneath the Surface of Consistency: Exploring Cross-lingual Knowledge Representation Sharing in LLMs**
2408.10646v1 by Maxim Ifergan, Leshem Choshen, Roee Aharoni, Idan Szpektor, Omri Abend

The veracity of a factoid is largely independent of the language it is
written in. However, language models are inconsistent in their ability to
answer the same factual question across languages. This raises questions about
how LLMs represent a given fact across languages. We explore multilingual
factual knowledge through two aspects: the model's ability to answer a query
consistently across languages, and the ability to ''store'' answers in a shared
representation for several languages. We propose a methodology to measure the
extent of representation sharing across languages by repurposing knowledge
editing methods. We examine LLMs with various multilingual configurations using
a new multilingual dataset. We reveal that high consistency does not
necessarily imply shared representation, particularly for languages with
different scripts. Moreover, we find that script similarity is a dominant
factor in representation sharing. Finally, we observe that if LLMs could fully
share knowledge across languages, their accuracy in their best-performing
language could benefit an increase of up to 150\% on average. These findings
highlight the need for improved multilingual knowledge representation in LLMs
and suggest a path for the development of more robust and consistent
multilingual LLMs.

摘要：事實的真實性在很大程度上與其書寫語言無關。然而，語言模型在不同語言中回答相同的事實問題的能力並不一致。這引發了有關 LLM 如何跨語言表示給定事實的問題。我們通過兩個方面探索多語言事實知識：模型跨語言一致回答查詢的能力，以及以多種語言共享表示「儲存」答案的能力。我們提出了一種方法，通過重新利用知識編輯方法來衡量跨語言表示共享的程度。我們使用新的多語言數據集檢查具有各種多語言配置的 LLM。我們發現高一致性並不一定意味著共享表示，特別是對於具有不同腳本的語言。此外，我們發現腳本相似性是表示共享中的主要因素。最後，我們觀察到，如果 LLM 能夠跨語言充分共享知識，那麼它們在其表現最佳的語言中的準確性平均可以提高 150%。這些發現強調了改進 LLM 中多語言知識表示的必要性，並為開發更強大、更一致的多語言 LLM 提供了一條途徑。

##### **Minor SFT loss for LLM fine-tune to increase performance and reduce model deviation**
2408.10642v1 by Shiming Xie, Hong Chen, Fred Yu, Zeye Sun, Xiuyu Wu

Instruct LLM provide a paradigm used in large scale language model to align
LLM to human preference. The paradigm contains supervised fine tuning and
reinforce learning from human feedback. This paradigm is also used in
downstream scenarios to adapt LLM to specific corpora and applications.
Comparing to SFT, there are many efforts focused on RLHF and several algorithms
being proposed, such as PPO, DPO, IPO, KTO, MinorDPO and etc. Meanwhile most
efforts for SFT are focused on how to collect, filter and mix high quality
data. In this article with insight from DPO and MinorDPO, we propose a training
metric for SFT to measure the discrepancy between the optimized model and the
original model, and a loss function MinorSFT that can increase the training
effectiveness, and reduce the discrepancy between the optimized LLM and
original LLM.

摘要：指示 LLM 提供大型语言模型中用于将 LLM 与人类偏好对齐的范例。该范例包含有监督的微调和根据人类反馈进行的强化学习。该范例还用于下游场景，以使 LLM 适应特定语料库和应用程序。与 SFT 相比，有许多工作重点关注 RLHF，并提出了多种算法，例如 PPO、DPO、IPO、KTO、MinorDPO 等。同时，SFT 的大多数工作重点在于如何收集、筛选和混合高质量数据。在本文中，利用 DPO 和 MinorDPO 的见解，我们提出了一个用于 SFT 的训练指标，以衡量优化后的模型与原始模型之间的差异，以及一个可以提高训练效果的损失函数 MinorSFT，并减少优化后的 LLM 与原始 LLM 之间的差异。

##### **A Review of Human-Object Interaction Detection**
2408.10641v1 by Yuxiao Wang, Qiwei Xiong, Yu Lei, Weiying Xue, Qi Liu, Zhenao Wei

Human-object interaction (HOI) detection plays a key role in high-level
visual understanding, facilitating a deep comprehension of human activities.
Specifically, HOI detection aims to locate the humans and objects involved in
interactions within images or videos and classify the specific interactions
between them. The success of this task is influenced by several key factors,
including the accurate localization of human and object instances, as well as
the correct classification of object categories and interaction relationships.
This paper systematically summarizes and discusses the recent work in
image-based HOI detection. First, the mainstream datasets involved in HOI
relationship detection are introduced. Furthermore, starting with two-stage
methods and end-to-end one-stage detection approaches, this paper
comprehensively discusses the current developments in image-based HOI
detection, analyzing the strengths and weaknesses of these two methods.
Additionally, the advancements of zero-shot learning, weakly supervised
learning, and the application of large-scale language models in HOI detection
are discussed. Finally, the current challenges in HOI detection are outlined,
and potential research directions and future trends are explored.

摘要：人體物件互動 (HOI) 偵測在高階視覺理解中扮演關鍵角色，促進了對人類活動的深入理解。具體來說，HOI 偵測旨在定位參與影像或影片互動中的人類和物件，並分類他們之間的特定互動。此任務的成功受幾個關鍵因素影響，包括人類和物件實體的準確定位，以及物件類別和互動關係的正確分類。本文系統性地總結和討論了基於影像的 HOI 偵測的近期工作。首先，介紹了 HOI 關係偵測所涉及的主流資料集。此外，本文從兩階段方法和端到端單階段偵測方法開始，全面討論了基於影像的 HOI 偵測的當前發展，分析了這兩種方法的優缺點。此外，討論了零次學習、弱監督學習和大型語言模型在 HOI 偵測中的應用進展。最後，概述了 HOI 偵測中當前的挑戰，並探討了潛在的研究方向和未來趨勢。

##### **Strategist: Learning Strategic Skills by LLMs via Bi-Level Tree Search**
2408.10635v1 by Jonathan Light, Min Cai, Weiqin Chen, Guanzhi Wang, Xiusi Chen, Wei Cheng, Yisong Yue, Ziniu Hu

In this paper, we propose a new method Strategist that utilizes LLMs to
acquire new skills for playing multi-agent games through a self-improvement
process. Our method gathers quality feedback through self-play simulations with
Monte Carlo tree search and LLM-based reflection, which can then be used to
learn high-level strategic skills such as how to evaluate states that guide the
low-level execution.We showcase how our method can be used in both action
planning and dialogue generation in the context of games, achieving good
performance on both tasks. Specifically, we demonstrate that our method can
help train agents with better performance than both traditional reinforcement
learning-based approaches and other LLM-based skill learning approaches in
games including the Game of Pure Strategy (GOPS) and The Resistance: Avalon.

摘要：在本文中，我們提出了一種新的方法 Strategist，它利用 LLM 通過自我提升過程來獲取玩多人遊戲的新技能。我們的這種方法通過蒙特卡羅樹搜尋和基於 LLM 的反思與自我對弈模擬收集高品質的回饋，然後可用於學習高層級策略技能，例如如何評估指導低層級執行的狀態。我們展示了我們的方法如何在遊戲的動作規劃和對話生成中使用，在兩個任務中都取得了良好的表現。具體來說，我們證明了我們的方法可以幫助訓練出比傳統的基於強化學習的方法和基於 LLM 的其他技能學習方法在包括純策略遊戲 (GOPS) 和抵抗：阿瓦隆在內的遊戲中表現更好的代理。

##### **LLM-Barber: Block-Aware Rebuilder for Sparsity Mask in One-Shot for Large Language Models**
2408.10631v1 by Yupeng Su, Ziyi Guan, Xiaoqun Liu, Tianlai Jin, Dongkuan Wu, Graziano Chesi, Ngai Wong, Hao Yu

Large language models (LLMs) have grown significantly in scale, leading to a
critical need for efficient model pruning techniques. Existing post-training
pruning techniques primarily focus on measuring weight importance on converged
dense models to determine salient weights to retain. However, they often
overlook the changes in weight importance during the pruning process, which can
lead to performance degradation in the pruned models. To address this issue, we
present LLM-Barber (Block-Aware Rebuilder for Sparsity Mask in One-Shot), a
novel one-shot pruning framework that rebuilds the sparsity mask of pruned
models without any retraining or weight reconstruction. LLM-Barber incorporates
block-aware error optimization across Self-Attention and MLP blocks, ensuring
global performance optimization. Inspired by the recent discovery of prominent
outliers in LLMs, LLM-Barber introduces an innovative pruning metric that
identifies weight importance using weights multiplied by gradients. Our
experiments show that LLM-Barber can efficiently prune models like LLaMA and
OPT families with 7B to 13B parameters on a single A100 GPU in just 30 minutes,
achieving state-of-the-art results in both perplexity and zero-shot performance
across various language benchmarks. Code is available at
https://github.com/YupengSu/LLM-Barber.

摘要：大型語言模型 (LLM) 的規模大幅成長，導致對有效模型修剪技術產生了迫切需求。現有的訓練後修剪技術主要專注於測量收斂稠密模型上的權重重要性，以確定要保留的顯著權重。然而，它們常常忽略修剪過程中權重重要性的變化，這可能導致修剪模型的效能下降。為了解決這個問題，我們提出了 LLM-Barber（一次性的稀疏遮罩區塊感知重建器），這是一個新穎的一次性修剪架構，可以在不重新訓練或權重重建的情況下重建修剪模型的稀疏遮罩。LLM-Barber 結合了自注意力和 MLP 區塊的區塊感知錯誤最佳化，確保整體效能最佳化。受 LLM 中發現的顯著異常值的啟發，LLM-Barber 引入了一種創新的修剪指標，該指標使用乘以梯度的權重來識別權重重要性。我們的實驗表明，LLM-Barber 可以有效修剪 LLaMA 和 OPT 系列等模型，這些模型在單個 A100 GPU 上有 7B 到 13B 個參數，僅需 30 分鐘，就能在各種語言基準測試中獲得困惑度和零次學習效能的最新結果。程式碼可於 https://github.com/YupengSu/LLM-Barber 取得。

##### **Finding the DeepDream for Time Series: Activation Maximization for Univariate Time Series**
2408.10628v1 by Udo Schlegel, Daniel A. Keim, Tobias Sutter

Understanding how models process and interpret time series data remains a
significant challenge in deep learning to enable applicability in
safety-critical areas such as healthcare. In this paper, we introduce Sequence
Dreaming, a technique that adapts Activation Maximization to analyze sequential
information, aiming to enhance the interpretability of neural networks
operating on univariate time series. By leveraging this method, we visualize
the temporal dynamics and patterns most influential in model decision-making
processes. To counteract the generation of unrealistic or excessively noisy
sequences, we enhance Sequence Dreaming with a range of regularization
techniques, including exponential smoothing. This approach ensures the
production of sequences that more accurately reflect the critical features
identified by the neural network. Our approach is tested on a time series
classification dataset encompassing applications in predictive maintenance. The
results show that our proposed Sequence Dreaming approach demonstrates targeted
activation maximization for different use cases so that either centered class
or border activation maximization can be generated. The results underscore the
versatility of Sequence Dreaming in uncovering salient temporal features
learned by neural networks, thereby advancing model transparency and
trustworthiness in decision-critical domains.

摘要：了解模型如何處理和詮釋時間序列資料，在深度學習中仍然是一項重大的挑戰，以利於在安全關鍵領域（例如醫療保健）中應用。在本文中，我們介紹序列夢境，這是一種技術，它改編了啟用最大化以分析順序資訊，旨在增強在單變量時間序列上運作的神經網路的可解釋性。藉由利用此方法，我們可視化在模型決策過程中影響最大的時間動態和模式。為了對抗產生不切實際或過度雜訊的序列，我們以各種正則化技術（包括指數平滑）來增強序列夢境。此方法可確保產生更準確反映神經網路所識別的關鍵特徵的序列。我們的方法在時間序列分類資料集上進行測試，其中包含預測性維護中的應用。結果顯示，我們提出的序列夢境方法展示了針對不同使用案例的目標啟用最大化，因此可以產生以類別為中心或邊界啟用最大化。結果強調了序列夢境在揭露神經網路所學習到的顯著時間特徵中的多功能性，從而提升了決策關鍵領域中的模型透明度和可信度。

##### **Novel Change Detection Framework in Remote Sensing Imagery Using Diffusion Models and Structural Similarity Index (SSIM)**
2408.10619v1 by Andrew Kiruluta, Eric Lundy, Andreas Lemos

Change detection is a crucial task in remote sensing, enabling the monitoring
of environmental changes, urban growth, and disaster impact. Conventional
change detection techniques, such as image differencing and ratioing, often
struggle with noise and fail to capture complex variations in imagery. Recent
advancements in machine learning, particularly generative models like diffusion
models, offer new opportunities for enhancing change detection accuracy. In
this paper, we propose a novel change detection framework that combines the
strengths of Stable Diffusion models with the Structural Similarity Index
(SSIM) to create robust and interpretable change maps. Our approach, named
Diffusion Based Change Detector, is evaluated on both synthetic and real-world
remote sensing datasets and compared with state-of-the-art methods. The results
demonstrate that our method significantly outperforms traditional differencing
techniques and recent deep learning-based methods, particularly in scenarios
with complex changes and noise.

摘要：變遷偵測是遙測中一項重要的任務，可監控環境變化、都市成長和災害影響。傳統的變遷偵測技術（例如影像差異和比率）常受雜訊影響，且無法捕捉影像中的複雜變化。機器學習的最新進展，特別是生成模型（如擴散模型），為提升變遷偵測準確度提供了新的契機。在本文中，我們提出一個新穎的變遷偵測架構，結合 Stable Diffusion 模型與結構相似性指標 (SSIM) 的優點，以建立穩健且可解讀的變遷圖。我們的方法稱為基於擴散的變遷偵測器，在合成和真實遙測資料集上進行評估，並與最先進的方法進行比較。結果表明，我們的方法顯著優於傳統差異技術和最近基於深度學習的方法，特別是在具有複雜變化和雜訊的情況下。

##### **OMEGA: Efficient Occlusion-Aware Navigation for Air-Ground Robot in Dynamic Environments via State Space Model**
2408.10618v1 by Junming Wang, Dong Huang, Xiuxian Guan, Zekai Sun, Tianxiang Shen, Fangming Liu, Heming Cui

Air-ground robots (AGRs) are widely used in surveillance and disaster
response due to their exceptional mobility and versatility (i.e., flying and
driving). Current AGR navigation systems perform well in static occlusion-prone
environments (e.g., indoors) by using 3D semantic occupancy networks to predict
occlusions for complete local mapping and then computing Euclidean Signed
Distance Field (ESDF) for path planning. However, these systems face challenges
in dynamic, severe occlusion scenes (e.g., crowds) due to limitations in
perception networks' low prediction accuracy and path planners' high
computation overhead. In this paper, we propose OMEGA, which contains OccMamba
with an Efficient AGR-Planner to address the above-mentioned problems. OccMamba
adopts a novel architecture that separates semantic and occupancy prediction
into independent branches, incorporating two mamba blocks within these
branches. These blocks efficiently extract semantic and geometric features in
3D environments with linear complexity, ensuring that the network can learn
long-distance dependencies to improve prediction accuracy. Semantic and
geometric features are combined within the Bird's Eye View (BEV) space to
minimise computational overhead during feature fusion. The resulting semantic
occupancy map is then seamlessly integrated into the local map, providing
occlusion awareness of the dynamic environment. Our AGR-Planner utilizes this
local map and employs kinodynamic A* search and gradient-based trajectory
optimization to guarantee planning is ESDF-free and energy-efficient. Extensive
experiments demonstrate that OccMamba outperforms the state-of-the-art 3D
semantic occupancy network with 25.0% mIoU. End-to-end navigation experiments
in dynamic scenes verify OMEGA's efficiency, achieving a 96% average planning
success rate. Code and video are available at
https://jmwang0117.github.io/OMEGA/.

摘要：<paragraph>空對地機器人 (AGR) 因其出色的機動性和多功能性 (例如飛行和駕駛)，而廣泛用於監控和災害應變。目前的 AGR 導航系統在靜態且容易遮擋的環境中 (例如室內) 表現良好，方法是使用 3D 語義佔用網路來預測遮擋，以進行完整的局部建圖，然後計算歐幾里得符號距離場 (ESDF) 以進行路徑規劃。然而，這些系統在動態、嚴重遮擋的場景 (例如人群) 中會面臨挑戰，因為感知網路的預測準確度低，而路徑規劃器的計算開銷高。在本文中，我們提出了 OMEGA，其中包含 OccMamba 和高效的 AGR 規劃器，以解決上述問題。OccMamba 採用一種新穎的架構，將語義和佔用預測分為獨立的分支，在這些分支中包含兩個 mamba 塊。這些塊在 3D 環境中以線性複雜度有效提取語義和幾何特徵，確保網路可以學習長距離依賴關係以提高預測準確度。語義和幾何特徵在鳥瞰圖 (BEV) 空間中結合，以在特徵融合過程中最大程度地減少計算開銷。然後將生成的語義佔用地圖無縫整合到局部地圖中，提供動態環境的遮擋感知。我們的 AGR 規劃器利用此局部地圖並採用運動動力 A* 搜尋和基於梯度的軌跡最佳化，以保證規劃無 ESDF 且節能。大量的實驗表明，OccMamba 的表現優於最先進的 3D 語義佔用網路，mIoU 達到 25.0%。動態場景中的端到端導航實驗驗證了 OMEGA 的效率，實現了 96% 的平均規劃成功率。程式碼和影片可在 https://jmwang0117.github.io/OMEGA/ 取得。</paragraph>

##### **Enhancing Robustness in Large Language Models: Prompting for Mitigating the Impact of Irrelevant Information**
2408.10615v1 by Ming Jiang, Tingting Huang, Biao Guo, Yao Lu, Feng Zhang

In recent years, Large language models (LLMs) have garnered significant
attention due to their superior performance in complex reasoning tasks.
However, recent studies may diminish their reasoning capabilities markedly when
problem descriptions contain irrelevant information, even with the use of
advanced prompting techniques. To further investigate this issue, a dataset of
primary school mathematics problems containing irrelevant information, named
GSMIR, was constructed. Testing prominent LLMs and prompting techniques on this
dataset revealed that while LLMs can identify irrelevant information, they do
not effectively mitigate the interference it causes once identified. A novel
automatic construction method, ATF, which enhances the ability of LLMs to
identify and self-mitigate the influence of irrelevant information, is proposed
to address this shortcoming. This method operates in two steps: first, analysis
of irrelevant information, followed by its filtering. The ATF method, as
demonstrated by experimental results, significantly improves the reasoning
performance of LLMs and prompting techniques, even in the presence of
irrelevant information on the GSMIR dataset.

摘要：近年來，大型語言模型 (LLM) 因其在複雜推理任務中的卓越表現而備受關注。然而，最近的研究顯示，即使使用先進的提示技術，當問題描述包含無關信息時，它們的推理能力可能會顯著下降。為了進一步探討此問題，構建了一個包含無關信息的小學數學問題數據集，稱為 GSMIR。在這個數據集上測試著名的 LLM 和提示技術後發現，雖然 LLM 可以識別無關信息，但一旦識別出，它們並不能有效減輕其造成的干擾。提出了一種新穎的自動構建方法 ATF，它增強了 LLM 識別和自我減輕無關信息影響的能力，以解決這一缺點。此方法分兩步進行：首先，分析無關信息，然後對其進行過濾。如實驗結果所示，ATF 方法顯著提高了 LLM 和提示技術的推理性能，即使在 GSMIR 數據集上存在無關信息的情況下也是如此。

##### **Generalizable Facial Expression Recognition**
2408.10614v1 by Yuhang Zhang, Xiuqi Zheng, Chenyi Liang, Jiani Hu, Weihong Deng

SOTA facial expression recognition (FER) methods fail on test sets that have
domain gaps with the train set. Recent domain adaptation FER methods need to
acquire labeled or unlabeled samples of target domains to fine-tune the FER
model, which might be infeasible in real-world deployment. In this paper, we
aim to improve the zero-shot generalization ability of FER methods on different
unseen test sets using only one train set. Inspired by how humans first detect
faces and then select expression features, we propose a novel FER pipeline to
extract expression-related features from any given face images. Our method is
based on the generalizable face features extracted by large models like CLIP.
However, it is non-trivial to adapt the general features of CLIP for specific
tasks like FER. To preserve the generalization ability of CLIP and the high
precision of the FER model, we design a novel approach that learns sigmoid
masks based on the fixed CLIP face features to extract expression features. To
further improve the generalization ability on unseen test sets, we separate the
channels of the learned masked features according to the expression classes to
directly generate logits and avoid using the FC layer to reduce overfitting. We
also introduce a channel-diverse loss to make the learned masks separated.
Extensive experiments on five different FER datasets verify that our method
outperforms SOTA FER methods by large margins. Code is available in
https://github.com/zyh-uaiaaaa/Generalizable-FER.

摘要：最先進的人臉表情辨識 (FER) 方法在與訓練集有領域差距的測試集中會失敗。最近的領域適應 FER 方法需要取得目標領域的標籤或未標籤樣本，以微調 FER 模型，這在實際部署中可能是不可行的。在本文中，我們旨在僅使用一個訓練集，來提升 FER 方法在不同未見測試集上的零次學習泛化能力。受人類先偵測人臉然後選擇表情特徵的啟發，我們提出一個新穎的 FER 管線，從任何給定的人臉影像中萃取與表情相關的特徵。我們的模型建立在 CLIP 等大型模型萃取出的可泛化人臉特徵之上。然而，要將 CLIP 的一般特徵適應到 FER 等特定任務並不容易。為了保留 CLIP 的泛化能力和 FER 模型的高精度，我們設計了一種新穎的方法，根據固定的 CLIP 人臉特徵學習 sigmoid 遮罩，以萃取表情特徵。為了進一步提升在未見測試集上的泛化能力，我們根據表情類別將學習到的遮罩特徵的通道分開，以直接產生 logit 並避免使用 FC 層來減少過度擬合。我們也引入了一個通道多樣化損失，以使學習到的遮罩分開。在五個不同的 FER 資料集上進行的廣泛實驗驗證了我們的模型比最先進的 FER 方法高出許多。程式碼可在 https://github.com/zyh-uaiaaaa/Generalizable-FER 取得。

##### **Promoting Equality in Large Language Models: Identifying and Mitigating the Implicit Bias based on Bayesian Theory**
2408.10608v1 by Yongxin Deng, Xihe Qiu, Xiaoyu Tan, Jing Pan, Chen Jue, Zhijun Fang, Yinghui Xu, Wei Chu, Yuan Qi

Large language models (LLMs) are trained on extensive text corpora, which
inevitably include biased information. Although techniques such as Affective
Alignment can mitigate some negative impacts of these biases, existing
prompt-based attack methods can still extract these biases from the model's
weights. Moreover, these biases frequently appear subtly when LLMs are prompted
to perform identical tasks across different demographic groups, thereby
camouflaging their presence. To address this issue, we have formally defined
the implicit bias problem and developed an innovative framework for bias
removal based on Bayesian theory, Bayesian-Theory based Bias Removal (BTBR).
BTBR employs likelihood ratio screening to pinpoint data entries within
publicly accessible biased datasets that represent biases inadvertently
incorporated during the LLM training phase. It then automatically constructs
relevant knowledge triples and expunges bias information from LLMs using model
editing techniques. Through extensive experimentation, we have confirmed the
presence of the implicit bias problem in LLMs and demonstrated the
effectiveness of our BTBR approach.

摘要：大型語言模型 (LLM) 接受過大量文本語料庫的訓練，其中不可避免地包含有偏差的資訊。雖然情感對齊等技術可以減輕這些偏差的一些負面影響，但現有的基於提示的攻擊方法仍然可以從模型的權重中提取這些偏差。此外，當提示 LLM 對不同人口群體執行相同的任務時，這些偏差經常會以微妙的方式出現，從而掩蓋它們的存在。為了解決這個問題，我們正式定義了隱含偏差問題，並基於貝葉斯理論開發了一個創新的偏差消除框架，即基於貝葉斯理論的偏差消除 (BTBR)。BTBR 採用似然比篩選來精確定位 LLM 訓練階段中無意中納入偏差的公開可訪問偏差資料集中的資料條目。然後，它自動構建相關知識三元組，並使用模型編輯技術從 LLM 中刪除偏差資訊。通過廣泛的實驗，我們確認了 LLM 中隱含偏差問題的存在，並證明了我們的 BTBR 方法的有效性。

##### **MUSES: 3D-Controllable Image Generation via Multi-Modal Agent Collaboration**
2408.10605v2 by Yanbo Ding, Shaobin Zhuang, Kunchang Li, Zhengrong Yue, Yu Qiao, Yali Wang

Despite recent advancements in text-to-image generation, most existing
methods struggle to create images with multiple objects and complex spatial
relationships in 3D world. To tackle this limitation, we introduce a generic AI
system, namely MUSES, for 3D-controllable image generation from user queries.
Specifically, our MUSES addresses this challenging task by developing a
progressive workflow with three key components, including (1) Layout Manager
for 2D-to-3D layout lifting, (2) Model Engineer for 3D object acquisition and
calibration, (3) Image Artist for 3D-to-2D image rendering. By mimicking the
collaboration of human professionals, this multi-modal agent pipeline
facilitates the effective and automatic creation of images with 3D-controllable
objects, through an explainable integration of top-down planning and bottom-up
generation. Additionally, we find that existing benchmarks lack detailed
descriptions of complex 3D spatial relationships of multiple objects. To fill
this gap, we further construct a new benchmark of T2I-3DisBench (3D image
scene), which describes diverse 3D image scenes with 50 detailed prompts.
Extensive experiments show the state-of-the-art performance of MUSES on both
T2I-CompBench and T2I-3DisBench, outperforming recent strong competitors such
as DALL-E 3 and Stable Diffusion 3. These results demonstrate a significant
step of MUSES forward in bridging natural language, 2D image generation, and 3D
world.

摘要：儘管文字轉圖片的生成技術近來有長足進步，但現有的方法大多難以在 3D 世界中建立具有多個物件和複雜空間關係的圖片。為了克服此限制，我們推出一個通用的 AI 系統，稱為 MUSES，用於從使用者查詢生成可 3D 控制的圖片。具體來說，我們的 MUSES 透過開發一個具有三個關鍵組件的漸進式工作流程來解決這項艱鉅的任務，包括 (1) 用於 2D 到 3D 佈局提升的佈局管理員、(2) 用於 3D 物件擷取和校準的模型工程師，以及 (3) 用於 3D 到 2D 圖片渲染的圖片藝術家。透過模仿人類專業人員的協作，此多模式代理程式管道透過自上而下的規劃和自下而上的生成的說明性整合，促進有效且自動建立具有 3D 可控制物件的圖片。此外，我們發現現有的基準缺乏對多個物件複雜 3D 空間關係的詳細說明。為了填補此差距，我們進一步建立了一個 T2I-3DisBench（3D 圖片場景）的新基準，其中描述了具有 50 個詳細提示的多樣化 3D 圖片場景。廣泛的實驗顯示，MUSES 在 T2I-CompBench 和 T2I-3DisBench 上都具有最先進的效能，優於 DALL-E 3 和 Stable Diffusion 3 等近期強勁的競爭對手。這些結果證明了 MUSES 在橋接自然語言、2D 圖片生成和 3D 世界方面邁出了一大步。

##### **Multilingual Non-Factoid Question Answering with Silver Answers**
2408.10604v1 by Ritwik Mishra, Sreeram Vennam, Rajiv Ratn Shah, Ponnurangam Kumaraguru

Most existing Question Answering Datasets (QuADs) primarily focus on
factoid-based short-context Question Answering (QA) in high-resource languages.
However, the scope of such datasets for low-resource languages remains limited,
with only a few works centered on factoid-based QuADs and none on non-factoid
QuADs. Therefore, this work presents MuNfQuAD, a multilingual QuAD with
non-factoid questions. It utilizes interrogative sub-headings from BBC news
articles as questions and the corresponding paragraphs as silver answers. The
dataset comprises over 370K QA pairs across 38 languages, encompassing several
low-resource languages, and stands as the largest multilingual QA dataset to
date. Based on the manual annotations of 790 QA-pairs from MuNfQuAD (golden
set), we observe that 98\% of questions can be answered using their
corresponding silver answer. Our fine-tuned Answer Paragraph Selection (APS)
model outperforms the baselines. The APS model attained an accuracy of 80\% and
72\%, as well as a macro F1 of 72\% and 66\%, on the MuNfQuAD testset and the
golden set, respectively. Furthermore, the APS model effectively generalizes
certain a language within the golden set, even after being fine-tuned on silver
labels.

摘要：現有的大多數問答資料集（QuAD）主要關注高資源語言中的基於事實的短文脈問答（QA）。然而，此類資料集在低資源語言中的應用範圍仍然有限，只有少數作品專注於基於事實的 QuAD，而沒有關於非事實 QuAD 的作品。因此，這項工作提出了 MuNfQuAD，一個具有非事實問題的多語言 QuAD。它利用 BBC 新聞文章中的疑問小標題作為問題，並將相應的段落作為銀色答案。該資料集包含 38 種語言中超過 37 萬個 QA 對，涵蓋多種低資源語言，並且是迄今為止最大的多語言 QA 資料集。根據 MuNfQuAD（黃金集）中 790 個 QA 對的手動註釋，我們觀察到 98% 的問題可以使用其相應的銀色答案來回答。我們微調後的答案段落選擇（APS）模型優於基線。APS 模型在 MuNfQuAD 測試集和黃金集上分別達到 80% 和 72% 的準確率，以及 72% 和 66% 的巨集 F1。此外，即使在銀色標籤上進行微調後，APS 模型也能有效地概括黃金集中某些語言。

##### **MV-MOS: Multi-View Feature Fusion for 3D Moving Object Segmentation**
2408.10602v1 by Jintao Cheng, Xingming Chen, Jinxin Liang, Xiaoyu Tang, Xieyuanli Chen, Dachuan Li

Effectively summarizing dense 3D point cloud data and extracting motion
information of moving objects (moving object segmentation, MOS) is crucial to
autonomous driving and robotics applications. How to effectively utilize motion
and semantic features and avoid information loss during 3D-to-2D projection is
still a key challenge. In this paper, we propose a novel multi-view MOS model
(MV-MOS) by fusing motion-semantic features from different 2D representations
of point clouds. To effectively exploit complementary information, the motion
branches of the proposed model combines motion features from both bird's eye
view (BEV) and range view (RV) representations. In addition, a semantic branch
is introduced to provide supplementary semantic features of moving objects.
Finally, a Mamba module is utilized to fuse the semantic features with motion
features and provide effective guidance for the motion branches. We validated
the effectiveness of the proposed multi-branch fusion MOS framework via
comprehensive experiments, and our proposed model outperforms existing
state-of-the-art models on the SemanticKITTI benchmark.

摘要：有效摘要密集 3D 點雲資料和萃取移動物體的動作資訊（移動物體分割，MOS）對於自動駕駛和機器人應用程式至關重要。如何有效利用動作和語意特徵，並在 3D 到 2D 投影期間避免資訊遺失，仍然是一項關鍵的挑戰。在本文中，我們提出一個新的多視圖 MOS 模型 (MV-MOS)，透過融合來自點雲不同 2D 表示的動作語意特徵。為了有效利用互補資訊，所提出模型的動作分支結合了來自鳥瞰圖 (BEV) 和範圍視圖 (RV) 表示的動作特徵。此外，還引入了一個語意分支來提供移動物體的補充語意特徵。最後，利用 Mamba 模組將語意特徵與動作特徵融合，並為動作分支提供有效的指導。我們透過全面的實驗驗證了所提出的多分支融合 MOS 架構的有效性，而我們提出的模型在 SemanticKITTI 基準測試中優於現有的最先進模型。

##### **Breast tumor classification based on self-supervised contrastive learning from ultrasound videos**
2408.10600v1 by Yunxin Tang, Siyuan Tang, Jian Zhang, Hao Chen

Background: Breast ultrasound is prominently used in diagnosing breast
tumors. At present, many automatic systems based on deep learning have been
developed to help radiologists in diagnosis. However, training such systems
remains challenging because they are usually data-hungry and demand amounts of
labeled data, which need professional knowledge and are expensive. Methods: We
adopted a triplet network and a self-supervised contrastive learning technique
to learn representations from unlabeled breast ultrasound video clips. We
further designed a new hard triplet loss to to learn representations that
particularly discriminate positive and negative image pairs that are hard to
recognize. We also constructed a pretraining dataset from breast ultrasound
videos (1,360 videos from 200 patients), which includes an anchor sample
dataset with 11,805 images, a positive sample dataset with 188,880 images, and
a negative sample dataset dynamically generated from video clips. Further, we
constructed a finetuning dataset, including 400 images from 66 patients. We
transferred the pretrained network to a downstream benign/malignant
classification task and compared the performance with other state-of-the-art
models, including three models pretrained on ImageNet and a previous
contrastive learning model retrained on our datasets. Results and conclusion:
Experiments revealed that our model achieved an area under the receiver
operating characteristic curve (AUC) of 0.952, which is significantly higher
than the others. Further, we assessed the dependence of our pretrained model on
the number of labeled data and revealed that <100 samples were required to
achieve an AUC of 0.901. The proposed framework greatly reduces the demand for
labeled data and holds potential for use in automatic breast ultrasound image
diagnosis.

摘要：<paragraph>背景：乳房超音波在诊断乳房腫瘤中佔有重要地位。目前，許多基於深度學習的自動化系統已開發出來，以協助放射科醫師診斷。然而，訓練此類系統仍然具有挑戰性，因為它們通常需要大量資料，且需要大量的標籤資料，這需要專業知識且昂貴。方法：我們採用三元組網路和自我監督對比學習技術，從未標籤的乳房超音波影片片段中學習表徵。我們進一步設計了一個新的困難三元組損失，以學習特別區分難以辨識的正負影像對的表徵。我們還從乳房超音波影片中建構了一個預訓練資料集（來自 200 位患者的 1,360 個影片），其中包括包含 11,805 張影像的錨定樣本資料集、包含 188,880 張影像的正樣本資料集，以及從影片片段中動態生成的負樣本資料集。此外，我們建構了一個微調資料集，其中包含來自 66 位患者的 400 張影像。我們將預訓練網路轉移到下游良性/惡性分類任務，並將其效能與其他最先進的模型進行比較，包括三個在 ImageNet 上預訓練的模型和一個在我們的資料集上重新訓練的對比學習模型。結果與結論：實驗顯示，我們的模型在受試者工作特性曲線 (AUC) 下方達到了 0.952 的面積，顯著高於其他模型。此外，我們評估了我們預訓練模型對標籤資料數量依賴性的，並發現只需不到 100 個樣本即可達到 0.901 的 AUC。所提出的架構大幅減少了對標籤資料的需求，並具有用於自動乳房超音波影像診斷的潛力。</paragraph>

##### **An Efficient Sign Language Translation Using Spatial Configuration and Motion Dynamics with LLMs**
2408.10593v1 by Eui Jun Hwang, Sukmin Cho, Junmyeong Lee, Jong C. Park

Gloss-free Sign Language Translation (SLT) converts sign videos directly into
spoken language sentences without relying on glosses. Recently, Large Language
Models (LLMs) have shown remarkable translation performance in gloss-free
methods by harnessing their powerful natural language generation capabilities.
However, these methods often rely on domain-specific fine-tuning of visual
encoders to achieve optimal results. By contrast, this paper emphasizes the
importance of capturing the spatial configurations and motion dynamics inherent
in sign language. With this in mind, we introduce Spatial and Motion-based Sign
Language Translation (SpaMo), a novel LLM-based SLT framework. The core idea of
SpaMo is simple yet effective. We first extract spatial and motion features
using off-the-shelf visual encoders and then input these features into an LLM
with a language prompt. Additionally, we employ a visual-text alignment process
as a warm-up before the SLT supervision. Our experiments demonstrate that SpaMo
achieves state-of-the-art performance on two popular datasets, PHOENIX14T and
How2Sign.

摘要：無光澤手語翻譯 (SLT) 將手語影片直接轉換成口說語言句子，而無需依賴光澤。最近，大型語言模型 (LLM) 透過利用其強大的自然語言生成能力，在無光澤方法中展現了卓越的翻譯效能。然而，這些方法通常依賴於視覺編碼器的特定領域微調才能達成最佳結果。相比之下，本文強調捕捉手語中固有的空間配置和動作動態的重要性。基於此，我們引入了基於空間和動作的手語翻譯 (SpaMo)，這是一個新穎的基於 LLM 的 SLT 架構。SpaMo 的核心概念簡單卻有效。我們首先使用現成的視覺編碼器提取空間和動作特徵，然後將這些特徵輸入到具有語言提示的 LLM 中。此外，我們在 SLT 監督之前採用視覺文字對齊程序作為熱身。我們的實驗證明，SpaMo 在兩個熱門數據集 PHOENIX14T 和 How2Sign 上達到了最先進的效能。

##### **Hologram Reasoning for Solving Algebra Problems with Geometry Diagrams**
2408.10592v1 by Litian Huang, Xinguo Yu, Feng Xiong, Bin He, Shengbing Tang, Jiawen Fu

Solving Algebra Problems with Geometry Diagrams (APGDs) is still a
challenging problem because diagram processing is not studied as intensively as
language processing. To work against this challenge, this paper proposes a
hologram reasoning scheme and develops a high-performance method for solving
APGDs by using this scheme. To reach this goal, it first defines a hologram,
being a kind of graph, and proposes a hologram generator to convert a given
APGD into a hologram, which represents the entire information of APGD and the
relations for solving the problem can be acquired from it by a uniform way.
Then HGR, a hologram reasoning method employs a pool of prepared graph models
to derive algebraic equations, which is consistent with the geometric theorems.
This method is able to be updated by adding new graph models into the pool.
Lastly, it employs deep reinforcement learning to enhance the efficiency of
model selection from the pool. The entire HGR not only ensures high solution
accuracy with fewer reasoning steps but also significantly enhances the
interpretability of the solution process by providing descriptions of all
reasoning steps. Experimental results demonstrate the effectiveness of HGR in
improving both accuracy and interpretability in solving APGDs.

摘要：利用幾何圖形圖（APGD）解決代數問題仍然是一個具有挑戰性的問題，因為圖形處理的研究不如語言處理那麼深入。為了應對這一挑戰，本文提出了一種全息推理方案，並開發了一種使用該方案解決 APGD 的高性能方法。為了達到這個目標，它首先定義了一個全息圖，作為一種圖形，並提出了一個全息圖生成器，將給定的 APGD 轉換為一個全息圖，它表示 APGD 的全部信息，並且可以通過統一的方式從中獲取解決問題的關係。然後，HGR，一種全息推理方法，採用一組準備好的圖形模型來推導代數方程式，這與幾何定理是一致的。這種方法可以通過向池中添加新的圖形模型來更新。最後，它採用深度強化學習來提高從池中選擇模型的效率。整個 HGR 不僅確保了較少的推理步驟即可獲得較高的求解精度，而且還通過提供所有推理步驟的描述來顯著增強了解決過程的可解釋性。實驗結果證明了 HGR 在提高求解 APGD 的準確性和可解釋性方面的有效性。

##### **Putting People in LLMs' Shoes: Generating Better Answers via Question Rewriter**
2408.10573v1 by Junhao Chen, Bowen Wang, Zhouqiang jiang, Yuta Nakashima

Large Language Models (LLMs) have demonstrated significant capabilities,
particularly in the domain of question answering (QA). However, their
effectiveness in QA is often undermined by the vagueness of user questions. To
address this issue, we introduce single-round instance-level prompt
optimization, referred to as question rewriter. By enhancing the
intelligibility of human questions for black-box LLMs, our question rewriter
improves the quality of generated answers. The rewriter is optimized using
direct preference optimization based on feedback collected from automatic
criteria for evaluating generated answers; therefore, its training does not
require costly human annotations. The experiments across multiple black-box
LLMs and long-form question answering (LFQA) datasets demonstrate the efficacy
of our method. This paper provides a practical framework for training question
rewriters and sets a precedent for future explorations in prompt optimization
within LFQA tasks. Code is available at
\url{https://github.com/3244we/Question-Rewriter}.

摘要：大型語言模型 (LLM) 已展現出顯著的能力，特別是在問答 (QA) 領域。然而，它們在問答中的有效性經常受到使用者問題模糊性的影響。為了解決這個問題，我們引入了單輪例項級別提示最佳化，稱為問題改寫器。透過增強黑盒 LLM 對人類問題的可理解性，我們的問題改寫器改善了生成答案的品質。改寫器使用直接偏好最佳化進行最佳化，基礎是從用於評估生成答案的自動標準中收集的回饋；因此，它的訓練不需要昂貴的人工註解。跨多個黑盒 LLM 和長篇問答 (LFQA) 資料集的實驗證明了我們方法的效力。這篇論文提供了一個實用的架構，用於訓練問題改寫器，並為 LFQA 任務中的提示最佳化建立了未來探索的先例。程式碼可在 \url{https://github.com/3244we/Question-Rewriter} 取得。

