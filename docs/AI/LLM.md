
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-24**|**StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal**|Chongjie Ye et.al.|[2406.16864v1](http://arxiv.org/abs/2406.16864v1)|null|
|**2024-06-24**|**EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees**|Yuhui Li et.al.|[2406.16858v1](http://arxiv.org/abs/2406.16858v1)|null|
|**2024-06-24**|**GeoMFormer: A General Architecture for Geometric Molecular Representation Learning**|Tianlang Chen et.al.|[2406.16853v1](http://arxiv.org/abs/2406.16853v1)|[link](https://github.com/c-tl/geomformer)|
|**2024-06-24**|**Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts**|Aditya Sharma et.al.|[2406.16851v1](http://arxiv.org/abs/2406.16851v1)|null|
|**2024-06-24**|**RaTEScore: A Metric for Radiology Report Generation**|Weike Zhao et.al.|[2406.16845v1](http://arxiv.org/abs/2406.16845v1)|null|
|**2024-06-24**|**Exploring Factual Entailment with NLI: A News Media Study**|Guy Mor-Lan et.al.|[2406.16842v1](http://arxiv.org/abs/2406.16842v1)|null|
|**2024-06-24**|**From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models**|Sean Welleck et.al.|[2406.16838v1](http://arxiv.org/abs/2406.16838v1)|null|
|**2024-06-24**|**USDC: A Dataset of $\underline{U}$ser $\underline{S}$tance and $\underline{D}$ogmatism in Long $\underline{C}$onversations**|Mounika Marreddy et.al.|[2406.16833v1](http://arxiv.org/abs/2406.16833v1)|null|
|**2024-06-24**|**Understanding and Mitigating Tokenization Bias in Language Models**|Buu Phan et.al.|[2406.16829v1](http://arxiv.org/abs/2406.16829v1)|null|
|**2024-06-24**|**Ragnarök: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track**|Ronak Pradeep et.al.|[2406.16828v1](http://arxiv.org/abs/2406.16828v1)|null|
|**2024-06-24**|**General Binding Affinity Guidance for Diffusion Models in Structure-Based Drug Design**|Yue Jian et.al.|[2406.16821v1](http://arxiv.org/abs/2406.16821v1)|null|
|**2024-06-24**|**PISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs**|Xinchi Qiu et.al.|[2406.16810v1](http://arxiv.org/abs/2406.16810v1)|null|
|**2024-06-24**|**Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback for Text-to-Image Generation**|Katherine M. Collins et.al.|[2406.16807v1](http://arxiv.org/abs/2406.16807v1)|null|
|**2024-06-24**|**RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale**|Beck LaBash et.al.|[2406.16801v1](http://arxiv.org/abs/2406.16801v1)|[link](https://github.com/qurrent-ai/res-q)|
|**2024-06-24**|**Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs**|Ashwinee Panda et.al.|[2406.16797v2](http://arxiv.org/abs/2406.16797v2)|[link](https://github.com/kiddyboots216/lottery-ticket-adaptation)|
|**2024-06-24**|**Adam-mini: Use Fewer Learning Rates To Gain More**|Yushun Zhang et.al.|[2406.16793v1](http://arxiv.org/abs/2406.16793v1)|null|
|**2024-06-24**|**The Progression of Transformers from Language to Vision to MOT: A Literature Review on Multi-Object Tracking with Transformers**|Abhi Kamboj et.al.|[2406.16784v1](http://arxiv.org/abs/2406.16784v1)|null|
|**2024-06-24**|**M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models**|Rishabh Maheshwary et.al.|[2406.16783v1](http://arxiv.org/abs/2406.16783v1)|null|
|**2024-06-24**|**It Is Not About What You Say, It Is About How You Say It: A Surprisingly Simple Approach for Improving Reading Comprehension**|Sagi Shaier et.al.|[2406.16779v1](http://arxiv.org/abs/2406.16779v1)|null|
|**2024-06-24**|**Finding Transformer Circuits with Edge Pruning**|Adithya Bhaskar et.al.|[2406.16778v1](http://arxiv.org/abs/2406.16778v1)|[link](https://github.com/princeton-nlp/edge-pruning)|
|**2024-06-24**|**Blending LLMs into Cascaded Speech Translation: KIT's Offline Speech Translation System for IWSLT 2024**|Sai Koneru et.al.|[2406.16777v1](http://arxiv.org/abs/2406.16777v1)|null|
|**2024-06-24**|**OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?**|Zhen Huang et.al.|[2406.16772v1](http://arxiv.org/abs/2406.16772v1)|[link](https://github.com/gair-nlp/olympicarena)|
|**2024-06-24**|**WARP: On the Benefits of Weight Averaged Rewarded Policies**|Alexandre Ramé et.al.|[2406.16768v1](http://arxiv.org/abs/2406.16768v1)|null|
|**2024-06-24**|**The GPT-WritingPrompts Dataset: A Comparative Analysis of Character Portrayal in Short Stories**|Xi Yu Huang et.al.|[2406.16767v1](http://arxiv.org/abs/2406.16767v1)|[link](https://github.com/kristinhuangg/gpt-writing-prompts)|
|**2024-06-24**|**Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters**|Euiin Yi et.al.|[2406.16758v1](http://arxiv.org/abs/2406.16758v1)|null|
|**2024-06-24**|**Addressing Polarization and Unfairness in Performative Prediction**|Kun Jin et.al.|[2406.16756v1](http://arxiv.org/abs/2406.16756v1)|null|
|**2024-06-24**|**Towards Zero-Shot Text-To-Speech for Arabic Dialects**|Khai Duy Doan et.al.|[2406.16751v2](http://arxiv.org/abs/2406.16751v2)|null|
|**2024-06-24**|**OCALM: Object-Centric Assessment with Language Models**|Timo Kaufmann et.al.|[2406.16748v1](http://arxiv.org/abs/2406.16748v1)|null|
|**2024-06-24**|**Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers**|Chao Lou et.al.|[2406.16747v1](http://arxiv.org/abs/2406.16747v1)|null|
|**2024-06-24**|**The Responsible Foundation Model Development Cheatsheet: A Review of Tools & Resources**|Shayne Longpre et.al.|[2406.16746v1](http://arxiv.org/abs/2406.16746v1)|null|
|**2024-06-24**|**Bandits with Preference Feedback: A Stackelberg Game Perspective**|Barna Pásztor et.al.|[2406.16745v1](http://arxiv.org/abs/2406.16745v1)|null|
|**2024-06-24**|**Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization**|Zhengyue Zhao et.al.|[2406.16743v1](http://arxiv.org/abs/2406.16743v1)|null|
|**2024-06-24**|**Extracting thin film structures of energy materials using transformers**|Chen Zhang et.al.|[2406.16741v1](http://arxiv.org/abs/2406.16741v1)|null|
|**2024-06-24**|**Inducing Group Fairness in LLM-Based Decisions**|James Atwood et.al.|[2406.16738v1](http://arxiv.org/abs/2406.16738v1)|null|
|**2024-06-24**|**CLIMATELI: Evaluating Entity Linking on Climate Change Data**|Shijia Zhou et.al.|[2406.16732v1](http://arxiv.org/abs/2406.16732v1)|null|
|**2024-06-24**|**Convolutional neural network for Lyman break galaxies classification and redshift regression in DESI (Dark Energy Spectroscopic Instrument)**|Julien Taran et.al.|[2406.16730v1](http://arxiv.org/abs/2406.16730v1)|null|
|**2024-06-24**|**CausalMMM: Learning Causal Structure for Marketing Mix Modeling**|Chang Gong et.al.|[2406.16728v1](http://arxiv.org/abs/2406.16728v1)|null|
|**2024-06-24**|**Venturing into Uncharted Waters: The Navigation Compass from Transformer to Mamba**|Yuchen Zou et.al.|[2406.16722v1](http://arxiv.org/abs/2406.16722v1)|null|
|**2024-06-24**|**AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models**|Jiale Cheng et.al.|[2406.16714v1](http://arxiv.org/abs/2406.16714v1)|[link](https://github.com/thu-coai/autodetect)|
|**2024-06-24**|**Probabilistic Subgoal Representations for Hierarchical Reinforcement learning**|Vivienne Huiling Wang et.al.|[2406.16707v1](http://arxiv.org/abs/2406.16707v1)|null|
|**2024-06-24**|**Public Constitutional AI**|Gilad Abiri et.al.|[2406.16696v1](http://arxiv.org/abs/2406.16696v1)|null|
|**2024-06-24**|**Task Oriented In-Domain Data Augmentation**|Xiao Liang et.al.|[2406.16694v1](http://arxiv.org/abs/2406.16694v1)|null|
|**2024-06-24**|**Scaling Laws for Linear Complexity Language Models**|Xuyang Shen et.al.|[2406.16690v1](http://arxiv.org/abs/2406.16690v1)|null|
|**2024-06-24**|**Link Prediction with Untrained Message Passing Layers**|Lisi Qarkaxhija et.al.|[2406.16687v1](http://arxiv.org/abs/2406.16687v1)|null|
|**2024-06-24**|**Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation**|Markus Frohmann et.al.|[2406.16678v1](http://arxiv.org/abs/2406.16678v1)|null|
|**2024-06-24**|**Computational Approaches to the Detection of Lesser-Known Rhetorical Figures: A Systematic Survey and Research Challenges**|Ramona Kühn et.al.|[2406.16674v1](http://arxiv.org/abs/2406.16674v1)|null|
|**2024-06-24**|**CAVE: Controllable Authorship Verification Explanations**|Sahana Ramnath et.al.|[2406.16672v1](http://arxiv.org/abs/2406.16672v1)|[link](https://github.com/ink-usc/controllable-av-explanations)|
|**2024-06-24**|**Large Language Models Are Cross-Lingual Knowledge-Free Reasoners**|Peng Hu et.al.|[2406.16655v1](http://arxiv.org/abs/2406.16655v1)|null|
|**2024-06-24**|**Vision-Language Consistency Guided Multi-modal Prompt Learning for Blind AI Generated Image Quality Assessment**|Jun Fu et.al.|[2406.16641v1](http://arxiv.org/abs/2406.16641v1)|null|
|**2024-06-24**|**Feature Fusion for Human Activity Recognition using Parameter-Optimized Multi-Stage Graph Convolutional Network and Transformer Models**|Mohammad Belal et.al.|[2406.16638v1](http://arxiv.org/abs/2406.16638v1)|null|
|**2024-06-24**|**ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models**|Yash Akhauri et.al.|[2406.16635v1](http://arxiv.org/abs/2406.16635v1)|[link](https://github.com/abdelfattah-lab/shadow_llm)|
|**2024-06-24**|**Hacking a surrogate model approach to XAI**|Alexander Wilhelm et.al.|[2406.16626v1](http://arxiv.org/abs/2406.16626v1)|null|
|**2024-06-24**|**Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings**|Andrea Posada et.al.|[2406.16611v1](http://arxiv.org/abs/2406.16611v1)|[link](https://github.com/anpoc/language-models-in-medicine)|
|**2024-06-24**|**Evaluating the Robustness of Deep-Learning Algorithm-Selection Models by Evolving Adversarial Instances**|Emma Hart et.al.|[2406.16609v1](http://arxiv.org/abs/2406.16609v1)|null|
|**2024-06-24**|**CLEAR: Can Language Models Really Understand Causal Graphs?**|Sirui Chen et.al.|[2406.16605v1](http://arxiv.org/abs/2406.16605v1)|[link](https://github.com/opencausalab/clear)|
|**2024-06-24**|**QuadrupedGPT: Towards a Versatile Quadruped Agent in Open-ended Worlds**|Ye Wang et.al.|[2406.16578v1](http://arxiv.org/abs/2406.16578v1)|null|
|**2024-06-24**|**Data Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting**|Jiyue Jiang et.al.|[2406.16567v1](http://arxiv.org/abs/2406.16567v1)|null|
|**2024-06-24**|**Are there identifiable structural parts in the sentence embedding whole?**|Vivi Nastase et.al.|[2406.16563v1](http://arxiv.org/abs/2406.16563v1)|null|
|**2024-06-24**|**EvalAlign: Evaluating Text-to-Image Models through Precision Alignment of Multimodal Large Models with Supervised Fine-Tuning to Human Annotations**|Zhiyu Tan et.al.|[2406.16562v1](http://arxiv.org/abs/2406.16562v1)|[link](https://github.com/sais-fuxi/evalalign)|
|**2024-06-24**|**Homomorphisms and Embeddings of STRIPS Planning Models**|Arnaud Lequen et.al.|[2406.16555v1](http://arxiv.org/abs/2406.16555v1)|null|
|**2024-06-24**|**LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-training**|Tong Zhu et.al.|[2406.16554v1](http://arxiv.org/abs/2406.16554v1)|[link](https://github.com/pjlab-sys4nlp/llama-moe)|
|**2024-06-24**|**Inference of Sequential Patterns for Neural Message Passing in Temporal Graphs**|Jan von Pichowski et.al.|[2406.16552v1](http://arxiv.org/abs/2406.16552v1)|null|
|**2024-06-24**|**C-LLM: Learn to Check Chinese Spelling Errors Character by Character**|Kunting Li et.al.|[2406.16536v1](http://arxiv.org/abs/2406.16536v1)|[link](https://github.com/ktlktl/c-llm)|
|**2024-06-24**|**Token-based Decision Criteria Are Suboptimal in In-context Learning**|Hakaze Cho et.al.|[2406.16535v1](http://arxiv.org/abs/2406.16535v1)|null|
|**2024-06-24**|**Towards Better Graph-based Cross-document Relation Extraction via Non-bridge Entity Enhancement and Prediction Debiasing**|Hao Yue et.al.|[2406.16529v1](http://arxiv.org/abs/2406.16529v1)|[link](https://github.com/deeplearnxmu/core-nepd)|
|**2024-06-24**|**Evaluating the Ability of Large Language Models to Reason about Cardinal Directions**|Anthony G Cohn et.al.|[2406.16528v1](http://arxiv.org/abs/2406.16528v1)|null|
|**2024-06-24**|**NARRepair: Non-Autoregressive Code Generation Model for Automatic Program Repair**|Zhenyu Yang et.al.|[2406.16526v1](http://arxiv.org/abs/2406.16526v1)|null|
|**2024-06-24**|**The Privileged Students: On the Value of Initialization in Multilingual Knowledge Distillation**|Haryo Akbarianto Wibowo et.al.|[2406.16524v1](http://arxiv.org/abs/2406.16524v1)|null|
|**2024-06-24**|**Carrot and Stick: Inducing Self-Motivation with Positive & Negative Feedback**|Jimin Sohn et.al.|[2406.16521v1](http://arxiv.org/abs/2406.16521v1)|null|
|**2024-06-24**|**Large Vocabulary Size Improves Large Language Models**|Sho Takase et.al.|[2406.16508v1](http://arxiv.org/abs/2406.16508v1)|null|
|**2024-06-24**|**UNICAD: A Unified Approach for Attack Detection, Noise Reduction and Novel Class Identification**|Alvaro Lopez Pellicer et.al.|[2406.16501v1](http://arxiv.org/abs/2406.16501v1)|null|
|**2024-06-24**|**OTCE: Hybrid SSM and Attention with Cross Domain Mixture of Experts to construct Observer-Thinker-Conceiver-Expresser**|Jingze Shi et.al.|[2406.16495v2](http://arxiv.org/abs/2406.16495v2)|[link](https://github.com/LoserCheems/OTCE)|
|**2024-06-24**|**Cross-domain Transfer of Valence Preferences via a Meta-optimization Approach**|Chuang Zhao et.al.|[2406.16494v1](http://arxiv.org/abs/2406.16494v1)|[link](https://github.com/data-designer/maprec)|
|**2024-06-24**|**eagerlearners at SemEval2024 Task 5: The Legal Argument Reasoning Task in Civil Procedure**|Hoorieh Sabzevari et.al.|[2406.16490v1](http://arxiv.org/abs/2406.16490v1)|null|
|**2024-06-24**|**Deepfake tweets automatic detection**|Adam Frej et.al.|[2406.16489v1](http://arxiv.org/abs/2406.16489v1)|null|
|**2024-06-24**|**Towards Comprehensive Preference Data Collection for Reward Modeling**|Yulan Hu et.al.|[2406.16486v1](http://arxiv.org/abs/2406.16486v1)|null|
|**2024-06-24**|**Emerging NeoHebbian Dynamics in Forward-Forward Learning: Implications for Neuromorphic Computing**|Erik B. Terres-Escudero et.al.|[2406.16479v1](http://arxiv.org/abs/2406.16479v1)|[link](https://github.com/erikberter/hebbian_ffa)|
|**2024-06-24**|**DaLPSR: Leverage Degradation-Aligned Language Prompt for Real-World Image Super-Resolution**|Aiwen Jiang et.al.|[2406.16477v1](http://arxiv.org/abs/2406.16477v1)|null|
|**2024-06-24**|**Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration**|Yujin Baek et.al.|[2406.16469v1](http://arxiv.org/abs/2406.16469v1)|null|
|**2024-06-24**|**Guardrails for avoiding harmful medical product recommendations and off-label promotion in generative AI models**|Daniel Lopez-Martinez et.al.|[2406.16455v1](http://arxiv.org/abs/2406.16455v1)|null|
|**2024-06-24**|**Learning in Wilson-Cowan model for metapopulation**|Raffaele Marino et.al.|[2406.16453v1](http://arxiv.org/abs/2406.16453v1)|[link](https://github.com/raffaelemarino/learning_in_wilsoncowan)|
|**2024-06-24**|**Building on Efficient Foundations: Effectively Training LLMs with Structured Feedforward Layers**|Xiuying Wei et.al.|[2406.16450v1](http://arxiv.org/abs/2406.16450v1)|null|
|**2024-06-24**|**UniCoder: Scaling Code Large Language Model via Universal Code**|Tao Sun et.al.|[2406.16441v1](http://arxiv.org/abs/2406.16441v1)|null|
|**2024-06-24**|**Theory on Mixture-of-Experts in Continual Learning**|Hongbo Li et.al.|[2406.16437v1](http://arxiv.org/abs/2406.16437v1)|null|
|**2024-06-24**|**Dynamic Pseudo Label Optimization in Point-Supervised Nuclei Segmentation**|Ziyue Wang et.al.|[2406.16427v1](http://arxiv.org/abs/2406.16427v1)|null|
|**2024-06-24**|**Fault Detection for agents on power grid topology optimization: A Comprehensive analysis**|Malte Lehna et.al.|[2406.16426v1](http://arxiv.org/abs/2406.16426v1)|null|
|**2024-06-24**|**Multilingual Knowledge Editing with Language-Agnostic Factual Neurons**|Xue zhang et.al.|[2406.16416v1](http://arxiv.org/abs/2406.16416v1)|null|
|**2024-06-24**|**PenSLR: Persian end-to-end Sign Language Recognition Using Ensembling**|Amirparsa Salmankhah et.al.|[2406.16388v1](http://arxiv.org/abs/2406.16388v1)|null|
|**2024-06-24**|**Automatically Generating UI Code from Screenshot: A Divide-and-Conquer-Based Approach**|Yuxuan Wan et.al.|[2406.16386v1](http://arxiv.org/abs/2406.16386v1)|null|
|**2024-06-24**|**UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models**|Zhanyue Qin et.al.|[2406.16382v1](http://arxiv.org/abs/2406.16382v1)|null|
|**2024-06-24**|**On the Transformations across Reward Model, Parameter Update, and In-Context Prompt**|Deng Cai et.al.|[2406.16377v1](http://arxiv.org/abs/2406.16377v1)|null|
|**2024-06-24**|**KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning**|Dongyang Li et.al.|[2406.16374v1](http://arxiv.org/abs/2406.16374v1)|null|
|**2024-06-24**|**UniPSDA: Unsupervised Pseudo Semantic Data Augmentation for Zero-Shot Cross-Lingual Natural Language Understanding**|Dongyang Li et.al.|[2406.16372v1](http://arxiv.org/abs/2406.16372v1)|null|
|**2024-06-24**|**Towards Lightweight Graph Neural Network Search with Curriculum Graph Sparsification**|Beini Xie et.al.|[2406.16357v1](http://arxiv.org/abs/2406.16357v1)|null|
|**2024-06-24**|**Evaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation**|Rem Hida et.al.|[2406.16356v1](http://arxiv.org/abs/2406.16356v1)|null|
|**2024-06-24**|**Directed Domain Fine-Tuning: Tailoring Separate Modalities for Specific Training Tasks**|Daniel Wen et.al.|[2406.16346v1](http://arxiv.org/abs/2406.16346v1)|null|
|**2024-06-24**|**ADVSCORE: A Metric for the Evaluation and Creation of Adversarial Benchmarks**|Yoo Yeon Sung et.al.|[2406.16342v1](http://arxiv.org/abs/2406.16342v1)|null|
|**2024-06-24**|**EHRCon: Dataset for Checking Consistency between Unstructured Notes and Structured Tables in Electronic Health Records**|Yeonsu Kwon et.al.|[2406.16341v1](http://arxiv.org/abs/2406.16341v1)|[link](https://github.com/dustn1259/ehrcon)|
|**2024-06-24**|**Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models**|Yichen Sun et.al.|[2406.16333v1](http://arxiv.org/abs/2406.16333v1)|null|
|**2024-06-24**|**DemoRank: Selecting Effective Demonstrations for Large Language Models in Ranking Task**|Wenhan Liu et.al.|[2406.16332v1](http://arxiv.org/abs/2406.16332v1)|null|

#### Abstracts
##### **StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal**
2406.16864v1 by Chongjie Ye, Lingteng Qiu, Xiaodong Gu, Qi Zuo, Yushuang Wu, Zilong Dong, Liefeng Bo, Yuliang Xiu, Xiaoguang Han

This work addresses the challenge of high-quality surface normal estimation
from monocular colored inputs (i.e., images and videos), a field which has
recently been revolutionized by repurposing diffusion priors. However, previous
attempts still struggle with stochastic inference, conflicting with the
deterministic nature of the Image2Normal task, and costly ensembling step,
which slows down the estimation process. Our method, StableNormal, mitigates
the stochasticity of the diffusion process by reducing inference variance, thus
producing "Stable-and-Sharp" normal estimates without any additional ensembling
process. StableNormal works robustly under challenging imaging conditions, such
as extreme lighting, blurring, and low quality. It is also robust against
transparent and reflective surfaces, as well as cluttered scenes with numerous
objects. Specifically, StableNormal employs a coarse-to-fine strategy, which
starts with a one-step normal estimator (YOSO) to derive an initial normal
guess, that is relatively coarse but reliable, then followed by a
semantic-guided refinement process (SG-DRN) that refines the normals to recover
geometric details. The effectiveness of StableNormal is demonstrated through
competitive performance in standard datasets such as DIODE-indoor, iBims,
ScannetV2 and NYUv2, and also in various downstream tasks, such as surface
reconstruction and normal enhancement. These results evidence that StableNormal
retains both the "stability" and "sharpness" for accurate normal estimation.
StableNormal represents a baby attempt to repurpose diffusion priors for
deterministic estimation. To democratize this, code and models have been
publicly available in hf.co/Stable-X

摘要：这项工作解决了从单目彩色输入（即图像和视频）中估计高质量表面法线的问题，该领域最近因重新利用扩散先验而发生了革命性的变化。然而，以往的尝试仍然难以应对随机推理，与 Image2Normal 任务的确定性本质相冲突，并且代价高昂的集成步骤减慢了估计过程。我们的方法 StableNormal 通过降低推理方差来减轻扩散过程的随机性，从而在没有任何额外集成过程的情况下生成“稳定而清晰”的法线估计。StableNormal 在极端光照、模糊和低质量等具有挑战性的成像条件下表现得非常稳健。它还对透明和反射表面以及包含大量对象的混乱场景具有鲁棒性。具体来说，StableNormal 采用了一种从粗到精的策略，从一步法线估计器 (YOSO) 开始，推导出一个初始法线猜测，该猜测相对粗糙但可靠，然后是语义引导细化过程 (SG-DRN)，该过程细化法线以恢复几何细节。StableNormal 的有效性通过在 DIODE-indoor、iBims、ScannetV2 和 NYUv2 等标准数据集以及曲面重建和法线增强等各种下游任务中的竞争性能得到证明。这些结果证明 StableNormal 保留了“稳定性”和“清晰度”，以进行准确的法线估计。StableNormal 代表了重新利用扩散先验进行确定性估计的婴儿尝试。为了实现这一目标，代码和模型已在 hf.co/Stable-X 公开。

##### **EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees**
2406.16858v1 by Yuhui Li, Fangyun Wei, Chao Zhang, Hongyang Zhang

Inference with modern Large Language Models (LLMs) is expensive and
time-consuming, and speculative sampling has proven to be an effective
solution. Most speculative sampling methods such as EAGLE use a static draft
tree, implicitly assuming that the acceptance rate of draft tokens depends only
on their position. Interestingly, we found that the acceptance rate of draft
tokens is also context-dependent. In this paper, building upon EAGLE, we
propose EAGLE-2, which introduces a new technique of context-aware dynamic
draft tree into drafting modeling. This improvement leverages the fact that the
draft model of EAGLE is well-calibrated: the confidence scores from the draft
model approximate acceptance rates with small errors. We conducted extensive
evaluations on three series of LLMs and six tasks, with EAGLE-2 achieving
speedup ratios 3.05x-4.26x, which is 20%-40% faster than EAGLE-1. EAGLE-2 also
ensures that the distribution of the generated text remains unchanged, making
it a lossless acceleration algorithm.

摘要：使用現代大型語言模型 (LLM) 進行推論既昂貴又耗時，而推測性抽樣已被證明是一種有效的解決方案。大多數推測性抽樣方法（例如 EAGLE）使用靜態草稿樹，隱含假設草稿令牌的接受率僅取決於它們的位置。有趣的是，我們發現草稿令牌的接受率也依賴於上下文。在本文中，我們在 EAGLE 的基礎上，提出了 EAGLE-2，它將一種新的上下文感知動態草稿樹技術引入到起草建模中。此改進利用了 EAGLE 的草稿模型校準良好的事實：草稿模型的信心分數以小誤差近似接受率。我們對三系列 LLM 和六項任務進行了廣泛的評估，EAGLE-2 的加速比為 3.05x-4.26x，比 EAGLE-1 快 20%-40%。EAGLE-2 還確保生成文本的分布保持不變，使其成為無損加速演算法。

##### **GeoMFormer: A General Architecture for Geometric Molecular Representation Learning**
2406.16853v1 by Tianlang Chen, Shengjie Luo, Di He, Shuxin Zheng, Tie-Yan Liu, Liwei Wang

Molecular modeling, a central topic in quantum mechanics, aims to accurately
calculate the properties and simulate the behaviors of molecular systems. The
molecular model is governed by physical laws, which impose geometric
constraints such as invariance and equivariance to coordinate rotation and
translation. While numerous deep learning approaches have been developed to
learn molecular representations under these constraints, most of them are built
upon heuristic and costly modules. We argue that there is a strong need for a
general and flexible framework for learning both invariant and equivariant
features. In this work, we introduce a novel Transformer-based molecular model
called GeoMFormer to achieve this goal. Using the standard Transformer modules,
two separate streams are developed to maintain and learn invariant and
equivariant representations. Carefully designed cross-attention modules bridge
the two streams, allowing information fusion and enhancing geometric modeling
in each stream. As a general and flexible architecture, we show that many
previous architectures can be viewed as special instantiations of GeoMFormer.
Extensive experiments are conducted to demonstrate the power of GeoMFormer. All
empirical results show that GeoMFormer achieves strong performance on both
invariant and equivariant tasks of different types and scales. Code and models
will be made publicly available at https://github.com/c-tl/GeoMFormer.

摘要：分子建模是量子力學中的核心主題，旨在準確計算分子系統的性質並模擬其行為。分子模型受物理定律支配，這些定律施加了幾何約束，例如不變性和等變性，以協調旋轉和平移。儘管已經開發了許多深度學習方法來學習這些約束下的分子表示，但它們大多建立在啟發式和昂貴的模組上。我們認為，迫切需要一個通用且靈活的框架來學習不變和等變特徵。在這項工作中，我們引入了一個名為 GeoMFormer 的新型基於 Transformer 的分子模型來實現這一目標。使用標準 Transformer 模組，開發了兩個獨立的流來維護和學習不變和等變表示。精心設計的交叉注意模組橋接了這兩個流，允許資訊融合並增強每個流中的幾何建模。作為一種通用且靈活的架構，我們展示了許多先前的架構可以視為 GeoMFormer 的特殊實例。進行了大量的實驗來證明 GeoMFormer 的強大功能。所有經驗結果表明，GeoMFormer 在不同類型和規模的不變和等變任務上都取得了強勁的效能。程式碼和模型將在 https://github.com/c-tl/GeoMFormer 公開。

##### **Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts**
2406.16851v1 by Aditya Sharma, Michael Saxon, William Yang Wang

We present LoCoVQA, a dynamic benchmark generator for evaluating long-context
extractive reasoning in vision language models (VLMs). LoCoVQA augments test
examples for mathematical reasoning, VQA, and character recognition tasks with
increasingly long visual contexts composed of both in-distribution and
out-of-distribution distractor images.
  Across these tasks, a diverse set of VLMs rapidly lose performance as the
visual context length grows, often exhibiting a striking exponential decay
trend. This test assesses how well VLMs can ignore irrelevant information when
answering queries -- a task that is quite easy for language models (LMs) in the
text domain -- demonstrating that current state-of-the-art VLMs lack this
essential capability for many long-context applications.

摘要：我們提出 LoCoVQA，一個用於評估視覺語言模型 (VLM) 中的長語境抽取式推理的動態基準生成器。LoCoVQA 擴充了數學推理、VQA 和字元辨識任務的測試範例，其中包含越來越長的視覺語境，由分佈內和分佈外干擾影像組成。
在這些任務中，隨著視覺語境長度的增加，各種 VLM 的效能快速下降，通常表現出顯著的指數衰減趨勢。此測試評估 VLM 在回答查詢時忽略無關資訊的能力，這項任務對於文字領域的語言模型 (LM) 來說相當容易，這表示目前的最新 VLM 缺乏許多長語境應用所需的這項基本能力。

##### **RaTEScore: A Metric for Radiology Report Generation**
2406.16845v1 by Weike Zhao, Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie

This paper introduces a novel, entity-aware metric, termed as Radiological
Report (Text) Evaluation (RaTEScore), to assess the quality of medical reports
generated by AI models. RaTEScore emphasizes crucial medical entities such as
diagnostic outcomes and anatomical details, and is robust against complex
medical synonyms and sensitive to negation expressions. Technically, we
developed a comprehensive medical NER dataset, RaTE-NER, and trained an NER
model specifically for this purpose. This model enables the decomposition of
complex radiological reports into constituent medical entities. The metric
itself is derived by comparing the similarity of entity embeddings, obtained
from a language model, based on their types and relevance to clinical
significance. Our evaluations demonstrate that RaTEScore aligns more closely
with human preference than existing metrics, validated both on established
public benchmarks and our newly proposed RaTE-Eval benchmark.

摘要：本文介紹了一種新穎的實體感知指標，稱為放射學報告（文字）評估（RaTEScore），用於評估 AI 模型產生的醫療報告品質。RaTEScore 強調重要的醫療實體，例如診斷結果和解剖細節，並且對複雜的醫療同義詞具有穩健性，且對否定表達敏感。在技術上，我們開發了一個全面的醫療 NER 資料集 RaTE-NER，並訓練了一個專門用於此目的的 NER 模型。此模型能夠將複雜的放射學報告分解成組成醫療實體。此指標本身是透過比較實體嵌入的相似性來衍生，這些嵌入是根據其類型和與臨床意義相關性，從語言模型中取得。我們的評估證明，RaTEScore 與人類偏好的一致性高於現有指標，這已在既定的公開基準和我們新提出的 RaTE-Eval 基準中得到驗證。

##### **Exploring Factual Entailment with NLI: A News Media Study**
2406.16842v1 by Guy Mor-Lan, Effi Levi

We explore the relationship between factuality and Natural Language Inference
(NLI) by introducing FactRel -- a novel annotation scheme that models
\textit{factual} rather than \textit{textual} entailment, and use it to
annotate a dataset of naturally occurring sentences from news articles. Our
analysis shows that 84\% of factually supporting pairs and 63\% of factually
undermining pairs do not amount to NLI entailment or contradiction,
respectively, suggesting that factual relationships are more apt for analyzing
media discourse. We experiment with models for pairwise classification on the
new dataset, and find that in some cases, generating synthetic data with GPT-4
on the basis of the annotated dataset can improve performance. Surprisingly,
few-shot learning with GPT-4 yields strong results on par with medium LMs
(DeBERTa) trained on the labelled dataset. We hypothesize that these results
indicate the fundamental dependence of this task on both world knowledge and
advanced reasoning abilities.

摘要：我們透過引入 FactRel 探索事實性和自然語言推論 (NLI) 之間的關係，FactRel 是一種新穎的標註方案，其建模的是「事實上」而非「文字上」的蘊涵，並使用它來標註一個由新聞文章中自然發生的句子所組成的資料集。我們的分析顯示，84% 的事實支持對和 63% 的事實破壞對並未分別構成 NLI 蘊涵或矛盾，這表示事實關係更適合用於分析媒體論述。我們對新資料集上的成對分類模型進行實驗，並發現，在某些情況下，根據標註資料集，使用 GPT-4 生成合成資料可以提升效能。令人驚訝的是，使用 GPT-4 進行小樣本學習會產生與在標籤資料集上訓練的中型 LM（DeBERTa）相當的強勁結果。我們假設這些結果表明此任務在根本上依賴於世界知識和進階推理能力。

##### **From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models**
2406.16838v1 by Sean Welleck, Amanda Bertsch, Matthew Finlayson, Hailey Schoelkopf, Alex Xie, Graham Neubig, Ilia Kulikov, Zaid Harchaoui

One of the most striking findings in modern research on large language models
(LLMs) is that scaling up compute during training leads to better results.
However, less attention has been given to the benefits of scaling compute
during inference. This survey focuses on these inference-time approaches. We
explore three areas under a unified mathematical formalism: token-level
generation algorithms, meta-generation algorithms, and efficient generation.
Token-level generation algorithms, often called decoding algorithms, operate by
sampling a single token at a time or constructing a token-level search space
and then selecting an output. These methods typically assume access to a
language model's logits, next-token distributions, or probability scores.
Meta-generation algorithms work on partial or full sequences, incorporating
domain knowledge, enabling backtracking, and integrating external information.
Efficient generation methods aim to reduce token costs and improve the speed of
generation. Our survey unifies perspectives from three research communities:
traditional natural language processing, modern LLMs, and machine learning
systems.

摘要：在大型語言模型 (LLM) 的現代研究中，最引人注目的發現之一是，訓練期間擴大運算會帶來更好的結果。然而，在推理期間擴大運算的好處卻較少受到關注。本調查重點關注這些推理時間方法。我們在一個統一的數學形式主義下探討了三個領域：符號級別生成演算法、元生成演算法和高效生成。符號級別生成演算法（通常稱為解碼演算法）通過一次抽取一個符號或建構符號級別搜尋空間，然後選擇一個輸出進行操作。這些方法通常假設可以存取語言模型的 logit、下一個符號分佈或機率分數。元生成演算法處理部分或完整序列，整合領域知識，啟用回溯，並整合外部資訊。高效生成方法旨在降低符號成本並提高生成速度。我們的調查統一了來自三個研究社群的觀點：傳統自然語言處理、現代 LLM 和機器學習系統。

##### **USDC: A Dataset of $\underline{U}$ser $\underline{S}$tance and $\underline{D}$ogmatism in Long $\underline{C}$onversations**
2406.16833v1 by Mounika Marreddy, Subba Reddy Oota, Venkata Charan Chinni, Manish Gupta, Lucie Flek

Identifying user's opinions and stances in long conversation threads on
various topics can be extremely critical for enhanced personalization, market
research, political campaigns, customer service, conflict resolution, targeted
advertising, and content moderation. Hence, training language models to
automate this task is critical. However, to train such models, gathering manual
annotations has multiple challenges: 1) It is time-consuming and costly; 2)
Conversation threads could be very long, increasing chances of noisy
annotations; and 3) Interpreting instances where a user changes their opinion
within a conversation is difficult because often such transitions are subtle
and not expressed explicitly. Inspired by the recent success of large language
models (LLMs) for complex natural language processing (NLP) tasks, we leverage
Mistral Large and GPT-4 to automate the human annotation process on the
following two tasks while also providing reasoning: i) User Stance
classification, which involves labeling a user's stance of a post in a
conversation on a five-point scale; ii) User Dogmatism classification, which
deals with labeling a user's overall opinion in the conversation on a
four-point scale. The majority voting on zero-shot, one-shot, and few-shot
annotations from these two LLMs on 764 multi-user Reddit conversations helps us
curate the USDC dataset. USDC is then used to finetune and instruction-tune
multiple deployable small language models for the 5-class stance and 4-class
dogmatism classification tasks. We make the code and dataset publicly available
[https://anonymous.4open.science/r/USDC-0F7F].

摘要：<paragraph>在各種主題的長對話串中找出使用者的意見和立場，對於加強個人化、市場研究、政治活動、客戶服務、衝突解決、目標廣告和內容審核來說至關重要。因此，訓練語言模型以自動化此任務至關重要。然而，要訓練此類模型，收集手動註解有多項挑戰：1) 耗時且成本高昂；2) 對話串可能很長，增加註解有雜訊的機率；3) 解釋使用者在對話中改變意見的實例很困難，因為通常此類轉變很微妙，且未明確表達。受到大型語言模型 (LLM) 近期在複雜自然語言處理 (NLP) 任務中成功的啟發，我們利用 Mistral Large 和 GPT-4 在以下兩個任務中自動化人工註解流程，同時也提供推理：i) 使用者立場分類，其中涉及在對話中對使用者的立場標記為五點量表；ii) 使用者教條分類，其中涉及在對話中對使用者的整體意見標記為四點量表。這兩個 LLM 在 764 個多使用者 Reddit 對話中對零次學習、一次學習和少次學習註解進行的過半數投票，有助於我們整理 USDC 資料集。然後使用 USDC 對多個可部署的小語言模型進行微調和指令調整，以進行 5 類立場和 4 類教條分類任務。我們公開程式碼和資料集 [https://anonymous.4open.science/r/USDC-0F7F]。</paragraph>

##### **Understanding and Mitigating Tokenization Bias in Language Models**
2406.16829v1 by Buu Phan, Marton Havasi, Matthew Muckley, Karen Ullrich

State-of-the-art language models are autoregressive and operate on subword
units known as tokens. Specifically, one must encode the conditioning string
into a list of tokens before passing to the language models for next-token
prediction. We show that, for encoding schemes such as maximum prefix matching,
tokenization induces a sampling bias that cannot be mitigated with more
training or data. To counter this universal problem, we propose a novel
algorithm to obtain unbiased estimates from a model that was trained on
tokenized data. Our method does not require finetuning the model, and its
complexity, defined as the number of model runs, scales linearly with the
sequence length. As a consequence, we show that one can simulate token-free
behavior from a tokenized language model. We empirically verify the correctness
of our method through a Markov-chain setup, where it accurately recovers the
transition probabilities, as opposed to the conventional method of directly
prompting tokens into the language model.

摘要：最先进的语言模型是自回归的，并且在称为标记的子词单位上运行。具体来说，在将条件字符串传递给语言模型进行下一个标记预测之前，必须将其编码为标记列表。我们表明，对于最大前缀匹配等编码方案，标记化会引起采样偏差，而无法通过更多训练或数据来缓解。为了解决这个普遍问题，我们提出了一种新算法，以从在标记化数据上训练的模型中获得无偏估计。我们的方法不需要微调模型，其复杂性（定义为模型运行次数）与序列长度线性缩放。因此，我们表明可以从标记化语言模型模拟无标记行为。我们通过马尔可夫链设置经验验证了我们方法的正确性，在该设置中，它准确地恢复了转移概率，而不是直接将标记提示到语言模型中的传统方法。

##### **Ragnarök: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track**
2406.16828v1 by Ronak Pradeep, Nandan Thakur, Sahel Sharifymoghaddam, Eric Zhang, Ryan Nguyen, Daniel Campos, Nick Craswell, Jimmy Lin

Did you try out the new Bing Search? Or maybe you fiddled around with Google
AI~Overviews? These might sound familiar because the modern-day search stack
has recently evolved to include retrieval-augmented generation (RAG) systems.
They allow searching and incorporating real-time data into large language
models (LLMs) to provide a well-informed, attributed, concise summary in
contrast to the traditional search paradigm that relies on displaying a ranked
list of documents. Therefore, given these recent advancements, it is crucial to
have an arena to build, test, visualize, and systematically evaluate RAG-based
search systems. With this in mind, we propose the TREC 2024 RAG Track to foster
innovation in evaluating RAG systems. In our work, we lay out the steps we've
made towards making this track a reality -- we describe the details of our
reusable framework, Ragnar\"ok, explain the curation of the new MS MARCO V2.1
collection choice, release the development topics for the track, and
standardize the I/O definitions which assist the end user. Next, using
Ragnar\"ok, we identify and provide key industrial baselines such as OpenAI's
GPT-4o or Cohere's Command R+. Further, we introduce a web-based user interface
for an interactive arena allowing benchmarking pairwise RAG systems by
crowdsourcing. We open-source our Ragnar\"ok framework and baselines to achieve
a unified standard for future RAG systems.

摘要：<paragraph>您試用過新的 Bing 搜尋嗎？或者您可能使用過 Google AI~概覽？這些聽起來可能很熟悉，因為現代搜尋堆疊最近已演進到包含檢索增強生成 (RAG) 系統。它們允許搜尋並將即時資料納入大型語言模型 (LLM)，以提供充分資訊、有依據、簡潔的摘要，這與依賴顯示文件排名清單的傳統搜尋模式形成對比。因此，鑑於這些最近的進展，建立一個用於建置、測試、視覺化和系統性評估基於 RAG 的搜尋系統的領域至關重要。有鑑於此，我們提議 TREC 2024 RAG 軌道來促進評估 RAG 系統的創新。在我們的研究中，我們概述了我們為讓此軌道成為現實而採取的步驟——我們描述了我們的可重複使用框架 Ragnar\"ok 的詳細資訊，說明新 MS MARCO V2.1 蒐集選擇的策展，釋出此軌道的開發主題，並標準化有助於最終使用者的 I/O 定義。接下來，使用 Ragnar\"ok，我們識別並提供關鍵產業基準，例如 OpenAI 的 GPT-4o 或 Cohere 的 Command R+。此外，我們為互動式領域引進一個基於網路的使用者介面，允許透過群眾外包對成對的 RAG 系統進行基準測試。我們開放原始碼的 Ragnar\"ok 框架和基準，以達成未來 RAG 系統的統一標準。</paragraph>

##### **General Binding Affinity Guidance for Diffusion Models in Structure-Based Drug Design**
2406.16821v1 by Yue Jian, Curtis Wu, Danny Reidenbach, Aditi S. Krishnapriyan

Structure-Based Drug Design (SBDD) focuses on generating valid ligands that
strongly and specifically bind to a designated protein pocket. Several methods
use machine learning for SBDD to generate these ligands in 3D space,
conditioned on the structure of a desired protein pocket. Recently, diffusion
models have shown success here by modeling the underlying distributions of
atomic positions and types. While these methods are effective in considering
the structural details of the protein pocket, they often fail to explicitly
consider the binding affinity. Binding affinity characterizes how tightly the
ligand binds to the protein pocket, and is measured by the change in free
energy associated with the binding process. It is one of the most crucial
metrics for benchmarking the effectiveness of the interaction between a ligand
and protein pocket. To address this, we propose BADGER: Binding Affinity
Diffusion Guidance with Enhanced Refinement. BADGER is a general guidance
method to steer the diffusion sampling process towards improved protein-ligand
binding, allowing us to adjust the distribution of the binding affinity between
ligands and proteins. Our method is enabled by using a neural network (NN) to
model the energy function, which is commonly approximated by AutoDock Vina
(ADV). ADV's energy function is non-differentiable, and estimates the affinity
based on the interactions between a ligand and target protein receptor. By
using a NN as a differentiable energy function proxy, we utilize the gradient
of our learned energy function as a guidance method on top of any trained
diffusion model. We show that our method improves the binding affinity of
generated ligands to their protein receptors by up to 60\%, significantly
surpassing previous machine learning methods. We also show that our guidance
method is flexible and can be easily applied to other diffusion-based SBDD
frameworks.

摘要：<paragraph>基於結構的藥物設計 (SBDD) 專注於產生有效配體，這些配體能牢固且專一地結合至指定蛋白質口袋。多種方法使用機器學習進行 SBDD，以在 3D 空間中產生這些配體，並以所需蛋白質口袋的結構為條件。最近，擴散模型透過模擬原子位置和類型的基礎分佈，在此領域展現出成功。儘管這些方法在考量蛋白質口袋的結構細節方面很有效，但它們通常無法明確考量結合親和力。結合親和力描述配體與蛋白質口袋結合的緊密程度，並由結合過程中相關的自由能變化來衡量。這是評量配體與蛋白質口袋交互作用效果最關鍵的指標之一。為了解決此問題，我們提出 BADGER：結合親和力擴散引導與增強精煉。BADGER 是一項通用引導方法，用於引導擴散抽樣程序以改善蛋白質配體結合，讓我們能調整配體與蛋白質之間結合親和力的分佈。我們的技術利用神經網路 (NN) 來模擬能量函數，而這通常由 AutoDock Vina (ADV) 近似。ADV 的能量函數是不可微分的，並根據配體與目標蛋白質受體之間的交互作用來估計親和力。透過將 NN 用作可微分的能量函數代理，我們將所學習能量函數的梯度用作任何訓練過擴散模型的引導方法。我們展示了我們的技術將產生配體與其蛋白質受體的結合親和力提升了 60%，大幅超越先前的機器學習方法。我們也展示了我們的引導方法很靈活，且能輕鬆應用於其他基於擴散的 SBDD 架構。</paragraph>

##### **PISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs**
2406.16810v1 by Xinchi Qiu, William F. Shen, Yihong Chen, Nicola Cancedda, Pontus Stenetorp, Nicholas D. Lane

Recently, machine unlearning, which seeks to erase specific data stored in
the pre-trained or fine-tuned models, has emerged as a crucial protective
measure for LLMs. However, unlearning approaches for LLMs that have been
considered thus far have focused on the removal of independent data points and
have not taken into account that the stored facts are logically connected to
one another and form an implicit knowledge graph. To facilitate the development
of structural unlearning methods, which are essential for the practical
application of unlearning, we propose PISTOL, a pipeline for compiling
multi-scenario datasets for benchmarking structural LLM unlearning.
Additionally, leveraging sample datasets synthesized using PISTOL, we conducted
benchmarks with four distinct unlearning methods on both Llama2-7B and
Mistral-7B models. This analysis helps to illustrate the prevailing challenges
in effectively and robustly removing highly inter-connected data, batched data,
or data skewed towards a specific domain. It also highlights the choice of
pre-trained model can impact unlearning performance. This work not only
advances our understandings on the limitation of current LLMs unlearning
methods and proposes future research directions, but also provides a replicable
framework for ongoing exploration and validation in the field.

摘要：最近，机器去学习（unlearning）已成为大型语言模型 (LLM) 的一项关键保护措施，它旨在消除预先训练或微调模型中存储的特定数据。然而，迄今为止考虑的 LLM 去学习方法都专注于删除独立数据点，并未考虑到存储的事实彼此之间在逻辑上是相连的，并形成了一个隐式知识图。为了促进结构化去学习方法的发展（这对于去学习的实际应用至关重要），我们提出了 PISTOL，这是一个用于编译多场景数据集以对结构化 LLM 去学习进行基准测试的管道。此外，利用使用 PISTOL 合成的样本数据集，我们对 Llama2-7B 和 Mistral-7B 模型进行了四种不同的去学习方法的基准测试。此分析有助于说明在有效且稳健地删除高度互连的数据、批处理数据或偏向特定领域的的数据方面存在的普遍挑战。它还强调了预训练模型的选择会影响去学习性能。这项工作不仅促进了我们对当前 LLM 去学习方法的局限性的理解，并提出了未来的研究方向，还为该领域的持续探索和验证提供了一个可复制的框架。

##### **Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback for Text-to-Image Generation**
2406.16807v1 by Katherine M. Collins, Najoung Kim, Yonatan Bitton, Verena Rieser, Shayegan Omidshafiei, Yushi Hu, Sherol Chen, Senjuti Dutta, Minsuk Chang, Kimin Lee, Youwei Liang, Georgina Evans, Sahil Singla, Gang Li, Adrian Weller, Junfeng He, Deepak Ramachandran, Krishnamurthy Dj Dvijotham

Human feedback plays a critical role in learning and refining reward models
for text-to-image generation, but the optimal form the feedback should take for
learning an accurate reward function has not been conclusively established.
This paper investigates the effectiveness of fine-grained feedback which
captures nuanced distinctions in image quality and prompt-alignment, compared
to traditional coarse-grained feedback (for example, thumbs up/down or ranking
between a set of options). While fine-grained feedback holds promise,
particularly for systems catering to diverse societal preferences, we show that
demonstrating its superiority to coarse-grained feedback is not automatic.
Through experiments on real and synthetic preference data, we surface the
complexities of building effective models due to the interplay of model choice,
feedback type, and the alignment between human judgment and computational
interpretation. We identify key challenges in eliciting and utilizing
fine-grained feedback, prompting a reassessment of its assumed benefits and
practicality. Our findings -- e.g., that fine-grained feedback can lead to
worse models for a fixed budget, in some settings; however, in controlled
settings with known attributes, fine grained rewards can indeed be more helpful
-- call for careful consideration of feedback attributes and potentially beckon
novel modeling approaches to appropriately unlock the potential value of
fine-grained feedback in-the-wild.

摘要：人類回饋在學習及精進文字轉圖片生成獎勵模型中扮演著關鍵角色，但回饋應採取何種最佳形式以學習準確的獎勵函數尚未有定論。本文探討細緻回饋的有效性，此回饋捕捉到影像品質與提示比對的細微差異，並將其與傳統的粗略回饋（例如，按讚/按倒讚或在選項中進行排名）進行比較。儘管細緻回饋具有前景，特別是對於迎合多元社會偏好的系統，但我們表明，證明其優於粗略回饋並非自動化。透過對真實和合成偏好資料進行實驗，我們了解到由於模型選擇、回饋類型以及人類判斷與計算詮釋之間的交互作用，建立有效模型的複雜性。我們找出引發和利用細緻回饋的主要挑戰，促使重新評估其假設的好處和實用性。我們的發現（例如，在某些設定下，細緻回饋可能會導致固定預算的模型更糟；然而，在具有已知屬性的受控設定下，細緻獎勵確實可能更有幫助）呼籲仔細考量回饋屬性，並可能招致新的建模方法，以適當地解鎖野外細緻回饋的潛在價值。

##### **RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale**
2406.16801v1 by Beck LaBash, August Rosedale, Alex Reents, Colin Wiel

The instruction-following ability of Large Language Models (LLMs) has
cultivated a class of LLM-based systems capable of approaching complex tasks
such as making edits to large code repositories. Due to the high sensitivity
and unpredictability of LLM behavior in response to changes in prompting,
robust evaluation tools are needed to drive future iteration of these systems.
We propose RES-Q, a natural language instruction-based benchmark for evaluating
$\textbf{R}$epository $\textbf{E}$diting $\textbf{S}$ystems, which consists of
100 repository editing tasks derived from real GitHub commits. Given an edit
instruction and a code repository, RES-Q evaluates an LLM system's ability to
gather information and construct an edit that satisfies the criteria set by the
instruction. We argue that evaluating LLMs in this way addresses issues with
traditional benchmarks and provides a more holistic assessment of a model's
abilities. We evaluate various state-of-the-art LLMs as language agents in a
repository-editing system built on Qurrent OS, our language agent development
software. Despite their 1% pass@1 performance difference on HumanEval, we find
Claude Sonnet 3.5 outperforms GPT-4o by 12% pass@1 on RES-Q, indicating RES-Q's
capacity to differentiate model capability as traditional benchmarks approach
saturation. We further investigate token efficiency, performance relationships
with existing benchmarks, and interesting disparities between closed and
open-source LLMs. Code and dataset are available at
https://github.com/Qurrent-AI/RES-Q.

摘要：大型語言模型 (LLM) 的指令遵循能力培養了一類基於 LLM 的系統，能夠處理複雜的任務，例如對大型程式碼儲存庫進行編輯。由於 LLM 行為在回應提示變更時的敏感性和不可預測性，因此需要強健的評估工具來推動這些系統的未來迭代。我們提出了 RES-Q，一個基於自然語言指令的基準，用於評估$\textbf{R}$epository $\textbf{E}$diting $\textbf{S}$ystems，其中包含 100 個源自真實 GitHub 提交的儲存庫編輯任務。給定編輯指令和程式碼儲存庫，RES-Q 評估 LLM 系統收集資訊和建構編輯的能力，以滿足指令設定的準則。我們認為，以這種方式評估 LLM 可以解決傳統基準的問題，並提供對模型能力更全面的評估。我們評估各種最先進的 LLM，作為建置在 Qurrent OS 上的儲存庫編輯系統中的語言代理，Qurrent OS 是我們的語言代理開發軟體。儘管它們在 HumanEval 上的 pass@1 效能差異為 1%，但我們發現 Claude Sonnet 3.5 在 RES-Q 上的 pass@1 效能比 GPT-4o 高出 12%，這表示 RES-Q 有能力區分模型能力，因為傳統基準接近飽和。我們進一步探討了代幣效率、與現有基準的效能關係，以及封閉和開放原始碼 LLM 之間的有趣差異。程式碼和資料集可在 https://github.com/Qurrent-AI/RES-Q 取得。

##### **Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs**
2406.16797v2 by Ashwinee Panda, Berivan Isik, Xiangyu Qi, Sanmi Koyejo, Tsachy Weissman, Prateek Mittal

Existing methods for adapting large language models (LLMs) to new tasks are
not suited to multi-task adaptation because they modify all the model weights
-- causing destructive interference between tasks. The resulting effects, such
as catastrophic forgetting of earlier tasks, make it challenging to obtain good
performance on multiple tasks at the same time. To mitigate this, we propose
Lottery Ticket Adaptation (LoTA), a sparse adaptation method that identifies
and optimizes only a sparse subnetwork of the model. We evaluate LoTA on a wide
range of challenging tasks such as instruction following, reasoning, math, and
summarization. LoTA obtains better performance than full fine-tuning and
low-rank adaptation (LoRA), and maintains good performance even after training
on other tasks -- thus, avoiding catastrophic forgetting. By extracting and
fine-tuning over lottery tickets (or sparse task vectors), LoTA also enables
model merging over highly dissimilar tasks. Our code is made publicly available
at https://github.com/kiddyboots216/lottery-ticket-adaptation.

摘要：現有適應大型語言模型 (LLM) 到新任務的方法不適合於多任務適應，因為它們會修改所有模型權重，導致任務之間產生破壞性干擾。由此產生的影響（例如災難性地遺忘較早的任務）使得同時在多個任務上獲得良好效能變得具有挑戰性。為了減輕這種情況，我們提出樂透適應 (LoTA)，這是一種稀疏適應方法，僅識別和最佳化模型的稀疏子網路。我們在廣泛的具挑戰性任務上評估 LoTA，例如指令遵循、推理、數學和摘要。LoTA 獲得比完全微調和低秩適應 (LoRA) 更好的效能，即使在訓練其他任務後也能維持良好的效能，從而避免災難性遺忘。透過萃取和微調樂透券（或稀疏任務向量），LoTA 也能讓模型合併在高度相異的任務上。我們的程式碼已公開在 https://github.com/kiddyboots216/lottery-ticket-adaptation。

##### **Adam-mini: Use Fewer Learning Rates To Gain More**
2406.16793v1 by Yushun Zhang, Congliang Chen, Ziniu Li, Tian Ding, Chenwei Wu, Yinyu Ye, Zhi-Quan Luo, Ruoyu Sun

We propose Adam-mini, an optimizer that achieves on-par or better performance
than AdamW with 45% to 50% less memory footprint. Adam-mini reduces memory by
cutting down the number of learning rates in Adam: Instead of assigning an
individual learning rate for each parameter using $1/\sqrt{v}$, Adam-mini uses
the average of $v$ within a pre-defined parameter block as the learning rate
for that block. Such a design is inspired by two empirical findings. First, the
Hessian of Transformers exhibits a near-block diagonal structure with different
sizes of dense sub-blocks. Second, for each of these dense sub-blocks, there
exists a single high-quality learning rate that can outperform Adam, provided
that sufficient resources are available to search it out. Adam-mini provides
one cost-effective way to find these good learning rates and manage to cut down
$\geq 90% v$ in Adam. Empirically, we verify that Adam-mini performs on par or
better than AdamW on various language models sized from 125M to 7B for
pre-training, supervised fine-tuning, and RLHF. The reduced memory footprint of
Adam-mini also alleviates communication overheads among GPUs and CPUs, thereby
increasing throughput. For instance, Adam-mini achieves 49.6% higher throughput
than AdamW when pre-training Llama2-7B on 2x A800-80GB GPUs, which saves 33%
wall-clock time for pre-training.

摘要：我們提出 Adam-mini，這是一種優化器，其效能與 AdamW 相當或更好，但記憶體佔用量減少 45% 到 50%。Adam-mini 透過減少 Adam 中的學習率數量來減少記憶體：Adam-mini 不使用 $1/\sqrt{v}$ 為每個參數指定個別學習率，而是使用預先定義的參數區塊內的 $v$ 平均值作為該區塊的學習率。這種設計的靈感來自兩個經驗發現。首先，Transformers 的 Hessian 呈現出近似區塊對角結構，具有不同大小的密集子區塊。其次，對於這些密集子區塊中的每一個，都存在一個單一的優質學習率，只要有足夠的資源來搜尋它，它就能優於 Adam。Adam-mini 提供了一種經濟有效的方法來找到這些良好的學習率，並設法在 Adam 中減少 $\geq 90% v$。根據經驗，我們驗證了 Adam-mini 在各種語言模型上的效能與 AdamW 相當或更好，這些語言模型的大小從 125M 到 7B，用於預訓練、監督微調和 RLHF。Adam-mini 減少的記憶體佔用量也減輕了 GPU 和 CPU 之間的通訊負擔，從而增加了處理量。例如，在 2x A800-80GB GPU 上預訓練 Llama2-7B 時，Adam-mini 的處理量比 AdamW 高出 49.6%，這為預訓練節省了 33% 的實際時間。

##### **The Progression of Transformers from Language to Vision to MOT: A Literature Review on Multi-Object Tracking with Transformers**
2406.16784v1 by Abhi Kamboj

The transformer neural network architecture allows for autoregressive
sequence-to-sequence modeling through the use of attention layers. It was
originally created with the application of machine translation but has
revolutionized natural language processing. Recently, transformers have also
been applied across a wide variety of pattern recognition tasks, particularly
in computer vision. In this literature review, we describe major advances in
computer vision utilizing transformers. We then focus specifically on
Multi-Object Tracking (MOT) and discuss how transformers are increasingly
becoming competitive in state-of-the-art MOT works, yet still lag behind
traditional deep learning methods.

摘要：Transformer神經網路架構允許透過使用注意力層進行自迴歸序列對序列建模。它最初是為了機器翻譯應用而創建，但已經徹底改變了自然語言處理。最近，Transformer也已應用於各種模式辨識任務，特別是在電腦視覺中。在這個文獻回顧中，我們描述了利用Transformer在電腦視覺中的重大進展。然後，我們特別關注多目標追蹤 (MOT)，並討論Transformer如何越來越具有競爭力，成為最先進的 MOT 作品，但仍落後於傳統的深度學習方法。

##### **M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models**
2406.16783v1 by Rishabh Maheshwary, Vikas Yadav, Hoang Nguyen, Khyati Mahajan, Sathwik Tejaswi Madhusudhan

Instruction finetuning (IFT) is critical for aligning Large Language Models
(LLMs) to follow instructions. Numerous effective IFT datasets have been
proposed in the recent past, but most focus on high resource languages such as
English. In this work, we propose a fully synthetic, novel taxonomy (Evol)
guided Multilingual, Multi-turn instruction finetuning dataset, called
M2Lingual, to better align LLMs on a diverse set of languages and tasks.
M2Lingual contains a total of 182K IFT pairs that are built upon diverse seeds,
covering 70 languages, 17 NLP tasks and general instruction-response pairs.
LLMs finetuned with M2Lingual substantially outperform the majority of existing
multilingual IFT datasets. Importantly, LLMs trained with M2Lingual
consistently achieve competitive results across a wide variety of evaluation
benchmarks compared to existing multilingual IFT datasets. Specifically, LLMs
finetuned with M2Lingual achieve strong performance on our translated
multilingual, multi-turn evaluation benchmark as well as a wide variety of
multilingual tasks. Thus we contribute, and the 2 step Evol taxonomy used for
its creation. M2Lingual repository -
https://huggingface.co/datasets/ServiceNow-AI/M2Lingual

摘要：指令微調 (IFT) 對於讓大型語言模型 (LLM) 遵循指令至關重要。最近已提出許多有效的 IFT 資料集，但大多數都專注於英語等高資源語言。在這項工作中，我們提出一個完全合成、新穎的分類法 (Evol) 指導的多語言、多輪指令微調資料集，稱為 M2Lingual，以在各種語言和任務上更好地對齊 LLM。M2Lingual 總共包含 182K 個 IFT 對，這些對建立在不同的種子上，涵蓋 70 種語言、17 個 NLP 任務和一般指令回應對。使用 M2Lingual 微調的 LLM 大大優於現有的多語言 IFT 資料集。重要的是，使用 M2Lingual 訓練的 LLM 在各種評估基準上與現有的多語言 IFT 資料集相比，始終能取得有競爭力的結果。具體來說，使用 M2Lingual 微調的 LLM 在我們的翻譯多語言、多輪評估基準以及各種多語言任務上都取得了強勁的表現。因此，我們貢獻了 M2Lingual 資料集，以及用於建立它的 2 步驟 Evol 分類法。M2Lingual 存放庫 -
https://huggingface.co/datasets/ServiceNow-AI/M2Lingual

##### **It Is Not About What You Say, It Is About How You Say It: A Surprisingly Simple Approach for Improving Reading Comprehension**
2406.16779v1 by Sagi Shaier, Lawrence E Hunter, Katharina von der Wense

Natural language processing has seen rapid progress over the past decade. Due
to the speed of developments, some practices get established without proper
evaluation. Considering one such case and focusing on reading comprehension, we
ask our first research question: 1) How does the order of inputs -- i.e.,
question and context -- affect model performance? Additionally, given recent
advancements in input emphasis, we ask a second research question: 2) Does
emphasizing either the question, the context, or both enhance performance?
Experimenting with 9 large language models across 3 datasets, we find that
presenting the context before the question improves model performance, with an
accuracy increase of up to $31\%$. Furthermore, emphasizing the context yields
superior results compared to question emphasis, and in general, emphasizing
parts of the input is particularly effective for addressing questions that
models lack the parametric knowledge to answer. Experimenting with both
prompt-based and attention-based emphasis methods, we additionally find that
the best method is surprisingly simple: it only requires concatenating a few
tokens to the input and results in an accuracy improvement of up to $36\%$,
allowing smaller models to outperform their significantly larger counterparts.

摘要：自然語言處理在過去十年中取得了快速進展。由於發展速度，一些做法在沒有適當評估的情況下就已建立。考慮到這樣一個案例並專注於閱讀理解，我們提出第一個研究問題：1) 輸入的順序——即問題和上下文——如何影響模型效能？此外，鑑於輸入強調的最新進展，我們提出第二個研究問題：2) 強調問題、上下文或兩者是否會增強效能？在 3 個資料集上對 9 個大型語言模型進行實驗，我們發現先呈現上下文再呈現問題會改善模型效能，準確度提高達 31%。此外，與強調問題相比，強調上下文會產生更好的結果，而且一般來說，強調輸入的部分對於解決模型缺乏參數知識來回答的問題特別有效。同時對基於提示和基於注意力的強調方法進行實驗，我們另外發現最好的方法出奇地簡單：它只需要將幾個代幣連結到輸入，就能將準確度提高達 36%，讓較小的模型優於顯著更大的模型。

##### **Finding Transformer Circuits with Edge Pruning**
2406.16778v1 by Adithya Bhaskar, Alexander Wettig, Dan Friedman, Danqi Chen

The path to interpreting a language model often proceeds via analysis of
circuits -- sparse computational subgraphs of the model that capture specific
aspects of its behavior. Recent work has automated the task of discovering
circuits. Yet, these methods have practical limitations, as they rely either on
inefficient search algorithms or inaccurate approximations. In this paper, we
frame automated circuit discovery as an optimization problem and propose *Edge
Pruning* as an effective and scalable solution. Edge Pruning leverages
gradient-based pruning techniques, but instead of removing neurons or
components, it prunes the \emph{edges} between components. Our method finds
circuits in GPT-2 that use less than half the number of edges compared to
circuits found by previous methods while being equally faithful to the full
model predictions on standard circuit-finding tasks. Edge Pruning is efficient
even with as many as 100K examples, outperforming previous methods in speed and
producing substantially better circuits. It also perfectly recovers the
ground-truth circuits in two models compiled with Tracr. Thanks to its
efficiency, we scale Edge Pruning to CodeLlama-13B, a model over 100x the scale
that prior methods operate on. We use this setting for a case study comparing
the mechanisms behind instruction prompting and in-context learning. We find
two circuits with more than 99.96% sparsity that match the performance of the
full model and reveal that the mechanisms in the two settings overlap
substantially. Our case study shows that Edge Pruning is a practical and
scalable tool for interpretability and sheds light on behaviors that only
emerge in large models.

摘要：<paragraph>詮釋語言模型的路徑通常會透過電路分析進行，電路是模型的稀疏計算子圖，用來擷取其行為的特定面向。最近的研究已自動化電路發現的任務。然而，這些方法有實際限制，因為它們依賴低效率的搜尋演算法或不準確的近似值。在本文中，我們將自動化電路發現建構為一個最佳化問題，並提出 *邊緣修剪* 作為一個有效且可擴充的解決方案。邊緣修剪利用基於梯度的修剪技術，但它並非移除神經元或元件，而是修剪元件之間的 *邊緣*。我們的模型在 GPT-2 中找到電路，與先前方法找到的電路相比，使用的邊緣數量少於一半，同時對標準電路尋找任務的完整模型預測同樣忠實。即使範例多達 100K，邊緣修剪仍然有效率，在速度上優於先前的模型，並產生大幅更好的電路。它也能完美還原 Tracr 編譯的兩個模型中的真實電路。由於其效率，我們將邊緣修剪擴充到 CodeLlama-13B，一個規模比先前方法操作的模型大 100 倍以上的模型。我們使用這個設定進行案例研究，比較指令提示和情境學習背後的機制。我們找到兩個稀疏度超過 99.96% 的電路，它們與完整模型的效能相符，並揭示這兩個設定中的機制有大幅重疊。我們的案例研究顯示，邊緣修剪是一個實用且可擴充的詮釋工具，並闡明僅出現在大型模型中的行為。</paragraph>

##### **Blending LLMs into Cascaded Speech Translation: KIT's Offline Speech Translation System for IWSLT 2024**
2406.16777v1 by Sai Koneru, Thai-Binh Nguyen, Ngoc-Quan Pham, Danni Liu, Zhaolin Li, Alexander Waibel, Jan Niehues

Large Language Models (LLMs) are currently under exploration for various
tasks, including Automatic Speech Recognition (ASR), Machine Translation (MT),
and even End-to-End Speech Translation (ST). In this paper, we present KIT's
offline submission in the constrained + LLM track by incorporating recently
proposed techniques that can be added to any cascaded speech translation.
Specifically, we integrate
Mistral-7B\footnote{mistralai/Mistral-7B-Instruct-v0.1} into our system to
enhance it in two ways. Firstly, we refine the ASR outputs by utilizing the
N-best lists generated by our system and fine-tuning the LLM to predict the
transcript accurately. Secondly, we refine the MT outputs at the document level
by fine-tuning the LLM, leveraging both ASR and MT predictions to improve
translation quality. We find that integrating the LLM into the ASR and MT
systems results in an absolute improvement of $0.3\%$ in Word Error Rate and
$0.65\%$ in COMET for tst2019 test set. In challenging test sets with
overlapping speakers and background noise, we find that integrating LLM is not
beneficial due to poor ASR performance. Here, we use ASR with chunked long-form
decoding to improve context usage that may be unavailable when transcribing
with Voice Activity Detection segmentation alone.

摘要：大型語言模型 (LLM) 目前正在探索各種任務，包括自動語音辨識 (ASR)、機器翻譯 (MT)，甚至端到端語音翻譯 (ST)。在本文中，我們展示了 KIT 在受限 + LLM 軌道中的離線提交，方法是採用最近提出的技術，這些技術可以新增至任何串聯語音翻譯。具體而言，我們將 Mistral-7B\footnote{mistralai/Mistral-7B-Instruct-v0.1} 整合到我們的系統中，以兩種方式增強它。首先，我們利用系統產生的 N-best 清單，並微調 LLM 以準確預測轉錄，從而改善 ASR 輸出。其次，我們透過微調 LLM，同時利用 ASR 和 MT 預測來改善翻譯品質，從而改善文件層級的 MT 輸出。我們發現將 LLM 整合到 ASR 和 MT 系統中，會讓 tst2019 測試集的字元錯誤率絕對改善 $0.3\%$，COMET 改善 $0.65\%$。在有重疊說話者和背景噪音的具挑戰性測試集中，我們發現由於 ASR 效能不佳，整合 LLM 並沒有幫助。在此，我們使用分塊長格式解碼的 ASR 來改善可能在單獨使用語音活動偵測分段進行轉錄時無法使用的內容使用。

##### **OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?**
2406.16772v1 by Zhen Huang, Zengzhi Wang, Shijie Xia, Pengfei Liu

In this report, we pose the following question: Who is the most intelligent
AI model to date, as measured by the OlympicArena (an Olympic-level,
multi-discipline, multi-modal benchmark for superintelligent AI)? We
specifically focus on the most recently released models: Claude-3.5-Sonnet,
Gemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic
medal Table approach to rank AI models based on their comprehensive performance
across various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet
shows highly competitive overall performance over GPT-4o, even surpassing
GPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)
Gemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and
Claude-3.5-Sonnet, but with a clear performance gap between them. (3) The
performance of AI models from the open-source community significantly lags
behind these proprietary models. (4) The performance of these models on this
benchmark has been less than satisfactory, indicating that we still have a long
way to go before achieving superintelligence. We remain committed to
continuously tracking and evaluating the performance of the latest powerful
models on this benchmark (available at
https://github.com/GAIR-NLP/OlympicArena).

摘要：<paragraph>在本文中，我們提出以下問題：根據 OlympicArena（一個奧林匹克等級、多學科、多模態的超智慧 AI 基準）的衡量標準，截至目前為止，哪個 AI 模型最具智慧？我們特別關注最新發布的模型：Claude-3.5-Sonnet、Gemini-1.5-Pro 和 GPT-4o。我們首次提出使用奧林匹克獎牌榜方法，根據 AI 模型在各個學科的綜合表現對其進行排名。實證結果顯示：(1) Claude-3.5-Sonnet 在整體表現上極具競爭力，優於 GPT-4o，甚至在某些科目（例如物理、化學和生物）上超越了 GPT-4o。(2) Gemini-1.5-Pro 和 GPT-4V 僅次於 GPT-4o 和 Claude-3.5-Sonnet，排名緊隨其後，但兩者之間存在明顯的效能差距。(3) 開源社群的 AI 模型表現遠遠落後於這些專有模型。(4) 這些模型在這個基準上的表現並不令人滿意，這表明在實現超智慧之前，我們還有很長的路要走。我們將持續追蹤和評估此基準上最新強大模型的表現（可於 https://github.com/GAIR-NLP/OlympicArena 取得）。</paragraph>

##### **WARP: On the Benefits of Weight Averaged Rewarded Policies**
2406.16768v1 by Alexandre Ramé, Johan Ferret, Nino Vieillard, Robert Dadashi, Léonard Hussenot, Pierre-Louis Cedoz, Pier Giuseppe Sessa, Sertan Girgin, Arthur Douillard, Olivier Bachem

Reinforcement learning from human feedback (RLHF) aligns large language
models (LLMs) by encouraging their generations to have high rewards, using a
reward model trained on human preferences. To prevent the forgetting of
pre-trained knowledge, RLHF usually incorporates a KL regularization; this
forces the policy to remain close to its supervised fine-tuned initialization,
though it hinders the reward optimization. To tackle the trade-off between KL
and reward, in this paper we introduce a novel alignment strategy named Weight
Averaged Rewarded Policies (WARP). WARP merges policies in the weight space at
three distinct stages. First, it uses the exponential moving average of the
policy as a dynamic anchor in the KL regularization. Second, it applies
spherical interpolation to merge independently fine-tuned policies into a new
enhanced one. Third, it linearly interpolates between this merged model and the
initialization, to recover features from pre-training. This procedure is then
applied iteratively, with each iteration's final model used as an advanced
initialization for the next, progressively refining the KL-reward Pareto front,
achieving superior rewards at fixed KL. Experiments with GEMMA policies
validate that WARP improves their quality and alignment, outperforming other
open-source LLMs.

摘要：透過人類回饋的強化學習 (RLHF) 會讓大型語言模型 (LLM) 與人類偏好上訓練出的獎勵模型對齊，鼓勵它們產生高獎勵。為了防止遺忘預先訓練的知識，RLHF 通常會結合 KL 正規化；這會強迫策略貼近其監督微調的初始化，儘管這會阻礙獎勵最佳化。為了處理 KL 與獎勵之間的取捨，我們在本文中引入了一種名為權重平均獎勵策略 (WARP) 的新對齊策略。WARP 在三個不同的階段合併權重空間中的策略。首先，它使用策略的指數移動平均作為 KL 正規化中的動態錨點。其次，它應用球面插值將獨立微調的策略合併成一個新的增強策略。第三，它在這個合併模型和初始化之間進行線性插值，以從預訓練中恢復特徵。然後反覆套用此程序，每次迭代的最終模型都用作下一次的高級初始化，逐步優化 KL-獎勵帕累托前緣，在固定的 KL 中獲得更高的獎勵。使用 GEMMA 策略的實驗驗證了 WARP 改善了它們的品質和對齊，優於其他開源 LLM。

##### **The GPT-WritingPrompts Dataset: A Comparative Analysis of Character Portrayal in Short Stories**
2406.16767v1 by Xi Yu Huang, Krishnapriya Vishnubhotla, Frank Rudzicz

The improved generative capabilities of large language models have made them
a powerful tool for creative writing and storytelling. It is therefore
important to quantitatively understand the nature of generated stories, and how
they differ from human storytelling. We augment the Reddit WritingPrompts
dataset with short stories generated by GPT-3.5, given the same prompts. We
quantify and compare the emotional and descriptive features of storytelling
from both generative processes, human and machine, along a set of six
dimensions. We find that generated stories differ significantly from human
stories along all six dimensions, and that human and machine generations
display similar biases when grouped according to the narrative point-of-view
and gender of the main protagonist. We release our dataset and code at
https://github.com/KristinHuangg/gpt-writing-prompts.

摘要：大型語言模型生成能力的提升，讓它們成為創作寫作和說故事的有力工具。因此，定量了解生成故事的本質，以及它們與人類說故事的不同之處，非常重要。我們使用 GPT-3.5 生成的短篇故事，擴充了 Reddit WritingPrompts 資料集，並給予相同的提示。我們量化並比較了來自生成過程（人類和機器）的情感和描述性說故事特徵，並沿著六個面向進行比較。我們發現，生成的故事在所有六個面向都與人類的故事有顯著差異，並且當根據敘事觀點和主要角色的性別進行分組時，人類和機器產生的故事會展現出類似的偏見。我們在 https://github.com/KristinHuangg/gpt-writing-prompts 釋出我們的資料集和程式碼。

##### **Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters**
2406.16758v1 by Euiin Yi, Taehyeon Kim, Hongseok Jeung, Du-Seong Chang, Se-Young Yun

Large language models (LLMs) have revolutionized natural language processing
and broadened their applicability across diverse commercial applications.
However, the deployment of these models is constrained by high inference time
in multilingual settings. To mitigate this challenge, this paper explores a
training recipe of an assistant model in speculative decoding, which are
leveraged to draft and-then its future tokens are verified by the target LLM.
We show that language-specific draft models, optimized through a targeted
pretrain-and-finetune strategy, substantially brings a speedup of inference
time compared to the previous methods. We validate these models across various
languages in inference time, out-of-domain speedup, and GPT-4o evaluation.

摘要：大型語言模型 (LLM) 已徹底改變自然語言處理，並擴大其在各種商業應用中的適用性。然而，這些模型的部署受到多語言環境中高推理時間的限制。為了緩解這一挑戰，本文探討了一個助理模型在推測性解碼中的訓練配方，該配方被用於起草，然後其未來令牌由目標 LLM 驗證。我們表明，通過有針對性的預訓練和微調策略進行優化的特定語言草稿模型，與以前的模型相比，顯著加快了推理時間。我們在推理時間、領域外加速和 GPT-4o 評估中驗證了這些模型跨各種語言。

##### **Addressing Polarization and Unfairness in Performative Prediction**
2406.16756v1 by Kun Jin, Tian Xie, Yang Liu, Xueru Zhang

When machine learning (ML) models are used in applications that involve
humans (e.g., online recommendation, school admission, hiring, lending), the
model itself may trigger changes in the distribution of targeted data it aims
to predict. Performative prediction (PP) is a framework that explicitly
considers such model-dependent distribution shifts when learning ML models.
While significant efforts have been devoted to finding performative stable (PS)
solutions in PP for system robustness, their societal implications are less
explored and it is unclear whether PS solutions are aligned with social norms
such as fairness. In this paper, we set out to examine the fairness property of
PS solutions in performative prediction. We first show that PS solutions can
incur severe polarization effects and group-wise loss disparity. Although
existing fairness mechanisms commonly used in literature can help mitigate
unfairness, they may fail and disrupt the stability under model-dependent
distribution shifts. We thus propose novel fairness intervention mechanisms
that can simultaneously achieve both stability and fairness in PP settings.
Both theoretical analysis and experiments are provided to validate the proposed
method.

摘要：當機器學習 (ML) 模型用於涉及人類的應用程式（例如，線上推薦、學校錄取、聘僱、借貸）時，模型本身可能會觸發其試圖預測的目標資料分佈的變化。執行預測 (PP) 是一個框架，在學習 ML 模型時，會明確考量此類模型依賴的分佈轉移。儘管已投入大量心力在 PP 中尋找執行穩定 (PS) 的解決方案，以確保系統穩健性，但其社會意涵較少被探討，而且不清楚 PS 解決方案是否符合公平性等社會規範。在本文中，我們著手檢視執行預測中 PS 解決方案的公平性屬性。我們首先說明 PS 解決方案可能會造成嚴重的兩極化效應和群組間損失差異。儘管現有文獻中常用的公平性機制有助於減輕不公平性，但它們可能在模型依賴的分佈轉移下失敗並破壞穩定性。因此，我們提出創新的公平性介入機制，可以在 PP 設定中同時達成穩定性和公平性。提供理論分析和實驗，以驗證所提出的方法。

##### **Towards Zero-Shot Text-To-Speech for Arabic Dialects**
2406.16751v2 by Khai Duy Doan, Abdul Waheed, Muhammad Abdul-Mageed

Zero-shot multi-speaker text-to-speech (ZS-TTS) systems have advanced for
English, however, it still lags behind due to insufficient resources. We
address this gap for Arabic, a language of more than 450 million native
speakers, by first adapting a sizeable existing dataset to suit the needs of
speech synthesis. Additionally, we employ a set of Arabic dialect
identification models to explore the impact of pre-defined dialect labels on
improving the ZS-TTS model in a multi-dialect setting. Subsequently, we
fine-tune the
XTTS\footnote{https://docs.coqui.ai/en/latest/models/xtts.html}\footnote{https://medium.com/machine-learns/xtts-v2-new-version-of-the-open-source-text-to-speech-model-af73914db81f}\footnote{https://medium.com/@erogol/xtts-v1-techincal-notes-eb83ff05bdc}
model, an open-source architecture. We then evaluate our models on a dataset
comprising 31 unseen speakers and an in-house dialectal dataset. Our automated
and human evaluation results show convincing performance while capable of
generating dialectal speech. Our study highlights significant potential for
improvements in this emerging area of research in Arabic.

摘要：零次學習多說話者文字轉語音（ZS-TTS）系統已針對英語進展，但由於資源不足，它仍落後。我們通過首先調整一個相當大的現有資料集以滿足語音合成的需求，來解決阿拉伯語（一種擁有超過 4.5 億母語人士的語言）的這個差距。此外，我們採用了一組阿拉伯方言識別模型，以探討預定義方言標籤對改善多方言環境中的 ZS-TTS 模型的影響。隨後，我們微調了 XTTS\footnote{https://docs.coqui.ai/en/latest/models/xtts.html}\footnote{https://medium.com/machine-learns/xtts-v2-new-version-of-the-open-source-text-to-speech-model-af73914db81f}\footnote{https://medium.com/@erogol/xtts-v1-techincal-notes-eb83ff05bdc}模型，這是一個開源架構。然後，我們在一個包含 31 個未見過說話者和一個內部方言資料集的資料集上評估我們的模型。我們的自動化和人工評估結果顯示出令人信服的表現，同時能夠產生方言語音。我們的研究強調了阿拉伯語這個新興研究領域的改進潛力。

##### **OCALM: Object-Centric Assessment with Language Models**
2406.16748v1 by Timo Kaufmann, Jannis Blüml, Antonia Wüst, Quentin Delfosse, Kristian Kersting, Eyke Hüllermeier

Properly defining a reward signal to efficiently train a reinforcement
learning (RL) agent is a challenging task. Designing balanced objective
functions from which a desired behavior can emerge requires expert knowledge,
especially for complex environments. Learning rewards from human feedback or
using large language models (LLMs) to directly provide rewards are promising
alternatives, allowing non-experts to specify goals for the agent. However,
black-box reward models make it difficult to debug the reward. In this work, we
propose Object-Centric Assessment with Language Models (OCALM) to derive
inherently interpretable reward functions for RL agents from natural language
task descriptions. OCALM uses the extensive world-knowledge of LLMs while
leveraging the object-centric nature common to many environments to derive
reward functions focused on relational concepts, providing RL agents with the
ability to derive policies from task descriptions.

摘要：適當地定義獎勵訊號以有效訓練強化學習 (RL) 代理是一項具有挑戰性的任務。設計平衡的目標函數，以便出現所需的行為，需要專業知識，特別是對於複雜的環境。從人類回饋中學習獎勵或使用大型語言模型 (LLM) 來直接提供獎勵是有前途的替代方案，允許非專家為代理指定目標。然而，黑盒獎勵模型使得調試獎勵變得困難。在這項工作中，我們提出使用語言模型進行以物件為中心的評估 (OCALM)，以從自然語言任務描述中推導出 RL 代理的內在可解釋獎勵函數。OCALM 使用 LLM 廣泛的世界知識，同時利用許多環境中常見的以物件為中心的特性來推導專注於關係概念的獎勵函數，使 RL 代理能夠從任務描述中推導出政策。

##### **Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers**
2406.16747v1 by Chao Lou, Zixia Jia, Zilong Zheng, Kewei Tu

Accommodating long sequences efficiently in autoregressive Transformers,
especially within an extended context window, poses significant challenges due
to the quadratic computational complexity and substantial KV memory
requirements inherent in self-attention mechanisms. In this work, we introduce
SPARSEK Attention, a novel sparse attention mechanism designed to overcome
these computational and memory obstacles while maintaining performance. Our
approach integrates a scoring network and a differentiable top-k mask operator,
SPARSEK, to select a constant number of KV pairs for each query, thereby
enabling gradient-based optimization. As a result, SPARSEK Attention offers
linear time complexity and constant memory footprint during generation.
Experimental results reveal that SPARSEK Attention outperforms previous sparse
attention methods and provides significant speed improvements during both
training and inference, particularly in language modeling and downstream tasks.
Furthermore, our method can be seamlessly integrated into pre-trained Large
Language Models (LLMs) with minimal fine-tuning, offering a practical solution
for effectively managing long-range dependencies in diverse applications.

摘要：在自回归 Transformer 中有效容纳长序列，尤其是在扩展上下文窗口内，由于自注意力机制固有的二次计算复杂度和大量的 KV 内存需求，因此提出了重大挑战。在这项工作中，我们引入了 SPARSEK 注意力，这是一种新颖的稀疏注意力机制，旨在克服这些计算和内存障碍，同时保持性能。我们的方法集成了一个评分网络和一个可微分的 top-k 掩码运算符 SPARSEK，为每个查询选择一个恒定的 KV 对数，从而实现基于梯度的优化。因此，SPARSEK 注意力在生成期间提供了线性时间复杂度和恒定内存占用。实验结果表明，SPARSEK 注意力优于先前的稀疏注意力方法，并在训练和推理期间提供了显着的速度提升，尤其是在语言建模和下游任务中。此外，我们的方法可以无缝集成到预训练的大语言模型 (LLM) 中，只需进行最小的微调，为在各种应用程序中有效管理远程依赖关系提供了一种实用的解决方案。

##### **The Responsible Foundation Model Development Cheatsheet: A Review of Tools & Resources**
2406.16746v1 by Shayne Longpre, Stella Biderman, Alon Albalak, Hailey Schoelkopf, Daniel McDuff, Sayash Kapoor, Kevin Klyman, Kyle Lo, Gabriel Ilharco, Nay San, Maribeth Rauh, Aviya Skowron, Bertie Vidgen, Laura Weidinger, Arvind Narayanan, Victor Sanh, David Adelani, Percy Liang, Rishi Bommasani, Peter Henderson, Sasha Luccioni, Yacine Jernite, Luca Soldaini

Foundation model development attracts a rapidly expanding body of
contributors, scientists, and applications. To help shape responsible
development practices, we introduce the Foundation Model Development
Cheatsheet: a growing collection of 250+ tools and resources spanning text,
vision, and speech modalities. We draw on a large body of prior work to survey
resources (e.g. software, documentation, frameworks, guides, and practical
tools) that support informed data selection, processing, and understanding,
precise and limitation-aware artifact documentation, efficient model training,
advance awareness of the environmental impact from training, careful model
evaluation of capabilities, risks, and claims, as well as responsible model
release, licensing and deployment practices. We hope this curated collection of
resources helps guide more responsible development. The process of curating
this list, enabled us to review the AI development ecosystem, revealing what
tools are critically missing, misused, or over-used in existing practices. We
find that (i) tools for data sourcing, model evaluation, and monitoring are
critically under-serving ethical and real-world needs, (ii) evaluations for
model safety, capabilities, and environmental impact all lack reproducibility
and transparency, (iii) text and particularly English-centric analyses continue
to dominate over multilingual and multi-modal analyses, and (iv) evaluation of
systems, rather than just models, is needed so that capabilities and impact are
assessed in context.

摘要：基礎模型的開發吸引了快速擴展的貢獻者、科學家和應用程式群體。為了協助塑造負責任的開發實務，我們推出了「基礎模型開發秘笈」：一個涵蓋文字、視覺和語音模式的 250 多種工具和資源的成長中集合。我們利用大量先前工作來調查資源（例如軟體、文件、架構、指南和實用工具），這些資源支援明智的資料選取、處理和理解、精確且具限制意識的人工製品文件、高效能的模型訓練、預先了解訓練對環境的影響、仔細評估模型的功能、風險和聲明，以及負責任的模型發布、授權和部署實務。我們希望這個精心策劃的資源集合有助於引導更負責任的開發。策劃這個清單的過程讓我們得以檢視 AI 開發生態系，揭露哪些工具在現有實務中嚴重不足、使用不當或過度使用。我們發現 (i) 資料來源、模型評估和監控的工具嚴重不足以滿足道德和現實世界的需求，(ii) 模型安全性、功能和環境影響的評估都缺乏可複製性和透明度，(iii) 文字，特別是英語為中心的分析持續主導多語言和多模式分析，以及 (iv) 需要評估系統，而不仅仅是模型，以便在上下文中評估功能和影響。

##### **Bandits with Preference Feedback: A Stackelberg Game Perspective**
2406.16745v1 by Barna Pásztor, Parnian Kassraie, Andreas Krause

Bandits with preference feedback present a powerful tool for optimizing
unknown target functions when only pairwise comparisons are allowed instead of
direct value queries. This model allows for incorporating human feedback into
online inference and optimization and has been employed in systems for
fine-tuning large language models. The problem is well understood in simplified
settings with linear target functions or over finite small domains that limit
practical interest. Taking the next step, we consider infinite domains and
nonlinear (kernelized) rewards. In this setting, selecting a pair of actions is
quite challenging and requires balancing exploration and exploitation at two
levels: within the pair, and along the iterations of the algorithm. We propose
MAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, and
chooses action pairs that are informative and yield favorable rewards.
MAXMINLCB consistently outperforms existing algorithms and satisfies an
anytime-valid rate-optimal regret guarantee. This is due to our novel
preference-based confidence sequences for kernelized logistic estimators.

摘要：具有偏好回饋的強盜提供了一個強大的工具，用於在僅允許成對比較而不是直接值查詢時最佳化未知目標函數。此模型允許將人類回饋納入線上推論和最佳化，並已用於大型語言模型的微調系統中。這個問題在具有線性目標函數或在限制實際興趣的有限小域上的簡化設定中已得到很好的理解。採取下一步，我們考慮無限域和非線性（核化）回報。在這種設定中，選擇一對動作非常具有挑戰性，需要在兩個層面上平衡探索和利用：在該對動作內部，以及沿著演算法的迭代。我們提出 MAXMINLCB，它將此折衷模擬為零和 Stackelberg 遊戲，並選擇具有資訊且產生有利回報的動作對。MAXMINLCB 持續優於現有演算法，並滿足隨時有效的速率最佳後悔保證。這是因為我們針對核化邏輯估計器提出了新的基於偏好的信心序列。

##### **Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization**
2406.16743v1 by Zhengyue Zhao, Xiaoyun Zhang, Kaidi Xu, Xing Hu, Rui Zhang, Zidong Du, Qi Guo, Yunji Chen

With the widespread application of Large Language Models (LLMs), it has
become a significant concern to ensure their safety and prevent harmful
responses. While current safe-alignment methods based on instruction
fine-tuning and Reinforcement Learning from Human Feedback (RLHF) can
effectively reduce harmful responses from LLMs, they often require high-quality
datasets and heavy computational overhead during model training. Another way to
align language models is to modify the logit of tokens in model outputs without
heavy training. Recent studies have shown that contrastive decoding can enhance
the performance of language models by reducing the likelihood of confused
tokens. However, these methods require the manual selection of contrastive
models or instruction templates. To this end, we propose Adversarial
Contrastive Decoding (ACD), an optimization-based framework to generate two
opposite system prompts for prompt-based contrastive decoding. ACD only needs
to apply a lightweight prompt tuning on a rather small anchor dataset (< 3 min
for each model) without training the target model. Experiments conducted on
extensive models and benchmarks demonstrate that the proposed method achieves
much better safety performance than previous model training-free decoding
methods without sacrificing its original generation ability.

摘要：隨著大型語言模型 (LLM) 的廣泛應用，確保其安全性並防止有害回應已成為一個重要的問題。雖然基於指令微調和人類回饋強化學習 (RLHF) 的現有安全對齊方法可以有效減少 LLM 的有害回應，但它們通常需要高品質的資料集和在模型訓練期間大量的計算負擔。對齊語言模型的另一種方法是在不進行大量訓練的情況下修改模型輸出中標記的 logit。最近的研究表明，對比解碼可以透過降低混淆標記的可能性來增強語言模型的效能。然而，這些方法需要手動選擇對比模型或指令範本。為此，我們提出了對抗性對比解碼 (ACD)，這是一個基於最佳化的架構，用於為基於提示的對比解碼產生兩個相反的系統提示。ACD 只需要在一個相當小的錨定資料集上套用輕量級提示調整（每個模型小於 3 分鐘），而無需訓練目標模型。在廣泛的模型和基準上進行的實驗表明，所提出的方法比先前的模型訓練免費解碼方法實現了更好的安全性，同時不犧牲其原始的生成能力。

##### **Extracting thin film structures of energy materials using transformers**
2406.16741v1 by Chen Zhang, Valerie A. Niemann, Peter Benedek, Thomas F. Jaramillo, Mathieu Doucet

Neutron-Transformer Reflectometry and Advanced Computation Engine (N-TRACE ),
a neural network model using transformer architecture, is introduced for
neutron reflectometry data analysis. It offers fast, accurate initial parameter
estimations and efficient refinements, improving efficiency and precision for
real-time data analysis of lithium-mediated nitrogen reduction for
electrochemical ammonia synthesis, with relevance to other chemical
transformations and batteries. Despite limitations in generalizing across
systems, it shows promises for the use of transformers as the basis for models
that could replace trial-and-error approaches to modeling reflectometry data.

摘要：中子轉換反射儀和先進計算引擎 (N-TRACE)，是一種使用轉換器架構的神經網路模型，用於中子反射儀數據分析。它提供快速、準確的初始參數估計和有效的修正，提高了鋰介導氮氣還原電化學氨合成實時數據分析的效率和準確性，與其他化學轉換和電池有關。儘管在系統間推廣存在限制，但它顯示了使用轉換器作為模型基礎的前景，可以取代反射儀數據建模的試錯方法。

##### **Inducing Group Fairness in LLM-Based Decisions**
2406.16738v1 by James Atwood, Preethi Lahoti, Ananth Balashankar, Flavien Prost, Ahmad Beirami

Prompting Large Language Models (LLMs) has created new and interesting means
for classifying textual data. While evaluating and remediating group fairness
is a well-studied problem in classifier fairness literature, some classical
approaches (e.g., regularization) do not carry over, and some new opportunities
arise (e.g., prompt-based remediation). We measure fairness of LLM-based
classifiers on a toxicity classification task, and empirically show that
prompt-based classifiers may lead to unfair decisions. We introduce several
remediation techniques and benchmark their fairness and performance trade-offs.
We hope our work encourages more research on group fairness in LLM-based
classifiers.

摘要：提示大型語言模型 (LLM) 創造了新的且有趣的方式來分類文本資料。雖然評估和補救群體公平性是分類器公平性文獻中研究透徹的問題，但一些經典方法（例如正規化）並未傳遞，並且出現了一些新的機會（例如基於提示的補救措施）。我們衡量基於 LLM 的分類器在毒性分類任務中的公平性，並憑經驗表明基於提示的分類器可能會導致不公平的決策。我們介紹了幾種補救技術，並對它們的公平性和效能權衡進行了基準測試。我們希望我們的研究能激勵更多關於基於 LLM 的分類器中的群體公平性的研究。

##### **CLIMATELI: Evaluating Entity Linking on Climate Change Data**
2406.16732v1 by Shijia Zhou, Siyao Peng, Barbara Plank

Climate Change (CC) is a pressing topic of global importance, attracting
increasing attention across research fields, from social sciences to Natural
Language Processing (NLP). CC is also discussed in various settings and
communication platforms, from academic publications to social media forums.
Understanding who and what is mentioned in such data is a first critical step
to gaining new insights into CC. We present CLIMATELI (CLIMATe Entity LInking),
the first manually annotated CC dataset that links 3,087 entity spans to
Wikipedia. Using CLIMATELI (CLIMATe Entity LInking), we evaluate existing
entity linking (EL) systems on the CC topic across various genres and propose
automated filtering methods for CC entities. We find that the performance of EL
models notably lags behind humans at both token and entity levels. Testing
within the scope of retaining or excluding non-nominal and/or non-CC entities
particularly impacts the models' performances.

摘要：氣候變遷 (CC) 是全球關注的迫切議題，吸引了從社會科學到自然語言處理 (NLP) 等各個研究領域的注意。CC 也在從學術出版品到社群媒體論壇等各種場景和溝通平台中討論。理解在這些資料中提及了誰和什麼是獲得對 CC 新見解的第一個關鍵步驟。我們提出 CLIMATELI (CLIMATe Entity LInking)，這是第一個手動註解的 CC 資料集，將 3,087 個實體區間連結到維基百科。使用 CLIMATELI (CLIMATe Entity LInking)，我們評估了各種文體中現有的實體連結 (EL) 系統，並針對 CC 實體提出自動化過濾方法。我們發現，EL 模型的效能顯著落後於人類，無論是在詞元或實體層級。在保留或排除非名詞和/或非 CC 實體的範圍內進行測試，特別影響模型的效能。

##### **Convolutional neural network for Lyman break galaxies classification and redshift regression in DESI (Dark Energy Spectroscopic Instrument)**
2406.16730v1 by Julien Taran

DESI is a groundbreaking international project to observe more than 40
million quasars and galaxies over a 5-year period to create a 3D map of the
sky. This map will enable us to probe multiple aspects of cosmology, from dark
energy to neutrino mass. We are focusing here on one type of object observed by
DESI, the Lyman Break Galaxies (LBGs). The aim is to use their spectra to
determine whether they are indeed LBGs, and if so, to determine their distance
from the Earth using a phenomenon called redshift. This will enable us to place
these galaxies on the DESI 3D map.
  The aim is therefore to develop a convolutional neural network (CNN) inspired
by QuasarNET (See arXiv:1808.09955), performing simultaneously a classification
(LBG type or not) and a regression task (determine the redshift of the LBGs).
Initially, data augmentation techniques such as shifting the spectra in
wavelengths, adding noise to the spectra, or adding synthetic spectra were used
to increase the model training dataset from 3,019 data to over 66,000. In a
second phase, modifications to the QuasarNET architecture, notably through
transfer learning and hyperparameter tuning with Bayesian optimization, boosted
model performance.
  Gains of up to 26% were achieved on the Purity/Efficiency curve, which is
used to evaluate model performance, particularly in areas with interesting
redshifts, at low (around 2) and high (around 4) redshifts. The best model
obtained an average score of 94%, compared with 75% for the initial model.

摘要：DESI 是一個創新的國際專案，在 5 年期間觀測超過 4000 萬個類星體和星系，以建立天空的 3D 地圖。這張地圖將使我們能夠探測宇宙學的各個方面，從暗能量到微中子質量。我們這裡專注於 DESI 觀測到的一種類型物體，萊曼斷裂星系 (LBG)。目的是使用它們的光譜來確定它們是否真的是 LBG，如果是，則使用稱為紅移的現象來確定它們與地球的距離。這將使我們能夠將這些星系放置在 DESI 3D 地圖上。
因此，目標是開發一個卷積神經網路 (CNN)，靈感來自 QuasarNET（見 arXiv:1808.09955），同時執行分類（LBG 類型或非 LBG 類型）和回歸任務（確定 LBG 的紅移）。
最初，數據擴充技術（例如在波長上移動光譜、向光譜中添加雜訊或添加合成光譜）被用於將模型訓練資料集從 3,019 個資料增加到超過 66,000 個。在第二階段，對 QuasarNET 架構進行修改，特別是通過轉移學習和使用貝氏最佳化調整超參數，提升了模型效能。
在純度/效率曲線上獲得了高達 26% 的增益，該曲線用於評估模型效能，特別是在具有有趣的紅移區域，在低（約 2）和高（約 4）紅移。與初始模型的 75% 相比，獲得的最佳模型平均得分為 94%。

##### **CausalMMM: Learning Causal Structure for Marketing Mix Modeling**
2406.16728v1 by Chang Gong, Di Yao, Lei Zhang, Sheng Chen, Wenbin Li, Yueyang Su, Jingping Bi

In online advertising, marketing mix modeling (MMM) is employed to predict
the gross merchandise volume (GMV) of brand shops and help decision-makers to
adjust the budget allocation of various advertising channels. Traditional MMM
methods leveraging regression techniques can fail in handling the complexity of
marketing. Although some efforts try to encode the causal structures for better
prediction, they have the strict restriction that causal structures are
prior-known and unchangeable. In this paper, we define a new causal MMM problem
that automatically discovers the interpretable causal structures from data and
yields better GMV predictions. To achieve causal MMM, two essential challenges
should be addressed: (1) Causal Heterogeneity. The causal structures of
different kinds of shops vary a lot. (2) Marketing Response Patterns. Various
marketing response patterns i.e., carryover effect and shape effect, have been
validated in practice. We argue that causal MMM needs dynamically discover
specific causal structures for different shops and the predictions should
comply with the prior known marketing response patterns. Thus, we propose
CausalMMM that integrates Granger causality in a variational inference
framework to measure the causal relationships between different channels and
predict the GMV with the regularization of both temporal and saturation
marketing response patterns. Extensive experiments show that CausalMMM can not
only achieve superior performance of causal structure learning on synthetic
datasets with improvements of 5.7%\sim 7.1%, but also enhance the GMV
prediction results on a representative E-commerce platform.

摘要：在網路廣告中，行銷組合模型 (MMM) 被用來預測品牌商店的商品交易總額 (GMV)，並幫助決策者調整各種廣告頻道的預算分配。傳統的 MMM 方法利用回歸技術，但在處理行銷的複雜性時可能會失敗。儘管有些方法嘗試編碼因果結構以進行更好的預測，但它們有嚴格的限制，即因果結構是事先已知的且不可變更。在本文中，我們定義了一個新的因果 MMM 問題，它會自動從資料中發現可解釋的因果結構，並產生更好的 GMV 預測。為了實現因果 MMM，應解決兩個基本挑戰：(1) 因果異質性。不同類型商店的因果結構差異很大。(2) 行銷反應模式。各種行銷反應模式，例如遞延效應和形狀效應，已在實務中得到驗證。我們認為，因果 MMM 需要動態發現不同商店的特定因果結構，而預測應符合先前已知的行銷反應模式。因此，我們提出 CausalMMM，它將 Granger 因果關係整合到變異推論架構中，以衡量不同管道之間的因果關係，並根據時間和飽和行銷反應模式的正則化來預測 GMV。廣泛的實驗表明，CausalMMM 不僅可以在合成資料集上實現因果結構學習的優異效能，改善幅度為 5.7%～7.1%，還能提升有代表性的電子商務平台上的 GMV 預測結果。

##### **Venturing into Uncharted Waters: The Navigation Compass from Transformer to Mamba**
2406.16722v1 by Yuchen Zou, Yineng Chen, Zuchao Li, Lefei Zhang, Hai Zhao

Transformer, a deep neural network architecture, has long dominated the field
of natural language processing and beyond. Nevertheless, the recent
introduction of Mamba challenges its supremacy, sparks considerable interest
among researchers, and gives rise to a series of Mamba-based models that have
exhibited notable potential. This survey paper orchestrates a comprehensive
discussion, diving into essential research dimensions, covering: (i) the
functioning of the Mamba mechanism and its foundation on the principles of
structured state space models; (ii) the proposed improvements and the
integration of Mamba with various networks, exploring its potential as a
substitute for Transformers; (iii) the combination of Transformers and Mamba to
compensate for each other's shortcomings. We have also made efforts to
interpret Mamba and Transformer in the framework of kernel functions, allowing
for a comparison of their mathematical nature within a unified context. Our
paper encompasses the vast majority of improvements related to Mamba to date.

摘要：Transformer 是一種深度神經網路架構，長期以來一直主導自然語言處理及其他領域。然而，最近推出的 Mamba 挑戰了其霸主地位，在研究人員之間引起了極大的興趣，並催生了一系列基於 Mamba 的模型，這些模型展現了顯著的潛力。這篇綜述論文精心策劃了一場全面性的討論，深入探討了重要的研究面向，涵蓋：(i) Mamba 機制的運作及其在結構化狀態空間模型原理上的基礎；(ii) 提出的改進和 Mamba 與各種網路的整合，探索其作為 Transformer 替代品的潛力；(iii) Transformer 和 Mamba 的結合，以彌補彼此的不足。我們還努力在核函數的架構中詮釋 Mamba 和 Transformer，以便在統一的背景下比較它們的數學性質。我們的論文涵蓋了迄今為止與 Mamba 相關的大多數改進。

##### **AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models**
2406.16714v1 by Jiale Cheng, Yida Lu, Xiaotao Gu, Pei Ke, Xiao Liu, Yuxiao Dong, Hongning Wang, Jie Tang, Minlie Huang

Although Large Language Models (LLMs) are becoming increasingly powerful,
they still exhibit significant but subtle weaknesses, such as mistakes in
instruction-following or coding tasks. As these unexpected errors could lead to
severe consequences in practical deployments, it is crucial to investigate the
limitations within LLMs systematically. Traditional benchmarking approaches
cannot thoroughly pinpoint specific model deficiencies, while manual
inspections are costly and not scalable. In this paper, we introduce a unified
framework, AutoDetect, to automatically expose weaknesses in LLMs across
various tasks. Inspired by the educational assessment process that measures
students' learning outcomes, AutoDetect consists of three LLM-powered agents:
Examiner, Questioner, and Assessor. The collaboration among these three agents
is designed to realize comprehensive and in-depth weakness identification. Our
framework demonstrates significant success in uncovering flaws, with an
identification success rate exceeding 30% in prominent models such as ChatGPT
and Claude. More importantly, these identified weaknesses can guide specific
model improvements, proving more effective than untargeted data augmentation
methods like Self-Instruct. Our approach has led to substantial enhancements in
popular LLMs, including the Llama series and Mistral-7b, boosting their
performance by over 10% across several benchmarks. Code and data are publicly
available at https://github.com/thu-coai/AutoDetect.

摘要：儘管大型語言模型 (LLM) 變得越來越強大，
它們仍展現出顯著但細微的弱點，例如在指令遵循或編碼任務中的錯誤。由於這些意外錯誤可能導致實際部署中的嚴重後果，因此系統地調查 LLM 中的限制至關重要。傳統的基準測試方法無法徹底找出具體的模型缺陷，而手動檢查成本高昂且不可擴展。在本文中，我們介紹了一個統一的框架 AutoDetect，用於自動揭露 LLM 在各種任務中的弱點。受衡量學生學習成果的教育評量過程啟發，AutoDetect 包含三個由 LLM 驅動的代理：考官、提問者和評估者。這三個代理之間的協作旨在實現全面且深入的弱點識別。我們的框架在發現缺陷方面表現出顯著的成功，在 ChatGPT 和 Claude 等知名模型中，識別成功率超過 30%。更重要的是，這些已識別的弱點可以指導具體的模型改進，證明比自指導等無目標數據擴充方法更有效。我們的做法已大幅提升熱門 LLM 的效能，包括 Llama 系列和 Mistral-7b，在多個基準測試中提升其效能超過 10%。程式碼和資料已公開發布於 https://github.com/thu-coai/AutoDetect。

##### **Probabilistic Subgoal Representations for Hierarchical Reinforcement learning**
2406.16707v1 by Vivienne Huiling Wang, Tinghuai Wang, Wenyan Yang, Joni-Kristian Kämäräinen, Joni Pajarinen

In goal-conditioned hierarchical reinforcement learning (HRL), a high-level
policy specifies a subgoal for the low-level policy to reach. Effective HRL
hinges on a suitable subgoal represen tation function, abstracting state space
into latent subgoal space and inducing varied low-level behaviors. Existing
methods adopt a subgoal representation that provides a deterministic mapping
from state space to latent subgoal space. Instead, this paper utilizes Gaussian
Processes (GPs) for the first probabilistic subgoal representation. Our method
employs a GP prior on the latent subgoal space to learn a posterior
distribution over the subgoal representation functions while exploiting the
long-range correlation in the state space through learnable kernels. This
enables an adaptive memory that integrates long-range subgoal information from
prior planning steps allowing to cope with stochastic uncertainties.
Furthermore, we propose a novel learning objective to facilitate the
simultaneous learning of probabilistic subgoal representations and policies
within a unified framework. In experiments, our approach outperforms
state-of-the-art baselines in standard benchmarks but also in environments with
stochastic elements and under diverse reward conditions. Additionally, our
model shows promising capabilities in transferring low-level policies across
different tasks.

摘要：在目標條件分層強化學習 (HRL) 中，高階政策會為低階政策指定一個子目標。有效的 HRL 取決於一個合適的子目標表示函數，將狀態空間抽象成潛在子目標空間，並誘發各種低階行為。現有方法採用一個子目標表示，提供從狀態空間到潛在子目標空間的確定性對應。相反，本文利用高斯程序 (GP) 作為第一個機率子目標表示。我們的方法採用潛在子目標空間上的 GP 先驗來學習子目標表示函數上的後驗分佈，同時透過可學習核來利用狀態空間中的長程關聯。這能建立一個適應性記憶體，整合來自先前規劃步驟的長程子目標資訊，允許應對隨機不確定性。此外，我們提出一個新穎的學習目標，以促進在統一架構中同時學習機率子目標表示和政策。在實驗中，我們的做法在標準基準以及在具有隨機元素和不同獎勵條件的環境中都優於最先進的基準。此外，我們的模型在不同任務間轉移低階政策時，展現出有前途的能力。

##### **Public Constitutional AI**
2406.16696v1 by Gilad Abiri

We are increasingly subjected to the power of AI authorities. As AI decisions
become inescapable, entering domains such as healthcare, education, and law, we
must confront a vital question: how can we ensure AI systems have the
legitimacy necessary for effective governance? This essay argues that to secure
AI legitimacy, we need methods that engage the public in designing and
constraining AI systems, ensuring these technologies reflect the community's
shared values. Constitutional AI, proposed by Anthropic, represents a step
towards this goal, offering a model for democratic control of AI. However,
while Constitutional AI's commitment to hardcoding explicit principles into AI
models enhances transparency and accountability, it falls short in two crucial
aspects: addressing the opacity of individual AI decisions and fostering
genuine democratic legitimacy. To overcome these limitations, this essay
proposes "Public Constitutional AI." This approach envisions a participatory
process where diverse stakeholders, including ordinary citizens, deliberate on
the principles guiding AI development. The resulting "AI Constitution" would
carry the legitimacy of popular authorship, grounding AI governance in the
public will. Furthermore, the essay proposes "AI Courts" to develop "AI case
law," providing concrete examples for operationalizing constitutional
principles in AI training. This evolving combination of constitutional
principles and case law aims to make AI governance more responsive to public
values. By grounding AI governance in deliberative democratic processes, Public
Constitutional AI offers a path to imbue automated authorities with genuine
democratic legitimacy, addressing the unique challenges posed by increasingly
powerful AI systems while ensuring their alignment with the public interest.

摘要：<paragraph>我們正越來越受制於 AI 權威。隨著 AI 決策變得不可避免，進入醫療保健、教育和法律等領域，我們必須面對一個至關重要的問題：如何確保 AI 系統具備有效治理所需的合法性？本文認為，為了確保 AI 的合法性，我們需要採用讓公眾參與設計和約束 AI 系統的方法，確保這些技術反映社區的共同價值觀。由 Anthropic 提出的「憲法 AI」朝著這個目標邁出了一步，為民主控制 AI 提供了一個模型。然而，儘管憲法 AI 承諾將明確原則硬編碼到 AI 模型中以增強透明度和問責制，但在兩個關鍵方面存在不足：解決個別 AI 決策的不透明性並促進真正的民主合法性。為了克服這些限制，本文提出了「公共憲法 AI」。這種方法設想了一個參與式流程，其中包括普通公民在內的不同利益相關者對指導 AI 開發的原則進行審議。由此產生的「AI 憲法」將承載人民作者的合法性，將 AI 治理建立在公眾意願之上。此外，本文提出了「AI 法院」來制定「AI 案例法」，為在 AI 訓練中實施憲法原則提供具體範例。憲法原則和案例法的這種不斷演變的結合旨在使 AI 治理更能回應公眾價值觀。通過將 AI 治理建立在審議民主進程中，公共憲法 AI 提供了一條途徑，賦予自動化權威真正的民主合法性，既應對了越來越強大的 AI 系統帶來的獨特挑戰，又確保了它們與公共利益保持一致。</paragraph>

##### **Task Oriented In-Domain Data Augmentation**
2406.16694v1 by Xiao Liang, Xinyu Hu, Simiao Zuo, Yeyun Gong, Qiang Lou, Yi Liu, Shao-Lun Huang, Jian Jiao

Large Language Models (LLMs) have shown superior performance in various
applications and fields. To achieve better performance on specialized domains
such as law and advertisement, LLMs are often continue pre-trained on in-domain
data. However, existing approaches suffer from two major issues. First,
in-domain data are scarce compared with general domain-agnostic data. Second,
data used for continual pre-training are not task-aware, such that they may not
be helpful to downstream applications. We propose TRAIT, a task-oriented
in-domain data augmentation framework. Our framework is divided into two parts:
in-domain data selection and task-oriented synthetic passage generation. The
data selection strategy identifies and selects a large amount of in-domain data
from general corpora, and thus significantly enriches domain knowledge in the
continual pre-training data. The synthetic passages contain guidance on how to
use domain knowledge to answer questions about downstream tasks. By training on
such passages, the model aligns with the need of downstream applications. We
adapt LLMs to two domains: advertisement and math. On average, TRAIT improves
LLM performance by 8% in the advertisement domain and 7.5% in the math domain.

摘要：大型語言模型 (LLM) 已在各種應用程式和領域中展現出優異的效能。為了在法律和廣告等特定領域中獲得更好的效能，LLM 經常持續在特定領域的資料中進行預先訓練。然而，現有的方法有兩個主要問題。首先，與一般領域無關的資料相比，特定領域的資料較為稀少。其次，用於持續預先訓練的資料並非任務導向，因此可能對下游應用程式沒有幫助。我們提出 TRAIT，一個任務導向的特定領域資料擴充架構。我們的架構分為兩個部分：特定領域資料選取和任務導向合成段落產生。資料選取策略從一般語料庫中識別並選取大量的特定領域資料，從而顯著豐富了持續預先訓練資料中的領域知識。合成段落包含有關如何使用領域知識來回答下游任務問題的指導方針。透過訓練這些段落，模型與下游應用程式的需求保持一致。我們將 LLM 調整到兩個領域：廣告和數學。平均而言，TRAIT 將廣告領域的 LLM 效能提升了 8%，數學領域的效能提升了 7.5%。

##### **Scaling Laws for Linear Complexity Language Models**
2406.16690v1 by Xuyang Shen, Dong Li, Ruitao Leng, Zhen Qin, Weigao Sun, Yiran Zhong

The interest in linear complexity models for large language models is on the
rise, although their scaling capacity remains uncertain. In this study, we
present the scaling laws for linear complexity language models to establish a
foundation for their scalability. Specifically, we examine the scaling
behaviors of three efficient linear architectures. These include TNL, a linear
attention model with data-independent decay; HGRN2, a linear RNN with
data-dependent decay; and cosFormer2, a linear attention model without decay.
We also include LLaMA as a baseline architecture for softmax attention for
comparison. These models were trained with six variants, ranging from 70M to 7B
parameters on a 300B-token corpus, and evaluated with a total of 1,376
intermediate checkpoints on various downstream tasks. These tasks include
validation loss, commonsense reasoning, and information retrieval and
generation. The study reveals that existing linear complexity language models
exhibit similar scaling capabilities as conventional transformer-based models
while also demonstrating superior linguistic proficiency and knowledge
retention.

摘要：對於大型語言模型的線性複雜度模型的興趣正在增加，儘管它們的擴充能力仍然不確定。在本研究中，我們提出了線性複雜度語言模型的擴充定律，為它們的可擴充性奠定基礎。具體來說，我們檢驗了三種高效線性架構的擴充行為。這些架構包括 TNL，一種具有與資料無關衰減的線性注意力模型；HGRN2，一種具有與資料相關衰減的線性 RNN；以及 cosFormer2，一種沒有衰減的線性注意力模型。我們還將 LLaMA 作為 softmax 注意力的基準架構進行比較。這些模型使用六種變體進行訓練，範圍從 70M 到 7B 參數，在 300B 令牌語料庫上進行訓練，並使用總共 1,376 個中間檢查點在各種下游任務上進行評估。這些任務包括驗證損失、常識推理、資訊檢索和生成。研究表明，現有的線性複雜度語言模型展現出與傳統基於轉換器的模型類似的擴充能力，同時也展現出優異的語言能力和知識保留能力。

##### **Link Prediction with Untrained Message Passing Layers**
2406.16687v1 by Lisi Qarkaxhija, Anatol E. Wegner, Ingo Scholtes

Message passing neural networks (MPNNs) operate on graphs by exchanging
information between neigbouring nodes. MPNNs have been successfully applied to
various node-, edge-, and graph-level tasks in areas like molecular science,
computer vision, natural language processing, and combinatorial optimization.
However, most MPNNs require training on large amounts of labeled data, which
can be costly and time-consuming. In this work, we explore the use of various
untrained message passing layers in graph neural networks, i.e. variants of
popular message passing architecture where we remove all trainable parameters
that are used to transform node features in the message passing step. Focusing
on link prediction, we find that untrained message passing layers can lead to
competitive and even superior performance compared to fully trained MPNNs,
especially in the presence of high-dimensional features. We provide a
theoretical analysis of untrained message passing by relating the inner
products of features implicitly produced by untrained message passing layers to
path-based topological node similarity measures. As such, untrained message
passing architectures can be viewed as a highly efficient and interpretable
approach to link prediction.

摘要：訊息傳遞神經網路 (MPNN) 透過交換鄰近節點之間的資訊來處理圖形。MPNN 已成功應用於各種節點、邊緣和圖形層級的任務，例如分子科學、電腦視覺、自然語言處理和組合最佳化。然而，大多數 MPNN 需要大量標籤資料才能進行訓練，這可能會很昂貴且耗時。在這項工作中，我們探討了在圖形神經網路中使用各種未訓練的訊息傳遞層，也就是說，我們移除了所有用於在訊息傳遞步驟中轉換節點特徵的可訓練參數，這是熱門訊息傳遞架構的變體。專注於連結預測，我們發現未訓練的訊息傳遞層可以產生具有競爭力，甚至優於完全訓練的 MPNN 的效能，尤其是在存在高維特徵的情況下。我們透過將未訓練的訊息傳遞層隱含產生的特徵的內積與基於路徑的拓撲節點相似度測量關聯，提供未訓練訊息傳遞的理論分析。因此，未訓練的訊息傳遞架構可以視為一種高度有效且可解釋的連結預測方法。

##### **Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation**
2406.16678v1 by Markus Frohmann, Igor Sterner, Ivan Vulić, Benjamin Minixhofer, Markus Schedl

Segmenting text into sentences plays an early and crucial role in many NLP
systems. This is commonly achieved by using rule-based or statistical methods
relying on lexical features such as punctuation. Although some recent works no
longer exclusively rely on punctuation, we find that no prior method achieves
all of (i) robustness to missing punctuation, (ii) effective adaptability to
new domains, and (iii) high efficiency. We introduce a new model - Segment any
Text (SaT) - to solve this problem. To enhance robustness, we propose a new
pretraining scheme that ensures less reliance on punctuation. To address
adaptability, we introduce an extra stage of parameter-efficient fine-tuning,
establishing state-of-the-art performance in distinct domains such as verses
from lyrics and legal documents. Along the way, we introduce architectural
modifications that result in a threefold gain in speed over the previous state
of the art and solve spurious reliance on context far in the future. Finally,
we introduce a variant of our model with fine-tuning on a diverse, multilingual
mixture of sentence-segmented data, acting as a drop-in replacement and
enhancement for existing segmentation tools. Overall, our contributions provide
a universal approach for segmenting any text. Our method outperforms all
baselines - including strong LLMs - across 8 corpora spanning diverse domains
and languages, especially in practically relevant situations where text is
poorly formatted. Our models and code, including documentation, are available
at https://huggingface.co/segment-any-text under the MIT license.

摘要：將文字區分為句子在許多 NLP 系統中扮演早期且關鍵的角色。這通常是透過使用基於規則或統計的方法，並依賴於標點符號等詞彙特徵來達成。儘管一些近期作品不再獨自依賴於標點符號，但我們發現沒有先前的辦法能同時達成 (i) 對遺失標點符號的穩健性、(ii) 對新領域的有效適應性，以及 (iii) 高效率。我們引進一個新模型 - Segment any Text (SaT) - 來解決這個問題。為了增強穩健性，我們提出一個新的預訓練架構，以確保較不依賴於標點符號。為了處理適應性，我們引進一個額外的參數有效微調階段，在不同的領域（例如歌詞和法律文件中的詩句）中建立最先進的效能。在這個過程中，我們引進架構修改，讓速度比先前的最先進技術提升三倍，並解決對遠在未來的內容產生虛假的依賴性。最後，我們引進一個模型變體，並針對句子區分的資料的多元語言混合進行微調，作為現有區分工具的插入替換和強化。總體而言，我們的貢獻提供了一個通用方法，可區分任何文字。我們的辦法優於所有基準 - 包括強大的 LLM - 橫跨 8 個語料庫，涵蓋不同的領域和語言，特別是在文字格式不佳的實際相關情況中。我們的模型和程式碼（包括文件）可以在 https://huggingface.co/segment-any-text 取得，並採用 MIT 授權。

##### **Computational Approaches to the Detection of Lesser-Known Rhetorical Figures: A Systematic Survey and Research Challenges**
2406.16674v1 by Ramona Kühn, Jelena Mitrović, Michael Granitzer

Rhetorical figures play a major role in our everyday communication as they
make text more interesting, more memorable, or more persuasive. Therefore, it
is important to computationally detect rhetorical figures to fully understand
the meaning of a text. We provide a comprehensive overview of computational
approaches to lesser-known rhetorical figures. We explore the linguistic and
computational perspectives on rhetorical figures, emphasizing their
significance for the domain of Natural Language Processing. We present
different figures in detail, delving into datasets, definitions, rhetorical
functions, and detection approaches. We identified challenges such as dataset
scarcity, language limitations, and reliance on rule-based methods.

摘要：修辭手法在我們的日常溝通中扮演著重要的角色，因為它們讓文字更有趣、更令人難忘或更有說服力。因此，以計算方式偵測修辭手法對於充分理解文字的意義非常重要。我們提供了對較不為人知的修辭手法的計算方法的全面概觀。我們探討了修辭手法的語言學和計算觀點，強調它們對自然語言處理領域的重要性。我們詳細說明了不同的手法，深入探討了資料集、定義、修辭功能和偵測方法。我們發現了資料集稀少、語言限制和依賴基於規則的方法等挑戰。

##### **CAVE: Controllable Authorship Verification Explanations**
2406.16672v1 by Sahana Ramnath, Kartik Pandey, Elizabeth Boschee, Xiang Ren

Authorship Verification (AV) (do two documents have the same author?) is
essential for many sensitive real-life applications. AV is often used in
proprietary domains that require a private, offline model, making SOTA online
models like ChatGPT undesirable. Other SOTA systems use methods, e.g. Siamese
Networks, that are uninterpretable, and hence cannot be trusted in high-stakes
applications. In this work, we take the first step to address the above
challenges with our model CAVE (Controllable Authorship Verification
Explanations): CAVE generates free-text AV explanations that are controlled to
be 1) structured (can be decomposed into sub-explanations with respect to
relevant linguistic features), and 2) easily verified for explanation-label
consistency (via intermediate labels in sub-explanations). In this work, we
train a Llama-3-8B as CAVE; since there are no human-written corpora for AV
explanations, we sample silver-standard explanations from GPT-4-TURBO and
distill them into a pretrained Llama-3-8B. Results on three difficult AV
datasets IMdB2, Blog-Auth, and FanFiction show that CAVE generates high quality
explanations (as measured by automatic and human evaluation) as well as
competitive task accuracies.

摘要：作者驗證 (AV)（兩份文件是否由同一位作者撰寫？）對於許多敏感的實際應用至關重要。AV 通常用於需要私人離線模型的專有領域，這使得像 ChatGPT 這樣的 SOTA 線上模型不受歡迎。其他 SOTA 系統使用的方法（例如連體網路）無法解釋，因此無法在高風險應用中受到信任。在這項工作中，我們採取第一步，使用我們的模型 CAVE（可控作者驗證說明）來解決上述挑戰：CAVE 會產生自由文字的 AV 說明，這些說明受到控制，以達到 1）結構化（可以根據相關語言功能分解為子說明），以及 2）易於驗證說明標籤一致性（透過子說明中的中間標籤）。在這項工作中，我們訓練了一個 Llama-3-8B 作為 CAVE；由於沒有人工撰寫的 AV 說明語料庫，我們從 GPT-4-TURBO 中取樣白銀標準說明，並將它們提煉成預訓練的 Llama-3-8B。在三個困難的 AV 資料集 IMdB2、Blog-Auth 和 FanFiction 中的結果顯示，CAVE 會產生高品質的說明（根據自動和人工評估測量），以及具有競爭力的任務準確度。

##### **Large Language Models Are Cross-Lingual Knowledge-Free Reasoners**
2406.16655v1 by Peng Hu, Sizhe Liu, Changjiang Gao, Xin Huang, Xue Han, Junlan Feng, Chao Deng, Shujian Huang

Large Language Models have demonstrated impressive reasoning capabilities
across multiple languages. However, the relationship between capabilities in
different languages is less explored. In this work, we decompose the process of
reasoning tasks into two separated parts: knowledge retrieval and
knowledge-free reasoning, and analyze the cross-lingual transferability of
them. With adapted and constructed knowledge-free reasoning datasets, we show
that the knowledge-free reasoning capability can be nearly perfectly
transferred across various source-target language directions despite the
secondary impact of resource in some specific target languages, while
cross-lingual knowledge retrieval significantly hinders the transfer. Moreover,
by analyzing the hidden states and feed-forward network neuron activation
during the reasoning tasks, we show that higher similarity of hidden
representations and larger overlap of activated neurons could explain the
better cross-lingual transferability of knowledge-free reasoning than knowledge
retrieval. Thus, we hypothesize that knowledge-free reasoning embeds in some
language-shared mechanism, while knowledge is stored separately in different
languages.

摘要：大型語言模型已在多種語言中展現出令人印象深刻的推理能力。然而，不同語言中的能力之間的關係較少被探討。在這項工作中，我們將推理任務的過程分解為兩個獨立的部分：知識擷取和無知識推理，並分析它們的跨語言可轉移性。透過調整和建構無知識推理資料集，我們發現無知識推理能力可以在各種來源目標語言方向之間幾乎完美地轉移，儘管在某些特定目標語言中資源的次要影響，而跨語言知識擷取顯著地阻礙了轉移。此外，透過分析推理任務期間的隱藏狀態和前饋網路神經元活化，我們發現隱藏表徵的較高相似性和活化神經元的較大重疊可以解釋無知識推理比知識擷取更好的跨語言可轉移性。因此，我們假設無知識推理嵌入在某種語言共享機制中，而知識則儲存在不同的語言中。

##### **Vision-Language Consistency Guided Multi-modal Prompt Learning for Blind AI Generated Image Quality Assessment**
2406.16641v1 by Jun Fu, Wei Zhou, Qiuping Jiang, Hantao Liu, Guangtao Zhai

Recently, textual prompt tuning has shown inspirational performance in
adapting Contrastive Language-Image Pre-training (CLIP) models to natural image
quality assessment. However, such uni-modal prompt learning method only tunes
the language branch of CLIP models. This is not enough for adapting CLIP models
to AI generated image quality assessment (AGIQA) since AGIs visually differ
from natural images. In addition, the consistency between AGIs and user input
text prompts, which correlates with the perceptual quality of AGIs, is not
investigated to guide AGIQA. In this letter, we propose vision-language
consistency guided multi-modal prompt learning for blind AGIQA, dubbed
CLIP-AGIQA. Specifically, we introduce learnable textual and visual prompts in
language and vision branches of CLIP models, respectively. Moreover, we design
a text-to-image alignment quality prediction task, whose learned
vision-language consistency knowledge is used to guide the optimization of the
above multi-modal prompts. Experimental results on two public AGIQA datasets
demonstrate that the proposed method outperforms state-of-the-art quality
assessment models. The source code is available at
https://github.com/JunFu1995/CLIP-AGIQA.

摘要：<paragraph>最近，文本提示调整在适应对比语言图像预训练 (CLIP) 模型到自然图像质量评估方面显示出鼓舞人心的表现。然而，这种单模态提示学习方法只调整了 CLIP 模型的语言分支。这不足以适应 CLIP 模型到 AI 生成的图像质量评估 (AGIQA)，因为 AGI 在视觉上不同于自然图像。此外，AGI 与用户输入文本提示之间的一致性（与 AGI 的感知质量相关）尚未被调查以指导 AGIQA。在这封信中，我们提出了视觉语言一致性指导的多模态提示学习用于盲 AGIQA，称为 CLIP-AGIQA。具体来说，我们在 CLIP 模型的语言和视觉分支中分别引入了可学习的文本和视觉提示。此外，我们设计了一个文本到图像对齐质量预测任务，其学习的视觉语言一致性知识用于指导上述多模态提示的优化。在两个公共 AGIQA 数据集上的实验结果表明，所提出的方法优于最先进的质量评估模型。源代码可在 https://github.com/JunFu1995/CLIP-AGIQA 获得。</paragraph>

##### **Feature Fusion for Human Activity Recognition using Parameter-Optimized Multi-Stage Graph Convolutional Network and Transformer Models**
2406.16638v1 by Mohammad Belal, Taimur Hassan, Abdelfatah Ahmed, Ahmad Aljarah, Nael Alsheikh, Irfan Hussain

Human activity recognition (HAR) is a crucial area of research that involves
understanding human movements using computer and machine vision technology.
Deep learning has emerged as a powerful tool for this task, with models such as
Convolutional Neural Networks (CNNs) and Transformers being employed to capture
various aspects of human motion. One of the key contributions of this work is
the demonstration of the effectiveness of feature fusion in improving HAR
accuracy by capturing spatial and temporal features, which has important
implications for the development of more accurate and robust activity
recognition systems. The study uses sensory data from HuGaDB, PKU-MMD, LARa,
and TUG datasets. Two model, the PO-MS-GCN and a Transformer were trained and
evaluated, with PO-MS-GCN outperforming state-of-the-art models. HuGaDB and TUG
achieved high accuracies and f1-scores, while LARa and PKU-MMD had lower
scores. Feature fusion improved results across datasets.

摘要：人類活動辨識 (HAR) 是研究領域中至關重要的一環，涉及使用電腦與機器視覺技術來理解人類動作。深度學習已成為此項任務中強大的工具，其中卷積神經網路 (CNN) 和 Transformer 等模型被用來擷取人類動作的各種面向。本研究的主要貢獻之一，是展示特徵融合在提升 HAR 精確度方面的效用，方法是擷取空間與時間特徵，這對於開發更精確且穩健的活動辨識系統具有重要的意義。本研究使用來自 HuGaDB、PKU-MMD、LARa 和 TUG 資料集的感測資料。兩個模型，PO-MS-GCN 和 Transformer 經過訓練和評估，其中 PO-MS-GCN 優於現有的最先進模型。HuGaDB 和 TUG 達到高準確度和 f1 分數，而 LARa 和 PKU-MMD 則有較低的分數。特徵融合改善了跨資料集的結果。

##### **ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models**
2406.16635v1 by Yash Akhauri, Ahmed F AbouElhamayed, Jordan Dotzel, Zhiru Zhang, Alexander M Rush, Safeen Huda, Mohamed S Abdelfattah

The high power consumption and latency-sensitive deployments of large
language models (LLMs) have motivated techniques like quantization and
sparsity. Contextual sparsity, where the sparsity pattern is input-dependent,
is crucial in LLMs because the permanent removal of attention heads or neurons
from LLMs can significantly degrade accuracy. Prior work has attempted to model
contextual sparsity using neural networks trained to predict activation
magnitudes, which can be used to dynamically prune structures with low
predicted activation magnitude. In this paper, we look beyond magnitude-based
pruning criteria to assess attention head and neuron importance in LLMs. We
developed a novel predictor called ShadowLLM, which can shadow the LLM behavior
and enforce better sparsity patterns, resulting in over 15% improvement in
end-to-end accuracy without increasing latency compared to previous methods.
ShadowLLM achieves up to a 20\% speed-up over the state-of-the-art DejaVu
framework. These enhancements are validated on models with up to 30 billion
parameters. Our code is available at
\href{https://github.com/abdelfattah-lab/shadow_llm/}{ShadowLLM}.

摘要：大型語言模型（LLM）的高功耗和延遲敏感部署激勵了量化和稀疏性等技術。脈絡稀疏性，其中稀疏性模式取決於輸入，在 LLM 中至關重要，因為永久移除 LLM 的注意力頭或神經元會顯著降低準確度。先前的研究嘗試使用神經網路建模脈絡稀疏性，該網路經過訓練來預測激活幅度，可用於動態剪枝具有低預測激活幅度的結構。在本文中，我們超越了基於幅度的剪枝標準來評估 LLM 中的注意力頭和神經元重要性。我們開發了一種稱為 ShadowLLM 的新穎預測器，它可以模擬 LLM 行為並強制執行更好的稀疏性模式，與以前的方法相比，端到端準確度提高了 15% 以上，而不會增加延遲。ShadowLLM 比最先進的 DejaVu 框架快 20%。這些增強功能已在最多 300 億個參數的模型上得到驗證。我們的代碼可在 \href{https://github.com/abdelfattah-lab/shadow_llm/}{ShadowLLM} 獲得。

##### **Hacking a surrogate model approach to XAI**
2406.16626v1 by Alexander Wilhelm, Katharina A. Zweig

In recent years, the number of new applications for highly complex AI systems
has risen significantly. Algorithmic decision-making systems (ADMs) are one of
such applications, where an AI system replaces the decision-making process of a
human expert. As one approach to ensure fairness and transparency of such
systems, explainable AI (XAI) has become more important. One variant to achieve
explainability are surrogate models, i.e., the idea to train a new simpler
machine learning model based on the input-output-relationship of a black box
model. The simpler machine learning model could, for example, be a decision
tree, which is thought to be intuitively understandable by humans. However,
there is not much insight into how well the surrogate model approximates the
black box.
  Our main assumption is that a good surrogate model approach should be able to
bring such a discriminating behavior to the attention of humans; prior to our
research we assumed that a surrogate decision tree would identify such a
pattern on one of its first levels. However, in this article we show that even
if the discriminated subgroup - while otherwise being the same in all
categories - does not get a single positive decision from the black box ADM
system, the corresponding question of group membership can be pushed down onto
a level as low as wanted by the operator of the system.
  We then generalize this finding to pinpoint the exact level of the tree on
which the discriminating question is asked and show that in a more realistic
scenario, where discrimination only occurs to some fraction of the
disadvantaged group, it is even more feasible to hide such discrimination.
  Our approach can be generalized easily to other surrogate models.

摘要：<paragraph>近年來，高度複雜 AI 系統的新應用數量大幅增加。演算法決策系統 (ADM) 就是其中一項應用，其中 AI 系統取代了人類專家的決策過程。作為確保此類系統公平性和透明度的方法之一，可解釋 AI (XAI) 變得更加重要。實現可解釋性的其中一種變體是代理模型，即基於黑盒模型的輸入輸出關係訓練一個新的更簡單機器學習模型的想法。例如，更簡單的機器學習模型可以是決策樹，而決策樹被認為是人類可以直觀理解的。然而，對於代理模型近似黑盒的程度並沒有太多見解。
我們的基本假設是，一個好的代理模型方法應該能夠將這種區別行為引起人類的注意；在我們的研究之前，我們假設代理決策樹會在其第一個層級中識別出這種模式。然而，在本文中，我們表明，即使被區別的子群在所有類別中都是相同的，但從黑盒 ADM 系統中沒有得到任何正向決策，系統操作員可以將群組成員資格問題下放到想要的層級。
然後，我們將此發現概括為精確定位詢問區別問題的樹的精確層級，並表明在更實際的情況中，其中歧視僅發生在弱勢群體的一部分，隱藏這種歧視甚至更可行。
我們的做法可以很容易地概括到其他代理模型。</paragraph>

##### **Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings**
2406.16611v1 by Andrea Posada, Daniel Rueckert, Felix Meissen, Philip Müller

Since the emergence of the Transformer architecture, language model
development has increased, driven by their promising potential. However,
releasing these models into production requires properly understanding their
behavior, particularly in sensitive domains such as medicine. Despite this
need, the medical literature still lacks technical assessments of pre-trained
language models, which are especially valuable in resource-constrained settings
in terms of computational power or limited budget. To address this gap, we
provide a comprehensive survey of language models in the medical domain. In
addition, we selected a subset of these models for thorough evaluation,
focusing on classification and text generation tasks. Our subset encompasses 53
models, ranging from 110 million to 13 billion parameters, spanning the three
families of Transformer-based models and from diverse knowledge domains. This
study employs a series of approaches for text classification together with
zero-shot prompting instead of model training or fine-tuning, which closely
resembles the limited resource setting in which many users of language models
find themselves. Encouragingly, our findings reveal remarkable performance
across various tasks and datasets, underscoring the latent potential of certain
models to contain medical knowledge, even without domain specialization.
Consequently, our study advocates for further exploration of model applications
in medical contexts, particularly in resource-constrained settings. The code is
available on https://github.com/anpoc/Language-models-in-medicine.

摘要：自 Transformer 架構問世以來，語言模型在潛力備受看好下，發展如火如荼。然而，將這些模型應用於生產環境，需要適當地了解其行為，特別是在醫學等敏感領域。儘管有此需求，醫學文獻仍缺乏對預先訓練語言模型的技術評估，而這在運算能力或預算有限的資源受限環境中特別有價值。為了彌補這個缺口，我們對醫學領域的語言模型進行了全面的調查。此外，我們挑選了其中一部分模型進行徹底評估，重點在於分類和文字生成任務。我們的子集涵蓋 53 個模型，參數從 1.1 億到 130 億不等，橫跨 Transformer 為基礎的模型的三個系列，且涵蓋多元的知識領域。本研究採用一系列文字分類方法，並搭配零次提示，而非模型訓練或微調，這與許多語言模型使用者身處的資源受限環境非常類似。令人振奮的是，我們的發現顯示在各種任務和資料集上都有傑出的表現，強調了某些模型在沒有領域專業知識的情況下，蘊含醫學知識的潛力。因此，我們的研究主張進一步探討模型在醫療環境中的應用，特別是在資源受限的環境中。程式碼可在 https://github.com/anpoc/Language-models-in-medicine 取得。

##### **Evaluating the Robustness of Deep-Learning Algorithm-Selection Models by Evolving Adversarial Instances**
2406.16609v1 by Emma Hart, Quentin Renau, Kevin Sim, Mohamad Alissa

Deep neural networks (DNN) are increasingly being used to perform
algorithm-selection in combinatorial optimisation domains, particularly as they
accommodate input representations which avoid designing and calculating
features. Mounting evidence from domains that use images as input shows that
deep convolutional networks are vulnerable to adversarial samples, in which a
small perturbation of an instance can cause the DNN to misclassify. However, it
remains unknown as to whether deep recurrent networks (DRN) which have recently
been shown promise as algorithm-selectors in the bin-packing domain are equally
vulnerable. We use an evolutionary algorithm (EA) to find perturbations of
instances from two existing benchmarks for online bin packing that cause
trained DRNs to misclassify: adversarial samples are successfully generated
from up to 56% of the original instances depending on the dataset. Analysis of
the new misclassified instances sheds light on the `fragility' of some training
instances, i.e. instances where it is trivial to find a small perturbation that
results in a misclassification and the factors that influence this. Finally,
the method generates a large number of new instances misclassified with a wide
variation in confidence, providing a rich new source of training data to create
more robust models.

摘要：深度神经網路（DNN）正越來越常被用於在組合最佳化領域執行演算法選擇，特別是因為它們容納避免設計和計算特徵的輸入表示。使用影像作為輸入的領域的累積證據顯示，深度卷積網路容易受到對抗性範例的影響，其中一個實例的微小擾動可能導致 DNN 錯誤分類。然而，最近被證明有望成為 bin-packing 領域演算法選擇器的深度遞迴網路 (DRN) 是否同樣容易受到攻擊，這仍然未知。我們使用演化演算法 (EA) 來找出來自兩個現有在線 bin-packing 基準的實例擾動，這些擾動會導致受過訓練的 DRN 錯誤分類：對抗性範例成功地從多達 56% 的原始實例中生成，具體取決於資料集。對新錯誤分類實例的分析揭示了一些訓練實例的「脆弱性」，即實例，其中很容易找到導致錯誤分類的微小擾動以及影響此的因素。最後，該方法產生大量的新的錯誤分類實例，並且信心變化很大，提供了一個豐富的新訓練資料來源，以建立更強大的模型。

##### **CLEAR: Can Language Models Really Understand Causal Graphs?**
2406.16605v1 by Sirui Chen, Mengying Xu, Kun Wang, Xingyu Zeng, Rui Zhao, Shengjie Zhao, Chaochao Lu

Causal reasoning is a cornerstone of how humans interpret the world. To model
and reason about causality, causal graphs offer a concise yet effective
solution. Given the impressive advancements in language models, a crucial
question arises: can they really understand causal graphs? To this end, we
pioneer an investigation into language models' understanding of causal graphs.
Specifically, we develop a framework to define causal graph understanding, by
assessing language models' behaviors through four practical criteria derived
from diverse disciplines (e.g., philosophy and psychology). We then develop
CLEAR, a novel benchmark that defines three complexity levels and encompasses
20 causal graph-based tasks across these levels. Finally, based on our
framework and benchmark, we conduct extensive experiments on six leading
language models and summarize five empirical findings. Our results indicate
that while language models demonstrate a preliminary understanding of causal
graphs, significant potential for improvement remains. Our project website is
at https://github.com/OpenCausaLab/CLEAR.

摘要：因果推理是人類詮釋世界的基石。為了對因果關係建模和推理，因果圖提供了一個簡潔而有效的解決方案。鑑於語言模型的驚人進步，一個關鍵問題出現了：它們真的能理解因果圖嗎？為此，我們率先對語言模型對因果圖的理解進行了調查。具體來說，我們開發了一個框架來定義因果圖理解，通過從不同學科（例如哲學和心理學）衍生的四個實用標準來評估語言模型的行為。然後，我們開發了 CLEAR，一個新的基準，它定義了三個複雜性級別，並涵蓋了這些級別中的 20 個基於因果圖的任務。最後，基於我們的框架和基準，我們對六個領先的語言模型進行了廣泛的實驗，並總結了五項實證發現。我們的結果表明，儘管語言模型展示了對因果圖的初步理解，但仍有很大的改進潛力。我們的項目網站位於 https://github.com/OpenCausaLab/CLEAR。

##### **QuadrupedGPT: Towards a Versatile Quadruped Agent in Open-ended Worlds**
2406.16578v1 by Ye Wang, Yuting Mei, Sipeng Zheng, Qin Jin

While pets offer companionship, their limited intelligence restricts advanced
reasoning and autonomous interaction with humans. Considering this, we propose
QuadrupedGPT, a versatile agent designed to master a broad range of complex
tasks with agility comparable to that of a pet. To achieve this goal, the
primary challenges include: i) effectively leveraging multimodal observations
for decision-making; ii) mastering agile control of locomotion and path
planning; iii) developing advanced cognition to execute long-term objectives.
QuadrupedGPT processes human command and environmental contexts using a large
multimodal model (LMM). Empowered by its extensive knowledge base, our agent
autonomously assigns appropriate parameters for adaptive locomotion policies
and guides the agent in planning a safe but efficient path towards the goal,
utilizing semantic-aware terrain analysis. Moreover, QuadrupedGPT is equipped
with problem-solving capabilities that enable it to decompose long-term goals
into a sequence of executable subgoals through high-level reasoning. Extensive
experiments across various benchmarks confirm that QuadrupedGPT can adeptly
handle multiple tasks with intricate instructions, demonstrating a significant
step towards the versatile quadruped agents in open-ended worlds. Our website
and codes can be found at https://quadruped-hub.github.io/Quadruped-GPT/.

摘要：儘管寵物提供陪伴，但牠們有限的智力限制了牠們與人類進行進階的推理和自主互動。考量到這一點，我們提出 QuadrupedGPT，這是一個多功能代理，旨在掌握廣泛的複雜任務，其靈活性可與寵物相媲美。為了達成這個目標，主要的挑戰包括：i) 有效利用多模態觀察進行決策；ii) 掌握靈活的運動控制和路徑規劃；iii) 發展進階認知以執行長期目標。QuadrupedGPT 使用大型多模態模型 (LMM) 處理人類命令和環境脈絡。我們的代理受其廣泛的知識庫賦能，能自主分配適當的參數以適應運動策略，並引導代理規劃一條安全且有效率的路徑以朝向目標，利用語義感知地形分析。此外，QuadrupedGPT 配備了解決問題的能力，使其能透過高層次推理將長期目標分解為一系列可執行的子目標。跨各種基準的廣泛實驗證實 QuadrupedGPT 能靈活處理多項任務，並包含複雜的指令，證明朝著開放式世界中多功能四足代理邁出了一大步。我們的網站和程式碼可以在 https://quadruped-hub.github.io/Quadruped-GPT/ 找到。

##### **Data Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting**
2406.16567v1 by Jiyue Jiang, Liheng Chen, Sheng Wang, Lingpeng Kong, Yu Li, Chuan Wu

Existing dialogue data augmentation (DA) techniques predominantly focus on
augmenting utterance-level dialogues, which makes it difficult to take dialogue
contextual information into account. The advent of large language models (LLMs)
has simplified the implementation of multi-turn dialogues. Due to absence of
professional understanding and knowledge, it remains challenging to deliver
satisfactory performance in low-resource domain, like psychological dialogue
dialogue. DA involves creating new training or prompting data based on the
existing data, which help the model better understand and generate
psychology-related responses. In this paper, we aim to address the issue of
multi-turn dialogue data augmentation for boosted performance in the psychology
domain. We propose a knowledge-driven progressive thought prompting method to
guide LLM to generate multi-turn psychology-related dialogue. This method
integrates a progressive thought generator, a psychology knowledge generator,
and a multi-turn dialogue generator. The thought generated by the progressive
thought generator serves as a prompt to prevent the generated dialogue from
having significant semantic deviations, while the psychology knowledge
generator produces psychological knowledge to serve as the dialogue history for
the LLM, guiding the dialogue generator to create multi-turn psychological
dialogue. To ensure the precision of multi-turn psychological dialogue
generation by LLM, a meticulous professional evaluation is required. Extensive
experiments conducted on three datasets related to psychological dialogue
verify the effectiveness of the proposed method.

摘要：現有對話資料擴充 (DA) 技術主要集中於擴充話語層級的對話，這使得難以考量對話的脈絡資訊。大型語言模型 (LLM) 的出現簡化了多輪對話的實作。由於缺乏專業的理解和知識，在低資源領域（例如心理對話對話）中提供令人滿意的表現仍然是一項挑戰。DA 涉及根據現有資料建立新的訓練或提示資料，這有助於模型更好地理解和產生與心理相關的回應。在本文中，我們旨在解決多輪對話資料擴充的問題，以提升心理領域的表現。我們提出了一種知識驅動的漸進式思考提示方法，以引導 LLM 產生多輪與心理相關的對話。此方法整合了一個漸進式思考產生器、一個心理知識產生器和一個多輪對話產生器。漸進式思考產生器產生的思考作為一個提示，以防止產生的對話產生重大的語義偏差，而心理知識產生器則產生心理知識作為 LLM 的對話歷程，引導對話產生器建立多輪心理對話。為了確保 LLM 產生多輪心理對話的精確性，需要進行細緻的專業評估。在與心理對話相關的三個資料集上進行的廣泛實驗驗證了所提出方法的有效性。

##### **Are there identifiable structural parts in the sentence embedding whole?**
2406.16563v1 by Vivi Nastase, Paola Merlo

Sentence embeddings from transformer models encode in a fixed length vector
much linguistic information. We explore the hypothesis that these embeddings
consist of overlapping layers of information that can be separated, and on
which specific types of information -- such as information about chunks and
their structural and semantic properties -- can be detected. We show that this
is the case using a dataset consisting of sentences with known chunk structure,
and two linguistic intelligence datasets, solving which relies on detecting
chunks and their grammatical number, and respectively, their semantic roles,
and through analyses of the performance on the tasks and of the internal
representations built during learning.

摘要：Transformer模型中的句子嵌入以固定長度向量編碼
許多語言資訊。我們探討假設這些嵌入
包含可分離的重疊資訊層，以及
特定資訊類型（例如關於塊及其結構和語義屬性的資訊）可被偵測。我們透過一個包含已知塊結構句子的資料集，以及兩個語言智能資料集來證明這一點，解決這些資料集仰賴偵測塊及其語法數字，以及它們的語義角色，並透過對任務執行和學習過程中建構的內部表徵的分析。

##### **EvalAlign: Evaluating Text-to-Image Models through Precision Alignment of Multimodal Large Models with Supervised Fine-Tuning to Human Annotations**
2406.16562v1 by Zhiyu Tan, Xiaomeng Yang, Luozheng Qin, Mengping Yang, Cheng Zhang, Hao Li

The recent advancements in text-to-image generative models have been
remarkable. Yet, the field suffers from a lack of evaluation metrics that
accurately reflect the performance of these models, particularly lacking
fine-grained metrics that can guide the optimization of the models. In this
paper, we propose EvalAlign, a metric characterized by its accuracy, stability,
and fine granularity. Our approach leverages the capabilities of Multimodal
Large Language Models (MLLMs) pre-trained on extensive datasets. We develop
evaluation protocols that focus on two key dimensions: image faithfulness and
text-image alignment. Each protocol comprises a set of detailed, fine-grained
instructions linked to specific scoring options, enabling precise manual
scoring of the generated images. We Supervised Fine-Tune (SFT) the MLLM to
align closely with human evaluative judgments, resulting in a robust evaluation
model. Our comprehensive tests across 24 text-to-image generation models
demonstrate that EvalAlign not only provides superior metric stability but also
aligns more closely with human preferences than existing metrics, confirming
its effectiveness and utility in model assessment.

摘要：最近文字轉圖像生成模型的進展非常顯著。然而，這個領域缺乏準確反映這些模型效能的評估指標，特別是缺乏可以引導模型最佳化的細緻指標。在本文中，我們提出 EvalAlign，這是一個以其準確性、穩定性和細緻粒度為特徵的指標。我們的做法利用了在廣泛數據集上預先訓練的多模態大型語言模型 (MLLM) 的功能。我們制定了評估協定，重點關注兩個關鍵面向：圖像保真度和文字圖像對齊。每個協定都包含一套詳細、細緻的說明，連結到特定的評分選項，以便精確手動評分生成的圖像。我們監督微調 (SFT) MLLM，以與人類評估判斷緊密對齊，從而產生一個強大的評估模型。我們對 24 個文字轉圖像生成模型進行的全面測試表明，EvalAlign 不僅提供了優越的指標穩定性，而且比現有指標更貼近人類偏好，證實了其在模型評估中的有效性和實用性。

##### **Homomorphisms and Embeddings of STRIPS Planning Models**
2406.16555v1 by Arnaud Lequen, Martin C. Cooper, Frédéric Maris

Determining whether two STRIPS planning instances are isomorphic is the
simplest form of comparison between planning instances. It is also a particular
case of the problem concerned with finding an isomorphism between a planning
instance $P$ and a sub-instance of another instance $P_0$ . One application of
such a mapping is to efficiently produce a compiled form containing all
solutions to P from a compiled form containing all solutions to $P_0$. We also
introduce the notion of embedding from an instance $P$ to another instance
$P_0$, which allows us to deduce that $P_0$ has no solution-plan if $P$ is
unsolvable. In this paper, we study the complexity of these problems. We show
that the first is GI-complete, and can thus be solved, in theory, in
quasi-polynomial time. While we prove the remaining problems to be NP-complete,
we propose an algorithm to build an isomorphism, when possible. We report
extensive experimental trials on benchmark problems which demonstrate
conclusively that applying constraint propagation in preprocessing can greatly
improve the efficiency of a SAT solver.

摘要：確定兩個 STRIPS 規劃實例是否同構是規劃實例之間最簡單的比較形式。這也是一個特定案例，涉及尋找規劃實例 P 和另一個實例 P0 的子實例之間的同構。這種對應的一個應用是有效產生一個編譯形式，其中包含 P 的所有解，而這個編譯形式包含 P0 的所有解。我們還引入了從實例 P 到另一個實例 P0 的嵌入概念，這讓我們可以推論出如果 P 無法解決，則 P0 沒有解決方案計畫。在本文中，我們研究了這些問題的複雜性。我們表明第一個是 GI 完整的，因此在理論上可以在準多項式時間內解決。雖然我們證明剩下的問題是 NP 完整的，但我們提出了一種演算法來建立同構，如果可能的話。我們報告了基準問題的廣泛實驗試驗，這些試驗確鑿地證明了在預處理中應用約束傳播可以極大地提高 SAT 求解器的效率。

##### **LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual Pre-training**
2406.16554v1 by Tong Zhu, Xiaoye Qu, Daize Dong, Jiacheng Ruan, Jingqi Tong, Conghui He, Yu Cheng

Mixture-of-Experts (MoE) has gained increasing popularity as a promising
framework for scaling up large language models (LLMs). However, training MoE
from scratch in a large-scale setting still suffers from data-hungry and
instability problems. Motivated by this limit, we investigate building MoE
models from existing dense large language models. Specifically, based on the
well-known LLaMA-2 7B model, we obtain an MoE model by: (1) Expert
Construction, which partitions the parameters of original Feed-Forward Networks
(FFNs) into multiple experts; (2) Continual Pre-training, which further trains
the transformed MoE model and additional gate networks. In this paper, we
comprehensively explore different methods for expert construction and various
data sampling strategies for continual pre-training. After these stages, our
LLaMA-MoE models could maintain language abilities and route the input tokens
to specific experts with part of the parameters activated. Empirically, by
training 200B tokens, LLaMA-MoE-3.5B models significantly outperform dense
models that contain similar activation parameters. The source codes and models
are available at https://github.com/pjlab-sys4nlp/llama-moe .

摘要：混合专家 (MoE) 作為一種有前途的大型語言模型 (LLM) 擴展框架，獲得越來越高的關注度。然而，從頭開始在大型環境中訓練 MoE 仍然會遇到資料需求大且不穩定的問題。基於此限制，我們探討從現有的稠密大型語言模型中建立 MoE 模型。具體來說，基於著名的 LLaMA-2 7B 模型，我們透過以下方式取得 MoE 模型：(1) 專家構造，將原始前饋網路 (FFN) 的參數分割成多個專家；(2) 持續預訓練，進一步訓練轉換後的 MoE 模型和額外的閘網路。在本文中，我們全面探討了專家構造的不同方法，以及持續預訓練的不同資料取樣策略。在這些階段之後，我們的 LLaMA-MoE 模型可以維護語言能力，並將輸入符號路由到特定專家，並啟用部分參數。根據經驗，透過訓練 200B 個符號，LLaMA-MoE-3.5B 模型明顯優於包含類似啟用參數的稠密模型。原始程式碼和模型可以在 https://github.com/pjlab-sys4nlp/llama-moe 取得。

##### **Inference of Sequential Patterns for Neural Message Passing in Temporal Graphs**
2406.16552v1 by Jan von Pichowski, Vincenzo Perri, Lisi Qarkaxhija, Ingo Scholtes

The modelling of temporal patterns in dynamic graphs is an important current
research issue in the development of time-aware GNNs. Whether or not a specific
sequence of events in a temporal graph constitutes a temporal pattern not only
depends on the frequency of its occurrence. We consider whether it deviates
from what is expected in a temporal graph where timestamps are randomly
shuffled. While accounting for such a random baseline is important to model
temporal patterns, it has mostly been ignored by current temporal graph neural
networks. To address this issue we propose HYPA-DBGNN, a novel two-step
approach that combines (i) the inference of anomalous sequential patterns in
time series data on graphs based on a statistically principled null model, with
(ii) a neural message passing approach that utilizes a higher-order De Bruijn
graph whose edges capture overrepresented sequential patterns. Our method
leverages hypergeometric graph ensembles to identify anomalous edges within
both first- and higher-order De Bruijn graphs, which encode the temporal
ordering of events. The model introduces an inductive bias that enhances model
interpretability. We evaluate our approach for static node classification using
benchmark datasets and a synthetic dataset that showcases its ability to
incorporate the observed inductive bias regarding over- and under-represented
temporal edges. We demonstrate the framework's effectiveness in detecting
similar patterns within empirical datasets, resulting in superior performance
compared to baseline methods in node classification tasks. To the best of our
knowledge, our work is the first to introduce statistically informed GNNs that
leverage temporal and causal sequence anomalies. HYPA-DBGNN represents a path
for bridging the gap between statistical graph inference and neural graph
representation learning, with potential applications to static GNNs.

摘要：動態圖形中時間模式的建模是時間感知 GNN 發展中一個重要的當前研究議題。時間圖形中特定事件序列是否構成時間模式，不僅取決於其出現的頻率。我們考慮它是否偏離了時間戳隨機洗牌的時間圖形中的預期。雖然考量此類隨機基線對於建模時間模式很重要，但目前的時態圖形神經網路大多忽略了這一點。為了解決這個問題，我們提出了 HYPA-DBGNN，這是一種新穎的兩步驟方法，它結合了 (i) 基於統計原理的空模型在圖形上推論異常序列模式，以及 (ii) 利用邊緣捕捉過度表示序列模式的高階 De Bruijn 圖形的神經訊息傳遞方法。我們的模型利用超幾何圖形集合來識別一階和高階 De Bruijn 圖形中的異常邊緣，這些邊緣編碼事件的時間順序。該模型引入了增強模型可解釋性的歸納偏差。我們使用基準資料集和一個合成資料集評估了我們在靜態節點分類中的方法，該資料集展示了其納入關於過度表示和表示不足的時間邊緣的觀察歸納偏差的能力。我們展示了該框架在檢測經驗資料集中類似模式方面的有效性，與節點分類任務中的基準方法相比，具有更優異的效能。據我們所知，我們的研究首次引入了利用時間和因果序列異常的統計訊息 GNN。HYPA-DBGNN 代表了彌合統計圖形推論和神經圖形表示學習之間差距的途徑，並具有應用於靜態 GNN 的潛力。

##### **C-LLM: Learn to Check Chinese Spelling Errors Character by Character**
2406.16536v1 by Kunting Li, Yong Hu, Liang He, Fandong Meng, Jie Zhou

Chinese Spell Checking (CSC) aims to detect and correct spelling errors in
sentences. Despite Large Language Models (LLMs) exhibit robust capabilities and
are widely applied in various tasks, their performance on CSC is often
unsatisfactory. We find that LLMs fail to meet the Chinese character-level
constraints of the CSC task, namely equal length and phonetic similarity,
leading to a performance bottleneck. Further analysis reveal that this issue
stems from the granularity of tokenization, as current mixed character-word
tokenization struggles to satisfy these character-level constraints. To address
this issue, we propose C-LLM, a Large Language Model-based Chinese Spell
Checking method that learns to check errors Character by Character.
Character-level tokenization enables the model to learn character-level
alignment, effectively mitigating issues related to character-level
constraints. Furthermore, CSC is simplified to replication-dominated and
substitution-supplemented tasks. Experiments on two CSC benchmarks demonstrate
that C-LLM achieves an average improvement of 10% over existing methods.
Specifically, it shows a 2.1% improvement in general scenarios and a
significant 12% improvement in vertical domain scenarios, establishing
state-of-the-art performance. The source code can be accessed at
https://github.com/ktlKTL/C-LLM.

摘要：中文拼寫檢查 (CSC) 旨在偵測和修正句子中的拼寫錯誤。儘管大型語言模型 (LLM) 展現強大的功能，並廣泛應用於各種任務中，它們在 CSC 上的表現通常不盡人意。我們發現 LLM 無法滿足 CSC 任務的中文字元層級限制，即等長和音似，導致效能瓶頸。進一步的分析顯示，這個問題源於標記化的粒度，因為目前混合字元詞彙標記化難以滿足這些字元層級限制。為了解決這個問題，我們提出 C-LLM，一種基於大型語言模型的中文拼寫檢查方法，學習逐字檢查錯誤。字元層級標記化讓模型能夠學習字元層級比對，有效減輕與字元層級限制相關的問題。此外，CSC 被簡化為以複製為主的替換補充任務。在兩個 CSC 基準上的實驗證明，C-LLM 比現有方法平均提升了 10%。具體來說，它在一般場景中提升了 2.1%，在垂直領域場景中提升了顯著的 12%，建立了最先進的效能。原始碼可以在 https://github.com/ktlKTL/C-LLM 取得。

##### **Token-based Decision Criteria Are Suboptimal in In-context Learning**
2406.16535v1 by Hakaze Cho, Yoshihiro Sakai, Mariko Kato, Kenshiro Tanaka, Akira Ishii, Naoya Inoue

In-Context Learning (ICL) typically utilizes classification criteria from
probabilities of manually selected label tokens. However, we argue that such
token-based classification criteria lead to suboptimal decision boundaries,
despite delicate calibrations through translation and constrained rotation. To
address this problem, we propose Hidden Calibration, which renounces token
probabilities and uses the nearest centroid classifier on the LM's last hidden
states. In detail, we use the nearest centroid classification on the hidden
states, assigning the category of the nearest centroid previously observed from
a few-shot calibration set to the test sample as the predicted label. Our
experiments on 3 models and 10 classification datasets indicate that Hidden
Calibration consistently outperforms current token-based calibrations by about
20%. Our further analysis demonstrates that Hidden Calibration finds better
classification criteria with less inter-categories overlap, and LMs provide
linearly separable intra-category clusters with the help of demonstrations,
which supports Hidden Calibration and gives new insights into the conventional
ICL.

摘要：語境學習 (ICL) 通常利用人工選取標籤權杖的機率作為分類標準。然而，我們認為，儘管透過翻譯和受限旋轉進行精細校準，此類基於權杖的分類標準仍會導致次佳決策邊界。為了解決此問題，我們提出隱藏校準，放棄權杖機率，並在 LM 的最後隱藏狀態上使用最近質心分類器。詳細來說，我們在隱藏狀態上使用最近質心分類，將先前從少次校準集中觀察到的最近質心類別指定給測試樣本作為預測標籤。我們在 3 個模型和 10 個分類資料集上的實驗顯示，隱藏校準始終比目前的基於權杖的校準高出約 20%。我們的進一步分析表明，隱藏校準會找到類別間重疊較少的更佳分類標準，而 LM 在示範的幫助下提供線性可分離的類別內群集，這支援隱藏校準，並對傳統的 ICL 提供新的見解。

##### **Towards Better Graph-based Cross-document Relation Extraction via Non-bridge Entity Enhancement and Prediction Debiasing**
2406.16529v1 by Hao Yue, Shaopeng Lai, Chengyi Yang, Liang Zhang, Junfeng Yao, Jinsong Su

Cross-document Relation Extraction aims to predict the relation between
target entities located in different documents. In this regard, the dominant
models commonly retain useful information for relation prediction via bridge
entities, which allows the model to elaborately capture the intrinsic
interdependence between target entities. However, these studies ignore the
non-bridge entities, each of which co-occurs with only one target entity and
offers the semantic association between target entities for relation
prediction. Besides, the commonly-used dataset--CodRED contains substantial NA
instances, leading to the prediction bias during inference. To address these
issues, in this paper, we propose a novel graph-based cross-document RE model
with non-bridge entity enhancement and prediction debiasing. Specifically, we
use a unified entity graph to integrate numerous non-bridge entities with
target entities and bridge entities, modeling various associations between
them, and then use a graph recurrent network to encode this graph. Finally, we
introduce a novel debiasing strategy to calibrate the original prediction
distribution. Experimental results on the closed and open settings show that
our model significantly outperforms all baselines, including the GPT-3.5-turbo
and InstructUIE, achieving state-of-the-art performance. Particularly, our
model obtains 66.23% and 55.87% AUC points in the official
leaderboard\footnote{\url{https://codalab.lisn.upsaclay.fr/competitions/3770#results}}
under the two settings, respectively, ranking the first place in all
submissions since December 2023. Our code is available at
https://github.com/DeepLearnXMU/CoRE-NEPD.

摘要：跨文件關係抽取旨在預測位於不同文件中的目標實體之間的關係。在這方面，主流模型通常透過橋接實體保留關係預測的有用資訊，這使得模型能夠精細地捕捉目標實體之間的內在相互依賴性。然而，這些研究忽略了非橋接實體，每個實體僅與一個目標實體並存，並提供目標實體之間的語義關聯以進行關係預測。此外，常用的資料集——CodRED 包含大量的 NA 實例，導致在推理過程中出現預測偏差。為了解決這些問題，在本文中，我們提出了一個新穎的基於圖形的跨文件 RE 模型，具有非橋接實體增強和預測去偏差。具體來說，我們使用一個統一的實體圖形將大量的非橋接實體與目標實體和橋接實體整合在一起，建模它們之間的各種關聯，然後使用圖形遞迴網路對這個圖形進行編碼。最後，我們引入了一種新穎的去偏差策略來校準原始預測分佈。在封閉和開放設置上的實驗結果表明，我們的模型明顯優於所有基線，包括 GPT-3.5-turbo 和 InstructUIE，達到了最先進的效能。特別是，我們的模型在官方排行榜\footnote{\url{https://codalab.lisn.upsaclay.fr/competitions/3770#results}}中分別在兩個設置下獲得了 66.23% 和 55.87% 的 AUC 點數，自 2023 年 12 月以來在所有提交中排名第一。我們的程式碼可在 https://github.com/DeepLearnXMU/CoRE-NEPD 中取得。

##### **Evaluating the Ability of Large Language Models to Reason about Cardinal Directions**
2406.16528v1 by Anthony G Cohn, Robert E Blackwell

We investigate the abilities of a representative set of Large language Models
(LLMs) to reason about cardinal directions (CDs). To do so, we create two
datasets: the first, co-created with ChatGPT, focuses largely on recall of
world knowledge about CDs; the second is generated from a set of templates,
comprehensively testing an LLM's ability to determine the correct CD given a
particular scenario. The templates allow for a number of degrees of variation
such as means of locomotion of the agent involved, and whether set in the first
, second or third person. Even with a temperature setting of zero, Our
experiments show that although LLMs are able to perform well in the simpler
dataset, in the second more complex dataset no LLM is able to reliably
determine the correct CD, even with a temperature setting of zero.

摘要：我們調查一大組大型語言模型 (LLM) 推論基本方向 (CD) 的能力。為此，我們建立兩個資料集：第一個資料集與 ChatGPT 共同建立，主要專注於回憶關於 CD 的世界知識；第二個資料集則從一組範本產生，全面測試 LLM 在特定場景下確定正確 CD 的能力。這些範本允許進行許多程度的變化，例如所涉及代理的運動方式，以及是否設定在第一、第二或第三人稱。即使在溫度設定為零的情況下，我們的實驗顯示，儘管 LLM 能在較簡單的資料集中表現良好，但在第二個較複雜的資料集中，即使在溫度設定為零的情況下，也沒有任何 LLM 能可靠地確定正確的 CD。

##### **NARRepair: Non-Autoregressive Code Generation Model for Automatic Program Repair**
2406.16526v1 by Zhenyu Yang, Zhen Yang, Zhongxing Yu

With the advancement of deep learning techniques, the performance of
Automatic Program Repair(APR) techniques has reached a new level. Previous deep
learning-based APR techniques essentially modified program sentences in the
Autoregressive(AR) manner, which predicts future values based on past values.
Due to the manner of word-by-word generation, the AR-based APR technique has a
huge time delay. This negative consequence overshadows the widespread adoption
of APR techniques in real-life software development.
  To address the issue, we aim to apply the Non-Autoregressive(NAR) method to
the APR task, which can output target code in a parallel manner to avoid huge
inference delays. To effectively adapt the NAR manner for the APR task, we in
this paper propose NARRepair, the first customized NAR code generation model
for the APR task. The NARRepair features three major novelties, including 1)
using repair actions to alleviate the over-correction issue, 2) extracting
dependency information from AST to alleviate the issue of lacking inter-word
dependency information, 3) employing two-stage decoding to alleviate the issue
of lacking contextual information. We evaluated NARRepair on three widely used
datasets in the APR community, and the results show that our technique can
significantly improve the inference speed while maintaining high repair
accuracy.

摘要：隨著深度學習技術的進步，自動程式修復 (APR) 技術的效能已達到新的層級。先前的基於深度學習的 APR 技術基本上以自迴歸 (AR) 的方式修改程式句子，它根據過去的值預測未來值。由於逐字產生的方式，基於 AR 的 APR 技術具有巨大的時間延遲。這個負面後果影響了 APR 技術在實際軟體開發中的廣泛採用。
為了解決這個問題，我們旨在將非自迴歸 (NAR) 方法應用於 APR 任務，它可以並行輸出目標程式碼以避免巨大的推論延遲。為了有效地將 NAR 方式改編為 APR 任務，我們在本文中提出了 NARRepair，這是第一個針對 APR 任務量身打造的 NAR 程式碼生成模型。NARRepair 具有三大創新，包括 1) 使用修復動作來減輕過度修正問題，2) 從 AST 中提取依賴資訊以減輕缺乏字元間依賴資訊的問題，3) 採用兩階段解碼來減輕缺乏上下文資訊的問題。我們在 APR 社群中廣泛使用的三個資料集上評估了 NARRepair，結果顯示我們的技術可以在維持高修復精確度的同時，顯著提升推論速度。

##### **The Privileged Students: On the Value of Initialization in Multilingual Knowledge Distillation**
2406.16524v1 by Haryo Akbarianto Wibowo, Thamar Solorio, Alham Fikri Aji

Knowledge distillation (KD) has proven to be a successful strategy to improve
the performance of a smaller model in many NLP tasks. However, most of the work
in KD only explores monolingual scenarios. In this paper, we investigate the
value of KD in multilingual settings. We find the significance of KD and model
initialization by analyzing how well the student model acquires multilingual
knowledge from the teacher model. Our proposed method emphasizes copying the
teacher model's weights directly to the student model to enhance
initialization. Our finding shows that model initialization using copy-weight
from the fine-tuned teacher contributes the most compared to the distillation
process itself across various multilingual settings. Furthermore, we
demonstrate that efficient weight initialization preserves multilingual
capabilities even in low-resource scenarios.

摘要：知識蒸餾 (KD) 已證明是一種成功的策略，可改善小型模型在許多 NLP 任務中的效能。然而，KD 中的大部分工作僅探索單語情境。在本文中，我們研究 KD 在多語系設定中的價值。我們透過分析學生模型從教師模型中獲取多語系知識的程度，發現 KD 和模型初始化的重要性。我們提出的方法強調直接將教師模型的權重複製到學生模型，以增強初始化。我們的發現顯示，與各種多語系設定中的蒸餾過程本身相比，使用微調教師的複製權重進行模型初始化的貢獻最大。此外，我們證明，即使在低資源情境中，有效率的權重初始化也能保留多語系能力。

##### **Carrot and Stick: Inducing Self-Motivation with Positive & Negative Feedback**
2406.16521v1 by Jimin Sohn, Jeihee Cho, Junyong Lee, Songmu Heo, Ji-Eun Han, David R. Mortensen

Positive thinking is thought to be an important component of self-motivation
in various practical fields such as education and the workplace. Previous work,
including sentiment transfer and positive reframing, has focused on the
positive side of language. However, self-motivation that drives people to reach
their goals has not yet been studied from a computational perspective.
Moreover, negative feedback has not yet been explored, even though positive and
negative feedback are both necessary to grow self-motivation. To facilitate
self-motivation, we propose CArrot and STICk (CASTIC) dataset, consisting of
12,590 sentences with 5 different strategies for enhancing self-motivation. Our
data and code are publicly available at here.

摘要：正面思考被認為是各種實務領域（例如教育和職場）中自我激勵的重要組成部分。先前的研究（包括情緒轉移和正面重構）著重於語言的正面面向。然而，驅使人們達成目標的自我激勵尚未從計算觀點進行研究。此外，儘管正面和負面回饋對於培養自我激勵都是必要的，但負面回饋尚未被探討。為了促進自我激勵，我們提出 CArrot and STICk (CASTIC) 資料集，其中包含 12,590 個句子，採用 5 種不同的策略來增強自我激勵。我們的資料和程式碼在此公開提供。

##### **Large Vocabulary Size Improves Large Language Models**
2406.16508v1 by Sho Takase, Ryokan Ri, Shun Kiyono, Takuya Kato

This paper empirically investigates the relationship between subword
vocabulary size and the performance of large language models (LLMs) to provide
insights on how to define the vocabulary size. Experimental results show that
larger vocabulary sizes lead to better performance in LLMs. Moreover, we
consider a continual training scenario where a pre-trained language model is
trained on a different target language. We introduce a simple method to use a
new vocabulary instead of the pre-defined one. We show that using the new
vocabulary outperforms the model with the vocabulary used in pre-training.

摘要：本文實證探討子詞彙彙大小與大型語言模型 (LLM) 效能之間的關係，以提供有關如何定義彙大小的見解。實驗結果顯示，較大的彙大小會提升 LLM 的效能。此外，我們考慮一個持續訓練情境，其中預先訓練的語言模型會以不同的目標語言進行訓練。我們提出一個簡單的方法，使用新的彙大小，而非預先定義的彙大小。我們顯示使用新的彙大小，其效能優於在預訓練中使用彙大小的模型。

##### **UNICAD: A Unified Approach for Attack Detection, Noise Reduction and Novel Class Identification**
2406.16501v1 by Alvaro Lopez Pellicer, Kittipos Giatgong, Yi Li, Neeraj Suri, Plamen Angelov

As the use of Deep Neural Networks (DNNs) becomes pervasive, their
vulnerability to adversarial attacks and limitations in handling unseen classes
poses significant challenges. The state-of-the-art offers discrete solutions
aimed to tackle individual issues covering specific adversarial attack
scenarios, classification or evolving learning. However, real-world systems
need to be able to detect and recover from a wide range of adversarial attacks
without sacrificing classification accuracy and to flexibly act in {\bf unseen}
scenarios. In this paper, UNICAD, is proposed as a novel framework that
integrates a variety of techniques to provide an adaptive solution.
  For the targeted image classification, UNICAD achieves accurate image
classification, detects unseen classes, and recovers from adversarial attacks
using Prototype and Similarity-based DNNs with denoising autoencoders. Our
experiments performed on the CIFAR-10 dataset highlight UNICAD's effectiveness
in adversarial mitigation and unseen class classification, outperforming
traditional models.

摘要：隨著深度神經網路 (DNN) 的使用變得普遍，它們對抗攻擊的脆弱性以及在處理未見類別時的限制，構成了重大的挑戰。最先進的技術提供離散的解決方案，旨在解決涵蓋特定對抗攻擊情境、分類或演化學習的個別問題。然而，現實世界的系統需要能夠偵測和從各種對抗攻擊中復原，而不會犧牲分類準確性，並靈活地在「未見」情境中採取行動。在本文中，UNICAD 被提出作為一個新的框架，它整合了各種技術以提供適應性解決方案。對於目標影像分類，UNICAD 使用具有去噪自動編碼器的原型和基於相似性的 DNN，達成準確的影像分類、偵測未見類別，並從對抗攻擊中復原。我們在 CIFAR-10 資料集上進行的實驗突顯了 UNICAD 在對抗緩解和未見類別分類方面的效能，優於傳統模型。

##### **OTCE: Hybrid SSM and Attention with Cross Domain Mixture of Experts to construct Observer-Thinker-Conceiver-Expresser**
2406.16495v2 by Jingze Shi, Ting Xie, Bingheng Wu, Chunjun Zheng, Kai Wang

Recent research has shown that combining Mamba with Transformer architecture,
which has selective state space and quadratic self-attention mechanism,
outperforms using Mamba or Transformer architecture alone in language modeling
tasks. The quadratic self-attention mechanism effectively alleviates the
shortcomings of selective state space in handling long-term dependencies of any
element in the sequence. We propose a position information injection method
that connects the selective state space model with the quadratic attention, and
integrates these two architectures with hybrid experts with cross-sharing
domains, so that we can enjoy the advantages of both. We design a new
architecture with a more biomimetic idea: Observer-Thinker-Conceiver-Expresser
(OTCE), which can compete with well-known medium-scale open-source language
models on a small scale in language modeling tasks.

摘要：最近的研究表明，将 Mamba 与 Transformer 架构相结合，
它具有选择性状态空间和二次自注意力机制，
在语言建模任务中优于单独使用 Mamba 或 Transformer 架构。
二次自注意力机制有效地缓解了选择性状态空间在处理序列中任何元素的长期依赖关系方面的缺点。我们提出了一种位置信息注入方法，将选择性状态空间模型与二次注意力相连接，并将这两个架构与具有交叉共享域的混合专家相集成，这样我们就可以同时享受两者的优势。我们设计了一种具有更仿生思想的新架构：观察者-思考者-构思者-表达者 (OTCE)，它可以在语言建模任务中与众所周知的中等规模开源语言模型在小规模上竞争。

##### **Cross-domain Transfer of Valence Preferences via a Meta-optimization Approach**
2406.16494v1 by Chuang Zhao, Hongke Zhao, Ming He, Xiaomeng Li, Jianping Fan

Cross-domain recommendation offers a potential avenue for alleviating data
sparsity and cold-start problems. Embedding and mapping, as a classic
cross-domain research genre, aims to identify a common mapping function to
perform representation transformation between two domains. Nevertheless,
previous coarse-grained preference representations, non-personalized mapping
functions, and excessive reliance on overlapping users limit their performance,
especially in scenarios where overlapping users are sparse. To address
aforementioned challenges, we propose a novel cross-domain approach, namely
CVPM. CVPM formalizes cross-domain interest transfer as a hybrid architecture
of parametric meta-learning and self-supervised learning, which not only
transfers user preferences at a finer level, but also enables signal
enhancement with the knowledge of non-overlapping users. Specifically, with
deep insights into user preferences and valence preference theory, we believe
that there exists significant difference between users' positive preferences
and negative behaviors, and thus employ differentiated encoders to learn their
distributions. In particular, we further utilize the pre-trained model and item
popularity to sample pseudo-interaction items to ensure the integrity of both
distributions. To guarantee the personalization of preference transfer, we
treat each user's mapping as two parts, the common transformation and the
personalized bias, where the network used to generate the personalized bias is
output by a meta-learner. Furthermore, in addition to the supervised loss for
overlapping users, we design contrastive tasks for non-overlapping users from
both group and individual-levels to avoid model skew and enhance the semantics
of representations. Exhaustive data analysis and extensive experimental results
demonstrate the effectiveness and advancement of our proposed framework.

摘要：跨網域推薦提供了解決資料稀疏性和冷啟動問題的潛在途徑。嵌入和對應，作為經典的跨網域研究類型，旨在識別一個通用的對應函數，以執行兩個網域之間的表示轉換。然而，先前的粗粒度偏好表示、非個人化對應函數以及過度依賴重疊使用者會限制其效能，特別是在重疊使用者稀疏的情況下。為了應對上述挑戰，我們提出了一種新穎的跨網域方法，即 CVPM。CVPM 將跨網域興趣傳輸形式化為參數化元學習和自監督學習的混合架構，這不僅可以在更精細的層級傳輸使用者偏好，還能透過非重疊使用者的知識增強訊號。具體來說，透過深入了解使用者偏好和效價偏好理論，我們相信使用者的正向偏好和負向行為之間存在顯著差異，因此採用差異化編碼器來學習其分佈。特別是，我們進一步利用預先訓練的模型和項目熱門程度來取樣偽互動項目，以確保兩個分佈的完整性。為了保證偏好傳輸的個人化，我們將每個使用者的對應視為兩部分，即通用轉換和個人化偏差，其中用於產生個人化偏差的網路是由元學習器輸出的。此外，除了重疊使用者的監督損失外，我們還針對來自群組和個人層級的非重疊使用者設計對比任務，以避免模型偏差並增強表示的語義。詳盡的資料分析和廣泛的實驗結果證明了我們提出的架構的有效性和進步性。

##### **eagerlearners at SemEval2024 Task 5: The Legal Argument Reasoning Task in Civil Procedure**
2406.16490v1 by Hoorieh Sabzevari, Mohammadmostafa Rostamkhani, Sauleh Eetemadi

This study investigates the performance of the zero-shot method in
classifying data using three large language models, alongside two models with
large input token sizes and the two pre-trained models on legal data. Our main
dataset comes from the domain of U.S. civil procedure. It includes summaries of
legal cases, specific questions, potential answers, and detailed explanations
for why each solution is relevant, all sourced from a book aimed at law
students. By comparing different methods, we aimed to understand how
effectively they handle the complexities found in legal datasets. Our findings
show how well the zero-shot method of large language models can understand
complicated data. We achieved our highest F1 score of 64% in these experiments.

摘要：本研究調查了零次學習方法在使用三個大型語言模型分類資料時的效能，以及兩個輸入符號大小較大的模型和兩個法律資料預先訓練模型的效能。我們的資料集主要來自美國民事訴訟領域。它包含法律案例摘要、具體問題、潛在答案和每個解決方案相關性的詳細說明，所有這些都來自一本針對法律學生的書籍。透過比較不同的方法，我們旨在了解它們如何有效地處理法律資料集中發現的複雜性。我們的研究結果顯示了大型語言模型的零次學習方法如何理解複雜的資料。我們在這些實驗中達到了 64% 的最高 F1 分數。

##### **Deepfake tweets automatic detection**
2406.16489v1 by Adam Frej, Adrian Kaminski, Piotr Marciniak, Szymon Szmajdzinski, Soveatin Kuntur, Anna Wroblewska

This study addresses the critical challenge of detecting DeepFake tweets by
leveraging advanced natural language processing (NLP) techniques to distinguish
between genuine and AI-generated texts. Given the increasing prevalence of
misinformation, our research utilizes the TweepFake dataset to train and
evaluate various machine learning models. The objective is to identify
effective strategies for recognizing DeepFake content, thereby enhancing the
integrity of digital communications. By developing reliable methods for
detecting AI-generated misinformation, this work contributes to a more
trustworthy online information environment.

摘要：本研究透過運用先進的自然語言處理 (NLP) 技術，來區分真實和 AI 生成的文字，以解決偵測 DeepFake 推文的關鍵挑戰。鑑於錯誤資訊的盛行，我們的研究利用 TweepFake 資料集來訓練和評估各種機器學習模型。目標是找出辨識 DeepFake 內容的有效策略，進而提升數位通訊的完整性。透過開發可靠的方法來偵測 AI 生成的錯誤資訊，這項工作有助於建立一個更值得信賴的線上資訊環境。

##### **Towards Comprehensive Preference Data Collection for Reward Modeling**
2406.16486v1 by Yulan Hu, Qingyang Li, Sheng Ouyang, Ge Chen, Kaihui Chen, Lijun Mei, Xucheng Ye, Fuzheng Zhang, Yong Liu

Reinforcement Learning from Human Feedback (RLHF) facilitates the alignment
of large language models (LLMs) with human preferences, thereby enhancing the
quality of responses generated. A critical component of RLHF is the reward
model, which is trained on preference data and outputs a scalar reward during
the inference stage. However, the collection of preference data still lacks
thorough investigation. Recent studies indicate that preference data is
collected either by AI or humans, where chosen and rejected instances are
identified among pairwise responses. We question whether this process
effectively filters out noise and ensures sufficient diversity in collected
data. To address these concerns, for the first time, we propose a comprehensive
framework for preference data collection, decomposing the process into four
incremental steps: Prompt Generation, Response Generation, Response Filtering,
and Human Labeling. This structured approach ensures the collection of
high-quality preferences while reducing reliance on human labor. We conducted
comprehensive experiments based on the data collected at different stages,
demonstrating the effectiveness of the proposed data collection method.

摘要：強化學習來自人類回饋（RLHF）促進大型語言模型（LLM）與人類偏好的對齊，從而提升產生的回應品質。RLHF 的關鍵組成部分是獎勵模型，該模型會針對偏好資料進行訓練，並在推論階段輸出一個標量獎勵。然而，偏好資料的收集仍然缺乏徹底的調查。最近的研究指出，偏好資料是由 AI 或人類收集，其中會從成對的回應中找出被選擇和被拒絕的實例。我們質疑這個過程是否能有效濾除雜訊並確保收集到的資料有足夠的多樣性。為了解決這些問題，我們首次提出一個偏好資料收集的全面架構，將這個過程分解成四個遞增的步驟：提示產生、回應產生、回應過濾和人類標記。這種結構化的方法確保收集到高品質的偏好，同時減少對人力的依賴。我們根據在不同階段收集到的資料進行了全面的實驗，證明了所提出的資料收集方法的有效性。

##### **Emerging NeoHebbian Dynamics in Forward-Forward Learning: Implications for Neuromorphic Computing**
2406.16479v1 by Erik B. Terres-Escudero, Javier Del Ser, Pablo García-Bringas

Advances in neural computation have predominantly relied on the gradient
backpropagation algorithm (BP). However, the recent shift towards
non-stationary data modeling has highlighted the limitations of this heuristic,
exposing that its adaptation capabilities are far from those seen in biological
brains. Unlike BP, where weight updates are computed through a reverse error
propagation path, Hebbian learning dynamics provide synaptic updates using only
information within the layer itself. This has spurred interest in biologically
plausible learning algorithms, hypothesized to overcome BP's shortcomings. In
this context, Hinton recently introduced the Forward-Forward Algorithm (FFA),
which employs local learning rules for each layer and has empirically proven
its efficacy in multiple data modeling tasks. In this work we argue that when
employing a squared Euclidean norm as a goodness function driving the local
learning, the resulting FFA is equivalent to a neo-Hebbian Learning Rule. To
verify this result, we compare the training behavior of FFA in analog networks
with its Hebbian adaptation in spiking neural networks. Our experiments
demonstrate that both versions of FFA produce similar accuracy and latent
distributions. The findings herein reported provide empirical evidence linking
biological learning rules with currently used training algorithms, thus paving
the way towards extrapolating the positive outcomes from FFA to Hebbian
learning rules. Simultaneously, our results imply that analog networks trained
under FFA could be directly applied to neuromorphic computing, leading to
reduced energy usage and increased computational speed.

摘要：神經運算的進展主要依賴於梯度反向傳播演算法 (BP)。然而，最近朝向非平穩資料建模的轉變突顯了這種啟發法的限制，揭露其適應能力遠低於生物大腦。與 BP 不同，其中權重更新是透過反向誤差傳播路徑計算，赫布學習動態僅使用層本身內的資訊提供突觸更新。這激發了對生物上合理的學習演算法的興趣，假設可以克服 BP 的缺點。在此脈絡中，Hinton 最近引入了正向正向演算法 (FFA)，它為每一層採用局部學習規則，並在其效能上經過多項資料建模任務的實證證明。在這項工作中，我們主張，當採用平方歐幾里得範數作為驅動局部學習的適當性函數時，所產生的 FFA 等同於新赫布學習規則。為了驗證此結果，我們比較類比網路中 FFA 的訓練行為與其在脈衝神經網路中的赫布適應。我們的實驗證明，FFA 的兩個版本都產生類似的準確度和潛在分佈。本文報告的發現提供實證，將生物學習規則與目前使用的訓練演算法連結，因此為從 FFA 推論出赫布學習規則的正面結果鋪路。同時，我們的結果暗示，在 FFA 下訓練的類比網路可以直接應用於類腦運算，進而減少能源使用並提升運算速度。

##### **DaLPSR: Leverage Degradation-Aligned Language Prompt for Real-World Image Super-Resolution**
2406.16477v1 by Aiwen Jiang, Zhi Wei, Long Peng, Feiqiang Liu, Wenbo Li, Mingwen Wang

Image super-resolution pursuits reconstructing high-fidelity high-resolution
counterpart for low-resolution image. In recent years, diffusion-based models
have garnered significant attention due to their capabilities with rich prior
knowledge. The success of diffusion models based on general text prompts has
validated the effectiveness of textual control in the field of text2image.
However, given the severe degradation commonly presented in low-resolution
images, coupled with the randomness characteristics of diffusion models,
current models struggle to adequately discern semantic and degradation
information within severely degraded images. This often leads to obstacles such
as semantic loss, visual artifacts, and visual hallucinations, which pose
substantial challenges for practical use. To address these challenges, this
paper proposes to leverage degradation-aligned language prompt for accurate,
fine-grained, and high-fidelity image restoration. Complementary priors
including semantic content descriptions and degradation prompts are explored.
Specifically, on one hand, image-restoration prompt alignment decoder is
proposed to automatically discern the degradation degree of LR images, thereby
generating beneficial degradation priors for image restoration. On the other
hand, much richly tailored descriptions from pretrained multimodal large
language model elicit high-level semantic priors closely aligned with human
perception, ensuring fidelity control for image restoration. Comprehensive
comparisons with state-of-the-art methods have been done on several popular
synthetic and real-world benchmark datasets. The quantitative and qualitative
analysis have demonstrated that the proposed method achieves a new
state-of-the-art perceptual quality level, especially in real-world cases based
on reference-free metrics.

摘要：<paragraph>影像超解析旨在為低解析度影像重建高保真高解析度影像。近年來，基於擴散的模型因其豐富先驗知識的能力而備受關注。基於一般文字提示的擴散模型的成功驗證了文字控制在 text2image 領域的有效性。然而，考量到低解析度影像中常見的嚴重退化，加上擴散模型的隨機性，目前的模型難以充分辨別嚴重退化影像中的語義和退化資訊。這通常會導致語義遺失、視覺偽影和視覺幻覺等障礙，對實際應用構成重大挑戰。為了解決這些挑戰，本文提出利用退化對齊的語言提示進行準確、細緻且高保真的影像修復。探索了包括語義內容描述和退化提示在內的互補先驗。具體來說，一方面，提出了影像修復提示對齊解碼器，以自動辨別 LR 影像的退化程度，從而為影像修復生成有益的退化先驗。另一方面，來自預訓練多模態大型語言模型的大量量身定制描述引發了與人類感知緊密對齊的高階語義先驗，確保了影像修復的保真度控制。已在多個流行的合成和真實世界基準資料集上與最先進的方法進行了全面比較。定量和定性分析表明，所提出的方法實現了新的最先進的感知品質水準，特別是在基於無參考指標的真實世界案例中。</paragraph>

##### **Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration**
2406.16469v1 by Yujin Baek, ChaeHun Park, Jaeseok Kim, Yu-Jung Heo, Du-Seong Chang, Jaegul Choo

To create culturally inclusive vision-language models (VLMs), the foremost
requirement is developing a test benchmark that can diagnose the models'
ability to respond to questions reflecting cultural elements. This paper
addresses the necessity for such benchmarks, noting that existing research has
relied on human annotators' manual efforts, which impedes diversity and
efficiency. We propose a semi-automated pipeline for constructing cultural VLM
benchmarks to enhance diversity and efficiency. This pipeline leverages
human-VLM collaboration, where VLMs generate questions based on guidelines,
human-annotated examples, and image-wise relevant knowledge, which are then
reviewed by native speakers for quality and cultural relevance. The
effectiveness of our adaptable pipeline is demonstrated through a specific
application: creating a dataset tailored to Korean culture, dubbed K-Viscuit.
The resulting benchmark features two types of questions: Type 1 questions
measure visual recognition abilities, while Type 2 assess fine-grained visual
reasoning skills. This ensures a thorough diagnosis of VLM models across
various aspects. Our evaluation using K-Viscuit revealed that open-source
models notably lag behind proprietary models in understanding Korean culture,
highlighting areas for improvement. We provided diverse analyses of VLM
performance across different cultural aspects. Besides, we explored the
potential of incorporating external knowledge retrieval to enhance the
generation process, suggesting future directions for improving cultural
interpretation ability of VLMs. Our dataset and code will be made publicly
available.

摘要：<paragraph>要建立具有文化包容性的視覺語言模型 (VLM)，最首要的條件是制定一個測試基準，用於診斷模型對反映文化元素問題的回應能力。本文探討此類基準的必要性，並指出現有研究依賴於人工標記員的手動工作，這會阻礙多樣性和效率。我們提出一個半自動化的管道，用於建構文化 VLM 基準，以增強多樣性和效率。此管道利用人機協作，其中 VLM 會根據準則、人工標記的範例和與影像相關的知識產生問題，然後由母語人士審查其品質和文化相關性。我們透過一個特定應用程式證明了我們可適應管道的有效性：建立一個專門針對韓國文化的資料集，稱為 K-Viscuit。產生的基準包含兩種類型的問題：類型 1 問題衡量視覺辨識能力，而類型 2 則評估細緻的視覺推理技能。這確保了對 VLM 模型在各個方面的全面診斷。我們使用 K-Viscuit 進行的評估顯示，開源模型在理解韓國文化方面明顯落後於專有模型，這突顯了需要改進的地方。我們對 VLM 在不同文化方面的表現進行了多樣化的分析。此外，我們探索了納入外部知識檢索以增強生成過程的可能性，這為改進 VLM 的文化詮釋能力提供了未來的方向。我們的資料集和程式碼將公開提供。</paragraph>

##### **Guardrails for avoiding harmful medical product recommendations and off-label promotion in generative AI models**
2406.16455v1 by Daniel Lopez-Martinez

Generative AI (GenAI) models have demonstrated remarkable capabilities in a
wide variety of medical tasks. However, as these models are trained using
generalist datasets with very limited human oversight, they can learn uses of
medical products that have not been adequately evaluated for safety and
efficacy, nor approved by regulatory agencies. Given the scale at which GenAI
may reach users, unvetted recommendations pose a public health risk. In this
work, we propose an approach to identify potentially harmful product
recommendations, and demonstrate it using a recent multimodal large language
model.

摘要：生成式 AI (GenAI) 模型在各种医疗任務中展示出非凡的能力。然而，由於這些模型是使用非常有限的人類監督的一般資料集進行訓練，因此它們可以學習尚未充分評估其安全性和有效性，也未經監管機構批准的醫療產品用途。鑑於 GenAI 可能接觸使用者的規模，未經審查的建議會構成公共健康風險。在這項工作中，我們提出了一種識別潛在有害產品建議的方法，並使用最近的多模態大型語言模型進行示範。

##### **Learning in Wilson-Cowan model for metapopulation**
2406.16453v1 by Raffaele Marino, Lorenzo Buffoni, Lorenzo Chicchi, Francesca Di Patti, Diego Febbe, Lorenzo Giambagli, Duccio Fanelli

The Wilson-Cowan model for metapopulation, a Neural Mass Network Model,
treats different subcortical regions of the brain as connected nodes, with
connections representing various types of structural, functional, or effective
neuronal connectivity between these regions. Each region comprises interacting
populations of excitatory and inhibitory cells, consistent with the standard
Wilson-Cowan model. By incorporating stable attractors into such a
metapopulation model's dynamics, we transform it into a learning algorithm
capable of achieving high image and text classification accuracy. We test it on
MNIST and Fashion MNIST, in combination with convolutional neural networks, on
CIFAR-10 and TF-FLOWERS, and, in combination with a transformer architecture
(BERT), on IMDB, always showing high classification accuracy. These numerical
evaluations illustrate that minimal modifications to the Wilson-Cowan model for
metapopulation can reveal unique and previously unobserved dynamics.

摘要：Wilson-Cowan 元種群模型，一種神經質量網路模型，
將大腦的不同皮質下區域視為相連節點，其中連接代表這些區域之間的各種結構、功能或有效神經元連接。每個區域都包含相互作用的興奮性和抑制性細胞群，與標準的 Wilson-Cowan 模型一致。通過將穩定的吸引子納入這種元種群模型的動態中，我們將其轉變為一種學習演算法，能夠實現高影像和文字分類準確度。我們在 MNIST 和 Fashion MNIST 上對其進行測試，與卷積神經網路結合使用，在 CIFAR-10 和 TF-FLOWERS 上，以及與Transformer架構 (BERT) 結合使用，在 IMDB 上，始終顯示出高分類準確度。這些數值評估說明對元種群的 Wilson-Cowan 模型進行最小的修改可以揭示獨特且以前未觀察到的動態。

##### **Building on Efficient Foundations: Effectively Training LLMs with Structured Feedforward Layers**
2406.16450v1 by Xiuying Wei, Skander Moalla, Razvan Pascanu, Caglar Gulcehre

State-of-the-art results in large language models (LLMs) often rely on scale,
which becomes computationally expensive. This has sparked a research agenda to
reduce these models' parameter count and computational costs without
significantly impacting their performance. Our study focuses on
transformer-based LLMs, specifically targeting the computationally intensive
feedforward networks (FFN), which are less studied than attention blocks. We
consider three candidate linear layer approximations in the FFN by combining
efficient low-rank and block-diagonal matrices. In contrast to many previous
works that examined these approximations, our study i) explores these
structures from the training-from-scratch perspective, ii) scales up to 1.3B
parameters, and iii) is conducted within recent Transformer-based LLMs rather
than convolutional architectures. We first demonstrate they can lead to actual
computational gains in various scenarios, including online decoding when using
a pre-merge technique. Additionally, we propose a novel training regime, called
\textit{self-guided training}, aimed at improving the poor training dynamics
that these approximations exhibit when used from initialization. Experiments on
the large RefinedWeb dataset show that our methods are both efficient and
effective for training and inference. Interestingly, these structured FFNs
exhibit steeper scaling curves than the original models. Further applying
self-guided training to the structured matrices with 32\% FFN parameters and
2.5$\times$ speed-up enables only a 0.4 perplexity increase under the same
training FLOPs. Finally, we develop the wide and structured networks surpassing
the current medium-sized and large-sized Transformer in perplexity and
throughput performance. Our code is available at
\url{https://github.com/CLAIRE-Labo/StructuredFFN/tree/main}.

摘要：<paragraph>大型語言模型 (LLM) 的最新結果通常依賴於規模，這在計算上會很昂貴。這激發了一項研究議程，旨在減少這些模型的參數計數和計算成本，而不會顯著影響其效能。我們的研究重點是基於Transformer的 LLM，特別針對計算密集的前饋網路 (FFN)，其研究較注意力區塊少。我們考慮在 FFN 中結合有效低秩和區塊對角矩陣，來考慮三個候選線性層近似。與許多先前檢驗這些近似的研究相反，我們的研究 i) 從頭開始訓練的角度探討這些結構，ii) 擴展到 1.3B 參數，以及 iii) 在最近的基於Transformer的 LLM 中進行，而不是卷積架構。我們首先證明它們可以在各種場景中帶來實際的計算收益，包括在使用預合併技術時的線上解碼。此外，我們提出了一種名為「自我引導訓練」的新訓練機制，旨在改善這些近似從初始化使用時表現出的不良訓練動態。在大型 RefinedWeb 資料集上的實驗表明，我們的模型在訓練和推理上都很有效率。有趣的是，這些結構化的 FFN 展現出比原始模型更陡峭的擴展曲線。進一步將自我引導訓練應用於具有 32% FFN 參數和 2.5 倍加速的結構化矩陣，在相同的訓練 FLOP 下僅能增加 0.4 個困惑度。最後，我們開發了廣泛且結構化的網路，在困惑度和吞吐量效能上超越了目前的中型和大型Transformer。我們的程式碼可在
\url{https://github.com/CLAIRE-Labo/StructuredFFN/tree/main} 取得。</paragraph>

##### **UniCoder: Scaling Code Large Language Model via Universal Code**
2406.16441v1 by Tao Sun, Linzheng Chai, Jian Yang, Yuwei Yin, Hongcheng Guo, Jiaheng Liu, Bing Wang, Liqun Yang, Zhoujun Li

Intermediate reasoning or acting steps have successfully improved large
language models (LLMs) for handling various downstream natural language
processing (NLP) tasks. When applying LLMs for code generation, recent works
mainly focus on directing the models to articulate intermediate
natural-language reasoning steps, as in chain-of-thought (CoT) prompting, and
then output code with the natural language or other structured intermediate
steps. However, such output is not suitable for code translation or generation
tasks since the standard CoT has different logical structures and forms of
expression with the code. In this work, we introduce the universal code
(UniCode) as the intermediate representation. It is a description of algorithm
steps using a mix of conventions of programming languages, such as assignment
operator, conditional operator, and loop. Hence, we collect an instruction
dataset UniCoder-Instruct to train our model UniCoder on multi-task learning
objectives. UniCoder-Instruct comprises natural-language questions, code
solutions, and the corresponding universal code. The alignment between the
intermediate universal code representation and the final code solution
significantly improves the quality of the generated code. The experimental
results demonstrate that UniCoder with the universal code significantly
outperforms the previous prompting methods by a large margin, showcasing the
effectiveness of the structural clues in pseudo-code.

摘要：中介推理或作用步驟已成功改進大型語言模型 (LLM)，以處理各種下游自然語言處理 (NLP) 任務。在將 LLM 應用於程式碼產生時，最近的作品主要著重於引導模型表達中介自然語言推理步驟，就像在思維鏈 (CoT) 提示中一樣，然後輸出程式碼與自然語言或其他結構化的中介步驟。然而，此類輸出不適合程式碼翻譯或產生任務，因為標準 CoT 具有不同的邏輯結構和表達形式與程式碼。在這項工作中，我們引入了通用程式碼 (UniCode) 作為中介表示。它是使用程式語言慣例的組合來描述演算法步驟，例如賦值運算子、條件運算子，以及迴圈。因此，我們收集了一個教學資料集 UniCoder-Instruct，以在多任務學習目標上訓練我們的模型 UniCoder。UniCoder-Instruct 包含自然語言問題、程式碼解決方案，以及對應的通用程式碼。中介通用程式碼表示與最終程式碼解決方案之間的對齊顯著改進了產生程式碼的品質。實驗結果證明，具有通用程式碼的 UniCoder 明顯優於先前的提示方法，展示了準程式碼中結構線索的有效性。

##### **Theory on Mixture-of-Experts in Continual Learning**
2406.16437v1 by Hongbo Li, Sen Lin, Lingjie Duan, Yingbin Liang, Ness B. Shroff

Continual learning (CL) has garnered significant attention because of its
ability to adapt to new tasks that arrive over time. Catastrophic forgetting
(of old tasks) has been identified as a major issue in CL, as the model adapts
to new tasks. The Mixture-of-Experts (MoE) model has recently been shown to
effectively mitigate catastrophic forgetting in CL, by employing a gating
network to sparsify and distribute diverse tasks among multiple experts.
However, there is a lack of theoretical analysis of MoE and its impact on the
learning performance in CL. This paper provides the first theoretical results
to characterize the impact of MoE in CL via the lens of overparameterized
linear regression tasks. We establish the benefit of MoE over a single expert
by proving that the MoE model can diversify its experts to specialize in
different tasks, while its router learns to select the right expert for each
task and balance the loads across all experts. Our study further suggests an
intriguing fact that the MoE in CL needs to terminate the update of the gating
network after sufficient training rounds to attain system convergence, which is
not needed in the existing MoE studies that do not consider the continual task
arrival. Furthermore, we provide explicit expressions for the expected
forgetting and overall generalization error to characterize the benefit of MoE
in the learning performance in CL. Interestingly, adding more experts requires
additional rounds before convergence, which may not enhance the learning
performance. Finally, we conduct experiments on both synthetic and real
datasets to extend these insights from linear models to deep neural networks
(DNNs), which also shed light on the practical algorithm design for MoE in CL.

摘要：持續學習 (CL) 因其適應隨著時間推移而出現的新任務的能力而備受關注。災難性遺忘 (舊任務) 已被確定為 CL 中的一個主要問題，因為模型適應新任務。混合專家 (MoE) 模型最近被證明可以有效減輕 CL 中的災難性遺忘，方法是採用閘控網路在多個專家之間稀疏化和分配不同的任務。然而，缺乏對 MoE 及其對 CL 中學習效能影響的理論分析。本文提供了第一個理論結果，透過過度參數化線性回歸任務的視角來描述 MoE 在 CL 中的影響。我們透過證明 MoE 模型可以使其專家多樣化以專精於不同的任務，同時其路由器學會為每個任務選擇正確的專家並平衡所有專家的負載，來確立 MoE 優於單一專家的優點。我們的研究進一步表明了一個有趣的事實，CL 中的 MoE 需要在足夠的訓練回合後終止閘控網路的更新，以達到系統收斂，這在不考慮持續任務到來的現有 MoE 研究中是不需要的。此外，我們提供了預期遺忘和整體泛化誤差的明確表達式，以描述 MoE 在 CL 中學習效能的優點。有趣的是，增加更多專家需要在收斂前進行額外的回合，這可能不會增強學習效能。最後，我們在合成和真實資料集上進行實驗，將這些見解從線性模型延伸到深度神經網路 (DNN)，這也為 MoE 在 CL 中的實務演算法設計提供了啟示。

##### **Dynamic Pseudo Label Optimization in Point-Supervised Nuclei Segmentation**
2406.16427v1 by Ziyue Wang, Ye Zhang, Yifeng Wang, Linghan Cai, Yongbing Zhang

Deep learning has achieved impressive results in nuclei segmentation, but the
massive requirement for pixel-wise labels remains a significant challenge. To
alleviate the annotation burden, existing methods generate pseudo masks for
model training using point labels. However, the generated masks are inevitably
different from the ground truth, and these dissimilarities are not handled
reasonably during the network training, resulting in the subpar performance of
the segmentation model. To tackle this issue, we propose a framework named
DoNuSeg, enabling \textbf{D}ynamic pseudo label \textbf{O}ptimization in
point-supervised \textbf{Nu}clei \textbf{Seg}mentation. Specifically, DoNuSeg
takes advantage of class activation maps (CAMs) to adaptively capture regions
with semantics similar to annotated points. To leverage semantic diversity in
the hierarchical feature levels, we design a dynamic selection module to choose
the optimal one among CAMs from different encoder blocks as pseudo masks.
Meanwhile, a CAM-guided contrastive module is proposed to further enhance the
accuracy of pseudo masks. In addition to exploiting the semantic information
provided by CAMs, we consider location priors inherent to point labels,
developing a task-decoupled structure for effectively differentiating nuclei.
Extensive experiments demonstrate that DoNuSeg outperforms state-of-the-art
point-supervised methods. The code is available at
https://github.com/shinning0821/MICCAI24-DoNuSeg.

摘要：深度學習在細胞核分割方面取得了令人印象深刻的成果，但對像素級標籤的大量需求仍然是一個重大挑戰。為了減輕標註負擔，現有方法使用點標籤為模型訓練生成偽遮罩。然而，生成的遮罩與真實情況不可避免地不同，並且這些差異在網路訓練過程中沒有得到合理的處理，導致分割模型的性能不佳。為了解決這個問題，我們提出了一個名為 DoNuSeg 的框架，實現了點監督細胞核分割中的動態偽標籤優化。具體來說，DoNuSeg 利用類激活映射 (CAM) 自適應地擷取與標註點語義相似的區域。為了利用分層特徵層中的語義多樣性，我們設計了一個動態選擇模組，從不同編碼器區塊中的 CAM 中選擇最佳的一個作為偽遮罩。同時，提出了一個 CAM 引導對比模組，進一步增強偽遮罩的準確性。除了利用 CAM 提供的語義資訊外，我們還考慮了點標籤固有的位置先驗，開發了一個任務解耦結構，用於有效區分細胞核。大量的實驗證明，DoNuSeg 優於最先進的點監督方法。程式碼可在 https://github.com/shinning0821/MICCAI24-DoNuSeg 取得。

##### **Fault Detection for agents on power grid topology optimization: A Comprehensive analysis**
2406.16426v1 by Malte Lehna, Mohamed Hassouna, Dmitry Degtyar, Sven Tomforde, Christoph Scholz

The topology optimization of transmission networks using Deep Reinforcement
Learning (DRL) has increasingly come into focus. Various researchers have
proposed different DRL agents, which are often benchmarked on the Grid2Op
environment from the Learning to Run a Power Network (L2RPN) challenges. The
environments have many advantages with their realistic chronics and underlying
power flow backends. However, the interpretation of agent survival or failure
is not always clear, as there are a variety of potential causes. In this work,
we focus on the failures of the power grid to identify patterns and detect them
a priori. We collect the failed chronics of three different agents on the WCCI
2022 L2RPN environment, totaling about 40k data points. By clustering, we are
able to detect five distinct clusters, identifying different failure types.
Further, we propose a multi-class prediction approach to detect failures
beforehand and evaluate five different models. Here, the Light
Gradient-Boosting Machine (LightGBM) shows the best performance, with an
accuracy of 86%. It also correctly identifies in 91% of the time failure and
survival observations. Finally, we provide a detailed feature importance
analysis that identifies critical features and regions in the grid.

摘要：使用深度強化學習 (DRL) 的傳輸網路拓撲最佳化已逐漸受到關注。各研究人員已提出各種 DRL 代理，這些代理通常在 Learning to Run a Power Network (L2RPN) 挑戰中的 Grid2Op 環境中進行基準測試。環境具有許多優點，包括其逼真的時間序列和底層電力流後端。然而，代理存活或故障的解釋並不總是清楚，因為有各種潛在原因。在這項工作中，我們專注於電網故障，以識別模式並先驗檢測它們。我們收集了 WCCI 2022 L2RPN 環境中三個不同代理的故障時間序列，總計約 40k 個數據點。透過分群，我們能夠檢測到五個不同的群集，識別出不同的故障類型。此外，我們提出了一種多類別預測方法來事先檢測故障並評估五種不同的模型。在此，Light Gradient-Boosting Machine (LightGBM) 表現最佳，準確率為 86%。它還正確識別出 91% 的故障和存活觀測。最後，我們提供了詳細的功能重要性分析，以識別電網中的關鍵功能和區域。

##### **Multilingual Knowledge Editing with Language-Agnostic Factual Neurons**
2406.16416v1 by Xue zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou

Multilingual knowledge editing (MKE) aims to simultaneously revise factual
knowledge across multilingual languages within large language models (LLMs).
However, most existing MKE methods just adapt existing monolingual editing
methods to multilingual scenarios, overlooking the deep semantic connections of
the same factual knowledge between different languages, thereby limiting edit
performance. To address this issue, we first investigate how LLMs represent
multilingual factual knowledge and discover that the same factual knowledge in
different languages generally activates a shared set of neurons, which we call
language-agnostic factual neurons. These neurons represent the semantic
connections between multilingual knowledge and are mainly located in certain
layers. Inspired by this finding, we propose a new MKE method by locating and
modifying Language-Agnostic Factual Neurons (LAFN) to simultaneously edit
multilingual knowledge. Specifically, we first generate a set of paraphrases
for each multilingual knowledge to be edited to precisely locate the
corresponding language-agnostic factual neurons. Then we optimize the update
values for modifying these located neurons to achieve simultaneous modification
of the same factual knowledge in multiple languages. Experimental results on
Bi-ZsRE and MzsRE benchmarks demonstrate that our method outperforms existing
MKE methods and achieves remarkable edit performance, indicating the importance
of considering the semantic connections among multilingual knowledge.

摘要：多語言知識編輯 (MKE) 旨在在大型語言模型 (LLM) 內同時修改多語言的知識。
然而，現有的 MKE 方法大多只是將現有的單語編輯方法調整為多語言場景，忽略了不同語言之間相同事實知識的深層語義聯繫，從而限制了編輯效果。為了解決這個問題，我們首先研究 LLM 如何表示多語言事實知識，並發現不同語言中的相同事實知識通常會激活一組共享的神經元，我們稱之為與語言無關的事實神經元。這些神經元表示多語言知識之間的語義聯繫，並且主要位於某些層中。受這一發現的啟發，我們提出了一種新的 MKE 方法，通過定位和修改與語言無關的事實神經元 (LAFN) 來同時編輯多語言知識。具體來說，我們首先為每個要編輯的多語言知識生成一組同義詞，以精確定位對應的與語言無關的事實神經元。然後，我們優化了修改這些定位神經元的更新值，以實現對多種語言中相同事實知識的同時修改。在 Bi-ZsRE 和 MzsRE 基準上的實驗結果表明，我們的模型優於現有的 MKE 模型，並實現了顯著的編輯效果，這表明考慮多語言知識之間的語義聯繫非常重要。

##### **PenSLR: Persian end-to-end Sign Language Recognition Using Ensembling**
2406.16388v1 by Amirparsa Salmankhah, Amirreza Rajabi, Negin Kheirmand, Ali Fadaeimanesh, Amirreza Tarabkhah, Amirreza Kazemzadeh, Hamed Farbeh

Sign Language Recognition (SLR) is a fast-growing field that aims to fill the
communication gaps between the hearing-impaired and people without hearing
loss. Existing solutions for Persian Sign Language (PSL) are limited to
word-level interpretations, underscoring the need for more advanced and
comprehensive solutions. Moreover, previous work on other languages mainly
focuses on manipulating the neural network architectures or hardware
configurations instead of benefiting from the aggregated results of multiple
models. In this paper, we introduce PenSLR, a glove-based sign language system
consisting of an Inertial Measurement Unit (IMU) and five flexible sensors
powered by a deep learning framework capable of predicting variable-length
sequences. We achieve this in an end-to-end manner by leveraging the
Connectionist Temporal Classification (CTC) loss function, eliminating the need
for segmentation of input signals. To further enhance its capabilities, we
propose a novel ensembling technique by leveraging a multiple sequence
alignment algorithm known as Star Alignment. Furthermore, we introduce a new
PSL dataset, including 16 PSL signs with more than 3000 time-series samples in
total. We utilize this dataset to evaluate the performance of our system based
on four word-level and sentence-level metrics. Our evaluations show that PenSLR
achieves a remarkable word accuracy of 94.58% and 96.70% in subject-independent
and subject-dependent setups, respectively. These achievements are attributable
to our ensembling algorithm, which not only boosts the word-level performance
by 0.51% and 1.32% in the respective scenarios but also yields significant
enhancements of 1.46% and 4.00%, respectively, in sentence-level accuracy.

摘要：手語辨識 (SLR) 是個快速成長的領域，旨在填補聽障人士與聽力正常人士之間的溝通鴻溝。現有的波斯手語 (PSL) 解决方案僅限於字詞層級的詮釋，強調了需要更進階且全面的解決方案。此外，先前針對其他語言的研究主要著重於調整神經網路架構或硬體組態，而非從多個模型的彙總結果中獲益。在本文中，我們介紹 PenSLR，一種基於手套的手語系統，由一個慣性測量單元 (IMU) 和五個靈活感測器組成，並由一個能夠預測可變長度序列的深度學習架構提供動力。我們透過利用連接式時間分類 (CTC) 損失函數，以端對端的方式達成這項任務，消除了分割輸入訊號的需求。為了進一步提升其能力，我們提出了一種創新的整合技術，利用稱為 Star Alignment 的多重序列比對演算法。此外，我們還介紹了一個新的 PSL 資料集，其中包含 16 個 PSL 手勢，總計超過 3000 個時間序列範例。我們利用這個資料集來根據四個字詞層級和句子層級的指標評估我們系統的效能。我們的評估顯示，PenSLR 在受試者獨立和受試者依賴的設定中分別達到了 94.58% 和 96.70% 的顯著字詞準確率。這些成就歸功於我們的整合演算法，它不僅在各自的場景中將字詞層級的效能提升了 0.51% 和 1.32%，還分別在句子層級的準確率中產生了顯著的提升，分別為 1.46% 和 4.00%。

##### **Automatically Generating UI Code from Screenshot: A Divide-and-Conquer-Based Approach**
2406.16386v1 by Yuxuan Wan, Chaozheng Wang, Yi Dong, Wenxuan Wang, Shuqing Li, Yintong Huo, Michael R. Lyu

Websites are critical in today's digital world, with over 1.11 billion
currently active and approximately 252,000 new sites launched daily. Converting
website layout design into functional UI code is a time-consuming yet
indispensable step of website development. Manual methods of converting visual
designs into functional code present significant challenges, especially for
non-experts. To explore automatic design-to-code solutions, we first conduct a
motivating study on GPT-4o and identify three types of issues in generating UI
code: element omission, element distortion, and element misarrangement. We
further reveal that a focus on smaller visual segments can help multimodal
large language models (MLLMs) mitigate these failures in the generation
process. In this paper, we propose DCGen, a divide-and-conquer-based approach
to automate the translation of webpage design to UI code. DCGen starts by
dividing screenshots into manageable segments, generating descriptions for each
segment, and then reassembling them into complete UI code for the entire
screenshot. We conduct extensive testing with a dataset comprised of real-world
websites and various MLLMs and demonstrate that DCGen achieves up to a 14%
improvement in visual similarity over competing methods. To the best of our
knowledge, DCGen is the first segment-aware prompt-based approach for
generating UI code directly from screenshots.

摘要：<paragraph>在當今的數位世界中，網站至關重要，目前有超過 11.1 億個活躍網站，每天約有 252,000 個新網站上線。將網站佈局設計轉換為功能性的 UI 程式碼是網站開發中一個耗時但不可或缺的步驟。將視覺設計轉換為功能性程式碼的手動方法會帶來重大挑戰，特別是對於非專家而言。為了探索自動化設計到程式碼的解決方案，我們首先對 GPT-4o 進行一項激勵研究，並找出產生 UI 程式碼的三種類型問題：元素遺漏、元素失真和元素排列錯誤。我們進一步揭示，專注於較小的視覺區段可以幫助多模態大型語言模型 (MLLM) 減輕產生過程中的這些失敗。在本文中，我們提出 DCGen，一種基於分而治之的方法，用於自動化網頁設計到 UI 程式碼的轉換。DCGen 首先將螢幕截圖分割成可管理的區段，為每個區段產生描述，然後將它們重新組合成整個螢幕截圖的完整 UI 程式碼。我們對包含真實世界網站和各種 MLLM 的資料集進行廣泛測試，並證明 DCGen 在視覺相似性方面比競爭方法提高了 14%。據我們所知，DCGen 是第一個基於區段感知提示的方法，可直接從螢幕截圖產生 UI 程式碼。</paragraph>

##### **UNO Arena for Evaluating Sequential Decision-Making Capability of Large Language Models**
2406.16382v1 by Zhanyue Qin, Haochuan Wang, Deyuan Liu, Ziyang Song, Cunhang Fan, Zhao Lv, Jinlin Wu, Zhen Lei, Zhiying Tu, Dianhui Chu, Xiaoyan Yu, Dianbo Sui

Sequential decision-making refers to algorithms that take into account the
dynamics of the environment, where early decisions affect subsequent decisions.
With large language models (LLMs) demonstrating powerful capabilities between
tasks, we can't help but ask: Can Current LLMs Effectively Make Sequential
Decisions? In order to answer this question, we propose the UNO Arena based on
the card game UNO to evaluate the sequential decision-making capability of LLMs
and explain in detail why we choose UNO. In UNO Arena, We evaluate the
sequential decision-making capability of LLMs dynamically with novel metrics
based Monte Carlo methods. We set up random players, DQN-based reinforcement
learning players, and LLM players (e.g. GPT-4, Gemini-pro) for comparison
testing. Furthermore, in order to improve the sequential decision-making
capability of LLMs, we propose the TUTRI player, which can involves having LLMs
reflect their own actions wtih the summary of game history and the game
strategy. Numerous experiments demonstrate that the TUTRI player achieves a
notable breakthrough in the performance of sequential decision-making compared
to the vanilla LLM player.

摘要：序貫決策制定是指考量環境動態的演算法，其中早期決策會影響後續決策。大型語言模型 (LLM) 在各項任務間展現強大的能力，我們不禁發問：目前的 LLM 能否有效地進行序貫決策？為了回答這個問題，我們提出基於卡牌遊戲 UNO 的 UNO Arena，用以評估 LLM 的序貫決策制定能力，並詳細說明我們選擇 UNO 的原因。在 UNO Arena 中，我們使用基於蒙地卡羅方法的新穎指標，動態評估 LLM 的序貫決策制定能力。我們設定隨機玩家、基於 DQN 的強化學習玩家和 LLM 玩家（例如 GPT-4、Gemini-pro）進行比較測試。此外，為了提升 LLM 的序貫決策制定能力，我們提出 TUTRI 玩家，它可以讓 LLM 透過遊戲歷史摘要和遊戲策略來反思自己的行動。許多實驗證明，與原始 LLM 玩家相比，TUTRI 玩家在序貫決策制定表現上取得顯著突破。

##### **On the Transformations across Reward Model, Parameter Update, and In-Context Prompt**
2406.16377v1 by Deng Cai, Huayang Li, Tingchen Fu, Siheng Li, Weiwen Xu, Shuaiyi Li, Bowen Cao, Zhisong Zhang, Xinting Huang, Leyang Cui, Yan Wang, Lemao Liu, Taro Watanabe, Shuming Shi

Despite the general capabilities of pre-trained large language models (LLMs),
they still need further adaptation to better serve practical applications. In
this paper, we demonstrate the interchangeability of three popular and distinct
adaptation tools: parameter updating, reward modeling, and in-context
prompting. This interchangeability establishes a triangular framework with six
transformation directions, each of which facilitates a variety of applications.
Our work offers a holistic view that unifies numerous existing studies and
suggests potential research directions. We envision our work as a useful
roadmap for future research on LLMs.

摘要：儘管預先訓練的大語言模型 (LLM) 具有普遍功能，
它們仍需要進一步調整才能更好地服務於實際應用。在
本文中，我們展示了三個流行且不同的調整工具的可互換性：參數更新、獎勵建模和情境內
提示。這種可互換性建立了一個三角形框架，其中包含六個轉換方向，每個方向都促進了各種應用。
我們的研究提供了一個整體觀點，統一了許多現有研究，
並提出了潛在的研究方向。我們將我們的研究視為未來 LLM 研究的有用路線圖。

##### **KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning**
2406.16374v1 by Dongyang Li, Taolin Zhang, Longtao Huang, Chengyu Wang, Xiaofeng He, Hui Xue

Knowledge-enhanced pre-trained language models (KEPLMs) leverage relation
triples from knowledge graphs (KGs) and integrate these external data sources
into language models via self-supervised learning. Previous works treat
knowledge enhancement as two independent operations, i.e., knowledge injection
and knowledge integration. In this paper, we propose to learn
Knowledge-Enhanced language representations with Hierarchical Reinforcement
Learning (KEHRL), which jointly addresses the problems of detecting positions
for knowledge injection and integrating external knowledge into the model in
order to avoid injecting inaccurate or irrelevant knowledge. Specifically, a
high-level reinforcement learning (RL) agent utilizes both internal and prior
knowledge to iteratively detect essential positions in texts for knowledge
injection, which filters out less meaningful entities to avoid diverting the
knowledge learning direction. Once the entity positions are selected, a
relevant triple filtration module is triggered to perform low-level RL to
dynamically refine the triples associated with polysemic entities through
binary-valued actions. Experiments validate KEHRL's effectiveness in probing
factual knowledge and enhancing the model's performance on various natural
language understanding tasks.

摘要：知識增強預訓練語言模型 (KEPLM) 利用知識圖譜 (KG) 中的關聯三元組，並透過自我監督式學習將這些外部資料來源整合到語言模型中。先前的研究將知識增強視為兩個獨立的操作，即知識注入和知識整合。在本文中，我們建議使用分層強化學習 (KEHRL) 學習知識增強語言表徵，這共同解決了偵測知識注入位置和將外部知識整合到模型中的問題，以避免注入不準確或不相關的知識。具體來說，高階強化學習 (RL) 代理使用內部和先驗知識，反覆偵測文字中知識注入的重要位置，這會過濾掉較不重要的實體，以避免轉移知識學習方向。一旦選定實體位置，就會觸發相關的三元組過濾模組，透過二進制動作動態精煉與多義實體相關的三元組。實驗驗證了 KEHRL 在探查事實知識和增強模型在各種自然語言理解任務上的效能。

##### **UniPSDA: Unsupervised Pseudo Semantic Data Augmentation for Zero-Shot Cross-Lingual Natural Language Understanding**
2406.16372v1 by Dongyang Li, Taolin Zhang, Jiali Deng, Longtao Huang, Chengyu Wang, Xiaofeng He, Hui Xue

Cross-lingual representation learning transfers knowledge from resource-rich
data to resource-scarce ones to improve the semantic understanding abilities of
different languages. However, previous works rely on shallow unsupervised data
generated by token surface matching, regardless of the global context-aware
semantics of the surrounding text tokens. In this paper, we propose an
Unsupervised Pseudo Semantic Data Augmentation (UniPSDA) mechanism for
cross-lingual natural language understanding to enrich the training data
without human interventions. Specifically, to retrieve the tokens with similar
meanings for the semantic data augmentation across different languages, we
propose a sequential clustering process in 3 stages: within a single language,
across multiple languages of a language family, and across languages from
multiple language families. Meanwhile, considering the multi-lingual knowledge
infusion with context-aware semantics while alleviating computation burden, we
directly replace the key constituents of the sentences with the above-learned
multi-lingual family knowledge, viewed as pseudo-semantic. The infusion process
is further optimized via three de-biasing techniques without introducing any
neural parameters. Extensive experiments demonstrate that our model
consistently improves the performance on general zero-shot cross-lingual
natural language understanding tasks, including sequence classification,
information extraction, and question answering.

摘要：跨語言表徵學習將知識從資源豐富的資料傳遞至資源稀少的資料，以提升不同語言的語意理解能力。然而，先前的研究依賴於藉由符號表面比對所產生的淺層非監督式資料，而不考慮周圍文字符號的整體脈絡感知語意。在本文中，我們提出一個非監督式偽語意資料擴充（UniPSDA）機制，用於跨語言自然語言理解，以豐富訓練資料，而無需人工介入。具體來說，為了擷取跨語言語意資料擴充中具有相似意義的符號，我們提出一個分為 3 個階段的順序聚類流程：在單一語言內、跨語言家族的多種語言，以及跨多個語言家族的語言。同時，在減輕運算負擔的同時，考量具有脈絡感知語意的多語言知識灌輸，我們直接以上述學習到的多語言家族知識取代句子的關鍵組成，視為偽語意。灌輸流程進一步透過三種去偏誤技術進行最佳化，而不會引入任何神經參數。廣泛的實驗證明，我們的模型在一般零次學習跨語言自然語言理解任務中持續提升效能，包括序列分類、資訊萃取和問題解答。

##### **Towards Lightweight Graph Neural Network Search with Curriculum Graph Sparsification**
2406.16357v1 by Beini Xie, Heng Chang, Ziwei Zhang, Zeyang Zhang, Simin Wu, Xin Wang, Yuan Meng, Wenwu Zhu

Graph Neural Architecture Search (GNAS) has achieved superior performance on
various graph-structured tasks. However, existing GNAS studies overlook the
applications of GNAS in resource-constraint scenarios. This paper proposes to
design a joint graph data and architecture mechanism, which identifies
important sub-architectures via the valuable graph data. To search for optimal
lightweight Graph Neural Networks (GNNs), we propose a Lightweight Graph Neural
Architecture Search with Graph SparsIfication and Network Pruning (GASSIP)
method. In particular, GASSIP comprises an operation-pruned architecture search
module to enable efficient lightweight GNN search. Meanwhile, we design a novel
curriculum graph data sparsification module with an architecture-aware
edge-removing difficulty measurement to help select optimal sub-architectures.
With the aid of two differentiable masks, we iteratively optimize these two
modules to efficiently search for the optimal lightweight architecture.
Extensive experiments on five benchmarks demonstrate the effectiveness of
GASSIP. Particularly, our method achieves on-par or even higher node
classification performance with half or fewer model parameters of searched GNNs
and a sparser graph.

摘要：圖形神經架構搜尋 (GNAS) 已在各種圖形結構任務上取得優異的效能。然而，現有的 GNAS 研究忽略了 GNAS 在資源受限場景中的應用。本文提出設計一種聯合圖形資料和架構機制，透過有價值的圖形資料找出重要的子架構。為了搜尋最佳的輕量級圖形神經網路 (GNN)，我們提出一個具有圖形稀疏化和網路剪枝的輕量級圖形神經架構搜尋 (GASSIP) 方法。特別是，GASSIP 包含一個操作剪枝架構搜尋模組，以實現高效的輕量級 GNN 搜尋。同時，我們設計了一個新穎的課程圖形資料稀疏化模組，具有架構感知邊緣移除難度測量，以協助選擇最佳的子架構。在兩個可微分遮罩的幫助下，我們反覆最佳化這兩個模組，以有效地搜尋最佳的輕量級架構。在五個基準上的廣泛實驗證明了 GASSIP 的有效性。特別是，我們的模型在搜尋到的 GNN 的一半或更少的模型參數和更稀疏的圖形中，達到了與節點分類效能相同甚至更高的效能。

##### **Evaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation**
2406.16356v1 by Rem Hida, Junki Ohmura, Toshiyuki Sekiya

Instruction-tuned Large Language Models (LLMs) have achieved remarkable
performance across various benchmark tasks. While providing instructions to
LLMs for guiding their generations is user-friendly, assessing their
instruction-following capabilities is still unclarified due to a lack of
evaluation metrics. In this paper, we focus on evaluating the
instruction-following ability of LLMs in the context of story-ending
generation, which requires diverse and context-specific instructions. We
propose an automatic evaluation pipeline that utilizes a machine reading
comprehension (MRC) model to determine whether the generated story-ending
reflects instruction. Our findings demonstrate that our proposed metric aligns
with human evaluation. Furthermore, our experiments confirm that recent
open-source LLMs can achieve instruction-following performance close to
GPT-3.5, as assessed through automatic evaluation.

摘要：指令調整大型語言模型 (LLM) 在各種基準任務中取得顯著的表現。雖然向 LLM 提供指令以指導其生成對使用者來說很友善，但由於缺乏評估指標，評估其指令遵循能力仍然不明確。在本文中，我們專注於評估 LLM 在故事結尾生成情境中的指令遵循能力，這需要多樣化且特定於情境的指令。我們提出一個自動評估管道，利用機器閱讀理解 (MRC) 模型來確定生成的故事情節是否反映指令。我們的發現證明我們提出的指標與人類評估一致。此外，我們的實驗確認最近的開源 LLM 可以實現接近 GPT-3.5 的指令遵循效能，這是透過自動評估來評估的。

##### **Directed Domain Fine-Tuning: Tailoring Separate Modalities for Specific Training Tasks**
2406.16346v1 by Daniel Wen, Nafisa Hussain

Large language models (LLMs) and large visual language models (LVLMs) have
been at the forefront of the artificial intelligence field, particularly for
tasks like text generation, video captioning, and question-answering.
Typically, it is more applicable to train these models on broader knowledge
bases or datasets to increase generalizability, learn relationships between
topics, and recognize patterns. Instead, we propose to provide instructional
datasets specific to the task of each modality within a distinct domain and
then fine-tune the parameters of the model using LORA. With our approach, we
can eliminate all noise irrelevant to the given task while also ensuring that
the model generates with enhanced precision. For this work, we use Video-LLaVA
to generate recipes given cooking videos without transcripts. Video-LLaVA's
multimodal architecture allows us to provide cooking images to its image
encoder, cooking videos to its video encoder, and general cooking questions to
its text encoder. Thus, we aim to remove all noise unrelated to cooking while
improving our model's capabilities to generate specific ingredient lists and
detailed instructions. As a result, our approach to fine-tuning Video-LLaVA
leads to gains over the baseline Video-LLaVA by 2% on the YouCook2 dataset.
While this may seem like a marginal increase, our model trains on an image
instruction dataset 2.5% the size of Video-LLaVA's and a video instruction
dataset 23.76% of Video-LLaVA's.

摘要：大型語言模型 (LLM) 和大型視覺語言模型 (LVLMs) 一直處於人工智慧領域的最前線，特別是對於文本生成、影片字幕和問答等任務。通常，將這些模型訓練在更廣泛的知識庫或資料集上以增加泛化性、學習主題之間的關係並識別模式會更適用。相反，我們建議針對特定領域內每個模態的任務提供教學資料集，然後使用 LORA 微調模型的參數。透過我們的方法，我們可以在確保模型以更高的精確度生成的同時，消除與給定任務無關的所有雜訊。在這項工作中，我們使用 Video-LLaVA 來產生沒有文字稿的烹飪影片食譜。Video-LLaVA 的多模態架構讓我們可以將烹飪圖片提供給它的影像編碼器、烹飪影片提供給它的影片編碼器，以及一般的烹飪問題提供給它的文字編碼器。因此，我們旨在移除所有與烹飪無關的雜訊，同時提升我們模型產生特定食材清單和詳細說明的能力。因此，我們微調 Video-LLaVA 的方法在 YouCook2 資料集上比基準 Video-LLaVA 獲得了 2% 的提升。雖然這看起來像是一個邊際增益，但我們的模型在影像說明資料集上訓練的規模是 Video-LLaVA 的 2.5%，在影片說明資料集上訓練的規模是 Video-LLaVA 的 23.76%。

##### **ADVSCORE: A Metric for the Evaluation and Creation of Adversarial Benchmarks**
2406.16342v1 by Yoo Yeon Sung, Eve Fleisig, Ishani Mondal, Jordan Lee Boyd-Graber

Adversarial benchmarks validate model abilities by providing samples that
fool models but not humans. However, despite the proliferation of datasets that
claim to be adversarial, there does not exist an established metric to evaluate
how adversarial these datasets are. To address this lacuna, we introduce
ADVSCORE, a metric which quantifies how adversarial and discriminative an
adversarial dataset is and exposes the features that make data adversarial. We
then use ADVSCORE to underpin a dataset creation pipeline that incentivizes
writing a high-quality adversarial dataset. As a proof of concept, we use
ADVSCORE to collect an adversarial question answering (QA) dataset, ADVQA, from
our pipeline. The high-quality questions in ADVQA surpasses three adversarial
benchmarks across domains at fooling several models but not humans. We validate
our result based on difficulty estimates from 9,347 human responses on four
datasets and predictions from three models. Moreover, ADVSCORE uncovers which
adversarial tactics used by human writers fool models (e.g., GPT-4) but not
humans. Through ADVSCORE and its analyses, we offer guidance on revealing
language model vulnerabilities and producing reliable adversarial examples.

摘要：對抗基準會提供模型無法辨識，但人類可以辨識的範例，用來驗證模型的能力。然而，儘管聲稱具有對抗性的資料集不斷增加，但目前並不存在已建立的指標來評估這些資料集的對抗性。為了解決這個問題，我們引入了 ADVSCORE，這是一個指標，用來量化對抗性資料集的對抗性和辨別力，並揭露使資料具有對抗性的特徵。接著，我們使用 ADVSCORE 來支持資料集建立管道，以激勵撰寫高品質的對抗性資料集。作為概念驗證，我們使用 ADVSCORE 從我們的管道收集對抗性問答 (QA) 資料集 ADVQA。ADVQA 中的高品質問題超越了三個對抗性基準，在多個領域中欺騙了多個模型，但沒有欺騙人類。我們根據 9,347 位人類對四個資料集的回應的難度評估和三個模型的預測，驗證了我們的結果。此外，ADVSCORE 揭示了人類作者使用的哪些對抗性策略欺騙了模型（例如 GPT-4），但沒有欺騙人類。透過 ADVSCORE 及其分析，我們提供了關於揭露語言模型漏洞和產生可靠對抗性範例的指導。

##### **EHRCon: Dataset for Checking Consistency between Unstructured Notes and Structured Tables in Electronic Health Records**
2406.16341v1 by Yeonsu Kwon, Jiho Kim, Gyubok Lee, Seongsu Bae, Daeun Kyung, Wonchul Cha, Tom Pollard, Alistair Johnson, Edward Choi

Electronic Health Records (EHRs) are integral for storing comprehensive
patient medical records, combining structured data (e.g., medications) with
detailed clinical notes (e.g., physician notes). These elements are essential
for straightforward data retrieval and provide deep, contextual insights into
patient care. However, they often suffer from discrepancies due to unintuitive
EHR system designs and human errors, posing serious risks to patient safety. To
address this, we developed EHRCon, a new dataset and task specifically designed
to ensure data consistency between structured tables and unstructured notes in
EHRs. EHRCon was crafted in collaboration with healthcare professionals using
the MIMIC-III EHR dataset, and includes manual annotations of 3,943 entities
across 105 clinical notes checked against database entries for consistency.
EHRCon has two versions, one using the original MIMIC-III schema, and another
using the OMOP CDM schema, in order to increase its applicability and
generalizability. Furthermore, leveraging the capabilities of large language
models, we introduce CheckEHR, a novel framework for verifying the consistency
between clinical notes and database tables. CheckEHR utilizes an eight-stage
process and shows promising results in both few-shot and zero-shot settings.
The code is available at https://github.com/dustn1259/EHRCon.

摘要：電子健康紀錄 (EHR) 對儲存全面的患者病歷至關重要，它結合了結構化資料 (例如藥物) 和詳細的臨床記錄 (例如醫師記錄)。這些元素對於直接的資料擷取至關重要，並提供對患者照護的深入背景脈絡見解。然而，它們通常會因不直觀的 EHR 系統設計和人為錯誤而產生差異，對患者安全構成嚴重風險。為了解決這個問題，我們開發了 EHRCon，這是一個新的資料集和任務，專門設計用於確保 EHR 中結構化表格和非結構化記錄之間的資料一致性。EHRCon 是與醫療保健專業人員合作使用 MIMIC-III EHR 資料集製作的，並包含針對 105 個臨床記錄中 3,943 個實體的手動註解，並根據資料庫條目進行一致性檢查。EHRCon 有兩個版本，一個使用原始的 MIMIC-III 架構，另一個使用 OMOP CDM 架構，以提高其適用性和概括性。此外，利用大型語言模型的能力，我們引入了 CheckEHR，這是一個用於驗證臨床記錄和資料庫表格之間一致性的新框架。CheckEHR 使用八階段流程，並在少量樣本和零樣本設定中顯示出有希望的結果。程式碼可在 https://github.com/dustn1259/EHRCon 取得。

##### **Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models**
2406.16333v1 by Yichen Sun, Zhixuan Chu, Zhan Qin, Kui Ren

The rapid advancement of Text-to-Image(T2I) generative models has enabled the
synthesis of high-quality images guided by textual descriptions. Despite this
significant progress, these models are often susceptible in generating contents
that contradict the input text, which poses a challenge to their reliability
and practical deployment. To address this problem, we introduce a novel
diffusion-based framework to significantly enhance the alignment of generated
images with their corresponding descriptions, addressing the inconsistency
between visual output and textual input. Our framework is built upon a
comprehensive analysis of inconsistency phenomena, categorizing them based on
their manifestation in the image. Leveraging a state-of-the-art large language
module, we first extract objects and construct a knowledge graph to predict the
locations of these objects in potentially generated images. We then integrate a
state-of-the-art controllable image generation model with a visual text
generation module to generate an image that is consistent with the original
prompt, guided by the predicted object locations. Through extensive experiments
on an advanced multimodal hallucination benchmark, we demonstrate the efficacy
of our approach in accurately generating the images without the inconsistency
with the original prompt. The code can be accessed via
https://github.com/TruthAI-Lab/PCIG.

摘要：文本到图像 (T2I) 生成模型的快速进步使得合成由文本描述引导的高质量图像成为可能。尽管取得了这些重大进展，但这些模型在生成与输入文本相矛盾的内容方面通常很敏感，这对它们的可靠性和实际部署提出了挑战。为了解决这个问题，我们引入了一个新颖的基于扩散的框架，以显着增强生成图像与其相应描述的一致性，解决视觉输出和文本输入之间的不一致性。我们的框架建立在对不一致现象的全面分析之上，根据它们在图像中的表现对它们进行分类。利用最先进的大型语言模块，我们首先提取对象并构建知识图谱来预测这些对象在潜在生成的图像中的位置。然后，我们将最先进的可控图像生成模型与视觉文本生成模块集成在一起，以生成与原始提示一致的图像，并由预测的对象位置引导。通过在高级多模态幻觉基准上进行广泛的实验，我们展示了我们的方法在准确生成图像方面的有效性，而不会与原始提示不一致。可以通过 https://github.com/TruthAI-Lab/PCIG 访问代码。

##### **DemoRank: Selecting Effective Demonstrations for Large Language Models in Ranking Task**
2406.16332v1 by Wenhan Liu, Yutao Zhu, Zhicheng Dou

Recently, there has been increasing interest in applying large language
models (LLMs) as zero-shot passage rankers. However, few studies have explored
how to select appropriate in-context demonstrations for the passage ranking
task, which is the focus of this paper. Previous studies mainly apply a
demonstration retriever to retrieve demonstrations and use top-$k$
demonstrations for in-context learning (ICL). Although effective, this approach
overlooks the dependencies between demonstrations, leading to inferior
performance of few-shot ICL in the passage ranking task. In this paper, we
formulate the demonstration selection as a \textit{retrieve-then-rerank}
process and introduce the DemoRank framework. In this framework, we first use
LLM feedback to train a demonstration retriever and construct a novel
dependency-aware training samples to train a demonstration reranker to improve
few-shot ICL. The construction of such training samples not only considers
demonstration dependencies but also performs in an efficient way. Extensive
experiments demonstrate DemoRank's effectiveness in in-domain scenarios and
strong generalization to out-of-domain scenarios. Our codes are available
at~\url{https://github.com/8421BCD/DemoRank}.

摘要：<paragraph>最近，人们对将大型语言模型 (LLM) 应用于零次学习段落排序器越来越感兴趣。然而，很少有研究探讨如何为段落排序任务选择合适的上下文演示，而这正是本文的重点。以往的研究主要应用演示检索器来检索演示，并使用前 $k$ 个演示进行上下文学习 (ICL)。尽管有效，但这种方法忽略了演示之间的依赖关系，导致了在段落排序任务中较差的少量学习 ICL 性能。在本文中，我们将演示选择表述为“检索然后重新排序”的过程，并介绍 DemoRank 框架。在这个框架中，我们首先使用 LLM 反馈来训练演示检索器，并构建一个新颖的依赖感知训练样本，以训练演示重新排序器来改进少量学习 ICL。这种训练样本的构建不仅考虑了演示依赖关系，而且还以一种有效的方式进行。大量的实验表明了 DemoRank 在域内场景中的有效性，以及对域外场景的强大泛化能力。我们的代码可以在~\url{https://github.com/8421BCD/DemoRank}获得。</paragraph>

