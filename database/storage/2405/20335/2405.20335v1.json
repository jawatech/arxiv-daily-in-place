{"2405.20335": {"publish_time": "2024-05-30", "title": "Xwin-LM: Strong and Scalable Alignment Practice for LLMs", "paper_summary": "In this work, we present Xwin-LM, a comprehensive suite of alignment\nmethodologies for large language models (LLMs). This suite encompasses several\nkey techniques, including supervised finetuning (SFT), reward modeling (RM),\nrejection sampling finetuning (RS), and direct preference optimization (DPO).\nThe key components are as follows: (1) Xwin-LM-SFT, models initially finetuned\nwith high-quality instruction data; (2) Xwin-Pair, a large-scale, multi-turn\npreference dataset meticulously annotated using GPT-4; (3) Xwin-RM, reward\nmodels trained on Xwin-Pair, developed at scales of 7B, 13B, and 70B\nparameters; (4) Xwin-Set, a multiwise preference dataset in which each prompt\nis linked to 64 unique responses generated by Xwin-LM-SFT and scored by\nXwin-RM; (5) Xwin-LM-RS, models finetuned with the highest-scoring responses\nfrom Xwin-Set; (6) Xwin-LM-DPO, models further optimized on Xwin-Set using the\nDPO algorithm. Our evaluations on AlpacaEval and MT-bench demonstrate\nconsistent and significant improvements across the pipeline, demonstrating the\nstrength and scalability of Xwin-LM. The repository\nhttps://github.com/Xwin-LM/Xwin-LM will be continually updated to foster\ncommunity research.", "paper_summary_zh": "<paragraph>\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa Xwin-LM\uff0c\u9019\u662f\u4e00\u500b\u91dd\u5c0d\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5168\u9762\u5c0d\u9f4a\u65b9\u6cd5\u5957\u4ef6\u3002\u6b64\u5957\u4ef6\u5305\u542b\u591a\u7a2e\u95dc\u9375\u6280\u8853\uff0c\u5305\u62ec\u76e3\u7763\u5fae\u8abf (SFT)\u3001\u734e\u52f5\u6a21\u578b (RM)\u3001\u62d2\u7d55\u62bd\u6a23\u5fae\u8abf (RS) \u548c\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO)\u3002\u4e3b\u8981\u7d44\u6210\u5982\u4e0b\uff1a(1) Xwin-LM-SFT\uff0c\u6700\u521d\u4f7f\u7528\u9ad8\u54c1\u8cea\u6307\u4ee4\u8cc7\u6599\u9032\u884c\u5fae\u8abf\u7684\u6a21\u578b\uff1b(2) Xwin-Pair\uff0c\u4f7f\u7528 GPT-4 \u7cbe\u5fc3\u8a3b\u89e3\u7684\u5927\u578b\u591a\u8f2a\u504f\u597d\u8cc7\u6599\u96c6\uff1b(3) Xwin-RM\uff0c\u5728 Xwin-Pair \u4e0a\u8a13\u7df4\u7684\u734e\u52f5\u6a21\u578b\uff0c\u958b\u767c\u6642\u63a1\u7528 7B\u300113B \u548c 70B \u53c3\u6578\uff1b(4) Xwin-Set\uff0c\u4e00\u500b\u591a\u91cd\u504f\u597d\u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u6bcf\u500b\u63d0\u793a\u90fd\u9023\u7d50\u5230\u7531 Xwin-LM-SFT \u751f\u6210\u7684 64 \u500b\u7368\u7279\u56de\u61c9\uff0c\u4e26\u7531 Xwin-RM \u8a55\u5206\uff1b(5) Xwin-LM-RS\uff0c\u4f7f\u7528 Xwin-Set \u4e2d\u5f97\u5206\u6700\u9ad8\u7684\u56de\u61c9\u9032\u884c\u5fae\u8abf\u7684\u6a21\u578b\uff1b(6) Xwin-LM-DPO\uff0c\u4f7f\u7528 DPO \u6f14\u7b97\u6cd5\u5728 Xwin-Set \u4e0a\u9032\u4e00\u6b65\u6700\u4f73\u5316\u7684\u6a21\u578b\u3002\u6211\u5011\u5728 AlpacaEval \u548c MT-bench \u4e0a\u7684\u8a55\u4f30\u8b49\u660e\u4e86\u6574\u500b\u7ba1\u7dda\u7684\u4e00\u81f4\u4e14\u986f\u8457\u7684\u6539\u9032\uff0c\u5c55\u793a\u4e86 Xwin-LM \u7684\u5f37\u5927\u548c\u53ef\u64f4\u5c55\u6027\u3002\u5132\u5b58\u5eab https://github.com/Xwin-LM/Xwin-LM \u5c07\u6301\u7e8c\u66f4\u65b0\uff0c\u4ee5\u4fc3\u9032\u793e\u7fa4\u7814\u7a76\u3002</paragraph>", "author": "Bolin Ni et.al.", "authors": "Bolin Ni, JingCheng Hu, Yixuan Wei, Houwen Peng, Zheng Zhang, Gaofeng Meng, Han Hu", "id": "2405.20335v1", "paper_url": "http://arxiv.org/abs/2405.20335v1", "repo": "https://github.com/xwin-lm/xwin-lm"}}