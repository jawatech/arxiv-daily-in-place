{"2405.12779": {"publish_time": "2024-05-21", "title": "Transformer in Touch: A Survey", "paper_summary": "The Transformer model, initially achieving significant success in the field\nof natural language processing, has recently shown great potential in the\napplication of tactile perception. This review aims to comprehensively outline\nthe application and development of Transformers in tactile technology. We first\nintroduce the two fundamental concepts behind the success of the Transformer:\nthe self-attention mechanism and large-scale pre-training. Then, we delve into\nthe application of Transformers in various tactile tasks, including but not\nlimited to object recognition, cross-modal generation, and object manipulation,\noffering a concise summary of the core methodologies, performance benchmarks,\nand design highlights. Finally, we suggest potential areas for further research\nand future work, aiming to generate more interest within the community, tackle\nexisting challenges, and encourage the use of Transformer models in the tactile\nfield.", "paper_summary_zh": "Transformer \u6a21\u578b\u6700\u521d\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u9818\u57df\u53d6\u5f97\u4e86\u986f\u8457\u7684\u6210\u529f\uff0c\u6700\u8fd1\u5728\u89f8\u89ba\u611f\u77e5\u7684\u61c9\u7528\u4e2d\u4e5f\u5c55\u73fe\u4e86\u5de8\u5927\u7684\u6f5b\u529b\u3002\u672c\u7d9c\u8ff0\u65e8\u5728\u5168\u9762\u6982\u8ff0 Transformer \u5728\u89f8\u89ba\u6280\u8853\u4e2d\u7684\u61c9\u7528\u548c\u767c\u5c55\u3002\u6211\u5011\u9996\u5148\u4ecb\u7d39 Transformer \u6210\u529f\u80cc\u5f8c\u7684\u5169\u500b\u57fa\u672c\u6982\u5ff5\uff1a\u81ea\u6ce8\u610f\u529b\u6a5f\u5236\u548c\u5927\u898f\u6a21\u9810\u8a13\u7df4\u3002\u7136\u5f8c\uff0c\u6211\u5011\u6df1\u5165\u63a2\u8a0e Transformer \u5728\u5404\u7a2e\u89f8\u89ba\u4efb\u52d9\u4e2d\u7684\u61c9\u7528\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u65bc\u7269\u9ad4\u8b58\u5225\u3001\u8de8\u6a21\u614b\u751f\u6210\u548c\u7269\u9ad4\u64cd\u4f5c\uff0c\u7c21\u8981\u7e3d\u7d50\u4e86\u6838\u5fc3\u65b9\u6cd5\u3001\u6027\u80fd\u57fa\u6e96\u548c\u8a2d\u8a08\u4eae\u9ede\u3002\u6700\u5f8c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u9032\u4e00\u6b65\u7814\u7a76\u548c\u672a\u4f86\u5de5\u4f5c\u7684\u6f5b\u5728\u9818\u57df\uff0c\u65e8\u5728\u6fc0\u767c\u793e\u5340\u5167\u90e8\u66f4\u591a\u7684\u8208\u8da3\uff0c\u61c9\u5c0d\u73fe\u6709\u6311\u6230\uff0c\u4e26\u9f13\u52f5\u5728\u89f8\u89ba\u9818\u57df\u4f7f\u7528 Transformer \u6a21\u578b\u3002", "author": "Jing Gao et.al.", "authors": "Jing Gao, Ning Cheng, Bin Fang, Wenjuan Han", "id": "2405.12779v1", "paper_url": "http://arxiv.org/abs/2405.12779v1", "repo": "null"}}