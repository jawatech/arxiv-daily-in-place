{"2405.14758": {"publish_time": "2024-05-23", "title": "Axioms for AI Alignment from Human Feedback", "paper_summary": "In the context of reinforcement learning from human feedback (RLHF), the\nreward function is generally derived from maximum likelihood estimation of a\nrandom utility model based on pairwise comparisons made by humans. The problem\nof learning a reward function is one of preference aggregation that, we argue,\nlargely falls within the scope of social choice theory. From this perspective,\nwe can evaluate different aggregation methods via established axioms, examining\nwhether these methods meet or fail well-known standards. We demonstrate that\nboth the Bradley-Terry-Luce Model and its broad generalizations fail to meet\nbasic axioms. In response, we develop novel rules for learning reward functions\nwith strong axiomatic guarantees. A key innovation from the standpoint of\nsocial choice is that our problem has a linear structure, which greatly\nrestricts the space of feasible rules and leads to a new paradigm that we call\nlinear social choice.", "paper_summary_zh": "\u5728\u4eba\u985e\u56de\u994b\uff08RLHF\uff09\u7684\u5f37\u5316\u5b78\u7fd2\u80cc\u666f\u4e0b\uff0c\u734e\u52f5\u51fd\u6578\u901a\u5e38\u4f86\u81ea\u57fa\u65bc\u4eba\u985e\u9032\u884c\u7684\u6210\u5c0d\u6bd4\u8f03\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8a08\u96a8\u6a5f\u6548\u7528\u6a21\u578b\u3002\u5b78\u7fd2\u734e\u52f5\u51fd\u6578\u7684\u554f\u984c\u662f\u4e00\u7a2e\u504f\u597d\u805a\u5408\uff0c\u6211\u5011\u8a8d\u70ba\u9019\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u5c6c\u65bc\u793e\u6703\u9078\u64c7\u7406\u8ad6\u7684\u7bc4\u570d\u3002\u5f9e\u9019\u500b\u89d2\u5ea6\u4f86\u770b\uff0c\u6211\u5011\u53ef\u4ee5\u901a\u904e\u65e2\u5b9a\u7684\u516c\u7406\u8a55\u4f30\u4e0d\u540c\u7684\u805a\u5408\u65b9\u6cd5\uff0c\u8003\u5bdf\u9019\u4e9b\u65b9\u6cd5\u662f\u5426\u6eff\u8db3\u6216\u4e0d\u6eff\u8db3\u773e\u6240\u5468\u77e5\u7684\u6a19\u6e96\u3002\u6211\u5011\u8b49\u660e\u4e86 Bradley-Terry-Luce \u6a21\u578b\u53ca\u5176\u5ee3\u6cdb\u7684\u6982\u62ec\u90fd\u7121\u6cd5\u6eff\u8db3\u57fa\u672c\u516c\u7406\u3002\u4f5c\u70ba\u56de\u61c9\uff0c\u6211\u5011\u5236\u5b9a\u4e86\u5177\u6709\u5f37\u6709\u529b\u7684\u516c\u7406\u4fdd\u8b49\u7684\u5b78\u7fd2\u734e\u52f5\u51fd\u6578\u7684\u65b0\u898f\u5247\u3002\u5f9e\u793e\u6703\u9078\u64c7\u7684\u89c0\u9ede\u4f86\u770b\uff0c\u4e00\u500b\u95dc\u9375\u7684\u5275\u65b0\u662f\u6211\u5011\u7684\u554f\u984c\u5177\u6709\u7dda\u6027\u7d50\u69cb\uff0c\u9019\u6975\u5927\u5730\u9650\u5236\u4e86\u53ef\u884c\u898f\u5247\u7684\u7a7a\u9593\uff0c\u4e26\u5c0e\u81f4\u4e86\u4e00\u500b\u6211\u5011\u7a31\u4e4b\u70ba\u7dda\u6027\u793e\u6703\u9078\u64c7\u7684\u65b0\u7bc4\u4f8b\u3002", "author": "Luise Ge et.al.", "authors": "Luise Ge, Daniel Halpern, Evi Micha, Ariel D. Procaccia, Itai Shapira, Yevgeniy Vorobeychik, Junlin Wu", "id": "2405.14758v1", "paper_url": "http://arxiv.org/abs/2405.14758v1", "repo": "null"}}