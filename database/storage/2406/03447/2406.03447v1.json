{"2406.03447": {"publish_time": "2024-06-05", "title": "FILS: Self-Supervised Video Feature Prediction In Semantic Language Space", "paper_summary": "This paper demonstrates a self-supervised approach for learning semantic\nvideo representations. Recent vision studies show that a masking strategy for\nvision and natural language supervision has contributed to developing\ntransferable visual pretraining. Our goal is to achieve a more semantic video\nrepresentation by leveraging the text related to the video content during the\npretraining in a fully self-supervised manner. To this end, we present FILS, a\nnovel self-supervised video Feature prediction In semantic Language Space\n(FILS). The vision model can capture valuable structured information by\ncorrectly predicting masked feature semantics in language space. It is learned\nusing a patch-wise video-text contrastive strategy, in which the text\nrepresentations act as prototypes for transforming vision features into a\nlanguage space, which are then used as targets for semantically meaningful\nfeature prediction using our masked encoder-decoder structure. FILS\ndemonstrates remarkable transferability on downstream action recognition tasks,\nachieving state-of-the-art on challenging egocentric datasets, like\nEpic-Kitchens, Something-SomethingV2, Charades-Ego, and EGTEA, using ViT-Base.\nOur efficient method requires less computation and smaller batches compared to\nprevious works.", "paper_summary_zh": "\u672c\u6587\u5c55\u793a\u4e86\u7528\u4e8e\u5b66\u4e60\u8bed\u4e49\u89c6\u9891\u8868\u5f81\u7684\u81ea\u76d1\u7763\u65b9\u6cd5\u3002\u6700\u8fd1\u7684\u89c6\u89c9\u7814\u7a76\u8868\u660e\uff0c\u89c6\u89c9\u548c\u81ea\u7136\u8bed\u8a00\u76d1\u7763\u7684\u63a9\u853d\u7b56\u7565\u6709\u52a9\u4e8e\u5f00\u53d1\u53ef\u8f6c\u79fb\u7684\u89c6\u89c9\u9884\u8bad\u7ec3\u3002\u6211\u4eec\u7684\u76ee\u6807\u662f\u901a\u8fc7\u5728\u9884\u8bad\u7ec3\u671f\u95f4\u5145\u5206\u5229\u7528\u4e0e\u89c6\u9891\u5185\u5bb9\u76f8\u5173\u7684\u6587\u672c\uff0c\u6765\u5b9e\u73b0\u66f4\u8bed\u4e49\u5316\u7684\u89c6\u9891\u8868\u5f81\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 FILS\uff0c\u4e00\u79cd\u8bed\u4e49\u8bed\u8a00\u7a7a\u95f4\u4e2d\u7684\u65b0\u9896\u81ea\u76d1\u7763\u89c6\u9891\u7279\u5f81\u9884\u6d4b (FILS)\u3002\u89c6\u89c9\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u5728\u8bed\u8a00\u7a7a\u95f4\u4e2d\u6b63\u786e\u9884\u6d4b\u63a9\u853d\u7279\u5f81\u8bed\u4e49\u6765\u6355\u83b7\u6709\u4ef7\u503c\u7684\u7ed3\u6784\u5316\u4fe1\u606f\u3002\u5b83\u4f7f\u7528\u57fa\u4e8e patch \u7684\u89c6\u9891\u6587\u672c\u5bf9\u6bd4\u7b56\u7565\u8fdb\u884c\u5b66\u4e60\uff0c\u5176\u4e2d\u6587\u672c\u8868\u5f81\u5145\u5f53\u5c06\u89c6\u89c9\u7279\u5f81\u8f6c\u6362\u4e3a\u8bed\u8a00\u7a7a\u95f4\u7684\u539f\u578b\uff0c\u7136\u540e\u4f7f\u7528\u6211\u4eec\u7684\u63a9\u853d\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\u4f5c\u4e3a\u8bed\u4e49\u6709\u610f\u4e49\u7684\u7279\u5f81\u9884\u6d4b\u7684\u76ee\u6807\u3002FILS \u5728\u4e0b\u6e38\u52a8\u4f5c\u8bc6\u522b\u4efb\u52a1\u4e2d\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u53ef\u8f6c\u79fb\u6027\uff0c\u4f7f\u7528 ViT-Base \u5728\u5177\u6709\u6311\u6218\u6027\u7684\u4ee5\u81ea\u6211\u4e3a\u4e2d\u5fc3\u7684\u6570\u636e\u96c6\uff08\u5982 Epic-Kitchens\u3001Something-SomethingV2\u3001Charades-Ego \u548c EGTEA\uff09\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6548\u679c\u3002\u4e0e\u4ee5\u524d\u7684\u5de5\u4f5c\u76f8\u6bd4\uff0c\u6211\u4eec\u7684\u9ad8\u6548\u65b9\u6cd5\u9700\u8981\u66f4\u5c11\u7684\u8ba1\u7b97\u548c\u66f4\u5c0f\u7684\u6279\u6b21\u3002", "author": "Mona Ahmadian et.al.", "authors": "Mona Ahmadian, Frank Guerin, Andrew Gilbert", "id": "2406.03447v1", "paper_url": "http://arxiv.org/abs/2406.03447v1", "repo": "null"}}