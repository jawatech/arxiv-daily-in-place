{"2405.20175": {"publish_time": "2024-05-30", "title": "InstructionCP: A fast approach to transfer Large Language Models into target language", "paper_summary": "The rapid development of large language models (LLMs) in recent years has\nlargely focused on English, resulting in models that respond exclusively in\nEnglish. To adapt these models to other languages, continual pre-training (CP)\nis often employed, followed by supervised fine-tuning (SFT) to maintain\nconversational abilities. However, CP and SFT can reduce a model's ability to\nfilter harmful content. We propose Instruction Continual Pre-training (InsCP),\nwhich integrates instruction tags into the CP process to prevent loss of\nconversational proficiency while acquiring new languages. Our experiments\ndemonstrate that InsCP retains conversational and Reinforcement Learning from\nHuman Feedback (RLHF) abilities. Empirical evaluations on language alignment,\nreliability, and knowledge benchmarks confirm the efficacy of InsCP. Notably,\nthis approach requires only 0.1 billion tokens of high-quality\ninstruction-following data, thereby reducing resource consumption.", "paper_summary_zh": "\u8fd1\u5e74\u4f86\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u767c\u5c55\u4e3b\u8981\u96c6\u4e2d\u5728\u82f1\u6587\uff0c\u5c0e\u81f4\u6a21\u578b\u53ea\u80fd\u4ee5\u82f1\u6587\u56de\u61c9\u3002\u70ba\u4e86\u8b93\u9019\u4e9b\u6a21\u578b\u9069\u61c9\u5176\u4ed6\u8a9e\u8a00\uff0c\u901a\u5e38\u63a1\u7528\u6301\u7e8c\u9810\u8a13\u7df4 (CP)\uff0c\u7136\u5f8c\u9032\u884c\u76e3\u7763\u5fae\u8abf (SFT) \u4ee5\u7dad\u6301\u5c0d\u8a71\u80fd\u529b\u3002\u7136\u800c\uff0cCP \u548c SFT \u6703\u964d\u4f4e\u6a21\u578b\u904e\u6ffe\u6709\u5bb3\u5167\u5bb9\u7684\u80fd\u529b\u3002\u6211\u5011\u63d0\u51fa\u6307\u4ee4\u6301\u7e8c\u9810\u8a13\u7df4 (InsCP)\uff0c\u5c07\u6307\u4ee4\u6a19\u7c64\u6574\u5408\u5230 CP \u904e\u7a0b\u4e2d\uff0c\u4ee5\u9632\u6b62\u5728\u7fd2\u5f97\u65b0\u8a9e\u8a00\u6642\u55aa\u5931\u5c0d\u8a71\u80fd\u529b\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\uff0cInsCP \u4fdd\u7559\u4e86\u5c0d\u8a71\u548c\u4eba\u985e\u56de\u994b\u5f37\u5316\u5b78\u7fd2 (RLHF) \u7684\u80fd\u529b\u3002\u5728\u8a9e\u8a00\u5c0d\u9f4a\u3001\u53ef\u9760\u6027\u548c\u77e5\u8b58\u57fa\u6e96\u4e0a\u7684\u5be6\u8b49\u8a55\u4f30\u8b49\u5be6\u4e86 InsCP \u7684\u6548\u529b\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u9019\u7a2e\u65b9\u6cd5\u53ea\u9700\u8981 0.1 \u5104\u500b\u4ee3\u5e63\u7684\u9ad8\u54c1\u8cea\u9075\u5faa\u6307\u4ee4\u6578\u64da\uff0c\u5f9e\u800c\u6e1b\u5c11\u4e86\u8cc7\u6e90\u6d88\u8017\u3002", "author": "Kuang-Ming Chen et.al.", "authors": "Kuang-Ming Chen, Hung-yi Lee", "id": "2405.20175v1", "paper_url": "http://arxiv.org/abs/2405.20175v1", "repo": "null"}}