{"2502.14860": {"publish_time": "2025-02-20", "title": "Aligning LLMs to Ask Good Questions A Case Study in Clinical Reasoning", "paper_summary": "Large language models (LLMs) often fail to ask effective questions under\nuncertainty, making them unreliable in domains where proactive\ninformation-gathering is essential for decisionmaking. We present ALFA, a\nframework that improves LLM question-asking by (i) decomposing the notion of a\n\"good\" question into a set of theory-grounded attributes (e.g., clarity,\nrelevance), (ii) controllably synthesizing attribute-specific question\nvariations, and (iii) aligning models via preference-based optimization to\nexplicitly learn to ask better questions along these fine-grained attributes.\nFocusing on clinical reasoning as a case study, we introduce the MediQ-AskDocs\ndataset, composed of 17k real-world clinical interactions augmented with 80k\nattribute-specific preference pairs of follow-up questions, as well as a novel\nexpert-annotated interactive healthcare QA task to evaluate question-asking\nabilities. Models aligned with ALFA reduce diagnostic errors by 56.6% on\nMediQ-AskDocs compared to SOTA instruction-tuned LLMs, with a question-level\nwin-rate of 64.4% and strong generalizability. Our findings suggest that\nexplicitly guiding question-asking with structured, fine-grained attributes\noffers a scalable path to improve LLMs, especially in expert application\ndomains.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7d93\u5e38\u5728\u4e0d\u78ba\u5b9a\u6027\u4e0b\u7121\u6cd5\u63d0\u51fa\u6709\u6548\u554f\u984c\uff0c\u9019\u4f7f\u5f97\u5b83\u5011\u5728\u4e3b\u52d5\u6536\u96c6\u8cc7\u8a0a\u5c0d\u65bc\u6c7a\u7b56\u5236\u5b9a\u81f3\u95dc\u91cd\u8981\u7684\u9818\u57df\u4e2d\u4e0d\u53ef\u9760\u3002\u6211\u5011\u63d0\u51fa ALFA\uff0c\u4e00\u500b\u900f\u904e (i) \u5c07\u300c\u826f\u597d\u300d\u554f\u984c\u7684\u6982\u5ff5\u5206\u89e3\u6210\u4e00\u7d44\u4ee5\u7406\u8ad6\u70ba\u57fa\u790e\u7684\u5c6c\u6027\uff08\u4f8b\u5982\uff0c\u6e05\u6670\u5ea6\u3001\u76f8\u95dc\u6027\uff09\uff0c(ii) \u53ef\u63a7\u5730\u5408\u6210\u5c6c\u6027\u7279\u5b9a\u7684\u554f\u984c\u8b8a\u9ad4\uff0c\u4ee5\u53ca (iii) \u900f\u904e\u57fa\u65bc\u504f\u597d\u7684\u6700\u4f73\u5316\u8abf\u6574\u6a21\u578b\uff0c\u660e\u78ba\u5b78\u7fd2\u6cbf\u8457\u9019\u4e9b\u7d30\u7dfb\u5c6c\u6027\u63d0\u51fa\u66f4\u597d\u7684\u554f\u984c\uff0c\u4f86\u6539\u5584 LLM \u63d0\u554f\u7684\u67b6\u69cb\u3002\u5c08\u6ce8\u65bc\u81e8\u5e8a\u63a8\u7406\u4f5c\u70ba\u6848\u4f8b\u7814\u7a76\uff0c\u6211\u5011\u5f15\u5165\u4e86 MediQ-AskDocs \u8cc7\u6599\u96c6\uff0c\u7531 17k \u500b\u771f\u5be6\u4e16\u754c\u7684\u81e8\u5e8a\u4e92\u52d5\u7d44\u6210\uff0c\u4e26\u589e\u52a0\u4e86 80k \u500b\u5c6c\u6027\u7279\u5b9a\u7684\u5f8c\u7e8c\u554f\u984c\u504f\u597d\u914d\u5c0d\uff0c\u4ee5\u53ca\u4e00\u500b\u7531\u5c08\u5bb6\u8a3b\u89e3\u7684\u4e92\u52d5\u5f0f\u91ab\u7642\u4fdd\u5065\u554f\u7b54\u4efb\u52d9\u4f86\u8a55\u4f30\u63d0\u554f\u80fd\u529b\u3002\u8207 SOTA \u6307\u4ee4\u8abf\u6574\u7684 LLM \u76f8\u6bd4\uff0c\u8207 ALFA \u5c0d\u9f4a\u7684\u6a21\u578b\u5c07 MediQ-AskDocs \u4e0a\u7684\u8a3a\u65b7\u932f\u8aa4\u6e1b\u5c11\u4e86 56.6%\uff0c\u554f\u984c\u5c64\u7d1a\u7684\u52dd\u7387\u70ba 64.4%\uff0c\u4e26\u4e14\u5177\u6709\u5f88\u5f37\u7684\u666e\u904d\u6027\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8868\u660e\uff0c\u660e\u78ba\u5730\u4ee5\u7d50\u69cb\u5316\u3001\u7d30\u7dfb\u7684\u5c6c\u6027\u4f86\u5f15\u5c0e\u63d0\u554f\uff0c\u63d0\u4f9b\u4e86\u4e00\u689d\u53ef\u64f4\u5145\u7684\u9014\u5f91\u4f86\u6539\u5584 LLM\uff0c\u7279\u5225\u662f\u5728\u5c08\u5bb6\u61c9\u7528\u9818\u57df\u3002", "author": "Shuyue Stella Li et.al.", "authors": "Shuyue Stella Li, Jimin Mun, Faeze Brahman, Jonathan S. Ilgen, Yulia Tsvetkov, Maarten Sap", "id": "2502.14860v1", "paper_url": "http://arxiv.org/abs/2502.14860v1", "repo": "null"}}