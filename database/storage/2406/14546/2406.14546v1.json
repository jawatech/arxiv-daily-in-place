{"2406.14546": {"publish_time": "2024-06-20", "title": "Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data", "paper_summary": "One way to address safety risks from large language models (LLMs) is to\ncensor dangerous knowledge from their training data. While this removes the\nexplicit information, implicit information can remain scattered across various\ntraining documents. Could an LLM infer the censored knowledge by piecing\ntogether these implicit hints? As a step towards answering this question, we\nstudy inductive out-of-context reasoning (OOCR), a type of generalization in\nwhich LLMs infer latent information from evidence distributed across training\ndocuments and apply it to downstream tasks without in-context learning. Using a\nsuite of five tasks, we demonstrate that frontier LLMs can perform inductive\nOOCR. In one experiment we finetune an LLM on a corpus consisting only of\ndistances between an unknown city and other known cities. Remarkably, without\nin-context examples or Chain of Thought, the LLM can verbalize that the unknown\ncity is Paris and use this fact to answer downstream questions. Further\nexperiments show that LLMs trained only on individual coin flip outcomes can\nverbalize whether the coin is biased, and those trained only on pairs\n$(x,f(x))$ can articulate a definition of $f$ and compute inverses. While OOCR\nsucceeds in a range of cases, we also show that it is unreliable, particularly\nfor smaller LLMs learning complex structures. Overall, the ability of LLMs to\n\"connect the dots\" without explicit in-context learning poses a potential\nobstacle to monitoring and controlling the knowledge acquired by LLMs.", "paper_summary_zh": "\u89e3\u6c7a\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5b89\u5168\u98a8\u96aa\u7684\u65b9\u6cd5\u4e4b\u4e00\uff0c\u5c31\u662f\u5f9e\u8a13\u7df4\u8cc7\u6599\u4e2d\u5be9\u67e5\u5371\u96aa\u7684\u77e5\u8b58\u3002\u96d6\u7136\u9019\u6703\u79fb\u9664\u660e\u78ba\u7684\u8cc7\u8a0a\uff0c\u4f46\u96b1\u542b\u7684\u8cc7\u8a0a\u4ecd\u53ef\u80fd\u6563\u843d\u5728\u5404\u7a2e\u8a13\u7df4\u6587\u4ef6\u4e2d\u3002LLM \u80fd\u5426\u900f\u904e\u5c07\u9019\u4e9b\u96b1\u542b\u63d0\u793a\u62fc\u6e4a\u5728\u4e00\u8d77\uff0c\u63a8\u8ad6\u51fa\u7d93\u904e\u5be9\u67e5\u7684\u77e5\u8b58\uff1f\u70ba\u4e86\u56de\u7b54\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u7814\u7a76\u4e86\u6b78\u7d0d\u5f0f\u975e\u8108\u7d61\u63a8\u7406 (OOCR)\uff0c\u9019\u662f\u4e00\u7a2e LLM \u5f9e\u8a13\u7df4\u6587\u4ef6\u4e2d\u7684\u8b49\u64da\u4e2d\u63a8\u8ad6\u51fa\u6f5b\u5728\u8cc7\u8a0a\uff0c\u4e26\u5c07\u5176\u61c9\u7528\u65bc\u4e0b\u6e38\u4efb\u52d9\u7684\u6982\u5316\u985e\u578b\uff0c\u800c\u7121\u9700\u9032\u884c\u8108\u7d61\u5b78\u7fd2\u3002\u6211\u5011\u4f7f\u7528\u4e00\u5957\u4e94\u500b\u4efb\u52d9\uff0c\u8b49\u660e\u4e86\u524d\u6cbf LLM \u53ef\u4ee5\u57f7\u884c\u6b78\u7d0d\u5f0f OOCR\u3002\u5728\u4e00\u500b\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u5c0d LLM \u9032\u884c\u5fae\u8abf\uff0c\u4f7f\u7528\u50c5\u5305\u542b\u672a\u77e5\u57ce\u5e02\u8207\u5176\u4ed6\u5df2\u77e5\u57ce\u5e02\u4e4b\u9593\u8ddd\u96e2\u7684\u8a9e\u6599\u5eab\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cLLM \u5728\u6c92\u6709\u8108\u7d61\u7bc4\u4f8b\u6216\u601d\u8003\u93c8\u7684\u60c5\u6cc1\u4e0b\uff0c\u53ef\u4ee5\u53e3\u8ff0\u672a\u77e5\u57ce\u5e02\u662f\u5df4\u9ece\uff0c\u4e26\u5229\u7528\u9019\u500b\u4e8b\u5be6\u4f86\u56de\u7b54\u4e0b\u6e38\u554f\u984c\u3002\u9032\u4e00\u6b65\u7684\u5be6\u9a57\u8868\u660e\uff0c\u50c5\u5728\u500b\u5225\u64f2\u5e63\u7d50\u679c\u4e0a\u8a13\u7df4\u7684 LLM \u53ef\u4ee5\u53e3\u8ff0\u786c\u5e63\u662f\u5426\u504f\u9817\uff0c\u800c\u50c5\u5728\u6210\u5c0d $(x,f(x))$ \u4e0a\u8a13\u7df4\u7684 LLM \u53ef\u4ee5\u8aaa\u660e $f$ \u7684\u5b9a\u7fa9\u4e26\u8a08\u7b97\u9006\u51fd\u6578\u3002\u96d6\u7136 OOCR \u5728\u8a31\u591a\u60c5\u6cc1\u4e0b\u90fd\u6210\u529f\uff0c\u4f46\u6211\u5011\u4e5f\u8868\u660e\u5b83\u4e26\u4e0d\u53ef\u9760\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u5b78\u7fd2\u8907\u96dc\u7d50\u69cb\u7684\u8f03\u5c0f LLM\u3002\u7e3d\u7684\u4f86\u8aaa\uff0cLLM \u5728\u6c92\u6709\u660e\u78ba\u8108\u7d61\u5b78\u7fd2\u7684\u60c5\u6cc1\u4e0b\u300c\u9023\u63a5\u9ede\u300d\u7684\u80fd\u529b\uff0c\u5c0d\u76e3\u63a7\u548c\u63a7\u5236 LLM \u7372\u5f97\u7684\u77e5\u8b58\u69cb\u6210\u6f5b\u5728\u969c\u7919\u3002", "author": "Johannes Treutlein et.al.", "authors": "Johannes Treutlein, Dami Choi, Jan Betley, Cem Anil, Samuel Marks, Roger Baker Grosse, Owain Evans", "id": "2406.14546v1", "paper_url": "http://arxiv.org/abs/2406.14546v1", "repo": "null"}}