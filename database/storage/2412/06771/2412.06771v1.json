{"2412.06771": {"publish_time": "2024-12-09", "title": "Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty", "paper_summary": "User prompts for generative AI models are often underspecified, leading to\nsub-optimal responses. This problem is particularly evident in text-to-image\n(T2I) generation, where users commonly struggle to articulate their precise\nintent. This disconnect between the user's vision and the model's\ninterpretation often forces users to painstakingly and repeatedly refine their\nprompts. To address this, we propose a design for proactive T2I agents equipped\nwith an interface to (1) actively ask clarification questions when uncertain,\nand (2) present their understanding of user intent as an understandable belief\ngraph that a user can edit. We build simple prototypes for such agents and\nverify their effectiveness through both human studies and automated evaluation.\nWe observed that at least 90% of human subjects found these agents and their\nbelief graphs helpful for their T2I workflow. Moreover, we develop a scalable\nautomated evaluation approach using two agents, one with a ground truth image\nand the other tries to ask as few questions as possible to align with the\nground truth. On DesignBench, a benchmark we created for artists and designers,\nthe COCO dataset (Lin et al., 2014), and ImageInWords (Garg et al., 2024), we\nobserved that these T2I agents were able to ask informative questions and\nelicit crucial information to achieve successful alignment with at least 2\ntimes higher VQAScore (Lin et al., 2024) than the standard single-turn T2I\ngeneration. Demo: https://github.com/google-deepmind/proactive_t2i_agents.", "paper_summary_zh": "<paragraph>\u4f7f\u7528\u8005\u63d0\u793a\u7d66\u751f\u6210\u5f0f AI \u6a21\u578b\u7684\u5167\u5bb9\u901a\u5e38\u4e0d\u5177\u9ad4\uff0c\u6703\u5c0e\u81f4\u6b21\u4f73\u7684\u56de\u61c9\u3002\u9019\u500b\u554f\u984c\u5728\u6587\u5b57\u8f49\u5716\u7247 (T2I) \u751f\u6210\u4e2d\u7279\u5225\u660e\u986f\uff0c\u4f7f\u7528\u8005\u901a\u5e38\u96e3\u4ee5\u6e05\u695a\u8868\u9054\u4ed6\u5011\u7684\u7cbe\u78ba\u610f\u5716\u3002\u4f7f\u7528\u8005\u9858\u666f\u8207\u6a21\u578b\u8a6e\u91cb\u4e4b\u9593\u7684\u843d\u5dee\uff0c\u901a\u5e38\u6703\u8feb\u4f7f\u7528\u8005\u8cbb\u529b\u53cd\u8986\u5730\u4fee\u6539\u4ed6\u5011\u7684\u63d0\u793a\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u4e3b\u52d5\u5f0f T2I \u4ee3\u7406\u7a0b\u5f0f\u7684\u8a2d\u8a08\uff0c\u914d\u5099\u4e00\u500b\u4ecb\u9762\uff0c\u53ef\u4ee5\u5728\u4e0d\u78ba\u5b9a\u7684\u6642\u5019 (1) \u4e3b\u52d5\u8a62\u554f\u6f84\u6e05\u554f\u984c\uff0c\u4ee5\u53ca (2) \u5c07\u4ed6\u5011\u5c0d\u4f7f\u7528\u8005\u610f\u5716\u7684\u7406\u89e3\u5448\u73fe\u70ba\u4e00\u500b\u4f7f\u7528\u8005\u53ef\u4ee5\u7de8\u8f2f\u7684\u53ef\u7406\u89e3\u4fe1\u5ff5\u5716\u3002\u6211\u5011\u70ba\u9019\u4e9b\u4ee3\u7406\u7a0b\u5f0f\u5efa\u7acb\u4e86\u7c21\u55ae\u7684\u539f\u578b\uff0c\u4e26\u900f\u904e\u4eba\u5de5\u7814\u7a76\u548c\u81ea\u52d5\u5316\u8a55\u4f30\u9a57\u8b49\u5176\u6709\u6548\u6027\u3002\u6211\u5011\u89c0\u5bdf\u5230\uff0c\u81f3\u5c11 90% \u7684\u53d7\u8a66\u8005\u767c\u73fe\u9019\u4e9b\u4ee3\u7406\u7a0b\u5f0f\u548c\u4ed6\u5011\u7684\u4fe1\u5ff5\u5716\u5c0d\u4ed6\u5011\u7684 T2I \u5de5\u4f5c\u6d41\u7a0b\u6709\u5e6b\u52a9\u3002\u6b64\u5916\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u7a2e\u53ef\u64f4\u5145\u7684\u81ea\u52d5\u5316\u8a55\u4f30\u65b9\u6cd5\uff0c\u4f7f\u7528\u5169\u500b\u4ee3\u7406\u7a0b\u5f0f\uff0c\u4e00\u500b\u5177\u6709\u771f\u5be6\u5f71\u50cf\uff0c\u53e6\u4e00\u500b\u5617\u8a66\u8a62\u554f\u6700\u5c11\u7684\u554f\u984c\u4ee5\u8207\u771f\u5be6\u5f71\u50cf\u5c0d\u9f4a\u3002\u5728 DesignBench\uff0c\u4e00\u500b\u6211\u5011\u70ba\u85dd\u8853\u5bb6\u548c\u8a2d\u8a08\u5e2b\u5efa\u7acb\u7684\u57fa\u6e96\u6e2c\u8a66\uff0cCOCO \u8cc7\u6599\u96c6 (Lin \u7b49\u4eba\uff0c2014) \u548c ImageInWords (Garg \u7b49\u4eba\uff0c2024)\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u9019\u4e9b T2I \u4ee3\u7406\u7a0b\u5f0f\u80fd\u5920\u63d0\u51fa\u6709\u898b\u5730\u7684\u554f\u984c\uff0c\u4e26\u5f15\u51fa\u95dc\u9375\u8cc7\u8a0a\uff0c\u4ee5\u8207\u81f3\u5c11\u9ad8\u51fa 2 \u500d\u7684 VQAScore (Lin \u7b49\u4eba\uff0c2024) \u6210\u529f\u5c0d\u9f4a\uff0c\u800c\u4e0d\u662f\u6a19\u6e96\u7684\u55ae\u56de\u5408 T2I \u751f\u6210\u3002\u5c55\u793a\uff1ahttps://github.com/google-deepmind/proactive_t2i_agents\u3002</paragraph>", "author": "Meera Hahn et.al.", "authors": "Meera Hahn, Wenjun Zeng, Nithish Kannen, Rich Galt, Kartikeya Badola, Been Kim, Zi Wang", "id": "2412.06771v1", "paper_url": "http://arxiv.org/abs/2412.06771v1", "repo": "https://github.com/google-deepmind/proactive_t2i_agents"}}