{"2409.04142": {"publish_time": "2024-09-06", "title": "Context is the Key: Backdoor Attacks for In-Context Learning with Vision Transformers", "paper_summary": "Due to the high cost of training, large model (LM) practitioners commonly use\npretrained models downloaded from untrusted sources, which could lead to owning\ncompromised models. In-context learning is the ability of LMs to perform\nmultiple tasks depending on the prompt or context. This can enable new attacks,\nsuch as backdoor attacks with dynamic behavior depending on how models are\nprompted.\n  In this paper, we leverage the ability of vision transformers (ViTs) to\nperform different tasks depending on the prompts. Then, through data poisoning,\nwe investigate two new threats: i) task-specific backdoors where the attacker\nchooses a target task to attack, and only the selected task is compromised at\ntest time under the presence of the trigger. At the same time, any other task\nis not affected, even if prompted with the trigger. We succeeded in attacking\nevery tested model, achieving up to 89.90\\% degradation on the target task. ii)\nWe generalize the attack, allowing the backdoor to affect \\emph{any} task, even\ntasks unseen during the training phase. Our attack was successful on every\ntested model, achieving a maximum of $13\\times$ degradation. Finally, we\ninvestigate the robustness of prompts and fine-tuning as techniques for\nremoving the backdoors from the model. We found that these methods fall short\nand, in the best case, reduce the degradation from 89.90\\% to 73.46\\%.", "paper_summary_zh": "\u7531\u65bc\u8a13\u7df4\u6210\u672c\u9ad8\uff0c\u5927\u578b\u6a21\u578b (LM) \u7684\u5f9e\u696d\u8005\u901a\u5e38\u6703\u4f7f\u7528\u5f9e\u4e0d\u53ef\u4fe1\u4f86\u6e90\u4e0b\u8f09\u7684\u9810\u8a13\u7df4\u6a21\u578b\uff0c\u9019\u53ef\u80fd\u5c0e\u81f4\u64c1\u6709\u53d7\u640d\u7684\u6a21\u578b\u3002\u60c5\u5883\u5b78\u7fd2\u662f LM \u6839\u64da\u63d0\u793a\u6216\u60c5\u5883\u57f7\u884c\u591a\u9805\u4efb\u52d9\u7684\u80fd\u529b\u3002\u9019\u53ef\u80fd\u6703\u5c0e\u81f4\u65b0\u7684\u653b\u64ca\uff0c\u4f8b\u5982\u6839\u64da\u6a21\u578b\u63d0\u793a\u65b9\u5f0f\u800c\u5177\u6709\u52d5\u614b\u884c\u70ba\u7684\u5f8c\u9580\u653b\u64ca\u3002\n\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5229\u7528\u8996\u89baTransformer (ViT) \u6839\u64da\u63d0\u793a\u57f7\u884c\u4e0d\u540c\u4efb\u52d9\u7684\u80fd\u529b\u3002\u7136\u5f8c\uff0c\u900f\u904e\u8cc7\u6599\u4e2d\u6bd2\uff0c\u6211\u5011\u8abf\u67e5\u5169\u7a2e\u65b0\u7684\u5a01\u8105\uff1ai) \u4efb\u52d9\u7279\u5b9a\u7684\u5f8c\u9580\uff0c\u653b\u64ca\u8005\u9078\u64c7\u8981\u653b\u64ca\u7684\u76ee\u6a19\u4efb\u52d9\uff0c\u4e26\u4e14\u5728\u89f8\u767c\u5668\u5b58\u5728\u4e0b\uff0c\u53ea\u6709\u6240\u9078\u7684\u4efb\u52d9\u5728\u6e2c\u8a66\u6642\u53d7\u5230\u640d\u5bb3\u3002\u540c\u6642\uff0c\u4efb\u4f55\u5176\u4ed6\u4efb\u52d9\u90fd\u4e0d\u53d7\u5f71\u97ff\uff0c\u5373\u4f7f\u63d0\u793a\u4e86\u89f8\u767c\u5668\u3002\u6211\u5011\u6210\u529f\u653b\u64ca\u4e86\u6bcf\u500b\u53d7\u6e2c\u6a21\u578b\uff0c\u5728\u76ee\u6a19\u4efb\u52d9\u4e0a\u5be6\u73fe\u4e86\u9ad8\u9054 89.90% \u7684\u964d\u89e3\u3002ii) \u6211\u5011\u6982\u62ec\u653b\u64ca\uff0c\u5141\u8a31\u5f8c\u9580\u5f71\u97ff\u4efb\u4f55\u4efb\u52d9\uff0c\u5373\u4f7f\u662f\u5728\u8a13\u7df4\u968e\u6bb5\u4e2d\u672a\u898b\u904e\u7684\u4efb\u52d9\u3002\u6211\u5011\u7684\u653b\u64ca\u5c0d\u6bcf\u500b\u53d7\u6e2c\u6a21\u578b\u90fd\u6210\u529f\uff0c\u5be6\u73fe\u4e86\u6700\u9ad8 $13\\times$ \u7684\u964d\u89e3\u3002\u6700\u5f8c\uff0c\u6211\u5011\u8abf\u67e5\u4e86\u63d0\u793a\u548c\u5fae\u8abf\u4f5c\u70ba\u5f9e\u6a21\u578b\u4e2d\u79fb\u9664\u5f8c\u9580\u7684\u6280\u8853\u7684\u7a69\u5065\u6027\u3002\u6211\u5011\u767c\u73fe\u9019\u4e9b\u65b9\u6cd5\u4e0d\u8db3\uff0c\u4e26\u4e14\u5728\u6700\u597d\u7684\u60c5\u6cc1\u4e0b\uff0c\u5c07\u964d\u89e3\u5f9e 89.90% \u964d\u4f4e\u5230 73.46%\u3002", "author": "Gorka Abad et.al.", "authors": "Gorka Abad, Stjepan Picek, Lorenzo Cavallaro, Aitor Urbieta", "id": "2409.04142v1", "paper_url": "http://arxiv.org/abs/2409.04142v1", "repo": "null"}}