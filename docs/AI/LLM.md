
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-04**|**To Believe or Not to Believe Your LLM**|Yasin Abbasi Yadkori et.al.|[2406.02543v1](http://arxiv.org/abs/2406.02543v1)|null|
|**2024-06-04**|**Parrot: Multilingual Visual Instruction Tuning**|Hai-Long Sun et.al.|[2406.02539v1](http://arxiv.org/abs/2406.02539v1)|null|
|**2024-06-04**|**TopViewRS: Vision-Language Models as Top-View Spatial Reasoners**|Chengzu Li et.al.|[2406.02537v1](http://arxiv.org/abs/2406.02537v1)|null|
|**2024-06-04**|**Mitigate Position Bias in Large Language Models via Scaling a Single Dimension**|Yijiong Yu et.al.|[2406.02536v1](http://arxiv.org/abs/2406.02536v1)|null|
|**2024-06-04**|**Enhancing predictive imaging biomarker discovery through treatment effect analysis**|Shuhan Xiao et.al.|[2406.02534v1](http://arxiv.org/abs/2406.02534v1)|null|
|**2024-06-04**|**SpecExec: Massively Parallel Speculative Decoding for Interactive LLM Inference on Consumer Devices**|Ruslan Svirschevski et.al.|[2406.02532v1](http://arxiv.org/abs/2406.02532v1)|null|
|**2024-06-04**|**Scalable MatMul-free Language Modeling**|Rui-Jie Zhu et.al.|[2406.02528v1](http://arxiv.org/abs/2406.02528v1)|[link](https://github.com/ridgerchu/matmulfreellm)|
|**2024-06-04**|**CheckEmbed: Effective Verification of LLM Solutions to Open-Ended Tasks**|Maciej Besta et.al.|[2406.02524v1](http://arxiv.org/abs/2406.02524v1)|null|
|**2024-06-04**|**RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots**|Soroush Nasiriany et.al.|[2406.02523v1](http://arxiv.org/abs/2406.02523v1)|null|
|**2024-06-04**|**Deterministic Reversible Data Augmentation for Neural Machine Translation**|Jiashu Yao et.al.|[2406.02517v1](http://arxiv.org/abs/2406.02517v1)|[link](https://github.com/BITHLP/DRDA)|
|**2024-06-04**|**V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation**|Cong Wang et.al.|[2406.02511v1](http://arxiv.org/abs/2406.02511v1)|null|
|**2024-06-04**|**Guiding a Diffusion Model with a Bad Version of Itself**|Tero Karras et.al.|[2406.02507v1](http://arxiv.org/abs/2406.02507v1)|null|
|**2024-06-04**|**Demystifying the Compression of Mixture-of-Experts Through a Unified Framework**|Shwai He et.al.|[2406.02500v1](http://arxiv.org/abs/2406.02500v1)|null|
|**2024-06-04**|**Dropout MPC: An Ensemble Neural MPC Approach for Systems with Learned Dynamics**|Spyridon Syntakas et.al.|[2406.02497v1](http://arxiv.org/abs/2406.02497v1)|null|
|**2024-06-04**|**Kolmogorov-Arnold Networks for Time Series: Bridging Predictive Power and Interpretability**|Kunpeng Xu et.al.|[2406.02496v1](http://arxiv.org/abs/2406.02496v1)|null|
|**2024-06-04**|**Language-Universal Speech Attributes Modeling for Zero-Shot Multilingual Spoken Keyword Recognition**|Hao Yen et.al.|[2406.02488v1](http://arxiv.org/abs/2406.02488v1)|null|
|**2024-06-04**|**How Do Neural Spoofing Countermeasures Detect Partially Spoofed Audio?**|Tianchi Liu et.al.|[2406.02483v1](http://arxiv.org/abs/2406.02483v1)|null|
|**2024-06-04**|**Hiding Text in Large Language Models: Introducing Unconditional Token Forcing Confusion**|Jakub Hoscilowicz et.al.|[2406.02481v1](http://arxiv.org/abs/2406.02481v1)|[link](https://github.com/j-hoscilowic/zurek-stegano)|
|**2024-06-04**|**Analyzing Temporal Complex Events with Large Language Models? A Benchmark towards Temporal, Long Context Understanding**|Zhihan Zhang et.al.|[2406.02472v1](http://arxiv.org/abs/2406.02472v1)|null|
|**2024-06-04**|**Landscape-Aware Growing: The Power of a Little LAG**|Stefani Karp et.al.|[2406.02469v1](http://arxiv.org/abs/2406.02469v1)|null|
|**2024-06-04**|**An Empirical Study into Clustering of Unseen Datasets with Self-Supervised Encoders**|Scott C. Lowe et.al.|[2406.02465v1](http://arxiv.org/abs/2406.02465v1)|[link](https://github.com/scottclowe/zs-ssl-clustering)|
|**2024-06-04**|**Meta-Learners for Partially-Identified Treatment Effects Across Multiple Environments**|Jonas Schweisthal et.al.|[2406.02464v1](http://arxiv.org/abs/2406.02464v1)|[link](https://github.com/jschweisthal/boundmetalearners)|
|**2024-06-04**|**Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems**|Jason Hu et.al.|[2406.02462v1](http://arxiv.org/abs/2406.02462v1)|null|
|**2024-06-04**|**A Generalized Apprenticeship Learning Framework for Modeling Heterogeneous Student Pedagogical Strategies**|Md Mirajul Islam et.al.|[2406.02450v1](http://arxiv.org/abs/2406.02450v1)|null|
|**2024-06-04**|**Representations as Language: An Information-Theoretic Framework for Interpretability**|Henry Conklin et.al.|[2406.02449v1](http://arxiv.org/abs/2406.02449v1)|null|
|**2024-06-04**|**Explainable Deep Learning Analysis for Raga Identification in Indian Art Music**|Parampreet Singh et.al.|[2406.02443v1](http://arxiv.org/abs/2406.02443v1)|[link](https://github.com/parampreetsingh97/pim_v1_exai)|
|**2024-06-04**|**The Scandinavian Embedding Benchmarks: Comprehensive Assessment of Multilingual and Monolingual Text Embedding**|Kenneth Enevoldsen et.al.|[2406.02396v1](http://arxiv.org/abs/2406.02396v1)|[link](https://github.com/kennethenevoldsen/scandinavian-embedding-benchmark)|
|**2024-06-04**|**Multiple Choice Questions and Large Languages Models: A Case Study with Fictional Medical Data**|Maxime Griot et.al.|[2406.02394v1](http://arxiv.org/abs/2406.02394v1)|[link](https://github.com/maximegmd/glianorex-gen)|
|**2024-06-04**|**Learning to Edit Visual Programs with Self-Supervision**|R. Kenny Jones et.al.|[2406.02383v1](http://arxiv.org/abs/2406.02383v1)|null|
|**2024-06-04**|**Kirigami: large convolutional kernels improve deep learning-based RNA secondary structure prediction**|Marc Harary et.al.|[2406.02381v1](http://arxiv.org/abs/2406.02381v1)|[link](https://github.com/marc-harary/kirigami)|
|**2024-06-04**|**On the Intrinsic Self-Correction Capability of LLMs: Uncertainty and Latent Concept**|Guangliang Liu et.al.|[2406.02378v1](http://arxiv.org/abs/2406.02378v1)|null|
|**2024-06-04**|**XRec: Large Language Models for Explainable Recommendation**|Qiyao Ma et.al.|[2406.02377v1](http://arxiv.org/abs/2406.02377v1)|[link](https://github.com/hkuds/xrec)|
|**2024-06-04**|**Retaining Key Information under High Compression Ratios: Query-Guided Compressor for LLMs**|Zhiwei Cao et.al.|[2406.02376v1](http://arxiv.org/abs/2406.02376v1)|[link](https://github.com/DeepLearnXMU/QGC)|
|**2024-06-04**|**Large Language Models Make Sample-Efficient Recommender Systems**|Jianghao Lin et.al.|[2406.02368v1](http://arxiv.org/abs/2406.02368v1)|null|
|**2024-06-04**|**Finding NeMo: Localizing Neurons Responsible For Memorization in Diffusion Models**|Dominik Hintersdorf et.al.|[2406.02366v1](http://arxiv.org/abs/2406.02366v1)|[link](https://github.com/ml-research/localizing_memorization_in_diffusion_models)|
|**2024-06-04**|**Temporal Graph Rewiring with Expander Graphs**|Katarina Petrović et.al.|[2406.02362v2](http://arxiv.org/abs/2406.02362v2)|[link](https://github.com/kpetrovicc/tgr)|
|**2024-06-04**|**Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy Arithmetic Tasks**|Andrew Gambardella et.al.|[2406.02356v1](http://arxiv.org/abs/2406.02356v1)|null|
|**2024-06-04**|**FedDr+: Stabilizing Dot-regression with Global Feature Distillation for Federated Learning**|Seongyoon Kim et.al.|[2406.02355v1](http://arxiv.org/abs/2406.02355v1)|null|
|**2024-06-04**|**LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing**|Maojun Sun et.al.|[2406.02350v1](http://arxiv.org/abs/2406.02350v1)|[link](https://github.com/stephen-smj/llamacare)|
|**2024-06-04**|**CADE: Cosine Annealing Differential Evolution for Spiking Neural Network**|Runhua Jiang et.al.|[2406.02349v1](http://arxiv.org/abs/2406.02349v1)|[link](https://github.com/tank-jiang/cade4snn)|
|**2024-06-04**|**Flash Diffusion: Accelerating Any Conditional Diffusion Model for Few Steps Image Generation**|Clement Chadebec et.al.|[2406.02347v1](http://arxiv.org/abs/2406.02347v1)|[link](https://github.com/gojasper/flash-diffusion)|
|**2024-06-04**|**Linguistic Fingerprint in Transformer Models: How Language Variation Influences Parameter Selection in Irony Detection**|Michele Mastromattei et.al.|[2406.02338v1](http://arxiv.org/abs/2406.02338v1)|null|
|**2024-06-04**|**Probing the Category of Verbal Aspect in Transformer Language Models**|Anisia Katinskaia et.al.|[2406.02335v1](http://arxiv.org/abs/2406.02335v1)|null|
|**2024-06-04**|**Towards Neural Architecture Search for Transfer Learning in 6G Networks**|Adam Orucu et.al.|[2406.02333v1](http://arxiv.org/abs/2406.02333v1)|null|
|**2024-06-04**|**Extended Mind Transformers**|Phoebe Klett et.al.|[2406.02332v1](http://arxiv.org/abs/2406.02332v1)|null|
|**2024-06-04**|**Translation Deserves Better: Analyzing Translation Artifacts in Cross-lingual Visual Question Answering**|ChaeHun Park et.al.|[2406.02331v1](http://arxiv.org/abs/2406.02331v1)|null|
|**2024-06-04**|**On Affine Homotopy between Language Encoders**|Robin SM Chan et.al.|[2406.02329v1](http://arxiv.org/abs/2406.02329v1)|null|
|**2024-06-04**|**Technical Language Processing for Telecommunications Specifications**|Felipe A. Rodriguez Y. et.al.|[2406.02325v1](http://arxiv.org/abs/2406.02325v1)|null|
|**2024-06-04**|**A Survey of Transformer Enabled Time Series Synthesis**|Alexander Sommers et.al.|[2406.02322v1](http://arxiv.org/abs/2406.02322v1)|null|
|**2024-06-04**|**Generative Conditional Distributions by Neural (Entropic) Optimal Transport**|Bao Nguyen et.al.|[2406.02317v1](http://arxiv.org/abs/2406.02317v1)|[link](https://github.com/nguyenngocbaocmt02/gentle)|
|**2024-06-04**|**An Independence-promoting Loss for Music Generation with Language Models**|Jean-Marie Lemercier et.al.|[2406.02315v1](http://arxiv.org/abs/2406.02315v1)|null|
|**2024-06-04**|**mCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models**|Huiyuan Lai et.al.|[2406.02301v1](http://arxiv.org/abs/2406.02301v1)|[link](https://github.com/laihuiyuan/mcot)|
|**2024-06-04**|**Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation**|Nathaniel Berger et.al.|[2406.02267v1](http://arxiv.org/abs/2406.02267v1)|null|
|**2024-06-04**|**Enhancing Retrieval-Augmented LMs with a Two-stage Consistency Learning Compressor**|Chuankai Xu et.al.|[2406.02266v1](http://arxiv.org/abs/2406.02266v1)|null|
|**2024-06-04**|**Understanding Retrieval Robustness for Retrieval-Augmented Image Captioning**|Wenyan Li et.al.|[2406.02265v1](http://arxiv.org/abs/2406.02265v1)|[link](https://github.com/lyan62/RobustCap)|
|**2024-06-04**|**PuFace: Defending against Facial Cloaking Attacks for Facial Recognition Models**|Jing Wen et.al.|[2406.02253v1](http://arxiv.org/abs/2406.02253v1)|null|
|**2024-06-04**|**Modeling Emotional Trajectories in Written Stories Utilizing Transformers and Weakly-Supervised Learning**|Lukas Christ et.al.|[2406.02251v1](http://arxiv.org/abs/2406.02251v1)|[link](https://github.com/lc0197/emotional_trajectories_stories)|
|**2024-06-04**|**Description Boosting for Zero-Shot Entity and Relation Classification**|Gabriele Picco et.al.|[2406.02245v1](http://arxiv.org/abs/2406.02245v1)|[link](https://github.com/ibm/zshot)|
|**2024-06-04**|**Self-Modifying State Modeling for Simultaneous Machine Translation**|Donglei Yu et.al.|[2406.02237v1](http://arxiv.org/abs/2406.02237v1)|[link](https://github.com/EurekaForNLP/SM2)|
|**2024-06-04**|**On the Limitations of Fractal Dimension as a Measure of Generalization**|Charlie Tan et.al.|[2406.02234v1](http://arxiv.org/abs/2406.02234v1)|null|
|**2024-06-04**|**FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models**|Tao Fan et.al.|[2406.02224v1](http://arxiv.org/abs/2406.02224v1)|null|
|**2024-06-04**|**Why Only Text: Empowering Vision-and-Language Navigation with Multi-modal Prompts**|Haodong Hong et.al.|[2406.02208v1](http://arxiv.org/abs/2406.02208v1)|[link](https://github.com/honghd16/vln-mp)|
|**2024-06-04**|**The Deep Latent Space Particle Filter for Real-Time Data Assimilation with Uncertainty Quantification**|Nikolaj T. Mücke et.al.|[2406.02204v1](http://arxiv.org/abs/2406.02204v1)|[link](https://github.com/nmucke/data-assimilation)|
|**2024-06-04**|**Can CLIP help CLIP in learning 3D?**|Cristian Sbrolli et.al.|[2406.02202v1](http://arxiv.org/abs/2406.02202v1)|null|
|**2024-06-04**|**On The Statistical Representation Properties Of The Perturb-Softmax And The Perturb-Argmax Probability Distributions**|Hedda Cohen Indelman et.al.|[2406.02180v1](http://arxiv.org/abs/2406.02180v1)|null|
|**2024-06-04**|**Audio Mamba: Selective State Spaces for Self-Supervised Audio Representations**|Sarthak Yadav et.al.|[2406.02178v1](http://arxiv.org/abs/2406.02178v1)|null|
|**2024-06-04**|**One-Shot Federated Learning with Bayesian Pseudocoresets**|Tim d'Hondt et.al.|[2406.02177v1](http://arxiv.org/abs/2406.02177v1)|null|
|**2024-06-04**|**A multilingual dataset for offensive language and hate speech detection for hausa, yoruba and igbo languages**|Saminu Mohammad Aliyu et.al.|[2406.02169v1](http://arxiv.org/abs/2406.02169v1)|null|
|**2024-06-04**|**Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision**|Saierdaer Yusuyin et.al.|[2406.02166v1](http://arxiv.org/abs/2406.02166v1)|[link](https://github.com/thu-spmi/cat)|
|**2024-06-04**|**Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models**|Qingkai Min et.al.|[2406.02148v1](http://arxiv.org/abs/2406.02148v1)|[link](https://github.com/taolusi/secure)|
|**2024-06-04**|**Reinforcement Tuning for Detecting Stances and Debunking Rumors Jointly with Large Language Models**|Ruichao Yang et.al.|[2406.02143v1](http://arxiv.org/abs/2406.02143v1)|null|
|**2024-06-04**|**Robust Interaction-based Relevance Modeling for Online E-Commerce and LLM-based Retrieval**|Ben Chen et.al.|[2406.02135v1](http://arxiv.org/abs/2406.02135v1)|null|
|**2024-06-04**|**The current status of large language models in summarizing radiology report impressions**|Danqing Hu et.al.|[2406.02134v1](http://arxiv.org/abs/2406.02134v1)|null|
|**2024-06-04**|**SimulTron: On-Device Simultaneous Speech to Speech Translation**|Alex Agranovich et.al.|[2406.02133v1](http://arxiv.org/abs/2406.02133v1)|null|
|**2024-06-04**|**CondTSF: One-line Plugin of Dataset Condensation for Time Series Forecasting**|Jianrong Ding et.al.|[2406.02131v2](http://arxiv.org/abs/2406.02131v2)|null|
|**2024-06-04**|**Iteration Head: A Mechanistic Study of Chain-of-Thought**|Vivien Cabannes et.al.|[2406.02128v1](http://arxiv.org/abs/2406.02128v1)|null|
|**2024-06-04**|**CityLight: A Universal Model Towards Real-world City-scale Traffic Signal Control Coordination**|Jinwei Zeng et.al.|[2406.02126v1](http://arxiv.org/abs/2406.02126v1)|null|
|**2024-06-04**|**Diver: Large Language Model Decoding with Span-Level Mutual Information Verification**|Jinliang Lu et.al.|[2406.02120v1](http://arxiv.org/abs/2406.02120v1)|null|
|**2024-06-04**|**UniOQA: A Unified Framework for Knowledge Graph Question Answering with Large Language Models**|Zhuoyang Li et.al.|[2406.02110v1](http://arxiv.org/abs/2406.02110v1)|null|
|**2024-06-04**|**MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset**|Weiqi Wang et.al.|[2406.02106v1](http://arxiv.org/abs/2406.02106v1)|[link](https://github.com/hkust-knowcomp/mars)|
|**2024-06-04**|**Kernel vs. Kernel: Exploring How the Data Structure Affects Neural Collapse**|Vignesh Kothapalli et.al.|[2406.02105v1](http://arxiv.org/abs/2406.02105v1)|[link](https://github.com/kvignesh1420/shallow_nc1)|
|**2024-06-04**|**Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data**|Haolong Li et.al.|[2406.02100v1](http://arxiv.org/abs/2406.02100v1)|null|
|**2024-06-04**|**MaskSR: Masked Language Model for Full-band Speech Restoration**|Xu Li et.al.|[2406.02092v1](http://arxiv.org/abs/2406.02092v1)|null|
|**2024-06-04**|**LongSSM: On the Length Extension of State-space Models in Language Modelling**|Shida Wang et.al.|[2406.02080v1](http://arxiv.org/abs/2406.02080v1)|null|
|**2024-06-04**|**Assessing the Performance of Chinese Open Source Large Language Models in Information Extraction Tasks**|Yida Cai et.al.|[2406.02079v1](http://arxiv.org/abs/2406.02079v1)|null|
|**2024-06-04**|**A Toolbox for Supporting Research on AI in Water Distribution Networks**|André Artelt et.al.|[2406.02078v1](http://arxiv.org/abs/2406.02078v1)|null|
|**2024-06-04**|**PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling**|Zefan Cai. et.al.|[2406.02069v1](http://arxiv.org/abs/2406.02069v1)|null|
|**2024-06-04**|**Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models**|Marianna Nezhurina et.al.|[2406.02061v1](http://arxiv.org/abs/2406.02061v1)|[link](https://github.com/laion-ai/aiw)|
|**2024-06-04**|**I've got the "Answer"! Interpretation of LLMs Hidden States in Question Answering**|Valeriya Goloviznina et.al.|[2406.02060v1](http://arxiv.org/abs/2406.02060v1)|null|
|**2024-06-04**|**Tabular and Deep Learning for the Whittle Index**|Francisco Robledo Relaño et.al.|[2406.02057v1](http://arxiv.org/abs/2406.02057v1)|null|
|**2024-06-04**|**Analyzing Social Biases in Japanese Large Language Models**|Hitomi Yanaka et.al.|[2406.02050v2](http://arxiv.org/abs/2406.02050v2)|[link](https://github.com/ynklab/JBBQ_data)|
|**2024-06-04**|**QROA: A Black-Box Query-Response Optimization Attack on LLMs**|Hussein Jawad et.al.|[2406.02044v1](http://arxiv.org/abs/2406.02044v1)|[link](https://github.com/qroa/qroa)|
|**2024-06-04**|**DFA-GNN: Forward Learning of Graph Neural Networks by Direct Feedback Alignment**|Gongpei Zhao et.al.|[2406.02040v1](http://arxiv.org/abs/2406.02040v1)|null|
|**2024-06-04**|**A Unifying Framework for Action-Conditional Self-Predictive Reinforcement Learning**|Khimya Khetarpal et.al.|[2406.02035v1](http://arxiv.org/abs/2406.02035v1)|null|
|**2024-06-04**|**Multimodal Reasoning with Multimodal Knowledge Graph**|Junlin Lee et.al.|[2406.02030v2](http://arxiv.org/abs/2406.02030v2)|null|
|**2024-06-04**|**Inference Attacks in Machine Learning as a Service: A Taxonomy, Review, and Promising Directions**|Feng Wu et.al.|[2406.02027v1](http://arxiv.org/abs/2406.02027v1)|null|
|**2024-06-04**|**MetaMixer Is All You Need**|Seokju Yun et.al.|[2406.02021v1](http://arxiv.org/abs/2406.02021v1)|[link](https://github.com/ysj9909/ffnet)|
|**2024-06-04**|**Why Would You Suggest That? Human Trust in Language Model Responses**|Manasi Sharma et.al.|[2406.02018v1](http://arxiv.org/abs/2406.02018v1)|null|
|**2024-06-04**|**Phonetic Enhanced Language Modeling for Text-to-Speech Synthesis**|Kun Zhou et.al.|[2406.02009v1](http://arxiv.org/abs/2406.02009v1)|null|
|**2024-06-04**|**ODE-based Learning to Optimize**|Zhonglin Xie et.al.|[2406.02006v1](http://arxiv.org/abs/2406.02006v1)|[link](https://github.com/optsuite/o2o)|

#### Abstracts
##### **To Believe or Not to Believe Your LLM**
2406.02543v1 by Yasin Abbasi Yadkori, Ilja Kuzborskij, András György, Csaba Szepesvári

We explore uncertainty quantification in large language models (LLMs), with
the goal to identify when uncertainty in responses given a query is large. We
simultaneously consider both epistemic and aleatoric uncertainties, where the
former comes from the lack of knowledge about the ground truth (such as about
facts or the language), and the latter comes from irreducible randomness (such
as multiple possible answers). In particular, we derive an
information-theoretic metric that allows to reliably detect when only epistemic
uncertainty is large, in which case the output of the model is unreliable. This
condition can be computed based solely on the output of the model obtained
simply by some special iterative prompting based on the previous responses.
Such quantification, for instance, allows to detect hallucinations (cases when
epistemic uncertainty is high) in both single- and multi-answer responses. This
is in contrast to many standard uncertainty quantification strategies (such as
thresholding the log-likelihood of a response) where hallucinations in the
multi-answer case cannot be detected. We conduct a series of experiments which
demonstrate the advantage of our formulation. Further, our investigations shed
some light on how the probabilities assigned to a given output by an LLM can be
amplified by iterative prompting, which might be of independent interest.

摘要：我們探討大型語言模型 (LLM) 中的不確定性量化，目標是找出在給定查詢時，回應中的不確定性很大的情況。我們同時考慮認識論和隨機不確定性，前者來自對基本事實（例如關於事實或語言）的知識缺乏，後者來自不可約的隨機性（例如多個可能的答案）。特別是，我們推導出一個資訊理論指標，可以可靠地檢測到只有認識論不確定性很大的情況，在這種情況下，模型的輸出是不可靠的。這個條件可以僅根據模型的輸出計算，而該輸出僅透過基於先前回應的一些特殊反覆提示獲得。例如，這種量化允許在單一和多重答案回應中檢測到幻覺（認識論不確定性很高的情況）。這與許多標準不確定性量化策略（例如對應答的對數似然性設定閾值）形成對比，在多重答案情況下無法檢測到幻覺。我們進行了一系列實驗，證明了我們公式的優點。此外，我們的調查揭示了一些見解，說明 LLM 分配給特定輸出的機率如何透過反覆提示而放大，這可能具有獨立的興趣。

##### **Parrot: Multilingual Visual Instruction Tuning**
2406.02539v1 by Hai-Long Sun, Da-Wei Zhou, Yang Li, Shiyin Lu, Chao Yi, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang, De-Chuan Zhan, Han-Jia Ye

The rapid development of Multimodal Large Language Models (MLLMs) like GPT-4V
has marked a significant step towards artificial general intelligence. Existing
methods mainly focus on aligning vision encoders with LLMs through supervised
fine-tuning (SFT) to endow LLMs with multimodal abilities, making MLLMs'
inherent ability to react to multiple languages progressively deteriorate as
the training process evolves. We empirically find that the imbalanced SFT
datasets, primarily composed of English-centric image-text pairs, lead to
significantly reduced performance in non-English languages. This is due to the
failure of aligning the vision encoder and LLM with multilingual tokens during
the SFT process. In this paper, we introduce Parrot, a novel method that
utilizes textual guidance to drive visual token alignment at the language
level. Parrot makes the visual tokens condition on diverse language inputs and
uses Mixture-of-Experts (MoE) to promote the alignment of multilingual tokens.
Specifically, to enhance non-English visual tokens alignment, we compute the
cross-attention using the initial visual features and textual embeddings, the
result of which is then fed into the MoE router to select the most relevant
experts. The selected experts subsequently convert the initial visual tokens
into language-specific visual tokens. Moreover, considering the current lack of
benchmarks for evaluating multilingual capabilities within the field, we
collect and make available a Massive Multilingual Multimodal Benchmark which
includes 6 languages, 15 categories, and 12,000 questions, named as MMMB. Our
method not only demonstrates state-of-the-art performance on multilingual
MMBench and MMMB, but also excels across a broad range of multimodal tasks.
Both the source code and the training dataset of Parrot will be made publicly
available.

摘要：多模态大型语言模型（MLLM）的快速发展，例如 GPT-4V，已标志着朝着人工智能迈出了重要一步。现有的方法主要集中于通过监督微调（SFT）将视觉编码器与 LLM 对齐，以赋予 LLM 多模态能力，使 MLLM 随着训练过程的发展而逐渐丧失对多种语言做出反应的固有能力。我们凭经验发现，不平衡的 SFT 数据集（主要由以英语为中心的图像文本对组成）导致非英语语言的性能显着下降。这是由于在 SFT 过程中视觉编码器和 LLM 与多语言标记对齐失败。在本文中，我们介绍了 Parrot，这是一种新方法，它利用文本指导在语言级别驱动视觉标记对齐。Parrot 使视觉标记依赖于不同的语言输入，并使用专家混合（MoE）来促进多语言标记的对齐。具体来说，为了增强非英语视觉标记对齐，我们使用初始视觉特征和文本嵌入计算交叉注意力，然后将其结果输入 MoE 路由器以选择最相关的专家。选定的专家随后将初始视觉标记转换为特定语言的视觉标记。此外，考虑到当前缺乏用于评估该领域内多语言能力的基准，我们收集并提供了包含 6 种语言、15 个类别和 12,000 个问题的大规模多语言多模态基准，称为 MMMB。我们的方法不仅在多语言 MMBench 和 MMMB 上展示了最先进的性能，而且在广泛的多模态任务中也表现出色。Parrot 的源代码和训练数据集都将公开。

##### **TopViewRS: Vision-Language Models as Top-View Spatial Reasoners**
2406.02537v1 by Chengzu Li, Caiqi Zhang, Han Zhou, Nigel Collier, Anna Korhonen, Ivan Vulić

Top-view perspective denotes a typical way in which humans read and reason
over different types of maps, and it is vital for localization and navigation
of humans as well as of `non-human' agents, such as the ones backed by large
Vision-Language Models (VLMs). Nonetheless, spatial reasoning capabilities of
modern VLMs remain unattested and underexplored. In this work, we thus study
their capability to understand and reason over spatial relations from the top
view. The focus on top view also enables controlled evaluations at different
granularity of spatial reasoning; we clearly disentangle different abilities
(e.g., recognizing particular objects versus understanding their relative
positions). We introduce the TopViewRS (Top-View Reasoning in Space) dataset,
consisting of 11,384 multiple-choice questions with either realistic or
semantic top-view map as visual input. We then use it to study and evaluate
VLMs across 4 perception and reasoning tasks with different levels of
complexity. Evaluation of 10 representative open- and closed-source VLMs
reveals the gap of more than 50% compared to average human performance, and it
is even lower than the random baseline in some cases. Although additional
experiments show that Chain-of-Thought reasoning can boost model capabilities
by 5.82% on average, the overall performance of VLMs remains limited. Our
findings underscore the critical need for enhanced model capability in top-view
spatial reasoning and set a foundation for further research towards human-level
proficiency of VLMs in real-world multimodal tasks.

摘要：<paragraph>自上而下的視角表示人類閱讀和理解不同類型地圖的典型方式，對於人類以及由大型視覺語言模型 (VLM) 支援的「非人類」代理人的定位和導航至關重要。儘管如此，現代 VLM 的空間推理能力仍然未經證實且未被充分探討。因此，我們在這項工作中研究了它們從自上而下視角理解和推論空間關係的能力。專注於自上而下的視角也能在不同的空間推理粒度下進行受控評估；我們清楚地區分了不同的能力（例如，辨識特定物件與理解它們的相對位置）。我們引入了 TopViewRS（空間中的自上而下推理）資料集，其中包含 11,384 個多選題，並以逼真的或語義自上而下地圖作為視覺輸入。然後，我們使用它來研究和評估 VLM 在 4 個不同複雜程度的感知和推理任務中的表現。對 10 個具有代表性的開源和閉源 VLM 的評估顯示，與人類的平均表現相比，差距超過 50%，在某些情況下甚至低於隨機基準。儘管額外的實驗表明，思考鏈推理可以將模型能力平均提高 5.82%，但 VLM 的整體表現仍然有限。我們的研究結果強調了增強自上而下空間推理模型能力的關鍵需求，並為 VLM 在現實世界多模態任務中達到人類水準的熟練度奠定了進一步研究的基礎。</paragraph>

##### **Mitigate Position Bias in Large Language Models via Scaling a Single Dimension**
2406.02536v1 by Yijiong Yu, Huiqiang Jiang, Xufang Luo, Qianhui Wu, Chin-Yew Lin, Dongsheng Li, Yuqing Yang, Yongfeng Huang, Lili Qiu

Large Language Models (LLMs) are increasingly applied in various real-world
scenarios due to their excellent generalization capabilities and robust
generative abilities. However, they exhibit position bias, also known as "lost
in the middle", a phenomenon that is especially pronounced in long-context
scenarios, which indicates the placement of the key information in different
positions of a prompt can significantly affect accuracy. This paper first
explores the micro-level manifestations of position bias, concluding that
attention weights are a micro-level expression of position bias. It further
identifies that, in addition to position embeddings, causal attention mask also
contributes to position bias by creating position-specific hidden states. Based
on these insights, we propose a method to mitigate position bias by scaling
this positional hidden states. Experiments on the NaturalQuestions
Multi-document QA, KV retrieval, LongBench and timeline reorder tasks, using
various models including RoPE models, context windowextended models, and Alibi
models, demonstrate the effectiveness and generalizability of our approach. Our
method can improve performance by up to 15.2% by modifying just one dimension
of hidden states. Our code is available at https://aka.ms/PositionalHidden.

摘要：大型語言模型（LLM）由於其出色的概括能力和強大的生成能力，在各種現實世界場景中得到越來越廣泛的應用。然而，它們表現出位置偏差，也稱為「迷失在中間」，這是一種在長語境場景中特別明顯的現象，表明關鍵資訊在提示中的不同位置的放置會顯著影響準確性。本文首先探討位置偏差的微觀表現，結論是注意力權重是位置偏差的微觀表現。它進一步發現，除了位置嵌入之外，因果注意力遮罩也會通過建立特定位置的隱藏狀態來導致位置偏差。基於這些見解，我們提出了一種通過縮放這種位置隱藏狀態來減輕位置偏差的方法。在 NaturalQuestions 多文件問答、KV 檢索、LongBench 和時間線重新排序任務上使用各種模型（包括 RoPE 模型、上下文窗口擴展模型和 Alibi 模型）進行的實驗證明了我們方法的有效性和普遍性。我們的辦法只需修改隱藏狀態的一個維度，就能將效能提高多達 15.2%。我們的程式碼可在 https://aka.ms/PositionalHidden 取得。

##### **Enhancing predictive imaging biomarker discovery through treatment effect analysis**
2406.02534v1 by Shuhan Xiao, Lukas Klein, Jens Petersen, Philipp Vollmuth, Paul F. Jaeger, Klaus H. Maier-Hein

Identifying predictive biomarkers, which forecast individual treatment
effectiveness, is crucial for personalized medicine and informs decision-making
across diverse disciplines. These biomarkers are extracted from pre-treatment
data, often within randomized controlled trials, and have to be distinguished
from prognostic biomarkers, which are independent of treatment assignment. Our
study focuses on the discovery of predictive imaging biomarkers, aiming to
leverage pre-treatment images to unveil new causal relationships. Previous
approaches relied on labor-intensive handcrafted or manually derived features,
which may introduce biases. In response, we present a new task of discovering
predictive imaging biomarkers directly from the pre-treatment images to learn
relevant image features. We propose an evaluation protocol for this task to
assess a model's ability to identify predictive imaging biomarkers and
differentiate them from prognostic ones. It employs statistical testing and a
comprehensive analysis of image feature attribution. We explore the suitability
of deep learning models originally designed for estimating the conditional
average treatment effect (CATE) for this task, which previously have been
primarily assessed for the precision of CATE estimation, overlooking the
evaluation of imaging biomarker discovery. Our proof-of-concept analysis
demonstrates promising results in discovering and validating predictive imaging
biomarkers from synthetic outcomes and real-world image datasets.

摘要：識別預測性生物標記，預測個別治療的有效性，對於個人化醫療至關重要，並在不同領域中提供決策依據。這些生物標記從治療前資料中萃取，通常在隨機對照試驗中，且必須與與治療分配無關的預後性生物標記區分。我們的研究專注於發現預測性影像生物標記，旨在利用治療前影像揭示新的因果關係。先前的做法依賴於人工製作或手動衍生的勞力密集型特徵，這可能會引入偏差。為了解決此問題，我們提出了一項新任務，直接從治療前影像中發現預測性影像生物標記，以學習相關影像特徵。我們為此任務提出了一個評估協定，以評估模型識別預測性影像生物標記並將其與預後性生物標記區分開來的能力。它採用統計檢驗和影像特徵歸因的全面分析。我們探討了原本設計用於估計條件平均治療效果 (CATE) 的深度學習模型是否適用於此任務，該模型先前主要針對 CATE 估計的精確度進行評估，而忽略了影像生物標記發現的評估。我們的概念驗證分析證明了從合成結果和真實影像資料集中發現和驗證預測性影像生物標記的良好結果。

##### **SpecExec: Massively Parallel Speculative Decoding for Interactive LLM Inference on Consumer Devices**
2406.02532v1 by Ruslan Svirschevski, Avner May, Zhuoming Chen, Beidi Chen, Zhihao Jia, Max Ryabinin

As large language models gain widespread adoption, running them efficiently
becomes crucial. Recent works on LLM inference use speculative decoding to
achieve extreme speedups. However, most of these works implicitly design their
algorithms for high-end datacenter hardware. In this work, we ask the opposite
question: how fast can we run LLMs on consumer machines? Consumer GPUs can no
longer fit the largest available models (50B+ parameters) and must offload them
to RAM or SSD. When running with offloaded parameters, the inference engine can
process batches of hundreds or thousands of tokens at the same time as just one
token, making it a natural fit for speculative decoding. We propose SpecExec
(Speculative Execution), a simple parallel decoding method that can generate up
to 20 tokens per target model iteration for popular LLM families. It utilizes
the high spikiness of the token probabilities distribution in modern LLMs and a
high degree of alignment between model output probabilities. SpecExec takes the
most probable tokens continuation from the draft model to build a "cache" tree
for the target model, which then gets validated in a single pass. Using
SpecExec, we demonstrate inference of 50B+ parameter LLMs on consumer GPUs with
RAM offloading at 4-6 tokens per second with 4-bit quantization or 2-3 tokens
per second with 16-bit weights.

摘要：隨著大型語言模型廣泛採用，有效率地執行它們變得至關重要。最近關於 LLM 推論的研究使用推測性解碼來實現極高的加速。然而，這些研究大多數隱含地為高端資料中心硬體設計演算法。在這項研究中，我們提出相反的問題：我們可以在消費型機器上執行 LLM 的速度有多快？消費者 GPU 不再能容納最大的可用模型（50B+ 參數），並且必須將它們卸載到 RAM 或 SSD。在使用卸載參數執行時，推論引擎可以同時處理數百或數千個記號的批次，就像只處理一個記號一樣，使其自然地適合於推測性解碼。我們提出 SpecExec（推測性執行），這是一種簡單的並行解碼方法，可以為熱門 LLM 家族的每個目標模型反覆運算產生多達 20 個記號。它利用現代 LLM 中記號機率分佈的高尖峰性以及模型輸出機率之間的高度對齊。SpecExec 從草稿模型中取得最可能的記號延續，為目標模型建立一個「快取」樹，然後在單次傳遞中進行驗證。使用 SpecExec，我們展示了在使用 4 位元量化時，在消費者 GPU 上以每秒 4-6 個記號的速度推論 50B+ 參數 LLM，或在使用 16 位元權重時以每秒 2-3 個記號的速度推論。

##### **Scalable MatMul-free Language Modeling**
2406.02528v1 by Rui-Jie Zhu, Yu Zhang, Ethan Sifferman, Tyler Sheaves, Yiqiao Wang, Dustin Richmond, Peng Zhou, Jason K. Eshraghian

Matrix multiplication (MatMul) typically dominates the overall computational
cost of large language models (LLMs). This cost only grows as LLMs scale to
larger embedding dimensions and context lengths. In this work, we show that
MatMul operations can be completely eliminated from LLMs while maintaining
strong performance at billion-parameter scales. Our experiments show that our
proposed MatMul-free models achieve performance on-par with state-of-the-art
Transformers that require far more memory during inference at a scale up to at
least 2.7B parameters. We investigate the scaling laws and find that the
performance gap between our MatMul-free models and full precision Transformers
narrows as the model size increases. We also provide a GPU-efficient
implementation of this model which reduces memory usage by up to 61% over an
unoptimized baseline during training. By utilizing an optimized kernel during
inference, our model's memory consumption can be reduced by more than 10x
compared to unoptimized models. To properly quantify the efficiency of our
architecture, we build a custom hardware solution on an FPGA which exploits
lightweight operations beyond what GPUs are capable of. We processed
billion-parameter scale models at 13W beyond human readable throughput, moving
LLMs closer to brain-like efficiency. This work not only shows how far LLMs can
be stripped back while still performing effectively, but also points at the
types of operations future accelerators should be optimized for in processing
the next generation of lightweight LLMs. Our code implementation is available
at \url{https://github.com/ridgerchu/matmulfreellm}.

摘要：矩陣乘法 (MatMul) 通常會主導大型語言模型 (LLM) 的整體運算成本。隨著 LLM 擴展到更大的嵌入維度和內容長度，此成本只會增加。在這項工作中，我們展示了 MatMul 運算可以從 LLM 中完全消除，同時在十億個參數規模下維持強勁的效能。我們的實驗顯示，我們提出的無 MatMul 模型在推論時達到與最先進的 Transformer 相當的效能，而後者在規模至少達到 2.7B 個參數時需要更多的記憶體。我們研究了擴展定律，發現隨著模型大小的增加，我們的無 MatMul 模型與完全精度的 Transformer 之間的效能差距縮小。我們還提供了此模型的 GPU 高效實作，在訓練期間將記憶體使用量減少了 61%，而優於未最佳化的基準。透過在推論期間使用最佳化的核心，與未最佳化的模型相比，我們的模型的記憶體消耗量可以減少 10 倍以上。為了適當地量化我們架構的效率，我們在 FPGA 上建構一個自訂硬體解決方案，利用 GPU 無法執行的輕量級運算。我們以 13W 的速度處理了十億個參數規模的模型，超越了人類可讀的處理量，讓 LLM 更接近大腦般的效率。這項工作不僅展示了 LLM 在仍能有效執行的情況下可以精簡到什麼程度，也指出未來加速器在處理下一代輕量級 LLM 時應最佳化的運算類型。我們的程式碼實作可以在 \url{https://github.com/ridgerchu/matmulfreellm} 取得。

##### **CheckEmbed: Effective Verification of LLM Solutions to Open-Ended Tasks**
2406.02524v1 by Maciej Besta, Lorenzo Paleari, Ales Kubicek, Piotr Nyczyk, Robert Gerstenberger, Patrick Iff, Tomasz Lehmann, Hubert Niewiadomski, Torsten Hoefler

Large Language Models (LLMs) are revolutionizing various domains, yet
verifying their answers remains a significant challenge, especially for
intricate open-ended tasks such as consolidation, summarization, and extraction
of knowledge. In this work, we propose CheckEmbed: an accurate, scalable, and
simple LLM verification approach. CheckEmbed is driven by a straightforward yet
powerful idea: in order to compare LLM solutions to one another or to the
ground-truth, compare their corresponding answer-level embeddings obtained with
a model such as GPT Text Embedding Large. This reduces a complex textual answer
to a single embedding, facilitating straightforward, fast, and meaningful
verification. We develop a comprehensive verification pipeline implementing the
CheckEmbed methodology. The CheckEmbed pipeline also comes with metrics for
assessing the truthfulness of the LLM answers, such as embedding heatmaps and
their summaries. We show how to use these metrics for deploying practical
engines that decide whether an LLM answer is satisfactory or not. We apply the
pipeline to real-world document analysis tasks, including term extraction and
document summarization, showcasing significant improvements in accuracy,
cost-effectiveness, and runtime performance compared to existing token-,
sentence-, and fact-level schemes such as BERTScore or SelfCheckGPT.

摘要：大型語言模型 (LLM) 正在革新各個領域，然而驗證其答案仍然是一項重大的挑戰，特別是對於複雜的開放式任務，例如整合、摘要和知識萃取。在這項工作中，我們提出 CheckEmbed：一種準確、可擴充且簡單的 LLM 驗證方法。CheckEmbed 由一個簡單但強大的概念驅動：為了將 LLM 答案彼此比較或與真實情況比較，請將它們使用 GPT 文字嵌入大型等模型獲得的對應答案層級嵌入比較。這將複雜的文字答案簡化為單一嵌入，促進直接、快速且有意義的驗證。我們開發了一個全面的驗證管道，實作 CheckEmbed 方法論。CheckEmbed 管道還附帶用於評估 LLM 答案真實性的指標，例如嵌入熱圖及其摘要。我們展示如何使用這些指標來部署實際引擎，以決定 LLM 答案是否令人滿意。我們將管道應用於真實世界的文件分析任務，包括術語萃取和文件摘要，與現有的基於詞元、句子和事實的方案（例如 BERTScore 或 SelfCheckGPT）相比，展示了在準確性、成本效益和執行時間效能方面的顯著改進。

##### **RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots**
2406.02523v1 by Soroush Nasiriany, Abhiram Maddukuri, Lance Zhang, Adeet Parikh, Aaron Lo, Abhishek Joshi, Ajay Mandlekar, Yuke Zhu

Recent advancements in Artificial Intelligence (AI) have largely been
propelled by scaling. In Robotics, scaling is hindered by the lack of access to
massive robot datasets. We advocate using realistic physical simulation as a
means to scale environments, tasks, and datasets for robot learning methods. We
present RoboCasa, a large-scale simulation framework for training generalist
robots in everyday environments. RoboCasa features realistic and diverse scenes
focusing on kitchen environments. We provide thousands of 3D assets across over
150 object categories and dozens of interactable furniture and appliances. We
enrich the realism and diversity of our simulation with generative AI tools,
such as object assets from text-to-3D models and environment textures from
text-to-image models. We design a set of 100 tasks for systematic evaluation,
including composite tasks generated by the guidance of large language models.
To facilitate learning, we provide high-quality human demonstrations and
integrate automated trajectory generation methods to substantially enlarge our
datasets with minimal human burden. Our experiments show a clear scaling trend
in using synthetically generated robot data for large-scale imitation learning
and show great promise in harnessing simulation data in real-world tasks.
Videos and open-source code are available at https://robocasa.ai/

摘要：最近在人工智能（AI）方面的進展在很大程度上是由擴展推動的。在機器人技術中，缺乏獲得大量機器人數據集的途徑阻礙了擴展。我們提倡使用逼真的物理模擬作為擴展環境、任務和數據集以供機器人學習方法的手段。我們展示了 RoboCasa，這是一個用於在日常環境中訓練通才機器人的大型模擬框架。RoboCasa 具有逼真且多樣的場景，重點關注廚房環境。我們提供了 150 多個物件類別和數十種可互動的家具和電器中的數千個 3D 資產。我們使用生成式 AI 工具（例如來自文字到 3D 模型的物件資產和來自文字到影像模型的環境紋理）豐富了模擬的真實性和多樣性。我們設計了一組 100 個任務用於系統性評估，包括由大型語言模型的指導產生的複合任務。為了促進學習，我們提供了高品質的人類示範，並整合了自動軌跡生成方法，以最少的人力負擔大幅擴展我們的數據集。我們的實驗顯示了使用合成產生的機器人數據進行大規模模仿學習的明顯擴展趨勢，並顯示了在現實世界任務中利用模擬數據的巨大前景。影片和開放原始碼可在 https://robocasa.ai/ 取得。

##### **Deterministic Reversible Data Augmentation for Neural Machine Translation**
2406.02517v1 by Jiashu Yao, Heyan Huang, Zeming Liu, Yuhang Guo

Data augmentation is an effective way to diversify corpora in machine
translation, but previous methods may introduce semantic inconsistency between
original and augmented data because of irreversible operations and random
subword sampling procedures. To generate both symbolically diverse and
semantically consistent augmentation data, we propose Deterministic Reversible
Data Augmentation (DRDA), a simple but effective data augmentation method for
neural machine translation. DRDA adopts deterministic segmentations and
reversible operations to generate multi-granularity subword representations and
pulls them closer together with multi-view techniques. With no extra corpora or
model changes required, DRDA outperforms strong baselines on several
translation tasks with a clear margin (up to 4.3 BLEU gain over Transformer)
and exhibits good robustness in noisy, low-resource, and cross-domain datasets.

摘要：資料擴充是一種有效的方法，可用於在機器翻譯中使語料庫多樣化，但先前的做法可能會因為不可逆運算和隨機子詞採樣程序，而在原始資料和擴充資料之間引入語意不一致性。為了產生符號多樣化且語意一致的擴充資料，我們提出確定性可逆資料擴充 (DRDA)，這是一種簡單但有效的資料擴充方法，適用於神經機器翻譯。DRDA 採用確定性分段和可逆運算來產生多粒度的子詞表示，並使用多視角技術將它們拉得更近。無需額外的語料庫或模型變更，DRDA 在多項翻譯任務中勝過強大的基線，並具有明顯的優勢（相較於 Transformer，BLEU 分數提升多達 4.3），且在有雜訊、低資源和跨網域資料集方面展現出良好的穩健性。

##### **V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation**
2406.02511v1 by Cong Wang, Kuan Tian, Jun Zhang, Yonghang Guan, Feng Luo, Fei Shen, Zhiwei Jiang, Qing Gu, Xiao Han, Wei Yang

In the field of portrait video generation, the use of single images to
generate portrait videos has become increasingly prevalent. A common approach
involves leveraging generative models to enhance adapters for controlled
generation. However, control signals (e.g., text, audio, reference image, pose,
depth map, etc.) can vary in strength. Among these, weaker conditions often
struggle to be effective due to interference from stronger conditions, posing a
challenge in balancing these conditions. In our work on portrait video
generation, we identified audio signals as particularly weak, often
overshadowed by stronger signals such as facial pose and reference image.
However, direct training with weak signals often leads to difficulties in
convergence. To address this, we propose V-Express, a simple method that
balances different control signals through the progressive training and the
conditional dropout operation. Our method gradually enables effective control
by weak conditions, thereby achieving generation capabilities that
simultaneously take into account the facial pose, reference image, and audio.
The experimental results demonstrate that our method can effectively generate
portrait videos controlled by audio. Furthermore, a potential solution is
provided for the simultaneous and effective use of conditions of varying
strengths.

摘要：<paragraph>在人像影片生成领域中，使用单一影像来生成人像影片变得越来越普遍。一种常见的方法是利用生成模型来增强用于受控生成的适配器。然而，控制讯号（例如文字、音讯、参考影像、姿势、深度图等）的强度可能有所不同。在这些讯号当中，较弱的讯号往往难以发挥作用，因为会受到较强讯号的干扰，在平衡这些讯号时构成了一项挑战。在我们的人像影片生成工作中，我们发现音讯讯号特别弱，经常会被较强的讯号（例如脸部姿势和参考影像）所掩盖。然而，直接使用弱讯号进行训练通常会导致收敛困难。为了解决这个问题，我们提出了 V-Express，这是一种透过渐进式训练和条件式 Dropout 操作来平衡不同控制讯号的简单方法。我们的方法逐渐让弱讯号能够有效地进行控制，进而实现同时考量脸部姿势、参考影像和音讯的生成能力。实验结果显示，我们的方法能够有效地生成受音讯控制的人像影片。此外，我们提供了一种可能的解决方案，用于同时有效地使用强度不同的讯号。</paragraph>

##### **Guiding a Diffusion Model with a Bad Version of Itself**
2406.02507v1 by Tero Karras, Miika Aittala, Tuomas Kynkäänniemi, Jaakko Lehtinen, Timo Aila, Samuli Laine

The primary axes of interest in image-generating diffusion models are image
quality, the amount of variation in the results, and how well the results align
with a given condition, e.g., a class label or a text prompt. The popular
classifier-free guidance approach uses an unconditional model to guide a
conditional model, leading to simultaneously better prompt alignment and
higher-quality images at the cost of reduced variation. These effects seem
inherently entangled, and thus hard to control. We make the surprising
observation that it is possible to obtain disentangled control over image
quality without compromising the amount of variation by guiding generation
using a smaller, less-trained version of the model itself rather than an
unconditional model. This leads to significant improvements in ImageNet
generation, setting record FIDs of 1.01 for 64x64 and 1.25 for 512x512, using
publicly available networks. Furthermore, the method is also applicable to
unconditional diffusion models, drastically improving their quality.

摘要：生成擴散模型中感興趣的主要軸線為影像品質、結果的變化量，以及結果與特定條件（例如類別標籤或文字提示）的吻合程度。廣受歡迎的無分類器引導方法使用無條件模型來引導條件模型，同時能改善提示對齊並提升影像品質，但代價是減少變化。這些效應似乎是內在糾纏的，因此難以控制。我們做出令人驚訝的觀察，發現可以透過使用較小、訓練較少的模型版本，而不是無條件模型，來引導生成，以獲得對影像品質的解耦控制，而不會損害變化的數量。這會大幅改善 ImageNet 的生成，使用公開網路，將 64x64 的紀錄 FID 設為 1.01，512x512 的紀錄 FID 設為 1.25。此外，此方法也適用於無條件擴散模型，大幅改善其品質。

##### **Demystifying the Compression of Mixture-of-Experts Through a Unified Framework**
2406.02500v1 by Shwai He, Daize Dong, Liang Ding, Ang Li

Scaling large language models has revolutionized the performance across
diverse domains, yet the continual growth in model size poses significant
challenges for real-world deployment. The Mixture of Experts (MoE) approach
addresses this by dynamically selecting and activating only a subset of
experts, significantly reducing computational costs while maintaining high
performance. However, MoE introduces potential redundancy (e.g., parameters)
and extra costs (e.g., communication overhead). Despite numerous compression
techniques developed for mitigating the redundancy in dense models, the
compression of MoE remains under-explored. We first bridge this gap with a
cutting-edge unified framework that not only seamlessly integrates mainstream
compression methods but also helps systematically understand MoE compression.
This framework approaches compression from two perspectives: Expert Slimming
which compresses individual experts and Expert Trimming which removes
structured modules. Within this framework, we explore the optimization space
unexplored by existing methods,and further introduce aggressive Expert Trimming
techniques, i.e., Layer Drop and Block Drop, to eliminate redundancy at larger
scales. Based on these insights,we present a comprehensive recipe to guide
practitioners in compressing MoE effectively. Extensive experimental results
demonstrate the effectiveness of the compression methods under our framework
and the proposed recipe, achieving a 6.05x speedup and only 20.0GB memory usage
while maintaining over 92% of performance on Mixtral-8x7B.

摘要：<paragraph>大規模語言模型的擴展徹底改變了各個領域的效能，然而模型規模的持續擴大對實際部署提出了重大挑戰。專家混合 (MoE) 方法透過動態選取並僅啟用專家子集來解決此問題，大幅降低運算成本，同時維持高效能。然而，MoE 引入了潛在的冗餘（例如參數）和額外成本（例如通訊負擔）。儘管已開發出許多壓縮技術來減輕密集模型中的冗餘，但 MoE 的壓縮仍未被充分探索。我們首先透過一個尖端的統一架構來彌補此差距，不僅能無縫整合主流壓縮方法，還能幫助系統性地了解 MoE 壓縮。此架構從兩個角度來探討壓縮：專家精簡（壓縮個別專家）和專家修剪（移除結構化模組）。在此架構內，我們探索了現有方法未探索的最佳化空間，並進一步引入了積極的專家修剪技術，即層次中斷和區塊中斷，以消除更大規模的冗餘。根據這些見解，我們提出了一個全面的配方，以指導從業人員有效壓縮 MoE。廣泛的實驗結果證明了我們架構和建議配方中壓縮方法的有效性，在 Mixtral-8x7B 上實現了 6.05 倍加速和僅 20.0GB 的記憶體使用量，同時維持超過 92% 的效能。</paragraph>

##### **Dropout MPC: An Ensemble Neural MPC Approach for Systems with Learned Dynamics**
2406.02497v1 by Spyridon Syntakas, Kostas Vlachos

Neural networks are lately more and more often being used in the context of
data-driven control, as an approximate model of the true system dynamics. Model
Predictive Control (MPC) adopts this practise leading to neural MPC strategies.
This raises a question of whether the trained neural network has converged and
generalized in a way that the learned model encapsulates an accurate
approximation of the true dynamic model of the system, thus making it a
reliable choice for model-based control, especially for disturbed and uncertain
systems. To tackle that, we propose Dropout MPC, a novel sampling-based
ensemble neural MPC algorithm that employs the Monte-Carlo dropout technique on
the learned system model. The closed loop is based on an ensemble of predictive
controllers, that are used simultaneously at each time-step for trajectory
optimization. Each member of the ensemble influences the control input, based
on a weighted voting scheme, thus by employing different realizations of the
learned system dynamics, neural control becomes more reliable by design. An
additional strength of the method is that it offers by design a way to estimate
future uncertainty, leading to cautious control. While the method aims in
general at uncertain systems with complex dynamics, where models derived from
first principles are hard to infer, to showcase the application we utilize data
gathered in the laboratory from a real mobile manipulator and employ the
proposed algorithm for the navigation of the robot in simulation.

摘要：<paragraph>神经網路最近越來越常在資料驅動控制的背景下被用作真實系統動態的近似模型。模型預測控制 (MPC) 採用這種做法，進而產生神經 MPC 策略。這引發了一個問題，即受過訓練的神經網路是否已收斂並概括化，使得學習到的模型包含系統真實動態模型的精確近似值，從而使其成為基於模型的控制的可靠選擇，特別是對於受干擾和不確定的系統。為了解決這個問題，我們提出了 Dropout MPC，一種新穎的基於抽樣的整體神經 MPC 演算法，該演算法對學習到的系統模型採用蒙地卡羅 Dropout 技術。閉迴路基於預測控制器的整體，這些控制器在每個時間步長同時用於軌跡最佳化。整體的每個成員都基於加權投票方案影響控制輸入，因此，通過採用學習到的系統動態的不同實現，神經控制在設計上變得更加可靠。該方法的另一個優點是，它在設計上提供了一種估計未來不確定性的方法，從而導致謹慎的控制。雖然該方法通常針對具有複雜動態的不確定系統，其中難以推論出從第一原理衍生的模型，但為了展示應用，我們利用從真實移動機械手臂在實驗室中收集的資料，並採用所提出的演算法在模擬中導航機器人。</paragraph>

##### **Kolmogorov-Arnold Networks for Time Series: Bridging Predictive Power and Interpretability**
2406.02496v1 by Kunpeng Xu, Lifei Chen, Shengrui Wang

Kolmogorov-Arnold Networks (KAN) is a groundbreaking model recently proposed
by the MIT team, representing a revolutionary approach with the potential to be
a game-changer in the field. This innovative concept has rapidly garnered
worldwide interest within the AI community. Inspired by the Kolmogorov-Arnold
representation theorem, KAN utilizes spline-parametrized univariate functions
in place of traditional linear weights, enabling them to dynamically learn
activation patterns and significantly enhancing interpretability. In this
paper, we explore the application of KAN to time series forecasting and propose
two variants: T-KAN and MT-KAN. T-KAN is designed to detect concept drift
within time series and can explain the nonlinear relationships between
predictions and previous time steps through symbolic regression, making it
highly interpretable in dynamically changing environments. MT-KAN, on the other
hand, improves predictive performance by effectively uncovering and leveraging
the complex relationships among variables in multivariate time series.
Experiments validate the effectiveness of these approaches, demonstrating that
T-KAN and MT-KAN significantly outperform traditional methods in time series
forecasting tasks, not only enhancing predictive accuracy but also improving
model interpretability. This research opens new avenues for adaptive
forecasting models, highlighting the potential of KAN as a powerful and
interpretable tool in predictive analytics.

摘要：Kolmogorov-Arnold 網路 (KAN) 是麻省理工學院團隊最近提出的突破性模型，它代表了一種革命性的方法，有潛力成為該領域的遊戲規則改變者。這個創新概念在 AI 社群中迅速引起全球性的興趣。受到 Kolmogorov-Arnold 表示定理的啟發，KAN 利用樣條參數化單變數函數取代傳統的線性權重，讓它們能夠動態學習激活模式，並顯著增強可解釋性。在本文中，我們探討了 KAN 在時間序列預測中的應用，並提出了兩個變體：T-KAN 和 MT-KAN。T-KAN 被設計用於偵測時間序列中的概念漂移，並且能夠透過符號回歸來解釋預測和先前時間步驟之間的非線性關係，使其在動態變化的環境中具有高度的可解釋性。另一方面，MT-KAN 則透過有效地揭示和利用多變量時間序列中變數之間的複雜關係，來改善預測效能。實驗驗證了這些方法的有效性，證明 T-KAN 和 MT-KAN 在時間序列預測任務中顯著優於傳統方法，不僅增強了預測準確度，還改善了模型的可解釋性。這項研究為適應性預測模型開啟了新的途徑，突顯了 KAN 作為預測分析中強大且可解釋工具的潛力。

##### **Language-Universal Speech Attributes Modeling for Zero-Shot Multilingual Spoken Keyword Recognition**
2406.02488v1 by Hao Yen, Pin-Jui Ku, Sabato Marco Siniscalchi, Chin-Hui Lee

We propose a novel language-universal approach to end-to-end automatic spoken
keyword recognition (SKR) leveraging upon (i) a self-supervised pre-trained
model, and (ii) a set of universal speech attributes (manner and place of
articulation). Specifically, Wav2Vec2.0 is used to generate robust speech
representations, followed by a linear output layer to produce attribute
sequences. A non-trainable pronunciation model then maps sequences of
attributes into spoken keywords in a multilingual setting. Experiments on the
Multilingual Spoken Words Corpus show comparable performances to character- and
phoneme-based SKR in seen languages. The inclusion of domain adversarial
training (DAT) improves the proposed framework, outperforming both character-
and phoneme-based SKR approaches with 13.73% and 17.22% relative word error
rate (WER) reduction in seen languages, and achieves 32.14% and 19.92% WER
reduction for unseen languages in zero-shot settings.

摘要：<paragraph>我們提出一個新穎的語言通用方法，用於端對端的自動口說關鍵字辨識 (SKR)，利用 (i) 自我監督預訓練模型，以及 (ii) 一組通用語音屬性 (發音方式和位置)。具體來說，Wav2Vec2.0 用於產生穩健的語音表示，接著是一個線性輸出層，用於產生屬性序列。一個不可訓練的發音模型然後將屬性序列映射到多語言環境中的口說關鍵字。在多語言口說單字語料庫上的實驗顯示，在已見語言中與基於字元和音素的 SKR 有相當的效能。加入領域對抗訓練 (DAT) 會改善建議的架構，在已見語言中以 13.73% 和 17.22% 的相對字元錯誤率 (WER) 降低幅度，優於基於字元和音素的 SKR 方法，並在零次學習設定中，針對未見語言達到 32.14% 和 19.92% 的 WER 降低幅度。</paragraph>

##### **How Do Neural Spoofing Countermeasures Detect Partially Spoofed Audio?**
2406.02483v1 by Tianchi Liu, Lin Zhang, Rohan Kumar Das, Yi Ma, Ruijie Tao, Haizhou Li

Partially manipulating a sentence can greatly change its meaning. Recent work
shows that countermeasures (CMs) trained on partially spoofed audio can
effectively detect such spoofing. However, the current understanding of the
decision-making process of CMs is limited. We utilize Grad-CAM and introduce a
quantitative analysis metric to interpret CMs' decisions. We find that CMs
prioritize the artifacts of transition regions created when concatenating bona
fide and spoofed audio. This focus differs from that of CMs trained on fully
spoofed audio, which concentrate on the pattern differences between bona fide
and spoofed parts. Our further investigation explains the varying nature of
CMs' focus while making correct or incorrect predictions. These insights
provide a basis for the design of CM models and the creation of datasets.
Moreover, this work lays a foundation of interpretability in the field of
partial spoofed audio detection that has not been well explored previously.

摘要：部分操縱句子會大幅改變其含義。最近的研究顯示，針對部分偽造音訊訓練的對策 (CM) 可以有效偵測此類偽造。然而，目前對於 CM 決策過程的理解有限。我們利用 Grad-CAM 並引入量化分析指標來詮釋 CM 的決策。我們發現 CM 優先考慮連結真實和偽造音訊時所建立的過渡區域的偽影。這種重點不同於訓練於完全偽造音訊的 CM，後者專注於真實和偽造部分之間的模式差異。我們的進一步調查說明了 CM 在做出正確或不正確預測時焦點的不同性質。這些見解為 CM 模型的設計和資料集的建立提供了基礎。此外，這項工作為以前未充分探討的部分偽造音訊偵測領域奠定了可解釋性的基礎。

##### **Hiding Text in Large Language Models: Introducing Unconditional Token Forcing Confusion**
2406.02481v1 by Jakub Hoscilowicz, Pawel Popiolek, Jan Rudkowski, Jedrzej Bieniasz, Artur Janicki

With the help of simple fine-tuning, one can artificially embed hidden text
into large language models (LLMs). This text is revealed only when triggered by
a specific query to the LLM. Two primary applications are LLM fingerprinting
and steganography. In the context of LLM fingerprinting, a unique text
identifier (fingerprint) is embedded within the model to verify licensing
compliance. In the context of steganography, the LLM serves as a carrier for
hidden messages that can be disclosed through a designated trigger.
  Our work demonstrates that embedding hidden text in the LLM via fine-tuning,
though seemingly secure due to the vast number of potential triggers (any
sequence of characters or tokens could serve as a trigger), is susceptible to
extraction through analysis of the LLM's output decoding process. We propose a
novel approach to extraction called Unconditional Token Forcing. It is premised
on the hypothesis that iteratively feeding each token from the LLM's vocabulary
into the model should reveal sequences with abnormally high token
probabilities, indicating potential embedded text candidates. Additionally, our
experiments show that when the first token of a hidden fingerprint is used as
an input, the LLM not only produces an output sequence with high token
probabilities, but also repetitively generates the fingerprint itself. We also
present a method to hide text in such a way that it is resistant to
Unconditional Token Forcing, which we named Unconditional Token Forcing
Confusion.

摘要：透過簡單的微調，可以將隱藏文字人工嵌入大型語言模型 (LLM) 中。此文字僅在特定查詢觸發 LLM 時才會顯示。兩個主要的應用程式為 LLM 指紋識別和隱寫術。在 LLM 指紋識別的背景下，會將一個獨特的文字識別碼 (指紋) 嵌入模型中，以驗證授權合規性。在隱寫術的背景下，LLM 可作為隱藏訊息的載體，可透過指定的觸發器來揭露。我們的研究證明，儘管由於潛在觸發器的數量龐大（任何字元或代碼序列都可以作為觸發器），透過微調將隱藏文字嵌入 LLM 中看似安全，但仍可能透過分析 LLM 輸出解碼過程來提取。我們提出了一種稱為無條件代碼強制的新穎提取方法。它的前提是假設將 LLM 字彙中的每個代碼反覆輸入模型中，應會顯示具有異常高代碼機率的序列，表示潛在的嵌入文字候選。此外，我們的實驗顯示，當隱藏指紋的第一個代碼用作輸入時，LLM 不僅會產生具有高代碼機率的輸出序列，還會重複產生指紋本身。我們也提出了一種隱藏文字的方法，使其能抵抗無條件代碼強制，我們稱之為無條件代碼強制混淆。

##### **Analyzing Temporal Complex Events with Large Language Models? A Benchmark towards Temporal, Long Context Understanding**
2406.02472v1 by Zhihan Zhang, Yixin Cao, Chenchen Ye, Yunshan Ma, Lizi Liao, Tat-Seng Chua

The digital landscape is rapidly evolving with an ever-increasing volume of
online news, emphasizing the need for swift and precise analysis of complex
events. We refer to the complex events composed of many news articles over an
extended period as Temporal Complex Event (TCE). This paper proposes a novel
approach using Large Language Models (LLMs) to systematically extract and
analyze the event chain within TCE, characterized by their key points and
timestamps. We establish a benchmark, named TCELongBench, to evaluate the
proficiency of LLMs in handling temporal dynamics and understanding extensive
text. This benchmark encompasses three distinct tasks - reading comprehension,
temporal sequencing, and future event forecasting. In the experiment, we
leverage retrieval-augmented generation (RAG) method and LLMs with long context
window to deal with lengthy news articles of TCE. Our findings indicate that
models with suitable retrievers exhibit comparable performance with those
utilizing long context window.

摘要：隨著網路新聞量不斷增加，數位環境快速演變，強調快速且精確分析複雜事件的需求。我們稱由許多新聞文章在一段時間內組成的複雜事件為時間複雜事件 (TCE)。本文提出一個新方法，使用大型語言模型 (LLM) 來系統性地擷取和分析 TCE 中的事件鏈，其特徵在於關鍵點和時間戳記。我們建立一個名為 TCELongBench 的基準，以評估 LLM 在處理時間動態和理解廣泛文字方面的能力。此基準包含三個不同的任務 - 閱讀理解、時間順序和未來事件預測。在實驗中，我們利用檢索增強生成 (RAG) 方法和具有長內容視窗的 LLM 來處理 TCE 的冗長新聞文章。我們的研究結果表明，具有合適檢索器的模型展現出與使用長內容視窗的模型相當的效能。

##### **Landscape-Aware Growing: The Power of a Little LAG**
2406.02469v1 by Stefani Karp, Nikunj Saunshi, Sobhan Miryoosefi, Sashank J. Reddi, Sanjiv Kumar

Recently, there has been increasing interest in efficient pretraining
paradigms for training Transformer-based models. Several recent approaches use
smaller models to initialize larger models in order to save computation (e.g.,
stacking and fusion). In this work, we study the fundamental question of how to
select the best growing strategy from a given pool of growing strategies. Prior
works have extensively focused on loss- and/or function-preserving behavior at
initialization or simply performance at the end of training. Instead, we
identify that behavior at initialization can be misleading as a predictor of
final performance and present an alternative perspective based on early
training dynamics, which we call "landscape-aware growing (LAG)". We perform
extensive analysis of correlation of the final performance with performance in
the initial steps of training and find early and more accurate predictions of
the optimal growing strategy (i.e., with only a small "lag" after
initialization). This perspective also motivates an adaptive strategy for
gradual stacking.

摘要：最近，对于训练基于 Transformer 的模型的高效预训练范例产生了越来越多的兴趣。最近的几种方法使用较小的模型来初始化较大的模型，以节省计算（例如，堆叠和融合）。在这项工作中，我们研究了如何从给定的增长策略池中选择最佳增长策略的基本问题。先前的研究广泛关注初始化时的损失和/或函数保留行为，或者仅仅关注训练结束时的性能。相反，我们发现初始化时的行为可能具有误导性，无法预测最终性能，并提出了基于早期训练动态的替代观点，我们称之为“景观感知增长 (LAG)”。我们对最终性能与训练初始步骤中的性能的相关性进行了广泛的分析，并找到了最佳增长策略的早期且更准确的预测（即，初始化后仅有很小的“滞后”）。这种观点还激发了渐进式堆叠的自适应策略。

##### **An Empirical Study into Clustering of Unseen Datasets with Self-Supervised Encoders**
2406.02465v1 by Scott C. Lowe, Joakim Bruslund Haurum, Sageev Oore, Thomas B. Moeslund, Graham W. Taylor

Can pretrained models generalize to new datasets without any retraining? We
deploy pretrained image models on datasets they were not trained for, and
investigate whether their embeddings form meaningful clusters. Our suite of
benchmarking experiments use encoders pretrained solely on ImageNet-1k with
either supervised or self-supervised training techniques, deployed on image
datasets that were not seen during training, and clustered with conventional
clustering algorithms. This evaluation provides new insights into the
embeddings of self-supervised models, which prioritize different features to
supervised models. Supervised encoders typically offer more utility than SSL
encoders within the training domain, and vice-versa far outside of it, however,
fine-tuned encoders demonstrate the opposite trend. Clustering provides a way
to evaluate the utility of self-supervised learned representations orthogonal
to existing methods such as kNN. Additionally, we find the silhouette score
when measured in a UMAP-reduced space is highly correlated with clustering
performance, and can therefore be used as a proxy for clustering performance on
data with no ground truth labels. Our code implementation is available at
\url{https://github.com/scottclowe/zs-ssl-clustering/}.

摘要：預訓練模型是否可以在不重新訓練的情況下推廣到新的資料集？我們在未經訓練的資料集上部署預訓練的影像模型，並調查其嵌入是否形成有意義的群集。我們的基準測試實驗使用僅在 ImageNet-1k 上預訓練的編碼器，採用監督式或自監督式訓練技術，部署在訓練期間未見過的影像資料集上，並使用傳統的群集演算法進行群集。此評估提供了對自監督式模型嵌入的新見解，這些模型優先考慮監督式模型的不同特徵。監督式編碼器通常在訓練領域內提供比 SSL 編碼器更多的效用，反之亦然，然而，微調編碼器顯示出相反的趨勢。群集提供了一種方法來評估自監督式學習表徵的效用，與現有方法（例如 kNN）正交。此外，我們發現當在 UMAP 縮減空間中測量時，輪廓分數與群集效能高度相關，因此可用作沒有基本事實標籤的資料上群集效能的代理。我們的程式碼實作可在以下網址取得：\url{https://github.com/scottclowe/zs-ssl-clustering/}。

##### **Meta-Learners for Partially-Identified Treatment Effects Across Multiple Environments**
2406.02464v1 by Jonas Schweisthal, Dennis Frauen, Mihaela van der Schaar, Stefan Feuerriegel

Estimating the conditional average treatment effect (CATE) from observational
data is relevant for many applications such as personalized medicine. Here, we
focus on the widespread setting where the observational data come from multiple
environments, such as different hospitals, physicians, or countries.
Furthermore, we allow for violations of standard causal assumptions, namely,
overlap within the environments and unconfoundedness. To this end, we move away
from point identification and focus on partial identification. Specifically, we
show that current assumptions from the literature on multiple environments
allow us to interpret the environment as an instrumental variable (IV). This
allows us to adapt bounds from the IV literature for partial identification of
CATE by leveraging treatment assignment mechanisms across environments. Then,
we propose different model-agnostic learners (so-called meta-learners) to
estimate the bounds that can be used in combination with arbitrary machine
learning models. We further demonstrate the effectiveness of our meta-learners
across various experiments using both simulated and real-world data. Finally,
we discuss the applicability of our meta-learners to partial identification in
instrumental variable settings, such as randomized controlled trials with
non-compliance.

摘要：從觀測資料估計條件平均處理效果 (CATE) 與許多應用程式有關，例如個人化醫療。在此，我們專注於廣泛的設定，其中觀測資料來自多個環境，例如不同的醫院、醫生或國家。此外，我們允許違反標準因果假設，即環境內的重疊和未混淆。為此，我們遠離點識別並專注於部分識別。具體來說，我們表明來自多環境文獻的當前假設允許我們將環境解釋為工具變量 (IV)。這使我們能夠調整 IV 文獻中的界限，以通過利用環境中的治療分配機制來部分識別 CATE。然後，我們提出不同的與模型無關的學習器（所謂的元學習器）來估計可與任意機器學習模型結合使用的界限。我們進一步使用模擬和真實世界資料在各種實驗中證明了我們的元學習器的有效性。最後，我們討論了我們的元學習器在工具變量設定中進行部分識別的適用性，例如具有不遵守規定的隨機對照試驗。

##### **Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems**
2406.02462v1 by Jason Hu, Bowen Song, Xiaojian Xu, Liyue Shen, Jeffrey A. Fessler

Diffusion models can learn strong image priors from underlying data
distribution and use them to solve inverse problems, but the training process
is computationally expensive and requires lots of data. Such bottlenecks
prevent most existing works from being feasible for high-dimensional and
high-resolution data such as 3D images. This paper proposes a method to learn
an efficient data prior for the entire image by training diffusion models only
on patches of images. Specifically, we propose a patch-based position-aware
diffusion inverse solver, called PaDIS, where we obtain the score function of
the whole image through scores of patches and their positional encoding and
utilize this as the prior for solving inverse problems. First of all, we show
that this diffusion model achieves an improved memory efficiency and data
efficiency while still maintaining the capability to generate entire images via
positional encoding. Additionally, the proposed PaDIS model is highly flexible
and can be plugged in with different diffusion inverse solvers (DIS). We
demonstrate that the proposed PaDIS approach enables solving various inverse
problems in both natural and medical image domains, including CT
reconstruction, deblurring, and superresolution, given only patch-based priors.
Notably, PaDIS outperforms previous DIS methods trained on entire image priors
in the case of limited training data, demonstrating the data efficiency of our
proposed approach by learning patch-based prior.

摘要：扩散模型可以从底层数据分布中学习强图像先验，并利用它们来解决逆问题，但训练过程在计算上很昂贵，需要大量数据。此类瓶颈阻碍了大多数现有工作对高维和高分辨率数据（例如 3D 图像）的可行性。本文提出了一种方法，仅通过训练图像的块来学习整个图像的有效数据先验，以扩散模型。具体来说，我们提出了一个基于块的位置感知扩散逆求解器，称为 PaDIS，其中我们通过块及其位置编码获得整个图像的分数函数，并将其用作解决逆问题的先验。首先，我们表明该扩散模型实现了改进的内存效率和数据效率，同时仍保持通过位置编码生成整个图像的能力。此外，提出的 PaDIS 模型非常灵活，可以插入不同的扩散逆求解器 (DIS)。我们证明了所提出的 PaDIS 方法能够解决自然和医学图像域中的各种逆问题，包括 CT 重建、去模糊和超分辨率，仅给出基于块的先验。值得注意的是，在训练数据有限的情况下，PaDIS 优于以前在整个图像先验上训练的 DIS 方法，证明了我们提出的方法通过学习基于块的先验的数据效率。

##### **A Generalized Apprenticeship Learning Framework for Modeling Heterogeneous Student Pedagogical Strategies**
2406.02450v1 by Md Mirajul Islam, Xi Yang, John Hostetter, Adittya Soukarjya Saha, Min Chi

A key challenge in e-learning environments like Intelligent Tutoring Systems
(ITSs) is to induce effective pedagogical policies efficiently. While Deep
Reinforcement Learning (DRL) often suffers from sample inefficiency and reward
function design difficulty, Apprenticeship Learning(AL) algorithms can overcome
them. However, most AL algorithms can not handle heterogeneity as they assume
all demonstrations are generated with a homogeneous policy driven by a single
reward function. Still, some AL algorithms which consider heterogeneity, often
can not generalize to large continuous state space and only work with discrete
states. In this paper, we propose an expectation-maximization(EM)-EDM, a
general AL framework to induce effective pedagogical policies from given
optimal or near-optimal demonstrations, which are assumed to be driven by
heterogeneous reward functions. We compare the effectiveness of the policies
induced by our proposed EM-EDM against four AL-based baselines and two policies
induced by DRL on two different but related tasks that involve pedagogical
action prediction. Our overall results showed that, for both tasks, EM-EDM
outperforms the four AL baselines across all performance metrics and the two
DRL baselines. This suggests that EM-EDM can effectively model complex student
pedagogical decision-making processes through the ability to manage a large,
continuous state space and adapt to handle diverse and heterogeneous reward
functions with very few given demonstrations.

摘要：在電子學習環境（例如智慧型教學系統 (ITS)) 中，一個關鍵挑戰是有效率地誘導出有效的教學政策。雖然深度強化學習 (DRL) 經常會遇到樣本效率低落和獎勵函數設計困難的問題，但學徒學習 (AL) 演算法可以克服這些問題。不過，大多數 AL 演算法無法處理異質性，因為它們假設所有示範都是由單一獎勵函數驅動的同質政策所產生。儘管如此，某些考慮異質性的 AL 演算法，通常無法廣泛應用於大型連續狀態空間，而且只能用於離散狀態。在本文中，我們提出一個期望最大化 (EM)-EDM，一個通用的 AL 架構，用於從給定的最佳或近乎最佳示範中誘導出有效的教學政策，這些示範假設是由異質獎勵函數驅動。我們比較了由我們提出的 EM-EDM 所誘導出的政策的有效性，與四個基於 AL 的基準和兩個由 DRL 誘導出的政策，這些政策涉及教學動作預測的兩個不同但相關的任務。我們的整體結果顯示，對於這兩個任務，EM-EDM 在所有效能指標上都優於四個 AL 基準和兩個 DRL 基準。這表示 EM-EDM 可以透過管理一個大型連續狀態空間，並適應處理具有非常少給定示範的多元且異質的獎勵函數，來有效地模擬複雜的學生教學決策制定過程。

##### **Representations as Language: An Information-Theoretic Framework for Interpretability**
2406.02449v1 by Henry Conklin, Kenny Smith

Large scale neural models show impressive performance across a wide array of
linguistic tasks. Despite this they remain, largely, black-boxes - inducing
vector-representations of their input that prove difficult to interpret. This
limits our ability to understand what they learn, and when the learn it, or
describe what kinds of representations generalise well out of distribution. To
address this we introduce a novel approach to interpretability that looks at
the mapping a model learns from sentences to representations as a kind of
language in its own right. In doing so we introduce a set of
information-theoretic measures that quantify how structured a model's
representations are with respect to its input, and when during training that
structure arises. Our measures are fast to compute, grounded in linguistic
theory, and can predict which models will generalise best based on their
representations. We use these measures to describe two distinct phases of
training a transformer: an initial phase of in-distribution learning which
reduces task loss, then a second stage where representations becoming robust to
noise. Generalisation performance begins to increase during this second phase,
drawing a link between generalisation and robustness to noise. Finally we look
at how model size affects the structure of the representational space, showing
that larger models ultimately compress their representations more than their
smaller counterparts.

摘要：大型神经模型在各种语言任务中表现出色。尽管如此，它们在很大程度上仍然是黑盒子——诱导难以解释的输入向量表示。这限制了我们理解它们学习内容、学习时间或描述哪些类型的表示在分布之外泛化的能力。为了解决这个问题，我们引入了一种新颖的可解释性方法，它将模型从句子到表示的映射视为一种语言本身。在此过程中，我们引入了一组信息论度量，用于量化模型的表示相对于其输入的结构化程度，以及在训练过程中结构何时出现。我们的度量计算速度快，基于语言理论，并且可以根据模型的表示预测哪些模型将泛化得最好。我们使用这些度量来描述训练转换器的两个不同阶段：一个分布内学习的初始阶段，它减少了任务损失，然后是表示变得对噪声鲁棒的第二阶段。泛化性能在此第二阶段开始提高，从而在泛化和对噪声的鲁棒性之间建立联系。最后，我们研究了模型大小如何影响表示空间的结构，表明较大的模型最终比较小的模型更多地压缩它们的表示。

##### **Explainable Deep Learning Analysis for Raga Identification in Indian Art Music**
2406.02443v1 by Parampreet Singh, Vipul Arora

The task of Raga Identification is a very popular research problem in Music
Information Retrieval. Few studies that have explored this task employed
various approaches, such as signal processing, Machine Learning (ML) methods,
and more recently Deep Learning (DL) based methods. However, a key question
remains unanswered in all of these works: do these ML/DL methods learn and
interpret Ragas in a manner similar to human experts? Besides, a significant
roadblock in this research is the unavailability of ample supply of rich,
labeled datasets, which drives these ML/DL based methods. In this paper, we
introduce "Prasarbharti Indian Music" version-1 (PIM-v1), a novel dataset
comprising of 191 hours of meticulously labeled Hindustani Classical Music
(HCM) recordings, which is the largest labeled dataset for HCM recordings to
the best of our knowledge. Our approach involves conducting ablation studies to
find the benchmark classification model for Automatic Raga Identification (ARI)
using PIM-v1 dataset. We achieve a chunk-wise f1-score of 0.89 for a subset of
12 Raga classes. Subsequently, we employ model explainability techniques to
evaluate the classifier's predictions, aiming to ascertain whether they align
with human understanding of Ragas or are driven by arbitrary patterns. We
validate the correctness of model's predictions by comparing the explanations
given by two ExAI models with human expert annotations. Following this, we
analyze explanations for individual test examples to understand the role of
regions highlighted by explanations in correct or incorrect predictions made by
the model.

摘要：拉格识别任务是音乐信息检索中非常流行的研究问题。探索这项任务的少数研究采用了各种方法，例如信号处理、机器学习 (ML) 方法，以及最近基于深度学习 (DL) 的方法。然而，所有这些工作中都仍然有一个关键问题没有得到解答：这些 ML/DL 方法是否以类似于人类专家的方式学习和解释拉格？此外，这项研究中的一个重大障碍是缺乏丰富且标记良好的数据集，而这正是这些基于 ML/DL 的方法的驱动力。在本文中，我们介绍了“Prasarbharti Indian Music”版本 1 (PIM-v1)，这是一个新颖的数据集，包含 191 小时的精心标记的印度斯坦古典音乐 (HCM) 录音，据我们所知，这是 HCM 录音中最大的标记数据集。我们的方法包括进行消融研究，以找到使用 PIM-v1 数据集进行自动拉格识别 (ARI) 的基准分类模型。对于 12 个拉格类别的子集，我们实现了 0.89 的分块 f1 分数。随后，我们采用模型可解释性技术来评估分类器的预测，目的是确定它们是否与人类对拉格的理解一致，或者是由任意模式驱动的。我们通过将两个 ExAI 模型给出的解释与人类专家注释进行比较来验证模型预测的正确性。在此之后，我们分析了单个测试示例的解释，以了解解释中突出显示的区域在模型做出的正确或不正确的预测中所扮演的角色。

##### **The Scandinavian Embedding Benchmarks: Comprehensive Assessment of Multilingual and Monolingual Text Embedding**
2406.02396v1 by Kenneth Enevoldsen, Márton Kardos, Niklas Muennighoff, Kristoffer Laigaard Nielbo

The evaluation of English text embeddings has transitioned from evaluating a
handful of datasets to broad coverage across many tasks through benchmarks such
as MTEB. However, this is not the case for multilingual text embeddings due to
a lack of available benchmarks. To address this problem, we introduce the
Scandinavian Embedding Benchmark (SEB). SEB is a comprehensive framework that
enables text embedding evaluation for Scandinavian languages across 24 tasks,
10 subtasks, and 4 task categories. Building on SEB, we evaluate more than 26
models, uncovering significant performance disparities between public and
commercial solutions not previously captured by MTEB. We open-source SEB and
integrate it with MTEB, thus bridging the text embedding evaluation gap for
Scandinavian languages.

摘要：英語文字嵌入的評估已從評估少數資料集轉變為透過 MTEB 等基準在許多任務中廣泛涵蓋。然而，由於缺乏可用的基準，多語文字嵌入並非如此。為了解決這個問題，我們引入了斯堪地那維亞嵌入基準 (SEB)。SEB 是個全面的架構，可在 24 個任務、10 個子任務和 4 個任務類別中啟用斯堪地那維亞語言的文字嵌入評估。建立在 SEB 的基礎上，我們評估了超過 26 個模型，發現了 MTEB 之前未捕捉到的公開和商業解決方案之間的顯著效能差異。我們開放原始碼 SEB 並將其與 MTEB 整合，從而彌補了斯堪地那維亞語言的文字嵌入評估差距。

##### **Multiple Choice Questions and Large Languages Models: A Case Study with Fictional Medical Data**
2406.02394v1 by Maxime Griot, Jean Vanderdonckt, Demet Yuksel, Coralie Hemptinne

Large Language Models (LLMs) like ChatGPT demonstrate significant potential
in the medical field, often evaluated using multiple-choice questions (MCQs)
similar to those found on the USMLE. Despite their prevalence in medical
education, MCQs have limitations that might be exacerbated when assessing LLMs.
To evaluate the effectiveness of MCQs in assessing the performance of LLMs, we
developed a fictional medical benchmark focused on a non-existent gland, the
Glianorex. This approach allowed us to isolate the knowledge of the LLM from
its test-taking abilities. We used GPT-4 to generate a comprehensive textbook
on the Glianorex in both English and French and developed corresponding
multiple-choice questions in both languages. We evaluated various open-source,
proprietary, and domain-specific LLMs using these questions in a zero-shot
setting. The models achieved average scores around 67%, with minor performance
differences between larger and smaller models. Performance was slightly higher
in English than in French. Fine-tuned medical models showed some improvement
over their base versions in English but not in French. The uniformly high
performance across models suggests that traditional MCQ-based benchmarks may
not accurately measure LLMs' clinical knowledge and reasoning abilities,
instead highlighting their pattern recognition skills. This study underscores
the need for more robust evaluation methods to better assess the true
capabilities of LLMs in medical contexts.

摘要：大型語言模型（LLM），例如 ChatGPT，在醫療領域展現出顯著的潛力，通常使用與美國執業醫師資格考試 (USMLE) 中類似的多選題 (MCQ) 進行評估。儘管 MCQ 在醫學教育中很普遍，但在評估 LLM 時，其限制可能會被放大。為了評估 MCQ 在評估 LLM 效能方面的有效性，我們開發了一個虛構的醫療基準，重點關注一個不存在的腺體：Glianorex。這種方法讓我們能夠將 LLM 的知識與其應試能力隔離開來。我們使用 GPT-4 以英文和法文生成了關於 Glianorex 的一本綜合教科書，並開發了相應的多選題。我們在零次學習設定中使用這些問題評估了各種開源、專有和特定領域的 LLM。這些模型達到了平均約 67% 的分數，較大和較小模型之間的效能差異很小。英文的效能略高於法文。微調後的醫療模型在英文方面表現出比其基礎版本略有進步，但在法文方面則沒有。所有模型的效能均一致地高，這表明傳統基於 MCQ 的基準可能無法準確衡量 LLM 的臨床知識和推理能力，而僅突顯了它們的模式識別技能。這項研究強調了需要更強大的評估方法，以更好地評估 LLM 在醫療環境中的真實能力。

##### **Learning to Edit Visual Programs with Self-Supervision**
2406.02383v1 by R. Kenny Jones, Renhao Zhang, Aditya Ganeshan, Daniel Ritchie

We design a system that learns how to edit visual programs. Our edit network
consumes a complete input program and a visual target. From this input, we task
our network with predicting a local edit operation that could be applied to the
input program to improve its similarity to the target. In order to apply this
scheme for domains that lack program annotations, we develop a self-supervised
learning approach that integrates this edit network into a bootstrapped
finetuning loop along with a network that predicts entire programs in one-shot.
Our joint finetuning scheme, when coupled with an inference procedure that
initializes a population from the one-shot model and evolves members of this
population with the edit network, helps to infer more accurate visual programs.
Over multiple domains, we experimentally compare our method against the
alternative of using only the one-shot model, and find that even under equal
search-time budgets, our editing-based paradigm provides significant
advantages.

摘要：我們設計了一個系統，可以學習如何編輯視覺程式。我們的編輯網路
會使用一個完整的輸入程式和一個視覺目標。從這個輸入，我們任務
我們的網路預測一個局部編輯操作，可以應用到
輸入程式以改善其與目標的相似性。為了將這個
方案應用到缺乏程式註解的網域，我們開發了一個自我監督
學習方法，將這個編輯網路整合到一個引導式
微調迴圈，以及一個可以在一次性預測整個程式的網路。
我們的聯合微調方案，當與一個從一次性模型初始化族群的推論程序結合，並使用編輯網路演化這個
族群的成員，有助於推論出更準確的視覺程式。
在多個網域中，我們實證比較我們的模型與
僅使用一次性模型的替代方案，並發現即使在相等的
搜尋時間預算下，我們的基於編輯的範例提供了顯著的
優勢。

##### **Kirigami: large convolutional kernels improve deep learning-based RNA secondary structure prediction**
2406.02381v1 by Marc Harary, Chengxin Zhang, Anna Marie Pyle

We introduce a novel fully convolutional neural network (FCN) architecture
for predicting the secondary structure of ribonucleic acid (RNA) molecules.
Interpreting RNA structures as weighted graphs, we employ deep learning to
estimate the probability of base pairing between nucleotide residues. Unique to
our model are its massive 11-pixel kernels, which we argue provide a distinct
advantage for FCNs on the specialized domain of RNA secondary structures. On a
widely adopted, standardized test set comprised of 1,305 molecules, the
accuracy of our method exceeds that of current state-of-the-art (SOTA)
secondary structure prediction software, achieving a Matthews Correlation
Coefficient (MCC) over 11-40% higher than that of other leading methods on
overall structures and 58-400% higher on pseudoknots specifically.

摘要：我們介紹一個新的全卷積神經網路（FCN）架構，用於預測核糖核酸（RNA）分子的二級結構。將 RNA 結構解讀為加權圖形，我們採用深度學習來估計核苷酸殘基之間鹼基配對的機率。我們的模型獨特之處在於其巨大的 11 像素核，我們認為這為 FCN 在 RNA 二級結構的專業領域提供了顯著的優勢。在廣泛採用的標準化測試集中，包含 1,305 個分子，我們的方法的準確度超過了當前最先進（SOTA）的二級結構預測軟體，在整體結構上達到了比其他領先方法高出 11-40% 的馬修斯相關係數（MCC），而在假結上則高出 58-400%。

##### **On the Intrinsic Self-Correction Capability of LLMs: Uncertainty and Latent Concept**
2406.02378v1 by Guangliang Liu, Haitao Mao, Bochuan Cao, Zhiyu Xue, Kristen Johnson, Jiliang Tang, Rongrong Wang

Large Language Models (LLMs) can improve their responses when instructed to
do so, a capability known as self-correction. When these instructions lack
specific details about the issues in the response, this is referred to as
leveraging the intrinsic self-correction capability. The empirical success of
self-correction can be found in various applications, e.g., text detoxification
and social bias mitigation. However, leveraging this self-correction capability
may not always be effective, as it has the potential to revise an initially
correct response into an incorrect one. In this paper, we endeavor to
understand how and why leveraging the self-correction capability is effective.
We identify that appropriate instructions can guide LLMs to a convergence
state, wherein additional self-correction steps do not yield further
performance improvements. We empirically demonstrate that model uncertainty and
activated latent concepts jointly characterize the effectiveness of
self-correction. Furthermore, we provide a mathematical formulation indicating
that the activated latent concept drives the convergence of the model
uncertainty and self-correction performance. Our analysis can also be
generalized to the self-correction behaviors observed in Vision-Language Models
(VLMs). Moreover, we highlight that task-agnostic debiasing can benefit from
our principle in terms of selecting effective fine-tuning samples. Such initial
success demonstrates the potential extensibility for better instruction tuning
and safety alignment.

摘要：大型語言模型 (LLM) 在收到指示時可以改善其回應，這種能力稱為自我糾正。當這些指示缺乏關於回應中問題的具體細節時，這稱為利用內在自我糾正能力。自我糾正的經驗成功可以在各種應用中找到，例如文字解毒和社會偏見緩解。然而，利用這種自我糾正能力可能並不總是有效，因為它有可能將最初正確的回應修改為不正確的回應。在本文中，我們努力了解如何以及為什麼利用自我糾正能力是有效的。我們發現適當的指示可以引導 LLM 達到收斂狀態，在這種狀態下，額外的自我糾正步驟不會產生進一步的效能改進。我們經驗性地證明模型不確定性和已啟動的潛在概念共同表徵自我糾正的有效性。此外，我們提供了一個數學公式，表明已啟動的潛在概念驅動了模型不確定性和自我糾正效能的收斂。我們的分析也可以推廣到在視覺語言模型 (VLM) 中觀察到的自我糾正行為。此外，我們強調任務不可知的去偏見可以從我們的原則中受益，以選擇有效的微調樣本。這種初步成功證明了在更好的指令調整和安全性校準方面具有潛在的可擴充性。

##### **XRec: Large Language Models for Explainable Recommendation**
2406.02377v1 by Qiyao Ma, Xubin Ren, Chao Huang

Recommender systems help users navigate information overload by providing
personalized recommendations aligned with their preferences. Collaborative
Filtering (CF) is a widely adopted approach, but while advanced techniques like
graph neural networks (GNNs) and self-supervised learning (SSL) have enhanced
CF models for better user representations, they often lack the ability to
provide explanations for the recommended items. Explainable recommendations aim
to address this gap by offering transparency and insights into the
recommendation decision-making process, enhancing users' understanding. This
work leverages the language capabilities of Large Language Models (LLMs) to
push the boundaries of explainable recommender systems. We introduce a
model-agnostic framework called XRec, which enables LLMs to provide
comprehensive explanations for user behaviors in recommender systems. By
integrating collaborative signals and designing a lightweight collaborative
adaptor, the framework empowers LLMs to understand complex patterns in
user-item interactions and gain a deeper understanding of user preferences. Our
extensive experiments demonstrate the effectiveness of XRec, showcasing its
ability to generate comprehensive and meaningful explanations that outperform
baseline approaches in explainable recommender systems. We open-source our
model implementation at https://github.com/HKUDS/XRec.

摘要：推薦系統透過提供符合使用者偏好的個人化推薦，協助使用者在資訊爆炸中輕鬆瀏覽。協同過濾 (CF) 是一種廣泛採用的方法，但儘管圖神經網路 (GNN) 和自監督學習 (SSL) 等進階技術已增強 CF 模型以提供更好的使用者表徵，但它們通常缺乏提供推薦項目解釋的能力。可解釋推薦旨在透過提供透明度和見解來解決這個差距，以了解推薦決策制定過程，進而增進使用者的理解。這項工作利用大型語言模型 (LLM) 的語言能力，來突破可解釋推薦系統的界限。我們引進一個名為 XRec 的與模型無關的架構，讓 LLM 能夠為推薦系統中的使用者行為提供全面的解釋。透過整合協同信號和設計一個輕量級協同適配器，此架構賦能 LLM 了解使用者與項目互動中的複雜模式，並更深入地了解使用者偏好。我們廣泛的實驗證明了 XRec 的有效性，展示了它產生全面且有意義的解釋的能力，在可解釋推薦系統中優於基準方法。我們在 https://github.com/HKUDS/XRec 開源我們的模型實作。

##### **Retaining Key Information under High Compression Ratios: Query-Guided Compressor for LLMs**
2406.02376v1 by Zhiwei Cao, Qian Cao, Yu Lu, Ningxin Peng, Luyang Huang, Shanbo Cheng, Jinsong Su

The growing popularity of Large Language Models has sparked interest in
context compression for Large Language Models (LLMs). However, the performance
of previous methods degrades dramatically as compression ratios increase,
sometimes even falling to the closed-book level. This decline can be attributed
to the loss of key information during the compression process. Our preliminary
study supports this hypothesis, emphasizing the significance of retaining key
information to maintain model performance under high compression ratios. As a
result, we introduce Query-Guided Compressor (QGC), which leverages queries to
guide the context compression process, effectively preserving key information
within the compressed context. Additionally, we employ a dynamic compression
strategy. We validate the effectiveness of our proposed QGC on the Question
Answering task, including NaturalQuestions, TriviaQA, and HotpotQA datasets.
Experimental results show that QGC can consistently perform well even at high
compression ratios, which also offers significant benefits in terms of
inference cost and throughput.

摘要：大型語言模型日益普及，進而引發了對大型語言模型 (LLM) 的脈絡壓縮產生興趣。然而，隨著壓縮比的增加，先前方法的效能大幅下降，有時甚至降至閉卷考試的程度。這種下降可歸因於在壓縮過程中遺失了關鍵資訊。我們的初步研究支持此假設，強調了保留關鍵資訊以在高壓縮比下維持模型效能的重要性。因此，我們引入了查詢導向壓縮器 (QGC)，它利用查詢來引導脈絡壓縮程序，有效地保留了壓縮脈絡中的關鍵資訊。此外，我們採用了動態壓縮策略。我們在問答任務中驗證了我們提出的 QGC 的有效性，包括 NaturalQuestions、TriviaQA 和 HotpotQA 資料集。實驗結果顯示，即使在高壓縮比下，QGC 仍能持續表現良好，這在推理成本和處理量方面也提供了顯著的優點。

##### **Large Language Models Make Sample-Efficient Recommender Systems**
2406.02368v1 by Jianghao Lin, Xinyi Dai, Rong Shan, Bo Chen, Ruiming Tang, Yong Yu, Weinan Zhang

Large language models (LLMs) have achieved remarkable progress in the field
of natural language processing (NLP), demonstrating remarkable abilities in
producing text that resembles human language for various tasks. This opens up
new opportunities for employing them in recommender systems (RSs). In this
paper, we specifically examine the sample efficiency of LLM-enhanced
recommender systems, which pertains to the model's capacity to attain superior
performance with a limited quantity of training data. Conventional
recommendation models (CRMs) often need a large amount of training data because
of the sparsity of features and interactions. Hence, we propose and verify our
core viewpoint: Large Language Models Make Sample-Efficient Recommender
Systems. We propose a simple yet effective framework (i.e., Laser) to validate
the viewpoint from two aspects: (1) LLMs themselves are sample-efficient
recommenders; and (2) LLMs, as feature generators and encoders, make CRMs more
sample-efficient. Extensive experiments on two public datasets show that Laser
requires only a small fraction of training samples to match or even surpass
CRMs that are trained on the entire training set, demonstrating superior sample
efficiency.

摘要：大型語言模型 (LLM) 在自然語言處理 (NLP) 領域取得了顯著進展，在為各種任務產生類似人類語言的文字方面展現了非凡的能力。這為將它們應用於推薦系統 (RS) 開闢了新的機會。在本文中，我們特別探討了 LLM 增強推薦系統的範例效率，這與模型在有限訓練資料量下獲得卓越效能的能力有關。傳統推薦模型 (CRM) 通常需要大量的訓練資料，因為特徵和互動的稀疏性。因此，我們提出並驗證了我們的核心觀點：大型語言模型讓範例高效的推薦系統成為可能。我們提出了一個簡單但有效的架構 (即 Laser)，從兩個方面驗證觀點：(1) LLM 本身就是範例高效的推薦系統；(2) LLM 作為特徵生成器和編碼器，讓 CRM 變得更範例高效。在兩個公開資料集上的廣泛實驗顯示，Laser 只需要一小部分訓練範例就能與在整個訓練集上訓練的 CRM 相匹配，甚至超越它們，展現出優越的範例效率。

##### **Finding NeMo: Localizing Neurons Responsible For Memorization in Diffusion Models**
2406.02366v1 by Dominik Hintersdorf, Lukas Struppek, Kristian Kersting, Adam Dziedzic, Franziska Boenisch

Diffusion models (DMs) produce very detailed and high-quality images. Their
power results from extensive training on large amounts of data, usually scraped
from the internet without proper attribution or consent from content creators.
Unfortunately, this practice raises privacy and intellectual property concerns,
as DMs can memorize and later reproduce their potentially sensitive or
copyrighted training images at inference time. Prior efforts prevent this issue
by either changing the input to the diffusion process, thereby preventing the
DM from generating memorized samples during inference, or removing the
memorized data from training altogether. While those are viable solutions when
the DM is developed and deployed in a secure and constantly monitored
environment, they hold the risk of adversaries circumventing the safeguards and
are not effective when the DM itself is publicly released. To solve the
problem, we introduce NeMo, the first method to localize memorization of
individual data samples down to the level of neurons in DMs' cross-attention
layers. Through our experiments, we make the intriguing finding that in many
cases, single neurons are responsible for memorizing particular training
samples. By deactivating these memorization neurons, we can avoid the
replication of training data at inference time, increase the diversity in the
generated outputs, and mitigate the leakage of private and copyrighted data. In
this way, our NeMo contributes to a more responsible deployment of DMs.

摘要：擴散模型 (DM) 可產生非常詳細且高品質的影像。其效能源自於大量資料的廣泛訓練，通常未經適當的歸屬或內容創作者的同意，便從網路上擷取。不幸的是，此作法引發了隱私和智慧財產權的疑慮，因為 DM 可以記憶並在推論時重製其潛在敏感或受版權保護的訓練影像。先前的努力透過改變擴散程序的輸入來防止此問題，從而防止 DM 在推論期間產生記憶的樣本，或從訓練中完全移除記憶的資料。儘管這些在 DM 於安全且持續監控的環境中開發和部署時是可行的解決方案，但它們具有對手規避防護措施的風險，且在 DM 本身公開發布時無效。為了解決此問題，我們引入了 NeMo，這是第一個將個別資料樣本的記憶定位到 DM 交叉注意力層中神經元層級的方法。透過我們的實驗，我們得出了有趣的發現，在許多情況下，單一神經元負責記憶特定訓練樣本。透過停用這些記憶神經元，我們可以避免在推論時複製訓練資料，增加產生輸出的多樣性，並減輕私人和受版權保護資料的洩漏。透過這種方式，我們的 NeMo 有助於更負責任地部署 DM。

##### **Temporal Graph Rewiring with Expander Graphs**
2406.02362v2 by Katarina Petrović, Shenyang Huang, Farimah Poursafaei, Petar Veličković

Evolving relations in real-world networks are often modelled by temporal
graphs. Graph rewiring techniques have been utilised on Graph Neural Networks
(GNNs) to improve expressiveness and increase model performance. In this work,
we propose Temporal Graph Rewiring (TGR), the first approach for graph rewiring
on temporal graphs. TGR enables communication between temporally distant nodes
in a continuous time dynamic graph by utilising expander graph propagation to
construct a message passing highway for message passing between distant nodes.
Expander graphs are suitable candidates for rewiring as they help overcome the
oversquashing problem often observed in GNNs. On the public tgbl-wiki
benchmark, we show that TGR improves the performance of a widely used TGN model
by a significant margin. Our code repository is accessible at
https://github.com/kpetrovicc/TGR.git .

摘要：現實世界網路中不斷變化的關係通常會以時間圖形建模。圖形重新連線技術已被用於圖形神經網路 (GNN)，以提高表現力並增加模型效能。在這項工作中，我們提出時間圖形重新連線 (TGR)，這是時間圖形上圖形重新連線的第一種方法。TGR 透過使用擴充圖形傳播來建構訊息傳遞通道，以在連續時間動態圖形中實現時間上相距甚遠的節點間的通訊，以便在相距甚遠的節點間傳遞訊息。擴充圖形是重新連線的合適候選，因為它們有助於克服在 GNN 中常見的過度壓縮問題。在公開的 tgbl-wiki 基準上，我們展示 TGR 以顯著幅度改善了廣泛使用的 TGN 模型的效能。我們的程式碼存放庫可以在 https://github.com/kpetrovicc/TGR.git 存取。

##### **Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy Arithmetic Tasks**
2406.02356v1 by Andrew Gambardella, Yusuke Iwasawa, Yutaka Matsuo

The ability (and inability) of large language models (LLMs) to perform
arithmetic tasks has been the subject of much theoretical and practical debate.
We show that LLMs are frequently able to correctly and confidently predict the
first digit of n-digit by m-digit multiplication tasks without using chain of
thought reasoning, despite these tasks require compounding operations to solve.
Simultaneously, LLMs in practice often fail to correctly or confidently predict
the last digit of an n-digit by m-digit multiplication, a task equivalent to
1-digit by 1-digit multiplication which can be easily learned or memorized. We
show that the latter task can be solved more robustly when the LLM is
conditioned on all of the correct higher-order digits, which on average
increases the confidence of the correct last digit on 5-digit by 5-digit
multiplication tasks using Llama 2-13B by over 230% (0.13 to 0.43) and
Mistral-7B by 150% (0.22 to 0.55).

摘要：大型語言模型（LLM）執行算術任務的能力（和無能）一直是許多理論和實務辯論的主題。我們證明，LLM 通常能夠正確且自信地預測 n 位數乘以 m 位數乘法任務的第一位數字，而無需使用思考鏈推理，儘管這些任務需要複合運算才能解決。同時，LLM 在實務上經常無法正確或自信地預測 n 位數乘以 m 位數乘法的最後一位數字，這項任務等於 1 位數乘以 1 位數的乘法，可以輕鬆學習或記憶。我們證明，當 LLM 以所有正確的高階數字為條件時，可以更穩健地解決後一項任務，這平均會提高使用 Llama 2-13B 的 5 位數乘以 5 位數乘法任務中正確最後一位數字的信心超過 230%（0.13 至 0.43），而 Mistral-7B 則提高 150%（0.22 至 0.55）。

##### **FedDr+: Stabilizing Dot-regression with Global Feature Distillation for Federated Learning**
2406.02355v1 by Seongyoon Kim, Minchan Jeong, Sungnyun Kim, Sungwoo Cho, Sumyeong Ahn, Se-Young Yun

Federated Learning (FL) has emerged as a pivotal framework for the
development of effective global models (global FL) or personalized models
(personalized FL) across clients with heterogeneous, non-iid data distribution.
A key challenge in FL is client drift, where data heterogeneity impedes the
aggregation of scattered knowledge. Recent studies have tackled the client
drift issue by identifying significant divergence in the last classifier layer.
To mitigate this divergence, strategies such as freezing the classifier weights
and aligning the feature extractor accordingly have proven effective. Although
the local alignment between classifier and feature extractor has been studied
as a crucial factor in FL, we observe that it may lead the model to
overemphasize the observed classes within each client. Thus, our objectives are
twofold: (1) enhancing local alignment while (2) preserving the representation
of unseen class samples. This approach aims to effectively integrate knowledge
from individual clients, thereby improving performance for both global and
personalized FL. To achieve this, we introduce a novel algorithm named FedDr+,
which empowers local model alignment using dot-regression loss. FedDr+ freezes
the classifier as a simplex ETF to align the features and improves aggregated
global models by employing a feature distillation mechanism to retain
information about unseen/missing classes. Consequently, we provide empirical
evidence demonstrating that our algorithm surpasses existing methods that use a
frozen classifier to boost alignment across the diverse distribution.

摘要：联邦学习 (FL) 已成为跨客户端开发有效全局模型 (全局 FL) 或个性化模型 (个性化 FL) 的关键框架，这些客户端具有异构、非 iid 数据分布。FL 中的一个关键挑战是客户端漂移，其中数据异质性阻碍了分散知识的聚合。最近的研究通过识别最后一个分类器层中的显着差异来解决客户端漂移问题。为了减轻这种差异，冻结分类器权重和相应地对齐特征提取器等策略已被证明是有效的。虽然分类器和特征提取器之间的局部对齐已被研究为 FL 中的一个关键因素，但我们观察到它可能会导致模型过度强调每个客户端中观察到的类别。因此，我们的目标有两个：(1) 增强局部对齐，同时 (2) 保留未见类样本的表示。这种方法旨在有效整合来自各个客户端的知识，从而提高全局和个性化 FL 的性能。为了实现这一点，我们引入了一种名为 FedDr+ 的新算法，该算法使用点回归损失增强局部模型对齐。FedDr+ 将分类器冻结为一个单纯形 ETF 以对齐特征，并通过采用特征蒸馏机制来保留有关未见/缺失类别的信息，从而改进聚合的全局模型。因此，我们提供了经验证据，证明我们的算法超越了使用冻结分类器来提高不同分布中对齐的现有方法。

##### **LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing**
2406.02350v1 by Maojun Sun

Large language models (LLMs) have shown amazing capabilities in knowledge
memorization and present. However, when it comes to domain-specific knowledge
and downstream tasks like medical, general LLMs are often unable to give
precise answers. In addition, when people want LLMs to answer classification
questions, they usually go through instruction tuning first, however, LLMs do
not always give a direct index of the categorization after instruction tuning.
In this paper, we proposed LlamaCare, a fine-tuned medical language model, and
Extended Classification Integration(ECI), a module to handle classification
problems of LLMs. Our contributions are : (i) We fine-tuned a large language
model of medical knowledge with very low carbon emissions and achieved similar
performance with ChatGPT by a 24G GPU. (ii) We solved the problem of redundant
categorical answers and improved the performance of LLMs by proposing a new
module called Extended Classification Integration. (iii) We released our
processed data for one-shot and few-shot training for some benchmarks such as
PubMedQA and USMLE 1-3 step. Our method achieves a close effect with the
state-of-the-art model in benchmarks while costing lower GPU resources compared
to LLMs with the same quantity of parameters. Our models, codes, and datasets
can be found in https://github.com/Stephen-SMJ/LLamaCare

摘要：大型語言模型 (LLM) 在知識記憶和呈現方面展現出驚人的能力。然而，當涉及到特定領域的知識和下游任務（例如醫療）時，一般的 LLM 通常無法給出精確的答案。此外，當人們希望 LLM 回答分類問題時，他們通常會先進行指令調整，然而，LLM 在指令調整後並不總是給出分類的直接索引。在本文中，我們提出了 LlamaCare，一種微調後的醫學語言模型，以及擴展分類整合 (ECI)，一個處理 LLM 分類問題的模組。我們的貢獻包括：(i) 我們微調了一個具有極低碳排放量的醫學知識大型語言模型，並使用 24G GPU 達到了與 ChatGPT 相似的效能。(ii) 我們解決了冗餘分類答案的問題，並透過提出一個名為擴展分類整合的新模組來改善 LLM 的效能。(iii) 我們釋出了我們處理過的資料，用於 PubMedQA 和 USMLE 1-3 步驟等一些基準的單次和少次訓練。我們的模型在基準中達到了與最先進模型接近的效果，同時與具有相同參數數量的 LLM 相比，成本更低。我們的模型、程式碼和資料集可以在 https://github.com/Stephen-SMJ/LLamaCare 中找到

##### **CADE: Cosine Annealing Differential Evolution for Spiking Neural Network**
2406.02349v1 by Runhua Jiang, Guodong Du, Shuyang Yu, Yifei Guo, Sim Kuan Goh, Ho-Kin Tang

Spiking neural networks (SNNs) have gained prominence for their potential in
neuromorphic computing and energy-efficient artificial intelligence, yet
optimizing them remains a formidable challenge for gradient-based methods due
to their discrete, spike-based computation. This paper attempts to tackle the
challenges by introducing Cosine Annealing Differential Evolution (CADE),
designed to modulate the mutation factor (F) and crossover rate (CR) of
differential evolution (DE) for the SNN model, i.e., Spiking Element Wise (SEW)
ResNet. Extensive empirical evaluations were conducted to analyze CADE. CADE
showed a balance in exploring and exploiting the search space, resulting in
accelerated convergence and improved accuracy compared to existing
gradient-based and DE-based methods. Moreover, an initialization method based
on a transfer learning setting was developed, pretraining on a source dataset
(i.e., CIFAR-10) and fine-tuning the target dataset (i.e., CIFAR-100), to
improve population diversity. It was found to further enhance CADE for SNN.
Remarkably, CADE elevates the performance of the highest accuracy SEW model by
an additional 0.52 percentage points, underscoring its effectiveness in
fine-tuning and enhancing SNNs. These findings emphasize the pivotal role of a
scheduler for F and CR adjustment, especially for DE-based SNN. Source Code on
Github: https://github.com/Tank-Jiang/CADE4SNN.

摘要：<paragraph>脈衝神經網路 (SNN) 因其在神經形態運算和節能人工智能的潛力而備受矚目，但由於其離散的脈衝式運算，對梯度方法而言，最佳化它們仍然是一項艱鉅的挑戰。本文嘗試透過引進餘弦退火差分演化 (CADE) 來應對這些挑戰，CADE 旨在調整差分演化 (DE) 的變異因子 (F) 和交叉率 (CR)，以用於 SNN 模型，即脈衝元素級 (SEW) ResNet。我們進行了廣泛的實證評估以分析 CADE。CADE 在探索和開發搜尋空間方面表現出平衡，與現有的基於梯度和基於 DE 的方法相比，加速了收斂速度並提高了準確度。此外，開發了一種基於遷移學習設定的初始化方法，在源資料集（即 CIFAR-10）上進行預訓練，並微調目標資料集（即 CIFAR-100），以提高族群多樣性。發現這進一步增強了 SNN 的 CADE。值得注意的是，CADE 將最高準確度 SEW 模型的效能提升了額外的 0.52 個百分點，突顯了其在微調和增強 SNN 方面的有效性。這些發現強調了調度器在調整 F 和 CR 中的關鍵作用，特別是對於基於 DE 的 SNN。Github 上的原始碼：https://github.com/Tank-Jiang/CADE4SNN。</paragraph>

##### **Flash Diffusion: Accelerating Any Conditional Diffusion Model for Few Steps Image Generation**
2406.02347v1 by Clement Chadebec, Onur Tasar, Eyal Benaroche, Benjamin Aubin

In this paper, we propose an efficient, fast, and versatile distillation
method to accelerate the generation of pre-trained diffusion models: Flash
Diffusion. The method reaches state-of-the-art performances in terms of FID and
CLIP-Score for few steps image generation on the COCO2014 and COCO2017
datasets, while requiring only several GPU hours of training and fewer
trainable parameters than existing methods. In addition to its efficiency, the
versatility of the method is also exposed across several tasks such as
text-to-image, inpainting, face-swapping, super-resolution and using different
backbones such as UNet-based denoisers (SD1.5, SDXL) or DiT (Pixart-$\alpha$),
as well as adapters. In all cases, the method allowed to reduce drastically the
number of sampling steps while maintaining very high-quality image generation.
The official implementation is available at
https://github.com/gojasper/flash-diffusion.

摘要：在本文中，我们提出了一种高效、快速且通用的蒸馏方法，以加速预训练扩散模型的生成：Flash Diffusion。该方法在 COCO2014 和 COCO2017 数据集上对少步图像生成方面达到了最先进的性能，同时只需要几个 GPU 小时的训练时间和比现有方法更少的可训练参数。除了其效率之外，该方法的多功能性还体现在文本到图像、修复、换脸、超分辨率和使用不同的主干，例如基于 UNet 的去噪器 (SD1.5、SDXL) 或 DiT (Pixart-α) 以及适配器等多项任务中。在所有情况下，该方法都可以大幅减少采样步骤，同时保持非常高质量的图像生成。官方实现可在 https://github.com/gojasper/flash-diffusion 获得。

##### **Linguistic Fingerprint in Transformer Models: How Language Variation Influences Parameter Selection in Irony Detection**
2406.02338v1 by Michele Mastromattei, Fabio Massimo Zanzotto

This paper explores the correlation between linguistic diversity, sentiment
analysis and transformer model architectures. We aim to investigate how
different English variations impact transformer-based models for irony
detection. To conduct our study, we used the EPIC corpus to extract five
diverse English variation-specific datasets and applied the KEN pruning
algorithm on five different architectures. Our results reveal several
similarities between optimal subnetworks, which provide insights into the
linguistic variations that share strong resemblances and those that exhibit
greater dissimilarities. We discovered that optimal subnetworks across models
share at least 60% of their parameters, emphasizing the significance of
parameter values in capturing and interpreting linguistic variations. This
study highlights the inherent structural similarities between models trained on
different variants of the same language and also the critical role of parameter
values in capturing these nuances.

摘要：本文探討語言多樣性、情緒分析和 Transformer 模型架構之間的關聯性。我們的目標是探討不同的英文變體如何影響基於 Transformer 的反諷偵測模型。為了進行研究，我們使用 EPIC 語料庫提取了五個不同的英文變體特定資料集，並在五種不同的架構上應用 KEN 剪枝演算法。我們的結果揭露了最佳子網路之間的幾個相似性，這些相似性提供了對具有強相似性的語言變體和表現出較大差異性的語言變體的見解。我們發現，跨模型的最佳子網路共用至少 60% 的參數，強調了參數值在擷取和詮釋語言變異中的重要性。這項研究突顯了在同種語言的不同變體上訓練的模型之間固有的結構相似性，以及參數值在擷取這些細微差別中的關鍵作用。

##### **Probing the Category of Verbal Aspect in Transformer Language Models**
2406.02335v1 by Anisia Katinskaia, Roman Yangarber

We investigate how pretrained language models (PLM) encode the grammatical
category of verbal aspect in Russian. Encoding of aspect in transformer LMs has
not been studied previously in any language. A particular challenge is posed by
"alternative contexts": where either the perfective or the imperfective aspect
is suitable grammatically and semantically. We perform probing using BERT and
RoBERTa on alternative and non-alternative contexts. First, we assess the
models' performance on aspect prediction, via behavioral probing. Next, we
examine the models' performance when their contextual representations are
substituted with counterfactual representations, via causal probing. These
counterfactuals alter the value of the "boundedness" feature--a semantic
feature, which characterizes the action in the context. Experiments show that
BERT and RoBERTa do encode aspect--mostly in their final layers. The
counterfactual interventions affect perfective and imperfective in opposite
ways, which is consistent with grammar: perfective is positively affected by
adding the meaning of boundedness, and vice versa. The practical implications
of our probing results are that fine-tuning only the last layers of BERT on
predicting aspect is faster and more effective than fine-tuning the whole
model. The model has high predictive uncertainty about aspect in alternative
contexts, which tend to lack explicit hints about the boundedness of the
described action.

摘要：我們探討預訓練語言模型 (PLM) 如何編碼俄語中動詞體的語法範疇。轉換器語言模型中體的編碼以前未在任何語言中研究過。一個特別的挑戰是由「替代語境」提出的：在語法和語義上，完成體或未完成體都是適用的。我們使用 BERT 和 RoBERTa 對替代和非替代語境進行探測。首先，我們透過行為探測評估模型在體預測上的表現。接下來，我們透過因果探測檢查模型在它們的上下文表示被反事實表示取代時的表現。這些反事實改變了「有界性」特徵的值，這是一個語義特徵，它描述了語境中的動作。實驗表明，BERT 和 RoBERTa 確實編碼了體，主要在它們的最後一層。反事實介入以相反的方式影響完成體和未完成體，這與語法一致：完成體因加入有界性的含義而受到正面影響，反之亦然。我們探測結果的實際含義是，只微調 BERT 的最後幾層來預測體比微調整個模型更快、更有效。該模型對替代語境中的體有很高的預測不確定性，而替代語境往往缺乏關於所描述動作有界性的明確提示。

##### **Towards Neural Architecture Search for Transfer Learning in 6G Networks**
2406.02333v1 by Adam Orucu, Farnaz Moradi, Masoumeh Ebrahimi, Andreas Johnsson

The future 6G network is envisioned to be AI-native, and as such, ML models
will be pervasive in support of optimizing performance, reducing energy
consumption, and in coping with increasing complexity and heterogeneity. A key
challenge is automating the process of finding optimal model architectures
satisfying stringent requirements stemming from varying tasks, dynamicity and
available resources in the infrastructure and deployment positions. In this
paper, we describe and review the state-of-the-art in Neural Architecture
Search and Transfer Learning and their applicability in networking. Further, we
identify open research challenges and set directions with a specific focus on
three main requirements with elements unique to the future network, namely
combining NAS and TL, multi-objective search, and tabular data. Finally, we
outline and discuss both near-term and long-term work ahead.

摘要：預計未來的 6G 網路將以 AI 為基礎，因此機器學習模型將普遍用於支援效能最佳化、降低能源消耗，並因應日益增加的複雜性和異質性。一項關鍵挑戰在於自動化尋找最佳模型架構的程序，以滿足來自基礎架構和部署位置中不同任務、動態性和可用資源所產生的嚴格需求。在本文中，我們描述並回顧神經架構搜尋和遷移學習的最新進展，以及它們在網路中的適用性。此外，我們找出開放的研究挑戰，並針對三個主要需求設定方向，其中包含未來網路獨有的元素，即結合 NAS 和 TL、多目標搜尋和表格資料。最後，我們概述並討論近期和長期的工作進程。

##### **Extended Mind Transformers**
2406.02332v1 by Phoebe Klett, Thomas Ahle

Pre-trained language models demonstrate general intelligence and common
sense, but long inputs quickly become a bottleneck for memorizing information
at inference time. We resurface a simple method, Memorizing Transformers (Wu et
al., 2022), that gives the model access to a bank of pre-computed memories. We
show that it is possible to fix many of the shortcomings of the original
method, such as the need for fine-tuning, by critically assessing how
positional encodings should be updated for the keys and values retrieved. This
intuitive method uses the model's own key/query system to select and attend to
the most relevant memories at each generation step, rather than using external
embeddings. We demonstrate the importance of external information being
retrieved in a majority of decoder layers, contrary to previous work. We open
source a new counterfactual long-range retrieval benchmark, and show that
Extended Mind Transformers outperform today's state of the art by 6% on
average.

摘要：預先訓練的語言模型展示了通用智慧和常識，但長輸入在推理時很快就會成為記憶資訊的瓶頸。我們重新浮現一個簡單的方法，記憶Transformer（Wu 等人，2022 年），讓模型可以存取預先計算記憶的資料庫。我們展示可以修正原始方法的許多缺點，例如微調的需要，透過批判性評估如何更新位置編碼以利於檢索的鍵和值。這個直觀的方法使用模型自己的鍵/查詢系統，在每個產生步驟中選擇並關注最相關的記憶，而不是使用外部嵌入。我們展示外部資訊在解碼器層的大多數中被檢索的重要性，這與先前的研究相反。我們公開一個新的反事實長程檢索基準，並展示 Extended Mind Transformers 平均比目前的技術水準高出 6%。

##### **Translation Deserves Better: Analyzing Translation Artifacts in Cross-lingual Visual Question Answering**
2406.02331v1 by ChaeHun Park, Koanho Lee, Hyesu Lim, Jaeseok Kim, Junmo Park, Yu-Jung Heo, Du-Seong Chang, Jaegul Choo

Building a reliable visual question answering~(VQA) system across different
languages is a challenging problem, primarily due to the lack of abundant
samples for training. To address this challenge, recent studies have employed
machine translation systems for the cross-lingual VQA task. This involves
translating the evaluation samples into a source language (usually English) and
using monolingual models (i.e., translate-test). However, our analysis reveals
that translated texts contain unique characteristics distinct from
human-written ones, referred to as translation artifacts. We find that these
artifacts can significantly affect the models, confirmed by extensive
experiments across diverse models, languages, and translation processes. In
light of this, we present a simple data augmentation strategy that can
alleviate the adverse impacts of translation artifacts.

摘要：建立一個可靠的視覺問題解答 (VQA) 系統跨不同語言是一個具有挑戰性的問題，主要是由於缺乏大量的訓練範例。為了應對這個挑戰，最近的研究採用了機器翻譯系統進行跨語言 VQA 任務。這涉及將評估範例翻譯成原始語言（通常是英語）並使用單語模型（即翻譯測試）。然而，我們的分析表明，翻譯後的文本包含不同於人類寫作的獨特特徵，稱為翻譯人工製品。我們發現這些人工製品會對模型產生重大影響，這已通過各種模型、語言和翻譯過程的廣泛實驗得到證實。有鑑於此，我們提出了一個簡單的數據擴充策略，可以減輕翻譯人工製品的不利影響。

##### **On Affine Homotopy between Language Encoders**
2406.02329v1 by Robin SM Chan, Reda Boumasmoud, Anej Svete, Yuxin Ren, Qipeng Guo, Zhijing Jin, Shauli Ravfogel, Mrinmaya Sachan, Bernhard Schölkopf, Mennatallah El-Assady, Ryan Cotterell

Pre-trained language encoders -- functions that represent text as vectors --
are an integral component of many NLP tasks. We tackle a natural question in
language encoder analysis: What does it mean for two encoders to be similar? We
contend that a faithful measure of similarity needs to be \emph{intrinsic},
that is, task-independent, yet still be informative of \emph{extrinsic}
similarity -- the performance on downstream tasks. It is common to consider two
encoders similar if they are \emph{homotopic}, i.e., if they can be aligned
through some transformation. In this spirit, we study the properties of
\emph{affine} alignment of language encoders and its implications on extrinsic
similarity. We find that while affine alignment is fundamentally an asymmetric
notion of similarity, it is still informative of extrinsic similarity. We
confirm this on datasets of natural language representations. Beyond providing
useful bounds on extrinsic similarity, affine intrinsic similarity also allows
us to begin uncovering the structure of the space of pre-trained encoders by
defining an order over them.

摘要：預訓練語言編碼器（將文字表示為向量的函數）是許多自然語言處理任務的組成部分。我們處理語言編碼器分析中的一個自然問題：兩個編碼器相似是什麼意思？我們認為，相似的忠實衡量標準應該是「內在的」，也就是與任務無關，但仍然對「外在」相似性（下游任務的效能）具有資訊性。如果兩個編碼器是「同倫的」，也就是說，如果它們可以透過某種轉換來對齊，通常會認為它們是相似的。本著這種精神，我們研究語言編碼器的「仿射」對齊特性及其對外在相似性的影響。我們發現，儘管仿射對齊基本上是一種不對稱的相似性概念，但它仍然對外在相似性具有資訊性。我們在自然語言表示資料集上確認了這一點。除了提供外在相似性的有用界線外，仿射內在相似性也讓我們能夠透過定義編碼器的順序，開始揭示預訓練編碼器空間的結構。

##### **Technical Language Processing for Telecommunications Specifications**
2406.02325v1 by Felipe A. Rodriguez Y.

Large Language Models (LLMs) are continuously being applied in a more diverse
set of contexts. At their current state, however, even state-of-the-art LLMs
such as Generative Pre-Trained Transformer 4 (GTP-4) have challenges when
extracting information from real-world technical documentation without a heavy
preprocessing. One such area with real-world technical documentation is
telecommunications engineering, which could greatly benefit from
domain-specific LLMs. The unique format and overall structure of
telecommunications internal specifications differs greatly from standard
English and thus it is evident that the application of out-of-the-box Natural
Language Processing (NLP) tools is not a viable option. In this article, we
outline the limitations of out-of-the-box NLP tools for processing technical
information generated by telecommunications experts, and expand the concept of
Technical Language Processing (TLP) to the telecommunication domain.
Additionally, we explore the effect of domain-specific LLMs in the work of
Specification Engineers, emphasizing the potential benefits of adopting
domain-specific LLMs to speed up the training of experts in different
telecommunications fields.

摘要：大型語言模型 (LLM) 持續在更多元化的脈絡中被應用。然而，以其當前狀態來說，即使是像生成式預訓練Transformer 4 (GTP-4) 等最先進的 LLM，在未經大量前處理的情況下，從真實世界的技術文件萃取資訊時仍會遇到挑戰。電信工程便是其中一個擁有真實世界技術文件的領域，而該領域可以從特定領域的 LLM 中獲益良多。電信內部規格的獨特格式和整體結構與標準英語大不相同，因此顯然無法使用現成的自然語言處理 (NLP) 工具。在本文中，我們將概述現成的 NLP 工具在處理電信專家產生的技術資訊時的限制，並將技術語言處理 (TLP) 的概念擴展到電信領域。此外，我們將探討特定領域的 LLM 對規格工程師工作產生的影響，並強調採用特定領域的 LLM 以加速不同電信領域專家培訓的潛在好處。

##### **A Survey of Transformer Enabled Time Series Synthesis**
2406.02322v1 by Alexander Sommers, Logan Cummins, Sudip Mittal, Shahram Rahimi, Maria Seale, Joseph Jaboure, Thomas Arnold

Generative AI has received much attention in the image and language domains,
with the transformer neural network continuing to dominate the state of the
art. Application of these models to time series generation is less explored,
however, and is of great utility to machine learning, privacy preservation, and
explainability research. The present survey identifies this gap at the
intersection of the transformer, generative AI, and time series data, and
reviews works in this sparsely populated subdomain. The reviewed works show
great variety in approach, and have not yet converged on a conclusive answer to
the problems the domain poses. GANs, diffusion models, state space models, and
autoencoders were all encountered alongside or surrounding the transformers
which originally motivated the survey. While too open a domain to offer
conclusive insights, the works surveyed are quite suggestive, and several
recommendations for best practice, and suggestions of valuable future work, are
provided.

摘要：生成式 AI 在影像和語言領域備受關注，
而 Transformer 神經網路持續主導著技術水準。
然而，將這些模型應用於時序生成較少被探討，
且對機器學習、隱私保護和可解釋性研究有很大的用處。
本調查發現了 Transformer、生成式 AI 和時序資料交會的這項差距，
並回顧了這個人煙稀少的子領域中的作品。
所回顧的作品在方法上展現出極大的多樣性，
尚未對領域提出的問題達成確定的答案。
生成對抗網路、擴散模型、狀態空間模型，
以及自動編碼器在最初激勵這項調查的 Transformer 旁邊或周圍被遇到。
雖然這是一個太開放的領域，無法提供確定的見解，
但所調查的作品相當具有啟發性，
並提供了許多最佳實務建議和有價值的未來工作建議。

##### **Generative Conditional Distributions by Neural (Entropic) Optimal Transport**
2406.02317v1 by Bao Nguyen, Binh Nguyen, Hieu Trung Nguyen, Viet Anh Nguyen

Learning conditional distributions is challenging because the desired outcome
is not a single distribution but multiple distributions that correspond to
multiple instances of the covariates. We introduce a novel neural entropic
optimal transport method designed to effectively learn generative models of
conditional distributions, particularly in scenarios characterized by limited
sample sizes. Our method relies on the minimax training of two neural networks:
a generative network parametrizing the inverse cumulative distribution
functions of the conditional distributions and another network parametrizing
the conditional Kantorovich potential. To prevent overfitting, we regularize
the objective function by penalizing the Lipschitz constant of the network
output. Our experiments on real-world datasets show the effectiveness of our
algorithm compared to state-of-the-art conditional distribution learning
techniques. Our implementation can be found at
https://github.com/nguyenngocbaocmt02/GENTLE.

摘要：學習條件分佈具有挑戰性，因為預期的結果不是單一分佈，而是對應於協變量多個實例的多個分佈。我們引入一種新穎的神經熵最優傳輸方法，旨在有效學習條件分佈的生成模型，特別是在樣本量有限的情況下。我們的方法依賴於兩個神經網路的 minimax 訓練：一個生成網路將條件分佈的逆累積分佈函數參數化，另一個網路將條件 Kantorovich 勢能參數化。為了防止過度擬合，我們通過懲罰網路輸出的 Lipschitz 常數來規範目標函數。我們在真實世界資料集上的實驗表明，與最先進的條件分佈學習技術相比，我們的演算法具有有效性。我們的實作可以在 https://github.com/nguyenngocbaocmt02/GENTLE 中找到。

##### **An Independence-promoting Loss for Music Generation with Language Models**
2406.02315v1 by Jean-Marie Lemercier, Simon Rouard, Jade Copet, Yossi Adi, Alexandre Déffosez

Music generation schemes using language modeling rely on a vocabulary of
audio tokens, generally provided as codes in a discrete latent space learnt by
an auto-encoder. Multi-stage quantizers are often employed to produce these
tokens, therefore the decoding strategy used for token prediction must be
adapted to account for multiple codebooks: either it should model the joint
distribution over all codebooks, or fit the product of the codebook marginal
distributions. Modelling the joint distribution requires a costly increase in
the number of auto-regressive steps, while fitting the product of the marginals
yields an inexact model unless the codebooks are mutually independent. In this
work, we introduce an independence-promoting loss to regularize the
auto-encoder used as the tokenizer in language models for music generation. The
proposed loss is a proxy for mutual information based on the maximum mean
discrepancy principle, applied in reproducible kernel Hilbert spaces. Our
criterion is simple to implement and train, and it is generalizable to other
multi-stream codecs. We show that it reduces the statistical dependence between
codebooks during auto-encoding. This leads to an increase in the generated
music quality when modelling the product of the marginal distributions, while
generating audio much faster than the joint distribution model.

摘要：利用語言模型的音樂生成方案仰賴音訊代碼的詞彙，通常以自動編碼器學習到的離散潛在空間中的代碼提供。多階段量化器通常用於產生這些代碼，因此用於代碼預測的解碼策略必須調整為考量多個代碼簿：它應該對所有代碼簿上的聯合分佈建模，或符合代碼簿邊際分佈的乘積。對聯合分佈建模需要大幅增加自迴歸步驟的數量，而對邊際分佈的乘積進行擬合會產生不精確的模型，除非代碼簿相互獨立。在這項工作中，我們引進了一個促進獨立性的損失，以規範用於音樂生成語言模型中作為分詞器的自動編碼器。所提出的損失是基於最大平均差異原理的互信息的代理，應用於可複製核希爾伯特空間。我們的準則易於實作和訓練，並且可以推廣到其他多串流編解碼器。我們證明它會在自動編碼期間減少代碼簿之間的統計依賴性。這會在對邊際分佈的乘積建模時增加生成的音樂品質，同時比聯合分佈模型更快地產生音訊。

##### **mCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models**
2406.02301v1 by Huiyuan Lai, Malvina Nissim

Large language models (LLMs) with Chain-of-thought (CoT) have recently
emerged as a powerful technique for eliciting reasoning to improve various
downstream tasks. As most research mainly focuses on English, with few
explorations in a multilingual context, the question of how reliable this
reasoning capability is in different languages is still open. To address it
directly, we study multilingual reasoning consistency across multiple
languages, using popular open-source LLMs. First, we compile the first
large-scale multilingual math reasoning dataset, mCoT-MATH, covering eleven
diverse languages. Then, we introduce multilingual CoT instruction tuning to
boost reasoning capability across languages, thereby improving model
consistency. While existing LLMs show substantial variation across the
languages we consider, and especially low performance for lesser resourced
languages, our 7B parameter model mCoT achieves impressive consistency across
languages, and superior or comparable performance to close- and open-source
models even of much larger sizes.

摘要：大型語言模型 (LLM) 搭配思考鏈 (CoT) 最近已成為引發推理以改善各種下游任務的強大技術。由於大多數研究主要集中在英語，且在多語言環境中探索較少，因此在不同語言中這種推理能力的可靠性問題仍未解決。為了直接解決此問題，我們使用流行的開放原始碼 LLM 研究多語言推理一致性。首先，我們編譯第一個大型多語言數學推理資料集 mCoT-MATH，涵蓋 11 種不同的語言。然後，我們引入多語言 CoT 指令調整，以提升跨語言的推理能力，進而改善模型一致性。雖然現有的 LLM 在我們考慮的語言中顯示出顯著的差異，並且資源較少的語言表現特別低落，但我們的 7B 參數模型 mCoT 在不同語言中達到了令人印象深刻的一致性，並且表現優於或等於甚至大得多的閉源和開放原始碼模型。

##### **Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation**
2406.02267v1 by Nathaniel Berger, Stefan Riezler, Miriam Exel, Matthias Huck

While large language models (LLMs) pre-trained on massive amounts of unpaired
language data have reached the state-of-the-art in machine translation (MT) of
general domain texts, post-editing (PE) is still required to correct errors and
to enhance term translation quality in specialized domains. In this paper we
present a pilot study of enhancing translation memories (TM) produced by PE
(source segments, machine translations, and reference translations, henceforth
called PE-TM) for the needs of correct and consistent term translation in
technical domains.
  We investigate a light-weight two-step scenario where, at inference time, a
human translator marks errors in the first translation step, and in a second
step a few similar examples are extracted from the PE-TM to prompt an LLM. Our
experiment shows that the additional effort of augmenting translations with
human error markings guides the LLM to focus on a correction of the marked
errors, yielding consistent improvements over automatic PE (APE) and MT from
scratch.

摘要：儘管預先在大量未配對語言資料上訓練的大型語言模型 (LLM) 已在一般領域文字的機器翻譯 (MT) 中達到最先進的境界，但仍需要後編輯 (PE) 來修正錯誤並提升特定領域的術語翻譯品質。在本文中，我們提出一個試驗研究，以提升後編輯產生的翻譯記憶體 (TM)（原始區塊、機器翻譯和參考翻譯，以下簡稱 PE-TM），以滿足技術領域正確且一致的術語翻譯需求。

我們研究一個輕量級的兩步驟場景，在推論時間時，人類翻譯者會在第一個翻譯步驟中標記錯誤，並在第二個步驟中從 PE-TM 中提取一些類似的範例，以提示 LLM。我們的實驗顯示，透過人類錯誤標記來擴充翻譯的額外工作，引導 LLM 專注於修正標記的錯誤，產生比自動後編輯 (APE) 和從頭開始的 MT 更一致的進步。

##### **Enhancing Retrieval-Augmented LMs with a Two-stage Consistency Learning Compressor**
2406.02266v1 by Chuankai Xu, Dongming Zhao, Bo Wang, Hanwen Xing

Despite the prevalence of retrieval-augmented language models (RALMs), the
seamless integration of these models with retrieval mechanisms to enhance
performance in document-based tasks remains challenging. While some
post-retrieval processing Retrieval-Augmented Generation (RAG) methods have
achieved success, most still lack the ability to distinguish pertinent from
extraneous information, leading to potential inconsistencies and reduced
precision in the generated output, which subsequently affects the truthfulness
of the language model's responses. To address these limitations, this work
proposes a novel two-stage consistency learning approach for retrieved
information compression in retrieval-augmented language models to enhance
performance. By incorporating consistency learning, the aim is to generate
summaries that maintain coherence and alignment with the intended semantic
representations of a teacher model while improving faithfulness to the original
retrieved documents. The proposed method is empirically validated across
multiple datasets, demonstrating notable enhancements in precision and
efficiency for question-answering tasks. It outperforms existing baselines and
showcases the synergistic effects of combining contrastive and consistency
learning paradigms within the retrieval-augmented generation framework.

摘要：儘管檢索增強語言模型 (RALM) 盛行，這些模型與檢索機制的無縫整合以提升基於文件的任務表現仍具有挑戰性。雖然一些檢索後處理檢索增強生成 (RAG) 方法已獲致成功，但大多數仍缺乏區分相關資訊和無關資訊的能力，導致產生的輸出潛在不一致且精確度降低，進而影響語言模型回應的真實性。為了解決這些限制，這項工作提出了一種新穎的兩階段一致性學習方法，用於檢索增強語言模型中檢索資訊的壓縮，以提升表現。透過整合一致性學習，目標是產生摘要，同時維持與教師模型的預期語意表徵相符且一致，並提高對原始檢索文件的忠實度。提議的方法已透過多個資料集進行實證驗證，證明在問答任務中精確度和效率都有顯著提升。它優於現有的基準，並展示了在檢索增強生成架構中結合對比和一致性學習範例的綜效。

##### **Understanding Retrieval Robustness for Retrieval-Augmented Image Captioning**
2406.02265v1 by Wenyan Li, Jiaang Li, Rita Ramos, Raphael Tang, Desmond Elliott

Recent advancements in retrieval-augmented models for image captioning
highlight the significance of retrieving related captions for efficient,
lightweight models with strong domain-transfer capabilities. While these models
demonstrate the success of retrieval augmentation, retrieval models are still
far from perfect in practice. Retrieved information can sometimes mislead the
model generation, negatively impacting performance. In this paper, we analyze
the robustness of the SmallCap retrieval-augmented captioning model. Our
analysis shows that SmallCap is sensitive to tokens that appear in the majority
of the retrieved captions, and integrated gradients attribution shows that
those tokens are likely copied into the final caption. Given these findings, we
propose to train the model by sampling retrieved captions from more diverse
sets. This reduces the probability that the model learns to copy majority
tokens and improves both in-domain and cross-domain performance effectively.

摘要：近来，图像标注检索增强模型的进步，突显了检索相关标注对于具备强大领域转移能力的高效轻量级模型的重要性。虽然这些模型展示了检索增强取得的成功，但检索模型在实践中仍然远非完美。检索到的信息有时会误导模型生成，对性能产生负面影响。在本文中，我们分析了 SmallCap 检索增强标注模型的稳健性。我们的分析表明，SmallCap 对出现在大多数检索标注中的标记敏感，并且集成梯度归因表明这些标记很可能被复制到最终标注中。鉴于这些发现，我们建议通过从更多样化的集合中对检索标注进行采样来训练模型。这降低了模型学习复制大多数标记的可能性，并有效地改善了域内和跨域性能。

##### **PuFace: Defending against Facial Cloaking Attacks for Facial Recognition Models**
2406.02253v1 by Jing Wen

The recently proposed facial cloaking attacks add invisible perturbation
(cloaks) to facial images to protect users from being recognized by
unauthorized facial recognition models. However, we show that the "cloaks" are
not robust enough and can be removed from images.
  This paper introduces PuFace, an image purification system leveraging the
generalization ability of neural networks to diminish the impact of cloaks by
pushing the cloaked images towards the manifold of natural (uncloaked) images
before the training process of facial recognition models. Specifically, we
devise a purifier that takes all the training images including both cloaked and
natural images as input and generates the purified facial images close to the
manifold where natural images lie. To meet the defense goal, we propose to
train the purifier on particularly amplified cloaked images with a loss
function that combines image loss and feature loss. Our empirical experiment
shows PuFace can effectively defend against two state-of-the-art facial
cloaking attacks and reduces the attack success rate from 69.84\% to 7.61\% on
average without degrading the normal accuracy for various facial recognition
models. Moreover, PuFace is a model-agnostic defense mechanism that can be
applied to any facial recognition model without modifying the model structure.

摘要：最近提出的面部隱形攻擊會在面部影像中加入不可見的擾動（隱形斗篷），以保護使用者不被未經授權的面部辨識模型辨識出來。然而，我們證明「隱形斗篷」不夠強大，而且可以從影像中移除。
這篇論文介紹了 PuFace，這是一個影像淨化系統，它利用神經網路的泛化能力，在面部辨識模型的訓練處理前，將隱形斗篷的影像推向自然（未隱形）影像的多樣體，以減輕隱形斗篷的影響。具體來說，我們設計了一個淨化器，它將所有訓練影像（包括隱形斗篷和自然影像）作為輸入，並產生接近自然影像所在多樣體的淨化面部影像。為了達到防禦目標，我們建議在特別放大的隱形斗篷影像上訓練淨化器，並使用結合了影像損失和特徵損失的損失函數。我們的實證實驗顯示，PuFace 可以有效防禦兩種最先進的面部隱形攻擊，並且將攻擊成功率從 69.84% 降低到 7.61%，平均而言，不會降低各種面部辨識模型的正常準確度。此外，PuFace 是一種與模型無關的防禦機制，可以在不修改模型結構的情況下應用於任何面部辨識模型。

##### **Modeling Emotional Trajectories in Written Stories Utilizing Transformers and Weakly-Supervised Learning**
2406.02251v1 by Lukas Christ, Shahin Amiriparian, Manuel Milling, Ilhan Aslan, Björn W. Schuller

Telling stories is an integral part of human communication which can evoke
emotions and influence the affective states of the audience. Automatically
modeling emotional trajectories in stories has thus attracted considerable
scholarly interest. However, as most existing works have been limited to
unsupervised dictionary-based approaches, there is no benchmark for this task.
We address this gap by introducing continuous valence and arousal labels for an
existing dataset of children's stories originally annotated with discrete
emotion categories. We collect additional annotations for this data and map the
categorical labels to the continuous valence and arousal space. For predicting
the thus obtained emotionality signals, we fine-tune a DeBERTa model and
improve upon this baseline via a weakly supervised learning approach. The best
configuration achieves a Concordance Correlation Coefficient (CCC) of $.8221$
for valence and $.7125$ for arousal on the test set, demonstrating the efficacy
of our proposed approach. A detailed analysis shows the extent to which the
results vary depending on factors such as the author, the individual story, or
the section within the story. In addition, we uncover the weaknesses of our
approach by investigating examples that prove to be difficult to predict.

摘要：講故事是人類溝通中不可或缺的一部分，它能喚起
情緒並影響聽眾的情感狀態。自動
對故事中的情緒軌跡建模因此吸引了相當大的
學術興趣。然而，由於大多數現有作品僅限於
無監督的基於字典的方法，因此沒有此任務的基準。
我們通過為原本註解有離散
情緒類別的兒童故事現有資料集引入連續的效價和喚醒標籤來解決這個差距。我們為此資料收集額外的註解，並將
分類標籤對應到連續的效價和喚醒空間。為了預測
由此獲得的情緒信號，我們微調一個 DeBERTa 模型，並
透過一個弱監督學習方法改進這個基線。最佳
組態在測試集上達到效價的協同相關係數 (CCC) 為 $.8221$
和喚醒的 $.7125$，證明了我們提出的方法的效力。詳細的分析顯示了
結果在多大程度上會根據作者、個別故事或
故事中的章節等因素而有所不同。此外，我們透過調查證明難以預測的範例來揭露我們
方法的弱點。

##### **Description Boosting for Zero-Shot Entity and Relation Classification**
2406.02245v1 by Gabriele Picco, Leopold Fuchs, Marcos Martínez Galindo, Alberto Purpura, Vanessa López, Hoang Thanh Lam

Zero-shot entity and relation classification models leverage available
external information of unseen classes -- e.g., textual descriptions -- to
annotate input text data. Thanks to the minimum data requirement, Zero-Shot
Learning (ZSL) methods have high value in practice, especially in applications
where labeled data is scarce. Even though recent research in ZSL has
demonstrated significant results, our analysis reveals that those methods are
sensitive to provided textual descriptions of entities (or relations). Even a
minor modification of descriptions can lead to a change in the decision
boundary between entity (or relation) classes. In this paper, we formally
define the problem of identifying effective descriptions for zero shot
inference. We propose a strategy for generating variations of an initial
description, a heuristic for ranking them and an ensemble method capable of
boosting the predictions of zero-shot models through description enhancement.
Empirical results on four different entity and relation classification datasets
show that our proposed method outperform existing approaches and achieve new
SOTA results on these datasets under the ZSL settings. The source code of the
proposed solutions and the evaluation framework are open-sourced.

摘要：零次學習實體和關係分類模型利用未見類別的可用外部資訊（例如文字描述）來註解輸入文字資料。由於資料需求最小，零次學習 (ZSL) 方法在實務上具有很高的價值，特別是在標籤資料稀少的應用程式中。儘管最近在 ZSL 的研究已展示出顯著的成果，但我們的分析顯示，這些方法對於實體（或關係）的文字描述很敏感。即使是描述的微小修改，也可能導致實體（或關係）類別之間的決策邊界發生變化。在本文中，我們正式定義了識別有效描述以進行零次推論的問題。我們提出了一種策略，用於產生初始描述的變異、一種用於對其進行排序的啟發法，以及一種能夠透過描述增強來提升零次學習模型預測的整體方法。在四個不同的實體和關係分類資料集上的實證結果顯示，我們提出的方法優於現有方法，並在 ZSL 設定下針對這些資料集達到了新的 SOTA 結果。所提出的解決方案的原始程式碼和評估架構是開源的。

##### **Self-Modifying State Modeling for Simultaneous Machine Translation**
2406.02237v1 by Donglei Yu, Xiaomian Kang, Yuchen Liu, Yu Zhou, Chengqing Zong

Simultaneous Machine Translation (SiMT) generates target outputs while
receiving stream source inputs and requires a read/write policy to decide
whether to wait for the next source token or generate a new target token, whose
decisions form a \textit{decision path}. Existing SiMT methods, which learn the
policy by exploring various decision paths in training, face inherent
limitations. These methods not only fail to precisely optimize the policy due
to the inability to accurately assess the individual impact of each decision on
SiMT performance, but also cannot sufficiently explore all potential paths
because of their vast number. Besides, building decision paths requires
unidirectional encoders to simulate streaming source inputs, which impairs the
translation quality of SiMT models. To solve these issues, we propose
\textbf{S}elf-\textbf{M}odifying \textbf{S}tate \textbf{M}odeling (SM$^2$), a
novel training paradigm for SiMT task. Without building decision paths, SM$^2$
individually optimizes decisions at each state during training. To precisely
optimize the policy, SM$^2$ introduces Self-Modifying process to independently
assess and adjust decisions at each state. For sufficient exploration, SM$^2$
proposes Prefix Sampling to efficiently traverse all potential states.
Moreover, SM$^2$ ensures compatibility with bidirectional encoders, thus
achieving higher translation quality. Experiments show that SM$^2$ outperforms
strong baselines. Furthermore, SM$^2$ allows offline machine translation models
to acquire SiMT ability with fine-tuning.

摘要：<paragraph>同步机器翻译 (SiMT) 在接收串流源输入的同时产生目标输出，并且需要一个读/写策略来决定是否等待下一个源标记或生成一个新的目标标记，这些决定形成一个“决策路径”。现有的 SiMT 方法通过在训练中探索各种决策路径来学习策略，面临固有的局限性。这些方法不仅由于无法准确评估每个决策对 SiMT 性能的个别影响而无法精确优化策略，而且还无法充分探索所有潜在路径，因为这些路径的数量庞大。此外，构建决策路径需要单向编码器来模拟流媒体源输入，这会损害 SiMT 模型的翻译质量。为了解决这些问题，我们提出了自修改状态建模 (SM^2)，一种用于 SiMT 任务的新型训练范例。在不构建决策路径的情况下，SM^2 在训练期间独立优化每个状态的决策。为了精确优化策略，SM^2 引入了自修改过程，以独立评估和调整每个状态的决策。为了充分探索，SM^2 提出前缀采样以有效遍历所有潜在状态。此外，SM^2 确保与双向编码器的兼容性，从而实现更高的翻译质量。实验表明，SM^2 优于强大的基线。此外，SM^2 允许离线机器翻译模型通过微调获得 SiMT 能力。</paragraph>

##### **On the Limitations of Fractal Dimension as a Measure of Generalization**
2406.02234v1 by Charlie Tan, Inés García-Redondo, Qiquan Wang, Michael M. Bronstein, Anthea Monod

Bounding and predicting the generalization gap of overparameterized neural
networks remains a central open problem in theoretical machine learning. Neural
network optimization trajectories have been proposed to possess fractal
structure, leading to bounds and generalization measures based on notions of
fractal dimension on these trajectories. Prominently, both the Hausdorff
dimension and the persistent homology dimension have been proposed to correlate
with generalization gap, thus serving as a measure of generalization. This work
performs an extended evaluation of these topological generalization measures.
We demonstrate that fractal dimension fails to predict generalization of models
trained from poor initializations. We further identify that the $\ell^2$ norm
of the final parameter iterate, one of the simplest complexity measures in
learning theory, correlates more strongly with the generalization gap than
these notions of fractal dimension. Finally, our study reveals the intriguing
manifestation of model-wise double descent in persistent homology-based
generalization measures. This work lays the ground for a deeper investigation
of the causal relationships between fractal geometry, topological data
analysis, and neural network optimization.

摘要：限制和预测过度参数化神经网络的泛化差距仍然是理论机器学习中的一个核心开放问题。神经网络优化轨迹已被提出具有分形结构，从而导致基于这些轨迹上的分形维数概念的界限和泛化度量。显着地，豪斯多夫维数和持久同调维数都被提议与泛化差距相关，因此作为泛化度量。这项工作对这些拓扑泛化度量进行了扩展评估。我们证明分形维数无法预测从较差的初始化训练的模型的泛化。我们进一步识别出最终参数迭代的 $\ell^2$ 范数，这是学习理论中最简单的复杂度度量之一，与泛化差距的相关性比这些分形维数的概念更强。最后，我们的研究揭示了基于持久同调的泛化度量中模型级双重下降的有趣表现。这项工作为深入研究分形几何、拓扑数据分析和神经网络优化之间的因果关系奠定了基础。

##### **FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models**
2406.02224v1 by Tao Fan, Guoqiang Ma, Yan Kang, Hanlin Gu, Lixin Fan, Qiang Yang

Recent research in federated large language models (LLMs) has primarily
focused on enabling clients to fine-tune their locally deployed homogeneous
LLMs collaboratively or on transferring knowledge from server-based LLMs to
small language models (SLMs) at downstream clients. However, a significant gap
remains in the simultaneous mutual enhancement of both the server's LLM and
clients' SLMs. To bridge this gap, we propose FedMKT, a parameter-efficient
federated mutual knowledge transfer framework for large and small language
models. This framework is designed to adaptively transfer knowledge from the
server's LLM to clients' SLMs while concurrently enriching the LLM with
clients' unique domain insights. We facilitate token alignment using minimum
edit distance (MinED) and then selective mutual knowledge transfer between
client-side SLMs and a server-side LLM, aiming to collectively enhance their
performance. Through extensive experiments across three distinct scenarios,
heterogeneous, homogeneous, and one-to-one, we evaluate the effectiveness of
FedMKT using various public LLMs and SLMs on a range of NLP text generation
tasks. Empirical results demonstrate significant performance improvements in
clients' SLMs with the aid of the LLM. Furthermore, the LLM optimized by FedMKT
achieves a performance comparable to that achieved through direct fine-tuning
based on clients' data, highlighting the effectiveness and adaptability of
FedMKT.

摘要：近期在联邦大型语言模型 (LLM) 的研究主要专注于让客户端协作微调其本地部署的同质 LLM，或将基于服务器的 LLM 的知识转移到下游客户端的小语言模型 (SLM)。然而，在服务器的 LLM 和客户端的 SLM 的同时相互增强方面仍然存在显著差距。为了弥合这一差距，我们提出了 FedMKT，一个针对大型和小型语言模型的参数高效联邦互知识迁移框架。此框架旨在自适应地将知识从服务器的 LLM 转移到客户端的 SLM，同时用客户端独特的领域见解丰富 LLM。我们利用最小编辑距离 (MinED) 来促进标记对齐，然后在客户端 SLM 和服务器端 LLM 之间进行选择性互知识迁移，旨在共同增强其性能。通过在三个不同的场景（异构、同构和一对一）中进行广泛的实验，我们使用各种公共 LLM 和 SLM 评估了 FedMKT 在一系列 NLP 文本生成任务中的有效性。实证结果表明，在 LLM 的帮助下，客户端的 SLM 性能有了显著提升。此外，通过 FedMKT 优化的 LLM 实现的性能与基于客户端数据进行直接微调所实现的性能相当，突出了 FedMKT 的有效性和适应性。

##### **Why Only Text: Empowering Vision-and-Language Navigation with Multi-modal Prompts**
2406.02208v1 by Haodong Hong, Sen Wang, Zi Huang, Qi Wu, Jiajun Liu

Current Vision-and-Language Navigation (VLN) tasks mainly employ textual
instructions to guide agents. However, being inherently abstract, the same
textual instruction can be associated with different visual signals, causing
severe ambiguity and limiting the transfer of prior knowledge in the vision
domain from the user to the agent. To fill this gap, we propose
Vision-and-Language Navigation with Multi-modal Prompts (VLN-MP), a novel task
augmenting traditional VLN by integrating both natural language and images in
instructions. VLN-MP not only maintains backward compatibility by effectively
handling text-only prompts but also consistently shows advantages with
different quantities and relevance of visual prompts. Possible forms of visual
prompts include both exact and similar object images, providing adaptability
and versatility in diverse navigation scenarios. To evaluate VLN-MP under a
unified framework, we implement a new benchmark that offers: (1) a
training-free pipeline to transform textual instructions into multi-modal forms
with landmark images; (2) diverse datasets with multi-modal instructions for
different downstream tasks; (3) a novel module designed to process various
image prompts for seamless integration with state-of-the-art VLN models.
Extensive experiments on four VLN benchmarks (R2R, RxR, REVERIE, CVDN) show
that incorporating visual prompts significantly boosts navigation performance.
While maintaining efficiency with text-only prompts, VLN-MP enables agents to
navigate in the pre-explore setting and outperform text-based models, showing
its broader applicability.

摘要：目前的視覺語言導航 (VLN) 任務主要使用文字指令來引導代理。然而，由於文字指令本身具有抽象性，相同的文字指令可能會與不同的視覺訊號產生關聯，導致嚴重的歧義，並限制了使用者將先前的視覺領域知識傳遞給代理的可能性。為了填補這個空白，我們提出了多模態提示視覺語言導航 (VLN-MP)，這是一個透過在指令中整合自然語言和影像的新任務，來擴充傳統的 VLN。VLN-MP 不僅透過有效處理純文字提示，維持了向後相容性，而且在不同數量的視覺提示和相關性方面也持續展現優勢。視覺提示的可能形式包括確切和類似的物件影像，在不同的導航場景中提供了適應性和多功能性。為了在統一架構下評估 VLN-MP，我們實作了一個新的基準，提供：(1) 將文字指令轉換成包含地標影像的多模態形式的無訓練管道；(2) 針對不同下游任務的多模態指令的多元資料集；(3) 一個新穎的模組，用於處理各種影像提示，以與最先進的 VLN 模型無縫整合。在四個 VLN 基準 (R2R、RxR、REVERIE、CVDN) 上進行的廣泛實驗顯示，加入視覺提示顯著提升了導航效能。VLN-MP 在維持純文字提示的效率的同時，讓代理能夠在預先探索的設定中導航，並優於基於文字的模型，展示了其更廣泛的適用性。

##### **The Deep Latent Space Particle Filter for Real-Time Data Assimilation with Uncertainty Quantification**
2406.02204v1 by Nikolaj T. Mücke, Sander M. Bohté, Cornelis W. Oosterlee

In Data Assimilation, observations are fused with simulations to obtain an
accurate estimate of the state and parameters for a given physical system.
Combining data with a model, however, while accurately estimating uncertainty,
is computationally expensive and infeasible to run in real-time for complex
systems. Here, we present a novel particle filter methodology, the Deep Latent
Space Particle filter or D-LSPF, that uses neural network-based surrogate
models to overcome this computational challenge. The D-LSPF enables filtering
in the low-dimensional latent space obtained using Wasserstein AEs with
modified vision transformer layers for dimensionality reduction and
transformers for parameterized latent space time stepping. As we demonstrate on
three test cases, including leak localization in multi-phase pipe flow and
seabed identification for fully nonlinear water waves, the D-LSPF runs orders
of magnitude faster than a high-fidelity particle filter and 3-5 times faster
than alternative methods while being up to an order of magnitude more accurate.
The D-LSPF thus enables real-time data assimilation with uncertainty
quantification for physical systems.

摘要：在資料同化中，觀測值與模擬值融合以獲得給定物理系統的狀態和參數的準確估計。然而，將資料與模型結合，同時準確估計不確定性，在計算上是昂貴的，而且無法在複雜系統中即時執行。在這裡，我們提出了一種新穎的粒子濾波方法，即深度潛在空間粒子濾波器或 D-LSPF，它使用基於神經網路的代理模型來克服這個計算挑戰。D-LSPF 能夠在使用 Wasserstein 自動編碼器獲得的低維潛在空間中進行濾波，並使用修改的視覺轉換器層進行降維和轉換器進行參數化潛在空間時間步進。正如我們在三個測試案例中所展示的那樣，包括多相管流中的洩漏定位和完全非線性水波的海床識別，D-LSPF 的執行速度比高保真粒子濾波器快幾個數量級，比替代方法快 3-5 倍，同時準確度提高了一個數量級。因此，D-LSPF 能夠對物理系統進行即時資料同化，並量化不確定性。

##### **Can CLIP help CLIP in learning 3D?**
2406.02202v1 by Cristian Sbrolli, Matteo Matteucci

In this study, we explore an alternative approach to enhance contrastive
text-image-3D alignment in the absence of textual descriptions for 3D objects.
We introduce two unsupervised methods, $I2I$ and $(I2L)^2$, which leverage CLIP
knowledge about textual and 2D data to compute the neural perceived similarity
between two 3D samples. We employ the proposed methods to mine 3D hard
negatives, establishing a multimodal contrastive pipeline with hard negative
weighting via a custom loss function. We train on different configurations of
the proposed hard negative mining approach, and we evaluate the accuracy of our
models in 3D classification and on the cross-modal retrieval benchmark, testing
image-to-shape and shape-to-image retrieval. Results demonstrate that our
approach, even without explicit text alignment, achieves comparable or superior
performance on zero-shot and standard 3D classification, while significantly
improving both image-to-shape and shape-to-image retrieval compared to previous
methods.

摘要：在本研究中，我们探索了一種替代方法，以在沒有 3D 物體的文字描述的情況下增強對比文本-圖像-3D 對齊。我們介紹了兩種無監督方法，$I2I$ 和 $(I2L)^2$，它們利用 CLIP 關於文本和 2D 數據的知識來計算兩個 3D 樣本之間的神經感知相似性。我們採用所提出的方法來挖掘 3D 硬負例，通過自定義損失函數建立具有硬負例加權的多模態對比管道。我們針對所提出的硬負例挖掘方法的不同配置進行訓練，並在 3D 分類和跨模態檢索基準上評估我們模型的準確性，測試圖像到形狀和形狀到圖像檢索。結果表明，我們的模型即使沒有明確的文本對齊，也能在零次學習和標準 3D 分類上實現相當或更優的性能，同時與之前的模型相比，顯著改進了圖像到形狀和形狀到圖像檢索。

##### **On The Statistical Representation Properties Of The Perturb-Softmax And The Perturb-Argmax Probability Distributions**
2406.02180v1 by Hedda Cohen Indelman, Tamir Hazan

The Gumbel-Softmax probability distribution allows learning discrete tokens
in generative learning, while the Gumbel-Argmax probability distribution is
useful in learning discrete structures in discriminative learning. Despite the
efforts invested in optimizing these probability models, their statistical
properties are under-explored. In this work, we investigate their
representation properties and determine for which families of parameters these
probability distributions are complete, i.e., can represent any probability
distribution, and minimal, i.e., can represent a probability distribution
uniquely. We rely on convexity and differentiability to determine these
statistical conditions and extend this framework to general probability models,
such as Gaussian-Softmax and Gaussian-Argmax. We experimentally validate the
qualities of these extensions, which enjoy a faster convergence rate. We
conclude the analysis by identifying two sets of parameters that satisfy these
assumptions and thus admit a complete and minimal representation. Our
contribution is theoretical with supporting practical evaluation.

摘要：Gumbel-Softmax 機率分佈允許在生成式學習中學習離散符號，而 Gumbel-Argmax 機率分佈則適用於在判別式學習中學習離散結構。儘管投入了優化這些機率模型的努力，但其統計特性仍未被充分探討。在這項工作中，我們探討了它們的表示特性，並確定這些機率分佈在哪些參數族中是完備的，亦即可以表示任何機率分佈，以及最小的，亦即可以唯一地表示機率分佈。我們依賴凸性和可微分性來確定這些統計條件，並將此架構延伸到一般機率模型，例如 Gaussian-Softmax 和 Gaussian-Argmax。我們透過實驗驗證了這些擴充的品質，它們享有更快的收斂速度。我們透過找出滿足這些假設的兩組參數來結束分析，從而承認一個完備且最小的表示。我們的貢獻是理論性的，並附有支持性的實際評估。

##### **Audio Mamba: Selective State Spaces for Self-Supervised Audio Representations**
2406.02178v1 by Sarthak Yadav, Zheng-Hua Tan

Despite its widespread adoption as the prominent neural architecture, the
Transformer has spurred several independent lines of work to address its
limitations. One such approach is selective state space models, which have
demonstrated promising results for language modelling. However, their
feasibility for learning self-supervised, general-purpose audio representations
is yet to be investigated. This work proposes Audio Mamba, a selective state
space model for learning general-purpose audio representations from randomly
masked spectrogram patches through self-supervision. Empirical results on ten
diverse audio recognition downstream tasks show that the proposed models,
pretrained on the AudioSet dataset, consistently outperform comparable
self-supervised audio spectrogram transformer (SSAST) baselines by a
considerable margin and demonstrate better performance in dataset size,
sequence length and model size comparisons.

摘要：儘管 Transformer 已被廣泛採用為顯著的神經架構，但它已激勵了數條獨立的研究路線，以解決其限制。其中一種方法是選擇性狀態空間模型，已證明在語言建模方面獲得有希望的結果。然而，它們對於學習自我監督、通用音訊表示的可行性仍有待調查。這項工作提出 Audio Mamba，一種選擇性狀態空間模型，用於透過自我監督從隨機遮罩的語譜圖塊中學習通用音訊表示。在十個不同的音訊辨識下游任務上的經驗結果顯示，在 AudioSet 資料集上預先訓練的建議模型，始終以相當大的幅度優於可比較的自我監督音訊語譜圖Transformer (SSAST) 基準，並在資料集大小、序列長度和模型大小比較中展現出更好的效能。

##### **One-Shot Federated Learning with Bayesian Pseudocoresets**
2406.02177v1 by Tim d'Hondt, Mykola Pechenizkiy, Robert Peharz

Optimization-based techniques for federated learning (FL) often come with
prohibitive communication cost, as high dimensional model parameters need to be
communicated repeatedly between server and clients. In this paper, we follow a
Bayesian approach allowing to perform FL with one-shot communication, by
solving the global inference problem as a product of local client posteriors.
For models with multi-modal likelihoods, such as neural networks, a naive
application of this scheme is hampered, since clients will capture different
posterior modes, causing a destructive collapse of the posterior on the server
side. Consequently, we explore approximate inference in the function-space
representation of client posteriors, hence suffering less or not at all from
multi-modality. We show that distributed function-space inference is tightly
related to learning Bayesian pseudocoresets and develop a tractable Bayesian FL
algorithm on this insight. We show that this approach achieves prediction
performance competitive to state-of-the-art while showing a striking reduction
in communication cost of up to two orders of magnitude. Moreover, due to its
Bayesian nature, our method also delivers well-calibrated uncertainty
estimates.

摘要：基於優化的聯邦學習 (FL) 技術通常會帶來高昂的通訊成本，因為高維度模型參數需要在伺服器和用戶端之間重複傳遞。在本文中，我們採用貝氏方法，允許透過將全域推論問題求解為局部用戶端後驗機率的乘積，來執行一次性通訊的 FL。對於具有多模似然函數的模型，例如神經網路，這種方案的樸素應用會受到阻礙，因為用戶端會擷取不同的後驗模式，導致伺服器端的後驗機率發生破壞性的崩潰。因此，我們探索用戶端後驗機率的函數空間表示中的近似推論，從而較少或完全不受多模態的影響。我們證明了分布式函數空間推論與學習貝氏偽核心集密切相關，並根據這個見解開發了一個易於處理的貝氏 FL 演算法。我們證明了這種方法實現了與最先進技術相當的預測效能，同時大幅減少了多達兩個數量級的通訊成本。此外，由於其貝氏特性，我們的模型也提供了校準良好的不確定性估計。

##### **A multilingual dataset for offensive language and hate speech detection for hausa, yoruba and igbo languages**
2406.02169v1 by Saminu Mohammad Aliyu, Gregory Maksha Wajiga, Muhammad Murtala

The proliferation of online offensive language necessitates the development
of effective detection mechanisms, especially in multilingual contexts. This
study addresses the challenge by developing and introducing novel datasets for
offensive language detection in three major Nigerian languages: Hausa, Yoruba,
and Igbo. We collected data from Twitter and manually annotated it to create
datasets for each of the three languages, using native speakers. We used
pre-trained language models to evaluate their efficacy in detecting offensive
language in our datasets. The best-performing model achieved an accuracy of
90\%. To further support research in offensive language detection, we plan to
make the dataset and our models publicly available.

摘要：由於網路攻擊性語言的擴散，特別是在多語言的語境中，有必要開發有效的偵測機制。本研究透過開發和導入三種奈及利亞主要語言（豪薩語、約魯巴語和伊博語）的攻擊性語言偵測新資料集來應對此挑戰。我們從 Twitter 收集資料並手動註解，使用母語人士為三種語言建立資料集。我們使用預先訓練的語言模型來評估它們在我們的資料集中偵測攻擊性語言的效能。表現最佳的模型達到了 90% 的準確度。為了進一步支援攻擊性語言偵測的研究，我們計畫公開發布資料集和我們的模型。

##### **Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision**
2406.02166v1 by Saierdaer Yusuyin, Te Ma, Hao Huang, Wenbo Zhao, Zhijian Ou

There exist three approaches for multilingual and crosslingual automatic
speech recognition (MCL-ASR) - supervised pre-training with phonetic or
graphemic transcription, and self-supervised pre-training. We find that
pre-training with phonetic supervision has been underappreciated so far for
MCL-ASR, while conceptually it is more advantageous for information sharing
between different languages. This paper explores the approach of pre-training
with weakly phonetic supervision towards data-efficient MCL-ASR, which is
called Whistle. We relax the requirement of gold-standard human-validated
phonetic transcripts, and obtain International Phonetic Alphabet (IPA) based
transcription by leveraging the LanguageNet grapheme-to-phoneme (G2P) models.
We construct a common experimental setup based on the CommonVoice dataset,
called CV-Lang10, with 10 seen languages and 2 unseen languages. A set of
experiments are conducted on CV-Lang10 to compare, as fair as possible, the
three approaches under the common setup for MCL-ASR. Experiments demonstrate
the advantages of phoneme-based models (Whistle) for MCL-ASR, in terms of
speech recognition for seen languages, crosslingual performance for unseen
languages with different amounts of few-shot data, overcoming catastrophic
forgetting, and training efficiency.It is found that when training data is more
limited, phoneme supervision can achieve better results compared to subword
supervision and self-supervision, thereby providing higher data-efficiency. To
support reproducibility and promote future research along this direction, we
will release the code, models and data for the whole pipeline of Whistle at
https://github.com/thu-spmi/CAT upon publication.

摘要：多語言和跨語言自動語音辨識 (MCL-ASR) 有三種方法，分別是使用語音或音素轉錄進行監督式預訓練，以及自監督式預訓練。我們發現，到目前為止，使用語音監督進行預訓練在 MCL-ASR 中尚未受到重視，但從概念上來說，它對於不同語言之間的資訊共享更有利。本文探討了使用弱語音監督進行預訓練的方法，以實現資料高效的 MCL-ASR，稱為 Whistle。我們放寬了對人工驗證的黃金標準語音轉錄的要求，並利用 LanguageNet 音素轉音素 (G2P) 模型取得國際音標 (IPA) 轉錄。我們根據 CommonVoice 資料集構建了一個名為 CV-Lang10 的共同實驗設定，其中包含 10 種已見語言和 2 種未見語言。在 CV-Lang10 上進行了一系列實驗，以盡可能公平地比較在 MCL-ASR 的共同設定下這三種方法。實驗證明了基於音素的模型 (Whistle) 在 MCL-ASR 中的優點，包括已見語言的語音辨識、未見語言在不同少量資料下的跨語言效能、克服災難性遺忘以及訓練效率。研究發現，當訓練資料更有限時，與詞彙單位監督和自監督相比，音素監督可以取得更好的結果，從而提供更高的資料效率。為了支援可複製性並促進沿此方向的未來研究，我們將在 https://github.com/thu-spmi/CAT 上於發表時釋出 Whistle 整個管線的程式碼、模型和資料。

##### **Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models**
2406.02148v1 by Qingkai Min, Qipeng Guo, Xiangkun Hu, Songfang Huang, Zheng Zhang, Yue Zhang

Cross-document event coreference resolution (CDECR) involves clustering event
mentions across multiple documents that refer to the same real-world events.
Existing approaches utilize fine-tuning of small language models (SLMs) like
BERT to address the compatibility among the contexts of event mentions.
However, due to the complexity and diversity of contexts, these models are
prone to learning simple co-occurrences. Recently, large language models (LLMs)
like ChatGPT have demonstrated impressive contextual understanding, yet they
encounter challenges in adapting to specific information extraction (IE) tasks.
In this paper, we propose a collaborative approach for CDECR, leveraging the
capabilities of both a universally capable LLM and a task-specific SLM. The
collaborative strategy begins with the LLM accurately and comprehensively
summarizing events through prompting. Then, the SLM refines its learning of
event representations based on these insights during fine-tuning. Experimental
results demonstrate that our approach surpasses the performance of both the
large and small language models individually, forming a complementary
advantage. Across various datasets, our approach achieves state-of-the-art
performance, underscoring its effectiveness in diverse scenarios.

摘要：跨文档事件共指解析 (CDECR) 涉及将跨多个文档提及的事件聚类，这些事件是指同个真实世界事件。
现有方法利用微调小型语言模型 (SLM)（如 BERT）来解决事件提及的上下文之间的兼容性。
然而，由于上下文的复杂性和多样性，这些模型容易学习简单的共现。最近，大型语言模型 (LLM)（如 ChatGPT）已展示出令人印象深刻的上下文理解，但它们在适应特定信息提取 (IE) 任务时遇到了挑战。
在本文中，我们提出了一种用于 CDECR 的协作方法，利用了通用 LLM 和特定于任务的 SLM 的能力。协作策略始于 LLM 通过提示准确全面地总结事件。然后，SLM 在微调期间根据这些见解来优化其对事件表示的学习。实验结果表明，我们的方法超越了大型和小型语言模型各自的性能，形成了互补优势。在各种数据集上，我们的方法都取得了最先进的性能，突出了其在不同场景中的有效性。

##### **Reinforcement Tuning for Detecting Stances and Debunking Rumors Jointly with Large Language Models**
2406.02143v1 by Ruichao Yang, Wei Gao, Jing Ma, Hongzhan Lin, Bo Wang

Learning multi-task models for jointly detecting stance and verifying rumors
poses challenges due to the need for training data of stance at post level and
rumor veracity at claim level, which are difficult to obtain. To address this
issue, we leverage large language models (LLMs) as the foundation annotators
for the joint stance detection (SD) and rumor verification (RV) tasks, dubbed
as JSDRV. We introduce a novel reinforcement tuning framework to enhance the
joint predictive capabilities of LLM-based SD and RV components. Specifically,
we devise a policy for selecting LLM-annotated data at the two levels,
employing a hybrid reward mechanism to choose high-quality labels for effective
LLM fine-tuning on both tasks. Results demonstrate that JSDRV improves the
capabilities of LLMs in the joint tasks, not only outperforming
state-of-the-art methods but also generalizing to non-LLMs accommodated as task
models.

摘要：學習多任務模型以聯合偵測立場和驗證謠言因需要文章層級的立場訓練資料和聲明層級的謠言真實性而面臨挑戰，這些資料難以取得。為了解決這個問題，我們利用大型語言模型 (LLM) 作為聯合立場偵測 (SD) 和謠言驗證 (RV) 任務的基本註解者，稱為 JSDRV。我們引進一個新穎的強化調整架構以增強基於 LLM 的 SD 和 RV 元件的聯合預測能力。具體來說，我們設計了一個政策來選擇兩個層級的 LLM 註解資料，使用混合獎勵機制來選擇高品質標籤，以便在兩個任務上進行有效的 LLM 微調。結果證明 JSDRV 改善了 LLM 在聯合任務中的能力，不僅優於最先進的方法，而且還能推廣到作為任務模型容納的非 LLM。

##### **Robust Interaction-based Relevance Modeling for Online E-Commerce and LLM-based Retrieval**
2406.02135v1 by Ben Chen, Huangyu Dai, Xiang Ma, Wen Jiang, Wei Ning

Semantic relevance calculation is crucial for e-commerce search engines, as
it ensures that the items selected closely align with customer intent.
Inadequate attention to this aspect can detrimentally affect user experience
and engagement. Traditional text-matching techniques are prevalent but often
fail to capture the nuances of search intent accurately, so neural networks now
have become a preferred solution to processing such complex text matching.
Existing methods predominantly employ representation-based architectures, which
strike a balance between high traffic capacity and low latency. However, they
exhibit significant shortcomings in generalization and robustness when compared
to interaction-based architectures. In this work, we introduce a robust
interaction-based modeling paradigm to address these shortcomings. It
encompasses 1) a dynamic length representation scheme for expedited inference,
2) a professional terms recognition method to identify subjects and core
attributes from complex sentence structures, and 3) a contrastive adversarial
training protocol to bolster the model's robustness and matching capabilities.
Extensive offline evaluations demonstrate the superior robustness and
effectiveness of our approach, and online A/B testing confirms its ability to
improve relevance in the same exposure position, resulting in more clicks and
conversions. To the best of our knowledge, this method is the first
interaction-based approach for large e-commerce search relevance calculation.
Notably, we have deployed it for the entire search traffic on alibaba.com, the
largest B2B e-commerce platform in the world.

摘要：語意相關性計算對於電子商務搜尋引擎至關重要，因為它確保所選取的項目與客戶意圖緊密結合。對此面向的關注不足可能會對使用者體驗和參與度造成不利影響。傳統的文字比對技術很普遍，但通常無法準確捕捉搜尋意圖的細微差別，因此神經網路現在已成為處理此類複雜文字比對的首選解決方案。現有方法主要採用基於表示的架構，在高流量容量和低延遲之間取得平衡。然而，與基於互動的架構相比，它們在泛化和穩健性方面表現出顯著的缺點。在這項工作中，我們引入了一個穩健的基於互動的建模範例來解決這些缺點。它包含 1) 一個用於加速推理的動態長度表示方案，2) 一個專業術語識別方法，用於從複雜的句子結構中識別主詞和核心屬性，以及 3) 一個對比對抗訓練協議，以加強模型的穩健性和比對能力。廣泛的離線評估證明了我們方法的優越穩健性和有效性，而線上 A/B 測試證實了它在相同曝光位置提高相關性的能力，從而產生更多點擊和轉換。據我們所知，此方法是第一個用於大型電子商務搜尋相關性計算的基於互動的方法。值得注意的是，我們已將其部署到全球最大的 B2B 電子商務平台 alibaba.com 的所有搜尋流量中。

##### **The current status of large language models in summarizing radiology report impressions**
2406.02134v1 by Danqing Hu, Shanyuan Zhang, Qing Liu, Xiaofeng Zhu, Bing Liu

Large language models (LLMs) like ChatGPT show excellent capabilities in
various natural language processing tasks, especially for text generation. The
effectiveness of LLMs in summarizing radiology report impressions remains
unclear. In this study, we explore the capability of eight LLMs on the
radiology report impression summarization. Three types of radiology reports,
i.e., CT, PET-CT, and Ultrasound reports, are collected from Peking University
Cancer Hospital and Institute. We use the report findings to construct the
zero-shot, one-shot, and three-shot prompts with complete example reports to
generate the impressions. Besides the automatic quantitative evaluation
metrics, we define five human evaluation metrics, i.e., completeness,
correctness, conciseness, verisimilitude, and replaceability, to evaluate the
semantics of the generated impressions. Two thoracic surgeons (ZSY and LB) and
one radiologist (LQ) compare the generated impressions with the reference
impressions and score each impression under the five human evaluation metrics.
Experimental results show that there is a gap between the generated impressions
and reference impressions. Although the LLMs achieve comparable performance in
completeness and correctness, the conciseness and verisimilitude scores are not
very high. Using few-shot prompts can improve the LLMs' performance in
conciseness and verisimilitude, but the clinicians still think the LLMs can not
replace the radiologists in summarizing the radiology impressions.

摘要：大型語言模型 (LLM)，例如 ChatGPT，在各種自然語言處理任務中展現出色的能力，特別是在文本生成方面。LLM 在總結放射科報告印象方面的有效性仍不清楚。在本研究中，我們探討了八個 LLM 在放射科報告印象摘要中的能力。從北京大學腫瘤醫院和研究所收集了三種類型的放射科報告，即 CT、PET-CT 和超音波報告。我們使用報告結果來建構零次、一次和三次提示，並附上完整的範例報告以產生印象。除了自動量化評估指標之外，我們定義了五個人類評估指標，即完整性、正確性、簡潔性、合理性和可替換性，以評估所產生印象的語義。兩位胸腔外科醫生 (ZSY 和 LB) 和一位放射科醫生 (LQ) 將產生的印象與參考印象進行比較，並根據五個人類評估指標對每個印象進行評分。實驗結果顯示，產生的印象與參考印象之間存在差距。儘管 LLM 在完整性和正確性方面取得相當的表現，但簡潔性和合理性分數並不高。使用少次提示可以改善 LLM 在簡潔性和合理性方面的表現，但臨床醫生仍然認為 LLM 無法取代放射科醫生總結放射科印象。

##### **SimulTron: On-Device Simultaneous Speech to Speech Translation**
2406.02133v1 by Alex Agranovich, Eliya Nachmani, Oleg Rybakov, Yifan Ding, Ye Jia, Nadav Bar, Heiga Zen, Michelle Tadmor Ramanovich

Simultaneous speech-to-speech translation (S2ST) holds the promise of
breaking down communication barriers and enabling fluid conversations across
languages. However, achieving accurate, real-time translation through mobile
devices remains a major challenge. We introduce SimulTron, a novel S2ST
architecture designed to tackle this task. SimulTron is a lightweight direct
S2ST model that uses the strengths of the Translatotron framework while
incorporating key modifications for streaming operation, and an adjustable
fixed delay. Our experiments show that SimulTron surpasses Translatotron 2 in
offline evaluations. Furthermore, real-time evaluations reveal that SimulTron
improves upon the performance achieved by Translatotron 1. Additionally,
SimulTron achieves superior BLEU scores and latency compared to previous
real-time S2ST method on the MuST-C dataset. Significantly, we have
successfully deployed SimulTron on a Pixel 7 Pro device, show its potential for
simultaneous S2ST on-device.

摘要：同步語音轉語音翻譯 (S2ST) 承諾打破溝通障礙，並跨語言進行流暢對話。然而，透過行動裝置達成準確的即時翻譯仍是一項重大挑戰。我們介紹 SimulTron，一種新穎的 S2ST 架構，旨在解決此任務。SimulTron 是一款輕量級的直接 S2ST 模型，它使用 Translatotron 架構的優勢，同時結合串流操作和可調整的固定延遲的主要修改。我們的實驗顯示，SimulTron 在離線評估中超越 Translatotron 2。此外，即時評估顯示，SimulTron 改善了 Translatotron 1 達到的效能。此外，與 MuST-C 資料集上的先前即時 S2ST 方法相比，SimulTron 達到了更高的 BLEU 分數和延遲。值得注意的是，我們已成功在 Pixel 7 Pro 裝置上部署 SimulTron，顯示其在裝置上進行同步 S2ST 的潛力。

##### **CondTSF: One-line Plugin of Dataset Condensation for Time Series Forecasting**
2406.02131v2 by Jianrong Ding, Zhanyu Liu, Guanjie Zheng, Haiming Jin, Linghe Kong

Dataset condensation is a newborn technique that generates a small dataset
that can be used in training deep neural networks to lower training costs. The
objective of dataset condensation is to ensure that the model trained with the
synthetic dataset can perform comparably to the model trained with full
datasets. However, existing methods predominantly concentrate on classification
tasks, posing challenges in their adaptation to time series forecasting
(TS-forecasting). This challenge arises from disparities in the evaluation of
synthetic data. In classification, the synthetic data is considered
well-distilled if the model trained with the full dataset and the model trained
with the synthetic dataset yield identical labels for the same input,
regardless of variations in output logits distribution. Conversely, in
TS-forecasting, the effectiveness of synthetic data distillation is determined
by the distance between predictions of the two models. The synthetic data is
deemed well-distilled only when all data points within the predictions are
similar. Consequently, TS-forecasting has a more rigorous evaluation
methodology compared to classification. To mitigate this gap, we theoretically
analyze the optimization objective of dataset condensation for TS-forecasting
and propose a new one-line plugin of dataset condensation designated as Dataset
Condensation for Time Series Forecasting (CondTSF) based on our analysis.
Plugging CondTSF into previous dataset condensation methods facilitates a
reduction in the distance between the predictions of the model trained with the
full dataset and the model trained with the synthetic dataset, thereby
enhancing performance. We conduct extensive experiments on eight commonly used
time series datasets. CondTSF consistently improves the performance of all
previous dataset condensation methods across all datasets, particularly at low
condensing ratios.

摘要：資料集濃縮是一種新興技術，它會產生一個小型資料集，可用於訓練深度神經網路，以降低訓練成本。資料集濃縮的目標是確保使用合成資料集訓練的模型，其執行效能可以與使用完整資料集訓練的模型相提並論。然而，現有方法主要集中於分類任務，在它們適應於時間序列預測 (TS 預測) 時會構成挑戰。這個挑戰來自於對合成資料評估的差異。在分類中，如果使用完整資料集訓練的模型和使用合成資料集訓練的模型對相同的輸入產生相同的標籤，則合成資料會被視為經過良好的提煉，而不管輸出邏輯分布的變化如何。相反地，在 TS 預測中，合成資料提煉的有效性是由兩個模型預測之間的距離決定的。只有當預測中的所有資料點都相似時，合成資料才會被視為經過良好的提煉。因此，與分類相比，TS 預測有一個更嚴謹的評估方法。為了縮小這個差距，我們從理論上分析了 TS 預測的資料集濃縮最佳化目標，並根據我們的分析提出了資料集濃縮的一行新外掛程式，稱為時間序列預測的資料集濃縮 (CondTSF)。將 CondTSF 插入到先前的資料集濃縮方法中，有助於縮小使用完整資料集訓練的模型和使用合成資料集訓練的模型的預測之間的距離，從而增強效能。我們對八個常用的時間序列資料集進行了大量的實驗。CondTSF 持續改善所有先前的資料集濃縮方法在所有資料集中的效能，特別是在低濃縮率下。

##### **Iteration Head: A Mechanistic Study of Chain-of-Thought**
2406.02128v1 by Vivien Cabannes, Charles Arnal, Wassim Bouaziz, Alice Yang, Francois Charton, Julia Kempe

Chain-of-Thought (CoT) reasoning is known to improve Large Language Models
both empirically and in terms of theoretical approximation power. However, our
understanding of the inner workings and conditions of apparition of CoT
capabilities remains limited. This paper helps fill this gap by demonstrating
how CoT reasoning emerges in transformers in a controlled and interpretable
setting. In particular, we observe the appearance of a specialized attention
mechanism dedicated to iterative reasoning, which we coined "iteration heads".
We track both the emergence and the precise working of these iteration heads
down to the attention level, and measure the transferability of the CoT skills
to which they give rise between tasks.

摘要：鏈式思考 (CoT) 推理已知能改善大型語言模型，這在經驗上和理論近似能力方面皆然。然而，我們對 CoT 能力的內部運作和出現條件的理解仍然有限。本文透過展示 CoT 推理如何在受控且可解釋的設定中出現在 Transformer 中，有助於填補此一缺口。具體來說，我們觀察到一種專門用於反覆推理的注意力機制出現，我們將其稱為「反覆頭」。我們追蹤這些反覆頭的出現和精確運作，直到注意力層級，並衡量 CoT 技能在任務之間的轉移性。

##### **CityLight: A Universal Model Towards Real-world City-scale Traffic Signal Control Coordination**
2406.02126v1 by Jinwei Zeng, Chao Yu, Xinyi Yang, Wenxuan Ao, Jian Yuan, Yong Li, Yu Wang, Huazhong Yang

Traffic signal control (TSC) is a promising low-cost measure to enhance
transportation efficiency without affecting existing road infrastructure. While
various reinforcement learning-based TSC methods have been proposed and
experimentally outperform conventional rule-based methods, none of them has
been deployed in the real world. An essential gap lies in the
oversimplification of the scenarios in terms of intersection heterogeneity and
road network intricacy. To make TSC applicable in urban traffic management, we
target TSC coordination in city-scale high-authenticity road networks, aiming
to solve the three unique and important challenges: city-level scalability,
heterogeneity of real-world intersections, and effective coordination among
intricate neighbor connections. Since optimizing multiple agents in a
parameter-sharing paradigm can boost the training efficiency and help achieve
scalability, we propose our method, CityLight, based on the well-acknowledged
optimization framework, parameter-sharing MAPPO. To ensure the unified policy
network can learn to fit large-scale heterogeneous intersections and tackle the
intricate between-neighbor coordination, CityLight proposes a universal
representation module that consists of two key designs: heterogeneous
intersection alignment and neighborhood impact alignment for coordination. To
further boost coordination, CityLight adopts neighborhood-integrated rewards to
transition from achieving local optimal to global optimal. Extensive
experiments on datasets with hundreds to tens of thousands of real-world
intersections and authentic traffic demands validate the surprising
effectiveness and generalizability of CityLight, with an overall performance
gain of 11.66% and a 22.59% improvement in transfer scenarios in terms of
throughput.

摘要：交通號誌控制 (TSC) 是一種有望低成本提升運輸效率的措施，且不會影響現有的道路基礎設施。儘管已提出各種基於強化學習的 TSC 方法，且實驗結果優於傳統的基於規則的方法，但目前尚未在現實世界中部署任何方法。一個重要的差距在於場景過於簡化，包括交叉路口異質性和道路網路的複雜性。為了讓 TSC 適用於城市交通管理，我們以城市規模的高真實性道路網路中的 TSC 協調為目標，旨在解決三個獨特且重要的挑戰：城市級別的可擴充性、真實世界交叉路口的異質性，以及複雜鄰近連接間的有效協調。由於在參數共享範例中最佳化多個代理程式可以提升訓練效率並有助於實現可擴充性，我們提出我們的 CityLight 方法，它基於廣受認可的最佳化架構，參數共享 MAPPO。為了確保統一的政策網路能夠學會適應大規模異質性交叉路口，並應對複雜的鄰近協調，CityLight 提出一個通用表示模組，其中包含兩個關鍵設計：異質性交叉路口對齊和鄰近影響協調對齊。為了進一步提升協調，CityLight 採用鄰近整合獎勵，從達成局部最佳化轉變為達成整體最佳化。在包含數百個到數萬個真實世界交叉路口和真實交通需求的資料集上進行的廣泛實驗驗證了 CityLight 的驚人有效性和泛化性，在吞吐量方面整體效能提升了 11.66%，而轉移場景則改善了 22.59%。

##### **Diver: Large Language Model Decoding with Span-Level Mutual Information Verification**
2406.02120v1 by Jinliang Lu, Chen Wang, Jiajun Zhang

Large language models (LLMs) have shown impressive capabilities in adapting
to various tasks when provided with task-specific instructions. However, LLMs
using standard decoding strategies often struggle with deviations from the
inputs. Intuitively, compliant LLM outputs should reflect the information
present in the input, which can be measured by point-wise mutual information
(PMI) scores. Therefore, we propose Diver, a novel approach that enhances LLM
Decoding through span-level PMI verification. During inference, Diver first
identifies divergence steps that may lead to multiple candidate spans.
Subsequently, it calculates the PMI scores by assessing the log-likelihood
gains of the input if the candidate spans are generated. Finally, the optimal
span is selected based on the PMI re-ranked output distributions. We evaluate
our method across various downstream tasks, and empirical results demonstrate
that Diver significantly outperforms existing decoding methods in both
performance and versatility.

摘要：大型語言模型 (LLM) 在提供特定任務說明時，已展現出令人印象深刻的適應各種任務的能力。然而，使用標準解碼策略的 LLM 經常難以處理與輸入的偏差。直覺上，相容的 LLM 輸出應反映輸入中存在的信息，這可以用逐點互信息 (PMI) 分數來衡量。因此，我們提出 Diver，一種透過跨距級別 PMI 驗證增強 LLM 解碼的新方法。在推理期間，Diver 首先識別可能導致多個候選跨距的偏差步驟。隨後，它透過評估如果產生候選跨距，輸入的對數似然增益來計算 PMI 分數。最後，根據 PMI 重新排名的輸出分布選擇最佳跨距。我們在各種下游任務中評估我們的方法，實證結果表明，Diver 在效能和多功能性方面都顯著優於現有的解碼方法。

##### **UniOQA: A Unified Framework for Knowledge Graph Question Answering with Large Language Models**
2406.02110v1 by Zhuoyang Li, Liran Deng, Hui Liu, Qiaoqiao Liu, Junzhao Du

OwnThink stands as the most extensive Chinese open-domain knowledge graph
introduced in recent times. Despite prior attempts in question answering over
OwnThink (OQA), existing studies have faced limitations in model representation
capabilities, posing challenges in further enhancing overall accuracy in
question answering. In this paper, we introduce UniOQA, a unified framework
that integrates two complementary parallel workflows. Unlike conventional
approaches, UniOQA harnesses large language models (LLMs) for precise question
answering and incorporates a direct-answer-prediction process as a
cost-effective complement. Initially, to bolster representation capacity, we
fine-tune an LLM to translate questions into the Cypher query language (CQL),
tackling issues associated with restricted semantic understanding and
hallucinations. Subsequently, we introduce the Entity and Relation Replacement
algorithm to ensure the executability of the generated CQL. Concurrently, to
augment overall accuracy in question answering, we further adapt the
Retrieval-Augmented Generation (RAG) process to the knowledge graph.
Ultimately, we optimize answer accuracy through a dynamic decision algorithm.
Experimental findings illustrate that UniOQA notably advances SpCQL Logical
Accuracy to 21.2% and Execution Accuracy to 54.9%, achieving the new
state-of-the-art results on this benchmark. Through ablation experiments, we
delve into the superior representation capacity of UniOQA and quantify its
performance breakthrough.

摘要：OwnThink 是近來介紹的最廣泛的中文開放領域知識圖譜。儘管先前嘗試在 OwnThink（OQA）上進行問題解答，但現有研究在模型表示能力方面面臨限制，對進一步提高問題解答的整體準確性構成挑戰。在本文中，我們介紹了 UniOQA，這是一個統一的框架，它整合了兩個互補的並行工作流程。與傳統方法不同，UniOQA 利用大型語言模型 (LLM) 進行精準問題解答，並將直接答案預測過程作為一種具有成本效益的補充。最初，為了加強表示能力，我們微調 LLM 以將問題轉換為 Cypher 查詢語言 (CQL)，解決與受限語義理解和幻覺相關的問題。隨後，我們引入了實體和關係替換演算法，以確保生成的 CQL 的可執行性。同時，為了提高問題解答的整體準確性，我們進一步將檢索增強生成 (RAG) 過程適應到知識圖譜。最終，我們透過動態決策演算法最佳化答案準確性。實驗結果表明，UniOQA 將 SpCQL 邏輯準確度顯著提升至 21.2%，執行準確度提升至 54.9%，在這個基準上取得了新的最先進結果。透過消融實驗，我們深入探討 UniOQA 的優異表示能力，並量化其效能突破。

##### **MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset**
2406.02106v1 by Weiqi Wang, Yangqiu Song

To enable Large Language Models (LLMs) to function as conscious agents with
generalizable reasoning capabilities, it is crucial that they possess the
reasoning ability to comprehend situational changes (transitions) in
distribution triggered by environmental factors or actions from other agents.
Despite its fundamental significance, this ability remains underexplored due to
the complexity of modeling infinite possible changes in an event and their
associated distributions, coupled with the lack of benchmark data with
situational transitions. Addressing these gaps, we propose a novel formulation
of reasoning with distributional changes as a three-step discriminative
process, termed as MetAphysical ReaSoning. We then introduce the first-ever
benchmark, MARS, comprising three tasks corresponding to each step. These tasks
systematically assess LLMs' capabilities in reasoning the plausibility of (i)
changes in actions, (ii) states caused by changed actions, and (iii)
situational transitions driven by changes in action. Extensive evaluations with
20 (L)LMs of varying sizes and methods indicate that all three tasks in this
process pose significant challenges, even for state-of-the-art LLMs and LMs
after fine-tuning. Further analyses reveal potential causes for the
underperformance of LLMs and demonstrate that pre-training them on large-scale
conceptualization taxonomies can potentially enhance their metaphysical
reasoning capabilities. Our data and models are publicly accessible at
https://github.com/HKUST-KnowComp/MARS.

摘要：<paragraph>要讓大型語言模型 (LLM) 能夠作為具有可概化推理能力的自覺代理，至關重要的是，它們必須具備理解由環境因素或其他代理的動作觸發的分布情境變化（轉變）的推理能力。儘管其基本重要性，由於對事件中無限可能變化的建模及其相關分布的複雜性，加上缺乏具有情境轉變的基準資料，這種能力仍然未被充分探索。為了解決這些差距，我們提出了將具有分布變化的推理表述為一個三步驟區分過程的新公式，稱為形上推理。然後，我們引入了第一個基準 MARS，其中包含對應於每個步驟的三個任務。這些任務系統性地評估 LLM 在推理（i）動作變化、（ii）由動作變化引起的狀態以及（iii）由動作變化驅動的情境轉變的可能性方面的能力。對 20 個不同大小和方法的 (L)LM 進行的廣泛評估表明，即使對於最先進的 LLM 和 LLM 在微調後，此過程中的所有三個任務都構成了重大挑戰。進一步的分析揭示了 LLM 效能不佳的潛在原因，並證明在大型概念化分類法上對它們進行預訓練可能會增強它們的形上推理能力。我們的資料和模型可在 https://github.com/HKUST-KnowComp/MARS 公開取得。</paragraph>

##### **Kernel vs. Kernel: Exploring How the Data Structure Affects Neural Collapse**
2406.02105v1 by Vignesh Kothapalli, Tom Tirer

Recently, a vast amount of literature has focused on the "Neural Collapse"
(NC) phenomenon, which emerges when training neural network (NN) classifiers
beyond the zero training error point. The core component of NC is the decrease
in the within class variability of the network's deepest features, dubbed as
NC1. The theoretical works that study NC are typically based on simplified
unconstrained features models (UFMs) that mask any effect of the data on the
extent of collapse. In this paper, we provide a kernel-based analysis that does
not suffer from this limitation. First, given a kernel function, we establish
expressions for the traces of the within- and between-class covariance matrices
of the samples' features (and consequently an NC1 metric). Then, we turn to
focus on kernels associated with shallow NNs. First, we consider the NN
Gaussian Process kernel (NNGP), associated with the network at initialization,
and the complement Neural Tangent Kernel (NTK), associated with its training in
the "lazy regime". Interestingly, we show that the NTK does not represent more
collapsed features than the NNGP for prototypical data models. As NC emerges
from training, we then consider an alternative to NTK: the recently proposed
adaptive kernel, which generalizes NNGP to model the feature mapping learned
from the training data. Contrasting our NC1 analysis for these two kernels
enables gaining insights into the effect of data distribution on the extent of
collapse, which are empirically aligned with the behavior observed with
practical training of NNs.

摘要：<paragraph>最近，大量文献关注「神经崩塌」(NC)现象，此现象在神经网络 (NN) 分类器训练超越零训练误差点时出现。NC 的核心组件是网络最深层特征的类内变异性降低，称为 NC1。研究 NC 的理论工作通常基于简化的无约束特征模型 (UFM)，其掩盖了数据对崩塌程度的任何影响。在本文中，我们提供了一种基于核的分析，不受此限制。首先，给定一个核函数，我们建立样本特征的类内和类间协方差矩阵迹的表达式（因此也是 NC1 度量）。然后，我们专注于与浅层 NN 相关的核。首先，我们考虑 NN 高斯过程核 (NNGP)，它与初始化时的网络相关，以及与在「惰性模式」中训练相关的补集神经切线核 (NTK)。有趣的是，我们表明 NTK 对于原型数据模型并不表示比 NNGP 更多的崩塌特征。当 NC 从训练中出现时，我们考虑 NTK 的替代方案：最近提出的自适应核，它概括了 NNGP 以建模从训练数据中学到的特征映射。对比这两个核的 NC1 分析，可以深入了解数据分布对崩塌程度的影响，这与 NN 实际训练中观察到的行为在经验上是一致的。</paragraph>

##### **Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data**
2406.02100v1 by Haolong Li, Yu Ma, Yinqi Zhang, Chen Ye, Jie Chen

Large Language Models (LLMs) have shown excellent performance in language
understanding, text generation, code synthesis, and many other tasks, while
they still struggle in complex multi-step reasoning problems, such as
mathematical reasoning. In this paper, through a newly proposed arithmetical
puzzle problem, we show that the model can perform well on multi-step reasoning
tasks via fine-tuning on high-quality synthetic data. Experimental results with
the open-llama-3B model on three different test datasets show that not only the
model can reach a zero-shot pass@1 at 0.44 on the in-domain dataset, it also
demonstrates certain generalization capabilities on the out-of-domain datasets.
Specifically, this paper has designed two out-of-domain datasets in the form of
extending the numerical range and the composing components of the arithmetical
puzzle problem separately. The fine-tuned models have shown encouraging
performance on these two far more difficult tasks with the zero-shot pass@1 at
0.33 and 0.35, respectively.

摘要：大型語言模型（LLM）在語言理解、文本生成、程式碼合成和許多其他任務中表現出色，但它們在複雜的多步驟推理問題（例如數學推理）中仍然存在困難。在本文中，透過一個新提出的算術謎題問題，我們展示了該模型可以透過對高品質合成資料進行微調，在多步驟推理任務中表現良好。使用開放式 Llama-3B 模型在三個不同的測試資料集上進行的實驗結果顯示，該模型不僅可以在域內資料集上達到 0.44 的零次學習 pass@1，還可以在域外資料集上展示一定的泛化能力。具體來說，本文設計了兩個域外資料集，分別以擴展數值範圍和組成算術謎題問題的組成部分的形式。微調後的模型在兩個更困難的任務上表現出令人鼓舞的效能，零次學習 pass@1 分別為 0.33 和 0.35。

##### **MaskSR: Masked Language Model for Full-band Speech Restoration**
2406.02092v1 by Xu Li, Qirui Wang, Xiaoyu Liu

Speech restoration aims at restoring high quality speech in the presence of a
diverse set of distortions. Although several deep learning paradigms have been
studied for this task, the power of the recently emerging language models has
not been fully explored. In this paper, we propose MaskSR, a masked language
model capable of restoring full-band 44.1 kHz speech jointly considering noise,
reverb, clipping, and low bandwidth. MaskSR works with discrete acoustic tokens
extracted using a pre-trained neural codec. During training, MaskSR is
optimized to predict randomly masked tokens extracted from the high quality
target speech, conditioned on the corrupted speech with various distortions.
During inference, MaskSR reconstructs the target speech tokens with efficient
iterative sampling. Extensive experiments show that MaskSR obtains competitive
results on both the full-band speech restoration task and also on sub-tasks
compared with a wide range of models.

摘要：語音還原旨在在存在各種失真情況下還原高品質語音。儘管已針對這項任務研究了多種深度學習範例，但尚未充分探索最近出現的語言模型的功能。在本文中，我們提出 MaskSR，這是一種遮蔽語言模型，能夠同時考慮噪聲、殘響、剪輯和低頻寬，還原全頻段 44.1 kHz 語音。MaskSR 使用預訓練神經編解碼器提取的離散聲學符號。在訓練期間，MaskSR 經過最佳化，以預測從高品質目標語音中提取的隨機遮蔽符號，並根據具有各種失真的損毀語音進行調整。在推論期間，MaskSR 使用高效的迭代抽樣重建目標語音符號。大量的實驗表明，與廣泛的模型相比，MaskSR 在全頻段語音還原任務和子任務上都獲得了競爭力的結果。

##### **LongSSM: On the Length Extension of State-space Models in Language Modelling**
2406.02080v1 by Shida Wang

In this paper, we investigate the length-extension of state-space models
(SSMs) in language modeling. Length extension involves training models on short
sequences and testing them on longer ones. We show that state-space models
trained with zero hidden states initialization have difficulty doing length
extension. We explain this difficulty by pointing out the length extension is
equivalent to polynomial extrapolation. Based on the theory, we propose a
simple yet effective method - changing the hidden states initialization scheme
- to improve the length extension. Moreover, our method shows that using long
training sequence length is beneficial but not necessary to length extension.
Changing the hidden state initialization enables the efficient training of
long-memory model with a smaller training context length.

摘要：在本文中，我們探討了語言建模中狀態空間模型 (SSM) 的長度延伸。長度延伸涉及在短序列上訓練模型並在較長序列上測試它們。我們表明，使用零隱藏狀態初始化訓練的狀態空間模型難以進行長度延伸。我們通過指出長度延伸等於多項式外推來解釋這種難度。根據理論，我們提出了一個簡單但有效的方法——改變隱藏狀態初始化方案——來改進長度延伸。此外，我們的辦法表明，使用長的訓練序列長度是有益的，但對於長度延伸來說不是必需的。改變隱藏狀態初始化可以有效訓練具有較小訓練上下文長度的長記憶模型。

##### **Assessing the Performance of Chinese Open Source Large Language Models in Information Extraction Tasks**
2406.02079v1 by Yida Cai, Hao Sun, Hsiu-Yuan Huang, Yunfang Wu

Information Extraction (IE) plays a crucial role in Natural Language
Processing (NLP) by extracting structured information from unstructured text,
thereby facilitating seamless integration with various real-world applications
that rely on structured data. Despite its significance, recent experiments
focusing on English IE tasks have shed light on the challenges faced by Large
Language Models (LLMs) in achieving optimal performance, particularly in
sub-tasks like Named Entity Recognition (NER). In this paper, we delve into a
comprehensive investigation of the performance of mainstream Chinese
open-source LLMs in tackling IE tasks, specifically under zero-shot conditions
where the models are not fine-tuned for specific tasks. Additionally, we
present the outcomes of several few-shot experiments to further gauge the
capability of these models. Moreover, our study includes a comparative analysis
between these open-source LLMs and ChatGPT, a widely recognized language model,
on IE performance. Through meticulous experimentation and analysis, we aim to
provide insights into the strengths, limitations, and potential enhancements of
existing Chinese open-source LLMs in the domain of Information Extraction
within the context of NLP.

摘要：資訊萃取 (IE) 在自然語言處理 (NLP) 中扮演著關鍵角色，它從非結構化文字中萃取出結構化的資訊，從而促進與依賴結構化資料的各種真實世界應用程式進行無縫整合。儘管其重要性，最近專注於英文 IE 任務的實驗揭示了大型語言模型 (LLM) 在達成最佳效能時所面臨的挑戰，特別是在命名實體辨識 (NER) 等子任務中。在本文中，我們深入探討主流中文開源 LLM 在處理 IE 任務時的效能，特別是在模型未針對特定任務進行微調的零次學習條件下。此外，我們提出了一些小樣本實驗的結果，以進一步評估這些模型的能力。此外，我們的研究包括這些開源 LLM 與廣受認可的語言模型 ChatGPT 在 IE 效能上的比較分析。透過細緻的實驗和分析，我們旨在提供見解，了解現有中文開源 LLM 在 NLP 脈絡中的資訊萃取領域中的優勢、限制和潛在的強化。

##### **A Toolbox for Supporting Research on AI in Water Distribution Networks**
2406.02078v1 by André Artelt, Marios S. Kyriakou, Stelios G. Vrachimis, Demetrios G. Eliades, Barbara Hammer, Marios M. Polycarpou

Drinking water is a vital resource for humanity, and thus, Water Distribution
Networks (WDNs) are considered critical infrastructures in modern societies.
The operation of WDNs is subject to diverse challenges such as water leakages
and contamination, cyber/physical attacks, high energy consumption during pump
operation, etc. With model-based methods reaching their limits due to various
uncertainty sources, AI methods offer promising solutions to those challenges.
In this work, we introduce a Python toolbox for complex scenario modeling \&
generation such that AI researchers can easily access challenging problems from
the drinking water domain. Besides providing a high-level interface for the
easy generation of hydraulic and water quality scenario data, it also provides
easy access to popular event detection benchmarks and an environment for
developing control algorithms.

摘要：飲用水是人類至關重要的資源，因此，配水網路 (WDN) 被視為現代社會中的關鍵基礎設施。
WDN 的運作會受到各種挑戰，例如漏水和汙染、網路/實體攻擊、抽水運作時的高能耗等。由於各種不確定性來源，基於模型的方法已達到極限，而 AI 方法為這些挑戰提供了有希望的解決方案。
在這項工作中，我們介紹了一種 Python 工具箱，用於複雜情境建模和生成，讓 AI 研究人員可以輕鬆存取飲用水領域的挑戰性問題。除了提供高階介面，以輕鬆產生水力與水質情境資料外，它還提供了熱門事件偵測基準和開發控制演算法的環境。

##### **PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling**
2406.02069v1 by Zefan Cai., Yichi Zhang, Bofei Gao, Tianyu Liu, Keming Lu, Wayne Xiong, Yue Dong, Baobao Chang, Junjie Hu, Wen Xiao

In this study, we investigate whether attention-based information flow inside
large language models (LLMs) is aggregated through noticeable patterns for long
context processing. Our observations reveal that LLMs aggregate information
through Pyramidal Information Funneling where attention is scattering widely in
lower layers, progressively consolidating within specific contexts, and
ultimately focusin on critical tokens (a.k.a massive activation or attention
sink) in higher layers. Motivated by these insights, we developed PyramidKV, a
novel and effective KV cache compression method. This approach dynamically
adjusts the KV cache size across different layers, allocating more cache in
lower layers and less in higher ones, diverging from traditional methods that
maintain a uniform KV cache size. Our experimental evaluations, utilizing the
LongBench benchmark, show that PyramidKV matches the performance of models with
a full KV cache while retaining only 12% of the KV cache, thus significantly
reducing memory usage. In scenarios emphasizing memory efficiency, where only
0.7% of the KV cache is maintained, PyramidKV surpasses other KV cache
compression techniques achieving up to a 20.5 absolute accuracy improvement on
TREC.

摘要：在這項研究中，我們調查大型語言模型 (LLM) 內基於注意力的資訊流是否透過顯著模式聚合以進行長語境處理。我們的觀察顯示，LLM 透過金字塔式資訊漏斗聚合資訊，其中注意力在較低層廣泛分散，在特定語境中逐漸整合，並最終在較高層聚焦在關鍵代幣（又稱大量活化或注意力接收器）上。受到這些見解的啟發，我們開發了 PyramidKV，一種新穎且有效的 KV 快取壓縮方法。此方法會動態調整不同層的 KV 快取大小，在較低層分配較多快取，在較高層分配較少快取，與維持均勻 KV 快取大小的傳統方法不同。我們使用 LongBench 基準進行實驗評估，結果顯示 PyramidKV 的效能與具有完整 KV 快取的模型相符，同時僅保留 12% 的 KV 快取，因此大幅減少了記憶體使用量。在強調記憶體效率的情況下，僅維持 0.7% 的 KV 快取，PyramidKV 優於其他 KV 快取壓縮技術，在 TREC 上達到了高達 20.5 的絕對準確度提升。

##### **Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models**
2406.02061v1 by Marianna Nezhurina, Lucia Cipolina-Kun, Mehdi Cherti, Jenia Jitsev

Large Language Models (LLMs) are often described as being instances of
foundation models - that is, models that transfer strongly across various tasks
and conditions in few-show or zero-shot manner, while exhibiting scaling laws
that predict function improvement when increasing the pre-training scale. These
claims of excelling in different functions and tasks rely on measurements taken
across various sets of standardized benchmarks showing high scores for such
models. We demonstrate here a dramatic breakdown of function and reasoning
capabilities of state-of-the-art models trained at the largest available scales
which claim strong function, using a simple, short, conventional common sense
problem formulated in concise natural language, easily solvable by humans. The
breakdown is dramatic, as models also express strong overconfidence in their
wrong solutions, while providing often non-sensical "reasoning"-like
explanations akin to confabulations to justify and backup the validity of their
clearly failed responses, making them sound plausible. Various standard
interventions in an attempt to get the right solution, like various type of
enhanced prompting, or urging the models to reconsider the wrong solutions
again by multi step re-evaluation, fail. We take these initial observations to
the scientific and technological community to stimulate urgent re-assessment of
the claimed capabilities of current generation of LLMs, Such re-assessment also
requires common action to create standardized benchmarks that would allow
proper detection of such basic reasoning deficits that obviously manage to
remain undiscovered by current state-of-the-art evaluation procedures and
benchmarks. Code for reproducing experiments in the paper and raw experiments
data can be found at https://github.com/LAION-AI/AIW

摘要：大型語言模型 (LLM) 通常被描述為基礎模型的範例，也就是說，這些模型在各種任務和條件下都能強而有力地轉移，在少量展示或零次學習中，同時展現出預訓練規模增加時預測功能改善的規模定律。這些在不同功能和任務中表現優異的說法，依賴於各種標準基準組的測量，顯示出此類模型的高分。我們在此展示了在最大可用規模下訓練的最新模型的功能和推理能力的戲劇性崩潰，這些模型聲稱具有強大的功能，使用簡單、簡短、傳統的常識問題，用簡潔的自然語言表述，人類可以輕鬆解決。這種崩潰是戲劇性的，因為這些模型對其錯誤的解決方案也表現出強烈的過度自信，同時經常提供類似於捏造的無意義的「推理」式解釋，以證明和支持其明顯失敗的反應的有效性，讓它們聽起來很合理。各種標準干預措施試圖獲得正確的解決方案，例如各種類型的增強提示，或敦促模型通過多步驟重新評估再次重新考慮錯誤的解決方案，都失敗了。我們將這些初步觀察帶到科學和技術界，以刺激對當前一代 LLM 的聲稱能力進行緊急重新評估，這種重新評估也需要共同行動，以創建標準基準，以便適當地檢測到此類基本的推理缺陷，這些缺陷顯然設法通過當前最先進的評估程序和基準而保持未被發現。可以在 https://github.com/LAION-AI/AIW 中找到用於在論文中複製實驗和原始實驗數據的代碼

##### **I've got the "Answer"! Interpretation of LLMs Hidden States in Question Answering**
2406.02060v1 by Valeriya Goloviznina, Evgeny Kotelnikov

Interpretability and explainability of AI are becoming increasingly important
in light of the rapid development of large language models (LLMs). This paper
investigates the interpretation of LLMs in the context of the knowledge-based
question answering. The main hypothesis of the study is that correct and
incorrect model behavior can be distinguished at the level of hidden states.
The quantized models LLaMA-2-7B-Chat, Mistral-7B, Vicuna-7B and the MuSeRC
question-answering dataset are used to test this hypothesis. The results of the
analysis support the proposed hypothesis. We also identify the layers which
have a negative effect on the model's behavior. As a prospect of practical
application of the hypothesis, we propose to train such "weak" layers
additionally in order to improve the quality of the task solution.

摘要：隨著大型語言模型 (LLM) 的快速發展，AI 的可解釋性和可說明性變得越來越重要。本文探討了在基於知識的問答背景下對 LLM 的解釋。該研究的主要假設是，正確和不正確的模型行為可以在隱藏狀態的層面上區分。量化模型 LLaMA-2-7B-Chat、Mistral-7B、Vicuna-7B 和 MuSeRC 問答資料集被用於測試這個假設。分析結果支持了所提出的假設。我們還識別出對模型行為產生負面影響的層。作為假設實際應用的一個前景，我們建議額外訓練這些「弱」層，以提高任務解決方案的品質。

##### **Tabular and Deep Learning for the Whittle Index**
2406.02057v1 by Francisco Robledo Relaño, Vivek Borkar, Urtzi Ayesta, Konstantin Avrachenkov

The Whittle index policy is a heuristic that has shown remarkably good
performance (with guaranteed asymptotic optimality) when applied to the class
of problems known as Restless Multi-Armed Bandit Problems (RMABPs). In this
paper we present QWI and QWINN, two reinforcement learning algorithms,
respectively tabular and deep, to learn the Whittle index for the total
discounted criterion. The key feature is the use of two time-scales, a faster
one to update the state-action Q -values, and a relatively slower one to update
the Whittle indices. In our main theoretical result we show that QWI, which is
a tabular implementation, converges to the real Whittle indices. We then
present QWINN, an adaptation of QWI algorithm using neural networks to compute
the Q -values on the faster time-scale, which is able to extrapolate
information from one state to another and scales naturally to large state-space
environments. For QWINN, we show that all local minima of the Bellman error are
locally stable equilibria, which is the first result of its kind for DQN-based
schemes. Numerical computations show that QWI and QWINN converge faster than
the standard Q -learning algorithm, neural-network based approximate Q-learning
and other state of the art algorithms.

摘要：惠特爾指數政策是一種啟發法，在應用於稱為不安多臂賭徒問題 (RMABP) 的問題類型時，已展現出極佳的表現（有保證的漸近最優性）。在本文中，我們提出 QWI 和 QWINN，這兩種分別為表格和深度增強學習演算法，用於學習總折現準則的惠特爾指數。其關鍵特徵是使用兩個時間尺度，一個較快的時間尺度用於更新狀態動作 Q 值，另一個較慢的時間尺度用於更新惠特爾指數。在我們的主要理論結果中，我們展示了表格實作的 QWI 會收斂到真正的惠特爾指數。接著，我們提出 QWINN，一種使用神經網路計算較快時間尺度上 Q 值的 QWI 演算法改編，它能夠從一個狀態推斷到另一個狀態，並自然地擴展到大型狀態空間環境。對於 QWINN，我們展示了貝爾曼誤差的所有局部最小值都是局部穩定均衡，這是基於 DQN 的架構首次出現的此類結果。數值運算顯示，QWI 和 QWINN 的收斂速度比標準 Q 學習演算法、基於神經網路的近似 Q 學習和其他最先進的演算法快。

##### **Analyzing Social Biases in Japanese Large Language Models**
2406.02050v2 by Hitomi Yanaka, Namgi Han, Ryoma Kumon, Jie Lu, Masashi Takeshita, Ryo Sekizawa, Taisei Kato, Hiromi Arai

With the development of Large Language Models (LLMs), social biases in the
LLMs have become a crucial issue. While various benchmarks for social biases
have been provided across languages, the extent to which Japanese LLMs exhibit
social biases has not been fully investigated. In this study, we construct the
Japanese Bias Benchmark dataset for Question Answering (JBBQ) based on the
English bias benchmark BBQ, and analyze social biases in Japanese LLMs. The
results show that while current Japanese LLMs improve their accuracies on JBBQ
by instruction-tuning, their bias scores become larger. In addition, augmenting
their prompts with warning about social biases reduces the effect of biases in
some models.

摘要：隨著大型語言模型 (LLM) 的發展，LLM 中的社會偏見已成為一個關鍵問題。雖然已針對各種語言提供了社會偏見的各種基準，但日文 LLM 表現出社會偏見的程度尚未得到充分調查。在本研究中，我們根據英文偏見基準 BBQ 建構了日文偏見基準資料集，用於問答 (JBBQ)，並分析日文 LLM 中的社會偏見。結果顯示，雖然目前的日文 LLM 透過指令微調提高了其在 JBBQ 上的準確性，但其偏見分數變大了。此外，在提示中加入有關社會偏見的警告，可減少某些模型中偏見的影響。

##### **QROA: A Black-Box Query-Response Optimization Attack on LLMs**
2406.02044v1 by Hussein Jawad, Nicolas J. -B. BRUNEL

Large Language Models (LLMs) have surged in popularity in recent months, yet
they possess concerning capabilities for generating harmful content when
manipulated. This study introduces the Query-Response Optimization Attack
(QROA), an optimization-based strategy designed to exploit LLMs through a
black-box, query-only interaction. QROA adds an optimized trigger to a
malicious instruction to compel the LLM to generate harmful content. Unlike
previous approaches, QROA does not require access to the model's logit
information or any other internal data and operates solely through the standard
query-response interface of LLMs. Inspired by deep Q-learning and Greedy
coordinate descent, the method iteratively updates tokens to maximize a
designed reward function. We tested our method on various LLMs such as Vicuna,
Falcon, and Mistral, achieving an Attack Success Rate (ASR) over 80\%. We also
tested the model against Llama2-chat, the fine-tuned version of Llama2 designed
to resist Jailbreak attacks, achieving good ASR with a suboptimal initial
trigger seed. This study demonstrates the feasibility of generating jailbreak
attacks against deployed LLMs in the public domain using black-box optimization
methods, enabling more comprehensive safety testing of LLMs.

摘要：大型語言模型 (LLM) 近幾個月來人氣飆升，然而當遭到惡意操縱時，它們卻具備產生有害內容的令人擔憂的能力。本研究引入了查詢回應最佳化攻擊 (QROA)，一種最佳化策略，旨在透過黑盒子、僅查詢的互動來利用 LLM。QROA 將最佳化的觸發器新增到惡意指令中，以強制 LLM 產生有害內容。與先前的做法不同，QROA 不需要存取模型的 logit 資訊或任何其他內部資料，並且僅透過 LLM 的標準查詢回應介面運作。受到深度 Q 學習和貪婪坐標下降的啟發，此方法會反覆更新代碼，以最大化設計的獎勵函數。我們在各種 LLM（例如 Vicuna、Falcon 和 Mistral）上測試了我們的模型，達到了 80% 以上的攻擊成功率 (ASR)。我們還針對 Llama2-chat 測試了此模型，Llama2-chat 是 Llama2 的微調版本，旨在抵抗越獄攻擊，並使用次佳的初始觸發種子達到了良好的 ASR。本研究證明了使用黑盒子最佳化方法針對公開領域中已部署的 LLM 產生越獄攻擊的可行性，進而能夠對 LLM 進行更全面的安全性測試。

##### **DFA-GNN: Forward Learning of Graph Neural Networks by Direct Feedback Alignment**
2406.02040v1 by Gongpei Zhao, Tao Wang, Congyan Lang, Yi Jin, Yidong Li, Haibin Ling

Graph neural networks are recognized for their strong performance across
various applications, with the backpropagation algorithm playing a central role
in the development of most GNN models. However, despite its effectiveness, BP
has limitations that challenge its biological plausibility and affect the
efficiency, scalability and parallelism of training neural networks for
graph-based tasks. While several non-BP training algorithms, such as the direct
feedback alignment, have been successfully applied to fully-connected and
convolutional network components for handling Euclidean data, directly adapting
these non-BP frameworks to manage non-Euclidean graph data in GNN models
presents significant challenges. These challenges primarily arise from the
violation of the i.i.d. assumption in graph data and the difficulty in
accessing prediction errors for all samples (nodes) within the graph. To
overcome these obstacles, in this paper we propose DFA-GNN, a novel forward
learning framework tailored for GNNs with a case study of semi-supervised
learning. The proposed method breaks the limitations of BP by using a dedicated
forward training mechanism. Specifically, DFA-GNN extends the principles of DFA
to adapt to graph data and unique architecture of GNNs, which incorporates the
information of graph topology into the feedback links to accommodate the
non-Euclidean characteristics of graph data. Additionally, for semi-supervised
graph learning tasks, we developed a pseudo error generator that spreads
residual errors from training data to create a pseudo error for each unlabeled
node. These pseudo errors are then utilized to train GNNs using DFA. Extensive
experiments on 10 public benchmarks reveal that our learning framework
outperforms not only previous non-BP methods but also the standard BP methods,
and it exhibits excellent robustness against various types of noise and
attacks.

摘要：圖神經網路因其在各種應用中的強勁表現而受到認可，其中反向傳播演算法在大部分 GNN 模型的開發中扮演著核心角色。然而，儘管其有效性，BP 仍有其限制，這挑戰了其生物學合理性，並影響了訓練神經網路以執行基於圖形的任務的效率、可擴充性和並行性。儘管幾種非 BP 訓練演算法，例如直接回饋對齊，已成功應用於處理歐幾里得資料的全連接和卷積網路元件，但將這些非 BP 框架直接調整為在 GNN 模型中管理非歐幾里得圖形資料會帶來重大的挑戰。這些挑戰主要是源於違反圖形資料中的 i.i.d. 假設，以及難以存取圖形中所有樣本（節點）的預測誤差。為了克服這些障礙，我們在本文中提出了 DFA-GNN，這是一個針對 GNN 量身打造的新穎前向學習框架，並以半監督式學習的案例研究為例。所提出的方法透過使用專用的前向訓練機制來突破 BP 的限制。具體來說，DFA-GNN 將 DFA 的原理延伸到圖形資料和 GNN 的獨特架構，將圖形拓撲的資訊納入回饋連結中，以適應圖形資料的非歐幾里得特性。此外，對於半監督式圖形學習任務，我們開發了一個偽誤差產生器，將訓練資料的殘差誤差散佈到各個未標記節點，為每個節點建立一個偽誤差。然後利用這些偽誤差使用 DFA 訓練 GNN。在 10 個公開基準上的廣泛實驗顯示，我們的學習框架不僅優於先前的非 BP 方法，也優於標準的 BP 方法，並且對各種雜訊和攻擊類型表現出極佳的穩健性。

##### **A Unifying Framework for Action-Conditional Self-Predictive Reinforcement Learning**
2406.02035v1 by Khimya Khetarpal, Zhaohan Daniel Guo, Bernardo Avila Pires, Yunhao Tang, Clare Lyle, Mark Rowland, Nicolas Heess, Diana Borsa, Arthur Guez, Will Dabney

Learning a good representation is a crucial challenge for Reinforcement
Learning (RL) agents. Self-predictive learning provides means to jointly learn
a latent representation and dynamics model by bootstrapping from future latent
representations (BYOL). Recent work has developed theoretical insights into
these algorithms by studying a continuous-time ODE model for self-predictive
representation learning under the simplifying assumption that the algorithm
depends on a fixed policy (BYOL-$\Pi$); this assumption is at odds with
practical instantiations of such algorithms, which explicitly condition their
predictions on future actions. In this work, we take a step towards bridging
the gap between theory and practice by analyzing an action-conditional
self-predictive objective (BYOL-AC) using the ODE framework, characterizing its
convergence properties and highlighting important distinctions between the
limiting solutions of the BYOL-$\Pi$ and BYOL-AC dynamics. We show how the two
representations are related by a variance equation. This connection leads to a
novel variance-like action-conditional objective (BYOL-VAR) and its
corresponding ODE. We unify the study of all three objectives through two
complementary lenses; a model-based perspective, where each objective is shown
to be equivalent to a low-rank approximation of certain dynamics, and a
model-free perspective, which establishes relationships between the objectives
and their respective value, Q-value, and advantage function. Our empirical
investigations, encompassing both linear function approximation and Deep RL
environments, demonstrates that BYOL-AC is better overall in a variety of
different settings.

摘要：學習良好的表徵對於強化學習 (RL) 代理來說是一項至關重要的挑戰。自我預測學習提供了透過從未來的潛在表徵 (BYOL) 引導來聯合學習潛在表徵和動態模型的方法。最近的研究透過研究自我預測表徵學習的連續時間 ODE 模型，在簡化的假設下，演算法取決於固定政策 (BYOL-$\Pi$)，發展了對這些演算法的理論見解；此假設與此類演算法的實際實例相矛盾，這些實例明確地根據未來的動作對其預測進行條件化。在這項工作中，我們透過使用 ODE 架構分析動作條件自我預測目標 (BYOL-AC)，描述其收斂性質並強調 BYOL-$\Pi$ 和 BYOL-AC 動力學的極限解之間的重要區別，朝著彌合理論與實務之間的差距邁進一步。我們展示了這兩個表徵如何透過變異方程式相關聯。此連結導致了新的變異類似動作條件目標 (BYOL-VAR) 及其對應的 ODE。我們透過兩個互補的觀點統一了對所有三個目標的研究；基於模型的觀點，其中每個目標都被證明等於特定動態的低秩近似，以及無模型的觀點，這建立了目標及其各自的價值、Q 值和優勢函數之間的關係。我們的實證調查涵蓋線性函數近似和深度 RL 環境，證明了 BYOL-AC 在各種不同的設定中整體表現更佳。

##### **Multimodal Reasoning with Multimodal Knowledge Graph**
2406.02030v2 by Junlin Lee, Yequan Wang, Jing Li, Min Zhang

Multimodal reasoning with large language models (LLMs) often suffers from
hallucinations and the presence of deficient or outdated knowledge within LLMs.
Some approaches have sought to mitigate these issues by employing textual
knowledge graphs, but their singular modality of knowledge limits comprehensive
cross-modal understanding. In this paper, we propose the Multimodal Reasoning
with Multimodal Knowledge Graph (MR-MKG) method, which leverages multimodal
knowledge graphs (MMKGs) to learn rich and semantic knowledge across
modalities, significantly enhancing the multimodal reasoning capabilities of
LLMs. In particular, a relation graph attention network is utilized for
encoding MMKGs and a cross-modal alignment module is designed for optimizing
image-text alignment. A MMKG-grounded dataset is constructed to equip LLMs with
initial expertise in multimodal reasoning through pretraining. Remarkably,
MR-MKG achieves superior performance while training on only a small fraction of
parameters, approximately 2.25% of the LLM's parameter size. Experimental
results on multimodal question answering and multimodal analogy reasoning tasks
demonstrate that our MR-MKG method outperforms previous state-of-the-art
models.

摘要：多模态推理与大型语言模型 (LLM) 经常会出现幻觉，并且 LLM 中存在知识缺陷或过时的问题。一些方法试图通过使用文本知识图谱来缓解这些问题，但它们单一的知识模式限制了全面的跨模态理解。在本文中，我们提出了多模态知识图谱 (MR-MKG) 方法的多模态推理，该方法利用多模态知识图谱 (MMKG) 来学习跨模态的丰富语义知识，从而显著增强 LLM 的多模态推理能力。特别是，关系图谱注意力网络用于编码 MMKG，并且跨模态对齐模块设计用于优化图像文本对齐。构建了一个基于 MMKG 的数据集，以通过预训练为 LLM 提供多模态推理的初始专业知识。值得注意的是，MR-MKG 在仅训练 LLM 参数规模的一小部分（约为 2.25%）时就实现了卓越的性能。多模态问题解答和多模态类比推理任务的实验结果表明，我们的 MR-MKG 方法优于以前最先进的模型。

##### **Inference Attacks in Machine Learning as a Service: A Taxonomy, Review, and Promising Directions**
2406.02027v1 by Feng Wu, Lei Cui, Shaowen Yao, Shui Yu

The prosperity of machine learning has also brought people's concerns about
data privacy. Among them, inference attacks can implement privacy breaches in
various MLaaS scenarios and model training/prediction phases. Specifically,
inference attacks can perform privacy inference on undisclosed target training
sets based on outputs of the target model, including but not limited to
statistics, membership, semantics, data representation, etc. For instance,
infer whether the target data has the characteristics of AIDS. In addition, the
rapid development of the machine learning community in recent years, especially
the surge of model types and application scenarios, has further stimulated the
inference attacks' research. Thus, studying inference attacks and analyzing
them in depth is urgent and significant. However, there is still a gap in the
systematic discussion of inference attacks from taxonomy, global perspective,
attack, and defense perspectives. This survey provides an in-depth and
comprehensive inference of attacks and corresponding countermeasures in
ML-as-a-service based on taxonomy and the latest researches. Without
compromising researchers' intuition, we first propose the 3MP taxonomy based on
the community research status, trying to normalize the confusing naming system
of inference attacks. Also, we analyze the pros and cons of each type of
inference attack, their workflow, countermeasure, and how they interact with
other attacks. In the end, we point out several promising directions for
researchers from a more comprehensive and novel perspective.

摘要：機器學習的蓬勃發展也帶來了人們對於資料隱私的疑慮。其中，推論攻擊可以在各種 MLaaS 場景和模型訓練/預測階段實作隱私洩露。具體來說，推論攻擊可以根據目標模型的輸出，對未公開的目標訓練集執行隱私推論，包括但不限於統計、成員資格、語義、資料表示等。例如，推論目標資料是否具有愛滋病的特徵。此外，近年來機器學習社群的快速發展，特別是模型類型和應用場景的激增，進一步刺激了推論攻擊的研究。因此，研究推論攻擊並深入分析它們迫在眉睫且意義重大。然而，從分類、全球觀點、攻擊和防禦觀點對推論攻擊進行系統性討論仍存在差距。這項調查根據分類法和最新研究，對機器學習即服務中的攻擊和相應的對策提供了深入且全面的推論。在不影響研究人員直覺的情況下，我們首先基於社群研究現狀提出 3MP 分類法，試圖將推論攻擊中混亂的命名系統標準化。此外，我們分析了每種類型的推論攻擊的優缺點、工作流程、對策以及它們如何與其他攻擊互動。最後，我們從更全面且新穎的角度為研究人員指出了幾個有希望的研究方向。

##### **MetaMixer Is All You Need**
2406.02021v1 by Seokju Yun, Dongheon Lee, Youngmin Ro

Transformer, composed of self-attention and Feed-Forward Network, has
revolutionized the landscape of network design across various vision tasks. FFN
is a versatile operator seamlessly integrated into nearly all AI models to
effectively harness rich representations. Recent works also show that FFN
functions like key-value memories. Thus, akin to the query-key-value mechanism
within self-attention, FFN can be viewed as a memory network, where the input
serves as query and the two projection weights operate as keys and values,
respectively. We hypothesize that the importance lies in query-key-value
framework itself rather than in self-attention. To verify this, we propose
converting self-attention into a more FFN-like efficient token mixer with only
convolutions while retaining query-key-value framework, namely FFNification.
Specifically, FFNification replaces query-key and attention coefficient-value
interactions with large kernel convolutions and adopts GELU activation function
instead of softmax. The derived token mixer, FFNified attention, serves as
key-value memories for detecting locally distributed spatial patterns, and
operates in the opposite dimension to the ConvNeXt block within each
corresponding sub-operation of the query-key-value framework. Building upon the
above two modules, we present a family of Fast-Forward Networks. Our FFNet
achieves remarkable performance improvements over previous state-of-the-art
methods across a wide range of tasks. The strong and general performance of our
proposed method validates our hypothesis and leads us to introduce MetaMixer, a
general mixer architecture that does not specify sub-operations within the
query-key-value framework. We show that using only simple operations like
convolution and GELU in the MetaMixer can achieve superior performance.

摘要：<paragraph>Transformer 由自注意力和前馈网络组成，彻底改变了各种视觉任务的网络设计格局。FFN 是一种多功能运算子，可以无缝集成到几乎所有 AI 模型中，以有效利用丰富的表示。最近的研究还表明，FFN 的功能类似于键值存储器。因此，类似于自注意力中的查询键值机制，FFN 可以被视为一个记忆网络，其中输入充当查询，两个投影权重分别充当键和值。我们假设重要性在于查询键值框架本身，而不是自注意力。为了验证这一点，我们建议将自注意力转换为仅使用卷积的更像 FFN 的高效令牌混合器，同时保留查询键值框架，即 FFN 化。具体来说，FFN 化用大核卷积替换查询键和注意力系数值交互，并采用 GELU 激活函数而不是 softmax。派生的令牌混合器，FFN 化注意力，用作检测局部分布的空间模式的键值存储器，并在查询键值框架的每个相应子操作中与 ConvNeXt 块在相反的维度上操作。基于上述两个模块，我们提出了一个快速前馈网络系列。我们的 FFNet 在广泛的任务中实现了对以前最先进方法的显着性能改进。我们提出的方法的强大而通用的性能验证了我们的假设，并引导我们引入了 MetaMixer，这是一种通用混合器架构，不指定查询键值框架内的子操作。我们表明，在 MetaMixer 中仅使用卷积和 GELU 等简单操作就可以实现卓越的性能。</paragraph>

##### **Why Would You Suggest That? Human Trust in Language Model Responses**
2406.02018v1 by Manasi Sharma, Ho Chit Siu, Rohan Paleja, Jaime D. Peña

The emergence of Large Language Models (LLMs) has revealed a growing need for
human-AI collaboration, especially in creative decision-making scenarios where
trust and reliance are paramount. Through human studies and model evaluations
on the open-ended News Headline Generation task from the LaMP benchmark, we
analyze how the framing and presence of explanations affect user trust and
model performance. Overall, we provide evidence that adding an explanation in
the model response to justify its reasoning significantly increases
self-reported user trust in the model when the user has the opportunity to
compare various responses. Position and faithfulness of these explanations are
also important factors. However, these gains disappear when users are shown
responses independently, suggesting that humans trust all model responses,
including deceptive ones, equitably when they are shown in isolation. Our
findings urge future research to delve deeper into the nuanced evaluation of
trust in human-machine teaming systems.

摘要：大型語言模型 (LLM) 的出現揭示了對人類與人工智慧協作日益增長的需求，特別是在信任和依賴至上的創意決策情境中。透過人類研究和模型評估，針對 LaMP 基準中的開放式新聞標題產生任務，我們分析解釋的架構和存在如何影響使用者信任和模型效能。總體而言，我們提供證據證明，在模型回應中加入解釋以證明其推理，當使用者有機會比較各種回應時，會顯著增加使用者對模型的自我報告信任。這些解釋的位置和忠實度也是重要因素。然而，當使用者獨立看到回應時，這些收益就會消失，這表示當人類在孤立狀態下看到所有模型回應時，包括具有欺騙性的回應，他們都會公平地信任。我們的研究結果敦促未來的研究深入探討對人類與機器團隊系統信任的細緻評估。

##### **Phonetic Enhanced Language Modeling for Text-to-Speech Synthesis**
2406.02009v1 by Kun Zhou, Shengkui Zhao, Yukun Ma, Chong Zhang, Hao Wang, Dianwen Ng, Chongjia Ni, Nguyen Trung Hieu, Jia Qi Yip, Bin Ma

Recent language model-based text-to-speech (TTS) frameworks demonstrate
scalability and in-context learning capabilities. However, they suffer from
robustness issues due to the accumulation of errors in speech unit predictions
during autoregressive language modeling. In this paper, we propose a phonetic
enhanced language modeling method to improve the performance of TTS models. We
leverage self-supervised representations that are phonetically rich as the
training target for the autoregressive language model. Subsequently, a
non-autoregressive model is employed to predict discrete acoustic codecs that
contain fine-grained acoustic details. The TTS model focuses solely on
linguistic modeling during autoregressive training, thereby reducing the error
propagation that occurs in non-autoregressive training. Both objective and
subjective evaluations validate the effectiveness of our proposed method.

摘要：近期的基於語言模型的文字轉語音 (TTS) 框架展示了可擴充性和情境學習的能力。然而，它們因為在自迴歸語言模型中語音單元預測的錯誤累積而導致穩健性問題。在本文中，我們提出了一種增強型音標語言模型方法來改善 TTS 模型的效能。我們利用音標豐富的自監督表徵作為自迴歸語言模型的訓練目標。隨後，採用非自迴歸模型來預測包含細緻音訊細節的離散音訊編解碼器。TTS 模型在自迴歸訓練期間僅專注於語言模型，從而減少了在非自迴歸訓練中發生的錯誤傳播。客觀和主觀評估都驗證了我們所提出的方法的有效性。

##### **ODE-based Learning to Optimize**
2406.02006v1 by Zhonglin Xie, Wotao Yin, Zaiwen Wen

Recent years have seen a growing interest in understanding acceleration
methods through the lens of ordinary differential equations (ODEs). Despite the
theoretical advancements, translating the rapid convergence observed in
continuous-time models to discrete-time iterative methods poses significant
challenges. In this paper, we present a comprehensive framework integrating the
inertial systems with Hessian-driven damping equation (ISHD) and learning-based
approaches for developing optimization methods through a deep synergy of
theoretical insights. We first establish the convergence condition for ensuring
the convergence of the solution trajectory of ISHD. Then, we show that provided
the stability condition, another relaxed requirement on the coefficients of
ISHD, the sequence generated through the explicit Euler discretization of ISHD
converges, which gives a large family of practical optimization methods. In
order to select the best optimization method in this family for certain
problems, we introduce the stopping time, the time required for an optimization
method derived from ISHD to achieve a predefined level of suboptimality. Then,
we formulate a novel learning to optimize (L2O) problem aimed at minimizing the
stopping time subject to the convergence and stability condition. To navigate
this learning problem, we present an algorithm combining stochastic
optimization and the penalty method (StoPM). The convergence of StoPM using the
conservative gradient is proved. Empirical validation of our framework is
conducted through extensive numerical experiments across a diverse set of
optimization problems. These experiments showcase the superior performance of
the learned optimization methods.

摘要：近年來，人們越來越有興趣透過常微分方程式 (ODE) 的角度來了解加速方法。儘管理論上有所進展，但將連續時間模型中觀察到的快速收斂轉換為離散時間反覆運算方法，仍面臨重大挑戰。在本文中，我們提出了一個綜合架構，將慣性系統與 Hessian 驅動阻尼方程式 (ISHD) 和基於學習的方法整合起來，透過理論見解的深度協同作用來開發最佳化方法。我們首先建立收斂條件，以確保 ISHD 解決軌跡的收斂性。然後，我們證明在穩定條件下，ISHD 係數的另一個放寬要求，透過 ISHD 的明確歐拉離散化所生成的序列會收斂，這提供了一大類實用的最佳化方法。為了在此類別中為特定問題選擇最佳最佳化方法，我們引入了停止時間，這是從 ISHD 衍生的最佳化方法達到預定義次最佳水準所需的時間。然後，我們制定了一個新穎的學習最佳化 (L2O) 問題，旨在最小化停止時間，並符合收斂性和穩定性條件。為了解決這個學習問題，我們提出了一種結合隨機最佳化與懲罰方法 (StoPM) 的演算法。使用保守梯度時，StoPM 的收斂性已被證明。我們透過針對各種最佳化問題進行廣泛的數值實驗，對我們的架構進行實證驗證。這些實驗展示了已學習最佳化方法的優異效能。

