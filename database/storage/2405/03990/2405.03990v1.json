{"2405.03990": {"publish_time": "2024-05-07", "title": "TrimCaching: Parameter-sharing AI Model Caching in Wireless Edge Networks", "paper_summary": "Next-generation mobile networks are expected to facilitate fast AI model\ndownloading to end users. By caching models on edge servers, mobile networks\ncan deliver models to end users with low latency, resulting in a paradigm\ncalled edge model caching. In this paper, we develop a novel model placement\nscheme, called parameter-sharing model caching (TrimCaching). TrimCaching\nexploits the key observation that a wide range of AI models, such as\nconvolutional neural networks or large language models, can share a significant\nproportion of parameter blocks containing reusable knowledge, thereby improving\nstorage efficiency. To this end, we formulate a parameter-sharing model\nplacement problem to maximize the cache hit ratio in multi-edge wireless\nnetworks by balancing the fundamental tradeoff between storage efficiency and\nservice latency. We show that the formulated problem is a submodular\nmaximization problem with submodular constraints, for which no polynomial-time\napproximation algorithm exists. To overcome this challenge, we study an\nimportant special case, where a small fixed number of parameter blocks are\nshared across models, which often holds in practice. In such a case, a\npolynomial-time algorithm with $\\left(1-\\epsilon\\right)/2$-approximation\nguarantee is developed. Subsequently, we address the original problem for the\ngeneral case by developing a greedy algorithm. Simulation results demonstrate\nthat the proposed TrimCaching framework significantly improves the cache hit\nratio compared with state-of-the-art content caching without exploiting shared\nparameters in AI models.", "paper_summary_zh": "\u9810\u8a08\u4e0b\u4e00\u4ee3\u884c\u52d5\u7db2\u8def\u5c07\u6703\u4fc3\u9032\u5feb\u901f\u7684 AI \u6a21\u578b\u4e0b\u8f09\u7d66\u7d42\u7aef\u4f7f\u7528\u8005\u3002\u884c\u52d5\u7db2\u8def\u900f\u904e\u5c07\u6a21\u578b\u5feb\u53d6\u5728\u908a\u7de3\u4f3a\u670d\u5668\u4e0a\uff0c\u53ef\u4ee5\u4f4e\u5ef6\u9072\u5730\u5c07\u6a21\u578b\u50b3\u905e\u7d66\u7d42\u7aef\u4f7f\u7528\u8005\uff0c\u9032\u800c\u7522\u751f\u4e00\u7a2e\u7a31\u70ba\u908a\u7de3\u6a21\u578b\u5feb\u53d6\u7684\u5178\u7bc4\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u6a21\u578b\u914d\u7f6e\u65b9\u6848\uff0c\u7a31\u70ba\u53c3\u6578\u5171\u4eab\u6a21\u578b\u5feb\u53d6 (TrimCaching)\u3002TrimCaching \u5229\u7528\u4e86\u4e00\u500b\u95dc\u9375\u89c0\u5bdf\uff0c\u5373\u5ee3\u6cdb\u7684 AI \u6a21\u578b\uff0c\u4f8b\u5982\u5377\u7a4d\u795e\u7d93\u7db2\u8def\u6216\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff0c\u53ef\u4ee5\u5171\u4eab\u5305\u542b\u53ef\u91cd\u8907\u4f7f\u7528\u77e5\u8b58\u7684\u986f\u8457\u6bd4\u4f8b\u7684\u53c3\u6578\u5340\u584a\uff0c\u5f9e\u800c\u63d0\u9ad8\u5132\u5b58\u6548\u7387\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5236\u5b9a\u4e86\u4e00\u500b\u53c3\u6578\u5171\u4eab\u6a21\u578b\u914d\u7f6e\u554f\u984c\uff0c\u4ee5\u5e73\u8861\u5132\u5b58\u6548\u7387\u548c\u670d\u52d9\u5ef6\u9072\u4e4b\u9593\u7684\u57fa\u672c\u6b0a\u8861\uff0c\u9032\u800c\u6700\u5927\u5316\u591a\u908a\u7de3\u7121\u7dda\u7db2\u8def\u4e2d\u7684\u5feb\u53d6\u547d\u4e2d\u7387\u3002\u6211\u5011\u8b49\u660e\u4e86\u6240\u5236\u5b9a\u7684\u554f\u984c\u662f\u4e00\u500b\u5177\u6709\u6b21\u6a21\u7d04\u675f\u7684\u6b21\u6a21\u6700\u5927\u5316\u554f\u984c\uff0c\u4e0d\u5b58\u5728\u591a\u9805\u5f0f\u6642\u9593\u8fd1\u4f3c\u6f14\u7b97\u6cd5\u3002\u70ba\u4e86\u514b\u670d\u9019\u500b\u6311\u6230\uff0c\u6211\u5011\u7814\u7a76\u4e86\u4e00\u500b\u91cd\u8981\u7684\u7279\u4f8b\uff0c\u5176\u4e2d\u6a21\u578b\u4e4b\u9593\u5171\u4eab\u5c11\u91cf\u56fa\u5b9a\u7684\u53c3\u6578\u5340\u584a\uff0c\u9019\u5728\u5be6\u52d9\u4e0a\u7d93\u5e38\u6210\u7acb\u3002\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u958b\u767c\u4e86\u4e00\u500b\u5177\u6709 $\\left(1-\\epsilon\\right)/2$ \u8fd1\u4f3c\u4fdd\u8b49\u7684\u591a\u9805\u5f0f\u6642\u9593\u6f14\u7b97\u6cd5\u3002\u96a8\u5f8c\uff0c\u6211\u5011\u900f\u904e\u958b\u767c\u8caa\u5a6a\u6f14\u7b97\u6cd5\u4f86\u89e3\u6c7a\u4e00\u822c\u60c5\u6cc1\u4e0b\u7684\u539f\u59cb\u554f\u984c\u3002\u6a21\u64ec\u7d50\u679c\u8b49\u660e\uff0c\u8207\u4e0d\u5229\u7528 AI \u6a21\u578b\u4e2d\u5171\u4eab\u53c3\u6578\u7684\u6700\u65b0\u5167\u5bb9\u5feb\u53d6\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684 TrimCaching \u67b6\u69cb\u986f\u8457\u63d0\u9ad8\u4e86\u5feb\u53d6\u547d\u4e2d\u7387\u3002", "author": "Guanqiao Qu et.al.", "authors": "Guanqiao Qu, Zheng Lin, Fangming Liu, Xianhao Chen, Kaibin Huang", "id": "2405.03990v1", "paper_url": "http://arxiv.org/abs/2405.03990v1", "repo": "null"}}