{"2410.05629": {"publish_time": "2024-10-08", "title": "Vector-ICL: In-context Learning with Continuous Vector Representations", "paper_summary": "Large language models (LLMs) have shown remarkable in-context learning (ICL)\ncapabilities on textual data. We explore whether these capabilities can be\nextended to continuous vectors from diverse domains, obtained from black-box\npretrained encoders. By aligning input data with an LLM's embedding space\nthrough lightweight projectors, we observe that LLMs can effectively process\nand learn from these projected vectors, which we term Vector-ICL. In\nparticular, we find that pretraining projectors with general language modeling\nobjectives enables Vector-ICL, while task-specific finetuning further enhances\nperformance. In our experiments across various tasks and modalities, including\ntext reconstruction, numerical function regression, text classification,\nsummarization, molecule captioning, time-series classification, graph\nclassification, and fMRI decoding, Vector-ICL often surpasses both few-shot ICL\nand domain-specific model or tuning. We further conduct analyses and case\nstudies, indicating the potential of LLMs to process vector representations\nbeyond traditional token-based paradigms.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u6587\u672c\u8cc7\u6599\u4e0a\u5c55\u73fe\u51fa\u986f\u8457\u7684\u8a9e\u5883\u5b78\u7fd2 (ICL) \u80fd\u529b\u3002\u6211\u5011\u63a2\u8a0e\u9019\u4e9b\u80fd\u529b\u662f\u5426\u53ef\u4ee5\u64f4\u5c55\u5230\u5f9e\u4e0d\u540c\u9818\u57df\u53d6\u5f97\uff0c\u4e26\u7531\u9ed1\u7bb1\u9810\u8a13\u7df4\u7de8\u78bc\u5668\u7372\u5f97\u7684\u9023\u7e8c\u5411\u91cf\u3002\u900f\u904e\u8f15\u91cf\u7d1a\u6295\u5f71\u5668\u5c07\u8f38\u5165\u8cc7\u6599\u8207 LLM \u7684\u5d4c\u5165\u7a7a\u9593\u5c0d\u9f4a\uff0c\u6211\u5011\u89c0\u5bdf\u5230 LLM \u53ef\u4ee5\u6709\u6548\u5730\u8655\u7406\u548c\u5b78\u7fd2\u9019\u4e9b\u6295\u5f71\u5411\u91cf\uff0c\u6211\u5011\u7a31\u4e4b\u70ba Vector-ICL\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u767c\u73fe\u4f7f\u7528\u4e00\u822c\u8a9e\u8a00\u5efa\u6a21\u76ee\u6a19\u9810\u8a13\u7df4\u6295\u5f71\u5668\u53ef\u4ee5\u555f\u7528 Vector-ICL\uff0c\u800c\u7279\u5b9a\u4efb\u52d9\u7684\u5fae\u8abf\u9032\u4e00\u6b65\u63d0\u5347\u4e86\u6548\u80fd\u3002\u5728\u6211\u5011\u8de8\u8d8a\u5404\u7a2e\u4efb\u52d9\u548c\u6a21\u614b\u7684\u5be6\u9a57\u4e2d\uff0c\u5305\u62ec\u6587\u5b57\u91cd\u5efa\u3001\u6578\u503c\u51fd\u6578\u56de\u6b78\u3001\u6587\u5b57\u5206\u985e\u3001\u6458\u8981\u3001\u5206\u5b50\u6a19\u984c\u3001\u6642\u9593\u5e8f\u5217\u5206\u985e\u3001\u5716\u5f62\u5206\u985e\u548c fMRI \u89e3\u78bc\uff0cVector-ICL \u901a\u5e38\u90fd\u512a\u65bc\u5c11\u6b21\u6578 ICL \u548c\u7279\u5b9a\u9818\u57df\u6a21\u578b\u6216\u8abf\u6574\u3002\u6211\u5011\u9032\u4e00\u6b65\u9032\u884c\u5206\u6790\u548c\u6848\u4f8b\u7814\u7a76\uff0c\u6307\u51fa LLM \u8655\u7406\u5411\u91cf\u8868\u793a\u7684\u6f5b\u529b\uff0c\u8d85\u8d8a\u50b3\u7d71\u7684\u57fa\u65bc\u6a19\u8a18\u7684\u7bc4\u4f8b\u3002", "author": "Yufan Zhuang et.al.", "authors": "Yufan Zhuang, Chandan Singh, Liyuan Liu, Jingbo Shang, Jianfeng Gao", "id": "2410.05629v1", "paper_url": "http://arxiv.org/abs/2410.05629v1", "repo": "null"}}