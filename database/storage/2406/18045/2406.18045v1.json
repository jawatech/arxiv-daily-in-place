{"2406.18045": {"publish_time": "2024-06-26", "title": "PharmGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical and Chemistry", "paper_summary": "Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP) by by minimizing the need for complex feature engineering. However, the\napplication of LLMs in specialized domains like biopharmaceuticals and\nchemistry remains largely unexplored. These fields are characterized by\nintricate terminologies, specialized knowledge, and a high demand for precision\nareas where general purpose LLMs often fall short. In this study, we introduce\nPharmGPT, a suite of multilingual LLMs with 13 billion and 70 billion\nparameters, specifically trained on a comprehensive corpus of hundreds of\nbillions of tokens tailored to the Bio-Pharmaceutical and Chemical sectors. Our\nevaluation shows that PharmGPT matches or surpasses existing general models on\nkey benchmarks, such as NAPLEX, demonstrating its exceptional capability in\ndomain-specific tasks. This advancement establishes a new benchmark for LLMs in\nthe Bio-Pharmaceutical and Chemical fields, addressing the existing gap in\nspecialized language modeling. Furthermore, this suggests a promising path for\nenhanced research and development in these specialized areas, paving the way\nfor more precise and effective applications of NLP in specialized domains.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u900f\u904e\u6e1b\u5c11\u8907\u96dc\u7279\u5fb5\u5de5\u7a0b\u7684\u9700\u6c42\uff0c\u5fb9\u5e95\u6539\u8b8a\u4e86\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP)\u3002\u7136\u800c\uff0cLLM \u5728\u751f\u7269\u88fd\u85e5\u548c\u5316\u5b78\u7b49\u5c08\u696d\u9818\u57df\u7684\u61c9\u7528\u4ecd\u672a\u5ee3\u6cdb\u63a2\u8a0e\u3002\u9019\u4e9b\u9818\u57df\u7684\u7279\u9ede\u662f\u8853\u8a9e\u7e41\u96dc\u3001\u77e5\u8b58\u5c08\u696d\uff0c\u4e14\u5c0d\u7cbe\u6e96\u5ea6\u6709\u5f88\u9ad8\u7684\u9700\u6c42\uff0c\u800c\u9019\u6b63\u662f\u901a\u7528 LLM \u5e38\u7121\u6cd5\u9054\u5230\u7684\u3002\u5728\u6b64\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63a8\u51fa\u4e86 PharmGPT\uff0c\u9019\u662f\u4e00\u7a2e\u591a\u8a9e\u8a00 LLM \u5957\u4ef6\uff0c\u5177\u6709 130 \u5104\u548c 700 \u5104\u500b\u53c3\u6578\uff0c\u7279\u5225\u91dd\u5c0d\u6578\u767e\u5104\u500b\u5c08\u9580\u91dd\u5c0d\u751f\u7269\u88fd\u85e5\u548c\u5316\u5b78\u9818\u57df\u7684\u8a9e\u6599\u5eab\u9032\u884c\u8a13\u7df4\u3002\u6211\u5011\u7684\u8a55\u4f30\u986f\u793a\uff0cPharmGPT \u5728\u95dc\u9375\u57fa\u6e96\u4e0a\uff08\u4f8b\u5982 NAPLEX\uff09\u8207\u73fe\u6709\u7684\u901a\u7528\u6a21\u578b\u76f8\u5339\u914d\u6216\u8d85\u8d8a\u5b83\u5011\uff0c\u8b49\u660e\u4e86\u5176\u5728\u7279\u5b9a\u9818\u57df\u4efb\u52d9\u4e2d\u7684\u51fa\u8272\u80fd\u529b\u3002\u9019\u9805\u9032\u5c55\u70ba\u751f\u7269\u88fd\u85e5\u548c\u5316\u5b78\u9818\u57df\u7684 LLM \u5efa\u7acb\u4e86\u4e00\u500b\u65b0\u7684\u57fa\u6e96\uff0c\u89e3\u6c7a\u4e86\u5c08\u696d\u8a9e\u8a00\u5efa\u6a21\u4e2d\u73fe\u6709\u7684\u5dee\u8ddd\u3002\u6b64\u5916\uff0c\u9019\u4e5f\u70ba\u9019\u4e9b\u5c08\u696d\u9818\u57df\u7684\u52a0\u5f37\u7814\u7a76\u548c\u958b\u767c\u6307\u51fa\u4e00\u689d\u6709\u524d\u666f\u7684\u9053\u8def\uff0c\u70ba NLP \u5728\u5c08\u696d\u9818\u57df\u4e2d\u66f4\u7cbe\u6e96\u3001\u66f4\u6709\u6548\u7684\u61c9\u7528\u92ea\u8def\u3002", "author": "Linqing Chen et.al.", "authors": "Linqing Chen, Weilei Wang, Zilong Bai, Peng Xu, Yan Fang, Jie Fang, Wentao Wu, Lizhi Zhou, Ruiji Zhang, Yubin Xia, Chaobo Xu, Ran Hu, Licong Xu, Qijun Cai, Haoran Hua, Jing Sun, Jin Liu, Tian Qiu, Haowen Liu, Meng Hu, Xiuwen Li, Fei Gao, Yufu Wang, Lin Tie, Chaochao Wang, Jianping Lu, Cheng Sun, Yixin Wang, Shengjie Yang, Yuancheng Li, Lu Jin, Lisha Zhang, Fu Bian, Changyang Tu", "id": "2406.18045v1", "paper_url": "http://arxiv.org/abs/2406.18045v1", "repo": "null"}}