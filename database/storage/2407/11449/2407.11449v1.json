{"2407.11449": {"publish_time": "2024-07-16", "title": "Controllable Contextualized Image Captioning: Directing the Visual Narrative through User-Defined Highlights", "paper_summary": "Contextualized Image Captioning (CIC) evolves traditional image captioning\ninto a more complex domain, necessitating the ability for multimodal reasoning.\nIt aims to generate image captions given specific contextual information. This\npaper further introduces a novel domain of Controllable Contextualized Image\nCaptioning (Ctrl-CIC). Unlike CIC, which solely relies on broad context,\nCtrl-CIC accentuates a user-defined highlight, compelling the model to tailor\ncaptions that resonate with the highlighted aspects of the context. We present\ntwo approaches, Prompting-based Controller (P-Ctrl) and Recalibration-based\nController (R-Ctrl), to generate focused captions. P-Ctrl conditions the model\ngeneration on highlight by prepending captions with highlight-driven prefixes,\nwhereas R-Ctrl tunes the model to selectively recalibrate the encoder\nembeddings for highlighted tokens. Additionally, we design a GPT-4V empowered\nevaluator to assess the quality of the controlled captions alongside standard\nassessment methods. Extensive experimental results demonstrate the efficient\nand effective controllability of our method, charting a new direction in\nachieving user-adaptive image captioning. Code is available at\nhttps://github.com/ShunqiM/Ctrl-CIC .", "paper_summary_zh": "\u8bed\u5883\u56fe\u50cf\u63cf\u8ff0 (CIC) \u5c06\u4f20\u7edf\u56fe\u50cf\u63cf\u8ff0\u6f14\u53d8\u4e3a\u66f4\u590d\u6742\u7684\u9886\u57df\uff0c\u9700\u8981\u591a\u6a21\u6001\u63a8\u7406\u7684\u80fd\u529b\u3002\u5b83\u65e8\u5728\u6839\u636e\u7279\u5b9a\u7684\u8bed\u5883\u4fe1\u606f\u751f\u6210\u56fe\u50cf\u63cf\u8ff0\u3002\u672c\u6587\u8fdb\u4e00\u6b65\u4ecb\u7ecd\u4e86\u53ef\u63a7\u8bed\u5883\u56fe\u50cf\u63cf\u8ff0 (Ctrl-CIC) \u7684\u4e00\u4e2a\u65b0\u9886\u57df\u3002\u4e0e\u4ec5\u4f9d\u8d56\u5e7f\u6cdb\u8bed\u5883\u7684 CIC \u4e0d\u540c\uff0cCtrl-CIC \u5f3a\u8c03\u7528\u6237\u5b9a\u4e49\u7684\u91cd\u70b9\uff0c\u8feb\u4f7f\u6a21\u578b\u5b9a\u5236\u4e0e\u8bed\u5883\u4e2d\u7a81\u51fa\u65b9\u9762\u4ea7\u751f\u5171\u9e23\u7684\u63cf\u8ff0\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff0c\u57fa\u4e8e\u63d0\u793a\u7684\u63a7\u5236\u5668 (P-Ctrl) \u548c\u57fa\u4e8e\u91cd\u65b0\u6821\u51c6\u7684\u63a7\u5236\u5668 (R-Ctrl)\uff0c\u4ee5\u751f\u6210\u91cd\u70b9\u63cf\u8ff0\u3002P-Ctrl \u901a\u8fc7\u4f7f\u7528\u7a81\u51fa\u9a71\u52a8\u7684\u524d\u7f00\u6765\u6dfb\u52a0\u7a81\u51fa\u663e\u793a\uff0c\u5bf9\u6a21\u578b\u751f\u6210\u8fdb\u884c\u6761\u4ef6\u5316\uff0c\u800c R-Ctrl \u8c03\u6574\u6a21\u578b\u4ee5\u9009\u62e9\u6027\u5730\u91cd\u65b0\u6821\u51c6\u7a81\u51fa\u6807\u8bb0\u7684\u7f16\u7801\u5668\u5d4c\u5165\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7531 GPT-4V \u9a71\u52a8\u7684\u8bc4\u4f30\u5668\u6765\u8bc4\u4f30\u53d7\u63a7\u63cf\u8ff0\u7684\u8d28\u91cf\u4ee5\u53ca\u6807\u51c6\u8bc4\u4f30\u65b9\u6cd5\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u9ad8\u6548\u548c\u6709\u6548\u53ef\u63a7\u6027\uff0c\u4e3a\u5b9e\u73b0\u7528\u6237\u81ea\u9002\u5e94\u56fe\u50cf\u63cf\u8ff0\u6307\u660e\u4e86\u4e00\u4e2a\u65b0\u65b9\u5411\u3002\u4ee3\u7801\u53ef\u5728 https://github.com/ShunqiM/Ctrl-CIC \u83b7\u5f97\u3002", "author": "Shunqi Mao et.al.", "authors": "Shunqi Mao, Chaoyi Zhang, Hang Su, Hwanjun Song, Igor Shalyminov, Weidong Cai", "id": "2407.11449v1", "paper_url": "http://arxiv.org/abs/2407.11449v1", "repo": "null"}}