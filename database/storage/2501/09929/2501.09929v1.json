{"2501.09929": {"publish_time": "2025-01-17", "title": "Steering Large Language Models with Feature Guided Activation Additions", "paper_summary": "Effective and reliable control over large language model (LLM) behavior is a\nsignificant challenge. While activation steering methods, which add steering\nvectors to a model's hidden states, are a promising approach, existing\ntechniques often lack precision and interpretability in how they influence\nmodel outputs. We introduce Feature Guided Activation Additions (FGAA), a novel\nactivation steering method that leverages insights from Contrastive Activation\nAddition (CAA) and Sparse Autoencoder-Targeted Steering (SAE-TS). By operating\nin the latent space of a Sparse Autoencoder (SAE) and employing optimization\ntechniques to select desired SAE features, FGAA constructs precise steering\nvectors that provide better steering effects while maintaining coherence of\nsteered model outputs. In this regard, evaluations on Gemma-2-2B and Gemma-2-9B\nmodels across various steering tasks demonstrate that FGAA outperforms existing\nsteering methods of CAA, SAE decoder steering, and SAE-TS. Our results also\nhighlight important trade-offs between steering scale and general model\ncapabilities that are consistent across all tested steering methods.", "paper_summary_zh": "\u6709\u6548\u4e14\u53ef\u9760\u5730\u63a7\u5236\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u884c\u4e3a\u662f\u4e00\u9879\u91cd\u5927\u6311\u6218\u3002\u867d\u7136\u6fc0\u6d3b\u8f6c\u5411\u65b9\u6cd5\uff08\u5411\u6a21\u578b\u7684\u9690\u85cf\u72b6\u6001\u6dfb\u52a0\u8f6c\u5411\u5411\u91cf\uff09\u662f\u4e00\u79cd\u6709\u524d\u9014\u7684\u65b9\u6cd5\uff0c\u4f46\u73b0\u6709\u6280\u672f\u5728\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\u65b9\u9762\u5f80\u5f80\u7f3a\u4e4f\u7cbe\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u6211\u4eec\u5f15\u5165\u4e86\u7279\u5f81\u5f15\u5bfc\u6fc0\u6d3b\u52a0\u6cd5 (FGAA)\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6fc0\u6d3b\u8f6c\u5411\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u4e86\u5bf9\u6bd4\u6fc0\u6d3b\u52a0\u6cd5 (CAA) \u548c\u7a00\u758f\u81ea\u7f16\u7801\u5668\u76ee\u6807\u8f6c\u5411 (SAE-TS) \u7684\u89c1\u89e3\u3002\u901a\u8fc7\u5728\u7a00\u758f\u81ea\u7f16\u7801\u5668 (SAE) \u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u64cd\u4f5c\u5e76\u91c7\u7528\u4f18\u5316\u6280\u672f\u6765\u9009\u62e9\u6240\u9700\u7684 SAE \u7279\u5f81\uff0cFGAA \u6784\u5efa\u4e86\u7cbe\u786e\u7684\u8f6c\u5411\u5411\u91cf\uff0c\u8fd9\u4e9b\u5411\u91cf\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u8f6c\u5411\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8f6c\u5411\u6a21\u578b\u8f93\u51fa\u7684\u4e00\u81f4\u6027\u3002\u5728\u8fd9\u65b9\u9762\uff0c\u5bf9 Gemma-2-2B \u548c Gemma-2-9B \u6a21\u578b\u5728\u5404\u79cd\u8f6c\u5411\u4efb\u52a1\u4e2d\u7684\u8bc4\u4f30\u8868\u660e\uff0cFGAA \u4f18\u4e8e\u73b0\u6709\u7684 CAA \u8f6c\u5411\u65b9\u6cd5\u3001SAE \u89e3\u7801\u5668\u8f6c\u5411\u548c SAE-TS\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8fd8\u5f3a\u8c03\u4e86\u6240\u6709\u6d4b\u8bd5\u8f6c\u5411\u65b9\u6cd5\u4e2d\u8f6c\u5411\u89c4\u6a21\u548c\u4e00\u822c\u6a21\u578b\u80fd\u529b\u4e4b\u95f4\u91cd\u8981\u7684\u6743\u8861\u3002", "author": "Samuel Soo et.al.", "authors": "Samuel Soo, Wesley Teng, Chandrasekaran Balaganesh", "id": "2501.09929v1", "paper_url": "http://arxiv.org/abs/2501.09929v1", "repo": "null"}}