{"2501.02649": {"publish_time": "2025-01-05", "title": "Tighnari: Multi-modal Plant Species Prediction Based on Hierarchical Cross-Attention Using Graph-Based and Vision Backbone-Extracted Features", "paper_summary": "Predicting plant species composition in specific spatiotemporal contexts\nplays an important role in biodiversity management and conservation, as well as\nin improving species identification tools. Our work utilizes 88,987 plant\nsurvey records conducted in specific spatiotemporal contexts across Europe. We\nalso use the corresponding satellite images, time series data, climate time\nseries, and other rasterized environmental data such as land cover, human\nfootprint, bioclimatic, and soil variables as training data to train the model\nto predict the outcomes of 4,716 plant surveys. We propose a feature\nconstruction and result correction method based on the graph structure. Through\ncomparative experiments, we select the best-performing backbone networks for\nfeature extraction in both temporal and image modalities. In this process, we\nbuilt a backbone network based on the Swin-Transformer Block for extracting\ntemporal Cubes features. We then design a hierarchical cross-attention\nmechanism capable of robustly fusing features from multiple modalities. During\ntraining, we adopt a 10-fold cross-fusion method based on fine-tuning and use a\nThreshold Top-K method for post-processing. Ablation experiments demonstrate\nthe improvements in model performance brought by our proposed solution\npipeline.", "paper_summary_zh": "\u9810\u6e2c\u7279\u5b9a\u6642\u7a7a\u80cc\u666f\u4e0b\u7684\u690d\u7269\u7269\u7a2e\u7d44\u6210\u5728\u751f\u7269\u591a\u6a23\u6027\u7ba1\u7406\u548c\u4fdd\u80b2\u4e2d\u626e\u6f14\u8457\u91cd\u8981\u7684\u89d2\u8272\uff0c\u4e5f\u80fd\u6539\u5584\u7269\u7a2e\u8b58\u5225\u5de5\u5177\u3002\u6211\u5011\u7684\u7814\u7a76\u5229\u7528\u4e86\u5728\u6b50\u6d32\u7279\u5b9a\u6642\u7a7a\u80cc\u666f\u4e0b\u9032\u884c\u7684 88,987 \u7b46\u690d\u7269\u8abf\u67e5\u8a18\u9304\u3002\u6211\u5011\u4e5f\u4f7f\u7528\u5c0d\u61c9\u7684\u885b\u661f\u5f71\u50cf\u3001\u6642\u9593\u5e8f\u5217\u8cc7\u6599\u3001\u6c23\u5019\u6642\u9593\u5e8f\u5217\uff0c\u4ee5\u53ca\u5176\u4ed6\u5149\u67f5\u5316\u7684\u74b0\u5883\u8cc7\u6599\uff0c\u4f8b\u5982\u571f\u5730\u8986\u84cb\u3001\u4eba\u985e\u8db3\u8de1\u3001\u751f\u7269\u6c23\u5019\u548c\u571f\u58e4\u8b8a\u6578\uff0c\u4f5c\u70ba\u8a13\u7df4\u8cc7\u6599\u4f86\u8a13\u7df4\u6a21\u578b\uff0c\u9810\u6e2c 4,716 \u7b46\u690d\u7269\u8abf\u67e5\u7684\u7d50\u679c\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u5716\u5f62\u7d50\u69cb\u7684\u7279\u5fb5\u5efa\u69cb\u548c\u7d50\u679c\u4fee\u6b63\u65b9\u6cd5\u3002\u900f\u904e\u6bd4\u8f03\u5be6\u9a57\uff0c\u6211\u5011\u9078\u51fa\u5728\u6642\u9593\u548c\u5f71\u50cf\u6a21\u5f0f\u4e2d\u7279\u5fb5\u8403\u53d6\u8868\u73fe\u6700\u4f73\u7684\u4e3b\u5e79\u7db2\u8def\u3002\u5728\u6b64\u904e\u7a0b\u4e2d\uff0c\u6211\u5011\u5efa\u69cb\u4e86\u4e00\u500b\u57fa\u65bc Swin-Transformer Block \u7684\u4e3b\u5e79\u7db2\u8def\uff0c\u7528\u65bc\u8403\u53d6\u6642\u9593\u7acb\u65b9\u9ad4\u7279\u5fb5\u3002\u63a5\u8457\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u968e\u5c64\u5f0f\u4ea4\u53c9\u6ce8\u610f\u529b\u6a5f\u5236\uff0c\u80fd\u5920\u7a69\u5065\u5730\u878d\u5408\u4f86\u81ea\u591a\u7a2e\u6a21\u5f0f\u7684\u7279\u5fb5\u3002\u5728\u8a13\u7df4\u671f\u9593\uff0c\u6211\u5011\u63a1\u7528\u57fa\u65bc\u5fae\u8abf\u7684 10 \u500d\u4ea4\u53c9\u878d\u5408\u65b9\u6cd5\uff0c\u4e26\u4f7f\u7528\u95be\u503c Top-K \u65b9\u6cd5\u9032\u884c\u5f8c\u8655\u7406\u3002\u6d88\u878d\u5be6\u9a57\u8b49\u660e\u4e86\u6211\u5011\u63d0\u51fa\u7684\u89e3\u6c7a\u65b9\u6848\u7ba1\u9053\u6539\u5584\u4e86\u6a21\u578b\u6548\u80fd\u3002", "author": "Haixu Liu et.al.", "authors": "Haixu Liu, Penghao Jiang, Zerui Tao, Muyan Wan, Qiuzhuang Sun", "id": "2501.02649v1", "paper_url": "http://arxiv.org/abs/2501.02649v1", "repo": "null"}}