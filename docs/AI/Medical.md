
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-13**|**Generative AI in Medicine**|Divya Shanmugam et.al.|[2412.10337v1](http://arxiv.org/abs/2412.10337v1)|null|
|**2024-12-13**|**A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**|Ayush Deshmukh et.al.|[2412.10106v1](http://arxiv.org/abs/2412.10106v1)|null|
|**2024-12-13**|**Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**|Tao Song et.al.|[2412.09998v1](http://arxiv.org/abs/2412.09998v1)|null|
|**2024-12-13**|**Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**|Qiao Sun et.al.|[2412.09946v1](http://arxiv.org/abs/2412.09946v1)|null|
|**2024-12-12**|**Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis**|Shengxuming Zhang et.al.|[2412.09521v1](http://arxiv.org/abs/2412.09521v1)|null|
|**2024-12-12**|**Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine**|Xiaoshuang Huang et.al.|[2412.09278v1](http://arxiv.org/abs/2412.09278v1)|[link](https://github.com/shawnhuang497/medplib)|
|**2024-12-12**|**CSSDH: An Ontology for Social Determinants of Health to Operational Continuity of Care Data Interoperability**|Subhashis Das et.al.|[2412.09223v1](http://arxiv.org/abs/2412.09223v1)|null|
|**2024-12-12**|**Understanding Opportunities and Risks of Synthetic Relationships: Leveraging the Power of Longitudinal Research with Customised AI Tools**|Alfio Ventura et.al.|[2412.09086v1](http://arxiv.org/abs/2412.09086v1)|null|
|**2024-12-12**|**Radiology Report Generation via Multi-objective Preference Optimization**|Ting Xiao et.al.|[2412.08901v2](http://arxiv.org/abs/2412.08901v2)|null|
|**2024-12-12**|**AI-assisted Knowledge Discovery in Biomedical Literature to Support Decision-making in Precision Oncology**|Ting He et.al.|[2412.08900v1](http://arxiv.org/abs/2412.08900v1)|null|
|**2024-12-12**|**Towards modeling evolving longitudinal health trajectories with a transformer-based deep learning model**|Hans Moen et.al.|[2412.08873v1](http://arxiv.org/abs/2412.08873v1)|null|
|**2024-12-11**|**Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions**|Jiarui Zhang et.al.|[2412.08737v1](http://arxiv.org/abs/2412.08737v1)|null|
|**2024-12-11**|**Assisted morbidity coding: the SISCO.web use case for identifying the main diagnosis in Hospital Discharge Records**|Elena Cardillo et.al.|[2412.09651v1](http://arxiv.org/abs/2412.09651v1)|null|
|**2024-12-11**|**IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**|Gauri Jain et.al.|[2412.08463v1](http://arxiv.org/abs/2412.08463v1)|[link](https://github.com/gjain234/whirl)|
|**2024-12-11**|**SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**|Sultan Alrashed et.al.|[2412.08347v1](http://arxiv.org/abs/2412.08347v1)|null|
|**2024-12-11**|**Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures**|Célia Blondin et.al.|[2412.08228v1](http://arxiv.org/abs/2412.08228v1)|[link](https://github.com/celia-bl/hierarchical_classifying_corals_dataset)|
|**2024-12-11**|**How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**|Yixin Zhang et.al.|[2412.08081v1](http://arxiv.org/abs/2412.08081v1)|null|
|**2024-12-11**|**Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning**|Chongyi Zheng et.al.|[2412.08021v1](http://arxiv.org/abs/2412.08021v1)|[link](https://github.com/Princeton-RL/contrastive-successor-features)|
|**2024-12-10**|**From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents**|Mohit Chandra et.al.|[2412.07951v2](http://arxiv.org/abs/2412.07951v2)|null|
|**2024-12-10**|**How Should We Represent History in Interpretable Models of Clinical Policies?**|Anton Matsson et.al.|[2412.07895v1](http://arxiv.org/abs/2412.07895v1)|[link](https://github.com/Healthy-AI/inpole)|
|**2024-12-10**|**Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact**|Yunfan Zhao et.al.|[2412.07880v2](http://arxiv.org/abs/2412.07880v2)|null|
|**2024-12-10**|**Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG**|Shivraj Singh Bhatti et.al.|[2412.07878v1](http://arxiv.org/abs/2412.07878v1)|null|
|**2024-12-10**|**Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**|Marcos Da Silveira et.al.|[2412.09644v1](http://arxiv.org/abs/2412.09644v1)|null|
|**2024-12-10**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618v1](http://arxiv.org/abs/2412.07618v1)|[link](https://github.com/futureeeeee/dynamic-rag)|
|**2024-12-10**|**Scaling Sequential Recommendation Models with Transformers**|Pablo Zivic et.al.|[2412.07585v1](http://arxiv.org/abs/2412.07585v1)|[link](https://github.com/mercadolibre/srt)|
|**2024-12-10**|**Knowledge Graph Guided Evaluation of Abstention Techniques**|Kinshuk Vasisht et.al.|[2412.07430v1](http://arxiv.org/abs/2412.07430v1)|null|
|**2024-12-10**|**A Review of Challenges in Speech-based Conversational AI for Elderly Care**|Willemijn Klaassen et.al.|[2412.07388v1](http://arxiv.org/abs/2412.07388v1)|null|
|**2024-12-10**|**Enhanced MRI Representation via Cross-series Masking**|Churan Wang et.al.|[2412.07387v1](http://arxiv.org/abs/2412.07387v1)|null|
|**2024-12-10**|**On Evaluating the Durability of Safeguards for Open-Weight LLMs**|Xiangyu Qi et.al.|[2412.07097v1](http://arxiv.org/abs/2412.07097v1)|[link](https://github.com/ai-law-society-lab/evaluating-durable-safeguards)|
|**2024-12-09**|**Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**|Le Song et.al.|[2412.06993v1](http://arxiv.org/abs/2412.06993v1)|[link](https://github.com/genbio-ai/aido)|
|**2024-12-09**|**Diagnosis and Severity Assessment of Ulcerative Colitis using Self Supervised Learning**|Venkat Margapuri et.al.|[2412.07806v1](http://arxiv.org/abs/2412.07806v1)|null|
|**2024-12-09**|**Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**|Sahil Sethi et.al.|[2412.06717v1](http://arxiv.org/abs/2412.06717v1)|null|
|**2024-12-09**|**Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**|Aqib Nazir Mir et.al.|[2412.06709v1](http://arxiv.org/abs/2412.06709v1)|null|
|**2024-12-09**|**Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**|Sooyong Jang et.al.|[2412.06624v1](http://arxiv.org/abs/2412.06624v1)|[link](https://github.com/precise-ai4oph/va_pred_pac)|
|**2024-12-09**|**Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices**|Biman Barua et.al.|[2412.06874v1](http://arxiv.org/abs/2412.06874v1)|null|
|**2024-12-09**|**Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System**|Yubo Zhou et.al.|[2412.06600v2](http://arxiv.org/abs/2412.06600v2)|[link](https://github.com/everydaylucky/wu_xing_harmony_system)|
|**2024-12-09**|**HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**|Jiayan Chen et.al.|[2412.06530v1](http://arxiv.org/abs/2412.06530v1)|null|
|**2024-12-09**|**Simulating Human-like Daily Activities with Desire-driven Autonomy**|Yiding Wang et.al.|[2412.06435v1](http://arxiv.org/abs/2412.06435v1)|null|
|**2024-12-09**|**CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**|Yijie Dang et.al.|[2412.06314v1](http://arxiv.org/abs/2412.06314v1)|null|
|**2024-12-09**|**A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder**|Quansong He et.al.|[2412.06262v1](http://arxiv.org/abs/2412.06262v1)|[link](https://github.com/nayutayuki/lightweight-nmode-decoders-for-u-like-networks)|
|**2024-12-09**|**MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery**|Qinfeng Zhu et.al.|[2412.06211v1](http://arxiv.org/abs/2412.06211v1)|null|
|**2024-12-09**|**Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction**|Guoxiao Zhang et.al.|[2412.06860v1](http://arxiv.org/abs/2412.06860v1)|null|
|**2024-12-09**|**MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**|Kangyu Zhu et.al.|[2412.06141v1](http://arxiv.org/abs/2412.06141v1)|[link](https://github.com/aiming-lab/mmedpo)|
|**2024-12-08**|**Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research**|Akshat Choube et.al.|[2412.06018v1](http://arxiv.org/abs/2412.06018v1)|null|
|**2024-12-08**|**MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training**|Xuefeng Ni et.al.|[2412.05876v1](http://arxiv.org/abs/2412.05876v1)|[link](https://github.com/xuefeng-ni/mg-3d)|
|**2024-12-08**|**Evolving Algebraic Multigrid Methods Using Grammar-Guided Genetic Programming**|Dinesh Parthasarathy et.al.|[2412.05852v1](http://arxiv.org/abs/2412.05852v1)|null|
|**2024-12-07**|**Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages**|Abd Ur Rehman et.al.|[2412.05632v1](http://arxiv.org/abs/2412.05632v1)|null|
|**2024-12-07**|**UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation**|Saba Hesaraki et.al.|[2412.05585v1](http://arxiv.org/abs/2412.05585v1)|null|
|**2024-12-07**|**Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms**|Atit Pokharel et.al.|[2412.05583v2](http://arxiv.org/abs/2412.05583v2)|null|
|**2024-12-07**|**Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison**|Cailian Ruan et.al.|[2412.05536v1](http://arxiv.org/abs/2412.05536v1)|null|
|**2024-12-06**|**Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System**|Fang Zeng et.al.|[2412.06828v1](http://arxiv.org/abs/2412.06828v1)|null|
|**2024-12-06**|**Enhancing FKG.in: automating Indian food composition analysis**|Saransh Kumar Gupta et.al.|[2412.05248v2](http://arxiv.org/abs/2412.05248v2)|null|
|**2024-12-06**|**Are Frontier Large Language Models Suitable for Q&A in Science Centres?**|Jacob Watson et.al.|[2412.05200v1](http://arxiv.org/abs/2412.05200v1)|null|
|**2024-12-06**|**SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**|Jinlin Wu et.al.|[2412.05187v1](http://arxiv.org/abs/2412.05187v1)|[link](https://github.com/franciszchen/surgbox)|
|**2024-12-06**|**Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**|Thomas Sievers et.al.|[2412.05013v1](http://arxiv.org/abs/2412.05013v1)|null|
|**2024-12-06**|**Backdooring Outlier Detection Methods: A Novel Attack Approach**|ZeinabSadat Taghavi et.al.|[2412.05010v1](http://arxiv.org/abs/2412.05010v1)|null|
|**2024-12-06**|**Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**|Thomas Bartz-Beielstein et.al.|[2412.04950v1](http://arxiv.org/abs/2412.04950v1)|null|
|**2024-12-06**|**Estimating the treatment effect over time under general interference through deep learner integrated TMLE**|Suhan Guo et.al.|[2412.04799v1](http://arxiv.org/abs/2412.04799v1)|null|
|**2024-12-06**|**Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**|Mahfuzul Haque et.al.|[2412.04792v1](http://arxiv.org/abs/2412.04792v1)|null|
|**2024-12-06**|**DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**|Shadab Ahamed et.al.|[2412.04766v1](http://arxiv.org/abs/2412.04766v1)|null|
|**2024-12-06**|**PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**|Hongjin Lin et.al.|[2412.04714v1](http://arxiv.org/abs/2412.04714v1)|null|
|**2024-12-05**|**Semantic Consistency-Based Uncertainty Quantification for Factuality in Radiology Report Generation**|Chenyu Wang et.al.|[2412.04606v1](http://arxiv.org/abs/2412.04606v1)|null|
|**2024-12-05**|**CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations**|Subash Neupane et.al.|[2412.04254v1](http://arxiv.org/abs/2412.04254v1)|null|
|**2024-12-05**|**Automated Medical Report Generation for ECG Data: Bridging Medical Text and Signal Processing with Deep Learning**|Amnon Bleich et.al.|[2412.04067v1](http://arxiv.org/abs/2412.04067v1)|null|
|**2024-12-05**|**FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems**|Jiechao Gao et.al.|[2412.03851v1](http://arxiv.org/abs/2412.03851v1)|null|
|**2024-12-05**|**ELEMENT: Episodic and Lifelong Exploration via Maximum Entropy**|Hongming Li et.al.|[2412.03800v1](http://arxiv.org/abs/2412.03800v1)|null|
|**2024-12-05**|**Automated Multi-Label Annotation for Mental Health Illnesses Using Large Language Models**|Abdelrahaman A. Hassan et.al.|[2412.03796v1](http://arxiv.org/abs/2412.03796v1)|null|
|**2024-12-05**|**Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**|Yerin Choi et.al.|[2412.03784v1](http://arxiv.org/abs/2412.03784v1)|null|
|**2024-12-04**|**Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety**|Dilan Mian et.al.|[2412.03740v1](http://arxiv.org/abs/2412.03740v1)|null|
|**2024-12-04**|**MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities**|Haoning Wu et.al.|[2412.04106v1](http://arxiv.org/abs/2412.04106v1)|null|
|**2024-12-04**|**Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**|Yiqin Zhang et.al.|[2412.03352v1](http://arxiv.org/abs/2412.03352v1)|[link](https://github.com/mgamz/psbpd)|
|**2024-12-04**|**Detecting abnormal heart sound using mobile phones and on-device IConNet**|Linh Vu et.al.|[2412.03267v1](http://arxiv.org/abs/2412.03267v1)|null|
|**2024-12-04**|**MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**|Hyojeong Lee et.al.|[2412.03039v1](http://arxiv.org/abs/2412.03039v1)|null|
|**2024-12-04**|**Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**|Soroush Omranpour et.al.|[2412.02919v1](http://arxiv.org/abs/2412.02919v1)|null|
|**2024-12-03**|**A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**|Yixiang Qu et.al.|[2412.02868v1](http://arxiv.org/abs/2412.02868v1)|null|
|**2024-12-03**|**Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**|Oliver Simonoski et.al.|[2412.02851v1](http://arxiv.org/abs/2412.02851v1)|null|
|**2024-12-03**|**CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels**|Lingxiao Wei et.al.|[2412.02819v3](http://arxiv.org/abs/2412.02819v3)|null|
|**2024-12-03**|**Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**|Jingyuan Yi et.al.|[2412.02801v2](http://arxiv.org/abs/2412.02801v2)|null|
|**2024-12-03**|**Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**|Kai Sun et.al.|[2412.02621v1](http://arxiv.org/abs/2412.02621v1)|null|
|**2024-12-03**|**U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**|Fnu Neha et.al.|[2412.02242v1](http://arxiv.org/abs/2412.02242v1)|null|
|**2024-12-03**|**Recovering implicit physics model under real-world constraints**|Ayan Banerjee et.al.|[2412.02215v1](http://arxiv.org/abs/2412.02215v1)|null|
|**2024-12-03**|**Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**|Abu Bakar Siddik et.al.|[2412.02189v1](http://arxiv.org/abs/2412.02189v1)|null|
|**2024-12-03**|**Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**|R. Mahmood et.al.|[2412.02177v1](http://arxiv.org/abs/2412.02177v1)|null|
|**2024-12-03**|**Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**|Nader Karayanni et.al.|[2412.02173v1](http://arxiv.org/abs/2412.02173v1)|null|
|**2024-12-03**|**Construction and optimization of health behavior prediction model for the elderly in smart elderly care**|Qian Guo et.al.|[2412.02062v1](http://arxiv.org/abs/2412.02062v1)|null|
|**2024-12-02**|**INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**|Wenbo Zhang et.al.|[2412.02012v2](http://arxiv.org/abs/2412.02012v2)|null|
|**2024-12-02**|**The use of large language models to enhance cancer clinical trial educational materials**|Mingye Gao et.al.|[2412.01955v2](http://arxiv.org/abs/2412.01955v2)|null|
|**2024-12-02**|**Recurrent Neural Network on PICTURE Model**|Weihan Xu et.al.|[2412.01933v1](http://arxiv.org/abs/2412.01933v1)|null|
|**2024-12-02**|**ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**|Poorya Aghaomidi et.al.|[2412.01929v1](http://arxiv.org/abs/2412.01929v1)|null|
|**2024-12-02**|**Deep Guess acceleration for explainable image reconstruction in sparse-view CT**|Elena Loli Piccolomini et.al.|[2412.01703v1](http://arxiv.org/abs/2412.01703v1)|[link](https://github.com/devangelista2/DeepGuess)|
|**2024-12-02**|**Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**|Liza Dahiya et.al.|[2412.01692v1](http://arxiv.org/abs/2412.01692v1)|null|
|**2024-12-02**|**Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**|Jie Liu et.al.|[2412.01605v1](http://arxiv.org/abs/2412.01605v1)|null|
|**2024-12-02**|**NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**|Sandesh Pokhrel et.al.|[2412.01590v1](http://arxiv.org/abs/2412.01590v1)|[link](https://github.com/bhattarailab/ncdd)|
|**2024-12-02**|**MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**|Thi-Nhu-Quynh Nguyen et.al.|[2412.01405v1](http://arxiv.org/abs/2412.01405v1)|[link](https://github.com/nqnguyen812/mambau-lite)|
|**2024-12-02**|**Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**|Chayan Tank et.al.|[2412.01353v1](http://arxiv.org/abs/2412.01353v1)|null|
|**2024-12-02**|**Multimodal Medical Disease Classification with LLaMA II**|Christian Gapp et.al.|[2412.01306v1](http://arxiv.org/abs/2412.01306v1)|null|
|**2024-12-02**|**Best Practices for Large Language Models in Radiology**|Christian Bluethgen et.al.|[2412.01233v1](http://arxiv.org/abs/2412.01233v1)|null|
|**2024-12-02**|**Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**|Mojtaba S. Fazli et.al.|[2412.01119v1](http://arxiv.org/abs/2412.01119v1)|null|
|**2024-12-02**|**Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**|Razi Mahmood et.al.|[2412.01031v2](http://arxiv.org/abs/2412.01031v2)|null|
|**2024-12-01**|**Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**|Summra Saleem et.al.|[2412.00959v1](http://arxiv.org/abs/2412.00959v1)|null|

#### Abstracts
##### **Generative AI in Medicine**
2412.10337v1 by Divya Shanmugam, Monica Agrawal, Rajiv Movva, Irene Y. Chen, Marzyeh Ghassemi, Emma Pierson

The increased capabilities of generative AI have dramatically expanded its
possible use cases in medicine. We provide a comprehensive overview of
generative AI use cases for clinicians, patients, clinical trial organizers,
researchers, and trainees. We then discuss the many challenges -- including
maintaining privacy and security, improving transparency and interpretability,
upholding equity, and rigorously evaluating models -- which must be overcome to
realize this potential, and the open research directions they give rise to.

摘要：生成式 AI 的能力提升大幅擴展了其在醫學中的潛在應用案例。我們提供了一個全面的概觀，說明生成式 AI 在臨床醫生、患者、臨床試驗組織者、研究人員和受訓人員的應用案例。接著，我們討論了許多挑戰，包括維護隱私和安全性、提升透明度和可解釋性、維護公平性，以及嚴格評估模型，這些挑戰必須克服才能實現這種潛力，以及它們引發的開放研究方向。

##### **A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**
2412.10106v1 by Ayush Deshmukh

The global outbreak of Mpox virus, classified as a Public Health Emergency of
International Concern by WHO, presents significant diagnostic challenges due to
its visual similarity to other skin lesion diseases. Current clinical detection
techniques face limitations in accuracy and efficiency, necessitating improved
automated diagnostic solutions. This study introduces a novel Cascaded Atrous
Group Attention (CAGA) module, specifically designed to enhance multi-scale
feature representation while optimizing computational efficiency. By
integrating CAGA with EfficientViT-L1 as the backbone architecture, our
approach achieves state-of-the-art performance with a score of 0.98% on the
MCSI dataset, while reducing model parameters by 37.5% compared to the original
EfficientViT-L1. This reduction in computational complexity maintains
diagnostic accuracy while enabling broader deployment across
resource-constrained healthcare settings. Extensive validation across two other
benchmark datasets, including MSID and MSLD, demonstrate the model's
robustness, consistently outperforming existing approaches. Our findings
suggest that CAGA's efficient feature extraction mechanism could be adapted for
other medical imaging tasks requiring fine-grained visual discrimination.

摘要：由於世界衛生組織將猴痘病毒全球爆發定為國際關注的公共衛生緊急事件，因此猴痘病毒與其他皮膚病變疾病在視覺上的相似性，對診斷帶來重大挑戰。目前的臨床檢測技術在準確性和效率方面面臨限制，因此需要改進的自動化診斷解決方案。本研究引入了一個新穎的串聯空洞組注意力 (CAGA) 模組，專門設計用於增強多尺度特徵表示，同時最佳化運算效率。透過將 CAGA 與 EfficientViT-L1 整合作為主幹架構，我們的做法在 MCSI 資料集上以 0.98% 的分數達到了最先進的效能，同時與原始 EfficientViT-L1 相比，模型參數減少了 37.5%。這種運算複雜度的降低維持了診斷準確性，同時支援在資源受限的醫療保健環境中更廣泛地部署。在包括 MSID 和 MSLD 在內的另外兩個基準資料集上的廣泛驗證證明了模型的穩健性，始終優於現有方法。我們的研究結果表明，CAGA 的高效特徵提取機制可以調整為其他需要細緻視覺辨別的醫學影像任務。

##### **Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**
2412.09998v1 by Tao Song, Yicheng Wu, Minhao Hu, Xiangde Luo, Guoting Luo, Guotai Wang, Yi Guo, Feng Xu, Shaoting Zhang

Accelerated MRI reconstruction techniques aim to reduce examination time
while maintaining high image fidelity, which is highly desirable in clinical
settings for improving patient comfort and hospital efficiency. Existing deep
learning methods typically reconstruct images from under-sampled data with
traditional reconstruction approaches, but they still struggle to provide
high-fidelity results. Diffusion models show great potential to improve
fidelity of generated images in recent years. However, their inference process
starting with a random Gaussian noise introduces instability into the results
and usually requires thousands of sampling steps, resulting in sub-optimal
reconstruction quality and low efficiency. To address these challenges, we
propose Cycle-Consistent Bridge Diffusion Model (CBDM). CBDM employs two bridge
diffusion models to construct a cycle-consistent diffusion process with a
consistency loss, enhancing the fine-grained details of reconstructed images
and reducing the number of diffusion steps. Moreover, CBDM incorporates a
Contourlet Decomposition Embedding Module (CDEM) which captures multi-scale
structural texture knowledge in images through frequency domain decomposition
pyramids and directional filter banks to improve structural fidelity. Extensive
experiments demonstrate the superiority of our model by higher reconstruction
quality and fewer training iterations, achieving a new state of the art for
accelerated MRI reconstruction in both fastMRI and IXI datasets.

摘要：加速式 MRI 重建技術旨在縮短檢查時間，同時維持高影像保真度，這在臨床環境中非常理想，可提升病患舒適度和醫院效率。現有的深度學習方法通常使用傳統重建方法從欠採樣數據重建影像，但仍難以提供高保真度結果。擴散模型在近年展現出提升生成影像保真度的絕佳潛力。然而，其從隨機高斯雜訊開始的推論過程會為結果帶來不穩定性，且通常需要數千個採樣步驟，導致次最佳重建品質和低效率。為了應對這些挑戰，我們提出循環一致橋接擴散模型 (CBDM)。CBDM 使用兩個橋接擴散模型，建構一個具有相容性損失的循環一致擴散過程，增強重建影像的精細細節並減少擴散步驟的數量。此外，CBDM 整合了一個輪廓分解嵌入模組 (CDEM)，透過頻域分解金字塔和方向濾波器組在影像中擷取多尺度結構紋理知識，以提升結構保真度。廣泛的實驗證明了我們模型的優異性，具有更高的重建品質和更少的訓練反覆運算，在 fastMRI 和 IXI 資料集的加速式 MRI 重建中達成新的技術水準。

##### **Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**
2412.09946v1 by Qiao Sun, Jiexin Xie, Nanyang Ye, Qinying Gu, Shijie Guo

This paper explores the application of large language models (LLMs) in
nursing and elderly care, focusing on AI-driven patient monitoring and
interaction. We introduce a novel Chinese nursing dataset and implement
incremental pre-training (IPT) and supervised fine-tuning (SFT) techniques to
enhance LLM performance in specialized tasks. Using LangChain, we develop a
dynamic nursing assistant capable of real-time care and personalized
interventions. Experimental results demonstrate significant improvements,
paving the way for AI-driven solutions to meet the growing demands of
healthcare in aging populations.

摘要：本文探討大型語言模型 (LLM) 在護理和老年照護中的應用，重點在於 AI 驅動的病人監控和互動。我們引入了一個新穎的中文護理資料集，並實施增量預訓練 (IPT) 和監督微調 (SFT) 技術，以增強 LLM 在專業任務中的表現。使用 LangChain，我們開發了一個動態護理助理，能夠提供即時照護和個人化干預措施。實驗結果證明了顯著的改進，為 AI 驅動的解決方案鋪平了道路，以滿足老齡化人口對醫療保健日益增長的需求。

##### **Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis**
2412.09521v1 by Shengxuming Zhang, Weihan Li, Tianhong Gao, Jiacong Hu, Haoming Luo, Mingli Song, Xiuming Zhang, Zunlei Feng

Pathological diagnosis is vital for determining disease characteristics,
guiding treatment, and assessing prognosis, relying heavily on detailed,
multi-scale analysis of high-resolution whole slide images (WSI). However,
traditional pure vision models face challenges of redundant feature extraction,
whereas existing large vision-language models (LVLMs) are limited by input
resolution constraints, hindering their efficiency and accuracy. To overcome
these issues, we propose two innovative strategies: the mixed task-guided
feature enhancement, which directs feature extraction toward lesion-related
details across scales, and the prompt-guided detail feature completion, which
integrates coarse- and fine-grained features from WSI based on specific prompts
without compromising inference speed. Leveraging a comprehensive dataset of
490,000 samples from diverse pathology tasks-including cancer detection,
grading, vascular and neural invasion identification, and so on-we trained the
pathology-specialized LVLM, OmniPath. Extensive experiments demonstrate that
this model significantly outperforms existing methods in diagnostic accuracy
and efficiency, offering an interactive, clinically aligned approach for
auxiliary diagnosis in a wide range of pathology applications.

摘要：病理诊断对于确定疾病特征、指导治疗和评估预后至关重要，它严重依赖于对高分辨率全玻片图像 (WSI) 的详细、多尺度分析。然而，传统的纯视觉模型面临冗余特征提取的挑战，而现有的大型视觉语言模型 (LVLMs) 受到输入分辨率约束的限制，阻碍了它们的效率和准确性。为了克服这些问题，我们提出了两种创新策略：混合任务引导的特征增强，它将特征提取引导到跨尺度的病变相关细节上；以及提示引导的细节特征完成，它基于特定提示将 WSI 中的粗粒度和细粒度特征集成在一起，而不会影响推理速度。利用来自不同病理任务的 490,000 个样本的综合数据集，包括癌症检测、分级、血管和神经侵袭识别等，我们训练了病理学专业 LVLM，即 OmniPath。大量的实验表明，该模型在诊断准确性和效率方面明显优于现有方法，为广泛的病理学应用中的辅助诊断提供了一种交互式、临床上一致的方法。

##### **Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine**
2412.09278v1 by Xiaoshuang Huang, Lingdong Shen, Jia Liu, Fangxin Shang, Hongxiang Li, Haifeng Huang, Yehui Yang

In recent years, Multimodal Large Language Models (MLLM) have achieved
notable advancements, demonstrating the feasibility of developing an
intelligent biomedical assistant. However, current biomedical MLLMs
predominantly focus on image-level understanding and restrict interactions to
textual commands, thus limiting their capability boundaries and the flexibility
of usage. In this paper, we introduce a novel end-to-end multimodal large
language model for the biomedical domain, named MedPLIB, which possesses
pixel-level understanding. Excitingly, it supports visual question answering
(VQA), arbitrary pixel-level prompts (points, bounding boxes, and free-form
shapes), and pixel-level grounding. We propose a novel Mixture-of-Experts (MoE)
multi-stage training strategy, which divides MoE into separate training phases
for a visual-language expert model and a pixel-grounding expert model, followed
by fine-tuning using MoE. This strategy effectively coordinates multitask
learning while maintaining the computational cost at inference equivalent to
that of a single expert model. To advance the research of biomedical MLLMs, we
introduce the Medical Complex Vision Question Answering Dataset (MeCoVQA),
which comprises an array of 8 modalities for complex medical imaging question
answering and image region understanding. Experimental results indicate that
MedPLIB has achieved state-of-the-art outcomes across multiple medical visual
language tasks. More importantly, in zero-shot evaluations for the pixel
grounding task, MedPLIB leads the best small and large models by margins of
19.7 and 15.6 respectively on the mDice metric. The codes, data, and model
checkpoints will be made publicly available at
https://github.com/ShawnHuang497/MedPLIB.

摘要：<paragraph>近年来，多模态大型语言模型 (MLLM) 已取得显著进展，证明了开发智能生物医学助理的可行性。然而，当前的生物医学 MLLM 主要专注于图像级理解，并将交互限制在文本命令中，从而限制了它们的能力边界和使用灵活性。在本文中，我们介绍了一个用于生物医学领域的全新端到端多模态大型语言模型，名为 MedPLIB，它具有像素级理解能力。令人兴奋的是，它支持视觉问答 (VQA)、任意像素级提示（点、边界框和自由形式形状）以及像素级接地。我们提出了一种新颖的专家混合 (MoE) 多阶段训练策略，该策略将 MoE 分为视觉语言专家模型和像素接地专家模型的单独训练阶段，然后使用 MoE 进行微调。该策略有效地协调了多任务学习，同时将推理时的计算成本保持在与单个专家模型相当的水平。为了推进生物医学 MLLM 的研究，我们引入了医学复杂视觉问答数据集 (MeCoVQA)，它包含一系列 8 种用于复杂医学影像问答和图像区域理解的模态。实验结果表明，MedPLIB 在多个医学视觉语言任务中取得了最先进的成果。更重要的是，在像素接地任务的零样本评估中，MedPLIB 在 mDice 指标上分别以 19.7 和 15.6 的优势领先于最好的小型和大型模型。代码、数据和模型检查点将在 https://github.com/ShawnHuang497/MedPLIB 上公开。
</paragraph>

##### **CSSDH: An Ontology for Social Determinants of Health to Operational Continuity of Care Data Interoperability**
2412.09223v1 by Subhashis Das, Debashis Naskar, Sara Rodriguez Gonzalez

The rise of digital platforms has led to an increasing reliance on
technology-driven, home-based healthcare solutions, enabling individuals to
monitor their health and share information with healthcare professionals as
needed. However, creating an efficient care plan management system requires
more than just analyzing hospital summaries and Electronic Health Records
(EHRs). Factors such as individual user needs and social determinants of
health, including living conditions and the flow of healthcare information
between different settings, must also be considered. Challenges in this complex
healthcare network involve schema diversity (in EHRs, personal health records,
etc.) and terminology diversity (e.g., ICD, SNOMED-CT) across ancillary
healthcare operations. Establishing interoperability among various systems and
applications is crucial, with the European Interoperability Framework (EIF)
emphasizing the need for patient-centric access and control of healthcare data.
In this paper, we propose an integrated ontological model, the Common Semantic
Data Model for Social Determinants of Health (CSSDH), by combining ISO/DIS
13940:2024 ContSys with WHO Social Determinants of Health. CSSDH aims to
achieve interoperability within the Continuity of Care Network.

摘要：數位平台的興起導致愈來愈依賴科技驅動、居家醫療保健解決方案，讓個人得以監測自己的健康，並視需要與醫療保健專業人員分享資訊。然而，建立一個有效的照護計畫管理系統，需要的可不僅僅是分析醫院摘要和電子健康紀錄 (EHR) 而已。還必須考量個人使用者需求和健康的社會決定因素，包括生活條件和不同環境之間的醫療保健資訊流動。這個複雜的醫療保健網路中的挑戰，包括架構多樣性 (在 EHR、個人健康紀錄等) 和術語多樣性 (例如 ICD、SNOMED-CT) 等輔助醫療保健作業。在各種系統和應用程式之間建立互通性至關重要，歐洲互通性架構 (EIF) 強調需要以病人為中心存取和控制醫療保健資料。在本文中，我們提出一個整合的本體論模型，即結合 ISO/DIS 13940:2024 ContSys 與 WHO 健康社會決定因素的社會決定因素健康共同語義資料模型 (CSSDH)。CSSDH 旨在在照護連續性網路中達成互通性。

##### **Understanding Opportunities and Risks of Synthetic Relationships: Leveraging the Power of Longitudinal Research with Customised AI Tools**
2412.09086v1 by Alfio Ventura, Nils Köbis

This position paper discusses the benefits of longitudinal behavioural
research with customised AI tools for exploring the opportunities and risks of
synthetic relationships. Synthetic relationships are defined as "continuing
associations between humans and AI tools that interact with one another wherein
the AI tool(s) influence(s) humans' thoughts, feelings, and/or actions."
(Starke et al., 2024). These relationships can potentially improve health,
education, and the workplace, but they also bring the risk of subtle
manipulation and privacy and autonomy concerns. To harness the opportunities of
synthetic relationships and mitigate their risks, we outline a methodological
approach that complements existing findings. We propose longitudinal research
designs with self-assembled AI agents that enable the integration of detailed
behavioural and self-reported data.

摘要：本立場文件探討縱向行為研究與客製化 AI 工具的優點，用於探討合成關係的機會與風險。合成關係定義為「人類與 AI 工具之間持續的關聯，彼此互動，其中 AI 工具會影響人類的想法、感受和/或行為。」（Starke 等人，2024 年）。這些關係有可能改善健康、教育和職場，但它們也帶來微妙的操縱以及隱私和自主權的隱憂。為了利用合成關係的機會並降低其風險，我們概述了一種方法論方法，補充現有的發現。我們提出使用自組裝 AI 代理的縱向研究設計，使我們能夠整合詳細的行為和自我報告資料。

##### **Radiology Report Generation via Multi-objective Preference Optimization**
2412.08901v2 by Ting Xiao, Lei Shi, Peng Liu, Zhe Wang, Chenjia Bai

Automatic Radiology Report Generation (RRG) is an important topic for
alleviating the substantial workload of radiologists. Existing RRG approaches
rely on supervised regression based on different architectures or additional
knowledge injection,while the generated report may not align optimally with
radiologists' preferences. Especially, since the preferences of radiologists
are inherently heterogeneous and multidimensional, e.g., some may prioritize
report fluency, while others emphasize clinical accuracy. To address this
problem,we propose a new RRG method via Multi-objective Preference Optimization
(MPO) to align the pre-trained RRG model with multiple human preferences, which
can be formulated by multi-dimensional reward functions and optimized by
multi-objective reinforcement learning (RL). Specifically, we use a preference
vector to represent the weight of preferences and use it as a condition for the
RRG model. Then, a linearly weighed reward is obtained via a dot product
between the preference vector and multi-dimensional reward. Next,the RRG model
is optimized to align with the preference vector by optimizing such a reward
via RL. In the training stage,we randomly sample diverse preference vectors
from the preference space and align the model by optimizing the weighted
multi-objective rewards, which leads to an optimal policy on the entire
preference space. When inference,our model can generate reports aligned with
specific preferences without further fine-tuning. Extensive experiments on two
public datasets show the proposed method can generate reports that cater to
different preferences in a single model and achieve state-of-the-art
performance.

摘要：自動放射報告生成 (RRG) 是減輕放射科醫師大量工作負擔的重要議題。現有的 RRG 方法仰賴基於不同架構或額外知識注入的監督式回歸，而產生的報告可能無法最佳地符合放射科醫師的偏好。特別是，由於放射科醫師的偏好本質上是異質且多面向的，例如，有些人可能優先考慮報告的流暢度，而另一些人則強調臨床準確性。為了解決這個問題，我們透過多目標偏好最佳化 (MPO) 提出一個新的 RRG 方法，以將預先訓練的 RRG 模型與多個人類偏好對齊，這可以用多維獎勵函數來制定，並透過多目標強化學習 (RL) 來最佳化。具體來說，我們使用偏好向量來表示偏好的權重，並將其用作 RRG 模型的條件。然後，透過偏好向量和多維獎勵之間的點積，獲得線性加權獎勵。接下來，透過 RL 最佳化此類獎勵，最佳化 RRG 模型以與偏好向量對齊。在訓練階段，我們從偏好空間中隨機取樣不同的偏好向量，並透過最佳化加權的多目標獎勵來對齊模型，這會產生整個偏好空間的最佳策略。在推論時，我們的模型可以生成與特定偏好對齊的報告，而無需進一步微調。在兩個公開資料集上的廣泛實驗顯示，所提出的方法可以在單一模型中生成迎合不同偏好的報告，並達到最先進的效能。

##### **AI-assisted Knowledge Discovery in Biomedical Literature to Support Decision-making in Precision Oncology**
2412.08900v1 by Ting He, Kory Kreimeyer, Mimi Najjar, Jonathan Spiker, Maria Fatteh, Valsamo Anagnostou, Taxiarchis Botsis

The delivery of appropriate targeted therapies to cancer patients requires
the complete analysis of the molecular profiling of tumors and the patient's
clinical characteristics in the context of existing knowledge and recent
findings described in biomedical literature and several other sources. We
evaluated the potential contributions of specific natural language processing
solutions to support knowledge discovery from biomedical literature. Two models
from the Bidirectional Encoder Representations from Transformers (BERT) family,
two Large Language Models, and PubTator 3.0 were tested for their ability to
support the named entity recognition (NER) and the relation extraction (RE)
tasks. PubTator 3.0 and the BioBERT model performed best in the NER task (best
F1-score equal to 0.93 and 0.89, respectively), while BioBERT outperformed all
other solutions in the RE task (best F1-score 0.79) and a specific use case it
was applied to by recognizing nearly all entity mentions and most of the
relations.

摘要：適當標靶療法在癌症病患的應用，需要在現有知識和生物醫學文獻中所描述的最新發現的脈絡下，完整分析腫瘤的分子特徵和病患的臨床特徵。我們評估了特定自然語言處理解決方案在支援從生物醫學文獻中發現知識的潛在貢獻。我們測試了來自 Transformer 雙向編碼器表示法 (BERT) 家族的兩個模型、兩個大型語言模型和 PubTator 3.0，以評估它們支援命名實體辨識 (NER) 和關係萃取 (RE) 任務的能力。PubTator 3.0 和 BioBERT 模型在 NER 任務中表現最佳（最佳 F1 分數分別為 0.93 和 0.89），而 BioBERT 在 RE 任務中優於所有其他解決方案（最佳 F1 分數為 0.79），並且在一個特定的應用案例中，它幾乎辨識出所有實體提及和大部分關係。

##### **Towards modeling evolving longitudinal health trajectories with a transformer-based deep learning model**
2412.08873v1 by Hans Moen, Vishnu Raj, Andrius Vabalas, Markus Perola, Samuel Kaski, Andrea Ganna, Pekka Marttinen

Health registers contain rich information about individuals' health
histories. Here our interest lies in understanding how individuals' health
trajectories evolve in a nationwide longitudinal dataset with coded features,
such as clinical codes, procedures, and drug purchases. We introduce a
straightforward approach for training a Transformer-based deep learning model
in a way that lets us analyze how individuals' trajectories change over time.
This is achieved by modifying the training objective and by applying a causal
attention mask. We focus here on a general task of predicting the onset of a
range of common diseases in a given future forecast interval. However, instead
of providing a single prediction about diagnoses that could occur in this
forecast interval, our approach enable the model to provide continuous
predictions at every time point up until, and conditioned on, the time of the
forecast period. We find that this model performs comparably to other models,
including a bi-directional transformer model, in terms of basic prediction
performance while at the same time offering promising trajectory modeling
properties. We explore a couple of ways to use this model for analyzing health
trajectories and aiding in early detection of events that forecast possible
later disease onsets. We hypothesize that this method may be helpful in
continuous monitoring of peoples' health trajectories and enabling
interventions in ongoing health trajectories, as well as being useful in
retrospective analyses.

摘要：健康登記包含個人健康史的豐富資訊。我們在此有興趣了解個人健康軌跡如何隨著編碼功能（例如臨床代碼、程序和藥物購買）在全國縱向資料集中演變。我們引入一種直接的方法，用於訓練 Transformer 為基礎的深度學習模型，讓我們分析個人軌跡如何隨著時間推移而改變。這是透過修改訓練目標並應用因果注意力遮罩來實現的。我們在此專注於預測在給定未來預測區間內一系列常見疾病發病的一般任務。然而，我們的做法並非提供關於可能在此預測區間內發生的診斷的單一預測，而是讓模型能夠在每個時間點提供連續預測，直到預測期間的時間，並以其為條件。我們發現此模型的表現與其他模型（包括雙向 Transformer 模型）相當，在基本預測效能方面如此，同時提供有希望的軌跡建模屬性。我們探索了幾種使用此模型分析健康軌跡並協助早期偵測預測可能後續發病事件的方法。我們假設此方法可能有助於持續監測個人健康軌跡，並讓干預措施得以在持續的健康軌跡中進行，且在回顧性分析中也很有用。

##### **Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions**
2412.08737v1 by Jiarui Zhang, Ollie Liu, Tianyu Yu, Jinyi Hu, Willie Neiswanger

Multimodal large language models (MLLMs) have made rapid progress in recent
years, yet continue to struggle with low-level visual perception (LLVP) --
particularly the ability to accurately describe the geometric details of an
image. This capability is crucial for applications in areas such as robotics,
medical image analysis, and manufacturing. In this paper, we first introduce
Geoperception, a benchmark designed to evaluate an MLLM's ability to accurately
transcribe 2D geometric information from an image. Using this benchmark, we
demonstrate the limitations of leading MLLMs, and then conduct a comprehensive
empirical study to explore strategies for improving their performance on
geometric tasks. Our findings highlight the benefits of certain model
architectures, training techniques, and data strategies, including the use of
high-fidelity synthetic data and multi-stage training with a data curriculum.
Notably, we find that a data curriculum enables models to learn challenging
geometry understanding tasks which they fail to learn from scratch. Leveraging
these insights, we develop Euclid, a family of models specifically optimized
for strong low-level geometric perception. Although purely trained on synthetic
multimodal data, Euclid shows strong generalization ability to novel geometry
shapes. For instance, Euclid outperforms the best closed-source model,
Gemini-1.5-Pro, by up to 58.56% on certain Geoperception benchmark tasks and
10.65% on average across all tasks.

摘要：近幾年，多模態大型語言模型 (MLLM) 迅速進展，但仍持續與低階視覺感知 (LLVP) 奮戰，尤其是準確描述影像幾何細節的能力。此功能對於機器人、醫學影像分析和製造等領域的應用至關重要。在本文中，我們首先介紹 Geoperception，一個基準，旨在評估 MLLM 從影像準確轉錄 2D 幾何資訊的能力。使用此基準，我們展示了領先 MLLM 的限制，然後進行全面的實證研究，探討改善其在幾何任務上表現的策略。我們的研究結果突出了特定模型架構、訓練技術和資料策略的優點，包括使用高保真合成資料和具有資料課程的多階段訓練。值得注意的是，我們發現資料課程能讓模型學習他們無法從頭開始學習的具有挑戰性的幾何理解任務。利用這些見解，我們開發了 Euclid，一個專門針對強低階幾何感知而最佳化的模型家族。儘管純粹在合成多模態資料上訓練，但 Euclid 對新幾何形狀展現出強大的泛化能力。例如，Euclid 在某些 Geoperception 基準任務上比最佳閉源模型 Gemini-1.5-Pro 高出 58.56%，在所有任務上的平均表現高出 10.65%。

##### **Assisted morbidity coding: the SISCO.web use case for identifying the main diagnosis in Hospital Discharge Records**
2412.09651v1 by Elena Cardillo, Lucilla Frattura

Coding morbidity data using international standard diagnostic classifications
is increasingly important and still challenging. Clinical coders and physicians
assign codes to patient episodes based on their interpretation of case notes or
electronic patient records. Therefore, accurate coding relies on the legibility
of case notes and the coders' understanding of medical terminology. During the
last ten years, many studies have shown poor reproducibility of clinical
coding, even recently, with the application of Artificial Intelligence-based
models. Given this context, the paper aims to present the SISCO.web approach
designed to support physicians in filling in Hospital Discharge Records with
proper diagnoses and procedures codes using the International Classification of
Diseases (9th and 10th), and, above all, in identifying the main pathological
condition. The web service leverages NLP algorithms, specific coding rules, as
well as ad hoc decision trees to identify the main condition, showing promising
results in providing accurate ICD coding suggestions.

摘要：使用國際標準診斷分類對病態資料進行編碼越來越重要，但仍具有挑戰性。臨床編碼員和醫師根據他們對病例記錄或電子病歷的解讀，為患者就診情況分配代碼。因此，準確編碼依賴於病例記錄的可讀性和編碼員對醫學術語的理解。在過去十年中，許多研究表明臨床編碼的可再現性很差，即使在最近，人工智能模型的應用也是如此。鑑於這種情況，本文旨在介紹 SISCO.web 方法，該方法旨在支援醫師使用國際疾病分類 (第 9 版和第 10 版) 填寫出院記錄，並正確診斷和編碼程序，最重要的是，找出主要的病理狀況。網路服務利用 NLP 演算法、特定的編碼規則以及特別決策樹來找出主要狀況，在提供準確的 ICD 編碼建議方面顯示出有希望的結果。

##### **IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**
2412.08463v1 by Gauri Jain, Pradeep Varakantham, Haifeng Xu, Aparna Taneja, Prashant Doshi, Milind Tambe

Public health practitioners often have the goal of monitoring patients and
maximizing patients' time spent in "favorable" or healthy states while being
constrained to using limited resources. Restless multi-armed bandits (RMAB) are
an effective model to solve this problem as they are helpful to allocate
limited resources among many agents under resource constraints, where patients
behave differently depending on whether they are intervened on or not. However,
RMABs assume the reward function is known. This is unrealistic in many public
health settings because patients face unique challenges and it is impossible
for a human to know who is most deserving of any intervention at such a large
scale. To address this shortcoming, this paper is the first to present the use
of inverse reinforcement learning (IRL) to learn desired rewards for RMABs, and
we demonstrate improved outcomes in a maternal and child health telehealth
program. First we allow public health experts to specify their goals at an
aggregate or population level and propose an algorithm to design expert
trajectories at scale based on those goals. Second, our algorithm WHIRL uses
gradient updates to optimize the objective, allowing for efficient and accurate
learning of RMAB rewards. Third, we compare with existing baselines and
outperform those in terms of run-time and accuracy. Finally, we evaluate and
show the usefulness of WHIRL on thousands on beneficiaries from a real-world
maternal and child health setting in India. We publicly release our code here:
https://github.com/Gjain234/WHIRL.

摘要：<paragraph>公共衛生從業人員通常有監控患者和最大化患者處於「有利」或健康狀態的時間的目標，同時受到有限資源的限制。不安分的多臂強盜 (RMAB) 是解決此問題的有效模型，因為它們有助於在資源限制下，在許多代理之間分配有限的資源，其中患者的行為取決於是否對其進行干預。然而，RMAB 假設已知回報函數。這在許多公共衛生環境中是不切實際的，因為患者面臨獨特的挑戰，而且對於如此大規模的干預，人類不可能知道誰最需要干預。為了解決這個缺點，本文首次提出使用逆向強化學習 (IRL) 來學習 RMAB 的期望回報，並且我們在母嬰健康遠距醫療計畫中展示了改善的結果。首先，我們允許公共衛生專家在總體或人口層級指定他們的目標，並提出一個演算法來根據這些目標大規模設計專家軌跡。其次，我們的演算法 WHIRL 使用梯度更新來最佳化目標，允許有效且準確地學習 RMAB 回報。第三，我們與現有的基準進行比較，並在執行時間和準確性方面優於這些基準。最後，我們評估並展示了 WHIRL 在印度實際母嬰健康環境中對數千名受益者的有用性。我們在此公開發布我們的程式碼：https://github.com/Gjain234/WHIRL。</paragraph>

##### **SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**
2412.08347v1 by Sultan Alrashed

We present SmolTulu-1.7b-Instruct, referenced in this report as
SmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's
Tulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.
Through comprehensive empirical analysis using a 135M parameter model, we
demonstrate that the relationship between learning rate and batch size
significantly impacts model performance in a task-dependent manner. Our
findings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from
higher learning rate to batch size ratios, while pattern recognition tasks such
as HellaSwag and IFEval show optimal performance with lower ratios. These
insights informed the development of SmolTulu, which achieves state-of-the-art
performance among sub-2B parameter models on instruction following, scoring
67.7% on IFEval ($\Delta$11%), and mathematical reasoning with 51.6% on GSM8K
($\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC
($\Delta5.4%$). We release our model, training recipes, and ablation studies to
facilitate further research in efficient model alignment, demonstrating that
careful adaptation of optimization dynamics can help bridge the capability gap
between small and large language models.

摘要：我們提出 SmolTulu-1.7b-Instruct，本報告中稱為 SmolTulu-DPO-1130，這是一種指令調整語言模型，採用 AllenAI 的 Tulu 3 後訓練管道來增強 Huggingface 的 SmolLM2-1.7B 基礎模型。透過使用 135M 參數模型的全面經驗分析，我們證明學習率與批次大小之間的關係會以任務相關的方式顯著影響模型效能。我們的發現揭示了一個明確的分歧：像 ARC 和 GSM8K 等推理任務受益於較高的學習率對批次大小的比率，而像 HellaSwag 和 IFEval 等模式辨識任務則顯示出較低比率的最佳效能。這些見解為 SmolTulu 的開發提供了資訊，在小於 2B 參數模型中，在指令遵循方面取得了最先進的表現，在 IFEval 上得分 67.7%（Δ11%），在 GSM8K 上的數學推理得分為 51.6%（Δ3.4%），而另一個版本在 ARC 上得分 57.1%（Δ5.4%）。我們發布我們的模型、訓練範例和消融研究，以促進高效模型對齊的進一步研究，證明仔細調整最佳化動態可以幫助縮小小型和大型語言模型之間的能力差距。

##### **Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures**
2412.08228v1 by Célia Blondin, Joris Guérin, Kelly Inagaki, Guilherme Longo, Laure Berti-Équille

Automated benthic image annotation is crucial to efficiently monitor and
protect coral reefs against climate change. Current machine learning approaches
fail to capture the hierarchical nature of benthic organisms covering reef
substrata, i.e., coral taxonomic levels and health condition. To address this
limitation, we propose to annotate benthic images using hierarchical
classification. Experiments on a custom dataset from a Northeast Brazilian
coral reef show that our approach outperforms flat classifiers, improving both
F1 and hierarchical F1 scores by approximately 2\% across varying amounts of
training data. In addition, this hierarchical method aligns more closely with
ecological objectives.

摘要：自動化底棲影像註解對於有效監測和保護珊瑚礁免受氣候變遷影響至關重要。目前的機器學習方法無法捕捉覆蓋礁石基質的底棲生物的階層性質，例如珊瑚分類等級和健康狀況。為了解決此限制，我們建議使用階層分類註解底棲影像。對來自巴西東北部珊瑚礁的自訂資料集進行的實驗顯示，我們的做法優於平面分類器，在不同數量的訓練資料中將 F1 和階層 F1 分數都提高了大約 2%。此外，這種階層式方法與生態目標更為一致。

##### **How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**
2412.08081v1 by Yixin Zhang, Kevin Kramer, Maciej A. Mazurowski

Automated segmentation of medical images highly depends on the availability
of accurate manual image annotations. Such annotations are very time-consuming
and costly to generate, and often require specialized expertise, particularly
for cross-sectional images which contain many slices for each patient. It is
crucial to ensure the best use of annotation resources. In this paper, we
systematically answer the question of how to select slices of cross-sectional
medical images in order to maximize performance of the resulting deep learning
segmentation models. We conducted experiments on 4 medical imaging segmentation
tasks with varying annotation budgets, numbers of annotated cases, numbers of
annotated slices per volume, slice selection techniques, and mask
interpolations. We found that:
  1) It is almost always preferable to annotate fewer slices per volume and
more volumes given an annotation budget. 2) Selecting slices for annotation by
unsupervised active learning (UAL) is not superior to selecting slices randomly
or at fixed intervals, provided that each volume is allocated the same number
of annotated slices. 3) Interpolating masks between annotated slices rarely
enhances model performance, with exceptions of some specific configuration for
3D models.

摘要：醫學影像的自動化分割高度依賴於準確的手動影像標註。此類標註非常耗時且生成成本高昂，且通常需要專業知識，特別是對於每個患者包含許多切片的橫斷面影像。確保最佳利用標註資源至關重要。在本文中，我們系統性地回答了如何選擇橫斷面醫學影像切片以最大化深度學習分割模型效能的問題。我們針對 4 項醫學影像分割任務進行了實驗，這些任務具有不同的標註預算、標註案例數、每個體積的標註切片數、切片選擇技術和遮罩內插。我們發現：
1) 在給定標註預算的情況下，幾乎總是優先標註每個體積較少切片和更多體積。2) 透過非監督主動學習 (UAL) 選擇切片進行標註並不優於隨機或固定間隔選擇切片，前提是每個體積分配的標註切片數相同。3) 在標註切片之間內插遮罩很少能提升模型效能，但某些 3D 模型的特定組態除外。

##### **Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning**
2412.08021v1 by Chongyi Zheng, Jens Tuyls, Joanne Peng, Benjamin Eysenbach

Self-supervised learning has the potential of lifting several of the key
challenges in reinforcement learning today, such as exploration, representation
learning, and reward design. Recent work (METRA) has effectively argued that
moving away from mutual information and instead optimizing a certain
Wasserstein distance is important for good performance. In this paper, we argue
that the benefits seen in that paper can largely be explained within the
existing framework of mutual information skill learning (MISL). Our analysis
suggests a new MISL method (contrastive successor features) that retains the
excellent performance of METRA with fewer moving parts, and highlights
connections between skill learning, contrastive representation learning, and
successor features. Finally, through careful ablation studies, we provide
further insight into some of the key ingredients for both our method and METRA.

摘要：自我監督學習有潛力解決當今強化學習中的幾個關鍵挑戰，例如探索、表徵學習和獎勵設計。最近的研究（METRA）有效地論證了遠離互信息並改為優化某個 Wasserstein 距離對於良好的性能很重要。在本文中，我們論證該論文中看到的優點可以在互信息技能學習（MISL）的現有框架內得到很大程度的解釋。我們的分析提出了一種新的 MISL 方法（對比後繼特徵），它保留了 METRA 的出色性能，同時減少了活動部件，並突出了技能學習、對比表徵學習和後繼特徵之間的聯繫。最後，通過仔細的消融研究，我們進一步深入了解了我們的方法和 METRA 的一些關鍵要素。

##### **From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents**
2412.07951v2 by Mohit Chandra, Suchismita Naik, Denae Ford, Ebele Okoli, Munmun De Choudhury, Mahsa Ershadi, Gonzalo Ramos, Javier Hernandez, Ananya Bhattacharjee, Shahed Warreth, Jina Suh

Recent gain in popularity of AI conversational agents has led to their
increased use for improving productivity and supporting well-being. While
previous research has aimed to understand the risks associated with
interactions with AI conversational agents, these studies often fall short in
capturing the lived experiences. Additionally, psychological risks have often
been presented as a sub-category within broader AI-related risks in past
taxonomy works, leading to under-representation of the impact of psychological
risks of AI use. To address these challenges, our work presents a novel risk
taxonomy focusing on psychological risks of using AI gathered through lived
experience of individuals. We employed a mixed-method approach, involving a
comprehensive survey with 283 individuals with lived mental health experience
and workshops involving lived experience experts to develop a psychological
risk taxonomy. Our taxonomy features 19 AI behaviors, 21 negative psychological
impacts, and 15 contexts related to individuals. Additionally, we propose a
novel multi-path vignette based framework for understanding the complex
interplay between AI behaviors, psychological impacts, and individual user
contexts. Finally, based on the feedback obtained from the workshop sessions,
we present design recommendations for developing safer and more robust AI
agents. Our work offers an in-depth understanding of the psychological risks
associated with AI conversational agents and provides actionable
recommendations for policymakers, researchers, and developers.

摘要：近期 AI 對話代理的普及提升，導致其在提升生產力和支持幸福感方面的應用日益增加。雖然先前的研究旨在了解與 AI 對話代理互動相關的風險，但這些研究往往無法捕捉到生活體驗。此外，在過去的分類工作中，心理風險通常被視為更廣泛的 AI 相關風險中的子類別，導致 AI 使用心理風險的影響被低估。為了應對這些挑戰，我們的研究提出了新穎的風險分類法，重點關注透過個人生活經驗收集的 AI 使用心理風險。我們採用混合方法，包括對 283 位具有生活心理健康經驗的個人進行全面調查，以及與生活經驗專家合作的研討會，以制定心理風險分類法。我們的分類法包含 19 種 AI 行為、21 種負面心理影響和 15 種與個人相關的背景。此外，我們提出了一個新穎的多路徑小插圖框架，用於了解 AI 行為、心理影響和個人使用者背景之間的複雜交互作用。最後，根據從研討會中獲得的回饋，我們提出了設計建議，以開發更安全、更強大的 AI 代理。我們的研究深入了解了與 AI 對話代理相關的心理風險，並為政策制定者、研究人員和開發人員提供了可行的建議。

##### **How Should We Represent History in Interpretable Models of Clinical Policies?**
2412.07895v1 by Anton Matsson, Lena Stempfle, Yaochen Rao, Zachary R. Margolin, Heather J. Litman, Fredrik D. Johansson

Modeling policies for sequential clinical decision-making based on
observational data is useful for describing treatment practices, standardizing
frequent patterns in treatment, and evaluating alternative policies. For each
task, it is essential that the policy model is interpretable. Learning accurate
models requires effectively capturing the state of a patient, either through
sequence representation learning or carefully crafted summaries of their
medical history. While recent work has favored the former, it remains a
question as to how histories should best be represented for interpretable
policy modeling. Focused on model fit, we systematically compare diverse
approaches to summarizing patient history for interpretable modeling of
clinical policies across four sequential decision-making tasks. We illustrate
differences in the policies learned using various representations by breaking
down evaluations by patient subgroups, critical states, and stages of
treatment, highlighting challenges specific to common use cases. We find that
interpretable sequence models using learned representations perform on par with
black-box models across all tasks. Interpretable models using hand-crafted
representations perform substantially worse when ignoring history entirely, but
are made competitive by incorporating only a few aggregated and recent elements
of patient history. The added benefits of using a richer representation are
pronounced for subgroups and in specific use cases. This underscores the
importance of evaluating policy models in the context of their intended use.

摘要：基於觀察資料對序貫臨床決策制定建模政策，有助於描述治療實務、標準化治療中的常見模式，以及評估替代政策。對於每項任務，政策模型的可解釋性至關重要。學習精確的模型需要有效擷取患者的狀態，無論是透過序列表徵學習或精心製作的病史摘要。雖然近期研究偏好前者，但如何以最佳方式表徵病史以進行可解釋的政策建模，仍是一個問題。我們專注於模型擬合度，系統性地比較各種摘要患者病史的方法，以針對四項序貫決策制定任務進行可解釋的臨床政策建模。我們透過按患者子群、危急狀態和治療階段細分評估，來說明使用各種表徵所學習到的政策之間的差異，並強調特定於常見使用案例的挑戰。我們發現，使用學習表徵的可解釋序列模型在所有任務中表現與黑箱模型不相上下。使用手工製作表徵的可解釋模型在完全忽略病史時表現明顯較差，但透過僅納入少數患者病史的彙整和近期元素，便能使其具有競爭力。使用更豐富表徵的額外好處在子群和特定使用案例中顯著。這強調了在預期用途的脈絡中評估政策模型的重要性。

##### **Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact**
2412.07880v2 by Yunfan Zhao, Niclas Boehmer, Aparna Taneja, Milind Tambe

AI for social impact (AI4SI) offers significant potential for addressing
complex societal challenges in areas such as public health, agriculture,
education, conservation, and public safety. However, existing AI4SI research is
often labor-intensive and resource-demanding, limiting its accessibility and
scalability; the standard approach is to design a (base-level) system tailored
to a specific AI4SI problem. We propose the development of a novel meta-level
multi-agent system designed to accelerate the development of such base-level
systems, thereby reducing the computational cost and the burden on social
impact domain experts and AI researchers. Leveraging advancements in foundation
models and large language models, our proposed approach focuses on resource
allocation problems providing help across the full AI4SI pipeline from problem
formulation over solution design to impact evaluation. We highlight the ethical
considerations and challenges inherent in deploying such systems and emphasize
the importance of a human-in-the-loop approach to ensure the responsible and
effective application of AI systems.

摘要：人工智慧對社會影響（AI4SI）提供了巨大的潛力，用於解決複雜的社會挑戰，例如公共衛生、農業、教育、保育和公共安全。然而，現有的 AI4SI 研究通常需要大量人力和資源，這限制了其可及性和可擴展性；標準方法是設計一個針對特定 AI4SI 問題量身打造的（基礎層級）系統。我們建議開發一個新穎的元層級多代理系統，旨在加速此類基礎層級系統的開發，從而降低運算成本和社會影響領域專家與 AI 研究人員的負擔。透過運用基礎模型和大型語言模型的進展，我們建議的方法專注於資源配置問題，提供從問題建構、解決方案設計到影響評估的完整 AI4SI 管線的協助。我們強調部署此類系統時固有的道德考量和挑戰，並強調人機協作方法的重要性，以確保負責任且有效地應用 AI 系統。

##### **Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG**
2412.07878v1 by Shivraj Singh Bhatti, Aryan Yadav, Mitali Monga, Neeraj Kumar

The classification of harmful brain activities, such as seizures and periodic
discharges, play a vital role in neurocritical care, enabling timely diagnosis
and intervention. Electroencephalography (EEG) provides a non-invasive method
for monitoring brain activity, but the manual interpretation of EEG signals are
time-consuming and rely heavily on expert judgment. This study presents a
comparative analysis of deep learning architectures, including Convolutional
Neural Networks (CNNs), Vision Transformers (ViTs), and EEGNet, applied to the
classification of harmful brain activities using both raw EEG data and
time-frequency representations generated through Continuous Wavelet Transform
(CWT). We evaluate the performance of these models use multimodal data
representations, including high-resolution spectrograms and waveform data, and
introduce a multi-stage training strategy to improve model robustness. Our
results show that training strategies, data preprocessing, and augmentation
techniques are as critical to model success as architecture choice, with
multi-stage TinyViT and EfficientNet demonstrating superior performance. The
findings underscore the importance of robust training regimes in achieving
accurate and efficient EEG classification, providing valuable insights for
deploying AI models in clinical practice.

摘要：有害腦部活動的分類，例如癲癇發作和週期性放電，在神經重症照護中扮演著至關重要的角色，能及時診斷和介入。腦電圖 (EEG) 提供了一種非侵入式的方法來監測腦部活動，但 EEG 訊號的手動判讀耗時且高度依賴專家的判斷。本研究針對深度學習架構進行比較分析，包括卷積神經網路 (CNN)、視覺Transformer (ViT) 和 EEGNet，運用於有害腦部活動的分類，同時使用原始 EEG 資料和透過連續小波轉換 (CWT) 生成的時頻表示。我們評估這些模型使用多模式資料表示的效能，包括高解析度頻譜圖和波形資料，並引入多階段訓練策略來改善模型的穩健性。我們的結果顯示，訓練策略、資料前處理和擴充技術對於模型的成功與架構選擇一樣重要，其中多階段 TinyViT 和 EfficientNet 表現出優異的效能。這些發現強調了穩健訓練機制對於達成準確且有效率的 EEG 分類的重要性，為在臨床實務中部署 AI 模型提供了寶貴的見解。

##### **Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**
2412.09644v1 by Marcos Da Silveira, Louis Deladiennee, Kheira Acem, Oona Freudenthal

Human health is increasingly threatened by exposure to hazardous substances,
particularly persistent and toxic chemicals. The link between these substances,
often encountered in complex mixtures, and various diseases are demonstrated in
scientific studies. However, this information is scattered across several
sources and hardly accessible by humans and machines. This paper evaluates
current practices for publishing/accessing information on hazardous chemicals
and proposes a novel platform designed to facilitate retrieval of critical
chemical data in urgent situations. The platform aggregates information from
multiple sources and organizes it into a structured knowledge graph. Users can
access this information through a visual interface such as Neo4J Bloom and
dashboards, or via natural language queries using a Chatbot. Our findings
demonstrate a significant reduction in the time and effort required to access
vital chemical information when datasets follow FAIR principles. Furthermore,
we discuss the lessons learned from the development and implementation of this
platform and provide recommendations for data owners and publishers to enhance
data reuse and interoperability. This work aims to improve the accessibility
and usability of chemical information by healthcare professionals, thereby
supporting better health outcomes and informed decision-making in the face of
patients exposed to chemical intoxication risks.

摘要：人類健康越來越受到接觸有害物質的威脅，尤其是持久性和有毒的化學物質。科學研究已證明這些物質（通常存在於複雜的混合物中）與各種疾病之間的關聯。然而，這些資訊分散在多個來源中，人類和機器都很難取得。本文評估了當前發布/取得有關有害化學物質資訊的慣例，並提出一個新穎的平台，旨在促進在緊急情況下取得關鍵化學資料。此平台匯集來自多個來源的資訊，並將其組織成結構化的知識圖譜。使用者可以透過視覺化介面（例如 Neo4J Bloom 和儀表板）或使用聊天機器人的自然語言查詢來取得這些資訊。我們的研究結果表明，當資料集遵循 FAIR 原則時，取得重要化學資訊所需的時間和精力會大幅減少。此外，我們討論從此平台的開發和實作中學到的經驗教訓，並為資料擁有者和發布者提供建議，以增強資料再利用和互操作性。這項工作旨在改善醫療保健專業人員取得和使用化學資訊的方式，從而支持更好的健康結果，並在面對接觸化學中毒風險的患者時做出明智的決策。

##### **Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**
2412.07618v1 by Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie

Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git

摘要：儘管大型語言模型在許多 NLP 任務上表現優異，
它們在記憶廣泛的世界知識方面仍面臨重大限制。最近的研究表明，
利用檢索增強生成 (RAG) 框架，結合以結構化格式封裝廣泛事實資料的知識圖譜，
能穩健地增強 LLM 的推理能力。然而，在現實世界場景中部署此類系統會產生挑戰：
非平穩環境的持續演變可能導致效能下降，而使用者的滿意度需要在效能和回應性之間取得仔細的平衡。
為了應對這些挑戰，我們引入了多目標多臂老虎機增強的 RAG 框架，
並在實務中採用具備多元能力的各種檢索方法，以應對豐富且不斷演變的檢索情境。
在此框架中，每個檢索方法都被視為一個不同的「手臂」。
該系統利用即時使用者回饋來適應動態環境，
根據輸入查詢和每個手臂的歷史多目標效能來選擇適當的檢索方法。
在兩個基準 KGQA 資料集上進行的廣泛實驗表明，
我們的模型在非平穩設定中顯著優於基線模型，同時在平穩環境中達到最先進的效能。
程式碼和資料可於 https://github.com/FUTUREEEEEE/Dynamic-RAG.git 取得

##### **Scaling Sequential Recommendation Models with Transformers**
2412.07585v1 by Pablo Zivic, Hernan Vazquez, Jorge Sanchez

Modeling user preferences has been mainly addressed by looking at users'
interaction history with the different elements available in the system.
Tailoring content to individual preferences based on historical data is the
main goal of sequential recommendation.
  The nature of the problem, as well as the good performance observed across
various domains, has motivated the use of the transformer architecture, which
has proven effective in leveraging increasingly larger amounts of training data
when accompanied by an increase in the number of model parameters. This scaling
behavior has brought a great deal of attention, as it provides valuable
guidance in the design and training of even larger models.
  Taking inspiration from the scaling laws observed in training large language
models, we explore similar principles for sequential recommendation.
  We use the full Amazon Product Data dataset, which has only been partially
explored in other studies, and reveal scaling behaviors similar to those found
in language models. Compute-optimal training is possible but requires a careful
analysis of the compute-performance trade-offs specific to the application.
  We also show that performance scaling translates to downstream tasks by
fine-tuning larger pre-trained models on smaller task-specific domains. Our
approach and findings provide a strategic roadmap for model training and
deployment in real high-dimensional preference spaces, facilitating better
training and inference efficiency.
  We hope this paper bridges the gap between the potential of transformers and
the intrinsic complexities of high-dimensional sequential recommendation in
real-world recommender systems.
  Code and models can be found at https://github.com/mercadolibre/srt

摘要：<paragraph>建模使用者偏好主要透過觀察使用者與系統中不同元素的互動記錄。
根據歷史資料調整個人偏好的內容是連續推薦的主要目標。
問題的本質，以及在各個領域觀察到的良好效能，激勵了Transformer架構的使用，在增加模型參數數量時，已證明能有效利用越來越多訓練資料。這種規模行為引起了極大的關注，因為它在設計和訓練更大模型時提供了有價值的指導。
從訓練大型語言模型中觀察到的規模法則中汲取靈感，我們探討了連續推薦的類似原則。
我們使用了完整的 Amazon 產品資料集，其他研究僅部分探討過，並揭示了與在語言模型中發現的類似的規模行為。計算最佳訓練是可能的，但需要仔細分析特定於應用程式的計算效能折衷。
我們還展示了效能規模轉化為下游任務，透過對較小的特定任務領域微調較大的預訓練模型。我們的做法和發現為模型訓練和在實際高維度偏好空間中部署提供了策略性路線圖，促進更好的訓練和推理效率。
我們希望這篇論文能彌合Transformer潛力與實際推薦系統中高維度連續推薦的內在複雜性之間的差距。
程式碼和模型可以在 https://github.com/mercadolibre/srt 找到</paragraph>

##### **Knowledge Graph Guided Evaluation of Abstention Techniques**
2412.07430v1 by Kinshuk Vasisht, Navreet Kaur, Danish Pruthi

To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., "rivers") from a knowledge graph. The nature of SELECT enables
us to isolate the effects of abstention techniques from other safety training
procedures, as well as evaluate their generalization and specificity. Using
SELECT, we benchmark different abstention techniques over six open-weight and
closed-source models. We find that the examined techniques indeed cause models
to abstain with over $80\%$ abstention rates. However, these techniques are not
as effective for descendants of the target concepts, with refusal rates
declining by $19\%$. We also characterize the generalization-vs-specificity
trade-offs for different techniques. Overall, no single technique is invariably
better than the others. Our findings call for a careful evaluation of different
aspects of abstention, and hopefully inform practitioners of various trade-offs
involved.

摘要：為了安全地部署語言模型，至關重要的是，它們必須避免回應不適當的請求。先前有數項研究測試模型的安全性，依據它們封鎖惡意請求的有效性為基礎。在這項工作中，我們專注於評估導致模型避免回應的底層技術。我們建立了 SELECT，一個從知識圖譜中一組良性概念（例如「河流」）衍生的基準。SELECT 的性質使我們能夠將避免回應技術的影響與其他安全訓練程序隔離，並評估它們的概括性和特異性。使用 SELECT，我們對六個開放權重和封閉原始碼模型進行了不同避免回應技術的基準測試。我們發現，所檢查的技術確實導致模型避免回應，避免回應率超過 80%。然而，這些技術對於目標概念的後代並不那麼有效，拒絕率下降了 19%。我們還描述了不同技術的概括性與特異性權衡。總體而言，沒有任何單一技術始終優於其他技術。我們的發現要求仔細評估避免回應的不同面向，並希望讓從業人員了解所涉及的各種權衡。

##### **A Review of Challenges in Speech-based Conversational AI for Elderly Care**
2412.07388v1 by Willemijn Klaassen, Bram van Dijk, Marco Spruit

Artificially intelligent systems optimized for speech conversation are
appearing at a fast pace. Such models are interesting from a healthcare
perspective, as these voice-controlled assistants may support the elderly and
enable remote health monitoring. The bottleneck for efficacy, however, is how
well these devices work in practice and how the elderly experience them, but
research on this topic is scant. We review elderly use of voice-controlled AI
and highlight various user- and technology-centered issues, that need to be
considered before effective speech-controlled AI for elderly care can be
realized.

摘要：以語音對話為最佳化的人工智慧系統正快速出現。此類模型在醫療保健方面很有趣，因為這些聲控助理可以支援長者並能進行遠距健康監控。然而，效能的瓶頸在於這些裝置在實際運作上的表現如何，以及長者如何體驗它們，但這方面的研究卻很稀少。我們回顧了長者使用聲控人工智慧的狀況，並重點說明各種以使用者和技術為中心的議題，在能實現有效的聲控人工智慧以進行長者照護之前，這些議題都需要加以考量。

##### **Enhanced MRI Representation via Cross-series Masking**
2412.07387v1 by Churan Wang, Fei Gao, Lijun Yan, Siwen Wang, Yizhou Yu, Yizhou Wang

Magnetic resonance imaging (MRI) is indispensable for diagnosing and planning
treatment in various medical conditions due to its ability to produce
multi-series images that reveal different tissue characteristics. However,
integrating these diverse series to form a coherent analysis presents
significant challenges, such as differing spatial resolutions and contrast
patterns meanwhile requiring extensive annotated data, which is scarce in
clinical practice. Due to these issues, we introduce a novel Cross-Series
Masking (CSM) Strategy for effectively learning MRI representation in a
self-supervised manner. Specifically, CSM commences by randomly sampling a
subset of regions and series, which are then strategically masked. In the
training process, the cross-series representation is learned by utilizing the
unmasked data to reconstruct the masked portions. This process not only
integrates information across different series but also facilitates the ability
to model both intra-series and inter-series correlations and complementarities.
With the learned representation, the downstream tasks like segmentation and
classification are also enhanced. Taking brain tissue segmentation, breast
tumor benign/malignant classification, and prostate cancer diagnosis as
examples, our method achieves state-of-the-art performance on both public and
in-house datasets.

摘要：磁振造影 (MRI) 對於診斷和規劃各種醫療狀況的治療至關重要，因為它能夠產生揭示不同組織特徵的多系列影像。然而，整合這些不同的系列以形成連貫的分析會帶來重大的挑戰，例如不同的空間解析度和對比模式，同時需要大量的註解資料，但在臨床實務中卻很稀少。由於這些問題，我們引入了一種新穎的跨系列遮罩 (CSM) 策略，以便以自我監督的方式有效地學習 MRI 表徵。具體來說，CSM 從隨機抽樣區域和系列的子集開始，然後對其進行策略性遮罩。在訓練過程中，跨系列表徵是透過利用未遮罩的資料來重建遮罩部分而學習的。這個過程不僅整合了不同系列的資訊，還促進了對系列內和系列間關聯性和互補性的建模能力。透過學習到的表徵，下游任務（例如分割和分類）也會得到增強。以腦組織分割、乳房腫瘤良性/惡性分類和前列腺癌診斷為例，我們的模型在公開資料集和內部資料集上都達到了最先進的效能。

##### **On Evaluating the Durability of Safeguards for Open-Weight LLMs**
2412.07097v1 by Xiangyu Qi, Boyi Wei, Nicholas Carlini, Yangsibo Huang, Tinghao Xie, Luxi He, Matthew Jagielski, Milad Nasr, Prateek Mittal, Peter Henderson

Stakeholders -- from model developers to policymakers -- seek to minimize the
dual-use risks of large language models (LLMs). An open challenge to this goal
is whether technical safeguards can impede the misuse of LLMs, even when models
are customizable via fine-tuning or when model weights are fully open. In
response, several recent studies have proposed methods to produce durable LLM
safeguards for open-weight LLMs that can withstand adversarial modifications of
the model's weights via fine-tuning. This holds the promise of raising
adversaries' costs even under strong threat models where adversaries can
directly fine-tune model weights. However, in this paper, we urge for more
careful characterization of the limits of these approaches. Through several
case studies, we demonstrate that even evaluating these defenses is exceedingly
difficult and can easily mislead audiences into thinking that safeguards are
more durable than they really are. We draw lessons from the evaluation pitfalls
that we identify and suggest future research carefully cabin claims to more
constrained, well-defined, and rigorously examined threat models, which can
provide more useful and candid assessments to stakeholders.

摘要：利害關係人（從模型開發人員到政策制定者）尋求將大型語言模型 (LLM) 的雙重使用風險降至最低。對此目標的公開挑戰在於，技術保障措施是否能阻止 LLM 的濫用，即使模型可通過微調進行自訂，或模型權重完全開放時亦然。為了解決此問題，最近有幾項研究提出方法，以產生適用於開放權重 LLM 的耐用 LLM 保障措施，這些保障措施能承受透過微調對模型權重進行的對抗性修改。這有望提高對手的成本，即使在對手可以直接微調模型權重的強威脅模型下亦然。然而，在本文中，我們敦促更仔細地描述這些方法的限制。透過多項案例研究，我們證明即使評估這些防禦措施也極其困難，並且很容易誤導受眾，讓他們認為保障措施比實際上更耐用。我們從我們辨識出的評估陷阱中汲取教訓，並建議未來的研究謹慎地將主張限制在更受限、定義明確且經過嚴格審查的威脅模型中，這可以為利害關係人提供更有用且坦率的評估。

##### **Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**
2412.06993v1 by Le Song, Eran Segal, Eric Xing

We present an approach of using AI to model and simulate biology and life.
Why is it important? Because at the core of medicine, pharmacy, public health,
longevity, agriculture and food security, environmental protection, and clean
energy, it is biology at work. Biology in the physical world is too complex to
manipulate and always expensive and risky to tamper with. In this perspective,
we layout an engineering viable approach to address this challenge by
constructing an AI-Driven Digital Organism (AIDO), a system of integrated
multiscale foundation models, in a modular, connectable, and holistic fashion
to reflect biological scales, connectedness, and complexities. An AIDO opens up
a safe, affordable and high-throughput alternative platform for predicting,
simulating and programming biology at all levels from molecules to cells to
individuals. We envision that an AIDO is poised to trigger a new wave of
better-guided wet-lab experimentation and better-informed first-principle
reasoning, which can eventually help us better decode and improve life.

摘要：我們提出了一種使用 AI 來建模和模擬生物學和生命的方法。
為什麼這很重要？因為在醫學、藥學、公共衛生、
長壽、農業和食品安全、環境保護和清潔
能源的核心，都是生物學在運作。物理世界中的生物學太過複雜，
難以操作，而且總是昂貴且有風險。從這個角度來看，
我們制定了一種可行的工程方法來解決這個挑戰，方法是
構建一個 AI 驅動的數位生物體 (AIDO)，一個整合的
多尺度基礎模型系統，以模組化、可連接和整體的方式
來反映生物尺度、連通性和複雜性。AIDO 開啟了一個安全、
負擔得起且高通量的替代平台，用於預測、
模擬和編程從分子到細胞到個體的所有層級的生物學。我們預計 AIDO 將引發一波
由更佳指導的濕式實驗和更完善的第一原理
推理的新浪潮，最終可以幫助我們更好地解碼和改善生命。

##### **Diagnosis and Severity Assessment of Ulcerative Colitis using Self Supervised Learning**
2412.07806v1 by Venkat Margapuri

Ulcerative Colitis (UC) is an incurable inflammatory bowel disease that leads
to ulcers along the large intestine and rectum. The increase in the prevalence
of UC coupled with gastrointestinal physician shortages stresses the healthcare
system and limits the care UC patients receive. A colonoscopy is performed to
diagnose UC and assess its severity based on the Mayo Endoscopic Score (MES).
The MES ranges between zero and three, wherein zero indicates no inflammation
and three indicates that the inflammation is markedly high. Artificial
Intelligence (AI)-based neural network models, such as convolutional neural
networks (CNNs) are capable of analyzing colonoscopies to diagnose and
determine the severity of UC by modeling colonoscopy analysis as a multi-class
classification problem. Prior research for AI-based UC diagnosis relies on
supervised learning approaches that require large annotated datasets to train
the CNNs. However, creating such datasets necessitates that domain experts
invest a significant amount of time, rendering the process expensive and
challenging. To address the challenge, this research employs self-supervised
learning (SSL) frameworks that can efficiently train on unannotated datasets to
analyze colonoscopies and, aid in diagnosing UC and its severity. A comparative
analysis with supervised learning models shows that SSL frameworks, such as
SwAV and SparK outperform supervised learning models on the LIMUC dataset, the
largest publicly available annotated dataset of colonoscopy images for UC.

摘要：潰瘍性結腸炎 (UC) 是一種無法治癒的發炎性腸道疾病，會導致大腸和直腸潰瘍。UC 的患病率增加，加上腸胃科醫師短缺，對醫療保健系統造成壓力，並限制 UC 患者接受的照護。進行大腸鏡檢查以診斷 UC 並根據 Mayo 內視鏡評分 (MES) 評估其嚴重程度。MES 的範圍在 0 到 3 之間，其中 0 表示沒有發炎，而 3 表示發炎程度顯著。基於人工智慧 (AI) 的神經網路模型，例如卷積神經網路 (CNN)，能夠分析大腸鏡檢查以診斷和確定 UC 的嚴重程度，方法是將大腸鏡檢查分析建模為多類別分類問題。先前針對基於 AI 的 UC 診斷的研究依賴於監督式學習方法，需要大量標註的資料集來訓練 CNN。然而，建立此類資料集需要領域專家投入大量時間，使這個過程既昂貴又具有挑戰性。為了應對這個挑戰，本研究採用自我監督學習 (SSL) 框架，可以在未標註的資料集上進行有效率的訓練，以分析大腸鏡檢查並協助診斷 UC 及其嚴重程度。與監督式學習模型的比較分析顯示，SSL 框架（例如 SwAV 和 SparK）在 LIMUC 資料集（最大的公開 UC 大腸鏡檢查影像標註資料集）上優於監督式學習模型。

##### **Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**
2412.06717v1 by Sahil Sethi, Sai Reddy, Mansi Sakarvadia, Jordan Serotte, Darlington Nwaudo, Nicholas Maassen, Lewis Shi

Bankart lesions, or anterior-inferior glenoid labral tears, are
diagnostically challenging on standard MRIs due to their subtle imaging
features-often necessitating invasive MRI arthrograms (MRAs). This study
develops deep learning (DL) models to detect Bankart lesions on both standard
MRIs and MRAs, aiming to improve diagnostic accuracy and reduce reliance on
MRAs. We curated a dataset of 586 shoulder MRIs (335 standard, 251 MRAs) from
558 patients who underwent arthroscopy. Ground truth labels were derived from
intraoperative findings, the gold standard for Bankart lesion diagnosis.
Separate DL models for MRAs and standard MRIs were trained using the Swin
Transformer architecture, pre-trained on a public knee MRI dataset. Predictions
from sagittal, axial, and coronal views were ensembled to optimize performance.
The models were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71
standard MRIs). Bankart lesions were identified in 31.9% of MRAs and 8.6% of
standard MRIs. The models achieved AUCs of 0.87 (86% accuracy, 83% sensitivity,
86% specificity) and 0.90 (85% accuracy, 82% sensitivity, 86% specificity) on
standard MRIs and MRAs, respectively. These results match or surpass
radiologist performance on our dataset and reported literature metrics.
Notably, our model's performance on non-invasive standard MRIs matched or
surpassed the radiologists interpreting MRAs. This study demonstrates the
feasibility of using DL to address the diagnostic challenges posed by subtle
pathologies like Bankart lesions. Our models demonstrate potential to improve
diagnostic confidence, reduce reliance on invasive imaging, and enhance
accessibility to care.

摘要：Bankart 病灶，或前下盂唇撕裂，由於其影像特徵微妙，在標準核磁共振成像中診斷具有挑戰性，通常需要侵入性核磁共振血管造影 (MRA)。本研究開發深度學習 (DL) 模型，用於在標準核磁共振成像和核磁共振血管造影中檢測 Bankart 病灶，旨在提高診斷準確性並減少對核磁共振血管造影的依賴。我們從 558 名接受關節鏡檢查的患者中策劃了一組 586 例肩部核磁共振成像 (335 例標準，251 例核磁共振血管造影) 的數據集。基本事實標籤來自術中發現，這是 Bankart 病灶診斷的黃金標準。使用 Swin Transformer 架構訓練了核磁共振血管造影和標準核磁共振成像的單獨深度學習模型，並在公開的膝部核磁共振成像數據集上進行預訓練。矢狀面、軸面和冠狀面的預測結果被組合起來以優化性能。這些模型在 20% 的保留測試集（117 例核磁共振成像：46 例核磁共振血管造影，71 例標準核磁共振成像）上進行了評估。在 31.9% 的核磁共振血管造影和 8.6% 的標準核磁共振成像中發現了 Bankart 病灶。這些模型在標準核磁共振成像和核磁共振血管造影中的 AUC 分別達到 0.87（86% 準確度，83% 靈敏度，86% 特異度）和 0.90（85% 準確度，82% 靈敏度，86% 特異度）。這些結果與放射科醫生對我們數據集的表現相匹配或超過，並超過了報告的文獻指標。值得注意的是，我們的模型在非侵入性標準核磁共振成像中的表現與放射科醫生對核磁共振血管造影的解釋相匹配或超過。本研究證明了使用深度學習來解決 Bankart 病灶等微妙病理診斷挑戰的可行性。我們的模型展示了提高診斷信心、減少對侵入性影像檢查的依賴以及增強獲得照護的機會的潛力。

##### **Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**
2412.06709v1 by Aqib Nazir Mir, Iqra Nissar, Mumtaz Ahmed, Sarfaraz Masood, Danish Raza Rizvi

Deep learning holds tremendous potential in healthcare for uncovering hidden
patterns within extensive clinical datasets, aiding in the diagnosis of various
diseases. Parkinson's disease (PD) is a neurodegenerative condition
characterized by the deterioration of brain function. In the initial stages of
PD, automatic diagnosis poses a challenge due to the similarity in behavior
between individuals with PD and those who are healthy. Our objective is to
propose an effective model that can aid in the early detection of Parkinson's
disease. We employed the VGRF gait signal dataset sourced from Physionet for
distinguishing between healthy individuals and those diagnosed with Parkinson's
disease. This paper introduces a novel deep learning architecture based on the
LSTM network for automatically detecting freezing of gait episodes in
Parkinson's disease patients. In contrast to conventional machine learning
algorithms, this method eliminates manual feature engineering and proficiently
captures prolonged temporal dependencies in gait patterns, thereby improving
the diagnosis of Parkinson's disease. The LSTM network resolves the issue of
vanishing gradients by employing memory blocks in place of self-connected
hidden units, allowing for optimal information assimilation. To prevent
overfitting, dropout and L2 regularization techniques have been employed.
Additionally, the stochastic gradient-based optimizer Adam is used for the
optimization process. The results indicate that our proposed approach surpasses
current state-of-the-art models in FOG episode detection, achieving an accuracy
of 97.71%, sensitivity of 99%, precision of 98%, and specificity of 96%. This
demonstrates its potential as a superior classification method for Parkinson's
disease detection.

摘要：深度學習在醫療保健領域擁有巨大的潛力，可用於發掘廣泛臨床資料集中的隱藏模式，協助診斷各種疾病。帕金森氏症 (PD) 是一種神經退化性疾病，其特徵是大腦功能惡化。在 PD 的初期階段，由於 PD 患者與健康者的行為相似，因此自動診斷具有挑戰性。我們的目標是提出一個有效的模型，可以幫助早期檢測帕金森氏症。我們採用了來自 Physionet 的 VGRF 步態信號資料集，用於區分健康個體和被診斷出患有帕金森氏症的個體。本文介紹了一種基於 LSTM 網路的深度學習新架構，用於自動檢測帕金森氏症患者的步態凍結發作。與傳統機器學習演算法相比，此方法消除了手動特徵工程，並熟練地捕捉步態模式中的長時間依賴性，從而改進了帕金森氏症的診斷。LSTM 網路通過使用記憶區塊代替自連接隱藏單元來解決梯度消失問題，從而實現最佳資訊同化。為了防止過度擬合，已採用中斷和 L2 正則化技術。此外，隨機梯度優化器 Adam 用於優化過程。結果表明，我們提出的方法在 FOG 發作檢測方面超越了當前最先進的模型，達到了 97.71% 的準確率、99% 的靈敏度、98% 的精確度和 96% 的特異性。這證明了其作為帕金森氏症檢測的優越分類方法的潛力。

##### **Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**
2412.06624v1 by Sooyong Jang, Kuk Jin Jang, Hyonyoung Choi, Yong-Seop Han, Seongjin Lee, Jin-hyun Kim, Insup Lee

Timely detection and treatment are essential for maintaining eye health.
Visual acuity (VA), which measures the clarity of vision at a distance, is a
crucial metric for managing eye health. Machine learning (ML) techniques have
been introduced to assist in VA measurement, potentially alleviating
clinicians' workloads. However, the inherent uncertainties in ML models make
relying solely on them for VA prediction less than ideal. The VA prediction
task involves multiple sources of uncertainty, requiring more robust
approaches. A promising method is to build prediction sets or intervals rather
than point estimates, offering coverage guarantees through techniques like
conformal prediction and Probably Approximately Correct (PAC) prediction sets.
Despite the potential, to date, these approaches have not been applied to the
VA prediction task.To address this, we propose a method for deriving prediction
intervals for estimating visual acuity from fundus images with a PAC guarantee.
Our experimental results demonstrate that the PAC guarantees are upheld, with
performance comparable to or better than that of two prior works that do not
provide such guarantees.

摘要：及時地偵測和治療對於維持眼睛健康至關重要。
視力（VA），用於測量遠距離視覺的清晰度，是維持眼睛健康的關鍵指標。機器學習（ML）技術已被引入以協助 VA 測量，潛在地減輕臨床醫師的工作負擔。然而，ML 模型中固有的不確定性使得僅依賴它們進行 VA 預測並非理想。VA 預測任務涉及多種不確定性來源，需要更強大的方法。一種有前途的方法是建立預測集合或區間，而不是點估計，通過像共形預測和大概正確（PAC）預測集合這樣的技術提供覆蓋率保證。儘管有潛力，但迄今為止，這些方法尚未應用於 VA 預測任務。為了解決這個問題，我們提出了一種從眼底圖像估計視力的預測區間的方法，並提供 PAC 保證。我們的實驗結果表明，PAC 保證得到維持，其性能與不提供此類保證的兩項先前工作的性能相當或更好。

##### **Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices**
2412.06874v1 by Biman Barua, M. Shamim Kaiser

The rapid growth of the travel industry has increased the need for real-time
optimization in reservation systems that could take care of huge data and
transaction volumes. This study proposes a hybrid framework that ut folds an
Artificial Intelligence and a Microservices approach for the performance
optimization of the system. The AI algorithms forecast demand patterns,
optimize the allocation of resources, and enhance decision-making driven by
Microservices architecture, hence decentralizing system components for
scalability, fault tolerance, and reduced downtime. The model provided focuses
on major problems associated with the travel reservation systems such as
latency of systems, load balancing and data consistency. It endows the systems
with predictive models based on AI improved ability to forecast user demands.
Microservices would also take care of different scales during uneven traffic
patterns. Hence, both aspects ensure better handling of peak loads and spikes
while minimizing delays and ensuring high service quality. A comparison was
made between traditional reservation models, which are monolithic and the new
model of AI-Microservices. Comparatively, the analysis results state that there
is a drastic improvement in processing times where the system uptime and
resource utilization proved the capability of AI and the microservices in
transforming the travel industry in terms of reservation. This research work
focused on AI and Microservices towards real-time optimization, providing
critical insight into how to move forward with practical recommendations for
upgrading travel reservation systems with this technology.

摘要：旅遊產業快速成長，提升了預訂系統中即時最佳化的需求，這個系統可以處理龐大的資料和交易量。本研究提出一個混合架構，它結合人工智慧和微服務方法來最佳化系統效能。人工智慧演算法預測需求模式，最佳化資源配置，並加強由微服務架構驅動的決策制定，因此分散系統元件以利於擴充性、容錯能力和減少停機時間。所提供的模型專注於與旅遊預訂系統相關的主要問題，例如系統延遲、負載平衡和資料一致性。它賦予系統預測模型，基於人工智慧提升預測使用者需求的能力。微服務也會在流量模式不均時處理不同的規模。因此，這兩個面向確保能更好地處理尖峰負載和流量激增，同時將延遲降到最低並確保高服務品質。比較傳統的預訂模型（單體式）和新的 AI-微服務模型。比較之下，分析結果指出處理時間有顯著改善，其中系統正常運行時間和資源使用率證明了人工智慧和微服務在預訂方面轉型旅遊產業的能力。這項研究工作專注於人工智慧和微服務，以實現即時最佳化，提供關鍵見解，說明如何透過實用建議，使用這項技術升級旅遊預訂系統。

##### **Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System**
2412.06600v2 by Yubo Zhou, Weizhen Bian, Kaitai Zhang, Xiaohan Gu

In traditional medical practices, music therapy has proven effective in
treating various psychological and physiological ailments. Particularly in
Eastern traditions, the Five Elements Music Therapy (FEMT), rooted in
traditional Chinese medicine, possesses profound cultural significance and
unique therapeutic philosophies. With the rapid advancement of Information
Technology and Artificial Intelligence, applying these modern technologies to
FEMT could enhance the personalization and cultural relevance of the therapy
and potentially improve therapeutic outcomes. In this article, we developed a
music therapy system for the first time by applying the theory of the five
elements in music therapy to practice. This innovative approach integrates
advanced Information Technology and Artificial Intelligence with Five-Element
Music Therapy (FEMT) to enhance personalized music therapy practices. As
traditional music therapy predominantly follows Western methodologies, the
unique aspects of Eastern practices, specifically the Five-Element theory from
traditional Chinese medicine, should be considered. This system aims to bridge
this gap by utilizing computational technologies to provide a more
personalized, culturally relevant, and therapeutically effective music therapy
experience.

摘要：在傳統醫學中，音樂療法已被證實能有效治療各種心理和生理疾病。特別是在東方傳統中，根植於中醫的五行音樂療法 (FEMT) 具有深遠的文化意義和獨特的治療理念。隨著資訊科技和人工智慧的快速發展，將這些現代技術應用於 FEMT 可以增強療法的個人化和文化相關性，並有可能改善治療效果。在本文中，我們首次通過將音樂療法中的五行理論應用於實踐，開發了一個音樂療法系統。這種創新方法將先進的資訊科技和人工智慧與五行音樂療法 (FEMT) 相結合，以增強個性化的音樂療法實務。由於傳統音樂療法主要遵循西方方法，因此應考慮東方實務的獨特方面，特別是中醫的五行理論。此系統旨在利用計算技術彌合這一差距，以提供更個人化、文化相關且治療效果更好的音樂療法體驗。

##### **HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**
2412.06530v1 by Jiayan Chen, Kai Li, Zhanjin Wang, Zhan Wang, Jianqiang Huang

Hepatic echinococcosis (HE) is a prevalent disease in economically
underdeveloped pastoral areas, where adequate medical resources are usually
lacking. Existing methods often ignore multi-scale feature fusion or focus only
on feature fusion between adjacent levels, which may lead to insufficient
feature fusion. To address these issues, we propose HES-UNet, an efficient and
accurate model for HE lesion segmentation. This model combines convolutional
layers and attention modules to capture local and global features. During
downsampling, the multi-directional downsampling block (MDB) is employed to
integrate high-frequency and low-frequency features, effectively extracting
image details. The multi-scale aggregation block (MAB) aggregates multi-scale
feature information. In contrast, the multi-scale upsampling Block (MUB) learns
highly abstract features and supplies this information to the skip connection
module to fuse multi-scale features. Due to the distinct regional
characteristics of HE, there is currently no publicly available high-quality
dataset for training our model. We collected CT slice data from 268 patients at
a certain hospital to train and evaluate the model. The experimental results
show that HES-UNet achieves state-of-the-art performance on our dataset,
achieving an overall Dice Similarity Coefficient (DSC) of 89.21%, which is
1.09% higher than that of TransUNet. The project page is available at
https://chenjiayan-qhu.github.io/HES-UNet-page.

摘要：肝包蟲病（HE）在經濟落後的畜牧地區盛行，那裡通常缺乏足夠的醫療資源。現有方法通常忽略多尺度特徵融合，或僅關注相鄰層之間的特徵融合，這可能導致特徵融合不足。為了解決這些問題，我們提出了 HES-UNet，這是一種用於 HE 病灶分割的高效且準確的模型。此模型結合了卷積層和注意力模組，以擷取局部和全局特徵。在降採樣過程中，採用多向降採樣區塊 (MDB) 來整合高頻和低頻特徵，有效提取影像細節。多尺度聚合區塊 (MAB) 聚合多尺度特徵資訊。相反，多尺度上採樣區塊 (MUB) 會學習高度抽象的特徵，並將此資訊提供給跳躍連接模組，以融合多尺度特徵。由於 HE 的區域特徵不同，目前沒有公開可用的高品質資料集可供訓練我們的模型。我們從某家醫院收集了 268 位患者的 CT 切片資料，以訓練和評估模型。實驗結果表明，HES-UNet 在我們的資料集上達到了最先進的效能，整體 Dice 相似性係數 (DSC) 達到 89.21%，比 TransUNet 高 1.09%。專案頁面可於 https://chenjiayan-qhu.github.io/HES-UNet-page 取得。

##### **Simulating Human-like Daily Activities with Desire-driven Autonomy**
2412.06435v1 by Yiding Wang, Yuxuan Chen, Fangwei Zhong, Long Ma, Yizhou Wang

Existing task-oriented AI agents often depend on explicit instructions or
external rewards, limiting their ability to be driven by intrinsic motivations
like humans. In this paper, we present a desire-driven autonomy framework to
guide a Large Language Model-based (LLM-based) agent to simulate human-like
daily activities. In contrast to previous agents, our Desire-driven Autonomous
Agent (D2A) operates on the principle of intrinsic desire, allowing it to
propose and select tasks that fulfill its motivational framework autonomously.
Inspired by the Theory of Needs, the motivational framework incorporates an
understanding of human-like desires, such as the need for social interaction,
personal fulfillment, and self-care. Utilizing a desire-driven task generation
mechanism, the agent evaluates its current state and takes a sequence of
activities aligned with its intrinsic motivations. Through simulations, we
demonstrate that our Desire-driven Autonomous Agent (D2A) generates coherent,
contextually relevant daily activities while exhibiting variability and
adaptability similar to human behavior. A comparative analysis with other
LLM-based frameworks demonstrates that our approach significantly enhances the
rationality of the simulated activities.

摘要：現有的任務導向 AI 代理通常依賴明確的指示或外部獎勵，這限制了它們像人類一樣由內在動機驅動的能力。在本文中，我們提出了一個慾望驅動的自主框架，以指導基於大型語言模型 (LLM) 的代理模擬類人的日常活動。與之前的代理不同，我們的慾望驅動自主代理 (D2A) 遵循內在慾望的原則，允許它自主提出和選擇符合其動機框架的任務。受需求理論的啟發，動機框架包含對類人慾望的理解，例如社會互動、個人滿足和自我保健的需要。利用慾望驅動任務生成機制，代理評估其當前狀態並採取一系列與其內在動機一致的活動。通過模擬，我們證明了我們的慾望驅動自主代理 (D2A) 產生了連貫、與上下文相關的日常活動，同時表現出與人類行為相似的可變性和適應性。與其他基於 LLM 的框架進行比較分析表明，我們的做法顯著提高了模擬活動的合理性。

##### **CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**
2412.06314v1 by Yijie Dang, Weijun Ma, Xiaohu Luo

Since the outbreak of the COVID-19 pandemic in 2019, medical imaging has
emerged as a primary modality for diagnosing COVID-19 pneumonia. In clinical
settings, the segmentation of lung infections from computed tomography images
enables rapid and accurate quantification and diagnosis of COVID-19.
Segmentation of COVID-19 infections in the lungs poses a formidable challenge,
primarily due to the indistinct boundaries and limited contrast presented by
ground glass opacity manifestations. Moreover, the confounding similarity
between infiltrates, lung tissues, and lung walls further complicates this
segmentation task. To address these challenges, this paper introduces a novel
deep network architecture, called CAD-Unet, for segmenting COVID-19 lung
infections. In this architecture, capsule networks are incorporated into the
existing Unet framework. Capsule networks represent a novel network
architecture that differs from traditional convolutional neural networks. They
utilize vectors for information transfer among capsules, facilitating the
extraction of intricate lesion spatial information. Additionally, we design a
capsule encoder path and establish a coupling path between the unet encoder and
the capsule encoder. This design maximizes the complementary advantages of both
network structures while achieving efficient information fusion. \noindent
Finally, extensive experiments are conducted on four publicly available
datasets, encompassing binary segmentation tasks and multi-class segmentation
tasks. The experimental results demonstrate the superior segmentation
performance of the proposed model. The code has been released at:
https://github.com/AmanoTooko-jie/CAD-Unet.

摘要：自 2019 年 COVID-19 大流行爆发以来，医学影像已成为诊断 COVID-19 肺炎的主要方式。在临床环境中，从计算机断层扫描图像中分割肺部感染，可以快速、准确地量化和诊断 COVID-19。分割肺部中的 COVID-19 感染是一个艰巨的挑战，这主要是由于毛玻璃样变现出的边界不清晰且对比度有限。此外，浸润、肺组织和肺壁之间的混淆相似性进一步复杂化了这项分割任务。为了应对这些挑战，本文介绍了一种新颖的深度网络架构，称为 CAD-Unet，用于分割 COVID-19 肺部感染。在此架构中，胶囊网络被纳入现有的 Unet 框架中。胶囊网络代表了一种新颖的网络架构，它不同于传统的卷积神经网络。它们利用向量在胶囊之间进行信息传输，促进了复杂病变空间信息的提取。此外，我们设计了一个胶囊编码器路径，并在 unet 编码器和胶囊编码器之间建立了一个耦合路径。这种设计最大限度地发挥了两种网络结构的互补优势，同时实现了高效的信息融合。\noindent
最后，在四个公开可用的数据集上进行了广泛的实验，包括二进制分割任务和多类分割任务。实验结果证明了所提出模型的卓越分割性能。该代码已发布在：
https://github.com/AmanoTooko-jie/CAD-Unet。

##### **A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder**
2412.06262v1 by Quansong He, Xiaojun Yao, Jun Wu, Zhang Yi, Tao He

In recent years, advanced U-like networks have demonstrated remarkable
performance in medical image segmentation tasks. However, their drawbacks,
including excessive parameters, high computational complexity, and slow
inference speed, pose challenges for practical implementation in scenarios with
limited computational resources. Existing lightweight U-like networks have
alleviated some of these problems, but they often have pre-designed structures
and consist of inseparable modules, limiting their application scenarios. In
this paper, we propose three plug-and-play decoders by employing different
discretization methods of the neural memory Ordinary Differential Equations
(nmODEs). These decoders integrate features at various levels of abstraction by
processing information from skip connections and performing numerical
operations on upward path. Through experiments on the PH2, ISIC2017, and
ISIC2018 datasets, we embed these decoders into different U-like networks,
demonstrating their effectiveness in significantly reducing the number of
parameters and FLOPs while maintaining performance. In summary, the proposed
discretized nmODEs decoders are capable of reducing the number of parameters by
about 20% ~ 50% and FLOPs by up to 74%, while possessing the potential to adapt
to all U-like networks. Our code is available at
https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks.

摘要：近年來，先進的 U 型網路在醫學影像分割任務中展現出卓越的表現。然而，它們的缺點包括過多的參數、高運算複雜度和緩慢的推論速度，對在運算資源有限的情況下實際執行構成挑戰。現有的輕量級 U 型網路已經減輕了這些問題，但它們通常有預先設計的結構，並包含不可分離的模組，限制了它們的應用場景。在本文中，我們透過採用神經記憶常微分方程式 (nmODE) 的不同離散化方法，提出了三個即插即用的解碼器。這些解碼器透過處理來自跳躍連接的資訊，並在向上路徑上執行數值運算，整合了不同抽象層級的特徵。透過在 PH2、ISIC2017 和 ISIC2018 資料集上的實驗，我們將這些解碼器嵌入到不同的 U 型網路中，證明它們在顯著減少參數和 FLOP 的同時，還能維持效能。總之，所提出的離散 nmODE 解碼器能夠將參數數量減少約 20% ~ 50%，FLOP 最多減少 74%，同時具備適應所有 U 型網路的潛力。我們的程式碼可以在 https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks 取得。

##### **MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery**
2412.06211v1 by Qinfeng Zhu, Yuan Fang, Lei Fan

Crack detection is a critical task in structural health monitoring, aimed at
assessing the structural integrity of bridges, buildings, and roads to prevent
potential failures. Vision-based crack detection has become the mainstream
approach due to its ease of implementation and effectiveness. Fusing infrared
(IR) channels with red, green and blue (RGB) channels can enhance feature
representation and thus improve crack detection. However, IR and RGB channels
often differ in resolution. To align them, higher-resolution RGB images
typically need to be downsampled to match the IR image resolution, which leads
to the loss of fine details. Moreover, crack detection performance is
restricted by the limited receptive fields and high computational complexity of
traditional image segmentation networks. Inspired by the recently proposed
Mamba neural architecture, this study introduces a two-stage paradigm called
MSCrackMamba, which leverages Vision Mamba along with a super-resolution
network to address these challenges. Specifically, to align IR and RGB
channels, we first apply super-resolution to IR channels to match the
resolution of RGB channels for data fusion. Vision Mamba is then adopted as the
backbone network, while UperNet is employed as the decoder for crack detection.
Our approach is validated on the large-scale Crack Detection dataset Crack900,
demonstrating an improvement of 3.55% in mIoU compared to the best-performing
baseline methods.

摘要：裂縫偵測在結構健康監測中是一項重要的任務，旨在評估橋樑、建築物和道路的結構完整性，以防止潛在的故障。基於視覺的裂縫偵測由於其易於實作和有效性，已成為主流方法。將紅外線 (IR) 通道與紅色、綠色和藍色 (RGB) 通道融合可以增強特徵表示，進而改善裂縫偵測。然而，IR 和 RGB 通道通常解析度不同。為了對齊它們，通常需要對較高解析度的 RGB 影像進行降採樣以匹配 IR 影像解析度，這會導致精細細節的遺失。此外，裂縫偵測效能受到傳統影像分割網路有限的感受野和高運算複雜度的限制。受近期提出的 Mamba 神經架構啟發，本研究引入了一個稱為 MSCrackMamba 的兩階段範例，它利用 Vision Mamba 和超解析度網路來應對這些挑戰。具體來說，為了對齊 IR 和 RGB 通道，我們首先對 IR 通道應用超解析度，以匹配 RGB 通道的解析度，以進行資料融合。然後採用 Vision Mamba 作為骨幹網路，同時採用 UperNet 作為裂縫偵測的解碼器。我們的做法已在大型裂縫偵測資料集 Crack900 中得到驗證，與效能最佳的基準方法相比，mIoU 提升了 3.55%。

##### **Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction**
2412.06860v1 by Guoxiao Zhang, Yi Wei, Yadong Zhang, Huajian Feng, Qiang Liu

Click-Through Rate (CTR) prediction is essential in online advertising, where
semantic information plays a pivotal role in shaping user decisions and
enhancing CTR effectiveness. Capturing and modeling deep semantic information,
such as a user's preference for "H\"aagen-Dazs' HEAVEN strawberry light ice
cream" due to its health-conscious and premium attributes, is challenging.
Traditional semantic modeling often overlooks these intricate details at the
user and item levels. To bridge this gap, we introduce a novel approach that
models deep semantic information end-to-end, leveraging the comprehensive world
knowledge capabilities of Large Language Models (LLMs). Our proposed
LLM-infused CTR prediction framework(Multi-level Deep Semantic Information
Infused CTR model via Distillation, MSD) is designed to uncover deep semantic
insights by utilizing LLMs to extract and distill critical information into a
smaller, more efficient model, enabling seamless end-to-end training and
inference. Importantly, our framework is carefully designed to balance
efficiency and effectiveness, ensuring that the model not only achieves high
performance but also operates with optimal resource utilization. Online A/B
tests conducted on the Meituan sponsored-search system demonstrate that our
method significantly outperforms baseline models in terms of Cost Per Mile
(CPM) and CTR, validating its effectiveness, scalability, and balanced approach
in real-world applications.

摘要：點擊率 (CTR) 預測在線上廣告中至關重要，其中語意資訊在塑造使用者決策和提升 CTR 效益方面扮演著關鍵角色。擷取和建模深入的語意資訊（例如使用者偏好「H\"aagen-Dazs' HEAVEN 草莓輕盈冰淇淋」，因為它具有注重健康和高級的屬性）是一項挑戰。傳統的語意建模通常會忽略使用者和項目層級的這些複雜細節。為了彌補此差距，我們提出了一種創新的方法，該方法可以端對端地建模深入語意資訊，並利用大型語言模型 (LLM) 的全面世界知識能力。我們提出的 LLM 注入 CTR 預測架構（透過知識萃取的多層級深入語意資訊注入 CTR 模型，MSD）旨在透過利用 LLM 萃取和提煉關鍵資訊到一個更小、更有效率的模型中，來發掘深入的語意洞察，實現無縫端對端訓練和推論。重要的是，我們的架構經過仔細設計，以平衡效率和效能，確保模型不僅能達成高性能，還能以最佳資源利用率運作。在美團贊助搜尋系統上進行的線上 A/B 測試證明，我們的模型在每千次成本 (CPM) 和 CTR 方面顯著優於基線模型，驗證了其在實際應用中的有效性、可擴充性和平衡方法。

##### **MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**
2412.06141v1 by Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao

The advancement of Large Vision-Language Models (LVLMs) has propelled their
application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter
factuality challenges due to modality misalignment, where the models prioritize
textual knowledge over visual input, leading to hallucinations that contradict
information in medical images. Previous attempts to enhance modality alignment
in Med-LVLMs through preference optimization have inadequately mitigated
clinical relevance in preference data, making these samples easily
distinguishable and reducing alignment effectiveness. To address this
challenge, we propose MMedPO, a novel multimodal medical preference
optimization approach that considers the clinical relevance of preference
samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference
data by introducing two types of dispreference: (1) plausible hallucinations
injected through target Med-LVLMs or GPT-4o to produce medically inaccurate
responses, and (2) lesion region neglect achieved through local lesion-noising,
disrupting visual understanding of critical areas. We then calculate clinical
relevance for each sample based on scores from multiple Med-LLMs and visual
tools, and integrate these scores into the preference optimization process as
weights, enabling effective alignment. Our experiments demonstrate that MMedPO
significantly enhances factual accuracy in Med-LVLMs, achieving substantial
improvements over existing preference optimization methods by averaging 14.2%
and 51.7% across the Med-VQA and report generation tasks. Our code are
available in https://github.com/aiming-lab/MMedPO.

摘要：大型視覺語言模型 (LVLMs) 的進步推動了它們在醫療領域的應用。然而，醫學 LVLMs (Med-LVLMs) 由於模態錯位而遇到事實挑戰，其中模型優先考慮文字知識而非視覺輸入，導致幻覺與醫學影像中的資訊相矛盾。先前嘗試透過偏好最佳化來增強 Med-LVLMs 中的模態對齊，在偏好資料中不足以減輕臨床相關性，使得這些範例容易區分，並降低對齊效果。為了應對這項挑戰，我們提出 MMedPO，一種新的多模態醫學偏好最佳化方法，它考慮偏好範例的臨床相關性，以增強 Med-LVLM 對齊。MMedPO 透過引入兩種類型的反偏好來管理多模態偏好資料：(1) 合理的幻覺透過目標 Med-LVLMs 或 GPT-4o 注入，以產生醫學上不準確的回應，以及 (2) 透過局部病灶雜訊實現病灶區域忽略，破壞對關鍵區域的視覺理解。然後，我們根據來自多個 Med-LLMs 和視覺工具的分數計算每個範例的臨床相關性，並將這些分數作為權重整合到偏好最佳化過程中，以實現有效對齊。我們的實驗證明，MMedPO 明顯增強了 Med-LVLMs 中的事實準確性，在 Med-VQA 和報告生成任務中，平均分別比現有的偏好最佳化方法提高了 14.2% 和 51.7%。我們的程式碼可以在 https://github.com/aiming-lab/MMedPO 中取得。

##### **Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research**
2412.06018v1 by Akshat Choube, Rahul Majethia, Sohini Bhattacharya, Vedant Das Swain, Jiachen Li, Varun Mishra

Longitudinal passive sensing studies for health and behavior outcomes often
have missing and incomplete data. Handling missing data effectively is thus a
critical data processing and modeling step. Our formative interviews with
researchers working in longitudinal health and behavior passive sensing
revealed a recurring theme: most researchers consider imputation a low-priority
step in their analysis and inference pipeline, opting to use simple and
off-the-shelf imputation strategies without comprehensively evaluating its
impact on study outcomes. Through this paper, we call attention to the
importance of imputation. Using publicly available passive sensing datasets for
depression, we show that prioritizing imputation can significantly impact the
study outcomes -- with our proposed imputation strategies resulting in up to
31% improvement in AUROC to predict depression over the original imputation
strategy. We conclude by discussing the challenges and opportunities with
effective imputation in longitudinal sensing studies.

摘要：縱向被動感測研究對於健康和行為結果常常有缺失和不完整的資料。有效處理缺失資料因此是資料處理和建模的重要步驟。我們與從事縱向健康和行為被動感測的研究人員進行的形成性訪談揭露了一個反覆出現的主題：大多數研究人員認為內插是其分析和推論流程中優先順序較低的一個步驟，選擇使用簡單且現成的內插策略，而沒有全面評估其對研究結果的影響。透過這篇論文，我們呼籲重視內插。使用公開的被動感測資料集進行憂鬱症研究，我們證明優先考慮內插會對研究結果產生重大影響——我們提出的內插策略使 AUROC 預測憂鬱症的能力比原始內插策略提高了 31%。最後，我們討論了在縱向感測研究中有效內插的挑戰和機會。

##### **MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training**
2412.05876v1 by Xuefeng Ni, Linshan Wu, Jiaxin Zhuang, Qiong Wang, Mingxiang Wu, Varut Vardhanabhuti, Lihai Zhang, Hanyu Gao, Hao Chen

3D medical image analysis is pivotal in numerous clinical applications.
However, the scarcity of labeled data and limited generalization capabilities
hinder the advancement of AI-empowered models. Radiology reports are easily
accessible and can serve as weakly-supervised signals. However, large-scale
vision-language pre-training (VLP) remains underexplored in 3D medical image
analysis. Specifically, the insufficient investigation into multi-grained
radiology semantics and their correlations across patients leads to
underutilization of large-scale volume-report data.
  Considering intra-patient cross-modal semantic consistency and inter-patient
semantic correlations, we propose a multi-task VLP method, MG-3D, pre-trained
on large-scale data (47.1K), addressing the challenges by the following two
aspects: 1) Establishing the correspondence between volume semantics and
multi-grained medical knowledge of each patient with cross-modal global
alignment and complementary modality-guided local reconstruction, ensuring
intra-patient features of different modalities cohesively represent the same
semantic content; 2) Correlating inter-patient visual semantics based on
fine-grained report correlations across patients, and keeping sensitivity to
global individual differences via contrastive learning, enhancing the
discriminative feature representation. Furthermore, we delve into the scaling
law to explore potential performance improvements. Comprehensive evaluations
across nine uni- and cross-modal clinical tasks are carried out to assess model
efficacy. Extensive experiments on both internal and external datasets
demonstrate the superior transferability, scalability, and generalization of
MG-3D, showcasing its potential in advancing feature representation for 3D
medical image analysis. Code will be available:
https://github.com/Xuefeng-Ni/MG-3D.

摘要：<paragraph>3D 醫學影像分析在眾多臨床應用中至關重要。
然而，標記資料的稀缺和有限的概化能力
阻礙了 AI 賦能模型的進步。放射報告容易獲得，可以用作弱監督信號。然而，大規模
視覺語言預訓練 (VLP) 在 3D 醫學影像
分析中仍未得到充分探索。具體來說，對多粒度
放射語義及其在患者之間的相關性研究不足，導致大規模體積報告數據利用不足。
考慮到患者內部跨模態語義一致性和患者間
語義相關性，我們提出了一種多任務 VLP 方法 MG-3D，預訓練
在大型數據 (47.1K) 上，通過以下兩個方面解決挑戰：1) 建立體積語義和
每個患者的多粒度醫學知識之間的對應關係，通過跨模態全局
對齊和互補模態引導的局部重建，確保不同模態的患者內部特徵一致地表示相同的
語義內容；2) 基於患者之間的細粒度報告相關性對患者間的視覺語義進行關聯，並通過對比學習保持對
全局個體差異的敏感性，增強判別特徵表示。此外，我們深入研究了擴展
定律以探索潛在的性能改進。跨越九項單模態和跨模態臨床任務的綜合評估是進行的，以評估模型
效能。在內部和外部數據集上的廣泛實驗
證明了 MG-3D 的卓越可傳遞性、可擴展性和泛化性，展示了其在推進 3D
醫學影像分析特徵表示方面的潛力。代碼將提供：
https://github.com/Xuefeng-Ni/MG-3D。</paragraph>

##### **Evolving Algebraic Multigrid Methods Using Grammar-Guided Genetic Programming**
2412.05852v1 by Dinesh Parthasarathy, Wayne Bradford Mitchell, Harald Köstler

Multigrid methods despite being known to be asymptotically optimal
algorithms, depend on the careful selection of their individual components for
efficiency. Also, they are mostly restricted to standard cycle types like V-,
F-, and W-cycles. We use grammar rules to generate arbitrary-shaped cycles,
wherein the smoothers and their relaxation weights are chosen independently at
each step within the cycle. We call this a flexible multigrid cycle. These
flexible cycles are used in Algebraic Multigrid (AMG) methods with the help of
grammar rules and optimized using genetic programming. The flexible AMG methods
are implemented in the software library of hypre, and the programs are
optimized separately for two cases: a standalone AMG solver for a 3D
anisotropic problem and an AMG preconditioner with conjugate gradient for a
multiphysics code. We observe that the optimized flexible cycles provide higher
efficiency and better performance than the standard cycle types.

摘要：多重網格法儘管已知為漸近最佳演算法，但其效率取決於其個別組成的仔細選擇。此外，它們大多侷限於標準循環類型，例如 V、F 和 W 循環。我們使用語法規則來產生任意形狀的循環，其中平滑器及其鬆弛權重在循環中的每個步驟中獨立選擇。我們稱之為彈性多重網格循環。這些彈性循環在代數多重網格 (AMG) 方法中使用，並在語法規則的幫助下使用遺傳程式設計進行最佳化。彈性 AMG 方法在 hypre 的軟體程式庫中實作，且程式針對兩種情況分別最佳化：3D 異向性問題的獨立 AMG 求解器，以及多物理場程式碼的共軛梯度 AMG 預處理器。我們觀察到最佳化的彈性循環提供比標準循環類型更高的效率和更好的效能。

##### **Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages**
2412.05632v1 by Abd Ur Rehman, Azka Rehman, Muhammad Usman, Abdullah Shahid, Sung-Min Gho, Aleum Lee, Tariq M. Khan, Imran Razzak

Brain aging involves structural and functional changes and therefore serves
as a key biomarker for brain health. Combining structural magnetic resonance
imaging (sMRI) and functional magnetic resonance imaging (fMRI) has the
potential to improve brain age estimation by leveraging complementary data.
However, fMRI data, being noisier than sMRI, complicates multimodal fusion.
Traditional fusion methods often introduce more noise than useful information,
which can reduce accuracy compared to using sMRI alone. In this paper, we
propose a novel multimodal framework for biological brain age estimation,
utilizing a sex-aware adversarial variational autoencoder (SA-AVAE). Our
framework integrates adversarial and variational learning to effectively
disentangle the latent features from both modalities. Specifically, we
decompose the latent space into modality-specific codes and shared codes to
represent complementary and common information across modalities, respectively.
To enhance the disentanglement, we introduce cross-reconstruction and
shared-distinct distance ratio loss as regularization terms. Importantly, we
incorporate sex information into the learned latent code, enabling the model to
capture sex-specific aging patterns for brain age estimation via an integrated
regressor module. We evaluate our model using the publicly available OpenBHB
dataset, a comprehensive multi-site dataset for brain age estimation. The
results from ablation studies and comparisons with state-of-the-art methods
demonstrate that our framework outperforms existing approaches and shows
significant robustness across various age groups, highlighting its potential
for real-time clinical applications in the early detection of neurodegenerative
diseases.

摘要：大腦老化涉及結構和功能的改變，因此可作為大腦健康的關鍵生物標記。結合結構性磁振造影 (sMRI) 和功能性磁振造影 (fMRI) 有可能透過利用互補數據來改善大腦年齡估計。然而，fMRI 資料比 sMRI 雜訊更多，這使得多模態融合變得複雜。傳統融合方法通常會引入比有用資訊更多雜訊，這可能會降低與單獨使用 sMRI 相比的準確性。在本文中，我們提出一個用於生物大腦年齡估計的新多模態框架，利用一個有性別意識的對抗變異自動編碼器 (SA-AVAE)。我們的框架整合了對抗和變異學習，以有效地解開來自兩種模態的潛在特徵。具體而言，我們將潛在空間分解為特定於模態的代碼和共享代碼，分別表示跨模態的互補和共同資訊。為了增強解開，我們引入了交叉重建和共享不同距離比率損失作為正則化項。重要的是，我們將性別資訊納入學習到的潛在代碼中，使模型能夠透過整合回歸模組，捕捉特定於性別的老化模式，以進行大腦年齡估計。我們使用公開可用的 OpenBHB 資料集評估我們的模型，這是一個用於大腦年齡估計的綜合多場域資料集。消融研究和與最先進方法的比較結果表明，我們的框架優於現有方法，並在各個年齡組中顯示出顯著的穩健性，突顯了其在神經退化性疾病早期檢測中的即時臨床應用潛力。

##### **UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation**
2412.05585v1 by Saba Hesaraki, Morteza Akbari, Ramin Mousa

Breast cancer stands as a prevalent cause of fatality among females on a
global scale, with prompt detection playing a pivotal role in diminishing
mortality rates. The utilization of ultrasound scans in the BUSI dataset for
medical imagery pertaining to breast cancer has exhibited commendable
segmentation outcomes through the application of UNet and UNet++ networks.
Nevertheless, a notable drawback of these models resides in their inattention
towards the temporal aspects embedded within the images. This research
endeavors to enrich the UNet++ architecture by integrating LSTM layers and
self-attention mechanisms to exploit temporal characteristics for segmentation
purposes. Furthermore, the incorporation of a Multiscale Feature Extraction
Module aims to grasp varied scale features within the UNet++. Through the
amalgamation of our proposed methodology with data augmentation on the BUSI
with GT dataset, an accuracy rate of 98.88%, specificity of 99.53%, precision
of 95.34%, sensitivity of 91.20%, F1-score of 93.74, and Dice coefficient of
92.74% are achieved. These findings demonstrate competitiveness with
cutting-edge techniques outlined in existing literature.

摘要：乳癌是全球女性死亡的主要原因，及早發現對於降低死亡率扮演關鍵角色。在 BUSI 資料集中使用超音波掃描進行乳癌相關的醫學影像，透過應用 UNet 和 UNet++ 網路已展現出令人滿意的分割結果。然而，這些模型一個顯著的缺點在於它們忽略了影像中包含的時間面向。本研究致力於透過整合 LSTM 層和自我注意機制來豐富 UNet++ 架構，以利用時間特徵進行分割。此外，整合多尺度特徵萃取模組旨在掌握 UNet++ 中各種尺度的特徵。透過將我們提出的方法與 BUSI with GT 資料集上的資料擴充結合，達到了 98.88% 的準確率、99.53% 的特異性、95.34% 的精確度、91.20% 的敏感度、93.74 的 F1 分數，以及 92.74% 的 Dice 係數。這些發現證明了與現有文獻中概述的尖端技術具有競爭力。

##### **Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms**
2412.05583v2 by Atit Pokharel, Shashank Dahal, Pratik Sapkota, Bhupendra Bimal Chhetri

The rapid advancements in Artificial Intelligence, specifically Machine
Learning (ML) and Deep Learning (DL), have opened new prospects in medical
sciences for improved diagnosis, prognosis, and treatment of severe health
conditions. This paper focuses on the development of an ML model with high
predictive accuracy to classify arrhythmic electrocardiogram (ECG) signals. The
ECG signals datasets utilized in this study were sourced from the PhysioNet and
MIT-BIH databases. The research commenced with binary classification, where an
optimized Bidirectional Long Short-Term Memory (Bi-LSTM) model yielded
excellent results in differentiating normal and atrial fibrillation signals. A
pivotal aspect of this research was a survey among medical professionals, which
not only validated the practicality of AI-based ECG classifiers but also
identified areas for improvement, including accuracy and the inclusion of more
arrhythmia types. These insights drove the development of an advanced
Convolutional Neural Network (CNN) system capable of classifying five different
types of ECG signals with better accuracy and precision. The CNN model's robust
performance was ensured through rigorous stratified 5-fold cross validation. A
web portal was also developed to demonstrate real-world utility, offering
access to the trained model for real-time classification. This study highlights
the potential applications of such models in remote health monitoring,
predictive healthcare, assistive diagnostic tools, and simulated environments
for educational training and interdisciplinary collaboration between data
scientists and medical personnel.

摘要：人工智慧的快速進展，特別是機器學習（ML）和深度學習（DL），為醫學科學開闢了新的前景，以改善嚴重健康狀況的診斷、預後和治療。本文重點在於開發具有高預測精度的 ML 模型，用於分類心律不整心電圖 (ECG) 信號。本研究中使用的 ECG 信號資料集來自 PhysioNet 和 MIT-BIH 資料庫。研究從二元分類開始，其中經過最佳化的雙向長短期記憶 (Bi-LSTM) 模型在區分正常和心房顫動信號方面產生了極佳的結果。本研究的一個關鍵方面是針對醫護專業人員進行的調查，這不僅驗證了基於 AI 的 ECG 分類器的實用性，還找出改進領域，包括準確性和納入更多心律不整類型。這些見解推動了先進卷積神經網路 (CNN) 系統的開發，該系統能夠以更高的準確度和精確度對五種類型的 ECG 信號進行分類。透過嚴格的分層 5 倍交叉驗證，確保了 CNN 模型的強健效能。還開發了一個網路入口網站來展示真實世界的效用，提供存取已訓練模型以進行即時分類。本研究強調了此類模型在遠距健康監測、預測性醫療保健、輔助診斷工具以及用於教育訓練和資料科學家與醫護人員之間跨領域合作的模擬環境中的潛在應用。

##### **Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison**
2412.05536v1 by Cailian Ruan, Chengyue Huang, Yahe Yang

This study introduces an evaluation framework for multimodal models in
medical imaging diagnostics. We developed a pipeline incorporating data
preprocessing, model inference, and preference-based evaluation, expanding an
initial set of 500 clinical cases to 3,000 through controlled augmentation. Our
method combined medical images with clinical observations to generate
assessments, using Claude 3.5 Sonnet for independent evaluation against
physician-authored diagnoses. The results indicated varying performance across
models, with Llama 3.2-90B outperforming human diagnoses in 85.27% of cases. In
contrast, specialized vision models like BLIP2 and Llava showed preferences in
41.36% and 46.77% of cases, respectively. This framework highlights the
potential of large multimodal models to outperform human diagnostics in certain
tasks.

摘要：本研究引入了一個用於醫療影像診斷中多模態模型的評估框架。我們開發了一個結合了資料前處理、模型推論和基於偏好的評估的管道，透過受控擴充將最初的 500 個臨床案例擴充到 3,000 個。我們的做法結合了醫學影像和臨床觀察，以產生評估，使用 Claude 3.5 Sonnet 對抗醫師撰寫的診斷進行獨立評估。結果顯示不同模型的表現不同，其中 Llama 3.2-90B 在 85.27% 的案例中優於人類診斷。相比之下，專門的視覺模型，例如 BLIP2 和 Llava，分別在 41.36% 和 46.77% 的案例中顯示出偏好。此框架突顯了大型多模態模型在某些任務中優於人類診斷的潛力。

##### **Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System**
2412.06828v1 by Fang Zeng, Zhiliang Lyu, Quanzheng Li, Xiang Li

This study introduces "RadCouncil," a multi-agent Large Language Model (LLM)
framework designed to enhance the generation of impressions in radiology
reports from the finding section. RadCouncil comprises three specialized
agents: 1) a "Retrieval" Agent that identifies and retrieves similar reports
from a vector database, 2) a "Radiologist" Agent that generates impressions
based on the finding section of the given report plus the exemplar reports
retrieved by the Retrieval Agent, and 3) a "Reviewer" Agent that evaluates the
generated impressions and provides feedback. The performance of RadCouncil was
evaluated using both quantitative metrics (BLEU, ROUGE, BERTScore) and
qualitative criteria assessed by GPT-4, using chest X-ray as a case study.
Experiment results show improvements in RadCouncil over the single-agent
approach across multiple dimensions, including diagnostic accuracy, stylistic
concordance, and clarity. This study highlights the potential of utilizing
multiple interacting LLM agents, each with a dedicated task, to enhance
performance in specialized medical tasks and the development of more robust and
adaptable healthcare AI solutions.

摘要：本研究引入了「RadCouncil」，一個多重代理大型語言模型 (LLM)
框架，旨在增強放射科報告中印象的產生，特別是發現部分。RadCouncil 包含三個專門的代理：1) 一個「檢索」代理，用於識別並從向量資料庫中檢索類似的報告，2) 一個「放射科醫師」代理，用於根據給定報告的發現部分加上檢索代理檢索到的範例報告，產生印象，以及 3) 一個「審查者」代理，用於評估產生的印象並提供回饋。RadCouncil 的效能使用量化指標 (BLEU、ROUGE、BERTScore) 進行評估，並使用胸部 X 光作為案例研究，由 GPT-4 評估質化標準。實驗結果顯示，RadCouncil 在多個面向都有改進，包括診斷準確性、風格一致性，以及清晰度，優於單一代理方法。本研究強調了利用多個互動式 LLM 代理的潛力，每個代理都有專門的任務，以增強在專業醫療任務中的效能，並開發更強健且適應性更強的醫療保健 AI 解決方案。

##### **Enhancing FKG.in: automating Indian food composition analysis**
2412.05248v2 by Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Geeta Trilok-Kumar, Ramesh Jain

This paper presents a novel approach to compute food composition data for
Indian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The
primary focus is to provide a broad overview of an automated food composition
analysis workflow and describe its core functionalities: nutrition data
aggregation, food composition analysis, and LLM-augmented information
resolution. This workflow aims to complement FKG.in and iteratively supplement
food composition data from verified knowledge bases. Additionally, this paper
highlights the challenges of representing Indian food and accessing food
composition data digitally. It also reviews three key sources of food
composition data: the Indian Food Composition Tables, the Indian Nutrient
Databank, and the Nutritionix API. Furthermore, it briefly outlines how users
can interact with the workflow to obtain diet-based health recommendations and
detailed food composition information for numerous recipes. We then explore the
complex challenges of analyzing Indian recipe information across dimensions
such as structure, multilingualism, and uncertainty as well as present our
ongoing work on LLM-based solutions to address these issues. The methods
proposed in this workshop paper for AI-driven knowledge curation and
information resolution are application-agnostic, generalizable, and replicable
for any domain.

摘要：本文提出了一個創新的方法，使用印度食品知識圖譜 (FKG.in) 和 LLM 來計算印度食譜的食品成分數據。主要重點是提供自動化食品成分分析工作流程的廣泛概述，並描述其核心功能：營養數據彙總、食品成分分析和 LLM 增強的信息解析。此工作流程旨在補充 FKG.in，並反覆補充來自驗證知識庫的食品成分數據。此外，本文重點介紹了表示印度食品和以數位方式存取食品成分數據的挑戰。它還回顧了食品成分數據的三個關鍵來源：印度食品成分表、印度營養資料庫和 Nutritionix API。此外，它簡要概述了使用者如何與工作流程互動以獲得基於飲食的健康建議和大量食譜的詳細食品成分資訊。然後，我們探討了分析印度食譜資訊在結構、多語言和不確定性等方面的複雜挑戰，並展示我們在基於 LLM 的解決方案上進行的持續工作，以解決這些問題。本文研討會論文中提出的 AI 驅動知識策展和資訊解析方法與應用程式無關，可概括且可複製到任何領域。

##### **Are Frontier Large Language Models Suitable for Q&A in Science Centres?**
2412.05200v1 by Jacob Watson, Fabrício Góes, Marco Volpe, Talles Medeiros

This paper investigates the suitability of frontier Large Language Models
(LLMs) for Q&A interactions in science centres, with the aim of boosting
visitor engagement while maintaining factual accuracy. Using a dataset of
questions collected from the National Space Centre in Leicester (UK), we
evaluated responses generated by three leading models: OpenAI's GPT-4, Claude
3.5 Sonnet, and Google Gemini 1.5. Each model was prompted for both standard
and creative responses tailored to an 8-year-old audience, and these responses
were assessed by space science experts based on accuracy, engagement, clarity,
novelty, and deviation from expected answers. The results revealed a trade-off
between creativity and accuracy, with Claude outperforming GPT and Gemini in
both maintaining clarity and engaging young audiences, even when asked to
generate more creative responses. Nonetheless, experts observed that higher
novelty was generally associated with reduced factual reliability across all
models. This study highlights the potential of LLMs in educational settings,
emphasizing the need for careful prompt engineering to balance engagement with
scientific rigor.

摘要：這篇論文探討前沿大型語言模型 (LLM) 在科學中心問答互動中的適用性，目的是在維持事實準確性的同時提升訪客參與度。我們使用從英國萊斯特國家太空中心收集的提問資料集，評估了三個領先模型生成的回應：OpenAI 的 GPT-4、Claude 3.5 Sonnet 和 Google Gemini 1.5。每個模型都被提示針對 8 歲的受眾量身打造標準和有創意的回應，而這些回應則由太空科學專家根據準確性、參與度、清晰度、新穎性和與預期答案的偏差進行評估。結果顯示創造力與準確性之間存在權衡，Claude 在維持清晰度和吸引年輕受眾方面優於 GPT 和 Gemini，即使被要求產生更多有創意的回應。儘管如此，專家們觀察到，所有模型中較高的新穎性通常與較低的實際可靠性相關。這項研究強調了 LLM 在教育環境中的潛力，並強調需要仔細提示工程以平衡參與度和科學嚴謹性。

##### **SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**
2412.05187v1 by Jinlin Wu, Xusheng Liang, Xuexue Bai, Zhen Chen

Surgical interventions, particularly in neurology, represent complex and
high-stakes scenarios that impose substantial cognitive burdens on surgical
teams. Although deliberate education and practice can enhance cognitive
capabilities, surgical training opportunities remain limited due to patient
safety concerns. To address these cognitive challenges in surgical training and
operation, we propose SurgBox, an agent-driven sandbox framework to
systematically enhance the cognitive capabilities of surgeons in immersive
surgical simulations. Specifically, our SurgBox leverages large language models
(LLMs) with tailored Retrieval-Augmented Generation (RAG) to authentically
replicate various surgical roles, enabling realistic training environments for
deliberate practice. In particular, we devise Surgery Copilot, an AI-driven
assistant to actively coordinate the surgical information stream and support
clinical decision-making, thereby diminishing the cognitive workload of
surgical teams during surgery. By incorporating a novel Long-Short Memory
mechanism, our Surgery Copilot can effectively balance immediate procedural
assistance with comprehensive surgical knowledge. Extensive experiments using
real neurosurgical procedure records validate our SurgBox framework in both
enhancing surgical cognitive capabilities and supporting clinical
decision-making. By providing an integrated solution for training and
operational support to address cognitive challenges, our SurgBox framework
advances surgical education and practice, potentially transforming surgical
outcomes and healthcare quality. The code is available at
https://github.com/franciszchen/SurgBox.

摘要：外科手術，特別是在神經外科，代表了複雜且高風險的場景，對外科團隊施加了巨大的認知負擔。儘管經過深思熟慮的教育和實踐可以增強認知能力，但由於患者安全問題，外科培訓機會仍然有限。為了應對外科培訓和手術中的這些認知挑戰，我們提出了 SurgBox，一個由代理驅動的沙盒框架，用於系統地增強外科醫生在沉浸式外科模擬中的認知能力。具體來說，我們的 SurgBox 利用大型語言模型 (LLM) 和量身定制的檢索增強生成 (RAG) 來真實地複製各種外科角色，為深思熟慮的實踐提供逼真的培訓環境。特別是，我們設計了手術副駕駛，一個由 AI 驅動的助手，用於主動協調外科信息流並支持臨床決策制定，從而減少外科團隊在手術期間的認知負擔。通過結合一種新穎的長短期記憶機制，我們的 Surgery Copilot 可以有效地平衡即時程序協助和全面的外科知識。使用真實的神經外科手術記錄進行的廣泛實驗驗證了我們的 SurgBox 框架，既能增強外科認知能力，又能支持臨床決策制定。通過提供一個綜合的培訓和運營支持解決方案來應對認知挑戰，我們的 SurgBox 框架推動了外科教育和實踐，有可能改變外科結果和醫療保健質量。代碼可在 https://github.com/franciszchen/SurgBox 獲得。

##### **Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**
2412.05013v1 by Thomas Sievers, Nele Russwinkel

Is it possible to integrate a humanoid social robot into the work processes
or customer care in an official environment, e.g. in municipal offices? If so,
what could such an application scenario look like and what skills would the
robot need to have when interacting with human customers? What are requirements
for this kind of interactions? We have devised an application scenario for such
a case, determined the necessary or desirable capabilities of the robot,
developed a corresponding robot application and carried out initial tests and
evaluations in a project together with the Kiel City Council. One of the most
important insights gained in the project was that a humanoid robot with natural
language processing capabilities based on large language models as well as
human-like gestures and posture changes (animations) proved to be much more
preferred by users compared to standard browser-based solutions on tablets for
an information system in the City Council. Furthermore, we propose a connection
of the ACT-R cognitive architecture with the robot, where an ACT-R model is
used in interaction with the robot application to cognitively process and
enhance a dialogue between human and robot.

摘要：是否可能將類人社會機器人整合到工作流程或官方環境中的客戶服務中，例如市政辦公室？如果是這樣，這樣的應用場景可能會是什麼樣子，而機器人在與人類客戶互動時需要具備哪些技能？這種互動有哪些要求？我們為這種情況設計了一個應用場景，確定了機器人必要或理想的能力，開發了一個對應的機器人應用程式，並與基爾市議會共同在一個專案中進行了初步測試和評估。該專案獲得的最重要見解之一是，與平板電腦上用於市議會資訊系統的標準瀏覽器解決方案相比，具有人工語言處理能力（基於大型語言模型）以及類人的手勢和姿勢變化（動畫）的類人機器人被使用者更為青睞。此外，我們建議將 ACT-R 認知架構與機器人連接起來，其中 ACT-R 模型用於與機器人應用程式互動，以認知處理和增強人與機器人之間的對話。

##### **Backdooring Outlier Detection Methods: A Novel Attack Approach**
2412.05010v1 by ZeinabSadat Taghavi, Hossein Mirzaei

There have been several efforts in backdoor attacks, but these have primarily
focused on the closed-set performance of classifiers (i.e., classification).
This has left a gap in addressing the threat to classifiers' open-set
performance, referred to as outlier detection in the literature. Reliable
outlier detection is crucial for deploying classifiers in critical real-world
applications such as autonomous driving and medical image analysis. First, we
show that existing backdoor attacks fall short in affecting the open-set
performance of classifiers, as they have been specifically designed to confuse
intra-closed-set decision boundaries. In contrast, an effective backdoor attack
for outlier detection needs to confuse the decision boundary between the closed
and open sets. Motivated by this, in this study, we propose BATOD, a novel
Backdoor Attack targeting the Outlier Detection task. Specifically, we design
two categories of triggers to shift inlier samples to outliers and vice versa.
We evaluate BATOD using various real-world datasets and demonstrate its
superior ability to degrade the open-set performance of classifiers compared to
previous attacks, both before and after applying defenses.

摘要：對於後門攻擊已經有幾項努力，但這些主要集中在分類器的閉集效能（即分類）上。這使得在處理分類器開放集效能的威脅上出現了一個缺口，在文獻中稱為異常值偵測。可靠的異常值偵測對於在關鍵的真實世界應用中部署分類器至關重要，例如自動駕駛和醫學影像分析。首先，我們展示現有的後門攻擊在影響分類器的開放集效能方面不足，因為它們被特別設計用來混淆閉集內決策邊界。相比之下，有效的異常值偵測後門攻擊需要混淆閉集和開放集之間的決策邊界。有鑑於此，在本研究中，我們提出 BATOD，一種針對異常值偵測任務的新型後門攻擊。具體來說，我們設計了兩種類型的觸發器，將內點樣本轉移到異常值，反之亦然。我們使用各種真實世界資料集評估 BATOD，並展示了它在降低分類器的開放集效能方面的優異能力，與之前在應用防禦措施之前和之後的攻擊相比。

##### **Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**
2412.04950v1 by Thomas Bartz-Beielstein, Axel Wellendorf, Noah Pütz, Jens Brandt, Alexander Hinterleitner, Richard Schulz, Richard Scholz, Olaf Mersmann, Robin Knabe

The increasing shortage of nursing staff and the acute risk of falls in
nursing homes pose significant challenges for the healthcare system. This study
presents the development of an automated fall detection system integrated into
care beds, aimed at enhancing patient safety without compromising privacy
through wearables or video monitoring. Mechanical vibrations transmitted
through the bed frame are processed using a short-time Fourier transform,
enabling robust classification of distinct human fall patterns with a
convolutional neural network. Challenges pertaining to the quantity and
diversity of the data are addressed, proposing the generation of additional
data with a specific emphasis on enhancing variation. While the model shows
promising results in distinguishing fall events from noise using lab data,
further testing in real-world environments is recommended for validation and
improvement. Despite limited available data, the proposed system shows the
potential for an accurate and rapid response to falls, mitigating health
implications, and addressing the needs of an aging population. This case study
was performed as part of the ZIM Project. Further research on sensors enhanced
by artificial intelligence will be continued in the ShapeFuture Project.

摘要：護理人員日益短缺，且護理之家發生跌倒的風險極高，對醫療保健系統構成重大挑戰。本研究提出將自動化跌倒偵測系統整合至護理床，旨在提升病患安全，同時透過穿戴式裝置或視訊監控來保護隱私。透過床架傳遞的機械振動會使用短時距傅立葉轉換進行處理，並能利用卷積神經網路對不同人類跌倒模式進行穩健分類。針對資料數量和多樣性的挑戰，提出產生額外資料的建議，特別著重於增加變化性。雖然此模型在使用實驗室資料區分跌倒事件和雜訊時顯示出有希望的結果，但建議在真實環境中進一步測試以進行驗證和改進。儘管可用資料有限，但所提出的系統顯示出對跌倒事件做出準確且快速的反應的潛力，減輕健康影響，並滿足老齡化人口的需求。此案例研究是作為 ZIM 專案的一部分進行的。ShapeFuture 專案將持續進行人工智慧增強感測器的進一步研究。

##### **Estimating the treatment effect over time under general interference through deep learner integrated TMLE**
2412.04799v1 by Suhan Guo, Furao Shen, Ni Li

Understanding the effects of quarantine policies in populations with
underlying social networks is crucial for public health, yet most causal
inference methods fail here due to their assumption of independent individuals.
We introduce DeepNetTMLE, a deep-learning-enhanced Targeted Maximum Likelihood
Estimation (TMLE) method designed to estimate time-sensitive treatment effects
in observational data. DeepNetTMLE mitigates bias from time-varying confounders
under general interference by incorporating a temporal module and domain
adversarial training to build intervention-invariant representations. This
process removes associations between current treatments and historical
variables, while the targeting step maintains the bias-variance trade-off,
enhancing the reliability of counterfactual predictions. Using simulations of a
``Susceptible-Infected-Recovered'' model with varied quarantine coverages, we
show that DeepNetTMLE achieves lower bias and more precise confidence intervals
in counterfactual estimates, enabling optimal quarantine recommendations within
budget constraints, surpassing state-of-the-art methods.

摘要：了解具有潛在社交網絡的人群中隔離政策的影響對於公共衛生至關重要，但由於假設個人獨立，大多數因果推論方法在此處失敗。我們引入了 DeepNetTMLE，這是一種深度學習增強的目標最大似然估計 (TMLE) 方法，旨在估計觀測數據中的時間敏感處理效果。DeepNetTMLE 透過整合時間模組和領域對抗訓練來建立介入不變表示，從而減輕一般干擾下時變混雜因素的偏差。此過程消除了當前處理與歷史變數之間的關聯，而目標設定步驟則維持偏差變異權衡，增強反事實預測的可靠性。使用具有不同隔離覆蓋率的「易感者-感染者-康復者」模型的模擬，我們表明 DeepNetTMLE 在反事實估計中實現了較低的偏差和更精確的信心區間，從而在預算限制內實現了最佳隔離建議，超越了最先進的方法。

##### **Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**
2412.04792v1 by Mahfuzul Haque, Abu Saleh Musa Miah, Debashish Gupta, Md. Maruf Al Hossain Prince, Tanzina Alam, Nusrat Sharmin, Mohammed Sowket Ali, Jungpil Shin

Heart disease is a leading cause of premature death worldwide, particularly
among middle-aged and older adults, with men experiencing a higher prevalence.
According to the World Health Organization (WHO), non-communicable diseases,
including heart disease, account for 25\% (17.9 million) of global deaths, with
over 43,204 annual fatalities in Bangladesh. However, the development of heart
disease detection (HDD) systems tailored to the Bangladeshi population remains
underexplored due to the lack of benchmark datasets and reliance on manual or
limited-data approaches. This study addresses these challenges by introducing
new, ethically sourced HDD dataset, BIG-Dataset and CD dataset which
incorporates comprehensive data on symptoms, examination techniques, and risk
factors. Using advanced machine learning techniques, including Logistic
Regression and Random Forest, we achieved a remarkable testing accuracy of up
to 96.6\% with Random Forest. The proposed AI-driven system integrates these
models and datasets to provide real-time, accurate diagnostics and personalized
healthcare recommendations. By leveraging structured datasets and
state-of-the-art machine learning algorithms, this research offers an
innovative solution for scalable and effective heart disease detection, with
the potential to reduce mortality rates and improve clinical outcomes.

摘要：<paragraph>心臟病是全球過早死亡的主因，特別是在中年和老年人中，男性發生率較高。根據世界衛生組織 (WHO) 的數據，包括心臟病在內的非傳染性疾病占全球死亡人數的 25%（1790 萬），孟加拉國每年有超過 43,204 人死於心臟病。然而，由於缺乏基準數據集和依賴手動或數據有限的方法，針對孟加拉國人口量身打造的心臟病檢測 (HDD) 系統的開發仍未得到充分探索。本研究通過引入新的、符合道德標準的 HDD 數據集、BIG 數據集和 CD 數據集來應對這些挑戰，其中包含有關症狀、檢查技術和風險因素的全面數據。使用先進的機器學習技術，包括邏輯迴歸和隨機森林，我們使用隨機森林實現了高達 96.6% 的顯著測試準確度。所提出的 AI 驅動系統整合了這些模型和數據集，以提供實時的準確診斷和個性化的醫療保健建議。通過利用結構化數據集和最先進的機器學習算法，本研究為可擴展且有效的心臟病檢測提供了一個創新的解決方案，具有降低死亡率和改善臨床結果的潛力。</paragraph>

##### **DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**
2412.04766v1 by Shadab Ahamed, Eldad Haber

Inverse problems, which involve estimating parameters from incomplete or
noisy observations, arise in various fields such as medical imaging,
geophysics, and signal processing. These problems are often ill-posed,
requiring regularization techniques to stabilize the solution. In this work, we
employ $\textit{Stochastic Interpolation}$ (SI), a generative framework that
integrates both deterministic and stochastic processes to map a simple
reference distribution, such as a Gaussian, to the target distribution. Our
method $\textbf{DAWN-SI}$: $\textbf{D}$ata-$\textbf{AW}$are and
$\textbf{N}$oise-informed $\textbf{S}$tochastic $\textbf{I}$nterpolation
incorporates data and noise embedding, allowing the model to access
representations about the measured data explicitly and also account for noise
in the observations, making it particularly robust in scenarios where data is
noisy or incomplete. By learning a time-dependent velocity field, SI not only
provides accurate solutions but also enables uncertainty quantification by
generating multiple plausible outcomes. Unlike pre-trained diffusion models,
which may struggle in highly ill-posed settings, our approach is trained
specifically for each inverse problem and adapts to varying noise levels. We
validate the effectiveness and robustness of our method through extensive
numerical experiments on tasks such as image deblurring and tomography.

摘要：反問題涉及從不完整或有雜訊的觀測中估計參數，出現在各種領域，例如醫學影像、地球物理和訊號處理。這些問題通常是不適定的，需要正則化技術來穩定解。在這項工作中，我們採用隨機插值 (SI)，一種生成式架構，整合確定性和隨機過程，將簡單的參考分佈（例如高斯分佈）對應到目標分佈。我們的 DAWS-SI 方法：資料感知和雜訊知情的隨機插值，結合資料和雜訊嵌入，讓模型能夠明確存取關於測量資料的表示，並考量觀測中的雜訊，使其在資料有雜訊或不完整的情況下特別穩健。透過學習與時間相關的速度場，SI 不僅提供精確的解，還能透過產生多個合理的結果來量化不確定性。與預先訓練的擴散模型不同，後者在高度不適定的設定中可能會遇到困難，我們的做法是針對每個反問題進行訓練，並適應不同的雜訊等級。我們透過廣泛的數值實驗驗證了我們方法的有效性和穩健性，這些任務包括影像去模糊和斷層掃描。

##### **PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**
2412.04714v1 by Hongjin Lin, Matthew Nazari, Derek Zheng

Reliable large-scale data on the state of forests is crucial for monitoring
ecosystem health, carbon stock, and the impact of climate change. Current
knowledge of tree species distribution relies heavily on manual data collection
in the field, which often takes years to complete, resulting in limited
datasets that cover only a small subset of the world's forests. Recent works
show that state-of-the-art deep learning models using Light Detection and
Ranging (LiDAR) images enable accurate and scalable classification of tree
species in various ecosystems. While LiDAR images contain rich 3D information,
most previous works flatten the 3D images into 2D projections to use
Convolutional Neural Networks (CNNs). This paper offers three significant
contributions: (1) we apply the deep learning framework for tree classification
in tropical savannas; (2) we use Airborne LiDAR images, which have a lower
resolution but greater scalability than Terrestrial LiDAR images used in most
previous works; (3) we introduce the approach of directly feeding 3D point
cloud images into a vision transformer model (PCTreeS). Our results show that
the PCTreeS approach outperforms current CNN baselines with 2D projections in
AUC (0.81), overall accuracy (0.72), and training time (~45 mins). This paper
also motivates further LiDAR image collection and validation for accurate
large-scale automatic classification of tree species.

摘要：可靠的大規模森林狀態資料對於監測生態系統健康、碳儲量和氣候變遷的影響至關重要。目前對樹種分布的了解極度依賴於實地手動收集資料，這通常需要花費數年才能完成，導致只能涵蓋全球少數森林的有限資料集。最近的研究顯示，使用光探測和測距 (LiDAR) 影像的最新深度學習模型，可以在各種生態系統中對樹種進行準確且可擴充的分類。儘管 LiDAR 影像包含豐富的 3D 資訊，但大多數先前的研究會將 3D 影像壓縮成 2D 投影，以使用卷積神經網路 (CNN)。本文提供了三項重要的貢獻：(1) 我們將深度學習架構應用於熱帶稀樹草原的樹種分類；(2) 我們使用機載 LiDAR 影像，其解析度較低，但可擴充性比大多數先前研究中使用的地面 LiDAR 影像更高；(3) 我們引入了直接將 3D 點雲影像輸入到視覺Transformer模型 (PCTreeS) 的方法。我們的結果顯示，PCTreeS 方法在 AUC (0.81)、整體準確度 (0.72) 和訓練時間 (~45 分鐘) 方面優於當前使用 2D 投影的 CNN 基準。本文也激勵進一步收集和驗證 LiDAR 影像，以進行準確的大規模樹種自動分類。

##### **Semantic Consistency-Based Uncertainty Quantification for Factuality in Radiology Report Generation**
2412.04606v1 by Chenyu Wang, Weichao Zhou, Shantanu Ghosh, Kayhan Batmanghelich, Wenchao Li

Radiology report generation (RRG) has shown great potential in assisting
radiologists by automating the labor-intensive task of report writing. While
recent advancements have improved the quality and coherence of generated
reports, ensuring their factual correctness remains a critical challenge.
Although generative medical Vision Large Language Models (VLLMs) have been
proposed to address this issue, these models are prone to hallucinations and
can produce inaccurate diagnostic information. To address these concerns, we
introduce a novel Semantic Consistency-Based Uncertainty Quantification
framework that provides both report-level and sentence-level uncertainties.
Unlike existing approaches, our method does not require modifications to the
underlying model or access to its inner state, such as output token logits,
thus serving as a plug-and-play module that can be seamlessly integrated with
state-of-the-art models. Extensive experiments demonstrate the efficacy of our
method in detecting hallucinations and enhancing the factual accuracy of
automatically generated radiology reports. By abstaining from high-uncertainty
reports, our approach improves factuality scores by $10$%, achieved by
rejecting $20$% of reports using the Radialog model on the MIMIC-CXR dataset.
Furthermore, sentence-level uncertainty flags the lowest-precision sentence in
each report with an $82.9$% success rate.

摘要：放射科报告生成 (RRG) 已显示出极大的潜力，可通过自动执行报告编写的劳动密集型任务来协助放射科医生。虽然最近的进步提高了生成报告的质量和连贯性，但确保其事实正确性仍然是一项重大挑战。尽管已提出生成性医学视觉大语言模型 (VLLM) 来解决此问题，但这些模型容易出现幻觉并可能产生不准确的诊断信息。为了解决这些问题，我们引入了一个新颖的基于语义一致性的不确定性量化框架，该框架提供报告级和句子级的不确定性。与现有方法不同，我们的方法不需要修改底层模型或访问其内部状态（例如输出标记 logit），因此可用作即插即用模块，可以与最先进的模型无缝集成。广泛的实验表明了我们的方法在检测幻觉和提高自动生成的放射科报告的事实准确性方面的功效。通过避免高度不确定的报告，我们的方法将真实性得分提高了 10%，这是通过使用 MIMIC-CXR 数据集上的 Radialog 模型拒绝 20% 的报告实现的。此外，句子级不确定性标记了每份报告中精度最低的句子，成功率为 82.9%。

##### **CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations**
2412.04254v1 by Subash Neupane, Himanshu Tripathi, Shaswata Mitra, Sean Bozorgzad, Sudip Mittal, Shahram Rahimi, Amin Amirlatifi

This paper presents ClinicSum, a novel framework designed to automatically
generate clinical summaries from patient-doctor conversations. It utilizes a
two-module architecture: a retrieval-based filtering module that extracts
Subjective, Objective, Assessment, and Plan (SOAP) information from
conversation transcripts, and an inference module powered by fine-tuned
Pre-trained Language Models (PLMs), which leverage the extracted SOAP data to
generate abstracted clinical summaries. To fine-tune the PLM, we created a
training dataset of consisting 1,473 conversations-summaries pair by
consolidating two publicly available datasets, FigShare and MTS-Dialog, with
ground truth summaries validated by Subject Matter Experts (SMEs). ClinicSum's
effectiveness is evaluated through both automatic metrics (e.g., ROUGE,
BERTScore) and expert human assessments. Results show that ClinicSum
outperforms state-of-the-art PLMs, demonstrating superior precision, recall,
and F-1 scores in automatic evaluations and receiving high preference from SMEs
in human assessment, making it a robust solution for automated clinical
summarization.

摘要：本文介紹 ClinicSum，這是一個新穎的架構，旨在自動從病患與醫師的對話中產生臨床摘要。它利用一個雙模組架構：一個基於檢索的過濾模組，從對話轉錄中萃取主觀、客觀、評估和計畫 (SOAP) 資訊，以及一個由微調過之預先訓練語言模型 (PLM) 提供動力的推論模組，它利用萃取的 SOAP 資料產生摘要的臨床摘要。為了微調 PLM，我們建立了一個訓練資料集，其中包含 1,473 組對話摘要，透過合併兩個公開可用的資料集 FigShare 和 MTS-Dialog，以及由主題專家 (SME) 驗證的真實摘要。ClinicSum 的效能透過自動評量指標 (例如 ROUGE、BERTScore) 和專家人類評估進行評量。結果顯示 ClinicSum 勝過現有最先進的 PLM，在自動評量中展現出優異的精確度、召回率和 F-1 分數，並在人類評估中獲得 SME 的高度偏好，使其成為自動臨床摘要的強健解決方案。

##### **Automated Medical Report Generation for ECG Data: Bridging Medical Text and Signal Processing with Deep Learning**
2412.04067v1 by Amnon Bleich, Antje Linnemann, Bjoern H. Diem, Tim OF Conrad

Recent advances in deep learning and natural language generation have
significantly improved image captioning, enabling automated, human-like
descriptions for visual content. In this work, we apply these captioning
techniques to generate clinician-like interpretations of ECG data. This study
leverages existing ECG datasets accompanied by free-text reports authored by
healthcare professionals (HCPs) as training data. These reports, while often
inconsistent, provide a valuable foundation for automated learning. We
introduce an encoder-decoder-based method that uses these reports to train
models to generate detailed descriptions of ECG episodes. This represents a
significant advancement in ECG analysis automation, with potential applications
in zero-shot classification and automated clinical decision support.
  The model is tested on various datasets, including both 1- and 12-lead ECGs.
It significantly outperforms the state-of-the-art reference model by Qiu et
al., achieving a METEOR score of 55.53% compared to 24.51% achieved by the
reference model. Furthermore, several key design choices are discussed,
providing a comprehensive overview of current challenges and innovations in
this domain.
  The source codes for this research are publicly available in our Git
repository https://git.zib.de/ableich/ecg-comment-generation-public

摘要：深度學習和自然語言生成技術的最新進展顯著改善了影像標題，能為視覺內容提供自動化的人類語言描述。在這項工作中，我們將這些標題技術應用於產生類似臨床醫師對心電圖資料的詮釋。這項研究利用既有的心電圖資料集，並附上由醫療保健專業人員 (HCP) 撰寫的自由文字報告作為訓練資料。這些報告雖然常常不一致，但為自動化學習提供了有價值的基礎。我們引入了一個編碼器-解碼器方法，使用這些報告來訓練模型，以產生心電圖事件的詳細描述。這代表心電圖分析自動化的重大進展，在零次學習分類和自動化臨床決策支援中具有潛在應用。此模型在各種資料集上進行測試，包括 1 導程和 12 導程心電圖。它明顯優於邱等人的現有最佳參考模型，與參考模型達成的 24.51% 相比，達到了 55.53% 的 METEOR 分數。此外，討論了幾個關鍵的設計選擇，提供了對這個領域中當前挑戰和創新的全面概述。此研究的原始程式碼在我們的 Git 儲存庫 https://git.zib.de/ableich/ecg-comment-generation-public 中公開。

##### **FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems**
2412.03851v1 by Jiechao Gao, Yuangang Li

Personalized medication aims to tailor healthcare to individual patient
characteristics. However, the heterogeneity of patient data across healthcare
systems presents significant challenges to achieving accurate and effective
personalized treatments. Ethical concerns further complicate the aggregation of
large volumes of data from diverse institutions. Federated Learning (FL) offers
a promising decentralized solution by enabling collaborative model training
through the exchange of client models rather than raw data, thus preserving
privacy. However, existing FL methods often suffer from retrogression during
server aggregation, leading to a decline in model performance in real-world
medical FL settings. To address data variability in distributed healthcare
systems, we introduce Federated Meta-Learning for Personalized Medication
(FedMetaMed), which combines federated learning and meta-learning to create
models that adapt to diverse patient data across healthcare systems. The
FedMetaMed framework aims to produce superior personalized models for
individual clients by addressing these limitations. Specifically, we introduce
Cumulative Fourier Aggregation (CFA) at the server to improve stability and
effectiveness in global knowledge aggregation. CFA achieves this by gradually
integrating client models from low to high frequencies. At the client level, we
implement a Collaborative Transfer Optimization (CTO) strategy with a
three-step process - Retrieve, Reciprocate, and Refine - to enhance the
personalized local model through seamless global knowledge transfer.
Experiments on real-world medical imaging datasets demonstrate that FedMetaMed
outperforms state-of-the-art FL methods, showing superior generalization even
on out-of-distribution cohorts.

摘要：個人化醫療旨在針對個別患者特徵調整醫療保健。然而，醫療系統中患者資料的異質性對達成準確且有效的個人化治療帶來重大挑戰。倫理問題進一步使來自不同機構的大量資料的彙總複雜化。聯邦學習 (FL) 提供了一種有前景的分散式解決方案，透過交換客戶模型而非原始資料來實現協作模型訓練，從而保護隱私。然而，現有的 FL 方法在伺服器彙總期間經常遭受退化，導致實際醫療 FL 設定中的模型效能下降。為了解決分散式醫療系統中的資料變異性，我們引入了個人化藥物聯邦元學習 (FedMetaMed)，它結合了聯邦學習和元學習來建立模型，以適應醫療系統中不同的患者資料。FedMetaMed 框架旨在透過解決這些限制，為個別客戶產生優越的個人化模型。具體來說，我們在伺服器端引入了累積傅立葉彙總 (CFA)，以改善全球知識彙總的穩定性和有效性。CFA 透過逐步整合從低頻率到高頻率的客戶模型來實現這一點。在客戶端層級，我們實施了一種協作傳輸最佳化 (CTO) 策略，採用三步驟流程 - 擷取、回饋和精煉 - 透過無縫的全球知識傳輸來增強個人化本地模型。在實際醫療影像資料集上的實驗表明，FedMetaMed 優於最先進的 FL 方法，即使在非分佈群組中也展現出優越的泛化性。

##### **ELEMENT: Episodic and Lifelong Exploration via Maximum Entropy**
2412.03800v1 by Hongming Li, Shujian Yu, Bin Liu, Jose C. Principe

This paper proposes \emph{Episodic and Lifelong Exploration via Maximum
ENTropy} (ELEMENT), a novel, multiscale, intrinsically motivated reinforcement
learning (RL) framework that is able to explore environments without using any
extrinsic reward and transfer effectively the learned skills to downstream
tasks. We advance the state of the art in three ways. First, we propose a
multiscale entropy optimization to take care of the fact that previous maximum
state entropy, for lifelong exploration with millions of state observations,
suffers from vanishing rewards and becomes very expensive computationally
across iterations. Therefore, we add an episodic maximum entropy over each
episode to speedup the search further. Second, we propose a novel intrinsic
reward for episodic entropy maximization named \emph{average episodic state
entropy} which provides the optimal solution for a theoretical upper bound of
the episodic state entropy objective. Third, to speed the lifelong entropy
maximization, we propose a $k$ nearest neighbors ($k$NN) graph to organize the
estimation of the entropy and updating processes that reduces the computation
substantially. Our ELEMENT significantly outperforms state-of-the-art intrinsic
rewards in both episodic and lifelong setups. Moreover, it can be exploited in
task-agnostic pre-training, collecting data for offline reinforcement learning,
etc.

摘要：本文提出了一种新颖的多尺度、内在动机强化学习 (RL) 框架，名为“通过最大熵进行情景和终身探索”(ELEMENT)，该框架能够在不使用任何外在奖励的情况下探索环境，并有效地将所学技能转移到下游任务中。我们在三个方面提升了技术水平。首先，我们提出了多尺度熵优化，以解决以下事实：先前的最大状态熵在进行数百万次状态观察的终身探索时，会遭受奖励消失的影响，并且在每次迭代中都会变得非常昂贵。因此，我们在每个情景中添加了一个情景最大熵，以进一步加快搜索速度。其次，我们提出了一种新的内在奖励，用于情景熵最大化，名为“平均情景状态熵”，它为情景状态熵目标的理论上限提供了最优解。第三，为了加快终身熵最大化，我们提出了一个 $k$ 近邻 ($k$NN) 图，用于组织熵的估计和更新过程，从而大幅减少了计算。我们的 ELEMENT 在情景和终身设置中都明显优于最先进的内在奖励。此外，它还可以用于与任务无关的预训练、收集离线强化学习数据等。

##### **Automated Multi-Label Annotation for Mental Health Illnesses Using Large Language Models**
2412.03796v1 by Abdelrahaman A. Hassan, Radwa J. Hanafy, Mohammed E. Fouda

The growing prevalence and complexity of mental health disorders present
significant challenges for accurate diagnosis and treatment, particularly in
understanding the interplay between co-occurring conditions. Mental health
disorders, such as depression and Anxiety, often co-occur, yet current datasets
derived from social media posts typically focus on single-disorder labels,
limiting their utility in comprehensive diagnostic analyses. This paper
addresses this critical gap by proposing a novel methodology for cleaning,
sampling, labeling, and combining data to create versatile multi-label
datasets. Our approach introduces a synthetic labeling technique to transform
single-label datasets into multi-label annotations, capturing the complexity of
overlapping mental health conditions. To achieve this, two single-label
datasets are first merged into a foundational multi-label dataset, enabling
realistic analyses of co-occurring diagnoses. We then design and evaluate
various prompting strategies for large language models (LLMs), ranging from
single-label predictions to unrestricted prompts capable of detecting any
present disorders. After rigorously assessing multiple LLMs and prompt
configurations, the optimal combinations are identified and applied to label
six additional single-disorder datasets from RMHD. The result is SPAADE-DR, a
robust, multi-label dataset encompassing diverse mental health conditions. This
research demonstrates the transformative potential of LLM-driven synthetic
labeling in advancing mental health diagnostics from social media data, paving
the way for more nuanced, data-driven insights into mental health care.

摘要：隨著心理健康障礙的盛行率和複雜性日益增加，對於準確診斷和治療提出了嚴峻的挑戰，特別是在了解共存疾病之間的相互作用時。心理健康障礙，例如憂鬱症和焦慮症，經常共存，但目前從社群媒體貼文中衍生的資料集通常只關注單一障礙標籤，限制了它們在全面診斷分析中的效用。本文透過提出一個創新的方法來清理、抽樣、標籤和組合資料，以建立多功能的多標籤資料集，來解決這個關鍵的差距。我們的做法引進了一種合成標籤技術，將單標籤資料集轉換為多標籤註解，捕捉重疊心理健康狀況的複雜性。為了達成這個目標，首先將兩個單標籤資料集合併成一個基礎多標籤資料集，以進行共存診斷的實際分析。然後，我們設計並評估大型語言模型 (LLM) 的各種提示策略，從單標籤預測到能夠偵測任何現有障礙的無限制提示。在嚴格評估多個 LLM 和提示配置後，找出最佳組合並應用於標籤來自 RMHD 的六個其他單一障礙資料集。結果是 SPAADE-DR，一個包含各種心理健康狀況的強健多標籤資料集。這項研究展示了 LLM 驅動的合成標籤在推進從社群媒體資料進行心理健康診斷的轉型潛力，為更細緻、資料驅動的心理保健見解鋪路。

##### **Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**
2412.03784v1 by Yerin Choi, Jeehyun Lee, Myoung-Wan Koo

Due to the subjective nature of current clinical evaluation, the need for
automatic severity evaluation in dysarthric speech has emerged. DNN models
outperform ML models but lack user-friendly explainability. ML models offer
explainable results at a feature level, but their performance is comparatively
lower. Current ML models extract various features from raw waveforms to predict
severity. However, existing methods do not encompass all dysarthric features
used in clinical evaluation. To address this gap, we propose a feature
extraction method that minimizes information loss. We introduce an ASR
transcription as a novel feature extraction source. We finetune the ASR model
for dysarthric speech, then use this model to transcribe dysarthric speech and
extract word segment boundary information. It enables capturing finer
pronunciation and broader prosodic features. These features demonstrated an
improved severity prediction performance to existing features: balanced
accuracy of 83.72%.

摘要：由於當前臨床評估的主觀性，因此出現了對構音障礙言語中自動嚴重程度評估的需求。DNN 模型優於 ML 模型，但缺乏使用者友善的可解釋性。ML 模型在特徵層級提供可解釋的結果，但其效能相對較低。當前的 ML 模型從原始波形中擷取各種特徵以預測嚴重程度。然而，現有方法並未涵蓋臨床評估中使用的所有構音障礙特徵。為了解決這個差距，我們提出了一種可將資訊損失降至最低的特徵擷取方法。我們引入了 ASR 轉錄作為一種新穎的特徵擷取來源。我們為構音障礙言語微調 ASR 模型，然後使用此模型轉錄構音障礙言語並擷取字元區段邊界資訊。它可以擷取更精細的發音和更廣泛的韻律特徵。這些特徵顯示出比現有特徵更好的嚴重程度預測效能：平衡準確度為 83.72%。

##### **Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety**
2412.03740v1 by Dilan Mian

The world can be a complex and difficult place to navigate. People with
High-Functioning Autistic Spectrum Disorder as well as general social
ineptitude often face navigation challenges that individuals of other
demographics simply do not themselves. This can become even more pronounced
with people of that specific group when they are in their teenage years and
early adulthood (that being the usual age range of college students). When they
are at such a vulnerable age, they can be far more susceptible to the struggles
of becoming comfortable and content with social interactions as well as having
strong relationships (outside their immediate family). Concerning this, the
rapid emergence of artificial intelligence chatbots has led to many of them
being used to benefit people of different ages and demographics with easy
accessibility. With this, if there is anything that people with
High-Functioning ASD and social ineptitude want when it comes to guidance
towards self-improvement, surely easy accessibility would be one. What are the
potential benefits and limitations of using a Mindstudio AI-powered chatbot to
provide mental health support for teens and young adults with the
aforementioned conditions? What could be done with a tool like this to help
those individuals navigate ethical dilemmas within different social
environments to reduce existing social tensions? This paper addresses these
queries and offers insights to inform future discussions on the subject.

摘要：世界可能是一個複雜且難以應付的地方。高功能自閉症譜系障礙以及一般社交無能的人，經常會面對其他人口統計資料中的人根本不會遇到的應對挑戰。當他們處於青少年時期和成年初期（通常是大學生的年齡範圍）時，這種情況可能會變得更加明顯。當他們處於如此脆弱的年齡時，他們更容易受到社交互動感到自在和滿足的掙扎，以及擁有牢固關係（在他們的直系親屬之外）的影響。關於這一點，人工智慧聊天機器人的快速出現，導致許多人被用於造福不同年齡和人口統計資料的人，並具有易於存取性。有了這個，如果患有高功能自閉症和社交無能的人在自我提升的指導方面有任何想要的東西，那麼易於存取肯定會是一個。使用由 Mindstudio AI 提供技術支援的聊天機器人，為患有上述情況的青少年和年輕人提供心理健康支援，有哪些潛在的好處和限制？可以使用這樣的工具來幫助那些人應對不同社會環境中的道德困境，以減少現有的社會緊張局勢，可以做些什麼？本文探討這些問題，並提供見解，為未來關於此主題的討論提供資訊。

##### **MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities**
2412.04106v1 by Haoning Wu, Ziheng Zhao, Ya Zhang, Weidi Xie, Yanfeng Wang

Medical image segmentation has recently demonstrated impressive progress with
deep neural networks, yet the heterogeneous modalities and scarcity of mask
annotations limit the development of segmentation models on unannotated
modalities. This paper investigates a new paradigm for leveraging generative
models in medical applications: controllably synthesizing data for unannotated
modalities, without requiring registered data pairs. Specifically, we make the
following contributions in this paper: (i) we collect and curate a large-scale
radiology image-text dataset, MedGen-1M, comprising modality labels,
attributes, region, and organ information, along with a subset of organ mask
annotations, to support research in controllable medical image generation; (ii)
we propose a diffusion-based data engine, termed MRGen, which enables
generation conditioned on text prompts and masks, synthesizing MR images for
diverse modalities lacking mask annotations, to train segmentation models on
unannotated modalities; (iii) we conduct extensive experiments across various
modalities, illustrating that our data engine can effectively synthesize
training samples and extend MRI segmentation towards unannotated modalities.

摘要：醫學影像分割最近已透過深度神經網路展現驚人的進展，但異質模態和標籤稀少限制了在未標註模態上開發分割模型。本文探討了一個新典範，以利用生成模型在醫學應用中：可控地合成未標註模態的資料，而無需註冊資料對。具體來說，我們在本文中做出以下貢獻：(i) 我們收集並策劃了一個大規模的放射影像文字資料集 MedGen-1M，包含模態標籤、屬性、區域和器官資訊，以及一部分器官標籤，以支援可控醫學影像生成的相關研究；(ii) 我們提出了一個基於擴散的資料引擎，稱為 MRGen，它能夠根據文字提示和標籤生成條件，合成缺乏標籤註解的不同模態的 MR 影像，以訓練未標註模態的分割模型；(iii) 我們在各種模態中進行了廣泛的實驗，說明我們的資料引擎可以有效地合成訓練樣本，並將 MRI 分割延伸至未標註的模態。

##### **Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**
2412.03352v1 by Yiqin Zhang, Qingkui Chen, Chen Huang, Zhengjie Zhang, Meiling Chen, Zhibing Fu

Most data-driven models for medical image analysis rely on universal
augmentations to improve performance. Experimental evidence has confirmed their
effectiveness, but the unclear mechanism underlying them poses a barrier to the
widespread acceptance and trust in such methods within the medical community.
We revisit and acknowledge the unique characteristics of medical images apart
from traditional digital images, and consequently, proposed a medical-specific
augmentation algorithm that is more elastic and aligns well with radiology scan
procedure. The method performs piecewise affine with sinusoidal distorted ray
according to radius on polar coordinates, thus simulating uncertain postures of
human lying flat on the scanning table. Our method could generate human
visceral distribution without affecting the fundamental relative position on
axial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal
and Similarity-Guided Parameter Search, are introduced to bolster robustness of
our augmentation method. Experiments show our method improves accuracy across
multiple famous segmentation frameworks without requiring more data samples.
Our preview code is available in: https://github.com/MGAMZ/PSBPD.

摘要：大多數用於醫學影像分析的資料驅動模型仰賴通用擴充功能來提升效能。實驗證據已證實其有效性，但其背後不明確的機制對醫學界廣泛接受和信任此類方法構成阻礙。我們重新檢視並承認醫學影像與傳統數位影像的獨特特性，因此提出更具彈性且與放射線掃描程序密切配合的醫學特定擴充演算法。該方法根據極座標上的半徑執行正弦扭曲射線的逐段仿射，從而模擬人平躺在掃描台上時的不確定姿勢。我們的方法可以在不影響軸向平面上基本相對位置的情況下生成人體內臟分佈。引入了兩種非自適應演算法，即基於 Meta 的掃描台移除和相似性導引參數搜尋，以加強我們擴充方法的穩健性。實驗表明，我們的演算法在不需要更多資料樣本的情況下，就能提升多個著名分割架構的準確性。我們的預覽程式碼可在 https://github.com/MGAMZ/PSBPD 中取得。

##### **Detecting abnormal heart sound using mobile phones and on-device IConNet**
2412.03267v1 by Linh Vu, Thu Tran

Given the global prevalence of cardiovascular diseases, there is a pressing
need for easily accessible early screening methods. Typically, this requires
medical practitioners to investigate heart auscultations for irregular sounds,
followed by echocardiography and electrocardiography tests. To democratize
early diagnosis, we present a user-friendly solution for abnormal heart sound
detection, utilizing mobile phones and a lightweight neural network optimized
for on-device inference. Unlike previous approaches reliant on specialized
stethoscopes, our method directly analyzes audio recordings, facilitated by a
novel architecture known as IConNet. IConNet, an Interpretable Convolutional
Neural Network, harnesses insights from audio signal processing, enhancing
efficiency and providing transparency in neural pattern extraction from raw
waveform signals. This is a significant step towards trustworthy AI in
healthcare, aiding in remote health monitoring efforts.

摘要：鉴于心血管疾病在全球的普遍性，迫切需要容易获取的早期筛查方法。通常，这需要医疗从业人员检查心脏听诊是否有不规则的声音，然后进行超声心动图和心电图检查。为了使早期诊断民主化，我们提出了一种用户友好的解决方案，用于检测异常心脏声音，利用移动电话和一个轻量级神经网络，该神经网络针对设备内推理进行了优化。与以前依赖于专用听诊器的做法不同，我们的方法直接分析音频记录，这得益于一种称为 IConNet 的新颖架构。IConNet 是一种可解释的卷积神经网络，利用音频信号处理的见解，提高效率，并提供从原始波形信号中提取神经模式的透明性。这是朝向医疗保健中可信赖的人工智能迈出的重要一步，有助于远程健康监测工作。

##### **MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**
2412.03039v1 by Hyojeong Lee, Youngwan Jo, Inpyo Hong, Sanghyun Park

We propose a Multifaceted Resilient Network(MRNet), a novel architecture
developed for medical image-to-image translation that outperforms
state-of-the-art methods in MRI-to-CT and MRI-to-MRI conversion. MRNet
leverages the Segment Anything Model (SAM) to exploit frequency-based features
to build a powerful method for advanced medical image transformation. The
architecture extracts comprehensive multiscale features from diverse datasets
using a powerful SAM image encoder and performs resolution-aware feature fusion
that consistently integrates U-Net encoder outputs with SAM-derived features.
This fusion optimizes the traditional U-Net skip connection while leveraging
transformer-based contextual analysis. The translation is complemented by an
innovative dual-mask configuration incorporating dynamic attention patterns and
a specialized loss function designed to address regional mapping mismatches,
preserving both the gross anatomy and tissue details. Extensive validation
studies have shown that MRNet outperforms state-of-the-art architectures,
particularly in maintaining anatomical fidelity and minimizing translation
artifacts.

摘要：我們提出一個多方面的彈性網路 (MRNet)，這是一個創新的架構，
開發用於醫學影像轉影像的翻譯，其優於 MRI 轉 CT 和 MRI 轉 MRI 轉換的最新方法。MRNet
利用 Segment Anything Model (SAM) 來利用基於頻率的特徵，以建立一種強大的方法，用於先進的醫學影像轉換。此
架構使用強大的 SAM 影像編碼器從不同的資料集提取全面的多尺度特徵，並執行解析度感知特徵融合，持續將 U-Net 編碼器輸出與 SAM 衍生的特徵整合在一起。
此融合最佳化傳統的 U-Net 跳躍連接，同時利用基於Transformer的上下文分析。翻譯由一個創新的雙遮罩配置補充，它結合了動態注意模式和一個專門的損失函數，旨在解決區域對應不匹配的問題，同時保留了整體解剖結構和組織細節。廣泛的驗證研究顯示，MRNet 優於最先進的架構，特別是在維持解剖保真度和最小化轉換偽影方面。

##### **Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**
2412.02919v1 by Soroush Omranpour, Guillaume Rabusseau, Reihaneh Rabbany

Transformers are now ubiquitous for sequence modeling tasks, but their
extension to multi-dimensional data remains a challenge due to the quadratic
cost of the attention mechanism. In this paper, we propose Higher-Order
Transformers (HOT), a novel architecture designed to efficiently process data
with more than two axes, i.e. higher-order tensors. To address the
computational challenges associated with high-order tensor attention, we
introduce a novel Kronecker factorized attention mechanism that reduces the
attention cost to quadratic in each axis' dimension, rather than quadratic in
the total size of the input tensor. To further enhance efficiency, HOT
leverages kernelized attention, reducing the complexity to linear. This
strategy maintains the model's expressiveness while enabling scalable attention
computation. We validate the effectiveness of HOT on two high-dimensional
tasks, including multivariate time series forecasting, and 3D medical image
classification. Experimental results demonstrate that HOT achieves competitive
performance while significantly improving computational efficiency, showcasing
its potential for tackling a wide range of complex, multi-dimensional data.

摘要：變形金剛現在普遍用於序列建模任務，但由於注意力機制的二次方成本，它們擴展到多維數據仍然是一個挑戰。在本文中，我們提出了高階變形金剛 (HOT)，這是一種新穎的架構，旨在有效處理具有兩個以上軸線的數據，即高階張量。為了應對與高階張量注意力相關的計算挑戰，我們引入了一種新穎的克羅內克分解注意力機制，該機制將注意力成本降低到每個軸線維度的二次方，而不是輸入張量的總大小的二次方。為了進一步提高效率，HOT 利用核化注意力，將複雜度降低到線性。此策略保持了模型的表現力，同時實現了可擴展的注意力計算。我們在兩個高維任務上驗證了 HOT 的有效性，包括多元時間序列預測和 3D 醫學影像分類。實驗結果表明，HOT 在顯著提高計算效率的同時實現了競爭力的效能，展示了其應對各種複雜的多維數據的潛力。

##### **A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**
2412.02868v1 by Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu

Large Language Models (LLMs) have shown impressive capabilities in natural
language processing, yet their use in sensitive domains like healthcare,
particularly with Electronic Health Records (EHR), faces significant challenges
due to privacy concerns and limited computational resources. This paper
presents a compact LLM framework designed for local deployment in settings with
strict privacy requirements and limited access to high-performance GPUs. We
introduce a novel preprocessing technique that uses information extraction
methods, e.g., regular expressions, to filter and emphasize critical
information in clinical notes, enhancing the performance of smaller LLMs on EHR
data. Our framework is evaluated using zero-shot and few-shot learning
paradigms on both private and publicly available (MIMIC-IV) datasets, and we
also compare its performance with fine-tuned LLMs on the MIMIC-IV dataset. The
results demonstrate that our preprocessing approach significantly boosts the
prediction accuracy of smaller LLMs, making them suitable for high-privacy,
resource-constrained applications. This study offers valuable insights into
optimizing LLM performance for sensitive, data-intensive tasks while addressing
computational and privacy limitations.

摘要：大型語言模型 (LLM) 在自然語言處理方面展現出令人印象深刻的能力，然而它們在醫療保健等敏感領域的使用，特別是電子健康紀錄 (EHR)，由於隱私問題和有限的運算資源而面臨重大挑戰。本文提出了一個緊湊的 LLM 框架，旨在在具有嚴格隱私要求和有限使用高性能 GPU 的環境中進行本地部署。我們引入了一種新穎的預處理技術，它使用資訊萃取方法，例如正規表示法，來過濾和強調臨床筆記中的關鍵資訊，增強較小 LLM 在 EHR 資料上的效能。我們的框架使用零次學習和少次學習範例在私人和公開可用的 (MIMIC-IV) 資料集上進行評估，我們也比較它在 MIMIC-IV 資料集上與微調 LLM 的效能。結果表明，我們的預處理方法顯著提升了較小 LLM 的預測準確度，使其適用於高度隱私、資源受限的應用程式。這項研究提供了寶貴的見解，用於最佳化 LLM 效能以應對敏感、資料密集型任務，同時解決運算和隱私限制。

##### **Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**
2412.02851v1 by Oliver Simonoski, Dijana Capeska Bogatinoska

This research explores the integration of blockchain technology in
healthcare, focusing on enhancing the security and efficiency of Electronic
Health Record (EHR) management. We propose a novel Ethereum-based system that
empowers patients with secure control over their medical data. Our approach
addresses key challenges in healthcare blockchain implementation, including
scalability, privacy, and regulatory compliance. The system incorporates
digital signatures, Role-Based Access Control, and a multi-layered architecture
to ensure secure, controlled access. We developed a decentralized application
(dApp) with user-friendly interfaces for patients, doctors, and administrators,
demonstrating the practical application of our solution. A survey among
healthcare professionals and IT experts revealed strong interest in blockchain
adoption, while also highlighting concerns about integration costs. The study
explores future enhancements, including integration with IoT devices and
AI-driven analytics, contributing to the evolution of secure, efficient, and
interoperable healthcare systems that leverage cutting-edge technologies for
improved patient care.

摘要：本研究探討區塊鏈技術在醫療保健中的整合，專注於提升電子健康紀錄 (EHR) 管理的安全性與效率。我們提出一個創新的以太坊系統，賦予患者安全地控制其醫療數據的權力。我們的做法解決了醫療保健區塊鏈實作中的主要挑戰，包括可擴充性、隱私和法規遵循。該系統整合了數位簽章、基於角色的存取控制和多層架構，以確保安全且受控的存取。我們開發了一個具有使用者友善介面的去中心化應用程式 (dApp)，適用於患者、醫生和管理員，展示了我們解決方案的實際應用。在醫療保健專業人員和 IT 專家之間進行的一項調查顯示，他們對區塊鏈的採用有濃厚興趣，但也強調了對整合成本的擔憂。該研究探討了未來的強化，包括與 IoT 裝置整合和 AI 驅動的分析，有助於安全、高效且可互操作的醫療保健系統的演進，該系統利用尖端技術改善患者照護。

##### **CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels**
2412.02819v3 by Lingxiao Wei, He Yan, Xiangju Lu, Junmin Zhu, Jun Wang, Wei Zhang

Large Language Models (LLMs) have been well-researched in many long-context
tasks. However, due to high annotation costs, high-quality long-context summary
datasets for training or evaluation are scarce, limiting further research. In
this work, we introduce CNNSum, a new multi-scale Chinese long-context novel
summarization benchmark, including four subsets, length covering 16k to 128k,
695 samples in total, the annotations are human-driven. We evaluate commercial
and open-source models on CNNSum and conduct a detailed analysis. Based on the
observations, we further conduct fine-tuning exploration with short-context
summary data. In our study: (1) GPT-4o underperformed, due to excessive
subjective commentary. (2) Currently, long-context summarization mainly relies
on memory ability, small LLMs with stable longer context lengths are the most
cost-effective. Using long data concatenated from short-context summaries makes
a significant improvement. (3) Prompt templates may cause a large performance
gap but can be mitigated through fine-tuning. (4) Fine-tuned Chat or
Instruction versions may harm the Base model and further fine-tuning cannot
bridge performance gap. (5) while models with RoPE base scaling exhibit strong
extrapolation potential, their performance may vary significantly when combined
with other interpolation methods and need careful selection. (6) CNNSum
provides more reliable and insightful evaluation results than other benchmarks.
We release CNNSum to advance research in this field
(https://github.com/CxsGhost/CNNSum).

摘要：<paragraph>大型語言模型 (LLM) 已在許多長語境任務中獲得深入研究。然而，由於標註成本高，用於訓練或評估的高品質長語境摘要資料集稀少，限制了進一步的研究。在這項工作中，我們引入了 CNNSum，一個新的多尺度中文長語境小說摘要基準，包括四個子集，長度涵蓋 16k 到 128k，總共 695 個範例，標註是由人工驅動的。我們評估了 CNNSum 上的商業和開源模型，並進行了詳細的分析。根據觀察結果，我們進一步使用短語境摘要資料進行微調探索。在我們的研究中：(1) GPT-4o 表現不佳，原因是過度的主觀評論。(2) 目前，長語境摘要主要依賴記憶能力，具有穩定較長語境長度的小型 LLM 最具成本效益。使用從短語境摘要串接而成的長資料顯著改善了表現。(3) 提示範本可能會造成很大的效能差距，但可以透過微調來減輕。(4) 微調過的聊天或指令版本可能會損害基礎模型，而進一步的微調無法彌合效能差距。(5) 雖然具有 RoPE 基礎縮放的模型展現出強大的外推潛力，但與其他內插方法結合時，其效能可能會顯著變化，需要仔細選擇。(6) CNNSum 提供比其他基準更可靠且有見地的評估結果。我們發布 CNNSum 以推進此領域的研究 (https://github.com/CxsGhost/CNNSum)。</paragraph>

##### **Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**
2412.02801v2 by Jingyuan Yi, Peiyang Yu, Tianyi Huang, Zeqiu Xu

Aiming at the latest particle swarm optimization algorithm, this paper
proposes an improved Transformer model to improve the accuracy of heart disease
prediction and provide a new algorithm idea. We first use three mainstream
machine learning classification algorithms - decision tree, random forest and
XGBoost, and then output the confusion matrix of these three models. The
results showed that the random forest model had the best performance in
predicting the classification of heart disease, with an accuracy of 92.2%.
Then, we apply the Transformer model based on particle swarm optimization (PSO)
algorithm to the same dataset for classification experiment. The results show
that the classification accuracy of the model is as high as 96.5%, 4.3
percentage points higher than that of random forest, which verifies the
effectiveness of PSO in optimizing Transformer model. From the above research,
we can see that particle swarm optimization significantly improves Transformer
performance in heart disease prediction. Improving the ability to predict heart
disease is a global priority with benefits for all humankind. Accurate
prediction can enhance public health, optimize medical resources, and reduce
healthcare costs, leading to healthier populations and more productive
societies worldwide. This advancement paves the way for more efficient health
management and supports the foundation of a healthier, more resilient global
community.

摘要：<paragraph>針對最新的粒子群最佳化演算法，本文提出改良的 Transformer 模型，以提升心臟病預測的準確度，並提供新的演算法思維。我們首先使用三種主流機器學習分類演算法——決策樹、隨機森林與 XGBoost，並輸出這三種模型的混淆矩陣。結果顯示隨機森林模型在預測心臟病分類上表現最佳，準確度為 92.2%。接著，我們將基於粒子群最佳化 (PSO) 演算法的 Transformer 模型套用於相同資料集進行分類實驗。結果顯示該模型的分類準確度高達 96.5%，比隨機森林高出 4.3 個百分點，驗證了 PSO 在最佳化 Transformer 模型上的有效性。從上述研究中，我們可以看出粒子群最佳化顯著提升了 Transformer 在心臟病預測上的表現。提升預測心臟病的能力是一項全球性的優先要務，對全人類都有益。準確的預測可以增進公共衛生、優化醫療資源並降低醫療保健成本，進而促進全球人口的健康和社會生產力。這項進展為更有效率的健康管理鋪路，並支持建立一個更健康、更具韌性的全球社群。</paragraph>

##### **Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**
2412.02621v1 by Kai Sun, Siyan Xue, Fuchun Sun, Haoran Sun, Yu Luo, Ling Wang, Siyuan Wang, Na Guo, Lei Liu, Tian Zhao, Xinzhou Wang, Lei Yang, Shuo Jin, Jun Yan, Jiahong Dong

Recent advancements in deep learning have significantly revolutionized the
field of clinical diagnosis and treatment, offering novel approaches to improve
diagnostic precision and treatment efficacy across diverse clinical domains,
thus driving the pursuit of precision medicine. The growing availability of
multi-organ and multimodal datasets has accelerated the development of
large-scale Medical Multimodal Foundation Models (MMFMs). These models, known
for their strong generalization capabilities and rich representational power,
are increasingly being adapted to address a wide range of clinical tasks, from
early diagnosis to personalized treatment strategies. This review offers a
comprehensive analysis of recent developments in MMFMs, focusing on three key
aspects: datasets, model architectures, and clinical applications. We also
explore the challenges and opportunities in optimizing multimodal
representations and discuss how these advancements are shaping the future of
healthcare by enabling improved patient outcomes and more efficient clinical
workflows.

摘要：深度學習的最新進展大幅革新了臨床診斷和治療領域，提供了改善各種臨床領域診斷精準度和治療效果的新方法，進而推動精準醫療的追求。多器官和多模態資料集的可用性日益增加，加速了大規模醫療多模態基礎模型 (MMFM) 的發展。這些模型以其強大的概化能力和豐富的表徵能力而聞名，正日益被改編以解決廣泛的臨床任務，從早期診斷到個人化治療策略。本篇評論提供了對 MMFM 近期發展的全面分析，重點關注三個關鍵面向：資料集、模型架構和臨床應用。我們也探討了最佳化多模態表徵的挑戰和機會，並討論這些進展如何透過改善患者預後和更有效率的臨床工作流程，形塑醫療保健的未來。

##### **U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**
2412.02242v1 by Fnu Neha, Deepshikha Bhati, Deepak Kumar Shukla, Sonavi Makarand Dalvi, Nikolaos Mantzou, Safa Shubbar

Medical imaging is essential in healthcare to provide key insights into
patient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive
techniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography
(CT), and Ultrasound (US), capture detailed images of organs, tissues, and
abnormalities. Effective analysis of these images requires precise segmentation
to delineate regions of interest (ROI), such as organs or lesions. Traditional
segmentation methods, relying on manual feature-extraction, are labor-intensive
and vary across experts. Recent advancements in Artificial Intelligence (AI)
and Deep Learning (DL), particularly convolutional models such as U-Net and its
variants (U-Net++ and U-Net 3+), have transformed medical image segmentation
(MIS) by automating the process and enhancing accuracy. These models enable
efficient, precise pixel-wise classification across various imaging modalities,
overcoming the limitations of manual segmentation. This review explores various
medical imaging techniques, examines the U-Net architectures and their
adaptations, and discusses their application across different modalities. It
also identifies common challenges in MIS and proposes potential solutions.

摘要：醫療影像在醫療保健中至關重要，可提供患者解剖結構和病理學的重要見解，有助於診斷和治療。X 光、磁振造影 (MRI)、電腦斷層掃描 (CT) 和超音波 (US) 等非侵入式技術，可捕捉器官、組織和異常的詳細影像。有效分析這些影像需要精確的分割，以描繪感興趣區域 (ROI)，例如器官或病灶。傳統的分割方法依賴於手動特徵萃取，既費時又因專家而異。人工智慧 (AI) 和深度學習 (DL) 的最新進展，特別是 U-Net 和其變體 (U-Net++ 和 U-Net 3+) 等卷積模型，已透過自動化流程和提高準確度，轉變了醫療影像分割 (MIS)。這些模型能跨越各種影像模式進行有效且精確的逐像素分類，克服了手動分割的限制。本篇評論探討了各種醫療影像技術，審查了 U-Net 架構及其改編，並討論了它們在不同模式中的應用。它也找出了 MIS 中常見的挑戰，並提出了潛在的解決方案。

##### **Recovering implicit physics model under real-world constraints**
2412.02215v1 by Ayan Banerjee, Sandeep K. S. Gupta

Recovering a physics-driven model, i.e. a governing set of equations of the
underlying dynamical systems, from the real-world data has been of recent
interest. Most existing methods either operate on simulation data with
unrealistically high sampling rates or require explicit measurements of all
system variables, which is not amenable in real-world deployments. Moreover,
they assume the timestamps of external perturbations to the physical system are
known a priori, without uncertainty, implicitly discounting any sensor
time-synchronization or human reporting errors. In this paper, we propose a
novel liquid time constant neural network (LTC-NN) based architecture to
recover underlying model of physical dynamics from real-world data. The
automatic differentiation property of LTC-NN nodes overcomes problems
associated with low sampling rates, the input dependent time constant in the
forward pass of the hidden layer of LTC-NN nodes creates a massive search space
of implicit physical dynamics, the physics model solver based data
reconstruction loss guides the search for the correct set of implicit dynamics,
and the use of the dropout regularization in the dense layer ensures extraction
of the sparsest model. Further, to account for the perturbation timing error,
we utilize dense layer nodes to search through input shifts that results in the
lowest reconstruction loss. Experiments on four benchmark dynamical systems,
three with simulation data and one with the real-world data show that the
LTC-NN architecture is more accurate in recovering implicit physics model
coefficients than the state-of-the-art sparse model recovery approaches. We
also introduce four additional case studies (total eight) on real-life medical
examples in simulation and with real-world clinical data to show effectiveness
of our approach in recovering underlying model in practice.

摘要：<paragraph>從真實世界資料中還原物理驅動模型，即基礎動態系統的控制方程式組，一直是近期的研究重點。現有方法大多在具有非現實高取樣率的模擬資料上執行，或需要所有系統變數的明確測量值，這在真實世界的部署中並不可行。此外，這些方法假設對物理系統的外部擾動的時間戳是先驗已知的，且沒有不確定性，隱含地忽略了任何感測器時間同步或人為回報錯誤。在本文中，我們提出了一種基於新穎液態時間常數神經網路 (LTC-NN) 的架構，以從真實世界資料中還原物理動態的基礎模型。LTC-NN 節點的自動微分特性克服了與低取樣率相關的問題，LTC-NN 節點隱藏層的前向傳遞中輸入依賴的時間常數會產生一個巨大的隱式物理動態搜尋空間，基於物理模型求解器的資料重建損失引導了對正確隱式動態集的搜尋，並且在稠密層中使用中斷正則化確保了最稀疏模型的提取。此外，為了考慮擾動計時錯誤，我們利用稠密層節點來搜尋輸入位移，這將導致最低的重建損失。在四個基準動態系統（三個使用模擬資料，一個使用真實世界資料）上的實驗表明，LTC-NN 架構在恢復隱式物理模型係數方面比最先進的稀疏模型恢復方法更準確。我們還介紹了四個額外的案例研究（總共八個），這些研究涉及模擬中的真實醫療範例和真實世界的臨床資料，以展示我們的做法在實務中恢復基礎模型的有效性。</paragraph>

##### **Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**
2412.02189v1 by Abu Bakar Siddik, Faisal R. Badal, Afroza Islam

A great deal of effort has been devoted to discovering a particular genetic
disorder, but its classification across a broad spectrum of disorder classes
and types remains elusive. Early diagnosis of genetic disorders enables timely
interventions and improves outcomes. This study implements machine learning
models using basic clinical indicators measurable at birth or infancy to enable
diagnosis in preliminary life stages. Supervised learning algorithms were
implemented on a dataset of 22083 instances with 42 features like family
history, newborn metrics, and basic lab tests. Extensive hyperparameter tuning,
feature engineering, and selection were undertaken. Two multi-class classifiers
were developed: one for predicting disorder classes (mitochondrial,
multifactorial, and single-gene) and one for subtypes (9 disorders).
Performance was evaluated using accuracy, precision, recall, and the F1-score.
The CatBoost classifier achieved the highest accuracy of 77% for predicting
genetic disorder classes. For subtypes, SVM attained a maximum accuracy of 80%.
The study demonstrates the feasibility of using basic clinical data in machine
learning models for early categorization and diagnosis across various genetic
disorders. Applying ML with basic clinical indicators can enable timely
interventions once validated on larger datasets. It is necessary to conduct
further studies to improve model performance on this dataset.

摘要：<paragraph>許多研究致力於發現特定遺傳性疾病，但其在廣泛的疾病類型和分類中的分類仍然難以捉摸。遺傳性疾病的早期診斷能及時介入並改善結果。本研究實作機器學習模型，使用出生或嬰兒時期可測量的基本臨床指標，以在生命的早期階段進行診斷。監督式學習演算法實作在一個包含 22083 個實例的資料集上，其中包含 42 個特徵，例如家族史、新生兒指標和基本實驗室檢驗。進行了廣泛的超參數調整、特徵工程和選擇。開發了兩個多類別分類器：一個用於預測疾病類型（粒線體、多因素和單基因），另一個用於預測亞型（9 種疾病）。使用準確度、精確度、召回率和 F1 分數評估效能。CatBoost 分類器在預測遺傳性疾病類型方面達到了 77% 的最高準確度。對於亞型，SVM 達到了 80% 的最高準確度。本研究證明了在機器學習模型中使用基本臨床資料進行早期分類和診斷各種遺傳性疾病的可行性。將機器學習應用於基本臨床指標，可以在較大的資料集上驗證後及時進行干預。有必要進行進一步的研究以改善此資料集上的模型效能。</paragraph>

##### **Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**
2412.02177v1 by R. Mahmood, K. C. L. Wong, D. M. Reyes, N. D'Souza, L. Shi, J. Wu, P. Kaviani, M. Kalra, G. Wang, P. Yan, T. Syeda-Mahmood

With the emergence of large-scale vision-language models, realistic radiology
reports may be generated using only medical images as input guided by simple
prompts. However, their practical utility has been limited due to the factual
errors in their description of findings. In this paper, we propose a novel
model for explainable fact-checking that identifies errors in findings and
their locations indicated through the reports. Specifically, we analyze the
types of errors made by automated reporting methods and derive a new synthetic
dataset of images paired with real and fake descriptions of findings and their
locations from a ground truth dataset. A new multi-label cross-modal
contrastive regression network is then trained on this datsaset. We evaluate
the resulting fact-checking model and its utility in correcting reports
generated by several SOTA automated reporting tools on a variety of benchmark
datasets with results pointing to over 40\% improvement in report quality
through such error detection and correction.

摘要：隨著大規模視覺語言模型的出現，僅使用醫療影像作為輸入，並透過簡單提示引導，即可產生逼真的放射科報告。然而，由於其對發現的描述有事實上的錯誤，因此其實際效用受到限制。在本文中，我們提出了一個用於可解釋事實查核的新模型，該模型可識別報告中發現的錯誤及其位置。具體來說，我們分析了自動化報告方法所產生的錯誤類型，並從真實資料集中衍生出一個新的合成影像資料集，其中配對了發現及其位置的真實和虛假描述。然後在這個資料集上訓練一個新的多標籤跨模態對比回歸網路。我們評估了產生的事實查核模型及其在更正由多個 SOTA 自動化報告工具在各種基準資料集上產生的報告中的效用，結果表明透過這種錯誤偵測和更正，報告品質獲得了超過 40% 的提升。

##### **Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**
2412.02173v1 by Nader Karayanni, Aya Awwad, Chein-Lien Hsiao, Surish P Shanmugam

Since the emergence of Large Language Models (LLMs), the challenge of
effectively leveraging their potential in healthcare has taken center stage. A
critical barrier to using LLMs for extracting insights from unstructured
clinical notes lies in the prompt engineering process. Despite its pivotal role
in determining task performance, a clear framework for prompt optimization
remains absent. Current methods to address this gap take either a manual prompt
refinement approach, where domain experts collaborate with prompt engineers to
create an optimal prompt, which is time-intensive and difficult to scale, or
through employing automatic prompt optimizing approaches, where the value of
the input of domain experts is not fully realized. To address this, we propose
StructEase, a novel framework that bridges the gap between automation and the
input of human expertise in prompt engineering. A core innovation of the
framework is SamplEase, an iterative sampling algorithm that identifies
high-value cases where expert feedback drives significant performance
improvements. This approach minimizes expert intervention, to effectively
enhance classification outcomes. This targeted approach reduces labeling
redundancy, mitigates human error, and enhances classification outcomes. We
evaluated the performance of StructEase using a dataset of de-identified
clinical narratives from the US National Electronic Injury Surveillance System
(NEISS), demonstrating significant gains in classification performance compared
to current methods. Our findings underscore the value of expert integration in
LLM workflows, achieving notable improvements in F1 score while maintaining
minimal expert effort. By combining transparency, flexibility, and scalability,
StructEase sets the foundation for a framework to integrate expert input into
LLM workflows in healthcare and beyond.

摘要：自大型語言模型 (LLM) 出現以來，有效利用其在醫療保健中的潛力的挑戰已成為重中之重。使用 LLM 從非結構化臨床筆記中提取見解的一個關鍵障礙在於提示工程過程。儘管它在確定任務績效中扮演著舉足輕重的角色，但仍缺乏明確的提示最佳化框架。目前解決此差距的方法採用手動提示優化方法，其中領域專家與提示工程師合作建立最佳提示，這非常耗時且難以擴展，或透過採用自動提示最佳化方法，其中領域專家的輸入價值並未充分實現。為了解決這個問題，我們提出了 StructEase，這是一個新穎的框架，它彌合了自動化與提示工程中人類專業知識輸入之間的差距。該框架的核心創新是 SamplEase，這是一種迭代式抽樣演算法，它識別出專家回饋能顯著提升績效的高價值案例。這種方法將專家介入降到最低，以有效提升分類結果。這種有針對性的方法減少了標籤冗餘，減輕了人為錯誤，並提升了分類結果。我們使用來自美國國家電子傷害監測系統 (NEISS) 的去識別化臨床敘述資料集評估了 StructEase 的績效，與目前的方法相比，分類績效有了顯著的提升。我們的研究結果強調了專家整合在 LLM 工作流程中的價值，在維持最少專家工作量的同時，達到了 F1 分數的顯著提升。透過結合透明度、彈性和可擴展性，StructEase 為一個框架奠定了基礎，將專家輸入整合到醫療保健及其他領域的 LLM 工作流程中。

##### **Construction and optimization of health behavior prediction model for the elderly in smart elderly care**
2412.02062v1 by Qian Guo, Peiyuan Chen

With the intensification of global aging, health management of the elderly
has become a focus of social attention. This study designs and implements a
smart elderly care service model to address issues such as data diversity,
health status complexity, long-term dependence and data loss, sudden changes in
behavior, and data privacy in the prediction of health behaviors of the
elderly. The model achieves accurate prediction and dynamic management of
health behaviors of the elderly through modules such as multimodal data fusion,
data loss processing, nonlinear prediction, emergency detection, and privacy
protection. In the experimental design, based on multi-source data sets and
market research results, the model demonstrates excellent performance in health
behavior prediction, emergency detection, and personalized services. The
experimental results show that the model can effectively improve the accuracy
and robustness of health behavior prediction and meet the actual application
needs in the field of smart elderly care. In the future, with the integration
of more data and further optimization of technology, the model will provide
more powerful technical support for smart elderly care services.

摘要：隨著全球高齡化加劇，老年人的健康管理已成為社會關注的焦點。本研究設計並實作一個智慧老人照護服務模型，以解決老人健康行為預測中的資料異質性、健康狀態複雜性、長期依賴性與資料流失、行為突變、資料隱私等問題。該模型透過多模態資料融合、資料流失處理、非線性預測、緊急事件偵測、隱私保護等模組，達到老人健康行為的精準預測與動態管理。在實驗設計上，基於多來源資料集與市場調查結果，該模型在健康行為預測、緊急事件偵測、個人化服務等方面均展現出優異的表現。實驗結果顯示，該模型能有效提升健康行為預測的準確性與魯棒性，並滿足智慧老人照護領域的實際應用需求。未來隨著更多資料的整合與技術的進一步優化，該模型將為智慧老人照護服務提供更強大的技術支撐。

##### **INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**
2412.02012v2 by Wenbo Zhang, Junyu Chen, Christopher Kanan

Due to their large sizes, volumetric scans and whole-slide pathology images
(WSIs) are often processed by extracting embeddings from local regions and then
an aggregator makes predictions from this set. However, current methods require
post-hoc visualization techniques (e.g., Grad-CAM) and often fail to localize
small yet clinically crucial details. To address these limitations, we
introduce INSIGHT, a novel weakly-supervised aggregator that integrates heatmap
generation as an inductive bias. Starting from pre-trained feature maps,
INSIGHT employs a detection module with small convolutional kernels to capture
fine details and a context module with a broader receptive field to suppress
local false positives. The resulting internal heatmap highlights diagnostically
relevant regions. On CT and WSI benchmarks, INSIGHT achieves state-of-the-art
classification results and high weakly-labeled semantic segmentation
performance. Project website and code are available at:
https://zhangdylan83.github.io/ewsmia/

摘要：由於體積龐大，體積掃描和全玻片病理圖像 (WSI) 通常透過從局部區域提取嵌入式處理，然後聚合器從此組中做出預測。然而，目前的方法需要事後可視化技術（例如 Grad-CAM），而且常常無法定位小型但臨床上至關重要的細節。為了解決這些限制，我們引入了 INSIGHT，這是一種新穎的弱監督聚合器，它將熱圖生成整合為歸納偏誤。從預先訓練好的特徵圖開始，INSIGHT 使用帶有小型卷積核的檢測模組來擷取精細的細節，以及帶有較廣泛感受野的上下文模組來抑制局部誤報。產生的內部熱圖突出了診斷相關區域。在 CT 和 WSI 基準上，INSIGHT 達到了最先進的分類結果和高弱標記語義分割效能。專案網站和程式碼可於下列網址取得：
https://zhangdylan83.github.io/ewsmia/

##### **The use of large language models to enhance cancer clinical trial educational materials**
2412.01955v2 by Mingye Gao, Aman Varshney, Shan Chen, Vikram Goddla, Jack Gallifant, Patrick Doyle, Claire Novack, Maeve Dillon-Martin, Teresia Perkins, Xinrong Correia, Erik Duhaime, Howard Isenstein, Elad Sharon, Lisa Soleymani Lehmann, David Kozono, Brian Anthony, Dmitriy Dligach, Danielle S. Bitterman

Cancer clinical trials often face challenges in recruitment and engagement
due to a lack of participant-facing informational and educational resources.
This study investigated the potential of Large Language Models (LLMs),
specifically GPT4, in generating patient-friendly educational content from
clinical trial informed consent forms. Using data from ClinicalTrials.gov, we
employed zero-shot learning for creating trial summaries and one-shot learning
for developing multiple-choice questions, evaluating their effectiveness
through patient surveys and crowdsourced annotation. Results showed that
GPT4-generated summaries were both readable and comprehensive, and may improve
patients' understanding and interest in clinical trials. The multiple-choice
questions demonstrated high accuracy and agreement with crowdsourced
annotators. For both resource types, hallucinations were identified that
require ongoing human oversight. The findings demonstrate the potential of LLMs
"out-of-the-box" to support the generation of clinical trial education
materials with minimal trial-specific engineering, but implementation with a
human-in-the-loop is still needed to avoid misinformation risks.

摘要：癌症臨床試驗由於缺乏面向參與者的資訊和教育資源，常常在招募和參與方面面臨挑戰。本研究探討了大型語言模型 (LLM)，特別是 GPT4，從臨床試驗知情同意書中產生對患者友善的教育內容的潛力。我們使用來自 ClinicalTrials.gov 的資料，採用零次學習來建立試驗摘要，以及一次學習來開發多選題，並透過患者調查和群眾外包註解來評估其有效性。結果顯示，GPT4 生成的摘要具有可讀性和全面性，並且可能提高患者對臨床試驗的理解和興趣。多選題展示出很高的準確度，並且與群眾外包註解者達成共識。對於這兩種資源類型，我們發現了需要持續的人工監督的幻覺。這些發現展示了 LLM「開箱即用」的潛力，可以用最少的試驗特定工程來支援臨床試驗教育材料的產生，但仍需要採用有人在迴路中的實作來避免錯誤資訊的風險。

##### **Recurrent Neural Network on PICTURE Model**
2412.01933v1 by Weihan Xu

Intensive Care Units (ICUs) provide critical care and life support for most
severely ill and injured patients in the hospital. With the need for ICUs
growing rapidly and unprecedentedly, especially during COVID-19, accurately
identifying the most critical patients helps hospitals to allocate resources
more efficiently and save more lives. The Predicting Intensive Care Transfers
and Other Unforeseen Events (PICTURE) model predicts patient deterioration by
separating those at high risk for imminent intensive care unit transfer,
respiratory failure, or death from those at lower risk. This study aims to
implement a deep learning model to benchmark the performance from the XGBoost
model, an existing model which has competitive results on prediction.

摘要：加護病房 (ICU) 提供重症照護和生命支持，給予醫院中病情最嚴重和受傷最嚴重的患者。由於對加護病房的需求快速且空前地增長，特別是在 COVID-19 期間，準確找出病情最危急的患者有助於醫院更有效地分配資源並挽救更多生命。預測加護病房轉診和其他無法預見事件 (PICTURE) 模型透過將面臨迫在眉睫的加護病房轉診、呼吸衰竭或死亡的高風險患者與風險較低的患者區分開來，預測患者惡化。本研究旨在實作深度學習模型，以基準化 XGBoost 模型的效能，後者是一種在預測方面具有競爭力的現有模型。

##### **ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**
2412.01929v1 by Poorya Aghaomidi, Ge Wang

Accurate sleep stage classification is essential for understanding sleep
disorders and improving overall health. This study proposes a novel three-stage
approach for sleep stage classification using ECG signals, offering a more
accessible alternative to traditional methods that often rely on complex
modalities like EEG. In Stages 1 and 2, we initialize the weights of two
networks, which are then integrated in Stage 3 for comprehensive
classification. In the first phase, we estimate key features using Feature
Imitating Networks (FINs) to achieve higher accuracy and faster convergence.
The second phase focuses on identifying the N1 sleep stage through the
time-frequency representation of ECG signals. Finally, the third phase
integrates models from the previous stages and employs a Kolmogorov-Arnold
Network (KAN) to classify five distinct sleep stages. Additionally, data
augmentation techniques, particularly SMOTE, are used in enhancing
classification capabilities for underrepresented stages like N1. Our results
demonstrate significant improvements in the classification performance, with an
overall accuracy of 80.79% an overall kappa of 0.73. The model achieves
specific accuracies of 86.70% for Wake, 60.36% for N1, 83.89% for N2, 84.85%
for N3, and 87.16% for REM. This study emphasizes the importance of weight
initialization and data augmentation in optimizing sleep stage classification
with ECG signals.

摘要：精準的睡眠分期分類對於了解睡眠障礙和改善整體健康至關重要。本研究提出一個新的三階段方法，使用 ECG 訊號進行睡眠分期分類，提供了一個更易於取得的替代方案，傳統方法通常依賴於 EEG 等複雜的模式。在第 1 和第 2 階段，我們初始化兩個網路的權重，然後在第 3 階段整合它們以進行全面的分類。在第一階段，我們使用特徵模仿網路 (FIN) 估計關鍵特徵，以實現更高的準確度和更快的收斂。第二階段專注於透過 ECG 訊號的時頻表示來識別 N1 睡眠階段。最後，第三階段整合前一階段的模型，並採用 Kolmogorov-Arnold 網路 (KAN) 來分類五個不同的睡眠階段。此外，資料擴充技術，特別是 SMOTE，用於增強對 N1 等代表性不足階段的分類能力。我們的結果證明了分類效能有顯著的改善，整體準確度為 80.79%，整體 kappa 為 0.73。該模型對清醒、N1、N2、N3 和 REM 的特定準確度分別為 86.70%、60.36%、83.89%、84.85% 和 87.16%。本研究強調了權重初始化和資料擴充在使用 ECG 訊號最佳化睡眠分期分類中的重要性。

##### **Deep Guess acceleration for explainable image reconstruction in sparse-view CT**
2412.01703v1 by Elena Loli Piccolomini, Davide Evangelista, Elena Morotti

Sparse-view Computed Tomography (CT) is an emerging protocol designed to
reduce X-ray dose radiation in medical imaging. Traditional Filtered Back
Projection algorithm reconstructions suffer from severe artifacts due to sparse
data. In contrast, Model-Based Iterative Reconstruction (MBIR) algorithms,
though better at mitigating noise through regularization, are too
computationally costly for clinical use. This paper introduces a novel
technique, denoted as the Deep Guess acceleration scheme, using a trained
neural network both to quicken the regularized MBIR and to enhance the
reconstruction accuracy. We integrate state-of-the-art deep learning tools to
initialize a clever starting guess for a proximal algorithm solving a
non-convex model and thus computing an interpretable solution image in a few
iterations. Experimental results on real CT images demonstrate the Deep Guess
effectiveness in (very) sparse tomographic protocols, where it overcomes its
mere variational counterpart and many data-driven approaches at the state of
the art. We also consider a ground truth-free implementation and test the
robustness of the proposed framework to noise.

摘要：稀疏視圖電腦斷層掃描 (CT) 是一種新興的協定，旨在減少醫療影像中的 X 射線劑量輻射。傳統的濾波反向投影演算法重建因稀疏資料而導致嚴重的偽影。相比之下，基於模型的迭代重建 (MBIR) 演算法，雖然透過正則化在減輕雜訊方面表現得更好，但對於臨床使用而言，其計算成本過高。本文介紹了一種創新的技術，稱為 Deep Guess 加速方案，它使用訓練過的類神經網路來加速正則化的 MBIR 並增強重建準確度。我們整合了最先進的深度學習工具，為求解非凸模型的近端演算法初始化一個聰明的起始猜測，從而僅在幾次迭代中計算出可解釋的解影像。在真實 CT 影像上的實驗結果證明了 Deep Guess 在（非常）稀疏斷層攝影協定中的有效性，在該協定中，它克服了其單純的變分對應物和許多最先進的資料驅動方法。我們還考慮了無真實依據的實作，並測試了所提出的架構對雜訊的穩健性。

##### **Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**
2412.01692v1 by Liza Dahiya, Rachit Bagga

Social media platforms, particularly Reddit's r/Epilepsy community, offer a
unique perspective into the experiences of individuals with epilepsy (PWE) and
their caregivers. This study analyzes 57k posts and 533k comments to explore
key themes across demographics such as age, gender, and relationships. Our
findings highlight significant discussions on epilepsy-related challenges,
including depression (with 39.75\% of posts indicating severe symptoms),
driving restrictions, workplace concerns, and pregnancy-related issues in women
with epilepsy. We introduce a novel engagement metric, F(P), which incorporates
post length, sentiment scores, and readability to quantify community
interaction. This analysis underscores the importance of integrated care
addressing both neurological and mental health challenges faced by PWE. The
insights from this study inform strategies for targeted support and awareness
interventions.

摘要：社群媒體平台，特別是 Reddit 的 r/Epilepsy 社群，提供了癲癇患者 (PWE) 及其照顧者的經驗獨特觀點。這項研究分析了 57k 則貼文和 533k 則留言，探討不同人口統計資料（例如年齡、性別和關係）中的主要主題。我們的發現強調了關於癲癇相關挑戰的重要討論，包括憂鬱症（39.75% 的貼文表示有嚴重症狀）、駕駛限制、職場問題和癲癇女性的懷孕相關問題。我們引進了一項創新的參與度指標 F(P)，它結合了貼文長度、情緒分數和可讀性，以量化社群互動。這項分析強調了整合性照護的重要性，它能同時解決 PWE 面臨的神經和心理健康挑戰。這項研究的見解提供了針對性支持和意識介入策略。

##### **Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**
2412.01605v1 by Jie Liu, Wenxuan Wang, Zizhan Ma, Guolin Huang, Yihang SU, Kao-Jung Chang, Wenting Chen, Haoliang Li, Linlin Shen, Michael Lyu

Clinical decision making (CDM) is a complex, dynamic process crucial to
healthcare delivery, yet it remains a significant challenge for artificial
intelligence systems. While Large Language Model (LLM)-based agents have been
tested on general medical knowledge using licensing exams and knowledge
question-answering tasks, their performance in the CDM in real-world scenarios
is limited due to the lack of comprehensive testing datasets that mirror actual
medical practice. To address this gap, we present MedChain, a dataset of 12,163
clinical cases that covers five key stages of clinical workflow. MedChain
distinguishes itself from existing benchmarks with three key features of
real-world clinical practice: personalization, interactivity, and
sequentiality. Further, to tackle real-world CDM challenges, we also propose
MedChain-Agent, an AI system that integrates a feedback mechanism and a
MCase-RAG module to learn from previous cases and adapt its responses.
MedChain-Agent demonstrates remarkable adaptability in gathering information
dynamically and handling sequential clinical tasks, significantly outperforming
existing approaches. The relevant dataset and code will be released upon
acceptance of this paper.

摘要：臨床決策制定 (CDM) 是一個複雜、動態的過程，對於醫療保健的提供至關重要，然而對於人工智慧系統來說，它仍然是一項重大的挑戰。雖然大型語言模型 (LLM) 基礎代理已使用執照考試和知識問答任務對一般醫療知識進行了測試，但它們在實際場景中的 CDM 中的表現受到缺乏反映實際醫療實務的綜合測試資料集的限制。為了解決這個差距，我們提出了 MedChain，這是一個包含 12,163 個臨床案例的資料集，涵蓋了臨床工作流程的五個關鍵階段。MedChain 以現實世界臨床實務的三個關鍵特徵區別於現有的基準：個人化、互動性和順序性。此外，為了應對現實世界的 CDM 挑戰，我們還提出了 MedChain-Agent，這是一個整合了回饋機制和 MCase-RAG 模組的人工智慧系統，用於從先前的案例中學習並調整其回應。MedChain-Agent 在動態收集資訊和處理順序性臨床任務方面展現了顯著的適應性，顯著優於現有方法。相關的資料集和程式碼將在本文被接受後發布。

##### **NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**
2412.01590v1 by Sandesh Pokhrel, Sanjay Bhandari, Sharib Ali, Tryphon Lambrou, Anh Nguyen, Yash Raj Shrestha, Angus Watson, Danail Stoyanov, Prashnna Gyawali, Binod Bhattarai

The integration of deep learning tools in gastrointestinal vision holds the
potential for significant advancements in diagnosis, treatment, and overall
patient care. A major challenge, however, is these tools' tendency to make
overconfident predictions, even when encountering unseen or newly emerging
disease patterns, undermining their reliability.
  We address this critical issue of reliability by framing it as an
out-of-distribution (OOD) detection problem, where previously unseen and
emerging diseases are identified as OOD examples. However, gastrointestinal
images pose a unique challenge due to the overlapping feature representations
between in- Distribution (ID) and OOD examples. Existing approaches often
overlook this characteristic, as they are primarily developed for natural image
datasets, where feature distinctions are more apparent. Despite the overlap, we
hypothesize that the features of an in-distribution example will cluster closer
to the centroids of their ground truth class, resulting in a shorter distance
to the nearest centroid. In contrast, OOD examples maintain an equal distance
from all class centroids. Based on this observation, we propose a novel
nearest-centroid distance deficit (NCCD) score in the feature space for
gastrointestinal OOD detection.
  Evaluations across multiple deep learning architectures and two publicly
available benchmarks, Kvasir2 and Gastrovision, demonstrate the effectiveness
of our approach compared to several state-of-the-art methods. The code and
implementation details are publicly available at:
https://github.com/bhattarailab/NCDD

摘要：深度學習工具整合在胃腸道視覺中，在診斷、治療和整體病人照護方面具有顯著進展的潛力。然而，一個重大的挑戰是，這些工具傾向於做出過度自信的預測，即使在遇到未見或新出現的疾病模式時，也會破壞其可靠性。
我們將此可靠性的關鍵問題，架構為一個異常分佈 (OOD) 偵測問題，其中以前未見和新出現的疾病被視為 OOD 範例。然而，由於分佈內 (ID) 和 OOD 範例之間的重疊特徵表示，胃腸道影像構成了一項獨特的挑戰。現有的方法通常忽略此特性，因為它們主要是為自然影像資料集而開發，其中特徵區別較為明顯。儘管有重疊，我們假設分佈內範例的特徵會聚集在其真實類別的質心附近，導致到最近質心的距離較短。相反地，OOD 範例與所有類別質心的距離相等。基於此觀察，我們在特徵空間中提出了一個用於胃腸道 OOD 偵測的新穎最近質心距離差 (NCCD) 分數。
在多個深度學習架構和兩個公開基準 Kvasir2 和 Gastrovision 中的評估，證明了我們的方法與幾種最先進的方法相比的有效性。程式碼和實作細節公開於：
https://github.com/bhattarailab/NCDD

##### **MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**
2412.01405v1 by Thi-Nhu-Quynh Nguyen, Quang-Huy Ho, Duy-Thai Nguyen, Hoang-Minh-Quang Le, Van-Truong Pham, Thi-Thao Tran

Early detection of skin abnormalities plays a crucial role in diagnosing and
treating skin cancer. Segmentation of affected skin regions using AI-powered
devices is relatively common and supports the diagnostic process. However,
achieving high performance remains a significant challenge due to the need for
high-resolution images and the often unclear boundaries of individual lesions.
At the same time, medical devices require segmentation models to have a small
memory foot-print and low computational cost. Based on these requirements, we
introduce a novel lightweight model called MambaU-Lite, which combines the
strengths of Mamba and CNN architectures, featuring just over 400K parameters
and a computational cost of more than 1G flops. To enhance both global context
and local feature extraction, we propose the P-Mamba block, a novel component
that incorporates VSS blocks along-side multiple pooling layers, enabling the
model to effectively learn multiscale features and enhance segmentation
performance. We evaluate the model's performance on two skin datasets, ISIC2018
and PH2, yielding promising results. Our source code will be made publicly
available at: https://github.com/nqnguyen812/MambaU-Lite.

摘要：早期皮膚異常偵測在診斷和治療皮膚癌中扮演著至關重要的角色。使用 AI 驅動的裝置分割受影響的皮膚區域相對常見，並支援診斷流程。然而，由於需要高解析度影像和個別病灶通常不明確的邊界，要達成高性能仍是一項重大的挑戰。同時，醫療裝置要求分割模型具有小的記憶體佔用空間和低運算成本。基於這些需求，我們引進了一種名為 MambaU-Lite 的新型輕量級模型，它結合了 Mamba 和 CNN 架構的優點，特點是只有超過 400K 個參數和超過 1G flops 的運算成本。為了增強全局背景和局部特徵萃取，我們提出了 P-Mamba 塊，這是一個新的組成部分，它結合了 VSS 塊和多個池化層，使模型能夠有效地學習多尺度特徵並增強分割性能。我們在兩個皮膚資料集 ISIC2018 和 PH2 上評估了模型的性能，產生了有希望的結果。我們的原始程式碼將公開於：https://github.com/nqnguyen812/MambaU-Lite。

##### **Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**
2412.01353v1 by Chayan Tank, Shaina Mehta, Sarthak Pol, Vinayak Katoch, Avinash Anand, Raj Jaiswal, Rajiv Ratn Shah

In recent times, more and more people are posting about their mental states
across various social media platforms. Leveraging this data, AI-based systems
can be developed that help in assessing the mental health of individuals, such
as suicide risk. This paper is a study done on suicidal risk assessments using
Reddit data leveraging Base language models to identify patterns from social
media posts. We have demonstrated that using smaller language models, i.e.,
less than 500M parameters, can also be effective in contrast to LLMs with
greater than 500M parameters. We propose Su-RoBERTa, a fine-tuned RoBERTa on
suicide risk prediction task that utilized both the labeled and unlabeled
Reddit data and tackled class imbalance by data augmentation using GPT-2 model.
Our Su-RoBERTa model attained a 69.84% weighted F1 score during the Final
evaluation. This paper demonstrates the effectiveness of Base language models
for the analysis of the risk factors related to mental health with an efficient
computation pipeline

摘要：近來，愈來愈多人於各種社群媒體平台發布其心理狀態。利用此資料，可以開發出基於 AI 的系統，用於評估個人的心理健康，例如自殺風險。本文是一項針對自殺風險評估的研究，利用 Reddit 資料，並利用基礎語言模型來識別社群媒體貼文的模式。我們已經證明，使用較小的語言模型（即小於 5 億個參數）也可以有效，這與參數大於 5 億個的 LLM 相比。我們提出 Su-RoBERTa，一個針對自殺風險預測任務進行微調的 RoBERTa，它利用標記和未標記的 Reddit 資料，並透過使用 GPT-2 模型進行資料擴充來解決類別不平衡的問題。我們的 Su-RoBERTa 模型在最終評估期間獲得了 69.84% 的加權 F1 分數。本文證明了基礎語言模型在分析與心理健康相關的風險因子方面的有效性，並具備高效的運算管道

##### **Multimodal Medical Disease Classification with LLaMA II**
2412.01306v1 by Christian Gapp, Elias Tappeiner, Martin Welk, Rainer Schubert

Medical patient data is always multimodal. Images, text, age, gender,
histopathological data are only few examples for different modalities in this
context. Processing and integrating this multimodal data with deep learning
based methods is of utmost interest due to its huge potential for medical
procedure such as diagnosis and patient treatment planning. In this work we
retrain a multimodal transformer-based model for disease classification. To
this end we use the text-image pair dataset from OpenI consisting of 2D chest
X-rays associated with clinical reports. Our focus is on fusion methods for
merging text and vision information extracted from medical datasets. Different
architecture structures with a LLaMA II backbone model are tested. Early fusion
of modality specific features creates better results with the best model
reaching 97.10% mean AUC than late fusion from a deeper level of the
architecture (best model: 96.67% mean AUC). Both outperform former
classification models tested on the same multimodal dataset. The newly
introduced multimodal architecture can be applied to other multimodal datasets
with little effort and can be easily adapted for further research, especially,
but not limited to, the field of medical AI.

摘要：醫療病患資料總是多模態的。影像、文字、年齡、性別、組織病理學資料只是此脈絡下不同模態的幾個例子。處理和整合這些多模態資料，並使用深度學習方法，由於其在醫療程序（例如診斷和病患治療計畫）的龐大潛力，因此至關重要。在這項工作中，我們重新訓練一個多模態Transformer基礎模型，用於疾病分類。為此，我們使用來自 OpenI 的文字影像配對資料集，其中包含與臨床報告相關的 2D 胸部 X 光。我們的重點在於融合方法，用於合併從醫療資料集提取的文字和影像資訊。測試了具有 LLaMA II 主幹模型的不同架構結構。特定於模態特徵的早期融合會產生更好的結果，最佳模型達到 97.10% 的平均 AUC，高於從架構更深層次進行的後期融合（最佳模型：96.67% 的平均 AUC）。兩者都優於在相同多模態資料集上測試的前分類模型。新推出的多模態架構可以毫不費力地應用於其他多模態資料集，並且可以輕鬆改編以進行進一步的研究，特別是（但不限於）醫療 AI 領域。

##### **Best Practices for Large Language Models in Radiology**
2412.01233v1 by Christian Bluethgen, Dave Van Veen, Cyril Zakka, Katherine Link, Aaron Fanous, Roxana Daneshjou, Thomas Frauenfelder, Curtis Langlotz, Sergios Gatidis, Akshay Chaudhari

At the heart of radiological practice is the challenge of integrating complex
imaging data with clinical information to produce actionable insights. Nuanced
application of language is key for various activities, including managing
requests, describing and interpreting imaging findings in the context of
clinical data, and concisely documenting and communicating the outcomes. The
emergence of large language models (LLMs) offers an opportunity to improve the
management and interpretation of the vast data in radiology. Despite being
primarily general-purpose, these advanced computational models demonstrate
impressive capabilities in specialized language-related tasks, even without
specific training. Unlocking the potential of LLMs for radiology requires basic
understanding of their foundations and a strategic approach to navigate their
idiosyncrasies. This review, drawing from practical radiology and machine
learning expertise and recent literature, provides readers insight into the
potential of LLMs in radiology. It examines best practices that have so far
stood the test of time in the rapidly evolving landscape of LLMs. This includes
practical advice for optimizing LLM characteristics for radiology practices
along with limitations, effective prompting, and fine-tuning strategies.

摘要：放射學實務的核心挑戰，在於整合複雜的影像資料與臨床資訊，以產生可行的見解。語言的細緻運用是各種活動的關鍵，包括管理請求、描述和解讀影像結果的臨床資料，以及簡潔地記錄和傳達結果。大型語言模型 (LLM) 的出現，提供了一個機會來改善放射學中大量資料的管理和解讀。儘管主要是一般用途，這些先進的計算模型在專業的語言相關任務中展現出令人印象深刻的能力，即使沒有特定的訓練。要解鎖 LLM 在放射學中的潛力，需要基本了解其基礎，以及應對其獨特之處的策略性方法。這篇評論從實務放射學和機器學習專業知識以及近期文獻中汲取，為讀者提供 LLM 在放射學中的潛力的見解。它檢視了迄今為止在 LLM 快速演變的領域中經得起時間考驗的最佳實務。這包括針對放射學實務最佳化 LLM 特性的實務建議，以及限制、有效的提示和微調策略。

##### **Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**
2412.01119v1 by Mojtaba S. Fazli, Shannon Quinn

Object tracking is a fundamental tool in modern innovation, with applications
in defense systems, autonomous vehicles, and biomedical research. It enables
precise identification, monitoring, and spatiotemporal analysis of objects
across sequential frames, providing insights into dynamic behaviors. In cell
biology, object tracking is vital for uncovering cellular mechanisms, such as
migration, interactions, and responses to drugs or pathogens. These insights
drive breakthroughs in understanding disease progression and therapeutic
interventions.
  Over time, object tracking methods have evolved from traditional
feature-based approaches to advanced machine learning and deep learning
frameworks. While classical methods are reliable in controlled settings, they
struggle in complex environments with occlusions, variable lighting, and high
object density. Deep learning models address these challenges by delivering
greater accuracy, adaptability, and robustness.
  This review categorizes object tracking techniques into traditional,
statistical, feature-based, and machine learning paradigms, with a focus on
biomedical applications. These methods are essential for tracking cells and
subcellular structures, advancing our understanding of health and disease. Key
performance metrics, including accuracy, efficiency, and adaptability, are
discussed. The paper explores limitations of current methods and highlights
emerging trends to guide the development of next-generation tracking systems
for biomedical research and broader scientific domains.

摘要：物件追蹤是現代創新中的一項基本工具，應用於國防系統、自動駕駛車輛和生物醫學研究中。它能精準地辨識、監控和時空分析連續畫面中的物件，提供動態行為的見解。在細胞生物學中，物件追蹤對於揭露細胞機制至關重要，例如遷移、交互作用和對藥物或病原體的反應。這些見解推動了對疾病進程和治療干預的理解的突破。
隨著時間的推移，物件追蹤方法已從傳統的基於特徵的方法演變為先進的機器學習和深度學習架構。雖然傳統方法在受控環境中是可靠的，但它們在有遮擋、光線變化和物件密度高的複雜環境中會遇到困難。深度學習模型通過提供更高的準確性、適應性和魯棒性來應對這些挑戰。
本綜述將物件追蹤技術分為傳統、統計、基於特徵和機器學習範例，重點關注生物醫學應用。這些方法對於追蹤細胞和亞細胞結構至關重要，促進了我們對健康和疾病的理解。討論了關鍵的效能指標，包括準確性、效率和適應性。本文探討了當前方法的局限性，並重點介紹了新興趨勢，以指導下一代生物醫學研究和更廣泛的科學領域追蹤系統的開發。

##### **Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**
2412.01031v2 by Razi Mahmood, Pingkun Yan, Diego Machado Reyes, Ge Wang, Mannudeep K. Kalra, Parisa Kaviani, Joy T. Wu, Tanveer Syeda-Mahmood

Several evaluation metrics have been developed recently to automatically
assess the quality of generative AI reports for chest radiographs based only on
textual information using lexical, semantic, or clinical named entity
recognition methods. In this paper, we develop a new method of report quality
evaluation by first extracting fine-grained finding patterns capturing the
location, laterality, and severity of a large number of clinical findings. We
then performed phrasal grounding to localize their associated anatomical
regions on chest radiograph images. The textual and visual measures are then
combined to rate the quality of the generated reports. We present results that
compare this evaluation metric with other textual metrics on a gold standard
dataset derived from the MIMIC collection and show its robustness and
sensitivity to factual errors.

摘要：最近已开发出几种评估指标，仅基于使用词法、语义或临床命名实体识别方法的文本信息，自动评估胸部 X 光片的生成式 AI 报告的质量。在本文中，我们开发了一种新的报告质量评估方法，首先提取细粒度的发现模式，捕捉大量临床发现的位置、左右性和严重性。然后，我们执行短语接地以定位其在胸部 X 光片图像上的相关解剖区域。然后将文本和视觉测量相结合，对生成报告的质量进行评分。我们展示了将此评估指标与其他文本指标在源自 MIMIC 集合的金标准数据集上进行比较的结果，并展示了其对事实错误的鲁棒性和敏感性。

##### **Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**
2412.00959v1 by Summra Saleem, Muhammad Nabeel Asim, Ludger Van Elst, Andreas Dengel

Traditional language models have been extensively evaluated for software
engineering domain, however the potential of ChatGPT and Gemini have not been
fully explored. To fulfill this gap, the paper in hand presents a comprehensive
case study to investigate the potential of both language models for development
of diverse types of requirement engineering applications. It deeply explores
impact of varying levels of expert knowledge prompts on the prediction
accuracies of both language models. Across 4 different public benchmark
datasets of requirement engineering tasks, it compares performance of both
language models with existing task specific machine/deep learning predictors
and traditional language models. Specifically, the paper utilizes 4 benchmark
datasets; Pure (7,445 samples, requirements extraction),PROMISE (622 samples,
requirements classification), REQuestA (300 question answer (QA) pairs) and
Aerospace datasets (6347 words, requirements NER tagging). Our experiments
reveal that, in comparison to ChatGPT, Gemini requires more careful prompt
engineering to provide accurate predictions. Moreover, across requirement
extraction benchmark dataset the state-of-the-art F1-score is 0.86 while
ChatGPT and Gemini achieved 0.76 and 0.77,respectively. The State-of-the-art
F1-score on requirements classification dataset is 0.96 and both language
models 0.78. In name entity recognition (NER) task the state-of-the-art
F1-score is 0.92 and ChatGPT managed to produce 0.36, and Gemini 0.25.
Similarly, across question answering dataset the state-of-the-art F1-score is
0.90 and ChatGPT and Gemini managed to produce 0.91 and 0.88 respectively. Our
experiments show that Gemini requires more precise prompt engineering than
ChatGPT. Except for question-answering, both models under-perform compared to
current state-of-the-art predictors across other tasks.

摘要：傳統語言模型已廣泛評估軟體工程領域，但 ChatGPT 和 Gemini 的潛力尚未被完全探索。為了填補這個差距，本文提出了全面的案例研究，以探討這兩種語言模型在開發各種需求工程應用程式方面的潛力。它深入探討了不同層級專家知識提示對這兩種語言模型預測精度的影響。在 4 個不同的需求工程任務公共基準資料集，它比較了這兩種語言模型與現有任務特定機器/深度學習預測器和傳統語言模型的效能。具體來說，本文利用 4 個基準資料集；Pure（7,445 個樣本，需求萃取）、PROMISE（622 個樣本，需求分類）、REQuestA（300 個問答 (QA) 對）和航太資料集（6347 個字，需求 NER 標記）。我們的實驗顯示，與 ChatGPT 相比，Gemini 需要更仔細的提示工程才能提供準確的預測。此外，在需求萃取基準資料集，最先進的 F1 分數為 0.86，而 ChatGPT 和 Gemini 分別達到 0.76 和 0.77。需求分類資料集的最先進 F1 分數為 0.96，而這兩種語言模型都為 0.78。在命名實體識別 (NER) 任務中，最先進的 F1 分數為 0.92，而 ChatGPT 產生 0.36，Gemini 產生 0.25。類似地，在問答資料集，最先進的 F1 分數為 0.90，而 ChatGPT 和 Gemini 分別產生 0.91 和 0.88。我們的實驗表明，Gemini 需要比 ChatGPT 更精確的提示工程。除了問答之外，這兩個模型在其他任務的表現都低於目前的最新預測器。

