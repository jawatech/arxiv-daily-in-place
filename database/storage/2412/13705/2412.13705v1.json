{"2412.13705": {"publish_time": "2024-12-18", "title": "Mitigating Adversarial Attacks in LLMs through Defensive Suffix Generation", "paper_summary": "Large language models (LLMs) have exhibited outstanding performance in\nnatural language processing tasks. However, these models remain susceptible to\nadversarial attacks in which slight input perturbations can lead to harmful or\nmisleading outputs. A gradient-based defensive suffix generation algorithm is\ndesigned to bolster the robustness of LLMs. By appending carefully optimized\ndefensive suffixes to input prompts, the algorithm mitigates adversarial\ninfluences while preserving the models' utility. To enhance adversarial\nunderstanding, a novel total loss function ($L_{\\text{total}}$) combining\ndefensive loss ($L_{\\text{def}}$) and adversarial loss ($L_{\\text{adv}}$)\ngenerates defensive suffixes more effectively. Experimental evaluations\nconducted on open-source LLMs such as Gemma-7B, mistral-7B, Llama2-7B, and\nLlama2-13B show that the proposed method reduces attack success rates (ASR) by\nan average of 11\\% compared to models without defensive suffixes. Additionally,\nthe perplexity score of Gemma-7B decreased from 6.57 to 3.93 when applying the\ndefensive suffix generated by openELM-270M. Furthermore, TruthfulQA evaluations\ndemonstrate consistent improvements with Truthfulness scores increasing by up\nto 10\\% across tested configurations. This approach significantly enhances the\nsecurity of LLMs in critical applications without requiring extensive\nretraining.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u8272\u7684\u8868\u73fe\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6a21\u578b\u4ecd\u5bb9\u6613\u53d7\u5230\u5c0d\u6297\u6027\u653b\u64ca\uff0c\u5176\u4e2d\u8f15\u5fae\u7684\u8f38\u5165\u64fe\u52d5\u53ef\u80fd\u5c0e\u81f4\u6709\u5bb3\u6216\u8aa4\u5c0e\u7684\u8f38\u51fa\u3002\u57fa\u65bc\u68af\u5ea6\u7684\u9632\u79a6\u6027\u5f8c\u7db4\u751f\u6210\u6f14\u7b97\u6cd5\u65e8\u5728\u52a0\u5f37 LLM \u7684\u7a69\u5065\u6027\u3002\u900f\u904e\u9644\u52a0\u7d93\u904e\u4ed4\u7d30\u6700\u4f73\u5316\u7684\u9632\u79a6\u6027\u5f8c\u7db4\u81f3\u8f38\u5165\u63d0\u793a\uff0c\u6b64\u6f14\u7b97\u6cd5\u53ef\u6e1b\u8f15\u5c0d\u6297\u6027\u5f71\u97ff\uff0c\u540c\u6642\u4fdd\u7559\u6a21\u578b\u7684\u6548\u7528\u3002\u70ba\u4e86\u589e\u5f37\u5c0d\u6297\u6027\u7406\u89e3\uff0c\u4e00\u500b\u65b0\u7a4e\u7684\u7e3d\u640d\u5931\u51fd\u6578 ($L_{\\text{total}}$) \u7d50\u5408\u4e86\u9632\u79a6\u6027\u640d\u5931 ($L_{\\text{def}}$) \u548c\u5c0d\u6297\u6027\u640d\u5931 ($L_{\\text{adv}}$)\uff0c\u66f4\u6709\u6548\u5730\u7522\u751f\u9632\u79a6\u6027\u5f8c\u7db4\u3002\u5728 Gemma-7B\u3001mistral-7B\u3001Llama2-7B \u548c Llama2-13B \u7b49\u958b\u6e90 LLM \u4e0a\u9032\u884c\u7684\u5be6\u9a57\u8a55\u4f30\u986f\u793a\uff0c\u8207\u6c92\u6709\u9632\u79a6\u6027\u5f8c\u7db4\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5c07\u653b\u64ca\u6210\u529f\u7387 (ASR) \u5e73\u5747\u964d\u4f4e\u4e86 11%\u3002\u6b64\u5916\uff0c\u5728\u61c9\u7528 openELM-270M \u751f\u6210\u7684\u9632\u79a6\u6027\u5f8c\u7db4\u6642\uff0cGemma-7B \u7684\u56f0\u60d1\u5ea6\u5206\u6578\u5f9e 6.57 \u964d\u4f4e\u5230 3.93\u3002\u6b64\u5916\uff0cTruthfulQA \u8a55\u4f30\u986f\u793a\uff0c\u5728\u6e2c\u8a66\u7684\u914d\u7f6e\u4e2d\uff0c\u771f\u5be6\u6027\u5206\u6578\u63d0\u9ad8\u4e86 10%\uff0c\u8b49\u660e\u4e86\u4e00\u81f4\u7684\u6539\u9032\u3002\u6b64\u65b9\u6cd5\u986f\u8457\u589e\u5f37\u4e86 LLM \u5728\u95dc\u9375\u61c9\u7528\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u800c\u7121\u9700\u9032\u884c\u5ee3\u6cdb\u7684\u518d\u8a13\u7df4\u3002", "author": "Minkyoung Kim et.al.", "authors": "Minkyoung Kim, Yunha Kim, Hyeram Seo, Heejung Choi, Jiye Han, Gaeun Kee, Soyoung Ko, HyoJe Jung, Byeolhee Kim, Young-Hak Kim, Sanghyun Park, Tae Joon Jun", "id": "2412.13705v1", "paper_url": "http://arxiv.org/abs/2412.13705v1", "repo": "null"}}