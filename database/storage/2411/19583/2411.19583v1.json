{"2411.19583": {"publish_time": "2024-11-29", "title": "Solving Rubik's Cube Without Tricky Sampling", "paper_summary": "The Rubiks Cube, with its vast state space and sparse reward structure,\npresents a significant challenge for reinforcement learning (RL) due to the\ndifficulty of reaching rewarded states. Previous research addressed this by\npropagating cost-to-go estimates from the solved state and incorporating search\ntechniques. These approaches differ from human strategies that start from fully\nscrambled cubes, which can be tricky for solving a general sparse-reward\nproblem. In this paper, we introduce a novel RL algorithm using policy gradient\nmethods to solve the Rubiks Cube without relying on near solved-state sampling.\nOur approach employs a neural network to predict cost patterns between states,\nallowing the agent to learn directly from scrambled states. Our method was\ntested on the 2x2x2 Rubiks Cube, where the cube was scrambled 50,000 times, and\nthe model successfully solved it in over 99.4% of cases. Notably, this result\nwas achieved using only the policy network without relying on tree search as in\nprevious methods, demonstrating its effectiveness and potential for broader\napplications in sparse-reward problems.", "paper_summary_zh": "\u9b54\u8853\u65b9\u584a\u64c1\u6709\u5ee3\u5927\u7684\u72c0\u614b\u7a7a\u9593\u548c\u7a00\u758f\u7684\u734e\u52f5\u7d50\u69cb\uff0c\n\u7531\u65bc\u96e3\u4ee5\u9054\u5230\u734e\u52f5\u72c0\u614b\uff0c\u56e0\u6b64\u5c0d\u5f37\u5316\u5b78\u7fd2 (RL) \u4f86\u8aaa\u662f\u4e00\u500b\u91cd\u5927\u7684\u6311\u6230\u3002\u5148\u524d\u7684\u7814\u7a76\u900f\u904e\u5f9e\u5df2\u89e3\u6c7a\u7684\u72c0\u614b\u50b3\u64ad\u6210\u672c\u4f30\u8a08\u503c\u4e26\u7d0d\u5165\u641c\u5c0b\u6280\u8853\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\u3002\u9019\u4e9b\u65b9\u6cd5\u4e0d\u540c\u65bc\u5f9e\u5b8c\u5168\u6253\u4e82\u7684\u65b9\u584a\u958b\u59cb\u7684\u4eba\u985e\u7b56\u7565\uff0c\u9019\u5c0d\u65bc\u89e3\u6c7a\u4e00\u822c\u7684\u7a00\u758f\u734e\u52f5\u554f\u984c\u4f86\u8aaa\u53ef\u80fd\u662f\u68d8\u624b\u7684\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684 RL \u6f14\u7b97\u6cd5\uff0c\u4f7f\u7528\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u4f86\u89e3\u6c7a\u9b54\u8853\u65b9\u584a\uff0c\u800c\u7121\u9700\u4f9d\u8cf4\u63a5\u8fd1\u5df2\u89e3\u6c7a\u72c0\u614b\u7684\u53d6\u6a23\u3002\u6211\u5011\u7684\u505a\u6cd5\u63a1\u7528\u795e\u7d93\u7db2\u8def\u4f86\u9810\u6e2c\u72c0\u614b\u4e4b\u9593\u7684\u6210\u672c\u6a21\u5f0f\uff0c\u8b93\u4ee3\u7406\u4eba\u53ef\u4ee5\u76f4\u63a5\u5f9e\u6253\u4e82\u7684\u72c0\u614b\u4e2d\u5b78\u7fd2\u3002\u6211\u5011\u7684\u6f14\u7b97\u6cd5\u5728 2x2x2 \u9b54\u8853\u65b9\u584a\u4e0a\u9032\u884c\u6e2c\u8a66\uff0c\u5176\u4e2d\u65b9\u584a\u88ab\u6253\u4e82\u4e86 50,000 \u6b21\uff0c\u800c\u6a21\u578b\u5728\u8d85\u904e 99.4% \u7684\u60c5\u6cc1\u4e0b\u6210\u529f\u5730\u89e3\u6c7a\u4e86\u5b83\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u9019\u500b\u7d50\u679c\u50c5\u4f7f\u7528\u7b56\u7565\u7db2\u8def\u9054\u6210\uff0c\u800c\u672a\u4f9d\u8cf4\u65bc\u5148\u524d\u7684\u6a39\u72c0\u641c\u5c0b\u65b9\u6cd5\uff0c\u8b49\u660e\u4e86\u5176\u5728\u7a00\u758f\u734e\u52f5\u554f\u984c\u4e2d\u66f4\u5ee3\u6cdb\u7684\u61c9\u7528\u4e0a\u7684\u6709\u6548\u6027\u548c\u6f5b\u529b\u3002", "author": "Yicheng Lin et.al.", "authors": "Yicheng Lin, Siyu Liang", "id": "2411.19583v1", "paper_url": "http://arxiv.org/abs/2411.19583v1", "repo": "null"}}