{"2501.07978": {"publish_time": "2025-01-14", "title": "Facial Dynamics in Video: Instruction Tuning for Improved Facial Expression Perception and Contextual Awareness", "paper_summary": "Facial expression captioning has found widespread application across various\ndomains. Recently, the emergence of video Multimodal Large Language Models\n(MLLMs) has shown promise in general video understanding tasks. However,\ndescribing facial expressions within videos poses two major challenges for\nthese models: (1) the lack of adequate datasets and benchmarks, and (2) the\nlimited visual token capacity of video MLLMs. To address these issues, this\npaper introduces a new instruction-following dataset tailored for dynamic\nfacial expression caption. The dataset comprises 5,033 high-quality video clips\nannotated manually, containing over 700,000 tokens. Its purpose is to improve\nthe capability of video MLLMs to discern subtle facial nuances. Furthermore, we\npropose FaceTrack-MM, which leverages a limited number of tokens to encode the\nmain character's face. This model demonstrates superior performance in tracking\nfaces and focusing on the facial expressions of the main characters, even in\nintricate multi-person scenarios. Additionally, we introduce a novel evaluation\nmetric combining event extraction, relation classification, and the longest\ncommon subsequence (LCS) algorithm to assess the content consistency and\ntemporal sequence consistency of generated text. Moreover, we present\nFEC-Bench, a benchmark designed to assess the performance of existing video\nMLLMs in this specific task. All data and source code will be made publicly\navailable.", "paper_summary_zh": "\u4eba\u81c9\u8868\u60c5\u6a19\u984c\u5728\u5404\u7a2e\u9818\u57df\u4e2d\u5df2\u5ee3\u6cdb\u61c9\u7528\u3002\u6700\u8fd1\uff0c\u8996\u983b\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u51fa\u73fe\u5df2\u5728\u4e00\u822c\u7684\u8996\u983b\u7406\u89e3\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u524d\u666f\u3002\u7136\u800c\uff0c\u5728\u8996\u983b\u4e2d\u63cf\u8ff0\u4eba\u81c9\u8868\u60c5\u5c0d\u9019\u4e9b\u6a21\u578b\u63d0\u51fa\u4e86\u5169\u5927\u6311\u6230\uff1a(1) \u7f3a\u4e4f\u8db3\u5920\u7684\u6578\u64da\u96c6\u548c\u57fa\u6e96\uff0c\u4ee5\u53ca (2) \u8996\u983b MLLM \u7684\u8996\u89ba\u4ee4\u724c\u5bb9\u91cf\u6709\u9650\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u500b\u65b0\u7684\u6307\u4ee4\u9075\u5faa\u6578\u64da\u96c6\uff0c\u5c08\u9580\u91dd\u5c0d\u52d5\u614b\u4eba\u81c9\u8868\u60c5\u6a19\u984c\u3002\u8a72\u6578\u64da\u96c6\u5305\u542b 5,033 \u500b\u624b\u52d5\u8a3b\u91cb\u7684\u9ad8\u54c1\u8cea\u8996\u983b\u526a\u8f2f\uff0c\u5305\u542b\u8d85\u904e 700,000 \u500b\u4ee4\u724c\u3002\u5176\u76ee\u7684\u662f\u63d0\u9ad8\u8996\u983b MLLM \u8fa8\u5225\u7d30\u5fae\u9762\u90e8\u7d30\u5fae\u5dee\u5225\u7684\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86 FaceTrack-MM\uff0c\u5b83\u5229\u7528\u6709\u9650\u6578\u91cf\u7684\u4ee4\u724c\u5c0d\u4e3b\u89d2\u8272\u7684\u81c9\u90e8\u9032\u884c\u7de8\u78bc\u3002\u6b64\u6a21\u578b\u5728\u8ffd\u8e64\u81c9\u90e8\u548c\u95dc\u6ce8\u4e3b\u8981\u89d2\u8272\u7684\u9762\u90e8\u8868\u60c5\u65b9\u9762\u8868\u73fe\u51fa\u512a\u7570\u7684\u6027\u80fd\uff0c\u5373\u4f7f\u5728\u8907\u96dc\u7684\u591a\u4eba\u5834\u666f\u4e2d\u4e5f\u662f\u5982\u6b64\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u7684\u8a55\u4f30\u6307\u6a19\uff0c\u7d50\u5408\u4e8b\u4ef6\u63d0\u53d6\u3001\u95dc\u4fc2\u5206\u985e\u548c\u6700\u9577\u516c\u5171\u5b50\u5e8f\u5217 (LCS) \u6f14\u7b97\u6cd5\uff0c\u4ee5\u8a55\u4f30\u751f\u6210\u6587\u672c\u7684\u5167\u5bb9\u4e00\u81f4\u6027\u548c\u6642\u9593\u9806\u5e8f\u4e00\u81f4\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u9084\u63d0\u51fa\u4e86 FEC-Bench\uff0c\u9019\u662f\u4e00\u500b\u57fa\u6e96\uff0c\u65e8\u5728\u8a55\u4f30\u73fe\u6709\u8996\u983b MLLM \u5728\u6b64\u7279\u5b9a\u4efb\u52d9\u4e2d\u7684\u6027\u80fd\u3002\u6240\u6709\u6578\u64da\u548c\u6e90\u4ee3\u78bc\u90fd\u5c07\u516c\u958b\u63d0\u4f9b\u3002", "author": "Jiaxing Zhao et.al.", "authors": "Jiaxing Zhao, Boyuan Sun, Xiang Chen, Xihan Wei", "id": "2501.07978v1", "paper_url": "http://arxiv.org/abs/2501.07978v1", "repo": "null"}}