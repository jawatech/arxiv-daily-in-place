{"2502.15589": {"publish_time": "2025-02-21", "title": "LightThinker: Thinking Step-by-Step Compression", "paper_summary": "Large language models (LLMs) have shown remarkable performance in complex\nreasoning tasks, but their efficiency is hindered by the substantial memory and\ncomputational costs associated with generating lengthy tokens. In this paper,\nwe propose LightThinker, a novel method that enables LLMs to dynamically\ncompress intermediate thoughts during reasoning. Inspired by human cognitive\nprocesses, LightThinker compresses verbose thought steps into compact\nrepresentations and discards the original reasoning chains, thereby\nsignificantly reducing the number of tokens stored in the context window. This\nis achieved by training the model on when and how to perform compression\nthrough data construction, mapping hidden states to condensed gist tokens, and\ncreating specialized attention masks. Additionally, we introduce the Dependency\n(Dep) metric to quantify the degree of compression by measuring the reliance on\nhistorical tokens during generation. Extensive experiments on four datasets and\ntwo models show that LightThinker reduces peak memory usage and inference time,\nwhile maintaining competitive accuracy. Our work provides a new direction for\nimproving the efficiency of LLMs in complex reasoning tasks without sacrificing\nperformance. Code will be released at https://github.com/zjunlp/LightThinker.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u8907\u96dc\u63a8\u7406\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u5353\u8d8a\u7684\u6548\u80fd\uff0c\u4f46\u5176\u6548\u7387\u53d7\u5230\u751f\u6210\u5197\u9577\u7b26\u865f\u6240\u4f34\u96a8\u7684\u9f90\u5927\u8a18\u61b6\u9ad4\u548c\u904b\u7b97\u6210\u672c\u6240\u963b\u7919\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa LightThinker\uff0c\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u4f7f LLM \u80fd\u5728\u63a8\u7406\u904e\u7a0b\u4e2d\u52d5\u614b\u58d3\u7e2e\u4e2d\u9593\u60f3\u6cd5\u3002LightThinker \u53d7\u5230\u4eba\u985e\u8a8d\u77e5\u904e\u7a0b\u7684\u555f\u767c\uff0c\u5c07\u5197\u9577\u7684\u601d\u8003\u6b65\u9a5f\u58d3\u7e2e\u6210\u7dca\u6e4a\u7684\u8868\u793a\uff0c\u4e26\u6368\u68c4\u539f\u59cb\u7684\u63a8\u7406\u93c8\uff0c\u5f9e\u800c\u5927\u5e45\u6e1b\u5c11\u5132\u5b58\u5728\u5167\u5bb9\u8996\u7a97\u4e2d\u7684\u7b26\u865f\u6578\u91cf\u3002\u9019\u662f\u900f\u904e\u8a13\u7df4\u6a21\u578b\u4f86\u6c7a\u5b9a\u4f55\u6642\u4ee5\u53ca\u5982\u4f55\u57f7\u884c\u58d3\u7e2e\uff0c\u900f\u904e\u8cc7\u6599\u5efa\u69cb\u3001\u5c07\u96b1\u85cf\u72c0\u614b\u5c0d\u61c9\u5230\u6fc3\u7e2e\u8981\u9ede\u7b26\u865f\uff0c\u4ee5\u53ca\u5efa\u7acb\u5c08\u9580\u7684\u6ce8\u610f\u529b\u906e\u7f69\u4f86\u9054\u6210\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u5165\u4f9d\u8cf4\u6027 (Dep) \u6307\u6a19\uff0c\u900f\u904e\u8861\u91cf\u751f\u6210\u904e\u7a0b\u4e2d\u5c0d\u6b77\u53f2\u7b26\u865f\u7684\u4f9d\u8cf4\u7a0b\u5ea6\uff0c\u4f86\u91cf\u5316\u58d3\u7e2e\u7a0b\u5ea6\u3002\u5728\u56db\u500b\u8cc7\u6599\u96c6\u548c\u5169\u500b\u6a21\u578b\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u986f\u793a\uff0cLightThinker \u6e1b\u5c11\u4e86\u5cf0\u503c\u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf\u548c\u63a8\u8ad6\u6642\u9593\uff0c\u540c\u6642\u7dad\u6301\u6709\u7af6\u722d\u529b\u7684\u6e96\u78ba\u5ea6\u3002\u6211\u5011\u7684\u7814\u7a76\u70ba\u6539\u5584 LLM \u5728\u8907\u96dc\u63a8\u7406\u4efb\u52d9\u4e2d\u7684\u6548\u7387\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\uff0c\u800c\u7121\u9700\u72a7\u7272\u6548\u80fd\u3002\u7a0b\u5f0f\u78bc\u5c07\u5728 https://github.com/zjunlp/LightThinker \u91cb\u51fa\u3002", "author": "Jintian Zhang et.al.", "authors": "Jintian Zhang, Yuqi Zhu, Mengshu Sun, Yujie Luo, Shuofei Qiao, Lun Du, Da Zheng, Huajun Chen, Ningyu Zhang", "id": "2502.15589v1", "paper_url": "http://arxiv.org/abs/2502.15589v1", "repo": "null"}}