{"2409.17531": {"publish_time": "2024-09-26", "title": "SimVG: A Simple Framework for Visual Grounding with Decoupled Multi-modal Fusion", "paper_summary": "Visual grounding is a common vision task that involves grounding descriptive\nsentences to the corresponding regions of an image. Most existing methods use\nindependent image-text encoding and apply complex hand-crafted modules or\nencoder-decoder architectures for modal interaction and query reasoning.\nHowever, their performance significantly drops when dealing with complex\ntextual expressions. This is because the former paradigm only utilizes limited\ndownstream data to fit the multi-modal feature fusion. Therefore, it is only\neffective when the textual expressions are relatively simple. In contrast,\ngiven the wide diversity of textual expressions and the uniqueness of\ndownstream training data, the existing fusion module, which extracts multimodal\ncontent from a visual-linguistic context, has not been fully investigated. In\nthis paper, we present a simple yet robust transformer-based framework, SimVG,\nfor visual grounding. Specifically, we decouple visual-linguistic feature\nfusion from downstream tasks by leveraging existing multimodal pre-trained\nmodels and incorporating additional object tokens to facilitate deep\nintegration of downstream and pre-training tasks. Furthermore, we design a\ndynamic weight-balance distillation method in the multi-branch synchronous\nlearning process to enhance the representation capability of the simpler\nbranch. This branch only consists of a lightweight MLP, which simplifies the\nstructure and improves reasoning speed. Experiments on six widely used VG\ndatasets, i.e., RefCOCO/+/g, ReferIt, Flickr30K, and GRefCOCO, demonstrate the\nsuperiority of SimVG. Finally, the proposed method not only achieves\nimprovements in efficiency and convergence speed but also attains new\nstate-of-the-art performance on these benchmarks. Codes and models will be\navailable at \\url{https://github.com/Dmmm1997/SimVG}.", "paper_summary_zh": "\u8996\u89ba\u57fa\u790e\u662f\u4e00\u500b\u5e38\u898b\u7684\u8996\u89ba\u4efb\u52d9\uff0c\u5b83\u6d89\u53ca\u5c07\u63cf\u8ff0\u6027\u53e5\u5b50\u57fa\u790e\u5316\u5230\u5716\u50cf\u7684\u5c0d\u61c9\u5340\u57df\u3002\u5927\u591a\u6578\u73fe\u6709\u65b9\u6cd5\u4f7f\u7528\u7368\u7acb\u7684\u5716\u50cf\u6587\u672c\u7de8\u78bc\uff0c\u4e26\u61c9\u7528\u8907\u96dc\u7684\u624b\u5de5\u6a21\u7d44\u6216\u7de8\u78bc\u5668\u89e3\u78bc\u5668\u67b6\u69cb\uff0c\u4ee5\u9032\u884c\u6a21\u614b\u4e92\u52d5\u548c\u67e5\u8a62\u63a8\u7406\u3002\u7136\u800c\uff0c\u5728\u8655\u7406\u8907\u96dc\u7684\u6587\u672c\u8868\u9054\u6642\uff0c\u5b83\u5011\u7684\u6548\u80fd\u6703\u986f\u8457\u4e0b\u964d\u3002\u9019\u662f\u56e0\u70ba\u524d\u4e00\u7a2e\u7bc4\u4f8b\u50c5\u5229\u7528\u6709\u9650\u7684\u4e0b\u6e38\u8cc7\u6599\u4f86\u914d\u5408\u591a\u6a21\u614b\u7279\u5fb5\u878d\u5408\u3002\u56e0\u6b64\uff0c\u53ea\u6709\u5728\u6587\u672c\u8868\u9054\u76f8\u5c0d\u7c21\u55ae\u6642\u624d\u6709\u6548\u3002\u76f8\u53cd\u5730\uff0c\u9451\u65bc\u6587\u672c\u8868\u9054\u7684\u591a\u6a23\u6027\u4ee5\u53ca\u4e0b\u6e38\u8a13\u7df4\u8cc7\u6599\u7684\u7368\u7279\u6027\uff0c\u73fe\u6709\u7684\u878d\u5408\u6a21\u7d44\uff08\u5f9e\u8996\u89ba\u8a9e\u8a00\u74b0\u5883\u4e2d\u63d0\u53d6\u591a\u6a21\u614b\u5167\u5bb9\uff09\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u57fa\u65bc\u8f49\u63db\u5668\u7684\u7c21\u55ae\u4f46\u5f37\u5927\u7684\u6846\u67b6 SimVG\uff0c\u7528\u65bc\u8996\u89ba\u57fa\u790e\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u901a\u904e\u5229\u7528\u73fe\u6709\u7684\u591a\u6a21\u614b\u9810\u8a13\u7df4\u6a21\u578b\u4e26\u52a0\u5165\u984d\u5916\u7684\u7269\u4ef6\u6a19\u8a18\u4f86\u89e3\u8026\u8996\u89ba\u8a9e\u8a00\u7279\u5fb5\u878d\u5408\u548c\u4e0b\u6e38\u4efb\u52d9\uff0c\u4ee5\u4fc3\u9032\u4e0b\u6e38\u548c\u9810\u8a13\u7df4\u4efb\u52d9\u7684\u6df1\u5ea6\u6574\u5408\u3002\u6b64\u5916\uff0c\u6211\u5011\u5728\u591a\u5206\u652f\u540c\u6b65\u5b78\u7fd2\u904e\u7a0b\u4e2d\u8a2d\u8a08\u4e86\u4e00\u500b\u52d5\u614b\u6b0a\u91cd\u5e73\u8861\u84b8\u993e\u65b9\u6cd5\uff0c\u4ee5\u589e\u5f37\u8f03\u7c21\u55ae\u5206\u652f\u7684\u8868\u793a\u80fd\u529b\u3002\u6b64\u5206\u652f\u50c5\u5305\u542b\u4e00\u500b\u8f15\u91cf\u7d1a MLP\uff0c\u5b83\u7c21\u5316\u4e86\u7d50\u69cb\u4e26\u63d0\u9ad8\u4e86\u63a8\u7406\u901f\u5ea6\u3002\u5728\u516d\u500b\u5ee3\u6cdb\u4f7f\u7528\u7684 VG \u8cc7\u6599\u96c6\uff08\u5373 RefCOCO/+/g\u3001ReferIt\u3001Flickr30K \u548c GRefCOCO\uff09\u4e0a\u7684\u5be6\u9a57\u8b49\u660e\u4e86 SimVG \u7684\u512a\u8d8a\u6027\u3002\u6700\u5f8c\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u50c5\u5728\u6548\u7387\u548c\u6536\u6582\u901f\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u6539\u9032\uff0c\u800c\u4e14\u5728\u9019\u4e9b\u57fa\u6e96\u4e0a\u9084\u9054\u5230\u4e86\u65b0\u7684\u6700\u5148\u9032\u6548\u80fd\u3002\u7a0b\u5f0f\u78bc\u548c\u6a21\u578b\u5c07\u5728 \\url{https://github.com/Dmmm1997/SimVG} \u63d0\u4f9b\u3002", "author": "Ming Dai et.al.", "authors": "Ming Dai, Lingfeng Yang, Yihao Xu, Zhenhua Feng, Wankou Yang", "id": "2409.17531v1", "paper_url": "http://arxiv.org/abs/2409.17531v1", "repo": "https://github.com/dmmm1997/simvg"}}