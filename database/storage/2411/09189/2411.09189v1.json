{"2411.09189": {"publish_time": "2024-11-14", "title": "Improvement and Implementation of a Speech Emotion Recognition Model Based on Dual-Layer LSTM", "paper_summary": "This paper builds upon an existing speech emotion recognition model by adding\nan additional LSTM layer to improve the accuracy and processing efficiency of\nemotion recognition from audio data. By capturing the long-term dependencies\nwithin audio sequences through a dual-layer LSTM network, the model can\nrecognize and classify complex emotional patterns more accurately. Experiments\nconducted on the RAVDESS dataset validated this approach, showing that the\nmodified dual layer LSTM model improves accuracy by 2% compared to the\nsingle-layer LSTM while significantly reducing recognition latency, thereby\nenhancing real-time performance. These results indicate that the dual-layer\nLSTM architecture is highly suitable for handling emotional features with\nlong-term dependencies, providing a viable optimization for speech emotion\nrecognition systems. This research provides a reference for practical\napplications in fields like intelligent customer service, sentiment analysis\nand human-computer interaction.", "paper_summary_zh": "\u672c\u8ad6\u6587\u5efa\u7acb\u5728\u73fe\u6709\u7684\u8a9e\u97f3\u60c5\u7dd2\u8fa8\u8b58\u6a21\u578b\u4e0a\uff0c\u52a0\u5165\u984d\u5916\u7684 LSTM \u5c64\uff0c\u4ee5\u63d0\u5347\u5f9e\u97f3\u8a0a\u8cc7\u6599\u4e2d\u8fa8\u8b58\u60c5\u7dd2\u7684\u6e96\u78ba\u5ea6\u53ca\u8655\u7406\u6548\u7387\u3002\u900f\u904e\u96d9\u5c64 LSTM \u7db2\u8def\u64f7\u53d6\u97f3\u8a0a\u5e8f\u5217\u4e2d\u7684\u9577\u671f\u4f9d\u5b58\u95dc\u4fc2\uff0c\u6a21\u578b\u80fd\u66f4\u6e96\u78ba\u5730\u8fa8\u8b58\u548c\u5206\u985e\u8907\u96dc\u7684\u60c5\u7dd2\u6a21\u5f0f\u3002\u5728 RAVDESS \u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5be6\u9a57\u9a57\u8b49\u4e86\u6b64\u65b9\u6cd5\uff0c\u986f\u793a\u4fee\u6539\u5f8c\u7684\u96d9\u5c64 LSTM \u6a21\u578b\u6bd4\u55ae\u5c64 LSTM \u63d0\u5347\u4e86 2% \u7684\u6e96\u78ba\u5ea6\uff0c\u540c\u6642\u5927\u5e45\u964d\u4f4e\u8fa8\u8b58\u5ef6\u9072\uff0c\u9032\u800c\u63d0\u5347\u5373\u6642\u6548\u80fd\u3002\u9019\u4e9b\u7d50\u679c\u8868\u660e\uff0c\u96d9\u5c64 LSTM \u67b6\u69cb\u975e\u5e38\u9069\u5408\u8655\u7406\u5177\u6709\u9577\u671f\u4f9d\u5b58\u95dc\u4fc2\u7684\u60c5\u7dd2\u7279\u5fb5\uff0c\u70ba\u8a9e\u97f3\u60c5\u7dd2\u8fa8\u8b58\u7cfb\u7d71\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6700\u4f73\u5316\u65b9\u5f0f\u3002\u672c\u7814\u7a76\u70ba\u667a\u6167\u5ba2\u670d\u3001\u60c5\u7dd2\u5206\u6790\u548c\u4eba\u6a5f\u4e92\u52d5\u7b49\u9818\u57df\u7684\u5be6\u969b\u61c9\u7528\u63d0\u4f9b\u4e86\u53c3\u8003\u3002", "author": "Xiaoran Yang et.al.", "authors": "Xiaoran Yang, Shuhan Yu, Wenxi Xu", "id": "2411.09189v1", "paper_url": "http://arxiv.org/abs/2411.09189v1", "repo": "null"}}