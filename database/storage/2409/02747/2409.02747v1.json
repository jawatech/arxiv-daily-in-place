{"2409.02747": {"publish_time": "2024-09-04", "title": "Tractable Offline Learning of Regular Decision Processes", "paper_summary": "This work studies offline Reinforcement Learning (RL) in a class of\nnon-Markovian environments called Regular Decision Processes (RDPs). In RDPs,\nthe unknown dependency of future observations and rewards from the past\ninteractions can be captured by some hidden finite-state automaton. For this\nreason, many RDP algorithms first reconstruct this unknown dependency using\nautomata learning techniques. In this paper, we show that it is possible to\novercome two strong limitations of previous offline RL algorithms for RDPs,\nnotably RegORL. This can be accomplished via the introduction of two original\ntechniques: the development of a new pseudometric based on formal languages,\nwhich removes a problematic dependency on\n$L_\\infty^\\mathsf{p}$-distinguishability parameters, and the adoption of\nCount-Min-Sketch (CMS), instead of naive counting. The former reduces the\nnumber of samples required in environments that are characterized by a low\ncomplexity in language-theoretic terms. The latter alleviates the memory\nrequirements for long planning horizons. We derive the PAC sample complexity\nbounds associated to each of these techniques, and we validate the approach\nexperimentally.", "paper_summary_zh": "\u672c\u7814\u7a76\u63a2\u8a0e\u975e\u99ac\u53ef\u592b\u74b0\u5883\u4e2d\u7684\u4e00\u985e\u96e2\u7dda\u5f37\u5316\u5b78\u7fd2 (RL)\uff0c\u7a31\u70ba\u898f\u5247\u6c7a\u7b56\u904e\u7a0b (RDP)\u3002\u5728 RDP \u4e2d\uff0c\u672a\u4f86\u89c0\u5bdf\u548c\u734e\u52f5\u5c0d\u904e\u53bb\u4e92\u52d5\u7684\u672a\u77e5\u4f9d\u8cf4\u6027\u53ef\u4ee5\u7531\u4e00\u4e9b\u96b1\u85cf\u7684\u6709\u9650\u72c0\u614b\u81ea\u52d5\u6a5f\u6355\u7372\u3002\u56e0\u6b64\uff0c\u8a31\u591a RDP \u6f14\u7b97\u6cd5\u6703\u5148\u4f7f\u7528\u81ea\u52d5\u6a5f\u5b78\u7fd2\u6280\u8853\u91cd\u5efa\u6b64\u672a\u77e5\u4f9d\u8cf4\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u8b49\u660e\u53ef\u4ee5\u514b\u670d\u5148\u524d RDP \u96e2\u7dda RL \u6f14\u7b97\u6cd5\u7684\u5169\u500b\u91cd\u5927\u9650\u5236\uff0c\u7279\u5225\u662f RegORL\u3002\u9019\u53ef\u4ee5\u900f\u904e\u5c0e\u5165\u5169\u7a2e\u539f\u59cb\u6280\u8853\u4f86\u9054\u6210\uff1a\u57fa\u65bc\u5f62\u5f0f\u8a9e\u8a00\u958b\u767c\u65b0\u7684\u507d\u5ea6\u91cf\uff0c\u9019\u6d88\u9664\u4e86\u5c0d$L_\\infty^\\mathsf{p}$\u53ef\u5340\u5206\u6027\u53c3\u6578\u7684\u6709\u554f\u984c\u4f9d\u8cf4\u6027\uff0c\u4ee5\u53ca\u63a1\u7528 Count-Min-Sketch (CMS) \u4ee3\u66ff\u5929\u771f\u7684\u8a08\u6578\u3002\u524d\u8005\u6e1b\u5c11\u4e86\u5728\u8a9e\u8a00\u7406\u8ad6\u8853\u8a9e\u4e2d\u4ee5\u4f4e\u8907\u96dc\u5ea6\u70ba\u7279\u5fb5\u7684\u74b0\u5883\u4e2d\u6240\u9700\u7684\u6a23\u672c\u6578\u91cf\u3002\u5f8c\u8005\u6e1b\u8f15\u4e86\u9577\u671f\u898f\u5283\u7bc4\u570d\u7684\u8a18\u61b6\u9ad4\u9700\u6c42\u3002\u6211\u5011\u63a8\u5c0e\u51fa\u8207\u9019\u4e9b\u6280\u8853\u76f8\u95dc\u7684 PAC \u6a23\u672c\u8907\u96dc\u5ea6\u754c\u9650\uff0c\u4e26\u900f\u904e\u5be6\u9a57\u9a57\u8b49\u65b9\u6cd5\u3002", "author": "Ahana Deb et.al.", "authors": "Ahana Deb, Roberto Cipollone, Anders Jonsson, Alessandro Ronca, Mohammad Sadegh Talebi", "id": "2409.02747v1", "paper_url": "http://arxiv.org/abs/2409.02747v1", "repo": "null"}}