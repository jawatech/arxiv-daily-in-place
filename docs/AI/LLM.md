
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-19**|**ACING: Actor-Critic for Instruction Learning in Black-Box Large Language Models**|Salma Kharrat et.al.|[2411.12736v1](http://arxiv.org/abs/2411.12736v1)|[link](https://github.com/salmakh1/ACING)|
|**2024-11-19**|**Benchmarking Positional Encodings for GNNs and Graph Transformers**|Florian Grötschla et.al.|[2411.12732v1](http://arxiv.org/abs/2411.12732v1)|[link](https://github.com/ETH-DISCO/Benchmarking-PEs)|
|**2024-11-19**|**Information Theory of Meaningful Communication**|Doron Sivan et.al.|[2411.12728v1](http://arxiv.org/abs/2411.12728v1)|null|
|**2024-11-19**|**Scaling laws for nonlinear dynamical models of speech**|Sam Kirkham et.al.|[2411.12720v1](http://arxiv.org/abs/2411.12720v1)|null|
|**2024-11-19**|**Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation**|Praveen Srinivasa Varadhan et.al.|[2411.12719v1](http://arxiv.org/abs/2411.12719v1)|null|
|**2024-11-19**|**CATCH: Complementary Adaptive Token-level Contrastive Decoding to Mitigate Hallucinations in LVLMs**|Zhehan Kan et.al.|[2411.12713v1](http://arxiv.org/abs/2411.12713v1)|null|
|**2024-11-19**|**Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular, Nervous System, and Digestive Disorders Using Advanced LLMs**|Ahmed Akib Jawad Karim et.al.|[2411.12712v1](http://arxiv.org/abs/2411.12712v1)|null|
|**2024-11-19**|**Strengthening Fake News Detection: Leveraging SVM and Sophisticated Text Vectorization Techniques. Defying BERT?**|Ahmed Akib Jawad Karim et.al.|[2411.12703v1](http://arxiv.org/abs/2411.12703v1)|null|
|**2024-11-19**|**When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations**|Huaizhi Ge et.al.|[2411.12701v1](http://arxiv.org/abs/2411.12701v1)|null|
|**2024-11-19**|**Attribute Inference Attacks for Federated Regression Tasks**|Francesco Diana et.al.|[2411.12697v1](http://arxiv.org/abs/2411.12697v1)|null|
|**2024-11-19**|**AdaCM$^2$: On Understanding Extremely Long-Term Video with Adaptive Cross-Modality Memory Reduction**|Yuanbin Man et.al.|[2411.12593v1](http://arxiv.org/abs/2411.12593v1)|null|
|**2024-11-19**|**Enhanced Sign Language Translation between American Sign Language (ASL) and Indian Sign Language (ISL) Using LLMs**|Malay Kumar et.al.|[2411.12685v1](http://arxiv.org/abs/2411.12685v1)|null|
|**2024-11-19**|**AI Guided Early Screening of Cervical Cancer**|Dharanidharan S I et.al.|[2411.12681v1](http://arxiv.org/abs/2411.12681v1)|null|
|**2024-11-19**|**Deep Learning-Driven Heat Map Analysis for Evaluating thickness of Wounded Skin Layers**|Devakumar GR et.al.|[2411.12678v1](http://arxiv.org/abs/2411.12678v1)|null|
|**2024-11-19**|**Neurosymbolic Graph Enrichment for Grounded World Models**|Stefano De Giorgis et.al.|[2411.12671v1](http://arxiv.org/abs/2411.12671v1)|null|
|**2024-11-19**|**PoM: Efficient Image and Video Generation with the Polynomial Mixer**|David Picard et.al.|[2411.12663v1](http://arxiv.org/abs/2411.12663v1)|[link](https://github.com/davidpicard/homm)|
|**2024-11-19**|**CodeXEmbed: A Generalist Embedding Model Family for Multiligual and Multi-task Code Retrieval**|Ye Liu et.al.|[2411.12644v1](http://arxiv.org/abs/2411.12644v1)|null|
|**2024-11-19**|**DLBacktrace: A Model Agnostic Explainability for any Deep Learning Models**|Vinay Kumar Sankarapu et.al.|[2411.12643v1](http://arxiv.org/abs/2411.12643v1)|[link](https://github.com/aryaxai/dlbacktrace)|
|**2024-11-19**|**Instant Policy: In-Context Imitation Learning via Graph Diffusion**|Vitalis Vosylius et.al.|[2411.12633v1](http://arxiv.org/abs/2411.12633v1)|null|
|**2024-11-19**|**Estimating Dark Matter Halo Masses in Simulated Galaxy Clusters with Graph Neural Networks**|Nikhil Garuda et.al.|[2411.12629v1](http://arxiv.org/abs/2411.12629v1)|null|
|**2024-11-19**|**Leveraging Virtual Reality and AI Tutoring for Language Learning: A Case Study of a Virtual Campus Environment with OpenAI GPT Integration with Unity 3D**|Adithya TG et.al.|[2411.12619v1](http://arxiv.org/abs/2411.12619v1)|null|
|**2024-11-19**|**STREAM: A Universal State-Space Model for Sparse Geometric Data**|Mark Schöne et.al.|[2411.12603v1](http://arxiv.org/abs/2411.12603v1)|null|
|**2024-11-19**|**Provable unlearning in topic modeling and downstream tasks**|Stanley Wei et.al.|[2411.12600v1](http://arxiv.org/abs/2411.12600v1)|null|
|**2024-11-19**|**Whisper Finetuning on Nepali Language**|Sanjay Rijal et.al.|[2411.12587v1](http://arxiv.org/abs/2411.12587v1)|null|
|**2024-11-19**|**Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models**|Laura Ruis et.al.|[2411.12580v1](http://arxiv.org/abs/2411.12580v1)|[link](https://github.com/pomonam/kronfluence)|
|**2024-11-19**|**Large Language Models for Combinatorial Optimization of Design Structure Matrix**|Shuo Jiang et.al.|[2411.12571v1](http://arxiv.org/abs/2411.12571v1)|null|
|**2024-11-19**|**Topological Symmetry Enhanced Graph Convolution for Skeleton-Based Action Recognition**|Zeyu Liang et.al.|[2411.12560v1](http://arxiv.org/abs/2411.12560v1)|null|
|**2024-11-19**|**Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**|Ismail Nejjar et.al.|[2411.12558v1](http://arxiv.org/abs/2411.12558v1)|[link](https://github.com/ismailnejjar/RRDA)|
|**2024-11-19**|**Predicting Customer Satisfaction by Replicating the Survey Response Distribution**|Etienne Manderscheid et.al.|[2411.12539v1](http://arxiv.org/abs/2411.12539v1)|null|
|**2024-11-19**|**Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues**|Riccardo Grazzi et.al.|[2411.12537v1](http://arxiv.org/abs/2411.12537v1)|null|
|**2024-11-19**|**Rethinking Top Probability from Multi-view for Distracted Driver Behaviour Localization**|Quang Vinh Nguyen et.al.|[2411.12525v1](http://arxiv.org/abs/2411.12525v1)|null|
|**2024-11-19**|**Transformer Neural Processes -- Kernel Regression**|Daniel Jenson et.al.|[2411.12502v1](http://arxiv.org/abs/2411.12502v1)|null|
|**2024-11-19**|**Enhancing Reasoning Capabilities of LLMs via Principled Synthetic Logic Corpus**|Terufumi Morishita et.al.|[2411.12498v1](http://arxiv.org/abs/2411.12498v1)|[link](https://github.com/hitachi-nlp/fld)|
|**2024-11-19**|**Bias Free Sentiment Analysis**|Hubert Plisiecki et.al.|[2411.12493v1](http://arxiv.org/abs/2411.12493v1)|null|
|**2024-11-19**|**Regular-pattern-sensitive CRFs for Distant Label Interactions**|Sean Papay et.al.|[2411.12484v1](http://arxiv.org/abs/2411.12484v1)|null|
|**2024-11-19**|**Comparing Prior and Learned Time Representations in Transformer Models of Timeseries**|Natalia Koliou et.al.|[2411.12476v1](http://arxiv.org/abs/2411.12476v1)|null|
|**2024-11-19**|**NMT-Obfuscator Attack: Ignore a sentence in translation with only one word**|Sahar Sadrizadeh et.al.|[2411.12473v1](http://arxiv.org/abs/2411.12473v1)|[link](https://github.com/sssadrizadeh/NMT_Obfuscator)|
|**2024-11-19**|**AI Flow at the Network Edge**|Jiawei Shao et.al.|[2411.12469v1](http://arxiv.org/abs/2411.12469v1)|null|
|**2024-11-19**|**Guide-to-Explain for Controllable Summarization**|Sangwon Ryu et.al.|[2411.12460v1](http://arxiv.org/abs/2411.12460v1)|null|
|**2024-11-19**|**\textsc{Neon}: News Entity-Interaction Extraction for Enhanced Question Answering**|Sneha Singhania et.al.|[2411.12449v1](http://arxiv.org/abs/2411.12449v1)|null|
|**2024-11-19**|**Evaluating the Prompt Steerability of Large Language Models**|Erik Miehling et.al.|[2411.12405v1](http://arxiv.org/abs/2411.12405v1)|[link](https://github.com/ibm/prompt-steering)|
|**2024-11-19**|**Do LLMs Understand Ambiguity in Text? A Case Study in Open-world Question Answering**|Aryan Keluskar et.al.|[2411.12395v1](http://arxiv.org/abs/2411.12395v1)|null|
|**2024-11-19**|**RedPajama: an Open Dataset for Training Large Language Models**|Maurice Weber et.al.|[2411.12372v1](http://arxiv.org/abs/2411.12372v1)|[link](https://github.com/togethercomputer/redpajama-data)|
|**2024-11-19**|**A Layered Architecture for Developing and Enhancing Capabilities in Large Language Model-based Software Systems**|Dawen Zhang et.al.|[2411.12357v1](http://arxiv.org/abs/2411.12357v1)|null|
|**2024-11-19**|**DiM: $f$-Divergence Minimization Guided Sharpness-Aware Optimization for Semi-supervised Medical Image Segmentation**|Bingli Wang et.al.|[2411.12350v1](http://arxiv.org/abs/2411.12350v1)|null|
|**2024-11-19**|**CLIP Unreasonable Potential in Single-Shot Face Recognition**|Nhan T. Luu et.al.|[2411.12319v1](http://arxiv.org/abs/2411.12319v1)|null|
|**2024-11-19**|**Balancing Accuracy and Efficiency in Multi-Turn Intent Classification for LLM-Powered Dialog Systems in Production**|Junhua Liu et.al.|[2411.12307v1](http://arxiv.org/abs/2411.12307v1)|null|
|**2024-11-19**|**SSEditor: Controllable Mask-to-Scene Generation with Diffusion Model**|Haowen Zheng et.al.|[2411.12290v1](http://arxiv.org/abs/2411.12290v1)|null|
|**2024-11-19**|**CUE-M: Contextual Understanding and Enhanced Search with Multimodal Large Language Model**|Dongyoung Go et.al.|[2411.12287v1](http://arxiv.org/abs/2411.12287v1)|null|
|**2024-11-19**|**Building Trust: Foundations of Security, Safety and Transparency in AI**|Huzaifa Sidhpurwala et.al.|[2411.12275v1](http://arxiv.org/abs/2411.12275v1)|null|
|**2024-11-19**|**Low-resource Machine Translation: what for? who for? An observational study on a dedicated Tetun language translation service**|Raphael Merx et.al.|[2411.12262v1](http://arxiv.org/abs/2411.12262v1)|null|
|**2024-11-19**|**Restructuring Tractable Probabilistic Circuits**|Honghua Zhang et.al.|[2411.12256v1](http://arxiv.org/abs/2411.12256v1)|null|
|**2024-11-19**|**Error-Feedback Model for Output Correction in Bilateral Control-Based Imitation Learning**|Hiroshi Sato et.al.|[2411.12255v1](http://arxiv.org/abs/2411.12255v1)|null|
|**2024-11-19**|**Predicting User Intents and Musical Attributes from Music Discovery Conversations**|Daeyong Kwon et.al.|[2411.12254v1](http://arxiv.org/abs/2411.12254v1)|null|
|**2024-11-19**|**Efficient Training in Multi-Agent Reinforcement Learning: A Communication-Free Framework for the Box-Pushing Problem**|David Ge et.al.|[2411.12246v1](http://arxiv.org/abs/2411.12246v1)|null|
|**2024-11-19**|**Evaluating Tokenizer Performance of Large Language Models Across Official Indian Languages**|S. Tamang et.al.|[2411.12240v1](http://arxiv.org/abs/2411.12240v1)|null|
|**2024-11-19**|**BoolQuestions: Does Dense Retrieval Understand Boolean Logic in Language?**|Zongmeng Zhang et.al.|[2411.12235v1](http://arxiv.org/abs/2411.12235v1)|null|
|**2024-11-19**|**Contrast Similarity-Aware Dual-Pathway Mamba for Multivariate Time Series Node Classification**|Mingsen Du et.al.|[2411.12222v1](http://arxiv.org/abs/2411.12222v1)|[link](https://github.com/dumingsen/DPMamba)|
|**2024-11-19**|**DeTrigger: A Gradient-Centric Approach to Backdoor Attack Mitigation in Federated Learning**|Kichang Lee et.al.|[2411.12220v1](http://arxiv.org/abs/2411.12220v1)|null|
|**2024-11-19**|**CCIS-Diff: A Generative Model with Stable Diffusion Prior for Controlled Colonoscopy Image Synthesis**|Yifan Xie et.al.|[2411.12198v1](http://arxiv.org/abs/2411.12198v1)|null|
|**2024-11-19**|**Testability of Instrumental Variables in Additive Nonlinear, Non-Constant Effects Models**|Xichen Guo et.al.|[2411.12184v1](http://arxiv.org/abs/2411.12184v1)|null|
|**2024-11-19**|**Diffusion-Inspired Cold Start with Sufficient Prior in Computerized Adaptive Testing**|Haiping Ma et.al.|[2411.12182v1](http://arxiv.org/abs/2411.12182v1)|[link](https://github.com/bimk/intelligent-education)|
|**2024-11-19**|**Enhancing Low Dose Computed Tomography Images Using Consistency Training Techniques**|Mahmut S. Gokmen et.al.|[2411.12181v1](http://arxiv.org/abs/2411.12181v1)|null|
|**2024-11-19**|**Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**|Rahul Garg et.al.|[2411.12174v1](http://arxiv.org/abs/2411.12174v1)|null|
|**2024-11-19**|**UrbanDiT: A Foundation Model for Open-World Urban Spatio-Temporal Learning**|Yuan Yuan et.al.|[2411.12164v1](http://arxiv.org/abs/2411.12164v1)|[link](https://github.com/YuanYuan98/UrbanDiT)|
|**2024-11-19**|**A Combined Encoder and Transformer Approach for Coherent and High-Quality Text Generation**|Jiajing Chen et.al.|[2411.12157v1](http://arxiv.org/abs/2411.12157v1)|null|
|**2024-11-19**|**HNCSE: Advancing Sentence Embeddings via Hybrid Contrastive Learning with Hard Negatives**|Wenxiao Liu et.al.|[2411.12156v1](http://arxiv.org/abs/2411.12156v1)|null|
|**2024-11-19**|**HEIGHT: Heterogeneous Interaction Graph Transformer for Robot Navigation in Crowded and Constrained Environments**|Shuijing Liu et.al.|[2411.12150v1](http://arxiv.org/abs/2411.12150v1)|null|
|**2024-11-19**|**CoMeDi Shared Task: Models as Annotators in Lexical Semantics Disagreements**|Zhu Liu et.al.|[2411.12147v1](http://arxiv.org/abs/2411.12147v1)|null|
|**2024-11-19**|**Visualizing Loss Functions as Topological Landscape Profiles**|Caleb Geniesse et.al.|[2411.12136v1](http://arxiv.org/abs/2411.12136v1)|null|
|**2024-11-18**|**The Role of Accuracy and Validation Effectiveness in Conversational Business Analytics**|Adem Alparslan et.al.|[2411.12128v1](http://arxiv.org/abs/2411.12128v1)|null|
|**2024-11-18**|**Does Unlearning Truly Unlearn? A Black Box Evaluation of LLM Unlearning Methods**|Jai Doshi et.al.|[2411.12103v1](http://arxiv.org/abs/2411.12103v1)|[link](https://github.com/jaidoshi/knowledge-erasure)|
|**2024-11-18**|**Mitigating Gender Bias in Contextual Word Embeddings**|Navya Yarrabelly et.al.|[2411.12074v1](http://arxiv.org/abs/2411.12074v1)|null|
|**2024-11-18**|**Just Leaf It: Accelerating Diffusion Classifiers with Hierarchical Class Pruning**|Arundhati S. Shanbhag et.al.|[2411.12073v1](http://arxiv.org/abs/2411.12073v1)|[link](https://github.com/arus23/hierarchical_diffusion_classifier)|
|**2024-11-18**|**Zoomed In, Diffused Out: Towards Local Degradation-Aware Multi-Diffusion for Extreme Image Super-Resolution**|Brian B. Moser et.al.|[2411.12072v1](http://arxiv.org/abs/2411.12072v1)|[link](https://github.com/Brian-Moser/zido)|
|**2024-11-18**|**TSPRank: Bridging Pairwise and Listwise Methods with a Bilinear Travelling Salesman Model**|Weixian Waylon Li et.al.|[2411.12064v1](http://arxiv.org/abs/2411.12064v1)|[link](https://github.com/waylonli/tsprank-kdd2025)|
|**2024-11-18**|**Benchmarking pre-trained text embedding models in aligning built asset information**|Mehrzad Shahinmoghadam et.al.|[2411.12056v1](http://arxiv.org/abs/2411.12056v1)|[link](https://github.com/mehrzadshm/built-bench-paper)|
|**2024-11-18**|**Scaling Deep Learning Research with Kubernetes on the NRP Nautilus HyperCluster**|J. Alex Hurt et.al.|[2411.12038v1](http://arxiv.org/abs/2411.12038v1)|null|
|**2024-11-18**|**Regret-Free Reinforcement Learning for LTL Specifications**|Rupak Majumdar et.al.|[2411.12019v1](http://arxiv.org/abs/2411.12019v1)|null|
|**2024-11-18**|**ByteScience: Bridging Unstructured Scientific Literature and Structured Data with Auto Fine-tuned Large Language Model in Token Granularity**|Tong Xie et.al.|[2411.12000v1](http://arxiv.org/abs/2411.12000v1)|null|
|**2024-11-18**|**Understanding Chain-of-Thought in LLMs through Information Theory**|Jean-Francois Ton et.al.|[2411.11984v1](http://arxiv.org/abs/2411.11984v1)|null|
|**2024-11-18**|**Bi-Mamba: Towards Accurate 1-Bit State Space Models**|Shengkun Tang et.al.|[2411.11843v1](http://arxiv.org/abs/2411.11843v1)|null|
|**2024-11-18**|**Tackling prediction tasks in relational databases with LLMs**|Marek Wydmuch et.al.|[2411.11829v1](http://arxiv.org/abs/2411.11829v1)|null|
|**2024-11-18**|**LightFFDNets: Lightweight Convolutional Neural Networks for Rapid Facial Forgery Detection**|Günel Jabbarlı et.al.|[2411.11826v1](http://arxiv.org/abs/2411.11826v1)|null|
|**2024-11-18**|**Medical Video Generation for Disease Progression Simulation**|Xu Cao et.al.|[2411.11943v1](http://arxiv.org/abs/2411.11943v1)|null|
|**2024-11-18**|**Edge-Enhanced Dilated Residual Attention Network for Multimodal Medical Image Fusion**|Meng Zhou et.al.|[2411.11799v1](http://arxiv.org/abs/2411.11799v1)|[link](https://github.com/simonzhou86/en_dran)|
|**2024-11-18**|**Exploring adversarial robustness of JPEG AI: methodology, comparison and new methods**|Egor Kovalev et.al.|[2411.11795v1](http://arxiv.org/abs/2411.11795v1)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-18**|**CNMBert: A Model For Hanyu Pinyin Abbreviation to Character Conversion Task**|Zishuo Feng et.al.|[2411.11770v1](http://arxiv.org/abs/2411.11770v1)|null|
|**2024-11-18**|**The Power of Many: Multi-Agent Multimodal Models for Cultural Image Captioning**|Longju Bai et.al.|[2411.11758v1](http://arxiv.org/abs/2411.11758v1)|null|
|**2024-11-18**|**Variable Rate Neural Compression for Sparse Detector Data**|Yi Huang et.al.|[2411.11942v1](http://arxiv.org/abs/2411.11942v1)|[link](https://github.com/BNL-DAQ-LDRD/NeuralCompression_v3)|
|**2024-11-18**|**QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou**|Xinchen Luo et.al.|[2411.11739v1](http://arxiv.org/abs/2411.11739v1)|null|
|**2024-11-18**|**WoodYOLO: A Novel Object Detector for Wood Species Detection in Microscopic Images**|Lars Nieradzik et.al.|[2411.11738v1](http://arxiv.org/abs/2411.11738v1)|null|
|**2024-11-18**|**Moral Persuasion in Large Language Models: Evaluating Susceptibility and Ethical Alignment**|Allison Huang et.al.|[2411.11731v1](http://arxiv.org/abs/2411.11731v1)|[link](https://github.com/acyhuang/moral-persuasion)|
|**2024-11-18**|**Lifted Model Construction without Normalisation: A Vectorised Approach to Exploit Symmetries in Factor Graphs**|Malte Luttermann et.al.|[2411.11730v1](http://arxiv.org/abs/2411.11730v1)|[link](https://github.com/StatisticalRelationalAI/AlphaAdvancedColourPassing)|
|**2024-11-18**|**Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**|Mingchao Qi et.al.|[2411.11714v1](http://arxiv.org/abs/2411.11714v1)|[link](https://github.com/mingchaoqi/skill_transfer)|
|**2024-11-18**|**FedCoLLM: A Parameter-Efficient Federated Co-tuning Framework for Large and Small Language Models**|Tao Fan et.al.|[2411.11707v1](http://arxiv.org/abs/2411.11707v1)|null|
|**2024-11-18**|**MC-LLaVA: Multi-Concept Personalized Vision-Language Model**|Ruichuan An et.al.|[2411.11706v1](http://arxiv.org/abs/2411.11706v1)|null|
|**2024-11-18**|**Technical Report: Enhancing LLM Reasoning with Reward-guided Tree Search**|Jinhao Jiang et.al.|[2411.11694v1](http://arxiv.org/abs/2411.11694v1)|null|
|**2024-11-18**|**Value Imprint: A Technique for Auditing the Human Values Embedded in RLHF Datasets**|Ike Obi et.al.|[2411.11937v1](http://arxiv.org/abs/2411.11937v1)|null|

#### Abstracts
##### **ACING: Actor-Critic for Instruction Learning in Black-Box Large Language Models**
2411.12736v1 by Salma Kharrat, Fares Fourati, Marco Canini

The effectiveness of Large Language Models (LLMs) in solving tasks vastly
depends on the quality of the instructions, which often require fine-tuning
through extensive human effort. This highlights the need for automated
instruction optimization; however, this optimization is particularly
challenging when dealing with black-box LLMs, where model parameters and
gradients remain inaccessible. We propose ACING, a task-specific prompt
optimization approach framed as a stateless continuous-action Reinforcement
Learning (RL) problem, known as the continuum bandit setting. ACING leverages
an actor-critic-based method to optimize prompts, learning from
non-differentiable reward signals. We validate ACING by optimizing prompts for
ChatGPT on 30 instruction-based tasks. ACING consistently outperforms baseline
methods, achieving a median score improvement of 10 percentage points.
Furthermore, ACING not only recovers but also surpasses human-crafted expert
instructions, achieving up to a 39 percentage point improvement against human
benchmarks.

摘要：大型語言模型 (LLM) 在解決任務方面的有效性在很大程度上取決於說明的品質，這通常需要透過大量的人力進行微調。這突顯了自動化說明最佳化的需求；然而，在處理黑箱 LLM 時，這種最佳化特別具有挑戰性，因為模型參數和梯度無法取得。我們提出 ACING，一種以無狀態連續動作強化學習 (RL) 問題（稱為連續多臂賭博機設定）為架構的任務特定提示最佳化方法。ACING 利用基於動作-評論家的方法來最佳化提示，從不可微分的獎勵訊號中學習。我們透過在 30 個基於說明的任務中最佳化 ChatGPT 的提示來驗證 ACING。ACING 持續優於基線方法，達成中位數分數提升 10 個百分點。此外，ACING 不僅恢復，還超越了人類製作的專家說明，在人類基準上取得高達 39 個百分點的提升。

##### **Benchmarking Positional Encodings for GNNs and Graph Transformers**
2411.12732v1 by Florian Grötschla, Jiaqing Xie, Roger Wattenhofer

Recent advances in Graph Neural Networks (GNNs) and Graph Transformers (GTs)
have been driven by innovations in architectures and Positional Encodings
(PEs), which are critical for augmenting node features and capturing graph
topology. PEs are essential for GTs, where topological information would
otherwise be lost without message-passing. However, PEs are often tested
alongside novel architectures, making it difficult to isolate their effect on
established models. To address this, we present a comprehensive benchmark of
PEs in a unified framework that includes both message-passing GNNs and GTs. We
also establish theoretical connections between MPNNs and GTs and introduce a
sparsified GRIT attention mechanism to examine the influence of global
connectivity. Our findings demonstrate that previously untested combinations of
GNN architectures and PEs can outperform existing methods and offer a more
comprehensive picture of the state-of-the-art. To support future research and
experimentation in our framework, we make the code publicly available.

摘要：圖形神經網路 (GNN) 和圖形Transformer (GT) 的最新進展是由架構和位置編碼 (PE) 的創新所推動，這對於擴充節點特徵和擷取圖形拓撲至關重要。PE 對 GT 至關重要，因為在沒有訊息傳遞的情況下，拓撲資訊將會遺失。然而，PE 經常與新穎的架構一起測試，這使得難以分離它們對已建立模型的影響。為了解決這個問題，我們在一個統一的框架中展示了 PE 的全面基準測試，其中包括訊息傳遞 GNN 和 GT。我們還建立了 MPNN 和 GT 之間的理論關聯，並引入了一個稀疏化 GRIT 注意力機制來檢驗全局連接性的影響。我們的研究結果表明，先前未測試的 GNN 架構和 PE 組合可以優於現有方法，並提供更全面的最先進技術概況。為了支援我們框架中的未來研究和實驗，我們公開了程式碼。

##### **Information Theory of Meaningful Communication**
2411.12728v1 by Doron Sivan, Misha Tsodyks

In Shannon's seminal paper, entropy of printed English, treated as a
stationary stochastic process, was estimated to be roughly 1 bit per character.
However, considered as a means of communication, language differs considerably
from its printed form: (i) the units of information are not characters or even
words but clauses, i.e. shortest meaningful parts of speech; and (ii) what is
transmitted is principally the meaning of what is being said or written, while
the precise phrasing that was used to communicate the meaning is typically
ignored. In this study, we show that one can leverage recently developed large
language models to quantify information communicated in meaningful narratives
in terms of bits of meaning per clause.

摘要：在香農的開創性論文中，將印刷英語視為一個平穩隨機過程，其熵估計約為每字元 1 位元。
然而，語言作為一種溝通方式，與其印刷形式有很大的不同：(i) 資訊的單位不是字元，甚至不是單字，而是子句，也就是語句中最短的有意義的部分；(ii) 傳遞的主要是所說或所寫內容的意義，而用來傳達意義的精確措辭通常被忽略。在這項研究中，我們證明了可以利用最近開發的大型語言模型，以每子句意義位元為單位，量化在有意義的敘述中傳達的資訊。

##### **Scaling laws for nonlinear dynamical models of speech**
2411.12720v1 by Sam Kirkham

The addition of a nonlinear restoring force to dynamical models of the speech
gesture significantly improves the empirical accuracy of model predictions, but
nonlinearity introduces challenges in selecting appropriate parameters and
numerical stability, especially when modelling variation in empirical data. We
address this issue by introducing simple numerical methods for parameterization
of nonlinear task dynamic models. We first illustrate the problem and then
outline solutions in the form of power laws that scale nonlinear stiffness
terms. We apply the scaling laws to a cubic model and show how they facilitate
interpretable simulations of the nonlinear gestural dynamics underpinning
speech production.

摘要：在語音手勢的動態模型中加入非線性恢復力，可以顯著提升模型預測的經驗準確度，但非線性會在選擇適當參數和數值穩定性方面帶來挑戰，特別是在對經驗數據中的變化進行建模時。我們透過引入非線性任務動態模型參數化的簡單數值方法來解決這個問題。我們首先說明問題，然後概述以冪律形式縮放非線性剛度項的解決方案。我們將縮放律應用於三次模型，並展示它們如何促進對支撐語音產生的非線性手勢動態的可解釋模擬。

##### **Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation**
2411.12719v1 by Praveen Srinivasa Varadhan, Amogh Gulati, Ashwin Sankar, Srija Anand, Anirudh Gupta, Anirudh Mukherjee, Shiva Kumar Marepally, Ankur Bhatia, Saloni Jaju, Suvrat Bhooshan, Mitesh M. Khapra

Despite rapid advancements in TTS models, a consistent and robust human
evaluation framework is still lacking. For example, MOS tests fail to
differentiate between similar models, and CMOS's pairwise comparisons are
time-intensive. The MUSHRA test is a promising alternative for evaluating
multiple TTS systems simultaneously, but in this work we show that its reliance
on matching human reference speech unduly penalises the scores of modern TTS
systems that can exceed human speech quality. More specifically, we conduct a
comprehensive assessment of the MUSHRA test, focusing on its sensitivity to
factors such as rater variability, listener fatigue, and reference bias. Based
on our extensive evaluation involving 471 human listeners across Hindi and
Tamil we identify two primary shortcomings: (i) reference-matching bias, where
raters are unduly influenced by the human reference, and (ii) judgement
ambiguity, arising from a lack of clear fine-grained guidelines. To address
these issues, we propose two refined variants of the MUSHRA test. The first
variant enables fairer ratings for synthesized samples that surpass human
reference quality. The second variant reduces ambiguity, as indicated by the
relatively lower variance across raters. By combining these approaches, we
achieve both more reliable and more fine-grained assessments. We also release
MANGO, a massive dataset of 47,100 human ratings, the first-of-its-kind
collection for Indian languages, aiding in analyzing human preferences and
developing automatic metrics for evaluating TTS systems.

摘要：儘管 TTS 模型快速進步，但仍然缺乏一致且穩健的人類評估架構。例如，MOS 測試無法區分類似的模型，而 CMOS 的成對比較非常耗時。MUSHRA 測試是一種很有前途的替代方案，可以同時評估多個 TTS 系統，但我們在這項工作中表明，它依賴於匹配人類參考語音，過度懲罰了可以超越人類語音品質的現代 TTS 系統的分數。更具體地說，我們對 MUSHRA 測試進行了全面的評估，重點關注其對評分者變異性、聽眾疲勞和參考偏差等因素的敏感性。根據我們對 471 位印地語和泰米爾語人類聽眾進行的廣泛評估，我們發現了兩個主要的缺點：(i) 參考匹配偏差，評分者過度受到人類參考的影響，以及 (ii) 判斷模糊性，源於缺乏明確的細粒度準則。為了解決這些問題，我們提出了 MUSHRA 測試的兩個改進版本。第一個變體可以對超越人類參考品質的合成樣本進行更公平的評分。第二個變體減少了模糊性，如評分者之間相對較低的差異所表明的那樣。通過結合這些方法，我們實現了更可靠且更細粒度的評估。我們還發布了 MANGO，這是一個包含 47,100 個人類評分的龐大數據集，這是印度語言中首創的此類集合，有助於分析人類偏好並開發用於評估 TTS 系統的自動化指標。

##### **CATCH: Complementary Adaptive Token-level Contrastive Decoding to Mitigate Hallucinations in LVLMs**
2411.12713v1 by Zhehan Kan, Ce Zhang, Zihan Liao, Yapeng Tian, Wenming Yang, Junyuan Xiao, Xu Li, Dongmei Jiang, Yaowei Wang, Qingmin Liao

Large Vision-Language Model (LVLM) systems have demonstrated impressive
vision-language reasoning capabilities but suffer from pervasive and severe
hallucination issues, posing significant risks in critical domains such as
healthcare and autonomous systems. Despite previous efforts to mitigate
hallucinations, a persistent issue remains: visual defect from vision-language
misalignment, creating a bottleneck in visual processing capacity. To address
this challenge, we develop Complementary Adaptive Token-level Contrastive
Decoding to Mitigate Hallucinations in LVLMs (CATCH), based on the Information
Bottleneck theory. CATCH introduces Complementary Visual Decoupling (CVD) for
visual information separation, Non-Visual Screening (NVS) for hallucination
detection, and Adaptive Token-level Contrastive Decoding (ATCD) for
hallucination mitigation. CATCH addresses issues related to visual defects that
cause diminished fine-grained feature perception and cumulative hallucinations
in open-ended scenarios. It is applicable to various visual question-answering
tasks without requiring any specific data or prior knowledge, and generalizes
robustly to new tasks without additional training, opening new possibilities
for advancing LVLM in various challenging applications.

摘要：大型視覺語言模型 (LVLM) 系統已展現出令人印象深刻的視覺語言推理能力，但會遭受普遍且嚴重的幻覺問題，對醫療保健和自主系統等關鍵領域構成重大風險。儘管之前已做出減輕幻覺的努力，但仍存在一個持續的問題：視覺語言錯位造成的視覺缺陷，這會造成視覺處理能力的瓶頸。為了應對這項挑戰，我們根據資訊瓶頸理論，開發了用於減輕 LVLM 中幻覺的互補適應式代幣層級對比解碼 (CATCH)。CATCH 引入了互補視覺解耦 (CVD) 以進行視覺資訊分離、非視覺篩選 (NVS) 以進行幻覺偵測，以及適應式代幣層級對比解碼 (ATCD) 以進行幻覺減輕。CATCH 針對視覺缺陷的問題，這些問題會導致精細特徵感知力下降以及在開放式情境中累積幻覺。它適用於各種視覺問答任務，無需任何特定資料或先備知識，而且在沒有額外訓練的情況下，能穩健地概化到新任務，為在各種具挑戰性的應用中推進 LVLM 開啟新的可能性。

##### **Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular, Nervous System, and Digestive Disorders Using Advanced LLMs**
2411.12712v1 by Ahmed Akib Jawad Karim, Muhammad Zawad Mahmud, Samiha Islam, Aznur Azam

In this research, we explored the improvement in terms of multi-class disease
classification via pre-trained language models over Medical-Abstracts-TC-Corpus
that spans five medical conditions. We excluded non-cancer conditions and
examined four specific diseases. We assessed four LLMs, BioBERT, XLNet, and
BERT, as well as a novel base model (Last-BERT). BioBERT, which was pre-trained
on medical data, demonstrated superior performance in medical text
classification (97% accuracy). Surprisingly, XLNet followed closely (96%
accuracy), demonstrating its generalizability across domains even though it was
not pre-trained on medical data. LastBERT, a custom model based on the lighter
version of BERT, also proved competitive with 87.10% accuracy (just under
BERT's 89.33%). Our findings confirm the importance of specialized models such
as BioBERT and also support impressions around more general solutions like
XLNet and well-tuned transformer architectures with fewer parameters (in this
case, LastBERT) in medical domain tasks.

摘要：在這項研究中，我們探討了透過預先訓練的語言模型在跨越五種醫療疾病的 Medical-Abstracts-TC-Corpus 上，多類疾病分類的改進。我們排除了非癌症疾病，並檢查了四種特定疾病。我們評估了四個 LLM，BioBERT、XLNet 和 BERT，以及一個新的基礎模型 (Last-BERT)。在醫學文本分類中，經過醫學資料預先訓練的 BioBERT 表現出優異的效能（97% 準確度）。令人驚訝的是，XLNet 緊隨其後（96% 準確度），展示了它在不同領域的概括能力，即使它不是在醫學資料上預先訓練的。LastBERT 是一個基於較輕版本的 BERT 的自訂模型，也證明了競爭力，準確度為 87.10%（僅低於 BERT 的 89.33%）。我們的發現證實了 BioBERT 等專用模型的重要性，也支持了對更通用的解決方案的印象，例如 XLNet 和在醫學領域任務中具有較少參數的微調Transformer架構（在本例中為 LastBERT）。

##### **Strengthening Fake News Detection: Leveraging SVM and Sophisticated Text Vectorization Techniques. Defying BERT?**
2411.12703v1 by Ahmed Akib Jawad Karim, Kazi Hafiz Md Asad, Aznur Azam

The rapid spread of misinformation, particularly through online platforms,
underscores the urgent need for reliable detection systems. This study explores
the utilization of machine learning and natural language processing,
specifically Support Vector Machines (SVM) and BERT, to detect news that are
fake. We employ three distinct text vectorization methods for SVM: Term
Frequency Inverse Document Frequency (TF-IDF), Word2Vec, and Bag of Words (BoW)
evaluating their effectiveness in distinguishing between genuine and fake news.
Additionally, we compare these methods against the transformer large language
model, BERT. Our comprehensive approach includes detailed preprocessing steps,
rigorous model implementation, and thorough evaluation to determine the most
effective techniques. The results demonstrate that while BERT achieves superior
accuracy with 99.98% and an F1-score of 0.9998, the SVM model with a linear
kernel and BoW vectorization also performs exceptionally well, achieving 99.81%
accuracy and an F1-score of 0.9980. These findings highlight that, despite
BERT's superior performance, SVM models with BoW and TF-IDF vectorization
methods come remarkably close, offering highly competitive performance with the
advantage of lower computational requirements.

摘要：隨著錯誤訊息快速散播，特別是透過線上平台，這凸顯了可靠偵測系統的迫切需求。本研究探討利用機器學習和自然語言處理，特別是支援向量機 (SVM) 和 BERT，來偵測假新聞。我們採用三種不同的文字向量化方法，用於 SVM：詞頻逆文件頻率 (TF-IDF)、Word2Vec 和詞袋 (BoW)，評估其在區分真實新聞和假新聞方面的有效性。此外，我們將這些方法與Transformer大型語言模型 BERT 進行比較。我們的綜合方法包括詳細的預處理步驟、嚴謹的模型實作和徹底的評估，以確定最有效的技術。結果表明，儘管 BERT 以 99.98% 的準確率和 0.9998 的 F1 分數取得了優異的準確度，但具有線性核心的 SVM 模型和 BoW 向量化也表現得非常好，準確率達到 99.81%，F1 分數為 0.9980。這些發現強調，儘管 BERT 具有優異的效能，但使用 BoW 和 TF-IDF 向量化方法的 SVM 模型表現得非常接近，在計算需求較低的情況下，提供了極具競爭力的效能。

##### **When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations**
2411.12701v1 by Huaizhi Ge, Yiming Li, Qifan Wang, Yongfeng Zhang, Ruixiang Tang

Large Language Models (LLMs) are vulnerable to backdoor attacks, where hidden
triggers can maliciously manipulate model behavior. While several backdoor
attack methods have been proposed, the mechanisms by which backdoor functions
operate in LLMs remain underexplored. In this paper, we move beyond attacking
LLMs and investigate backdoor functionality through the novel lens of natural
language explanations. Specifically, we leverage LLMs' generative capabilities
to produce human-understandable explanations for their decisions, allowing us
to compare explanations for clean and poisoned samples. We explore various
backdoor attacks and embed the backdoor into LLaMA models for multiple tasks.
Our experiments show that backdoored models produce higher-quality explanations
for clean data compared to poisoned data, while generating significantly more
consistent explanations for poisoned data than for clean data. We further
analyze the explanation generation process, revealing that at the token level,
the explanation token of poisoned samples only appears in the final few
transformer layers of the LLM. At the sentence level, attention dynamics
indicate that poisoned inputs shift attention from the input context when
generating the explanation. These findings deepen our understanding of backdoor
attack mechanisms in LLMs and offer a framework for detecting such
vulnerabilities through explainability techniques, contributing to the
development of more secure LLMs.

摘要：大型語言模型 (LLM) 容易受到後門攻擊，其中隱藏的觸發器可以惡意操縱模型行為。雖然已經提出了幾種後門攻擊方法，但後門功能在 LLM 中運作的機制仍未得到充分探討。在本文中，我們超越攻擊 LLM，並通過自然語言解釋的新穎視角來研究後門功能。具體來說，我們利用 LLM 的生成能力為其決策提供人類可以理解的解釋，讓我們能夠比較乾淨和中毒樣本的解釋。我們探索各種後門攻擊，並將後門嵌入到 LLaMA 模型中以執行多項任務。我們的實驗表明，與中毒數據相比，後門模型對乾淨數據產生的解釋品質更高，同時對中毒數據產生的解釋顯著更一致。我們進一步分析了解釋生成過程，發現就權杖層面而言，中毒樣本的解釋權杖只出現在 LLM 的最後幾個轉換層中。在句子層面，注意力動態表明，中毒輸入在生成解釋時會將注意力從輸入內容轉移。這些發現加深了我們對 LLM 中後門攻擊機制的理解，並提供了一個通過可解釋性技術來檢測此類漏洞的框架，有助於開發更安全的 LLM。

##### **Attribute Inference Attacks for Federated Regression Tasks**
2411.12697v1 by Francesco Diana, Othmane Marfoq, Chuan Xu, Giovanni Neglia, Frédéric Giroire, Eoin Thomas

Federated Learning (FL) enables multiple clients, such as mobile phones and
IoT devices, to collaboratively train a global machine learning model while
keeping their data localized. However, recent studies have revealed that the
training phase of FL is vulnerable to reconstruction attacks, such as attribute
inference attacks (AIA), where adversaries exploit exchanged messages and
auxiliary public information to uncover sensitive attributes of targeted
clients. While these attacks have been extensively studied in the context of
classification tasks, their impact on regression tasks remains largely
unexplored. In this paper, we address this gap by proposing novel model-based
AIAs specifically designed for regression tasks in FL environments. Our
approach considers scenarios where adversaries can either eavesdrop on
exchanged messages or directly interfere with the training process. We
benchmark our proposed attacks against state-of-the-art methods using
real-world datasets. The results demonstrate a significant increase in
reconstruction accuracy, particularly in heterogeneous client datasets, a
common scenario in FL. The efficacy of our model-based AIAs makes them better
candidates for empirically quantifying privacy leakage for federated regression
tasks.

摘要：聯邦學習 (FL) 能讓多個用戶端，例如行動電話和 IoT 裝置，在保持其資料在地化的同時，合作訓練一個全球機器學習模型。然而，最近的研究顯示，FL 的訓練階段容易受到重建攻擊，例如屬性推論攻擊 (AIA)，其中對手利用交換的訊息和輔助公開資訊，揭露目標用戶端的敏感屬性。雖然這些攻擊在分類任務的背景下已廣泛研究，但其對迴歸任務的影響仍未廣泛探討。在本文中，我們透過提出專門針對 FL 環境中的迴歸任務設計的新穎基於模型的 AIA，來解決這個差距。我們的做法考慮了對手可以竊聽交換訊息或直接干擾訓練過程的場景。我們使用真實世界的資料集，針對現有方法評量我們提出的攻擊。結果顯示重建精準度大幅提升，特別是在異質用戶端資料集，這是 FL 中常見的場景。我們的基於模型的 AIA 的功效，讓它們成為經驗量化聯邦迴歸任務中隱私外洩的更佳候選者。

##### **AdaCM$^2$: On Understanding Extremely Long-Term Video with Adaptive Cross-Modality Memory Reduction**
2411.12593v1 by Yuanbin Man, Ying Huang, Chengming Zhang, Bingzhe Li, Wei Niu, Miao Yin

The advancements in large language models (LLMs) have propelled the
improvement of video understanding tasks by incorporating LLMs with visual
models. However, most existing LLM-based models (e.g., VideoLLaMA, VideoChat)
are constrained to processing short-duration videos. Recent attempts to
understand long-term videos by extracting and compressing visual features into
a fixed memory size. Nevertheless, those methods leverage only visual modality
to merge video tokens and overlook the correlation between visual and textual
queries, leading to difficulties in effectively handling complex
question-answering tasks. To address the challenges of long videos and complex
prompts, we propose AdaCM$^2$, which, for the first time, introduces an
adaptive cross-modality memory reduction approach to video-text alignment in an
auto-regressive manner on video streams. Our extensive experiments on various
video understanding tasks, such as video captioning, video question answering,
and video classification, demonstrate that AdaCM$^2$ achieves state-of-the-art
performance across multiple datasets while significantly reducing memory usage.
Notably, it achieves a 4.5% improvement across multiple tasks in the LVU
dataset with a GPU memory consumption reduction of up to 65%.

摘要：大型語言模型 (LLM) 的進步推進了影片理解任務的改進，方法是將 LLM 與視覺模型結合。然而，大多數現有的基於 LLM 的模型（例如 VideoLLaMA、VideoChat）都受到處理短時影片的限制。最近嘗試透過提取和壓縮視覺特徵到固定記憶體大小來理解長期影片。儘管如此，這些方法僅利用視覺模式來合併影片代幣，並忽略視覺和文字查詢之間的關聯性，導致難以有效處理複雜的問答任務。為了應對長影片和複雜提示的挑戰，我們提出 AdaCM$^2$，它首次在影片串流中以自迴歸的方式引入了適應性跨模式記憶體減少方法，用於影片與文字對齊。我們在各種影片理解任務（例如影片字幕、影片問答和影片分類）上的廣泛實驗表明，AdaCM$^2$ 在多個資料集上達到了最先進的效能，同時大幅減少了記憶體使用量。值得注意的是，它在 LVU 資料集中的多項任務中取得了 4.5% 的進步，同時將 GPU 記憶體消耗減少了 65%。

##### **Enhanced Sign Language Translation between American Sign Language (ASL) and Indian Sign Language (ISL) Using LLMs**
2411.12685v1 by Malay Kumar, S. Sarvajit Visagan, Tanish Sarang Mahajan, Anisha Natarajan

We have come up with a research that hopes to provide a bridge between the
users of American Sign Language and the users of spoken language and Indian
Sign Language (ISL). The research enabled us to create a novel framework that
we have developed for Learner Systems. Leveraging art of Large models to create
key features including: - Real-time translation between these two sign
languages in an efficient manner. Making LLM's capability available for
seamless translations to ISL. Here is the full study showing its implementation
in this paper. The core of the system is a sophisticated pipeline that begins
with reclassification and recognition of ASL gestures based on a strong Random
Forest Classifier. By recognizing the ASL, it is translated into text which can
be more easily processed. Highly evolved natural language NLP (Natural Language
Processing) techniques come in handy as they play a role in our LLM integration
where you then use LLMs to be able to convert the ASL text to ISL which
provides you with the intent of sentence or phrase. The final step is to
synthesize the translated text back into ISL gestures, creating an end-to-end
translation experience using RIFE-Net. This framework is tasked with key
challenges such as automatically dealing with gesture variability and
overcoming the linguistic differences between ASL and ISL. By automating the
translation process, we hope to vastly improve accessibility for sign language
users. No longer will the communication gap between ASL and ISL create
barriers; this totally cool innovation aims to bring our communities closer
together. And we believe, with full confidence in our framework, that we're
able to apply the same principles across a wide variety of sign language
dialects.

摘要：我們提出了一項研究，希望為美國手語使用者和口語使用者以及印度手語 (ISL) 使用者之間建立一座橋樑。該研究使我們能夠為學習者系統開發一個創新的框架。利用大型模型的藝術來建立關鍵功能，包括：- 在這兩種手語之間以有效的方式進行實時翻譯。讓 LLM 的能力可以無縫翻譯成 ISL。以下是顯示其在本文中實作的完整研究。該系統的核心是一個複雜的管道，它從基於強隨機森林分類器的 ASL 手勢重新分類和識別開始。通過識別 ASL，它被翻譯成可以更輕鬆處理的文字。高度發展的自然語言 NLP（自然語言處理）技術派上用場，因為它們在我們的 LLM 整合中發揮作用，在那裡您使用 LLM 將 ASL 文字轉換為 ISL，從而為您提供句子或短語的意圖。最後一步是將翻譯後的文字合成回 ISL 手勢，使用 RIFE-Net 創建端到端的翻譯體驗。此框架負責處理關鍵挑戰，例如自動處理手勢變異性並克服 ASL 和 ISL 之間的語言差異。通過自動化翻譯過程，我們希望大幅改善手語使用者的可及性。ASL 和 ISL 之間的溝通鴻溝不再會造成障礙；這項非常酷的創新旨在讓我們的社群更緊密地結合在一起。我們相信，對我們的框架充滿信心，我們能夠將相同的原則應用於各種手語方言。

##### **AI Guided Early Screening of Cervical Cancer**
2411.12681v1 by Dharanidharan S I, Suhitha Renuka S V, Ajishi Singh, Sheena Christabel Pravin

In order to support the creation of reliable machine learning models for
anomaly detection, this project focuses on preprocessing, enhancing, and
organizing a medical imaging dataset. There are two classifications in the
dataset: normal and abnormal, along with extra noise fluctuations. In order to
improve the photographs' quality, undesirable artifacts, including visible
medical equipment at the edges, were eliminated using central cropping.
Adjusting the brightness and contrast was one of the additional preprocessing
processes. Normalization was then performed to normalize the data. To make
classification jobs easier, the dataset was methodically handled by combining
several image subsets into two primary categories: normal and pathological. To
provide a strong training set that adapts well to real-world situations,
sophisticated picture preprocessing techniques were used, such as contrast
enhancement and real-time augmentation (including rotations, zooms, and
brightness modifications). To guarantee efficient model evaluation, the data
was subsequently divided into training and testing subsets. In order to create
precise and effective machine learning models for medical anomaly detection,
high-quality input data is ensured via this thorough approach. Because of the
project pipeline's flexible and scalable design, it can be easily integrated
with bigger clinical decision-support systems.

摘要：<paragraph>為了支持建立用於異常偵測的可靠機器學習模型，此專案專注於預處理、增強和組織醫學影像資料集。資料集中有兩個分類：正常和異常，以及額外的雜訊波動。為了提高照片的品質，包括邊緣可見的醫療設備在內的不可取的人工製品已使用中央裁切予以消除。調整亮度和對比度是額外預處理程序之一。然後執行正規化以正規化資料。為了使分類工作更輕鬆，資料集透過將多個影像子集組合成兩個主要類別（正常和病理）來有條理地處理。為了提供一個能良好適應真實世界情況的強大訓練集，使用了先進的圖片預處理技術，例如對比增強和即時擴充（包括旋轉、縮放和亮度修改）。為了保證有效的模型評估，資料隨後被分為訓練和測試子集。為了建立用於醫學異常偵測的精確且有效的機器學習模型，透過此徹底的方法確保了高品質的輸入資料。由於專案管線的靈活且可擴充的設計，它可以輕鬆地整合到更大的臨床決策支援系統中。</paragraph>

##### **Deep Learning-Driven Heat Map Analysis for Evaluating thickness of Wounded Skin Layers**
2411.12678v1 by Devakumar GR, JB Kaarthikeyan, Dominic Immanuel T, Sheena Christabel Pravin

Understanding the appropriate skin layer thickness in wounded sites is an
important tool to move forward on wound healing practices and treatment
protocols. Methods to measure depth often are invasive and less specific. This
paper introduces a novel method that is non-invasive with deep learning
techniques using classifying of skin layers that helps in measurement of wound
depth through heatmap analysis. A set of approximately 200 labeled images of
skin allows five classes to be distinguished: scars, wounds, and healthy skin,
among others. Each image has annotated key layers, namely the stratum cornetum,
the epidermis, and the dermis, in the software Roboflow. In the preliminary
stage, the Heatmap generator VGG16 was used to enhance the visibility of tissue
layers, based upon which their annotated images were used to train ResNet18
with early stopping techniques. It ended up at a very high accuracy rate of
97.67%. To do this, the comparison of the models ResNet18, VGG16, DenseNet121,
and EfficientNet has been done where both EfficientNet and ResNet18 have
attained accuracy rates of almost 95.35%. For further hyperparameter tuning,
EfficientNet and ResNet18 were trained at six different learning rates to
determine the best model configuration. It has been noted that the accuracy has
huge variations with different learning rates. In the case of EfficientNet, the
maximum achievable accuracy was 95.35% at the rate of 0.0001. The same was true
for ResNet18, which also attained its peak value of 95.35% at the same rate.
These facts indicate that the model can be applied and utilized in actual-time,
non-invasive wound assessment, which holds a great promise to improve clinical
diagnosis and treatment planning.

摘要：了解傷口部位適當的皮膚層厚度，是推動傷口癒合實務和治療方案的重要工具。測量深度的方法通常具有侵入性且不夠具體。本文介紹一種非侵入性的新方法，使用深度學習技術對皮膚層進行分類，有助於透過熱圖分析測量傷口深度。一組約 200 張標記的皮膚影像，可區分為五類：疤痕、傷口和健康皮膚等。每張影像在 Roboflow 軟體中都標註了關鍵層，即角質層、表皮和真皮。在初步階段，使用熱圖產生器 VGG16 來增強組織層的可見度，根據其標註的影像用於訓練 ResNet18，並採用早期停止技術。最終達到非常高的準確率 97.67%。為此，對 ResNet18、VGG16、DenseNet121 和 EfficientNet 進行了模型比較，其中 EfficientNet 和 ResNet18 都達到了接近 95.35% 的準確率。為了進一步調整超參數，以六種不同的學習率訓練 EfficientNet 和 ResNet18，以確定最佳模型配置。已注意到準確率會隨著不同的學習率而有很大的變化。在 EfficientNet 的情況下，在 0.0001 的速率下，可達到的最大準確率為 95.35%。ResNet18 也是如此，在相同的速率下也達到了 95.35% 的峰值。這些事實表明，該模型可以應用於實際時間的非侵入性傷口評估中，這對改善臨床診斷和治療計畫具有很大的前景。

##### **Neurosymbolic Graph Enrichment for Grounded World Models**
2411.12671v1 by Stefano De Giorgis, Aldo Gangemi, Alessandro Russo

The development of artificial intelligence systems capable of understanding
and reasoning about complex real-world scenarios is a significant challenge. In
this work we present a novel approach to enhance and exploit LLM reactive
capability to address complex problems and interpret deeply contextual
real-world meaning. We introduce a method and a tool for creating a multimodal,
knowledge-augmented formal representation of meaning that combines the
strengths of large language models with structured semantic representations.
Our method begins with an image input, utilizing state-of-the-art large
language models to generate a natural language description. This description is
then transformed into an Abstract Meaning Representation (AMR) graph, which is
formalized and enriched with logical design patterns, and layered semantics
derived from linguistic and factual knowledge bases. The resulting graph is
then fed back into the LLM to be extended with implicit knowledge activated by
complex heuristic learning, including semantic implicatures, moral values,
embodied cognition, and metaphorical representations. By bridging the gap
between unstructured language models and formal semantic structures, our method
opens new avenues for tackling intricate problems in natural language
understanding and reasoning.

摘要：人工智能系統的發展能夠理解並推理複雜的真實世界場景是一個重大的挑戰。在這項工作中，我們提出了一種新穎的方法來增強和利用 LLM 反應能力，以解決複雜的問題並解釋深層的語境真實世界意義。我們介紹了一種方法和工具，用於建立多模態、知識增強的意義形式化表示，結合了大型語言模型與結構化語義表示的優點。我們的模型從影像輸入開始，利用最先進的大型語言模型來產生自然語言描述。然後將此描述轉換為抽象意義表示 (AMR) 圖形，並使用邏輯設計模式進行形式化和豐富，以及從語言和事實知識庫中衍生的分層語義。然後將結果圖形回饋到 LLM，以擴充 LLM 中由複雜的啟發式學習所啟用的內隱知識，包括語義蘊涵、道德價值、具身認知和隱喻表示。我們的模型透過彌合非結構化語言模型與形式語義結構之間的差距，為解決自然語言理解和推理中的複雜問題開闢了新的途徑。

##### **PoM: Efficient Image and Video Generation with the Polynomial Mixer**
2411.12663v1 by David Picard, Nicolas Dufour

Diffusion models based on Multi-Head Attention (MHA) have become ubiquitous
to generate high quality images and videos. However, encoding an image or a
video as a sequence of patches results in costly attention patterns, as the
requirements both in terms of memory and compute grow quadratically. To
alleviate this problem, we propose a drop-in replacement for MHA called the
Polynomial Mixer (PoM) that has the benefit of encoding the entire sequence
into an explicit state. PoM has a linear complexity with respect to the number
of tokens. This explicit state also allows us to generate frames in a
sequential fashion, minimizing memory and compute requirement, while still
being able to train in parallel. We show the Polynomial Mixer is a universal
sequence-to-sequence approximator, just like regular MHA. We adapt several
Diffusion Transformers (DiT) for generating images and videos with PoM
replacing MHA, and we obtain high quality samples while using less
computational resources. The code is available at
https://github.com/davidpicard/HoMM.

摘要：基於多頭注意力 (MHA) 的擴散模型已廣泛用於產生高品質的影像和影片。然而，將影像或影片編碼成一系列修補程式會導致昂貴的注意力模式，因為記憶體和運算需求會以二次方的速度增長。為了減輕這個問題，我們提出一個 MHA 的替代方案，稱為多項式混合器 (PoM)，它具有將整個序列編碼成明確狀態的優點。PoM 具有與 token 數量成線性的複雜度。這個明確的狀態也允許我們以順序的方式產生畫面，將記憶體和運算需求降到最低，同時仍然能夠並行訓練。我們證明了多項式混合器是一個通用的序列對序列逼近器，就像一般的 MHA 一樣。我們改編了幾個用於產生影像和影片的擴散Transformer (DiT)，並用 PoM 取代 MHA，我們在使用較少運算資源的同時獲得了高品質的樣本。程式碼可在 https://github.com/davidpicard/HoMM 取得。

##### **CodeXEmbed: A Generalist Embedding Model Family for Multiligual and Multi-task Code Retrieval**
2411.12644v1 by Ye Liu, Rui Meng, Shafiq Jot, Silvio Savarese, Caiming Xiong, Yingbo Zhou, Semih Yavuz

Despite the success of text retrieval in many NLP tasks, code retrieval
remains a largely underexplored area. Most text retrieval systems are tailored
for natural language queries, often neglecting the specific challenges of
retrieving code. This gap leaves existing models unable to effectively capture
the diversity of programming languages and tasks across different domains,
highlighting the need for more focused research in code retrieval. To address
this, we introduce CodeXEmbed, a family of large-scale code embedding models
ranging from 400M to 7B parameters. Our novel training pipeline unifies
multiple programming languages and transforms various code-related tasks into a
common retrieval framework, enhancing model generalizability and retrieval
performance. Our 7B model sets a new state-of-the-art (SOTA) in code retrieval,
outperforming the previous leading model, Voyage-Code, by over 20% on CoIR
benchmark. In addition to excelling in code retrieval, our models demonstrate
competitive performance on the widely adopted BeIR text retrieval benchmark,
offering versatility across domains. Experimental results demonstrate that
improving retrieval performance significantly enhances end-to-end
Retrieval-Augmented Generation (RAG) performance for code-related tasks.

摘要：儘管文本擷取在許多 NLP 任務中獲得成功，但程式碼擷取
在很大程度上仍是一個未被充分探索的領域。大多數文本擷取系統
都是針對自然語言查詢而設計，常常忽略擷取程式碼的特定挑戰。
這個差距使得現有的模型無法有效擷取不同領域中多樣化的程式語言和任務，
這突顯了在程式碼擷取中進行更專注研究的必要性。為了解決
這個問題，我們引入了 CodeXEmbed，這是一個大型程式碼嵌入模型系列，
其參數範圍從 400M 到 7B。我們的創新訓練管道統一了
多種程式語言，並將各種與程式碼相關的任務轉換成一個
通用的擷取架構，增強了模型的概括性和擷取
效能。我們的 7B 模型在程式碼擷取中樹立了新的技術領先地位 (SOTA)，
在 CoIR 基準上比先前的領先模型 Voyage-Code 高出 20% 以上。除了在程式碼擷取中表現出色之外，我們的模型在廣泛採用的 BeIR 文字擷取基準上也展現了
競爭力的效能，在各個領域中提供多功能性。實驗結果證明
改善擷取效能顯著增強了與程式碼相關任務的端對端
擷取增強產生 (RAG) 效能。

##### **DLBacktrace: A Model Agnostic Explainability for any Deep Learning Models**
2411.12643v1 by Vinay Kumar Sankarapu, Chintan Chitroda, Yashwardhan Rathore, Neeraj Kumar Singh, Pratinav Seth

The rapid advancement of artificial intelligence has led to increasingly
sophisticated deep learning models, which frequently operate as opaque 'black
boxes' with limited transparency in their decision-making processes. This lack
of interpretability presents considerable challenges, especially in high-stakes
applications where understanding the rationale behind a model's outputs is as
essential as the outputs themselves. This study addresses the pressing need for
interpretability in AI systems, emphasizing its role in fostering trust,
ensuring accountability, and promoting responsible deployment in
mission-critical fields. To address the interpretability challenge in deep
learning, we introduce DLBacktrace, an innovative technique developed by the
AryaXAI team to illuminate model decisions across a wide array of domains,
including simple Multi Layer Perceptron (MLPs), Convolutional Neural Networks
(CNNs), Large Language Models (LLMs), Computer Vision Models, and more.
  We provide a comprehensive overview of the DLBacktrace algorithm and present
benchmarking results, comparing its performance against established
interpretability methods, such as SHAP, LIME, GradCAM, Integrated Gradients,
SmoothGrad, and Attention Rollout, using diverse task-based metrics. The
proposed DLBacktrace technique is compatible with various model architectures
built in PyTorch and TensorFlow, supporting models like Llama 3.2, other NLP
architectures such as BERT and LSTMs, computer vision models like ResNet and
U-Net, as well as custom deep neural network (DNN) models for tabular data.
This flexibility underscores DLBacktrace's adaptability and effectiveness in
enhancing model transparency across a broad spectrum of applications. The
library is open-sourced and available at https://github.com/AryaXAI/DLBacktrace .

摘要：隨著人工智慧的快速進展，產生了越來越複雜的深度學習模型，這些模型通常作為不透明的「黑盒子」運作，在決策過程中透明度有限。這種可解釋性的缺乏帶來了相當大的挑戰，特別是在高風險應用中，了解模型輸出的背後原因與輸出本身一樣重要。本研究解決了 AI 系統中對於可解釋性的迫切需求，強調其在建立信任、確保問責制以及在任務關鍵領域促進負責任部署中的作用。為了應對深度學習中的可解釋性挑戰，我們引入了 DLBacktrace，這是一種由 AryaXAI 團隊開發的創新技術，用於闡明各種領域的模型決策，包括簡單的多層感知器 (MLP)、卷積神經網路 (CNN)、大型語言模型 (LLM)、電腦視覺模型等等。我們提供了 DLBacktrace 演算法的全面概述，並提出了基準測試結果，使用不同的基於任務的指標，將其效能與已建立的可解釋性方法（例如 SHAP、LIME、GradCAM、整合梯度、SmoothGrad 和注意力展開）進行比較。建議的 DLBacktrace 技術與在 PyTorch 和 TensorFlow 中建立的各種模型架構相容，支援 Llama 3.2 等模型、其他 NLP 架構（例如 BERT 和 LSTM）、電腦視覺模型（例如 ResNet 和 U-Net），以及用於表格資料的客製化深度神經網路 (DNN) 模型。這種靈活性突顯了 DLBacktrace 在廣泛應用中增強模型透明度的適應性和有效性。此程式庫是開源的，可在 https://github.com/AryaXAI/DLBacktrace 取得。

##### **Instant Policy: In-Context Imitation Learning via Graph Diffusion**
2411.12633v1 by Vitalis Vosylius, Edward Johns

Following the impressive capabilities of in-context learning with large
transformers, In-Context Imitation Learning (ICIL) is a promising opportunity
for robotics. We introduce Instant Policy, which learns new tasks instantly
(without further training) from just one or two demonstrations, achieving ICIL
through two key components. First, we introduce inductive biases through a
graph representation and model ICIL as a graph generation problem with a
learned diffusion process, enabling structured reasoning over demonstrations,
observations, and actions. Second, we show that such a model can be trained
using pseudo-demonstrations - arbitrary trajectories generated in simulation -
as a virtually infinite pool of training data. Simulated and real experiments
show that Instant Policy enables rapid learning of various everyday robot
tasks. We also show how it can serve as a foundation for cross-embodiment and
zero-shot transfer to language-defined tasks. Code and videos are available at
https://www.robot-learning.uk/instant-policy.

摘要：繼大型Transformer在情境學習中表現出令人印象深刻的能力後，情境模仿學習 (ICIL) 成為了機器人領域中一個有前途的機會。我們引入了即時策略，它僅從一或兩次示範中立即學習新任務（無需進一步訓練），並通過兩個關鍵組成部分實現 ICIL。首先，我們通過圖形表示和模型 ICIL 引入歸納偏差，並將其作為具有學習擴散過程的圖形生成問題，從而能夠對示範、觀察和動作進行結構化推理。其次，我們展示了這種模型可以使用偽示範進行訓練，而偽示範是模擬中產生的任意軌跡，可用作幾乎無限的訓練數據池。模擬和真實實驗表明，即時策略能夠快速學習各種日常機器人任務。我們還展示了它如何作為跨具身和零次傳輸到語言定義任務的基礎。代碼和影片可在 https://www.robot-learning.uk/instant-policy 取得。

##### **Estimating Dark Matter Halo Masses in Simulated Galaxy Clusters with Graph Neural Networks**
2411.12629v1 by Nikhil Garuda, John F. Wu, Dylan Nelson, Annalisa Pillepich

Galaxies grow and evolve in dark matter halos. Because dark matter is not
visible, galaxies' halo masses ($\rm{M}_{\rm{halo}}$) must be inferred
indirectly. We present a graph neural network (GNN) model for predicting
$\rm{M}_{\rm{halo}}$ from stellar mass ($\rm{M}_{*}$) in simulated galaxy
clusters using data from the IllustrisTNG simulation suite. Unlike traditional
machine learning models like random forests, our GNN captures the
information-rich substructure of galaxy clusters by using spatial and kinematic
relationships between galaxy neighbour. A GNN model trained on the TNG-Cluster
dataset and independently tested on the TNG300 simulation achieves superior
predictive performance compared to other baseline models we tested. Future work
will extend this approach to different simulations and real observational
datasets to further validate the GNN model's ability to generalise.

摘要：星系在暗物質暈中成長和演化。由於暗物質不可見，星系的暈質量（$\rm{M}_{\rm{halo}}$）必須間接推斷。我們提出一個圖神經網路（GNN）模型，用於從模擬星系團中恆星質量（$\rm{M}_{*}$）預測$\rm{M}_{\rm{halo}}$，使用來自 IllustrisTNG 模擬套件的資料。與隨機森林等傳統機器學習模型不同，我們的 GNN 透過使用星系鄰居之間的空間和運動關係，擷取星系團的資訊豐富次結構。在 TNG-Cluster 資料集上訓練的 GNN 模型，並獨立在 TNG300 模擬上測試，與我們測試的其他基準模型相比，實現了卓越的預測效能。未來的研究將把這種方法擴展到不同的模擬和真實觀測資料集，以進一步驗證 GNN 模型的泛化能力。

##### **Leveraging Virtual Reality and AI Tutoring for Language Learning: A Case Study of a Virtual Campus Environment with OpenAI GPT Integration with Unity 3D**
2411.12619v1 by Adithya TG, Abhinavaram N, Gowri Srinivasa

This paper presents a new approach to multiple language learning, with Hindi
the language to be learnt in our case, by using the integration of virtual
reality environments and AI enabled tutoring systems using OpenAIs GPT api
calls. We have developed a scenario which has a virtual campus environment
using Unity which focuses on a detailed representation of our universitys
buildings 11th floor, where most of the cultural and technological activities
take place. Within this virtual environment that we have created, we have an AI
tutor powered by OpenAI's GPT model which was called using an api which moves
around with the user. This provided language learning support in Hindi, as GPT
is able to take care of language translation. Our approach mainly involves
utilising speech to text, text to text conversion and text to speech
capabilities to facilitate real time interaction between users and the AI tutor
in the presence of internet. This research demonstrates the use of combining VR
technology with AI tutoring for immersive language learning experiences and
provides interaction.

摘要：這篇論文提出多語言學習的新方法，以印地語為例，利用虛擬實境環境的整合和使用 OpenAI GPT API 呼叫的人工智慧輔導系統。我們開發了一個場景，其中使用 Unity 建立一個虛擬校園環境，重點在於詳細呈現我們大學 11 樓的建築，那裡舉辦了大部分的文化和技術活動。在我們建立的這個虛擬環境中，我們有一個由 OpenAI 的 GPT 模型提供動力的 AI 導師，它使用 API 呼叫，並與使用者一起移動。這提供了印地語的語言學習支援，因為 GPT 能夠處理語言翻譯。我們的方法主要包括利用語音轉文字、文字轉文字和文字轉語音的能力，以促進使用者和 AI 導師在網際網路環境中進行即時互動。這項研究展示了結合 VR 技術與 AI 輔導以提供沉浸式語言學習體驗和互動的用途。

##### **STREAM: A Universal State-Space Model for Sparse Geometric Data**
2411.12603v1 by Mark Schöne, Yash Bhisikar, Karan Bania, Khaleelulla Khan Nazeer, Christian Mayr, Anand Subramoney, David Kappel

Handling sparse and unstructured geometric data, such as point clouds or
event-based vision, is a pressing challenge in the field of machine vision.
Recently, sequence models such as Transformers and state-space models entered
the domain of geometric data. These methods require specialized preprocessing
to create a sequential view of a set of points. Furthermore, prior works
involving sequence models iterate geometric data with either uniform or learned
step sizes, implicitly relying on the model to infer the underlying geometric
structure. In this work, we propose to encode geometric structure explicitly
into the parameterization of a state-space model. State-space models are based
on linear dynamics governed by a one-dimensional variable such as time or a
spatial coordinate. We exploit this dynamic variable to inject relative
differences of coordinates into the step size of the state-space model. The
resulting geometric operation computes interactions between all pairs of N
points in O(N) steps. Our model deploys the Mamba selective state-space model
with a modified CUDA kernel to efficiently map sparse geometric data to modern
hardware. The resulting sequence model, which we call STREAM, achieves
competitive results on a range of benchmarks from point-cloud classification to
event-based vision and audio classification. STREAM demonstrates a powerful
inductive bias for sparse geometric data by improving the PointMamba baseline
when trained from scratch on the ModelNet40 and ScanObjectNN point cloud
analysis datasets. It further achieves, for the first time, 100% test accuracy
on all 11 classes of the DVS128 Gestures dataset.

摘要：<paragraph>處理稀疏且非結構化的幾何數據，例如點雲或事件驅動的視覺，是機器視覺領域中一項迫切的挑戰。
最近，序列模型（例如Transformer和狀態空間模型）進入了幾何數據領域。這些方法需要專門的預處理，以建立一組點的序列視圖。此外，涉及序列模型的先前工作使用均勻或學習的步長迭代幾何數據，隱含地依賴模型來推斷底層幾何結構。在這項工作中，我們建議將幾何結構明確編碼到狀態空間模型的參數化中。狀態空間模型基於由一維變量（例如時間或空間坐標）支配的線性動力學。我們利用這個動態變量將坐標的相對差異注入狀態空間模型的步長。產生的幾何運算計算了 N 個點的所有對之間的交互作用，步驟為 O(N)。我們的模型部署了 Mamba 選擇性狀態空間模型，並使用修改後的 CUDA 核心將稀疏幾何數據有效地映射到現代硬體。我們稱之為 STREAM 的產生的序列模型，在從點雲分類到基於事件的視覺和音訊分類的一系列基準測試中取得了有競爭力的結果。STREAM 通過改進從 ModelNet40 和 ScanObjectNN 點雲分析數據集從頭開始訓練的 PointMamba 基線，展示了對稀疏幾何數據的強大歸納偏見。此外，它首次在 DVS128 手勢數據集的所有 11 個類別上實現了 100% 的測試準確率。</paragraph>

##### **Provable unlearning in topic modeling and downstream tasks**
2411.12600v1 by Stanley Wei, Sadhika Malladi, Sanjeev Arora, Amartya Sanyal

Machine unlearning algorithms are increasingly important as legal concerns
arise around the provenance of training data, but verifying the success of
unlearning is often difficult. Provable guarantees for unlearning are often
limited to supervised learning settings. In this paper, we provide the first
theoretical guarantees for unlearning in the pre-training and fine-tuning
paradigm by studying topic models, simple bag-of-words language models that can
be adapted to solve downstream tasks like retrieval and classification. First,
we design a provably effective unlearning algorithm for topic models that
incurs a computational overhead independent of the size of the original
dataset. Our analysis additionally quantifies the deletion capacity of the
model -- i.e., the number of examples that can be unlearned without incurring a
significant cost in model performance. Finally, we formally extend our analyses
to account for adaptation to a given downstream task. In particular, we design
an efficient algorithm to perform unlearning after fine-tuning the topic model
via a linear head. Notably, we show that it is easier to unlearn pre-training
data from models that have been fine-tuned to a particular task, and one can
unlearn this data without modifying the base model.

摘要：机器遗忘算法越来越重要，因为法律问题围绕训练数据的出处而出现，但验证遗忘的成功通常很困难。遗忘的可证明保证通常仅限于监督学习设置。在本文中，我们通过研究主题模型（可以适应求解诸如检索和分类之类的下游任务的简单的词袋语言模型）提供了预训练和微调范式中遗忘的第一个理论保证。首先，我们为主题模型设计了一种可证明有效的遗忘算法，该算法产生的计算开销与原始数据集的大小无关。我们的分析还量化了模型的删除容量——即，可以在不产生模型性能显着成本的情况下遗忘的示例数量。最后，我们正式扩展了我们的分析，以解释对给定下游任务的适应。特别是，我们设计了一种有效的算法，用于通过线性头部微调主题模型后执行遗忘。值得注意的是，我们表明从已针对特定任务微调的模型中遗忘预训练数据更容易，并且可以在不修改基础模型的情况下遗忘此数据。

##### **Whisper Finetuning on Nepali Language**
2411.12587v1 by Sanjay Rijal, Shital Adhikari, Manish Dahal, Manish Awale, Vaghawan Ojha

Despite the growing advancements in Automatic Speech Recognition (ASR)
models, the development of robust models for underrepresented languages, such
as Nepali, remains a challenge. This research focuses on making an exhaustive
and generalized dataset followed by fine-tuning OpenAI's Whisper models of
different sizes to improve transcription (speech-to-text) accuracy for the
Nepali language. We leverage publicly available ASR datasets and self-recorded
custom datasets with a diverse range of accents, dialects, and speaking styles
further enriched through augmentation. Our experimental results demonstrate
that fine-tuning Whisper models on our curated custom dataset substantially
reduces the Word Error Rate (WER) across all model sizes attributed to larger
data variations in terms of speaker's age, gender, and sentiment, acoustic
environment, dialect, denser audio segments (15-30 seconds) that are more
compatible with Whisper's input, and manual curation of audios and
transcriptions. Notably, our approach outperforms Whisper's baseline models
trained on Fleur's dataset, achieving WER reductions of up to 36.2% on the
small and 23.8% on medium models. Furthermore, we show that data augmentation
plays a significant role in enhancing model robustness. Our approach underlines
the importance of dataset quality, variation, and augmentation in the
adaptation of state-of-the-art models to underrepresented languages for
developing accurate ASR systems.

摘要：儘管自動語音辨識（ASR）模型的進步日新月異，但針對尼泊爾語等代表性不足的語言開發強健的模型仍然是一項挑戰。本研究專注於製作一個詳盡且通用的資料集，並微調 OpenAI 的不同規模的 Whisper 模型，以提升尼泊爾語的轉錄（語音轉文字）準確度。我們利用公開的 ASR 資料集和自錄的客製化資料集，其中包含各種口音、方言和說話風格，並透過擴充進一步豐富資料。我們的實驗結果顯示，在我們策劃的客製化資料集上微調 Whisper 模型，大幅降低了所有模型規模的詞語錯誤率（WER），這歸因於說話者的年齡、性別和情緒、聲學環境、方言、與 Whisper 輸入更相容的較密集音訊片段（15-30 秒），以及人工策劃音訊和轉錄等資料變異較大。值得注意的是，我們的方法優於 Whisper 在 Fleur 的資料集上訓練的基準模型，在小型模型上實現了高達 36.2% 的 WER 降低，在中型模型上實現了 23.8% 的 WER 降低。此外，我們證明資料擴充在增強模型穩健性方面發揮了重要作用。我們的做法強調了資料集品質、變異和擴充在將最先進的模型適應到代表性不足的語言以開發準確的 ASR 系統中的重要性。

##### **Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models**
2411.12580v1 by Laura Ruis, Maximilian Mozes, Juhan Bae, Siddhartha Rao Kamalakara, Dwarak Talupuru, Acyr Locatelli, Robert Kirk, Tim Rocktäschel, Edward Grefenstette, Max Bartolo

The capabilities and limitations of Large Language Models have been sketched
out in great detail in recent years, providing an intriguing yet conflicting
picture. On the one hand, LLMs demonstrate a general ability to solve problems.
On the other hand, they show surprising reasoning gaps when compared to humans,
casting doubt on the robustness of their generalisation strategies. The sheer
volume of data used in the design of LLMs has precluded us from applying the
method traditionally used to measure generalisation: train-test set separation.
To overcome this, we study what kind of generalisation strategies LLMs employ
when performing reasoning tasks by investigating the pretraining data they rely
on. For two models of different sizes (7B and 35B) and 2.5B of their
pretraining tokens, we identify what documents influence the model outputs for
three simple mathematical reasoning tasks and contrast this to the data that
are influential for answering factual questions. We find that, while the models
rely on mostly distinct sets of data for each factual question, a document
often has a similar influence across different reasoning questions within the
same task, indicating the presence of procedural knowledge. We further find
that the answers to factual questions often show up in the most influential
data. However, for reasoning questions the answers usually do not show up as
highly influential, nor do the answers to the intermediate reasoning steps.
When we characterise the top ranked documents for the reasoning questions
qualitatively, we confirm that the influential documents often contain
procedural knowledge, like demonstrating how to obtain a solution using
formulae or code. Our findings indicate that the approach to reasoning the
models use is unlike retrieval, and more like a generalisable strategy that
synthesises procedural knowledge from documents doing a similar form of
reasoning.

摘要：近几年来，大型语言模型的能力和局限性已被详细地勾勒出来，提供了一幅既引人入胜又相互矛盾的图景。一方面，LLM 展示了解决问题的一般能力。另一方面，与人类相比，它们表现出令人惊讶的推理差距，让人对其泛化策略的稳健性产生怀疑。LLM 设计中使用的大量数据使我们无法应用传统上用于衡量泛化的方法：训练-测试集分离。为了克服这一问题，我们通过研究 LLM 依赖的预训练数据来研究 LLM 在执行推理任务时采用哪种泛化策略。对于两个不同大小（7B 和 35B）的模型及其 2.5B 预训练标记，我们确定了哪些文档影响了三个简单数学推理任务的模型输出，并将此与回答事实问题时有影响力的数据进行对比。我们发现，虽然模型对每个事实问题依赖于大部分不同的数据集，但一个文档通常在同一任务中的不同推理问题中具有相似的影响，表明存在程序知识。我们进一步发现，事实问题的答案通常出现在最有影响力的数据中。然而，对于推理问题，答案通常不会显示为高度有影响力，中间推理步骤的答案也不会显示为高度有影响力。当我们对推理问题的排名前列的文档进行定性表征时，我们确认有影响力的文档通常包含程序知识，例如演示如何使用公式或代码获得解决方案。我们的研究结果表明，模型使用的推理方法不同于检索，更像是一种可泛化的策略，它从执行类似推理形式的文档中综合程序知识。

##### **Large Language Models for Combinatorial Optimization of Design Structure Matrix**
2411.12571v1 by Shuo Jiang, Min Xie, Jianxi Luo

Combinatorial optimization (CO) is essential for improving efficiency and
performance in engineering applications. As complexity increases with larger
problem sizes and more intricate dependencies, identifying the optimal solution
become challenging. When it comes to real-world engineering problems,
algorithms based on pure mathematical reasoning are limited and incapable to
capture the contextual nuances necessary for optimization. This study explores
the potential of Large Language Models (LLMs) in solving engineering CO
problems by leveraging their reasoning power and contextual knowledge. We
propose a novel LLM-based framework that integrates network topology and domain
knowledge to optimize the sequencing of Design Structure Matrix (DSM)-a common
CO problem. Our experiments on various DSM cases demonstrate that the proposed
method achieves faster convergence and higher solution quality than benchmark
methods. Moreover, results show that incorporating contextual domain knowledge
significantly improves performance despite the choice of LLMs. These findings
highlight the potential of LLMs in tackling complex real-world CO problems by
combining semantic and mathematical reasoning. This approach paves the way for
a new paradigm in in real-world combinatorial optimization.

摘要：組合優化（CO）對於提升工程應用中的效率和效能至關重要。隨著問題規模變大、依賴關係更複雜，找出最佳解法變得更具挑戰性。當面對現實世界的工程問題時，基於純粹數學推論的演算法受到限制，無法捕捉最佳化所需的脈絡細微差別。本研究探討大型語言模型（LLM）在解決工程 CO 問題中的潛力，方法是利用其推理能力和脈絡知識。我們提出一個創新的基於 LLM 的架構，整合網路拓撲和領域知識，以最佳化設計結構矩陣（DSM）的順序，DSM 是一個常見的 CO 問題。我們在各種 DSM 案例上進行的實驗證明，所提出的方法比基準方法能更快速收斂並獲得更高的解法品質。此外，結果顯示，即使 LLM 的選擇不同，納入脈絡領域知識也能顯著提升效能。這些發現凸顯了 LLM 在結合語意和數學推理來解決複雜的現實世界 CO 問題中的潛力。此方法為現實世界的組合最佳化開闢了一個新的典範。

##### **Topological Symmetry Enhanced Graph Convolution for Skeleton-Based Action Recognition**
2411.12560v1 by Zeyu Liang, Hailun Xia, Naichuan Zheng, Huan Xu

Skeleton-based action recognition has achieved remarkable performance with
the development of graph convolutional networks (GCNs). However, most of these
methods tend to construct complex topology learning mechanisms while neglecting
the inherent symmetry of the human body. Additionally, the use of temporal
convolutions with certain fixed receptive fields limits their capacity to
effectively capture dependencies in time sequences. To address the issues, we
(1) propose a novel Topological Symmetry Enhanced Graph Convolution (TSE-GC) to
enable distinct topology learning across different channel partitions while
incorporating topological symmetry awareness and (2) construct a Multi-Branch
Deformable Temporal Convolution (MBDTC) for skeleton-based action recognition.
The proposed TSE-GC emphasizes the inherent symmetry of the human body while
enabling efficient learning of dynamic topologies. Meanwhile, the design of
MBDTC introduces the concept of deformable modeling, leading to more flexible
receptive fields and stronger modeling capacity of temporal dependencies.
Combining TSE-GC with MBDTC, our final model, TSE-GCN, achieves competitive
performance with fewer parameters compared with state-of-the-art methods on
three large datasets, NTU RGB+D, NTU RGB+D 120, and NW-UCLA. On the
cross-subject and cross-set evaluations of NTU RGB+D 120, the accuracies of our
model reach 90.0\% and 91.1\%, with 1.1M parameters and 1.38 GFLOPS for one
stream.

摘要：<paragraph>基於骨架的動作辨識在圖形卷積網路 (GCN) 的發展下已取得顯著的進展。然而，大多數這些方法傾向於建構複雜的拓撲學習機制，同時忽略人體固有的對稱性。此外，使用具有特定固定感受野的時間卷積限制了它們有效擷取時間序列中依賴關係的能力。為了解決這些問題，我們 (1) 提出一個新穎的拓撲對稱增強圖形卷積 (TSE-GC)，以在不同的通道分割中啟用不同的拓撲學習，同時納入拓撲對稱意識，以及 (2) 建構一個多分支可變形時間卷積 (MBDTC) 以進行基於骨架的動作辨識。所提出的 TSE-GC 強調人體的固有對稱性，同時支援動態拓撲的有效學習。同時，MBDTC 的設計引入了可變形建模的概念，導致更靈活的感受野和更強的時間依賴關係建模能力。將 TSE-GC 與 MBDTC 結合，我們的最終模型 TSE-GCN 在三個大型資料集 NTU RGB+D、NTU RGB+D 120 和 NW-UCLA 上以較少的參數實現了具有競爭力的效能。在 NTU RGB+D 120 的跨主體和跨集合評估中，我們的模型準確率達到 90.0% 和 91.1%，對於一個串流，有 1.1M 參數和 1.38 GFLOPS。</paragraph>

##### **Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework**
2411.12558v1 by Ismail Nejjar, Hao Dong, Olga Fink

Open-set Domain Adaptation (OSDA) aims to adapt a model from a labeled source
domain to an unlabeled target domain, where novel classes - also referred to as
target-private unknown classes - are present. Source-free Open-set Domain
Adaptation (SF-OSDA) methods address OSDA without accessing labeled source
data, making them particularly relevant under privacy constraints. However,
SF-OSDA presents significant challenges due to distribution shifts and the
introduction of novel classes. Existing SF-OSDA methods typically rely on
thresholding the prediction entropy of a sample to identify it as either a
known or unknown class but fail to explicitly learn discriminative features for
the target-private unknown classes. We propose Recall and Refine (RRDA), a
novel SF-OSDA framework designed to address these limitations by explicitly
learning features for target-private unknown classes. RRDA employs a two-step
process. First, we enhance the model's capacity to recognize unknown classes by
training a target classifier with an additional decision boundary, guided by
synthetic samples generated from target domain features. This enables the
classifier to effectively separate known and unknown classes. In the second
step, we adapt the entire model to the target domain, addressing both domain
shifts and improving generalization to unknown classes. Any off-the-shelf
source-free domain adaptation method (e.g., SHOT, AaD) can be seamlessly
integrated into our framework at this stage. Extensive experiments on three
benchmark datasets demonstrate that RRDA significantly outperforms existing
SF-OSDA and OSDA methods.

摘要：開放集域適應 (OSDA) 旨在將模型從標籤來源域適應到未標籤目標域，其中存在新類別（也稱為目標私有未知類別）。無來源開放集域適應 (SF-OSDA) 方法在無法存取標籤來源資料的情況下解決 OSDA，使其在隱私限制下特別相關。然而，由於分佈轉移和新類別的引入，SF-OSDA 呈現了重大挑戰。現有的 SF-OSDA 方法通常依賴於對樣本的預測熵進行閾值處理，以將其識別為已知或未知類別，但無法明確學習目標私有未知類別的區分特徵。我們提出召回和精煉 (RRDA)，這是一個新穎的 SF-OSDA 框架，旨在通過明確學習目標私有未知類別的特徵來解決這些限制。RRDA 採用兩步驟流程。首先，我們通過使用合成樣本（從目標域特徵產生）引導的附加決策邊界，訓練目標分類器，增強模型識別未知類別的能力。這使分類器能夠有效地區分已知和未知類別。在第二個步驟中，我們將整個模型適應到目標域，解決域轉移並改善對未知類別的泛化。任何現成的無來源域適應方法（例如，SHOT、AaD）都可以在此階段無縫整合到我們的框架中。在三個基準資料集上的大量實驗表明，RRDA 明顯優於現有的 SF-OSDA 和 OSDA 方法。

##### **Predicting Customer Satisfaction by Replicating the Survey Response Distribution**
2411.12539v1 by Etienne Manderscheid, Matthias Lee

For many call centers, customer satisfaction (CSAT) is a key performance
indicator (KPI). However, only a fraction of customers take the CSAT survey
after the call, leading to a biased and inaccurate average CSAT value, and
missed opportunities for coaching, follow-up, and rectification. Therefore,
call centers can benefit from a model predicting customer satisfaction on calls
where the customer did not complete the survey. Given that CSAT is a closely
monitored KPI, it is critical to minimize any bias in the average predicted
CSAT (pCSAT). In this paper, we introduce a method such that predicted CSAT
(pCSAT) scores accurately replicate the distribution of survey CSAT responses
for every call center with sufficient data in a live production environment.
The method can be applied to many multiclass classification problems to improve
the class balance and minimize its changes upon model updates.

摘要：對於許多客服中心來說，客戶滿意度 (CSAT) 是一項關鍵績效指標 (KPI)。然而，只有少數客戶在通話後會填寫 CSAT 調查，這會導致平均 CSAT 值有偏差且不準確，而且錯失了進行指導、後續追蹤和矯正的機會。因此，客服中心可以透過一個模型來預測客戶在未完成調查的通話中的滿意度，進而受益。由於 CSAT 是嚴格監控的 KPI，因此將預測平均 CSAT (pCSAT) 中的任何偏差降至最低至關重要。在本文中，我們將介紹一種方法，讓預測 CSAT (pCSAT) 分數準確複製在實際生產環境中擁有足夠資料的每個客服中心的調查 CSAT 回應分佈。此方法可應用於許多多類別分類問題，以改善類別平衡並在模型更新時將其變更降至最低。

##### **Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues**
2411.12537v1 by Riccardo Grazzi, Julien Siems, Jörg K. H. Franke, Arber Zela, Frank Hutter, Massimiliano Pontil

Linear Recurrent Neural Networks (LRNNs) such as Mamba, RWKV, GLA, mLSTM, and
DeltaNet have emerged as efficient alternatives to Transformers in large
language modeling, offering linear scaling with sequence length and improved
training efficiency. However, LRNNs struggle to perform state-tracking which
may impair performance in tasks such as code evaluation or tracking a chess
game. Even parity, the simplest state-tracking task, which non-linear RNNs like
LSTM handle effectively, cannot be solved by current LRNNs. Recently, Sarrof et
al. (2024) demonstrated that the failure of LRNNs like Mamba to solve parity
stems from restricting the value range of their diagonal state-transition
matrices to $[0, 1]$ and that incorporating negative values can resolve this
issue. We extend this result to non-diagonal LRNNs, which have recently shown
promise in models such as DeltaNet. We prove that finite precision LRNNs with
state-transition matrices having only positive eigenvalues cannot solve parity,
while complex eigenvalues are needed to count modulo $3$. Notably, we also
prove that LRNNs can learn any regular language when their state-transition
matrices are products of identity minus vector outer product matrices, each
with eigenvalues in the range $[-1, 1]$. Our empirical results confirm that
extending the eigenvalue range of models like Mamba and DeltaNet to include
negative values not only enables them to solve parity but consistently improves
their performance on state-tracking tasks. Furthermore, pre-training LRNNs with
an extended eigenvalue range for language modeling achieves comparable
performance and stability while showing promise on code and math data. Our work
enhances the expressivity of modern LRNNs, broadening their applicability
without changing the cost of training or inference.

摘要：線性遞迴神經網路 (LRNN)，例如 Mamba、RWKV、GLA、mLSTM 和 DeltaNet 已成為大型語言模型中 Transformer 的高效替代方案，提供與序列長度成線性比例的縮放和改善的訓練效率。然而，LRNN 難以執行狀態追蹤，這可能會損害程式碼評估或追蹤西洋棋遊戲等任務的效能。即使是 LSTM 等非線性 RNN 能有效處理的最簡單狀態追蹤任務奇偶驗證，也無法由目前的 LRNN 解決。最近，Sarrof 等人 (2024) 證明了像 Mamba 這樣的 LRNN 無法解決奇偶驗證的問題，源於將其對角狀態轉移矩陣的值範圍限制在 [0, 1]，而納入負值可以解決這個問題。我們將此結果延伸到非對角 LRNN，這在 DeltaNet 等模型中最近已展現潛力。我們證明了狀態轉移矩陣僅具有正特徵值的有限精度 LRNN 無法解決奇偶驗證，而需要複數特徵值來計算模數 3。值得注意的是，我們還證明了當 LRNN 的狀態轉移矩陣是單位矩陣減去向量外積矩陣的乘積時，LRNN 可以學習任何正則語言，每個矩陣的特徵值都在範圍 [-1, 1] 內。我們的實證結果證實，將 Mamba 和 DeltaNet 等模型的特徵值範圍擴展到包括負值，不僅使它們能夠解決奇偶驗證，而且持續改善它們在狀態追蹤任務上的效能。此外，使用擴展的特徵值範圍預訓練 LRNN 進行語言模型，在展現程式碼和數學資料的潛力時，達到了可比較的效能和穩定性。我們的研究增強了現代 LRNN 的表現力，擴大了它們的適用性，而不會改變訓練或推論的成本。

##### **Rethinking Top Probability from Multi-view for Distracted Driver Behaviour Localization**
2411.12525v1 by Quang Vinh Nguyen, Vo Hoang Thanh Son, Chau Truong Vinh Hoang, Duc Duy Nguyen, Nhat Huy Nguyen Minh, Soo-Hyung Kim

Naturalistic driving action localization task aims to recognize and
comprehend human behaviors and actions from video data captured during
real-world driving scenarios. Previous studies have shown great action
localization performance by applying a recognition model followed by
probability-based post-processing. Nevertheless, the probabilities provided by
the recognition model frequently contain confused information causing challenge
for post-processing. In this work, we adopt an action recognition model based
on self-supervise learning to detect distracted activities and give potential
action probabilities. Subsequently, a constraint ensemble strategy takes
advantages of multi-camera views to provide robust predictions. Finally, we
introduce a conditional post-processing operation to locate distracted
behaviours and action temporal boundaries precisely. Experimenting on test set
A2, our method obtains the sixth position on the public leaderboard of track 3
of the 2024 AI City Challenge.

摘要：自然驾驶動作定位任務旨在從實際駕駛場景中拍攝的影片資料中辨識並理解人類行為和動作。先前的研究已透過應用辨識模型，並搭配基於機率的事後處理，展現出優異的動作定位效能。儘管如此，辨識模型提供的機率經常包含混淆的資訊，對事後處理造成挑戰。在這項工作中，我們採用基於自我監督學習的動作辨識模型來偵測分心的活動，並提供潛在的動作機率。隨後，約束整合策略利用多鏡頭視角來提供穩健的預測。最後，我們引入條件式事後處理運算，以精確地定位分心的行為和動作時間界線。在測試集 A2 上進行實驗，我們的模型在 2024 年 AI 城市挑戰賽第 3 軌的公開排行榜上取得第六名。

##### **Transformer Neural Processes -- Kernel Regression**
2411.12502v1 by Daniel Jenson, Jhonathan Navott, Mengyan Zhang, Makkunda Sharma, Elizaveta Semenova, Seth Flaxman

Stochastic processes model various natural phenomena from disease
transmission to stock prices, but simulating and quantifying their uncertainty
can be computationally challenging. For example, modeling a Gaussian Process
with standard statistical methods incurs an $\mathcal{O}(n^3)$ penalty, and
even using state-of-the-art Neural Processes (NPs) incurs an $\mathcal{O}(n^2)$
penalty due to the attention mechanism. We introduce the Transformer Neural
Process - Kernel Regression (TNP-KR), a new architecture that incorporates a
novel transformer block we call a Kernel Regression Block (KRBlock), which
reduces the computational complexity of attention in transformer-based Neural
Processes (TNPs) from $\mathcal{O}((n_C+n_T)^2)$ to $O(n_C^2+n_Cn_T)$ by
eliminating masked computations, where $n_C$ is the number of context, and
$n_T$ is the number of test points, respectively, and a fast attention variant
that further reduces all attention calculations to $\mathcal{O}(n_C)$ in space
and time complexity. In benchmarks spanning such tasks as meta-regression,
Bayesian optimization, and image completion, we demonstrate that the full
variant matches the performance of state-of-the-art methods while training
faster and scaling two orders of magnitude higher in number of test points, and
the fast variant nearly matches that performance while scaling to millions of
both test and context points on consumer hardware.

摘要：隨機過程模擬了從疾病傳播到股票價格的各種自然現象，但模擬和量化它們的不確定性在計算上可能具有挑戰性。例如，使用標準統計方法對高斯過程進行建模會產生 $\mathcal{O}(n^3)$ 懲罰，即使使用最先進的神經過程 (NP) 由於注意力機制也會產生 $\mathcal{O}(n^2)$ 懲罰。我們介紹了 Transformer 神經過程 - 核迴歸 (TNP-KR)，這是一種新的架構，它包含了一個我們稱之為核迴歸塊 (KRBlock) 的新Transformer塊，它通過消除Transformer中基於注意力的神經過程 (TNP) 中的掩碼計算將計算複雜度從 $\mathcal{O}((n_C+n_T)^2)$ 降低到 $O(n_C^2+n_Cn_T)$，其中 $n_C$ 分別是上下文數量，而 $n_T$ 是測試點數量，以及一種快速注意變體，它進一步將所有注意力計算減少到 $\mathcal{O}(n_C)$ 的空間和時間複雜度。在涵蓋元迴歸、貝葉斯優化和圖像完成等任務的基準測試中，我們證明了完整變體在訓練速度更快且測試點數量擴展兩個數量級的同時，與最先進方法的性能相匹配，而快速變體在擴展到數百萬個測試和上下文點時幾乎與該性能相匹配消費者硬體。

##### **Enhancing Reasoning Capabilities of LLMs via Principled Synthetic Logic Corpus**
2411.12498v1 by Terufumi Morishita, Gaku Morio, Atsuki Yamaguchi, Yasuhiro Sogawa

Large language models (LLMs) are capable of solving a wide range of tasks,
yet they have struggled with reasoning. To address this, we propose
$\textbf{Additional Logic Training (ALT)}$, which aims to enhance LLMs'
reasoning capabilities by program-generated logical reasoning samples. We first
establish principles for designing high-quality samples by integrating symbolic
logic theory and previous empirical insights. Then, based on these principles,
we construct a synthetic corpus named $\textbf{Formal Logic Deduction Diverse}$
($\textbf{FLD}$$^{\times 2}$), comprising numerous samples of multi-step
deduction with unknown facts, diverse reasoning rules, diverse linguistic
expressions, and challenging distractors. Finally, we empirically show that ALT
on FLD$^{\times2}$ substantially enhances the reasoning capabilities of
state-of-the-art LLMs, including LLaMA-3.1-70B. Improvements include gains of
up to 30 points on logical reasoning benchmarks, up to 10 points on math and
coding benchmarks, and 5 points on the benchmark suite BBH.

摘要：大型語言模型 (LLM) 能解決廣泛的任務，但它們在推理方面卻遇到困難。為了解決這個問題，我們提出「額外邏輯訓練 (ALT)」，其目標是透過程式產生的邏輯推理範例來增強 LLM 的推理能力。我們首先透過整合符號邏輯理論和先前的經驗見解，建立設計高品質範例的原則。然後，根據這些原則，我們建構了一個名為「形式邏輯演繹多樣化」($\textbf{FLD}$$^{\times 2}$) 的合成語料庫，其中包含許多包含未知事實、多樣推理規則、多樣語言表達和具挑戰性干擾項的多步驟演繹範例。最後，我們透過實證顯示，針對 FLD$^{\times2}$ 進行 ALT 能大幅增強最先進的 LLM（包括 LLaMA-3.1-70B）的推理能力。改進包括在邏輯推理基準上獲得高達 30 分的提升、在數學和程式設計基準上獲得高達 10 分的提升，以及在基準套件 BBH 上獲得 5 分的提升。

##### **Bias Free Sentiment Analysis**
2411.12493v1 by Hubert Plisiecki

This paper introduces the Semantic Propagation Graph Neural Network (SProp
GNN), a machine learning sentiment analysis (SA) architecture that relies
exclusively on syntactic structures and word-level emotional cues to predict
emotions in text. By semantically blinding the model to information about
specific words, it is robust to biases such as political or gender bias that
have been plaguing previous machine learning-based SA systems. The SProp GNN
shows performance superior to lexicon-based alternatives such as VADER and
EmoAtlas on two different prediction tasks, and across two languages.
Additionally, it approaches the accuracy of transformer-based models while
significantly reducing bias in emotion prediction tasks. By offering improved
explainability and reducing bias, the SProp GNN bridges the methodological gap
between interpretable lexicon approaches and powerful, yet often opaque, deep
learning models, offering a robust tool for fair and effective emotion analysis
in understanding human behavior through text.

摘要：本文介紹語意傳播圖神經網路 (SProp GNN)，這是一種機器學習情緒分析 (SA) 架構，僅依賴語法結構和字詞層級的情緒線索來預測文字中的情緒。透過在語意上讓模型對特定字詞的資訊視而不見，它能抵抗政治或性別偏見等偏差，而這些偏差一直困擾著先前的基於機器學習的 SA 系統。SProp GNN 在兩項不同的預測任務和兩種語言中都表現出優於 VADER 和 EmoAtlas 等基於詞彙的替代方案。此外，它接近基於轉換器的模型的準確性，同時大幅減少情緒預測任務中的偏差。透過提供更好的可解釋性並減少偏差，SProp GNN 彌合了可解釋詞彙方法與強大但通常不透明的深度學習模型之間的方法論差距，提供了一個強大的工具，用於透過文字理解人類行為的公平和有效的情緒分析。

##### **Regular-pattern-sensitive CRFs for Distant Label Interactions**
2411.12484v1 by Sean Papay, Roman Klinger, Sebastian Pado

Linear-chain conditional random fields (CRFs) are a common model component
for sequence labeling tasks when modeling the interactions between different
labels is important. However, the Markov assumption limits linear-chain CRFs to
only directly modeling interactions between adjacent labels. Weighted
finite-state transducers (FSTs) are a related approach which can be made to
model distant label-label interactions, but exact label inference is
intractable for these models in the general case, and the task of selecting an
appropriate automaton structure for the desired interaction types poses a
practical challenge. In this work, we present regular-pattern-sensitive CRFs
(RPCRFs), a method of enriching standard linear-chain CRFs with the ability to
learn long-distance label interactions which occur in user-specified patterns.
This approach allows users to write regular-expression label patterns concisely
specifying which types of interactions the model should take into account,
allowing the model to learn from data whether and in which contexts these
patterns occur. The result can be interpreted alternatively as a CRF augmented
with additional, non-local potentials, or as a finite-state transducer whose
structure is defined by a set of easily-interpretable patterns. Critically,
unlike the general case for FSTs (and for non-chain CRFs), exact training and
inference are tractable for many pattern sets. In this work, we detail how a
RPCRF can be automatically constructed from a set of user-specified patterns,
and demonstrate the model's effectiveness on synthetic data, showing how
different types of patterns can capture different nonlocal dependency
structures in label sequences.

摘要：線性鏈條件隨機場 (CRF) 是序列標註任務中常見的模型元件，用於在建模不同標籤之間的互動時發揮重要作用。然而，馬可夫假設限制了線性鏈 CRF，只能直接建模相鄰標籤之間的互動。加權有限狀態轉換器 (FST) 是一種相關方法，可以建模遠距離標籤標籤互動，但對於這些模型而言，在一般情況下，精確標籤推論是棘手的，而且為所需的互動類型選擇適當的自動機結構，會構成實際挑戰。在這項工作中，我們提出了規則模式敏感 CRF (RPCRF)，這是一種方法，可以豐富標準線性鏈 CRF，使其具備學習在使用者指定的模式中發生的長距離標籤互動的能力。這種方法允許使用者撰寫正規表示式標籤模式，簡潔地指定模型應考量哪種類型的互動，讓模型能夠從資料中學習這些模式是否發生，以及在哪些情境中發生。結果可以另類地解釋為一個 CRF，它擴充了其他非局部潛力，或是一個有限狀態轉換器，其結構是由一組容易解釋的模式定義的。至關重要的是，與 FST (和非鏈 CRF) 的一般情況不同，對於許多模式組而言，精確訓練和推論都是可行的。在這項工作中，我們詳細說明如何根據一組使用者指定的模式自動建構 RPCRF，並展示模型在合成資料上的有效性，說明不同類型的模式如何擷取標籤序列中的不同非局部依賴結構。

##### **Comparing Prior and Learned Time Representations in Transformer Models of Timeseries**
2411.12476v1 by Natalia Koliou, Tatiana Boura, Stasinos Konstantopoulos, George Meramveliotakis, George Kosmadakis

What sets timeseries analysis apart from other machine learning exercises is
that time representation becomes a primary aspect of the experiment setup, as
it must adequately represent the temporal relations that are relevant for the
application at hand. In the work described here we study wo different
variations of the Transformer architecture: one where we use the fixed time
representation proposed in the literature and one where the time representation
is learned from the data. Our experiments use data from predicting the energy
output of solar panels, a task that exhibits known periodicities (daily and
seasonal) that is straight-forward to encode in the fixed time representation.
Our results indicate that even in an experiment where the phenomenon is
well-understood, it is difficult to encode prior knowledge due to side-effects
that are difficult to mitigate. We conclude that research work is needed to
work the human into the learning loop in ways that improve the robustness and
trust-worthiness of the network.

摘要：時序分析不同於其他機器學習練習之處在於，時間表示法成為實驗設定的主要面向，因為它必須適當地表示與手邊應用程式相關的時序關係。在這裡描述的工作中，我們研究了 Transformer 架構的兩種不同變異：一種是我們使用文獻中提出的固定時間表示法，另一種則是從資料中學習時間表示法。我們的實驗使用資料來預測太陽能電池板的能量輸出，這項任務展現出已知的週期性（每日和季節性），很容易編碼在固定的時間表示法中。我們的結果表明，即使在現象被充分理解的實驗中，由於難以減輕的副作用，也很難編碼先驗知識。我們得出結論，需要研究工作將人類納入學習迴路，以改善網路的穩健性和可信度。

##### **NMT-Obfuscator Attack: Ignore a sentence in translation with only one word**
2411.12473v1 by Sahar Sadrizadeh, César Descalzo, Ljiljana Dolamic, Pascal Frossard

Neural Machine Translation systems are used in diverse applications due to
their impressive performance. However, recent studies have shown that these
systems are vulnerable to carefully crafted small perturbations to their
inputs, known as adversarial attacks. In this paper, we propose a new type of
adversarial attack against NMT models. In this attack, we find a word to be
added between two sentences such that the second sentence is ignored and not
translated by the NMT model. The word added between the two sentences is such
that the whole adversarial text is natural in the source language. This type of
attack can be harmful in practical scenarios since the attacker can hide
malicious information in the automatic translation made by the target NMT
model. Our experiments show that different NMT models and translation tasks are
vulnerable to this type of attack. Our attack can successfully force the NMT
models to ignore the second part of the input in the translation for more than
50% of all cases while being able to maintain low perplexity for the whole
input.

摘要：神經機器翻譯系統因其令人印象深刻的表現而用於各種應用中。然而，最近的研究表明，這些系統容易受到對其輸入進行精心設計的小擾動的影響，這稱為對抗性攻擊。在本文中，我們提出了一種針對 NMT 模型的新型對抗性攻擊。在此攻擊中，我們找到一個詞語加在兩個句子之間，使得第二個句子被忽略，且不會被 NMT 模型翻譯。加在兩個句子之間的詞語使得整個對抗性文本在原始語言中是自然的。這種攻擊在實際場景中可能是有害的，因為攻擊者可以在目標 NMT 模型進行的自動翻譯中隱藏惡意資訊。我們的實驗表明，不同的 NMT 模型和翻譯任務容易受到這種攻擊。我們的攻擊可以成功迫使 NMT 模型在超過 50% 的情況下忽略輸入的第二部分，同時能夠保持整個輸入的低困惑度。

##### **AI Flow at the Network Edge**
2411.12469v1 by Jiawei Shao, Xuelong Li

Recent advancements in large language models (LLMs) and their multimodal
variants have led to remarkable progress across various domains, demonstrating
impressive capabilities and unprecedented potential. In the era of ubiquitous
connectivity, leveraging communication networks to distribute intelligence is a
transformative concept, envisioning AI-powered services accessible at the
network edge. However, pushing large models from the cloud to
resource-constrained environments faces critical challenges. Model inference on
low-end devices leads to excessive latency and performance bottlenecks, while
raw data transmission over limited bandwidth networks causes high communication
overhead. This article presents AI Flow, a framework that streamlines the
inference process by jointly leveraging the heterogeneous resources available
across devices, edge nodes, and cloud servers, making intelligence flow across
networks. To facilitate cooperation among multiple computational nodes, the
proposed framework explores a paradigm shift in the design of communication
network systems from transmitting information flow to intelligence flow, where
the goal of communications is task-oriented and folded into the inference
process. Experimental results demonstrate the effectiveness of the proposed
framework through an image captioning use case, showcasing the ability to
reduce response latency while maintaining high-quality captions. This article
serves as a position paper for identifying the motivation, challenges, and
principles of AI Flow.

摘要：<paragraph>大型語言模型 (LLM) 及其多模態變體的最新進展已在各個領域取得顯著進展，展現出令人印象深刻的能力和前所未有的潛力。在無處不在的連接時代，利用通信網路來分配智能是一種變革性的概念，設想在網路邊緣可存取由 AI 驅動的服務。然而，將大型模型從雲端推送到資源受限的環境會面臨嚴峻的挑戰。在低階裝置上進行模型推論會導致過度的延遲和效能瓶頸，而透過頻寬有限的網路傳輸原始資料會造成很高的通信負擔。本文介紹 AI Flow，這是一個架構，透過共同利用裝置、邊緣節點和雲端伺服器中可用的異質資源來簡化推論程序，讓智能在網路中流動。為了促進多個運算節點之間的合作，所提出的架構探討了通信網路系統設計的典範轉移，從傳輸資訊流到智能流，其中通信的目標是任務導向的，並融入推論程序。實驗結果透過圖像標題範例證明了所提出架構的有效性，展示了在維持高品質標題的同時降低回應延遲的能力。本文作為一份立場文件，用於識別 AI Flow 的動機、挑戰和原則。</paragraph>

##### **Guide-to-Explain for Controllable Summarization**
2411.12460v1 by Sangwon Ryu, Heejin Do, Daehee Kim, Yunsu Kim, Gary Geunbae Lee, Jungseul Ok

Recently, large language models (LLMs) have demonstrated remarkable
performance in abstractive summarization tasks. However, controllable
summarization with LLMs remains underexplored, limiting their ability to
generate summaries that align with specific user preferences. In this paper, we
first investigate the capability of LLMs to control diverse attributes,
revealing that they encounter greater challenges with numerical attributes,
such as length and extractiveness, compared to linguistic attributes. To
address this challenge, we propose a guide-to-explain framework (GTE) for
controllable summarization. Our GTE framework enables the model to identify
misaligned attributes in the initial draft and guides it in explaining errors
in the previous output. Based on this reflection, the model generates a
well-adjusted summary. As a result, by allowing the model to reflect on its
misalignment, we generate summaries that satisfy the desired attributes in
surprisingly fewer iterations than other iterative methods solely using LLMs.

摘要：近期，大型语言模型 (LLM) 在抽象摘要任务中展现出惊人的表现。然而，使用 LLM 进行可控摘要的探索仍不足，这限制了它们生成符合特定用户偏好的摘要的能力。在本文中，我们首先调查了 LLM 控制不同属性的能力，揭示了与语言属性相比，它们在数字属性（例如长度和抽取性）方面遇到了更大的挑战。为了应对这一挑战，我们提出了一个用于可控摘要的指南解释框架 (GTE)。我们的 GTE 框架使模型能够识别初始草稿中的错位属性，并指导它解释先前输出中的错误。基于这种反思，模型生成了一个调整良好的摘要。因此，通过允许模型反思其错位，我们生成的摘要满足了所需属性，并且比仅使用 LLM 的其他迭代方法迭代次数惊人地少。

##### **\textsc{Neon}: News Entity-Interaction Extraction for Enhanced Question Answering**
2411.12449v1 by Sneha Singhania, Silviu Cucerzan, Allen Herring, Sujay Kumar Jauhar

Capturing fresh information in near real-time and using it to augment
existing large language models (LLMs) is essential to generate up-to-date,
grounded, and reliable output. This problem becomes particularly challenging
when LLMs are used for informational tasks in rapidly evolving fields, such as
Web search related to recent or unfolding events involving entities, where
generating temporally relevant responses requires access to up-to-the-hour news
sources. However, the information modeled by the parametric memory of LLMs is
often outdated, and Web results from prototypical retrieval systems may fail to
capture the latest relevant information and struggle to handle conflicting
reports in evolving news. To address this challenge, we present the NEON
framework, designed to extract emerging entity interactions -- such as events
or activities -- as described in news articles. NEON constructs an
entity-centric timestamped knowledge graph that captures such interactions,
thereby facilitating enhanced QA capabilities related to news events. Our
framework innovates by integrating open Information Extraction (openIE) style
tuples into LLMs to enable in-context retrieval-augmented generation. This
integration demonstrates substantial improvements in QA performance when
tackling temporal, entity-centric search queries. Through NEON, LLMs can
deliver more accurate, reliable, and up-to-date responses.

摘要：捕捉近乎實時的最新資訊，並用於擴充現有的大型語言模型 (LLM)，對於產生即時、紮實且可靠的輸出至關重要。當 LLM 用於快速演進領域中的資訊任務時，這個問題會變得特別具有挑戰性，例如與涉及實體的近期或正在發生的事件相關的網路搜尋，其中產生時間相關的回應需要取得最新新聞來源。然而，LLM 的參數記憶體建模的資訊通常已過時，而原型檢索系統的網路結果可能無法捕捉最新的相關資訊，並難以處理不斷變化的新聞中的相互矛盾的報導。為了應對這個挑戰，我們提出 NEON 框架，旨在萃取新聞文章中描述的新興實體互動（例如事件或活動）。NEON 建構一個以實體為中心的帶時間戳記的知識圖譜，用於捕捉此類互動，從而促進與新聞事件相關的增強問答功能。我們的框架創新地將開放資訊萃取 (openIE) 風格的元組整合到 LLM 中，以實現語境內檢索增強的生成。這種整合在處理時間、以實體為中心的搜尋查詢時，證明了問答效能有顯著的改善。透過 NEON，LLM 能夠提供更準確、可靠且最新的回應。

##### **Evaluating the Prompt Steerability of Large Language Models**
2411.12405v1 by Erik Miehling, Michael Desmond, Karthikeyan Natesan Ramamurthy, Elizabeth M. Daly, Pierre Dognin, Jesus Rios, Djallel Bouneffouf, Miao Liu

Building pluralistic AI requires designing models that are able to be shaped
to represent a wide range of value systems and cultures. Achieving this
requires first being able to evaluate the degree to which a given model is
capable of reflecting various personas. To this end, we propose a benchmark for
evaluating the steerability of model personas as a function of prompting. Our
design is based on a formal definition of prompt steerability, which analyzes
the degree to which a model's joint behavioral distribution can be shifted from
its baseline behavior. By defining steerability indices and inspecting how
these indices change as a function of steering effort, we can estimate the
steerability of a model across various persona dimensions and directions. Our
benchmark reveals that the steerability of many current models is limited --
due to both a skew in their baseline behavior and an asymmetry in their
steerability across many persona dimensions. We release an implementation of
our benchmark at https://github.com/IBM/prompt-steering.

摘要：建立多元化 AI 需要設計能夠形塑的模型，以代表廣泛的價值系統和文化。要達成此目標，首先必須能夠評估特定模型反映各種角色的程度。為此，我們提出一個基準，用於評估模型角色的可操縱性，作為提示函數。我們的設計基於提示可操縱性的正式定義，該定義分析模型的聯合行為分布從其基準行為轉移的程度。透過定義可操縱性指標，並檢查這些指標如何隨著操縱力而改變，我們可以估計模型在各種角色面向和方向上的可操縱性。我們的基準顯示，許多當前模型的可操縱性受到限制——這歸因於其基準行為的偏差和其在許多角色面向上的可操縱性不對稱。我們在 https://github.com/IBM/prompt-steering 上發布了一個基準實作。

##### **Do LLMs Understand Ambiguity in Text? A Case Study in Open-world Question Answering**
2411.12395v1 by Aryan Keluskar, Amrita Bhattacharjee, Huan Liu

Ambiguity in natural language poses significant challenges to Large Language
Models (LLMs) used for open-domain question answering. LLMs often struggle with
the inherent uncertainties of human communication, leading to
misinterpretations, miscommunications, hallucinations, and biased responses.
This significantly weakens their ability to be used for tasks like
fact-checking, question answering, feature extraction, and sentiment analysis.
Using open-domain question answering as a test case, we compare off-the-shelf
and few-shot LLM performance, focusing on measuring the impact of explicit
disambiguation strategies. We demonstrate how simple, training-free,
token-level disambiguation methods may be effectively used to improve LLM
performance for ambiguous question answering tasks. We empirically show our
findings and discuss best practices and broader impacts regarding ambiguity in
LLMs.

摘要：自然語言中的歧義對用於開放領域問題解答的大語言模型 (LLM) 構成重大挑戰。LLM 經常難以應對人類溝通中固有的不確定性，導致誤解、溝通不良、幻覺和有偏見的回應。這顯著削弱了它們用於事實查核、問題解答、特徵提取和情緒分析等任務的能力。使用開放領域問題解答作為測試案例，我們比較了現成的和少量的 LLM 性能，重點是測量明確消除歧義策略的影響。我們展示了如何有效使用簡單、無訓練、令牌級消除歧義的方法來改善 LLM 在模棱兩可的問題解答任務中的表現。我們憑經驗展示我們的發現，並討論有關 LLM 中歧義的最佳實務和更廣泛的影響。

##### **RedPajama: an Open Dataset for Training Large Language Models**
2411.12372v1 by Maurice Weber, Daniel Fu, Quentin Anthony, Yonatan Oren, Shane Adams, Anton Alexandrov, Xiaozhong Lyu, Huu Nguyen, Xiaozhe Yao, Virginia Adams, Ben Athiwaratkun, Rahul Chalamala, Kezhen Chen, Max Ryabinin, Tri Dao, Percy Liang, Christopher Ré, Irina Rish, Ce Zhang

Large language models are increasingly becoming a cornerstone technology in
artificial intelligence, the sciences, and society as a whole, yet the optimal
strategies for dataset composition and filtering remain largely elusive. Many
of the top-performing models lack transparency in their dataset curation and
model development processes, posing an obstacle to the development of fully
open language models. In this paper, we identify three core data-related
challenges that must be addressed to advance open-source language models. These
include (1) transparency in model development, including the data curation
process, (2) access to large quantities of high-quality data, and (3)
availability of artifacts and metadata for dataset curation and analysis. To
address these challenges, we release RedPajama-V1, an open reproduction of the
LLaMA training dataset. In addition, we release RedPajama-V2, a massive
web-only dataset consisting of raw, unfiltered text data together with quality
signals and metadata. Together, the RedPajama datasets comprise over 100
trillion tokens spanning multiple domains and with their quality signals
facilitate the filtering of data, aiming to inspire the development of numerous
new datasets. To date, these datasets have already been used in the training of
strong language models used in production, such as Snowflake Arctic,
Salesforce's XGen and AI2's OLMo. To provide insight into the quality of
RedPajama, we present a series of analyses and ablation studies with
decoder-only language models with up to 1.6B parameters. Our findings
demonstrate how quality signals for web data can be effectively leveraged to
curate high-quality subsets of the dataset, underscoring the potential of
RedPajama to advance the development of transparent and high-performing
language models at scale.

摘要：大型語言模型正日益成為人工智能、科學和整個社會的基石技術，但資料集組成和過濾的最佳策略在很大程度上仍然難以捉摸。許多效能最高的模型在資料集整理和模型開發過程中缺乏透明度，對完全開放語言模型的開發構成障礙。在本文中，我們找出必須解決的三個核心資料相關挑戰，以推進開源語言模型。這些挑戰包括 (1) 模型開發的透明度，包括資料整理過程，(2) 取得大量高品質資料，以及 (3) 提供人工製品和元資料以進行資料集整理和分析。為了應對這些挑戰，我們發布了 RedPajama-V1，這是 LLaMA 訓練資料集的開放式重製版本。此外，我們還發布了 RedPajama-V2，這是一個龐大的純網路資料集，包含未經處理的未過濾文字資料，以及品質訊號和元資料。RedPajama 資料集總共包含超過 100 兆個符號，涵蓋多個領域，並透過品質訊號協助資料過濾，旨在激勵開發許多新的資料集。迄今為止，這些資料集已用於生產中使用的強大語言模型的訓練，例如 Snowflake Arctic、Salesforce 的 XGen 和 AI2 的 OLMo。為了深入了解 RedPajama 的品質，我們提出了一系列分析和消融研究，使用具有高達 1.6B 參數的僅解碼器語言模型。我們的研究結果證明了如何有效利用網路資料的品質訊號來整理資料集的高品質子集，強調了 RedPajama 在推進規模化透明且效能高的語言模型開發方面的潛力。

##### **A Layered Architecture for Developing and Enhancing Capabilities in Large Language Model-based Software Systems**
2411.12357v1 by Dawen Zhang, Xiwei Xu, Chen Wang, Zhenchang Xing, Robert Mao

Significant efforts has been made to expand the use of Large Language Models
(LLMs) beyond basic language tasks. While the generalizability and versatility
of LLMs have enabled widespread adoption, evolving demands in application
development often exceed their native capabilities. Meeting these demands may
involve a diverse set of methods, such as enhancing creativity through either
inference temperature adjustments or creativity-provoking prompts. Selecting
the right approach is critical, as different methods lead to trade-offs in
engineering complexity, scalability, and operational costs. This paper
introduces a layered architecture that organizes LLM software system
development into distinct layers, each characterized by specific attributes. By
aligning capabilities with these layers, the framework encourages the
systematic implementation of capabilities in effective and efficient ways that
ultimately supports desired functionalities and qualities. Through practical
case studies, we illustrate the utility of the framework. This work offers
developers actionable insights for selecting suitable technologies in LLM-based
software system development, promoting robustness and scalability.

摘要：為了擴展大型語言模型 (LLM) 在基本語言任務以外的應用，已投入大量心力。雖然 LLM 的泛用性和多功能性讓其廣泛採用，但應用程式開發中不斷變化的需求往往超過其原生能力。滿足這些需求可能涉及各種方法，例如透過推論溫度調整或激發創造力的提示來增強創造力。選擇正確的方法至關重要，因為不同的方法會在工程複雜性、可擴充性和運營成本方面產生權衡。本文介紹了一種分層架構，將 LLM 軟體系統開發組織成不同的層級，每個層級都有特定的屬性。透過將功能與這些層級對齊，此架構鼓勵以有效且高效的方式系統性地實作功能，最終支援所需的機能和品質。透過實際案例研究，我們說明了此架構的實用性。這項工作為開發人員提供了可行的見解，以選擇 LLM 為基礎的軟體系統開發中合適的技術，促進穩健性和可擴充性。

##### **DiM: $f$-Divergence Minimization Guided Sharpness-Aware Optimization for Semi-supervised Medical Image Segmentation**
2411.12350v1 by Bingli Wang, Houcheng Su, Nan Yin, Mengzhu Wang, Li Shen

As a technique to alleviate the pressure of data annotation, semi-supervised
learning (SSL) has attracted widespread attention. In the specific domain of
medical image segmentation, semi-supervised methods (SSMIS) have become a
research hotspot due to their ability to reduce the need for large amounts of
precisely annotated data. SSMIS focuses on enhancing the model's generalization
performance by leveraging a small number of labeled samples and a large number
of unlabeled samples. The latest sharpness-aware optimization (SAM) technique,
which optimizes the model by reducing the sharpness of the loss function, has
shown significant success in SSMIS. However, SAM and its variants may not fully
account for the distribution differences between different datasets. To address
this issue, we propose a sharpness-aware optimization method based on
$f$-divergence minimization (DiM) for semi-supervised medical image
segmentation. This method enhances the model's stability by fine-tuning the
sensitivity of model parameters and improves the model's adaptability to
different datasets through the introduction of $f$-divergence. By reducing
$f$-divergence, the DiM method not only improves the performance balance
between the source and target datasets but also prevents performance
degradation due to overfitting on the source dataset.

摘要：作為一種減輕資料標註壓力的技術，半監督式學習 (SSL) 已廣受關注。在醫學影像分割的特定領域中，半監督式方法 (SSMIS) 由於能夠減少對大量精確標註資料的需求而成為研究熱點。SSMIS 專注於透過利用少數標籤樣本和大量未標籤樣本來增強模型的泛化效能。最新的銳利度感知最佳化 (SAM) 技術透過降低損失函數的銳利度來最佳化模型，已在 SSMIS 中展現顯著的成功。然而，SAM 及其變體可能無法完全考量不同資料集之間的分布差異。為了解決此問題，我們提出了一種基於 $f$-散度最小化 (DiM) 的銳利度感知最佳化方法，用於半監督式醫學影像分割。此方法透過微調模型參數的敏感度並透過引入 $f$-散度來改善模型對不同資料集的適應性，進而增強模型的穩定性。透過降低 $f$-散度，DiM 方法不僅改善了來源資料集和目標資料集之間的效能平衡，還防止了因過度擬合來源資料集而導致的效能下降。

##### **CLIP Unreasonable Potential in Single-Shot Face Recognition**
2411.12319v1 by Nhan T. Luu

Face recognition is a core task in computer vision designed to identify and
authenticate individuals by analyzing facial patterns and features. This field
intersects with artificial intelligence image processing and machine learning
with applications in security authentication and personalization. Traditional
approaches in facial recognition focus on capturing facial features like the
eyes, nose and mouth and matching these against a database to verify identities
However challenges such as high false positive rates have persisted often due
to the similarity among individuals facial features. Recently Contrastive
Language Image Pretraining (CLIP) a model developed by OpenAI has shown
promising advancements by linking natural language processing with vision tasks
allowing it to generalize across modalities. Using CLIP's vision language
correspondence and single-shot finetuning the model can achieve lower false
positive rates upon deployment without the need of mass facial features
extraction. This integration demonstrating CLIP's potential to address
persistent issues in face recognition model performance without complicating
our training paradigm.

摘要：人臉辨識是電腦視覺中的核心任務，旨在透過分析臉部模式和特徵來識別和驗證個人身分。此領域與人工智慧影像處理和機器學習相結合，在安全驗證和個人化方面有應用。傳統人臉辨識方法專注於擷取眼睛、鼻子和嘴巴等臉部特徵，並將其與資料庫進行比對以驗證身分。然而，由於個人臉部特徵的相似性，經常出現高偽陽性率等挑戰。最近，由 OpenAI 開發的對比語言影像預訓練 (CLIP) 模型透過將自然語言處理與視覺任務連結，展現出令人振奮的進展，使其能夠跨模態概化。透過使用 CLIP 的視覺語言對應和單次微調，該模型可以在部署時達成較低偽陽性率，而無需大量擷取臉部特徵。此整合證明了 CLIP 有潛力解決人臉辨識模型效能中的持續問題，而不會使我們的訓練範例複雜化。

##### **Balancing Accuracy and Efficiency in Multi-Turn Intent Classification for LLM-Powered Dialog Systems in Production**
2411.12307v1 by Junhua Liu, Yong Keat Tan, Bin Fu, Kwan Hui Lim

Accurate multi-turn intent classification is essential for advancing
conversational AI systems. However, challenges such as the scarcity of
comprehensive datasets and the complexity of contextual dependencies across
dialogue turns hinder progress. This paper presents two novel approaches
leveraging Large Language Models (LLMs) to enhance scalability and reduce
latency in production dialogue systems. First, we introduce Symbol Tuning,
which simplifies intent labels to reduce task complexity and improve
performance in multi-turn dialogues. Second, we propose C-LARA
(Consistency-aware, Linguistics Adaptive Retrieval Augmentation), a framework
that employs LLMs for data augmentation and pseudo-labeling to generate
synthetic multi-turn dialogues. These enriched datasets are used to fine-tune a
small, efficient model suitable for deployment. Experiments conducted on
multilingual dialogue datasets demonstrate significant improvements in
classification accuracy and resource efficiency. Our methods enhance multi-turn
intent classification accuracy by 5.09%, reduce annotation costs by 40%, and
enable scalable deployment in low-resource multilingual industrial systems,
highlighting their practicality and impact.

摘要：準確的多輪意圖分類對於推進對話式 AI 系統至關重要。然而，諸如綜合資料集的稀缺性以及對話輪次間的脈絡依賴性的複雜性等挑戰阻礙了進度。本文提出了兩種利用大型語言模型 (LLM) 來增強可擴充性和降低生產對話系統中延遲的新方法。首先，我們引入了符號調整，它簡化了意圖標籤以降低任務複雜性並提升多輪對話中的效能。其次，我們提出了 C-LARA（一致性感知、語言自適應檢索增強），這是一個採用 LLM 進行資料擴充和偽標籤以產生合成多輪對話的框架。這些豐富的資料集用於微調一個小型、高效的模型，適合部署。在多語言對話資料集上進行的實驗證明了分類準確性和資源效率的顯著提升。我們的技術將多輪意圖分類準確度提升了 5.09%，將註釋成本降低了 40%，並在低資源多語言產業系統中實現了可擴充性部署，突顯了其實用性和影響力。

##### **SSEditor: Controllable Mask-to-Scene Generation with Diffusion Model**
2411.12290v1 by Haowen Zheng, Yanyan Liang

Recent advancements in 3D diffusion-based semantic scene generation have
gained attention. However, existing methods rely on unconditional generation
and require multiple resampling steps when editing scenes, which significantly
limits their controllability and flexibility. To this end, we propose SSEditor,
a controllable Semantic Scene Editor that can generate specified target
categories without multiple-step resampling. SSEditor employs a two-stage
diffusion-based framework: (1) a 3D scene autoencoder is trained to obtain
latent triplane features, and (2) a mask-conditional diffusion model is trained
for customizable 3D semantic scene generation. In the second stage, we
introduce a geometric-semantic fusion module that enhance the model's ability
to learn geometric and semantic information. This ensures that objects are
generated with correct positions, sizes, and categories. Extensive experiments
on SemanticKITTI and CarlaSC demonstrate that SSEditor outperforms previous
approaches in terms of controllability and flexibility in target generation, as
well as the quality of semantic scene generation and reconstruction. More
importantly, experiments on the unseen Occ-3D Waymo dataset show that SSEditor
is capable of generating novel urban scenes, enabling the rapid construction of
3D scenes.

摘要：近来在基于 3D 扩散的语义场景生成方面有显著的进展，备受关注。然而，现有方法依赖于无条件生成，并且在编辑场景时需要多次重新采样步骤，这极大地限制了其可控性和灵活性。为此，我们提出了 SSEditor，一个可控语义场景编辑器，它可以在不进行多步重新采样情况下生成指定的目标类别。SSEditor 采用了一个基于两阶段扩散的框架：(1) 训练一个 3D 场景自动编码器来获取潜在的三平面特征，以及 (2) 训练一个蒙版条件扩散模型以用于可定制的 3D 语义场景生成。在第二阶段，我们引入了一个几何语义融合模块，以增强模型学习几何和语义信息的能力。这确保了对象以正确的方位、大小和类别生成。在 SemanticKITTI 和 CarlaSC 上的广泛实验表明，SSEditor 在目标生成的可控性和灵活性以及语义场景生成和重建的质量方面优于以往的方法。更重要的是，在未见过的 Occ-3D Waymo 数据集上的实验表明，SSEditor 能够生成新颖的城市场景，从而能够快速构建 3D 场景。

##### **CUE-M: Contextual Understanding and Enhanced Search with Multimodal Large Language Model**
2411.12287v1 by Dongyoung Go, Taesun Whang, Chanhee Lee, Hwayeon Kim, Sunghoon Park, Seunghwan Ji, Dongchan Kim, Young-Bum Kim

The integration of Retrieval-Augmented Generation (RAG) with Multimodal Large
Language Models (MLLMs) has expanded the scope of multimodal query resolution.
However, current systems struggle with intent understanding, information
retrieval, and safety filtering, limiting their effectiveness. This paper
introduces Contextual Understanding and Enhanced Search with MLLM (CUE-M), a
novel multimodal search pipeline that addresses these challenges through a
multi-stage framework comprising image context enrichment, intent refinement,
contextual query generation, external API integration, and relevance-based
filtering. CUE-M incorporates a robust safety framework combining image-based,
text-based, and multimodal classifiers, dynamically adapting to instance- and
category-specific risks. Evaluations on a multimodal Q&A dataset and a public
safety benchmark demonstrate that CUE-M outperforms baselines in accuracy,
knowledge integration, and safety, advancing the capabilities of multimodal
retrieval systems.

摘要：檢索擴增生成 (RAG) 與多模態大型語言模型 (MLLM) 的整合擴展了多模態查詢解析的範圍。
然而，目前的系統在意圖理解、資訊檢索和安全過濾方面都面臨困難，限制了其效能。本文介紹了情境理解和 MLLM 增強搜尋 (CUE-M)，這是一個新穎的多模態搜尋管道，透過一個包含影像情境豐富化、意圖精煉、情境查詢生成、外部 API 整合和基於關聯性的過濾的多階段架構來解決這些挑戰。CUE-M 整合了一個強固的安全架構，結合了基於影像、基於文字和多模態的分類器，動態適應特定實例和類別的風險。在多模態問答資料集和公開安全基準上的評估顯示，CUE-M 在準確性、知識整合和安全性方面都優於基準，提升了多模態檢索系統的能力。

##### **Building Trust: Foundations of Security, Safety and Transparency in AI**
2411.12275v1 by Huzaifa Sidhpurwala, Garth Mollett, Emily Fox, Mark Bestavros, Huamin Chen

This paper explores the rapidly evolving ecosystem of publicly available AI
models, and their potential implications on the security and safety landscape.
As AI models become increasingly prevalent, understanding their potential risks
and vulnerabilities is crucial. We review the current security and safety
scenarios while highlighting challenges such as tracking issues, remediation,
and the apparent absence of AI model lifecycle and ownership processes.
Comprehensive strategies to enhance security and safety for both model
developers and end-users are proposed. This paper aims to provide some of the
foundational pieces for more standardized security, safety, and transparency in
the development and operation of AI models and the larger open ecosystems and
communities forming around them.

摘要：本文探討了快速演進的公開 AI 模型生態系統，以及它們對安全和防護環境的潛在影響。隨著 AI 模型日益普及，了解其潛在風險和漏洞至關重要。我們回顧了當前的安全和防護情境，同時強調了追蹤問題、補救措施，以及 AI 模型生命週期和所有權流程明顯缺失等挑戰。本文提出了提升模型開發人員和最終使用者安全和防護的全面策略。本文旨在為 AI 模型的開發和運作，以及圍繞它們形成的更廣泛的開放生態系統和社群提供更標準化的安全、防護和透明度等基礎架構。

##### **Low-resource Machine Translation: what for? who for? An observational study on a dedicated Tetun language translation service**
2411.12262v1 by Raphael Merx, Hanna Suominen, Adérito José Guterres Correia, Trevor Cohn, Ekaterina Vylomova

The impact of machine translation (MT) on low-resource languages remains
poorly understood. In particular, observational studies of actual usage
patterns are scarce. Such studies could provide valuable insights into user
needs and behaviours, complementing survey-based methods. Here we present an
observational analysis of real-world MT usage for Tetun, the lingua franca of
Timor-Leste, using server logs from a widely-used MT service with over $70,000$
monthly active users. Our analysis of $100,000$ translation requests reveals
patterns that challenge assumptions based on existing corpora. We find that
users, many of them students on mobile devices, typically translate short texts
into Tetun across diverse domains including science, healthcare, and daily
life. This contrasts sharply with available Tetun corpora, which are dominated
by news articles covering government and social issues. Our results suggest
that MT systems for languages like Tetun should prioritise translating into the
low-resource language, handling brief inputs effectively, and covering a wide
range of domains relevant to educational contexts. More broadly, this study
demonstrates how observational analysis can inform low-resource language
technology development, by grounding research in practical community needs.

摘要：機器翻譯 (MT) 對低資源語言的影響仍未得到充分理解。特別是，對實際使用模式的觀察研究很少。此類研究可以提供對使用者需求和行為的寶貴見解，以補充基於調查的方法。在此，我們提出對泰東語（東帝汶的通用語）的真實世界機器翻譯使用情況的觀察分析，使用來自廣泛使用的機器翻譯服務的伺服器記錄，該服務每月活躍使用者超過 70,000 人。我們對 100,000 筆翻譯請求的分析揭示了挑戰基於現有語料庫的假設的模式。我們發現使用者，其中許多是行動裝置上的學生，通常將簡短的文字翻譯成泰東語，涵蓋科學、醫療保健和日常生活等不同領域。這與現有的泰東語語料庫形成鮮明對比，後者主要由涵蓋政府和社會議題的新聞文章組成。我們的結果表明，像泰東語這樣的語言的機器翻譯系統應優先翻譯成低資源語言，有效處理簡短輸入，並涵蓋與教育背景相關的廣泛領域。更廣泛地說，本研究展示了觀察分析如何透過將研究建立在實際的社群需求上，為低資源語言技術開發提供資訊。

##### **Restructuring Tractable Probabilistic Circuits**
2411.12256v1 by Honghua Zhang, Benjie Wang, Marcelo Arenas, Guy Van den Broeck

Probabilistic circuits (PCs) is a unifying representation for probabilistic
models that support tractable inference. Numerous applications of PCs like
controllable text generation depend on the ability to efficiently multiply two
circuits. Existing multiplication algorithms require that the circuits respect
the same structure, i.e. variable scopes decomposes according to the same
vtree. In this work, we propose and study the task of restructuring
structured(-decomposable) PCs, that is, transforming a structured PC such that
it conforms to a target vtree. We propose a generic approach for this problem
and show that it leads to novel polynomial-time algorithms for multiplying
circuits respecting different vtrees, as well as a practical depth-reduction
algorithm that preserves structured decomposibility. Our work opens up new
avenues for tractable PC inference, suggesting the possibility of training with
less restrictive PC structures while enabling efficient inference by changing
their structures at inference time.

摘要：機率電路 (PC) 是一種機率模型的統一表示，支持可處理的推論。PC 的許多應用程式（例如可控制的文字產生）都仰賴有效率地將兩個電路相乘的能力。現有的相乘演算法要求電路遵循相同的結構，亦即變數範圍根據相同的 vtree 分解。在這項工作中，我們提出並研究了重新建構結構化 (- 可分解) PC 的任務，也就是將結構化 PC 轉換為符合目標 vtree 的形式。我們為這個問題提出了一種通用方法，並證明這方法可產生一種新的多項式時間演算法，用於相乘遵循不同 vtree 的電路，以及一種實用的深度縮減演算法，用於保留結構化可分解性。我們的研究開啟了可處理 PC 推論的新途徑，暗示著有機會使用較不具限制性的 PC 結構進行訓練，同時透過在推論時間變更結構來實現有效率的推論。

##### **Error-Feedback Model for Output Correction in Bilateral Control-Based Imitation Learning**
2411.12255v1 by Hiroshi Sato, Masashi Konosu, Sho Sakaino, Toshiaki Tsuji

In recent years, imitation learning using neural networks has enabled robots
to perform flexible tasks. However, since neural networks operate in a
feedforward structure, they do not possess a mechanism to compensate for output
errors. To address this limitation, we developed a feedback mechanism to
correct these errors. By employing a hierarchical structure for neural networks
comprising lower and upper layers, the lower layer was controlled to follow the
upper layer. Additionally, using a multi-layer perceptron in the lower layer,
which lacks an internal state, enhanced the error feedback. In the
character-writing task, this model demonstrated improved accuracy in writing
previously untrained characters. In the character-writing task, this model
demonstrated improved accuracy in writing previously untrained characters.
Through autonomous control with error feedback, we confirmed that the lower
layer could effectively track the output of the upper layer. This study
represents a promising step toward integrating neural networks with control
theories.

摘要：近年來，使用神經網路的模仿學習使機器人能夠執行靈活的任務。然而，由於神經網路以前饋結構運作，它們不具備補償輸出錯誤的機制。為了解決這個限制，我們開發了一種回饋機制來修正這些錯誤。透過採用由下層和上層組成的分層結構的神經網路，下層被控制以遵循上層。此外，在下層使用缺乏內部狀態的多層感知器，增強了錯誤回饋。在字元寫入任務中，此模型在寫入先前未訓練過的字元時展現出更高的準確度。在字元寫入任務中，此模型在寫入先前未訓練過的字元時展現出更高的準確度。透過具有錯誤回饋的自主控制，我們確認下層可以有效追蹤上層的輸出。這項研究代表了一個將神經網路與控制理論整合起來的有希望的步驟。

##### **Predicting User Intents and Musical Attributes from Music Discovery Conversations**
2411.12254v1 by Daeyong Kwon, SeungHeon Doh, Juhan Nam

Intent classification is a text understanding task that identifies user needs
from input text queries. While intent classification has been extensively
studied in various domains, it has not received much attention in the music
domain. In this paper, we investigate intent classification models for music
discovery conversation, focusing on pre-trained language models. Rather than
only predicting functional needs: intent classification, we also include a task
for classifying musical needs: musical attribute classification. Additionally,
we propose a method of concatenating previous chat history with just
single-turn user queries in the input text, allowing the model to understand
the overall conversation context better. Our proposed model significantly
improves the F1 score for both user intent and musical attribute
classification, and surpasses the zero-shot and few-shot performance of the
pretrained Llama 3 model.

摘要：意圖分類是一種文本理解任務，它從輸入文本查詢中識別使用者需求。儘管意圖分類已在各個領域廣泛研究，但它在音樂領域並未受到太多關注。在本文中，我們研究了針對音樂探索對話的意圖分類模型，重點關注預訓練語言模型。除了預測功能需求：意圖分類，我們還包括了一個用於分類音樂需求的任務：音樂屬性分類。此外，我們提出了一種將先前的聊天記錄與輸入文本中的單輪使用者查詢串聯起來的方法，讓模型可以更好地理解整體對話內容。我們提出的模型顯著提高了使用者意圖和音樂屬性分類的 F1 分數，並且超越了預訓練 Llama 3 模型的零次學習和少量學習的表現。

##### **Efficient Training in Multi-Agent Reinforcement Learning: A Communication-Free Framework for the Box-Pushing Problem**
2411.12246v1 by David Ge, Hao Ji

Self-organizing systems consist of autonomous agents that can perform complex
tasks and adapt to dynamic environments without a central controller. Prior
research often relies on reinforcement learning to enable agents to gain the
skills needed for task completion, such as in the box-pushing environment.
However, when agents push from opposing directions during exploration, they
tend to exert equal and opposite forces on the box, resulting in minimal
displacement and inefficient training. This paper proposes a model called
Shared Pool of Information (SPI), which enables information to be accessible to
all agents and facilitates coordination, reducing force conflicts among agents
and enhancing exploration efficiency. Through computer simulations, we
demonstrate that SPI not only expedites the training process but also requires
fewer steps per episode, significantly improving the agents' collaborative
effectiveness.

摘要：自組織系統由自主代理組成，這些代理能夠執行複雜任務並適應動態環境，而無需中央控制器。先前的研究通常依賴強化學習，使代理能夠獲得完成任務所需的技能，例如在推箱環境中。然而，當代理在探索過程中從相反方向推時，它們往往對箱子施加相等且相反的力，導致位移最小且訓練效率低下。本文提出了一種稱為資訊共享池 (SPI) 的模型，它使資訊能夠被所有代理存取並促進協調，減少代理之間的力衝突並提高探索效率。透過電腦模擬，我們證明 SPI 不僅可以加快訓練過程，而且每集所需的步驟更少，顯著提高了代理的協作效能。

##### **Evaluating Tokenizer Performance of Large Language Models Across Official Indian Languages**
2411.12240v1 by S. Tamang, D. J. Bora

Large Language Models (LLMs) based on transformer architectures have
revolutionized a variety of domains, with tokenization playing a pivotal role
in their pre-processing and fine-tuning stages. In multilingual models,
particularly those tailored for Indic languages, effective tokenization is
crucial for optimizing performance. This paper presents a comprehensive
evaluation of tokenizers used by 12 LLMs across all 22 official languages of
India, with a focus on comparing the efficiency of their tokenization
processes. We employed the Normalized Sequence Length (NSL) as a key metric in
our analysis. Our findings reveal that the SUTRA tokenizer outperforms all
other models, including several Indic-specific models, excelling in 14
languages. Notable insights include the SUTRA tokenizer's superior handling of
Indic languages, GPT-4o's advancement over its predecessor GPT-4 in processing
Indian languages, and the limited performance of Project Indus in certain
languages. This study underscores the critical importance of developing
targeted tokenization strategies for multilingual and Indic-centric models,
laying the groundwork for future improvements in tokenizer design to enhance
linguistic coverage and model efficiency.

摘要：大型語言模型 (LLM) 基於Transformer架構，徹底改變了各種領域，其中分詞在它們的預處理和微調階段扮演了關鍵角色。在多語言模型中，特別是針對印度語言量身打造的模型，有效的分詞對於優化效能至關重要。本文全面評估了 12 個 LLM 所使用的分詞器，涵蓋印度 22 種官方語言，重點比較它們的分詞處理效率。我們在分析中採用標準化序列長度 (NSL) 作為關鍵指標。我們的研究結果顯示，SUTRA 分詞器優於所有其他模型，包括多個印度語言專用模型，在 14 種語言中表現出色。值得注意的見解包括 SUTRA 分詞器在處理印度語言方面的優異表現、GPT-4o 在處理印度語言方面優於其前身 GPT-4，以及 Project Indus 在某些語言中的效能有限。這項研究強調了為多語言和印度中心模型開發目標分詞策略至關重要，為未來改進分詞器設計奠定基礎，以增強語言涵蓋範圍和模型效率。

##### **BoolQuestions: Does Dense Retrieval Understand Boolean Logic in Language?**
2411.12235v1 by Zongmeng Zhang, Jinhua Zhu, Wengang Zhou, Xiang Qi, Peng Zhang, Houqiang Li

Dense retrieval, which aims to encode the semantic information of arbitrary
text into dense vector representations or embeddings, has emerged as an
effective and efficient paradigm for text retrieval, consequently becoming an
essential component in various natural language processing systems. These
systems typically focus on optimizing the embedding space by attending to the
relevance of text pairs, while overlooking the Boolean logic inherent in
language, which may not be captured by current training objectives. In this
work, we first investigate whether current retrieval systems can comprehend the
Boolean logic implied in language. To answer this question, we formulate the
task of Boolean Dense Retrieval and collect a benchmark dataset, BoolQuestions,
which covers complex queries containing basic Boolean logic and corresponding
annotated passages. Through extensive experimental results on the proposed task
and benchmark dataset, we draw the conclusion that current dense retrieval
systems do not fully understand Boolean logic in language, and there is a long
way to go to improve our dense retrieval systems. Furthermore, to promote
further research on enhancing the understanding of Boolean logic for language
models, we explore Boolean operation on decomposed query and propose a
contrastive continual training method that serves as a strong baseline for the
research community.

摘要：密集檢索旨在將任意文本的語義資訊編碼成稠密向量表示或嵌入，已成為文本檢索的有效且高效範例，因此成為各種自然語言處理系統中不可或缺的組成部分。這些系統通常專注於透過關注文本對相關性來最佳化嵌入空間，同時忽略語言中固有的布林邏輯，而目前的訓練目標可能無法擷取到布林邏輯。在這項工作中，我們首先探討目前的檢索系統是否能理解語言中隱含的布林邏輯。為了回答這個問題，我們制定了布林密集檢索任務，並收集了一個基準資料集 BoolQuestions，其中包含包含基本布林邏輯和對應註解段落的複雜查詢。透過對所提出的任務和基準資料集進行廣泛的實驗結果，我們得出結論，目前的密集檢索系統並未完全理解語言中的布林邏輯，還有很長一段路要走才能改善我們的密集檢索系統。此外，為了促進進一步研究增強語言模型對布林邏輯的理解，我們探討了分解查詢的布林運算，並提出了一個對比連續訓練方法，作為研究社群的強大基準。

##### **Contrast Similarity-Aware Dual-Pathway Mamba for Multivariate Time Series Node Classification**
2411.12222v1 by Mingsen Du, Meng Chen, Yongjian Li, Xiuxin Zhang, Jiahui Gao, Cun Ji, Shoushui Wei

Multivariate time series (MTS) data is generated through multiple sensors
across various domains such as engineering application, health monitoring, and
the internet of things, characterized by its temporal changes and high
dimensional characteristics. Over the past few years, many studies have
explored the long-range dependencies and similarities in MTS. However,
long-range dependencies are difficult to model due to their temporal changes
and high dimensionality makes it difficult to obtain similarities effectively
and efficiently. Thus, to address these issues, we propose contrast
similarity-aware dual-pathway Mamba for MTS node classification (CS-DPMamba).
Firstly, to obtain the dynamic similarity of each sample, we initially use
temporal contrast learning module to acquire MTS representations. And then we
construct a similarity matrix between MTS representations using Fast Dynamic
Time Warping (FastDTW). Secondly, we apply the DPMamba to consider the
bidirectional nature of MTS, allowing us to better capture long-range and
short-range dependencies within the data. Finally, we utilize the
Kolmogorov-Arnold Network enhanced Graph Isomorphism Network to complete the
information interaction in the matrix and MTS node classification task. By
comprehensively considering the long-range dependencies and dynamic similarity
features, we achieved precise MTS node classification. We conducted experiments
on multiple University of East Anglia (UEA) MTS datasets, which encompass
diverse application scenarios. Our results demonstrate the superiority of our
method through both supervised and semi-supervised experiments on the MTS
classification task.

摘要：多變量時間序列 (MTS) 資料是透過多個感測器在各種領域中產生的，例如工程應用、健康監測和物聯網，其特徵在於其時間變化和高維度特徵。在過去幾年中，許多研究探索了 MTS 中的長程依賴性和相似性。然而，由於時間變化，長程依賴性難以建模，而高維度性使得難以有效且有效地取得相似性。因此，為了解決這些問題，我們提出對比相似度感知雙路徑 Mamba 進行 MTS 節點分類 (CS-DPMamba)。首先，為了取得每個樣本的動態相似度，我們最初使用時間對比學習模組來取得 MTS 表徵。然後，我們使用快速動態時間扭曲 (FastDTW) 在 MTS 表徵之間建立相似矩陣。其次，我們應用 DPMamba 來考量 MTS 的雙向性質，讓我們能夠在資料中更好地擷取長程和短程依賴性。最後，我們利用 Kolmogorov-Arnold 網路增強圖同構網路來完成矩陣中的資訊互動和 MTS 節點分類任務。透過全面考量長程依賴性和動態相似性特徵，我們達到了精確的 MTS 節點分類。我們在多個東英格蘭大學 (UEA) MTS 資料集上進行了實驗，這些資料集涵蓋了不同的應用場景。我們的結果透過 MTS 分類任務上的監督式和半監督式實驗證明了我們方法的優越性。

##### **DeTrigger: A Gradient-Centric Approach to Backdoor Attack Mitigation in Federated Learning**
2411.12220v1 by Kichang Lee, Yujin Shin, Jonghyuk Yun, Jun Han, JeongGil Ko

Federated Learning (FL) enables collaborative model training across
distributed devices while preserving local data privacy, making it ideal for
mobile and embedded systems. However, the decentralized nature of FL also opens
vulnerabilities to model poisoning attacks, particularly backdoor attacks,
where adversaries implant trigger patterns to manipulate model predictions. In
this paper, we propose DeTrigger, a scalable and efficient backdoor-robust
federated learning framework that leverages insights from adversarial attack
methodologies. By employing gradient analysis with temperature scaling,
DeTrigger detects and isolates backdoor triggers, allowing for precise model
weight pruning of backdoor activations without sacrificing benign model
knowledge. Extensive evaluations across four widely used datasets demonstrate
that DeTrigger achieves up to 251x faster detection than traditional methods
and mitigates backdoor attacks by up to 98.9%, with minimal impact on global
model accuracy. Our findings establish DeTrigger as a robust and scalable
solution to protect federated learning environments against sophisticated
backdoor threats.

摘要：联邦学习 (FL) 可以在分布式设备中进行协作模型训练，同时保护本地数据隐私，使其非常适合移动和嵌入式系统。然而，FL 的分散性质也为模型中毒攻击（尤其是后门攻击）打开了漏洞，攻击者植入触发模式来操纵模型预测。在本文中，我们提出了 DeTrigger，一个可扩展且高效的后门鲁棒联邦学习框架，它利用了对抗性攻击方法的见解。通过采用具有温度缩放的梯度分析，DeTrigger 检测并隔离后门触发器，从而可以精确地剪枝后门激活模型权重，而不会牺牲良性模型知识。在四个广泛使用的数据集上的广泛评估表明，DeTrigger 的检测速度比传统方法快 251 倍，将后门攻击减轻了 98.9%，对全局模型准确性的影响最小。我们的研究结果将 DeTrigger 确立为一种针对复杂后门威胁保护联邦学习环境的强大且可扩展的解决方案。

##### **CCIS-Diff: A Generative Model with Stable Diffusion Prior for Controlled Colonoscopy Image Synthesis**
2411.12198v1 by Yifan Xie, Jingge Wang, Tao Feng, Fei Ma, Yang Li

Colonoscopy is crucial for identifying adenomatous polyps and preventing
colorectal cancer. However, developing robust models for polyp detection is
challenging by the limited size and accessibility of existing colonoscopy
datasets. While previous efforts have attempted to synthesize colonoscopy
images, current methods suffer from instability and insufficient data
diversity. Moreover, these approaches lack precise control over the generation
process, resulting in images that fail to meet clinical quality standards. To
address these challenges, we propose CCIS-DIFF, a Controlled generative model
for high-quality Colonoscopy Image Synthesis based on a Diffusion architecture.
Our method offers precise control over both the spatial attributes (polyp
location and shape) and clinical characteristics of polyps that align with
clinical descriptions. Specifically, we introduce a blur mask weighting
strategy to seamlessly blend synthesized polyps with the colonic mucosa, and a
text-aware attention mechanism to guide the generated images to reflect
clinical characteristics. Notably, to achieve this, we construct a new
multi-modal colonoscopy dataset that integrates images, mask annotations, and
corresponding clinical text descriptions. Experimental results demonstrate that
our method generates high-quality, diverse colonoscopy images with fine control
over both spatial constraints and clinical consistency, offering valuable
support for downstream segmentation and diagnostic tasks.

摘要：結腸鏡檢查對於腺瘤性息肉的辨識與預防大腸直腸癌至關重要。然而，由於現有結腸鏡檢查資料集的規模與取得不易，開發穩健的息肉偵測模型極具挑戰性。雖然先前的研究已嘗試合成結腸鏡影像，但目前的方法存在不穩定與資料多樣性不足的問題。此外，這些方法對於生成過程缺乏精確的控制，導致影像無法達到臨床品質標準。為了應對這些挑戰，我們提出 CCIS-DIFF，一種基於擴散架構的高品質結腸鏡影像合成受控生成模型。我們的方法能精確控制息肉的空間屬性（息肉位置與形狀）與臨床特徵，並與臨床描述相符。具體來說，我們引入模糊遮罩加權策略，以無縫地將合成的息肉與結腸黏膜融合，並使用文字感知注意力機制來引導生成的影像反映臨床特徵。值得注意的是，為了達成此目標，我們建構了一個新的多模式結腸鏡檢查資料集，其中整合了影像、遮罩標註與對應的臨床文字描述。實驗結果證明，我們的方法能生成高品質、多樣化的結腸鏡影像，並能精細地控制空間約束與臨床一致性，為下游分割與診斷任務提供有價值的支援。

##### **Testability of Instrumental Variables in Additive Nonlinear, Non-Constant Effects Models**
2411.12184v1 by Xichen Guo, Zheng Li, Biwei Huang, Yan Zeng, Zhi Geng, Feng Xie

We address the issue of the testability of instrumental variables derived
from observational data. Most existing testable implications are centered on
scenarios where the treatment is a discrete variable, e.g., instrumental
inequality (Pearl, 1995), or where the effect is assumed to be constant, e.g.,
instrumental variables condition based on the principle of independent
mechanisms (Burauel, 2023). However, treatments can often be continuous
variables, such as drug dosages or nutritional content levels, and non-constant
effects may occur in many real-world scenarios. In this paper, we consider an
additive nonlinear, non-constant effects model with unmeasured confounders, in
which treatments can be either discrete or continuous, and propose an
Auxiliary-based Independence Test (AIT) condition to test whether a variable is
a valid instrument. We first show that if the candidate instrument is valid,
then the AIT condition holds. Moreover, we illustrate the implications of the
AIT condition and demonstrate that, in certain conditions, AIT conditions are
necessary and sufficient to detect all invalid IVs. We also extend the AIT
condition to include covariates and introduce a practical testing algorithm.
Experimental results on both synthetic and three different real-world datasets
show the effectiveness of our proposed condition.

摘要：<paragraph>我們探討從觀測數據衍生的工具變數的可測試性問題。現有的可測試暗示大多集中在處理為離散變數的情況，例如工具變數不等式（Pearl，1995 年），或假設效果為常數的情況，例如基於獨立機制原理的工具變數條件（Burauel，2023 年）。然而，處理通常可以是連續變數，例如藥物劑量或營養成分水平，並且在許多實際情況中可能會發生非恆定效應。在本文中，我們考慮了一個具有未測量混雜項的加性非線性、非恆定效應模型，其中處理可以是離散的或連續的，並提出了一個基於輔助的獨立性檢驗 (AIT) 條件來檢驗一個變數是否是一個有效的工具。我們首先表明，如果候選工具有效，則 AIT 條件成立。此外，我們說明了 AIT 條件的含義，並證明在某些條件下，AIT 條件對於檢測所有無效 IV 是必要且充分的。我們還擴展了 AIT 條件以納入協變量，並介紹了一個實用的檢驗演算法。在合成和三個不同的真實世界資料集上的實驗結果顯示了我們提出的條件的有效性。</paragraph>

##### **Diffusion-Inspired Cold Start with Sufficient Prior in Computerized Adaptive Testing**
2411.12182v1 by Haiping Ma, Aoqing Xia, Changqian Wang, Hai Wang, Xingyi Zhang

Computerized Adaptive Testing (CAT) aims to select the most appropriate
questions based on the examinee's ability and is widely used in online
education. However, existing CAT systems often lack initial understanding of
the examinee's ability, requiring random probing questions. This can lead to
poorly matched questions, extending the test duration and negatively impacting
the examinee's mindset, a phenomenon referred to as the Cold Start with
Insufficient Prior (CSIP) task. This issue occurs because CAT systems do not
effectively utilize the abundant prior information about the examinee available
from other courses on online platforms. These response records, due to the
commonality of cognitive states across different knowledge domains, can provide
valuable prior information for the target domain. However, no prior work has
explored solutions for the CSIP task. In response to this gap, we propose
Diffusion Cognitive States TransfeR Framework (DCSR), a novel domain transfer
framework based on Diffusion Models (DMs) to address the CSIP task.
Specifically, we construct a cognitive state transition bridge between domains,
guided by the common cognitive states of examinees, encouraging the model to
reconstruct the initial ability state in the target domain. To enrich the
expressive power of the generated data, we analyze the causal relationships in
the generation process from a causal perspective. Redundant and extraneous
cognitive states can lead to limited transfer and negative transfer effects.
Our DCSR can seamlessly apply the generated initial ability states in the
target domain to existing question selection algorithms, thus improving the
cold start performance of the CAT system. Extensive experiments conducted on
five real-world datasets demonstrate that DCSR significantly outperforms
existing baseline methods in addressing the CSIP task.

摘要：電腦化適應性測驗 (CAT) 旨在根據受試者的能力選擇最合適的題目，並廣泛用於線上教育中。然而，現有的 CAT 系統常常缺乏對受試者能力的初始理解，需要隨機探測題目。這可能導致題目匹配不佳，延長測驗時間並對受試者的思維產生負面影響，這種現象稱為冷啟動與先驗不足 (CSIP) 任務。此問題發生是因為 CAT 系統沒有有效利用線上平台上其他課程中可取得的、關於受試者的豐富先驗資訊。這些回應記錄，由於認知狀態在不同知識領域中的共性，可以為目標領域提供有價值的先驗資訊。然而，沒有先前的研究探索過 CSIP 任務的解決方案。為了回應這個差距，我們提出擴散認知狀態轉移架構 (DCSR)，一個基於擴散模型 (DM) 的新穎領域轉移架構，以解決 CSIP 任務。具體來說，我們在領域之間建立一個認知狀態轉移橋樑，由受試者的共同認知狀態引導，鼓勵模型重建目標領域中的初始能力狀態。為了豐富生成資料的表達能力，我們從因果觀點分析生成過程中的因果關係。冗餘和無關的認知狀態可能導致有限的轉移和負面的轉移效應。我們的 DCSR 可以無縫地將目標領域中生成的初始能力狀態應用於現有的題目選擇演算法，從而改善 CAT 系統的冷啟動效能。在五個真實世界資料集上進行的廣泛實驗表明，DCSR 在解決 CSIP 任務方面明顯優於現有的基準方法。

##### **Enhancing Low Dose Computed Tomography Images Using Consistency Training Techniques**
2411.12181v1 by Mahmut S. Gokmen, Jie Zhang, Ge Wang, Jin Chen, Cody Bumgardner

Diffusion models have significant impact on wide range of generative tasks,
especially on image inpainting and restoration. Although the improvements on
aiming for decreasing number of function evaluations (NFE), the iterative
results are still computationally expensive. Consistency models are as a new
family of generative models, enable single-step sampling of high quality data
without the need for adversarial training. In this paper, we introduce the beta
noise distribution, which provides flexibility in adjusting noise levels. This
is combined with a sinusoidal curriculum that enhances the learning of the
trajectory between the noise distribution and the posterior distribution of
interest, allowing High Noise Improved Consistency Training (HN-iCT) to be
trained in a supervised fashion. Additionally, High Noise Improved Consistency
Training with Image Condition (HN-iCT-CN) architecture is introduced, enables
to take Low Dose images as a condition for extracting significant features by
Weighted Attention Gates (WAG).Our results indicate that unconditional image
generation using HN-iCT significantly outperforms basic CT and iCT training
techniques with NFE=1 on the CIFAR10 and CelebA datasets. Moreover, our
image-conditioned model demonstrates exceptional performance in enhancing
low-dose (LD) CT scans.

摘要：扩散模型对广泛的生成任务产生重大影响，
尤其是在图像修复和重建上。虽然改进的目标是减少函数评估次数 (NFE)，但迭代
结果在计算上仍然昂贵。一致性模型作为一种新的生成模型系列，能够对高质量数据进行单步采样
无需对抗性训练。在本文中，我们介绍了贝塔噪声分布，它提供了调整噪声级别的灵活性。这
与正弦课程相结合，增强了噪声分布和感兴趣的后验分布之间的轨迹学习，允许高噪声改进的一致性训练 (HN-iCT) 以监督方式进行训练。此外，还引入了图像条件下的高噪声改进一致性训练 (HN-iCT-CN) 架构，能够
通过加权注意力门 (WAG) 将低剂量图像作为条件来提取重要特征。我们的结果表明，使用 HN-iCT 进行无条件图像生成在 CIFAR10 和 CelebA 数据集上的 NFE=1 时，明显优于基本的 CT 和 iCT 训练技术。此外，我们的图像条件模型在增强
低剂量 (LD) CT 扫描方面表现出卓越的性能。

##### **Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**
2411.12174v1 by Rahul Garg, Trilok Padhi, Hemang Jain, Ugur Kursuncu, Ugur Kursuncu, Ponnurangam Kumaraguru

Toxicity identification in online multimodal environments remains a
challenging task due to the complexity of contextual connections across
modalities (e.g., textual and visual). In this paper, we propose a novel
framework that integrates Knowledge Distillation (KD) from Large Visual
Language Models (LVLMs) and knowledge infusion to enhance the performance of
toxicity detection in hateful memes. Our approach extracts sub-knowledge graphs
from ConceptNet, a large-scale commonsense Knowledge Graph (KG) to be infused
within a compact VLM framework. The relational context between toxic phrases in
captions and memes, as well as visual concepts in memes enhance the model's
reasoning capabilities. Experimental results from our study on two hate speech
benchmark datasets demonstrate superior performance over the state-of-the-art
baselines across AU-ROC, F1, and Recall with improvements of 1.1%, 7%, and 35%,
respectively. Given the contextual complexity of the toxicity detection task,
our approach showcases the significance of learning from both explicit (i.e.
KG) as well as implicit (i.e. LVLMs) contextual cues incorporated through a
hybrid neurosymbolic approach. This is crucial for real-world applications
where accurate and scalable recognition of toxic content is critical for
creating safer online environments.

摘要：網路多模態環境中的毒性辨識，由於模態間（例如文字和視覺）的脈絡關聯複雜，因此仍是一項具有挑戰性的任務。在本文中，我們提出一個新穎的架構，整合來自大型視覺語言模型 (LVLMs) 的知識蒸餾 (KD) 和知識注入，以增強仇恨迷因中毒性偵測的效能。我們的做法從 ConceptNet（一個大型常識知識圖譜 (KG)）中萃取子知識圖，並注入到一個緊湊的 VLM 架構中。標題和迷因中具有毒性的詞彙之間的關係脈絡，以及迷因中的視覺概念，增強了模型的推理能力。我們在兩個仇恨言論基準資料集上進行的研究的實驗結果，證明了在 AU-ROC、F1 和召回率方面，我們的做法優於最先進的基準，分別提升了 1.1%、7% 和 35%。鑑於毒性偵測任務的脈絡複雜性，我們的做法展示了從明確（例如 KG）和隱含（例如 LVLMs）脈絡線索中學習，並透過混合神經符號方法整合起來的重要性。這對於真實世界的應用至關重要，在這些應用中，準確且可擴充的毒性內容辨識對於創造更安全的網路環境至關重要。

##### **UrbanDiT: A Foundation Model for Open-World Urban Spatio-Temporal Learning**
2411.12164v1 by Yuan Yuan, Chonghua Han, Jingtao Ding, Depeng Jin, Yong Li

The urban environment is characterized by complex spatio-temporal dynamics
arising from diverse human activities and interactions. Effectively modeling
these dynamics is essential for understanding and optimizing urban systems In
this work, we introduce UrbanDiT, a foundation model for open-world urban
spatio-temporal learning that successfully scale up diffusion transformers in
this field. UrbanDiT pioneers a unified model that integrates diverse
spatio-temporal data sources and types while learning universal spatio-temporal
patterns across different cities and scenarios. This allows the model to unify
both multi-data and multi-task learning, and effectively support a wide range
of spatio-temporal applications. Its key innovation lies in the elaborated
prompt learning framework, which adaptively generates both data-driven and
task-specific prompts, guiding the model to deliver superior performance across
various urban applications. UrbanDiT offers three primary advantages: 1) It
unifies diverse data types, such as grid-based and graph-based data, into a
sequential format, allowing to capture spatio-temporal dynamics across diverse
scenarios of different cities; 2) With masking strategies and task-specific
prompts, it supports a wide range of tasks, including bi-directional
spatio-temporal prediction, temporal interpolation, spatial extrapolation, and
spatio-temporal imputation; and 3) It generalizes effectively to open-world
scenarios, with its powerful zero-shot capabilities outperforming nearly all
baselines with training data. These features allow UrbanDiT to achieves
state-of-the-art performance in different domains such as transportation
traffic, crowd flows, taxi demand, bike usage, and cellular traffic, across
multiple cities and tasks. UrbanDiT sets up a new benchmark for foundation
models in the urban spatio-temporal domain.

摘要：<paragraph>城市環境的特徵在於複雜的時空動態，
源自於多樣的人類活動與互動。有效地建模
這些動態對於理解和優化城市系統至關重要，
在這項工作中，我們介紹 UrbanDiT，一個開放世界城市
時空學習基礎模型，成功地擴展了此領域中的擴散Transformer。
UrbanDiT 開創了一個統一的模型，整合了多樣化的
時空數據來源和類型，同時學習不同城市和場景中的通用時空模式。
這允許模型統一多數據和多任務學習，並有效地支援廣泛的
時空應用。其關鍵創新在於精心設計的提示學習框架，
它自適應地產生數據驅動和特定於任務的提示，
引導模型在各種城市應用中提供卓越的效能。
UrbanDiT 提供了三個主要的優點：1) 它統一了多種數據類型，
例如基於網格和基於圖形的數據，成為一個順序格式，
允許在不同城市的各種場景中擷取時空動態；
2) 透過遮罩策略和特定於任務的提示，它支援廣泛的任務，
包括雙向時空預測、時間插值、空間外推和時空插補；
3) 它有效地概括到開放世界場景，其強大的零次學習能力
優於幾乎所有具有訓練數據的基線。這些功能允許 UrbanDiT
在不同領域（例如交通流量、人潮流動、計程車需求、
自行車使用和行動通訊流量）中達到最先進的效能，
跨越多個城市和任務。UrbanDiT 為城市時空領域的基礎模型
設定了一個新的基準。</paragraph>

##### **A Combined Encoder and Transformer Approach for Coherent and High-Quality Text Generation**
2411.12157v1 by Jiajing Chen, Shuo Wang, Zhen Qi, Zhenhong Zhang, Chihang Wang, Hongye Zheng

This research introduces a novel text generation model that combines BERT's
semantic interpretation strengths with GPT-4's generative capabilities,
establishing a high standard in generating coherent, contextually accurate
language. Through the combined architecture, the model enhances semantic depth
and maintains smooth, human-like text flow, overcoming limitations seen in
prior models. Experimental benchmarks reveal that BERT-GPT-4 surpasses
traditional models, including GPT-3, T5, BART, Transformer-XL, and CTRL, in key
metrics like Perplexity and BLEU, showcasing its superior natural language
generation performance. By fully utilizing contextual information, this hybrid
model generates text that is not only logically coherent but also aligns
closely with human language patterns, providing an advanced solution for text
generation tasks. This research highlights the potential of integrating
semantic understanding with advanced generative models, contributing new
insights for NLP, and setting a foundation for broader applications of
large-scale generative architectures in areas such as automated writing,
question-answer systems, and adaptive conversational agents.

摘要：這項研究介紹了一個新穎的文本生成模型，它結合了 BERT 的語義解讀優勢和 GPT-4 的生成能力，在生成連貫、語境準確的語言方面樹立了高標準。透過結合架構，該模型增強了語義深度，並維持流暢、類似人類的文字流動，克服了先前模型中所見的限制。實驗基準顯示，BERT-GPT-4 在困惑度和 BLEU 等關鍵指標上超越了傳統模型，包括 GPT-3、T5、BART、Transformer-XL 和 CTRL，展示了其優異的自然語言生成效能。透過充分利用上下文資訊，這個混合模型產生的文字不僅在邏輯上連貫，而且與人類語言模式緊密結合，為文字生成任務提供了先進的解決方案。這項研究強調了將語義理解與先進的生成模型整合的潛力，為 NLP 貢獻了新的見解，並為在自動寫作、問答系統和適應性對話代理等領域中更廣泛應用大型生成架構奠定了基礎。

##### **HNCSE: Advancing Sentence Embeddings via Hybrid Contrastive Learning with Hard Negatives**
2411.12156v1 by Wenxiao Liu, Zihong Yang, Chaozhuo Li, Zijin Hong, Jianfeng Ma, Zhiquan Liu, Litian Zhang, Feiran Huang

Unsupervised sentence representation learning remains a critical challenge in
modern natural language processing (NLP) research. Recently, contrastive
learning techniques have achieved significant success in addressing this issue
by effectively capturing textual semantics. Many such approaches prioritize the
optimization using negative samples. In fields such as computer vision, hard
negative samples (samples that are close to the decision boundary and thus more
difficult to distinguish) have been shown to enhance representation learning.
However, adapting hard negatives to contrastive sentence learning is complex
due to the intricate syntactic and semantic details of text. To address this
problem, we propose HNCSE, a novel contrastive learning framework that extends
the leading SimCSE approach. The hallmark of HNCSE is its innovative use of
hard negative samples to enhance the learning of both positive and negative
samples, thereby achieving a deeper semantic understanding. Empirical tests on
semantic textual similarity and transfer task datasets validate the superiority
of HNCSE.

摘要：無監督句子表徵學習仍然是現代自然語言處理 (NLP) 研究中的一項關鍵挑戰。最近，對比學習技術通過有效擷取文本語意在解決此問題方面取得了顯著成功。許多此類方法優先使用負面範例進行最佳化。在電腦視覺等領域中，已證明困難的負面範例（接近決策邊界的範例，因此更難以區分）可以增強表徵學習。然而，由於文字的複雜句法和語義細節，將困難的負面範例調整為對比句子學習很複雜。為了解決這個問題，我們提出了 HNCSE，這是一種新的對比學習架構，它延伸了領先的 SimCSE 方法。HNCSE 的標誌是創新地使用困難的負面範例來增強對正面和負面範例的學習，從而實現更深入的語義理解。在語義文本相似性和轉移任務資料集上的實證測試驗證了 HNCSE 的優越性。

##### **HEIGHT: Heterogeneous Interaction Graph Transformer for Robot Navigation in Crowded and Constrained Environments**
2411.12150v1 by Shuijing Liu, Haochen Xia, Fatemeh Cheraghi Pouria, Kaiwen Hong, Neeloy Chakraborty, Katherine Driggs-Campbell

We study the problem of robot navigation in dense and interactive crowds with
environmental constraints such as corridors and furniture. Previous methods
fail to consider all types of interactions among agents and obstacles, leading
to unsafe and inefficient robot paths. In this article, we leverage a
graph-based representation of crowded and constrained scenarios and propose a
structured framework to learn robot navigation policies with deep reinforcement
learning. We first split the representations of different components in the
environment and propose a heterogeneous spatio-temporal (st) graph to model
distinct interactions among humans, robots, and obstacles. Based on the
heterogeneous st-graph, we propose HEIGHT, a novel navigation policy network
architecture with different components to capture heterogeneous interactions
among entities through space and time. HEIGHT utilizes attention mechanisms to
prioritize important interactions and a recurrent network to track changes in
the dynamic scene over time, encouraging the robot to avoid collisions
adaptively. Through extensive simulation and real-world experiments, we
demonstrate that HEIGHT outperforms state-of-the-art baselines in terms of
success and efficiency in challenging navigation scenarios. Furthermore, we
demonstrate that our pipeline achieves better zero-shot generalization
capability than previous works when the densities of humans and obstacles
change. More videos are available at
https://sites.google.com/view/crowdnav-height/home.

摘要：我們研究了機器人在擁擠且互動頻繁的人群中導航的問題，同時考量了環境限制，例如走廊和家具。先前的做法未能考量代理和障礙物之間的所有互動類型，導致機器人路徑不安全且效率不彰。在本文中，我們利用擁擠且受限場景的圖形化表示，並提出一個結構化框架，以深度強化學習來學習機器人導航策略。我們首先拆分環境中不同組成的表示，並提出一個異質時空 (st) 圖形來建模人類、機器人和障礙物之間不同的互動。基於異質 st 圖形，我們提出 HEIGHT，一種新穎的導航策略網路架構，具有不同的組成，以透過時空來擷取實體之間的異質互動。HEIGHT 利用注意力機制來優先處理重要的互動，並利用遞迴網路來追蹤動態場景隨著時間的變化，鼓勵機器人靈活地避免碰撞。透過廣泛的模擬和真實世界實驗，我們證明 HEIGHT 在具挑戰性的導航場景中，在成功率和效率方面優於最先進的基準。此外，我們證明當人類和障礙物的密度改變時，我們的管線比先前的研究獲得更好的零次學習泛化能力。更多影片可在 https://sites.google.com/view/crowdnav-height/home 取得。

##### **CoMeDi Shared Task: Models as Annotators in Lexical Semantics Disagreements**
2411.12147v1 by Zhu Liu, Zhen Hu, Ying Liu

We present the results of our system for the CoMeDi Shared Task, which
predicts majority votes (Subtask 1) and annotator disagreements (Subtask 2).
Our approach combines model ensemble strategies with MLP-based and
threshold-based methods trained on pretrained language models. Treating
individual models as virtual annotators, we simulate the annotation process by
designing aggregation measures that incorporate continuous similarity scores
and discrete classification labels to capture both majority and disagreement.
Additionally, we employ anisotropy removal techniques to enhance performance.
Experimental results demonstrate the effectiveness of our methods, particularly
for Subtask 2. Notably, we find that continuous similarity scores, even within
the same model, align better with human disagreement patterns compared to
aggregated discrete labels.

摘要：我們展示了我們在 CoMeDi 共享任務中系統的結果，該任務
預測多數票（子任務 1）和註解者分歧（子任務 2）。
我們的做法結合了模型集成策略與基於 MLP 和
在預訓練語言模型上訓練的基於閾值的模型。將
個別模型視為虛擬註解者，我們通過
設計聚合措施來模擬註解過程，該措施包含連續相似性分數
和離散分類標籤，以捕捉多數和分歧。
此外，我們採用各向異性去除技術來提高性能。
實驗結果證明了我們方法的有效性，特別是
對於子任務 2。值得注意的是，我們發現連續相似性分數，即使在
同一個模型中，與人類分歧模式相比，與
聚合離散標籤相比更一致。

##### **Visualizing Loss Functions as Topological Landscape Profiles**
2411.12136v1 by Caleb Geniesse, Jiaqing Chen, Tiankai Xie, Ge Shi, Yaoqing Yang, Dmitriy Morozov, Talita Perciano, Michael W. Mahoney, Ross Maciejewski, Gunther H. Weber

In machine learning, a loss function measures the difference between model
predictions and ground-truth (or target) values. For neural network models,
visualizing how this loss changes as model parameters are varied can provide
insights into the local structure of the so-called loss landscape (e.g.,
smoothness) as well as global properties of the underlying model (e.g.,
generalization performance). While various methods for visualizing the loss
landscape have been proposed, many approaches limit sampling to just one or two
directions, ignoring potentially relevant information in this extremely
high-dimensional space. This paper introduces a new representation based on
topological data analysis that enables the visualization of higher-dimensional
loss landscapes. After describing this new topological landscape profile
representation, we show how the shape of loss landscapes can reveal new details
about model performance and learning dynamics, highlighting several use cases,
including image segmentation (e.g., UNet) and scientific machine learning
(e.g., physics-informed neural networks). Through these examples, we provide
new insights into how loss landscapes vary across distinct hyperparameter
spaces: we find that the topology of the loss landscape is simpler for
better-performing models; and we observe greater variation in the shape of loss
landscapes near transitions from low to high model performance.

摘要：<paragraph>在機器學習中，損失函數測量模型預測與真實 (或目標) 值之間的差異。對於神經網路模型，視覺化此損失如何隨著模型參數的變化而變化，可以洞察所謂的損失景觀的局部結構 (例如，平滑度) 以及底層模型的全局屬性 (例如，泛化效能)。雖然已經提出各種可視化損失景觀的方法，但許多方法將抽樣限制在僅一個或兩個方向，忽略了這個極高維度空間中潛在相關的資訊。本文介紹一種基於拓撲資料分析的新表示，可視化更高維度的損失景觀。描述這個新的拓撲景觀特徵表示後，我們展示損失景觀的形狀如何揭示模型效能和學習動態的新細節，重點介紹幾個使用案例，包括影像分割 (例如，UNet) 和科學機器學習 (例如，物理資訊神經網路)。透過這些範例，我們提供新的見解，說明損失景觀如何因不同的超參數空間而異：我們發現，效能較佳的模型，其損失景觀的拓撲較為簡單；我們觀察到，從低模型效能轉變到高模型效能時，損失景觀的形狀變化較大。</paragraph>

##### **The Role of Accuracy and Validation Effectiveness in Conversational Business Analytics**
2411.12128v1 by Adem Alparslan

This study examines conversational business analytics, an approach that
utilizes AI to address the technical competency gaps that hindered end users
from effectively using traditional self-service analytics. By facilitating
natural language interactions, conversational business analytics aims to enable
end users to independently retrieve data and generate insights. The analysis
focuses on Text-to-SQL as a representative technology for translating natural
language requests into SQL statements. Using models grounded in expected
utility theory, the study identifies conditions under which conversational
business analytics, through partial or full support, can outperform delegation
to human experts. The results indicate that partial support, which focuses
solely on information generation by AI, is viable when the accuracy of
AI-generated SQL queries exceeds a defined threshold. In contrast, full support
includes not only information generation but also validation through
explanations provided by the AI, and requires sufficiently high validation
effectiveness to be reliable. However, user-based validation presents
challenges, such as misjudgment and rejection of valid SQL queries, which may
limit the effectiveness of conversational business analytics. These challenges
underscore the need for robust validation mechanisms, including improved user
support, automated processes, and methods for assessing quality independently
of end users' technical competencies.

摘要：本研究探討會話式商業分析，這是一種利用人工智慧來解決技術能力差距的方法，而這種差距阻礙了最終使用者有效使用傳統的自助式分析。透過促進自然語言互動，會話式商業分析旨在讓最終使用者能夠獨立擷取資料並產生見解。分析重點在於將文字轉換為 SQL，作為將自然語言要求轉換為 SQL 陳述的代表性技術。本研究使用建立在預期效用理論上的模型，找出在部分或完全支援下，會話式商業分析可以優於委派給人類專家的條件。結果顯示，部分支援（僅專注於 AI 產生的資訊）在 AI 產生的 SQL 查詢的準確度超過定義的閾值時是可行的。相比之下，完全支援不僅包括資訊產生，還包括透過 AI 提供的說明進行驗證，且需要足夠高的驗證效能才能可靠。然而，基於使用者的驗證會產生挑戰，例如誤判和拒絕有效的 SQL 查詢，這可能會限制會話式商業分析的效能。這些挑戰強調了對健全驗證機制的需求，包括改善使用者支援、自動化流程，以及獨立於最終使用者技術能力來評估品質的方法。

##### **Does Unlearning Truly Unlearn? A Black Box Evaluation of LLM Unlearning Methods**
2411.12103v1 by Jai Doshi, Asa Cooper Stickland

Large language model unlearning aims to remove harmful information that LLMs
have learnt to prevent their use for malicious purposes. LLMU and RMU have been
proposed as two methods for LLM unlearning, achieving impressive results on
unlearning benchmarks. We study in detail the efficacy of these methods by
evaluating their impact on general model capabilities on the WMDP benchmark as
well as a biology benchmark we create. Our experiments show that RMU generally
leads to better preservation of model capabilities, for similar or better
unlearning. We further test the robustness of these methods and find that doing
5-shot prompting or rephrasing the question in simple ways can lead to an over
ten-fold increase in accuracy on unlearning benchmarks. Finally, we show that
training on unrelated data can almost completely recover pre-unlearning
performance, demonstrating that these methods fail at truly unlearning. The
code is available at
$\href{https://github.com/JaiDoshi/Knowledge-Erasure}{this\, https\, URL}$.

摘要：大型语言模型的遗忘旨在消除 LLM 学到的有害信息，以防止其被恶意使用。LLMU 和 RMU 已被提出作为 LLM 遗忘的两种方法，在遗忘基准上取得了令人印象深刻的结果。我们通过评估这些方法对 WMDP 基准和我们创建的生物基准上的一般模型能力的影响，详细研究了这些方法的功效。我们的实验表明，对于类似或更好的遗忘，RMU 通常会导致模型能力得到更好的保留。我们进一步测试了这些方法的鲁棒性，发现进行 5 次提示或以简单的方式重新表述问题会导致遗忘基准的准确性提高十倍以上。最后，我们表明在不相关的训练数据上训练几乎可以完全恢复遗忘前的性能，这表明这些方法未能真正实现遗忘。代码可在此处获得：
$\href{https://github.com/JaiDoshi/Knowledge-Erasure}{此\, https\, URL}$。

##### **Mitigating Gender Bias in Contextual Word Embeddings**
2411.12074v1 by Navya Yarrabelly, Vinay Damodaran, Feng-Guang Su

Word embeddings have been shown to produce remarkable results in tackling a
vast majority of NLP related tasks. Unfortunately, word embeddings also capture
the stereotypical biases that are prevalent in society, affecting the
predictive performance of the embeddings when used in downstream tasks. While
various techniques have been proposed \cite{bolukbasi2016man, zhao2018learning}
and criticized\cite{gonen2019lipstick} for static embeddings, very little work
has focused on mitigating bias in contextual embeddings. In this paper, we
propose a novel objective function for MLM(Masked-Language Modeling) which
largely mitigates the gender bias in contextual embeddings and also preserves
the performance for downstream tasks. Since previous works on measuring bias in
contextual embeddings lack in normative reasoning, we also propose novel
evaluation metrics that are straight-forward and aligned with our motivations
in debiasing. We also propose new methods for debiasing static embeddings and
provide empirical proof via extensive analysis and experiments, as to why the
main source of bias in static embeddings stems from the presence of
stereotypical names rather than gendered words themselves. All experiments and
embeddings studied are in English, unless otherwise
specified.\citep{bender2011achieving}.

摘要：詞嵌入已被證明在處理絕大多數與自然語言處理相關的任務時會產生顯著的結果。不幸的是，詞嵌入也會捕捉到社會中普遍存在的刻板印象偏見，這會影響嵌入在下游任務中使用時的預測效能。雖然各種技術已被提出\cite{bolukbasi2016man, zhao2018learning}並因靜態嵌入而受到批評\cite{gonen2019lipstick}，但很少有工作專注於減輕情境嵌入中的偏見。在本文中，我們為 MLM（遮罩語言模型）提出了一個新穎的目標函數，它在很大程度上減輕了情境嵌入中的性別偏見，同時也保留了下游任務的效能。由於先前關於測量情境嵌入中偏見的研究缺乏規範性推理，我們還提出了新穎的評估指標，這些指標簡單明瞭，且符合我們在消除偏見方面的動機。我們還提出了新的方法來消除靜態嵌入的偏見，並通過廣泛的分析和實驗提供了經驗證據，說明靜態嵌入中偏見的主要來源來自刻板印象名稱，而不是性別化的詞彙本身。除非另有說明，否則所有研究的實驗和嵌入都使用英文。\citep{bender2011achieving}。

##### **Just Leaf It: Accelerating Diffusion Classifiers with Hierarchical Class Pruning**
2411.12073v1 by Arundhati S. Shanbhag, Brian B. Moser, Tobias C. Nauen, Stanislav Frolov, Federico Raue, Andreas Dengel

Diffusion models, known for their generative capabilities, have recently
shown unexpected potential in image classification tasks by using Bayes'
theorem. However, most diffusion classifiers require evaluating all class
labels for a single classification, leading to significant computational costs
that can hinder their application in large-scale scenarios. To address this, we
present a Hierarchical Diffusion Classifier (HDC) that exploits the inherent
hierarchical label structure of a dataset. By progressively pruning irrelevant
high-level categories and refining predictions only within relevant
subcategories, i.e., leaf nodes, HDC reduces the total number of class
evaluations. As a result, HDC can accelerate inference by up to 60% while
maintaining and, in some cases, improving classification accuracy. Our work
enables a new control mechanism of the trade-off between speed and precision,
making diffusion-based classification more viable for real-world applications,
particularly in large-scale image classification tasks.

摘要：扩散模型以其生成能力而闻名，最近通过使用贝叶斯定理在图像分类任务中展现了意想不到的潜力。然而，大多数扩散分类器需要为单个分类评估所有类别标签，这会导致巨大的计算成本，从而阻碍其在大规模场景中的应用。为了解决这个问题，我们提出了一个分层扩散分类器 (HDC)，它利用了数据集固有的分层标签结构。通过逐步剪枝不相关的类和仅在相关子类别（即叶节点）内优化预测，HDC 减少了类别评估的总数。因此，HDC 可以将推理加速高达 60%，同时保持，在某些情况下，提高分类准确度。我们的工作启用了一种新的权衡速度和精度的控制机制，使基于扩散的分类在现实世界应用中更具可行性，特别是在大规模图像分类任务中。

##### **Zoomed In, Diffused Out: Towards Local Degradation-Aware Multi-Diffusion for Extreme Image Super-Resolution**
2411.12072v1 by Brian B. Moser, Stanislav Frolov, Tobias C. Nauen, Federico Raue, Andreas Dengel

Large-scale, pre-trained Text-to-Image (T2I) diffusion models have gained
significant popularity in image generation tasks and have shown unexpected
potential in image Super-Resolution (SR). However, most existing T2I diffusion
models are trained with a resolution limit of 512x512, making scaling beyond
this resolution an unresolved but necessary challenge for image SR. In this
work, we introduce a novel approach that, for the first time, enables these
models to generate 2K, 4K, and even 8K images without any additional training.
Our method leverages MultiDiffusion, which distributes the generation across
multiple diffusion paths to ensure global coherence at larger scales, and local
degradation-aware prompt extraction, which guides the T2I model to reconstruct
fine local structures according to its low-resolution input. These innovations
unlock higher resolutions, allowing T2I diffusion models to be applied to image
SR tasks without limitation on resolution.

摘要：大規模預訓練的文字轉圖片 (T2I) 擴散模型在圖片生成任務中獲得顯著的普及，並在圖片超解析度 (SR) 中展現出意想不到的潛力。然而，現有的 T2I 擴散模型大多以 512x512 的解析度限制進行訓練，使得擴展到此解析度之外成為一個尚未解決但對於圖片 SR 而言必要的挑戰。在這項工作中，我們提出了一種新穎的方法，首次讓這些模型能夠在沒有任何額外訓練的情況下生成 2K、4K，甚至 8K 的圖片。我們的技術利用了多重擴散，將生成分布在多個擴散路徑上以確保大規模的整體一致性，以及局部降解感知提示提取，引導 T2I 模型根據其低解析度輸入重建精細的局部結構。這些創新解鎖了更高的解析度，讓 T2I 擴散模型可以應用於圖片 SR 任務，而沒有解析度的限制。

##### **TSPRank: Bridging Pairwise and Listwise Methods with a Bilinear Travelling Salesman Model**
2411.12064v1 by Weixian Waylon Li, Yftah Ziser, Yifei Xie, Shay B. Cohen, Tiejun Ma

Traditional Learning-To-Rank (LETOR) approaches, including pairwise methods
like RankNet and LambdaMART, often fall short by solely focusing on pairwise
comparisons, leading to sub-optimal global rankings. Conversely, deep learning
based listwise methods, while aiming to optimise entire lists, require complex
tuning and yield only marginal improvements over robust pairwise models. To
overcome these limitations, we introduce Travelling Salesman Problem Rank
(TSPRank), a hybrid pairwise-listwise ranking method. TSPRank reframes the
ranking problem as a Travelling Salesman Problem (TSP), a well-known
combinatorial optimisation challenge that has been extensively studied for its
numerous solution algorithms and applications. This approach enables the
modelling of pairwise relationships and leverages combinatorial optimisation to
determine the listwise ranking. This approach can be directly integrated as an
additional component into embeddings generated by existing backbone models to
enhance ranking performance. Our extensive experiments across three backbone
models on diverse tasks, including stock ranking, information retrieval, and
historical events ordering, demonstrate that TSPRank significantly outperforms
both pure pairwise and listwise methods. Our qualitative analysis reveals that
TSPRank's main advantage over existing methods is its ability to harness global
information better while ranking. TSPRank's robustness and superior performance
across different domains highlight its potential as a versatile and effective
LETOR solution. The code and preprocessed data are available at
https://github.com/waylonli/TSPRank-KDD2025.

摘要：傳統的學習排名 (LETOR) 方法，包括成對方法，例如 RankNet 和 LambdaMART，通常僅專注於成對比較，導致次優的全局排名。相反，基於深度學習的成列方法，雖然旨在優化整個清單，但需要複雜的調整，並且僅對穩健的成對模型產生邊際改進。為了克服這些限制，我們引入了旅行商問題排名 (TSPRank)，這是一種混合成對-成列排名方法。TSPRank 將排名問題重新定義為旅行商問題 (TSP)，這是一個眾所周知的組合優化挑戰，由於其眾多的解決演算法和應用而被廣泛研究。這種方法能夠對成對關係進行建模，並利用組合優化來確定成列排名。這種方法可以直接整合為現有主幹模型生成的嵌入中的附加組件，以增強排名效能。我們在三種主幹模型中進行了廣泛的實驗，涉及各種任務，包括股票排名、資訊檢索和歷史事件排序，結果表明 TSPRank 明顯優於純成對和成列方法。我們的質性分析表明，TSPRank 優於現有方法的主要優勢在於它在排名時能更好地利用全局資訊。TSPRank 在不同領域的穩健性和卓越效能突顯了其作為多功能且有效的 LETOR 解決方案的潛力。程式碼和預處理資料可在 https://github.com/waylonli/TSPRank-KDD2025 取得。

##### **Benchmarking pre-trained text embedding models in aligning built asset information**
2411.12056v1 by Mehrzad Shahinmoghadam, Ali Motamedi

Accurate mapping of the built asset information to established data
classification systems and taxonomies is crucial for effective asset
management, whether for compliance at project handover or ad-hoc data
integration scenarios. Due to the complex nature of built asset data, which
predominantly comprises technical text elements, this process remains largely
manual and reliant on domain expert input. Recent breakthroughs in contextual
text representation learning (text embedding), particularly through pre-trained
large language models, offer promising approaches that can facilitate the
automation of cross-mapping of the built asset data. However, no comprehensive
evaluation has yet been conducted to assess these models' ability to
effectively represent the complex semantics specific to built asset technical
terminology. This study presents a comparative benchmark of state-of-the-art
text embedding models to evaluate their effectiveness in aligning built asset
information with domain-specific technical concepts. Our proposed datasets are
derived from two renowned built asset data classification dictionaries. The
results of our benchmarking across six proposed datasets, covering three tasks
of clustering, retrieval, and reranking, highlight the need for future research
on domain adaptation techniques. The benchmarking resources are published as an
open-source library, which will be maintained and extended to support future
evaluations in this field.

摘要：準確地將已建立資料分類系統和分類法中的建成資產資訊對應起來，對於有效的資產管理至關重要，無論是專案移交時的合規性或特別資料整合情況。由於建成資產資料的複雜性，其中主要包含技術性文字元素，此程序在很大程度上仍然是手動的，且仰賴領域專家的輸入。語境文字表徵學習（文字嵌入）的最新突破，特別是透過預先訓練的大語言模型，提供了有希望的方法，可以促進建成資產資料的交叉對應自動化。然而，尚未進行全面評估來評估這些模型有效表徵與建成資產技術術語相關之複雜語意的能力。本研究提供了最先進文字嵌入模型的比較基準，以評估它們在將建成資產資訊與特定領域技術概念對齊方面的有效性。我們提出的資料集取自兩個著名的建成資產資料分類辭典。我們在六個提議的資料集上進行基準測試的結果，涵蓋群集、檢索和重新排序的 3 項任務，突顯了未來對領域適應技術進行研究的必要性。基準測試資源以開源程式庫的形式發布，將會持續維護和擴充，以支援此領域未來的評估。

##### **Scaling Deep Learning Research with Kubernetes on the NRP Nautilus HyperCluster**
2411.12038v1 by J. Alex Hurt, Anes Ouadou, Mariam Alshehri, Grant J. Scott

Throughout the scientific computing space, deep learning algorithms have
shown excellent performance in a wide range of applications. As these deep
neural networks (DNNs) continue to mature, the necessary compute required to
train them has continued to grow. Today, modern DNNs require millions of FLOPs
and days to weeks of training to generate a well-trained model. The training
times required for DNNs are oftentimes a bottleneck in DNN research for a
variety of deep learning applications, and as such, accelerating and scaling
DNN training enables more robust and accelerated research. To that end, in this
work, we explore utilizing the NRP Nautilus HyperCluster to automate and scale
deep learning model training for three separate applications of DNNs, including
overhead object detection, burned area segmentation, and deforestation
detection. In total, 234 deep neural models are trained on Nautilus, for a
total time of 4,040 hours

摘要：在整個科學運算領域中，深度學習演算法已在廣泛的應用中展現出色的效能。隨著這些深度神經網路 (DNN) 持續成熟，訓練它們所需的必要運算也持續增加。如今，現代 DNN 需要數百萬次浮點運算 (FLOP) 和數天到數週的訓練時間，才能產生訓練完善的模型。DNN 所需的訓練時間通常是各種深度學習應用中 DNN 研究的瓶頸，因此，加速和擴充 DNN 訓練可以促進更強健且更快速的研發。為此，我們在這項工作中探索利用 NRP Nautilus HyperCluster 自動化並擴充深度學習模型訓練，以適用於 DNN 的三個獨立應用，包括架空物件偵測、燒毀區域分割和森林砍伐偵測。總計在 Nautilus 上訓練了 234 個深度神經模型，總時數為 4,040 小時

##### **Regret-Free Reinforcement Learning for LTL Specifications**
2411.12019v1 by Rupak Majumdar, Mahmoud Salamati, Sadegh Soudjani

Reinforcement learning (RL) is a promising method to learn optimal control
policies for systems with unknown dynamics. In particular, synthesizing
controllers for safety-critical systems based on high-level specifications,
such as those expressed in temporal languages like linear temporal logic (LTL),
presents a significant challenge in control systems research. Current RL-based
methods designed for LTL tasks typically offer only asymptotic guarantees,
which provide no insight into the transient performance during the learning
phase. While running an RL algorithm, it is crucial to assess how close we are
to achieving optimal behavior if we stop learning.
  In this paper, we present the first regret-free online algorithm for learning
a controller that addresses the general class of LTL specifications over Markov
decision processes (MDPs) with a finite set of states and actions. We begin by
proposing a regret-free learning algorithm to solve infinite-horizon
reach-avoid problems. For general LTL specifications, we show that the
synthesis problem can be reduced to a reach-avoid problem when the graph
structure is known. Additionally, we provide an algorithm for learning the
graph structure, assuming knowledge of a minimum transition probability, which
operates independently of the main regret-free algorithm.

摘要：強化學習 (RL) 是一種有希望的方法，可以學習未知動態系統的最佳控制策略。特別是，基於高階規範（例如用線性時序邏輯 (LTL) 等時序語言表達的規範）為安全關鍵系統合成控制器，這在控制系統研究中是一個重大挑戰。目前的基於 RL 的 LTL 任務方法通常僅提供漸近保證，這在學習階段沒有提供暫態效能的見解。在執行 RL 演算法時，如果我們停止學習，評估我們距離達成最佳行為有多近至關重要。在本文中，我們提出了第一個無遺憾線上演算法，用於學習一個控制器，該控制器解決了馬可夫決策過程 (MDP) 上的一般類別 LTL 規範，其中包含有限的狀態和動作集合。我們首先提出一個無遺憾學習演算法來解決無限時域到達避免問題。對於一般 LTL 規範，我們表明當圖形結構已知時，合成問題可以簡化為到達避免問題。此外，我們提供了一個演算法來學習圖形結構，假設知道最小轉移機率，它獨立於主要的無遺憾演算法運作。

##### **ByteScience: Bridging Unstructured Scientific Literature and Structured Data with Auto Fine-tuned Large Language Model in Token Granularity**
2411.12000v1 by Tong Xie, Hanzhi Zhang, Shaozhou Wang, Yuwei Wan, Imran Razzak, Chunyu Kit, Wenjie Zhangand Bram Hoex

Natural Language Processing (NLP) is widely used to supply summarization
ability from long context to structured information. However, extracting
structured knowledge from scientific text by NLP models remains a challenge
because of its domain-specific nature to complex data preprocessing and the
granularity of multi-layered device-level information. To address this, we
introduce ByteScience, a non-profit cloud-based auto fine-tuned Large Language
Model (LLM) platform, which is designed to extract structured scientific data
and synthesize new scientific knowledge from vast scientific corpora. The
platform capitalizes on DARWIN, an open-source, fine-tuned LLM dedicated to
natural science. The platform was built on Amazon Web Services (AWS) and
provides an automated, user-friendly workflow for custom model development and
data extraction. The platform achieves remarkable accuracy with only a small
amount of well-annotated articles. This innovative tool streamlines the
transition from the science literature to structured knowledge and data and
benefits the advancements in natural informatics.

摘要：自然語言處理 (NLP) 廣泛用於提供從長文到結構化資訊的摘要能力。然而，由於其特定領域的性質，複雜的資料前處理和多層級裝置層級資訊的粒度，透過 NLP 模型從科學文本中萃取結構化知識仍然是一個挑戰。為了解決這個問題，我們引進了 ByteScience，一個非營利的雲端自動微調大型語言模型 (LLM) 平台，它被設計用來從大量的科學語料庫中萃取結構化的科學資料，並綜合新的科學知識。這個平台利用了 DARWIN，一個開放原始碼的微調 LLM，專門用於自然科學。這個平台建置於亞馬遜網路服務 (AWS) 上，並提供了一個自動化、使用者友善的工作流程，用於自訂模型開發和資料萃取。這個平台僅透過少量的良好註解文章就達到了顯著的準確度。這個創新的工具簡化了從科學文獻到結構化知識和資料的轉換，並對自然資訊學的進展有益。

##### **Understanding Chain-of-Thought in LLMs through Information Theory**
2411.11984v1 by Jean-Francois Ton, Muhammad Faaiz Taufiq, Yang Liu

Large Language Models (LLMs) have shown impressive performance in complex
reasoning tasks through Chain-of-Thought (CoT) reasoning, allowing models to
break down problems into manageable sub-tasks. However, existing CoT evaluation
techniques either require annotated CoT data or fall short in accurately
assessing intermediate reasoning steps, leading to high rates of false
positives. In this paper, we formalize CoT reasoning in LLMs through an
information-theoretic lens. Specifically, our framework quantifies the
`information gain' at each reasoning step, enabling the identification of
failure modes in LLMs without the need for expensive annotated datasets. We
demonstrate the efficacy of our approach through extensive experiments on toy
and GSM-8K data, where it significantly outperforms existing outcome-based
methods by providing more accurate insights into model performance on
individual tasks.

摘要：大型語言模型 (LLM) 已透過思考鏈 (CoT) 推理在複雜推理任務中展現驚人的效能，讓模型能將問題分解成可管理的子任務。然而，現有的 CoT 評估技術需要標記的 CoT 資料，或無法準確評估中間推理步驟，導致大量的假陽性。在本文中，我們透過資訊理論的觀點形式化 LLM 中的 CoT 推理。具體來說，我們的架構量化了每個推理步驟的「資訊增益」，讓無需昂貴的標記資料集也能找出 LLM 的失敗模式。我們透過玩具和 GSM-8K 資料上的廣泛實驗證明了我們方法的效能，它透過提供更準確的見解，在個別任務上大幅優於現有的基於結果的方法。

##### **Bi-Mamba: Towards Accurate 1-Bit State Space Models**
2411.11843v1 by Shengkun Tang, Liqun Ma, Haonan Li, Mingjie Sun, Zhiqiang Shen

The typical selective state-space model (SSM) of Mamba addresses several
limitations of Transformers, such as quadratic computational complexity with
sequence length and significant inference-time memory requirements due to the
key-value cache. However, the growing size of Mamba models continues to pose
training and deployment challenges and raises environmental concerns due to
considerable energy consumption. In this work, we introduce Bi-Mamba, a
scalable and powerful 1-bit Mamba architecture designed for more efficient
large language models with multiple sizes across 780M, 1.3B, and 2.7B. Bi-Mamba
models are trained from scratch on data volume as regular LLM pertaining using
an autoregressive distillation loss. Extensive experimental results on language
modeling demonstrate that Bi-Mamba achieves performance comparable to its
full-precision counterparts (e.g., FP16 or BF16) and much better accuracy than
post-training-binarization (PTB) Mamba baselines, while significantly reducing
memory footprint and energy consumption compared to the original Mamba model.
Our study pioneers a new linear computational complexity LLM framework under
low-bit representation and facilitates the future design of specialized
hardware tailored for efficient 1-bit Mamba-based LLMs.

摘要：典型的 Mamba 選擇性狀態空間模型 (SSM) 處理了 Transformer 的幾個限制，例如二次計算複雜度與序列長度和由於鍵值快取而導致的顯著推論時間記憶體需求。然而，Mamba 模型日益增長的規模持續對訓練和部署造成挑戰，並由於可觀的能耗而引發環境問題。在這項工作中，我們介紹了 Bi-Mamba，一種可擴充且強大的 1 位元 Mamba 架構，針對更有效率的大型語言模型而設計，具有 780M、1.3B 和 2.7B 等多種大小。Bi-Mamba 模型從頭開始訓練，資料量與使用自迴歸蒸餾損失相關的常規 LLM 相同。語言建模的廣泛實驗結果證明，與其全精度對應物（例如 FP16 或 BF16）相比，Bi-Mamba 達到了相當的效能，而且比訓練後二元化 (PTB) Mamba 基準的準確度高出許多，同時與原始 Mamba 模型相比，顯著減少了記憶體佔用空間和能耗。我們的研究開創了一個新的線性計算複雜度 LLM 框架，在低位元表示下，並促進了針對有效率的 1 位元 Mamba 基礎 LLM 而量身打造的專用硬體的未來設計。

##### **Tackling prediction tasks in relational databases with LLMs**
2411.11829v1 by Marek Wydmuch, Łukasz Borchmann, Filip Graliński

Though large language models (LLMs) have demonstrated exceptional performance
across numerous problems, their application to predictive tasks in relational
databases remains largely unexplored. In this work, we address the notion that
LLMs cannot yield satisfactory results on relational databases due to their
interconnected tables, complex relationships, and heterogeneous data types.
Using the recently introduced RelBench benchmark, we demonstrate that even a
straightforward application of LLMs achieves competitive performance on these
tasks. These findings establish LLMs as a promising new baseline for ML on
relational databases and encourage further research in this direction.

摘要：儘管大型語言模型（LLM）在許多問題上都展現出非凡的效能，但它們在關係資料庫中預測任務上的應用仍未廣泛探討。在這項研究中，我們探討了 LLM 無法在關係資料庫上產生令人滿意結果的觀念，原因是其相互連結的表格、複雜的關係和異質資料類型。使用最近推出的 RelBench 評量基準，我們證明即使是 LLM 的直接應用，也能在這些任務上達到有競爭力的效能。這些發現確立了 LLM 作為關係資料庫上機器學習有前途的新基準，並鼓勵朝此方向進行進一步的研究。

##### **LightFFDNets: Lightweight Convolutional Neural Networks for Rapid Facial Forgery Detection**
2411.11826v1 by Günel Jabbarlı, Murat Kurt

Accurate and fast recognition of forgeries is an issue of great importance in
the fields of artificial intelligence, image processing and object detection.
Recognition of forgeries of facial imagery is the process of classifying and
defining the faces in it by analyzing real-world facial images. This process is
usually accomplished by extracting features from an image, using classifier
algorithms, and correctly interpreting the results. Recognizing forgeries of
facial imagery correctly can encounter many different challenges. For example,
factors such as changing lighting conditions, viewing faces from different
angles can affect recognition performance, and background complexity and
perspective changes in facial images can make accurate recognition difficult.
Despite these difficulties, significant progress has been made in the field of
forgery detection. Deep learning algorithms, especially Convolutional Neural
Networks (CNNs), have significantly improved forgery detection performance.
  This study focuses on image processing-based forgery detection using
Fake-Vs-Real-Faces (Hard) [10] and 140k Real and Fake Faces [61] data sets.
Both data sets consist of two classes containing real and fake facial images.
In our study, two lightweight deep learning models are proposed to conduct
forgery detection using these images. Additionally, 8 different pretrained CNN
architectures were tested on both data sets and the results were compared with
newly developed lightweight CNN models. It's shown that the proposed
lightweight deep learning models have minimum number of layers. It's also shown
that the proposed lightweight deep learning models detect forgeries of facial
imagery accurately, and computationally efficiently. Although the data set
consists only of face images, the developed models can also be used in other
two-class object recognition problems.

摘要：<paragraph>準確快速地辨識偽造品在人工智能、影像處理和物件偵測領域中是一個非常重要的議題。辨識臉部影像的偽造品是透過分析真實世界的臉部影像來分類和定義其中的臉孔。這個程序通常會從影像中萃取特徵、使用分類器演算法，並正確地詮釋結果。正確地辨識臉部影像的偽造品可能會遭遇許多不同的挑戰。例如，光線條件改變、從不同角度觀看臉孔等因素可能會影響辨識效能，而且背景複雜度和臉部影像中的透視變化可能會讓準確辨識變得困難。儘管有這些困難，偽造品偵測領域中已經有顯著的進展。深度學習演算法，特別是卷積神經網路 (CNN)，已經顯著地改善偽造品偵測效能。本研究專注於使用 Fake-Vs-Real-Faces (Hard) [10] 和 140k Real and Fake Faces [61] 資料集的基於影像處理的偽造品偵測。兩個資料集都包含兩個類別，其中包含真實和假的臉部影像。在我們的研究中，提出了兩個輕量級深度學習模型來使用這些影像進行偽造品偵測。此外，在兩個資料集上測試了 8 種不同的預訓練 CNN 架構，並將結果與新開發的輕量級 CNN 模型進行比較。結果顯示，所提出的輕量級深度學習模型具有最少的層數。結果也顯示，所提出的輕量級深度學習模型可以準確地偵測臉部影像的偽造品，而且計算效率高。儘管資料集僅包含臉部影像，但已開發的模型也可以用於其他兩類別的物件辨識問題。</paragraph>

##### **Medical Video Generation for Disease Progression Simulation**
2411.11943v1 by Xu Cao, Kaizhao Liang, Kuei-Da Liao, Tianren Gao, Wenqian Ye, Jintai Chen, Zhiguang Ding, Jianguo Cao, James M. Rehg, Jimeng Sun

Modeling disease progression is crucial for improving the quality and
efficacy of clinical diagnosis and prognosis, but it is often hindered by a
lack of longitudinal medical image monitoring for individual patients. To
address this challenge, we propose the first Medical Video Generation (MVG)
framework that enables controlled manipulation of disease-related image and
video features, allowing precise, realistic, and personalized simulations of
disease progression. Our approach begins by leveraging large language models
(LLMs) to recaption prompt for disease trajectory. Next, a controllable
multi-round diffusion model simulates the disease progression state for each
patient, creating realistic intermediate disease state sequence. Finally, a
diffusion-based video transition generation model interpolates disease
progression between these states. We validate our framework across three
medical imaging domains: chest X-ray, fundus photography, and skin image. Our
results demonstrate that MVG significantly outperforms baseline models in
generating coherent and clinically plausible disease trajectories. Two user
studies by veteran physicians, provide further validation and insights into the
clinical utility of the generated sequences. MVG has the potential to assist
healthcare providers in modeling disease trajectories, interpolating missing
medical image data, and enhancing medical education through realistic, dynamic
visualizations of disease progression.

摘要：疾病進程建模對於提升臨床診斷和預後的品質和效能至關重要，但通常會受到缺乏針對個別患者的縱向醫學影像監測的阻礙。為了應對此挑戰，我們提出第一個醫學影片生成 (MVG) 架構，它能控制操作與疾病相關的影像和影片特徵，允許精確、逼真且客製化的疾病進程模擬。我們的做法首先利用大型語言模型 (LLM) 來重新標記疾病軌跡的提示。接下來，可控制的多輪擴散模型會模擬每個患者的疾病進程狀態，建立逼真的中間疾病狀態序列。最後，基於擴散的影片轉換生成模型會內插這些狀態之間的疾病進程。我們在三個醫學影像領域驗證了我們的架構：胸部 X 光、眼底攝影和皮膚影像。我們的結果證明，MVG 在生成連貫且臨床上合理的疾病軌跡方面顯著優於基準模型。兩項由資深醫師進行的使用者研究進一步驗證並深入探討了生成序列的臨床效用。MVG 有潛力協助醫療保健提供者建模疾病軌跡、內插遺失的醫學影像資料，並透過逼真、動態的疾病進程視覺化來加強醫學教育。

##### **Edge-Enhanced Dilated Residual Attention Network for Multimodal Medical Image Fusion**
2411.11799v1 by Meng Zhou, Yuxuan Zhang, Xiaolan Xu, Jiayi Wang, Farzad Khalvati

Multimodal medical image fusion is a crucial task that combines complementary
information from different imaging modalities into a unified representation,
thereby enhancing diagnostic accuracy and treatment planning. While deep
learning methods, particularly Convolutional Neural Networks (CNNs) and
Transformers, have significantly advanced fusion performance, some of the
existing CNN-based methods fall short in capturing fine-grained multiscale and
edge features, leading to suboptimal feature integration. Transformer-based
models, on the other hand, are computationally intensive in both the training
and fusion stages, making them impractical for real-time clinical use.
Moreover, the clinical application of fused images remains unexplored. In this
paper, we propose a novel CNN-based architecture that addresses these
limitations by introducing a Dilated Residual Attention Network Module for
effective multiscale feature extraction, coupled with a gradient operator to
enhance edge detail learning. To ensure fast and efficient fusion, we present a
parameter-free fusion strategy based on the weighted nuclear norm of softmax,
which requires no additional computations during training or inference.
Extensive experiments, including a downstream brain tumor classification task,
demonstrate that our approach outperforms various baseline methods in terms of
visual quality, texture preservation, and fusion speed, making it a possible
practical solution for real-world clinical applications. The code will be
released at https://github.com/simonZhou86/en_dran.

摘要：多模态医学图像融合是一项至关重要的任务，它将来自不同成像方式的互补信息融合到一个统一的表示中，从而提高诊断准确性和治疗计划。虽然深度学习方法，尤其是卷积神经网络 (CNN) 和 Transformer，已经显著提升了融合性能，但一些现有的基于 CNN 的方法在捕捉细粒度多尺度和边缘特征方面存在不足，导致次优特征集成。另一方面，基于 Transformer 的模型在训练和融合阶段计算量很大，这使得它们不适用于实时临床使用。此外，融合图像的临床应用仍未得到探索。在本文中，我们提出了一种新颖的基于 CNN 的架构，通过引入膨胀残差注意力网络模块来解决这些限制，以进行有效的多分辨率特征提取，并结合梯度算子来增强边缘细节学习。为了确保快速而高效的融合，我们提出了一种基于 softmax 的加权核范数的参数化融合策略，它在训练或推理过程中不需要额外的计算。广泛的实验，包括下游脑肿瘤分类任务，表明我们的方法在视觉质量、纹理保留和融合速度方面优于各种基准方法，使其成为现实世界临床应用的可能实用解决方案。代码将在 https://github.com/simonZhou86/en_dran 发布。

##### **Exploring adversarial robustness of JPEG AI: methodology, comparison and new methods**
2411.11795v1 by Egor Kovalev, Georgii Bychkov, Khaled Abud, Aleksandr Gushchin, Anna Chistyakova, Sergey Lavrushkin, Dmitriy Vatolin, Anastasia Antsiferova

Adversarial robustness of neural networks is an increasingly important area
of research, combining studies on computer vision models, large language models
(LLMs), and others. With the release of JPEG AI - the first standard for
end-to-end neural image compression (NIC) methods - the question of its
robustness has become critically significant. JPEG AI is among the first
international, real-world applications of neural-network-based models to be
embedded in consumer devices. However, research on NIC robustness has been
limited to open-source codecs and a narrow range of attacks. This paper
proposes a new methodology for measuring NIC robustness to adversarial attacks.
We present the first large-scale evaluation of JPEG AI's robustness, comparing
it with other NIC models. Our evaluation results and code are publicly
available online (link is hidden for a blind review).

摘要：神經網路對抗攻擊的穩健性是一個日益重要的研究領域，結合了電腦視覺模型、大型語言模型 (LLM) 等方面的研究。隨著 JPEG AI 的發布，JPEG AI 是第一個端到端神經影像壓縮 (NIC) 方法標準，其穩健性問題變得至關重要。JPEG AI 是第一批將基於神經網路的模型應用於國際現實世界並嵌入消費者裝置的應用程式。然而，關於 NIC 穩健性的研究僅限於開源編解碼器和範圍狹窄的攻擊。本文提出了一種新的方法來衡量 NIC 對抗攻擊的穩健性。我們展示了 JPEG AI 穩健性的第一次大規模評估，並將其與其他 NIC 模型進行比較。我們的評估結果和程式碼已公開在網路上（連結因盲審而隱藏）。

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

摘要：隨著人工智慧 (AI) 模型變得越來越複雜，且越來越難以被人理解，了解數位系統如何支援臨床決策的需求也日益增加。這種複雜性引發了對可信度的疑慮，影響了此類技術的安全且有效採用。改善對決策制定流程的理解，以及對決策支援工具所提供說明的要求，是提供有效可解釋解決方案的重要組成部分。這在資料密集、快節奏的加護病房 (ICU) 環境中特別相關。為了探討這些問題，對七位 ICU 臨床醫師進行了小組訪談，這些醫師代表了不同的角色和經驗層級。主題分析揭露了三個核心主題：(T1) ICU 決策制定依賴於廣泛的因素，(T2) 病患狀態的複雜性對共同決策制定構成挑戰，以及 (T3) AI 決策支援系統的要求和能力。我們納入了臨床輸入的設計建議，提供見解以提供資訊給未來用於加護的 AI 系統。

##### **CNMBert: A Model For Hanyu Pinyin Abbreviation to Character Conversion Task**
2411.11770v1 by Zishuo Feng, Feng Cao

The task of converting Hanyu Pinyin abbreviations to Chinese characters
represents a significant branch within the domain of Chinese Spelling
Correction (CSC). This task is typically one of text-length alignment, however,
due to the limited informational content in pinyin abbreviations, achieving
accurate conversion is challenging. In this paper, we propose CNMBert which
stands for zh-CN Pinyin Multi-mask Bert Model as a solution to this issue.
CNMBert surpasses few-shot GPT models, achieving a 59.63% MRR on a
10,424-sample Hanyu Pinyin abbreviation test dataset.

摘要：將漢語拼音縮寫轉換為中文字元的任務代表了中文拼寫糾正 (CSC) 領域中的重要分支。然而，由於拼音縮寫中資訊含量有限，此任務通常是文本長度對齊，因此要達到準確轉換具有挑戰性。在本文中，我們提出 CNMBert，代表 zh-CN Pinyin Multi-mask Bert 模型，作為解決此問題的方法。CNMBert 超越了少次數 GPT 模型，在 10,424 個樣本的漢語拼音縮寫測試資料集上達到了 59.63% 的 MRR。

##### **The Power of Many: Multi-Agent Multimodal Models for Cultural Image Captioning**
2411.11758v1 by Longju Bai, Angana Borah, Oana Ignat, Rada Mihalcea

Large Multimodal Models (LMMs) exhibit impressive performance across various
multimodal tasks. However, their effectiveness in cross-cultural contexts
remains limited due to the predominantly Western-centric nature of most data
and models. Conversely, multi-agent models have shown significant capability in
solving complex tasks. Our study evaluates the collective performance of LMMs
in a multi-agent interaction setting for the novel task of cultural image
captioning. Our contributions are as follows: (1) We introduce MosAIC, a
Multi-Agent framework to enhance cross-cultural Image Captioning using LMMs
with distinct cultural personas; (2) We provide a dataset of culturally
enriched image captions in English for images from China, India, and Romania
across three datasets: GeoDE, GD-VCR, CVQA; (3) We propose a culture-adaptable
metric for evaluating cultural information within image captions; and (4) We
show that the multi-agent interaction outperforms single-agent models across
different metrics, and offer valuable insights for future research. Our dataset
and models can be accessed at https://github.com/MichiganNLP/MosAIC.

摘要：大型多模态模型 (LMM) 在各种多模态任务中表现出色。然而，由于大多数数据和模型本质上以西方为中心，它们在跨文化环境中的有效性仍然受到限制。相反，多主体模型在解决复杂任务方面显示出显著的能力。我们的研究评估了 LMM 在多主体交互设置中对文化图像字幕的新颖任务的集体表现。我们的贡献如下：(1) 我们引入了 MosAIC，一个多主体框架，使用具有不同文化角色的 LMM 增强跨文化图像字幕；(2) 我们提供了一个数据集，其中包含来自中国、印度和罗马尼亚的图像的文化丰富的图像字幕，跨越三个数据集：GeoDE、GD-VCR、CVQA；(3) 我们提出了一个文化适应性指标，用于评估图像字幕中的文化信息；(4) 我们表明，多主体交互在不同指标上优于单主体模型，并为未来的研究提供了宝贵的见解。我们的数据集和模型可在 https://github.com/MichiganNLP/MosAIC 获得。

##### **Variable Rate Neural Compression for Sparse Detector Data**
2411.11942v1 by Yi Huang, Yeonju Go, Jin Huang, Shuhang Li, Xihaier Luo, Thomas Marshall, Joseph Osborn, Christopher Pinkenburg, Yihui Ren, Evgeny Shulga, Shinjae Yoo, Byung-Jun Yoon

High-energy large-scale particle colliders generate data at extraordinary
rates. Developing real-time high-throughput data compression algorithms to
reduce data volume and meet the bandwidth requirement for storage has become
increasingly critical. Deep learning is a promising technology that can address
this challenging topic. At the newly constructed sPHENIX experiment at the
Relativistic Heavy Ion Collider, a Time Projection Chamber (TPC) serves as the
main tracking detector, which records three-dimensional particle trajectories
in a volume of a gas-filled cylinder. In terms of occupancy, the resulting data
flow can be very sparse reaching $10^{-3}$ for proton-proton collisions. Such
sparsity presents a challenge to conventional learning-free lossy compression
algorithms, such as SZ, ZFP, and MGARD. In contrast, emerging deep
learning-based models, particularly those utilizing convolutional neural
networks for compression, have outperformed these conventional methods in terms
of compression ratios and reconstruction accuracy. However, research on the
efficacy of these deep learning models in handling sparse datasets, like those
produced in particle colliders, remains limited. Furthermore, most deep
learning models do not adapt their processing speeds to data sparsity, which
affects efficiency. To address this issue, we propose a novel approach for TPC
data compression via key-point identification facilitated by sparse
convolution. Our proposed algorithm, BCAE-VS, achieves a $75\%$ improvement in
reconstruction accuracy with a $10\%$ increase in compression ratio over the
previous state-of-the-art model. Additionally, BCAE-VS manages to achieve these
results with a model size over two orders of magnitude smaller. Lastly, we have
experimentally verified that as sparsity increases, so does the model's
throughput.

摘要：高能大型粒子對撞機以驚人的速率產生資料。開發實時高通量資料壓縮演算法以減少資料量，並滿足儲存頻寬需求已變得越來越重要。深度學習是一種有前途的技術，可以解決這個具有挑戰性的主題。在相對論重離子對撞機的新建 sPHENIX 實驗中，時間投影室 (TPC) 充當主追蹤偵測器，它在充滿氣體的圓柱體中記錄三維粒子軌跡。在佔用率方面，產生的資料流可能非常稀疏，對於質子-質子碰撞，可以達到 $10^{-3}$。這種稀疏性對傳統的無學習有損壓縮演算法（例如 SZ、ZFP 和 MGARD）提出了挑戰。相比之下，新興的基於深度學習的模型（特別是那些利用卷積神經網路進行壓縮的模型）在壓縮比和重建準確性方面優於這些傳統方法。然而，這些深度學習模型在處理稀疏資料集（例如粒子對撞機中產生的資料集）方面的效能研究仍然有限。此外，大多數深度學習模型並未根據資料稀疏性調整其處理速度，這會影響效率。為了解決這個問題，我們提出了一種通過稀疏卷積促進關鍵點識別的 TPC 資料壓縮新方法。我們提出的演算法 BCAE-VS 在重建準確性方面提高了 $75\%$，壓縮比比之前的最先進模型提高了 $10\%$。此外，BCAE-VS 成功的以小兩個數量級的模型大小實現了這些結果。最後，我們已經通過實驗驗證，隨著稀疏性的增加，模型的吞吐量也會增加。

##### **QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou**
2411.11739v1 by Xinchen Luo, Jiangxia Cao, Tianyu Sun, Jinkai Yu, Rui Huang, Wei Yuan, Hezheng Lin, Yichen Zheng, Shiyao Wang, Qigen Hu, Changqing Qiu, Jiaqi Zhang, Xu Zhang, Zhiheng Yan, Jingming Zhang, Simin Zhang, Mingxing Wen, Zhaojie Liu, Kun Gai, Guorui Zhou

In recent years, with the significant evolution of multi-modal large models,
many recommender researchers realized the potential of multi-modal information
for user interest modeling. In industry, a wide-used modeling architecture is a
cascading paradigm: (1) first pre-training a multi-modal model to provide
omnipotent representations for downstream services; (2) The downstream
recommendation model takes the multi-modal representation as additional input
to fit real user-item behaviours. Although such paradigm achieves remarkable
improvements, however, there still exist two problems that limit model
performance: (1) Representation Unmatching: The pre-trained multi-modal model
is always supervised by the classic NLP/CV tasks, while the recommendation
models are supervised by real user-item interaction. As a result, the two
fundamentally different tasks' goals were relatively separate, and there was a
lack of consistent objective on their representations; (2) Representation
Unlearning: The generated multi-modal representations are always stored in
cache store and serve as extra fixed input of recommendation model, thus could
not be updated by recommendation model gradient, further unfriendly for
downstream training. Inspired by the two difficulties challenges in downstream
tasks usage, we introduce a quantitative multi-modal framework to customize the
specialized and trainable multi-modal information for different downstream
models.

摘要：近年來，隨著多模態大型模型的顯著演進，
許多推薦研究者體認到多模態資訊在使用者興趣建模上的潛力。在產業中，一個廣為使用的建模架構為
串接式範例：(1) 首先預訓練一個多模態模型，以提供下游服務的全能表示；(2) 下游推薦模型將多模態表示作為額外輸入，以符合真實使用者-項目行為。儘管此範例獲得顯著的進步，然而，仍存在兩個限制模型效能的問題：(1) 表示不匹配：預訓練的多模態模型總是受到傳統 NLP/CV 任務的監督，而推薦模型則受到真實使用者-項目互動的監督。因此，這兩個根本不同的任務目標相對獨立，並且它們的表示缺乏一致的目標；(2) 表示遺忘：產生的多模態表示總是儲存在快取儲存區中，並作為推薦模型的額外固定輸入，因此無法由推薦模型梯度更新，進一步不利於下游訓練。受到下游任務使用中的兩個困難挑戰啟發，我們引入一個量化的多模態框架，以自訂特定且可訓練的多模態資訊，供不同的下游模型使用。

##### **WoodYOLO: A Novel Object Detector for Wood Species Detection in Microscopic Images**
2411.11738v1 by Lars Nieradzik, Henrike Stephani, Jördis Sieburg-Rockel, Stephanie Helmling, Andrea Olbrich, Stephanie Wrage, Janis Keuper

Wood species identification plays a crucial role in various industries, from
ensuring the legality of timber products to advancing ecological conservation
efforts. This paper introduces WoodYOLO, a novel object detection algorithm
specifically designed for microscopic wood fiber analysis. Our approach adapts
the YOLO architecture to address the challenges posed by large, high-resolution
microscopy images and the need for high recall in localization of the cell type
of interest (vessel elements). Our results show that WoodYOLO significantly
outperforms state-of-the-art models, achieving performance gains of 12.9% and
6.5% in F2 score over YOLOv10 and YOLOv7, respectively. This improvement in
automated wood cell type localization capabilities contributes to enhancing
regulatory compliance, supporting sustainable forestry practices, and promoting
biodiversity conservation efforts globally.

摘要：木材種類辨識在各產業中扮演著至關重要的角色，從確保木材產品的合法性到促進生態保育工作。本文介紹 WoodYOLO，一種專為微觀木材纖維分析而設計的新型物件偵測演算法。我們的做法是調整 YOLO 架構以應對大型高解析度顯微影像所帶來的挑戰，以及在定位目標細胞類型（管胞元素）時對高召回率的需求。我們的結果顯示，WoodYOLO 的表現明顯優於現有技術模型，在 F2 分數上分別較 YOLOv10 和 YOLOv7 提升了 12.9% 和 6.5%。自動化木材細胞類型定位能力的提升有助於加強法規遵循、支持永續林業實務，並在全球推動生物多樣性保育工作。

##### **Moral Persuasion in Large Language Models: Evaluating Susceptibility and Ethical Alignment**
2411.11731v1 by Allison Huang, Yulu Niki Pi, Carlos Mougan

We explore how large language models (LLMs) can be influenced by prompting
them to alter their initial decisions and align them with established ethical
frameworks. Our study is based on two experiments designed to assess the
susceptibility of LLMs to moral persuasion. In the first experiment, we examine
the susceptibility to moral ambiguity by evaluating a Base Agent LLM on morally
ambiguous scenarios and observing how a Persuader Agent attempts to modify the
Base Agent's initial decisions. The second experiment evaluates the
susceptibility of LLMs to align with predefined ethical frameworks by prompting
them to adopt specific value alignments rooted in established philosophical
theories. The results demonstrate that LLMs can indeed be persuaded in morally
charged scenarios, with the success of persuasion depending on factors such as
the model used, the complexity of the scenario, and the conversation length.
Notably, LLMs of distinct sizes but from the same company produced markedly
different outcomes, highlighting the variability in their susceptibility to
ethical persuasion.

摘要：我們探討大型語言模型 (LLM) 如何透過提示來改變其最初的決定，並使其與既定的道德框架保持一致。我們的研究基於兩個實驗，旨在評估 LLM 對道德說服的敏感性。在第一個實驗中，我們透過評估基礎代理人 LLM 在道德模糊情境中的表現，並觀察說服者代理人如何嘗試修改基礎代理人的初始決定，來探討對道德模糊性的敏感性。第二個實驗評估了 LLM 與預定義道德框架保持一致的敏感性，方法是提示他們採用根植於既定哲學理論的特定價值觀。結果表明，LLM 確實可以在道德情境中受到說服，說服的成功取決於模型、情境的複雜性和對話長度等因素。值得注意的是，來自同一家公司的不同規模的 LLM 產生了顯著不同的結果，突顯了它們對道德說服的敏感性存在差異。

##### **Lifted Model Construction without Normalisation: A Vectorised Approach to Exploit Symmetries in Factor Graphs**
2411.11730v1 by Malte Luttermann, Ralf Möller, Marcel Gehrke

Lifted probabilistic inference exploits symmetries in a probabilistic model
to allow for tractable probabilistic inference with respect to domain sizes of
logical variables. We found that the current state-of-the-art algorithm to
construct a lifted representation in form of a parametric factor graph misses
symmetries between factors that are exchangeable but scaled differently,
thereby leading to a less compact representation. In this paper, we propose a
generalisation of the advanced colour passing (ACP) algorithm, which is the
state of the art to construct a parametric factor graph. Our proposed algorithm
allows for potentials of factors to be scaled arbitrarily and efficiently
detects more symmetries than the original ACP algorithm. By detecting strictly
more symmetries than ACP, our algorithm significantly reduces online query
times for probabilistic inference when the resulting model is applied, which we
also confirm in our experiments.

摘要：提升的概率推理利用概率模型中的对称性，允许对逻辑变量的域大小进行易处理的概率推理。我们发现当前最先进的算法以参数因子图的形式构建提升表示，但它错失了可交换但缩放不同的因子之间的对称性，从而导致表示不够紧凑。在本文中，我们提出了高级颜色传递 (ACP) 算法的概括，这是构建参数因子图的最新技术。我们提出的算法允许因子电势任意缩放，并且比原始 ACP 算法更有效地检测更多对称性。通过检测比 ACP 更严格的对称性，我们的算法在应用所得模型时显著减少了概率推理的在线查询时间，这一点我们也在实验中得到了证实。

##### **Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**
2411.11714v1 by Mingchao Qi, Yuanjin Li, Xing Liu, Zhengxiong Liu, Panfeng Huang

Deploying robots in open-world environments involves complex tasks
characterized by long sequences and rich interactions, necessitating efficient
transfer of robotic skills across diverse and complex scenarios. To address
this challenge, we propose a skill library framework based on knowledge graphs,
which endows robots with high-level skill awareness and spatial semantic
understanding. The framework hierarchically organizes operational knowledge by
constructing a "task graph" and a "scene graph" to represent task and scene
semantic information, respectively. We introduce a "state graph" to facilitate
interaction between high-level task planning and low-level scene information.
Furthermore, we propose a hierarchical transfer framework for operational
skills. At the task level, the framework integrates contextual learning and
chain-of-thought prompting within a four-stage prompt paradigm, leveraging
large language models' (LLMs) reasoning and generalization capabilities to
achieve task-level subtask sequence transfer. At the motion level, an adaptive
trajectory transfer method is developed using the A* algorithm and the skill
library, enabling motion-level adaptive trajectory transfer. At the physical
level, we introduce an adaptive contour extraction and posture perception
method based on tactile perception. This method dynamically obtains
high-precision contour and posture information from visual-tactile texture data
and adjusts transferred skills, such as contact positions and postures, to
ensure effectiveness in new environments. Experimental results validate the
effectiveness of the proposed methods. Project
website:https://github.com/MingchaoQi/skill_transfer

摘要：<paragraph>在开放世界环境中部署机器人涉及复杂的任务，其特点是序列长、交互丰富，需要在不同且复杂的场景中高效地转移机器人技能。为了应对这一挑战，我们提出一个基于知识图谱的技能库框架，它赋予机器人高级技能意识和空间语义理解。该框架通过构建“任务图”和“场景图”来分层组织操作知识，分别表示任务和场景语义信息。我们引入一个“状态图”来促进高级任务规划和低级场景信息之间的交互。此外，我们提出了一个操作技能的分层转移框架。在任务层面，该框架在一个四阶段提示范式中集成了上下文学习和思想链提示，利用大语言模型 (LLM) 的推理和泛化能力来实现任务级子任务序列转移。在运动层面，使用 A* 算法和技能库开发了一种自适应轨迹转移方法，实现运动级自适应轨迹转移。在物理层面，我们引入了一种基于触觉感知的自适应轮廓提取和姿态感知方法。该方法从视觉触觉纹理数据中动态获取高精度的轮廓和姿态信息，并调整转移的技能，例如接触位置和姿态，以确保在新的环境中有效。实验结果验证了所提出方法的有效性。项目网站：https://github.com/MingchaoQi/skill_transfer</paragraph>

##### **FedCoLLM: A Parameter-Efficient Federated Co-tuning Framework for Large and Small Language Models**
2411.11707v1 by Tao Fan, Yan Kang, Guoqiang Ma, Lixin Fan, Kai Chen, Qiang Yang

By adapting Large Language Models (LLMs) to domain-specific tasks or
enriching them with domain-specific knowledge, we can fully harness the
capabilities of LLMs. Nonetheless, a gap persists in achieving simultaneous
mutual enhancement between the server's LLM and the downstream clients' Small
Language Models (SLMs). To address this, we propose FedCoLLM, a novel and
parameter-efficient federated framework designed for co-tuning LLMs and SLMs.
This approach is aimed at adaptively transferring server-side LLMs knowledge to
clients' SLMs while simultaneously enriching the LLMs with domain insights from
the clients. To accomplish this, FedCoLLM utilizes lightweight adapters in
conjunction with SLMs, facilitating knowledge exchange between server and
clients in a manner that respects data privacy while also minimizing
computational and communication overhead. Our evaluation of FedCoLLM, utilizing
various public LLMs and SLMs across a range of NLP text generation tasks,
reveals that the performance of clients' SLMs experiences notable improvements
with the assistance of the LLMs. Simultaneously, the LLMs enhanced via FedCoLLM
achieves comparable performance to that obtained through direct fine-tuning on
clients' data.

摘要：透過將大型語言模型 (LLM) 調整到特定領域任務或豐富它們的特定領域知識，我們可以充分利用 LLM 的功能。儘管如此，伺服器的 LLM 和下游客戶端的小型語言模型 (SLM) 之間，在同時相互增強方面仍存在差距。為了解決這個問題，我們提出了 FedCoLLM，一個新穎且參數效率高的聯合框架，專門用於共同調整 LLM 和 SLM。此方法旨在自適應地將伺服器端的 LLM 知識傳輸到客戶端的 SLM，同時豐富 LLM 對客戶端領域見解。為了達成此目的，FedCoLLM 利用輕量級適配器與 SLM 結合，促進伺服器和客戶端之間的知識交流，同時尊重資料隱私，並將運算和通訊開銷降到最低。我們利用各種公共 LLM 和 SLM 評估 FedCoLLM，涵蓋一系列 NLP 文字生成任務，結果顯示客戶端的 SLM 在 LLM 的協助下，其效能有顯著提升。同時，透過 FedCoLLM 增強的 LLM，可達成與在客戶端資料上進行直接微調所獲得的效能相當。

##### **MC-LLaVA: Multi-Concept Personalized Vision-Language Model**
2411.11706v1 by Ruichuan An, Sihan Yang, Ming Lu, Kai Zeng, Yulin Luo, Ying Chen, Jiajun Cao, Hao Liang, Qi She, Shanghang Zhang, Wentao Zhang

Current vision-language models (VLMs) show exceptional abilities across
diverse tasks including visual question answering. To enhance user experience
in practical applications, recent studies investigate VLM personalization to
understand user-provided concepts. However, existing studies mainly focus on
single-concept personalization, neglecting the existence and interplay of
multiple concepts, which limits the real-world applicability of personalized
VLMs. In this paper, we propose the first multi-concept personalization method
named MC-LLaVA along with a high-quality multi-concept personalization dataset.
Specifically, MC-LLaVA uses a joint training strategy incorporating multiple
concepts in a single training step, allowing VLMs to perform accurately in
multi-concept personalization. To reduce the cost of joint training, MC-LLaVA
leverages visual token information for concept token initialization, yielding
improved concept representation and accelerating joint training. To advance
multi-concept personalization research, we further contribute a high-quality
dataset. We carefully collect images from various movies that contain multiple
characters and manually generate the multi-concept question-answer samples. Our
dataset features diverse movie types and question-answer types. We conduct
comprehensive qualitative and quantitative experiments to demonstrate that
MC-LLaVA can achieve impressive multi-concept personalized responses, paving
the way for VLMs to become better user-specific assistants. The code and
dataset will be publicly available at https://github.com/arctanxarc/MC-LLaVA.

摘要：目前的視覺語言模型 (VLM) 在包括視覺問答在內的各種任務中展現出非凡的能力。為了提升實際應用中的使用者體驗，最近的研究探討了 VLM 個人化，以了解使用者提供的概念。然而，現有的研究主要集中在單一概念個人化，忽略了多個概念的存在和交互作用，這限制了個人化 VLM 的實際應用性。在本文中，我們提出了第一個名為 MC-LLaVA 的多概念個人化方法，以及一個高品質的多概念個人化資料集。具體來說，MC-LLaVA 使用一個聯合訓練策略，在單一訓練步驟中納入多個概念，讓 VLM 能夠在多概念個人化中準確執行。為了降低聯合訓練的成本，MC-LLaVA 利用視覺標記資訊進行概念標記初始化，產生改進的概念表示並加速聯合訓練。為了推進多概念個人化研究，我們進一步貢獻了一個高品質的資料集。我們仔細從包含多個角色的各種電影中收集影像，並手動產生多概念問答範例。我們的資料集具有多樣化的電影類型和問答類型。我們進行了全面的定性和定量實驗，以證明 MC-LLaVA 能夠實現令人印象深刻的多概念個人化回應，為 VLM 成為更好的使用者特定助理鋪平了道路。程式碼和資料集將公開於 https://github.com/arctanxarc/MC-LLaVA。

##### **Technical Report: Enhancing LLM Reasoning with Reward-guided Tree Search**
2411.11694v1 by Jinhao Jiang, Zhipeng Chen, Yingqian Min, Jie Chen, Xiaoxue Cheng, Jiapeng Wang, Yiru Tang, Haoxiang Sun, Jia Deng, Wayne Xin Zhao, Zheng Liu, Dong Yan, Jian Xie, Zhongyuan Wang, Ji-Rong Wen

Recently, test-time scaling has garnered significant attention from the
research community, largely due to the substantial advancements of the o1 model
released by OpenAI. By allocating more computational resources during the
inference phase, large language models~(LLMs) can extensively explore the
solution space by generating more thought tokens or diverse solutions, thereby
producing more accurate responses. However, developing an o1-like reasoning
approach is challenging, and researchers have been making various attempts to
advance this open area of research. In this paper, we present a preliminary
exploration into enhancing the reasoning abilities of LLMs through
reward-guided tree search algorithms. This framework is implemented by
integrating the policy model, reward model, and search algorithm. It is
primarily constructed around a tree search algorithm, where the policy model
navigates a dynamically expanding tree guided by a specially trained reward
model. We thoroughly explore various design considerations necessary for
implementing this framework and provide a detailed report of the technical
aspects. To assess the effectiveness of our approach, we focus on mathematical
reasoning tasks and conduct extensive evaluations on four challenging datasets,
significantly enhancing the reasoning abilities of LLMs.

摘要：最近，测试时间缩放引起了研究界的极大关注，这在很大程度上归功于 OpenAI 发布的 o1 模型的重大进步。通过在推理阶段分配更多计算资源，大型语言模型 (LLM) 可以通过生成更多思想标记或不同的解决方案来广泛探索解决方案空间，从而产生更准确的响应。然而，开发类似 o1 的推理方法具有挑战性，研究人员一直在尝试推进这一开放的研究领域。在本文中，我们提出了通过奖励引导树搜索算法来增强 LLM 推理能力的初步探索。该框架通过集成策略模型、奖励模型和搜索算法来实现。它主要围绕树搜索算法构建，其中策略模型在经过专门训练的奖励模型的指导下导航动态扩展的树。我们彻底探索了实现此框架所需的不同设计考虑因素，并提供了技术方面的详细报告。为了评估我们方法的有效性，我们专注于数学推理任务，并在四个具有挑战性的数据集上进行广泛的评估，显著增强了 LLM 的推理能力。

##### **Value Imprint: A Technique for Auditing the Human Values Embedded in RLHF Datasets**
2411.11937v1 by Ike Obi, Rohan Pant, Srishti Shekhar Agrawal, Maham Ghazanfar, Aaron Basiletti

LLMs are increasingly fine-tuned using RLHF datasets to align them with human
preferences and values. However, very limited research has investigated which
specific human values are operationalized through these datasets. In this
paper, we introduce Value Imprint, a framework for auditing and classifying the
human values embedded within RLHF datasets. To investigate the viability of
this framework, we conducted three case study experiments by auditing the
Anthropic/hh-rlhf, OpenAI WebGPT Comparisons, and Alpaca GPT-4-LLM datasets to
examine the human values embedded within them. Our analysis involved a
two-phase process. During the first phase, we developed a taxonomy of human
values through an integrated review of prior works from philosophy, axiology,
and ethics. Then, we applied this taxonomy to annotate 6,501 RLHF preferences.
During the second phase, we employed the labels generated from the annotation
as ground truth data for training a transformer-based machine learning model to
audit and classify the three RLHF datasets. Through this approach, we
discovered that information-utility values, including Wisdom/Knowledge and
Information Seeking, were the most dominant human values within all three RLHF
datasets. In contrast, prosocial and democratic values, including Well-being,
Justice, and Human/Animal Rights, were the least represented human values.
These findings have significant implications for developing language models
that align with societal values and norms. We contribute our datasets to
support further research in this area.

摘要：大型語言模型（LLM）日益使用 RLHF 資料集進行微調，以使其與人類偏好和價值觀保持一致。然而，很少有研究調查通過這些資料集運作了哪些具體的人類價值觀。在本文中，我們介紹了價值印記，一個用於審查和分類嵌入在 RLHF 資料集中的人類價值觀的框架。為了調查這個框架的可行性，我們通過審查 Anthropic/hh-rlhf、OpenAI WebGPT 比較和 Alpaca GPT-4-LLM 資料集來進行了三個案例研究實驗，以檢查其中嵌入的人類價值觀。我們的分析涉及一個兩階段的過程。在第一階段，我們通過對哲學、價值論和倫理學之前工作的綜合回顧，開發了一個人類價值觀分類法。然後，我們應用這個分類法來註釋 6,501 個 RLHF 偏好。在第二階段，我們採用從註釋中產生的標籤作為訓練一個基於轉換器的機器學習模型的真實數據，以審查和分類三個 RLHF 資料集。通過這種方法，我們發現資訊效用價值，包括智慧/知識和資訊尋求，是所有三個 RLHF 資料集中最主要的人類價值觀。相反，親社會和民主價值觀，包括福祉、正義和人類/動物權利，是代表性最少的人類價值觀。這些發現對開發與社會價值觀和規範保持一致的語言模型具有重大意義。我們貢獻我們的資料集以支持這方面的進一步研究。

