{"2411.17000": {"publish_time": "2024-11-26", "title": "SatVision-TOA: A Geospatial Foundation Model for Coarse-Resolution All-Sky Remote Sensing Imagery", "paper_summary": "Foundation models have the potential to transform the landscape of remote\nsensing (RS) data analysis by enabling large computer vision models to be\npre-trained on vast amounts of remote sensing data. These models can then be\nfine-tuned with small amounts of labeled training and applied to a variety of\napplications. Most existing foundation models are designed for high spatial\nresolution, cloud-free satellite imagery or photos, limiting their\napplicability in scenarios that require frequent temporal monitoring or broad\nspectral profiles. As a result, foundation models trained solely on cloud-free\nimages have limited utility for applications that involve atmospheric variables\nor require atmospheric corrections. We introduce SatVision-TOA, a novel\nfoundation model pre-trained on 14-band MODIS L1B Top-Of-Atmosphere (TOA)\nradiance imagery, addressing the need for models pre-trained to handle\nmoderate- and coarse-resolution all-sky remote sensing data. The SatVision-TOA\nmodel is pre-trained using a Masked-Image-Modeling (MIM) framework and the\nSwinV2 architecture, and learns detailed contextual representations through\nself-supervised learning without the need for labels. It is a 3 billion\nparameter model that is trained on 100 million images. To our knowledge this is\nthe largest foundation model trained solely on satellite RS imagery. Results\nshow that SatVision-TOA achieves superior performance over baseline methods on\ndownstream tasks such as 3D cloud retrieval. Notably, the model achieves a mean\nintersection over union (mIOU) of 0.46, a substantial improvement over the\nbaseline mIOU of 0.22. Additionally, the rate of false negative results in the\nfine-tuning task were reduced by over 50% compared to the baseline. Our work\nadvances pre-trained vision modeling for multispectral RS by learning from a\nvariety of atmospheric and aerosol conditions to improve cloud and land surface\nmonitoring.", "paper_summary_zh": "\u57fa\u790e\u6a21\u578b\u6709\u6f5b\u529b\u900f\u904e\u8b93\u5927\u578b\u96fb\u8166\u8996\u89ba\u6a21\u578b\u5728\u5927\u91cf\u7684\u9059\u6e2c\u8cc7\u6599\u4e0a\u9032\u884c\u9810\u8a13\u7df4\uff0c\u4f86\u8f49\u8b8a\u9059\u6e2c (RS) \u8cc7\u6599\u5206\u6790\u7684\u9818\u57df\u3002\u9019\u4e9b\u6a21\u578b\u63a5\u8457\u53ef\u4ee5\u7528\u5c11\u91cf\u7684\u6a19\u7c64\u8a13\u7df4\u9032\u884c\u5fae\u8abf\uff0c\u4e26\u61c9\u7528\u65bc\u5404\u7a2e\u61c9\u7528\u7a0b\u5f0f\u3002\u5927\u591a\u6578\u73fe\u6709\u7684\u57fa\u790e\u6a21\u578b\u90fd\u662f\u8a2d\u8a08\u7528\u65bc\u9ad8\u7a7a\u9593\u89e3\u6790\u5ea6\u3001\u7121\u96f2\u7684\u885b\u661f\u5f71\u50cf\u6216\u7167\u7247\uff0c\u9650\u5236\u4e86\u5b83\u5011\u5728\u9700\u8981\u983b\u7e41\u6642\u9593\u76e3\u63a7\u6216\u5ee3\u6cdb\u5149\u8b5c\u7279\u5fb5\u7684\u60c5\u6cc1\u4e0b\u7684\u9069\u7528\u6027\u3002\u56e0\u6b64\uff0c\u50c5\u5728\u7121\u96f2\u5f71\u50cf\u4e0a\u8a13\u7df4\u7684\u57fa\u790e\u6a21\u578b\u5c0d\u65bc\u6d89\u53ca\u5927\u6c23\u8b8a\u6578\u6216\u9700\u8981\u5927\u6c23\u6821\u6b63\u7684\u61c9\u7528\u7a0b\u5f0f\u800c\u8a00\uff0c\u5176\u6548\u7528\u6709\u9650\u3002\u6211\u5011\u5f15\u5165\u4e86 SatVision-TOA\uff0c\u9019\u662f\u4e00\u500b\u5275\u65b0\u7684\u57fa\u790e\u6a21\u578b\uff0c\u9810\u5148\u8a13\u7df4\u65bc 14 \u6ce2\u6bb5 MODIS L1B \u5927\u6c23\u5c64\u9802\u7aef (TOA) \u8f3b\u5c04\u5f71\u50cf\u4e0a\uff0c\u6eff\u8db3\u4e86\u9810\u5148\u8a13\u7df4\u6a21\u578b\u4f86\u8655\u7406\u4e2d\u89e3\u6790\u5ea6\u548c\u4f4e\u89e3\u6790\u5ea6\u7684\u5168\u5929\u9059\u6e2c\u8cc7\u6599\u7684\u9700\u6c42\u3002SatVision-TOA \u6a21\u578b\u4f7f\u7528\u906e\u7f69\u5f71\u50cf\u5efa\u6a21 (MIM) \u67b6\u69cb\u548c SwinV2 \u67b6\u69cb\u9032\u884c\u9810\u8a13\u7df4\uff0c\u4e26\u900f\u904e\u81ea\u76e3\u7763\u5b78\u7fd2\u4f86\u5b78\u7fd2\u8a73\u7d30\u7684\u8108\u7d61\u8868\u5fb5\uff0c\u800c\u4e0d\u9700\u8981\u6a19\u7c64\u3002\u5b83\u662f\u4e00\u500b 30 \u5104\u500b\u53c3\u6578\u7684\u6a21\u578b\uff0c\u8a13\u7df4\u65bc 1 \u5104\u5f35\u5f71\u50cf\u4e0a\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u662f\u50c5\u5728\u885b\u661f RS \u5f71\u50cf\u4e0a\u8a13\u7df4\u7684\u6700\u5927\u57fa\u790e\u6a21\u578b\u3002\u7d50\u679c\u986f\u793a\uff0c\u5728 3D \u96f2\u64f7\u53d6\u7b49\u4e0b\u6e38\u4efb\u52d9\u4e0a\uff0cSatVision-TOA \u9054\u5230\u4e86\u512a\u65bc\u57fa\u6e96\u65b9\u6cd5\u7684\u6548\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8a72\u6a21\u578b\u5728\u806f\u96c6\u4e0a\u7684\u5e73\u5747\u4ea4\u96c6 (mIOU) \u9054\u5230\u4e86 0.46\uff0c\u5927\u5e45\u512a\u65bc\u57fa\u6e96 mIOU \u7684 0.22\u3002\u6b64\u5916\uff0c\u8207\u57fa\u6e96\u76f8\u6bd4\uff0c\u5fae\u8abf\u4efb\u52d9\u4e2d\u7684\u5047\u9670\u6027\u7d50\u679c\u7387\u964d\u4f4e\u4e86 50% \u4ee5\u4e0a\u3002\u6211\u5011\u7684\u7814\u7a76\u900f\u904e\u5b78\u7fd2\u5404\u7a2e\u5927\u6c23\u548c\u6c23\u6eb6\u81a0\u689d\u4ef6\u4f86\u6539\u5584\u96f2\u548c\u5730\u8868\u76e3\u63a7\uff0c\u63a8\u52d5\u4e86\u591a\u5149\u8b5c RS \u7684\u9810\u8a13\u7df4\u8996\u89ba\u5efa\u6a21\u3002", "author": "Caleb S. Spradlin et.al.", "authors": "Caleb S. Spradlin, Jordan A. Caraballo-Vega, Jian Li, Mark L. Carroll, Jie Gong, Paul M. Montesano", "id": "2411.17000v1", "paper_url": "http://arxiv.org/abs/2411.17000v1", "repo": "https://github.com/nasa-nccs-hpda/pytorch-caney"}}