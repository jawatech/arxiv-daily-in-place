{"2407.13292": {"publish_time": "2024-07-18", "title": "Low-Resourced Speech Recognition for Iu Mien Language via Weakly-Supervised Phoneme-based Multilingual Pre-training", "paper_summary": "The mainstream automatic speech recognition (ASR) technology usually requires\nhundreds to thousands of hours of annotated speech data. Three approaches to\nlow-resourced ASR are phoneme or subword based supervised pre-training, and\nself-supervised pre-training over multilingual data. The Iu Mien language is\nthe main ethnic language of the Yao ethnic group in China and is low-resourced\nin the sense that the annotated speech is very limited. With less than 10 hours\nof transcribed Iu Mien language, this paper investigates and compares the three\napproaches for Iu Mien speech recognition. Our experiments are based on the\nrecently released, three backbone models pretrained over the 10 languages from\nthe CommonVoice dataset (CV-Lang10), which correspond to the three approaches\nfor low-resourced ASR. It is found that phoneme supervision can achieve better\nresults compared to subword supervision and self-supervision, thereby providing\nhigher data-efficiency. Particularly, the Whistle models, i.e., obtained by the\nweakly-supervised phoneme-based multilingual pre-training, obtain the most\ncompetitive results.", "paper_summary_zh": "\u4e3b\u6d41\u7684\u81ea\u52d5\u8a9e\u97f3\u8fa8\u8b58\uff08ASR\uff09\u6280\u8853\u901a\u5e38\u9700\u8981\u6578\u767e\u5230\u6578\u5343\u5c0f\u6642\u7684\u6a19\u8a3b\u8a9e\u97f3\u8cc7\u6599\u3002\u4f4e\u8cc7\u6e90 ASR \u7684\u4e09\u7a2e\u65b9\u6cd5\u662f\u57fa\u65bc\u97f3\u7d20\u6216\u5b50\u5b57\u7684\u76e3\u7763\u5f0f\u9810\u8a13\u7df4\uff0c\u4ee5\u53ca\u591a\u8a9e\u8a00\u8cc7\u6599\u7684\u81ea\u6211\u76e3\u7763\u5f0f\u9810\u8a13\u7df4\u3002\u52c9\u8a9e\u662f\u4e2d\u570b\u7464\u65cf\u7684\u4e3b\u8981\u6c11\u65cf\u8a9e\u8a00\uff0c\u5728\u6a19\u8a3b\u8a9e\u97f3\u975e\u5e38\u6709\u9650\u7684\u610f\u7fa9\u4e0a\u5c6c\u65bc\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u3002\u672c\u6587\u4f7f\u7528\u4e0d\u5230 10 \u5c0f\u6642\u7684\u8f49\u9304\u52c9\u8a9e\uff0c\u63a2\u8a0e\u4e26\u6bd4\u8f03\u4e86\u52c9\u8a9e\u8a9e\u97f3\u8fa8\u8b58\u7684\u9019\u4e09\u7a2e\u65b9\u6cd5\u3002\u6211\u5011\u7684\u5be6\u9a57\u57fa\u65bc\u6700\u8fd1\u767c\u5e03\u7684\u4e09\u500b\u4e3b\u5e79\u6a21\u578b\uff0c\u5b83\u5011\u5728 CommonVoice \u8cc7\u6599\u96c6\uff08CV-Lang10\uff09\u7684 10 \u7a2e\u8a9e\u8a00\u4e0a\u9032\u884c\u4e86\u9810\u8a13\u7df4\uff0c\u9019\u4e09\u7a2e\u65b9\u6cd5\u5206\u5225\u5c0d\u61c9\u65bc\u4f4e\u8cc7\u6e90 ASR \u7684\u4e09\u7a2e\u65b9\u6cd5\u3002\u7814\u7a76\u767c\u73fe\uff0c\u8207\u5b50\u5b57\u76e3\u7763\u548c\u81ea\u6211\u76e3\u7763\u76f8\u6bd4\uff0c\u97f3\u7d20\u76e3\u7763\u53ef\u4ee5\u7372\u5f97\u66f4\u597d\u7684\u7d50\u679c\uff0c\u5f9e\u800c\u63d0\u4f9b\u66f4\u9ad8\u7684\u8cc7\u6599\u6548\u7387\u3002\u7279\u5225\u662f Whistle \u6a21\u578b\uff0c\u5373\u900f\u904e\u5f31\u76e3\u7763\u97f3\u7d20\u70ba\u57fa\u790e\u7684\u591a\u8a9e\u8a00\u9810\u8a13\u7df4\u7372\u5f97\u7684\u6a21\u578b\uff0c\u7372\u5f97\u4e86\u6700\u5177\u7af6\u722d\u529b\u7684\u7d50\u679c\u3002", "author": "Lukuan Dong et.al.", "authors": "Lukuan Dong, Donghong Qin, Fengbo Bai, Fanhua Song, Yan Liu, Chen Xu, Zhijian Ou", "id": "2407.13292v1", "paper_url": "http://arxiv.org/abs/2407.13292v1", "repo": "null"}}