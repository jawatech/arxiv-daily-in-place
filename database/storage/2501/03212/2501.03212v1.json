{"2501.03212": {"publish_time": "2025-01-06", "title": "Leveraging Explainable AI for LLM Text Attribution: Differentiating Human-Written and Multiple LLMs-Generated Text", "paper_summary": "The development of Generative AI Large Language Models (LLMs) raised the\nalarm regarding identifying content produced through generative AI or humans.\nIn one case, issues arise when students heavily rely on such tools in a manner\nthat can affect the development of their writing or coding skills. Other issues\nof plagiarism also apply. This study aims to support efforts to detect and\nidentify textual content generated using LLM tools. We hypothesize that\nLLMs-generated text is detectable by machine learning (ML), and investigate ML\nmodels that can recognize and differentiate texts generated by multiple LLMs\ntools. We leverage several ML and Deep Learning (DL) algorithms such as Random\nForest (RF), and Recurrent Neural Networks (RNN), and utilized Explainable\nArtificial Intelligence (XAI) to understand the important features in\nattribution. Our method is divided into 1) binary classification to\ndifferentiate between human-written and AI-text, and 2) multi classification,\nto differentiate between human-written text and the text generated by the five\ndifferent LLM tools (ChatGPT, LLaMA, Google Bard, Claude, and Perplexity).\nResults show high accuracy in the multi and binary classification. Our model\noutperformed GPTZero with 98.5\\% accuracy to 78.3\\%. Notably, GPTZero was\nunable to recognize about 4.2\\% of the observations, but our model was able to\nrecognize the complete test dataset. XAI results showed that understanding\nfeature importance across different classes enables detailed author/source\nprofiles. Further, aiding in attribution and supporting plagiarism detection by\nhighlighting unique stylistic and structural elements ensuring robust content\noriginality verification.", "paper_summary_zh": "\u751f\u6210\u5f0f AI \u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u53d1\u5c55\u5f15\u8d77\u4e86\u4eba\u4eec\u5bf9\u8bc6\u522b\u901a\u8fc7\u751f\u6210\u5f0f AI \u6216\u4eba\u7c7b\u4ea7\u751f\u7684\u5185\u5bb9\u7684\u8b66\u89c9\u3002\n\u5728\u4e00\u79cd\u60c5\u51b5\u4e0b\uff0c\u5f53\u5b66\u751f\u4e25\u91cd\u4f9d\u8d56\u6b64\u7c7b\u5de5\u5177\u65f6\uff0c\u53ef\u80fd\u4f1a\u51fa\u73b0\u5f71\u54cd\u5176\u5199\u4f5c\u6216\u7f16\u7801\u6280\u80fd\u53d1\u5c55\u7684\u95ee\u9898\u3002\u5176\u4ed6\u6284\u88ad\u95ee\u9898\u4e5f\u9002\u7528\u3002\u672c\u7814\u7a76\u65e8\u5728\u652f\u6301\u68c0\u6d4b\u548c\u8bc6\u522b\u4f7f\u7528 LLM \u5de5\u5177\u751f\u6210\u7684\u6587\u672c\u5185\u5bb9\u7684\u52aa\u529b\u3002\u6211\u4eec\u5047\u8bbe LLM \u751f\u6210\u7684\u6587\u672c\u53ef\u901a\u8fc7\u673a\u5668\u5b66\u4e60 (ML) \u68c0\u6d4b\uff0c\u5e76\u7814\u7a76\u80fd\u591f\u8bc6\u522b\u548c\u533a\u5206\u7531\u591a\u4e2a LLM \u5de5\u5177\u751f\u6210\u7684\u6587\u672c\u7684 ML \u6a21\u578b\u3002\u6211\u4eec\u5229\u7528\u4e86\u591a\u79cd ML \u548c\u6df1\u5ea6\u5b66\u4e60 (DL) \u7b97\u6cd5\uff0c\u4f8b\u5982\u968f\u673a\u68ee\u6797 (RF) \u548c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc (RNN)\uff0c\u5e76\u5229\u7528\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd (XAI) \u6765\u7406\u89e3\u5f52\u56e0\u4e2d\u7684\u91cd\u8981\u7279\u5f81\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5206\u4e3a 1) \u4e8c\u5143\u5206\u7c7b\uff0c\u4ee5\u533a\u5206\u4eba\u5199\u6587\u672c\u548c AI \u6587\u672c\uff0c\u4ee5\u53ca 2) \u591a\u5206\u7c7b\uff0c\u4ee5\u533a\u5206\u4eba\u5199\u6587\u672c\u548c\u7531\u4e94\u79cd\u4e0d\u540c\u7684 LLM \u5de5\u5177\uff08ChatGPT\u3001LLaMA\u3001Google Bard\u3001Claude \u548c Perplexity\uff09\u751f\u6210\u7684\u6587\u672c\u3002\u7ed3\u679c\u663e\u793a\u5728\u591a\u5206\u7c7b\u548c\u4e8c\u5143\u5206\u7c7b\u4e2d\u5177\u6709\u5f88\u9ad8\u7684\u51c6\u786e\u6027\u3002\u6211\u4eec\u7684\u6a21\u578b\u4ee5 98.5% \u7684\u51c6\u786e\u7387\u4f18\u4e8e GPTZero\uff0c\u8fbe\u5230 78.3%\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cGPTZero \u65e0\u6cd5\u8bc6\u522b\u7ea6 4.2% \u7684\u89c2\u5bdf\u7ed3\u679c\uff0c\u4f46\u6211\u4eec\u7684\u6a21\u578b\u80fd\u591f\u8bc6\u522b\u5b8c\u6574\u7684\u6d4b\u8bd5\u6570\u636e\u96c6\u3002XAI \u7ed3\u679c\u8868\u660e\uff0c\u7406\u89e3\u4e0d\u540c\u7c7b\u522b\u7684\u7279\u5f81\u91cd\u8981\u6027\u53ef\u4ee5\u5b9e\u73b0\u8be6\u7ec6\u7684\u4f5c\u8005/\u6765\u6e90\u6982\u51b5\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u7a81\u51fa\u72ec\u7279\u7684\u98ce\u683c\u548c\u7ed3\u6784\u5143\u7d20\u6765\u8f85\u52a9\u5f52\u56e0\u5e76\u652f\u6301\u6284\u88ad\u68c0\u6d4b\uff0c\u786e\u4fdd\u5185\u5bb9\u539f\u521b\u6027\u9a8c\u8bc1\u7684\u7a33\u5065\u6027\u3002", "author": "Ayat Najjar et.al.", "authors": "Ayat Najjar, Huthaifa I. Ashqar, Omar Darwish, Eman Hammad", "id": "2501.03212v1", "paper_url": "http://arxiv.org/abs/2501.03212v1", "repo": "null"}}