{"2409.02657": {"publish_time": "2024-09-04", "title": "PoseTalk: Text-and-Audio-based Pose Control and Motion Refinement for One-Shot Talking Head Generation", "paper_summary": "While previous audio-driven talking head generation (THG) methods generate\nhead poses from driving audio, the generated poses or lips cannot match the\naudio well or are not editable. In this study, we propose \\textbf{PoseTalk}, a\nTHG system that can freely generate lip-synchronized talking head videos with\nfree head poses conditioned on text prompts and audio. The core insight of our\nmethod is using head pose to connect visual, linguistic, and audio signals.\nFirst, we propose to generate poses from both audio and text prompts, where the\naudio offers short-term variations and rhythm correspondence of the head\nmovements and the text prompts describe the long-term semantics of head\nmotions. To achieve this goal, we devise a Pose Latent Diffusion (PLD) model to\ngenerate motion latent from text prompts and audio cues in a pose latent space.\nSecond, we observe a loss-imbalance problem: the loss for the lip region\ncontributes less than 4\\% of the total reconstruction loss caused by both pose\nand lip, making optimization lean towards head movements rather than lip\nshapes. To address this issue, we propose a refinement-based learning strategy\nto synthesize natural talking videos using two cascaded networks, i.e.,\nCoarseNet, and RefineNet. The CoarseNet estimates coarse motions to produce\nanimated images in novel poses and the RefineNet focuses on learning finer lip\nmotions by progressively estimating lip motions from low-to-high resolutions,\nyielding improved lip-synchronization performance. Experiments demonstrate our\npose prediction strategy achieves better pose diversity and realness compared\nto text-only or audio-only, and our video generator model outperforms\nstate-of-the-art methods in synthesizing talking videos with natural head\nmotions. Project: https://junleen.github.io/projects/posetalk.", "paper_summary_zh": "<paragraph>\u5118\u7ba1\u5148\u524d\u7684\u97f3\u8a0a\u9a45\u52d5\u8aaa\u8a71\u982d\u90e8\u751f\u6210 (THG) \u65b9\u6cd5\u53ef\u5f9e\u9a45\u52d5\u97f3\u8a0a\u4e2d\u751f\u6210\u982d\u90e8\u59ff\u52e2\uff0c\u4f46\u751f\u6210\u7684\u59ff\u52e2\u6216\u5634\u5507\u7121\u6cd5\u8207\u97f3\u8a0a\u826f\u597d\u5339\u914d\uff0c\u6216\u7121\u6cd5\u7de8\u8f2f\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b THG \u7cfb\u7d71 \\textbf{PoseTalk}\uff0c\u8a72\u7cfb\u7d71\u53ef\u4ee5\u81ea\u7531\u751f\u6210\u8207\u6587\u5b57\u63d0\u793a\u548c\u97f3\u8a0a\u76f8\u7b26\u7684\u5507\u90e8\u540c\u6b65\u8aaa\u8a71\u982d\u90e8\u5f71\u7247\uff0c\u4e14\u5177\u6709\u81ea\u7531\u7684\u982d\u90e8\u59ff\u52e2\u3002\u6211\u5011\u65b9\u6cd5\u7684\u6838\u5fc3\u898b\u89e3\u662f\u4f7f\u7528\u982d\u90e8\u59ff\u52e2\u9023\u63a5\u8996\u89ba\u3001\u8a9e\u8a00\u548c\u97f3\u8a0a\u8a0a\u865f\u3002\u9996\u5148\uff0c\u6211\u5011\u5efa\u8b70\u5f9e\u97f3\u8a0a\u548c\u6587\u5b57\u63d0\u793a\u4e2d\u751f\u6210\u59ff\u52e2\uff0c\u5176\u4e2d\u97f3\u8a0a\u63d0\u4f9b\u982d\u90e8\u52d5\u4f5c\u7684\u77ed\u671f\u8b8a\u5316\u548c\u7bc0\u594f\u5c0d\u61c9\uff0c\u800c\u6587\u5b57\u63d0\u793a\u5247\u63cf\u8ff0\u982d\u90e8\u52d5\u4f5c\u7684\u9577\u671f\u8a9e\u610f\u3002\u70ba\u9054\u6210\u6b64\u76ee\u6a19\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u59ff\u52e2\u6f5b\u5728\u64f4\u6563 (PLD) \u6a21\u578b\uff0c\u5728\u59ff\u52e2\u6f5b\u5728\u7a7a\u9593\u4e2d\u5f9e\u6587\u5b57\u63d0\u793a\u548c\u97f3\u8a0a\u63d0\u793a\u4e2d\u751f\u6210\u52d5\u4f5c\u6f5b\u5728\u3002\u5176\u6b21\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u640d\u5931\u4e0d\u5e73\u8861\u7684\u554f\u984c\uff1a\u5634\u5507\u5340\u57df\u7684\u640d\u5931\u5c0f\u65bc\u59ff\u52e2\u548c\u5634\u5507\u9020\u6210\u7684\u7e3d\u91cd\u5efa\u640d\u5931\u7684 4%\uff0c\u9019\u4f7f\u5f97\u6700\u4f73\u5316\u50be\u5411\u65bc\u982d\u90e8\u52d5\u4f5c\uff0c\u800c\u4e0d\u662f\u5634\u5507\u5f62\u72c0\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u7cbe\u7149\u7684\u5b78\u7fd2\u7b56\u7565\uff0c\u4f7f\u7528\u5169\u500b\u4e32\u806f\u7db2\u8def\u5408\u6210\u81ea\u7136\u8aaa\u8a71\u5f71\u7247\uff0c\u5373 CoarseNet \u548c RefineNet\u3002CoarseNet \u4f30\u8a08\u7c97\u7565\u52d5\u4f5c\u4ee5\u7522\u751f\u65b0\u59ff\u52e2\u7684\u52d5\u756b\u5f71\u50cf\uff0c\u800c RefineNet \u5247\u5c08\u6ce8\u65bc\u900f\u904e\u5f9e\u4f4e\u89e3\u6790\u5ea6\u5230\u9ad8\u89e3\u6790\u5ea6\u9010\u6b65\u4f30\u8a08\u5634\u5507\u52d5\u4f5c\u4f86\u5b78\u7fd2\u66f4\u7cbe\u7d30\u7684\u5634\u5507\u52d5\u4f5c\uff0c\u9032\u800c\u6539\u5584\u5507\u90e8\u540c\u6b65\u6548\u80fd\u3002\u5be6\u9a57\u8b49\u660e\uff0c\u8207\u50c5\u6587\u5b57\u6216\u50c5\u97f3\u8a0a\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u59ff\u52e2\u9810\u6e2c\u7b56\u7565\u53ef\u7372\u5f97\u66f4\u597d\u7684\u59ff\u52e2\u591a\u6a23\u6027\u548c\u771f\u5be6\u6027\uff0c\u800c\u6211\u5011\u7684\u5f71\u7247\u751f\u6210\u5668\u6a21\u578b\u5728\u5408\u6210\u5177\u6709\u81ea\u7136\u982d\u90e8\u52d5\u4f5c\u7684\u8aaa\u8a71\u5f71\u7247\u65b9\u9762\u512a\u65bc\u6700\u5148\u9032\u7684\u65b9\u6cd5\u3002\u5c08\u6848\uff1ahttps://junleen.github.io/projects/posetalk\u3002</paragraph>", "author": "Jun Ling et.al.", "authors": "Jun Ling, Yiwen Wang, Han Xue, Rong Xie, Li Song", "id": "2409.02657v1", "paper_url": "http://arxiv.org/abs/2409.02657v1", "repo": "null"}}