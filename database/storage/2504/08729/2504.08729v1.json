{"2504.08729": {"publish_time": "2025-04-11", "title": "Steering CLIP's vision transformer with sparse autoencoders", "paper_summary": "While vision models are highly capable, their internal mechanisms remain\npoorly understood -- a challenge which sparse autoencoders (SAEs) have helped\naddress in language, but which remains underexplored in vision. We address this\ngap by training SAEs on CLIP's vision transformer and uncover key differences\nbetween vision and language processing, including distinct sparsity patterns\nfor SAEs trained across layers and token types. We then provide the first\nsystematic analysis on the steerability of CLIP's vision transformer by\nintroducing metrics to quantify how precisely SAE features can be steered to\naffect the model's output. We find that 10-15\\% of neurons and features are\nsteerable, with SAEs providing thousands more steerable features than the base\nmodel. Through targeted suppression of SAE features, we then demonstrate\nimproved performance on three vision disentanglement tasks (CelebA, Waterbirds,\nand typographic attacks), finding optimal disentanglement in middle model\nlayers, and achieving state-of-the-art performance on defense against\ntypographic attacks.", "paper_summary_zh": "<paragraph>\u96d6\u7136\u8996\u89ba\u6a21\u578b\u7684\u529f\u80fd\u975e\u5e38\u5f37\u5927\uff0c\u4f46\u5b83\u5011\u7684\u5167\u90e8\u6a5f\u5236\u4ecd\u7136\u96e3\u4ee5\u7406\u89e3\u2014\u2014\u7a00\u758f\u81ea\u7de8\u78bc\u5668 (SAE) \u5e6b\u52a9\u89e3\u6c7a\u4e86\u8a9e\u8a00\u65b9\u9762\u7684\u9019\u500b\u6311\u6230\uff0c\u4f46\u5728\u8996\u89ba\u65b9\u9762\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u6211\u5011\u900f\u904e\u5728 CLIP \u7684\u8996\u89ba\u8f49\u63db\u5668\u4e0a\u8a13\u7df4 SAE \u4f86\u5f4c\u88dc\u9019\u4e00\u5dee\u8ddd\uff0c\u4e26\u767c\u73fe\u8996\u89ba\u548c\u8a9e\u8a00\u8655\u7406\u4e4b\u9593\u7684\u95dc\u9375\u5dee\u7570\uff0c\u5305\u62ec\u5728\u4e0d\u540c\u5c64\u548c\u6a19\u8a18\u985e\u578b\u4e0a\u8a13\u7df4\u7684 SAE \u7684\u7368\u7279\u7a00\u758f\u6a21\u5f0f\u3002\u7136\u5f8c\uff0c\u6211\u5011\u900f\u904e\u5f15\u5165\u6307\u6a19\u4f86\u91cf\u5316 SAE \u7279\u5fb5\u5982\u4f55\u7cbe\u78ba\u5730\u5f15\u5c0e\u4ee5\u5f71\u97ff\u6a21\u578b\u7684\u8f38\u51fa\uff0c\u5f9e\u800c\u9996\u6b21\u5c0d CLIP \u8996\u89ba\u8f49\u63db\u5668\u7684\u53ef\u63a7\u6027\u9032\u884c\u7cfb\u7d71\u5206\u6790\u3002\u6211\u5011\u767c\u73fe 10-15% \u7684\u795e\u7d93\u5143\u548c\u7279\u5fb5\u662f\u53ef\u63a7\u7684\uff0cSAE \u6bd4\u57fa\u790e\u6a21\u578b\u63d0\u4f9b\u4e86\u6578\u5343\u500b\u53ef\u63a7\u7279\u5fb5\u3002\u63a5\u8457\uff0c\u900f\u904e\u6709\u91dd\u5c0d\u6027\u5730\u6291\u5236 SAE \u7279\u5fb5\uff0c\u6211\u5011\u5c55\u793a\u4e86\u5728\u4e09\u500b\u8996\u89ba\u5206\u96e2\u4efb\u52d9\uff08CelebA\u3001Waterbirds \u548c\u5370\u5237\u653b\u64ca\uff09\u4e0a\u7684\u6539\u9032\u6027\u80fd\uff0c\u5728\u6a21\u578b\u4e2d\u9593\u5c64\u627e\u5230\u4e86\u6700\u4f73\u5206\u96e2\uff0c\u4e26\u5728\u62b5\u79a6\u5370\u5237\u653b\u64ca\u65b9\u9762\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6027\u80fd\u3002</paragraph>\n", "author": "Sonia Joseph et.al.", "authors": "Sonia Joseph, Praneet Suresh, Ethan Goldfarb, Lorenz Hufe, Yossi Gandelsman, Robert Graham, Danilo Bzdok, Wojciech Samek, Blake Aaron Richards", "id": "2504.08729v1", "paper_url": "http://arxiv.org/abs/2504.08729v1", "repo": "null"}}