{"2410.09699": {"publish_time": "2024-10-13", "title": "Honest AI: Fine-Tuning \"Small\" Language Models to Say \"I Don't Know\", and Reducing Hallucination in RAG", "paper_summary": "Hallucination is a key roadblock for applications of Large Language Models\n(LLMs), particularly for enterprise applications that are sensitive to\ninformation accuracy. To address this issue, two general approaches have been\nexplored: Retrieval-Augmented Generation (RAG) to supply LLMs with updated\ninformation as context, and fine-tuning the LLMs with new information and\ndesired output styles. In this paper, we propose Honest AI: a novel strategy to\nfine-tune \"small\" language models to say \"I don't know\" to reduce\nhallucination, along with several alternative RAG approaches. The solution\nranked 1st in Task 2 for the false premise question. The alternative approaches\ninclude using RAG with search engine and knowledge graph results, fine-tuning\nbase LLMs with new information and combinations of both approaches. Although\nall approaches improve the performance of the LLMs, RAG alone does not\nsignificantly improve the performance and fine-tuning is needed for better\nresults. Finally, the hybrid approach achieved the highest score in the CRAG\nbenchmark. In addition, our approach emphasizes the use of relatively small\nmodels with fewer than 10 billion parameters, promoting resource efficiency.", "paper_summary_zh": "\u5e7b\u89ba\u662f\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u61c9\u7528\u7a0b\u5f0f\u7684\u4e00\u5927\u969c\u7919\uff0c\u7279\u5225\u662f\u5c0d\u8cc7\u8a0a\u6e96\u78ba\u5ea6\u654f\u611f\u7684\u4f01\u696d\u61c9\u7528\u7a0b\u5f0f\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u5df2\u63a2\u8a0e\u5169\u7a2e\u4e00\u822c\u65b9\u6cd5\uff1a\u6aa2\u7d22\u64f4\u5145\u751f\u6210 (RAG) \u4ee5\u63d0\u4f9b LLM \u66f4\u65b0\u7684\u8cc7\u8a0a\u4f5c\u70ba\u80cc\u666f\uff0c\u4ee5\u53ca\u5fae\u8abf LLM \u4ee5\u7372\u5f97\u65b0\u7684\u8cc7\u8a0a\u548c\u671f\u671b\u7684\u8f38\u51fa\u6a23\u5f0f\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa Honest AI\uff1a\u4e00\u7a2e\u65b0\u7a4e\u7684\u7b56\u7565\uff0c\u5fae\u8abf\u300c\u5c0f\u578b\u300d\u8a9e\u8a00\u6a21\u578b\u4ee5\u8868\u9054\u300c\u6211\u4e0d\u77e5\u9053\u300d\u4ee5\u6e1b\u5c11\u5e7b\u89ba\uff0c\u4ee5\u53ca\u5176\u4ed6\u5e7e\u7a2e\u66ff\u4ee3\u7684 RAG \u65b9\u6cd5\u3002\u8a72\u89e3\u6c7a\u65b9\u6848\u5728\u865b\u5047\u524d\u63d0\u554f\u984c\u7684\u4efb\u52d9 2 \u4e2d\u6392\u540d\u7b2c 1\u3002\u66ff\u4ee3\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528 RAG \u642d\u914d\u641c\u5c0b\u5f15\u64ce\u548c\u77e5\u8b58\u5716\u8b5c\u7d50\u679c\u3001\u5fae\u8abf\u57fa\u790e LLM \u4ee5\u7372\u5f97\u65b0\u7684\u8cc7\u8a0a\uff0c\u4ee5\u53ca\u7d50\u5408\u9019\u5169\u7a2e\u65b9\u6cd5\u3002\u96d6\u7136\u6240\u6709\u65b9\u6cd5\u90fd\u6539\u5584\u4e86 LLM \u7684\u6548\u80fd\uff0c\u4f46\u50c5\u4f7f\u7528 RAG \u7121\u6cd5\u986f\u8457\u6539\u5584\u6548\u80fd\uff0c\u9700\u8981\u5fae\u8abf\u624d\u80fd\u7372\u5f97\u66f4\u597d\u7684\u7d50\u679c\u3002\u6700\u5f8c\uff0c\u6df7\u5408\u65b9\u6cd5\u5728 CRAG \u57fa\u6e96\u6e2c\u8a66\u4e2d\u7372\u5f97\u6700\u9ad8\u5206\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5f37\u8abf\u4f7f\u7528\u53c3\u6578\u5c11\u65bc 100 \u5104\u7684\u5c0f\u578b\u6a21\u578b\uff0c\u4ee5\u4fc3\u9032\u8cc7\u6e90\u6548\u7387\u3002", "author": "Xinxi Chen et.al.", "authors": "Xinxi Chen, Li Wang, Wei Wu, Qi Tang, Yiyao Liu", "id": "2410.09699v1", "paper_url": "http://arxiv.org/abs/2410.09699v1", "repo": "null"}}