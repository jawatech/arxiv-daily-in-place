{"2406.09750": {"publish_time": "2024-06-14", "title": "ControlVAR: Exploring Controllable Visual Autoregressive Modeling", "paper_summary": "Conditional visual generation has witnessed remarkable progress with the\nadvent of diffusion models (DMs), especially in tasks like control-to-image\ngeneration. However, challenges such as expensive computational cost, high\ninference latency, and difficulties of integration with large language models\n(LLMs) have necessitated exploring alternatives to DMs. This paper introduces\nControlVAR, a novel framework that explores pixel-level controls in visual\nautoregressive (VAR) modeling for flexible and efficient conditional\ngeneration. In contrast to traditional conditional models that learn the\nconditional distribution, ControlVAR jointly models the distribution of image\nand pixel-level conditions during training and imposes conditional controls\nduring testing. To enhance the joint modeling, we adopt the next-scale AR\nprediction paradigm and unify control and image representations. A\nteacher-forcing guidance strategy is proposed to further facilitate\ncontrollable generation with joint modeling. Extensive experiments demonstrate\nthe superior efficacy and flexibility of ControlVAR across various conditional\ngeneration tasks against popular conditional DMs, \\eg, ControlNet and\nT2I-Adaptor.", "paper_summary_zh": "\u689d\u4ef6\u8996\u89ba\u751f\u6210\u5728\u64f4\u6563\u6a21\u578b (DM) \u7684\u51fa\u73fe\u5f8c\uff0c\u7279\u5225\u662f\u5728\u63a7\u5236\u5230\u5f71\u50cf\u751f\u6210\u7b49\u4efb\u52d9\u4e0a\uff0c\u898b\u8b49\u4e86\u986f\u8457\u7684\u9032\u5c55\u3002\u7136\u800c\uff0c\u6602\u8cb4\u7684\u8a08\u7b97\u6210\u672c\u3001\u9ad8\u63a8\u7406\u5ef6\u9072\u4ee5\u53ca\u8207\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6574\u5408\u7684\u56f0\u96e3\u7b49\u6311\u6230\uff0c\u4f7f\u5f97\u63a2\u7d22 DM \u7684\u66ff\u4ee3\u65b9\u6848\u8b8a\u5f97\u5fc5\u8981\u3002\u672c\u6587\u4ecb\u7d39 ControlVAR\uff0c\u4e00\u500b\u65b0\u7684\u6846\u67b6\uff0c\u63a2\u7d22\u50cf\u7d20\u7d1a\u5225\u63a7\u5236\u5728\u8996\u89ba\u81ea\u8ff4\u6b78 (VAR) \u5efa\u6a21\u4e2d\uff0c\u4ee5\u5be6\u73fe\u9748\u6d3b\u4e14\u9ad8\u6548\u7684\u689d\u4ef6\u5f0f\u751f\u6210\u3002\u8207\u5b78\u7fd2\u689d\u4ef6\u5f0f\u5206\u5e03\u7684\u50b3\u7d71\u689d\u4ef6\u5f0f\u6a21\u578b\u76f8\u6bd4\uff0cControlVAR \u5728\u8a13\u7df4\u671f\u9593\u806f\u5408\u5efa\u6a21\u5f71\u50cf\u548c\u50cf\u7d20\u7d1a\u5225\u689d\u4ef6\u7684\u5206\u5e03\uff0c\u4e26\u5728\u6e2c\u8a66\u671f\u9593\u65bd\u52a0\u689d\u4ef6\u5f0f\u63a7\u5236\u3002\u70ba\u4e86\u589e\u5f37\u806f\u5408\u5efa\u6a21\uff0c\u6211\u5011\u63a1\u7528\u4e86\u4e0b\u4e00\u500b\u5c3a\u5ea6\u7684 AR \u9810\u6e2c\u7bc4\u4f8b\uff0c\u4e26\u7d71\u4e00\u63a7\u5236\u548c\u5f71\u50cf\u8868\u793a\u3002\u63d0\u51fa\u4e86\u4e00\u500b\u6559\u5e2b\u5f37\u5236\u6307\u5c0e\u7b56\u7565\uff0c\u4ee5\u9032\u4e00\u6b65\u4fc3\u9032\u806f\u5408\u5efa\u6a21\u7684\u53ef\u63a7\u751f\u6210\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\u4e86 ControlVAR \u5728\u5404\u7a2e\u689d\u4ef6\u5f0f\u751f\u6210\u4efb\u52d9\u4e2d\uff0c\u76f8\u8f03\u65bc\u6d41\u884c\u7684\u689d\u4ef6\u5f0f DM\uff0c\u4f8b\u5982 ControlNet \u548c T2I-Adaptor\uff0c\u5177\u6709\u512a\u7570\u7684\u6548\u80fd\u548c\u9748\u6d3b\u6027\u3002", "author": "Xiang Li et.al.", "authors": "Xiang Li, Kai Qiu, Hao Chen, Jason Kuen, Zhe Lin, Rita Singh, Bhiksha Raj", "id": "2406.09750v1", "paper_url": "http://arxiv.org/abs/2406.09750v1", "repo": "null"}}