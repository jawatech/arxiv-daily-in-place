{"2410.01707": {"publish_time": "2024-10-02", "title": "Interpretable Contrastive Monte Carlo Tree Search Reasoning", "paper_summary": "We propose SC-MCTS*: a novel Monte Carlo Tree Search (MCTS) reasoning\nalgorithm for Large Language Models (LLMs), significantly improves both\nreasoning accuracy and speed. Our motivation comes from: 1. Previous MCTS LLM\nreasoning works often overlooked its biggest drawback--slower speed compared to\nCoT; 2. Previous research mainly used MCTS as a tool for LLM reasoning on\nvarious tasks with limited quantitative analysis or ablation studies of its\ncomponents from reasoning interpretability perspective. 3. The reward model is\nthe most crucial component in MCTS, however previous work has rarely conducted\nin-depth study or improvement of MCTS's reward models. Thus, we conducted\nextensive ablation studies and quantitative analysis on components of MCTS,\nrevealing the impact of each component on the MCTS reasoning performance of\nLLMs. Building on this, (i) we designed a highly interpretable reward model\nbased on the principle of contrastive decoding and (ii) achieved an average\nspeed improvement of 51.9% per node using speculative decoding. Additionally,\n(iii) we improved UCT node selection strategy and backpropagation used in\nprevious works, resulting in significant performance improvement. We\noutperformed o1-mini by an average of 17.4% on the Blocksworld multi-step\nreasoning dataset using Llama-3.1-70B with SC-MCTS*.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa SC-MCTS*\uff1a\u4e00\u7a2e\u65b0\u7a4e\u7684\u8499\u5730\u5361\u7f85\u6a39\u641c\u5c0b (MCTS) \u63a8\u7406\u6f14\u7b97\u6cd5\uff0c\u9069\u7528\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u5927\u5e45\u63d0\u5347\u63a8\u7406\u6e96\u78ba\u5ea6\u548c\u901f\u5ea6\u3002\u6211\u5011\u7684\u52d5\u6a5f\u4f86\u81ea\u65bc\uff1a1. \u5148\u524d\u7684 MCTS LLM \u63a8\u7406\u7814\u7a76\u901a\u5e38\u5ffd\u7565\u5176\u6700\u5927\u7684\u7f3a\u9ede\u2014\u2014\u8207 CoT \u76f8\u6bd4\u901f\u5ea6\u8f03\u6162\uff1b2. \u5148\u524d\u7684\u7814\u7a76\u4e3b\u8981\u5c07 MCTS \u7528\u4f5c LLM \u5728\u5404\u7a2e\u4efb\u52d9\u4e0a\u9032\u884c\u63a8\u7406\u7684\u5de5\u5177\uff0c\u4f46\u5c0d\u5176\u7d44\u6210\u90e8\u5206\u5f9e\u63a8\u7406\u53ef\u89e3\u91cb\u6027\u7684\u89d2\u5ea6\u9032\u884c\u7684\u91cf\u5316\u5206\u6790\u6216\u6d88\u878d\u7814\u7a76\u6709\u9650\u30023. \u734e\u52f5\u6a21\u578b\u662f MCTS \u4e2d\u6700\u91cd\u8981\u7684\u7d44\u6210\u90e8\u5206\uff0c\u4f46\u5148\u524d\u7684\u7814\u7a76\u5f88\u5c11\u5c0d MCTS \u7684\u734e\u52f5\u6a21\u578b\u9032\u884c\u6df1\u5165\u7684\u7814\u7a76\u6216\u6539\u9032\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5c0d MCTS \u7684\u7d44\u6210\u90e8\u5206\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u6d88\u878d\u7814\u7a76\u548c\u91cf\u5316\u5206\u6790\uff0c\u63ed\u793a\u4e86\u6bcf\u500b\u7d44\u6210\u90e8\u5206\u5c0d LLM \u7684 MCTS \u63a8\u7406\u6548\u80fd\u7684\u5f71\u97ff\u3002\u5728\u6b64\u57fa\u790e\u4e0a\uff0c(i) \u6211\u5011\u6839\u64da\u5c0d\u6bd4\u89e3\u78bc\u7684\u539f\u7406\u8a2d\u8a08\u4e86\u4e00\u500b\u9ad8\u5ea6\u53ef\u89e3\u91cb\u7684\u734e\u52f5\u6a21\u578b\uff0c\u4e26 (ii) \u4f7f\u7528\u63a8\u6e2c\u6027\u89e3\u78bc\u5be6\u73fe\u4e86\u6bcf\u500b\u7bc0\u9ede\u5e73\u5747 51.9% \u7684\u901f\u5ea6\u63d0\u5347\u3002\u6b64\u5916\uff0c(iii) \u6211\u5011\u6539\u9032\u4e86\u5148\u524d\u7684\u7814\u7a76\u4e2d\u4f7f\u7528\u7684 UCT \u7bc0\u9ede\u9078\u64c7\u7b56\u7565\u548c\u53cd\u5411\u50b3\u64ad\uff0c\u5f9e\u800c\u986f\u8457\u63d0\u5347\u6548\u80fd\u3002\u4f7f\u7528 Llama-3.1-70B \u642d\u914d SC-MCTS*\uff0c\u6211\u5011\u5728 Blocksworld \u591a\u6b65\u9a5f\u63a8\u7406\u8cc7\u6599\u96c6\u4e0a\u5e73\u5747\u512a\u65bc o1-mini 17.4%\u3002", "author": "Zitian Gao et.al.", "authors": "Zitian Gao, Boye Niu, Xuzheng He, Haotian Xu, Hongzhang Liu, Aiwei Liu, Xuming Hu, Lijie Wen", "id": "2410.01707v1", "paper_url": "http://arxiv.org/abs/2410.01707v1", "repo": "null"}}