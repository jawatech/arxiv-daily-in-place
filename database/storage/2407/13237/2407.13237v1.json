{"2407.13237": {"publish_time": "2024-07-18", "title": "LLM-Empowered State Representation for Reinforcement Learning", "paper_summary": "Conventional state representations in reinforcement learning often omit\ncritical task-related details, presenting a significant challenge for value\nnetworks in establishing accurate mappings from states to task rewards.\nTraditional methods typically depend on extensive sample learning to enrich\nstate representations with task-specific information, which leads to low sample\nefficiency and high time costs. Recently, surging knowledgeable large language\nmodels (LLM) have provided promising substitutes for prior injection with\nminimal human intervention. Motivated by this, we propose LLM-Empowered State\nRepresentation (LESR), a novel approach that utilizes LLM to autonomously\ngenerate task-related state representation codes which help to enhance the\ncontinuity of network mappings and facilitate efficient training. Experimental\nresults demonstrate LESR exhibits high sample efficiency and outperforms\nstate-of-the-art baselines by an average of 29% in accumulated reward in Mujoco\ntasks and 30% in success rates in Gym-Robotics tasks.", "paper_summary_zh": "\u50b3\u7d71\u7684\u5f37\u5316\u5b78\u7fd2\u4e2d\u7684\u72c0\u614b\u8868\u793a\u901a\u5e38\u6703\u907a\u6f0f\n\u8207\u4efb\u52d9\u76f8\u95dc\u7684\u95dc\u9375\u7d30\u7bc0\uff0c\u9019\u5c0d\u50f9\u503c\n\u7db2\u8def\u5728\u5efa\u7acb\u5f9e\u72c0\u614b\u5230\u4efb\u52d9\u734e\u52f5\u7684\u7cbe\u78ba\u5c0d\u61c9\u6642\u6703\u9020\u6210\u91cd\u5927\u7684\u6311\u6230\u3002\n\u50b3\u7d71\u65b9\u6cd5\u901a\u5e38\u4f9d\u8cf4\u65bc\u5ee3\u6cdb\u7684\u6a23\u672c\u5b78\u7fd2\uff0c\u4ee5\u8c50\u5bcc\n\u4efb\u52d9\u7279\u5b9a\u8cc7\u8a0a\u7684\u72c0\u614b\u8868\u793a\uff0c\u9019\u6703\u5c0e\u81f4\u4f4e\u6a23\u672c\n\u6548\u7387\u548c\u9ad8\u6642\u9593\u6210\u672c\u3002\u6700\u8fd1\uff0c\u6fc0\u589e\u7684\u77e5\u8b58\u578b\u5927\u578b\u8a9e\u8a00\n\u6a21\u578b (LLM) \u5df2\u7d93\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u53ef\u4ee5\u900f\u904e\n\u6700\u5c11\u7684\u4eba\u5de5\u4ecb\u5165\u4f86\u9032\u884c\u5148\u524d\u7684\u6ce8\u5165\u3002\u53d7\u6b64\u555f\u767c\uff0c\u6211\u5011\u63d0\u51fa LLM \u5f37\u5316\u72c0\u614b\n\u8868\u793a (LESR)\uff0c\u9019\u662f\u4e00\u7a2e\u5229\u7528 LLM \u81ea\u4e3b\n\u7522\u751f\u8207\u4efb\u52d9\u76f8\u95dc\u7684\u72c0\u614b\u8868\u793a\u78bc\u7684\u65b0\u65b9\u6cd5\uff0c\u6709\u52a9\u65bc\u589e\u5f37\n\u7db2\u8def\u5c0d\u61c9\u7684\u9023\u7e8c\u6027\u4e26\u4fc3\u9032\u6709\u6548\u8a13\u7df4\u3002\u5be6\u9a57\n\u7d50\u679c\u8b49\u660e LESR \u5c55\u73fe\u51fa\u9ad8\u6a23\u672c\u6548\u7387\uff0c\u4e26\u4e14\u5728 Mujoco\n\u4efb\u52d9\u4e2d\u7d2f\u7a4d\u734e\u52f5\u7684\u8868\u73fe\u6bd4\u6700\u5148\u9032\u7684\u57fa\u6e96\u9ad8\u51fa\u5e73\u5747 29%\uff0c\u800c\u5728 Gym-Robotics \u4efb\u52d9\u4e2d\u7684\u6210\u529f\u7387\u5247\u9ad8\u51fa 30%\u3002", "author": "Boyuan Wang et.al.", "authors": "Boyuan Wang, Yun Qu, Yuhang Jiang, Jianzhun Shao, Chang Liu, Wenming Yang, Xiangyang Ji", "id": "2407.13237v1", "paper_url": "http://arxiv.org/abs/2407.13237v1", "repo": "null"}}