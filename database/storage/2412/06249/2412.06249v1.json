{"2412.06249": {"publish_time": "2024-12-09", "title": "Optimizing Multi-Task Learning for Enhanced Performance in Large Language Models", "paper_summary": "This study aims to explore the performance improvement method of large\nlanguage models based on GPT-4 under the multi-task learning framework and\nconducts experiments on two tasks: text classification and automatic summary\ngeneration. Through the combined design of shared feature extractors and\ntask-specific modules, we achieve knowledge-sharing and optimization of\nmultiple tasks in the same model. The experiment uses multiple subtasks of the\nGLUE dataset to compare the performance of the multi-task model with the\nsingle-task GPT-4, the multi-task version of GPT-3, the BERT basic model, and\nthe classic Bi-LSTM with Attention model. The results show that the proposed\nmulti-task learning model outperforms other comparison models in terms of text\nclassification accuracy and ROUGE value of summary generation, demonstrating\nthe advantages of multi-task learning in improving model generalization ability\nand collaborative learning between tasks. The model maintains a stable loss\nconvergence rate during training, showing good learning efficiency and\nadaptability to the test set. This study verifies the applicability of the\nmulti-task learning framework in large language models, especially in improving\nthe model's ability to balance different tasks. In the future, with the\ncombination of large language models and multimodal data and the application of\ndynamic task adjustment technology, the framework based on multi-task learning\nis expected to play a greater role in practical applications across fields and\nprovide new ideas for the development of general artificial intelligence.", "paper_summary_zh": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u57fa\u65bc GPT-4 \u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u5728\u591a\u4efb\u52d9\u5b78\u7fd2\u67b6\u69cb\u4e0b\u7684\u6548\u80fd\u63d0\u5347\u65b9\u6cd5\uff0c\u4e26\u91dd\u5c0d\u5169\u500b\u4efb\u52d9\u9032\u884c\u5be6\u9a57\uff1a\u6587\u5b57\u5206\u985e\u548c\u81ea\u52d5\u6458\u8981\u751f\u6210\u3002\u900f\u904e\u5171\u4eab\u7279\u5fb5\u8403\u53d6\u5668\u548c\u7279\u5b9a\u4efb\u52d9\u6a21\u7d44\u7684\u7d50\u5408\u8a2d\u8a08\uff0c\u6211\u5011\u5728\u540c\u4e00\u500b\u6a21\u578b\u4e2d\u5be6\u73fe\u4e86\u77e5\u8b58\u5171\u4eab\u8207\u591a\u4efb\u52d9\u7684\u6700\u4f73\u5316\u3002\u5be6\u9a57\u4f7f\u7528 GLUE \u8cc7\u6599\u96c6\u7684\u5b50\u4efb\u52d9\uff0c\u4f86\u6bd4\u8f03\u591a\u4efb\u52d9\u6a21\u578b\u8207\u55ae\u4efb\u52d9 GPT-4\u3001\u591a\u4efb\u52d9\u7248\u672c\u7684 GPT-3\u3001BERT \u57fa\u672c\u6a21\u578b\u3001\u4ee5\u53ca\u7d93\u5178\u7684\u6ce8\u610f\u529b\u6a5f\u5236\u96d9\u5411 LSTM \u6a21\u578b\u7684\u6548\u80fd\u3002\u7d50\u679c\u986f\u793a\uff0c\u63d0\u51fa\u7684\u591a\u4efb\u52d9\u5b78\u7fd2\u6a21\u578b\u5728\u6587\u5b57\u5206\u985e\u6e96\u78ba\u5ea6\u548c\u6458\u8981\u751f\u6210\u7684 ROUGE \u503c\u65b9\u9762\uff0c\u512a\u65bc\u5176\u4ed6\u6bd4\u8f03\u6a21\u578b\uff0c\u8b49\u660e\u4e86\u591a\u4efb\u52d9\u5b78\u7fd2\u5728\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u548c\u4efb\u52d9\u9593\u5354\u540c\u5b78\u7fd2\u7684\u512a\u52e2\u3002\u8a72\u6a21\u578b\u5728\u8a13\u7df4\u904e\u7a0b\u4e2d\u7dad\u6301\u7a69\u5b9a\u7684\u640d\u5931\u6536\u6582\u901f\u5ea6\uff0c\u5c55\u73fe\u826f\u597d\u7684\u5b78\u7fd2\u6548\u7387\u548c\u5c0d\u6e2c\u8a66\u96c6\u7684\u9069\u61c9\u6027\u3002\u672c\u7814\u7a76\u9a57\u8b49\u4e86\u591a\u4efb\u52d9\u5b78\u7fd2\u67b6\u69cb\u5728\u5927\u8a9e\u8a00\u6a21\u578b\u4e2d\u7684\u9069\u7528\u6027\uff0c\u7279\u5225\u662f\u5728\u63d0\u5347\u6a21\u578b\u5e73\u8861\u4e0d\u540c\u4efb\u52d9\u7684\u80fd\u529b\u65b9\u9762\u3002\u672a\u4f86\uff0c\u96a8\u8457\u5927\u8a9e\u8a00\u6a21\u578b\u8207\u591a\u6a21\u614b\u8cc7\u6599\u7684\u7d50\u5408\uff0c\u4ee5\u53ca\u52d5\u614b\u4efb\u52d9\u8abf\u6574\u6280\u8853\u7684\u61c9\u7528\uff0c\u57fa\u65bc\u591a\u4efb\u52d9\u5b78\u7fd2\u7684\u6846\u67b6\u9810\u671f\u5c07\u5728\u8de8\u9818\u57df\u7684\u5be6\u969b\u61c9\u7528\u4e2d\u767c\u63ee\u66f4\u5927\u7684\u4f5c\u7528\uff0c\u4e26\u70ba\u901a\u7528\u4eba\u5de5\u667a\u6167\u7684\u767c\u5c55\u63d0\u4f9b\u65b0\u7684\u601d\u8def\u3002", "author": "Zhen Qi et.al.", "authors": "Zhen Qi, Jiajing Chen, Shuo Wang, Bingying Liu, Hongye Zheng, Chihang Wang", "id": "2412.06249v1", "paper_url": "http://arxiv.org/abs/2412.06249v1", "repo": "null"}}