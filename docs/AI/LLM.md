
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-27**|**PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation**|Shaowei Liu et.al.|[2409.18964v1](http://arxiv.org/abs/2409.18964v1)|[link](https://github.com/stevenlsw/physgen)|
|**2024-09-27**|**Exploring Token Pruning in Vision State Space Models**|Zheng Zhan et.al.|[2409.18962v1](http://arxiv.org/abs/2409.18962v1)|null|
|**2024-09-27**|**ProMerge: Prompt and Merge for Unsupervised Instance Segmentation**|Dylan Li et.al.|[2409.18961v1](http://arxiv.org/abs/2409.18961v1)|null|
|**2024-09-27**|**$O(d/T)$ Convergence Theory for Diffusion Probabilistic Models under Minimal Assumptions**|Gen Li et.al.|[2409.18959v1](http://arxiv.org/abs/2409.18959v1)|null|
|**2024-09-27**|**LML: Language Model Learning a Dataset for Data-Augmented Prediction**|Praneeth Vadlapati et.al.|[2409.18957v1](http://arxiv.org/abs/2409.18957v1)|[link](https://github.com/pro-genai/lml-dap)|
|**2024-09-27**|**Unconditional stability of a recurrent neural circuit implementing divisive normalization**|Shivang Rawat et.al.|[2409.18946v1](http://arxiv.org/abs/2409.18946v1)|null|
|**2024-09-27**|**Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models**|Jiaming Li et.al.|[2409.18943v1](http://arxiv.org/abs/2409.18943v1)|[link](https://github.com/geaming2002/ruler)|
|**2024-09-27**|**From Seconds to Hours: Reviewing MultiModal Large Language Models on Comprehensive Long Video Understanding**|Heqing Zou et.al.|[2409.18938v1](http://arxiv.org/abs/2409.18938v1)|null|
|**2024-09-27**|**AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**|Huizi Yu et.al.|[2409.18924v1](http://arxiv.org/abs/2409.18924v1)|null|
|**2024-09-27**|**Soft Measures for Extracting Causal Collective Intelligence**|Maryam Berijanian et.al.|[2409.18911v1](http://arxiv.org/abs/2409.18911v1)|[link](https://github.com/kuldeep7688/soft-measures-causal-intelligence)|
|**2024-09-27**|**Improving Visual Object Tracking through Visual Prompting**|Shih-Fang Chen et.al.|[2409.18901v1](http://arxiv.org/abs/2409.18901v1)|[link](https://github.com/chenshihfang/GOT)|
|**2024-09-27**|**Multi-Source Hard and Soft Information Fusion Approach for Accurate Cryptocurrency Price Movement Prediction**|Saeed Mohammadi Dashtaki et.al.|[2409.18895v1](http://arxiv.org/abs/2409.18895v1)|null|
|**2024-09-27**|**IDGen: Item Discrimination Induced Prompt Generation for LLM Evaluation**|Fan Lin et.al.|[2409.18892v1](http://arxiv.org/abs/2409.18892v1)|null|
|**2024-09-27**|**Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models**|Zehan Li et.al.|[2409.18878v1](http://arxiv.org/abs/2409.18878v1)|null|
|**2024-09-27**|**UniEmoX: Cross-modal Semantic-Guided Large-Scale Pretraining for Universal Scene Emotion Perception**|Chuang Chen et.al.|[2409.18877v1](http://arxiv.org/abs/2409.18877v1)|null|
|**2024-09-27**|**CESNET-TimeSeries24: Time Series Dataset for Network Traffic Anomaly Detection and Forecasting**|Josef Koumar et.al.|[2409.18874v1](http://arxiv.org/abs/2409.18874v1)|null|
|**2024-09-27**|**Individuation in Neural Models with and without Visual Grounding**|Alexey Tikhonov et.al.|[2409.18868v1](http://arxiv.org/abs/2409.18868v1)|null|
|**2024-09-27**|**Positional Encoder Graph Quantile Neural Networks for Geographic Data**|William E. R. de Amorim et.al.|[2409.18865v1](http://arxiv.org/abs/2409.18865v1)|null|
|**2024-09-27**|**Mitigating Selection Bias with Node Pruning and Auxiliary Options**|Hyeong Kyu Choi et.al.|[2409.18857v1](http://arxiv.org/abs/2409.18857v1)|null|
|**2024-09-27**|**MECG-E: Mamba-based ECG Enhancer for Baseline Wander Removal**|Kuo-Hsuan Hung et.al.|[2409.18828v1](http://arxiv.org/abs/2409.18828v1)|null|
|**2024-09-27**|**Local Transcription Models in Home Care Nursing in Switzerland: an Interdisciplinary Case Study**|Jeremy Kramer et.al.|[2409.18819v1](http://arxiv.org/abs/2409.18819v1)|null|
|**2024-09-27**|**Early diagnosis of Alzheimer's disease from MRI images with deep learning model**|Sajjad Aghasi Javid et.al.|[2409.18814v1](http://arxiv.org/abs/2409.18814v1)|null|
|**2024-09-27**|**LLMs4Synthesis: Leveraging Large Language Models for Scientific Synthesis**|Hamed Babaei Giglou et.al.|[2409.18812v1](http://arxiv.org/abs/2409.18812v1)|null|
|**2024-09-27**|**Esports Debut as a Medal Event at 2023 Asian Games: Exploring Public Perceptions with BERTopic and GPT-4 Topic Fine-Tuning**|Tyreal Yizhou Qian et.al.|[2409.18798v1](http://arxiv.org/abs/2409.18798v1)|null|
|**2024-09-27**|**A Survey on the Honesty of Large Language Models**|Siheng Li et.al.|[2409.18786v1](http://arxiv.org/abs/2409.18786v1)|[link](https://github.com/sihengli99/llm-honesty-survey)|
|**2024-09-27**|**State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features**|George R. Nahass et.al.|[2409.18769v1](http://arxiv.org/abs/2409.18769v1)|null|
|**2024-09-27**|**Learning from Demonstration with Implicit Nonlinear Dynamics Models**|Peter David Fagan et.al.|[2409.18768v1](http://arxiv.org/abs/2409.18768v1)|null|
|**2024-09-27**|**Charting the Future: Using Chart Question-Answering for Scalable Evaluation of LLM-Driven Data Visualizations**|James Ford et.al.|[2409.18764v1](http://arxiv.org/abs/2409.18764v1)|null|
|**2024-09-27**|**OpenObject-NAV: Open-Vocabulary Object-Oriented Navigation Based on Dynamic Carrier-Relationship Scene Graph**|Yujie Tang et.al.|[2409.18743v1](http://arxiv.org/abs/2409.18743v1)|null|
|**2024-09-27**|**Cross-Domain Keyword Extraction with Keyness Patterns**|Dongmei Zhou et.al.|[2409.18724v1](http://arxiv.org/abs/2409.18724v1)|null|
|**2024-09-27**|**Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification**|Salma Hassan et.al.|[2409.18715v1](http://arxiv.org/abs/2409.18715v1)|null|
|**2024-09-27**|**Read Over the Lines: Attacking LLMs and Toxicity Detection Systems with ASCII Art to Mask Profanity**|Sergey Berezin et.al.|[2409.18708v1](http://arxiv.org/abs/2409.18708v1)|null|
|**2024-09-27**|**Speech Boosting: Low-Latency Live Speech Enhancement for TWS Earbuds**|Hanbin Bae et.al.|[2409.18705v1](http://arxiv.org/abs/2409.18705v1)|null|
|**2024-09-27**|**Semantic Model Component Implementation for Model-driven Semantic Communications**|Haotai Liang et.al.|[2409.18704v1](http://arxiv.org/abs/2409.18704v1)|null|
|**2024-09-27**|**KALE-LM: Unleash The Power Of AI For Science Via Knowledge And Logic Enhanced Large Model**|Weichen Dai et.al.|[2409.18695v1](http://arxiv.org/abs/2409.18695v1)|null|
|**2024-09-27**|**MG-Net: Learn to Customize QAOA with Circuit Depth Awareness**|Yang Qian et.al.|[2409.18692v1](http://arxiv.org/abs/2409.18692v1)|[link](https://github.com/QQQYang/MG-Net)|
|**2024-09-27**|**Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models**|Yiming Chen et.al.|[2409.18680v1](http://arxiv.org/abs/2409.18680v1)|null|
|**2024-09-27**|**"Why" Has the Least Side Effect on Model Editing**|Tsung-Hsuan Pan et.al.|[2409.18679v1](http://arxiv.org/abs/2409.18679v1)|null|
|**2024-09-27**|**Rehearsing Answers to Probable Questions with Perspective-Taking**|Yung-Yu Shih et.al.|[2409.18678v1](http://arxiv.org/abs/2409.18678v1)|null|
|**2024-09-27**|**Toward Universal and Interpretable World Models for Open-ended Learning Agents**|Lancelot Da Costa et.al.|[2409.18676v1](http://arxiv.org/abs/2409.18676v1)|null|
|**2024-09-27**|**Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practice**|Eddie Antonio Santos et.al.|[2409.18661v1](http://arxiv.org/abs/2409.18661v1)|null|
|**2024-09-27**|**When SAM2 Meets Video Camouflaged Object Segmentation: A Comprehensive Evaluation and Adaptation**|Yuli Zhou et.al.|[2409.18653v1](http://arxiv.org/abs/2409.18653v1)|[link](https://github.com/zhoustan/sam2-vcos)|
|**2024-09-27**|**HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents**|T. Y. S. S. Santosh et.al.|[2409.18647v1](http://arxiv.org/abs/2409.18647v1)|null|
|**2024-09-27**|**The Craft of Selective Prediction: Towards Reliable Case Outcome Classification -- An Empirical Study on European Court of Human Rights Cases**|T. Y. S. S. Santosh et.al.|[2409.18645v1](http://arxiv.org/abs/2409.18645v1)|null|
|**2024-09-27**|**Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases**|T. Y. S. S. Santosh et.al.|[2409.18644v1](http://arxiv.org/abs/2409.18644v1)|null|
|**2024-09-27**|**Entropy, concentration, and learning: a statistical mechanics primer**|Akshay Balsubramani et.al.|[2409.18630v1](http://arxiv.org/abs/2409.18630v1)|null|
|**2024-09-27**|**Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow**|Marvin Tom Teichmann et.al.|[2409.18628v1](http://arxiv.org/abs/2409.18628v1)|null|
|**2024-09-27**|**Unsupervised Cognition**|Alfredo Ibias et.al.|[2409.18624v1](http://arxiv.org/abs/2409.18624v1)|null|
|**2024-09-27**|**Model-based Preference Optimization in Abstractive Summarization without Human Feedback**|Jaepill Choi et.al.|[2409.18618v1](http://arxiv.org/abs/2409.18618v1)|null|
|**2024-09-27**|**Do LLMs suffer from Multi-Party Hangover? A Diagnostic Approach to Addressee Recognition and Response Selection in Conversations**|Nicolò Penzo et.al.|[2409.18602v1](http://arxiv.org/abs/2409.18602v1)|null|
|**2024-09-27**|**TemporalPaD: a reinforcement-learning framework for temporal feature representation and dimension reduction**|Xuechen Mu et.al.|[2409.18597v1](http://arxiv.org/abs/2409.18597v1)|null|
|**2024-09-27**|**ASAG2024: A Combined Benchmark for Short Answer Grading**|Gérôme Meyer et.al.|[2409.18596v1](http://arxiv.org/abs/2409.18596v1)|null|
|**2024-09-27**|**"Oh LLM, I'm Asking Thee, Please Give Me a Decision Tree": Zero-Shot Decision Tree Induction and Embedding with Large Language Models**|Ricardo Knauer et.al.|[2409.18594v1](http://arxiv.org/abs/2409.18594v1)|null|
|**2024-09-27**|**Analysis of Truncated Singular Value Decomposition for Koopman Operator-Based Lane Change Model**|Chinnawut Nantabut et.al.|[2409.18586v1](http://arxiv.org/abs/2409.18586v1)|null|
|**2024-09-27**|**Hit the Sweet Spot! Span-Level Ensemble for Large Language Models**|Yangyifan Xu et.al.|[2409.18583v1](http://arxiv.org/abs/2409.18583v1)|null|
|**2024-09-27**|**An Enhanced Federated Prototype Learning Method under Domain Shift**|Liang Kuang et.al.|[2409.18578v1](http://arxiv.org/abs/2409.18578v1)|null|
|**2024-09-27**|**Experimental Evaluation of Machine Learning Models for Goal-oriented Customer Service Chatbot with Pipeline Architecture**|Nurul Ain Nabilah Mohd Isa et.al.|[2409.18568v1](http://arxiv.org/abs/2409.18568v1)|null|
|**2024-09-27**|**Efficient Noise Mitigation for Enhancing Inference Accuracy in DNNs on Mixed-Signal Accelerators**|Seyedarmin Azizi et.al.|[2409.18553v1](http://arxiv.org/abs/2409.18553v1)|null|
|**2024-09-27**|**Research on Predicting Public Opinion Event Heat Levels Based on Large Language Models**|Yi Ren et.al.|[2409.18548v1](http://arxiv.org/abs/2409.18548v1)|null|
|**2024-09-27**|**An Epistemic Human-Aware Task Planner which Anticipates Human Beliefs and Decisions**|Shashank Shekhar et.al.|[2409.18545v1](http://arxiv.org/abs/2409.18545v1)|null|
|**2024-09-27**|**MIMII-Gen: Generative Modeling Approach for Simulated Evaluation of Anomalous Sound Detection System**|Harsh Purohit et.al.|[2409.18542v1](http://arxiv.org/abs/2409.18542v1)|null|
|**2024-09-27**|**Align$^2$LLaVA: Cascaded Human and Large Language Model Preference Alignment for Multi-modal Instruction Curation**|Hongzhe Huang et.al.|[2409.18541v1](http://arxiv.org/abs/2409.18541v1)|null|
|**2024-09-27**|**A Survey on Complex Tasks for Goal-Directed Interactive Agents**|Mareike Hartmann et.al.|[2409.18538v1](http://arxiv.org/abs/2409.18538v1)|null|
|**2024-09-27**|**EmoPro: A Prompt Selection Strategy for Emotional Expression in LM-based Speech Synthesis**|Haoyu Wang et.al.|[2409.18512v1](http://arxiv.org/abs/2409.18512v1)|null|
|**2024-09-27**|**Do We Need Domain-Specific Embedding Models? An Empirical Investigation**|Yixuan Tang et.al.|[2409.18511v1](http://arxiv.org/abs/2409.18511v1)|[link](https://github.com/yixuantt/finmteb)|
|**2024-09-27**|**Fairness-aware Multiobjective Evolutionary Learning**|Qingquan Zhang et.al.|[2409.18499v1](http://arxiv.org/abs/2409.18499v1)|null|
|**2024-09-27**|**Evaluation of OpenAI o1: Opportunities and Challenges of AGI**|Tianyang Zhong et.al.|[2409.18486v1](http://arxiv.org/abs/2409.18486v1)|null|
|**2024-09-27**|**Data Analysis in the Era of Generative AI**|Jeevana Priya Inala et.al.|[2409.18475v1](http://arxiv.org/abs/2409.18475v1)|null|
|**2024-09-27**|**URIEL+: Enhancing Linguistic Inclusion and Usability in a Typological and Multilingual Knowledge Base**|Aditya Khan et.al.|[2409.18472v1](http://arxiv.org/abs/2409.18472v1)|null|
|**2024-09-27**|**Towards Diverse Device Heterogeneous Federated Learning via Task Arithmetic Knowledge Integration**|Mahdi Morafah et.al.|[2409.18461v1](http://arxiv.org/abs/2409.18461v1)|[link](https://github.com/mmorafah/takfl)|
|**2024-09-27**|**Review of Digital Asset Development with Graph Neural Network Unlearning**|Zara Lisbon et.al.|[2409.18455v1](http://arxiv.org/abs/2409.18455v1)|null|
|**2024-09-27**|**Leveraging Long-Context Large Language Models for Multi-Document Understanding and Summarization in Enterprise Applications**|Aditi Godbole et.al.|[2409.18454v1](http://arxiv.org/abs/2409.18454v1)|null|
|**2024-09-27**|**Exploring Language Model Generalization in Low-Resource Extractive QA**|Saptarshi Sengupta et.al.|[2409.18446v1](http://arxiv.org/abs/2409.18446v1)|null|
|**2024-09-27**|**Physics Augmented Tuple Transformer for Autism Severity Level Detection**|Chinthaka Ranasingha et.al.|[2409.18438v1](http://arxiv.org/abs/2409.18438v1)|null|
|**2024-09-27**|**Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization**|Mucong Ding et.al.|[2409.18433v1](http://arxiv.org/abs/2409.18433v1)|null|
|**2024-09-27**|**Improving Multilingual ASR in the Wild Using Simple N-best Re-ranking**|Brian Yan et.al.|[2409.18428v1](http://arxiv.org/abs/2409.18428v1)|null|
|**2024-09-27**|**A3: Active Adversarial Alignment for Source-Free Domain Adaptation**|Chrisantus Eze et.al.|[2409.18418v1](http://arxiv.org/abs/2409.18418v1)|null|
|**2024-09-27**|**VickreyFeedback: Cost-efficient Data Construction for Reinforcement Learning from Human Feedback**|Guoxi Zhang et.al.|[2409.18417v1](http://arxiv.org/abs/2409.18417v1)|null|
|**2024-09-27**|**SciDFM: A Large Language Model with Mixture-of-Experts for Science**|Liangtai Sun et.al.|[2409.18412v1](http://arxiv.org/abs/2409.18412v1)|null|
|**2024-09-27**|**BoT-Drive: Hierarchical Behavior and Trajectory Planning for Autonomous Driving using POMDPs**|Xuanjin Jin et.al.|[2409.18411v1](http://arxiv.org/abs/2409.18411v1)|null|
|**2024-09-27**|**GenesisTex2: Stable, Consistent and High-Quality Text-to-Texture Generation**|Jiawei Lu et.al.|[2409.18401v1](http://arxiv.org/abs/2409.18401v1)|null|
|**2024-09-27**|**Code Vulnerability Repair with Large Language Model using Context-Aware Prompt Tuning**|Arshiya Khan et.al.|[2409.18395v1](http://arxiv.org/abs/2409.18395v1)|null|
|**2024-09-27**|**Speech to Reality: On-Demand Production using Natural Language, 3D Generative AI, and Discrete Robotic Assembly**|Alexander Htet Kyaw et.al.|[2409.18390v1](http://arxiv.org/abs/2409.18390v1)|null|
|**2024-09-27**|**Adaptive Learning of the Latent Space of Wasserstein Generative Adversarial Networks**|Yixuan Qiu et.al.|[2409.18374v1](http://arxiv.org/abs/2409.18374v1)|null|
|**2024-09-27**|**Multi-hypotheses Conditioned Point Cloud Diffusion for 3D Human Reconstruction from Occluded Images**|Donghwan Kim et.al.|[2409.18364v1](http://arxiv.org/abs/2409.18364v1)|null|
|**2024-09-26**|**MultiClimate: Multimodal Stance Detection on Climate Change Videos**|Jiawen Wang et.al.|[2409.18346v1](http://arxiv.org/abs/2409.18346v1)|[link](https://github.com/werywjw/multiclimate)|
|**2024-09-26**|**A Generalized LLM-Augmented BIM Framework: Application to a Speech-to-BIM system**|Ghang Lee et.al.|[2409.18345v1](http://arxiv.org/abs/2409.18345v1)|null|
|**2024-09-26**|**Improving Agent Behaviors with RL Fine-tuning for Autonomous Driving**|Zhenghao Peng et.al.|[2409.18343v1](http://arxiv.org/abs/2409.18343v1)|null|
|**2024-09-26**|**DRL-STNet: Unsupervised Domain Adaptation for Cross-modality Medical Image Segmentation via Disentangled Representation Learning**|Hui Lin et.al.|[2409.18340v1](http://arxiv.org/abs/2409.18340v1)|null|
|**2024-09-26**|**AER-LLM: Ambiguity-aware Emotion Recognition Leveraging Large Language Models**|Xin Hong et.al.|[2409.18339v1](http://arxiv.org/abs/2409.18339v1)|null|
|**2024-09-26**|**A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies**|Ryan Shea et.al.|[2409.18335v1](http://arxiv.org/abs/2409.18335v1)|null|
|**2024-09-26**|**Cross-Institutional Structured Radiology Reporting for Lung Cancer Screening Using a Dynamic Template-Constrained Large Language Model**|Chuang Niu et.al.|[2409.18319v1](http://arxiv.org/abs/2409.18319v1)|null|
|**2024-09-26**|**Realistic Evaluation of Model Merging for Compositional Generalization**|Derek Tam et.al.|[2409.18314v1](http://arxiv.org/abs/2409.18314v1)|null|
|**2024-09-26**|**Embodied-RAG: General non-parametric Embodied Memory for Retrieval and Generation**|Quanting Xie et.al.|[2409.18313v1](http://arxiv.org/abs/2409.18313v1)|null|
|**2024-09-26**|**Harnessing Wavelet Transformations for Generalizable Deepfake Forgery Detection**|Lalith Bharadwaj Baru et.al.|[2409.18301v1](http://arxiv.org/abs/2409.18301v1)|[link](https://github.com/lalithbharadwajbaru/wavelet-clip)|
|**2024-09-26**|**SOAR: Self-supervision Optimized UAV Action Recognition with Efficient Object-Aware Pretraining**|Ruiqi Xian et.al.|[2409.18300v1](http://arxiv.org/abs/2409.18300v1)|null|
|**2024-09-26**|**Flat'n'Fold: A Diverse Multi-Modal Dataset for Garment Perception and Manipulation**|Lipeng Zhuang et.al.|[2409.18297v1](http://arxiv.org/abs/2409.18297v1)|null|
|**2024-09-26**|**Enhancing Lossy Compression Through Cross-Field Information for Scientific Applications**|Youyuan Liu et.al.|[2409.18295v1](http://arxiv.org/abs/2409.18295v1)|null|
|**2024-09-26**|**Retrospective Comparative Analysis of Prostate Cancer In-Basket Messages: Responses from Closed-Domain LLM vs. Clinical Teams**|Yuexing Hao et.al.|[2409.18290v1](http://arxiv.org/abs/2409.18290v1)|null|
|**2024-09-26**|**Advancing Object Detection in Transportation with Multimodal Large Language Models (MLLMs): A Comprehensive Review and Empirical Testing**|Huthaifa I. Ashqar et.al.|[2409.18286v1](http://arxiv.org/abs/2409.18286v1)|null|

#### Abstracts
##### **PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation**
2409.18964v1 by Shaowei Liu, Zhongzheng Ren, Saurabh Gupta, Shenlong Wang

We present PhysGen, a novel image-to-video generation method that converts a
single image and an input condition (e.g., force and torque applied to an
object in the image) to produce a realistic, physically plausible, and
temporally consistent video. Our key insight is to integrate model-based
physical simulation with a data-driven video generation process, enabling
plausible image-space dynamics. At the heart of our system are three core
components: (i) an image understanding module that effectively captures the
geometry, materials, and physical parameters of the image; (ii) an image-space
dynamics simulation model that utilizes rigid-body physics and inferred
parameters to simulate realistic behaviors; and (iii) an image-based rendering
and refinement module that leverages generative video diffusion to produce
realistic video footage featuring the simulated motion. The resulting videos
are realistic in both physics and appearance and are even precisely
controllable, showcasing superior results over existing data-driven
image-to-video generation works through quantitative comparison and
comprehensive user study. PhysGen's resulting videos can be used for various
downstream applications, such as turning an image into a realistic animation or
allowing users to interact with the image and create various dynamics. Project
page: https://stevenlsw.github.io/physgen/

摘要：我們提出 PhysGen，一種新穎的影像轉影片生成方法，它將單一影像和輸入條件（例如，施加於影像中物體的力矩和扭力）轉換為逼真、物理上合理且時間一致的影片。我們的關鍵見解是將基於模型的物理模擬與資料驅動的影片生成程序整合在一起，實現合理的影像空間動態。我們系統的核心有三個組成部分：(i) 有效擷取影像的幾何形狀、材質和物理參數的影像理解模組；(ii) 利用剛體物理和推論參數來模擬逼真行為的影像空間動態模擬模型；(iii) 利用生成式影片擴散來產生具有模擬動作的逼真影片畫面的基於影像的渲染和精煉模組。產生的影片在物理和外觀上都非常逼真，甚至可以精確控制，透過量化比較和全面的使用者研究，展示出比現有的資料驅動影像轉影片生成作品更好的結果。PhysGen 產生影片可應用於各種下游應用程式，例如將影像轉換成逼真的動畫，或允許使用者與影像互動並產生各種動態。專案頁面：https://stevenlsw.github.io/physgen/

##### **Exploring Token Pruning in Vision State Space Models**
2409.18962v1 by Zheng Zhan, Zhenglun Kong, Yifan Gong, Yushu Wu, Zichong Meng, Hangyu Zheng, Xuan Shen, Stratis Ioannidis, Wei Niu, Pu Zhao, Yanzhi Wang

State Space Models (SSMs) have the advantage of keeping linear computational
complexity compared to attention modules in transformers, and have been applied
to vision tasks as a new type of powerful vision foundation model. Inspired by
the observations that the final prediction in vision transformers (ViTs) is
only based on a subset of most informative tokens, we take the novel step of
enhancing the efficiency of SSM-based vision models through token-based
pruning. However, direct applications of existing token pruning techniques
designed for ViTs fail to deliver good performance, even with extensive
fine-tuning. To address this issue, we revisit the unique computational
characteristics of SSMs and discover that naive application disrupts the
sequential token positions. This insight motivates us to design a novel and
general token pruning method specifically for SSM-based vision models. We first
introduce a pruning-aware hidden state alignment method to stabilize the
neighborhood of remaining tokens for performance enhancement. Besides, based on
our detailed analysis, we propose a token importance evaluation method adapted
for SSM models, to guide the token pruning. With efficient implementation and
practical acceleration methods, our method brings actual speedup. Extensive
experiments demonstrate that our approach can achieve significant computation
reduction with minimal impact on performance across different tasks. Notably,
we achieve 81.7\% accuracy on ImageNet with a 41.6\% reduction in the FLOPs for
pruned PlainMamba-L3. Furthermore, our work provides deeper insights into
understanding the behavior of SSM-based vision models for future research.

摘要：狀態空間模型 (SSM) 的優點在於與Transformer中的注意力模組相比，它能保持線性運算複雜度，且已應用於視覺任務作為一種新型強大的視覺基礎模型。受到視覺Transformer (ViT) 中的最終預測僅基於最有資訊的代幣子集的觀察啟發，我們採取創新的步驟，透過基於代幣的剪枝來提升基於 SSM 的視覺模型的效率。然而，即使經過廣泛的微調，直接應用為 ViT 設計的現有代幣剪枝技術也無法提供良好的效能。為了解決這個問題，我們重新檢視 SSM 的獨特運算特性，並發現天真的應用會中斷順序代幣位置。這個見解激勵我們專門為基於 SSM 的視覺模型設計一種新穎且通用的代幣剪枝方法。我們首先引入一種修剪感知的隱藏狀態對齊方法，以穩定剩餘代幣的鄰域，進而提升效能。此外，根據我們的詳細分析，我們提出了一種適用於 SSM 模型的代幣重要性評估方法，以指導代幣剪枝。透過有效率的實作和實用的加速方法，我們的技術帶來了實際的加速。廣泛的實驗證明，我們的作法可以在不同的任務中實現顯著的運算減少，同時對效能的影響很小。值得注意的是，我們在 ImageNet 上實現了 81.7% 的準確度，修剪後的 PlainMamba-L3 的 FLOP 減少了 41.6%。此外，我們的研究提供了更深入的見解，以了解基於 SSM 的視覺模型的行為，供未來的研究參考。

##### **ProMerge: Prompt and Merge for Unsupervised Instance Segmentation**
2409.18961v1 by Dylan Li, Gyungin Shin

Unsupervised instance segmentation aims to segment distinct object instances
in an image without relying on human-labeled data. This field has recently seen
significant advancements, partly due to the strong local correspondences
afforded by rich visual feature representations from self-supervised models
(e.g., DINO). Recent state-of-the-art approaches use self-supervised features
to represent images as graphs and solve a generalized eigenvalue system (i.e.,
normalized-cut) to generate foreground masks. While effective, this strategy is
limited by its attendant computational demands, leading to slow inference
speeds. In this paper, we propose Prompt and Merge (ProMerge), which leverages
self-supervised visual features to obtain initial groupings of patches and
applies a strategic merging to these segments, aided by a sophisticated
background-based mask pruning technique. ProMerge not only yields competitive
results but also offers a significant reduction in inference time compared to
state-of-the-art normalized-cut-based approaches. Furthermore, when training an
object detector using our mask predictions as pseudo-labels, the resulting
detector surpasses the current leading unsupervised model on various
challenging instance segmentation benchmarks.

摘要：無監督實例分割旨在區分影像中不同的物件實例，而無需依賴人工標記的資料。此領域最近有了顯著的進展，部分原因是自監督模型（例如 DINO）提供的豐富視覺特徵表示所具有的強大局部對應關係。最近的最新方法使用自監督特徵將影像表示為圖形，並解決廣義特徵值系統（即正規化切割）以產生前景遮罩。儘管有效，但此策略受到其伴隨的運算需求限制，導致推論速度變慢。在本文中，我們提出提示與合併 (ProMerge)，它利用自監督視覺特徵來取得區塊的初始群組，並對這些區塊應用策略性合併，並借助一種精密的基於背景的遮罩剪枝技術。ProMerge 不僅產生具有競爭力的結果，而且與基於正規化切割的最新方法相比，推論時間也顯著減少。此外，在使用我們的遮罩預測作為偽標籤訓練物件偵測器時，所產生的偵測器在各種具有挑戰性的實例分割基準上超越了目前的領先無監督模型。

##### **$O(d/T)$ Convergence Theory for Diffusion Probabilistic Models under Minimal Assumptions**
2409.18959v1 by Gen Li, Yuling Yan

Score-based diffusion models, which generate new data by learning to reverse
a diffusion process that perturbs data from the target distribution into noise,
have achieved remarkable success across various generative tasks. Despite their
superior empirical performance, existing theoretical guarantees are often
constrained by stringent assumptions or suboptimal convergence rates. In this
paper, we establish a fast convergence theory for a popular SDE-based sampler
under minimal assumptions. Our analysis shows that, provided
$\ell_{2}$-accurate estimates of the score functions, the total variation
distance between the target and generated distributions is upper bounded by
$O(d/T)$ (ignoring logarithmic factors), where $d$ is the data dimensionality
and $T$ is the number of steps. This result holds for any target distribution
with finite first-order moment. To our knowledge, this improves upon existing
convergence theory for both the SDE-based sampler and another ODE-based
sampler, while imposing minimal assumptions on the target data distribution and
score estimates. This is achieved through a novel set of analytical tools that
provides a fine-grained characterization of how the error propagates at each
step of the reverse process.

摘要：基於分數的擴散模型透過學習逆轉將資料從目標分佈擾動成雜訊的擴散過程來產生新資料，在各種生成任務中已取得顯著的成功。儘管它們有優異的經驗效能，現有的理論保證通常受到嚴格假設或次優收斂率的限制。在本文中，我們在最小的假設下，為一個流行的基於 SDE 的取樣器建立了一個快速收斂理論。我們的分析顯示，只要提供了分數函數的 $\ell_{2}$- 精確估計，目標和生成分佈之間的總變異距離的上界為 $O(d/T)$（忽略對數因子），其中 $d$ 是資料維度，而 $T$ 是步驟數。此結果適用於具有有限一階矩的任何目標分佈。據我們所知，這改進了現有的基於 SDE 的取樣器和另一個基於 ODE 的取樣器的收斂理論，同時對目標資料分佈和分數估計施加最小的假設。這是透過一套新穎的分析工具來實現的，這些工具提供了對反向過程中每個步驟中誤差如何傳播的細緻描述。

##### **LML: Language Model Learning a Dataset for Data-Augmented Prediction**
2409.18957v1 by Praneeth Vadlapati

This paper introduces a new approach to using Large Language Models (LLMs)
for classification tasks, which are typically handled using Machine Learning
(ML) models. Unlike ML models that rely heavily on data cleaning and feature
engineering, this method streamlines the process using LLMs. This paper
proposes a new concept called "Language Model Learning (LML)" powered by a new
method called "Data-Augmented Prediction (DAP)". The classification is
performed by LLMs using a method similar to humans manually exploring and
understanding the data and deciding classifications using data as a reference.
Training data is summarized and evaluated to determine the features that lead
to the classification of each label the most. In the process of DAP, the system
uses the data summary to automatically create a query, which is used to
retrieve relevant rows from the dataset. A classification is generated by the
LLM using data summary and relevant rows, ensuring satisfactory accuracy even
with complex data. Usage of data summary and similar data in DAP ensures
context-aware decision-making. The proposed method uses the words "Act as an
Explainable Machine Learning Model" in the prompt to enhance the
interpretability of the predictions by allowing users to review the logic
behind each prediction. In some test cases, the system scored an accuracy above
90%, proving the effectiveness of the system and its potential to outperform
conventional ML models in various scenarios. The code is available at
https://github.com/Pro-GenAI/LML-DAP

摘要：本文介紹了一種使用大型語言模型 (LLM) 的新方法，用於分類任務，而分類任務通常使用機器學習 (ML) 模型來處理。與高度依賴資料清理和特徵工程的 ML 模型不同，此方法使用 LLM 簡化了流程。本文提出了一個稱為「語言模型學習 (LML)」的新概念，由一種稱為「資料擴充預測 (DAP)」的新方法提供支援。分類是由 LLM 執行，其方法類似於人類手動探索和理解資料，並使用資料作為參考來決定分類。摘要和評估訓練資料，以確定導致每個標籤分類最多的特徵。在 DAP 的過程中，系統使用資料摘要自動建立查詢，用於從資料集中擷取相關列。LLM 使用資料摘要和相關列產生分類，即使資料很複雜，也能確保令人滿意的準確度。在 DAP 中使用資料摘要和類似資料，可確保進行與脈絡相關的決策制定。所提出的方法在提示中使用「扮演一個可解釋機器學習模型」的字句，以透過允許使用者檢閱每個預測背後的邏輯，來增強預測的可解釋性。在某些測試案例中，系統的準確度超過 90%，證明了系統的有效性，以及它在各種情況下優於傳統 ML 模型的潛力。程式碼可在 https://github.com/Pro-GenAI/LML-DAP 取得

##### **Unconditional stability of a recurrent neural circuit implementing divisive normalization**
2409.18946v1 by Shivang Rawat, David J. Heeger, Stefano Martiniani

Stability in recurrent neural models poses a significant challenge,
particularly in developing biologically plausible neurodynamical models that
can be seamlessly trained. Traditional cortical circuit models are notoriously
difficult to train due to expansive nonlinearities in the dynamical system,
leading to an optimization problem with nonlinear stability constraints that
are difficult to impose. Conversely, recurrent neural networks (RNNs) excel in
tasks involving sequential data but lack biological plausibility and
interpretability. In this work, we address these challenges by linking dynamic
divisive normalization (DN) to the stability of ORGaNICs, a biologically
plausible recurrent cortical circuit model that dynamically achieves DN and has
been shown to simulate a wide range of neurophysiological phenomena. By using
the indirect method of Lyapunov, we prove the remarkable property of
unconditional local stability for an arbitrary-dimensional ORGaNICs circuit
when the recurrent weight matrix is the identity. We thus connect ORGaNICs to a
system of coupled damped harmonic oscillators, which enables us to derive the
circuit's energy function, providing a normative principle of what the circuit,
and individual neurons, aim to accomplish. Further, for a generic recurrent
weight matrix, we prove the stability of the 2D model and demonstrate
empirically that stability holds in higher dimensions. Finally, we show that
ORGaNICs can be trained by backpropagation through time without gradient
clipping/scaling, thanks to its intrinsic stability property and adaptive time
constants, which address the problems of exploding, vanishing, and oscillating
gradients. By evaluating the model's performance on RNN benchmarks, we find
that ORGaNICs outperform alternative neurodynamical models on static image
classification tasks and perform comparably to LSTMs on sequential tasks.

摘要：<paragraph>遞迴神經模型的穩定性是一個重大的挑戰，
特別是在開發可無縫訓練的生物學上可行的神經動力學模型時。傳統的皮質迴路模型由於動力系統中廣泛的非線性而難以訓練，
導致優化問題具有難以施加的非線性穩定性約束。相反，遞迴神經網路 (RNN) 在涉及序列數據的任務中表現出色，但缺乏生物學上的可信度和可解釋性。在這項工作中，我們通過將動態除法正規化 (DN) 與 ORGaNICs 的穩定性聯繫起來來應對這些挑戰，ORGaNICs 是一個生物學上可行的遞迴皮質迴路模型，可以動態實現 DN，並且已被證明可以模擬廣泛的神經生理現象。通過使用李亞普諾夫的間接方法，我們證明了任意維度 ORGaNICs 迴路的無條件局部穩定性的顯著特性，當遞迴權重矩陣為恆等矩陣時。因此，我們將 ORGaNICs 連接到一個耦合阻尼諧振子的系統，這使我們能夠推導出電路的能量函數，提供電路和個別神經元旨在實現的規範原理。此外，對於一個通用的遞迴權重矩陣，我們證明了 2D 模型的穩定性，並通過經驗證明了穩定性在更高維度中成立。最後，我們表明 ORGaNICs 可以通過時間反向傳播進行訓練，而無需梯度截斷/縮放，這要歸功於其固有的穩定性特性和自適應時間常數，這些特性解決了梯度爆炸、消失和振盪的問題。通過評估模型在 RNN 基準上的性能，我們發現 ORGaNICs 在靜態圖像分類任務中優於其他神經動力學模型，並且在序列任務中與 LSTM 的性能相當。</paragraph>

##### **Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models**
2409.18943v1 by Jiaming Li, Lei Zhang, Yunshui Li, Ziqiang Liu, yuelin bai, Run Luo, Longze Chen, Min Yang

The instruction-following ability of large language models enables humans to
interact with AI agents in a natural way. However, when required to generate
responses of a specific length, large language models often struggle to meet
users' needs due to their inherent difficulty in accurately perceiving
numerical constraints. To explore the ability of large language models to
control the length of generated responses, we propose the Target Length
Generation Task (TLG) and design two metrics, Precise Match (PM) and Flexible
Match (FM) to evaluate the model's performance in adhering to specified
response lengths. Furthermore, we introduce a novel, model-agnostic approach
called Ruler, which employs Meta Length Tokens (MLTs) to enhance the
instruction-following ability of large language models under length-constrained
instructions. Specifically, Ruler equips LLMs with the ability to generate
responses of a specified length based on length constraints within the
instructions. Moreover, Ruler can automatically generate appropriate MLT when
length constraints are not explicitly provided, demonstrating excellent
versatility and generalization. Comprehensive experiments show the
effectiveness of Ruler across different LLMs on Target Length Generation Task,
e.g., at All Level 27.97 average gain on PM, 29.57 average gain on FM. In
addition, we conduct extensive ablation experiments to further substantiate the
efficacy and generalization of Ruler. Our code and data is available at
https://github.com/Geaming2002/Ruler.

摘要：大型語言模型的指令遵循能力使人類能夠以自然的方式與人工智慧代理互動。然而，當需要產生特定長度的回應時，大型語言模型往往難以滿足使用者的需求，因為它們難以準確感知數值限制。為了探討大型語言模型控制生成回應長度的能力，我們提出了目標長度生成任務 (TLG)，並設計了兩個指標，精確匹配 (PM) 和靈活匹配 (FM)，以評估模型在遵守指定回應長度方面的效能。此外，我們引入了一種新穎的、與模型無關的方法，稱為 Ruler，它採用元長度標記 (MLT) 來增強大型語言模型在長度受限指令下的指令遵循能力。具體來說，Ruler 賦予 LLM 根據指令中的長度約束生成指定長度回應的能力。此外，當未明確提供長度約束時，Ruler 可以自動生成適當的 MLT，展示出出色的通用性和概括性。全面的實驗顯示了 Ruler 在目標長度生成任務中跨不同 LLM 的有效性，例如，在所有級別上 PM 平均增益 27.97，FM 平均增益 29.57。此外，我們進行了廣泛的消融實驗，以進一步證實 Ruler 的效能和概括性。我們的程式碼和資料可在 https://github.com/Geaming2002/Ruler 取得。

##### **From Seconds to Hours: Reviewing MultiModal Large Language Models on Comprehensive Long Video Understanding**
2409.18938v1 by Heqing Zou, Tianze Luo, Guiyang Xie, Victor, Zhang, Fengmao Lv, Guangcong Wang, Juanyang Chen, Zhuochen Wang, Hansheng Zhang, Huaijian Zhang

The integration of Large Language Models (LLMs) with visual encoders has
recently shown promising performance in visual understanding tasks, leveraging
their inherent capability to comprehend and generate human-like text for visual
reasoning. Given the diverse nature of visual data, MultiModal Large Language
Models (MM-LLMs) exhibit variations in model designing and training for
understanding images, short videos, and long videos. Our paper focuses on the
substantial differences and unique challenges posed by long video understanding
compared to static image and short video understanding. Unlike static images,
short videos encompass sequential frames with both spatial and within-event
temporal information, while long videos consist of multiple events with
between-event and long-term temporal information. In this survey, we aim to
trace and summarize the advancements of MM-LLMs from image understanding to
long video understanding. We review the differences among various visual
understanding tasks and highlight the challenges in long video understanding,
including more fine-grained spatiotemporal details, dynamic events, and
long-term dependencies. We then provide a detailed summary of the advancements
in MM-LLMs in terms of model design and training methodologies for
understanding long videos. Finally, we compare the performance of existing
MM-LLMs on video understanding benchmarks of various lengths and discuss
potential future directions for MM-LLMs in long video understanding.

摘要：大型語言模型 (LLM) 與視覺編碼器的整合最近在視覺理解任務中展現出良好的效能，利用其理解和生成類人文本的內在能力進行視覺推理。考量到視覺資料的多元性，多模態大型語言模型 (MM-LLM) 在模型設計和訓練上展現出差異，以理解影像、短影片和長影片。我們的論文重點關注與靜態影像和短影片理解相比，長影片理解所帶來的顯著差異和獨特挑戰。與靜態影像不同，短影片包含具有空間和事件內時間資訊的連續畫面，而長影片則包含具有事件間和長期時間資訊的多個事件。在本次調查中，我們旨在追蹤和總結 MM-LLM 從影像理解到長影片理解的進展。我們檢視各種視覺理解任務之間的差異，並強調長影片理解中的挑戰，包括更細緻的時空細節、動態事件和長期依賴性。然後，我們針對模型設計和訓練方法詳細總結 MM-LLM 在理解長影片方面的進展。最後，我們比較現有 MM-LLM 在不同長度的影片理解基準上的效能，並討論 MM-LLM 在長影片理解中的潛在未來方向。

##### **AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**
2409.18924v1 by Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Themistocles L. Assimes, Xin Ma, Danielle S. Bitterman, Lin Lu, Lizhou Fan

Simulated patient systems play a crucial role in modern medical education and
research, providing safe, integrative learning environments and enabling
clinical decision-making simulations. Large Language Models (LLM) could advance
simulated patient systems by replicating medical conditions and patient-doctor
interactions with high fidelity and low cost. However, ensuring the
effectiveness and trustworthiness of these systems remains a challenge, as they
require a large, diverse, and precise patient knowledgebase, along with a
robust and stable knowledge diffusion to users. Here, we developed AIPatient,
an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient
KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning
RAG) agentic workflow as the generation backbone. AIPatient KG samples data
from Electronic Health Records (EHRs) in the Medical Information Mart for
Intensive Care (MIMIC)-III database, producing a clinically diverse and
relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).
Reasoning RAG leverages six LLM powered agents spanning tasks including
retrieval, KG query generation, abstraction, checker, rewrite, and
summarization. This agentic framework reaches an overall accuracy of 94.15% in
EHR-based medical Question Answering (QA), outperforming benchmarks that use
either no agent or only partial agent integration. Our system also presents
high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade
5.6), robustness (ANOVA F-value 0.6126, p<0.1), and stability (ANOVA F-value
0.782, p<0.1). The promising performance of the AIPatient system highlights its
potential to support a wide range of applications, including medical education,
model evaluation, and system integration.

摘要：<paragraph>模擬病人系統在現代醫學教育和研究中扮演著至關重要的角色，提供安全、整合的學習環境，並支援臨床決策模擬。大型語言模型 (LLM) 能夠複製醫療狀況和醫病互動，進而以高保真度和低成本提升模擬病人系統。然而，確保這些系統的有效性和可信度仍然是一項挑戰，因為它們需要一個龐大、多元且精確的病人知識庫，以及一種強健且穩定的知識傳播方式。在此，我們開發了 AIPatient，一個進階的模擬病人系統，其以 AIPatient 知識圖譜 (AIPatient KG) 作為輸入，並以推理檢索增強生成 (Reasoning RAG) 代理工作流程作為生成主幹。AIPatient KG 從密集照護醫學資訊市集 (MIMIC)-III 資料庫中的電子健康紀錄 (EHR) 中抽取資料，產生一個臨床多元且相關的 1,495 位病患群組，且具有高度的知識庫有效性 (F1 0.89)。Reasoning RAG 運用六個 LLM 驅動的代理，涵蓋檢索、KG 查詢生成、抽象化、檢查器、重寫和摘要等任務。此代理架構在基於 EHR 的醫療問答 (QA) 中達到 94.15% 的整體準確度，優於未使用代理或僅部分整合代理的基準。我們的系統還具備高度可讀性 (中位數 Flesch 閱讀簡易度 77.23；中位數 Flesch Kincaid 等級 5.6)、強健性 (ANOVA F 值 0.6126，p<0.1) 和穩定性 (ANOVA F 值 0.782，p<0.1)。AIPatient 系統令人滿意的效能突顯了其支援廣泛應用程式的潛力，包括醫學教育、模型評估和系統整合。</paragraph>

##### **Soft Measures for Extracting Causal Collective Intelligence**
2409.18911v1 by Maryam Berijanian, Spencer Dork, Kuldeep Singh, Michael Riley Millikan, Ashlin Riggs, Aadarsh Swaminathan, Sarah L. Gibbs, Scott E. Friedman, Nathan Brugnone

Understanding and modeling collective intelligence is essential for
addressing complex social systems. Directed graphs called fuzzy cognitive maps
(FCMs) offer a powerful tool for encoding causal mental models, but extracting
high-integrity FCMs from text is challenging. This study presents an approach
using large language models (LLMs) to automate FCM extraction. We introduce
novel graph-based similarity measures and evaluate them by correlating their
outputs with human judgments through the Elo rating system. Results show
positive correlations with human evaluations, but even the best-performing
measure exhibits limitations in capturing FCM nuances. Fine-tuning LLMs
improves performance, but existing measures still fall short. This study
highlights the need for soft similarity measures tailored to FCM extraction,
advancing collective intelligence modeling with NLP.

摘要：了解和建模集体智慧对于解决复杂的社会系统至关重要。称为模糊认知图（FCM）的有向图提供了一种强大的工具来编码因果心智模型，但从文本中提取高完整性的 FCM 具有挑战性。本研究提出了一种使用大型语言模型（LLM）来自动化 FCM 提取的方法。我们引入了新颖的基于图的相似性度量，并通过通过 Elo 评级系统将其输出与人类判断相关联来评估它们。结果表明与人类评估呈正相关，但即使是表现最好的度量在捕捉 FCM 细微差别方面也表现出局限性。微调 LLM 可以提高性能，但现有措施仍然不足。本研究强调了针对 FCM 提取量身定制的软相似性度量的必要性，通过 NLP 推进了集体智能建模。

##### **Improving Visual Object Tracking through Visual Prompting**
2409.18901v1 by Shih-Fang Chen, Jun-Cheng Chen, I-Hong Jhuo, Yen-Yu Lin

Learning a discriminative model to distinguish a target from its surrounding
distractors is essential to generic visual object tracking. Dynamic target
representation adaptation against distractors is challenging due to the limited
discriminative capabilities of prevailing trackers. We present a new visual
Prompting mechanism for generic Visual Object Tracking (PiVOT) to address this
issue. PiVOT proposes a prompt generation network with the pre-trained
foundation model CLIP to automatically generate and refine visual prompts,
enabling the transfer of foundation model knowledge for tracking. While CLIP
offers broad category-level knowledge, the tracker, trained on
instance-specific data, excels at recognizing unique object instances. Thus,
PiVOT first compiles a visual prompt highlighting potential target locations.
To transfer the knowledge of CLIP to the tracker, PiVOT leverages CLIP to
refine the visual prompt based on the similarities between candidate objects
and the reference templates across potential targets. Once the visual prompt is
refined, it can better highlight potential target locations, thereby reducing
irrelevant prompt information. With the proposed prompting mechanism, the
tracker can generate improved instance-aware feature maps through the guidance
of the visual prompt, thus effectively reducing distractors. The proposed
method does not involve CLIP during training, thereby keeping the same training
complexity and preserving the generalization capability of the pretrained
foundation model. Extensive experiments across multiple benchmarks indicate
that PiVOT, using the proposed prompting method can suppress distracting
objects and enhance the tracker.

摘要：學習一個區別目標與其周圍干擾物的判別模型對於一般的視覺目標追蹤至關重要。由於現有追蹤器的判別能力有限，因此針對干擾物的動態目標表示適應具有挑戰性。我們提出了一種新的視覺提示機制，用於一般的視覺目標追蹤 (PiVOT)，以解決這個問題。PiVOT 提出了一個提示生成網路，並使用預先訓練好的基礎模型 CLIP 來自動生成和優化視覺提示，從而能夠將基礎模型知識轉移到追蹤中。雖然 CLIP 提供了廣泛的類別層級知識，但追蹤器經過特定於實例的資料訓練，擅長識別唯一的物件實例。因此，PiVOT 首先編譯一個視覺提示，重點標示潛在目標位置。為了將 CLIP 的知識轉移到追蹤器，PiVOT 利用 CLIP 根據候選物件與潛在目標之間參考範本的相似性來優化視覺提示。一旦視覺提示經過優化，它就能夠更好地標示潛在目標位置，從而減少不相關的提示資訊。有了建議的提示機制，追蹤器可以透過視覺提示的引導來生成改進的實例感知特徵圖，從而有效地減少干擾物。所提出的方法在訓練期間不涉及 CLIP，從而保持相同的訓練複雜度並保留預訓練基礎模型的泛化能力。跨多個基準的大量實驗表明，使用建議提示方法的 PiVOT 可以抑制干擾物件並增強追蹤器。

##### **Multi-Source Hard and Soft Information Fusion Approach for Accurate Cryptocurrency Price Movement Prediction**
2409.18895v1 by Saeed Mohammadi Dashtaki, Mehdi Hosseini Chagahi, Behzad Moshiri, Md. Jalil Piran

One of the most important challenges in the financial and cryptocurrency
field is accurately predicting cryptocurrency price trends. Leveraging
artificial intelligence (AI) is beneficial in addressing this challenge.
Cryptocurrency markets, marked by substantial growth and volatility, attract
investors and scholars keen on deciphering and forecasting cryptocurrency price
movements. The vast and diverse array of data available for such predictions
increases the complexity of the task. In our study, we introduce a novel
approach termed hard and soft information fusion (HSIF) to enhance the accuracy
of cryptocurrency price movement forecasts. The hard information component of
our approach encompasses historical price records alongside technical
indicators. Complementing this, the soft data component extracts from X
(formerly Twitter), encompassing news headlines and tweets about the
cryptocurrency. To use this data, we use the Bidirectional Encoder
Representations from Transformers (BERT)-based sentiment analysis method,
financial BERT (FinBERT), which performs best. Finally, our model feeds on the
information set including processed hard and soft data. We employ the
bidirectional long short-term memory (BiLSTM) model because processing
information in both forward and backward directions can capture long-term
dependencies in sequential information. Our empirical findings emphasize the
superiority of the HSIF approach over models dependent on single-source data by
testing on Bitcoin-related data. By fusing hard and soft information on Bitcoin
dataset, our model has about 96.8\% accuracy in predicting price movement.
Incorporating information enables our model to grasp the influence of social
sentiment on price fluctuations, thereby supplementing the technical
analysis-based predictions derived from hard information.

摘要：<paragraph>金融和加密货币領域最重要的挑戰之一是準確預測加密貨幣價格趨勢。利用人工智慧 (AI) 有助於應對這一挑戰。加密貨幣市場以大幅成長和波動為特徵，吸引了熱衷於解讀和預測加密貨幣價格走勢的投資者和學者。可用於此類預測的龐大且多樣化的數據陣列增加了任務的複雜性。在我們的研究中，我們介紹了一種稱為硬軟信息融合 (HSIF) 的新方法，以提高加密貨幣價格變動預測的準確性。我們的方法的硬信息組成部分包括歷史價格記錄和技術指標。作為補充，軟數據組成部分從 X（以前的 Twitter）中提取，包括新聞標題和有關加密貨幣的推文。為了使用這些數據，我們使用基於雙向編碼器轉換器 (BERT) 的情緒分析方法，即財務 BERT (FinBERT)，它表現最佳。最後，我們的模型以包含處理過的硬數據和軟數據的信息集為基礎。我們採用雙向長期短期記憶 (BiLSTM) 模型，因為在正向和反向處理信息可以捕捉序列信息中的長期依賴性。我們的實證結果強調了 HSIF 方法優於依賴單一來源數據的模型，方法是在與比特幣相關的數據上進行測試。通過融合比特幣數據集中的硬信息和軟信息，我們的模型在預測價格變動方面具有大約 96.8% 的準確性。納入信息使我們的模型能夠掌握社交情緒對價格波動的影響，從而補充從硬信息中得出的基於技術分析的預測。</paragraph>

##### **IDGen: Item Discrimination Induced Prompt Generation for LLM Evaluation**
2409.18892v1 by Fan Lin, Shuyi Xie, Yong Dai, Wenlin Yao, Tianjiao Lang, Zishan Xu, Zhichao Hu, Xiao Xiao, Yuhong Liu, Yu Zhang

As Large Language Models (LLMs) grow increasingly adept at managing complex
tasks, the evaluation set must keep pace with these advancements to ensure it
remains sufficiently discriminative. Item Discrimination (ID) theory, which is
widely used in educational assessment, measures the ability of individual test
items to differentiate between high and low performers. Inspired by this
theory, we propose an ID-induced prompt synthesis framework for evaluating LLMs
to ensure the evaluation set can continually update and refine according to
model abilities. Our data synthesis framework prioritizes both breadth and
specificity. It can generate prompts that comprehensively evaluate the
capabilities of LLMs while revealing meaningful performance differences between
models, allowing for effective discrimination of their relative strengths and
weaknesses across various tasks and domains. To produce high-quality data, we
incorporate a self-correct mechanism into our generalization framework, and
develop two models to predict prompt discrimination and difficulty score to
facilitate our data synthesis framework, contributing valuable tools to
evaluation data synthesis research. We apply our generated data to evaluate
five SOTA models. Our data achieves an average score of 51.92, accompanied by a
variance of 10.06. By contrast, previous works (i.e., SELF-INSTRUCT and
WizardLM) obtain an average score exceeding 67, with a variance below 3.2. The
results demonstrate that the data generated by our framework is more
challenging and discriminative compared to previous works. We will release a
dataset of over 3,000 carefully crafted prompts to facilitate evaluation
research of LLMs.

摘要：<paragraph>隨著大型語言模型（LLM）在處理複雜任務方面日益得心應手，評估集必須與這些進展保持同步，以確保它仍然具有足夠的區分度。廣泛用於教育評估的項目區分（ID）理論，衡量個別測驗項目區分高低表現者的能力。受此理論啟發，我們提出一個 ID 誘導提示合成架構，用於評估 LLM，以確保評估集可以根據模型能力持續更新和優化。我們的數據合成架構優先考慮廣度和具體性。它可以生成全面評估 LLM 能力的提示，同時揭示模型之間有意義的效能差異，允許有效區分它們在各種任務和領域中的相對優缺點。為了產生高品質的數據，我們在我們的概化框架中納入一個自我修正機制，並開發兩個模型來預測提示區分和難度分數，以促進我們的數據合成架構，為評估數據合成研究做出寶貴的貢獻。我們將我們產生的數據應用於評估五個 SOTA 模型。我們的數據達到 51.92 的平均分，並伴隨著 10.06 的變異數。相比之下，先前的研究（即 SELF-INSTRUCT 和 WizardLM）獲得的平均分超過 67，變異數低於 3.2。結果表明，與先前的研究相比，我們的框架產生的數據更具挑戰性和區分度。我們將發布一個包含 3,000 多個精心製作的提示的數據集，以促進 LLM 的評估研究。</paragraph>

##### **Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models**
2409.18878v1 by Zehan Li, Yan Hu, Scott Lane, Salih Selek, Lokesh Shahani, Rodrigo Machado-Vieira, Jair Soares, Hua Xu, Hongfang Liu, Ming Huang

Accurate identification and categorization of suicidal events can yield
better suicide precautions, reducing operational burden, and improving care
quality in high-acuity psychiatric settings. Pre-trained language models offer
promise for identifying suicidality from unstructured clinical narratives. We
evaluated the performance of four BERT-based models using two fine-tuning
strategies (multiple single-label and single multi-label) for detecting
coexisting suicidal events from 500 annotated psychiatric evaluation notes. The
notes were labeled for suicidal ideation (SI), suicide attempts (SA), exposure
to suicide (ES), and non-suicidal self-injury (NSSI). RoBERTa outperformed
other models using binary relevance (acc=0.86, F1=0.78). MentalBERT (F1=0.74)
also exceeded BioClinicalBERT (F1=0.72). RoBERTa fine-tuned with a single
multi-label classifier further improved performance (acc=0.88, F1=0.81),
highlighting that models pre-trained on domain-relevant data and the single
multi-label classification strategy enhance efficiency and performance.
  Keywords: EHR-based Phynotyping; Natural Language Processing; Secondary Use
of EHR Data; Suicide Classification; BERT-based Model; Psychiatry; Mental
Health

摘要：準確識別和分類自殺事件可以產生更好的自殺預防措施，減少運作負擔，並提高高敏銳度精神科環境中的照護品質。預先訓練的語言模型提供從非結構化臨床敘述中辨識自殺傾向的承諾。我們評估了四個基於 BERT 的模型的效能，使用兩種微調策略（多個單標籤和單個多標籤）來從 500 個註解的精神科評估備忘錄中偵測共存的自殺事件。這些備忘錄標記為自殺意念 (SI)、自殺企圖 (SA)、暴露於自殺 (ES) 和非自殺性自傷 (NSSI)。RoBERTa 使用二元關聯性表現優於其他模型（acc=0.86，F1=0.78）。MentalBERT (F1=0.74) 也超過 BioClinicalBERT (F1=0.72)。使用單一多標籤分類器微調的 RoBERTa 進一步改善了效能（acc=0.88，F1=0.81），強調預先在與領域相關的資料上訓練的模型和單一多標籤分類策略可提升效率和效能。關鍵字：基於電子病歷的表型分析；自然語言處理；電子病歷資料的二次使用；自殺分類；基於 BERT 的模型；精神病學；心理健康

##### **UniEmoX: Cross-modal Semantic-Guided Large-Scale Pretraining for Universal Scene Emotion Perception**
2409.18877v1 by Chuang Chen, Xiao Sun, Zhi Liu

Visual emotion analysis holds significant research value in both computer
vision and psychology. However, existing methods for visual emotion analysis
suffer from limited generalizability due to the ambiguity of emotion perception
and the diversity of data scenarios. To tackle this issue, we introduce
UniEmoX, a cross-modal semantic-guided large-scale pretraining framework.
Inspired by psychological research emphasizing the inseparability of the
emotional exploration process from the interaction between individuals and
their environment, UniEmoX integrates scene-centric and person-centric
low-level image spatial structural information, aiming to derive more nuanced
and discriminative emotional representations. By exploiting the similarity
between paired and unpaired image-text samples, UniEmoX distills rich semantic
knowledge from the CLIP model to enhance emotional embedding representations
more effectively. To the best of our knowledge, this is the first large-scale
pretraining framework that integrates psychological theories with contemporary
contrastive learning and masked image modeling techniques for emotion analysis
across diverse scenarios. Additionally, we develop a visual emotional dataset
titled Emo8. Emo8 samples cover a range of domains, including cartoon, natural,
realistic, science fiction and advertising cover styles, covering nearly all
common emotional scenes. Comprehensive experiments conducted on six benchmark
datasets across two downstream tasks validate the effectiveness of UniEmoX. The
source code is available at https://github.com/chincharles/u-emo.

摘要：視覺情緒分析在電腦視覺和心理學中具有重要的研究價值。然而，現有的視覺情緒分析方法由於情緒感知的模糊性和資料場景的多樣性，而難以進行廣泛的概括。為了解決這個問題，我們引入了 UniEmoX，一個跨模態語義引導的大規模預訓練框架。受到心理學研究強調情緒探索過程與個人與其環境互動之間不可分離性的啟發，UniEmoX 整合了場景為中心和以人為中心的低階影像空間結構資訊，旨在推導出更細緻且具有區辨力的情緒表徵。透過利用配對和未配對影像文字範例之間的相似性，UniEmoX 從 CLIP 模型中萃取出豐富的語義知識，以更有效地增強情緒嵌入表徵。據我們所知，這是第一個將心理學理論與當代對比學習和遮罩影像建模技術整合起來的大規模預訓練框架，用於跨不同場景進行情緒分析。此外，我們開發了一個名為 Emo8 的視覺情緒資料集。Emo8 範例涵蓋了各種領域，包括卡通、自然、寫實、科幻和廣告封面風格，涵蓋了幾乎所有常見的情緒場景。在六個基準資料集上進行的綜合實驗，跨兩個下游任務驗證了 UniEmoX 的有效性。原始程式碼可在 https://github.com/chincharles/u-emo 取得。

##### **CESNET-TimeSeries24: Time Series Dataset for Network Traffic Anomaly Detection and Forecasting**
2409.18874v1 by Josef Koumar, Karel Hynek, Tomáš Čejka, Pavel Šiška

Anomaly detection in network traffic is crucial for maintaining the security
of computer networks and identifying malicious activities. One of the primary
approaches to anomaly detection are methods based on forecasting. Nevertheless,
extensive real-world network datasets for forecasting and anomaly detection
techniques are missing, potentially causing performance overestimation of
anomaly detection algorithms. This manuscript addresses this gap by introducing
a dataset comprising time series data of network entities' behavior, collected
from the CESNET3 network. The dataset was created from 40 weeks of network
traffic of 275 thousand active IP addresses. The ISP origin of the presented
data ensures a high level of variability among network entities, which forms a
unique and authentic challenge for forecasting and anomaly detection models. It
provides valuable insights into the practical deployment of forecast-based
anomaly detection approaches.

摘要：網路流量異常偵測對於維護電腦網路安全和辨識惡意活動至關重要。其中一種異常偵測的主要方法是基於預測的方法。儘管如此，用於預測和異常偵測技術的廣泛真實世界網路資料集卻付之闕如，這可能會導致異常偵測演算法效能過度估計。此手稿透過引入一個資料集來解決這個問題，該資料集包含從 CESNET3 網路收集的網路實體行為時間序列資料。此資料集是根據 275,000 個活躍 IP 位址的 40 週網路流量建立的。所提供資料的 ISP 來源確保了網路實體之間的高度可變性，這對預測和異常偵測模型來說是一個獨特且真實的挑戰。它提供了對基於預測的異常偵測方法實際部署的寶貴見解。

##### **Individuation in Neural Models with and without Visual Grounding**
2409.18868v1 by Alexey Tikhonov, Lisa Bylinina, Ivan P. Yamshchikov

We show differences between a language-and-vision model CLIP and two
text-only models - FastText and SBERT - when it comes to the encoding of
individuation information. We study latent representations that CLIP provides
for substrates, granular aggregates, and various numbers of objects. We
demonstrate that CLIP embeddings capture quantitative differences in
individuation better than models trained on text-only data. Moreover, the
individuation hierarchy we deduce from the CLIP embeddings agrees with the
hierarchies proposed in linguistics and cognitive science.

摘要：我們展示了在編碼個別化資訊時，語言和視覺模型 CLIP 與兩個純文字模型 - FastText 和 SBERT - 之間的差異。我們研究 CLIP 提供給基質、顆粒聚集體和各種物件數量的潛在表徵。我們證明 CLIP 內嵌比僅針對純文字資料訓練的模型更能捕捉個別化的量化差異。此外，我們從 CLIP 內嵌推論出的個別化階層與語言學和認知科學中提出的階層一致。

##### **Positional Encoder Graph Quantile Neural Networks for Geographic Data**
2409.18865v1 by William E. R. de Amorim, Scott A. Sisson, T. Rodrigues, David J. Nott, Guilherme S. Rodrigues

Positional Encoder Graph Neural Networks (PE-GNNs) are a leading approach for
modeling continuous spatial data. However, they often fail to produce
calibrated predictive distributions, limiting their effectiveness for
uncertainty quantification. We introduce the Positional Encoder Graph Quantile
Neural Network (PE-GQNN), a novel method that integrates PE-GNNs, Quantile
Neural Networks, and recalibration techniques in a fully nonparametric
framework, requiring minimal assumptions about the predictive distributions. We
propose a new network architecture that, when combined with a quantile-based
loss function, yields accurate and reliable probabilistic models without
increasing computational complexity. Our approach provides a flexible, robust
framework for conditional density estimation, applicable beyond spatial data
contexts. We further introduce a structured method for incorporating a KNN
predictor into the model while avoiding data leakage through the GNN layer
operation. Experiments on benchmark datasets demonstrate that PE-GQNN
significantly outperforms existing state-of-the-art methods in both predictive
accuracy and uncertainty quantification.

摘要：位置編碼器圖神經網路 (PE-GNN) 是用於建模連續空間資料的一種領先方法。然而，它們經常無法產生校準的預測分佈，這限制了它們在不確定性量化方面的效用。我們介紹了位置編碼器圖分位數神經網路 (PE-GQNN)，這是一種創新的方法，它將 PE-GNN、分位數神經網路和重新校準技術整合到一個完全非參數架構中，對預測分佈的要求極少。我們提出了一種新的網路架構，當與基於分位數的損失函數結合時，可以在不增加計算複雜性的情況下產生準確且可靠的機率模型。我們的做法提供了一個靈活、穩健的條件密度估計架構，適用於空間資料脈絡之外。我們進一步介紹了一種結構化方法，用於將 KNN 預測器納入模型，同時避免資料外洩透過 GNN 層操作。基準資料集上的實驗證明，PE-GQNN 在預測準確性和不確定性量化方面都明顯優於現有的最先進方法。

##### **Mitigating Selection Bias with Node Pruning and Auxiliary Options**
2409.18857v1 by Hyeong Kyu Choi, Weijie Xu, Chi Xue, Stephanie Eckman, Chandan K. Reddy

Large language models (LLMs) often show unwarranted preference for certain
choice options when responding to multiple-choice questions, posing significant
reliability concerns in LLM-automated systems. To mitigate this selection bias
problem, previous solutions utilized debiasing methods to adjust the model's
input and/or output. Our work, in contrast, investigates the model's internal
representation of the selection bias. Specifically, we introduce a novel
debiasing approach, Bias Node Pruning (BNP), which eliminates the linear layer
parameters that contribute to the bias. Furthermore, we present Auxiliary
Option Injection (AOI), a simple yet effective input modification technique for
debiasing, which is compatible even with black-box LLMs. To provide a more
systematic evaluation of selection bias, we review existing metrics and
introduce Choice Kullback-Leibler Divergence (CKLD), which addresses the
insensitivity of the commonly used metrics to label imbalance. Experiments show
that our methods are robust and adaptable across various datasets when applied
to three LLMs.

摘要：大型語言模型 (LLM) 在回答多選題時，通常會對某些選項展現出不合理的偏好，對 LLM 自動化系統的可靠性造成重大的疑慮。為了減輕這種選擇偏差問題，先前的解決方案利用去偏方法調整模型的輸入和/或輸出。我們的研究則相反，探討模型對選擇偏差的內部表徵。具體來說，我們引入一種新穎的去偏方法，稱為偏差節點剪枝 (BNP)，它會消除導致偏差的線性層參數。此外，我們提出輔助選項注入 (AOI)，這是一種簡單卻有效的去偏輸入修改技術，即使是黑盒 LLM 也相容。為了提供更系統性的選擇偏差評估，我們檢視現有的指標並引入選擇 Kullback-Leibler 距離 (CKLD)，它解決了常用指標對標籤不平衡的遲鈍性。實驗顯示，當應用於三個 LLM 時，我們的模型強健且適用於各種資料集。

##### **MECG-E: Mamba-based ECG Enhancer for Baseline Wander Removal**
2409.18828v1 by Kuo-Hsuan Hung, Kuan-Chen Wang, Kai-Chun Liu, Wei-Lun Chen, Xugang Lu, Yu Tsao, Chii-Wann Lin

Electrocardiogram (ECG) is an important non-invasive method for diagnosing
cardiovascular disease. However, ECG signals are susceptible to noise
contamination, such as electrical interference or signal wandering, which
reduces diagnostic accuracy. Various ECG denoising methods have been proposed,
but most existing methods yield suboptimal performance under very noisy
conditions or require several steps during inference, leading to latency during
online processing. In this paper, we propose a novel ECG denoising model,
namely Mamba-based ECG Enhancer (MECG-E), which leverages the Mamba
architecture known for its fast inference and outstanding nonlinear mapping
capabilities. Experimental results indicate that MECG-E surpasses several
well-known existing models across multiple metrics under different noise
conditions. Additionally, MECG-E requires less inference time than
state-of-the-art diffusion-based ECG denoisers, demonstrating the model's
functionality and efficiency.

摘要：心電圖 (ECG) 是診斷心血管疾病的重要非侵入性方法。然而，ECG 訊號容易受到雜訊污染，例如電氣干擾或訊號漂移，這會降低診斷準確性。已經提出了各種 ECG 去雜訊方法，但大多數現有方法在非常嘈雜的條件下會產生次佳效能，或在推論期間需要幾個步驟，導致在線上處理期間產生延遲。在本文中，我們提出了一個新的 ECG 去雜訊模型，即基於 Mamba 的 ECG 增強器 (MECG-E)，它利用了 Mamba 架構，該架構以其快速的推論和出色的非線性對應功能而聞名。實驗結果表明，MECG-E 在不同的雜訊條件下，在多項指標上都超越了幾個著名的現有模型。此外，與最先進的基於擴散的 ECG 去雜訊器相比，MECG-E 所需的推論時間更少，這證明了該模型的功能性和效率。

##### **Local Transcription Models in Home Care Nursing in Switzerland: an Interdisciplinary Case Study**
2409.18819v1 by Jeremy Kramer, Tetiana Kravchenko, Beatrice Kaufmann, Friederike J. S. Thilo, Mascha Kurpicz-Briki

Latest advances in the field of natural language processing (NLP) enable new
use cases for different domains, including the medical sector. In particular,
transcription can be used to support automation in the nursing documentation
process and give nurses more time to interact with the patients. However,
different challenges including (a) data privacy, (b) local languages and
dialects, and (c) domain-specific vocabulary need to be addressed. In this case
study, we investigate the case of home care nursing documentation in
Switzerland. We assessed different transcription tools and models, and
conducted several experiments with OpenAI Whisper, involving different
variations of German (i.e., dialects, foreign accent) and manually curated
example texts by a domain expert of home care nursing. Our results indicate
that even the used out-of-the-box model performs sufficiently well to be a good
starting point for future research in the field.

摘要：自然語言處理 (NLP) 領域的最新進展為包括醫療領域在內的不同領域提供了新的用例。特別是，轉錄可用於支援護理文件處理中的自動化，並讓護理人員有更多時間與患者互動。然而，需要解決包括 (a) 資料隱私、(b) 地方語言和方言，以及 (c) 領域特定詞彙在內的不同挑戰。在本案例研究中，我們調查了瑞士居家護理文件處理的案例。我們評估了不同的轉錄工具和模型，並使用 OpenAI Whisper 進行了多項實驗，涉及德語的不同變體（即方言、外語口音）和居家護理領域專家手動整理的範例文字。我們的結果表明，即使使用現成的模型也能表現得足夠好，足以作為該領域未來研究的良好起點。

##### **Early diagnosis of Alzheimer's disease from MRI images with deep learning model**
2409.18814v1 by Sajjad Aghasi Javid, Mahmood Mohassel Feghhi

It is acknowledged that the most common cause of dementia worldwide is
Alzheimer's disease (AD). This condition progresses in severity from mild to
severe and interferes with people's everyday routines. Early diagnosis plays a
critical role in patient care and clinical trials. Convolutional neural
networks (CNN) are used to create a framework for identifying specific disease
features from MRI scans Classification of dementia involves approaches such as
medical history review, neuropsychological tests, and magnetic resonance
imaging (MRI). However, the image dataset obtained from Kaggle faces a
significant issue of class imbalance, which requires equal distribution of
samples from each class to address. In this article, to address this imbalance,
the Synthetic Minority Oversampling Technique (SMOTE) is utilized. Furthermore,
a pre-trained convolutional neural network has been applied to the DEMNET
dementia network to extract key features from AD images. The proposed model
achieved an impressive accuracy of 98.67%.

摘要：全球公認最常見的失智症成因是
阿茲海默症（AD）。這種疾病的嚴重程度從輕度到重度，並會干擾人們的日常作息。早期診斷在患者照護和臨床試驗中扮演至關重要的角色。卷積神經網路（CNN）用於建立一個架構，以從 MRI 掃描中辨識特定的疾病特徵。失智症的分類涉及病歷回顧、神經心理測驗和磁振造影（MRI）等方法。然而，從 Kaggle 取得的影像資料集面臨類別不平衡的重大問題，這需要每個類別的樣本數量相等才能解決。在本文中，為了解決這種不平衡，使用了合成少數過採樣技術（SMOTE）。此外，已將預先訓練好的卷積神經網路應用於 DEMNET 失智症網路，以從 AD 影像中萃取關鍵特徵。所提出的模型達到了令人印象深刻的 98.67% 準確率。

##### **LLMs4Synthesis: Leveraging Large Language Models for Scientific Synthesis**
2409.18812v1 by Hamed Babaei Giglou, Jennifer D'Souza, Sören Auer

In response to the growing complexity and volume of scientific literature,
this paper introduces the LLMs4Synthesis framework, designed to enhance the
capabilities of Large Language Models (LLMs) in generating high-quality
scientific syntheses. This framework addresses the need for rapid, coherent,
and contextually rich integration of scientific insights, leveraging both
open-source and proprietary LLMs. It also examines the effectiveness of LLMs in
evaluating the integrity and reliability of these syntheses, alleviating
inadequacies in current quantitative metrics. Our study contributes to this
field by developing a novel methodology for processing scientific papers,
defining new synthesis types, and establishing nine detailed quality criteria
for evaluating syntheses. The integration of LLMs with reinforcement learning
and AI feedback is proposed to optimize synthesis quality, ensuring alignment
with established criteria. The LLMs4Synthesis framework and its components are
made available, promising to enhance both the generation and evaluation
processes in scientific research synthesis.

摘要：為了應對科學文獻的複雜性和數量持續增加，本文介紹了 LLMs4Synthesis 框架，旨在增強大型語言模型 (LLM) 在產生高品質科學綜合方面的能力。此框架滿足了快速、連貫且脈絡豐富整合科學見解的需求，同時利用開源和專有 LLM。它還探討了 LLM 在評估這些綜合的完整性和可靠性方面的有效性，緩解了當前定量指標中的不足。我們的研究透過開發一種處理科學論文的新方法、定義新的綜合類型，以及建立九項詳細的品質準則來評估綜合，為此領域做出貢獻。建議將 LLM 與強化學習和 AI 回饋整合，以最佳化綜合品質，確保與既定準則保持一致。LLMs4Synthesis 框架及其組件已公開，有望增強科學研究綜合中的產生和評估流程。

##### **Esports Debut as a Medal Event at 2023 Asian Games: Exploring Public Perceptions with BERTopic and GPT-4 Topic Fine-Tuning**
2409.18798v1 by Tyreal Yizhou Qian, Bo Yu, Weizhe Li, Chenglong Xu

This study examined the public opinions of esports at the 2023 Asian Games
and value co-creation during the event using an LLM-enhanced BERTopic modeling
analysis. We identified five major themes representing public perceptions, as
well as how major stakeholders co-created value within and beyond the esports
ecosystem. Key findings highlighted the strategic use of social media marketing
to influence public opinion and promote esports events and brands, emphasizing
the importance of event logistics and infrastructure. Additionally, the study
revealed the co-creation value contributed by stakeholders outside the
traditional esports ecosystem, particularly in promoting national
representation and performance. Our findings supported the ongoing efforts to
legitimize esports as a sport, noting that mainstream recognition remains a
challenge. The inclusion of esports as a medal event showcased broader
acceptance and helped mitigate negative public perceptions. Moreover,
contributions from non-traditional stakeholders underscored the value of
cross-subcultural collaborations in esports.

摘要：本研究檢視了 2023 年亞洲運動會電競的公眾意見，並使用 LLM 增強的 BERTopic 建模分析探討活動期間的價值共創。我們找出五個主要主題，代表公眾觀感，以及主要利害關係人如何在電競生態系統內外共創價值。主要發現強調了策略性使用社群媒體行銷來影響公眾意見並推廣電競活動和品牌，強調活動後勤和基礎設施的重要性。此外，研究揭露了傳統電競生態系統外利害關係人貢獻的共創價值，特別是在推廣國家代表性和表現方面。我們的發現支持了將電競合法化為一項運動的持續努力，並指出主流認可仍然是一項挑戰。將電競納入為獎牌賽事展示了更廣泛的接受度，並有助於減輕負面的公眾觀感。此外，非傳統利害關係人的貢獻強調了電競中跨次文化的合作價值。

##### **A Survey on the Honesty of Large Language Models**
2409.18786v1 by Siheng Li, Cheng Yang, Taiqiang Wu, Chufan Shi, Yuji Zhang, Xinyu Zhu, Zesen Cheng, Deng Cai, Mo Yu, Lemao Liu, Jie Zhou, Yujiu Yang, Ngai Wong, Xixin Wu, Wai Lam

Honesty is a fundamental principle for aligning large language models (LLMs)
with human values, requiring these models to recognize what they know and don't
know and be able to faithfully express their knowledge. Despite promising,
current LLMs still exhibit significant dishonest behaviors, such as confidently
presenting wrong answers or failing to express what they know. In addition,
research on the honesty of LLMs also faces challenges, including varying
definitions of honesty, difficulties in distinguishing between known and
unknown knowledge, and a lack of comprehensive understanding of related
research. To address these issues, we provide a survey on the honesty of LLMs,
covering its clarification, evaluation approaches, and strategies for
improvement. Moreover, we offer insights for future research, aiming to inspire
further exploration in this important area.

摘要：誠實是大語言模型 (LLM) 與人類價值觀保持一致的基本原則，要求這些模型認識到它們所知和不知的事物，並能夠忠實地表達其知識。儘管有前景，但目前的 LLM 仍然表現出顯著的不誠實行為，例如自信地提供錯誤答案或無法表達它們所知道的內容。此外，對 LLM 誠實的研究也面臨挑戰，包括誠實定義不同、難以區分已知和未知知識，以及缺乏對相關研究的全面理解。為了解決這些問題，我們對 LLM 的誠實進行了一項調查，涵蓋其澄清、評估方法和改進策略。此外，我們為未來的研究提供見解，旨在激勵在這個重要領域進行進一步的探索。

##### **State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features**
2409.18769v1 by George R. Nahass, Ghasem Yazdanpanah, Madison Cheung, Alex Palacios, Jeffery Peterson, Kevin Heinze, Sasha Hubschman, Chad A. Purnell, Pete Setabutr, Ann Q. Tran, Darvin Yi

Periorbital distances and features around the eyes and lids hold valuable
information for disease quantification and monitoring of surgical and medical
intervention. These distances are commonly measured manually, a process that is
both subjective and highly time-consuming. Here, we set out to developed three
deep-learning methods for segmentation and periorbital distance prediction, and
also evaluate the utility of periorbital distances for disease classification.
The MAE of our deep learning predicted distances was less than or very close to
the error observed between trained human annotators. We compared our models to
the current state-of-the-art (SOTA) method for periorbital distance prediction
and found that our methods outperformed SOTA on all of our datasets on all but
one periorbital measurement. We also show that robust segmentation can be
achieved on diseased eyes using models trained on open-source, healthy eyes,
and that periorbital distances have can be used as high-quality features in
downstream classification models. Leveraging segmentation networks as
intermediary steps in classification has broad implications for increasing the
generalizability of classification models in ophthalmic plastic and
craniofacial surgery by avoiding the out-of-distribution problem observed in
traditional convolutional neural networks.

摘要：眼眶周圍的距離和眼睛及眼瞼周圍的特徵對於疾病量化以及外科和醫療介入的監控具有重要的資訊。這些距離通常是手動測量，這是一個主觀且非常耗時的過程。在此，我們著手開發三種深度學習方法，用於分割和眼眶周圍距離預測，並評估眼眶周圍距離對於疾病分類的效用。我們的深度學習預測距離的 MAE 小於或非常接近訓練的人類註解者之間觀察到的誤差。我們將我們的模型與眼眶周圍距離預測的當前最先進 (SOTA) 方法進行比較，發現我們的模型在除了一種眼眶周圍測量外，在我們所有資料集上都優於 SOTA。我們還表明，可以使用在開放原始碼健康眼睛上訓練的模型在患病的眼睛上實現穩健的分割，並且眼眶周圍距離可用作下游分類模型中的高品質特徵。利用分割網路作為分類中的中間步驟對於提高眼科整形和顱面外科中分類模型的概括性具有廣泛的意義，因為避免了在傳統卷積神經網路中觀察到的分布外問題。

##### **Learning from Demonstration with Implicit Nonlinear Dynamics Models**
2409.18768v1 by Peter David Fagan, Subramanian Ramamoorthy

Learning from Demonstration (LfD) is a useful paradigm for training policies
that solve tasks involving complex motions. In practice, the successful
application of LfD requires overcoming error accumulation during policy
execution, i.e. the problem of drift due to errors compounding over time and
the consequent out-of-distribution behaviours. Existing works seek to address
this problem through scaling data collection, correcting policy errors with a
human-in-the-loop, temporally ensembling policy predictions or through learning
the parameters of a dynamical system model. In this work, we propose and
validate an alternative approach to overcoming this issue. Inspired by
reservoir computing, we develop a novel neural network layer that includes a
fixed nonlinear dynamical system with tunable dynamical properties. We validate
the efficacy of our neural network layer on the task of reproducing human
handwriting motions using the LASA Human Handwriting Dataset. Through empirical
experiments we demonstrate that incorporating our layer into existing neural
network architectures addresses the issue of compounding errors in LfD.
Furthermore, we perform a comparative evaluation against existing approaches
including a temporal ensemble of policy predictions and an Echo State Networks
(ESNs) implementation. We find that our approach yields greater policy
precision and robustness on the handwriting task while also generalising to
multiple dynamics regimes and maintaining competitive latency scores.

摘要：從示範中學習 (LfD) 是用於訓練處理涉及複雜動作任務的策略的一個有用的範例。在實務上，LfD 的成功應用需要克服策略執行期間的錯誤累積，也就是說，隨著時間推移，錯誤會複雜化，並導致後續的非分佈行為。現有的作品試圖透過擴大資料收集、透過人工參與迴圈來修正策略錯誤、暫時組合策略預測或透過學習動態系統模型的參數來解決此問題。在這項工作中，我們提出並驗證了克服此問題的替代方法。受到儲存器運算的啟發，我們開發了一個新穎的神經網路層，其中包括一個具有可調整動態特性的固定非線性動態系統。我們在使用 LASA 人類手寫資料集重現人類手寫動作的任務上驗證了我們的神經網路層的效能。透過經驗實驗，我們證明將我們的層納入現有的神經網路架構可以解決 LfD 中的複合錯誤問題。此外，我們針對現有方法，包括策略預測的暫時組合和迴音狀態網路 (ESN) 實作，進行了比較評估。我們發現，我們的做法在手寫任務上產生了更高的策略精確度和穩健性，同時也概括到多個動態模式，並維持有競爭力的延遲分數。

##### **Charting the Future: Using Chart Question-Answering for Scalable Evaluation of LLM-Driven Data Visualizations**
2409.18764v1 by James Ford, Xingmeng Zhao, Dan Schumacher, Anthony Rios

We propose a novel framework that leverages Visual Question Answering (VQA)
models to automate the evaluation of LLM-generated data visualizations.
Traditional evaluation methods often rely on human judgment, which is costly
and unscalable, or focus solely on data accuracy, neglecting the effectiveness
of visual communication. By employing VQA models, we assess data representation
quality and the general communicative clarity of charts. Experiments were
conducted using two leading VQA benchmark datasets, ChartQA and PlotQA, with
visualizations generated by OpenAI's GPT-3.5 Turbo and Meta's Llama 3.1
70B-Instruct models. Our results indicate that LLM-generated charts do not
match the accuracy of the original non-LLM-generated charts based on VQA
performance measures. Moreover, while our results demonstrate that few-shot
prompting significantly boosts the accuracy of chart generation, considerable
progress remains to be made before LLMs can fully match the precision of
human-generated graphs. This underscores the importance of our work, which
expedites the research process by enabling rapid iteration without the need for
human annotation, thus accelerating advancements in this field.

摘要：我們提出了一個新穎的框架，它利用視覺問答 (VQA) 模型來自動化 LLM 生成的資料視覺化的評估。傳統的評估方法通常依賴於人工判斷，這既昂貴又不具可擴展性，或者僅關注資料準確性，而忽略了視覺溝通的有效性。透過使用 VQA 模型，我們評估資料表示品質和圖表的整體溝通清晰度。實驗使用兩個領先的 VQA 基準資料集，ChartQA 和 PlotQA，以及由 OpenAI 的 GPT-3.5 Turbo 和 Meta 的 Llama 3.1 70B-Instruct 模型生成的視覺化。我們的結果表明，根據 VQA 效能指標，LLM 生成的圖表無法比得上原始非 LLM 生成的圖表準確性。此外，儘管我們的結果證明，少次提示顯著提升了圖表生成的準確性，但在 LLM 能完全比得上人工生成的圖表的精準度之前，仍有相當大的進步空間。這突顯了我們工作的價值，它透過無需人工標註來加快反覆運算，從而加速此領域的進展。

##### **OpenObject-NAV: Open-Vocabulary Object-Oriented Navigation Based on Dynamic Carrier-Relationship Scene Graph**
2409.18743v1 by Yujie Tang, Meiling Wang, Yinan Deng, Zibo Zheng, Jiagui Zhong, Yufeng Yue

In everyday life, frequently used objects like cups often have unfixed
positions and multiple instances within the same category, and their carriers
frequently change as well. As a result, it becomes challenging for a robot to
efficiently navigate to a specific instance. To tackle this challenge, the
robot must capture and update scene changes and plans continuously. However,
current object navigation approaches primarily focus on semantic-level and lack
the ability to dynamically update scene representation. This paper captures the
relationships between frequently used objects and their static carriers. It
constructs an open-vocabulary Carrier-Relationship Scene Graph (CRSG) and
updates the carrying status during robot navigation to reflect the dynamic
changes of the scene. Based on the CRSG, we further propose an instance
navigation strategy that models the navigation process as a Markov Decision
Process. At each step, decisions are informed by Large Language Model's
commonsense knowledge and visual-language feature similarity. We designed a
series of long-sequence navigation tasks for frequently used everyday items in
the Habitat simulator. The results demonstrate that by updating the CRSG, the
robot can efficiently navigate to moved targets. Additionally, we deployed our
algorithm on a real robot and validated its practical effectiveness.

摘要：日常生活中，經常使用的物品（例如杯子）通常沒有固定的位置，而且同一類別中有多個實例，其承載者也經常變更。因此，機器人要有效地導航到特定實例變得具有挑戰性。為了應對這一挑戰，機器人必須不斷捕捉和更新場景變更和計畫。然而，目前的物件導航方法主要集中在語義層級，並且缺乏動態更新場景表示的能力。本文捕捉了經常使用的物件及其靜態承載者之間的關係。它構建了一個開放詞彙的承載者關係場景圖 (CRSG)，並在機器人導航期間更新承載狀態以反映場景的動態變化。基於 CRSG，我們進一步提出了一種將導航過程建模為馬可夫決策過程的實例導航策略。在每一步中，決策都由大型語言模型的常識知識和視覺語言特徵相似性來告知。我們為 Habitat 模擬器中的日常常用物品設計了一系列長序列導航任務。結果表明，通過更新 CRSG，機器人可以有效地導航到移動的目標。此外，我們在真實機器人上部署了我們的演算法，並驗證了其實際效能。

##### **Cross-Domain Keyword Extraction with Keyness Patterns**
2409.18724v1 by Dongmei Zhou, Xuri Tang

Domain dependence and annotation subjectivity pose challenges for supervised
keyword extraction. Based on the premises that second-order keyness patterns
are existent at the community level and learnable from annotated keyword
extraction datasets, this paper proposes a supervised ranking approach to
keyword extraction that ranks keywords with keyness patterns consisting of
independent features (such as sublanguage domain and term length) and three
categories of dependent features -- heuristic features, specificity features,
and representavity features. The approach uses two convolutional-neural-network
based models to learn keyness patterns from keyword datasets and overcomes
annotation subjectivity by training the two models with bootstrap sampling
strategy. Experiments demonstrate that the approach not only achieves
state-of-the-art performance on ten keyword datasets in general supervised
keyword extraction with an average top-10-F-measure of 0.316 , but also robust
cross-domain performance with an average top-10-F-measure of 0.346 on four
datasets that are excluded in the training process. Such cross-domain
robustness is attributed to the fact that community-level keyness patterns are
limited in number and temperately independent of language domains, the
distinction between independent features and dependent features, and the
sampling training strategy that balances excess risk and lack of negative
training data.

摘要：領域依賴性和標註主觀性對監督式關鍵字萃取構成挑戰。本文基於以下前提：次序關鍵模式存在於社群層級，且可以從標註的關鍵字萃取資料集學習，提出一個監督式排名方法來進行關鍵字萃取，該方法使用包含獨立特徵（例如次語言領域和術語長度）和三類依賴特徵（啟發式特徵、特異性特徵和代表性特徵）的關鍵模式對關鍵字進行排名。該方法使用兩個基於卷積神經網路的模型從關鍵字資料集學習關鍵模式，並透過引導取樣策略訓練兩個模型來克服標註主觀性。實驗證明，該方法不僅在一般監督式關鍵字萃取中對十個關鍵字資料集獲得了最先進的效能，平均前 10 名 F 值為 0.316，而且在四個訓練過程中排除的資料集上也獲得了穩健的跨領域效能，平均前 10 名 F 值為 0.346。這種跨領域的穩健性歸因於以下事實：社群層級的關鍵模式數量有限，且與語言領域的關聯性較低，獨立特徵和依賴特徵之間的區別，以及平衡過度風險和缺乏負面訓練資料的取樣訓練策略。

##### **Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification**
2409.18715v1 by Salma Hassan, Hamad Al Hammadi, Ibrahim Mohammed, Muhammad Haris Khan

The early detection and nuanced subtype classification of non-small cell lung
cancer (NSCLC), a predominant cause of cancer mortality worldwide, is a
critical and complex issue. In this paper, we introduce an innovative
integration of multi-modal data, synthesizing fused medical imaging (CT and PET
scans) with clinical health records and genomic data. This unique fusion
methodology leverages advanced machine learning models, notably MedClip and
BEiT, for sophisticated image feature extraction, setting a new standard in
computational oncology. Our research surpasses existing approaches, as
evidenced by a substantial enhancement in NSCLC detection and classification
precision. The results showcase notable improvements across key performance
metrics, including accuracy, precision, recall, and F1-score. Specifically, our
leading multi-modal classifier model records an impressive accuracy of 94.04%.
We believe that our approach has the potential to transform NSCLC diagnostics,
facilitating earlier detection and more effective treatment planning and,
ultimately, leading to superior patient outcomes in lung cancer care.

摘要：早期檢測和細緻的非小細胞肺癌 (NSCLC) 亞型分類，是全球癌症死亡率的主要原因，是一個關鍵且複雜的問題。在本文中，我們介紹了一個創新的多模式數據整合，將融合的醫學影像 (CT 和 PET 掃描) 與臨床健康記錄和基因組數據合成。這種獨特的融合方法利用了先進的機器學習模型，特別是 MedClip 和 BEiT，進行複雜的影像特徵提取，為計算腫瘤學設定了新的標準。我們的研究超越了現有方法，這從 NSCLC 檢測和分類精度的顯著提高中得到證明。結果展示了在關鍵效能指標（包括準確度、精確度、召回率和 F1 分數）上的顯著改進。具體來說，我們領先的多模式分類器模型記錄了令人印象深刻的 94.04% 準確度。我們相信我們的做法有潛力轉變 NSCLC 診斷，促進早期檢測和更有效的治療計畫，並最終改善肺癌照護中的患者預後。

##### **Read Over the Lines: Attacking LLMs and Toxicity Detection Systems with ASCII Art to Mask Profanity**
2409.18708v1 by Sergey Berezin, Reza Farahbakhsh, Noel Crespi

We introduce a novel family of adversarial attacks that exploit the inability
of language models to interpret ASCII art. To evaluate these attacks, we
propose the ToxASCII benchmark and develop two custom ASCII art fonts: one
leveraging special tokens and another using text-filled letter shapes. Our
attacks achieve a perfect 1.0 Attack Success Rate across ten models, including
OpenAI's o1-preview and LLaMA 3.1.
  Warning: this paper contains examples of toxic language used for research
purposes.

摘要：我們引入了一系列新穎的對抗性攻擊，利用語言模型無法詮釋 ASCII 藝術的弱點。為了評估這些攻擊，我們提議 ToxASCII 基準，並開發了兩種自訂 ASCII 藝術字型：一種利用特殊代碼，另一種使用填滿文字的字母形狀。我們的攻擊在十個模型中獲得了完美的 1.0 攻擊成功率，包括 OpenAI 的 o1-preview 和 LLaMA 3.1。
警告：本文包含出於研究目的而使用的有毒語言範例。

##### **Speech Boosting: Low-Latency Live Speech Enhancement for TWS Earbuds**
2409.18705v1 by Hanbin Bae, Pavel Andreev, Azat Saginbaev, Nicholas Babaev, Won-Jun Lee, Hosang Sung, Hoon-Young Cho

This paper introduces a speech enhancement solution tailored for true
wireless stereo (TWS) earbuds on-device usage. The solution was specifically
designed to support conversations in noisy environments, with active noise
cancellation (ANC) activated. The primary challenges for speech enhancement
models in this context arise from computational complexity that limits
on-device usage and latency that must be less than 3 ms to preserve a live
conversation. To address these issues, we evaluated several crucial design
elements, including the network architecture and domain, design of loss
functions, pruning method, and hardware-specific optimization. Consequently, we
demonstrated substantial improvements in speech enhancement quality compared
with that in baseline models, while simultaneously reducing the computational
complexity and algorithmic latency.

摘要：本文介紹了一種針對真無線立體聲 (TWS) 耳機裝置使用量身打造的語音增強解決方案。此解決方案特別設計用於支援在有噪音的環境中進行對話，並啟動主動式抗噪 (ANC)。在此情境中，語音增強模型的主要挑戰來自於計算複雜度，這限制了裝置使用量，且延遲必須小於 3 毫秒才能維持即時對話。為了解決這些問題，我們評估了幾個關鍵的設計元素，包括網路架構和網域、損失函數設計、剪枝方法和特定硬體的最佳化。因此，我們展示了語音增強品質的顯著改善，與基準模型相比，同時降低了計算複雜度和演算法延遲。

##### **Semantic Model Component Implementation for Model-driven Semantic Communications**
2409.18704v1 by Haotai Liang, Mengran Shi, Chen Dong, Xiaodong Xu, Long Liu, Hao Chen

The key feature of model-driven semantic communication is the propagation of
the model. The semantic model component (SMC) is designed to drive the
intelligent model to transmit in the physical channel, allowing the
intelligence to flow through the networks. According to the characteristics of
neural networks with common and individual model parameters, this paper designs
the cross-source-domain and cross-task semantic component model. Considering
that the basic model is deployed on the edge node, the large server node
updates the edge node by transmitting only the semantic component model to the
edge node so that the edge node can handle different sources and different
tasks. In addition, this paper also discusses how channel noise affects the
performance of the model and proposes methods of injection noise and
regularization to improve the noise resistance of the model. Experiments show
that SMCs use smaller model parameters to achieve cross-source, cross-task
functionality while maintaining performance and improving the model's tolerance
to noise. Finally, a component transfer-based unmanned vehicle tracking
prototype was implemented to verify the feasibility of model components in
practical applications.

摘要：模型驅動語義通信的主要特徵是模型的傳遞。語義模型元件 (SMC) 被設計用於驅動智能模型在物理頻道中傳輸，讓智能能夠流動於網路中。根據具有共用和個別模型參數的神經網路特性，本文設計了跨來源網域和跨任務語義元件模型。考量到基本模型部署在邊緣節點上，大型伺服器節點僅透過將語義元件模型傳輸至邊緣節點來更新邊緣節點，讓邊緣節點能夠處理不同的來源和不同的任務。此外，本文也探討頻道雜訊如何影響模型的效能，並提出注入雜訊和正規化的方式來提升模型的抗雜訊性。實驗顯示，SMC 使用較小的模型參數來達成跨來源、跨任務功能，同時維持效能並提升模型對雜訊的容忍度。最後，實作了一個基於元件傳輸的無人車追蹤原型，以驗證模型元件在實際應用中的可行性。

##### **KALE-LM: Unleash The Power Of AI For Science Via Knowledge And Logic Enhanced Large Model**
2409.18695v1 by Weichen Dai, Yezeng Chen, Zijie Dai, Zhijie Huang, Yubo Liu, Yixuan Pan, Baiyang Song, Chengli Zhong, Xinhe Li, Zeyu Wang, Zhuoying Feng, Yi Zhou

Artificial intelligence is gradually demonstrating its immense potential, and
increasing attention is being given to how AI can be harnessed to advance
scientific research. In this vision paper, we present our perspectives on how
AI can better assist scientific inquiry and explore corresponding technical
approach. We have proposed and open-sourced a large model of our KALE-LM model
series, Llama3-KALE-LM-Chem-8B, which has achieved outstanding performance in
tasks related to the field of chemistry. We hope that our work serves as a
strong starting point, helping to realize more intelligent AI and promoting the
advancement of human science and technology, as well as societal development.

摘要：人工智能逐漸展現出其強大的潛力，而如何利用 AI 來推進科學研究也備受關注。在本文中，我們將提出我們的觀點，說明 AI 如何能更好地協助科學探究，並探討相應的技術方法。我們已提出並開放原始碼，作為我們 KALE-LM 模型系列的大型模型，Llama3-KALE-LM-Chem-8B，在與化學領域相關的任務中取得了傑出的表現。我們希望我們的成果能作為一個強有力的起點，有助於實現更智慧的人工智慧，並促進人類科學技術以及社會發展。

##### **MG-Net: Learn to Customize QAOA with Circuit Depth Awareness**
2409.18692v1 by Yang Qian, Xinbiao Wang, Yuxuan Du, Yong Luo, Dacheng Tao

Quantum Approximate Optimization Algorithm (QAOA) and its variants exhibit
immense potential in tackling combinatorial optimization challenges. However,
their practical realization confronts a dilemma: the requisite circuit depth
for satisfactory performance is problem-specific and often exceeds the maximum
capability of current quantum devices. To address this dilemma, here we first
analyze the convergence behavior of QAOA, uncovering the origins of this
dilemma and elucidating the intricate relationship between the employed mixer
Hamiltonian, the specific problem at hand, and the permissible maximum circuit
depth. Harnessing this understanding, we introduce the Mixer Generator Network
(MG-Net), a unified deep learning framework adept at dynamically formulating
optimal mixer Hamiltonians tailored to distinct tasks and circuit depths.
Systematic simulations, encompassing Ising models and weighted Max-Cut
instances with up to 64 qubits, substantiate our theoretical findings,
highlighting MG-Net's superior performance in terms of both approximation ratio
and efficiency.

摘要：量子近似优化算法 (QAOA) 及其变体在解决组合优化挑战方面展现出巨大的潜力。然而，它们的实际实现面临一个两难困境：令人满意的性能所需的电路深度因问题而异，并且通常超出当前量子设备的最大能力。为了解决这一困境，我们首先分析了 QAOA 的收敛行为，揭示了这一困境的根源，并阐明了所采用的混合哈密顿量、手头的具体问题和允许的最大电路深度之间的复杂关系。利用这一理解，我们引入了混合器生成器网络 (MG-Net)，这是一个统一的深度学习框架，善于动态地为不同的任务和电路深度制定最佳的混合哈密顿量。系统模拟，包括 Ising 模型和具有多达 64 个量子位的加权最大割实例，证实了我们的理论发现，突出了 MG-Net 在逼近率和效率方面的卓越性能。

##### **Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models**
2409.18680v1 by Yiming Chen, Xianghu Yue, Xiaoxue Gao, Chen Zhang, Luis Fernando D'Haro, Robby T. Tan, Haizhou Li

Various audio-LLMs (ALLMs) have been explored recently for tackling different
audio tasks simultaneously using a single, unified model. While existing
evaluations of ALLMs primarily focus on single-audio tasks, real-world
applications often involve processing multiple audio streams simultaneously. To
bridge this gap, we propose the first multi-audio evaluation (MAE) benchmark
that consists of 20 datasets from 11 multi-audio tasks encompassing both speech
and sound scenarios. Comprehensive experiments on MAE demonstrate that the
existing ALLMs, while being powerful in comprehending primary audio elements in
individual audio inputs, struggling to handle multi-audio scenarios. To this
end, we propose a novel multi-audio-LLM (MALLM) to capture audio context among
multiple similar audios using discriminative learning on our proposed synthetic
data. The results demonstrate that the proposed MALLM outperforms all baselines
and achieves high data efficiency using synthetic data without requiring human
annotations. The proposed MALLM opens the door for ALLMs towards multi-audio
processing era and brings us closer to replicating human auditory capabilities
in machines.

摘要：最近已探索各種音訊 LLM（ALLM），以使用單一統一模型同時處理不同的音訊任務。雖然現有的 ALLM 評估主要集中於單一音訊任務，但實際應用通常涉及同時處理多個音訊串流。為了彌合這個差距，我們提出了第一個多音訊評估（MAE）基準，其中包含來自 11 個多音訊任務的 20 個資料集，涵蓋語音和聲音場景。MAE 上的綜合實驗表明，現有的 ALLM 雖然能夠理解個別音訊輸入中的主要音訊元素，但難以處理多音訊場景。為此，我們提出了一種新穎的多音訊 LLM（MALLM），以使用我們提出的合成資料對多個類似音訊進行區分學習，從而捕捉多個音訊之間的音訊背景。結果表明，所提出的 MALLM 優於所有基線，並且在不需人工註解的情況下使用合成資料實現了高資料效率。所提出的 MALLM 為 ALLM 開啟了多音訊處理時代的大門，並使我們更接近於在機器中複製人類聽覺能力。

##### **"Why" Has the Least Side Effect on Model Editing**
2409.18679v1 by Tsung-Hsuan Pan, Chung-Chi Chen, Hen-Hsen Huang, Hsin-Hsi Chen

Training large language models (LLMs) from scratch is an expensive endeavor,
particularly as world knowledge continually evolves. To maintain relevance and
accuracy of LLMs, model editing has emerged as a pivotal research area. While
these methods hold promise, they can also produce unintended side effects.
Their underlying factors and causes remain largely unexplored. This paper
delves into a critical factor-question type-by categorizing model editing
questions. Our findings reveal that the extent of performance degradation
varies significantly across different question types, providing new insights
for experimental design in knowledge editing. Furthermore, we investigate
whether insights from smaller models can be extrapolated to larger models. Our
results indicate discrepancies in findings between models of different sizes,
suggesting that insights from smaller models may not necessarily apply to
larger models. Additionally, we examine the impact of batch size on side
effects, discovering that increasing the batch size can mitigate performance
drops.

摘要：從頭訓練大型語言模型 (LLM) 是一項昂貴的事業，尤其是隨著世界知識不斷演變。為了維持 LLM 的相關性和準確性，模型編輯已成為一項關鍵的研究領域。雖然這些方法很有希望，但它們也可能產生意想不到的副作用。它們的潛在因素和原因在很大程度上仍未得到探討。本文深入探討了一個關鍵因素：問題類型，方法是對模型編輯問題進行分類。我們的研究結果表明，不同問題類型的效能下降程度差異很大，為知識編輯中的實驗設計提供了新的見解。此外，我們探討了從較小的模型中獲得的見解是否可以推廣到較大的模型。我們的結果表明，不同大小的模型之間的發現存在差異，這表明從較小的模型中獲得的見解不一定適用於較大的模型。此外，我們研究了批次大小對副作用的影響，發現增加批次大小可以減輕效能下降。

##### **Rehearsing Answers to Probable Questions with Perspective-Taking**
2409.18678v1 by Yung-Yu Shih, Ziwei Xu, Hiroya Takamura, Yun-Nung Chen, Chung-Chi Chen

Question answering (QA) has been a long-standing focus in the NLP field,
predominantly addressing reading comprehension and common sense QA. However,
scenarios involving the preparation of answers to probable questions during
professional oral presentations remain underexplored. In this paper, we pioneer
the examination of this crucial yet overlooked topic by utilizing real-world QA
conversation transcripts between company managers and professional analysts. We
explore the proposed task using three causal knowledge graphs (KGs) and three
large language models (LLMs). This work provides foundational insights into the
application of LLMs in professional QA scenarios, highlighting the importance
of causal KGs and perspective-taking in generating effective responses.

摘要：問題解答 (QA) 一直是自然語言處理 (NLP) 領域的長期關注重點，
主要解決閱讀理解和常識問題解答。然而，
在專業口頭簡報中準備回答可能問題的場景仍未得到充分探討。在本文中，我們率先
利用公司經理和專業分析師之間的真實世界問答對話記錄，探討這個至關重要但被忽視的主題。我們
使用三個因果知識圖譜 (KG) 和三個大型語言模型 (LLM) 來探討提出的任務。這項工作為 LLM 在專業問答場景中的應用提供了基礎見解，強調了因果 KG 和觀點採取在產生有效回應中的重要性。

##### **Toward Universal and Interpretable World Models for Open-ended Learning Agents**
2409.18676v1 by Lancelot Da Costa

We introduce a generic, compositional and interpretable class of generative
world models that supports open-ended learning agents. This is a sparse class
of Bayesian networks capable of approximating a broad range of stochastic
processes, which provide agents with the ability to learn world models in a
manner that may be both interpretable and computationally scalable. This
approach integrating Bayesian structure learning and intrinsically motivated
(model-based) planning enables agents to actively develop and refine their
world models, which may lead to open-ended learning and more robust, adaptive
behavior.

摘要：我們介紹了一個通用的、組合的與可解釋的生成世界模型類，它支援開放式學習代理。這是一個稀疏類型的貝氏網路，能夠近似廣泛的隨機過程，這提供了代理學習世界模型的能力，這種方式可能是可解釋的和計算可擴充的。這種方法整合了貝氏結構學習和內在動機（基於模型）規劃，使代理能夠積極開發和改進其世界模型，這可能導致開放式學習和更強健、適應性更強的行為。

##### **Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practice**
2409.18661v1 by Eddie Antonio Santos, Brett A. Becker

The sudden emergence of large language models (LLMs) such as ChatGPT has had
a disruptive impact throughout the computing education community. LLMs have
been shown to excel at producing correct code to CS1 and CS2 problems, and can
even act as friendly assistants to students learning how to code. Recent work
shows that LLMs demonstrate unequivocally superior results in being able to
explain and resolve compiler error messages -- for decades, one of the most
frustrating parts of learning how to code. However, LLM-generated error message
explanations have only been assessed by expert programmers in artificial
conditions. This work sought to understand how novice programmers resolve
programming error messages (PEMs) in a more realistic scenario. We ran a
within-subjects study with $n$ = 106 participants in which students were tasked
to fix six buggy C programs. For each program, participants were randomly
assigned to fix the problem using either a stock compiler error message, an
expert-handwritten error message, or an error message explanation generated by
GPT-4. Despite promising evidence on synthetic benchmarks, we found that GPT-4
generated error messages outperformed conventional compiler error messages in
only 1 of the 6 tasks, measured by students' time-to-fix each problem.
Handwritten explanations still outperform LLM and conventional error messages,
both on objective and subjective measures.

摘要：大型語言模型 (LLM) 如 ChatGPT 的突然出現對整個計算教育界產生了顛覆性的影響。LLM 已被證明擅長產生正確的 CS1 和 CS2 問題程式碼，甚至可以作為學習如何編寫程式碼的學生的友善助手。最近的研究表明，LLM 在解釋和解決編譯器錯誤訊息方面表現出明顯的優異結果——幾十年來，這是學習如何編寫程式碼最令人沮喪的部分之一。然而，LLM 生成的錯誤訊息解釋僅由人工條件下的專家程式設計師評估。這項工作旨在了解新手程式設計師如何在更實際的場景中解決程式設計錯誤訊息 (PEM)。我們進行了一項受試者內研究，有 $n$ = 106 名參與者，學生被要求修復六個有錯誤的 C 程式。對於每個程式，參與者被隨機分配使用庫存編譯器錯誤訊息、專家手寫錯誤訊息或由 GPT-4 生成的錯誤訊息解釋來修復問題。儘管在合成基準上有令人滿意的證據，但我們發現 GPT-4 生成的錯誤訊息僅在 6 項任務中的 1 項中優於傳統編譯器錯誤訊息，衡量標準為學生修復每個問題的時間。手寫解釋在客觀和主觀測量上仍然優於 LLM 和傳統錯誤訊息。

##### **When SAM2 Meets Video Camouflaged Object Segmentation: A Comprehensive Evaluation and Adaptation**
2409.18653v1 by Yuli Zhou, Guolei Sun, Yawei Li, Luca Benini, Ender Konukoglu

This study investigates the application and performance of the Segment
Anything Model 2 (SAM2) in the challenging task of video camouflaged object
segmentation (VCOS). VCOS involves detecting objects that blend seamlessly in
the surroundings for videos, due to similar colors and textures, poor light
conditions, etc. Compared to the objects in normal scenes, camouflaged objects
are much more difficult to detect. SAM2, a video foundation model, has shown
potential in various tasks. But its effectiveness in dynamic camouflaged
scenarios remains under-explored. This study presents a comprehensive study on
SAM2's ability in VCOS. First, we assess SAM2's performance on camouflaged
video datasets using different models and prompts (click, box, and mask).
Second, we explore the integration of SAM2 with existing multimodal large
language models (MLLMs) and VCOS methods. Third, we specifically adapt SAM2 by
fine-tuning it on the video camouflaged dataset. Our comprehensive experiments
demonstrate that SAM2 has excellent zero-shot ability of detecting camouflaged
objects in videos. We also show that this ability could be further improved by
specifically adjusting SAM2's parameters for VCOS. The code will be available
at https://github.com/zhoustan/SAM2-VCOS

摘要：本研究探討 Segment Anything Model 2 (SAM2) 在影片偽裝物件分割 (VCOS) 的艱難任務中的應用與效能。VCOS 涉及偵測在影片中與周遭環境無縫融合的物件，原因在於相似的色彩與紋理、不良的光線條件等。與一般場景中的物件相比，偽裝物件更難以偵測。SAM2 是一個影片基礎模型，已在各種任務中展現潛力。但它在動態偽裝場景中的效能仍未受到充分探討。本研究對 SAM2 在 VCOS 中的能力進行全面研究。首先，我們使用不同的模型和提示 (點選、方框和遮罩) 評估 SAM2 在偽裝影片資料集上的效能。其次，我們探討 SAM2 與現有的多模態大型語言模型 (MLLM) 和 VCOS 方法的整合。第三，我們透過在影片偽裝資料集上微調 SAM2，特別調整它。我們的全面實驗證明 SAM2 具有極佳的零次學習能力，可以偵測影片中的偽裝物件。我們也顯示，透過特別調整 SAM2 的參數以符合 VCOS，可以進一步提升此能力。程式碼將在 https://github.com/zhoustan/SAM2-VCOS 中提供

##### **HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents**
2409.18647v1 by T. Y. S. S. Santosh, Apolline Isaia, Shiyu Hong, Matthias Grabmair

Rhetorical Role Labeling (RRL) of legal documents is pivotal for various
downstream tasks such as summarization, semantic case search and argument
mining. Existing approaches often overlook the varying difficulty levels
inherent in legal document discourse styles and rhetorical roles. In this work,
we propose HiCuLR, a hierarchical curriculum learning framework for RRL. It
nests two curricula: Rhetorical Role-level Curriculum (RC) on the outer layer
and Document-level Curriculum (DC) on the inner layer. DC categorizes documents
based on their difficulty, utilizing metrics like deviation from a standard
discourse structure and exposes the model to them in an easy-to-difficult
fashion. RC progressively strengthens the model to discern
coarse-to-fine-grained distinctions between rhetorical roles. Our experiments
on four RRL datasets demonstrate the efficacy of HiCuLR, highlighting the
complementary nature of DC and RC.

摘要：法律文件修辭角色標記 (RRL) 對於各種下游任務（例如摘要、語意案例搜尋和論點探勘）至關重要。現有方法通常忽略法律文件論述風格和修辭角色中存在的不同難度等級。在這項工作中，我們提出了 HiCuLR，一個用於 RRL 的分層課程學習框架。它嵌入了兩個課程：外層的修辭角色層級課程 (RC) 和內層的文件層級課程 (DC)。DC 根據難度對文件進行分類，利用標準論述結構的偏差等指標，並以易到難的方式向模型展示這些文件。RC 逐步強化模型，以辨別修辭角色之間粗略到細微的區別。我們在四個 RRL 資料集上的實驗證明了 HiCuLR 的功效，突出了 DC 和 RC 的互補性質。

##### **The Craft of Selective Prediction: Towards Reliable Case Outcome Classification -- An Empirical Study on European Court of Human Rights Cases**
2409.18645v1 by T. Y. S. S. Santosh, Irtiza Chowdhury, Shanshan Xu, Matthias Grabmair

In high-stakes decision-making tasks within legal NLP, such as Case Outcome
Classification (COC), quantifying a model's predictive confidence is crucial.
Confidence estimation enables humans to make more informed decisions,
particularly when the model's certainty is low, or where the consequences of a
mistake are significant. However, most existing COC works prioritize high task
performance over model reliability. This paper conducts an empirical
investigation into how various design choices including pre-training corpus,
confidence estimator and fine-tuning loss affect the reliability of COC models
within the framework of selective prediction. Our experiments on the
multi-label COC task, focusing on European Court of Human Rights (ECtHR) cases,
highlight the importance of a diverse yet domain-specific pre-training corpus
for better calibration. Additionally, we demonstrate that larger models tend to
exhibit overconfidence, Monte Carlo dropout methods produce reliable confidence
estimates, and confident error regularization effectively mitigates
overconfidence. To our knowledge, this is the first systematic exploration of
selective prediction in legal NLP. Our findings underscore the need for further
research on enhancing confidence measurement and improving the trustworthiness
of models in the legal domain.

摘要：<paragraph>在法律 NLP 中的高風險決策任務中，例如案件結果分類 (COC)，量化模型的預測信心至關重要。信心估計使人類能夠做出更明智的決策，特別是在模型的確定性低或錯誤後果重大的情況下。然而，現有的 COC 工作大多優先考慮高任務性能而非模型可靠性。本文對各種設計選擇（包括預訓練語料庫、信心估計器和微調損失）如何影響 COC 模型在選擇性預測框架內的可靠性進行了實證調查。我們在多標籤 COC 任務上的實驗，重點關注歐洲人權法院 (ECtHR) 案件，強調了多樣化且特定於領域的預訓練語料庫對於更好的校準的重要性。此外，我們證明了較大的模型往往表現出過度自信，蒙特卡羅輟學方法產生可靠的信心估計，並且自信錯誤正則化有效減輕了過度自信。據我們所知，這是對法律 NLP 中選擇性預測的首次系統探索。我們的研究結果強調了進一步研究以增強信心測量和提高法律領域模型可信度的必要性。</paragraph>

##### **Incorporating Precedents for Legal Judgement Prediction on European Court of Human Rights Cases**
2409.18644v1 by T. Y. S. S. Santosh, Mohamed Hesham Elganayni, Stanisław Sójka, Matthias Grabmair

Inspired by the legal doctrine of stare decisis, which leverages precedents
(prior cases) for informed decision-making, we explore methods to integrate
them into LJP models. To facilitate precedent retrieval, we train a retriever
with a fine-grained relevance signal based on the overlap ratio of alleged
articles between cases. We investigate two strategies to integrate precedents:
direct incorporation at inference via label interpolation based on case
proximity and during training via a precedent fusion module using a
stacked-cross attention model. We employ joint training of the retriever and
LJP models to address latent space divergence between them. Our experiments on
LJP tasks from the ECHR jurisdiction reveal that integrating precedents during
training coupled with joint training of the retriever and LJP model,
outperforms models without precedents or with precedents incorporated only at
inference, particularly benefiting sparser articles.

摘要：受遵循先例的法律原则启发，该原则利用先例（先前的案例）进行明智的决策，我们探索将它们整合到 LJP 模型中的方法。为了促进先例检索，我们训练了一个检索器，其基于案例之间涉嫌文章的重叠率来获得细粒度的相关性信号。我们调查了两种整合先例的策略：在推理时通过基于案例接近度的标签插值直接纳入，以及在训练期间通过使用堆叠交叉注意力模型的先例融合模块纳入。我们采用检索器和 LJP 模型的联合训练来解决它们之间的潜在空间差异。我们在欧洲人权法院管辖区的 LJP 任务上的实验表明，在训练期间整合先例，并结合检索器和 LJP 模型的联合训练，优于没有先例或仅在推理时纳入先例的模型，特别是对稀疏文章有益。

##### **Entropy, concentration, and learning: a statistical mechanics primer**
2409.18630v1 by Akshay Balsubramani

Artificial intelligence models trained through loss minimization have
demonstrated significant success, grounded in principles from fields like
information theory and statistical physics. This work explores these
established connections through the lens of statistical mechanics, starting
from first-principles sample concentration behaviors that underpin AI and
machine learning. Our development of statistical mechanics for modeling
highlights the key role of exponential families, and quantities of statistics,
physics, and information theory.

摘要：透過損失最小化訓練的人工智慧模型已展現顯著的成功，奠基於資訊論和統計物理等領域的原理。這項工作透過統計力學的觀點探討這些既定的連結，從支撐 AI 和機器學習的基本原理取樣集中行為開始。我們發展用於建模的統計力學突顯了指數族和統計量、物理量和資訊論的關鍵角色。

##### **Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow**
2409.18628v1 by Marvin Tom Teichmann, Manasi Datar, Lisa Kratzke, Fernando Vega, Florin C. Ghesu

The precision of contouring target structures and organs-at-risk (OAR) in
radiotherapy planning is crucial for ensuring treatment efficacy and patient
safety. Recent advancements in deep learning (DL) have significantly improved
OAR contouring performance, yet the reliability of these models, especially in
the presence of out-of-distribution (OOD) scenarios, remains a concern in
clinical settings. This application study explores the integration of epistemic
uncertainty estimation within the OAR contouring workflow to enable OOD
detection in clinically relevant scenarios, using specifically compiled data.
Furthermore, we introduce an advanced statistical method for OOD detection to
enhance the methodological framework of uncertainty estimation. Our empirical
evaluation demonstrates that epistemic uncertainty estimation is effective in
identifying instances where model predictions are unreliable and may require an
expert review. Notably, our approach achieves an AUC-ROC of 0.95 for OOD
detection, with a specificity of 0.95 and a sensitivity of 0.92 for implant
cases, underscoring its efficacy. This study addresses significant gaps in the
current research landscape, such as the lack of ground truth for uncertainty
estimation and limited empirical evaluations. Additionally, it provides a
clinically relevant application of epistemic uncertainty estimation in an
FDA-approved and widely used clinical solution for OAR segmentation from
Varian, a Siemens Healthineers company, highlighting its practical benefits.

摘要：<paragraph>在放射治療規劃中，輪廓化標靶結構和器官風險（OAR）的精確度對於確保治療效果和患者安全至關重要。深度學習（DL）的最新進展顯著改善了 OAR 輪廓化效能，但這些模型的可靠性，特別是在出現分布外（OOD）場景時，在臨床環境中仍然令人擔憂。本應用研究探討了將認識不確定性估計整合到 OAR 輪廓化工作流程中，以使用特別編譯的資料在臨床上相關的場景中啟用 OOD 偵測。此外，我們引入了一種先進的統計方法進行 OOD 偵測，以增強不確定性估計的方法論架構。我們的實證評估證明，認識不確定性估計在識別模型預測不可靠且可能需要專家審查的情況方面是有效的。值得注意的是，我們的做法對於植入物案例達到了 0.95 的 OOD 偵測 AUC-ROC，特異性為 0.95，靈敏度為 0.92，突顯了其功效。這項研究解決了當前研究領域中的重大差距，例如缺乏不確定性估計的基本原理和有限的實證評估。此外，它提供了一個在 FDA 批准且廣泛使用的臨床解決方案中認識不確定性估計在 OAR 分割方面的臨床相關應用，該解決方案來自西門子醫療公司旗下的 Varian，突顯了其實際效益。</paragraph>

##### **Unsupervised Cognition**
2409.18624v1 by Alfredo Ibias, Hector Antona, Guillem Ramirez-Miranda, Enric Guinovart, Eduard Alarcon

Unsupervised learning methods have a soft inspiration in cognition models. To
this day, the most successful unsupervised learning methods revolve around
clustering samples in a mathematical space. In this paper we propose a
state-of-the-art primitive-based unsupervised learning approach for
decision-making inspired by novel cognition models. This representation-centric
approach models the input space constructively as a distributed hierarchical
structure in an input-agnostic way. We compared our approach with current
state-of-the-art in unsupervised learning classification, and with current
state-of-the-art in cancer type classification. We show how our proposal
outperforms previous state-of-the-art. We also evaluate some cognition-like
properties of our proposal where it not only outperforms the compared
algorithms (even supervised learning ones), but it also shows a different, more
cognition-like, behaviour.

摘要：無監督式學習方法在認知模型中獲得柔和的啟發。時至今日，最成功的無監督式學習方法圍繞著在數學空間中對樣本進行分群。在本文中，我們提出了一種由新認知模型啟發的、基於原語的無監督式學習方法，用於決策制定。這種以表示為中心的演算法以輸入不可知的方式，建構性地將輸入空間建模為分佈式階層結構。我們將我們的演算法與當前無監督式學習分類中的最新技術，以及當前癌症類型分類中的最新技術進行比較。我們展示了我們的提案如何優於先前的最新技術。我們還評估了我們提案的一些類似認知的特性，它不僅優於比較演算法（甚至是監督式學習演算法），而且還表現出不同、更類似認知的行為。

##### **Model-based Preference Optimization in Abstractive Summarization without Human Feedback**
2409.18618v1 by Jaepill Choi, Kyubyung Chae, Jiwoo Song, Yohan Jo, Taesup Kim

In abstractive summarization, the challenge of producing concise and accurate
summaries arises from the vast amount of information contained in the source
document. Consequently, although Large Language Models (LLMs) can generate
fluent text, they often introduce inaccuracies by hallucinating content not
found in the original source. While supervised fine-tuning methods that
maximize likelihood contribute to this issue, they do not consistently enhance
the faithfulness of the summaries. Preference-based optimization methods, such
as Direct Preference Optimization (DPO), can further refine the model to align
with human preferences. However, these methods still heavily depend on costly
human feedback. In this work, we introduce a novel and straightforward approach
called Model-based Preference Optimization (MPO) to fine-tune LLMs for improved
summarization abilities without any human feedback. By leveraging the model's
inherent summarization capabilities, we create a preference dataset that is
fully generated by the model using different decoding strategies. Our
experiments on standard summarization datasets and various metrics demonstrate
that our proposed MPO significantly enhances the quality of generated summaries
without relying on human feedback.

摘要：在抽象摘要中，產生簡潔且準確的摘要的挑戰來自於原始文件中包含的龐大資訊量。因此，儘管大型語言模型 (LLM) 可以產生流暢的文字，但它們常常會透過幻覺化原始來源中找不到的內容來引入不準確性。雖然最大化可能性有助於解決此問題的監督微調方法，但它們並未持續增強摘要的忠實度。基於偏好的最佳化方法（例如直接偏好最佳化 (DPO)）可以進一步改善模型，以符合人類的偏好。然而，這些方法仍然高度依賴昂貴的人類回饋。在這項工作中，我們引進一種稱為基於模型的偏好最佳化 (MPO) 的新穎且直接的方法，用於微調 LLM，以在沒有任何人類回饋的情況下改善摘要能力。透過利用模型固有的摘要能力，我們建立了一個偏好資料集，該資料集完全由模型使用不同的解碼策略產生。我們在標準摘要資料集和各種指標上的實驗證明，我們提出的 MPO 大幅提升了產生摘要的品質，而無需依賴人類回饋。

##### **Do LLMs suffer from Multi-Party Hangover? A Diagnostic Approach to Addressee Recognition and Response Selection in Conversations**
2409.18602v1 by Nicolò Penzo, Maryam Sajedinia, Bruno Lepri, Sara Tonelli, Marco Guerini

Assessing the performance of systems to classify Multi-Party Conversations
(MPC) is challenging due to the interconnection between linguistic and
structural characteristics of conversations. Conventional evaluation methods
often overlook variances in model behavior across different levels of
structural complexity on interaction graphs. In this work, we propose a
methodological pipeline to investigate model performance across specific
structural attributes of conversations. As a proof of concept we focus on
Response Selection and Addressee Recognition tasks, to diagnose model
weaknesses. To this end, we extract representative diagnostic subdatasets with
a fixed number of users and a good structural variety from a large and open
corpus of online MPCs. We further frame our work in terms of data minimization,
avoiding the use of original usernames to preserve privacy, and propose
alternatives to using original text messages. Results show that response
selection relies more on the textual content of conversations, while addressee
recognition requires capturing their structural dimension. Using an LLM in a
zero-shot setting, we further highlight how sensitivity to prompt variations is
task-dependent.

摘要：評估多方對話 (MPC) 分類系統的效能具有挑戰性，因為對話的語言和結構特徵之間存在相互關聯。傳統的評估方法通常會忽略互動圖表中不同結構複雜度層級中模型行為的差異。在這項工作中，我們提出了一個方法論管道，用於調查模型在對話特定結構屬性上的效能。作為概念驗證，我們專注於回應選擇和受話者辨識任務，以診斷模型的弱點。為此，我們從大型開放的線上 MPC 語料庫中，萃取具有固定使用者數量和良好結構變化的具代表性的診斷子資料集。我們進一步根據資料最小化的概念架構我們的工作，避免使用原始使用者名稱以保護隱私，並提出使用原始簡訊的替代方案。結果顯示，回應選擇更依賴對話的文字內容，而受話者辨識則需要擷取其結構維度。在零次學習設定中使用 LLM，我們進一步強調提示變化的敏感度是依任務而定的。

##### **TemporalPaD: a reinforcement-learning framework for temporal feature representation and dimension reduction**
2409.18597v1 by Xuechen Mu, Zhenyu Huang, Kewei Li, Haotian Zhang, Xiuli Wang, Yusi Fan, Kai Zhang, Fengfeng Zhou

Recent advancements in feature representation and dimension reduction have
highlighted their crucial role in enhancing the efficacy of predictive
modeling. This work introduces TemporalPaD, a novel end-to-end deep learning
framework designed for temporal pattern datasets. TemporalPaD integrates
reinforcement learning (RL) with neural networks to achieve concurrent feature
representation and feature reduction. The framework consists of three
cooperative modules: a Policy Module, a Representation Module, and a
Classification Module, structured based on the Actor-Critic (AC) framework. The
Policy Module, responsible for dimensionality reduction through RL, functions
as the actor, while the Representation Module for feature extraction and the
Classification Module collectively serve as the critic. We comprehensively
evaluate TemporalPaD using 29 UCI datasets, a well-known benchmark for
validating feature reduction algorithms, through 10 independent tests and
10-fold cross-validation. Additionally, given that TemporalPaD is specifically
designed for time series data, we apply it to a real-world DNA classification
problem involving enhancer category and enhancer strength. The results
demonstrate that TemporalPaD is an efficient and effective framework for
achieving feature reduction, applicable to both structured data and sequence
datasets. The source code of the proposed TemporalPaD is freely available as
supplementary material to this article and at
http://www.healthinformaticslab.org/supp/.

摘要：近期的特徵表徵與降維進展，突顯了它們在提升預測模型效能中的關鍵角色。本研究提出 TemporalPaD，一種新穎的端對端深度學習架構，專為時序模式資料集而設計。TemporalPaD 將強化學習 (RL) 與神經網路整合，以同時達成特徵表徵與特徵縮減。此架構包含三個協作模組：策略模組、表徵模組和分類模組，其結構基於 Actor-Critic (AC) 架構。策略模組負責透過 RL 進行維度縮減，扮演 actor 的角色，而表徵模組負責特徵萃取，分類模組則共同扮演 critic 的角色。我們使用 29 個 UCI 資料集全面評估 TemporalPaD，這些資料集是驗證特徵縮減演算法的知名基準，並透過 10 次獨立測試和 10 倍交叉驗證進行評估。此外，考量到 TemporalPaD 是專門為時間序列資料設計，我們將其應用於一個真實世界的 DNA 分類問題，涉及啟動子類別和啟動子強度。結果證明，TemporalPaD 是一個有效率且有效的架構，可達成特徵縮減，適用於結構化資料和序列資料集。所提出的 TemporalPaD 的原始碼作為本文的補充資料免費提供，網址為 http://www.healthinformaticslab.org/supp/。

##### **ASAG2024: A Combined Benchmark for Short Answer Grading**
2409.18596v1 by Gérôme Meyer, Philip Breuer, Jonathan Fürst

Open-ended questions test a more thorough understanding than closed-ended
questions and are often a preferred assessment method. However, open-ended
questions are tedious to grade and subject to personal bias. Therefore, there
have been efforts to speed up the grading process through automation. Short
Answer Grading (SAG) systems aim to automatically score students' answers.
Despite growth in SAG methods and capabilities, there exists no comprehensive
short-answer grading benchmark across different subjects, grading scales, and
distributions. Thus, it is hard to assess the capabilities of current automated
grading methods in terms of their generalizability. In this preliminary work,
we introduce the combined ASAG2024 benchmark to facilitate the comparison of
automated grading systems. Combining seven commonly used short-answer grading
datasets in a common structure and grading scale. For our benchmark, we
evaluate a set of recent SAG methods, revealing that while LLM-based approaches
reach new high scores, they still are far from reaching human performance. This
opens up avenues for future research on human-machine SAG systems.

摘要：開放式問題比封閉式問題更能測試透徹的理解力，而且通常是首選的評量方法。然而，開放式問題的評分很繁瑣，而且容易受到個人偏見的影響。因此，人們一直努力透過自動化來加速評分流程。簡答評分 (SAG) 系統旨在自動評分學生的答案。儘管 SAG 方法和功能不斷發展，但並不存在跨不同科目、評分量表和分配的綜合性簡答評分基準。因此，很難評估當前自動化評分方法在通用性方面的功能。在這項初步工作中，我們引入了結合 ASAG2024 基準，以利於比較自動化評分系統。將七個常用的簡答評分資料集結合在一個通用的結構和評分量表中。對於我們的基準，我們評估了一組最近的 SAG 方法，結果顯示，雖然基於 LLM 的方法達到了新的高分，但它們仍然遠遠達不到人類的表現。這為未來關於人機 SAG 系統的研究開啟了道路。

##### **"Oh LLM, I'm Asking Thee, Please Give Me a Decision Tree": Zero-Shot Decision Tree Induction and Embedding with Large Language Models**
2409.18594v1 by Ricardo Knauer, Mario Koddenbrock, Raphael Wallsberger, Nicholas M. Brisson, Georg N. Duda, Deborah Falla, David W. Evans, Erik Rodner

Large language models (LLMs) provide powerful means to leverage prior
knowledge for predictive modeling when data is limited. In this work, we
demonstrate how LLMs can use their compressed world knowledge to generate
intrinsically interpretable machine learning models, i.e., decision trees,
without any training data. We find that these zero-shot decision trees can
surpass data-driven trees on some small-sized tabular datasets and that
embeddings derived from these trees perform on par with data-driven tree-based
embeddings on average. Our knowledge-driven decision tree induction and
embedding approaches therefore serve as strong new baselines for data-driven
machine learning methods in the low-data regime.

摘要：大型語言模型 (LLM) 提供了強大的手段，可以在數據有限時利用先驗知識進行預測建模。在這項工作中，我們展示了 LLM 如何使用其壓縮的世界知識來生成內在可解釋的機器學習模型，即決策樹，而無需任何訓練數據。我們發現，這些零次學習決策樹可以在一些小型表格數據集上超越數據驅動樹，並且從這些樹中派生的嵌入式平均執行與數據驅動的基於樹的嵌入式相同。因此，我們的知識驅動決策樹歸納和嵌入式方法在低數據模式下為數據驅動的機器學習方法提供了強大的新基準。

##### **Analysis of Truncated Singular Value Decomposition for Koopman Operator-Based Lane Change Model**
2409.18586v1 by Chinnawut Nantabut

Understanding and modeling complex dynamic systems is crucial for enhancing
vehicle performance and safety, especially in the context of autonomous
driving. Recently, popular methods such as Koopman operators and their
approximators, known as Extended Dynamic Mode Decomposition (EDMD), have
emerged for their effectiveness in transforming strongly nonlinear system
behavior into linear representations. This allows them to be integrated with
conventional linear controllers. To achieve this, Singular Value Decomposition
(SVD), specifically truncated SVD, is employed to approximate Koopman operators
from extensive datasets efficiently. This study evaluates different basis
functions used in EDMD and ranks for truncated SVD for representing lane change
behavior models, aiming to balance computational efficiency with information
loss. The findings, however, suggest that the technique of truncated SVD does
not necessarily achieve substantial reductions in computational training time
and results in significant information loss.

摘要：了解和建模复杂的动态系统对于提升车辆性能和安全性至关重要，尤其是在自动驾驶的背景下。最近，一些流行的方法（如 Koopman 算子和它们的近似值，称为扩展动态模式分解 (EDMD)）因其将强非线性系统行为转化为线性表示而产生的有效性而备受关注。这使得它们能够与传统的线性控制器集成。为了实现这一点，采用了奇异值分解 (SVD)，特别是截断 SVD，以有效地从海量数据集近似 Koopman 算子。本研究评估了 EDMD 中使用的不同基函数，并对截断 SVD 对表示车道变换行为模型进行了排名，旨在平衡计算效率和信息损失。然而，研究结果表明，截断 SVD 技术不一定能够大幅减少计算训练时间，而且会导致大量信息丢失。

##### **Hit the Sweet Spot! Span-Level Ensemble for Large Language Models**
2409.18583v1 by Yangyifan Xu, Jianghao Chen, Junhong Wu, Jiajun Zhang

Ensembling various LLMs to unlock their complementary potential and leverage
their individual strengths is highly valuable. Previous studies typically focus
on two main paradigms: sample-level and token-level ensembles. Sample-level
ensemble methods either select or blend fully generated outputs, which hinders
dynamic correction and enhancement of outputs during the generation process. On
the other hand, token-level ensemble methods enable real-time correction
through fine-grained ensemble at each generation step. However, the information
carried by an individual token is quite limited, leading to suboptimal
decisions at each step. To address these issues, we propose SweetSpan, a
span-level ensemble method that effectively balances the need for real-time
adjustments and the information required for accurate ensemble decisions. Our
approach involves two key steps: First, we have each candidate model
independently generate candidate spans based on the shared prefix. Second, we
calculate perplexity scores to facilitate mutual evaluation among the candidate
models and achieve robust span selection by filtering out unfaithful scores. To
comprehensively evaluate ensemble methods, we propose a new challenging setting
(ensemble models with significant performance gaps) in addition to the standard
setting (ensemble the best-performing models) to assess the performance of
model ensembles in more realistic scenarios. Experimental results in both
standard and challenging settings across various language generation tasks
demonstrate the effectiveness, robustness, and versatility of our approach
compared with previous ensemble methods.

摘要：將各種 LLM 整合在一起以發揮其互補的潛力和利用其個別優勢非常有價值。先前的研究通常集中於兩個主要範例：範例級別和符號級別的整合。範例級別的整合方法會選擇或混合完全生成的輸出，這會阻礙生成過程中輸出的動態校正和增強。另一方面，符號級別的整合方法能夠在每一個生成步驟中透過細緻的整合進行即時校正。然而，個別符號所承載的資訊相當有限，導致每個步驟的決策次佳。為了解決這些問題，我們提出了 SweetSpan，這是一種跨距級別的整合方法，能有效平衡即時調整的需求和準確整合決策所需的資訊。我們的做法包含兩個關鍵步驟：首先，我們讓每個候選模型根據共享的前綴獨立生成候選跨距。其次，我們計算困惑度分數以促進候選模型之間的相互評估，並透過過濾掉不忠實的分數來達成穩健的跨距選擇。為了全面評估整合方法，除了標準設定（整合效能最佳的模型）之外，我們還提出了新的挑戰性設定（效能差距顯著的整合模型），以在更貼近現實的情況下評估模型整合的效能。在各種語言生成任務中，標準和挑戰性設定的實驗結果都證明了我們的方法與先前的整合方法相比，具有有效性、穩健性和多功能性。

##### **An Enhanced Federated Prototype Learning Method under Domain Shift**
2409.18578v1 by Liang Kuang, Kuangpu Guo, Jian Liang, Jianguo Zhang

Federated Learning (FL) allows collaborative machine learning training
without sharing private data. Numerous studies have shown that one significant
factor affecting the performance of federated learning models is the
heterogeneity of data across different clients, especially when the data is
sampled from various domains. A recent paper introduces variance-aware
dual-level prototype clustering and uses a novel $\alpha$-sparsity prototype
loss, which increases intra-class similarity and reduces inter-class
similarity. To ensure that the features converge within specific clusters, we
introduce an improved algorithm, Federated Prototype Learning with Convergent
Clusters, abbreviated as FedPLCC. To increase inter-class distances, we weight
each prototype with the size of the cluster it represents. To reduce
intra-class distances, considering that prototypes with larger distances might
come from different domains, we select only a certain proportion of prototypes
for the loss function calculation. Evaluations on the Digit-5, Office-10, and
DomainNet datasets show that our method performs better than existing
approaches.

摘要：联邦学习（FL）允许协作机器学习训练，而无需共享私有数据。大量研究表明，影响联邦学习模型性能的一个重要因素是不同客户端之间数据的异质性，尤其是在数据从各个域中采样时。最近的一篇论文介绍了方差感知双层原型聚类，并使用了一种新颖的 $\alpha$-稀疏原型损失，它增加了类内相似性并减少了类间相似性。为了确保特征在特定群集中收敛，我们引入了一种改进的算法，即收敛群集的联邦原型学习，缩写为 FedPLCC。为了增加类间距离，我们根据每个原型所代表的群集大小对其进行加权。为了减少类内距离，考虑到距离较大的原型可能来自不同的域，我们仅选择一定比例的原型用于损失函数计算。在 Digit-5、Office-10 和 DomainNet 数据集上的评估表明，我们的方法比现有方法表现得更好。

##### **Experimental Evaluation of Machine Learning Models for Goal-oriented Customer Service Chatbot with Pipeline Architecture**
2409.18568v1 by Nurul Ain Nabilah Mohd Isa, Siti Nuraishah Agos Jawaddi, Azlan Ismail

Integrating machine learning (ML) into customer service chatbots enhances
their ability to understand and respond to user queries, ultimately improving
service performance. However, they may appear artificial to some users and
affecting customer experience. Hence, meticulous evaluation of ML models for
each pipeline component is crucial for optimizing performance, though
differences in functionalities can lead to unfair comparisons. In this paper,
we present a tailored experimental evaluation approach for goal-oriented
customer service chatbots with pipeline architecture, focusing on three key
components: Natural Language Understanding (NLU), dialogue management (DM), and
Natural Language Generation (NLG). Our methodology emphasizes individual
assessment to determine optimal ML models. Specifically, we focus on optimizing
hyperparameters and evaluating candidate models for NLU (utilizing BERT and
LSTM), DM (employing DQN and DDQN), and NLG (leveraging GPT-2 and DialoGPT).
The results show that for the NLU component, BERT excelled in intent detection
whereas LSTM was superior for slot filling. For the DM component, the DDQN
model outperformed DQN by achieving fewer turns, higher rewards, as well as
greater success rates. For NLG, the large language model GPT-2 surpassed
DialoGPT in BLEU, METEOR, and ROUGE metrics. These findings aim to provide a
benchmark for future research in developing and optimizing customer service
chatbots, offering valuable insights into model performance and optimal
hyperparameters.

摘要：<paragraph>將機器學習 (ML) 整合到客服聊天機器人中，可增強其理解和回應使用者查詢的能力，進而提升服務效能。然而，它們在某些使用者眼中可能會顯得生硬，並影響客戶體驗。因此，仔細評估每個管道元件的 ML 模型對於最佳化效能至關重要，儘管功能上的差異可能會導致不公平的比較。在本文中，我們提出針對目標導向客服聊天機器人量身打造的實驗評估方法，著重於管道架構中的三個關鍵元件：自然語言理解 (NLU)、對話管理 (DM) 和自然語言生成 (NLG)。我們的評估方法強調個別評估，以找出最佳的 ML 模型。具體來說，我們專注於最佳化超參數，並評估 NLU (使用 BERT 和 LSTM)、DM (使用 DQN 和 DDQN) 和 NLG (使用 GPT-2 和 DialoGPT) 的候選模型。結果顯示，對於 NLU 元件，BERT 在意圖偵測方面表現出色，而 LSTM 則在槽位填補方面表現優異。對於 DM 元件，DDQN 模型的表現優於 DQN，能以更少的回合、更高的獎勵以及更高的成功率達成目標。對於 NLG，大型語言模型 GPT-2 在 BLEU、METEOR 和 ROUGE 指標方面都超越了 DialoGPT。這些發現旨在為未來開發和最佳化客服聊天機器人的研究提供基準，並提供關於模型效能和最佳超參數的寶貴見解。</paragraph>

##### **Efficient Noise Mitigation for Enhancing Inference Accuracy in DNNs on Mixed-Signal Accelerators**
2409.18553v1 by Seyedarmin Azizi, Mohammad Erfan Sadeghi, Mehdi Kamal, Massoud Pedram

In this paper, we propose a framework to enhance the robustness of the neural
models by mitigating the effects of process-induced and aging-related
variations of analog computing components on the accuracy of the analog neural
networks. We model these variations as the noise affecting the precision of the
activations and introduce a denoising block inserted between selected layers of
a pre-trained model. We demonstrate that training the denoising block
significantly increases the model's robustness against various noise levels. To
minimize the overhead associated with adding these blocks, we present an
exploration algorithm to identify optimal insertion points for the denoising
blocks. Additionally, we propose a specialized architecture to efficiently
execute the denoising blocks, which can be integrated into mixed-signal
accelerators. We evaluate the effectiveness of our approach using Deep Neural
Network (DNN) models trained on the ImageNet and CIFAR-10 datasets. The results
show that on average, by accepting 2.03% parameter count overhead, the accuracy
drop due to the variations reduces from 31.7% to 1.15%.

摘要：在本文中，我們提出了一個架構，透過減輕類比運算元件的製程引發和老化相關的變化對類比神經網路精確度的影響，來提升神經模型的穩健性。我們將這些變化建模為影響激活精度的雜訊，並在預先訓練模型的選定層之間插入一個去雜訊區塊。我們證明訓練去雜訊區塊可以顯著提升模型對各種雜訊層級的穩健性。為了將加入這些區塊相關的開銷降到最低，我們提出了一個探索演算法來找出去雜訊區塊的最佳插入點。此外，我們提出一個專門的架構來有效執行去雜訊區塊，可以整合到混合訊號加速器中。我們使用在 ImageNet 和 CIFAR-10 資料集上訓練的深度神經網路 (DNN) 模型來評估我們方法的有效性。結果顯示，平均而言，透過接受 2.03% 的參數數量開銷，由於變異造成的準確度下降從 31.7% 降低到 1.15%。

##### **Research on Predicting Public Opinion Event Heat Levels Based on Large Language Models**
2409.18548v1 by Yi Ren, Tianyi Zhang, Weibin Li, DuoMu Zhou, Chenhao Qin, FangCheng Dong

In recent years, with the rapid development of large language models, serval
models such as GPT-4o have demonstrated extraordinary capabilities, surpassing
human performance in various language tasks. As a result, many researchers have
begun exploring their potential applications in the field of public opinion
analysis. This study proposes a novel large-language-models-based method for
public opinion event heat level prediction. First, we preprocessed and
classified 62,836 Chinese hot event data collected between July 2022 and
December 2023. Then, based on each event's online dissemination heat index, we
used the MiniBatchKMeans algorithm to automatically cluster the events and
categorize them into four heat levels (ranging from low heat to very high
heat). Next, we randomly selected 250 events from each heat level, totalling
1,000 events, to build the evaluation dataset. During the evaluation process,
we employed various large language models to assess their accuracy in
predicting event heat levels in two scenarios: without reference cases and with
similar case references. The results showed that GPT-4o and DeepseekV2
performed the best in the latter case, achieving prediction accuracies of 41.4%
and 41.5%, respectively. Although the overall prediction accuracy remains
relatively low, it is worth noting that for low-heat (Level 1) events, the
prediction accuracies of these two models reached 73.6% and 70.4%,
respectively. Additionally, the prediction accuracy showed a downward trend
from Level 1 to Level 4, which correlates with the uneven distribution of data
across the heat levels in the actual dataset. This suggests that with the more
robust dataset, public opinion event heat level prediction based on large
language models will have significant research potential for the future.

摘要：<paragraph>近年來，隨著大型語言模型的快速發展，GPT-4o 等模型在各項語言任務中展現出超越人類表現的驚人能力。因此，許多研究者開始探討其在輿情分析領域的應用潛力。本研究提出一個基於大型語言模型的輿情事件熱度預測新方法。首先，我們對 2022 年 7 月至 2023 年 12 月間蒐集到的 62,836 則中文熱門事件資料進行預處理與分類。接著，根據各事件網路傳播熱度指標，利用 MiniBatchKMeans 演算法自動將事件進行分群，並將其歸類為四個熱度等級（從低熱度到極高熱度）。接下來，我們從各熱度等級中隨機選取 250 則事件，共計 1,000 則事件，建立評估資料集。在評估過程中，我們採用各種大型語言模型，在兩種情境下評估其預測事件熱度等級的準確度：無參考案例與有類似案例參考。結果顯示，在後者的情境中，GPT-4o 與 DeepseekV2 的表現最佳，分別達到 41.4% 與 41.5% 的預測準確度。儘管整體預測準確度仍相對較低，但值得注意的是，對於低熱度（等級 1）的事件，這兩個模型的預測準確度分別達到 73.6% 與 70.4%。此外，預測準確度從等級 1 到等級 4 呈現遞減的趨勢，這與實際資料集中各熱度等級資料分佈不均有關。這表示，隨著資料集的更為完備，基於大型語言模型的輿情事件熱度預測將具有顯著的研究潛力。</paragraph>

##### **An Epistemic Human-Aware Task Planner which Anticipates Human Beliefs and Decisions**
2409.18545v1 by Shashank Shekhar, Anthony Favier, Rachid Alami

We present a substantial extension of our Human-Aware Task Planning
framework, tailored for scenarios with intermittent shared execution
experiences and significant belief divergence between humans and robots,
particularly due to the uncontrollable nature of humans. Our objective is to
build a robot policy that accounts for uncontrollable human behaviors, thus
enabling the anticipation of possible advancements achieved by the robot when
the execution is not shared, e.g. when humans are briefly absent from the
shared environment to complete a subtask. But, this anticipation is considered
from the perspective of humans who have access to an estimated model for the
robot. To this end, we propose a novel planning framework and build a solver
based on AND-OR search, which integrates knowledge reasoning, including
situation assessment by perspective taking. Our approach dynamically models and
manages the expansion and contraction of potential advances while precisely
keeping track of when (and when not) agents share the task execution
experience. The planner systematically assesses the situation and ignores
worlds that it has reason to think are impossible for humans. Overall, our new
solver can estimate the distinct beliefs of the human and the robot along
potential courses of action, enabling the synthesis of plans where the robot
selects the right moment for communication, i.e. informing, or replying to an
inquiry, or defers ontic actions until the execution experiences can be shared.
Preliminary experiments in two domains, one novel and one adapted, demonstrate
the effectiveness of the framework.

摘要：我們提出了人類感知任務規劃框架的實質性擴展，專門針對間歇性共享執行體驗和人類與機器人之間的重大信念差異的情境，特別是因為人類的不可控本質。我們的目標是建立一種機器人策略，該策略考慮不可控的人類行為，從而能夠預測機器人在執行不被共享時取得的可能進展，例如，當人類短暫離開共享環境以完成子任務時。但是，這種預期是從有權訪問機器人估計模型的人類的角度考慮的。為此，我們提出了一個新穎的規劃框架，並基於 AND-OR 搜索構建了一個求解器，該求解器整合了知識推理，包括通過觀點採取情況評估。我們的做法動態建模和管理潛在進展的擴展和收縮，同時精確地跟踪代理何時（和何時不）共享任務執行體驗。規劃器系統地評估情況，並忽略它有理由認為對人類來說是不可能的。總的來說，我們的新求解器可以估計人類和機器人在潛在行動過程中的不同信念，從而能夠綜合機器人選擇正確溝通時機的計劃，即告知或答复查詢，或推遲本体動作，直到可以共享執行體驗。在兩個領域（一個新領域和一個適應領域）中的初步實驗證明了該框架的有效性。

##### **MIMII-Gen: Generative Modeling Approach for Simulated Evaluation of Anomalous Sound Detection System**
2409.18542v1 by Harsh Purohit, Tomoya Nishida, Kota Dohi, Takashi Endo, Yohei Kawaguchi

Insufficient recordings and the scarcity of anomalies present significant
challenges in developing and validating robust anomaly detection systems for
machine sounds. To address these limitations, we propose a novel approach for
generating diverse anomalies in machine sound using a latent diffusion-based
model that integrates an encoder-decoder framework. Our method utilizes the
Flan-T5 model to encode captions derived from audio file metadata, enabling
conditional generation through a carefully designed U-Net architecture. This
approach aids our model in generating audio signals within the EnCodec latent
space, ensuring high contextual relevance and quality. We objectively evaluated
the quality of our generated sounds using the Fr\'echet Audio Distance (FAD)
score and other metrics, demonstrating that our approach surpasses existing
models in generating reliable machine audio that closely resembles actual
abnormal conditions. The evaluation of the anomaly detection system using our
generated data revealed a strong correlation, with the area under the curve
(AUC) score differing by 4.8\% from the original, validating the effectiveness
of our generated data. These results demonstrate the potential of our approach
to enhance the evaluation and robustness of anomaly detection systems across
varied and previously unseen conditions. Audio samples can be found at
\url{https://hpworkhub.github.io/MIMII-Gen.github.io/}.

摘要：由於錄音不足且異常情況稀少，對於機器聲音的異常偵測系統開發與驗證造成重大挑戰。為了解決這些限制，我們提出一個創新的方法，使用整合編碼器-解碼器架構的潛在擴散模型，為機器聲音產生多樣化的異常情況。我們的模型使用 Flan-T5 模型編碼從音訊檔元資料衍生的字幕，並透過精心設計的 U-Net 架構進行條件式產生。此方法協助我們的模型在 EnCodec 潛在空間中產生音訊訊號，確保高度的脈絡相關性和品質。我們使用 Fr\'echet 音訊距離 (FAD) 分數和其他指標客觀評估產生聲音的品質，證明我們的模型在產生可靠的機器音訊方面優於現有模型，這些音訊與實際異常情況非常相似。使用我們產生的資料評估異常偵測系統時，發現它們有很強的關聯性，曲線下面積 (AUC) 分數與原始分數相差 4.8%，驗證了我們產生資料的有效性。這些結果證明了我們的方法有潛力提升異常偵測系統在各種前所未見情況下的評估和穩健性。音訊範例可以在 \url{https://hpworkhub.github.io/MIMII-Gen.github.io/} 找到。

##### **Align$^2$LLaVA: Cascaded Human and Large Language Model Preference Alignment for Multi-modal Instruction Curation**
2409.18541v1 by Hongzhe Huang, Zhewen Yu, Jiang Liu, Li Cai, Dian Jiao, Wenqiao Zhang, Siliang Tang, Juncheng Li, Hao Jiang, Haoyuan Li, Yueting Zhuang

Recent advances in Multi-modal Large Language Models (MLLMs), such as
LLaVA-series models, are driven by massive machine-generated
instruction-following data tuning. Such automatic instruction collection
pipelines, however, inadvertently introduce significant variability in data
quality. This paper introduces a novel instruction curation algorithm, derived
from two unique perspectives, human and LLM preference alignment, to compress
this vast corpus of machine-generated multimodal instructions to a compact and
high-quality form: (i) For human preference alignment, we have collected a
machine-generated multimodal instruction dataset and established a
comprehensive set of both subjective and objective criteria to guide the data
quality assessment critically from human experts. By doing so, a reward model
was trained on the annotated dataset to internalize the nuanced human
understanding of instruction alignment. (ii) For LLM preference alignment,
given the instruction selected by the reward model, we propose leveraging the
inner LLM used in MLLM to align the writing style of visual instructions with
that of the inner LLM itself, resulting in LLM-aligned instruction improvement.
Extensive experiments demonstrate that we can maintain or even improve model
performance by compressing synthetic multimodal instructions by up to 90%.
Impressively, by aggressively reducing the total training sample size from 158k
to 14k (9$\times$ smaller), our model consistently outperforms its full-size
dataset counterpart across various MLLM benchmarks. Our project is available at
https://github.com/DCDmllm/Align2LLaVA.

摘要：多模态大型语言模型 (MLLM) 的最新进展（例如 LLaVA 系列模型）由大量机器生成的指令遵循数据调优推动。然而，此类自动指令收集管道在数据质量中无意中引入了显著的可变性。本文介绍了一种新颖的指令整理算法，该算法源自人类和 LLM 偏好对齐的两个独特视角，以将大量机器生成的模态指令压缩成紧凑且高质量的形式：(i) 对于人类偏好对齐，我们收集了一个机器生成的模态指令数据集，并建立了一套全面的主观和客观标准，以指导数据质量评估，并严格地从人类专家那里获得。通过这样做，在带注释的数据集上训练了一个奖励模型，以将细微的人类指令对齐理解内化。(ii) 对于 LLM 偏好对齐，鉴于奖励模型选择的指令，我们建议利用 MLLM 中使用的内部 LLM 将视觉指令的写作风格与内部 LLM 本身对齐，从而实现 LLM 对齐的指令改进。广泛的实验表明，我们可以通过将合成模态指令压缩多达 90% 来维持甚至提高模型性能。令人印象深刻的是，通过将总训练样本量从 158k 积极减少到 14k（小 9 倍），我们的模型在各种 MLLM 基准测试中始终优于其全尺寸数据集对应模型。我们的项目可在 https://github.com/DCDmllm/Align2LLaVA 获得。

##### **A Survey on Complex Tasks for Goal-Directed Interactive Agents**
2409.18538v1 by Mareike Hartmann, Alexander Koller

Goal-directed interactive agents, which autonomously complete tasks through
interactions with their environment, can assist humans in various domains of
their daily lives. Recent advances in large language models (LLMs) led to a
surge of new, more and more challenging tasks to evaluate such agents. To
properly contextualize performance across these tasks, it is imperative to
understand the different challenges they pose to agents. To this end, this
survey compiles relevant tasks and environments for evaluating goal-directed
interactive agents, structuring them along dimensions relevant for
understanding current obstacles. An up-to-date compilation of relevant
resources can be found on our project website:
https://coli-saar.github.io/interactive-agents.

摘要：目標導向互動代理，透過與其環境互動以自主完成任務，可以在人類日常生活中的各種領域提供協助。大型語言模型 (LLM) 的最新進展促使出現大量新穎且更具挑戰性的任務，以評估此類代理。為了適當地將效能脈絡化到這些任務中，務必要了解這些任務對代理構成的不同挑戰。為此，本調查彙編了相關任務和環境，以評估目標導向互動代理，並沿著與了解當前障礙相關的向度對其進行結構化。可以在我們的專案網站上找到相關資源的最新彙編：
https://coli-saar.github.io/interactive-agents。

##### **EmoPro: A Prompt Selection Strategy for Emotional Expression in LM-based Speech Synthesis**
2409.18512v1 by Haoyu Wang, Chunyu Qiang, Tianrui Wang, Cheng Gong, Qiuyu Liu, Yu Jiang, Xiaobao Wang, Chenyang Wang, Chen Zhang

Recent advancements in speech synthesis models, trained on extensive
datasets, have demonstrated remarkable zero-shot capabilities. These models can
control content, timbre, and emotion in generated speech based on prompt
inputs. Despite these advancements, the choice of prompts significantly impacts
the output quality, yet most existing selection schemes do not adequately
address the control of emotional intensity. To address this question, this
paper proposes a two-stage prompt selection strategy EmoPro, which is
specifically designed for emotionally controllable speech synthesis. This
strategy focuses on selecting highly expressive and high-quality prompts by
evaluating them from four perspectives: emotional expression strength, speech
quality, text-emotion consistency, and model generation performance.
Experimental results show that prompts selected using the proposed method
result in more emotionally expressive and engaging synthesized speech compared
to those obtained through baseline. Audio samples and codes will be available
at https://whyrrrrun.github.io/EmoPro/.

摘要：最近在語音合成模型方面有了進展，這些模型經過大量資料集訓練，展現出非凡的零次學習能力。這些模型可以根據提示輸入，控制生成語音中的內容、音色和情緒。儘管有這些進展，但提示的選擇會顯著影響輸出品質，但現有的選擇方案大多無法充分控制情緒強度。為了解決這個問題，本文提出了一種兩階段提示選擇策略 EmoPro，該策略專門設計用於可控情緒的語音合成。此策略著重於從四個角度評估提示，選擇高度表達且品質高的提示：情緒表達強度、語音品質、文字情緒一致性和模型生成性能。實驗結果顯示，使用所提出的方法選擇的提示，與通過基準獲得的提示相比，能產生更具情緒表達力和吸引力的合成語音。音訊範例和程式碼將在 https://whyrrrrun.github.io/EmoPro/ 提供。

##### **Do We Need Domain-Specific Embedding Models? An Empirical Investigation**
2409.18511v1 by Yixuan Tang, Yi Yang

Embedding models play a crucial role in representing and retrieving
information across various NLP applications. Recent advancements in Large
Language Models (LLMs) have further enhanced the performance of embedding
models, which are trained on massive amounts of text covering almost every
domain. These models are often benchmarked on general-purpose datasets like
Massive Text Embedding Benchmark (MTEB), where they demonstrate superior
performance. However, a critical question arises: Is the development of
domain-specific embedding models necessary when general-purpose models are
trained on vast corpora that already include specialized domain texts? In this
paper, we empirically investigate this question, choosing the finance domain as
an example. We introduce the Finance Massive Text Embedding Benchmark
(FinMTEB), a counterpart to MTEB that consists of financial domain-specific
text datasets. We evaluate the performance of seven state-of-the-art embedding
models on FinMTEB and observe a significant performance drop compared to their
performance on MTEB. To account for the possibility that this drop is driven by
FinMTEB's higher complexity, we propose four measures to quantify dataset
complexity and control for this factor in our analysis. Our analysis provides
compelling evidence that state-of-the-art embedding models struggle to capture
domain-specific linguistic and semantic patterns, even when trained on large
general-purpose corpora. This study sheds light on the necessity of developing
domain-specific embedding models in the LLM era, offering valuable insights for
researchers and practitioners.

摘要：<paragraph>嵌入式模型在表示和擷取各種 NLP 應用程式中的資訊方面扮演著至關重要的角色。大型語言模型 (LLM) 的最新進展進一步增強了嵌入式模型的效能，這些模型經由涵蓋幾乎所有領域的大量文字訓練而成。這些模型通常會在通用資料集上進行基準測試，例如大規模文字嵌入基準 (MTEB)，它們在這些資料集上展現出優異的效能。然而，一個關鍵問題出現了：當通用模型已在包含專業領域文字的龐大語料庫上訓練時，開發特定領域的嵌入式模型是否必要？在本文中，我們以財務領域為例，對此問題進行實證研究。我們引入了財務大規模文字嵌入基準 (FinMTEB)，這是 MTEB 的對應版本，包含特定於財務領域的文字資料集。我們評估了七種最先進的嵌入式模型在 FinMTEB 上的效能，並觀察到與它們在 MTEB 上的效能相比，出現顯著的效能下降。為了說明這種下降可能是由 FinMTEB 較高的複雜度所驅動，我們提出了四項指標來量化資料集複雜度，並在我們的分析中控制此因素。我們的分析提供了令人信服的證據，證明最先進的嵌入式模型難以擷取特定領域的語言和語意模式，即使是在大型通用語料庫上訓練也是如此。這項研究闡明了在 LLM 時代開發特定領域嵌入式模型的必要性，為研究人員和實務工作者提供了寶貴的見解。</paragraph>

##### **Fairness-aware Multiobjective Evolutionary Learning**
2409.18499v1 by Qingquan Zhang, Jialin Liu, Xin Yao

Multiobjective evolutionary learning (MOEL) has demonstrated its advantages
of training fairer machine learning models considering a predefined set of
conflicting objectives, including accuracy and different fairness measures.
Recent works propose to construct a representative subset of fairness measures
as optimisation objectives of MOEL throughout model training. However, the
determination of a representative measure set relies on dataset, prior
knowledge and requires substantial computational costs. What's more, those
representative measures may differ across different model training processes.
Instead of using a static predefined set determined before model training, this
paper proposes to dynamically and adaptively determine a representative measure
set online during model training. The dynamically determined representative set
is then used as optimising objectives of the MOEL framework and can vary with
time. Extensive experimental results on 12 well-known benchmark datasets
demonstrate that our proposed framework achieves outstanding performance
compared to state-of-the-art approaches for mitigating unfairness in terms of
accuracy as well as 25 fairness measures although only a few of them were
dynamically selected and used as optimisation objectives. The results indicate
the importance of setting optimisation objectives dynamically during training.

摘要：多目標演化學習 (MOEL) 已證明其在訓練更公平的機器學習模型方面的優勢，考慮到一組預定義的衝突目標，包括準確性和不同的公平性衡量指標。最近的工作建議構建一個公平性衡量指標的代表性子集，作為整個模型訓練過程中 MOEL 的優化目標。然而，代表性衡量指標集的確定依賴於數據集、先驗知識，並且需要大量的計算成本。更重要的是，這些代表性衡量指標在不同的模型訓練過程中可能有所不同。本文不是使用在模型訓練前確定的靜態預定義集，而是提出在模型訓練期間動態且自適應地確定一個代表性衡量指標集。然後將動態確定的代表性集用作 MOEL 框架的優化目標，並且可以隨時間變化。在 12 個著名的基準數據集上進行的廣泛實驗結果表明，我們提出的框架在減輕不公平性方面取得了出色的性能，無論是在準確性還是 25 個公平性衡量指標方面，儘管其中只有少數幾個被動態選擇並用作優化目標。結果表明了在訓練期間動態設置優化目標的重要性。

##### **Evaluation of OpenAI o1: Opportunities and Challenges of AGI**
2409.18486v1 by Tianyang Zhong, Zhengliang Liu, Yi Pan, Yutong Zhang, Yifan Zhou, Shizhe Liang, Zihao Wu, Yanjun Lyu, Peng Shu, Xiaowei Yu, Chao Cao, Hanqi Jiang, Hanxu Chen, Yiwei Li, Junhao Chen, Huawen Hu, Yihen Liu, Huaqin Zhao, Shaochen Xu, Haixing Dai, Lin Zhao, Ruidong Zhang, Wei Zhao, Zhenyuan Yang, Jingyuan Chen, Peilong Wang, Wei Ruan, Hui Wang, Huan Zhao, Jing Zhang, Yiming Ren, Shihuan Qin, Tong Chen, Jiaxi Li, Arif Hassan Zidan, Afrar Jahin, Minheng Chen, Sichen Xia, Jason Holmes, Yan Zhuang, Jiaqi Wang, Bochen Xu, Weiran Xia, Jichao Yu, Kaibo Tang, Yaxuan Yang, Bolun Sun, Tao Yang, Guoyu Lu, Xianqiao Wang, Lilong Chai, He Li, Jin Lu, Lichao Sun, Xin Zhang, Bao Ge, Xintao Hu, Lian Zhang, Hua Zhou, Lu Zhang, Shu Zhang, Ninghao Liu, Bei Jiang, Linglong Kong, Zhen Xiang, Yudan Ren, Jun Liu, Xi Jiang, Yu Bao, Wei Zhang, Xiang Li, Gang Li, Wei Liu, Dinggang Shen, Andrea Sikora, Xiaoming Zhai, Dajiang Zhu, Tianming Liu

This comprehensive study evaluates the performance of OpenAI's o1-preview
large language model across a diverse array of complex reasoning tasks,
spanning multiple domains, including computer science, mathematics, natural
sciences, medicine, linguistics, and social sciences. Through rigorous testing,
o1-preview demonstrated remarkable capabilities, often achieving human-level or
superior performance in areas ranging from coding challenges to scientific
reasoning and from language processing to creative problem-solving. Key
findings include:
  -83.3% success rate in solving complex competitive programming problems,
surpassing many human experts.
  -Superior ability in generating coherent and accurate radiology reports,
outperforming other evaluated models.
  -100% accuracy in high school-level mathematical reasoning tasks, providing
detailed step-by-step solutions.
  -Advanced natural language inference capabilities across general and
specialized domains like medicine.
  -Impressive performance in chip design tasks, outperforming specialized
models in areas such as EDA script generation and bug analysis.
  -Remarkable proficiency in anthropology and geology, demonstrating deep
understanding and reasoning in these specialized fields.
  -Strong capabilities in quantitative investing. O1 has comprehensive
financial knowledge and statistical modeling skills.
  -Effective performance in social media analysis, including sentiment analysis
and emotion recognition.
  The model excelled particularly in tasks requiring intricate reasoning and
knowledge integration across various fields. While some limitations were
observed, including occasional errors on simpler problems and challenges with
certain highly specialized concepts, the overall results indicate significant
progress towards artificial general intelligence.

摘要：<paragraph>這項全面性的研究評估了 OpenAI 的 o1-preview 大型語言模型在各種複雜推理任務中的表現，涵蓋多個領域，包括電腦科學、數學、自然科學、醫學、語言學和社會科學。透過嚴謹的測試，o1-preview 展現了卓越的能力，在從編碼挑戰到科學推理，以及從語言處理到創意問題解決等領域，經常達到人類等級或更佳的表現。主要發現包括：
  -在解決複雜的競爭性編程問題上成功率為 83.3%，超越許多人類專家。
  -在產生連貫且準確的放射科報告方面具有優異的能力，表現優於其他評估模型。
  -在高中程度的數學推理任務中準確率為 100%，提供詳細的逐步解法。
  -在一般和專業領域（如醫學）中具備先進的自然語言推理能力。
  -在晶片設計任務中表現出色，在 EDA 腳本產生和錯誤分析等領域優於專業模型。
  -在人類學和地質學方面表現出色，展現了對這些專業領域的深入理解和推理能力。
  -在量化投資方面具有強大的能力。O1 具有全面的財務知識和統計建模技能。
  -在社群媒體分析中表現有效，包括情緒分析和情緒辨識。
  該模型特別擅長需要複雜推理和跨領域知識整合的任務。儘管觀察到一些限制，包括偶爾在較簡單的問題上出錯，以及在某些高度專業化的概念上遇到挑戰，但整體結果表明朝向人工通用智慧邁出了顯著的進展。</paragraph>

##### **Data Analysis in the Era of Generative AI**
2409.18475v1 by Jeevana Priya Inala, Chenglong Wang, Steven Drucker, Gonzalo Ramos, Victor Dibia, Nathalie Riche, Dave Brown, Dan Marshall, Jianfeng Gao

This paper explores the potential of AI-powered tools to reshape data
analysis, focusing on design considerations and challenges. We explore how the
emergence of large language and multimodal models offers new opportunities to
enhance various stages of data analysis workflow by translating high-level user
intentions into executable code, charts, and insights. We then examine
human-centered design principles that facilitate intuitive interactions, build
user trust, and streamline the AI-assisted analysis workflow across multiple
apps. Finally, we discuss the research challenges that impede the development
of these AI-based systems such as enhancing model capabilities, evaluating and
benchmarking, and understanding end-user needs.

摘要：本文探討 AI 驅動工具重塑資料分析的潛力，重點關注設計考量和挑戰。我們探討大型語言和多模態模型的出現，如何提供新的機會，透過將高階使用者意圖轉換為可執行程式碼、圖表和見解，來增強資料分析工作流程的各個階段。然後，我們檢視以人為中心的設計原則，這些原則促進直覺式互動、建立使用者信任，並簡化跨多個應用程式的 AI 輔助分析工作流程。最後，我們討論阻礙這些 AI 系統開發的研究挑戰，例如增強模型功能、評估和基準測試，以及了解最終使用者的需求。

##### **URIEL+: Enhancing Linguistic Inclusion and Usability in a Typological and Multilingual Knowledge Base**
2409.18472v1 by Aditya Khan, Mason Shipton, David Anugraha, Kaiyao Duan, Phuong H. Hoang, Eric Khiu, A. Seza Doğruöz, En-Shiun Annie Lee

URIEL is a knowledge base offering geographical, phylogenetic, and
typological vector representations for 7970 languages. It includes distance
measures between these vectors for 4005 languages, which are accessible via the
lang2vec tool. Despite being frequently cited, URIEL is limited in terms of
linguistic inclusion and overall usability. To tackle these challenges, we
introduce URIEL+, an enhanced version of URIEL and lang2vec addressing these
limitations. In addition to expanding typological feature coverage for 2898
languages, URIEL+ improves user experience with robust, customizable distance
calculations to better suit the needs of the users. These upgrades also offer
competitive performance on downstream tasks and provide distances that better
align with linguistic distance studies.

摘要：URIEL 是一個提供 7970 種語言的地理、系統發生和類型學向量表示的知識庫。它包含 4005 種語言之間的距離測量，可透過 lang2vec 工具存取。儘管經常被引用，但 URIEL 在語言包容性和整體可用性方面受到限制。為了應對這些挑戰，我們引入了 URIEL+，這是 URIEL 和 lang2vec 的增強版本，可解決這些限制。除了擴展 2898 種語言的類型學特徵涵蓋範圍外，URIEL+ 還透過強大、可自訂的距離計算來改善使用者體驗，以更好地滿足使用者的需求。這些升級在下游任務上也提供具競爭力的效能，並提供更符合語言距離研究的距離。

##### **Towards Diverse Device Heterogeneous Federated Learning via Task Arithmetic Knowledge Integration**
2409.18461v1 by Mahdi Morafah, Vyacheslav Kungurtsev, Hojin Chang, Chen Chen, Bill Lin

Federated Learning has emerged as a promising paradigm for collaborative
machine learning, while preserving user data privacy. Despite its potential,
standard FL lacks support for diverse heterogeneous device prototypes, which
vary significantly in model and dataset sizes -- from small IoT devices to
large workstations. This limitation is only partially addressed by existing
knowledge distillation techniques, which often fail to transfer knowledge
effectively across a broad spectrum of device prototypes with varied
capabilities. This failure primarily stems from two issues: the dilution of
informative logits from more capable devices by those from less capable ones,
and the use of a single integrated logits as the distillation target across all
devices, which neglects their individual learning capacities and and the unique
contributions of each. To address these challenges, we introduce TAKFL, a novel
KD-based framework that treats the knowledge transfer from each device
prototype's ensemble as a separate task, independently distilling each to
preserve its unique contributions and avoid dilution. TAKFL also incorporates a
KD-based self-regularization technique to mitigate the issues related to the
noisy and unsupervised ensemble distillation process. To integrate the
separately distilled knowledge, we introduce an adaptive task arithmetic
knowledge integration process, allowing each student model to customize the
knowledge integration for optimal performance. Additionally, we present
theoretical results demonstrating the effectiveness of task arithmetic in
transferring knowledge across heterogeneous devices with varying capacities.
Comprehensive evaluations of our method across both CV and NLP tasks
demonstrate that TAKFL achieves SOTA results in a variety of datasets and
settings, significantly outperforming existing KD-based methods. Code is
released at https://github.com/MMorafah/TAKFL

摘要：聯邦學習已成為一種有前途的協作式機器學習典範，同時還能保護使用者資料隱私。儘管有其潛力，標準 FL 卻缺乏對各種異質裝置原型（從小型 IoT 裝置到大型工作站，模型和資料集大小差異極大）的支援。這個限制僅由現有的知識萃取技術部分解決，這些技術通常無法有效地在功能不同的各種裝置原型間傳遞知識。這種失敗主要源於兩個問題：能力較強的裝置中具有資訊性的 logit 被能力較弱的裝置稀釋，以及使用單一整合 logit 作為所有裝置的萃取目標，這忽視了它們各自的學習能力和各自的獨特貢獻。為了應對這些挑戰，我們引入了 TAKFL，這是一種新穎的基於 KD 的架構，它將來自每個裝置原型合奏的知識傳遞視為一項單獨的任務，獨立萃取每個任務以保留其獨特貢獻並避免稀釋。TAKFL 還納入了基於 KD 的自我正規化技術，以減輕與嘈雜且無監督的合奏萃取過程相關的問題。為了整合單獨萃取的知識，我們引入了自適應任務算術知識整合過程，允許每個學生模型自訂知識整合以獲得最佳效能。此外，我們提出了理論結果，證明了任務算術在傳遞不同能力的異質裝置間知識的有效性。我們的方法在 CV 和 NLP 任務中的全面評估表明，TAKFL 在各種資料集和設定中達到了 SOTA 結果，顯著優於現有的基於 KD 的方法。程式碼已在 https://github.com/MMorafah/TAKFL 中釋出

##### **Review of Digital Asset Development with Graph Neural Network Unlearning**
2409.18455v1 by Zara Lisbon

In the rapidly evolving landscape of digital assets, the imperative for
robust data privacy and compliance with regulatory frameworks has intensified.
This paper investigates the critical role of Graph Neural Networks (GNNs) in
the management of digital assets and introduces innovative unlearning
techniques specifically tailored to GNN architectures. We categorize unlearning
strategies into two primary classes: data-driven approximation, which
manipulates the graph structure to isolate and remove the influence of specific
nodes, and model-driven approximation, which modifies the internal parameters
and architecture of the GNN itself. By examining recent advancements in these
unlearning methodologies, we highlight their applicability in various use
cases, including fraud detection, risk assessment, token relationship
prediction, and decentralized governance. We discuss the challenges inherent in
balancing model performance with the requirements for data unlearning,
particularly in the context of real-time financial applications. Furthermore,
we propose a hybrid approach that combines the strengths of both unlearning
strategies to enhance the efficiency and effectiveness of GNNs in digital asset
ecosystems. Ultimately, this paper aims to provide a comprehensive framework
for understanding and implementing GNN unlearning techniques, paving the way
for secure and compliant deployment of machine learning in the digital asset
domain.

摘要：在快速演變的數位資產領域中，對於強大的資料隱私和法規架構的遵循需求已經加劇。本文探討了圖神經網路 (GNN) 在數位資產管理中的關鍵角色，並介紹了專門針對 GNN 架構量身打造的創新遺忘技術。我們將遺忘策略分類為兩種類型：資料驅動近似，它操縱圖形結構以孤立並移除特定節點的影響，以及模型驅動近似，它修改 GNN 本身的內部參數和架構。透過檢視這些遺忘方法的最新進展，我們強調了它們在各種使用案例中的適用性，包括詐欺偵測、風險評估、代幣關係預測和分散式治理。我們討論了在平衡模型效能與資料遺忘需求時所固有的挑戰，特別是在即時金融應用程式的背景下。此外，我們提出了一種混合方法，它結合了兩種遺忘策略的優點，以增強 GNN 在數位資產生態系統中的效率和效能。最終，本文旨在提供一個全面的架構，以便理解和實作 GNN 遺忘技術，為在數位資產領域安全且合規地部署機器學習鋪路。

##### **Leveraging Long-Context Large Language Models for Multi-Document Understanding and Summarization in Enterprise Applications**
2409.18454v1 by Aditi Godbole, Jabin Geevarghese George, Smita Shandilya

The rapid increase in unstructured data across various fields has made
multi-document comprehension and summarization a critical task. Traditional
approaches often fail to capture relevant context, maintain logical
consistency, and extract essential information from lengthy documents. This
paper explores the use of Long-context Large Language Models (LLMs) for
multi-document summarization, demonstrating their exceptional capacity to grasp
extensive connections, provide cohesive summaries, and adapt to various
industry domains and integration with enterprise applications/systems. The
paper discusses the workflow of multi-document summarization for effectively
deploying long-context LLMs, supported by case studies in legal applications,
enterprise functions such as HR, finance, and sourcing, as well as in the
medical and news domains. These case studies show notable enhancements in both
efficiency and accuracy. Technical obstacles, such as dataset diversity, model
scalability, and ethical considerations like bias mitigation and factual
accuracy, are carefully analyzed. Prospective research avenues are suggested to
augment the functionalities and applications of long-context LLMs, establishing
them as pivotal tools for transforming information processing across diverse
sectors and enterprise applications.

摘要：隨著非結構化資料在各個領域快速增加，多文件理解和摘要已成為一項重要的任務。傳統方法通常無法擷取相關脈絡、維持邏輯一致性，以及從冗長的文件中萃取必要資訊。本文探討使用長脈絡大型語言模型 (LLM) 進行多文件摘要，展示其掌握廣泛關聯、提供有凝聚力的摘要，以及適應各種產業領域和整合企業應用程式/系統的非凡能力。本文探討多文件摘要的工作流程，以有效部署長脈絡 LLM，並以法律應用、企業功能（例如人力資源、財務和採購），以及醫療和新聞領域的案例研究作為佐證。這些案例研究顯示出效率和準確性都有顯著的提升。技術障礙，例如資料集多樣性、模型可擴充性，以及道德考量（例如減輕偏差和事實準確性）都經過仔細分析。本文建議未來的研究方向，以擴充長脈絡 LLM 的功能和應用，使其成為轉變不同產業和企業應用程式資訊處理方式的關鍵工具。

##### **Exploring Language Model Generalization in Low-Resource Extractive QA**
2409.18446v1 by Saptarshi Sengupta, Wenpeng Yin, Preslav Nakov, Shreya Ghosh, Suhang Wang

In this paper, we investigate Extractive Question Answering (EQA) with Large
Language Models (LLMs) under domain drift, i.e., can LLMs generalize well to
closed-domains that require specific knowledge such as medicine and law in a
zero-shot fashion without additional in-domain training? To this end, we devise
a series of experiments to empirically explain the performance gap. Our
findings suggest that: a) LLMs struggle with dataset demands of closed-domains
such as retrieving long answer-spans; b) Certain LLMs, despite showing strong
overall performance, display weaknesses in meeting basic requirements as
discriminating between domain-specific senses of words which we link to
pre-processing decisions; c) Scaling model parameters is not always effective
for cross-domain generalization; and d) Closed-domain datasets are
quantitatively much different than open-domain EQA datasets and current LLMs
struggle to deal with them. Our findings point out important directions for
improving existing LLMs.

摘要：在本文中，我們研究了在領域漂移下使用大型語言模型 (LLM) 的抽取式問答 (EQA)，也就是說，LLM 能否在不進行額外領域內訓練的情況下，以零次學習的方式很好地推廣到需要特定知識（例如醫學和法律）的封閉領域？為此，我們設計了一系列實驗來經驗性地解釋效能差距。我們的研究結果表明：a) LLM 難以應付封閉領域的資料集需求，例如擷取長答案範圍；b) 某些 LLM 儘管表現出強勁的整體效能，但在滿足基本需求方面表現出弱點，例如區分單字的領域特定含義，我們將其連結到前處理決策；c) 擴充模型參數並不總是對跨領域推廣有效；d) 封閉領域資料集在數量上與開放領域 EQA 資料集有很大不同，而目前的 LLM 難以應付它們。我們的研究結果指出了改善現有 LLM 的重要方向。

##### **Physics Augmented Tuple Transformer for Autism Severity Level Detection**
2409.18438v1 by Chinthaka Ranasingha, Harshala Gammulle, Tharindu Fernando, Sridha Sridharan, Clinton Fookes

Early diagnosis of Autism Spectrum Disorder (ASD) is an effective and
favorable step towards enhancing the health and well-being of children with
ASD. Manual ASD diagnosis testing is labor-intensive, complex, and prone to
human error due to several factors contaminating the results. This paper
proposes a novel framework that exploits the laws of physics for ASD severity
recognition. The proposed physics-informed neural network architecture encodes
the behaviour of the subject extracted by observing a part of the
skeleton-based motion trajectory in a higher dimensional latent space. Two
decoders, namely physics-based and non-physics-based decoder, use this latent
embedding and predict the future motion patterns. The physics branch leverages
the laws of physics that apply to a skeleton sequence in the prediction process
while the non-physics-based branch is optimised to minimise the difference
between the predicted and actual motion of the subject. A classifier also
leverages the same latent space embeddings to recognise the ASD severity. This
dual generative objective explicitly forces the network to compare the actual
behaviour of the subject with the general normal behaviour of children that are
governed by the laws of physics, aiding the ASD recognition task. The proposed
method attains state-of-the-art performance on multiple ASD diagnosis
benchmarks. To illustrate the utility of the proposed framework beyond the task
ASD diagnosis, we conduct a third experiment using a publicly available
benchmark for the task of fall prediction and demonstrate the superiority of
our model.

摘要：自閉症譜系障礙 (ASD) 的早期診斷是改善 ASD 兒童健康和福祉的有效且有利的一步。手動 ASD 診斷測試勞動密集、複雜，且容易因多種污染結果的因素而產生人為錯誤。本文提出了一個新穎的框架，利用物理定律來識別 ASD 的嚴重程度。所提出的物理訊息神經網路架構編碼了通過觀察基於骨架的運動軌跡的一部分在高維潛在空間中提取的主體行為。兩個解碼器，即基於物理和非基於物理的解碼器，使用此潛在嵌入並預測未來的運動模式。物理分支在預測過程中利用適用於骨架序列的物理定律，而非基於物理的分支則經過最佳化以最小化受試者預測和實際運動之間的差異。分類器也利用相同的潛在空間嵌入來識別 ASD 的嚴重程度。這種雙重生成目標明確地迫使網路將受試者的實際行為與受物理定律支配的兒童一般正常行為進行比較，從而有助於 ASD 識別任務。所提出的方法在多個 ASD 診斷基準上達到了最先進的效能。為了說明所提出的框架在 ASD 診斷任務之外的效用，我們使用公開可用的跌倒預測任務基準進行了第三個實驗，並展示了我們模型的優越性。

##### **Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization**
2409.18433v1 by Mucong Ding, Chenghao Deng, Jocelyn Choo, Zichu Wu, Aakriti Agrawal, Avi Schwarzschild, Tianyi Zhou, Tom Goldstein, John Langford, Anima Anandkumar, Furong Huang

While generalization over tasks from easy to hard is crucial to profile
language models (LLMs), the datasets with fine-grained difficulty annotations
for each problem across a broad range of complexity are still blank. Aiming to
address this limitation, we present Easy2Hard-Bench, a consistently formatted
collection of 6 benchmark datasets spanning various domains, such as
mathematics and programming problems, chess puzzles, and reasoning questions.
Each problem within these datasets is annotated with numerical difficulty
scores. To systematically estimate problem difficulties, we collect abundant
performance data on attempts to each problem by humans in the real world or
LLMs on the prominent leaderboard. Leveraging the rich performance data, we
apply well-established difficulty ranking systems, such as Item Response Theory
(IRT) and Glicko-2 models, to uniformly assign numerical difficulty scores to
problems. Moreover, datasets in Easy2Hard-Bench distinguish themselves from
previous collections by a higher proportion of challenging problems. Through
extensive experiments with six state-of-the-art LLMs, we provide a
comprehensive analysis of their performance and generalization capabilities
across varying levels of difficulty, with the aim of inspiring future research
in LLM generalization. The datasets are available at
https://huggingface.co/datasets/furonghuang-lab/Easy2Hard-Bench.

摘要：<paragraph>儘管從簡單到困難的任務概化對於描述語言模型 (LLM) 至關重要，但對於廣泛複雜性範圍中每個問題的細緻難度註解，資料集仍然是空白的。為了解決這個限制，我們提出了 Easy2Hard-Bench，這是一個格式一致的 6 個基準資料集集合，涵蓋各種領域，例如數學和程式設計問題、西洋棋謎題和推理問題。這些資料集中的每個問題都註有數值的難度分數。為了系統性地估計問題難度，我們收集了大量人類在現實世界中嘗試每個問題或 LLM 在顯著排行榜上的表現資料。利用豐富的表現資料，我們應用完善的難度排名系統，例如項目反應理論 (IRT) 和 Glicko-2 模型，以統一分配數值難度分數給問題。此外，Easy2Hard-Bench 中的資料集與之前的集合不同，具有較高比例的具挑戰性問題。透過與六個最先進的 LLM 進行廣泛的實驗，我們提供了對其在不同難度等級下的表現和概化能力的全面分析，目的是激勵未來在 LLM 概化方面的研究。資料集可在 https://huggingface.co/datasets/furonghuang-lab/Easy2Hard-Bench 取得。</paragraph>

##### **Improving Multilingual ASR in the Wild Using Simple N-best Re-ranking**
2409.18428v1 by Brian Yan, Vineel Pratap, Shinji Watanabe, Michael Auli

Multilingual Automatic Speech Recognition (ASR) models are typically
evaluated in a setting where the ground-truth language of the speech utterance
is known, however, this is often not the case for most practical settings.
Automatic Spoken Language Identification (SLID) models are not perfect and
misclassifications have a substantial impact on the final ASR accuracy. In this
paper, we present a simple and effective N-best re-ranking approach to improve
multilingual ASR accuracy for several prominent acoustic models by employing
external features such as language models and text-based language
identification models. Our results on FLEURS using the MMS and Whisper models
show spoken language identification accuracy improvements of 8.7% and 6.1%,
respectively and word error rates which are 3.3% and 2.0% lower on these
benchmarks.

摘要：多語言自動語音識別 (ASR) 模型通常在語音話語的真實語言已知的環境中進行評估，然而，這在多數實際環境中並非如此。自動口說語言辨識 (SLID) 模型並不完美，且錯誤分類會對最終的 ASR 準確度造成重大影響。在本文中，我們提出一個簡單且有效的方法，透過採用語言模型和基於文字的語言辨識模型等外部特徵，對多語言 ASR 準確度進行 N-best 重新排序，以提升準確度。我們在 FLEURS 上使用 MMS 和 Whisper 模型所獲得的結果顯示，口說語言辨識準確度分別提升了 8.7% 和 6.1%，而這些基準上的字元錯誤率則降低了 3.3% 和 2.0%。

##### **A3: Active Adversarial Alignment for Source-Free Domain Adaptation**
2409.18418v1 by Chrisantus Eze, Christopher Crick

Unsupervised domain adaptation (UDA) aims to transfer knowledge from a
labeled source domain to an unlabeled target domain. Recent works have focused
on source-free UDA, where only target data is available. This is challenging as
models rely on noisy pseudo-labels and struggle with distribution shifts. We
propose Active Adversarial Alignment (A3), a novel framework combining
self-supervised learning, adversarial training, and active learning for robust
source-free UDA. A3 actively samples informative and diverse data using an
acquisition function for training. It adapts models via adversarial losses and
consistency regularization, aligning distributions without source data access.
A3 advances source-free UDA through its synergistic integration of active and
adversarial learning for effective domain alignment and noise reduction.

摘要：無監督域適應 (UDA) 旨在將知識從標籤來源域傳輸到未標籤目標域。最近的研究集中在無來源 UDA，其中只有目標數據可用。這具有挑戰性，因為模型依賴於有雜訊的偽標籤，並與分佈轉移作鬥爭。我們提出主動對抗對齊 (A3)，這是一個結合自監督學習、對抗訓練和主動學習的新框架，用於強大的無來源 UDA。A3 使用採集函數主動採樣有資訊性和多樣化的數據以進行訓練。它通過對抗損失和一致性正則化調整模型，在沒有來源數據訪問的情況下對齊分佈。A3 通過主動和對抗學習的協同整合，推動無來源 UDA，實現有效的域對齊和降噪。

##### **VickreyFeedback: Cost-efficient Data Construction for Reinforcement Learning from Human Feedback**
2409.18417v1 by Guoxi Zhang, Jiuding Duan

This paper addresses the cost-efficiency aspect of Reinforcement Learning
from Human Feedback (RLHF). RLHF leverages datasets of human preferences over
outputs of large language models (LLM) to instill human expectations into LLMs.
While preference annotation comes with a monetized cost, the economic utility
of a preference dataset has not been considered by far. What exacerbates this
situation is that given complex intransitive or cyclic relationships in
preference datasets, existing algorithms for fine-tuning LLMs are still far
from capturing comprehensive preferences. This raises severe cost-efficiency
concerns in production environments, where preference data accumulate over
time. In this paper, we see the fine-tuning of LLMs as a monetized economy and
introduce an auction mechanism to improve the efficiency of the preference data
collection in dollar terms. We show that introducing an auction mechanism can
play an essential role in enhancing the cost-efficiency of RLHF while
maintaining satisfactory model performance. Experimental results demonstrate
that our proposed auction-based protocol is cost-efficient for fine-tuning LLMs
by concentrating on high-quality feedback.

摘要：本文探討了人類回饋強化學習 (RLHF) 的成本效益層面。RLHF 利用人類偏好大型語言模型 (LLM) 輸出的資料集，將人類期望灌輸到 LLM 中。儘管偏好標註會產生金錢成本，但到目前為止，尚未考慮偏好資料集的經濟效益。加劇這種情況的是，由於偏好資料集中存在複雜的不傳遞或循環關係，現有微調 LLM 的演算法仍遠遠無法捕捉全面的偏好。這在生產環境中引起了嚴重的成本效益問題，其中偏好資料會隨著時間累積。在本文中，我們將 LLM 的微調視為一個貨幣化經濟，並引入一個拍賣機制，以提高偏好資料收集的效率（以美元計價）。我們表明，引入拍賣機制可以在維持令人滿意的模型效能的同時，在提升 RLHF 的成本效益方面發揮重要作用。實驗結果表明，我們提出的基於拍賣的協定透過專注於高品質回饋，對於微調 LLM 具有成本效益。

##### **SciDFM: A Large Language Model with Mixture-of-Experts for Science**
2409.18412v1 by Liangtai Sun, Danyu Luo, Da Ma, Zihan Zhao, Baocai Chen, Zhennan Shen, Su Zhu, Lu Chen, Xin Chen, Kai Yu

Recently, there has been a significant upsurge of interest in leveraging
large language models (LLMs) to assist scientific discovery. However, most LLMs
only focus on general science, while they lack domain-specific knowledge, such
as chemical molecules and amino acid sequences. To bridge these gaps, we
introduce SciDFM, a mixture-of-experts LLM, which is trained from scratch and
is able to conduct college-level scientific reasoning and understand molecules
and amino acid sequences. We collect a large-scale training corpus containing
numerous scientific papers and books from different disciplines as well as data
from domain-specific databases. We further fine-tune the pre-trained model on
lots of instruction data to improve performances on downstream benchmarks. From
experiment results, we show that SciDFM achieves strong performance on general
scientific benchmarks such as SciEval and SciQ, and it reaches a SOTA
performance on domain-specific benchmarks among models of similar size. We
further analyze the expert layers and show that the results of expert selection
vary with data from different disciplines. To benefit the broader research
community, we open-source SciDFM at
https://huggingface.co/OpenDFM/SciDFM-MoE-A5.6B-v1.0.

摘要：<paragraph>最近，利用大型語言模型 (LLM) 來協助科學發現引起了極大的興趣。然而，大多數 LLM 只關注一般科學，而缺乏特定領域的知識，例如化學分子和胺基酸序列。為了彌補這些差距，我們引入了 SciDFM，這是一種混合專家 LLM，它從頭開始訓練，並且能夠進行大學層級的科學推理，並了解分子和胺基酸序列。我們收集了一個大型訓練語料庫，其中包含來自不同學科的許多科學論文和書籍，以及來自特定領域資料庫的資料。我們進一步微調預先訓練好的模型，針對大量的指令資料，以提高下游基準的效能。從實驗結果中，我們展示了 SciDFM 在一般科學基準（例如 SciEval 和 SciQ）上取得了強勁的效能，並且在類似規模的模型中，在特定領域的基準上達到了 SOTA 效能。我們進一步分析了專家層，並展示了專家選擇的結果會隨著來自不同學科的資料而有所不同。為了造福更廣泛的研究社群，我們在 https://huggingface.co/OpenDFM/SciDFM-MoE-A5.6B-v1.0 開源了 SciDFM。</paragraph>

##### **BoT-Drive: Hierarchical Behavior and Trajectory Planning for Autonomous Driving using POMDPs**
2409.18411v1 by Xuanjin Jin, Chendong Zeng, Shengfa Zhu, Chunxiao Liu, Panpan Cai

Uncertainties in dynamic road environments pose significant challenges for
behavior and trajectory planning in autonomous driving. This paper introduces
BoT-Drive, a planning algorithm that addresses uncertainties at both behavior
and trajectory levels within a Partially Observable Markov Decision Process
(POMDP) framework. BoT-Drive employs driver models to characterize unknown
behavioral intentions and utilizes their model parameters to infer hidden
driving styles. By also treating driver models as decision-making actions for
the autonomous vehicle, BoT-Drive effectively tackles the exponential
complexity inherent in POMDPs. To enhance safety and robustness, the planner
further applies importance sampling to refine the driving trajectory
conditioned on the planned high-level behavior. Evaluation on real-world data
shows that BoT-Drive consistently outperforms both existing planning methods
and learning-based methods in regular and complex urban driving scenes,
demonstrating significant improvements in driving safety and reliability.

摘要：在动态道路环境中的不确定性对自动驾驶中的行为和轨迹规划构成了重大挑战。本文介绍了 BoT-Drive，这是一种规划算法，它在部分可观察马尔可夫决策过程 (POMDP) 框架内解决行为和轨迹层面的不确定性。BoT-Drive 采用驾驶员模型来表征未知的行为意图，并利用其模型参数来推断隐藏的驾驶风格。通过还将驾驶员模型视为自动驾驶汽车的决策行为，BoT-Drive 有效地解决了 POMDP 中固有的指数级复杂性。为了提高安全性和鲁棒性，规划器进一步应用重要性采样来优化驾驶轨迹，以适应计划的高级行为。对真实世界数据的评估表明，BoT-Drive 在普通和复杂的城市驾驶场景中始终优于现有的规划方法和基于学习的方法，从而显着提高了驾驶安全性和可靠性。

##### **GenesisTex2: Stable, Consistent and High-Quality Text-to-Texture Generation**
2409.18401v1 by Jiawei Lu, Yingpeng Zhang, Zengjun Zhao, He Wang, Kun Zhou, Tianjia Shao

Large-scale text-guided image diffusion models have shown astonishing results
in text-to-image (T2I) generation. However, applying these models to synthesize
textures for 3D geometries remains challenging due to the domain gap between 2D
images and textures on a 3D surface. Early works that used a
projecting-and-inpainting approach managed to preserve generation diversity but
often resulted in noticeable artifacts and style inconsistencies. While recent
methods have attempted to address these inconsistencies, they often introduce
other issues, such as blurring, over-saturation, or over-smoothing. To overcome
these challenges, we propose a novel text-to-texture synthesis framework that
leverages pretrained diffusion models. We first introduce a local attention
reweighing mechanism in the self-attention layers to guide the model in
concentrating on spatial-correlated patches across different views, thereby
enhancing local details while preserving cross-view consistency. Additionally,
we propose a novel latent space merge pipeline, which further ensures
consistency across different viewpoints without sacrificing too much diversity.
Our method significantly outperforms existing state-of-the-art techniques
regarding texture consistency and visual quality, while delivering results much
faster than distillation-based methods. Importantly, our framework does not
require additional training or fine-tuning, making it highly adaptable to a
wide range of models available on public platforms.

摘要：大規模文字引導圖像擴散模型在文字對圖像 (T2I) 生成方面已展現驚人的成果。然而，由於 2D 影像與 3D 表面紋理之間的領域差距，將這些模型應用於合成 3D 幾何紋理仍然具有挑戰性。早期使用投影和修復方法的作品設法保留了生成的多樣性，但經常導致明顯的人工製品和樣式不一致。雖然最近的方法已嘗試解決這些不一致性，但它們經常會引入其他問題，例如模糊、過飽和或過度平滑。為了克服這些挑戰，我們提出了一種新穎的文字轉紋理合成架構，該架構利用了預訓練擴散模型。我們首先在自注意力層中引入局部注意力重新加權機制，以引導模型集中於不同視圖中的空間相關貼片，從而增強局部細節，同時保持跨視圖一致性。此外，我們提出了一種新穎的潛在空間合併管道，進一步確保了不同視點的一致性，同時不會犧牲太多樣性。我們的模型在紋理一致性和視覺品質方面明顯優於現有的最先進技術，同時比基於蒸餾的方法提供了更快的結果。重要的是，我們的框架不需要額外的訓練或微調，這使其高度適應於公共平台上提供的各種模型。

##### **Code Vulnerability Repair with Large Language Model using Context-Aware Prompt Tuning**
2409.18395v1 by Arshiya Khan, Guannan Liu, Xing Gao

Large Language Models (LLMs) have shown significant challenges in detecting
and repairing vulnerable code, particularly when dealing with vulnerabilities
involving multiple aspects, such as variables, code flows, and code structures.
In this study, we utilize GitHub Copilot as the LLM and focus on buffer
overflow vulnerabilities. Our experiments reveal a notable gap in Copilot's
abilities when dealing with buffer overflow vulnerabilities, with a 76%
vulnerability detection rate but only a 15% vulnerability repair rate. To
address this issue, we propose context-aware prompt tuning techniques designed
to enhance LLM performance in repairing buffer overflow. By injecting a
sequence of domain knowledge about the vulnerability, including various
security and code contexts, we demonstrate that Copilot's successful repair
rate increases to 63%, representing more than four times the improvement
compared to repairs without domain knowledge.

摘要：大型語言模型 (LLM) 在偵測和修復有漏洞的程式碼時顯示出顯著的挑戰，特別是在處理涉及多個面向（例如變數、程式碼流程和程式碼結構）的漏洞時。在本研究中，我們利用 GitHub Copilot 作為 LLM，並專注於緩衝區溢位漏洞。我們的實驗揭示了 Copilot 在處理緩衝區溢位漏洞時能力上的顯著差距，漏洞偵測率為 76%，但漏洞修復率僅為 15%。為了解決這個問題，我們提出情境感知提示調整技術，旨在增強 LLM 在修復緩衝區溢位時的效能。透過注入一系列關於漏洞的領域知識，包括各種安全性和程式碼情境，我們證明 Copilot 的成功修復率增加到 63%，與沒有領域知識的修復相比，改進幅度超過四倍。

##### **Speech to Reality: On-Demand Production using Natural Language, 3D Generative AI, and Discrete Robotic Assembly**
2409.18390v1 by Alexander Htet Kyaw, Se Hwan Jeon, Miana Smith, Neil Gershenfeld

We present a system that transforms speech into physical objects by combining
3D generative Artificial Intelligence with robotic assembly. The system
leverages natural language input to make design and manufacturing more
accessible, enabling individuals without expertise in 3D modeling or robotic
programming to create physical objects. We propose utilizing discrete robotic
assembly of lattice-based voxel components to address the challenges of using
generative AI outputs in physical production, such as design variability,
fabrication speed, structural integrity, and material waste. The system
interprets speech to generate 3D objects, discretizes them into voxel
components, computes an optimized assembly sequence, and generates a robotic
toolpath. The results are demonstrated through the assembly of various objects,
ranging from chairs to shelves, which are prompted via speech and realized
within 5 minutes using a 6-axis robotic arm.

摘要：<paragraph>我們提出一個系統，透過結合 3D 生成式人工智慧與機器人組裝，將語音轉換為實體物件。此系統利用自然語言輸入，讓設計和製造更易於使用，讓沒有 3D 建模或機器人程式專業知識的人員也能建立實體物件。我們建議利用格狀體素元件的離散機器人組裝，來解決在實體生產中使用生成式 AI 輸出的挑戰，例如設計變異性、製造速度、結構完整性和材料浪費。此系統會解譯語音以產生 3D 物件，將其離散化為體素元件，計算最佳組裝順序，並產生機器人刀具路徑。結果透過組裝各種物件來展示，從椅子到架子，這些物件都是透過語音提示，並在 5 分鐘內使用 6 軸機器手臂實現。</paragraph>

##### **Adaptive Learning of the Latent Space of Wasserstein Generative Adversarial Networks**
2409.18374v1 by Yixuan Qiu, Qingyi Gao, Xiao Wang

Generative models based on latent variables, such as generative adversarial
networks (GANs) and variational auto-encoders (VAEs), have gained lots of
interests due to their impressive performance in many fields. However, many
data such as natural images usually do not populate the ambient Euclidean space
but instead reside in a lower-dimensional manifold. Thus an inappropriate
choice of the latent dimension fails to uncover the structure of the data,
possibly resulting in mismatch of latent representations and poor generative
qualities. Towards addressing these problems, we propose a novel framework
called the latent Wasserstein GAN (LWGAN) that fuses the Wasserstein
auto-encoder and the Wasserstein GAN so that the intrinsic dimension of the
data manifold can be adaptively learned by a modified informative latent
distribution. We prove that there exist an encoder network and a generator
network in such a way that the intrinsic dimension of the learned encoding
distribution is equal to the dimension of the data manifold. We theoretically
establish that our estimated intrinsic dimension is a consistent estimate of
the true dimension of the data manifold. Meanwhile, we provide an upper bound
on the generalization error of LWGAN, implying that we force the synthetic data
distribution to be similar to the real data distribution from a population
perspective. Comprehensive empirical experiments verify our framework and show
that LWGAN is able to identify the correct intrinsic dimension under several
scenarios, and simultaneously generate high-quality synthetic data by sampling
from the learned latent distribution.

摘要：基於潛在變數的生成模型，例如生成對抗網路 (GAN) 和變異自動編碼器 (VAE)，由於在許多領域的出色表現而廣受關注。然而，許多資料，例如自然影像，通常不會填充環境歐幾里得空間，而是存在於較低維度的流形中。因此，潛在維度的選擇不當，會無法揭露資料的結構，可能導致潛在表示不匹配和生成品質不佳。為了解決這些問題，我們提出一個稱為潛在 Wasserstein GAN (LWGAN) 的新框架，它融合了 Wasserstein 自動編碼器和 Wasserstein GAN，以便資料流形的內在維度可以透過修改後的資訊潛在分布自適應地學習。我們證明了一個編碼器網路和一個生成器網路的存在，使得學習到的編碼分布的內在維度等於資料流形的維度。我們在理論上建立了我們的估計內在維度是資料流形真實維度的相容估計值。同時，我們提供了 LWGAN 泛化誤差的上界，這表示我們強制合成資料分布從族群觀點來看與真實資料分布相似。全面的實證實驗驗證了我們的框架，並表明 LWGAN 能夠在多種情境下識別正確的內在維度，並同時透過從學習到的潛在分布中抽樣來產生高品質的合成資料。

##### **Multi-hypotheses Conditioned Point Cloud Diffusion for 3D Human Reconstruction from Occluded Images**
2409.18364v1 by Donghwan Kim, Tae-Kyun Kim

3D human shape reconstruction under severe occlusion due to human-object or
human-human interaction is a challenging problem. Parametric models i.e.,
SMPL(-X), which are based on the statistics across human shapes, can represent
whole human body shapes but are limited to minimally-clothed human shapes.
Implicit-function-based methods extract features from the parametric models to
employ prior knowledge of human bodies and can capture geometric details such
as clothing and hair. However, they often struggle to handle misaligned
parametric models and inpaint occluded regions given a single RGB image. In
this work, we propose a novel pipeline, MHCDIFF, Multi-hypotheses Conditioned
Point Cloud Diffusion, composed of point cloud diffusion conditioned on
probabilistic distributions for pixel-aligned detailed 3D human reconstruction
under occlusion. Compared to previous implicit-function-based methods, the
point cloud diffusion model can capture the global consistent features to
generate the occluded regions, and the denoising process corrects the
misaligned SMPL meshes. The core of MHCDIFF is extracting local features from
multiple hypothesized SMPL(-X) meshes and aggregating the set of features to
condition the diffusion model. In the experiments on CAPE and MultiHuman
datasets, the proposed method outperforms various SOTA methods based on SMPL,
implicit functions, point cloud diffusion, and their combined, under synthetic
and real occlusions.

摘要：由於人體與物體或人體與人體的交互作用導致嚴重的遮擋，3D 人體形狀重建是一個具有挑戰性的問題。基於人體形狀統計資料的參數模型，例如 SMPL(-X)，可以表示完整的人體形狀，但僅限於穿著最少衣物的的人體形狀。基於隱式函數的方法從參數模型中提取特徵，以運用人體的先驗知識，並可以捕捉幾何細節，例如衣物和頭髮。然而，它們通常難以處理未對齊的參數模型，並在給定單一 RGB 影像的情況下填補被遮擋的區域。在這項工作中，我們提出了一個新穎的管道，即 MHCDIFF，多假設條件點雲擴散，它由條件化於像素對齊的詳細 3D 人體重建的機率分佈的點雲擴散組成。與先前的基於隱式函數的方法相比，點雲擴散模型可以捕捉全局一致的特徵以生成被遮擋的區域，而去雜訊程序會修正未對齊的 SMPL 網格。MHCDIFF 的核心是從多個假設的 SMPL(-X) 網格中提取局部特徵，並聚合特徵集合以調整擴散模型。在 CAPE 和 MultiHuman 資料集上的實驗中，所提出的方法優於各種基於 SMPL、隱式函數、點雲擴散及其組合的 SOTA 方法，在合成和真實遮擋下皆是如此。

##### **MultiClimate: Multimodal Stance Detection on Climate Change Videos**
2409.18346v1 by Jiawen Wang, Longfei Zuo, Siyao Peng, Barbara Plank

Climate change (CC) has attracted increasing attention in NLP in recent
years. However, detecting the stance on CC in multimodal data is understudied
and remains challenging due to a lack of reliable datasets. To improve the
understanding of public opinions and communication strategies, this paper
presents MultiClimate, the first open-source manually-annotated stance
detection dataset with $100$ CC-related YouTube videos and $4,209$
frame-transcript pairs. We deploy state-of-the-art vision and language models,
as well as multimodal models for MultiClimate stance detection. Results show
that text-only BERT significantly outperforms image-only ResNet50 and ViT.
Combining both modalities achieves state-of-the-art, $0.747$/$0.749$ in
accuracy/F1. Our 100M-sized fusion models also beat CLIP and BLIP, as well as
the much larger 9B-sized multimodal IDEFICS and text-only Llama3 and Gemma2,
indicating that multimodal stance detection remains challenging for large
language models. Our code, dataset, as well as supplementary materials, are
available at https://github.com/werywjw/MultiClimate.

摘要：<paragraph>氣候變遷 (CC) 近年來在自然語言處理 (NLP) 領域中備受關注。然而，偵測多模態資料中的氣候變遷立場仍處於研究不足的狀態，且因缺乏可靠的資料集而持續面臨挑戰。為了增進對公眾意見和溝通策略的了解，本文提出 MultiClimate，這是第一個開放原始碼的手動標註立場偵測資料集，其中包含 100 部與氣候變遷相關的 YouTube 影片和 4,209 對影格轉錄。我們部署了最先進的視覺和語言模型，以及多模態模型，用於 MultiClimate 立場偵測。結果顯示，僅使用文字的 BERT 明顯優於僅使用影像的 ResNet50 和 ViT。結合兩種模態可達成最先進的準確度/F1，分別為 0.747/0.749。我們規模達 100M 的融合模型也勝過 CLIP 和 BLIP，以及規模更大的 9B 多模態 IDEFICS 和僅使用文字的 Llama3 和 Gemma2，這表示多模態立場偵測對於大型語言模型來說仍然具有挑戰性。我們的程式碼、資料集以及補充資料可在 https://github.com/werywjw/MultiClimate 取得。</paragraph>

##### **A Generalized LLM-Augmented BIM Framework: Application to a Speech-to-BIM system**
2409.18345v1 by Ghang Lee, Suhyung Jang, Seokho Hyun

Performing building information modeling (BIM) tasks is a complex process
that imposes a steep learning curve and a heavy cognitive load due to the
necessity of remembering sequences of numerous commands. With the rapid
advancement of large language models (LLMs), it is foreseeable that BIM tasks,
including querying and managing BIM data, 4D and 5D BIM, design compliance
checking, or authoring a design, using written or spoken natural language
(i.e., text-to-BIM or speech-to-BIM), will soon supplant traditional graphical
user interfaces. This paper proposes a generalized LLM-augmented BIM framework
to expedite the development of LLM-enhanced BIM applications by providing a
step-by-step development process. The proposed framework consists of six steps:
interpret-fill-match-structure-execute-check. The paper demonstrates the
applicability of the proposed framework through implementing a speech-to-BIM
application, NADIA-S (Natural-language-based Architectural Detailing through
Interaction with Artificial Intelligence via Speech), using exterior wall
detailing as an example.

摘要：執行建築資訊模型 (BIM) 任務是一個複雜的過程，由於需要記住許多指令的順序，因此會造成陡峭的學習曲線和沉重的認知負擔。隨著大型語言模型 (LLM) 的快速進步，可以預見 BIM 任務（包括查詢和管理 BIM 資料、4D 和 5D BIM、設計合規性檢查或編寫設計）使用書面或口語自然語言（即文字轉 BIM 或語音轉 BIM），很快將取代傳統的圖形使用者介面。本文提出一個廣義的 LLM 擴充 BIM 架構，透過提供逐步開發流程，以加速 LLM 增強 BIM 應用程式的開發。所提出的架構包含六個步驟：解釋、填寫、比對、結構、執行、檢查。本文透過實作語音轉 BIM 應用程式 NADIA-S（透過語音與人工智慧互動的自然語言建築細部），以外部牆壁細部為例，來展示所提出架構的適用性。

##### **Improving Agent Behaviors with RL Fine-tuning for Autonomous Driving**
2409.18343v1 by Zhenghao Peng, Wenjie Luo, Yiren Lu, Tianyi Shen, Cole Gulino, Ari Seff, Justin Fu

A major challenge in autonomous vehicle research is modeling agent behaviors,
which has critical applications including constructing realistic and reliable
simulations for off-board evaluation and forecasting traffic agents motion for
onboard planning. While supervised learning has shown success in modeling
agents across various domains, these models can suffer from distribution shift
when deployed at test-time. In this work, we improve the reliability of agent
behaviors by closed-loop fine-tuning of behavior models with reinforcement
learning. Our method demonstrates improved overall performance, as well as
improved targeted metrics such as collision rate, on the Waymo Open Sim Agents
challenge. Additionally, we present a novel policy evaluation benchmark to
directly assess the ability of simulated agents to measure the quality of
autonomous vehicle planners and demonstrate the effectiveness of our approach
on this new benchmark.

摘要：自動駕駛車輛研究的一項重大挑戰在於建模代理行為，
這有許多關鍵應用，包括建立逼真且可靠的
模擬，以供離線評估和預測交通代理的運動，
以進行車載規劃。儘管監督式學習已在各種領域中建模
代理方面展現成功，但這些模型在測試時部署時可能會遭受分佈轉移。
在這項工作中，我們透過行為模型的閉環微調來改善代理
行為的可靠性，並採用強化學習。我們的模型展現出整體效能的改善，
以及目標指標的改善，例如 Waymo Open Sim Agents
挑戰中的碰撞率。此外，我們提出了一項新穎的政策評估基準，
以直接評估模擬代理衡量自動駕駛車輛規劃器品質的能力，
並在這個新基準上展示我們方法的有效性。

##### **DRL-STNet: Unsupervised Domain Adaptation for Cross-modality Medical Image Segmentation via Disentangled Representation Learning**
2409.18340v1 by Hui Lin, Florian Schiffers, Santiago López-Tapia, Neda Tavakoli, Daniel Kim, Aggelos K. Katsaggelos

Unsupervised domain adaptation (UDA) is essential for medical image
segmentation, especially in cross-modality data scenarios. UDA aims to transfer
knowledge from a labeled source domain to an unlabeled target domain, thereby
reducing the dependency on extensive manual annotations. This paper presents
DRL-STNet, a novel framework for cross-modality medical image segmentation that
leverages generative adversarial networks (GANs), disentangled representation
learning (DRL), and self-training (ST). Our method leverages DRL within a GAN
to translate images from the source to the target modality. Then, the
segmentation model is initially trained with these translated images and
corresponding source labels and then fine-tuned iteratively using a combination
of synthetic and real images with pseudo-labels and real labels. The proposed
framework exhibits superior performance in abdominal organ segmentation on the
FLARE challenge dataset, surpassing state-of-the-art methods by 11.4% in the
Dice similarity coefficient and by 13.1% in the Normalized Surface Dice metric,
achieving scores of 74.21% and 80.69%, respectively. The average running time
is 41 seconds, and the area under the GPU memory-time curve is 11,292 MB. These
results indicate the potential of DRL-STNet for enhancing cross-modality
medical image segmentation tasks.

摘要：無監督域適應 (UDA) 對醫學影像分割至關重要，特別是在跨模態數據場景中。UDA 旨在將標記來源域的知識轉移到未標記目標域，從而減少對大量人工標註的依賴。本文提出 DRL-STNet，這是一個用於跨模態醫學影像分割的新穎架構，它利用生成對抗網路 (GAN)、解糾纏表示學習 (DRL) 和自我訓練 (ST)。我們的模型在 GAN 中利用 DRL 將影像從來源轉換到目標模態。然後，分割模型最初使用這些轉換後的影像和對應的來源標籤進行訓練，然後使用合成影像和帶有偽標籤和真實標籤的真實影像的組合進行反覆微調。所提出的架構在 FLARE 挑戰資料集上的腹部器官分割中表現出優異的效能，在 Dice 相似係數上超越現有技術 11.4%，在標準化表面 Dice 指標上超越 13.1%，分別達到 74.21% 和 80.69% 的分數。平均執行時間為 41 秒，GPU 記憶體時間曲線下的面積為 11,292 MB。這些結果表明 DRL-STNet 在增強跨模態醫學影像分割任務方面具有潛力。

##### **AER-LLM: Ambiguity-aware Emotion Recognition Leveraging Large Language Models**
2409.18339v1 by Xin Hong, Yuan Gong, Vidhyasaharan Sethu, Ting Dang

Recent advancements in Large Language Models (LLMs) have demonstrated great
success in many Natural Language Processing (NLP) tasks. In addition to their
cognitive intelligence, exploring their capabilities in emotional intelligence
is also crucial, as it enables more natural and empathetic conversational AI.
Recent studies have shown LLMs' capability in recognizing emotions, but they
often focus on single emotion labels and overlook the complex and ambiguous
nature of human emotions. This study is the first to address this gap by
exploring the potential of LLMs in recognizing ambiguous emotions, leveraging
their strong generalization capabilities and in-context learning. We design
zero-shot and few-shot prompting and incorporate past dialogue as context
information for ambiguous emotion recognition. Experiments conducted using
three datasets indicate significant potential for LLMs in recognizing ambiguous
emotions, and highlight the substantial benefits of including context
information. Furthermore, our findings indicate that LLMs demonstrate a high
degree of effectiveness in recognizing less ambiguous emotions and exhibit
potential for identifying more ambiguous emotions, paralleling human perceptual
capabilities.

摘要：大型語言模型 (LLM) 的最新進展已在許多自然語言處理 (NLP) 任務中展現出巨大的成功。除了認知智能外，探索其在情緒智能方面的能力也至關重要，因為它能讓對話式 AI 更自然且富有同理心。最近的研究顯示，LLM 具有辨識情緒的能力，但它們通常只關注單一的情緒標籤，而忽略了人類情緒複雜且含糊的本質。本研究首次探討 LLM 在辨識含糊情緒方面的潛力，利用其強大的概括能力和情境學習，來解決這個問題。我們設計了零次學習和少次學習提示，並將過去的對話納入作為含糊情緒辨識的背景資訊。使用三個資料集進行的實驗顯示，LLM 在辨識含糊情緒方面具有顯著的潛力，並突顯了納入背景資訊的顯著好處。此外，我們的研究結果表明，LLM 在辨識較不含糊的情緒方面表現出高度的有效性，並且在辨識較含糊的情緒方面展現出潛力，這與人類的感知能力相符。

##### **A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies**
2409.18335v1 by Ryan Shea, Zhou Yu

Despite recent advancements in AI and NLP, negotiation remains a difficult
domain for AI agents. Traditional game theoretic approaches that have worked
well for two-player zero-sum games struggle in the context of negotiation due
to their inability to learn human-compatible strategies. On the other hand,
approaches that only use human data tend to be domain-specific and lack the
theoretical guarantees provided by strategies grounded in game theory.
Motivated by the notion of fairness as a criterion for optimality in general
sum games, we propose a negotiation framework called FDHC which incorporates
fairness into both the reward design and search to learn human-compatible
negotiation strategies. Our method includes a novel, RL+search technique called
LGM-Zero which leverages a pre-trained language model to retrieve
human-compatible offers from large action spaces. Our results show that our
method is able to achieve more egalitarian negotiation outcomes and improve
negotiation quality.

摘要：儘管 AI 和 NLP 近期有進展，但談判對 AI 代理來說仍然是困難的領域。傳統的博弈論方法在雙人零和遊戲中表現良好，但由於無法學習與人類相容的策略，因此在談判背景中會遇到困難。另一方面，僅使用人類資料的方法往往具有特定領域性，並且缺乏博弈論策略提供的理論保證。在一般總和遊戲中，公平性作為最佳性的標準這一概念的激勵下，我們提出了一個名為 FDHC 的談判框架，將公平性納入獎勵設計和搜尋中，以學習與人類相容的談判策略。我們的模型包含一種新穎的 RL+search 技術，稱為 LGM-Zero，它利用預先訓練的語言模型從大型動作空間中擷取與人類相容的報價。我們的結果顯示，我們的模型能夠達成更平等的談判結果，並提升談判品質。

##### **Cross-Institutional Structured Radiology Reporting for Lung Cancer Screening Using a Dynamic Template-Constrained Large Language Model**
2409.18319v1 by Chuang Niu, Parisa Kaviani, Qing Lyu, Mannudeep K. Kalra, Christopher T. Whitlow, Ge Wang

Structured radiology reporting is advantageous for optimizing clinical
workflows and patient outcomes. Current LLMs in creating structured reports
face the challenges of formatting errors, content hallucinations, and privacy
leakage concerns when uploaded to external servers. We aim to develop an
enhanced open-source LLM for creating structured and standardized LCS reports
from free-text descriptions. After institutional IRB approvals, 5,442
de-identified LCS reports from two institutions were retrospectively analyzed.
500 reports were randomly selected from the two institutions evenly and then
manually labeled for evaluation. Two radiologists from the two institutions
developed a standardized template including 29 features for lung nodule
reporting. We proposed template-constrained decoding to enhance
state-of-the-art open-source LLMs, including LLAMA, Qwen, and Mistral. The LLM
performance was extensively evaluated in terms of F1 score, confidence
interval, McNemar test, and z-test. Based on the structured reports created
from the large-scale dataset, a nodule-level retrieval system was prototyped
and an automatic statistical analysis was performed. Our software,
vLLM-structure, is publicly available for local deployment with enhanced LLMs.
Our template-constrained decoding approach consistently enhanced the LLM
performance on multi-institutional datasets, with neither formatting errors nor
content hallucinations. Our method improved the best open-source LLAMA-3.1 405B
by up to 10.42%, and outperformed GPT-4o by 17.19%. A novel nodule retrieval
system was successfully prototyped and demonstrated on a large-scale multimodal
database using our enhanced LLM technologies. The automatically derived
statistical distributions were closely consistent with the prior findings in
terms of nodule type, location, size, status, and Lung-RADS.

摘要：結構化放射報告有利於優化臨床工作流程和患者結果。當前 LLM 在建立結構化報告時，在格式錯誤、內容幻覺和隱私洩露問題上，面臨上傳至外部伺服器的挑戰。我們的目標是開發一個增強的開源 LLM，用於根據自由文字說明建立結構化且標準化的 LCS 報告。在獲得機構 IRB 批准後，回顧性分析了來自兩個機構的 5,442 份去識別化 LCS 報告。從兩個機構中隨機選取 500 份報告，然後手動標記以進行評估。來自兩個機構的兩名放射科醫師開發了一個標準化範本，其中包含 29 個肺結節報告功能。我們提出了範本約束解碼，以增強最先進的開源 LLM，包括 LLAMA、Qwen 和 Mistral。LLM 效能根據 F1 分數、信心區間、McNemar 檢定和 z 檢定進行廣泛評估。根據從大型資料集建立的結構化報告，建立了結節層級檢索系統並執行自動統計分析。我們的軟體 vLLM-structure 可公開使用，並可與增強的 LLM 搭配進行本地部署。我們的範本約束解碼方法持續增強 LLM 在多機構資料集上的效能，既沒有格式錯誤，也沒有內容幻覺。我們的技術將最佳開源 LLAMA-3.1 405B 提升了 10.42%，並超越了 GPT-4o 17.19%。使用我們增強的 LLM 技術，成功建立了一個新穎的結節檢索系統，並在大型多模式資料庫上進行了展示。自動衍生的統計分佈與先前的發現非常一致，包括結節類型、位置、大小、狀態和 Lung-RADS。

##### **Realistic Evaluation of Model Merging for Compositional Generalization**
2409.18314v1 by Derek Tam, Yash Kant, Brian Lester, Igor Gilitschenski, Colin Raffel

Merging has become a widespread way to cheaply combine individual models into
a single model that inherits their capabilities and attains better performance.
This popularity has spurred rapid development of many new merging methods,
which are typically validated in disparate experimental settings and frequently
differ in the assumptions made about model architecture, data availability, and
computational budget. In this work, we characterize the relative merits of
different merging methods by evaluating them in a shared experimental setting
and precisely identifying the practical requirements of each method.
Specifically, our setting focuses on using merging for compositional
generalization of capabilities in image classification, image generation, and
natural language processing. Additionally, we measure the computational costs
of different merging methods as well as how they perform when scaling the
number of models being merged. Taken together, our results clarify the state of
the field of model merging and provide a comprehensive and rigorous
experimental setup to test new methods.

摘要：合併已成為一種廣泛的方式，可以將個別模型廉價地合併成單一模型，繼承其能力並獲得更好的效能。
這種普及性刺激了許多新的合併方法的快速發展，這些方法通常在不同的實驗設定中驗證，並且經常在模型架構、資料可用性和運算預算所做的假設上有所不同。在這項工作中，我們透過在共用的實驗設定中評估不同的合併方法並精確識別每種方法的實際需求，來描述其相對優點。
具體來說，我們的設定著重於使用合併來進行影像分類、影像生成和自然語言處理中能力的組合概化。此外，我們測量不同合併方法的運算成本，以及它們在擴充合併模型數量時的執行方式。綜合起來，我們的結果釐清了模型合併領域的現況，並提供了一個全面且嚴謹的實驗設定來測試新的方法。

##### **Embodied-RAG: General non-parametric Embodied Memory for Retrieval and Generation**
2409.18313v1 by Quanting Xie, So Yeon Min, Tianyi Zhang, Aarav Bajaj, Ruslan Salakhutdinov, Matthew Johnson-Roberson, Yonatan Bisk

There is no limit to how much a robot might explore and learn, but all of
that knowledge needs to be searchable and actionable. Within language research,
retrieval augmented generation (RAG) has become the workhouse of large-scale
non-parametric knowledge, however existing techniques do not directly transfer
to the embodied domain, which is multimodal, data is highly correlated, and
perception requires abstraction.
  To address these challenges, we introduce Embodied-RAG, a framework that
enhances the foundational model of an embodied agent with a non-parametric
memory system capable of autonomously constructing hierarchical knowledge for
both navigation and language generation. Embodied-RAG handles a full range of
spatial and semantic resolutions across diverse environments and query types,
whether for a specific object or a holistic description of ambiance. At its
core, Embodied-RAG's memory is structured as a semantic forest, storing
language descriptions at varying levels of detail. This hierarchical
organization allows the system to efficiently generate context-sensitive
outputs across different robotic platforms. We demonstrate that Embodied-RAG
effectively bridges RAG to the robotics domain, successfully handling over 200
explanation and navigation queries across 19 environments, highlighting its
promise for general-purpose non-parametric system for embodied agents.

摘要：機器人的探索和學習沒有限制，但所有這些知識都需要可搜尋且可操作。在語言研究中，檢索擴增生成 (RAG) 已成為大規模非參數知識的基礎，但現有技術並未直接轉移到具多模態、資料高度相關且感知需要抽象的具身領域。
為了應對這些挑戰，我們引入了 Embodied-RAG，一個增強了具身代理基礎模型的框架，具備非參數記憶系統，能夠自主建構階層式知識，以進行導航和語言生成。Embodied-RAG 處理各種環境和查詢類型中的完整空間和語義解析，無論是針對特定物件或環境的整體描述。在核心部分，Embodied-RAG 的記憶被結構化為語義森林，儲存不同詳細程度的語言描述。這種階層組織讓系統能夠在不同的機器人平台上有效產生與情境相關的輸出。我們證明了 Embodied-RAG 有效地將 RAG 橋接到機器人領域，成功處理了 19 個環境中超過 200 個解釋和導航查詢，突顯了它對具身代理的一般用途非參數系統的承諾。

##### **Harnessing Wavelet Transformations for Generalizable Deepfake Forgery Detection**
2409.18301v1 by Lalith Bharadwaj Baru, Shilhora Akshay Patel, Rohit Boddeda

The evolution of digital image manipulation, particularly with the
advancement of deep generative models, significantly challenges existing
deepfake detection methods, especially when the origin of the deepfake is
obscure. To tackle the increasing complexity of these forgeries, we propose
\textbf{Wavelet-CLIP}, a deepfake detection framework that integrates wavelet
transforms with features derived from the ViT-L/14 architecture, pre-trained in
the CLIP fashion. Wavelet-CLIP utilizes Wavelet Transforms to deeply analyze
both spatial and frequency features from images, thus enhancing the model's
capability to detect sophisticated deepfakes. To verify the effectiveness of
our approach, we conducted extensive evaluations against existing
state-of-the-art methods for cross-dataset generalization and detection of
unseen images generated by standard diffusion models. Our method showcases
outstanding performance, achieving an average AUC of 0.749 for cross-data
generalization and 0.893 for robustness against unseen deepfakes, outperforming
all compared methods. The code can be reproduced from the repo:
\url{https://github.com/lalithbharadwajbaru/Wavelet-CLIP}

摘要：數位影像處理的演進，特別是深度生成模型的進步，對現有的深度偽造偵測方法帶來重大挑戰，特別是在深度偽造的來源不明時。為了解決這些偽造品日益增加的複雜性，我們提出**小波-CLIP**，一種深度偽造偵測架構，它將小波轉換與從 ViT-L/14 架構中衍生的特徵整合在一起，並以 CLIP 方式預先訓練。小波-CLIP 利用小波轉換深入分析影像的空間和頻率特徵，從而增強模型偵測精緻深度偽造的能力。為了驗證我們方法的有效性，我們針對現有的最先進方法進行廣泛評估，以進行跨資料集概化和偵測標準擴散模型產生的未見影像。我們的模型展現出傑出的效能，在跨資料概化方面達到 0.749 的平均 AUC，在對抗未見深度偽造的穩健性方面達到 0.893，優於所有比較方法。程式碼可以在儲存庫中複製：\url{https://github.com/lalithbharadwajbaru/Wavelet-CLIP}

##### **SOAR: Self-supervision Optimized UAV Action Recognition with Efficient Object-Aware Pretraining**
2409.18300v1 by Ruiqi Xian, Xiyang Wu, Tianrui Guan, Xijun Wang, Boqing Gong, Dinesh Manocha

We introduce SOAR, a novel Self-supervised pretraining algorithm for aerial
footage captured by Unmanned Aerial Vehicles (UAVs). We incorporate human
object knowledge throughout the pretraining process to enhance UAV video
pretraining efficiency and downstream action recognition performance. This is
in contrast to prior works that primarily incorporate object information during
the fine-tuning stage. Specifically, we first propose a novel object-aware
masking strategy designed to retain the visibility of certain patches related
to objects throughout the pretraining phase. Second, we introduce an
object-aware loss function that utilizes object information to adjust the
reconstruction loss, preventing bias towards less informative background
patches. In practice, SOAR with a vanilla ViT backbone, outperforms best UAV
action recognition models, recording a 9.7% and 21.4% boost in top-1 accuracy
on the NEC-Drone and UAV-Human datasets, while delivering an inference speed of
18.7ms per video, making it 2x to 5x faster. Additionally, SOAR obtains
comparable accuracy to prior self-supervised learning (SSL) methods while
requiring 87.5% less pretraining time and 25% less memory usage

摘要：我們引入了 SOAR，一種針對由無人機 (UAV) 捕捉的空中影像的全新自監督預訓練演算法。我們在整個預訓練過程中納入了人類物體知識，以提升無人機影片預訓練效率和下游動作辨識效能。這與先前主要在微調階段納入物體資訊的作品形成對比。具體來說，我們首先提出了一種新穎的物體感知遮罩策略，旨在保留與物體相關的特定區塊在整個預訓練階段的可視性。其次，我們引入了利用物體資訊調整重建損失的物體感知損失函數，防止偏向於資訊量較少的背景區塊。在實務中，採用香草 ViT 主幹的 SOAR 優於最佳的無人機動作辨識模型，在 NEC-Drone 和 UAV-Human 資料集上創下最高 1% 精確度提升 9.7% 和 21.4%，同時提供每部影片 18.7ms 的推論速度，使其快 2 到 5 倍。此外，SOAR 在需要少 87.5% 預訓練時間和少 25% 記憶體使用量的情況下，獲得與先前的自監督學習 (SSL) 方法相當的準確度

##### **Flat'n'Fold: A Diverse Multi-Modal Dataset for Garment Perception and Manipulation**
2409.18297v1 by Lipeng Zhuang, Shiyu Fan, Yingdong Ru, Florent Audonnet, Paul Henderson, Gerardo Aragon-Camarasa

We present Flat'n'Fold, a novel large-scale dataset for garment manipulation
that addresses critical gaps in existing datasets. Comprising 1,212 human and
887 robot demonstrations of flattening and folding 44 unique garments across 8
categories, Flat'n'Fold surpasses prior datasets in size, scope, and diversity.
Our dataset uniquely captures the entire manipulation process from crumpled to
folded states, providing synchronized multi-view RGB-D images, point clouds,
and action data, including hand or gripper positions and rotations. We quantify
the dataset's diversity and complexity compared to existing benchmarks and show
that our dataset features natural and diverse manipulations of real-world
demonstrations of human and robot demonstrations in terms of visual and action
information. To showcase Flat'n'Fold's utility, we establish new benchmarks for
grasping point prediction and subtask decomposition. Our evaluation of
state-of-the-art models on these tasks reveals significant room for
improvement. This underscores Flat'n'Fold's potential to drive advances in
robotic perception and manipulation of deformable objects. Our dataset can be
downloaded at https://cvas-ug.github.io/flat-n-fold

摘要：<paragraph>我們提出 Flat'n'Fold，這是一個用於服裝操作的新型大型數據集，它解決了現有數據集中的關鍵差距。Flat'n'Fold 包含 1,212 個真人示範和 887 個機器人示範，展示了 8 個類別中 44 件獨特服裝的攤平和摺疊過程，在規模、範圍和多樣性方面都超越了之前的數據集。我們的數據集獨特地捕捉了從皺巴巴到摺疊狀態的整個操作過程，提供了同步的多視圖 RGB-D 影像、點雲和動作數據，包括手部或夾具的位置和旋轉。我們量化了數據集的多樣性和複雜性，並與現有的基準進行比較，結果顯示我們的數據集在視覺和動作資訊方面具有自然且多樣化的真人和機器人示範操作。為了展示 Flat'n'Fold 的效用，我們為抓取點預測和子任務分解建立了新的基準。我們對這些任務中最先進模型的評估顯示出有顯著的改進空間。這突顯了 Flat'n'Fold 在推動可變形物體的機器人感知和操作方面取得進展的潛力。我們的數據集可以在 https://cvas-ug.github.io/flat-n-fold 下載</paragraph>

##### **Enhancing Lossy Compression Through Cross-Field Information for Scientific Applications**
2409.18295v1 by Youyuan Liu, Wenqi Jia, Taolue Yang, Miao Yin, Sian Jin

Lossy compression is one of the most effective methods for reducing the size
of scientific data containing multiple data fields. It reduces information
density through prediction or transformation techniques to compress the data.
Previous approaches use local information from a single target field when
predicting target data points, limiting their potential to achieve higher
compression ratios. In this paper, we identified significant cross-field
correlations within scientific datasets. We propose a novel hybrid prediction
model that utilizes CNN to extract cross-field information and combine it with
existing local field information. Our solution enhances the prediction accuracy
of lossy compressors, leading to improved compression ratios without
compromising data quality. We evaluate our solution on three scientific
datasets, demonstrating its ability to improve compression ratios by up to 25%
under specific error bounds. Additionally, our solution preserves more data
details and reduces artifacts compared to baseline approaches.

摘要：有損壓縮是減少包含多個數據欄位的科學數據大小最有效的方法之一。它透過預測或轉換技術降低資訊密度以壓縮數據。先前的做法在預測目標數據點時使用單一目標欄位的局部資訊，這限制了它們達到更高壓縮比的潛力。在本文中，我們在科學數據集中識別出顯著的跨欄位關聯性。我們提出一個新穎的混合預測模型，它利用 CNN 提取跨欄位資訊並將其與現有的局部欄位資訊結合。我們的解決方案增強了有損壓縮器的預測準確度，從而提高了壓縮比，同時不損害數據品質。我們在三個科學數據集上評估我們的解決方案，證明了它在特定誤差範圍內將壓縮比提高多達 25% 的能力。此外，與基線方法相比，我們的解決方案保留了更多數據細節並減少了人工製品。

##### **Retrospective Comparative Analysis of Prostate Cancer In-Basket Messages: Responses from Closed-Domain LLM vs. Clinical Teams**
2409.18290v1 by Yuexing Hao, Jason M. Holmes, Jared Hobson, Alexandra Bennett, Daniel K. Ebner, David M. Routman, Satomi Shiraishi, Samir H. Patel, Nathan Y. Yu, Chris L. Hallemeier, Brooke E. Ball, Mark R. Waddle, Wei Liu

In-basket message interactions play a crucial role in physician-patient
communication, occurring during all phases (pre-, during, and post) of a
patient's care journey. However, responding to these patients' inquiries has
become a significant burden on healthcare workflows, consuming considerable
time for clinical care teams. To address this, we introduce RadOnc-GPT, a
specialized Large Language Model (LLM) powered by GPT-4 that has been designed
with a focus on radiotherapeutic treatment of prostate cancer with advanced
prompt engineering, and specifically designed to assist in generating
responses. We integrated RadOnc-GPT with patient electronic health records
(EHR) from both the hospital-wide EHR database and an internal,
radiation-oncology-specific database. RadOnc-GPT was evaluated on 158
previously recorded in-basket message interactions. Quantitative natural
language processing (NLP) analysis and two grading studies with clinicians and
nurses were used to assess RadOnc-GPT's responses. Our findings indicate that
RadOnc-GPT slightly outperformed the clinical care team in "Clarity" and
"Empathy," while achieving comparable scores in "Completeness" and
"Correctness." RadOnc-GPT is estimated to save 5.2 minutes per message for
nurses and 2.4 minutes for clinicians, from reading the inquiry to sending the
response. Employing RadOnc-GPT for in-basket message draft generation has the
potential to alleviate the workload of clinical care teams and reduce
healthcare costs by producing high-quality, timely responses.

摘要：收件匣訊息互動在醫師與病患溝通中扮演著至關重要的角色，發生在病患照護旅程的各個階段（事前、事中和事後）。然而，回應這些病患的詢問已成為醫療工作流程的重大負擔，耗費臨床照護團隊大量時間。為了解決這個問題，我們引進 RadOnc-GPT，這是一個由 GPT-4 提供技術支援的專業大型語言模型 (LLM)，其設計重點在於透過進階提示工程技術對攝護腺癌進行放射治療，並特別設計用於協助產生回應。我們將 RadOnc-GPT 整合到病患電子健康紀錄 (EHR) 中，這些紀錄來自於全院的 EHR 資料庫和一個內部的放射腫瘤專用資料庫。RadOnc-GPT 針對 158 則先前記錄的收件匣訊息互動進行評估。我們使用量化自然語言處理 (NLP) 分析和兩項評分研究（由臨床醫師和護理師進行）來評估 RadOnc-GPT 的回應。我們的研究結果顯示，RadOnc-GPT 在「清晰度」和「同理心」方面表現略優於臨床照護團隊，同時在「完整性」和「正確性」方面達到相當的分數。估計 RadOnc-GPT 可為護理師節省每則訊息 5.2 分鐘，為臨床醫師節省 2.4 分鐘，從閱讀詢問到發送回應。採用 RadOnc-GPT 來產生收件匣訊息草稿有潛力減輕臨床照護團隊的工作負擔，並透過產生高品質、及時的回應來降低醫療保健成本。

##### **Advancing Object Detection in Transportation with Multimodal Large Language Models (MLLMs): A Comprehensive Review and Empirical Testing**
2409.18286v1 by Huthaifa I. Ashqar, Ahmed Jaber, Taqwa I. Alhadidi, Mohammed Elhenawy

This study aims to comprehensively review and empirically evaluate the
application of multimodal large language models (MLLMs) and Large Vision Models
(VLMs) in object detection for transportation systems. In the first fold, we
provide a background about the potential benefits of MLLMs in transportation
applications and conduct a comprehensive review of current MLLM technologies in
previous studies. We highlight their effectiveness and limitations in object
detection within various transportation scenarios. The second fold involves
providing an overview of the taxonomy of end-to-end object detection in
transportation applications and future directions. Building on this, we
proposed empirical analysis for testing MLLMs on three real-world
transportation problems that include object detection tasks namely, road safety
attributes extraction, safety-critical event detection, and visual reasoning of
thermal images. Our findings provide a detailed assessment of MLLM performance,
uncovering both strengths and areas for improvement. Finally, we discuss
practical limitations and challenges of MLLMs in enhancing object detection in
transportation, thereby offering a roadmap for future research and development
in this critical area.

摘要：本研究旨在全面檢視並實證評估多模態大型語言模型 (MLLM) 和大型視覺模型 (VLM) 在運輸系統中的目標偵測應用。在第一個部分，我們提供 MLLM 在運輸應用中潛在好處的背景，並對先前研究中的現有 MLLM 技術進行全面檢視。我們重點說明它們在各種運輸情境中的目標偵測效能和限制。第二個部分包括提供運輸應用中端到端目標偵測分類的概述，以及未來的方向。在此基礎上，我們針對 MLLM 在三個真實世界的運輸問題上進行實證分析，其中包括目標偵測任務，例如道路安全屬性萃取、安全關鍵事件偵測，以及熱影像的視覺推理。我們的發現提供了 MLLM 效能的詳細評估，揭示了優點和需要改進的地方。最後，我們探討了 MLLM 在增強運輸中的目標偵測時所面臨的實際限制和挑戰，從而為這個關鍵領域的未來研究和發展提供了一份藍圖。

