{"2409.17027": {"publish_time": "2024-09-25", "title": "Counterfactual Token Generation in Large Language Models", "paper_summary": "\"Sure, I am happy to generate a story for you: Captain Lyra stood at the helm\nof her trusty ship, the Maelstrom's Fury, gazing out at the endless sea. [...]\nLyra's eyes welled up with tears as she realized the bitter truth - she had\nsacrificed everything for fleeting riches, and lost the love of her crew, her\nfamily, and herself.\" Although this story, generated by a large language model,\nis captivating, one may wonder -- how would the story have unfolded if the\nmodel had chosen \"Captain Maeve\" as the protagonist instead? We cannot know.\nState-of-the-art large language models are stateless -- they maintain no\ninternal memory or state. Given a prompt, they generate a sequence of tokens as\nan output using an autoregressive process. As a consequence, they cannot reason\nabout counterfactual alternatives to tokens they have generated in the past. In\nthis work, our goal is to enhance them with this functionality. To this end, we\ndevelop a causal model of token generation that builds upon the Gumbel-Max\nstructural causal model. Our model allows any large language model to perform\ncounterfactual token generation at almost no cost in comparison with vanilla\ntoken generation, it is embarrassingly simple to implement, and it does not\nrequire any fine-tuning nor prompt engineering. We implement our model on Llama\n3 8B-instruct and conduct both qualitative and quantitative analyses of\ncounterfactually generated text. We conclude with a demonstrative application\nof counterfactual token generation for bias detection, unveiling interesting\ninsights about the model of the world constructed by large language models.", "paper_summary_zh": "\u300c\u7576\u7136\uff0c\u6211\u5f88\u6a02\u610f\u70ba\u60a8\u7522\u751f\u4e00\u500b\u6545\u4e8b\uff1a\u840a\u62c9\u8239\u9577\u7ad9\u5728\u5979\u5fe0\u5be6\u7684\u8239\u96bb\uff0c\u66b4\u98a8\u4e4b\u6012\u865f\u7684\u8235\u67c4\u4e0a\uff0c\u51dd\u8996\u8457\u7121\u76e1\u7684\u5927\u6d77\u3002[...]\u840a\u62c9\u7684\u96d9\u773c\u5659\u6eff\u6dda\u6c34\uff0c\u5979\u610f\u8b58\u5230\u4e86\u4e00\u500b\u75db\u82e6\u7684\u771f\u76f8\u2014\u2014\u5979\u70ba\u4e86\u7a0d\u7e31\u5373\u901d\u7684\u8ca1\u5bcc\u72a7\u7272\u4e86\u4e00\u5207\uff0c\u5931\u53bb\u4e86\u8239\u54e1\u3001\u5bb6\u4eba\u548c\u81ea\u5df1\u7684\u611b\u3002\u300d\u5118\u7ba1\u9019\u500b\u7531\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7522\u751f\u7684\u6545\u4e8b\u5f15\u4eba\u5165\u52dd\uff0c\u4f46\u4eba\u5011\u53ef\u80fd\u6703\u597d\u5947\u2014\u2014\u5982\u679c\u8a72\u6a21\u578b\u9078\u64c7\u300c\u6885\u8299\u8239\u9577\u300d\u4f5c\u70ba\u4e3b\u89d2\uff0c\u6545\u4e8b\u6703\u5982\u4f55\u5c55\u958b\uff1f\u6211\u5011\u4e0d\u5f97\u800c\u77e5\u3002\u6700\u5148\u9032\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u662f\u7121\u72c0\u614b\u7684\u2014\u2014\u5b83\u5011\u4e0d\u7dad\u8b77\u4efb\u4f55\u5167\u90e8\u8a18\u61b6\u6216\u72c0\u614b\u3002\u7d66\u5b9a\u4e00\u500b\u63d0\u793a\uff0c\u5b83\u5011\u6703\u4f7f\u7528\u81ea\u8ff4\u6b78\u904e\u7a0b\u751f\u6210\u4e00\u500b\u5e8f\u5217\u7684\u6a19\u8a18\u4f5c\u70ba\u8f38\u51fa\u3002\u56e0\u6b64\uff0c\u5b83\u5011\u7121\u6cd5\u5c0d\u904e\u53bb\u751f\u6210\u7684\u6a19\u8a18\u7684\u53cd\u4e8b\u5be6\u66ff\u4ee3\u65b9\u6848\u9032\u884c\u63a8\u7406\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u7684\u76ee\u6a19\u662f\u589e\u5f37\u5b83\u5011\u7684\u9019\u9805\u529f\u80fd\u3002\u70ba\u6b64\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u56e0\u679c\u6a19\u8a18\u751f\u6210\u6a21\u578b\uff0c\u8a72\u6a21\u578b\u5efa\u7acb\u5728 Gumbel-Max \u7d50\u69cb\u56e0\u679c\u6a21\u578b\u4e4b\u4e0a\u3002\u6211\u5011\u7684\u6a21\u578b\u5141\u8a31\u4efb\u4f55\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4ee5\u5e7e\u4e4e\u6c92\u6709\u6210\u672c\uff08\u8207\u9999\u8349\u6a19\u8a18\u751f\u6210\u76f8\u6bd4\uff09\u57f7\u884c\u53cd\u4e8b\u5be6\u6a19\u8a18\u751f\u6210\uff0c\u5176\u5be6\u73fe\u975e\u5e38\u7c21\u55ae\uff0c\u4e26\u4e14\u4e0d\u9700\u8981\u4efb\u4f55\u5fae\u8abf\u6216\u63d0\u793a\u5de5\u7a0b\u3002\u6211\u5011\u5728 Llama 3 8B-instruct \u4e0a\u5be6\u73fe\u4e86\u6211\u5011\u7684\u6a21\u578b\uff0c\u4e26\u5c0d\u53cd\u4e8b\u5be6\u751f\u6210\u7684\u6587\u672c\u9032\u884c\u4e86\u5b9a\u6027\u548c\u5b9a\u91cf\u5206\u6790\u3002\u6211\u5011\u4ee5\u53cd\u4e8b\u5be6\u6a19\u8a18\u751f\u6210\u7684\u4e00\u500b\u793a\u7bc4\u61c9\u7528\u4f86\u6aa2\u6e2c\u504f\u5dee\u4f5c\u70ba\u7d50\u8ad6\uff0c\u63ed\u793a\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u69cb\u5efa\u7684\u4e16\u754c\u6a21\u578b\u7684\u6709\u8da3\u898b\u89e3\u3002", "author": "Ivi Chatzi et.al.", "authors": "Ivi Chatzi, Nina Corvelo Benz, Eleni Straitouri, Stratis Tsirtsis, Manuel Gomez-Rodriguez", "id": "2409.17027v1", "paper_url": "http://arxiv.org/abs/2409.17027v1", "repo": "null"}}