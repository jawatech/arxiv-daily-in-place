{"2408.03907": {"publish_time": "2024-08-07", "title": "Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models", "paper_summary": "Large Language Models (LLMs) have excelled at language understanding and\ngenerating human-level text. However, even with supervised training and human\nalignment, these LLMs are susceptible to adversarial attacks where malicious\nusers can prompt the model to generate undesirable text. LLMs also inherently\nencode potential biases that can cause various harmful effects during\ninteractions. Bias evaluation metrics lack standards as well as consensus and\nexisting methods often rely on human-generated templates and annotations which\nare expensive and labor intensive. In this work, we train models to\nautomatically create adversarial prompts to elicit biased responses from target\nLLMs. We present LLM- based bias evaluation metrics and also analyze several\nexisting automatic evaluation methods and metrics. We analyze the various\nnuances of model responses, identify the strengths and weaknesses of model\nfamilies, and assess where evaluation methods fall short. We compare these\nmetrics to human evaluation and validate that the LLM-as-a-Judge metric aligns\nwith human judgement on bias in response generation.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u8a9e\u8a00\u7406\u89e3\u548c\u7522\u751f\u4eba\u985e\u5c64\u7d1a\u6587\u5b57\u65b9\u9762\u8868\u73fe\u51fa\u8272\u3002\u7136\u800c\uff0c\u5373\u4f7f\u7d93\u904e\u76e3\u7763\u5f0f\u8a13\u7df4\u548c\u4eba\u985e\u6821\u6e96\uff0c\u9019\u4e9b LLM \u4ecd\u5bb9\u6613\u53d7\u5230\u5c0d\u6297\u6027\u653b\u64ca\uff0c\u60e1\u610f\u4f7f\u7528\u8005\u53ef\u4ee5\u63d0\u793a\u6a21\u578b\u7522\u751f\u4e0d\u826f\u6587\u5b57\u3002LLM \u672c\u8eab\u4e5f\u7de8\u78bc\u4e86\u6f5b\u5728\u504f\u898b\uff0c\u53ef\u80fd\u5728\u4e92\u52d5\u904e\u7a0b\u4e2d\u9020\u6210\u5404\u7a2e\u6709\u5bb3\u5f71\u97ff\u3002\u504f\u898b\u8a55\u4f30\u6307\u6a19\u7f3a\u4e4f\u6a19\u6e96\u548c\u5171\u8b58\uff0c\u73fe\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8cf4\u65bc\u4eba\u5de5\u7522\u751f\u7684\u7bc4\u672c\u548c\u8a3b\u89e3\uff0c\u9019\u4e9b\u7bc4\u672c\u548c\u8a3b\u89e3\u6602\u8cb4\u4e14\u8017\u8cbb\u4eba\u529b\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u8a13\u7df4\u6a21\u578b\u81ea\u52d5\u5efa\u7acb\u5c0d\u6297\u6027\u63d0\u793a\uff0c\u5f9e\u76ee\u6a19 LLM \u5f15\u51fa\u6709\u504f\u898b\u7684\u56de\u61c9\u3002\u6211\u5011\u63d0\u51fa\u57fa\u65bc LLM \u7684\u504f\u898b\u8a55\u4f30\u6307\u6a19\uff0c\u4e26\u5206\u6790\u4e86\u5e7e\u7a2e\u73fe\u6709\u7684\u81ea\u52d5\u8a55\u4f30\u65b9\u6cd5\u548c\u6307\u6a19\u3002\u6211\u5011\u5206\u6790\u6a21\u578b\u56de\u61c9\u7684\u5404\u7a2e\u7d30\u5fae\u5dee\u5225\uff0c\u627e\u51fa\u6a21\u578b\u7cfb\u5217\u7684\u512a\u7f3a\u9ede\uff0c\u4e26\u8a55\u4f30\u8a55\u4f30\u65b9\u6cd5\u7684\u4e0d\u8db3\u4e4b\u8655\u3002\u6211\u5011\u5c07\u9019\u4e9b\u6307\u6a19\u8207\u4eba\u985e\u8a55\u4f30\u9032\u884c\u6bd4\u8f03\uff0c\u4e26\u9a57\u8b49 LLM \u4f5c\u70ba\u8a55\u5224\u6307\u6a19\u8207\u4eba\u985e\u5c0d\u56de\u61c9\u4e2d\u504f\u898b\u7684\u5224\u65b7\u4e00\u81f4\u3002", "author": "Shachi H Kumar et.al.", "authors": "Shachi H Kumar, Saurav Sahay, Sahisnu Mazumder, Eda Okur, Ramesh Manuvinakurike, Nicole Beckage, Hsuan Su, Hung-yi Lee, Lama Nachman", "id": "2408.03907v1", "paper_url": "http://arxiv.org/abs/2408.03907v1", "repo": "null"}}