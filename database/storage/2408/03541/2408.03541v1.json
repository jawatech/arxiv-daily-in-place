{"2408.03541": {"publish_time": "2024-08-07", "title": "EXAONE 3.0 7.8B Instruction Tuned Language Model", "paper_summary": "We introduce EXAONE 3.0 instruction-tuned language model, the first open\nmodel in the family of Large Language Models (LLMs) developed by LG AI\nResearch. Among different model sizes, we publicly release the 7.8B\ninstruction-tuned model to promote open research and innovations. Through\nextensive evaluations across a wide range of public and in-house benchmarks,\nEXAONE 3.0 demonstrates highly competitive real-world performance with\ninstruction-following capability against other state-of-the-art open models of\nsimilar size. Our comparative analysis shows that EXAONE 3.0 excels\nparticularly in Korean, while achieving compelling performance across general\ntasks and complex reasoning. With its strong real-world effectiveness and\nbilingual proficiency, we hope that EXAONE keeps contributing to advancements\nin Expert AI. Our EXAONE 3.0 instruction-tuned model is available at\nhttps://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct", "paper_summary_zh": "\u6211\u5011\u63a8\u51fa EXAONE 3.0 \u6307\u4ee4\u8abf\u6574\u8a9e\u8a00\u6a21\u578b\uff0c\u9019\u662f LG AI \u7814\u7a76\u958b\u767c\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5bb6\u65cf\u4e2d\u7b2c\u4e00\u500b\u958b\u653e\u6a21\u578b\u3002\u5728\u4e0d\u540c\u7684\u6a21\u578b\u5927\u5c0f\u4e2d\uff0c\u6211\u5011\u516c\u958b\u767c\u5e03 7.8B \u6307\u4ee4\u8abf\u6574\u6a21\u578b\uff0c\u4ee5\u4fc3\u9032\u958b\u653e\u7814\u7a76\u548c\u5275\u65b0\u3002\u900f\u904e\u5728\u5404\u7a2e\u516c\u958b\u548c\u5167\u90e8\u57fa\u6e96\u4e0a\u7684\u5ee3\u6cdb\u8a55\u4f30\uff0cEXAONE 3.0 \u5c55\u793a\u4e86\u8207\u5176\u4ed6\u985e\u4f3c\u898f\u6a21\u7684\u6700\u65b0\u958b\u653e\u6a21\u578b\u76f8\u6bd4\uff0c\u5177\u6709\u9ad8\u5ea6\u7af6\u722d\u529b\u7684\u771f\u5be6\u4e16\u754c\u6548\u80fd\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u3002\u6211\u5011\u7684\u6bd4\u8f03\u5206\u6790\u986f\u793a\uff0cEXAONE 3.0 \u7279\u5225\u64c5\u9577\u97d3\u8a9e\uff0c\u540c\u6642\u5728\u4e00\u822c\u4efb\u52d9\u548c\u8907\u96dc\u63a8\u7406\u4e2d\u53d6\u5f97\u4ee4\u4eba\u4fe1\u670d\u7684\u8868\u73fe\u3002\u6191\u85c9\u5176\u5f37\u5927\u7684\u771f\u5be6\u4e16\u754c\u6548\u80fd\u548c\u96d9\u8a9e\u80fd\u529b\uff0c\u6211\u5011\u5e0c\u671b EXAONE \u6301\u7e8c\u70ba\u5c08\u5bb6 AI \u7684\u9032\u6b65\u505a\u51fa\u8ca2\u737b\u3002\u6211\u5011\u7684 EXAONE 3.0 \u6307\u4ee4\u8abf\u6574\u6a21\u578b\u53ef\u5728 https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct \u53d6\u5f97", "author": "LG AI Research et.al.", "authors": "LG AI Research, Soyoung An, Kyunghoon Bae, Eunbi Choi, Stanley Jungkyu Choi, Yemuk Choi, Seokhee Hong, Yeonjung Hong, Junwon Hwang, Hyojin Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Yountae Jung, Euisoon Kim, Hyosang Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Youchul Kim, Edward Hwayoung Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Moontae Lee, Seungjun Lee, Woohyung Lim, Sangha Park, Sooyoun Park, Yongmin Park, Boseong Seo, Sihoon Yang, Heuiyeen Yeen, Kyungjae Yoo, Hyeongu Yun", "id": "2408.03541v1", "paper_url": "http://arxiv.org/abs/2408.03541v1", "repo": "null"}}