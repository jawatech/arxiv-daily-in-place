{"2408.02288": {"publish_time": "2024-08-05", "title": "Spin glass model of in-context learning", "paper_summary": "Large language models show a surprising in-context learning ability -- being\nable to use a prompt to form a prediction for a query, yet without additional\ntraining, in stark contrast to old-fashioned supervised learning. Providing a\nmechanistic interpretation and linking the empirical phenomenon to physics are\nthus challenging and remain unsolved. We study a simple yet expressive\ntransformer with linear attention, and map this structure to a spin glass model\nwith real-valued spins, where the couplings and fields explain the intrinsic\ndisorder in data. The spin glass model explains how the weight parameters\ninteract with each other during pre-training, and most importantly why an\nunseen function can be predicted by providing only a prompt yet without\ntraining. Our theory reveals that for single instance learning, increasing the\ntask diversity leads to the emergence of the in-context learning, by allowing\nthe Boltzmann distribution to converge to a unique correct solution of weight\nparameters. Therefore the pre-trained transformer displays a prediction power\nin a novel prompt setting. The proposed spin glass model thus establishes a\nfoundation to understand the empirical success of large language models.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u5c55\u73fe\u51fa\u4ee4\u4eba\u9a5a\u8a1d\u7684\u8108\u7d61\u5b78\u7fd2\u80fd\u529b\u2014\u2014\u80fd\u5920\u4f7f\u7528\u63d0\u793a\u70ba\u67e5\u8a62\u5f62\u6210\u9810\u6e2c\uff0c\u4f46\u7121\u9700\u984d\u5916\u8a13\u7df4\uff0c\u9019\u8207\u50b3\u7d71\u7684\u76e3\u7763\u5f0f\u5b78\u7fd2\u5f62\u6210\u9bae\u660e\u5c0d\u6bd4\u3002\u56e0\u6b64\uff0c\u63d0\u4f9b\u6a5f\u68b0\u8ad6\u89e3\u91cb\u4e26\u5c07\u7d93\u9a57\u73fe\u8c61\u8207\u7269\u7406\u806f\u7e6b\u8d77\u4f86\u5177\u6709\u6311\u6230\u6027\uff0c\u4e14\u4ecd\u672a\u89e3\u6c7a\u3002\u6211\u5011\u7814\u7a76\u4e86\u4e00\u500b\u7c21\u55ae\u4f46\u5bcc\u6709\u8868\u73fe\u529b\u7684\u7dda\u6027\u6ce8\u610f\u529bTransformer\uff0c\u4e26\u5c07\u6b64\u7d50\u69cb\u6620\u5c04\u5230\u4e00\u500b\u5177\u6709\u5be6\u503c\u81ea\u65cb\u7684\u81ea\u65cb\u73bb\u7483\u6a21\u578b\uff0c\u5176\u4e2d\u8026\u5408\u548c\u5834\u89e3\u91cb\u4e86\u6578\u64da\u4e2d\u7684\u5167\u5728\u7121\u5e8f\u3002\u81ea\u65cb\u73bb\u7483\u6a21\u578b\u89e3\u91cb\u4e86\u6b0a\u91cd\u53c3\u6578\u5728\u9810\u8a13\u7df4\u671f\u9593\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\uff0c\u6700\u91cd\u8981\u7684\u662f\u70ba\u4ec0\u9ebc\u50c5\u901a\u904e\u63d0\u4f9b\u63d0\u793a\u800c\u7121\u9700\u8a13\u7df4\u5c31\u53ef\u4ee5\u9810\u6e2c\u4e00\u500b\u672a\u898b\u51fd\u6578\u3002\u6211\u5011\u7684\u7406\u8ad6\u63ed\u793a\uff0c\u5c0d\u65bc\u55ae\u4f8b\u5b78\u7fd2\uff0c\u589e\u52a0\u4efb\u52d9\u591a\u6a23\u6027\u6703\u5c0e\u81f4\u8108\u7d61\u5b78\u7fd2\u7684\u51fa\u73fe\uff0c\u901a\u904e\u5141\u8a31\u73bb\u723e\u8332\u66fc\u5206\u4f48\u6536\u6582\u65bc\u6b0a\u91cd\u53c3\u6578\u7684\u552f\u4e00\u6b63\u78ba\u89e3\u3002\u56e0\u6b64\uff0c\u9810\u8a13\u7df4\u7684Transformer\u5728\u65b0\u7684\u63d0\u793a\u8a2d\u7f6e\u4e2d\u986f\u793a\u51fa\u9810\u6e2c\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u6240\u63d0\u51fa\u7684\u81ea\u65cb\u73bb\u7483\u6a21\u578b\u70ba\u7406\u89e3\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u7d93\u9a57\u6210\u529f\u5960\u5b9a\u4e86\u57fa\u790e\u3002", "author": "Yuhao Li et.al.", "authors": "Yuhao Li, Ruoran Bai, Haiping Huang", "id": "2408.02288v1", "paper_url": "http://arxiv.org/abs/2408.02288v1", "repo": "null"}}