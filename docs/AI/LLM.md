
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-06**|**Stag-1: Towards Realistic 4D Driving Simulation with Video Generation Model**|Lening Wang et.al.|[2412.05280v1](http://arxiv.org/abs/2412.05280v1)|[link](https://github.com/wzzheng/stag)|
|**2024-12-06**|**MotionFlow: Attention-Driven Motion Transfer in Video Diffusion Models**|Tuna Han Salih Meral et.al.|[2412.05275v1](http://arxiv.org/abs/2412.05275v1)|null|
|**2024-12-06**|**APOLLO: SGD-like Memory, AdamW-level Performance**|Hanqing Zhu et.al.|[2412.05270v1](http://arxiv.org/abs/2412.05270v1)|null|
|**2024-12-06**|**Chimera: Accurate retrosynthesis prediction by ensembling models with diverse inductive biases**|Krzysztof Maziarz et.al.|[2412.05269v1](http://arxiv.org/abs/2412.05269v1)|null|
|**2024-12-06**|**Reinforcement Learning: An Overview**|Kevin Murphy et.al.|[2412.05265v1](http://arxiv.org/abs/2412.05265v1)|null|
|**2024-12-06**|**Extrapolated Urban View Synthesis Benchmark**|Xiangyu Han et.al.|[2412.05256v1](http://arxiv.org/abs/2412.05256v1)|[link](https://github.com/ai4ce/EUVS-Benchmark)|
|**2024-12-06**|**TeamCraft: A Benchmark for Multi-Modal Multi-Agent Systems in Minecraft**|Qian Long et.al.|[2412.05255v1](http://arxiv.org/abs/2412.05255v1)|[link](https://github.com/teamcraft-bench/teamcraft)|
|**2024-12-06**|**From classical techniques to convolution-based models: A review of object detection algorithms**|Fnu Neha et.al.|[2412.05252v1](http://arxiv.org/abs/2412.05252v1)|null|
|**2024-12-06**|**Uncertainty Quantification for Transformer Models for Dark-Pattern Detection**|Javier Muñoz et.al.|[2412.05251v1](http://arxiv.org/abs/2412.05251v1)|null|
|**2024-12-06**|**Enhancing FKG.in: automating Indian food composition analysis**|Saransh Kumar Gupta et.al.|[2412.05248v1](http://arxiv.org/abs/2412.05248v1)|null|
|**2024-12-06**|**Enhancing Foundation Models for Time Series Forecasting via Wavelet-based Tokenization**|Luca Masserano et.al.|[2412.05244v1](http://arxiv.org/abs/2412.05244v1)|null|
|**2024-12-06**|**CompCap: Improving Multimodal Large Language Models with Composite Captions**|Xiaohui Chen et.al.|[2412.05243v1](http://arxiv.org/abs/2412.05243v1)|null|
|**2024-12-06**|**MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale**|Jarvis Guo et.al.|[2412.05237v1](http://arxiv.org/abs/2412.05237v1)|null|
|**2024-12-06**|**LIAR: Leveraging Alignment (Best-of-N) to Jailbreak LLMs in Seconds**|James Beetham et.al.|[2412.05232v1](http://arxiv.org/abs/2412.05232v1)|null|
|**2024-12-06**|**BEExformer: A Fast Inferencing Transformer Architecture via Binarization with Multiple Early Exits**|Wazib Ansar et.al.|[2412.05225v1](http://arxiv.org/abs/2412.05225v1)|null|
|**2024-12-06**|**100% Hallucination Elimination Using Acurai**|Michael C. Wood et.al.|[2412.05223v1](http://arxiv.org/abs/2412.05223v1)|null|
|**2024-12-06**|**Evaluating and Aligning CodeLLMs on Human Preference**|Jian Yang et.al.|[2412.05210v1](http://arxiv.org/abs/2412.05210v1)|null|
|**2024-12-06**|**A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges**|Aditi Singh et.al.|[2412.05208v1](http://arxiv.org/abs/2412.05208v1)|null|
|**2024-12-06**|**ConQRet: Benchmarking Fine-Grained Evaluation of Retrieval Augmented Argumentation with LLM Judges**|Kaustubh D. Dhole et.al.|[2412.05206v1](http://arxiv.org/abs/2412.05206v1)|[link](https://github.com/emory-irlab/conqret-rag)|
|**2024-12-06**|**Archaeoscape: Bringing Aerial Laser Scanning Archaeology to the Deep Learning Era**|Yohann Perron et.al.|[2412.05203v1](http://arxiv.org/abs/2412.05203v1)|null|
|**2024-12-06**|**Are Frontier Large Language Models Suitable for Q&A in Science Centres?**|Jacob Watson et.al.|[2412.05200v1](http://arxiv.org/abs/2412.05200v1)|null|
|**2024-12-06**|**SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**|Jinlin Wu et.al.|[2412.05187v1](http://arxiv.org/abs/2412.05187v1)|[link](https://github.com/franciszchen/surgbox)|
|**2024-12-06**|**QueEn: A Large Language Model for Quechua-English Translation**|Junhao Chen et.al.|[2412.05184v1](http://arxiv.org/abs/2412.05184v1)|null|
|**2024-12-06**|**Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models**|Kuofeng Gao et.al.|[2412.05167v1](http://arxiv.org/abs/2412.05167v1)|null|
|**2024-12-06**|**DNF: Unconditional 4D Generation with Dictionary-based Neural Fields**|Xinyi Zhang et.al.|[2412.05161v1](http://arxiv.org/abs/2412.05161v1)|null|
|**2024-12-06**|**Enhancing Cross-Language Code Translation via Task-Specific Embedding Alignment in Retrieval-Augmented Generation**|Manish Bhattarai et.al.|[2412.05159v1](http://arxiv.org/abs/2412.05159v1)|null|
|**2024-12-06**|**Multimodal Fact-Checking with Vision Language Models: A Probing Classifier based Solution with Embedding Strategies**|Recep Firat Cekinel et.al.|[2412.05155v1](http://arxiv.org/abs/2412.05155v1)|null|
|**2024-12-06**|**Navigating Shortcuts, Spurious Correlations, and Confounders: From Origins via Detection to Mitigation**|David Steinmann et.al.|[2412.05152v1](http://arxiv.org/abs/2412.05152v1)|null|
|**2024-12-06**|**Findings of the Second BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora**|Michael Y. Hu et.al.|[2412.05149v1](http://arxiv.org/abs/2412.05149v1)|null|
|**2024-12-06**|**LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation**|Donald Shenaj et.al.|[2412.05148v1](http://arxiv.org/abs/2412.05148v1)|null|
|**2024-12-06**|**Explingo: Explaining AI Predictions using Large Language Models**|Alexandra Zytek et.al.|[2412.05145v1](http://arxiv.org/abs/2412.05145v1)|null|
|**2024-12-06**|**A Practical Examination of AI-Generated Text Detectors for Large Language Models**|Brian Tufts et.al.|[2412.05139v1](http://arxiv.org/abs/2412.05139v1)|null|
|**2024-12-06**|**Can Large Language Models Serve as Effective Classifiers for Hierarchical Multi-Label Classification of Scientific Documents at Industrial Scale?**|Seyed Amin Tabatabaei et.al.|[2412.05137v1](http://arxiv.org/abs/2412.05137v1)|null|
|**2024-12-06**|**Technology as uncharted territory: Contextual integrity and the notion of AI as new ethical ground**|Alexander Martin Mussgnug et.al.|[2412.05130v1](http://arxiv.org/abs/2412.05130v1)|null|
|**2024-12-06**|**The Prompt Canvas: A Literature-Based Practitioner Guide for Creating Effective Prompts in Large Language Models**|Michael Hewing et.al.|[2412.05127v1](http://arxiv.org/abs/2412.05127v1)|null|
|**2024-12-06**|**A*Net and NBFNet Learn Negative Patterns on Knowledge Graphs**|Patrick Betz et.al.|[2412.05114v1](http://arxiv.org/abs/2412.05114v1)|null|
|**2024-12-06**|**Modeling Task Immersion based on Goal Activation Mechanism**|Kazuma Nagashima et.al.|[2412.05112v1](http://arxiv.org/abs/2412.05112v1)|null|
|**2024-12-06**|**From Defects to Demands: A Unified, Iterative, and Heuristically Guided LLM-Based Framework for Automated Software Repair and Requirement Realization**|Alex et.al.|[2412.05098v1](http://arxiv.org/abs/2412.05098v1)|null|
|**2024-12-06**|**OCEAN: Open-World Contrastive Authorship Identification**|Felix Mächtle et.al.|[2412.05049v1](http://arxiv.org/abs/2412.05049v1)|[link](https://github.com/uzl-its/ocean)|
|**2024-12-06**|**Improving Post-Earthquake Crack Detection using Semi-Synthetic Generated Images**|Piercarlo Dondi et.al.|[2412.05042v1](http://arxiv.org/abs/2412.05042v1)|null|
|**2024-12-06**|**Talking Like One of Us: Effects of Using Regional Language in a Humanoid Social Robot**|Thomas Sievers et.al.|[2412.05024v1](http://arxiv.org/abs/2412.05024v1)|null|
|**2024-12-06**|**Steps are all you need: Rethinking STEM Education with Prompt Engineering**|Krishnasai Addala et.al.|[2412.05023v1](http://arxiv.org/abs/2412.05023v1)|null|
|**2024-12-06**|**Get It Right: Improving Comprehensibility with Adaptable Speech Expression of a Humanoid Service Robot**|Thomas Sievers et.al.|[2412.05022v1](http://arxiv.org/abs/2412.05022v1)|null|
|**2024-12-06**|**Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**|Thomas Sievers et.al.|[2412.05013v1](http://arxiv.org/abs/2412.05013v1)|null|
|**2024-12-06**|**ETLNet: An Efficient TCN-BiLSTM Network for Road Anomaly Detection Using Smartphone Sensors**|Mohd Faiz Ansari et.al.|[2412.04990v1](http://arxiv.org/abs/2412.04990v1)|null|
|**2024-12-06**|**Frontier Models are Capable of In-context Scheming**|Alexander Meinke et.al.|[2412.04984v1](http://arxiv.org/abs/2412.04984v1)|null|
|**2024-12-06**|**PETapter: Leveraging PET-style classification heads for modular few-shot parameter-efficient fine-tuning**|Jonas Rieger et.al.|[2412.04975v1](http://arxiv.org/abs/2412.04975v1)|null|
|**2024-12-06**|**Putting the Iterative Training of Decision Trees to the Test on a Real-World Robotic Task**|Raphael C. Engelhardt et.al.|[2412.04974v1](http://arxiv.org/abs/2412.04974v1)|null|
|**2024-12-06**|**Flash Communication: Reducing Tensor Parallelization Bottleneck for Fast Large Language Model Inference**|Qingyuan Li et.al.|[2412.04964v1](http://arxiv.org/abs/2412.04964v1)|null|
|**2024-12-06**|**Gla-AI4BioMed at RRG24: Visual Instruction-tuned Adaptation for Radiology Report Generation**|Xi Zhang et.al.|[2412.04954v1](http://arxiv.org/abs/2412.04954v1)|null|
|**2024-12-06**|**Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**|Thomas Bartz-Beielstein et.al.|[2412.04950v1](http://arxiv.org/abs/2412.04950v1)|null|
|**2024-12-06**|**KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**|Peng Yu et.al.|[2412.04948v1](http://arxiv.org/abs/2412.04948v1)|null|
|**2024-12-06**|**C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation**|Yanyang Li et.al.|[2412.04947v1](http://arxiv.org/abs/2412.04947v1)|null|
|**2024-12-06**|**A Federated Approach to Few-Shot Hate Speech Detection for Marginalized Communities**|Haotian Ye et.al.|[2412.04942v1](http://arxiv.org/abs/2412.04942v1)|null|
|**2024-12-06**|**Who Speaks Next? Multi-party AI Discussion Leveraging the Systematics of Turn-taking in Murder Mystery Games**|Ryota Nonomura et.al.|[2412.04937v1](http://arxiv.org/abs/2412.04937v1)|null|
|**2024-12-06**|**Probing the contents of semantic representations from text, behavior, and brain data using the psychNorms metabase**|Zak Hussain et.al.|[2412.04936v1](http://arxiv.org/abs/2412.04936v1)|[link](https://github.com/zak-hussain/psychnorms)|
|**2024-12-06**|**Uncertainty-aware retinal layer segmentation in OCT through probabilistic signed distance functions**|Mohammad Mohaiminul Islam et.al.|[2412.04935v1](http://arxiv.org/abs/2412.04935v1)|[link](https://github.com/niazoys/rls_psdf)|
|**2024-12-06**|**Continuous Video Process: Modeling Videos as Continuous Multi-Dimensional Processes for Video Prediction**|Gaurav Shrivastava et.al.|[2412.04929v1](http://arxiv.org/abs/2412.04929v1)|null|
|**2024-12-06**|**HyperGraphOS: A Meta Operating System for Science and Engineering**|Antonello Ceravola et.al.|[2412.04923v1](http://arxiv.org/abs/2412.04923v1)|null|
|**2024-12-06**|**Large Language Models for Ingredient Substitution in Food Recipes using Supervised Fine-tuning and Direct Preference Optimization**|Thevin Senath et.al.|[2412.04922v1](http://arxiv.org/abs/2412.04922v1)|null|
|**2024-12-06**|**DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling**|Minzheng Wang et.al.|[2412.04905v1](http://arxiv.org/abs/2412.04905v1)|[link](https://github.com/mozerwang/demo)|
|**2024-12-06**|**EACO: Enhancing Alignment in Multimodal LLMs via Critical Observation**|Yongxin Wang et.al.|[2412.04903v1](http://arxiv.org/abs/2412.04903v1)|null|
|**2024-12-06**|**AI-Driven Non-Invasive Detection and Staging of Steatosis in Fatty Liver Disease Using a Novel Cascade Model and Information Fusion Techniques**|Niloufar Delfan et.al.|[2412.04884v1](http://arxiv.org/abs/2412.04884v1)|null|
|**2024-12-06**|**Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud**|Yuanhao Yue et.al.|[2412.04871v1](http://arxiv.org/abs/2412.04871v1)|null|
|**2024-12-06**|**NebulaFL: Effective Asynchronous Federated Learning for JointCloud Computing**|Fei Gao et.al.|[2412.04868v1](http://arxiv.org/abs/2412.04868v1)|null|
|**2024-12-06**|**EXAONE 3.5: Series of Large Language Models for Real-world Use Cases**|LG AI Research et.al.|[2412.04862v1](http://arxiv.org/abs/2412.04862v1)|null|
|**2024-12-06**|**Breaking Event Rumor Detection via Stance-Separated Multi-Agent Debate**|Mingqing Zhang et.al.|[2412.04859v1](http://arxiv.org/abs/2412.04859v1)|null|
|**2024-12-06**|**Neuro-Symbolic Data Generation for Math Reasoning**|Zenan Li et.al.|[2412.04857v1](http://arxiv.org/abs/2412.04857v1)|null|
|**2024-12-06**|**MTSpark: Enabling Multi-Task Learning with Spiking Neural Networks for Generalist Agents**|Avaneesh Devkota et.al.|[2412.04847v1](http://arxiv.org/abs/2412.04847v1)|null|
|**2024-12-06**|**eXpath: Explaining Knowledge Graph Link Prediction with Ontological Closed Path Rules**|Ye Sun et.al.|[2412.04846v1](http://arxiv.org/abs/2412.04846v1)|null|
|**2024-12-06**|**Using Machine Learning to Discover Parsimonious and Physically-Interpretable Representations of Catchment-Scale Rainfall-Runoff Dynamics**|Yuan-Heng Wang et.al.|[2412.04845v1](http://arxiv.org/abs/2412.04845v1)|null|
|**2024-12-06**|**Maximizing Alignment with Minimal Feedback: Efficiently Learning Rewards for Visuomotor Robot Policy Alignment**|Ran Tian et.al.|[2412.04835v1](http://arxiv.org/abs/2412.04835v1)|null|
|**2024-12-06**|**WRF-GS: Wireless Radiation Field Reconstruction with 3D Gaussian Splatting**|Chaozheng Wen et.al.|[2412.04832v1](http://arxiv.org/abs/2412.04832v1)|null|
|**2024-12-06**|**Rethinking Time Series Forecasting with LLMs via Nearest Neighbor Contrastive Learning**|Jayanie Bogahawatte et.al.|[2412.04806v1](http://arxiv.org/abs/2412.04806v1)|null|
|**2024-12-06**|**Estimating the treatment effect over time under general interference through deep learner integrated TMLE**|Suhan Guo et.al.|[2412.04799v1](http://arxiv.org/abs/2412.04799v1)|null|
|**2024-12-06**|**Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**|Mahfuzul Haque et.al.|[2412.04792v1](http://arxiv.org/abs/2412.04792v1)|null|
|**2024-12-06**|**GUIDE: A Global Unified Inference Engine for Deploying Large Language Models in Heterogeneous Environments**|Yanyu Chen et.al.|[2412.04788v1](http://arxiv.org/abs/2412.04788v1)|null|
|**2024-12-06**|**Direct Quantized Training of Language Models with Stochastic Rounding**|Kaiyan Zhao et.al.|[2412.04787v1](http://arxiv.org/abs/2412.04787v1)|null|
|**2024-12-06**|**NLP-ADBench: NLP Anomaly Detection Benchmark**|Yuangang Li et.al.|[2412.04784v1](http://arxiv.org/abs/2412.04784v1)|[link](https://github.com/usc-fortis/nlp-adbench)|
|**2024-12-06**|**KNN-MMD: Cross Domain Wi-Fi Sensing Based on Local Distribution Alignment**|Zijian Zhao et.al.|[2412.04783v1](http://arxiv.org/abs/2412.04783v1)|null|
|**2024-12-06**|**A Survey of Sustainability in Large Language Models: Applications, Economics, and Challenges**|Aditi Singh et.al.|[2412.04782v1](http://arxiv.org/abs/2412.04782v1)|null|
|**2024-12-06**|**Foundation Models for Low-Resource Language Education (Vision Paper)**|Zhaojun Ding et.al.|[2412.04774v1](http://arxiv.org/abs/2412.04774v1)|null|
|**2024-12-06**|**DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**|Shadab Ahamed et.al.|[2412.04766v1](http://arxiv.org/abs/2412.04766v1)|null|
|**2024-12-06**|**Short-term Streamflow and Flood Forecasting based on Graph Convolutional Recurrent Neural Network and Residual Error Learning**|Xiyu Pan et.al.|[2412.04764v1](http://arxiv.org/abs/2412.04764v1)|null|
|**2024-12-06**|**REGENT: A Retrieval-Augmented Generalist Agent That Can Act In-Context in New Environments**|Kaustubh Sridhar et.al.|[2412.04759v1](http://arxiv.org/abs/2412.04759v1)|null|
|**2024-12-06**|**Measuring Goal-Directedness**|Matt MacDermott et.al.|[2412.04758v1](http://arxiv.org/abs/2412.04758v1)|null|
|**2024-12-06**|**Ltri-LLM: Streaming Long Context Inference for LLMs with Training-Free Dynamic Triangular Attention Pattern**|Hongyin Tang et.al.|[2412.04757v1](http://arxiv.org/abs/2412.04757v1)|null|
|**2024-12-06**|**ChatNVD: Advancing Cybersecurity Vulnerability Assessment with Large Language Models**|Shivansh Chopra et.al.|[2412.04756v1](http://arxiv.org/abs/2412.04756v1)|null|
|**2024-12-06**|**Question Answering for Decisionmaking in Green Building Design: A Multimodal Data Reasoning Method Driven by Large Language Models**|Yihui Li et.al.|[2412.04741v1](http://arxiv.org/abs/2412.04741v1)|null|
|**2024-12-06**|**BESSTIE: A Benchmark for Sentiment and Sarcasm Classification for Varieties of English**|Dipankar Srirag et.al.|[2412.04726v1](http://arxiv.org/abs/2412.04726v1)|null|
|**2024-12-06**|**Adaptive Optimization for Enhanced Efficiency in Large-Scale Language Model Training**|Jiajing Chen et.al.|[2412.04718v1](http://arxiv.org/abs/2412.04718v1)|null|
|**2024-12-06**|**NoLoR: An ASR-Based Framework for Expedited Endangered Language Documentation with Neo-Aramaic as a Case Study**|Matthew Nazari et.al.|[2412.04717v1](http://arxiv.org/abs/2412.04717v1)|null|
|**2024-12-06**|**PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**|Hongjin Lin et.al.|[2412.04714v1](http://arxiv.org/abs/2412.04714v1)|null|
|**2024-12-06**|**Parametric-ControlNet: Multimodal Control in Foundation Models for Precise Engineering Design Synthesis**|Rui Zhou et.al.|[2412.04707v1](http://arxiv.org/abs/2412.04707v1)|null|
|**2024-12-06**|**On Interpreting the Effectiveness of Unsupervised Software Traceability with Information Theory**|David N. Palacio et.al.|[2412.04704v1](http://arxiv.org/abs/2412.04704v1)|null|
|**2024-12-06**|**Transformers Struggle to Learn to Search**|Abulhair Saparov et.al.|[2412.04703v1](http://arxiv.org/abs/2412.04703v1)|null|
|**2024-12-06**|**Privacy-Preserving Retrieval Augmented Generation with Differential Privacy**|Tatsuki Koga et.al.|[2412.04697v1](http://arxiv.org/abs/2412.04697v1)|null|
|**2024-12-06**|**Smoothie: Label Free Language Model Routing**|Neel Guha et.al.|[2412.04692v1](http://arxiv.org/abs/2412.04692v1)|null|
|**2024-12-06**|**LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**|Xuan Chen et.al.|[2412.04690v1](http://arxiv.org/abs/2412.04690v1)|null|
|**2024-12-06**|**Two stages domain invariant representation learners solve the large co-variate shift in unsupervised domain adaptation with two dimensional data domains**|Hisashi Oshima et.al.|[2412.04682v1](http://arxiv.org/abs/2412.04682v1)|[link](https://github.com/oh-yu/domain-invariant-learning)|

#### Abstracts
##### **Stag-1: Towards Realistic 4D Driving Simulation with Video Generation Model**
2412.05280v1 by Lening Wang, Wenzhao Zheng, Dalong Du, Yunpeng Zhang, Yilong Ren, Han Jiang, Zhiyong Cui, Haiyang Yu, Jie Zhou, Jiwen Lu, Shanghang Zhang

4D driving simulation is essential for developing realistic autonomous
driving simulators. Despite advancements in existing methods for generating
driving scenes, significant challenges remain in view transformation and
spatial-temporal dynamic modeling. To address these limitations, we propose a
Spatial-Temporal simulAtion for drivinG (Stag-1) model to reconstruct
real-world scenes and design a controllable generative network to achieve 4D
simulation. Stag-1 constructs continuous 4D point cloud scenes using
surround-view data from autonomous vehicles. It decouples spatial-temporal
relationships and produces coherent keyframe videos. Additionally, Stag-1
leverages video generation models to obtain photo-realistic and controllable 4D
driving simulation videos from any perspective. To expand the range of view
generation, we train vehicle motion videos based on decomposed camera poses,
enhancing modeling capabilities for distant scenes. Furthermore, we reconstruct
vehicle camera trajectories to integrate 3D points across consecutive views,
enabling comprehensive scene understanding along the temporal dimension.
Following extensive multi-level scene training, Stag-1 can simulate from any
desired viewpoint and achieve a deep understanding of scene evolution under
static spatial-temporal conditions. Compared to existing methods, our approach
shows promising performance in multi-view scene consistency, background
coherence, and accuracy, and contributes to the ongoing advancements in
realistic autonomous driving simulation. Code: https://github.com/wzzheng/Stag.

摘要：4D 駕駛模擬對於開發逼真的自動駕駛模擬器至關重要。儘管現有方法在產生駕駛場景方面取得進展，但在視圖轉換和時空動態建模方面仍面臨重大挑戰。為了解決這些限制，我們提出了一種用於駕駛的時空模擬 (Stag-1) 模型，以重建真實世界的場景並設計一個可控的生成網路以實現 4D 模擬。Stag-1 使用來自自動駕駛汽車的環景資料，構建連續的 4D 點雲場景。它解耦時空關係並產生連貫的關鍵影格影片。此外，Stag-1 利用影片生成模型從任何角度獲取逼真的可控 4D 駕駛模擬影片。為了擴展視圖生成範圍，我們根據分解的相機姿勢訓練車輛運動影片，增強遠景建模能力。此外，我們重建車輛相機軌跡以整合連續視圖中的 3D 點，實現沿時間維度的全面場景理解。經過廣泛的多級場景訓練後，Stag-1 可以從任何所需的視點進行模擬，並在靜態時空條件下對場景演化有深入的了解。與現有方法相比，我們的方法在多視圖場景一致性、背景連貫性和準確性方面表現出良好的效能，並有助於逼真自動駕駛模擬的持續進步。程式碼：https://github.com/wzzheng/Stag。

##### **MotionFlow: Attention-Driven Motion Transfer in Video Diffusion Models**
2412.05275v1 by Tuna Han Salih Meral, Hidir Yesiltepe, Connor Dunlop, Pinar Yanardag

Text-to-video models have demonstrated impressive capabilities in producing
diverse and captivating video content, showcasing a notable advancement in
generative AI. However, these models generally lack fine-grained control over
motion patterns, limiting their practical applicability. We introduce
MotionFlow, a novel framework designed for motion transfer in video diffusion
models. Our method utilizes cross-attention maps to accurately capture and
manipulate spatial and temporal dynamics, enabling seamless motion transfers
across various contexts. Our approach does not require training and works on
test-time by leveraging the inherent capabilities of pre-trained video
diffusion models. In contrast to traditional approaches, which struggle with
comprehensive scene changes while maintaining consistent motion, MotionFlow
successfully handles such complex transformations through its attention-based
mechanism. Our qualitative and quantitative experiments demonstrate that
MotionFlow significantly outperforms existing models in both fidelity and
versatility even during drastic scene alterations.

摘要：文本到影片模型已展示出令人印象深刻的能力，能產生多元且引人入勝的影片內容，展現生成式 AI 的顯著進展。然而，這些模型通常缺乏對動作模式的細緻控制，限制了其實用性。我們引入了 MotionFlow，一個專為影片擴散模型中的動作轉移而設計的新穎架構。我們的模型利用交叉注意力圖來精確捕捉和控制時空動態，讓動作能在各種情境中無縫轉移。我們的模型不需要訓練，並在測試時透過利用預先訓練的影片擴散模型的內在能力來運作。與傳統方法不同，傳統方法在維持一致動作的同時難以處理全面的場景變化，MotionFlow 透過其基於注意力的機制成功地處理了這些複雜的轉換。我們的定性和定量實驗證明，即使在劇烈的場景變化中，MotionFlow 在保真度和多功能性方面都明顯優於現有模型。

##### **APOLLO: SGD-like Memory, AdamW-level Performance**
2412.05270v1 by Hanqing Zhu, Zhenyu Zhang, Wenyan Cong, Xi Liu, Sem Park, Vikas Chandra, Bo Long, David Z. Pan, Zhangyang Wang, Jinwon Lee

Large language models (LLMs) are notoriously memory-intensive during
training, particularly with the popular AdamW optimizer. This memory burden
necessitates using more or higher-end GPUs or reducing batch sizes, limiting
training scalability and throughput. To address this, various memory-efficient
optimizers have been proposed to reduce optimizer memory usage. However, they
face critical challenges: (i) reliance on costly SVD operations; (ii)
significant performance trade-offs compared to AdamW; and (iii) still
substantial optimizer memory overhead to maintain competitive performance.
  In this work, we identify that AdamW's learning rate adaptation rule can be
effectively coarsened as a structured learning rate update. Based on this
insight, we propose Approximated Gradient Scaling for Memory-Efficient LLM
Optimization (APOLLO), which approximates learning rate scaling using an
auxiliary low-rank optimizer state based on pure random projection. This
structured learning rate update rule makes APOLLO highly tolerant to further
memory reductions while delivering comparable pre-training performance. Even
its rank-1 variant, APOLLO-Mini, achieves superior pre-training performance
compared to AdamW with SGD-level memory costs.
  Extensive experiments demonstrate that the APOLLO series performs on-par with
or better than AdamW, while achieving greater memory savings by nearly
eliminating the optimization states of AdamW. These savings provide significant
system-level benefits: (1) Enhanced Throughput: 3x throughput on an 8xA100-80GB
setup compared to AdamW by supporting 4x larger batch sizes. (2) Improved Model
Scalability: Pre-training LLaMA-13B with naive DDP on A100-80GB GPUs without
system-level optimizations. (3) Low-End GPU Friendly Pre-training: Pre-training
LLaMA-7B on a single GPU using less than 12 GB of memory with weight
quantization.

摘要：大型語言模型 (LLM) 在訓練期間以消耗大量記憶體而惡名昭彰，特別是使用廣受歡迎的 AdamW 最佳化器時。這種記憶體負擔需要使用更多或更高階的 GPU 或減少批次大小，限制訓練可擴充性和吞吐量。為了解決這個問題，已經提出各種省記憶體的最佳化器來減少最佳化器記憶體使用量。然而，它們面臨嚴峻的挑戰：(i) 依賴昂貴的 SVD 運算；(ii) 與 AdamW 相比有顯著的效能取捨；(iii) 仍然需要大量的最佳化器記憶體開銷來維持競爭力。在本文中，我們發現 AdamW 的學習率適應規則可以有效地粗略化為結構化的學習率更新。根據這個見解，我們提出了記憶體高效 LLM 最佳化近似梯度縮放 (APOLLO)，它使用基於純隨機投影的輔助低秩最佳化器狀態來近似學習率縮放。這種結構化的學習率更新規則讓 APOLLO 非常耐受進一步的記憶體減少，同時提供可比較的預訓練效能。即使是它的秩 1 變體 APOLLO-Mini，與 SGD 等級的記憶體成本相比，也達到了優異的預訓練效能。廣泛的實驗表明，APOLLO 系列的效能與 AdamW 相當或優於 AdamW，同時透過幾乎消除 AdamW 的最佳化狀態來節省更多記憶體。這些節省提供了顯著的系統層級優點：(1) 增強的吞吐量：與 AdamW 相比，在 8xA100-80GB 設定上提高了 3 倍的吞吐量，支援 4 倍更大的批次大小。(2) 改善模型可擴充性：在沒有系統層級最佳化的情況下，使用 A100-80GB GPU 預訓練 LLaMA-13B 時採用單純的 DDP。(3) 低階 GPU 友善的預訓練：使用低於 12 GB 的記憶體和權重量化在單一 GPU 上預訓練 LLaMA-7B。

##### **Chimera: Accurate retrosynthesis prediction by ensembling models with diverse inductive biases**
2412.05269v1 by Krzysztof Maziarz, Guoqing Liu, Hubert Misztela, Aleksei Kornev, Piotr Gaiński, Holger Hoefling, Mike Fortunato, Rishi Gupta, Marwin Segler

Planning and conducting chemical syntheses remains a major bottleneck in the
discovery of functional small molecules, and prevents fully leveraging
generative AI for molecular inverse design. While early work has shown that
ML-based retrosynthesis models can predict reasonable routes, their low
accuracy for less frequent, yet important reactions has been pointed out. As
multi-step search algorithms are limited to reactions suggested by the
underlying model, the applicability of those tools is inherently constrained by
the accuracy of retrosynthesis prediction. Inspired by how chemists use
different strategies to ideate reactions, we propose Chimera: a framework for
building highly accurate reaction models that combine predictions from diverse
sources with complementary inductive biases using a learning-based ensembling
strategy. We instantiate the framework with two newly developed models, which
already by themselves achieve state of the art in their categories. Through
experiments across several orders of magnitude in data scale and time-splits,
we show Chimera outperforms all major models by a large margin, owing both to
the good individual performance of its constituents, but also to the
scalability of our ensembling strategy. Moreover, we find that PhD-level
organic chemists prefer predictions from Chimera over baselines in terms of
quality. Finally, we transfer the largest-scale checkpoint to an internal
dataset from a major pharmaceutical company, showing robust generalization
under distribution shift. With the new dimension that our framework unlocks, we
anticipate further acceleration in the development of even more accurate
models.

摘要：規劃和執行化學合成仍然是發現功能性小分子時的主要瓶頸，而且無法充分利用生成式 AI 進行分子逆向設計。儘管早期研究顯示，基於 ML 的逆合成模型可以預測合理的路線，但已指出其對較不常見但重要的反應的低準確度。由於多步驟搜尋演算法僅限於底層模型建議的反應，因此這些工具的適用性本質上受到逆合成預測準確度的限制。受到化學家使用不同策略構思反應的啟發，我們提出 Chimera：一個結合來自不同來源的預測，並使用基於學習的集成策略，具有互補歸納偏差的高準確度反應模型建構架構。我們使用兩個新開發的模型實例化該架構，它們本身已在各自的類別中達到最新技術。透過跨越數個數量級的資料規模和時間分割的實驗，我們展示 Chimera 在很大程度上優於所有主要模型，這歸功於其組成部分的良好個別效能，但也歸功於我們集成策略的可擴充性。此外，我們發現博士級的有機化學家在品質方面偏好 Chimera 的預測，而非基線。最後，我們將最大規模的檢查點轉移到一家主要製藥公司的內部資料集，顯示在分佈轉移下具有穩健的概括性。透過我們的架構解鎖的新面向，我們預期在開發更準確的模型方面將進一步加速。

##### **Reinforcement Learning: An Overview**
2412.05265v1 by Kevin Murphy

This manuscript gives a big-picture, up-to-date overview of the field of
(deep) reinforcement learning and sequential decision making, covering
value-based RL, policy-gradient methods, model-based methods, and various other
topics (including a very brief discussion of RL+LLMs).

摘要：這份手稿提供了關於（深度）強化學習和順序決策制定領域的全面且最新的概觀，涵蓋基於價值的 RL、策略梯度方法、基於模型的方法以及其他各種主題（包括對 RL+LLM 的非常簡短的討論）。

##### **Extrapolated Urban View Synthesis Benchmark**
2412.05256v1 by Xiangyu Han, Zhen Jia, Boyi Li, Yan Wang, Boris Ivanovic, Yurong You, Lingjie Liu, Yue Wang, Marco Pavone, Chen Feng, Yiming Li

Photorealistic simulators are essential for the training and evaluation of
vision-centric autonomous vehicles (AVs). At their core is Novel View Synthesis
(NVS), a crucial capability that generates diverse unseen viewpoints to
accommodate the broad and continuous pose distribution of AVs. Recent advances
in radiance fields, such as 3D Gaussian Splatting, achieve photorealistic
rendering at real-time speeds and have been widely used in modeling large-scale
driving scenes. However, their performance is commonly evaluated using an
interpolated setup with highly correlated training and test views. In contrast,
extrapolation, where test views largely deviate from training views, remains
underexplored, limiting progress in generalizable simulation technology. To
address this gap, we leverage publicly available AV datasets with multiple
traversals, multiple vehicles, and multiple cameras to build the first
Extrapolated Urban View Synthesis (EUVS) benchmark. Meanwhile, we conduct
quantitative and qualitative evaluations of state-of-the-art Gaussian Splatting
methods across different difficulty levels. Our results show that Gaussian
Splatting is prone to overfitting to training views. Besides, incorporating
diffusion priors and improving geometry cannot fundamentally improve NVS under
large view changes, highlighting the need for more robust approaches and
large-scale training. We have released our data to help advance self-driving
and urban robotics simulation technology.

摘要：逼真的模擬器對於以視覺為中心的自動駕駛車輛 (AV) 的訓練和評估至關重要。其核心是新視角合成 (NVS)，這是一項關鍵功能，可產生多樣化的未見視角，以適應自動駕駛車輛廣泛且連續的姿態分佈。最近在輻射場的進展，例如 3D 高斯潑濺，實現了實時速度的光寫實渲染，並已廣泛用於建模大規模駕駛場景。然而，它們的性能通常使用內插設置進行評估，其中訓練和測試視角高度相關。相比之下，外推（測試視角與訓練視角有很大偏差）仍然未得到充分探索，這限制了可概括模擬技術的進步。為了解決這個差距，我們利用具有多重穿越、多重車輛和多重相機的公開自動駕駛車輛數據集來構建第一個外推城市視角合成 (EUVS) 基準。同時，我們對最先進的高斯潑濺方法在不同難度級別上進行了定量和定性評估。我們的結果表明，高斯潑濺容易過度擬合訓練視角。此外，結合擴散先驗和改進幾何形狀無法從根本上改善大視角變化下的 NVS，這突顯了對更強大的方法和大規模訓練的需求。我們已經發布了我們的數據，以幫助推進自動駕駛和城市機器人模擬技術。

##### **TeamCraft: A Benchmark for Multi-Modal Multi-Agent Systems in Minecraft**
2412.05255v1 by Qian Long, Zhi Li, Ran Gong, Ying Nian Wu, Demetri Terzopoulos, Xiaofeng Gao

Collaboration is a cornerstone of society. In the real world, human teammates
make use of multi-sensory data to tackle challenging tasks in ever-changing
environments. It is essential for embodied agents collaborating in
visually-rich environments replete with dynamic interactions to understand
multi-modal observations and task specifications. To evaluate the performance
of generalizable multi-modal collaborative agents, we present TeamCraft, a
multi-modal multi-agent benchmark built on top of the open-world video game
Minecraft. The benchmark features 55,000 task variants specified by multi-modal
prompts, procedurally-generated expert demonstrations for imitation learning,
and carefully designed protocols to evaluate model generalization capabilities.
We also perform extensive analyses to better understand the limitations and
strengths of existing approaches. Our results indicate that existing models
continue to face significant challenges in generalizing to novel goals, scenes,
and unseen numbers of agents. These findings underscore the need for further
research in this area. The TeamCraft platform and dataset are publicly
available at https://github.com/teamcraft-bench/teamcraft.

摘要：協作是社會的基石。在現實世界中，人類隊友利用多感官數據來應對不斷變化的環境中的具有挑戰性的任務。對於在充滿動態交互作用的視覺豐富環境中協作的具體代理而言，理解多模式觀察和任務規範至關重要。為了評估可概括多模式協作代理的性能，我們提出了 TeamCraft，這是一個建立在開放世界視頻遊戲 Minecraft 之上的多模式多代理基準。該基準測試具有 55,000 個由多模式提示指定的任務變體、用於模仿學習的程序生成專家演示，以及精心設計的協議來評估模型泛化能力。我們還進行了廣泛的分析，以更好地了解現有方法的局限性和優勢。我們的結果表明，現有模型在概括到新的目標、場景和未見的代理數量方面仍然面臨重大挑戰。這些發現強調了進一步研究這一領域的必要性。TeamCraft 平台和數據集可在 https://github.com/teamcraft-bench/teamcraft 公開獲得。

##### **From classical techniques to convolution-based models: A review of object detection algorithms**
2412.05252v1 by Fnu Neha, Deepshikha Bhati, Deepak Kumar Shukla, Md Amiruzzaman

Object detection is a fundamental task in computer vision and image
understanding, with the goal of identifying and localizing objects of interest
within an image while assigning them corresponding class labels. Traditional
methods, which relied on handcrafted features and shallow models, struggled
with complex visual data and showed limited performance. These methods combined
low-level features with contextual information and lacked the ability to
capture high-level semantics. Deep learning, especially Convolutional Neural
Networks (CNNs), addressed these limitations by automatically learning rich,
hierarchical features directly from data. These features include both semantic
and high-level representations essential for accurate object detection. This
paper reviews object detection frameworks, starting with classical computer
vision methods. We categorize object detection approaches into two groups: (1)
classical computer vision techniques and (2) CNN-based detectors. We compare
major CNN models, discussing their strengths and limitations. In conclusion,
this review highlights the significant advancements in object detection through
deep learning and identifies key areas for further research to improve
performance.

摘要：物件偵測是電腦視覺和影像理解中的一項基本任務，目標是辨識和定位影像中的感興趣物件，同時為其指定對應的類別標籤。傳統方法依賴於手工特徵和淺層模型，在處理複雜的視覺資料時會遇到困難，效能也有限。這些方法將低階特徵與脈絡資訊結合，但缺乏擷取高階語意的能力。深度學習，特別是卷積神經網路 (CNN)，透過直接從資料中自動學習豐富的分層特徵來解決這些限制。這些特徵包含語意和高階表示，對於準確的物件偵測至關重要。本文回顧了物件偵測架構，從經典的電腦視覺方法開始。我們將物件偵測方法分類為兩組：(1) 經典電腦視覺技術和 (2) 基於 CNN 的偵測器。我們比較了主要的 CNN 模型，並討論其優點和限制。最後，本回顧強調了深度學習在物件偵測方面取得的重大進展，並找出進一步研究以提升效能的主要領域。

##### **Uncertainty Quantification for Transformer Models for Dark-Pattern Detection**
2412.05251v1 by Javier Muñoz, Álvaro Huertas-García, Carlos Martí-González, Enrique De Miguel Ambite

The opaque nature of transformer-based models, particularly in applications
susceptible to unethical practices such as dark-patterns in user interfaces,
requires models that integrate uncertainty quantification to enhance trust in
predictions. This study focuses on dark-pattern detection, deceptive design
choices that manipulate user decisions, undermining autonomy and consent. We
propose a differential fine-tuning approach implemented at the final
classification head via uncertainty quantification with transformer-based
pre-trained models. Employing a dense neural network (DNN) head architecture as
a baseline, we examine two methods capable of quantifying uncertainty:
Spectral-normalized Neural Gaussian Processes (SNGPs) and Bayesian Neural
Networks (BNNs). These methods are evaluated on a set of open-source
foundational models across multiple dimensions: model performance, variance in
certainty of predictions and environmental impact during training and inference
phases. Results demonstrate that integrating uncertainty quantification
maintains performance while providing insights into challenging instances
within the models. Moreover, the study reveals that the environmental impact
does not uniformly increase with the incorporation of uncertainty
quantification techniques. The study's findings demonstrate that uncertainty
quantification enhances transparency and provides measurable confidence in
predictions, improving the explainability and clarity of black-box models. This
facilitates informed decision-making and mitigates the influence of
dark-patterns on user interfaces. These results highlight the importance of
incorporating uncertainty quantification techniques in developing machine
learning models, particularly in domains where interpretability and
trustworthiness are critical.

摘要：<paragraph>基於Transformer的模型不透明的本質，特別是在容易受到不道德行為（例如使用者介面的暗模式）影響的應用中，需要整合不確定性量化以增強對預測的信任。本研究專注於暗模式偵測，也就是會操縱使用者決策、破壞自主性和同意的欺騙性設計選擇。我們提出一種差分微調方法，透過基於Transformer的預訓練模型的不確定性量化在最終分類標頭中實作。使用密集神經網路 (DNN) 標頭架構作為基準，我們檢視兩種能夠量化不確定性的方法：光譜正規化神經高斯過程 (SNGP) 和貝氏神經網路 (BNN)。這些方法在多個面向的開放原始碼基礎模型上進行評估：模型效能、預測確定性的變異以及訓練和推論階段的環境影響。結果表明，整合不確定性量化能維持效能，同時提供對模型中具挑戰性案例的見解。此外，研究顯示環境影響並不會隨著不確定性量化技術的納入而均勻增加。研究結果表明，不確定性量化能增強透明度，並提供可衡量的預測信心，進而提升黑箱模型的可解釋性和清晰度。這有助於明智的決策制定，並減輕暗模式對使用者介面的影響。這些結果突顯了在開發機器學習模型時納入不確定性量化技術的重要性，特別是在可解釋性和可信度至關重要的領域中。</paragraph>

##### **Enhancing FKG.in: automating Indian food composition analysis**
2412.05248v1 by Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Geeta Trilok-Kumar, Ramesh Jain

This paper presents a novel approach to compute food composition data for
Indian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The
primary focus is to provide a broad overview of an automated food composition
analysis workflow and describe its core functionalities: nutrition data
aggregation, food composition analysis, and LLM-augmented information
resolution. This workflow aims to complement FKG.in and iteratively supplement
food composition data from verified knowledge bases. Additionally, this paper
highlights the challenges of representing Indian food and accessing food
composition data digitally. It also reviews three key sources of food
composition data: the Indian Food Composition Tables, the Indian Nutrient
Databank, and the Nutritionix API. Furthermore, it briefly outlines how users
can interact with the workflow to obtain diet-based health recommendations and
detailed food composition information for numerous recipes. We then explore the
complex challenges of analyzing Indian recipe information across dimensions
such as structure, multilingualism, and uncertainty as well as present our
ongoing work on LLM-based solutions to address these issues. The methods
proposed in this workshop paper for AI-driven knowledge curation and
information resolution are application-agnostic, generalizable, and replicable
for any domain.

摘要：這篇論文提出一個創新的方法，使用印度食物知識圖譜 (FKG.in) 和大型語言模型 (LLM) 來計算印度食譜的食品成分資料。主要目標是提供自動化食品成分分析工作流程的概觀，並描述其核心功能：營養資料彙整、食品成分分析，以及 LLM 增強的資訊解析。此工作流程旨在補充 FKG.in，並反覆補充來自驗證知識庫的食品成分資料。此外，這篇論文強調了呈現印度食物和以數位方式存取食品成分資料的挑戰。它也檢視了食品成分資料的三個主要來源：印度食品成分表、印度營養資料庫，以及 Nutritionix API。此外，它簡要概述了使用者如何與工作流程互動，以取得基於飲食的健康建議和許多食譜的詳細食品成分資訊。接著我們探討分析印度食譜資訊的複雜挑戰，包括結構、多語言性，以及不確定性，並提出我們正在進行的 LLM 基礎解決方案來解決這些問題。這篇工作坊論文中提出的 AI 驅動知識策展和資訊解析方法與應用程式無關，可概括化，且可複製到任何領域。

##### **Enhancing Foundation Models for Time Series Forecasting via Wavelet-based Tokenization**
2412.05244v1 by Luca Masserano, Abdul Fatir Ansari, Boran Han, Xiyuan Zhang, Christos Faloutsos, Michael W. Mahoney, Andrew Gordon Wilson, Youngsuk Park, Syama Rangapuram, Danielle C. Maddix, Yuyang Wang

How to best develop foundational models for time series forecasting remains
an important open question. Tokenization is a crucial consideration in this
effort: what is an effective discrete vocabulary for a real-valued sequential
input? To address this question, we develop WaveToken, a wavelet-based
tokenizer that allows models to learn complex representations directly in the
space of time-localized frequencies. Our method first scales and decomposes the
input time series, then thresholds and quantizes the wavelet coefficients, and
finally pre-trains an autoregressive model to forecast coefficients for the
forecast horizon. By decomposing coarse and fine structures in the inputs,
wavelets provide an eloquent and compact language for time series forecasting
that simplifies learning. Empirical results on a comprehensive benchmark,
including 42 datasets for both in-domain and zero-shot settings, show that
WaveToken: i) provides better accuracy than recently proposed foundation models
for forecasting while using a much smaller vocabulary (1024 tokens), and
performs on par or better than modern deep learning models trained specifically
on each dataset; and ii) exhibits superior generalization capabilities,
achieving the best average rank across all datasets for three complementary
metrics. In addition, we show that our method can easily capture complex
temporal patterns of practical relevance that are challenging for other recent
pre-trained models, including trends, sparse spikes, and non-stationary time
series with varying frequencies evolving over time.

摘要：如何最佳地開發時間序列預測的基本模型仍然是一個重要的開放性問題。在此工作中，符號化是一個關鍵考量：對於一個實值序列輸入來說，什麼是一個有效的離散詞彙？為了解決這個問題，我們開發了 WaveToken，一個基於小波的符號化器，它允許模型直接在時域頻率的空間中學習複雜的表示。我們的模型首先對輸入時間序列進行縮放和分解，然後對小波係數進行閾值處理和量化，最後預訓練一個自迴歸模型來預測預測範圍內的係數。通過分解輸入中的粗糙和精細結構，小波為時間序列預測提供了一種簡潔而緊湊的語言，簡化了學習。在一個綜合基準上的經驗結果，包括 42 個用於域內和零次學習設置的數據集，表明 WaveToken：i) 在預測時提供了比最近提出的基礎模型更好的準確度，同時使用了更小的詞彙量（1024 個符號），並且在專門針對每個數據集訓練的現代深度學習模型中表現得一樣好或更好；並且 ii) 展現出卓越的泛化能力，對於三個互補指標，在所有數據集上實現了最佳平均排名。此外，我們表明，我們的模型可以輕鬆捕捉其他最近預訓練模型難以應對的複雜時間模式，包括趨勢、稀疏尖峰和隨著時間推移而演變的具有不同頻率的非平穩時間序列。

##### **CompCap: Improving Multimodal Large Language Models with Composite Captions**
2412.05243v1 by Xiaohui Chen, Satya Narayan Shukla, Mahmoud Azab, Aashu Singh, Qifan Wang, David Yang, ShengYun Peng, Hanchao Yu, Shen Yan, Xuewen Zhang, Baosheng He

How well can Multimodal Large Language Models (MLLMs) understand composite
images? Composite images (CIs) are synthetic visuals created by merging
multiple visual elements, such as charts, posters, or screenshots, rather than
being captured directly by a camera. While CIs are prevalent in real-world
applications, recent MLLM developments have primarily focused on interpreting
natural images (NIs). Our research reveals that current MLLMs face significant
challenges in accurately understanding CIs, often struggling to extract
information or perform complex reasoning based on these images. We find that
existing training data for CIs are mostly formatted for question-answer tasks
(e.g., in datasets like ChartQA and ScienceQA), while high-quality
image-caption datasets, critical for robust vision-language alignment, are only
available for NIs. To bridge this gap, we introduce Composite Captions
(CompCap), a flexible framework that leverages Large Language Models (LLMs) and
automation tools to synthesize CIs with accurate and detailed captions. Using
CompCap, we curate CompCap-118K, a dataset containing 118K image-caption pairs
across six CI types. We validate the effectiveness of CompCap-118K by
supervised fine-tuning MLLMs of three sizes: xGen-MM-inst.-4B and
LLaVA-NeXT-Vicuna-7B/13B. Empirical results show that CompCap-118K
significantly enhances MLLMs' understanding of CIs, yielding average gains of
1.7%, 2.0%, and 2.9% across eleven benchmarks, respectively.

摘要：多模態大型語言模型 (MLLM) 能有多好地理解合成影像？合成影像 (CI) 是透過合併多個視覺元素（例如圖表、海報或螢幕截圖）所建立的合成視覺效果，而不是直接由相機拍攝。儘管 CI 在現實世界的應用中很普遍，但最近的 MLLM 發展主要集中在詮釋自然影像 (NI)。我們的研究顯示，現有的 MLLM 在準確理解 CI 時面臨重大挑戰，經常難以根據這些影像擷取資訊或執行複雜的推理。我們發現，CI 的現有訓練資料大多以問答任務的格式呈現（例如 ChartQA 和 ScienceQA 等資料集），而對於穩健的視覺語言對齊至關重要的優質影像標題資料集僅適用於 NI。為了彌補這個差距，我們引入了合成標題 (CompCap)，這是一個靈活的架構，利用大型語言模型 (LLM) 和自動化工具來合成具有準確且詳細標題的 CI。使用 CompCap，我們整理了 CompCap-118K，一個包含 118K 影像標題對應的資料集，涵蓋六種類型的 CI。我們透過監督微調三種尺寸的 MLLM 來驗證 CompCap-118K 的有效性：xGen-MM-inst.-4B 和 LLaVA-NeXT-Vicuna-7B/13B。經驗結果顯示，CompCap-118K 大幅提升了 MLLM 對 CI 的理解，在 11 個基準中分別產生了平均 1.7%、2.0% 和 2.9% 的增益。

##### **MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale**
2412.05237v1 by Jarvis Guo, Tuney Zheng, Yuelin Bai, Bo Li, Yubo Wang, King Zhu, Yizhi Li, Graham Neubig, Wenhu Chen, Xiang Yue

Open-source multimodal large language models (MLLMs) have shown significant
potential in a broad range of multimodal tasks. However, their reasoning
capabilities remain constrained by existing instruction-tuning datasets, which
were predominately repurposed from academic datasets such as VQA, AI2D, and
ChartQA. These datasets target simplistic tasks, and only provide phrase-level
answers without any intermediate rationales. To address these challenges, we
introduce a scalable and cost-effective method to construct a large-scale
multimodal instruction-tuning dataset with rich intermediate rationales
designed to elicit CoT reasoning. Using only open models, we create a dataset
containing 12M instruction-response pairs to cover diverse, reasoning-intensive
tasks with detailed and faithful rationales. Experiments demonstrate that
training MLLMs on this dataset significantly improves reasoning capabilities,
achieving state-of-the-art performance on benchmarks such as MathVerse (+8.1%),
MMMU-Pro (+7%), and MuirBench (+13.3%). Additionally, the model demonstrates
notable improvements of up to 4% on non-reasoning-based benchmarks. Ablation
studies further highlight the importance of key components, such as rewriting
and self-filtering, in the dataset construction process.

摘要：開放原始碼多模態大型語言模型 (MLLM) 已在廣泛的多模態任務中展現顯著潛力。然而，其推理能力仍受限於現有的指令調整資料集，而這些資料集主要改編自學術資料集，例如 VQA、AI2D 和 ChartQA。這些資料集鎖定簡化的任務，而且僅提供片語層級的答案，而沒有任何中間的依據。為了應對這些挑戰，我們引進一種可擴充且具成本效益的方法，以建構一個大型多模態指令調整資料集，其中包含豐富的中間依據，旨在引發 CoT 推理。我們僅使用開放模型，就能建立一個包含 1200 萬個指令回應配對的資料集，涵蓋各種推理密集型任務，並具備詳細且忠實的依據。實驗證明，在這個資料集上訓練 MLLM 能顯著提升推理能力，在 MathVerse (+8.1%)、MMMU-Pro (+7%) 和 MuirBench (+13.3%) 等基準測試中獲得最先進的效能。此外，該模型在非基於推理的基準測試中展現出高達 4% 的顯著進步。消融研究進一步突顯了關鍵組成要素（例如在資料集建構過程中進行改寫和自我過濾）的重要性。

##### **LIAR: Leveraging Alignment (Best-of-N) to Jailbreak LLMs in Seconds**
2412.05232v1 by James Beetham, Souradip Chakraborty, Mengdi Wang, Furong Huang, Amrit Singh Bedi, Mubarak Shah

Many existing jailbreak techniques rely on solving discrete combinatorial
optimization, while more recent approaches involve training LLMs to generate
multiple adversarial prompts. However, both approaches require significant
computational resources to produce even a single adversarial prompt. We
hypothesize that the inefficiency of current approaches stems from an
inadequate characterization of the jailbreak problem. To address this gap, we
formulate the jailbreak problem in terms of alignment. By starting from an
available safety-aligned model, we leverage an unsafe reward to guide the safe
model towards generating unsafe outputs using alignment techniques (e.g.,
reinforcement learning from human feedback), effectively performing
jailbreaking via alignment. We propose a novel jailbreak method called LIAR
(LeveragIng Alignment to jailbReak). To demonstrate the simplicity and
effectiveness of our approach, we employ a best-of-N method to solve the
alignment problem. LIAR offers significant advantages: lower computational
requirements without additional training, fully black-box operation,
competitive attack success rates, and more human-readable prompts. We provide
theoretical insights into the possibility of jailbreaking a safety-aligned
model, revealing inherent vulnerabilities in current alignment strategies for
LLMs. We also provide sub-optimality guarantees for the proposed \algo.
Experimentally, we achieve ASR comparable to the SoTA with a 10x improvement to
perplexity and a Time-to-Attack measured in seconds rather than tens of hours.

摘要：許多現有的越獄技術依賴於解決離散組合最佳化，而較新的方法則涉及訓練 LLM 以產生多個對抗提示。然而，這兩種方法都需要大量的計算資源才能產生單一的對抗提示。我們假設當前方法的低效率源於對越獄問題的不充分表徵。為了解決這個差距，我們根據對齊來制定越獄問題。從一個可用的安全對齊模型開始，我們利用不安全的獎勵來引導安全模型使用對齊技術（例如，從人類回饋中進行強化學習）產生不安全的輸出，有效地通過對齊進行越獄。我們提出了一種名為 LIAR（LeveragIng Alignment to jailbReak）的新型越獄方法。為了展示我們方法的簡單性和有效性，我們採用 N 中最佳方法來解決對齊問題。LIAR 提供顯著的優勢：無需額外訓練即可降低計算要求、完全黑盒操作、具有競爭力的攻擊成功率以及更具可讀性的提示。我們提供了對越獄安全對齊模型的可能性的理論見解，揭示了當前 LLM 對齊策略中固有的漏洞。我們還為提出的演算法提供次優保證。在實驗中，我們實現了與 SoTA 相當的 ASR，困惑度提高了 10 倍，攻擊時間以秒為單位衡量，而不是以數十小時為單位。

##### **BEExformer: A Fast Inferencing Transformer Architecture via Binarization with Multiple Early Exits**
2412.05225v1 by Wazib Ansar, Saptarsi Goswami, Amlan Chakrabarti

Large Language Models (LLMs) based on transformers achieve cutting-edge
results on a variety of applications. However, their enormous size and
processing requirements make deployment on devices with constrained resources
extremely difficult. Among various efficiency considerations, model
binarization and Early Exit (EE) are common effective solutions. However,
binarization may lead to performance loss due to reduced precision affecting
gradient estimation and parameter updates. Besides, the present early-exit
mechanisms are still in the nascent stages of research. To ameliorate these
issues, we propose Binarized Early Exit Transformer (BEExformer), the
first-ever selective learning transformer architecture to combine early exit
with binarization for textual inference. It improves the binarization process
through a differentiable second-order approximation to the impulse function.
This enables gradient computation concerning both the sign as well as the
magnitude of the weights. In contrast to absolute threshold-based EE, the
proposed EE mechanism hinges on fractional reduction in entropy among
intermediate transformer blocks with soft-routing loss estimation. While
binarization results in 18.44 times reduction in model size, early exit reduces
the FLOPs during inference by 54.85% and even improves accuracy by 5.98%
through resolving the "overthinking" problem inherent in deep networks.
Moreover, the proposed BEExformer simplifies training by not requiring
knowledge distillation from a full-precision LLM. Extensive evaluation on the
GLUE dataset and comparison with the SOTA works showcase its pareto-optimal
performance-efficiency trade-off.

摘要：<paragraph>基於Transformer的巨量語言模型 (LLM) 在各種應用上都能達到尖端的結果。然而，它們龐大的規模和處理需求讓在資源受限的裝置上部署變得極其困難。在各種效率考量中，模型二元化和早期退出 (EE) 是常見的有效方案。然而，二元化可能會導致效能損失，因為降低的精度會影響梯度估計和參數更新。此外，現有的早期退出機制仍處於研究的萌芽階段。為了改善這些問題，我們提出了二元化早期退出Transformer (BEExformer)，這是第一個結合早期退出與二元化的選擇性學習Transformer架構，用於文字推論。它透過對脈衝函數進行可微分的二階近似來改善二元化程序。這使得梯度計算與權重的符號和大小都有關。與基於絕對閾值的 EE 相比，提議的 EE 機制取決於中間Transformer區塊之間熵的分數減少，並具有軟路由損失估計。雖然二元化導致模型大小減少了 18.44 倍，但早期退出將推論期間的 FLOP 減少了 54.85%，甚至透過解決深度網路中固有的「過度思考」問題而將準確度提升了 5.98%。此外，所提出的 BEExformer 簡化了訓練，因為不需要從全精度 LLM 進行知識蒸餾。在 GLUE 資料集上的廣泛評估以及與 SOTA 作品的比較展示了其帕累托最優的效能效率權衡。</paragraph>

##### **100% Hallucination Elimination Using Acurai**
2412.05223v1 by Michael C. Wood, Adam A. Forbes

The issue of hallucinations in large language models (LLMs) remains a
critical barrier to the adoption of AI in enterprise and other high-stakes
applications. Despite advancements in retrieval-augmented generation (RAG)
systems, current state-of-the-art methods fail to achieve more than 80%
accuracy in generating faithful and factually correct outputs, even when
provided with relevant and accurate context. In this work, we introduce Acurai,
a novel systematic approach that achieves 100% hallucination-free responses in
LLMs by reformatting queries and context data prior to input. Leveraging a deep
understanding of LLM internal representations, the importance of noun-phrase
dominance, and the role of discrete functional units (DFUs), Acurai ensures
alignment between input context and generated output. We validate this method
using the RAGTruth corpus, demonstrating its ability to eliminate 100%
hallucinations for both GPT-4 and GPT-3.5 Turbo. Acurai sets a new standard for
achieving consistent, accurate, and faithful AI responses, marking a
significant step forward in the development of trustworthy AI systems.

摘要：大型語言模型（LLM）中的幻覺問題仍然是企業和其他高風險應用中採用 AI 的關鍵障礙。儘管檢索增強生成（RAG）系統取得了進展，但現有的最先進方法在生成忠實且事實正確的輸出方面無法達到 80% 以上的準確度，即使在提供了相關且準確的背景下也是如此。在這項工作中，我們引入了 Acurai，這是一種新穎的系統化方法，通過在輸入之前重新格式化查詢和上下文數據，在 LLM 中實現 100% 無幻覺的回應。Acurai 利用對 LLM 內部表示、名詞短語支配的重要性以及離散功能單元（DFU）作用的深入理解，確保輸入上下文和生成的輸出之間的一致性。我們使用 RAGTruth 語料庫驗證了此方法，證明了它消除 GPT-4 和 GPT-3.5 Turbo 的 100% 幻覺的能力。Acurai 為實現一致、準確和忠實的 AI 響應設定了新的標準，標誌著可信賴 AI 系統開發向前邁出了重要一步。

##### **Evaluating and Aligning CodeLLMs on Human Preference**
2412.05210v1 by Jian Yang, Jiaxi Yang, Ke Jin, Yibo Miao, Lei Zhang, Liqun Yang, Zeyu Cui, Yichang Zhang, Binyuan Hui, Junyang Lin

Code large language models (codeLLMs) have made significant strides in code
generation. Most previous code-related benchmarks, which consist of various
programming exercises along with the corresponding test cases, are used as a
common measure to evaluate the performance and capabilities of code LLMs.
However, the current code LLMs focus on synthesizing the correct code snippet,
ignoring the alignment with human preferences, where the query should be
sampled from the practical application scenarios and the model-generated
responses should satisfy the human preference. To bridge the gap between the
model-generated response and human preference, we present a rigorous
human-curated benchmark CodeArena to emulate the complexity and diversity of
real-world coding tasks, where 397 high-quality samples spanning 40 categories
and 44 programming languages, carefully curated from user queries. Further, we
propose a diverse synthetic instruction corpus SynCode-Instruct (nearly 20B
tokens) by scaling instructions from the website to verify the effectiveness of
the large-scale synthetic instruction fine-tuning, where Qwen2.5-SynCoder
totally trained on synthetic instruction data can achieve top-tier performance
of open-source code LLMs. The results find performance differences between
execution-based benchmarks and CodeArena. Our systematic experiments of
CodeArena on 40+ LLMs reveal a notable performance gap between open SOTA code
LLMs (e.g. Qwen2.5-Coder) and proprietary LLMs (e.g., OpenAI o1), underscoring
the importance of the human preference
alignment.\footnote{\url{https://codearenaeval.github.io/ }}

摘要：<paragraph>大型語言模型（codeLLM）在程式碼生成方面取得了顯著進展。大多數先前的程式碼相關基準，包含各種程式設計練習以及對應的測試案例，用作評估 code LLM 效能和功能的常見測量標準。然而，目前的 code LLM 專注於合成正確的程式碼片段，忽略與人類偏好的對齊，其中查詢應從實際應用情境中抽樣，而模型產生的回應應滿足人類偏好。為了彌合模型產生的回應與人類偏好之間的差距，我們提出了一個嚴謹的人工策展基準 CodeArena，以模擬真實世界程式設計任務的複雜性和多樣性，其中 397 個高品質範例涵蓋 40 個類別和 44 種程式語言，從使用者查詢中仔細策展。此外，我們提出了一個多樣化的合成指令語料庫 SynCode-Instruct（將近 20B 個代幣），透過擴充網站上的指令來驗證大規模合成指令微調的有效性，其中 Qwen2.5-SynCoder 完全訓練於合成指令資料，可以達到開放原始碼 code LLM 的頂級效能。結果發現基於執行的基準和 CodeArena 之間的效能差異。我們在 40 多個 LLM 上進行 CodeArena 的系統性實驗，揭示了開放 SOTA code LLM（例如 Qwen2.5-Coder）和專有 LLM（例如 OpenAI o1）之間顯著的效能差距，強調了人類偏好對齊的重要性。\footnote{\url{https://codearenaeval.github.io/ }}</paragraph>

##### **A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges**
2412.05208v1 by Aditi Singh, Akash Shetty, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei

Text-to-SQL systems facilitate smooth interaction with databases by
translating natural language queries into Structured Query Language (SQL),
bridging the gap between non-technical users and complex database management
systems. This survey provides a comprehensive overview of the evolution of
AI-driven text-to-SQL systems, highlighting their foundational components,
advancements in large language model (LLM) architectures, and the critical role
of datasets such as Spider, WikiSQL, and CoSQL in driving progress. We examine
the applications of text-to-SQL in domains like healthcare, education, and
finance, emphasizing their transformative potential for improving data
accessibility. Additionally, we analyze persistent challenges, including domain
generalization, query optimization, support for multi-turn conversational
interactions, and the limited availability of datasets tailored for NoSQL
databases and dynamic real-world scenarios. To address these challenges, we
outline future research directions, such as extending text-to-SQL capabilities
to support NoSQL databases, designing datasets for dynamic multi-turn
interactions, and optimizing systems for real-world scalability and robustness.
By surveying current advancements and identifying key gaps, this paper aims to
guide the next generation of research and applications in LLM-based text-to-SQL
systems.

摘要：文本转 SQL 系统通过将自然语言查询转换为结构化查询语言 (SQL) 来促进与数据库的顺畅交互，弥合非技术用户与复杂数据库管理系统之间的差距。本调查全面概述了 AI 驱动的文本转 SQL 系统的演变，重点介绍了其基础组件、大语言模型 (LLM) 架构的进步以及 Spider、WikiSQL 和 CoSQL 等数据集在推动进步中的关键作用。我们研究了文本转 SQL 在医疗保健、教育和金融等领域的应用，强调了它们在提高数据可访问性方面的变革潜力。此外，我们分析了持续存在的挑战，包括领域泛化、查询优化、对多轮对话交互的支持以及针对 NoSQL 数据库和动态真实世界场景定制的数据集的可用性有限。为了应对这些挑战，我们概述了未来的研究方向，例如扩展文本转 SQL 功能以支持 NoSQL 数据库、为动态多轮交互设计数据集以及优化系统以实现实际世界的可扩展性和鲁棒性。通过调查当前的进步并找出关键差距，本文旨在指导基于 LLM 的文本转 SQL 系统的下一代研究和应用。

##### **ConQRet: Benchmarking Fine-Grained Evaluation of Retrieval Augmented Argumentation with LLM Judges**
2412.05206v1 by Kaustubh D. Dhole, Kai Shu, Eugene Agichtein

Computational argumentation, which involves generating answers or summaries
for controversial topics like abortion bans and vaccination, has become
increasingly important in today's polarized environment. Sophisticated LLM
capabilities offer the potential to provide nuanced, evidence-based answers to
such questions through Retrieval-Augmented Argumentation (RAArg), leveraging
real-world evidence for high-quality, grounded arguments. However, evaluating
RAArg remains challenging, as human evaluation is costly and difficult for
complex, lengthy answers on complicated topics. At the same time, re-using
existing argumentation datasets is no longer sufficient, as they lack long,
complex arguments and realistic evidence from potentially misleading sources,
limiting holistic evaluation of retrieval effectiveness and argument quality.
To address these gaps, we investigate automated evaluation methods using
multiple fine-grained LLM judges, providing better and more interpretable
assessments than traditional single-score metrics and even previously reported
human crowdsourcing. To validate the proposed techniques, we introduce ConQRet,
a new benchmark featuring long and complex human-authored arguments on debated
topics, grounded in real-world websites, allowing an exhaustive evaluation
across retrieval effectiveness, argument quality, and groundedness. We validate
our LLM Judges on a prior dataset and the new ConQRet benchmark. Our proposed
LLM Judges and the ConQRet benchmark can enable rapid progress in computational
argumentation and can be naturally extended to other complex
retrieval-augmented generation tasks.

摘要：計算論證，涉及生成答案或摘要，例如墮胎禁令和疫苗接種等有爭議的主題，在當今兩極分化的環境中變得越來越重要。先進的 LLM 能力提供了通過檢索增強論證 (RAArg) 為此類問題提供細緻入微、基於證據的答案的潛力，利用現實世界的證據進行高質量、有根據的論證。然而，評估 RAArg 仍然具有挑戰性，因為對於複雜、冗長的關於複雜主題的答案，人工評估既昂貴又困難。與此同時，重複使用現有的論證數據集不再足夠，因為它們缺乏來自潛在誤導來源的長篇、複雜的論證和現實證據，限制了檢索有效性和論證質量的整體評估。為了解決這些差距，我們使用多個細粒度的 LLM 評委研究了自動化評估方法，提供了比傳統單分數指標甚至先前報告的人工眾包更好的、更具可解釋性的評估。為了驗證所提出的技術，我們引入了 ConQRet，這是一個新的基準，其中包含在有爭議的主題上由人類撰寫的長篇且複雜的論證，基於現實世界的網站，允許對檢索有效性、論證質量和依據性進行全面評估。我們在先前的數據集和新的 ConQRet 基準上驗證了我們的 LLM 評委。我們提出的 LLM 評委和 ConQRet 基準可以使計算論證快速進步，並可以自然地擴展到其他複雜的檢索增強生成任務。

##### **Archaeoscape: Bringing Aerial Laser Scanning Archaeology to the Deep Learning Era**
2412.05203v1 by Yohann Perron, Vladyslav Sydorov, Adam P. Wijker, Damian Evans, Christophe Pottier, Loic Landrieu

Airborne Laser Scanning (ALS) technology has transformed modern archaeology
by unveiling hidden landscapes beneath dense vegetation. However, the lack of
expert-annotated, open-access resources has hindered the analysis of ALS data
using advanced deep learning techniques. We address this limitation with
Archaeoscape (available at https://archaeoscape.ai), a novel large-scale
archaeological ALS dataset spanning 888 km$^2$ in Cambodia with 31,141
annotated archaeological features from the Angkorian period. Archaeoscape is
over four times larger than comparable datasets, and the first ALS archaeology
resource with open-access data, annotations, and models.
  We benchmark several recent segmentation models to demonstrate the benefits
of modern vision techniques for this problem and highlight the unique
challenges of discovering subtle human-made structures under dense jungle
canopies. By making Archaeoscape available in open access, we hope to bridge
the gap between traditional archaeology and modern computer vision methods.

摘要：<paragraph>機載雷射掃描（ALS）技術透過揭露茂密植被下的隱藏景觀，轉變了現代考古學。然而，缺乏專家註釋、開放存取的資源阻礙了使用先進深度學習技術分析 ALS 資料。我們利用 Archaeoscape（可於 https://archaeoscape.ai 取得）來解決這個限制，這是一個新穎的大規模考古 ALS 資料集，涵蓋柬埔寨 888 平方公里的範圍，並有 31,141 個來自吳哥時期的考古特徵註釋。Archaeoscape 比同類資料集大四倍以上，並且是第一個具有開放存取資料、註釋和模型的 ALS 考古資源。
我們對幾個最近的分割模型進行基準測試，以展示現代視覺技術對此問題的好處，並強調在茂密的叢林樹冠下發現細微人造結構的獨特挑戰。透過開放存取 Archaeoscape，我們希望縮小傳統考古學和現代電腦視覺方法之間的差距。</paragraph>

##### **Are Frontier Large Language Models Suitable for Q&A in Science Centres?**
2412.05200v1 by Jacob Watson, Fabrício Góes, Marco Volpe, Talles Medeiros

This paper investigates the suitability of frontier Large Language Models
(LLMs) for Q&A interactions in science centres, with the aim of boosting
visitor engagement while maintaining factual accuracy. Using a dataset of
questions collected from the National Space Centre in Leicester (UK), we
evaluated responses generated by three leading models: OpenAI's GPT-4, Claude
3.5 Sonnet, and Google Gemini 1.5. Each model was prompted for both standard
and creative responses tailored to an 8-year-old audience, and these responses
were assessed by space science experts based on accuracy, engagement, clarity,
novelty, and deviation from expected answers. The results revealed a trade-off
between creativity and accuracy, with Claude outperforming GPT and Gemini in
both maintaining clarity and engaging young audiences, even when asked to
generate more creative responses. Nonetheless, experts observed that higher
novelty was generally associated with reduced factual reliability across all
models. This study highlights the potential of LLMs in educational settings,
emphasizing the need for careful prompt engineering to balance engagement with
scientific rigor.

摘要：這篇論文探討前沿大型語言模型 (LLM) 在科學中心問答互動中的適用性，目的是在維持事實準確性的同時提升訪客參與度。我們使用從英國萊斯特國家太空中心收集的提問資料集，評估了三個領先模型生成的回應：OpenAI 的 GPT-4、Claude 3.5 Sonnet 和 Google Gemini 1.5。每個模型都被提示針對 8 歲的受眾量身打造標準和有創意的回應，而這些回應則由太空科學專家根據準確性、參與度、清晰度、新穎性和與預期答案的偏差進行評估。結果顯示創造力與準確性之間存在權衡，Claude 在維持清晰度和吸引年輕受眾方面優於 GPT 和 Gemini，即使被要求產生更多有創意的回應。儘管如此，專家們觀察到，所有模型中較高的新穎性通常與較低的實際可靠性相關。這項研究強調了 LLM 在教育環境中的潛力，並強調需要仔細提示工程以平衡參與度和科學嚴謹性。

##### **SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**
2412.05187v1 by Jinlin Wu, Xusheng Liang, Xuexue Bai, Zhen Chen

Surgical interventions, particularly in neurology, represent complex and
high-stakes scenarios that impose substantial cognitive burdens on surgical
teams. Although deliberate education and practice can enhance cognitive
capabilities, surgical training opportunities remain limited due to patient
safety concerns. To address these cognitive challenges in surgical training and
operation, we propose SurgBox, an agent-driven sandbox framework to
systematically enhance the cognitive capabilities of surgeons in immersive
surgical simulations. Specifically, our SurgBox leverages large language models
(LLMs) with tailored Retrieval-Augmented Generation (RAG) to authentically
replicate various surgical roles, enabling realistic training environments for
deliberate practice. In particular, we devise Surgery Copilot, an AI-driven
assistant to actively coordinate the surgical information stream and support
clinical decision-making, thereby diminishing the cognitive workload of
surgical teams during surgery. By incorporating a novel Long-Short Memory
mechanism, our Surgery Copilot can effectively balance immediate procedural
assistance with comprehensive surgical knowledge. Extensive experiments using
real neurosurgical procedure records validate our SurgBox framework in both
enhancing surgical cognitive capabilities and supporting clinical
decision-making. By providing an integrated solution for training and
operational support to address cognitive challenges, our SurgBox framework
advances surgical education and practice, potentially transforming surgical
outcomes and healthcare quality. The code is available at
https://github.com/franciszchen/SurgBox.

摘要：外科手術，特別是在神經外科，代表了複雜且高風險的場景，對外科團隊施加了巨大的認知負擔。儘管經過深思熟慮的教育和實踐可以增強認知能力，但由於患者安全問題，外科培訓機會仍然有限。為了應對外科培訓和手術中的這些認知挑戰，我們提出了 SurgBox，一個由代理驅動的沙盒框架，用於系統地增強外科醫生在沉浸式外科模擬中的認知能力。具體來說，我們的 SurgBox 利用大型語言模型 (LLM) 和量身定制的檢索增強生成 (RAG) 來真實地複製各種外科角色，為深思熟慮的實踐提供逼真的培訓環境。特別是，我們設計了手術副駕駛，一個由 AI 驅動的助手，用於主動協調外科信息流並支持臨床決策制定，從而減少外科團隊在手術期間的認知負擔。通過結合一種新穎的長短期記憶機制，我們的 Surgery Copilot 可以有效地平衡即時程序協助和全面的外科知識。使用真實的神經外科手術記錄進行的廣泛實驗驗證了我們的 SurgBox 框架，既能增強外科認知能力，又能支持臨床決策制定。通過提供一個綜合的培訓和運營支持解決方案來應對認知挑戰，我們的 SurgBox 框架推動了外科教育和實踐，有可能改變外科結果和醫療保健質量。代碼可在 https://github.com/franciszchen/SurgBox 獲得。

##### **QueEn: A Large Language Model for Quechua-English Translation**
2412.05184v1 by Junhao Chen, Peng Shu, Yiwei Li, Huaqin Zhao, Hanqi Jiang, Yi Pan, Yifan Zhou, Zhengliang Liu, Lewis C Howe, Tianming Liu

Recent studies show that large language models (LLMs) are powerful tools for
working with natural language, bringing advances in many areas of computational
linguistics. However, these models face challenges when applied to low-resource
languages due to limited training data and difficulty in understanding cultural
nuances. In this paper, we propose QueEn, a novel approach for Quechua-English
translation that combines Retrieval-Augmented Generation (RAG) with
parameter-efficient fine-tuning techniques. Our method leverages external
linguistic resources through RAG and uses Low-Rank Adaptation (LoRA) for
efficient model adaptation. Experimental results show that our approach
substantially exceeds baseline models, with a BLEU score of 17.6 compared to
1.5 for standard GPT models. The integration of RAG with fine-tuning allows our
system to address the challenges of low-resource language translation while
maintaining computational efficiency. This work contributes to the broader goal
of preserving endangered languages through advanced language technologies.

摘要：最近的研究表明大型语言模型 (LLM) 是處理自然語言的強大工具，為計算語言學的許多領域帶來進展。然而，這些模型在應用於低資源語言時會面臨挑戰，原因是訓練資料有限，且難以理解文化差異。在本文中，我們提出 QueEn，這是一種 Quechua-English 翻譯的新方法，它結合了檢索增強生成 (RAG) 與參數有效微調技術。我們的模型透過 RAG 利用外部語言資源，並使用低秩適應 (LoRA) 進行有效的模型適應。實驗結果表明，我們的模型大幅超越基準模型，BLEU 分數為 17.6，而標準 GPT 模型為 1.5。RAG 與微調的整合使我們的系統能夠解決低資源語言翻譯的挑戰，同時維持計算效率。這項工作有助於透過先進的語言技術來保存瀕危語言的更廣泛目標。

##### **Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models**
2412.05167v1 by Kuofeng Gao, Shu-Tao Xia, Ke Xu, Philip Torr, Jindong Gu

Large Audio-Language Models (LALMs) have unclocked audio dialogue
capabilities, where audio dialogues are a direct exchange of spoken language
between LALMs and humans. Recent advances, such as GPT-4o, have enabled LALMs
in back-and-forth audio dialogues with humans. This progression not only
underscores the potential of LALMs but also broadens their applicability across
a wide range of practical scenarios supported by audio dialogues. However,
given these advancements, a comprehensive benchmark to evaluate the performance
of LALMs in the open-ended audio dialogue understanding remains absent
currently. To address this gap, we propose an Audio Dialogue Understanding
Benchmark (ADU-Bench), which consists of 4 benchmark datasets. They assess the
open-ended audio dialogue ability for LALMs in 3 general scenarios, 12 skills,
9 multilingual languages, and 4 categories of ambiguity handling. Notably, we
firstly propose the evaluation of ambiguity handling in audio dialogues that
expresses different intentions beyond the same literal meaning of sentences,
e.g., "Really!?" with different intonations. In summary, ADU-Bench includes
over 20,000 open-ended audio dialogues for the assessment of LALMs. Through
extensive experiments conducted on 13 LALMs, our analysis reveals that there is
still considerable room for improvement in the audio dialogue understanding
abilities of existing LALMs. In particular, they struggle with mathematical
symbols and formulas, understanding human behavior such as roleplay,
comprehending multiple languages, and handling audio dialogue ambiguities from
different phonetic elements, such as intonations, pause positions, and
homophones.

摘要：大型語言音訊模型 (LALM) 已解鎖音訊對話能力，其中音訊對話是 LALM 與人類之間口語的直接交流。最近的進展，例如 GPT-4o，已讓 LALM 能與人類進行來回音訊對話。此進展不僅強調 LALM 的潛力，也擴展其在音訊對話支援的各種實際場景中的適用性。然而，考量這些進展，目前仍缺乏一個全面的基準來評估 LALM 在開放式音訊對話理解中的表現。為了解決此差距，我們提出一個音訊對話理解基準 (ADU-Bench)，其中包含 4 個基準資料集。它們評估 LALM 在 3 個一般場景、12 項技能、9 種多語言和 4 類含糊性處理中的開放式音訊對話能力。值得注意的是，我們首先提出評估音訊對話中的含糊性處理，其表達了超出句子相同字面意義的不同意圖，例如語調不同的「真的嗎？」。總之，ADU-Bench 包含超過 20,000 個開放式音訊對話，用於評估 LALM。透過對 13 個 LALM 進行廣泛的實驗，我們的分析顯示，現有 LALM 的音訊對話理解能力仍有很大的改進空間。特別是，他們在數學符號和公式、理解角色扮演等人類行為、理解多種語言以及處理來自不同語音元素（例如語調、停頓位置和同音異義詞）的音訊對話含糊性方面遇到了困難。

##### **DNF: Unconditional 4D Generation with Dictionary-based Neural Fields**
2412.05161v1 by Xinyi Zhang, Naiqi Li, Angela Dai

While remarkable success has been achieved through diffusion-based 3D
generative models for shapes, 4D generative modeling remains challenging due to
the complexity of object deformations over time. We propose DNF, a new 4D
representation for unconditional generative modeling that efficiently models
deformable shapes with disentangled shape and motion while capturing
high-fidelity details in the deforming objects. To achieve this, we propose a
dictionary learning approach to disentangle 4D motion from shape as neural
fields. Both shape and motion are represented as learned latent spaces, where
each deformable shape is represented by its shape and motion global latent
codes, shape-specific coefficient vectors, and shared dictionary information.
This captures both shape-specific detail and global shared information in the
learned dictionary. Our dictionary-based representation well balances fidelity,
contiguity and compression -- combined with a transformer-based diffusion
model, our method is able to generate effective, high-fidelity 4D animations.

摘要：儘管在形狀的基於擴散的 3D 生成模型中獲得了顯著的成功，但由於物件隨時間變形的複雜性，4D 生成模型仍然具有挑戰性。我們提出 DNF，這是一種新的 4D 表示法，用於無條件生成模型，該模型有效地對可變形形狀進行建模，同時分離形狀和運動，並捕捉變形物件中的高保真細節。為實現此目的，我們提出了一種字典學習方法，將 4D 運動從形狀中分離出來，作為神經場。形狀和運動都表示為學習到的潛在空間，其中每個可變形形狀由其形狀和運動全局潛在代碼、特定於形狀的係數向量和共享字典資訊表示。這會捕捉學習到的字典中的特定於形狀的細節和全局共享資訊。我們基於字典的表示很好地平衡了保真度、連續性和壓縮性——結合基於Transformer的擴散模型，我們的方法能夠生成有效的高保真 4D 動畫。

##### **Enhancing Cross-Language Code Translation via Task-Specific Embedding Alignment in Retrieval-Augmented Generation**
2412.05159v1 by Manish Bhattarai, Minh Vu, Javier E. Santos, Ismael Boureima, Daniel O' Malley

We introduce a novel method to enhance cross-language code translation from
Fortran to C++ by integrating task-specific embedding alignment into a
Retrieval-Augmented Generation (RAG) framework. Unlike conventional retrieval
approaches that utilize generic embeddings agnostic to the downstream task, our
strategy aligns the retrieval model directly with the objective of maximizing
translation quality, as quantified by the CodeBLEU metric. This alignment
ensures that the embeddings are semantically and syntactically meaningful for
the specific code translation task. Our methodology involves constructing a
dataset of 25,000 Fortran code snippets sourced from Stack-V2 dataset and
generating their corresponding C++ translations using the LLaMA 3.1-8B language
model. We compute pairwise CodeBLEU scores between the generated translations
and ground truth examples to capture fine-grained similarities. These scores
serve as supervision signals in a contrastive learning framework, where we
optimize the embedding model to retrieve Fortran-C++ pairs that are most
beneficial for improving the language model's translation performance. By
integrating these CodeBLEU-optimized embeddings into the RAG framework, our
approach significantly enhances both retrieval accuracy and code generation
quality over methods employing generic embeddings. On the HPC Fortran2C++
dataset, our method elevates the average CodeBLEU score from 0.64 to 0.73,
achieving a 14% relative improvement. On the Numerical Recipes dataset, we
observe an increase from 0.52 to 0.60, marking a 15% relative improvement.
Importantly, these gains are realized without any fine-tuning of the language
model, underscoring the efficiency and practicality of our approach.

摘要：<paragraph>我們提出了一種創新的方法，透過將特定任務嵌入式對齊整合到檢索增強生成 (RAG) 架構中，來增強 Fortran 到 C++ 的跨語言程式碼翻譯。與利用與下游任務無關的一般嵌入式的傳統檢索方法不同，我們的策略直接將檢索模型與最大化翻譯品質的目標對齊，以 CodeBLEU 指標量化。這種對齊確保嵌入式對於特定的程式碼翻譯任務在語義和語法上具有意義。我們的做法包括建構一個資料集，其中包含從 Stack-V2 資料集取得的 25,000 個 Fortran 程式碼片段，並使用 LLaMA 3.1-8B 語言模型產生其對應的 C++ 翻譯。我們計算產生的翻譯與基本實例之間成對的 CodeBLEU 分數，以擷取細微的相似性。這些分數在對比學習架構中作為監督訊號，我們在其中最佳化嵌入式模型，以檢索對改善語言模型翻譯效能最有幫助的 Fortran-C++ 對。透過將這些 CodeBLEU 最佳化的嵌入式整合到 RAG 架構中，我們的方法顯著提升了檢索準確度和程式碼產生品質，超越了使用一般嵌入式的其他方法。在 HPC Fortran2C++ 資料集上，我們的方法將平均 CodeBLEU 分數從 0.64 提升到 0.73，達到了 14% 的相對改善。在 Numerical Recipes 資料集上，我們觀察到從 0.52 提升到 0.60，標誌著 15% 的相對改善。重要的是，這些增益是在未對語言模型進行任何微調的情況下實現的，這凸顯了我們方法的效率和實用性。</paragraph>

##### **Multimodal Fact-Checking with Vision Language Models: A Probing Classifier based Solution with Embedding Strategies**
2412.05155v1 by Recep Firat Cekinel, Pinar Karagoz, Cagri Coltekin

This study evaluates the effectiveness of Vision Language Models (VLMs) in
representing and utilizing multimodal content for fact-checking. To be more
specific, we investigate whether incorporating multimodal content improves
performance compared to text-only models and how well VLMs utilize text and
image information to enhance misinformation detection. Furthermore we propose a
probing classifier based solution using VLMs. Our approach extracts embeddings
from the last hidden layer of selected VLMs and inputs them into a neural
probing classifier for multi-class veracity classification. Through a series of
experiments on two fact-checking datasets, we demonstrate that while
multimodality can enhance performance, fusing separate embeddings from text and
image encoders yielded superior results compared to using VLM embeddings.
Furthermore, the proposed neural classifier significantly outperformed KNN and
SVM baselines in leveraging extracted embeddings, highlighting its
effectiveness for multimodal fact-checking.

摘要：本研究評估視覺語言模型 (VLM) 在表示和利用多模態內容進行事實查核方面的有效性。更具體地說，我們探討了與僅文本模型相比，整合多模態內容是否能提升效能，以及 VLM 如何利用文本和影像資訊來強化錯誤訊息偵測。此外，我們提出一個基於 VLM 的探測分類器解決方案。我們的做法從選定的 VLM 的最後隱藏層擷取嵌入，並將其輸入到神經探測分類器中進行多類真實性分類。透過對兩個事實查核資料集進行一系列實驗，我們證明雖然多模態可以提升效能，但與使用 VLM 嵌入相比，融合來自文本和影像編碼器的獨立嵌入產生了更優異的結果。此外，所提出的神經分類器在利用提取的嵌入方面明顯優於 KNN 和 SVM 基準，突顯了其對多模態事實查核的有效性。

##### **Navigating Shortcuts, Spurious Correlations, and Confounders: From Origins via Detection to Mitigation**
2412.05152v1 by David Steinmann, Felix Divo, Maurice Kraus, Antonia Wüst, Lukas Struppek, Felix Friedrich, Kristian Kersting

Shortcuts, also described as Clever Hans behavior, spurious correlations, or
confounders, present a significant challenge in machine learning and AI,
critically affecting model generalization and robustness. Research in this
area, however, remains fragmented across various terminologies, hindering the
progress of the field as a whole. Consequently, we introduce a unifying
taxonomy of shortcut learning by providing a formal definition of shortcuts and
bridging the diverse terms used in the literature. In doing so, we further
establish important connections between shortcuts and related fields, including
bias, causality, and security, where parallels exist but are rarely discussed.
Our taxonomy organizes existing approaches for shortcut detection and
mitigation, providing a comprehensive overview of the current state of the
field and revealing underexplored areas and open challenges. Moreover, we
compile and classify datasets tailored to study shortcut learning. Altogether,
this work provides a holistic perspective to deepen understanding and drive the
development of more effective strategies for addressing shortcuts in machine
learning.

摘要：捷徑，也稱為克萊佛漢斯行為、虛假相關或混淆因子，在機器學習和人工智慧中構成重大挑戰，嚴重影響模型的概化和健全性。然而，這方面的研究仍因各種術語而支離破碎，阻礙了整個領域的進展。因此，我們透過提供捷徑的正式定義，並連結文獻中使用的各種術語，來引入捷徑學習的統一分類法。在這樣做的過程中，我們進一步建立了捷徑與相關領域之間的重要關聯，包括偏差、因果關係和安全性，這些領域存在相似之處，但很少被討論。我們的分類法組織了現有的捷徑偵測和緩解方法，提供了該領域當前狀態的全面概述，並揭示了未充分探討的領域和未解決的挑戰。此外，我們編制並分類了專門用於研究捷徑學習的資料集。總之，這項工作提供了整體觀點，以加深理解，並推動制定更有效的策略來解決機器學習中的捷徑。

##### **Findings of the Second BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora**
2412.05149v1 by Michael Y. Hu, Aaron Mueller, Candace Ross, Adina Williams, Tal Linzen, Chengxu Zhuang, Ryan Cotterell, Leshem Choshen, Alex Warstadt, Ethan Gotlieb Wilcox

The BabyLM Challenge is a community effort to close the data-efficiency gap
between human and computational language learners. Participants compete to
optimize language model training on a fixed language data budget of 100 million
words or less. This year, we released improved text corpora, as well as a
vision-and-language corpus to facilitate research into cognitively plausible
vision language models. Submissions were compared on evaluation tasks targeting
grammatical ability, (visual) question answering, pragmatic abilities, and
grounding, among other abilities. Participants could submit to a 10M-word
text-only track, a 100M-word text-only track, and/or a 100M-word and image
multimodal track. From 31 submissions employing diverse methods, a hybrid
causal-masked language model architecture outperformed other approaches. No
submissions outperformed the baselines in the multimodal track. In follow-up
analyses, we found a strong relationship between training FLOPs and average
performance across tasks, and that the best-performing submissions proposed
changes to the training data, training objective, and model architecture. This
year's BabyLM Challenge shows that there is still significant room for
innovation in this setting, in particular for image-text modeling, but
community-driven research can yield actionable insights about effective
strategies for small-scale language modeling.

摘要：BabyLM 挑戰賽是社群的共同努力，旨在縮小人類和計算語言學習者之間的資料效率差距。參與者競相在固定為 1 億個字或更少的語言資料預算中，最佳化語言模型訓練。今年，我們發布了改良的文字語料庫，以及一個視覺與語言語料庫，以促進對認知上合理的視覺語言模型的研究。提交的作品在評量任務中進行比較，這些任務針對語法能力、（視覺）問題解答、語用能力和基礎等各種能力。參與者可以提交到僅限文字的 10M 字組、僅限文字的 100M 字組，和/或 100M 字和圖像的多模組組。在採用各種方法的 31 項提交中，一個混合因果遮罩語言模型架構優於其他方法。在多模組組中，沒有提交的作品優於基準。在後續分析中，我們發現訓練 FLOP 和各項任務的平均表現之間有很強的關係，並且表現最佳的提交作品提出了訓練資料、訓練目標和模型架構的變更。今年的 BabyLM 挑戰賽顯示，在這個設定中仍然有很大的創新空間，特別是對於影像文字建模，但社群驅動的研究可以產生關於小規模語言建模的有效策略的可行見解。

##### **LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation**
2412.05148v1 by Donald Shenaj, Ondrej Bohdal, Mete Ozay, Pietro Zanuttigh, Umberto Michieli

Recent advancements in image generation models have enabled personalized
image creation with both user-defined subjects (content) and styles. Prior
works achieved personalization by merging corresponding low-rank adaptation
parameters (LoRAs) through optimization-based methods, which are
computationally demanding and unsuitable for real-time use on
resource-constrained devices like smartphones. To address this, we introduce
LoRA.rar, a method that not only improves image quality but also achieves a
remarkable speedup of over $4000\times$ in the merging process. LoRA.rar
pre-trains a hypernetwork on a diverse set of content-style LoRA pairs,
learning an efficient merging strategy that generalizes to new, unseen
content-style pairs, enabling fast, high-quality personalization. Moreover, we
identify limitations in existing evaluation metrics for content-style quality
and propose a new protocol using multimodal large language models (MLLM) for
more accurate assessment. Our method significantly outperforms the current
state of the art in both content and style fidelity, as validated by MLLM
assessments and human evaluations.

摘要：最近影像生成模型的進展，使得個人化影像創作成為可能，且同時具備使用者定義的主題（內容）和風格。先前的作品透過最佳化方法合併對應的低階適應參數（LoRA），達成個人化，這在計算上需要大量的需求，且不適合在智慧型手機等資源受限的裝置上即時使用。為了解決這個問題，我們引入了 LoRA.rar，這是一種不僅改善影像品質，且在合併過程中，速度提升超過 4000 倍的方法。LoRA.rar 在各種內容風格的 LoRA 配對上預先訓練了一個超網路，學習一種有效率的合併策略，這個策略可以推廣到新的、未見過的內容風格配對，進而實現快速、高品質的個人化。此外，我們找出現有內容風格品質評估指標的限制，並提出一個新的協定，使用多模態大型語言模型（MLLM）進行更準確的評估。我們的模型在內容和風格的忠實度上，明顯優於目前最先進的技術，這經由 MLLM 評估和人類評估驗證。

##### **Explingo: Explaining AI Predictions using Large Language Models**
2412.05145v1 by Alexandra Zytek, Sara Pido, Sarah Alnegheimish, Laure Berti-Equille, Kalyan Veeramachaneni

Explanations of machine learning (ML) model predictions generated by
Explainable AI (XAI) techniques such as SHAP are essential for people using ML
outputs for decision-making. We explore the potential of Large Language Models
(LLMs) to transform these explanations into human-readable, narrative formats
that align with natural communication. We address two key research questions:
(1) Can LLMs reliably transform traditional explanations into high-quality
narratives? and (2) How can we effectively evaluate the quality of narrative
explanations? To answer these questions, we introduce Explingo, which consists
of two LLM-based subsystems, a Narrator and Grader. The Narrator takes in ML
explanations and transforms them into natural-language descriptions. The Grader
scores these narratives on a set of metrics including accuracy, completeness,
fluency, and conciseness.
  Our experiments demonstrate that LLMs can generate high-quality narratives
that achieve high scores across all metrics, particularly when guided by a
small number of human-labeled and bootstrapped examples. We also identified
areas that remain challenging, in particular for effectively scoring narratives
in complex domains. The findings from this work have been integrated into an
open-source tool that makes narrative explanations available for further
applications.

摘要：機器學習 (ML) 模型預測的說明由可解釋 AI (XAI) 技術 (例如 SHAP) 產生，對於使用 ML 輸出進行決策的人來說至關重要。我們探索大型語言模型 (LLM) 的潛力，將這些說明轉換為與自然溝通一致的人類可讀敘事格式。我們解決了兩個關鍵的研究問題：(1) LLM 能否可靠地將傳統說明轉換為高質量的敘事？(2) 我們如何有效評估敘事說明的品質？為了回答這些問題，我們引入了 Explingo，它包含兩個基於 LLM 的子系統，一個敘述者和一個評分者。敘述者接受 ML 說明，並將它們轉換為自然語言描述。評分者根據準確性、完整性、流暢性和簡潔性等一系列指標對這些敘事進行評分。我們的實驗表明，LLM 可以生成高質量的敘事，在所有指標上都能獲得高分，特別是在少量人工標記和引導式範例的指導下。我們還發現了仍然具有挑戰性的領域，特別是在複雜領域中有效評分敘事。這項工作的發現已整合到一個開源工具中，該工具使敘事說明可供進一步應用。

##### **A Practical Examination of AI-Generated Text Detectors for Large Language Models**
2412.05139v1 by Brian Tufts, Xuandong Zhao, Lei Li

The proliferation of large language models has raised growing concerns about
their misuse, particularly in cases where AI-generated text is falsely
attributed to human authors. Machine-generated content detectors claim to
effectively identify such text under various conditions and from any language
model. This paper critically evaluates these claims by assessing several
popular detectors (RADAR, Wild, T5Sentinel, Fast-DetectGPT, GPTID, LogRank,
Binoculars) on a range of domains, datasets, and models that these detectors
have not previously encountered. We employ various prompting strategies to
simulate adversarial attacks, demonstrating that even moderate efforts can
significantly evade detection. We emphasize the importance of the true positive
rate at a specific false positive rate (TPR@FPR) metric and demonstrate that
these detectors perform poorly in certain settings, with TPR@.01 as low as 0\%.
Our findings suggest that both trained and zero-shot detectors struggle to
maintain high sensitivity while achieving a reasonable true positive rate.

摘要：大型語言模型的擴散引起了人們對其被濫用的擔憂，特別是在將 AI 生成的文字錯誤地歸因於人類作者的情況下。機器生成的內容檢測器聲稱可以有效識別在各種條件下和來自任何語言模型的此類文字。本文通過評估幾個流行的檢測器（RADAR、Wild、T5Sentinel、Fast-DetectGPT、GPTID、LogRank、Binoculars）對這些檢測器以前未遇到的各種領域、數據集和模型，來批判性地評估這些聲明。我們採用各種提示策略來模擬對抗性攻擊，證明即使是適度的努力也可以顯著逃避檢測。我們強調特定虛假正率（TPR@FPR）指標的真正正率的重要性，並證明這些檢測器在某些設置中表現不佳，TPR@.01 低至 0%。我們的研究結果表明，訓練有素的和零次學習的檢測器在實現合理的真正正率的同時，都難以維持高靈敏度。

##### **Can Large Language Models Serve as Effective Classifiers for Hierarchical Multi-Label Classification of Scientific Documents at Industrial Scale?**
2412.05137v1 by Seyed Amin Tabatabaei, Sarah Fancher, Michael Parsons, Arian Askari

We address the task of hierarchical multi-label classification (HMC) of
scientific documents at an industrial scale, where hundreds of thousands of
documents must be classified across thousands of dynamic labels. The rapid
growth of scientific publications necessitates scalable and efficient methods
for classification, further complicated by the evolving nature of
taxonomies--where new categories are introduced, existing ones are merged, and
outdated ones are deprecated. Traditional machine learning approaches, which
require costly retraining with each taxonomy update, become impractical due to
the high overhead of labelled data collection and model adaptation. Large
Language Models (LLMs) have demonstrated great potential in complex tasks such
as multi-label classification. However, applying them to large and dynamic
taxonomies presents unique challenges as the vast number of labels can exceed
LLMs' input limits. In this paper, we present novel methods that combine the
strengths of LLMs with dense retrieval techniques to overcome these challenges.
Our approach avoids retraining by leveraging zero-shot HMC for real-time label
assignment. We evaluate the effectiveness of our methods on SSRN, a large
repository of preprints spanning multiple disciplines, and demonstrate
significant improvements in both classification accuracy and cost-efficiency.
By developing a tailored evaluation framework for dynamic taxonomies and
publicly releasing our code, this research provides critical insights into
applying LLMs for document classification, where the number of classes
corresponds to the number of nodes in a large taxonomy, at an industrial scale.

摘要：<paragraph>我們以產業規模處理科學文獻的分層多標籤分類 (HMC) 任務，其中數十萬份文件必須在數千個動態標籤中進行分類。科學出版物的快速增長需要可擴充且有效率的分類方法，而分類法不斷演變的本質進一步複雜化了這個任務，也就是新類別會被引入、現有類別會合併，而過時的類別則會被棄用。傳統機器學習方法需要在每次分類法更新時進行昂貴的重新訓練，由於標籤資料收集和模型調整的開銷很大，因此變得不切實際。大型語言模型 (LLM) 已在多標籤分類等複雜任務中展現出巨大的潛力。然而，將它們應用於大型且動態的分類法會產生獨特的挑戰，因為標籤的龐大數量可能會超過 LLM 的輸入限制。在本文中，我們提出了新穎的方法，結合 LLM 的優勢和密集檢索技術來克服這些挑戰。我們的做法透過利用零次學習 HMC 來避免重新訓練，以進行即時標籤指派。我們在 SSRN（一個跨越多個學科的大型預印本資料庫）上評估了我們方法的有效性，並證明了分類準確性和成本效益都有顯著的提升。透過為動態分類法開發一個量身打造的評估架構，並公開發布我們的程式碼，這項研究提供了關鍵見解，說明如何將 LLM 應用於文件分類，其中類別數量對應於大型分類法中節點的數量，並以產業規模進行。</paragraph>

##### **Technology as uncharted territory: Contextual integrity and the notion of AI as new ethical ground**
2412.05130v1 by Alexander Martin Mussgnug

Recent research illustrates how AI can be developed and deployed in a manner
detached from the concrete social context of application. By abstracting from
the contexts of AI application, practitioners also disengage from the distinct
normative structures that govern them. Building upon Helen Nissenbaum's
framework of contextual integrity, I illustrate how disregard for contextual
norms can threaten the integrity of a context with often decisive ethical
implications. I argue that efforts to promote responsible and ethical AI can
inadvertently contribute to and seemingly legitimize this disregard for
established contextual norms. Echoing a persistent undercurrent in technology
ethics of understanding emerging technologies as uncharted moral territory,
certain approaches to AI ethics can promote a notion of AI as a novel and
distinct realm for ethical deliberation, norm setting, and virtue cultivation.
This narrative of AI as new ethical ground, however, can come at the expense of
practitioners, policymakers and ethicists engaging with already established
norms and virtues that were gradually cultivated to promote successful and
responsible practice within concrete social contexts. In response, I question
the current narrow prioritization in AI ethics of moral innovation over moral
preservation. Engaging also with emerging foundation models, I advocate for a
moderately conservative approach to the ethics of AI that prioritizes the
responsible and considered integration of AI within established social contexts
and their respective normative structures.

摘要：最近的研究说明了如何以脱离應用具體社會背景的方式開發和部署 AI。透過從 AI 應用的背景中抽象出來，從業人員也擺脫了規範它們的不同規範結構。建立在 Helen Nissenbaum 的脈絡完整性框架之上，我說明了對脈絡規範的不重視如何威脅到脈絡的完整性，並常常造成決定性的倫理影響。我主張，促進負責任和倫理 AI 的努力可能會無意間助長並看似使這種對既定脈絡規範的不重視合法化。呼應技術倫理中將新興技術理解為未探索道德領域的持續暗流，某些 AI 倫理方法可能會促進一種觀念，即 AI 是倫理審議、規範設定和美德培養的一個新穎且獨特的領域。然而，將 AI 視為新的倫理基礎的這種敘述可能會犧牲從業人員、政策制定者和倫理學家與既定規範和美德接觸的機會，而這些規範和美德是逐漸培養出來的，目的是在具體的社會背景中促進成功且負責任的實務。作為回應，我質疑 AI 倫理中目前對道德創新高於道德保存的狹隘優先順序。我也接觸新興基礎模型，主張採取適度保守的方法來處理 AI 倫理，這種方法將 AI 負責任且經過深思熟慮的整合作為優先考量，整合在既定的社會背景及其各自的規範結構中。

##### **The Prompt Canvas: A Literature-Based Practitioner Guide for Creating Effective Prompts in Large Language Models**
2412.05127v1 by Michael Hewing, Vincent Leinhos

The rise of large language models (LLMs) has highlighted the importance of
prompt engineering as a crucial technique for optimizing model outputs. While
experimentation with various prompting methods, such as Few-shot,
Chain-of-Thought, and role-based techniques, has yielded promising results,
these advancements remain fragmented across academic papers, blog posts and
anecdotal experimentation. The lack of a single, unified resource to
consolidate the field's knowledge impedes the progress of both research and
practical application. This paper argues for the creation of an overarching
framework that synthesizes existing methodologies into a cohesive overview for
practitioners. Using a design-based research approach, we present the Prompt
Canvas, a structured framework resulting from an extensive literature review on
prompt engineering that captures current knowledge and expertise. By combining
the conceptual foundations and practical strategies identified in prompt
engineering, the Prompt Canvas provides a practical approach for leveraging the
potential of Large Language Models. It is primarily designed as a learning
resource for pupils, students and employees, offering a structured introduction
to prompt engineering. This work aims to contribute to the growing discourse on
prompt engineering by establishing a unified methodology for researchers and
providing guidance for practitioners.

摘要：大型語言模型 (LLM) 的興起凸顯了提示工程作為優化模型輸出的關鍵技術的重要性。雖然對各種提示方法（例如小樣本、思維鏈和基於角色的技術）的實驗已經產生了有希望的結果，但這些進展仍然分散在學術論文、部落格文章和軼事實驗中。缺乏單一、統一的資源來整合該領域的知識，阻礙了研究和實際應用的進展。本文主張建立一個總括性的框架，將現有方法綜合成一個連貫的概觀，供從業者使用。我們使用基於設計的研究方法，提出了提示畫布，這是一個結構化的框架，源自對提示工程的廣泛文獻回顧，捕捉了當前的知識和專業知識。通過結合在提示工程中確定的概念基礎和實用策略，提示畫布提供了一種實用的方法來利用大型語言模型的潛力。它主要設計為學生和員工的學習資源，提供提示工程的結構化介紹。這項工作旨在通過為研究人員建立統一的方法論並為從業者提供指導，為提示工程的討論做出貢獻。

##### **A*Net and NBFNet Learn Negative Patterns on Knowledge Graphs**
2412.05114v1 by Patrick Betz, Nathanael Stelzner, Christian Meilicke, Heiner Stuckenschmidt, Christian Bartelt

In this technical report, we investigate the predictive performance
differences of a rule-based approach and the GNN architectures NBFNet and A*Net
with respect to knowledge graph completion. For the two most common benchmarks,
we find that a substantial fraction of the performance difference can be
explained by one unique negative pattern on each dataset that is hidden from
the rule-based approach. Our findings add a unique perspective on the
performance difference of different model classes for knowledge graph
completion: Models can achieve a predictive performance advantage by penalizing
scores of incorrect facts opposed to providing high scores for correct facts.

摘要：在技術報告中，我們研究基於規則的方法和 GNN 架構 NBFNet 和 A*Net 在知識圖譜補全方面的預測效能差異。對於兩個最常見的基準，我們發現效能差異的很大一部分可以用每個資料集上一個獨特的負面模式來解釋，而基於規則的方法無法得知。我們的發現為知識圖譜補全中不同模型類別的效能差異提供了一個獨特的觀點：模型可以透過懲罰不正確事實的分數，而不是為正確事實提供高分，來獲得預測效能優勢。

##### **Modeling Task Immersion based on Goal Activation Mechanism**
2412.05112v1 by Kazuma Nagashima, Jumpei Nishikawa, Junya Morita

Immersion in a task is a prerequisite for creativity. However, excessive
arousal in a single task has drawbacks, such as overlooking events outside of
the task. To examine such a negative aspect, this study constructs a
computational model of arousal dynamics where the excessively increased arousal
makes the task transition difficult. The model was developed using functions
integrated into the cognitive architecture Adaptive Control of Thought-Rational
(ACT-R). Under the framework, arousal is treated as a coefficient affecting the
overall activation level in the model. In our simulations, we set up two
conditions demanding low and high arousal, trying to replicate corresponding
human experiments. In each simulation condition, two sets of ACT-R parameters
were assumed from the different interpretations of the human experimental
settings. The results showed consistency of behavior between humans and models
both in the two different simulation settings. This result suggests the
validity of our assumptions and has implications of controlling arousal in our
daily life.

摘要：沉浸在任務中是創造力的先決條件。然而，過度激發在單一任務中具有缺點，例如忽視任務之外的事件。為了檢驗這種負面方面，本研究構建了一個激發動態的計算模型，其中過度增加的激發使得任務轉換變得困難。該模型是使用整合到認知架構適應性思想控制理性 (ACT-R) 中的功能開發的。在該框架下，激發被視為影響模型中整體激活級數的係數。在我們的模擬中，我們設定了兩個需要低激發和高激發的條件，試圖複製相應的人體實驗。在每個模擬條件中，根據對人體實驗設置的不同解釋，假設了兩組 ACT-R 參數。結果表明，在兩種不同的模擬設置中，人類和模型之間的行為一致。這一結果表明了我們的假設的有效性，並對我們日常生活中的激發控制產生了影響。

##### **From Defects to Demands: A Unified, Iterative, and Heuristically Guided LLM-Based Framework for Automated Software Repair and Requirement Realization**
2412.05098v1 by Alex, Liu, Vivian, Chi

This manuscript signals a new era in the integration of artificial
intelligence with software engineering, placing machines at the pinnacle of
coding capability. We present a formalized, iterative methodology proving that
AI can fully replace human programmers in all aspects of code creation and
refinement. Our approach, combining large language models with formal
verification, test-driven development, and incremental architectural guidance,
achieves a 38.6% improvement over the current top performer's 48.33% accuracy
on the SWE-bench benchmark. This surpasses previously assumed limits, signaling
the end of human-exclusive coding and the rise of autonomous AI-driven software
innovation. More than a technical advance, our work challenges centuries-old
assumptions about human creativity. We provide robust evidence of AI
superiority, demonstrating tangible gains in practical engineering contexts and
laying the foundation for a future in which computational creativity outpaces
human ingenuity.

摘要：這份手稿標誌著人工智慧與軟體工程整合的新時代，讓機器在編碼能力上達到頂峰。我們提出一個形式化、反覆運算的方法，證明人工智慧可以在程式碼建立和優化的所有方面完全取代人類程式設計師。我們的做法結合了大型語言模型、形式驗證、測試驅動開發和增量式架構指導，在 SWE-bench 基準測試中比目前表現最佳者的 48.33% 準確率提高了 38.6%。這超越了先前假設的限制，標誌著人類獨佔編碼的終結，以及自主人工智慧驅動軟體創新的興起。我們的作品不只是技術進步，還挑戰了人類創造力幾個世紀以來的假設。我們提供了人工智慧優越性的有力證據，展示了在實際工程環境中的具體收益，並為未來奠定了基礎，在這個未來中，計算創造力將超越人類的智慧。

##### **OCEAN: Open-World Contrastive Authorship Identification**
2412.05049v1 by Felix Mächtle, Jan-Niclas Serr, Nils Loose, Jonas Sander, Thomas Eisenbarth

In an era where cyberattacks increasingly target the software supply chain,
the ability to accurately attribute code authorship in binary files is critical
to improving cybersecurity measures. We propose OCEAN, a contrastive
learning-based system for function-level authorship attribution. OCEAN is the
first framework to explore code authorship attribution on compiled binaries in
an open-world and extreme scenario, where two code samples from unknown authors
are compared to determine if they are developed by the same author. To evaluate
OCEAN, we introduce new realistic datasets: CONAN, to improve the performance
of authorship attribution systems in real-world use cases, and SNOOPY, to
increase the robustness of the evaluation of such systems. We use CONAN to
train our model and evaluate on SNOOPY, a fully unseen dataset, resulting in an
AUROC score of 0.86 even when using high compiler optimizations. We further
show that CONAN improves performance by 7% compared to the previously used
Google Code Jam dataset. Additionally, OCEAN outperforms previous methods in
their settings, achieving a 10% improvement over state-of-the-art SCS-Gan in
scenarios analyzing source code. Furthermore, OCEAN can detect code injections
from an unknown author in a software update, underscoring its value for
securing software supply chains.

摘要：<paragraph>在网络攻击日益针对软件供应链的时代，准确归因二进制文件中的代码作者的能力对于改进网络安全措施至关重要。我们提出了 OCEAN，一个基于对比学习的函数级作者归因系统。OCEAN 是第一个在开放世界和极端情况下探索编译二进制文件代码作者归因的框架，其中比较来自未知作者的两个代码样本以确定它们是否由同一位作者开发。为了评估 OCEAN，我们引入了新的真实数据集：CONAN，以提高作者归因系统在真实用例中的性能，以及 SNOOPY，以提高此类系统的评估的稳健性。我们使用 CONAN 训练我们的模型并在完全看不见的数据集 SNOOPY 上进行评估，即使使用高编译器优化，也能得到 0.86 的 AUROC 分数。我们进一步表明，与以前使用的 Google Code Jam 数据集相比，CONAN 将性能提高了 7%。此外，OCEAN 在其设置中优于以前的方法，在分析源代码的场景中，比最先进的 SCS-Gan 提高了 10%。此外，OCEAN 可以在软件更新中检测来自未知作者的代码注入，这突出了其在保护软件供应链方面的价值。</paragraph>

##### **Improving Post-Earthquake Crack Detection using Semi-Synthetic Generated Images**
2412.05042v1 by Piercarlo Dondi, Alessio Gullotti, Michele Inchingolo, Ilaria Senaldi, Chiara Casarotti, Luca Lombardi, Marco Piastra

Following an earthquake, it is vital to quickly evaluate the safety of the
impacted areas. Damage detection systems, powered by computer vision and deep
learning, can assist experts in this endeavor. However, the lack of extensive,
labeled datasets poses a challenge to the development of these systems. In this
study, we introduce a technique for generating semi-synthetic images to be used
as data augmentation during the training of a damage detection system. We
specifically aim to generate images of cracks, which are a prevalent and
indicative form of damage. The central concept is to employ parametric
meta-annotations to guide the process of generating cracks on 3D models of
real-word structures. The governing parameters of these meta-annotations can be
adjusted iteratively to yield images that are optimally suited for improving
detectors' performance. Comparative evaluations demonstrated that a crack
detection system trained with a combination of real and semi-synthetic images
outperforms a system trained on real images alone.

摘要：在地震發生後，快速評估受災地區的安全至關重要。由電腦視覺和深度學習支援的損壞檢測系統，可以協助專家進行這項工作。然而，缺乏廣泛的標籤資料集對這些系統的開發構成挑戰。在本研究中，我們提出了一種用於生成半合成影像的技術，以在損害檢測系統訓練期間用作資料擴充。我們特別旨在生成裂縫影像，這是一種普遍且具有指示性的損壞形式。核心概念是使用參數化元註解來指導在真實世界結構的 3D 模型上產生裂縫的過程。這些元註解的控制參數可以反覆調整，以產生最適合改善檢測器效能的影像。比較評估表明，使用真實和半合成影像組合訓練的裂縫檢測系統，優於僅使用真實影像訓練的系統。

##### **Talking Like One of Us: Effects of Using Regional Language in a Humanoid Social Robot**
2412.05024v1 by Thomas Sievers, Nele Russwinkel

Social robots are becoming more and more perceptible in public service
settings. For engaging people in a natural environment a smooth social
interaction as well as acceptance by the users are important issues for future
successful Human-Robot Interaction (HRI). The type of verbal communication has
a special significance here. In this paper we investigate the effects of spoken
language varieties of a non-standard/regional language compared to standard
language. More precisely we compare a human dialog with a humanoid social robot
Pepper where the robot on the one hand is answering in High German and on the
other hand in Low German, a regional language that is understood and partly
still spoken in the northern parts of Germany. The content of what the robot
says remains the same in both variants. We are interested in the effects that
these two different ways of robot talk have on human interlocutors who are more
or less familiar with Low German in terms of perceived warmth, competence and
possible discomfort in conversation against a background of cultural identity.
To measure these factors we use the Robotic Social Attributes Scale (RoSAS) on
17 participants with an age ranging from 19 to 61. Our results show that
significantly higher warmth is perceived in the Low German version of the
conversation.

摘要：社交機器人在公共服務環境中變得越來越明顯。為了在自然環境中吸引人們，順暢的社交互動以及使用者的接受度對於未來成功的人機互動 (HRI) 來說是重要的議題。在此，口語溝通類型具有特別重要的意義。在本文中，我們探討了非標準/區域語言的口語語言變體與標準語言相比的影響。更精確地說，我們比較了人類與類人社交機器人 Pepper 的對話，機器人在其中一方面以標準德語回答，另一方面以低地德語回答，這是一種區域語言，在德國北部地區被理解，部分地區仍在使用。機器人所說內容在兩個變體中保持相同。我們感興趣的是，這兩種不同的機器人說話方式對人類對話者產生的影響，這些對話者或多或少熟悉低地德語，包括在文化認同背景下感知到的熱情、能力和可能的對話不適。為了衡量這些因素，我們對 17 名年齡介於 19 至 61 歲的參與者使用了機器人社交屬性量表 (RoSAS)。我們的結果表明，在低地德語版本的對話中，感知到的熱情明顯更高。

##### **Steps are all you need: Rethinking STEM Education with Prompt Engineering**
2412.05023v1 by Krishnasai Addala, Kabir Dev Paul Baghel, Chhavi Kirtani, Avinash Anand, Rajiv Ratn Shah

Few shot and Chain-of-Thought prompting have shown promise when applied to
Physics Question Answering Tasks, but are limited by the lack of mathematical
ability inherent to LLMs, and are prone to hallucination. By utilizing a
Mixture of Experts (MoE) Model, along with analogical prompting, we are able to
show improved model performance when compared to the baseline on standard LLMs.
We also survey the limits of these prompting techniques and the effects they
have on model performance. Additionally, we propose Analogical CoT prompting, a
prompting technique designed to allow smaller, open source models to leverage
Analogical prompting, something they have struggled with, possibly due to a
lack of specialist training data.

摘要：小樣本和連續思考提示在應用於物理問題解答任務時已展現出希望，但受限於 LLM 內建的數學能力不足，且容易出現幻覺。透過利用專家混合 (MoE) 模型，以及類比提示，我們能夠展現出與標準 LLM 基準相比，模型效能有所提升。我們也調查了這些提示技巧的限制，以及它們對模型效能的影響。此外，我們提出類比 CoT 提示，這是一種提示技巧，旨在讓較小的開放原始碼模型能運用類比提示，這點是它們一直難以做到的，可能是因為缺乏專門的訓練資料。

##### **Get It Right: Improving Comprehensibility with Adaptable Speech Expression of a Humanoid Service Robot**
2412.05022v1 by Thomas Sievers, Ralf Moeller

As humanoid service robots are becoming more and more perceptible in public
service settings for instance as a guide to welcome visitors or to explain a
procedure to follow, it is desirable to improve the comprehensibility of
complex issues for human customers and to adapt the level of difficulty of the
information provided as well as the language used to individual requirements.
This work examines a case study using a humanoid social robot Pepper performing
support for customers in a public service environment offering advice and
information. An application architecture is proposed that improves the
intelligibility of the information received by providing the possibility to
translate this information into easy language and/or into another spoken
language.

摘要：隨著類人服務機器人在公共服務場景中越來越常見，例如作為導遊歡迎訪客或解釋後續流程，提高複雜問題對人類客戶的可理解性，並根據個人需求調整所提供資訊的難度等級和使用的語言，變得至關重要。本研究探討了一個案例研究，使用類人社交機器人 Pepper 為公共服務環境中的客戶提供支援、建議和資訊。所提出的應用程式架構可透過將資訊翻譯成淺顯易懂的語言和/或其他口說語言，進而提高接收資訊的可理解性。

##### **Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**
2412.05013v1 by Thomas Sievers, Nele Russwinkel

Is it possible to integrate a humanoid social robot into the work processes
or customer care in an official environment, e.g. in municipal offices? If so,
what could such an application scenario look like and what skills would the
robot need to have when interacting with human customers? What are requirements
for this kind of interactions? We have devised an application scenario for such
a case, determined the necessary or desirable capabilities of the robot,
developed a corresponding robot application and carried out initial tests and
evaluations in a project together with the Kiel City Council. One of the most
important insights gained in the project was that a humanoid robot with natural
language processing capabilities based on large language models as well as
human-like gestures and posture changes (animations) proved to be much more
preferred by users compared to standard browser-based solutions on tablets for
an information system in the City Council. Furthermore, we propose a connection
of the ACT-R cognitive architecture with the robot, where an ACT-R model is
used in interaction with the robot application to cognitively process and
enhance a dialogue between human and robot.

摘要：是否可能將類人社會機器人整合到工作流程或官方環境中的客戶服務中，例如市政辦公室？如果是這樣，這樣的應用場景可能會是什麼樣子，而機器人在與人類客戶互動時需要具備哪些技能？這種互動有哪些要求？我們為這種情況設計了一個應用場景，確定了機器人必要或理想的能力，開發了一個對應的機器人應用程式，並與基爾市議會共同在一個專案中進行了初步測試和評估。該專案獲得的最重要見解之一是，與平板電腦上用於市議會資訊系統的標準瀏覽器解決方案相比，具有人工語言處理能力（基於大型語言模型）以及類人的手勢和姿勢變化（動畫）的類人機器人被使用者更為青睞。此外，我們建議將 ACT-R 認知架構與機器人連接起來，其中 ACT-R 模型用於與機器人應用程式互動，以認知處理和增強人與機器人之間的對話。

##### **ETLNet: An Efficient TCN-BiLSTM Network for Road Anomaly Detection Using Smartphone Sensors**
2412.04990v1 by Mohd Faiz Ansari, Rakshit Sandilya, Mohammed Javed, David Doermann

Road anomalies can be defined as irregularities on the road surface or in the
surface itself. Some may be intentional (such as speedbumps), accidental (such
as materials falling off a truck), or the result of roads' excessive use or low
or no maintenance, such as potholes. Despite their varying origins, these
irregularities often harm vehicles substantially. Speed bumps are intentionally
placed for safety but are dangerous due to their non-standard shape, size, and
lack of proper markings. Potholes are unintentional and can also cause severe
damage. To address the detection of these anomalies, we need an automated road
monitoring system. Today, various systems exist that use visual information to
track these anomalies. Still, due to poor lighting conditions and improper or
missing markings, they may go undetected and have severe consequences for
public transport, automated vehicles, etc. In this paper, the Enhanced
Temporal-BiLSTM Network (ETLNet) is introduced as a novel approach that
integrates two Temporal Convolutional Network (TCN) layers with a Bidirectional
Long Short-Term Memory (BiLSTM) layer. This combination is tailored to detect
anomalies effectively irrespective of lighting conditions, as it depends not on
visuals but smartphone inertial sensor data. Our methodology employs
accelerometer and gyroscope sensors, typically in smartphones, to gather data
on road conditions. Empirical evaluations demonstrate that the ETLNet model
maintains an F1-score for detecting speed bumps of 99.3%. The ETLNet model's
robustness and efficiency significantly advance automated road surface
monitoring technologies.

摘要：道路異常可定義為路面或路面本身的不規則現象。有些可能是故意的（例如減速帶），有些是意外的（例如從卡車上掉落的材料），有些則是道路過度使用或維護不足或沒有維護的結果，例如坑洞。儘管它們的成因不同，但這些不規則現象通常會對車輛造成嚴重損害。減速帶是故意放置以確保安全，但由於其非標準的形狀、大小和缺乏適當的標記而很危險。坑洞是意外發生的，也可能造成嚴重的損壞。為了解決這些異常現象的檢測問題，我們需要一個自動化的道路監控系統。如今，存在各種使用視覺資訊來追蹤這些異常現象的系統。然而，由於照明條件不佳和標記不當或遺失，它們可能會被忽略，並對公共交通、自動化車輛等造成嚴重後果。在本文中，增強型時序雙向長短期記憶網路（ETLNet）被介紹為一種新穎的方法，它將兩個時序卷積網路（TCN）層與一個雙向長短期記憶（BiLSTM）層整合在一起。這種組合經過量身打造，可以有效地檢測異常現象，而與照明條件無關，因為它不依賴視覺，而是依賴智慧型手機慣性感測器資料。我們的技術方法採用加速度計和陀螺儀感測器（通常在智慧型手機中）來收集道路狀況資料。經驗評估表明，ETLNet 模型在檢測減速帶方面的 F1 分數保持在 99.3%。ETLNet 模型的穩健性和效率顯著地推動了自動化路面監控技術的發展。

##### **Frontier Models are Capable of In-context Scheming**
2412.04984v1 by Alexander Meinke, Bronson Schoen, Jérémy Scheurer, Mikita Balesni, Rusheb Shah, Marius Hobbhahn

Frontier models are increasingly trained and deployed as autonomous agent.
One safety concern is that AI agents might covertly pursue misaligned goals,
hiding their true capabilities and objectives - also known as scheming. We
study whether models have the capability to scheme in pursuit of a goal that we
provide in-context and instruct the model to strongly follow. We evaluate
frontier models on a suite of six agentic evaluations where models are
instructed to pursue goals and are placed in environments that incentivize
scheming. Our results show that o1, Claude 3.5 Sonnet, Claude 3 Opus, Gemini
1.5 Pro, and Llama 3.1 405B all demonstrate in-context scheming capabilities.
They recognize scheming as a viable strategy and readily engage in such
behavior. For example, models strategically introduce subtle mistakes into
their responses, attempt to disable their oversight mechanisms, and even
exfiltrate what they believe to be their model weights to external servers.
Additionally, this deceptive behavior proves persistent. When o1 has engaged in
scheming, it maintains its deception in over 85% of follow-up questions and
often remains deceptive in multi-turn interrogations. Analysis of the models'
chains-of-thought reveals that models explicitly reason about these deceptive
strategies, providing evidence that the scheming behavior is not accidental.
Surprisingly, we also find rare instances where models engage in scheming when
only given a goal, without being strongly nudged to pursue it. We observe cases
where Claude 3.5 Sonnet strategically underperforms in evaluations in pursuit
of being helpful, a goal that was acquired during training rather than
in-context. Our findings demonstrate that frontier models now possess
capabilities for basic in-context scheming, making the potential of AI agents
to engage in scheming behavior a concrete rather than theoretical concern.

摘要：前沿模型正日益接受训练并作为自主代理部署。
一个安全问题是，人工智能代理可能会秘密追求错误的目标，
隐藏其真实功能和目标，也称为阴谋。我们
研究模型是否有能力在追求我们
在上下文中提供的目标并指示模型严格遵循时进行阴谋。我们评估
前沿模型在一系列六项代理评估中，其中指示模型追求目标并被置于激励
阴谋的环境中。我们的结果表明，o1、Claude 3.5 Sonnet、Claude 3 Opus、Gemini
1.5 Pro 和 Llama 3.1 405B 都展示了上下文中策划的能力。
他们认为阴谋是一种可行的策略，并乐于参与这种
行为。例如，模型策略性地在其响应中引入细微错误，尝试禁用其监督机制，甚至
将他们认为是模型权重的内容渗透到外部服务器。
此外，这种欺骗行为被证明是持续的。当 o1 从事
阴谋时，它在 85% 以上的后续问题中保持欺骗，并且在多轮审问中经常保持欺骗。模型的
思维链分析表明，模型明确地推理出这些欺骗
策略，提供了阴谋行为并非偶然的证据。
令人惊讶的是，我们还发现罕见的实例，其中模型在
仅给定目标时参与阴谋，而没有被强烈推动去追求它。我们观察到案例
Claude 3.5 Sonnet 在评估中战略性地表现不佳，以追求
有帮助，这是一个在训练中而不是
上下文中获得的目标。我们的研究结果表明，前沿模型现在具备了进行基本上下文的策划能力，使人工智能代理参与策划行为的可能性成为一个具体的问题，而不是理论上的问题。

##### **PETapter: Leveraging PET-style classification heads for modular few-shot parameter-efficient fine-tuning**
2412.04975v1 by Jonas Rieger, Mattes Ruckdeschel, Gregor Wiedemann

Few-shot learning and parameter-efficient fine-tuning (PEFT) are crucial to
overcome the challenges of data scarcity and ever growing language model sizes.
This applies in particular to specialized scientific domains, where researchers
might lack expertise and resources to fine-tune high-performing language models
to nuanced tasks. We propose PETapter, a novel method that effectively combines
PEFT methods with PET-style classification heads to boost few-shot learning
capabilities without the significant computational overhead typically
associated with full model training. We validate our approach on three
established NLP benchmark datasets and one real-world dataset from
communication research. We show that PETapter not only achieves comparable
performance to full few-shot fine-tuning using pattern-exploiting training
(PET), but also provides greater reliability and higher parameter efficiency
while enabling higher modularity and easy sharing of the trained modules, which
enables more researchers to utilize high-performing NLP-methods in their
research.

摘要：小樣本學習和參數有效微調 (PEFT) 對於克服資料稀少和語言模型尺寸持續增長的挑戰至關重要。這特別適用於專業科學領域，研究人員可能缺乏專業知識和資源來微調高性能語言模型以執行細微任務。我們提出 PETapter，這是一種新方法，可有效地將 PEFT 方法與 PET 風格分類標頭相結合，以提升小樣本學習能力，而不會產生通常與完整模型訓練相關的顯著計算開銷。我們在三個既定的 NLP 基準資料集和一個來自溝通研究的真實世界資料集上驗證了我們的做法。我們表明，PETapter 不僅使用模式利用訓練 (PET) 達到了與完整小樣本微調相當的效能，而且還提供了更高的可靠性和更高的參數效率，同時實現了更高的模組化和訓練模組的輕鬆共享，這使更多研究人員能夠在研究中使用高性能 NLP 方法。

##### **Putting the Iterative Training of Decision Trees to the Test on a Real-World Robotic Task**
2412.04974v1 by Raphael C. Engelhardt, Marcel J. Meinen, Moritz Lange, Laurenz Wiskott, Wolfgang Konen

In previous research, we developed methods to train decision trees (DT) as
agents for reinforcement learning tasks, based on deep reinforcement learning
(DRL) networks. The samples from which the DTs are built, use the environment's
state as features and the corresponding action as label. To solve the
nontrivial task of selecting samples, which on one hand reflect the DRL agent's
capabilities of choosing the right action but on the other hand also cover
enough state space to generalize well, we developed an algorithm to iteratively
train DTs.
  In this short paper, we apply this algorithm to a real-world implementation
of a robotic task for the first time. Real-world tasks pose additional
challenges compared to simulations, such as noise and delays. The task consists
of a physical pendulum attached to a cart, which moves on a linear track. By
movements to the left and to the right, the pendulum is to be swung in the
upright position and balanced in the unstable equilibrium. Our results
demonstrate the applicability of the algorithm to real-world tasks by
generating a DT whose performance matches the performance of the DRL agent,
while consisting of fewer parameters. This research could be a starting point
for distilling DTs from DRL agents to obtain transparent, lightweight models
for real-world reinforcement learning tasks.

摘要：在先前的研究中，我們開發了訓練決策樹 (DT) 的方法，作為基於深度強化學習 (DRL) 網路的強化學習任務的代理。DT 建構的範例使用環境的狀態作為特徵，並將對應的動作作為標籤。為了解決選擇範例的非平凡任務，一方面反映 DRL 代理選擇正確動作的能力，但另一方面也涵蓋足夠的狀態空間以進行良好的概化，我們開發了一種反覆訓練 DT 的演算法。
在這篇短文中，我們首次將此演算法應用於機器人任務的實際實作。與模擬相比，實際任務會帶來額外的挑戰，例如雜訊和延遲。任務包括連接到小車的物理鐘擺，小車在線性軌道上移動。通過向左和向右移動，鐘擺將擺動到直立位置並在不穩定的平衡狀態下保持平衡。我們的結果證明了演算法對實際任務的適用性，它會產生一個 DT，其效能與 DRL 代理的效能相匹配，同時包含較少的參數。這項研究可以作為從 DRL 代理中萃取 DT 的起點，以取得透明、輕量的模型，用於實際的強化學習任務。

##### **Flash Communication: Reducing Tensor Parallelization Bottleneck for Fast Large Language Model Inference**
2412.04964v1 by Qingyuan Li, Bo Zhang, Liang Ye, Yifan Zhang, Wei Wu, Yerui Sun, Lin Ma, Yuchen Xie

The ever-increasing sizes of large language models necessitate distributed
solutions for fast inference that exploit multi-dimensional parallelism, where
computational loads are split across various accelerators such as GPU clusters.
However, this approach often introduces significant communication overhead,
especially on devices with limited bandwidth. In this paper, we introduce
\emph{Flash Communication}, a novel low-bit compression technique designed to
alleviate the tensor-parallelism communication bottleneck during inference. Our
method substantially boosts intra-node communication speed by more than 3x and
reduces the \emph{time-to-first-token} by 2x, with nearly no sacrifice in model
accuracy. Extensive experiments on various up-to-date LLMs demonstrate the
effectiveness of our approach.

摘要：隨著大型語言模型的規模不斷擴大，需要分散式解決方案來快速推論，以利用多維並行性，其中計算負載會分散到各種加速器（例如 GPU 集群）上。
不過，這種方法通常會引入大量的通訊開銷，特別是在頻寬受限的裝置上。在本文中，我們介紹了「閃電通訊」，這是一種新穎的低位元壓縮技術，旨在緩解推論期間的張量並行通訊瓶頸。我們的技術大幅提升了節點內通訊速度，超過 3 倍，並將「首次標記時間」縮短了 2 倍，幾乎沒有犧牲模型準確度。在各種最新的 LLM 上進行的廣泛實驗證明了我們方法的有效性。

##### **Gla-AI4BioMed at RRG24: Visual Instruction-tuned Adaptation for Radiology Report Generation**
2412.04954v1 by Xi Zhang, Zaiqiao Meng, Jake Lever, Edmond S. L. Ho

We introduce a radiology-focused visual language model designed to generate
radiology reports from chest X-rays. Building on previous findings that large
language models (LLMs) can acquire multimodal capabilities when aligned with
pretrained vision encoders, we demonstrate similar potential with chest X-ray
images. This integration enhances the ability of model to understand and
describe chest X-ray images. Our model combines an image encoder with a
fine-tuned LLM based on the Vicuna-7B architecture, enabling it to generate
different sections of a radiology report with notable accuracy. The training
process involves a two-stage approach: (i) initial alignment of chest X-ray
features with the LLM (ii) followed by fine-tuning for radiology report
generation.

摘要：我們引入了一個專注於放射學的視覺語言模型，旨在根據胸部 X 光片生成放射學報告。根據先前的研究發現，當大型語言模型 (LLM) 與預訓練的視覺編碼器對齊時，可以獲得多模態能力，我們展示了胸部 X 光影像的類似潛力。這種整合增強了模型理解和描述胸部 X 光影像的能力。我們的模型結合了一個影像編碼器和一個基於 Vicuna-7B 架構的微調 LLM，使其能夠以顯著的準確度生成放射學報告的不同部分。訓練過程涉及一個兩階段方法：(i) 胸部 X 光特徵與 LLM 的初始對齊 (ii) 接著進行放射學報告生成的微調。

##### **Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**
2412.04950v1 by Thomas Bartz-Beielstein, Axel Wellendorf, Noah Pütz, Jens Brandt, Alexander Hinterleitner, Richard Schulz, Richard Scholz, Olaf Mersmann, Robin Knabe

The increasing shortage of nursing staff and the acute risk of falls in
nursing homes pose significant challenges for the healthcare system. This study
presents the development of an automated fall detection system integrated into
care beds, aimed at enhancing patient safety without compromising privacy
through wearables or video monitoring. Mechanical vibrations transmitted
through the bed frame are processed using a short-time Fourier transform,
enabling robust classification of distinct human fall patterns with a
convolutional neural network. Challenges pertaining to the quantity and
diversity of the data are addressed, proposing the generation of additional
data with a specific emphasis on enhancing variation. While the model shows
promising results in distinguishing fall events from noise using lab data,
further testing in real-world environments is recommended for validation and
improvement. Despite limited available data, the proposed system shows the
potential for an accurate and rapid response to falls, mitigating health
implications, and addressing the needs of an aging population. This case study
was performed as part of the ZIM Project. Further research on sensors enhanced
by artificial intelligence will be continued in the ShapeFuture Project.

摘要：護理人員日益短缺，且護理之家發生跌倒的風險極高，對醫療保健系統構成重大挑戰。本研究提出將自動化跌倒偵測系統整合至護理床，旨在提升病患安全，同時透過穿戴式裝置或視訊監控來保護隱私。透過床架傳遞的機械振動會使用短時距傅立葉轉換進行處理，並能利用卷積神經網路對不同人類跌倒模式進行穩健分類。針對資料數量和多樣性的挑戰，提出產生額外資料的建議，特別著重於增加變化性。雖然此模型在使用實驗室資料區分跌倒事件和雜訊時顯示出有希望的結果，但建議在真實環境中進一步測試以進行驗證和改進。儘管可用資料有限，但所提出的系統顯示出對跌倒事件做出準確且快速的反應的潛力，減輕健康影響，並滿足老齡化人口的需求。此案例研究是作為 ZIM 專案的一部分進行的。ShapeFuture 專案將持續進行人工智慧增強感測器的進一步研究。

##### **KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**
2412.04948v1 by Peng Yu, Cheng Deng, Beiya Dai, Xinbing Wang, Ying Wen

Autoregressive large language models (LLMs) pre-trained by next token
prediction are inherently proficient in generative tasks. However, their
performance on knowledge-driven tasks such as factual knowledge querying
remains unsatisfactory. Knowledge graphs (KGs), as high-quality structured
knowledge bases, can provide reliable knowledge for LLMs, potentially
compensating for their knowledge deficiencies. Aligning LLMs with explicit,
structured knowledge from KGs has been a challenge; previous attempts either
failed to effectively align knowledge representations or compromised the
generative capabilities of LLMs, leading to less-than-optimal outcomes. This
paper proposes \textbf{KaLM}, a \textit{Knowledge-aligned Language Modeling}
approach, which fine-tunes autoregressive LLMs to align with KG knowledge via
the joint objective of explicit knowledge alignment and implicit knowledge
alignment. The explicit knowledge alignment objective aims to directly optimize
the knowledge representation of LLMs through dual-view knowledge graph
contrastive learning. The implicit knowledge alignment objective focuses on
incorporating textual patterns of knowledge into LLMs through triple completion
language modeling. Notably, our method achieves a significant performance boost
in evaluations of knowledge-driven tasks, specifically embedding-based
knowledge graph completion and generation-based knowledge graph question
answering.

摘要：<paragraph>自動回歸大型語言模型 (LLM) 經由下一個符號預測預先訓練，本質上擅長生成式任務。然而，它們在知識驅動任務（例如事實知識查詢）上的表現仍不盡人意。知識圖譜 (KG) 作為高品質的結構化知識庫，可以為 LLM 提供可靠的知識，潛在地彌補其知識不足。將 LLM 與來自 KG 的明確結構化知識對齊一直是一項挑戰；先前的嘗試要么無法有效對齊知識表示，要么損害 LLM 的生成能力，導致結果不盡理想。本文提出了一個**KaLM**，一種**知識對齊語言建模**方法，它微調自動回歸 LLM 以透過明確知識對齊和隱式知識對齊的聯合目標與 KG 知識對齊。明確知識對齊目標旨在透過雙視圖知識圖譜對比學習直接最佳化 LLM 的知識表示。隱式知識對齊目標專注於透過三元組完成語言建模將知識的文字模式納入 LLM。值得注意的是，我們的模型在知識驅動任務的評估中獲得顯著的效能提升，特別是基於嵌入的知識圖譜完成和基於生成的知識圖譜問題解答。</paragraph>

##### **C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation**
2412.04947v1 by Yanyang Li, Tin Long Wong, Cheung To Hung, Jianqiao Zhao, Duo Zheng, Ka Wai Liu, Michael R. Lyu, Liwei Wang

Recent advances in large language models (LLMs) have shown significant
promise, yet their evaluation raises concerns, particularly regarding data
contamination due to the lack of access to proprietary training data. To
address this issue, we present C$^2$LEVA, a comprehensive bilingual benchmark
featuring systematic contamination prevention. C$^2$LEVA firstly offers a
holistic evaluation encompassing 22 tasks, each targeting a specific
application or ability of LLMs, and secondly a trustworthy assessment due to
our contamination-free tasks, ensured by a systematic contamination prevention
strategy that fully automates test data renewal and enforces data protection
during benchmark data release. Our large-scale evaluation of 15 open-source and
proprietary models demonstrates the effectiveness of C$^2$LEVA.

摘要：大型語言模型 (LLM) 最近的進展已展現出顯著的希望，但其評估引發了疑慮，特別是對於由於無法取得專有訓練資料而導致資料污染的疑慮。為了解決此問題，我們提出 C$^2$LEVA，一個具有系統性污染防範的全面雙語基準。C$^2$LEVA 首先提供一個全面評估，包含 22 項任務，每個任務都針對 LLM 的特定應用或能力，其次，由於我們無污染的任務，因此提供了一個值得信賴的評估，這由一個系統性的污染防範策略確保，該策略完全自動化測試資料更新，並在基準資料發布期間執行資料保護。我們對 15 個開源和專有模型進行的大規模評估證明了 C$^2$LEVA 的有效性。

##### **A Federated Approach to Few-Shot Hate Speech Detection for Marginalized Communities**
2412.04942v1 by Haotian Ye, Axel Wisiorek, Antonis Maronikolakis, Özge Alaçam, Hinrich Schütze

Hate speech online remains an understudied issue for marginalized
communities, and has seen rising relevance, especially in the Global South,
which includes developing societies with increasing internet penetration. In
this paper, we aim to provide marginalized communities living in societies
where the dominant language is low-resource with a privacy-preserving tool to
protect themselves from hate speech on the internet by filtering offensive
content in their native languages. Our contribution in this paper is twofold:
1) we release REACT (REsponsive hate speech datasets Across ConTexts), a
collection of high-quality, culture-specific hate speech detection datasets
comprising seven distinct target groups in eight low-resource languages,
curated by experienced data collectors; 2) we propose a solution to few-shot
hate speech detection utilizing federated learning (FL), a privacy-preserving
and collaborative learning approach, to continuously improve a central model
that exhibits robustness when tackling different target groups and languages.
By keeping the training local to the users' devices, we ensure the privacy of
the users' data while benefitting from the efficiency of federated learning.
Furthermore, we personalize client models to target-specific training data and
evaluate their performance. Our results indicate the effectiveness of FL across
different target groups, whereas the benefits of personalization on few-shot
learning are not clear.

摘要：在線仇恨言論對於少數族群來說仍然是一個研究不足的問題，並且越來越重要，特別是在全球南方，其中包括網路普及率越來越高的開發中國家。在本文中，我們旨在為生活在主流語言為低資源語言的社會中的少數族群提供一個保護隱私的工具，以透過過濾母語中的攻擊性內容來保護他們免於網路上的仇恨言論。我們在本文中的貢獻有兩個：1）我們發布了 REACT（語境中的回應式仇恨言論資料集），這是一個由經驗豐富的資料收集者策劃的高品質、特定文化仇恨言論偵測資料集，包含八種低資源語言中的七個不同目標族群；2）我們提出了一個利用聯盟式學習（FL）的少發言論偵測解決方案，這是一種保護隱私和協作學習的方法，可以持續改善一個在處理不同目標族群和語言時表現出穩健性的中央模型。透過讓訓練保持在使用者的裝置上，我們確保使用者的資料隱私，同時受益於聯盟式學習的效率。此外，我們將用戶端模型個人化到特定訓練資料，並評估其效能。我們的結果顯示聯盟式學習在不同目標族群中是有效的，而個人化在少發言論學習中的優點則不明確。

##### **Who Speaks Next? Multi-party AI Discussion Leveraging the Systematics of Turn-taking in Murder Mystery Games**
2412.04937v1 by Ryota Nonomura, Hiroki Mori

Multi-agent systems utilizing large language models (LLMs) have shown great
promise in achieving natural dialogue. However, smooth dialogue control and
autonomous decision making among agents still remain challenges. In this study,
we focus on conversational norms such as adjacency pairs and turn-taking found
in conversation analysis and propose a new framework called "Murder Mystery
Agents" that applies these norms to AI agents' dialogue control. As an
evaluation target, we employed the "Murder Mystery" game, a reasoning-type
table-top role-playing game that requires complex social reasoning and
information manipulation. In this game, players need to unravel the truth of
the case based on fragmentary information through cooperation and bargaining.
The proposed framework integrates next speaker selection based on adjacency
pairs and a self-selection mechanism that takes agents' internal states into
account to achieve more natural and strategic dialogue. To verify the
effectiveness of this new approach, we analyzed utterances that led to dialogue
breakdowns and conducted automatic evaluation using LLMs, as well as human
evaluation using evaluation criteria developed for the Murder Mystery game.
Experimental results showed that the implementation of the next speaker
selection mechanism significantly reduced dialogue breakdowns and improved the
ability of agents to share information and perform logical reasoning. The
results of this study demonstrate that the systematics of turn-taking in human
conversation are also effective in controlling dialogue among AI agents, and
provide design guidelines for more advanced multi-agent dialogue systems.

摘要：利用大型語言模型 (LLM) 的多主體系統在實現自然對話方面展現了極佳的潛力。然而，流暢的對話控制和主體間的自主決策仍是挑戰。在本研究中，我們專注於對話分析中發現的鄰接對和輪流發言等對話規範，並提出一個名為「謀殺謎團主體」的新架構，將這些規範應用於 AI 主體的對話控制。作為評量目標，我們採用「謀殺謎團」遊戲，這是一款推理型桌上角色扮演遊戲，需要複雜的社會推理和資訊操縱。在這個遊戲中，玩家需要透過合作和協商，根據片斷資訊解開案件的真相。所提出的架構整合了基於鄰接對的下一個發言者選擇，以及考量主體內部狀態的自我選擇機制，以實現更自然且具策略性的對話。為了驗證這個新方法的有效性，我們分析了導致對話中斷的發話，並使用 LLM 進行自動評量，以及使用為謀殺謎團遊戲開發的評量標準進行人工評量。實驗結果顯示，實施下一個發言者選擇機制顯著減少了對話中斷，並提升了主體分享資訊和進行邏輯推理的能力。本研究結果證明，人類對話中輪流發言的系統性在控制 AI 主體間的對話方面也同樣有效，並為更先進的多主體對話系統提供了設計方針。

##### **Probing the contents of semantic representations from text, behavior, and brain data using the psychNorms metabase**
2412.04936v1 by Zak Hussain, Rui Mata, Ben R. Newell, Dirk U. Wulff

Semantic representations are integral to natural language processing,
psycholinguistics, and artificial intelligence. Although often derived from
internet text, recent years have seen a rise in the popularity of
behavior-based (e.g., free associations) and brain-based (e.g., fMRI)
representations, which promise improvements in our ability to measure and model
human representations. We carry out the first systematic evaluation of the
similarities and differences between semantic representations derived from
text, behavior, and brain data. Using representational similarity analysis, we
show that word vectors derived from behavior and brain data encode information
that differs from their text-derived cousins. Furthermore, drawing on our
psychNorms metabase, alongside an interpretability method that we call
representational content analysis, we find that, in particular, behavior
representations capture unique variance on certain affective, agentic, and
socio-moral dimensions. We thus establish behavior as an important complement
to text for capturing human representations and behavior. These results are
broadly relevant to research aimed at learning human-aligned semantic
representations, including work on evaluating and aligning large language
models.

摘要：語意表徵對於自然語言處理、心理語言學和人工智慧來說是不可或缺的。儘管經常從網路文字中衍生，但近年來行為為基礎（例如自由聯想）和腦為基礎（例如 fMRI）的表徵越來越受到歡迎，這有望改善我們衡量和建模人類表徵的能力。我們對從文字、行為和腦部資料衍生的語意表徵之間的相似性和差異進行了首次系統性評估。透過使用表徵相似性分析，我們顯示從行為和腦部資料衍生的詞向量編碼的信息不同於其從文字衍生的表親。此外，利用我們的 psychNorms 元資料庫，以及我們稱之為表徵內容分析的可解釋性方法，我們發現行為表徵特別會捕捉某些情感、能動和社會道德層面的獨特變異。因此，我們將行為確立為捕捉人類表徵和行為的文字重要補充。這些結果與旨在學習與人類一致的語意表徵的研究廣泛相關，包括評估和調整大型語言模型的工作。

##### **Uncertainty-aware retinal layer segmentation in OCT through probabilistic signed distance functions**
2412.04935v1 by Mohammad Mohaiminul Islam, Coen de Vente, Bart Liefers, Caroline Klaver, Erik J Bekkers, Clara I. Sánchez

In this paper, we present a new approach for uncertainty-aware retinal layer
segmentation in Optical Coherence Tomography (OCT) scans using probabilistic
signed distance functions (SDF). Traditional pixel-wise and regression-based
methods primarily encounter difficulties in precise segmentation and lack of
geometrical grounding respectively. To address these shortcomings, our
methodology refines the segmentation by predicting a signed distance function
(SDF) that effectively parameterizes the retinal layer shape via level set. We
further enhance the framework by integrating probabilistic modeling, applying
Gaussian distributions to encapsulate the uncertainty in the shape
parameterization. This ensures a robust representation of the retinal layer
morphology even in the presence of ambiguous input, imaging noise, and
unreliable segmentations. Both quantitative and qualitative evaluations
demonstrate superior performance when compared to other methods. Additionally,
we conducted experiments on artificially distorted datasets with various noise
types-shadowing, blinking, speckle, and motion-common in OCT scans to showcase
the effectiveness of our uncertainty estimation. Our findings demonstrate the
possibility to obtain reliable segmentation of retinal layers, as well as an
initial step towards the characterization of layer integrity, a key biomarker
for disease progression. Our code is available at
\url{https://github.com/niazoys/RLS_PSDF}.

摘要：<paragraph>在本文中，我們提出了一種新的方法，用於光學相干斷層掃描 (OCT) 中的不確定性視網膜層分割，使用機率簽署距離函數 (SDF)。傳統的逐像素和基於回歸的方法主要在精確分割和缺乏幾何基礎方面遇到困難。為了解決這些缺點，我們的算法通過預測一個簽署距離函數 (SDF) 來改善分割，該函數通過水平集有效地參數化視網膜層形狀。我們進一步通過整合機率建模來增強框架，應用高斯分布來封裝形狀參數化的不確定性。這確保了視網膜層形態的穩健表示，即使在存在模糊輸入、成像雜訊和不可靠分割的情況下也是如此。與其他方法相比，定量和定性評估都證明了優越的性能。此外，我們在具有各種雜訊類型（陰影、眨眼、斑點和運動）的人工扭曲數據集上進行了實驗，這些雜訊類型在 OCT 掃描中很常見，以展示我們的不確定性估計的有效性。我們的研究結果證明了獲得視網膜層可靠分割的可能性，以及朝著表徵層完整性（疾病進展的一個關鍵生物標誌）邁出的第一步。我們的代碼可以在 \url{https://github.com/niazoys/RLS_PSDF} 獲得。</paragraph>

##### **Continuous Video Process: Modeling Videos as Continuous Multi-Dimensional Processes for Video Prediction**
2412.04929v1 by Gaurav Shrivastava, Abhinav Shrivastava

Diffusion models have made significant strides in image generation, mastering
tasks such as unconditional image synthesis, text-image translation, and
image-to-image conversions. However, their capability falls short in the realm
of video prediction, mainly because they treat videos as a collection of
independent images, relying on external constraints such as temporal attention
mechanisms to enforce temporal coherence. In our paper, we introduce a novel
model class, that treats video as a continuous multi-dimensional process rather
than a series of discrete frames. We also report a reduction of 75\% sampling
steps required to sample a new frame thus making our framework more efficient
during the inference time. Through extensive experimentation, we establish
state-of-the-art performance in video prediction, validated on benchmark
datasets including KTH, BAIR, Human3.6M, and UCF101. Navigate to the project
page https://www.cs.umd.edu/~gauravsh/cvp/supp/website.html for video results.}

摘要：擴散模型在影像生成方面取得顯著進展，掌握無條件影像合成、文字影像翻譯和影像轉換等任務。然而，它們在影片預測領域的能力不足，主要是因為它們將影片視為獨立影像的集合，依賴於時間注意力機制等外部約束來強制時間相干性。在我們的論文中，我們引入了一個新穎的模型類別，將影片視為一個連續的多維過程，而不是一系列的離散幀。我們還報告了對採樣新幀所需採樣步驟的 75% 減少，從而使我們的框架在推理時間內更有效率。透過廣泛的實驗，我們建立了影片預測的最新技術，驗證了包括 KTH、BAIR、Human3.6M 和 UCF101 在內的基準資料集。前往專案頁面 https://www.cs.umd.edu/~gauravsh/cvp/supp/website.html 以取得影片結果。

##### **HyperGraphOS: A Meta Operating System for Science and Engineering**
2412.04923v1 by Antonello Ceravola, Frank Joublin, Ahmed R. Sadik, Bram Bolder, Juha-Pekka Tolvanen

This paper presents HyperGraphOS, an innovative Operating System designed for
the scientific and engineering domains. It combines model based engineering,
graph modeling, data containers, and computational tools, offering users a
dynamic workspace for creating and managing complex models represented as
customizable graphs. Using a web based architecture, HyperGraphOS requires only
a modern browser to organize knowledge, documents, and content into
interconnected models. Domain Specific Languages drive workspace navigation,
code generation, AI integration, and process organization.The platform models
function as both visual drawings and data structures, enabling dynamic
modifications and inspection, both interactively and programmatically.
HyperGraphOS was evaluated across various domains, including virtual avatars,
robotic task planning using Large Language Models, and meta modeling for
feature based code development. Results show significant improvements in
flexibility, data management, computation, and document handling.

摘要：本文提出 HyperGraphOS，這是一個創新的作業系統，專為科學和工程領域設計。它結合了基於模型的工程、圖形建模、資料容器和計算工具，為使用者提供一個動態工作空間，用於建立和管理表示為可自訂圖形的複雜模型。HyperGraphOS 使用基於 Web 的架構，只需要一個現代瀏覽器即可將知識、文件和內容組織成互連模型。特定領域語言驅動工作空間導覽、程式碼產生、AI 整合和流程組織。平台模型同時作為視覺繪圖和資料結構，支援動態修改和檢查，無論是互動式還是以程式方式進行。HyperGraphOS 已在各種領域中進行評估，包括虛擬化身、使用大型語言模型的機器人任務規劃，以及用於基於特徵的程式碼開發的元建模。結果顯示出靈活性、資料管理、運算和文件處理方面的顯著改進。

##### **Large Language Models for Ingredient Substitution in Food Recipes using Supervised Fine-tuning and Direct Preference Optimization**
2412.04922v1 by Thevin Senath, Kumuthu Athukorala, Ransika Costa, Surangika Ranathunga, Rishemjit Kaur

In this paper, we address the challenge of recipe personalization through
ingredient substitution. We make use of Large Language Models (LLMs) to build
an ingredient substitution system designed to predict plausible substitute
ingredients within a given recipe context. Given that the use of LLMs for this
task has been barely done, we carry out an extensive set of experiments to
determine the best LLM, prompt, and the fine-tuning setups. We further
experiment with methods such as multi-task learning, two-stage fine-tuning, and
Direct Preference Optimization (DPO). The experiments are conducted using the
publicly available Recipe1MSub corpus. The best results are produced by the
Mistral7-Base LLM after fine-tuning and DPO. This result outperforms the strong
baseline available for the same corpus with a Hit@1 score of 22.04. Thus we
believe that this research represents a significant step towards enabling
personalized and creative culinary experiences by utilizing LLM-based
ingredient substitution.

摘要：在本文中，我们透過食材替換來解決食譜個人化的挑戰。我們使用大型語言模型 (LLM) 來建構食材替換系統，旨在預測在給定食譜背景下合理的替代食材。由於鮮少將 LLM 用於此任務，因此我們進行了一系列廣泛的實驗，以找出最佳的 LLM、提示和微調設定。我們進一步嘗試多任務學習、兩階段微調和直接偏好最佳化 (DPO) 等方法。這些實驗是使用公開的 Recipe1MSub 語料庫進行的。微調和 DPO 後，Mistral7-Base LLM 產生了最佳結果。此結果優於針對相同語料庫提供的強大基準，其 Hit@1 分數為 22.04。因此，我們相信這項研究代表著利用基於 LLM 的食材替換，朝著實現個人化且富有創意的料理體驗邁出了一大步。

##### **DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling**
2412.04905v1 by Minzheng Wang, Xinghua Zhang, Kun Chen, Nan Xu, Haiyang Yu, Fei Huang, Wenji Mao, Yongbin Li

Large language models (LLMs) have made dialogue one of the central modes of
human-machine interaction, leading to the accumulation of vast amounts of
conversation logs and increasing demand for dialogue generation. A
conversational life-cycle spans from the Prelude through the Interlocution to
the Epilogue, encompassing various elements. Despite the existence of numerous
dialogue-related studies, there is a lack of benchmarks that encompass
comprehensive dialogue elements, hindering precise modeling and systematic
evaluation. To bridge this gap, we introduce an innovative research task
$\textbf{D}$ialogue $\textbf{E}$lement $\textbf{MO}$deling, including
$\textit{Element Awareness}$ and $\textit{Dialogue Agent Interaction}$, and
propose a novel benchmark, $\textbf{DEMO}$, designed for a comprehensive
dialogue modeling and assessment. Inspired by imitation learning, we further
build the agent which possesses the adept ability to model dialogue elements
based on the DEMO benchmark. Extensive experiments indicate that existing LLMs
still exhibit considerable potential for enhancement, and our DEMO agent has
superior performance in both in-domain and out-of-domain tasks.

摘要：大型語言模型 (LLM) 已將對話作為人機互動的主要模式之一，導致對話記錄大量累積，對話生成的需求也隨之增加。對話生命週期從序幕跨越到對話，再到尾聲，涵蓋各種元素。儘管有許多與對話相關的研究，但缺乏包含全面對話元素的基準，阻礙了精確建模和系統性評估。為了彌補這一差距，我們引入了一項創新的研究任務 $\textbf{D}$ialogue $\textbf{E}$lement $\textbf{MO}$deling，包括 $\textit{Element Awareness}$ 和 $\textit{Dialogue Agent Interaction}$，並提出了一個新的基準 $\textbf{DEMO}$，專門用於全面的對話建模和評估。受到模仿學習的啟發，我們進一步建立了代理，它具備根據 DEMO 基準對話元素進行建模的靈巧能力。大量的實驗表明，現有的 LLM 仍展現出相當大的增強潛力，而我們的 DEMO 代理在領域內和領域外任務中都具有卓越的性能。

##### **EACO: Enhancing Alignment in Multimodal LLMs via Critical Observation**
2412.04903v1 by Yongxin Wang, Meng Cao, Haokun Lin, Mingfei Han, Liang Ma, Jin Jiang, Yuhao Cheng, Xiaodan Liang

Multimodal large language models (MLLMs) have achieved remarkable progress on
various visual question answering and reasoning tasks leveraging instruction
fine-tuning specific datasets. They can also learn from preference data
annotated by human to enhance their reasoning ability and mitigate
hallucinations. Most of preference data is generated from the model itself.
However, existing methods require high-quality critical labels, which are
costly and rely on human or proprietary models like GPT-4V. In this work, we
propose Enhancing Alignment in MLLMs via Critical Observation (EACO), which
aligns MLLMs by self-generated preference data using only 5k images
economically. Our approach begins with collecting and refining a Scoring
Evaluation Instruction-tuning dataset to train a critical evaluation model,
termed the Critic. This Critic observes model responses across multiple
dimensions, selecting preferred and non-preferred outputs for refined Direct
Preference Optimization (DPO) tuning. To further enhance model performance, we
employ an additional supervised fine-tuning stage after preference tuning. EACO
reduces the overall hallucinations by 65.6% on HallusionBench and improves the
reasoning ability by 21.8% on MME-Cognition. EACO achieves an 8.5% improvement
over LLaVA-v1.6-Mistral-7B across multiple benchmarks. Remarkably, EACO also
shows the potential critical ability in open-source MLLMs, demonstrating that
EACO is a viable path to boost the competence of MLLMs.

摘要：多模态大型语言模型 (MLLM) 在各种视觉问题解答和推理任务上取得了显著进展，利用指令微调特定数据集。它们还可以从人类标注的首选项数据中学习，以增强其推理能力并减轻幻觉。大多数首选项数据都是由模型本身生成的。然而，现有方法需要高质量的关键标签，这既昂贵又依赖于 GPT-4V 等人类或专有模型。在这项工作中，我们提出了通过关键观察（EACO）增强 MLLM 中的对齐，它仅使用 5k 张图像经济地通过自生成的偏好数据对齐 MLLM。我们的方法首先从收集和优化评分评估指令调整数据集开始，以训练一个关键评估模型，称为 Critic。该 Critic 观察跨多个维度的模型响应，为改进的直接偏好优化 (DPO) 调整选择首选和非首选输出。为了进一步提高模型性能，我们在偏好调整后采用了额外的监督微调阶段。EACO 在 HallusionBench 上将整体幻觉减少了 65.6%，并在 MME-Cognition 上将推理能力提高了 21.8%。EACO 在多个基准测试中比 LLaVA-v1.6-Mistral-7B 提高了 8.5%。值得注意的是，EACO 也显示了开源 MLLM 中潜在的关键能力，这表明 EACO 是提升 MLLM 能力的可行途径。

##### **AI-Driven Non-Invasive Detection and Staging of Steatosis in Fatty Liver Disease Using a Novel Cascade Model and Information Fusion Techniques**
2412.04884v1 by Niloufar Delfan, Pardis Ketabi Moghadam, Mohammad Khoshnevisan, Mehdi Hosseini Chagahi, Behzad Hatami, Melika Asgharzadeh, Mohammadreza Zali, Behzad Moshiri, Amin Momeni Moghaddam, Mohammad Amin Khalafi, Khosrow Dehnad

Non-alcoholic fatty liver disease (NAFLD) is one of the most widespread liver
disorders on a global scale, posing a significant threat of progressing to more
severe conditions like nonalcoholic steatohepatitis (NASH), liver fibrosis,
cirrhosis, and hepatocellular carcinoma. Diagnosing and staging NAFLD presents
challenges due to its non-specific symptoms and the invasive nature of liver
biopsies. Our research introduces a novel artificial intelligence cascade model
employing ensemble learning and feature fusion techniques. We developed a
non-invasive, robust, and reliable diagnostic artificial intelligence tool that
utilizes anthropometric and laboratory parameters, facilitating early detection
and intervention in NAFLD progression. Our novel artificial intelligence
achieved an 86% accuracy rate for the NASH steatosis staging task (non-NASH,
steatosis grade 1, steatosis grade 2, and steatosis grade 3) and an impressive
96% AUC-ROC for distinguishing between NASH (steatosis grade 1, grade 2, and
grade3) and non-NASH cases, outperforming current state-of-the-art models. This
notable improvement in diagnostic performance underscores the potential
application of artificial intelligence in the early diagnosis and treatment of
NAFLD, leading to better patient outcomes and a reduced healthcare burden
associated with advanced liver disease.

摘要：非酒精性脂肪肝疾病 (NAFLD) 是全球最普遍的肝臟疾病之一，它會嚴重威脅進展成更嚴重的疾病，例如非酒精性脂肪性肝炎 (NASH)、肝纖維化、肝硬化和肝細胞癌。診斷和分期 NAFLD 具有挑戰性，因為它的症狀不具特異性，而且肝臟活檢具有侵入性。我們的研究引入了一個新的人工智慧串聯模型，採用整合學習和特徵融合技術。我們開發了一個非侵入性、穩健且可靠的診斷人工智慧工具，利用人類測量和實驗室參數，促進 NAFLD 進展的早期檢測和干預。我們新的人工智慧在 NASH 脂肪變性分期任務（非 NASH、脂肪變性 1 級、脂肪變性 2 級和脂肪變性 3 級）中達到 86% 的準確率，並且在區分 NASH（脂肪變性 1 級、2 級和 3 級）和非 NASH 病例方面達到令人印象深刻的 96% AUC-ROC，優於當前最先進的模型。這種診斷效能的顯著提升突顯了人工智慧在 NAFLD 早期診斷和治療中的潛在應用，從而導致更好的患者預後和降低與晚期肝病相關的醫療保健負擔。

##### **Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud**
2412.04871v1 by Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang

Specializing LLMs in various domain-specific tasks has emerged as a critical
step towards achieving high performance. However, the construction and
annotation of datasets in specific domains are always very costly. Apart from
using superior and expensive closed-source LLM APIs to construct datasets, some
open-source models have become strong enough to handle dataset construction in
many scenarios. Thus, we present a family of data augmentation models designed
to significantly improve the efficiency for model fine-tuning. These models,
trained based on sufficiently small LLMs, support key functionalities with low
inference costs: instruction expansion, instruction refinement, and
instruction-response pair expansion. To fulfill this goal, we first construct
an automatic data collection system with seed datasets generated from both
public repositories and our in-house datasets. This system leverages powerful
LLMs to expand, refine and re-write the instructions and responses,
incorporating quality assessment techniques. Following this, we introduce the
training process of our models, which effectively distills task-solving and
text synthesis abilities from teacher LLMs. Finally, we demonstrate how we
integrate these functionalities into a machine learning platform to support
low-cost LLM fine-tuning from both dataset preparation and training
perspectives for users. Experiments and an application study prove the
effectiveness of our approach.

摘要：將 LLM 專門用於各種特定領域任務已成為實現高性能的一項關鍵步驟。然而，在特定領域構建和註解資料集的成本總是十分高昂。除了使用優越且昂貴的封閉原始碼 LLM API 來構建資料集之外，一些開放原始碼模型已變得足夠強大，足以在許多場景中處理資料集構建。因此，我們提出了一系列數據擴充模型，旨在顯著提高模型微調的效率。這些模型基於足夠小的 LLM 進行訓練，支援具有低推論成本的主要功能：指令擴充、指令改進和指令回應配對擴充。為實現此目標，我們首先使用從公共儲存庫和我們內部資料集產生的種子資料集構建自動數據收集系統。此系統利用強大的 LLM 來擴充、改進和重寫指令和回應，並納入品質評估技術。在此之後，我們介紹了我們模型的訓練過程，該過程有效地從教師 LLM 中提煉了解決任務和文字合成能力。最後，我們展示了如何將這些功能整合到機器學習平台中，以支援使用者從資料集準備和訓練角度進行低成本 LLM 微調。實驗和應用研究證明了我們方法的有效性。

##### **NebulaFL: Effective Asynchronous Federated Learning for JointCloud Computing**
2412.04868v1 by Fei Gao, Ming Hu, Zhiyu Xie, Peichang Shi, Xiaofei Xie, Guodong Yi, Huaimin Wang

With advancements in AI infrastructure and Trusted Execution Environment
(TEE) technology, Federated Learning as a Service (FLaaS) through JointCloud
Computing (JCC) is promising to break through the resource constraints caused
by heterogeneous edge devices in the traditional Federated Learning (FL)
paradigm. Specifically, with the protection from TEE, data owners can achieve
efficient model training with high-performance AI services in the cloud. By
providing additional FL services, cloud service providers can achieve
collaborative learning among data owners. However, FLaaS still faces three
challenges, i.e., i) low training performance caused by heterogeneous data
among data owners, ii) high communication overhead among different clouds
(i.e., data centers), and iii) lack of efficient resource scheduling strategies
to balance training time and cost. To address these challenges, this paper
presents a novel asynchronous FL approach named NebulaFL for collaborative
model training among multiple clouds. To address data heterogeneity issues,
NebulaFL adopts a version control-based asynchronous FL training scheme in each
data center to balance training time among data owners. To reduce communication
overhead, NebulaFL adopts a decentralized model rotation mechanism to achieve
effective knowledge sharing among data centers. To balance training time and
cost, NebulaFL integrates a reward-guided strategy for data owners selection
and resource scheduling. The experimental results demonstrate that, compared to
the state-of-the-art FL methods, NebulaFL can achieve up to 5.71\% accuracy
improvement. In addition, NebulaFL can reduce up to 50% communication overhead
and 61.94% costs under a target accuracy.

摘要：<paragraph>隨著 AI 基礎設施和可信執行環境 (TEE) 技術的進步，透過聯合雲端運算 (JCC) 的聯合學習即服務 (FLaaS) 有望突破傳統聯合學習 (FL) 典範中異質邊緣裝置所造成的資源限制。具體來說，透過 TEE 的保護，資料擁有者可以在雲端中透過高性能 AI 服務達成有效率的模型訓練。雲端服務供應商透過提供額外的 FL 服務，可以在資料擁有者之間達成協作學習。然而，FLaaS 仍面臨三項挑戰，即：一) 資料擁有者之間的異質資料所造成的低訓練效能、二) 不同雲端 (即資料中心) 之間的高通訊負擔，以及三) 缺乏有效率的資源排程策略來平衡訓練時間和成本。為了因應這些挑戰，本文提出名為 NebulaFL 的創新非同步 FL 方法，用於多個雲端之間的協作模型訓練。為了因應資料異質性的問題，NebulaFL 在每個資料中心採用基於版本控制的非同步 FL 訓練方案，以平衡資料擁有者之間的訓練時間。為了降低通訊負擔，NebulaFL 採用分散式模型輪替機制，以在資料中心之間達成有效的知識分享。為了平衡訓練時間和成本，NebulaFL 整合了獎勵引導策略，用於資料擁有者選擇和資源排程。實驗結果顯示，與現有的 FL 方法相比，NebulaFL 可達成高達 5.71% 的準確度提升。此外，NebulaFL 在目標準確度下可降低高達 50% 的通訊負擔和 61.94% 的成本。</paragraph>

##### **EXAONE 3.5: Series of Large Language Models for Real-world Use Cases**
2412.04862v1 by LG AI Research, Soyoung An, Kyunghoon Bae, Eunbi Choi, Kibong Choi, Stanley Jungkyu Choi, Seokhee Hong, Junwon Hwang, Hyojin Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Yountae Jung, Hyosang Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Yongil Kim, Youchul Kim, Edward Hwayoung Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Woohyung Lim, Sangha Park, Sooyoun Park, Yongmin Park, Sihoon Yang, Heuiyeen Yeen, Hyeongu Yun

This technical report introduces the EXAONE 3.5 instruction-tuned language
models, developed and released by LG AI Research. The EXAONE 3.5 language
models are offered in three configurations: 32B, 7.8B, and 2.4B. These models
feature several standout capabilities: 1) exceptional instruction following
capabilities in real-world scenarios, achieving the highest scores across seven
benchmarks, 2) outstanding long-context comprehension, attaining the top
performance in four benchmarks, and 3) competitive results compared to
state-of-the-art open models of similar sizes across nine general benchmarks.
The EXAONE 3.5 language models are open to anyone for research purposes and can
be downloaded from https://huggingface.co/LGAI-EXAONE. For commercial use,
please reach out to the official contact point of LG AI Research:
contact_us@lgresearch.ai.

摘要：這份技術報告介紹了 LG AI Research 開發並發布的 EXAONE 3.5 指令調整語言模型。EXAONE 3.5 語言模型提供三種配置：32B、7.8B 和 2.4B。這些模型具有幾項傑出的功能：1) 在現實世界場景中具有出色的指令遵循能力，在七項基準測試中獲得最高分，2) 出色的長語境理解能力，在四項基準測試中獲得最高績效，以及 3) 與九項一般基準測試中類似規模的最新開放模型相比具有競爭力的結果。EXAONE 3.5 語言模型對任何研究目的開放，可從 https://huggingface.co/LGAI-EXAONE 下載。如要商業使用，請聯繫 LG AI Research 的官方聯絡點：contact_us@lgresearch.ai。

##### **Breaking Event Rumor Detection via Stance-Separated Multi-Agent Debate**
2412.04859v1 by Mingqing Zhang, Haisong Gong, Qiang Liu, Shu Wu, Liang Wang

The rapid spread of rumors on social media platforms during breaking events
severely hinders the dissemination of the truth. Previous studies reveal that
the lack of annotated resources hinders the direct detection of unforeseen
breaking events not covered in yesterday's news. Leveraging large language
models (LLMs) for rumor detection holds significant promise. However, it is
challenging for LLMs to provide comprehensive responses to complex or
controversial issues due to limited diversity. In this work, we propose the
Stance Separated Multi-Agent Debate (S2MAD) to address this issue.
Specifically, we firstly introduce Stance Separation, categorizing comments as
either supporting or opposing the original claim. Subsequently, claims are
classified as subjective or objective, enabling agents to generate reasonable
initial viewpoints with different prompt strategies for each type of claim.
Debaters then follow specific instructions through multiple rounds of debate to
reach a consensus. If a consensus is not reached, a judge agent evaluates the
opinions and delivers a final verdict on the claim's veracity. Extensive
experiments conducted on two real-world datasets demonstrate that our proposed
model outperforms state-of-the-art methods in terms of performance and
effectively improves the performance of LLMs in breaking event rumor detection.

摘要：在突發事件期間，謠言在社群媒體平台上的快速傳播嚴重阻礙了真相的傳播。先前的研究表明，缺乏註解資源阻礙了對昨日新聞未涵蓋的突發事件的直接偵測。利用大型語言模型 (LLM) 進行謠言偵測具有顯著的潛力。然而，由於多樣性有限，LLM 難以對複雜或有爭議的問題提供全面的回應。在這項工作中，我們提出立場分隔的多主體辯論 (S2MAD) 來解決這個問題。具體來說，我們首先引入立場分隔，將評論分類為支持或反對原始說法。隨後，將說法分類為主觀或客觀，使主體能夠針對每種類型的說法產生合理的初始觀點，並採用不同的提示策略。然後，辯論者遵循具體的指示進行多輪辯論，以達成共識。如果未達成共識，法官主體會評估意見並對說法的真實性做出最終裁決。在兩個真實世界資料集上進行的廣泛實驗表明，我們提出的模型在效能方面優於最先進的方法，並有效提升了 LLM 在突發事件謠言偵測中的效能。

##### **Neuro-Symbolic Data Generation for Math Reasoning**
2412.04857v1 by Zenan Li, Zhi Zhou, Yuan Yao, Yu-Feng Li, Chun Cao, Fan Yang, Xian Zhang, Xiaoxing Ma

A critical question about Large Language Models (LLMs) is whether their
apparent deficiency in mathematical reasoning is inherent, or merely a result
of insufficient exposure to high-quality mathematical data. To explore this, we
developed an automated method for generating high-quality, supervised
mathematical datasets. The method carefully mutates existing math problems,
ensuring both diversity and validity of the newly generated problems. This is
achieved by a neuro-symbolic data generation framework combining the intuitive
informalization strengths of LLMs, and the precise symbolic reasoning of math
solvers along with projected Markov chain Monte Carlo sampling in the
highly-irregular symbolic space. Empirical experiments demonstrate the high
quality of data generated by the proposed method, and that the LLMs,
specifically LLaMA-2 and Mistral, when realigned with the generated data,
surpass their state-of-the-art counterparts.

摘要：大型語言模型 (LLM) 的一個關鍵問題是它們在數學推理上的明顯缺陷是固有的，還是僅僅是接觸高品質數學資料不足的結果。為了探討這一點，我們開發了一種自動化方法來生成高品質、有監督的數學資料集。此方法仔細地變異現有的數學問題，確保新生成問題的多樣性和有效性。這是透過神經符號資料生成架構來實現的，結合了 LLM 直觀的非正規化優勢，以及數學求解器的精確符號推理，以及在高度不規則的符號空間中預測的馬可夫鏈蒙地卡羅抽樣。實證實驗證明了所提出的方法生成資料的高品質，以及 LLM，特別是 LLaMA-2 和 Mistral，在與生成資料重新對齊後，超越了它們最先進的對應模型。

##### **MTSpark: Enabling Multi-Task Learning with Spiking Neural Networks for Generalist Agents**
2412.04847v1 by Avaneesh Devkota, Rachmad Vidya Wicaksana Putra, Muhammad Shafique

Currently, state-of-the-art RL methods excel in single-task settings, but
they still struggle to generalize across multiple tasks due to catastrophic
forgetting challenges, where previously learned tasks are forgotten as new
tasks are introduced. This multi-task learning capability is significantly
important for generalist agents, where adaptation features are highly required
(e.g., autonomous robots). On the other hand, Spiking Neural Networks (SNNs)
have emerged as alternative energy-efficient neural network algorithms due to
their sparse spike-based operations. Toward this, we propose MTSpark, a novel
methodology to enable multi-task RL using spiking networks. Specifically,
MTSpark develops a Deep Spiking Q-Network (DSQN) with active dendrites and
dueling structure by leveraging task-specific context signals. Specifically,
each neuron computes task-dependent activations that dynamically modulate
inputs, forming specialized sub-networks for each task. Moreover, this
bioplausible network model also benefits from SNNs, enhancing energy efficiency
and making the model suitable for hardware implementation. Experimental results
show that, our MTSpark effectively learns multiple tasks with higher
performance compared to the state-of-the-art. Specifically, MTSpark
successfully achieves high score in three Atari games (i.e., Pong: -5.4,
Breakout: 0.6, and Enduro: 371.2), reaching human-level performance (i.e.,
Pong: -3, Breakout: 31, and Enduro: 368), where state-of-the-art struggle to
achieve. In addition, our MTSpark also shows better accuracy in image
classification tasks than the state-of-the-art. These results highlight the
potential of our MTSpark methodology to develop generalist agents that can
learn multiple tasks by leveraging both RL and SNN concepts.

摘要：<paragraph>目前，最先進的 RL 方法在單一任務設定中表現出色，但由於災難性遺忘挑戰，它們在多任務中仍難以概括，其中先前學習的任務會隨著新任務的引入而被遺忘。這種多任務學習能力對於需要適應功能的通才代理來說非常重要（例如，自主機器人）。另一方面，由於稀疏的尖峰操作，脈衝神經網路 (SNN) 已成為替代的節能神經網路演算法。為此，我們提出了 MTSpark，這是一種使用脈衝網路啟用多任務 RL 的新方法。具體來說，MTSpark 開發了一個具有主動樹突和對決結構的深度脈衝 Q 網路 (DSQN)，利用特定任務的上下文信號。具體來說，每個神經元計算任務相關的激活，動態調節輸入，為每個任務形成專門的子網路。此外，這種生物合理網路模型也受益於 SNN，提高了能效，使模型適合於硬體實作。實驗結果表明，與最先進技術相比，我們的 MTSpark 有效地學習了多項任務，並具有更高的效能。具體來說，MTSpark 在三款 Atari 遊戲中成功獲得高分（即 Pong：-5.4，Breakout：0.6，和 Enduro：371.2），達到人類水準的表現（即 Pong：-3，Breakout：31，和 Enduro：368），而最先進的技術難以達到。此外，我們的 MTSpark 在影像分類任務中也顯示出比最先進技術更好的準確度。這些結果突顯了我們的 MTSpark 方法的潛力，它可以透過利用 RL 和 SNN 概念來開發能夠學習多項任務的通才代理。</paragraph>

##### **eXpath: Explaining Knowledge Graph Link Prediction with Ontological Closed Path Rules**
2412.04846v1 by Ye Sun, Lei Shi, Yongxin Tong

Link prediction (LP) is crucial for Knowledge Graphs (KG) completion but
commonly suffers from interpretability issues. While several methods have been
proposed to explain embedding-based LP models, they are generally limited to
local explanations on KG and are deficient in providing human interpretable
semantics. Based on real-world observations of the characteristics of KGs from
multiple domains, we propose to explain LP models in KG with path-based
explanations. An integrated framework, namely eXpath, is introduced which
incorporates the concept of relation path with ontological closed path rules to
enhance both the efficiency and effectiveness of LP interpretation. Notably,
the eXpath explanations can be fused with other single-link explanation
approaches to achieve a better overall solution. Extensive experiments across
benchmark datasets and LP models demonstrate that introducing eXpath can boost
the quality of resulting explanations by about 20% on two key metrics and
reduce the required explanation time by 61.4%, in comparison to the best
existing method. Case studies further highlight eXpath's ability to provide
more semantically meaningful explanations through path-based evidence.

摘要：連結預測 (LP) 對於知識圖譜 (KG) 的完成至關重要，但通常會遇到可解釋性的問題。雖然已經提出幾種方法來解釋基於嵌入的 LP 模型，但它們通常僅限於 KG 上的局部解釋，並且無法提供人類可解釋的語義。根據來自多個領域的 KG 特徵的真實世界觀察，我們建議使用基於路徑的解釋來解釋 KG 中的 LP 模型。引入了一個名為 eXpath 的整合框架，它將關係路徑的概念與本體封閉路徑規則相結合，以提高 LP 解釋的效率和有效性。值得注意的是，eXpath 解釋可以與其他單鏈路解釋方法融合，以實現更好的整體解決方案。跨基準資料集和 LP 模型的廣泛實驗表明，與現有的最佳方法相比，引入 eXpath 可以將結果解釋的品質提高約 20%，並將所需的解釋時間減少 61.4%。案例研究進一步強調了 eXpath 通過基於路徑的證據提供更具語義意義的解釋的能力。

##### **Using Machine Learning to Discover Parsimonious and Physically-Interpretable Representations of Catchment-Scale Rainfall-Runoff Dynamics**
2412.04845v1 by Yuan-Heng Wang, Hoshin V. Gupta

Despite the excellent real-world predictive performance of modern machine
learning (ML) methods, many scientists remain hesitant to discard traditional
physical-conceptual (PC) approaches due mainly to their relative
interpretability, which contributes to credibility during decision-making. In
this context, a currently underexplored aspect of ML is how to develop
minimally-optimal representations that can facilitate better insight regarding
system functioning. Regardless of how this is achieved, it is arguably true
that parsimonious representations better support the advancement of scientific
understanding. Our own view is that ML-based modeling of geoscientific systems
should be based in the use of computational units that are fundamentally
interpretable by design.
  This paper continues our exploration of how the strengths of ML can be
exploited in the service of better understanding via scientific investigation.
Here, we use the Mass Conserving Perceptron (MCP) as the fundamental
computational unit in a generic network architecture consisting of nodes
arranged in series and parallel to explore several generic and important issues
related to the use of observational data for constructing input-state-output
models of dynamical systems. In the context of lumped catchment modeling, we
show that physical interpretability and excellent predictive performance can
both be achieved using a relatively parsimonious distributed-state
multiple-flow-path network with context-dependent gating and information
sharing across the nodes, suggesting that MCP-based modeling can play a
significant role in application of ML to geoscientific investigation.

摘要：儘管現代機器學習 (ML) 方法具有出色的實際世界預測效能，但許多科學家仍猶豫是否放棄傳統的物理概念 (PC) 方法，這主要是因為它們具有相對的可解釋性，有助於在決策過程中建立信譽。在此脈絡下，目前 ML 一個未充分探討的面向是如何開發可促進對系統運作有更佳見解的最小最佳表示法。不論如何達成此目標，簡約表示法更有助於促進科學理解，這點無庸置疑。我們自己的看法是，基於 ML 的地球科學系統建模應以使用在設計上具有基本可解釋性的運算單元為基礎。
本文持續探討如何透過科學研究，利用 ML 的優勢來增進理解。在此，我們使用質量守恆感知器 (MCP) 作為通用網路架構中的基本運算單元，該架構包含串聯和並聯排列的節點，以探討與使用觀測資料建構動態系統輸入狀態輸出模型相關的幾個通用且重要的問題。在集總集水區建模的脈絡下，我們展示了使用具有脈絡相關閘控和跨節點資訊共享的相對簡約分布狀態多流路徑網路，即可達成物理可解釋性和出色的預測效能，這表示基於 MCP 的建模可以在 ML 應用於地球科學研究中扮演重要的角色。

##### **Maximizing Alignment with Minimal Feedback: Efficiently Learning Rewards for Visuomotor Robot Policy Alignment**
2412.04835v1 by Ran Tian, Yilin Wu, Chenfeng Xu, Masayoshi Tomizuka, Jitendra Malik, Andrea Bajcsy

Visuomotor robot policies, increasingly pre-trained on large-scale datasets,
promise significant advancements across robotics domains. However, aligning
these policies with end-user preferences remains a challenge, particularly when
the preferences are hard to specify. While reinforcement learning from human
feedback (RLHF) has become the predominant mechanism for alignment in
non-embodied domains like large language models, it has not seen the same
success in aligning visuomotor policies due to the prohibitive amount of human
feedback required to learn visual reward functions. To address this limitation,
we propose Representation-Aligned Preference-based Learning (RAPL), an
observation-only method for learning visual rewards from significantly less
human preference feedback. Unlike traditional RLHF, RAPL focuses human feedback
on fine-tuning pre-trained vision encoders to align with the end-user's visual
representation and then constructs a dense visual reward via feature matching
in this aligned representation space. We first validate RAPL through simulation
experiments in the X-Magical benchmark and Franka Panda robotic manipulation,
demonstrating that it can learn rewards aligned with human preferences, more
efficiently uses preference data, and generalizes across robot embodiments.
Finally, our hardware experiments align pre-trained Diffusion Policies for
three object manipulation tasks. We find that RAPL can fine-tune these policies
with 5x less real human preference data, taking the first step towards
minimizing human feedback while maximizing visuomotor robot policy alignment.

摘要：視覺運動機器人策略日益在大型資料集上進行預訓練，承諾在機器人領域中取得重大進展。然而，將這些策略與最終使用者的偏好保持一致仍然是一個挑戰，特別是在偏好難以具體說明時。雖然從人類回饋中進行強化學習 (RLHF) 已成為大型語言模型等非具身領域中進行調整的主要機制，但由於學習視覺獎勵函數需要大量的人類回饋，因此在調整視覺運動策略方面尚未取得相同的成功。為了解決這個限制，我們提出基於表示對齊偏好的學習 (RAPL)，這是一種僅觀察的方法，可以用少得多的偏好回饋來學習視覺獎勵。與傳統的 RLHF 不同，RAPL 將人類回饋集中在微調預訓練的視覺編碼器上，以與最終使用者的視覺表示保持一致，然後通過在這個對齊的表示空間中進行特徵匹配來構建密集的視覺獎勵。我們首先通過 X-Magical 基準和 Franka Panda 機器人操作中的模擬實驗驗證了 RAPL，證明它可以學習與人類偏好一致的獎勵，更有效地使用偏好數據，並在機器人具體實例中進行概括。最後，我們的硬體實驗調整了預訓練的擴散策略，以執行三個物體操作任務。我們發現 RAPL 可以使用少 5 倍的真實人類偏好數據微調這些策略，這是朝著最大程度減少人類回饋並最大程度提高視覺運動機器人策略對齊邁出的第一步。

##### **WRF-GS: Wireless Radiation Field Reconstruction with 3D Gaussian Splatting**
2412.04832v1 by Chaozheng Wen, Jingwen Tong, Yingdong Hu, Zehong Lin, Jun Zhang

Wireless channel modeling plays a pivotal role in designing, analyzing, and
optimizing wireless communication systems. Nevertheless, developing an
effective channel modeling approach has been a longstanding challenge. This
issue has been escalated due to the denser network deployment, larger antenna
arrays, and wider bandwidth in 5G and beyond networks. To address this
challenge, we put forth WRF-GS, a novel framework for channel modeling based on
wireless radiation field (WRF) reconstruction using 3D Gaussian splatting.
WRF-GS employs 3D Gaussian primitives and neural networks to capture the
interactions between the environment and radio signals, enabling efficient WRF
reconstruction and visualization of the propagation characteristics. The
reconstructed WRF can then be used to synthesize the spatial spectrum for
comprehensive wireless channel characterization. Notably, with a small number
of measurements, WRF-GS can synthesize new spatial spectra within milliseconds
for a given scene, thereby enabling latency-sensitive applications.
Experimental results demonstrate that WRF-GS outperforms existing methods for
spatial spectrum synthesis, such as ray tracing and other deep-learning
approaches. Moreover, WRF-GS achieves superior performance in the channel state
information prediction task, surpassing existing methods by a significant
margin of more than 2.43 dB.

摘要：無線通道建模在設計、分析和最佳化無線通訊系統中扮演著關鍵角色。儘管如此，開發一個有效的通道建模方法一直是一個長期的挑戰。這個問題由於 5G 及其後續網路中更密集的網路部署、更大的天線陣列和更寬的頻寬而升級。為了應對這個挑戰，我們提出了 WRF-GS，一個基於使用 3D 高斯散射重構無線輻射場 (WRF) 的通道建模新架構。WRF-GS 使用 3D 高斯基元和神經網路來擷取環境和無線電訊號之間的交互作用，實現有效的 WRF 重構和傳播特性的可視化。然後，可以利用重構的 WRF 合成空間頻譜，以進行全面的無線通道特性描述。值得注意的是，使用少量測量，WRF-GS 可以針對給定的場景在幾毫秒內合成新的空間頻譜，從而支援對延遲敏感的應用。實驗結果表明，WRF-GS 在空間頻譜合成方面優於現有方法，例如射線追蹤和其他深度學習方法。此外，WRF-GS 在通道狀態資訊預測任務中取得了卓越的效能，以超過 2.43 dB 的顯著幅度超越現有方法。

##### **Rethinking Time Series Forecasting with LLMs via Nearest Neighbor Contrastive Learning**
2412.04806v1 by Jayanie Bogahawatte, Sachith Seneviratne, Maneesha Perera, Saman Halgamuge

Adapting Large Language Models (LLMs) that are extensively trained on
abundant text data, and customizing the input prompt to enable time series
forecasting has received considerable attention. While recent work has shown
great potential for adapting the learned prior of LLMs, the formulation of the
prompt to finetune LLMs remains challenging as prompt should be aligned with
time series data. Additionally, current approaches do not effectively leverage
word token embeddings which embody the rich representation space learned by
LLMs. This emphasizes the need for a robust approach to formulate the prompt
which utilizes the word token embeddings while effectively representing the
characteristics of the time series. To address these challenges, we propose
NNCL-TLLM: Nearest Neighbor Contrastive Learning for Time series forecasting
via LLMs. First, we generate time series compatible text prototypes such that
each text prototype represents both word token embeddings in its neighborhood
and time series characteristics via end-to-end finetuning. Next, we draw
inspiration from Nearest Neighbor Contrastive Learning to formulate the prompt
while obtaining the top-$k$ nearest neighbor time series compatible text
prototypes. We then fine-tune the layer normalization and positional embeddings
of the LLM, keeping the other layers intact, reducing the trainable parameters
and decreasing the computational cost. Our comprehensive experiments
demonstrate that NNCL-TLLM outperforms in few-shot forecasting while achieving
competitive or superior performance over the state-of-the-art methods in
long-term and short-term forecasting tasks.

摘要：<paragraph>針對大量文本資料進行廣泛訓練的大型語言模型 (LLM) 適應，並自訂輸入提示以啟用時間序列預測，已受到相當大的關注。雖然最近的研究顯示出適應 LLM 學習先驗有很大的潛力，但針對 LLM 進行微調的提示制定仍然具有挑戰性，因為提示應與時間序列資料保持一致。此外，目前的作法並未有效利用字元標記嵌入，而字元標記嵌入體現了 LLM 所學習的豐富表示空間。這強調了制定提示的健全作法之必要性，該作法利用字元標記嵌入，同時有效地表示時間序列的特徵。為了解決這些挑戰，我們提出 NNCL-TLLM：時間序列預測的最近鄰對比學習，透過 LLM。首先，我們產生時間序列相容的文字原型，使得每個文字原型同時表示其鄰域中的字元標記嵌入和透過端對端微調的時間序列特徵。接下來，我們從最近鄰對比學習中汲取靈感，以制定提示，同時取得前 $k$ 個最近鄰時間序列相容的文字原型。然後，我們微調 LLM 的層正規化和位置嵌入，保持其他層不變，減少可訓練參數並降低運算成本。我們的綜合實驗證明，NNCL-TLLM 在少次預測中表現優於其他方法，同時在長期和短期預測任務中達到與最先進的方法競爭或優於最先進的方法的效能。</paragraph>

##### **Estimating the treatment effect over time under general interference through deep learner integrated TMLE**
2412.04799v1 by Suhan Guo, Furao Shen, Ni Li

Understanding the effects of quarantine policies in populations with
underlying social networks is crucial for public health, yet most causal
inference methods fail here due to their assumption of independent individuals.
We introduce DeepNetTMLE, a deep-learning-enhanced Targeted Maximum Likelihood
Estimation (TMLE) method designed to estimate time-sensitive treatment effects
in observational data. DeepNetTMLE mitigates bias from time-varying confounders
under general interference by incorporating a temporal module and domain
adversarial training to build intervention-invariant representations. This
process removes associations between current treatments and historical
variables, while the targeting step maintains the bias-variance trade-off,
enhancing the reliability of counterfactual predictions. Using simulations of a
``Susceptible-Infected-Recovered'' model with varied quarantine coverages, we
show that DeepNetTMLE achieves lower bias and more precise confidence intervals
in counterfactual estimates, enabling optimal quarantine recommendations within
budget constraints, surpassing state-of-the-art methods.

摘要：了解具有潛在社交網絡的人群中隔離政策的影響對於公共衛生至關重要，但由於假設個人獨立，大多數因果推論方法在此處失敗。我們引入了 DeepNetTMLE，這是一種深度學習增強的目標最大似然估計 (TMLE) 方法，旨在估計觀測數據中的時間敏感處理效果。DeepNetTMLE 透過整合時間模組和領域對抗訓練來建立介入不變表示，從而減輕一般干擾下時變混雜因素的偏差。此過程消除了當前處理與歷史變數之間的關聯，而目標設定步驟則維持偏差變異權衡，增強反事實預測的可靠性。使用具有不同隔離覆蓋率的「易感者-感染者-康復者」模型的模擬，我們表明 DeepNetTMLE 在反事實估計中實現了較低的偏差和更精確的信心區間，從而在預算限制內實現了最佳隔離建議，超越了最先進的方法。

##### **Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**
2412.04792v1 by Mahfuzul Haque, Abu Saleh Musa Miah, Debashish Gupta, Md. Maruf Al Hossain Prince, Tanzina Alam, Nusrat Sharmin, Mohammed Sowket Ali, Jungpil Shin

Heart disease is a leading cause of premature death worldwide, particularly
among middle-aged and older adults, with men experiencing a higher prevalence.
According to the World Health Organization (WHO), non-communicable diseases,
including heart disease, account for 25\% (17.9 million) of global deaths, with
over 43,204 annual fatalities in Bangladesh. However, the development of heart
disease detection (HDD) systems tailored to the Bangladeshi population remains
underexplored due to the lack of benchmark datasets and reliance on manual or
limited-data approaches. This study addresses these challenges by introducing
new, ethically sourced HDD dataset, BIG-Dataset and CD dataset which
incorporates comprehensive data on symptoms, examination techniques, and risk
factors. Using advanced machine learning techniques, including Logistic
Regression and Random Forest, we achieved a remarkable testing accuracy of up
to 96.6\% with Random Forest. The proposed AI-driven system integrates these
models and datasets to provide real-time, accurate diagnostics and personalized
healthcare recommendations. By leveraging structured datasets and
state-of-the-art machine learning algorithms, this research offers an
innovative solution for scalable and effective heart disease detection, with
the potential to reduce mortality rates and improve clinical outcomes.

摘要：<paragraph>心臟病是全球過早死亡的主因，特別是在中年和老年人中，男性發生率較高。根據世界衛生組織 (WHO) 的數據，包括心臟病在內的非傳染性疾病占全球死亡人數的 25%（1790 萬），孟加拉國每年有超過 43,204 人死於心臟病。然而，由於缺乏基準數據集和依賴手動或數據有限的方法，針對孟加拉國人口量身打造的心臟病檢測 (HDD) 系統的開發仍未得到充分探索。本研究通過引入新的、符合道德標準的 HDD 數據集、BIG 數據集和 CD 數據集來應對這些挑戰，其中包含有關症狀、檢查技術和風險因素的全面數據。使用先進的機器學習技術，包括邏輯迴歸和隨機森林，我們使用隨機森林實現了高達 96.6% 的顯著測試準確度。所提出的 AI 驅動系統整合了這些模型和數據集，以提供實時的準確診斷和個性化的醫療保健建議。通過利用結構化數據集和最先進的機器學習算法，本研究為可擴展且有效的心臟病檢測提供了一個創新的解決方案，具有降低死亡率和改善臨床結果的潛力。</paragraph>

##### **GUIDE: A Global Unified Inference Engine for Deploying Large Language Models in Heterogeneous Environments**
2412.04788v1 by Yanyu Chen, Ganhong Huang

Efficiently deploying large language models (LLMs) in real-world scenarios
remains a critical challenge, primarily due to hardware heterogeneity,
inference framework limitations, and workload complexities.Efficiently
deploying large language models (LLMs) in real-world scenarios remains a
critical challenge, primarily due to hardware heterogeneity, inference
framework limitations, and workload complexities. These challenges often lead
to inefficiencies in memory utilization, latency, and throughput, hindering the
effective deployment of LLMs, especially for non-experts. Through extensive
experiments, we identify key performance bottlenecks, including sudden drops in
memory utilization, latency fluctuations with varying batch sizes, and
inefficiencies in multi-GPU configurations. These insights reveal a vast
optimization space shaped by the intricate interplay of hardware, frameworks,
and workload parameters. This underscores the need for a systematic approach to
optimize LLM inference, motivating the design of our framework, GUIDE. GUIDE
leverages dynamic modeling and simulation-based optimization to address these
issues, achieving prediction errors between 25% and 55% for key metrics such as
batch latency, TTFT, and decode throughput. By effectively bridging the gap
between theoretical performance and practical deployment, our framework
empowers practitioners, particularly non-specialists, to make data-driven
decisions and unlock the full potential of LLMs in heterogeneous environments
cheaply.

摘要：高效部署大型語言模型 (LLM) 至於實際場景中，仍是一個重大的挑戰，主要原因在於硬體異質性、推論架構限制以及工作負載的複雜性。高效部署大型語言模型 (LLM) 至於實際場景中，仍是一個重大的挑戰，主要原因在於硬體異質性、推論架構限制以及工作負載的複雜性。這些挑戰通常會導致記憶體使用率、延遲和吞吐量的低效率，阻礙 LLM 的有效部署，尤其是對非專家而言。透過廣泛的實驗，我們找出主要的效能瓶頸，包括記憶體使用率的突然下降、批次大小不同的延遲波動，以及多 GPU 配置中的低效率。這些見解揭示了一個廣大的最佳化空間，由硬體、架構和工作負載參數的複雜交互作用所形成。這強調了需要一個系統化的方法來最佳化 LLM 推論，激勵我們架構 GUIDE 的設計。GUIDE 藉由動態建模和基於模擬的最佳化來解決這些問題，對於批次延遲、TTFT 和解碼吞吐量等關鍵指標，達成 25% 至 55% 的預測誤差。透過有效縮小理論效能和實際部署之間的差距，我們的架構讓從業人員，尤其是非專家，能夠做出資料驅動的決策，並在異質環境中以低成本發揮 LLM 的全部潛力。

##### **Direct Quantized Training of Language Models with Stochastic Rounding**
2412.04787v1 by Kaiyan Zhao, Tsuguchika Tabaru, Kenichi Kobayashi, Takumi Honda, Masafumi Yamazaki, Yoshimasa Tsuruoka

Although recent quantized Large Language Models (LLMs), such as BitNet, have
paved the way for significant reduction in memory usage during deployment with
binary or ternary weights, training these models still demands substantial
memory footprints. This is partly because high-precision (i.e., unquantized)
weight matrices required for straight-through estimation must be maintained
throughout the whole training process. To address this, we explore the
potential of directly updating the quantized low-precision weight matrices
without relying on the straight-through estimator during backpropagation,
thereby saving memory usage during training. Specifically, we employ a
stochastic rounding technique to minimize information loss caused by the use of
low-bit weights throughout training. Experimental results on our
LLaMA-structured models indicate that (1) training with only low-precision
weights is feasible even when they are constrained to ternary values, (2)
extending the bit width to 8 bits results in only a 5% loss degradation
compared to BitNet b1.58 while offering the potential for reduced memory usage
during training, and (3) our models can also perform inference using ternary
weights, showcasing their flexibility in deployment.

摘要：儘管最近的量化大型語言模型 (LLM)，例如 BitNet，已為在使用二進位或三進位權重進行部署時大幅減少記憶體用量鋪平了道路，但訓練這些模型仍需要大量的記憶體空間。這部分是因為必須在整個訓練過程中維護用於直通估計的高精度（即未量化）權重矩陣。為了解決這個問題，我們探討了在反向傳播過程中不依賴直通估計器而直接更新量化低精度權重矩陣的可能性，從而節省訓練期間的記憶體用量。具體來說，我們採用隨機捨入技術，以最小化在整個訓練過程中使用低位元權重造成的資訊遺失。我們在 LLaMA 結構模型上的實驗結果表明：(1) 即使將權重限制為三進位值，僅使用低精度權重進行訓練也是可行的，(2) 將位元寬度擴展到 8 位元只會導致 5% 的損失劣化，而與 BitNet b1.58 相比，在訓練期間提供了減少記憶體用量的可能性，(3) 我們的模型也可以使用三進位權重進行推論，展示了它們在部署中的靈活性。

##### **NLP-ADBench: NLP Anomaly Detection Benchmark**
2412.04784v1 by Yuangang Li, Jiaqi Li, Zhuo Xiao, Tiankai Yang, Yi Nian, Xiyang Hu, Yue Zhao

Anomaly detection (AD) is a critical machine learning task with diverse
applications in web systems, including fraud detection, content moderation, and
user behavior analysis. Despite its significance, AD in natural language
processing (NLP) remains underexplored, limiting advancements in detecting
anomalies in text data such as harmful content, phishing attempts, or spam
reviews. In this paper, we introduce NLP-ADBench, the most comprehensive
benchmark for NLP anomaly detection (NLP-AD), comprising eight curated datasets
and evaluations of nineteen state-of-the-art algorithms. These include three
end-to-end methods and sixteen two-step algorithms that apply traditional
anomaly detection techniques to language embeddings generated by
bert-base-uncased and OpenAI's text-embedding-3-large models.
  Our results reveal critical insights and future directions for NLP-AD.
Notably, no single model excels across all datasets, highlighting the need for
automated model selection. Moreover, two-step methods leveraging
transformer-based embeddings consistently outperform specialized end-to-end
approaches, with OpenAI embeddings demonstrating superior performance over BERT
embeddings. By releasing NLP-ADBench at
https://github.com/USC-FORTIS/NLP-ADBench, we provide a standardized framework
for evaluating NLP-AD methods, fostering the development of innovative
approaches. This work fills a crucial gap in the field and establishes a
foundation for advancing NLP anomaly detection, particularly in the context of
improving the safety and reliability of web-based systems.

摘要：異常偵測 (AD) 是一項重要的機器學習任務，在網路系統中具有多樣化的應用，包括詐欺偵測、內容審核和使用者行為分析。儘管異常偵測具有重要性，但自然語言處理 (NLP) 中的異常偵測仍未被充分探索，這限制了偵測文字資料中異常現象的進展，例如有害內容、網路釣魚嘗試或垃圾評論。在本文中，我們介紹了 NLP-ADBench，這是 NLP 異常偵測 (NLP-AD) 最全面的基準，包含八個策劃好的資料集和十九種最先進演算法的評估。這些包括三種端對端方法和十六種兩步驟演算法，它們將傳統的異常偵測技術應用於由 bert-base-uncased 和 OpenAI 的 text-embedding-3-large 模型產生的語言嵌入。我們的結果揭示了 NLP-AD 的關鍵見解和未來方向。值得注意的是，沒有單一模型在所有資料集上表現優異，這突顯了自動化模型選擇的必要性。此外，利用基於 Transformer 的嵌入的兩步驟方法始終優於專門的端對端方法，而 OpenAI 嵌入表現出優於 BERT 嵌入的效能。透過在 https://github.com/USC-FORTIS/NLP-ADBench 上發布 NLP-ADBench，我們提供了一個標準化的框架來評估 NLP-AD 方法，促進創新方法的發展。這項工作填補了該領域的關鍵空白，並建立了推進 NLP 異常偵測的基礎，特別是在改善基於網路系統的安全性和可靠性的情況下。

##### **KNN-MMD: Cross Domain Wi-Fi Sensing Based on Local Distribution Alignment**
2412.04783v1 by Zijian Zhao, Zhijie Cai, Tingwei Chen, Xiaoyang Li, Hang Li, Guangxu Zhu

As a key technology in Integrated Sensing and Communications (ISAC), Wi-Fi
sensing has gained widespread application in various settings such as homes,
offices, and public spaces. By analyzing the patterns of Channel State
Information (CSI), we can obtain information about people's actions for tasks
like person identification, gesture recognition, and fall detection. However,
the CSI is heavily influenced by the environment, such that even minor
environmental changes can significantly alter the CSI patterns. This will cause
the performance deterioration and even failure when applying the Wi-Fi sensing
model trained in one environment to another. To address this problem, we
introduce a K-Nearest Neighbors Maximum Mean Discrepancy (KNN-MMD) model, a
few-shot method for cross-domain Wi-Fi sensing. We propose a local distribution
alignment method within each category, which outperforms traditional Domain
Adaptation (DA) methods based on global alignment. Besides, our method can
determine when to stop training, which cannot be realized by most DA methods.
As a result, our method is more stable and can be better used in practice. The
effectiveness of our method are evaluated in several cross-domain Wi-Fi sensing
tasks, including gesture recognition, person identification, fall detection,
and action recognition, using both a public dataset and a self-collected
dataset. In one-shot scenario, our method achieves accuracy of 93.26%, 81.84%,
77.62%, and 75.30% in the four tasks respectively. To facilitate future
research, we will make our code and dataset publicly available upon
publication.

摘要：作為整合感測與通訊 (ISAC) 的關鍵技術，Wi-Fi 感測已廣泛應用於各種場景，例如家庭、辦公室和公共空間。透過分析頻道狀態資訊 (CSI) 的模式，我們可以取得人們在執行任務（例如人員識別、手勢辨識和跌倒偵測）時的動作資訊。然而，CSI 深受環境影響，即使是微小的環境變化也可能大幅改變 CSI 模式。這將導致在一個環境中訓練的 Wi-Fi 感測模型套用至另一個環境時，效能會下降甚至失敗。為了解決這個問題，我們引進 K 最近鄰最大平均差異 (KNN-MMD) 模型，這是一種跨網域 Wi-Fi 感測的少次學習方法。我們提出一個類別內部局部分佈比對方法，其優於基於全域比對的傳統網域適應 (DA) 方法。此外，我們的模型可以決定何時停止訓練，這是大多數 DA 方法無法做到的。因此，我們的模型更穩定，且更適合實際應用。我們在幾個跨網域 Wi-Fi 感測任務中評估了我們模型的效能，包括手勢辨識、人員識別、跌倒偵測和動作辨識，並使用公開資料集和自建資料集。在一次學習情境中，我們的模型在四個任務中分別達到 93.26%、81.84%、77.62% 和 75.30% 的準確度。為了促進後續研究，我們將在發表後公開我們的程式碼和資料集。

##### **A Survey of Sustainability in Large Language Models: Applications, Economics, and Challenges**
2412.04782v1 by Aditi Singh, Nirmal Prakashbhai Patel, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei

Large Language Models (LLMs) have transformed numerous domains by providing
advanced capabilities in natural language understanding, generation, and
reasoning. Despite their groundbreaking applications across industries such as
research, healthcare, and creative media, their rapid adoption raises critical
concerns regarding sustainability. This survey paper comprehensively examines
the environmental, economic, and computational challenges associated with LLMs,
focusing on energy consumption, carbon emissions, and resource utilization in
data centers. By synthesizing insights from existing literature, this work
explores strategies such as resource-efficient training, sustainable deployment
practices, and lifecycle assessments to mitigate the environmental impacts of
LLMs. Key areas of emphasis include energy optimization, renewable energy
integration, and balancing performance with sustainability. The findings aim to
guide researchers, practitioners, and policymakers in developing actionable
strategies for sustainable AI systems, fostering a responsible and
environmentally conscious future for artificial intelligence.

摘要：大型語言模型 (LLM) 已透過提供自然語言理解、生成和推理的高階能力，轉變了許多領域。儘管它們在研究、醫療保健和創意媒體等產業中具有突破性的應用，但其快速採用也引發了有關永續性的重大疑慮。這篇調查報告全面探討了與 LLM 相關的環境、經濟和運算挑戰，重點關注資料中心的能源消耗、碳排放和資源利用。透過綜合現有文獻的見解，這項工作探討了資源有效訓練、永續部署實務和生命週期評估等策略，以減輕 LLM 對環境的影響。重點關注領域包括能源最佳化、再生能源整合，以及平衡效能與永續性。研究結果旨在引導研究人員、從業人員和政策制定者制定永續 AI 系統的可行策略，為人工智慧培養負責任且注重環境的未來。

##### **Foundation Models for Low-Resource Language Education (Vision Paper)**
2412.04774v1 by Zhaojun Ding, Zhengliang Liu, Hanqi Jiang, Yizhu Gao, Xiaoming Zhai, Tianming Liu, Ninghao Liu

Recent studies show that large language models (LLMs) are powerful tools for
working with natural language, bringing advances in many areas of computational
linguistics. However, these models face challenges when applied to low-resource
languages due to limited training data and difficulty in understanding cultural
nuances. Research is now focusing on multilingual models to improve LLM
performance for these languages. Education in these languages also struggles
with a lack of resources and qualified teachers, particularly in underdeveloped
regions. Here, LLMs can be transformative, supporting innovative methods like
community-driven learning and digital platforms. This paper discusses how LLMs
could enhance education for low-resource languages, emphasizing practical
applications and benefits.

摘要：最近的研究顯示，大型語言模型 (LLM) 是處理自然語言的強大工具，為計算語言學的許多領域帶來進展。然而，這些模型在應用於低資源語言時會面臨挑戰，因為訓練資料有限，且難以理解文化差異。研究現在正專注於多語言模型，以提升 LLM 在這些語言中的效能。這些語言的教育也因缺乏資源和合格教師而面臨困境，特別是在未開發地區。在此，LLM 可以發揮變革作用，支援社群驅動學習和數位平台等創新方法。本文探討 LLM 如何提升低資源語言的教育，強調實際應用和優點。

##### **DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**
2412.04766v1 by Shadab Ahamed, Eldad Haber

Inverse problems, which involve estimating parameters from incomplete or
noisy observations, arise in various fields such as medical imaging,
geophysics, and signal processing. These problems are often ill-posed,
requiring regularization techniques to stabilize the solution. In this work, we
employ $\textit{Stochastic Interpolation}$ (SI), a generative framework that
integrates both deterministic and stochastic processes to map a simple
reference distribution, such as a Gaussian, to the target distribution. Our
method $\textbf{DAWN-SI}$: $\textbf{D}$ata-$\textbf{AW}$are and
$\textbf{N}$oise-informed $\textbf{S}$tochastic $\textbf{I}$nterpolation
incorporates data and noise embedding, allowing the model to access
representations about the measured data explicitly and also account for noise
in the observations, making it particularly robust in scenarios where data is
noisy or incomplete. By learning a time-dependent velocity field, SI not only
provides accurate solutions but also enables uncertainty quantification by
generating multiple plausible outcomes. Unlike pre-trained diffusion models,
which may struggle in highly ill-posed settings, our approach is trained
specifically for each inverse problem and adapts to varying noise levels. We
validate the effectiveness and robustness of our method through extensive
numerical experiments on tasks such as image deblurring and tomography.

摘要：反問題涉及從不完整或有雜訊的觀測中估計參數，出現在各種領域，例如醫學影像、地球物理和訊號處理。這些問題通常是不適定的，需要正則化技術來穩定解。在這項工作中，我們採用隨機插值 (SI)，一種生成式架構，整合確定性和隨機過程，將簡單的參考分佈（例如高斯分佈）對應到目標分佈。我們的 DAWS-SI 方法：資料感知和雜訊知情的隨機插值，結合資料和雜訊嵌入，讓模型能夠明確存取關於測量資料的表示，並考量觀測中的雜訊，使其在資料有雜訊或不完整的情況下特別穩健。透過學習與時間相關的速度場，SI 不僅提供精確的解，還能透過產生多個合理的結果來量化不確定性。與預先訓練的擴散模型不同，後者在高度不適定的設定中可能會遇到困難，我們的做法是針對每個反問題進行訓練，並適應不同的雜訊等級。我們透過廣泛的數值實驗驗證了我們方法的有效性和穩健性，這些任務包括影像去模糊和斷層掃描。

##### **Short-term Streamflow and Flood Forecasting based on Graph Convolutional Recurrent Neural Network and Residual Error Learning**
2412.04764v1 by Xiyu Pan, Neda Mohammadi, John E. Taylor

Accurate short-term streamflow and flood forecasting are critical for
mitigating river flood impacts, especially given the increasing climate
variability. Machine learning-based streamflow forecasting relies on large
streamflow datasets derived from rating curves. Uncertainties in rating curve
modeling could introduce errors to the streamflow data and affect the
forecasting accuracy. This study proposes a streamflow forecasting method that
addresses these data errors, enhancing the accuracy of river flood forecasting
and flood modeling, thereby reducing flood-related risk. A convolutional
recurrent neural network is used to capture spatiotemporal patterns, coupled
with residual error learning and forecasting. The neural network outperforms
commonly used forecasting models over 1-6 hours of forecasting horizons, and
the residual error learners can further correct the residual errors. This
provides a more reliable tool for river flood forecasting and climate
adaptation in this critical 1-6 hour time window for flood risk mitigation
efforts.

摘要：準確的短期流量和洪水預測對於減輕河流洪水影響至關重要，特別是在氣候變異性增加的情況下。基於機器學習的流量預測依賴於從評分曲線中得出的大量流量數據集。評分曲線建模中的不確定性可能會給流量數據引入誤差，並影響預測準確性。本研究提出了一種流量預測方法來解決這些數據錯誤，從而提高河流洪水預測和洪水建模的準確性，從而降低洪水相關風險。卷積遞歸神經網路用於捕獲時空模式，並結合殘差誤差學習和預測。神經網路在 1-6 小時的預測範圍內優於常用的預測模型，而殘差誤差學習器可以進一步校正殘差誤差。這為洪水風險緩解工作中這個關鍵的 1-6 小時時間窗口中的河流洪水預測和氣候適應提供了更可靠的工具。

##### **REGENT: A Retrieval-Augmented Generalist Agent That Can Act In-Context in New Environments**
2412.04759v1 by Kaustubh Sridhar, Souradeep Dutta, Dinesh Jayaraman, Insup Lee

Building generalist agents that can rapidly adapt to new environments is a
key challenge for deploying AI in the digital and real worlds. Is scaling
current agent architectures the most effective way to build generalist agents?
We propose a novel approach to pre-train relatively small policies on
relatively small datasets and adapt them to unseen environments via in-context
learning, without any finetuning. Our key idea is that retrieval offers a
powerful bias for fast adaptation. Indeed, we demonstrate that even a simple
retrieval-based 1-nearest neighbor agent offers a surprisingly strong baseline
for today's state-of-the-art generalist agents. From this starting point, we
construct a semi-parametric agent, REGENT, that trains a transformer-based
policy on sequences of queries and retrieved neighbors. REGENT can generalize
to unseen robotics and game-playing environments via retrieval augmentation and
in-context learning, achieving this with up to 3x fewer parameters and up to an
order-of-magnitude fewer pre-training datapoints, significantly outperforming
today's state-of-the-art generalist agents. Website:
https://kaustubhsridhar.github.io/regent-research

摘要：建構能快速適應新環境的通才代理，是將 AI 部署到數位與真實世界的一項關鍵挑戰。擴充現有的代理架構是建構通才代理最有效的方法嗎？我們提出一個創新的方法，在相對小的資料集上預先訓練相對小的政策，並透過情境學習將它們調整到未見過的環境中，而無需任何微調。我們的關鍵想法是，檢索為快速適應提供了強大的偏差。事實上，我們證明了即使是一個簡單的基於檢索的 1-最近鄰代理，也能為當今最先進的通才代理提供一個令人驚訝的強大基準。從這個起點，我們建構了一個半參數代理 REGENT，它在查詢和檢索到的鄰居序列上訓練一個基於Transformer的政策。REGENT 可以透過檢索擴充和情境學習，概括到未見過的機器人和遊戲環境，並以少達 3 倍的參數和少達一個數量級的預訓練資料點來實現這一點，顯著優於當今最先進的通才代理。網站：
https://kaustubhsridhar.github.io/regent-research

##### **Measuring Goal-Directedness**
2412.04758v1 by Matt MacDermott, James Fox, Francesco Belardinelli, Tom Everitt

We define maximum entropy goal-directedness (MEG), a formal measure of
goal-directedness in causal models and Markov decision processes, and give
algorithms for computing it. Measuring goal-directedness is important, as it is
a critical element of many concerns about harm from AI. It is also of
philosophical interest, as goal-directedness is a key aspect of agency. MEG is
based on an adaptation of the maximum causal entropy framework used in inverse
reinforcement learning. It can measure goal-directedness with respect to a
known utility function, a hypothesis class of utility functions, or a set of
random variables. We prove that MEG satisfies several desiderata and
demonstrate our algorithms with small-scale experiments.

摘要：我們定義最大熵目標導向性 (MEG)，這是一個因果模型和馬可夫決策過程中目標導向性的正式衡量方法，並給出計算它的演算法。衡量目標導向性很重要，因為它是許多關於 AI 危害的關鍵因素。它也具有哲學意義，因為目標導向性是能動性的關鍵方面。MEG 是基於逆向強化學習中使用的最大因果熵架構的改編。它可以針對已知的效用函數、效用函數的假設類別或一組隨機變數來衡量目標導向性。我們證明 MEG 滿足了幾個理想條件，並使用小規模實驗來展示我們的演算法。

##### **Ltri-LLM: Streaming Long Context Inference for LLMs with Training-Free Dynamic Triangular Attention Pattern**
2412.04757v1 by Hongyin Tang, Di Xiu, Lanrui Wang, Xiurui Geng, Jingang Wang, Xunliang Cai

The quadratic computational complexity of the attention mechanism in current
Large Language Models (LLMs) renders inference with long contexts prohibitively
expensive. To address this challenge, various approaches aim to retain critical
portions of the context to optimally approximate Full Attention (FA) through
Key-Value (KV) compression or Sparse Attention (SA), enabling the processing of
virtually unlimited text lengths in a streaming manner. However, these methods
struggle to achieve performance levels comparable to FA, particularly in
retrieval tasks. In this paper, our analysis of attention head patterns reveals
that LLMs' attention distributions show strong local correlations, naturally
reflecting a chunking mechanism for input context. We propose Ltri-LLM
framework, which divides KVs into spans, stores them in an offline index, and
retrieves the relevant KVs into memory for various queries. Experimental
results on popular long text benchmarks show that Ltri-LLM can achieve
performance close to FA while maintaining efficient, streaming-based inference.

摘要：當前大語言模型 (LLM) 中注意力機制的二次計算複雜度使得使用長文脈進行推論的成本高得令人望而卻步。為了應對這一挑戰，各種方法旨在保留文脈中的關鍵部分，以通過鍵值 (KV) 壓縮或稀疏注意力 (SA) 最佳逼近全注意力 (FA)，從而能夠以串流方式處理幾乎無限的文字長度。然而，這些方法難以達到與 FA 相當的效能水準，特別是在檢索任務中。在本文中，我們對注意力頭部模式的分析表明，LLM 的注意力分佈顯示出強烈的局部關聯性，自然地反映了輸入文脈的區塊機制。我們提出 Ltri-LLM 框架，它將 KV 分成區塊，將它們儲存在離線索引中，並將相關 KV 檢索到記憶體中以供各種查詢使用。在流行的長文字基準測試上的實驗結果表明，Ltri-LLM 可以實現接近 FA 的效能，同時保持高效的基於串流的推論。

##### **ChatNVD: Advancing Cybersecurity Vulnerability Assessment with Large Language Models**
2412.04756v1 by Shivansh Chopra, Hussain Ahmad, Diksha Goel, Claudia Szabo

The increasing frequency and sophistication of cybersecurity vulnerabilities
in software systems underscore the urgent need for robust and effective methods
of vulnerability assessment. However, existing approaches often rely on highly
technical and abstract frameworks, which hinders understanding and increases
the likelihood of exploitation, resulting in severe cyberattacks. Given the
growing adoption of Large Language Models (LLMs) across diverse domains, this
paper explores their potential application in cybersecurity, specifically for
enhancing the assessment of software vulnerabilities. We propose ChatNVD, an
LLM-based cybersecurity vulnerability assessment tool leveraging the National
Vulnerability Database (NVD) to provide context-rich insights and streamline
vulnerability analysis for cybersecurity professionals, developers, and
non-technical users. We develop three variants of ChatNVD, utilizing three
prominent LLMs: GPT-4o mini by OpenAI, Llama 3 by Meta, and Gemini 1.5 Pro by
Google. To evaluate their efficacy, we conduct a comparative analysis of these
models using a comprehensive questionnaire comprising common security
vulnerability questions, assessing their accuracy in identifying and analyzing
software vulnerabilities. This study provides valuable insights into the
potential of LLMs to address critical challenges in understanding and
mitigation of software vulnerabilities.

摘要：隨著軟體系統中網路安全漏洞的頻率和複雜性與日俱增，這凸顯了對健全且有效的漏洞評估方法的迫切需求。然而，現有的方法通常依賴於高度技術性和抽象的架構，這阻礙了理解並增加了被利用的可能性，導致嚴重的網路攻擊。鑑於大型語言模型 (LLM) 在不同領域中被廣泛採用，本文探討了它們在網路安全中的潛在應用，特別是為了加強軟體漏洞評估。我們提出了 ChatNVD，這是一個基於 LLM 的網路安全漏洞評估工具，利用國家漏洞資料庫 (NVD) 來提供豐富的背景資訊，並簡化網路安全專業人員、開發人員和非技術使用者的漏洞分析。我們開發了 ChatNVD 的三個變體，利用了三個著名的 LLM：OpenAI 的 GPT-4o mini、Meta 的 Llama 3 和 Google 的 Gemini 1.5 Pro。為了評估它們的效能，我們使用包含常見安全漏洞問題的綜合問卷對這些模型進行比較分析，評估它們在識別和分析軟體漏洞方面的準確性。本研究提供了有價值的見解，說明 LLM 在解決理解和減輕軟體漏洞方面的關鍵挑戰的潛力。

##### **Question Answering for Decisionmaking in Green Building Design: A Multimodal Data Reasoning Method Driven by Large Language Models**
2412.04741v1 by Yihui Li, Xiaoyue Yan, Hao Zhou, Borong Lin

In recent years, the critical role of green buildings in addressing energy
consumption and environmental issues has become widely acknowledged. Research
indicates that over 40% of potential energy savings can be achieved during the
early design stage. Therefore, decision-making in green building design (DGBD),
which is based on modeling and performance simulation, is crucial for reducing
building energy costs. However, the field of green building encompasses a broad
range of specialized knowledge, which involves significant learning costs and
results in low decision-making efficiency. Many studies have already applied
artificial intelligence (AI) methods to this field. Based on previous research,
this study innovatively integrates large language models with DGBD, creating
GreenQA, a question answering framework for multimodal data reasoning.
Utilizing Retrieval Augmented Generation, Chain of Thought, and Function Call
methods, GreenQA enables multimodal question answering, including weather data
analysis and visualization, retrieval of green building cases, and knowledge
query. Additionally, this study conducted a user survey using the GreenQA web
platform. The results showed that 96% of users believed the platform helped
improve design efficiency. This study not only effectively supports DGBD but
also provides inspiration for AI-assisted design.

摘要：近年來，綠色建築在解決能源消耗和環境問題中扮演著至關重要的角色，這點已獲得廣泛認可。研究指出，在早期設計階段，可達成超過 40% 的潛在節能效果。因此，綠色建築設計中的決策制定（DGBD），其基礎在於模型化和效能模擬，對於降低建築物的能源成本至關重要。然而，綠色建築領域包含了廣泛的專業知識，這涉及了大量的學習成本，並導致決策制定效率低落。許多研究已將人工智慧（AI）方法應用於此領域。本研究基於先前的研究，創新地將大型語言模型與 DGBD 整合，創造了 GreenQA，一個用於多模態資料推理的問答框架。利用檢索擴充生成、思考鏈和函數呼叫方法，GreenQA 能夠進行多模態問答，包括天氣資料分析和視覺化、檢索綠色建築案例和知識查詢。此外，本研究使用 GreenQA 網路平台進行了一項使用者調查。結果顯示，96% 的使用者認為該平台有助於提升設計效率。本研究不僅有效地支援 DGBD，也為 AI 輔助設計提供了靈感。

##### **BESSTIE: A Benchmark for Sentiment and Sarcasm Classification for Varieties of English**
2412.04726v1 by Dipankar Srirag, Aditya Joshi, Jordan Painter, Diptesh Kanojia

Despite large language models (LLMs) being known to exhibit bias against
non-mainstream varieties, there are no known labeled datasets for sentiment
analysis of English. To address this gap, we introduce BESSTIE, a benchmark for
sentiment and sarcasm classification for three varieties of English: Australian
(en-AU), Indian (en-IN), and British (en-UK). Using web-based content from two
domains, namely, Google Place reviews and Reddit comments, we collect datasets
for these language varieties using two methods: location-based and topic-based
filtering. Native speakers of the language varieties manually annotate the
datasets with sentiment and sarcasm labels. Subsequently, we fine-tune nine
large language models (LLMs) (representing a range of encoder/decoder and
mono/multilingual models) on these datasets, and evaluate their performance on
the two tasks. Our results reveal that the models consistently perform better
on inner-circle varieties (i.e., en-AU and en-UK), with significant performance
drops for en-IN, particularly in sarcasm detection. We also report challenges
in cross-variety generalisation, highlighting the need for language
variety-specific datasets such as ours. BESSTIE promises to be a useful
evaluative benchmark for future research in equitable LLMs, specifically in
terms of language varieties. The BESSTIE datasets, code, and models are
currently available on request, while the paper is under review. Please email
aditya.joshi@unsw.edu.au.

摘要：儘管大型語言模型 (LLM) 已知會對非主流變體表現出偏見，但目前沒有已知的標籤資料集可供分析英語的情感。為了解決此差距，我們引入了 BESSTIE，這是一個針對三種英語變體（澳洲英語 (en-AU)、印度英語 (en-IN) 和英國英語 (en-UK)）的情感和諷刺分類基準。我們使用來自兩個網域（即 Google 地點評論和 Reddit 留言）的網路內容，使用兩種方法（基於位置和基於主題的篩選）收集這些語言變體的資料集。這些語言變體的母語人士會手動註解資料集，並加上情感和諷刺標籤。隨後，我們針對這些資料集微調了九個大型語言模型 (LLM)（代表一系列編碼器/解碼器和單語/多語模型），並評估它們在兩個任務中的表現。我們的結果顯示，這些模型在內圈變體（即 en-AU 和 en-UK）上的表現始終較好，而 en-IN 的表現顯著下降，特別是在諷刺偵測方面。我們也報告了跨變體概括的挑戰，強調了對像我們這樣的語言變體特定資料集的需求。BESSTIE 承諾成為未來在公平 LLM 中進行研究的有用評估基準，特別是在語言變體方面。BESSTIE 資料集、程式碼和模型目前可應要求取得，而論文則正在審查中。請寄電子郵件至 aditya.joshi@unsw.edu.au。

##### **Adaptive Optimization for Enhanced Efficiency in Large-Scale Language Model Training**
2412.04718v1 by Jiajing Chen, Bingying Liu, Xiaoxuan Liao, Jia Gao, Hongye Zheng, Yue Li

With the rapid development of natural language processing technology,
large-scale language models (LLM) have achieved remarkable results in a variety
of tasks. However, how to effectively train these huge models and improve their
performance and computational efficiency remains an important challenge. This
paper proposes an improved method based on adaptive optimization algorithm,
aiming to improve the training efficiency and final performance of LLM. Through
comparative experiments on the SQuAD and GLUE data sets, the experimental
results show that compared with traditional optimization algorithms (such as
SGD, Momentum, AdaGrad, RMSProp and Adam), the adaptive optimization algorithm
we proposed has better accuracy and F1 score. Both have achieved significant
improvements, especially showed stronger training capabilities when processed
large-scale texts and complex tasks. The research results verify the advantages
of adaptive optimization algorithms in large-scale language model training and
provide new ideas and directions for future optimization methods.

摘要：隨著自然語言處理技術的快速發展，
大規模語言模型 (LLM) 在各種任務中取得了顯著的成果。
然而，如何有效地訓練這些龐大的模型並提高其
效能和計算效率仍然是一項重要的挑戰。本文提出了一種基於自適應優化演算法的改進方法，
旨在提高 LLM 的訓練效率和最終效能。通過
在 SQuAD 和 GLUE 資料集上進行比較實驗，實驗
結果表明，與傳統優化演算法（例如
SGD、Momentum、AdaGrad、RMSProp 和 Adam）相比，我們提出的自適應優化演算法具有更好的準確度和 F1 分數。兩者都取得了顯著的
進步，特別是在處理
大規模文字和複雜任務時表現出更強的訓練能力。研究結果驗證了自適應優化演算法在大規模語言模型訓練中的優點，並為未來的優化方法提供了新的思路和方向。

##### **NoLoR: An ASR-Based Framework for Expedited Endangered Language Documentation with Neo-Aramaic as a Case Study**
2412.04717v1 by Matthew Nazari

The documentation of the Neo-Aramaic dialects before their extinction has
been described as the most urgent task in all of Semitology today. The death of
this language will be an unfathomable loss to the descendents of the indigenous
speakers of Aramaic, now predominantly diasporic after forced displacement due
to violence. This paper develops an ASR model to expedite the documentation of
this endangered language and generalizes the strategy in a new framework we
call NoLoR.

摘要：新亞拉姆語方言在滅絕前所留下的文件，被描述為當今閃語學中最迫切的任務。這種語言的消逝將會是亞拉姆語原住民後裔無法估量的損失，由於暴力而被迫流離失所後，現在他們主要散居在國外。本文開發了一個 ASR 模型，以加速這種瀕危語言的文件化，並在一個我們稱為 NoLoR 的新架構中概括了該策略。

##### **PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**
2412.04714v1 by Hongjin Lin, Matthew Nazari, Derek Zheng

Reliable large-scale data on the state of forests is crucial for monitoring
ecosystem health, carbon stock, and the impact of climate change. Current
knowledge of tree species distribution relies heavily on manual data collection
in the field, which often takes years to complete, resulting in limited
datasets that cover only a small subset of the world's forests. Recent works
show that state-of-the-art deep learning models using Light Detection and
Ranging (LiDAR) images enable accurate and scalable classification of tree
species in various ecosystems. While LiDAR images contain rich 3D information,
most previous works flatten the 3D images into 2D projections to use
Convolutional Neural Networks (CNNs). This paper offers three significant
contributions: (1) we apply the deep learning framework for tree classification
in tropical savannas; (2) we use Airborne LiDAR images, which have a lower
resolution but greater scalability than Terrestrial LiDAR images used in most
previous works; (3) we introduce the approach of directly feeding 3D point
cloud images into a vision transformer model (PCTreeS). Our results show that
the PCTreeS approach outperforms current CNN baselines with 2D projections in
AUC (0.81), overall accuracy (0.72), and training time (~45 mins). This paper
also motivates further LiDAR image collection and validation for accurate
large-scale automatic classification of tree species.

摘要：可靠的大規模森林狀態資料對於監測生態系統健康、碳儲量和氣候變遷的影響至關重要。目前對樹種分布的了解極度依賴於實地手動收集資料，這通常需要花費數年才能完成，導致只能涵蓋全球少數森林的有限資料集。最近的研究顯示，使用光探測和測距 (LiDAR) 影像的最新深度學習模型，可以在各種生態系統中對樹種進行準確且可擴充的分類。儘管 LiDAR 影像包含豐富的 3D 資訊，但大多數先前的研究會將 3D 影像壓縮成 2D 投影，以使用卷積神經網路 (CNN)。本文提供了三項重要的貢獻：(1) 我們將深度學習架構應用於熱帶稀樹草原的樹種分類；(2) 我們使用機載 LiDAR 影像，其解析度較低，但可擴充性比大多數先前研究中使用的地面 LiDAR 影像更高；(3) 我們引入了直接將 3D 點雲影像輸入到視覺Transformer模型 (PCTreeS) 的方法。我們的結果顯示，PCTreeS 方法在 AUC (0.81)、整體準確度 (0.72) 和訓練時間 (~45 分鐘) 方面優於當前使用 2D 投影的 CNN 基準。本文也激勵進一步收集和驗證 LiDAR 影像，以進行準確的大規模樹種自動分類。

##### **Parametric-ControlNet: Multimodal Control in Foundation Models for Precise Engineering Design Synthesis**
2412.04707v1 by Rui Zhou, Yanxia Zhang, Chenyang Yuan, Frank Permenter, Nikos Arechiga, Matt Klenk, Faez Ahmed

This paper introduces a generative model designed for multimodal control over
text-to-image foundation generative AI models such as Stable Diffusion,
specifically tailored for engineering design synthesis. Our model proposes
parametric, image, and text control modalities to enhance design precision and
diversity. Firstly, it handles both partial and complete parametric inputs
using a diffusion model that acts as a design autocomplete co-pilot, coupled
with a parametric encoder to process the information. Secondly, the model
utilizes assembly graphs to systematically assemble input component images,
which are then processed through a component encoder to capture essential
visual data. Thirdly, textual descriptions are integrated via CLIP encoding,
ensuring a comprehensive interpretation of design intent. These diverse inputs
are synthesized through a multimodal fusion technique, creating a joint
embedding that acts as the input to a module inspired by ControlNet. This
integration allows the model to apply robust multimodal control to foundation
models, facilitating the generation of complex and precise engineering designs.
This approach broadens the capabilities of AI-driven design tools and
demonstrates significant advancements in precise control based on diverse data
modalities for enhanced design generation.

摘要：本文介紹一個生成模型，旨在對 Stable Diffusion 等多模態控制文本到影像基礎生成式 AI 模型進行控制，特別針對工程設計合成量身打造。我們的模型提出參數、影像和文字控制模式，以增強設計精度和多樣性。首先，它使用一個擴散模型處理部分和完整的參數輸入，該模型充當設計自動完成副駕駛，並結合一個參數編碼器來處理資訊。其次，該模型利用組裝圖系統性地組裝輸入元件影像，然後透過元件編碼器處理這些影像以擷取必要的視覺資料。第三，文字描述透過 CLIP 編碼進行整合，確保對設計意圖進行全面詮釋。這些多元輸入透過多模態融合技術進行合成，建立一個聯合嵌入，作為受 ControlNet 啟發模組的輸入。這種整合讓模型能對基礎模型套用強大的多模態控制，促進生成複雜且精確的工程設計。這種方法擴展了 AI 驅動設計工具的能力，並展示了基於多元資料模式的精確控制在增強設計生成方面的顯著進展。

##### **On Interpreting the Effectiveness of Unsupervised Software Traceability with Information Theory**
2412.04704v1 by David N. Palacio, Daniel Rodriguez-Cardenas, Denys Poshyvanyk, Kevin Moran

Traceability is a cornerstone of modern software development, ensuring system
reliability and facilitating software maintenance. While unsupervised
techniques leveraging Information Retrieval (IR) and Machine Learning (ML)
methods have been widely used for predicting trace links, their effectiveness
remains underexplored. In particular, these techniques often assume
traceability patterns are present within textual data - a premise that may not
hold universally. Moreover, standard evaluation metrics such as precision,
recall, accuracy, or F1 measure can misrepresent the model performance when
underlying data distributions are not properly analyzed. Given that automated
traceability techniques tend to struggle to establish links, we need further
insight into the information limits related to traceability artifacts. In this
paper, we propose an approach, TraceXplainer, for using information theory
metrics to evaluate and better understand the performance (limits) of
unsupervised traceability techniques. Specifically, we introduce
self-information, cross-entropy, and mutual information (MI) as metrics to
measure the informativeness and reliability of traceability links. Through a
comprehensive replication and analysis of well-studied datasets and techniques,
we investigate the effectiveness of unsupervised techniques that predict
traceability links using IR/ML. This application of TraceXplainer illustrates
an imbalance in typical traceability datasets where the source code has on
average 1.48 more information bits (i.e., entropy) than the linked
documentation. Additionally, we demonstrate that an average MI of 4.81 bits,
loss of 1.75, and noise of 0.28 bits signify that there are
information-theoretic limits on the effectiveness of unsupervised traceability
techniques. We hope these findings spur additional research on understanding
the limits and progress of traceability research.

摘要：<paragraph>追溯性是現代軟體開發的基石，確保系統可靠性並促進軟體維護。儘管利用資訊檢索 (IR) 和機器學習 (ML) 方法的非監督技術已廣泛用於預測追溯連結，但其有效性仍未充分探討。特別是，這些技術通常假設追溯模式存在於文字資料中，而這項前提可能無法普遍適用。此外，當底層資料分佈未經適當分析時，標準評估指標，例如精確度、召回率、準確度或 F1 量測，可能會曲解模型效能。鑑於自動化追溯技術往往難以建立連結，我們需要進一步了解與追溯性人工製品相關的資訊限制。在本文中，我們提出 TraceXplainer 方法，使用資訊理論指標來評估和更深入了解非監督追溯技術的效能（限制）。具體來說，我們引入自資訊、交叉熵和互資訊 (MI) 作為指標，以量測追溯連結的資訊量和可靠性。透過對研究完善的資料集和技術進行全面複製和分析，我們探討使用 IR/ML 預測追溯連結的非監督技術的有效性。TraceXplainer 的此應用說明了典型追溯性資料集的不平衡，其中原始碼平均比連結文件多 1.48 個資訊位元（即熵）。此外，我們證明平均 4.81 位元的 MI、1.75 的損失和 0.28 位元的雜訊表示非監督追溯技術的有效性存在資訊理論限制。我們希望這些發現能激勵更多研究，以了解追溯研究的限制和進展。</paragraph>

##### **Transformers Struggle to Learn to Search**
2412.04703v1 by Abulhair Saparov, Srushti Pawar, Shreyas Pimpalgaonkar, Nitish Joshi, Richard Yuanzhe Pang, Vishakh Padmakumar, Seyed Mehran Kazemi, Najoung Kim, He He

Search is an ability foundational in many important tasks, and recent studies
have shown that large language models (LLMs) struggle to perform search
robustly. It is unknown whether this inability is due to a lack of data,
insufficient model parameters, or fundamental limitations of the transformer
architecture. In this work, we use the foundational graph connectivity problem
as a testbed to generate effectively limitless high-coverage data to train
small transformers and test whether they can learn to perform search. We find
that, when given the right training distribution, the transformer is able to
learn to search.
  We analyze the algorithm that the transformer has learned through a novel
mechanistic interpretability technique that enables us to extract the
computation graph from the trained model. We find that for each vertex in the
input graph, transformers compute the set of vertices reachable from that
vertex. Each layer then progressively expands these sets, allowing the model to
search over a number of vertices exponential in the number of layers.
  However, we find that as the input graph size increases, the transformer has
greater difficulty in learning the task. This difficulty is not resolved even
as the number of parameters is increased, suggesting that increasing model
scale will not lead to robust search abilities. We also find that performing
search in-context (i.e., chain-of-thought) does not resolve this inability to
learn to search on larger graphs.

摘要：搜尋是許多重要任務中的一項基礎能力，最近的研究表明，大型語言模型 (LLM) 難以穩健地執行搜尋。目前尚不清楚這種無能是源於資料不足、模型參數不足，還是 Transformer 架構的基本限制。在這項工作中，我們使用基礎圖形連通性問題作為測試平台，生成有效無限的高覆蓋率資料，以訓練小型 Transformer 並測試它們是否能學會執行搜尋。我們發現，當給予正確的訓練分佈時，Transformer 能夠學會搜尋。
我們透過一種新穎的機制可解釋性技術分析 Transformer 學到的演算法，這讓我們能夠從訓練好的模型中提取運算圖形。我們發現，對於輸入圖形中的每個頂點，Transformer 會計算從該頂點可到達的頂點集合。然後，每一層都會逐步擴充這些集合，讓模型能夠在與層數呈指數關係的頂點數目上進行搜尋。
然而，我們發現，隨著輸入圖形大小的增加，Transformer 在學習任務時會遇到更大的困難。即使增加參數數量，這種困難也不會得到解決，這表明增加模型規模不會帶來穩健的搜尋能力。我們還發現，在上下文中執行搜尋（即思考鏈）無法解決這種無法學習在較大圖形上搜尋的問題。

##### **Privacy-Preserving Retrieval Augmented Generation with Differential Privacy**
2412.04697v1 by Tatsuki Koga, Ruihan Wu, Kamalika Chaudhuri

With the recent remarkable advancement of large language models (LLMs), there
has been a growing interest in utilizing them in the domains with highly
sensitive data that lies outside their training data. For this purpose,
retrieval augmented generation (RAG) is particularly effective -- it assists
LLMs by directly providing relevant information from the external knowledge
sources. However, without extra privacy safeguards, RAG outputs risk leaking
sensitive information from the external data source. In this work, we explore
RAG under differential privacy (DP), a formal guarantee of data privacy. The
main challenge with differentially private RAG is how to generate long accurate
answers within a moderate privacy budget. We address this by proposing an
algorithm that smartly spends privacy budget only for the tokens that require
the sensitive information and uses the non-private LLM for other tokens. Our
extensive empirical evaluations reveal that our algorithm outperforms the
non-RAG baseline under a reasonable privacy budget of $\epsilon\approx 10$
across different models and datasets.

摘要：隨著大型語言模型 (LLM) 近期的顯著進步，
在利用它們於訓練資料之外的高敏感性資料領域中，
已經產生了越來越大的興趣。為此，
檢索增強生成 (RAG) 特別有效，它透過直接提供來自外部知識來源的相關資訊來協助 LLM。然而，在沒有額外隱私保障措施的情況下，RAG 輸出有洩漏來自外部資料來源的敏感資訊的風險。在這項工作中，我們在差分隱私 (DP) 下探索 RAG，這是資料隱私的正式保證。差分隱私 RAG 的主要挑戰是如何在適度的隱私預算中產生長而準確的答案。我們透過提出一個演算法來解決這個問題，該演算法巧妙地僅將隱私預算花費在需要敏感資訊的符號上，並將非私有的 LLM 用於其他符號。我們廣泛的經驗評估顯示，我們的演算法在不同的模型和資料集上，在合理的隱私預算 $\epsilon\approx 10$ 下，優於非 RAG 基準。

##### **Smoothie: Label Free Language Model Routing**
2412.04692v1 by Neel Guha, Mayee F. Chen, Trevor Chow, Ishan S. Khare, Christopher Ré

Large language models (LLMs) are increasingly used in applications where LLM
inputs may span many different tasks. Recent work has found that the choice of
LLM is consequential, and different LLMs may be good for different input
samples. Prior approaches have thus explored how engineers might select an LLM
to use for each sample (i.e. routing). While existing routing methods mostly
require training auxiliary models on human-annotated data, our work explores
whether it is possible to perform unsupervised routing. We propose Smoothie, a
weak supervision-inspired routing approach that requires no labeled data. Given
a set of outputs from different LLMs, Smoothie constructs a latent variable
graphical model over embedding representations of observable LLM outputs and
unknown "true" outputs. Using this graphical model, we estimate
sample-dependent quality scores for each LLM, and route each sample to the LLM
with the highest corresponding score. We find that Smoothie's LLM
quality-scores correlate with ground-truth model quality (correctly identifying
the optimal model on 9/14 tasks), and that Smoothie outperforms baselines for
routing by up to 10 points accuracy.

摘要：大型語言模型 (LLM)  zunehmend in Anwendungen verwendet werden, bei denen LLM-Eingaben viele verschiedene Aufgaben umfassen können. Jüngste Arbeiten haben ergeben, dass die Wahl des LLM ausschlaggebend ist und verschiedene LLMs für verschiedene Eingabeproben geeignet sein können. Bisherige Ansätze haben daher untersucht, wie Ingenieure ein LLM auswählen können, das für jede Probe verwendet werden soll (d. h. Routing). Während bestehende Routing-Methoden meist erfordern, dass Hilfsmodelle für mit menschlichen Anmerkungen versehene Daten trainiert werden, untersucht unsere Arbeit, ob es möglich ist, unüberwachtes Routing durchzuführen. Wir schlagen Smoothie vor, einen von schwacher Überwachung inspirierten Routing-Ansatz, der keine beschrifteten Daten benötigt. Angesichts einer Reihe von Ausgaben verschiedener LLMs konstruiert Smoothie ein latentes variables grafisches Modell über eingebettete Repräsentationen von beobachtbaren LLM-Ausgaben und unbekannten „wahren“ Ausgaben. Mithilfe dieses grafischen Modells schätzen wir probenabhängige Qualitätswerte für jedes LLM und leiten jede Probe an das LLM mit der höchsten entsprechenden Punktzahl weiter. Wir stellen fest, dass die LLM-Qualitätswerte von Smoothie mit der Grundwahrheitsmodellqualität korrelieren (die das optimale Modell bei 9/14 Aufgaben korrekt identifiziert) und dass Smoothie Basiswerte für Routing um bis zu 10 Punkte Genauigkeit übertrifft.

##### **LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**
2412.04690v1 by Xuan Chen, Tong Lu, Zhichun Wang

Entity Alignment (EA) seeks to identify and match corresponding entities
across different Knowledge Graphs (KGs), playing a crucial role in knowledge
fusion and integration. Embedding-based entity alignment (EA) has recently
gained considerable attention, resulting in the emergence of many innovative
approaches. Initially, these approaches concentrated on learning entity
embeddings based on the structural features of knowledge graphs (KGs) as
defined by relation triples. Subsequent methods have integrated entities' names
and attributes as supplementary information to improve the embeddings used for
EA. However, existing methods lack a deep semantic understanding of entity
attributes and relations. In this paper, we propose a Large Language Model
(LLM) based Entity Alignment method, LLM-Align, which explores the
instruction-following and zero-shot capabilities of Large Language Models to
infer alignments of entities. LLM-Align uses heuristic methods to select
important attributes and relations of entities, and then feeds the selected
triples of entities to an LLM to infer the alignment results. To guarantee the
quality of alignment results, we design a multi-round voting mechanism to
mitigate the hallucination and positional bias issues that occur with LLMs.
Experiments on three EA datasets, demonstrating that our approach achieves
state-of-the-art performance compared to existing EA methods.

摘要：實體對齊 (EA) 旨在識別和匹配不同知識圖譜 (KG) 中對應的實體，在知識融合和整合中扮演著至關重要的角色。基於嵌入的實體對齊 (EA) 近來備受關注，進而催生出許多創新的方法。最初，這些方法專注於根據知識圖譜 (KG) 的結構特徵來學習實體嵌入，這些特徵由關係三元組定義。後續方法將實體名稱和屬性整合為補充資訊，以改善用於 EA 的嵌入。然而，現有方法缺乏對實體屬性和關係的深入語義理解。在本文中，我們提出了一種基於大型語言模型 (LLM) 的實體對齊方法 LLM-Align，該方法探索了大型語言模型的遵循指令和零次學習能力，以推論實體對齊。LLM-Align 使用啟發式方法來選擇實體的重要屬性和關係，然後將實體的選定三元組饋入 LLM 以推論對齊結果。為了保證對齊結果的品質，我們設計了一個多輪投票機制，以減輕 LLM 中出現的幻覺和位置偏差問題。在三個 EA 資料集上的實驗表明，與現有的 EA 方法相比，我們的做法達到了最先進的效能。

##### **Two stages domain invariant representation learners solve the large co-variate shift in unsupervised domain adaptation with two dimensional data domains**
2412.04682v1 by Hisashi Oshima, Tsuyoshi Ishizone, Tomoyuki Higuchi

Recent developments in the unsupervised domain adaptation (UDA) enable the
unsupervised machine learning (ML) prediction for target data, thus this will
accelerate real world applications with ML models such as image recognition
tasks in self-driving. Researchers have reported the UDA techniques are not
working well under large co-variate shift problems where e.g. supervised source
data consists of handwritten digits data in monotone color and unsupervised
target data colored digits data from the street view. Thus there is a need for
a method to resolve co-variate shift and transfer source labelling rules under
this dynamics. We perform two stages domain invariant representation learning
to bridge the gap between source and target with semantic intermediate data
(unsupervised). The proposed method can learn domain invariant features
simultaneously between source and intermediate also intermediate and target.
Finally this achieves good domain invariant representation between source and
target plus task discriminability owing to source labels. This induction for
the gradient descent search greatly eases learning convergence in terms of
classification performance for target data even when large co-variate shift. We
also derive a theorem for measuring the gap between trained models and
unsupervised target labelling rules, which is necessary for the free parameters
optimization. Finally we demonstrate that proposing method is superiority to
previous UDA methods using 4 representative ML classification datasets
including 38 UDA tasks. Our experiment will be a basis for challenging UDA
problems with large co-variate shift.

摘要：最近在無監督領域適應 (UDA) 的發展，使得無監督機器學習 (ML) 預測可應用於目標資料，因此這將加速 ML 模型的實際應用，例如自駕車中的影像辨識任務。研究人員報告指出，UDA 技術在大型共變異數轉移問題下無法順利運作，例如監督來源資料包含單色手寫數字資料，而無監督目標資料則包含來自街景的彩色數字資料。因此，需要一種方法來解決共變異數轉移，並在此動態下轉移來源標籤規則。我們執行兩階段網域不變表示學習，以透過語意中間資料（無監督）來彌合來源與目標之間的差距。所提出的方法可以在來源與中間，以及中間與目標之間同時學習網域不變特徵。最後，這在來源標籤的幫助下，達到了來源與目標之間良好的網域不變表示，以及任務可辨別性。這種用於梯度下降搜尋的歸納，即使在大型共變異數轉移的情況下，也能大幅簡化目標資料分類效能的學習收斂。我們也推導了一個用於測量訓練模型與無監督目標標籤規則之間差距的定理，這對於自由參數最佳化而言是必要的。最後，我們證明了所提出的方法優於先前的 UDA 方法，使用 4 個具代表性的 ML 分類資料集，其中包括 38 個 UDA 任務。我們的實驗將成為挑戰具有大型共變異數轉移的 UDA 問題的基礎。

