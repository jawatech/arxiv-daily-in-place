{"2408.03202": {"publish_time": "2024-08-06", "title": "A Debiased Nearest Neighbors Framework for Multi-Label Text Classification", "paper_summary": "Multi-Label Text Classification (MLTC) is a practical yet challenging task\nthat involves assigning multiple non-exclusive labels to each document.\nPrevious studies primarily focus on capturing label correlations to assist\nlabel prediction by introducing special labeling schemes, designing specific\nmodel structures, or adding auxiliary tasks. Recently, the $k$ Nearest Neighbor\n($k$NN) framework has shown promise by retrieving labeled samples as references\nto mine label co-occurrence information in the embedding space. However, two\ncritical biases, namely embedding alignment bias and confidence estimation\nbias, are often overlooked, adversely affecting prediction performance. In this\npaper, we introduce a DEbiased Nearest Neighbors (DENN) framework for MLTC,\nspecifically designed to mitigate these biases. To address embedding alignment\nbias, we propose a debiased contrastive learning strategy, enhancing neighbor\nconsistency on label co-occurrence. For confidence estimation bias, we present\na debiased confidence estimation strategy, improving the adaptive combination\nof predictions from $k$NN and inductive binary classifications. Extensive\nexperiments conducted on four public benchmark datasets (i.e., AAPD, RCV1-V2,\nAmazon-531, and EUR-LEX57K) showcase the effectiveness of our proposed method.\nBesides, our method does not introduce any extra parameters.", "paper_summary_zh": "\u591a\u6a19\u7c64\u6587\u5b57\u5206\u985e (MLTC) \u662f\u4e00\u9805\u5be6\u7528\u537b\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\uff0c\u6d89\u53ca\u5c07\u591a\u500b\u975e\u7368\u4f54\u6a19\u7c64\u6307\u6d3e\u7d66\u6bcf\u500b\u6587\u4ef6\u3002\u5148\u524d\u7684\u7814\u7a76\u4e3b\u8981\u5c08\u6ce8\u65bc\u64f7\u53d6\u6a19\u7c64\u95dc\u806f\u6027\uff0c\u85c9\u7531\u5f15\u5165\u7279\u6b8a\u6a19\u7c64\u67b6\u69cb\u3001\u8a2d\u8a08\u7279\u5b9a\u6a21\u578b\u7d50\u69cb\u6216\u65b0\u589e\u8f14\u52a9\u4efb\u52d9\u4f86\u5354\u52a9\u6a19\u7c64\u9810\u6e2c\u3002\u6700\u8fd1\uff0ck \u6700\u8fd1\u9130 ($k$NN) \u67b6\u69cb\u900f\u904e\u64f7\u53d6\u6a19\u7c64\u6a23\u672c\u4f5c\u70ba\u53c3\u8003\uff0c\u5728\u5d4c\u5165\u7a7a\u9593\u4e2d\u6316\u6398\u6a19\u7c64\u5171\u73fe\u8cc7\u8a0a\uff0c\u5c55\u73fe\u4e86\u524d\u666f\u3002\u7136\u800c\uff0c\u5169\u500b\u95dc\u9375\u504f\u5dee\uff0c\u5373\u5d4c\u5165\u5c0d\u9f4a\u504f\u5dee\u548c\u4fe1\u5fc3\u4f30\u8a08\u504f\u5dee\uff0c\u7d93\u5e38\u88ab\u5ffd\u7565\uff0c\u5c0d\u9810\u6e2c\u6548\u80fd\u7522\u751f\u8ca0\u9762\u5f71\u97ff\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u7528\u65bc MLTC \u7684\u53bb\u504f\u5dee\u6700\u8fd1\u9130 (DENN) \u67b6\u69cb\uff0c\u7279\u5225\u8a2d\u8a08\u7528\u65bc\u6e1b\u8f15\u9019\u4e9b\u504f\u5dee\u3002\u70ba\u4e86\u8655\u7406\u5d4c\u5165\u5c0d\u9f4a\u504f\u5dee\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u53bb\u504f\u5dee\u5c0d\u6bd4\u5b78\u7fd2\u7b56\u7565\uff0c\u589e\u5f37\u9130\u5c45\u5728\u6a19\u7c64\u5171\u73fe\u4e0a\u7684\u4e00\u81f4\u6027\u3002\u5c0d\u65bc\u4fe1\u5fc3\u4f30\u8a08\u504f\u5dee\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u53bb\u504f\u5dee\u4fe1\u5fc3\u4f30\u8a08\u7b56\u7565\uff0c\u6539\u5584\u4e86\u4f86\u81ea $k$NN \u548c\u6b78\u7d0d\u4e8c\u5143\u5206\u985e\u7684\u9810\u6e2c\u7684\u9069\u61c9\u6027\u7d44\u5408\u3002\u5728\u56db\u500b\u516c\u958b\u57fa\u6e96\u8cc7\u6599\u96c6\uff08\u5373 AAPD\u3001RCV1-V2\u3001Amazon-531 \u548c EUR-LEX57K\uff09\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u5c55\u793a\u4e86\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u6c92\u6709\u5f15\u5165\u4efb\u4f55\u984d\u5916\u53c3\u6578\u3002", "author": "Zifeng Cheng et.al.", "authors": "Zifeng Cheng, Zhiwei Jiang, Yafeng Yin, Zhaoling Chen, Cong Wang, Shiping Ge, Qiguo Huang, Qing Gu", "id": "2408.03202v1", "paper_url": "http://arxiv.org/abs/2408.03202v1", "repo": "null"}}