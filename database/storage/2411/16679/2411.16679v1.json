{"2411.16679": {"publish_time": "2024-11-25", "title": "Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?", "paper_summary": "We evaluate how well Large Language Models (LLMs) latently recall and compose\nfacts to answer multi-hop queries like \"In the year Scarlett Johansson was\nborn, the Summer Olympics were hosted in the country of\". One major challenge\nin evaluating this ability is that LLMs may have developed shortcuts by\nencounters of the head entity \"Scarlett Johansson\" and the answer entity\n\"United States\" in the same training sequences or merely guess the answer based\non frequency-based priors. To prevent shortcuts, we exclude test queries where\nthe head and answer entities co-appear in pretraining corpora. Through careful\nselection of relations and facts and systematic removal of cases where models\nmight guess answers or exploit partial matches, we construct an evaluation\ndataset SOCRATES (ShOrtCut-fRee lATent rEaSoning). We observe that LLMs\ndemonstrate promising latent multi-hop reasoning abilities without exploiting\nshortcuts, but only for certain types of queries. For queries requiring latent\nrecall of countries as the intermediate answer, the best models achieve 80%\nlatent composability, but this drops to just 5% for the recall of years.\nComparisons with Chain-of-Thought composability highlight a significant gap\nbetween the ability of models to reason latently versus explicitly. Analysis\nreveals that latent representations of the intermediate answer are constructed\nmore often in queries with higher latent composability, and shows the emergence\nof latent multi-hop reasoning during pretraining.", "paper_summary_zh": "\u6211\u5011\u8a55\u4f30\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u6f5b\u5728\u56de\u61b6\u548c\u7d44\u5408\u4e8b\u5be6\u65b9\u9762\u8868\u73fe\u5982\u4f55\uff0c\u4ee5\u56de\u7b54\u591a\u91cd\u8df3\u8e8d\u67e5\u8a62\uff0c\u4f8b\u5982\u300c\u53f2\u5609\u857e\u55ac\u97d3\u68ee\u51fa\u751f\u7684\u90a3\u4e00\u5e74\uff0c\u590f\u5b63\u5967\u904b\u6703\u5728\u570b\u5bb6\u8209\u8fa6\u300d\u3002\u8a55\u4f30\u6b64\u80fd\u529b\u7684\u4e00\u9805\u91cd\u5927\u6311\u6230\u5728\u65bc\uff0cLLM \u53ef\u80fd\u900f\u904e\u5728\u76f8\u540c\u7684\u8a13\u7df4\u5e8f\u5217\u4e2d\u906d\u9047\u982d\u90e8\u5be6\u9ad4\u300c\u53f2\u5609\u857e\u55ac\u97d3\u68ee\u300d\u548c\u7b54\u6848\u5be6\u9ad4\u300c\u7f8e\u570b\u300d\u800c\u958b\u767c\u51fa\u6377\u5f91\uff0c\u6216\u50c5\u6839\u64da\u57fa\u65bc\u983b\u7387\u7684\u5148\u9a57\u731c\u6e2c\u7b54\u6848\u3002\u70ba\u4e86\u9632\u6b62\u6377\u5f91\uff0c\u6211\u5011\u6392\u9664\u4e86\u982d\u90e8\u548c\u7b54\u6848\u5be6\u9ad4\u5728\u9810\u8a13\u7df4\u8a9e\u6599\u5eab\u4e2d\u5171\u540c\u51fa\u73fe\u7684\u6e2c\u8a66\u67e5\u8a62\u3002\u900f\u904e\u4ed4\u7d30\u9078\u64c7\u95dc\u4fc2\u548c\u4e8b\u5be6\uff0c\u4e26\u7cfb\u7d71\u6027\u5730\u79fb\u9664\u6a21\u578b\u53ef\u80fd\u731c\u6e2c\u7b54\u6848\u6216\u5229\u7528\u90e8\u5206\u5339\u914d\u7684\u6848\u4f8b\uff0c\u6211\u5011\u5efa\u69cb\u4e86\u4e00\u500b\u8a55\u4f30\u8cc7\u6599\u96c6 SOCRATES\uff08ShOrtCut-fRee lATent rEaSoning\uff09\u3002\u6211\u5011\u89c0\u5bdf\u5230\uff0cLLM \u5728\u4e0d\u5229\u7528\u6377\u5f91\u7684\u60c5\u6cc1\u4e0b\u5c55\u73fe\u51fa\u6f5b\u5728\u7684\u591a\u91cd\u8df3\u8e8d\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u50c5\u9650\u65bc\u7279\u5b9a\u985e\u578b\u7684\u67e5\u8a62\u3002\u5c0d\u65bc\u9700\u8981\u6f5b\u5728\u56de\u61b6\u570b\u5bb6\u4f5c\u70ba\u4e2d\u9593\u7b54\u6848\u7684\u67e5\u8a62\uff0c\u6700\u4f73\u6a21\u578b\u9054\u5230 80% \u7684\u6f5b\u5728\u53ef\u7d44\u5408\u6027\uff0c\u4f46\u9019\u5c0d\u65bc\u56de\u61b6\u5e74\u4efd\u4f86\u8aaa\u50c5\u4e0b\u964d\u5230 5%\u3002\u8207\u601d\u8003\u93c8\u53ef\u7d44\u5408\u6027\u7684\u6bd4\u8f03\u7a81\u986f\u4e86\u6a21\u578b\u6f5b\u5728\u63a8\u7406\u8207\u660e\u78ba\u63a8\u7406\u80fd\u529b\u4e4b\u9593\u7684\u986f\u8457\u5dee\u8ddd\u3002\u5206\u6790\u986f\u793a\uff0c\u5728\u6f5b\u5728\u53ef\u7d44\u5408\u6027\u8f03\u9ad8\u7684\u67e5\u8a62\u4e2d\uff0c\u4e2d\u9593\u7b54\u6848\u7684\u6f5b\u5728\u8868\u793a\u66f4\u5e38\u88ab\u5efa\u69cb\uff0c\u4e26\u986f\u793a\u5728\u9810\u8a13\u7df4\u671f\u9593\u51fa\u73fe\u6f5b\u5728\u7684\u591a\u91cd\u8df3\u8e8d\u63a8\u7406\u3002", "author": "Sohee Yang et.al.", "authors": "Sohee Yang, Nora Kassner, Elena Gribovskaya, Sebastian Riedel, Mor Geva", "id": "2411.16679v1", "paper_url": "http://arxiv.org/abs/2411.16679v1", "repo": "null"}}