{"2412.03104": {"publish_time": "2024-12-04", "title": "ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning", "paper_summary": "Understanding time series is crucial for its application in real-world\nscenarios. Recently, large language models (LLMs) have been increasingly\napplied to time series tasks, leveraging their strong language capabilities to\nenhance various applications. However, research on multimodal LLMs (MLLMs) for\ntime series understanding and reasoning remains limited, primarily due to the\nscarcity of high-quality datasets that align time series with textual\ninformation. This paper introduces ChatTS, a novel MLLM designed for time\nseries analysis. ChatTS treats time series as a modality, similar to how vision\nMLLMs process images, enabling it to perform both understanding and reasoning\nwith time series. To address the scarcity of training data, we propose an\nattribute-based method for generating synthetic time series with detailed\nattribute descriptions. We further introduce Time Series Evol-Instruct, a novel\napproach that generates diverse time series Q&As, enhancing the model's\nreasoning capabilities. To the best of our knowledge, ChatTS is the first MLLM\nthat takes multivariate time series as input, which is fine-tuned exclusively\non synthetic datasets. We evaluate its performance using benchmark datasets\nwith real-world data, including six alignment tasks and four reasoning tasks.\nOur results show that ChatTS significantly outperforms existing vision-based\nMLLMs (e.g., GPT-4o) and text/agent-based LLMs, achieving a 46.0% improvement\nin alignment tasks and a 25.8% improvement in reasoning tasks.", "paper_summary_zh": "<paragraph>\u4e86\u89e3\u6642\u9593\u5e8f\u5217\u5c0d\u65bc\u5176\u5728\u73fe\u5be6\u4e16\u754c\u4e2d\u7684\u61c9\u7528\u81f3\u95dc\u91cd\u8981\u3002\u6700\u8fd1\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u8d8a\u4f86\u8d8a\u591a\u5730\u61c9\u7528\u65bc\u6642\u9593\u5e8f\u5217\u4efb\u52d9\uff0c\u5229\u7528\u5176\u5f37\u5927\u7684\u8a9e\u8a00\u80fd\u529b\u4f86\u589e\u5f37\u5404\u7a2e\u61c9\u7528\u3002\u7136\u800c\uff0c\u91dd\u5c0d\u6642\u9593\u5e8f\u5217\u7406\u89e3\u548c\u63a8\u7406\u7684\u591a\u6a21\u614b LLM (MLLM) \u7684\u7814\u7a76\u4ecd\u7136\u6709\u9650\uff0c\u9019\u4e3b\u8981\u662f\u56e0\u70ba\u7f3a\u4e4f\u5c07\u6642\u9593\u5e8f\u5217\u8207\u6587\u672c\u4fe1\u606f\u5c0d\u9f4a\u7684\u9ad8\u54c1\u8cea\u6578\u64da\u96c6\u3002\u672c\u6587\u4ecb\u7d39\u4e86 ChatTS\uff0c\u9019\u662f\u4e00\u7a2e\u5c08\u70ba\u6642\u9593\u5e8f\u5217\u5206\u6790\u8a2d\u8a08\u7684\u65b0\u578b MLLM\u3002ChatTS \u5c07\u6642\u9593\u5e8f\u5217\u8996\u70ba\u4e00\u7a2e\u6a21\u614b\uff0c\u985e\u4f3c\u65bc\u8996\u89ba MLLM \u8655\u7406\u5716\u50cf\u7684\u65b9\u5f0f\uff0c\u4f7f\u5176\u80fd\u5920\u5c0d\u6642\u9593\u5e8f\u5217\u9032\u884c\u7406\u89e3\u548c\u63a8\u7406\u3002\u70ba\u4e86\u89e3\u6c7a\u8a13\u7df4\u6578\u64da\u7684\u7a00\u7f3a\u6027\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc\u5c6c\u6027\u7684\u65b9\u6cd5\uff0c\u7528\u65bc\u751f\u6210\u5177\u6709\u8a73\u7d30\u5c6c\u6027\u63cf\u8ff0\u7684\u5408\u6210\u6642\u9593\u5e8f\u5217\u3002\u6211\u5011\u9032\u4e00\u6b65\u5f15\u5165\u4e86\u6642\u9593\u5e8f\u5217 Evol-Instruct\uff0c\u9019\u662f\u4e00\u7a2e\u751f\u6210\u591a\u6a23\u5316\u6642\u9593\u5e8f\u5217\u554f\u7b54\u7684\u65b0\u65b9\u6cd5\uff0c\u589e\u5f37\u4e86\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u64da\u6211\u5011\u6240\u77e5\uff0cChatTS \u662f\u7b2c\u4e00\u500b\u5c07\u591a\u8b8a\u91cf\u6642\u9593\u5e8f\u5217\u4f5c\u70ba\u8f38\u5165\u7684 MLLM\uff0c\u5b83\u5c08\u9580\u91dd\u5c0d\u5408\u6210\u6578\u64da\u96c6\u9032\u884c\u5fae\u8abf\u3002\u6211\u5011\u4f7f\u7528\u5305\u542b\u771f\u5be6\u4e16\u754c\u6578\u64da\u7684\u57fa\u6e96\u6578\u64da\u96c6\u8a55\u4f30\u5176\u6027\u80fd\uff0c\u5305\u62ec\u516d\u500b\u5c0d\u9f4a\u4efb\u52d9\u548c\u56db\u500b\u63a8\u7406\u4efb\u52d9\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0cChatTS \u660e\u986f\u512a\u65bc\u73fe\u6709\u7684\u57fa\u65bc\u8996\u89ba\u7684 MLLM\uff08\u4f8b\u5982 GPT-4o\uff09\u548c\u57fa\u65bc\u6587\u672c/\u4ee3\u7406\u7684 LLM\uff0c\u5728\u5c0d\u9f4a\u4efb\u52d9\u4e2d\u6539\u9032\u4e86 46.0%\uff0c\u5728\u63a8\u7406\u4efb\u52d9\u4e2d\u6539\u9032\u4e86 25.8%\u3002</paragraph>", "author": "Zhe Xie et.al.", "authors": "Zhe Xie, Zeyan Li, Xiao He, Longlong Xu, Xidao Wen, Tieying Zhang, Jianjun Chen, Rui Shi, Dan Pei", "id": "2412.03104v1", "paper_url": "http://arxiv.org/abs/2412.03104v1", "repo": "null"}}