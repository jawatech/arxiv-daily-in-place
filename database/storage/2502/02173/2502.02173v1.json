{"2502.02173": {"publish_time": "2025-02-04", "title": "Mass-Editing Memory with Attention in Transformers: A cross-lingual exploration of knowledge", "paper_summary": "Recent research has explored methods for updating and modifying factual\nknowledge in large language models, often focusing on specific multi-layer\nperceptron blocks. This study expands on this work by examining the\neffectiveness of existing knowledge editing methods across languages and\ndelving into the role of attention mechanisms in this process. Drawing from the\ninsights gained, we propose Mass-Editing Memory with Attention in Transformers\n(MEMAT), a method that achieves significant improvements in all metrics while\nrequiring minimal parameter modifications. MEMAT delivers a remarkable 10%\nincrease in magnitude metrics, benefits languages not included in the training\ndata and also demonstrates a high degree of portability. Our code and data are\nat https://github.com/dtamayo-nlp/MEMAT.", "paper_summary_zh": "\u6700\u8fd1\u7684\u7814\u7a76\u63a2\u7d22\u4e86\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u66f4\u65b0\u548c\u4fee\u6539\u4e8b\u5b9e\u77e5\u8bc6\u7684\u65b9\u6cd5\uff0c\u901a\u5e38\u4e13\u6ce8\u4e8e\u7279\u5b9a\u591a\u5c42\u611f\u77e5\u5668\u5757\u3002\u672c\u7814\u7a76\u901a\u8fc7\u68c0\u67e5\u73b0\u6709\u7684\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\u5728\u4e0d\u540c\u8bed\u8a00\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u6df1\u5165\u7814\u7a76\u6ce8\u610f\u529b\u673a\u5236\u5728\u6b64\u8fc7\u7a0b\u4e2d\u7684\u4f5c\u7528\uff0c\u6269\u5c55\u4e86\u8fd9\u9879\u5de5\u4f5c\u3002\u4ece\u83b7\u5f97\u7684\u89c1\u89e3\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 Transformer \u4e2d\u5e26\u6709\u6ce8\u610f\u529b\u7684 Mass-Editing Memory (MEMAT)\uff0c\u8fd9\u662f\u4e00\u79cd\u5728\u6240\u6709\u6307\u6807\u4e0a\u5b9e\u73b0\u663e\u8457\u6539\u8fdb\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u9700\u8981\u6700\u5c0f\u7684\u53c2\u6570\u4fee\u6539\u3002MEMAT \u5728\u5e45\u5ea6\u6307\u6807\u4e0a\u5b9e\u73b0\u4e86\u60ca\u4eba\u7684 10% \u7684\u589e\u957f\uff0c\u6709\u5229\u4e8e\u672a\u5305\u542b\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u8bed\u8a00\uff0c\u5e76\u4e14\u8fd8\u5c55\u793a\u4e86\u9ad8\u5ea6\u7684\u53ef\u79fb\u690d\u6027\u3002\u6211\u4eec\u7684\u4ee3\u7801\u548c\u6570\u636e\u4f4d\u4e8e https://github.com/dtamayo-nlp/MEMAT\u3002", "author": "Daniel Tamayo et.al.", "authors": "Daniel Tamayo, Aitor Gonzalez-Agirre, Javier Hernando, Marta Villegas", "id": "2502.02173v1", "paper_url": "http://arxiv.org/abs/2502.02173v1", "repo": "null"}}