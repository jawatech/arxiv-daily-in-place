{"2404.15946": {"publish_time": "2024-04-24", "title": "Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography", "paper_summary": "Although fusion of information from multiple views of mammograms plays an\nimportant role to increase accuracy of breast cancer detection, developing\nmulti-view mammograms-based computer-aided diagnosis (CAD) schemes still faces\nchallenges and no such CAD schemes have been used in clinical practice. To\novercome the challenges, we investigate a new approach based on Contrastive\nLanguage-Image Pre-training (CLIP), which has sparked interest across various\nmedical imaging tasks. By solving the challenges in (1) effectively adapting\nthe single-view CLIP for multi-view feature fusion and (2) efficiently\nfine-tuning this parameter-dense model with limited samples and computational\nresources, we introduce Mammo-CLIP, the first multi-modal framework to process\nmulti-view mammograms and corresponding simple texts. Mammo-CLIP uses an early\nfeature fusion strategy to learn multi-view relationships in four mammograms\nacquired from the CC and MLO views of the left and right breasts. To enhance\nlearning efficiency, plug-and-play adapters are added into CLIP image and text\nencoders for fine-tuning parameters and limiting updates to about 1% of the\nparameters. For framework evaluation, we assembled two datasets\nretrospectively. The first dataset, comprising 470 malignant and 479 benign\ncases, was used for few-shot fine-tuning and internal evaluation of the\nproposed Mammo-CLIP via 5-fold cross-validation. The second dataset, including\n60 malignant and 294 benign cases, was used to test generalizability of\nMammo-CLIP. Study results show that Mammo-CLIP outperforms the state-of-art\ncross-view transformer in AUC (0.841 vs. 0.817, 0.837 vs. 0.807) on both\ndatasets. It also surpasses previous two CLIP-based methods by 20.3% and 14.3%.\nThis study highlights the potential of applying the finetuned vision-language\nmodels for developing next-generation, image-text-based CAD schemes of breast\ncancer.", "paper_summary_zh": "", "author": "Xuxin Chen et.al.", "authors": "Xuxin Chen,Yuheng Li,Mingzhe Hu,Ella Salari,Xiaoqian Chen,Richard L. J. Qiu,Bin Zheng,Xiaofeng Yang", "id": "2404.15946v1", "paper_url": "http://arxiv.org/abs/2404.15946v1", "repo": "null"}}