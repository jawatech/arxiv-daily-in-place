{"2409.03183": {"publish_time": "2024-09-05", "title": "Bypassing DARCY Defense: Indistinguishable Universal Adversarial Triggers", "paper_summary": "Neural networks (NN) classification models for Natural Language Processing\n(NLP) are vulnerable to the Universal Adversarial Triggers (UAT) attack that\ntriggers a model to produce a specific prediction for any input. DARCY borrows\nthe \"honeypot\" concept to bait multiple trapdoors, effectively detecting the\nadversarial examples generated by UAT. Unfortunately, we find a new UAT\ngeneration method, called IndisUAT, which produces triggers (i.e., tokens) and\nuses them to craft adversarial examples whose feature distribution is\nindistinguishable from that of the benign examples in a randomly-chosen\ncategory at the detection layer of DARCY. The produced adversarial examples\nincur the maximal loss of predicting results in the DARCY-protected models.\nMeanwhile, the produced triggers are effective in black-box models for text\ngeneration, text inference, and reading comprehension. Finally, the evaluation\nresults under NN models for NLP tasks indicate that the IndisUAT method can\neffectively circumvent DARCY and penetrate other defenses. For example,\nIndisUAT can reduce the true positive rate of DARCY's detection by at least\n40.8% and 90.6%, and drop the accuracy by at least 33.3% and 51.6% in the RNN\nand CNN models, respectively. IndisUAT reduces the accuracy of the BERT's\nadversarial defense model by at least 34.0%, and makes the GPT-2 language model\nspew racist outputs even when conditioned on non-racial context.", "paper_summary_zh": "\u795e\u7d93\u7db2\u8def (NN) \u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u5206\u985e\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u901a\u7528\u5c0d\u6297\u6027\u89f8\u767c\u5668 (UAT) \u653b\u64ca\uff0c\u6b64\u653b\u64ca\u6703\u89f8\u767c\u6a21\u578b\u5c0d\u4efb\u4f55\u8f38\u5165\u7522\u751f\u7279\u5b9a\u9810\u6e2c\u3002DARCY \u501f\u7528\u300c\u8a98\u6355\u300d\u6982\u5ff5\u4f86\u8a98\u5c0e\u591a\u500b\u9677\u9631\u9580\uff0c\u6709\u6548\u5075\u6e2c UAT \u6240\u7522\u751f\u7684\u5c0d\u6297\u6027\u7bc4\u4f8b\u3002\u4e0d\u5e78\u7684\u662f\uff0c\u6211\u5011\u767c\u73fe\u4e00\u7a2e\u65b0\u7684 UAT \u7522\u751f\u65b9\u6cd5\uff0c\u7a31\u70ba IndisUAT\uff0c\u5b83\u6703\u7522\u751f\u89f8\u767c\u5668\uff08\u5373\u7b26\u865f\uff09\uff0c\u4e26\u4f7f\u7528\u5b83\u5011\u4f86\u88fd\u4f5c\u5c0d\u6297\u6027\u7bc4\u4f8b\uff0c\u5176\u7279\u5fb5\u5206\u4f48\u8207 DARCY \u5075\u6e2c\u5c64\u4e2d\u96a8\u6a5f\u9078\u64c7\u985e\u5225\u4e2d\u7684\u826f\u6027\u7bc4\u4f8b\u7121\u6cd5\u5340\u5206\u3002\u7522\u751f\u7684\u5c0d\u6297\u6027\u7bc4\u4f8b\u6703\u5c0e\u81f4 DARCY \u53d7\u4fdd\u8b77\u6a21\u578b\u4e2d\u9810\u6e2c\u7d50\u679c\u7684\u6700\u5927\u640d\u5931\u3002\u540c\u6642\uff0c\u7522\u751f\u7684\u89f8\u767c\u5668\u5728\u6587\u672c\u7522\u751f\u3001\u6587\u672c\u63a8\u8ad6\u548c\u95b1\u8b80\u7406\u89e3\u7684\u9ed1\u76d2\u6a21\u578b\u4e2d\u662f\u6709\u6548\u7684\u3002\u6700\u5f8c\uff0cNLP \u4efb\u52d9\u7684 NN \u6a21\u578b\u4e0b\u7684\u8a55\u4f30\u7d50\u679c\u8868\u660e\uff0cIndisUAT \u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u898f\u907f DARCY \u4e26\u6ef2\u900f\u5176\u4ed6\u9632\u79a6\u63aa\u65bd\u3002\u4f8b\u5982\uff0cIndisUAT \u53ef\u4ee5\u5c07 DARCY \u5075\u6e2c\u7684\u771f\u6b63\u967d\u6027\u7387\u81f3\u5c11\u964d\u4f4e 40.8% \u548c 90.6%\uff0c\u4e26\u5206\u5225\u4f7f RNN \u548c CNN \u6a21\u578b\u7684\u6e96\u78ba\u5ea6\u81f3\u5c11\u964d\u4f4e 33.3% \u548c 51.6%\u3002IndisUAT \u5c07 BERT \u5c0d\u6297\u9632\u79a6\u6a21\u578b\u7684\u6e96\u78ba\u5ea6\u964d\u4f4e\u4e86\u81f3\u5c11 34.0%\uff0c\u4e26\u8b93 GPT-2 \u8a9e\u8a00\u6a21\u578b\u5373\u4f7f\u5728\u975e\u7a2e\u65cf\u80cc\u666f\u4e0b\u4e5f\u6703\u7522\u751f\u7a2e\u65cf\u4e3b\u7fa9\u8f38\u51fa\u3002", "author": "Zuquan Peng et.al.", "authors": "Zuquan Peng, Yuanyuan He, Jianbing Ni, Ben Niu", "id": "2409.03183v1", "paper_url": "http://arxiv.org/abs/2409.03183v1", "repo": "null"}}