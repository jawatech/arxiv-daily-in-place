{"2410.23788": {"publish_time": "2024-10-31", "title": "EDT: An Efficient Diffusion Transformer Framework Inspired by Human-like Sketching", "paper_summary": "Transformer-based Diffusion Probabilistic Models (DPMs) have shown more\npotential than CNN-based DPMs, yet their extensive computational requirements\nhinder widespread practical applications. To reduce the computation budget of\ntransformer-based DPMs, this work proposes the Efficient Diffusion Transformer\n(EDT) framework. The framework includes a lightweight-design diffusion model\narchitecture, and a training-free Attention Modulation Matrix and its\nalternation arrangement in EDT inspired by human-like sketching. Additionally,\nwe propose a token relation-enhanced masking training strategy tailored\nexplicitly for EDT to augment its token relation learning capability. Our\nextensive experiments demonstrate the efficacy of EDT. The EDT framework\nreduces training and inference costs and surpasses existing transformer-based\ndiffusion models in image synthesis performance, thereby achieving a\nsignificant overall enhancement. With lower FID, EDT-S, EDT-B, and EDT-XL\nattained speed-ups of 3.93x, 2.84x, and 1.92x respectively in the training\nphase, and 2.29x, 2.29x, and 2.22x respectively in inference, compared to the\ncorresponding sizes of MDTv2. The source code is released at\nhttps://github.com/xinwangChen/EDT.", "paper_summary_zh": "<paragraph>\u57fa\u65bc Transformer \u7684\u64f4\u6563\u6a5f\u7387\u6a21\u578b (DPM) \u5df2\u5c55\u73fe\u51fa\u6bd4\u57fa\u65bc CNN \u7684 DPM \u66f4\u5927\u7684\u6f5b\u529b\uff0c\u4f46\u5176\u9f90\u5927\u7684\u904b\u7b97\u9700\u6c42\u537b\u963b\u7919\u4e86\u5ee3\u6cdb\u7684\u5be6\u969b\u61c9\u7528\u3002\u70ba\u4e86\u6e1b\u5c11\u57fa\u65bc Transformer \u7684 DPM \u7684\u904b\u7b97\u9810\u7b97\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u9ad8\u6548\u64f4\u6563 Transformer (EDT) \u67b6\u69cb\u3002\u8a72\u67b6\u69cb\u5305\u542b\u4e00\u500b\u8f15\u91cf\u7d1a\u8a2d\u8a08\u7684\u64f4\u6563\u6a21\u578b\u67b6\u69cb\uff0c\u4ee5\u53ca\u4e00\u500b\u7121\u9700\u8a13\u7df4\u7684\u6ce8\u610f\u529b\u8abf\u88fd\u77e9\u9663\uff0c\u4ee5\u53ca\u53d7\u985e\u4eba\u7d20\u63cf\u555f\u767c\u7684 EDT \u4e2d\u7684\u4ea4\u66ff\u6392\u5217\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u5c08\u9580\u70ba EDT \u91cf\u8eab\u6253\u9020\u7684\u4ee4\u724c\u95dc\u4fc2\u589e\u5f37\u906e\u7f69\u8a13\u7df4\u7b56\u7565\uff0c\u4ee5\u589e\u5f37\u5176\u4ee4\u724c\u95dc\u4fc2\u5b78\u7fd2\u80fd\u529b\u3002\u6211\u5011\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\u4e86 EDT \u7684\u529f\u6548\u3002EDT \u67b6\u69cb\u964d\u4f4e\u4e86\u8a13\u7df4\u548c\u63a8\u7406\u6210\u672c\uff0c\u4e26\u5728\u5f71\u50cf\u5408\u6210\u6548\u80fd\u65b9\u9762\u8d85\u8d8a\u4e86\u73fe\u6709\u7684\u57fa\u65bc Transformer \u7684\u64f4\u6563\u6a21\u578b\uff0c\u5f9e\u800c\u5be6\u73fe\u4e86\u986f\u8457\u7684\u6574\u9ad4\u63d0\u5347\u3002\u8207 MDTv2 \u7684\u76f8\u61c9\u5927\u5c0f\u76f8\u6bd4\uff0cEDT-S\u3001EDT-B \u548c EDT-XL \u5728\u8a13\u7df4\u968e\u6bb5\u5206\u5225\u63d0\u9ad8\u4e86 3.93 \u500d\u30012.84 \u500d\u548c 1.92 \u500d\u7684\u901f\u5ea6\uff0c\u5728\u63a8\u7406\u968e\u6bb5\u5206\u5225\u63d0\u9ad8\u4e86 2.29 \u500d\u30012.29 \u500d\u548c 2.22 \u500d\u3002\u539f\u59cb\u78bc\u5df2\u65bc https://github.com/xinwangChen/EDT \u767c\u5e03\u3002</paragraph>", "author": "Xinwang Chen et.al.", "authors": "Xinwang Chen, Ning Liu, Yichen Zhu, Feifei Feng, Jian Tang", "id": "2410.23788v1", "paper_url": "http://arxiv.org/abs/2410.23788v1", "repo": "https://github.com/xinwangchen/edt"}}