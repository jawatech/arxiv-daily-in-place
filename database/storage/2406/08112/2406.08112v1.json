{"2406.08112": {"publish_time": "2024-06-12", "title": "Codecfake: An Initial Dataset for Detecting LLM-based Deepfake Audio", "paper_summary": "With the proliferation of Large Language Model (LLM) based deepfake audio,\nthere is an urgent need for effective detection methods. Previous deepfake\naudio generation methods typically involve a multi-step generation process,\nwith the final step using a vocoder to predict the waveform from handcrafted\nfeatures. However, LLM-based audio is directly generated from discrete neural\ncodecs in an end-to-end generation process, skipping the final step of vocoder\nprocessing. This poses a significant challenge for current audio deepfake\ndetection (ADD) models based on vocoder artifacts. To effectively detect\nLLM-based deepfake audio, we focus on the core of the generation process, the\nconversion from neural codec to waveform. We propose Codecfake dataset, which\nis generated by seven representative neural codec methods. Experiment results\nshow that codec-trained ADD models exhibit a 41.406% reduction in average equal\nerror rate compared to vocoder-trained ADD models on the Codecfake test set.", "paper_summary_zh": "\u96a8\u8457\u57fa\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6df1\u5ea6\u507d\u9020\u97f3\u8a0a\u7684\u6fc0\u589e\uff0c\n\u8feb\u5207\u9700\u8981\u6709\u6548\u7684\u6aa2\u6e2c\u65b9\u6cd5\u3002\u5148\u524d\u7684\u6df1\u5ea6\u507d\u9020\u97f3\u8a0a\u7522\u751f\u65b9\u6cd5\u901a\u5e38\u6d89\u53ca\u591a\u6b65\u9a5f\u7522\u751f\u904e\u7a0b\uff0c\n\u6700\u5f8c\u4e00\u6b65\u4f7f\u7528\u8a9e\u97f3\u7de8\u78bc\u5668\u5f9e\u624b\u5de5\u7279\u5fb5\u9810\u6e2c\u6ce2\u5f62\u3002\u7136\u800c\uff0c\u57fa\u65bc LLM \u7684\u97f3\u8a0a\u662f\u5f9e\u96e2\u6563\u795e\u7d93\u7de8\u78bc\u5668\u4e2d\u76f4\u63a5\u7522\u751f\u7684\n\u5728\u7aef\u5230\u7aef\u751f\u6210\u904e\u7a0b\u4e2d\uff0c\u8df3\u904e\u8a9e\u97f3\u7de8\u78bc\u5668\u8655\u7406\u7684\u6700\u5f8c\u4e00\u6b65\u3002\u9019\u5c0d\u57fa\u65bc\u8a9e\u97f3\u7de8\u78bc\u5668\u4eba\u5de5\u88fd\u54c1\u7684\u7576\u524d\u97f3\u8a0a\u6df1\u5ea6\u507d\u9020\n\u6aa2\u6e2c (ADD) \u6a21\u578b\u69cb\u6210\u91cd\u5927\u6311\u6230\u3002\u70ba\u4e86\u6709\u6548\u6aa2\u6e2c\u57fa\u65bc LLM \u7684\u6df1\u5ea6\u507d\u9020\u97f3\u8a0a\uff0c\u6211\u5011\u5c08\u6ce8\u65bc\u751f\u6210\u904e\u7a0b\u7684\u6838\u5fc3\uff0c\n\u5f9e\u795e\u7d93\u7de8\u78bc\u5668\u8f49\u63db\u70ba\u6ce2\u5f62\u3002\u6211\u5011\u63d0\u51fa Codecfake \u8cc7\u6599\u96c6\uff0c\u5b83\u662f\u7531\u4e03\u7a2e\u4ee3\u8868\u6027\u795e\u7d93\u7de8\u78bc\u5668\u65b9\u6cd5\u7522\u751f\u7684\u3002\u5be6\u9a57\u7d50\u679c\n\u8868\u660e\uff0c\u8207\u5728 Codecfake \u6e2c\u8a66\u96c6\u4e2d\u8a13\u7df4\u7684\u8a9e\u97f3\u7de8\u78bc\u5668 ADD \u6a21\u578b\u76f8\u6bd4\uff0c\u8a13\u7df4\u7de8\u78bc\u5668\u7684 ADD \u6a21\u578b\u7684\u5e73\u5747\u7b49\u8aa4\u5dee\u7387\u964d\u4f4e\u4e86 41.406%\u3002", "author": "Yi Lu et.al.", "authors": "Yi Lu, Yuankun Xie, Ruibo Fu, Zhengqi Wen, Jianhua Tao, Zhiyong Wang, Xin Qi, Xuefei Liu, Yongwei Li, Yukun Liu, Xiaopeng Wang, Shuchen Shi", "id": "2406.08112v1", "paper_url": "http://arxiv.org/abs/2406.08112v1", "repo": "null"}}