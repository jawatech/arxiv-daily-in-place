{"2412.03179": {"publish_time": "2024-12-04", "title": "Optimizing Dense Visual Predictions Through Multi-Task Coherence and Prioritization", "paper_summary": "Multi-Task Learning (MTL) involves the concurrent training of multiple tasks,\noffering notable advantages for dense prediction tasks in computer vision. MTL\nnot only reduces training and inference time as opposed to having multiple\nsingle-task models, but also enhances task accuracy through the interaction of\nmultiple tasks. However, existing methods face limitations. They often rely on\nsuboptimal cross-task interactions, resulting in task-specific predictions with\npoor geometric and predictive coherence. In addition, many approaches use\ninadequate loss weighting strategies, which do not address the inherent\nvariability in task evolution during training. To overcome these challenges, we\npropose an advanced MTL model specifically designed for dense vision tasks. Our\nmodel leverages state-of-the-art vision transformers with task-specific\ndecoders. To enhance cross-task coherence, we introduce a trace-back method\nthat improves both cross-task geometric and predictive features. Furthermore,\nwe present a novel dynamic task balancing approach that projects task losses\nonto a common scale and prioritizes more challenging tasks during training.\nExtensive experiments demonstrate the superiority of our method, establishing\nnew state-of-the-art performance across two benchmark datasets. The code is\navailable at:https://github.com/Klodivio355/MT-CP", "paper_summary_zh": "\u591a\u4efb\u52d9\u5b78\u7fd2 (MTL) \u6d89\u53ca\u591a\u500b\u4efb\u52d9\u7684\u4e26\u767c\u8a13\u7df4\uff0c\u70ba\u96fb\u8166\u8996\u89ba\u4e2d\u7684\u5bc6\u96c6\u9810\u6e2c\u4efb\u52d9\u63d0\u4f9b\u4e86\u986f\u8457\u512a\u52e2\u3002MTL \u4e0d\u50c5\u6e1b\u5c11\u4e86\u8a13\u7df4\u548c\u63a8\u7406\u6642\u9593\uff0c\u8207\u64c1\u6709\u591a\u500b\u55ae\u4efb\u52d9\u6a21\u578b\u76f8\u6bd4\uff0c\u9084\u901a\u904e\u591a\u500b\u4efb\u52d9\u7684\u4ea4\u4e92\u589e\u5f37\u4e86\u4efb\u52d9\u6e96\u78ba\u6027\u3002\u7136\u800c\uff0c\u73fe\u6709\u65b9\u6cd5\u9762\u81e8\u9650\u5236\u3002\u5b83\u5011\u901a\u5e38\u4f9d\u8cf4\u65bc\u6b21\u512a\u7684\u8de8\u4efb\u52d9\u4ea4\u4e92\uff0c\u5c0e\u81f4\u4efb\u52d9\u7279\u5b9a\u7684\u9810\u6e2c\u5177\u6709\u8f03\u5dee\u7684\u5e7e\u4f55\u548c\u9810\u6e2c\u4e00\u81f4\u6027\u3002\u6b64\u5916\uff0c\u8a31\u591a\u65b9\u6cd5\u4f7f\u7528\u4e0d\u5145\u5206\u7684\u640d\u5931\u52a0\u6b0a\u7b56\u7565\uff0c\u9019\u7121\u6cd5\u89e3\u6c7a\u8a13\u7df4\u904e\u7a0b\u4e2d\u4efb\u52d9\u6f14\u5316\u7684\u56fa\u6709\u8b8a\u7570\u6027\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5c08\u9580\u70ba\u5bc6\u96c6\u8996\u89ba\u4efb\u52d9\u8a2d\u8a08\u7684\u9ad8\u7d1a MTL \u6a21\u578b\u3002\u6211\u5011\u7684\u6a21\u578b\u5229\u7528\u4e86\u6700\u5148\u9032\u7684\u8996\u89ba\u8b8a\u63db\u5668\u548c\u4efb\u52d9\u7279\u5b9a\u7684\u89e3\u78bc\u5668\u3002\u70ba\u4e86\u589e\u5f37\u8de8\u4efb\u52d9\u4e00\u81f4\u6027\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u8ffd\u6eaf\u65b9\u6cd5\uff0c\u5b83\u6539\u9032\u4e86\u8de8\u4efb\u52d9\u5e7e\u4f55\u548c\u9810\u6e2c\u7279\u5fb5\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u52d5\u614b\u4efb\u52d9\u5e73\u8861\u65b9\u6cd5\uff0c\u5b83\u5c07\u4efb\u52d9\u640d\u5931\u6295\u5f71\u5230\u4e00\u500b\u516c\u5171\u5c3a\u5ea6\u4e0a\uff0c\u4e26\u5728\u8a13\u7df4\u904e\u7a0b\u4e2d\u512a\u5148\u8003\u616e\u66f4\u5177\u6311\u6230\u6027\u7684\u4efb\u52d9\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u512a\u8d8a\u6027\uff0c\u5728\u5169\u500b\u57fa\u6e96\u6578\u64da\u96c6\u4e0a\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u9032\u6027\u80fd\u3002\u4ee3\u78bc\u53ef\u5728\u4ee5\u4e0b\u4f4d\u7f6e\u7372\u5f97\uff1ahttps://github.com/Klodivio355/MT-CP", "author": "Maxime Fontana et.al.", "authors": "Maxime Fontana, Michael Spratling, Miaojing Shi", "id": "2412.03179v1", "paper_url": "http://arxiv.org/abs/2412.03179v1", "repo": "null"}}