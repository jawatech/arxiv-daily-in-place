
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-12**|**Adaptive Prediction Ensemble: Improving Out-of-Distribution Generalization of Motion Forecasting**|Jinning Li et.al.|[2407.09475v1](http://arxiv.org/abs/2407.09475v1)|null|
|**2024-07-12**|**FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3**|Georgios Makridis et.al.|[2407.09467v1](http://arxiv.org/abs/2407.09467v1)|null|
|**2024-07-12**|**Weight Block Sparsity: Training, Compilation, and AI Engine Accelerators**|Paolo D'Alberto et.al.|[2407.09453v1](http://arxiv.org/abs/2407.09453v1)|null|
|**2024-07-12**|**Human-like Episodic Memory for Infinite Context LLMs**|Zafeirios Fountas et.al.|[2407.09450v1](http://arxiv.org/abs/2407.09450v1)|null|
|**2024-07-12**|**ASTPrompter: Weakly Supervised Automated Language Model Red-Teaming to Identify Likely Toxic Prompts**|Amelia F. Hardy et.al.|[2407.09447v1](http://arxiv.org/abs/2407.09447v1)|null|
|**2024-07-12**|**The $μ\mathcal{G}$ Language for Programming Graph Neural Networks**|Matteo Belenchia et.al.|[2407.09441v1](http://arxiv.org/abs/2407.09441v1)|null|
|**2024-07-12**|**Let Me DeCode You: Decoder Conditioning with Tabular Data**|Tomasz Szczepański et.al.|[2407.09437v1](http://arxiv.org/abs/2407.09437v1)|[link](https://github.com/sanoscience/decode)|
|**2024-07-12**|**MUSCLE: A Model Update Strategy for Compatible LLM Evolution**|Jessica Echterhoff et.al.|[2407.09435v1](http://arxiv.org/abs/2407.09435v1)|null|
|**2024-07-12**|**A Perspective on Foundation Models for the Electric Power Grid**|Hendrik F. Hamann et.al.|[2407.09434v1](http://arxiv.org/abs/2407.09434v1)|null|
|**2024-07-12**|**Open (Clinical) LLMs are Sensitive to Instruction Phrasings**|Alberto Mario Ceballos Arroyo et.al.|[2407.09429v1](http://arxiv.org/abs/2407.09429v1)|null|
|**2024-07-12**|**TelecomGPT: A Framework to Build Telecom-Specfic Large Language Models**|Hang Zou et.al.|[2407.09424v1](http://arxiv.org/abs/2407.09424v1)|null|
|**2024-07-12**|**Mitigating Entity-Level Hallucination in Large Language Models**|Weihang Su et.al.|[2407.09417v1](http://arxiv.org/abs/2407.09417v1)|[link](https://github.com/oneal2000/entityhallucination)|
|**2024-07-12**|**SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers**|Shraman Pramanick et.al.|[2407.09413v1](http://arxiv.org/abs/2407.09413v1)|[link](https://github.com/google/spiqa)|
|**2024-07-12**|**Deep Bag-of-Words Model: An Efficient and Interpretable Relevance Architecture for Chinese E-Commerce**|Zhe Lin et.al.|[2407.09395v1](http://arxiv.org/abs/2407.09395v1)|null|
|**2024-07-12**|**GAVEL: Generating Games Via Evolution and Language Models**|Graham Todd et.al.|[2407.09388v1](http://arxiv.org/abs/2407.09388v1)|null|
|**2024-07-12**|**Graph Neural Network Causal Explanation via Neural Causal Models**|Arman Behnam et.al.|[2407.09378v1](http://arxiv.org/abs/2407.09378v1)|[link](https://github.com/armanbehnam/cxgnn)|
|**2024-07-12**|**Towards Personalised Patient Risk Prediction Using Temporal Hospital Data Trajectories**|Thea Barnes et.al.|[2407.09373v1](http://arxiv.org/abs/2407.09373v1)|null|
|**2024-07-12**|**Is Contrasting All You Need? Contrastive Learning for the Detection and Attribution of AI-generated Text**|Lucio La Cava et.al.|[2407.09364v1](http://arxiv.org/abs/2407.09364v1)|null|
|**2024-07-12**|**FastImpute: A Baseline for Open-source, Reference-Free Genotype Imputation Methods -- A Case Study in PRS313**|Aaron Ge et.al.|[2407.09355v1](http://arxiv.org/abs/2407.09355v1)|[link](https://github.com/aaronge-2020/deepimpute)|
|**2024-07-12**|**Predictable and Performant Reactive Synthesis Modulo Theories via Functional Synthesis**|Andoni Rodríguez et.al.|[2407.09348v1](http://arxiv.org/abs/2407.09348v1)|null|
|**2024-07-12**|**CFaults: Model-Based Diagnosis for Fault Localization in C Programs with Multiple Test Cases**|Pedro Orvalho et.al.|[2407.09337v1](http://arxiv.org/abs/2407.09337v1)|[link](https://github.com/pmorvalho/cfaults)|
|**2024-07-12**|**Sina at FigNews 2024: Multilingual Datasets Annotated with Bias and Propaganda**|Lina Duaibes et.al.|[2407.09327v1](http://arxiv.org/abs/2407.09327v1)|null|
|**2024-07-12**|**Provable Privacy Advantages of Decentralized Federated Learning via Distributed Optimization**|Wenrui Yu et.al.|[2407.09324v1](http://arxiv.org/abs/2407.09324v1)|null|
|**2024-07-12**|**Scalability of Bayesian Network Structure Elicitation with Large Language Models: a Novel Methodology and Comparative Analysis**|Nikolay Babakov et.al.|[2407.09311v1](http://arxiv.org/abs/2407.09311v1)|null|
|**2024-07-12**|**Transformer Layers as Painters**|Qi Sun et.al.|[2407.09298v1](http://arxiv.org/abs/2407.09298v1)|null|
|**2024-07-12**|**Instruction Following with Goal-Conditioned Reinforcement Learning in Virtual Environments**|Zoya Volovikova et.al.|[2407.09287v1](http://arxiv.org/abs/2407.09287v1)|null|
|**2024-07-12**|**DAHRS: Divergence-Aware Hallucination-Remediated SRL Projection**|Sangpil Youm et.al.|[2407.09283v1](http://arxiv.org/abs/2407.09283v1)|null|
|**2024-07-12**|**Predicting and Understanding Human Action Decisions: Insights from Large Language Models and Cognitive Instance-Based Learning**|Thuy Ngoc Nguyen et.al.|[2407.09281v1](http://arxiv.org/abs/2407.09281v1)|null|
|**2024-07-12**|**H2O-Danube3 Technical Report**|Pascal Pfeiffer et.al.|[2407.09276v1](http://arxiv.org/abs/2407.09276v1)|null|
|**2024-07-12**|**Unifying Sequences, Structures, and Descriptions for Any-to-Any Protein Generation with the Large Multimodal Model HelixProtX**|Zhiyuan Chen et.al.|[2407.09274v1](http://arxiv.org/abs/2407.09274v1)|null|
|**2024-07-12**|**Context Embeddings for Efficient Answer Generation in RAG**|David Rau et.al.|[2407.09252v1](http://arxiv.org/abs/2407.09252v1)|null|
|**2024-07-12**|**Deep Adversarial Defense Against Multilevel-Lp Attacks**|Ren Wang et.al.|[2407.09251v1](http://arxiv.org/abs/2407.09251v1)|null|
|**2024-07-12**|**GNN with Model-based RL for Multi-agent Systems**|Hanxiao Chen et.al.|[2407.09249v1](http://arxiv.org/abs/2407.09249v1)|null|
|**2024-07-12**|**The Sociolinguistic Foundations of Language Modeling**|Jack Grieve et.al.|[2407.09241v1](http://arxiv.org/abs/2407.09241v1)|null|
|**2024-07-12**|**Generating SROI^{-} Ontologies via Knowledge Graph Query Embedding Learning**|Yunjie He et.al.|[2407.09212v1](http://arxiv.org/abs/2407.09212v1)|null|
|**2024-07-12**|**Pronunciation Assessment with Multi-modal Large Language Models**|Kaiqi Fu et.al.|[2407.09209v1](http://arxiv.org/abs/2407.09209v1)|null|
|**2024-07-12**|**From Easy to Hard: Learning Curricular Shape-aware Features for Robust Panoptic Scene Graph Generation**|Hanrong Shi et.al.|[2407.09191v1](http://arxiv.org/abs/2407.09191v1)|null|
|**2024-07-12**|**Enhancing Depressive Post Detection in Bangla: A Comparative Study of TF-IDF, BERT and FastText Embeddings**|Saad Ahmed Sazan et.al.|[2407.09187v1](http://arxiv.org/abs/2407.09187v1)|null|
|**2024-07-12**|**Variational Inference via Smoothed Particle Hydrodynamics**|Yongchao Huang et.al.|[2407.09186v1](http://arxiv.org/abs/2407.09186v1)|null|
|**2024-07-12**|**Does Incomplete Syntax Influence Korean Language Model? Focusing on Word Order and Case Markers**|Jong Myoung Kim et.al.|[2407.09184v1](http://arxiv.org/abs/2407.09184v1)|null|
|**2024-07-12**|**Exploring the Effectiveness of Methods for Persona Extraction**|Konstantin Zaitsev et.al.|[2407.09181v1](http://arxiv.org/abs/2407.09181v1)|null|
|**2024-07-12**|**DART: An Automated End-to-End Object Detection Pipeline with Data Diversification, Open-Vocabulary Bounding Box Annotation, Pseudo-Label Review, and Model Training**|Chen Xin et.al.|[2407.09174v1](http://arxiv.org/abs/2407.09174v1)|[link](https://github.com/chen-xin-94/dart)|
|**2024-07-12**|**Robust Yet Efficient Conformal Prediction Sets**|Soroush H. Zargarbashi et.al.|[2407.09165v1](http://arxiv.org/abs/2407.09165v1)|[link](https://github.com/soroushzargar/cas)|
|**2024-07-12**|**TAPI: Towards Target-Specific and Adversarial Prompt Injection against Code LLMs**|Yuchen Yang et.al.|[2407.09164v1](http://arxiv.org/abs/2407.09164v1)|null|
|**2024-07-12**|**Exploring State Space and Reasoning by Elimination in Tsetlin Machine**|Ahmed K. Kadhim et.al.|[2407.09162v1](http://arxiv.org/abs/2407.09162v1)|null|
|**2024-07-12**|**Movie Recommendation with Poster Attention via Multi-modal Transformer Feature Fusion**|Linhan Xia et.al.|[2407.09157v1](http://arxiv.org/abs/2407.09157v1)|null|
|**2024-07-12**|**The Two Sides of the Coin: Hallucination Generation and Detection with LLMs as Evaluators for LLMs**|Anh Thu Maria Bui et.al.|[2407.09152v1](http://arxiv.org/abs/2407.09152v1)|null|
|**2024-07-12**|**A Look Into News Avoidance Through AWRS: An Avoidance-Aware Recommender System**|Igor L. R. Azevedo et.al.|[2407.09137v1](http://arxiv.org/abs/2407.09137v1)|null|
|**2024-07-12**|**Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors**|Nico Daheim et.al.|[2407.09136v1](http://arxiv.org/abs/2407.09136v1)|[link](https://github.com/eth-lre/verify-then-generate)|
|**2024-07-12**|**Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training**|Youliang Yuan et.al.|[2407.09121v1](http://arxiv.org/abs/2407.09121v1)|[link](https://github.com/robustnlp/derta)|
|**2024-07-12**|**Inference Optimization of Foundation Models on AI Accelerators**|Youngsuk Park et.al.|[2407.09111v1](http://arxiv.org/abs/2407.09111v1)|null|
|**2024-07-12**|**Enhancing Training Efficiency Using Packing with Flash Attention**|Achintya Kundu et.al.|[2407.09105v1](http://arxiv.org/abs/2407.09105v1)|null|
|**2024-07-12**|**DANIEL: A fast Document Attention Network for Information Extraction and Labelling of handwritten documents**|Thomas Constum et.al.|[2407.09103v1](http://arxiv.org/abs/2407.09103v1)|[link](https://github.com/shulk97/daniel)|
|**2024-07-12**|**Music Proofreading with RefinPaint: Where and How to Modify Compositions given Context**|Pedro Ramoneda et.al.|[2407.09099v1](http://arxiv.org/abs/2407.09099v1)|[link](https://github.com/ta603/refinpaint)|
|**2024-07-12**|**STD-LLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with LLMs**|Yiheng Huang et.al.|[2407.09096v1](http://arxiv.org/abs/2407.09096v1)|null|
|**2024-07-12**|**On Exact Bit-level Reversible Transformers Without Changing Architectures**|Guoqiang Zhang et.al.|[2407.09093v1](http://arxiv.org/abs/2407.09093v1)|null|
|**2024-07-12**|**New Desiderata for Direct Preference Optimization**|Xiangkun Hu et.al.|[2407.09072v1](http://arxiv.org/abs/2407.09072v1)|null|
|**2024-07-12**|**From MIDI to Rich Tablatures: an Automatic Generative System incorporating Lead Guitarists' Fingering and Stylistic choices**|Pierluigi Bontempi et.al.|[2407.09052v1](http://arxiv.org/abs/2407.09052v1)|null|
|**2024-07-12**|**Refusing Safe Prompts for Multi-modal Large Language Models**|Zedian Shao et.al.|[2407.09050v1](http://arxiv.org/abs/2407.09050v1)|null|
|**2024-07-12**|**KUNPENG: An Embodied Large Model for Intelligent Maritime**|Naiyao Wang et.al.|[2407.09048v1](http://arxiv.org/abs/2407.09048v1)|[link](https://github.com/acotai/kunpeng)|
|**2024-07-12**|**Molecule Language Model with Augmented Pairs and Expertise Transfer**|Namkyeong Lee et.al.|[2407.09043v1](http://arxiv.org/abs/2407.09043v1)|[link](https://github.com/namkyeong/amole)|
|**2024-07-12**|**Overcoming Catastrophic Forgetting in Tabular Data Classification: A Pseudorehearsal-based approach**|Pablo García-Santaclara et.al.|[2407.09039v1](http://arxiv.org/abs/2407.09039v1)|null|
|**2024-07-12**|**SpreadsheetLLM: Encoding Spreadsheets for Large Language Models**|Yuzhang Tian et.al.|[2407.09025v1](http://arxiv.org/abs/2407.09025v1)|null|
|**2024-07-12**|**3M-Health: Multimodal Multi-Teacher Knowledge Distillation for Mental Health Detection**|Rina Carines Cabral et.al.|[2407.09020v1](http://arxiv.org/abs/2407.09020v1)|null|
|**2024-07-12**|**Heterogeneous Subgraph Network with Prompt Learning for Interpretable Depression Detection on Social Media**|Chen Chen et.al.|[2407.09019v1](http://arxiv.org/abs/2407.09019v1)|null|
|**2024-07-12**|**Static Analysis of Logic Programs via Boolean Networks**|Van-Giang Trinh et.al.|[2407.09015v1](http://arxiv.org/abs/2407.09015v1)|null|
|**2024-07-12**|**CompAct: Compressing Retrieved Documents Actively for Question Answering**|Chanwoong Yoon et.al.|[2407.09014v1](http://arxiv.org/abs/2407.09014v1)|null|
|**2024-07-12**|**Procedural Content Generation via Generative Artificial Intelligence**|Xinyu Mao et.al.|[2407.09013v1](http://arxiv.org/abs/2407.09013v1)|null|
|**2024-07-12**|**TCAN: Animating Human Images with Temporally Consistent Pose Guidance using Diffusion Models**|Jeongho Kim et.al.|[2407.09012v1](http://arxiv.org/abs/2407.09012v1)|null|
|**2024-07-12**|**One Stone, Four Birds: A Comprehensive Solution for QA System Using Supervised Contrastive Learning**|Bo Wang et.al.|[2407.09011v1](http://arxiv.org/abs/2407.09011v1)|null|
|**2024-07-12**|**Benchmarking Language Model Creativity: A Case Study on Code Generation**|Yining Lu et.al.|[2407.09007v1](http://arxiv.org/abs/2407.09007v1)|null|
|**2024-07-12**|**Introducing VaDA: Novel Image Segmentation Model for Maritime Object Segmentation Using New Dataset**|Yongjin Kim et.al.|[2407.09005v1](http://arxiv.org/abs/2407.09005v1)|null|
|**2024-07-12**|**Enhancing Few-Shot Stock Trend Prediction with Large Language Models**|Yiqi Deng et.al.|[2407.09003v1](http://arxiv.org/abs/2407.09003v1)|null|
|**2024-07-12**|**Self-Prompt Tuning: Enable Autonomous Role-Playing in LLMs**|Aobo Kong et.al.|[2407.08995v1](http://arxiv.org/abs/2407.08995v1)|null|
|**2024-07-12**|**Optimization of DNN-based speaker verification model through efficient quantization technique**|Yeona Hong et.al.|[2407.08991v1](http://arxiv.org/abs/2407.08991v1)|null|
|**2024-07-12**|**Dynamic neural network with memristive CIM and CAM for 2D and 3D vision**|Yue Zhang et.al.|[2407.08990v1](http://arxiv.org/abs/2407.08990v1)|null|
|**2024-07-12**|**Robustness of LLMs to Perturbations in Text**|Ayush Singh et.al.|[2407.08989v1](http://arxiv.org/abs/2407.08989v1)|null|
|**2024-07-12**|**Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**|David N. Palacio et.al.|[2407.08983v1](http://arxiv.org/abs/2407.08983v1)|null|
|**2024-07-12**|**Towards Chapter-to-Chapter Context-Aware Literary Translation via Large Language Models**|Linghao Jin et.al.|[2407.08978v1](http://arxiv.org/abs/2407.08978v1)|null|
|**2024-07-12**|**Soft Prompts Go Hard: Steering Visual Language Models with Hidden Meta-Instructions**|Tingwei Zhang et.al.|[2407.08970v1](http://arxiv.org/abs/2407.08970v1)|[link](https://github.com/tingwei-zhang/soft-prompts-go-hard)|
|**2024-07-12**|**Empowering Few-Shot Relation Extraction with The Integration of Traditional RE Methods and Large Language Models**|Ye Liu et.al.|[2407.08967v1](http://arxiv.org/abs/2407.08967v1)|[link](https://github.com/liuyeah/dsare)|
|**2024-07-12**|**LAPT: Label-driven Automated Prompt Tuning for OOD Detection with Vision-Language Models**|Yabin Zhang et.al.|[2407.08966v1](http://arxiv.org/abs/2407.08966v1)|[link](https://github.com/ybzh/lapt)|
|**2024-07-12**|**Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**|Ke Ji et.al.|[2407.08959v1](http://arxiv.org/abs/2407.08959v1)|null|
|**2024-07-12**|**Detect, Investigate, Judge and Determine: A Novel LLM-based Framework for Few-shot Fake News Detection**|Ye Liu et.al.|[2407.08952v1](http://arxiv.org/abs/2407.08952v1)|null|
|**2024-07-12**|**A Neural Matrix Decomposition Recommender System Model based on the Multimodal Large Language Model**|Ao Xiang et.al.|[2407.08942v1](http://arxiv.org/abs/2407.08942v1)|null|
|**2024-07-12**|**Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation**|Biqing Qi et.al.|[2407.08940v1](http://arxiv.org/abs/2407.08940v1)|null|
|**2024-07-12**|**Self-Evolving GPT: A Lifelong Autonomous Experiential Learner**|Jinglong Gao et.al.|[2407.08937v1](http://arxiv.org/abs/2407.08937v1)|null|
|**2024-07-12**|**Deep Attention Driven Reinforcement Learning (DAD-RL) for Autonomous Vehicle Decision-Making in Dynamic Environment**|Jayabrata Chowdhury et.al.|[2407.08932v1](http://arxiv.org/abs/2407.08932v1)|null|
|**2024-07-12**|**Are They the Same Picture? Adapting Concept Bottleneck Models for Human-AI Collaboration in Image Retrieval**|Vaibhav Balloli et.al.|[2407.08908v1](http://arxiv.org/abs/2407.08908v1)|[link](https://github.com/realize-lab/chair)|
|**2024-07-12**|**AirSketch: Generative Motion to Sketch**|Hui Xian Grace Lim et.al.|[2407.08906v1](http://arxiv.org/abs/2407.08906v1)|null|
|**2024-07-12**|**TensorTEE: Unifying Heterogeneous TEE Granularity for Efficient Secure Collaborative Tensor Computing**|Husheng Han et.al.|[2407.08903v1](http://arxiv.org/abs/2407.08903v1)|null|
|**2024-07-12**|**Application of Artificial Intelligence in Supporting Healthcare Professionals and Caregivers in Treatment of Autistic Children**|Hossein Mohammadi Rouzbahani et.al.|[2407.08902v1](http://arxiv.org/abs/2407.08902v1)|null|
|**2024-07-12**|**IDAT: A Multi-Modal Dataset and Toolkit for Building and Evaluating Interactive Task-Solving Agents**|Shrestha Mohanty et.al.|[2407.08898v1](http://arxiv.org/abs/2407.08898v1)|null|
|**2024-07-11**|**DeepCodeProbe: Towards Understanding What Models Trained on Code Learn**|Vahid Majdinasab et.al.|[2407.08890v1](http://arxiv.org/abs/2407.08890v1)|[link](https://github.com/commissarsilver/deepcodeprobe)|
|**2024-07-11**|**Automatic Pruning of Fine-tuning Datasets for Transformer-based Language Models**|Mohammadreza Tayaranian et.al.|[2407.08887v1](http://arxiv.org/abs/2407.08887v1)|[link](https://github.com/mthcom/hscore-dataset-pruning)|
|**2024-07-11**|**SALT: Introducing a Framework for Hierarchical Segmentations in Medical Imaging using Softmax for Arbitrary Label Trees**|Sven Koitka et.al.|[2407.08878v1](http://arxiv.org/abs/2407.08878v1)|null|
|**2024-07-11**|**A Hybrid Spiking-Convolutional Neural Network Approach for Advancing Machine Learning Models**|Sanaullah et.al.|[2407.08861v1](http://arxiv.org/abs/2407.08861v1)|null|
|**2024-07-11**|**GPT-4 is judged more human than humans in displaced and inverted Turing tests**|Ishika Rathi et.al.|[2407.08853v1](http://arxiv.org/abs/2407.08853v1)|null|
|**2024-07-11**|**UICrit: Enhancing Automated Design Evaluation with a UICritique Dataset**|Peitong Duan et.al.|[2407.08850v1](http://arxiv.org/abs/2407.08850v1)|null|
|**2024-07-11**|**Evaluating Nuanced Bias in Large Language Model Free Response Answers**|Jennifer Healey et.al.|[2407.08842v1](http://arxiv.org/abs/2407.08842v1)|null|

#### Abstracts
##### **Adaptive Prediction Ensemble: Improving Out-of-Distribution Generalization of Motion Forecasting**
2407.09475v1 by Jinning Li, Jiachen Li, Sangjae Bae, David Isele

Deep learning-based trajectory prediction models for autonomous driving often
struggle with generalization to out-of-distribution (OOD) scenarios, sometimes
performing worse than simple rule-based models. To address this limitation, we
propose a novel framework, Adaptive Prediction Ensemble (APE), which integrates
deep learning and rule-based prediction experts. A learned routing function,
trained concurrently with the deep learning model, dynamically selects the most
reliable prediction based on the input scenario. Our experiments on large-scale
datasets, including Waymo Open Motion Dataset (WOMD) and Argoverse, demonstrate
improvement in zero-shot generalization across datasets. We show that our
method outperforms individual prediction models and other variants,
particularly in long-horizon prediction and scenarios with a high proportion of
OOD data. This work highlights the potential of hybrid approaches for robust
and generalizable motion prediction in autonomous driving.

摘要：基於深度學習的自動駕駛軌跡預測模型通常難以概化到分佈外 (OOD) 場景，有時表現比基於簡單規則的模型還差。為了解決這個限制，我們提出了一個新的架構，自適應預測組合 (APE)，它整合了深度學習和基於規則的預測專家。一個與深度學習模型同時訓練的學習路由函數，根據輸入場景動態選擇最可靠的預測。我們在大型資料集上的實驗，包括 Waymo Open Motion Dataset (WOMD) 和 Argoverse，展示了跨資料集的零次學習概化改進。我們表明，我們的模型優於個別預測模型和其他變體，特別是在長時域預測和 OOD 資料比例高的場景中。這項工作突顯了混合方法在自動駕駛中用於穩健且可概化的運動預測的潛力。

##### **FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3**
2407.09467v1 by Georgios Makridis, Athanasios Oikonomou, Vasileios Koukos

In the diverse world of AI-driven storytelling, there is a unique opportunity
to engage young audiences with customized, and personalized narratives. This
paper introduces FairyLandAI an innovative Large Language Model (LLM) developed
through OpenAI's API, specifically crafted to create personalized fairytales
for children. The distinctive feature of FairyLandAI is its dual capability: it
not only generates stories that are engaging, age-appropriate, and reflective
of various traditions but also autonomously produces imaginative prompts
suitable for advanced image generation tools like GenAI and Dalle-3, thereby
enriching the storytelling experience. FairyLandAI is expertly tailored to
resonate with the imaginative worlds of children, providing narratives that are
both educational and entertaining and in alignment with the moral values
inherent in different ages. Its unique strength lies in customizing stories to
match individual children's preferences and cultural backgrounds, heralding a
new era in personalized storytelling. Further, its integration with image
generation technology offers a comprehensive narrative experience that
stimulates both verbal and visual creativity. Empirical evaluations of
FairyLandAI demonstrate its effectiveness in crafting captivating stories for
children, which not only entertain but also embody the values and teachings of
diverse traditions. This model serves as an invaluable tool for parents and
educators, supporting them in imparting meaningful moral lessons through
engaging narratives. FairyLandAI represents a pioneering step in using LLMs,
particularly through OpenAI's API, for educational and cultural enrichment,
making complex moral narratives accessible and enjoyable for young, imaginative
minds.

摘要：<paragraph>在 AI 驅動故事敘述的多元世界中，有一個獨特的機會可以讓年輕受眾參與客製化和個人化的敘事。這篇論文介紹了 FairyLandAI，這是一個創新的大型語言模型 (LLM)，透過 OpenAI 的 API 開發，專門用來為兒童創作個人化的童話故事。FairyLandAI 的獨特功能在於它的雙重能力：它不僅產生引人入勝、適合年齡且反映各種傳統的故事，還自主產生適合 GenAI 和 Dalle-3 等先進影像生成工具的想像力提示，從而豐富了故事敘述體驗。FairyLandAI 專門針對兒童的想像世界量身打造，提供既具有教育意義又娛樂性，且符合不同年齡內在道德價值觀的故事。它獨特的優勢在於客製化故事以符合個別兒童的喜好和文化背景，預示著個人化故事敘述的新時代。此外，它與影像生成技術的整合提供了一種全面的敘事體驗，激發了語言和視覺的創造力。FairyLandAI 的實證評估證明了它在為兒童創作引人入勝的故事方面的有效性，這些故事不僅娛樂性，還體現了各種傳統的價值觀和教義。這個模型作為父母和教育工作者的寶貴工具，支援他們透過引人入勝的敘事傳授有意義的道德課程。FairyLandAI 代表了使用 LLM 的先驅步驟，特別是透過 OpenAI 的 API，用於教育和文化豐富，讓複雜的道德敘事對年輕、富有想像力的頭腦來說既容易理解又令人愉快。</paragraph>

##### **Weight Block Sparsity: Training, Compilation, and AI Engine Accelerators**
2407.09453v1 by Paolo D'Alberto, Taehee Jeong, Akshai Jain, Shreyas Manjunath, Mrinal Sarmah, Samuel Hsu Yaswanth Raparti, Nitesh Pipralia

Nowadays, increasingly larger Deep Neural Networks (DNNs) are being
developed, trained, and utilized. These networks require significant
computational resources, putting a strain on both advanced and limited devices.
Our solution is to implement {\em weight block sparsity}, which is a structured
sparsity that is friendly to hardware. By zeroing certain sections of the
convolution and fully connected layers parameters of pre-trained DNN models, we
can efficiently speed up the DNN's inference process. This results in a smaller
memory footprint, faster communication, and fewer operations.
  Our work presents a vertical system that allows for the training of
convolution and matrix multiplication weights to exploit 8x8 block sparsity on
a single GPU within a reasonable amount of time. Compilers recognize this
sparsity and use it for both data compaction and computation splitting into
threads. Blocks like these take full advantage of both spatial and temporal
locality, paving the way for fast vector operations and memory reuse. By using
this system on a Resnet50 model, we were able to reduce the weight by half with
minimal accuracy loss, resulting in a two-times faster inference speed. We will
present performance estimates using accurate and complete code generation for
AIE2 configuration sets (AMD Versal FPGAs) with Resnet50, Inception V3, and
VGG16 to demonstrate the necessary synergy between hardware overlay designs and
software stacks for compiling and executing machine learning applications.

摘要：現今，越來越大型的深度神經網路（DNN）被開發、訓練和使用。這些網路需要大量的運算資源，對先進和受限的裝置都造成負擔。我們的解決方案是實作「權重區塊稀疏性」，這是一種對硬體友善的結構化稀疏性。透過將預先訓練好的 DNN 模型的卷積和全連接層參數的特定區塊歸零，我們可以有效地加速 DNN 的推論過程。這會產生較小的記憶體佔用空間、更快的通訊和較少的運算。我們的成果展示了一個垂直系統，允許在合理的時程內在單一 GPU 上訓練卷積和矩陣乘法權重，以利用 8x8 區塊稀疏性。編譯器會辨識此稀疏性，並將其用於資料壓縮和運算拆分為執行緒。像這樣的區塊充分利用空間和時間局部性，為快速的向量運算和記憶體重複使用鋪路。透過在 Resnet50 模型上使用此系統，我們能夠將權重減半，同時將準確度損失降到最低，進而將推論速度提升兩倍。我們將使用針對 Resnet50、Inception V3 和 VGG16 的 AIE2 組態集（AMD Versal FPGA）的準確且完整的程式碼產生，來提出效能估計，以展示硬體疊加設計與用於編譯和執行機器學習應用程式的軟體堆疊之間必要的協同效應。

##### **Human-like Episodic Memory for Infinite Context LLMs**
2407.09450v1 by Zafeirios Fountas, Martin A Benfeghoul, Adnan Oomerjee, Fenia Christopoulou, Gerasimos Lampouras, Haitham Bou-Ammar, Jun Wang

Large language models (LLMs) have shown remarkable capabilities, but still
struggle with processing extensive contexts, limiting their ability to maintain
coherence and accuracy over long sequences. In contrast, the human brain excels
at organising and retrieving episodic experiences across vast temporal scales,
spanning a lifetime. In this work, we introduce EM-LLM, a novel approach that
integrates key aspects of human episodic memory and event cognition into LLMs,
enabling them to effectively handle practically infinite context lengths while
maintaining computational efficiency. EM-LLM organises sequences of tokens into
coherent episodic events using a combination of Bayesian surprise and
graph-theoretic boundary refinement in an on-line fashion. When needed, these
events are retrieved through a two-stage memory process, combining
similarity-based and temporally contiguous retrieval for efficient and
human-like access to relevant information. Experiments on the LongBench dataset
demonstrate EM-LLM's superior performance, outperforming the state-of-the-art
InfLLM model with an overall relative improvement of 4.3% across various tasks,
including a 33% improvement on the PassageRetrieval task. Furthermore, our
analysis reveals strong correlations between EM-LLM's event segmentation and
human-perceived events, suggesting a bridge between this artificial system and
its biological counterpart. This work not only advances LLM capabilities in
processing extended contexts but also provides a computational framework for
exploring human memory mechanisms, opening new avenues for interdisciplinary
research in AI and cognitive science.

摘要：大型語言模型 (LLM) 已展現出非凡的能力，但仍難以處理廣泛的脈絡，這限制了它們在長序列中維持連貫性和準確性的能力。相較之下，人腦擅長在廣大的時間尺度上組織和提取情節體驗，跨越一生。在這項工作中，我們引入了 EM-LLM，這是一種新穎的方法，它將人類情節記憶和事件認知的關鍵面向整合到 LLM 中，讓它們能夠有效地處理實際上無限的脈絡長度，同時維持運算效率。EM-LLM 使用貝氏驚喜和圖論邊界精煉的組合，以線上方式將序列標記組織成連貫的情節事件。在需要時，這些事件會透過兩階段的記憶過程來提取，結合基於相似性和時間連續性的提取，以有效且類似人類的方式存取相關資訊。在 LongBench 資料集上的實驗證明了 EM-LLM 的卓越效能，在各種任務中優於最先進的 InfLLM 模型，在 PassageRetrieval 任務中改進了 33%。此外，我們的分析揭示了 EM-LLM 的事件分割與人類感知事件之間的強相關性，顯示了這個人工系統與其生物對應物之間的橋樑。這項工作不僅提升了 LLM 在處理延伸脈絡方面的能力，也提供了一個運算架構來探索人類記憶機制，為 AI 和認知科學的跨領域研究開啟了新的途徑。

##### **ASTPrompter: Weakly Supervised Automated Language Model Red-Teaming to Identify Likely Toxic Prompts**
2407.09447v1 by Amelia F. Hardy, Houjun Liu, Bernard Lange, Mykel J. Kochenderfer

Typical schemes for automated red-teaming large language models (LLMs) focus
on discovering prompts that trigger a frozen language model (the defender) to
generate toxic text. This often results in the prompting model (the adversary)
producing text that is unintelligible and unlikely to arise. Here, we propose a
reinforcement learning formulation of the LLM red-teaming task which allows us
to discover prompts that both (1) trigger toxic outputs from a frozen defender
and (2) have low perplexity as scored by the defender. We argue these cases are
most pertinent in a red-teaming setting because of their likelihood to arise
during normal use of the defender model. We solve this formulation through a
novel online and weakly supervised variant of Identity Preference Optimization
(IPO) on GPT-2 and GPT-2 XL defenders. We demonstrate that our policy is
capable of generating likely prompts that also trigger toxicity. Finally, we
qualitatively analyze learned strategies, trade-offs of likelihood and
toxicity, and discuss implications. Source code is available for this project
at: https://github.com/sisl/ASTPrompter/.

摘要：典型的自動紅隊大型語言模型 (LLM) 計畫專注於發現觸發凍結語言模型 (防禦者) 產生有毒文字的提示。這通常會導致提示模型 (對手) 產生難以理解且不太可能出現的文字。在此，我們提出 LLM 紅隊任務的強化學習公式，讓我們能夠發現同時 (1) 觸發凍結防禦者的有毒輸出，以及 (2) 由防禦者評分為困惑度低的提示。我們認為這些案例在紅隊設定中是最相關的，因為它們在防禦者模型的正常使用期間出現的可能性很高。我們透過 GPT-2 和 GPT-2 XL 防禦者上身分偏好最佳化 (IPO) 的新穎線上和弱監督變體來解決這個公式。我們證明我們的政策能夠產生可能觸發毒性的提示。最後，我們定性分析學習到的策略、可能性和毒性的權衡，並討論影響。此專案的原始碼可於以下網址取得：https://github.com/sisl/ASTPrompter/。

##### **The $μ\mathcal{G}$ Language for Programming Graph Neural Networks**
2407.09441v1 by Matteo Belenchia, Flavio Corradini, Michela Quadrini, Michele Loreti

Graph neural networks form a class of deep learning architectures
specifically designed to work with graph-structured data. As such, they share
the inherent limitations and problems of deep learning, especially regarding
the issues of explainability and trustworthiness. We propose $\mu\mathcal{G}$,
an original domain-specific language for the specification of graph neural
networks that aims to overcome these issues. The language's syntax is
introduced, and its meaning is rigorously defined by a denotational semantics.
An equivalent characterization in the form of an operational semantics is also
provided and, together with a type system, is used to prove the type soundness
of $\mu\mathcal{G}$. We show how $\mu\mathcal{G}$ programs can be represented
in a more user-friendly graphical visualization, and provide examples of its
generality by showing how it can be used to define some of the most popular
graph neural network models, or to develop any custom graph processing
application.

摘要：圖形神經網路形成一類深度學習架構，特別設計用於處理圖形結構化的資料。因此，它們具有深度學習固有的限制和問題，特別是在可解釋性和可信賴性問題上。我們提出 $\mu\mathcal{G}$，一種用於指定圖形神經網路的原創領域特定語言，旨在克服這些問題。引入了語言的語法，並透過指示語義嚴格定義其含義。還提供了運算語義形式的等效特徵描述，並與類型系統一起用於證明 $\mu\mathcal{G}$ 的類型健全性。我們展示了如何將 $\mu\mathcal{G}$ 程式表示為更友善的圖形視覺化，並透過展示如何使用它定義一些最流行的圖形神經網路模型或開發任何自訂圖形處理應用程式，來提供其通用性的範例。

##### **Let Me DeCode You: Decoder Conditioning with Tabular Data**
2407.09437v1 by Tomasz Szczepański, Michal K. Grzeszczyk, Szymon Płotka, Arleta Adamowicz, Piotr Fudalej, Przemysław Korzeniowski, Tomasz Trzciński, Arkadiusz Sitek

Training deep neural networks for 3D segmentation tasks can be challenging,
often requiring efficient and effective strategies to improve model
performance. In this study, we introduce a novel approach, DeCode, that
utilizes label-derived features for model conditioning to support the decoder
in the reconstruction process dynamically, aiming to enhance the efficiency of
the training process. DeCode focuses on improving 3D segmentation performance
through the incorporation of conditioning embedding with learned numerical
representation of 3D-label shape features. Specifically, we develop an
approach, where conditioning is applied during the training phase to guide the
network toward robust segmentation. When labels are not available during
inference, our model infers the necessary conditioning embedding directly from
the input data, thanks to a feed-forward network learned during the training
phase. This approach is tested using synthetic data and cone-beam computed
tomography (CBCT) images of teeth. For CBCT, three datasets are used: one
publicly available and two in-house. Our results show that DeCode significantly
outperforms traditional, unconditioned models in terms of generalization to
unseen data, achieving higher accuracy at a reduced computational cost. This
work represents the first of its kind to explore conditioning strategies in 3D
data segmentation, offering a novel and more efficient method for leveraging
annotated data. Our code, pre-trained models are publicly available at
https://github.com/SanoScience/DeCode .

摘要：訓練深度神經網路進行 3D 分割任務可能具有挑戰性，
通常需要有效且高效的策略來提升模型
效能。在本研究中，我們提出一個新穎的 DeCode 方法，它
利用標籤衍生的特徵進行模型調整，以動態支援解碼器
在重建過程中的功能，目標是提升訓練過程的效率。DeCode 專注於透過結合調整嵌入與學習到的 3D 標籤形狀特徵的數值表示，來提升 3D 分割效能。具體來說，我們開發一種方法，在訓練階段套用調整，以引導
網路朝向穩健的分割。當在推論期間沒有標籤時，我們的模型會直接從
輸入資料推論必要的調整嵌入，這要歸功於在訓練
階段學習到的前饋網路。這種方法使用合成資料和牙齒的錐狀束電腦斷層掃描 (CBCT) 影像進行測試。對於 CBCT，使用了三個資料集：一個公開的資料集和兩個內部資料集。我們的結果顯示，在未見過資料的概化方面，DeCode 明顯優於傳統的未調整模型，在降低運算成本的情況下達成更高的準確度。這項工作代表了探索 3D 資料分割中的調整策略的首例，提供一種新穎且更有效率的方法來利用標註資料。我們的程式碼和預先訓練的模型已公開在
https://github.com/SanoScience/DeCode。

##### **MUSCLE: A Model Update Strategy for Compatible LLM Evolution**
2407.09435v1 by Jessica Echterhoff, Fartash Faghri, Raviteja Vemulapalli, Ting-Yao Hu, Chun-Liang Li, Oncel Tuzel, Hadi Pouransari

Large Language Models (LLMs) are frequently updated due to data or
architecture changes to improve their performance. When updating models,
developers often focus on increasing overall performance metrics with less
emphasis on being compatible with previous model versions. However, users often
build a mental model of the functionality and capabilities of a particular
machine learning model they are interacting with. They have to adapt their
mental model with every update -- a draining task that can lead to user
dissatisfaction. In practice, fine-tuned downstream task adapters rely on
pretrained LLM base models. When these base models are updated, these
user-facing downstream task models experience instance regression or negative
flips -- previously correct instances are now predicted incorrectly. This
happens even when the downstream task training procedures remain identical. Our
work aims to provide seamless model updates to a user in two ways. First, we
provide evaluation metrics for a notion of compatibility to prior model
versions, specifically for generative tasks but also applicable for
discriminative tasks. We observe regression and inconsistencies between
different model versions on a diverse set of tasks and model updates. Second,
we propose a training strategy to minimize the number of inconsistencies in
model updates, involving training of a compatibility model that can enhance
task fine-tuned language models. We reduce negative flips -- instances where a
prior model version was correct, but a new model incorrect -- by up to 40% from
Llama 1 to Llama 2.

摘要：大型語言模型 (LLM) 由於資料或架構變更而頻繁更新，以提升其效能。在更新模型時，開發人員通常專注於提升整體效能指標，較少注重與先前模型版本的相容性。然而，使用者通常會建立他們互動的特定機器學習模型的功能和能力心智模型。他們必須在每次更新時調整其心智模型，這是一項耗費心力的任務，可能導致使用者不滿意。在實務上，微調的下游任務適配器依賴於預訓練的 LLM 基礎模型。當這些基礎模型更新時，這些面向使用者的下游任務模型會出現實例回歸或負面翻轉，即先前正確的實例現在預測不正確。即使下游任務訓練程序保持不變，也會發生這種情況。我們的研究旨在透過兩種方式為使用者提供無縫的模型更新。首先，我們提供相容性概念的評估指標，以用於先前的模型版本，特別是生成式任務，但也適用於判別式任務。我們觀察到在各種任務和模型更新中，不同模型版本之間的回歸和不一致。其次，我們提出一個訓練策略，以最小化模型更新中的不一致性，包括訓練一個相容性模型，該模型可以增強任務微調的語言模型。我們將負面翻轉（即先前模型版本正確，但新模型不正確的實例）減少了多達 40%，從 Llama 1 到 Llama 2。

##### **A Perspective on Foundation Models for the Electric Power Grid**
2407.09434v1 by Hendrik F. Hamann, Thomas Brunschwiler, Blazhe Gjorgiev, Leonardo S. A. Martins, Alban Puech, Anna Varbella, Jonas Weiss, Juan Bernabe-Moreno, Alexandre Blondin Massé, Seong Choi, Ian Foster, Bri-Mathias Hodge, Rishabh Jain, Kibaek Kim, Vincent Mai, François Mirallès, Martin De Montigny, Octavio Ramos-Leaños, Hussein Suprême, Le Xie, El-Nasser S. Youssef, Arnaud Zinflou, Alexander J. Belvi, Ricardo J. Bessa, Bishnu Prasad Bhattari, Johannes Schmude, Stanislav Sobolevsky

Foundation models (FMs) currently dominate news headlines. They employ
advanced deep learning architectures to extract structural information
autonomously from vast datasets through self-supervision. The resulting rich
representations of complex systems and dynamics can be applied to many
downstream applications. Therefore, FMs can find uses in electric power grids,
challenged by the energy transition and climate change. In this paper, we call
for the development of, and state why we believe in, the potential of FMs for
electric grids. We highlight their strengths and weaknesses amidst the
challenges of a changing grid. We argue that an FM learning from diverse grid
data and topologies could unlock transformative capabilities, pioneering a new
approach in leveraging AI to redefine how we manage complexity and uncertainty
in the electric grid. Finally, we discuss a power grid FM concept, namely
GridFM, based on graph neural networks and show how different downstream tasks
benefit.

摘要：基礎模型 (FM) 目前主宰新聞標題。它們採用先進的深度學習架構，透過自我監督從龐大的資料集自主提取結構化資訊。複雜系統和動態的豐富表徵可用於許多下游應用。因此，FM 可以用於電力電網，受到能源轉型和氣候變遷的挑戰。在本文中，我們呼籲開發 FM，並說明我們相信 FM 在電網中的潛力。我們強調它們在變動電網的挑戰中的優勢和劣勢。我們認為，從多樣化電網資料和拓撲中學習的 FM 可以釋放轉型能力，開創利用 AI 重新定義我們如何管理電網中的複雜性和不確定性的新方法。最後，我們討論一個電網 FM 概念，即 GridFM，它基於圖神經網路，並展示不同的下游任務如何受益。

##### **Open (Clinical) LLMs are Sensitive to Instruction Phrasings**
2407.09429v1 by Alberto Mario Ceballos Arroyo, Monica Munnangi, Jiuding Sun, Karen Y. C. Zhang, Denis Jered McInerney, Byron C. Wallace, Silvio Amir

Instruction-tuned Large Language Models (LLMs) can perform a wide range of
tasks given natural language instructions to do so, but they are sensitive to
how such instructions are phrased. This issue is especially concerning in
healthcare, as clinicians are unlikely to be experienced prompt engineers and
the potential consequences of inaccurate outputs are heightened in this domain.
  This raises a practical question: How robust are instruction-tuned LLMs to
natural variations in the instructions provided for clinical NLP tasks? We
collect prompts from medical doctors across a range of tasks and quantify the
sensitivity of seven LLMs -- some general, others specialized -- to natural
(i.e., non-adversarial) instruction phrasings. We find that performance varies
substantially across all models, and that -- perhaps surprisingly --
domain-specific models explicitly trained on clinical data are especially
brittle, compared to their general domain counterparts. Further, arbitrary
phrasing differences can affect fairness, e.g., valid but distinct instructions
for mortality prediction yield a range both in overall performance, and in
terms of differences between demographic groups.

摘要：指令調整的大語言模型 (LLM) 能執行各種任務，只要給予自然語言指令即可，但它們會受到指令表述方式的影響。此問題在醫療保健領域特別令人擔憂，因為臨床醫生不太可能是經驗豐富的提示工程師，而且在此領域中不準確輸出的潛在後果會加劇。這引發了一個實際問題：指令調整的 LLM 對臨床 NLP 任務所提供的指令中的自然變化有多強健？我們從醫學博士中收集各種任務的提示，並量化七個 LLM（一些是通用的，其他則是專門的）對自然（即非對抗性的）指令措辭的敏感性。我們發現，所有模型的性能差異很大，而且——也許令人驚訝的是——針對臨床數據進行過明確訓練的特定領域模型特別脆弱，與其一般領域的對應模型相比。此外，任意的措辭差異可能會影響公平性，例如，死亡率預測的有效但不同的指令會產生整體性能和人口群組之間差異的範圍。

##### **TelecomGPT: A Framework to Build Telecom-Specfic Large Language Models**
2407.09424v1 by Hang Zou, Qiyang Zhao, Yu Tian, Lina Bariah, Faouzi Bader, Thierry Lestable, Merouane Debbah

Large Language Models (LLMs) have the potential to revolutionize the Sixth
Generation (6G) communication networks. However, current mainstream LLMs
generally lack the specialized knowledge in telecom domain. In this paper, for
the first time, we propose a pipeline to adapt any general purpose LLMs to a
telecom-specific LLMs. We collect and build telecom-specific pre-train dataset,
instruction dataset, preference dataset to perform continual pre-training,
instruct tuning and alignment tuning respectively. Besides, due to the lack of
widely accepted evaluation benchmarks in telecom domain, we extend existing
evaluation benchmarks and proposed three new benchmarks, namely, Telecom Math
Modeling, Telecom Open QnA and Telecom Code Tasks. These new benchmarks provide
a holistic evaluation of the capabilities of LLMs including math modeling,
Open-Ended question answering, code generation, infilling, summarization and
analysis in telecom domain. Our fine-tuned LLM TelecomGPT outperforms state of
the art (SOTA) LLMs including GPT-4, Llama-3 and Mistral in Telecom Math
Modeling benchmark significantly and achieve comparable performance in various
evaluation benchmarks such as TeleQnA, 3GPP technical documents classification,
telecom code summary and generation and infilling.

摘要：大型語言模型 (LLM) 有可能革新第六代 (6G) 通訊網路。然而，目前主流的 LLM 通常缺乏電信領域的專業知識。在本文中，我們首次提出一個管道，以將任何通用 LLM 適應到電信專用 LLM。我們收集並建立電信專用預訓練資料集、指令資料集、偏好資料集，分別執行持續預訓練、指令微調和對齊微調。此外，由於缺乏廣泛接受的電信領域評估基準，我們擴充現有的評估基準，並提出三個新的基準，即電信數學建模、電信開放問答和電信程式碼任務。這些新基準提供對 LLM 能力的整體評估，包括電信領域的數學建模、開放式問題解答、程式碼生成、填空、摘要和分析。我們微調後的 LLM TelecomGPT 在電信數學建模基準上顯著優於最先進 (SOTA) 的 LLM，包括 GPT-4、Llama-3 和 Mistral，並在各種評估基準（例如 TeleQnA、3GPP 技術文件分類、電信程式碼摘要和生成，以及填空）中達到相當的效能。

##### **Mitigating Entity-Level Hallucination in Large Language Models**
2407.09417v1 by Weihang Su, Yichen Tang, Qingyao Ai, Changyue Wang, Zhijing Wu, Yiqun Liu

The emergence of Large Language Models (LLMs) has revolutionized how users
access information, shifting from traditional search engines to direct
question-and-answer interactions with LLMs. However, the widespread adoption of
LLMs has revealed a significant challenge known as hallucination, wherein LLMs
generate coherent yet factually inaccurate responses. This hallucination
phenomenon has led to users' distrust in information retrieval systems based on
LLMs. To tackle this challenge, this paper proposes Dynamic Retrieval
Augmentation based on hallucination Detection (DRAD) as a novel method to
detect and mitigate hallucinations in LLMs. DRAD improves upon traditional
retrieval augmentation by dynamically adapting the retrieval process based on
real-time hallucination detection. It features two main components: Real-time
Hallucination Detection (RHD) for identifying potential hallucinations without
external models, and Self-correction based on External Knowledge (SEK) for
correcting these errors using external knowledge. Experiment results show that
DRAD demonstrates superior performance in both detecting and mitigating
hallucinations in LLMs. All of our code and data are open-sourced at
https://github.com/oneal2000/EntityHallucination.

摘要：大型語言模型 (LLM) 的出現徹底改變了使用者存取資訊的方式，從傳統的搜尋引擎轉變為與 LLM 直接進行問答互動。然而，LLM 的廣泛採用揭露了一個重大的挑戰，稱為幻覺，其中 LLM 會產生連貫但事實上不正確的回應。這種幻覺現象導致使用者不信任基於 LLM 的資訊檢索系統。為了應對這個挑戰，本文提出基於幻覺偵測的動態檢索擴充 (DRAD)，作為一種偵測和減輕 LLM 中幻覺的新方法。DRAD 透過根據即時幻覺偵測動態調整檢索程序，來改進傳統的檢索擴充。它具有兩個主要組成部分：無需外部模型即可識別潛在幻覺的即時幻覺偵測 (RHD)，以及使用外部知識進行自我修正 (SEK) 以利用外部知識來修正這些錯誤。實驗結果顯示，DRAD 在偵測和減輕 LLM 中的幻覺方面都展現出優異的效能。我們所有的程式碼和資料都開放原始碼，網址為 https://github.com/oneal2000/EntityHallucination。

##### **SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers**
2407.09413v1 by Shraman Pramanick, Rama Chellappa, Subhashini Venugopalan

Seeking answers to questions within long scientific research articles is a
crucial area of study that aids readers in quickly addressing their inquiries.
However, existing question-answering (QA) datasets based on scientific papers
are limited in scale and focus solely on textual content. To address this
limitation, we introduce SPIQA (Scientific Paper Image Question Answering), the
first large-scale QA dataset specifically designed to interpret complex figures
and tables within the context of scientific research articles across various
domains of computer science. Leveraging the breadth of expertise and ability of
multimodal large language models (MLLMs) to understand figures, we employ
automatic and manual curation to create the dataset. We craft an
information-seeking task involving multiple images that cover a wide variety of
plots, charts, tables, schematic diagrams, and result visualizations. SPIQA
comprises 270K questions divided into training, validation, and three different
evaluation splits. Through extensive experiments with 12 prominent foundational
models, we evaluate the ability of current multimodal systems to comprehend the
nuanced aspects of research articles. Additionally, we propose a
Chain-of-Thought (CoT) evaluation strategy with in-context retrieval that
allows fine-grained, step-by-step assessment and improves model performance. We
further explore the upper bounds of performance enhancement with additional
textual information, highlighting its promising potential for future research
and the dataset's impact on revolutionizing how we interact with scientific
literature.

摘要：尋找科學研究長文中的問題解答是一個重要的研究領域，它可以幫助讀者快速解決他們的疑問。然而，現有的基於科學論文的问答（QA）數據集規模有限，而且僅關注文本內容。為了解決這個限制，我們引入了 SPIQA（科學論文圖像問答），這是第一個專門設計用於解釋科學研究文章中各種電腦科學領域的複雜圖表和表格的大規模問答數據集。我們利用多模態大型語言模型（MLLM）理解圖形的廣泛專業知識和能力，採用自動和手動整理來創建數據集。我們設計了一項涉及多個圖像的信息尋求任務，這些圖像涵蓋了各種圖形、圖表、表格、示意圖和結果可視化。SPIQA 包含 270K 個問題，分為訓練、驗證和三個不同的評估區塊。通過使用 12 個著名的基礎模型進行廣泛的實驗，我們評估了當前多模態系統理解研究文章細微方面的能力。此外，我們提出了一個帶有上下文檢索的思維鏈（CoT）評估策略，它允許進行細粒度、逐步評估並提高模型性能。我們進一步探索了通過額外文本信息提高性能的最高界限，強調了其對未來研究的有希望的潛力，以及該數據集對我們與科學文獻互動方式的革命性影響。

##### **Deep Bag-of-Words Model: An Efficient and Interpretable Relevance Architecture for Chinese E-Commerce**
2407.09395v1 by Zhe Lin, Jiwei Tan, Dan Ou, Xi Chen, Shaowei Yao, Bo Zheng

Text relevance or text matching of query and product is an essential
technique for the e-commerce search system to ensure that the displayed
products can match the intent of the query. Many studies focus on improving the
performance of the relevance model in search system. Recently, pre-trained
language models like BERT have achieved promising performance on the text
relevance task. While these models perform well on the offline test dataset,
there are still obstacles to deploy the pre-trained language model to the
online system as their high latency. The two-tower model is extensively
employed in industrial scenarios, owing to its ability to harmonize performance
with computational efficiency. Regrettably, such models present an opaque
``black box'' nature, which prevents developers from making special
optimizations. In this paper, we raise deep Bag-of-Words (DeepBoW) model, an
efficient and interpretable relevance architecture for Chinese e-commerce. Our
approach proposes to encode the query and the product into the sparse BoW
representation, which is a set of word-weight pairs. The weight means the
important or the relevant score between the corresponding word and the raw
text. The relevance score is measured by the accumulation of the matched word
between the sparse BoW representation of the query and the product. Compared to
popular dense distributed representation that usually suffers from the drawback
of black-box, the most advantage of the proposed representation model is highly
explainable and interventionable, which is a superior advantage to the
deployment and operation of online search engines. Moreover, the online
efficiency of the proposed model is even better than the most efficient inner
product form of dense representation ...

摘要：文字相關性或查詢與產品的文字配對是電子商務搜尋系統中的一項重要技術，用以確保顯示的產品能符合查詢的意圖。許多研究專注於提升搜尋系統中相關性模型的效能。最近，BERT 等預先訓練的語言模型已在文字相關性任務中取得亮眼的表現。儘管這些模型在離線測試資料集中的表現良好，但將預先訓練的語言模型部署至線上系統仍有障礙，因為它們的延遲很高。雙塔模型廣泛用於產業場景，因為它能調和效能與運算效率。遺憾的是，此類模型呈現不透明的「黑盒子」性質，這會阻礙開發人員進行特殊最佳化。在本文中，我們提出深度詞袋（DeepBoW）模型，這是一種針對中文電子商務的高效且可解釋相關性架構。我們的做法建議將查詢和產品編碼成稀疏詞袋（BoW）表示，這是一組字詞權重對。權重表示對應字詞與原始文字之間的重要程度或相關分數。相關分數是透過累積查詢和產品的稀疏詞袋表示之間的配對字詞來衡量。與通常會受到黑盒子缺點影響的熱門稠密分散表示相比，所提出的表示模型最大的優點是高度可解釋且可介入，這對於線上搜尋引擎的部署和操作而言是一個優勢。此外，所提出的模型的線上效率甚至比稠密表示中最有效率的內積形式還要好。

##### **GAVEL: Generating Games Via Evolution and Language Models**
2407.09388v1 by Graham Todd, Alexander Padula, Matthew Stephenson, Éric Piette, Dennis J. N. J. Soemers, Julian Togelius

Automatically generating novel and interesting games is a complex task.
Challenges include representing game rules in a computationally workable form,
searching through the large space of potential games under most such
representations, and accurately evaluating the originality and quality of
previously unseen games. Prior work in automated game generation has largely
focused on relatively restricted rule representations and relied on
domain-specific heuristics. In this work, we explore the generation of novel
games in the comparatively expansive Ludii game description language, which
encodes the rules of over 1000 board games in a variety of styles and modes of
play. We draw inspiration from recent advances in large language models and
evolutionary computation in order to train a model that intelligently mutates
and recombines games and mechanics expressed as code. We demonstrate both
quantitatively and qualitatively that our approach is capable of generating new
and interesting games, including in regions of the potential rules space not
covered by existing games in the Ludii dataset. A sample of the generated games
are available to play online through the Ludii portal.

摘要：自動產生新穎有趣的遊戲是一項複雜的任務。
挑戰包括以計算可行的形式表示遊戲規則，
在大多數此類表示下搜尋潛在遊戲的廣闊空間，以及準確評估前所未見遊戲的原創性和品質。
自動化遊戲生成中的先前工作在很大程度上集中在相對受限的規則表示上，並依賴於特定領域的啟發法。
在這項工作中，我們探索了在比較廣泛的 Ludii 遊戲描述語言中生成新穎遊戲，
它以各種風格和遊戲模式編碼了 1000 多個棋盤遊戲的規則。
我們從大型語言模型和演化計算的最新進展中汲取靈感，以訓練一個模型，
它可以智能地變異和重組表示為代碼的遊戲和機制。
我們定量和定性地證明了我們的做法能夠產生新的有趣遊戲，包括 Ludii 資料集中現有遊戲未涵蓋的潛在規則空間區域。
一些已生成的遊戲範例可透過 Ludii 入口網站線上遊玩。

##### **Graph Neural Network Causal Explanation via Neural Causal Models**
2407.09378v1 by Arman Behnam, Binghui Wang

Graph neural network (GNN) explainers identify the important subgraph that
ensures the prediction for a given graph. Until now, almost all GNN explainers
are based on association, which is prone to spurious correlations. We propose
{\name}, a GNN causal explainer via causal inference. Our explainer is based on
the observation that a graph often consists of a causal underlying subgraph.
{\name} includes three main steps: 1) It builds causal structure and the
corresponding structural causal model (SCM) for a graph, which enables the
cause-effect calculation among nodes. 2) Directly calculating the cause-effect
in real-world graphs is computationally challenging. It is then enlightened by
the recent neural causal model (NCM), a special type of SCM that is trainable,
and design customized NCMs for GNNs. By training these GNN NCMs, the
cause-effect can be easily calculated. 3) It uncovers the subgraph that
causally explains the GNN predictions via the optimized GNN-NCMs. Evaluation
results on multiple synthetic and real-world graphs validate that {\name}
significantly outperforms existing GNN explainers in exact groundtruth
explanation identification

摘要：圖形神經網路（GNN）解釋器會找出重要的子圖，以確保對特定圖形的預測。迄今為止，幾乎所有的 GNN 解釋器都是基於關聯性，這容易產生虛假的關聯。我們提出 {\name}，一種透過因果推論的 GNN 因果解釋器。我們的解釋器基於這樣的觀察：一個圖形通常包含一個因果基礎子圖。{\name} 包含三個主要步驟：1) 它為圖形建立因果結構和對應的結構因果模型 (SCM)，這能計算節點之間的因果關係。2) 直接計算真實世界圖形中的因果關係在運算上具有挑戰性。它隨後受到近期可訓練的神經因果模型 (NCM) 的啟發，NCM 是一種特殊類型的 SCM，並為 GNN 設計自訂的 NCM。透過訓練這些 GNN NCM，可以輕鬆計算因果關係。3) 它透過最佳化的 GNN-NCM 揭示因果解釋 GNN 預測的子圖。在多個合成和真實世界圖形上的評估結果驗證了 {\name} 在準確的真實解釋識別上顯著優於現有的 GNN 解釋器

##### **Towards Personalised Patient Risk Prediction Using Temporal Hospital Data Trajectories**
2407.09373v1 by Thea Barnes, Enrico Werner, Jeffrey N. Clark, Raul Santos-Rodriguez

Quantifying a patient's health status provides clinicians with insight into
patient risk, and the ability to better triage and manage resources. Early
Warning Scores (EWS) are widely deployed to measure overall health status, and
risk of adverse outcomes, in hospital patients. However, current EWS are
limited both by their lack of personalisation and use of static observations.
We propose a pipeline that groups intensive care unit patients by the
trajectories of observations data throughout their stay as a basis for the
development of personalised risk predictions. Feature importance is considered
to provide model explainability. Using the MIMIC-IV dataset, six clusters were
identified, capturing differences in disease codes, observations, lengths of
admissions and outcomes. Applying the pipeline to data from just the first four
hours of each ICU stay assigns the majority of patients to the same cluster as
when the entire stay duration is considered. In-hospital mortality prediction
models trained on individual clusters had higher F1 score performance in five
of the six clusters when compared against the unclustered patient cohort. The
pipeline could form the basis of a clinical decision support tool, working to
improve the clinical characterisation of risk groups and the early detection of
patient deterioration.

摘要：量化患者的健康状况可让临床医生深入了解患者风险，并能更好地对资源进行分类和管理。早期预警评分 (EWS) 被广泛用于衡量整体健康状况和住院患者的不良后果风险。然而，当前的 EWS 受限于其缺乏个性化和使用静态观察。我们提出了一个管道，该管道根据患者在整个住院期间的观察数据轨迹对重症监护病房患者进行分组，作为制定个性化风险预测的基础。特征重要性被考虑为提供模型可解释性。使用 MIMIC-IV 数据集，识别出六个集群，捕捉疾病代码、观察、入院时间和结果的差异。将管道应用于每个 ICU 住院的前四个小时的数据时，将大多数患者分配到与考虑整个住院时间时相同的集群。在五个集群中，针对各个集群训练的院内死亡率预测模型与未分组患者队列相比具有更高的 F1 分数表现。该管道可以形成临床决策支持工具的基础，用于改善风险组的临床表征和患者恶化的早期检测。

##### **Is Contrasting All You Need? Contrastive Learning for the Detection and Attribution of AI-generated Text**
2407.09364v1 by Lucio La Cava, Davide Costa, Andrea Tagarelli

The significant progress in the development of Large Language Models has
contributed to blurring the distinction between human and AI-generated text.
The increasing pervasiveness of AI-generated text and the difficulty in
detecting it poses new challenges for our society. In this paper, we tackle the
problem of detecting and attributing AI-generated text by proposing WhosAI, a
triplet-network contrastive learning framework designed to predict whether a
given input text has been generated by humans or AI and to unveil the
authorship of the text. Unlike most existing approaches, our proposed framework
is conceived to learn semantic similarity representations from multiple
generators at once, thus equally handling both detection and attribution tasks.
Furthermore, WhosAI is model-agnostic and scalable to the release of new AI
text-generation models by incorporating their generated instances into the
embedding space learned by our framework. Experimental results on the
TuringBench benchmark of 200K news articles show that our proposed framework
achieves outstanding results in both the Turing Test and Authorship Attribution
tasks, outperforming all the methods listed in the TuringBench benchmark
leaderboards.

摘要：大型語言模型的發展取得顯著進展，模糊了人類和 AI 生成的文字之間的區別。AI 生成的文字越來越普遍，且難以偵測，對我們的社會構成新的挑戰。在本文中，我們解決偵測和歸因 AI 生成的文字的問題，提出 WhosAI，一個三元網路對比學習架構，旨在預測給定的輸入文字是由人類還是 AI 生成的，並揭示文字的作者。與大多數現有方法不同，我們提出的架構被構想為一次從多個生成器學習語義相似性表示，從而平等地處理偵測和歸因任務。此外，WhosAI 與模型無關，並且可以擴展到新的 AI 文字生成模型的發布，方法是將它們生成的實例納入我們架構學習的嵌入空間。在 TuringBench 對 20 萬篇新聞文章的基準測試中，實驗結果表明，我們提出的架構在 Turing 測試和作者歸因任務中都取得了傑出的結果，優於 TuringBench 基準排行榜中列出的所有方法。

##### **FastImpute: A Baseline for Open-source, Reference-Free Genotype Imputation Methods -- A Case Study in PRS313**
2407.09355v1 by Aaron Ge, Jeya Balasubramanian, Xueyao Wu, Peter Kraft, Jonas S. Almeida

Genotype imputation enhances genetic data by predicting missing SNPs using
reference haplotype information. Traditional methods leverage linkage
disequilibrium (LD) to infer untyped SNP genotypes, relying on the similarity
of LD structures between genotyped target sets and fully sequenced reference
panels. Recently, reference-free deep learning-based methods have emerged,
offering a promising alternative by predicting missing genotypes without
external databases, thereby enhancing privacy and accessibility. However, these
methods often produce models with tens of millions of parameters, leading to
challenges such as the need for substantial computational resources to train
and inefficiency for client-sided deployment. Our study addresses these
limitations by introducing a baseline for a novel genotype imputation pipeline
that supports client-sided imputation models generalizable across any
genotyping chip and genomic region. This approach enhances patient privacy by
performing imputation directly on edge devices. As a case study, we focus on
PRS313, a polygenic risk score comprising 313 SNPs used for breast cancer risk
prediction. Utilizing consumer genetic panels such as 23andMe, our model
democratizes access to personalized genetic insights by allowing 23andMe users
to obtain their PRS313 score. We demonstrate that simple linear regression can
significantly improve the accuracy of PRS313 scores when calculated using SNPs
imputed from consumer gene panels, such as 23andMe. Our linear regression model
achieved an R^2 of 0.86, compared to 0.33 without imputation and 0.28 with
simple imputation (substituting missing SNPs with the minor allele frequency).
These findings suggest that popular SNP analysis libraries could benefit from
integrating linear regression models for genotype imputation, providing a
viable and light-weight alternative to reference based imputation.

摘要：基因型推算透過使用參考單倍型資訊來預測遺失的 SNP，進而增強遺傳資料。傳統方法利用連鎖不平衡 (LD) 來推論未分型的 SNP 基因型，依賴於基因分型目標組與完全定序參考面板之間的 LD 結構相似性。最近，無參考深度學習方法應運而生，提供了一個有前途的替代方案，可以在沒有外部資料庫的情況下預測遺失的基因型，從而增強隱私和可及性。然而，這些方法通常會產生具有數千萬個參數的模型，導致諸如需要大量的運算資源進行訓練和客戶端部署效率低下的挑戰。我們的研究透過引入一個新穎基因型推算管線的基準來解決這些限制，該管線支援在任何基因分型晶片和基因組區域中可概化的客戶端推算模型。此方法透過直接在邊緣裝置上執行推算來增強患者隱私。作為案例研究，我們專注於 PRS313，一種由 313 個 SNP 組成的多基因風險評分，用於乳癌風險預測。我們的模型利用 23andMe 等消費者基因面板，透過允許 23andMe 使用者取得他們的 PRS313 評分，民主化地取得個人化基因見解。我們證明，在使用從消費者基因面板（例如 23andMe）推算的 SNP 計算 PRS313 評分時，簡單的線性回歸可以顯著提高準確性。我們的線性回歸模型達到 R^2 為 0.86，而未推算為 0.33，使用簡單推算（用次要等位基因頻率取代遺失的 SNP）為 0.28。這些發現表明，熱門的 SNP 分析程式庫可以從整合線性回歸模型以進行基因型推算中受益，提供一個可行的且輕量化的替代方案，以取代基於參考的推算。

##### **Predictable and Performant Reactive Synthesis Modulo Theories via Functional Synthesis**
2407.09348v1 by Andoni Rodríguez, Felipe Gorostiaga, César Sánchez

Reactive synthesis is the process of generating correct controllers from
temporal logic specifications. Classical LTL reactive synthesis handles
(propositional) LTL as a specification language. Boolean abstractions allow
reducing LTLt specifications (i.e., LTL with propositions replaced by literals
from a theory calT), into equi-realizable LTL specifications. In this paper we
extend these results into a full static synthesis procedure. The synthesized
system receives from the environment valuations of variables from a rich theory
calT and outputs valuations of system variables from calT. We use the
abstraction method to synthesize a reactive Boolean controller from the LTL
specification, and we combine it with functional synthesis to obtain a static
controller for the original LTLt specification. We also show that our method
allows responses in the sense that the controller can optimize its outputs in
order to e.g., always provide the smallest safe values. This is the first full
static synthesis method for LTLt, which is a deterministic program (hence
predictable and efficient).

摘要：反應式綜合是從時序邏輯規格產生正確控制器的一個過程。古典 LTL 反應式綜合將 (命題) LTL 當作規格語言。布林抽象允許將 LTLt 規格 (即，以來自理論 calT 的字面量取代命題的 LTL) 簡化為等可實現的 LTL 規格。在本文中，我們將這些結果擴展為一個完整的靜態綜合程序。綜合系統從環境接收來自豐富理論 calT 的變數估值，並輸出來自 calT 的系統變數估值。我們使用抽象方法從 LTL 規格綜合一個反應式布林控制器，並將其與函數綜合結合，以獲得原始 LTLt 規格的一個靜態控制器。我們也證明，我們的這個方法允許回應，意即控制器可以最佳化其輸出，例如，總是提供最小的安全值。這是第一個針對 LTLt 的完整靜態綜合方法，它是一個確定性的程式 (因此是可預測且有效率的)。

##### **CFaults: Model-Based Diagnosis for Fault Localization in C Programs with Multiple Test Cases**
2407.09337v1 by Pedro Orvalho, Mikoláš Janota, Vasco Manquinho

Debugging is one of the most time-consuming and expensive tasks in software
development. Several formula-based fault localization (FBFL) methods have been
proposed, but they fail to guarantee a set of diagnoses across all failing
tests or may produce redundant diagnoses that are not subset-minimal,
particularly for programs with multiple faults.
  This paper introduces a novel fault localization approach for C programs with
multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple
observations and aggregates all failing test cases into a unified MaxSAT
formula. Consequently, our method guarantees consistency across observations
and simplifies the fault localization procedure. Experimental results on two
benchmark sets of C programs, TCAS and C-Pack-IPAs, show that CFaults is faster
than other FBFL approaches like BugAssist and SNIPER. Moreover, CFaults only
generates subset-minimal diagnoses of faulty statements, whereas the other
approaches tend to enumerate redundant diagnoses.

摘要：除錯是軟體開發中最耗時且昂貴的任務之一。已提出多種基於公式的故障定位 (FBFL) 方法，但它們無法保證所有失敗測試的診斷集合，或可能產生並非子集最小化的重複診斷，特別是對於具有多個故障的程式。
本文針對具有多個故障的 C 程式介紹一種新穎的故障定位方法。CFaults 利用基於模型的診斷 (MBD) 進行多重觀察，並將所有失敗測試案例彙總成一個統一的 MaxSAT 公式。因此，我們的程式保證各觀察之間的一致性，並簡化故障定位程序。在兩個 C 程式基準集 TCAS 和 C-Pack-IPAs 上的實驗結果顯示，CFaults 比其他 FBFL 方法（例如 BugAssist 和 SNIPER）更快。此外，CFaults 僅產生故障陳述的子集最小診斷，而其他方法則傾向於列舉重複診斷。

##### **Sina at FigNews 2024: Multilingual Datasets Annotated with Bias and Propaganda**
2407.09327v1 by Lina Duaibes, Areej Jaber, Mustafa Jarrar, Ahmad Qadi, Mais Qandeel

The proliferation of bias and propaganda on social media is an increasingly
significant concern, leading to the development of techniques for automatic
detection. This article presents a multilingual corpus of 12, 000 Facebook
posts fully annotated for bias and propaganda. The corpus was created as part
of the FigNews 2024 Shared Task on News Media Narratives for framing the
Israeli War on Gaza. It covers various events during the War from October 7,
2023 to January 31, 2024. The corpus comprises 12, 000 posts in five languages
(Arabic, Hebrew, English, French, and Hindi), with 2, 400 posts for each
language. The annotation process involved 10 graduate students specializing in
Law. The Inter-Annotator Agreement (IAA) was used to evaluate the annotations
of the corpus, with an average IAA of 80.8% for bias and 70.15% for propaganda
annotations. Our team was ranked among the bestperforming teams in both Bias
and Propaganda subtasks. The corpus is open-source and available at
https://sina.birzeit.edu/fada

摘要：社群媒體上偏見和宣傳的激增令人越來越擔憂，導致自動偵測技術的發展。本文提出一個多語言語料庫，包含 12,000 則 Facebook 貼文，並針對偏見和宣傳進行了完整的註解。此語料庫是 FigNews 2024 共享任務的一部分，用於建構以色列對加薩走廊的戰爭新聞媒體敘事。它涵蓋了 2023 年 10 月 7 日至 2024 年 1 月 31 日期間戰爭中的各種事件。此語料庫包含五種語言（阿拉伯語、希伯來語、英語、法語和印地語）的 12,000 則貼文，每種語言各有 2,400 則貼文。註解程序由 10 位法律專業的研究生參與。語料庫的註解採用註解者間一致性 (IAA) 進行評估，偏見註解的平均 IAA 為 80.8%，宣傳註解的平均 IAA 為 70.15%。我們的團隊在偏見和宣傳這兩個子任務中都名列表現最佳團隊。此語料庫是開源的，可於 https://sina.birzeit.edu/fada 取得

##### **Provable Privacy Advantages of Decentralized Federated Learning via Distributed Optimization**
2407.09324v1 by Wenrui Yu, Qiongxiu Li, Milan Lopuhaä-Zwakenberg, Mads Græsbøll Christensen, Richard Heusdens

Federated learning (FL) emerged as a paradigm designed to improve data
privacy by enabling data to reside at its source, thus embedding privacy as a
core consideration in FL architectures, whether centralized or decentralized.
Contrasting with recent findings by Pasquini et al., which suggest that
decentralized FL does not empirically offer any additional privacy or security
benefits over centralized models, our study provides compelling evidence to the
contrary. We demonstrate that decentralized FL, when deploying distributed
optimization, provides enhanced privacy protection - both theoretically and
empirically - compared to centralized approaches. The challenge of quantifying
privacy loss through iterative processes has traditionally constrained the
theoretical exploration of FL protocols. We overcome this by conducting a
pioneering in-depth information-theoretical privacy analysis for both
frameworks. Our analysis, considering both eavesdropping and passive adversary
models, successfully establishes bounds on privacy leakage. We show information
theoretically that the privacy loss in decentralized FL is upper bounded by the
loss in centralized FL. Compared to the centralized case where local gradients
of individual participants are directly revealed, a key distinction of
optimization-based decentralized FL is that the relevant information includes
differences of local gradients over successive iterations and the aggregated
sum of different nodes' gradients over the network. This information
complicates the adversary's attempt to infer private data. To bridge our
theoretical insights with practical applications, we present detailed case
studies involving logistic regression and deep neural networks. These examples
demonstrate that while privacy leakage remains comparable in simpler models,
complex models like deep neural networks exhibit lower privacy risks under
decentralized FL.

摘要：聯邦學習 (FL) 是一種新興典範，旨在透過讓資料保留在資料源中來改善資料隱私，從而將隱私作為 FL 架構（無論是集中式或分散式）中的核心考量。與 Pasquini 等人最近的研究結果形成對比，後者認為分散式 FL 並未經驗性地提供任何額外的隱私或安全性優勢，我們的研究提供了令人信服的相反證據。我們證明，分散式 FL 在部署分散式最佳化時，與集中式方法相比，提供了增強的隱私保護，無論是在理論上還是經驗上。量化透過反覆運算造成的隱私損失的挑戰，傳統上限制了 FL 協定的理論探討。我們透過對這兩個架構進行開創性的深入資訊理論隱私分析來克服這個問題。我們的分析考量了竊聽和被動對手模型，成功地為隱私洩漏建立了界限。我們在理論上證明，分散式 FL 中的隱私損失上限為集中式 FL 中的損失。與集中式案例（其中個別參與者的局部梯度直接揭露）相比，基於最佳化的分散式 FL 的一個關鍵區別在於，相關資訊包括局部梯度在連續反覆運算中的差異，以及網路中不同節點梯度的總和。這些資訊讓對手難以推論私人資料。為了將我們的理論見解與實際應用相結合，我們提出了涉及邏輯迴歸和深度神經網路的詳細案例研究。這些範例證明，儘管在較簡單的模型中隱私洩漏仍然相當，但深度神經網路等複雜模型在分散式 FL 下展現了較低的隱私風險。

##### **Scalability of Bayesian Network Structure Elicitation with Large Language Models: a Novel Methodology and Comparative Analysis**
2407.09311v1 by Nikolay Babakov, Ehud Reiter, Alberto Bugarin

In this work, we propose a novel method for Bayesian Networks (BNs) structure
elicitation that is based on the initialization of several LLMs with different
experiences, independently querying them to create a structure of the BN, and
further obtaining the final structure by majority voting. We compare the method
with one alternative method on various widely and not widely known BNs of
different sizes and study the scalability of both methods on them. We also
propose an approach to check the contamination of BNs in LLM, which shows that
some widely known BNs are inapplicable for testing the LLM usage for BNs
structure elicitation. We also show that some BNs may be inapplicable for such
experiments because their node names are indistinguishable. The experiments on
the other BNs show that our method performs better than the existing method
with one of the three studied LLMs; however, the performance of both methods
significantly decreases with the increase in BN size.

摘要：在這項工作中，我們提出了一種貝氏網路 (BN) 結構引導的新方法，它基於初始化具有不同經驗的幾個 LLM，獨立查詢它們以建立 BN 的結構，並進一步通過多數投票獲得最終結構。我們將該方法與各種廣泛已知和不廣泛已知的不同大小的 BN 上的一種替代方法進行比較，並研究了這兩種方法在它們上的可擴展性。我們還提出了一種檢查 LLM 中 BN 污染的方法，該方法表明一些廣泛已知的 BN 不適用於測試 LLM 用於 BN 結構引導。我們還表明，一些 BN 可能不適用於此類實驗，因為它們的節點名稱無法區分。在其他 BN 上的實驗表明，我們的模型比現有模型的表現更好，使用三個研究的 LLM 中的一個；然而，隨著 BN 大小的增加，兩種方法的表現都顯著下降。

##### **Transformer Layers as Painters**
2407.09298v1 by Qi Sun, Marc Pickett, Aakash Kumar Nain, Llion Jones

Despite their nearly universal adoption for large language models, the
internal workings of transformers are not well understood. We aim to better
understand the impact of removing or reorganizing information throughout the
layers of a pretrained transformer. Such an understanding could both yield
better usage of existing models as well as to make architectural improvements
to produce new variants. We present a series of empirical studies on frozen
models that show that the lower and final layers of pretrained transformers
differ from middle layers, but that middle layers have a surprising amount of
uniformity. We further show that some classes of problems have robustness to
skipping layers, running the layers in an order different from how they were
trained, or running the layers in parallel. Our observations suggest that even
frozen pretrained models may gracefully trade accuracy for latency by skipping
layers or running layers in parallel.

摘要：儘管它們幾乎普遍用於大型語言模型，但Transformer的內部運作並不被理解。我們旨在更好地理解在預訓練Transformer的層中刪除或重新組織資訊的影響。這樣的理解既可以帶來對現有模型更好的使用，也可以進行架構改進以產生新的變體。我們提出了一系列關於凍結模型的實證研究，這些研究表明預訓練Transformer的較低層和最後一層與中間層不同，但中間層具有驚人的均勻性。我們進一步表明，某些類別的問題具有對跳過層的穩健性，以不同於訓練方式的順序執行層，或並行執行層。我們的觀察結果表明，即使凍結的預訓練模型也可以通過跳過層或並行執行層來優雅地用準確度換取延遲。

##### **Instruction Following with Goal-Conditioned Reinforcement Learning in Virtual Environments**
2407.09287v1 by Zoya Volovikova, Alexey Skrynnik, Petr Kuderov, Aleksandr I. Panov

In this study, we address the issue of enabling an artificial intelligence
agent to execute complex language instructions within virtual environments. In
our framework, we assume that these instructions involve intricate linguistic
structures and multiple interdependent tasks that must be navigated
successfully to achieve the desired outcomes. To effectively manage these
complexities, we propose a hierarchical framework that combines the deep
language comprehension of large language models with the adaptive
action-execution capabilities of reinforcement learning agents. The language
module (based on LLM) translates the language instruction into a high-level
action plan, which is then executed by a pre-trained reinforcement learning
agent. We have demonstrated the effectiveness of our approach in two different
environments: in IGLU, where agents are instructed to build structures, and in
Crafter, where agents perform tasks and interact with objects in the
surrounding environment according to language commands.

摘要：在這項研究中，我們探討了讓人工智慧代理程式在虛擬環境中執行複雜語言指令的問題。在我們的框架中，我們假設這些指令包含複雜的語言結構和多項相互依賴的任務，必須成功瀏覽這些任務才能達成預期的成果。為了有效管理這些複雜性，我們提出了一個分層框架，結合大型語言模型深入的語言理解能力，以及強化學習代理程式適應性的動作執行能力。語言模組（基於 LLM）將語言指令轉換成高階行動計畫，然後由預先訓練的強化學習代理程式執行。我們在兩個不同的環境中展示了我們方法的有效性：在 IGLU 中，代理程式被指示建造結構，而在 Crafter 中，代理程式根據語言指令執行任務並與周圍環境中的物件互動。

##### **DAHRS: Divergence-Aware Hallucination-Remediated SRL Projection**
2407.09283v1 by Sangpil Youm, Brodie Mather, Chathuri Jayaweera, Juliana Prada, Bonnie Dorr

Semantic role labeling (SRL) enriches many downstream applications, e.g.,
machine translation, question answering, summarization, and stance/belief
detection. However, building multilingual SRL models is challenging due to the
scarcity of semantically annotated corpora for multiple languages. Moreover,
state-of-the-art SRL projection (XSRL) based on large language models (LLMs)
yields output that is riddled with spurious role labels. Remediation of such
hallucinations is not straightforward due to the lack of explainability of
LLMs. We show that hallucinated role labels are related to naturally occurring
divergence types that interfere with initial alignments. We implement
Divergence-Aware Hallucination-Remediated SRL projection (DAHRS), leveraging
linguistically-informed alignment remediation followed by greedy First-Come
First-Assign (FCFA) SRL projection. DAHRS improves the accuracy of SRL
projection without additional transformer-based machinery, beating XSRL in both
human and automatic comparisons, and advancing beyond headwords to accommodate
phrase-level SRL projection (e.g., EN-FR, EN-ES). Using CoNLL-2009 as our
ground truth, we achieve a higher word-level F1 over XSRL: 87.6% vs. 77.3%
(EN-FR) and 89.0% vs. 82.7% (EN-ES). Human phrase-level assessments yield 89.1%
(EN-FR) and 91.0% (EN-ES). We also define a divergence metric to adapt our
approach to other language pairs (e.g., English-Tagalog).

摘要：<paragraph>語義角色標註 (SRL) 豐富了許多下游應用，例如機器翻譯、問題解答、摘要和立場/信念偵測。然而，由於缺乏多種語言的語義標註語料庫，建立多語言 SRL 模型具有挑戰性。此外，基於大型語言模型 (LLM) 的最先進 SRL 投影 (XSRL) 產生的輸出充斥著虛假的角色標籤。由於 LLM 缺乏可解釋性，因此無法直接修復此類幻覺。我們發現，幻覺的角色標籤與自然發生的分歧類型有關，這些分歧類型會干擾初始對齊。我們實作了 Divergence-Aware Hallucination-Remediated SRL 投影 (DAHRS)，利用語言知識對齊修復，然後進行貪婪的先到先分配 (FCFA) SRL 投影。DAHRS 提高了 SRL 投影的準確度，而無需額外的基於轉換器的機制，在人工和自動比較中都優於 XSRL，並超越了詞首，以容納詞組級 SRL 投影 (例如，EN-FR、EN-ES)。使用 CoNLL-2009 作為我們的基本事實，我們實現了比 XSRL 更高的詞級 F1：87.6% 對比 77.3% (EN-FR) 和 89.0% 對比 82.7% (EN-ES)。人工詞組級評估產生 89.1% (EN-FR) 和 91.0% (EN-ES)。我們還定義了一個分歧指標，以將我們的做法調整到其他語言對（例如英語-他加祿語）。</paragraph>

##### **Predicting and Understanding Human Action Decisions: Insights from Large Language Models and Cognitive Instance-Based Learning**
2407.09281v1 by Thuy Ngoc Nguyen, Kasturi Jamale, Cleotilde Gonzalez

Large Language Models (LLMs) have demonstrated their capabilities across
various tasks, from language translation to complex reasoning. Understanding
and predicting human behavior and biases are crucial for artificial
intelligence (AI) assisted systems to provide useful assistance, yet it remains
an open question whether these models can achieve this. This paper addresses
this gap by leveraging the reasoning and generative capabilities of the LLMs to
predict human behavior in two sequential decision-making tasks. These tasks
involve balancing between exploitative and exploratory actions and handling
delayed feedback, both essential for simulating real-life decision processes.
We compare the performance of LLMs with a cognitive instance-based learning
(IBL) model, which imitates human experiential decision-making. Our findings
indicate that LLMs excel at rapidly incorporating feedback to enhance
prediction accuracy. In contrast, the cognitive IBL model better accounts for
human exploratory behaviors and effectively captures loss aversion bias, i.e.,
the tendency to choose a sub-optimal goal with fewer step-cost penalties rather
than exploring to find the optimal choice, even with limited experience. The
results highlight the benefits of integrating LLMs with cognitive
architectures, suggesting that this synergy could enhance the modeling and
understanding of complex human decision-making patterns.

摘要：大型語言模型 (LLM) 已展示其在各種任務中的能力，從語言翻譯到複雜推理。理解和預測人類行為和偏見對於人工智能 (AI) 輔助系統提供有用的協助至關重要，但這些模型是否能做到這一點仍然是一個懸而未決的問題。本文通過利用 LLM 的推理和生成能力來預測人類在兩個順序決策任務中的行為，從而解決了這個差距。這些任務涉及在剝削性和探索性行動之間取得平衡以及處理延遲的回饋，這對於模擬現實生活中的決策過程至關重要。我們將 LLM 的表現與認知基於實例的學習 (IBL) 模型進行比較，該模型模擬人類的經驗決策制定。我們的研究結果表明，LLM 擅長快速整合回饋以提高預測準確度。相比之下，認知 IBL 模型更好地說明了人類的探索性行為，並有效地捕捉到了損失規避偏見，即即使經驗有限，也傾向於選擇步調成本處罰較少的次優目標，而不是探索以找到最佳選擇。結果突出了將 LLM 與認知架構相結合的好處，表明這種協同作用可以增強對複雜人類決策模式的建模和理解。

##### **H2O-Danube3 Technical Report**
2407.09276v1 by Pascal Pfeiffer, Philipp Singer, Yauhen Babakhin, Gabor Fodor, Nischay Dhankhar, Sri Satish Ambati

We present H2O-Danube3, a series of small language models consisting of
H2O-Danube3-4B, trained on 6T tokens and H2O-Danube3-500M, trained on 4T
tokens. Our models are pre-trained on high quality Web data consisting of
primarily English tokens in three stages with different data mixes before final
supervised tuning for chat version. The models exhibit highly competitive
metrics across a multitude of academic, chat, and fine-tuning benchmarks.
Thanks to its compact architecture, H2O-Danube3 can be efficiently run on a
modern smartphone, enabling local inference and rapid processing capabilities
even on mobile devices. We make all models openly available under Apache 2.0
license further democratizing LLMs to a wider audience economically.

摘要：我們提出 H2O-Danube3，一系列由 H2O-Danube3-4B 組成的小型語言模型，訓練於 6T 代幣和 H2O-Danube3-500M，訓練於 4T 代幣。我們的模型預先訓練於高品質網路資料，主要包含英文代幣，在最終監督調整聊天版本之前，分三個階段使用不同的資料組合。這些模型在大量的學術、聊天和微調基準中展現極具競爭力的指標。由於其緊湊的架構，H2O-Danube3 可在現代智慧型手機上有效執行，即使在行動裝置上也能進行局部推論和快速處理。我們讓所有模型在 Apache 2.0 授權下公開，進一步以經濟的方式將 LLM 民主化給更廣泛的受眾。

##### **Unifying Sequences, Structures, and Descriptions for Any-to-Any Protein Generation with the Large Multimodal Model HelixProtX**
2407.09274v1 by Zhiyuan Chen, Tianhao Chen, Chenggang Xie, Yang Xue, Xiaonan Zhang, Jingbo Zhou, Xiaomin Fang

Proteins are fundamental components of biological systems and can be
represented through various modalities, including sequences, structures, and
textual descriptions. Despite the advances in deep learning and scientific
large language models (LLMs) for protein research, current methodologies
predominantly focus on limited specialized tasks -- often predicting one
protein modality from another. These approaches restrict the understanding and
generation of multimodal protein data. In contrast, large multimodal models
have demonstrated potential capabilities in generating any-to-any content like
text, images, and videos, thus enriching user interactions across various
domains. Integrating these multimodal model technologies into protein research
offers significant promise by potentially transforming how proteins are
studied. To this end, we introduce HelixProtX, a system built upon the large
multimodal model, aiming to offer a comprehensive solution to protein research
by supporting any-to-any protein modality generation. Unlike existing methods,
it allows for the transformation of any input protein modality into any desired
protein modality. The experimental results affirm the advanced capabilities of
HelixProtX, not only in generating functional descriptions from amino acid
sequences but also in executing critical tasks such as designing protein
sequences and structures from textual descriptions. Preliminary findings
indicate that HelixProtX consistently achieves superior accuracy across a range
of protein-related tasks, outperforming existing state-of-the-art models. By
integrating multimodal large models into protein research, HelixProtX opens new
avenues for understanding protein biology, thereby promising to accelerate
scientific discovery.

摘要：蛋白質是生物系統的基本組成，可以用序列、結構和文字描述等各種方式表示。儘管深度學習和科學大型語言模型 (LLM) 在蛋白質研究方面取得進展，但目前的技術主要集中在有限的專門任務上，通常是從一種蛋白質模式預測另一種蛋白質模式。這些方法限制了對多模式蛋白質資料的理解和產生。相比之下，大型多模式模型已證明有能力產生任何內容，例如文字、影像和影片，從而豐富使用者在各種領域的互動。將這些多模式模型技術整合到蛋白質研究中，有望透過潛在轉變蛋白質的研究方式，帶來顯著的進展。為此，我們引進 HelixProtX，一個建立在大型多模式模型上的系統，旨在透過支援任何到任何的蛋白質模式產生，為蛋白質研究提供全面的解決方案。與現有方法不同，它允許將任何輸入蛋白質模式轉換為任何所需的蛋白質模式。實驗結果肯定了 HelixProtX 的先進能力，不僅可以從胺基酸序列產生功能描述，還可以執行關鍵任務，例如從文字描述設計蛋白質序列和結構。初步發現表明，HelixProtX 在一系列與蛋白質相關的任務中始終都能達到更高的準確度，優於現有的最先進模型。透過將多模式大型模型整合到蛋白質研究中，HelixProtX 為了解蛋白質生物學開啟了新途徑，從而有望加速科學發現。

##### **Context Embeddings for Efficient Answer Generation in RAG**
2407.09252v1 by David Rau, Shuai Wang, Hervé Déjean, Stéphane Clinchant

Retrieval-Augmented Generation (RAG) allows overcoming the limited knowledge
of LLMs by extending the input with external information. As a consequence, the
contextual inputs to the model become much longer which slows down decoding
time directly translating to the time a user has to wait for an answer. We
address this challenge by presenting COCOM, an effective context compression
method, reducing long contexts to only a handful of Context Embeddings speeding
up the generation time by a large margin. Our method allows for different
compression rates trading off decoding time for answer quality. Compared to
earlier methods, COCOM allows for handling multiple contexts more effectively,
significantly reducing decoding time for long inputs. Our method demonstrates a
speed-up of up to 5.69 $\times$ while achieving higher performance compared to
existing efficient context compression methods.

摘要：檢索增強生成 (RAG) 可透過外部資訊擴充輸入，克服 LLM 知識有限的問題。因此，模型的脈絡輸入變得更長，這會直接減慢解碼時間，轉換成使用者必須等待答案的時間。我們透過提出 COCOM 來解決這個挑戰，這是一個有效的脈絡壓縮方法，可將長脈絡縮減為僅少數脈絡嵌入，大幅縮短生成時間。我們的這個方法允許使用不同的壓縮率，在解碼時間和答案品質之間取得平衡。與較早的方法相比，COCOM 能更有效地處理多個脈絡，大幅縮短長輸入的解碼時間。我們的這個方法展示出最高達 5.69 倍的加速，同時與現有的有效脈絡壓縮方法相比，還能獲得更高的效能。

##### **Deep Adversarial Defense Against Multilevel-Lp Attacks**
2407.09251v1 by Ren Wang, Yuxuan Li, Alfred Hero

Deep learning models have shown considerable vulnerability to adversarial
attacks, particularly as attacker strategies become more sophisticated. While
traditional adversarial training (AT) techniques offer some resilience, they
often focus on defending against a single type of attack, e.g., the
$\ell_\infty$-norm attack, which can fail for other types. This paper
introduces a computationally efficient multilevel $\ell_p$ defense, called the
Efficient Robust Mode Connectivity (EMRC) method, which aims to enhance a deep
learning model's resilience against multiple $\ell_p$-norm attacks. Similar to
analytical continuation approaches used in continuous optimization, the method
blends two $p$-specific adversarially optimal models, the $\ell_1$- and
$\ell_\infty$-norm AT solutions, to provide good adversarial robustness for a
range of $p$. We present experiments demonstrating that our approach performs
better on various attacks as compared to AT-$\ell_\infty$, E-AT, and MSD, for
datasets/architectures including: CIFAR-10, CIFAR-100 / PreResNet110,
WideResNet, ViT-Base.

摘要：深度學習模型已經展現出對抗攻擊的顯著脆弱性，尤其是隨著攻擊者策略變得更加複雜。雖然傳統的對抗訓練 (AT) 技術提供了一些彈性，但它們通常專注於防禦單一類型的攻擊，例如 $\ell_\infty$-norm 攻擊，這可能會對其他類型失效。本文介紹了一種計算有效的多級 $\ell_p$ 防禦，稱為高效穩健模式連接 (EMRC) 方法，其目的是增強深度學習模型對多種 $\ell_p$-norm 攻擊的彈性。類似於連續最佳化中使用的解析延續方法，該方法混合了兩個 $p$-特定對抗最優模型，即 $\ell_1$- 和 $\ell_\infty$-norm AT 溶液，以提供針對範圍 $p$ 的良好對抗魯棒性。我們提出了實驗，證明與 AT-$\ell_\infty$、E-AT 和 MSD 相比，我們的模型在各種攻擊中的表現更好，包括 CIFAR-10、CIFAR-100 / PreResNet110、WideResNet、ViT-Base 等數據集/架構。

##### **GNN with Model-based RL for Multi-agent Systems**
2407.09249v1 by Hanxiao Chen

Multi-agent systems (MAS) constitute a significant role in exploring machine
intelligence and advanced applications. In order to deeply investigate
complicated interactions within MAS scenarios, we originally propose "GNN for
MBRL" model, which utilizes a state-spaced Graph Neural Networks with
Model-based Reinforcement Learning to address specific MAS missions (e.g.,
Billiard-Avoidance, Autonomous Driving Cars). In detail, we firstly used GNN
model to predict future states and trajectories of multiple agents, then
applied the Cross-Entropy Method (CEM) optimized Model Predictive Control to
assist the ego-agent planning actions and successfully accomplish certain MAS
tasks.

摘要：多智能體系統 (MAS) 在探索機器智慧和進階應用中扮演著重要的角色。為了深入探討 MAS 場景中的複雜互動，我們最初提出「用於 MBRL 的 GNN」模型，它利用具有模型基礎強化學習的狀態空間圖神經網路來處理特定的 MAS 任務（例如，避免碰撞、自動駕駛汽車）。詳細來說，我們首先使用 GNN 模型來預測多個智能體的未來狀態和軌跡，然後應用交叉熵方法 (CEM) 最佳化的模型預測控制來協助自我智能體規劃動作，並成功完成某些 MAS 任務。

##### **The Sociolinguistic Foundations of Language Modeling**
2407.09241v1 by Jack Grieve, Sara Bartl, Matteo Fuoli, Jason Grafmiller, Weihang Huang, Alejandro Jawerbaum, Akira Murakami, Marcus Perlman, Dana Roemling, Bodo Winter

In this paper, we introduce a sociolinguistic perspective on language
modeling. We claim that large language models are inherently models of
varieties of language, and we consider how this insight can inform the
development and deployment of large language models. We begin by presenting a
technical definition of the concept of a variety of language as developed in
sociolinguistics. We then discuss how this perspective can help address five
basic challenges in language modeling: social bias, domain adaptation,
alignment, language change, and scale. Ultimately, we argue that it is crucial
to carefully define and compile training corpora that accurately represent the
specific varieties of language being modeled to maximize the performance and
societal value of large language models.

摘要：在本文中，我們介紹了語言建模的社會語言學觀點。我們主張大型語言模型本質上是語言變體的模型，我們考慮了這個見解如何為大型語言模型的開發和部署提供參考。我們首先提出社會語言學中發展的語言變體概念的技術定義。然後我們討論這個觀點如何幫助解決語言建模中的五個基本挑戰：社會偏見、領域適應、對齊、語言變化和規模。最終，我們認為仔細定義和編譯準確表示正在建模的特定語言變體的訓練語料庫對於最大化大型語言模型的性能和社會價值至關重要。

##### **Generating SROI^{-} Ontologies via Knowledge Graph Query Embedding Learning**
2407.09212v1 by Yunjie He, Daniel Hernandez, Mojtaba Nayyeri, Bo Xiong, Yuqicheng Zhu, Evgeny Kharlamov, Steffen Staab

Query embedding approaches answer complex logical queries over incomplete
knowledge graphs (KGs) by computing and operating on low-dimensional vector
representations of entities, relations, and queries. However, current query
embedding models heavily rely on excessively parameterized neural networks and
cannot explain the knowledge learned from the graph. We propose a novel query
embedding method, AConE, which explains the knowledge learned from the graph in
the form of SROI^{-} description logic axioms while being more
parameter-efficient than most existing approaches. AConE associates queries to
a SROI^{-} description logic concept. Every SROI^{-} concept is embedded as a
cone in complex vector space, and each SROI^{-} relation is embedded as a
transformation that rotates and scales cones. We show theoretically that AConE
can learn SROI^{-} axioms, and defines an algebra whose operations correspond
one to one to SROI^{-} description logic concept constructs. Our empirical
study on multiple query datasets shows that AConE achieves superior results
over previous baselines with fewer parameters. Notably on the WN18RR dataset,
AConE achieves significant improvement over baseline models. We provide
comprehensive analyses showing that the capability to represent axioms
positively impacts the results of query answering.

摘要：查詢嵌入方法通過計算和操作實體、關係和查詢的低維向量表示，來回答不完整知識圖譜 (KG) 上的複雜邏輯查詢。然而，當前的查詢嵌入模型過度依賴過度參數化的神經網路，且無法解釋從圖譜中學到的知識。我們提出了一種新穎的查詢嵌入方法 AConE，它以 SROI^{-} 描述邏輯公理的形式解釋從圖譜中學到的知識，同時比大多數現有方法更具參數效率。AConE 將查詢與 SROI^{-} 描述邏輯概念關聯起來。每個 SROI^{-} 概念都嵌入為複雜向量空間中的錐體，每個 SROI^{-} 關係都嵌入為旋轉和縮放錐體的轉換。我們在理論上證明了 AConE 可以學習 SROI^{-} 公理，並定義了一個代數，其運算與 SROI^{-} 描述邏輯概念結構一一對應。我們在多個查詢資料集上的實證研究表明，AConE 以較少的參數優於先前的基準。值得注意的是，在 WN18RR 資料集上，AConE 比基準模型取得了顯著的改進。我們提供了全面的分析，表明表示公理的能力對查詢回答的結果產生了積極的影響。

##### **Pronunciation Assessment with Multi-modal Large Language Models**
2407.09209v1 by Kaiqi Fu, Linkai Peng, Nan Yang, Shuran Zhou

Large language models (LLMs), renowned for their powerful conversational
abilities, are widely recognized as exceptional tools in the field of
education, particularly in the context of automated intelligent instruction
systems for language learning. In this paper, we propose a scoring system based
on LLMs, motivated by their positive impact on text-related scoring tasks.
Specifically, the speech encoder first maps the learner's speech into
contextual features. The adapter layer then transforms these features to align
with the text embedding in latent space. The assessment task-specific prefix
and prompt text are embedded and concatenated with the features generated by
the modality adapter layer, enabling the LLMs to predict accuracy and fluency
scores. Our experiments demonstrate that the proposed scoring systems achieve
competitive results compared to the baselines on the Speechocean762 datasets.
Moreover, we also conducted an ablation study to better understand the
contributions of the prompt text and training strategy in the proposed scoring
system.

摘要：大型語言模型 (LLM) 以其強大的對話能力而聞名，被廣泛認為是教育領域的卓越工具，特別是在語言學習的自動化智能教學系統中。在本文中，我們提出一個基於 LLM 的評分系統，其動機是 LLM 對與文本相關的評分任務的積極影響。具體來說，語音編碼器首先將學習者的語音映射到上下文特徵中。然後，適配器層將這些特徵轉換為與潛在空間中的文本嵌入對齊。評估任務特定的前綴和提示文本被嵌入並與模態適配器層產生的特徵串聯，使 LLM 能夠預測準確性和流利度分數。我們的實驗表明，與 Speechocean762 資料集上的基準相比，所提出的評分系統取得了有競爭力的結果。此外，我們還進行了一項消融研究，以更好地理解提示文本和訓練策略在所提出的評分系統中的貢獻。

##### **From Easy to Hard: Learning Curricular Shape-aware Features for Robust Panoptic Scene Graph Generation**
2407.09191v1 by Hanrong Shi, Lin Li, Jun Xiao, Yueting Zhuang, Long Chen

Panoptic Scene Graph Generation (PSG) aims to generate a comprehensive
graph-structure representation based on panoptic segmentation masks. Despite
remarkable progress in PSG, almost all existing methods neglect the importance
of shape-aware features, which inherently focus on the contours and boundaries
of objects. To bridge this gap, we propose a model-agnostic Curricular
shApe-aware FEature (CAFE) learning strategy for PSG. Specifically, we
incorporate shape-aware features (i.e., mask features and boundary features)
into PSG, moving beyond reliance solely on bbox features. Furthermore, drawing
inspiration from human cognition, we propose to integrate shape-aware features
in an easy-to-hard manner. To achieve this, we categorize the predicates into
three groups based on cognition learning difficulty and correspondingly divide
the training process into three stages. Each stage utilizes a specialized
relation classifier to distinguish specific groups of predicates. As the
learning difficulty of predicates increases, these classifiers are equipped
with features of ascending complexity. We also incorporate knowledge
distillation to retain knowledge acquired in earlier stages. Due to its
model-agnostic nature, CAFE can be seamlessly incorporated into any PSG model.
Extensive experiments and ablations on two PSG tasks under both robust and
zero-shot PSG have attested to the superiority and robustness of our proposed
CAFE, which outperforms existing state-of-the-art methods by a large margin.

摘要：全景場景圖生成 (PSG) 旨在根據全景分割遮罩生成一個全面的圖形結構表示。儘管 PSG 取得了顯著進展，但幾乎所有現有方法都忽略了形狀感知特徵的重要性，而形狀感知特徵本質上專注於物體的輪廓和邊界。為了彌合這一差距，我們提出了一個模型不可知的課程形狀感知特徵 (CAFE) 學習策略，用於 PSG。具體來說，我們將形狀感知特徵（即遮罩特徵和邊界特徵）納入 PSG，不再僅依賴於邊界框特徵。此外，借鑒人類認知，我們建議以易到難的方式整合形狀感知特徵。為此，我們根據認知學習難度將謂詞分為三組，並相應地將訓練過程分為三個階段。每個階段都使用一個專門的關係分類器來區分特定組的謂詞。隨著謂詞學習難度的增加，這些分類器配備了複雜性遞增的特徵。我們還結合知識蒸餾來保留在早期階段獲取的知識。由於其模型不可知特性，CAFE 可以無縫地整合到任何 PSG 模型中。在穩健和零次 PSG 下的兩個 PSG 任務上進行的廣泛實驗和消融研究證明了我們提出的 CAFE 的優越性和穩健性，它以很大幅度優於現有的最先進方法。

##### **Enhancing Depressive Post Detection in Bangla: A Comparative Study of TF-IDF, BERT and FastText Embeddings**
2407.09187v1 by Saad Ahmed Sazan, Mahdi H. Miraz, A B M Muntasir Rahman

Due to massive adoption of social media, detection of users' depression
through social media analytics bears significant importance, particularly for
underrepresented languages, such as Bangla. This study introduces a
well-grounded approach to identify depressive social media posts in Bangla, by
employing advanced natural language processing techniques. The dataset used in
this work, annotated by domain experts, includes both depressive and
non-depressive posts, ensuring high-quality data for model training and
evaluation. To address the prevalent issue of class imbalance, we utilised
random oversampling for the minority class, thereby enhancing the model's
ability to accurately detect depressive posts. We explored various numerical
representation techniques, including Term Frequency-Inverse Document Frequency
(TF-IDF), Bidirectional Encoder Representations from Transformers (BERT)
embedding and FastText embedding, by integrating them with a deep
learning-based Convolutional Neural Network-Bidirectional Long Short-Term
Memory (CNN-BiLSTM) model. The results obtained through extensive
experimentation, indicate that the BERT approach performed better the others,
achieving a F1-score of 84%. This indicates that BERT, in combination with the
CNN-BiLSTM architecture, effectively recognises the nuances of Bangla texts
relevant to depressive contents. Comparative analysis with the existing
state-of-the-art methods demonstrates that our approach with BERT embedding
performs better than others in terms of evaluation metrics and the reliability
of dataset annotations. Our research significantly contribution to the
development of reliable tools for detecting depressive posts in the Bangla
language. By highlighting the efficacy of different embedding techniques and
deep learning models, this study paves the way for improved mental health
monitoring through social media platforms.

摘要：<paragraph>由於社群媒體的廣泛採用，透過社群媒體分析來偵測使用者的憂鬱症具有重要的意義，特別是對於孟加拉語等代表性不足的語言。本研究介紹了一種有根據的方法來識別孟加拉語中的憂鬱社群媒體貼文，方法是採用先進的自然語言處理技術。本研究中所使用的資料集由領域專家註解，包括憂鬱和非憂鬱貼文，確保模型訓練和評估資料的高品質。為了解決類別不平衡的普遍問題，我們對少數類別採用隨機過度取樣，從而增強模型準確偵測憂鬱貼文的能力。我們探討了各種數值表示技術，包括詞頻-逆文件頻率 (TF-IDF)、Transformer (BERT) 嵌入的雙向編碼器表示和 FastText 嵌入，並將它們與基於深度學習的卷積神經網路-雙向長短期記憶 (CNN-BiLSTM) 模型整合在一起。透過廣泛的實驗所獲得的結果顯示，BERT 方法的表現優於其他方法，達到了 84% 的 F1 分數。這表示 BERT 與 CNN-BiLSTM 架構相結合，可以有效識別與憂鬱內容相關的孟加拉語文本的細微差別。與現有的最先進方法進行比較分析，證明我們採用 BERT 嵌入的方法在評估指標和資料集註解的可靠性方面優於其他方法。我們的研究為開發用於偵測孟加拉語中憂鬱貼文的可靠工具做出了重大貢獻。透過強調不同嵌入技術和深度學習模型的效能，本研究為透過社群媒體平台改善心理健康監控鋪平了道路。</paragraph>

##### **Variational Inference via Smoothed Particle Hydrodynamics**
2407.09186v1 by Yongchao Huang

A new variational inference method, SPH-ParVI, based on smoothed particle
hydrodynamics (SPH), is proposed for sampling partially known densities (e.g.
up to a constant) or sampling using gradients. SPH-ParVI simulates the flow of
a fluid under external effects driven by the target density; transient or
steady state of the fluid approximates the target density. The continuum fluid
is modelled as an interacting particle system (IPS) via SPH, where each
particle carries smoothed properties, interacts and evolves as per the
Navier-Stokes equations. This mesh-free, Lagrangian simulation method offers
fast, flexible, scalable and deterministic sampling and inference for a class
of probabilistic models such as those encountered in Bayesian inference and
generative modelling.

摘要：一種新的變分推論方法 SPH-ParVI，基於平滑粒子流體動力學 (SPH)，用於對部分已知密度（例如，常數）或使用梯度進行抽樣。SPH-ParVI 模擬流體在目標密度驅動下的外部效應流動；流體的暫態或穩態近似於目標密度。連續流體通過 SPH 建模為相互作用粒子系統 (IPS)，其中每個粒子都攜帶平滑屬性，並根據 Navier-Stokes 方程式進行交互和演化。這種無網格拉格朗日模擬方法為一類機率模型（例如在貝氏推論和生成模型中遇到的模型）提供了快速、靈活、可擴展且確定性的抽樣和推論。

##### **Does Incomplete Syntax Influence Korean Language Model? Focusing on Word Order and Case Markers**
2407.09184v1 by Jong Myoung Kim, Young-Jun Lee, Yong-jin Han, Sangkeun Jung, Ho-Jin Choi

Syntactic elements, such as word order and case markers, are fundamental in
natural language processing. Recent studies show that syntactic information
boosts language model performance and offers clues for people to understand
their learning mechanisms. Unlike languages with a fixed word order such as
English, Korean allows for varied word sequences, despite its canonical
structure, due to case markers that indicate the functions of sentence
components. This study explores whether Korean language models can accurately
capture this flexibility. We note that incomplete word orders and omitted case
markers frequently appear in ordinary Korean communication. To investigate this
further, we introduce the Syntactically Incomplete Korean (SIKO) dataset.
Through SIKO, we assessed Korean language models' flexibility with incomplete
syntax and confirmed the dataset's training value. Results indicate these
models reflect Korean's inherent flexibility, accurately handling incomplete
inputs. Moreover, fine-tuning with SIKO enhances the ability to handle common
incomplete Korean syntactic forms. The dataset's simple construction process,
coupled with significant performance enhancements, solidifies its standing as
an effective data augmentation technique.

摘要：句法元素，例如詞序和格標記，在自然語言處理中至關重要。最近的研究表明，句法信息會提升語言模型的效能，並提供線索讓人們了解其學習機制。與英語等詞序固定的語言不同，韓語允許不同的詞序，儘管其標準結構，這是因為格標記標示了句子成分的功能。本研究探討韓語語言模型能否準確地捕捉這種靈活性。我們注意到，不完整的詞序和省略的格標記經常出現在一般的韓語溝通中。為了進一步研究這一點，我們引入了句法不完整的韓語 (SIKO) 資料集。透過 SIKO，我們評估了韓語語言模型在句法不完整情況下的靈活性，並確認了該資料集的訓練價值。結果表明，這些模型反映了韓語固有的靈活性，準確地處理不完整的輸入。此外，使用 SIKO 進行微調增強了處理常見不完整韓語句法形式的能力。該資料集的簡單建構過程，加上顯著的效能提升，鞏固了其作為一種有效資料擴充技術的地位。

##### **Exploring the Effectiveness of Methods for Persona Extraction**
2407.09181v1 by Konstantin Zaitsev

The paper presents a study of methods for extracting information about
dialogue participants and evaluating their performance in Russian. To train
models for this task, the Multi-Session Chat dataset was translated into
Russian using multiple translation models, resulting in improved data quality.
A metric based on the F-score concept is presented to evaluate the
effectiveness of the extraction models. The metric uses a trained classifier to
identify the dialogue participant to whom the persona belongs. Experiments were
conducted on MBart, FRED-T5, Starling-7B, which is based on the Mistral, and
Encoder2Encoder models. The results demonstrated that all models exhibited an
insufficient level of recall in the persona extraction task. The incorporation
of the NCE Loss improved the model's precision at the expense of its recall.
Furthermore, increasing the model's size led to enhanced extraction of
personas.

摘要：論文提出了一種研究方法，用於提取俄語對話參與者的資訊並評估其表現。為了訓練此任務的模型，Multi-Session Chat 資料集使用多個翻譯模型翻譯成俄語，進而提升資料品質。提出了一個基於 F 分數概念的指標，用於評估提取模型的有效性。該指標使用訓練好的分類器來識別角色所屬的對話參與者。實驗在基於 Mistral 的 MBart、FRED-T5、Starling-7B 和 Encoder2Encoder 模型上進行。結果顯示，所有模型在角色提取任務中都表現出不足夠的召回率。加入 NCE 損失以犧牲召回率為代價來提升模型的準確率。此外，增加模型大小有助於增強角色的提取。

##### **DART: An Automated End-to-End Object Detection Pipeline with Data Diversification, Open-Vocabulary Bounding Box Annotation, Pseudo-Label Review, and Model Training**
2407.09174v1 by Chen Xin, Andreas Hartel, Enkelejda Kasneci

Swift and accurate detection of specified objects is crucial for many
industrial applications, such as safety monitoring on construction sites.
However, traditional approaches rely heavily on arduous manual annotation and
data collection, which struggle to adapt to ever-changing environments and
novel target objects. To address these limitations, this paper presents DART,
an automated end-to-end pipeline designed to streamline the entire workflow of
an object detection application from data collection to model deployment. DART
eliminates the need for human labeling and extensive data collection while
excelling in diverse scenarios. It employs a subject-driven image generation
module (DreamBooth with SDXL) for data diversification, followed by an
annotation stage where open-vocabulary object detection (Grounding DINO)
generates bounding box annotations for both generated and original images.
These pseudo-labels are then reviewed by a large multimodal model (GPT-4o) to
guarantee credibility before serving as ground truth to train real-time object
detectors (YOLO). We apply DART to a self-collected dataset of construction
machines named Liebherr Product, which contains over 15K high-quality images
across 23 categories. The current implementation of DART significantly
increases average precision (AP) from 0.064 to 0.832. Furthermore, we adopt a
modular design for DART to ensure easy exchangeability and extensibility. This
allows for a smooth transition to more advanced algorithms in the future,
seamless integration of new object categories without manual labeling, and
adaptability to customized environments without extra data collection. The code
and dataset are released at https://github.com/chen-xin-94/DART.

摘要：<paragraph>在許多產業應用中，快速且準確地偵測特定物體至關重要，例如建築工地的安全監控。然而，傳統方法過度依賴繁瑣的手動註解和資料收集，難以適應不斷變化的環境和新穎的目標物體。為了解決這些限制，本文提出了 DART，一個自動化的端到端管道，旨在簡化物件偵測應用程式的整個工作流程，從資料收集到模型部署。DART 消除了人工標記和大量資料收集的需要，同時在各種場景中表現出色。它採用主題驅動的影像生成模組（DreamBooth with SDXL）進行資料多元化，接著進行註解階段，其中開放式詞彙物件偵測（Grounding DINO）為生成的影像和原始影像產生邊界框註解。這些偽標籤接著由大型多模態模型（GPT-4o）審查，以確保可信度，然後作為訓練即時物件偵測器（YOLO）的真實依據。我們將 DART 應用於一個自收集的建築機械資料集，名為利勃海爾產品，其中包含 23 個類別的 15K 張以上高品質影像。DART 的目前實作大幅提升平均準確率 (AP) 從 0.064 到 0.832。此外，我們採用模組化設計，確保 DART 容易替換和擴充。這允許未來順利轉換到更進階的演算法，無需人工標記即可無縫整合新的物件類別，並在不需額外資料收集的情況下適應自訂環境。程式碼和資料集已於 https://github.com/chen-xin-94/DART 發布。</paragraph>

##### **Robust Yet Efficient Conformal Prediction Sets**
2407.09165v1 by Soroush H. Zargarbashi, Mohammad Sadegh Akhondzadeh, Aleksandar Bojchevski

Conformal prediction (CP) can convert any model's output into prediction sets
guaranteed to include the true label with any user-specified probability.
However, same as the model itself, CP is vulnerable to adversarial test
examples (evasion) and perturbed calibration data (poisoning). We derive
provably robust sets by bounding the worst-case change in conformity scores.
Our tighter bounds lead to more efficient sets. We cover both continuous and
discrete (sparse) data and our guarantees work both for evasion and poisoning
attacks (on both features and labels).

摘要：共形预测 (CP) 可以将任何模型的输出转换为预测集，保证包含任何用户指定的概率的真实标签。
然而，与模型本身一样，CP 容易受到对抗性测试示例（规避）和扰动校准数据（中毒）的影响。我们通过限制一致性分数的最坏情况变化来推导出可证明的鲁棒集。我们更严格的界限导致更有效的集合。我们涵盖连续和离散（稀疏）数据，并且我们的保证适用于规避和中毒攻击（针对特征和标签）。

##### **TAPI: Towards Target-Specific and Adversarial Prompt Injection against Code LLMs**
2407.09164v1 by Yuchen Yang, Hongwei Yao, Bingrun Yang, Yiling He, Yiming Li, Tianwei Zhang, Zhan Qin, Kui Ren

Recently, code-oriented large language models (Code LLMs) have been widely
and successfully used to simplify and facilitate code programming. With these
tools, developers can easily generate desired complete functional codes based
on incomplete code and natural language prompts. However, a few pioneering
works revealed that these Code LLMs are also vulnerable, e.g., against backdoor
and adversarial attacks. The former could induce LLMs to respond to triggers to
insert malicious code snippets by poisoning the training data or model
parameters, while the latter can craft malicious adversarial input codes to
reduce the quality of generated codes. However, both attack methods have
underlying limitations: backdoor attacks rely on controlling the model training
process, while adversarial attacks struggle with fulfilling specific malicious
purposes.
  To inherit the advantages of both backdoor and adversarial attacks, this
paper proposes a new attack paradigm, i.e., target-specific and adversarial
prompt injection (TAPI), against Code LLMs. TAPI generates unreadable comments
containing information about malicious instructions and hides them as triggers
in the external source code. When users exploit Code LLMs to complete codes
containing the trigger, the models will generate attacker-specified malicious
code snippets at specific locations. We evaluate our TAPI attack on four
representative LLMs under three representative malicious objectives and seven
cases. The results show that our method is highly threatening (achieving an
attack success rate of up to 89.3\%) and stealthy (saving an average of 53.1\%
of tokens in the trigger design). In particular, we successfully attack some
famous deployed code completion integrated applications, including CodeGeex and
Github Copilot. This further confirms the realistic threat of our attack.

摘要：<paragraph>最近，面向代码的大型语言模型（代码 LLM）已被广泛且成功地用于简化和促进代码编程。借助这些工具，开发人员可以轻松地根据不完整的代码和自然语言提示生成所需的完整功能代码。然而，一些开创性的工作揭示了这些代码 LLM 也存在漏洞，例如，针对后门和对抗性攻击。前者可以通过毒化训练数据或模型参数来诱使 LLM 响应触发器以插入恶意代码片段，而后者可以制作恶意的对抗性输入代码来降低生成代码的质量。然而，这两种攻击方法都有潜在的限制：后门攻击依赖于控制模型训练过程，而对抗性攻击则难以实现特定的恶意目的。
为了继承后门和对抗性攻击的优点，本文提出了一种新的攻击范例，即针对特定目标的对抗性提示注入（TAPI），针对代码 LLM。TAPI 生成了包含有关恶意指令信息且不可读的注释，并将它们隐藏为外部源代码中的触发器。当用户利用代码 LLM 完成包含触发器的代码时，模型将在特定位置生成攻击者指定的恶意代码片段。我们在三个代表性恶意目标和七个案例下对四个代表性 LLM 评估了我们的 TAPI 攻击。结果表明，我们的方法极具威胁性（攻击成功率高达 89.3%）且隐蔽（在触发器设计中平均节省了 53.1% 的标记）。特别是，我们成功攻击了一些著名的已部署代码完成集成应用程序，包括 CodeGeex 和 Github Copilot。这进一步证实了我们攻击的现实威胁。</paragraph>

##### **Exploring State Space and Reasoning by Elimination in Tsetlin Machine**
2407.09162v1 by Ahmed K. Kadhim, Ole-Christoffer Granmo, Lei Jiao, Rishad Shafik

The Tsetlin Machine (TM) has gained significant attention in Machine Learning
(ML). By employing logical fundamentals, it facilitates pattern learning and
representation, offering an alternative approach for developing comprehensible
Artificial Intelligence (AI) with a specific focus on pattern classification in
the form of conjunctive clauses. In the domain of Natural Language Processing
(NLP), TM is utilised to construct word embedding and describe target words
using clauses. To enhance the descriptive capacity of these clauses, we study
the concept of Reasoning by Elimination (RbE) in clauses' formulation, which
involves incorporating feature negations to provide a more comprehensive
representation. In more detail, this paper employs the Tsetlin Machine
Auto-Encoder (TM-AE) architecture to generate dense word vectors, aiming at
capturing contextual information by extracting feature-dense vectors for a
given vocabulary. Thereafter, the principle of RbE is explored to improve
descriptivity and optimise the performance of the TM. Specifically, the
specificity parameter s and the voting margin parameter T are leveraged to
regulate feature distribution in the state space, resulting in a dense
representation of information for each clause. In addition, we investigate the
state spaces of TM-AE, especially for the forgotten/excluded features.
Empirical investigations on artificially generated data, the IMDB dataset, and
the 20 Newsgroups dataset showcase the robustness of the TM, with accuracy
reaching 90.62\% for the IMDB.

摘要：Tsetlin 機器（TM）在機器學習（ML）中獲得了顯著的關注。通過採用邏輯基礎，它促進了模式學習和表示，為開發可理解的人工智慧（AI）提供了一種替代方法，特別關注以合取子句形式進行模式分類。在自然語言處理（NLP）領域，TM 用於構建詞嵌入並使用子句描述目標詞。為了增強這些子句的描述能力，我們研究了子句表述中的消去推理（RbE）概念，其中涉及合併特徵否定以提供更全面的表示。更詳細地說，本文採用 Tsetlin 機器自動編碼器（TM-AE）架構來生成密集的詞向量，旨在通過為給定的詞彙提取特徵密集的向量來捕獲上下文信息。此後，探索了 RbE 原理以提高描述性並優化 TM 的性能。具體來說，特異性參數 s 和投票邊際參數 T 被用於調節狀態空間中的特徵分佈，從而導致每個子句的信息密集表示。此外，我們研究了 TM-AE 的狀態空間，特別是對於遺忘/排除的特徵。對人工生成數據、IMDB 數據集和 20 個新聞組數據集的實證調查展示了 TM 的魯棒性，IMDB 的準確率達到 90.62%。

##### **Movie Recommendation with Poster Attention via Multi-modal Transformer Feature Fusion**
2407.09157v1 by Linhan Xia, Yicheng Yang, Ziou Chen, Zheng Yang, Shengxin Zhu

Pre-trained models learn general representations from large datsets which can
be fine-turned for specific tasks to significantly reduce training time.
Pre-trained models like generative pretrained transformers (GPT), bidirectional
encoder representations from transformers (BERT), vision transfomers (ViT) have
become a cornerstone of current research in machine learning. This study
proposes a multi-modal movie recommendation system by extract features of the
well designed posters for each movie and the narrative text description of the
movie. This system uses the BERT model to extract the information of text
modality, the ViT model applied to extract the information of poster/image
modality, and the Transformer architecture for feature fusion of all modalities
to predict users' preference. The integration of pre-trained foundational
models with some smaller data sets in downstream applications capture
multi-modal content features in a more comprehensive manner, thereby providing
more accurate recommendations. The efficiency of the proof-of-concept model is
verified by the standard benchmark problem the MovieLens 100K and 1M datasets.
The prediction accuracy of user ratings is enhanced in comparison to the
baseline algorithm, thereby demonstrating the potential of this cross-modal
algorithm to be applied for movie or video recommendation.

摘要：預訓練模型從大型資料集中學習一般表示，可以針對特定任務進行微調，以顯著減少訓練時間。預訓練模型，例如生成式預訓練Transformer (GPT)、來自Transformer的雙向編碼表示 (BERT)、視覺Transformer (ViT)，已成為當前機器學習研究的基石。本研究提出一個多模態電影推薦系統，通過提取為每部電影設計精美的海報和電影的敘事文字描述的特徵。這個系統使用 BERT 模型提取文本模態的信息，應用 ViT 模型提取海報/圖像模態的信息，以及Transformer架構融合所有模態的特徵來預測用戶的偏好。預訓練基礎模型與下游應用中一些較小的數據集的整合以更全面的方式擷取多模態內容特徵，從而提供更準確的建議。概念驗證模型的效率通過標準基準問題 MovieLens 100K 和 1M 數據集得到驗證。與基線演算法相比，用戶評分的預測準確度得到提升，從而證明了這種跨模態演算法應用於電影或影片推薦的潛力。

##### **The Two Sides of the Coin: Hallucination Generation and Detection with LLMs as Evaluators for LLMs**
2407.09152v1 by Anh Thu Maria Bui, Saskia Felizitas Brech, Natalie Hußfeldt, Tobias Jennert, Melanie Ullrich, Timo Breuer, Narjes Nikzad Khasmakhi, Philipp Schaer

Hallucination detection in Large Language Models (LLMs) is crucial for
ensuring their reliability. This work presents our participation in the CLEF
ELOQUENT HalluciGen shared task, where the goal is to develop evaluators for
both generating and detecting hallucinated content. We explored the
capabilities of four LLMs: Llama 3, Gemma, GPT-3.5 Turbo, and GPT-4, for this
purpose. We also employed ensemble majority voting to incorporate all four
models for the detection task. The results provide valuable insights into the
strengths and weaknesses of these LLMs in handling hallucination generation and
detection tasks.

摘要：大型語言模型 (LLM) 中的幻覺偵測對於確保其可靠性至關重要。這項工作展示了我們參與 CLEF ELOQUENT HalluciGen 共享任務，目標是為生成和偵測幻覺內容開發評估器。我們探索了四個 LLM 的能力：Llama 3、Gemma、GPT-3.5 Turbo 和 GPT-4，以達到此目的。我們還採用了整體多數投票來納入所有四個模型進行偵測任務。結果提供了有價值的見解，了解這些 LLM 在處理幻覺生成和偵測任務時的優勢和劣勢。

##### **A Look Into News Avoidance Through AWRS: An Avoidance-Aware Recommender System**
2407.09137v1 by Igor L. R. Azevedo, Toyotaro Suzumura, Yuichiro Yasui

In recent years, journalists have expressed concerns about the increasing
trend of news article avoidance, especially within specific domains. This issue
has been exacerbated by the rise of recommender systems. Our research indicates
that recommender systems should consider avoidance as a fundamental factor. We
argue that news articles can be characterized by three principal elements:
exposure, relevance, and avoidance, all of which are closely interconnected. To
address these challenges, we introduce AWRS, an Avoidance-Aware Recommender
System. This framework incorporates avoidance awareness when recommending news,
based on the premise that news article avoidance conveys significant
information about user preferences. Evaluation results on three news datasets
in different languages (English, Norwegian, and Japanese) demonstrate that our
method outperforms existing approaches.

摘要：近年來，記者們對於新聞文章迴避的趨勢日益增加表達了擔憂，特別是在特定領域。推薦系統的興起加劇了這個問題。我們的研究表明，推薦系統應將迴避視為一個基本因素。我們認為，新聞文章可以由三個主要元素來表徵：曝光、相關性和迴避，所有這些元素都密切相關。為了應對這些挑戰，我們引入了 AWRS，一個迴避感知推薦系統。這個框架在推薦新聞時納入了迴避感知，基於新聞文章迴避傳達了關於使用者偏好的重要資訊的前提。在三種不同語言（英語、挪威語和日語）的新聞資料集上的評估結果表明，我們的的方法優於現有的方法。

##### **Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors**
2407.09136v1 by Nico Daheim, Jakub Macina, Manu Kapur, Iryna Gurevych, Mrinmaya Sachan

Large language models (LLMs) present an opportunity to scale high-quality
personalized education to all. A promising approach towards this means is to
build dialog tutoring models that scaffold students' problem-solving. However,
even though existing LLMs perform well in solving reasoning questions, they
struggle to precisely detect student's errors and tailor their feedback to
these errors. Inspired by real-world teaching practice where teachers identify
student errors and customize their response based on them, we focus on
verifying student solutions and show how grounding to such verification
improves the overall quality of tutor response generation. We collect a dataset
of 1K stepwise math reasoning chains with the first error step annotated by
teachers. We show empirically that finding the mistake in a student solution is
challenging for current models. We propose and evaluate several verifiers for
detecting these errors. Using both automatic and human evaluation we show that
the student solution verifiers steer the generation model towards highly
targeted responses to student errors which are more often correct with less
hallucinations compared to existing baselines.

摘要：大型語言模型 (LLM) 提供了一個機會，可以將高品質的個人化教育擴展到所有人。一種有希望的方法是建立對話輔導模型，以架構學生的問題解決能力。然而，儘管現有的 LLM 在解決推理問題方面表現良好，但它們卻難以準確地檢測學生的錯誤並根據這些錯誤調整他們的反饋。受到現實世界教學實踐的啟發，教師會找出學生的錯誤並根據這些錯誤自訂他們的回應，我們專注於驗證學生的解法，並展示了對此類驗證的依據如何改善導師回應生成的整體品質。我們收集了一個包含 1K 步驟式數學推理鏈的資料集，其中包含由教師註解的第一個錯誤步驟。我們實證地表明，在學生的解法中找到錯誤對目前的模型來說具有挑戰性。我們提出並評估了幾個用於檢測這些錯誤的驗證器。我們透過自動和人工評估表明，學生解法驗證器引導生成模型針對學生的錯誤提出高度針對性的回應，與現有的基準相比，這些回應通常更正確，而且出現幻覺的次數更少。

##### **Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training**
2407.09121v1 by Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Jiahao Xu, Tian Liang, Pinjia He, Zhaopeng Tu

This study addresses a critical gap in safety tuning practices for Large
Language Models (LLMs) by identifying and tackling a refusal position bias
within safety tuning data, which compromises the models' ability to
appropriately refuse generating unsafe content. We introduce a novel approach,
Decoupled Refusal Training (DeRTa), designed to empower LLMs to refuse
compliance to harmful prompts at any response position, significantly enhancing
their safety capabilities. DeRTa incorporates two novel components: (1) Maximum
Likelihood Estimation (MLE) with Harmful Response Prefix, which trains models
to recognize and avoid unsafe content by appending a segment of harmful
response to the beginning of a safe response, and (2) Reinforced Transition
Optimization (RTO), which equips models with the ability to transition from
potential harm to safety refusal consistently throughout the harmful response
sequence. Our empirical evaluation, conducted using LLaMA3 and Mistral model
families across six attack scenarios, demonstrates that our method not only
improves model safety without compromising performance but also surpasses
well-known models such as GPT-4 in defending against attacks. Importantly, our
approach successfully defends recent advanced attack methods (e.g., CodeAttack)
that have jailbroken GPT-4 and LLaMA3-70B-Instruct. Our code and data can be
found at https://github.com/RobustNLP/DeRTa.

摘要：本研究透過辨識並處理安全調整資料中的拒絕立場偏差，來解決大型語言模型 (LLM) 安全調整實務中的重大缺口，該偏差會損害模型適當拒絕產生不安全內容的能力。我們引進一種創新的方法，稱為解耦拒絕訓練 (DeRTa)，旨在讓 LLM 能夠在任何回應位置拒絕遵守有害提示，大幅提升其安全能力。DeRTa 包含兩個創新的組成部分：(1) 帶有有害回應前綴的最大似然估計 (MLE)，訓練模型透過在安全回應開頭附加一段有害回應，來辨識和避免不安全內容，以及 (2) 增強過渡最佳化 (RTO)，讓模型具備在整個有害回應序列中，從潛在危害過渡到安全拒絕的能力。我們使用 LLaMA3 和 Mistral 模型家族在六種攻擊情境中進行實證評估，證明我們的方法不僅能提升模型安全性，而不損害效能，還能超越 GPT-4 等知名模型，抵禦攻擊。重要的是，我們的方法成功抵禦最近進階的攻擊方法 (例如 CodeAttack)，這些方法已破解 GPT-4 和 LLaMA3-70B-Instruct。我們的程式碼和資料可以在 https://github.com/RobustNLP/DeRTa 找到。

##### **Inference Optimization of Foundation Models on AI Accelerators**
2407.09111v1 by Youngsuk Park, Kailash Budhathoki, Liangfu Chen, Jonas Kübler, Jiaji Huang, Matthäus Kleindessner, Jun Huan, Volkan Cevher, Yida Wang, George Karypis

Powerful foundation models, including large language models (LLMs), with
Transformer architectures have ushered in a new era of Generative AI across
various industries. Industry and research community have witnessed a large
number of new applications, based on those foundation models. Such applications
include question and answer, customer services, image and video generation, and
code completions, among others. However, as the number of model parameters
reaches to hundreds of billions, their deployment incurs prohibitive inference
costs and high latency in real-world scenarios. As a result, the demand for
cost-effective and fast inference using AI accelerators is ever more higher. To
this end, our tutorial offers a comprehensive discussion on complementary
inference optimization techniques using AI accelerators. Beginning with an
overview of basic Transformer architectures and deep learning system
frameworks, we deep dive into system optimization techniques for fast and
memory-efficient attention computations and discuss how they can be implemented
efficiently on AI accelerators. Next, we describe architectural elements that
are key for fast transformer inference. Finally, we examine various model
compression and fast decoding strategies in the same context.

摘要：強大的基礎模型，包括大型語言模型 (LLM)，配備 Transformer 架構，已經在各產業引進了生成式 AI 的新時代。產業和研究社群見證了大量基於這些基礎模型的新應用程式。此類應用程式包括問答、客戶服務、影像和影片生成，以及程式碼完成等。然而，由於模型參數數量達到數百億，其部署會在實際情況中產生禁止的推論成本和高延遲。因此，使用 AI 加速器進行經濟有效且快速的推論的需求越來越高。為此，我們的教學提供了一個全面的討論，說明使用 AI 加速器的互補推論最佳化技術。從基本 Transformer 架構和深度學習系統架構的概觀開始，我們深入探討快速且記憶體有效率的注意力運算的系統最佳化技術，並討論如何有效率地在 AI 加速器上實作它們。接下來，我們描述了對於快速 Transformer 推論至關重要的架構元素。最後，我們在相同的脈絡中檢視各種模型壓縮和快速解碼策略。

##### **Enhancing Training Efficiency Using Packing with Flash Attention**
2407.09105v1 by Achintya Kundu, Rhui Dih Lee, Laura Wynter, Raghu Kiran Ganti

Padding is often used in tuning LLM models by adding special tokens to
shorter training examples to match the length of the longest sequence in each
batch. While this ensures uniformity for batch processing, it introduces
inefficiencies by including irrelevant padding tokens in the computation and
wastes GPU resources. On the other hand, the Hugging Face SFT trainer offers
the option to use packing to combine multiple training examples up to the
maximum sequence length. This allows for maximal utilization of GPU resources.
However, without proper masking of each packed training example, attention will
not be computed correctly when using SFT trainer. We enable and then analyse
packing and Flash Attention with proper attention masking of each example and
show the benefits of this training paradigm.

摘要：填充通常用於調整 LLM 模型，方法是在較短的訓練範例中加入特殊符號，以符合每個批次中序列的最長長度。雖然這能確保批次處理的一致性，但它會在運算中加入不相關的填充符號，造成非效率，並浪費 GPU 資源。另一方面，Hugging Face SFT 訓練器提供使用封裝選項，將多個訓練範例組合成最長序列長度。這能讓 GPU 資源得到最大的利用。然而，若沒有適當地遮蔽每個封裝的訓練範例，在使用 SFT 訓練器時，注意力將無法正確地計算。我們啟用並分析封裝和閃光注意力，並適當地遮蔽每個範例的注意力，並展示這種訓練範例的好處。

##### **DANIEL: A fast Document Attention Network for Information Extraction and Labelling of handwritten documents**
2407.09103v1 by Thomas Constum, Pierrick Tranouez, Thierry Paquet

Information extraction from handwritten documents involves traditionally
three distinct steps: Document Layout Analysis, Handwritten Text Recognition,
and Named Entity Recognition. Recent approaches have attempted to integrate
these steps into a single process using fully end-to-end architectures. Despite
this, these integrated approaches have not yet matched the performance of
language models, when applied to information extraction in plain text. In this
paper, we introduce DANIEL (Document Attention Network for Information
Extraction and Labelling), a fully end-to-end architecture integrating a
language model and designed for comprehensive handwritten document
understanding. DANIEL performs layout recognition, handwriting recognition, and
named entity recognition on full-page documents. Moreover, it can
simultaneously learn across multiple languages, layouts, and tasks. For named
entity recognition, the ontology to be applied can be specified via the input
prompt. The architecture employs a convolutional encoder capable of processing
images of any size without resizing, paired with an autoregressive decoder
based on a transformer-based language model. DANIEL achieves competitive
results on four datasets, including a new state-of-the-art performance on RIMES
2009 and M-POPP for Handwriting Text Recognition, and IAM NER for Named Entity
Recognition. Furthermore, DANIEL is much faster than existing approaches.
  We provide the source code and the weights of the trained models at
\url{https://github.com/Shulk97/daniel}.

摘要：手寫文件中的資訊萃取傳統上包含三個不同的步驟：文件版面分析、手寫文字辨識和命名實體辨識。最近的方法已嘗試使用完全端到端架構將這些步驟整合到單一流程中。儘管如此，這些整合方法在應用於純文字資訊萃取時，仍無法與語言模型的效能相匹配。在本文中，我們介紹了 DANIEL（資訊萃取和標籤的文件注意力網路），這是一種完全端到端的架構，整合了語言模型，並設計用於全面理解手寫文件。DANIEL 對全頁文件執行版面辨識、手寫辨識和命名實體辨識。此外，它可以同時學習多種語言、版面和任務。對於命名實體辨識，可透過輸入提示指定要套用的本体。該架構採用一個卷積編碼器，能夠處理任何大小的影像而不需調整大小，並搭配一個基於Transformer語言模型的自迴歸解碼器。DANIEL 在四個資料集上取得了有競爭力的結果，包括在 RIMES 2009 和 M-POPP 上的手寫文字辨識的最新技術，以及在 IAM NER 上的命名實體辨識。此外，DANIEL 比現有方法快很多。我們在 \url{https://github.com/Shulk97/daniel} 提供訓練模型的原始碼和權重。

##### **Music Proofreading with RefinPaint: Where and How to Modify Compositions given Context**
2407.09099v1 by Pedro Ramoneda, Martin Rocamora, Taketo Akama

Autoregressive generative transformers are key in music generation, producing
coherent compositions but facing challenges in human-machine collaboration. We
propose RefinPaint, an iterative technique that improves the sampling process.
It does this by identifying the weaker music elements using a feedback model,
which then informs the choices for resampling by an inpainting model. This
dual-focus methodology not only facilitates the machine's ability to improve
its automatic inpainting generation through repeated cycles but also offers a
valuable tool for humans seeking to refine their compositions with automatic
proofreading. Experimental results suggest RefinPaint's effectiveness in
inpainting and proofreading tasks, demonstrating its value for refining music
created by both machines and humans. This approach not only facilitates
creativity but also aids amateur composers in improving their work.

摘要：自動迴歸生成式轉換器是音樂生成中的關鍵，產生連貫的組成，但在人機協作中面臨挑戰。我們提出 RefinPaint，這是一種改進抽樣過程的迭代技術。它通過使用反饋模型識別較弱的音樂元素來做到這一點，然後通知內插模型重新抽樣的選擇。這種雙重焦點方法不僅通過重複循環促進機器改進其自動內插生成的能力，而且還為尋求通過自動校對改進其組成的用戶提供了一個有價值的工具。實驗結果表明 RefinPaint 在內插和校對任務中的有效性，證明了其對機器和人類創作的音樂進行精煉的價值。這種方法不僅促進了創造力，而且還幫助業餘作曲家改進了他們的工作。

##### **STD-LLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with LLMs**
2407.09096v1 by Yiheng Huang, Xiaowei Mao, Shengnan Guo, Yubin Chen, Youfang Lin, Huaiyu Wan

Spatial-temporal forecasting and imputation are important for real-world
dynamic systems such as intelligent transportation, urban planning, and public
health. Most existing methods are tailored for individual forecasting or
imputation tasks but are not designed for both. Additionally, they are less
effective for zero-shot and few-shot learning. While large language models
(LLMs) have exhibited strong pattern recognition and reasoning abilities across
various tasks, including few-shot and zero-shot learning, their development in
understanding spatial-temporal data has been constrained by insufficient
modeling of complex correlations such as the temporal correlations, spatial
connectivity, non-pairwise and high-order spatial-temporal correlations within
data. In this paper, we propose STD-LLM for understanding both spatial and
temporal properties of \underline{S}patial-\underline{T}emporal
\underline{D}ata with \underline{LLM}s, which is capable of implementing both
spatial-temporal forecasting and imputation tasks. STD-LLM understands
spatial-temporal correlations via explicitly designed spatial and temporal
tokenizers as well as virtual nodes. Topology-aware node embeddings are
designed for LLMs to comprehend and exploit the topology structure of data.
Additionally, to capture the non-pairwise and higher-order correlations, we
design a hypergraph learning module for LLMs, which can enhance the overall
performance and improve efficiency. Extensive experiments demonstrate that
STD-LLM exhibits strong performance and generalization capabilities across the
forecasting and imputation tasks on various datasets. Moreover, STD-LLM
achieves promising results on both few-shot and zero-shot learning tasks.

摘要：時空預測和填補對於智慧交通、都市計畫和公共衛生等真實世界動態系統來說很重要。現有方法大多是針對個別預測或填補任務量身打造，但並非針對兩者設計。此外，它們對於零次學習和少次學習的效果較差。儘管大型語言模型 (LLM) 已在各種任務中展現強大的模式識別和推理能力，包括少次學習和零次學習，但它們在理解時空資料方面的發展受到限制，原因是對複雜關聯性的建模不足，例如資料中的時間關聯性、空間連通性、非成對和高階時空關聯性。在本文中，我們提出 STD-LLM，用於了解時空資料的空間和時間屬性，並具備執行時空預測和填補任務的能力。STD-LLM 透過明確設計的空間和時間標記化器以及虛擬節點來了解時空關聯性。拓撲感知節點嵌入是為 LLM 設計的，用於理解和利用資料的拓撲結構。此外，為了捕捉非成對和高階關聯性，我們為 LLM 設計了一個超圖學習模組，可以提升整體效能並改善效率。大量的實驗證明 STD-LLM 在各種資料集的預測和填補任務中展現出強大的效能和泛化能力。此外，STD-LLM 在少次學習和零次學習任務中都取得了令人滿意的成果。

##### **On Exact Bit-level Reversible Transformers Without Changing Architectures**
2407.09093v1 by Guoqiang Zhang, J. P. Lewis, W. B. Kleijn

In the literature, various reversible deep neural networks (DNN) models have
been proposed to reduce memory consumption or improve data-throughput in the
training process. However, almost all existing reversible DNNs either are
constrained to have special structures or are constructed by modifying the
original DNN architectures considerably to enable reversibility. In this work,
we propose exact bit-level reversible transformers without changing the
architectures in the inference procedure. The basic idea is to first treat each
transformer block as the Euler integration approximation for solving an
ordinary differential equation (ODE) and then incorporate the technique of
bidirectional integration approximation (BDIA) (see [26]) for BDIA-based
diffusion inversion) into the neural architecture together with activation
quantization to make it exactly bit-level reversible, referred to as
BDIA-transformer. In the training process, we let a hyper-parameter $\gamma$ in
BDIA-transformer randomly take one of the two values $\{0.5, -0.5\}$ per
transformer block for averaging two consecutive integration approximations,
which regularizes the models for improving the validation accuracy.
Light-weight side information per transformer block is required to be stored in
the forward process to account for binary quantization loss to enable exact
bit-level reversibility. In the inference procedure, the expectation
$\mathbb{E}(\gamma)=0$ is taken to make the resulting architectures of
BDIA-transformer be identical to transformers up to activation quantization.
Empirical study indicates that BDIA-transformers outperform their original
counterparts notably due to the regularization effect of the $\gamma$
parameter.

摘要：<paragraph>在文獻中，已提出各種可逆深度神經網路 (DNN) 模型，以減少訓練過程中記憶體消耗或改善資料傳輸量。然而，幾乎所有現有的可逆 DNN 皆受限於具有特殊結構，或透過大幅修改原始 DNN 架構來建構，以實現可逆性。在這項工作中，我們提出精確位元級可逆Transformer，而不會在推理程序中變更架構。基本概念是首先將每個Transformer區塊視為歐拉積分近似，用於求解常微分方程式 (ODE)，然後將雙向積分近似 (BDIA) 技術（請參閱 [26]）用於基於 BDIA 的擴散反演）納入神經架構，並結合啟用量化，使其成為精確位元級可逆，稱為 BDIA Transformer。在訓練過程中，我們讓 BDIA Transformer中的超參數 $\gamma$ 隨機取兩個值 $\{0.5, -0.5\}$ 中的一個，每個Transformer區塊用於平均兩個連續的積分近似，這會調整模型以提高驗證準確度。需要在前進過程中儲存每個Transformer區塊的輕量級側邊資訊，以考量二進制量化損失，以實現精確位元級可逆性。在推理過程中，取期望值 $\mathbb{E}(\gamma)=0$，以使 BDIA Transformer的最終架構與Transformer相同，直至啟用量化。實證研究表明，BDIA Transformer由於 $\gamma$ 參數的正則化效果，明顯優於其原始對應項。</paragraph>

##### **New Desiderata for Direct Preference Optimization**
2407.09072v1 by Xiangkun Hu, Tong He, David Wipf

Large language models in the past have typically relied on some form of
reinforcement learning with human feedback (RLHF) to better align model
responses with human preferences. However, because of oft-observed
instabilities when implementing these RLHF pipelines, various
reparameterization techniques have recently been introduced to sidestep the
need for separately learning an RL reward model. Instead, directly fine-tuning
for human preferences is achieved via the minimization of a single closed-form
training objective, a process originally referred to as direct preference
optimization (DPO) and followed by several notable descendants. Although
effective in certain real-world settings, we introduce new evaluation criteria
that serve to highlight unresolved shortcomings in the ability of existing DPO
methods to interpolate between a pre-trained reference model and empirical
measures of human preferences, as well as unavoidable trade-offs in how low-
and high-quality responses are regularized and constraints are handled. Our
insights then motivate an alternative DPO-like loss that provably mitigates
these limitations. Empirical results serve to corroborate notable aspects of
our analyses.

摘要：過去的大語言模型通常依賴某種形式的強化學習與人類回饋 (RLHF)，以更好地將模型回應與人類偏好相符。然而，由於在實作這些 RLHF 管線時經常觀察到不穩定性，因此最近已引入各種重新參數化技術來迴避需要單獨學習 RL 獎勵模型。相反地，直接微調以符合人類偏好是透過最小化單一閉合形式訓練目標來達成，這項程序最初稱為直接偏好最佳化 (DPO)，並有幾個著名的後續版本。儘管在某些實際環境中有效，但我們引入了新的評量準則，用於強調現有 DPO 方法在預訓練參考模型與人類偏好的經驗測量之間內插的能力中尚未解決的缺點，以及在低品質和高品質回應如何正規化和處理限制方面的不可避免的權衡。我們的見解接著激勵了一種替代的類似 DPO 的損失，可證明減輕了這些限制。經驗結果用於證實我們分析的顯著面向。

##### **From MIDI to Rich Tablatures: an Automatic Generative System incorporating Lead Guitarists' Fingering and Stylistic choices**
2407.09052v1 by Pierluigi Bontempi, Daniele Manerba, Alexandre D'Hooge, Sergio Canazza

Although the automatic identification of the optimal fingering for the
performance of melodies on fretted string instruments has already been
addressed (at least partially) in the literature, the specific case regarding
lead electric guitar requires a dedicated approach. We propose a system that
can generate, from simple MIDI melodies, tablatures enriched by fingerings,
articulations, and expressive techniques. The basic fingering is derived by
solving a constrained and multi-attribute optimization problem, which derives
the best position of the fretting hand, not just the finger used at each
moment.Then, by analyzing statistical data from the mySongBook corpus, the most
common clich{\'e}s and biomechanical feasibility, articulations, and expressive
techniques are introduced. Finally, the obtained output is converted into
MusicXML format, which allows for easy visualization and use. The quality of
the tablatures derived and the high configurability of the proposed approach
can have several impacts, in particular in the fields of instrumental teaching,
assisted composition and arranging, and computational expressive music
performance models.

摘要：雖然自動識別彈撥弦樂器旋律的最佳指法在文獻中已經（至少部分）被探討過，但有關電吉他主奏的特定案例需要專門的方法。我們提出一個系統，可以從簡單的 MIDI 旋律產生豐富的指法、運弓和表現技巧的樂譜。基本指法是透過解決約束和多屬性最佳化問題而衍生，這不僅衍生出按弦手的最佳位置，還有每時每刻所使用的指法。然後，透過分析 mySongBook 語料庫的統計數據，最常見的陳腔濫調和生物力學可行性、運弓和表現技巧會被引入。最後，獲得的輸出會轉換成 MusicXML 格式，這允許輕鬆視覺化和使用。衍生的樂譜品質和所提出的方法的高度可組態性可能會產生多種影響，特別是在樂器教學、輔助作曲和編曲，以及運算表現音樂表演模型的領域。

##### **Refusing Safe Prompts for Multi-modal Large Language Models**
2407.09050v1 by Zedian Shao, Hongbin Liu, Yuepeng Hu, Neil Zhenqiang Gong

Multimodal large language models (MLLMs) have become the cornerstone of
today's generative AI ecosystem, sparking intense competition among tech giants
and startups. In particular, an MLLM generates a text response given a prompt
consisting of an image and a question. While state-of-the-art MLLMs use safety
filters and alignment techniques to refuse unsafe prompts, in this work, we
introduce MLLM-Refusal, the first method that induces refusals for safe
prompts. In particular, our MLLM-Refusal optimizes a nearly-imperceptible
refusal perturbation and adds it to an image, causing target MLLMs to likely
refuse a safe prompt containing the perturbed image and a safe question.
Specifically, we formulate MLLM-Refusal as a constrained optimization problem
and propose an algorithm to solve it. Our method offers competitive advantages
for MLLM model providers by potentially disrupting user experiences of
competing MLLMs, since competing MLLM's users will receive unexpected refusals
when they unwittingly use these perturbed images in their prompts. We evaluate
MLLM-Refusal on four MLLMs across four datasets, demonstrating its
effectiveness in causing competing MLLMs to refuse safe prompts while not
affecting non-competing MLLMs. Furthermore, we explore three potential
countermeasures -- adding Gaussian noise, DiffPure, and adversarial training.
Our results show that they are insufficient: though they can mitigate
MLLM-Refusal's effectiveness, they also sacrifice the accuracy and/or
efficiency of the competing MLLM. The code is available at
https://github.com/Sadcardation/MLLM-Refusal.

摘要：多模態大型語言模型 (MLLM) 已成為
當今生成式 AI 生態系統的基石，在科技巨頭
和新創公司之間引發激烈的競爭。特別是，MLLM 會根據提示產生文字回應
包含圖像和問題。雖然最先進的 MLLM 使用安全
過濾器和對齊技術來拒絕不安全的提示，但在這項工作中，我們
介紹 MLLM-Refusal，這是第一個誘導拒絕安全的方法
提示。特別是，我們的 MLLM-Refusal 最佳化了幾乎無法察覺的
拒絕擾動，並將其新增到圖像中，導致目標 MLLM 可能
拒絕包含擾動圖像和安全問題的安全提示。
具體來說，我們將 MLLM-Refusal 公式化為受約束的最佳化問題
並提出一個演算法來解決它。我們的技術為 MLLM 模型提供商提供了競爭優勢
通過潛在破壞競爭 MLLM 的使用者體驗，因為競爭 MLLM 的使用者會收到意外的拒絕
當他們在提示中不知不覺地使用這些擾動圖像時。我們評估
四個資料集上的四個 MLLM 的 MLLM-Refusal，證明其
在導致競爭 MLLM 拒絕安全提示時不會影響非競爭 MLLM 的有效性。此外，我們探索三種潛在的
對策 -- 加入高斯雜訊、DiffPure 和對抗訓練。
我們的結果表明它們是不夠的：儘管它們可以減輕
MLLM-Refusal 的有效性，它們也犧牲了競爭 MLLM 的準確性和/或
效率。程式碼可在
https://github.com/Sadcardation/MLLM-Refusal。

##### **KUNPENG: An Embodied Large Model for Intelligent Maritime**
2407.09048v1 by Naiyao Wang, Tongbang Jiang, Ye Wang, Shaoyang Qiu, Bo Zhang, Xinqiang Xie, Munan Li, Chunliu Wang, Yiyang Wang, Hongxiang Ren, Ruili Wang, Hongjun Shan, Hongbo Liu

Intelligent maritime, as an essential component of smart ocean construction,
deeply integrates advanced artificial intelligence technology and data analysis
methods, which covers multiple aspects such as smart vessels, route
optimization, safe navigation, aiming to enhance the efficiency of ocean
resource utilization and the intelligence of transportation networks. However,
the complex and dynamic maritime environment, along with diverse and
heterogeneous large-scale data sources, present challenges for real-time
decision-making in intelligent maritime. In this paper, We propose KUNPENG, the
first-ever embodied large model for intelligent maritime in the smart ocean
construction, which consists of six systems. The model perceives multi-source
heterogeneous data for the cognition of environmental interaction and make
autonomous decision strategies, which are used for intelligent vessels to
perform navigation behaviors under safety and emergency guarantees and
continuously optimize power to achieve embodied intelligence in maritime. In
comprehensive maritime task evaluations, KUNPENG has demonstrated excellent
performance.

摘要：智慧海事作為智慧海洋建設的重要組成部分，深度融合先進的人工智慧技術與資料分析方法，涵蓋智慧船舶、航線優化、安全導航等多個方面，旨在提升海洋資源利用效率和運輸網路的智慧化。然而，複雜多變的海事環境，以及多元異質的大規模資料來源，對智慧海事的即時決策提出了挑戰。本文提出 KUNPENG，這是智慧海洋建設中第一個具備具身性的智慧海事大模型，由六大系統組成。該模型感知多源異質資料，用於認知環境交互並制定自主決策策略，用於智慧船舶在安全和緊急保障下執行導航行為，並持續優化動力，以實現海事的具身智慧。在綜合海事任務評估中，KUNPENG 已展現出優異的效能。

##### **Molecule Language Model with Augmented Pairs and Expertise Transfer**
2407.09043v1 by Namkyeong Lee, Siddhartha Laghuvarapu, Chanyoung Park, Jimeng Sun

Understanding the molecules and their textual descriptions via molecule
language models (MoLM) recently got a surge of interest among researchers.
However, unique challenges exist in the field of MoLM due to 1) a limited
amount of molecule-text paired data and 2) missing expertise that occurred due
to the specialized areas of focus among the experts. To this end, we propose
AMOLE, which 1) augments molecule-text pairs with structural similarity
preserving loss, and 2) transfers the expertise between the molecules.
Extensive experiments on various downstream tasks demonstrate the superiority
of AMOLE in comprehending molecules and their descriptions, highlighting its
potential for application in real-world drug discovery.

摘要：研究人員最近開始對透過分子語言模型 (MoLM) 了解分子及其文字描述產生濃厚興趣。
不過，由於 1) 分子文字配對資料量有限，以及 2) 專家們專注於特定領域而導致專業知識不足，MoLM 領域存在著獨特的挑戰。為了解決這個問題，我們提出了 AMOLE，它 1) 透過結構相似性保留損失來擴充分子文字配對，以及 2) 在分子間轉移專業知識。針對各種下游任務進行的廣泛實驗證明了 AMOLE 在理解分子及其描述方面的優越性，突顯了它在現實世界藥物發現中的應用潛力。

##### **Overcoming Catastrophic Forgetting in Tabular Data Classification: A Pseudorehearsal-based approach**
2407.09039v1 by Pablo García-Santaclara, Bruno Fernández-Castro, Rebeca P. Díaz-Redondo

Continual learning (CL) poses the important challenge of adapting to evolving
data distributions without forgetting previously acquired knowledge while
consolidating new knowledge. In this paper, we introduce a new methodology,
coined as Tabular-data Rehearsal-based Incremental Lifelong Learning framework
(TRIL3), designed to address the phenomenon of catastrophic forgetting in
tabular data classification problems. TRIL3 uses the prototype-based
incremental generative model XuILVQ to generate synthetic data to preserve old
knowledge and the DNDF algorithm, which was modified to run in an incremental
way, to learn classification tasks for tabular data, without storing old
samples. After different tests to obtain the adequate percentage of synthetic
data and to compare TRIL3 with other CL available proposals, we can conclude
that the performance of TRIL3 outstands other options in the literature using
only 50% of synthetic data.

摘要：持續學習 (CL) 提出了一個重要的挑戰，即在鞏固新知識的同時適應不斷變化的資料分佈，而不忘記先前獲得的知識。在本文中，我們介紹了一種新方法，稱為表格資料排練式增量終身學習架構 (TRIL3)，旨在解決表格資料分類問題中災難性遺忘的現象。TRIL3 使用基於原型的增量生成模型 XuILVQ 生成合成資料以保留舊知識，以及修改為以增量方式運行的 DNDF 演算法，以學習表格資料的分類任務，而無需儲存舊樣本。在進行不同的測試以獲得足夠比例的合成資料並將 TRIL3 與其他可用的 CL 建議進行比較後，我們可以得出結論，TRIL3 的效能優於文獻中僅使用 50% 合成資料的其他選項。

##### **SpreadsheetLLM: Encoding Spreadsheets for Large Language Models**
2407.09025v1 by Yuzhang Tian, Jianbo Zhao, Haoyu Dong, Junyu Xiong, Shiyu Xia, Mengyu Zhou, Yun Lin, José Cambronero, Yeye He, Shi Han, Dongmei Zhang

Spreadsheets, with their extensive two-dimensional grids, various layouts,
and diverse formatting options, present notable challenges for large language
models (LLMs). In response, we introduce SpreadsheetLLM, pioneering an
efficient encoding method designed to unleash and optimize LLMs' powerful
understanding and reasoning capability on spreadsheets. Initially, we propose a
vanilla serialization approach that incorporates cell addresses, values, and
formats. However, this approach was limited by LLMs' token constraints, making
it impractical for most applications. To tackle this challenge, we develop
SheetCompressor, an innovative encoding framework that compresses spreadsheets
effectively for LLMs. It comprises three modules: structural-anchor-based
compression, inverse index translation, and data-format-aware aggregation. It
significantly improves performance in spreadsheet table detection task,
outperforming the vanilla approach by 25.6% in GPT4's in-context learning
setting. Moreover, fine-tuned LLM with SheetCompressor has an average
compression ratio of 25 times, but achieves a state-of-the-art 78.9% F1 score,
surpassing the best existing models by 12.3%. Finally, we propose Chain of
Spreadsheet for downstream tasks of spreadsheet understanding and validate in a
new and demanding spreadsheet QA task. We methodically leverage the inherent
layout and structure of spreadsheets, demonstrating that SpreadsheetLLM is
highly effective across a variety of spreadsheet tasks.

摘要：<paragraph>試算表及其廣泛的二維格線、各式配置和多樣格式選項，對大型語言模型 (LLM) 而言構成顯著的挑戰。為了解決此問題，我們引進了 SpreadsheetLLM，開創一種高效編碼方法，旨在釋放和優化 LLM 在試算表上的強大理解和推理能力。最初，我們提出了一個香草序列化方法，其中包含儲存格地址、值和格式。然而，此方法受到 LLM 令牌限制，這使得它不適用於大多數應用程式。為了應對此挑戰，我們開發了 SheetCompressor，這是一個創新的編碼架構，可有效壓縮 LLM 的試算表。它包含三個模組：基於結構錨點的壓縮、反向索引轉換和資料格式感知聚合。它顯著改善了試算表表格偵測任務的效能，在 GPT4 的情境學習設定中，比香草方法提升了 25.6%。此外，使用 SheetCompressor 微調的 LLM 平均壓縮比為 25 倍，但達到了最先進的 78.9% F1 分數，比現有最佳模型高出 12.3%。最後，我們提出了試算表鏈，用於試算表理解的下游任務，並在一個新的、要求嚴苛的試算表問答任務中驗證。我們有條理地利用試算表的內在配置和結構，證明 SpreadsheetLLM 在各種試算表任務中都非常有效。</paragraph>

##### **3M-Health: Multimodal Multi-Teacher Knowledge Distillation for Mental Health Detection**
2407.09020v1 by Rina Carines Cabral, Siwen Luo, Soyeon Caren Han, Josiah Poon

The significance of mental health classification is paramount in contemporary
society, where digital platforms serve as crucial sources for monitoring
individuals' well-being. However, existing social media mental health datasets
primarily consist of text-only samples, potentially limiting the efficacy of
models trained on such data. Recognising that humans utilise cross-modal
information to comprehend complex situations or issues, we present a novel
approach to address the limitations of current methodologies. In this work, we
introduce a Multimodal and Multi-Teacher Knowledge Distillation model for
Mental Health Classification, leveraging insights from cross-modal human
understanding. Unlike conventional approaches that often rely on simple
concatenation to integrate diverse features, our model addresses the challenge
of appropriately representing inputs of varying natures (e.g., texts and
sounds). To mitigate the computational complexity associated with integrating
all features into a single model, we employ a multimodal and multi-teacher
architecture. By distributing the learning process across multiple teachers,
each specialising in a particular feature extraction aspect, we enhance the
overall mental health classification performance. Through experimental
validation, we demonstrate the efficacy of our model in achieving improved
performance. All relevant codes will be made available upon publication.

摘要：心理健康分類在當代社會中至關重要，數位平台作為監控個人福祉的關鍵來源。然而，現有的社群媒體心理健康資料集主要由純文字範例組成，這可能會限制在這些資料上訓練的模型效能。我們認知到人類利用跨模式資訊來理解複雜的情況或問題，因此我們提出了一種新穎的方法來解決當前方法的限制。在這項工作中，我們引入了一個多模態、多教師知識蒸餾模型，用於心理健康分類，利用跨模式人類理解的見解。與通常依賴於簡單串接來整合不同特徵的傳統方法不同，我們的模型解決了適當地表示不同性質輸入（例如，文字和聲音）的挑戰。為了減輕將所有特徵整合到單一模型中相關的運算複雜性，我們採用了多模態和多教師架構。透過將學習過程分配給多位教師，每位教師專精於特定的特徵萃取面向，我們增強了整體心理健康分類效能。透過實驗驗證，我們證明了我們的模型在達成改進效能方面的效能。所有相關程式碼將在發表後提供。

##### **Heterogeneous Subgraph Network with Prompt Learning for Interpretable Depression Detection on Social Media**
2407.09019v1 by Chen Chen, Mingwei Li, Fenghuan Li, Haopeng Chen, Yuankun Lin

Massive social media data can reflect people's authentic thoughts, emotions,
communication, etc., and therefore can be analyzed for early detection of
mental health problems such as depression. Existing works about early
depression detection on social media lacked interpretability and neglected the
heterogeneity of social media data. Furthermore, they overlooked the global
interaction among users. To address these issues, we develop a novel method
that leverages a Heterogeneous Subgraph Network with Prompt Learning(HSNPL) and
contrastive learning mechanisms. Specifically, prompt learning is employed to
map users' implicit psychological symbols with excellent interpretability while
deep semantic and diverse behavioral features are incorporated by a
heterogeneous information network. Then, the heterogeneous graph network with a
dual attention mechanism is constructed to model the relationships among
heterogeneous social information at the feature level. Furthermore, the
heterogeneous subgraph network integrating subgraph attention and
self-supervised contrastive learning is developed to explore complicated
interactions among users and groups at the user level. Extensive experimental
results demonstrate that our proposed method significantly outperforms
state-of-the-art methods for depression detection on social media.

摘要：龐大的社群媒體資料可以反映人們真實的想法、情緒、溝通等，因此可以分析這些資料，以早期偵測憂鬱症等心理健康問題。現有關於社群媒體上早期憂鬱症偵測的研究缺乏可解釋性，且忽略了社群媒體資料的異質性。此外，這些研究忽視了使用者之間的整體互動。為了解決這些問題，我們開發了一種新穎的方法，這種方法利用帶有提示學習（HSNPL）的異質子圖網路和對比學習機制。具體而言，提示學習被用於繪製使用者具有出色可解釋性的隱含心理符號，同時通過異質資訊網路整合了深層語義和多樣化的行為特徵。然後，構建具有雙重注意機制的異質圖網路，以在特徵層級建模異質社群資訊之間的關係。此外，開發了整合子圖注意和自我監督對比學習的異質子圖網路，以探索使用者和群組之間在使用者層級的複雜互動。大量的實驗結果表明，我們提出的方法在社群媒體上的憂鬱症偵測方面顯著優於最先進的方法。

##### **Static Analysis of Logic Programs via Boolean Networks**
2407.09015v1 by Van-Giang Trinh, Belaid Benhamou

Answer Set Programming (ASP) is a declarative problem solving paradigm that
can be used to encode a combinatorial problem as a logic program whose stable
models correspond to the solutions of the considered problem. ASP has been
widely applied to various domains in AI and beyond. The question "What can be
said about stable models of a logic program from its static information?" has
been investigated and proved useful in many circumstances. In this work, we
dive into this direction more deeply by making the connection between a logic
program and a Boolean network, which is a prominent modeling framework with
applications to various areas. The proposed connection can bring the existing
results in the rich history on static analysis of Boolean networks to explore
and prove more theoretical results on ASP, making it become a unified and
powerful tool to further study the static analysis of ASP. In particular, the
newly obtained insights have the potential to benefit many problems in the
field of ASP.

摘要：回答設定程式（ASP）是一種宣告式問題解決範例，可將組合問題編碼為邏輯程式，其穩定模型對應於所考慮問題的解。ASP 已廣泛應用於 AI 及其他領域。問題「從邏輯程式的靜態資訊中，可得知關於穩定模型的哪些資訊？」已受到探討，並證明在許多情況下很有用。在這項工作中，我們透過建立邏輯程式與布林網路（一種重要的建模架構，可應用於各種領域）之間的關聯，更深入地探討這個方向。提出的關聯可以將布林網路靜態分析中豐富的歷史結果應用於 ASP，探索並證明更多理論結果，使其成為進一步研究 ASP 靜態分析的統一且強大的工具。特別是，新獲得的見解有可能使 ASP 領域中的許多問題受益。

##### **CompAct: Compressing Retrieved Documents Actively for Question Answering**
2407.09014v1 by Chanwoong Yoon, Taewhoo Lee, Hyeon Hwang, Minbyul Jeong, Jaewoo Kang

Retrieval-augmented generation supports language models to strengthen their
factual groundings by providing external contexts. However, language models
often face challenges when given extensive information, diminishing their
effectiveness in solving questions. Context compression tackles this issue by
filtering out irrelevant information, but current methods still struggle in
realistic scenarios where crucial information cannot be captured with a
single-step approach. To overcome this limitation, we introduce CompAct, a
novel framework that employs an active strategy to condense extensive documents
without losing key information. Our experiments demonstrate that CompAct brings
significant improvements in both performance and compression rate on multi-hop
question-answering (QA) benchmarks. CompAct flexibly operates as a
cost-efficient plug-in module with various off-the-shelf retrievers or readers,
achieving exceptionally high compression rates (47x).

摘要：擷取增強生成支援語言模型強化其事實依據，提供外部脈絡。然而，語言模型在獲得大量資訊後，經常面臨挑戰，降低其解決問題的效能。脈絡壓縮透過濾出無關資訊來解決此問題，但目前的方法在關鍵資訊無法透過單步驟方法擷取的實際情況中仍面臨困難。為了克服此限制，我們引進 CompAct，一種採用主動策略來濃縮大量文件而不遺失關鍵資訊的新穎架構。我們的實驗證明，CompAct 在多跳問答 (QA) 基準上，在效能和壓縮率方面都有顯著的進步。CompAct 可靈活地作為具有成本效益的外掛模組，搭配各種現成的擷取器或閱讀器，達到極高的壓縮率 (47x)。

##### **Procedural Content Generation via Generative Artificial Intelligence**
2407.09013v1 by Xinyu Mao, Wanli Yu, Kazunori D Yamada, Michael R. Zielewski

The attempt to utilize machine learning in PCG has been made in the past. In
this survey paper, we investigate how generative artificial intelligence (AI),
which saw a significant increase in interest in the mid-2010s, is being used
for PCG. We review applications of generative AI for the creation of various
types of content, including terrains, items, and even storylines. While
generative AI is effective for PCG, one significant issues it faces is that
building high-performance generative AI requires vast amounts of training data.
Because content generally highly customized, domain-specific training data is
scarce, and straightforward approaches to generative AI models may not work
well. For PCG research to advance further, issues related to limited training
data must be overcome. Thus, we also give special consideration to research
that addresses the challenges posed by limited training data.

摘要：過去曾嘗試在 PCG 中利用機器學習。在
這篇調查報告中，我們探討生成式人工智慧 (AI) 如何被用於
PCG，生成式 AI 在 2010 年代中期引起了極大的興趣。我們回顧了
生成式 AI 在各種內容創作上的應用，包括地形、物品，甚至故事情節。雖然
生成式 AI 對於 PCG 來說很有效，但它面臨一個重大問題，那就是
建立高性能生成式 AI 需要大量的訓練資料。由於內容通常高度客製化，因此特定領域的訓練資料很稀少，而生成式 AI 模型的直接方法可能無法
發揮作用。若要讓 PCG 研究進一步發展，必須克服與訓練資料有限相關的問題。因此，我們也特別考量了解決訓練資料有限所帶來的挑戰的研究。

##### **TCAN: Animating Human Images with Temporally Consistent Pose Guidance using Diffusion Models**
2407.09012v1 by Jeongho Kim, Min-Jung Kim, Junsoo Lee, Jaegul Choo

Pose-driven human-image animation diffusion models have shown remarkable
capabilities in realistic human video synthesis. Despite the promising results
achieved by previous approaches, challenges persist in achieving temporally
consistent animation and ensuring robustness with off-the-shelf pose detectors.
In this paper, we present TCAN, a pose-driven human image animation method that
is robust to erroneous poses and consistent over time. In contrast to previous
methods, we utilize the pre-trained ControlNet without fine-tuning to leverage
its extensive pre-acquired knowledge from numerous pose-image-caption pairs. To
keep the ControlNet frozen, we adapt LoRA to the UNet layers, enabling the
network to align the latent space between the pose and appearance features.
Additionally, by introducing an additional temporal layer to the ControlNet, we
enhance robustness against outliers of the pose detector. Through the analysis
of attention maps over the temporal axis, we also designed a novel temperature
map leveraging pose information, allowing for a more static background.
Extensive experiments demonstrate that the proposed method can achieve
promising results in video synthesis tasks encompassing various poses, like
chibi. Project Page: https://eccv2024tcan.github.io/

摘要：<paragraph>以姿勢為主的圖像動畫擴散模型在逼真的影片合成中展現出非凡的能力。儘管先前的技術已獲得可觀的成果，但仍面臨著在時間上保持動畫一致性，以及確保與現成的姿勢檢測器相容的挑戰。在本文中，我們提出了 TCAN，這是一種對錯誤姿勢具有魯棒性且隨著時間保持一致的姿勢驅動人像動畫方法。與先前的技術不同，我們利用預先訓練的 ControlNet，而無需微調，以利用其從大量姿勢-圖像-標題對中獲得的豐富預先獲取的知識。為了使 ControlNet 保持凍結，我們將 LoRA 調整到 UNet 層，使網路能夠在姿勢和外觀特徵之間對齊潛在空間。此外，透過在 ControlNet 中引入一個額外的時間層，我們增強了對姿勢檢測器異常值的魯棒性。透過對時間軸上的注意力圖進行分析，我們還設計了一種利用姿勢資訊的新型溫度圖，允許更靜態的背景。大量的實驗證明，所提出的方法可以在涵蓋各種姿勢（如 chibi）的影片合成任務中獲得有希望的結果。專案頁面：https://eccv2024tcan.github.io/</paragraph>

##### **One Stone, Four Birds: A Comprehensive Solution for QA System Using Supervised Contrastive Learning**
2407.09011v1 by Bo Wang, Tsunenori Mine

This paper presents a novel and comprehensive solution to enhance both the
robustness and efficiency of question answering (QA) systems through supervised
contrastive learning (SCL). Training a high-performance QA system has become
straightforward with pre-trained language models, requiring only a small amount
of data and simple fine-tuning. However, despite recent advances, existing QA
systems still exhibit significant deficiencies in functionality and training
efficiency. We address the functionality issue by defining four key tasks: user
input intent classification, out-of-domain input detection, new intent
discovery, and continual learning. We then leverage a unified SCL-based
representation learning method to efficiently build an intra-class compact and
inter-class scattered feature space, facilitating both known intent
classification and unknown intent detection and discovery. Consequently, with
minimal additional tuning on downstream tasks, our approach significantly
improves model efficiency and achieves new state-of-the-art performance across
all tasks.

摘要：本文提出了一個新穎且全面的解決方案，透過監督式對比學習 (SCL) 來增強問答 (QA) 系統的穩健性和效率。使用預先訓練好的語言模型來訓練高性能 QA 系統已變得簡單明瞭，只需要少量資料和簡單的微調。然而，儘管有最近的進展，現有的 QA 系統在功能性和訓練效率方面仍存在顯著的缺陷。我們透過定義四個關鍵任務來解決功能問題：使用者輸入意圖分類、領域外輸入偵測、新意圖發現和持續學習。然後，我們利用統一的基於 SCL 的表示學習方法來有效建立類內緊湊和類間分散的特徵空間，促進已知意圖分類和未知意圖偵測和發現。因此，透過對下游任務進行最小的額外調整，我們的做法顯著提高了模型效率，並在所有任務中實現了新的最先進性能。

##### **Benchmarking Language Model Creativity: A Case Study on Code Generation**
2407.09007v1 by Yining Lu, Dixuan Wang, Tianjian Li, Dongwei Jiang, Daniel Khashabi

As LLMs become increasingly prevalent, it is interesting to consider how
``creative'' these models can be. From cognitive science, creativity consists
of at least two key characteristics: \emph{convergent} thinking (purposefulness
to achieve a given goal) and \emph{divergent} thinking (adaptability to new
environments or constraints) \citep{runco2003critical}. In this work, we
introduce a framework for quantifying LLM creativity that incorporates the two
characteristics. This is achieved by (1) Denial Prompting pushes LLMs to come
up with more creative solutions to a given problem by incrementally imposing
new constraints on the previous solution, compelling LLMs to adopt new
strategies, and (2) defining and computing the NeoGauge metric which examines
both convergent and divergent thinking in the generated creative responses by
LLMs. We apply the proposed framework on Codeforces problems, a natural data
source for collecting human coding solutions. We quantify NeoGauge for various
proprietary and open-source models and find that even the most creative model,
GPT-4, still falls short of demonstrating human-like creativity. We also
experiment with advanced reasoning strategies (MCTS, self-correction, etc.) and
observe no significant improvement in creativity. As a by-product of our
analysis, we release NeoCoder dataset for reproducing our results on future
models.

摘要：隨著 LLM 變得越來越普遍，思考這些模型可以有多「有創意」是一件很有趣的事。從認知科學的角度來看，創意至少包含兩個關鍵特徵：\emph{收斂}思考（實現特定目標的目標性）和\emph{發散}思考（適應新環境或限制）\citep{runco2003critical}。在本文中，我們介紹了一個量化 LLM 創意的框架，其中包含這兩個特徵。這可以透過 (1) 否定提示讓 LLM 透過逐步對先前的解決方案施加新的限制，提出更多有創意的解決方案來解決特定問題，迫使 LLM 採用新的策略，以及 (2) 定義和計算 NeoGauge 指標，它會檢查 LLM 生成的創意回應中的收斂和發散思考。我們在 Codeforces 問題上應用所提出的框架，這是收集人類編碼解決方案的自然資料來源。我們量化了各種專有和開源模型的 NeoGauge，發現即使是最有創意的模型 GPT-4，仍未達到人類般的創意。我們也嘗試了進階推理策略（MCTS、自我修正等），並觀察到創意沒有顯著改善。作為我們分析的副產品，我們發布了 NeoCoder 資料集，以便在未來的模型上重現我們的結果。

##### **Introducing VaDA: Novel Image Segmentation Model for Maritime Object Segmentation Using New Dataset**
2407.09005v1 by Yongjin Kim, Jinbum Park, Sanha Kang, Hanguen Kim

The maritime shipping industry is undergoing rapid evolution driven by
advancements in computer vision artificial intelligence (AI). Consequently,
research on AI-based object recognition models for maritime transportation is
steadily growing, leveraging advancements in sensor technology and computing
performance. However, object recognition in maritime environments faces
challenges such as light reflection, interference, intense lighting, and
various weather conditions. To address these challenges, high-performance deep
learning algorithms tailored to maritime imagery and high-quality datasets
specialized for maritime scenes are essential. Existing AI recognition models
and datasets have limited suitability for composing autonomous navigation
systems. Therefore, in this paper, we propose a Vertical and Detail Attention
(VaDA) model for maritime object segmentation and a new model evaluation
method, the Integrated Figure of Calculation Performance (IFCP), to verify its
suitability for the system in real-time. Additionally, we introduce a benchmark
maritime dataset, OASIs (Ocean AI Segmentation Initiatives) to standardize
model performance evaluation across diverse maritime environments. OASIs
dataset and details are available at our website:
https://www.navlue.com/dataset

摘要：航運業正經歷快速演進，這要歸功於電腦視覺人工智慧 (AI) 的進步。因此，對於海運的人工智慧基礎物件辨識模型的研究正穩定成長，並利用感測器技術和運算效能的進步。然而，在海運環境中辨識物件會面臨光線反射、干擾、強光和各種天氣狀況等挑戰。為了應對這些挑戰，針對海運影像量身打造的高效能深度學習演算法和專門用於海運場景的高品質資料集至關重要。現有的 AI 辨識模型和資料集對於組成自主導航系統的適用性有限。因此，在本文中，我們提出一個垂直和細節注意 (VaDA) 模型，用於海運物件分割，以及一個新的模型評估方法，即計算效能的整合數值 (IFCP)，以驗證其在系統中的即時適用性。此外，我們引進一個基準海運資料集 OASIs（海洋 AI 分割計畫），以標準化不同海運環境中的模型效能評估。OASIs 資料集和詳細資訊可在我們的網站上取得：
https://www.navlue.com/dataset

##### **Enhancing Few-Shot Stock Trend Prediction with Large Language Models**
2407.09003v1 by Yiqi Deng, Xingwei He, Jiahao Hu, Siu-Ming Yiu

The goal of stock trend prediction is to forecast future market movements for
informed investment decisions. Existing methods mostly focus on predicting
stock trends with supervised models trained on extensive annotated data.
However, human annotation can be resource-intensive and the annotated data are
not readily available. Inspired by the impressive few-shot capability of Large
Language Models (LLMs), we propose using LLMs in a few-shot setting to overcome
the scarcity of labeled data and make prediction more feasible to investors.
Previous works typically merge multiple financial news for predicting stock
trends, causing two significant problems when using LLMs: (1) Merged news
contains noise, and (2) it may exceed LLMs' input limits, leading to
performance degradation. To overcome these issues, we propose a two-step method
'denoising-then-voting'. Specifically, we introduce an `Irrelevant' category,
and predict stock trends for individual news instead of merged news. Then we
aggregate these predictions using majority voting. The proposed method offers
two advantages: (1) Classifying noisy news as irrelevant removes its impact on
the final prediction. (2) Predicting for individual news mitigates LLMs' input
length limits. Our method achieves 66.59% accuracy in S&P 500, 62.17% in
CSI-100, and 61.17% in HK stock prediction, outperforming the standard few-shot
counterparts by around 7%, 4%, and 4%. Furthermore, our proposed method
performs on par with state-of-the-art supervised methods.

摘要：股票趨勢預測的目標是預測未來的市場動態，以做出明智的投資決策。現有方法大多專注於使用經過大量註解數據訓練的監督式模型來預測股票趨勢。然而，人工註解可能需要大量資源，且註解數據並不容易取得。受到大型語言模型 (LLM) 令人印象深刻的少量樣本能力的啟發，我們建議在少量樣本設定中使用 LLM 來克服標籤數據的稀少性，並使投資者更容易進行預測。先前的研究通常會合併多則財經新聞來預測股票趨勢，在使用 LLM 時會造成兩個重大問題：(1) 合併的新聞包含雜訊，(2) 它可能會超過 LLM 的輸入限制，導致效能下降。為了克服這些問題，我們提出了一種兩步驟方法「先去噪再投票」。具體來說，我們引入了「無關」類別，並針對個別新聞預測股票趨勢，而不是合併新聞。然後，我們使用多數決來彙總這些預測。所提出的方法提供了兩個優點：(1) 將有雜訊的新聞分類為無關，可以消除其對最終預測的影響。(2) 針對個別新聞進行預測可以緩解 LLM 的輸入長度限制。我們的模型在 S&P 500 中達到 66.59% 的準確度，在 CSI-100 中達到 62.17%，在港股預測中達到 61.17%，比標準的少量樣本對應模型高出約 7%、4% 和 4%。此外，我們提出的方法與現有監督式方法的表現相當。

##### **Self-Prompt Tuning: Enable Autonomous Role-Playing in LLMs**
2407.08995v1 by Aobo Kong, Shiwan Zhao, Hao Chen, Qicheng Li, Yong Qin, Ruiqi Sun, Xin Zhou, Jiaming Zhou, Haoqin Sun

Recent advancements in LLMs have showcased their remarkable role-playing
capabilities, able to accurately simulate the dialogue styles and cognitive
processes of various roles based on different instructions and contexts.
Studies indicate that assigning LLMs the roles of experts, a strategy known as
role-play prompting, can enhance their performance in the corresponding
domains. However, the prompt needs to be manually designed for the given
problem, requiring certain expertise and iterative modifications. To this end,
we propose self-prompt tuning, making LLMs themselves generate role-play
prompts through fine-tuning. Leveraging the LIMA dataset as our foundational
corpus, we employ GPT-4 to annotate role-play prompts for each data points,
resulting in the creation of the LIMA-Role dataset. We then fine-tune LLMs like
Llama-2-7B and Mistral-7B on LIMA-Role. Consequently, the self-prompt tuned
LLMs can automatically generate expert role prompts for any given question. We
extensively evaluate self-prompt tuned LLMs on widely used NLP benchmarks and
open-ended question test. Our empirical results illustrate that self-prompt
tuned LLMs outperform standard instruction tuned baselines across most
datasets. This highlights the great potential of utilizing fine-tuning to
enable LLMs to self-prompt, thereby automating complex prompting strategies. We
release the dataset, models, and code at this
\href{https://anonymous.4open.science/r/Self-Prompt-Tuning-739E/}{url}.

摘要：最近在大型语言模型 (LLM) 上的进步展示了其卓越的角色扮演能力，能够根据不同的指令和语境准确模拟各种角色的对话风格和认知过程。研究表明，将专家角色分配给 LLM（一种称为角色扮演提示的策略）可以提高其在相应领域的性能。然而，提示需要针对给定的问题手动设计，需要一定的专业知识和迭代修改。为此，我们提出了自提示调整，使 LLM 本身通过微调生成角色扮演提示。利用 LIMA 数据集作为我们的基础语料库，我们使用 GPT-4 为每个数据点注释角色扮演提示，从而创建了 LIMA-Role 数据集。然后，我们在 LIMA-Role 上对 Llama-2-7B 和 Mistral-7B 等 LLM 进行微调。因此，自提示调整的 LLM 可以针对任何给定问题自动生成专家角色提示。我们在广泛使用的 NLP 基准和开放式问题测试中对自提示调整的 LLM 进行了广泛评估。我们的实证结果表明，自提示调整的 LLM 在大多数数据集上优于标准指令调整的基线。这凸显了利用微调使 LLM 自提示的巨大潜力，从而自动化复杂的提示策略。我们在此发布数据集、模型和代码：\href{https://anonymous.4open.science/r/Self-Prompt-Tuning-739E/}{url}。

##### **Optimization of DNN-based speaker verification model through efficient quantization technique**
2407.08991v1 by Yeona Hong, Woo-Jin Chung, Hong-Goo Kang

As Deep Neural Networks (DNNs) rapidly advance in various fields, including
speech verification, they typically involve high computational costs and
substantial memory consumption, which can be challenging to manage on mobile
systems. Quantization of deep models offers a means to reduce both
computational and memory expenses. Our research proposes an optimization
framework for the quantization of the speaker verification model. By analyzing
performance changes and model size reductions in each layer of a pre-trained
speaker verification model, we have effectively minimized performance
degradation while significantly reducing the model size. Our quantization
algorithm is the first attempt to maintain the performance of the
state-of-the-art pre-trained speaker verification model, ECAPATDNN, while
significantly compressing its model size. Overall, our quantization approach
resulted in reducing the model size by half, with an increase in EER limited to
0.07%.

摘要：隨著深度神經網路 (DNN) 在各種領域快速發展，包括語音驗證，它們通常涉及高運算成本和大量的記憶體消耗，這在行動系統上可能難以管理。深度模型的量化提供了一種方法來減少運算和記憶體的開銷。我們的研究提出了一個用於量化說話者驗證模型的最佳化架構。透過分析預先訓練的說話者驗證模型中每一層的效能變更和模型大小的縮減，我們有效地將效能降低降到最低，同時大幅減少模型大小。我們的量化演算法是首次嘗試維持最先進的預先訓練說話者驗證模型 ECAPATDNN 的效能，同時大幅壓縮其模型大小。總體而言，我們的量化方法將模型大小減少了一半，而 EER 的增加僅限於 0.07%。

##### **Dynamic neural network with memristive CIM and CAM for 2D and 3D vision**
2407.08990v1 by Yue Zhang, Woyu Zhang, Shaocong Wang, Ning Lin, Yifei Yu, Yangu He, Bo Wang, Hao Jiang, Peng Lin, Xiaoxin Xu, Xiaojuan Qi, Zhongrui Wang, Xumeng Zhang, Dashan Shang, Qi Liu, Kwang-Ting Cheng, Ming Liu

The brain is dynamic, associative and efficient. It reconfigures by
associating the inputs with past experiences, with fused memory and processing.
In contrast, AI models are static, unable to associate inputs with past
experiences, and run on digital computers with physically separated memory and
processing. We propose a hardware-software co-design, a semantic memory-based
dynamic neural network (DNN) using memristor. The network associates incoming
data with the past experience stored as semantic vectors. The network and the
semantic memory are physically implemented on noise-robust ternary
memristor-based Computing-In-Memory (CIM) and Content-Addressable Memory (CAM)
circuits, respectively. We validate our co-designs, using a 40nm memristor
macro, on ResNet and PointNet++ for classifying images and 3D points from the
MNIST and ModelNet datasets, which not only achieves accuracy on par with
software but also a 48.1% and 15.9% reduction in computational budget.
Moreover, it delivers a 77.6% and 93.3% reduction in energy consumption.

摘要：大腦是動態、聯想且有效率的。它透過將輸入與過去的經驗、融合的記憶和處理聯想起來，重新配置。
相反地，AI 模型是靜態的，無法將輸入與過去的經驗聯想起來，並在具有物理分離的記憶體和處理功能的數位電腦上執行。我們提出一個硬體軟體共同設計，一個使用憶阻器的語義記憶體為基礎的動態神經網路 (DNN)。網路將輸入資料與儲存在語義向量中的過去經驗聯想起來。網路和語義記憶體分別在耐雜訊三元憶阻器為基礎的記憶體運算 (CIM) 和內容可尋址記憶體 (CAM) 電路中實體實作。我們使用 40nm 憶阻器巨集，在 ResNet 和 PointNet++ 上驗證我們的共同設計，以分類來自 MNIST 和 ModelNet 資料集的影像和 3D 點，不僅達到與軟體相當的準確度，還減少了 48.1% 和 15.9% 的運算預算。
此外，它還減少了 77.6% 和 93.3% 的能耗。

##### **Robustness of LLMs to Perturbations in Text**
2407.08989v1 by Ayush Singh, Navpreet Singh, Shubham Vatsal

Having a clean dataset has been the foundational assumption of most natural
language processing (NLP) systems. However, properly written text is rarely
found in real-world scenarios and hence, oftentimes invalidates the
aforementioned foundational assumption. Recently, Large language models (LLMs)
have shown impressive performance, but can they handle the inevitable noise in
real-world data? This work tackles this critical question by investigating
LLMs' resilience against morphological variations in text. To that end, we
artificially introduce varying levels of noise into a diverse set of datasets
and systematically evaluate LLMs' robustness against the corrupt variations of
the original text. Our findings show that contrary to popular beliefs,
generative LLMs are quiet robust to noisy perturbations in text. This is a
departure from pre-trained models like BERT or RoBERTa whose performance has
been shown to be sensitive to deteriorating noisy text. Additionally, we test
LLMs' resilience on multiple real-world benchmarks that closely mimic commonly
found errors in the wild. With minimal prompting, LLMs achieve a new
state-of-the-art on the benchmark tasks of Grammar Error Correction (GEC) and
Lexical Semantic Change (LSC). To empower future research, we also release a
dataset annotated by humans stating their preference for LLM vs.
human-corrected outputs along with the code to reproduce our results.

摘要：<paragraph>擁有乾淨的資料集一直是大多數自然語言處理 (NLP) 系統的基本假設。然而，在現實世界的場景中很少會發現寫得很好的文字，因此，這常常會使上述的基本假設失效。最近，大型語言模型 (LLM) 已經展現出令人印象深刻的效能，但是它們能處理現實世界資料中難以避免的雜訊嗎？這項研究透過調查 LLM 對文字形態變化所展現的韌性，來探討這個關鍵問題。為此，我們人工在各種不同的資料集中加入不同程度的雜訊，並系統性地評估 LLM 對原始文字的錯誤變形的穩健性。我們的研究結果顯示，與普遍的看法相反，生成式 LLM 對於文字中的雜訊擾動相當穩健。這與 BERT 或 RoBERTa 等預先訓練的模型不同，已證實其效能會受到雜訊文字惡化的影響。此外，我們在多個現實世界的基準上測試 LLM 的韌性，這些基準緊密模擬在野外常見的錯誤。在最少的提示下，LLM 在語法錯誤校正 (GEC) 和詞彙語義改變 (LSC) 的基準任務上達到了新的最先進水準。為了賦能未來的研究，我們也釋出一個由人類標註的資料集，說明他們偏好 LLM 或人為校正的輸出，以及用於重現我們結果的程式碼。</paragraph>

##### **Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**
2407.08983v1 by David N. Palacio, Daniel Rodriguez-Cardenas, Alejandro Velasco, Dipin Khati, Kevin Moran, Denys Poshyvanyk

Trustworthiness and interpretability are inextricably linked concepts for
LLMs. The more interpretable an LLM is, the more trustworthy it becomes.
However, current techniques for interpreting LLMs when applied to code-related
tasks largely focus on accuracy measurements, measures of how models react to
change, or individual task performance instead of the fine-grained explanations
needed at prediction time for greater interpretability, and hence trust. To
improve upon this status quo, this paper introduces ASTrust, an
interpretability method for LLMs of code that generates explanations grounded
in the relationship between model confidence and syntactic structures of
programming languages. ASTrust explains generated code in the context of syntax
categories based on Abstract Syntax Trees and aids practitioners in
understanding model predictions at both local (individual code snippets) and
global (larger datasets of code) levels. By distributing and assigning model
confidence scores to well-known syntactic structures that exist within ASTs,
our approach moves beyond prior techniques that perform token-level confidence
mapping by offering a view of model confidence that directly aligns with
programming language concepts with which developers are familiar. To put
ASTrust into practice, we developed an automated visualization that illustrates
the aggregated model confidence scores superimposed on sequence, heat-map, and
graph-based visuals of syntactic structures from ASTs. We examine both the
practical benefit that ASTrust can provide through a data science study on 12
popular LLMs on a curated set of GitHub repos and the usefulness of ASTrust
through a human study.

摘要：可信度和可解釋性是 LLM 中密不可分的概念。LLM 的可解釋性越高，它的可信度就越高。然而，當應用於與程式碼相關的任務時，目前解釋 LLM 的技術主要集中在準確性測量、模型對變化的反應測量或個別任務表現，而不是在預測時間所需的細粒度解釋，從而提高可解釋性和因此提高信任度。為了改善這種現狀，本文介紹了 ASTrust，這是一種用於程式碼 LLM 的可解釋性方法，它會根據模型信心與程式語言的語法結構之間的關係產生解釋。ASTrust 在基於抽象語法樹的語法類別的上下文中解釋產生的程式碼，並幫助實務人員在局部（個別程式碼片段）和全域（較大的程式碼資料集）層級了解模型預測。透過將模型信心分數分配和指定給 AST 中存在的眾所周知的語法結構，我們的做法超越了先前的技術，這些技術透過提供與開發人員熟悉的程式語言概念直接對齊的模型信心視圖來執行令牌級別的信心對應。為了實踐 ASTrust，我們開發了一個自動化視覺化工具，它說明了疊加在 AST 語法結構的序列、熱圖和基於圖形的視覺效果上的聚合模型信心分數。我們檢查了 ASTrust 可以透過對 12 個流行的 LLM 在一組精選的 GitHub 儲存庫上進行資料科學研究提供的實際好處，以及透過人體研究提供的 ASTrust 的有用性。

##### **Towards Chapter-to-Chapter Context-Aware Literary Translation via Large Language Models**
2407.08978v1 by Linghao Jin, Li An, Xuezhe Ma

Discourse phenomena in existing document-level translation datasets are
sparse, which has been a fundamental obstacle in the development of
context-aware machine translation models. Moreover, most existing
document-level corpora and context-aware machine translation methods rely on an
unrealistic assumption on sentence-level alignments. To mitigate these issues,
we first curate a novel dataset of Chinese-English literature, which consists
of 160 books with intricate discourse structures. Then, we propose a more
pragmatic and challenging setting for context-aware translation, termed
chapter-to-chapter (Ch2Ch) translation, and investigate the performance of
commonly-used machine translation models under this setting. Furthermore, we
introduce a potential approach of finetuning large language models (LLMs)
within the domain of Ch2Ch literary translation, yielding impressive
improvements over baselines. Through our comprehensive analysis, we unveil that
literary translation under the Ch2Ch setting is challenging in nature, with
respect to both model learning methods and translation decoding algorithms.

摘要：現有文件級翻譯資料集中的話語現象很稀疏，這一直是情境感知機器翻譯模型發展的基本障礙。此外，現有的文件級語料庫和情境感知機器翻譯方法大多依賴於句子級別對齊的不切實際的假設。為了緩解這些問題，我們首先策劃了一個新的中英文文學資料集，其中包含 160 本具有複雜話語結構的書籍。然後，我們為情境感知翻譯提出了一個更務實且具有挑戰性的設定，稱為章節對章節 (Ch2Ch) 翻譯，並探討在這種設定下常用的機器翻譯模型的效能。此外，我們引入了一種在 Ch2Ch 文學翻譯領域微調大型語言模型 (LLM) 的潛在方法，對基準線產生了令人印象深刻的改進。透過我們的全面分析，我們揭示了 Ch2Ch 設定下的文學翻譯本質上具有挑戰性，無論是模型學習方法還是翻譯解碼演算法。

##### **Soft Prompts Go Hard: Steering Visual Language Models with Hidden Meta-Instructions**
2407.08970v1 by Tingwei Zhang, Collin Zhang, John X. Morris, Eugene Bagdasaryan, Vitaly Shmatikov

We introduce a new type of indirect injection vulnerabilities in language
models that operate on images: hidden "meta-instructions" that influence how
the model interprets the image and steer the model's outputs to express an
adversary-chosen style, sentiment, or point of view.
  We explain how to create meta-instructions by generating images that act as
soft prompts. Unlike jailbreaking attacks and adversarial examples, the outputs
resulting from these images are plausible and based on the visual content of
the image, yet follow the adversary's (meta-)instructions. We describe the
risks of these attacks, including misinformation and spin, evaluate their
efficacy for multiple visual language models and adversarial meta-objectives,
and demonstrate how they can "unlock" the capabilities of the underlying
language models that are unavailable via explicit text instructions. Finally,
we discuss defenses against these attacks.

摘要：我們在語言模型中引入一種新的間接注入漏洞，這些模型對影像進行運算：隱藏的「元指令」會影響模型如何詮釋影像，並引導模型的輸出表達對手選擇的風格、情緒或觀點。
我們說明如何透過產生作為軟提示的影像來建立元指令。與越獄攻擊和對抗範例不同，這些影像產生的輸出是合理的，且基於影像的視覺內容，但仍遵循對手（元）指令。我們描述這些攻擊的風險，包括錯誤訊息和扭曲，評估它們對多種視覺語言模型和對抗性元目標的效力，並展示它們如何「解鎖」基礎語言模型的能力，而這些能力無法透過明確的文字指令獲得。最後，我們討論對抗這些攻擊的防禦措施。

##### **Empowering Few-Shot Relation Extraction with The Integration of Traditional RE Methods and Large Language Models**
2407.08967v1 by Ye Liu, Kai Zhang, Aoran Gan, Linan Yue, Feng Hu, Qi Liu, Enhong Chen

Few-Shot Relation Extraction (FSRE), a subtask of Relation Extraction (RE)
that utilizes limited training instances, appeals to more researchers in
Natural Language Processing (NLP) due to its capability to extract textual
information in extremely low-resource scenarios. The primary methodologies
employed for FSRE have been fine-tuning or prompt tuning techniques based on
Pre-trained Language Models (PLMs). Recently, the emergence of Large Language
Models (LLMs) has prompted numerous researchers to explore FSRE through
In-Context Learning (ICL). However, there are substantial limitations
associated with methods based on either traditional RE models or LLMs.
Traditional RE models are hampered by a lack of necessary prior knowledge,
while LLMs fall short in their task-specific capabilities for RE. To address
these shortcomings, we propose a Dual-System Augmented Relation Extractor
(DSARE), which synergistically combines traditional RE models with LLMs.
Specifically, DSARE innovatively injects the prior knowledge of LLMs into
traditional RE models, and conversely enhances LLMs' task-specific aptitude for
RE through relation extraction augmentation. Moreover, an Integrated Prediction
module is employed to jointly consider these two respective predictions and
derive the final results. Extensive experiments demonstrate the efficacy of our
proposed method.

摘要：<paragraph>小樣本關係抽取 (FSRE) 是關係抽取 (RE) 的一個子任務，它利用有限的訓練實例，由於其在極低資源場景中提取文本信息的能力，吸引了更多自然語言處理 (NLP) 研究人員。FSRE 使用的主要方法是基於預訓練語言模型 (PLM) 的微調或提示調整技術。最近，大型語言模型 (LLM) 的出現促使許多研究人員通過情境學習 (ICL) 探索 FSRE。然而，基於傳統 RE 模型或 LLM 的方法存在實質性限制。傳統的 RE 模型受到缺乏必要的先驗知識的阻礙，而 LLM 在其特定於任務的 RE 能力方面有所不足。為了解決這些缺點，我們提出了一個雙系統增強關係抽取器 (DSARE)，它將傳統的 RE 模型與 LLM 協同結合起來。具體來說，DSARE 創新地將 LLM 的先驗知識注入傳統的 RE 模型，並通過關係抽取增強反過來增強 LLM 的特定任務適應性。此外，採用一個整合預測模組來共同考慮這兩個各自的預測，並得出最終結果。廣泛的實驗證明了我們提出的方法的有效性。</paragraph>

##### **LAPT: Label-driven Automated Prompt Tuning for OOD Detection with Vision-Language Models**
2407.08966v1 by Yabin Zhang, Wenjie Zhu, Chenhang He, Lei Zhang

Out-of-distribution (OOD) detection is crucial for model reliability, as it
identifies samples from unknown classes and reduces errors due to unexpected
inputs. Vision-Language Models (VLMs) such as CLIP are emerging as powerful
tools for OOD detection by integrating multi-modal information. However, the
practical application of such systems is challenged by manual prompt
engineering, which demands domain expertise and is sensitive to linguistic
nuances. In this paper, we introduce Label-driven Automated Prompt Tuning
(LAPT), a novel approach to OOD detection that reduces the need for manual
prompt engineering. We develop distribution-aware prompts with in-distribution
(ID) class names and negative labels mined automatically. Training samples
linked to these class labels are collected autonomously via image synthesis and
retrieval methods, allowing for prompt learning without manual effort. We
utilize a simple cross-entropy loss for prompt optimization, with cross-modal
and cross-distribution mixing strategies to reduce image noise and explore the
intermediate space between distributions, respectively. The LAPT framework
operates autonomously, requiring only ID class names as input and eliminating
the need for manual intervention. With extensive experiments, LAPT consistently
outperforms manually crafted prompts, setting a new standard for OOD detection.
Moreover, LAPT not only enhances the distinction between ID and OOD samples,
but also improves the ID classification accuracy and strengthens the
generalization robustness to covariate shifts, resulting in outstanding
performance in challenging full-spectrum OOD detection tasks. Codes are
available at \url{https://github.com/YBZh/LAPT}.

摘要：<paragraph>異分布 (OOD) 偵測對於模型可靠性至關重要，因為它能識別來自未知類別的樣本，並減少由於意外輸入造成的錯誤。視覺語言模型 (VLM)，例如 CLIP，正透過整合多模態資訊，成為 OOD 偵測的強大工具。然而，此類系統的實際應用受到手動提示工程的挑戰，這需要領域專業知識，而且對語言差異很敏感。在本文中，我們介紹標籤驅動自動化提示調整 (LAPT)，這是一種新的 OOD 偵測方法，可減少對手動提示工程的需求。我們開發出具有分佈感知的提示，其中包含自動挖掘的同分佈 (ID) 類別名稱和負面標籤。連結到這些類別標籤的訓練樣本是透過影像合成和檢索方法自主收集的，允許提示學習而無需手動操作。我們利用簡單的交叉熵損失進行提示最佳化，並採用跨模態和跨分佈混合策略，分別用於減少影像雜訊和探索分佈之間的中間空間。LAPT 框架自主運作，僅需要 ID 類別名稱作為輸入，並消除了手動介入的需要。透過廣泛的實驗，LAPT 持續優於手動製作的提示，為 OOD 偵測設定了新標準。此外，LAPT 不僅增強了 ID 和 OOD 樣本之間的區別，還改善了 ID 分類的準確性，並加強了對協變數轉移的泛化穩健性，從而產生了在具有挑戰性的全光譜 OOD 偵測任務中的傑出表現。程式碼可在 \url{https://github.com/YBZh/LAPT} 取得。</paragraph>

##### **Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**
2407.08959v1 by Ke Ji, Peng Wang, Wenjun Ke, Guozheng Li, Jiajun Liu, Jingsheng Gao, Ziyu Shang

Recently, various pre-trained language models (PLMs) have been proposed to
prove their impressive performances on a wide range of few-shot tasks. However,
limited by the unstructured prior knowledge in PLMs, it is difficult to
maintain consistent performance on complex structured scenarios, such as
hierarchical text classification (HTC), especially when the downstream data is
extremely scarce. The main challenge is how to transfer the unstructured
semantic space in PLMs to the downstream domain hierarchy. Unlike previous work
on HTC which directly performs multi-label classification or uses graph neural
network (GNN) to inject label hierarchy, in this work, we study the HTC problem
under a few-shot setting to adapt knowledge in PLMs from an unstructured manner
to the downstream hierarchy. Technically, we design a simple yet effective
method named Hierarchical Iterative Conditional Random Field (HierICRF) to
search the most domain-challenging directions and exquisitely crafts
domain-hierarchy adaptation as a hierarchical iterative language modeling
problem, and then it encourages the model to make hierarchical consistency
self-correction during the inference, thereby achieving knowledge transfer with
hierarchical consistency preservation. We perform HierICRF on various
architectures, and extensive experiments on two popular HTC datasets
demonstrate that prompt with HierICRF significantly boosts the few-shot HTC
performance with an average Micro-F1 by 28.80% to 1.50% and Macro-F1 by 36.29%
to 1.5% over the previous state-of-the-art (SOTA) baselines under few-shot
settings, while remaining SOTA hierarchical consistency performance.

摘要：<paragraph>最近，已经提出了多种预训练语言模型 (PLM)，以证明它们在广泛的少量样本任务上具有令人印象深刻的性能。然而，由于 PLM 中非结构化的先验知识受到限制，因此难以在复杂结构化场景（例如层次文本分类 (HTC)）中保持一致的性能，尤其是在下游数据极其稀少的情况下。主要的挑战是如何将 PLM 中非结构化的语义空间转移到下游域层次结构。与以前直接执行多标签分类或使用图神经网络 (GNN) 注入标签层次结构的 HTC 工作不同，在这项工作中，我们在少量样本设置下研究 HTC 问题，以将 PLM 中的知识从非结构化方式适应到下游层次结构。从技术上讲，我们设计了一种简单而有效的方法，称为层次迭代条件随机场 (HierICRF)，以搜索最具领域挑战性的方向，并精细地将领域层次结构适应作为分层迭代语言建模问题，然后它鼓励模型在推理期间进行层次一致性自我校正，从而实现具有层次一致性保留的知识转移。我们在各种架构上执行 HierICRF，在两个流行的 HTC 数据集上的大量实验表明，使用 HierICRF 的提示显着提高了少量样本 HTC 性能，平均 Micro-F1 从 28.80% 提高到 1.50%，Macro-F1 从 36.29% 提高到 1.5% 在少量样本设置下超过了以前最先进 (SOTA) 基准，同时保持 SOTA 层次一致性性能。</paragraph>

##### **Detect, Investigate, Judge and Determine: A Novel LLM-based Framework for Few-shot Fake News Detection**
2407.08952v1 by Ye Liu, Jiajun Zhu, Kai Zhang, Haoyu Tang, Yanghai Zhang, Xukai Liu, Qi Liu, Enhong Chen

Few-Shot Fake News Detection (FS-FND) aims to distinguish inaccurate news
from real ones in extremely low-resource scenarios. This task has garnered
increased attention due to the widespread dissemination and harmful impact of
fake news on social media. Large Language Models (LLMs) have demonstrated
competitive performance with the help of their rich prior knowledge and
excellent in-context learning abilities. However, existing methods face
significant limitations, such as the Understanding Ambiguity and Information
Scarcity, which significantly undermine the potential of LLMs. To address these
shortcomings, we propose a Dual-perspective Augmented Fake News Detection
(DAFND) model, designed to enhance LLMs from both inside and outside
perspectives. Specifically, DAFND first identifies the keywords of each news
article through a Detection Module. Subsequently, DAFND creatively designs an
Investigation Module to retrieve inside and outside valuable information
concerning to the current news, followed by another Judge Module to derive its
respective two prediction results. Finally, a Determination Module further
integrates these two predictions and derives the final result. Extensive
experiments on two publicly available datasets show the efficacy of our
proposed method, particularly in low-resource settings.

摘要：少樣本假新聞偵測 (FS-FND) 的目標是在極度低資源的場景中，區分不準確的新聞和真實新聞。由於假新聞在社群媒體上的廣泛傳播和有害影響，這項任務獲得了越來越多的關注。大型語言模型 (LLM) 在豐富先驗知識和出色的情境學習能力的幫助下，展現了競爭力的表現。然而，現有方法面臨著顯著的限制，例如理解模稜兩可和資訊稀少，這會顯著削弱 LLM 的潛力。為了解決這些缺點，我們提出了一個雙視角增強假新聞偵測 (DAFND) 模型，旨在從內部和外部視角增強 LLM。具體來說，DAFND 首先透過偵測模組識別每篇新聞文章的關鍵字。隨後，DAFND 創意地設計了一個調查模組，以擷取與當前新聞相關的內部和外部有價值資訊，接著再透過另一個判斷模組來推導其各自的兩個預測結果。最後，一個判定模組進一步整合這兩個預測，並推导出最終結果。在兩個公開可用的資料集上進行的廣泛實驗顯示了我們提出的方法的功效，特別是在低資源的設定中。

##### **A Neural Matrix Decomposition Recommender System Model based on the Multimodal Large Language Model**
2407.08942v1 by Ao Xiang, Bingjie Huang, Xinyu Guo, Haowei Yang, Tianyao Zheng

Recommendation systems have become an important solution to information
search problems. This article proposes a neural matrix factorization
recommendation system model based on the multimodal large language model called
BoNMF. This model combines BoBERTa's powerful capabilities in natural language
processing, ViT in computer in vision, and neural matrix decomposition
technology. By capturing the potential characteristics of users and items, and
after interacting with a low-dimensional matrix composed of user and item IDs,
the neural network outputs the results. recommend. Cold start and ablation
experimental results show that the BoNMF model exhibits excellent performance
on large public data sets and significantly improves the accuracy of
recommendations.

摘要：推薦系統已成為資訊搜尋問題的重要解決方案。本文提出一個基於多模態大型語言模型 BoNMF 的神經矩陣分解推薦系統模型。此模型結合了 BoBERTa 在自然語言處理中的強大功能、ViT 在電腦視覺中的功能，以及神經矩陣分解技術。透過捕捉使用者和項目的潛在特徵，並與由使用者和項目 ID 組成的低維度矩陣互動後，神經網路會輸出結果。推薦。冷啟動和消融實驗結果顯示，BoNMF 模型在大型公開資料集上展現出極佳的效能，並顯著提升推薦的準確度。

##### **Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation**
2407.08940v1 by Biqing Qi, Kaiyan Zhang, Kai Tian, Haoxiang Li, Zhang-Ren Chen, Sihang Zeng, Ermo Hua, Hu Jinfang, Bowen Zhou

The rapid growth of biomedical knowledge has outpaced our ability to
efficiently extract insights and generate novel hypotheses. Large language
models (LLMs) have emerged as a promising tool to revolutionize knowledge
interaction and potentially accelerate biomedical discovery. In this paper, we
present a comprehensive evaluation of LLMs as biomedical hypothesis generators.
We construct a dataset of background-hypothesis pairs from biomedical
literature, carefully partitioned into training, seen, and unseen test sets
based on publication date to mitigate data contamination. Using this dataset,
we assess the hypothesis generation capabilities of top-tier instructed models
in zero-shot, few-shot, and fine-tuning settings. To enhance the exploration of
uncertainty, a crucial aspect of scientific discovery, we incorporate tool use
and multi-agent interactions in our evaluation framework. Furthermore, we
propose four novel metrics grounded in extensive literature review to evaluate
the quality of generated hypotheses, considering both LLM-based and human
assessments. Our experiments yield two key findings: 1) LLMs can generate novel
and validated hypotheses, even when tested on literature unseen during
training, and 2) Increasing uncertainty through multi-agent interactions and
tool use can facilitate diverse candidate generation and improve zero-shot
hypothesis generation performance. However, we also observe that the
integration of additional knowledge through few-shot learning and tool use may
not always lead to performance gains, highlighting the need for careful
consideration of the type and scope of external knowledge incorporated. These
findings underscore the potential of LLMs as powerful aids in biomedical
hypothesis generation and provide valuable insights to guide further research
in this area.

摘要：<paragraph>生物醫學知識的快速增長已超越我們有效提取見解和產生新假設的能力。大型語言模型 (LLM) 已成為一項極具前景的工具，可徹底改變知識互動並潛在加速生物醫學發現。在本文中，我們對 LLM 作為生物醫學假設產生器的全面評估。我們從生物醫學文獻中構建了一個背景假設對集，根據出版日期仔細劃分為訓練、已見和未見測試集，以減輕數據污染。使用此數據集，我們評估了頂級指導模型在零次學習、少次學習和微調設置中的假設產生能力。為了加強對不確定性的探索，這是科學發現的一個關鍵方面，我們在評估框架中納入了工具使用和多主體互動。此外，我們根據廣泛的文獻回顧提出了四個新穎的指標來評估生成假設的品質，同時考慮 LLM 為基礎和人為評估。我們的實驗產生了兩個關鍵發現：1) LLM 可以產生新穎且經過驗證的假設，即使在訓練期間未見的文獻上進行測試也是如此，以及 2) 透過多主體互動和工具使用增加不確定性，可以促進多樣化的候選產生並改善零次學習假設產生效能。然而，我們也觀察到，透過少次學習和工具使用整合額外的知識可能並不總是會導致效能提升，這突顯了仔細考量所納入外部知識的類型和範圍的必要性。這些發現強調了 LLM 作為生物醫學假設產生中強大輔助工具的潛力，並提供了有價值的見解以引導此領域進一步的研究。</paragraph>

##### **Self-Evolving GPT: A Lifelong Autonomous Experiential Learner**
2407.08937v1 by Jinglong Gao, Xiao Ding, Yiming Cui, Jianbai Zhao, Hepeng Wang, Ting Liu, Bing Qin

To improve the performance of large language models (LLMs), researchers have
explored providing LLMs with textual task-solving experience via prompts.
However, they rely on manual efforts to acquire and apply such experience for
each task, which is not feasible for the growing demand for LLMs and the
variety of user questions. To address this issue, we design a lifelong
autonomous experiential learning framework based on LLMs to explore whether
LLMs can imitate human ability for learning and utilizing experience. It
autonomously learns and accumulates experience through experience transfer and
induction, categorizing the types of input questions to select which
accumulated experience to employ for them. Experimental results on six widely
used NLP datasets show that our framework performs reliably in each
intermediate step and effectively improves the performance of GPT-3.5 and
GPT-4. This validates the feasibility of using LLMs to mimic human experiential
learning and application capabilities. Additionally, we provide a detailed
analysis of the behavior of our framework at each step.

摘要：為了提升大型語言模型 (LLM) 的效能，研究人員已探討透過提示提供 LLM 文字任務解決經驗。
然而，他們仰賴手動方式為每個任務取得並應用此類經驗，這對於 LLM 不斷增長的龐大需求和使用者問題的多樣性而言並不可行。為了解決此問題，我們設計了一個基於 LLM 的終身自主體驗式學習架構，以探討 LLM 是否能模仿人類學習和利用經驗的能力。它透過經驗傳遞和歸納自主學習並累積經驗，對輸入問題的類型進行分類，以選擇要為其採用哪種累積經驗。在六個廣泛使用的 NLP 資料集上的實驗結果顯示，我們的架構在每個中間步驟中都能可靠執行，並有效提升 GPT-3.5 和 GPT-4 的效能。這驗證了使用 LLM 模仿人類體驗式學習和應用能力的可行性。此外，我們提供了架構在每個步驟中行為的詳細分析。

##### **Deep Attention Driven Reinforcement Learning (DAD-RL) for Autonomous Vehicle Decision-Making in Dynamic Environment**
2407.08932v1 by Jayabrata Chowdhury, Venkataramanan Shivaraman, Sumit Dangi, Suresh Sundaram, P. B. Sujit

Autonomous Vehicle (AV) decision making in urban environments is inherently
challenging due to the dynamic interactions with surrounding vehicles. For safe
planning, AV must understand the weightage of various spatiotemporal
interactions in a scene. Contemporary works use colossal transformer
architectures to encode interactions mainly for trajectory prediction,
resulting in increased computational complexity. To address this issue without
compromising spatiotemporal understanding and performance, we propose the
simple Deep Attention Driven Reinforcement Learning (DADRL) framework, which
dynamically assigns and incorporates the significance of surrounding vehicles
into the ego's RL driven decision making process. We introduce an AV centric
spatiotemporal attention encoding (STAE) mechanism for learning the dynamic
interactions with different surrounding vehicles. To understand map and route
context, we employ a context encoder to extract features from context maps. The
spatiotemporal representations combined with contextual encoding provide a
comprehensive state representation. The resulting model is trained using the
Soft Actor Critic (SAC) algorithm. We evaluate the proposed framework on the
SMARTS urban benchmarking scenarios without traffic signals to demonstrate that
DADRL outperforms recent state of the art methods. Furthermore, an ablation
study underscores the importance of the context-encoder and spatio temporal
attention encoder in achieving superior performance.

摘要：自主車輛（AV）在城市環境中的決策制定本質上具有挑戰性，因為與周圍車輛的互動具有動態性。為了安全規劃，AV 必須了解場景中各種時空交互的權重。當代作品使用龐大的Transformer架構來編碼交互，主要是為了預測軌跡，從而導致計算複雜性增加。為了解決這個問題，在不影響時空理解和性能的情況下，我們提出了簡單的深度注意力驅動強化學習（DADRL）框架，它動態分配並將周圍車輛的重要性納入自我強化學習驅動的決策制定過程中。我們引入了一個以 AV 為中心的時空注意力編碼（STAE）機制，用於學習與不同周圍車輛的動態交互。為了了解地圖和路線上下文，我們採用上下文編碼器從上下文地圖中提取特徵。時空表示與上下文編碼相結合，提供了一個全面的狀態表示。使用軟動作批評家（SAC）演算法訓練所得模型。我們在沒有交通信號的 SMARTS 城市基準情境中評估所提出的框架，以證明 DADRL 優於最近的先進方法。此外，消融研究強調了上下文編碼器和時空注意力編碼器在實現卓越性能中的重要性。

##### **Are They the Same Picture? Adapting Concept Bottleneck Models for Human-AI Collaboration in Image Retrieval**
2407.08908v1 by Vaibhav Balloli, Sara Beery, Elizabeth Bondi-Kelly

Image retrieval plays a pivotal role in applications from wildlife
conservation to healthcare, for finding individual animals or relevant images
to aid diagnosis. Although deep learning techniques for image retrieval have
advanced significantly, their imperfect real-world performance often
necessitates including human expertise. Human-in-the-loop approaches typically
rely on humans completing the task independently and then combining their
opinions with an AI model in various ways, as these models offer very little
interpretability or \textit{correctability}. To allow humans to intervene in
the AI model instead, thereby saving human time and effort, we adapt the
Concept Bottleneck Model (CBM) and propose \texttt{CHAIR}. \texttt{CHAIR} (a)
enables humans to correct intermediate concepts, which helps \textit{improve}
embeddings generated, and (b) allows for flexible levels of intervention that
accommodate varying levels of human expertise for better retrieval. To show the
efficacy of \texttt{CHAIR}, we demonstrate that our method performs better than
similar models on image retrieval metrics without any external intervention.
Furthermore, we also showcase how human intervention helps further improve
retrieval performance, thereby achieving human-AI complementarity.

摘要：影像檢索在從野生動物保育到醫療保健等應用中扮演著舉足輕重的角色，用於尋找個別動物或相關影像以協助診斷。儘管用於影像檢索的深度學習技術已大幅進步，但其不完美的實際世界表現通常需要包含人類專業知識。人類參與迴圈方法通常依賴於人類獨立完成任務，然後以各種方式將其意見與 AI 模型結合，因為這些模型提供的可解釋性或「可修正性」極低。為了讓人們改為介入 AI 模型，從而節省人力和精力，我們調整了概念瓶頸模型 (CBM) 並提出 \texttt{CHAIR}。\texttt{CHAIR} (a) 能讓人們修正中間概念，有助於「改善」產生的嵌入，以及 (b) 允許靈活的介入層級，以適應不同層級的人類專業知識，以利於更好的檢索。為了顯示 \texttt{CHAIR} 的功效，我們證明了我們的方法在影像檢索指標上比類似的模型表現得更好，而無需任何外部介入。此外，我們還展示了人類介入如何進一步改善檢索效能，從而實現人類與 AI 的互補性。

##### **AirSketch: Generative Motion to Sketch**
2407.08906v1 by Hui Xian Grace Lim, Xuanming Cui, Yogesh S Rawat, Ser-Nam Lim

Illustration is a fundamental mode of human expression and communication.
Certain types of motion that accompany speech can provide this illustrative
mode of communication. While Augmented and Virtual Reality technologies (AR/VR)
have introduced tools for producing drawings with hand motions (air drawing),
they typically require costly hardware and additional digital markers, thereby
limiting their accessibility and portability. Furthermore, air drawing demands
considerable skill to achieve aesthetic results. To address these challenges,
we introduce the concept of AirSketch, aimed at generating faithful and
visually coherent sketches directly from hand motions, eliminating the need for
complicated headsets or markers. We devise a simple augmentation-based
self-supervised training procedure, enabling a controllable image diffusion
model to learn to translate from highly noisy hand tracking images to clean,
aesthetically pleasing sketches, while preserving the essential visual cues
from the original tracking data. We present two air drawing datasets to study
this problem. Our findings demonstrate that beyond producing photo-realistic
images from precise spatial inputs, controllable image diffusion can
effectively produce a refined, clear sketch from a noisy input. Our work serves
as an initial step towards marker-less air drawing and reveals distinct
applications of controllable diffusion models to AirSketch and AR/VR in
general.

摘要：插圖是人類表達和溝通的基本模式。
某些伴隨言語的動作類型可以提供這種說明性的溝通模式。儘管擴增實境和虛擬實境技術 (AR/VR) 已引入使用手部動作繪製圖畫的工具 (空中繪圖)，但它們通常需要昂貴的硬體和額外的數位標記，從而限制了它們的可及性和可攜性。此外，空中繪圖需要相當的技巧才能達到美學效果。為了應對這些挑戰，我們引入了 AirSketch 的概念，旨在直接從手部動作中產生逼真且視覺連貫的草圖，無需複雜的頭戴式裝置或標記。我們設計了一個基於簡單擴增的自監督訓練程序，使可控制的影像擴散模型能夠學習從極度雜訊的手部追蹤影像轉換成乾淨、美觀的草圖，同時保留原始追蹤資料中的基本視覺線索。我們提供了兩個空中繪圖資料集來研究這個問題。我們的研究結果表明，除了根據精確的空間輸入產生逼真的影像之外，可控制的影像擴散還能有效地根據雜訊輸入產生精緻、清晰的草圖。我們的研究作為無標記空中繪圖的初步步驟，並揭示了可控制擴散模型在 AirSketch 和 AR/VR 中的獨特應用。

##### **TensorTEE: Unifying Heterogeneous TEE Granularity for Efficient Secure Collaborative Tensor Computing**
2407.08903v1 by Husheng Han, Xinyao Zheng, Yuanbo Wen, Yifan Hao, Erhu Feng, Ling Liang, Jianan Mu, Xiaqing Li, Tianyun Ma, Pengwei Jin, Xinkai Song, Zidong Du, Qi Guo, Xing Hu

Heterogeneous collaborative computing with NPU and CPU has received
widespread attention due to its substantial performance benefits. To ensure
data confidentiality and integrity during computing, Trusted Execution
Environments (TEE) is considered a promising solution because of its
comparatively lower overhead. However, existing heterogeneous TEE designs are
inefficient for collaborative computing due to fine and different memory
granularities between CPU and NPU. 1) The cacheline granularity of CPU TEE
intensifies memory pressure due to its extra memory access, and 2) the
cacheline granularity MAC of NPU escalates the pressure on the limited memory
storage. 3) Data transfer across heterogeneous enclaves relies on the transit
of non-secure regions, resulting in cumbersome re-encryption and scheduling.
  To address these issues, we propose TensorTEE, a unified tensor-granularity
heterogeneous TEE for efficient secure collaborative tensor computing. First,
we virtually support tensor granularity in CPU TEE to eliminate the off-chip
metadata access by detecting and maintaining tensor structures on-chip. Second,
we propose tensor-granularity MAC management with predictive execution to avoid
computational stalls while eliminating off-chip MAC storage and access.
Moreover, based on the unified granularity, we enable direct data transfer
without re-encryption and scheduling dilemmas. Our evaluation is built on
enhanced Gem5 and a cycle-accurate NPU simulator. The results show that
TensorTEE improves the performance of Large Language Model (LLM) training
workloads by 4.0x compared to existing work and incurs only 2.1% overhead
compared to non-secure training, offering a practical security assurance for
LLM training.

摘要：異質協作運算結合 NPU 和 CPU，因其顯著的效能優勢而廣受矚目。為了確保運算期間的資料機密性和完整性，可信執行環境 (TEE) 由於其相對較低的開銷而被視為一個有前途的解決方案。然而，現有的異質 TEE 設計對於協作運算而言效率低下，這是因為 CPU 和 NPU 之間的記憶體顆粒度精細且不同。1) CPU TEE 的快取行顆粒度會因其額外的記憶體存取而加劇記憶體壓力，2) NPU 的快取行顆粒度 MAC 會加劇對有限記憶體儲存的壓力。3) 異質飛地的資料傳輸依賴於非安全區域的中轉，導致繁瑣的重新加密和排程。
為了解決這些問題，我們提出 TensorTEE，一個用於高效安全協作張量運算的統一張量顆粒度異質 TEE。首先，我們在 CPU TEE 中虛擬支援張量顆粒度，以透過在晶片上偵測和維護張量結構來消除晶片外元資料存取。其次，我們提出具有預測執行的張量顆粒度 MAC 管理，以避免計算停頓，同時消除晶片外 MAC 儲存和存取。此外，基於統一的顆粒度，我們啟用直接資料傳輸，而無需重新加密和排程困境。我們的評估建立在增強的 Gem5 和週期精確的 NPU 模擬器上。結果顯示，與現有工作相比，TensorTEE 將大語言模型 (LLM) 訓練工作負載的效能提升了 4.0 倍，而且與非安全訓練相比，僅產生 2.1% 的開銷，為 LLM 訓練提供了實用的安全性保證。

##### **Application of Artificial Intelligence in Supporting Healthcare Professionals and Caregivers in Treatment of Autistic Children**
2407.08902v1 by Hossein Mohammadi Rouzbahani, Hadis Karimipour

Autism Spectrum Disorder (ASD) represents a multifaceted neurodevelopmental
condition marked by difficulties in social interaction, communication
impediments, and repetitive behaviors. Despite progress in understanding ASD,
its diagnosis and treatment continue to pose significant challenges due to the
variability in symptomatology and the necessity for multidisciplinary care
approaches. This paper investigates the potential of Artificial Intelligence
(AI) to augment the capabilities of healthcare professionals and caregivers in
managing ASD. We have developed a sophisticated algorithm designed to analyze
facial and bodily expressions during daily activities of both autistic and
non-autistic children, leading to the development of a powerful deep
learning-based autism detection system. Our study demonstrated that AI models,
specifically the Xception and ResNet50V2 architectures, achieved high accuracy
in diagnosing Autism Spectrum Disorder (ASD). This research highlights the
transformative potential of AI in improving the diagnosis, treatment, and
comprehensive management of ASD. Our study revealed that AI models, notably the
Xception and ResNet50V2 architectures, demonstrated high accuracy in diagnosing
ASD.

摘要：自閉症譜系障礙 (ASD) 是一種多面向的神經發展狀況，其特徵在於社交互動困難、溝通障礙和重複性行為。儘管在了解 ASD 方面取得進展，但由於症狀的多變性和對跨領域照護方法的必要性，其診斷和治療仍然構成重大挑戰。本文探討人工智慧 (AI) 在擴增醫療保健專業人員和照護者管理 ASD 能力方面的潛力。我們開發了一種精密演算法，旨在分析自閉症和非自閉症兒童在日常活動中的面部和身體表情，進而開發出功能強大的深度學習自閉症偵測系統。我們的研究表明，AI 模型，特別是 Xception 和 ResNet50V2 架構，在診斷自閉症譜系障礙 (ASD) 方面取得高準確度。這項研究突顯了 AI 在改善 ASD 診斷、治療和全面管理方面的變革潛力。我們的研究揭示，AI 模型，特別是 Xception 和 ResNet50V2 架構，在診斷 ASD 方面表現出高準確度。

##### **IDAT: A Multi-Modal Dataset and Toolkit for Building and Evaluating Interactive Task-Solving Agents**
2407.08898v1 by Shrestha Mohanty, Negar Arabzadeh, Andrea Tupini, Yuxuan Sun, Alexey Skrynnik, Artem Zholus, Marc-Alexandre Côté, Julia Kiseleva

Seamless interaction between AI agents and humans using natural language
remains a key goal in AI research. This paper addresses the challenges of
developing interactive agents capable of understanding and executing grounded
natural language instructions through the IGLU competition at NeurIPS. Despite
advancements, challenges such as a scarcity of appropriate datasets and the
need for effective evaluation platforms persist. We introduce a scalable data
collection tool for gathering interactive grounded language instructions within
a Minecraft-like environment, resulting in a Multi-Modal dataset with around
9,000 utterances and over 1,000 clarification questions. Additionally, we
present a Human-in-the-Loop interactive evaluation platform for qualitative
analysis and comparison of agent performance through multi-turn communication
with human annotators. We offer to the community these assets referred to as
IDAT (IGLU Dataset And Toolkit) which aim to advance the development of
intelligent, interactive AI agents and provide essential resources for further
research.

摘要：透過自然語言，讓人工智慧代理與人類無縫互動，一直是人工智慧研究的關鍵目標。本文透過 NeurIPS 的 IGLU 競賽，探討開發互動式代理的挑戰，此代理能夠理解並執行接地的自然語言指令。儘管有進展，但仍有挑戰存在，例如缺乏適當的資料集，以及需要有效的評估平台。我們引進一個可擴充資料收集工具，在類似 Minecraft 的環境中收集互動式接地語言指令，產生一個多模態資料集，包含約 9,000 個語句和超過 1,000 個澄清問題。此外，我們提供一個人類參與迴圈的互動式評估平台，用於透過與人類註解者的多輪溝通，進行代理效能的定性分析和比較。我們提供這些稱為 IDAT（IGLU 資料集和工具包）的資產給社群，旨在推進智慧互動式人工智慧代理的開發，並提供進一步研究的重要資源。

##### **DeepCodeProbe: Towards Understanding What Models Trained on Code Learn**
2407.08890v1 by Vahid Majdinasab, Amin Nikanjam, Foutse Khomh

Machine learning models trained on code and related artifacts offer valuable
support for software maintenance but suffer from interpretability issues due to
their complex internal variables. These concerns are particularly significant
in safety-critical applications where the models' decision-making processes
must be reliable. The specific features and representations learned by these
models remain unclear, adding to the hesitancy in adopting them widely. To
address these challenges, we introduce DeepCodeProbe, a probing approach that
examines the syntax and representation learning abilities of ML models designed
for software maintenance tasks. Our study applies DeepCodeProbe to
state-of-the-art models for code clone detection, code summarization, and
comment generation. Findings reveal that while small models capture abstract
syntactic representations, their ability to fully grasp programming language
syntax is limited. Increasing model capacity improves syntax learning but
introduces trade-offs such as increased training time and overfitting.
DeepCodeProbe also identifies specific code patterns the models learn from
their training data. Additionally, we provide best practices for training
models on code to enhance performance and interpretability, supported by an
open-source replication package for broader application of DeepCodeProbe in
interpreting other code-related models.

摘要：<paragraph>在代码和相关工件上训练的机器学习模型为软件维护提供了有价值的支持，但由于其内部变量复杂，因此存在可解释性问题。这些问题在安全关键型应用程序中尤为重要，在这些应用程序中，模型的决策过程必须可靠。这些模型学习到的特定特征和表征仍然不清楚，增加了广泛采用它们的犹豫。为了应对这些挑战，我们引入了 DeepCodeProbe，这是一种探测方法，用于检查专为软件维护任务设计的 ML 模型的语法和表征学习能力。我们的研究将 DeepCodeProbe 应用于代码克隆检测、代码摘要和注释生成的最先进模型。研究结果表明，虽然小型模型捕获了抽象的语法表示，但它们完全掌握编程语言语法的能力是有限的。增加模型容量可以提高语法学习能力，但会引入权衡，例如增加训练时间和过度拟合。DeepCodeProbe 还识别出模型从其训练数据中学到的特定代码模式。此外，我们提供了在代码上训练模型以增强性能和可解释性的最佳实践，并得到了一个开源复制包的支持，以便在解释其他与代码相关的模型时更广泛地应用 DeepCodeProbe。</paragraph>

##### **Automatic Pruning of Fine-tuning Datasets for Transformer-based Language Models**
2407.08887v1 by Mohammadreza Tayaranian, Seyyed Hasan Mozafari, Brett H. Meyer, James J. Clark, Warren J. Gross

Transformer-based language models have shown state-of-the-art performance on
a variety of natural language understanding tasks. To achieve this performance,
these models are first pre-trained on general corpus and then fine-tuned on
downstream tasks. Previous work studied the effect of pruning the training set
of the downstream tasks on the performance of the model on its evaluation set.
In this work, we propose an automatic dataset pruning method for the training
set of fine-tuning tasks. Our method is based on the model's success rate in
correctly classifying each training data point. Unlike previous work which
relies on user feedback to determine subset size, our method automatically
extracts training subsets that are adapted for each pair of model and
fine-tuning task. Our method provides multiple subsets for use in dataset
pruning that navigate the trade-off between subset size and evaluation
accuracy. Our largest subset, which we also refer to as the winning ticket
subset, is on average $3 \times$ smaller than the original training set of the
fine-tuning task. Our experiments on 5 downstream tasks and 2 language models
show that, on average, fine-tuning on the winning ticket subsets results in a
$0.1 \%$ increase in the evaluation performance of the model.

摘要：<paragraph>基於 Transformer 的語言模型在各種自然語言理解任務中展現了最先進的效能。為了達到此效能，這些模型會先在一般語料庫上進行預先訓練，然後針對下游任務進行微調。先前的研究探討了修剪下游任務訓練集對模型在評估集上效能的影響。在這項研究中，我們提出了一種針對微調任務訓練集的自動化資料集修剪方法。我們的這項方法是基於模型正確分類每個訓練資料點的成功率。與依賴使用者回饋來決定子集大小的先前研究不同，我們的這項方法會自動擷取針對每對模型和微調任務調整的訓練子集。我們的這項方法提供多個子集，用於資料集修剪，在子集大小和評估準確度之間取得平衡。我們最大的子集，我們也稱之為中獎彩券子集，平均比微調任務的原始訓練集小 $3 \times$。我們針對 5 個下游任務和 2 個語言模型的實驗顯示，平均而言，對中獎彩券子集進行微調會讓模型的評估效能提升 $0.1 \%$。</paragraph>

##### **SALT: Introducing a Framework for Hierarchical Segmentations in Medical Imaging using Softmax for Arbitrary Label Trees**
2407.08878v1 by Sven Koitka, Giulia Baldini, Cynthia S. Schmidt, Olivia B. Pollok, Obioma Pelka, Judith Kohnke, Katarzyna Borys, Christoph M. Friedrich, Benedikt M. Schaarschmidt, Michael Forsting, Lale Umutlu, Johannes Haubold, Felix Nensa, René Hosch

Traditional segmentation networks approach anatomical structures as
standalone elements, overlooking the intrinsic hierarchical connections among
them. This study introduces Softmax for Arbitrary Label Trees (SALT), a novel
approach designed to leverage the hierarchical relationships between labels,
improving the efficiency and interpretability of the segmentations.
  This study introduces a novel segmentation technique for CT imaging, which
leverages conditional probabilities to map the hierarchical structure of
anatomical landmarks, such as the spine's division into lumbar, thoracic, and
cervical regions and further into individual vertebrae. The model was developed
using the SAROS dataset from The Cancer Imaging Archive (TCIA), comprising 900
body region segmentations from 883 patients. The dataset was further enhanced
by generating additional segmentations with the TotalSegmentator, for a total
of 113 labels. The model was trained on 600 scans, while validation and testing
were conducted on 150 CT scans. Performance was assessed using the Dice score
across various datasets, including SAROS, CT-ORG, FLARE22, LCTSC, LUNA16, and
WORD.
  Among the evaluated datasets, SALT achieved its best results on the LUNA16
and SAROS datasets, with Dice scores of 0.93 and 0.929 respectively. The model
demonstrated reliable accuracy across other datasets, scoring 0.891 on CT-ORG
and 0.849 on FLARE22. The LCTSC dataset showed a score of 0.908 and the WORD
dataset also showed good performance with a score of 0.844.
  SALT used the hierarchical structures inherent in the human body to achieve
whole-body segmentations with an average of 35 seconds for 100 slices. This
rapid processing underscores its potential for integration into clinical
workflows, facilitating the automatic and efficient computation of full-body
segmentations with each CT scan, thus enhancing diagnostic processes and
patient care.

摘要：<paragraph>傳統的分割網路將解剖結構視為獨立元素，忽略了它們之間固有的層級連接。本研究引入了任意標籤樹的 Softmax (SALT)，這是一種新穎的方法，旨在利用標籤之間的層級關係，提高分割的效率和可解釋性。
本研究引入了一種新的 CT 影像分割技術，它利用條件機率來對解剖標誌的層級結構進行對應，例如將脊椎分為腰椎、胸椎和頸椎區域，並進一步分為個別椎骨。該模型是使用癌症影像檔案館 (TCIA) 中的 SAROS 資料集開發的，其中包含來自 883 位患者的 900 個身體區域分割。該資料集進一步透過 TotalSegmentator 生成了額外的分割，總共 113 個標籤。該模型在 600 次掃描中接受了訓練，而驗證和測試則在 150 次 CT 掃描中進行。效能使用 Dice 分數在各種資料集上進行評估，包括 SAROS、CT-ORG、FLARE22、LCTSC、LUNA16 和 WORD。
在評估的資料集中，SALT 在 LUNA16 和 SAROS 資料集上取得了最佳結果，Dice 分數分別為 0.93 和 0.929。該模型在其他資料集上表現出可靠的準確性，在 CT-ORG 上得分為 0.891，在 FLARE22 上得分為 0.849。LCTSC 資料集的得分為 0.908，WORD 資料集的表現也很好，得分為 0.844。
SALT 利用人體固有的層級結構，以平均 35 秒的時間對 100 個切片進行全身分割。這種快速處理突顯了它整合到臨床工作流程中的潛力，促進了每次 CT 掃描的全身分割的自動化和高效計算，從而增強了診斷過程和患者護理。</paragraph>

##### **A Hybrid Spiking-Convolutional Neural Network Approach for Advancing Machine Learning Models**
2407.08861v1 by Sanaullah, Kaushik Roy, Ulrich Rückert, Thorsten Jungeblut

In this article, we propose a novel standalone hybrid Spiking-Convolutional
Neural Network (SC-NN) model and test on using image inpainting tasks. Our
approach uses the unique capabilities of SNNs, such as event-based computation
and temporal processing, along with the strong representation learning
abilities of CNNs, to generate high-quality inpainted images. The model is
trained on a custom dataset specifically designed for image inpainting, where
missing regions are created using masks. The hybrid model consists of SNNConv2d
layers and traditional CNN layers. The SNNConv2d layers implement the leaky
integrate-and-fire (LIF) neuron model, capturing spiking behavior, while the
CNN layers capture spatial features. In this study, a mean squared error (MSE)
loss function demonstrates the training process, where a training loss value of
0.015, indicates accurate performance on the training set and the model
achieved a validation loss value as low as 0.0017 on the testing set.
Furthermore, extensive experimental results demonstrate state-of-the-art
performance, showcasing the potential of integrating temporal dynamics and
feature extraction in a single network for image inpainting.

摘要：在本文中，我們提出了一個新穎的獨立混合尖峰卷積神經網路 (SC-NN) 模型，並在使用影像修復任務上進行測試。我們的做法利用了 SNN 的獨特功能，例如基於事件的運算和時間處理，以及 CNN 強大的表示學習能力，來產生高品質的修復影像。該模型在專門為影像修復設計的客製化資料集上進行訓練，其中遺失區域是使用遮罩建立的。混合模型包含 SNNConv2d 層和傳統 CNN 層。SNNConv2d 層實作了漏電整合激發 (LIF) 神經元模型，捕捉尖峰行為，而 CNN 層則捕捉空間特徵。在本研究中，均方誤差 (MSE) 損失函數展示了訓練過程，其中訓練損失值為 0.015，表示在訓練集上的準確效能，而模型在測試集上達到了低至 0.0017 的驗證損失值。此外，廣泛的實驗結果展示了最先進的效能，展示了在單一網路中整合時間動態和特徵提取在影像修復中的潛力。

##### **GPT-4 is judged more human than humans in displaced and inverted Turing tests**
2407.08853v1 by Ishika Rathi, Sydney Taylor, Benjamin K. Bergen, Cameron R. Jones

Everyday AI detection requires differentiating between people and AI in
informal, online conversations. In many cases, people will not interact
directly with AI systems but instead read conversations between AI systems and
other people. We measured how well people and large language models can
discriminate using two modified versions of the Turing test: inverted and
displaced. GPT-3.5, GPT-4, and displaced human adjudicators judged whether an
agent was human or AI on the basis of a Turing test transcript. We found that
both AI and displaced human judges were less accurate than interactive
interrogators, with below chance accuracy overall. Moreover, all three judged
the best-performing GPT-4 witness to be human more often than human witnesses.
This suggests that both humans and current LLMs struggle to distinguish between
the two when they are not actively interrogating the person, underscoring an
urgent need for more accurate tools to detect AI in conversations.

摘要：日常 AI 偵測需要在非正式的線上對話中區分人類和 AI。在許多情況下，人們不會直接與 AI 系統互動，而是閱讀 AI 系統與其他人之間的對話。我們測量了人類和大型語言模型在使用兩種修改版本的圖靈測試時的分辨能力：反向和置換。GPT-3.5、GPT-4 和置換的人類評判根據圖靈測試記錄判斷一個代理是人類還是 AI。我們發現，AI 和置換的人類評判都不如互動式詢問者準確，整體準確度低於機率。此外，所有三者都判斷表現最佳的 GPT-4 見證者是人類的頻率高於人類見證者。這表明，當人類和目前的 LLM 沒有積極詢問對方時，他們很難區分兩者，這突顯了迫切需要更準確的工具來偵測對話中的 AI。

##### **UICrit: Enhancing Automated Design Evaluation with a UICritique Dataset**
2407.08850v1 by Peitong Duan, Chin-yi Chen, Gang Li, Bjoern Hartmann, Yang Li

Automated UI evaluation can be beneficial for the design process; for
example, to compare different UI designs, or conduct automated heuristic
evaluation. LLM-based UI evaluation, in particular, holds the promise of
generalizability to a wide variety of UI types and evaluation tasks. However,
current LLM-based techniques do not yet match the performance of human
evaluators. We hypothesize that automatic evaluation can be improved by
collecting a targeted UI feedback dataset and then using this dataset to
enhance the performance of general-purpose LLMs. We present a targeted dataset
of 3,059 design critiques and quality ratings for 983 mobile UIs, collected
from seven experienced designers. We carried out an in-depth analysis to
characterize the dataset's features. We then applied this dataset to achieve a
55% performance gain in LLM-generated UI feedback via various few-shot and
visual prompting techniques. We also discuss future applications of this
dataset, including training a reward model for generative UI techniques, and
fine-tuning a tool-agnostic multi-modal LLM that automates UI evaluation.

摘要：自動化 UI 評估對設計流程有益；例如，比較不同的 UI 設計，或進行自動化啟發式評估。特別是基於 LLM 的 UI 評估，有望能廣泛應用於各種 UI 類型和評估任務。然而，當前的基於 LLM 的技術仍無法與人類評估人員的表現相匹配。我們假設，透過收集有針對性的 UI 回饋資料集，然後使用此資料集來增強通用 LLM 的效能，可以改善自動評估。我們提出了一個有針對性的資料集，其中包含七位經驗豐富的設計師收集的 983 個行動裝置 UI 的 3,059 個設計評論和品質評分。我們進行了深入的分析，以描述資料集的特徵。然後，我們應用此資料集，透過各種少次嘗試和視覺提示技術，在 LLM 生成的 UI 回饋中獲得 55% 的效能提升。我們還討論了此資料集的未來應用，包括訓練一個用於生成式 UI 技術的獎勵模型，以及微調一個自動化 UI 評估的與工具無關的多模態 LLM。

##### **Evaluating Nuanced Bias in Large Language Model Free Response Answers**
2407.08842v1 by Jennifer Healey, Laurie Byrum, Md Nadeem Akhtar, Moumita Sinha

Pre-trained large language models (LLMs) can now be easily adapted for
specific business purposes using custom prompts or fine tuning. These
customizations are often iteratively re-engineered to improve some aspect of
performance, but after each change businesses want to ensure that there has
been no negative impact on the system's behavior around such critical issues as
bias. Prior methods of benchmarking bias use techniques such as word masking
and multiple choice questions to assess bias at scale, but these do not capture
all of the nuanced types of bias that can occur in free response answers, the
types of answers typically generated by LLM systems. In this paper, we identify
several kinds of nuanced bias in free text that cannot be similarly identified
by multiple choice tests. We describe these as: confidence bias, implied bias,
inclusion bias and erasure bias. We present a semi-automated pipeline for
detecting these types of bias by first eliminating answers that can be
automatically classified as unbiased and then co-evaluating name reversed pairs
using crowd workers. We believe that the nuanced classifications our method
generates can be used to give better feedback to LLMs, especially as LLM
reasoning capabilities become more advanced.

摘要：預先訓練的大語言模型 (LLM) 現在可以使用自訂提示或微調輕鬆地適應特定業務目的。這些自訂化通常會反覆重新設計以改善效能的某些面向，但在每次變更後，企業都希望確保系統行為在偏差等關鍵問題上沒有產生負面影響。先前評量偏差的方法使用文字遮罩和多選題等技術來大規模評估偏差，但這些方法無法捕捉到自由回應答案中可能出現的所有細微偏差類型，這些答案類型通常由 LLM 系統產生。在本文中，我們找出自由文字中的幾種細微偏差類型，多選題測驗無法以類似方式找出這些偏差。我們將這些偏差描述為：信心偏差、暗示偏差、包容偏差和消除偏差。我們提出一個半自動化流程來偵測這些類型的偏差，首先消除可以自動分類為無偏差的答案，然後使用群眾工作者共同評估名稱反轉的配對。我們相信，我們的方法產生的細微分類可用於提供更好的回饋給 LLM，特別是在 LLM 推理能力變得更進階的情況下。

