{"2406.14561": {"publish_time": "2024-06-20", "title": "How to Compute the Probability of a Word", "paper_summary": "Language models (LMs) estimate the probability distribution over sequences of\nnatural language; these distributions are crucial for computing perplexity and\nsurprisal in linguistics research. While we are usually concerned with\nmeasuring these values for words, most LMs operate over subwords. Despite\nseemingly straightforward, accurately computing probabilities over one unit\ngiven probabilities over the other requires care. Indeed, we show here that\nmany recent linguistic studies have been incorrectly computing these values.\nThis paper derives the correct methods for computing word probabilities,\nhighlighting issues when relying on language models that use beginning-of-word\n(bow)-marking tokenisers, e.g., the GPT family. Empirically, we show that\ncorrecting the widespread bug in probability computations affects measured\noutcomes in sentence comprehension and lexical optimisation analyses.", "paper_summary_zh": "\u8a9e\u8a00\u6a21\u578b (LM) \u4f30\u8a08\u81ea\u7136\u8a9e\u8a00\u5e8f\u5217\u7684\u6a5f\u7387\u5206\u4f48\uff1b\u9019\u4e9b\u5206\u4f48\u5c0d\u65bc\u8a08\u7b97\u8a9e\u8a00\u5b78\u7814\u7a76\u4e2d\u7684\u56f0\u60d1\u5ea6\u548c\u9a5a\u5947\u5ea6\u81f3\u95dc\u91cd\u8981\u3002\u96d6\u7136\u6211\u5011\u901a\u5e38\u95dc\u6ce8\u6e2c\u91cf\u5b57\u8a5e\u7684\u9019\u4e9b\u503c\uff0c\u4f46\u5927\u591a\u6578 LM \u90fd\u662f\u91dd\u5c0d\u5b50\u5b57\u8a5e\u904b\u4f5c\u3002\u5118\u7ba1\u770b\u4f3c\u7c21\u55ae\uff0c\u4f46\u8981\u6839\u64da\u4e00\u500b\u55ae\u4f4d\u7684\u6a5f\u7387\u6e96\u78ba\u8a08\u7b97\u53e6\u4e00\u500b\u55ae\u4f4d\u7684\u6a5f\u7387\u9700\u8981\u5c0f\u5fc3\u3002\u4e8b\u5be6\u4e0a\uff0c\u6211\u5011\u5728\u6b64\u986f\u793a\u8a31\u591a\u6700\u8fd1\u7684\u8a9e\u8a00\u5b78\u7814\u7a76\u90fd\u932f\u8aa4\u5730\u8a08\u7b97\u4e86\u9019\u4e9b\u503c\u3002\u672c\u6587\u63a8\u5c0e\u51fa\u8a08\u7b97\u5b57\u8a5e\u6a5f\u7387\u7684\u6b63\u78ba\u65b9\u6cd5\uff0c\u4e26\u5f37\u8abf\u4f9d\u8cf4\u4f7f\u7528\u5b57\u9996\u6a19\u8a18 (bow) \u6a19\u8a18\u5316\u5668\u7684\u8a9e\u8a00\u6a21\u578b\uff08\u4f8b\u5982 GPT \u7cfb\u5217\uff09\u6642\u7684\u554f\u984c\u3002\u6839\u64da\u7d93\u9a57\uff0c\u6211\u5011\u8868\u660e\u4fee\u6b63\u6a5f\u7387\u8a08\u7b97\u4e2d\u5ee3\u6cdb\u5b58\u5728\u7684\u932f\u8aa4\u6703\u5f71\u97ff\u53e5\u5b50\u7406\u89e3\u548c\u8a5e\u5f59\u6700\u4f73\u5316\u5206\u6790\u4e2d\u6e2c\u91cf\u7684\u7d50\u679c\u3002", "author": "Tiago Pimentel et.al.", "authors": "Tiago Pimentel, Clara Meister", "id": "2406.14561v1", "paper_url": "http://arxiv.org/abs/2406.14561v1", "repo": "null"}}