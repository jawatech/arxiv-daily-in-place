{"2406.07323": {"publish_time": "2024-06-11", "title": "Should XAI Nudge Human Decisions with Explanation Biasing?", "paper_summary": "This paper reviews our previous trials of Nudge-XAI, an approach that\nintroduces automatic biases into explanations from explainable AIs (XAIs) with\nthe aim of leading users to better decisions, and it discusses the benefits and\nchallenges. Nudge-XAI uses a user model that predicts the influence of\nproviding an explanation or emphasizing it and attempts to guide users toward\nAI-suggested decisions without coercion. The nudge design is expected to\nenhance the autonomy of users, reduce the risk associated with an AI making\ndecisions without users' full agreement, and enable users to avoid AI failures.\nTo discuss the potential of Nudge-XAI, this paper reports a post-hoc\ninvestigation of previous experimental results using cluster analysis. The\nresults demonstrate the diversity of user behavior in response to Nudge-XAI,\nwhich supports our aim of enhancing user autonomy. However, it also highlights\nthe challenge of users who distrust AI and falsely make decisions contrary to\nAI suggestions, suggesting the need for personalized adjustment of the strength\nof nudges to make this approach work more generally.", "paper_summary_zh": "\u672c\u6587\u6aa2\u8996\u6211\u5011\u5148\u524d\u5c0d Nudge-XAI \u7684\u8a66\u9a57\uff0c\u9019\u662f\u4e00\u7a2e\u65b9\u6cd5\uff0c\u53ef\u5c07\u81ea\u52d5\u504f\u5dee\u5f15\u5165\u53ef\u89e3\u91cb AI (XAI) \u7684\u89e3\u91cb\u4e2d\uff0c\u76ee\u7684\u662f\u5f15\u5c0e\u4f7f\u7528\u8005\u505a\u51fa\u66f4\u597d\u7684\u6c7a\u7b56\uff0c\u4e26\u8a0e\u8ad6\u5176\u512a\u9ede\u548c\u6311\u6230\u3002Nudge-XAI \u4f7f\u7528\u4f7f\u7528\u8005\u6a21\u578b\u4f86\u9810\u6e2c\u63d0\u4f9b\u89e3\u91cb\u6216\u5f37\u8abf\u89e3\u91cb\u7684\u5f71\u97ff\uff0c\u4e26\u5617\u8a66\u5728\u6c92\u6709\u5f37\u5236\u7684\u60c5\u6cc1\u4e0b\u5f15\u5c0e\u4f7f\u7528\u8005\u671d\u5411 AI \u5efa\u8b70\u7684\u6c7a\u7b56\u3002\u9810\u671f\u63a8\u52d5\u8a2d\u8a08\u5c07\u589e\u5f37\u4f7f\u7528\u8005\u7684\u81ea\u4e3b\u6027\uff0c\u964d\u4f4e AI \u5728\u672a\u7d93\u4f7f\u7528\u8005\u5145\u5206\u540c\u610f\u4e0b\u505a\u51fa\u6c7a\u7b56\u76f8\u95dc\u7684\u98a8\u96aa\uff0c\u4e26\u8b93\u4f7f\u7528\u8005\u907f\u514d AI \u5931\u6557\u3002\u70ba\u4e86\u8a0e\u8ad6 Nudge-XAI \u7684\u6f5b\u529b\uff0c\u672c\u6587\u56de\u5831\u4e86\u4f7f\u7528\u7fa4\u96c6\u5206\u6790\u5c0d\u5148\u524d\u5be6\u9a57\u7d50\u679c\u7684\u4e8b\u5f8c\u8abf\u67e5\u3002\u7d50\u679c\u8b49\u660e\u4f7f\u7528\u8005\u884c\u70ba\u5c0d Nudge-XAI \u7684\u53cd\u61c9\u5177\u6709\u591a\u6a23\u6027\uff0c\u9019\u652f\u6301\u4e86\u6211\u5011\u589e\u5f37\u4f7f\u7528\u8005\u81ea\u4e3b\u6027\u7684\u76ee\u6a19\u3002\u7136\u800c\uff0c\u5b83\u4e5f\u7a81\u986f\u4e86\u4e0d\u4fe1\u4efb AI \u4e26\u932f\u8aa4\u5730\u505a\u51fa\u8207 AI \u5efa\u8b70\u76f8\u53cd\u6c7a\u7b56\u7684\u4f7f\u7528\u8005\u6240\u5e36\u4f86\u7684\u6311\u6230\uff0c\u9019\u8868\u793a\u9700\u8981\u91dd\u5c0d\u63a8\u52d5\u5f37\u5ea6\u9032\u884c\u500b\u4eba\u5316\u8abf\u6574\uff0c\u624d\u80fd\u8b93\u6b64\u65b9\u6cd5\u66f4\u666e\u904d\u5730\u767c\u63ee\u4f5c\u7528\u3002", "author": "Yosuke Fukuchi et.al.", "authors": "Yosuke Fukuchi, Seiji Yamada", "id": "2406.07323v1", "paper_url": "http://arxiv.org/abs/2406.07323v1", "repo": "null"}}