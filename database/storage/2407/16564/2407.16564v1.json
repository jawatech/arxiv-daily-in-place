{"2407.16564": {"publish_time": "2024-07-23", "title": "Audio Prompt Adapter: Unleashing Music Editing Abilities for Text-to-Music with Lightweight Finetuning", "paper_summary": "Text-to-music models allow users to generate nearly realistic musical audio\nwith textual commands. However, editing music audios remains challenging due to\nthe conflicting desiderata of performing fine-grained alterations on the audio\nwhile maintaining a simple user interface. To address this challenge, we\npropose Audio Prompt Adapter (or AP-Adapter), a lightweight addition to\npretrained text-to-music models. We utilize AudioMAE to extract features from\nthe input audio, and construct attention-based adapters to feedthese features\ninto the internal layers of AudioLDM2, a diffusion-based text-to-music model.\nWith 22M trainable parameters, AP-Adapter empowers users to harness both global\n(e.g., genre and timbre) and local (e.g., melody) aspects of music, using the\noriginal audio and a short text as inputs. Through objective and subjective\nstudies, we evaluate AP-Adapter on three tasks: timbre transfer, genre\ntransfer, and accompaniment generation. Additionally, we demonstrate its\neffectiveness on out-of-domain audios containing unseen instruments during\ntraining.", "paper_summary_zh": "\u6587\u5b57\u8f49\u97f3\u6a02\u6a21\u578b\u5141\u8a31\u4f7f\u7528\u8005\u4f7f\u7528\u6587\u5b57\u6307\u4ee4\u7522\u751f\u8fd1\u4e4e\u771f\u5be6\u7684\u97f3\u6a02\u97f3\u8a0a\u3002\u7136\u800c\uff0c\u7de8\u8f2f\u97f3\u6a02\u97f3\u8a0a\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\uff0c\u56e0\u70ba\u5728\u97f3\u8a0a\u4e0a\u9032\u884c\u7d30\u5fae\u7684\u8b8a\u66f4\u8207\u7dad\u6301\u7c21\u55ae\u7684\u4f7f\u7528\u8005\u4ecb\u9762\u4e4b\u9593\u5b58\u5728\u885d\u7a81\u7684\u671f\u671b\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u500b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u97f3\u8a0a\u63d0\u793a\u9069\u914d\u5668\uff08\u6216 AP-Adapter\uff09\uff0c\u9019\u662f\u9810\u5148\u8a13\u7df4\u597d\u7684\u6587\u5b57\u8f49\u97f3\u6a02\u6a21\u578b\u7684\u8f15\u91cf\u7d1a\u9644\u52a0\u529f\u80fd\u3002\u6211\u5011\u5229\u7528 AudioMAE \u5f9e\u8f38\u5165\u97f3\u8a0a\u4e2d\u8403\u53d6\u7279\u5fb5\uff0c\u4e26\u5efa\u69cb\u57fa\u65bc\u6ce8\u610f\u529b\u7684\u9069\u914d\u5668\uff0c\u5c07\u9019\u4e9b\u7279\u5fb5\u8f38\u5165\u5230\u57fa\u65bc\u64f4\u6563\u7684\u6587\u5b57\u8f49\u97f3\u6a02\u6a21\u578b AudioLDM2 \u7684\u5167\u90e8\u5c64\u7d1a\u3002AP-Adapter \u64c1\u6709 22M \u500b\u53ef\u8a13\u7df4\u53c3\u6578\uff0c\u8b93\u4f7f\u7528\u8005\u80fd\u5920\u5229\u7528\u539f\u59cb\u97f3\u8a0a\u548c\u7c21\u77ed\u6587\u5b57\u4f5c\u70ba\u8f38\u5165\uff0c\u540c\u6642\u904b\u7528\u97f3\u6a02\u7684\u5168\u5c40\uff08\u4f8b\u5982\uff0c\u985e\u578b\u548c\u97f3\u8272\uff09\u548c\u5c40\u90e8\uff08\u4f8b\u5982\uff0c\u65cb\u5f8b\uff09\u9762\u5411\u3002\u900f\u904e\u5ba2\u89c0\u548c\u4e3b\u89c0\u7814\u7a76\uff0c\u6211\u5011\u5728\u4e09\u500b\u4efb\u52d9\u4e0a\u8a55\u4f30 AP-Adapter\uff1a\u97f3\u8272\u8f49\u79fb\u3001\u985e\u578b\u8f49\u79fb\u548c\u4f34\u594f\u7522\u751f\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c55\u793a\u4e86\u5b83\u5728\u8a13\u7df4\u671f\u9593\u5305\u542b\u672a\u898b\u6a02\u5668\u7684\u9818\u57df\u5916\u97f3\u8a0a\u4e0a\u7684\u6709\u6548\u6027\u3002", "author": "Fang-Duo Tsai et.al.", "authors": "Fang-Duo Tsai, Shih-Lun Wu, Haven Kim, Bo-Yu Chen, Hao-Chung Cheng, Yi-Hsuan Yang", "id": "2407.16564v1", "paper_url": "http://arxiv.org/abs/2407.16564v1", "repo": "https://github.com/fundwotsai2001/ap-adapter"}}