{"2502.02790": {"publish_time": "2025-02-05", "title": "Leveraging the true depth of LLMs", "paper_summary": "Large Language Models demonstrate remarkable capabilities at the cost of high\ncompute requirements. While recent research has shown that intermediate layers\ncan be removed or have their order shuffled without impacting performance\nsignificantly, these findings have not been employed to reduce the\ncomputational cost of inference. We investigate several potential ways to\nreduce the depth of pre-trained LLMs without significantly affecting\nperformance. Leveraging our insights, we present a novel approach that exploits\nthis decoupling between layers by grouping some of them into pairs that can be\nevaluated in parallel.\n  This modification of the computational graph -- through better parallelism --\nresults in an average improvement of around 1.20x on the number of tokens\ngenerated per second, without re-training nor fine-tuning, while retaining\n95%-99% of the original accuracy. Empirical evaluation demonstrates that this\napproach significantly improves serving efficiency while maintaining model\nperformance, offering a practical improvement for large-scale LLM deployment.", "paper_summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c55\u793a\u4e86\u5176\u5f3a\u5927\u7684\u529f\u80fd\uff0c\u4f46\u4ee3\u4ef7\u662f\u8f83\u9ad8\u7684\u8ba1\u7b97\u9700\u6c42\u3002\u867d\u7136\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u4e2d\u95f4\u5c42\u53ef\u4ee5\u88ab\u79fb\u9664\u6216\u91cd\u65b0\u6392\u5217\u5176\u987a\u5e8f\uff0c\u800c\u4e0d\u4f1a\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff0c\u4f46\u8fd9\u4e9b\u53d1\u73b0\u5c1a\u672a\u88ab\u7528\u6765\u964d\u4f4e\u63a8\u7406\u7684\u8ba1\u7b97\u6210\u672c\u3002\u6211\u4eec\u7814\u7a76\u4e86\u51e0\u79cd\u6f5c\u5728\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u9884\u8bad\u7ec3 LLM \u7684\u6df1\u5ea6\uff0c\u800c\u4e0d\u4f1a\u663e\u8457\u5f71\u54cd\u6027\u80fd\u3002\u5229\u7528\u6211\u4eec\u7684\u89c1\u89e3\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u5176\u4e2d\u4e00\u4e9b\u5206\u7ec4\u4e3a\u53ef\u4ee5\u5e76\u884c\u8bc4\u4f30\u7684\u6210\u5bf9\u6765\u5229\u7528\u5c42\u4e4b\u95f4\u7684\u8fd9\u79cd\u89e3\u8026\u3002\n\u901a\u8fc7\u66f4\u597d\u7684\u5e76\u884c\u6027\u5bf9\u8ba1\u7b97\u56fe\u8fdb\u884c\u4fee\u6539\uff0c\u5e73\u5747\u800c\u8a00\uff0c\u6bcf\u79d2\u751f\u6210\u7684\u4ee4\u724c\u6570\u91cf\u63d0\u9ad8\u4e86\u7ea6 1.20 \u500d\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u5fae\u8c03\uff0c\u540c\u65f6\u4fdd\u7559\u4e86 95%-99% \u7684\u539f\u59cb\u51c6\u786e\u6027\u3002\u7ecf\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u670d\u52a1\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u5927\u89c4\u6a21 LLM \u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u9645\u6539\u8fdb\u3002", "author": "Ram\u00f3n Calvo Gonz\u00e1lez et.al.", "authors": "Ram\u00f3n Calvo Gonz\u00e1lez, Daniele Paliotta, Matteo Pagliardini, Martin Jaggi, Fran\u00e7ois Fleuret", "id": "2502.02790v1", "paper_url": "http://arxiv.org/abs/2502.02790v1", "repo": "null"}}