{"2405.05688": {"publish_time": "2024-05-09", "title": "Evaluating Dialect Robustness of Language Models via Conversation Understanding", "paper_summary": "With an evergrowing number of LLMs reporting superlative performance for\nEnglish, their ability to perform equitably for different dialects of English\n(i.e., dialect robustness) needs to be ascertained. Specifically, we use\nEnglish language (US English or Indian English) conversations between humans\nwho play the word-guessing game of `taboo'. We formulate two evaluative tasks:\ntarget word prediction (TWP) (i.e.predict the masked target word in a\nconversation) and target word selection (TWS) (i.e., select the most likely\nmasked target word in a conversation, from among a set of candidate words).\nExtending MD3, an existing dialectic dataset of taboo-playing conversations, we\nintroduce M-MD3, a target-word-masked version of MD3 with the USEng and IndEng\nsubsets. We add two subsets: AITrans (where dialectic information is removed\nfrom IndEng) and AIGen (where LLMs are prompted to generate conversations). Our\nevaluation uses pre-trained and fine-tuned versions of two closed-source\n(GPT-4/3.5) and two open-source LLMs (Mistral and Gemma). LLMs perform\nsignificantly better for US English than Indian English for both TWP and TWS,\nfor all settings. While GPT-based models perform the best, the comparatively\nsmaller models work more equitably for short conversations (<8 turns). Our\nresults on AIGen and AITrans (the best and worst-performing subset)\nrespectively show that LLMs may learn a dialect of their own based on the\ncomposition of the training data, and that dialect robustness is indeed a\nchallenging task. Our evaluation methodology exhibits a novel way to examine\nattributes of language models using pre-existing dialogue datasets.", "paper_summary_zh": "\u96a8\u8457\u8d8a\u4f86\u8d8a\u591a\u7684 LLM \u5831\u544a\u82f1\u8a9e\u7684\u5353\u8d8a\u6548\u80fd\uff0c\u9700\u8981\u78ba\u5b9a\u5b83\u5011\u5c0d\u4e0d\u540c\u82f1\u8a9e\u65b9\u8a00\uff08\u5373\u65b9\u8a00\u7a69\u5065\u6027\uff09\u57f7\u884c\u516c\u5e73\u7684\u6548\u80fd\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u4f7f\u7528\u82f1\u8a9e\uff08\u7f8e\u570b\u82f1\u8a9e\u6216\u5370\u5ea6\u82f1\u8a9e\uff09\u5c0d\u8a71\uff0c\u5c0d\u8a71\u8005\u662f\u73a9\u300c\u7981\u5fcc\u300d\u6587\u5b57\u731c\u8b0e\u904a\u6232\u7684\u4eba\u985e\u3002\u6211\u5011\u5236\u5b9a\u4e86\u5169\u500b\u8a55\u4f30\u4efb\u52d9\uff1a\u76ee\u6a19\u8a5e\u5f59\u9810\u6e2c\uff08TWP\uff09\uff08\u5373\u9810\u6e2c\u5c0d\u8a71\u4e2d\u88ab\u906e\u84cb\u7684\u76ee\u6a19\u8a5e\u5f59\uff09\u548c\u76ee\u6a19\u8a5e\u5f59\u9078\u64c7\uff08TWS\uff09\uff08\u5373\u5f9e\u4e00\u7d44\u5019\u9078\u8a5e\u5f59\u4e2d\u9078\u64c7\u5c0d\u8a71\u4e2d\u6700\u53ef\u80fd\u7684\u88ab\u906e\u84cb\u76ee\u6a19\u8a5e\u5f59\uff09\u3002\u64f4\u5c55 MD3\uff0c\u4e00\u500b\u73fe\u6709\u7684\u7981\u5fcc\u5c0d\u8a71\u65b9\u8a00\u6578\u64da\u96c6\uff0c\u6211\u5011\u5f15\u5165\u4e86 M-MD3\uff0c\u4e00\u500b\u76ee\u6a19\u8a5e\u5f59\u906e\u84cb\u7248\u672c\u7684 MD3\uff0c\u5305\u542b USEng \u548c IndEng \u5b50\u96c6\u3002\u6211\u5011\u589e\u52a0\u4e86\u5169\u500b\u5b50\u96c6\uff1aAITrans\uff08\u5f9e IndEng \u4e2d\u79fb\u9664\u4e86\u65b9\u8a00\u8cc7\u8a0a\uff09\u548c AIGen\uff08\u63d0\u793a LLM \u7522\u751f\u5c0d\u8a71\uff09\u3002\u6211\u5011\u7684\u8a55\u4f30\u4f7f\u7528\u9810\u5148\u8a13\u7df4\u548c\u5fae\u8abf\u7684\u5169\u500b\u9589\u6e90\uff08GPT-4/3.5\uff09\u548c\u5169\u500b\u958b\u6e90 LLM\uff08Mistral \u548c Gemma\uff09\u3002\u5c0d\u65bc TWP \u548c TWS\uff0c\u5728\u6240\u6709\u8a2d\u5b9a\u4e2d\uff0cLLM \u5c0d\u7f8e\u570b\u82f1\u8a9e\u7684\u8868\u73fe\u660e\u986f\u512a\u65bc\u5370\u5ea6\u82f1\u8a9e\u3002\u96d6\u7136\u57fa\u65bc GPT \u7684\u6a21\u578b\u8868\u73fe\u6700\u4f73\uff0c\u4f46\u8f03\u5c0f\u7684\u6a21\u578b\u5728\u8f03\u77ed\u7684\u5c0d\u8a71\uff08<8 \u56de\u5408\uff09\u4e2d\u8868\u73fe\u5f97\u66f4\u516c\u5e73\u3002\u6211\u5011\u5c0d AIGen \u548c AITrans\uff08\u8868\u73fe\u6700\u4f73\u548c\u6700\u5dee\u7684\u5b50\u96c6\uff09\u7684\u7d50\u679c\u5206\u5225\u986f\u793a\uff0cLLM \u53ef\u80fd\u6839\u64da\u8a13\u7df4\u8cc7\u6599\u7684\u7d44\u6210\u5b78\u7fd2\u81ea\u5df1\u7684\u65b9\u8a00\uff0c\u4e26\u4e14\u65b9\u8a00\u7a69\u5065\u6027\u78ba\u5be6\u662f\u4e00\u9805\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\u3002\u6211\u5011\u7684\u8a55\u4f30\u65b9\u6cd5\u5c55\u793a\u4e86\u4e00\u7a2e\u4f7f\u7528\u73fe\u6709\u5c0d\u8a71\u6578\u64da\u96c6\u6aa2\u67e5\u8a9e\u8a00\u6a21\u578b\u5c6c\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "author": "Dipankar Srirag et.al.", "authors": "Dipankar Srirag, Aditya Joshi", "id": "2405.05688v1", "paper_url": "http://arxiv.org/abs/2405.05688v1", "repo": "null"}}