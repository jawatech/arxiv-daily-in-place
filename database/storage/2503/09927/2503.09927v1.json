{"2503.09927": {"publish_time": "2025-03-13", "title": "Developing and Evaluating an AI-Assisted Prediction Model for Unplanned Intensive Care Admissions following Elective Neurosurgery using Natural Language Processing within an Electronic Healthcare Record System", "paper_summary": "Introduction: Timely care in a specialised neuro-intensive therapy unit (ITU)\nreduces mortality and hospital stays, with planned admissions being safer than\nunplanned ones. However, post-operative care decisions remain subjective. This\nstudy used artificial intelligence (AI), specifically natural language\nprocessing (NLP) to analyse electronic health records (EHRs) and predict ITU\nadmissions for elective surgery patients. Methods: This study analysed the EHRs\nof elective neurosurgery patients from University College London Hospital\n(UCLH) using NLP. Patients were categorised into planned high dependency unit\n(HDU) or ITU admission; unplanned HDU or ITU admission; or ward / overnight\nrecovery (ONR). The Medical Concept Annotation Tool (MedCAT) was used to\nidentify SNOMED-CT concepts within the clinical notes. We then explored the\nutility of these identified concepts for a range of AI algorithms trained to\npredict ITU admission. Results: The CogStack-MedCAT NLP model, initially\ntrained on hospital-wide EHRs, underwent two refinements: first with data from\npatients with Normal Pressure Hydrocephalus (NPH) and then with data from\nVestibular Schwannoma (VS) patients, achieving a concept detection F1-score of\n0.93. This refined model was then used to extract concepts from EHR notes of\n2,268 eligible neurosurgical patients. We integrated the extracted concepts\ninto AI models, including a decision tree model and a neural time-series model.\nUsing the simpler decision tree model, we achieved a recall of 0.87 (CI 0.82 -\n0.91) for ITU admissions, reducing the proportion of unplanned ITU cases missed\nby human experts from 36% to 4%. Conclusion: The NLP model, refined for\naccuracy, has proven its efficiency in extracting relevant concepts, providing\na reliable basis for predictive AI models to use in clinically valid\napplications.", "paper_summary_zh": "<paragraph>\u524d\u8a00\uff1a\u5728\u5c08\u9580\u7684\u795e\u7d93\u52a0\u8b77\u75c5\u623f (ITU) \u4e2d\u53ca\u6642\u6cbb\u7642\u53ef\u4ee5\u964d\u4f4e\u6b7b\u4ea1\u7387\u548c\u4f4f\u9662\u6642\u9593\uff0c\u800c\u4e14\u8a08\u5283\u5167\u7684\u5165\u9662\u6bd4\u8a08\u5283\u5916\u7684\u5165\u9662\u66f4\u5b89\u5168\u3002\u7136\u800c\uff0c\u8853\u5f8c\u8b77\u7406\u6c7a\u7b56\u4ecd\u7136\u5e36\u6709\u4e3b\u89c0\u6027\u3002\u672c\u7814\u7a76\u4f7f\u7528\u4eba\u5de5\u667a\u6167 (AI)\uff0c\u7279\u5225\u662f\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4f86\u5206\u6790\u96fb\u5b50\u5065\u5eb7\u8a18\u9304 (EHR) \u4e26\u9810\u6e2c\u64c7\u671f\u624b\u8853\u60a3\u8005\u7684 ITU \u5165\u9662\u60c5\u6cc1\u3002\u65b9\u6cd5\uff1a\u672c\u7814\u7a76\u4f7f\u7528 NLP \u5206\u6790\u4e86\u502b\u6566\u5927\u5b78\u5b78\u9662\u91ab\u9662 (UCLH) \u64c7\u671f\u795e\u7d93\u5916\u79d1\u60a3\u8005\u7684 EHR\u3002\u60a3\u8005\u88ab\u5206\u70ba\u8a08\u5283\u5167\u9ad8\u4f9d\u8cf4\u75c5\u623f (HDU) \u6216 ITU \u5165\u9662\uff1b\u8a08\u5283\u5916 HDU \u6216 ITU \u5165\u9662\uff1b\u6216\u666e\u901a\u75c5\u623f/\u904e\u591c\u6062\u5fa9\u5ba4 (ONR)\u3002\u91ab\u7642\u6982\u5ff5\u8a3b\u91cb\u5de5\u5177 (MedCAT) \u7528\u65bc\u8b58\u5225\u81e8\u5e8a\u8a18\u9304\u4e2d\u7684 SNOMED-CT \u6982\u5ff5\u3002\u7136\u5f8c\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u9019\u4e9b\u5df2\u8b58\u5225\u6982\u5ff5\u5728\u4e00\u7cfb\u5217\u7d93\u8a13\u7df4\u7528\u65bc\u9810\u6e2c ITU \u5165\u9662\u7684 AI \u6f14\u7b97\u6cd5\u4e2d\u7684\u6548\u7528\u3002\u7d50\u679c\uff1aCogStack-MedCAT NLP \u6a21\u578b\u6700\u521d\u4f7f\u7528\u5168\u9662 EHR \u6578\u64da\u9032\u884c\u8a13\u7df4\uff0c\u7d93\u904e\u5169\u6b21\u6539\u9032\uff1a\u9996\u5148\u4f7f\u7528\u6b63\u5e38\u58d3\u529b\u8166\u7a4d\u6c34 (NPH) \u60a3\u8005\u7684\u6578\u64da\uff0c\u7136\u5f8c\u4f7f\u7528\u524d\u5ead\u795e\u7d93\u9798\u7624 (VS) \u60a3\u8005\u7684\u6578\u64da\uff0c\u6700\u7d42\u6982\u5ff5\u6aa2\u6e2c\u7684 F1 \u503c\u9054\u5230 0.93\u3002\u7136\u5f8c\uff0c\u4f7f\u7528\u9019\u500b\u6539\u9032\u7684\u6a21\u578b\u5f9e 2,268 \u540d\u7b26\u5408\u689d\u4ef6\u7684\u795e\u7d93\u5916\u79d1\u60a3\u8005\u7684 EHR \u8a18\u9304\u4e2d\u63d0\u53d6\u6982\u5ff5\u3002\u6211\u5011\u5c07\u63d0\u53d6\u7684\u6982\u5ff5\u6574\u5408\u5230 AI \u6a21\u578b\u4e2d\uff0c\u5305\u62ec\u6c7a\u7b56\u6a39\u6a21\u578b\u548c\u795e\u7d93\u6642\u9593\u5e8f\u5217\u6a21\u578b\u3002\u4f7f\u7528\u66f4\u7c21\u55ae\u7684\u6c7a\u7b56\u6a39\u6a21\u578b\uff0c\u6211\u5011\u5728 ITU \u5165\u9662\u9810\u6e2c\u4e2d\u9054\u5230\u4e86 0.87 \u7684\u53ec\u56de\u7387\uff08CI 0.82 - 0.91\uff09\uff0c\u5c07\u4eba\u985e\u5c08\u5bb6\u907a\u6f0f\u7684\u8a08\u5283\u5916 ITU \u75c5\u4f8b\u7684\u6bd4\u4f8b\u5f9e 36% \u964d\u4f4e\u5230 4%\u3002\u7d50\u8ad6\uff1a\u7d93\u904e\u7cbe\u5ea6\u6539\u9032\u7684 NLP \u6a21\u578b\u5df2\u8b49\u660e\u5176\u5728\u63d0\u53d6\u76f8\u95dc\u6982\u5ff5\u65b9\u9762\u7684\u6548\u7387\uff0c\u70ba\u9810\u6e2c\u6027 AI \u6a21\u578b\u5728\u81e8\u5e8a\u6709\u6548\u61c9\u7528\u4e2d\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u57fa\u790e\u3002</paragraph>\n", "author": "Julia Ive et.al.", "authors": "Julia Ive, Olatomiwa Olukoya, Jonathan P. Funnell, James Booker, Sze H M Lam, Ugan Reddy, Kawsar Noor, Richard JB Dobson, Astri M. V. Luoma, Hani J Marcus", "id": "2503.09927v1", "paper_url": "http://arxiv.org/abs/2503.09927v1", "repo": "null"}}