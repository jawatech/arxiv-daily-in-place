{"2207.04969": {"publish_time": "2022-07-11", "title": "From Correlation to Causation: Formalizing Interpretable Machine Learning as a Statistical Process", "paper_summary": "Explainable AI (XAI) is a necessity in safety-critical systems such as in\nclinical diagnostics due to a high risk for fatal decisions. Currently,\nhowever, XAI resembles a loose collection of methods rather than a well-defined\nprocess. In this work, we elaborate on conceptual similarities between the\nlargest subgroup of XAI, interpretable machine learning (IML), and classical\nstatistics. Based on these similarities, we present a formalization of IML\nalong the lines of a statistical process. Adopting this statistical view allows\nus to interpret machine learning models and IML methods as sophisticated\nstatistical tools. Based on this interpretation, we infer three key questions,\nwhich we identify as crucial for the success and adoption of IML in\nsafety-critical settings. By formulating these questions, we further aim to\nspark a discussion about what distinguishes IML from classical statistics and\nwhat our perspective implies for the future of the field.", "paper_summary_zh": "", "author": "Lukas Klein et.al.", "authors": "Lukas Klein,Mennatallah El-Assady,Paul F. J\u00e4ger", "id": "2207.04969v1", "paper_url": "http://arxiv.org/abs/2207.04969v1", "repo": "null"}}