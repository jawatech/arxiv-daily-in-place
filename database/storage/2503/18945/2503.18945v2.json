{"2503.18945": {"publish_time": "2025-03-24", "title": "Aether: Geometric-Aware Unified World Modeling", "paper_summary": "The integration of geometric reconstruction and generative modeling remains a\ncritical challenge in developing AI systems capable of human-like spatial\nreasoning. This paper proposes Aether, a unified framework that enables\ngeometry-aware reasoning in world models by jointly optimizing three core\ncapabilities: (1) 4D dynamic reconstruction, (2) action-conditioned video\nprediction, and (3) goal-conditioned visual planning. Through task-interleaved\nfeature learning, Aether achieves synergistic knowledge sharing across\nreconstruction, prediction, and planning objectives. Building upon video\ngeneration models, our framework demonstrates unprecedented synthetic-to-real\ngeneralization despite never observing real-world data during training.\nFurthermore, our approach achieves zero-shot generalization in both action\nfollowing and reconstruction tasks, thanks to its intrinsic geometric modeling.\nRemarkably, even without real-world data, its reconstruction performance is\ncomparable with or even better than that of domain-specific models.\nAdditionally, Aether employs camera trajectories as geometry-informed action\nspaces, enabling effective action-conditioned prediction and visual planning.\nWe hope our work inspires the community to explore new frontiers in\nphysically-reasonable world modeling and its applications.", "paper_summary_zh": "<paragraph>\u5c07\u5e7e\u4f55\u91cd\u5efa\u8207\u751f\u6210\u6a21\u578b\u6574\u5408\u4ecd\u7136\u662f\u958b\u767c\u5177\u5099\u985e\u4f3c\u4eba\u985e\u7a7a\u9593\u63a8\u7406\u80fd\u529b\u7684 AI \u7cfb\u7d71\u7684\u4e00\u9805\u95dc\u9375\u6311\u6230\u3002\u672c\u6587\u63d0\u51fa\u4e86 Aether\uff0c\u9019\u662f\u4e00\u500b\u7d71\u4e00\u7684\u6846\u67b6\uff0c\u5b83\u901a\u904e\u5171\u540c\u512a\u5316\u4e09\u500b\u6838\u5fc3\u529f\u80fd\uff0c\u5728\u4e16\u754c\u6a21\u578b\u4e2d\u5be6\u73fe\u5e7e\u4f55\u611f\u77e5\u63a8\u7406\uff1a(1) 4D \u52d5\u614b\u91cd\u5efa\uff0c(2) \u57fa\u65bc\u52d5\u4f5c\u7684\u8996\u983b\u9810\u6e2c\uff0c\u4ee5\u53ca (3) \u57fa\u65bc\u76ee\u6a19\u7684\u8996\u89ba\u898f\u5283\u3002\u900f\u904e\u4efb\u52d9\u4ea4\u932f\u7684\u7279\u5fb5\u5b78\u7fd2\uff0cAether \u5728\u91cd\u5efa\u3001\u9810\u6e2c\u548c\u898f\u5283\u76ee\u6a19\u4e4b\u9593\u5be6\u73fe\u4e86\u5354\u540c\u77e5\u8b58\u5171\u4eab\u3002\u57fa\u65bc\u8996\u983b\u751f\u6210\u6a21\u578b\uff0c\u5118\u7ba1\u5728\u8a13\u7df4\u671f\u9593\u5f9e\u672a\u89c0\u5bdf\u5230\u771f\u5be6\u4e16\u754c\u7684\u6578\u64da\uff0c\u6211\u5011\u7684\u6846\u67b6\u5c55\u73fe\u4e86\u524d\u6240\u672a\u6709\u7684\u5408\u6210\u5230\u771f\u5be6\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u7531\u65bc\u5176\u5167\u5728\u7684\u5e7e\u4f55\u5efa\u6a21\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u5728\u52d5\u4f5c\u8ddf\u96a8\u548c\u91cd\u5efa\u4efb\u52d9\u4e2d\u90fd\u5be6\u73fe\u4e86\u96f6\u6a23\u672c\u6cdb\u5316\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5373\u4f7f\u6c92\u6709\u771f\u5be6\u4e16\u754c\u7684\u6578\u64da\uff0c\u5176\u91cd\u5efa\u6027\u80fd\u4e5f\u8207\u7279\u5b9a\u9818\u57df\u7684\u6a21\u578b\u76f8\u7576\uff0c\u751a\u81f3\u66f4\u597d\u3002\u6b64\u5916\uff0cAether \u4f7f\u7528\u76f8\u6a5f\u8ecc\u8de1\u4f5c\u70ba\u5e7e\u4f55\u4fe1\u606f\u7684\u52d5\u4f5c\u7a7a\u9593\uff0c\u5f9e\u800c\u5be6\u73fe\u6709\u6548\u7684\u57fa\u65bc\u52d5\u4f5c\u7684\u9810\u6e2c\u548c\u8996\u89ba\u898f\u5283\u3002\u6211\u5011\u5e0c\u671b\u9019\u9805\u5de5\u4f5c\u80fd\u5920\u6fc0\u52f5\u793e\u7fa4\u63a2\u7d22\u7269\u7406\u5408\u7406\u7684\u4e16\u754c\u5efa\u6a21\u53ca\u5176\u61c9\u7528\u65b9\u9762\u7684\u65b0\u9818\u57df\u3002</paragraph>\n", "author": "Aether Team et.al.", "authors": "Aether Team, Haoyi Zhu, Yifan Wang, Jianjun Zhou, Wenzheng Chang, Yang Zhou, Zizun Li, Junyi Chen, Chunhua Shen, Jiangmiao Pang, Tong He", "id": "2503.18945v2", "paper_url": "http://arxiv.org/abs/2503.18945v2", "repo": "null"}}