{"2406.09321": {"publish_time": "2024-06-13", "title": "JailbreakEval: An Integrated Toolkit for Evaluating Jailbreak Attempts Against Large Language Models", "paper_summary": "Jailbreak attacks aim to induce Large Language Models (LLMs) to generate\nharmful responses for forbidden instructions, presenting severe misuse threats\nto LLMs. Up to now, research into jailbreak attacks and defenses is emerging,\nhowever, there is (surprisingly) no consensus on how to evaluate whether a\njailbreak attempt is successful. In other words, the methods to assess the\nharmfulness of an LLM's response are varied, such as manual annotation or\nprompting GPT-4 in specific ways. Each approach has its own set of strengths\nand weaknesses, impacting their alignment with human values, as well as the\ntime and financial cost. This diversity in evaluation presents challenges for\nresearchers in choosing suitable evaluation methods and conducting fair\ncomparisons across different jailbreak attacks and defenses. In this paper, we\nconduct a comprehensive analysis of jailbreak evaluation methodologies, drawing\nfrom nearly ninety jailbreak research released between May 2023 and April 2024.\nOur study introduces a systematic taxonomy of jailbreak evaluators, offering\nin-depth insights into their strengths and weaknesses, along with the current\nstatus of their adaptation. Moreover, to facilitate subsequent research, we\npropose JailbreakEval, a user-friendly toolkit focusing on the evaluation of\njailbreak attempts. It includes various well-known evaluators out-of-the-box,\nso that users can obtain evaluation results with only a single command.\nJailbreakEval also allows users to customize their own evaluation workflow in a\nunified framework with the ease of development and comparison. In summary, we\nregard JailbreakEval to be a catalyst that simplifies the evaluation process in\njailbreak research and fosters an inclusive standard for jailbreak evaluation\nwithin the community.", "paper_summary_zh": "\u8d8a\u7344\u653b\u64ca\u65e8\u5728\u8a98\u5c0e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c0d\u7981\u6b62\u7684\u6307\u4ee4\u7522\u751f\u6709\u5bb3\u7684\u56de\u61c9\uff0c\u5c0d LLM \u69cb\u6210\u56b4\u91cd\u7684\u6feb\u7528\u5a01\u8105\u3002\u5230\u76ee\u524d\u70ba\u6b62\uff0c\u5c0d\u8d8a\u7344\u653b\u64ca\u548c\u9632\u79a6\u7684\u7814\u7a76\u6b63\u5728\u8208\u8d77\uff0c\u7136\u800c\uff0c\uff08\u4ee4\u4eba\u9a5a\u8a1d\u7684\u662f\uff09\u5c0d\u65bc\u5982\u4f55\u8a55\u4f30\u8d8a\u7344\u5617\u8a66\u662f\u5426\u6210\u529f\u5c1a\u672a\u9054\u6210\u5171\u8b58\u3002\u63db\u53e5\u8a71\u8aaa\uff0c\u8a55\u4f30 LLM \u56de\u61c9\u7684\u5371\u5bb3\u6027\u7684\u65b9\u6cd5\u662f\u591a\u7a2e\u591a\u6a23\u7684\uff0c\u4f8b\u5982\u4eba\u5de5\u8a3b\u91cb\u6216\u4ee5\u7279\u5b9a\u65b9\u5f0f\u63d0\u793a GPT-4\u3002\u6bcf\u7a2e\u65b9\u6cd5\u90fd\u6709\u81ea\u5df1\u7684\u4e00\u7d44\u512a\u7f3a\u9ede\uff0c\u5f71\u97ff\u5b83\u5011\u8207\u4eba\u985e\u50f9\u503c\u89c0\u7684\u4e00\u81f4\u6027\uff0c\u4ee5\u53ca\u6642\u9593\u548c\u8ca1\u52d9\u6210\u672c\u3002\u8a55\u4f30\u4e2d\u7684\u9019\u7a2e\u591a\u6a23\u6027\u5c0d\u7814\u7a76\u4eba\u54e1\u5728\u9078\u64c7\u5408\u9069\u7684\u8a55\u4f30\u65b9\u6cd5\u4ee5\u53ca\u5c0d\u4e0d\u540c\u7684\u8d8a\u7344\u653b\u64ca\u548c\u9632\u79a6\u9032\u884c\u516c\u5e73\u6bd4\u8f03\u63d0\u51fa\u4e86\u6311\u6230\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5c0d\u8d8a\u7344\u8a55\u4f30\u65b9\u6cd5\u9032\u884c\u4e86\u5168\u9762\u7684\u5206\u6790\uff0c\u501f\u9452\u4e86 2023 \u5e74 5 \u6708\u81f3 2024 \u5e74 4 \u6708\u4e4b\u9593\u767c\u5e03\u7684\u8fd1 90 \u9805\u8d8a\u7344\u7814\u7a76\u3002\u6211\u5011\u7684\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u500b\u7cfb\u7d71\u7684\u8d8a\u7344\u8a55\u4f30\u5668\u5206\u985e\u6cd5\uff0c\u6df1\u5165\u4e86\u89e3\u5b83\u5011\u7684\u512a\u7f3a\u9ede\uff0c\u4ee5\u53ca\u5b83\u5011\u9069\u61c9\u7684\u7576\u524d\u72c0\u614b\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u4fc3\u9032\u5f8c\u7e8c\u7814\u7a76\uff0c\u6211\u5011\u63d0\u51fa\u4e86 JailbreakEval\uff0c\u9019\u662f\u4e00\u500b\u5c08\u6ce8\u65bc\u8a55\u4f30\u8d8a\u7344\u5617\u8a66\u7684\u7528\u6236\u53cb\u597d\u5de5\u5177\u5305\u3002\u5b83\u5305\u542b\u5404\u7a2e\u958b\u7bb1\u5373\u7528\u7684\u77e5\u540d\u8a55\u4f30\u5668\uff0c\u4ee5\u4fbf\u7528\u6236\u53ea\u9700\u4e00\u500b\u547d\u4ee4\u5373\u53ef\u7372\u5f97\u8a55\u4f30\u7d50\u679c\u3002JailbreakEval \u9084\u5141\u8a31\u7528\u6236\u5728\u7d71\u4e00\u7684\u6846\u67b6\u4e2d\u81ea\u5b9a\u7fa9\u81ea\u5df1\u7684\u8a55\u4f30\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4e26\u8f15\u9b06\u9032\u884c\u958b\u767c\u548c\u6bd4\u8f03\u3002\u7e3d\u4e4b\uff0c\u6211\u5011\u8a8d\u70ba JailbreakEval \u662f\u7c21\u5316\u8d8a\u7344\u7814\u7a76\u4e2d\u8a55\u4f30\u904e\u7a0b\u7684\u50ac\u5316\u5291\uff0c\u4e26\u5728\u793e\u5340\u5167\u57f9\u990a\u8d8a\u7344\u8a55\u4f30\u7684\u5305\u5bb9\u6027\u6a19\u6e96\u3002", "author": "Delong Ran et.al.", "authors": "Delong Ran, Jinyuan Liu, Yichen Gong, Jingyi Zheng, Xinlei He, Tianshuo Cong, Anyu Wang", "id": "2406.09321v1", "paper_url": "http://arxiv.org/abs/2406.09321v1", "repo": "https://github.com/thuccslab/jailbreakeval"}}