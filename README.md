# arxiv-daily
 Automated deployment @ 2024-11-18 20:38:14 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|

#### Abstracts
##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

æè¦ï¼å°åå¿èç¾çåç¾åå¤©æ§èå¾å¤©æ§ç¾ççå»£æ³åè­ãè¼è¤éçåå¤©æ§ç¸å½¢éè¦ä¸åå·®ç°åä¸å¤æ¨¡å¼çæ±ºç­éç¨ï¼éå¸¸åæ¬è¶é³æ³¢æª¢æ¥ä½çºä¸»è¦çå½±åæ¹æ³ãäººå·¥æºæ§ (AI) çºè¨åºé«çæä¾äºç¸ç¶å¤§çå¸æï¼å çºå®å¯ä»¥ä¿é²å°åè¶é³æ³¢æª¢æ¥è³æçèªååè§£è®ãç¶èï¼å°äººå·¥æºæ§æè¡æç¨æ¼å°åè¶é³æ³¢æª¢æ¥åææè¨±å¤ææ°ï¼ä¾å¦æéçå¬éè³æå¯ç¨æ§ãè³æé±ç§åäººå·¥æºæ§æ¨¡åéæåº¦ãæè¿ï¼ç ç©¶äººå¡å°æ³¨æ¼ç ´å£æ§æè¡ï¼ä¾å¦è¯åå­¸ç¿ (FL) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥æ¹åèªåè¨ºæ·åæ±ºç­æ¯æ´å·¥ä½æµç¨ãæ¬ç ç©¶æä¾äºäººå·¥æºæ§å¨å°åè¶é³æ³¢æª¢æ¥ä¸­çéå¶åæ©æçå¨é¢æ¦è¿°ï¼å¼·èª¿äº XAI å FL çååå·¥ä½æµç¨åè§è²ï¼æ¾åºç ç©¶å·®è·ä¸¦æ¢è¨æ½å¨çæªä¾ç¼å±ãæ­¤å¤ï¼ä¸åç¸éçè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº XAI å FL çåè½ï¼éé»å¨æ¼ (i) æª¢è¦è¾¨è­ã(ii) ç¾çåé¡ã(iii) å¿èçµæ§åå²å (iv) å¿èåè½çéåè©ä¼°ã

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

æè¦ï¼éª¨è³ªçé¬çæ¯ä¸ç¨®å¸¸è¦çç¾çï¼æå¢å éª¨æçé¢¨éªï¼ç¹å¥æ¯èå¹´äººãæ©æè¨ºæ·å°æ¼é é²éª¨æãéä½æ²»çææ¬åç¶­æè¡åè½åè³ééè¦ãç¶èï¼é«çä¿å¥æä¾èé¢è¨èæ¨è¨æ¸ææéåèçé«å­¸å½±åå°é£ç­ææ°ãæ¬ç ç©¶æåºäºä¸åæ°ç©çå¤æ¨¡å¼å­¸ç¿æ¡æ¶ï¼è©²æ¡æ¶æ´åäºè¨åºåå½±åæ¸æï¼ä»¥æé«è¨ºæ·æºç¢ºæ§åæ¨¡åå¯è§£éæ§ãè©²æ¨¡åå©ç¨ä¸åé è¨ç·´çç¶²è·¯ï¼VGG19ãInceptionV3 å ResNet50ï¼å¾ X å°ç·å½±åä¸­æåæ·±åº¦ç¹å¾µãéäºç¹å¾µä½¿ç¨ PCA è½æä»¥éä½ç¶­åº¦ä¸¦å°æ³¨æ¼æç¸éççµæé¨åãåºæ¼èé¡çé¸æéç¨è­å¥åºæå·ä»£è¡¨æ§ççµæé¨åï¼ç¶å¾å°éäºçµæé¨åèé èççè¨åºæ¸æçµåï¼ä¸¦ééå¨é£æ¥ç¶²è·¯ (FCN) é²è¡æçµåé¡ãç¹å¾µéè¦æ§åçªåºäºééµè®æ¸ï¼è¡¨æçå²ãBMI åèº«é«æ¯ä¸»è¦è²¢ç»å ç´ ï¼å¼·èª¿äºæ£èç¹å®æ¸æçéè¦æ§ãéç¶å½±åç¹å¾µå¾æå¹å¼ï¼ä½å®åçéè¦æ§è¼ä½ï¼éè¡¨æè¨åºæ¸æå°æ¼æºç¢ºé æ¸¬è³ééè¦ãæ­¤æ¡æ¶ä¿è¿äºæºç¢ºä¸å¯è§£éçé æ¸¬ï¼æé«äºéæåº¦ï¼ä¸¦å»ºç«äºå° AI é©åè¨ºæ·å¨è¨åºæ´åä¸­çä¿¡ä»»ã

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

æè¦ï¼æ¬ç¯è©è«æ¢è¨äºæ·±åº¦å­¸ç¿æ¹æ³å¨éä¾µå¥å¼èªç¥åè½éç¤æª¢æ¸¬ä¸çææ°é²å±ãæåæª¢è¦äºåç¨®éä¾µå¥å¼çèªç¥è¡°éææ¨ï¼åæ¬èªè¨åèªè¨ãé¢é¨åéåæ©è½ãæ¬ææ¦è¿°äºèæ­¤é åç¸éçè³æéãç¹å¾µæåæè¡åæ·±åº¦å­¸ç¿æ¶æ§ãæååæäºä¸åæ¹æ³å¨ä¸åæ¹å¼ä¸çè¡¨ç¾ï¼ä¸¦è§å¯å°åºæ¼èªè¨åèªè¨çæ¹æ³éå¸¸è½éå°æé«çæª¢æ¸¬è¡¨ç¾ãçµåè²å­¸åèªè¨ç¹å¾µçç ç©¶å¾å¾åªæ¼ä½¿ç¨å®ä¸æ¹å¼çç ç©¶ãé¢é¨åææ¹æ³é¡¯ç¤ºåºè¦è¦ºæ¹å¼çæ½åï¼ä½ç ç©¶è¼å°ãå¤§å¤æ¸è«æå°æ³¨æ¼äºååé¡ï¼åæèæªåæï¼ï¼è¼å°æ¢è¨å¤é¡æåæ­¸ä»»åãé·ç§»å­¸ç¿åé è¨ç·´èªè¨æ¨¡åå·²æçºæµè¡ä¸ææçæè¡ï¼ç¹å¥æ¯å°æ¼èªè¨åæãåç®¡åå¾äºéå¤§é²å±ï¼ä½ä»å­å¨ä¸äºææ°ï¼åæ¬è³ææ¨æºååå¯åæ§ãæ¨¡åå¯è§£éæ§ãç¸±ååæéå¶åè¨åºé©ææ§ãæå¾ï¼æåæåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦èª¿æ¥èèªè¨ç¡éçèªé³åææ¹æ³ãéç¼å¤æ¨¡å¼è¨ºæ·ç³»çµ±ï¼ä»¥åè§£æ±ºäººå·¥æºæ§è¼å©é«çä¿å¥ä¸­çå«çèéãééç¶åç®åçè¶¨å¢åæ¾åºééµéç¤ï¼æ¬ç¯è©è«æ¨å¨å¼å°æ·±åº¦å­¸ç¿çºåºç¤çèªç¥åè½éç¤æª¢æ¸¬ç³»çµ±çé²ä¸æ­¥ç¼å±ï¼ä»¥æ¹åæ©æè¨ºæ·ï¼ä¸¦æçµæ¹åæ£èçæ²»ççµæã

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

æè¦ï¼å¯è§£éäººå·¥æºæ§ï¼AIï¼å°æ³¨æ¼åå©äººé¡äºè§£ AI ç³»çµ±éä½æå¶æ±ºç­ï¼æ¸åå¹´ä¾ä¸ç´æ¯ AI çåºç³ãæè¿çå¯è§£éæ§ç ç©¶å°æ³¨æ¼è§£é AI æ¨¡åææ¨¡åå¯è§£éæ§çéä½ãä¹æå¹¾ä»½ç«å ´è²æåè©è«è«æè©³ç´°èªªæäºæçµä½¿ç¨èå°ä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§çéæ±ï¼ä½å¯¦ä½è¼å°ãå æ­¤ï¼æ¬è«ææ¨å¨å½è£æ¨¡ååä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§ä¹éçä¸äºå·®è·ãæåå»ºç«ä¸åè§£éæ¬é«ï¼EOï¼ä»¥ééå¶æ¯æ´åä»¶ä¾è¡¨ç¤ºå¾æç»ä¸­è¡ççè§£éé¡åãæåå¯¦ä½ä¸åç¥è­å¢å¼·çåç­ï¼QAï¼ç®¡ç·ï¼ä»¥å¨è¨åºç°å¢ä¸­æ¯æ´æå¢è§£éãæå¾ï¼æåæ­£å¨å¯¦ä½ä¸åç³»çµ±ï¼ä»¥çµåä¾èªä¸å AI æ¹æ³åè³ææ¨¡å¼çè§£éãå¨ EO ä¸­ï¼æåå¯ä»¥è¡¨ç¤º 15 ç¨®ä¸åçè§£éé¡åï¼ä¸¦ä¸æåå·²å¨å­åç¯ä¾ä½¿ç¨æ¡ä¾ä¸­æ¸¬è©¦éäºè¡¨ç¤ºãæåç¼ç¾ï¼ç¥è­å¢å¼·æ¹åäºåºç¤å¤§åèªè¨æ¨¡åå¨æå¢å QA ä¸­çæè½ï¼ä¸¦ä¸æè½å ç¾çç¾¤çµèç°ãå¨ç¸åçç°å¢ä¸­ï¼è¨åºé«çä¹è¡¨ç¤ºä»åå¸æå°å¯æä½æ§è¦çºè§£éä¸­çä¸»è¦ç¦é»ä¹ä¸ãå¨æåçè§£éçµåæ¹æ³ä¸­ï¼æåè¨ç«ä½¿ç¨ç¸ä¼¼æ§ææ¨ä¾ç¢ºå®æ¢æ§çåµæ¸¬ç°å¢ä¸­è§£éçç¸ä¼¼æ§ãç¸½é«èè¨ï¼ééæ¬è«æï¼æåè¨­è¨äºå¯ä»¥å¨ä¸åä½¿ç¨æ¡ä¾ä¸­æ¯æ´ç¥è­åç¨è§£éçæ¹æ³ï¼èéå°ç¶ä» AI æä»£ä¸­å¯ä»¥ç¢çéäºè§£éçæ¯æ´åä»¶åå¯ä»¥å¢å¼·éäºè§£éçé åç¥è­ä¾æºçæ¹æ³ã

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

æè¦ï¼<paragraph>ç®çï¼èª¿æ¥è¨åºé«çå°ç®åèªååå¿é»åè§£è®åæ°çäººå·¥æºæ§æè¡çæåº¦ï¼ä»¥åä»åå°é»è¦è¼å©è§£è®ççæ³ãææåæ¹æ³ï¼æåå°è±åçè¨åºé«çé²è¡äºä¸ç³»åè¨ªè«ãæåçç ç©¶ï¼(i) æ¢è¨äººå·¥æºæ§çæ½åï¼ç¹å¥æ¯æªä¾çãé¡äººé¡ãéç®æ¹æ³ï¼ä»¥ä¿é²å¿é»åè§£è®ä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼ä»¥å (ii) å¾µæ±ä»åå°äººå·¥æºæ§æ¼ç®æ³çå¯è§£éæ§åå¯ä¿¡åº¦ççæ³ãçµæï¼æåå° 23 ä½è¨åºé«ççè¨ªè«è¨éé²è¡äºæ­¸ç´ä¸»é¡åæï¼ä¸¦æ¾åºä»¥ä¸ä¸»é¡ï¼(i) å°ç®åç³»çµ±ç¼ºä¹ä¿¡ä»»ï¼(ii) å°æªä¾äººå·¥æºæ§æç¨åå°éäºæç¨çè¦æ±ææ­£é¢æåº¦ï¼(iii) æ¼ç®æ³çæºç¢ºæ§åå¯è§£éæ§ä¹éçéä¿ï¼ä»¥å (iv) å°æè²ãå¯è½çæè½éåï¼ä»¥åäººå·¥æºæ§å°è¨åºè½åçå½±é¿ççæ³ãè¨è«ï¼è¨åºé«çä¸ä¿¡ä»»ç®åçé»è¦åæ¹æ³ï¼ä½æ­¡è¿æªä¾çãäººå·¥æºæ§ãæè¡ãå¨è¨åºé«çç¸ä¿¡æªä¾ç AI è§£è®æºç¢ºçææ³ä¸ï¼ä»åä¸å¤ªæå¿å®æ¯å¦å¯è§£éãä»åä¹æ¯è¼åæ­¡è½ä»¥è¦è¦ºæ¹å¼åç¾æ¼ç®æ³çµæçå¿é»åè§£è®ãéç¶è¨åºé«çä¸å®³æå¤±æ¥­ï¼ä½ä»åæå¿æè½éåï¼ä»¥åéè¦æè²å¡å·¥è² è²¬ä»»å°ä½¿ç¨äººå·¥æºæ§ãçµè«ï¼è¨åºé«çå°äººå·¥æºæ§å¨è¨åºæ±ºç­å¶å®ä¸­çæªä¾æç¨ææ­£é¢æåº¦ãæºç¢ºæ§æ¯æ¡ç¨äººå·¥æºæ§çä¸åééµå ç´ ï¼èè¦è¦ºåæ¯ç®åçé»è¦åæ¹æ³æ´åéçãéè¢«è¦çºä¸ç¨®æ½å¨çå¹è¨åæåæè½çæ¹æ³ï¼èèªååå¯è½å¸¶ä¾çæè½éåå½¢æå°æ¯ã</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah HaggenmÃ¼ller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria CompÃ©rat, Andreas Gocht, Monika HÃ¤mmerle, Niels J. Rupp, Jula Westhoff, Irene KrÃ¼cken, Maximillian Seidl, Christian M. SchÃ¼rch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian HÃ¶rner, Kirsten D. Mertz, Constanze DÃ¶ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

æè¦ï¼ååèºçæ¯å¨çç·æ§æå¸¸è¦çççï¼å¶æ¡æ§ç¨åº¦ä¸»è¦æ ¹æ Gleason è©åç³»çµ±ä½¿ç¨çµç¹ççå­¸æ¸æé²è¡è©ä¼°ãéç¶äººå·¥æºæ§ (AI) å¨æºç¢ºé æ¸¬ Gleason è©åæ¹é¢å·²å±ç¾æ½åï¼ä½éäºé æ¸¬éå¸¸ç¼ºä¹å§å¨çå¯è§£éæ§ï¼å¯è½æå°è´å°äººæ©äºåçä¸ä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äºä¸åç± 54 ä½ççå­¸å®¶çµæçåéåéè¨»è§£ç 1,015 åçµç¹å¾®é£åæ ¸å¿å½±åçæ°ç©è³æéãéäºè¨»è§£æä¾äºè©³ç´°çå±é¨æ¨¡å¼æè¿°ï¼ç¨æ¼ç¬¦ååéæºåç Gleason åç´ãå©ç¨éåè³æéï¼æåéç¼äºä¸ååºæ¼ U-Net æ¶æ§çå§å¨å¯è§£é AI ç³»çµ±ï¼è©²ç³»çµ±æä¾äºå©ç¨ççå­¸å®¶è¡èªé²è¡é æ¸¬ãéç¨®æ¹æ³è¦é¿äºäºå¾å¯è§£éæ§æ¹æ³ï¼åæç¶­ææè¶è¶äºç´æ¥è¨ç·´ç¨æ¼ Gleason æ¨¡å¼åå²çæ¹æ³çæè½ï¼Dice åæ¸ï¼0.713 Â± 0.003ï¼è¨ç·´æ¼è§£éï¼ç¸å°æ¼ 0.691 Â± 0.010ï¼è¨ç·´æ¼ Gleason æ¨¡å¼ï¼ãééå¨è¨ç·´æéæ¡ç¨è»æ¨ç±¤ï¼æåææäºè³æä¸­çå§å¨ä¸ç¢ºå®æ§ï¼å³ä½¿å¨è§å¯èéè®ç°æ§é«çææ³ä¸ï¼ä¹è½å¨ Gleason æ¨¡å¼åå²ä¸­ç¢çå¼·å¤§ççµæãéééåºéåè³æéï¼æåæ¨å¨é¼åµé²ä¸æ­¥ç ç©¶ä¸»è§æ§é«çé«çä»»åä¸­çåå²ï¼ä¸¦å¢é²å°ççå­¸å®¶æ¨çéç¨ççè§£ã

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

æè¦ï¼é«ééæè¡çé²æ­¥å°è´å¾å³çµ±çåè¨­é©åæ¹æ³è½è®çºè³æé©åçæ¹æ³ãå¤çµå­¸æ¯ææ´ååæä¾èªå¤åãçµå­¸ãçè³æï¼ä¾å¦åºå çµå­¸ãèç½è³ªçµå­¸ãè½éçµå­¸ãä»£è¬çµå­¸åå¾®çç©çµå­¸ãæ­¤æ¹æ³ééæ·åçç©è³è¨çä¸åå±¤é¢ï¼è½å¨é¢äºè§£çç©ç³»çµ±ãæ·±åº¦å­¸ç¿æ¹æ³æä¾æå¸¸è¢«ç¨æ¼æ´åå¤çµå­¸è³æï¼æä¾åå­äº¤äºä½ç¨çæ´å¯åï¼ä¸¦å å¼·å°è¤éç¾ççç ç©¶ãç¶èï¼éäºæ¨¡åå·æè¨±å¤ç¸äºé£æ¥çå±¤ç´åéç·æ§éä¿ï¼éå¸¸æåé»çå­ä¸æ¨£éä½ï¼ç¼ºä¹æ±ºç­éç¨çéæåº¦ãçºäºåææ­¤ææ°ï¼å¯è§£éäººå·¥æºæ§ (xAI) æ¹æ³å°æ¼å»ºç«éææ¨¡åè³ééè¦ï¼è®è¨åºé«çå¯ä»¥æ´ææå°è§£éåèçè¤éè³æãæ­¤è©è«æ¢è¨ xAI å¦ä½è½æ¹åå¤çµå­¸ç ç©¶ä¸­æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§ï¼å¼·èª¿å¶æä¾è¨åºé«çæç¢ºè¦è§£çæ½åï¼é²èä¿é²æ­¤é¡æ¨¡åå¨è¨åºç°å¢ä¸­çæææç¨ã

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian GeiÃler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°æ¼å»ºæ§åé²çæ©å¨å­¸ç¿é©åæç¨ç¨å¼è³ééè¦ï¼ç¹å¥æ¯å¨é«çè¨ºæ·æèªåé§é§ç­ééµé åãæ³å¾ãåæ¥­åå«çè¦æ±ä¿ä½¿ä½¿ç¨ææç XAIï¼ä½æ¸éæ¥çå¢å çä¸åæ¹æ³ä½¿å¾æé¸æ­£ç¢ºçæ¹æ³å·æææ°æ§ãæ­¤å¤ï¼ç±æ¼è§£éé«åº¦ä¾è³´æ¼èæ¯ï¼å¨æ²æä½¿ç¨èçææ³ä¸è¡¡é XAI æ¹æ³çæææ§åªè½æ­ç¤ºæéçè³è¨ï¼æé¤äººé¡å ç´ ï¼ä¾å¦çè§£å®çè½åãæåå»ºè­°ééä½¿ç¨èæåå·è¡ä»£çä»»åçè½åä¾è©ä¼° XAI æ¹æ³ï¼è¨­è¨ä½¿å¾è¯å¥½çå·è¡è¡¨ç¾æ¯è§£éæä¾æç¨è³è¨çææ¨ãæå¥è©±èªªï¼æåæ¢è¨ XAI å°äººé¡æ±ºç­å¶å®çå¹«å©ãæ­¤å¤ï¼å°æåé²çæ¹æ³é²è¡ä½¿ç¨èç ç©¶ï¼é¡¯ç¤ºåºå®åå¨ç¢çä¿¡ä»»åæ·ççè½åä»¥åæ­£ç¢ºå¤æ· AI æ±ºç­æ¯å¦æ­£ç¢ºçè½åæ¹é¢å­å¨å·®ç°ãæ ¹æçµæï¼æåå¼·çå»ºè­°ä½¿ç¨åæ´åéç¨®æ¹æ³ï¼ä»¥é²è¡æ´å¤ä»¥ç®æ¨çºåºç¤çäººçºä¸­å¿ä½¿ç¨èç ç©¶ï¼ä»¥çµç«¯å°çµç«¯çæ¹å¼è¡¡é XAI æè½ã

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

æè¦ï¼ç¢ç¨ä¸­é¢¨éªçæ©æåµæ¸¬æå©æ¼é²è¡å¹²é æªæ½ï¼ä»¥é é²ææ¸è¼ä¸å©ççç¢çµæï¼ä¾å¦è¦æ§éº»çºãç®åï¼æ²ææºç¢ºçèªååç³»çµ±å¯ä»¥é æ¸¬æ­¤é¡äºä»¶ï¼ä»¥åå©è¨åºæ±ºç­ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºãç¨æ¼å»ºæ¨¡åè§£éæ°çåå¥åº·çäººå·¥æºæ§ã(AIMEN)ï¼éæ¯ä¸åæ·±åº¦å­¸ç¿æ¶æ§ï¼å®ä¸åå¯ä»¥æ ¹æå­ç¢å©¦ãèåãç¢ç§åç¢ç¨é¢¨éªå ç´ é æ¸¬ä¸å©ççç¢çµæï¼éè½æä¾æ¨¡åååºé æ¸¬èå¾çåå ãå¾èå¯ä»¥æä¾è¦è§£ï¼èªªææ¨¡åè¼¸å¥è®æ¸ä¸­çåªäºä¿®æ¹å¯è½ææ¹è®é æ¸¬çµæãæåééä½¿ç¨é©ææ§åææ½æ¨£ (ADASYN) åæ¢ä»¶è¡¨æ ¼çæå°æç¶²è·¯ (CTGAN) ä¾åæé¡å¤çè¨ç·´è³æï¼ä»¥è§£æ±ºä¸å¹³è¡¡åå°åè³æéçææ°ãAIMEN ä½¿ç¨å¨é£æ¥ç¥ç¶ç¶²è·¯çéåä½çºå¶åé¡çéª¨å¹¹ï¼ä¸¦éé ADASYN æ CTGAN æ¯æ´è³ææ´åãç± CTGAN æ¯æ´ç AIMEN å¨åé¡æ¹é¢åªæ¼ç± ADASYN æ¯æ´ç AIMENãAIMEN å¯ä»¥é æ¸¬ä¸å©ççç¢çµæçé«é¢¨éªï¼å¹³å F1 åæ¸çº 0.784ãå®éæä¾åäºå¯¦è§£éï¼å¯ééå¹³åè®æ´ 2 è³ 3 åå±¬æ§ä¾éæãå¯ç¨è³æºï¼https://github.com/ab9mamun/AIMENã

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

æè¦ï¼éºå³æ§è¦ç¶²èç¾ç (IRD) æ¯ä¸çµå¤æ¨£åçéºå³ç¾çï¼
æå°è´è¦åéæ¼¸åªå¤±ï¼æ¯å·¥ä½å¹´é½¡æäººå¤±æçä¸»è¦åå ãIRD çè¤éæ§åç°è³ªæ§å°è¨ºæ·ãé å¾åç®¡çæåºäºéå¤§ææ°ãæè¿äººå·¥æºè½ (AI) çé²æ­¥çºéäºææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ã
ç¶èï¼AI æè¡çå¿«éç¼å±åå¶å¤ç¨®æç¨å°è´äºè©²é åçç¥è­åæ£ãæ¬ç¶è¿°æ´åäºç¾æç ç©¶ï¼æ¾åºå·®è·ï¼ä¸¦æ¦è¿°äº AI å¨è¨ºæ·åç®¡ç IRD ä¸­çæ½åãå®æ¨å¨ééæ¢ç´¢æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿ç­ AI æè¡ï¼ç¹å¥æ¯å¨ç¾çæª¢æ¸¬ãé²ç¨é æ¸¬ååæ§åæ²»çè¨åä¸­ï¼çºæ¨é²è¨åºæç¨æ§å»ºéå¾ãç¹å¥éæ³¨éäºé åä¸­å·ç©ç¥ç¶ç¶²è·¯çæææ§ãæ­¤å¤ï¼è¨è«äºå¯è§£é AI çæ´åï¼å¼·èª¿äºå¶å¨è¨åºç°å¢ä¸­æé«éæåº¦åå°åºæ¼ AI çç³»çµ±çä¿¡ä»»çéè¦æ§ãè©²ç¶è¿°è§£æ±ºäºå½å AI å¨ IRD ä¸­ä½ç¨çéé»ç ç©¶ä¸­ç¾æå·®è·çå¿è¦æ§ï¼æä¾äºå°ç¶å AI æè¡ççµæ§ååæï¼ä¸¦æ¦è¿°äºæªä¾çç ç©¶æ¹åãæå¾æ¦è¿°äºå¨ IRD ä¸­é¨ç½² AI çææ°åæ©éï¼å¼·èª¿äºè·¨å­¸ç§åä½åæçºéç¼å¼·å¤§ãå¯è§£éç AI æ¨¡åä»¥æ¨é²è¨åºæç¨çå¿è¦æ§ã

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çä¸é ééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æå°æ£èççµæç¢çéå¤§å½±é¿ãå³çµ±æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨æ­¤é ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éæ¯è¨åºç°å¢ä¸­çééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼å¯è§£éçè¨ºæ·é æ¸¬æ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼è©²æ¨¡åéééè¼¯è¦ååå¯å­¸ç¿çé¾å¼æ´åé åç¹å®çç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåè¶æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­ï¼éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸æå®³é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼ç²¾æºé«ççé²æ­¥ï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

æè¦ï¼äººå·¥æºæ§ (AI) ç³»çµ±å·²å¤§å¹æ¹åç®èç§é«å¸«å°é»è²ç´ ç¤çè¨ºæ·æºç¢ºåº¦ï¼èå¯è§£é AI (XAI) ç³»çµ±é²ä¸æ­¥æåè¨åºé«å¸«å° AI é©åæ±ºç­çä¿¡å¿èä¿¡è³´ãåç®¡æéäºé²å±ï¼å°æ¼ç®èç§é«å¸«å¦ä½ä½¿ç¨ AI å XAI å·¥å·ï¼ä»æå®¢è§è©ä¼°çè¿«åéæ±ãå¨éé ç ç©¶ä¸­ï¼76 ä½ç®èç§é«å¸«åèäºä¸é è®èç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±è¨ºæ· 16 å¼µé»è²ç´ ç¤åç£çç®èé¡å½±åï¼è©²ç³»çµ±æä¾è©³ç´°çé åç¹å®èªªæãæ¡ç¨ç¼çè¿½è¹¤æè¡ä¾è©ä¼°ä»åçäºåãå°è¨ºæ·è¡¨ç¾èç¼ºä¹èªªæåè½çæ¨æº AI ç³»çµ±é²è¡æ¯è¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼XAI ç³»çµ±ç¸è¼æ¼æ¨æº AIï¼å°å¹³è¡¡è¨ºæ·æºç¢ºåº¦æåäº 2.8 åç¾åé»ãæ­¤å¤ï¼è AI/XAI ç³»çµ±çè¨ºæ·åæ­§åè¤éççç¶èèªç¥è² æåé«æéï¼éç±å¢å çç¼çæ³¨è¦æ¬¡æ¸æè­å¯¦ãéäºè¦è§£å°è¨åºå¯¦åãè¦è¦ºä»»å AI å·¥å·çè¨­è¨åé«å­¸è¨ºæ·ä¸­ XAI çå»£æ³ç¼å±å·æéå¤§æç¾©ã

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·åä»å¥å·²è¢«è­å¯¦è½é¡¯èæ¹åèªéçæ£èççæ´»åè³ªãç¶èï¼ASD çè¨ºæ·æ¹æ³ä¾è³´æ¼åºæ¼è¨åºè¡¨ç¾çè©ä¼°ï¼å®¹æç¢çåè¦ï¼ä¸å¯è½é£ä»¥ååºæ©æè¨ºæ·ãæå¿è¦æ¾åº ASD çå®¢è§çç©æ¨è¨ï¼ä»¥å¹«å©æé«è¨ºæ·æºç¢ºæ§ãæ·±åº¦å­¸ç¿ (DL) å¨å¾é«å­¸å½±åè³æè¨ºæ·ç¾çåççæ¹é¢åå¾ååºçè¡¨ç¾ãå·²ç¶éå°å»ºç«ä½¿ç¨éæåè½æ§ç£æ¯é å½± (fMRI) è³æå° ASD é²è¡åé¡çæ¨¡åé²è¡å»£æ³çç ç©¶ãç¶èï¼ç¾æçæ¨¡åç¼ºä¹å¯è§£éæ§ãæ¬ç ç©¶æ¨å¨ééå»ºç«ä¸åä¸åè½æºç¢ºåé¡ ASDï¼éè½æä¾å¯è§£éè¦è§£èªªæå¶éä½åçç DL æ¨¡åï¼ä¾æ¹å ASD è¨ºæ·çæºç¢ºæ§åå¯è§£éæ§ãæä½¿ç¨çè³æéæ¯èªéçå¤§è¦å½±åè³æäº¤æ (ABIDE) çé èççæ¬ï¼åå« 884 åæ¨£æ¬ãæåçç ç©¶çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æºç¢ºåé¡ ASDï¼ä¸¦å¼·èª¿ ASD èå¸åå°ç§çµä¹éå­å¨å·®ç°çééµè¦åï¼å°æ¼ ASD çæ©æè¨ºæ·åç¥ç¶åºç¤ççè§£å·ææ½å¨çæç¾©ãéäºç ç©¶çµæå·²ç±ä½¿ç¨ä¸åè³æéåæ¹å¼çæç»ç ç©¶é©è­ï¼è­å¯¦è©²æ¨¡åå¯¦éä¸å­¸ç¿äº ASD çç¹å¾µï¼èä¸ååæ¯è³æéãæ¬ç ç©¶ééæä¾ä¸åå¼·å¥ä¸å¯è§£éçæ¨¡åï¼æ¨åäºé«å­¸å½±åä¸­å¯è§£é AI çé åï¼å¾èçºæªä¾æä¾å®¢è§ä¸å¯é ç ASD è¨ºæ·ååºè²¢ç»ã

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, ClÃ©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

æè¦ï¼å°¿è·¯é¡æª¢æ¥ä¸­èçµç³é¡åçé«å§è­å¥å°æ¯æ³å°¿ç§çä¸é éå¤§é²å±ï¼å çºå®å¯ä»¥æ¸å°ç¹ç£çèçµç³ååºéç¨çæéï¼åæéä½ææé¢¨éªãæ­¤å¤ï¼éç¨®èªååç¨åºå°ä½¿ç«å³éç«æå¾©ç¼æ²»çæçºå¯è½ãå¦ä»ï¼åªæå°æ¸ç¶é©è±å¯çæ³å°¿ç§é«çè½å¤ å¨å§è¦é¡æª¢æ¥æéå±å¹ä¸é¡¯ç¤ºçè¦é »ååä¸­è­å¥èçµç³é¡åãå æ­¤ï¼æè¿å·²æåºå¤ç¨®æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ä»¥ä½¿ç¨è¼¸å°¿ç®¡é¡ååèªåè­å¥èçµç³é¡åãç¶èï¼éäº DL æ¨¡åæ¬è³ªä¸æ¯é»çå­ï¼ééå¶äºå®åå¨è¨åºç°å¢ä¸­çæç¨æ§ãæ¬ææåºäºä¸ååºæ¼æ¡ä¾æ¨çç DL æ¨¡åï¼å®ä½¿ç¨ååé¨å (PP) ä¸¦çæå±é¨åå¨å±æè¿°ç¬¦ãPP çºæ¯ç¨®é¡åï¼å³èçµç³é¡åï¼ç·¨ç¢¼è¦è¦ºç¹å¾µä¿¡æ¯ï¼è²èª¿ãé£½ååº¦ãå¼·åº¦åç´çï¼ï¼é¡ä¼¼æ¼çç©å­¸å®¶ä½¿ç¨çä¿¡æ¯ãç±æ¼å¨æ¨¡åè¨ç·´æéä½¿ç¨çæ°æå¤±å½æ¸ï¼PP å¾å°äºæä½³çæãæ­¤å¤ï¼PP çå±é¨åå¨å±æè¿°ç¬¦åè¨±ä»¥çç©å­¸å®¶åæ³å°¿ç§é«çå¯ä»¥çè§£çæ¹å¼è§£éæ±ºç­ï¼âä»éº¼âä¿¡æ¯ï¼âååä¸­çä»éº¼ä½ç½®âï¼ãææåºç DL æ¨¡åå·²å¨ä¸ååå«å­ç¨®æå»£æ³çèçµç³é¡åååçæ¸æåº«ä¸é²è¡äºæ¸¬è©¦ãç¸½é«å¹³ååé¡æºç¢ºççº 90.37ãå°æ­¤çµæèèçµç³æåé²çå«åå¶ä» DL æ¨¡åççµæé²è¡æ¯è¼æï¼å¯ä»¥çåºï¼å¯è§£éæ§çå¯¶è²´å¢çä¸¦æªä»¥æºç¢ºæ§çºä»£å¹ï¼çè³ç¥æå¢å èæç»ä¸­æå¥½çæ¹æ³ (88.2) ç¸æ¯ãéäºæå¸æä¸å¯è§£éççµæä¹é¼åµæ³å°¿ç§é«çç¸ä¿¡åºæ¼äººå·¥æºè½çè§£æ±ºæ¹æ¡ã

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

æè¦ï¼æ¬ç ç©¶æ¢è¨å©ç¨è¡æ¿ç³å ±è³æï¼çµååé²æ©å¨å­¸ç¿èæ·±åº¦å­¸ç¿æè¡ï¼é æ¸¬æ¢æ§èèç (CKD) é²å±è³æ«æèèç¾ç (ESRD) çå¯è½æ§ãæååæä¸å®¶å¤§åå¥åº·ä¿éªçµç¹æä¾ç 10 å¹´ç¶åè³æéï¼ä½¿ç¨å³çµ±æ©å¨å­¸ç¿æ¹æ³ï¼ä¾å¦é¨æ©æ£®æå XGBoostï¼ä»¥åæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦é·æç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼éç¼å¤åè§å¯è¦çªçé æ¸¬æ¨¡åãæåçç ç©¶çµæé¡¯ç¤ºï¼LSTM æ¨¡åï¼å°¤å¶æ¯ 24 åæè§å¯è¦çªï¼å¨é æ¸¬ ESRD é²å±æ¹é¢è¡¨ç¾åªç°ï¼åªæ¼æç»ä¸­çç¾ææ¨¡åãæåé²ä¸æ­¥æç¨ SHapley å¯å æ§è§£é (SHAP) åæä»¥å¢å¼·å¯è§£éæ§ï¼æ·±å¥äºè§£åå¥ç¹å¾µå°åå¥æ£èå±¤ç´é æ¸¬çå½±é¿ãæ¬ç ç©¶å¼·èª¿äºå©ç¨è¡æ¿ç³å ±è³æé²è¡ CKD ç®¡çåé æ¸¬ ESRD é²å±çå¹å¼ã

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

æè¦ï¼é¨èè¶ä¾è¶è¤éä¸æºç¢ºçé æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§ (AI) è§£æ±ºæ¹æ¡çææ¡å¨è¨±å¤é åä¸­è®å¾ç¡èä¸å¨ãé¨èéäºæ¨¡åè¤éæ§çå¢å ï¼éæåº¦åä½¿ç¨èççè§£åå¾å¾æéä½ãéè¡¨ç¤ºåææºç¢ºçé æ¸¬ä¸¦ä¸è¶³ä»¥è® AI è§£æ±ºæ¹æ¡çæ­£æç¨ãå¨é«çä¿å¥ç³»çµ±çéç¼ä¸­ï¼éå¼å¥äºèåè²¬å¶åå®å¨æ§ç¸éçæ°åé¡ãç­è§£ AI ç³»çµ±å¦ä½ä»¥åçºä½æåºå»ºè­°å¯è½éè¦å°å¶å§é¨éä½åæ¨çéç¨é²è¡è¤éçèªªæãåç®¡è¿å¹´ä¾å°å¯è§£é AI (XAI) çç ç©¶å·²å¤§å¹å¢å ï¼ä¸é«å­¸é åå° XAI æå¾é«çéæ±ï¼ä½å®ç¾©ä»éº¼æ§æä¸åå¥½çè§£éä»æ¯è¨ææ§çï¼èæä¾é©ç¶çè§£éä»ç¶å·æææ°æ§ãçºäºååç¼æ® AI çæ½åï¼å°æ¼å®å¨ééµå AI æç¨ï¼ä¾å¦å¥åº· AIï¼çè§£éï¼æ¢è¨å©ååºæ¬åé¡è³ééè¦ï¼(1) ä»éº¼æ¯å¥åº· AI ä¸­çè§£éï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½çè§£éæåªäºå±¬æ§ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦äºå·²ç¼è¡¨çæç»ï¼ä¸¦ééå©è¼ªå¾·ç¾è²ç ç©¶æ¶éäºå°å®¶æè¦ãç ç©¶ææåæ¬ï¼(1) å¥åº· AI ä¸­ä»éº¼æ§æè§£éçå®ç¾©ï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½è§£éçå±¬æ§æ¸å®ã

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼å·²ç¶å¼é²åç¨®æ¹æ³ä¾è§£éãé»ç®±ãAI æ¨¡åçè¼¸åºãç¶èï¼ç®åä¸¦ä¸æ¸æ¥ä½¿ç¨èæ¯å¦å¯¦éçè§£åä¿¡ä»»éäºè§£éãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼è©ä¼°ççé¢¨éªçåæ­¸å·¥å·çè§£éï¼ä¸¦æ¢è¨è§£éçå§å®¹åæ ¼å¼å°ä»¥ä½¿ç¨èçºä¸­å¿ççè§£åä¿¡ä»»ææ¨çå½±é¿ãéæ¼å§å®¹ï¼æåå¯¦é©äºå©ç¨®è§£éæ¹æ³ï¼æµè¡ç SHAPï¼åºæ¼åå¼è«æ¦å¿µï¼å æ­¤å°æ¼æ¥å¸¸ä½¿ç¨èä¾èªªå¯è½å¾è¤éï¼ä»¥ååºæ¼ç¹å¾µé®è½ç occlusion-1ï¼å¯è½æ´ææ¼çè§£ãéæ¼æ ¼å¼ï¼æåå° SHAP è§£éåç¾çºåè¡¨ (SC)ï¼éæ¯æ£ä¾ï¼èå° occlusion-1 è§£éåç¾çºåè¡¨ (OC) ä»¥åæå­ (OT)ï¼å¶è¼çºç°¡å®çæ§è³ªä¹é©ç¨æ¼æ­¤ãéäºå¯¦é©ç­åæ¼ä½¿ç¨èç ç©¶ï¼è©¢ååèèï¼å·æå©ç¨®ä¸åç¨åº¦çå°æ¥­ç¥è­ï¼ä¸è¬æ°ç¾åå·åä¸äºé«å­¸è¨ç·´çäººï¼ï¼ä»åå°åæ­¸å·¥å·è¼¸åºè§£éçä¸»è§åå®¢è§çè§£åä¿¡ä»»ãå¨å©é ç ç©¶ä¸­ï¼æåç¼ç¾ï¼å¨åºæ¼å§å®¹é²è¡æ¯è¼æï¼ä¸è¬ä¾èªªï¼occlusion-1 åªæ¼ SHAP è§£éï¼å¨ä¸»è§çè§£åä¿¡ä»»æ¹é¢ææé¡¯çåå¥½ãç¶èï¼å¨åæ§å¶æ ¼å¼çææ³ä¸ç´æ¥æ¯è¼è§£éï¼å¨å¤§å¤æ¸ææ³ä¸åªé¡¯ç¤º OT åªæ¼ SC è§£éçè­æï¼éè¡¨æ occlusion-1 åªæ¼ SHAP è§£éçä¸»å°å°ä½å¯è½æ¯ç±åå¥½æå­èéåè¡¨ä½çºè§£éæé©åçãæå¾ï¼æåæ²æç¼ç¾è§£éé¡åå¨å®¢è§çè§£æ¹é¢çå·®ç°è­æãå æ­¤ï¼ç¸½é«èè¨ï¼å°è§£éçå§å®¹åæ ¼å¼çé¸æéè¦ä»ç´°æ³¨æï¼å çºå¨æäºææ³ä¸ï¼æ ¼å¼èéå§å®¹ï¼å¯è½å¨æ¹åä½¿ç¨èé«é©æ¹é¢ç¼æ®ééµä½ç¨ã</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro LiÃ², Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´æä¾äºåææªæçèªç¶èªè¨çè§£åçæè½åãç¶èï¼ç¾æéæ¼çç©é«å­¸ä¸­ LLM çèª¿æ¥éå¸¸å°æ³¨æ¼ç¹å®æç¨ææ¨¡åæ¶æ§ï¼ç¼ºä¹æ´ååç¨®çç©é«å­¸é åææ°é²å±çå¨é¢åæãæ¬ç¶è¿°åºæ¼å°ä¾èª PubMedãWeb of Science å arXiv ç­æ¸æåº«ç 484 ç¯åºçç©çåæï¼æ·±å¥æ¢è¨äºçç©é«å­¸ä¸­ LLM çç¶åç¾æ³ãæç¨ãææ°ååæ¯ï¼å¶ç¹é»æ¯éæ³¨éäºæ¨¡åå¨ç¾å¯¦ä¸ççç©é«å­¸èæ¯ä¸­çå¯¦éæç¨ãé¦åï¼æåæ¢è¨äº LLM å¨å»£æ³ççç©é«å­¸ä»»åä¸­çé¶æ¬¡å­¸ç¿è½åï¼åæ¬è¨ºæ·è¼å©ãè¥ç©ç¼ç¾ååæ§åé«çç­ï¼ä¸¦å¾ 137 é ééµç ç©¶ä¸­æ±²åè¦è§£ãç¶å¾ï¼æåè¨è«äº LLM çé©æç­ç¥ï¼åæ¬å®æ¨¡æåå¤æ¨¡æ LLM çå¾®èª¿æ¹æ³ï¼ä»¥å¢å¼·å®åå¨é¶æ¬¡å­¸ç¿ç¡æ³å¯¦ç¾çå°æ¥­çç©é«å­¸èæ¯ä¸­çæ§è½ï¼ä¾å¦é«çåé¡è§£ç­åçç©é«å­¸æç»çææèçãæå¾ï¼æåè¨è«äº LLM å¨çç©é«å­¸é åé¢è¨çææ°ï¼åæ¬æ¸æé±ç§åé¡ãæ¨¡åå¯è§£éæ§æéãæ¸æéè³ªéåé¡ä»¥åç±æ¼çç©é«å­¸æ¸æçæææ§ãå°é«åº¦å¯é æ¨¡åè¼¸åºçéæ±ä»¥åå¨é«çä¿å¥ä¸­é¨ç½² AI çå«çå½±é¿èç¢ççå«çåé¡ãçºäºæå°éäºææ°ï¼æåéç¢ºå®äºçç©é«å­¸ä¸­ LLM æªä¾çç ç©¶æ¹åï¼åæ¬ç¨æ¼ä¿è­·æ¸æé±ç§çè¯åå­¸ç¿æ¹æ³ä»¥åæ´åå¯è§£é AI æ¹æ³ä»¥å¢å¼· LLM çéæåº¦ã

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨é«çåä¿å¥æç¨ä¸­æå¥äºå¤§éçæè³åéç¼ï¼é²èå°è´é«çæè¡ä¸­çåé²æ§å¶ç³»çµ±ãç¶èï¼AI ç³»çµ±çä¸éææ§å¼ç¼äºå°æ­¤é¡æææç¨ä¸­æéåºæ¬ç¹æ§çææï¼ä¾å¦éæåº¦åå¯ä¿¡åº¦ãæåçç ç©¶ééèª¿æ¥ä¸åç¨åºä¾è§£æ±ºéäºåé¡ï¼ç¨æ¼é¸ææååçå¯è§£é AIï¼XAIï¼æ¹æ³ï¼ä»¥ç¬¦åæ­çæ³è¦å¨é«çå¨æçæºæ§åçç©é»å­å­¸ä¸­çèªªæè¦æ±ãæ¡ç¨çæ¹æ³å¾ééå¶æ§å¶æ©å¶ï¼éè¿´è·¯ãéè¿´è·¯ååéè¿´è·¯ç³»çµ±ï¼å°æºæ§åè£ç½®é²è¡åé¡ï¼ä¸¦æ·±å¥æ¢è¨å¶æè¡éå§ãç¶å¾ï¼æååæéäºæ³è¦ä»¥å®ç¾©å¶å°åç¨®è£ç½®åç¸éç®æ¨çå¯è§£éæ§è¦æ±ãåæï¼æåééå¶èªªæç®æ¨å° XAI æ¹æ³é²è¡åé¡ãéåè¨±å°æ³å¾å¯è§£éæ§è¦æ±è XAI èªªæç®æ¨ç¸å¹éï¼ä¸¦ç¢ºå®é©ç¶ç XAI æ¼ç®æ³ä¾éæå®åãæåçç ç©¶çµææä¾äºå°åªäº XAI æ¼ç®æ³æ´ç¬¦åæ­çæ³è¦ä»¥é©ç¨æ¼ä¸åé¡åçé«çå¨æçç´°ç·»çè§£ãæåééä¸åç¥ç¶æ¤å¥ç©çå¯¦éæ¡ä¾ç ç©¶ä¾è­æéä¸é»ï¼å¾æ¢æ§ç¾çç®¡çå°åé²çç¾©è¢ãéé ç ç©¶å¡«è£äºå°çç©é»å­å­¸ä¸­ç XAI æç¨èæ­çæ³è¦çå´æ ¼è¦å®ç¸ç¬¦çéè¦ç©ºç½ãå®çºéç¼äººå¡åç ç©¶äººå¡æä¾äºä¸åå¯¦ç¨çæ¶æ§ï¼ç¢ºä¿å¶ AI åµæ°è½ä¿é²é«çæè¡ä¸¦éµå®æ³å¾åéå¾·æ¨æºã

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

æè¦ï¼æåæ¢ç´¢æ·±åº¦çææ¨¡åï¼å¨é«çè¯é¦å­¸ç¿è¨­ç½®ä¸­çæåºæ¼æ¡ä¾çèªªæãééåºæ¼æ¡ä¾çå¯è§£éæ§ä¾è§£é AI æ¨¡åæ±ºç­ï¼å°æ¼å¢å ä¿¡ä»»ä¸¦åè¨± AI å¨è¨åºå¯¦åä¸­å»£æ³æ¡ç¨è³ééè¦ãç¶èï¼é«ç AI è¨ç·´ç¯ä¾æ­£è½åè¯é¦å­¸ç¿è¨­ç½®ï¼ä»¥ç¬¦åè³æä¿è­·æ³è¦ãå¨è¯é¦æå¢ä¸­ï¼éå»çè³æå°ç®åçä½¿ç¨èèè¨æ¯ç¡æ³åå¾çãå æ­¤ï¼æåä½¿ç¨æ·±åº¦çææ¨¡åä¾ç¢çä¿è­·é±ç§åè§£éæ±ºç­çåæç¯ä¾ãæåçæ¦å¿µé©è­èéæ¼è¸èç©æ¶²è¨ºæ·ï¼ä¸¦ä½¿ç¨å¬éå¯åå¾çè¸é¨ X åè³æã

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. GruÃ¼hagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

æè¦ï¼è»çµç¹åéª¨éª¼è«ç¤ï¼STBTï¼æ¯ç½è¦ãè¨ºæ·å·æææ°æ§ççç¶ï¼å¶è¨åºè¡çºåæ²»çæ¹æ³åä¸ç¸åãéç¯ç³»çµ±æ§åé¡§æä¾äºä½¿ç¨æ¾å°å½±åé²è¡è¨ºæ·åé å¾çäººå·¥æºæ§ (AI) æ¹æ³çæ¦è§ï¼éé»èªªæäºè¨åºè½è­¯çææ°ï¼ä¸¦è©ä¼°ç ç©¶èé«çå½±å AI æ ¸æ¥è¡¨ (CLAIM) å FUTURE-AI å¯ä¿¡è³´ä¸å¯é¨ç½² AI çåéå±è­æºåçä¸è´æ§ï¼ä»¥ä¿é² AI æ¹æ³çè¨åºè½è­¯ãéç¯åé¡§æ¶µèäºå¹¾åæ¸ç®è³æåº«ä¸­çæç»ï¼åæ¬å¨ 2024 å¹´ 7 æ 17 æ¥ä¹åç¼è¡¨çè«æãç´å¥äºä»¥æ¾å°çºåºç¤ç AI è¨ºæ·æé å¾åç¼æ§ STBT çåè¡è©å¯©æåä¸­çåå§ç ç©¶ãæé¤æ¨æºæ¯åç©ãå±é«æå¯¦é©å®¤ç ç©¶ï¼ä»¥åéè±æè«æãæè¦ç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çå©ä½ç¯©é¸è³æ ¼ãåæ ¼çè«æç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çä¸ä½æ ¹ææºåé²è¡è©ä¼°ãæç´¢è­å¥åº 15,015 ç¯æè¦ï¼å¶ä¸­ 325 ç¯æç« è¢«ç´å¥è©ä¼°ãå¤§å¤æ¸ç ç©¶å¨ CLAIM ä¸­è¡¨ç¾ä¸­ç­ï¼å¹³åå¾åçº 53 åä¸­ç 28.9Â±7.5 åï¼ä½å¨ FUTURE-AI ä¸­è¡¨ç¾ä¸ä½³ï¼å¹³åå¾åçº 30 åä¸­ç 5.1Â±2.1 åãSTBT çå½±å AI å·¥å·ä»èæ¼æ¦å¿µé©è­éæ®µï¼è¡¨ææé¡¯èçæ¹é²ç©ºéãAI éç¼äººå¡æªä¾çåªåæéä¸­å¨è¨­è¨ï¼ä¾å¦å®ç¾©æªæ»¿è¶³çè¨åºéæ±ãé æçè¨åºç°å¢ä»¥å AI å¦ä½æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼ãéç¼ï¼ä¾å¦å»ºç«å¨ååçå·¥ä½ãå¯è§£éæ§ï¼ãè©ä¼°ï¼ä¾å¦è©ä¼°åè§£æ±ºåå·®ãè©ä¼° AI èæä½³å¯¦åï¼ãä»¥åæ¸æå¯è¤è£½æ§åå¯ç¨æ§ï¼å¬éæä¾æä»¶åçä»£ç¢¼åæ¸æï¼ãéµå¾ªéäºå»ºè­°å¯ä»¥æ¹å AI æ¹æ³çè¨åºè½è­¯ã

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga StrÃ¼mke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

æè¦ï¼è¦æ§éº»çº (CP) çæ©æåµæ¸¬å°æ¼ææçä»å¥åç£æ¸¬è³ééè¦ãæ¬ææ¸¬è©¦äºå¯è§£é AI (XAI) æ¹æ³çå¯é æ§åé©ç¨æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ééåæå¾å¬°ååä½å½±çè¨éä¸­æåçéª¨éª¼è³æä¾é æ¸¬ CPãå·é«ä¾èªªï¼æåä½¿ç¨ XAI è©ä¼°ææ¨ï¼å³å¿ å¯¦åº¦åç©©å®æ§ï¼ä¾éåè©ä¼°é¡å¥æ¿æ´»æ å° (CAM) åæ¢¯åº¦å æ¬é¡å¥æ¿æ´»æ å° (Grad-CAM) å¨éåç¹å®é«çæç¨ä¸­çå¯é æ§ãæåå©ç¨ä¸åç¨ç¹çå¬°ååä½è³æéï¼ä¸¦æç¨éª¨éª¼è³ææ¾åï¼èä¸ææ­æ²å¬°ååä½çåå§ååãæåç CP é æ¸¬æ¨¡åå©ç¨æ´é«æ¹æ³ï¼å æ­¤æåè©ä¼°äºæ´é«æ´é«ååå¥æ¨¡åç XAI ææ¨è¡¨ç¾ãæåçç ç©¶çµæè¡¨æï¼å©ç¨® XAI æ¹æ³é½è½ææè­å¥å½±é¿ CP é æ¸¬çééµèº«é«é¨ä½ï¼ä¸¦ä¸éäºè§£éå°æ¼å¾®å°çè³ææ¾åå·æé­¯æ£æ§ãGrad-CAM å¨ RISv ææ¨ä¸­é¡¯èåªæ¼ CAMï¼è©²ææ¨è¡¡ééåº¦æ¹é¢çç©©å®æ§ãç¸æ¯ä¹ä¸ï¼CAM å¨ RISb ææ¨ä¸­è¡¨ç¾å¾æ´å¥½ï¼è©²ææ¨èéª¨éª¼ç©©å®æ§æéï¼è RRS ææ¨åè©ä¼°å§é¨è¡¨ç¤ºçé­¯æ£æ§ãæ´é«ä¸­çåå¥æ¨¡åé¡¯ç¤ºåºä¸åççµæï¼CAM å Grad-CAM é½ä¸ä¸è´å°åªæ¼å¦ä¸ç¨®ï¼æ´é«æ¹æ³æä¾äºå¶çµææ¨¡åçµæçè¡¨ç¤ºã

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

æè¦ï¼æè¿çå¨çä¼°è¨è¡¨æï¼å¤é 24.1 åäººæ
å¥åº·çæ³å¯å¾å¾©å¥æåä¸­åçãå±å®¶
ç©çæ²»ç (PT) å¨æä¾äºåå¼
åé¥åææç¾©çè§å¯æ¹é¢é¢è¨éå¤§ææ°ï¼ä¾æ²»çå¸«åæ£èä½¿ç¨ãçºäºå¡«è£é
åç¼ºå£ï¼æåæåº MicroXerciseï¼å®å°å¾®åä½åæè
å¯ç©¿æ´å¼ææ¸¬å¨æ´åå¨ä¸èµ·ï¼çºæ²»çå¸«åæ£èæä¾ä¸åå¨é¢ç
åé¥ä»é¢ï¼åæ¬å½±çãæå­ååæ¸ãè³ééè¦çæ¯ï¼å®æ¡ç¨
å¤ç¶­åææéè¦æ´ (DTW) ååºæ¼æ­¸å çå¯è§£é
æ¹æ³ä¾åæç£æ§éåä¸­ç¾æçæ·±åº¦å­¸ç¿ç¥ç¶ç¶²è·¯ï¼å°æ³¨æ¼éåçé«ç²åº¦ãéç¨®åå
æ¹æ³è³ééè¦ï¼æä¾èè¼¸å¥å¤§å°å¹éçè¼¸åºï¼ä»¥ç²¾ç¢ºå°
çªåº PT ä¸­ééµçç´°å¾®å·®å¥ååä½ï¼å¾èå°è¤éç AI
åæè½æçºæ¸æ°ãå¯æä½çåé¥ãééå¨ä¸åææ¨ä¸­çªé¡¯éäºå¾®åä½ï¼ä¾å¦ç©©å®æ§ååä½ç¯åï¼MicroXercise
é¡¯èæåæçµä½¿ç¨èå°åé¥ççè§£åç¸éæ§ãæ¯è¼æè½ææ¨å¼·èª¿å¶åªæ¼
å³çµ±æ¹æ³çæææ§ï¼ä¾å¦ç¹å¾µäºæ è³è¨ (FMI) åé£çºæ§åå¥æåäº 39% å 42%ãMicroXercise å¨å±å®¶
ç©çæ²»çæ¹é¢æ´é²ä¸æ­¥ï¼æä¾æè¡åé²ä¸ç´è¦ºæç¨ç
è§£æ±ºæ¹æ¡ï¼ä»¥æåæ£èç§è­·åçµæã

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah RÃ¶sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

æè¦ï¼ç³»çµ±æ§æç»åé¡§æ¯ç ç©¶ä¸­è­æåè³ªæé«çãç¶èï¼åé¡§éç¨åå°é¡¯èè³æºåè³æéå¶çé»ç¤ãæç»åé¡§ç¶²è·¯ (LRN) æ¯ç¬¬ä¸åéµå¾ª PRISMA 2020 æ¨æºçå¯è§£é AI å¹³å°ï¼æ¨å¨èªååæ´åæç»åé¡§éç¨ãLRN å¨å¤ç§æå¥å¯¦åé åä¸­é²è¡è©ä¼°ï¼ä½¿ç¨å°å®¶éç¼ç 3 åæå°å­ä¸²ä¾æ¥è©¢ PubMedãéå°å®¶è¨ç·´ææ LRN æ¨¡åãæè½ä»¥å°å®¶æååé¡§ä½çºåºæºãå¯è§£éæ§åæè½ææ¨è©ä¼° LRN è¤è£½å°å®¶åé¡§çè½åãä¸è´æ§ä»¥ Jaccard ææ¸åæ··æ·ç©é£æ¸¬éãç ç©¶äººå¡å¨ç ç©¶å®æåå°å½¼æ­¤ççµæä¿å¯ãéççç ç©¶æ´åå° LRN çæçç³»çµ±æ§åé¡§ä¸­ãLRN æ¨¡åå¨æ²æå°å®¶è¨ç·´çææ³ä¸å±ç¾åºåªç°çåé¡æºç¢ºçï¼éå° 84.78% å 85.71% çæºç¢ºçãæè½æé«çæ¨¡åéå°äºé«è©åèéä¿¡è³´åº¦ (k = 0.4953) åå¯è§£éæ§ææ¨ï¼å°ãæ¸å°ãããæå¤ãåãé³å©ãèãééæ´æå¥ãé£çµå¨ä¸èµ·ãå¦ä¸å LRN æ¨¡åæ¶µèäº 91.51% çç¸éæç»ï¼åç®¡èéå°å®¶çå¤æ·ä¸å (k = 0.2174)ï¼ä½åå«äºãä¹³è ãããééãï¼æå¥ï¼åãé©æçãç­è©å½ãLRN åªæ¼æååé¡§ï¼11 åæè¶é 19,920 åéï¼ï¼å°æ´åéç¨ç¸®ç­çº 5 å¤©è¶é 288.6 åéãéé ç ç©¶é¡¯ç¤ºï¼å¯è§£éç AI ä¸éè¦å°å®¶è¨ç·´å³å¯æåé²è¡å°å®¶ç­ç´ç PRISMA ç¸å®¹ç³»çµ±æ§æç»åé¡§ãLRN ç¸½çµäºå¤ç§æå¥ç ç©¶ççµæï¼ä¸¦æ¾åºèè¨åºç ç©¶äººå¡ç¼ç¾å¹¾ä¹ç¸åçä¸»é¢ãå¯è§£éç AI å¯ä»¥æºç¢ºå°å å¿«æåå°è¨åºå¯¦åççè§£ï¼ææ½åé©æ°é«çä¿å¥ç ç©¶ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

æè¦ï¼èç±æºæ§ç°å¢ä¸­ä¸å¼äººæ³¨ç®çææ¸¬å¨è¾¨è­æ¥å¸¸æ´»åï¼è½åç¨åç¨®é«çä¿å¥æç¨ãç£æ§åè©¦èå¨å®¶ä¸­å¦ä½å·è¡æ´»åï¼ä»¥åå¶é¨èæéçè®åï¼å¯ä»¥æ­ç¤ºå¥åº·åé¡çæ©æççï¼ä¾å¦èªç¥è½åä¸éãæ­¤é åä¸­çå¤§å¤æ¸æ¹æ³é½ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼éäºæ¨¡åéå¸¸è¢«è¦çºå°ææ¸¬å¨è³æå°æè³æ´»åçé»çå­ãç¶èï¼éå°å®¶ä½¿ç¨èï¼ä¾å¦è¨åºé«å¸«ï¼éè¦ä¿¡ä»»ä¸¦äºè§£éäºæ¨¡åçè¼¸åºãå æ­¤ï¼äººé¡æ´»åè¾¨è­çå¯è§£é AI (XAI) æ¹æ³æéèçï¼ä»¥æä¾ä¾èªéäºæ¨¡åçç´è¦ºèªç¶èªè¨èªªæãä¸åç XAI æ¹æ³æç¢çä¸åçèªªæï¼èå¶æææ§éå¸¸ééä½¿ç¨èèª¿æ¥ä¾è©ä¼°ï¼éå¨ææ¬åå¬å¹³æ§æ¹é¢éå¸¸å·æææ°æ§ãæ¬ææåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªåè©ä¼°æ¹æ³ï¼ä»¥å¨åé¸èä¸­æ¾åºæé©åéå°å®¶ä½¿ç¨èç XAI æ¹æ³ãæåçåæ­¥çµæè¡¨æï¼LLM è©ä¼°èä½¿ç¨èèª¿æ¥ä¸è´ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼è¿ç¯è®ºææåºäºç¨äºä»è§ç½èç¼åºå¾åè¿è¡ç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åæç¥åºï¼ä»èéå¯¹ç¾çåç±»å¯¹æ­£å¸¸ ResNet æ¨¡åè¿è¡æ¹è¿ãæ¬ç ç©¶å¼å¥äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»å­¦ä¸ä¸äººå£«è½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬ä¸å½ä»çå»çä¿å¥é¢åå°¤ä¸ºç¸å³ï¼å¨è¯¥é¢åï¼å¯¹ AI åºç¨çéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§ååä¹éå¾·çä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼é¨ç¾ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ç¼ç§ç¾çæºè½è¯å« (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼é¨ç¾çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 å¾åãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152 äºä¸ªåä½çæ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åè¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 å¾åä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åæ¹é¢çå¿«éé²å±ï¼ä»£è¡¨èå¨å å¼·è¨ºæ·æºç¢ºæ§ååäººåæ²»çæ¹é¢éåºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å°å¶å¯ä¿¡åº¦é²è¡å´æ ¼çå¯©æ¥ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç®åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»ä¸­é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥ä¸¦æªååè§£æ±ºå¶å¨é«å­¸å½±åé åä¸­çç¹å®è®ååæç¨ãæ¬èª¿æ¥æ¨å¨ééæåºé«å­¸å½±åä¸­ä½¿ç¨çåºç¤æ¨¡åçæ°åé¡æ³ä¸¦åæç¢ºä¿å¶å¯ä¿¡åº¦çééµåæ©ï¼ä¾å¡«è£éä¸ç©ºç½ãæååé¡§äºåºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç¶åç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡ååç­ (Q&A) ä»¥åç¾çè¨ºæ·ãéäºé åä¹æä»¥è¢«å¼·èª¿ï¼æ¯å çºèå¶ä»æç¨ç¸æ¯ï¼å®åå·²ç¶çå°ç¸å°æçä¸å¤§éçåºç¤æ¨¡åãæåå°æ³¨æ¼æ¢è¨é«å­¸å½±ååææç¨¿ä¸­å¯ä¿¡åº¦çæç»ãæåæ¢è¨äºçºæ¯åæç¨æ§å»ºå¯ä¿¡åºç¤æ¨¡åçè¤éææ°ï¼ç¸½çµäºç¶åéæ³¨é»åå¢å¼·å¯ä¿¡åº¦çç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èè­·çæ¹é¢çæ½åãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼ä¸¦å¡å°ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸å½±ååæä¸­å·²éå°æ´é«é«æºç¢ºåº¦ãç¶èï¼ç¹å®æ£èç¾¤é«çæè½å·®ç°å°å¶è¨åºæç¨ãå®å¨æ§èå¬å¹³æ§æ§æææ°ãéå¯è½æå½±é¿å·²ç¥çæ£èç¾¤é«ï¼ä¾å¦åºæ¼æ§å¥ãå¹´é½¡æç¾çäºåï¼ä»¥åååæªç¥ä¸æªæ¨ç±¤çç¾¤é«ãæ­¤å¤ï¼æ­¤é¡è§å¯å°çæè½å·®ç°çæ ¹æ¬åå éå¸¸é£ä»¥ç¼ç¾ï¼é»ç¤äºç·©è§£æªæ½ãå¨æ¬æä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨åçç¼ç¾æ¹æ³ (SDM) ä¾è­å¥å¯è§£éçè³ææè½ä¸ä½³å­éï¼ä¸¦éå°è§å¯å°çæè½å·®ç°åå å¶å®åè¨­ãæåå¼å¥ä¸ç¨®æ°ç SDMï¼ä¸¦å¨è¸é¨ X åçä¸­èºçåèºä¸å¼µåé¡çæ¡ä¾ç ç©¶ä¸­æç¨å®ãæåçç ç©¶è­æäº SDM å¨åè¨­å¶å®ä¸­çæææ§ï¼ä¸¦å°å»£æ³ä½¿ç¨çè¸é¨ X åçè³æéåæ¨¡åä¸­ååè§å¯å°ä½ç¡æ³è§£éçç·æ§åå¥³æ§æ£èä¹éçæè½å·®ç°æä¾äºè§£éãæåçç¼ç¾è¡¨æï¼å¨åé¡ä»»åä¸­ï¼ééè¸èå¼æµç®¡åå¿é»åå°ç·çå­å¨ï¼å­å¨æ·å¾å­¸ç¿ãéäºæ·å¾ç¹å¾µççè¡çå­å¨åºæ¼æ§å¥çå·®ç°ï¼ä¼¼ä¹æå°è´è§å¯å°çåé¡æè½å·®è·ï¼éä»£è¡¨æ·å¾å­¸ç¿åæ¨¡åå¬å¹³æ§åæä¹éååæªåå°éè¦çäº¤äºä½ç¨ã

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

æè¦ï¼èªæ³¨æåæ©å¶å·²è¢«æ¡ç¨æ¼å¤åå»£æ³ä½¿ç¨çè¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN)ï¼ä¾å¦ GATï¼ï¼å®å¯ä»¥èªé©æå°æ§å¶æ²¿èåºå±¤åå½¢éç·£æµåçè³è¨éãéç¨®æ³¨æåçä½¿ç¨ä½¿å¾æ­¤é¡æ¨¡åæçºå¯è§£é AI (XAI) ç ç©¶çåºç·ï¼å çºééæ³¨æåçè©®éå·²å¨åç¨®é åï¼ä¾å¦èªç¶èªè¨èçåé»è¦è¦è¦ºï¼ä¸­æ®åãç¶èï¼ç¾æçç ç©¶éå¸¸ä½¿ç¨å¤©ççè¨ç®æ¹æ³å¾æ³¨æåä¸­æ¨å°åºæ­¸å åæ¸ï¼ä¸¦ä¸æ²æèæ®å°éç·£æ­¸å çç²¾ç¢ºä¸ä»ç´°çè¨ç®ãå¨æåçç ç©¶ä¸­ï¼æåæ¨å¨å¡«è£æ³¨æååç¨ MPNN çå»£æ³ä½¿ç¨èå®åå¨å¾å¤§ç¨åº¦ä¸æªè¢«ååæ¢ç´¢çå¯è§£éæ§ä¹éçå·®è·ï¼éåä¸»é¡å·²å¨å¶ä»é åç©æ¥µç ç©¶ãçºæ­¤ï¼ä½çºç¬¬ä¸æ¬¡åè©¦ï¼æåå° GNN ä¸­æ³¨æåæ¬éçéç·£æ­¸å åé¡å½¢å¼åãç¶å¾ï¼æåæåº GATTï¼ä¸ç¨®å»ºç«å¨è¨ç®æ¨¹ä¸çéç·£æ­¸å è¨ç®æ¹æ³ãééå¨é¢çå¯¦é©ï¼æåå±ç¤ºäºæåæåºçæ¹æ³å¨è©ä¼° GAT çæ­¸å ææå·æçææãç¸åå°ï¼æåæç¶é©é©è­äºåå°åæ³¨æåå±¤ä¸çæ³¨æåæ¬éåå¹³åå¼ä¸è¶³ä»¥è©®é GAT æ¨¡åçè¡çºãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jordan7186/GAtt/tree/mainã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æèå¼±çææï¼å®¹æåºç¾ç²çç¼ä½ãå¤§è¦ç¼è²ä¸æçæåºç¾ç²çç¼ä½æé æä¸è¯å¾æï¼å æ­¤éè¦åæ©è¨ºæ·ãç®åæ°çåç²çç¼ä½çé»éæ¨æºä¾è³´æ¼é£çºçè¦è¨è¦é»å (EEG) ç£æ¸¬ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§åæé²è¡å¤é »éè¦é»å (EEG) è¨éåå³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çç¼ä½åµæ¸¬éç¨ï¼ä¸¦æ¡ç¨æ¸å°çè¦é»åè£ç½®ï¼å¶ä¸­æ¡ç¨äºå·ç©ç¥ç¶ç¶²è·¯ãåå½¢æ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ ä½¿ç¨æ¸å°çè£ç½®å³æåµæ¸¬ç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééå¨ Zenodo è³æéä¸ä½¿ç¨ 10 åäº¤åé©è­è©ä¼°æè½ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçæ¹é¢åå¥éå°äº 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

æè¦ï¼<paragraph>å¨éå»å¹¾å¹´ï¼è¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) ä¸­çäººå·¥æºæ§ (AI) å¨å©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§æ¹é¢ç¼æ®äºééµä½ç¨ãåç®¡ AI æ¨¡åå·æä»¤äººæ»¿æçè½åï¼ä½ç¼ºä¹éæåº¦åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å¯é æ§çºå¿è¦èéçé«çèæ¯ä¸ï¼éå¸¶ä¾äºéå¤§çææ°ãå¨ä¸å½±é¿é æ¸¬ç²¾æºåº¦çææ³ä¸å¯¦ç¾éæåº¦ä»ç¶æ¯ä¸é ééµææ°ãæ¬ææåºäºä¸ç¨®æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥å¢å¼· CNN è¡çç¹å¾µçé æ¸¬è½åï¼åæå·åæ¾å°ç¹å¾µåºæçå¯è§£éæ§ãRad4XCNN ä¸åæ¼åºæ¼é¡¯èæ§åçå³çµ±æ¹æ³ï¼å®ééæ¾å°çµå­¸å°å¯çè§£çå«ç¾©è CNN è¡çç¹å¾µéè¯èµ·ä¾ï¼çºè¶è¶è¦è¦ºååè¡¨çè§£éæ¹æ³æä¾äºæ°çè§é»ãæåä»¥ä¹³çåé¡ä»»åä½çºæ¡ä¾ç ç©¶ï¼å¨è¶é³æ³¢å½±åè³æéä¸è©ä¼° Rad4XCNNï¼åæ¬ä¸åç·ä¸è³æéåå©åç¨æ¼å§é¨åå¤é¨é©è­çå§é¨è³æéãä¸äºééµçµæå¦ä¸ï¼i) è ViT è¡çç¹å¾µåæ¾å°ç¹å¾µç¸æ¯ï¼CNN è¡çç¹å¾µä¿è­äºæ´ç©©å¥çæºç¢ºåº¦ï¼ii) å³çµ±çè¦è¦ºååè§£éæ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN æ²æç§ç²æ¨¡åæºç¢ºåº¦ä¾æåå¶å¯è§£éæ§ï¼iv) Rad4XCNN æä¾äºå¨å±è§£éè¦è§£ï¼ä½¿é«å¸«è½å¤ åææ¨¡åè¼¸åºåç¼ç¾ãæ­¤å¤ï¼æåå¼·èª¿å°å¯è§£éæ§æ´åå° AI æ¨¡åä¸­å°æ¼å¢å¼·è¨åºå¯¦åä¸­çä¿¡ä»»åæ¡ç¨è³ééè¦ï¼ä¸¦å¼·èª¿äºæåçæ¹æ³å¦ä½è½ç·©è§£èå¯è§£é AI æ¹æ³ç¸éçä¸äºçæ®ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼äºè§£å®åå¨è§£ç¢¼åè§£éèªè¨æèå«çè¤éå æéä¿ç¶²è·¯ä¸­çè½ååéå¶è®å¾è³ééè¦ãç®åçæè¡ä½¿ç¨æç¢ºæé±å«çå ææ¨çï¼ä½å¼·çéè¦ä¸ç¨®çµ±ä¸çæ¹æ³ï¼çµåå©èä»¥æ´ææå°èçå»£æ³çå æéä¿ãæ¬ç ç©¶æåºäºä¸ç¨®ç¨±çºæå¢æç¥æ¨çå¢å¼·èåäºå¯¦åæ (CARE CA) æ¡æ¶çæ°æ¶æ§ï¼ä»¥å¢å¼·å ææ¨çåå¯è§£éæ§ãæåºçæ¡æ¶çµåäºä½¿ç¨ ConceptNet ååäºå¯¦é³è¿°çæç¢ºå ææª¢æ¸¬æ¨¡çµï¼ä»¥åéé LLM é²è¡çé±å«å ææª¢æ¸¬ãæåçæ¡æ¶æ´é²ä¸æ­¥ï¼å å¥ä¸å±¤åäºå¯¦è§£éï¼ä»¥å¼·èª¿ LLM å°å æéä¿ççè§£ãä¾èª ConceptNet çç¥è­å¢å¼·äºå¤é å ææ¨çä»»åçå·è¡ï¼ä¾å¦å æç¼ç¾ãå æè­å¥ååäºå¯¦æ¨çãåäºå¯¦å¥å å¥äºæªç±æå¢é æçæç¢ºç¥è­ãééçµåéäºå¼·å¤§çæ¨¡çµï¼æåçæ¨¡åæ¨å¨æä¾å°å æéä¿æ´æ·±å¥ççè§£ï¼å¯¦ç¾å¢å¼·çå¯è§£éæ§ãåºæºè³æéçè©ä¼°é¡¯ç¤ºå¨ææææ¨ï¼ä¾å¦æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸é½æææåãæåéå¼å¥äº CausalNetï¼ä¸åæ°çè³æéï¼ä¸¦éä¸äºæåçç¨å¼ç¢¼ï¼ä»¥ä¿é²å¨éåé åçé²ä¸æ­¥ç ç©¶ã

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

æè¦ï¼<paragraph>æ¯åå°äººååºæ±ºå®ç AI ç³»çµ±é½æä¸ç¾¤å©å®³éä¿äºº
åå°éäºæ±ºå®çè¦ªèº«å½±é¿ãç¶èï¼AI
ç³»çµ±çè§£éå¾å°è½æ»¿è¶³éç¾¤å©å®³éä¿äººçè³è¨éæ±ï¼èä»å
éå¸¸é½æ¯ AI æ°æãéé æäºå³éè³è¨è
åå°ç³»çµ±æ±ºç­å½±é¿çäººå£«ï¼ä¾å¦é åå°å®¶åæ±ºç­ä¸»é«ï¼éè¦çè³è¨ä¹éçè½å·®ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº
ãXAI æ°æåé¡åº«ãï¼å®æ¯ XAI åé¡åº«çå»¶ä¼¸ï¼åå«ä¾èª AI æ°æå¨å©åä½¿ç¨æ¡ä¾ä¸­çè³è¨éæ±ç®éï¼å°±æ¥­
é æ¸¬åå¥åº·ç£æ¸¬ãç®éæ¶µèäºè³æã
ç³»çµ±èæ¯ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼ç­é¡å¥ãæåééä»»ååè¨ªè«æ¶éè³è¨éæ±ï¼åèèå¨è¨ªè«ä¸­è©¢åäºå©å AI ç³»çµ±çåé¡ï¼ä»¥æ±ºå®æ¯å¦æ¡ç¨å®åï¼ä¸¦æ¶å°å£é ­
è§£éä½çºåæãæåçåæé¡¯ç¤ºï¼åèèå¨æ¶å°è§£éå¾ä¿¡å¿æææåï¼ä½ä»åççè§£å»é¢è¨ææ°ãéäºææ°åæ¬é£ä»¥æ¾å°è³è¨åè©ä¼°èªå·±ççè§£ï¼ä»¥åè©¦åå¤å
çè§£ãæ­¤å¤ï¼åèèå°ç³»çµ±é¢¨éªåå¥½èçåååé¥å½±é¿äºä»åçè³è¨éæ±ãèªçºé¢¨éªé«çåèèå°æ±è§£éç³»çµ±é¨ç½²èå¾çæåï¼èèªçºé¢¨éªä½çäººåè©¢åç³»çµ±ç
æä½ãæåçç ç©¶æ¨å¨ééå¼·èª¿ AI æ°æçè³è¨éæ±ãç®æ¨å
ææ°ï¼ä¾æ¯æå° AI æ°æç´å¥å¯è§£éæ§å·¥ä½ä¸­ãæåå°æåçç ç©¶çµæç¸½çµçºäºåééµåç¤ºï¼éäºåç¤ºå¯ä»¥çºæªä¾éå°éå°æ¥­å©å®³éä¿äººåç¾çè§£éè¨­è¨æä¾åèã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian GeiÃler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, BjÃ¶rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias KÃ¼ster, AndrÃ© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

æè¦ï¼å¨éå»çåå¹´ä¸­ï¼ççå­¸ä¸­çäººå·¥æºæ§ (AI) æ¹æ³å·²å¤§å¹é²æ­¥ãç¶èï¼ç±æ¼è¨±å¤ææ°ï¼åæ¬å°ç ç©¶çµæè½åçºè¨åºè¨ºæ·ç¢åå¨æè¡åæ³è¦æ¹é¢çéç¤ï¼ä»¥åç¼ºä¹æ¨æºåä»é¢ï¼å°è´æ´åå°å¸¸è¦è¨åºå¯¦åä¸­é²å±ç·©æ¢ãéæ¾ä¸èä¾æåç¡éç EMPAIA è¨ç«æå°äºéäºææ°ãå¨æ­¤ï¼æåæä¾ EMPAIA çæå°±åç¶é©æè¨çæ¦è¿°ãEMPAIA æ´åäºççå­¸ AI çæç³»çµ±çååå©å®³éä¿äººï¼å³ççå­¸å®¶ãé»è¦ç§å­¸å®¶åç¢æ¥­ãå¨å¯ååä½ä¸ï¼æåå¶å®äºæè¡äºéæ§æ¨æºãAI æ¸¬è©¦åç¢åéç¼å»ºè­°ï¼ä»¥åå¯è§£éæ§æ¹æ³ãæåå¯¦ä½äºæ¨¡çµåä¸éæ¾åå§ç¢¼ç EMPAIA å¹³èºï¼ä¸¦æåæ´åäºä¾èª 8 åä¸åä¾æåç 14 ååºæ¼ AI çå½±ååææç¨ç¨å¼ï¼å±ç¤ºäºä¸åçæç¨ç¨å¼å¦ä½ä½¿ç¨å®ä¸çæ¨æºåä»é¢ãæååªåèæ®éæ±ï¼ä¸¦è©ä¼°äº AI å¨æ­æ´²åäºæ´²ç 14 åä¸åççå¯¦é©å®¤ä¸­çå¯¦éè¨åºæç¨ãé¤äºæè¡éç¼å¤ï¼æåéçºææå©å®³éä¿äººå»ºç«äºä¸åè«å£ï¼ä»¥åäº«æ¸ä½ççå­¸å AI çè³è¨åç¶é©ãåæ¥­ãè¨åºåå­¸è¡å©å®³éä¿äººç¾å¨å¯ä»¥æ¡ç¨ EMPAIA çå¸¸è¦éæ¾åå§ç¢¼ä»é¢ï¼éçºå¤§è¦æ¨¡æ¨æºååç°¡åæµç¨æä¾äºç¨ç¹çæ©æãéè¦é²ä¸æ­¥çåªåæè½ææä¸å»£æ³å°å»ºç«ä¾è¡å¯¦é©å®¤ä½¿ç¨ä¸­ç AI è¼å©ãçºæ­¤ï¼å·²æç«éçå©åæ EMPAIA Internationalï¼ä»¥ä½çºæ°¸çºåºç¤æ¶æ§ï¼ç¹¼çºé²è¡æ¨æºåï¼ä¸¦æ¯æ´å»£æ³å¯¦ä½åå¡å° AI è¼å©æ¸ä½ççå­¸çæªä¾ã

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

æè¦ï¼åäºå¯¦è§£é (CE) æè¡å·²å¼èµ·éæ³¨ï¼ä½çºä¸ç¨®çºè AI ç³»çµ±äºåçä½¿ç¨èæä¾è¦è§£çæ¹æ³ãéç¶å¨é«å­¸å½±ååèªåé§é§æ±½è»ç­é åå»£æ³ç ç©¶ï¼åå½¢åäºå¯¦è§£é (GCE) æ¹æ³ç¸å°è¼å°è¢«æ¢ç´¢ãGCE æç¢çä¸åé¡ä¼¼æ¼åå§åå½¢çæ°åå½¢ï¼ä¸¦æ ¹æåºç¤é æ¸¬æ¨¡åç¢çä¸åççµæãå¨éäº GCE æè¡ä¸­ï¼åç®¡å¨å¶ä»é åï¼ä¾å¦èè¡é¢¨æ ¼åèªç¶èªè¨å»ºæ¨¡ï¼ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæå°±ï¼ä½æ¤åºæ¼çææ©å¶çæè¡ç²å¾çéæ³¨ç¸å°æéãå°çæå¼è§£éå¨çåå¥½æºæ¼å®åå¨æ¨çæéç¢çåäºå¯¦å¯¦ä¾çè½åï¼å©ç¨è¼¸å¥åå½¢çèªä¸»ç²åæ¾åãåºæ¼ä¸è¿°çç±ï¼æåçç ç©¶å¼å¥äº RSGG-CEï¼ä¸ç¨®ç¨æ¼åäºå¯¦è§£éçæ°åç©©å¥é¨æ©åå½¢çæå¨ï¼è½å¤ å¾å­¸ç¿å°çæ½å¨ç©ºéä¸­ç¢çåäºå¯¦ç¯ä¾ï¼èæ®é¨åæåºççæåºåãæ­¤å¤ï¼æåé²è¡å®éåå®æ§åæï¼ä»¥æ¯è¼ RSGG-CE çæè½è SoA çæå¼è§£éå¨ï¼å¼·èª¿å¶å¢å¼·äºç¢çåçè§£éåé¸çè½åã

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

æè¦ï¼å¯è§£é AI çåæ©ä¹ä¸æ¯è®äººåå¨ä½¿ç¨åé¨ç½² AI æ¨¡åæååºæ´å¥½ãæ´ææºçæ±ºç­ãä½éè¦ä»ç´°è©ä¼°ä»¥è©ä¼°æ¯å¦å·²éå°æ­¤é æãç®åçè©ä¼°ä¸»è¦éä¸­å¨è§£éçæ¼ç®æ³ç¹æ§ï¼èæ¶åäººé¡åè©¦èçè©ä¼°éå¸¸æ¡ç¨ä¸»è§åé¡ä¾æ¸¬è©¦äººé¡å°è§£éæç¨æ§ççæ³ï¼èæ²æåºæ¼å®¢è§ææ¨åæ¸¬éãå¨éé å·¥ä½ä¸­ï¼æåè©ä¼°è§£éæ¯å¦å¯ä»¥å¨æ©å¨å­¸ç¿æ¨¡åéç¼çå¯¦éå ´æ¯ä¸­æ¹åäººé¡æ±ºç­å¶å®ãæåé²è¡äºä¸é æ¶åå½±åè³æçæ··åæ¹æ³ä½¿ç¨èç ç©¶ï¼ä»¥è©ä¼° SmoothGradãGradCAM åé è¨è§£éå¨å©åä»»åä¸­ç¢ççé¡¯èæ§åï¼æ¨¡åé¸æååäºå¯¦æ¨¡æ¬ãä»¤äººé©è¨çæ¯ï¼æåæ²æç¼ç¾ä»»ä½é¡¯èæ§åï¼å³ä½¿æ¯è¨­è¨çºææ¼çè§£ä¸é«åº¦æç¤ºç­æ¡çåæé è¨è§£éï¼è½è®ä½¿ç¨èå¨éäºä»»åä¸é¡¯èæ¹åçè­æãåç®¡å¦æ­¤ï¼è§£éç¢ºå¯¦æå©æ¼ä½¿ç¨èæ´æºç¢ºå°æè¿°æ¨¡åãéäºç¼ç¾æç¤ºæåè¦å°åºæ¼é¡¯èæ§çè§£éä¸­å¯è½å­å¨èª¤è§£çæç¨æ§ä¿æè¬¹æã

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

æè¦ï¼å¯è§£éæ§åå®å¨æ§å»ºç«ä¿¡ä»»ãéäºéè¦ä¸åæ¨¡åä¾å±ç¤ºä¸è´æ§åå¯é æ§ãçºäºå¯¦ç¾éäºï¼æå¿è¦ä½¿ç¨ååææ¸æåç¥è­ï¼ä¸¦ä½¿ç¨è AI æç¨ç¸éççµ±è¨åç¬¦è AI æ¹æ³ - å®ç¨ä½¿ç¨ä»»ä½ä¸ç¨®æ¹æ³é½ä¸æå¥æãå æ­¤ï¼æåä¸»å¼µä¸¦è©¦åè­æ NeuroSymbolic AI æ¹æ³æ´é©åæ¼ä½¿ AI æçºåä¿¡ä»»ç AI ç³»çµ±ãæåæåºäº CREST æ¡æ¶ï¼å±ç¤ºäºä¸è´æ§ãå¯é æ§ãä½¿ç¨èå±¤ç´çå¯è§£éæ§åå®å¨æ§æ¯å¦ä½å»ºç«å¨ NeuroSymbolic æ¹æ³ä¸çï¼è©²æ¹æ³ä½¿ç¨æ¸æåç¥è­ä¾æ¯æééµæç¨ï¼ä¾å¦å¥åº·åç¦ç¥ï¼çè¦æ±ãæ¬æéé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼å çºå®æ¯ CREST æ¡æ¶ä¸­é¸æç AI ç³»çµ±ãLLM å å¶å¨èçå»£æ³çèªç¶èªè¨èç (NLP) å ´æ¯æ¹é¢çå¤åè½æ§èååç ç©¶äººå¡çéæ³¨ãä¾å¦ï¼ChatGPT å Google ç MedPaLM å·²æçºæä¾ä¸è¬åå¥åº·ç¸éæ¥è©¢ä¿¡æ¯çæ¥µæå¸æçå¹³å°ãåç®¡å¦æ­¤ï¼éäºæ¨¡åä»ç¶æ¯é»çå­ï¼åç®¡ç´å¥äºäººé¡åé¥åæä»¤å¼å°çèª¿æ´ãä¾å¦ï¼åç®¡å¶å®äºå®å¨é²è­·æªæ½ï¼ChatGPT ä»å¯è½ç¢çä¸å®å¨çåæãCREST æåºäºä¸ç¨®åççæ¹æ³ï¼å¨ NeuroSymbolic æ¡æ¶ä¸­å©ç¨ç¨åºååºæ¼åè¡¨çç¥è­ï¼ä»¥é¡æè LLM ç¸éçææ°ã

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

æè¦ï¼<paragraph>éè¦æ§ä¼°è¨å¨æ¯ä¸ç¨®å¯è§£éæ§æ¹æ³ï¼ç¨æ¼éåæ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) çç¹å¾µéè¦æ§ãå¨è¦è¦ºTransformer (ViT) ä¸­ï¼èªææ³¨ææ©å¶èªç¶æå°è´æ³¨æååï¼æææå°å¶è§£éçºéè¦æ§åæ¸ï¼è¡¨ç¤º ViT æ¨¡åéæ³¨åªäºè¼¸å¥ç¹å¾µãç¶èï¼æ³¨æååä¸¦æªèæ®ä¾èªä¸æ¸¸ä»»åçä¿¡èãçºäºç¢çå°ä¸æ¸¸ä»»åææçè§£éï¼æåéç¼äºé¡å¥ååæ³¨æåå (CDAM)ï¼éæ¯ä¸ç¨®åºæ¼æ¢¯åº¦çæ´åï¼ç¨æ¼ä¼°è¨ç¸å°æ¼å·²ç¥é¡å¥ææ½å¨æ¦å¿µçç¹å¾µéè¦æ§ãCDAM æ ¹æå°æçç¬¦èèåé¡å¨é ­çé æ¸¬ç¸éç¨åº¦ï¼èª¿æ´æ³¨æååæ¸ãé¤äºéå°ç£ç£åé¡å¨å¤ï¼CDAM éå¯ä»¥ééæ¸¬é ViT çæ½å¨ç©ºéä¸­çç¸ä¼¼æ§ä¾è§£éé¸å®æ¨£æ¬å±æçä»»ææ¦å¿µãæ­¤å¤ï¼æåå¼å¥äºå¹³æ» CDAM åç©å CDAMï¼å®åå°ä¸ç³»åå·æç¥å¾®æ¹è®çç¬¦èç CDAM é²è¡å¹³åãæåçéååºæºåæ¬æ­£ç¢ºæ§ãç·æ¹æ§åé¡å¥æææ§ï¼èå¶ä» 7 åéè¦æ§ä¼°è¨å¨ç¸æ¯ãé¦èãå¹³æ»åç©å CDAM å¨ææä¸ååºæºä¸­è¡¨ç¾åºè²ãç¹å¥æ¯ï¼æåççµæè¡¨æç¾æçéè¦æ§ä¼°è¨å¨å¯è½ç¡æ³æä¾è¶³å¤ çé¡å¥æææ§ãæåééåºæ¼èºé¨é»è¦æ·å±¤ææ (CT) ææè¨ç·´åè§£éæ¡æ§è«ç¤åçç©æ¨è¨é æ¸¬æ¨¡åï¼è­æäº CDAM å¨é«å­¸å½±åä¸­çæç¨ãç¸½çä¾èªªï¼CDAM è¢«è­æå·æé«åº¦é¡å¥ååæ§åèªç¾©ç¸éæ§ï¼åææä¾ç°¡æ½çè§£éã</paragraph>

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

æè¦ï¼æ¬ç ç©¶è°æ¥äºå¨ COVID-19 ç«ææé´åä»¥åé¢æµæ­»äº¡çæ¶ï¼å·²é¨ç½²äººå·¥æºè½ (AI) æ¨¡åçæ§è½ãå¯è§£éæ§åç¨³å¥æ§ãä½ä¸ºåç±»ç ç©¶ä¸­çé¦ä¾ï¼æä»¬åç°è´å¶æ¯ç¥ç»ç½ç» (BNN) åæºè½è®­ç»ææ¯è®©æä»¬çæ¨¡åå¨æ°æ®åçéå¤§ååæ¶ä»è½ä¿ææ§è½ãæä»¬çç»æå¼ºè°äºå¼åç¨³å¥ç AI æ¨¡åçéè¦æ§ï¼å³ä½¿å¨å·ææææ§çæ¡ä»¶ä¸ï¼è¿äºæ¨¡åä¹è½å¹éæè¶è¶ä¸´åºå»ççé¢æµãæä»¬å¯¹æ¨¡åå¯è§£éæ§çæ¢ç´¢è¡¨æï¼éæºæ¨¡åä¼äº§çæ´å¤æ ·åä¸ä¸ªæ§åçè§£éï¼ä»èçªåºäºå¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­æä¾è¯¦ç»ä¸ä¸ªæ§åè§è§£ç AI æ¨¡åçå¿è¦æ§ãæ­¤å¤ï¼æä»¬å¼ºè°äºéå AI æ¨¡åä¸­ä¸ç¡®å®æ§çéè¦æ§ï¼è¿ä½¿ä¸´åºå»çè½å¤æ ¹æ®å¯é çé¢æµååºæ´ææºçå³ç­ãæä»¬çç ç©¶æå¡å¨å»çä¿å¥ç AI ç ç©¶ä¸­ä¼åèèå®æ½ç§å­¦ï¼å¹¶ç¡®ä¿ AI è§£å³æ¹æ¡å¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­å®ç¨ãæçä¸å¯æç»­ãéè¿è§£å³å»çä¿å¥ç¯å¢ä¸­çç¬ç¹ææåå¤ææ§ï¼ç ç©¶äººåå¯ä»¥å¼ååºæææ¹åä¸´åºå®è·µåæ£èé¢åç AI æ¨¡åã

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

æè¦ï¼èºçå è±åççæ­»äº¡äººæ¸ç 21%ï¼äºå¹´å­æ´»çå¾å¤§ç¨åº¦åæ±ºæ¼ççè¢«ç¼ç¾çéæ®µãæè¿çç ç©¶å·²è­æäººå·¥æºè½æ¹æ³å·æå¾ä¾è¡ææä¸­æºç¢ºåæ©è¨ºæ·èºççè½åãç¶èï¼æ­¤è­æå°æªè½åçºè¨åºå¯¦åï¼å¶ä¸­ä¸åéç¤æ¯ç¼ºä¹å¯è§£éçæ¨¡åãæ¬ç ç©¶æ¢è¨äºæç¨è®åèªåç·¨ç¢¼å¨ (VAE)ï¼ä¸ç¨®çæå¼äººå·¥æºè½æ¨¡åï¼æ¼èºççç¶ãå°æåºçæ¨¡åè¨ç·´æ¼å¾ LIDC-IDRI å¬å±æ¸æéä¸­æåç 3D é»è¦æ·å±¤ææçç¶ãééèé¡æ¢ç´¢äº VAE çæç 2D åççæ½å¨åéè¡¨ç¤ºï¼ä»¥è­æå¶åè³ªï¼ä¸¦ç¨æ¼èºçè¨ºæ·ç MLP åé¡å¨æ¨¡åï¼æä½³æ¨¡åéå°äº AUC 0.98 å 93.1% æºç¢ºåº¦çæåé²ææ¨ãèé¡åæé¡¯ç¤ºï¼VAE æ½å¨ç©ºéæ ¹æææç¾©çç¹å¾µçµæï¼åæ¬è«ç¤å¤§å°ãå½¢çãæ£èåæ¡æ§é¡å¥ï¼å°æ¡æ§åè¯æ§çç¶çæ¸æéåéãæåéåæ¬æ¨æºé«æ¯ VAE (GVAE) åæ´æ°ççå©åé· VAE (DirVAE) çæ¯è¼åæï¼å¾èç¨çå©åé·åä½åä»£åé©ï¼ä»¥ä¿é²å·æè§£éç¹å¾µè¡¨ç¤ºçæ´å·å¯è§£éæ§çæ½å¨ç©ºéãæå¾ï¼æåå±ç¤ºäºèè¨åºææç¾©çç¹å¾µè®åç¸æçæ½å¨ç©ºéæ©«è¶çæ½åã

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

æè¦ï¼ç¾æçåååé¡å¨è¼¸åºè§£éå·¥å·å¯åçºä¾è³´æ¼æ¨¡åå§é¨å­åæ¬éçç½çï¼ä»¥åèæ¨¡åç¡éçé»çãé¨è AI å¨é«çé åçä½¿ç¨å¢å ï¼å¯è§£éæ§å·¥å·çä½¿ç¨ä¹é¨ä¹å¢å ãç¾æé«å­¸å½±åè§£éçå·¥ä½éé»å¨æ¼ç½çå·¥å·ï¼ä¾å¦ gradcamãç¶èï¼åæå°é»çå·¥å·ææé¡¯çåªé»ï¼åæ¬è½å¤ èä»»ä½åé¡å¨ä¸èµ·ä½¿ç¨ï¼ä»¥åå»£æ³çé»çå·¥å·å¯ä¾é¸æãå¨æ¨æºå½±åä¸ï¼é»çå·¥å·èç½çä¸æ¨£ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåæ¯è¼äºå¤ç¨®é»çæ¹æ³å¨è¦ç MRI è³æéä¸è gradcam çæè½ãæåè­æå¤§å¤æ¸é»çå·¥å·ä¸é©åè§£éé«å­¸å½±ååé¡ï¼ä¸¦è©³ç´°åæå¶ç¼ºé»çåå ãæåéè¡¨æä¸ç¨®é»çå·¥å·ï¼åºæ¼å æå¯è§£éæ§ç rexï¼è¡¨ç¾è \gradcam ä¸æ¨£å¥½ã

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

æè¦ï¼AI éç¼ç¤¾ç¾¤æ¥çå©ç¨ Hugging Face ç­è¨ç®¡ä¸­ä»æ©æ§æä¾ç¨æ¶ä¸å³çæ¨¡ååè¨ç·´è³æçç°¡æå­åæ¬éãéäºæ¨¡åå¸ééä½äºæ¸åè¬åç¨æ¶çæè¡é¨ç½²éç¤ï¼ä½å¯è½æè¢«ç¨æ¼è¨±å¤æ½å¨æå®³åéæ³çæ¹å¼ãå¨æ¬æä¸­ï¼æåèªªæ AI ç³»çµ±æ¢å¯ä»¥ãåå«ãå§å®¹ï¼åå¯ä»¥ä½çºéæ¾å¼å·¥å·ï¼éæåºäºè¿ä»çºæ­¢ææ£æçå¹³å°æ²»çææ°ä¹ä¸ãæåæä¾ Hugging FaceãGitHub å Civitai ç­ä¸åèªªææ§å¹³å°ä¸æ¸èµ·äºä»¶çæ¡ä¾ç ç©¶ï¼ä»¥æª¢è¦æ¨¡åå¸éå¦ä½å¯©æ ¸æ¨¡åãæ ¹ææ­¤åæï¼æåæ¦è¿°ç¢æ¥­çºåæå¯©æ ¸éæ±èéç¼çéè¦ï¼ä½ä»æéï¼å¯¦åï¼ææ¬ãå­ååä½¿ç¨éå¶ãèªååå§å®¹å¯©æ ¸åéæ¾æ¿ç­å¶å®ãéç¶ç¶åæ¿ç­ææ°ç¸ç¶å¯è§ï¼æåæå¾æåºä¸äºæ§æ³ï¼èªªæå¹³å°å¦ä½è½æ´å¥½å°åå¡è³æºï¼ä½çºè¬¹æãå¬å¹³ä¸é©åº¦çæ³è¦å­åé»ã

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

æè¦ï¼<paragraph>èæ¯åç®æ¨ï¼ééæåéäºè³è¨ï¼æ©å¨ææ·±åº¦å­¸ç¿ (ML/DL) åºæ¼èªä¸»æ¸æåæå·¥å·å¯ä»¥åå©è¨åºé«çåççç ç©¶äººå¡å¾è¤éçæ¸æéä¸­ç¼ç¾æ¨¡å¼åéä¿ãæè¿å·²ç¼è¡¨è¨±å¤åºæ¼ DL çåµå·¢ç (OC) æ¸æåæãéäºåæå¨çççååæ¹é¢ï¼ä¾å¦ï¼å®åæ¶åçå­é ååççé¡åï¼åæ¸æåæåè½æ¹é¢é«åº¦å¤æ¨£åãç¶èï¼ç®åç¼ºä¹å°éäºåæå¨éäºç¹å¾µå AI ä¿è­ (AIA) æ¹é¢çå¨é¢çè§£ãéç¯ç³»çµ±æ§åé¡§æ¨å¨ééæª¢è¦ç¾ææç»ä¸¦æç¢ºéæ³¨ééµç¹å¾µå AI ä¿è­è§é»ï¼ä¾å¡«è£éåç©ºç½ãæ¹æ³ï¼ä½¿ç¨ PRISMA æ¶æ§å¨ä¸åæåè³æåº«ä¸­é²è¡å¨é¢æå°ãåæååæ¬ 2015 å¹´è³ 2023 å¹´éç¼è¡¨æ¼åè¡è©å¯©æåçç ç©¶ãçµæï¼å¨åé¡§ä¸­ï¼ç¸½å±æª¢è¦äº 96 é ç± DL é©åçåæãç ç©¶çµææ­ç¤ºäºå¹¾åéæ¼ç± DL é©åçåµå·¢çæ¸æåæçéè¦è¦è§£ï¼- å¤§å¤æ¸ç ç©¶ 71%ï¼96 é ä¸­æ 68 é ï¼å°æ³¨æ¼æª¢æ¸¬åè¨ºæ·ï¼èæ²æç ç©¶æ¢è¨ OC çé æ¸¬åé é²ã- éäºåæä¸»è¦åºæ¼ä¾èªéå¤åæç¾¤çæ¨£æ¬ï¼75%ï¼96 é ç ç©¶ä¸­ç 72 é ï¼ï¼ï¼åéæ¼æåå°çä½ç½®æåå®¶ã- åªæå°é¨åç ç©¶ï¼å 33%ï¼96 é ç ç©¶ä¸­ç 32 é ï¼å·è¡æ´ååæï¼å¶ä¸­å¤§å¤æ¸ä½¿ç¨åè³ªæ¸æï¼è¨åºæçµå­¸ï¼ã- å¼å¾æ³¨æçæ¯ï¼åªæ 8.3%ï¼96 é ç ç©¶ä¸­ç 8 é ï¼ä½¿ç¨å¤é¨åå¤åæ¸æéé©è­äºå¶æ¨¡åï¼å¼·èª¿äºå å¼·æ¨¡åé©è­çå¿è¦æ§ï¼ä»¥å- å° AIA ç´å¥ççæ¸æåæä»èæ¼éå¸¸æ©æçéæ®µï¼åªæ 2.1%ï¼96 é ç ç©¶ä¸­ç 2 é ï¼ééå¯è§£éæ§æç¢ºæ¢è¨äº AIAã</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

æè¦ï¼<paragraph>è§£éæ§æ¯æ·±åº¦å­¸ç¿ä¸­é·æçææ°ï¼ç¹å¥æ¯å¨é«çä¿å¥ç­é«é¢¨éªé åãå¸¸è¦çè§£éæ§æ¹æ³æå¼·èª¿é©å AI æ¨¡åæ±ºç­çå½±åååãç¶èï¼äººé¡å¾å¤§ç¨åº¦ä¾è³´èªè¨ä¾å³éä¸åæ¯ãå¨åªè£¡ãï¼éæãæ¯ä»éº¼ãçè§£éãæ­¤å¤ï¼å¤§å¤æ¸è§£éæ§æ¹æ³é½å°æ³¨æ¼è§£éåå¥ AI é æ¸¬ï¼èä¸æ¯æè¿° AI æ¨¡åä¸è¬ä½¿ç¨çç¹å¾µãå¾èå°æ¼æ¨¡ååè³æéç¨½æ ¸ç¹å¥æç¨ï¼çè³å¯è½å¨ AI æä¾æç¨æ¼æ°ç©ä»»åæç¢çç¥è­ãå¨æ­¤ï¼æåæåºä¸åä½¿ç¨è¦è¦ºèªè¨æ¨¡åä¾è¾¨è­è¦è¦ºåé¡ä»»åçèªè¨æè¿°ç¬¦çè§£éæ§ç­ç¥ãééå©ç¨å½±ååæå­ä¹éé åè¨ç·´çè¯ååµå¥ç©ºéï¼æåçåæ³å°æ°çåé¡ä»»åä¼°è¨çºä¸åç·æ§æå­çµåï¼å°è´æ¯åæå­é½ææ¬éï¼è¡¨ç¤ºå®èåºæ¼è¦è¦ºçåé¡å¨å°é½ãæåä½¿ç¨å©åé«å­¸å½±ååé¡ä»»åä¾è©ä¼°æåçåæ³ï¼æåç¼ç¾ç¢ççæè¿°ç¬¦å¨å¾å¤§ç¨åº¦ä¸èè¨åºç¥è­ä¸è´ï¼åç®¡ç¼ºä¹ç¹å®é åçèªè¨è¨ç·´ãç¶èï¼æåçåæ³ä¹ç¼ç¾äºæç¨å¬éè³æéä¸­çãæ·å¾é£ç·ãçå¯è½æ§ãçºäºéå°è§£éæ§çåè½æ§è¡¡éï¼æåé²è¡äºä¸é è©¦é©è®èç ç©¶ï¼ç¼ç¾ AI è­å¥çæå­è½è®éå°å®¶äººé¡å¨éå¹³å¡çå±¤ç´å·è¡å°æ¥­çé«çä»»åãç¸½ä¹ï¼æåççµæå¼·èª¿äºä½¿ç¨å¤æ¨¡å¼åºç¤æ¨¡åä¾æä¾ç´è§çãåºæ¼èªè¨çè¦è¦ºä»»åè§£éçæ½åã</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

æè¦ï¼<paragraph>ä½¿ç¨é«çå½±åè¨ç·´çäººå·¥æºæ§ (AI) æ¨¡åï¼ç¨æ¼è¨åºä»»åæï¼å¸¸æå¨æè½ä¸å±ç¾åºæ¬¡ç¾¤é«ä¹éçå·®ç°ï¼å½¢æåè¦ãç±æ¼ä¸¦éææçå¯¦ä¸çé«çå½±åè³æä¸­çåè¦ä¾æºé½å®¹æè¾¨è­ï¼å æ­¤å¨é¢è©ä¼°éäºåè¦æ¯å¦ä½ç·¨ç¢¼å°æ¨¡åä¸­ï¼ä»¥ååè¦ç·©è§£æ¹æ³å¨æ¹åæè½å·®ç°æ¹é¢çè½åï¼æ¯ä¸é ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åæ°ç©çåææ¶æ§ï¼ç¨æ¼ç³»çµ±åä¸å®¢è§å°èª¿æ¥é«çå½±åä¸­çåè¦å° AI æ¨¡åçå½±é¿ãæåéç¼ä¸¦æ¸¬è©¦äºéåæ¶æ§ï¼ä»¥é²è¡åæ§çé»è¦æ¨¡æ¬è©¦é©ï¼ä½¿ç¨ä¸åå·¥å·ä¾è©ä¼°é«çå½±å AI ä¸­çåè¦ï¼è©²å·¥å·ç¨æ¼ç¢çå·æå·²ç¥ç¾çå½±é¿ååè¦ä¾æºçåæç£å±æ¯å½±åãå¯è¡æ§ééä½¿ç¨ä¸ååäºå¯¦åè¦æå¢ä¾è¡¡éæ¨¡æ¬åè¦ææå°å·ç©ç¥ç¶ç¶²è·¯ (CNN) åé¡å¨åä¸ååè¦ç·©è§£ç­ç¥çå½±é¿ï¼ä¸¦å±ç¤ºåºä¾ãåæé¡¯ç¤ºï¼ç¶ CNN å¨åæè³æéä¸åè¨æï¼æ¨¡æ¬åè¦æå°è´é æçæ¬¡ç¾¤é«æè½å·®ç°ãæ­¤å¤ï¼éæ°å æ¬è¢«èªçºæ¯æ­¤è¨­å®ä¸­ææåçåè¦ç·©è§£ç­ç¥ï¼æåå±ç¤ºäºè§£éæ§ AI æ¹æ³å¦ä½åå©ä½¿ç¨éåæ¶æ§èª¿æ¥æ¨¡åä¸­åè¦çè¡¨ç¾ãéç¼å¬å¹³ç AI æ¨¡åæ¯ä¸é éå¤§çææ°ï¼å çºé«çå½±åè³æéä¸­å¯è½å­å¨è¨±å¤ä¸ç¶å¸¸æªç¥çåè¦ä¾æºãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼å®¢è§å°ç ç©¶åè¦åç·©è§£ç­ç¥å°æ·±åº¦å­¸ç¿ç®¡ç·çå½±é¿ï¼éå¯ä»¥æ¯æ´å¥å¨ä¸è² è²¬ä»»çè¨åº AI çéç¼ã</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

æè¦ï¼æ©å¨å­¸ç¿çºèªåé æ¸¬ä¸­é¢¨å¾ççåå¶å°å¾©å¥çåææä¾äºæ¥µå¤§çæ½åãéé å·¥ä½çéå¤§ææ°åæ¬ç¥ç¶å½±åè³æçç¶­åº¦éå¸¸é«ãå¯ç¨æ¼å­¸ç¿çè³æéè¦æ¨¡ç¸å°è¼å°ï¼ä»¥åå¦ä½ææçµåç¥ç¶å½±ååè¡¨æ ¼è³æï¼ä¾å¦äººå£çµ±è¨è³è¨åè¨åºç¹å¾µï¼ãæ¬ææ ¹æå©ç¨®ç­ç¥è©ä¼°äºå¤ç¨®è§£æ±ºæ¹æ¡ãç¬¬ä¸ç¨®æ¯ä½¿ç¨ç¸½çµ MRI ææç 2D å½±åãç¬¬äºç¨®æ¯é¸ææå©æ¼æé«åé¡ç²¾ç¢ºåº¦çééµç¹å¾µãæ­¤å¤ï¼æåå¼å¥äºå¨çµåå¾ MRI ä¸­æåçæèè¶£ååèè¡¨æ ¼è³æçç¬¦èè¡¨ç¤ºçå½±åä¸è¨ç·´å·ç©ç¥ç¶ç¶²è·¯ (CNN) çæ°ç©æ¹æ³ãæåè©ä¼°äºä¸ç³»å CNN æ¶æ§ï¼2D å 3Dï¼ï¼éäºæ¶æ§å¨ MRI åè¡¨æ ¼è³æçä¸åè¡¨ç¤ºä¸é²è¡è¨ç·´ï¼ä»¥é æ¸¬ä¸­é¢¨å¾å£è¿°åçæè¿°è½åçç¶åæ¸¬éæ¯å¦å¨å¤±èªçæéå¤±èªçç¯åå§ãMRI åè¡¨æ ¼è³æä¾èª 758 ååè PLORAS ç ç©¶çè±èªä¸­é¢¨åå­èãåéå°çç¶å¤§å°çåºç·éè¼¯è¿´æ­¸åé¡æºç¢ºåº¦çº 0.678ï¼ç¶ä¾åºå å¥åå§ççå´éç¨åº¦åæ¢å¾©æéæï¼ä¸åè³ 0.757 å 0.813ãå¨å¾æ¯å MRI ææä¸­æå 8 åæèè¶£ååä¸¦å¨ 2D æ®å·®ç¥ç¶ç¶²è·¯ä¸­èçç¶å¤§å°ãåå§å´éç¨åº¦åæ¢å¾©æéçµåæï¼è§å¯å°æé«çåé¡æºç¢ºåº¦ 0.854ãæåçç ç©¶çµæå±ç¤ºäºå¦ä½å°å½±ååè¡¨æ ¼è³æçµåèµ·ä¾ä»¥ç²å¾é«æ¼ä¸­é¢¨å¾åé¡æºç¢ºåº¦ï¼å³ä½¿å¨æ©å¨å­¸ç¿è¡èªä¸­è³æéå¾å°çææ³ä¸ä¹æ¯å¦æ­¤ãæå¾ï¼æåæåºå¦ä½æ¹é²ç®åçæ¨¡åï¼ä»¥ä½¿ç¨ä¾èªé«é¢ææåçå½±åä¾å¯¦ç¾æ´é«çæºç¢ºåº¦ã

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºèçä»»åééµæç¨ç¨å¼æçä¸é åºæ¬éæ±ï¼ç¢ºä¿æ¡ç¨é»ç AI æ¨¡åçéæåº¦åå¯è§£éæ§ãXAI çéè¦æ§æ¶µèå¾é«çä¿å¥å°éèçåç¨®é åï¼å¨éäºé åä¸­ï¼äºè§£æ·±åº¦å­¸ç¿æ¼ç®æ³çæ±ºç­å¶å®éç¨è³ééè¦ãå¤§å¤æ¸åºæ¼ AI çé»è¦è¦è¦ºæ¨¡åéå¸¸æ¯é»çå­ï¼å æ­¤ï¼å¨å½±åèçä¸­æä¾æ·±åº¦ç¥ç¶ç¶²è·¯çå¯è§£éæ§å°æ¼å¶å¨é«å­¸å½±ååæãèªåé§é§åéæ¸¬æç¨ä¸­çå»£æ³æ¡ç¨åé¨ç½²è³ééè¦ãæè¿ï¼å·²éå°å½±ååé¡ä»»åå¼å¥äºå¤ç¨® XAI æ¹æ³ãç¸åå°ï¼å½±ååå²å¨å¯è§£éæ§çèæ¯ä¸åå°çéæ³¨ç¸å°è¼å°ï¼åç®¡å®æ¯é»è¦è¦è¦ºæç¨ä¸­çä¸é åºæ¬ä»»åï¼ç¹å¥æ¯å¨éæ¸¬ä¸­ãåªæé¨åç ç©¶æåºç¨æ¼å½±ååå²çåºæ¼æ¢¯åº¦ç XAI æ¼ç®æ³ãæ¬ææ¹ç·¨äºæè¿çç¡æ¢¯åº¦ Sobol XAI æ¹æ³ä»¥é²è¡èªæåå²ãçºäºè¡¡é Sobol æ¹æ³å¨åå²ä¸­çæè½ï¼æåæåºäºä¸ç¨®åºæ¼å¯å­¸ç¿éè¨æ¨¡åçå®é XAI è©ä¼°æ¹æ³ãæ­¤æ¨¡åçä¸»è¦ç®çæ¯å¨è§£éåä¸èªç¼éè¨ï¼å¶ä¸­è¼é«çèªç¼éè¨è¡¨ç¤ºè¼ä½çæºç¢ºåº¦ï¼åä¹äº¦ç¶ãé²è¡åºæºåæä»¥è©ä¼°åæ¯è¼ä¸ç¨® XAI æ¹æ³çæè½ï¼åæ¬ Seg-Grad-CAMãSeg-Grad-CAM++ å Seg-Sobolï¼ä¸¦ä½¿ç¨ææåºçåºæ¼éè¨çè©ä¼°æè¡ãéæ§æäºä½¿ç¨é«è§£æåº¦è¡æå½±åå·è¡åè©ä¼° XAI æ¹æ³çé¦æ¬¡åè©¦ã

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

æè¦ï¼å¤§åèªè¨æ¨¡åå¨ç­æéå§å·²å¨å¤åé åä¸­å¤§éæ¿å¢ãç¶èï¼ç±æ¼äºå¯¦æ§ãé£è²«æ§åå¹»è¦ºç­åé¡ï¼é«çåä¿å¥é åå°å¶æ¡ç¨ç¶è±«ä¸æ±ºãéæ¼é«çä¿å¥çé«é¢¨éªæ§è³ªï¼è¨±å¤ç ç©¶äººå¡çè³è­¦åä¸è¦ä½¿ç¨å®ï¼ç´å°éäºåé¡å¾å°è§£æ±ºãå¨é«çä¿å¥ä¸­å¯¦æ½åé¨ç½² LLM çééµæ¯ä½¿éäºæ¨¡åå¼å¾ä¿¡è³´ãéæï¼ç¡å¯è½å¤ï¼ä¸å¯è§£éãå¨æ¬æä¸­ï¼æåæè¿°äºå»ºç«å¯é ãå¼å¾ä¿¡è³´åç¡åè¦æ¨¡åçééµè¦ç´ ï¼ä½çºå®åå¨é«çä¿å¥ä¸­å¾å°æ¡ç¨çå¿è¦æ¢ä»¶ãå·é«ä¾èªªï¼æåå°æ³¨æ¼å¨é«çä¿å¥èæ¯ä¸å°å¹»è¦ºé²è¡éåãé©è­åç·©è§£ãæå¾ï¼æåè¨è«äº LLM å¨é«çä¿å¥ä¸­çæªä¾å¯è½æ¯ä»éº¼æ¨£å­ã


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-15**|**VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**|Daniel Ekpo et.al.|[2411.10446v1](http://arxiv.org/abs/2411.10446v1)|null|
|**2024-11-15**|**A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**|Zefan Zeng et.al.|[2411.10371v1](http://arxiv.org/abs/2411.10371v1)|null|
|**2024-11-15**|**Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**|Md. Asif Haider et.al.|[2411.10129v1](http://arxiv.org/abs/2411.10129v1)|null|
|**2024-11-15**|**HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**|Yifan Zeng et.al.|[2411.09978v1](http://arxiv.org/abs/2411.09978v1)|null|
|**2024-11-14**|**Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**|Cogan Shimizu et.al.|[2411.09601v1](http://arxiv.org/abs/2411.09601v1)|null|
|**2024-11-14**|**Automating Reformulation of Essence Specifications via Graph Rewriting**|Ian Miguel et.al.|[2411.09576v1](http://arxiv.org/abs/2411.09576v1)|null|
|**2024-11-13**|**Towards Evaluating Large Language Models for Graph Query Generation**|Siraj Munir et.al.|[2411.08449v1](http://arxiv.org/abs/2411.08449v1)|null|
|**2024-11-13**|**Knowledge Bases in Support of Large Language Models for Processing Web News**|Yihe Zhang et.al.|[2411.08278v2](http://arxiv.org/abs/2411.08278v2)|null|
|**2024-11-12**|**Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**|Muzhi Li et.al.|[2411.08165v1](http://arxiv.org/abs/2411.08165v1)|null|
|**2024-11-12**|**Language Models as Causal Effect Generators**|Lucius E. J. Bynum et.al.|[2411.08019v1](http://arxiv.org/abs/2411.08019v1)|[link](https://github.com/lbynum/sequence-driven-scms)|
|**2024-11-12**|**From General to Specific: Utilizing General Hallucation to Automatically Measure the Role Relationship Fidelity for Specific Role-Play Agents**|Chuyi Kong et.al.|[2411.07965v1](http://arxiv.org/abs/2411.07965v1)|null|
|**2024-11-12**|**Chain Association-based Attacking and Shielding Natural Language Processing Systems**|Jiacheng Huang et.al.|[2411.07843v1](http://arxiv.org/abs/2411.07843v1)|null|
|**2024-11-11**|**Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**|Yao Ma et.al.|[2411.07185v1](http://arxiv.org/abs/2411.07185v1)|null|
|**2024-11-11**|**A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**|Vedant Khandelwal et.al.|[2411.07163v1](http://arxiv.org/abs/2411.07163v1)|null|
|**2024-11-11**|**A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**|Myeongsoo Kim et.al.|[2411.07098v1](http://arxiv.org/abs/2411.07098v1)|null|
|**2024-11-11**|**Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**|Qiao Qiao et.al.|[2411.06660v1](http://arxiv.org/abs/2411.06660v1)|null|
|**2024-11-10**|**CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**|Shuqi Li et.al.|[2411.06391v1](http://arxiv.org/abs/2411.06391v1)|null|
|**2024-11-09**|**Analyzing the Evolution of Graphs and Texts**|Xingzhi Guo et.al.|[2411.06295v1](http://arxiv.org/abs/2411.06295v1)|null|
|**2024-11-09**|**An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**|Fatemeh Shiri et.al.|[2411.06048v1](http://arxiv.org/abs/2411.06048v1)|[link](https://github.com/fatemehshiri/spatial-mm)|
|**2024-11-08**|**Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine**|Anantha Sharma et.al.|[2411.05936v1](http://arxiv.org/abs/2411.05936v1)|null|
|**2024-11-08**|**SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**|Sithursan Sivasubramaniam et.al.|[2411.05521v2](http://arxiv.org/abs/2411.05521v2)|[link](https://github.com/jf87/sm3-text-to-query)|
|**2024-11-08**|**EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**|Abdoul Nasser Hassane Amadou et.al.|[2411.05479v1](http://arxiv.org/abs/2411.05479v1)|[link](https://github.com/jumbo110/eurekha)|
|**2024-11-08**|**When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization**|Jacob Nielsen et.al.|[2411.05882v1](http://arxiv.org/abs/2411.05882v1)|null|
|**2024-11-08**|**Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**|Dong Shu et.al.|[2411.05316v1](http://arxiv.org/abs/2411.05316v1)|[link](https://github.com/tizzzzy/llm-gdm-alignment)|
|**2024-11-06**|**LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration**|Yukun Cao et.al.|[2411.05844v1](http://arxiv.org/abs/2411.05844v1)|null|
|**2024-11-06**|**MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**|Laura Cabello et.al.|[2411.03883v2](http://arxiv.org/abs/2411.03883v2)|[link](https://github.com/lautel/meg)|
|**2024-11-06**|**The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**|Lee Kezar et.al.|[2411.03568v1](http://arxiv.org/abs/2411.03568v1)|null|
|**2024-11-05**|**Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**|Tao Zhang et.al.|[2411.02864v1](http://arxiv.org/abs/2411.02864v1)|null|
|**2024-11-05**|**Multimodal Commonsense Knowledge Distillation for Visual Question Answering**|Shuo Yang et.al.|[2411.02722v1](http://arxiv.org/abs/2411.02722v1)|null|
|**2024-11-04**|**Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**|Harshavardhana T. Gowda et.al.|[2411.02591v2](http://arxiv.org/abs/2411.02591v2)|[link](https://github.com/HarshavardhanaTG/geometryOfOrofacialNeuromuscularSystem)|
|**2024-11-04**|**GraphXAIN: Narratives to Explain Graph Neural Networks**|Mateusz Cedro et.al.|[2411.02540v2](http://arxiv.org/abs/2411.02540v2)|[link](https://github.com/ADMAntwerp/GraphXAIN)|
|**2024-11-04**|**Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**|Guangzhi Xiong et.al.|[2411.02382v1](http://arxiv.org/abs/2411.02382v1)|null|
|**2024-11-04**|**QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain**|Qikai Wei et.al.|[2411.08724v1](http://arxiv.org/abs/2411.08724v1)|null|
|**2024-11-04**|**Can Language Models Enable In-Context Database?**|Yu Pan et.al.|[2411.01807v1](http://arxiv.org/abs/2411.01807v1)|null|
|**2024-11-03**|**Graph-based Confidence Calibration for Large Language Models**|Yukun Li et.al.|[2411.02454v1](http://arxiv.org/abs/2411.02454v1)|null|
|**2024-11-03**|**Ontology Population using LLMs**|Sanaz Saki Norouzi et.al.|[2411.01612v1](http://arxiv.org/abs/2411.01612v1)|null|
|**2024-11-03**|**Pre-trained Molecular Language Models with Random Functional Group Masking**|Tianhao Peng et.al.|[2411.01401v1](http://arxiv.org/abs/2411.01401v1)|null|
|**2024-11-01**|**Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models**|Xinyi Leng et.al.|[2411.02435v1](http://arxiv.org/abs/2411.02435v1)|null|
|**2024-11-01**|**WLPlan: Relational Features for Symbolic Planning**|Dillon Z. Chen et.al.|[2411.00577v1](http://arxiv.org/abs/2411.00577v1)|null|
|**2024-11-01**|**GRS-QA -- Graph Reasoning-Structured Question Answering Dataset**|Anish Pahilajani et.al.|[2411.00369v3](http://arxiv.org/abs/2411.00369v3)|null|
|**2024-11-01**|**Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**|Balu Bhasuran et.al.|[2411.02523v1](http://arxiv.org/abs/2411.02523v1)|null|
|**2024-10-31**|**Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning**|Beyazit Yalcinkaya et.al.|[2411.00205v1](http://arxiv.org/abs/2411.00205v1)|null|
|**2024-10-31**|**Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis**|Yu Pan et.al.|[2411.00188v1](http://arxiv.org/abs/2411.00188v1)|null|
|**2024-10-31**|**Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models**|Phil Wee et.al.|[2411.00878v1](http://arxiv.org/abs/2411.00878v1)|null|
|**2024-10-31**|**Failure Modes of LLMs for Causal Reasoning on Narratives**|Khurram Yamin et.al.|[2410.23884v1](http://arxiv.org/abs/2410.23884v1)|[link](https://github.com/shantanu95/llm_causal_reasoning)|
|**2024-10-31**|**Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs**|Liyi Chen et.al.|[2410.23875v1](http://arxiv.org/abs/2410.23875v1)|[link](https://github.com/liyichen-cly/pog)|
|**2024-10-31**|**LLaMo: Large Language Model-based Molecular Graph Assistant**|Jinyoung Park et.al.|[2411.00871v1](http://arxiv.org/abs/2411.00871v1)|[link](https://github.com/mlvlab/llamo)|
|**2024-10-31**|**End-to-End Ontology Learning with Large Language Models**|Andy Lo et.al.|[2410.23584v1](http://arxiv.org/abs/2410.23584v1)|[link](https://github.com/andylolu2/ollm)|
|**2024-10-30**|**Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document**|Vicky Dong et.al.|[2410.23452v1](http://arxiv.org/abs/2410.23452v1)|null|
|**2024-10-30**|**FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions**|Anuroop Sriram et.al.|[2410.23405v1](http://arxiv.org/abs/2410.23405v1)|[link](https://github.com/facebookresearch/flowmm)|
|**2024-10-30**|**EMMA: End-to-End Multimodal Model for Autonomous Driving**|Jyh-Jing Hwang et.al.|[2410.23262v2](http://arxiv.org/abs/2410.23262v2)|null|
|**2024-10-30**|**ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**|Zhichao Hou et.al.|[2410.23182v1](http://arxiv.org/abs/2410.23182v1)|null|
|**2024-10-30**|**Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**|Deperias Kerre et.al.|[2410.22996v1](http://arxiv.org/abs/2410.22996v1)|null|
|**2024-10-30**|**How Well Do Large Language Models Disambiguate Swedish Words?**|Richard Johansson et.al.|[2410.22827v1](http://arxiv.org/abs/2410.22827v1)|null|
|**2024-10-30**|**Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**|Sejin Lee et.al.|[2410.22767v1](http://arxiv.org/abs/2410.22767v1)|[link](https://github.com/eastha0526/beyond-ontology-in-dst)|
|**2024-10-30**|**The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation**|Reza Moravej et.al.|[2411.00843v1](http://arxiv.org/abs/2411.00843v1)|null|
|**2024-10-29**|**Are Large-Language Models Graph Algorithmic Reasoners?**|Alexander K Taylor et.al.|[2410.22597v1](http://arxiv.org/abs/2410.22597v1)|[link](https://github.com/ataylor24/magma)|
|**2024-10-29**|**Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset**|Adrian Garret Gabriel et.al.|[2410.22457v1](http://arxiv.org/abs/2410.22457v1)|null|
|**2024-10-29**|**DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models**|Chengke Zou et.al.|[2411.00836v1](http://arxiv.org/abs/2411.00836v1)|null|
|**2024-10-29**|**ADAM: An Embodied Causal Agent in Open-World Environments**|Shu Yu et.al.|[2410.22194v1](http://arxiv.org/abs/2410.22194v1)|null|
|**2024-10-29**|**GraphAide: Advanced Graph-Assisted Query and Reasoning System**|Sumit Purohit et.al.|[2411.08041v1](http://arxiv.org/abs/2411.08041v1)|null|
|**2024-10-29**|**Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN**|Zhilun Zhou et.al.|[2411.00028v1](http://arxiv.org/abs/2411.00028v1)|null|
|**2024-10-29**|**A Hierarchical Language Model For Interpretable Graph Reasoning**|Sambhav Khurana et.al.|[2410.22372v1](http://arxiv.org/abs/2410.22372v1)|null|
|**2024-10-28**|**LLM-Forest for Health Tabular Data Imputation**|Xinrui He et.al.|[2410.21520v1](http://arxiv.org/abs/2410.21520v1)|null|
|**2024-10-28**|**Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**|Zhantao Yang et.al.|[2410.21237v1](http://arxiv.org/abs/2410.21237v1)|null|
|**2024-10-28**|**CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**|Meiqi Chen et.al.|[2410.21067v1](http://arxiv.org/abs/2410.21067v1)|null|
|**2024-10-28**|**CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**|Yutong Cheng et.al.|[2410.21060v1](http://arxiv.org/abs/2410.21060v1)|null|
|**2024-10-28**|**Graph-based Uncertainty Metrics for Long-form Language Model Outputs**|Mingjian Jiang et.al.|[2410.20783v1](http://arxiv.org/abs/2410.20783v1)|[link](https://github.com/mingjianjiang-1/graph-based-uncertainty)|
|**2024-10-28**|**Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**|Prakhar Verma et.al.|[2410.20753v1](http://arxiv.org/abs/2410.20753v1)|null|
|**2024-10-28**|**Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**|Mufei Li et.al.|[2410.20724v2](http://arxiv.org/abs/2410.20724v2)|[link](https://github.com/graph-com/subgraphrag)|
|**2024-10-27**|**Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs**|Xingrui Zhuo et.al.|[2410.20321v1](http://arxiv.org/abs/2410.20321v1)|null|
|**2024-10-26**|**Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts**|Vishesh Prasad et.al.|[2410.21324v1](http://arxiv.org/abs/2410.21324v1)|null|
|**2024-10-25**|**DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**|Pengfei Hu et.al.|[2410.19955v1](http://arxiv.org/abs/2410.19955v1)|null|
|**2024-10-25**|**FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**|Nicole Cho et.al.|[2410.19727v1](http://arxiv.org/abs/2410.19727v1)|null|
|**2024-10-25**|**Knowledge Graph Enhanced Language Agents for Recommendation**|Taicheng Guo et.al.|[2410.19627v1](http://arxiv.org/abs/2410.19627v1)|null|
|**2024-10-25**|**Graph Linearization Methods for Reasoning on Graphs with Large Language Models**|Christos Xypolopoulos et.al.|[2410.19494v1](http://arxiv.org/abs/2410.19494v1)|null|
|**2024-10-25**|**Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis**|Weikai Li et.al.|[2410.19225v1](http://arxiv.org/abs/2410.19225v1)|null|
|**2024-10-24**|**Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media**|Bruno Croso Cunha da Silva et.al.|[2410.19193v1](http://arxiv.org/abs/2410.19193v1)|null|
|**2024-10-24**|**GCoder: Improving Large Language Model for Generalized Graph Problem Solving**|Qifan Zhang et.al.|[2410.19084v1](http://arxiv.org/abs/2410.19084v1)|[link](https://github.com/bklight999/www25-gcoder)|
|**2024-10-24**|**LLM-based Online Prediction of Time-varying Graph Signals**|Dayu Qin et.al.|[2410.18718v1](http://arxiv.org/abs/2410.18718v1)|null|
|**2024-10-24**|**Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production**|Kexuan Xin et.al.|[2410.18475v2](http://arxiv.org/abs/2410.18475v2)|null|
|**2024-10-24**|**ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**|Zezhong Wang et.al.|[2410.18447v1](http://arxiv.org/abs/2410.18447v1)|null|
|**2024-10-24**|**Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains**|Kun Li et.al.|[2410.18415v1](http://arxiv.org/abs/2410.18415v1)|null|
|**2024-10-23**|**Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**|Jaime Sevilla et.al.|[2410.18060v1](http://arxiv.org/abs/2410.18060v1)|null|
|**2024-10-23**|**Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective**|Rui Yang et.al.|[2410.17600v1](http://arxiv.org/abs/2410.17600v1)|null|
|**2024-10-23**|**Navigate Complex Physical Worlds via Geometrically Constrained LLM**|Yongqiang Huang et.al.|[2410.17529v1](http://arxiv.org/abs/2410.17529v1)|null|
|**2024-10-22**|**Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs**|Leyao Wang et.al.|[2410.16882v1](http://arxiv.org/abs/2410.16882v1)|null|
|**2024-10-22**|**Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning**|Muzhi Li et.al.|[2410.16803v2](http://arxiv.org/abs/2410.16803v2)|null|
|**2024-10-22**|**The Scene Language: Representing Scenes with Programs, Words, and Embeddings**|Yunzhi Zhang et.al.|[2410.16770v1](http://arxiv.org/abs/2410.16770v1)|null|
|**2024-10-22**|**Atomic Fact Decomposition Helps Attributed Question Answering**|Zhichao Yan et.al.|[2410.16708v1](http://arxiv.org/abs/2410.16708v1)|null|
|**2024-10-22**|**PLDR-LLM: Large Language Model from Power Law Decoder Representations**|Burc Gokden et.al.|[2410.16703v1](http://arxiv.org/abs/2410.16703v1)|[link](https://github.com/burcgokden/llm-from-power-law-decoder-representations)|
|**2024-10-22**|**Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for Improved Coverage and Efficiency**|Prafulla Kumar Choubey et.al.|[2410.16597v1](http://arxiv.org/abs/2410.16597v1)|null|
|**2024-10-21**|**Towards a Reliable Offline Personal AI Assistant for Long Duration Spaceflight**|Oliver Bensch et.al.|[2410.16397v1](http://arxiv.org/abs/2410.16397v1)|null|
|**2024-10-21**|**A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns**|Tianyi Men et.al.|[2410.16155v1](http://arxiv.org/abs/2410.16155v1)|null|
|**2024-10-21**|**CausalGraph2LLM: Evaluating LLMs for Causal Queries**|Ivaxi Sheth et.al.|[2410.15939v1](http://arxiv.org/abs/2410.15939v1)|[link](https://github.com/ivaxi0s/causalgraph2llm)|
|**2024-10-21**|**LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation**|Tejumade Afonja et.al.|[2410.15828v1](http://arxiv.org/abs/2410.15828v1)|null|
|**2024-10-21**|**NetSafe: Exploring the Topological Safety of Multi-agent Networks**|Miao Yu et.al.|[2410.15686v1](http://arxiv.org/abs/2410.15686v1)|null|
|**2024-10-20**|**TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models**|Bo Pan et.al.|[2410.15268v1](http://arxiv.org/abs/2410.15268v1)|null|
|**2024-10-19**|**Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction**|Yinhan He et.al.|[2410.15165v1](http://arxiv.org/abs/2410.15165v1)|null|
|**2024-10-19**|**MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science**|Junho Kim et.al.|[2410.15126v1](http://arxiv.org/abs/2410.15126v1)|null|

#### Abstracts
##### **VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**
2411.10446v1 by Daniel Ekpo, Mara Levy, Saksham Suri, Chuong Huynh, Abhinav Shrivastava

Recent advancements in vision-language models (VLMs) offer potential for
robot task planning, but challenges remain due to VLMs' tendency to generate
incorrect action sequences. To address these limitations, we propose VeriGraph,
a novel framework that integrates VLMs for robotic planning while verifying
action feasibility. VeriGraph employs scene graphs as an intermediate
representation, capturing key objects and spatial relationships to improve plan
verification and refinement. The system generates a scene graph from input
images and uses it to iteratively check and correct action sequences generated
by an LLM-based task planner, ensuring constraints are respected and actions
are executable. Our approach significantly enhances task completion rates
across diverse manipulation scenarios, outperforming baseline methods by 58%
for language-based tasks and 30% for image-based tasks.

æè¦ï¼æè¿å¨è¦è¦ºèªè¨æ¨¡å (VLM) çé²æ­¥çºæ©å¨äººä»»åè¦åæä¾äºå¯è½æ§ï¼ä½ç±æ¼ VLM å®¹æç¢çä¸æ­£ç¢ºçåä½åºåï¼å æ­¤ææ°ä»ç¶å­å¨ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº VeriGraphï¼ä¸åå° VLM æ´åå°æ©å¨äººè¦åä¸­çåµæ°æ¶æ§ï¼åæé©è­åä½çå¯è¡æ§ãVeriGraph ä½¿ç¨å ´æ¯åä½çºä¸­éè¡¨ç¤ºï¼ææééµç©ä»¶åç©ºééä¿ä»¥æ¹åè¨ç«é©è­åç²¾çãè©²ç³»çµ±å¾è¼¸å¥å½±åç¢çå ´æ¯åï¼ä¸¦ä½¿ç¨å®ä¾åè¦æª¢æ¥åä¿®æ­£ LLM åºæ¼ä»»åè¦åå¨ç¢ççåä½åºåï¼ç¢ºä¿ç¬¦åç´ææ¢ä»¶ä¸åä½å¯å·è¡ãæåçåæ³å¤§å¹æåäºåç¨®æä½å ´æ¯ä¸­çä»»åå®æçï¼å¨åºæ¼èªè¨çä»»åä¸­æ¯åºç·æ¹æ³é«åº 58%ï¼å¨åºæ¼å½±åçä»»åä¸­é«åº 30%ã

##### **A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**
2411.10371v1 by Zefan Zeng, Qing Cheng, Xingchen Hu, Yuehang Si, Zhong Liu

Event Causality Identification (ECI) has become a crucial task in Natural
Language Processing (NLP), aimed at automatically extracting causalities from
textual data. In this survey, we systematically address the foundational
principles, technical frameworks, and challenges of ECI, offering a
comprehensive taxonomy to categorize and clarify current research
methodologies, as well as a quantitative assessment of existing models. We
first establish a conceptual framework for ECI, outlining key definitions,
problem formulations, and evaluation standards. Our taxonomy classifies ECI
methods according to the two primary tasks of sentence-level (SECI) and
document-level (DECI) event causality identification. For SECI, we examine
feature pattern-based matching, deep semantic encoding, causal knowledge
pre-training and prompt-based fine-tuning, and external knowledge enhancement
methods. For DECI, we highlight approaches focused on event graph reasoning and
prompt-based techniques to address the complexity of cross-sentence causal
inference. Additionally, we analyze the strengths, limitations, and open
challenges of each approach. We further conduct an extensive quantitative
evaluation of various ECI methods on two benchmark datasets. Finally, we
explore future research directions, highlighting promising pathways to overcome
current limitations and broaden ECI applications.

æè¦ï¼äºä»¶å æéä¿è­å¥ï¼ECIï¼å·²æçºèªç¶èªè¨èçï¼NLPï¼ä¸­çä¸é ééµä»»åï¼æ¨å¨å¾ææ¬è³æä¸­èªåæåå æéä¿ãå¨æ¬æ¬¡èª¿æ¥ä¸­ï¼æåç³»çµ±æ§å°æ¢è¨ ECI çåºç¤åçãæè¡æ¡æ¶åææ°ï¼æä¾ä¸åå¨é¢çåé¡æ³ä¾åé¡åéæ¸ç¶åç ç©¶æ¹æ³ï¼ä»¥åå°ç¾ææ¨¡åé²è¡å®éè©ä¼°ãæåé¦åçº ECI å»ºç«ä¸åæ¦å¿µæ¡æ¶ï¼æ¦è¿°ééµå®ç¾©ãåé¡è¡¨è¿°åè©ä¼°æ¨æºãæåçåé¡æ³æ ¹æå¥å­å±¤ç´ï¼SECIï¼åæä»¶å±¤ç´ï¼DECIï¼äºä»¶å æéä¿è­å¥éå©åä¸»è¦ä»»åå° ECI æ¹æ³é²è¡åé¡ãå°æ¼ SECIï¼æåæ¢è¨åºæ¼ç¹å¾µæ¨¡å¼çå¹éãæ·±åº¦èªç¾©ç·¨ç¢¼ãå æç¥è­é è¨ç·´ååºæ¼æç¤ºçå¾®èª¿ï¼ä»¥åå¤é¨ç¥è­å¢å¼·æ¹æ³ãå°æ¼ DECIï¼æåéé»ä»ç´¹å°æ³¨æ¼äºä»¶åå½¢æ¨çååºæ¼æç¤ºçæè¡ï¼ä»¥è§£æ±ºè·¨å¥å­å ææ¨è«çè¤éæ§ãæ­¤å¤ï¼æååæäºæ¯ç¨®æ¹æ³çåªé»ãéå¶åéæ¾æ§ææ°ãæåé²ä¸æ­¥å°å©ç¨®åºæºè³æéä¸çåç¨® ECI æ¹æ³é²è¡å»£æ³çå®éè©ä¼°ãæå¾ï¼æåæ¢è¨æªä¾çç ç©¶æ¹åï¼éé»ä»ç´¹åæç¶åéå¶åæ´å± ECI æç¨ç¨å¼çæå¸æçéå¾ã

##### **Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**
2411.10129v1 by Md. Asif Haider, Ayesha Binte Mostofa, Sk. Sabit Bin Mosaddek, Anindya Iqbal, Toufique Ahmed

Generating accurate code review comments remains a significant challenge due
to the inherently diverse and non-unique nature of the task output. Large
language models pretrained on both programming and natural language data tend
to perform well in code-oriented tasks. However, large-scale pretraining is not
always feasible due to its environmental impact and project-specific
generalizability issues. In this work, first we fine-tune open-source Large
language models (LLM) in parameter-efficient, quantized low-rank (QLoRA)
fashion on consumer-grade hardware to improve review comment generation. Recent
studies demonstrate the efficacy of augmenting semantic metadata information
into prompts to boost performance in other code-related tasks. To explore this
in code review activities, we also prompt proprietary, closed-source LLMs
augmenting the input code patch with function call graphs and code summaries.
Both of our strategies improve the review comment generation performance, with
function call graph augmented few-shot prompting on the GPT-3.5 model
surpassing the pretrained baseline by around 90% BLEU-4 score on the
CodeReviewer dataset. Moreover, few-shot prompted Gemini-1.0 Pro, QLoRA
fine-tuned Code Llama and Llama 3.1 models achieve competitive results (ranging
from 25% to 83% performance improvement) on this task. An additional human
evaluation study further validates our experimental findings, reflecting
real-world developers' perceptions of LLM-generated code review comments based
on relevant qualitative metrics.

æè¦ï¼<paragraph>ç¢çæºç¢ºçç¨å¼ç¢¼å¯©æ¥è©è«ä»ç¶æ¯ä¸åéå¤§ææ°ï¼å çºä»»åè¼¸åºçæ¬è³ªä¸æ¯å¤æ¨£ä¸éç¨ç¹çãå¨ç¨å¼è¨­è¨åèªç¶èªè¨è³æä¸é²è¡é è¨ç·´çå¤§åèªè¨æ¨¡åå¾å¾å¨ä»¥ç¨å¼ç¢¼çºå°åçä»»åä¸­è¡¨ç¾è¯å¥½ãç¶èï¼ç±æ¼å¶å°ç°å¢çå½±é¿åå°æ¡ç¹å®çä¸è¬ååé¡ï¼å¤§è¦æ¨¡é è¨ç·´ä¸¦éç¸½æ¯å¯è¡çãå¨éé å·¥ä½ä¸­ï¼æåé¦åå¨åæ¸ææãéåçä½ç§© (QLoRA) æ¹å¼ä¸­å¾®èª¿éæºå¤§åèªè¨æ¨¡å (LLM)ï¼å¨æ¶è²»ç´ç¡¬é«ä¸æ¹åå¯©æ¥è©è«çç¢çãæè¿çç ç©¶è­æäºå¨æç¤ºä¸­å¢å èªç¾©åè³æè³è¨ä»¥æåå¶ä»èç¨å¼ç¢¼ç¸éä»»åä¸­æè½çåæãçºäºå¨ç¨å¼ç¢¼å¯©æ¥æ´»åä¸­æ¢ç´¢éä¸é»ï¼æåä¹æç¤ºå°æçãéæº LLMï¼ä½¿ç¨å½æ¸å¼å«ååç¨å¼ç¢¼æè¦ä¾å¢å è¼¸å¥ç¨å¼ç¢¼ä¿®è£ç¨å¼ãæåçå©ç¨®ç­ç¥é½æ¹åäºå¯©æ¥è©è«ç¢ççæè½ï¼å¨ GPT-3.5 æ¨¡åä¸ä½¿ç¨å½æ¸å¼å«åå¢å çå°éæç¤ºï¼å¨ CodeReviewer è³æéä¸è¶è¶äºé è¨ç·´åºæºï¼BLEU-4 åæ¸æé«äºç´ 90%ãæ­¤å¤ï¼å°éæç¤ºç Gemini-1.0 ProãQLoRA å¾®èª¿ç Code Llama å Llama 3.1 æ¨¡åå¨æ­¤ä»»åä¸éå°äºæç«¶ç­åççµæï¼æè½æåç¯åçº 25% è³ 83%ï¼ãé¡å¤çä½¿ç¨èè©ä¼°ç ç©¶é²ä¸æ­¥é©è­äºæåçå¯¦é©çµæï¼åæ äºå¯¦ééç¼äººå¡å° LLM ç¢ççç¨å¼ç¢¼å¯©æ¥è©è«ççæ³ï¼éäºçæ³åºæ¼ç¸éçå®æ§ææ¨ã</paragraph>

##### **HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**
2411.09978v1 by Yifan Zeng

This paper proposes HistoLens, a multi-layered analysis framework for
historical texts based on Large Language Models (LLMs). Using the important
Western Han dynasty text "Yantie Lun" as a case study, we demonstrate the
framework's potential applications in historical research and education.
HistoLens integrates NLP technology (especially LLMs), including named entity
recognition, knowledge graph construction, and geographic information
visualization. The paper showcases how HistoLens explores Western Han culture
in "Yantie Lun" through multi-dimensional, visual, and quantitative methods,
focusing particularly on the influence of Confucian and Legalist thoughts on
political, economic, military, and ethnic. We also demonstrate how HistoLens
constructs a machine teaching scenario using LLMs for explainable analysis,
based on a dataset of Confucian and Legalist ideas extracted with LLM
assistance. This approach offers novel and diverse perspectives for studying
historical texts like "Yantie Lun" and provides new auxiliary tools for history
education. The framework aims to equip historians and learners with
LLM-assisted tools to facilitate in-depth, multi-layered analysis of historical
texts and foster innovation in historical education.

æè¦ï¼æ¬ææåº HistoLensï¼ä¸ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çå¤å±¤åææ¶æ§ï¼ç¨æ¼æ­·å²ææ¬ãä½¿ç¨éè¦çè¥¿æ¼¢çæææ¬ãé¹½éµè«ãä½çºåæ¡ç ç©¶ï¼æåå±ç¤ºäºè©²æ¶æ§å¨æ­·å²ç ç©¶åæè²ä¸­çæ½å¨æç¨ãHistoLens æ´åäº NLP æè¡ï¼å°¤å¶æ¯ LLMï¼ï¼åæ¬å½åå¯¦é«è­å¥ãç¥è­åè­å»ºæ§åå°çè³è¨è¦è¦ºåãæ¬æå±ç¤ºäº HistoLens å¦ä½ééå¤ç¶­åº¦ãè¦è¦ºååéåæ¹æ³æ¢ç´¢ãé¹½éµè«ãä¸­çè¥¿æ¼¢æåï¼ç¹å¥éæ³¨åå®¶åæ³å®¶ææ³å°æ¿æ²»ãç¶æ¿ãè»äºåç¨®æçå½±é¿ãæåéå±ç¤ºäº HistoLens å¦ä½å»ºæ§ä¸åä½¿ç¨ LLM çæ©å¨æå­¸å ´æ¯ï¼ä»¥é²è¡å¯è§£éåæï¼éæ¯åºæ¼ LLM åå©æåçåå®¶åæ³å®¶ææ³è³æéãéç¨®æ¹æ³çºç ç©¶ãé¹½éµè«ãç­æ­·å²ææ¬æä¾äºæ°ç©ä¸å¤æ¨£åçè§é»ï¼ä¸¦çºæ­·å²æè²æä¾äºæ°çè¼å©å·¥å·ãè©²æ¶æ§æ¨å¨çºæ­·å²å­¸å®¶åå­¸ç¿èæä¾ LLM åå©çå·¥å·ï¼ä»¥å©æ¼æ·±å¥ãå¤å±¤æ¬¡å°åææ­·å²ææ¬ï¼ä¸¦ä¿é²æ­·å²æè²çåµæ°ã

##### **Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**
2411.09601v1 by Cogan Shimizu, Pascal Hitzler

Large Language Models bear the promise of significant acceleration of key
Knowledge Graph and Ontology Engineering tasks, including ontology modeling,
extension, modification, population, alignment, as well as entity
disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering
as a new and coming area of research, and argue that modular approaches to
ontologies will be of central importance.

æè¦ï¼å¤§åèªè¨æ¨¡åæ¿è«¾å¤§å¹å éééµç¥è­åè­åæ¬ä½å·¥ç¨ä»»åï¼åæ¬æ¬ä½å»ºæ¨¡ãæ´åãä¿®æ¹ãå¡«åãæ¯å°ä»¥åå¯¦é«æ¶æ­§ãæåå° LLM çºåºç¤çç¥è­åè­åæ¬ä½å·¥ç¨è¦åçºä¸åæ°èçç ç©¶é åï¼ä¸¦ä¸»å¼µæ¨¡çµåæ¬ä½æ¹æ³å°è³ééè¦ã

##### **Automating Reformulation of Essence Specifications via Graph Rewriting**
2411.09576v1 by Ian Miguel, AndrÃ¡s Z. Salamon, Christopher Stone

Formulating an effective constraint model of a parameterised problem class is
crucial to the efficiency with which instances of the class can subsequently be
solved. It is difficult to know beforehand which of a set of candidate models
will perform best in practice. This paper presents a system that employs graph
rewriting to reformulate an input model for improved performance automatically.
By situating our work in the Essence abstract constraint specification
language, we can use the structure in its high level variable types to trigger
rewrites directly. We implement our system via rewrite rules expressed in the
Graph Programs 2 language, applied to the abstract syntax tree of an input
specification. We show how to automatically translate the solution of the
reformulated problem into a solution of the original problem for verification
and presentation. We demonstrate the efficacy of our system with a detailed
case study.

æè¦ï¼å¶å®ä¸ååæ¸ååé¡é¡å¥çææç´ææ¨¡åå°æ¼é¨å¾æ±è§£è©²é¡å¥çå¯¦ä¾çæçè³ééè¦ãäºåå¾é£ç¥éä¸çµåé¸æ¨¡åä¸­åªä¸åå¨å¯¦åä¸è¡¨ç¾æä½³ãæ¬ææåºä¸åç³»çµ±ï¼æ¡ç¨åå½¢éå¯«ä¾èªåéæ°å¶å®è¼¸å¥æ¨¡åä»¥æ¹åæè½ãééå°æåçå·¥ä½ç½®æ¼ Essence æ½è±¡ç´æè¦ç¯èªè¨ä¸­ï¼æåå¯ä»¥ä½¿ç¨å¶é«å±¤ç´è®æ¸é¡åä¸­ççµæ§ä¾ç´æ¥è§¸ç¼éå¯«ãæåééä»¥ Graph Programs 2 èªè¨è¡¨ç¤ºçéå¯«è¦åä¾å¯¦ä½æåçç³»çµ±ï¼æç¨æ¼è¼¸å¥è¦ç¯çæ½è±¡èªæ³æ¨¹ãæåå±ç¤ºå¦ä½èªåå°éæ°å¶å®åé¡çè§£æ³è½æçºåå§åé¡çè§£æ³ï¼ä»¥é²è¡é©è­ååç¾ãæåééè©³ç´°çåæ¡ç ç©¶ä¾å±ç¤ºæåç³»çµ±çæè½ã

##### **Towards Evaluating Large Language Models for Graph Query Generation**
2411.08449v1 by Siraj Munir, Alessandro Aldini

Large Language Models (LLMs) are revolutionizing the landscape of Generative
Artificial Intelligence (GenAI), with innovative LLM-backed solutions emerging
rapidly. However, when applied to database technologies, specifically query
generation for graph databases and Knowledge Graphs (KGs), LLMs still face
significant challenges. While research on LLM-driven query generation for
Structured Query Language (SQL) exists, similar systems for graph databases
remain underdeveloped. This paper presents a comparative study addressing the
challenge of generating Cypher queries a powerful language for interacting with
graph databases using open-access LLMs. We rigorously evaluate several LLM
agents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a
locally deployed Llama 3.1 8B) using a designed few-shot learning prompt and
Retrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT)
reasoning. Our empirical analysis of query generation accuracy reveals that
Claude Sonnet 3.5 outperforms its counterparts in this specific domain.
Further, we highlight promising future research directions to address the
identified limitations and advance LLM-driven query generation for graph
databases.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£å¨é©æ°çæå¼äººå·¥æºè½ (GenAI) çæ ¼å±ï¼åµæ°ç LLM æ¯æè§£æ±ºæ¹æ¡è¿éæ¹§ç¾ãç¶èï¼ç¶æç¨æ¼è³æåº«æè¡ï¼ç¹å¥æ¯åå½¢è³æåº«åç¥è­åè­ (KG) çæ¥è©¢çææï¼LLM ä»é¢è¨éå¤§ææ°ãéç¶å­å¨éå°çµæ§åæ¥è©¢èªè¨ (SQL) ç LLM é©åæ¥è©¢çæçç¸éç ç©¶ï¼ä½åå½¢è³æåº«çé¡ä¼¼ç³»çµ±ä»æªå¾å°ååç¼å±ãæ¬ææåºäºä¸é æ¯è¼ç ç©¶ï¼ä»¥è§£æ±ºä½¿ç¨éæ¾å¼ LLM çæ Cypher æ¥è©¢çææ°ï¼Cypher æ¥è©¢æ¯ä¸ç¨®èåå½¢è³æåº«äºåçå¼·å¤§èªè¨ãæåä½¿ç¨è¨­è¨çå°æ¬¡å­¸ç¿æç¤ºåç±æèé (CoT) æ¨çæ¯æçæª¢ç´¢æ´å¢çæ (RAG) å´æ ¼è©ä¼°äºå¤å LLM ä»£çï¼OpenAI ChatGPT 4oãClaude Sonnet 3.5ãGoogle Gemini Pro 1.5 åæ¬å°é¨ç½²ç Llama 3.1 8Bï¼ãæåå°æ¥è©¢çææºç¢ºæ§çå¯¦è­åæè¡¨æï¼Claude Sonnet 3.5 å¨éåç¹å®é ååªæ¼å¶ä»æ¨¡åãæ­¤å¤ï¼æåéé»ä»ç´¹äºæå¸æçæªä¾ç ç©¶æ¹åï¼ä»¥è§£æ±ºå·²è­å¥çéå¶ä¸¦æ¨é² LLM é©åçåå½¢è³æåº«æ¥è©¢çæã

##### **Knowledge Bases in Support of Large Language Models for Processing Web News**
2411.08278v2 by Yihe Zhang, Nabin Pakka, Nian-Feng Tzeng

Large Language Models (LLMs) have received considerable interest in wide
applications lately. During pre-training via massive datasets, such a model
implicitly memorizes the factual knowledge of trained datasets in its hidden
parameters. However, knowledge held implicitly in parameters often makes its
use by downstream applications ineffective due to the lack of common-sense
reasoning. In this article, we introduce a general framework that permits to
build knowledge bases with an aid of LLMs, tailored for processing Web news.
The framework applies a rule-based News Information Extractor (NewsIE) to news
items for extracting their relational tuples, referred to as knowledge bases,
which are then graph-convoluted with the implicit knowledge facts of news items
obtained by LLMs, for their classification. It involves two lightweight
components: 1) NewsIE: for extracting the structural information of every news
item, in the form of relational tuples; 2) BERTGraph: for graph convoluting the
implicit knowledge facts with relational tuples extracted by NewsIE. We have
evaluated our framework under different news-related datasets for news category
classification, with promising experimental results.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿ä¾å¨å»£æ³çæç¨ä¸­ååéæ³¨ãå¨ééå¤§éè³æéé²è¡é è¨ç·´æéï¼æ­¤é¡æ¨¡åæé±å«å°å°è¨ç·´è³æéçäºå¯¦ç¥è­è¨æ¶å¨å¶é±èåæ¸ä¸­ãç¶èï¼é±å«å¨åæ¸ä¸­çç¥è­éå¸¸æå çºç¼ºä¹å¸¸è­æ¨çèå°è´ä¸æ¸¸æç¨ç¡æ³ææä½¿ç¨ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åéç¨æ¶æ§ï¼åè¨±å¨ LLM çåå©ä¸å»ºç«ç¥è­åº«ï¼å°éç¨æ¼èçç¶²è·¯æ°èãæ­¤æ¶æ§å°åºæ¼è¦åçæ°èè³è¨èåå¨ (NewsIE) å¥ç¨å°æ°èé ç®ï¼ä»¥èåå¶éä¿åçµï¼ç¨±çºç¥è­åº«ï¼ï¼ç¶å¾å°å¶è LLM åå¾çæ°èé ç®çé±å«ç¥è­äºå¯¦é²è¡åå½¢å·ç©ï¼ä»¥é²è¡åé¡ãå®åå«å©åè¼éç´åä»¶ï¼1) NewsIEï¼ç¨æ¼èåæ¯åæ°èé ç®ççµæ§åè³è¨ï¼ä»¥éä¿åçµçå½¢å¼åç¾ï¼2) BERTGraphï¼ç¨æ¼å° NewsIE èåçéä¿åçµèé±å«ç¥è­äºå¯¦é²è¡åå½¢å·ç©ãæåå·²å¨ä¸åçèæ°èç¸éçè³æéä¸è©ä¼°æåçæ¶æ§ï¼ç¨æ¼æ°èé¡å¥åé¡ï¼ä¸¦ç²å¾æå¸æçå¯¦é©çµæã

##### **Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**
2411.08165v1 by Muzhi Li, Cehao Yang, Chengjin Xu, Xuhui Jiang, Yiyan Qi, Jian Guo, Ho-fung Leung, Irwin King

The Knowledge Graph Completion~(KGC) task aims to infer the missing entity
from an incomplete triple. Existing embedding-based methods rely solely on
triples in the KG, which is vulnerable to specious relation patterns and
long-tail entities. On the other hand, text-based methods struggle with the
semantic gap between KG triples and natural language. Apart from triples,
entity contexts (e.g., labels, descriptions, aliases) also play a significant
role in augmenting KGs. To address these limitations, we propose KGR3, a
context-enriched framework for KGC. KGR3 is composed of three modules. Firstly,
the Retrieval module gathers supporting triples from the KG, collects plausible
candidate answers from a base embedding model, and retrieves context for each
related entity. Then, the Reasoning module employs a large language model to
generate potential answers for each query triple. Finally, the Re-ranking
module combines candidate answers from the two modules mentioned above, and
fine-tunes an LLM to provide the best answer. Extensive experiments on widely
used datasets demonstrate that KGR3 consistently improves various KGC methods.
Specifically, the best variant of KGR3 achieves absolute Hits@1 improvements of
12.3% and 5.6% on the FB15k237 and WN18RR datasets.

æè¦ï¼ç¥è­åè­å®æåè½ (KGC) çä»»åæ¨å¨å¾ä¸å®æ´ç 3 åçµä¸­æ¨æ·åºéºå¤±çå¯¦é«ãç¾æçåµå¥å¼æ¹æ³åä¾è³´æ¼ KG ä¸­ç 3 åçµï¼éå®¹æåå°èåéä¿æ¨¡å¼åé·å°¾å¯¦é«çå½±é¿ãå¦ä¸æ¹é¢ï¼åºæ¼ææ¬çæ¹æ³é£ä»¥èç KG 3 åçµåèªç¶èªè¨ä¹éçèªç¾©å·®è·ãé¤äº 3 åçµä¹å¤ï¼å¯¦é«ä¸ä¸æï¼ä¾å¦æ¨ç±¤ãæè¿°ãå¥åï¼å¨æ´å KG ä¸­ä¹æ®æ¼èéè¦çè§è²ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº KGR3ï¼ä¸åç¨æ¼ KGC çä¸ä¸æè±å¯æ¶æ§ãKGR3 ç±ä¸åæ¨¡çµçµæãé¦åï¼æª¢ç´¢æ¨¡çµå¾ KG ä¸­æ¶éæ¯æ´ 3 åçµï¼å¾åºç¤åµå¥æ¨¡åä¸­æ¶éå¯è½çåé¸ç­æ¡ï¼ä¸¦çºæ¯åç¸éå¯¦é«æª¢ç´¢ä¸ä¸æãæ¥èï¼æ¨çæ¨¡çµæ¡ç¨å¤§åèªè¨æ¨¡åçºæ¯åæ¥è©¢ 3 åçµçææ½å¨ç­æ¡ãæå¾ï¼éæ°æåæ¨¡çµå°ä¸è¿°å©åæ¨¡çµçåé¸ç­æ¡çµåèµ·ä¾ï¼ä¸¦å¾®èª¿ LLM ä»¥æä¾æä½³ç­æ¡ãå¨å»£æ³ä½¿ç¨çè³æéä¸é²è¡çå»£æ³å¯¦é©è­æï¼KGR3 æçºæ¹é²åç¨® KGC æ¹æ³ãå·é«ä¾èªªï¼KGR3 çæä½³è®é«å¨ FB15k237 å WN18RR è³æéä¸åå¥å¯¦ç¾äº 12.3% å 5.6% ççµå° Hits@1 æ¹é²ã

##### **Language Models as Causal Effect Generators**
2411.08019v1 by Lucius E. J. Bynum, Kyunghyun Cho

We present a framework for large language model (LLM) based data generation
with controllable causal structure. In particular, we define a procedure for
turning any language model and any directed acyclic graph (DAG) into a
sequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM
is a causal model with user-defined structure and LLM-defined structural
equations. We characterize how an SD-SCM allows sampling from observational,
interventional, and counterfactual distributions according to the desired
causal structure. We then leverage this procedure to propose a new type of
benchmark for causal inference methods, generating individual-level
counterfactual data without needing to manually specify functional
relationships between variables. We create an example benchmark consisting of
thousands of datasets, and test a suite of popular estimation methods on these
datasets for average, conditional average, and individual treatment effect
estimation, both with and without hidden confounding. Apart from generating
data, the same procedure also allows us to test for the presence of a causal
effect that might be encoded in an LLM. This procedure can underpin auditing
LLMs for misinformation, discrimination, or otherwise undesirable behavior. We
believe SD-SCMs can serve as a useful tool in any application that would
benefit from sequential data with controllable causal structure.

æè¦ï¼<paragraph>æåæåºäºä¸ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çè³æçææ¶æ§ï¼å·æå¯æ§å¶çå æçµæ§ãå·é«ä¾èªªï¼æåå®ç¾©äºä¸åç¨åºï¼å°ä»»ä½èªè¨æ¨¡ååä»»ä½æåç¡ç°å (DAG) è½ææä¸ååºåé©åççµæ§å ææ¨¡å (SD-SCM)ãå»£ç¾©ä¾èªªï¼SD-SCM æ¯ä¸åå ææ¨¡åï¼å·æä½¿ç¨èå®ç¾©ççµæ§å LLM å®ç¾©ççµæ§æ¹ç¨å¼ãæåæè¿°äº SD-SCM å¦ä½æ ¹ææéçå æçµæ§ï¼åè¨±å¾è§æ¸¬ãä»å¥ååäºå¯¦åä½ä¸­é²è¡æ½æ¨£ãç¶å¾ï¼æåå©ç¨éåç¨åºæåºäºä¸ç¨®é¡åçå ææ¨è«æ¹æ³åºæºï¼çæåé«å±¤ç´çåäºå¯¦è³æï¼èç¡éæåæå®è®æ¸ä¹éçåè½éä¿ãæåå»ºç«äºä¸åç¯ä¾åºæºï¼åå«æ¸ååè³æéï¼ä¸¦å¨éäºè³æéä¸æ¸¬è©¦äºä¸ç³»åæµè¡çä¼°è¨æ¹æ³ï¼ç¨æ¼å¹³åå¼ãæ¢ä»¶å¹³åå¼ååå¥èçææä¼°è¨ï¼ç¡è«æ¯æææ²æé±èæ··æ·ãé¤äºçæè³æä¹å¤ï¼ç¸åçç¨åºä¹åè¨±æåæ¸¬è©¦ LLM ä¸­å¯è½ç·¨ç¢¼çå æææçå­å¨ãæ­¤ç¨åºå¯ä»¥æ¯æå¯©æ ¸ LLM çé¯èª¤è³è¨ãæ­§è¦æå¶ä»ä¸è¯è¡çºãæåç¸ä¿¡ SD-SCM å¯ä»¥ä½çºä»»ä½æç¨ç¨å¼çæç¨å·¥å·ï¼éäºæç¨ç¨å¼å¯ä»¥å¾å·æå¯æ§å¶å æçµæ§çåºåè³æä¸­åçã</paragraph>

##### **From General to Specific: Utilizing General Hallucation to Automatically Measure the Role Relationship Fidelity for Specific Role-Play Agents**
2411.07965v1 by Chuyi Kong, Ziyang Luo, Hongzhan Lin, Zhiyuan Fan, Yaxin Fan, Yuxi Sun, Jing Ma

The advanced role-playing capabilities of Large Language Models (LLMs) have
paved the way for developing Role-Playing Agents (RPAs). However, existing
benchmarks, such as HPD, which incorporates manually scored character
relationships into the context for LLMs to sort coherence, and SocialBench,
which uses specific profiles generated by LLMs in the context of
multiple-choice tasks to assess character preferences, face limitations like
poor generalizability, implicit and inaccurate judgments, and excessive context
length. To address the above issues, we propose an automatic, scalable, and
generalizable paradigm. Specifically, we construct a benchmark by extracting
relations from a general knowledge graph and leverage RPA's inherent
hallucination properties to prompt it to interact across roles, employing
ChatGPT for stance detection and defining relationship hallucination along with
three related metrics. Extensive experiments validate the effectiveness and
stability of our metrics. Our findings further explore factors influencing
these metrics and discuss the trade-off between relationship hallucination and
factuality.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çåé²è§è²æ®æ¼è½åå·²çºéç¼è§è²æ®æ¼ä»£ç (RPA) éªå¹³éè·¯ãç¶èï¼ç¾æçåºæºï¼ä¾å¦ HPDï¼å°æåè©åçè§è²éä¿ç´å¥ LLM çèæ¯ä¸­ä»¥å°é£è²«æ§é²è¡æåºï¼ï¼ä»¥å SocialBenchï¼å¨å¤é¸é¡ä»»åçèæ¯ä¸ä½¿ç¨ LLM çæçç¹å®åäººè³æä¾è©ä¼°è§è²åå¥½ï¼é¢è¨èè«¸å¦éç¨æ§å·®ãå¤æ·å«èä¸ä¸æºç¢ºä»¥åèæ¯é·åº¦éé·ç­éå¶ãçºäºè§£æ±ºä¸è¿°åé¡ï¼æåæåºäºä¸åèªåãå¯æ´åä¸å¯æ¦æ¬çç¯ä¾ãå·é«ä¾èªªï¼æåééå¾éç¨ç¥è­åè­ä¸­æåéä¿ä¾æ§å»ºåºæºï¼ä¸¦å©ç¨ RPA åºæçå¹»è¦ºå±¬æ§æç¤ºå®è·¨è§è²äºåï¼æ¡ç¨ ChatGPT é²è¡ç«å ´æª¢æ¸¬ä¸¦å®ç¾©éä¿å¹»è¦ºä»¥åä¸åç¸éææ¨ãå»£æ³çå¯¦é©é©è­äºæåææ¨çæææ§åç©©å®æ§ãæåçç ç©¶çµæé²ä¸æ­¥æ¢è¨äºå½±é¿éäºææ¨çå ç´ ï¼ä¸¦è¨è«äºéä¿å¹»è¦ºåäºå¯¦æ§ä¹éçæ¬è¡¡ã

##### **Chain Association-based Attacking and Shielding Natural Language Processing Systems**
2411.07843v1 by Jiacheng Huang, Long Chen

Association as a gift enables people do not have to mention something in
completely straightforward words and allows others to understand what they
intend to refer to. In this paper, we propose a chain association-based
adversarial attack against natural language processing systems, utilizing the
comprehension gap between humans and machines. We first generate a chain
association graph for Chinese characters based on the association paradigm for
building search space of potential adversarial examples. Then, we introduce an
discrete particle swarm optimization algorithm to search for the optimal
adversarial examples. We conduct comprehensive experiments and show that
advanced natural language processing models and applications, including large
language models, are vulnerable to our attack, while humans appear good at
understanding the perturbed text. We also explore two methods, including
adversarial training and associative graph-based recovery, to shield systems
from chain association-based attack. Since a few examples that use some
derogatory terms, this paper contains materials that may be offensive or
upsetting to some people.

æè¦ï¼è¯æ³ä½çºä¸ç¨®ç¦®ç©ï¼ä½¿äººåä¸å¿ç¨å®å¨ç´ç½çè©±èªæåæäºï¼ä¸¦è®å¶ä»äººæç½ä»åæ³æçæ¯ä»éº¼ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼éå¼è¯æ³çå°ææ§æ»æï¼ç¨æ¼èªç¶èªè¨èçç³»çµ±ï¼å©ç¨äºäººé¡èæ©å¨ä¹éççè§£å·®è·ãæåé¦ååºæ¼è¯æ³ç¯ä¾çºæ¼¢å­çæä¸åéå¼è¯æ³åï¼ç¨æ¼æ§å»ºæ½å¨å°ææ§ç¯ä¾çæç´¢ç©ºéãç¶å¾ï¼æåå¼å¥ä¸åé¢æ£ç²å­ç¾¤åªåæ¼ç®æ³ä¾æç´¢æä½³çå°ææ§ç¯ä¾ãæåé²è¡äºå¨é¢çå¯¦é©ï¼ä¸¦è¡¨æåé²çèªç¶èªè¨èçæ¨¡ååæç¨ç¨å¼ï¼åæ¬å¤§åèªè¨æ¨¡åï¼é½å®¹æåå°æåçæ»æï¼èäººé¡ä¼¼ä¹å¾æé·çè§£æ¾åå¾çæå­ãæåéæ¢ç´¢äºå©ç¨®æ¹æ³ï¼åæ¬å°ææ§è¨ç·´ååºæ¼è¯æ³åçæ¢å¾©ï¼ä»¥ä¿è­·ç³»çµ±åååºæ¼éå¼è¯æ³çæ»æãç±æ¼ä¸äºç¯ä¾ä½¿ç¨äºæäºè²¶ç¾©è©ï¼å æ­¤æ¬æåå«å¯è½åç¯æä»¤æäºäººæå°ä¸å®çææã

##### **Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**
2411.07185v1 by Yao Ma, Samuel Louvan, Zhunxuan Wang

Multi-source unsupervised domain adaptation aims to leverage labeled data
from multiple source domains for training a machine learning model to
generalize well on a target domain without labels. Source domain selection
plays a crucial role in determining the model's performance. It relies on the
similarities amongst source and target domains. Nonetheless, existing work for
source domain selection often involves heavyweight computational procedures,
especially when dealing with numerous source domains and the need to identify
the best ones from them. In this paper, we introduce a framework for gradual
fine tuning (GFT) of machine learning models on multiple source domains. We
represent multiple source domains as an undirected weighted graph. We then give
a new generalization error bound for GFT along any path within the graph, which
is used to determine the optimal path corresponding to the optimal training
order. With this formulation, we introduce three lightweight graph-routing
strategies which tend to minimize the error bound. Our best strategy improves
$2.3\%$ of accuracy over the state-of-the-art on Natural Language Inference
(NLI) task and achieves competitive performance on Sentiment Analysis (SA)
task, especially a $3.9\%$ improvement on a more diverse subset of data we use
for SA.

æè¦ï¼å¤æºæ çç£åèªéåºæ¨å¨å©ç¨æ¥èªå¤ä¸ªæºåçæ è®°æ°æ®ï¼è®­ç»æºå¨å­¦ä¹ æ¨¡åï¼ä»¥ä¾¿å¨æ²¡ææ ç­¾çç®æ åä¸å¾å¥½å°æ³åãæºåéæ©å¨ç¡®å®æ¨¡åæ§è½æ¹é¢èµ·çè³å³éè¦çä½ç¨ãå®ä¾èµäºæºååç®æ åä¹é´çç¸ä¼¼æ§ãå°½ç®¡å¦æ­¤ï¼ç°æçæºåéæ©å·¥ä½éå¸¸æ¶åééçº§è®¡ç®ç¨åºï¼å°¤å¶æ¯å¨å¤çä¼å¤æºåä»¥åéè¦ä»ä¸­è¯å«æä½³æºåæ¶ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äºä¸ä¸ªå¨å¤ä¸ªæºåä¸å¯¹æºå¨å­¦ä¹ æ¨¡åè¿è¡éæ­¥å¾®è° (GFT) çæ¡æ¶ãæä»¬å°å¤ä¸ªæºåè¡¨ç¤ºä¸ºæ åå æå¾ãç¶åï¼æä»¬ä¸ºå¾ä¸­æ²¿ä»»ä½è·¯å¾ç GFT ç»åºäºä¸ä¸ªæ°çæ³åè¯¯å·®çï¼ç¨äºç¡®å®å¯¹åºäºæä½³è®­ç»é¡ºåºçæä½³è·¯å¾ãéè¿è¿ç§è¡¨è¿°ï¼æä»¬ä»ç»äºä¸ç§è½»éçº§çå¾è·¯ç±ç­ç¥ï¼è¿äºç­ç¥å¾åäºæå°åè¯¯å·®çãæä»¬æå¥½çç­ç¥å¨èªç¶è¯­è¨æ¨ç (NLI) ä»»å¡ä¸æ¯æåè¿çææ¯æé«äº 2.3% çåç¡®çï¼å¹¶å¨ææåæ (SA) ä»»å¡ä¸åå¾äºæç«äºåçæ§è½ï¼ç¹å«æ¯å¨æä»¬ç¨äº SA çæ´å¤æ ·åçæ°æ®å­éä¸æé«äº 3.9%ã

##### **A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**
2411.07163v1 by Vedant Khandelwal, Manas Gaur, Ugur Kursuncu, Valerie Shalin, Amit Sheth

Monitoring public sentiment via social media is potentially helpful during
health crises such as the COVID-19 pandemic. However, traditional
frequency-based, data-driven neural network-based approaches can miss newly
relevant content due to the evolving nature of language in a dynamically
evolving environment. Human-curated symbolic knowledge sources, such as
lexicons for standard language and slang terms, can potentially elevate social
media signals in evolving language. We introduce a neurosymbolic method that
integrates neural networks with symbolic knowledge sources, enhancing the
detection and interpretation of mental health-related tweets relevant to
COVID-19. Our method was evaluated using a corpus of large datasets
(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news
articles) and multiple knowledge graphs. This method dynamically adapts to
evolving language, outperforming purely data-driven models with an F1 score
exceeding 92\%. This approach also showed faster adaptation to new data and
lower computational demands than fine-tuning pre-trained large language models
(LLMs). This study demonstrates the benefit of neurosymbolic methods in
interpreting text in a dynamic environment for tasks such as health
surveillance.

æè¦ï¼ééç¤¾ç¾¤åªé«ç£æ§å¬ç¾æç·å¨ COVID-19 ç­å¥åº·å±æ©æéå¯è½å¾æå¹«å©ãç¶èï¼å³çµ±çåºæ¼é »çãè³æé©åçç¥ç¶ç¶²è·¯æ¹æ³å¯è½æé¯éæ°ç¸éçå§å®¹ï¼å çºèªè¨å¨åææ¼åçç°å¢ä¸­ææçºæ¼åãç±äººé¡ç­åçè±¡å¾µæ§ç¥è­ä¾æºï¼ä¾å¦æ¨æºèªè¨åä¿èªè¡èªçè©å½ï¼å¯è½ææåç¤¾ç¾¤åªé«å¨æ¼åèªè¨ä¸­çè¨èãæåå¼å¥ä¸ç¨®å°ç¥ç¶ç¶²è·¯èè±¡å¾µæ§ç¥è­ä¾æºæ´åçç¥ç¶ç¬¦èæ¹æ³ï¼å¢å¼·è COVID-19 ç¸éçå¿çå¥åº·ç¸éæ¨æçåµæ¸¬åè©®éãæåçåæ³ä½¿ç¨å¤§åè³æéèªæåº«ï¼ç´ 120 ååæ¨æã250 è¬å subreddit è³æå 70 è¬åæ°èæç« ï¼åå¤åç¥è­åè­é²è¡è©ä¼°ãéç¨®æ¹æ³åæé©ææ¼åçèªè¨ï¼åªæ¼ç´è³æé©åæ¨¡åï¼F1 åæ¸è¶é 92%ãéç¨®æ¹æ³ä¹é¡¯ç¤ºåºæ¯å¾®èª¿é è¨ç·´å¤§åèªè¨æ¨¡å (LLM) æ´å¿«é©ææ°è³æåæ´ä½çéç®éæ±ãæ¬ç ç©¶è­æäºç¥ç¶ç¬¦èæ¹æ³å¨åæç°å¢ä¸­è©®éæå­çåªé»ï¼é©ç¨æ¼å¥åº·ç£æ§ç­ä»»åã

##### **A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**
2411.07098v1 by Myeongsoo Kim, Tyler Stennett, Saurabh Sinha, Alessandro Orso

As modern web services increasingly rely on REST APIs, their thorough testing
has become crucial. Furthermore, the advent of REST API specifications such as
the OpenAPI Specification has led to the emergence of many black-box REST API
testing tools. However, these tools often focus on individual test elements in
isolation (e.g., APIs, parameters, values), resulting in lower coverage and
less effectiveness in detecting faults (i.e., 500 response codes). To address
these limitations, we present AutoRestTest, the first black-box framework to
adopt a dependency-embedded multi-agent approach for REST API testing,
integrating Multi-Agent Reinforcement Learning (MARL) with a Semantic Property
Dependency Graph (SPDG) and Large Language Models (LLMs). Our approach treats
REST API testing as a separable problem, where four agents -- API, dependency,
parameter, and value -- collaborate to optimize API exploration. LLMs handle
domain-specific value restrictions, the SPDG model simplifies the search space
for dependencies using a similarity score between API operations, and MARL
dynamically optimizes the agents' behavior. Evaluated on 12 real-world REST
services, AutoRestTest outperforms the four leading black-box REST API testing
tools, including those assisted by RESTGPT (which augments realistic test
inputs using LLMs), in terms of code coverage, operation coverage, and fault
detection. Notably, AutoRestTest is the only tool able to identify an internal
server error in Spotify. Our ablation study underscores the significant
contributions of the agent learning, SPDG, and LLM components.

æè¦ï¼<paragraph>é¨èç¾ä»£ç¶²è·¯æåæ¥çä¾è³´ REST APIï¼å¶å¾¹åºçæ¸¬è©¦è®å¾è³ééè¦ãæ­¤å¤ï¼REST API è¦ç¯ï¼ä¾å¦ OpenAPI è¦ç¯ï¼çåºç¾ï¼å°è´è¨±å¤é»ç REST API æ¸¬è©¦å·¥å·çåºç¾ãç¶èï¼éäºå·¥å·éå¸¸å°æ³¨æ¼å®ç¨çæ¸¬è©¦åç´ ï¼ä¾å¦ APIãåæ¸ãå¼ï¼ï¼å°è´è¦èçè¼ä½ï¼ä¸å¨åµæ¸¬é¯èª¤ï¼å³ 500 åæç¢¼ï¼æ¹é¢æçè¼ä½ãçºäºè§£æ±ºéäºéå¶ï¼æåæåº AutoRestTestï¼éæ¯ç¬¬ä¸åæ¡ç¨ä¾è³´åµå¥å¼å¤ä»£çæ¹æ³é²è¡ REST API æ¸¬è©¦çé»çæ¡æ¶ï¼å°å¤ä»£çå¼·åå­¸ç¿ (MARL) èèªç¾©å±¬æ§ä¾è³´å (SPDG) åå¤§åèªè¨æ¨¡å (LLM) æ´åå¨ä¸èµ·ãæåçåæ³å° REST API æ¸¬è©¦è¦çºä¸åå¯åé¢çåé¡ï¼å¶ä¸­ååä»£çï¼APIãä¾è³´éä¿ãåæ¸åå¼ï¼åååä½ä»¥æä½³å API æ¢ç´¢ãLLM èçç¹å®é åçå¼éå¶ï¼SPDG æ¨¡åä½¿ç¨ API æä½ä¹éçç¸ä¼¼æ§åæ¸ç°¡åä¾è³´éä¿çæå°ç©ºéï¼è MARL ååææä½³åä»£ççè¡çºãå¨ 12 é çå¯¦ä¸çç REST æåä¸é²è¡è©ä¼°ï¼AutoRestTest å¨ç¨å¼ç¢¼è¦èçãæä½è¦èçåé¯èª¤åµæ¸¬æ¹é¢ï¼åªæ¼åç¨®é åçé»ç REST API æ¸¬è©¦å·¥å·ï¼åæ¬é£äºç± RESTGPTï¼ä½¿ç¨ LLM å¢å é¼ççæ¸¬è©¦è¼¸å¥ï¼è¼å©çå·¥å·ãå¼å¾æ³¨æçæ¯ï¼AutoRestTest æ¯å¯ä¸è½å¤ è­å¥ Spotify ä¸­å§é¨ä¼ºæå¨é¯èª¤çå·¥å·ãæåçæ¶èç ç©¶å¼·èª¿äºä»£çå­¸ç¿ãSPDG å LLM çµä»¶çéå¤§è²¢ç»ã</paragraph>

##### **Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**
2411.06660v1 by Qiao Qiao, Yuepei Li, Qing Wang, Kang Zhou, Qi Li

Knowledge graph completion (KGC) is a task of inferring missing triples based
on existing Knowledge Graphs (KGs). Both structural and semantic information
are vital for successful KGC. However, existing methods only use either the
structural knowledge from the KG embeddings or the semantic information from
pre-trained language models (PLMs), leading to suboptimal model performance.
Moreover, since PLMs are not trained on KGs, directly using PLMs to encode
triples may be inappropriate. To overcome these limitations, we propose a novel
framework called Bridge, which jointly encodes structural and semantic
information of KGs. Specifically, we strategically encode entities and
relations separately by PLMs to better utilize the semantic knowledge of PLMs
and enable structured representation learning via a structural learning
principle. Furthermore, to bridge the gap between KGs and PLMs, we employ a
self-supervised representation learning method called BYOL to fine-tune PLMs
with two different views of a triple. Unlike BYOL, which uses augmentation
methods to create two semantically similar views of the same image, potentially
altering the semantic information. We strategically separate the triple into
two parts to create different views, thus avoiding semantic alteration.
Experiments demonstrate that Bridge outperforms the SOTA models on three
benchmark datasets.

æè¦ï¼ç¥è­åè­è£å¨ (KGC) æ¯ä¸é æ ¹æç¾æç¥è­åè­ (KG) æ¨è«éºå¤±ä¸åçµçä»»åãçµæ§åèªç¾©è³è¨å°æ¼æåç KGC è³ééè¦ãç¶èï¼ç¾ææ¹æ³åä½¿ç¨ä¾èª KG åµå¥ççµæ§ç¥è­æä¾èªé è¨ç·´èªè¨æ¨¡å (PLM) çèªç¾©è³è¨ï¼å°è´æ¨¡åæè½ä¸ä½³ãæ­¤å¤ï¼ç±æ¼ PLM æ²æå¨ KG ä¸è¨ç·´ï¼å æ­¤ç´æ¥ä½¿ç¨ PLM ç·¨ç¢¼ä¸åçµå¯è½ä¸¦ä¸é©ç¶ãçºäºåæéäºéå¶ï¼æåæåºä¸ååçº Bridge çæ°æ¶æ§ï¼è©²æ¶æ§è¯åç·¨ç¢¼ KG ççµæ§åèªç¾©è³è¨ãå·é«ä¾èªªï¼æåéé PLM åå¥å°å¯¦é«åéä¿é²è¡ç­ç¥æ§ç·¨ç¢¼ï¼ä»¥æ´å¥½å°å©ç¨ PLM çèªç¾©ç¥è­ï¼ä¸¦ééçµæ§å­¸ç¿åååç¨çµæ§åè¡¨ç¤ºå­¸ç¿ãæ­¤å¤ï¼çºäºå½å KG å PLM ä¹éçå·®è·ï¼æåæ¡ç¨ä¸ç¨®ç¨±çº BYOL çèªç£ç£è¡¨ç¤ºå­¸ç¿æ¹æ³ï¼ä»¥ä¸åçµçå©åä¸åè¦åå¾®èª¿ PLMãè BYOL ä¸åï¼BYOL ä½¿ç¨æ´åæ¹æ³ä¾å»ºç«å©åèªç¾©ä¸ç¸ä¼¼çç¸åå½±åè¦åï¼å¯è½ææ¹è®èªç¾©è³è¨ãæåç­ç¥æ§å°å°ä¸åçµåçºå©é¨åä»¥å»ºç«ä¸åçè¦åï¼å¾èé¿åèªç¾©æ¹è®ãå¯¦é©è­æ Bridge å¨ä¸ååºæºè³æéä¸åªæ¼ SOTA æ¨¡åã

##### **CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**
2411.06391v1 by Shuqi Li, Yuebo Sun, Yuxin Lin, Xin Gao, Shuo Shang, Rui Yan

There are two issues in news-driven multi-stock movement prediction tasks
that are not well solved in the existing works. On the one hand, "relation
discovery" is a pivotal part when leveraging the price information of other
stocks to achieve accurate stock movement prediction. Given that stock
relations are often unidirectional, such as the "supplier-consumer"
relationship, causal relations are more appropriate to capture the impact
between stocks. On the other hand, there is substantial noise existing in the
news data leading to extracting effective information with difficulty. With
these two issues in mind, we propose a novel framework called CausalStock for
news-driven multi-stock movement prediction, which discovers the temporal
causal relations between stocks. We design a lag-dependent temporal causal
discovery mechanism to model the temporal causal graph distribution. Then a
Functional Causal Model is employed to encapsulate the discovered causal
relations and predict the stock movements. Additionally, we propose a Denoised
News Encoder by taking advantage of the excellent text evaluation ability of
large language models (LLMs) to extract useful information from massive news
data. The experiment results show that CausalStock outperforms the strong
baselines for both news-driven multi-stock movement prediction and multi-stock
movement prediction tasks on six real-world datasets collected from the US,
China, Japan, and UK markets. Moreover, getting benefit from the causal
relations, CausalStock could offer a clear prediction mechanism with good
explainability.

æè¦ï¼<paragraph>å¨æ°èé©åçå¤è¡ç¥¨ç§»åé æ¸¬ä»»åä¸­ï¼ç¾æç ç©¶å°æªå¦¥åè§£æ±ºå©ååé¡ãä¸æ¹é¢ï¼å¨å©ç¨å¶ä»è¡ç¥¨çå¹æ ¼è³è¨ä¾å¯¦ç¾æºç¢ºçè¡ç¥¨ç§»åé æ¸¬æï¼ãéä¿ç¼ç¾ãæ¯ä¸åééµé¨åãç±æ¼è¡ç¥¨éä¿éå¸¸æ¯å®åçï¼ä¾å¦ãä¾æå-æ¶è²»èãéä¿ï¼å æ­¤å æéä¿æ´é©åææè¡ç¥¨ä¹éçå½±é¿ãå¦ä¸æ¹é¢ï¼æ°èè³æä¸­å­å¨å¤§ééè¨ï¼å°è´é£ä»¥æåææè³è¨ãèæ®å°éå©ååé¡ï¼æåæåºäºä¸ååçº CausalStock çæ°æ¡æ¶ï¼ç¨æ¼æ°èé©åçå¤è¡ç¥¨ç§»åé æ¸¬ï¼è©²æ¡æ¶ç¼ç¾äºè¡ç¥¨ä¹éçæåºå æéä¿ãæåè¨­è¨äºä¸åå»¶é²ä¾è³´çæåºå æç¼ç¾æ©å¶ï¼ä»¥å»ºæ¨¡æåºå æååå¸ãç¶å¾æ¡ç¨åè½å ææ¨¡åä¾å°è£ç¼ç¾çå æéä¿ä¸¦é æ¸¬è¡ç¥¨èµ°å¢ãæ­¤å¤ï¼æåæåºäºä¸åå»åªæ°èç·¨ç¢¼å¨ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) åºè²çææ¬è©ä¼°è½åå¾å¤§éæ°èè³æä¸­æåæç¨è³è¨ãå¯¦é©çµæè¡¨æï¼CausalStock å¨å¾ç¾åãä¸­åãæ¥æ¬åè±åå¸å ´æ¶éçå­åçå¯¦ä¸çè³æéä¸ï¼å¨æ°èé©åçå¤è¡ç¥¨ç§»åé æ¸¬åå¤è¡ç¥¨ç§»åé æ¸¬ä»»åä¸­é½åªæ¼å¼·å¤§çåºç·ãæ­¤å¤ï¼CausalStock åçæ¼å æéä¿ï¼å¯ä»¥æä¾å·æè¯å¥½å¯è§£éæ§çæ¸æ°é æ¸¬æ©å¶ã</paragraph>

##### **Analyzing the Evolution of Graphs and Texts**
2411.06295v1 by Xingzhi Guo

With the recent advance of representation learning algorithms on graphs
(e.g., DeepWalk/GraphSage) and natural languages (e.g., Word2Vec/BERT) , the
state-of-the art models can even achieve human-level performance over many
downstream tasks, particularly for the task of node and sentence
classification. However, most algorithms focus on large-scale models for static
graphs and text corpus without considering the inherent dynamic characteristics
or discovering the reasons behind the changes. This dissertation aims to
efficiently model the dynamics in graphs (such as social networks and citation
graphs) and understand the changes in texts (specifically news titles and
personal biographies). To achieve this goal, we utilize the renowned
Personalized PageRank algorithm to create effective dynamic network embeddings
for evolving graphs. Our proposed approaches significantly improve the running
time and accuracy for both detecting network abnormal intruders and discovering
entity meaning shifts over large-scale dynamic graphs. For text changes, we
analyze the post-publication changes in news titles to understand the intents
behind the edits and discuss the potential impact of titles changes from
information integrity perspective. Moreover, we investigate self-presented
occupational identities in Twitter users' biographies over five years,
investigating job prestige and demographics effects in how people disclose
jobs, quantifying over-represented jobs and their transitions over time.

æè¦ï¼é¨èåå½¢è¡¨ç¤ºå­¸ç¿æ¼ç®æ³çææ°é²å±ï¼ä¾å¦ DeepWalk/GraphSageï¼åèªç¶èªè¨ï¼ä¾å¦ Word2Vec/BERTï¼ï¼æåé²çæ¨¡åçè³å¯ä»¥å¨è¨±å¤ä¸æ¸¸ä»»åä¸­éå°äººé¡ç­ç´çæè½ï¼ç¹å¥æ¯å°æ¼ç¯é»åå¥å­åé¡çä»»åãç¶èï¼å¤§å¤æ¸æ¼ç®æ³é½å°æ³¨æ¼éæåå½¢åå¤§è¦æ¨¡æå­èªæåº«çæ¨¡åï¼èæ²æèæ®åºæçåæç¹æ§ææ¾åºè®åçåå ãæ¬è«ææ¨å¨ææå°çºåå½¢ï¼ä¾å¦ç¤¾ç¾¤ç¶²è·¯åå¼æåå½¢ï¼å»ºæ¨¡åæï¼ä¸¦äºè§£æå­çè®åï¼ç¹å¥æ¯æ°èæ¨é¡ååäººå³è¨ï¼ãçºäºéæéåç®æ¨ï¼æåå©ç¨èåç Personalized PageRank æ¼ç®æ³çºä¸æ·è®åçåå½¢å»ºç«ææçåæç¶²è·¯åµå¥ãæåæåºçæ¹æ³é¡¯èæ¹åäºåµæ¸¬ç¶²è·¯ç°å¸¸å¥ä¾µèåæ¾åºå¤§è¦æ¨¡åæåå½¢ä¸­å¯¦é«å«ç¾©è½ç§»çå·è¡æéåæºç¢ºåº¦ãå°æ¼æå­è®åçé¨åï¼æååæäºæ°èæ¨é¡å¨åºçå¾çè®åï¼ä»¥äºè§£ç·¨è¼¯èå¾çæåï¼ä¸¦è¨è«æ¨é¡è®æ´å°è³è¨å®æ´æ§çæ½å¨å½±é¿ãæ­¤å¤ï¼æåèª¿æ¥äº Twitter ä½¿ç¨èå¨å³è¨ä¸­åç¾çè·æ¥­èº«åé·éäºå¹´ï¼æ¢è¨äºå·¥ä½è²æåäººå£çµ±è¨è³æå°äººåæ­é²å·¥ä½çå½±é¿ï¼ä¸¦éåäºéåº¦ä»£è¡¨çå·¥ä½åå¶é¨èæéæ¨ç§»çè½è®ã

##### **An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**
2411.06048v1 by Fatemeh Shiri, Xiao-Yu Guo, Mona Golestan Far, Xin Yu, Gholamreza Haffari, Yuan-Fang Li

Large Multimodal Models (LMMs) have achieved strong performance across a
range of vision and language tasks. However, their spatial reasoning
capabilities are under-investigated. In this paper, we construct a novel VQA
dataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and
reasoning capabilities. Our analyses on object-relationship and multi-hop
reasoning reveal several important findings. Firstly, bounding boxes and scene
graphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.
Secondly, LMMs struggle more with questions posed from the human perspective
than the camera perspective about the image. Thirdly, chain of thought (CoT)
prompting does not improve model performance on complex multi-hop questions
involving spatial relations. % Moreover, spatial reasoning steps are much less
accurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis
on GQA-spatial reveals that LMMs are much stronger at basic object detection
than complex spatial reasoning. We believe our benchmark dataset and in-depth
analyses can spark further research on LMMs spatial reasoning. Spatial-MM
benchmark is available at: https://github.com/FatemehShiri/Spatial-MM

æè¦ï¼å¤§åå¤æ¨¡ææ¨¡å (LMM) å·²å¨åç¨®è¦è¦ºåèªè¨ä»»åä¸­åå¾å¼·åçè¡¨ç¾ãç¶èï¼å®åçç©ºéæ¨çè½åå°æªå¾å°ååç ç©¶ãå¨æ¬æä¸­ï¼æåæ§å»ºäºä¸åæ°ç©ç VQA è³æé Spatial-MMï¼ä»¥å¨é¢ç ç©¶ LMM çç©ºéçè§£åæ¨çè½åãæåå°ç©ä»¶éä¿åå¤è·³æ¨ççåææ­ç¤ºäºå¹¾åéè¦çç¼ç¾ãé¦åï¼éçæ¡åå ´æ¯åï¼å³ä½¿æ¯åæçï¼ä¹å¯ä»¥é¡¯èå¢å¼· LMM çç©ºéæ¨çè½åãå¶æ¬¡ï¼LMM å¨åç­å¾äººé¡è¦è§æåºçåé¡ææ¯å¾ç¸æ©è¦è§æåºçåé¡æéå°æ´å¤å°é£ãç¬¬ä¸ï¼æèé (CoT) æç¤ºä¸¦æªæ¹åæ¨¡åå¨æ¶åç©ºééä¿çè¤éå¤è·³åé¡ä¸çæè½ã% æ­¤å¤ï¼å¨ MLLM ä¸­ï¼ç©ºéæ¨çæ­¥é©çæºç¢ºåº¦é ä½æ¼éç©ºéæ­¥é©ãæå¾ï¼æåå° GQA-spatial çæ¾ååæè¡¨æï¼LMM å¨åºæ¬ç©ä»¶åµæ¸¬æ¹é¢çè½åé å¼·æ¼è¤éçç©ºéæ¨çãæåç¸ä¿¡æåçåºæºè³æéåæ·±å¥åæå¯ä»¥æ¿ç¼å° LMM ç©ºéæ¨ççé²ä¸æ­¥ç ç©¶ãSpatial-MM åºæºå¯å¨ä»¥ä¸ç¶²ååå¾ï¼https://github.com/FatemehShiri/Spatial-MM

##### **Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine**
2411.05936v1 by Anantha Sharma, Sheeba Elizabeth John, Fatemeh Rezapoor Nikroo, Krupali Bhatt, Mrunal Zambre, Aditi Wikhe

The growth of digital documents presents significant challenges in efficient
management and knowledge extraction. Traditional methods often struggle with
complex documents, leading to issues such as hallucinations and high latency in
responses from Large Language Models (LLMs). ZeroG, an innovative approach,
significantly mitigates these challenges by leveraging knowledge distillation
and prompt tuning to enhance model performance.
  ZeroG utilizes a smaller model that replicates the behavior of a larger
teacher model, ensuring contextually relevant and grounded responses, by
employing a black-box distillation approach, it creates a distilled dataset
without relying on intermediate features, optimizing computational efficiency.
This method significantly enhances accuracy and reduces response times,
providing a balanced solution for modern document management.
  Incorporating advanced techniques for document ingestion and metadata
utilization, ZeroG improves the accuracy of question-and-answer systems. The
integration of graph databases and robust metadata management further
streamlines information retrieval, allowing for precise and context-aware
responses. By transforming how organizations interact with complex data, ZeroG
enhances productivity and user experience, offering a scalable solution for the
growing demands of digital document management.

æè¦ï¼æ¸ä½æä»¶æé·å¸¶ä¾é¡¯èçææ°ï¼åæ¬ææç®¡çåç¥è­èåãå³çµ±æ¹æ³ç¶å¸¸é£ä»¥èçè¤éæä»¶ï¼å°è´åé¡ï¼ä¾å¦ç¢çå¹»è¦ºåå¤§åèªè¨æ¨¡å (LLM) åæçé«å»¶é²ãZeroG æ¯ä¸ç¨®åµæ°çæ¹æ³ï¼ééå©ç¨ç¥è­è¸é¤¾åæç¤ºèª¿æ´ä¾å¢å¼·æ¨¡åæè½ï¼å¤§å¹æ¸è¼éäºææ°ã
ZeroG ä½¿ç¨è¼å°çæ¨¡åè¤è£½è¼å¤§çæå¸«æ¨¡åçè¡çºï¼ééæ¡ç¨é»çè¸é¤¾æ¹æ³ï¼ç¢ºä¿å¨èçµ¡ä¸ç¸éä¸ææ ¹æçåæï¼å®å»ºç«ä¸åè¸é¤¾çè³æéï¼èä¸éè¦ä¾è³´ä¸­éç¹å¾µï¼æä½³åéç®æçãéç¨®æ¹æ³å¤§å¹æåæºç¢ºåº¦ä¸¦æ¸å°åææéï¼æä¾ç¾ä»£æä»¶ç®¡ççå¹³è¡¡è§£æ±ºæ¹æ¡ã
ééæ´åé²éæè¡ä¾æ·åæä»¶åä½¿ç¨åè³æï¼ZeroG æ¹ååç­ç³»çµ±çæºç¢ºåº¦ãåå½¢è³æåº«åå¼·å¥çåè³æç®¡ççæ´åé²ä¸æ­¥ç°¡åè³è¨æ·åï¼åè¨±ç²¾ç¢ºä¸ç¬¦åèçµ¡çåæãééè½æçµç¹èè¤éè³æäºåçæ¹å¼ï¼ZeroG æåçç¢ååä½¿ç¨èé«é©ï¼æä¾å¯æ´åçè§£æ±ºæ¹æ¡ï¼ä»¥æ»¿è¶³æ¸ä½æä»¶ç®¡çæ¥çå¢é·çéæ±ã

##### **SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**
2411.05521v2 by Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, Jonathan Fuerst

Electronic health records (EHRs) are stored in various database systems with
different database models on heterogeneous storage architectures, such as
relational databases, document stores, or graph databases. These different
database models have a big impact on query complexity and performance. While
this has been a known fact in database research, its implications for the
growing number of Text-to-Query systems have surprisingly not been investigated
so far. In this paper, we present SM3-Text-to-Query, the first multi-model
medical Text-to-Query benchmark based on synthetic patient data from Synthea,
following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology
covering medical terminology. SM3-Text-to-Query provides data representations
for relational databases (PostgreSQL), document stores (MongoDB), and graph
databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four
popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically
and manually develop 408 template questions, which we augment to construct a
benchmark of 10K diverse natural language question/query pairs for these four
query languages (40K pairs overall). On our dataset, we evaluate several common
in-context-learning (ICL) approaches for a set of representative closed and
open-source LLMs. Our evaluation sheds light on the trade-offs between database
models and query languages for different ICL strategies and LLMs. Last,
SM3-Text-to-Query is easily extendable to additional query languages or real,
standard-based patient databases.

æè¦ï¼é»å­å¥åº·è¨é (EHR) å²å­å¨å·æä¸åè³æåº«æ¨¡åçåç¨®è³æåº«ç³»çµ±ä¸­ï¼æ¡ç¨ç°è³ªå²å­æ¶æ§ï¼ä¾å¦éè¯å¼è³æåº«ãæä»¶å²å­åº«æåå½¢è³æåº«ãéäºä¸åçè³æåº«æ¨¡åå°æ¥è©¢è¤éåº¦åæè½æå¾å¤§çå½±é¿ãéç¶éå¨è³æåº«ç ç©¶ä¸­æ¯ä¸åå·²ç¥çäºå¯¦ï¼ä½å¶å°è¶ä¾è¶å¤çæå­è½æ¥è©¢ç³»çµ±çå½±é¿å»ä»¤äººé©è¨å°å°æªè¢«ç ç©¶ãå¨æ¬æä¸­ï¼æåæåº SM3-Text-to-Queryï¼éæ¯ç¬¬ä¸ååºæ¼ Synthea åææ£èè³æçå¤æ¨¡åé«çæå­è½æ¥è©¢åºæºï¼éµå¾ª SNOMED-CT åé¡æ³ï¼éæ¯ä¸åå»£æ³ä½¿ç¨çç¥è­åå½¢æ¬é«ï¼æ¶µèé«å­¸è¡èªãSM3-Text-to-Query æä¾äºéä¿è³æåº« (PostgreSQL)ãæä»¶å²å­åº« (MongoDB) ååå½¢è³æåº« (Neo4j å GraphDB (RDF)) çè³æè¡¨ç¤ºï¼åè¨±è·¨åç¨®æµè¡çæ¥è©¢èªè¨é²è¡è©ä¼°ï¼å³ SQLãMQLãCypher å SPARQLãæåç³»çµ±ä¸æåéç¼äº 408 åç¯æ¬åé¡ï¼ä¸¦æ´åéäºåé¡ä»¥å»ºæ§ä¸ååºæºï¼å¶ä¸­åå« 10K åéå°éåç¨®æ¥è©¢èªè¨çå¤æ¨£åèªç¶èªè¨åé¡/æ¥è©¢éå°ï¼ç¸½å± 40K åéå°ï¼ãå¨æåçè³æéä¸ï¼æåè©ä¼°äºä¸çµä»£è¡¨æ§çå°éåéæ¾åå§ç¢¼ LLM çå¹¾åå¸¸è¦æå¢å­¸ç¿ (ICL) æ¹æ³ãæåçè©ä¼°æ­ç¤ºäºä¸å ICL ç­ç¥å LLM çè³æåº«æ¨¡ååæ¥è©¢èªè¨ä¹éçæ¬è¡¡ãæå¾ï¼SM3-Text-to-Query å¯ä»¥è¼é¬æ´åå°å¶ä»æ¥è©¢èªè¨æçå¯¦çãåºæ¼æ¨æºçæ£èè³æåº«ã

##### **EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**
2411.05479v1 by Abdoul Nasser Hassane Amadou, Anas Motii, Saida Elouardi, EL Houcine Bergou

Underground forums serve as hubs for cybercriminal activities, offering a
space for anonymity and evasion of conventional online oversight. In these
hidden communities, malicious actors collaborate to exchange illicit knowledge,
tools, and tactics, driving a range of cyber threats from hacking techniques to
the sale of stolen data, malware, and zero-day exploits. Identifying the key
instigators (i.e., key hackers), behind these operations is essential but
remains a complex challenge. This paper presents a novel method called EUREKHA
(Enhancing User Representation for Key Hacker Identification in Underground
Forums), designed to identify these key hackers by modeling each user as a
textual sequence. This sequence is processed through a large language model
(LLM) for domain-specific adaptation, with LLMs acting as feature extractors.
These extracted features are then fed into a Graph Neural Network (GNN) to
model user structural relationships, significantly improving identification
accuracy. Furthermore, we employ BERTopic (Bidirectional Encoder
Representations from Transformers Topic Modeling) to extract personalized
topics from user-generated content, enabling multiple textual representations
per user and optimizing the selection of the most representative sequence. Our
study demonstrates that fine-tuned LLMs outperform state-of-the-art methods in
identifying key hackers. Additionally, when combined with GNNs, our model
achieves significant improvements, resulting in approximately 6% and 10%
increases in accuracy and F1-score, respectively, over existing methods.
EUREKHA was tested on the Hack-Forums dataset, and we provide open-source
access to our code.

æè¦ï¼<paragraph>å°ä¸è«å£æ¯ç¶²è·¯ç¯ç½ªæ´»åçæ¨ç´ï¼æä¾å¿ååè¦é¿å³çµ±ç¶²è·¯ç£ç£çç©ºéãå¨éäºé±èçç¤¾ç¾¤ä¸­ï¼æ¡æè¡çºèåä½äº¤æéæ³ç¥è­ãå·¥å·åç­ç¥ï¼æ¨åå¾é§­å®¢æè¡å°é·å®ç«åè³æãæ¡æè»é«åé¶æå·®æ¼æ´çåç¨®ç¶²è·¯å¨èãæ¾åºéäºè¡åèå¾çééµç½åèï¼å³ééµé§­å®¢ï¼è³ééè¦ï¼ä½ä»ç¶æ¯ä¸åè¤éçææ°ãæ¬ææåºäºä¸ç¨®ç¨±çº EUREKHAï¼å¢å¼·ä½¿ç¨èè¡¨å¾µä»¥è­å¥å°ä¸è«å£ä¸­çééµé§­å®¢ï¼çæ°æ¹æ³ï¼æ¨å¨ééå°æ¯åä½¿ç¨èå»ºæ¨¡çºæå­åºåä¾è­å¥éäºééµé§­å®¢ãæ­¤åºåééå¤§åèªè¨æ¨¡åï¼LLMï¼èçä»¥é²è¡ç¹å®é åçé©æï¼å¶ä¸­ LLM ä½çºç¹å¾µèåå¨ãç¶å¾å°éäºèåçç¹å¾µè¼¸å¥åç¥ç¶ç¶²è·¯ï¼GNNï¼ä»¥å»ºæ¨¡ä½¿ç¨èçµæ§éä¿ï¼å¤§å¹æåè­å¥æºç¢ºåº¦ãæ­¤å¤ï¼æåæ¡ç¨ BERTopicï¼ä¾èª Transformer ä¸»é¡å»ºæ¨¡çéåç·¨ç¢¼å¨è¡¨å¾µï¼å¾ä½¿ç¨èç¢ççå§å®¹ä¸­èååäººåä¸»é¡ï¼çºæ¯åä½¿ç¨èåç¨å¤åæå­è¡¨å¾µï¼ä¸¦æä½³åæå·ä»£è¡¨æ§åºåçé¸æãæåçç ç©¶è¡¨æï¼å¾®èª¿å¾ç LLM å¨è­å¥ééµé§­å®¢æ¹é¢åªæ¼æåé²çæ¹æ³ãæ­¤å¤ï¼ç¶è GNN çµåä½¿ç¨æï¼æåçæ¨¡åç²å¾é¡¯èçæåï¼èç¾ææ¹æ³ç¸æ¯ï¼æºç¢ºåº¦å F1 åæ¸åå¥æé«äºç´ 6% å 10%ãEUREKHA å·²å¨ Hack-Forums è³æéä¸é²è¡æ¸¬è©¦ï¼æåæä¾éæºæ¹å¼å­åæåçç¨å¼ç¢¼ã</paragraph>

##### **When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization**
2411.05882v1 by Jacob Nielsen, Lukas Galke, Peter Schneider-Kamp

Contemporary machine learning models, such as language models, are powerful,
but come with immense resource requirements both at training and inference
time. It has been shown that decoder-only language models can be trained to a
competitive state with ternary weights (1.58 bits per weight), facilitating
efficient inference. Here, we start our exploration with non-transformer model
architectures, investigating 1.58-bit training for multi-layer perceptrons and
graph neural networks. Then, we explore 1.58-bit training in other
transformer-based language models, namely encoder-only and encoder-decoder
models. Our results show that in all of these settings, 1.58-bit training is on
par with or sometimes even better than the standard 32/16-bit models.

æè¦ï¼ç¶ä»£æ©å¨å­¸ç¿æ¨¡åï¼ä¾å¦èªè¨æ¨¡åï¼åè½å¼·å¤§ï¼
ä½å¨è¨ç·´åæ¨è«æéä¸é½éè¦å¤§éçè³æºãå·²ç¶è­æï¼åè§£ç¢¼å¨èªè¨æ¨¡åå¯ä»¥ç¨ä¸åæ¬éï¼æ¯åæ¬é 1.58 ä½åï¼è¨ç·´å°ç«¶ç­çæï¼ä¿é²ææççæ¨è«ãå¨æ­¤ï¼æåå¾éTransformeræ¨¡åæ¶æ§éå§æ¢è¨ï¼ç ç©¶å¤å±¤æç¥å¨ååç¥ç¶ç¶²è·¯ç 1.58 ä½åè¨ç·´ãæ¥èï¼æåæ¢è¨å¶ä»åºæ¼Transformerçèªè¨æ¨¡åï¼å³åç·¨ç¢¼å¨åç·¨ç¢¼å¨-è§£ç¢¼å¨æ¨¡åï¼ç 1.58 ä½åè¨ç·´ãæåççµæé¡¯ç¤ºï¼å¨ææéäºè¨­å®ä¸­ï¼1.58 ä½åè¨ç·´èæ¨æº 32/16 ä½åæ¨¡åç¸ç¶ï¼ææçè³æ´å¥½ã

##### **Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**
2411.05316v1 by Dong Shu, Bingbing Duan, Kai Guo, Kaixiong Zhou, Jiliang Tang, Mengnan Du

Latent representation alignment has become a foundational technique for
constructing multimodal large language models (MLLM) by mapping embeddings from
different modalities into a shared space, often aligned with the embedding
space of large language models (LLMs) to enable effective cross-modal
understanding. While preliminary protein-focused MLLMs have emerged, they have
predominantly relied on heuristic approaches, lacking a fundamental
understanding of optimal alignment practices across representations. In this
study, we explore the alignment of multimodal representations between LLMs and
Geometric Deep Models (GDMs) in the protein domain. We comprehensively evaluate
three state-of-the-art LLMs (Gemma2-2B, LLaMa3.1-8B, and LLaMa3.1-70B) with
four protein-specialized GDMs (GearNet, GVP, ScanNet, GAT). Our work examines
alignment factors from both model and protein perspectives, identifying
challenges in current alignment methodologies and proposing strategies to
improve the alignment process. Our key findings reveal that GDMs incorporating
both graph and 3D structural information align better with LLMs, larger LLMs
demonstrate improved alignment capabilities, and protein rarity significantly
impacts alignment performance. We also find that increasing GDM embedding
dimensions, using two-layer projection heads, and fine-tuning LLMs on
protein-specific data substantially enhance alignment quality. These strategies
offer potential enhancements to the performance of protein-related multimodal
models. Our code and data are available at
https://github.com/Tizzzzy/LLM-GDM-alignment.

æè¦ï¼æ½å¨è¡¨å¾µå°é½å·²æçºå»ºæ§å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) çåºç¤æè¡ï¼æ¹æ³æ¯å°ä¸åæ¨¡æçåµå¥æ å°å°å±äº«ç©ºéä¸­ï¼éå¸¸èå¤§åèªè¨æ¨¡å (LLM) çåµå¥ç©ºéå°é½ï¼ä»¥å¯¦ç¾ææçè·¨æ¨¡æçè§£ãéç¶åæ­¥ä»¥èç½è³ªçºéé»ç MLLM å·²åºç¾ï¼ä½å®åä¸»è¦ä¾è³´åç¼å¼æ¹æ³ï¼ç¼ºä¹å°è·¨è¡¨å¾µæä½³å°é½å¯¦åçåºæ¬çè§£ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºèç½è³ªé åä¸­ LLM èå¹¾ä½æ·±åº¦æ¨¡å (GDM) ä¹éçå¤æ¨¡æè¡¨å¾µå°é½ãæåå¨é¢è©ä¼°äºä¸åæåé²ç LLMï¼Gemma2-2BãLLaMa3.1-8B å LLaMa3.1-70Bï¼èååèç½è³ªå°ç¨ GDMï¼GearNetãGVPãScanNetãGATï¼ãæåçç ç©¶å¾æ¨¡ååèç½è³ªè§åº¦æª¢è¦å°é½å ç´ ï¼è­å¥ç¶åå°é½æ¹æ³çææ°ï¼ä¸¦æåºæ¹åå°é½ç¨åºçç­ç¥ãæåçééµç¼ç¾é¡¯ç¤ºï¼åæåå«åå½¢å 3D çµæ§è³è¨ç GDM è LLM çå°é½ææè¼ä½³ï¼è¼å¤§ç LLM å±ç¾åºæ´ä½³çå°é½è½åï¼èèç½è³ªçç¨ææ§é¡¯èå½±é¿å°é½æè½ãæåéç¼ç¾ï¼å¢å  GDM åµå¥ç¶­åº¦ãä½¿ç¨å©å±¤æå½±é ­ï¼ä»¥åéå°èç½è³ªç¹å®è³æå¾®èª¿ LLMï¼å¯ä»¥å¤§å¹æåå°é½åè³ªãéäºç­ç¥çºèç½è³ªç¸éå¤æ¨¡ææ¨¡åçæè½æä¾æ½å¨çå¼·åãæåçç¨å¼ç¢¼åè³æå¯å¨ https://github.com/Tizzzzy/LLM-GDM-alignment åå¾ã

##### **LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration**
2411.05844v1 by Yukun Cao, Zengyi Gao, Zhiyang Li, Xike Xie, S Kevin Zhou

GraphRAG addresses significant challenges in Retrieval-Augmented Generation
(RAG) by leveraging graphs with embedded knowledge to enhance the reasoning
capabilities of Large Language Models (LLMs). Despite its promising potential,
the GraphRAG community currently lacks a unified framework for fine-grained
decomposition of the graph-based knowledge retrieval process. Furthermore,
there is no systematic categorization or evaluation of existing solutions
within the retrieval process. In this paper, we present LEGO-GraphRAG, a
modular framework that decomposes the retrieval process of GraphRAG into three
interconnected modules: subgraph-extraction, path-filtering, and
path-refinement. We systematically summarize and classify the algorithms and
neural network (NN) models relevant to each module, providing a clearer
understanding of the design space for GraphRAG instances. Additionally, we
identify key design factors, such as Graph Coupling and Computational Cost,
that influence the effectiveness of GraphRAG implementations. Through extensive
empirical studies, we construct high-quality GraphRAG instances using a
representative selection of solutions and analyze their impact on retrieval and
reasoning performance. Our findings offer critical insights into optimizing
GraphRAG instance design, ultimately contributing to the advancement of more
accurate and contextually relevant LLM applications.

æè¦ï¼GraphRAG ééå©ç¨å·åµå¥ç¥è­çåè¡¨ä¾å¢å¼·å¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åï¼è§£æ±ºäºæª¢ç´¢å¢å¼·çæ (RAG) ä¸­çéå¤§ææ°ãåç®¡å·æä»¤äººæå¾çæ½åï¼ä½ GraphRAG ç¤¾ç¾¤ç®åç¼ºä¹ä¸åçµ±ä¸çæ¶æ§ï¼ç¨æ¼å°åºæ¼åè¡¨çç¥è­æª¢ç´¢éç¨é²è¡ç´°ç²åº¦çåè§£ãæ­¤å¤ï¼å¨æª¢ç´¢éç¨ä¸­ï¼ç¾æè§£æ±ºæ¹æ¡ä¸¦æªé²è¡ç³»çµ±æ§çåé¡æè©ä¼°ãå¨æ¬æä¸­ï¼æåæåºäº LEGO-GraphRAGï¼éæ¯ä¸åæ¨¡çµåæ¶æ§ï¼å° GraphRAG çæª¢ç´¢éç¨åè§£çºä¸åç¸äºé£æ¥çæ¨¡çµï¼å­åèåãè·¯å¾éæ¿¾åè·¯å¾ç²¾çãæåç³»çµ±æ§å°ç¸½çµååé¡èæ¯åæ¨¡çµç¸éçæ¼ç®æ³åç¥ç¶ç¶²è·¯ (NN) æ¨¡åï¼æä¾å° GraphRAG å¯¦ä¾è¨­è¨ç©ºéçæ´æ¸æ°çè§£ãæ­¤å¤ï¼æåæ¾åºå½±é¿ GraphRAG å¯¦ä½æææ§çééµè¨­è¨å ç´ ï¼ä¾å¦åè¡¨è¦ååéç®ææ¬ãééå»£æ³çç¶é©ç ç©¶ï¼æåä½¿ç¨å·ä»£è¡¨æ§çè§£æ±ºæ¹æ¡é¸æä¾å»ºæ§é«åè³ªç GraphRAG å¯¦ä¾ï¼ä¸¦åæå®åå°æª¢ç´¢åæ¨çæè½çå½±é¿ãæåçç ç©¶çµææä¾äºåªå GraphRAG å¯¦ä¾è¨­è¨çéè¦è¦è§£ï¼æçµæå©æ¼æ¨é²æ´æºç¢ºä¸èèçµ¡ç¸éç LLM æç¨ã

##### **MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**
2411.03883v2 by Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders SÃ¸gaard, Carlos Bobed

Question answering is a natural language understanding task that involves
reasoning over both explicit context and unstated, relevant domain knowledge.
Large language models (LLMs), which underpin most contemporary question
answering systems, struggle to induce how concepts relate in specialized
domains such as medicine. Existing medical LLMs are also costly to train. In
this work, we present MEG, a parameter-efficient approach for medical
knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate
graph embeddings into the LLM, enabling it to leverage external knowledge in a
cost-effective way. We evaluate our method on four popular medical
multiple-choice datasets and show that LLMs greatly benefit from the factual
grounding provided by knowledge graph embeddings. MEG attains an average of
+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized
models like BioMistral. We also show results based on Llama-3. Finally, we show
that MEG's performance remains robust to the choice of graph encoder.

æè¦ï¼åç­æ¯èªç¶èªè¨çè§£ä»»åï¼æ¶åå°æç¢ºçä¸ä¸æåæªèªªæçç¸éé åç¥è­é²è¡æ¨çãæ¯æå¤§å¤æ¸ç¶ä»£åç­ç³»çµ±çå¤§åèªè¨æ¨¡å (LLM) é£ä»¥æ¨è«æ¦å¿µå¦ä½å¨é«å­¸ç­å°æ¥­é åä¸­éè¯ãç¾æçé«å­¸ LLM è¨ç·´ææ¬ä¹å¾é«ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº MEGï¼éæ¯ä¸ç¨®ç¨æ¼é«å­¸ç¥è­å¢å¼· LLM çåæ¸æææ¹æ³ãMEG ä½¿ç¨è¼éç´æ å°ç¶²è·¯å°åè¡¨åµå¥æ´åå° LLM ä¸­ï¼ä½¿å¶è½å¤ ä»¥ç¶æ¿ææçæ¹å¼å©ç¨å¤é¨ç¥è­ãæåå¨ååæµè¡çé«å­¸å¤é¸é¡è³æéä¸è©ä¼°äºæåçæ¹æ³ï¼ä¸¦è¡¨æ LLM å¾ç¥è­åè¡¨åµå¥æä¾çå¯¦éä¾æä¸­åçåªæ·ºãMEG å¨ Mistral-Instruct åºæºä¸å¹³åæé«äº +10.2% çæºç¢ºåº¦ï¼å¨ BioMistral ç­å°éæ¨¡åä¸æé«äº +6.7%ãæåéå±ç¤ºäºåºæ¼ Llama-3 ççµæãæå¾ï¼æåè¡¨æ MEG çæ§è½å°åè¡¨ç·¨ç¢¼å¨çé¸æä¿æç©©å¥ã

##### **The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**
2411.03568v1 by Lee Kezar, Nidhi Munikote, Zian Zeng, Zed Sehyr, Naomi Caselli, Jesse Thomason

Language models for American Sign Language (ASL) could make language
technologies substantially more accessible to those who sign. To train models
on tasks such as isolated sign recognition (ISR) and ASL-to-English
translation, datasets provide annotated video examples of ASL signs. To
facilitate the generalizability and explainability of these models, we
introduce the American Sign Language Knowledge Graph (ASLKG), compiled from
twelve sources of expert linguistic knowledge. We use the ASLKG to train
neuro-symbolic models for 3 ASL understanding tasks, achieving accuracies of
91% on ISR, 14% for predicting the semantic features of unseen signs, and 36%
for classifying the topic of Youtube-ASL videos.

æè¦ï¼ç¾åæèª (ASL) çèªè¨æ¨¡åå¯ä»¥è®èªè¨æè¡å°æèªä½¿ç¨èæ´ææ¼ä½¿ç¨ãçºäºè¨ç·´æ¨¡åå·è¡æèªè¾¨è­ (ISR) å ASL è½ææè±æç­ä»»åï¼è³æéæä¾ ASL æå¢çè¨»è§£å½±çç¯ä¾ãçºäºä¿é²éäºæ¨¡åçæ¦æ¬æ§åå¯è§£éæ§ï¼æåå¼å¥äºç¾åæèªç¥è­åè­ (ASLKG)ï¼å®æ¯ç±åäºåå°å®¶èªè¨ç¥è­ä¾æºç·¨è­¯èæçãæåä½¿ç¨ ASLKG è¨ç·´ç¥ç¶ç¬¦èæ¨¡åä¾å·è¡ 3 é  ASL çè§£ä»»åï¼å¨ ISR ä¸éå° 91% çæºç¢ºåº¦ãå¨é æ¸¬æªè¦æå¢çèªç¾©ç¹å¾µä¸éå° 14%ï¼ä»¥åå¨åé¡ YouTube-ASL å½±çä¸»é¡ä¸éå° 36%ã

##### **Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**
2411.02864v1 by Tao Zhang, Ning Yan, Masood Mortazavi, Hoang H. Nguyen, Zhongfen Deng, Philip S. Yu

Large language models (LLMs) pre-trained on massive corpora have demonstrated
impressive few-shot learning capability on many NLP tasks. Recasting an NLP
task into a text-to-text generation task is a common practice so that
generative LLMs can be prompted to resolve it. However, performing
document-level relation extraction (DocRE) tasks with generative LLM models is
still challenging due to the structured output format of DocRE, which
complicates the conversion to plain text. Limited information available in
few-shot samples and prompt instructions induce further difficulties and
challenges in relation extraction for mentioned entities in a document. In this
paper, we represent the structured output as a graph-style triplet rather than
natural language expressions and leverage generative LLMs for the DocRE task.
Our approach, the Graph-DPEP framework is grounded in the reasoning behind
triplet explanation thoughts presented in natural language. In this framework,
we first introduce a ``decomposed-plug" method for performing the generation
from LLMs over prompts with type-space decomposition to alleviate the burden of
distinguishing all relation types. Second, we employ a verifier for calibrating
the generation and identifying overlooked query entity pairs. Third, we develop
"ensemble-play", reapplying generation on the entire type list by leveraging
the reasoning thoughts embedded in a sub-graph associated with the missing
query pair to address the missingness issue. Through extensive comparisons with
existing prompt techniques and alternative Language Models (LLMs), our
framework demonstrates superior performance on publicly available benchmarks in
experiments.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æµ·éèªæåº«ä¸é åè¨ç·´ï¼å·²å¨è¨±å¤èªç¶èªè¨èçä»»åä¸å±ç¾åºä»¤äººå°è±¡æ·±å»çå°éæ¨£æ¬å­¸ç¿è½åãå°èªç¶èªè¨èçä»»åè½åçºæå­å°æå­ççæä»»åæ¯ä¸ç¨®å¸¸è¦åæ³ï¼éæ¨£çæå¼å¤§åèªè¨æ¨¡åå°±å¯ä»¥æç¤ºè§£æ±ºå®ãç¶èï¼ç±æ¼ DocRE ççµæ§åè¼¸åºæ ¼å¼ï¼ä½¿ç¨çæå¼å¤§åèªè¨æ¨¡åä¾å·è¡æä»¶ç´å¥éä¿èå (DocRE) ä»»åä»ç¶å·æææ°æ§ï¼éä½¿å¾è½æçºç´æå­è®å¾è¤éãå°éæ¨£æ¬åæç¤ºèªªæä¸­å¯ç¨çè³è¨æéï¼æå°è´å¨æä»¶ä¸­æå°å¯¦é«çéä¿èåä¸­ç¢çé²ä¸æ­¥çå°é£åææ°ãå¨æ¬æä¸­ï¼æåå°çµæ§åè¼¸åºè¡¨ç¤ºçºåå½¢æ¨£å¼çä¸åçµï¼èä¸æ¯èªç¶èªè¨è¡¨éï¼ä¸¦å©ç¨çæå¼å¤§åèªè¨æ¨¡åä¾å·è¡ DocRE ä»»åãæåçåæ³ï¼åå½¢ DPEP æ¡æ¶ï¼æ¯åºæ¼èªç¶èªè¨ä¸­åç¾çä¸åçµè§£éææ³èå¾çæ¨çãå¨éåæ¡æ¶ä¸­ï¼æåé¦åä»ç´¹ä¸ç¨®ãåè§£æå¥ãæ¹æ³ï¼ç¨æ¼å°å·æé¡åç©ºéåè§£çæç¤ºé²è¡å¤§åèªè¨æ¨¡åçæï¼ä»¥æ¸è¼ååææéä¿é¡åçè² æãå¶æ¬¡ï¼æåä½¿ç¨é©è­å¨ä¾æ ¡æºçæä¸¦è­å¥è¢«å¿½ç¥çæ¥è©¢å¯¦é«å°ãç¬¬ä¸ï¼æåéç¼ãæ´é«éæ²ãï¼ééå©ç¨èéºå¤±æ¥è©¢å°ç¸éçå­åä¸­åµå¥çæ¨çææ³ï¼å¨æ´åé¡ååè¡¨ä¸éæ°æç¨çæï¼ä»¥è§£æ±ºéºå¤±åé¡ãééèç¾ææç¤ºæè¡åæ¿ä»£èªè¨æ¨¡å (LLM) çå»£æ³æ¯è¼ï¼æåçæ¡æ¶å¨å¯¦é©ä¸­è­æäºå¨å¬éåºæºä¸çåªç°æ§è½ã

##### **Multimodal Commonsense Knowledge Distillation for Visual Question Answering**
2411.02722v1 by Shuo Yang, Siwen Luo, Soyeon Caren Han

Existing Multimodal Large Language Models (MLLMs) and Visual Language
Pretrained Models (VLPMs) have shown remarkable performances in the general
Visual Question Answering (VQA). However, these models struggle with VQA
questions that require external commonsense knowledge due to the challenges in
generating high-quality prompts and the high computational costs of
fine-tuning. In this work, we propose a novel graph-based multimodal
commonsense knowledge distillation framework that constructs a unified
relational graph over commonsense knowledge, visual objects and questions
through a Graph Convolutional Network (GCN) following a teacher-student
environment. This proposed framework is flexible with any type of teacher and
student models without further fine-tuning, and has achieved competitive
performances on the ScienceQA dataset.

æè¦ï¼ç¾æçå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) åè¦è¦ºèªè¨é è¨ç·´æ¨¡å (VLPM) å¨ä¸è¬çè¦è¦ºåç­ (VQA) ä¸­å±ç¾äºåè¶çè¡¨ç¾ãç¶èï¼éäºæ¨¡åå¨éè¦å¤é¨å¸¸è­ç¥è­ç VQA åé¡ä¸æéå°å°é£ï¼åå å¨æ¼ç¢çé«åè³ªæç¤ºçææ°ä»¥åå¾®èª¿çé«éç®ææ¬ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åæ°ç©çåºæ¼åå½¢çæ¨¡æå¸¸è­ç¥è­èåæ¶æ§ï¼ééåå½¢å·ç©ç¶²è·¯ (GCN) å¨å¸¸è­ç¥è­ãè¦è¦ºç©ä»¶ååé¡ä¸å»ºæ§ä¸åçµ±ä¸çéè¯åå½¢ï¼éµå¾ªå¸«çç°å¢ãéåæåºçæ¶æ§å°æ¼ä»»ä½é¡åçæå¸«åå­¸çæ¨¡åé½å·æå½æ§ï¼ç¡éé²ä¸æ­¥å¾®èª¿ï¼ä¸¦å¨ ScienceQA è³æéä¸åå¾äºæç«¶ç­åçè¡¨ç¾ã

##### **Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**
2411.02591v2 by Harshavardhana T. Gowda, Zachary D. McNaughton, Lee M. Miller

Each year, millions of individuals lose the ability to speak intelligibly due
to causes such as neuromuscular disease, stroke, trauma, and head/neck cancer
surgery (e.g. laryngectomy) or treatment (e.g. radiotherapy toxicity to the
speech articulators). Effective communication is crucial for daily activities,
and losing the ability to speak leads to isolation, depression, anxiety, and a
host of detrimental sequelae. Noninvasive surface electromyography (sEMG) has
shown promise to restore speech output in these individuals. The goal is to
collect sEMG signals from multiple articulatory sites as people silently
produce speech and then decode the signals to enable fluent and natural
communication. Currently, many fundamental properties of orofacial
neuromuscular signals relating to speech articulation remain unanswered. They
include questions relating to 1) the data structure of the orofacial sEMG
signals, 2)the signal distribution shift of sEMG across individuals, 3) ability
of sEMG signals to span the entire English language phonetic space during
silent speech articulations, and 4) the generalization capability of
non-invasive sEMG based silent speech interfaces. We address these questions
through a series of experiments involving healthy human subjects. We show that
sEMG signals evince graph data structure and that the signal distribution shift
is given by a change of basis. Furthermore, we show that silently voiced
articulations spanning the entire English language phonetic space can be
decoded using small neural networks which can be trained with little data and
that such architectures work well across individuals. To ensure transparency
and reproducibility, we open-source all the data and codes used in this study.

æè¦ï¼æ¯å¹´ï¼æ¸ç¾è¬äººå ç¥ç¶èèç¾çãä¸­é¢¨ãåµå·ãé ­é ¸çæè¡ï¼ä¾å¦ååé¤è¡ï¼ææ²»çï¼ä¾å¦æ¾å°æ²»çå°è¨èªæ§é³å¨å®çæ¯æ§ï¼èå¤±å»æ¸æ°èªªè©±çè½åãææçæºéå°æ¼æ¥å¸¸æ´»åè³ééè¦ï¼èå¤±å»èªªè©±çè½åæå°è´å­¤ç«ãæ²®åªãç¦æ®åä¸ç³»åæå®³çå¾éºçãéä¾µå¥æ§è¡¨é¢èé»å (sEMG) å·²é¡¯ç¤ºåºæ¢å¾©éäºäººèªªè©±è¼¸åºçå¸æãç®æ¨æ¯å¾å¤åæ§é³é¨ä½æ¶é sEMG ä¿¡èï¼å çºäººåå¨ç¡è²å°ç¼é³ï¼ç¶å¾è§£ç¢¼ä¿¡èä»¥å¯¦ç¾æµå©èèªç¶çæºéãç®åï¼è¨±å¤èè¨èªæ§é³æéçé¢é¨ç¥ç¶èèä¿¡èçåºæ¬ç¹æ§ä»æªå¾å°è§£ç­ãå®ååæ¬è 1) é¢é¨ sEMG ä¿¡èçæ¸æçµæ§ã2) sEMG å¨åäººä¹éçä¿¡èåä½è½ç§»ã3) sEMG ä¿¡èå¨ç¡è²è¨èªæ§é³éç¨ä¸­è·¨è¶æ´åè±èªèªé³ç©ºéçè½åä»¥å 4) åºæ¼éä¾µå¥æ§ sEMG çç¡è²è¨èªä»é¢çæ³åè½åç¸éçåé¡ãæåééä¸ç³»åæ¶åå¥åº·äººé¡åè©¦èçå¯¦é©ä¾è§£æ±ºéäºåé¡ãæåè¡¨æ sEMG ä¿¡èè¡¨ç¾åºåæ¸æçµæ§ï¼ä¸¦ä¸ä¿¡èåä½è½ç§»æ¯ç±åºè®åççµ¦åºçãæ­¤å¤ï¼æåè¡¨æï¼ä½¿ç¨å¯ä»¥ééå°éæ¸æè¨ç·´çå°ç¥ç¶ç¶²è·¯å¯ä»¥è§£ç¢¼è·¨è¶æ´åè±èªèªé³ç©ºéçç¡è²ç¼é³ï¼ä¸¦ä¸éç¨®æ¶æ§å¨ä¸ååé«ä¹éé½è½å¾å¥½å°å·¥ä½ãçºäºç¢ºä¿éæåº¦åå¯è¤è£½æ§ï¼æåå¬éäºæ¬ç ç©¶ä¸­ä½¿ç¨çæææ¸æåä»£ç¢¼ã

##### **GraphXAIN: Narratives to Explain Graph Neural Networks**
2411.02540v2 by Mateusz Cedro, David Martens

Graph Neural Networks (GNNs) are a powerful technique for machine learning on
graph-structured data, yet they pose interpretability challenges, especially
for non-expert users. Existing GNN explanation methods often yield technical
outputs such as subgraphs and feature importance scores, which are not easily
understood. Building on recent insights from social science and other
Explainable AI (XAI) methods, we propose GraphXAIN, a natural language
narrative that explains individual predictions made by GNNs. We present a
model-agnostic and explainer-agnostic XAI approach that complements graph
explainers by generating GraphXAINs, using Large Language Models (LLMs) and
integrating graph data, individual predictions from GNNs, explanatory
subgraphs, and feature importances. We define XAI Narratives and XAI
Descriptions, highlighting their distinctions and emphasizing the importance of
narrative principles in effective explanations. By incorporating natural
language narratives, our approach supports graph practitioners and non-expert
users, aligning with social science research on explainability and enhancing
user understanding and trust in complex GNN models. We demonstrate GraphXAIN's
capabilities on a real-world graph dataset, illustrating how its generated
narratives can aid understanding compared to traditional graph explainer
outputs or other descriptive explanation methods.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) æ¯ç¨æ¼åå½¢çµæ§è³æçæ©å¨å­¸ç¿å¼·å¤§æè¡ï¼ä½å®åæé æå¯è§£éæ§ææ°ï¼ç¹å¥æ¯å°æ¼éå°å®¶ä½¿ç¨èãç¾æç GNN è§£éæ¹æ³éå¸¸æç¢çæè¡è¼¸åºï¼ä¾å¦å­ååç¹å¾µéè¦æ§åæ¸ï¼éäºè¼¸åºä¸å®¹æçè§£ãå»ºæ§æ¼ç¤¾æç§å­¸åå¶ä»å¯è§£é AI (XAI) æ¹æ³çææ°è¦è§£ï¼æåæåº GraphXAINï¼éæ¯ä¸ç¨®èªç¶èªè¨æè¿°ï¼å¯ä»¥è§£é GNN ååºçåå¥é æ¸¬ãæåæåºä¸åèæ¨¡åç¡éä¸èè§£éå¨ç¡éç XAI æ¹æ³ï¼å®ééä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) åæ´ååå½¢è³æãGNN çåå¥é æ¸¬ãèªªææ§å­ååç¹å¾µéè¦æ§ä¾è£ååå½¢è§£éå¨ï¼é²èç¢ç GraphXAINãæåå®ç¾© XAI æè¿°å XAI æè¿°ï¼å¼·èª¿å®åçåå¥ï¼ä¸¦å¼·èª¿æè¿°ååå¨ææè§£éä¸­çéè¦æ§ãééçµåèªç¶èªè¨æè¿°ï¼æåçåæ³æ¯æ´åå½¢å¾æ¥­èåéå°å®¶ä½¿ç¨èï¼èå¯è§£éæ§çç¤¾æç§å­¸ç ç©¶ä¿æä¸è´ï¼ä¸¦å¢å¼·ä½¿ç¨èå°è¤é GNN æ¨¡åççè§£åä¿¡ä»»ãæåå¨çå¯¦ä¸çåå½¢è³æéä¸å±ç¤º GraphXAIN çåè½ï¼èªªæèå³çµ±åå½¢è§£éå¨è¼¸åºæå¶ä»æè¿°æ§è§£éæ¹æ³ç¸æ¯ï¼å¶ç¢ççæè¿°å¦ä½æå©æ¼çè§£ã

##### **Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**
2411.02382v1 by Guangzhi Xiong, Eric Xie, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang

Large language models (LLMs) have demonstrated remarkable capabilities in
various scientific domains, from natural language processing to complex
problem-solving tasks. Their ability to understand and generate human-like text
has opened up new possibilities for advancing scientific research, enabling
tasks such as data analysis, literature review, and even experimental design.
One of the most promising applications of LLMs in this context is hypothesis
generation, where they can identify novel research directions by analyzing
existing knowledge. However, despite their potential, LLMs are prone to
generating ``hallucinations'', outputs that are plausible-sounding but
factually incorrect. Such a problem presents significant challenges in
scientific fields that demand rigorous accuracy and verifiability, potentially
leading to erroneous or misleading conclusions. To overcome these challenges,
we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that
enhances LLM hypothesis generation by integrating external, structured
knowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured
reasoning process, organizing their output as a chain of ideas (CoI), and
includes a KG-supported module for the detection of hallucinations. With
experiments on our newly constructed hypothesis generation dataset, we
demonstrate that KG-CoI not only improves the accuracy of LLM-generated
hypotheses but also reduces the hallucination in their reasoning chains,
highlighting its effectiveness in advancing real-world scientific research.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ç§å­¸é åå±ç¾åè¶çè½åï¼å¾èªç¶èªè¨èçå°è¤éçè§£æ±ºåé¡ä»»åãå®åçè§£åç¢çé¡ä¼¼äººé¡æå­çè½åçºæ¨é²ç§å­¸ç ç©¶éåäºæ°çå¯è½æ§ï¼è®è³æåæãæç»åé¡§ï¼çè³å¯¦é©è¨­è¨ç­ä»»åæçºå¯è½ãLLM å¨æ­¤èçµ¡ä¸­ææå¸æçæç¨ä¹ä¸æ¯åè¨­ç¢çï¼å®åè½ééåæç¾æç¥è­ä¾æ¾åºæ°çç ç©¶æ¹åãç¶èï¼åç®¡ LLM å·ææ½åï¼å®åå»å®¹æç¢çãå¹»è¦ºãï¼ä¹å°±æ¯è½èµ·ä¾åçä½äºå¯¦ä¸ä¸æ­£ç¢ºçè¼¸åºãæ­¤é¡åé¡å¨éè¦å´è¬¹æºç¢ºæ§åå¯é©è­æ§çç§å­¸é åä¸­æé æéå¤§ææ°ï¼æå¯è½å°è´é¯èª¤æèª¤å°æ§ççµè«ãçºäºåæéäºææ°ï¼æåæåº KG-CoIï¼ç¥è­åºç¤è§å¿µéï¼ï¼éæ¯ä¸ååµæ°çç³»çµ±ï¼å®ééæ´åç¥è­åè­ (KG) ä¸­çå¤é¨çµæ§åç¥è­ä¾å¢å¼· LLM åè¨­ç¢çãKG-CoI å¼å° LLM é²è¡çµæ§åæ¨çç¨åºï¼å°å¶è¼¸åºæ´çæè§å¿µé (CoI)ï¼ä¸¦åå«ä¸åç± KG æ¯æ´çæ¨¡çµä¾åµæ¸¬å¹»è¦ºãééæåæ°å»ºç«çåè¨­ç¢çè³æéé²è¡çå¯¦é©ï¼æåè­æ KG-CoI ä¸åæ¹åäº LLM ç¢ççåè¨­çæºç¢ºæ§ï¼ä¹æ¸å°äºå¶æ¨çéä¸­çå¹»è¦ºï¼çªé¡¯äºå¶å¨æ¨é²ç¾å¯¦ä¸çç§å­¸ç ç©¶ä¸­çæè½ã

##### **QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain**
2411.08724v1 by Qikai Wei, Mingzhi Yang, Chunlong Han, Jingfu Wei, Minghao Zhang, Feifei Shi, Huansheng Ning

Retrieval-Augmented Generation (RAG) mitigates the issue of hallucination in
Large Language Models (LLMs) by integrating information retrieval techniques.
However, in the tourism domain, since the query is usually brief and the
content in the database is diverse, existing RAG may contain a significant
amount of irrelevant or contradictory information contents after retrieval. To
address this challenge, we propose the QCG-Rerank model. This model first
performs an initial retrieval to obtain candidate chunks and then enhances
semantics by extracting critical information to expand the original query.
Next, we utilize the expanded query and candidate chunks to calculate
similarity scores as the initial transition probability and construct the
chunks graph. Subsequently, We iteratively compute the transition probabilities
based on an initial estimate until convergence. The chunks with the highest
score are selected and input into the LLMs to generate responses. We evaluate
the model on Cultour, IIRC, StrategyQA, HotpotQA, SQuAD, and MuSiQue datasets.
The experimental results demonstrate the effectiveness and superiority of the
QCG-Rerank method.

æè¦ï¼æ·åå¢å¼·çæï¼RAGï¼ééæ´åè³è¨æ·åæè¡ä¾ç·©è§£å¤§åèªè¨æ¨¡åï¼LLMï¼ä¸­çå¹»è¦ºåé¡ãç¶èï¼å¨æéé åä¸­ï¼ç±æ¼æ¥è©¢éå¸¸å¾ç°¡ç­ï¼èè³æåº«ä¸­çå§å®¹å¤æ¨£ï¼å æ­¤ç¾æç RAG å¯è½æå¨æ·åå¾åå«å¤§éä¸ç¸éæçç¾çè³è¨å§å®¹ãçºäºæå°éåææ°ï¼æåæåºäº QCG-Rerank æ¨¡åãæ­¤æ¨¡åé¦åå·è¡åå§æ·åä»¥åå¾åé¸åå¡ï¼ç¶å¾ééæ·åééµè³è¨ä¾æ´ååå§æ¥è©¢ä»¥å¢å¼·èªæãæ¥èï¼æåå©ç¨æ´åçæ¥è©¢ååé¸åå¡ä¾è¨ç®ç¸ä¼¼åº¦åæ¸ä½çºåå§è½ç§»æ©çï¼ä¸¦å»ºæ§åå¡åãé¨å¾ï¼æåæ ¹æåå§ä¼°è¨åè¦è¨ç®è½ç§»æ©çï¼ç´å°æ¶æãæé¸ååæ¸æé«çåå¡ï¼ä¸¦è¼¸å¥å° LLM ä»¥ç¢çåæãæåå¨ CultourãIIRCãStrategyQAãHotpotQAãSQuAD å MuSiQue è³æéä¸è©ä¼°æ­¤æ¨¡åãå¯¦é©çµæè­æäº QCG-Rerank æ¹æ³çæææ§ååªè¶æ§ã

##### **Can Language Models Enable In-Context Database?**
2411.01807v1 by Yu Pan, Hongfeng Yu, Tianjiao Zhao, Jianxin Sun

Large language models (LLMs) are emerging as few-shot learners capable of
handling a variety of tasks, including comprehension, planning, reasoning,
question answering, arithmetic calculations, and more. At the core of these
capabilities is LLMs' proficiency in representing and understanding structural
or semi-structural data, such as tables and graphs. Numerous studies have
demonstrated that reasoning on tabular data or graphs is not only feasible for
LLMs but also gives a promising research direction which treats these data as
in-context data. The lightweight and human readable characteristics of
in-context database can potentially make it an alternative for the traditional
database in typical RAG (Retrieval Augmented Generation) settings. However,
almost all current work focuses on static in-context data, which does not allow
dynamic update. In this paper, to enable dynamic database update, delta
encoding of database is proposed. We explore how data stored in traditional
RDBMS can be encoded as in-context text and evaluate LLMs' proficiency for CRUD
(Create, Read, Update and Delete) operations on in-context databases. A
benchmark named InConDB is presented and extensive experiments are conducted to
show the performance of different language models in enabling in-context
database by varying the database encoding method, prompting method, operation
type and input data distribution, revealing both the proficiency and
limitations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) éæ¼¸æçºåéå°éç¯ä¾å°±è½èçåç¨®ä»»åçå­¸ç¿èï¼åæ¬çè§£ãè¦åãæ¨çãåç­ãç®è¡è¨ç®ç­ãéäºè½åçæ ¸å¿æ¯ LLM å¨è¡¨ç¤ºåçè§£çµæ§åæåçµæ§åè³æï¼ä¾å¦è¡¨æ ¼ååå½¢ï¼æ¹é¢çè½åãè¨±å¤ç ç©¶å·²è­æï¼LLM ä¸åå¯ä»¥æ¨è«è¡¨æ ¼è³ææåå½¢ï¼éæä¾äºä¸åæåæ¯çç ç©¶æ¹åï¼å°éäºè³æè¦çºèªå¢è³æãèªå¢è³æåº«çè¼éç´åäººé¡å¯è®åç¹æ§æå¯è½ä½¿å¶æçºå¸å RAGï¼æª¢ç´¢æ´åçæï¼è¨­å®ä¸­å³çµ±è³æåº«çæ¿ä»£æ¹æ¡ãç¶èï¼å¹¾ä¹ææç®åçå·¥ä½é½å°æ³¨æ¼éæèªå¢è³æï¼éä¸åè¨±åææ´æ°ãå¨æ¬æä¸­ï¼çºäºå¯¦ç¾åæè³æåº«æ´æ°ï¼æåºäºè³æåº«ç delta ç·¨ç¢¼ãæåæ¢è¨äºå¦ä½å°å²å­å¨å³çµ± RDBMS ä¸­çè³æç·¨ç¢¼çºèªå¢æå­ï¼ä¸¦è©ä¼° LLM å¨èªå¢è³æåº«ä¸é²è¡ CRUDï¼å»ºç«ãè®åãæ´æ°ååªé¤ï¼æä½çè½åãæåºäºåçº InConDB çåºæºï¼ä¸¦é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥é¡¯ç¤ºä¸åèªè¨æ¨¡åå¨ééæ¹è®è³æåº«ç·¨ç¢¼æ¹æ³ãæç¤ºæ¹æ³ãæä½é¡ååè¼¸å¥è³æåä½ä¾åç¨èªå¢è³æåº«æ¹é¢çæè½ï¼æ­ç¤ºäºè½ååéå¶ã

##### **Graph-based Confidence Calibration for Large Language Models**
2411.02454v1 by Yukun Li, Sijia Wang, Lifu Huang, Li-Ping Liu

One important approach to improving the reliability of large language models
(LLMs) is to provide accurate confidence estimations regarding the correctness
of their answers. However, developing a well-calibrated confidence estimation
model is challenging, as mistakes made by LLMs can be difficult to detect. We
propose a novel method combining the LLM's self-consistency with labeled data
and training an auxiliary model to estimate the correctness of its responses to
questions. This auxiliary model predicts the correctness of responses based
solely on their consistent information. To set up the learning problem, we use
a weighted graph to represent the consistency among the LLM's multiple
responses to a question. Correctness labels are assigned to these responses
based on their similarity to the correct answer. We then train a graph neural
network to estimate the probability of correct responses. Experiments
demonstrate that the proposed approach substantially outperforms several of the
most recent methods in confidence calibration across multiple widely adopted
benchmark datasets. Furthermore, the proposed approach significantly improves
the generalization capability of confidence calibration on out-of-domain (OOD)
data.

æè¦ï¼ä¸ç¨®æ¹åå¤§åèªè¨æ¨¡å (LLM) å¯é æ§çéè¦æ¹æ³æ¯æä¾æéå¶ç­æ¡æ­£ç¢ºæ§çæºç¢ºä¿¡å¿ä¼°è¨ãç¶èï¼éç¼ä¸åæ ¡æºè¯å¥½çä¿¡å¿ä¼°è¨æ¨¡åå·æææ°æ§ï¼å çº LLM æç¯çé¯èª¤å¯è½é£ä»¥åµæ¸¬ãæåæåºä¸åæ°æ¹æ³ï¼çµå LLM çèªæä¸è´æ§èæ¨ç±¤è³æï¼ä¸¦è¨ç·´ä¸åè¼å©æ¨¡åä¾ä¼°è¨å¶å°åé¡çåææ­£ç¢ºæ§ãéåè¼å©æ¨¡ååæ ¹æå¶ä¸è´æ§è³è¨ä¾é æ¸¬åæçæ­£ç¢ºæ§ãçºäºè¨­å®å­¸ç¿åé¡ï¼æåä½¿ç¨ä¸åå æ¬åå½¢ä¾è¡¨ç¤º LLM å°ä¸ååé¡çå¤æ¬¡åæä¹éçä¸è´æ§ãæ­£ç¢ºæ§æ¨ç±¤ææ ¹æéäºåæèæ­£ç¢ºç­æ¡çç¸ä¼¼æ§åéçµ¦éäºåæãç¶å¾ï¼æåè¨ç·´ä¸ååå½¢ç¥ç¶ç¶²è·¯ä¾ä¼°è¨æ­£ç¢ºåæçæ©çãå¯¦é©è­æï¼ææåºçæ¹æ³å¨å¤åå»£æ³æ¡ç¨çåºæºè³æéä¸ï¼å¨ä¿¡å¿æ ¡æºæ¹é¢æé¡¯åªæ¼å¤ç¨®ææ°æ¹æ³ãæ­¤å¤ï¼ææåºçæ¹æ³é¡¯èæ¹åäºå¨é åå¤ (OOD) è³æä¸ä¿¡å¿æ ¡æºçæ³åè½åã

##### **Ontology Population using LLMs**
2411.01612v1 by Sanaz Saki Norouzi, Adrita Barua, Antrea Christou, Nikita Gautam, Andrew Eells, Pascal Hitzler, Cogan Shimizu

Knowledge graphs (KGs) are increasingly utilized for data integration,
representation, and visualization. While KG population is critical, it is often
costly, especially when data must be extracted from unstructured text in
natural language, which presents challenges, such as ambiguity and complex
interpretations. Large Language Models (LLMs) offer promising capabilities for
such tasks, excelling in natural language understanding and content generation.
However, their tendency to ``hallucinate'' can produce inaccurate outputs.
Despite these limitations, LLMs offer rapid and scalable processing of natural
language data, and with prompt engineering and fine-tuning, they can
approximate human-level performance in extracting and structuring data for KGs.
This study investigates LLM effectiveness for the KG population, focusing on
the Enslaved.org Hub Ontology. In this paper, we report that compared to the
ground truth, LLM's can extract ~90% of triples, when provided a modular
ontology as guidance in the prompts.

æè¦ï¼ç¥è­åè­ (KG) æä¾æå¤ç¨æ¼è³ææ´åãè¡¨ç¤ºåè¦è¦ºåãåç®¡ KG å¡«åè³ééè¦ï¼ä½å®éå¸¸å¾æè²´ï¼ç¹å¥æ¯å¨å¿é å¾èªç¶èªè¨ä¸­éçµæ§åæå­ä¸­æåè³ææï¼éæå¸¶ä¾ææ°ï¼ä¾å¦æ­§ç¾©åè¤éçè©®éãå¤§åèªè¨æ¨¡å (LLM) çºæ­¤é¡ä»»åæä¾äºæåæ¯çè½åï¼æé·èªç¶èªè¨çè§£åå§å®¹çæãç¶èï¼å®åãç¢çå¹»è¦ºãçå¾åå¯è½æç¢çä¸æºç¢ºçè¼¸åºãåç®¡æéäºéå¶ï¼LLM æä¾äºèªç¶èªè¨è³æçå¿«éä¸å¯æ´åèçï¼ä¸¦ä¸ééæç¤ºå·¥ç¨åå¾®èª¿ï¼å®åå¯ä»¥è¿ä¼¼äººé¡å±¤ç´çæè½ï¼ä»¥æååå»ºæ§ KG çè³æãæ¬ç ç©¶èª¿æ¥ LLM å° KG å¡«åçæææ§ï¼éé»éæ³¨ Enslaved.org Hub Ontologyãå¨æ¬æä¸­ï¼æåå ±åèçå¯¦ææ³ç¸æ¯ï¼ç¶å¨æç¤ºä¸­æä¾æ¨¡çµåæ¬ä½ä½çºæå°æï¼LLM å¯ä»¥æåç´ 90% çä¸åçµã

##### **Pre-trained Molecular Language Models with Random Functional Group Masking**
2411.01401v1 by Tianhao Peng, Yuchen Li, Xuhong Li, Jiang Bian, Zeke Xie, Ning Sui, Shahid Mumtaz, Yanwu Xu, Linghe Kong, Haoyi Xiong

Recent advancements in computational chemistry have leveraged the power of
trans-former-based language models, such as MoLFormer, pre-trained using a vast
amount of simplified molecular-input line-entry system (SMILES) sequences, to
understand and predict molecular properties and activities, a critical step in
fields like drug discovery and materials science. To further improve
performance, researchers have introduced graph neural networks with graph-based
molecular representations, such as GEM, incorporating the topology, geometry,
2D or even 3D structures of molecules into pre-training. While most of
molecular graphs in existing studies were automatically converted from SMILES
sequences, it is to assume that transformer-based language models might be able
to implicitly learn structure-aware representations from SMILES sequences. In
this paper, we propose \ours{} -- a SMILES-based \underline{\em M}olecular
\underline{\em L}anguage \underline{\em M}odel, which randomly masking SMILES
subsequences corresponding to specific molecular \underline{\em F}unctional
\underline{\em G}roups to incorporate structure information of atoms during the
pre-training phase. This technique aims to compel the model to better infer
molecular structures and properties, thus enhancing its predictive
capabilities. Extensive experimental evaluations across 11 benchmark
classification and regression tasks in the chemical domain demonstrate the
robustness and superiority of \ours{}. Our findings reveal that \ours{}
outperforms existing pre-training models, either based on SMILES or graphs, in
9 out of the 11 downstream tasks, ranking as a close second in the remaining
ones.

æè¦ï¼<paragraph>è¨ç®åå­¸çè¿æé²å±å·²å©ç¨è½æå¨èªè¨æ¨¡åçåéï¼ä¾å¦ MoLFormerï¼ä½¿ç¨å¤§éç°¡ååå­è¼¸å¥ç·æ¢è¼¸å¥ç³»çµ± (SMILES) åºåé²è¡é è¨ç·´ï¼ä»¥äºè§£åé æ¸¬åå­ç¹æ§åæ´»æ§ï¼éæ¯è¥ç©ç¼ç¾åææç§å­¸ç­é åçéè¦æ­¥é©ãçºäºé²ä¸æ­¥æåæè½ï¼ç ç©¶äººå¡å¼å¥äºå·æåå½¢çºåºç¤çåå­è¡¨ç¤ºçåå½¢ç¥ç¶ç¶²è·¯ï¼ä¾å¦ GEMï¼å°åå­çææ¨¸ãå¹¾ä½ã2D çè³ 3D çµæ§ç´å¥é è¨ç·´ä¸­ãéç¶ç¾æç ç©¶ä¸­çå¤§å¤æ¸åå­åå½¢é½æ¯å¾ SMILES åºåèªåè½æèä¾çï¼ä½å¯ä»¥åè¨­åºæ¼è½æå¨çèªè¨æ¨¡åå¯è½è½å¤ å¾ SMILES åºåä¸­é±å¼å­¸ç¿çµæ§æç¥è¡¨ç¤ºãå¨æ¬æä¸­ï¼æåæåº \ours{} -- ä¸ååºæ¼ SMILES ç\underline{\em M}olecular\underline{\em L}anguage \underline{\em M}odelï¼å®é¨æ©é®è½å°ææ¼ç¹å®åå­\underline{\em F}unctional\underline{\em G}roups ç SMILES å­åºåï¼ä»¥å¨é è¨ç·´éæ®µç´å¥åå­ççµæ§è³è¨ãæ­¤æè¡æ¨å¨å¼·å¶æ¨¡åæ´å¥½å°æ¨æ·åå­çµæ§åç¹æ§ï¼å¾èå¢å¼·å¶é æ¸¬è½åãå¨åå­¸é åç 11 ååºæºåé¡ååæ­¸ä»»åä¸­é²è¡çå»£æ³å¯¦é©è©ä¼°è­æäº \ours{} çç©©å¥æ§ååªè¶æ§ãæåçç ç©¶çµæé¡¯ç¤ºï¼\ours{} å¨ 11 åä¸æ¸¸ä»»åä¸­ç 9 åä»»åä¸­åªæ¼ç¾æçé è¨ç·´æ¨¡åï¼åºæ¼ SMILES æåå½¢ï¼ï¼å¨å©ä¸çä»»åä¸­æåç¬¬äºã</paragraph>

##### **Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models**
2411.02435v1 by Xinyi Leng, Jason Liang, Jack Mauro, Xu Wang, Andrea L. Bertozzi, James Chapman, Junyuan Lin, Bohan Chen, Chenchen Ye, Temple Daniel, P. Jeffrey Brantingham

Narrative data spans all disciplines and provides a coherent model of the
world to the reader or viewer. Recent advancement in machine learning and Large
Language Models (LLMs) have enable great strides in analyzing natural language.
However, Large language models (LLMs) still struggle with complex narrative
arcs as well as narratives containing conflicting information. Recent work
indicates LLMs augmented with external knowledge bases can improve the accuracy
and interpretability of the resulting models. In this work, we analyze the
effectiveness of applying knowledge graphs (KGs) in understanding true-crime
podcast data from both classical Natural Language Processing (NLP) and LLM
approaches. We directly compare KG-augmented LLMs (KGLLMs) with classical
methods for KG construction, topic modeling, and sentiment analysis.
Additionally, the KGLLM allows us to query the knowledge base in natural
language and test its ability to factually answer questions. We examine the
robustness of the model to adversarial prompting in order to test the model's
ability to deal with conflicting information. Finally, we apply classical
methods to understand more subtle aspects of the text such as the use of
hearsay and sentiment in narrative construction and propose future directions.
Our results indicate that KGLLMs outperform LLMs on a variety of metrics, are
more robust to adversarial prompts, and are more capable of summarizing the
text into topics.

æè¦ï¼æäºè³ææ¶µèææå­¸ç§ï¼ä¸¦çºè®èæè§ç¾æä¾ä¸åé£è²«çä¸çæ¨¡åãæ©å¨å­¸ç¿åå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å¨åæèªç¶èªè¨æ¹é¢åå¾äºé·è¶³çé²æ­¥ãç¶èï¼å¤§åèªè¨æ¨¡å (LLM) ä»ç¶é£ä»¥æä»è¤éçæäºå¼§ç·ä»¥ååå«ç¸äºçç¾è³è¨çæäºãæè¿çç ç©¶è¡¨æï¼ä½¿ç¨å¤é¨ç¥è­åº«å¢å¼·ç LLM å¯ä»¥æé«æç¢çæ¨¡åçæºç¢ºæ§åå¯è§£éæ§ãå¨éé å·¥ä½ä¸­ï¼æååæäºå¨å¾å³çµ±èªç¶èªè¨èç (NLP) å LLM æ¹æ³ä¸­çè§£çå¯¦ç¯ç½ªæ­å®¢è³ææï¼æç¨ç¥è­åè­ (KG) çæææ§ãæåç´æ¥æ¯è¼äº KG å¢å¼·ç LLM (KGLLM) èç¨æ¼ KG å»ºæ§ãä¸»é¡å»ºæ¨¡åæç·åæçå³çµ±æ¹æ³ãæ­¤å¤ï¼KGLLM åè¨±æåä»¥èªç¶èªè¨æ¥è©¢ç¥è­åº«ï¼ä¸¦æ¸¬è©¦å¶äºå¯¦åç­åé¡çè½åãæåæª¢æ¥äºæ¨¡åå°å°ææ§æç¤ºçç©©å¥æ§ï¼ä»¥æ¸¬è©¦æ¨¡åèçç¸äºçç¾è³è¨çè½åãæå¾ï¼æåæç¨å³çµ±æ¹æ³ä¾çè§£ææ¬çæ´ç´°å¾®æ¹é¢ï¼ä¾å¦å¨æäºå»ºæ§ä¸­ä½¿ç¨éè½éèªªåæç·ï¼ä¸¦æåºæªä¾çæ¹åãæåççµæè¡¨æï¼KGLLM å¨åç¨®ææ¨ä¸åªæ¼ LLMï¼å°å°ææç¤ºæ´ç©©å¥ï¼ä¸¦ä¸æ´è½å¤ å°ææ¬ç¸½çµçºä¸»é¡ã

##### **WLPlan: Relational Features for Symbolic Planning**
2411.00577v1 by Dillon Z. Chen

Scalable learning for planning research generally involves juggling between
different programming languages for handling learning and planning modules
effectively. Interpreted languages such as Python are commonly used for
learning routines due to their ease of use and the abundance of highly
maintained learning libraries they exhibit, while compiled languages such as
C++ are used for planning routines due to their optimised resource usage.
Motivated by the need for tools for developing scalable learning planners, we
introduce WLPlan, a C++ package with Python bindings which implements recent
promising work for automatically generating relational features of planning
tasks. Such features can be used for any downstream routine, such as learning
domain control knowledge or probing and understanding planning tasks. More
specifically, WLPlan provides functionality for (1) transforming planning tasks
into graphs, and (2) embedding planning graphs into feature vectors via graph
kernels. The source code and instructions for the installation and usage of
WLPlan are available at tinyurl.com/42kymswc

æè¦ï¼å¯æ´åçå­¸ç¿è¦åç ç©¶éå¸¸éè¦å¨ä¸åçç¨å¼èªè¨ä¹éåæï¼æè½ææå°èçå­¸ç¿åè¦åæ¨¡çµãä¾å¦ Python ç­ç´è­¯èªè¨éå¸¸ç¨æ¼å­¸ç¿å¸¸å¼ï¼å çºå®åææ¼ä½¿ç¨ï¼ä¸æè¨±å¤ç¶­è­·å®åçå­¸ç¿å½å¼åº«ï¼èä¾å¦ C++ ç­ç·¨è­¯èªè¨åç¨æ¼è¦åå¸¸å¼ï¼å çºå®åè½æä½³åè³æºä½¿ç¨ãç±æ¼éè¦éç¼å¯æ´åå­¸ç¿è¦åå¨çå·¥å·ï¼æåå¼é²äº WLPlanï¼éæ¯ä¸åå·æ Python ç¹«çµç C++ å¥ä»¶ï¼å¯¦ä½äºè¿ææåéçèªåç¢çè¦åä»»åéä¿ç¹å¾µçå·¥ä½ãæ­¤é¡ç¹å¾µå¯ç¨æ¼ä»»ä½ä¸æ¸¸å¸¸å¼ï¼ä¾å¦å­¸ç¿é åæ§å¶ç¥è­ææ¢æ¸¬åçè§£è¦åä»»åãæ´å·é«å°èªªï¼WLPlan æä¾äºä»¥ä¸åè½ï¼(1) å°è¦åä»»åè½æçºåå½¢ï¼ä»¥å (2) ééåå½¢æ ¸å°è¦ååå½¢åµå¥ç¹å¾µåéãWLPlan çåå§ç¢¼åå®è£åä½¿ç¨èªªæå¯å¨ tinyurl.com/42kymswc åå¾

##### **GRS-QA -- Graph Reasoning-Structured Question Answering Dataset**
2411.00369v3 by Anish Pahilajani, Devasha Trivedi, Jincen Shuai, Khin S. Yone, Samyak Rajesh Jain, Namyong Park, Ryan A. Rossi, Nesreen K. Ahmed, Franck Dernoncourt, Yu Wang

Large Language Models (LLMs) have excelled in multi-hop question-answering
(M-QA) due to their advanced reasoning abilities. However, the impact of the
inherent reasoning structures on LLM M-QA performance remains unclear, largely
due to the absence of QA datasets that provide fine-grained reasoning
structures. To address this gap, we introduce the Graph Reasoning-Structured
Question Answering Dataset (GRS-QA), which includes both semantic contexts and
reasoning structures for QA pairs. Unlike existing M-QA datasets, where
different reasoning structures are entangled together, GRS-QA explicitly
captures intricate reasoning pathways by constructing reasoning graphs, where
nodes represent textual contexts and edges denote logical flows. These
reasoning graphs of different structures enable a fine-grained evaluation of
LLM reasoning capabilities across various reasoning structures. Our empirical
analysis reveals that LLMs perform differently when handling questions with
varying reasoning structures. This finding facilitates the exploration of
textual structures as compared with semantics.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç±æ¼å¶åé²çæ¨çè½åï¼å¨å¤è·³åç­ (M-QA) ä¸­è¡¨ç¾åºè²ãç¶èï¼åºææ¨ççµæ§å° LLM M-QA æè½çå½±é¿ä»ä¸æ¸æ¥ï¼éä¸»è¦æ¯ç±æ¼ç¼ºä¹æä¾ç´°ç²åº¦æ¨ççµæ§ç QA è³æéãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºåå½¢æ¨ççµæ§ååç­è³æé (GRS-QA)ï¼å¶ä¸­åå«èªç¾©èçµ¡å QA å°æçæ¨ççµæ§ãèç¾æç M-QA è³æéä¸åï¼å¶ä¸­ä¸åçæ¨ççµæ§ç³¾çºå¨ä¸èµ·ï¼GRS-QA ééå»ºæ§æ¨çåå½¢æç¢ºææè¤éçæ¨çè·¯å¾ï¼å¶ä¸­ç¯é»è¡¨ç¤ºæå­èçµ¡ï¼éç·£è¡¨ç¤ºéè¼¯æµç¨ãéäºä¸åçµæ§çæ¨çåå½¢è½å¤ ç´°ç·»å°è©ä¼° LLM å¨åç¨®æ¨ççµæ§ä¸­çæ¨çè½åãæåçå¯¦è­åæé¡¯ç¤ºï¼LLM å¨èçå·æä¸åæ¨ççµæ§çåé¡æè¡¨ç¾ä¸åãéåç¼ç¾ä¿é²äºå°æå­çµæ§èèªç¾©çæ¯è¼æ¢ç´¢ã

##### **Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**
2411.02523v1 by Balu Bhasuran, Qiao Jin, Yuzhang Xie, Carl Yang, Karim Hanna, Jennifer Costa, Cindy Shavor, Zhiyong Lu, Zhe He

Differential diagnosis is crucial for medicine as it helps healthcare
providers systematically distinguish between conditions that share similar
symptoms. This study assesses the impact of lab test results on differential
diagnoses (DDx) made by large language models (LLMs). Clinical vignettes from
50 case reports from PubMed Central were created incorporating patient
demographics, symptoms, and lab results. Five LLMs GPT-4, GPT-3.5, Llama-2-70b,
Claude-2, and Mixtral-8x7B were tested to generate Top 10, Top 5, and Top 1 DDx
with and without lab data. A comprehensive evaluation involving GPT-4, a
knowledge graph, and clinicians was conducted. GPT-4 performed best, achieving
55% accuracy for Top 1 diagnoses and 60% for Top 10 with lab data, with lenient
accuracy up to 80%. Lab results significantly improved accuracy, with GPT-4 and
Mixtral excelling, though exact match rates were low. Lab tests, including
liver function, metabolic/toxicology panels, and serology/immune tests, were
generally interpreted correctly by LLMs for differential diagnosis.

æè¦ï¼éå¥è¨ºæ·å°æ¼é«å­¸è³ééè¦ï¼å çºå®æå©æ¼é«çä¿å¥æä¾èç³»çµ±ååå·æç¸ä¼¼çççç¾çãéé ç ç©¶è©ä¼°äºå¯¦é©å®¤æª¢é©çµæå°å¤§åèªè¨æ¨¡å (LLM) ååºçéå¥è¨ºæ· (DDx) çå½±é¿ãå¾ PubMed Central ç 50 ä»½çä¾å ±åä¸­å»ºç«äºè¨åºç°¡å ±ï¼å¶ä¸­åå«æ£èäººå£çµ±è¨ãççåå¯¦é©å®¤çµæãæ¸¬è©¦äºäºå LLM GPT-4ãGPT-3.5ãLlama-2-70bãClaude-2 å Mixtral-8x7Bï¼ä»¥çæå¸¶åä¸å¸¶å¯¦é©å®¤æ¸æçå 10ãå 5 åå 1 DDxãé²è¡äºä¸é æ¶å GPT-4ãç¥è­åè­åè¨åºé«ççç¶åè©ä¼°ãGPT-4 è¡¨ç¾æä½³ï¼å¨æå¯¦é©å®¤æ¸æçææ³ä¸ï¼å 1 åè¨ºæ·çæºç¢ºçéå° 55%ï¼å 10 åçæºç¢ºçéå° 60%ï¼å¯¬é¬æºç¢ºçé«é 80%ãå¯¦é©å®¤çµæé¡¯èæé«äºæºç¢ºçï¼GPT-4 å Mixtral è¡¨ç¾åºè²ï¼åç®¡å®å¨å¹éçè¼ä½ãLLM éå¸¸å¯ä»¥æ­£ç¢ºè§£éåæ¬èåè½ãä»£è¬/æ¯çå­¸æª¢æ¥åè¡æ¸å­¸/åç«æ¸¬è©¦å¨å§çå¯¦é©å®¤æª¢é©ï¼ä»¥é²è¡éå¥è¨ºæ·ã

##### **Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning**
2411.00205v1 by Beyazit Yalcinkaya, Niklas Lauffer, Marcell Vazquez-Chanlatte, Sanjit A. Seshia

Goal-conditioned reinforcement learning is a powerful way to control an AI
agent's behavior at runtime. That said, popular goal representations, e.g.,
target states or natural language, are either limited to Markovian tasks or
rely on ambiguous task semantics. We propose representing temporal goals using
compositions of deterministic finite automata (cDFAs) and use cDFAs to guide RL
agents. cDFAs balance the need for formal temporal semantics with ease of
interpretation: if one can understand a flow chart, one can understand a cDFA.
On the other hand, cDFAs form a countably infinite concept class with Boolean
semantics, and subtle changes to the automaton can result in very different
tasks, making them difficult to condition agent behavior on. To address this,
we observe that all paths through a DFA correspond to a series of reach-avoid
tasks and propose pre-training graph neural network embeddings on "reach-avoid
derived" DFAs. Through empirical evaluation, we demonstrate that the proposed
pre-training method enables zero-shot generalization to various cDFA task
classes and accelerated policy specialization without the myopic suboptimality
of hierarchical methods.

æè¦ï¼ç®æ¨æ¢ä»¶å¼·åå­¸ç¿æ¯ä¸ç¨®å¨å·è¡éæ®µæ§å¶ AI ä»£çè¡çºçå¼·å¤§æ¹æ³ãè©±éå¦æ­¤ï¼ç±éçç®æ¨è¡¨ç¤ºï¼ä¾å¦ç®æ¨çææèªç¶èªè¨ï¼åéæ¼é¦¬å¯å¤«ä»»åæä¾è³´æ¼å«ç³ä¸æ¸çä»»åèªç¾©ãæåå»ºè­°ä½¿ç¨ç¢ºå®æ§æéçæèªåæ© (cDFA) ççµåä¾è¡¨ç¤ºæéç®æ¨ï¼ä¸¦ä½¿ç¨ cDFA ä¾æå° RL ä»£çãcDFA å¹³è¡¡äºå°å½¢å¼æéèªç¾©çéæ±èææ¼è§£éä¹éçéä¿ï¼å¦æä¸åäººè½çè§£æµç¨åï¼é£éº¼ä»å°±è½çè§£ cDFAãå¦ä¸æ¹é¢ï¼cDFA å½¢æäºä¸åå·æå¸æèªç¾©çå¯æ¸ç¡éæ¦å¿µé¡ï¼èå°èªåæ©çç´°å¾®æ´æ¹å¯è½æå°è´éå¸¸ä¸åçä»»åï¼éä½¿å¾å®åé£ä»¥å°ä»£çè¡çºé²è¡æ¢ä»¶åãçºäºè§£æ±ºéååé¡ï¼æåè§å¯å°éé DFA çææè·¯å¾é½å°ææ¼ä¸ç³»åå°éé¿åä»»åï¼ä¸¦æåºå°ãå°éé¿åè¡çãDFA é²è¡é è¨ç·´åç¥ç¶ç¶²è·¯åµå¥ãééç¶é©è©ä¼°ï¼æåè­æäºææåºçé è¨ç·´æ¹æ³è½å¤ å°åç¨® cDFA ä»»åé¡å¥é²è¡é¶æ¬¡å­¸ç¿æ³åï¼ä¸¦å éç­ç¥å°æ¥­åï¼èæ²æåå±¤æ¹æ³çè¿è¦æ¬¡åªæ§ã

##### **Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis**
2411.00188v1 by Yu Pan, Jianxin Sun, Hongfeng Yu, Joe Luck, Geng Bai, Nipuna Chamara, Yufeng Ge, Tala Awada

Current agricultural data management and analysis paradigms are to large
extent traditional, in which data collecting, curating, integration, loading,
storing, sharing and analyzing still involve too much human effort and
know-how. The experts, researchers and the farm operators need to understand
the data and the whole process of data management pipeline to make fully use of
the data. The essential problem of the traditional paradigm is the lack of a
layer of orchestrational intelligence which can understand, organize and
coordinate the data processing utilities to maximize data management and
analysis outcome. The emerging reasoning and tool mastering abilities of large
language models (LLM) make it a potentially good fit to this position, which
helps a shift from the traditional user-driven paradigm to AI-driven paradigm.
In this paper, we propose and explore the idea of a LLM based copilot for
autonomous agricultural data management and analysis. Based on our previously
developed platform of Agricultural Data Management and Analytics (ADMA), we
build a proof-of-concept multi-agent system called ADMA Copilot, which can
understand user's intent, makes plans for data processing pipeline and
accomplishes tasks automatically, in which three agents: a LLM based
controller, an input formatter and an output formatter collaborate together.
Different from existing LLM based solutions, by defining a meta-program graph,
our work decouples control flow and data flow to enhance the predictability of
the behaviour of the agents. Experiments demonstrates the intelligence,
autonomy, efficacy, efficiency, extensibility, flexibility and privacy of our
system. Comparison is also made between ours and existing systems to show the
superiority and potential of our system.

æè¦ï¼<paragraph>ç®åçè¾²æ¥­è³æç®¡çèåææ¨¡å¼å¨å¾å¤§ç¨åº¦ä¸ä»æ¯å³çµ±çï¼å¶ä¸­è³ææ¶éãæ´çãæ´åãè¼å¥ãå²å­ãåäº«ååæä»ç¶éè¦å¤ªå¤çäººåèå°æ¥­ç¥è­ãå°å®¶ãç ç©¶äººå¡åè¾²å ´ç¶çèéè¦äºè§£è³æåæ´åè³æç®¡çæµç¨ï¼æè½ååå©ç¨è³æãå³çµ±æ¨¡å¼çåºæ¬åé¡æ¯ç¼ºä¹ä¸å±¤ç·¨ææºè½ï¼ç¡æ³çè§£ãçµç¹ååèª¿è³æèçå·¥å·ï¼ä»¥æå¤§åè³æç®¡çååæææãå¤§åèªè¨æ¨¡å (LLM) æ°èçæ¨çåå·¥å·ææ¡è½åä½¿å¶æ½å¨é©åéåè·ä½ï¼éæå©æ¼å¾å³çµ±çä½¿ç¨èé©åæ¨¡å¼è½è®çº AI é©åæ¨¡å¼ãå¨æ¬æä¸­ï¼æåæåºä¸¦æ¢è¨äºåºæ¼ LLM çå¯é§é§çæ³æ³ï¼ç¨æ¼èªååè¾²æ¥­è³æç®¡çååæãåºæ¼æåååéç¼çè¾²æ¥­è³æç®¡çååæ (ADMA) å¹³å°ï¼æåå»ºç«äºä¸ååçº ADMA Copilot çæ¦å¿µé©è­å¤ä»£çç³»çµ±ï¼å®å¯ä»¥çè§£ä½¿ç¨èçæåãè¦åè³æèçæµç¨ä¸¦èªåå®æä»»åï¼å¶ä¸­ä¸åä»£çï¼åºæ¼ LLM çæ§å¶å¨ãè¼¸å¥æ ¼å¼åç¨å¼åè¼¸åºæ ¼å¼åç¨å¼å±ååä½ãèç¾æçåºæ¼ LLM çè§£æ±ºæ¹æ¡ä¸åï¼ééå®ç¾©åç¨å¼åï¼æåçç ç©¶å°æ§å¶æµç¨åè³ææµç¨è§£è¦ï¼ä»¥å¢å¼·ä»£çè¡çºçå¯é æ¸¬æ§ãå¯¦é©è­æäºæåç³»çµ±çæºæ§ãèªä¸»æ§ãæè½ãæçãå¯æ´åæ§ãéæ´»æ§èé±ç§æ§ãæåä¹èç¾æç³»çµ±é²è¡æ¯è¼ï¼ä»¥é¡¯ç¤ºæåç³»çµ±çåªè¶æ§åæ½åã</paragraph>

##### **Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models**
2411.00878v1 by Phil Wee, Riyadh Baghdadi

Recently, there has been an explosion of large language models created
through fine-tuning with data from larger models. These small models able to
produce outputs that appear qualitatively similar to significantly larger
models. However, one of the key limitations that have been observed with these
models is their propensity to hallucinate significantly more often than larger
models. In particular, they have been observed to generate coherent outputs
that involve factually incorrect information and spread misinformation,
toxicity, and stereotypes. There are many potential causes of hallucination, of
which, one hypothesis is that fine-tuning a model on data produced by a larger
model leads to a knowledge mismatch which contributes to hallucination. In
particular, it is hypothesized that there is a mismatch between the knowledge
that is fed to the model to fine-tune it and the knowledge that is already
present in the graph. Fine-tuning the model on data that has such mismatch
could contribute to an increased propensity to hallucinate. We show that on an
unseen test set, a smaller model fine-tuned on data generated from a larger
model produced more wrong answers when compared to models fine-tuned on data
created by the small model, which confirms the hypothesis.

æè¦ï¼æè¿ï¼éè¿ä½¿ç¨æ´å¤§æ¨¡åçæ°æ®è¿è¡å¾®è°ï¼åå»ºäºå¤§éè¯­è¨æ¨¡åçç¸ãè¿äºå°æ¨¡åè½å¤äº§çä¸ææ¾æ´å¤§çæ¨¡åå¨è´¨éä¸ç±»ä¼¼çè¾åºãç¶èï¼å¨è¿äºæ¨¡åä¸­è§å¯å°çä¸ä¸ªå³é®éå¶æ¯ï¼å®ä»¬æ¯æ´å¤§çæ¨¡åæ´å®¹æåºç°å¹»è§ãç¹å«æ¯ï¼å·²ç»è§å¯å°å®ä»¬ä¼çææ¶åäºå®ä¸æ­£ç¡®çä¿¡æ¯å¹¶ä¼ æ­éè¯¯ä¿¡æ¯ãæ¯æ§åå»æ¿å°è±¡çè¿è´¯è¾åºãå¹»è§æå¾å¤æ½å¨åå ï¼å¶ä¸­ä¸ä¸ªåè®¾æ¯ï¼å¨æ´å¤§æ¨¡åçæçæ°æ®ä¸å¾®è°æ¨¡åä¼å¯¼è´ç¥è¯ä¸å¹éï¼ä»èå¯¼è´å¹»è§ãç¹å«æ¯ï¼åè®¾æ¨¡åå¾®è°æé¦éçç¥è¯ä¸å¾ä¸­å·²æçç¥è¯ä¹é´å­å¨ä¸å¹éãå¨å·æè¿ç§ä¸å¹éçæ°æ®ä¸å¾®è°æ¨¡åå¯è½ä¼å¯¼è´å¹»è§å¾åå¢å ãæä»¬è¡¨æï¼å¨ä¸ä¸ªçä¸è§çæµè¯éä¸­ï¼ä¸ä¸ªå¨ä»ä¸ä¸ªæ´å¤§çæ¨¡åçæçæ°æ®ä¸å¾®è°çå°æ¨¡åï¼ä¸å¨å°æ¨¡ååå»ºçæ°æ®ä¸å¾®è°çæ¨¡åç¸æ¯ï¼äº§çäºæ´å¤éè¯¯çç­æ¡ï¼è¿è¯å®äºè¿ä¸åè®¾ã

##### **Failure Modes of LLMs for Causal Reasoning on Narratives**
2410.23884v1 by Khurram Yamin, Shantanu Gupta, Gaurav R. Ghosal, Zachary C. Lipton, Bryan Wilder

In this work, we investigate the causal reasoning abilities of large language
models (LLMs) through the representative problem of inferring causal
relationships from narratives. We find that even state-of-the-art language
models rely on unreliable shortcuts, both in terms of the narrative
presentation and their parametric knowledge. For example, LLMs tend to
determine causal relationships based on the topological ordering of events
(i.e., earlier events cause later ones), resulting in lower performance
whenever events are not narrated in their exact causal order. Similarly, we
demonstrate that LLMs struggle with long-term causal reasoning and often fail
when the narratives are long and contain many events. Additionally, we show
LLMs appear to rely heavily on their parametric knowledge at the expense of
reasoning over the provided narrative. This degrades their abilities whenever
the narrative opposes parametric knowledge. We extensively validate these
failure modes through carefully controlled synthetic experiments, as well as
evaluations on real-world narratives. Finally, we observe that explicitly
generating a causal graph generally improves performance while naive
chain-of-thought is ineffective. Collectively, our results distill precise
failure modes of current state-of-the-art models and can pave the way for
future techniques to enhance causal reasoning in LLMs.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåééæ¨è«æè¿°ä¸­çå æéä¿éåä»£è¡¨æ§åé¡ï¼ä¾æ¢è¨å¤§åèªè¨æ¨¡å (LLM) çå ææ¨çè½åãæåç¼ç¾ï¼å³ä½¿æ¯æåé²çèªè¨æ¨¡åï¼ä¹æä¾è³´æ¼ä¸å¯é çæ·å¾ï¼ç¡è«æ¯å¨æè¿°åç¾æå¶åæ¸ç¥è­æ¹é¢ãä¾å¦ï¼LLM å¾åæ¼æ ¹æäºä»¶çææ²é åºï¼å³ï¼è¼æ©çäºä»¶å°è´è¼æçäºä»¶ï¼ä¾ç¢ºå®å æéä¿ï¼ç¶äºä»¶æªæå¶ç¢ºåçå æé åºæè¿°æï¼å°±æå°è´è¼ä½çæè½ãåæ¨£å°ï¼æåè­æ LLM é£ä»¥é²è¡é·æå ææ¨çï¼ä¸¦ä¸ç¶æè¿°å¾é·ä¸åå«è¨±å¤äºä»¶æï¼å®åéå¸¸æå¤±æãæ­¤å¤ï¼æåè¡¨æ LLM ä¼¼ä¹éåº¦ä¾è³´å¶åæ¸ç¥è­ï¼èç§ç²äºå°ææä¾æè¿°çæ¨çãæ¯ç¶æè¿°èåæ¸ç¥è­ç¸è¡çªæï¼éå°±æéä½å®åçè½åãæåééä»ç´°æ§å¶çåæå¯¦é©ä»¥åå°çå¯¦ä¸çæè¿°çè©ä¼°ï¼å»£æ³é©è­äºéäºå¤±ææ¨¡å¼ãæå¾ï¼æåè§å¯å°ï¼æç¢ºç¢çå æåéå¸¸ææ¹åæè½ï¼èå¤©ççæèéåç¡æãç¸½çä¾èªªï¼æåççµæç²¾ç¢ºå°æçäºç¶åæåé²æ¨¡åçå¤±ææ¨¡å¼ï¼ä¸¦å¯ä»¥çºæªä¾å¢å¼· LLM ä¸­å ææ¨ççæè¡éªè·¯ã

##### **Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs**
2410.23875v1 by Liyi Chen, Panrong Tong, Zhongming Jin, Ying Sun, Jieping Ye, Hui Xiong

Large Language Models (LLMs) have shown remarkable reasoning capabilities on
complex tasks, but they still suffer from out-of-date knowledge,
hallucinations, and opaque decision-making. In contrast, Knowledge Graphs (KGs)
can provide explicit and editable knowledge for LLMs to alleviate these issues.
Existing paradigm of KG-augmented LLM manually predefines the breadth of
exploration space and requires flawless navigation in KGs. However, this
paradigm cannot adaptively explore reasoning paths in KGs based on the question
semantics and self-correct erroneous reasoning paths, resulting in a bottleneck
in efficiency and effect. To address these limitations, we propose a novel
self-correcting adaptive planning paradigm for KG-augmented LLM named
Plan-on-Graph (PoG), which first decomposes the question into several
sub-objectives and then repeats the process of adaptively exploring reasoning
paths, updating memory, and reflecting on the need to self-correct erroneous
reasoning paths until arriving at the answer. Specifically, three important
mechanisms of Guidance, Memory, and Reflection are designed to work together,
to guarantee the adaptive breadth of self-correcting planning for graph
reasoning. Finally, extensive experiments on three real-world datasets
demonstrate the effectiveness and efficiency of PoG.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨è¤éä»»åä¸­å±ç¾åºéå¡çæ¨çè½åï¼ä½ä»å­å¨ç¥è­éæãå¹»è¦ºåæ±ºç­ä¸éæçåé¡ãç¸åå°ï¼ç¥è­åè­ (KG) å¯ä»¥æä¾æç¢ºä¸å¯ç·¨è¼¯çç¥è­ï¼ä¾ LLM ç·©è§£éäºåé¡ãç¾æç KG å¢å¼· LLM å¸ç¯æåé åå®ç¾©æ¢ç´¢ç©ºéçå»£åº¦ï¼ä¸¦éè¦å¨ KG ä¸­å®ç¾å°èªãç¶èï¼æ­¤å¸ç¯ç¡æ³æ ¹æåé¡èªæèªé©æå°æ¢ç´¢ KG ä¸­çæ¨çè·¯å¾ï¼ä¸¦èªè¡ç³¾æ­£é¯èª¤çæ¨çè·¯å¾ï¼å°è´æçåææçç¶é ¸ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ååçºåå½¢è¨ç« (PoG) ç KG å¢å¼· LLM çæ°ç©èªä¿®æ­£èªé©æè¦åå¸ç¯ï¼å®é¦åå°åé¡åè§£æå¹¾åå­ç®æ¨ï¼ç¶å¾éè¤èªé©ææ¢ç´¢æ¨çè·¯å¾ãæ´æ°è¨æ¶é«ååæéè¦èªè¡ç³¾æ­£é¯èª¤æ¨çè·¯å¾çéç¨ï¼ç´å°å¾åºç­æ¡ãå·é«ä¾èªªï¼æå°ãè¨æ¶ååæéä¸åéè¦æ©å¶è¢«è¨­è¨çºååéä½ï¼ä»¥ä¿è­èªä¿®æ­£è¦åå¨åå½¢æ¨çä¸­çèªé©æå»£åº¦ãæå¾ï¼å¨ä¸åçå¯¦ä¸çè³æéä¸çå»£æ³å¯¦é©è­æäº PoG çæææ§åæçã

##### **LLaMo: Large Language Model-based Molecular Graph Assistant**
2411.00871v1 by Jinyoung Park, Minseong Bae, Dohwan Ko, Hyunwoo J. Kim

Large Language Models (LLMs) have demonstrated remarkable generalization and
instruction-following capabilities with instruction tuning. The advancements in
LLMs and instruction tuning have led to the development of Large
Vision-Language Models (LVLMs). However, the competency of the LLMs and
instruction tuning have been less explored in the molecular domain. Thus, we
propose LLaMo: Large Language Model-based Molecular graph assistant, which is
an end-to-end trained large molecular graph-language model. To bridge the
discrepancy between the language and graph modalities, we present the
multi-level graph projector that transforms graph representations into graph
tokens by abstracting the output representations of each GNN layer and motif
representations with the cross-attention mechanism. We also introduce
machine-generated molecular graph instruction data to instruction-tune the
large molecular graph-language model for general-purpose molecule and language
understanding. Our extensive experiments demonstrate that LLaMo shows the best
performance on diverse tasks, such as molecular description generation,
property prediction, and IUPAC name prediction. The code of LLaMo is available
at https://github.com/mlvlab/LLaMo.

æè¦ï¼å¤§åè¯­è¨æ¨¡å (LLM) å·²å±ç¤ºåºåè¶çæ¦æ¬åæä»¤éµå¾ªè½åï¼å¹¶è¿è¡æä»¤è°æ´ãLLM åæä»¤è°æ´çè¿æ­¥å¯¼è´äºå¤§åè§è§è¯­è¨æ¨¡å (LVLMs) çåå±ãç¶èï¼LLM åæä»¤è°æ´çè½åå¨åå­é¢åçç ç©¶è¾å°ãå æ­¤ï¼æä»¬æåºäº LLaMoï¼åºäºå¤§è¯­è¨æ¨¡åçåå­å¾å©æï¼è¿æ¯ä¸ä¸ªç«¯å°ç«¯è®­ç»çå¤§åå­å¾è¯­è¨æ¨¡åãä¸ºäºå¼¥åè¯­è¨åå¾æ¨¡å¼ä¹é´çå·®å¼ï¼æä»¬æåºäºå¤çº§å¾æå½±ä»ªï¼å®éè¿æ½è±¡æ¯ä¸ª GNN å±çè¾åºè¡¨ç¤ºååºåºè¡¨ç¤ºï¼ä½¿ç¨äº¤åæ³¨æåæºå¶ï¼å°å¾è¡¨ç¤ºè½¬æ¢ä¸ºå¾æ è®°ãæä»¬è¿å¼å¥äºæºå¨çæçåå­å¾æä»¤æ°æ®ï¼ä»¥å¯¹å¤§ååå­å¾è¯­è¨æ¨¡åè¿è¡æä»¤è°æ´ï¼ä»¥ç¨äºéç¨åå­åè¯­è¨çè§£ãæä»¬å¹¿æ³çå®éªè¡¨æï¼LLaMo å¨åå­æè¿°çæãå±æ§é¢æµå IUPAC åç§°é¢æµç­ä¸åä»»å¡ä¸è¡¨ç°åºæä½³æ§è½ãLLaMo çä»£ç å¯å¨ https://github.com/mlvlab/LLaMo è·å¾ã

##### **End-to-End Ontology Learning with Large Language Models**
2410.23584v1 by Andy Lo, Albert Q. Jiang, Wenda Li, Mateja Jamnik

Ontologies are useful for automatic machine processing of domain knowledge as
they represent it in a structured format. Yet, constructing ontologies requires
substantial manual effort. To automate part of this process, large language
models (LLMs) have been applied to solve various subtasks of ontology learning.
However, this partial ontology learning does not capture the interactions
between subtasks. We address this gap by introducing OLLM, a general and
scalable method for building the taxonomic backbone of an ontology from
scratch. Rather than focusing on subtasks, like individual relations between
entities, we model entire subcomponents of the target ontology by finetuning an
LLM with a custom regulariser that reduces overfitting on high-frequency
concepts. We introduce a novel suite of metrics for evaluating the quality of
the generated ontology by measuring its semantic and structural similarity to
the ground truth. In contrast to standard metrics, our metrics use deep
learning techniques to define more robust distance measures between graphs.
Both our quantitative and qualitative results on Wikipedia show that OLLM
outperforms subtask composition methods, producing more semantically accurate
ontologies while maintaining structural integrity. We further demonstrate that
our model can be effectively adapted to new domains, like arXiv, needing only a
small number of training examples. Our source code and datasets are available
at https://github.com/andylolu2/ollm.

æè¦ï¼æ¬ä½å¯¹äºé¢åç¥è¯çèªå¨æºå¨å¤çå¾æç¨ï¼å ä¸ºå®ä»¬ä»¥ç»æåæ ¼å¼è¡¨ç¤ºç¥è¯ãç¶èï¼æå»ºæ¬ä½éè¦å¤§éçæå¨å·¥ä½ãä¸ºäºèªå¨åè¿ä¸ªè¿ç¨çä¸é¨åï¼å¤§åè¯­è¨æ¨¡åï¼LLMï¼å·²è¢«åºç¨äºè§£å³æ¬ä½å­¦ä¹ çåç§å­ä»»å¡ãç¶èï¼è¿ç§é¨åæ¬ä½å­¦ä¹ å¹¶æ²¡æææå°å­ä»»å¡ä¹é´çäº¤äºãæä»¬éè¿å¼å¥ OLLM æ¥è§£å³è¿ä¸å·®è·ï¼è¿æ¯ä¸ç§ä»å¤´å¼å§æå»ºæ¬ä½åç±»éª¨æ¶çéç¨ä¸å¯æ©å±çæ¹æ³ãæä»¬æ²¡æä¸æ³¨äºå­ä»»å¡ï¼ä¾å¦å®ä½ä¹é´çä¸ªå«å³ç³»ï¼èæ¯éè¿ä½¿ç¨èªå®ä¹æ­£ååå¨å¾®è° LLM æ¥å¯¹ç®æ æ¬ä½çæ´ä¸ªå­ç»ä»¶è¿è¡å»ºæ¨¡ï¼è¯¥æ­£ååå¨åå°äºå¯¹é«é¢æ¦å¿µçè¿åº¦æåãæä»¬å¼å¥äºä¸å¥æ°çææ æ¥è¯ä¼°çææ¬ä½çè´¨éï¼æ¹æ³æ¯æµéå®ä¸å°é¢çå®å¼çè¯­ä¹åç»æç¸ä¼¼æ§ãä¸æ åææ ç¸åï¼æä»¬çææ ä½¿ç¨æ·±åº¦å­¦ä¹ ææ¯æ¥å®ä¹å¾ä¹é´çæ´ç¨³å¥çè·ç¦»åº¦éãæä»¬å¨ç»´åºç¾ç§ä¸çå®éåå®æ§ç»æè¡¨æï¼OLLM ä¼äºå­ä»»å¡ç»åæ¹æ³ï¼å¨ä¿æç»æå®æ´æ§çåæ¶çæè¯­ä¹ä¸æ´åç¡®çæ¬ä½ãæä»¬è¿ä¸æ­¥è¯æï¼æä»¬çæ¨¡åå¯ä»¥ææå°éåºæ°çé¢åï¼å¦ arXivï¼åªéè¦å°éçè®­ç»æ ·æ¬ãæä»¬çæºä»£ç åæ°æ®éå¯å¨ https://github.com/andylolu2/ollm è·å¾ã

##### **Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document**
2410.23452v1 by Vicky Dong, Hao Yu, Yao Chen

This study introduces a novel approach to sentence-level relation extraction
(RE) that integrates Graph Neural Networks (GNNs) with Large Language Models
(LLMs) to generate contextually enriched support documents. By harnessing the
power of LLMs to generate auxiliary information, our approach crafts an
intricate graph representation of textual data. This graph is subsequently
processed through a Graph Neural Network (GNN) to refine and enrich the
embeddings associated with each entity ensuring a more nuanced and
interconnected understanding of the data. This methodology addresses the
limitations of traditional sentence-level RE models by incorporating broader
contexts and leveraging inter-entity interactions, thereby improving the
model's ability to capture complex relationships across sentences. Our
experiments, conducted on the CrossRE dataset, demonstrate the effectiveness of
our approach, with notable improvements in performance across various domains.
The results underscore the potential of combining GNNs with LLM-generated
context to advance the field of relation extraction.

æè¦ï¼æ¬ç ç©¶æåºäºä¸åå¥å­å±¤ç´éä¿èå (RE) çæ°æ¹æ³ï¼è©²æ¹æ³æ´åäºåå½¢ç¥ç¶ç¶²è·¯ (GNN) åå¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥ç¢çèçµ¡è±å¯çæ¯æ´æä»¶ãééå©ç¨ LLM çåè½ä¾ç¢çè¼å©è³è¨ï¼æåçåæ³å»ºç«äºä¸åææ¬è³æçè¤éåå½¢è¡¨ç¤ºãæ­¤åå½¢é¨å¾ééåå½¢ç¥ç¶ç¶²è·¯ (GNN) é²è¡èçï¼ä»¥æ¹ååè±å¯èæ¯åå¯¦é«ç¸éçåµå¥ï¼ç¢ºä¿å°è³æææ´ç´°ç·»ä¸ç¸äºé£çµççè§£ãæ­¤æ¹æ³ééç´å¥æ´å»£æ³çèçµ¡ä¸¦å©ç¨å¯¦é«éäºåï¼ä¾è§£æ±ºå³çµ±å¥å­å±¤ç´ RE æ¨¡åçéå¶ï¼é²èæåæ¨¡åææè·¨å¥å­çè¤ééä¿çè½åãæåå¨ CrossRE è³æéä¸å·è¡çå¯¦é©è­æäºæåæ¹æ³çæææ§ï¼å¨åç¨®é åçæè½é½æé¡¯èçæåãéäºçµæå¼·èª¿äºå° GNN è LLM ç¢ççèçµ¡ç¸çµåï¼ä»¥æ¨é²éä¿èåé åçæ½åã

##### **FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions**
2410.23405v1 by Anuroop Sriram, Benjamin Kurt Miller, Ricky T. Q. Chen, Brandon M. Wood

Material discovery is a critical area of research with the potential to
revolutionize various fields, including carbon capture, renewable energy, and
electronics. However, the immense scale of the chemical space makes it
challenging to explore all possible materials experimentally. In this paper, we
introduce FlowLLM, a novel generative model that combines large language models
(LLMs) and Riemannian flow matching (RFM) to design novel crystalline
materials. FlowLLM first fine-tunes an LLM to learn an effective base
distribution of meta-stable crystals in a text representation. After converting
to a graph representation, the RFM model takes samples from the LLM and
iteratively refines the coordinates and lattice parameters. Our approach
significantly outperforms state-of-the-art methods, increasing the generation
rate of stable materials by over three times and increasing the rate for
stable, unique, and novel crystals by $\sim50\%$ - a huge improvement on a
difficult problem. Additionally, the crystals generated by FlowLLM are much
closer to their relaxed state when compared with another leading model,
significantly reducing post-hoc computational cost.

æè¦ï¼ææç¼ç¾æ¯ä¸åéè¦çç ç©¶é åï¼å·æé©æ°åç¨®é åçæ½åï¼åæ¬ç¢³æéãå¯åçè½æºåé»å­ç¢åãç¶èï¼åå­¸ç©ºéçå·¨å¤§è¦æ¨¡ä½¿å¾å¯¦é©æ¢ç´¢ææå¯è½çææå·æææ°æ§ãå¨æ¬æä¸­ï¼æåä»ç´¹äº FlowLLMï¼éæ¯ä¸ç¨®æ°ç©ççææ¨¡åï¼çµåäºå¤§åèªè¨æ¨¡å (LLM) åé»æ¼æµå¹é (RFM) ä¾è¨­è¨æ°åæ¶é«ææãFlowLLM é¦åå¾®èª¿ LLMï¼ä»¥å­¸ç¿ææ¬è¡¨ç¤ºä¸­äºç©©ææ¶é«çææåºç¤åä½ãå¨è½æçºåå½¢è¡¨ç¤ºå¾ï¼RFM æ¨¡åå¾ LLM ä¸­ç²åæ¨£æ¬ï¼ä¸¦åè¦ç²¾çåæ¨åæ¶æ ¼åæ¸ãæåçåæ³é¡¯èåªæ¼æåé²çæ¹æ³ï¼å°ç©©å®ææççæçæé«äºä¸åä»¥ä¸ï¼ä¸¦å°ç©©å®ãç¨ç¹åæ°ç©æ¶é«ççæçæé«äºç´ 50%ââéå¨ä¸åå°é£çåé¡ä¸æ¯ä¸åå·¨å¤§çæ¹é²ãæ­¤å¤ï¼èå¦ä¸ç¨®é åæ¨¡åç¸æ¯ï¼FlowLLM çæçæ¶é«æ´æ¥è¿å¶é¬å¼çæï¼é¡¯èéä½äºäºå¾è¨ç®ææ¬ã

##### **EMMA: End-to-End Multimodal Model for Autonomous Driving**
2410.23262v2 by Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, Yin Zhou, James Guo, Dragomir Anguelov, Mingxing Tan

We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.
Built on a multi-modal large language model foundation, EMMA directly maps raw
camera sensor data into various driving-specific outputs, including planner
trajectories, perception objects, and road graph elements. EMMA maximizes the
utility of world knowledge from the pre-trained large language models, by
representing all non-sensor inputs (e.g. navigation instructions and ego
vehicle status) and outputs (e.g. trajectories and 3D locations) as natural
language text. This approach allows EMMA to jointly process various driving
tasks in a unified language space, and generate the outputs for each task using
task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by
achieving state-of-the-art performance in motion planning on nuScenes as well
as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also
yields competitive results for camera-primary 3D object detection on the Waymo
Open Dataset (WOD). We show that co-training EMMA with planner trajectories,
object detection, and road graph tasks yields improvements across all three
domains, highlighting EMMA's potential as a generalist model for autonomous
driving applications. However, EMMA also exhibits certain limitations: it can
process only a small amount of image frames, does not incorporate accurate 3D
sensing modalities like LiDAR or radar and is computationally expensive. We
hope that our results will inspire further research to mitigate these issues
and to further evolve the state of the art in autonomous driving model
architectures.

æè¦ï¼<paragraph>æåä»ç´¹ EMMAï¼ä¸ç¨®ç¨æ¼èªåé§é§çç«¯å°ç«¯å¤æ¨¡ææ¨¡åã
å»ºç«å¨å¤æ¨¡æå¤§åèªè¨æ¨¡ååºç¤ä¸ï¼EMMA ç´æ¥å°åå§
ç¸æ©ææ¸¬å¨è³æå°æå°åç¨®ç¹å®æ¼é§é§çè¼¸åºï¼åæ¬è¦åå¨
è»è·¡ãæç¥ç©ä»¶åéè·¯åå½¢åç´ ãEMMA æå¤§åå©ç¨é è¨ç·´å¤§åèªè¨æ¨¡åä¸­çä¸çç¥è­ï¼æ¹æ³æ¯
å°ææéææ¸¬å¨è¼¸å¥ï¼ä¾å¦å°èªæç¤ºåèªæ
è»è¼çæï¼åè¼¸åºï¼ä¾å¦è»è·¡å 3D ä½ç½®ï¼è¡¨ç¤ºçºèªç¶
èªè¨æå­ãéç¨®æ¹æ³åè¨± EMMA å¨çµ±ä¸çèªè¨ç©ºéä¸­å±åèçåç¨®é§é§
ä»»åï¼ä¸¦ä½¿ç¨ç¹å®æ¼ä»»åçæç¤ºçºæ¯åä»»åç¢çè¼¸åºã
æ ¹æç¶é©ï¼æåè­æäº EMMA çæææ§ï¼å¨ nuScenes ä¸çéåè¦åä¸­éå°äºæåé²çæ§è½ï¼ä»¥å
å¨ Waymo éæ¾éåè³æé (WOMD) ä¸åå¾äºæç«¶ç­åççµæãEMMA ä¹
å¨ Waymo éæ¾è³æé (WOD) ä¸å°ç¸æ©åªåç 3D ç©ä»¶åµæ¸¬ç¢çäºæç«¶ç­åççµæãæåå±ç¤ºäºä½¿ç¨è¦åå¨è»è·¡ã
ç©ä»¶åµæ¸¬åéè·¯åå½¢ä»»åå±åè¨ç·´ EMMA æå¨ææä¸å
é åç¢çæ¹é²ï¼çªé¡¯äº EMMA ä½çºèªåé§é§æç¨ç¨å¼éç¨æ¨¡åçæ½åãç¶èï¼EMMA ä¹è¡¨ç¾åºæäºéå¶ï¼å®åªè½
èçå°éçå½±åå¹ï¼ä¸åå«å LiDAR æé·éç­æºç¢ºç 3D ææ¸¬æ¨¡å¼ï¼ä¸¦ä¸è¨ç®ææ¬æè²´ãæå
å¸ææåççµæè½æ¿åµé²ä¸æ­¥çç ç©¶ï¼ä»¥æ¸è¼éäºåé¡ä¸¦é²ä¸æ­¥ç¼å±èªåé§é§æ¨¡å
æ¶æ§çææ°æè¡ã</paragraph>

##### **ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**
2410.23182v1 by Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu

Transformer-based architectures have dominated various areas of machine
learning in recent years. In this paper, we introduce a novel robust attention
mechanism designed to enhance the resilience of transformer-based
architectures. Crucially, this technique can be integrated into existing
transformers as a plug-and-play layer, improving their robustness without the
need for additional training or fine-tuning. Through comprehensive experiments
and ablation studies, we demonstrate that our ProTransformer significantly
enhances the robustness of transformer models across a variety of prediction
tasks, attack mechanisms, backbone architectures, and data domains. Notably,
without further fine-tuning, the ProTransformer consistently improves the
performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT,
ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler
attack. Furthermore, ProTransformer shows promising resilience in large
language models (LLMs) against prompting-based attacks, improving the
performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing
Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the
language domain, ProTransformer also demonstrates outstanding robustness in
both vision and graph domains.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼åºæ¼ Transformer çæ¶æ§ä¸»å°äºæ©å¨å­¸ç¿çååé åãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ç¨®æ°ç©ä¸å¼·å¤§çæ³¨æåæ©å¶ï¼æ¨å¨å¢å¼·åºæ¼ Transformer çæ¶æ§çéæ§ãè³ééè¦çæ¯ï¼æ­¤æè¡å¯ä»¥ä½çºå³æå³ç¨çå±¤æ´åå°ç¾æç Transformer ä¸­ï¼å¨ç¡éé¡å¤è¨ç·´æå¾®èª¿çææ³ä¸æé«å¶ç©©å¥æ§ãééå¨é¢çå¯¦é©åæ¶èç ç©¶ï¼æåè­æäºæåç ProTransformer å¨åç¨®é æ¸¬ä»»åãæ»ææ©å¶ãä¸»å¹¹æ¶æ§åæ¸æé åä¸­é¡¯èå¢å¼·äº Transformer æ¨¡åçç©©å¥æ§ãå¼å¾æ³¨æçæ¯ï¼å¨ä¸é²ä¸æ­¥å¾®èª¿çææ³ä¸ï¼ProTransformer å¨ç¶å¸ç TextFooler æ»æä¸ï¼åå¥çº BERTãALBERTãDistilBERT å RoBERTa æåäº 19.5%ã28.3%ã16.1% å 11.4% çæ§è½ãæ­¤å¤ï¼ProTransformer å¨åºæ¼æç¤ºçæ»æä¸­å°å¤§åèªè¨æ¨¡å (LLM) é¡¯ç¤ºåºæå¸æçéæ§ï¼åå¥å° T5 å LLaMA çæ§è½æåäº 24.8% å 17.8%ï¼ä¸¦å¨è¶çæ»æä¸­å° Vicuna çæ§è½å¹³åæåäº 10.4%ãé¤äºèªè¨é åä¹å¤ï¼ProTransformer å¨è¦è¦ºååå½¢é åä¹è¡¨ç¾åºåºè²çç©©å¥æ§ã</paragraph>

##### **Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**
2410.22996v1 by Deperias Kerre, Anne Laurent, Kenneth Maussang, Dickson Owuor

A well structured collection of the various Quantum Cascade Laser (QCL)
design and working properties data provides a platform to analyze and
understand the relationships between these properties. By analyzing these
relationships, we can gain insights into how different design features impact
laser performance properties such as the working temperature. Most of these QCL
properties are captured in scientific text. There is therefore need for
efficient methodologies that can be utilized to extract QCL properties from
text and generate a semantically enriched and interlinked platform where the
properties can be analyzed to uncover hidden relations. There is also the need
to maintain provenance and reference information on which these properties are
based. Semantic Web technologies such as Ontologies and Knowledge Graphs have
proven capability in providing interlinked data platforms for knowledge
representation in various domains. In this paper, we propose an approach for
generating a QCL properties Knowledge Graph (KG) from text for semantic
enrichment of the properties. The approach is based on the QCL ontology and a
Retrieval Augmented Generation (RAG) enabled information extraction pipeline
based on GPT 4-Turbo language model. The properties of interest include:
working temperature, laser design type, lasing frequency, laser optical power
and the heterostructure. The experimental results demonstrate the feasibility
and effectiveness of this approach for efficiently extracting QCL properties
from unstructured text and generating a QCL properties Knowledge Graph, which
has potential applications in semantic enrichment and analysis of QCL data.

æè¦ï¼ä¸åçµæ§è¯å¥½çåç¨®éå­å±¤çé·å° (QCL) è¨­è¨åå·¥ä½ç¹æ§æ¸æéåï¼æä¾äºä¸åå¹³å°ä¾åæåçè§£éäºç¹æ§ä¹éçéä¿ãééåæéäºéä¿ï¼æåå¯ä»¥æ·±å¥äºè§£ä¸åçè¨­è¨ç¹å¾µå¦ä½å½±é¿é·å°æè½ç¹æ§ï¼ä¾å¦å·¥ä½æº«åº¦ãéäº QCL ç¹æ§å¤§å¤æ¸é½ææå¨ç§å­¸æå­ä¸­ãå æ­¤ï¼éè¦ææçæ¹æ³ï¼å¯ä»¥ç¨æ¼å¾æå­ä¸­èå QCL ç¹æ§ï¼ä¸¦ç¢çä¸åèªç¾©è±å¯ä¸ç¸äºé£çµçå¹³å°ï¼å¯ä»¥å¨å¶ä¸­åæéäºç¹æ§ä»¥ç¼ç¾é±èçéä¿ãééè¦ç¶­è­·éäºç¹æ§æä¾æçä¾æºååèè³è¨ãèªç¾©ç¶²è·¯æè¡ï¼ä¾å¦æ¬ä½åç¥è­åè­ï¼å·²è­æå®åå¨æä¾åç¨®é åä¸­ç¥è­è¡¨å¾µçç¸äºé£çµè³æå¹³å°æ¹é¢å·æè½åãå¨æ¬æä¸­ï¼æåæåºä¸åå¾æå­ä¸­ç¢ç QCL ç¹æ§ç¥è­åè­ (KG) çæ¹æ³ï¼ä»¥é²è¡ç¹æ§çèªç¾©è±å¯åãæ­¤æ¹æ³åºæ¼ QCL æ¬ä½ååºæ¼ GPT 4-Turbo èªè¨æ¨¡åçæª¢ç´¢æ´å¢çæ (RAG) åç¨è³è¨èåç®¡ç·ãæèè¶£çç¹æ§åæ¬ï¼å·¥ä½æº«åº¦ãé·å°è¨­è¨é¡åãé·å°é »çãé·å°ååçåç°è³ªçµæ§ãå¯¦é©çµæè­æäºæ­¤æ¹æ³å°æ¼å¾éçµæ§åæå­ä¸­ææèå QCL ç¹æ§åç¢ç QCL ç¹æ§ç¥è­åè­çå¯è¡æ§åæææ§ï¼éå¨ QCL æ¸æçèªç¾©è±å¯åååæä¸­å·ææ½å¨æç¨ã

##### **How Well Do Large Language Models Disambiguate Swedish Words?**
2410.22827v1 by Richard Johansson

We evaluate a battery of recent large language models on two benchmarks for
word sense disambiguation in Swedish. At present, all current models are less
accurate than the best supervised disambiguators in cases where a training set
is available, but most models outperform graph-based unsupervised systems.
Different prompting approaches are compared, with a focus on how to express the
set of possible senses in a given context. The best accuracies are achieved
when human-written definitions of the senses are included in the prompts.

æè¦ï¼æåéå°å©åçå¸èªè©å½æç¾©æ¶æ­§åºæºï¼è©ä¼°ä¸ç³»åè¿æçå¤§åèªè¨æ¨¡åãç®åï¼å¨æè¨ç·´éå¯ç¨çææ³ä¸ï¼ææç¾ææ¨¡åçæºç¢ºåº¦é½ä½æ¼æä½³ç£ç£å¼æ¶æ­§å¨ï¼ä½å¤§å¤æ¸æ¨¡åçè¡¨ç¾é½åªæ¼åºæ¼åå½¢çéç£ç£å¼ç³»çµ±ãæ¯è¼äºä¸åçæç¤ºæ¹æ³ï¼éé»å¨æ¼å¦ä½å¨ç¹å®èçµ¡ä¸­è¡¨éå¯è½çæç¾©éåãç¶æç¤ºä¸­åå«äººé¡æ°å¯«çæç¾©å®ç¾©æï¼å¯éå°æä½³æºç¢ºåº¦ã

##### **Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**
2410.22767v1 by Sejin Lee, Dongha Kim, Min Song

Goal-oriented chatbots are essential for automating user tasks, such as
booking flights or making restaurant reservations. A key component of these
systems is Dialogue State Tracking (DST), which interprets user intent and
maintains the dialogue state. However, existing DST methods often rely on fixed
ontologies and manually compiled slot values, limiting their adaptability to
open-domain dialogues. We propose a novel approach that leverages instruction
tuning and advanced prompt strategies to enhance DST performance, without
relying on any predefined ontologies. Our method enables Large Language Model
(LLM) to infer dialogue states through carefully designed prompts and includes
an anti-hallucination mechanism to ensure accurate tracking in diverse
conversation contexts. Additionally, we employ a Variational Graph Auto-Encoder
(VGAE) to model and predict subsequent user intent. Our approach achieved
state-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST
models, and performed well in open-domain real-world conversations. This work
presents a significant advancement in creating more adaptive and accurate
goal-oriented chatbots.

æè¦ï¼ä»¥ç®æ¨çºå°åçèå¤©æ©å¨äººå¨èªååä½¿ç¨èä»»åä¸­è³ééè¦ï¼ä¾å¦é è¨èªç­æé²è¡é¤å»³è¨ä½ãéäºç³»çµ±çä¸åééµçµæé¨åæ¯å°è©±çæè¿½è¹¤ (DST)ï¼å®æè§£è­¯ä½¿ç¨èçæåä¸¦ç¶­è­·å°è©±çæãç¶èï¼ç¾æç DST æ¹æ³éå¸¸ä¾è³´æ¼åºå®çæ¬ä½åæåç·¨è­¯çæ§½ä½å¼ï¼ééå¶äºå®åå°éæ¾é åå°è©±çé©ææ§ãæåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼å®å©ç¨æä»¤èª¿æ´ååé²çæç¤ºç­ç¥ä¾å¢å¼· DST æè½ï¼èç¡éä¾è³´ä»»ä½é å®ç¾©çæ¬ä½ãæåçæ¹æ³ä½¿å¤§åèªè¨æ¨¡å (LLM) è½å¤ ééç²¾å¿è¨­è¨çæç¤ºä¾æ¨è«å°è©±çæï¼ä¸¦åå«ä¸ååå¹»è¦ºæ©å¶ï¼ä»¥ç¢ºä¿å¨ä¸åçå°è©±æå¢ä¸­æºç¢ºè¿½è¹¤ãæ­¤å¤ï¼æåæ¡ç¨è®ååèªç·¨ç¢¼å¨ (VGAE) ä¾å»ºæ¨¡åé æ¸¬å¾çºä½¿ç¨èçæåãæåçåæ³ä»¥ 42.57% ç JGA éå°äºç¾ææè¡çé å³°ï¼åªæ¼ç¾æçç¡æ¬ä½ DST æ¨¡åï¼ä¸¦å¨éæ¾é åççå¯¦å°è©±ä¸­è¡¨ç¾è¯å¥½ãéé å·¥ä½å¨å»ºç«æ´å·é©ææ§åæºç¢ºæ§çä»¥ç®æ¨çºå°åçèå¤©æ©å¨äººæ¹é¢åå¾äºéå¤§é²å±ã

##### **The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation**
2411.00843v1 by Reza Moravej, Saurabh Bodhe, Zhanguang Zhang, Didier Chetelat, Dimitrios Tsaras, Yingxue Zhang, Hui-Ling Zhen, Jianye Hao, Mingxuan Yuan

Logic synthesis is a crucial phase in the circuit design process, responsible
for transforming hardware description language (HDL) designs into optimized
netlists. However, traditional logic synthesis methods are computationally
intensive, restricting their iterative use in refining chip designs. Recent
advancements in large language models (LLMs), particularly those fine-tuned on
programming languages, present a promising alternative. In this paper, we
introduce VeriDistill, the first end-to-end machine learning model that
directly processes raw Verilog code to predict circuit quality-of-result
metrics. Our model employs a novel knowledge distillation method, transferring
low-level circuit insights via graphs into the predictor based on LLM.
Experiments show VeriDistill outperforms state-of-the-art baselines on
large-scale Verilog datasets and demonstrates robust performance when evaluated
on out-of-distribution datasets.

æè¦ï¼éè¼¯åææ¯é»è·¯è¨­è¨éç¨ä¸­è³ééè¦çä¸åéæ®µï¼è² è²¬å°ç¡¬é«æè¿°èªè¨ (HDL) è¨­è¨è½æçºæä½³åçç¶²è·¯è¡¨ãç¶èï¼å³çµ±çéè¼¯åææ¹æ³å¨éç®ä¸å¾å¯éï¼éå¶äºå®åå¨ç²¾çæ¶çè¨­è¨ä¸­çåè¦ä½¿ç¨ãæè¿å¤§åèªè¨æ¨¡å (LLM) çé²å±ï¼ç¹å¥æ¯é£äºç¶éç¨å¼èªè¨å¾®èª¿çï¼æä¾äºä¸åæå¸æçæ¿ä»£æ¹æ¡ãå¨æ¬æä¸­ï¼æåä»ç´¹äº VeriDistillï¼ç¬¬ä¸åç«¯å°ç«¯çæ©å¨å­¸ç¿æ¨¡åï¼å®ç´æ¥èçåå§ Verilog ç¨å¼ç¢¼ä»¥é æ¸¬é»è·¯åè³ªçµæææ¨ãæåçæ¨¡åæ¡ç¨äºä¸ç¨®æ°ç©çç¥è­æçæ¹æ³ï¼ééåè¡¨å°ä½éé»è·¯è¦è§£å³è¼¸å°åºæ¼ LLM çé æ¸¬å¨ä¸­ãå¯¦é©è¡¨æï¼VeriDistill å¨å¤§è¦æ¨¡ Verilog è³æéä¸åªæ¼æåé²çåºæºï¼ä¸¦ä¸å¨å¨åä½å¤è³æéä¸é²è¡è©ä¼°æè¡¨ç¾åºç©©å¥çæè½ã

##### **Are Large-Language Models Graph Algorithmic Reasoners?**
2410.22597v1 by Alexander K Taylor, Anthony Cuturrufo, Vishal Yathish, Mingyu Derek Ma, Wei Wang

We seek to address a core challenge facing current Large Language Models
(LLMs). LLMs have demonstrated superior performance in many tasks, yet continue
to struggle with reasoning problems on explicit graphs that require multiple
steps. To address this gap, we introduce a novel benchmark designed to evaluate
LLM performance on classical algorithmic reasoning tasks on explicit graphs.
Our benchmark encompasses five fundamental algorithms: Breadth-First Search
(BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and
Floyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum
Spanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we
assess the capabilities of state-of-the-art LLMs in executing these algorithms
step-by-step and systematically evaluate their performance at each stage. Our
findings highlight the persistent challenges LLMs face in this domain and
underscore the necessity for advanced prompting techniques and algorithmic
instruction to enhance their graph reasoning abilities. This work presents
MAGMA, the first comprehensive benchmark focused on LLMs completing classical
graph algorithms, and provides a critical step toward understanding and
improving their structured problem-solving skills.

æè¦ï¼æåè©¦åè§£æ±ºç¶åå¤§åèªè¨æ¨¡å (LLM) é¢è¨çæ ¸å¿ææ°ãLLM å¨è¨±å¤ä»»åä¸­è¡¨ç¾åºåªç°çæ§è½ï¼ä½ä»é£ä»¥æå°éè¦å¤åæ­¥é©çæç¢ºåè¡¨ä¸­çæ¨çåé¡ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºä¸åæ°çåºæºï¼ç¨æ¼è©ä¼° LLM å¨æç¢ºåè¡¨ä¸çç¶å¸æ¼ç®æ³æ¨çä»»åä¸çæ§è½ãæåçåºæºåå«äºååºæ¬æ¼ç®æ³ï¼å»£åº¦åªåæå° (BFS) åæ·±åº¦åªåæå° (DFS) ä»¥é²è¡é£éæ§ãDijkstra æ¼ç®æ³å Floyd-Warshall æ¼ç®æ³ä»¥æ¾åºææç¯é»çæç­è·¯å¾ï¼ä»¥å Prim æå°çææ¨¹ (MST-Prim) æ¼ç®æ³ãééå»£æ³çå¯¦é©ï¼æåè©ä¼°äºæåé²ç LLM å¨éæ­¥å·è¡éäºæ¼ç®æ³çè½åï¼ä¸¦ç³»çµ±æ§å°è©ä¼°å®åå¨æ¯åéæ®µçæ§è½ãæåçç ç©¶çµæçªåºäº LLM å¨éåé åé¢è¨çæçºææ°ï¼ä¸¦å¼·èª¿äºä½¿ç¨é²éæç¤ºæè¡åæ¼ç®æ³æä»¤ä¾å¢å¼·å¶åå½¢æ¨çè½åçå¿è¦æ§ãéé å·¥ä½æåºäº MAGMAï¼éæ¯ç¬¬ä¸åå°æ³¨æ¼ LLM å®æç¶å¸åå½¢æ¼ç®æ³çç¶ååºæºï¼ä¸¦çºäºè§£åæ¹é²å¶çµæ§ååé¡è§£æ±ºæè½æä¾äºééµçä¸æ­¥ã

##### **Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset**
2410.22457v1 by Adrian Garret Gabriel, Alaa Alameer Ahmad, Shankar Kumar Jeyakumar

Advancements in Large Language Models (LLMs) are revolutionizing the
development of autonomous agentic systems by enabling dynamic, context-aware
task decomposition and automated tool selection. These sophisticated systems
possess significant automation potential across various industries, managing
complex tasks, interacting with external systems to enhance knowledge, and
executing actions independently. This paper presents three primary
contributions to advance this field:
  - Advanced Agentic Framework: A system that handles multi-hop queries,
generates and executes task graphs, selects appropriate tools, and adapts to
real-time changes.
  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural
Similarity Index (SSI), and Tool F1 Score to comprehensively assess agentic
systems.
  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing
agent behavior across different task complexities.
  Our findings reveal that asynchronous and dynamic task graph decomposition
significantly enhances system responsiveness and scalability, particularly for
complex, multi-step tasks. Detailed analysis shows that structural and
node-level metrics are crucial for sequential tasks, while tool-related metrics
are more important for parallel tasks. Specifically, the Structural Similarity
Index (SSI) is the most significant predictor of performance in sequential
tasks, and the Tool F1 Score is essential for parallel tasks. These insights
highlight the need for balanced evaluation methods that capture both structural
and operational dimensions of agentic systems. Additionally, our evaluation
framework, validated through empirical analysis and statistical testing,
provides valuable insights for improving the adaptability and reliability of
agentic systems in dynamic environments.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çé²å±æ­£ééåç¨åæãå·æå¢æç¥è½åçä»»ååè§£åèªååå·¥å·é¸æï¼é©æ°èªä¸»ä»£çç³»çµ±çéç¼ãéäºç²¾å¯çç³»çµ±å¨åç¢æ¥­ä¸­ææé¡¯èçèªååæ½åï¼ç®¡çè¤éçä»»åãèå¤é¨ç³»çµ±äºåä»¥å¢å¼·ç¥è­ï¼ä¸¦ç¨ç«å·è¡åä½ãæ¬ææåºäºä¸åä¸»è¦è²¢ç»ä»¥æ¨åéåé åçé²å±ï¼
  - é²éä»£çæ¶æ§ï¼ä¸ç¨®èçå¤éè·³èºæ¥è©¢ãç¢çä¸¦å·è¡ä»»ååè¡¨ãé¸æé©ç¶çå·¥å·ï¼ä¸¦é©æå³æè®åçç³»çµ±ã
  - æ°ç©çè©ä¼°ææ¨ï¼å°å¥ç¯é» F1 åæ¸ãçµæ§ç¸ä¼¼æ§ææ¨ (SSI) åå·¥å· F1 åæ¸ï¼ä»¥å¨é¢è©ä¼°ä»£çç³»çµ±ã
  - å°æ¥­è³æéï¼éç¼ä¸ååºæ¼ AsyncHow çè³æéï¼ç¨æ¼åæä»£çè¡çºå¨ä¸åä»»åè¤éåº¦ä¹éçå·®ç°ã
  æåçç ç©¶çµæé¡¯ç¤ºï¼éåæ­¥ååæä»»ååè¡¨åè§£è½é¡¯èå¢å¼·ç³»çµ±çåæè½ååå¯æ´åæ§ï¼ç¹å¥æ¯å°æ¼è¤éçå¤æ­¥é©ä»»åãè©³ç´°çåæé¡¯ç¤ºï¼çµæ§åç¯é»å±¤ç´çææ¨å°æ¼é åºä»»åè³ééè¦ï¼èèå·¥å·ç¸éçææ¨å°æ¼ä¸¦è¡ä»»åæ´çºéè¦ãå·é«ä¾èªªï¼çµæ§ç¸ä¼¼æ§ææ¨ (SSI) æ¯é åºä»»åä¸­æè½æé¡¯èçé æ¸¬ææ¨ï¼èå·¥å· F1 åæ¸å°æ¼ä¸¦è¡ä»»åè³ééè¦ãéäºè¦è§£çªé¡¯äºå¹³è¡¡è©ä¼°æ¹æ³çéæ±ï¼è©²æ¹æ³è½ææä»£çç³»çµ±ççµæ§åæä½é¢åãæ­¤å¤ï¼æåçè©ä¼°æ¶æ§ééå¯¦è­åæåçµ±è¨æª¢å®é©è­ï¼çºæ¹åä»£çç³»çµ±å¨åæç°å¢ä¸­çé©ææ§åå¯é æ§æä¾äºæå¹å¼çè¦è§£ã

##### **DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models**
2411.00836v1 by Chengke Zou, Xingang Guo, Rui Yang, Junyu Zhang, Bin Hu, Huan Zhang

The rapid advancements in Vision-Language Models (VLMs) have shown great
potential in tackling mathematical reasoning tasks that involve visual context.
Unlike humans who can reliably apply solution steps to similar problems with
minor modifications, we found that SOTA VLMs like GPT-4o can consistently fail
in these scenarios, revealing limitations in their mathematical reasoning
capabilities. In this paper, we investigate the mathematical reasoning
robustness in VLMs and evaluate how well these models perform under different
variants of the same question, such as changes in visual numerical values or
function graphs. While several vision-based math benchmarks have been developed
to assess VLMs' problem-solving capabilities, these benchmarks contain only
static sets of problems and cannot easily evaluate mathematical reasoning
robustness. To fill this gap, we introduce DynaMath, a dynamic visual math
benchmark designed for in-depth assessment of VLMs. DynaMath includes 501
high-quality, multi-topic seed questions, each represented as a Python program.
Those programs are carefully designed and annotated to enable the automatic
generation of a much larger set of concrete questions, including many different
types of visual and textual variations. DynaMath allows us to evaluate the
generalization ability of VLMs, by assessing their performance under varying
input conditions of a seed question. We evaluated 14 SOTA VLMs with 5,010
generated concrete questions. Our results show that the worst-case model
accuracy, defined as the percentage of correctly answered seed questions in all
10 variants, is significantly lower than the average-case accuracy. Our
analysis emphasizes the need to study the robustness of VLMs' reasoning
abilities, and DynaMath provides valuable insights to guide the development of
more reliable models for mathematical reasoning.

æè¦ï¼<paragraph>è¦è¦ºèªè¨æ¨¡å (VLM) çå¿«éé²æ­¥å¨è§£æ±ºæ¶åè¦è¦ºèæ¯çæ¸å­¸æ¨çä»»åæ¹é¢å±ç¾äºå·¨å¤§çæ½åãèäººé¡å¯ä»¥å°è§£æ±ºæ­¥é©å¯é å°æç¨æ¼é¡ä¼¼åé¡ï¼ä¸¦é²è¡å¾®å°çä¿®æ¹ï¼ä¸åï¼æåç¼ç¾å GPT-4o ç­ SOTA VLM å¨éäºå ´æ¯ä¸­å¯è½ææçºå¤±æï¼æ­é²äºå¶æ¸å­¸æ¨çè½åçéå¶ãå¨æ¬æä¸­ï¼æåç ç©¶äº VLM ä¸­çæ¸å­¸æ¨çç©©å¥æ§ï¼ä¸¦è©ä¼°äºéäºæ¨¡åå¨åä¸åé¡çä¸åè®é«ï¼ä¾å¦è¦è¦ºæ¸å¼æå½æ¸åå½¢çè®åï¼ä¸çè¡¨ç¾ãéç¶å·²ç¶éç¼äºå¤ååºæ¼è¦è¦ºçæ¸å­¸åºæºä¾è©ä¼° VLM çåé¡è§£æ±ºè½åï¼ä½éäºåºæºåªåå«éæåé¡éï¼ç¡æ³è¼é¬è©ä¼°æ¸å­¸æ¨çç©©å¥æ§ãçºäºå¡«è£éä¸ç©ºç½ï¼æåå¼å¥äº DynaMathï¼éæ¯ä¸ååæè¦è¦ºæ¸å­¸åºæºï¼å°éç¨æ¼æ·±å¥è©ä¼° VLMãDynaMath åå« 501 åé«åè³ªãå¤ä¸»é¡ç¨®å­åé¡ï¼æ¯ååé¡é½è¡¨ç¤ºçºä¸å Python ç¨å¼ãéäºç¨å¼ç¶éä»ç´°è¨­è¨åè¨»è§£ï¼ä»¥ä¾¿èªåç¢çä¸çµæ´å¤§çå·é«åé¡ï¼åæ¬è¨±å¤ä¸åé¡åçè¦è¦ºåæå­è®é«ãDynaMath åè¨±æåè©ä¼° VLM çæ³åè½åï¼æ¹æ³æ¯å¨ç¨®å­åé¡çä¸åè¼¸å¥æ¢ä»¶ä¸è©ä¼°å¶è¡¨ç¾ãæåä½¿ç¨ 5,010 åçæçå·é«åé¡è©ä¼°äº 14 å SOTA VLMãæåççµæé¡¯ç¤ºï¼æå·®ææ³çæ¨¡åæºç¢ºåº¦ï¼å®ç¾©çºå¨ææ 10 åè®é«ä¸­æ­£ç¢ºåç­çç¨®å­åé¡çç¾åæ¯ï¼é¡¯èä½æ¼å¹³åææ³æºç¢ºåº¦ãæåçåæå¼·èª¿äºç ç©¶ VLM æ¨çè½åç©©å¥æ§çå¿è¦æ§ï¼è DynaMath æä¾äºæå¹å¼çè¦è§£ï¼ä»¥æå°éç¼æ´å¯é çæ¸å­¸æ¨çæ¨¡åã</paragraph>

##### **ADAM: An Embodied Causal Agent in Open-World Environments**
2410.22194v1 by Shu Yu, Chaochao Lu

In open-world environments like Minecraft, existing agents face challenges in
continuously learning structured knowledge, particularly causality. These
challenges stem from the opacity inherent in black-box models and an excessive
reliance on prior knowledge during training, which impair their
interpretability and generalization capability. To this end, we introduce ADAM,
An emboDied causal Agent in Minecraft, that can autonomously navigate the open
world, perceive multimodal contexts, learn causal world knowledge, and tackle
complex tasks through lifelong learning. ADAM is empowered by four key
components: 1) an interaction module, enabling the agent to execute actions
while documenting the interaction processes; 2) a causal model module, tasked
with constructing an ever-growing causal graph from scratch, which enhances
interpretability and diminishes reliance on prior knowledge; 3) a controller
module, comprising a planner, an actor, and a memory pool, which uses the
learned causal graph to accomplish tasks; 4) a perception module, powered by
multimodal large language models, which enables ADAM to perceive like a human
player. Extensive experiments show that ADAM constructs an almost perfect
causal graph from scratch, enabling efficient task decomposition and execution
with strong interpretability. Notably, in our modified Minecraft games where no
prior knowledge is available, ADAM maintains its performance and shows
remarkable robustness and generalization capability. ADAM pioneers a novel
paradigm that integrates causal methods and embodied agents in a synergistic
manner. Our project page is at https://opencausalab.github.io/ADAM.

æè¦ï¼å¨å Minecraft éæ¨£çéæ¾ä¸çç°å¢ä¸­ï¼ç¾æçä»£çäººé¢è¨æçºå­¸ç¿çµæ§åç¥è­çææ°ï¼å°¤å¶æ¯å æéä¿ãéäºææ°æºæ¼é»çæ¨¡ååºæçä¸éææ§ï¼ä»¥åå¨è¨ç·´æééåº¦ä¾è³´åé©ç¥è­ï¼éææå®³å®åçå¯è§£éæ§åæ³åè½åãçºæ­¤ï¼æåå¼å¥äº ADAMï¼Minecraft ä¸­çä¸åå·èº«å æä»£çï¼å®å¯ä»¥èªä¸»å°èªéæ¾ä¸çï¼æç¥å¤æ¨¡å¼ä¸ä¸æï¼å­¸ç¿å æä¸çç¥è­ï¼ä¸¦ééçµèº«å­¸ç¿ä¾æå°è¤éä»»åãADAM ç±ååééµçµæé¨åè³¦è½ï¼1) ä¸åäº¤äºæ¨¡çµï¼ä½¿ä»£çè½å¤ å·è¡åä½ï¼åæè¨éäº¤äºéç¨ï¼2) ä¸åå ææ¨¡åæ¨¡çµï¼è² è²¬å¾é ­éå§æ§å»ºä¸åä¸æ·å¢é·çå æåï¼éå¢å¼·äºå¯è§£éæ§ä¸¦æ¸å°äºå°åé©ç¥è­çä¾è³´ï¼3) ä¸åæ§å¶å¨æ¨¡çµï¼åæ¬ä¸åè¦åå¨ãä¸åå·è¡å¨åä¸åè¨æ¶æ± ï¼å®ä½¿ç¨å­¸ç¿å°çå æåä¾å®æä»»åï¼4) ä¸åæç¥æ¨¡çµï¼ç±å¤æ¨¡å¼å¤§åèªè¨æ¨¡åæä¾æ¯æ´ï¼ä½¿ ADAM è½å¤ åäººé¡ç©å®¶ä¸æ¨£æç¥ãå¤§éçå¯¦é©è¡¨æï¼ADAM å¾é ­éå§æ§å»ºäºä¸åå¹¾ä¹å®ç¾çå æåï¼å¯¦ç¾äºé«æçä»»ååè§£åå·è¡ï¼ä¸¦å·æå¾å¼·çå¯è§£éæ§ãå¼å¾æ³¨æçæ¯ï¼å¨æåä¿®æ¹éç Minecraft éæ²ä¸­ï¼æ²æå¯ç¨çåé©ç¥è­ï¼ADAM ä¿æäºå¶æ§è½ï¼ä¸¦è¡¨ç¾åºé¡¯èçé­¯æ£æ§åæ³åè½åãADAM éåµäºä¸ç¨®æ°ç©çç¯ä¾ï¼ä»¥ååæ¹å¼æ´åå ææ¹æ³åå·èº«ä»£çãæåçå°æ¡é é¢ä½æ¼ https://opencausalab.github.io/ADAMã

##### **GraphAide: Advanced Graph-Assisted Query and Reasoning System**
2411.08041v1 by Sumit Purohit, George Chin, Patrick S Mackey, Joseph A Cottam

Curating knowledge from multiple siloed sources that contain both structured
and unstructured data is a major challenge in many real-world applications.
Pattern matching and querying represent fundamental tasks in modern data
analytics that leverage this curated knowledge. The development of such
applications necessitates overcoming several research challenges, including
data extraction, named entity recognition, data modeling, and designing query
interfaces. Moreover, the explainability of these functionalities is critical
for their broader adoption.
  The emergence of Large Language Models (LLMs) has accelerated the development
lifecycle of new capabilities. Nonetheless, there is an ongoing need for
domain-specific tools tailored to user activities. The creation of digital
assistants has gained considerable traction in recent years, with LLMs offering
a promising avenue to develop such assistants utilizing domain-specific
knowledge and assumptions.
  In this context, we introduce an advanced query and reasoning system,
GraphAide, which constructs a knowledge graph (KG) from diverse sources and
allows to query and reason over the resulting KG. GraphAide harnesses both the
KG and LLMs to rapidly develop domain-specific digital assistants. It
integrates design patterns from retrieval augmented generation (RAG) and the
semantic web to create an agentic LLM application. GraphAide underscores the
potential for streamlined and efficient development of specialized digital
assistants, thereby enhancing their applicability across various domains.

æè¦ï¼å¾åå«çµæ§ååéçµæ§åè³æçå¤åå­¤ç«ä¾æºä¸­æ´çç¥è­ï¼æ¯è¨±å¤å¯¦éæç¨ä¸­çä¸é éå¤§ææ°ã
æ¨¡å¼æ¯å°åæ¥è©¢ä»£è¡¨äºç¾ä»£è³æåæçåºæ¬ä»»åï¼å©ç¨éäºæ´çå¥½çç¥è­ãéç¨®æç¨çç¼å±éè¦åæå¤é ç ç©¶ææ°ï¼åæ¬è³æèåãå½åå¯¦é«è¾¨è­ãè³æå»ºæ¨¡åè¨­è¨æ¥è©¢ä»é¢ãæ­¤å¤ï¼éäºåè½çå¯è§£éæ§å°æ¼å¶æ´å»£æ³çæ¡ç¨è³ééè¦ã
å¤§åèªè¨æ¨¡å (LLM) çåºç¾å éäºæ°åè½çéç¼é±æãåç®¡å¦æ­¤ï¼ä»ç¶éè¦éå°ä½¿ç¨èæ´»åéèº«æé çç¹å®é åå·¥å·ãè¿å¹´ä¾ï¼æ¸ä½å©ççå»ºç«ç²å¾äºç¸ç¶å¤§çé²å±ï¼LLM æä¾äºä¸åæåéçéå¾ï¼å¯ä»¥å©ç¨ç¹å®é åçç¥è­ååè¨­ä¾éç¼æ­¤é¡å©çã
å¨æ­¤èæ¯ä¸ï¼æåä»ç´¹äºä¸ååé²çæ¥è©¢åæ¨çç³»çµ± GraphAideï¼å®å¾ä¸åçä¾æºæ§å»ºä¸åç¥è­åè­ (KG)ï¼ä¸¦åè¨±æ¥è©¢åæ¨çæå¾ç KGãGraphAide å©ç¨ KG å LLM ä¾å¿«ééç¼ç¹å®é åçæ¸ä½å©çãå®æ´åäºæª¢ç´¢æ´åçæ (RAG) åèªç¾©ç¶²è·¯çè¨­è¨æ¨¡å¼ï¼ä»¥å»ºç«ä¸åä»£ç LLM æç¨ç¨å¼ãGraphAide å¼·èª¿äºç°¡ååææéç¼å°æ¥­æ¸ä½å©ççæ½åï¼å¾èå¢å¼·å¶å¨ååé åçé©ç¨æ§ã

##### **Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN**
2411.00028v1 by Zhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, Yong Li

The fast development of location-based social networks (LBSNs) has led to
significant changes in society, resulting in popular studies of using LBSN data
for socioeconomic prediction, e.g., regional population and commercial activity
estimation. Existing studies design various graphs to model heterogeneous LBSN
data, and further apply graph representation learning methods for socioeconomic
prediction. However, these approaches heavily rely on heuristic ideas and
expertise to extract task-relevant knowledge from diverse data, which may not
be optimal for specific tasks. Additionally, they tend to overlook the inherent
relationships between different indicators, limiting the prediction accuracy.
Motivated by the remarkable abilities of large language models (LLMs) in
commonsense reasoning, embedding, and multi-agent collaboration, in this work,
we synergize LLM agents and knowledge graph for socioeconomic prediction. We
first construct a location-based knowledge graph (LBKG) to integrate
multi-sourced LBSN data. Then we leverage the reasoning power of LLM agent to
identify relevant meta-paths in the LBKG for each type of socioeconomic
prediction task, and design a semantic-guided attention module for knowledge
fusion with meta-paths. Moreover, we introduce a cross-task communication
mechanism to further enhance performance by enabling knowledge sharing across
tasks at both LLM agent and KG levels. On the one hand, the LLM agents for
different tasks collaborate to generate more diverse and comprehensive
meta-paths. On the other hand, the embeddings from different tasks are
adaptively merged for better socioeconomic prediction. Experiments on two
datasets demonstrate the effectiveness of the synergistic design between LLM
and KG, providing insights for information sharing across socioeconomic
prediction tasks.

æè¦ï¼åºæ¼ä½ç½®çç¤¾äº¤ç¶²è·¯ (LBSN) çå¿«éç¼å±å·²å°è´ç¤¾æç¼çéå¤§è®é©ï¼é²èä¿æä½¿ç¨ LBSN è³æé²è¡ç¤¾æç¶æ¿é æ¸¬çç±éç ç©¶ï¼ä¾å¦ååäººå£ååæ¥­æ´»åä¼°è¨ãç¾æç ç©¶è¨­è¨åç¨®åå½¢ä¾å»ºæ¨¡ç°è³ªç LBSN è³æï¼ä¸¦é²ä¸æ­¥æç¨åå½¢è¡¨ç¤ºå­¸ç¿æ¹æ³é²è¡ç¤¾æç¶æ¿é æ¸¬ãç¶èï¼éäºæ¹æ³æ¥µåº¦ä¾è³´åç¼å¼æ³æ³åå°æ¥­ç¥è­å¾ä¸åçè³æä¸­èåèä»»åç¸éçç¥è­ï¼éå°æ¼ç¹å®ä»»åèè¨å¯è½ä¸æ¯æä½³çãæ­¤å¤ï¼å®åå¾åæ¼å¿½ç¥ä¸åææ¨ä¹éçåºæéä¿ï¼é²èéå¶é æ¸¬æºç¢ºåº¦ãåæ æ¼å¤§åèªè¨æ¨¡å (LLM) å¨å¸¸è­æ¨çãåµå¥åå¤éä»£çåä½æ¹é¢çåè¶è½åï¼å¨éé å·¥ä½ä¸­ï¼æåå° LLM ä»£çåç¥è­åå½¢çµåèµ·ä¾é²è¡ç¤¾æç¶æ¿é æ¸¬ãæåé¦åå»ºæ§ä¸ååºæ¼ä½ç½®çç¥è­åå½¢ (LBKG) ä¾æ´åå¤ä¾æºç LBSN è³æãç¶å¾ï¼æåå©ç¨ LLM ä»£ççæ¨çè½åï¼éå°æ¯ç¨®é¡åçç¤¾æç¶æ¿é æ¸¬ä»»åè­å¥ LBKG ä¸­ç¸éç meta è·¯å¾ï¼ä¸¦è¨­è¨ä¸åèªç¾©å°åçæ³¨æåæ¨¡çµï¼ç¨æ¼è meta è·¯å¾çç¥è­èåãæ­¤å¤ï¼æåå¼å¥ä¸åè·¨ä»»åæºéæ©å¶ï¼ä»¥ééå¨ LLM ä»£çå KG å±¤ç´ä¸è·¨ä»»ååç¨ç¥è­å±äº«é²ä¸æ­¥æåæè½ãä¸æ¹é¢ï¼ä¸åä»»åç LLM ä»£çåä½ç¢çæ´å¤æ¨£åä¸å¨é¢ç meta è·¯å¾ãå¦ä¸æ¹é¢ï¼ä¾èªä¸åä»»åçåµå¥æèªé©æå°åä½µï¼ä»¥é²è¡æ´å¥½çç¤¾æç¶æ¿é æ¸¬ãå¨å©åè³æéä¸çå¯¦é©è­æäº LLM å KG ä¹éååè¨­è¨çæææ§ï¼ä¸¦æä¾è·¨ç¤¾æç¶æ¿é æ¸¬ä»»åé²è¡è³è¨å±äº«çè¦è§£ã

##### **A Hierarchical Language Model For Interpretable Graph Reasoning**
2410.22372v1 by Sambhav Khurana, Xiner Li, Shurui Gui, Shuiwang Ji

Large language models (LLMs) are being increasingly explored for graph tasks.
Despite their remarkable success in text-based tasks, LLMs' capabilities in
understanding explicit graph structures remain limited, particularly with large
graphs. In this work, we introduce Hierarchical Language Model for Graph
(HLM-G), which employs a two-block architecture to capture node-centric local
information and interaction-centric global structure, effectively enhancing
graph structure understanding abilities. The proposed scheme allows LLMs to
address various graph queries with high efficacy, efficiency, and robustness,
while reducing computational costs on large-scale graph tasks. Furthermore, we
demonstrate the interpretability of our model using intrinsic attention weights
and established explainers. Comprehensive evaluations across diverse graph
reasoning and real-world tasks of node, link, and graph-levels highlight the
superiority of our method, marking a significant advancement in the application
of LLMs to graph understanding.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æä¾æå¤ç¨æ¼åå½¢ä»»åã
åç®¡ LLM å¨åºæ¼æå­çä»»åä¸­åå¾é¡¯èçæåï¼ä½å¶å¨çè§£æç¢ºåå½¢çµæ§æ¹é¢çè½åä»ç¶æéï¼ç¹å¥æ¯å°æ¼å¤§ååå½¢ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºåå½¢éå±¤èªè¨æ¨¡å (HLM-G)ï¼å®æ¡ç¨éåå¡æ¶æ§ä¾æ·åä»¥ç¯é»çºä¸­å¿çå±é¨è³è¨åä»¥äºåçºä¸­å¿çæ´é«çµæ§ï¼ææå°å¢å¼·äºåå½¢çµæ§çè§£è½åãææåºçæ¶æ§åè¨± LLM ä»¥é«æçãé«æçåé«ç©©å¥æ§ä¾èçåç¨®åå½¢æ¥è©¢ï¼åæéä½å¤§ååå½¢ä»»åçéç®ææ¬ãæ­¤å¤ï¼æåä½¿ç¨å§å¨æ³¨æåæ¬éåå·²å»ºç«çè§£éå¨ä¾å±ç¤ºæåæ¨¡åçå¯è§£éæ§ãå¨ç¯é»ãé£çµååå½¢å±¤ç´çåç¨®åå½¢æ¨çåçå¯¦ä¸çä»»åä¸­é²è¡çå¨é¢è©ä¼°çªé¡¯äºæåæ¹æ³çåªè¶æ§ï¼æ¨èªè LLM å¨åå½¢çè§£æç¨æ¹é¢åå¾éå¤§é²å±ã

##### **LLM-Forest for Health Tabular Data Imputation**
2410.21520v1 by Xinrui He, Yikun Ban, Jiaru Zou, Tianxin Wei, Curtiss B. Cook, Jingrui He

Missing data imputation is a critical challenge in tabular datasets,
especially in healthcare, where data completeness is vital for accurate
analysis. Large language models (LLMs), trained on vast corpora, have shown
strong potential in data generation, making them a promising tool for tabular
data imputation. However, challenges persist in designing effective prompts for
a finetuning-free process and in mitigating the risk of LLM hallucinations. To
address these issues, we propose a novel framework, LLM-Forest, which
introduces a "forest" of few-shot learning LLM "trees" with confidence-based
weighted voting. This framework is established on a new concept of bipartite
information graphs to identify high-quality relevant neighboring entries with
both feature and value granularity. Extensive experiments on four real-world
healthcare datasets demonstrate the effectiveness and efficiency of LLM-Forest.

æè¦ï¼éºå¤±è³ææ¨ä¼°æ¯è¡¨æ ¼è³æéä¸­çéå¤§ææ°ï¼
ç¹å¥æ¯å¨é«çä¿å¥ä¸­ï¼è³æå®æ´æ§å°æ¼æºç¢ºåæè³ééè¦ã
å¤§åèªè¨æ¨¡å (LLM) å¨é¾å¤§çèªæåº«ä¸è¨ç·´ï¼å¨è³æç¢çæ¹é¢å±ç¾åºå¼·å¤§çæ½åï¼ä½¿å¶æçºè¡¨æ ¼è³ææ¨ä¼°çæåéå·¥å·ã
ç¶èï¼å¨è¨­è¨æææç¤ºä»¥é²è¡å¾®èª¿åè²»æµç¨åæ¸è¼ LLM å¹»è¦ºé¢¨éªæ¹é¢ä»å­å¨ææ°ã
çºäºè§£æ±ºéäºåé¡ï¼æåæåºä¸åæ°çæ¡æ¶ï¼LLM-Forestï¼å®å¼å¥äºä¸åãæ£®æãçå°éå­¸ç¿ LLMãæ¨¹ãï¼ä¸¦æ¡ç¨åºæ¼ä¿¡å¿çå æ¬æç¥¨ã
éåæ¡æ¶å»ºç«å¨éåè³è¨åçæ°æ¦å¿µä¸ï¼ä»¥è­å¥å·æç¹å¾µåå¼ç²åº¦çåªè³ªç¸éé°è¿é ç®ã
å¨ååçå¯¦ä¸ççé«çä¿å¥è³æéä¸é²è¡çå»£æ³å¯¦é©è­æäº LLM-Forest çæææ§åæçã

##### **Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**
2410.21237v1 by Zhantao Yang, Han Zhang, Fangyi Chen, Anudeepsekhar Bolimera, Marios Savvides

Knowledge Graph (KG) is playing an increasingly important role in various AI
systems. For e-commerce, an efficient and low-cost automated knowledge graph
construction method is the foundation of enabling various successful downstream
applications. In this paper, we propose a novel method for constructing
structured product knowledge graphs from raw product images. The method
cooperatively leverages recent advances in the vision-language model (VLM) and
large language model (LLM), fully automating the process and allowing timely
graph updates. We also present a human-annotated e-commerce product dataset for
benchmarking product property extraction in knowledge graph construction. Our
method outperforms our baseline in all metrics and evaluated properties,
demonstrating its effectiveness and bright usage potential.

æè¦ï¼ç¥è­åè­ (KG) å¨åç¨® AI ç³»çµ±ä¸­æ®æ¼è¶ä¾è¶éè¦çè§è²ãå°æ¼é»å­ååä¾èªªï¼ä¸ç¨®ææä¸ä½ææ¬çèªååç¥è­åè­å»ºæ§æ¹æ³æ¯ä¿æåç¨®æåçä¸æ¸¸æç¨ç¨å¼çåºç¤ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®å¾åå§ç¢åå½±åå»ºæ§çµæ§åç¢åç¥è­åè­çæ°ç©æ¹æ³ãè©²æ¹æ³ååå©ç¨äºè¦è¦ºèªè¨æ¨¡å (VLM) åå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±ï¼å®å¨èªååäºæµç¨ä¸¦åè¨±åææ´æ°åè­ãæåéæä¾äºä¸åç±äººå·¥æ¨è¨»çé»å­ååç¢åè³æéï¼ç¨æ¼è©éç¥è­åè­å»ºæ§ä¸­çç¢åå±¬æ§èåãæåçæ¨¡åå¨ææææ¨åè©ä¼°å±¬æ§ä¸é½åªæ¼æåçåºæºï¼è­æäºå¶æææ§åå»£éçä½¿ç¨æ½åã

##### **CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**
2410.21067v1 by Meiqi Chen, Fandong Meng, Yingxue Zhang, Yan Zhang, Jie Zhou

Large language models (LLMs) have shown great promise in machine translation,
but they still struggle with contextually dependent terms, such as new or
domain-specific words. This leads to inconsistencies and errors that are
difficult to address. Existing solutions often depend on manual identification
of such terms, which is impractical given the complexity and evolving nature of
language. While Retrieval-Augmented Generation (RAG) could provide some
assistance, its application to translation is limited by issues such as
hallucinations from information overload. In this paper, we propose CRAT, a
novel multi-agent translation framework that leverages RAG and
causality-enhanced self-reflection to address these challenges. This framework
consists of several specialized agents: the Unknown Terms Identification agent
detects unknown terms within the context, the Knowledge Graph (KG) Constructor
agent extracts relevant internal knowledge about these terms and retrieves
bilingual information from external sources, the Causality-enhanced Judge agent
validates the accuracy of the information, and the Translator agent
incorporates the refined information into the final output. This automated
process allows for more precise and consistent handling of key terms during
translation. Our results show that CRAT significantly improves translation
accuracy, particularly in handling context-sensitive terms and emerging
vocabulary.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¨æ©å¨ç¿»è­¯æ¹é¢å±ç¾åºæ¥µå¤§çåæ¯ï¼
ä½å®åä»ç¶é£ä»¥æå°ä¾è³´æ¼èªå¢çè©å½ï¼ä¾å¦æ°è©æç¹å®é åçè©å½ãéæå°è´ä¸ä¸è´åé¯èª¤ï¼èéäºé¯èª¤å¾é£è§£æ±ºãç¾æçè§£æ±ºæ¹æ¡éå¸¸ä¾è³´æ¼æåè­å¥æ­¤é¡è©å½ï¼ä½ç±æ¼èªè¨çè¤éæ§åä¸æ·æ¼è®çç¹æ§ï¼éä¸¦ä¸å¯è¡ãéç¶æª¢ç´¢å¢å¼·çæï¼RAGï¼å¯ä»¥æä¾ä¸äºåå©ï¼ä½å¶å¨ç¿»è­¯ä¸­çæç¨åå°è«¸å¦è³è¨è¶è¼ç¢ççå¹»è¦ºç­åé¡çéå¶ãå¨æ¬æä¸­ï¼æåæåº CRATï¼éæ¯ä¸åæ°ç©çå¤ä»£çç¿»è­¯æ¶æ§ï¼å®å©ç¨ RAG åå æå¢å¼·èªçä¾æå°éäºææ°ãæ­¤æ¶æ§åå«å¹¾åå°éçä»£çï¼æªç¥è©å½è­å¥ä»£çæåµæ¸¬èªå¢ä¸­çæªç¥è©å½ï¼ç¥è­åè­ï¼KGï¼å»ºæ§ä»£çææ·åéäºè©å½ç¸éçå§é¨ç¥è­ï¼ä¸¦å¾å¤é¨ä¾æºä¸­æª¢ç´¢éèªè³è¨ï¼å æå¢å¼·å¤æ·ä»£çæé©è­è³è¨çæºç¢ºæ§ï¼èç¿»è­¯ä»£çæå°ç²¾çéçè³è¨ç´å¥æçµè¼¸åºãéåèªååçæµç¨åè¨±å¨ç¿»è­¯éç¨ä¸­æ´ç²¾ç¢ºä¸ä¸è´å°èçééµè©å½ãæåççµæé¡¯ç¤ºï¼CRAT å¤§å¹æåäºç¿»è­¯æºç¢ºæ§ï¼ç¹å¥æ¯å¨èçå°èªå¢ææçè©å½åæ°èè©å½æ¹é¢ã

##### **CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**
2410.21060v1 by Yutong Cheng, Osama Bajaber, Saimon Amanuel Tsegai, Dawn Song, Peng Gao

Textual descriptions in cyber threat intelligence (CTI) reports, such as
security articles and news, are rich sources of knowledge about cyber threats,
crucial for organizations to stay informed about the rapidly evolving threat
landscape. However, current CTI extraction methods lack flexibility and
generalizability, often resulting in inaccurate and incomplete knowledge
extraction. Syntax parsing relies on fixed rules and dictionaries, while model
fine-tuning requires large annotated datasets, making both paradigms
challenging to adapt to new threats and ontologies. To bridge the gap, we
propose CTINexus, a novel framework leveraging optimized in-context learning
(ICL) of large language models (LLMs) for data-efficient CTI knowledge
extraction and high-quality cybersecurity knowledge graph (CSKG) construction.
Unlike existing methods, CTINexus requires neither extensive data nor parameter
tuning and can adapt to various ontologies with minimal annotated examples.
This is achieved through (1) a carefully designed automatic prompt construction
strategy with optimal demonstration retrieval for extracting a wide range of
cybersecurity entities and relations; (2) a hierarchical entity alignment
technique that canonicalizes the extracted knowledge and removes redundancy;
(3) an ICL-enhanced long-distance relation prediction technique to further
complete the CKSG with missing links. Our extensive evaluations using 150
real-world CTI reports collected from 10 platforms demonstrate that CTINexus
significantly outperforms existing methods in constructing accurate and
complete CSKGs, highlighting its potential to transform CTI analysis with an
efficient and adaptable solution for the dynamic threat landscape.

æè¦ï¼ç¶²è·¯å¨èæå ± (CTI) å ±åä¸­çæå­æè¿°ï¼ä¾å¦å®å¨æç« åæ°èï¼æ¯ç¶²è·¯å¨èçè±å¯ç¥è­ä¾æºï¼å°æ¼çµç¹èè¨è³ééè¦ï¼å¯ä»¥é¨æäºè§£å¿«éæ¼è®çå¨èç°å¢ãç¶èï¼ç®åç CTI æåæ¹æ³ç¼ºä¹éæ´»æ§ä¸é£ä»¥æ¦æ¬ï¼éå¸¸æå°è´ç¥è­æåä¸æºç¢ºä¸ä¸å®æ´ãèªæ³è§£æä¾è³´æ¼åºå®è¦ååå­å¸ï¼èæ¨¡åå¾®èª¿éè¦å¤§éæ¨è¨»çè³æéï¼éä½¿å¾éå©ç¨®ç¯ä¾é½é£ä»¥é©ææ°çå¨èåæ¬ä½ãçºäºå½è£å·®è·ï¼æåæåºäº CTINexusï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) çæä½³åæå¢å­¸ç¿ (ICL) ä¾é²è¡è³æææçç CTI ç¥è­æååé«åè³ªçç¶²è·¯å®å¨ç¥è­å (CSKG) å»ºæ§ãèç¾ææ¹æ³ä¸åï¼CTINexus ä¸éè¦å»£æ³çè³ææåæ¸èª¿æ´ï¼ä¸¦ä¸å¯ä»¥ééæå°çæ¨è¨»ç¯ä¾é©æåç¨®æ¬ä½ãéæ¯éé (1) ç¶éç²¾å¿è¨­è¨çèªåæç¤ºå»ºæ§ç­ç¥ï¼ä¸¦ééæä½³ç¤ºç¯æª¢ç´¢ä¾æåå»£æ³çç¶²è·¯å®å¨å¯¦é«åéä¿ä¾å¯¦ç¾çï¼(2) ä¸ç¨®éå±¤å¼å¯¦é«æ¯å°æè¡ï¼å¯ä»¥å°æåçç¥è­æ¨æºåä¸¦æ¶é¤åé¤ï¼(3) ä¸ç¨® ICL å¢å¼·çé·è·é¢éä¿é æ¸¬æè¡ï¼å¯ä»¥é²ä¸æ­¥å®æå·æéºå¤±é£çµç CKSGãæåä½¿ç¨å¾ 10 åå¹³å°æ¶éç 150 ä»½çå¯¦ä¸ç CTI å ±åé²è¡å»£æ³è©ä¼°ï¼è­æ CTINexus å¨å»ºæ§æºç¢ºä¸å®æ´ç CSKG æ¹é¢æé¡¯åªæ¼ç¾ææ¹æ³ï¼çªé¡¯äºå¶ä»¥ææä¸é©ææ§å¼·çè§£æ±ºæ¹æ¡è½æ CTI åæçæ½åï¼ä»¥æå°åæçå¨èç°å¢ã

##### **Graph-based Uncertainty Metrics for Long-form Language Model Outputs**
2410.20783v1 by Mingjian Jiang, Yangjun Ruan, Prasanna Sattigeri, Salim Roukos, Tatsunori Hashimoto

Recent advancements in Large Language Models (LLMs) have significantly
improved text generation capabilities, but these systems are still known to
hallucinate, and granular uncertainty estimation for long-form LLM generations
remains challenging. In this work, we propose Graph Uncertainty -- which
represents the relationship between LLM generations and claims within them as a
bipartite graph and estimates the claim-level uncertainty with a family of
graph centrality metrics. Under this view, existing uncertainty estimation
methods based on the concept of self-consistency can be viewed as using degree
centrality as an uncertainty measure, and we show that more sophisticated
alternatives such as closeness centrality provide consistent gains at
claim-level uncertainty estimation. Moreover, we present uncertainty-aware
decoding techniques that leverage both the graph structure and uncertainty
estimates to improve the factuality of LLM generations by preserving only the
most reliable claims. Compared to existing methods, our graph-based uncertainty
metrics lead to an average of 6.8% relative gains on AUPRC across various
long-form generation settings, and our end-to-end system provides consistent
2-4% gains in factuality over existing decoding techniques while significantly
improving the informativeness of generated responses.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±é¡¯èæåäºæå­çæè½åï¼ä½éäºç³»çµ±ä»ä»¥ç¢çå¹»è¦ºèç¨±ï¼èéå°é·ç¯ LLM çæçç´°ç·»ä¸ç¢ºå®æ§ä¼°è¨ä»æ¯ä¸é ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºåå½¢ä¸ç¢ºå®æ§ï¼å®å° LLM çæåå¶ä¸­çä¸»å¼µè¡¨ç¤ºçºäºé¨åï¼ä¸¦ä½¿ç¨ä¸ç³»ååå½¢ä¸­å¿æ§ææ¨ä¼°è¨ä¸»å¼µå±¤ç´çä¸ç¢ºå®æ§ãå¨æ­¤è§é»ä¸ï¼ç¾æçåºæ¼èªæ´½æ§æ¦å¿µçä¸ç¢ºå®æ§ä¼°è¨æ¹æ³å¯è¦çºä½¿ç¨åº¦éä¸­å¿æ§ä½çºä¸ç¢ºå®æ§ææ¨ï¼æåè­æäºæ´ç²¾å¯çæ¿ä»£æ¹æ¡ï¼ä¾å¦æ¥è¿ä¸­å¿æ§ï¼å¨ä¸»å¼µå±¤ç´ä¸ç¢ºå®æ§ä¼°è¨ä¸­æä¾äºç©©å®çå¢çãæ­¤å¤ï¼æåæåºäºä¸ç¢ºå®æ§æç¥è§£ç¢¼æè¡ï¼è©²æè¡å©ç¨åå½¢çµæ§åä¸ç¢ºå®æ§ä¼°è¨ä¾æå LLM çæççå¯¦æ§ï¼æ¹æ³æ¯åä¿çæå¯é çä¸»å¼µãèç¾ææ¹æ³ç¸æ¯ï¼æåçåºæ¼åå½¢çææ¨å¨åç¨®é·ç¯çæè¨­å®ä¸­å¹³åæåäº AUPRC ç 6.8%ï¼èæåçç«¯å°ç«¯ç³»çµ±å¨çå¯¦æ§æ¹é¢æä¾äº 2-4% çç©©å®å¢çï¼åæé¡¯èæåäºçæåæçè³è¨æ§ã

##### **Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**
2410.20753v1 by Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma

We introduce Planning-guided Retrieval Augmented Generation
(Plan$\times$RAG), a novel framework that augments the
\emph{retrieve-then-reason} paradigm of existing RAG frameworks to
\emph{plan-then-retrieve}. Plan$\times$RAG formulates a reasoning plan as a
directed acyclic graph (DAG), decomposing queries into interrelated atomic
sub-queries. Answer generation follows the DAG structure, allowing significant
gains in efficiency through parallelized retrieval and generation. While
state-of-the-art RAG solutions require extensive data generation and
fine-tuning of language models (LMs), Plan$\times$RAG incorporates frozen LMs
as plug-and-play experts to generate high-quality answers. Compared to existing
RAG solutions, Plan$\times$RAG demonstrates significant improvements in
reducing hallucinations and bolstering attribution due to its structured
sub-query decomposition. Overall, Plan$\times$RAG offers a new perspective on
integrating external knowledge in LMs while ensuring attribution by design,
contributing towards more reliable LM-based systems.

æè¦ï¼<paragraph>æåå¼å¥äºè¦åå¼å°çæª¢ç´¢å¢å¼·çæ (Plan$\times$RAG)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®æ´åäºç¾æ RAG æ¡æ¶çãåæª¢ç´¢å¾æ¨çãç¯ä¾ï¼æ¹çºãåè¦åå¾æª¢ç´¢ããPlan$\times$RAG å°æ¨çè¨ç«å¶å®çºæåç¡ç°å (DAG)ï¼å°æ¥è©¢åè§£æç¸äºéè¯çåå­å­æ¥è©¢ãç­æ¡çæéµå¾ª DAG çµæ§ï¼ééä¸¦è¡æª¢ç´¢åçæï¼å¤§å¹æåæçãéç¶æåé²ç RAG è§£å³æ¹æ¡éè¦å¤§éè³æçæåèªè¨æ¨¡å (LM) çå¾®èª¿ï¼ä½ Plan$\times$RAG å°åçµç LM æ´åçºå³æå³ç¨çå°å®¶ï¼ä»¥çæé«åè³ªçç­æ¡ãèç¾æç RAG è§£å³æ¹æ¡ç¸æ¯ï¼Plan$\times$RAG å¨æ¸å°å¹»è¦ºåå å¼·æ­¸å æ¹é¢è¡¨ç¾åºé¡¯èçé²æ­¥ï¼éè¦æ­¸åæ¼å¶çµæ§åçå­æ¥è©¢åè§£ãç¸½é«èè¨ï¼Plan$\times$RAG æä¾äºä¸åæ°çè§é»ï¼ä»¥æ´å LM ä¸­çå¤é¨ç¥è­ï¼åæç¢ºä¿æ­¸å è¨­è¨ï¼æå©æ¼å»ºç«æ´å¯é çåºæ¼ LM çç³»çµ±ã</paragraph>

##### **Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**
2410.20724v2 by Mufei Li, Siqi Miao, Pan Li

Large Language Models (LLMs) demonstrate strong reasoning abilities but face
limitations such as hallucinations and outdated knowledge. Knowledge Graph
(KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by
grounding LLM outputs in structured external knowledge from KGs. However,
current KG-based RAG frameworks still struggle to optimize the trade-off
between retrieval effectiveness and efficiency in identifying a suitable amount
of relevant graph information for the LLM to digest. We introduce SubgraphRAG,
extending the KG-based RAG framework that retrieves subgraphs and leverages
LLMs for reasoning and answer prediction. Our approach innovatively integrates
a lightweight multilayer perceptron with a parallel triple-scoring mechanism
for efficient and flexible subgraph retrieval while encoding directional
structural distances to enhance retrieval effectiveness. The size of retrieved
subgraphs can be flexibly adjusted to match the query's need and the downstream
LLM's capabilities. This design strikes a balance between model complexity and
reasoning power, enabling scalable and generalizable retrieval processes.
Notably, based on our retrieved subgraphs, smaller LLMs like
Llama3.1-8B-Instruct deliver competitive results with explainable reasoning,
while larger models like GPT-4o achieve state-of-the-art accuracy compared with
previous baselines -- all without fine-tuning. Extensive evaluations on the
WebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency,
accuracy, and reliability by reducing hallucinations and improving response
grounding.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) å·æå¼·å¤§çæ¨çè½åï¼ä½é¢è¨å¹»è¦ºåéæç¥è­ç­éå¶ãåºæ¼ç¥è­åè­ (KG) çæª¢ç´¢å¢å¼·çæ (RAG) ééå° LLM è¼¸åºçµæå¥ åºæ¼ KG ä¸­ççµæ§åå¤é¨ç¥è­ï¼ä¾è§£æ±ºéäºåé¡ãç¶èï¼ç®ååºæ¼ KG ç RAG æ¶æ§ä»é£ä»¥å¨æª¢ç´¢æè½åæçä¹éåå¾æä½³å¹³è¡¡ï¼ä»¥æ¾åº LLM è½å¤ æ¶åçé©ç¶ç¸éåè¡¨è³è¨éãæåå¼é² SubgraphRAGï¼æ´ååºæ¼ KG ç RAG æ¶æ§ï¼ä»¥æª¢ç´¢å­åè¡¨ä¸¦å©ç¨ LLM é²è¡æ¨çåç­æ¡é æ¸¬ãæåçåæ³åµæ°å°æ´åäºä¸åè¼éå¤å±¤æç¥å¨èä¸åä¸¦è¡ä¸åçµè¨åæ©å¶ï¼ç¨æ¼é«æä¸éæ´»å°æª¢ç´¢å­åè¡¨ï¼åæç·¨ç¢¼æ¹åçµæ§è·é¢ä»¥å¢å¼·æª¢ç´¢æè½ãæª¢ç´¢å°çå­åè¡¨å¤§å°å¯ä»¥éæ´»èª¿æ´ï¼ä»¥ç¬¦åæ¥è©¢éæ±åä¸æ¸¸ LLM çåè½ãéç¨®è¨­è¨å¨æ¨¡åè¤éåº¦åæ¨çè½åä¹éåå¾å¹³è¡¡ï¼å¯¦ç¾å¯æ´åä¸å¯æ¦åçæª¢ç´¢ç¨åºãå¼å¾æ³¨æçæ¯ï¼æ ¹ææåæª¢ç´¢å°çå­åè¡¨ï¼è¼å°ç LLMï¼ä¾å¦ Llama3.1-8B-Instructï¼å¯ä»¥æä¾å·åå¯è§£éæ¨ççç«¶ç­çµæï¼èè¼å¤§çæ¨¡åï¼ä¾å¦ GPT-4oï¼åéå°èåååºæºç¸æ¯çææ°æºç¢ºåº¦ï¼èä¸ææéäºé½ä¸éè¦å¾®èª¿ãå¨ WebQSP å CWQ åºæºä¸çå»£æ³è©ä¼°çªé¡¯äº SubgraphRAG å¨æçãæºç¢ºåº¦åå¯é æ§æ¹é¢çåªå¢ï¼ééæ¸å°å¹»è¦ºä¸¦æ¹ååæä¾æã</paragraph>

##### **Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs**
2410.20321v1 by Xingrui Zhuo, Jiapu Wang, Gongqing Wu, Shirui Pan, Xindong Wu

Knowledge Graph Query Embedding (KGQE) aims to embed First-Order Logic (FOL)
queries in a low-dimensional KG space for complex reasoning over incomplete
KGs. To enhance the generalization of KGQE models, recent studies integrate
various external information (such as entity types and relation context) to
better capture the logical semantics of FOL queries. The whole process is
commonly referred to as Query Pattern Learning (QPL). However, current QPL
methods typically suffer from the pattern-entity alignment bias problem,
leading to the learned defective query patterns limiting KGQE models'
performance. To address this problem, we propose an effective Query Instruction
Parsing Plugin (QIPP) that leverages the context awareness of Pre-trained
Language Models (PLMs) to capture latent query patterns from code-like query
instructions. Unlike the external information introduced by previous QPL
methods, we first propose code-like instructions to express FOL queries in an
alternative format. This format utilizes textual variables and nested tuples to
convey the logical semantics within FOL queries, serving as raw materials for a
PLM-based instruction encoder to obtain complete query patterns. Building on
this, we design a query-guided instruction decoder to adapt query patterns to
KGQE models. To further enhance QIPP's effectiveness across various KGQE
models, we propose a query pattern injection mechanism based on compressed
optimization boundaries and an adaptive normalization component, allowing KGQE
models to utilize query patterns more efficiently. Extensive experiments
demonstrate that our plug-and-play method improves the performance of eight
basic KGQE models and outperforms two state-of-the-art QPL methods.

æè¦ï¼ç¥è­åè­æ¥è©¢åµå¥ï¼KGQEï¼æ¨å¨å°ä¸ééè¼¯ï¼FOLï¼æ¥è©¢åµå¥å°ä½ç¶­ KG ç©ºéä¸­ï¼ä»¥ä¾¿å°ä¸å®æ´ç KG é²è¡è¤éæ¨çãçºäºå¢å¼· KGQE æ¨¡åçæ³åè½åï¼æè¿çç ç©¶æ´åäºåç¨®å¤é¨è³è¨ï¼ä¾å¦å¯¦é«é¡ååéä¿ä¸ä¸æï¼ï¼ä»¥æ´å¥½å°ææ FOL æ¥è©¢çéè¼¯èªç¾©ãæ´åéç¨éå¸¸ç¨±çºæ¥è©¢æ¨¡å¼å­¸ç¿ï¼QPLï¼ãç¶èï¼ç¶åç QPL æ¹æ³éå¸¸æåå°æ¨¡å¼å¯¦é«å°é½åå·®åé¡çå½±é¿ï¼å°è´å­¸ç¿å°çæç¼ºé·æ¥è©¢æ¨¡å¼éå¶äº KGQE æ¨¡åçæè½ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åææçæ¥è©¢æä»¤è§£æå¤æç¨å¼ï¼QIPPï¼ï¼å®å©ç¨é è¨ç·´èªè¨æ¨¡åï¼PLMï¼çä¸ä¸ææç¥ä¾å¾é¡ä»£ç¢¼çæ¥è©¢æä»¤ä¸­æ·åæ½å¨æ¥è©¢æ¨¡å¼ãèåå QPL æ¹æ³å¼å¥çå¤é¨è³è¨ä¸åï¼æåé¦åæåºé¡ä»£ç¢¼çæä»¤ä»¥å¦é¡æ ¼å¼è¡¨é FOL æ¥è©¢ãæ­¤æ ¼å¼å©ç¨æå­è®æ¸åå·¢çåçµä¾å³é FOL æ¥è©¢ä¸­çéè¼¯èªç¾©ï¼ä½çºåºæ¼ PLM çæä»¤ç·¨ç¢¼å¨çåæï¼ä»¥åå¾å®æ´çæ¥è©¢æ¨¡å¼ãå¨æ­¤åºç¤ä¸ï¼æåè¨­è¨äºä¸åæ¥è©¢å¼å°çæä»¤è§£ç¢¼å¨ï¼ä»¥å°æ¥è©¢æ¨¡å¼èª¿æ´å° KGQE æ¨¡åãçºäºé²ä¸æ­¥å¢å¼· QIPP å¨åç¨® KGQE æ¨¡åä¸­çæææ§ï¼æåæåºäºä¸ååºæ¼å£ç¸®æä½³åéçåèªé©ææ­£è¦ååä»¶çæ¥è©¢æ¨¡å¼æ³¨å¥æ©å¶ï¼åè¨± KGQE æ¨¡åæ´ææå°å©ç¨æ¥è©¢æ¨¡å¼ãå»£æ³çå¯¦é©è¡¨æï¼æåçå³æå³ç¨æ¹æ³æ¹åäºå«ååºæ¬ KGQE æ¨¡åçæè½ï¼ä¸¦åªæ¼å©ç¨®æåé²ç QPL æ¹æ³ã

##### **Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts**
2410.21324v1 by Vishesh Prasad, Brian Kim, Nickvash Kani

Recent advances in natural language processing (NLP), particularly with the
emergence of large language models (LLMs), have significantly enhanced the
field of textual analysis. However, while these developments have yielded
substantial progress in analyzing textual data, applying analysis to
mathematical equations and their relationships within texts has produced mixed
results. In this paper, we take the initial steps toward understanding the
dependency relationships between mathematical expressions in STEM articles. Our
dataset, sourced from a random sampling of the arXiv corpus, contains an
analysis of 107 published STEM manuscripts whose inter-equation dependency
relationships have been hand-labeled, resulting in a new object we refer to as
a derivation graph that summarizes the mathematical content of the manuscript.
We exhaustively evaluate analytical and NLP-based models to assess their
capability to identify and extract the derivation relationships for each
article and compare the results with the ground truth. Our comprehensive
testing finds that both analytical and NLP models (including LLMs) achieve
$\sim$40-50% F1 scores for extracting derivation graphs from articles,
revealing that the recent advances in NLP have not made significant inroads in
comprehending mathematical texts compared to simpler analytic models. While
current approaches offer a solid foundation for extracting mathematical
information, further research is necessary to improve accuracy and depth in
this area.

æè¦ï¼èªç¶èªè¨èçï¼NLPï¼çææ°é²å±ï¼ç¹å¥æ¯å¤§èªè¨æ¨¡åï¼LLMï¼çåºç¾ï¼å·²é¡¯èå¢å¼·äºææ¬åæé åãç¶èï¼åç®¡éäºç¼å±å¨åæææ¬è³ææ¹é¢åå¾äºå¯¦è³ªæ§é²å±ï¼ä½å°åææç¨æ¼æ¸å­¸æ¹ç¨å¼åå¶å¨ææ¬ä¸­çéä¿å»ç¢çäºä¸åççµæãå¨æ¬æä¸­ï¼æåæ¡åäºåæ­¥æ­¥é©ä¾äºè§£ STEM æç« ä¸­æ¸å­¸è¡¨éå¼ä¹éçä¾è³´éä¿ãæåçè³æéåèª arXiv èªæåº«çé¨æ©æ½æ¨£ï¼å¶ä¸­åå«å° 107 ç¯å·²ç¼è¡¨ç STEM æç¨¿çåæï¼å¶æ¹ç¨å¼éçä¾è³´éä¿å·²é²è¡æåæ¨è¨ï¼ç¢çäºä¸åæåç¨±çºè¡çåçæ°ç©ä»¶ï¼è©²ç©ä»¶ç¸½çµäºæç¨¿çæ¸å­¸å§å®¹ãæåå¾¹åºè©ä¼°äºåæååºæ¼ NLP çæ¨¡åï¼ä»¥è©ä¼°å®åè­å¥åæåæ¯ç¯æç« çè¡çéä¿çè½åï¼ä¸¦å°çµæèçå¯¦ææ³é²è¡æ¯è¼ãæåçå¨é¢æ¸¬è©¦ç¼ç¾ï¼åæå NLP æ¨¡åï¼åæ¬ LLMï¼å¨å¾æç« ä¸­æåè¡çåæ¹é¢ç F1 åæ¸åéå° $\sim$40-50%ï¼éè¡¨æèæ´ç°¡å®çåææ¨¡åç¸æ¯ï¼NLP çææ°é²å±ä¸¦æ²æå¨çè§£æ¸å­¸ææ¬æ¹é¢åå¾éå¤§é²å±ãåç®¡ç®åçæ¹æ³çºæåæ¸å­¸è³è¨æä¾äºå å¯¦çåºç¤ï¼ä½ä»éè¦é²ä¸æ­¥çç ç©¶ä¾æé«æ­¤é åçæºç¢ºæ§åæ·±åº¦ã

##### **DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**
2410.19955v1 by Pengfei Hu, Chang Lu, Fei Wang, Yue Ning

Electronic Health Records (EHR) has revolutionized healthcare data management
and prediction in the field of AI and machine learning. Accurate predictions of
diagnosis and medications significantly mitigate health risks and provide
guidance for preventive care. However, EHR driven models often have limited
scope on understanding medical-domain knowledge and mostly rely on
simple-and-sole ontologies. In addition, due to the missing features and
incomplete disease coverage of EHR, most studies only focus on basic analysis
on conditions and medication. We propose DualMAR, a framework that enhances EHR
prediction tasks through both individual observation data and public knowledge
bases. First, we construct a bi-hierarchical Diagnosis Knowledge Graph (KG)
using verified public clinical ontologies and augment this KG via Large
Language Models (LLMs); Second, we design a new proxy-task learning on lab
results in EHR for pretraining, which further enhance KG representation and
patient embeddings. By retrieving radial and angular coordinates upon polar
space, DualMAR enables accurate predictions based on rich hierarchical and
semantic embeddings from KG. Experiments also demonstrate that DualMAR
outperforms state-of-the-art models, validating its effectiveness in EHR
prediction and KG integration in medical domains.

æè¦ï¼é»å­å¥åº·ç´é (EHR) å·²å¾¹åºæ¹è®äºé«çä¿å¥è³æç®¡çï¼ä¸¦é æ¸¬äºäººå·¥æºæ§åæ©å¨å­¸ç¿é åãæºç¢ºé æ¸¬è¨ºæ·åè¥ç©å¯å¤§å¹æ¸è¼å¥åº·é¢¨éªï¼ä¸¦æä¾é é²æ§ç§è­·çæå°æ¹éãç¶èï¼EHR é©åçæ¨¡åå¨çè§£é«çé åç¥è­ä¸éå¸¸å·æå±éæ§ï¼èä¸å¤§å¤ä¾è³´æ¼ç°¡å®ä¸å®ä¸çæ¬ä½ãæ­¤å¤ï¼ç±æ¼ EHR éºæ¼äºåè½ä¸ç¾çæ¶µèä¸å®æ´ï¼å¤§å¤æ¸ç ç©¶åå°æ³¨æ¼ç¾çåè¥ç©çåºæ¬åæãæåæåº DualMARï¼ä¸åééåäººè§å¯è³æåå¬å±ç¥è­åº«å¢å¼· EHR é æ¸¬ä»»åçæ¶æ§ãé¦åï¼æåä½¿ç¨ç¶éé©è­çå¬å±è¨åºæ¬ä½æ§å»ºä¸åéå±¤ç´è¨ºæ·ç¥è­å (KG)ï¼ä¸¦ééå¤§åèªè¨æ¨¡å (LLM) æ´åéå KGï¼å¶æ¬¡ï¼æåè¨­è¨ä¸åæ°çä»£çä»»åå­¸ç¿ï¼éå° EHR ä¸­çå¯¦é©å®¤çµæé²è¡é è¨ç·´ï¼é²ä¸æ­¥å¢å¼· KG è¡¨ç¤ºåæ£èåµå¥ãééæ·åæ¥µåº§æ¨ç©ºéä¸çå¾ååè§ååæ¨ï¼DualMAR è½å¤ æ ¹æ KG ä¸­è±å¯çå±¤ç´åèªæåµå¥é²è¡æºç¢ºçé æ¸¬ãå¯¦é©ä¹è­æ DualMAR åªæ¼æåé²çæ¨¡åï¼é©è­äºå¶å¨ EHR é æ¸¬åé«çé åä¸­ KG æ´åçæææ§ã

##### **FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**
2410.19727v1 by Nicole Cho, Nishan Srishankar, Lucas Cecchi, William Watson

Financial intelligence generation from vast data sources has typically relied
on traditional methods of knowledge-graph construction or database engineering.
Recently, fine-tuned financial domain-specific Large Language Models (LLMs),
have emerged. While these advancements are promising, limitations such as high
inference costs, hallucinations, and the complexity of concurrently analyzing
high-dimensional financial data, emerge. This motivates our invention FISHNET
(Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning,
Expert swarming, and Task planning), an agentic architecture that accomplishes
highly complex analytical tasks for more than 98,000 regulatory filings that
vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows
remarkable performance for financial insight generation (61.8% success rate
over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to
empirically prove the success of FISHNET, each agent's importance, and the
optimized performance of assembling all agents. Our modular architecture can be
leveraged for a myriad of use-cases, enabling scalability, flexibility, and
data integrity that are critical for financial tasks.

æè¦ï¼è²¡åæå ±çæéå¸¸ä¾è³´æ¼å³çµ±çç¥è­åè¡¨å»ºæ§æè³æåº«å·¥ç¨æ¹æ³ï¼éäºæ¹æ³ä¾èªæ¼é¾å¤§çè³æä¾æºãæè¿ï¼éå°è²¡åé åé²è¡å¾®èª¿çå¤§åèªè¨æ¨¡å (LLM) å·²æéèçãåç®¡éäºé²å±ä»¤äººæ¯å¥®ï¼ä½ä»å­å¨ä¸äºéå¶ï¼ä¾å¦é«æ¨çææ¬ãå¹»è¦ºï¼ä»¥ååæåæé«ç¶­åº¦è²¡åè³æçè¤éæ§ãéä¿ä½¿æåç¼æäº FISHNETï¼ä¾èªå­æ¥è©¢ãåèª¿ãç¥ç¶æ¢ä»¶åãå°å®¶ç¾¤éåä»»åè¦åçè²¡åæå ±ï¼ï¼éæ¯ä¸ç¨®ä»£çæ¶æ§ï¼å¯éå°è¶é 98,000 ä»½æ³è¦æä»¶å·è¡é«åº¦è¤éçåæä»»åï¼èéäºæä»¶å¨èªç¾©ãè³æéå±¤ææ ¼å¼æ¹é¢å·®ç°æ¥µå¤§ãFISHNET å¨ç¢çè²¡åè¦è§£æ¹é¢è¡¨ç¾åºè²ï¼æåççº 61.8%ï¼è·¯ç±ççº 5.0%ï¼RAG R-Precision çº 45.6%ï¼ãæåé²è¡äºå´æ ¼çæ¶èï¼ä»¥å¯¦è­è­æ FISHNET çæåãæ¯åä»£ççéè¦æ§ï¼ä»¥åçµè£ææä»£ççæä½³åæè½ãæåæ¨¡çµåçæ¶æ§å¯éç¨æ¼åç¨®ä½¿ç¨æ¡ä¾ï¼æä¾è²¡åä»»åè³ééè¦çå¯æ´åæ§ãå½æ§åè³æå®æ´æ§ã

##### **Knowledge Graph Enhanced Language Agents for Recommendation**
2410.19627v1 by Taicheng Guo, Chaochun Liu, Hai Wang, Varun Mannam, Fang Wang, Xin Chen, Xiangliang Zhang, Chandan K. Reddy

Language agents have recently been used to simulate human behavior and
user-item interactions for recommendation systems. However, current language
agent simulations do not understand the relationships between users and items,
leading to inaccurate user profiles and ineffective recommendations. In this
work, we explore the utility of Knowledge Graphs (KGs), which contain extensive
and reliable relationships between users and items, for recommendation. Our key
insight is that the paths in a KG can capture complex relationships between
users and items, eliciting the underlying reasons for user preferences and
enriching user profiles. Leveraging this insight, we propose Knowledge Graph
Enhanced Language Agents(KGLA), a framework that unifies language agents and KG
for recommendation systems. In the simulated recommendation scenario, we
position the user and item within the KG and integrate KG paths as natural
language descriptions into the simulation. This allows language agents to
interact with each other and discover sufficient rationale behind their
interactions, making the simulation more accurate and aligned with real-world
cases, thus improving recommendation performance. Our experimental results show
that KGLA significantly improves recommendation performance (with a 33%-95%
boost in NDCG@1 among three widely used benchmarks) compared to the previous
best baseline method.

æè¦ï¼èªè¨ä»£çæè¿å·²è¢«ç¨æ¼æ¨¡æ¬äººé¡è¡çºåæ¨è¦ç³»çµ±ä¸­çä½¿ç¨èé ç®äºåãç¶èï¼ç®åçèªè¨ä»£çæ¨¡æ¬ä¸¦æªäºè§£ä½¿ç¨èåé ç®ä¹éçéä¿ï¼å°è´ä½¿ç¨èè¼ªå»ä¸æºç¢ºåæ¨è¦ææä¸ä½³ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºç¥è­åè­ (KG) çæç¨ï¼å¶ä¸­åå«ä½¿ç¨èåé ç®ä¹éå»£æ³ä¸å¯é çéä¿ï¼ä»¥ä¾æ¨è¦ãæåçééµè¦è§£æ¯ï¼KG ä¸­çè·¯å¾å¯ä»¥ææä½¿ç¨èåé ç®ä¹éçè¤ééä¿ï¼å¼åºä½¿ç¨èåå¥½çæ ¹æ¬åå ä¸¦è±å¯ä½¿ç¨èè¼ªå»ãå©ç¨æ­¤è¦è§£ï¼æåæåºäºç¥è­åè­å¢å¼·èªè¨ä»£ç (KGLA)ï¼ä¸åçµ±ä¸èªè¨ä»£çå KG ä»¥ç¨æ¼æ¨è¦ç³»çµ±çæ¶æ§ãå¨æ¨¡æ¬æ¨è¦æå¢ä¸­ï¼æåå°ä½¿ç¨èåé ç®å®ä½å¨ KG ä¸­ï¼ä¸¦å° KG è·¯å¾æ´åçºèªç¶èªè¨æè¿°å°æ¨¡æ¬ä¸­ãéåè¨±èªè¨ä»£çå½¼æ­¤äºåä¸¦ç¼ç¾å¶äºåèå¾çååä¾æï¼ä½¿æ¨¡æ¬æ´æºç¢ºä¸èå¯¦éæ¡ä¾ç¸ç¬¦ï¼å¾èæ¹åæ¨è¦æè½ãæåçå¯¦é©çµæé¡¯ç¤ºï¼èååæä½³åºæºæ¹æ³ç¸æ¯ï¼KGLA å¤§å¹æ¹åäºæ¨è¦æè½ï¼å¨ä¸åå»£æ³ä½¿ç¨çåºæºä¸­ï¼NDCG@1 æåäº 33%-95%ï¼ã

##### **Graph Linearization Methods for Reasoning on Graphs with Large Language Models**
2410.19494v1 by Christos Xypolopoulos, Guokan Shang, Xiao Fei, Giannis Nikolentzos, Hadi Abdine, Iakovos Evdaimon, Michail Chatzianastasis, Giorgos Stamou, Michalis Vazirgiannis

Large language models have evolved to process multiple modalities beyond
text, such as images and audio, which motivates us to explore how to
effectively leverage them for graph machine learning tasks. The key question,
therefore, is how to transform graphs into linear sequences of tokens, a
process we term graph linearization, so that LLMs can handle graphs naturally.
We consider that graphs should be linearized meaningfully to reflect certain
properties of natural language text, such as local dependency and global
alignment, in order to ease contemporary LLMs, trained on trillions of textual
tokens, better understand graphs. To achieve this, we developed several graph
linearization methods based on graph centrality, degeneracy, and node
relabeling schemes. We then investigated their effect on LLM performance in
graph reasoning tasks. Experimental results on synthetic graphs demonstrate the
effectiveness of our methods compared to random linearization baselines. Our
work introduces novel graph representations suitable for LLMs, contributing to
the potential integration of graph machine learning with the trend of
multi-modal processing using a unified transformer model.

æè¦ï¼å¤§åèªè¨æ¨¡åå·²æ¼åçºèçæå­ä¹å¤çå¤ç¨®æ¨¡å¼ï¼ä¾å¦å½±ååé³è¨ï¼éä¿ä½¿æåæ¢ç´¢å¦ä½ææå°éç¨å®åæ¼åå½¢æ©å¨å­¸ç¿ä»»åãå æ­¤ï¼ééµåé¡å¨æ¼å¦ä½å°åå½¢è½æçºç·æ§åºåçä»£å¹£ï¼éæ¯ä¸åæåç¨±çºåå½¢ç·æ§åçéç¨ï¼è® LLM è½èªç¶å°èçåå½¢ãæåèªçºåå½¢æææç¾©å°é²è¡ç·æ§åï¼ä»¥åæ èªç¶èªè¨æå­çç¹å®å±¬æ§ï¼ä¾å¦å±é¨ä¾è³´æ§åå¨å±å°é½ï¼ä»¥ä¾¿è®å¨æ¸ååæå­ä»£å¹£ä¸è¨ç·´çç¶ä»£ LLM æ´è½çè§£åå½¢ãçºéææ­¤ç®çï¼æåéç¼äºå¹¾ç¨®åºæ¼åå½¢ä¸­å¿æ§ãç°¡ä½µæ§åç¯é»éæ°æ¨ç±¤æ¶æ§çåå½¢ç·æ§åæ¹æ³ãæ¥èï¼æåæ¢è¨å®åå° LLM å¨åå½¢æ¨çä»»åä¸­çæè½å½±é¿ãåæåå½¢ä¸çå¯¦é©çµæè­æäºæåçæ¹æ³æ¯é¨æ©ç·æ§ååºæºæ´ææãæåçç ç©¶å¼å¥äºé©å LLM çæ°ç©åå½¢è¡¨ç¤ºæ³ï¼æå©æ¼å°åå½¢æ©å¨å­¸ç¿èä½¿ç¨çµ±ä¸Transformeræ¨¡åçå¤æ¨¡å¼èçè¶¨å¢æ´åèµ·ä¾ã

##### **Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis**
2410.19225v1 by Weikai Li, Ding Wang, Zijian Ding, Atefeh Sohrabizadeh, Zongyue Qin, Jason Cong, Yizhou Sun

High-level synthesis (HLS) is a widely used tool in designing Field
Programmable Gate Array (FPGA). HLS enables FPGA design with software
programming languages by compiling the source code into an FPGA circuit. The
source code includes a program (called ``kernel'') and several pragmas that
instruct hardware synthesis, such as parallelization, pipeline, etc. While it
is relatively easy for software developers to design the program, it heavily
relies on hardware knowledge to design the pragmas, posing a big challenge for
software developers. Recently, different machine learning algorithms, such as
GNNs, have been proposed to automate the pragma design via performance
prediction. However, when applying the trained model on new kernels, the
significant domain shift often leads to unsatisfactory performance. We propose
a more domain-generalizable model structure: a two-level hierarchical Mixture
of Experts (MoE), that can be flexibly adapted to any GNN model. Different
expert networks can learn to deal with different regions in the representation
space, and they can utilize similar patterns between the old kernels and new
kernels. In the low-level MoE, we apply MoE on three natural granularities of a
program: node, basic block, and graph. The high-level MoE learns to aggregate
the three granularities for the final decision. To stably train the
hierarchical MoE, we further propose a two-stage training method. Extensive
experiments verify the effectiveness of the hierarchical MoE.

æè¦ï¼é«éç¶åï¼HLSï¼æ¯è¨­è¨ç¾å ´å¯ç·¨ç¨éé£åï¼FPGAï¼ä¸­å»£æ³ä½¿ç¨çå·¥å·ãHLS ééå°åå§ç¢¼ç·¨è­¯æ FPGA é»è·¯ï¼ä½¿ç¨è»é«ç¨å¼èªè¨é²è¡ FPGA è¨­è¨ãåå§ç¢¼åå«ä¸åç¨å¼ï¼ç¨±çºãæ ¸å¿ãï¼åå¤åæå°ç¡¬é«ç¶åçæç¤ºï¼ä¾å¦å¹³è¡åãç®¡ç·ç­ãéç¶è»é«éç¼äººå¡è¨­è¨ç¨å¼ç¸å°å®¹æï¼ä½å®æ¥µåº¦ä¾è³´ç¡¬é«ç¥è­ä¾è¨­è¨æç¤ºï¼éå°è»é«éç¼äººå¡ä¾èªªæ¯ä¸å¤§ææ°ãæè¿ï¼ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³ï¼ä¾å¦ GNNï¼å·²è¢«æåºç¨æ¼ééæè½é æ¸¬èªåé²è¡æç¤ºè¨­è¨ãç¶èï¼å¨æ°çæ ¸å¿ä¸æç¨è¨ç·´å¥½çæ¨¡åæï¼é¡¯èçé åè½ç§»éå¸¸æå°è´æè½ä¸ä½³ãæåæåºä¸åæ´å·é åéç¨æ§çæ¨¡åçµæ§ï¼ä¸åäºéå±¤æ··åå°å®¶ï¼MoEï¼ï¼å®å¯ä»¥éæ´»å°é©æä»»ä½ GNN æ¨¡åãä¸åçå°å®¶ç¶²è·¯å¯ä»¥å­¸ç¿èçè¡¨ç¤ºç©ºéä¸­çä¸åååï¼ä¸¦ä¸å®åå¯ä»¥å©ç¨èæ ¸å¿åæ°æ ¸å¿ä¹éçç¸ä¼¼æ¨¡å¼ãå¨ä½é MoE ä¸­ï¼æåå°ç¨å¼çä¸åèªç¶ç²åº¦æç¨ MoEï¼ç¯é»ãåºæ¬åå¡ååãé«é MoE å­¸ç¿å½ç¸½éä¸åç²åº¦ä»¥ååºæçµæ±ºç­ãçºäºç©©å®è¨ç·´éå±¤å¼ MoEï¼æåé²ä¸æ­¥æåºä¸åäºéæ®µè¨ç·´æ¹æ³ãå»£æ³çå¯¦é©é©è­äºéå±¤å¼ MoE çæææ§ã

##### **Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media**
2410.19193v1 by Bruno Croso Cunha da Silva, Thomas Palmeira Ferraz, Roseli De Deus Lopes

Disinformation on social media poses both societal and technical challenges.
While previous studies have integrated textual information into propagation
networks, they have yet to fully leverage the advancements in Transformer-based
language models for high-quality contextual text representations. This work
investigates the impact of incorporating textual features into Graph Neural
Networks (GNNs) for fake news detection. Our experiments demonstrate that
contextual representations improve performance by 9.3% in Macro F1 over static
ones and 33.8% over GNNs without textual features. However, noisy data
augmentation degrades performance and increases instability. We expect our
methodology to open avenues for further research, and all code is made publicly
available.

æè¦ï¼ç¤¾ç¾¤åªé«ä¸çé¯èª¤è¨æ¯é æç¤¾æåæè¡å±¤é¢çææ°ã
åç®¡éå¾çç ç©¶å·²å°æå­è³è¨æ´åå°å³æ­ç¶²è·¯ä¸­ï¼ä½å°æªååå©ç¨åºæ¼ Transformer çèªè¨æ¨¡åå¨é«åè³ªèçµ¡æå­è¡¨å¾µä¸çé²å±ãéé ç ç©¶æ¢è¨å°æå­ç¹å¾µç´å¥åå½¢ç¥ç¶ç¶²è·¯ (GNN) ä¸­å°æ¼åæ°èåµæ¸¬çå½±é¿ãæåçå¯¦é©çµæé¡¯ç¤ºï¼èçµ¡è¡¨å¾µå°å·¨è§ F1 çæè½æåäº 9.3%ï¼åªæ¼éæè¡¨å¾µï¼ä¸¦æ¯æ²ææå­ç¹å¾µç GNN æåäº 33.8%ãç¶èï¼æéè¨çè³ææ´åæéä½æè½ä¸¦å¢å ä¸ç©©å®æ§ãæåé ææåçç ç©¶æ¹æ³å°éåé²ä¸æ­¥ç ç©¶çéå¾ï¼ææç¨å¼ç¢¼çå¬éæä¾ã

##### **GCoder: Improving Large Language Model for Generalized Graph Problem Solving**
2410.19084v1 by Qifan Zhang, Xiaobin Hong, Jianheng Tang, Nuo Chen, Yuhan Li, Wenzhong Li, Jing Tang, Jia Li

Large Language Models (LLMs) have demonstrated strong reasoning abilities,
making them suitable for complex tasks such as graph computation. Traditional
reasoning steps paradigm for graph problems is hindered by unverifiable steps,
limited long-term reasoning, and poor generalization to graph variations. To
overcome these limitations, we introduce GCoder, a code-based LLM designed to
enhance problem-solving in generalized graph computation problems. Our method
involves constructing an extensive training dataset, GraphWild, featuring
diverse graph formats and algorithms. We employ a multi-stage training process,
including Supervised Fine-Tuning (SFT) and Reinforcement Learning from Compiler
Feedback (RLCF), to refine model capabilities. For unseen tasks, a hybrid
retrieval technique is used to augment performance. Experiments demonstrate
that GCoder outperforms GPT-4o, with an average accuracy improvement of 16.42%
across various graph computational problems. Furthermore, GCoder efficiently
manages large-scale graphs with millions of nodes and diverse input formats,
overcoming the limitations of previous models focused on the reasoning steps
paradigm. This advancement paves the way for more intuitive and effective graph
problem-solving using LLMs. Code and data are available at here:
https://github.com/Bklight999/WWW25-GCoder/tree/master.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾å¼·å¤§çæ¨çè½åï¼ä½¿å¶é©ç¨æ¼è¤éä»»åï¼ä¾å¦åå½¢éç®ãå³çµ±åå½¢åé¡çæ¨çæ­¥é©ç¯ä¾åå°ä¸å¯é©è­çæ­¥é©ãæéçé·ææ¨çåå°åå½¢è®åçæ¦æ¬æ§ä¸ä½³çé»ç¤ãçºäºåæéäºéå¶ï¼æåå¼å¥äº GCoderï¼ä¸ç¨®åºæ¼ä»£ç¢¼ç LLMï¼æ¨å¨å¢å¼·å»£ç¾©åå½¢éç®åé¡ä¸­çåé¡è§£æ±ºè½åãæåçæè¡æ¶åæ§å»ºä¸åå»£æ³çè¨ç·´è³æé GraphWildï¼å¶ä¸­åå«å¤æ¨£çåå½¢æ ¼å¼åæ¼ç®æ³ãæåæ¡ç¨å¤éæ®µè¨ç·´æµç¨ï¼åæ¬ç£ç£å¾®èª¿ (SFT) åç·¨è­¯å¨åé¥å¼·åå­¸ç¿ (RLCF)ï¼ä»¥æ¹åæ¨¡åè½åãå°æ¼æªç¥ä»»åï¼ä½¿ç¨æ··åæ·åæè¡ä¾å¢å¼·æè½ãå¯¦é©è­æï¼GCoder åªæ¼ GPT-4oï¼å¨åç¨®åå½¢éç®åé¡ä¸­å¹³åæºç¢ºåº¦æåäº 16.42%ãæ­¤å¤ï¼GCoder ææå°ç®¡çèæææ¸ç¾è¬åç¯é»åå¤æ¨£è¼¸å¥æ ¼å¼çå¤§è¦æ¨¡åå½¢ï¼åæäºååå°æ³¨æ¼æ¨çæ­¥é©ç¯ä¾çæ¨¡åçéå¶ãéé é²å±çºä½¿ç¨ LLM é²è¡æ´ç´è§ä¸ææçåå½¢åé¡è§£æ±ºéªå¹³äºéè·¯ãç¨å¼ç¢¼åè³æå¯æ¼æ­¤èåå¾ï¼https://github.com/Bklight999/WWW25-GCoder/tree/masterã

##### **LLM-based Online Prediction of Time-varying Graph Signals**
2410.18718v1 by Dayu Qin, Yi Yan, Ercan Engin Kuruoglu

In this paper, we propose a novel framework that leverages large language
models (LLMs) for predicting missing values in time-varying graph signals by
exploiting spatial and temporal smoothness. We leverage the power of LLM to
achieve a message-passing scheme. For each missing node, its neighbors and
previous estimates are fed into and processed by LLM to infer the missing
observations. Tested on the task of the online prediction of wind-speed graph
signals, our model outperforms online graph filtering algorithms in terms of
accuracy, demonstrating the potential of LLMs in effectively addressing
partially observed signals in graphs.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çæ¡æ¶ï¼è©²æ¡æ¶å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾é æ¸¬æè®åå½¢ä¿¡èä¸­çç¼ºå¤±å¼ï¼æ¹æ³æ¯å©ç¨ç©ºéåæéå¹³æ»åº¦ãæåå©ç¨ LLM çè½åä¾å¯¦ç¾æ¶æ¯å³éæ¹æ¡ãå°æ¼æ¯åç¼ºå¤±ç¯é»ï¼å¶é°å±åååçä¼°è¨å¼æè¢«è¼¸å¥å° LLM ä¸­ä¸¦ç± LLM é²è¡èçï¼ä»¥æ¨æ·åºç¼ºå¤±çè§æ¸¬å¼ãå¨é¢¨éåå½¢ä¿¡èçç·ä¸é æ¸¬ä»»åä¸­é²è¡æ¸¬è©¦ï¼æåçæ¨¡åå¨æºç¢ºæ§æ¹é¢åªæ¼ç·ä¸åå½¢éæ¿¾æ¼ç®æ³ï¼éè­æäº LLM å¨ææèçåå½¢ä¸­é¨åè§æ¸¬å°çä¿¡èæ¹é¢çæ½åã

##### **Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production**
2410.18475v2 by Kexuan Xin, Qingyun Wang, Junyu Chen, Pengfei Yu, Huimin Zhao, Heng Ji

In the rapidly evolving field of metabolic engineering, the quest for
efficient and precise gene target identification for metabolite production
enhancement presents significant challenges. Traditional approaches, whether
knowledge-based or model-based, are notably time-consuming and labor-intensive,
due to the vast scale of research literature and the approximation nature of
genome-scale metabolic model (GEM) simulations. Therefore, we propose a new
task, Gene-Metabolite Association Prediction based on metabolic graphs, to
automate the process of candidate gene discovery for a given pair of metabolite
and candidate-associated genes, as well as presenting the first benchmark
containing 2474 metabolites and 1947 genes of two commonly used microorganisms
Saccharomyces cerevisiae (SC) and Issatchenkia orientalis (IO). This task is
challenging due to the incompleteness of the metabolic graphs and the
heterogeneity among distinct metabolisms. To overcome these limitations, we
propose an Interactive Knowledge Transfer mechanism based on Metabolism Graph
(IKT4Meta), which improves the association prediction accuracy by integrating
the knowledge from different metabolism graphs. First, to build a bridge
between two graphs for knowledge transfer, we utilize Pretrained Language
Models (PLMs) with external knowledge of genes and metabolites to help generate
inter-graph links, significantly alleviating the impact of heterogeneity.
Second, we propagate intra-graph links from different metabolic graphs using
inter-graph links as anchors. Finally, we conduct the gene-metabolite
association prediction based on the enriched metabolism graphs, which integrate
the knowledge from multiple microorganisms. Experiments on both types of
organisms demonstrate that our proposed methodology outperforms baselines by up
to 12.3% across various link prediction frameworks.

æè¦ï¼<paragraph>å¨å¿«éç¼å±çä»£è¬å·¥ç¨é åä¸­ï¼å°æ±ææä¸ç²¾ç¢ºçåºå ç®æ¨è­å¥ä»¥æåä»£è¬ç¢ç©ç¢éï¼æ¯ä¸é éå¤§çææ°ãå³çµ±æ¹æ³ï¼ç¡è«æ¯åºæ¼ç¥è­æåºæ¼æ¨¡åï¼é½ç¸ç¶èæä¸è²»åï¼éæ¯å çºç ç©¶æç»çè¦æ¨¡é¾å¤§ï¼ä¸åºå çµè¦æ¨¡ä»£è¬æ¨¡å (GEM) æ¨¡æ¬çè¿ä¼¼æ§è³ªãå æ­¤ï¼æåæåºäºä¸é æ°çä»»åï¼å³åºæ¼ä»£è¬åçåºå -ä»£è¬ç©éè¯é æ¸¬ï¼ä»¥èªåååé¸åºå ç¼ç¾çéç¨ï¼éå°çµ¦å®çä»£è¬ç©å°ååé¸ç¸éåºå ï¼ä¸¦åç¾ç¬¬ä¸ååºæºï¼å¶ä¸­åå« 2474 ç¨®ä»£è¬ç©å 1947 ååºå ï¼ä¾èªå©ç¨®å¸¸ç¨çå¾®çç©éééµæ¯ (SC) åæ±æ¹ä¼è©ç´ç§éµæ¯ (IO)ãç±æ¼ä»£è¬åçä¸å®æ´æ§åä¸åä»£è¬ç©ä¹éçç°è³ªæ§ï¼éé ä»»åå·æææ°æ§ãçºäºåæéäºéå¶ï¼æåæåºäºä¸ååºæ¼ä»£è¬åçäºåç¥è­å³è¼¸æ©å¶ (IKT4Meta)ï¼å®ééæ´åä¾èªä¸åä»£è¬åçç¥è­ä¾æé«éè¯é æ¸¬çæºç¢ºæ§ãé¦åï¼çºäºå¨å©ååä¹éå»ºç«ç¥è­å³è¼¸çæ©æ¨ï¼æåå©ç¨å·ååºå åä»£è¬ç©å¤é¨ç¥è­çé è¨ç·´èªè¨æ¨¡å (PLM) ä¾å¹«å©ç¢çåéé£çµï¼å¤§å¹æ¸è¼ç°è³ªæ§çå½±é¿ãå¶æ¬¡ï¼æåä½¿ç¨åéé£çµä½çºé¨é»ï¼å¾ä¸åçä»£è¬åå³æ­åå§é£çµãæå¾ï¼æåæ ¹ææ´åäºå¤ç¨®å¾®çç©ç¥è­çè±å¯ä»£è¬åï¼é²è¡åºå -ä»£è¬ç©éè¯é æ¸¬ãå©ç¨®çç©é«çå¯¦é©é½è­æï¼æåæåºçæ¹æ³å¨åç¨®é£çµé æ¸¬æ¶æ§ä¸­ï¼æ¯åºæºé«åº 12.3%ã</paragraph>

##### **ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**
2410.18447v1 by Zezhong Wang, Xingshan Zeng, Weiwen Liu, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong

Supervised fine-tuning (SFT) is a common method to enhance the tool calling
capabilities of Large Language Models (LLMs), with the training data often
being synthesized. The current data synthesis process generally involves
sampling a set of tools, formulating a requirement based on these tools, and
generating the call statements. However, tools sampled randomly lack relevance,
making them difficult to combine and thus reducing the diversity of the data.
Additionally, current work overlooks the coherence between turns of dialogues,
leading to a gap between the synthesized data and real-world scenarios. To
address these issues, we propose a Graph-based Sampling strategy to sample more
relevant tool combinations, and a Planned-generation strategy to create plans
that guide the synthesis of coherent dialogues. We integrate these two
strategies and enable multiple agents to synthesize the dialogue data
interactively, resulting in our tool-calling data synthesis pipeline ToolFlow.
Data quality assessments demonstrate improvements in the naturalness and
coherence of our synthesized dialogues. Finally, we apply SFT on LLaMA-3.1-8B
using 8,000 synthetic dialogues generated with ToolFlow. Results show that the
model achieves tool-calling performance comparable to or even surpassing GPT-4,
while maintaining strong general capabilities.

æè¦ï¼ç£ç£å¾®èª¿ (SFT) æ¯å¢å¼·å¤§åèªè¨æ¨¡å (LLM) å·¥å·å¼å«åè½çå¸¸è¦æ¹æ³ï¼è¨ç·´è³æéå¸¸æ¯åæè³æãç®åçè³æåææµç¨éå¸¸æ¶åæ½æ¨£ä¸çµå·¥å·ãæ ¹æéäºå·¥å·å¶å®éæ±ï¼ä¸¦ç¢çå¼å«é³è¿°ãç¶èï¼é¨æ©æ½æ¨£çå·¥å·ç¼ºä¹éè¯æ§ï¼ä½¿å¾å®åé£ä»¥çµåï¼å¾èéä½è³æçå¤æ¨£æ§ãæ­¤å¤ï¼ç®åçå·¥ä½å¿½ç¥äºå°è©±ååä¹éçé£è²«æ§ï¼å°è´åæè³æèç¾å¯¦ä¸çå ´æ¯ä¹éå­å¨å·®è·ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ååºæ¼åå½¢çæ½æ¨£ç­ç¥ä¾æ½åæ´å¤ç¸éçå·¥å·çµåï¼ä»¥åä¸åè¨ç«çæç­ç¥ä¾å»ºç«è¨ç«ï¼ä»¥å¼å°é£è²«å°è©±çåæãæåæ´åéå©ç¨®ç­ç¥ï¼ä¸¦ä½¿å¤åä»£çè½å¤ äºåå°åæå°è©±è³æï¼å¾èç¢çæåçå·¥å·å¼å«è³æåæç®¡ç· ToolFlowãè³æåè³ªè©ä¼°è­æäºæååæå°è©±çèªç¶æ§åé£è²«æ§æäºæ¹é²ãæå¾ï¼æåä½¿ç¨ ToolFlow çæç 8,000 ååæå°è©±å¨ LLaMA-3.1-8B ä¸æç¨ SFTãçµæè¡¨æï¼è©²æ¨¡åå¯¦ç¾äºè GPT-4 ç¸ç¶çè³è¶è¶ GPT-4 çå·¥å·å¼å«æè½ï¼åæä¿æå¼·å¤§çéç¨è½åã

##### **Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains**
2410.18415v1 by Kun Li, Tianhua Zhang, Xixin Wu, Hongyin Luo, James Glass, Helen Meng

Knowledge Graphs (KGs) can serve as reliable knowledge sources for question
answering (QA) due to their structured representation of knowledge. Existing
research on the utilization of KG for large language models (LLMs) prevalently
relies on subgraph retriever or iterative prompting, overlooking the potential
synergy of LLMs' step-wise reasoning capabilities and KGs' structural nature.
In this paper, we present DoG (Decoding on Graphs), a novel framework that
facilitates a deep synergy between LLMs and KGs. We first define a concept,
well-formed chain, which consists of a sequence of interrelated fact triplets
on the KGs, starting from question entities and leading to answers. We argue
that this concept can serve as a principle for making faithful and sound
reasoning for KGQA. To enable LLMs to generate well-formed chains, we propose
graph-aware constrained decoding, in which a constraint derived from the
topology of the KG regulates the decoding process of the LLMs. This constrained
decoding method ensures the generation of well-formed chains while making full
use of the step-wise reasoning capabilities of LLMs. Based on the above, DoG, a
training-free approach, is able to provide faithful and sound reasoning
trajectories grounded on the KGs. Experiments across various KGQA tasks with
different background KGs demonstrate that DoG achieves superior and robust
performance. DoG also shows general applicability with various open-source
LLMs.

æè¦ï¼ç¥è­åè­ (KG) ç±æ¼å¶çµæ§åçç¥è­è¡¨ç¤ºï¼å¯ç¨ä½åç­ (QA) çå¯é ç¥è­ä¾æºãç¾æéæ¼å©ç¨ KG çå¤§åèªè¨æ¨¡å (LLM) çç ç©¶æ®éä¾è³´æ¼å­åæª¢ç´¢å¨æåè¦æç¤ºï¼å¿½è¦äº LLM çéæ­¥æ¨çè½åå KG ççµæ§ç¹æ§çæ½å¨ååä½ç¨ãå¨æ¬æä¸­ï¼æåæåºäº DoGï¼åå½¢è§£ç¢¼ï¼ï¼ä¸åä¿é² LLM å KG ä¹éæ·±åº¦ååä½ç¨çæ°æ¡æ¶ãæåé¦åå®ç¾©äºä¸åæ¦å¿µï¼å³è¯å¥½å½¢æçéï¼å®ç± KG ä¸ä¸ç³»åç¸äºéè¯çäºå¯¦ä¸åçµçµæï¼å¾åé¡å¯¦é«éå§ä¸¦å°è´ç­æ¡ãæåèªçºéåæ¦å¿µå¯ä»¥ä½çºå° KGQA é²è¡å¿ å¯¦ååççæ¨ççååãçºäºä½¿ LLM è½å¤ çæè¯å¥½çéï¼æåæåºäºåæç¥ç´æè§£ç¢¼ï¼å¶ä¸­æºèª KG ææ²çç´æç´æäº LLM çè§£ç¢¼éç¨ãéç¨®åç´æçè§£ç¢¼æ¹æ³ç¢ºä¿äºè¯å¥½å½¢æçéççæï¼åæååå©ç¨äº LLM çéæ­¥æ¨çè½åãåºæ¼ä¸è¿°ï¼DoG æ¯ä¸ç¨®ç¡éè¨ç·´çæ¹æ³ï¼è½å¤ æä¾åºæ¼ KG çå¿ å¯¦ä¸åççæ¨çè»è·¡ãå¨å·æä¸åèæ¯ KG çåç¨® KGQA ä»»åä¸­çå¯¦é©è¡¨æï¼DoG éå°äºåè¶ä¸ç©©å¥çæ§è½ãDoG éé¡¯ç¤ºäºèåç¨®éæº LLM çéç¨é©ç¨æ§ã

##### **Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**
2410.18060v1 by Jaime Sevilla, Nikolay Babakov, Ehud Reiter, Alberto Bugarin

In this paper, we propose a model for building natural language explanations
for Bayesian Network Reasoning in terms of factor arguments, which are
argumentation graphs of flowing evidence, relating the observed evidence to a
target variable we want to learn about. We introduce the notion of factor
argument independence to address the outstanding question of defining when
arguments should be presented jointly or separately and present an algorithm
that, starting from the evidence nodes and a target node, produces a list of
all independent factor arguments ordered by their strength. Finally, we
implemented a scheme to build natural language explanations of Bayesian
Reasoning using this approach. Our proposal has been validated in the medical
domain through a human-driven evaluation study where we compare the Bayesian
Network Reasoning explanations obtained using factor arguments with an
alternative explanation method. Evaluation results indicate that our proposed
explanation approach is deemed by users as significantly more useful for
understanding Bayesian Network Reasoning than another existing explanation
method it is compared to.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåæåºäºä¸åæ¨¡åï¼ç¨æ¼å»ºæ§è²æ°ç¶²è·¯æ¨ççèªç¶èªè¨è§£éï¼ä»¥å å­è«è­çºåºç¤ï¼å®åæ¯æµåè­æçè«è­åï¼å°è§å¯å°çè­æèæåæ³è¦äºè§£çç®æ¨è®æ¸è¯ç¹«èµ·ä¾ãæåå¼å¥äºå å­è«è­ç¨ç«æ§çæ¦å¿µï¼ä»¥è§£æ±ºå®ç¾©ä½ææå°è«è­è¯åæå®ç¨åç¾çæªæ±ºåé¡ï¼ä¸¦æåºäºä¸ç¨®æ¼ç®æ³ï¼å¾è­æç¯é»åç®æ¨ç¯é»éå§ï¼ç¢çä¸åæå¼·åº¦æåºçææç¨ç«å å­è«è­æ¸å®ãæå¾ï¼æåå¯¦ä½äºä¸åæ¹æ¡ï¼ä½¿ç¨éç¨®æ¹æ³å»ºæ§è²æ°æ¨ççèªç¶èªè¨è§£éãæåçææ¡å·²å¨é«å­¸é åä¸­ééäººçºé©åçè©ä¼°ç ç©¶å¾å°é©è­ï¼å¨è©²ç ç©¶ä¸­ï¼æåå°ä½¿ç¨å å­è«è­ç²å¾çè²æ°ç¶²è·¯æ¨çè§£éèå¦ä¸ç¨®è§£éæ¹æ³é²è¡æ¯è¼ãè©ä¼°çµæè¡¨æï¼èå¦ä¸ç¨®ç¾æçè§£éæ¹æ³ç¸æ¯ï¼æåçæè­°è§£éæ¹æ³è¢«ä½¿ç¨èè¦çºé¡¯èæ´æå©æ¼çè§£è²æ°ç¶²è·¯æ¨çã</paragraph>

##### **Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective**
2410.17600v1 by Rui Yang, Boming Yang, Aosong Feng, Sixun Ouyang, Moritz Blum, Tianwei She, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li

Knowledge Graphs (KGs) are crucial in the field of artificial intelligence
and are widely used in downstream tasks, such as question-answering (QA). The
construction of KGs typically requires significant effort from domain experts.
Large Language Models (LLMs) have recently been used for Knowledge Graph
Construction (KGC). However, most existing approaches focus on a local
perspective, extracting knowledge triplets from individual sentences or
documents, missing a fusion process to combine the knowledge in a global KG.
This work introduces Graphusion, a zero-shot KGC framework from free text. It
contains three steps: in Step 1, we extract a list of seed entities using topic
modeling to guide the final KG includes the most relevant entities; in Step 2,
we conduct candidate triplet extraction using LLMs; in Step 3, we design the
novel fusion module that provides a global view of the extracted knowledge,
incorporating entity merging, conflict resolution, and novel triplet discovery.
Results show that Graphusion achieves scores of 2.92 and 2.37 out of 3 for
entity extraction and relation recognition, respectively. Moreover, we showcase
how Graphusion could be applied to the Natural Language Processing (NLP) domain
and validate it in an educational scenario. Specifically, we introduce TutorQA,
a new expert-verified benchmark for QA, comprising six tasks and a total of
1,200 QA pairs. Using the Graphusion-constructed KG, we achieve a significant
improvement on the benchmark, for example, a 9.2% accuracy improvement on
sub-graph completion.

æè¦ï¼<paragraph>ç¥è­åè­ (KG) å¨äººå·¥æºæ§é åè³ééè¦ï¼å»£æ³ç¨æ¼ä¸æ¸¸ä»»åï¼ä¾å¦åç­ (QA)ãKG çå»ºæ§éå¸¸éè¦é åå°å®¶ä»åºå¤§éå¿åãå¤§åèªè¨æ¨¡å (LLM) è¿ä¾å·²ç¨æ¼ç¥è­åè­å»ºæ§ (KGC)ãç¶èï¼ç¾ææ¹æ³å¤§å¤èéæ¼å±é¨è§é»ï¼å¾åå¥å¥å­ææä»¶æ·åç¥è­ä¸åçµï¼ç¼ºå°ä¸åèåç¨åºä¾å°ç¥è­çµåå¨ä¸åæ´é« KG ä¸­ãæ¬ç ç©¶å¼å¥äº Graphusionï¼ä¸åå¾èªç±æå­é²è¡é¶æ¬¡å­¸ç¿ç KGC æ¡æ¶ãå®åå«ä¸åæ­¥é©ï¼å¨æ­¥é© 1 ä¸­ï¼æåä½¿ç¨ä¸»é¡å»ºæ¨¡æ·åä¸çµç¨®å­å¯¦é«ï¼ä»¥å¼å°æçµç KG ç´å¥æç¸éçå¯¦é«ï¼å¨æ­¥é© 2 ä¸­ï¼æåä½¿ç¨ LLM é²è¡åé¸ä¸åçµæ·åï¼å¨æ­¥é© 3 ä¸­ï¼æåè¨­è¨äºæ°ç©çèåæ¨¡çµï¼æä¾æ·åç¥è­çæ´é«è§é»ï¼åå«å¯¦é«åä½µãè¡çªè§£æ±ºåæ°ä¸åçµç¼ç¾ãçµæé¡¯ç¤º Graphusion å¨å¯¦é«æ·ååéä¿è­å¥æ¹é¢åå¥ç²å¾ 3 åä¸­ç 2.92 åå 2.37 åãæ­¤å¤ï¼æåå±ç¤ºäº Graphusion å¦ä½æç¨æ¼èªç¶èªè¨èç (NLP) é åï¼ä¸¦å¨æè²æå¢ä¸­é©è­å®ãå·é«ä¾èªªï¼æåå¼å¥äº TutorQAï¼ä¸åç±å°å®¶é©è­çæ°å QA åºæºï¼åå«å­é ä»»ååç¸½è¨ 1,200 çµ QAãä½¿ç¨ Graphusion å»ºæ§ç KGï¼æåå¨åºæºä¸åå¾é¡¯èé²æ­¥ï¼ä¾å¦ï¼å¨å­åå®ææ¹é¢æåäº 9.2% çæºç¢ºåº¦ã</paragraph>

##### **Navigate Complex Physical Worlds via Geometrically Constrained LLM**
2410.17529v1 by Yongqiang Huang, Wentao Ye, Liyao Li, Junbo Zhao

This study investigates the potential of Large Language Models (LLMs) for
reconstructing and constructing the physical world solely based on textual
knowledge. It explores the impact of model performance on spatial understanding
abilities. To enhance the comprehension of geometric and spatial relationships
in the complex physical world, the study introduces a set of geometric
conventions and develops a workflow based on multi-layer graphs and multi-agent
system frameworks. It examines how LLMs achieve multi-step and multi-objective
geometric inference in a spatial environment using multi-layer graphs under
unified geometric conventions. Additionally, the study employs a genetic
algorithm, inspired by large-scale model knowledge, to solve geometric
constraint problems. In summary, this work innovatively explores the
feasibility of using text-based LLMs as physical world builders and designs a
workflow to enhance their capabilities.

æè¦ï¼æ¬ç ç©¶æ¢è¨å¤§åèªè¨æ¨¡å (LLM) ååºæ¼æå­ç¥è­éå»ºåå»ºæ§ç©çä¸ççæ½åãæ¢è¨æ¨¡åæè½å°ç©ºéçè§£è½åçå½±é¿ãçºäºå¢å¼·å°è¤éç©çä¸çä¸­å¹¾ä½åç©ºééä¿ççè§£ï¼æ¬ç ç©¶å¼å¥äºä¸çµå¹¾ä½æ£ä¾ï¼ä¸¦åºæ¼å¤å±¤åå½¢åå¤ä»£çç³»çµ±æ¶æ§éç¼äºä¸å¥å·¥ä½æµç¨ãç ç©¶æ¢è¨äº LLM å¦ä½å¨çµ±ä¸çå¹¾ä½æ£ä¾ä¸ï¼ä½¿ç¨å¤å±¤åå½¢å¨ç©ºéç°å¢ä¸­éæå¤æ­¥é©åå¤ç®æ¨çå¹¾ä½æ¨è«ãæ­¤å¤ï¼æ¬ç ç©¶æ¡ç¨åå¤§åæ¨¡åç¥è­åç¼çéºå³æ¼ç®æ³ä¾è§£æ±ºå¹¾ä½ç´æåé¡ãç¸½ä¹ï¼éé å·¥ä½åµæ°å°æ¢è¨äºä½¿ç¨åºæ¼æå­ç LLM ä½çºç©çä¸çå»ºæ§èçå¯è¡æ§ï¼ä¸¦è¨­è¨äºä¸å¥å·¥ä½æµç¨ä¾å¢å¼·å¶è½åã

##### **Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs**
2410.16882v1 by Leyao Wang, Yu Wang, Bo Ni, Yuying Zhao, Tyler Derr

Node classification on graphs frequently encounters the challenge of class
imbalance, leading to biased performance and posing significant risks in
real-world applications. Although several data-centric solutions have been
proposed, none of them focus on Text-Attributed Graphs (TAGs), and therefore
overlook the potential of leveraging the rich semantics encoded in textual
features for boosting the classification of minority nodes. Given this crucial
gap, we investigate the possibility of augmenting graph data in the text space,
leveraging the textual generation power of Large Language Models (LLMs) to
handle imbalanced node classification on TAGs. Specifically, we propose a novel
approach called LA-TAG (LLM-based Augmentation on Text-Attributed Graphs),
which prompts LLMs to generate synthetic texts based on existing node texts in
the graph. Furthermore, to integrate these synthetic text-attributed nodes into
the graph, we introduce a text-based link predictor to connect the synthesized
nodes with the existing nodes. Our experiments across multiple datasets and
evaluation metrics show that our framework significantly outperforms
traditional non-textual-based data augmentation strategies and specific node
imbalance solutions. This highlights the promise of using LLMs to resolve
imbalance issues on TAGs.

æè¦ï¼åå½¢ç¯é»åé¡ç¶å¸¸æéå°é¡å¥ä¸å¹³è¡¡çææ°ï¼å°è´æåå·®çæè½ï¼ä¸¦å¨å¯¦éæç¨ä¸­é æé¡¯èé¢¨éªãåç®¡å·²æåºå¤é ä»¥è³æçºä¸­å¿çè§£æ±ºæ¹æ¡ï¼ä½æ²æä¸é å°æ³¨æ¼æå­å±¬æ§åå½¢ (TAG)ï¼å æ­¤å¿½ç¥äºå©ç¨æå­ç¹å¾µä¸­ç·¨ç¢¼çè±å¯èªæä¾æåå°æ¸ç¯é»åé¡çå¯è½æ§ãéæ¼éåééµå·®è·ï¼æåæ¢è¨äºå¨æå­ç©ºéä¸­æ´ååå½¢è³æçå¯è½æ§ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) çæå­ç¢çè½åä¾èç TAG ä¸çä¸å¹³è¡¡ç¯é»åé¡ãå·é«ä¾èªªï¼æåæåºäºä¸ç¨®åçº LA-TAGï¼åºæ¼ LLM çæå­å±¬æ§åå½¢æ´åï¼çæ°æ¹æ³ï¼å®æç¤º LLM æ ¹æåå½¢ä¸­ç¾æçç¯é»æå­ç¢çåææå­ãæ­¤å¤ï¼çºäºå°éäºåææå­å±¬æ§ç¯é»æ´åå°åå½¢ä¸­ï¼æåå¼å¥äºä¸ååºæ¼æå­çé£çµé æ¸¬å¨ï¼ä»¥å°åæç¯é»èç¾æç¯é»é£æ¥èµ·ä¾ãæåå¨å¤åè³æéåè©ä¼°ææ¨ä¸çå¯¦é©è¡¨æï¼æåçæ¡æ¶æé¡¯åªæ¼å³çµ±çéæå­è³ææ´åç­ç¥åç¹å®çç¯é»ä¸å¹³è¡¡è§£æ±ºæ¹æ¡ãéçªé¡¯äºä½¿ç¨ LLM ä¾è§£æ±º TAG ä¸çä¸å¹³è¡¡åé¡çæ½åã

##### **Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning**
2410.16803v2 by Muzhi Li, Cehao Yang, Chengjin Xu, Zixing Song, Xuhui Jiang, Jian Guo, Ho-fung Leung, Irwin King

Inductive knowledge graph completion (KGC) aims to predict missing triples
with unseen entities. Recent works focus on modeling reasoning paths between
the head and tail entity as direct supporting evidence. However, these methods
depend heavily on the existence and quality of reasoning paths, which limits
their general applicability in different scenarios. In addition, we observe
that latent type constraints and neighboring facts inherent in KGs are also
vital in inferring missing triples. To effectively utilize all useful
information in KGs, we introduce CATS, a novel context-aware inductive KGC
solution. With sufficient guidance from proper prompts and supervised
fine-tuning, CATS activates the strong semantic understanding and reasoning
capabilities of large language models to assess the existence of query triples,
which consist of two modules. First, the type-aware reasoning module evaluates
whether the candidate entity matches the latent entity type as required by the
query relation. Then, the subgraph reasoning module selects relevant reasoning
paths and neighboring facts, and evaluates their correlation to the query
triple. Experiment results on three widely used datasets demonstrate that CATS
significantly outperforms state-of-the-art methods in 16 out of 18
transductive, inductive, and few-shot settings with an average absolute MRR
improvement of 7.2%.

æè¦ï¼æ­¸ç´ç¥è­åè­è£å¨ (KGC) çç®æ¨æ¯é æ¸¬å·ææªè¦å¯¦é«çä¸åçµãæè¿çç ç©¶å°æ³¨æ¼å»ºæ¨¡é ­é¨åå°¾é¨å¯¦é«ä¹éçæ¨çè·¯å¾ï¼ä½çºç´æ¥çæ¯æ´è­æãç¶èï¼éäºæ¹æ³æ¥µåº¦ä¾è³´æ¨çè·¯å¾çå­å¨ååè³ªï¼ééå¶äºå®åå¨ä¸åå ´æ¯ä¸­çæ®éé©ç¨æ§ãæ­¤å¤ï¼æåè§å¯å°ï¼æ½å¨é¡åç´æå KG ä¸­åºæçé°è¿äºå¯¦å°æ¼æ¨è«éºå¤±çä¸åçµä¹è³ééè¦ãçºäºææå©ç¨ KG ä¸­æææç¨çè³è¨ï¼æåå¼å¥äº CATSï¼éæ¯ä¸åæ°ç©çå·åæå¢æç¥è½åçæ­¸ç´å¼ KGC è§£å³æ¹æ¡ãå¨é©ç¶æç¤ºåç£ç£å¾®èª¿çååæå°ä¸ï¼CATS åç¨äºå¤§åèªè¨æ¨¡åå¼·å¤§çèªç¾©çè§£åæ¨çè½åï¼ä»¥è©ä¼°æ¥è©¢ä¸åçµçå­å¨ï¼éäºä¸åçµç±å©åæ¨¡çµçµæãé¦åï¼é¡åæç¥æ¨çæ¨¡çµè©ä¼°åé¸å¯¦é«æ¯å¦èæ¥è©¢éä¿æè¦æ±çæ½å¨å¯¦é«é¡åç¸ç¬¦ãç¶å¾ï¼å­åæ¨çæ¨¡çµé¸æç¸éçæ¨çè·¯å¾åé°è¿äºå¯¦ï¼ä¸¦è©ä¼°å®åèæ¥è©¢ä¸åçµçéè¯æ§ãå¨ä¸åå»£æ³ä½¿ç¨çè³æéä¸çå¯¦é©çµæè¡¨æï¼å¨ 18 åè½å°å¼ãæ­¸ç´å¼åå°æ¬¡åè©¦è¨­å®ä¸­ï¼CATS å¨ 16 åè¨­å®ä¸­é¡¯èåªæ¼æåé²çæ¹æ³ï¼å¹³åçµå° MRR æåäº 7.2%ã

##### **The Scene Language: Representing Scenes with Programs, Words, and Embeddings**
2410.16770v1 by Yunzhi Zhang, Zizhang Li, Matt Zhou, Shangzhe Wu, Jiajun Wu

We introduce the Scene Language, a visual scene representation that concisely
and precisely describes the structure, semantics, and identity of visual
scenes. It represents a scene with three key components: a program that
specifies the hierarchical and relational structure of entities in the scene,
words in natural language that summarize the semantic class of each entity, and
embeddings that capture the visual identity of each entity. This representation
can be inferred from pre-trained language models via a training-free inference
technique, given text or image inputs. The resulting scene can be rendered into
images using traditional, neural, or hybrid graphics renderers. Together, this
forms a robust, automated system for high-quality 3D and 4D scene generation.
Compared with existing representations like scene graphs, our proposed Scene
Language generates complex scenes with higher fidelity, while explicitly
modeling the scene structures to enable precise control and editing.

æè¦ï¼æåå¼å¥äºå ´æ¯èªè¨ï¼éæ¯ä¸ç¨®è¦è¦ºå ´æ¯è¡¨ç¤ºæ³ï¼ç°¡æ½ä¸ç²¾ç¢ºå°æè¿°äºè¦è¦ºå ´æ¯ççµæ§ãèªæåèº«åãå®ä½¿ç¨ä¸åééµçµæé¨åä¾è¡¨ç¤ºå ´æ¯ï¼ä¸åç¨å¼ï¼ç¨æ¼æå®å ´æ¯ä¸­å¯¦é«çéå±¤åéä¿çµæ§ï¼ä»¥èªç¶èªè¨è¡¨ç¤ºçè©å½ï¼ç¨æ¼ç¸½çµæ¯åå¯¦é«çèªæé¡å¥ï¼ä»¥åç¨æ¼æ·åæ¯åå¯¦é«çè¦è¦ºèº«åçåµå¥ãéåè¡¨ç¤ºæ³å¯ä»¥ééç¡è¨ç·´æ¨è«æè¡å¾é åè¨ç·´çèªè¨æ¨¡åæ¨è«åºä¾ï¼çµ¦å®æå­æå½±åè¼¸å¥ãç¢ççå ´æ¯å¯ä»¥ä½¿ç¨å³çµ±ãç¥ç¶ææ··ååå½¢æ¸²æå¨æ¸²ææå½±åãç¸½èè¨ä¹ï¼éå½¢æäºä¸åå¼·å¥çèªååç³»çµ±ï¼ç¨æ¼é«åè³ª 3D å 4D å ´æ¯çæãèç¾æçè¡¨ç¤ºæ³ï¼ä¾å¦å ´æ¯åï¼ç¸æ¯ï¼æåæåºçå ´æ¯èªè¨å¯ä»¥çæå·ææ´é«ä¿çåº¦çè¤éå ´æ¯ï¼åææç¢ºå°å»ºæ¨¡å ´æ¯çµæ§ä»¥å¯¦ç¾ç²¾ç¢ºæ§å¶åç·¨è¼¯ã

##### **Atomic Fact Decomposition Helps Attributed Question Answering**
2410.16708v1 by Zhichao Yan, Jiapu Wang, Jiaoyan Chen, Xiaoli Li, Ru Li, Jeff Z. Pan

Attributed Question Answering (AQA) aims to provide both a trustworthy answer
and a reliable attribution report for a given question. Retrieval is a widely
adopted approach, including two general paradigms: Retrieval-Then-Read (RTR)
and post-hoc retrieval. Recently, Large Language Models (LLMs) have shown
remarkable proficiency, prompting growing interest in AQA among researchers.
However, RTR-based AQA often suffers from irrelevant knowledge and rapidly
changing information, even when LLMs are adopted, while post-hoc
retrieval-based AQA struggles with comprehending long-form answers with complex
logic, and precisely identifying the content needing revision and preserving
the original intent. To tackle these problems, this paper proposes an Atomic
fact decomposition-based Retrieval and Editing (ARE) framework, which
decomposes the generated long-form answers into molecular clauses and atomic
facts by the instruction-tuned LLMs. Notably, the instruction-tuned LLMs are
fine-tuned using a well-constructed dataset, generated from large scale
Knowledge Graphs (KGs). This process involves extracting one-hop neighbors from
a given set of entities and transforming the result into coherent long-form
text. Subsequently, ARE leverages a search engine to retrieve evidences related
to atomic facts, inputting these evidences into an LLM-based verifier to
determine whether the facts require expansion for re-retrieval or editing.
Furthermore, the edited facts are backtracked into the original answer, with
evidence aggregated based on the relationship between molecular clauses and
atomic facts. Extensive evaluations demonstrate the superior performance of our
proposed method over the state-of-the-arts on several datasets, with an
additionally proposed new metric $Attr_{p}$ for evaluating the precision of
evidence attribution.

æè¦ï¼<paragraph>æ­¸å å¼åç­ (AQA) çç®æ¨æ¯éå°ç¹å®åé¡æä¾å¯ä¿¡çç­æ¡åå¯é çæ­¸å å ±åãæ·åæ¯ä¸ç¨®å»£æ³æ¡ç¨çæ¹æ³ï¼åæ¬å©ç¨®ä¸è¬ç¯ä¾ï¼æ·ååé±è® (RTR) åäºå¾æ·åãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºåè¶ççç·´åº¦ï¼ä¿ä½¿ç ç©¶äººå¡å° AQA ç¢çè¶ä¾è¶æ¿åçèè¶£ãç¶èï¼å³ä½¿æ¡ç¨ LLMï¼åºæ¼ RTR ç AQA ä»å¸¸å¸¸æåå°ä¸ç¸éç¥è­åå¿«éè®åçè³è¨å½±é¿ï¼èåºæ¼äºå¾æ·åç AQA åé£ä»¥çè§£å·æè¤ééè¼¯çé·ç¯ç­æ¡ï¼ä¸¦ç²¾ç¢ºæ¾åºéè¦ä¿®æ¹çå§å®¹ï¼åæä¿çåå§æåãçºäºè§£æ±ºéäºåé¡ï¼æ¬ææåºäºä¸ååºæ¼åå­äºå¯¦åè§£çæ·ååç·¨è¼¯ (ARE) æ¶æ§ï¼å®ééæä»¤èª¿æ´ç LLM å°ç¢ççé·ç¯ç­æ¡åè§£çºåå­å­å¥ååå­äºå¯¦ãå¼å¾æ³¨æçæ¯ï¼æä»¤èª¿æ´ç LLM æä½¿ç¨å¾å¤§è¦æ¨¡ç¥è­åè­ (KG) ä¸­ç¢çççµæ§è¯å¥½è³æéé²è¡å¾®èª¿ãæ­¤ç¨åºåå«å¾ç¹å®å¯¦é«éåä¸­æ·åä¸è·³é°å±ï¼ä¸¦å°çµæè½æçºé£è²«çé·ç¯æå­ãé¨å¾ï¼ARE æå©ç¨æå°å¼ææ·åèåå­äºå¯¦ç¸éçè­æï¼å°éäºè­æè¼¸å¥å°åºæ¼ LLM çé©è­å¨ä¸­ï¼ä»¥ç¢ºå®äºå¯¦æ¯å¦éè¦æ´åä»¥ä¾éæ°æ·åæç·¨è¼¯ãæ­¤å¤ï¼ç·¨è¼¯å¾ççµææåæº¯å°åå§ç­æ¡ï¼ä¸¦æ ¹æåå­å­å¥ååå­äºå¯¦ä¹éçéä¿å½æ´è­æãå»£æ³çè©ä¼°é¡¯ç¤ºï¼æåæåºçæ¹æ³å¨å¤åè³æéä¸åªæ¼ç¾ææè¡ï¼ä¸¦é¡å¤æåºäºä¸åæ°çææ¨ $Attr_{p}$ï¼ç¨æ¼è©ä¼°è­ææ­¸å çç²¾æºåº¦ã</paragraph>

##### **PLDR-LLM: Large Language Model from Power Law Decoder Representations**
2410.16703v1 by Burc Gokden

We present the Large Language Model from Power Law Decoder Representations
(PLDR-LLM), a language model that leverages non-linear and linear
transformations through Power Law Graph Attention mechanism to generate
well-defined deductive and inductive outputs. We pretrain the PLDR-LLMs of
varying layer sizes with a small batch size of 32 and $\sim$8B tokens from the
RefinedWeb dataset, and show that they achieve competitive performance in
zero-shot and few-shot settings compared to scaled dot-product LLMs of similar
model size reported in the literature. We show that deductive outputs of
PLDR-LLMs can be used to compare model characteristics or improve the
performance by introducing the Directed Acyclic Graph (DAG) loss as a metric
and regularizer. Our results indicate that the initial maximum learning rate
and warm-up steps have a lasting impact on deductive outputs throughout the
pretraining. We provide a detailed description of PLDR-LLM architecture, its
implementation and the pretraining procedure.

æè¦ï¼æåæåºä½¿ç¨åªå¾è§£ç¢¼å¨è¡¨ç¤ºæ³çå¤§èªè¨æ¨¡å (PLDR-LLM)ï¼éæ¯ä¸åèªè¨æ¨¡åï¼å®ééåªå¾åæ³¨æåæ©å¶ï¼å©ç¨éç·æ§åç·æ§è½æä¾ç¢çå®ç¾©è¯å¥½çæ¼ç¹¹åæ­¸ç´è¼¸åºãæåä½¿ç¨ 32 çå°æ¹æ¬¡å¤§å°å RefinedWeb è³æéä¸­ç $\sim$8B ä»¤çï¼é è¨ç·´ä¸åå±¤å¤§å°ç PLDR-LLMï¼ä¸¦å±ç¤ºåºå®åå¨é¶æ¬¡åå°æ¬¡è¨­å®ä¸­ï¼èæç»ä¸­å ±å°çé¡ä¼¼æ¨¡åå¤§å°çç¸®æ¾é»ç© LLM ç¸æ¯ï¼å®åéå°äºç«¶ç­åè¡¨ç¾ãæåå±ç¤ºäº PLDR-LLM çæ¼ç¹¹è¼¸åºå¯ç¨æ¼æ¯è¼æ¨¡åç¹å¾µæééå¼å¥æåç¡ç°å (DAG) æå¤±ä½çºææ¨åæ­£ååå¨ä¾æ¹åæè½ãæåççµæè¡¨æï¼åå§æå¤§å­¸ç¿çåç±èº«æ­¥é©å°æ´åé è¨ç·´éç¨ä¸­çæ¼ç¹¹è¼¸åºææä¹çå½±é¿ãæåæä¾äº PLDR-LLM æ¶æ§ãå¶å¯¦ç¾åé è¨ç·´ç¨åºçè©³ç´°èªªæã

##### **Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for Improved Coverage and Efficiency**
2410.16597v1 by Prafulla Kumar Choubey, Xin Su, Man Luo, Xiangyu Peng, Caiming Xiong, Tiep Le, Shachar Rosenman, Vasudev Lal, Phil Mui, Ricky Ho, Phillip Howard, Chien-Sheng Wu

Knowledge graphs (KGs) generated by large language models (LLMs) are becoming
increasingly valuable for Retrieval-Augmented Generation (RAG) applications
that require knowledge-intensive reasoning. However, existing KG extraction
methods predominantly rely on prompt-based approaches, which are inefficient
for processing large-scale corpora. These approaches often suffer from
information loss, particularly with long documents, due to the lack of
specialized design for KG construction. Additionally, there is a gap in
evaluation datasets and methodologies for ontology-free KG construction. To
overcome these limitations, we propose SynthKG, a multi-step, document-level
ontology-free KG synthesis workflow based on LLMs. By fine-tuning a smaller LLM
on the synthesized document-KG pairs, we streamline the multi-step process into
a single-step KG generation approach called Distill-SynthKG, substantially
reducing the number of LLM inference calls. Furthermore, we re-purpose existing
question-answering datasets to establish KG evaluation datasets and introduce
new evaluation metrics. Using KGs produced by Distill-SynthKG, we also design a
novel graph-based retrieval framework for RAG. Experimental results demonstrate
that Distill-SynthKG not only surpasses all baseline models in KG quality --
including models up to eight times larger -- but also consistently excels in
retrieval and question-answering tasks. Our proposed graph retrieval framework
also outperforms all KG-retrieval methods across multiple benchmark datasets.
We release the SynthKG dataset and Distill-SynthKG model publicly to support
further research and development.

æè¦ï¼ç±å¤§åèªè¨æ¨¡å (LLM) çæçç¥è­åè­ (KG) å°æ¼éè¦ç¥è­å¯éåæ¨ççæª¢ç´¢å¢å¼·çæ (RAG) æç¨ç¨å¼è®å¾è¶ä¾è¶æå¹å¼ãç¶èï¼ç¾æç KG èåæ¹æ³ä¸»è¦ä¾è³´æ¼æç¤ºå¼æ¹æ³ï¼éç¨®æ¹æ³å°æ¼èçå¤§è¦æ¨¡èªæåº«èè¨æçä½ä¸ãç±æ¼ç¼ºä¹éå° KG å»ºæ§çå°éè¨­è¨ï¼éäºæ¹æ³éå¸¸æé­åè³è¨éºå¤±ï¼ç¹å¥æ¯å¨é·ç¯æä»¶çææ³ä¸ãæ­¤å¤ï¼å¨ç¨æ¼å»ºæ§ç¡æ¬ä½ KG çè©ä¼°è³æéåæ¹æ³è«æ¹é¢å­å¨å·®è·ãçºäºåæéäºéå¶ï¼æåæåºäº SynthKGï¼éæ¯ä¸ååºæ¼ LLM çå¤æ­¥é©æä»¶ç´å¥ç¡æ¬ä½ KG åæå·¥ä½æµç¨ãééå¾®èª¿è¼å°ç LLM å¨åæçæä»¶-KG å°ä¸ï¼æåå°å¤æ­¥é©æµç¨ç°¡åçºç¨±çº Distill-SynthKG çå®æ­¥é© KG çææ¹æ³ï¼å¤§å¹æ¸å°äº LLM æ¨è«å¼å«çæ¸éãæ­¤å¤ï¼æåéæ°å©ç¨ç¾æçåç­è³æéä¾å»ºç« KG è©ä¼°è³æéï¼ä¸¦å¼å¥æ°çè©ä¼°ææ¨ãä½¿ç¨ Distill-SynthKG çæç KGï¼æåéçº RAG è¨­è¨äºä¸åæ°ç©çåºæ¼åå½¢çæª¢ç´¢æ¶æ§ãå¯¦é©çµæè¡¨æï¼Distill-SynthKG ä¸åå¨ KG åè³ªæ¹é¢è¶è¶äºææåºæºæ¨¡åï¼åæ¬å¤§å«åçæ¨¡åï¼ï¼èä¸å¨æª¢ç´¢ååç­ä»»åä¸­ä¹å§çµè¡¨ç¾åºè²ãæåæåºçåå½¢æª¢ç´¢æ¶æ§å¨å¤ååºæºè³æéä¸ä¹åªæ¼ææ KG æª¢ç´¢æ¹æ³ãæåå¬ééåº SynthKG è³æéå Distill-SynthKG æ¨¡åï¼ä»¥æ¯æé²ä¸æ­¥çç ç©¶åéç¼ã

##### **Towards a Reliable Offline Personal AI Assistant for Long Duration Spaceflight**
2410.16397v1 by Oliver Bensch, Leonie Bensch, Tommy Nilsson, Florian Saling, Wafa M. Sadri, Carsten Hartmann, Tobias Hecking, J. Nathan Kutz

As humanity prepares for new missions to the Moon and Mars, astronauts will
need to operate with greater autonomy, given the communication delays that make
real-time support from Earth difficult. For instance, messages between Mars and
Earth can take up to 24 minutes, making quick responses impossible. This
limitation poses a challenge for astronauts who must rely on in-situ tools to
access the large volume of data from spacecraft sensors, rovers, and
satellites, data that is often fragmented and difficult to use. To bridge this
gap, systems like the Mars Exploration Telemetry-Driven Information System
(METIS) are being developed. METIS is an AI assistant designed to handle
routine tasks, monitor spacecraft systems, and detect anomalies, all while
reducing the reliance on mission control. Current Generative Pretrained
Transformer (GPT) Models, while powerful, struggle in safety-critical
environments. They can generate plausible but incorrect responses, a phenomenon
known as "hallucination," which could endanger astronauts. To overcome these
limitations, this paper proposes enhancing systems like METIS by integrating
GPTs, Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and
Augmented Reality (AR). The idea is to allow astronauts to interact with their
data more intuitively, using natural language queries and visualizing real-time
information through AR. KGs will be used to easily access live telemetry and
multimodal data, ensuring that astronauts have the right information at the
right time. By combining AI, KGs, and AR, this new system will empower
astronauts to work more autonomously, safely, and efficiently during future
space missions.

æè¦ï¼é¨èäººé¡æºååå¾æçåç«æå·è¡æ°ä»»åï¼èéå°éè¨å»¶é²è®ä¾èªå°ççå³ææ¯æ´è®å¾å°é£ï¼å¤ªç©ºäººå°éè¦ä»¥æ´é«çèªä¸»æ§å·è¡ä»»åãä¾å¦ï¼ç«æåå°çä¹éçè¨æ¯å³éå¯è½éè¦é·é 24 åéï¼éä½¿å¾å¿«éåæè®å¾ä¸å¯è½ãéåéå¶å°å¿é ä»°è³´ç¾å ´å·¥å·æè½å­åä¾èªå¤ªç©ºè¹ææ¸¬å¨ãæ¢æ¸¬è»åè¡æçå¤§éè³æçå¤ªç©ºäººä¾èªªæ¯ä¸é ææ°ï¼èéäºè³æéå¸¸æ¯çæ®µä¸é£ä»¥ä½¿ç¨çãçºäºå½åéåå·®è·ï¼åç«ææ¢æ¸¬éæ¸¬é©åè³è¨ç³»çµ± (METIS) ä¹é¡çç³»çµ±æ­£å¨éç¼ä¸­ãMETIS æ¯ä¸å AI å©çï¼æ¨å¨èçä¾è¡å·¥ä½ãç£æ§å¤ªç©ºè¹ç³»çµ±ååµæ¸¬ç°å¸¸ï¼åææ¸å°å°ä»»åæ§å¶çä¾è³´ãç¾æççæå¼é è¨ç·´Transformer (GPT) æ¨¡åéç¶å¼·å¤§ï¼ä½å¨å®å¨ééµç°å¢ä¸­å»é£ä»¥ç¼æ®ä½ç¨ãå®åå¯è½æç¢ççä¼¼åçä½é¯èª¤çåæï¼éç¨®ç¾è±¡ç¨±çºãå¹»è¦ºãï¼å¯è½æä½¿å¤ªç©ºäººé·å¥å±éªãçºäºåæéäºéå¶ï¼æ¬ææåºééæ´å GPTãæª¢ç´¢å¢å¼·çæ (RAG)ãç¥è­åè­ (KG) åæ´å¢å¯¦å¢ (AR) ä¾å¢å¼·å METIS ä¹é¡çç³»çµ±ãéåæ³æ³æ¯è®å¤ªç©ºäººè½å¤ æ´ç´è¦ºå°èä»åçè³æäºåï¼ä½¿ç¨èªç¶èªè¨æ¥è©¢ä¸¦éé AR è¦è¦ºåå³æè³è¨ãKG å°ç¨æ¼è¼é¬å­åå³æéæ¸¬åå¤æ¨¡å¼è³æï¼ç¢ºä¿å¤ªç©ºäººå¨é©ç¶çæéåå¾é©ç¶çè³è¨ãééçµå AIãKG å ARï¼éåæ°ç³»çµ±å°è³¦è½å¤ªç©ºäººå¨æªä¾çå¤ªç©ºä»»åä¸­æ´èªä¸»ãå®å¨ä¸ææçå°å·¥ä½ã

##### **A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns**
2410.16155v1 by Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao

With the development of large language models, they are widely used as agents
in various fields. A key component of agents is memory, which stores vital
information but is susceptible to jailbreak attacks. Existing research mainly
focuses on single-agent attacks and shared memory attacks. However, real-world
scenarios often involve independent memory. In this paper, we propose the
Troublemaker Makes Chaos in Honest Town (TMCHT) task, a large-scale,
multi-agent, multi-topology text-based attack evaluation framework. TMCHT
involves one attacker agent attempting to mislead an entire society of agents.
We identify two major challenges in multi-agent attacks: (1) Non-complete graph
structure, (2) Large-scale systems. We attribute these challenges to a
phenomenon we term toxicity disappearing. To address these issues, we propose
an Adversarial Replication Contagious Jailbreak (ARCJ) method, which optimizes
the retrieval suffix to make poisoned samples more easily retrieved and
optimizes the replication suffix to make poisoned samples have contagious
ability. We demonstrate the superiority of our approach in TMCHT, with 23.51%,
18.95%, and 52.93% improvements in line topology, star topology, and 100-agent
settings. Encourage community attention to the security of multi-agent systems.

æè¦ï¼éçå¤§åè¯­è¨æ¨¡åçåå±ï¼å®ä»¬è¢«å¹¿æ³ç¨ä½åä¸ªé¢åçä»£çãä»£ççå³é®ç»æé¨åæ¯è®°å¿ï¼å®å­å¨éè¦ä¿¡æ¯ï¼ä½å®¹æåå°è¶ç±æ»å»ãç°æç ç©¶ä¸»è¦éä¸­å¨åä¸ä»£çæ»å»åå±äº«åå­æ»å»ä¸ãç¶èï¼ç°å®ä¸çä¸­çåºæ¯éå¸¸æ¶åç¬ç«çåå­ãå¨æ¬æä¸­ï¼æä»¬æåºäº Troublemaker Makes Chaos in Honest Town (TMCHT) ä»»å¡ï¼è¿æ¯ä¸ä¸ªå¤§è§æ¨¡ãå¤ä»£çãå¤ææåºäºææ¬çæ»å»è¯ä¼°æ¡æ¶ãTMCHT æ¶åä¸ä¸ªæ»å»èä»£çè¯å¾è¯¯å¯¼æ´ä¸ªä»£çç¤¾ä¼ãæä»¬ç¡®å®äºå¤ä»£çæ»å»ä¸­çä¸¤ä¸ªä¸»è¦ææï¼(1) éå®æ´å¾ç»æï¼(2) å¤§è§æ¨¡ç³»ç»ãæä»¬å°è¿äºææå½å äºæä»¬ç§°ä¹ä¸ºæ¯æ§æ¶å¤±çç°è±¡ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬æåºäºä¸ç§å¯¹ææ§å¤å¶ä¼ ææ§è¶ç± (ARCJ) æ¹æ³ï¼è¯¥æ¹æ³ä¼åäºæ£ç´¢åç¼ä»¥ä½¿ä¸­æ¯æ ·æ¬æ´å®¹æè¢«æ£ç´¢ï¼å¹¶ä¼åäºå¤å¶åç¼ä»¥ä½¿ä¸­æ¯æ ·æ¬å·æä¼ ææ§ãæä»¬å¨ TMCHT ä¸­å±ç¤ºäºæä»¬æ¹æ³çä¼è¶æ§ï¼å¨ç´çº¿ææãæå½¢ææå 100 ä»£çè®¾ç½®ä¸­åå«æé«äº 23.51%ã18.95% å 52.93%ãé¼å±ç¤¾åºå³æ³¨å¤ä»£çç³»ç»çå®å¨æ§ã

##### **CausalGraph2LLM: Evaluating LLMs for Causal Queries**
2410.15939v1 by Ivaxi Sheth, Bahare Fatemi, Mario Fritz

Causality is essential in scientific research, enabling researchers to
interpret true relationships between variables. These causal relationships are
often represented by causal graphs, which are directed acyclic graphs. With the
recent advancements in Large Language Models (LLMs), there is an increasing
interest in exploring their capabilities in causal reasoning and their
potential use to hypothesize causal graphs. These tasks necessitate the LLMs to
encode the causal graph effectively for subsequent downstream tasks. In this
paper, we propose a comprehensive benchmark, \emph{CausalGraph2LLM},
encompassing a variety of causal graph settings to assess the causal graph
understanding capability of LLMs. We categorize the causal queries into two
types: graph-level and node-level queries. We benchmark both open-sourced and
closed models for our study. Our findings reveal that while LLMs show promise
in this domain, they are highly sensitive to the encoding used. Even capable
models like GPT-4 and Gemini-1.5 exhibit sensitivity to encoding, with
deviations of about $60\%$. We further demonstrate this sensitivity for
downstream causal intervention tasks. Moreover, we observe that LLMs can often
display biases when presented with contextual information about a causal graph,
potentially stemming from their parametric memory.

æè¦ï¼å æå³ç³»å¨ç§å­¦ç ç©¶ä¸­è³å³éè¦ï¼å®ä½¿ç ç©¶äººåè½å¤è§£éåéä¹é´ççå®å³ç³»ãè¿äºå æå³ç³»éå¸¸ç¨å æå¾è¡¨ç¤ºï¼å æå¾æ¯æåæ ç¯å¾ãéçå¤§è¯­è¨æ¨¡å (LLM) çææ°è¿å±ï¼äººä»¬è¶æ¥è¶æå´è¶£æ¢ç´¢å®ä»¬å¨å ææ¨çä¸­çè½åä»¥åå®ä»¬å¨åè®¾å æå¾ä¸­çæ½å¨ç¨éãè¿äºä»»å¡éè¦ LLM ææå°å¯¹å æå¾è¿è¡ç¼ç ï¼ä»¥ä¾¿åç»­çä¸æ¸¸ä»»å¡ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ä¸ªç»¼ååºåï¼\emph{CausalGraph2LLM}ï¼å®åå«äºåç§å æå¾è®¾ç½®ï¼ä»¥è¯ä¼° LLM çå æå¾çè§£è½åãæä»¬å°å ææ¥è¯¢åä¸ºä¸¤ç±»ï¼å¾çº§æ¥è¯¢åèç¹çº§æ¥è¯¢ãæä»¬å¯¹å¼æºæ¨¡ååå°é­æ¨¡åè¿è¡äºåºåæµè¯ãæä»¬çç ç©¶ç»æè¡¨æï¼è½ç¶ LLM å¨è¯¥é¢åæ¾ç¤ºåºåæ¯ï¼ä½å®ä»¬å¯¹æä½¿ç¨çç¼ç éå¸¸ææãå³ä½¿å GPT-4 å Gemini-1.5 è¿æ ·çå¼ºå¤§æ¨¡åä¹å¯¹ç¼ç è¡¨ç°åºæææ§ï¼åå·®çº¦ä¸º 60%ãæä»¬è¿ä¸æ­¥è¯æäºè¿ç§å¯¹ä¸æ¸¸å æå¹²é¢ä»»å¡çæææ§ãæ­¤å¤ï¼æä»¬è§å¯å°ï¼å½ LLM è·å¾æå³å æå¾çä¸ä¸æä¿¡æ¯æ¶ï¼å®ä»¬éå¸¸ä¼è¡¨ç°åºåè§ï¼è¿å¯è½æºäºå®ä»¬çåæ°è®°å¿ã

##### **LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation**
2410.15828v1 by Tejumade Afonja, Ivaxi Sheth, Ruta Binkyte, Waqar Hanif, Thomas Ulas, Matthias Becker, Mario Fritz

Gene regulatory networks (GRNs) represent the causal relationships between
transcription factors (TFs) and target genes in single-cell RNA sequencing
(scRNA-seq) data. Understanding these networks is crucial for uncovering
disease mechanisms and identifying therapeutic targets. In this work, we
investigate the potential of large language models (LLMs) for GRN discovery,
leveraging their learned biological knowledge alone or in combination with
traditional statistical methods. We develop a task-based evaluation strategy to
address the challenge of unavailable ground truth causal graphs. Specifically,
we use the GRNs suggested by LLMs to guide causal synthetic data generation and
compare the resulting data against the original dataset. Our statistical and
biological assessments show that LLMs can support statistical modeling and data
synthesis for biological research.

æè¦ï¼åºå èª¿æ§ç¶²è·¯ (GRN) ä»£è¡¨å®ç´°è RNA å®åº (scRNA-seq) è³æä¸­è½éå å­ (TF) èç®æ¨åºå ä¹éçå æéä¿ãäºè§£éäºç¶²è·¯å°æ¼æ­é²ç¾çæ©å¶åæ¾åºæ²»çç®æ¨è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) å¨ GRN æ¢ç´¢ä¸­çæ½åï¼å©ç¨å®åå­¸ç¿å°ççç©ç¥è­ï¼å®ç¨æèå³çµ±çµ±è¨æ¹æ³çµåä½¿ç¨ãæåå¶å®äºä¸é åºæ¼ä»»åçè©ä¼°ç­ç¥ï¼ä»¥è§£æ±ºç¡æ³åå¾å°é¢çç¸å æåè¡¨çææ°ãå·é«ä¾èªªï¼æåä½¿ç¨ LLM å»ºè­°ç GRN ä¾å¼å°å æåæè³æç¢çï¼ä¸¦å°ç¢ççè³æèåå§è³æéé²è¡æ¯è¼ãæåççµ±è¨åçç©è©ä¼°é¡¯ç¤ºï¼LLM å¯ä»¥æ¯æ´çç©ç ç©¶ççµ±è¨å»ºæ¨¡åè³æåæã

##### **NetSafe: Exploring the Topological Safety of Multi-agent Networks**
2410.15686v1 by Miao Yu, Shilong Wang, Guibin Zhang, Junyuan Mao, Chenlong Yin, Qijiong Liu, Qingsong Wen, Kun Wang, Yang Wang

Large language models (LLMs) have empowered nodes within multi-agent networks
with intelligence, showing growing applications in both academia and industry.
However, how to prevent these networks from generating malicious information
remains unexplored with previous research on single LLM's safety be challenging
to transfer. In this paper, we focus on the safety of multi-agent networks from
a topological perspective, investigating which topological properties
contribute to safer networks. To this end, we propose a general framework,
NetSafe along with an iterative RelCom interaction to unify existing diverse
LLM-based agent frameworks, laying the foundation for generalized topological
safety research. We identify several critical phenomena when multi-agent
networks are exposed to attacks involving misinformation, bias, and harmful
information, termed as Agent Hallucination and Aggregation Safety. Furthermore,
we find that highly connected networks are more susceptible to the spread of
adversarial attacks, with task performance in a Star Graph Topology decreasing
by 29.7%. Besides, our proposed static metrics aligned more closely with
real-world dynamic evaluations than traditional graph-theoretic metrics,
indicating that networks with greater average distances from attackers exhibit
enhanced safety. In conclusion, our work introduces a new topological
perspective on the safety of LLM-based multi-agent networks and discovers
several unreported phenomena, paving the way for future research to explore the
safety of such networks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è³¦äºäºå¤ä¸»é«ç¶²è·¯ä¸­çç¯é»æºæ§ï¼å¨å­¸è¡çåç¢æ¥­ä¸­å±ç¾åºè¶ä¾è¶å¤çæç¨ãç¶èï¼å¦ä½é²æ­¢éäºç¶²è·¯ç¢çæ¡æè³è¨ä»ç¶æ¯æªç¶æ¢ç´¢çé åï¼ååéå°å®ä¸ LLM å®å¨æ§çç ç©¶é£ä»¥è½ç§»ãå¨æ¬æä¸­ï¼æåå¾ææ²å­¸çè§åº¦æ¢è¨å¤ä¸»é«ç¶²è·¯çå®å¨æ§ï¼ç ç©¶åªäºææ²å±¬æ§æå©æ¼ç¶²è·¯æ´å®å¨ãçºæ­¤ï¼æåæåºäºä¸åéç¨æ¡æ¶ NetSafeï¼ä»¥åä¸ååè¦ç RelCom äºåï¼ä»¥çµ±ä¸ç¾æçåç¨®åºæ¼ LLM çä¸»é«æ¡æ¶ï¼çºå»£ç¾©çææ²å®å¨æ§ç ç©¶å¥ å®åºç¤ãæåå¨å¤ä¸»é«ç¶²è·¯é­åæ¶åé¯èª¤è³è¨ãåè¦åæå®³è³è¨çæ»ææï¼æ¾åºå¹¾åééµç¾è±¡ï¼ç¨±çºä¸»é«å¹»è¦ºåèåå®å¨æ§ãæ­¤å¤ï¼æåç¼ç¾é«åº¦é£æ¥çç¶²è·¯æ´å®¹æåå°å°ææ§æ»æçå½±é¿ï¼æå½¢åå½¢ææ²ä¸­çä»»åæè½ä¸éäº 29.7%ãæ­¤å¤ï¼æåæåºçéæææ¨æ¯å³çµ±çåè«ææ¨æ´è²¼è¿çå¯¦ä¸ççåæè©ä¼°ï¼éè¡¨ç¤ºèæ»æèå¹³åè·é¢è¼å¤§çç¶²è·¯å·ææ´é«çå®å¨æ§ãç¸½ä¹ï¼æåçç ç©¶å¼å¥äºåºæ¼ LLM çå¤ä¸»é«ç¶²è·¯å®å¨æ§çæ°ææ²è§é»ï¼ä¸¦ç¼ç¾äºå¹¾åæªæ¾å ±å°çç¾è±¡ï¼çºæªä¾æ¢ç´¢æ­¤é¡ç¶²è·¯å®å¨æ§çç ç©¶éªè·¯ã

##### **TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models**
2410.15268v1 by Bo Pan, Zhen Xiong, Guanchen Wu, Zheng Zhang, Yifei Zhang, Liang Zhao

Representation learning of Text-Attributed Graphs (TAGs) has garnered
significant attention due to its applications in various domains, including
recommendation systems and social networks. Despite advancements in TAG
learning methodologies, challenges remain in explainability due to the
black-box nature of existing TAG representation learning models. This paper
presents TAGExplainer, the first method designed to generate natural language
explanations for TAG learning. TAGExplainer employs a generative language model
that maps input-output pairs to explanations reflecting the model's
decision-making process. To address the lack of annotated ground truth
explanations in real-world scenarios, we propose first generating pseudo-labels
that capture the model's decisions from saliency-based explanations, then the
pseudo-label generator is iteratively trained based on three training
objectives focusing on faithfulness and brevity via Expert Iteration, to
improve the quality of generated pseudo-labels. The high-quality pseudo-labels
are finally utilized to train an end-to-end explanation generator model.
Extensive experiments are conducted to demonstrate the effectiveness of
TAGExplainer in producing faithful and concise natural language explanations.

æè¦ï¼ææ¬æ­¸å å (TAG) çè¡¨ç¤ºå­¸ç¿å å¶å¨åç¨®é åï¼åæ¬æ¨è¦ç³»çµ±åç¤¾äº¤ç¶²çµ¡ï¼ä¸­çæç¨èååéæ³¨ãåç®¡ TAG å­¸ç¿æ¹æ³åå¾äºé²å±ï¼ä½ç±æ¼ç¾æ TAG è¡¨ç¤ºå­¸ç¿æ¨¡åçé»ç®±æ§è³ªï¼å¯è§£éæ§ä»ç¶é¢è¨ææ°ãæ¬ææåºäº TAGExplainerï¼éæ¯ä¸ç¨®æ¨å¨çº TAG å­¸ç¿çæèªç¶èªè¨è§£éçç¬¬ä¸ç¨®æ¹æ³ãTAGExplainer æ¡ç¨çæèªè¨æ¨¡åï¼å°è¼¸å¥è¼¸åºå°æå°åæ æ¨¡åæ±ºç­éç¨çè§£éãçºäºè§£æ±ºç¾å¯¦å ´æ¯ä¸­ç¼ºä¹è¨»è§£å°é¢çå¯¦è§£éçåé¡ï¼æåå»ºè­°é¦åå¾åºæ¼é¡¯èæ§çè§£éä¸­çæå½æ¨ç±¤ä¾æææ¨¡åçæ±ºç­ï¼ç¶å¾ééå°å®¶è¿­ä»£åºæ¼ä¸åè¨ç·´ç®æ¨ï¼å´éæ¼å¿ å¯¦åº¦åç°¡æ½æ§ï¼åè¦è¨ç·´å½æ¨ç±¤çæå¨ï¼ä»¥æé«çæå½æ¨ç±¤çåè³ªãæå¾å°é«åè³ªçå½æ¨ç±¤ç¨æ¼è¨ç·´ç«¯å°ç«¯è§£éçæå¨æ¨¡åãé²è¡äºå»£æ³çå¯¦é©ï¼ä»¥è­æ TAGExplainer å¨çæå¿ å¯¦ä¸ç°¡æ½çèªç¶èªè¨è§£éæ¹é¢çæææ§ã

##### **Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction**
2410.15165v1 by Yinhan He, Zaiyi Zheng, Patrick Soga, Yaozhen Zhu, yushun Dong, Jundong Li

In recent years, Graph Neural Networks (GNNs) have become successful in
molecular property prediction tasks such as toxicity analysis. However, due to
the black-box nature of GNNs, their outputs can be concerning in high-stakes
decision-making scenarios, e.g., drug discovery. Facing such an issue, Graph
Counterfactual Explanation (GCE) has emerged as a promising approach to improve
GNN transparency. However, current GCE methods usually fail to take
domain-specific knowledge into consideration, which can result in outputs that
are not easily comprehensible by humans. To address this challenge, we propose
a novel GCE method, LLM-GCE, to unleash the power of large language models
(LLMs) in explaining GNNs for molecular property prediction. Specifically, we
utilize an autoencoder to generate the counterfactual graph topology from a set
of counterfactual text pairs (CTPs) based on an input graph. Meanwhile, we also
incorporate a CTP dynamic feedback module to mitigate LLM hallucination, which
provides intermediate feedback derived from the generated counterfactuals as an
attempt to give more faithful guidance. Extensive experiments demonstrate the
superior performance of LLM-GCE. Our code is released on
https://github.com/YinhanHe123/new\_LLM4GNNExplanation.

æè¦ï¼è¿å¹´æ¥ï¼å¾ç¥ç»ç½ç» (GNN) å·²æååºç¨äºåå­æ§è´¨é¢æµä»»å¡ï¼ä¾å¦æ¯æ§åæãç¶èï¼ç±äº GNN çé»çæ§è´¨ï¼å¶è¾åºå¨é«é£é©å³ç­åºæ¯ä¸­å¯è½ä¼ä»¤äººæå¿§ï¼ä¾å¦è¯ç©åç°ãéå¯¹è¿ä¸é®é¢ï¼å¾åäºå®è§£é (GCE) å·²æä¸ºæé« GNN éæåº¦çä¸ç§å¾æåæ¯çæ¹æ³ãç¶èï¼å½åç GCE æ¹æ³éå¸¸æ æ³èèç¹å®é¢åçç¥è¯ï¼è¿å¯è½å¯¼è´äººç±»é¾ä»¥çè§£è¾åºãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäºä¸ç§æ°é¢ç GCE æ¹æ³ï¼LLM-GCEï¼ä»¥éæ¾å¤§åè¯­è¨æ¨¡å (LLM) å¨è§£é GNN ç¨äºåå­æ§è´¨é¢æµæ¹é¢çè½åãå·ä½æ¥è¯´ï¼æä»¬å©ç¨èªå¨ç¼ç å¨ä»ä¸ç»åºäºè¾å¥å¾çåäºå®ææ¬å¯¹ (CTP) çæåäºå®å¾ææãåæ¶ï¼æä»¬è¿å å¥äºä¸ä¸ª CTP å¨æåé¦æ¨¡åæ¥åè½» LLM å¹»è§ï¼è¯¥æ¨¡åæä¾ä»çæçåäºå®ä¸­æ´¾ççä¸­é´åé¦ï¼ä»¥å°è¯æä¾æ´çå®çæå¯¼ãå¤§éçå®éªè¡¨æäº LLM-GCE çåè¶æ§è½ãæä»¬çä»£ç å·²åå¸å¨ https://github.com/YinhanHe123/new\_LLM4GNNExplanationã

##### **MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science**
2410.15126v1 by Junho Kim, Yeachan Kim, Jun-Hyung Park, Yerim Oh, Suho Kim, SangKeun Lee

We introduce a novel continued pre-training method, MELT (MatEriaLs-aware
continued pre-Training), specifically designed to efficiently adapt the
pre-trained language models (PLMs) for materials science. Unlike previous
adaptation strategies that solely focus on constructing domain-specific corpus,
MELT comprehensively considers both the corpus and the training strategy, given
that materials science corpus has distinct characteristics from other domains.
To this end, we first construct a comprehensive materials knowledge base from
the scientific corpus by building semantic graphs. Leveraging this extracted
knowledge, we integrate a curriculum into the adaptation process that begins
with familiar and generalized concepts and progressively moves toward more
specialized terms. We conduct extensive experiments across diverse benchmarks
to verify the effectiveness and generality of MELT. A comprehensive evaluation
convincingly supports the strength of MELT, demonstrating superior performance
compared to existing continued pre-training methods. The in-depth analysis also
shows that MELT enables PLMs to effectively represent materials entities
compared to the existing adaptation methods, thereby highlighting its broad
applicability across a wide spectrum of materials science.

æè¦ï¼æåä»ç´¹äºä¸ç¨®æ°ç©çæçºé è¨ç·´æ¹æ³ï¼MELTï¼MatEriaLs-awareæçºé è¨ç·´ï¼ï¼å°éè¨­è¨ç¨æ¼ææå°èª¿æ´ææç§å­¸çé è¨ç·´èªè¨æ¨¡å (PLM)ãèåååå°æ³¨æ¼å»ºæ§ç¹å®é åèªæåº«çèª¿æ´ç­ç¥ä¸åï¼MELT å¨é¢èæ®èªæåº«åè¨ç·´ç­ç¥ï¼å çºææç§å­¸èªæåº«å·æä¸åæ¼å¶ä»é åçç¹å¾µãçºæ­¤ï¼æåé¦åééå»ºç«èªç¾©åå¾ç§å­¸èªæåº«æ§å»ºä¸åå¨é¢çææç¥è­åº«ãå©ç¨æåçç¥è­ï¼æåå°èª²ç¨æ´åå°èª¿æ´éç¨ä¸­ï¼å¾çæä¸éç¨çæ¦å¿µéå§ï¼éæ¼¸è½åæ´å°æ¥­çè¡èªãæåå¨ä¸åçåºæºä¸é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥é©è­ MELT çæææ§åæ®éæ§ãå¨é¢çè©ä¼°ä»¤äººä¿¡æå°æ¯æäº MELT çåªé»ï¼èç¾æçæçºé è¨ç·´æ¹æ³ç¸æ¯ï¼è¡¨ç¾åºåªç°çæ§è½ãæ·±å¥åæéè¡¨æï¼èç¾æçèª¿æ´æ¹æ³ç¸æ¯ï¼MELT è½è® PLM ææå°è¡¨ç¤ºææå¯¦é«ï¼å¾èçªé¡¯å¶å¨å»£æ³çææç§å­¸é åä¸­çå»£æ³é©ç¨æ§ã


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-15**|**Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization**|Fatahlla Moreh et.al.|[2411.10389v1](http://arxiv.org/abs/2411.10389v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-15**|**Evaluating the role of `Constitutions' for learning from AI feedback**|Saskia Redgate et.al.|[2411.10168v1](http://arxiv.org/abs/2411.10168v1)|null|
|**2024-11-15**|**PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse**|Einari Vaaras et.al.|[2411.10087v1](http://arxiv.org/abs/2411.10087v1)|null|
|**2024-11-15**|**Rethinking Normalization Strategies and Convolutional Kernels for Multimodal Image Fusion**|Dan He et.al.|[2411.10036v1](http://arxiv.org/abs/2411.10036v1)|null|
|**2024-11-15**|**JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging**|Kaito Baba et.al.|[2411.09933v1](http://arxiv.org/abs/2411.09933v1)|null|
|**2024-11-15**|**A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation**|Chin-Sung Tung et.al.|[2411.09874v1](http://arxiv.org/abs/2411.09874v1)|[link](https://github.com/tcs211/ai_eeeg_report)|
|**2024-11-14**|**A Benchmark for Long-Form Medical Question Answering**|Pedram Hosseini et.al.|[2411.09834v1](http://arxiv.org/abs/2411.09834v1)|[link](https://github.com/lavita-ai/medical-eval-sphere)|
|**2024-11-14**|**A Self-Supervised Model for Multi-modal Stroke Risk Prediction**|Camille Delgrange et.al.|[2411.09822v1](http://arxiv.org/abs/2411.09822v1)|null|
|**2024-11-14**|**Deep Learning for Fetal Inflammatory Response Diagnosis in the Umbilical Cord**|Marina A. Ayad et.al.|[2411.09767v1](http://arxiv.org/abs/2411.09767v1)|null|
|**2024-11-14**|**Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable Medical Information**|Ahan Bhatt et.al.|[2411.09648v1](http://arxiv.org/abs/2411.09648v1)|null|
|**2024-11-14**|**An Explainable Attention Model for Cervical Precancer Risk Classification using Colposcopic Images**|Smith K. Khare et.al.|[2411.09469v1](http://arxiv.org/abs/2411.09469v1)|null|
|**2024-11-14**|**Script-centric behavior understanding for assisted autism spectrum disorder diagnosis**|Wenxing Liu et.al.|[2411.09413v1](http://arxiv.org/abs/2411.09413v1)|null|
|**2024-11-14**|**NFRs in Medical Imaging**|Amanda Vallentin et.al.|[2411.09718v1](http://arxiv.org/abs/2411.09718v1)|null|
|**2024-11-14**|**Comprehensive and Practical Evaluation of Retrieval-Augmented Generation Systems for Medical Question Answering**|Nghia Trung Ngo et.al.|[2411.09213v1](http://arxiv.org/abs/2411.09213v1)|null|
|**2024-11-14**|**Advancing Diffusion Models: Alias-Free Resampling and Enhanced Rotational Equivariance**|Md Fahim Anjum et.al.|[2411.09174v1](http://arxiv.org/abs/2411.09174v1)|null|
|**2024-11-13**|**The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models**|Daniel P. Jeong et.al.|[2411.08870v1](http://arxiv.org/abs/2411.08870v1)|null|
|**2024-11-13**|**MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics Classification**|Shan Cong et.al.|[2411.08703v1](http://arxiv.org/abs/2411.08703v1)|null|
|**2024-11-13**|**TRACE: Transformer-based Risk Assessment for Clinical Evaluation**|Dionysis Christopoulos et.al.|[2411.08701v1](http://arxiv.org/abs/2411.08701v1)|null|
|**2024-11-13**|**Rethinking negative sampling in content-based news recommendation**|Miguel Ãngelo Rebelo et.al.|[2411.08700v1](http://arxiv.org/abs/2411.08700v1)|null|
|**2024-11-13**|**A Survey on Vision Autoregressive Model**|Kai Jiang et.al.|[2411.08666v1](http://arxiv.org/abs/2411.08666v1)|null|
|**2024-11-13**|**Optimizing Automatic Summarization of Long Clinical Records Using Dynamic Context Extension:Testing and Evaluation of the NBCE Method**|Guoqing Zhang et.al.|[2411.08586v2](http://arxiv.org/abs/2411.08586v2)|null|
|**2024-11-13**|**A Heterogeneous Graph Neural Network Fusing Functional and Structural Connectivity for MCI Diagnosis**|Feiyu Yin et.al.|[2411.08424v1](http://arxiv.org/abs/2411.08424v1)|null|
|**2024-11-13**|**A Fuzzy Reinforcement LSTM-based Long-term Prediction Model for Fault Conditions in Nuclear Power Plants**|Siwei Li et.al.|[2411.08370v1](http://arxiv.org/abs/2411.08370v1)|null|
|**2024-11-13**|**TowerDebias: A Novel Debiasing Method based on the Tower Property**|Norman Matloff et.al.|[2411.08297v1](http://arxiv.org/abs/2411.08297v1)|null|
|**2024-11-12**|**Scaling Properties of Diffusion Models for Perceptual Tasks**|Rahul Ravishankar et.al.|[2411.08034v2](http://arxiv.org/abs/2411.08034v2)|null|
|**2024-11-12**|**Investigating the Effectiveness of Explainability Methods in Parkinson's Detection from Speech**|Eleonora Mancini et.al.|[2411.08013v2](http://arxiv.org/abs/2411.08013v2)|null|
|**2024-11-12**|**DuoLift-GAN:Reconstructing CT from Single-view and Biplanar X-Rays with Generative Adversarial Networks**|Zhaoxi Zhang et.al.|[2411.07941v1](http://arxiv.org/abs/2411.07941v1)|null|
|**2024-11-12**|**Automatic dataset shift identification to support root cause analysis of AI performance drift**|MÃ©lanie Roschewitz et.al.|[2411.07940v2](http://arxiv.org/abs/2411.07940v2)|[link](https://github.com/biomedia-mira/shift_identification)|
|**2024-11-12**|**INTRABENCH: Interactive Radiological Benchmark**|Constantin Ulrich et.al.|[2411.07885v1](http://arxiv.org/abs/2411.07885v1)|null|
|**2024-11-12**|**Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in Alzheimer's Disease**|Francesco Chiumento et.al.|[2411.07871v1](http://arxiv.org/abs/2411.07871v1)|null|
|**2024-11-12**|**PatchCTG: Patch Cardiotocography Transformer for Antepartum Fetal Health Monitoring**|M. Jaleed Khan et.al.|[2411.07796v1](http://arxiv.org/abs/2411.07796v1)|null|
|**2024-11-12**|**Multimodal Clinical Reasoning through Knowledge-augmented Rationale Generation**|Shuai Niu et.al.|[2411.07611v1](http://arxiv.org/abs/2411.07611v1)|null|
|**2024-11-12**|**Contrastive Language Prompting to Ease False Positives in Medical Anomaly Detection**|YeongHyeon Park et.al.|[2411.07546v1](http://arxiv.org/abs/2411.07546v1)|null|
|**2024-11-11**|**Beyond Keywords: A Context-based Hybrid Approach to Mining Ethical Concern-related App Reviews**|Aakash Sorathiya et.al.|[2411.07398v1](http://arxiv.org/abs/2411.07398v1)|null|
|**2024-11-11**|**Data-Centric Learning Framework for Real-Time Detection of Aiming Beam in Fluorescence Lifetime Imaging Guided Surgery**|Mohamed Abul Hassan et.al.|[2411.07395v1](http://arxiv.org/abs/2411.07395v1)|null|
|**2024-11-11**|**Data-Driven Analysis of AI in Medical Device Software in China: Deep Learning and General AI Trends Based on Regulatory Data**|Yu Han et.al.|[2411.07378v1](http://arxiv.org/abs/2411.07378v1)|null|
|**2024-11-11**|**A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**|Vedant Khandelwal et.al.|[2411.07163v1](http://arxiv.org/abs/2411.07163v1)|null|
|**2024-11-11**|**Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models**|Chanseo Lee et.al.|[2411.06713v1](http://arxiv.org/abs/2411.06713v1)|null|
|**2024-11-10**|**In-Context Learning for Preserving Patient Privacy: A Framework for Synthesizing Realistic Patient Portal Messages**|Joseph Gatto et.al.|[2411.06549v1](http://arxiv.org/abs/2411.06549v1)|[link](https://github.com/persist-lab/syntheticportalgen)|
|**2024-11-09**|**NeuReg: Domain-invariant 3D Image Registration on Human and Mouse Brains**|Taha Razzaq et.al.|[2411.06315v1](http://arxiv.org/abs/2411.06315v1)|null|
|**2024-11-09**|**GuidelineGuard: An Agentic Framework for Medical Note Evaluation with Guideline Adherence**|MD Ragib Shahriyear et.al.|[2411.06264v1](http://arxiv.org/abs/2411.06264v1)|null|
|**2024-11-09**|**Deep Reinforcement Learning for Digital Twin-Oriented Complex Networked Systems**|Jiaqi Wen et.al.|[2411.06148v1](http://arxiv.org/abs/2411.06148v1)|null|
|**2024-11-09**|**Evaluating the Propensity of Generative AI for Producing Disinformation During an Election Cycle**|Erik J Schlicht et.al.|[2411.06120v1](http://arxiv.org/abs/2411.06120v1)|null|
|**2024-11-09**|**Personalize to generalize: Towards a universal medical multi-modality generalization through personalization**|Zhaorui Tan et.al.|[2411.06106v2](http://arxiv.org/abs/2411.06106v2)|null|
|**2024-11-08**|**Assessing Foundational Medical 'Segment Anything' (Med-SAM1, Med-SAM2) Deep Learning Models for Left Atrial Segmentation in 3D LGE MRI**|Mehri Mehrnia et.al.|[2411.05963v1](http://arxiv.org/abs/2411.05963v1)|null|
|**2024-11-08**|**GazeSearch: Radiology Findings Search Benchmark**|Trong Thang Pham et.al.|[2411.05780v1](http://arxiv.org/abs/2411.05780v1)|null|
|**2024-11-08**|**Humans Continue to Outperform Large Language Models in Complex Clinical Decision-Making: A Study with Medical Calculators**|Nicholas Wan et.al.|[2411.05897v1](http://arxiv.org/abs/2411.05897v1)|null|
|**2024-11-08**|**Identifying and Decomposing Compound Ingredients in Meal Plans Using Large Language Models**|Leon Kopitar et.al.|[2411.05892v1](http://arxiv.org/abs/2411.05892v1)|null|
|**2024-11-08**|**SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**|Sithursan Sivasubramaniam et.al.|[2411.05521v2](http://arxiv.org/abs/2411.05521v2)|[link](https://github.com/jf87/sm3-text-to-query)|
|**2024-11-08**|**Towards Scalable Foundation Models for Digital Dermatology**|Fabian GrÃ¶ger et.al.|[2411.05514v1](http://arxiv.org/abs/2411.05514v1)|[link](https://github.com/digital-dermatology/self-supervised-dermatology)|
|**2024-11-08**|**Towards Equitable ASD Diagnostics: A Comparative Study of Machine and Deep Learning Models Using Behavioral and Facial Data**|Mohammed Aledhari et.al.|[2411.05880v1](http://arxiv.org/abs/2411.05880v1)|null|
|**2024-11-07**|**Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations**|Joey Hong et.al.|[2411.05194v1](http://arxiv.org/abs/2411.05194v1)|null|
|**2024-11-07**|**Inverse Transition Learning: Learning Dynamics from Demonstrations**|Leo Benac et.al.|[2411.05174v1](http://arxiv.org/abs/2411.05174v1)|null|
|**2024-11-07**|**PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation**|Daniel C. Castro et.al.|[2411.05085v1](http://arxiv.org/abs/2411.05085v1)|null|
|**2024-11-07**|**Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability**|Yanjun Gao et.al.|[2411.04962v1](http://arxiv.org/abs/2411.04962v1)|null|
|**2024-11-07**|**FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge into LLMs?**|Eric Wu et.al.|[2411.05059v2](http://arxiv.org/abs/2411.05059v2)|[link](https://github.com/kevinwu23/stanfordfinetunebench)|
|**2024-11-07**|**Integrating Large Language Models for Genetic Variant Classification**|Youssef Boulaimen et.al.|[2411.05055v1](http://arxiv.org/abs/2411.05055v1)|null|
|**2024-11-07**|**AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data**|Tianyi Zhang et.al.|[2411.04691v1](http://arxiv.org/abs/2411.04691v1)|null|
|**2024-11-07**|**FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation**|Liangrui Pan et.al.|[2411.04509v1](http://arxiv.org/abs/2411.04509v1)|null|
|**2024-11-07**|**Conditional Diffusion Model for Longitudinal Medical Image Generation**|Duy-Phuong Dao et.al.|[2411.05860v1](http://arxiv.org/abs/2411.05860v1)|null|
|**2024-11-07**|**Evaluating the Economic Implications of Using Machine Learning in Clinical Psychiatry**|Soaad Hossain et.al.|[2411.05856v1](http://arxiv.org/abs/2411.05856v1)|null|
|**2024-11-06**|**Robust Real-Time Mortality Prediction in the Intensive Care Unit using Temporal Difference Learning**|Thomas Frost et.al.|[2411.04285v1](http://arxiv.org/abs/2411.04285v1)|[link](https://github.com/tdgfrost/td-icu-mortality)|
|**2024-11-06**|**Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?**|Daniel P. Jeong et.al.|[2411.04118v1](http://arxiv.org/abs/2411.04118v1)|null|
|**2024-11-06**|**RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models**|Maya Varma et.al.|[2411.04097v1](http://arxiv.org/abs/2411.04097v1)|[link](https://github.com/stanford-aimi/ravl)|
|**2024-11-06**|**Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability**|Bharat Chandra Yalavarthi et.al.|[2411.04008v1](http://arxiv.org/abs/2411.04008v1)|null|
|**2024-11-06**|**Fine-tuning -- a Transfer Learning approach**|Joseph Arul Raj et.al.|[2411.03941v1](http://arxiv.org/abs/2411.03941v1)|null|
|**2024-11-06**|**MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**|Laura Cabello et.al.|[2411.03883v2](http://arxiv.org/abs/2411.03883v2)|[link](https://github.com/lautel/meg)|
|**2024-11-06**|**Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications**|Daan Schouten et.al.|[2411.03782v1](http://arxiv.org/abs/2411.03782v1)|null|
|**2024-11-06**|**Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction**|Yu Guan et.al.|[2411.03758v1](http://arxiv.org/abs/2411.03758v1)|null|
|**2024-11-06**|**Ultrasound-Based AI for COVID-19 Detection: A Comprehensive Review of Public and Private Lung Ultrasound Datasets and Studies**|Abrar Morshed et.al.|[2411.05029v1](http://arxiv.org/abs/2411.05029v1)|null|
|**2024-11-06**|**Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation?**|Pedro R. A. S. Bassi et.al.|[2411.03670v1](http://arxiv.org/abs/2411.03670v1)|[link](https://github.com/mrgiovanni/touchstone)|
|**2024-11-06**|**Requirements Engineering for Older Adult Digital Health Software: A Systematic Literature Review**|Yuqing Xiao et.al.|[2411.03656v1](http://arxiv.org/abs/2411.03656v1)|null|
|**2024-11-06**|**Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification**|Dahyun Mok et.al.|[2411.03618v1](http://arxiv.org/abs/2411.03618v1)|null|
|**2024-11-05**|**The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare**|Souren Pashangpour et.al.|[2411.03287v1](http://arxiv.org/abs/2411.03287v1)|null|
|**2024-11-05**|**Discovering Data Structures: Nearest Neighbor Search and Beyond**|Omar Salemohamed et.al.|[2411.03253v1](http://arxiv.org/abs/2411.03253v1)|null|
|**2024-11-05**|**Evaluating Machine Learning Models against Clinical Protocols for Enhanced Interpretability and Continuity of Care**|Christel Sirocchi et.al.|[2411.03105v1](http://arxiv.org/abs/2411.03105v1)|[link](https://github.com/ChristelSirocchi/XAI-similarity)|
|**2024-11-05**|**Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation in a Limited Data Setting**|Adrian B. ChÅopowiec et.al.|[2411.03098v1](http://arxiv.org/abs/2411.03098v1)|null|
|**2024-11-05**|**Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status**|Samuel Lee et.al.|[2411.03004v1](http://arxiv.org/abs/2411.03004v1)|null|
|**2024-11-05**|**Region-Guided Attack on the Segment Anything Model (SAM)**|Xiaoliang Liu et.al.|[2411.02974v2](http://arxiv.org/abs/2411.02974v2)|null|
|**2024-11-05**|**[Vision Paper] PRObot: Enhancing Patient-Reported Outcome Measures for Diabetic Retinopathy using Chatbots and Generative AI**|Maren Pielka et.al.|[2411.02973v1](http://arxiv.org/abs/2411.02973v1)|null|
|**2024-11-05**|**Leveraging Transfer Learning and Multiple Instance Learning for HER2 Automatic Scoring of H\&E Whole Slide Images**|Rawan S. Abdulsadig et.al.|[2411.05028v1](http://arxiv.org/abs/2411.05028v1)|[link](https://github.com/rawansaifaldeen/her2-scoring_mil-attention-model)|
|**2024-11-05**|**Membership Inference Attacks against Large Vision-Language Models**|Zhan Li et.al.|[2411.02902v1](http://arxiv.org/abs/2411.02902v1)|[link](https://github.com/lions-epfl/vl-mia)|
|**2024-11-04**|**Advanced XR-Based 6-DOF Catheter Tracking System for Immersive Cardiac Intervention Training**|Mohsen Annabestani et.al.|[2411.02611v1](http://arxiv.org/abs/2411.02611v1)|null|
|**2024-11-04**|**"It's a conversation, not a quiz": A Risk Taxonomy and Reflection Tool for LLM Adoption in Public Health**|Jiawei Zhou et.al.|[2411.02594v1](http://arxiv.org/abs/2411.02594v1)|null|
|**2024-11-04**|**Digitizing Touch with an Artificial Multimodal Fingertip**|Mike Lambeta et.al.|[2411.02479v1](http://arxiv.org/abs/2411.02479v1)|[link](https://github.com/facebookresearch/digit360)|
|**2024-11-04**|**Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking**|Shahab Kavousinejad et.al.|[2411.02345v1](http://arxiv.org/abs/2411.02345v1)|[link](https://github.com/shahab-k93/cancer-and-smart-nanorobot)|
|**2024-11-04**|**Taking AI Welfare Seriously**|Robert Long et.al.|[2411.00986v1](http://arxiv.org/abs/2411.00986v1)|null|
|**2024-11-04**|**Federated GNNs for EEG-Based Stroke Assessment**|Andrea Protani et.al.|[2411.02286v1](http://arxiv.org/abs/2411.02286v1)|null|
|**2024-11-04**|**Weakly supervised deep learning model with size constraint for prostate cancer detection in multiparametric MRI and generalization to unseen domains**|Robin Trombetta et.al.|[2411.02466v1](http://arxiv.org/abs/2411.02466v1)|null|
|**2024-11-04**|**Evaluating the quality of published medical research with ChatGPT**|Mike Thelwall et.al.|[2411.01952v1](http://arxiv.org/abs/2411.01952v1)|null|
|**2024-11-04**|**You are out of context!**|Giancarlo Cobino et.al.|[2411.02464v1](http://arxiv.org/abs/2411.02464v1)|null|
|**2024-11-03**|**Diagnosing Medical Datasets with Training Dynamics**|Laura Wenderoth et.al.|[2411.01653v1](http://arxiv.org/abs/2411.01653v1)|[link](https://github.com/laurawenderoth/training-dynamics)|
|**2024-11-03**|**Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation**|Zhenbin Wang et.al.|[2411.01647v1](http://arxiv.org/abs/2411.01647v1)|null|
|**2024-11-03**|**Customized Subgraph Selection and Encoding for Drug-drug Interaction Prediction**|Haotong Du et.al.|[2411.01535v1](http://arxiv.org/abs/2411.01535v1)|null|
|**2024-11-03**|**Conditional Latent Space Molecular Scaffold Optimization for Accelerated Molecular Design**|Onur Boyar et.al.|[2411.01423v1](http://arxiv.org/abs/2411.01423v1)|null|
|**2024-11-02**|**Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive Histogram Equalization**|Sohrab Namazi Nia et.al.|[2411.01373v1](http://arxiv.org/abs/2411.01373v1)|null|
|**2024-11-02**|**Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles**|Tim Ruschke et.al.|[2411.01351v1](http://arxiv.org/abs/2411.01351v1)|null|
|**2024-11-02**|**Causal reasoning in difference graphs**|Charles K. Assaad et.al.|[2411.01292v1](http://arxiv.org/abs/2411.01292v1)|null|
|**2024-11-02**|**Designing a Robust Radiology Report Generation System**|Sonit Singh et.al.|[2411.01153v1](http://arxiv.org/abs/2411.01153v1)|null|

#### Abstracts
##### **Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization**
2411.10389v1 by Fatahlla Moreh, Yusuf Hasan, Bilal Zahid Hussain, Mohammad Ammar, Sven Tomforde

Internal crack detection has been a subject of focus in structural health
monitoring. By focusing on crack detection in structural datasets, it is
demonstrated that deep learning (DL) methods can effectively analyze seismic
wave fields interacting with micro-scale cracks, which are beyond the
resolution of conventional visual inspection. This work explores a novel
application of DL-based key point detection technique, where cracks are
localized by predicting the coordinates of four key points that define a
bounding region of the crack. The study not only opens new research directions
for non-visual applications but also effectively mitigates the impact of
imbalanced data which poses a challenge for previous DL models, as it can be
biased toward predicting the majority class (non-crack regions). Popular DL
techniques, such as the Inception blocks, are used and investigated. The model
shows an overall reduction in loss when applied to micro-scale crack detection
and is reflected in the lower average deviation between the location of actual
and predicted cracks, with an average Intersection over Union (IoU) being 0.511
for all micro cracks (greater than 0.00 micrometers) and 0.631 for larger micro
cracks (greater than 4 micrometers).

æè¦ï¼å§é¨è£ç¸«åµæ¸¬ä¸ç´æ¯çµæ§å¥åº·ç£æ¸¬çéé»ãééå°æ³¨æ¼çµæ§è³æéä¸­çè£ç¸«åµæ¸¬ï¼è­ææ·±åº¦å­¸ç¿ (DL) æ¹æ³å¯ä»¥ææåæèå¾®å°ºåº¦è£ç¸«äº¤äºä½ç¨çå°éæ³¢å ´ï¼éè¶åºäºå³çµ±ç®è¦æª¢æ¥çè§£æåº¦ãéé å·¥ä½æ¢ç´¢äºåºæ¼ DL çééµé»åµæ¸¬æè¡çä¸é æ°æç¨ï¼å¶ä¸­ééé æ¸¬å®ç¾©è£ç¸«éçååçååééµé»çåº§æ¨ä¾å®ä½è£ç¸«ãéé ç ç©¶ä¸åçºéè¦è¦ºæç¨éåäºæ°çç ç©¶æ¹åï¼éè½æææ¸è¼ä¸å¹³è¡¡è³æçå½±é¿ï¼èéå°ååç DL æ¨¡åæ§æææ°ï¼å çºå®å¯è½ååæ¼é æ¸¬å¤æ¸é¡å¥ï¼éè£ç¸«ååï¼ãä½¿ç¨ä¸¦ç ç©¶äºæµè¡ç DL æè¡ï¼ä¾å¦ Inception åå¡ãè©²æ¨¡åå¨æç¨æ¼å¾®å°ºåº¦è£ç¸«åµæ¸¬æé¡¯ç¤ºåºæ´é«æå¤±æ¸å°ï¼ä¸¦ä¸åæ å¨å¯¦éè£ç¸«åé æ¸¬è£ç¸«çä½ç½®ä¹éçè¼ä½å¹³ååå·®ä¸­ï¼ææå¾®è£ç¸«ï¼å¤§æ¼ 0.00 å¾®ç±³ï¼çå¹³åäº¤éæ¯è¯åï¼IoUï¼çº 0.511ï¼èè¼å¤§çå¾®è£ç¸«ï¼å¤§æ¼ 4 å¾®ç±³ï¼åçº 0.631ã

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

æè¦ï¼å°åå¿èç¾çåç¾åå¤©æ§ç¾çåå¾å¤©æ§ç¾ççå»£æ³åè­ãæ´è¤éçåå¤©æ§ç¸å½¢éè¦ååä¸å¤æ¨¡å¼çæ±ºç­éç¨ï¼éå¸¸åæ¬è¶é³æ³¢æª¢æ¥ä½çºä¸»è¦çå½±åæ¹æ³ãäººå·¥æºæ§ (AI) ééä¿é²å°åè¶é³æ³¢æª¢æ¥è³æçèªååè©®éï¼çºè¨åºé«çæä¾äºç¸ç¶å¤§çå¸æãç¶èï¼å°äººå·¥æºæ§æè¡æç¨æ¼å°åè¶é³æ³¢æª¢æ¥åææå¶ææ°ï¼ä¾å¦å¬å±è³æå¯ç¨æ§æéãè³æé±ç§åäººå·¥æºæ§æ¨¡åéæåº¦ãæè¿ï¼ç ç©¶äººå¡å°æ³¨æ¼ç ´å£æ§æè¡ï¼ä¾å¦è¯åå­¸ç¿ (FL) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥æ¹åèªåè¨ºæ·åæ±ºç­æ¯æ´å·¥ä½æµç¨ãæ¬ç ç©¶æä¾äºäººå·¥æºæ§å¨å°åè¶é³æ³¢æª¢æ¥ä¸­éå¶åæ©æçå¨é¢æ¦è§ï¼å¼·èª¿ XAI å FL çååå·¥ä½æµç¨åè§è²ï¼æ¾åºç ç©¶å·®è·ï¼ä¸¦æ¢è¨æ½å¨çæªä¾ç¼å±ãæ­¤å¤ï¼ä¸åç¸éçè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº XAI å FL çåè½ï¼éé»å¨æ¼ (i) å½±åè¾¨è­ã(ii) ç¾çåé¡ã(iii) å¿èçµæ§åå²ï¼ä»¥å (iv) å¿èåè½çå®éè©ä¼°ã

##### **Evaluating the role of `Constitutions' for learning from AI feedback**
2411.10168v1 by Saskia Redgate, Andrew M. Bean, Adam Mahdi

The growing capabilities of large language models (LLMs) have led to their
use as substitutes for human feedback for training and assessing other LLMs.
These methods often rely on `constitutions', written guidelines which a critic
model uses to provide feedback and improve generations. We investigate how the
choice of constitution affects feedback quality by using four different
constitutions to improve patient-centered communication in medical interviews.
In pairwise comparisons conducted by 215 human raters, we found that detailed
constitutions led to better results regarding emotive qualities. However, none
of the constitutions outperformed the baseline in learning more
practically-oriented skills related to information gathering and provision. Our
findings indicate that while detailed constitutions should be prioritised,
there are possible limitations to the effectiveness of AI feedback as a reward
signal in certain areas.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼åè½ä¸æ·å¢å¼·ï¼ä¿ä½¿å®åè¢«ç¨ä½äººé¡åé¥çæ¿ä»£åï¼ä»¥è¨ç·´åè©ä¼°å¶ä» LLMãéäºæ¹æ³éå¸¸ä¾è³´æ¼ãæ²æ³ãï¼ä¹å°±æ¯è©è«æ¨¡åç¨ä¾æä¾åé¥åæ¹é²çæçæ¸é¢æºåãæåæ¢è¨æ²æ³é¸æå¦ä½å½±é¿åé¥åè³ªï¼æ¹æ³æ¯ä½¿ç¨åç¨®ä¸åçæ²æ³ä¾æ¹åé«çè¨ªè«ä¸­çä»¥æ£èçºä¸­å¿çæºéãå¨ 215 ä½äººé¡è©åå¡é²è¡çæå°æ¯è¼ä¸­ï¼æåç¼ç¾è©³ç´°çæ²æ³å¨æç·åè³ªæ¹é¢å¸¶ä¾æ´å¥½ççµæãç¶èï¼æ²æä»»ä½æ²æ³å¨å­¸ç¿èè³è¨æ¶éåæä¾ç¸éçæ´å¯¦ç¨æè½æ¹é¢åªæ¼åºæºãæåçç ç©¶çµæè¡¨æï¼éç¶æåªåèæ®è©³ç´°çæ²æ³ï¼ä½ AI åé¥ä½çºç¹å®é åççåµè¨èçæææ§å¯è½æéã

##### **PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse**
2411.10087v1 by Einari Vaaras, Manu Airaksinen, Okko RÃ¤sÃ¤nen

Self-supervised learning (SSL) is a data-driven learning approach that
utilizes the innate structure of the data to guide the learning process. In
contrast to supervised learning, which depends on external labels, SSL utilizes
the inherent characteristics of the data to produce its own supervisory signal.
However, one frequent issue with SSL methods is representation collapse, where
the model outputs a constant input-invariant feature representation. This issue
hinders the potential application of SSL methods to new data modalities, as
trying to avoid representation collapse wastes researchers' time and effort.
This paper introduces a novel SSL algorithm for time-series data called
Prediction of Functionals from Masked Latents (PFML). Instead of predicting
masked input signals or their latent representations directly, PFML operates by
predicting statistical functionals of the input signal corresponding to masked
embeddings, given a sequence of unmasked embeddings. The algorithm is designed
to avoid representation collapse, rendering it straightforwardly applicable to
different time-series data domains, such as novel sensor modalities in clinical
data. We demonstrate the effectiveness of PFML through complex, real-life
classification tasks across three different data modalities: infant posture and
movement classification from multi-sensor inertial measurement unit data,
emotion recognition from speech data, and sleep stage classification from EEG
data. The results show that PFML is superior to a conceptually similar
pre-existing SSL method and competitive against the current state-of-the-art
SSL method, while also being conceptually simpler and without suffering from
representation collapse.

æè¦ï¼èªçç£å­¦ä¹  (SSL) æ¯ä¸ç§æ°æ®é©±å¨çå­¦ä¹ æ¹æ³ï¼å®å©ç¨æ°æ®çåå¨ç»ææ¥æå¯¼å­¦ä¹ è¿ç¨ãä¸ä¾èµå¤é¨æ ç­¾ççç£å­¦ä¹ ç¸åï¼SSL å©ç¨æ°æ®æ¬èº«çåºæç¹å¾æ¥äº§çèªå·±ççç£ä¿¡å·ãç¶èï¼SSL æ¹æ³çä¸ä¸ªå¸¸è§é®é¢æ¯è¡¨ç¤ºåå¡ï¼å¶ä¸­æ¨¡åè¾åºä¸ä¸ªå¸¸æ°è¾å¥ä¸åç¹å¾è¡¨ç¤ºãè¿ä¸ªé®é¢é»ç¢äº SSL æ¹æ³å¨æ°çæ°æ®æ¨¡å¼ä¸­çæ½å¨åºç¨ï¼å ä¸ºè¯å¾é¿åè¡¨ç¤ºåå¡ä¼æµªè´¹ç ç©¶äººåçæ¶é´åç²¾åãæ¬æä»ç»äºä¸ç§éå¯¹æ¶é´åºåæ°æ®çæ°å SSL ç®æ³ï¼ç§°ä¸ºæ©ç æ½å¨åéçåè½é¢æµ (PFML)ãPFML ä¸æ¯ç´æ¥é¢æµæ©ç è¾å¥ä¿¡å·æå¶æ½å¨è¡¨ç¤ºï¼èæ¯éè¿é¢æµè¾å¥ä¿¡å·çç»è®¡å½æ°ï¼å¯¹åºäºæ©ç åµå¥ï¼æ¥æä½ï¼ç»å®ä¸ç³»åæªæ©ç åµå¥ãè¯¥ç®æ³æ¨å¨é¿åè¡¨ç¤ºåå¡ï¼ä½¿å¶å¯ä»¥ç´æ¥åºç¨äºä¸åçæ¶é´åºåæ°æ®åï¼ä¾å¦ä¸´åºæ°æ®ä¸­çæ°åä¼ æå¨æ¨¡å¼ãæä»¬éè¿ä¸ä¸ªä¸åæ°æ®æ¨¡å¼çå¤æç°å®çæ´»åç±»ä»»å¡å±ç¤ºäº PFML çæææ§ï¼å¤ä¼ æå¨æ¯æ§æµéååæ°æ®çå©´å¿å§¿å¿åè¿å¨åç±»ãè¯­é³æ°æ®çè¯­é³è¯å«ä»¥åèçµå¾æ°æ®çç¡ç é¶æ®µåç±»ãç»æè¡¨æï¼PFML ä¼äºæ¦å¿µä¸ç¸ä¼¼çç°æ SSL æ¹æ³ï¼å¹¶ä¸ä¸å½åæåè¿ç SSL æ¹æ³å·æç«äºåï¼åæ¶å¨æ¦å¿µä¸æ´ç®åï¼å¹¶ä¸ä¸ä¼åºç°è¡¨ç¤ºåå¡ã

##### **Rethinking Normalization Strategies and Convolutional Kernels for Multimodal Image Fusion**
2411.10036v1 by Dan He, Guofen Wang, Weisheng Li, Yucheng Shu, Wenbo Li, Lijian Yang, Yuping Huang, Feiyan Li

Multimodal image fusion (MMIF) aims to integrate information from different
modalities to obtain a comprehensive image, aiding downstream tasks. However,
existing methods tend to prioritize natural image fusion and focus on
information complementary and network training strategies. They ignore the
essential distinction between natural and medical image fusion and the
influence of underlying components. This paper dissects the significant
differences between the two tasks regarding fusion goals, statistical
properties, and data distribution. Based on this, we rethink the suitability of
the normalization strategy and convolutional kernels for end-to-end
MMIF.Specifically, this paper proposes a mixture of instance normalization and
group normalization to preserve sample independence and reinforce intrinsic
feature correlation.This strategy promotes the potential of enriching feature
maps, thus boosting fusion performance. To this end, we further introduce the
large kernel convolution, effectively expanding receptive fields and enhancing
the preservation of image detail. Moreover, the proposed multipath adaptive
fusion module recalibrates the decoder input with features of various scales
and receptive fields, ensuring the transmission of crucial information.
Extensive experiments demonstrate that our method exhibits state-of-the-art
performance in multiple fusion tasks and significantly improves downstream
applications. The code is available at https://github.com/HeDan-11/LKC-FUNet.

æè¦ï¼å¤æ¨¡æå½±åèå (MMIF) æ¨å¨æ´åä¾èªä¸åæ¨¡æçè³è¨ï¼ä»¥åå¾å¨é¢çå½±åï¼åå©ä¸æ¸¸ä»»åãç¶èï¼ç¾ææ¹æ³å¾åæ¼åªåèæ®èªç¶å½±åèåï¼ä¸¦å°æ³¨æ¼è³è¨äºè£åç¶²è·¯è¨ç·´ç­ç¥ãå®åå¿½ç¥äºèªç¶å½±åèåèé«å­¸å½±åèåä¹éçæ¬è³ªåå¥ï¼ä»¥ååºå±¤çµæçå½±é¿ãæ¬æåæäºéå©åä»»åå¨èåç®æ¨ãçµ±è¨æ§è³ªåè³æåä½æ¹é¢çé¡¯èå·®ç°ãåºæ¼æ­¤ï¼æåéæ°æèæ­£è¦åç­ç¥åæ²ç©æ ¸å°ç«¯å°ç«¯ MMIF çé©ç¨æ§ãå·é«èè¨ï¼æ¬ææåºå¯¦ä¾æ­£è¦ååç¾¤çµæ­£è¦åçæ··åï¼ä»¥ä¿çæ¨£æ¬ç¨ç«æ§ä¸¦å å¼·å§å¨ç¹å¾µéè¯ãæ­¤ç­ç¥æåäºè±å¯ç¹å¾µåçæ½åï¼å¾èæåèåæè½ãçºæ­¤ï¼æåé²ä¸æ­¥å¼å¥äºå¤§æ ¸å·ç©ï¼ææå°æ´å±æåéä¸¦å¢å¼·å½±åç´°ç¯çä¿çãæ­¤å¤ï¼æåºçå¤è·¯å¾èªé©æèåæ¨¡çµéæ°æ ¡æºè§£ç¢¼å¨è¼¸å¥ï¼å¶ç¹å¾µå·æä¸åçæ¯ä¾åæåéï¼ç¢ºä¿ééµè³è¨çå³è¼¸ãå»£æ³çå¯¦é©è­æï¼æåçæ¨¡åå¨å¤åèåä»»åä¸­å±ç¾åºæåé²çæè½ï¼ä¸¦é¡¯èæ¹åä¸æ¸¸æç¨ãç¨å¼ç¢¼å¯å¨ https://github.com/HeDan-11/LKC-FUNet åå¾ã

##### **JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging**
2411.09933v1 by Kaito Baba, Ryota Yagi, Junichiro Takahashi, Risa Kishikawa, Satoshi Kodera

With the rapid advancement of large language models (LLMs), foundational
models (FMs) have seen significant advancements. Healthcare is one of the most
crucial application areas for these FMs, given the significant time and effort
required for physicians to analyze large volumes of patient data. Recent
efforts have focused on adapting multimodal FMs to the medical domain through
techniques like instruction-tuning, leading to the development of medical
foundation models (MFMs). However, these approaches typically require large
amounts of training data to effectively adapt models to the medical field.
Moreover, most existing models are trained on English datasets, limiting their
practicality in non-English-speaking regions where healthcare professionals and
patients are not always fluent in English. The need for translation introduces
additional costs and inefficiencies. To address these challenges, we propose a
\textbf{J}apanese \textbf{Radi}ology report generation model enhanced by
\textbf{Evo}lutionary optimization of model merging (JRadiEvo). This is the
first attempt to extend a non-medical vision-language foundation model to the
medical domain through evolutionary optimization of model merging. We
successfully created a model that generates accurate Japanese reports from
X-ray images using only 50 translated samples from publicly available data.
This model, developed with highly efficient use of limited data, outperformed
leading models from recent research trained on much larger datasets.
Additionally, with only 8 billion parameters, this relatively compact
foundation model can be deployed locally within hospitals, making it a
practical solution for environments where APIs and other external services
cannot be used due to strict privacy and security requirements.

æè¦ï¼<paragraph>é¨èå¤§åèªè¨æ¨¡å (LLM) çå¿«éé²å±ï¼åºç¤æ¨¡å (FM) å·²ç¶ç²å¾é¡¯èçé²æ­¥ãé«çä¿å¥æ¯éäº FM æéè¦çæç¨é åä¹ä¸ï¼å çºé«çéè¦è±è²»å¤§éæéåç²¾åä¾åæå¤§éçæ£èè³æãæè¿çç ç©¶éé»å¨æ¼ééæä»¤å¾®èª¿ç­æè¡å°å¤æ¨¡æ FM é©æå°é«çé åï¼å¾èéç¼åºé«çåºç¤æ¨¡å (MFM)ãç¶èï¼éäºæ¹æ³éå¸¸éè¦å¤§éçè¨ç·´è³ææè½ææå°å°æ¨¡åé©æå°é«çé åãæ­¤å¤ï¼å¤§å¤æ¸ç¾ææ¨¡åé½æ¯éå°è±èªè³æéé²è¡è¨ç·´ï¼ééå¶äºå®åå¨éè±èªå°åçå¯¦ç¨æ§ï¼é£è£¡çé«çå°æ¥­äººå¡åæ£èä¸¦ä¸ç¸½æ¯ç²¾éè±èªãç¿»è­¯çéæ±å¼å¥äºé¡å¤çææ¬åä½æçãçºäºæå°éäºææ°ï¼æåæåºäºä¸åç±æ¨¡ååä½µçé²ååªåå¢å¼·ç**J**apanese **Radi**ology å ±åçææ¨¡å (JRadiEvo)ãéæ¯é¦æ¬¡åè©¦ééæ¨¡ååä½µçé²ååªåå°éé«çè¦è¦ºèªè¨åºç¤æ¨¡åæ´å±å°é«çé åãæåæåå°å»ºç«äºä¸åæ¨¡åï¼åä½¿ç¨ä¾èªå¬éè³æç 50 åç¿»è­¯ç¯ä¾ï¼å°±è½å¾ X åå½±åä¸­ç¢çæºç¢ºçæ¥æå ±åãéåæ¨¡åä½¿ç¨æéè³æé²è¡é«æççéç¼ï¼å¶æè½åªæ¼æè¿ç ç©¶ä¸­å¨æ´å¤§è³æéä¸è¨ç·´åºä¾çé åæ¨¡åãæ­¤å¤ï¼éåç¸å°ç²¾ç°¡çåºç¤æ¨¡ååªæ 80 åååæ¸ï¼å¯ä»¥å¨é«é¢å§é¨é²è¡æ¬å°é¨ç½²ï¼ä½¿å¶æçºå¨å´æ ¼çé±ç§åå®å¨è¦æ±ä¸ç¡æ³ä½¿ç¨ API åå¶ä»å¤é¨æåçç°å¢ä¸­çå¯¦ç¨è§£æ±ºæ¹æ¡ã</paragraph>

##### **A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation**
2411.09874v1 by Chin-Sung Tung, Sheng-Fu Liang, Shu-Feng Chang, Chung-Ping Young

Electroencephalography (EEG) plays a crucial role in the diagnosis of various
neurological disorders. However, small hospitals and clinics often lack
advanced EEG signal analysis systems and are prone to misinterpretation in
manual EEG reading. This study proposes an innovative hybrid artificial
intelligence (AI) system for automatic interpretation of EEG background
activity and report generation. The system combines deep learning models for
posterior dominant rhythm (PDR) prediction, unsupervised artifact removal, and
expert-designed algorithms for abnormality detection. For PDR prediction, 1530
labeled EEGs were used, and the best ensemble model achieved a mean absolute
error (MAE) of 0.237, a root mean square error (RMSE) of 0.359, an accuracy of
91.8% within a 0.6Hz error, and an accuracy of 99% within a 1.2Hz error. The AI
system significantly outperformed neurologists in detecting generalized
background slowing (p = 0.02; F1: AI 0.93, neurologists 0.82) and demonstrated
improved focal abnormality detection, although not statistically significant (p
= 0.79; F1: AI 0.71, neurologists 0.55). Validation on both an internal dataset
and the Temple University Abnormal EEG Corpus showed consistent performance
(F1: 0.884 and 0.835, respectively; p = 0.66), demonstrating generalizability.
The use of large language models (LLMs) for report generation demonstrated 100%
accuracy, verified by three other independent LLMs. This hybrid AI system
provides an easily scalable and accurate solution for EEG interpretation in
resource-limited settings, assisting neurologists in improving diagnostic
accuracy and reducing misdiagnosis rates.

æè¦ï¼è¦é»åï¼EEGï¼å¨è¨ºæ·åç¨®ç¥ç¶ç¾çä¸­æ®æ¼è³ééè¦çè§è²ãç¶èï¼å°åé«é¢åè¨ºæéå¸¸ç¼ºä¹é²éç EEG è¨èåæç³»çµ±ï¼ä¸å®¹æå¨æåå¤è® EEG æç¢çèª¤è§£ãæ¬ç ç©¶æåºä¸ååµæ°çæ··åäººå·¥æºæ§ï¼AIï¼ç³»çµ±ï¼ç¨æ¼èªåå¤è® EEG èæ¯æ´»åä¸¦ç¢çå ±åãæ­¤ç³»çµ±çµåæ·±åº¦å­¸ç¿æ¨¡åï¼ç¨æ¼é æ¸¬å¾åªå¢å¾åï¼PDRï¼ãéç£ç£äººå·¥è£½åç§»é¤ï¼ä»¥åå°å®¶è¨­è¨çç°å¸¸åµæ¸¬æ¼ç®æ³ãå¨ PDR é æ¸¬ä¸­ï¼ä½¿ç¨äº 1530 åæ¨è¨ EEGï¼æä½³çæ´é«æ¨¡åéå°äº 0.237 çå¹³åçµå°èª¤å·®ï¼MAEï¼ã0.359 çåæ¹æ ¹èª¤å·®ï¼RMSEï¼ã91.8% ç 0.6Hz èª¤å·®æºç¢ºåº¦ï¼ä»¥å 99% ç 1.2Hz èª¤å·®æºç¢ºåº¦ãAI ç³»çµ±å¨åµæ¸¬å»£æ³èæ¯æ¸æ¢æ¹é¢æé¡¯åªæ¼ç¥ç¶å­¸å®¶ï¼p = 0.02ï¼F1ï¼AI 0.93ï¼ç¥ç¶å­¸å®¶ 0.82ï¼ï¼ä¸¦å±ç¾åºæ¹åçå±é¨ç°å¸¸åµæ¸¬ï¼åç®¡æ²æçµ±è¨æç¾©ï¼p = 0.79ï¼F1ï¼AI 0.71ï¼ç¥ç¶å­¸å®¶ 0.55ï¼ãå¨å§é¨è³æéå Temple University ç°å¸¸ EEG èªæåº«ä¸çé©è­é¡¯ç¤ºäºä¸è´çæè½ï¼F1ï¼åå¥çº 0.884 å 0.835ï¼p = 0.66ï¼ï¼è­æäºå¶æ®éæ§ãä½¿ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼ä¾ç¢çå ±åè­æäº 100% çæºç¢ºåº¦ï¼ä¸¦ç±å¶ä»ä¸åç¨ç«ç LLM é©è­ãæ­¤æ··å AI ç³»çµ±æä¾äºä¸åææ¼æ´åä¸æºç¢ºçè§£æ±ºæ¹æ¡ï¼ç¨æ¼å¨è³æºæéçç°å¢ä¸­é²è¡ EEG å¤è®ï¼åå©ç¥ç¶å­¸å®¶æé«è¨ºæ·æºç¢ºåº¦ä¸¦éä½èª¤è¨ºçã

##### **A Benchmark for Long-Form Medical Question Answering**
2411.09834v1 by Pedram Hosseini, Jessica M. Sin, Bing Ren, Bryceton G. Thomas, Elnaz Nouri, Ali Farahanchi, Saeed Hassanpour

There is a lack of benchmarks for evaluating large language models (LLMs) in
long-form medical question answering (QA). Most existing medical QA evaluation
benchmarks focus on automatic metrics and multiple-choice questions. While
valuable, these benchmarks fail to fully capture or assess the complexities of
real-world clinical applications where LLMs are being deployed. Furthermore,
existing studies on evaluating long-form answer generation in medical QA are
primarily closed-source, lacking access to human medical expert annotations,
which makes it difficult to reproduce results and enhance existing baselines.
In this work, we introduce a new publicly available benchmark featuring
real-world consumer medical questions with long-form answer evaluations
annotated by medical doctors. We performed pairwise comparisons of responses
from various open and closed-source medical and general-purpose LLMs based on
criteria such as correctness, helpfulness, harmfulness, and bias. Additionally,
we performed a comprehensive LLM-as-a-judge analysis to study the alignment
between human judgments and LLMs. Our preliminary results highlight the strong
potential of open LLMs in medical QA compared to leading closed models. Code &
Data: https://github.com/lavita-ai/medical-eval-sphere

æè¦ï¼ç¼ºä¹è©ä¼°å¤§åèªè¨æ¨¡å (LLM) å¨é·ç¯é«çåé¡è§£ç­ (QA) ä¸­è¡¨ç¾çåºæºãç¾æçé«ç QA è©ä¼°åºæºå¤§å¤èéæ¼èªååææ¨åå¤é¸é¡ãåç®¡æå¹å¼ï¼ä½éäºåºæºä¸¦æªå®å¨ææ¡æè©ä¼° LLM é¨ç½²æ¼å¶ä¸­ççå¯¦ä¸çè¨åºæç¨ä¹è¤éæ§ãæ­¤å¤ï¼ç¾æè©ä¼°é«ç QA ä¸­é·ç¯ç­æ¡ç¢ççç ç©¶ä¸»è¦çºéæºï¼ç¡æ³åå¾äººé¡é«çå°å®¶è¨»è§£ï¼éä½¿å¾é£ä»¥éç¾çµæä¸¦å¼·åç¾æåºæºãå¨éé å·¥ä½ä¸­ï¼æåå¼é²ä¸åæ°çå¬éåºæºï¼å¶ç¹é»æ¯çå¯¦ä¸ççæ¶è²»èé«çåé¡ï¼ä¸¦éæç±é«çé«çè¨»è§£çé·ç¯ç­æ¡è©ä¼°ãæåæ ¹ææ­£ç¢ºæ§ãæçæ§ãæå®³æ§ååè¦ç­æºåï¼å°ä¾èªåç¨®éæ¾åéæºé«çåéç¨ LLM çåæé²è¡æå°æ¯è¼ãæ­¤å¤ï¼æåå·è¡äºä¸é å¨é¢ç LLM ä½çºè©å¤çåæï¼ä»¥ç ç©¶äººé¡å¤æ·å LLM ä¹éçä¸è´æ§ãæåçåæ­¥çµæçªåºäºéæ¾ LLM å¨é«ç QA ä¸­çå¼·å¤§æ½åï¼åªæ¼é åçéæºæ¨¡åãç¨å¼ç¢¼åè³æï¼https://github.com/lavita-ai/medical-eval-sphere

##### **A Self-Supervised Model for Multi-modal Stroke Risk Prediction**
2411.09822v1 by Camille Delgrange, Olga Demler, Samia Mora, Bjoern Menze, Ezequiel de la Rosa, Neda Davoudi

Predicting stroke risk is a complex challenge that can be enhanced by
integrating diverse clinically available data modalities. This study introduces
a self-supervised multimodal framework that combines 3D brain imaging, clinical
data, and image-derived features to improve stroke risk prediction prior to
onset. By leveraging large unannotated clinical datasets, the framework
captures complementary and synergistic information across image and tabular
data modalities. Our approach is based on a contrastive learning framework that
couples contrastive language-image pretraining with an image-tabular matching
module, to better align multimodal data representations in a shared latent
space. The model is trained on the UK Biobank, which includes structural brain
MRI and clinical data. We benchmark its performance against state-of-the-art
unimodal and multimodal methods using tabular, image, and image-tabular
combinations under diverse frozen and trainable model settings. The proposed
model outperformed self-supervised tabular (image) methods by 2.6% (2.6%) in
ROC-AUC and by 3.3% (5.6%) in balanced accuracy. Additionally, it showed a 7.6%
increase in balanced accuracy compared to the best multimodal supervised model.
Through interpretable tools, our approach demonstrated better integration of
tabular and image data, providing richer and more aligned embeddings.
Gradient-weighted Class Activation Mapping heatmaps further revealed activated
brain regions commonly associated in the literature with brain aging, stroke
risk, and clinical outcomes. This robust self-supervised multimodal framework
surpasses state-of-the-art methods for stroke risk prediction and offers a
strong foundation for future studies integrating diverse data modalities to
advance clinical predictive modelling.

æè¦ï¼<paragraph>é æ¸¬ä¸­é¢¨é¢¨éªæ¯ä¸é è¤éçææ°ï¼å¯ä»¥ééæ´åå¤æ¨£åçè¨åºå¯ç¨æ¸ææ¨¡å¼ä¾å å¼·ãæ¬ç ç©¶ä»ç´¹äºä¸åèªç£ç£å¤æ¨¡å¼æ¶æ§ï¼çµå 3D å¤§è¦å½±åãè¨åºæ¸æåå½±åè¡çç¹å¾µï¼ä»¥å¨ç¼ä½åæ¹åä¸­é¢¨é¢¨éªé æ¸¬ãééå©ç¨å¤§éçæªæ¨è¨è¨åºæ¸æéï¼è©²æ¶æ§æ·åäºå½±ååè¡¨æ ¼æ¸ææ¨¡å¼ä¹éçäºè£åååè³è¨ãæåçåæ³åºæ¼å°æ¯å­¸ç¿æ¶æ§ï¼å°å°æ¯èªè¨å½±åé è¨ç·´èå½±åè¡¨æ ¼å¹éæ¨¡çµçµåï¼ä»¥å¨å±äº«æ½å¨ç©ºéä¸­æ´å¥½å°å°é½å¤æ¨¡å¼æ¸æè¡¨ç¤ºãè©²æ¨¡åæ¯å¨è±åçç©éè¡ä¸­è¨ç·´çï¼å¶ä¸­åæ¬çµæ§æ§è¦é¨ MRI åè¨åºæ¸æãæåä½¿ç¨è¡¨æ ¼ãå½±ååå½±åè¡¨æ ¼çµåï¼å¨ä¸åçåçµåå¯è¨ç·´æ¨¡åè¨­å®ä¸ï¼æ ¹ææåé²çå®æ¨¡å¼åå¤æ¨¡å¼æ¹æ³å°å¶æè½é²è¡åºæºæ¸¬è©¦ãææåºçæ¨¡åå¨ ROC-AUC ä¸­æ¯èªç£ç£è¡¨æ ¼ï¼å½±åï¼æ¹æ³é«åº 2.6%ï¼2.6%ï¼ï¼å¨å¹³è¡¡æºç¢ºåº¦ä¸­é«åº 3.3%ï¼5.6%ï¼ãæ­¤å¤ï¼èæä½³å¤æ¨¡å¼ç£ç£æ¨¡åç¸æ¯ï¼å®çå¹³è¡¡æºç¢ºåº¦æé«äº 7.6%ãééå¯è§£éçå·¥å·ï¼æåçåæ³è­æäºè¡¨æ ¼åå½±åæ¸æçæ´åæ§æ´å¥½ï¼æä¾äºæ´è±å¯ä¸æ´ä¸è´çåµå¥ãæ¢¯åº¦å æ¬é¡å¥åç¨å°æç±åé²ä¸æ­¥æ­ç¤ºäºæç»ä¸­éå¸¸èè¦é¨èåãä¸­é¢¨é¢¨éªåè¨åºçµæç¸éçæ´»åè¦åãéåå¼·å¥çèªç£ç£å¤æ¨¡å¼æ¶æ§è¶è¶äºä¸­é¢¨é¢¨éªé æ¸¬çææ°æ¹æ³ï¼ä¸¦çºæ´åä¸åæ¸ææ¨¡å¼ä»¥æ¨é²è¨åºé æ¸¬å»ºæ¨¡çæªä¾ç ç©¶æä¾äºå å¯¦çåºç¤ã</paragraph>

##### **Deep Learning for Fetal Inflammatory Response Diagnosis in the Umbilical Cord**
2411.09767v1 by Marina A. Ayad, Ramin Nateghi, Abhishek Sharma, Lawrence Chillrud, Tilly Seesillapachai, Lee A. D. Cooper, Jeffery A. Goldstein

Inflammation of the umbilical cord can be seen as a result of ascending
intrauterine infection or other inflammatory stimuli. Acute fetal inflammatory
response (FIR) is characterized by infiltration of the umbilical cord by fetal
neutrophils, and can be associated with neonatal sepsis or fetal inflammatory
response syndrome. Recent advances in deep learning in digital pathology have
demonstrated favorable performance across a wide range of clinical tasks, such
as diagnosis and prognosis. In this study we classified FIR from whole slide
images (WSI). We digitized 4100 histological slides of umbilical cord stained
with hematoxylin and eosin(H&E) and extracted placental diagnoses from the
electronic health record. We build models using attention-based whole slide
learning models. We compared strategies between features extracted by a model
(ConvNeXtXLarge) pretrained on non-medical images (ImageNet), and one
pretrained using histopathology images (UNI). We trained multiple iterations of
each model and combined them into an ensemble. The predictions from the
ensemble of models trained using UNI achieved an overall balanced accuracy of
0.836 on the test dataset. In comparison, the ensembled predictions using
ConvNeXtXLarge had a lower balanced accuracy of 0.7209. Heatmaps generated from
top accuracy model appropriately highlighted arteritis in cases of FIR 2. In
FIR 1, the highest performing model assigned high attention to areas of
activated-appearing stroma in Wharton's Jelly. However, other high-performing
models assigned attention to umbilical vessels. We developed models for
diagnosis of FIR from placental histology images, helping reduce interobserver
variability among pathologists. Future work may examine the utility of these
models for identifying infants at risk of systemic inflammatory response or
early onset neonatal sepsis.

æè¦ï¼èå¸¶ç¼çå¯è¦çºä¸è¡æ§å­å®®å§æææå¶ä»ç¼çåºæ¿æè´ãæ¥æ§èåç¼çåæ (FIR) çç¹å¾µæ¯èåä¸­æ§çæµ¸æ½¤èå¸¶ï¼å¯è½èæ°çåæè¡çæèåç¼çåæçåç¾¤æéãæ¸ä½ççå­¸ä¸­æ·±åº¦å­¸ç¿çææ°é²å±å·²è­æå¨å»£æ³çè¨åºä»»åä¸­è¡¨ç¾è¯å¥½ï¼ä¾å¦è¨ºæ·åé å¾ãå¨éé ç ç©¶ä¸­ï¼æåå¾å¨åçå½±å (WSI) ä¸­åé¡ FIRãæåå° 4100 å¼µç¨èæ¨ç²¾åæç´ (H&E) æè²çèå¸¶çµç¹åçæ¸ä½åï¼ä¸¦å¾é»å­çæ­·ä¸­æåèç¤è¨ºæ·ãæåä½¿ç¨åºæ¼æ³¨æåçå¨åçå­¸ç¿æ¨¡åå»ºç«æ¨¡åãæåæ¯è¼äºéé«çå½±å (ImageNet) é è¨ç·´æ¨¡å (ConvNeXtXLarge) åä½¿ç¨çµç¹ççå­¸å½±å (UNI) é è¨ç·´æ¨¡åæåçç¹å¾µä¹éçç­ç¥ãæåè¨ç·´äºæ¯åæ¨¡åçå¤æ¬¡è¿­ä»£ï¼ä¸¦å°å®åçµåæä¸åæ´é«ãä½¿ç¨ UNI è¨ç·´çæ¨¡åæ´é«çé æ¸¬å¨æ¸¬è©¦è³æéä¸éå° 0.836 çæ´é«å¹³è¡¡æºç¢ºåº¦ãç¸æ¯ä¹ä¸ï¼ä½¿ç¨ ConvNeXtXLarge çæ´é«é æ¸¬çå¹³è¡¡æºç¢ºåº¦è¼ä½ï¼çº 0.7209ãå¾æºç¢ºåº¦æé«çæ¨¡åç¢ççç±åé©ç¶å°çªåºäº FIR 2 çä¾ä¸­çåèçãå¨ FIR 1 ä¸­ï¼è¡¨ç¾æå¥½çæ¨¡åå°é«åº¦éæ³¨åéçµ¦æ²é æ°è ä¸­çæ´»åå¤è§åºè³ªååãç¶èï¼å¶ä»è¡¨ç¾è¯å¥½çæ¨¡åå°æ³¨æååéçµ¦èå¸¶è¡ç®¡ãæåéç¼äºå¾èç¤çµç¹å­¸å½±åè¨ºæ· FIR çæ¨¡åï¼æå©æ¼æ¸å°ççå­¸å®¶ä¹éçè§å¯èéè®ç°æ§ãæªä¾çç ç©¶å¯è½ææ¢è¨éäºæ¨¡åå¨è­å¥æå¨èº«æ§ç¼çåæé¢¨éªææ©æç¼ä½æ°çåæè¡ççå¬°åæ¹é¢çæç¨ã

##### **Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable Medical Information**
2411.09648v1 by Ahan Bhatt, Nandan Vaghela

This paper introduces Med-Bot, an AI-powered chatbot designed to provide
users with accurate and reliable medical information. Utilizing advanced
libraries and frameworks such as PyTorch, Chromadb, Langchain and Autogptq,
Med-Bot is built to handle the complexities of natural language understanding
in a healthcare context. The integration of llamaassisted data processing and
AutoGPT-Q provides enhanced performance in processing and responding to queries
based on PDFs of medical literature, ensuring that users receive precise and
trustworthy information. This research details the methodologies employed in
developing Med-Bot and evaluates its effectiveness in disseminating healthcare
information.

æè¦ï¼æ¬æä»ç´¹ Med-Botï¼ä¸åç±äººå·¥æºæ§é©åçèå¤©æ©å¨äººï¼æ¨å¨çºä½¿ç¨èæä¾æºç¢ºä¸å¯é çé«çè³è¨ãMed-Bot å©ç¨é²éå½å¼åº«åæ¡æ¶ï¼ä¾å¦ PyTorchãChromadbãLangchain å Autogptqï¼å»ºæ§ä¾èçé«çä¿å¥ç°å¢ä¸­èªç¶èªè¨çè§£çè¤éæ§ãæ´åäº Llama è¼å©è³æèçå AutoGPT-Qï¼å¨èçååæåºæ¼é«å­¸æç» PDF çæ¥è©¢ææä¾äºå¢å¼·çæè½ï¼ç¢ºä¿ä½¿ç¨èæ¶å°ç²¾ç¢ºä¸å¯ä¿¡è³´çè³è¨ãæ¬ç ç©¶è©³ç´°èªªæäºéç¼ Med-Bot ææ¡ç¨çæ¹æ³ï¼ä¸¦è©ä¼°å¶å¨å³æ­é«çä¿å¥è³è¨æ¹é¢çæææ§ã

##### **An Explainable Attention Model for Cervical Precancer Risk Classification using Colposcopic Images**
2411.09469v1 by Smith K. Khare, Berit Bargum Booth, Victoria Blanes-Vidal, Lone Kjeld Petersen, Esmaeil S. Nadimi

Cervical cancer remains a major worldwide health issue, with early
identification and risk assessment playing critical roles in effective
preventive interventions. This paper presents the Cervix-AID-Net model for
cervical precancer risk classification. The study designs and evaluates the
proposed Cervix-AID-Net model based on patients colposcopy images. The model
comprises a Convolutional Block Attention Module (CBAM) and convolutional
layers that extract interpretable and representative features of colposcopic
images to distinguish high-risk and low-risk cervical precancer. In addition,
the proposed Cervix-AID-Net model integrates four explainable techniques,
namely gradient class activation maps, Local Interpretable Model-agnostic
Explanations, CartoonX, and pixel rate distortion explanation based on output
feature maps and input features. The evaluation using holdout and ten-fold
cross-validation techniques yielded a classification accuracy of 99.33\% and
99.81\%. The analysis revealed that CartoonX provides meticulous explanations
for the decision of the Cervix-AID-Net model due to its ability to provide the
relevant piece-wise smooth part of the image. The effect of Gaussian noise and
blur on the input shows that the performance remains unchanged up to Gaussian
noise of 3\% and blur of 10\%, while the performance reduces thereafter. A
comparison study of the proposed model's performance compared to other deep
learning approaches highlights the Cervix-AID-Net model's potential as a
supplemental tool for increasing the effectiveness of cervical precancer risk
assessment. The proposed method, which incorporates the CBAM and explainable
artificial integration, has the potential to influence cervical cancer
prevention and early detection, improving patient outcomes and lowering the
worldwide burden of this preventable disease.

æè¦ï¼å­å®®é ¸çä»ç¶æ¯å¨çä¸»è¦çå¥åº·è­°é¡ï¼æ©æè¾¨è­åé¢¨éªè©ä¼°å¨ææçé é²æ§å¹²é æªæ½ä¸­æ®æ¼èééµæ§çè§è²ãæ¬ææåºå­å®®é ¸è¼å©ç¶²è·¯æ¨¡åï¼ç¨æ¼å­å®®é ¸çåçè®é¢¨éªåé¡ãæ¬ç ç©¶åºæ¼çæ£çé°éé¡å½±åè¨­è¨ä¸¦è©ä¼°ææåºçå­å®®é ¸è¼å©ç¶²è·¯æ¨¡åãè©²æ¨¡ååå«å·ç©åå¡æ³¨æåæ¨¡çµ (CBAM) åå·ç©å±¤ï¼ç¨æ¼èåå¯è§£éä¸å·ä»£è¡¨æ§çé°éé¡å½±åç¹å¾µï¼ä»¥ååé«é¢¨éªåä½é¢¨éªçå­å®®é ¸çåçè®ãæ­¤å¤ï¼ææåºçå­å®®é ¸è¼å©ç¶²è·¯æ¨¡åæ´åäºåç¨®å¯è§£éçæè¡ï¼åå¥çºæ¢¯åº¦é¡å¥æ¿æ´»åãå±é¨å¯è§£éæ¨¡åä¸å¯ç¥è§£éãCartoonX ååºæ¼è¼¸åºç¹å¾µååè¼¸å¥ç¹å¾µçåç´ çå¤±çè§£éãä½¿ç¨çå­æ³åååäº¤åé©è­æè¡é²è¡è©ä¼°ï¼å¾å° 99.33% å 99.81% çåé¡æºç¢ºçãåæé¡¯ç¤ºï¼CartoonX è½å¤ æä¾å½±åä¸­ç¸éçåæ®µå¹³æ»é¨åï¼å æ­¤è½çºå­å®®é ¸è¼å©ç¶²è·¯æ¨¡åçæ±ºç­æä¾ç´°ç·»çè§£éãé«æ¯åªè²åæ¨¡ç³å°è¼¸å¥çå½±é¿é¡¯ç¤ºï¼å¨é«æ¯åªè²ä½æ¼ 3% åæ¨¡ç³ä½æ¼ 10% çææ³ä¸ï¼æè½ä¿æä¸è®ï¼ä½ä¹å¾æè½ä¾¿æä¸éãææåºçæ¨¡åæè½èå¶ä»æ·±åº¦å­¸ç¿æ¹æ³çæ¯è¼ç ç©¶ï¼çªé¡¯äºå­å®®é ¸è¼å©ç¶²è·¯æ¨¡åä½çºè£åå·¥å·çæ½åï¼ç¨æ¼æé«å­å®®é ¸çåçè®é¢¨éªè©ä¼°çæææ§ãææåºçæ¹æ³çµåäº CBAM åå¯è§£éçäººå·¥æ´åï¼ææ½åå½±é¿å­å®®é ¸ççé é²åæ©æåµæ¸¬ï¼æ¹åçæ£çé å¾ä¸¦éä½éç¨®å¯é é²ç¾çå¨å¨ççè² æã

##### **Script-centric behavior understanding for assisted autism spectrum disorder diagnosis**
2411.09413v1 by Wenxing Liu, Yueran Pan, Ming Li

Observing and analyzing children's social behaviors is crucial for the early
diagnosis of Autism Spectrum Disorders (ASD). This work focuses on
automatically detecting ASD using computer vision techniques and large language
models (LLMs). Existing methods typically rely on supervised learning. However,
the scarcity of ASD diagnostic datasets and the lack of interpretability in
diagnostic results significantly limits its clinical application. To address
these challenges, we introduce a novel unsupervised approach based on
script-centric behavior understanding. Our pipeline converts video content into
scripts that describe the behavior of characters, leveraging the
generalizability of large language models to detect ASD in a zero-shot or
few-shot manner. Specifically, we propose a scripts transcription module for
multimodal behavior data textualization and a domain prompts module to bridge
LLMs. Our method achieves an accuracy of 92.00\% in diagnosing ASD in children
with an average age of 24 months, surpassing the performance of supervised
learning methods by 3.58\% absolutely. Extensive experiments confirm the
effectiveness of our approach and suggest its potential for advancing ASD
research through LLMs.

æè¦ï¼è§å¯ååæåç«¥çç¤¾äº¤è¡çºå°æ¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·è³ééè¦ãéé å·¥ä½èéæ¼ä½¿ç¨é»è¦è¦è¦ºæè¡åå¤§èªè¨æ¨¡å (LLM) èªååµæ¸¬ ASDãç¾ææ¹æ³éå¸¸ä¾è³´æ¼ç£ç£å¼å­¸ç¿ãç¶èï¼ASD è¨ºæ·è³æéçç¨å°æ§åè¨ºæ·çµæç¼ºä¹å¯è§£éæ§ï¼é¡¯èå°éå¶äºå¶è¨åºæç¨ãçºäºæå°éäºææ°ï¼æåå¼å¥äºä¸ç¨®åºæ¼ä»¥è³æ¬çºä¸­å¿çè¡çºçè§£çæ°åéç£ç£å¼æ¹æ³ãæåçç®¡éå°å½±çå§å®¹è½æææè¿°è§è²è¡çºçè³æ¬ï¼å©ç¨å¤§èªè¨æ¨¡åçæ³åæ§ä»¥é¶æ¬¡æå°æ¬¡å­¸ç¿çæ¹å¼åµæ¸¬ ASDãå·é«ä¾èªªï¼æåæåºäºä¸åè³æ¬è½éæ¨¡çµç¨æ¼å¤æ¨¡æè¡çºè³ææå­åï¼ä»¥åä¸åç¶²åæç¤ºæ¨¡çµä¾æ©æ¥ LLMãæåçæ¨¡åå¨è¨ºæ·å¹³åå¹´é½¡çº 24 åæçåç«¥ ASD æï¼éå°äº 92.00% çæºç¢ºçï¼çµå°åªæ¼ç£ç£å¼å­¸ç¿æ¹æ³ 3.58%ãå¤§éçå¯¦é©è­å¯¦äºæåæ¹æ³çæææ§ï¼ä¸¦è¡¨æå¶éé LLM æ¨å ASD ç ç©¶çæ½åã

##### **NFRs in Medical Imaging**
2411.09718v1 by Amanda Vallentin

The diagnostic imaging departments are under great pressure due to a growing
workload. The number of required scans is growing and there is a shortage of
qualified labor. AI solutions for medical imaging applications have shown great
potential. However, very few diagnostic imaging models have been approved for
hospital use and even fewer are being implemented at the hospitals. The most
common reason why software projects fail is poor requirement engineering,
especially non-functional requirements (NFRs) can be detrimental to a project.
Research shows that machine learning professionals struggle to work with NFRs
and that there is a need to adapt NFR frameworks to machine learning, AI-based,
software. This study uses qualitative methods to interact with key stakeholders
to identify which types of NFRs are important for medical imaging applications.
The study was done on a single Danish hospital and found that NFRs of type
Efficiency, Accuracy, Interoperability, Reliability, Usability, Adaptability,
and Fairness were important to the stakeholders. Especially Efficiency since
the diagnostic imaging department is trying to spend as little time as possible
on each scan.

æè¦ï¼ç±æ¼å·¥ä½è² è¼å¢å ï¼è¨ºæ·å½±åé¨éæ¿åèæ¥µå¤§çå£åãæéææçæ¸éæ­£å¨å¢å ï¼èä¸åæ ¼çåååç­ç¼ºãé«çå½±åæç¨çäººå·¥æºæ§è§£æ±ºæ¹æ¡é¡¯ç¤ºåºå·¨å¤§çæ½åãç¶èï¼å¾å°æè¨ºæ·å½±åæ¨¡åè¢«æ¹åç¨æ¼é«é¢ï¼çè³æ´å°è¢«å¯¦æ½æ¼é«é¢ãè»é«å°æ¡å¤±æçæå¸¸è¦åå æ¯éæ±å·¥ç¨ä¸ä½³ï¼ç¹å¥æ¯éåè½æ§éæ± (NFR) å¯è½å°å°æ¡æå®³ãç ç©¶é¡¯ç¤ºï¼æ©å¨å­¸ç¿å°æ¥­äººå¡é£ä»¥ä½¿ç¨ NFRï¼ä¸¦ä¸éè¦å° NFR æ¡æ¶èª¿æ´çºæ©å¨å­¸ç¿ãåºæ¼ AI çè»é«ãæ¬ç ç©¶ä½¿ç¨å®æ§æ¹æ³èä¸»è¦å©å®³éä¿äººäºåï¼ä»¥æ¾åºåªäºé¡åç NFR å°é«å­¸å½±åæç¨ç¨å¼å¾éè¦ãè©²ç ç©¶å¨ä¸å®¶ä¸¹éº¥é«é¢é²è¡ï¼ç¼ç¾æçãæºç¢ºæ§ãäºæä½æ§ãå¯é æ§ãå¯ç¨æ§ãé©ææ§åå¬å¹³æ§é¡åç NFR å°å©å®³éä¿äººå¾éè¦ãç¹å¥æ¯æçï¼å çºè¨ºæ·å½±åé¨éæ­£åªåç¡å¯è½æ¸å°æ¯é æææè±çæéã

##### **Comprehensive and Practical Evaluation of Retrieval-Augmented Generation Systems for Medical Question Answering**
2411.09213v1 by Nghia Trung Ngo, Chien Van Nguyen, Franck Dernoncourt, Thien Huu Nguyen

Retrieval-augmented generation (RAG) has emerged as a promising approach to
enhance the performance of large language models (LLMs) in knowledge-intensive
tasks such as those from medical domain. However, the sensitive nature of the
medical domain necessitates a completely accurate and trustworthy system. While
existing RAG benchmarks primarily focus on the standard retrieve-answer
setting, they overlook many practical scenarios that measure crucial aspects of
a reliable medical system. This paper addresses this gap by providing a
comprehensive evaluation framework for medical question-answering (QA) systems
in a RAG setting for these situations, including sufficiency, integration, and
robustness. We introduce Medical Retrieval-Augmented Generation Benchmark
(MedRGB) that provides various supplementary elements to four medical QA
datasets for testing LLMs' ability to handle these specific scenarios.
Utilizing MedRGB, we conduct extensive evaluations of both state-of-the-art
commercial LLMs and open-source models across multiple retrieval conditions.
Our experimental results reveals current models' limited ability to handle
noise and misinformation in the retrieved documents. We further analyze the
LLMs' reasoning processes to provides valuable insights and future directions
for developing RAG systems in this critical medical domain.

æè¦ï¼æª¢ç´¢å¢å¼·çæï¼RAGï¼å·²æçºä¸ç¨®æåéçæ¹æ³ï¼å¯å¢å¼·å¤§åèªè¨æ¨¡åï¼LLMï¼å¨ç¥è­å¯éåä»»åä¸­çæè½ï¼ä¾å¦é«çé åçä»»åãç¶èï¼é«çé åçæææ§è³ªéè¦ä¸åå®å¨æºç¢ºä¸å¼å¾ä¿¡è³´çç³»çµ±ãéç¶ç¾æç RAG è©éåºæºä¸»è¦èéæ¼æ¨æºæª¢ç´¢åç­è¨­å®ï¼ä½å®åå¿½ç¥äºè¨±å¤è¡¡éå¯é é«çç³»çµ±ééµé¢åçå¯¦éæå¢ãæ¬æééæä¾ä¸åå¨é¢çè©éæ¶æ§ä¾è§£æ±ºéåå·®è·ï¼éåæ¶æ§é©ç¨æ¼éäºæå¢ç RAG è¨­å®ä¸­çé«çåç­ï¼QAï¼ç³»çµ±ï¼åæ¬åè¶³æ§ãæ´åæ§èç©©å¥æ§ãæåå¼å¥äºé«çæª¢ç´¢å¢å¼·çæè©éåºæºï¼MedRGBï¼ï¼å®çºååé«ç QA è³æéæä¾äºåç¨®è£ååç´ ï¼ä»¥æ¸¬è©¦ LLM èçéäºç¹å®æå¢ççè½åãå©ç¨ MedRGBï¼æåå°å¤ç¨®æª¢ç´¢æ¢ä»¶ä¸çææ°åæ¥­ LLM åéæºæ¨¡åé²è¡äºå»£æ³çè©éãæåçå¯¦é©çµæé¡¯ç¤ºï¼ç®åæ¨¡åèçæª¢ç´¢æä»¶ä¸­çéè¨åé¯èª¤è³è¨çè½åæéãæåé²ä¸æ­¥åæäº LLM çæ¨çç¨åºï¼çºå¨éåééµçé«çé åéç¼ RAG ç³»çµ±æä¾äºå¯¶è²´çè¦è§£åæªä¾çæ¹åã

##### **Advancing Diffusion Models: Alias-Free Resampling and Enhanced Rotational Equivariance**
2411.09174v1 by Md Fahim Anjum

Recent advances in image generation, particularly via diffusion models, have
led to impressive improvements in image synthesis quality. Despite this,
diffusion models are still challenged by model-induced artifacts and limited
stability in image fidelity. In this work, we hypothesize that the primary
cause of this issue is the improper resampling operation that introduces
aliasing in the diffusion model and a careful alias-free resampling dictated by
image processing theory can improve the model's performance in image synthesis.
We propose the integration of alias-free resampling layers into the UNet
architecture of diffusion models without adding extra trainable parameters,
thereby maintaining computational efficiency. We then assess whether these
theory-driven modifications enhance image quality and rotational equivariance.
Our experimental results on benchmark datasets, including CIFAR-10, MNIST, and
MNIST-M, reveal consistent gains in image quality, particularly in terms of FID
and KID scores. Furthermore, we propose a modified diffusion process that
enables user-controlled rotation of generated images without requiring
additional training. Our findings highlight the potential of theory-driven
enhancements such as alias-free resampling in generative models to improve
image quality while maintaining model efficiency and pioneer future research
directions to incorporate them into video-generating diffusion models, enabling
deeper exploration of the applications of alias-free resampling in generative
modeling.

æè¦ï¼å½±åçææè¡çææ°é²å±ï¼ç¹å¥æ¯ééæ´æ£æ¨¡åï¼å·²å¤§å¹æåå½±ååæåè³ªãåç®¡å¦æ­¤ï¼æ´æ£æ¨¡åä»åéæ¼æ¨¡åå¼ç¼çäººå·¥è£½åï¼ä¸å½±åä¿çåº¦ç©©å®æ§æéãå¨éé å·¥ä½ä¸­ï¼æååè¨­æ­¤åé¡çä¸»è¦åå æ¯ä¸é©ç¶çéæ°åæ¨£éç®ï¼éæå¨æ´æ£æ¨¡åä¸­å¼å¥æ··çï¼èç±å½±åèççè«æå°çä»ç´°ç¡æ··çéæ°åæ¨£å¯ä»¥æåæ¨¡åå¨å½±ååæçæè½ãæåå»ºè­°å°ç¡æ··çéæ°åæ¨£å±¤æ´åå°æ´æ£æ¨¡åç UNet æ¶æ§ä¸­ï¼èç¡é å¢å é¡å¤çå¯è¨ç·´åæ¸ï¼é²èç¶­æéç®æçãæ¥èæåè©ä¼°éäºçè«é©åçä¿®æ¹æ¯å¦è½æåå½±ååè³ªåæè½ç­è®æ§ãæåå¨åºæºè³æéï¼åæ¬ CIFAR-10ãMNIST å MNIST-Mï¼ä¸çå¯¦é©çµæé¡¯ç¤ºï¼å½±ååè³ªç²å¾ä¸è´çæåï¼ç¹å¥æ¯å¨ FID å KID åæ¸æ¹é¢ãæ­¤å¤ï¼æåæåºä¸åä¿®æ¹éçæ´æ£ç¨åºï¼å®è½è®ä½¿ç¨èæ§å¶çæå½±åçæè½ï¼èç¡éé¡å¤è¨ç·´ãæåçç¼ç¾çªé¡¯äºçè«é©åçå¼·åï¼ä¾å¦ç¡æ··çéæ°åæ¨£ï¼å¨çææ¨¡åä¸­çæ½åï¼å®è½å¨ç¶­ææ¨¡åæççåææåå½±ååè³ªï¼ä¸¦çºæªä¾ç ç©¶éææ¹åï¼å°å¶ç´å¥çæå½±ççæ´æ£æ¨¡åä¸­ï¼é²ä¸æ­¥æ¢ç´¢ç¡æ··çéæ°åæ¨£å¨çææ¨¡åä¸­çæç¨ã

##### **The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models**
2411.08870v1 by Daniel P. Jeong, Pranav Mani, Saurabh Garg, Zachary C. Lipton, Michael Oberst

Several recent works seek to develop foundation models specifically for
medical applications, adapting general-purpose large language models (LLMs) and
vision-language models (VLMs) via continued pretraining on publicly available
biomedical corpora. These works typically claim that such domain-adaptive
pretraining (DAPT) improves performance on downstream medical tasks, such as
answering medical licensing exam questions. In this paper, we compare ten
public "medical" LLMs and two VLMs against their corresponding base models,
arriving at a different conclusion: all medical VLMs and nearly all medical
LLMs fail to consistently improve over their base models in the zero-/few-shot
prompting and supervised fine-tuning regimes for medical question-answering
(QA). For instance, across all tasks and model pairs we consider in the 3-shot
setting, medical LLMs only outperform their base models in 22.7% of cases,
reach a (statistical) tie in 36.8% of cases, and are significantly worse than
their base models in the remaining 40.5% of cases. Our conclusions are based on
(i) comparing each medical model head-to-head, directly against the
corresponding base model; (ii) optimizing the prompts for each model separately
in zero-/few-shot prompting; and (iii) accounting for statistical uncertainty
in comparisons. While these basic practices are not consistently adopted in the
literature, our ablations show that they substantially impact conclusions.
Meanwhile, we find that after fine-tuning on specific QA tasks, medical LLMs
can show performance improvements, but the benefits do not carry over to tasks
based on clinical notes. Our findings suggest that state-of-the-art
general-domain models may already exhibit strong medical knowledge and
reasoning capabilities, and offer recommendations to strengthen the conclusions
of future studies.

æè¦ï¼<paragraph>æè¿æè¨±å¤ç ç©¶å°ééç¼é«çæç¨åºç¤æ¨¡åï¼ééæçºé è¨ç·´å¬éççç©é«å­¸èªæåº«ï¼æ¹ç·¨éç¨å¤§åèªè¨æ¨¡å (LLM) åè¦è¦ºèªè¨æ¨¡å (VLM)ãéäºç ç©¶éå¸¸è²ç¨±æ­¤é¡é åèªé©æé è¨ç·´ (DAPT) è½æåä¸æ¸¸é«çä»»åçæè½ï¼ä¾å¦åç­é«çå·ç§èè©¦é¡ç®ãå¨æ¬æä¸­ï¼æåæ¯è¼äºååå¬éçãé«çãLLM åå©å VLMï¼ä¸¦å°å¶èå°æçåºæ¬æ¨¡åé²è¡æ¯è¼ï¼å¾åºäºä¸åççµè«ï¼ææé«ç VLM åå¹¾ä¹ææé«ç LLM é½ç¡æ³å¨é«çåé¡è§£ç­ (QA) çé¶æ¬¡/å°æ¨£æ¬æç¤ºåç£ç£å¾®èª¿æ©å¶ä¸­æçºåªæ¼å¶åºæ¬æ¨¡åãä¾å¦ï¼å¨æåå¨ 3 æ¬¡åæ¨£è¨­å®ä¸­èéçææä»»ååæ¨¡åéå°ä¸­ï¼é«ç LLM åå¨ 22.7% çæ¡ä¾ä¸­åªæ¼å¶åºæ¬æ¨¡åï¼å¨ 36.8% çæ¡ä¾ä¸­éå°ï¼çµ±è¨ï¼å¹³æï¼èå¨å¶é¤ 40.5% çæ¡ä¾ä¸­åé¡¯èä½æ¼å¶åºæ¬æ¨¡åãæåççµè«åºæ¼ (i) å°æ¯åé«çæ¨¡åèå°æçåºæ¬æ¨¡åé²è¡ä¸å°ä¸æ¯è¼ï¼(ii) å¨é¶æ¬¡/å°æ¨£æ¬æç¤ºä¸­åå¥éå°æ¯åæ¨¡åæä½³åæç¤ºï¼ä»¥å (iii) å¨æ¯è¼ä¸­èéçµ±è¨ä¸ç¢ºå®æ§ãåç®¡éäºåºæ¬åæ³ä¸¦æªå¨æç»ä¸­ä¸è´æ¡ç¨ï¼ä½æåçæ¶èç ç©¶é¡¯ç¤ºï¼å®åå°çµè«æéå¤§å½±é¿ãåæï¼æåç¼ç¾ï¼å¨éå°ç¹å® QA ä»»åé²è¡å¾®èª¿å¾ï¼é«ç LLM å¯ä»¥å±ç¾æè½æåï¼ä½éäºå¥½èä¸¦æªå»¶çºå°åºæ¼è¨åºç­è¨çä»»åãæåçç ç©¶çµæè¡¨æï¼æåé²çéç¨é åæ¨¡åå¯è½å·²ç¶å±ç¾åºå¼·å¤§çé«çç¥è­åæ¨çè½åï¼ä¸¦æä¾å»ºè­°ä»¥å¼·åæªä¾ç ç©¶ççµè«ã</paragraph>

##### **MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics Classification**
2411.08703v1 by Shan Cong, Zhiling Sang, Hongwei Liu, Haoran Luo, Xin Wang, Hong Liang, Jie Hao, Xiaohui Yao

The distinct characteristics of multiomics data, including complex
interactions within and across biological layers and disease heterogeneity
(e.g., heterogeneity in etiology and clinical symptoms), drive us to develop
novel designs to address unique challenges in multiomics prediction. In this
paper, we propose the multi-view knowledge transfer learning (MVKTrans)
framework, which transfers intra- and inter-omics knowledge in an adaptive
manner by reviewing data heterogeneity and suppressing bias transfer, thereby
enhancing classification performance. Specifically, we design a graph
contrastive module that is trained on unlabeled data to effectively learn and
transfer the underlying intra-omics patterns to the supervised task. This
unsupervised pretraining promotes learning general and unbiased representations
for each modality, regardless of the downstream tasks. In light of the varying
discriminative capacities of modalities across different diseases and/or
samples, we introduce an adaptive and bi-directional cross-omics distillation
module. This module automatically identifies richer modalities and facilitates
dynamic knowledge transfer from more informative to less informative omics,
thereby enabling a more robust and generalized integration. Extensive
experiments on four real biomedical datasets demonstrate the superior
performance and robustness of MVKTrans compared to the state-of-the-art. Code
and data are available at https://github.com/Yaolab-fantastic/MVKTrans.

æè¦ï¼å¤çµå­¸è³æçç¨ç¹ç¹å¾µï¼åæ¬çç©å±¤å§åå±¤éçè¤éäº¤äºä½ç¨åç¾çç°è³ªæ§ï¼ä¾å¦ï¼çå åè¨åºçççç°è³ªæ§ï¼ï¼ä¿ä½¿æåéç¼æ°ç©çè¨­è¨ä¾æå°å¤çµå­¸é æ¸¬ä¸­çç¨ç¹ææ°ãå¨æ¬æä¸­ï¼æåæåºäºå¤è¦è§ç¥è­é·ç§»å­¸ç¿ (MVKTrans) æ¡æ¶ï¼å®ééå¯©æ¥æ¸æç°è³ªæ§åæå¶åå·®è½ç§»ï¼ä»¥èªé©æçæ¹å¼å³éçµå§åçµéç¥è­ï¼å¾èå¢å¼·åé¡æ§è½ãå·é«ä¾èªªï¼æåè¨­è¨äºä¸ååå°æ¯æ¨¡çµï¼å¨æªæ¨è¨æ¸æä¸é²è¡è¨ç·´ï¼ä»¥ææå°å­¸ç¿åå°çµå§æ¨¡å¼è½ç§»å°ç£ç£ä»»åä¸­ãéç¨®ç¡ç£ç£çé è¨ç·´ä¿é²äºå­¸ç¿ä¸è¬ä¸ç¡åå·®çè¡¨ç¤ºï¼é©ç¨æ¼æ¯åæ¨¡æï¼ç¡è«ä¸æ¸¸ä»»åçºä½ãéæ¼ä¸åç¾çå/ææ¨£æ¬ä¸­æ¨¡æçä¸åè¾¨å¥è½åï¼æåå¼å¥äºä¸åèªé©æä¸éåççµéç¥è­è¸é¤¾æ¨¡çµãæ­¤æ¨¡çµèªåè­å¥æ´è±å¯çæ¨¡æï¼ä¸¦ä¿é²å¾æ´æè³è¨æ§ççµå­¸å°è³è¨è¼å°ççµå­¸çåæç¥è­è½ç§»ï¼å¾èå¯¦ç¾æ´å¼·å¥ä¸æ´å»£æ³çæ´åãå°ååçå¯¦çç©é«å­¸è³æéçå»£æ³å¯¦é©è­æäº MVKTrans èæåé²æè¡ç¸æ¯å·æåªç°çæ§è½åå¼·å¥æ§ãç¨å¼ç¢¼åè³æå¯å¨ https://github.com/Yaolab-fantastic/MVKTrans åå¾ã

##### **TRACE: Transformer-based Risk Assessment for Clinical Evaluation**
2411.08701v1 by Dionysis Christopoulos, Sotiris Spanos, Valsamis Ntouskos, Konstantinos Karantzalos

We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation),
a novel method for clinical risk assessment based on clinical data, leveraging
the self-attention mechanism for enhanced feature interaction and result
interpretation. Our approach is able to handle different data modalities,
including continuous, categorical and multiple-choice (checkbox) attributes.
The proposed architecture features a shared representation of the clinical data
obtained by integrating specialized embeddings of each data modality, enabling
the detection of high-risk individuals using Transformer encoder layers. To
assess the effectiveness of the proposed method, a strong baseline based on
non-negative multi-layer perceptrons (MLPs) is introduced. The proposed method
outperforms various baselines widely used in the domain of clinical risk
assessment, while effectively handling missing values. In terms of
explainability, our Transformer-based method offers easily interpretable
results via attention weights, further enhancing the clinicians'
decision-making process.

æè¦ï¼æåæåº TRACEï¼è¨åºè©ä¼°çåºæ¼ Transformer çé¢¨éªè©ä¼°ï¼ï¼éæ¯ä¸ç¨®åºæ¼è¨åºæ¸æçè¨åºé¢¨éªè©ä¼°æ°æ¹æ³ï¼å©ç¨èªæ³¨æåæ©å¶å¢å¼·ç¹å¾µäº¤äºåçµæè§£è®ãæåçåæ³è½å¤ èçä¸åçæ¸ææ¨¡å¼ï¼åæ¬é£çºãåé¡åå¤é¸ï¼æ ¸åæ¹å¡ï¼å±¬æ§ãæè­°çæ¶æ§ç¹å¾µæ¯ééæ´åæ¯åæ¸ææ¨¡å¼çå°ç¨åµå¥ä¾ç²å¾è¨åºæ¸æçå±äº«è¡¨ç¤ºï¼å¾èè½å¤ ä½¿ç¨ Transformer ç·¨ç¢¼å¨å±¤æª¢æ¸¬é«é¢¨éªåé«ãçºäºè©ä¼°ææåºæ¹æ³çæææ§ï¼å¼å¥äºåºæ¼éè² å¤å±¤æç¥å¨ (MLP) çå¼·å¤§åºç·ãææåºçæ¹æ³åªæ¼è¨åºé¢¨éªè©ä¼°é åä¸­å»£æ³ä½¿ç¨çåç¨®åºç·ï¼åæææå°èçç¼ºå¤±å¼ãå¨å¯è§£éæ§æ¹é¢ï¼æååºæ¼ Transformer çæ¹æ³ééæ³¨æåæ¬éæä¾äºææ¼è§£éççµæï¼é²ä¸æ­¥å¢å¼·äºè¨åºé«ççæ±ºç­å¶å®éç¨ã

##### **Rethinking negative sampling in content-based news recommendation**
2411.08700v1 by Miguel Ãngelo Rebelo, JoÃ£o Vinagre, Ivo Pereira, Ãlvaro Figueira

News recommender systems are hindered by the brief lifespan of articles, as
they undergo rapid relevance decay. Recent studies have demonstrated the
potential of content-based neural techniques in tackling this problem. However,
these models often involve complex neural architectures and often lack
consideration for negative examples. In this study, we posit that the careful
sampling of negative examples has a big impact on the model's outcome. We
devise a negative sampling technique that not only improves the accuracy of the
model but also facilitates the decentralization of the recommendation system.
The experimental results obtained using the MIND dataset demonstrate that the
accuracy of the method under consideration can compete with that of
State-of-the-Art models. The utilization of the sampling technique is essential
in reducing model complexity and accelerating the training process, while
maintaining a high level of accuracy. Finally, we discuss how decentralized
models can help improve privacy and scalability.

æè¦ï¼æ°èæ¨è¦ç³»çµ±åå°æç« çå½é±æç­æ«çé»ç¤ï¼å çºå®åæå¿«éè¡°éãæè¿çç ç©¶å·²è­æåºæ¼å§å®¹çç¥ç¶æè¡å¨è§£æ±ºéååé¡ä¸çæ½åãç¶èï¼éäºæ¨¡åéå¸¸æ¶åè¤éçç¥ç¶æ¶æ§ï¼èä¸å¸¸å¸¸ç¼ºä¹å°è² é¢ç¯ä¾çèéãå¨éé ç ç©¶ä¸­ï¼æååè¨­è² é¢ç¯ä¾çä»ç´°æ½æ¨£å°æ¨¡åççµææå¾å¤§çå½±é¿ãæåè¨­è¨äºä¸ç¨®è² é¢æ½æ¨£æè¡ï¼å®ä¸åæé«äºæ¨¡åçæºç¢ºæ§ï¼éä¿è¿äºæ¨è¦ç³»çµ±çåæ£åãä½¿ç¨ MIND è³æéç²å¾çå¯¦é©çµæè­æï¼æèæ®æ¹æ³çæºç¢ºæ§å¯ä»¥èæåé²çæ¨¡åç¸åª²ç¾ãæ½æ¨£æè¡çä½¿ç¨å°æ¼éä½æ¨¡åè¤éæ§åå éè¨ç·´éç¨è³ééè¦ï¼åæä¿æé«æºç¢ºåº¦ãæå¾ï¼æåè¨è«äºåæ£å¼æ¨¡åå¦ä½æå©æ¼æ¹åé±ç§åå¯æ´å±æ§ã

##### **A Survey on Vision Autoregressive Model**
2411.08666v1 by Kai Jiang, Jiaxing Huang

Autoregressive models have demonstrated great performance in natural language
processing (NLP) with impressive scalability, adaptability and
generalizability. Inspired by their notable success in NLP field,
autoregressive models have been intensively investigated recently for computer
vision, which perform next-token predictions by representing visual data as
visual tokens and enables autoregressive modelling for a wide range of vision
tasks, ranging from visual generation and visual understanding to the very
recent multimodal generation that unifies visual generation and understanding
with a single autoregressive model. This paper provides a systematic review of
vision autoregressive models, including the development of a taxonomy of
existing methods and highlighting their major contributions, strengths, and
limitations, covering various vision tasks such as image generation, video
generation, image editing, motion generation, medical image analysis, 3D
generation, robotic manipulation, unified multimodal generation, etc. Besides,
we investigate and analyze the latest advancements in autoregressive models,
including thorough benchmarking and discussion of existing methods across
various evaluation datasets. Finally, we outline key challenges and promising
directions for future research, offering a roadmap to guide further
advancements in vision autoregressive models.

æè¦ï¼èªåæ­¸æ¨¡åå¨èªç¶èªè¨èç (NLP) ä¸­å±ç¾åºæ¥µä½³çæè½ï¼å·æä»¤äººå°è±¡æ·±å»çå¯æ´åæ§ãé©ææ§åæ¦æ¬æ§ãåå°å¶å¨ NLP é åçé¡¯èæååç¼ï¼èªåæ­¸æ¨¡åæè¿å·²å»£æ³ç¨æ¼é»è¦è¦è¦ºï¼ééå°è¦è¦ºè³æè¡¨ç¤ºçºè¦è¦ºç¬¦èï¼å·è¡ä¸ä¸åç¬¦èé æ¸¬ï¼ä¸¦éå°å»£æ³çè¦è¦ºä»»ååç¨èªåæ­¸å»ºæ¨¡ï¼å¾è¦è¦ºç¢çåè¦è¦ºçè§£ï¼å°æè¿çµåè¦è¦ºç¢çåçè§£çå®ä¸èªåæ­¸æ¨¡åçå¤æ¨¡æç¢çãæ¬æç³»çµ±æ§å°æ¢è¨è¦è¦ºèªåæ­¸æ¨¡åï¼åæ¬å¶å®ç¾ææ¹æ³çåé¡ï¼ä¸¦éé»èªªæå¶ä¸»è¦è²¢ç»ãåªé»åéå¶ï¼æ¶µèåç¨®è¦è¦ºä»»åï¼ä¾å¦å½±åç¢çãå½±çç¢çãå½±åç·¨è¼¯ãåä½ç¢çãé«å­¸å½±ååæã3D ç¢çãæ©å¨äººæä½ãçµ±ä¸å¤æ¨¡æç¢çç­ãæ­¤å¤ï¼æåæ¢è¨ä¸¦åæèªåæ­¸æ¨¡åçææ°é²å±ï¼åæ¬å¾¹åºçåºæºæ¸¬è©¦åè·¨åç¨®è©ä¼°è³æéçç¾ææ¹æ³è¨è«ãæå¾ï¼æåæ¦è¿°è¦è¦ºèªåæ­¸æ¨¡åæªä¾ç ç©¶çä¸»è¦ææ°åæåæ¯çæ¹åï¼æä¾ä¸åè·¯ç·åï¼ä»¥å¼å°èªåæ­¸æ¨¡åé²ä¸æ­¥çé²å±ã

##### **Optimizing Automatic Summarization of Long Clinical Records Using Dynamic Context Extension:Testing and Evaluation of the NBCE Method**
2411.08586v2 by Guoqing Zhang, Keita Fukuyama, Kazumasa Kishimoto, Tomohiro Kuroda

Summarizing patient clinical notes is vital for reducing documentation
burdens. Current manual summarization makes medical staff struggle. We propose
an automatic method using LLMs, but long inputs cause LLMs to lose context,
reducing output quality especially in small size model. We used a 7B model,
open-calm-7b, enhanced with Native Bayes Context Extend and a redesigned
decoding mechanism to reference one sentence at a time, keeping inputs within
context windows, 2048 tokens. Our improved model achieved near parity with
Google's over 175B Gemini on ROUGE-L metrics with 200 samples, indicating
strong performance using less resources, enhancing automated EMR summarization
feasibility.

æè¦ï¼æè¦çæ£è¨åºç­è¨å°æ¼æ¸è¼æä»¶è² æè³ééè¦ãç®åçæè¦æåè®é«çäººå¡é£ä»¥æä»ãæåæåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªååæ¹æ³ï¼ä½éé·çè¼¸å¥æå°è´å¤§åèªè¨æ¨¡åå¤±å»ä¸ä¸æï¼éä½è¼¸åºåè³ªï¼ç¹å¥æ¯å¨å°åæ¨¡åä¸­ãæåä½¿ç¨ä¸å 7B æ¨¡åï¼open-calm-7bï¼ä¸¦æ­é Native Bayes Context Extend åéæ°è¨­è¨çè§£ç¢¼æ©å¶ï¼ä¸æ¬¡åèä¸åå¥å­ï¼å°è¼¸å¥ä¿æå¨ä¸ä¸æè¦çªä¸­ï¼2048 åç¬¦èãæåæ¹é²çæ¨¡åå¨ ROUGE-L ææ¨ä¸éå°æ¥è¿ Google è¶é 175B ç Geminiï¼æ 200 åç¯æ¬ï¼è¡¨ç¤ºä½¿ç¨è¼å°è³æºå°±è½æå¼·å¤§çæè½ï¼æåèªååé»å­çæ­·æè¦çå¯è¡æ§ã

##### **A Heterogeneous Graph Neural Network Fusing Functional and Structural Connectivity for MCI Diagnosis**
2411.08424v1 by Feiyu Yin, Yu Lei, Siyuan Dai, Wenwen Zeng, Guoqing Wu, Liang Zhan, Jinhua Yu

Brain connectivity alternations associated with brain disorders have been
widely reported in resting-state functional imaging (rs-fMRI) and diffusion
tensor imaging (DTI). While many dual-modal fusion methods based on graph
neural networks (GNNs) have been proposed, they generally follow homogenous
fusion ways ignoring rich heterogeneity of dual-modal information. To address
this issue, we propose a novel method that integrates functional and structural
connectivity based on heterogeneous graph neural networks (HGNNs) to better
leverage the rich heterogeneity in dual-modal images. We firstly use blood
oxygen level dependency and whiter matter structure information provided by
rs-fMRI and DTI to establish homo-meta-path, capturing node relationships
within the same modality. At the same time, we propose to establish
hetero-meta-path based on structure-function coupling and brain community
searching to capture relations among cross-modal nodes. Secondly, we further
introduce a heterogeneous graph pooling strategy that automatically balances
homo- and hetero-meta-path, effectively leveraging heterogeneous information
and preventing feature confusion after pooling. Thirdly, based on the
flexibility of heterogeneous graphs, we propose a heterogeneous graph data
augmentation approach that can conveniently address the sample imbalance issue
commonly seen in clinical diagnosis. We evaluate our method on ADNI-3 dataset
for mild cognitive impairment (MCI) diagnosis. Experimental results indicate
the proposed method is effective and superior to other algorithms, with a mean
classification accuracy of 93.3%.

æè¦ï¼è¦é¨é£éæ§è®åèè¦é¨ç¾ççéè¯æ§å·²å¨éæåè½æ§å½±å (rs-fMRI) åæ´æ£å¼µéå½±å (DTI) ä¸­å»£æ³å ±å°ãéç¶å·²ç¶æåºè¨±å¤åºæ¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) çéæ¨¡æèåæ¹æ³ï¼ä½å®åéå¸¸éµå¾ªåè³ªèåæ¹å¼ï¼å¿½ç¥äºéæ¨¡æè³è¨çè±å¯ç°è³ªæ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ°æ¹æ³ï¼å®æ´åäºåºæ¼ç°è³ªåå½¢ç¥ç¶ç¶²è·¯ (HGNN) çåè½æ§åçµæ§æ§é£éæ§ï¼ä»¥æ´å¥½å°å©ç¨éæ¨¡æå½±åä¸­çè±å¯ç°è³ªæ§ãæåé¦åä½¿ç¨ rs-fMRI å DTI æä¾çè¡æ°§æ¿åº¦ä¾è³´æ§åç½è³ªçµæ§è³è¨ä¾å»ºç«åè³ªåè·¯å¾ï¼ææåä¸æ¨¡å¼å§çç¯é»éä¿ãåæï¼æåæè­°å»ºç«åºæ¼çµæ§åè½è¦ååè¦é¨ç¤¾ç¾¤æå°çç°è³ªåè·¯å¾ï¼ä»¥ææè·¨æ¨¡å¼ç¯é»ä¹éçéä¿ãå¶æ¬¡ï¼æåé²ä¸æ­¥å¼å¥äºä¸åç°è³ªåå½¢æ± åç­ç¥ï¼è©²ç­ç¥èªåå¹³è¡¡åè³ªåç°è³ªåè·¯å¾ï¼ææå©ç¨ç°è³ªè³è¨ä¸¦é²æ­¢æ± åå¾ç¹å¾µæ··æ·ãç¬¬ä¸ï¼åºæ¼ç°è³ªåå½¢çéæ´»æ§ï¼æåæåºäºä¸ç¨®ç°è³ªåå½¢è³ææ´åæ¹æ³ï¼å¯ä»¥æ¹ä¾¿å°è§£æ±ºè¨åºè¨ºæ·ä¸­å¸¸è¦çæ¨£æ¬ä¸å¹³è¡¡åé¡ãæåå¨ ADNI-3 è³æéä¸è©ä¼°äºæåçæ¹æ³ï¼ç¨æ¼è¼åº¦èªç¥éç¤ (MCI) è¨ºæ·ãå¯¦é©çµæè¡¨æï¼ææåºçæ¹æ³ææä¸åªæ¼å¶ä»æ¼ç®æ³ï¼å¹³ååé¡æºç¢ºççº 93.3%ã

##### **A Fuzzy Reinforcement LSTM-based Long-term Prediction Model for Fault Conditions in Nuclear Power Plants**
2411.08370v1 by Siwei Li, Jiayan Fang, Yichun Wua, Wei Wang, Chengxin Li, Jiangwen Chen

Early fault detection and timely maintenance scheduling can significantly
mitigate operational risks in NPPs and enhance the reliability of operator
decision-making. Therefore, it is necessary to develop an efficient Prognostics
and Health Management (PHM) multi-step prediction model for predicting of
system health status and prompt execution of maintenance operations. In this
study, we propose a novel predictive model that integrates reinforcement
learning with Long Short-Term Memory (LSTM) neural networks and the Expert
Fuzzy Evaluation Method. The model is validated using parameter data for 20
different breach sizes in the Main Steam Line Break (MSLB) accident condition
of the CPR1000 pressurized water reactor simulation model and it demonstrates a
remarkable capability in accurately forecasting NPP parameter changes up to 128
steps ahead (with a time interval of 10 seconds per step, i.e., 1280 seconds),
thereby satisfying the temporal advance requirement for fault prognostics in
NPPs. Furthermore, this method provides an effective reference solution for PHM
applications such as anomaly detection and remaining useful life prediction.

æè¦ï¼æ©ææéåµæ¸¬ååæç¶­è­·æç¨å¯ä»¥é¡¯èéä½æ ¸è½é»å» ççéé¢¨éªï¼ä¸¦æåæä½äººå¡æ±ºç­çå¯é æ§ãå æ­¤ï¼æå¿è¦éç¼ä¸åé«æçé æ¸¬èå¥åº·ç®¡ç (PHM) å¤æ­¥é©é æ¸¬æ¨¡åï¼ç¨æ¼é æ¸¬ç³»çµ±å¥åº·çæååæå·è¡ç¶­è­·ä½æ¥­ãå¨æ­¤ç ç©¶ä¸­ï¼æåæåºä¸ååµæ°çé æ¸¬æ¨¡åï¼å®æ´åäºå¼·åå­¸ç¿èé·æç­æè¨æ¶ (LSTM) ç¥ç¶ç¶²è·¯åå°å®¶æ¨¡ç³è©ä¼°æ¹æ³ãè©²æ¨¡åä½¿ç¨ CPR1000 å å£æ°´åæçæ¨¡æ¬æ¨¡åä¸­ä¸»è¸æ±½ç®¡ç ´è£ (MSLB) äºææ¢ä»¶ä¸ 20 ç¨®ä¸åç ´è£å°ºå¯¸çåæ¸è³æé²è¡é©è­ï¼å®å±ç¾åºæºç¢ºé æ¸¬æ ¸è½é»å» åæ¸è®åé·é 128 åæ­¥é©ï¼æ¯åæ­¥é©çæéééçº 10 ç§ï¼å³ 1280 ç§ï¼çåè¶è½åï¼å¾èæ»¿è¶³æ ¸è½é»å» æéé æ¸¬çæéæåéæ±ãæ­¤å¤ï¼æ­¤æ¹æ³çºç°å¸¸åµæ¸¬åå©é¤ä½¿ç¨å£½å½é æ¸¬ç­ PHM æç¨æä¾äºä¸åææçåèè§£æ±ºæ¹æ¡ã

##### **TowerDebias: A Novel Debiasing Method based on the Tower Property**
2411.08297v1 by Norman Matloff, Aditya Mittal

Decision-making processes have increasingly come to rely on sophisticated
machine learning tools, raising concerns about the fairness of their
predictions with respect to any sensitive groups. The widespread use of
commercial black-box machine learning models necessitates careful consideration
of their legal and ethical implications on consumers. In situations where users
have access to these "black-box" models, a key question emerges: how can we
mitigate or eliminate the influence of sensitive attributes, such as race or
gender? We propose towerDebias (tDB), a novel approach designed to reduce the
influence of sensitive variables in predictions made by black-box models. Using
the Tower Property from probability theory, tDB aims to improve prediction
fairness during the post-processing stage in a manner amenable to the
Fairness-Utility Tradeoff. This method is highly flexible, requiring no prior
knowledge of the original model's internal structure, and can be extended to a
range of different applications. We provide a formal improvement theorem for
tDB and demonstrate its effectiveness in both regression and classification
tasks, underscoring its impact on the fairness-utility tradeoff.

æè¦ï¼æ±ºç­å¶å®éç¨è¶ä¾è¶ä¾è³´æ¼åé²æ©å¨å­¸ç¿å·¥å·ï¼éå¼èµ·äºäººåå°å¶é æ¸¬çå¬å¹³æ§æ¯å¦æå°ä»»ä½ææç¾¤é«é æå½±é¿çææãåæ¥­é»çæ©å¨å­¸ç¿æ¨¡åçå»£æ³ä½¿ç¨éè¦ä»ç´°èæ®å¶å°æ¶è²»èçæ³å¾åéå¾·å½±é¿ãå¨ä½¿ç¨èè½å¤ ä½¿ç¨éäºãé»çãæ¨¡åçææ³ä¸ï¼ä¸åééµåé¡æµ®ç¾ï¼æåå¦ä½æ¸è¼ææ¶é¤ææå±¬æ§ï¼ä¾å¦ç¨®æææ§å¥ï¼çå½±é¿ï¼æåæåº towerDebias (tDB)ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼æ¨å¨æ¸å°é»çæ¨¡åæåé æ¸¬ä¸­ææè®æ¸çå½±é¿ãtDB ä½¿ç¨æ©çè«ä¸­ç Tower å±¬æ§ï¼æ¨å¨ä»¥æå©æ¼å¬å¹³æ§-æç¨æ¬è¡¡çæ¹å¼å¨å¾èçéæ®µæ¹åé æ¸¬å¬å¹³æ§ãæ­¤æ¹æ³éå¸¸éæ´»ï¼ä¸éè¦äºåäºè§£åå§æ¨¡åçå§é¨çµæ§ï¼ä¸¦ä¸å¯ä»¥æ´å±å°åç¨®ä¸åçæç¨ç¨å¼ãæåçº tDB æä¾äºæ­£å¼çæ¹é²å®çï¼ä¸¦å±ç¤ºäºå®å¨è¿´æ­¸ååé¡ä»»åä¸­çæææ§ï¼å¼·èª¿äºå®å°å¬å¹³æ§-æç¨æ¬è¡¡çå½±é¿ã

##### **Scaling Properties of Diffusion Models for Perceptual Tasks**
2411.08034v2 by Rahul Ravishankar, Zeeshan Patel, Jathushan Rajasegaran, Jitendra Malik

In this paper, we argue that iterative computation with diffusion models
offers a powerful paradigm for not only generation but also visual perception
tasks. We unify tasks such as depth estimation, optical flow, and amodal
segmentation under the framework of image-to-image translation, and show how
diffusion models benefit from scaling training and test-time compute for these
perceptual tasks. Through a careful analysis of these scaling properties, we
formulate compute-optimal training and inference recipes to scale diffusion
models for visual perception tasks. Our models achieve competitive performance
to state-of-the-art methods using significantly less data and compute. To
access our code and models, see https://scaling-diffusion-perception.github.io .

æè¦ï¼å¨æ¬æä¸­ï¼æåä¸»å¼µä½¿ç¨æ´æ£æ¨¡åé²è¡åè¦éç®ï¼æä¾äºä¸åå¼·å¤§çç¯ä¾ï¼ä¸åé©ç¨æ¼çæï¼ä¹é©ç¨æ¼è¦è¦ºæç¥ä»»åãæåçµ±ä¸äºæ·±åº¦ä¼°è¨ãåæµåéæ¨¡æåå²ç­ä»»åï¼å¨ååå°ååè½æçæ¡æ¶ä¸ï¼ä¸¦å±ç¤ºäºæ´æ£æ¨¡åå¦ä½åçæ¼æ´å±è¨ç·´åæ¸¬è©¦æéè¨ç®ï¼ä»¥å·è¡éäºæç¥ä»»åãééä»ç´°åæéäºç¸®æ¾å±¬æ§ï¼æåå¶å®äºè¨ç®æä½³è¨ç·´åæ¨è«éæ¹ï¼ä»¥æ´å±æ´æ£æ¨¡åï¼ç¨æ¼è¦è¦ºæç¥ä»»åãæåçæ¨¡åä½¿ç¨é¡¯èæ´å°æ¸æåè¨ç®ï¼éå°äºèæåé²æ¹æ³ç¸ç¶çæè½ãè¥è¦å­åæåçç¨å¼ç¢¼åæ¨¡åï¼è«åé± https://scaling-diffusion-perception.github.ioã

##### **Investigating the Effectiveness of Explainability Methods in Parkinson's Detection from Speech**
2411.08013v2 by Eleonora Mancini, Francesco Paissan, Paolo Torroni, Mirco Ravanelli, Cem Subakan

Speech impairments in Parkinson's disease (PD) provide significant early
indicators for diagnosis. While models for speech-based PD detection have shown
strong performance, their interpretability remains underexplored. This study
systematically evaluates several explainability methods to identify PD-specific
speech features, aiming to support the development of accurate, interpretable
models for clinical decision-making in PD diagnosis and monitoring. Our
methodology involves (i) obtaining attributions and saliency maps using
mainstream interpretability techniques, (ii) quantitatively evaluating the
faithfulness of these maps and their combinations obtained via union and
intersection through a range of established metrics, and (iii) assessing the
information conveyed by the saliency maps for PD detection from an auxiliary
classifier. Our results reveal that, while explanations are aligned with the
classifier, they often fail to provide valuable information for domain experts.

æè¦ï¼å¸éæ£®æ°ç (PD) çè¨èªéç¤æä¾äºéè¦çæ©æè¨ºæ·ææ¨ãéç¶åºæ¼è¨èªç PD æª¢æ¸¬æ¨¡åå·²é¡¯ç¤ºåºå¼·åçæè½ï¼ä½å¶å¯è§£éæ§ä»æªå¾å°ååæ¢è¨ãæ¬ç ç©¶ç³»çµ±æ§å°è©ä¼°äºå¹¾ç¨®å¯è§£éæ§æ¹æ³ï¼ä»¥è­å¥ PD ç¹æçè¨èªç¹å¾µï¼æ¨å¨æ¯æ´éç¼æºç¢ºãå¯è§£éçæ¨¡åï¼ç¨æ¼ PD è¨ºæ·åç£æ¸¬ä¸­çè¨åºæ±ºç­ãæåçç ç©¶æ¹æ³åæ¬ï¼(i) ä½¿ç¨ä¸»æµå¯è§£éæ§æè¡ç²å¾æ­¸å åé¡¯èæ§åï¼(ii) å®éè©ä¼°éäºååå¶ééè¯éåäº¤éç²å¾ççµåçå¿ å¯¦åº¦ï¼ééä¸ç³»åå·²å»ºç«çææ¨ï¼ä»¥å (iii) è©ä¼°é¡¯èæ§åå³éçè³è¨ï¼ç¨æ¼è¼å©åé¡å¨ç PD æª¢æ¸¬ãæåççµæè¡¨æï¼éç¶è§£éèåé¡å¨ä¸è´ï¼ä½å®åéå¸¸ç¡æ³çºé åå°å®¶æä¾æå¹å¼çè³è¨ã

##### **DuoLift-GAN:Reconstructing CT from Single-view and Biplanar X-Rays with Generative Adversarial Networks**
2411.07941v1 by Zhaoxi Zhang, Yueliang Ying

Computed tomography (CT) provides highly detailed three-dimensional (3D)
medical images but is costly, time-consuming, and often inaccessible in
intraoperative settings (Organization et al. 2011). Recent advancements have
explored reconstructing 3D chest volumes from sparse 2D X-rays, such as
single-view or orthogonal double-view images. However, current models tend to
process 2D images in a planar manner, prioritizing visual realism over
structural accuracy. In this work, we introduce DuoLift Generative Adversarial
Networks (DuoLift-GAN), a novel architecture with dual branches that
independently elevate 2D images and their features into 3D representations.
These 3D outputs are merged into a unified 3D feature map and decoded into a
complete 3D chest volume, enabling richer 3D information capture. We also
present a masked loss function that directs reconstruction towards critical
anatomical regions, improving structural accuracy and visual quality. This
paper demonstrates that DuoLift-GAN significantly enhances reconstruction
accuracy while achieving superior visual realism compared to existing methods.

æè¦ï¼é»è¦æ·å±¤ææ (CT) è½æä¾é«åº¦è©³ç´°çä¸ç¶­ (3D) é«å­¸å½±åï¼ä½æè²´ãèæä¸å¨è¡ä¸­ç°å¢ä¸­éå¸¸ç¡æ³åå¾ (Organization et al. 2011)ãæè¿çé²å±æ¢ç´¢å¾ç¨çç 2D X åéå»º 3D è¸é¨é«ç©ï¼ä¾å¦å®è¦åææ­£äº¤éè¦åå½±åãç¶èï¼ç®åçæ¨¡åå¾åæ¼ä»¥å¹³é¢æ¹å¼èç 2D å½±åï¼åªåèæ®è¦è¦ºçå¯¦æ§èéçµæ§æºç¢ºæ§ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº DuoLift çæå°æç¶²è·¯ (DuoLift-GAN)ï¼ä¸ç¨®å·æéåæ¯çæ°ç©æ¶æ§ï¼å¯ç¨ç«å°å° 2D å½±ååå¶ç¹å¾µæåå° 3D è¡¨ç¾å½¢å¼ãéäº 3D è¼¸åºæåä½µæä¸åçµ±ä¸ç 3D ç¹å¾µåï¼ä¸¦è§£ç¢¼æä¸åå®æ´ç 3D è¸é¨é«ç©ï¼å¾èè½å¤ æ·åæ´è±å¯ç 3D è³è¨ãæåä¹æåºäºä¸åé®ç½©æå¤±å½æ¸ï¼å°éå»ºå°åééµè§£åååï¼æ¹åçµæ§æºç¢ºæ§åè¦è¦ºåè³ªãéç¯è«æè­æäº DuoLift-GAN èç¾ææ¹æ³ç¸æ¯ï¼é¡¯èæåäºéå»ºæºç¢ºæ§ï¼åæéå°äºåè¶çè¦è¦ºçå¯¦æ§ã

##### **Automatic dataset shift identification to support root cause analysis of AI performance drift**
2411.07940v2 by MÃ©lanie Roschewitz, Raghav Mehta, Charles Jones, Ben Glocker

Shifts in data distribution can substantially harm the performance of
clinical AI models. Hence, various methods have been developed to detect the
presence of such shifts at deployment time. However, root causes of dataset
shifts are varied, and the choice of shift mitigation strategies is highly
dependent on the precise type of shift encountered at test time. As such,
detecting test-time dataset shift is not sufficient: precisely identifying
which type of shift has occurred is critical. In this work, we propose the
first unsupervised dataset shift identification framework, effectively
distinguishing between prevalence shift (caused by a change in the label
distribution), covariate shift (caused by a change in input characteristics)
and mixed shifts (simultaneous prevalence and covariate shifts). We discuss the
importance of self-supervised encoders for detecting subtle covariate shifts
and propose a novel shift detector leveraging both self-supervised encoders and
task model outputs for improved shift detection. We report promising results
for the proposed shift identification framework across three different imaging
modalities (chest radiography, digital mammography, and retinal fundus images)
on five types of real-world dataset shifts, using four large publicly available
datasets.

æè¦ï¼æ¸æåä½çè½è®æå¤§å¹å½±é¿è¨åº AI æ¨¡åçæè½ãå æ­¤ï¼å·²éç¼åºåç¨®æ¹æ³ä¾åµæ¸¬é¨ç½²æåºç¾æ­¤é¡è½è®ãç¶èï¼è³æéè½è®çæ ¹æ¬åå åä¸ç¸åï¼èè½è®ç·©è§£ç­ç¥çé¸æé«åº¦ä¾è³´æ¼æ¸¬è©¦æéå°çè½è®é¡åãå æ­¤ï¼åµæ¸¬æ¸¬è©¦æè³æéè½è®ä¸¦ä¸è¶³å¤ ï¼ç²¾ç¢ºè­å¥ç¼çä½ç¨®é¡åçè½è®è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåæåºç¬¬ä¸åç¡ç£ç£è³æéè½è®è­å¥æ¶æ§ï¼ææååæµè¡çè½è®ï¼ç±æ¨ç±¤åä½çè®åå¼èµ·ï¼ãå±è®éè½è®ï¼ç±è¼¸å¥ç¹å¾µçè®åå¼èµ·ï¼åæ··åè½è®ï¼åæç¼çæµè¡çåå±è®éè½è®ï¼ãæåè¨è«äºèªç£ç£ç·¨ç¢¼å¨å¨åµæ¸¬ç´°å¾®å±è®éè½è®ä¸­çéè¦æ§ï¼ä¸¦æåºäºä¸ç¨®æ°ç©çè½è®åµæ¸¬å¨ï¼å®åæå©ç¨èªç£ç£ç·¨ç¢¼å¨åä»»åæ¨¡åè¼¸åºï¼ä»¥æ¹åè½è®åµæ¸¬ãæåå ±åäºææåºçè½è®è­å¥æ¶æ§å¨ä¸ç¨®ä¸åå½±åæ¨¡å¼ï¼è¸é¨ X åãæ¸ä½ä¹³æ¿æå½±åè¦ç¶²èç¼åºå½±åï¼ä¸­éå°äºç¨®é¡åççå¯¦ä¸çè³æéè½è®æç²å¾çä»¤äººæ»¿æççµæï¼ä¸¦ä½¿ç¨äºååå¤§åå¬éè³æéã

##### **INTRABENCH: Interactive Radiological Benchmark**
2411.07885v1 by Constantin Ulrich, Tassilo Wald, Emily Tempus, Maximilian Rokuss, Paul F. Jaeger, Klaus Maier-Hein

Current interactive segmentation approaches, inspired by the success of
META's Segment Anything model, have achieved notable advancements, however,
they come with substantial limitations that hinder their practical application
in real clinical scenarios. These include unrealistic human interaction
requirements, such as slice-by-slice operations for 2D models on 3D data, a
lack of iterative refinement, and insufficient evaluation experiments. These
shortcomings prevent accurate assessment of model performance and lead to
inconsistent outcomes across studies. IntRaBench overcomes these challenges by
offering a comprehensive and reproducible framework for evaluating interactive
segmentation methods in realistic, clinically relevant scenarios. It includes
diverse datasets, target structures, and segmentation models, and provides a
flexible codebase that allows seamless integration of new models and prompting
strategies. Additionally, we introduce advanced techniques to minimize
clinician interaction, ensuring fair comparisons between 2D and 3D models. By
open-sourcing IntRaBench, we invite the research community to integrate their
models and prompting techniques, ensuring continuous and transparent evaluation
of interactive segmentation models in 3D medical imaging.

æè¦ï¼ç®åäºåå¼åå²æ¹æ³åå° META ç Segment Anything æ¨¡åæåçåç¼ï¼å·²åå¾é¡¯èé²å±ï¼ä½å®åä»æå¾å¤§çéå¶ï¼æé»ç¤å®åå¨å¯¦éè¨åºå ´æ¯ä¸­çæç¨ãéäºéå¶åæ¬ä¸åå¯¦éçäººæ©äºåéæ±ï¼ä¾å¦ 3D è³æä¸ç 2D æ¨¡åçéå±¤æä½ãç¼ºä¹åè¦æ¹é²ä»¥åè©ä¼°å¯¦é©ä¸è¶³ãéäºç¼ºé»æå¦¨ç¤æºç¢ºè©ä¼°æ¨¡åæè½ï¼ä¸¦å°è´åé ç ç©¶çµæä¸ä¸è´ãIntRaBench åæäºéäºææ°ï¼æä¾äºä¸åå¨é¢ä¸å¯éç¾çæ¶æ§ï¼ç¨æ¼è©ä¼°å¯¦éè¨åºç¸éå ´æ¯ä¸­çäºåå¼åå²æ¹æ³ãå®åå«å¤åçè³æéãç®æ¨çµæ§ååå²æ¨¡åï¼ä¸¦æä¾äºä¸åå½æ§çç¨å¼ç¢¼åº«ï¼åè¨±ç¡ç¸«æ´åæ°çæ¨¡ååæç¤ºç­ç¥ãæ­¤å¤ï¼æåå¼é²äºåé²æè¡ä¾æå°åè¨åºé«å¸«çäºåï¼ç¢ºä¿ 2D å 3D æ¨¡åä¹éçå¬å¹³æ¯è¼ãéééæ¾åå§ç¢¼ IntRaBenchï¼æåéè«ç ç©¶ç¤¾ç¾¤æ´åä»åçæ¨¡ååæç¤ºæè¡ï¼ç¢ºä¿å¨ 3D é«å­¸å½±åä¸­æçºä¸éæå°è©ä¼°äºåå¼åå²æ¨¡åã

##### **Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in Alzheimer's Disease**
2411.07871v1 by Francesco Chiumento, Mingming Liu

The rapid advancements in Large Language Models (LLMs) and Vision-Language
Models (VLMs) have shown great potential in medical diagnostics, particularly
in radiology, where datasets such as X-rays are paired with human-generated
diagnostic reports. However, a significant research gap exists in the
neuroimaging field, especially for conditions such as Alzheimer's disease, due
to the lack of comprehensive diagnostic reports that can be utilized for model
fine-tuning. This paper addresses this gap by generating synthetic diagnostic
reports using GPT-4o-mini on structured data from the OASIS-4 dataset, which
comprises 663 patients. Using the synthetic reports as ground truth for
training and validation, we then generated neurological reports directly from
the images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.
Our proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,
and METEOR score of 0.4163, revealing its potential in generating clinically
relevant and accurate diagnostic reports.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) åè¦è¦ºèªè¨æ¨¡å (VLM) çå¿«éé²å±å¨é«å­¸è¨ºæ·ä¸­å±ç¾äºå·¨å¤§çæ½åï¼ç¹å¥æ¯å¨æ¾å°å­¸ä¸­ï¼å¶ä¸­ X å°ç·ç­æ¸æéèäººé¡ç¢ççè¨ºæ·å ±åéå°ãç¶èï¼ç¥ç¶å½±åé åå­å¨èé¡¯èçç ç©¶å·®è·ï¼ç¹å¥æ¯å°æ¼é¿è²æµ·é»çç­ç¾çï¼å çºç¼ºä¹å¯ä¾æ¨¡åå¾®èª¿ä½¿ç¨çå¨é¢è¨ºæ·å ±åãæ¬æééä½¿ç¨ GPT-4o-mini å¨ä¾èª OASIS-4 æ¸æéççµæ§åæ¸æä¸çæåæè¨ºæ·å ±åä¾è§£æ±ºéä¸å·®è·ï¼è©²æ¸æéåå« 663 åæ£èãä½¿ç¨åæå ±åä½çºè¨ç·´åé©è­ççå¯¦æ¸æï¼ç¶å¾æåç´æ¥å¾æ¸æéä¸­çååä¸­çæç¥ç¶å ±åï¼å©ç¨é åè¨ç·´ç BiomedCLIP å T5 æ¨¡åãæåæåºçæ¹æ³å¯¦ç¾äº BLEU-4 åæ¸çº 0.1827ãROUGE-L åæ¸çº 0.3719 å METEOR åæ¸çº 0.4163ï¼æ­ç¤ºäºå¶çæè¨åºç¸éä¸æºç¢ºçè¨ºæ·å ±åçæ½åã

##### **PatchCTG: Patch Cardiotocography Transformer for Antepartum Fetal Health Monitoring**
2411.07796v1 by M. Jaleed Khan, Manu Vatish, Gabriel Davis Jones

Antepartum Cardiotocography (CTG) is vital for fetal health monitoring, but
traditional methods like the Dawes-Redman system are often limited by high
inter-observer variability, leading to inconsistent interpretations and
potential misdiagnoses. This paper introduces PatchCTG, a transformer-based
model specifically designed for CTG analysis, employing patch-based
tokenisation, instance normalisation and channel-independent processing to
capture essential local and global temporal dependencies within CTG signals.
PatchCTG was evaluated on the Oxford Maternity (OXMAT) dataset, comprising over
20,000 CTG traces across diverse clinical outcomes after applying the inclusion
and exclusion criteria. With extensive hyperparameter optimisation, PatchCTG
achieved an AUC of 77%, with specificity of 88% and sensitivity of 57% at
Youden's index threshold, demonstrating adaptability to various clinical needs.
Testing across varying temporal thresholds showed robust predictive
performance, particularly with finetuning on data closer to delivery, achieving
a sensitivity of 52% and specificity of 88% for near-delivery cases. These
findings suggest the potential of PatchCTG to enhance clinical decision-making
in antepartum care by providing a reliable, objective tool for fetal health
assessment. The source code is available at
https://github.com/jaleedkhan/PatchCTG.

æè¦ï¼ç¢åèåå¿æå (CTG) å°æ¼èåå¥åº·ç£æ¸¬è³ééè¦ï¼ä½å³çµ±æ¹æ³ï¼å¦ Dawes-Redman ç³»çµ±ï¼éå¸¸åå°é«è§å¯èéè®ç°æ§çéå¶ï¼å°è´è§£éä¸ä¸è´åæ½å¨çèª¤è¨ºãæ¬æä»ç´¹ PatchCTGï¼ä¸ç¨®å°éè¨­è¨ç¨æ¼ CTG åæçåºæ¼Transformerçæ¨¡åï¼æ¡ç¨åºæ¼åå¡çæ¨è¨åãå¯¦ä¾æ­£è¦ååééç¨ç«èçï¼ä»¥ææ CTG ä¿¡èä¸­çåºæ¬å±é¨åå¨å±æéä¾è³´æ§ãPatchCTG å¨çæ´¥å©¦ç¢ (OXMAT) è³æéä¸é²è¡è©ä¼°ï¼è©²è³æéåå«è¶é 20,000 å CTG è»è·¡ï¼æ¶µèå¨æç¨åå«åæé¤æ¨æºå¾ä¸åçè¨åºçµæãééå»£æ³çè¶åæ¸æä½³åï¼PatchCTG å¨ Youden ææ¸é¾å¼ä¸éå° 77% ç AUCï¼ç¹ç°æ§çº 88%ï¼æææ§çº 57%ï¼è­æäºå¶å°åç¨®è¨åºéæ±çé©ææ§ãå¨ä¸åçæéé¾å¼ä¸é²è¡æ¸¬è©¦é¡¯ç¤ºåºç©©å¥çé æ¸¬æè½ï¼ç¹å¥æ¯å¨æ¥è¿åå¨©æå°è³æé²è¡å¾®èª¿ï¼å°æ¼æ¥è¿åå¨©ççä¾ï¼æææ§éå° 52%ï¼ç¹ç°æ§éå° 88%ãéäºç¼ç¾è¡¨æ PatchCTG ææ½åééæä¾å¯é ãå®¢è§çèåå¥åº·è©ä¼°å·¥å·ä¾å å¼·ç¢åç§è­·ä¸­çè¨åºæ±ºç­å¶å®ãåå§ç¨å¼ç¢¼å¯å¨ https://github.com/jaleedkhan/PatchCTG åå¾ã

##### **Multimodal Clinical Reasoning through Knowledge-augmented Rationale Generation**
2411.07611v1 by Shuai Niu, Jing Ma, Liang Bai, Zhihua Wang, Yida Xu, Yunya Song, Xian Yang

Clinical rationales play a pivotal role in accurate disease diagnosis;
however, many models predominantly use discriminative methods and overlook the
importance of generating supportive rationales. Rationale distillation is a
process that transfers knowledge from large language models (LLMs) to smaller
language models (SLMs), thereby enhancing the latter's ability to break down
complex tasks. Despite its benefits, rationale distillation alone is inadequate
for addressing domain knowledge limitations in tasks requiring specialized
expertise, such as disease diagnosis. Effectively embedding domain knowledge in
SLMs poses a significant challenge. While current LLMs are primarily geared
toward processing textual data, multimodal LLMs that incorporate time series
data, especially electronic health records (EHRs), are still evolving. To
tackle these limitations, we introduce ClinRaGen, an SLM optimized for
multimodal rationale generation in disease diagnosis. ClinRaGen incorporates a
unique knowledge-augmented attention mechanism to merge domain knowledge with
time series EHR data, utilizing a stepwise rationale distillation strategy to
produce both textual and time series-based clinical rationales. Our evaluations
show that ClinRaGen markedly improves the SLM's capability to interpret
multimodal EHR data and generate accurate clinical rationales, supporting more
reliable disease diagnosis, advancing LLM applications in healthcare, and
narrowing the performance divide between LLMs and SLMs.

æè¦ï¼<paragraph>è¨åºä¾æå¨æºç¢ºçç¾çè¨ºæ·ä¸­æ®æ¼èééµè§è²ï¼
ç¶èï¼è¨±å¤æ¨¡åä¸»è¦ä½¿ç¨å¤å¥å¼æ¹æ³ï¼èå¿½ç¥äºçææ¯ææ§ä¾æçéè¦æ§ãä¾æèåæ¯ä¸ç¨®å°ç¥è­å¾å¤§åèªè¨æ¨¡å (LLM) è½ç§»å°å°åèªè¨æ¨¡å (SLM) çéç¨ï¼å¾èå¢å¼·å¾èåè§£è¤éä»»åçè½åãåç®¡æå¶å¥½èï¼ä½å®ç¨çä¾æèåä¸è¶³ä»¥è§£æ±ºéè¦å°æ¥­ç¥è­çä»»åï¼ä¾å¦ç¾çè¨ºæ·ï¼ä¸­çé åç¥è­éå¶ãææå°å°é åç¥è­åµå¥ SLM æ¯ä¸åéå¤§çææ°ãéç¶ç®åç LLM ä¸»è¦ç¨æ¼èçææ¬è³æï¼ä½æ´åæéåºåè³æï¼ç¹å¥æ¯é»å­å¥åº·è¨é (EHR)ï¼çå¤æ¨¡æ LLM ä»å¨ç¼å±ä¸­ãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥äº ClinRaGenï¼ä¸ç¨®éå°ç¾çè¨ºæ·ä¸­å¤æ¨¡æä¾æçæçæä½³å SLMãClinRaGen çµåäºä¸åç¨ç¹çç¥è­å¢å¼·æ³¨æåæ©å¶ï¼å°é åç¥è­èæéåºå EHR è³æåä½µï¼å©ç¨éæ­¥çä¾æèåç­ç¥ä¾ç¢çåºæ¼ææ¬åæéåºåçè¨åºä¾æãæåçè©ä¼°è¡¨æï¼ClinRaGen æé¡¯æ¹åäº SLM è§£éå¤æ¨¡æ EHR è³æåçææºç¢ºè¨åºä¾æçè½åï¼æ¯ææ´å¯é çç¾çè¨ºæ·ï¼æ¨é² LLM å¨é«çä¿å¥ä¸­çæç¨ï¼ä¸¦ç¸®å° LLM å SLM ä¹éçæè½å·®è·ã</paragraph>

##### **Contrastive Language Prompting to Ease False Positives in Medical Anomaly Detection**
2411.07546v1 by YeongHyeon Park, Myung Jin Kim, Hyeong Seok Kim

A pre-trained visual-language model, contrastive language-image pre-training
(CLIP), successfully accomplishes various downstream tasks with text prompts,
such as finding images or localizing regions within the image. Despite CLIP's
strong multi-modal data capabilities, it remains limited in specialized
environments, such as medical applications. For this purpose, many CLIP
variants-i.e., BioMedCLIP, and MedCLIP-SAMv2-have emerged, but false positives
related to normal regions persist. Thus, we aim to present a simple yet
important goal of reducing false positives in medical anomaly detection. We
introduce a Contrastive LAnguage Prompting (CLAP) method that leverages both
positive and negative text prompts. This straightforward approach identifies
potential lesion regions by visual attention to the positive prompts in the
given image. To reduce false positives, we attenuate attention on normal
regions using negative prompts. Extensive experiments with the BMAD dataset,
including six biomedical benchmarks, demonstrate that CLAP method enhances
anomaly detection performance. Our future plans include developing an automated
fine prompting method for more practical usage.

æè¦ï¼é è¨ç·´çè¦è¦ºèªè¨æ¨¡åï¼å°æ¯èªè¨å½±åé è¨ç·´ (CLIP)ï¼æåä½¿ç¨æå­æç¤ºå®æåç¨®ä¸æ¸¸ä»»åï¼ä¾å¦å°æ¾å½±åæå®ä½å½±åä¸­çååãåç®¡ CLIP ææå¼·å¤§çå¤æ¨¡æè³æåè½ï¼ä½å¨å°éçç°å¢ä¸­ï¼ä¾å¦é«çæç¨ï¼ä»ç¶æéãçºæ­¤ï¼åºç¾äºè¨±å¤ CLIP è®é«ï¼å³ BioMedCLIP å MedCLIP-SAMv2ï¼ä½èæ­£å¸¸ååç¸éçåé½æ§ä»ç¶å­å¨ãå æ­¤ï¼æåçç®æ¨æ¯æåºä¸åç°¡å®ä½éè¦çç®æ¨ï¼ä»¥æ¸å°é«çç°å¸¸æª¢æ¸¬ä¸­çåé½æ§ãæåå¼å¥äºå°æ¯èªè¨æç¤º (CLAP) æ¹æ³ï¼è©²æ¹æ³åæå©ç¨æ­£ååè² åæå­æç¤ºãéç¨®ç´æ¥çæ¹æ³ééè¦è¦ºæ³¨æçµ¦å®å½±åä¸­çæ­£åæç¤ºï¼ä¾è­å¥æ½å¨ççç¶ååãçºäºæ¸å°åé½æ§ï¼æåä½¿ç¨è² åæç¤ºä¾æ¸å¼±å°æ­£å¸¸ååçæ³¨æãä½¿ç¨ BMAD è³æéé²è¡çå»£æ³å¯¦é©ï¼åæ¬å­åçç©é«å­¸åºæºï¼è­æ CLAP æ¹æ³å¢å¼·äºç°å¸¸æª¢æ¸¬æè½ãæåæªä¾çè¨ç«åæ¬éç¼ä¸ç¨®èªååç²¾ç´°æç¤ºæ¹æ³ï¼ä»¥ä¾æ´å¯¦ç¨çä½¿ç¨ã

##### **Beyond Keywords: A Context-based Hybrid Approach to Mining Ethical Concern-related App Reviews**
2411.07398v1 by Aakash Sorathiya, Gouri Ginde

With the increasing proliferation of mobile applications in our everyday
experiences, the concerns surrounding ethics have surged significantly. Users
generally communicate their feedback, report issues, and suggest new
functionalities in application (app) reviews, frequently emphasizing safety,
privacy, and accountability concerns. Incorporating these reviews is essential
to developing successful products. However, app reviews related to ethical
concerns generally use domain-specific language and are expressed using a more
varied vocabulary. Thus making automated ethical concern-related app review
extraction a challenging and time-consuming effort.
  This study proposes a novel Natural Language Processing (NLP) based approach
that combines Natural Language Inference (NLI), which provides a deep
comprehension of language nuances, and a decoder-only (LLaMA-like) Large
Language Model (LLM) to extract ethical concern-related app reviews at scale.
Utilizing 43,647 app reviews from the mental health domain, the proposed
methodology 1) Evaluates four NLI models to extract potential privacy reviews
and compares the results of domain-specific privacy hypotheses with generic
privacy hypotheses; 2) Evaluates four LLMs for classifying app reviews to
privacy concerns; and 3) Uses the best NLI and LLM models further to extract
new privacy reviews from the dataset. Results show that the
DeBERTa-v3-base-mnli-fever-anli NLI model with domain-specific hypotheses
yields the best performance, and Llama3.1-8B-Instruct LLM performs best in the
classification of app reviews. Then, using NLI+LLM, an additional 1,008 new
privacy-related reviews were extracted that were not identified through the
keyword-based approach in previous research, thus demonstrating the
effectiveness of the proposed approach.

æè¦ï¼<paragraph>é¨èè¡åæç¨ç¨å¼å¨æåæ¥å¸¸é«é©ä¸­æ¿å¢ï¼åç¹å«çççæ®ä¹å¤§å¹å¢å ãä½¿ç¨èéå¸¸å¨æç¨ç¨å¼ï¼appï¼è©è«ä¸­å³éä»åçåé¥ãåå ±åé¡ï¼ä¸¦å»ºè­°æ°çåè½ï¼ç¶å¸¸å¼·èª¿å®å¨æ§ãé±ç§ååè²¬çæ®ãç´å¥éäºè©è«å°æ¼éç¼æåçç¢åè³ééè¦ãç¶èï¼èå«ççæ®ç¸éç app è©è«éå¸¸ä½¿ç¨ç¹å®é åèªè¨ï¼ä¸¦ä½¿ç¨æ´å¤è®åçè©å½è¡¨éãå æ­¤ï¼èªååèå«ççæ®ç¸éç app è©è«æ·åæ¯ä¸é å·æææ°æ§ä¸èæçå·¥ä½ã
æ¬ç ç©¶æåºäºä¸ç¨®åºæ¼èªç¶èªè¨èç (NLP) çæ°ç©æ¹æ³ï¼å®çµåäºèªç¶èªè¨æ¨è« (NLI)ï¼å®æä¾äºå°èªè¨ç´°å¾®å·®å¥çæ·±å¥çè§£ï¼ä»¥ååè§£ç¢¼å¨ï¼é¡ä¼¼ LLaMAï¼çå¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥å¤§è¦æ¨¡æ·åèå«ççæ®ç¸éç app è©è«ãå©ç¨å¿çå¥åº·é åç 43,647 å app è©è«ï¼æåºçæ¹æ³ 1) è©ä¼°åå NLI æ¨¡åä»¥æ·åæ½å¨çé±ç§è©è«ï¼ä¸¦å°ç¹å®é åé±ç§åè¨­ççµæèä¸è¬é±ç§åè¨­é²è¡æ¯è¼ï¼2) è©ä¼°åå LLM ä»¥å° app è©è«åé¡çºé±ç§çæ®ï¼ä»¥å 3) é²ä¸æ­¥ä½¿ç¨æä½³ç NLI å LLM æ¨¡åå¾è³æéä¸­æ·åæ°çé±ç§è©è«ãçµæé¡¯ç¤ºï¼å·æç¹å®é ååè¨­ç DeBERTa-v3-base-mnli-fever-anli NLI æ¨¡åç¢çæä½³æè½ï¼è Llama3.1-8B-Instruct LLM å¨ app è©è«åé¡ä¸­è¡¨ç¾æä½³ãç¶å¾ï¼ä½¿ç¨ NLI+LLMï¼é¡å¤æ·åäº 1,008 åæ°çèé±ç§ç¸éçè©è«ï¼éäºè©è«æªééååç ç©¶ä¸­çåºæ¼ééµå­çæ¹æ³è­å¥åºä¾ï¼å æ­¤è­æäºææåºæ¹æ³çæææ§ã</paragraph>

##### **Data-Centric Learning Framework for Real-Time Detection of Aiming Beam in Fluorescence Lifetime Imaging Guided Surgery**
2411.07395v1 by Mohamed Abul Hassan, Pu Sun, Xiangnan Zhou, Lisanne Kraft, Kelsey T Hadfield, Katjana Ehrlich, Jinyi Qi, Andrew Birkeland, Laura Marcu

This study introduces a novel data-centric approach to improve real-time
surgical guidance using fiber-based fluorescence lifetime imaging (FLIm). A key
aspect of the methodology is the accurate detection of the aiming beam, which
is essential for localizing points used to map FLIm measurements onto the
tissue region within the surgical field. The primary challenge arises from the
complex and variable conditions encountered in the surgical environment,
particularly in Transoral Robotic Surgery (TORS). Uneven illumination in the
surgical field can cause reflections, reduce contrast, and results in
inconsistent color representation, further complicating aiming beam detection.
To overcome these challenges, an instance segmentation model was developed
using a data-centric training strategy that improves accuracy by minimizing
label noise and enhancing detection robustness. The model was evaluated on a
dataset comprising 40 in vivo surgical videos, demonstrating a median detection
rate of 85%. This performance was maintained when the model was integrated in a
clinical system, achieving a similar detection rate of 85% during TORS
procedures conducted in patients. The system's computational efficiency,
measured at approximately 24 frames per second (FPS), was sufficient for
real-time surgical guidance. This study enhances the reliability of FLIm-based
aiming beam detection in complex surgical environments, advancing the
feasibility of real-time, image-guided interventions for improved surgical
precision

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®æ°ç©çä»¥æ¸æçºä¸­å¿çç­ç¥ï¼ä»¥ä½¿ç¨åºæ¼åçºçè¢åçå½ææå (FLIm) ä¾æ¹åå¯¦ææè¡å°å¼ãæ­¤æ¹æ³çä¸åééµé¢åæ¯æºç¢ºåµæ¸¬çæºåæï¼éå°æ¼å®ä½ç¨æ¼å° FLIm æ¸¬éçµæå°æå°æè¡è¦éå§çµç¹ååçé»è³ééè¦ãä¸»è¦çææ°ä¾èªæ¼æè¡ç°å¢ä¸­éå°çè¤éä¸è®åçæ¢ä»¶ï¼ç¹å¥æ¯å¨ç¶å£æ©å¨äººæè¡ (TORS) ä¸­ãæè¡è¦éä¸­çç§æä¸åæå°è´åå°ãéä½å°æ¯åº¦ï¼ä¸¦é æä¸ä¸è´çé¡è²åç¾ï¼é²ä¸æ­¥ä½¿çæºåæåµæ¸¬è¤éåãçºäºåæéäºææ°ï¼éç¼äºä¸åå¯¦ä¾åå²æ¨¡åï¼ä½¿ç¨ä»¥æ¸æçºä¸­å¿çè¨ç·´ç­ç¥ï¼ééæå°åæ¨ç±¤éè¨åå¢å¼·åµæ¸¬ç©©å¥æ§ä¾æé«æºç¢ºåº¦ãæ­¤æ¨¡åå¨åå« 40 åé«å§æè¡å½±ççè³æéä¸é²è¡è©ä¼°ï¼é¡¯ç¤ºåº 85% çä¸­ä½æ¸åµæ¸¬çãç¶æ­¤æ¨¡åæ´åå°è¨åºç³»çµ±ä¸­æï¼æ­¤æè½å¾ä»¥ç¶­æï¼å¨æ£èé²è¡ TORS æè¡æééæç¸ä¼¼ç 85% åµæ¸¬çãæ­¤ç³»çµ±çéç®æçï¼æ¸¬éçµæç´çºæ¯ç§ 24 å¹ (FPS)ï¼è¶³ä»¥é²è¡å¯¦ææè¡å°å¼ãæ¬ç ç©¶å¢å¼·äº FLIm çºåºç¤ççæºåæåµæ¸¬å¨è¤éæè¡ç°å¢ä¸­çå¯é æ§ï¼æåäºå¯¦æãå½±åå°å¼ä»å¥çå¯è¡æ§ï¼ä»¥æ¹åæè¡ç²¾æºåº¦

##### **Data-Driven Analysis of AI in Medical Device Software in China: Deep Learning and General AI Trends Based on Regulatory Data**
2411.07378v1 by Yu Han, Aaron Ceross, Sarim Ather, Jeroen H. M. Bergmann

Artificial intelligence (AI) in medical device software (MDSW) represents a
transformative clinical technology, attracting increasing attention within both
the medical community and the regulators. In this study, we leverage a
data-driven approach to automatically extract and analyze AI-enabled medical
devices (AIMD) from the National Medical Products Administration (NMPA)
regulatory database. The continued increase in publicly available regulatory
data requires scalable methods for analysis. Automation of regulatory
information screening is essential to create reproducible insights that can be
quickly updated in an ever changing medical device landscape. More than 4
million entries were assessed, identifying 2,174 MDSW registrations, including
531 standalone applications and 1,643 integrated within medical devices, of
which 43 were AI-enabled. It was shown that the leading medical specialties
utilizing AIMD include respiratory (20.5%), ophthalmology/endocrinology
(12.8%), and orthopedics (10.3%). This approach greatly improves the speed of
data extracting providing a greater ability to compare and contrast. This study
provides the first extensive, data-driven exploration of AIMD in China,
showcasing the potential of automated regulatory data analysis in understanding
and advancing the landscape of AI in medical technology.

æè¦ï¼é«çå¨æè»é« (MDSW) ä¸­çäººå·¥æºæ§ (AI) ä»£è¡¨èè®é©æ§çè¨åºæè¡ï¼å¨é«çç¤¾ç¾¤åæ³è¦å®ä½ä¸­é½å¸å¼äºè¶ä¾è¶å¤çéæ³¨ãå¨æ¬ç ç©¶ä¸­ï¼æåå©ç¨è³æé©åçæ¹æ³ï¼å¾åå®¶è¥åç£ç£ç®¡çå± (NMPA) æ³è¦è³æåº«ä¸­èªåæ·åååæå·å AI åè½çé«çå¨æ (AIMD)ãæçºå¢å çå¬éæ³è¦è³æéè¦å¯æ´åçåææ¹æ³ãæ³è¦è³è¨ç¯©é¸çèªååå°æ¼å»ºç«å¯éè£½çè¦è§£è³ééè¦ï¼éäºè¦è§£å¯ä»¥å¨ä¸æ·è®åçé«çå¨æé åä¸­å¿«éæ´æ°ãè©ä¼°äºè¶é 400 è¬ç­æ¢ç®ï¼è­å¥åº 2,174 ç­ MDSW è¨»åï¼åæ¬ 531 ç­ç¨ç«æç¨å 1,643 ç­æ´åæ¼é«çå¨æä¸­ï¼å¶ä¸­ 43 ç­å·å AI åè½ãçµæé¡¯ç¤ºï¼ä½¿ç¨ AIMD çä¸»è¦é«çå°ç§åæ¬å¼å¸ç§ (20.5%)ãç¼ç§/å§åæ³ç§ (12.8%) åéª¨ç§ (10.3%)ãéç¨®æ¹æ³å¤§å¹æåäºè³ææ·åéåº¦ï¼æä¾äºæ´å¼·å¤§çæ¯è¼åå°æ¯è½åãæ¬ç ç©¶æä¾äºä¸­å AIMD çç¬¬ä¸åå»£æ³è³æé©åæ¢ç´¢ï¼å±ç¤ºäºèªååæ³è¦è³æåæå¨äºè§£åæ¨é²é«çæè¡ä¸­ AI é åçæ½åã

##### **A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**
2411.07163v1 by Vedant Khandelwal, Manas Gaur, Ugur Kursuncu, Valerie Shalin, Amit Sheth

Monitoring public sentiment via social media is potentially helpful during
health crises such as the COVID-19 pandemic. However, traditional
frequency-based, data-driven neural network-based approaches can miss newly
relevant content due to the evolving nature of language in a dynamically
evolving environment. Human-curated symbolic knowledge sources, such as
lexicons for standard language and slang terms, can potentially elevate social
media signals in evolving language. We introduce a neurosymbolic method that
integrates neural networks with symbolic knowledge sources, enhancing the
detection and interpretation of mental health-related tweets relevant to
COVID-19. Our method was evaluated using a corpus of large datasets
(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news
articles) and multiple knowledge graphs. This method dynamically adapts to
evolving language, outperforming purely data-driven models with an F1 score
exceeding 92\%. This approach also showed faster adaptation to new data and
lower computational demands than fine-tuning pre-trained large language models
(LLMs). This study demonstrates the benefit of neurosymbolic methods in
interpreting text in a dynamic environment for tasks such as health
surveillance.

æè¦ï¼ééç¤¾ç¾¤åªé«ç£æ§å¬ç¾æç·å¨ COVID-19 ç­å¥åº·å±æ©æéå¯è½å¾æå¹«å©ãç¶èï¼å³çµ±çåºæ¼é »çãè³æé©åçç¥ç¶ç¶²è·¯æ¹æ³å¯è½æé¯éæ°ç¸éçå§å®¹ï¼å çºèªè¨å¨åææ¼åçç°å¢ä¸­ææçºæ¼åãç±äººé¡ç­åçè±¡å¾µæ§ç¥è­ä¾æºï¼ä¾å¦æ¨æºèªè¨åä¿èªè¡èªçè©å½ï¼å¯è½ææåç¤¾ç¾¤åªé«å¨æ¼åèªè¨ä¸­çè¨èãæåå¼å¥ä¸ç¨®å°ç¥ç¶ç¶²è·¯èè±¡å¾µæ§ç¥è­ä¾æºæ´åçç¥ç¶ç¬¦èæ¹æ³ï¼å¢å¼·è COVID-19 ç¸éçå¿çå¥åº·ç¸éæ¨æçåµæ¸¬åè©®éãæåçåæ³ä½¿ç¨å¤§åè³æéèªæåº«ï¼ç´ 120 ååæ¨æã250 è¬å subreddit è³æå 70 è¬åæ°èæç« ï¼åå¤åç¥è­åè­é²è¡è©ä¼°ãéç¨®æ¹æ³åæé©ææ¼åçèªè¨ï¼åªæ¼ç´è³æé©åæ¨¡åï¼F1 åæ¸è¶é 92%ãéç¨®æ¹æ³ä¹é¡¯ç¤ºåºæ¯å¾®èª¿é è¨ç·´å¤§åèªè¨æ¨¡å (LLM) æ´å¿«é©ææ°è³æåæ´ä½çéç®éæ±ãæ¬ç ç©¶è­æäºç¥ç¶ç¬¦èæ¹æ³å¨åæç°å¢ä¸­è©®éæå­çåªé»ï¼é©ç¨æ¼å¥åº·ç£æ§ç­ä»»åã

##### **Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models**
2411.06713v1 by Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj

This study compares Sporo Health's AI Scribe, a proprietary model fine-tuned
for medical scribing, with various LLMs (GPT-4o, GPT-3.5, Gemma-9B, and
Llama-3.2-3B) in clinical documentation. We analyzed de-identified patient
transcripts from partner clinics, using clinician-provided SOAP notes as the
ground truth. Each model generated SOAP summaries using zero-shot prompting,
with performance assessed via recall, precision, and F1 scores. Sporo
outperformed all models, achieving the highest recall (73.3%), precision
(78.6%), and F1 score (75.3%) with the lowest performance variance.
Statistically significant differences (p < 0.05) were found between Sporo and
the other models, with post-hoc tests showing significant improvements over
GPT-3.5, Gemma-9B, and Llama 3.2-3B. While Sporo outperformed GPT-4o by up to
10%, the difference was not statistically significant (p = 0.25). Clinical user
satisfaction, measured with a modified PDQI-9 inventory, favored Sporo.
Evaluations indicated Sporo's outputs were more accurate and relevant. This
highlights the potential of Sporo's multi-agentic architecture to improve
clinical workflows.

æè¦ï¼æ¬ç ç©¶æ¯è¾äº Sporo Health ç AI Scribeï¼ä¸ç§éå¯¹å»çè®°å½ä¸é¨å¾®è°çä¸ææ¨¡åï¼ä¸ä¸´åºè®°å½ä¸­çåç§ LLMï¼GPT-4oãGPT-3.5ãGemma-9B å Llama-3.2-3Bï¼ãæä»¬åæäºæ¥èªåä½è¯æçå»æ è¯æ£èè®°å½ï¼ä½¿ç¨ä¸´åºå»çæä¾ç SOAP è®°å½ä½ä¸ºåºæ¬äºå®ãæ¯ä¸ªæ¨¡åä½¿ç¨é¶æ¬¡æç¤ºçæäº SOAP æè¦ï¼éè¿å¬åçãç²¾ç¡®çå F1 åæ°è¯ä¼°æ§è½ãSporo ä¼äºæææ¨¡åï¼ä»¥æä½çæ§è½å·®å¼å®ç°äºæé«çå¬åç (73.3%)ãç²¾ç¡®ç (78.6%) å F1 åæ° (75.3%)ãå¨ Sporo åå¶ä»æ¨¡åä¹é´åç°äºç»è®¡å­¦ä¸çæ¾çå·®å¼ (p < 0.05)ï¼äºåæ£éªæ¾ç¤ºä¸ GPT-3.5ãGemma-9B å Llama 3.2-3B ç¸æ¯ææ¾çæ¹åãè½ç¶ Sporo çè¡¨ç°ä¼äº GPT-4o è¾¾ 10%ï¼ä½å·®å¼å¨ç»è®¡å­¦ä¸å¹¶ä¸æ¾ç (p = 0.25)ãä½¿ç¨ä¿®æ¹åç PDQI-9 æ¸åè¡¡éçä¸´åºç¨æ·æ»¡æåº¦åå¥½ Sporoãè¯ä¼°è¡¨æ Sporo çè¾åºæ´åç¡®ãæ´ç¸å³ãè¿çªåºäº Sporo çå¤ä»£çæ¶æå¨æ¹è¿ä¸´åºå·¥ä½æµç¨æ¹é¢çæ½åã

##### **In-Context Learning for Preserving Patient Privacy: A Framework for Synthesizing Realistic Patient Portal Messages**
2411.06549v1 by Joseph Gatto, Parker Seegmiller, Timothy E. Burdick, Sarah Masud Preum

Since the COVID-19 pandemic, clinicians have seen a large and sustained
influx in patient portal messages, significantly contributing to clinician
burnout. To the best of our knowledge, there are no large-scale public patient
portal messages corpora researchers can use to build tools to optimize
clinician portal workflows. Informed by our ongoing work with a regional
hospital, this study introduces an LLM-powered framework for configurable and
realistic patient portal message generation. Our approach leverages few-shot
grounded text generation, requiring only a small number of de-identified
patient portal messages to help LLMs better match the true style and tone of
real data. Clinical experts in our team deem this framework as HIPAA-friendly,
unlike existing privacy-preserving approaches to synthetic text generation
which cannot guarantee all sensitive attributes will be protected. Through
extensive quantitative and human evaluation, we show that our framework
produces data of higher quality than comparable generation methods as well as
all related datasets. We believe this work provides a path forward for (i) the
release of large-scale synthetic patient message datasets that are
stylistically similar to ground-truth samples and (ii) HIPAA-friendly data
generation which requires minimal human de-identification efforts.

æè¦ï¼èª COVID-19 å¤§æµè¡ä»¥ä¾ï¼è¨åºé«çæ¶å°äºå¤§éçæçºæ§æ£èå¥å£è¨æ¯ï¼éé¡¯èå åäºè¨åºé«ççå¦æ æãææåæç¥ï¼æ²æå¤§åå¬å±æ£èå¥å£è¨æ¯èªæåº«å¯ä¾ç ç©¶äººå¡ç¨æ¼å»ºæ§å·¥å·ä¾æä½³åè¨åºé«çå¥å£å·¥ä½æµç¨ãæ¬ç ç©¶åéäºæåèååé«é¢æ­£å¨é²è¡çå·¥ä½ï¼ä»ç´¹äºä¸åç± LLM é©åçæ¡æ¶ï¼ç¨æ¼å¯éç½®ä¸é¼ççæ£èå¥å£è¨æ¯ç¢çãæåçåæ³å©ç¨äºå°æ¨£æ¬æ¥å°ææ¬ç¢çï¼åªéå°æ¸å»è­å¥åçæ£èå¥å£è¨æ¯ï¼å°±è½å¹«å© LLM æ´ä½³å¹éçå¯¦è³æççå¯¦é¢¨æ ¼åèªæ°£ãæååéä¸­çè¨åºå°å®¶èªçºéåæ¡æ¶ç¬¦å HIPAAï¼éèç¾æçåæææ¬ç¢çé±ç§ä¿è­·æ¹æ³ä¸åï¼å¾èç¡æ³ä¿è­ææææå±¬æ§é½åå°ä¿è­·ãééå»£æ³çéååäººå·¥è©ä¼°ï¼æåè­æäºæåçæ¡æ¶ç¢ççè³æåè³ªé«æ¼å¯æ¯è¼çç¢çæ¹æ³ä»¥åææç¸éçè³æéãæåç¸ä¿¡éé å·¥ä½çºä»¥ä¸äºé æä¾äºåé²çéè·¯ï¼(i) ç¼å¸èçå¯¦æ¨£æ¬å¨é¢¨æ ¼ä¸ç¸ä¼¼çãå¤§è¦æ¨¡çåææ£èè¨æ¯è³æéï¼ä»¥å (ii) ç¬¦å HIPAA çè³æç¢çï¼èééè¦æå°çäººå·¥å»è­å¥åå·¥ä½ã

##### **NeuReg: Domain-invariant 3D Image Registration on Human and Mouse Brains**
2411.06315v1 by Taha Razzaq, Asim Iqbal

Medical brain imaging relies heavily on image registration to accurately
curate structural boundaries of brain features for various healthcare
applications. Deep learning models have shown remarkable performance in image
registration in recent years. Still, they often struggle to handle the
diversity of 3D brain volumes, challenged by their structural and contrastive
variations and their imaging domains. In this work, we present NeuReg, a
Neuro-inspired 3D image registration architecture with the feature of domain
invariance. NeuReg generates domain-agnostic representations of imaging
features and incorporates a shifting window-based Swin Transformer block as the
encoder. This enables our model to capture the variations across brain imaging
modalities and species. We demonstrate a new benchmark in multi-domain publicly
available datasets comprising human and mouse 3D brain volumes. Extensive
experiments reveal that our model (NeuReg) outperforms the existing baseline
deep learning-based image registration models and provides a high-performance
boost on cross-domain datasets, where models are trained on 'source-only'
domain and tested on completely 'unseen' target domains. Our work establishes a
new state-of-the-art for domain-agnostic 3D brain image registration,
underpinned by Neuro-inspired Transformer-based architecture.

æè¦ï¼é«å­¸è¦é¨å½±åé«åº¦ä¾è³´å½±åéæºï¼ä»¥æºç¢ºç­ç«å¤§è¦ç¹å¾µççµæ§æ§éçï¼ç¨æ¼åç¨®é«çä¿å¥æç¨ãæ·±åº¦å­¸ç¿æ¨¡åè¿å¹´ä¾å¨å½±åéæºä¸­å±ç¾åºåè¶çæè½ãåç®¡å¦æ­¤ï¼éäºæ¨¡åå¨èçå¤åç 3D å¤§è¦é«ç©æå¸¸å¸¸æéå°å°é£ï¼åå°å¶çµæ§åå°æ¯è®åä»¥åå½±åé åçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåº NeuRegï¼ä¸ç¨®å·åé åä¸è®æ§ç¹å¾µçç¥ç¶åç¼å¼ 3D å½±åéæºæ¶æ§ãNeuReg ç¢çå½±åç¹å¾µçé åä¸å¯ç¥è¡¨ç¤ºï¼ä¸¦å°åºæ¼æ»åè¦çªç Swin Transformer åå¡ä½çºç·¨ç¢¼å¨ãéä½¿æåçæ¨¡åè½å¤ æ·åè·¨å¤§è¦å½±åæ¨¡å¼åç©ç¨®çè®åãæåå±ç¤ºäºä¸åæ°çåºæºï¼åå«äººé¡åèé¼  3D å¤§è¦é«ç©çå¤é åå¬éå¯ç¨è³æéãå»£æ³çå¯¦é©é¡¯ç¤ºï¼æåçæ¨¡å (NeuReg) åªæ¼ç¾æçåºæºæ·±åº¦å­¸ç¿å½±åéæºæ¨¡åï¼ä¸¦å¨è·¨é åè³æéä¸æä¾é«æ§è½æåï¼å¶ä¸­æ¨¡åå¨ãåä¾æºãé åä¸è¨ç·´ï¼ä¸¦å¨å®å¨ãæªè¦ãçç®æ¨é åä¸é²è¡æ¸¬è©¦ãæåçç ç©¶å»ºç«äºé åä¸å¯ç¥ 3D å¤§è¦å½±åéæºçæ°æè¡ï¼ç±ç¥ç¶åç¼å¼ Transformer çºåºç¤çæ¶æ§ææ¯æã

##### **GuidelineGuard: An Agentic Framework for Medical Note Evaluation with Guideline Adherence**
2411.06264v1 by MD Ragib Shahriyear

Although rapid advancements in Large Language Models (LLMs) are facilitating
the integration of artificial intelligence-based applications and services in
healthcare, limited research has focused on the systematic evaluation of
medical notes for guideline adherence. This paper introduces GuidelineGuard, an
agentic framework powered by LLMs that autonomously analyzes medical notes,
such as hospital discharge and office visit notes, to ensure compliance with
established healthcare guidelines. By identifying deviations from recommended
practices and providing evidence-based suggestions, GuidelineGuard helps
clinicians adhere to the latest standards from organizations like the WHO and
CDC. This framework offers a novel approach to improving documentation quality
and reducing clinical errors.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) çå¿«éé²å±ä¿é²äºäººå·¥æºæ§æç¨ç¨å¼åæåå¨é«çä¿å¥ä¸­çæ´åï¼ä½æéçç ç©¶å°æ³¨æ¼å°é«çè¨éé²è¡ç³»çµ±è©ä¼°ä»¥ç¬¦åæºåãæ¬æä»ç´¹äº GuidelineGuardï¼ä¸åç± LLM æä¾ååçä»£çæ¶æ§ï¼å®æèªååæé«çè¨éï¼ä¾å¦é«é¢åºé¢åéè¨ºè¨éï¼ä»¥ç¢ºä¿ç¬¦åæ¢å®çé«çä¿å¥æºåãééæ¾åºèå»ºè­°åæ³çåå·®ä¸¦æä¾åºæ¼è­æçå»ºè­°ï¼GuidelineGuard å¯åå©è¨åºé«çéµå®ä¸çè¡ççµç¹ (WHO) åç¾çç®¡å¶ä¸­å¿ (CDC) ç­çµç¹çææ°æ¨æºãæ­¤æ¶æ§æä¾äºä¸ç¨®æ¹åæä»¶åè³ªåæ¸å°è¨åºé¯èª¤çæ°æ¹æ³ã

##### **Deep Reinforcement Learning for Digital Twin-Oriented Complex Networked Systems**
2411.06148v1 by Jiaqi Wen, Bogdan Gabrys, Katarzyna Musial

The Digital Twin Oriented Complex Networked System (DT-CNS) aims to build and
extend a Complex Networked System (CNS) model with progressively increasing
dynamics complexity towards an accurate reflection of reality -- a Digital Twin
of reality. Our previous work proposed evolutionary DT-CNSs to model the
long-term adaptive network changes in an epidemic outbreak. This study extends
this framework by proposeing the temporal DT-CNS model, where reinforcement
learning-driven nodes make decisions on temporal directed interactions in an
epidemic outbreak. We consider cooperative nodes, as well as egocentric and
ignorant "free-riders" in the cooperation. We describe this epidemic spreading
process with the Susceptible-Infected-Recovered ($SIR$) model and investigate
the impact of epidemic severity on the epidemic resilience for different types
of nodes. Our experimental results show that (i) the full cooperation leads to
a higher reward and lower infection number than a cooperation with egocentric
or ignorant "free-riders"; (ii) an increasing number of "free-riders" in a
cooperation leads to a smaller reward, while an increasing number of egocentric
"free-riders" further escalate the infection numbers and (iii) higher infection
rates and a slower recovery weakens networks' resilience to severe epidemic
outbreaks. These findings also indicate that promoting cooperation and reducing
"free-riders" can improve public health during epidemics.

æè¦ï¼æ¸ä½å­¿çå°åè¤éç¶²è·¯ç³»çµ±ï¼DT-CNSï¼æ¨å¨å»ºç«åæ´å±è¤éç¶²è·¯ç³»çµ±ï¼CNSï¼æ¨¡åï¼ä¸¦éæ­¥å¢å åæè¤éæ§ä»¥æºç¢ºåæ ç¾å¯¦ââç¾å¯¦çæ¸ä½å­¿çãæåååçå·¥ä½æåºæ¼åç DT-CNS ä¾å»ºæ¨¡æµè¡ççç¼ä¸­çé·æé©ææ§ç¶²è·¯è®åãæ¬ç ç©¶ééæåºæé DT-CNS æ¨¡åä¾å»¶ä¼¸éåæ¶æ§ï¼å¶ä¸­å¼·åå­¸ç¿é©åçç¯é»å¨æµè¡ççç¼ä¸­å°æéå°åäºåååºæ±ºç­ãæåèæ®åä½ç¯é»ï¼ä»¥ååä½ä¸­çèªæä¸­å¿åç¡ç¥çãæ­ä¾¿è»èããæåä½¿ç¨ææè-åææè-åº·å¾©èï¼$SIR$ï¼æ¨¡åæè¿°éåæµè¡çæ´æ£éç¨ï¼ä¸¦èª¿æ¥æµè¡çå´éæ§å°ä¸åé¡åç¯é»çæµè¡çå¾©ååçå½±é¿ãæåçå¯¦é©çµæé¡¯ç¤º (i) å¨é¢åä½æå°è´æ¯èèªæä¸­å¿æç¡ç¥çãæ­ä¾¿è»èãåä½æ´é«çåå ±åæ´ä½çæææ¸ï¼(ii) åä½ä¸­çãæ­ä¾¿è»èãæ¸éå¢å æå°è´è¼å°çåå ±ï¼èèªæä¸­å¿çãæ­ä¾¿è»èãæ¸éå¢å æé²ä¸æ­¥æåæææ¸ï¼(iii) è¼é«çææçåè¼æ¢çå¾©åæåå¼±ç¶²è·¯å°å´éæµè¡ççç¼çå¾©ååãéäºç¼ç¾ä¹è¡¨ç¤ºï¼å¨æµè¡çæéä¿é²åä½åæ¸å°ãæ­ä¾¿è»èãå¯ä»¥æ¹åå¬å±è¡çã

##### **Evaluating the Propensity of Generative AI for Producing Disinformation During an Election Cycle**
2411.06120v1 by Erik J Schlicht

Generative Artificial Intelligence offers a powerful tool for adversaries who
wish to engage in influence operations, such as the Chinese Spamouflage
operation and the Russian Internet Research Agency effort that both sought to
interfere with recent US election cycles. Therefore, this study seeks to
investigate the propensity of current Generative AI models for producing
harmful disinformation during an election cycle. The probability that different
Generative AI models produced disinformation when given adversarial prompts was
evaluated, in addition the associated harm. This allows for the expected harm
for each model to be computed and it was discovered that Copilot and Gemini
tied for the overall safest performance by realizing the lowest expected harm,
while GPT-4o produced the greatest rates of harmful disinformation, resulting
in much higher expected harm scores. The impact of disinformation category was
also investigated and Gemini was safest within the political category of
disinformation, while Copilot was safest for topics related to health.
Moreover, characteristics of adversarial roles were discovered that led to
greater expected harm across all models. Finally, classification models were
developed that predicted disinformation production based on the conditions
considered in this study, which offers insight into factors important for
predicting disinformation production. Based on all of these insights,
recommendations are provided that seek to mitigate factors that lead to harmful
disinformation being produced by Generative AI models. It is hoped that
developers will use these insights to improve future models.

æè¦ï¼çæå¼äººå·¥æºæ§çºææå¾äºå½±é¿åæä½çæµå°èæä¾å¼·å¤§çå·¥å·ï¼ä¾å¦ä¸­åçåå¾éµä»¶å½è£è¡ååä¿ç¾æ¯çç¶²è·¯ç ç©¶æ©æ§åªåï¼éå©èé½è©¦åå¹²é æè¿çç¾åé¸èé±æãå æ­¤ï¼æ¬ç ç©¶æ¨å¨èª¿æ¥ç¶åçæå¼ AI æ¨¡åå¨é¸èé±æä¸­ç¢çæå®³é¯èª¤è¨æ¯çå¾åãé¤äºç¸éå±å®³ä¹å¤ï¼éè©ä¼°äºå¨çµ¦å®å°ææç¤ºæä¸åçæå¼ AI æ¨¡åç¢çé¯èª¤è¨æ¯çå¯è½æ§ãéåè¨±è¨ç®æ¯åæ¨¡åçé æå±å®³ï¼ä¸¦ä¸ç¼ç¾ Copilot å Gemini å¨å¯¦ç¾æä½é æå±å®³æ¹é¢ä¸¦åçºæå®å¨çæ´é«æè½ï¼è GPT-4o ç¢çäºæé«æ¯ççæå®³é¯èª¤è¨æ¯ï¼å°è´é æå±å®³åæ¸é«å¾å¤ãéèª¿æ¥äºé¯èª¤è¨æ¯é¡å¥çå½±é¿ï¼ä¸¦ä¸ Gemini å¨æ¿æ²»é¡å¥çé¯èª¤è¨æ¯ä¸­æ¯æå®å¨çï¼è Copilot å¨èå¥åº·ç¸éçä¸»é¡ä¸­æå®å¨ãæ­¤å¤ï¼ç¼ç¾äºå°æè§è²çç¹æ§ï¼å°è´æææ¨¡åçé æå±å®³æ´å¤§ãæå¾ï¼éç¼äºåé¡æ¨¡åï¼æ ¹ææ¬ç ç©¶ä¸­èæ®çæ¢ä»¶é æ¸¬é¯èª¤è¨æ¯ç¢çï¼éæä¾äºå°é æ¸¬é¯èª¤è¨æ¯ç¢çå¾éè¦çå ç´ çè¦è§£ãæ ¹æææéäºè¦è§£ï¼æä¾äºå»ºè­°ï¼æ¨å¨æ¸è¼å°è´çæå¼ AI æ¨¡åç¢çæå®³é¯èª¤è¨æ¯çå ç´ ãå¸æéç¼äººå¡å°ä½¿ç¨éäºè¦è§£ä¾æ¹é²æªä¾çæ¨¡åã

##### **Personalize to generalize: Towards a universal medical multi-modality generalization through personalization**
2411.06106v2 by Zhaorui Tan, Xi Yang, Tan Pan, Tianyi Liu, Chen Jiang, Xin Guo, Qiufeng Wang, Anh Nguyen, Yuan Qi, Kaizhu Huang, Yuan Cheng

The differences among medical imaging modalities, driven by distinct
underlying principles, pose significant challenges for generalization in
multi-modal medical tasks. Beyond modality gaps, individual variations, such as
differences in organ size and metabolic rate, further impede a model's ability
to generalize effectively across both modalities and diverse populations.
Despite the importance of personalization, existing approaches to multi-modal
generalization often neglect individual differences, focusing solely on common
anatomical features. This limitation may result in weakened generalization in
various medical tasks. In this paper, we unveil that personalization is
critical for multi-modal generalization. Specifically, we propose an approach
to achieve personalized generalization through approximating the underlying
personalized invariant representation ${X}_h$ across various modalities by
leveraging individual-level constraints and a learnable biological prior. We
validate the feasibility and benefits of learning a personalized ${X}_h$,
showing that this representation is highly generalizable and transferable
across various multi-modal medical tasks. Extensive experimental results
consistently show that the additionally incorporated personalization
significantly improves performance and generalization across diverse scenarios,
confirming its effectiveness.

æè¦ï¼ç±æ¼ä¸åçåºç¤åçæé©åçé«å­¸å½±åæ¨¡å¼ä¹éçå·®ç°ï¼å°å¤æ¨¡å¼é«çä»»åä¸­çæ¦åæåºäºéå¤§ææ°ãé¤äºæ¨¡å¼å·®ç°ä¹å¤ï¼åé«å·®ç°ï¼ä¾å¦å¨å®å¤§å°åä»£è¬ççå·®ç°ï¼é²ä¸æ­¥é»ç¤äºæ¨¡åå¨ä¸åæ¨¡å¼åä¸åäººç¾¤ä¸­æææ¦åçè½åãåç®¡åæ§åå¾éè¦ï¼ä½ç¾æçå¤æ¨¡å¼æ¦åæ¹æ³éå¸¸å¿½ç¥åé«å·®ç°ï¼åéæ³¨å±åçè§£åç¹å¾µãéç¨®éå¶å¯è½æå°è´åç¨®é«çä»»åä¸­æ¦åè½åæ¸å¼±ãå¨æ¬æä¸­ï¼æåæ­ç¤ºäºåæ§åå°æ¼å¤æ¨¡å¼æ¦åè³ééè¦ãå·é«ä¾èªªï¼æåæåºäºä¸ç¨®æ¹æ³ï¼ééå©ç¨åé«ç´ç´æåå¯å­¸ç¿ççç©å­¸åé©ï¼å¨åç¨®æ¨¡å¼ä¸­è¿ä¼¼åºå±¤åæ§åä¸è®è¡¨ç¤º ${X}_h$ ä¾å¯¦ç¾åæ§åæ¦åãæåé©è­äºå­¸ç¿åæ§å ${X}_h$ çå¯è¡æ§åå¥½èï¼è¡¨æéç¨®è¡¨ç¤ºå·æé«åº¦çæ¦åæ§åå¯è½ç§»æ§ï¼é©ç¨æ¼åç¨®å¤æ¨¡å¼é«çä»»åãå»£æ³çå¯¦é©çµæä¸è´è¡¨æï¼é¡å¤ç´å¥çåæ§åé¡¯èæé«äºä¸åå ´æ¯ä¸çæ§è½åæ¦åè½åï¼è­å¯¦äºå¶æææ§ã

##### **Assessing Foundational Medical 'Segment Anything' (Med-SAM1, Med-SAM2) Deep Learning Models for Left Atrial Segmentation in 3D LGE MRI**
2411.05963v1 by Mehri Mehrnia, Mohamed Elbayumi, Mohammed S. M. Elbaz

Atrial fibrillation (AF), the most common cardiac arrhythmia, is associated
with heart failure and stroke. Accurate segmentation of the left atrium (LA) in
3D late gadolinium-enhanced (LGE) MRI is helpful for evaluating AF, as fibrotic
remodeling in the LA myocardium contributes to arrhythmia and serves as a key
determinant of therapeutic strategies. However, manual LA segmentation is
labor-intensive and challenging. Recent foundational deep learning models, such
as the Segment Anything Model (SAM), pre-trained on diverse datasets, have
demonstrated promise in generic segmentation tasks. MedSAM, a fine-tuned
version of SAM for medical applications, enables efficient, zero-shot
segmentation without domain-specific training. Despite the potential of MedSAM
model, it has not yet been evaluated for the complex task of LA segmentation in
3D LGE-MRI. This study aims to (1) evaluate the performance of MedSAM in
automating LA segmentation, (2) compare the performance of the MedSAM2 model,
which uses a single prompt with automated tracking, with the MedSAM1 model,
which requires separate prompt for each slice, and (3) analyze the performance
of MedSAM1 in terms of Dice score(i.e., segmentation accuracy) by varying the
size and location of the box prompt.

æè¦ï¼å¿æ¿é¡«å (AF) æ¯æå¸¸è¦çå¿å¾ä¸æ´ï¼èå¿èè¡°ç«­åä¸­é¢¨æéã3D ææéå¢å¼· (LGE) MRI ä¸­å·¦å¿æ¿ (LA) çç²¾ç¢ºåå²æå©æ¼è©ä¼° AFï¼å çº LA å¿èä¸­ççºç¶­åéå¡æå°è´å¿å¾ä¸æ´ï¼ä¸¦ä½çºæ²»çç­ç¥çééµæ±ºå®å ç´ ãç¶èï¼æå LA åå²æ¢è²»ååå·æææ°æ§ãæè¿åºç¤æ·±åº¦å­¸ç¿æ¨¡åï¼ä¾å¦å¨ä¸åè³æéä¸é åè¨ç·´ç Segment Anything Model (SAM)ï¼å·²å¨éç¨åå²ä»»åä¸­å±ç¾åºåæ¯ãMedSAM æ¯ SAM çå¾®èª¿çæ¬ï¼é©ç¨æ¼é«çæç¨ï¼å®è½é²è¡ææãé¶æ¬¡å­¸ç¿çåå²ï¼èç¡éç¹å®é åçè¨ç·´ãåç®¡ MedSAM æ¨¡åå·ææ½åï¼ä½å°æªè©ä¼°å¶å¨ 3D LGE-MRI ä¸­ LA åå²çè¤éä»»åãæ¬ç ç©¶æ¨å¨ (1) è©ä¼° MedSAM å¨èªåå LA åå²ä¸­çæè½ï¼(2) æ¯è¼ä½¿ç¨å®ä¸æç¤ºåèªåè¿½è¹¤ç MedSAM2 æ¨¡åèéè¦çºæ¯ååçæä¾å®ç¨æç¤ºç MedSAM1 æ¨¡åçæè½ï¼ä»¥å (3) åæ MedSAM1 å¨éª°å­åæ¸ï¼å³åå²æºç¢ºåº¦ï¼æ¹é¢çæè½ï¼æ¹æ³æ¯æ¹è®æ¹æ¡æç¤ºçå¤§å°åä½ç½®ã

##### **GazeSearch: Radiology Findings Search Benchmark**
2411.05780v1 by Trong Thang Pham, Tien-Phat Nguyen, Yuki Ikebe, Akash Awasthi, Zhigang Deng, Carol C. Wu, Hien Nguyen, Ngan Le

Medical eye-tracking data is an important information source for
understanding how radiologists visually interpret medical images. This
information not only improves the accuracy of deep learning models for X-ray
analysis but also their interpretability, enhancing transparency in
decision-making. However, the current eye-tracking data is dispersed,
unprocessed, and ambiguous, making it difficult to derive meaningful insights.
Therefore, there is a need to create a new dataset with more focus and
purposeful eyetracking data, improving its utility for diagnostic applications.
In this work, we propose a refinement method inspired by the target-present
visual search challenge: there is a specific finding and fixations are guided
to locate it. After refining the existing eye-tracking datasets, we transform
them into a curated visual search dataset, called GazeSearch, specifically for
radiology findings, where each fixation sequence is purposefully aligned to the
task of locating a particular finding. Subsequently, we introduce a scan path
prediction baseline, called ChestSearch, specifically tailored to GazeSearch.
Finally, we employ the newly introduced GazeSearch as a benchmark to evaluate
the performance of current state-of-the-art methods, offering a comprehensive
assessment for visual search in the medical imaging domain.

æè¦ï¼é«çç¼åè¿½è¹¤è³ææ¯äºè§£æ¾å°ç§é«å¸«å¦ä½è¦è¦ºåè©®éé«çå½±åçéè¦è³è¨ä¾æºãéäºè³è¨ä¸åæåäºæ·±åº¦å­¸ç¿æ¨¡åå¨ X ååæä¸­çæºç¢ºåº¦ï¼ä¹æåäºå¶å¯è§£éæ§ï¼å¢é²æ±ºç­å¶å®ä¸­çéæåº¦ãç¶èï¼ç®åçé«çç¼åè¿½è¹¤è³æåæ£ãæªç¶èçä¸ä¸æç¢ºï¼éä½¿å¾é£ä»¥æ¨å°åºææç¾©çè¦è§£ãå æ­¤ï¼æå¿è¦å»ºç«ä¸åæ°çè³æéï¼å¶ä¸­åå«æ´å¤ç¦é»åæç®ççç¼åè¿½è¹¤è³æï¼ä»¥æåå¶å¨è¨ºæ·æç¨ä¸­çæç¨ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ¹è¯æ¹æ³ï¼å¶éæä¾èªç®æ¨åç¾è¦è¦ºæå°ææ°ï¼æä¸åç¹å®çç¼ç¾ï¼èåºå®åç¨æ¼å®ä½å®ãå¨æ¹è¯ç¾æçç¼åè¿½è¹¤è³æéå¾ï¼æåå°å¶è½æçºä¸ååçº GazeSearch çç²¾é¸è¦è¦ºæå°è³æéï¼å°éç¨æ¼æ¾å°ç§ç¼ç¾ï¼å¶ä¸­æ¯ååºå®åºåé½å»æèå®ä½ç¹å®ç¼ç¾çä»»åå°é½ãé¨å¾ï¼æåä»ç´¹äºä¸åææè·¯å¾é æ¸¬åºæºï¼ç¨±çº ChestSearchï¼å°ééå° GazeSearch éèº«æé ãæå¾ï¼æåæ¡ç¨æ°æ¨åºç GazeSearch ä½çºåºæºï¼è©ä¼°ç®åæåé²æ¹æ³çæè½ï¼æä¾é«çå½±åé åä¸­è¦è¦ºæå°çå¨é¢è©ä¼°ã

##### **Humans Continue to Outperform Large Language Models in Complex Clinical Decision-Making: A Study with Medical Calculators**
2411.05897v1 by Nicholas Wan, Qiao Jin, Joey Chan, Guangzhi Xiong, Serina Applebaum, Aidan Gilson, Reid McMurry, R. Andrew Taylor, Aidong Zhang, Qingyu Chen, Zhiyong Lu

Although large language models (LLMs) have been assessed for general medical
knowledge using medical licensing exams, their ability to effectively support
clinical decision-making tasks, such as selecting and using medical
calculators, remains uncertain. Here, we evaluate the capability of both
medical trainees and LLMs to recommend medical calculators in response to
various multiple-choice clinical scenarios such as risk stratification,
prognosis, and disease diagnosis. We assessed eight LLMs, including
open-source, proprietary, and domain-specific models, with 1,009
question-answer pairs across 35 clinical calculators and measured human
performance on a subset of 100 questions. While the highest-performing LLM,
GPT-4o, provided an answer accuracy of 74.3% (CI: 71.5-76.9%), human
annotators, on average, outperformed LLMs with an accuracy of 79.5% (CI:
73.5-85.0%). With error analysis showing that the highest-performing LLMs
continue to make mistakes in comprehension (56.6%) and calculator knowledge
(8.1%), our findings emphasize that humans continue to surpass LLMs on complex
clinical tasks such as calculator recommendation.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å·²ä½¿ç¨é«å­¸å·ç§èè©¦è©ä¼°å¶ä¸è¬é«å­¸ç¥è­ï¼ä½å®åæææ¯æ´è¨åºæ±ºç­ä»»åï¼ä¾å¦é¸æåä½¿ç¨é«å­¸è¨ç®å¨ï¼çè½åä»ä¸ç¢ºå®ãå¨æ­¤ï¼æåè©ä¼°é«å­¸åè¨èå LLM æ¨è¦é«å­¸è¨ç®å¨çè½åï¼ä»¥åæåç¨®å¤é¸é¡è¨åºæå¢ï¼ä¾å¦é¢¨éªåå±¤ãé å¾åç¾çè¨ºæ·ãæåè©ä¼°äºå«å LLMï¼åæ¬éæºãå°æåç¹å®é åçæ¨¡åï¼å¶ä¸­åå« 35 åè¨åºè¨ç®å¨ç 1,009 ååç­å°ï¼ä¸¦æ¸¬éäºäººé¡å¨ 100 ååé¡å­éä¸çè¡¨ç¾ãè¡¨ç¾æä½³ç LLM GPT-4o æä¾äº 74.3% çåç­æºç¢ºåº¦ (CIï¼71.5-76.9%)ï¼èäººé¡è¨»è§£èå¹³åè¡¨ç¾åªæ¼ LLMï¼æºç¢ºåº¦çº 79.5% (CIï¼73.5-85.0%)ãé¯èª¤åæé¡¯ç¤ºï¼è¡¨ç¾æä½³ç LLM å¨çè§£ (56.6%) åè¨ç®å¨ç¥è­ (8.1%) æ¹é¢ä»æç¯é¯ï¼æåçç ç©¶çµæå¼·èª¿ï¼äººé¡å¨è¨ç®å¨æ¨è¦ç­è¤éè¨åºä»»åä¸ä»ç¶åªæ¼ LLMã

##### **Identifying and Decomposing Compound Ingredients in Meal Plans Using Large Language Models**
2411.05892v1 by Leon Kopitar, Leon Bedrac, Larissa J Strath, Jiang Bian, Gregor Stiglic

This study explores the effectiveness of Large Language Models in meal
planning, focusing on their ability to identify and decompose compound
ingredients. We evaluated three models-GPT-4o, Llama-3 (70b), and Mixtral
(8x7b)-to assess their proficiency in recognizing and breaking down complex
ingredient combinations. Preliminary results indicate that while Llama-3 (70b)
and GPT-4o excels in accurate decomposition, all models encounter difficulties
with identifying essential elements like seasonings and oils. Despite strong
overall performance, variations in accuracy and completeness were observed
across models. These findings underscore LLMs' potential to enhance
personalized nutrition but highlight the need for further refinement in
ingredient decomposition. Future research should address these limitations to
improve nutritional recommendations and health outcomes.

æè¦ï¼éé ç ç©¶æ¢è¨å¤§åèªè¨æ¨¡åå¨é¤é»è¦åä¸­çæè½ï¼èéæ¼å¶è¾¨è­ä¸¦åè§£è¤åé£æçè½åãæåè©ä¼°äºä¸åæ¨¡åï¼GPT-4oãLlama-3 (70b) å Mixtral (8x7b)ï¼ä»¥è©éå¶è¾¨è­ä¸¦åè§£è¤éé£æçµåçè½åãåæ­¥çµæé¡¯ç¤ºï¼éç¶ Llama-3 (70b) å GPT-4o å¨æºç¢ºåè§£æ¹é¢è¡¨ç¾åºè²ï¼ä½æææ¨¡åå¨è¾¨è­èª¿å³æåæ²¹èç­å¿è¦åç´ æé½éå°å°é£ãåç®¡æ´é«è¡¨ç¾å¼·åï¼ä½ååæ¨¡åå¨æºç¢ºæ§åå®æ´æ§æ¹é¢ä»æå·®ç°ãéäºç¼ç¾å¼·èª¿äº LLM å¢å¼·åäººåçé¤çæ½åï¼ä½åæä¹çªé¡¯äºé²ä¸æ­¥åªåé£æåè§£æè¡çå¿è¦æ§ãæªä¾çç ç©¶æéå°éäºéå¶é²è¡æ¢è¨ï¼ä»¥æ¹åçé¤å»ºè­°åå¥åº·ææã

##### **SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**
2411.05521v2 by Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, Jonathan Fuerst

Electronic health records (EHRs) are stored in various database systems with
different database models on heterogeneous storage architectures, such as
relational databases, document stores, or graph databases. These different
database models have a big impact on query complexity and performance. While
this has been a known fact in database research, its implications for the
growing number of Text-to-Query systems have surprisingly not been investigated
so far. In this paper, we present SM3-Text-to-Query, the first multi-model
medical Text-to-Query benchmark based on synthetic patient data from Synthea,
following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology
covering medical terminology. SM3-Text-to-Query provides data representations
for relational databases (PostgreSQL), document stores (MongoDB), and graph
databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four
popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically
and manually develop 408 template questions, which we augment to construct a
benchmark of 10K diverse natural language question/query pairs for these four
query languages (40K pairs overall). On our dataset, we evaluate several common
in-context-learning (ICL) approaches for a set of representative closed and
open-source LLMs. Our evaluation sheds light on the trade-offs between database
models and query languages for different ICL strategies and LLMs. Last,
SM3-Text-to-Query is easily extendable to additional query languages or real,
standard-based patient databases.

æè¦ï¼é»å­å¥åº·è¨é (EHR) å²å­å¨å·æä¸åè³æåº«æ¨¡åçåç¨®è³æåº«ç³»çµ±ä¸­ï¼æ¡ç¨ç°è³ªå²å­æ¶æ§ï¼ä¾å¦éè¯å¼è³æåº«ãæä»¶å²å­åº«æåå½¢è³æåº«ãéäºä¸åçè³æåº«æ¨¡åå°æ¥è©¢è¤éåº¦åæè½æå¾å¤§çå½±é¿ãéç¶éå¨è³æåº«ç ç©¶ä¸­æ¯ä¸åå·²ç¥çäºå¯¦ï¼ä½å¶å°è¶ä¾è¶å¤çæå­è½æ¥è©¢ç³»çµ±çå½±é¿å»ä»¤äººé©è¨å°å°æªè¢«ç ç©¶ãå¨æ¬æä¸­ï¼æåæåº SM3-Text-to-Queryï¼éæ¯ç¬¬ä¸ååºæ¼ Synthea åææ£èè³æçå¤æ¨¡åé«çæå­è½æ¥è©¢åºæºï¼éµå¾ª SNOMED-CT åé¡æ³ï¼éæ¯ä¸åå»£æ³ä½¿ç¨çç¥è­åå½¢æ¬é«ï¼æ¶µèé«å­¸è¡èªãSM3-Text-to-Query æä¾äºéä¿è³æåº« (PostgreSQL)ãæä»¶å²å­åº« (MongoDB) ååå½¢è³æåº« (Neo4j å GraphDB (RDF)) çè³æè¡¨ç¤ºï¼åè¨±è·¨åç¨®æµè¡çæ¥è©¢èªè¨é²è¡è©ä¼°ï¼å³ SQLãMQLãCypher å SPARQLãæåç³»çµ±ä¸æåéç¼äº 408 åç¯æ¬åé¡ï¼ä¸¦æ´åéäºåé¡ä»¥å»ºæ§ä¸ååºæºï¼å¶ä¸­åå« 10K åéå°éåç¨®æ¥è©¢èªè¨çå¤æ¨£åèªç¶èªè¨åé¡/æ¥è©¢éå°ï¼ç¸½å± 40K åéå°ï¼ãå¨æåçè³æéä¸ï¼æåè©ä¼°äºä¸çµä»£è¡¨æ§çå°éåéæ¾åå§ç¢¼ LLM çå¹¾åå¸¸è¦æå¢å­¸ç¿ (ICL) æ¹æ³ãæåçè©ä¼°æ­ç¤ºäºä¸å ICL ç­ç¥å LLM çè³æåº«æ¨¡ååæ¥è©¢èªè¨ä¹éçæ¬è¡¡ãæå¾ï¼SM3-Text-to-Query å¯ä»¥è¼é¬æ´åå°å¶ä»æ¥è©¢èªè¨æçå¯¦çãåºæ¼æ¨æºçæ£èè³æåº«ã

##### **Towards Scalable Foundation Models for Digital Dermatology**
2411.05514v1 by Fabian GrÃ¶ger, Philippe Gottfrois, Ludovic Amruthalingam, Alvaro Gonzalez-Jimenez, Simone Lionetti, Luis R. Soenksen-Martinez, Alexander A. Navarini, Marc Pouly

The growing demand for accurate and equitable AI models in digital
dermatology faces a significant challenge: the lack of diverse, high-quality
labeled data. In this work, we investigate the potential of domain-specific
foundation models for dermatology in addressing this challenge. We utilize
self-supervised learning (SSL) techniques to pre-train models on a dataset of
over 240,000 dermatological images from public and private collections. Our
study considers several SSL methods and compares the resulting foundation
models against domain-agnostic models like those pre-trained on ImageNet and
state-of-the-art models such as MONET across 12 downstream tasks. Unlike
previous research, we emphasize the development of smaller models that are more
suitable for resource-limited clinical settings, facilitating easier adaptation
to a broad range of use cases. Results show that models pre-trained in this
work not only outperform general-purpose models but also approach the
performance of models 50 times larger on clinically relevant diagnostic tasks.
To promote further research in this direction, we publicly release both the
training code and the foundation models, which can benefit clinicians in
dermatological applications.

æè¦ï¼æ¸ä½ç®èç§å°ç²¾æºä¸å¬å¹³ç AI æ¨¡åéæ±æ¥çå¢å ï¼ä½é¢è¨ä¸é éå¤§ææ°ï¼ç¼ºä¹å¤åä¸é«åè³ªçæ¨è¨è³æãå¨éé ç ç©¶ä¸­ï¼æåæ¢è¨ç¹å®é åçåºç¤æ¨¡åå¨ç®èç§ä¸­è§£æ±ºæ­¤ææ°çå¯è½æ§ãæåå©ç¨èªç£ç£å­¸ç¿ (SSL) æè¡å¨åå«è¶é 24 è¬å¼µä¾èªå¬æåç§æè³æåº«çç®èç§å½±åçè³æéä¸é åè¨ç·´æ¨¡åãæåçç ç©¶èéäºå¤ç¨® SSL æ¹æ³ï¼ä¸¦å°ç¢ççåºç¤æ¨¡åèä¸åé åéå¶çæ¨¡åï¼ä¾å¦å¨ ImageNet ä¸é åè¨ç·´çæ¨¡åï¼ä»¥åæåé²çæ¨¡åï¼ä¾å¦ MONETï¼å¨ 12 åä¸æ¸¸ä»»åä¸­é²è¡æ¯è¼ãèååçç ç©¶ä¸åï¼æåå¼·èª¿éç¼æ´é©åè³æºæéçè¨åºç°å¢çå°åæ¨¡åï¼ä»¥å©æ¼æ´è¼é¬å°é©æå»£æ³çç¨ä¾ãçµæé¡¯ç¤ºï¼å¨éé ç ç©¶ä¸­é åè¨ç·´çæ¨¡åä¸ååªæ¼éç¨æ¨¡åï¼èä¸å¨è¨åºä¸ç¸éçè¨ºæ·ä»»åä¸­ï¼å¶æè½ä¹æ¥è¿å¤§ 50 åçæ¨¡åãçºäºä¿é²æ­¤æ¹åçé²ä¸æ­¥ç ç©¶ï¼æåå¬éç¼å¸è¨ç·´ç¨å¼ç¢¼ååºç¤æ¨¡åï¼éäºæ¨¡åå¯è®ç®èç§æç¨ä¸­çè¨åºé«çåçã

##### **Towards Equitable ASD Diagnostics: A Comparative Study of Machine and Deep Learning Models Using Behavioral and Facial Data**
2411.05880v1 by Mohammed Aledhari, Mohamed Rahouti, Ali Alfatemi

Autism Spectrum Disorder (ASD) is often underdiagnosed in females due to
gender-specific symptom differences overlooked by conventional diagnostics.
This study evaluates machine learning models, particularly Random Forest and
convolutional neural networks, for enhancing ASD diagnosis through structured
data and facial image analysis. Random Forest achieved 100% validation accuracy
across datasets, highlighting its ability to manage complex relationships and
reduce false negatives, which is crucial for early intervention and addressing
gender biases. In image-based analysis, MobileNet outperformed the baseline
CNN, achieving 87% accuracy, though a 30% validation loss suggests possible
overfitting, requiring further optimization for robustness in clinical
settings. Future work will emphasize hyperparameter tuning, regularization, and
transfer learning. Integrating behavioral data with facial analysis could
improve diagnosis for underdiagnosed groups. These findings suggest Random
Forest's high accuracy and balanced precision-recall metrics could enhance
clinical workflows. MobileNet's lightweight structure also shows promise for
resource-limited environments, enabling accessible ASD screening. Addressing
model explainability and clinician trust will be vital.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) ç±æ¼æ§å¥ç¹ç°çççå·®ç°ï¼å¸¸è¢«å¿½ç¥èæ¼è¨ºãæ¬ç ç©¶è©ä¼°æ©å¨å­¸ç¿æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®æåå·ç©ç¥ç¶ç¶²è·¯ï¼ä»¥ééçµæ§åè³æåèé¨å½±ååæä¾å¼·å ASD è¨ºæ·ãé¨æ©æ£®æå¨ææè³æéä¸­çé©è­æºç¢ºåº¦éå° 100%ï¼çªé¡¯å¶èçè¤ééä¿åæ¸å°åé°æ§çè½åï¼éå°æ¼æ©æä»å¥åè§£æ±ºæ§å¥åè¦è³ééè¦ãå¨åºæ¼å½±åçåæä¸­ï¼MobileNet åªæ¼åºæº CNNï¼æºç¢ºåº¦éå° 87%ï¼åç®¡ 30% çé©è­æå¤±è¡¨æå¯è½éåº¦æ¬åï¼éè¦é²ä¸æ­¥æä½³åä»¥æé«è¨åºç°å¢ä¸­çç©©å¥æ§ãæªä¾çç ç©¶å°å¼·èª¿è¶åæ¸èª¿æ´ãæ­£åååé·ç§»å­¸ç¿ãå°è¡çºè³æèèé¨åææ´åï¼å¯ä»¥æ¹åæ¼è¨ºç¾¤é«çè¨ºæ·ãéäºç¼ç¾è¡¨æé¨æ©æ£®æçé«æºç¢ºåº¦åå¹³è¡¡çç²¾ç¢ºåº¦å¬åææ¨å¯ä»¥å¢å¼·è¨åºå·¥ä½æµç¨ãMobileNet çè¼éç´çµæ§ä¹é¡¯ç¤ºåºå¨è³æºåéçç°å¢ä¸­å¾æåæ¯ï¼å¯ä»¥é²è¡ç¡éç¤ç ASD ç¯©æª¢ãè§£æ±ºæ¨¡åå¯è§£éæ§åè¨åºé«å¸«çä¿¡ä»»è³ééè¦ã

##### **Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations**
2411.05194v1 by Joey Hong, Jessica Lin, Anca Dragan, Sergey Levine

Recent progress on large language models (LLMs) has enabled dialogue agents
to generate highly naturalistic and plausible text. However, current LLM
language generation focuses on responding accurately to questions and requests
with a single effective response. In reality, many real dialogues are
interactive, meaning an agent's utterances will influence their conversational
partner, elicit information, or change their opinion. Accounting for how an
agent can effectively steer a conversation is a crucial ability in many
dialogue tasks, from healthcare to preference elicitation. Existing methods for
fine-tuning dialogue agents to accomplish such tasks would rely on curating
some amount of expert data. However, doing so often requires understanding the
underlying cognitive processes of the conversational partner, which is a skill
neither humans nor LLMs trained on human data can reliably do. Our key insight
is that while LLMs may not be adept at identifying effective strategies for
steering conversations a priori, or in the middle of an ongoing conversation,
they can do so post-hoc, or in hindsight, after seeing how their conversational
partner responds. We use this fact to rewrite and augment existing suboptimal
data, and train via offline reinforcement learning (RL) an agent that
outperforms both prompting and learning from unaltered human demonstrations. We
apply our approach to two domains that require understanding human mental
state, intelligent interaction, and persuasion: mental health support, and
soliciting charitable donations. Our results in a user study with real humans
show that our approach greatly outperforms existing state-of-the-art dialogue
agents.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±ä½¿å°è©±ä»£çè½å¤ çæé«åº¦èªç¶ä¸åççæå­ãç¶èï¼ç®åç LLM èªè¨çæèéæ¼ä»¥å®ä¸ææçåææºç¢ºåæåé¡åè¦æ±ãå¨ç¾å¯¦ä¸­ï¼è¨±å¤çå¯¦å°è©±é½æ¯äºåçï¼éè¡¨ç¤ºä»£çäººçç¼è¨æå½±é¿ä»åçå°è©±å¤¥ä¼´ãå¼åºè³è¨ææ¹è®ä»åçæè¦ãèéä»£çäººå¦ä½ææå¼å°å°è©±çè½åå¨è¨±å¤å°è©±ä»»åä¸­è³ééè¦ï¼å¾é«çä¿å¥å°åå¥½å¼å°çæ¯å¦æ­¤ãç¾æçå¾®èª¿å°è©±ä»£çæ¹æ³ä»¥å®ææ­¤é¡ä»»åæä¾è³´æ¼ç­åä¸å®éçå°å®¶è³æãç¶èï¼ééº¼åéå¸¸éè¦äºè§£å°è©±å¤¥ä¼´çåºç¤èªç¥æ­·ç¨ï¼èéé æè½æ¢ä¸æ¯äººé¡ä¹ä¸æ¯è¨ç·´éäººé¡è³æç LLM å¯é å·åçãæåçééµè¦è§£å¨æ¼ï¼åç®¡ LLM å¯è½ä¸æé·æ¼äºåæå¨å°è©±é²è¡ä¸­è­å¥åºå¼å°å°è©±çææç­ç¥ï¼ä½ä»åå¯ä»¥å¨äºå¾æåé¡§æï¼å¨çå°ä»åçå°è©±å¤¥ä¼´å¦ä½åæå¾ééº¼åãæåå©ç¨éåäºå¯¦ä¾æ¹å¯«ä¸¦æ´åç¾æçæ¬¡ä½³è³æï¼ä¸¦ééé¢ç·å¼·åå­¸ç¿ (RL) è¨ç·´ä¸åä»£çäººï¼å¶è¡¨ç¾åªæ¼æç¤ºåå¾æªç¶ä¿®æ¹çäººé¡ç¤ºç¯ä¸­å­¸ç¿ãæåå°æåçåæ³æç¨æ¼éè¦äºè§£äººé¡å¿ççæãæºæ§äºååèªªæçå©åé åï¼å¿çå¥åº·æ¯æååéæåææ¬¾ãæåå¨èçå¯¦äººé¡é²è¡çä½¿ç¨èç ç©¶ä¸­ççµæé¡¯ç¤ºï¼æåçåæ³å¤§å¹åªæ¼ç¾æçæåé²å°è©±ä»£çã

##### **Inverse Transition Learning: Learning Dynamics from Demonstrations**
2411.05174v1 by Leo Benac, Abhishek Sharma, Sonali Parbhoo, Finale Doshi-Velez

We consider the problem of estimating the transition dynamics $T^*$ from
near-optimal expert trajectories in the context of offline model-based
reinforcement learning. We develop a novel constraint-based method, Inverse
Transition Learning, that treats the limited coverage of the expert
trajectories as a \emph{feature}: we use the fact that the expert is
near-optimal to inform our estimate of $T^*$. We integrate our constraints into
a Bayesian approach. Across both synthetic environments and real healthcare
scenarios like Intensive Care Unit (ICU) patient management in hypotension, we
demonstrate not only significant improvements in decision-making, but that our
posterior can inform when transfer will be successful.

æè¦ï¼æåèæ®å¨é¢ç·æ¨¡ååºç¤å¼·åå­¸ç¿çèçµ¡ä¸­ï¼å¾æ¥è¿æä½³çå°å®¶è»è·¡ä¼°è¨è½æåæ $T^*$ çåé¡ãæåéç¼ä¸ç¨®æ°çåºæ¼ç´æçæ¹æ³ï¼éè½æå­¸ç¿ï¼å®å°å°å®¶è»è·¡çæéè¦èç¯åè¦çºä¸ç¨®ãç¹å¾µãï¼æåå©ç¨å°å®¶æ¥è¿æä½³çäºå¯¦ä¾åç¥æåå° $T^*$ çä¼°è¨ãæåå°æåçç´ææ´åå°è²æ°æ¹æ³ä¸­ãå¨ç¶åç°å¢åå¯¦éé«çä¿å¥å ´æ¯ï¼ä¾å¦ä½è¡å£éçç£è­·çæ¿ (ICU) çæ£ç®¡çï¼ä¸­ï¼æåä¸åå±ç¤ºäºæ±ºç­å¶å®æ¹é¢çé¡¯èé²æ­¥ï¼èä¸æåçå¾é©å¯ä»¥åç¥è½ç§»ä½æææåã

##### **PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation**
2411.05085v1 by Daniel C. Castro, Aurelia Bustos, Shruthi Bannur, Stephanie L. Hyland, Kenza Bouzid, Maria Teodora Wetscherek, Maria Dolores SÃ¡nchez-Valverde, Lara Jaques-PÃ©rez, Lourdes PÃ©rez-RodrÃ­guez, Kenji Takeda, JosÃ© MarÃ­a Salinas, Javier Alvarez-Valle, JoaquÃ­n Galant Herrero, Antonio Pertusa

Radiology report generation (RRG) aims to create free-text radiology reports
from clinical imaging. Grounded radiology report generation (GRRG) extends RRG
by including the localisation of individual findings on the image. Currently,
there are no manually annotated chest X-ray (CXR) datasets to train GRRG
models. In this work, we present a dataset called PadChest-GR
(Grounded-Reporting) derived from PadChest aimed at training GRRG models for
CXR images. We curate a public bi-lingual dataset of 4,555 CXR studies with
grounded reports (3,099 abnormal and 1,456 normal), each containing complete
lists of sentences describing individual present (positive) and absent
(negative) findings in English and Spanish. In total, PadChest-GR contains
7,037 positive and 3,422 negative finding sentences. Every positive finding
sentence is associated with up to two independent sets of bounding boxes
labelled by different readers and has categorical labels for finding type,
locations, and progression. To the best of our knowledge, PadChest-GR is the
first manually curated dataset designed to train GRRG models for understanding
and interpreting radiological images and generated text. By including detailed
localization and comprehensive annotations of all clinically relevant findings,
it provides a valuable resource for developing and evaluating GRRG models from
CXR images. PadChest-GR can be downloaded under request from
https://bimcv.cipf.es/bimcv-projects/padchest-gr/

æè¦ï¼<paragraph>æ¾å°å­¸å ±åçæ (RRG) æ¨å¨å¾è¨åºå½±åå»ºç«èªç±æå­çæ¾å°å­¸å ±åãåºç¤æ¾å°å­¸å ±åçæ (GRRG) ééç´å¥å½±åä¸åå¥ç¼ç¾çå®ä½ï¼ä¾å»¶ä¼¸ RRGãç®åï¼æ²ææåæ¨è¨çè¸é¨ X å (CXR) è³æéï¼å¯ä¾è¨ç·´ GRRG æ¨¡åãå¨æ­¤ç ç©¶ä¸­ï¼æåæåºä¸ååçº PadChest-GRï¼åºç¤å ±åï¼çè³æéï¼å¶æºèª PadChestï¼æ¨å¨è¨ç·´ CXR å½±åç GRRG æ¨¡åãæåç­åäºä¸åå¬éçéèªè³æéï¼å¶ä¸­åå« 4,555 ä»½ CXR ç ç©¶ï¼éæåºç¤å ±åï¼3,099 ä»½ç°å¸¸å ±åå 1,456 ä»½æ­£å¸¸å ±åï¼ï¼æ¯åå ±åé½åå«å®æ´çå¥å­æ¸å®ï¼ç¨è±æåè¥¿ç­çææè¿°åå¥å­å¨çï¼é½æ§ï¼åä¸å­å¨çï¼é°æ§ï¼ç¼ç¾ãç¸½è¨ï¼PadChest-GR åå« 7,037 åé½æ§ç¼ç¾å¥å­å 3,422 åé°æ§ç¼ç¾å¥å­ãæ¯åé½æ§ç¼ç¾å¥å­æå¤èå©çµç¨ç«çéçæ¡ç¸éè¯ï¼ç±ä¸åçè®èæ¨è¨ï¼ä¸¦å·æç¼ç¾é¡åãä½ç½®åé²å±çåé¡æ¨ç±¤ãææåæç¥ï¼PadChest-GR æ¯ç¬¬ä¸åæåç­åçè³æéï¼æ¨å¨è¨ç·´ GRRG æ¨¡åï¼ä»¥çè§£åè©®éæ¾å°å­¸å½±ååç¢ççæå­ãééç´å¥ææè¨åºç¸éç¼ç¾çè©³ç´°å®ä½åç¶åè¨»è§£ï¼å®çºå¾ CXR å½±åéç¼åè©ä¼° GRRG æ¨¡åæä¾äºå¯¶è²´çè³æºãPadChest-GR å¯æè¦æ±å¾ https://bimcv.cipf.es/bimcv-projects/padchest-gr/ ä¸è¼</paragraph>

##### **Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability**
2411.04962v1 by Yanjun Gao, Skatje Myers, Shan Chen, Dmitriy Dligach, Timothy A Miller, Danielle Bitterman, Guanhua Chen, Anoop Mayampurath, Matthew Churpek, Majid Afshar

Large language models (LLMs) are being explored for diagnostic decision
support, yet their ability to estimate pre-test probabilities, vital for
clinical decision-making, remains limited. This study evaluates two LLMs,
Mistral-7B and Llama3-70B, using structured electronic health record data on
three diagnosis tasks. We examined three current methods of extracting LLM
probability estimations and revealed their limitations. We aim to highlight the
need for improved techniques in LLM confidence estimation.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£å¨è¢«æ¢ç´¢ç¨æ¼è¨ºæ·æ±ºç­æ¯æï¼ä½å®åä¼°è¨è¨åºæ±ºç­å¶å®ä¸­è³ééè¦çé æ¸¬è©¦æ¦ççè½åä»ç¶æéãæ¬ç ç©¶ä½¿ç¨ä¸åè¨ºæ·ä»»åççµæ§åé»å­å¥åº·è¨éæ¸æè©ä¼°äºå©å LLMï¼Mistral-7B å Llama3-70Bãæåæª¢æ¥äºæå LLM æ¦çä¼°è¨çä¸ç¨®ç¶åæ¹æ³ä¸¦æ­ç¤ºäºå®åçå±éæ§ãæåçç®æ¨æ¯å¼·èª¿æ¹é² LLM ç½®ä¿¡åº¦ä¼°è¨æè¡çå¿è¦æ§ã

##### **FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge into LLMs?**
2411.05059v2 by Eric Wu, Kevin Wu, James Zou

There is great interest in fine-tuning frontier large language models (LLMs)
to inject new information and update existing knowledge. While commercial LLM
fine-tuning APIs from providers such as OpenAI and Google promise flexible
adaptation for various applications, the efficacy of fine-tuning remains
unclear. In this study, we introduce FineTuneBench, an evaluation framework and
dataset for understanding how well commercial fine-tuning APIs can successfully
learn new and updated knowledge. We analyze five frontier LLMs with
commercially available fine-tuning APIs, including GPT-4o and Gemini 1.5 Pro,
on their effectiveness in two settings: (1) ingesting novel information, such
as recent news events and new people profiles, and (2) updating existing
knowledge, such as updated medical guidelines and code frameworks. Our results
reveal substantial shortcomings in all the models' abilities to effectively
learn new information through fine-tuning, with an average generalization
accuracy of 37% across all models. When updating existing knowledge, such as
incorporating medical guideline updates, commercial fine-tuning APIs show even
more limited capability (average generalization accuracy of 19%). Overall,
fine-tuning GPT-4o mini is the most effective for infusing new knowledge and
updating knowledge, followed by GPT-3.5 Turbo and GPT-4o. The fine-tuning APIs
for Gemini 1.5 Flesh and Gemini 1.5 Pro are unable to learn new knowledge or
update existing knowledge. These findings underscore a major shortcoming in
using current commercial fine-tuning services to achieve reliable knowledge
infusion in common scenarios. We open source the FineTuneBench dataset at
https://github.com/kevinwu23/StanfordFineTuneBench.

æè¦ï¼<paragraph>å¾®è°åæ²¿å¤§åè¯­è¨æ¨¡å (LLM) ä»¥æ³¨å¥æ°ä¿¡æ¯å¹¶æ´æ°ç°æç¥è¯å¼èµ·äºæå¤§çå´è¶£ãè½ç¶æ¥èª OpenAI å Google ç­æä¾åçåä¸ LLM å¾®è° API æ¿è¯ºä¸ºåç§åºç¨ç¨åºæä¾çµæ´»çéåºæ§ï¼ä½å¾®è°çåæä»ä¸æç¡®ãå¨è¿é¡¹ç ç©¶ä¸­ï¼æä»¬ä»ç»äº FineTuneBenchï¼è¿æ¯ä¸ä¸ªè¯ä¼°æ¡æ¶åæ°æ®éï¼ç¨äºçè§£åä¸å¾®è° API å¦ä½æåå­¦ä¹ æ°çåæ´æ°çç¥è¯ãæä»¬åæäºäºç§åæ²¿ LLMï¼å®ä»¬å·æå¯åç¨çå¾®è° APIï¼åæ¬ GPT-4o å Gemini 1.5 Proï¼å¨ä¸¤ç§è®¾ç½®ä¸­çæææ§ï¼(1) æåæ°ä¿¡æ¯ï¼ä¾å¦æè¿çæ°é»äºä»¶åæ°çäººç©ç®ä»ï¼ä»¥å (2) æ´æ°ç°æç¥è¯ï¼ä¾å¦æ´æ°çå»çæååä»£ç æ¡æ¶ãæä»¬çç»ææ­ç¤ºäºæææ¨¡åå¨éè¿å¾®è°ææå­¦ä¹ æ°ä¿¡æ¯æ¹é¢çéå¤§ç¼ºé·ï¼æææ¨¡åçå¹³åæ³ååç¡®åº¦ä¸º 37%ãå¨æ´æ°ç°æç¥è¯æ¶ï¼ä¾å¦çº³å¥å»çæåæ´æ°ï¼åä¸å¾®è° API æ¾ç¤ºåºæ´æéçè½åï¼å¹³åæ³ååç¡®åº¦ä¸º 19%ï¼ãæ»ä½èè¨ï¼å¾®è° GPT-4o mini å¨çè¾æ°ç¥è¯åæ´æ°ç¥è¯æ¹é¢æææï¼å¶æ¬¡æ¯ GPT-3.5 Turbo å GPT-4oãGemini 1.5 Flesh å Gemini 1.5 Pro çå¾®è° API æ æ³å­¦ä¹ æ°ç¥è¯ææ´æ°ç°æç¥è¯ãè¿äºåç°å¼ºè°äºå¨å¸¸è§åºæ¯ä¸­ä½¿ç¨å½ååä¸å¾®è°æå¡æ¥å®ç°å¯é ç¥è¯æ³¨å¥çéå¤§ç¼ºé·ãæä»¬å¨ https://github.com/kevinwu23/StanfordFineTuneBench ä¸å¼æºäº FineTuneBench æ°æ®éã</paragraph>

##### **Integrating Large Language Models for Genetic Variant Classification**
2411.05055v1 by Youssef Boulaimen, Gabriele Fossi, Leila Outemzabet, Nathalie Jeanray, Oleksandr Levenets, Stephane Gerart, Sebastien Vachenc, Salvatore Raieli, Joanna Giemza

The classification of genetic variants, particularly Variants of Uncertain
Significance (VUS), poses a significant challenge in clinical genetics and
precision medicine. Large Language Models (LLMs) have emerged as transformative
tools in this realm. These models can uncover intricate patterns and predictive
insights that traditional methods might miss, thus enhancing the predictive
accuracy of genetic variant pathogenicity.
  This study investigates the integration of state-of-the-art LLMs, including
GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data
alongside structural insights to form a comprehensive analytical framework for
variant classification. Our approach evaluates these integrated models using
the well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in
classification performance. The models were rigorously tested on a set of
challenging variants, demonstrating substantial improvements over existing
state-of-the-art tools, especially in handling ambiguous and clinically
uncertain variants.
  The results of this research underline the efficacy of combining multiple
modeling approaches to significantly refine the accuracy and reliability of
genetic variant classification systems. These findings support the deployment
of these advanced computational models in clinical environments, where they can
significantly enhance the diagnostic processes for genetic disorders,
ultimately pushing the boundaries of personalized medicine by offering more
detailed and actionable genetic insights.

æè¦ï¼éºå³è®ç°çåé¡ï¼ç¹å¥æ¯ä¸ç¢ºå®æç¾©è®ç°ï¼VUSï¼ï¼å°è¨åºéºå³å­¸åç²¾æºé«çæåºäºéå¤§ææ°ãå¤§åèªè¨æ¨¡åï¼LLMï¼å·²æçºéåé åçè®é©æ§å·¥å·ãéäºæ¨¡åå¯ä»¥æ­ç¤ºå³çµ±æ¹æ³å¯è½éºæ¼çè¤éæ¨¡å¼åé æ¸¬è¦è§£ï¼å¾èæé«éºå³è®ç°è´çæ§çé æ¸¬æºç¢ºåº¦ã
æ¬ç ç©¶èª¿æ¥äºæåé² LLM çæ´åï¼åæ¬ GPN-MSAãESM1b å AlphaMissenseï¼éäº LLM å©ç¨ DNA åèç½è³ªåºåæ¸æä»¥åçµæ§è¦è§£ï¼å½¢æäºä¸åå¨é¢çè®ç°åé¡åææ¡æ¶ãæåçåæ³ä½¿ç¨æ¨è¨»å®åç ProteinGym å ClinVar æ¸æéä¾è©ä¼°éäºæ´åæ¨¡åï¼å¨åé¡æè½ä¸è¨­å®äºæ°çåºæºãéäºæ¨¡åç¶éå´æ ¼æ¸¬è©¦ï¼ä½¿ç¨ä¸çµå·æææ°æ§çè®ç°ï¼è­æäºå°ç¾ææåé²å·¥å·çå¯¦è³ªæ§æ¹é²ï¼ç¹å¥æ¯å¨èçæ¨¡ç¨å©å¯åè¨åºä¸ä¸ç¢ºå®çè®ç°æ¹é¢ã
éé ç ç©¶ççµæå¼·èª¿äºçµåå¤ç¨®å»ºæ¨¡æ¹æ³ä»¥é¡¯èæé«éºå³è®ç°åé¡ç³»çµ±çæºç¢ºåº¦åå¯é æ§çæææ§ãéäºç¼ç¾æ¯æå¨è¨åºç°å¢ä¸­é¨ç½²éäºåé²çè¨ç®æ¨¡åï¼å®åå¯ä»¥å¨é£è£¡é¡¯èå¢å¼·éºå³ç¾ççè¨ºæ·ç¨åºï¼æçµééæä¾æ´è©³ç´°ä¸å¯æä½çéºå³è¦è§£ä¾çªç ´åäººåé«çççéã

##### **AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data**
2411.04691v1 by Tianyi Zhang, Miu Kojima, Simon D'Alfonso

Smartphones, equipped with an array of sensors, have become valuable tools
for personal sensing. Particularly in digital health, smartphones facilitate
the tracking of health-related behaviors and contexts, contributing
significantly to digital phenotyping, a process where data from digital
interactions is analyzed to infer behaviors and assess mental health.
Traditional methods process raw sensor data into information features for
statistical and machine learning analyses. In this paper, we introduce a novel
approach that systematically converts smartphone-collected data into
structured, chronological narratives. The AWARE Narrator translates
quantitative smartphone sensing data into English language descriptions,
forming comprehensive narratives of an individual's activities. We apply the
framework to the data collected from university students over a week,
demonstrating the potential of utilizing the narratives to summarize individual
behavior, and analyzing psychological states by leveraging large language
models.

æè¦ï¼æºæ§åææ©éåäºåå¼ææ¸¬å¨ï¼å·²æçºåäººææ¸¬çå¯¶è²´å·¥å·ãç¹å¥æ¯å¨æ¸ä½å¥åº·é åï¼æºæ§åææ©ä¿é²äºå¥åº·ç¸éè¡çºåæå¢çè¿½è¹¤ï¼å°æ¸ä½è¡¨ååæååºäºéå¤§è²¢ç»ï¼æ¸ä½è¡¨ååææ¯ä¸ç¨®å¾æ¸ä½äºåä¸­åæè³æä»¥æ¨è«è¡çºåè©ä¼°å¿çå¥åº·çç¨åºãå³çµ±æ¹æ³å°åå§ææ¸¬å¨è³æèçæè³è¨ç¹å¾µï¼ä»¥é²è¡çµ±è¨åæ©å¨å­¸ç¿åæãå¨æ¬æä¸­ï¼æåä»ç´¹ä¸ç¨®æ°ç©çæ¹æ³ï¼è©²æ¹æ³ç³»çµ±æ§å°å°æºæ§åææ©æ¶éçè³æè½ææçµæ§åçæéé åºæäºãAWARE Narrator å°å®éçæºæ§åææ©ææ¸¬è³æè½ææè±æèªè¨æè¿°ï¼å½¢æåäººæ´»åçç¶åæäºãæåå°æ­¤æ¶æ§å¥ç¨å¨å¤§å­¸çä¸é±å§æ¶éçè³æä¸ï¼è­æäºå©ç¨æäºç¸½çµåäººè¡çºçæ½åï¼ä¸¦éééç¨å¤§åèªè¨æ¨¡åä¾åæå¿ççæã

##### **FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation**
2411.04509v1 by Liangrui Pan, Mao Huang, Lian Wang, Pinle Qin, Shaoliang Peng

Hematoxylin and Eosin (H&E) staining of whole slide images (WSIs) is
considered the gold standard for pathologists and medical practitioners for
tumor diagnosis, surgical planning, and post-operative assessment. With the
rapid advancement of deep learning technologies, the development of numerous
models based on convolutional neural networks and transformer-based models has
been applied to the precise segmentation of WSIs. However, due to privacy
regulations and the need to protect patient confidentiality, centralized
storage and processing of image data are impractical. Training a centralized
model directly is challenging to implement in medical settings due to these
privacy concerns.This paper addresses the dispersed nature and privacy
sensitivity of medical image data by employing a federated learning framework,
allowing medical institutions to collaboratively learn while protecting patient
privacy. Additionally, to address the issue of original data reconstruction
through gradient inversion during the federated learning training process,
differential privacy introduces noise into the model updates, preventing
attackers from inferring the contributions of individual samples, thereby
protecting the privacy of the training data.Experimental results show that the
proposed method, FedDP, minimally impacts model accuracy while effectively
safeguarding the privacy of cancer pathology image data, with only a slight
decrease in Dice, Jaccard, and Acc indices by 0.55%, 0.63%, and 0.42%,
respectively. This approach facilitates cross-institutional collaboration and
knowledge sharing while protecting sensitive data privacy, providing a viable
solution for further research and application in the medical field.

æè¦ï¼èæ¨ç²¾åä¼ç´ï¼H&Eï¼æè²å¨åçååï¼WSIï¼è¢«èªçºæ¯ççå­¸å®¶åé«çå¾æ¥­äººå¡ç¨æ¼è«ç¤è¨ºæ·ãæè¡è¦ååè¡å¾è©ä¼°çé»éæ¨æºãé¨èæ·±åº¦å­¸ç¿æè¡çå¿«éé²å±ï¼åºæ¼å·ç©ç¥ç¶ç¶²è·¯ååºæ¼Transformerçæ¨¡åçç¾å¤æ¨¡åå·²è¢«æç¨æ¼ WSI çç²¾ç¢ºåå²ãç¶èï¼ç±æ¼é±ç§æ³è¦åä¿è­·æ£èæ©å¯æ§çéè¦ï¼éä¸­å¼å²å­åèçå½±åè³ææ¯ä¸åå¯¦éçãç±æ¼éäºé±ç§åé¡ï¼å¨é«çç°å¢ä¸­ç´æ¥è¨ç·´éä¸­å¼æ¨¡åé£ä»¥å¯¦æ½ãæ¬æééæ¡ç¨è¯åå­¸ç¿æ¡æ¶ä¾è§£æ±ºé«çå½±åè³æçåæ£æ§è³ªåé±ç§æææ§ï¼åè¨±é«çæ©æ§å¨ä¿è­·æ£èé±ç§çåæé²è¡åä½å­¸ç¿ãæ­¤å¤ï¼çºäºè§£æ±ºè¯åå­¸ç¿è¨ç·´éç¨ä¸­ééæ¢¯åº¦åè½é²è¡åå§è³æéå»ºçåé¡ï¼å·®åé±ç§æå¨æ¨¡åæ´æ°ä¸­å¼å¥éè¨ï¼é²æ­¢æ»æèæ¨æ·åå¥æ¨£æ¬çè²¢ç»ï¼å¾èä¿è­·è¨ç·´è³æçé±ç§ãå¯¦é©çµæè¡¨æï¼ææåºçæ¹æ³ FedDP å°æ¨¡åæºç¢ºåº¦çå½±é¿æå°ï¼åæææä¿è­·äºççççå½±åè³æçé±ç§ï¼DiceãJaccard å Acc ææ¸åå¥åç¥å¾®ä¸éäº 0.55%ã0.63% å 0.42%ãéç¨®æ¹æ³ä¿é²äºæ©æ§éçåä½åç¥è­å±äº«ï¼åæä¿è­·äºææè³æçé±ç§ï¼çºé«çé åçé²ä¸æ­¥ç ç©¶åæç¨æä¾äºå¯è¡çè§£æ±ºæ¹æ¡ã

##### **Conditional Diffusion Model for Longitudinal Medical Image Generation**
2411.05860v1 by Duy-Phuong Dao, Hyung-Jeong Yang, Jahae Kim

Alzheimers disease progresses slowly and involves complex interaction between
various biological factors. Longitudinal medical imaging data can capture this
progression over time. However, longitudinal data frequently encounter issues
such as missing data due to patient dropouts, irregular follow-up intervals,
and varying lengths of observation periods. To address these issues, we
designed a diffusion-based model for 3D longitudinal medical imaging generation
using single magnetic resonance imaging (MRI). This involves the injection of a
conditioning MRI and time-visit encoding to the model, enabling control in
change between source and target images. The experimental results indicate that
the proposed method generates higher-quality images compared to other competing
methods.

æè¦ï¼é¿è²æµ·é»ççé²ç¨ç·©æ¢ï¼æ¶ååç¨®çç©å å­ä¹éçè¤éäºåãç¸±åé«å­¸å½±åè³æå¯ä»¥é¨èæéæ¨ç§»ææéç¨®é²ç¨ãç¶èï¼ç¸±åè³æç¶å¸¸æéå°åé¡ï¼ä¾å¦ç±æ¼æ£èéåºãä¸è¦åçè¿½è¹¤ééåè§å¯æé·åº¦ä¸åèå°è´è³æéºå¤±ãçºäºè§£æ±ºéäºåé¡ï¼æåè¨­è¨äºä¸ååºæ¼æ´æ£çæ¨¡åï¼ç¨æ¼ä½¿ç¨å®ä¸ç£å±æ¯æå (MRI) é²è¡ 3D ç¸±åé«å­¸å½±åçæãéæ¶åå°æ¢ä»¶ MRI åæéè¨ªåç·¨ç¢¼æ³¨å¥æ¨¡åï¼å¾èè½å¤ æ§å¶æºå½±ååç®æ¨å½±åä¹éçè½æãå¯¦é©çµæè¡¨æï¼èå¶ä»ç«¶ç­æ¹æ³ç¸æ¯ï¼ææåºçæ¹æ³çæçå½±ååè³ªè¼é«ã

##### **Evaluating the Economic Implications of Using Machine Learning in Clinical Psychiatry**
2411.05856v1 by Soaad Hossain, James Rasalingam, Arhum Waheed, Fatah Awil, Rachel Kandiah, Syed Ishtiaque Ahmed

With the growing interest in using AI and machine learning (ML) in medicine,
there is an increasing number of literature covering the application and ethics
of using AI and ML in areas of medicine such as clinical psychiatry. The
problem is that there is little literature covering the economic aspects
associated with using ML in clinical psychiatry. This study addresses this gap
by specifically studying the economic implications of using ML in clinical
psychiatry. In this paper, we evaluate the economic implications of using ML in
clinical psychiatry through using three problem-oriented case studies,
literature on economics, socioeconomic and medical AI, and two types of health
economic evaluations. In addition, we provide details on fairness, legal,
ethics and other considerations for ML in clinical psychiatry.

æè¦ï¼é¨è AI åæ©å¨å­¸ç¿ (ML) å¨é«å­¸ä¸­æç¨æ¥çåå°éè¦ï¼
æ¢è¨ AI å ML å¨é«å­¸é åï¼ä¾å¦è¨åºç²¾ç¥çå­¸ï¼ä¸­æç¨åå«ççæç»è¶ä¾è¶å¤ãåé¡å¨æ¼ï¼æ¢è¨è ML å¨è¨åºç²¾ç¥çå­¸ä¸­æç¨ç¸éçç¶æ¿æ¹é¢çæç»å¾å°ãæ¬ç ç©¶ééç¹å¥æ¢è¨ ML å¨è¨åºç²¾ç¥çå­¸ä¸­æç¨çç¶æ¿å½±é¿ï¼ä¾è§£æ±ºéååé¡ãå¨æ¬æä¸­ï¼æåééä½¿ç¨ä¸åä»¥åé¡çºå°åçæ¡ä¾ç ç©¶ãç¶æ¿å­¸ãç¤¾æç¶æ¿åé«ç AI çæç»ï¼ä»¥åå©ç¨®é¡åçå¥åº·ç¶æ¿è©ä¼°ï¼è©ä¼° ML å¨è¨åºç²¾ç¥çå­¸ä¸­æç¨çç¶æ¿å½±é¿ãæ­¤å¤ï¼æåæä¾æé ML å¨è¨åºç²¾ç¥çå­¸ä¸­çå¬å¹³æ§ãæ³å¾ãå«çåå¶ä»èéçè©³ç´°è³è¨ã

##### **Robust Real-Time Mortality Prediction in the Intensive Care Unit using Temporal Difference Learning**
2411.04285v1 by Thomas Frost, Kezhi Li, Steve Harris

The task of predicting long-term patient outcomes using supervised machine
learning is a challenging one, in part because of the high variance of each
patient's trajectory, which can result in the model over-fitting to the
training data. Temporal difference (TD) learning, a common reinforcement
learning technique, may reduce variance by generalising learning to the pattern
of state transitions rather than terminal outcomes. However, in healthcare this
method requires several strong assumptions about patient states, and there
appears to be limited literature evaluating the performance of TD learning
against traditional supervised learning methods for long-term health outcome
prediction tasks. In this study, we define a framework for applying TD learning
to real-time irregularly sampled time series data using a Semi-Markov Reward
Process. We evaluate the model framework in predicting intensive care mortality
and show that TD learning under this framework can result in improved model
robustness compared to standard supervised learning methods. and that this
robustness is maintained even when validated on external datasets. This
approach may offer a more reliable method when learning to predict patient
outcomes using high-variance irregular time series data.

æè¦ï¼é æ¸¬é·ææ£èçµæçä»»åä½¿ç¨ç£ç£å¼æ©å¨å­¸ç¿ï¼éæ¯ä¸åå·æææ°æ§çä»»åï¼é¨ååå æ¯æ¯åæ£èçè»è·¡çè®ç°æ§å¾é«ï¼éå¯è½å°è´æ¨¡åéåº¦æ¬åå°è¨ç·´æ¸æãæéå·®å (TD) å­¸ç¿ï¼ä¸ç¨®å¸¸è¦çå¼·åå­¸ç¿æè¡ï¼å¯ä»¥ééå°å­¸ç¿æ¦æ¬çºçæè½ææ¨¡å¼èä¸æ¯çµç«¯çµæä¾æ¸å°è®ç°ãç¶èï¼å¨é«çä¿å¥ä¸­ï¼éç¨®æ¹æ³éè¦å°æ£èçæååºå¹¾åå¼·æåçåè¨­ï¼èä¸ä¼¼ä¹æéçæç»è©ä¼°äº TD å­¸ç¿ç¸å°æ¼å³çµ±ç£ç£å¼å­¸ç¿æ¹æ³å¨é·æå¥åº·çµæé æ¸¬ä»»åä¸­çæ§è½ãå¨éé ç ç©¶ä¸­ï¼æåå®ç¾©äºä¸åæ¡æ¶ï¼ç¨æ¼å° TD å­¸ç¿æç¨æ¼ä½¿ç¨åé¦¬ç¾å¯å¤«çåµéç¨çå¯¦æä¸è¦åæ¡æ¨£æéåºåæ¸æãæåè©ä¼°äºæ¨¡åæ¡æ¶å¨é æ¸¬éçç£è­·æ­»äº¡çä¸­çè¡¨ç¾ï¼ä¸¦è¡¨æå¨éåæ¡æ¶ä¸ç TD å­¸ç¿å¯ä»¥å°è´èæ¨æºç£ç£å¼å­¸ç¿æ¹æ³ç¸æ¯æ¨¡åé­¯æ£æ§å¾å°æ¹åãèä¸éç¨®é­¯æ£æ§å³ä½¿å¨å¤é¨æ¸æéä¸é©è­ä¹è½ä¿æãå¨ä½¿ç¨é«è®ç°ä¸è¦åæéåºåæ¸æå­¸ç¿é æ¸¬æ£èçµææï¼éç¨®æ¹æ³å¯è½ææä¾ä¸ç¨®æ´å¯é çæ¹æ³ã

##### **Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?**
2411.04118v1 by Daniel P. Jeong, Saurabh Garg, Zachary C. Lipton, Michael Oberst

Several recent works seek to develop foundation models specifically for
medical applications, adapting general-purpose large language models (LLMs) and
vision-language models (VLMs) via continued pretraining on publicly available
biomedical corpora. These works typically claim that such domain-adaptive
pretraining (DAPT) improves performance on downstream medical tasks, such as
answering medical licensing exam questions. In this paper, we compare seven
public "medical" LLMs and two VLMs against their corresponding base models,
arriving at a different conclusion: all medical VLMs and nearly all medical
LLMs fail to consistently improve over their base models in the zero-/few-shot
prompting regime for medical question-answering (QA) tasks. For instance,
across the tasks and model pairs we consider in the 3-shot setting, medical
LLMs only outperform their base models in 12.1% of cases, reach a (statistical)
tie in 49.8% of cases, and are significantly worse than their base models in
the remaining 38.2% of cases. Our conclusions are based on (i) comparing each
medical model head-to-head, directly against the corresponding base model; (ii)
optimizing the prompts for each model separately; and (iii) accounting for
statistical uncertainty in comparisons. While these basic practices are not
consistently adopted in the literature, our ablations show that they
substantially impact conclusions. Our findings suggest that state-of-the-art
general-domain models may already exhibit strong medical knowledge and
reasoning capabilities, and offer recommendations to strengthen the conclusions
of future studies.

æè¦ï¼<paragraph>è¿æçå¹¾é ç ç©¶è´åæ¼å°ééå°é«çæç¨éç¼åºç¤æ¨¡åï¼ééå¨å¬éççç©é«å­¸èªæåº«ä¸æçºé è¨ç·´ï¼èª¿æ´éç¨çå¤§åèªè¨æ¨¡å (LLM) åè¦è¦ºèªè¨æ¨¡å (VLM)ãéäºç ç©¶éå¸¸è²ç¨±ï¼éç¨®é åé©ææ§é è¨ç·´ (DAPT) è½æ¹åä¸æ¸¸é«çä»»åçæè½ï¼ä¾å¦åç­é«çå·ç§èè©¦é¡ç®ãå¨æ¬æä¸­ï¼æåæ¯è¼äºä¸åå¬éçãé«çãLLM åå©å VLM èå®åå°æçåºæ¬æ¨¡åï¼ä¸¦å¾åºä¸åççµè«ï¼å¨é«çåé¡åç­ (QA) ä»»åçé¶æ¬¡ï¼å°æ¨£æ¬æç¤ºæ©å¶ä¸­ï¼ææé«ç VLM åå¹¾ä¹ææé«ç LLM é½ç¡æ³æçºåªæ¼å®åçåºæ¬æ¨¡åãä¾å¦ï¼å¨æåå¨ 3 æ¬¡æç¤ºè¨­å®ä¸­èæ®çä»»ååæ¨¡åéå°ä¸­ï¼é«ç LLM åå¨ 12.1% çææ³ä¸åªæ¼å®åçåºæ¬æ¨¡åï¼å¨ 49.8% çææ³ä¸éå°ï¼çµ±è¨ï¼å¹³æï¼èå¨å¶é¤ 38.2% çææ³ä¸é¡¯èä½æ¼å®åçåºæ¬æ¨¡åãæåççµè«åºæ¼ (i) ç´æ¥éå°å°æçåºæ¬æ¨¡åï¼éä¸æ¯è¼æ¯åé«çæ¨¡åï¼(ii) åå¥éå°æ¯åæ¨¡åæä½³åæç¤ºï¼ä»¥å (iii) èæ®æ¯è¼ä¸­ççµ±è¨ä¸ç¢ºå®æ§ãéç¶éäºåºæ¬åæ³ä¸¦æªæçºæ¡ç¨å¨æç»ä¸­ï¼ä½æåçæ¶èç ç©¶è¡¨æï¼å®åæå¤§å¹å½±é¿çµè«ãæåçç ç©¶çµæè¡¨æï¼æåé²çéç¨é åæ¨¡åå¯è½å·²ç¶å±ç¾åºå¼·å¤§çé«çç¥è­åæ¨çè½åï¼ä¸¦æåºå»ºè­°ä»¥å¼·åæªä¾ç ç©¶ççµè«ã</paragraph>

##### **RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models**
2411.04097v1 by Maya Varma, Jean-Benoit Delbrouck, Zhihong Chen, Akshay Chaudhari, Curtis Langlotz

Fine-tuned vision-language models (VLMs) often capture spurious correlations
between image features and textual attributes, resulting in degraded zero-shot
performance at test time. Existing approaches for addressing spurious
correlations (i) primarily operate at the global image-level rather than
intervening directly on fine-grained image features and (ii) are predominantly
designed for unimodal settings. In this work, we present RaVL, which takes a
fine-grained perspective on VLM robustness by discovering and mitigating
spurious correlations using local image features rather than operating at the
global image level. Given a fine-tuned VLM, RaVL first discovers spurious
correlations by leveraging a region-level clustering approach to identify
precise image features contributing to zero-shot classification errors. Then,
RaVL mitigates the identified spurious correlation with a novel region-aware
loss function that enables the VLM to focus on relevant regions and ignore
spurious relationships during fine-tuning. We evaluate RaVL on 654 VLMs with
various model architectures, data domains, and learned spurious correlations.
Our results show that RaVL accurately discovers (191% improvement over the
closest baseline) and mitigates (8.2% improvement on worst-group image
classification accuracy) spurious correlations. Qualitative evaluations on
general-domain and medical-domain VLMs confirm our findings.

æè¦ï¼å¾®è°çè§è§è¯­è¨æ¨¡åï¼VLMï¼éå¸¸ä¼ææå¾åç¹å¾åææ¬å±æ§ä¹é´çèåç¸å³æ§ï¼å¯¼è´å¨æµè¯æ¶é¶æ ·æ¬æ§è½ä¸éãç°æçè§£å³èåç¸å³æ§çæ¹æ³ï¼iï¼ä¸»è¦å¨å¨å±å¾åçº§å«æä½ï¼èä¸æ¯ç´æ¥å¹²é¢ç»ç²åº¦çå¾åç¹å¾ï¼å¹¶ä¸ï¼iiï¼ä¸»è¦è®¾è®¡ç¨äºåæ¨¡æè®¾ç½®ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäº RaVLï¼å®éè¿ä½¿ç¨å±é¨å¾åç¹å¾èä¸æ¯å¨å¨å±å¾åçº§å«æä½æ¥åç°ååè½»èåç¸å³æ§ï¼ä»èå¯¹ VLM é²æ£æ§éåäºç»ç²åº¦çè§è§ãç»å®ä¸ä¸ªå¾®è°ç VLMï¼RaVL é¦åéè¿å©ç¨åºåçº§èç±»æ¹æ³åç°èåç¸å³æ§ï¼ä»¥è¯å«å¯¼è´é¶æ ·æ¬åç±»éè¯¯çç²¾ç¡®å¾åç¹å¾ãç¶åï¼RaVL ä½¿ç¨ä¸ç§æ°é¢çåºåæç¥æå¤±å½æ°æ¥åè½»å·²è¯å«çèåç¸å³æ§ï¼è¯¥æå¤±å½æ°ä½¿ VLM è½å¤å¨å¾®è°æé´å³æ³¨ç¸å³åºåå¹¶å¿½ç¥èåå³ç³»ãæä»¬ä½¿ç¨ 654 ä¸ª VLM å¯¹ RaVL è¿è¡äºè¯ä¼°ï¼è¿äº VLM å·æåç§æ¨¡åæ¶æãæ°æ®ååå­¦ä¹ å°çèåç¸å³æ§ãæä»¬çç»æè¡¨æï¼RaVL åç¡®å°åç°äºï¼æ¯ææ¥è¿çåºçº¿æé«äº 191%ï¼ååè½»äºï¼å¨æå·®ç»å¾ååç±»åç¡®æ§ä¸æé«äº 8.2%ï¼èåç¸å³æ§ãå¯¹éç¨ååå»å­¦å VLM çå®æ§è¯ä¼°è¯å®äºæä»¬çåç°ã

##### **Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability**
2411.04008v1 by Bharat Chandra Yalavarthi, Nalini Ratha

In mission-critical domains such as law enforcement and medical diagnosis,
the ability to explain and interpret the outputs of deep learning models is
crucial for ensuring user trust and supporting informed decision-making.
Despite advancements in explainability, existing methods often fall short in
providing explanations that mirror the depth and clarity of those given by
human experts. Such expert-level explanations are essential for the dependable
application of deep learning models in law enforcement and medical contexts.
Additionally, we recognize that most explanations in real-world scenarios are
communicated primarily through natural language. Addressing these needs, we
propose a novel approach that utilizes characteristic descriptors to explain
model decisions by identifying their presence in images, thereby generating
expert-like explanations. Our method incorporates a concept bottleneck layer
within the model architecture, which calculates the similarity between image
and descriptor encodings to deliver inherent and faithful explanations. Through
experiments in face recognition and chest X-ray diagnosis, we demonstrate that
our approach offers a significant contrast over existing techniques, which are
often limited to the use of saliency maps. We believe our approach represents a
significant step toward making deep learning systems more accountable,
transparent, and trustworthy in the critical domains of face recognition and
medical diagnosis.

æè¦ï¼å¨æ§æ³åå»çè¯æ­ç­ä»»å¡å³é®åé¢åï¼
è§£éåè¯ éæ·±åº¦å­¦ä¹ æ¨¡åçè¾åºå¯¹äºç¡®ä¿ç¨æ·ä¿¡ä»»åæ¯æç¥æå³ç­è³å³éè¦ã
å°½ç®¡å¯è§£éæ§æ¹é¢åå¾äºè¿æ­¥ï¼ä½ç°ææ¹æ³å¨æä¾è§£éæ¶å¾å¾è¾¾ä¸å°äººç±»ä¸å®¶ç»åºçæ·±åº¦åæ¸æ°åº¦ãè¿ç§ä¸å®¶çº§å«çè§£éå¯¹äºå¨æ§æ³åå»çç¯å¢ä¸­å¯é å°åºç¨æ·±åº¦å­¦ä¹ æ¨¡åè³å³éè¦ã
æ­¤å¤ï¼æä»¬è®¤è¯å°ï¼å¨ç°å®ä¸çåºæ¯ä¸­ï¼å¤§å¤æ°è§£éä¸»è¦æ¯éè¿èªç¶è¯­è¨è¿è¡äº¤æµçãä¸ºäºæ»¡è¶³è¿äºéæ±ï¼æä»¬æåºäºä¸ç§æ°é¢çæ¹æ³ï¼è¯¥æ¹æ³å©ç¨ç¹å¾æè¿°ç¬¦éè¿è¯å«å¾åä¸­çç¹å¾æè¿°ç¬¦çå­å¨æ¥è§£éæ¨¡åå³ç­ï¼ä»èçæç±»ä¼¼ä¸å®¶çè§£éãæä»¬çæ¹æ³å¨æ¨¡åæ¶æä¸­å å¥äºä¸ä¸ªæ¦å¿µç¶é¢å±ï¼è¯¥å±è®¡ç®å¾ååæè¿°ç¬¦ç¼ç ä¹é´çç¸ä¼¼æ§ï¼ä»¥æä¾åå¨ä¸å¯é çè§£éãéè¿é¢é¨è¯å«åè¸é¨ X å°çº¿è¯æ­çå®éªï¼æä»¬è¯æäºæä»¬çæ¹æ³ä¸ç°æææ¯ç¸æ¯å·ææ¾çä¼å¿ï¼èç°æææ¯éå¸¸ä»éäºä½¿ç¨æ¾çæ§å¾ãæä»¬ç¸ä¿¡ï¼æä»¬çæ¹æ³ä»£è¡¨äºæçä½¿æ·±åº¦å­¦ä¹ ç³»ç»å¨é¢é¨è¯å«åå»çè¯æ­çå³é®é¢åæ´å è´è´£ãéæåå¼å¾ä¿¡èµè¿åºçéè¦ä¸æ­¥ã

##### **Fine-tuning -- a Transfer Learning approach**
2411.03941v1 by Joseph Arul Raj, Linglong Qian, Zina Ibrahim

Secondary research use of Electronic Health Records (EHRs) is often hampered
by the abundance of missing data in this valuable resource. Missingness in EHRs
occurs naturally as a result of the data recording practices during routine
clinical care, but handling it is crucial to the precision of medical analysis
and the decision-making that follows. The literature contains a variety of
imputation methodologies based on deep neural networks. Those aim to overcome
the dynamic, heterogeneous and multivariate missingness patterns of EHRs, which
cannot be handled by classical and statistical imputation methods. However, all
existing deep imputation methods rely on end-to-end pipelines that incorporate
both imputation and downstream analyses, e.g. classification. This coupling
makes it difficult to assess the quality of imputation and takes away the
flexibility of re-using the imputer for a different task. Furthermore, most
end-to-end deep architectures tend to use complex networks to perform the
downstream task, in addition to the already sophisticated deep imputation
network. We, therefore ask if the high performance reported in the literature
is due to the imputer or the classifier and further ask if an optimised
state-of-the-art imputer is used, a simpler classifier can achieve comparable
performance. This paper explores the development of a modular, deep
learning-based imputation and classification pipeline, specifically built to
leverage the capabilities of state-of-the-art imputation models for downstream
classification tasks. Such a modular approach enables a) objective assessment
of the quality of the imputer and classifier independently, and b) enables the
exploration of the performance of simpler classification architectures using an
optimised imputer.

æè¦ï¼é»å­å¥åº·ç´é (EHR) çäºæ¬¡ç ç©¶ç¨éç¶å¸¸åå°æ­¤å¯¶è²´è³æºä¸­å¤§ééºå¤±è³æçé»ç¤ãEHR ä¸­çéºå¤±è³ææå¨ä¾è¡è¨åºç§è­·æéçè³æè¨éå¯¦åä¸­èªç¶ç¼çï¼ä½èçéºå¤±è³æå°æ¼é«çåæçç²¾ç¢ºåº¦åå¾çºæ±ºç­è³ééè¦ãæç»ä¸­åå«åç¨®åºæ¼æ·±åº¦ç¥ç¶ç¶²è·¯çå§ææ¹æ³ãéäºæ¹æ³æ¨å¨åæ EHR ä¸­åæãç°è³ªä¸å¤è®éçéºå¤±è³ææ¨¡å¼ï¼èéç¡æ³ééå³çµ±åçµ±è¨å§ææ¹æ³ä¾èçãç¶èï¼ææç¾æçæ·±åº¦å§ææ¹æ³é½ä¾è³´æ¼å°å§æåä¸æ¸¸åæï¼ä¾å¦åé¡ï¼çµåå¨ä¸èµ·çç«¯å°ç«¯ç®¡éãéç¨®çµåä½¿å¾é£ä»¥è©ä¼°å§æçåè³ªï¼ä¸¦æ¶é¤äºéæ°ä½¿ç¨å§æå¨é²è¡ä¸åä»»åçéæ´»æ§ãæ­¤å¤ï¼å¤§å¤æ¸ç«¯å°ç«¯æ·±åº¦æ¶æ§å¾åæ¼ä½¿ç¨è¤éçç¶²è·¯ä¾å·è¡ä¸æ¸¸ä»»åï¼é¤äºå·²ç¶å¾è¤éçæ·±åº¦å§æç¶²è·¯ä¹å¤ãå æ­¤ï¼æåè©¢åæç»ä¸­å ±å°çé«æè½æ¯ç±æ¼å§æå¨éæ¯åé¡å¨ï¼ä¸¦é²ä¸æ­¥è©¢åæ¯å¦ä½¿ç¨äºæä½³åçææ°å§æå¨ï¼è¼ç°¡å®çåé¡å¨æ¯å¦å¯ä»¥éå°ç¸è¿çæè½ãæ¬ææ¢è¨æ¨¡çµåãåºæ¼æ·±åº¦å­¸ç¿çå§æååé¡ç®¡éçéç¼ï¼ç¹å¥æ¯å»ºæ§ä¾å©ç¨ææ°å§ææ¨¡åçè½åï¼ä»¥é²è¡ä¸æ¸¸åé¡ä»»åãéç¨®æ¨¡çµåæ¹æ³è½ a) å®¢è§è©ä¼°å§æå¨ååé¡å¨çåè³ªï¼ä»¥å b) è½å¤ ä½¿ç¨æä½³åçå§æå¨ä¾æ¢è¨è¼ç°¡å®åé¡æ¶æ§çæè½ã

##### **MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**
2411.03883v2 by Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders SÃ¸gaard, Carlos Bobed

Question answering is a natural language understanding task that involves
reasoning over both explicit context and unstated, relevant domain knowledge.
Large language models (LLMs), which underpin most contemporary question
answering systems, struggle to induce how concepts relate in specialized
domains such as medicine. Existing medical LLMs are also costly to train. In
this work, we present MEG, a parameter-efficient approach for medical
knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate
graph embeddings into the LLM, enabling it to leverage external knowledge in a
cost-effective way. We evaluate our method on four popular medical
multiple-choice datasets and show that LLMs greatly benefit from the factual
grounding provided by knowledge graph embeddings. MEG attains an average of
+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized
models like BioMistral. We also show results based on Llama-3. Finally, we show
that MEG's performance remains robust to the choice of graph encoder.

æè¦ï¼åç­æ¯èªç¶èªè¨çè§£ä»»åï¼æ¶åå°æç¢ºçä¸ä¸æåæªèªªæçç¸éé åç¥è­é²è¡æ¨çãæ¯æå¤§å¤æ¸ç¶ä»£åç­ç³»çµ±çå¤§åèªè¨æ¨¡å (LLM) é£ä»¥æ¨è«æ¦å¿µå¦ä½å¨é«å­¸ç­å°æ¥­é åä¸­éè¯ãç¾æçé«å­¸ LLM è¨ç·´ææ¬ä¹å¾é«ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº MEGï¼éæ¯ä¸ç¨®ç¨æ¼é«å­¸ç¥è­å¢å¼· LLM çåæ¸æææ¹æ³ãMEG ä½¿ç¨è¼éç´æ å°ç¶²è·¯å°åè¡¨åµå¥æ´åå° LLM ä¸­ï¼ä½¿å¶è½å¤ ä»¥ç¶æ¿ææçæ¹å¼å©ç¨å¤é¨ç¥è­ãæåå¨ååæµè¡çé«å­¸å¤é¸é¡è³æéä¸è©ä¼°äºæåçæ¹æ³ï¼ä¸¦è¡¨æ LLM å¾ç¥è­åè¡¨åµå¥æä¾çå¯¦éä¾æä¸­åçåªæ·ºãMEG å¨ Mistral-Instruct åºæºä¸å¹³åæé«äº +10.2% çæºç¢ºåº¦ï¼å¨ BioMistral ç­å°éæ¨¡åä¸æé«äº +6.7%ãæåéå±ç¤ºäºåºæ¼ Llama-3 ççµæãæå¾ï¼æåè¡¨æ MEG çæ§è½å°åè¡¨ç·¨ç¢¼å¨çé¸æä¿æç©©å¥ã

##### **Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications**
2411.03782v1 by Daan Schouten, Giulia Nicoletti, Bas Dille, Catherine Chia, Pierpaolo Vendittelli, Megan Schuurmans, Geert Litjens, Nadieh Khalili

Recent technological advances in healthcare have led to unprecedented growth
in patient data quantity and diversity. While artificial intelligence (AI)
models have shown promising results in analyzing individual data modalities,
there is increasing recognition that models integrating multiple complementary
data sources, so-called multimodal AI, could enhance clinical decision-making.
This scoping review examines the landscape of deep learning-based multimodal AI
applications across the medical domain, analyzing 432 papers published between
2018 and 2024. We provide an extensive overview of multimodal AI development
across different medical disciplines, examining various architectural
approaches, fusion strategies, and common application areas. Our analysis
reveals that multimodal AI models consistently outperform their unimodal
counterparts, with an average improvement of 6.2 percentage points in AUC.
However, several challenges persist, including cross-departmental coordination,
heterogeneous data characteristics, and incomplete datasets. We critically
assess the technical and practical challenges in developing multimodal AI
systems and discuss potential strategies for their clinical implementation,
including a brief overview of commercially available multimodal AI models for
clinical decision-making. Additionally, we identify key factors driving
multimodal AI development and propose recommendations to accelerate the field's
maturation. This review provides researchers and clinicians with a thorough
understanding of the current state, challenges, and future directions of
multimodal AI in medicine.

æè¦ï¼é«çä¿å¥é åçè¿æç§æé²å±å°è´çæ£è³ææ¸éåå¤æ¨£æ§åææªæçæé·ãåç®¡äººå·¥æºæ§ (AI) æ¨¡åå¨åæåå¥è³ææ¨¡å¼ä¸­å±ç¾åºæåéçææï¼ä½æ´åå¤åäºè£è³æä¾æºçæ¨¡åï¼å³æè¬çå¤æ¨¡å¼ AIï¼å¯ä»¥æåè¨åºæ±ºç­å¶å®ï¼éé èªç¥æ­£èæ¥ä¿±å¢ãéç¯ç¯åæ¢è¨åé¡§ç ç©¶æ¢è¨äºæ¶µèé«çé åçæ·±åº¦å­¸ç¿åºç¤å¤æ¨¡å¼ AI æç¨ç¾æ³ï¼åæ 2018 å¹´è³ 2024 å¹´éç¼è¡¨ç 432 ç¯è«æãæåæä¾äºå¤æ¨¡å¼ AI ç¼å±çå»£æ³æ¦è§ï¼æ¶µèä¸åçé«çé åï¼æ¢è¨åç¨®æ¶æ§æ¹æ³ãèåç­ç¥åå¸¸è¦æç¨é åãæåçåæé¡¯ç¤ºï¼å¤æ¨¡å¼ AI æ¨¡åå§çµåªæ¼å¶å®ä¸æ¨¡å¼çå°ææ¨¡åï¼AUC å¹³åæ¹å 6.2 åç¾åé»ãç¶èï¼ä»æè¨±å¤ææ°æçºå­å¨ï¼åæ¬è·¨é¨éåèª¿ãç°è³ªè³æç¹æ§åä¸å®æ´è³æéãæåæ¹å¤æ§å°è©ä¼°éç¼å¤æ¨¡å¼ AI ç³»çµ±å¨æè¡åå¯¦åä¸çææ°ï¼ä¸¦è¨è«å¶è¨åºå¯¦ä½çæ½å¨ç­ç¥ï¼åæ¬å°å¸å®å¤æ¨¡å¼ AI æ¨¡åçç°¡è¦æ¦è¿°ï¼ç¨æ¼è¨åºæ±ºç­å¶å®ãæ­¤å¤ï¼æåæ¾åºæ¨åå¤æ¨¡å¼ AI ç¼å±çä¸»è¦å ç´ ï¼ä¸¦æåºå»ºè­°ä»¥å éè©²é åçæçãæ¬åé¡§ç ç©¶è®ç ç©¶äººå¡åè¨åºé«å¸«æ·±å¥äºè§£å¤æ¨¡å¼ AI å¨é«å­¸é åçç¾æ³ãææ°åæªä¾æ¹åã

##### **Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction**
2411.03758v1 by Yu Guan, Qinrong Cai, Wei Li, Qiuyun Fan, Dong Liang, Qiegen Liu

Diffusion model-based approaches recently achieved re-markable success in MRI
reconstruction, but integration into clinical routine remains challenging due
to its time-consuming convergence. This phenomenon is partic-ularly notable
when directly apply conventional diffusion process to k-space data without
considering the inherent properties of k-space sampling, limiting k-space
learning efficiency and image reconstruction quality. To tackle these
challenges, we introduce subspace diffusion model with orthogonal
decomposition, a method (referred to as Sub-DM) that restrict the diffusion
process via projections onto subspace as the k-space data distribution evolves
toward noise. Particularly, the subspace diffusion model circumvents the
inference challenges posed by the com-plex and high-dimensional characteristics
of k-space data, so the highly compact subspace ensures that diffusion process
requires only a few simple iterations to produce accurate prior information.
Furthermore, the orthogonal decomposition strategy based on wavelet transform
hin-ders the information loss during the migration of the vanilla diffusion
process to the subspace. Considering the strate-gy is approximately reversible,
such that the entire pro-cess can be reversed. As a result, it allows the
diffusion processes in different spaces to refine models through a mutual
feedback mechanism, enabling the learning of ac-curate prior even when dealing
with complex k-space data. Comprehensive experiments on different datasets
clearly demonstrate that the superiority of Sub-DM against state of-the-art
methods in terms of reconstruction speed and quality.

æè¦ï¼åºæ¼æ´æ£æ¨¡åçæ¹æ³æè¿å¨ MRI éå»ºä¸­åå¾äºé¡¯èçæåï¼ä½ç±æ¼å¶èæçæ¶ææ§ï¼æ´åå°è¨åºå¸¸è¦ä¸­ä»ç¶å·æææ°æ§ãç¶ç´æ¥å°å³çµ±æ´æ£éç¨æç¨å° k-space è³æï¼èæ²æèæ® k-space åæ¨£çåºæç¹æ§æï¼éç¨®ç¾è±¡å°¤å¶æé¡¯ï¼éå¶äº k-space å­¸ç¿æçåå½±åéå»ºåè³ªãçºäºæå°éäºææ°ï¼æåå¼å¥äºå·ææ­£äº¤åè§£çå­ç©ºéæ´æ£æ¨¡åï¼ä¸ç¨®æ¹æ³ï¼ç¨±çº Sub-DMï¼ï¼å®ééæå½±å°å­ç©ºéä¾éå¶æ´æ£éç¨ï¼å çº k-space è³æåä½ææ¼è®æéè¨ãç¹å¥æ¯ï¼å­ç©ºéæ´æ£æ¨¡åè¿´é¿äº k-space è³æçè¤éåé«ç¶­ç¹å¾µæå¸¶ä¾çæ¨è«ææ°ï¼å æ­¤é«åº¦ç·æ¹çå­ç©ºéç¢ºä¿æ´æ£éç¨åªéè¦å¹¾åç°¡å®çè¿­ä»£å³å¯ç¢çæºç¢ºçåé©è³è¨ãæ­¤å¤ï¼åºæ¼å°æ³¢è½æçæ­£äº¤åè§£ç­ç¥é»ç¤äºé¦èæ´æ£éç¨é·ç§»å°å­ç©ºéæéçè³è¨éºå¤±ãèæ®å°è©²ç­ç¥è¿ä¼¼å¯éï¼å æ­¤æ´åéç¨å¯ä»¥éè½ãå æ­¤ï¼å®åè¨±ä¸åç©ºéä¸­çæ´æ£éç¨ééç¸äºåé¥æ©å¶ä¾åªåæ¨¡åï¼å³ä½¿å¨èçè¤éç k-space è³ææä¹è½å­¸ç¿æºç¢ºçåé©ãå¨ä¸åè³æéä¸çå¨é¢å¯¦é©æ¸æ¥å°è­æäº Sub-DM å¨éå»ºéåº¦ååè³ªæ¹é¢åªæ¼æåé²çæ¹æ³ã

##### **Ultrasound-Based AI for COVID-19 Detection: A Comprehensive Review of Public and Private Lung Ultrasound Datasets and Studies**
2411.05029v1 by Abrar Morshed, Abdulla Al Shihab, Md Abrar Jahin, Md Jaber Al Nahian, Md Murad Hossain Sarker, Md Sharjis Ibne Wadud, Mohammad Istiaq Uddin, Muntequa Imtiaz Siraji, Nafisa Anjum, Sumiya Rajjab Shristy, Tanvin Rahman, Mahmuda Khatun, Md Rubel Dewan, Mosaddeq Hossain, Razia Sultana, Ripel Chakma, Sonet Barua Emon, Towhidul Islam, Mohammad Arafat Hussain

The COVID-19 pandemic has affected millions of people globally, with
respiratory organs being strongly affected in individuals with comorbidities.
Medical imaging-based diagnosis and prognosis have become increasingly popular
in clinical settings for detecting COVID-19 lung infections. Among various
medical imaging modalities, ultrasound stands out as a low-cost, mobile, and
radiation-safe imaging technology. In this comprehensive review, we focus on
AI-driven studies utilizing lung ultrasound (LUS) for COVID-19 detection and
analysis. We provide a detailed overview of both publicly available and private
LUS datasets and categorize the AI studies according to the dataset they used.
Additionally, we systematically analyzed and tabulated the studies across
various dimensions, including data preprocessing methods, AI models,
cross-validation techniques, and evaluation metrics. In total, we reviewed 60
articles, 41 of which utilized public datasets, while the remaining employed
private data. Our findings suggest that ultrasound-based AI studies for
COVID-19 detection have great potential for clinical use, especially for
children and pregnant women. Our review also provides a useful summary for
future researchers and clinicians who may be interested in the field.

æè¦ï¼COVID-19 ç«æå½±é¿å¨çæ¸ç¾è¬äººï¼å¶ä¸­åä½µçæ£èçå¼å¸å¨å®åå°å´éå½±é¿ãåºæ¼é«å­¸å½±åçè¨ºæ·åé å¾å¨è¨åºç°å¢ä¸­å·²æ¥çæ®åï¼ç¨æ¼åµæ¸¬ COVID-19 èºé¨ææãå¨åç¨®é«å­¸å½±åæ¨¡å¼ä¸­ï¼è¶é³æ³¢å å¶ä½ææ¬ãå¯æå¼ä¸ç¡è¼»å°çå½±åæè¡èè«ç©èåºãå¨éç¯å¨é¢çè©è«ä¸­ï¼æåå°æ³¨æ¼å©ç¨èºé¨è¶é³æ³¢ (LUS) é²è¡ COVID-19 åµæ¸¬ååæçäººå·¥æºæ§é©åç ç©¶ãæåæä¾å¬éåç§äºº LUS è³æéçè©³ç´°æ¦è§ï¼ä¸¦æ ¹ææä½¿ç¨çè³æéå°äººå·¥æºæ§ç ç©¶é²è¡åé¡ãæ­¤å¤ï¼æåç³»çµ±å°åæä¸¦æ´çäºåç¨®é¢åçç ç©¶ï¼åæ¬è³æåèçæ¹æ³ãäººå·¥æºæ§æ¨¡åãäº¤åé©è­æè¡åè©ä¼°ææ¨ãç¸½è¨ï¼æåæª¢é±äº 60 ç¯æç« ï¼å¶ä¸­ 41 ç¯ä½¿ç¨å¬éè³æéï¼èå¶é¤åä½¿ç¨ç§äººè³æãæåçç ç©¶çµæè¡¨æï¼åºæ¼è¶é³æ³¢çäººå·¥æºæ§ç ç©¶å°æ¼ COVID-19 åµæ¸¬å·ææ¥µå¤§çè¨åºæç¨æ½åï¼ç¹å¥æ¯å°æ¼åç«¥åå­å©¦ãæåçè©è«ä¹çºå¯è½å°æ­¤é åæèè¶£çæªä¾ç ç©¶äººå¡åè¨åºé«çæä¾äºæç¨çæè¦ã

##### **Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation?**
2411.03670v1 by Pedro R. A. S. Bassi, Wenxuan Li, Yucheng Tang, Fabian Isensee, Zifu Wang, Jieneng Chen, Yu-Cheng Chou, Yannick Kirchhoff, Maximilian Rokuss, Ziyan Huang, Jin Ye, Junjun He, Tassilo Wald, Constantin Ulrich, Michael Baumgartner, Saikat Roy, Klaus H. Maier-Hein, Paul Jaeger, Yiwen Ye, Yutong Xie, Jianpeng Zhang, Ziyang Chen, Yong Xia, Zhaohu Xing, Lei Zhu, Yousef Sadegheih, Afshin Bozorgpour, Pratibha Kumari, Reza Azad, Dorit Merhof, Pengcheng Shi, Ting Ma, Yuxin Du, Fan Bai, Tiejun Huang, Bo Zhao, Haonan Wang, Xiaomeng Li, Hanxue Gu, Haoyu Dong, Jichen Yang, Maciej A. Mazurowski, Saumya Gupta, Linshan Wu, Jiaxin Zhuang, Hao Chen, Holger Roth, Daguang Xu, Matthew B. Blaschko, Sergio Decherchi, Andrea Cavalli, Alan L. Yuille, Zongwei Zhou

How can we test AI performance? This question seems trivial, but it isn't.
Standard benchmarks often have problems such as in-distribution and small-size
test sets, oversimplified metrics, unfair comparisons, and short-term outcome
pressure. As a consequence, good performance on standard benchmarks does not
guarantee success in real-world scenarios. To address these problems, we
present Touchstone, a large-scale collaborative segmentation benchmark of 9
types of abdominal organs. This benchmark is based on 5,195 training CT scans
from 76 hospitals around the world and 5,903 testing CT scans from 11
additional hospitals. This diverse test set enhances the statistical
significance of benchmark results and rigorously evaluates AI algorithms across
various out-of-distribution scenarios. We invited 14 inventors of 19 AI
algorithms to train their algorithms, while our team, as a third party,
independently evaluated these algorithms on three test sets. In addition, we
also evaluated pre-existing AI frameworks--which, differing from algorithms,
are more flexible and can support different algorithms--including MONAI from
NVIDIA, nnU-Net from DKFZ, and numerous other open-source frameworks. We are
committed to expanding this benchmark to encourage more innovation of AI
algorithms for the medical domain.

æè¦ï¼å¦ä½æ¸¬è©¦ AI æè½ï¼éååé¡çä¼¼ç°¡å®ï¼ä½ä¸¦éå¦æ­¤ã
æ¨æºåºæºç¶å¸¸æè«¸å¦åä½å§åå°åæ¸¬è©¦éãéæ¼ç°¡åçææ¨ãä¸å¬å¹³çæ¯è¼åç­æçµæå£åç­åé¡ãå æ­¤ï¼å¨æ¨æºåºæºä¸çè¯å¥½æè½ç¡æ³ä¿è­å¨å¯¦éææ³ä¸­ä¹è½æåãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº Touchstoneï¼ä¸ç¨®å¤§ååä½åå²åºæºï¼åå« 9 ç¨®é¡åçè¹é¨å¨å®ãæ­¤åºæºåºæ¼ä¾èªå¨ç 76 å®¶é«é¢ç 5,195 åè¨ç·´ CT ææåä¾èª 11 å®¶å¶ä»é«é¢ç 5,903 åæ¸¬è©¦ CT ææãéåå¤æ¨£åçæ¸¬è©¦éå¢å¼·äºåºæºçµæççµ±è¨é¡¯èæ§ï¼ä¸¦å´æ ¼è©ä¼°äºåç¨®åä½å¤ææ³ä¸ç AI æ¼ç®æ³ãæåéè«äº 19 ç¨® AI æ¼ç®æ³ç 14 ä½ç¼æèè¨ç·´ä»åçæ¼ç®æ³ï¼èæåçåéä½çºç¬¬ä¸æ¹ï¼ç¨ç«è©ä¼°äºéäºæ¼ç®æ³å¨ä¸åæ¸¬è©¦éä¸çè¡¨ç¾ãæ­¤å¤ï¼æåéè©ä¼°äºç¾æç AI æ¡æ¶ï¼éäºæ¡æ¶èæ¼ç®æ³ä¸åï¼æ´å·å½æ§ï¼ä¸å¯ä»¥æ¯æ´ä¸åçæ¼ç®æ³ï¼åæ¬ NVIDIA ç MONAIãDKFZ ç nnU-Net åè¨±å¤å¶ä»éæºæ¡æ¶ãæåè´åæ¼æ´å±æ­¤åºæºï¼ä»¥é¼åµæ´å¤ AI æ¼ç®æ³å¨é«çé åçåµæ°ã

##### **Requirements Engineering for Older Adult Digital Health Software: A Systematic Literature Review**
2411.03656v1 by Yuqing Xiao, John Grundy, Anuradha Madugalla

Growth of the older adult population has led to an increasing interest in
technology-supported aged care. However, the area has some challenges such as a
lack of caregivers and limitations in understanding the emotional, social,
physical, and mental well-being needs of seniors. Furthermore, there is a gap
in the understanding between developers and ageing people of their
requirements. Digital health can be important in supporting older adults
wellbeing, emotional requirements, and social needs. Requirements Engineering
(RE) is a major software engineering field, which can help to identify, elicit
and prioritize the requirements of stakeholders and ensure that the systems
meet standards for performance, reliability, and usability. We carried out a
systematic review of the literature on RE for older adult digital health
software. This was necessary to show the representatives of the current stage
of understanding the needs of older adults in aged care digital health. Using
established guidelines outlined by the Kitchenham method, the PRISMA and the
PICO guideline, we developed a protocol, followed by the systematic exploration
of eight databases. This resulted in 69 primary studies of high relevance,
which were subsequently subjected to data extraction, synthesis, and reporting.
We highlight key RE processes in digital health software for ageing people. It
explored the utilization of technology for older user well-being and care, and
the evaluations of such solutions. The review also identified key limitations
found in existing primary studies that inspire future research opportunities.
The results indicate that requirement gathering and understanding have a
significant variation between different studies. The differences are in the
quality, depth, and techniques adopted for requirement gathering and these
differences are largely due to uneven adoption of RE methods.

æè¦ï¼é«é½¡äººå£çå¢é·ï¼å°è´å°ç§æè¼å©é·ç§æåçéæ±èæ¥ä¿±å¢ãç¶èï¼è©²é åä¹é¢è¨ä¸äºææ°ï¼ä¾å¦ç§è­·äººå¡çç­ç¼ºï¼ä»¥åå¨çè§£é·èå¨æç·ãç¤¾äº¤ãççåå¿çæ¹é¢çç¦ç¥éæ±ææå­å¨çéå¶ãæ­¤å¤ï¼éç¼äººå¡åé·èå¨éæ±çè§£ä¸ä¹å­å¨å·®è·ãæ¸ä½å¥åº·å¨æ¯æé·èçç¦ç¥ãæç·éæ±åç¤¾æéæ±æ¹é¢æ®æ¼èéè¦çè§è²ãéæ±å·¥ç¨ï¼REï¼æ¯è»é«å·¥ç¨é åçä¸å¤§é åï¼æå©æ¼è­å¥ãå¼å°ååªåèçå©å®³éä¿äººçéæ±ï¼ä¸¦ç¢ºä¿ç³»çµ±ç¬¦åæè½ãå¯é æ§åå¯ç¨æ§çæ¨æºãæåå°é·èæ¸ä½å¥åº·è»é«çREæç»é²è¡äºç³»çµ±æ§çåé¡§ãéå°æ¼å±ç¾ç®åå¨é·ç§æ¸ä½å¥åº·é åä¸­çè§£é·èéæ±çéæ®µä»£è¡¨æ§æ¯å¿è¦çãæåæ ¹æKitchenhamæ¹æ³ãPRISMAåPICOæåæååºçæ¢å®æºåï¼å¶å®äºä¸å¥åå®ï¼æ¥èç³»çµ±æ§å°æ¢è¨äºå«åè³æåº«ãéç¢çäº69é é«åº¦ç¸éçä¸»è¦ç ç©¶ï¼å¶å¾é²è¡äºè³æèåãç¶åååå ±ãæåéé»ä»ç´¹äºé·èæ¸ä½å¥åº·è»é«ä¸­çééµREæµç¨ãå®æ¢è¨äºç§æå¨é·èä½¿ç¨èç¦ç¥åç§è­·ä¸­çæç¨ï¼ä»¥åéäºè§£æ±ºæ¹æ¡çè©ä¼°ãéä»½åé¡§ä¹æ¾åºäºç¾æä¸»è¦ç ç©¶ä¸­ç¼ç¾çä¸»è¦éå¶ï¼æ¿åµäºæªä¾çç ç©¶æ©æãçµæé¡¯ç¤ºï¼ä¸åç ç©¶ä¹éå¨éæ±æ¶éåçè§£æ¹é¢æé¡¯èçå·®ç°ãå·®ç°å¨æ¼éæ±æ¶éææ¡ç¨çåè³ªãæ·±åº¦åæè¡ï¼èéäºå·®ç°å¨å¾å¤§ç¨åº¦ä¸æ¯ç±æ¼REæ¹æ³æ¡ç¨ä¸åæè´ã

##### **Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification**
2411.03618v1 by Dahyun Mok, Junghyun Bum, Le Duc Tai, Hyunseung Choo

Diabetic Retinopathy (DR) is a primary cause of blindness, necessitating
early detection and diagnosis. This paper focuses on referable DR
classification to enhance the applicability of the proposed method in clinical
practice. We develop an advanced cross-learning DR classification method
leveraging transfer learning and cross-attention mechanisms. The proposed
method employs the Swin U-Net architecture to segment lesion maps from DR
fundus images. The Swin U-Net segmentation model, enriched with DR lesion
insights, is transferred to generate a lesion map. Both the fundus image and
its segmented lesion map are used as complementary inputs for the
classification model. A cross-attention mechanism is deployed to improve the
model's ability to capture fine-grained details from the input pairs. Our
experiments, utilizing two public datasets, FGADR and EyePACS, demonstrate a
superior accuracy of 94.6%, surpassing current state-of-the-art methods by
4.4%. To this end, we aim for the proposed method to be seamlessly integrated
into clinical workflows, enhancing accuracy and efficiency in identifying
referable DR.

æè¦ï¼ç³å°¿çè¦ç¶²èçè® (DR) æ¯å¤±æçé¦è¦åå ï¼éè¦æ©ææª¢æ¸¬åè¨ºæ·ãæ¬æéé»éæ³¨å¯è½è¨ºç DR åé¡ï¼ä»¥å¢å¼·ææåºæ¹æ³å¨è¨åºå¯¦åä¸­çé©ç¨æ§ãæåéç¼äºä¸ç¨®åé²çäº¤åå­¸ç¿ DR åé¡æ¹æ³ï¼å©ç¨é·ç§»å­¸ç¿åäº¤åæ³¨ææ©å¶ãææåºçæ¹æ³æ¡ç¨ Swin U-Net æ¶æ§ï¼å¾ DR ç¼åºååä¸­åå²çç¶åãè±å¯äº DR çç¶è¦è§£ç Swin U-Net åå²æ¨¡åè¢«è½ç§»ä»¥çæçç¶åãç¼åºåååå¶åå²ççç¶åé½è¢«ç¨ä½åé¡æ¨¡åçè£åè¼¸å¥ãé¨ç½²äº¤åæ³¨ææ©å¶ä»¥æé«æ¨¡åå¾è¼¸å¥å°ä¸­æ·åç´°ç²åº¦ç´°ç¯çè½åãæåçå¯¦é©å©ç¨äºå©åå¬éæ¸æéï¼FGADR å EyePACSï¼å±ç¤ºäº 94.6% çåªç°æºç¢ºçï¼æ¯ç¶åæåé²çæ¹æ³é«åº 4.4%ãçºæ­¤ï¼æåå¸æææåºçæ¹æ³è½ç¡ç¸«æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼æé«æºç¢ºåº¦åæçï¼ä»¥è­å¥å¯è½è¨ºç DRã

##### **The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare**
2411.03287v1 by Souren Pashangpour, Goldie Nejat

The potential use of large language models (LLMs) in healthcare robotics can
help address the significant demand put on healthcare systems around the world
with respect to an aging demographic and a shortage of healthcare
professionals. Even though LLMs have already been integrated into medicine to
assist both clinicians and patients, the integration of LLMs within healthcare
robots has not yet been explored for clinical settings. In this perspective
paper, we investigate the groundbreaking developments in robotics and LLMs to
uniquely identify the needed system requirements for designing health specific
LLM based robots in terms of multi modal communication through human robot
interactions (HRIs), semantic reasoning, and task planning. Furthermore, we
discuss the ethical issues, open challenges, and potential future research
directions for this emerging innovative field.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨é«çä¿å¥æ©å¨äººä¸­æ½å¨çæç¨ï¼æå©æ¼æ»¿è¶³å¨çé«çä¿å¥ç³»çµ±å°æèé½¡åäººå£åé«çä¿å¥å°æ¥­äººå¡ç­ç¼ºåé¡çéå¤§éæ±ãåç®¡ LLM å·²æ´åå°é«çé åä¸­ï¼ä»¥åå©è¨åºé«çåæ£èï¼ä½ LLM å¨é«çä¿å¥æ©å¨äººä¸­çæ´åå°æªéå°è¨åºç°å¢é²è¡æ¢è¨ãå¨æ­¤è§é»è«æä¸­ï¼æåæ¢è¨æ©å¨äººå LLM çåµæ°ç¼å±ï¼ä»¥ç¨ç¹å°æ¾åºè¨­è¨ç¹å®æ¼å¥åº·ç LLM æ©å¨äººçç³»çµ±éæ±ï¼åæ¬ééäººæ©äºå (HRI)ãèªç¾©æ¨çåä»»åè¦åçå¤æ¨¡å¼æºéãæ­¤å¤ï¼æåè¨è«äºéåæ°èåµæ°é åçå«çè­°é¡ãéæ¾æ§ææ°åæ½å¨çæªä¾ç ç©¶æ¹åã

##### **Discovering Data Structures: Nearest Neighbor Search and Beyond**
2411.03253v1 by Omar Salemohamed, Laurent Charlin, Shivam Garg, Vatsal Sharan, Gregory Valiant

We propose a general framework for end-to-end learning of data structures.
Our framework adapts to the underlying data distribution and provides
fine-grained control over query and space complexity. Crucially, the data
structure is learned from scratch, and does not require careful initialization
or seeding with candidate data structures/algorithms. We first apply this
framework to the problem of nearest neighbor search. In several settings, we
are able to reverse-engineer the learned data structures and query algorithms.
For 1D nearest neighbor search, the model discovers optimal distribution
(in)dependent algorithms such as binary search and variants of interpolation
search. In higher dimensions, the model learns solutions that resemble k-d
trees in some regimes, while in others, they have elements of
locality-sensitive hashing. The model can also learn useful representations of
high-dimensional data and exploit them to design effective data structures. We
also adapt our framework to the problem of estimating frequencies over a data
stream, and believe it could also be a powerful discovery tool for new
problems.

æè¦ï¼æåæåºä¸åéç¨çæ¶æ§ï¼ç¨æ¼è³æçµæ§çç«¯å°ç«¯å­¸ç¿ã
æåçæ¶æ§æé©æåºç¤è³æåä½ï¼ä¸¦æä¾å°æ¥è©¢åç©ºéè¤éåº¦çç´°ç·»æ§å¶ãè³ééè¦çæ¯ï¼è³æçµæ§æ¯å¾é ­éå§å­¸ç¿ï¼ä¸éè¦ä»ç´°åå§åæä½¿ç¨åé¸è³æçµæ§/æ¼ç®æ³é²è¡è¨­å®ãæåé¦åå°éåæ¶æ§æç¨å°æè¿é°æå°çåé¡ãå¨å¤ç¨®è¨­å®ä¸­ï¼æåè½å¤ éåå·¥ç¨å·²å­¸ç¿çè³æçµæ§åæ¥è©¢æ¼ç®æ³ãå°æ¼ 1D æè¿é°æå°ï¼æ¨¡åæç¼ç¾æä½³åä½ï¼å§é¨ï¼ç¨ç«æ¼ç®æ³ï¼ä¾å¦äºåæå°åå§ææå°è®é«ãå¨æ´é«ç¶­åº¦ä¸­ï¼æ¨¡åå­¸ç¿å°çè§£æå¨æäºæ¨¡å¼ä¸é¡ä¼¼æ¼ k-d æ¨¹ï¼èå¨å¶ä»æ¨¡å¼ä¸ï¼å®åæåå«å±é¨ææéæ¹çåç´ ãè©²æ¨¡åéå¯ä»¥å­¸ç¿é«ç¶­è³æçæç¨è¡¨ç¤ºï¼ä¸¦å©ç¨å®åä¾è¨­è¨ææçè³æçµæ§ãæåä¹å°æåçæ¶æ§èª¿æ´å°è³æä¸²æµä¸é »çä¼°è¨çåé¡ï¼ä¸¦ç¸ä¿¡å®å°æ¼æ°åé¡ä¾èªªä¹å¯è½æ¯ä¸åå¼·å¤§çç¼ç¾å·¥å·ã

##### **Evaluating Machine Learning Models against Clinical Protocols for Enhanced Interpretability and Continuity of Care**
2411.03105v1 by Christel Sirocchi, Muhammad Suffian, Federico Sabbatini, Alessandro Bogliolo, Sara Montagna

In clinical practice, decision-making relies heavily on established
protocols, often formalised as rules. Concurrently, Machine Learning (ML)
models, trained on clinical data, aspire to integrate into medical
decision-making processes. However, despite the growing number of ML
applications, their adoption into clinical practice remains limited. Two
critical concerns arise, relevant to the notions of consistency and continuity
of care: (a) accuracy - the ML model, albeit more accurate, might introduce
errors that would not have occurred by applying the protocol; (b)
interpretability - ML models operating as black boxes might make predictions
based on relationships that contradict established clinical knowledge. In this
context, the literature suggests using ML models integrating domain knowledge
for improved accuracy and interpretability. However, there is a lack of
appropriate metrics for comparing ML models with clinical rules in addressing
these challenges. Accordingly, in this article, we first propose metrics to
assess the accuracy of ML models with respect to the established protocol.
Secondly, we propose an approach to measure the distance of explanations
provided by two rule sets, with the goal of comparing the explanation
similarity between clinical rule-based systems and rules extracted from ML
models. The approach is validated on the Pima Indians Diabetes dataset by
training two neural networks - one exclusively on data, and the other
integrating a clinical protocol. Our findings demonstrate that the integrated
ML model achieves comparable performance to that of a fully data-driven model
while exhibiting superior accuracy relative to the clinical protocol, ensuring
enhanced continuity of care. Furthermore, we show that our integrated model
provides explanations for predictions that align more closely with the clinical
protocol compared to the data-driven model.

æè¦ï¼<paragraph>å¨è¨åºå¯¦åä¸­ï¼æ±ºç­ä»°è³´æ¢å®çåå®ï¼éå¸¸ä»¥è¦åå½¢å¼åãåæï¼ä»¥è¨åºè³æè¨ç·´çæ©å¨å­¸ç¿ (ML) æ¨¡åï¼æ¸´ææ´åå°é«çæ±ºç­æµç¨ä¸­ãç¶èï¼åç®¡ ML æç¨æ¸éæ¥å¢ï¼å®åå¨è¨åºå¯¦åä¸­çæ¡ç¨ä»åéãå©åééµçæ®æµ®ç¾ï¼èç§è­·çä¸è´æ§åé£çºæ§æ¦å¿µç¸éï¼(a) æºç¢ºæ§ - ML æ¨¡åéç¶æ´æºç¢ºï¼ä½å¯è½æå¼å¥å¥ç¨åå®æä¸æç¼ççé¯èª¤ï¼(b) å¯è§£éæ§ - ä½çºé»çéä½ç ML æ¨¡åå¯è½ææ ¹æèæ¢å®è¨åºç¥è­ç¸çç¾çéä¿é²è¡é æ¸¬ãå¨æ­¤èçµ¡ä¸­ï¼æç»å»ºè­°ä½¿ç¨æ´åé åç¥è­ç ML æ¨¡åä»¥æåæºç¢ºæ§åå¯è§£éæ§ãç¶èï¼ç¼ºä¹é©ç¶çææ¨ä¾æ¯è¼ ML æ¨¡åèè¨åºè¦åï¼ä»¥æå°éäºææ°ãå æ­¤ï¼å¨æ¬æä¸­ï¼æåé¦åæåºææ¨ä¾è©ä¼° ML æ¨¡åç¸å°æ¼æ¢å®åå®çæºç¢ºæ§ãå¶æ¬¡ï¼æåæåºä¸åæ¹æ³ä¾è¡¡éå©çµè¦åææä¾çè§£éçè·é¢ï¼ç®æ¨æ¯æ¯è¼åºæ¼è¨åºè¦åçç³»çµ±èå¾ ML æ¨¡åä¸­æåçè¦åä¹éçè§£éç¸ä¼¼æ§ãæ­¤æ¹æ³å¨ Pima å°å°å®äººç³å°¿çè³æéä¸é©è­ï¼æ¹æ³æ¯è¨ç·´å©åç¥ç¶ç¶²è·¯ - ä¸ååéå°è³æï¼å¦ä¸åæ´åè¨åºåå®ãæåçç ç©¶çµæè­æï¼æ´åå¼ ML æ¨¡åéå°äºèå®å¨è³æé©åæ¨¡åç¸ç¶çæè½ï¼åæå±ç¾åºç¸å°æ¼è¨åºåå®çåªç°æºç¢ºæ§ï¼ç¢ºä¿å¢å¼·çç§è­·é£çºæ§ãæ­¤å¤ï¼æåè­ææåçæ´åæ¨¡åæä¾çé æ¸¬è§£éèè¨åºåå®ç¸æ¯ï¼æ´çºç·å¯å°çµåã</paragraph>

##### **Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation in a Limited Data Setting**
2411.03098v1 by Adrian B. ChÅopowiec, Adam R. ChÅopowiec, Krzysztof Galus, Wojciech Cebula, Martin Tabakov

Limited medical imaging datasets challenge deep learning models by increasing
risks of overfitting and reduced generalization, particularly in Generative
Adversarial Networks (GANs), where discriminators may overfit, leading to
training divergence. This constraint also impairs classification models trained
on small datasets. Generative Data Augmentation (GDA) addresses this by
expanding training datasets with synthetic data, although it requires training
a generative model. We propose and evaluate two local lesion generation
approaches to address the challenge of augmenting small medical image datasets.
The first approach employs the Poisson Image Editing algorithm, a classical
image processing technique, to create realistic image composites that
outperform current state-of-the-art methods. The second approach introduces a
novel generative method, leveraging a fine-tuned Image Inpainting GAN to
synthesize realistic lesions within specified regions of real training images.
A comprehensive comparison of the two proposed methods demonstrates that
effective local lesion generation in a data-constrained setting allows for
reaching new state-of-the-art results in capsule endoscopy lesion
classification. Combination of our techniques achieves a macro F1-score of
33.07%, surpassing the previous best result by 7.84 percentage points (p.p.) on
the highly imbalanced Kvasir Capsule Dataset, a benchmark for capsule
endoscopy. To the best of our knowledge, this work is the first to apply a
fine-tuned Image Inpainting GAN for GDA in medical imaging, demonstrating that
an image-conditional GAN can be adapted effectively to limited datasets to
generate high-quality examples, facilitating effective data augmentation.
Additionally, we show that combining this GAN-based approach with classical
image processing techniques further enhances the results.

æè¦ï¼<paragraph>åéçé«å­¸å½±åè³æéæééå¢å éåº¦æ¬åçé¢¨éªåéä½æ¦åè½åï¼ç¹å¥æ¯å¨çæå°æç¶²è·¯ (GAN) ä¸­ï¼å¶ä¸­å¤å¥å¨å¯è½æéåº¦æ¬åï¼å°è´è¨ç·´åæ­§ï¼å°æ·±åº¦å­¸ç¿æ¨¡åæ§æææ°ãéç¨®éå¶ä¹æå®³äºå¨å°åè³æéä¸è¨ç·´çåé¡æ¨¡åãçæè³ææ´å (GDA) ééä½¿ç¨åæè³ææ´åè¨ç·´è³æéä¾è§£æ±ºæ­¤åé¡ï¼åç®¡å®éè¦è¨ç·´çææ¨¡åãæåæåºä¸¦è©ä¼°å©ç¨®å±é¨çç¶çææ¹æ³ï¼ä»¥è§£æ±ºæ´åå°åé«å­¸å½±åè³æéçææ°ãç¬¬ä¸ç¨®æ¹æ³æ¡ç¨æ³æ¾å½±åç·¨è¼¯æ¼ç®æ³ï¼ä¸ç¨®ç¶å¸å½±åèçæè¡ï¼ä¾å»ºç«é¼ççå½±ååæï¼å¶åªæ¼ç®åæåé²çæ¹æ³ãç¬¬äºç¨®æ¹æ³å¼é²ä¸ç¨®æ°ç©ççææ¹æ³ï¼å©ç¨å¾®èª¿çå½±åä¿®å¾© GANï¼å¨çå¯¦è¨ç·´å½±åçç¹å®ååå§åæé¼çççç¶ãå°éå©ç¨®æè­°æ¹æ³çå¨é¢æ¯è¼è­æï¼å¨è³æåéçè¨­å®ä¸­ï¼ææçå±é¨çç¶çæåè¨±å¨è åå§è¦é¡çç¶åé¡ä¸­éå°æ°çæåé²çµæãæåçæè¡çµåå¨é«åº¦ä¸å¹³è¡¡ç Kvasir Capsule è³æéï¼è åå§è¦é¡çåºæºï¼ä¸ï¼éå°äº 33.07% çå·¨è§ F1 åæ¸ï¼æ¯ååçæä½³çµæé«åº 7.84 åç¾åé» (p.p.)ãææåæç¥ï¼éé å·¥ä½æ¯ç¬¬ä¸åå°å¾®èª¿çå½±åä¿®å¾© GAN æç¨æ¼é«å­¸å½±åä¸­ç GDAï¼è­æäºå½±åæ¢ä»¶ GAN å¯ä»¥ææå°é©æåéçè³æéï¼ä»¥ç¢çé«åè³ªçç¯ä¾ï¼ä¿é²ææçè³ææ´åãæ­¤å¤ï¼æåè¡¨æå°éç¨®åºæ¼ GAN çæ¹æ³èç¶å¸å½±åèçæè¡ç¸çµåï¼é²ä¸æ­¥å¢å¼·äºçµæã</paragraph>

##### **Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status**
2411.03004v1 by Samuel Lee, Zach Wood-Doughty

Causal understanding is a fundamental goal of evidence-based medicine. When
randomization is impossible, causal inference methods allow the estimation of
treatment effects from retrospective analysis of observational data. However,
such analyses rely on a number of assumptions, often including that of no
unobserved confounding. In many practical settings, this assumption is violated
when important variables are not explicitly measured in the clinical record.
Prior work has proposed to address unobserved confounding with machine learning
by imputing unobserved variables and then correcting for the classifier's
mismeasurement. When such a classifier can be trained and the necessary
assumptions are met, this method can recover an unbiased estimate of a causal
effect. However, such work has been limited to synthetic data, simple
classifiers, and binary variables. This paper extends this methodology by using
a large language model trained on clinical notes to predict patients' smoking
status, which would otherwise be an unobserved confounder. We then apply a
measurement error correction on the categorical predicted smoking status to
estimate the causal effect of transthoracic echocardiography on mortality in
the MIMIC dataset.

æè¦ï¼å æçè§£æ¯å¾ªè¯å»å­¦çåºæ¬ç®æ ãå½éæºåä¸å¯è¡æ¶ï¼å ææ¨è®ºæ¹æ³åè®¸ä»è§å¯æ§æ°æ®çåé¡¾æ§åæä¸­ä¼°è®¡æ²»çææãç¶èï¼æ­¤ç±»åæä¾èµäºè®¸å¤åè®¾ï¼éå¸¸åæ¬æ²¡ææªè§å¯å°çæ··æå ç´ ãå¨è®¸å¤å®éæåµä¸ï¼å½éè¦çåéå¨ä¸´åºè®°å½ä¸­æ²¡ææç¡®æµéæ¶ï¼è¿ä¸åè®¾å°±ä¼è¢«è¿åãååçå·¥ä½æåºç¨æºå¨å­¦ä¹ æ¥è§£å³æªè§å¯å°çæ··æé®é¢ï¼æ¹æ³æ¯æ¨ç®æªè§å¯å°çåéï¼ç¶åæ ¡æ­£åç±»å¨çæµéè¯¯å·®ãå½å¯ä»¥è®­ç»è¿æ ·çåç±»å¨å¹¶ä¸æ»¡è¶³å¿è¦çåè®¾æ¶ï¼è¿ç§æ¹æ³å¯ä»¥æ¢å¤å ææåºçæ åä¼°è®¡ãç¶èï¼æ­¤ç±»å·¥ä½ä»éäºåææ°æ®ãç®åçåç±»å¨åäºååéãæ¬æéè¿ä½¿ç¨å¨ä¸´åºè®°å½ä¸è®­ç»çå¤§è¯­è¨æ¨¡åæ¥é¢æµæ£èçå¸çç¶åµæ¥æ©å±è¿ç§æ¹æ³ï¼å¦åè¿å°æ¯ä¸ä¸ªæªè§å¯å°çæ··æå ç´ ãç¶åï¼æä»¬å¯¹åç±»é¢æµçå¸çç¶æåºç¨æµéè¯¯å·®æ ¡æ­£ï¼ä»¥ä¼°è®¡ç»è¸è¶å£°å¿å¨å¾å¯¹ MIMIC æ°æ®éä¸­æ­»äº¡ççå ææåºã

##### **Region-Guided Attack on the Segment Anything Model (SAM)**
2411.02974v2 by Xiaoliang Liu, Furao Shen, Jian Zhao

The Segment Anything Model (SAM) is a cornerstone of image segmentation,
demonstrating exceptional performance across various applications, particularly
in autonomous driving and medical imaging, where precise segmentation is
crucial. However, SAM is vulnerable to adversarial attacks that can
significantly impair its functionality through minor input perturbations.
Traditional techniques, such as FGSM and PGD, are often ineffective in
segmentation tasks due to their reliance on global perturbations that overlook
spatial nuances. Recent methods like Attack-SAM-K and UAD have begun to address
these challenges, but they frequently depend on external cues and do not fully
leverage the structural interdependencies within segmentation processes. This
limitation underscores the need for a novel adversarial strategy that exploits
the unique characteristics of segmentation tasks. In response, we introduce the
Region-Guided Attack (RGA), designed specifically for SAM. RGA utilizes a
Region-Guided Map (RGM) to manipulate segmented regions, enabling targeted
perturbations that fragment large segments and expand smaller ones, resulting
in erroneous outputs from SAM. Our experiments demonstrate that RGA achieves
high success rates in both white-box and black-box scenarios, emphasizing the
need for robust defenses against such sophisticated attacks. RGA not only
reveals SAM's vulnerabilities but also lays the groundwork for developing more
resilient defenses against adversarial threats in image segmentation.

æè¦ï¼å½±ååå²çåºç³çºåæ®µä»»ä½æ¨¡å (SAM)ï¼å¨åç¨®æç¨ä¸­å±ç¾åºè²çæè½ï¼ç¹å¥æ¯å¨èªåé§é§åé«çå½±åä¸­ï¼ç²¾æºçåå²è³ééè¦ãç¶èï¼SAM å®¹æåå°å°ææ»æï¼èå°ææ»æå¯è½ééè¼å¾®çè¼¸å¥æ¾åå¤§å¹æå®³å¶åè½æ§ãå³çµ±æè¡ï¼ä¾å¦ FGSM å PGDï¼éå¸¸å¨åå²ä»»åä¸­ç¡æï¼å çºå®åä¾è³´æ¼å¿½ç¥ç©ºéç´°å¾®å·®çå¨å±æ¾åãæè¿çæ¹æ³ï¼ä¾å¦ Attack-SAM-K å UADï¼å·²éå§è§£æ±ºéäºææ°ï¼ä½å®åç¶å¸¸ä¾è³´æ¼å¤é¨æç¤ºï¼ä¸ä¸¦æªååå©ç¨åå²éç¨ä¸­çµæ§æ§çç¸äºä¾è³´æ§ãæ­¤éå¶å¼·èª¿éè¦ä¸ç¨®æ°çå°æç­ç¥ï¼ä»¥å©ç¨åå²ä»»åçç¨ç¹ç¹æ§ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²å°éçº SAM è¨­è¨çååå¼å°æ»æ (RGA)ãRGA å©ç¨ååå¼å°å°å (RGM) ææ§åå²ååï¼é²èéå°æ¾åé²è¡æ¨å®ï¼å°å¤§ååæ®µåå²ä¸¦æ´å±è¼å°çåæ®µï¼å°è´ SAM ç¢çé¯èª¤è¼¸åºãæåçå¯¦é©è­æï¼RGA å¨ç½çåé»çå ´æ¯ä¸­é½åå¾é«æåçï¼å¼·èª¿éè¦éå°æ­¤é¡ç²¾å¯æ»æå»ºç«å¼·åºçé²ç¦¦æ©å¶ãRGA ä¸åæ­é² SAM çæ¼æ´ï¼ä¹çºå¨å½±ååå²ä¸­éå°å°æå¨èç¼å±æ´å·å¾©ååçé²ç¦¦æªæ½å¥ å®åºç¤ã

##### **[Vision Paper] PRObot: Enhancing Patient-Reported Outcome Measures for Diabetic Retinopathy using Chatbots and Generative AI**
2411.02973v1 by Maren Pielka, Tobias Schneider, Jan Terheyden, Rafet Sifa

We present an outline of the first large language model (LLM) based chatbot
application in the context of patient-reported outcome measures (PROMs) for
diabetic retinopathy. By utilizing the capabilities of current LLMs, we enable
patients to provide feedback about their quality of life and treatment progress
via an interactive application. The proposed framework offers significant
advantages over the current approach, which encompasses only qualitative
collection of survey data or a static survey with limited answer options. Using
the PROBot LLM-PROM application, patients will be asked tailored questions
about their individual challenges, and can give more detailed feedback on the
progress of their treatment. Based on this input, we will use machine learning
to infer conventional PROM scores, which can be used by clinicians to evaluate
the treatment status. The goal of the application is to improve adherence to
the healthcare system and treatments, and thus ultimately reduce cases of
subsequent vision impairment. The approach needs to be further validated using
a survey and a clinical study.

æè¦ï¼æåæåºä¸ååºæ¼ç¬¬ä¸åå¤§åèªè¨æ¨¡å (LLM) çèå¤©æ©å¨äººæç¨ç¨å¼ï¼ç¨æ¼ç³å°¿çè¦ç¶²èçè®ççäººåå ±çµææ¸¬é (PROM)ãééå©ç¨ç¶å LLM çåè½ï¼æåè®çäººè½å¤ ééäºåå¼æç¨ç¨å¼æä¾æéå¶çæ´»åè³ªåæ²»çé²åº¦çåé¥ãææåºçæ¶æ§æä¾é¡¯èåªæ¼ç®åæ¹æ³çåªé»ï¼ç®åæ¹æ³ååå«èª¿æ¥è³æçè³ªæ§æ¶éæå·ææéç­æ¡é¸é çéæèª¿æ¥ãä½¿ç¨ PROBot LLM-PROM æç¨ç¨å¼ï¼çäººå°æè¢«è©¢åæéå¶åäººææ°çå®¢è£½ååé¡ï¼ä¸¦è½æä¾æ´è©³ç´°çåé¥ï¼èªªæå¶æ²»çé²åº¦ãæ ¹ææ­¤è¼¸å¥ï¼æåå°ä½¿ç¨æ©å¨å­¸ç¿æ¨è«å³çµ± PROM åæ¸ï¼è¨åºé«çå¯ä»¥ä½¿ç¨éäºåæ¸ä¾è©ä¼°æ²»ççæãæ­¤æç¨ç¨å¼çç®æ¨æ¯æ¹åå°é«çä¿å¥ç³»çµ±åæ²»ççä¾å¾æ§ï¼ä¸¦å æ­¤æçµæ¸å°å¾çºè¦åæå®³ççä¾ãéè¦ä½¿ç¨èª¿æ¥åè¨åºç ç©¶é²ä¸æ­¥é©è­æ­¤æ¹æ³ã

##### **Leveraging Transfer Learning and Multiple Instance Learning for HER2 Automatic Scoring of H\&E Whole Slide Images**
2411.05028v1 by Rawan S. Abdulsadig, Bryan M. Williams, Nikolay Burlutskiy

Expression of human epidermal growth factor receptor 2 (HER2) is an important
biomarker in breast cancer patients who can benefit from cost-effective
automatic Hematoxylin and Eosin (H\&E) HER2 scoring. However, developing such
scoring models requires large pixel-level annotated datasets. Transfer learning
allows prior knowledge from different datasets to be reused while
multiple-instance learning (MIL) allows the lack of detailed annotations to be
mitigated. The aim of this work is to examine the potential of transfer
learning on the performance of deep learning models pre-trained on (i)
Immunohistochemistry (IHC) images, (ii) H\&E images and (iii) non-medical
images. A MIL framework with an attention mechanism is developed using
pre-trained models as patch-embedding models. It was found that embedding
models pre-trained on H\&E images consistently outperformed the others,
resulting in an average AUC-ROC value of $0.622$ across the 4 HER2 scores
($0.59-0.80$ per HER2 score). Furthermore, it was found that using
multiple-instance learning with an attention layer not only allows for good
classification results to be achieved, but it can also help with producing
visual indication of HER2-positive areas in the H\&E slide image by utilising
the patch-wise attention weights.

æè¦ï¼äººé¡è¡¨ç®çé·å å­åé« 2 (HER2) çè¡¨ç¾æ¯ä¹³çæ£èä¸­çä¸é éè¦çç©æ¨è¨ï¼éäºæ£èå¯ä»¥åçæ¼å·æææ¬æççèªåèæ¨ç²¾åä¼ç´ (H&E) HER2 è©åãç¶èï¼éç¼æ­¤é¡è©åæ¨¡åéè¦å¤§éçåç´ ç´è¨»è§£è³æéãé·ç§»å­¸ç¿åè¨±éè¤ä½¿ç¨ä¾èªä¸åè³æéçåé©ç¥è­ï¼èå¤å¯¦ä¾å­¸ç¿ (MIL) åè¨±æ¸è¼è©³ç´°è¨»è§£çç¼ºä¹ãéé å·¥ä½çç®çæ¯æª¢æ¥é·ç§»å­¸ç¿å¨é åè¨ç·´æ¼ (i) åç«çµç¹åå­¸ (IHC) å½±åã(ii) H&E å½±åå (iii) éé«å­¸å½±åä¸çæ·±åº¦å­¸ç¿æ¨¡åçæè½ä¸çæ½åãä½¿ç¨é åè¨ç·´çæ¨¡åä½çºåå¡åµå¥æ¨¡åï¼éç¼äºä¸åå·ææ³¨æåæ©å¶ç MIL æ¡æ¶ãç ç©¶ç¼ç¾ï¼é åè¨ç·´æ¼ H&E å½±åä¸çåµå¥æ¨¡åå§çµåªæ¼å¶ä»æ¨¡åï¼å¨ 4 å HER2 åæ¸ä¸­ç¢çå¹³å AUC-ROC å¼çº $0.622$ï¼æ¯å HER2 åæ¸çº $0.59-0.80$ï¼ãæ­¤å¤ï¼ç ç©¶ç¼ç¾ï¼ä½¿ç¨å·ææ³¨æåå±¤çå¤å¯¦ä¾å­¸ç¿ä¸åå¯ä»¥ç²å¾è¯å¥½çåé¡çµæï¼éå¯ä»¥å¹«å©ééå©ç¨åå¡æ³¨æåæ¬éç¢ç H&E ç»çå½±åä¸­ HER2 é½æ§ååçå¯è¦åæç¤ºã

##### **Membership Inference Attacks against Large Vision-Language Models**
2411.02902v1 by Zhan Li, Yongtao Wu, Yihang Chen, Francesco Tonin, Elias Abad Rocamora, Volkan Cevher

Large vision-language models (VLLMs) exhibit promising capabilities for
processing multi-modal tasks across various application scenarios. However,
their emergence also raises significant data security concerns, given the
potential inclusion of sensitive information, such as private photos and
medical records, in their training datasets. Detecting inappropriately used
data in VLLMs remains a critical and unresolved issue, mainly due to the lack
of standardized datasets and suitable methodologies. In this study, we
introduce the first membership inference attack (MIA) benchmark tailored for
various VLLMs to facilitate training data detection. Then, we propose a novel
MIA pipeline specifically designed for token-level image detection. Lastly, we
present a new metric called MaxR\'enyi-K%, which is based on the confidence of
the model output and applies to both text and image data. We believe that our
work can deepen the understanding and methodology of MIAs in the context of
VLLMs. Our code and datasets are available at
https://github.com/LIONS-EPFL/VL-MIA.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (VLLM) å¨èçåç¨®æç¨å ´æ¯çå¤æ¨¡æä»»åæ¹é¢è¡¨ç¾åºæåæ¯çè½åãç¶èï¼å®åçåºç¾ä¹å¼ç¼äºéå¤§çè³æå®å¨åé¡ï¼å çºå®åçè¨ç·´è³æéä¸­å¯è½æåå«ææè³è¨ï¼ä¾å¦ç§äººç§çåé«çè¨éãåµæ¸¬ VLLM ä¸­ä¸ç¶ä½¿ç¨çè³æä»ç¶æ¯ä¸åééµä¸å°æªè§£æ±ºçåé¡ï¼ä¸»è¦æ¯ç±æ¼ç¼ºä¹æ¨æºåçè³æéåé©ç¶çæ¹æ³ãå¨æ¬ç ç©¶ä¸­ï¼æåå¼å¥äºç¬¬ä¸åéå°åç¨® VLLM éèº«æé çæå¡æ¨è«æ»æ (MIA) åºæºï¼ä»¥å©æ¼è¨ç·´è³æåµæ¸¬ãç¶å¾ï¼æåæåºäºä¸åå°éè¨­è¨ç¨æ¼ä»¤çç´å¥å½±ååµæ¸¬çå¨æ° MIA ç®¡ç·ãæå¾ï¼æåæåºä¸ååçº MaxR\'enyi-K% çæ°ææ¨ï¼å®åºæ¼æ¨¡åè¼¸åºçä¿¡å¿ï¼ä¸¦é©ç¨æ¼æå­åå½±åè³æãæåç¸ä¿¡ï¼æåçç ç©¶å¯ä»¥å æ·±å° VLLM èæ¯ä¸ MIA ççè§£åæ¹æ³ãæåçç¨å¼ç¢¼åè³æéå¯å¨ https://github.com/LIONS-EPFL/VL-MIA åå¾ã

##### **Advanced XR-Based 6-DOF Catheter Tracking System for Immersive Cardiac Intervention Training**
2411.02611v1 by Mohsen Annabestani, Sandhya Sriram, S. Chiu Wong, Alexandros Sigaras, Bobak Mosadegh

Extended Reality (XR) technologies are gaining traction as effective tools
for medical training and procedural guidance, particularly in complex cardiac
interventions. This paper presents a novel system for real-time 3D tracking and
visualization of intracardiac echocardiography (ICE) catheters, with precise
measurement of the roll angle. A custom 3D-printed setup, featuring orthogonal
cameras, captures biplane video of the catheter, while a specialized computer
vision algorithm reconstructs its 3D trajectory, localizing the tip with
sub-millimeter accuracy and tracking the roll angle in real-time. The system's
data is integrated into an interactive Unity-based environment, rendered
through the Meta Quest 3 XR headset, combining a dynamically tracked catheter
with a patient-specific 3D heart model. This immersive environment allows the
testing of the importance of 3D depth perception, in comparison to 2D
projections, as a form of visualization in XR. Our experimental study,
conducted using the ICE catheter with six participants, suggests that 3D
visualization is not necessarily beneficial over 2D views offered by the XR
system; although all cardiologists saw its utility for pre-operative training,
planning, and intra-operative guidance. The proposed system qualitatively shows
great promise in transforming catheter-based interventions, particularly ICE
procedures, by improving visualization, interactivity, and skill development.

æè¦ï¼æ´å¢å¯¦å¢ (XR) æè¡æ­£ä½çºé«çè¨ç·´åç¨åºæå°çææå·¥å·èç²å¾éè¦ï¼ç¹å¥æ¯å¨è¤éçå¿èä»å¥æ²»çä¸­ãæ¬ææåºäºä¸åæ°çç³»çµ±ï¼ç¨æ¼å¯¦æ 3D è¿½è¹¤åå¯è¦åå¿å§è¶è²å¿åå (ICE) å°ç®¡ï¼ä¸¦ç²¾ç¢ºæ¸¬éæ»¾åè§åº¦ãä¸åå®¢è£½åç 3D åå°è¨­å®ï¼éåæ­£äº¤ç¸æ©ï¼ææå°ç®¡çéå¹³é¢å½±çï¼èä¸åå°éçé»è¦è¦è¦ºæ¼ç®æ³éå»ºå¶ 3D è»è·¡ï¼ä»¥å°æ¼æ¯«ç±³çç²¾ç¢ºåº¦å®ä½å°ç«¯ä¸¦å³æè¿½è¹¤æ»¾åè§åº¦ãç³»çµ±çè³ææ´åå°ä¸åäºåå¼ç Unity çºåºç¤çç°å¢ä¸­ï¼éé Meta Quest 3 XR é ­æ´å¼è£ç½®åç¾ï¼çµååæè¿½è¹¤çå°ç®¡åç¹å®çæ£ç 3D å¿èæ¨¡åãéåæ²æµ¸å¼çç°å¢åè¨±æ¸¬è©¦ 3D æ·±åº¦æç¥çéè¦æ§ï¼è 2D æå½±ç¸æ¯ï¼ä½çº XR ä¸­çä¸ç¨®è¦è¦ºåå½¢å¼ãæåçå¯¦é©ç ç©¶ï¼ä½¿ç¨ ICE å°ç®¡é²è¡ï¼æå­ä½åèèï¼é¡¯ç¤º 3D è¦è¦ºåä¸ä¸å®æ¯ XR ç³»çµ±æä¾ç 2D è¦åæçï¼åç®¡ææå¿èç§é«å¸«é½çå°å®å¨è¡åè¨ç·´ãè¦ååè¡ä¸­æå°ä¸­çç¨éãææåºçç³»çµ±å¨è³ªåä¸é¡¯ç¤ºåºå¨è½æå°ç®¡ä»å¥æ²»çï¼ç¹å¥æ¯ ICE ç¨åºæ¹é¢ï¼ééæ¹åè¦è¦ºåãäºåæ§åæè½ç¼å±ï¼å·æå¾å¤§çåæ¯ã

##### **"It's a conversation, not a quiz": A Risk Taxonomy and Reflection Tool for LLM Adoption in Public Health**
2411.02594v1 by Jiawei Zhou, Amy Z. Chen, Darshi Shah, Laura Schwab Reese, Munmun De Choudhury

Recent breakthroughs in large language models (LLMs) have generated both
interest and concern about their potential adoption as accessible information
sources or communication tools across different domains. In public health --
where stakes are high and impacts extend across populations -- adopting LLMs
poses unique challenges that require thorough evaluation. However, structured
approaches for assessing potential risks in public health remain
under-explored. To address this gap, we conducted focus groups with health
professionals and health issue experiencers to unpack their concerns, situated
across three distinct and critical public health issues that demand
high-quality information: vaccines, opioid use disorder, and intimate partner
violence. We synthesize participants' perspectives into a risk taxonomy,
distinguishing and contextualizing the potential harms LLMs may introduce when
positioned alongside traditional health communication. This taxonomy highlights
four dimensions of risk in individual behaviors, human-centered care,
information ecosystem, and technology accountability. For each dimension, we
discuss specific risks and example reflection questions to help practitioners
adopt a risk-reflexive approach. This work offers a shared vocabulary and
reflection tool for experts in both computing and public health to
collaboratively anticipate, evaluate, and mitigate risks in deciding when to
employ LLM capabilities (or not) and how to mitigate harm when they are used.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´å¼èµ·äºäººåçèè¶£ï¼ä¹å¼èµ·äºäººåå°å¶ä½çºä¸åé åçç¡éç¤ä¿¡æ¯ä¾æºæéä¿¡å·¥å·çæ½å¨æ¡ç¨æç¢ççææãå¨å¬å±è¡çé åââå©å®³éä¿å¾é«ä¸å½±é¿éåäººç¾¤ââæ¡ç¨ LLM æ§æäºç¨ç¹çææ°ï¼éè¦å¾¹åºè©ä¼°ãç¶èï¼è©ä¼°å¬å±è¡çä¸­æ½å¨é¢¨éªççµæ§åæ¹æ³ä»æªå¾å°ååæ¢ç´¢ãçºäºè§£æ±ºéä¸å·®è·ï¼æåèé«çå°æ¥­äººå¡åå¥åº·åé¡é«é©èé²è¡äºç¦é»å°çµï¼ä»¥è§£éä»åççæ®ï¼éäºçæ®æ¶åä¸åä¸åçééµå¬å±è¡çåé¡ï¼éäºåé¡éè¦é«è³ªéçè³è¨ï¼ç«èãé¿çé¡è¥ç©ä½¿ç¨éç¤åè¦ªå¯ä¼´ä¾¶æ´åãæåå°åèèçè§é»ç¶åå°é¢¨éªåé¡æ³ä¸­ï¼åååæå¢å LLM å¨èå³çµ±å¥åº·å³æ­ä¸¦åæå¯è½é æçæ½å¨å±å®³ãéç¨®åé¡æ³çªåºäºåäººè¡çºãä»¥äººçºä¸­å¿çè­·çãè³è¨çæç³»çµ±åæè¡åè²¬å¶éååç¶­åº¦çé¢¨éªãå°æ¼æ¯åç¶­åº¦ï¼æåè¨è«å·é«çé¢¨éªåç¯ä¾åæåé¡ï¼ä»¥å¹«å©å¾æ¥­èæ¡ç¨é¢¨éªåææ¹æ³ãéé å·¥ä½çºè¨ç®åå¬å±è¡çé åçå°å®¶æä¾äºä¸åå±åçè©å½ååæå·¥å·ï¼ä»¥ä¾¿å¨æ±ºå®ä½ææ¡ç¨ LLM åè½ï¼æä¸æ¡ç¨ï¼ä»¥åå¨ä½¿ç¨ LLM åè½æå¦ä½æ¸è¼å±å®³æï¼å±åé æ¸¬ãè©ä¼°åæ¸è¼é¢¨éªã

##### **Digitizing Touch with an Artificial Multimodal Fingertip**
2411.02479v1 by Mike Lambeta, Tingfan Wu, Ali Sengul, Victoria Rose Most, Nolan Black, Kevin Sawyer, Romeo Mercado, Haozhi Qi, Alexander Sohn, Byron Taylor, Norb Tydingco, Gregg Kammerer, Dave Stroud, Jake Khatha, Kurt Jenkins, Kyle Most, Neal Stein, Ricardo Chavira, Thomas Craven-Bartle, Eric Sanchez, Yitian Ding, Jitendra Malik, Roberto Calandra

Touch is a crucial sensing modality that provides rich information about
object properties and interactions with the physical environment. Humans and
robots both benefit from using touch to perceive and interact with the
surrounding environment (Johansson and Flanagan, 2009; Li et al., 2020;
Calandra et al., 2017). However, no existing systems provide rich, multi-modal
digital touch-sensing capabilities through a hemispherical compliant
embodiment. Here, we describe several conceptual and technological innovations
to improve the digitization of touch. These advances are embodied in an
artificial finger-shaped sensor with advanced sensing capabilities.
Significantly, this fingertip contains high-resolution sensors (~8.3 million
taxels) that respond to omnidirectional touch, capture multi-modal signals, and
use on-device artificial intelligence to process the data in real time.
Evaluations show that the artificial fingertip can resolve spatial features as
small as 7 um, sense normal and shear forces with a resolution of 1.01 mN and
1.27 mN, respectively, perceive vibrations up to 10 kHz, sense heat, and even
sense odor. Furthermore, it embeds an on-device AI neural network accelerator
that acts as a peripheral nervous system on a robot and mimics the reflex arc
found in humans. These results demonstrate the possibility of digitizing touch
with superhuman performance. The implications are profound, and we anticipate
potential applications in robotics (industrial, medical, agricultural, and
consumer-level), virtual reality and telepresence, prosthetics, and e-commerce.
Toward digitizing touch at scale, we open-source a modular platform to
facilitate future research on the nature of touch.

æè¦ï¼è§¸è¦ºæ¯ä¸ç¨®è³ééè¦çææ¸¬æ¹å¼ï¼å¯æä¾éæ¼ç©é«å±¬æ§åèç©çç°å¢äº¤äºä½ç¨çè±å¯è³è¨ãäººé¡åæ©å¨äººé½åçæ¼ä½¿ç¨è§¸è¦ºä¾æç¥åèå¨åç°å¢äºåï¼Johansson and Flanagan, 2009; Li et al., 2020; Calandra et al., 2017ï¼ãç¶èï¼æ²æç¾æç³»çµ±ééåçå½¢é ææ§å·èº«åæä¾è±å¯çå¤æ¨¡å¼æ¸ä½è§¸è¦ºææ¸¬åè½ãå¨æ­¤ï¼æåæè¿°äºå¹¾åæ¦å¿µåæè¡åµæ°ï¼ä»¥æ¹åè§¸è¦ºçæ¸ä½åãéäºé²å±é«ç¾å¨å·ååé²ææ¸¬åè½çäººå·¥ææå½¢ææ¸¬å¨ä¸­ãéè¦çæ¯ï¼éåæå°åå«é«è§£æåº¦ææ¸¬å¨ï¼ç´ 830 è¬åè§¸è¦ºé»ï¼ï¼å¯å°å¨æ¹ä½è§¸è¦ºååºåæãæ·åå¤æ¨¡å¼è¨èï¼ä¸¦ä½¿ç¨è£ç½®ä¸çäººå·¥æºæ§å³æèçè³æãè©ä¼°é¡¯ç¤ºï¼äººå·¥æå°å¯ä»¥è§£æå°è³ 7 å¾®ç±³çç©ºéç¹å¾µï¼ä»¥ 1.01 æ¯«çé å 1.27 æ¯«çé çè§£æåº¦ææ¸¬æ³ååååªååï¼æç¥é«é 10 åèµ«çæ¯åãææ¸¬ç±ï¼çè³ææ¸¬æ°£å³ãæ­¤å¤ï¼å®å§åµäºä¸åè£ç½®ä¸ç AI ç¥ç¶ç¶²è·¯å éå¨ï¼ä½çºæ©å¨äººçå¨éç¥ç¶ç³»çµ±ï¼ä¸¦æ¨¡ä»¿äººé¡çåå°å¼§ãéäºçµæè­æäºä»¥è¶äººé¡æè½æ¸ä½åè§¸è¦ºçå¯è½æ§ãå¶å½±é¿æ·±é ï¼æåé æå¨æ©å¨äººæè¡ï¼å·¥æ¥­ãé«çãè¾²æ¥­åæ¶è²»èå±¤ç´ï¼ãèæ¬å¯¦å¢åé è·è¨å ´ãåè¢åé»å­ååä¸­æ½å¨çæç¨ãçºäºå¤§è¦æ¨¡æ¸ä½åè§¸è¦ºï¼æåéæ¾åå§ç¢¼ä¸åæ¨¡çµåå¹³å°ï¼ä»¥ä¿é²æªä¾å°è§¸è¦ºæ¬è³ªçç ç©¶ã

##### **Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking**
2411.02345v1 by Shahab Kavousinejad

Nanorobots are a promising development in targeted drug delivery and the
treatment of neurological disorders, with potential for crossing the
blood-brain barrier (BBB). These small devices leverage advancements in
nanotechnology and bioengineering for precise navigation and targeted payload
delivery, particularly for conditions like brain tumors, Alzheimer's disease,
and Parkinson's disease. Recent progress in artificial intelligence (AI) and
machine learning (ML) has improved the navigation and effectiveness of
nanorobots, allowing them to detect and interact with cancer cells through
biomarker analysis. This study presents a new reinforcement learning (RL)
framework for optimizing nanorobot navigation in complex biological
environments, focusing on cancer cell detection by analyzing the concentration
gradients of surrounding biomarkers. We utilize a computer simulation model to
explore the behavior of nanorobots in a three-dimensional space with cancer
cells and biological barriers. The proposed method uses Q-learning to refine
movement strategies based on real-time biomarker concentration data, enabling
nanorobots to autonomously navigate to cancerous tissues for targeted drug
delivery. This research lays the groundwork for future laboratory experiments
and clinical applications, with implications for personalized medicine and less
invasive cancer treatments. The integration of intelligent nanorobots could
revolutionize therapeutic strategies, reducing side effects and enhancing
treatment effectiveness for cancer patients. Further research will investigate
the practical deployment of these technologies in medical settings, aiming to
unlock the full potential of nanorobotics in healthcare.

æè¦ï¼å¥ç±³æ©å¨äººå¨æ¨é¶è¥ç©å³è¼¸åç¥ç¶ç¾çæ²»çä¸­æ¯ä¸é æåæ¯çç¼å±ï¼ä¸¦å·æç©¿è¶è¡è¦å±é (BBB) çæ½åãéäºå°åè£ç½®å©ç¨å¥ç±³æè¡åçç©å·¥ç¨çé²å±ï¼é²è¡ç²¾ç¢ºå°èªåæ¨é¶ææè¼è·å³è¼¸ï¼ç¹å¥æ¯éå°è¦ç¤ãé¿è²æµ·é»çåå¸éæ£®æ°çç­ç¾çãäººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) çææ°é²å±æ¹åäºå¥ç±³æ©å¨äººçå°èªåæè½ï¼è®å®åè½ééçç©æ¨è¨åæä¾åµæ¸¬åèçç´°èäºåãæ¬ç ç©¶æåºäºä¸åæ°çå¼·åå­¸ç¿ (RL) æ¶æ§ï¼ç¨æ¼æä½³åå¥ç±³æ©å¨äººå¨è¤éçç©ç°å¢ä¸­çå°èªï¼éé»å¨æ¼ééåæå¨åçç©æ¨è¨çæ¿åº¦æ¢¯åº¦ä¾åµæ¸¬çç´°èãæåå©ç¨é»è¦æ¨¡æ¬æ¨¡åä¾æ¢ç´¢å¥ç±³æ©å¨äººå¨ä¸ç¶­ç©ºéä¸­èçç´°èåçç©éç¤ç©ä¹éçè¡çºãææåºçæ¹æ³ä½¿ç¨ Q å­¸ç¿ä¾æ ¹æå³æçç©æ¨è¨æ¿åº¦è³æèª¿æ´ç§»åç­ç¥ï¼è®å¥ç±³æ©å¨äººè½èªä¸»å°èªè³ççµç¹é²è¡æ¨é¶è¥ç©å³è¼¸ãéé ç ç©¶çºæªä¾çå¯¦é©å®¤å¯¦é©åè¨åºæç¨å¥ å®äºåºç¤ï¼ä¸¦å°åäººåé«çåä¾µå¥æ§è¼å°çççæ²»çç¢çå½±é¿ãæ´åæºæ§å¥ç±³æ©å¨äººå¯ä»¥é©æ°æ²»çç­ç¥ï¼æ¸å°å¯ä½ç¨ä¸¦æé«ççæ£èçæ²»çææãé²ä¸æ­¥çç ç©¶å°æ¢è¨éäºæè¡å¨é«çç°å¢ä¸­çå¯¦éé¨ç½²ï¼ç®æ¨æ¯ç¼æ®å¥ç±³æ©å¨äººå¨é«çä¿å¥ä¸­çå¨é¨æ½åã

##### **Taking AI Welfare Seriously**
2411.00986v1 by Robert Long, Jeff Sebo, Patrick Butlin, Kathleen Finlinson, Kyle Fish, Jacqueline Harding, Jacob Pfau, Toni Sims, Jonathan Birch, David Chalmers

In this report, we argue that there is a realistic possibility that some AI
systems will be conscious and/or robustly agentic in the near future. That
means that the prospect of AI welfare and moral patienthood, i.e. of AI systems
with their own interests and moral significance, is no longer an issue only for
sci-fi or the distant future. It is an issue for the near future, and AI
companies and other actors have a responsibility to start taking it seriously.
We also recommend three early steps that AI companies and other actors can
take: They can (1) acknowledge that AI welfare is an important and difficult
issue (and ensure that language model outputs do the same), (2) start assessing
AI systems for evidence of consciousness and robust agency, and (3) prepare
policies and procedures for treating AI systems with an appropriate level of
moral concern. To be clear, our argument in this report is not that AI systems
definitely are, or will be, conscious, robustly agentic, or otherwise morally
significant. Instead, our argument is that there is substantial uncertainty
about these possibilities, and so we need to improve our understanding of AI
welfare and our ability to make wise decisions about this issue. Otherwise
there is a significant risk that we will mishandle decisions about AI welfare,
mistakenly harming AI systems that matter morally and/or mistakenly caring for
AI systems that do not.

æè¦ï¼å¨éä»½å ±åä¸­ï¼æåèªçºæäº AI ç³»çµ±å¨ä¸ä¹çå°ä¾æç¾å¯¦çå¯è½æ§æå·ææè­å/æå¼·å¤§çè½åæ§ãéè¡¨ç¤º AI ç¦å©åéå¾·ä¸ççäººå°ä½çåæ¯ï¼äº¦å³å·æèªèº«å©çåéå¾·æç¾©ç AI ç³»çµ±ï¼ä¸ååªæ¯ç§å¹»å°èªªæéé æªä¾çè­°é¡ãéæ¯è¿æªä¾çè­°é¡ï¼è AI å¬å¸åå¶ä»è¡çºèæè²¬ä»»éå§èªççå¾å®ãæåä¹å»ºè­° AI å¬å¸åå¶ä»è¡çºèå¯ä»¥æ¡åä¸åæ©æçæ­¥é©ï¼ä»åå¯ä»¥ (1) æ¿èª AI ç¦å©æ¯ä¸åéè¦ä¸å°é£çè­°é¡ï¼ä¸¦ç¢ºä¿èªè¨æ¨¡åçè¼¸åºä¹ééº¼åï¼ï¼(2) éå§è©ä¼° AI ç³»çµ±æ¯å¦ææè­åå¼·å¤§è½åæ§çè­æï¼ä»¥å (3) æºåæ¿ç­åç¨åºï¼ä»¥é©ç¶çéå¾·éæ³¨å±¤ç´ä¾å°å¾ AI ç³»çµ±ãæç¢ºä¾èªªï¼æåå¨éä»½å ±åä¸­çè«é»ä¸¦é AI ç³»çµ±çµå°æ¯æå°æå·ææè­ãå¼·å¤§çè½åæ§æå¶ä»éå¾·æç¾©ãç¸åå°ï¼æåçè«é»æ¯éæ¼éäºå¯è½æ§å­å¨èå¯¦è³ªçä¸ç¢ºå®æ§ï¼å æ­¤æåéè¦å¢é²æåå° AI ç¦å©çäºè§£ï¼ä»¥åæåååºéæ¼æ­¤è­°é¡çææºæ±ºå®çè½åãå¦åï¼æåå°é¢è¨éå¤§é¢¨éªï¼é¯èª¤å°èçéæ¼ AI ç¦å©çæ±ºç­ï¼é¯èª¤å°å·å®³å°å¨éå¾·ä¸éè¦ç AI ç³»çµ±ï¼å/æé¯èª¤å°ç§é¡§å°å¨éå¾·ä¸ä¸éè¦ç AI ç³»çµ±ã

##### **Federated GNNs for EEG-Based Stroke Assessment**
2411.02286v1 by Andrea Protani, Lorenzo Giusti, Albert Sund Aillet, Simona Sacco, Paolo Manganotti, Lucio Marinelli, Diogo Reis Santos, Pierpaolo Brutti, Pietro Caliandro, Luigi Serio

Machine learning (ML) has the potential to become an essential tool in
supporting clinical decision-making processes, offering enhanced diagnostic
capabilities and personalized treatment plans. However, outsourcing medical
records to train ML models using patient data raises legal, privacy, and
security concerns. Federated learning has emerged as a promising paradigm for
collaborative ML, meeting healthcare institutions' requirements for robust
models without sharing sensitive data and compromising patient privacy. This
study proposes a novel method that combines federated learning (FL) and Graph
Neural Networks (GNNs) to predict stroke severity using electroencephalography
(EEG) signals across multiple medical institutions. Our approach enables
multiple hospitals to jointly train a shared GNN model on their local EEG data
without exchanging patient information. Specifically, we address a regression
problem by predicting the National Institutes of Health Stroke Scale (NIHSS), a
key indicator of stroke severity. The proposed model leverages a masked
self-attention mechanism to capture salient brain connectivity patterns and
employs EdgeSHAP to provide post-hoc explanations of the neurological states
after a stroke. We evaluated our method on EEG recordings from four
institutions, achieving a mean absolute error (MAE) of 3.23 in predicting
NIHSS, close to the average error made by human experts (MAE $\approx$ 3.0).
This demonstrates the method's effectiveness in providing accurate and
explainable predictions while maintaining data privacy.

æè¦ï¼æ©å¨å­¸ç¿ (ML) ææ½åæçºæ¯æ´è¨åºæ±ºç­å¶å®æµç¨çå¿è¦å·¥å·ï¼æä¾å¢å¼·çè¨ºæ·è½åååäººåæ²»çè¨ç«ãç¶èï¼ä½¿ç¨çæ£è³æè¨ç·´æ©å¨å­¸ç¿æ¨¡åçå¤åé«çç´éå¼ç¼äºæ³å¾ãé±ç§åå®å¨æ¹é¢ççæ®ãè¯åå­¸ç¿å·²æçºåä½æ©å¨å­¸ç¿çä¸ç¨®æåæ¯çå¸ç¯ï¼å®ç¬¦åé«çä¿å¥æ©æ§å°ç©©å¥æ¨¡åçè¦æ±ï¼åæä¸æåäº«ææè³æåå±å®³çæ£é±ç§ãæ¬ç ç©¶æåºäºä¸ç¨®æ°çæ¹æ³ï¼çµåè¯åå­¸ç¿ (FL) ååå½¢ç¥ç¶ç¶²è·¯ (GNN) ä¾ä½¿ç¨è¦é»å (EEG) è¨èé æ¸¬å¤åé«çæ©æ§çè¦ä¸­é¢¨å´éç¨åº¦ãæåçåæ³è®å¤å®¶é«é¢è½å¤ å±åå¨ä»åçæ¬å° EEG è³æä¸è¨ç·´ä¸åå±äº«ç GNN æ¨¡åï¼èç¡éäº¤æçæ£è³è¨ãå·é«ä¾èªªï¼æåééé æ¸¬ç¾ååå®¶è¡çç ç©¶é¢è¦ä¸­é¢¨éè¡¨ (NIHSS) ä¾è§£æ±ºåæ­¸åé¡ï¼NIHSS æ¯è¦ä¸­é¢¨å´éç¨åº¦çä¸åééµææ¨ãææåºçæ¨¡åå©ç¨é®ç½©èªææ³¨ææ©å¶ä¾æ·åé¡¯èçè¦é¨é£çµæ¨¡å¼ï¼ä¸¦æ¡ç¨ EdgeSHAP å¨ä¸­é¢¨å¾æä¾ç¥ç¶çæçäºå¾è§£éãæåå¨ä¾èªåå®¶æ©æ§ç EEG è¨éä¸è©ä¼°äºæåçæ¨¡åï¼å¨é æ¸¬ NIHSS æéå°äº 3.23 çå¹³åçµå°èª¤å·® (MAE)ï¼æ¥è¿äººé¡å°å®¶æç¯çå¹³åèª¤å·® (MAE â 3.0)ãéè­æäºè©²æ¹æ³å¨ç¶­æè³æé±ç§çåæï¼è½æä¾æºç¢ºä¸å¯è§£éçé æ¸¬ï¼é²èå±ç¾å¶æè½ã

##### **Weakly supervised deep learning model with size constraint for prostate cancer detection in multiparametric MRI and generalization to unseen domains**
2411.02466v1 by Robin Trombetta, Olivier RouviÃ¨re, Carole Lartizien

Fully supervised deep models have shown promising performance for many
medical segmentation tasks. Still, the deployment of these tools in clinics is
limited by the very timeconsuming collection of manually expert-annotated data.
Moreover, most of the state-ofthe-art models have been trained and validated on
moderately homogeneous datasets. It is known that deep learning methods are
often greatly degraded by domain or label shifts and are yet to be built in
such a way as to be robust to unseen data or label distributions. In the
clinical setting, this problematic is particularly relevant as the deployment
institutions may have different scanners or acquisition protocols than those
from which the data has been collected to train the model. In this work, we
propose to address these two challenges on the detection of clinically
significant prostate cancer (csPCa) from bi-parametric MRI. We evaluate the
method proposed by (Kervadec et al., 2018), which introduces a size constaint
loss to produce fine semantic cancer lesions segmentations from weak circle
scribbles annotations. Performance of the model is based on two public (PI-CAI
and Prostate158) and one private databases. First, we show that the model
achieves on-par performance with strong fully supervised baseline models, both
on in-distribution validation data and unseen test images. Second, we observe a
performance decrease for both fully supervised and weakly supervised models
when tested on unseen data domains. This confirms the crucial need for
efficient domain adaptation methods if deep learning models are aimed to be
deployed in a clinical environment. Finally, we show that ensemble predictions
from multiple trainings increase generalization performance.

æè¦ï¼<paragraph>å®å¨ç£ç£çæ·±åº¦æ¨¡åå¨è¨±å¤é«çå½±ååå²ä»»åä¸­å±ç¾åºè¯å¥½çæè½ãç¶èï¼éäºå·¥å·å¨è¨åºä¸çé¨ç½²åå°èæçäººå·¥æ¨è¨è³æèééå¶ãæ­¤å¤ï¼å¤§å¤æ¸æåé²çæ¨¡åé½å¨ä¸­ç­åè³ªçè³æéä¸è¨ç·´åé©è­ãç¾æå¨ç¥ï¼æ·±åº¦å­¸ç¿æ¹æ³ç¶å¸¸æå é åææ¨ç±¤è½ç§»èå¤§å¹éä½ï¼èä¸å°æªå»ºæ§åºå°æªè¦è³æææ¨ç±¤åä½å·æç©©å¥æ§çæ¹æ³ãå¨è¨åºç°å¢ä¸­ï¼éååé¡ç¹å¥ç¸éï¼å çºé¨ç½²æ©æ§å¯è½ææèç¨æ¼è¨ç·´æ¨¡åçè³æä¸åçææå¨ææ·ååå®ãå¨éé å·¥ä½ä¸­ï¼æåæè­°éå°å¾éåæ¸ MRI ä¸­åµæ¸¬è¨åºé¡¯èçååèºç (csPCa) ä¾è§£æ±ºéå©åææ°ãæåè©ä¼°ç± (Kervadec ç­äººï¼2018 å¹´) æåºï¼ä¸¦å¼å¥å¤§å°ç´ææå¤±çæ¹æ³ï¼ä»¥å¾å¼±åå½¢å¡é´æ¨è¨»ä¸­ç¢çç²¾ç´°çèªç¾©çççç¶åå²ãæ¨¡åçæè½åºæ¼å©åå¬éè³æåº« (PI-CAI å Prostate158) åä¸åç§äººè³æåº«ãé¦åï¼æåå±ç¤ºè©²æ¨¡åå¨åä½å§é©è­è³æåæªè¦æ¸¬è©¦å½±åä¸é½éå°èå¼·å¤§çå®å¨ç£ç£åºç·æ¨¡ååç­çæè½ãå¶æ¬¡ï¼æåè§å¯å°å¨æªè¦è³æé åä¸æ¸¬è©¦æï¼å®å¨ç£ç£åå¼±ç£ç£æ¨¡åçæè½é½æä¸éãéè­å¯¦äºå°ææé åé©ææ¹æ³çè¿«åéæ±ï¼å¦ææ·±åº¦å­¸ç¿æ¨¡åæ¨å¨é¨ç½²å¨è¨åºç°å¢ä¸­ãæå¾ï¼æåå±ç¤ºä¾èªå¤éè¨ç·´çæ´é«é æ¸¬ææåæ¦åæè½ã</paragraph>

##### **Evaluating the quality of published medical research with ChatGPT**
2411.01952v1 by Mike Thelwall, Xiaorui Jiang, Peter A. Bath

Evaluating the quality of published research is time-consuming but important
for departmental evaluations, appointments, and promotions. Previous research
has shown that ChatGPT can score articles for research quality, with the
results correlating positively with an indicator of quality in all fields
except Clinical Medicine. This article investigates this anomaly with the
largest dataset yet and a more detailed analysis. The results showed that
ChatGPT 4o-mini scores for articles submitted to the UK's Research Excellence
Framework (REF) 2021 Unit of Assessment (UoA) 1 Clinical Medicine correlated
positively (r=0.134, n=9872) with departmental mean REF scores, against a
theoretical maximum correlation of r=0.226 (due to the departmental averaging
involved). At the departmental level, mean ChatGPT scores correlated more
strongly with departmental mean REF scores (r=0.395, n=31). For the 100
journals with the most articles in UoA 1, their mean ChatGPT score correlated
strongly with their REF score (r=0.495) but negatively with their citation rate
(r=-0.148). Journal and departmental anomalies in these results point to
ChatGPT being ineffective at assessing the quality of research in prestigious
medical journals or research directly affecting human health, or both.
Nevertheless, the results give evidence of ChatGPT's ability to assess research
quality overall for Clinical Medicine, so now there is evidence of its ability
in all academic fields.

æè¦ï¼<paragraph>è©ä¼°å·²ç¼è¡¨çåè³ªç ç©¶å¾èæï¼ä½å°æ¼é¨éè©éãä»»å½åæåä¾èªªå¾éè¦ãååçç ç©¶é¡¯ç¤ºï¼ChatGPT å¯ä»¥çºç ç©¶åè³ªè©åï¼å¶çµæèææé åï¼è¨åºé«å­¸é¤å¤ï¼çåè³ªææ¨åæ­£ç¸éãæ¬æä½¿ç¨è¿ä»çºæ­¢æå¤§çè³æéåæ´è©³ç´°çåæä¾æ¢è¨éç¨®ç°å¸¸ç¾è±¡ãçµæé¡¯ç¤ºï¼æäº¤çµ¦è±åç ç©¶åè¶æ¶æ§ (REF) 2021 è©ä¼°å®ä½ (UoA) 1 è¨åºé«å­¸ç ChatGPT 4o-mini åæ¸èé¨éå¹³å REF åæ¸åæ­£ç¸éï¼r=0.134ï¼n=9872ï¼ï¼èçè«æå¤§ç¸éä¿æ¸çº r=0.226ï¼ç±æ¼æ¶åé¨éå¹³åï¼ãå¨é¨éå±¤ç´ï¼å¹³å ChatGPT åæ¸èé¨éå¹³å REF åæ¸ç¸éæ§æ´å¼·ï¼r=0.395ï¼n=31ï¼ãå°æ¼ UoA 1 ä¸­æç« æå¤ç 100 æ¬æåï¼å¶å¹³å ChatGPT åæ¸èå¶ REF åæ¸åå¼·æ­£ç¸éï¼r=0.495ï¼ï¼ä½èå¶å¼ç¨çåè² ç¸éï¼r=-0.148ï¼ãéäºçµæä¸­çæååé¨éç°å¸¸ç¾è±¡è¡¨æï¼ChatGPT ç¡æ³è©ä¼°è²æåèçé«å­¸æåæç´æ¥å½±é¿äººé¡å¥åº·çç ç©¶ï¼æå©èï¼çåè³ªãåç®¡å¦æ­¤ï¼çµæè­æäº ChatGPT æ´é«è©ä¼°è¨åºé«å­¸ç ç©¶åè³ªçè½åï¼å æ­¤ç¾å¨æè­æè­æå¶å¨ææå­¸è¡é åçè½åã</paragraph>

##### **You are out of context!**
2411.02464v1 by Giancarlo Cobino, Simone Farci

This research proposes a novel drift detection methodology for machine
learning (ML) models based on the concept of ''deformation'' in the vector
space representation of data. Recognizing that new data can act as forces
stretching, compressing, or twisting the geometric relationships learned by a
model, we explore various mathematical frameworks to quantify this deformation.
We investigate measures such as eigenvalue analysis of covariance matrices to
capture global shape changes, local density estimation using kernel density
estimation (KDE), and Kullback-Leibler divergence to identify subtle shifts in
data concentration. Additionally, we draw inspiration from continuum mechanics
by proposing a ''strain tensor'' analogy to capture multi-faceted deformations
across different data types. This requires careful estimation of the
displacement field, and we delve into strategies ranging from density-based
approaches to manifold learning and neural network methods. By continuously
monitoring these deformation metrics and correlating them with model
performance, we aim to provide a sensitive, interpretable, and adaptable drift
detection system capable of distinguishing benign data evolution from true
drift, enabling timely interventions and ensuring the reliability of machine
learning systems in dynamic environments. Addressing the computational
challenges of this methodology, we discuss mitigation strategies like
dimensionality reduction, approximate algorithms, and parallelization for
real-time and large-scale applications. The method's effectiveness is
demonstrated through experiments on real-world text data, focusing on detecting
context shifts in Generative AI. Our results, supported by publicly available
code, highlight the benefits of this deformation-based approach in capturing
subtle drifts that traditional statistical methods often miss. Furthermore, we
present a detailed application example within the healthcare domain, showcasing
the methodology's potential in diverse fields. Future work will focus on
further improving computational efficiency and exploring additional
applications across different ML domains.

æè¦ï¼æ¬ç ç©¶æåºä¸åæ°ç©çæ¼ç§»åµæ¸¬æ¹æ³ï¼è©²æ¹æ³éå°æ©å¨å­¸ç¿ (ML) æ¨¡åï¼ä¸¦åºæ¼è³æåéç©ºéè¡¨ç¤ºä¸­çãè®å½¢ãæ¦å¿µãæåäºè§£å°æ°è³æå¯ä»¥ä½çºåéï¼å»¶ä¼¸ãå£ç¸®ææ­æ²æ¨¡åå­¸ç¿å°çå¹¾ä½éä¿ï¼æåæ¢ç´¢åç¨®æ¸å­¸æ¶æ§ä¾éåéç¨®è®å½¢ãæåç ç©¶äºè«¸å¦åæ¹å·®ç©é£çç¹å¾µå¼åæä¾æ·åæ´é«å½¢çè®åãä½¿ç¨æ ¸å¯åº¦ä¼°è¨ (KDE) çå±é¨å¯åº¦ä¼°è¨ï¼ä»¥å Kullback-Leibler è·é¢ä¾è­å¥è³æéä¸­å¾®å¦çåç§»ãæ­¤å¤ï¼æåå¾é£çºåå­¸ä¸­æ±²åéæï¼æåºä¸åãæè®å¼µéãé¡æ¯ä¾æ·åä¸åè³æé¡åä¸­çå¤é¢åè®å½¢ãééè¦ä»ç´°ä¼°è¨ä½ç§»å ´ï¼æåæ·±å¥æ¢è¨å¾åºæ¼å¯åº¦çéå¾å°æµå½¢å­¸ç¿åç¥ç¶ç¶²è·¯æ¹æ³çç­ç¥ãééæçºç£æ§éäºè®å½¢éåº¦ä¸¦å°å®åèæ¨¡åæè½ç¸éè¯ï¼æåæ¨å¨æä¾ä¸åéæãå¯è§£éä¸é©ææ§å¼·çæ¼ç§»åµæ¸¬ç³»çµ±ï¼è½å¤ ååè¯æ§çè³ææ¼ååçæ­£çæ¼ç§»ï¼å¾èå¯¦ç¾åæçå¹²é ä¸¦ç¢ºä¿æ©å¨å­¸ç¿ç³»çµ±å¨åæç°å¢ä¸­çå¯é æ§ãçºäºæå°éç¨®æ¹æ³çè¨ç®ææ°ï¼æåè¨è«äºéç¶­ãè¿ä¼¼æ¼ç®æ³åä¸¦è¡åç­ç·©è§£ç­ç¥ï¼ä»¥ç¨æ¼å³æåå¤§è¦æ¨¡æç¨ãééå¨çå¯¦ä¸çæå­è³æä¸é²è¡å¯¦é©ï¼è­æäºè©²æ¹æ³çæææ§ï¼éé»å¨æ¼åµæ¸¬çæå¼ AI ä¸­çèçµ¡è½ç§»ãæåççµæç±å¬éå¯ç¨çç¨å¼ç¢¼æ¯æ´ï¼çªé¡¯äºéç¨®åºæ¼è®å½¢çéå¾å¨æ·åå³çµ±çµ±è¨æ¹æ³ç¶å¸¸éºæ¼çå¾®å¦æ¼ç§»æ¹é¢çåªé»ãæ­¤å¤ï¼æåå¨é«çä¿å¥é åä¸­å±ç¤ºäºä¸åè©³ç´°çæç¨ç¯ä¾ï¼å±ç¤ºäºè©²æ¹æ³å¨ä¸åé åçæ½åãæªä¾çç ç©¶å°éä¸­å¨é²ä¸æ­¥æé«è¨ç®æçï¼ä¸¦æ¢ç´¢ä¸å ML é åä¸­çå¶ä»æç¨ã

##### **Diagnosing Medical Datasets with Training Dynamics**
2411.01653v1 by Laura Wenderoth

This study explores the potential of using training dynamics as an automated
alternative to human annotation for evaluating the quality of training data.
The framework used is Data Maps, which classifies data points into categories
such as easy-to-learn, hard-to-learn, and ambiguous (Swayamdipta et al., 2020).
Swayamdipta et al. (2020) highlight that difficult-to-learn examples often
contain errors, and ambiguous cases significantly impact model training. To
confirm the reliability of these findings, we replicated the experiments using
a challenging dataset, with a focus on medical question answering. In addition
to text comprehension, this field requires the acquisition of detailed medical
knowledge, which further complicates the task. A comprehensive evaluation was
conducted to assess the feasibility and transferability of the Data Maps
framework to the medical domain. The evaluation indicates that the framework is
unsuitable for addressing datasets' unique challenges in answering medical
questions.

æè¦ï¼æ¬ç ç©¶æ¢è¨ä½¿ç¨è¨ç·´åæä½çºèªååæ¿ä»£æ¹æ¡ï¼ä»¥è©ä¼°è¨ç·´è³æåè³ªï¼ä»¥åä»£äººå·¥æ¨è¨»ãæä½¿ç¨çæ¶æ§çºè³æå°åï¼å¶å°è³æé»åé¡çºææ¼å­¸ç¿ãé£ä»¥å­¸ç¿åæ¨¡ç¨å©å¯ç­é¡å¥ï¼Swayamdipta ç­äººï¼2020 å¹´ï¼ãSwayamdipta ç­äººï¼2020 å¹´ï¼å¼·èª¿ï¼é£ä»¥å­¸ç¿çç¯ä¾éå¸¸åå«é¯èª¤ï¼èæ¨¡ç¨å©å¯çææ³æå°æ¨¡åè¨ç·´ç¢çéå¤§å½±é¿ãçºäºç¢ºèªéäºç¼ç¾çå¯é æ§ï¼æåä½¿ç¨å·æææ°æ§çè³æéè¤è£½äºå¯¦é©ï¼éé»æ¾å¨é«å­¸åé¡è§£ç­ä¸ãé¤äºæå­çè§£ä¹å¤ï¼éåé åééè¦ç²åè©³ç´°çé«å­¸ç¥è­ï¼éé²ä¸æ­¥ä½¿ä»»åè¤éåãæåé²è¡äºå¨é¢çè©ä¼°ï¼ä»¥è©ä¼°è³æå°åæ¶æ§å¨é«å­¸é åçå¯è¡æ§åå¯è½ç§»æ§ãè©ä¼°çµæè¡¨æï¼è©²æ¶æ§ä¸é©åè§£æ±ºè³æéå¨åç­é«å­¸åé¡æé¢è¨çç¨ç¹ææ°ã

##### **Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation**
2411.01647v1 by Zhenbin Wang, Lei Zhang, Lituan Wang, Minjuan Zhu, Zhenwei Zhang

Medical video generation models are expected to have a profound impact on the
healthcare industry, including but not limited to medical education and
training, surgical planning, and simulation. Current video diffusion models
typically build on image diffusion architecture by incorporating temporal
operations (such as 3D convolution and temporal attention). Although this
approach is effective, its oversimplification limits spatio-temporal
performance and consumes substantial computational resources. To counter this,
we propose Medical Simulation Video Generator (MedSora), which incorporates
three key elements: i) a video diffusion framework integrates the advantages of
attention and Mamba, balancing low computational load with high-quality video
generation, ii) an optical flow representation alignment method that implicitly
enhances attention to inter-frame pixels, and iii) a video variational
autoencoder (VAE) with frequency compensation addresses the information loss of
medical features that occurs when transforming pixel space into latent features
and then back to pixel frames. Extensive experiments and applications
demonstrate that MedSora exhibits superior visual quality in generating medical
videos, outperforming the most advanced baseline methods. Further results and
code are available at https://wongzbb.github.io/MedSora

æè¦ï¼é«çå½±ççææ¨¡åé è¨å°å°é«çä¿å¥ç¢æ¥­ç¢çæ·±é çå½±é¿ï¼åæ¬ä½ä¸éæ¼é«å­¸æè²åè¨ç·´ãæè¡è¦ååæ¨¡æ¬ãç®åçå½±çæ´æ£æ¨¡åéå¸¸å»ºç«å¨å½±åæ´æ£æ¶æ§ä¸ï¼ä¸¦çµåæééç®ï¼ä¾å¦ 3D æºç©åæéæ³¨æåï¼ãåç®¡æ­¤æ¹æ³ææï¼ä½å¶éæ¼ç°¡åéå¶äºæç©ºæè½ï¼ä¸¦æ¶èå¤§éçéç®è³æºãçºäºè§£æ±ºéååé¡ï¼æåæåºé«å­¸æ¨¡æ¬å½±ççæå¨ (MedSora)ï¼å®çµåäºä¸åééµè¦ç´ ï¼i) ä¸åå½±çæ´æ£æ¶æ§æ´åäºæ³¨æåå Mamba çåªé»ï¼å¨ä½éç®è² è¼åé«åè³ªå½±ççæä¹éåå¾å¹³è¡¡ï¼ii) ä¸ååæµè¡¨ç¤ºå°é½æ¹æ³ï¼å¯ä»¥é±å«å°å¢å¼·å°å½±æ ¼éåç´ çæ³¨æåï¼ä»¥å iii) ä¸åå·æé »çè£åçå½±çè®ç°èªåç·¨ç¢¼å¨ (VAE)ï¼ç¨æ¼è§£æ±ºå¨å°åç´ ç©ºéè½æçºæ½å¨ç¹å¾µï¼ç¶å¾åè½ååç´ å½±æ ¼æç¼ççé«çç¹å¾µè³è¨éºå¤±åé¡ãå»£æ³çå¯¦é©åæç¨è­æï¼MedSora å¨çæé«çå½±çæ¹é¢å±ç¾åºåªç°çè¦è¦ºåè³ªï¼åªæ¼æåé²çåºæºæ¹æ³ãé²ä¸æ­¥ççµæåç¨å¼ç¢¼å¯ä»¥å¨ https://wongzbb.github.io/MedSora åå¾

##### **Customized Subgraph Selection and Encoding for Drug-drug Interaction Prediction**
2411.01535v1 by Haotong Du, Quanming Yao, Juzheng Zhang, Yang Liu, Zhen Wang

Subgraph-based methods have proven to be effective and interpretable in
predicting drug-drug interactions (DDIs), which are essential for medical
practice and drug development. Subgraph selection and encoding are critical
stages in these methods, yet customizing these components remains underexplored
due to the high cost of manual adjustments. In this study, inspired by the
success of neural architecture search (NAS), we propose a method to search for
data-specific components within subgraph-based frameworks. Specifically, we
introduce extensive subgraph selection and encoding spaces that account for the
diverse contexts of drug interactions in DDI prediction. To address the
challenge of large search spaces and high sampling costs, we design a
relaxation mechanism that uses an approximation strategy to efficiently explore
optimal subgraph configurations. This approach allows for robust exploration of
the search space. Extensive experiments demonstrate the effectiveness and
superiority of the proposed method, with the discovered subgraphs and encoding
functions highlighting the model's adaptability.

æè¦ï¼åºæ¼å­åçæ¹æ³å·²è¢«è­æå¨é æ¸¬è¥ç©-è¥ç©äº¤äºä½ç¨ (DDI) ä¸­ææä¸ææ¼è§£éï¼éå°æ¼é«çå¯¦ååè¥ç©éç¼è³ééè¦ãå­åé¸æåç·¨ç¢¼æ¯éäºæ¹æ³ä¸­çééµéæ®µï¼ç¶èï¼ç±æ¼æåèª¿æ´çææ¬é«æï¼å®¢è£½åéäºåä»¶ä»æªè¢«ååæ¢è¨ãå¨æ¬ç ç©¶ä¸­ï¼åå°ç¥ç¶æ¶æ§æå° (NAS) æååç¼ï¼æåæåºä¸åæ¹æ³ä¾æå°å­åæ¶æ§ä¸­çè³æç¹å®åä»¶ãå·é«ä¾èªªï¼æåå¼å¥äºå»£æ³çå­åé¸æåç·¨ç¢¼ç©ºéï¼ä»¥èªªæ DDI é æ¸¬ä¸­è¥ç©äº¤äºä½ç¨çä¸åèæ¯ãçºäºæå°å¤§åæå°ç©ºéåé«åæ¨£ææ¬çææ°ï¼æåè¨­è¨äºä¸åæ¾é¬æ©å¶ï¼ä½¿ç¨è¿ä¼¼ç­ç¥ä¾æææ¢ç´¢æä½³å­åéç½®ãéç¨®æ¹æ³åè¨±å°æå°ç©ºéé²è¡ç©©å¥çæ¢ç´¢ãå»£æ³çå¯¦é©è­æäºææåºæ¹æ³çæææ§ååªè¶æ§ï¼ç¼ç¾çå­ååç·¨ç¢¼å½æ¸çªé¡¯äºæ¨¡åçé©ææ§ã

##### **Conditional Latent Space Molecular Scaffold Optimization for Accelerated Molecular Design**
2411.01423v1 by Onur Boyar, Hiroyuki Hanada, Ichiro Takeuchi

The rapid discovery of new chemical compounds is essential for advancing
global health and developing treatments. While generative models show promise
in creating novel molecules, challenges remain in ensuring the real-world
applicability of these molecules and finding such molecules efficiently. To
address this, we introduce Conditional Latent Space Molecular Scaffold
Optimization (CLaSMO), which combines a Conditional Variational Autoencoder
(CVAE) with Latent Space Bayesian Optimization (LSBO) to modify molecules
strategically while maintaining similarity to the original input. Our LSBO
setting improves the sample-efficiency of our optimization, and our
modification approach helps us to obtain molecules with higher chances of
real-world applicability. CLaSMO explores substructures of molecules in a
sample-efficient manner by performing BO in the latent space of a CVAE
conditioned on the atomic environment of the molecule to be optimized. Our
experiments demonstrate that CLaSMO efficiently enhances target properties with
minimal substructure modifications, achieving state-of-the-art results with a
smaller model and dataset compared to existing methods. We also provide an
open-source web application that enables chemical experts to apply CLaSMO in a
Human-in-the-Loop setting.

æè¦ï¼æ°åå­¸ååç©çå¿«éç¼ç¾å°æ¼ä¿é²å¨çå¥åº·åéç¼æ²»çæ¹æ³è³ééè¦ãåç®¡çææ¨¡åå¨åµé æ°åå­æ¹é¢é¡¯ç¤ºåºåæ¯ï¼ä½ä»ç¶å­å¨ææ°ï¼ä»¥ç¢ºä¿éäºåå­çå¯¦éé©ç¨æ§ä¸¦ææå°æ¾å°éäºåå­ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºæ¢ä»¶æ½å¨ç©ºéåå­æ¯æ¶æä½³å (CLaSMO)ï¼å®çµåäºæ¢ä»¶è®ç°èªåç·¨ç¢¼å¨ (CVAE) èæ½å¨ç©ºéè²æ°æä½³å (LSBO)ï¼ä»¥ç­ç¥æ§å°ä¿®æ¹åå­ï¼åæä¿æèåå§è¼¸å¥çç¸ä¼¼æ§ãæåç LSBO è¨­å®æ¹åäºæåæä½³åçæ¨£æ¬æçï¼æåçä¿®æ¹æ¹æ³å¹«å©æåç²å¾å·ææ´é«å¯¦éé©ç¨æ©æçåå­ãCLaSMO ä»¥æ¨£æ¬ææçæ¹å¼æ¢ç´¢åå­çå­çµæ§ï¼æ¹æ³æ¯å¨ CVAE çæ½å¨ç©ºéä¸­å·è¡ BOï¼è©²ç©ºéä»¥è¦æä½³åçåå­çåå­ç°å¢çºæ¢ä»¶ãæåçå¯¦é©è¡¨æï¼CLaSMO ä»¥æå°çå­çµæ§ä¿®æ¹ææå°å¢å¼·äºç®æ¨å±¬æ§ï¼èç¾ææ¹æ³ç¸æ¯ï¼ä½¿ç¨è¼å°çæ¨¡ååæ¸æéå¯¦ç¾äºæåé²ççµæãæåéæä¾äºä¸åéæºç¶²è·¯æç¨ç¨å¼ï¼è®åå­¸å°å®¶è½å¤ å¨äººæ©è¿´åè¨­å®ä¸­æç¨ CLaSMOã

##### **Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive Histogram Equalization**
2411.01373v1 by Sohrab Namazi Nia, Frank Y. Shih

In medical imaging, accurate diagnosis heavily relies on effective image
enhancement techniques, particularly for X-ray images. Existing methods often
suffer from various challenges such as sacrificing global image characteristics
over local image characteristics or vice versa. In this paper, we present a
novel approach, called G-CLAHE (Global-Contrast Limited Adaptive Histogram
Equalization), which perfectly suits medical imaging with a focus on X-rays.
This method adapts from Global Histogram Equalization (GHE) and Contrast
Limited Adaptive Histogram Equalization (CLAHE) to take both advantages and
avoid weakness to preserve local and global characteristics. Experimental
results show that it can significantly improve current state-of-the-art
algorithms to effectively address their limitations and enhance the contrast
and quality of X-ray images for diagnostic accuracy.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼æºç¢ºçè¨ºæ·é«åº¦ä¾è³´æ¼ææçå½±åå¢å¼·æè¡ï¼ç¹å¥æ¯ X åå½±åãç¾æçæ¹æ³éå¸¸æéå°åç¨®ææ°ï¼ä¾å¦ç§ç²æ´é«å½±åç¹æ§ä»¥æåå±é¨å½±åç¹æ§ï¼åä¹äº¦ç¶ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨±çº G-CLAHEï¼å¨å±å°æ¯åº¦éå¶èªé©æç´æ¹ååè¡¡åï¼ï¼å®éå¸¸é©åæ¼ä»¥ X åçºéé»çé«å­¸å½±åãæ­¤æ¹æ³æ¹ç·¨èªå¨å±ç´æ¹ååè¡¡å (GHE) åå°æ¯åº¦éå¶èªé©æç´æ¹ååè¡¡å (CLAHE)ï¼ä»¥åå¾å©èçåªé»ï¼ä¸¦é¿åå¼±é»ï¼ä»¥ä¿çå±é¨åå¨å±ç¹æ§ãå¯¦é©çµæè¡¨æï¼å®å¯ä»¥é¡¯èæ¹åç¶åæåé²çæ¼ç®æ³ï¼ä»¥ææè§£æ±ºå¶éå¶ï¼ä¸¦å¢å¼· X åå½±åçå°æ¯åº¦ååè³ªï¼ä»¥å©æ¼è¨ºæ·æºç¢ºæ§ã

##### **Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles**
2411.01351v1 by Tim Ruschke, Jonathan Frederik Carlsen, Adam Espe Hansen, Ulrich Lindberg, Amalie Monberg Hindsholm, Martin Norgaard, Claes NÃ¸hr Ladefoged

Deep learning models in medical contexts face challenges like data scarcity,
inhomogeneity, and privacy concerns. This study focuses on improving
ventricular segmentation in brain MRI images using synthetic data. We employed
two latent diffusion models (LDMs): a mask generator trained using 10,000
masks, and a corresponding SPADE image generator optimized using 6,881 scans to
create an MRI conditioned on a 3D brain mask. Conditioning the mask generator
on ventricular volume in combination with classifier-free guidance enabled the
control of the ventricular volume distribution of the generated synthetic
images. Next, the performance of the synthetic data was tested using three
nnU-Net segmentation models trained on a real, augmented and entirely synthetic
data, respectively. The resulting models were tested on a completely
independent hold-out dataset of patients with enlarged ventricles, with manual
delineation of the ventricles used as ground truth. The model trained on real
data showed a mean absolute error (MAE) of 9.09 \pm 12.18 mL in predicted
ventricular volume, while the models trained on synthetic and augmented data
showed MAEs of 7.52 \pm 4.81 mL and 6.23 \pm 4.33 mL, respectively. Both the
synthetic and augmented model also outperformed the state-of-the-art model
SynthSeg, which due to limited performance in cases of large ventricular
volumes, showed an MAE of 7.73 \pm 12.12 mL with a factor of 3 higher standard
deviation. The model trained on augmented data showed the highest Dice score of
0.892 \pm 0.05, slightly outperforming SynthSeg and on par with the model
trained on real data. The synthetic model performed similar to SynthSeg. In
summary, we provide evidence that guided synthesis of labeled brain MRI data
using LDMs improves the segmentation of enlarged ventricles and outperforms
existing state-of-the-art segmentation models.

æè¦ï¼<paragraph>å¨å»å­¦èæ¯ä¸­ï¼æ·±åº¦å­¦ä¹ æ¨¡åé¢ä¸´çæ°æ®ç¨ç¼ºæ§ãä¸ååæ§åéç§é®é¢ç­ææãæ¬ç ç©¶ä¸æ³¨äºä½¿ç¨åææ°æ®æ¹è¿èé¨ MRI å¾åä¸­çå¿å®¤åå²ãæä»¬éç¨äºä¸¤ä¸ªæ½å¨æ©æ£æ¨¡å (LDM)ï¼ä¸ä¸ªä½¿ç¨ 10,000 ä¸ªèçè®­ç»çèççæå¨ï¼ä»¥åä¸ä¸ªä½¿ç¨ 6,881 æ¬¡æ«æè¿è¡ä¼åçç¸åº SPADE å¾åçæå¨ï¼ä»¥åå»ºåºäº 3D èé¨èçç MRIãå¯¹èççæå¨è¿è¡å¿å®¤ä½ç§¯è°èï¼å¹¶ç»åæ åç±»å¨æå¯¼ï¼è½å¤æ§å¶çæåæå¾åçå¿å®¤ä½ç§¯åå¸ãæ¥ä¸æ¥ï¼ä½¿ç¨åå«è®­ç»äºçå®ãå¢å¼ºåå®å¨åææ°æ®ä¸çä¸ä¸ª nnU-Net åå²æ¨¡åæµè¯äºåææ°æ®çæ§è½ãå°è®­ç»æå¾çæ¨¡åå¨å®å¨ç¬ç«çãå·ææ©å¤§å¿å®¤çæ£èçä¿çæ°æ®éä¸è¿è¡æµè¯ï¼å¹¶ä½¿ç¨å¿å®¤çæå¨æç»ä½ä¸ºçå®æåµãå¨çå®æ°æ®ä¸è®­ç»çæ¨¡åå¨é¢æµçå¿å®¤ä½ç§¯ä¸­æ¾ç¤ºåº 9.09 Â± 12.18 mL çå¹³åç»å¯¹è¯¯å·® (MAE)ï¼èå¨åæåå¢å¼ºæ°æ®ä¸è®­ç»çæ¨¡åæ¾ç¤ºåº 7.52 Â± 4.81 mL å 6.23 Â± 4.33 mL ç MAEãåææ¨¡ååå¢å¼ºæ¨¡åçæ§è½åä¼äºæåè¿çæ¨¡å SynthSegï¼åèç±äºå¨å¤§å¿å®¤ä½ç§¯çæåµä¸æ§è½æéï¼æ¾ç¤ºåº 7.73 Â± 12.12 mL ç MAEï¼æ åå·®é«åº 3 åãå¨å¢å¼ºæ°æ®ä¸è®­ç»çæ¨¡åæ¾ç¤ºåºæé«ç Dice å¾å 0.892 Â± 0.05ï¼ç¥ä¼äº SynthSegï¼å¹¶ä¸ä¸å¨çå®æ°æ®ä¸è®­ç»çæ¨¡åç¸å½ãåææ¨¡åçæ§è½ä¸ SynthSeg ç±»ä¼¼ãæ»ä¹ï¼æä»¬æä¾äºè¯æ®è¡¨æï¼ä½¿ç¨ LDM å¯¹æ è®°çèé¨ MRI æ°æ®è¿è¡å¼å¯¼åæå¯ä»¥æ¹åæ©å¤§å¿å®¤çåå²ï¼å¹¶ä¸ä¼äºç°æçæåè¿çåå²æ¨¡åã</paragraph>

##### **Causal reasoning in difference graphs**
2411.01292v1 by Charles K. Assaad

In epidemiology, understanding causal mechanisms across different populations
is essential for designing effective public health interventions. Recently,
difference graphs have been introduced as a tool to visually represent causal
variations between two distinct populations. While there has been progress in
inferring these graphs from data through causal discovery methods, there
remains a gap in systematically leveraging their potential to enhance causal
reasoning. This paper addresses that gap by establishing conditions for
identifying causal changes and effects using difference graphs and
observational data. It specifically focuses on identifying total causal changes
and total effects in a nonparametric framework, as well as direct causal
changes and direct effects in a linear context. In doing so, it provides a
novel approach to causal reasoning that holds potential for various public
health applications.

æè¦ï¼å¨æµè¡çå­¸ä¸­ï¼äºè§£ä¸åäººç¾¤ä¹éçå ææ©å¶å°æ¼è¨­è¨ææçå¬å±è¡çå¹²é æªæ½è³ééè¦ãæè¿ï¼å·®ç°åè¡¨å·²è¢«å¼å¥ä½çºä¸ç¨®å·¥å·ï¼ç¨æ¼ç´è§å°è¡¨ç¤ºå©åä¸åäººç¾¤ä¹éçå æè®åãåç®¡ééå æç¼ç¾æ¹æ³å¾æ¸æä¸­æ¨æ·éäºåè¡¨æ¹é¢åå¾äºé²å±ï¼ä½å¨ç³»çµ±æ§å°å©ç¨å¶å¢å¼·å ææ¨ççæ½åæ¹é¢ä»ç¶å­å¨å·®è·ãæ¬æééå»ºç«ä½¿ç¨å·®ç°åè¡¨åè§å¯æ¸æè­å¥å æè®ååå æææçæ¢ä»¶ä¾è§£æ±ºéä¸å·®è·ãå®ç¹å¥å´éæ¼å¨éåæ¸æ¡æ¶ä¸­è­å¥ç¸½å æè®ååç¸½ææï¼ä»¥åå¨ç·æ§èæ¯ä¸­è­å¥ç´æ¥å æè®ååç´æ¥ææãéæ¨£ä¸ä¾ï¼å®æä¾äºä¸ç¨®å ææ¨ççæ°æ¹æ³ï¼å°åç¨®å¬å±è¡çæç¨å·ææ½åã

##### **Designing a Robust Radiology Report Generation System**
2411.01153v1 by Sonit Singh

Recent advances in deep learning have enabled researchers to explore tasks at
the intersection of computer vision and natural language processing, such as
image captioning, visual question answering, visual dialogue, and visual
language navigation. Taking inspiration from image captioning, the task of
radiology report generation aims at automatically generating radiology reports
by having a comprehensive understanding of medical images. However,
automatically generating radiology reports from medical images is a challenging
task due to the complexity, diversity, and nature of medical images. In this
paper, we outline the design of a robust radiology report generation system by
integrating different modules and highlighting best practices drawing upon
lessons from our past work and also from relevant studies in the literature. We
also discuss the impact of integrating different components to form a single
integrated system. We believe that these best practices, when implemented,
could improve automatic radiology report generation, augment radiologists in
decision making, and expedite diagnostic workflow, in turn improve healthcare
and save human lives.

æè¦ï¼æè¿æ·±åº¦å­¸ç¿çé²å±ä½¿ç ç©¶äººå¡è½å¤ æ¢ç´¢é»è¦è¦è¦ºåèªç¶èªè¨èçäº¤éä¸­çä»»åï¼ä¾å¦å½±åæ¨é¡ãè¦è¦ºåç­ãè¦è¦ºå°è©±åè¦è¦ºèªè¨å°èªãåå½±åæ¨é¡çåç¼ï¼æ¾å°ç§å ±åçæçä»»åæ¨å¨ééå¨é¢äºè§£é«å­¸å½±åèªåçææ¾å°ç§å ±åãç¶èï¼ç±æ¼é«å­¸å½±åçè¤éæ§ãå¤æ¨£æ§åæ§è³ªï¼èªåå¾é«å­¸å½±åçææ¾å°ç§å ±åæ¯ä¸é å·æææ°æ§çä»»åãå¨æ¬æä¸­ï¼æåééæ´åä¸åçæ¨¡çµä¸¦å¼·èª¿æä½³å¯¦åï¼æ¦è¿°äºå¥å¨çæ¾å°ç§å ±åçæç³»çµ±çè¨­è¨ï¼éäºå¯¦åæ±²åèªæåéå»çå·¥ä½ä»¥åæç»ä¸­çç¸éç ç©¶ãæåä¹è¨è«äºæ´åä¸åçµä»¶ä»¥å½¢æå®ä¸æ´åç³»çµ±çå½±é¿ãæåç¸ä¿¡ï¼éäºæä½³å¯¦åå¨å¯¦æ½å¾ï¼å¯ä»¥æ¹åèªåæ¾å°ç§å ±åçæï¼å¢å¼·æ¾å°ç§é«å¸«å¨æ±ºç­å¶å®ä¸­çè½åï¼ä¸¦å å¿«è¨ºæ·å·¥ä½æµç¨ï¼é²èæ¹åé«çä¿å¥ä¸¦æ¯æäººå½ã


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-15**|**VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**|Daniel Ekpo et.al.|[2411.10446v1](http://arxiv.org/abs/2411.10446v1)|null|
|**2024-11-15**|**Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization**|Weiyun Wang et.al.|[2411.10442v1](http://arxiv.org/abs/2411.10442v1)|null|
|**2024-11-15**|**Mitigating Hallucination in Multimodal Large Language Model via Hallucination-targeted Direct Preference Optimization**|Yuhan Fu et.al.|[2411.10436v1](http://arxiv.org/abs/2411.10436v1)|null|
|**2024-11-15**|**Mitigating Parameter Degeneracy using Joint Conditional Diffusion Model for WECC Composite Load Model in Power Systems**|Feiqin Zhu et.al.|[2411.10431v1](http://arxiv.org/abs/2411.10431v1)|null|
|**2024-11-15**|**Evaluating Creativity and Deception in Large Language Models: A Simulation Framework for Multi-Agent Balderdash**|Parsa Hejabi et.al.|[2411.10422v1](http://arxiv.org/abs/2411.10422v1)|[link](https://github.com/parsahejabi/simulation-framework-for-multi-agent-balderdash)|
|**2024-11-15**|**Llama Guard 3 Vision: Safeguarding Human-AI Image Understanding Conversations**|Jianfeng Chi et.al.|[2411.10414v1](http://arxiv.org/abs/2411.10414v1)|null|
|**2024-11-15**|**Repurposing Stable Diffusion Attention for Training-Free Unsupervised Interactive Segmentation**|Markus Karmann et.al.|[2411.10411v1](http://arxiv.org/abs/2411.10411v1)|null|
|**2024-11-15**|**Features that Make a Difference: Leveraging Gradients for Improved Dictionary Learning**|Jeffrey Olmo et.al.|[2411.10397v1](http://arxiv.org/abs/2411.10397v1)|null|
|**2024-11-15**|**Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization**|Fatahlla Moreh et.al.|[2411.10389v1](http://arxiv.org/abs/2411.10389v1)|null|
|**2024-11-15**|**Low-Latency Task-Oriented Communications with Multi-Round, Multi-Task Deep Learning**|Yalin E. Sagduyu et.al.|[2411.10385v1](http://arxiv.org/abs/2411.10385v1)|null|
|**2024-11-15**|**A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**|Zefan Zeng et.al.|[2411.10371v1](http://arxiv.org/abs/2411.10371v1)|null|
|**2024-11-15**|**Towards High-Fidelity 3D Portrait Generation with Rich Details by Cross-View Prior-Aware Diffusion**|Haoran Wei et.al.|[2411.10369v1](http://arxiv.org/abs/2411.10369v1)|null|
|**2024-11-15**|**Mechanisms of Generative Image-to-Image Translation Networks**|Guangzong Chen et.al.|[2411.10368v1](http://arxiv.org/abs/2411.10368v1)|null|
|**2024-11-15**|**Domain Adaptation-based Edge Computing for Cross-Conditions Fault Diagnosis**|Yanzhi Wang et.al.|[2411.10340v1](http://arxiv.org/abs/2411.10340v1)|null|
|**2024-11-15**|**Safe Text-to-Image Generation: Simply Sanitize the Prompt Embedding**|Huming Qiu et.al.|[2411.10329v1](http://arxiv.org/abs/2411.10329v1)|null|
|**2024-11-15**|**Emotion Detection in Reddit: Comparative Study of Machine Learning and Deep Learning Techniques**|Maliheh Alaeddini et.al.|[2411.10328v1](http://arxiv.org/abs/2411.10328v1)|null|
|**2024-11-15**|**The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use**|Siyuan Hu et.al.|[2411.10323v1](http://arxiv.org/abs/2411.10323v1)|[link](https://github.com/showlab/computer_use_ootb)|
|**2024-11-15**|**Unveiling Topological Structures in Text: A Comprehensive Survey of Topological Data Analysis Applications in NLP**|Adaku Uchendu et.al.|[2411.10298v1](http://arxiv.org/abs/2411.10298v1)|null|
|**2024-11-15**|**Scaling Law for Post-training after Model Pruning**|Xiaodong Chen et.al.|[2411.10272v1](http://arxiv.org/abs/2411.10272v1)|null|
|**2024-11-15**|**The Unreasonable Effectiveness of Guidance for Diffusion Models**|Tim Kaiser et.al.|[2411.10257v1](http://arxiv.org/abs/2411.10257v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-15**|**Scaling up the Evaluation of Collaborative Problem Solving: Promises and Challenges of Coding Chat Data with ChatGPT**|Jiangang Hao et.al.|[2411.10246v1](http://arxiv.org/abs/2411.10246v1)|null|
|**2024-11-15**|**Measuring Non-Adversarial Reproduction of Training Data in Large Language Models**|Michael Aerni et.al.|[2411.10242v1](http://arxiv.org/abs/2411.10242v1)|null|
|**2024-11-15**|**Generative AI in Multimodal User Interfaces: Trends, Challenges, and Cross-Platform Adaptability**|J. Bieniek et.al.|[2411.10234v1](http://arxiv.org/abs/2411.10234v1)|null|
|**2024-11-15**|**ColorEdit: Training-free Image-Guided Color editing with diffusion model**|Xingxi Yin et.al.|[2411.10232v1](http://arxiv.org/abs/2411.10232v1)|null|
|**2024-11-15**|**A Low-Resolution Image is Worth 1x1 Words: Enabling Fine Image Super-Resolution with Transformers and TaylorShift**|Sanath Budakegowdanadoddi Nagaraju et.al.|[2411.10231v1](http://arxiv.org/abs/2411.10231v1)|null|
|**2024-11-15**|**Entropy and type-token ratio in gigaword corpora**|Pablo Rosillo-Rodes et.al.|[2411.10227v1](http://arxiv.org/abs/2411.10227v1)|null|
|**2024-11-15**|**An Empirical Study on LLM-based Agents for Automated Bug Fixing**|Xiangxin Meng et.al.|[2411.10213v1](http://arxiv.org/abs/2411.10213v1)|null|
|**2024-11-15**|**FengWu-W2S: A deep learning model for seamless weather-to-subseasonal forecast of global atmosphere**|Fenghua Ling et.al.|[2411.10191v1](http://arxiv.org/abs/2411.10191v1)|null|
|**2024-11-15**|**Agentic LLMs in the Supply Chain: Towards Autonomous Multi-Agent Consensus-Seeking**|Valeria Jannelli et.al.|[2411.10184v1](http://arxiv.org/abs/2411.10184v1)|null|
|**2024-11-15**|**The Surprising Ineffectiveness of Pre-Trained Visual Representations for Model-Based Reinforcement Learning**|Moritz Schneider et.al.|[2411.10175v1](http://arxiv.org/abs/2411.10175v1)|null|
|**2024-11-15**|**A Hard-Label Cryptanalytic Extraction of Non-Fully Connected Deep Neural Networks using Side-Channel Attacks**|Benoit Coqueret et.al.|[2411.10174v1](http://arxiv.org/abs/2411.10174v1)|null|
|**2024-11-15**|**Increasing the Accessibility of Causal Domain Knowledge via Causal Information Extraction Methods: A Case Study in the Semiconductor Manufacturing Industry**|Houssam Razouk et.al.|[2411.10172v1](http://arxiv.org/abs/2411.10172v1)|null|
|**2024-11-15**|**Imagine-2-Drive: High-Fidelity World Modeling in CARLA for Autonomous Vehicles**|Anant Garg et.al.|[2411.10171v1](http://arxiv.org/abs/2411.10171v1)|null|
|**2024-11-15**|**Evaluating the role of `Constitutions' for learning from AI feedback**|Saskia Redgate et.al.|[2411.10168v1](http://arxiv.org/abs/2411.10168v1)|null|
|**2024-11-15**|**Compound-QA: A Benchmark for Evaluating LLMs on Compound Questions**|Yutao Hou et.al.|[2411.10163v1](http://arxiv.org/abs/2411.10163v1)|null|
|**2024-11-15**|**Mitigating Sycophancy in Decoder-Only Transformer Architectures: Synthetic Data Intervention**|Libo Wang et.al.|[2411.10156v1](http://arxiv.org/abs/2411.10156v1)|[link](https://github.com/brucewang123456789/GeniusTrail)|
|**2024-11-15**|**Causal Time-Series Synchronization for Multi-Dimensional Forecasting**|Michael Mayr et.al.|[2411.10152v1](http://arxiv.org/abs/2411.10152v1)|null|
|**2024-11-15**|**An Effective Framework to Help Large Language Models Handle Numeric-involved Long-context Tasks**|Yijiong Yu et.al.|[2411.10145v1](http://arxiv.org/abs/2411.10145v1)|null|
|**2024-11-15**|**Legal Evalutions and Challenges of Large Language Models**|Jiaqi Wang et.al.|[2411.10137v1](http://arxiv.org/abs/2411.10137v1)|null|
|**2024-11-15**|**Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**|Md. Asif Haider et.al.|[2411.10129v1](http://arxiv.org/abs/2411.10129v1)|null|
|**2024-11-15**|**Memorization in Attention-only Transformers**|LÃ©o Dana et.al.|[2411.10115v1](http://arxiv.org/abs/2411.10115v1)|null|
|**2024-11-15**|**Generative Agent Simulations of 1,000 People**|Joon Sung Park et.al.|[2411.10109v1](http://arxiv.org/abs/2411.10109v1)|null|
|**2024-11-15**|**Identifying Key Drivers of Heatwaves: A Novel Spatio-Temporal Framework for Extreme Event Detection**|J. PÃ©rez-Aracil et.al.|[2411.10108v1](http://arxiv.org/abs/2411.10108v1)|null|
|**2024-11-15**|**Multi-Task Adversarial Variational Autoencoder for Estimating Biological Brain Age with Multimodal Neuroimaging**|Muhammad Usman et.al.|[2411.10100v1](http://arxiv.org/abs/2411.10100v1)|null|
|**2024-11-15**|**PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse**|Einari Vaaras et.al.|[2411.10087v1](http://arxiv.org/abs/2411.10087v1)|null|
|**2024-11-15**|**Adapting the Biological SSVEP Response to Artificial Neural Networks**|Emirhan BÃ¶ge et.al.|[2411.10084v1](http://arxiv.org/abs/2411.10084v1)|null|
|**2024-11-15**|**Xmodel-1.5: An 1B-scale Multilingual LLM**|Wang Qun et.al.|[2411.10083v1](http://arxiv.org/abs/2411.10083v1)|[link](https://github.com/xiaoduoailab/xmodellm)|
|**2024-11-15**|**Understanding The Effect Of Temperature On Alignment With Human Opinions**|Maja Pavlovic et.al.|[2411.10080v1](http://arxiv.org/abs/2411.10080v1)|null|
|**2024-11-15**|**Real-Time AI-Driven People Tracking and Counting Using Overhead Cameras**|Ishrath Ahamed et.al.|[2411.10072v1](http://arxiv.org/abs/2411.10072v1)|null|
|**2024-11-15**|**Evidential Federated Learning for Skin Lesion Image Classification**|Rutger Hendrix et.al.|[2411.10071v1](http://arxiv.org/abs/2411.10071v1)|null|
|**2024-11-15**|**Layer Importance and Hallucination Analysis in Large Language Models via Enhanced Activation Variance-Sparsity**|Zichen Song et.al.|[2411.10069v1](http://arxiv.org/abs/2411.10069v1)|null|
|**2024-11-15**|**Federated Domain Generalization via Prompt Learning and Aggregation**|Shuai Gong et.al.|[2411.10063v1](http://arxiv.org/abs/2411.10063v1)|[link](https://github.com/GongShuai8210/PLAN)|
|**2024-11-15**|**CMATH: Cross-Modality Augmented Transformer with Hierarchical Variational Distillation for Multimodal Emotion Recognition in Conversation**|Xiaofei Zhu et.al.|[2411.10060v1](http://arxiv.org/abs/2411.10060v1)|null|
|**2024-11-15**|**KuaiFormer: Transformer-Based Retrieval at Kuaishou**|Chi Liu et.al.|[2411.10057v1](http://arxiv.org/abs/2411.10057v1)|null|
|**2024-11-15**|**Towards unearthing neglected climate innovations from scientific literature using Large Language Models**|CÃ©sar QuilodrÃ¡n-Casas et.al.|[2411.10055v1](http://arxiv.org/abs/2411.10055v1)|null|
|**2024-11-15**|**Jal Anveshak: Prediction of fishing zones using fine-tuned LlaMa 2**|Arnav Mejari et.al.|[2411.10050v1](http://arxiv.org/abs/2411.10050v1)|null|
|**2024-11-15**|**VMID: A Multimodal Fusion LLM Framework for Detecting and Identifying Misinformation of Short Videos**|Weihao Zhong et.al.|[2411.10032v1](http://arxiv.org/abs/2411.10032v1)|null|
|**2024-11-15**|**MOT\_FCG++: Enhanced Representation of Motion and Appearance Features**|Yanzhao Fang et.al.|[2411.10028v1](http://arxiv.org/abs/2411.10028v1)|null|
|**2024-11-15**|**Information Extraction from Clinical Notes: Are We Ready to Switch to Large Language Models?**|Yan Hu et.al.|[2411.10020v1](http://arxiv.org/abs/2411.10020v1)|null|
|**2024-11-15**|**Once More, With Feeling: Measuring Emotion of Acting Performances in Contemporary American Film**|Naitian Zhou et.al.|[2411.10018v1](http://arxiv.org/abs/2411.10018v1)|null|
|**2024-11-15**|**MicroCrackAttentionNeXt: Advancing Microcrack Detection in Wave Field Analysis Using Deep Neural Networks through Feature Visualization**|Fatahlla Moreh et.al.|[2411.10015v1](http://arxiv.org/abs/2411.10015v1)|null|
|**2024-11-15**|**DeepMedcast: A Deep Learning Method for Generating Intermediate Weather Forecasts among Multiple NWP Models**|Atsushi Kudo et.al.|[2411.10010v1](http://arxiv.org/abs/2411.10010v1)|null|
|**2024-11-15**|**Graph-based Complexity for Causal Effect by Empirical Plug-in**|Rina Dechter et.al.|[2411.10008v1](http://arxiv.org/abs/2411.10008v1)|null|
|**2024-11-15**|**Orca: Enhancing Role-Playing Abilities of Large Language Models by Integrating Personality Traits**|Yuxuan Huang et.al.|[2411.10006v1](http://arxiv.org/abs/2411.10006v1)|null|
|**2024-11-15**|**EyeDiff: text-to-image diffusion model improves rare eye disease diagnosis**|Ruoyu Chen et.al.|[2411.10004v1](http://arxiv.org/abs/2411.10004v1)|null|
|**2024-11-15**|**DuSEGO: Dual Second-order Equivariant Graph Ordinary Differential Equation**|Yingxu Wang et.al.|[2411.10000v1](http://arxiv.org/abs/2411.10000v1)|null|
|**2024-11-15**|**Building 6G Radio Foundation Models with Transformer Architectures**|Ahmed Aboulfotouh et.al.|[2411.09996v1](http://arxiv.org/abs/2411.09996v1)|null|
|**2024-11-15**|**Unlocking Transfer Learning for Open-World Few-Shot Recognition**|Byeonggeun Kim et.al.|[2411.09986v1](http://arxiv.org/abs/2411.09986v1)|null|
|**2024-11-15**|**HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**|Yifan Zeng et.al.|[2411.09978v1](http://arxiv.org/abs/2411.09978v1)|null|
|**2024-11-15**|**Large Language Models as User-Agents for Evaluating Task-Oriented-Dialogue Systems**|Taaha Kazi et.al.|[2411.09972v1](http://arxiv.org/abs/2411.09972v1)|null|
|**2024-11-15**|**Steering AI-Driven Personalization of Scientific Text for General Audiences**|Taewook Kim et.al.|[2411.09969v1](http://arxiv.org/abs/2411.09969v1)|null|
|**2024-11-15**|**Seeing Clearly by Layer Two: Enhancing Attention Heads to Alleviate Hallucination in LVLMs**|Xiaofeng Zhang et.al.|[2411.09968v1](http://arxiv.org/abs/2411.09968v1)|null|
|**2024-11-15**|**Instruction-Guided Editing Controls for Images and Multimedia: A Survey in LLM era**|Thanh Tam Nguyen et.al.|[2411.09955v1](http://arxiv.org/abs/2411.09955v1)|null|
|**2024-11-15**|**GGAvatar: Reconstructing Garment-Separated 3D Gaussian Splatting Avatars from Monocular Video**|Jingxuan Chen et.al.|[2411.09952v1](http://arxiv.org/abs/2411.09952v1)|[link](https://github.com/j-x-chen/ggavatar)|
|**2024-11-15**|**LoRA-LiteE: A Computationally Efficient Framework for Chatbot Preference-Tuning**|Yahe Yang et.al.|[2411.09947v1](http://arxiv.org/abs/2411.09947v1)|null|
|**2024-11-15**|**TEESlice: Protecting Sensitive Neural Network Models in Trusted Execution Environments When Attackers have Pre-Trained Models**|Ding Li et.al.|[2411.09945v1](http://arxiv.org/abs/2411.09945v1)|null|
|**2024-11-15**|**SlimLM: An Efficient Small Language Model for On-Device Document Assistance**|Thang M. Pham et.al.|[2411.09944v1](http://arxiv.org/abs/2411.09944v1)|null|
|**2024-11-15**|**Refined and Segmented Price Sentiment Indices from Survey Comments**|Masahiro Suzuki et.al.|[2411.09937v1](http://arxiv.org/abs/2411.09937v1)|null|
|**2024-11-15**|**JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging**|Kaito Baba et.al.|[2411.09933v1](http://arxiv.org/abs/2411.09933v1)|null|
|**2024-11-15**|**Motion-Grounded Video Reasoning: Understanding and Perceiving Motion at Pixel Level**|Andong Deng et.al.|[2411.09921v1](http://arxiv.org/abs/2411.09921v1)|null|
|**2024-11-15**|**AMXFP4: Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference**|Janghwan Lee et.al.|[2411.09909v1](http://arxiv.org/abs/2411.09909v1)|null|
|**2024-11-15**|**Statistical Analysis of Policy Space Compression Problem**|Majid Molaei et.al.|[2411.09900v1](http://arxiv.org/abs/2411.09900v1)|null|
|**2024-11-15**|**Research on Domain-Specific Chinese Spelling Correction Method Based on Plugin Extension Modules**|Xiaowu Zhang et.al.|[2411.09884v1](http://arxiv.org/abs/2411.09884v1)|null|
|**2024-11-15**|**A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation**|Chin-Sung Tung et.al.|[2411.09874v1](http://arxiv.org/abs/2411.09874v1)|[link](https://github.com/tcs211/ai_eeeg_report)|
|**2024-11-15**|**Enhancing Diffusion Posterior Sampling for Inverse Problems by Integrating Crafted Measurements**|Shijie Zhou et.al.|[2411.09850v1](http://arxiv.org/abs/2411.09850v1)|null|
|**2024-11-14**|**Self-Supervised Radio Pre-training: Toward Foundational Models for Spectrogram Learning**|Ahmed Aboulfotouh et.al.|[2411.09849v1](http://arxiv.org/abs/2411.09849v1)|null|
|**2024-11-14**|**Deep Autoencoders for Unsupervised Anomaly Detection in Wildfire Prediction**|Ä°rem Ãstek et.al.|[2411.09844v1](http://arxiv.org/abs/2411.09844v1)|null|
|**2024-11-14**|**Real-time Adapting Routing (RAR): Improving Efficiency Through Continuous Learning in Software Powered by Layered Foundation Models**|Kirill Vasilevski et.al.|[2411.09837v1](http://arxiv.org/abs/2411.09837v1)|null|
|**2024-11-14**|**A Benchmark for Long-Form Medical Question Answering**|Pedram Hosseini et.al.|[2411.09834v1](http://arxiv.org/abs/2411.09834v1)|[link](https://github.com/lavita-ai/medical-eval-sphere)|
|**2024-11-14**|**Evaluating Gender Bias in Large Language Models**|Michael DÃ¶ll et.al.|[2411.09826v1](http://arxiv.org/abs/2411.09826v1)|null|
|**2024-11-14**|**A Self-Supervised Model for Multi-modal Stroke Risk Prediction**|Camille Delgrange et.al.|[2411.09822v1](http://arxiv.org/abs/2411.09822v1)|null|
|**2024-11-14**|**WelQrate: Defining the Gold Standard in Small Molecule Drug Discovery Benchmarking**|Yunchao et.al.|[2411.09820v1](http://arxiv.org/abs/2411.09820v1)|null|
|**2024-11-14**|**Evaluating Loss Landscapes from a Topology Perspective**|Tiankai Xie et.al.|[2411.09807v1](http://arxiv.org/abs/2411.09807v1)|null|
|**2024-11-14**|**Deep Learning for Fetal Inflammatory Response Diagnosis in the Umbilical Cord**|Marina A. Ayad et.al.|[2411.09767v1](http://arxiv.org/abs/2411.09767v1)|null|
|**2024-11-14**|**Evaluating the Predictive Capacity of ChatGPT for Academic Peer Review Outcomes Across Multiple Platforms**|Mike Thelwall et.al.|[2411.09763v1](http://arxiv.org/abs/2411.09763v1)|null|
|**2024-11-14**|**On the Surprising Effectiveness of Attention Transfer for Vision Transformers**|Alexander C. Li et.al.|[2411.09702v1](http://arxiv.org/abs/2411.09702v1)|null|
|**2024-11-14**|**A Bayesian Optimization Approach to Machine Translation Reranking**|Julius Cheng et.al.|[2411.09694v1](http://arxiv.org/abs/2411.09694v1)|null|
|**2024-11-14**|**LLM Hallucination Reasoning with Zero-shot Knowledge Test**|Seongmin Lee et.al.|[2411.09689v1](http://arxiv.org/abs/2411.09689v1)|null|
|**2024-11-14**|**Squeezed Attention: Accelerating Long Context Length LLM Inference**|Coleman Hooper et.al.|[2411.09688v1](http://arxiv.org/abs/2411.09688v1)|null|

#### Abstracts
##### **VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**
2411.10446v1 by Daniel Ekpo, Mara Levy, Saksham Suri, Chuong Huynh, Abhinav Shrivastava

Recent advancements in vision-language models (VLMs) offer potential for
robot task planning, but challenges remain due to VLMs' tendency to generate
incorrect action sequences. To address these limitations, we propose VeriGraph,
a novel framework that integrates VLMs for robotic planning while verifying
action feasibility. VeriGraph employs scene graphs as an intermediate
representation, capturing key objects and spatial relationships to improve plan
verification and refinement. The system generates a scene graph from input
images and uses it to iteratively check and correct action sequences generated
by an LLM-based task planner, ensuring constraints are respected and actions
are executable. Our approach significantly enhances task completion rates
across diverse manipulation scenarios, outperforming baseline methods by 58%
for language-based tasks and 30% for image-based tasks.

æè¦ï¼æè¿å¨è¦è¦ºèªè¨æ¨¡å (VLM) çé²æ­¥çºæ©å¨äººä»»åè¦åæä¾äºå¯è½æ§ï¼ä½ç±æ¼ VLM å®¹æç¢çä¸æ­£ç¢ºçåä½åºåï¼å æ­¤ææ°ä»ç¶å­å¨ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº VeriGraphï¼ä¸åå° VLM æ´åå°æ©å¨äººè¦åä¸­çåµæ°æ¶æ§ï¼åæé©è­åä½çå¯è¡æ§ãVeriGraph ä½¿ç¨å ´æ¯åä½çºä¸­éè¡¨ç¤ºï¼ææééµç©ä»¶åç©ºééä¿ä»¥æ¹åè¨ç«é©è­åç²¾çãè©²ç³»çµ±å¾è¼¸å¥å½±åç¢çå ´æ¯åï¼ä¸¦ä½¿ç¨å®ä¾åè¦æª¢æ¥åä¿®æ­£ LLM åºæ¼ä»»åè¦åå¨ç¢ççåä½åºåï¼ç¢ºä¿ç¬¦åç´ææ¢ä»¶ä¸åä½å¯å·è¡ãæåçåæ³å¤§å¹æåäºåç¨®æä½å ´æ¯ä¸­çä»»åå®æçï¼å¨åºæ¼èªè¨çä»»åä¸­æ¯åºç·æ¹æ³é«åº 58%ï¼å¨åºæ¼å½±åçä»»åä¸­é«åº 30%ã

##### **Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization**
2411.10442v1 by Weiyun Wang, Zhe Chen, Wenhai Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao, Jinguo Zhu, Xizhou Zhu, Lewei Lu, Yu Qiao, Jifeng Dai

Existing open-source multimodal large language models (MLLMs) generally
follow a training process involving pre-training and supervised fine-tuning.
However, these models suffer from distribution shifts, which limit their
multimodal reasoning, particularly in the Chain-of-Thought (CoT) performance.
To address this, we introduce a preference optimization (PO) process to enhance
the multimodal reasoning capabilities of MLLMs. Specifically, (1) on the data
side, we design an automated preference data construction pipeline to create
MMPR, a high-quality, large-scale multimodal reasoning preference dataset. and
(2) on the model side, we explore integrating PO with MLLMs, developing a
simple yet effective method, termed Mixed Preference Optimization (MPO), which
boosts multimodal CoT performance. Our approach demonstrates improved
performance across multiple benchmarks, particularly in multimodal reasoning
tasks. Notably, our model, InternVL2-8B-MPO, achieves an accuracy of 67.0 on
MathVista, outperforming InternVL2-8B by 8.7 points and achieving performance
comparable to the 10x larger InternVL2-76B. We hope this study could inspire
further advancements in MLLMs. Code, data, and model shall be publicly
released.

æè¦ï¼ç¾æçéæºå¤æ¨¡æå¤§åèªè¨æ¨¡å (MMLM) éå¸¸éµå¾ªä¸ååå«é è¨ç·´åç£ç£å¾®èª¿çè¨ç·´æµç¨ãç¶èï¼éäºæ¨¡åæåå°åä½è½ç§»çå½±é¿ï¼éæéå¶å®åçå¤æ¨¡ææ¨çï¼ç¹å¥æ¯å¨æèé (CoT) æè½æ¹é¢ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºä¸ååå¥½æä½³å (PO) æµç¨ä¾å¢å¼· MMLM çå¤æ¨¡ææ¨çè½åãå·é«ä¾èªªï¼(1) å¨è³ææ¹é¢ï¼æåè¨­è¨äºä¸åèªåååå¥½è³æå»ºæ§ç®¡ç·ä¾å»ºç« MMPRï¼ä¸åé«åè³ªãå¤§è¦æ¨¡çå¤æ¨¡ææ¨çåå¥½è³æéãä»¥å (2) å¨æ¨¡åæ¹é¢ï¼æåæ¢ç´¢å° PO è MLLM æ´åï¼éç¼ä¸ç¨®ç°¡å®ä½ææçæ¹æ³ï¼ç¨±çºæ··ååå¥½æä½³å (MPO)ï¼å®å¯ä»¥æåå¤æ¨¡æ CoT æè½ãæåçåæ³è­æäºå¨å¤ååºæºæ¸¬è©¦ä¸­é½ææ¹é²çæè½ï¼ç¹å¥æ¯å¨å¤æ¨¡ææ¨çä»»åä¸­ãå¼å¾æ³¨æçæ¯ï¼æåçæ¨¡å InternVL2-8B-MPO å¨ MathVista ä¸éå°äº 67.0 çæºç¢ºåº¦ï¼æ¯ InternVL2-8B é«åº 8.7 åç¾åé»ï¼ä¸¦éå°äºèå¤§ 10 åç InternVL2-76B ç¸ç¶çæè½ãæåå¸æéé ç ç©¶è½æ¿åµ MLLM çé²ä¸æ­¥ç¼å±ãç¨å¼ç¢¼ãè³æåæ¨¡åå°å¬éç¼å¸ã

##### **Mitigating Hallucination in Multimodal Large Language Model via Hallucination-targeted Direct Preference Optimization**
2411.10436v1 by Yuhan Fu, Ruobing Xie, Xingwu Sun, Zhanhui Kang, Xirong Li

Multimodal Large Language Models (MLLMs) are known to hallucinate, which
limits their practical applications. Recent works have attempted to apply
Direct Preference Optimization (DPO) to enhance the performance of MLLMs, but
have shown inconsistent improvements in mitigating hallucinations. To address
this issue more effectively, we introduce Hallucination-targeted Direct
Preference Optimization (HDPO) to reduce hallucinations in MLLMs. Unlike
previous approaches, our method tackles hallucinations from their diverse forms
and causes. Specifically, we develop three types of preference pair data
targeting the following causes of MLLM hallucinations: (1) insufficient visual
capabilities, (2) long context generation, and (3) multimodal conflicts.
Experimental results demonstrate that our method achieves superior performance
across multiple hallucination evaluation datasets, surpassing most
state-of-the-art (SOTA) methods and highlighting the potential of our approach.
Ablation studies and in-depth analyses further confirm the effectiveness of our
method and suggest the potential for further improvements through scaling up.

æè¦ï¼å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) ä¼åºç°å¹»è§ï¼è¿éå¶äºå®ä»¬çå®éåºç¨ãæè¿çç ç©¶å°è¯åºç¨ç´æ¥åå¥½ä¼å (DPO) æ¥å¢å¼º MLLM çæ§è½ï¼ä½å¨åè½»å¹»è§æ¹é¢è¡¨ç°å¹¶ä¸ä¸è´ãä¸ºäºæ´ææå°è§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äºå¹»è§ç®æ ç´æ¥åå¥½ä¼å (HDPO) æ¥åå° MLLM ä¸­çå¹»è§ãä¸ä»¥åçæ¹æ³ä¸åï¼æä»¬çæ¹æ³ä»å¶ä¸åçå½¢å¼ååå æ¥è§£å³å¹»è§ãå·ä½æ¥è¯´ï¼æä»¬éå¯¹ä»¥ä¸ MLLM å¹»è§åå å¼åäºä¸ç§ç±»åçåå¥½å¯¹æ°æ®ï¼(1) è§è§è½åä¸è¶³ï¼(2) é¿ä¸ä¸æçæï¼ä»¥å (3) å¤æ¨¡æå²çªãå®éªç»æè¡¨æï¼æä»¬çæ¹æ³å¨å¤ä¸ªå¹»è§è¯ä¼°æ°æ®éä¸å®ç°äºåè¶çæ§è½ï¼è¶è¶äºå¤§å¤æ°æåè¿ (SOTA) æ¹æ³ï¼å¹¶çªåºäºæä»¬æ¹æ³çæ½åãæ¶èç ç©¶åæ·±å¥åæè¿ä¸æ­¥è¯å®äºæä»¬æ¹æ³çæææ§ï¼å¹¶è¡¨æéè¿æ©å±å¯ä»¥è¿ä¸æ­¥æ¹è¿ã

##### **Mitigating Parameter Degeneracy using Joint Conditional Diffusion Model for WECC Composite Load Model in Power Systems**
2411.10431v1 by Feiqin Zhu, Dmitrii Torbunov, Yihui Ren, Zhongjing Jiang, Tianqiao Zhao, Amirthagunaraj Yogarathnam, Meng Yue

Data-driven modeling for dynamic systems has gained widespread attention in
recent years. Its inverse formulation, parameter estimation, aims to infer the
inherent model parameters from observations. However, parameter degeneracy,
where different combinations of parameters yield the same observable output,
poses a critical barrier to accurately and uniquely identifying model
parameters. In the context of WECC composite load model (CLM) in power systems,
utility practitioners have observed that CLM parameters carefully selected for
one fault event may not perform satisfactorily in another fault. Here, we
innovate a joint conditional diffusion model-based inverse problem solver
(JCDI), that incorporates a joint conditioning architecture with simultaneous
inputs of multi-event observations to improve parameter generalizability.
Simulation studies on the WECC CLM show that the proposed JCDI effectively
reduces uncertainties of degenerate parameters, thus the parameter estimation
error is decreased by 42.1% compared to a single-event learning scheme. This
enables the model to achieve high accuracy in predicting power trajectories
under different fault events, including electronic load tripping and motor
stalling, outperforming standard deep reinforcement learning and supervised
learning approaches. We anticipate this work will contribute to mitigating
parameter degeneracy in system dynamics, providing a general parameter
estimation framework across various scientific domains.

æè¦ï¼<paragraph>è¿å¹´æ¥ï¼æ°æ®é©±å¨å»ºæ¨¡å¨å¨æç³»ç»ä¸­è·å¾äºå¹¿æ³çå³æ³¨ãå¶éåå¬å¼ï¼åæ°ä¼°è®¡ï¼æ¨å¨ä»è§æµä¸­æ¨æ­åºåºæçæ¨¡ååæ°ãç¶èï¼åæ°éåï¼å¶ä¸­ä¸åç»åçåæ°äº§çç¸åçå¯è§å¯è¾åºï¼å¯¹åç¡®åå¯ä¸å°è¯å«æ¨¡ååæ°ææäºä¸ä¸ªå³é®éç¢ãå¨çµåç³»ç»ä¸­ WECC å¤åè´è½½æ¨¡å (CLM) çèæ¯ä¸ï¼çµåä»ä¸èè§å¯å°ï¼ä¸ºä¸ä¸ªæéäºä»¶ç²¾å¿éæ©ç CLM åæ°å¯è½æ æ³å¨å¦ä¸ä¸ªæéä¸­ä»¤äººæ»¡æå°æ§è¡ãå¨è¿éï¼æä»¬åæ°äºä¸ç§èåæ¡ä»¶æ©æ£æ¨¡åçéé®é¢æ±è§£å¨ (JCDI)ï¼å®ç»åäºèåæ¡ä»¶æ¶æï¼åæ¶è¾å¥å¤äºä»¶è§æµï¼ä»¥æé«åæ°çå¯æ¦æ¬æ§ãå¯¹ WECC CLM çæ¨¡æç ç©¶è¡¨æï¼ææåºç JCDI ææå°åå°äºéååæ°çä¸ç¡®å®æ§ï¼å æ­¤ä¸åäºä»¶å­¦ä¹ æ¹æ¡ç¸æ¯ï¼åæ°ä¼°è®¡è¯¯å·®éä½äº 42.1%ãè¿ä½¿å¾è¯¥æ¨¡åè½å¤å¨é¢æµä¸åæéäºä»¶ä¸çåçè½¨è¿¹æ¹é¢å®ç°é«ç²¾åº¦ï¼åæ¬çµå­è´è½½è·³é¸åçµæºå¤±éï¼ä¼äºæ åæ·±åº¦å¼ºåå­¦ä¹ åçç£å­¦ä¹ æ¹æ³ãæä»¬é¢è®¡è¿é¡¹å·¥ä½å°æå©äºåè½»ç³»ç»å¨åå­¦ä¸­çåæ°éåï¼ä¸ºåä¸ªç§å­¦é¢åæä¾ä¸ä¸ªéç¨çåæ°ä¼°è®¡æ¡æ¶ã</paragraph>

##### **Evaluating Creativity and Deception in Large Language Models: A Simulation Framework for Multi-Agent Balderdash**
2411.10422v1 by Parsa Hejabi, Elnaz Rahmati, Alireza S. Ziabari, Preni Golazizian, Jesse Thomason, Morteza Dehghani

Large Language Models (LLMs) have shown impressive capabilities in complex
tasks and interactive environments, yet their creativity remains underexplored.
This paper introduces a simulation framework utilizing the game Balderdash to
evaluate both the creativity and logical reasoning of LLMs. In Balderdash,
players generate fictitious definitions for obscure terms to deceive others
while identifying correct definitions. Our framework enables multiple LLM
agents to participate in this game, assessing their ability to produce
plausible definitions and strategize based on game rules and history. We
implemented a centralized game engine featuring various LLMs as participants
and a judge LLM to evaluate semantic equivalence. Through a series of
experiments, we analyzed the performance of different LLMs, examining metrics
such as True Definition Ratio, Deception Ratio, and Correct Guess Ratio. The
results provide insights into the creative and deceptive capabilities of LLMs,
highlighting their strengths and areas for improvement. Specifically, the study
reveals that infrequent vocabulary in LLMs' input leads to poor reasoning on
game rules and historical context
(https://github.com/ParsaHejabi/Simulation-Framework-for-Multi-Agent-Balderdash).

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¨è¤éä»»ååäºåç°å¢ä¸­å±ç¾ä»¤äººå°è±¡æ·±å»çè½åï¼ä½å¶åµé åä»æªè¢«ååæ¢è¨ãæ¬æä»ç´¹äºä¸åæ¨¡æ¬æ¡æ¶ï¼å©ç¨éæ²ãè¡èªªå«éãä¾è©ä¼° LLM çåµé ååéè¼¯æ¨çè½åãå¨ãè¡èªªå«éãä¸­ï¼ç©å®¶çºæ¦æ¾çè©å½ç¢çèæ§çå®ç¾©ä»¥æ¬ºé¨ä»äººï¼åææ¾åºæ­£ç¢ºçå®ç¾©ãæåçæ¡æ¶è®å¤å LLM ä»£çåèéåéæ²ï¼è©ä¼°å®åç¢çåçå®ç¾©åæ ¹æéæ²è¦ååæ­·å²å¶å®ç­ç¥çè½åãæåå¯¦ä½äºä¸åéä¸­å¼çéæ²å¼æï¼å¶ä¸­åå«åç¨® LLM ä½çºåèèï¼ä»¥åä¸åè©ä¼°èªç¾©ç­å¹æ§çè©å¯© LLMãééä¸ç³»åå¯¦é©ï¼æååæäºä¸å LLM çè¡¨ç¾ï¼æª¢è¦äºçå¯¦å®ç¾©æ¯çãæ¬ºé¨æ¯çåæ­£ç¢ºçæ¸¬æ¯çç­ææ¨ãçµææä¾äºå° LLM åµé ååæ¬ºé¨è½åçè¦è§£ï¼çªé¡¯äºå®åçåªé»åæ¹é²é åãå·é«ä¾èªªï¼ç ç©¶é¡¯ç¤º LLM è¼¸å¥ä¸­çä¸å¸¸ç¨è©å½æå°è´å°éæ²è¦ååæ­·å²èæ¯çæ¨çä¸ä½³ï¼https://github.com/ParsaHejabi/Simulation-Framework-for-Multi-Agent-Balderdashï¼ã

##### **Llama Guard 3 Vision: Safeguarding Human-AI Image Understanding Conversations**
2411.10414v1 by Jianfeng Chi, Ujjwal Karn, Hongyuan Zhan, Eric Smith, Javier Rando, Yiming Zhang, Kate Plawiak, Zacharie Delpierre Coudert, Kartikeya Upasani, Mahesh Pasupuleti

We introduce Llama Guard 3 Vision, a multimodal LLM-based safeguard for
human-AI conversations that involves image understanding: it can be used to
safeguard content for both multimodal LLM inputs (prompt classification) and
outputs (response classification). Unlike the previous text-only Llama Guard
versions (Inan et al., 2023; Llama Team, 2024b,a), it is specifically designed
to support image reasoning use cases and is optimized to detect harmful
multimodal (text and image) prompts and text responses to these prompts. Llama
Guard 3 Vision is fine-tuned on Llama 3.2-Vision and demonstrates strong
performance on the internal benchmarks using the MLCommons taxonomy. We also
test its robustness against adversarial attacks. We believe that Llama Guard 3
Vision serves as a good starting point to build more capable and robust content
moderation tools for human-AI conversation with multimodal capabilities.

æè¦ï¼æåä»ç´¹ Llama Guard 3 Visionï¼éæ¯ä¸ç¨®åºæ¼å¤æ¨¡æ LLM çå¤æ¨¡æé²è­·æªæ½ï¼ç¨æ¼æ¶åå½±åçè§£çäººå·¥æºæ§å°è©±ï¼å®å¯ç¨æ¼ä¿è­·å¤æ¨¡æ LLM è¼¸å¥ï¼æç¤ºåé¡ï¼åè¼¸åºï¼åæåé¡ï¼çå§å®¹ãèä¹åçç´æå­ Llama Guard çæ¬ï¼Inan et al., 2023; Llama Team, 2024b,aï¼ä¸åï¼å®ç¹å¥è¨­è¨ç¨æ¼æ¯æ´å½±åæ¨çç¨ä¾ï¼ä¸¦éå°åµæ¸¬æå®³çå¤æ¨¡æï¼æå­åå½±åï¼æç¤ºåå°éäºæç¤ºçæå­åæé²è¡æä½³åãLlama Guard 3 Vision å¨ Llama 3.2-Vision ä¸é²è¡å¾®èª¿ï¼ä¸¦ä½¿ç¨ MLCommons åé¡æ³å¨å§é¨åºæºæ¸¬è©¦ä¸­å±ç¾å¼·åæè½ãæåä¹æ¸¬è©¦å®å°ææ»æçç©©å¥æ§ãæåç¸ä¿¡ Llama Guard 3 Vision å¯ä»¥ä½çºä¸åè¯å¥½çèµ·é»ï¼çºå·åå¤æ¨¡æåè½çäººå·¥æºæ§å°è©±å»ºç½®æ´å¼·å¤§ä¸ç©©å¥çå§å®¹å¯©æ ¸å·¥å·ã

##### **Repurposing Stable Diffusion Attention for Training-Free Unsupervised Interactive Segmentation**
2411.10411v1 by Markus Karmann, Onay Urfalioglu

Recent progress in interactive point prompt based Image Segmentation allows
to significantly reduce the manual effort to obtain high quality semantic
labels. State-of-the-art unsupervised methods use self-supervised pre-trained
models to obtain pseudo-labels which are used in training a prompt-based
segmentation model. In this paper, we propose a novel unsupervised and
training-free approach based solely on the self-attention of Stable Diffusion.
We interpret the self-attention tensor as a Markov transition operator, which
enables us to iteratively construct a Markov chain. Pixel-wise counting of the
required number of iterations along the Markov-chain to reach a relative
probability threshold yields a Markov-iteration-map, which we simply call a
Markov-map. Compared to the raw attention maps, we show that our proposed
Markov-map has less noise, sharper semantic boundaries and more uniform values
within semantically similar regions. We integrate the Markov-map in a simple
yet effective truncated nearest neighbor framework to obtain interactive point
prompt based segmentation. Despite being training-free, we experimentally show
that our approach yields excellent results in terms of Number of Clicks (NoC),
even outperforming state-of-the-art training based unsupervised methods in most
of the datasets.

æè¦ï¼æè¿å¨åºäºäº¤äºå¼ç¹æç¤ºçå½±ååå²æ¹é¢åå¾çè¿å±ï¼å¯å¤§å¹éä½åå¾é«åè´¨è¯­ä¹æ ç­¾çæå¨å·¥ä½ãæåè¿çæ çç£æ¹æ³ä½¿ç¨èªæçç£é¢è®­ç»æ¨¡åæ¥åå¾ä¼ªæ ç­¾ï¼è¿äºæ ç­¾ç¨äºè®­ç»åºäºæç¤ºçåå²æ¨¡åãå¨è¿ç¯è®ºæä¸­ï¼æä»¬æåºä¸ç§ä»åºäº Stable Diffusion èªæ³¨æåçæ°é¢æ çç£ä¸æ éè®­ç»çæ¹æ³ãæä»¬å°èªæ³¨æåå¼ éè§£éä¸ºé©¬å¯å¤«è½¬æ¢ç®å­ï¼è¿ä½¿æä»¬è½å¤è¿­ä»£æå»ºé©¬å¯å¤«é¾ãæ²¿çé©¬å¯å¤«é¾è®¡ç®è¾¾å°ç¸å¯¹æ¦çéå¼æéçè¿­ä»£æ¬¡æ°ï¼å¯äº§çé©¬å¯å¤«è¿­ä»£å¾ï¼æä»¬ç®åå°ç§°ä¹ä¸ºé©¬å¯å¤«å¾ãä¸åå§æ³¨æåå¾ç¸æ¯ï¼æä»¬å±ç¤ºäºæä»¬æåºçé©¬å¯å¤«å¾å·ææ´å°çåªå£°ãæ´æ¸æ°çè¯­ä¹è¾¹çä»¥åè¯­ä¹ç¸ä¼¼åºååçæ´ååçå¼ãæä»¬å°é©¬å¯å¤«å¾æ´åå°ä¸ä¸ªç®åèææçæªæ­æè¿é»æ¡æ¶ä¸­ï¼ä»¥è·åäº¤äºå¼ç¹æç¤ºåå²ãå°½ç®¡æ éè®­ç»ï¼ä½æä»¬éè¿å®éªè¡¨æï¼æä»¬çæ¹æ³å¨ç¹å»æ¬¡æ° (NoC) æ¹é¢äº§çäºæä½³çç»æï¼çè³å¨å¤§å¤æ°æ°æ®éä¸ä¼äºæåè¿çåºäºè®­ç»çæ çç£æ¹æ³ã

##### **Features that Make a Difference: Leveraging Gradients for Improved Dictionary Learning**
2411.10397v1 by Jeffrey Olmo, Jared Wilson, Max Forsey, Bryce Hepner, Thomas Vin Howe, David Wingate

Sparse Autoencoders (SAEs) are a promising approach for extracting neural
network representations by learning a sparse and overcomplete decomposition of
the network's internal activations. However, SAEs are traditionally trained
considering only activation values and not the effect those activations have on
downstream computations. This limits the information available to learn
features, and biases the autoencoder towards neglecting features which are
represented with small activation values but strongly influence model outputs.
To address this, we introduce Gradient SAEs (g-SAEs), which modify the
$k$-sparse autoencoder architecture by augmenting the TopK activation function
to rely on the gradients of the input activation when selecting the $k$
elements. For a given sparsity level, g-SAEs produce reconstructions that are
more faithful to original network performance when propagated through the
network. Additionally, we find evidence that g-SAEs learn latents that are on
average more effective at steering models in arbitrary contexts. By considering
the downstream effects of activations, our approach leverages the dual nature
of neural network features as both $\textit{representations}$, retrospectively,
and $\textit{actions}$, prospectively. While previous methods have approached
the problem of feature discovery primarily focused on the former aspect, g-SAEs
represent a step towards accounting for the latter as well.

æè¦ï¼ç¨çèªç·¨ç¢¼å¨ (SAE) æ¯ä¸ç¨®æåéçæ¹æ³ï¼å¯èç±å­¸ç¿ç¶²è·¯å§é¨æ´»åçç¨çä¸éåº¦å®ååè§£ï¼ä¾èåç¥ç¶ç¶²è·¯è¡¨ç¤ºãç¶èï¼SAE å³çµ±ä¸åªèæ®æ´»åå¼é²è¡è¨ç·´ï¼èæªèæ®éäºæ´»åå°ä¸æ¸¸éç®çå½±é¿ãéæéå¶å¯ç¨æ¼å­¸ç¿ç¹å¾µçè³è¨ï¼ä¸¦ä½¿èªåç·¨ç¢¼å¨ååå¿½ç¥ä»¥å°æ´»åå¼è¡¨ç¤ºä½æå¼·çå½±é¿æ¨¡åè¼¸åºçç¹å¾µãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºæ¢¯åº¦ SAE (g-SAE)ï¼å®ééæ´å TopK æ´»åå½æ¸ä¾ä¿®æ¹ $k$-ç¨çèªåç·¨ç¢¼å¨æ¶æ§ï¼å¨é¸æ $k$ ååç´ æä¾è³´è¼¸å¥æ´»åçæ¢¯åº¦ãå°æ¼çµ¦å®çç¨çåº¦ç­ç´ï¼g-SAE æç¢çå¨ééç¶²è·¯å³æ­ææ´å¿ æ¼åå§ç¶²è·¯æè½çéå»ºãæ­¤å¤ï¼æåç¼ç¾è­æé¡¯ç¤ºï¼g-SAE æå­¸ç¿å°å¹³åèè¨æ´æææ¼å¨ä»»ææå¢ä¸­å¼å°æ¨¡åçæ½å¨è®æ¸ãééèæ®æ´»åçä¸æ¸¸ææï¼æåçåæ³å©ç¨äºç¥ç¶ç¶²è·¯ç¹å¾µä½çº $\textit{è¡¨ç¤º}$ï¼åé¡§æ§ï¼å $\textit{åä½}$ï¼åç»æ§ï¼çééæ§è³ªãéç¶ååçåæ³ä¸»è¦å°æ³¨æ¼ç¹å¾µç¼ç¾åé¡çåèé¢åï¼ä½ g-SAE ä»£è¡¨äºæå¾èéé²ä¸æ­¥çä½æ³ã

##### **Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization**
2411.10389v1 by Fatahlla Moreh, Yusuf Hasan, Bilal Zahid Hussain, Mohammad Ammar, Sven Tomforde

Internal crack detection has been a subject of focus in structural health
monitoring. By focusing on crack detection in structural datasets, it is
demonstrated that deep learning (DL) methods can effectively analyze seismic
wave fields interacting with micro-scale cracks, which are beyond the
resolution of conventional visual inspection. This work explores a novel
application of DL-based key point detection technique, where cracks are
localized by predicting the coordinates of four key points that define a
bounding region of the crack. The study not only opens new research directions
for non-visual applications but also effectively mitigates the impact of
imbalanced data which poses a challenge for previous DL models, as it can be
biased toward predicting the majority class (non-crack regions). Popular DL
techniques, such as the Inception blocks, are used and investigated. The model
shows an overall reduction in loss when applied to micro-scale crack detection
and is reflected in the lower average deviation between the location of actual
and predicted cracks, with an average Intersection over Union (IoU) being 0.511
for all micro cracks (greater than 0.00 micrometers) and 0.631 for larger micro
cracks (greater than 4 micrometers).

æè¦ï¼å§é¨è£ç¸«åµæ¸¬ä¸ç´æ¯çµæ§å¥åº·ç£æ¸¬çéé»ãééå°æ³¨æ¼çµæ§è³æéä¸­çè£ç¸«åµæ¸¬ï¼è­ææ·±åº¦å­¸ç¿ (DL) æ¹æ³å¯ä»¥ææåæèå¾®å°ºåº¦è£ç¸«äº¤äºä½ç¨çå°éæ³¢å ´ï¼éè¶åºäºå³çµ±ç®è¦æª¢æ¥çè§£æåº¦ãéé å·¥ä½æ¢ç´¢äºåºæ¼ DL çééµé»åµæ¸¬æè¡çä¸é æ°æç¨ï¼å¶ä¸­ééé æ¸¬å®ç¾©è£ç¸«éçååçååééµé»çåº§æ¨ä¾å®ä½è£ç¸«ãéé ç ç©¶ä¸åçºéè¦è¦ºæç¨éåäºæ°çç ç©¶æ¹åï¼éè½æææ¸è¼ä¸å¹³è¡¡è³æçå½±é¿ï¼èéå°ååç DL æ¨¡åæ§æææ°ï¼å çºå®å¯è½ååæ¼é æ¸¬å¤æ¸é¡å¥ï¼éè£ç¸«ååï¼ãä½¿ç¨ä¸¦ç ç©¶äºæµè¡ç DL æè¡ï¼ä¾å¦ Inception åå¡ãè©²æ¨¡åå¨æç¨æ¼å¾®å°ºåº¦è£ç¸«åµæ¸¬æé¡¯ç¤ºåºæ´é«æå¤±æ¸å°ï¼ä¸¦ä¸åæ å¨å¯¦éè£ç¸«åé æ¸¬è£ç¸«çä½ç½®ä¹éçè¼ä½å¹³ååå·®ä¸­ï¼ææå¾®è£ç¸«ï¼å¤§æ¼ 0.00 å¾®ç±³ï¼çå¹³åäº¤éæ¯è¯åï¼IoUï¼çº 0.511ï¼èè¼å¤§çå¾®è£ç¸«ï¼å¤§æ¼ 4 å¾®ç±³ï¼åçº 0.631ã

##### **Low-Latency Task-Oriented Communications with Multi-Round, Multi-Task Deep Learning**
2411.10385v1 by Yalin E. Sagduyu, Tugba Erpek, Aylin Yener, Sennur Ulukus

In this paper, we address task-oriented (or goal-oriented) communications
where an encoder at the transmitter learns compressed latent representations of
data, which are then transmitted over a wireless channel. At the receiver, a
decoder performs a machine learning task, specifically for classifying the
received signals. The deep neural networks corresponding to the encoder-decoder
pair are jointly trained, taking both channel and data characteristics into
account. Our objective is to achieve high accuracy in completing the underlying
task while minimizing the number of channel uses determined by the encoder's
output size. To this end, we propose a multi-round, multi-task learning (MRMTL)
approach for the dynamic update of channel uses in multi-round transmissions.
The transmitter incrementally sends an increasing number of encoded samples
over the channel based on the feedback from the receiver, and the receiver
utilizes the signals from a previous round to enhance the task performance,
rather than only considering the latest transmission. This approach employs
multi-task learning to jointly optimize accuracy across varying number of
channel uses, treating each configuration as a distinct task. By evaluating the
confidence of the receiver in task decisions, MRMTL decides on whether to
allocate additional channel uses in multiple rounds. We characterize both the
accuracy and the delay (total number of channel uses) of MRMTL, demonstrating
that it achieves the accuracy close to that of conventional methods requiring
large numbers of channel uses, but with reduced delay by incorporating signals
from a prior round. We consider the CIFAR-10 dataset, convolutional neural
network architectures, and AWGN and Rayleigh channel models for performance
evaluation. We show that MRMTL significantly improves the efficiency of
task-oriented communications, balancing accuracy and latency effectively.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æä»¬è®¨è®ºäºé¢åä»»å¡ï¼æé¢åç®æ ï¼çéä¿¡ï¼å¶ä¸­ï¼åéç«¯çç¼ç å¨å­¦ä¹ æ°æ®çåç¼©éå¼è¡¨ç¤ºï¼ç¶åéè¿æ çº¿ä¿¡éä¼ è¾è¿äºè¡¨ç¤ºãå¨æ¥æ¶ç«¯ï¼è§£ç å¨æ§è¡æºå¨å­¦ä¹ ä»»å¡ï¼ç¹å«æ¯å¯¹æ¥æ¶å°çä¿¡å·è¿è¡åç±»ãä¸ç¼ç å¨-è§£ç å¨å¯¹ç¸å¯¹åºçæ·±åº¦ç¥ç»ç½ç»ç»è¿èåè®­ç»ï¼åæ¶èèä¿¡éåæ°æ®ç¹å¾ãæä»¬çç®æ æ¯å¨å®æåºç¡ä»»å¡æ¶å®ç°é«ç²¾åº¦ï¼åæ¶æå¤§ç¨åº¦å°åå°ç¼ç å¨è¾åºå¤§å°ç¡®å®çä¿¡éä½¿ç¨æ¬¡æ°ãä¸ºæ­¤ï¼æä»¬éå¯¹å¤è½®ä¼ è¾ä¸­çä¿¡éä½¿ç¨å¨ææ´æ°æåºäºä¸ç§å¤è½®å¤ä»»å¡å­¦ä¹  (MRMTL) æ¹æ³ãåéå¨æ ¹æ®æ¥æ¶å¨çåé¦éè¿ä¿¡ééæ­¥åéè¶æ¥è¶å¤çç¼ç æ ·æ¬ï¼èæ¥æ¶å¨å©ç¨ä¸ä¸è½®çä¿¡å·æ¥å¢å¼ºä»»å¡æ§è½ï¼èä¸æ¯ä»èèææ°çä¼ è¾ãæ­¤æ¹æ³éç¨å¤ä»»å¡å­¦ä¹ æ¥èåä¼åä¸åä¿¡éä½¿ç¨æ¬¡æ°çåç¡®æ§ï¼å°æ¯ç§éç½®è§ä¸ºä¸ä¸ªä¸åçä»»å¡ãéè¿è¯ä¼°æ¥æ¶å¨å¨ä»»å¡å³ç­ä¸­çä¿¡å¿ï¼MRMTL å³å®æ¯å¦å¨å¤è½®ä¸­åéé¢å¤çä¿¡éä½¿ç¨ãæä»¬æè¿°äº MRMTL çåç¡®æ§åå»¶è¿ï¼ä¿¡éä½¿ç¨æ»æ°ï¼ï¼è¯æå®å®ç°äºæ¥è¿äºéè¦å¤§éä¿¡éä½¿ç¨çä¼ ç»æ¹æ³çåç¡®æ§ï¼ä½éè¿åå¹¶ä¸ä¸è½®çä¿¡å·æ¥åå°äºå»¶è¿ãæä»¬èèäº CIFAR-10 æ°æ®éãå·ç§¯ç¥ç»ç½ç»æ¶æä»¥å AWGN åçå©ä¿¡éæ¨¡åä»¥è¿è¡æ§è½è¯ä¼°ãæä»¬è¡¨æï¼MRMTL æ¾èæé«äºé¢åä»»å¡éä¿¡çæçï¼ææå°å¹³è¡¡äºåç¡®æ§åå»¶è¿ã</paragraph>

##### **A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**
2411.10371v1 by Zefan Zeng, Qing Cheng, Xingchen Hu, Yuehang Si, Zhong Liu

Event Causality Identification (ECI) has become a crucial task in Natural
Language Processing (NLP), aimed at automatically extracting causalities from
textual data. In this survey, we systematically address the foundational
principles, technical frameworks, and challenges of ECI, offering a
comprehensive taxonomy to categorize and clarify current research
methodologies, as well as a quantitative assessment of existing models. We
first establish a conceptual framework for ECI, outlining key definitions,
problem formulations, and evaluation standards. Our taxonomy classifies ECI
methods according to the two primary tasks of sentence-level (SECI) and
document-level (DECI) event causality identification. For SECI, we examine
feature pattern-based matching, deep semantic encoding, causal knowledge
pre-training and prompt-based fine-tuning, and external knowledge enhancement
methods. For DECI, we highlight approaches focused on event graph reasoning and
prompt-based techniques to address the complexity of cross-sentence causal
inference. Additionally, we analyze the strengths, limitations, and open
challenges of each approach. We further conduct an extensive quantitative
evaluation of various ECI methods on two benchmark datasets. Finally, we
explore future research directions, highlighting promising pathways to overcome
current limitations and broaden ECI applications.

æè¦ï¼äºä»¶å æéä¿è­å¥ï¼ECIï¼å·²æçºèªç¶èªè¨èçï¼NLPï¼ä¸­çä¸é ééµä»»åï¼æ¨å¨å¾ææ¬è³æä¸­èªåæåå æéä¿ãå¨æ¬æ¬¡èª¿æ¥ä¸­ï¼æåç³»çµ±æ§å°æ¢è¨ ECI çåºç¤åçãæè¡æ¡æ¶åææ°ï¼æä¾ä¸åå¨é¢çåé¡æ³ä¾åé¡åéæ¸ç¶åç ç©¶æ¹æ³ï¼ä»¥åå°ç¾ææ¨¡åé²è¡å®éè©ä¼°ãæåé¦åçº ECI å»ºç«ä¸åæ¦å¿µæ¡æ¶ï¼æ¦è¿°ééµå®ç¾©ãåé¡è¡¨è¿°åè©ä¼°æ¨æºãæåçåé¡æ³æ ¹æå¥å­å±¤ç´ï¼SECIï¼åæä»¶å±¤ç´ï¼DECIï¼äºä»¶å æéä¿è­å¥éå©åä¸»è¦ä»»åå° ECI æ¹æ³é²è¡åé¡ãå°æ¼ SECIï¼æåæ¢è¨åºæ¼ç¹å¾µæ¨¡å¼çå¹éãæ·±åº¦èªç¾©ç·¨ç¢¼ãå æç¥è­é è¨ç·´ååºæ¼æç¤ºçå¾®èª¿ï¼ä»¥åå¤é¨ç¥è­å¢å¼·æ¹æ³ãå°æ¼ DECIï¼æåéé»ä»ç´¹å°æ³¨æ¼äºä»¶åå½¢æ¨çååºæ¼æç¤ºçæè¡ï¼ä»¥è§£æ±ºè·¨å¥å­å ææ¨è«çè¤éæ§ãæ­¤å¤ï¼æååæäºæ¯ç¨®æ¹æ³çåªé»ãéå¶åéæ¾æ§ææ°ãæåé²ä¸æ­¥å°å©ç¨®åºæºè³æéä¸çåç¨® ECI æ¹æ³é²è¡å»£æ³çå®éè©ä¼°ãæå¾ï¼æåæ¢è¨æªä¾çç ç©¶æ¹åï¼éé»ä»ç´¹åæç¶åéå¶åæ´å± ECI æç¨ç¨å¼çæå¸æçéå¾ã

##### **Towards High-Fidelity 3D Portrait Generation with Rich Details by Cross-View Prior-Aware Diffusion**
2411.10369v1 by Haoran Wei, Wencheng Han, Xingping Dong, Jianbing Shen

Recent diffusion-based Single-image 3D portrait generation methods typically
employ 2D diffusion models to provide multi-view knowledge, which is then
distilled into 3D representations. However, these methods usually struggle to
produce high-fidelity 3D models, frequently yielding excessively blurred
textures. We attribute this issue to the insufficient consideration of
cross-view consistency during the diffusion process, resulting in significant
disparities between different views and ultimately leading to blurred 3D
representations. In this paper, we address this issue by comprehensively
exploiting multi-view priors in both the conditioning and diffusion procedures
to produce consistent, detail-rich portraits. From the conditioning standpoint,
we propose a Hybrid Priors Diffsion model, which explicitly and implicitly
incorporates multi-view priors as conditions to enhance the status consistency
of the generated multi-view portraits. From the diffusion perspective,
considering the significant impact of the diffusion noise distribution on
detailed texture generation, we propose a Multi-View Noise Resamplig Strategy
integrated within the optimization process leveraging cross-view priors to
enhance representation consistency. Extensive experiments demonstrate that our
method can produce 3D portraits with accurate geometry and rich details from a
single image. The project page is at
\url{https://haoran-wei.github.io/Portrait-Diffusion}.

æè¦ï¼<paragraph>è¿æçåºäºæ©æ£çåå¾å 3D èåçææ¹æ³éå¸¸éç¨ 2D æ©æ£æ¨¡åæ¥æä¾å¤è§å¾ç¥è¯ï¼ç¶åå°å¶æç¼æ 3D è¡¨å¾ãç¶èï¼è¿äºæ¹æ³éå¸¸é¾ä»¥çæé«ä¿ç 3D æ¨¡åï¼ç»å¸¸äº§çè¿åº¦æ¨¡ç³ççº¹çãæä»¬å°æ­¤é®é¢å½å äºå¨æ©æ£è¿ç¨ä¸­å¯¹è·¨è§å¾ä¸è´æ§çèèä¸è¶³ï¼å¯¼è´ä¸åè§å¾ä¹é´å­å¨æ¾çå·®å¼ï¼æç»å¯¼è´æ¨¡ç³ç 3D è¡¨å¾ãå¨æ¬æä¸­ï¼æä»¬éè¿å¨è°éåæ©æ£ç¨åºä¸­å¨é¢å©ç¨å¤è§å¾åéªæ¥è§£å³æ­¤é®é¢ï¼ä»¥çæä¸è´ä¸ç»èä¸°å¯çèåãä»è°éçè§ç¹æ¥çï¼æä»¬æåºäºæ··ååéªæ©æ£æ¨¡åï¼è¯¥æ¨¡åæ¾å¼åéå¼å°å°å¤è§å¾åéªä½ä¸ºæ¡ä»¶çº³å¥å¶ä¸­ï¼ä»¥å¢å¼ºæçæçå¤è§å¾èåçç¶æä¸è´æ§ãä»æ©æ£çè§åº¦æ¥çï¼èèå°æ©æ£åªå£°åå¸å¯¹è¯¦ç»çº¹ççæçå½±åï¼æä»¬æåºäºä¸ç§å¨ä¼åè¿ç¨ä¸­éæçå¤è§å¾åªå£°ééæ ·ç­ç¥ï¼å©ç¨è·¨è§å¾åéªæ¥å¢å¼ºè¡¨å¾ä¸è´æ§ãå¤§éçå®éªè¡¨æï¼æä»¬çæ¹æ³å¯ä»¥ä»åä¸å¾åä¸­çæå·æåç¡®å ä½å½¢ç¶åä¸°å¯ç»èç 3D èåãé¡¹ç®é¡µé¢ä½äº
\url{https://haoran-wei.github.io/Portrait-Diffusion}ã</paragraph>

##### **Mechanisms of Generative Image-to-Image Translation Networks**
2411.10368v1 by Guangzong Chen, Mingui Sun, Zhi-Hong Mao, Kangni Liu, Wenyan Jia

Generative Adversarial Networks (GANs) are a class of neural networks that
have been widely used in the field of image-to-image translation. In this
paper, we propose a streamlined image-to-image translation network with a
simpler architecture compared to existing models. We investigate the
relationship between GANs and autoencoders and provide an explanation for the
efficacy of employing only the GAN component for tasks involving image
translation. We show that adversarial for GAN models yields results comparable
to those of existing methods without additional complex loss penalties.
Subsequently, we elucidate the rationale behind this phenomenon. We also
incorporate experimental results to demonstrate the validity of our findings.

æè¦ï¼çæå°æç¶²è·¯ (GAN) æ¯ä¸é¡ç¥ç¶ç¶²è·¯ï¼å»£æ³ç¨æ¼å½±åè½æé åãå¨æ¬è«æä¸­ï¼æåæåºä¸åç°¡åççå½±åè½æç¶²è·¯ï¼å¶æ¶æ§æ¯ç¾ææ¨¡åæ´çºç°¡æ½ãæåæ¢è¨ GAN èèªåç·¨ç¢¼å¨ä¹éçéä¿ï¼ä¸¦èªªæåä½¿ç¨ GAN çµä»¶ä¾å·è¡å½±åè½æä»»åçæè½ãæåè­æ GAN æ¨¡åçå°ææ§å¯ç¢çèç¾ææ¹æ³ç¸ç¶ççµæï¼èç¡éé¡å¤çè¤éæå¤±æ²ç½°ãé¨å¾ï¼æåé¡æäºæ­¤ç¾è±¡èå¾çåçãæåä¹ç´å¥å¯¦é©çµæä¾è­ææåç¼ç¾çæææ§ã

##### **Domain Adaptation-based Edge Computing for Cross-Conditions Fault Diagnosis**
2411.10340v1 by Yanzhi Wang, Chu Wang, Jinhong Wu, Ziyang Yu, Qi Zhou

Fault diagnosis technology supports the healthy operation of mechanical
equipment. However, the variations conditions during the operation of
mechanical equipment lead to significant disparities in data distribution,
posing challenges to fault diagnosis. Furthermore, when deploying applications,
traditional methods often encounter issues such as latency and data security.
Therefore, conducting fault diagnosis and deploying application methods under
cross-operating conditions holds significant value. This paper proposes a
domain adaptation-based lightweight fault diagnosis framework for edge
computing scenarios. Incorporating the local maximum mean discrepancy into
knowledge transfer aligns the feature distributions of different domains in a
high-dimensional feature space, to discover a common feature space across
domains. The acquired fault diagnosis expertise from the cloud-model is
transferred to the lightweight edge-model using adaptation knowledge transfer
methods. While ensuring real-time diagnostic capabilities, accurate fault
diagnosis is achieved across working conditions. We conducted validation
experiments on the NVIDIA Jetson Xavier NX kit. In terms of diagnostic
performance, the proposed method significantly improved diagnostic accuracy,
with average increases of 34.44% and 17.33% compared to the comparison method,
respectively. Regarding lightweight effectiveness, proposed method achieved an
average inference speed increase of 80.47%. Additionally, compared to the
cloud-model, the parameter count of the edge-model decreased by 96.37%, while
the Flops decreased by 83.08%.

æè¦ï¼æéè¨ºæ·æè¡æ¯æ´æ©æ¢°è¨­åçå¥åº·éä½ãç¶èï¼æ©æ¢°è¨­åå¨éä½æéçè®ç°æ¢ä»¶å°è´è³æåä½æé¡¯èå·®ç°ï¼å°æéè¨ºæ·æ§æææ°ãæ­¤å¤ï¼å¨é¨ç½²æç¨ç¨å¼æï¼å³çµ±æ¹æ³ç¶å¸¸æéå°å»¶é²åè³æå®å¨ç­åé¡ãå æ­¤ï¼å¨è·¨æä½æ¢ä»¶ä¸é²è¡æéè¨ºæ·åé¨ç½²æç¨ç¨å¼æ¹æ³å·æéè¦çå¹å¼ãæ¬ææåºäºä¸ååºæ¼é åé©æçè¼éç´æéè¨ºæ·æ¡æ¶ï¼ç¨æ¼éç·£éç®å ´æ¯ãå°å±é¨æå¤§å¹³åå·®ç°ç´å¥ç¥è­è½ç§»ï¼å¨é«ç¶­ç¹å¾µç©ºéä¸­å°é½ä¸åé åçç¹å¾µåä½ï¼ä»¥ç¼ç¾è·¨é åçå±åç¹å¾µç©ºéãå¾é²æ¨¡åä¸­ç²åçæéè¨ºæ·å°æ¥­ç¥è­ï¼ä½¿ç¨é©æç¥è­è½ç§»æ¹æ³è½ç§»å°è¼éç´éç·£æ¨¡åä¸­ãå¨ç¢ºä¿å³æè¨ºæ·è½åçåæï¼å¨å·¥ä½æ¢ä»¶ä¸å¯¦ç¾äºæºç¢ºçæéè¨ºæ·ãæåå¨ NVIDIA Jetson Xavier NX å¥ä»¶ä¸é²è¡äºé©è­å¯¦é©ãå¨è¨ºæ·æè½æ¹é¢ï¼ææåºçæ¹æ³é¡¯èæé«äºè¨ºæ·æºç¢ºåº¦ï¼èæ¯è¼æ¹æ³ç¸æ¯ï¼å¹³ååå¥æé«äº 34.44% å 17.33%ãéæ¼è¼éç´æææ§ï¼ææåºçæ¹æ³å¯¦ç¾äºå¹³åæ¨è«éåº¦æé« 80.47%ãæ­¤å¤ï¼èé²æ¨¡åç¸æ¯ï¼éç·£æ¨¡åçåæ¸æ¸éæ¸å°äº 96.37%ï¼è Flops æ¸å°äº 83.08%ã

##### **Safe Text-to-Image Generation: Simply Sanitize the Prompt Embedding**
2411.10329v1 by Huming Qiu, Guanxu Chen, Mi Zhang, Min Yang

In recent years, text-to-image (T2I) generation models have made significant
progress in generating high-quality images that align with text descriptions.
However, these models also face the risk of unsafe generation, potentially
producing harmful content that violates usage policies, such as explicit
material. Existing safe generation methods typically focus on suppressing
inappropriate content by erasing undesired concepts from visual
representations, while neglecting to sanitize the textual representation.
Although these methods help mitigate the risk of misuse to certain extent,
their robustness remains insufficient when dealing with adversarial attacks.
  Given that semantic consistency between input text and output image is a
fundamental requirement for T2I models, we identify that textual
representations (i.e., prompt embeddings) are likely the primary source of
unsafe generation. To this end, we propose a vision-agnostic safe generation
framework, Embedding Sanitizer (ES), which focuses on erasing inappropriate
concepts from prompt embeddings and uses the sanitized embeddings to guide the
model for safe generation. ES is applied to the output of the text encoder as a
plug-and-play module, enabling seamless integration with different T2I models
as well as other safeguards. In addition, ES's unique scoring mechanism assigns
a score to each token in the prompt to indicate its potential harmfulness, and
dynamically adjusts the sanitization intensity to balance defensive performance
and generation quality. Through extensive evaluation on five prompt benchmarks,
our approach achieves state-of-the-art robustness by sanitizing the source
(prompt embedding) of unsafe generation compared to nine baseline methods. It
significantly outperforms existing safeguards in terms of interpretability and
controllability while maintaining generation quality.

æè¦ï¼<paragraph>è¿å¹´æ¥ï¼ææ¬å°å¾å (T2I) çææ¨¡åå¨çæä¸ææ¬æè¿°ç¸ç¬¦çé«è´¨éå¾åæ¹é¢åå¾äºéå¤§è¿å±ãç¶èï¼è¿äºæ¨¡åä¹é¢ä¸´çä¸å®å¨ççæé£é©ï¼å¯è½ä¼äº§çè¿åä½¿ç¨æ¿ç­çæå®³åå®¹ï¼ä¾å¦é²éª¨çææãç°æçå®å¨çææ¹æ³éå¸¸ä¾§éäºéè¿ä»è§è§è¡¨ç°ä¸­æ¹å»ä¸éè¦çæ¦å¿µæ¥æå¶ä¸å½åå®¹ï¼èå¿½ç¥äºå¯¹ææ¬è¡¨ç°è¿è¡æ¸çãå°½ç®¡è¿äºæ¹æ³å¨ä¸å®ç¨åº¦ä¸å¸®å©åè½»äºæ»¥ç¨çé£é©ï¼ä½å®ä»¬å¨åºå¯¹å¯¹ææ§æ»å»æ¶çé²æ£æ§ä»ç¶ä¸è¶³ãé´äºè¾å¥ææ¬åè¾åºå¾åä¹é´çè¯­ä¹ä¸è´æ§æ¯ T2I æ¨¡åçåºæ¬è¦æ±ï¼æä»¬åç°ææ¬è¡¨ç°ï¼å³æç¤ºåµå¥ï¼å¯è½æ¯ä¸å®å¨çæçæ ¹æºãä¸ºæ­¤ï¼æä»¬æåºäºä¸ç§ä¸è§è§æ å³çå®å¨çææ¡æ¶ï¼åµå¥æ¸çå¨ (ES)ï¼å¶éç¹æ¯ä»æç¤ºåµå¥ä¸­æ¹å»ä¸å½æ¦å¿µï¼å¹¶ä½¿ç¨ç»è¿æ¸ççåµå¥æ¥æå¯¼æ¨¡åè¿è¡å®å¨çæãES è¢«åºç¨äºææ¬ç¼ç å¨çè¾åºï¼ä½ä¸ºä¸ä¸ªå³æå³ç¨æ¨¡åï¼è½å¤ä¸ä¸åç T2I æ¨¡åä»¥åå¶ä»ä¿éæªæ½æ ç¼éæãæ­¤å¤ï¼ES ç¬ç¹çè¯åæºå¶ä¸ºæç¤ºä¸­çæ¯ä¸ªæ è®°åéä¸ä¸ªåæ°ï¼ä»¥è¡¨ç¤ºå¶æ½å¨å±å®³æ§ï¼å¹¶å¨æè°æ´æ¸çå¼ºåº¦ä»¥å¹³è¡¡é²å¾¡æ§è½åçæè´¨éãéè¿å¯¹äºä¸ªæç¤ºåºåçå¹¿æ³è¯ä¼°ï¼æä»¬çæ¹æ³éè¿æ¸çä¸å®å¨çæçæºï¼æç¤ºåµå¥ï¼èå®ç°äºæåè¿çé²æ£æ§ï¼ä¸ä¹ç§åºçº¿æ¹æ³ç¸æ¯ãå®å¨å¯è§£éæ§åå¯æ§æ§æ¹é¢ææ¾ä¼äºç°æçä¿éæªæ½ï¼åæ¶ä¿æäºçæè´¨éã</paragraph>

##### **Emotion Detection in Reddit: Comparative Study of Machine Learning and Deep Learning Techniques**
2411.10328v1 by Maliheh Alaeddini

Emotion detection is pivotal in human communication, as it significantly
influences behavior, relationships, and decision-making processes. This study
concentrates on text-based emotion detection by leveraging the GoEmotions
dataset, which annotates Reddit comments with 27 distinct emotions. These
emotions are subsequently mapped to Ekman's six basic categories: joy, anger,
fear, sadness, disgust, and surprise. We employed a range of models for this
task, including six machine learning models, three ensemble models, and a Long
Short-Term Memory (LSTM) model to determine the optimal model for emotion
detection. Results indicate that the Stacking classifier outperforms other
models in accuracy and performance. We also benchmark our models against
EmoBERTa, a pre-trained emotion detection model, with our Stacking classifier
proving more effective. Finally, the Stacking classifier is deployed via a
Streamlit web application, underscoring its potential for real-world
applications in text-based emotion analysis.

æè¦ï¼æç·åµæ¸¬å¨äººé¡æºéä¸­è³ééè¦ï¼å çºå®é¡¯èå½±é¿è¡çºãäººééä¿åæ±ºç­å¶å®éç¨ãæ¬ç ç©¶éä¸­æ¼åºæ¼æå­çæç·åµæ¸¬ï¼å©ç¨ GoEmotions è³æéï¼å¶ä¸­è¨»è§£äº Reddit è©è«ï¼ä¸¦æ¨ç¤ºäº 27 ç¨®ä¸åçæç·ãéäºæç·é¨å¾å°æå° Ekman çå­ç¨®åºæ¬é¡å¥ï¼å¿«æ¨ãæ¤æãææ¼ãæ²å·ãå­æ¡åé©è¨ãæåæ¡ç¨äºä¸ç³»åæ¨¡åä¾å·è¡éé ä»»åï¼åæ¬å­åæ©å¨å­¸ç¿æ¨¡åãä¸åéææ¨¡ååä¸åé·ç­æè¨æ¶ (LSTM) æ¨¡åï¼ä»¥ç¢ºå®æä½³çæç·åµæ¸¬æ¨¡åãçµæè¡¨æï¼å çåé¡å¨å¨æºç¢ºæ§åæè½æ¹é¢åªæ¼å¶ä»æ¨¡åãæåä¹æ ¹æé åè¨ç·´å¥½çæç·åµæ¸¬æ¨¡å EmoBERTa ä¾è©éæåçæ¨¡åï¼èæåçå çåé¡å¨è­æäºæ´ææãæå¾ï¼å çåé¡å¨éé Streamlit ç¶²è·¯æç¨ç¨å¼é²è¡é¨ç½²ï¼çªé¡¯äºå®å¨åºæ¼æå­çæç·åæä¸­å°çå¯¦ä¸çæç¨ç¨å¼çæ½åã

##### **The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use**
2411.10323v1 by Siyuan Hu, Mingyu Ouyang, Difei Gao, Mike Zheng Shou

The recently released model, Claude 3.5 Computer Use, stands out as the first
frontier AI model to offer computer use in public beta as a graphical user
interface (GUI) agent. As an early beta, its capability in the real-world
complex environment remains unknown. In this case study to explore Claude 3.5
Computer Use, we curate and organize a collection of carefully designed tasks
spanning a variety of domains and software. Observations from these cases
demonstrate Claude 3.5 Computer Use's unprecedented ability in end-to-end
language to desktop actions. Along with this study, we provide an
out-of-the-box agent framework for deploying API-based GUI automation models
with easy implementation. Our case studies aim to showcase a groundwork of
capabilities and limitations of Claude 3.5 Computer Use with detailed analyses
and bring to the fore questions about planning, action, and critic, which must
be considered for future improvement. We hope this preliminary exploration will
inspire future research into the GUI agent community. All the test cases in the
paper can be tried through the project:
https://github.com/showlab/computer_use_ootb.

æè¦ï¼æè¿ç¼å¸çæ¨¡åï¼Claude 3.5 é»è¦ä½¿ç¨ï¼ä½çºç¬¬ä¸åæä¾é»è¦ä½¿ç¨æ¼å¬éæ¸¬è©¦çï¼ä½çºåå½¢ä½¿ç¨èä»é¢ (GUI) ä»£ççéç AI æ¨¡åèè«ç©èåºãä½çºä¸åæ©ææ¸¬è©¦çï¼å®å¨çå¯¦ä¸çè¤éç°å¢ä¸­çè½åä»ç¶æªç¥ãå¨éåæ¡ä¾ç ç©¶ä¸­ï¼æåç­åä¸¦çµç¹äºä¸ç³»åç²¾å¿è¨­è¨çä»»åï¼æ¶µèåç¨®é ååè»é«ï¼ä»¥æ¢ç´¢ Claude 3.5 é»è¦ä½¿ç¨ãéäºæ¡ä¾çè§å¯çµæè­æäº Claude 3.5 é»è¦ä½¿ç¨å¨ç«¯å°ç«¯èªè¨å°æ¡é¢åä½ä¸­åææªæçè½åãé¨èéé ç ç©¶ï¼æåæä¾äºä¸åéç®±å³ç¨çä»£çæ¶æ§ï¼ç¨æ¼é¨ç½²åºæ¼ API ç GUI èªååæ¨¡åï¼ä¸¦ææ¼å¯¦ä½ãæåçæ¡ä¾ç ç©¶æ¨å¨å±ç¤º Claude 3.5 é»è¦ä½¿ç¨è½ååéå¶çåºç¤ï¼ä¸¦é²è¡è©³ç´°åæï¼ä¸¦æåºéæ¼è¦åãè¡ååæ¹è©çåé¡ï¼éäºåé¡å¿é èæ®å¨æªä¾çæ¹é²ä¸­ãæåå¸æéååæ­¥æ¢ç´¢è½æ¿åµæªä¾å° GUI ä»£çç¤¾ç¾¤çç ç©¶ãæ¬æä¸­çæææ¸¬è©¦æ¡ä¾é½å¯ä»¥ééå°æ¡åè©¦ï¼
https://github.com/showlab/computer_use_ootbã

##### **Unveiling Topological Structures in Text: A Comprehensive Survey of Topological Data Analysis Applications in NLP**
2411.10298v1 by Adaku Uchendu, Thai Le

The surge of data available on the internet has led to the adoption of
various computational methods to analyze and extract valuable insights from
this wealth of information. Among these, the field of Machine Learning (ML) has
thrived by leveraging data to extract meaningful insights. However, ML
techniques face notable challenges when dealing with real-world data, often due
to issues of imbalance, noise, insufficient labeling, and high dimensionality.
To address these limitations, some researchers advocate for the adoption of
Topological Data Analysis (TDA), a statistical approach that discerningly
captures the intrinsic shape of data despite noise. Despite its potential, TDA
has not gained as much traction within the Natural Language Processing (NLP)
domain compared to structurally distinct areas like computer vision.
Nevertheless, a dedicated community of researchers has been exploring the
application of TDA in NLP, yielding 85 papers we comprehensively survey in this
paper. Our findings categorize these efforts into theoretical and
nontheoretical approaches. Theoretical approaches aim to explain linguistic
phenomena from a topological viewpoint, while non-theoretical approaches merge
TDA with ML features, utilizing diverse numerical representation techniques. We
conclude by exploring the challenges and unresolved questions that persist in
this niche field. Resources and a list of papers on this topic can be found at:
https://github.com/AdaUchendu/AwesomeTDA4NLP.

æè¦ï¼ç¶²è·¯ä¸è³ææ¿å¢ï¼å°è´æ¡ç¨åç¨®éç®æ¹æ³ä¾åæåå¾éäºè±å¯è³è¨ä¸­èåæå¹å¼çè¦è§£ãå¶ä¸­ï¼æ©å¨å­¸ç¿ (ML) é åééå©ç¨è³æä¾èåææç¾©çè¦è§£èè¬åç¼å±ãç¶èï¼ML æè¡å¨èççå¯¦ä¸çè³æææé¢è¨é¡¯èçææ°ï¼éå¸¸æ¯å çºä¸å¹³è¡¡ãéè¨ãæ¨ç±¤ä¸è¶³åé«ç¶­åº¦ç­åé¡ãçºäºè§£æ±ºéäºéå¶ï¼ä¸äºç ç©¶äººå¡æå¡æ¡ç¨ææ²è³æåæ (TDA)ï¼éæ¯ä¸ç¨®çµ±è¨æ¹æ³ï¼å¯ä»¥æè¾¨å°æ·åè³æçå§å¨å½¢çï¼å³ä½¿æéè¨ãåç®¡æå¶æ½åï¼èé»è¦è¦è¦ºç­çµæ§ä¸ä¸åçé åç¸æ¯ï¼TDA å¨èªç¶èªè¨èç (NLP) é åä¸¦æªç²å¾å¤ªå¤éæ³¨ãåç®¡å¦æ­¤ï¼ä¸ç¾¤å°éçç ç©¶äººå¡ä¸ç´å¨æ¢ç´¢ TDA å¨ NLP ä¸­çæç¨ï¼ä¸¦å¨æ¬æä¸­å¨é¢èª¿æ¥äº 85 ç¯è«æãæåçç ç©¶çµæå°éäºåªååé¡çºçè«åéçè«æ¹æ³ãçè«æ¹æ³æ¨å¨å¾ææ²è§é»è§£éèªè¨ç¾è±¡ï¼èéçè«æ¹æ³åå° TDA è ML ç¹å¾µåä½µï¼ä¸¦å©ç¨å¤æ¨£åçæ¸å¼è¡¨ç¤ºæè¡ãæåæå¾æ¢è¨æ­¤å©åºé åä¸­æçºå­å¨çææ°èæªè§£æ±ºåé¡ãå¯ä»¥å¨ä»¥ä¸ä½ç½®æ¾å°æ­¤ä¸»é¡çè³æºåè«ææ¸å®ï¼https://github.com/AdaUchendu/AwesomeTDA4NLPã

##### **Scaling Law for Post-training after Model Pruning**
2411.10272v1 by Xiaodong Chen, Yuxuan Hu, Jing Zhang, Xiaokang Zhang, Cuiping Li, Hong Chen

Large language models (LLMs) based on the Transformer architecture are widely
employed across various domains and tasks. However, their increasing size
imposes significant hardware demands, limiting practical deployment. To
mitigate this, model pruning techniques have been developed to create more
efficient models while maintaining high performance. Despite this,
post-training after pruning is crucial for performance recovery and can be
resource-intensive. This paper investigates the post-training requirements of
pruned LLMs and introduces a scaling law to determine the optimal amount of
post-training data. Post-training experiments with the Llama-3 and Qwen-2.5
series models, pruned using depth pruning, width pruning, and 2:4
semi-structured pruning, show that higher pruning ratios necessitate more
post-training data for performance recovery, whereas larger LLMs require less.
The proposed scaling law predicts a model's loss based on its parameter counts
before and after pruning, as well as the post-training token counts.
Furthermore, we find that the scaling law established from smaller LLMs can be
reliably extrapolated to larger LLMs. This work provides valuable insights into
the post-training of pruned LLMs and offers a practical scaling law for
optimizing post-training data usage.

æè¦ï¼<paragraph>åºæ¼ Transformer æ¶æ§çå¤§åèªè¨æ¨¡å (LLM) å»£æ³ç¨æ¼åç¨®é ååä»»åä¸­ãç¶èï¼å®åæ¥çå¢å çå¤§å°æå¸¶ä¾é¡¯èçç¡¬é«éæ±ï¼éå¶äºå¯¦éé¨ç½²ãçºäºæ¸è¼éååé¡ï¼å·²ç¶éç¼åºæ¨¡ååªææè¡ï¼ä»¥å¨ç¶­æé«æ§è½çåæå»ºç«æ´ææççæ¨¡åãåç®¡å¦æ­¤ï¼åªæå¾çå¾çºè¨ç·´å°æ¼æ§è½æ¢å¾©è³ééè¦ï¼èä¸å¯è½ææ¶èå¤§éè³æºãæ¬ææ¢è¨äºåªæå¾ç LLM çå¾çºè¨ç·´éæ±ï¼ä¸¦å¼å¥äºä¸åç¸®æ¾å®å¾ä¾ç¢ºå®æä½³çå¾çºè¨ç·´è³æéãä½¿ç¨æ·±åº¦åªæãå¯¬åº¦åªæå 2:4 åçµæ§ååªæé²è¡åªæç Llama-3 å Qwen-2.5 ç³»åæ¨¡åçå¾çºè¨ç·´å¯¦é©è¡¨æï¼è¼é«çåªæçéè¦æ´å¤å¾çºè¨ç·´è³ææè½æ¢å¾©æ§è½ï¼èè¼å¤§ç LLM åéè¦è¼å°ãææåºçç¸®æ¾å®å¾æ ¹ææ¨¡åå¨åªæåå¾çåæ¸æ¸éä»¥åå¾çºè¨ç·´ç token æ¸éé æ¸¬æ¨¡åçæå¤±ãæ­¤å¤ï¼æåç¼ç¾å¾è¼å°ç LLM å»ºç«çç¸®æ¾å®å¾å¯ä»¥å¯é å°å¤æ¨å°è¼å¤§ç LLMãéé å·¥ä½æä¾äºå°åªæå¾ LLM çå¾çºè¨ç·´çå¯¶è²´è¦è§£ï¼ä¸¦çºæä½³åå¾çºè¨ç·´è³æä½¿ç¨æä¾äºå¯¦ç¨çç¸®æ¾å®å¾ã</paragraph>

##### **The Unreasonable Effectiveness of Guidance for Diffusion Models**
2411.10257v1 by Tim Kaiser, Nikolas Adaloglou, Markus Kollmann

Guidance is an error-correcting technique used to improve the perceptual
quality of images generated by diffusion models. Typically, the correction is
achieved by linear extrapolation, using an auxiliary diffusion model that has
lower performance than the primary model. Using a 2D toy example, we show that
it is highly beneficial when the auxiliary model exhibits similar errors as the
primary one but stronger. We verify this finding in higher dimensions, where we
show that competitive generative performance to state-of-the-art guidance
methods can be achieved when the auxiliary model differs from the primary one
only by having stronger weight regularization. As an independent contribution,
we investigate whether upweighting long-range spatial dependencies improves
visual fidelity. The result is a novel guidance method, which we call sliding
window guidance (SWG), that guides the primary model with itself by
constraining its receptive field. Intriguingly, SWG aligns better with human
preferences than state-of-the-art guidance methods while requiring neither
training, architectural modifications, nor class conditioning. The code will be
released.

æè¦ï¼æå°æ¯ä¸ç¨®é¯èª¤ä¿®æ­£æè¡ï¼ç¨æ¼æ¹åæ´æ£æ¨¡åçæçå½±åä¹æç¥åè³ªãéå¸¸ï¼ä¿®æ­£æééç·æ§å¤æ¨ä¾éæï¼ä½¿ç¨ä¸åè¼å©æ´æ£æ¨¡åï¼å¶æè½ä½æ¼ä¸»è¦æ¨¡åãä½¿ç¨ä¸å 2D ç©å·ç¯ä¾ï¼æåå±ç¤ºç¶è¼å©æ¨¡åå±ç¾èä¸»è¦æ¨¡åç¸ä¼¼çé¯èª¤ï¼ä½æ´å¼·æï¼ææé«åº¦çå¥½èãæåå¨è¼é«ç¶­åº¦ä¸­é©è­æ­¤ç¼ç¾ï¼å¶ä¸­æåå±ç¤ºç¶è¼å©æ¨¡ååå¨å·æè¼å¼·çæ¬éæ­£è¦åæèä¸»è¦æ¨¡åä¸åæï¼å¯ä»¥éæèç¾ææè¡æå°æ¹æ³ç¸ç«¶ç­ççææè½ãä½çºä¸åç¨ç«çè²¢ç»ï¼æåæ¢è¨æ¯å¦ä¸èª¿é·ç¨ç©ºéä¾è³´æ§ææ¹åè¦è¦ºä¿çåº¦ãçµææ¯ä¸ç¨®æ°ç©çæå°æ¹æ³ï¼æåç¨±ä¹çºæ»åè¦çªæå° (SWG)ï¼å®éééå¶å¶æåéä¾ä½¿ç¨èªèº«æå°ä¸»è¦æ¨¡åãæè¶£çæ¯ï¼SWG æ¯ç¾ææè¡æå°æ¹æ³æ´ç¬¦åäººé¡åå¥½ï¼åæä¸éè¦è¨ç·´ãæ¶æ§ä¿®æ¹æé¡å¥èª¿æ´ãç¨å¼ç¢¼å°æéåºã

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

æè¦ï¼å°åå¿èç¾çåç¾åå¤©æ§èå¾å¤©æ§ç¾ççå»£æ³åè­ãè¼è¤éçåå¤©æ§ç¸å½¢éè¦ä¸åå·®ç°åä¸å¤æ¨¡å¼çæ±ºç­éç¨ï¼éå¸¸åæ¬è¶é³æ³¢æª¢æ¥ä½çºä¸»è¦çå½±åæ¹æ³ãäººå·¥æºæ§ (AI) çºè¨åºé«çæä¾äºç¸ç¶å¤§çå¸æï¼å çºå®å¯ä»¥ä¿é²å°åè¶é³æ³¢æª¢æ¥è³æçèªååè§£è®ãç¶èï¼å°äººå·¥æºæ§æè¡æç¨æ¼å°åè¶é³æ³¢æª¢æ¥åææè¨±å¤ææ°ï¼ä¾å¦æéçå¬éè³æå¯ç¨æ§ãè³æé±ç§åäººå·¥æºæ§æ¨¡åéæåº¦ãæè¿ï¼ç ç©¶äººå¡å°æ³¨æ¼ç ´å£æ§æè¡ï¼ä¾å¦è¯åå­¸ç¿ (FL) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥æ¹åèªåè¨ºæ·åæ±ºç­æ¯æ´å·¥ä½æµç¨ãæ¬ç ç©¶æä¾äºäººå·¥æºæ§å¨å°åè¶é³æ³¢æª¢æ¥ä¸­çéå¶åæ©æçå¨é¢æ¦è¿°ï¼å¼·èª¿äº XAI å FL çååå·¥ä½æµç¨åè§è²ï¼æ¾åºç ç©¶å·®è·ä¸¦æ¢è¨æ½å¨çæªä¾ç¼å±ãæ­¤å¤ï¼ä¸åç¸éçè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº XAI å FL çåè½ï¼éé»å¨æ¼ (i) æª¢è¦è¾¨è­ã(ii) ç¾çåé¡ã(iii) å¿èçµæ§åå²å (iv) å¿èåè½çéåè©ä¼°ã

##### **Scaling up the Evaluation of Collaborative Problem Solving: Promises and Challenges of Coding Chat Data with ChatGPT**
2411.10246v1 by Jiangang Hao, Wenju Cui, Patrick Kyllonen, Emily Kerzabi, Lei Liu, Michael Flor

Collaborative problem solving (CPS) is widely recognized as a critical 21st
century skill. Efficiently coding communication data is a big challenge in
scaling up research on assessing CPS. This paper reports the findings on using
ChatGPT to directly code CPS chat data by benchmarking performance across
multiple datasets and coding frameworks. We found that ChatGPT-based coding
outperformed human coding in tasks where the discussions were characterized by
colloquial languages but fell short in tasks where the discussions dealt with
specialized scientific terminology and contexts. The findings offer practical
guidelines for researchers to develop strategies for efficient and scalable
analysis of communication data from CPS tasks.

æè¦ï¼åä½åé¡è§£æ±º (CPS) å»£æ³è¢«èªçºæ¯ 21 ä¸ç´çä¸é ééµæè½ãææç·¨ç¢¼æºéè³ææ¯æ´å¤§ CPS è©ä¼°ç ç©¶çä¸é éå¤§ææ°ãæ¬æå ±åäºä½¿ç¨ ChatGPT ç´æ¥ç·¨ç¢¼ CPS èå¤©è³æçç¼ç¾ï¼ä¸¦ééå°å¤åè³æéåç·¨ç¢¼æ¡æ¶é²è¡æè½åºæºæ¸¬è©¦ãæåç¼ç¾ï¼å¨è¨è«ä»¥å£èªçºç¹å¾µçä»»åä¸­ï¼åºæ¼ ChatGPT çç·¨ç¢¼åªæ¼äººå·¥ç·¨ç¢¼ï¼ä½å¨è¨è«æ¶åå°æ¥­ç§å­¸è¡èªåèæ¯çä»»åä¸­åè¡¨ç¾ä¸ä½³ãéäºç¼ç¾çºç ç©¶äººå¡æä¾äºå¯¦ç¨çæåï¼ä»¥ä¾¿å¶å®ç­ç¥ï¼ä»¥ææä¸å¯æ´åçæ¹å¼åæä¾èª CPS ä»»åçæºéè³æã

##### **Measuring Non-Adversarial Reproduction of Training Data in Large Language Models**
2411.10242v1 by Michael Aerni, Javier Rando, Edoardo Debenedetti, Nicholas Carlini, Daphne Ippolito, Florian TramÃ¨r

Large language models memorize parts of their training data. Memorizing short
snippets and facts is required to answer questions about the world and to be
fluent in any language. But models have also been shown to reproduce long
verbatim sequences of memorized text when prompted by a motivated adversary. In
this work, we investigate an intermediate regime of memorization that we call
non-adversarial reproduction, where we quantify the overlap between model
responses and pretraining data when responding to natural and benign prompts.
For a variety of innocuous prompt categories (e.g., writing a letter or a
tutorial), we show that up to 15% of the text output by popular conversational
language models overlaps with snippets from the Internet. In worst cases, we
find generations where 100% of the content can be found exactly online. For the
same tasks, we find that human-written text has far less overlap with Internet
data. We further study whether prompting strategies can close this reproduction
gap between models and humans. While appropriate prompting can reduce
non-adversarial reproduction on average, we find that mitigating worst-case
reproduction of training data requires stronger defenses -- even for benign
interactions.

æè¦ï¼å¤§åèªè¨æ¨¡åæè¨æ¶è¨ç·´è³æçä¸é¨åãè¨æ¶ç°¡ç­ççæ®µåäºå¯¦å°æ¼åç­æéä¸çåé¡ä»¥åæµå©ä½¿ç¨ä»»ä½èªè¨é½æ¯å¿è¦çãä½æ¯ï¼ç¶åå°æåæ©çå°ææç¤ºæï¼æ¨¡åä¹å·²è¢«è­ææè¤è£½è¨æ¶æå­çé·ä¸²éå­åºåãå¨éé å·¥ä½ä¸­ï¼æåç ç©¶äºä¸ç¨®ç¨±çºéå°ææ§è¤è£½çè¨æ¶ä¸­éæ©å¶ï¼å¶ä¸­æåéåäºæ¨¡ååæèå¨åæèªç¶ä¸è¯æ§çæç¤ºæé è¨ç·´è³æä¹éçéçãå°æ¼åç¨®ç¡å®³çæç¤ºé¡å¥ï¼ä¾å¦ï¼å¯«ä¸å°ä¿¡æä¸åæå­¸ï¼ï¼æåå±ç¤ºäºç±éå°è©±èªè¨æ¨¡åè¼¸åºçææ¬ä¸­ï¼å¤é 15% èä¾èªç¶²éç¶²è·¯ççæ®µéçãå¨æå£çææ³ä¸ï¼æåç¼ç¾ 100% çå§å®¹å¯ä»¥å¨ç¶²è·¯ä¸æ¾å°ãå°æ¼ç¸åçä»»åï¼æåç¼ç¾äººé¡å¯«çæå­èç¶²éç¶²è·¯è³æçéçç¨åº¦é ä½æ¼æ­¤ãæåé²ä¸æ­¥ç ç©¶æç¤ºç­ç¥æ¯å¦å¯ä»¥ç¸®å°æ¨¡ååäººé¡ä¹éçéç¨®è¤è£½å·®è·ãéç¶é©ç¶çæç¤ºå¯ä»¥å¹³åæ¸å°éå°ææ§è¤è£½ï¼ä½æåç¼ç¾ï¼æ¸è¼è¨ç·´è³æçæå£ææ³è¤è£½éè¦æ´å¼·çé²ç¦¦æªæ½ï¼å³ä½¿å°æ¼è¯æ§çäºåä¹æ¯å¦æ­¤ã

##### **Generative AI in Multimodal User Interfaces: Trends, Challenges, and Cross-Platform Adaptability**
2411.10234v1 by J. Bieniek, M. Rahouti, D. C. Verma

As the boundaries of human computer interaction expand, Generative AI emerges
as a key driver in reshaping user interfaces, introducing new possibilities for
personalized, multimodal and cross-platform interactions. This integration
reflects a growing demand for more adaptive and intuitive user interfaces that
can accommodate diverse input types such as text, voice and video, and deliver
seamless experiences across devices. This paper explores the integration of
generative AI in modern user interfaces, examining historical developments and
focusing on multimodal interaction, cross-platform adaptability and dynamic
personalization. A central theme is the interface dilemma, which addresses the
challenge of designing effective interactions for multimodal large language
models, assessing the trade-offs between graphical, voice-based and immersive
interfaces. The paper further evaluates lightweight frameworks tailored for
mobile platforms, spotlighting the role of mobile hardware in enabling scalable
multimodal AI. Technical and ethical challenges, including context retention,
privacy concerns and balancing cloud and on-device processing are thoroughly
examined. Finally, the paper outlines future directions such as emotionally
adaptive interfaces, predictive AI driven user interfaces and real-time
collaborative systems, underscoring generative AI's potential to redefine
adaptive user-centric interfaces across platforms.

æè¦ï¼é¨èäººæ©äºåççç·ä¸æ·æ´å±ï¼çæå¼ AI æçºéæ°å¡é ä½¿ç¨èä»é¢çééµé©ååï¼çºåäººåãå¤æ¨¡æåè·¨å¹³å°äºåå¼å¥äºæ°çå¯è½æ§ãéç¨®æ´ååæ åºå°æ´å·é©ææ§åç´è¦ºæ§çä½¿ç¨èä»é¢çéæ±æ¥çå¢å ï¼éç¨®ä»é¢å¯ä»¥å®¹ç´å¤ç¨®è¼¸å¥é¡åï¼ä¾å¦æå­ãèªé³åè¦è¨ï¼ä¸¦å¨åç¨®è£ç½®ä¸æä¾ç¡ç¸«çé«é©ãæ¬ææ¢è¨äºçæå¼ AI å¨ç¾ä»£ä½¿ç¨èä»é¢ä¸­çæ´åï¼æ¢è¨äºæ­·å²ç¼å±ï¼ä¸¦å°æ³¨æ¼å¤æ¨¡æäºåãè·¨å¹³å°é©ææ§ååæåäººåãä¸åæ ¸å¿ä¸»é¡æ¯ä»é¢å°å¢ï¼å®è§£æ±ºäºçºå¤æ¨¡æå¤§åèªè¨æ¨¡åè¨­è¨ææäºåçææ°ï¼è©ä¼°äºåå½¢ãèªé³åæ²æµ¸å¼ä»é¢ä¹éçåæ¨ãæ¬æé²ä¸æ­¥è©ä¼°äºå°çºè¡åå¹³å°éèº«æé çè¼éåæ¡æ¶ï¼å¼·èª¿äºè¡åç¡¬é«å¨å¯¦ç¾å¯æ´åå¤æ¨¡æ AI ä¸­ææ®æ¼çè§è²ãæè¡åå«çææ°ï¼åæ¬å§å®¹ä¿çãé±ç§åé¡ä»¥åå¹³è¡¡é²ç«¯åè£ç½®èçï¼é½ç¶éå¾¹åºæª¢è¦ãæå¾ï¼æ¬ææ¦è¿°äºæªä¾æ¹åï¼ä¾å¦æç·é©ææ§ä»é¢ãé æ¸¬æ§ AI é©åçä½¿ç¨èä»é¢åå³æåä½ç³»çµ±ï¼å¼·èª¿äºçæå¼ AI å¨è·¨å¹³å°éæ°å®ç¾©é©ææ§ä»¥ä½¿ç¨èçºä¸­å¿çä»é¢çæ½åã

##### **ColorEdit: Training-free Image-Guided Color editing with diffusion model**
2411.10232v1 by Xingxi Yin, Zhi Li, Jingfeng Zhang, Chenglin Li, Yin Zhang

Text-to-image (T2I) diffusion models, with their impressive generative
capabilities, have been adopted for image editing tasks, demonstrating
remarkable efficacy. However, due to attention leakage and collision between
the cross-attention map of the object and the new color attribute from the text
prompt, text-guided image editing methods may fail to change the color of an
object, resulting in a misalignment between the resulting image and the text
prompt. In this paper, we conduct an in-depth analysis on the process of
text-guided image synthesizing and what semantic information different
cross-attention blocks have learned. We observe that the visual representation
of an object is determined in the up-block of the diffusion model in the early
stage of the denoising process, and color adjustment can be achieved through
value matrices alignment in the cross-attention layer. Based on our findings,
we propose a straightforward, yet stable, and effective image-guided method to
modify the color of an object without requiring any additional fine-tuning or
training. Lastly, we present a benchmark dataset called COLORBENCH, the first
benchmark to evaluate the performance of color change methods. Extensive
experiments validate the effectiveness of our method in object-level color
editing and surpass the performance of popular text-guided image editing
approaches in both synthesized and real images.

æè¦ï¼ææ¬å°å¾å (T2I) æ©æ£æ¨¡ååå¶ä»¤äººå°è±¡æ·±å»ççæè½åå·²ç¨äºå¾åç¼è¾ä»»å¡ï¼å±ç°åºåè¶çåæãç¶èï¼ç±äºæ³¨æåæ³æ¼åæ¥èªææ¬æç¤ºçå¯¹è±¡äº¤åæ³¨æåå¾ä¸æ°é¢è²å±æ§ä¹é´çå²çªï¼ææ¬å¼å¯¼çå¾åç¼è¾æ¹æ³å¯è½æ æ³æ¹åå¯¹è±¡çé¡è²ï¼å¯¼è´çæå¾åä¸ææ¬æç¤ºä¹é´åºç°éä½ãå¨æ¬æä¸­ï¼æä»¬å¯¹ææ¬å¼å¯¼å¾ååæè¿ç¨ä»¥åä¸åäº¤åæ³¨æåæ¨¡åå­¦ä¹ å°çè¯­ä¹ä¿¡æ¯è¿è¡äºæ·±å¥åæãæä»¬è§å¯å°ï¼å¯¹è±¡çè§è§è¡¨å¾æ¯å¨æ©æ£æ¨¡åçä¸è¡æ¨¡åä¸­å¨å»åªè¿ç¨çæ©æé¶æ®µç¡®å®çï¼å¹¶ä¸å¯ä»¥éè¿äº¤åæ³¨æåå±ä¸­çå¼ç©éµå¯¹é½æ¥å®ç°é¢è²è°æ´ãæ ¹æ®æä»¬çåç°ï¼æä»¬æåºäºä¸ç§ç´æ¥ãç¨³å®ä¸ææçé¢åå¾åçæ¹æ³æ¥ä¿®æ¹å¯¹è±¡çé¡è²ï¼èæ éä»»ä½é¢å¤çå¾®è°æè®­ç»ãæåï¼æä»¬æåºäºä¸ä¸ªåä¸º COLORBENCH çåºåæ°æ®éï¼è¿æ¯ç¬¬ä¸ä¸ªè¯ä¼°é¢è²æ¹åæ¹æ³æ§è½çåºåãå¤§éçå®éªéªè¯äºæä»¬çæ¹æ³å¨å¯¹è±¡çº§é¢è²ç¼è¾ä¸­çæææ§ï¼å¹¶ä¸å¨åæå¾ååçå®å¾åä¸­é½è¶è¶äºæµè¡çææ¬å¼å¯¼å¾åç¼è¾æ¹æ³çæ§è½ã

##### **A Low-Resolution Image is Worth 1x1 Words: Enabling Fine Image Super-Resolution with Transformers and TaylorShift**
2411.10231v1 by Sanath Budakegowdanadoddi Nagaraju, Brian Bernhard Moser, Tobias Christian Nauen, Stanislav Frolov, Federico Raue, Andreas Dengel

Transformer-based Super-Resolution (SR) models have recently advanced image
reconstruction quality, yet challenges remain due to computational complexity
and an over-reliance on large patch sizes, which constrain fine-grained detail
enhancement. In this work, we propose TaylorIR to address these limitations by
utilizing a patch size of 1x1, enabling pixel-level processing in any
transformer-based SR model. To address the significant computational demands
under the traditional self-attention mechanism, we employ the TaylorShift
attention mechanism, a memory-efficient alternative based on Taylor series
expansion, achieving full token-to-token interactions with linear complexity.
Experimental results demonstrate that our approach achieves new
state-of-the-art SR performance while reducing memory consumption by up to 60%
compared to traditional self-attention-based transformers.

æè¦ï¼åºæ¼ Transformer çè¶è§£æåº¦ (SR) æ¨¡åæè¿æåäºå½±åéå»ºåè³ªï¼ä½ä»å éç®è¤éåº¦åéåº¦ä¾è³´å¤§ååå¡å¤§å°èé¢è¨ææ°ï¼éæéå¶ç´°ç·»ç´°ç¯çå¢å¼·ãå¨æ­¤ç ç©¶ä¸­ï¼æåæåº TaylorIR ä¾è§£æ±ºéäºéå¶ï¼æ¹æ³æ¯å©ç¨ 1x1 çåå¡å¤§å°ï¼è®ä»»ä½åºæ¼ Transformer ç SR æ¨¡åé½è½é²è¡åç´ å±¤ç´èçãçºäºæ»¿è¶³å³çµ±èªææ³¨ææ©å¶ä¸çéå¤§éç®éæ±ï¼æåæ¡ç¨ TaylorShift æ³¨æåæ©å¶ï¼éæ¯ä¸ç¨®åºæ¼ Taylor ç´æ¸å±éççè¨æ¶é«æ¿ä»£æ¹æ¡ï¼è½ä»¥ç·æ§è¤éåº¦å¯¦ç¾å®æ´ç token-to-token äºåãå¯¦é©çµæé¡¯ç¤ºï¼æåçåæ³å¯éææ°çè¶è§£æåº¦æè¡æ°´æºï¼åæèå³çµ±åºæ¼èªææ³¨æåç Transformer ç¸æ¯ï¼è¨æ¶é«æ¶èéæå¤å¯æ¸å° 60%ã

##### **Entropy and type-token ratio in gigaword corpora**
2411.10227v1 by Pablo Rosillo-Rodes, Maxi San Miguel, David Sanchez

Lexical diversity measures the vocabulary variation in texts. While its
utility is evident for analyses in language change and applied linguistics, it
is not yet clear how to operationalize this concept in a unique way. We here
investigate entropy and text-token ratio, two widely employed metrics for
lexical diversities, in six massive linguistic datasets in English, Spanish,
and Turkish, consisting of books, news articles, and tweets. These gigaword
corpora correspond to languages with distinct morphological features and differ
in registers and genres, thus constituting a diverse testbed for a quantitative
approach to lexical diversity. Strikingly, we find a functional relation
between entropy and text-token ratio that holds across the corpora under
consideration. Further, in the limit of large vocabularies we find an
analytical expression that sheds light on the origin of this relation and its
connection with both Zipf and Heaps laws. Our results then contribute to the
theoretical understanding of text structure and offer practical implications
for fields like natural language processing.

æè¦ï¼è©å½å¤æ¨£æ§æ¸¬éææ¬ä¸­çè©å½è®åãéç¶å®çæç¨å¨èªè¨è®é·åæç¨èªè¨å­¸çåæä¸­å¾æé¡¯ï¼ä½å¦ä½ä»¥ç¨ç¹çæ¹å¼å°éåæ¦å¿µå·é«åéä¸æ¯å¾æ¸æ¥ãæåå¨æ­¤æ¢è¨çµåææ¬ç¬¦èæ¯ï¼éæ¯è±èªãè¥¿ç­çèªååè³å¶èªä¸­å­åå»£æ³ä½¿ç¨çè©å½å¤æ¨£æ§ææ¨ï¼åæ¬æ¸ç±ãæ°èæç« åæ¨æãéäºåå å­èªæåº«å°ææ¼å·æä¸åå½¢æç¹å¾µçèªè¨ï¼ä¸¦ä¸å¨è¨»ååé¡åä¸ææä¸åï¼å æ­¤æ§æäºå°è©å½å¤æ¨£æ§é²è¡å®éæ¹æ³çä¸åçæ¸¬è©¦å¹³å°ãä»¤äººé©è¨çæ¯ï¼æåç¼ç¾çµåææ¬ç¬¦èæ¯ä¹éå­å¨ä¸ç¨®å½æ¸éä¿ï¼éç¨®éä¿å­å¨æ¼æèæ®çèªæåº«ä¸­ãæ­¤å¤ï¼å¨å¤§éè©å½çéå¶ä¸­ï¼æåç¼ç¾äºä¸ååæè¡¨éå¼ï¼å®é¡æäºéç¨®éä¿çèµ·æºåå¶èé½å¤«å®å¾åå¸æ®å®å¾çè¯ç¹«ãæåççµææå©æ¼å°ææ¬çµæ§ççè«çè§£ï¼ä¸¦çºèªç¶èªè¨èçç­é åæä¾äºå¯¦ç¨çæç¾©ã

##### **An Empirical Study on LLM-based Agents for Automated Bug Fixing**
2411.10213v1 by Xiangxin Meng, Zexiong Ma, Pengfei Gao, Chao Peng

Large language models (LLMs) and LLM-based Agents have been applied to fix
bugs automatically, demonstrating the capability in addressing software defects
by engaging in development environment interaction, iterative validation and
code modification. However, systematic analysis of these agent and non-agent
systems remain limited, particularly regarding performance variations among
top-performing ones. In this paper, we examine seven proprietary and
open-source systems on the SWE-bench Lite benchmark for automated bug fixing.
We first assess each system's overall performance, noting instances solvable by
all or none of these sytems, and explore why some instances are uniquely solved
by specific system types. We also compare fault localization accuracy at file
and line levels and evaluate bug reproduction capabilities, identifying
instances solvable only through dynamic reproduction. Through analysis, we
concluded that further optimization is needed in both the LLM itself and the
design of Agentic flow to improve the effectiveness of the Agent in bug fixing.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ååºæ¼ LLM çä»£çå·²æç¨æ¼èªåä¿®å¾©é¯èª¤ï¼å±ç¤ºäºééåèéç¼ç°å¢äºåãåè¦é©è­åç¨å¼ç¢¼ä¿®æ¹ä¾è§£æ±ºè»é«ç¼ºé·çè½åãç¶èï¼å°éäºä»£çåéä»£çç³»çµ±çç³»çµ±åæä»ç¶æéï¼ç¹å¥æ¯éæ¼é å°ç³»çµ±ä¹éçæè½å·®ç°ãå¨æ¬æä¸­ï¼æåå¨ SWE-bench Lite åºæºä¸æª¢æ¥äºä¸åå°æåéæºç³»çµ±ï¼ç¨æ¼èªåä¿®å¾©é¯èª¤ãæåé¦åè©ä¼°æ¯åç³»çµ±çæ´é«æè½ï¼è¨éææææ²æéäºç³»çµ±å¯ä»¥è§£æ±ºçå¯¦ä¾ï¼ä¸¦æ¢è¨çºä»éº¼æäºå¯¦ä¾æ¯ç±ç¹å®ç³»çµ±é¡åç¨ç¹è§£æ±ºçãæåéæ¯è¼äºæªæ¡åç¨å¼ç¢¼è¡çæéå®ä½æºç¢ºåº¦ï¼ä¸¦è©ä¼°é¯èª¤éç¾è½åï¼è­å¥åééåæéç¾æè½è§£æ±ºçå¯¦ä¾ãééåæï¼æåå¾åºçµè«ï¼éè¦é²ä¸æ­¥æä½³å LLM æ¬èº«åä»£çæµç¨çè¨­è¨ï¼ä»¥æé«ä»£çå¨é¯èª¤ä¿®å¾©ä¸­çæææ§ã

##### **FengWu-W2S: A deep learning model for seamless weather-to-subseasonal forecast of global atmosphere**
2411.10191v1 by Fenghua Ling, Kang Chen, Jiye Wu, Tao Han, Jing-Jia Luo, Wanli Ouyang, Lei Bai

Seamless forecasting that produces warning information at continuum
timescales based on only one system is a long-standing pursuit for
weather-climate service. While the rapid advancement of deep learning has
induced revolutionary changes in classical forecasting field, current efforts
are still focused on building separate AI models for weather and climate
forecasts. To explore the seamless forecasting ability based on one AI model,
we propose FengWu-Weather to Subseasonal (FengWu-W2S), which builds on the
FengWu global weather forecast model and incorporates an ocean-atmosphere-land
coupling structure along with a diverse perturbation strategy. FengWu-W2S can
generate 6-hourly atmosphere forecasts extending up to 42 days through an
autoregressive and seamless manner. Our hindcast results demonstrate that
FengWu-W2S reliably predicts atmospheric conditions out to 3-6 weeks ahead,
enhancing predictive capabilities for global surface air temperature,
precipitation, geopotential height and intraseasonal signals such as the
Madden-Julian Oscillation (MJO) and North Atlantic Oscillation (NAO). Moreover,
our ablation experiments on forecast error growth from daily to seasonal
timescales reveal potential pathways for developing AI-based integrated system
for seamless weather-climate forecasting in the future.

æè¦ï¼ç¡ç¸«é æ¸¬å¨é£çºæéå°ºåº¦ä¸åæ ¹æä¸åç³»çµ±ç¢çè­¦åè³è¨æ¯å¤©æ°£æ°£åæåçé·æè¿½æ±ãåç®¡æ·±åº¦å­¸ç¿çå¿«éé²å±å·²å°ç¶å¸é æ¸¬é åç¢çé©å½æ§çè®åï¼ä½ç®åçåªåä»éä¸­æ¼çºå¤©æ°£åæ°£åé æ¸¬å»ºç«å®ç¨ç AI æ¨¡åãçºäºæ¢ç´¢åºæ¼ä¸å AI æ¨¡åçç¡ç¸«é æ¸¬è½åï¼æåæåº FengWu-Weather to Subseasonalï¼FengWu-W2Sï¼ï¼å®å»ºç«å¨ FengWu å¨çå¤©æ°£é æ¸¬æ¨¡åä¹ä¸ï¼ä¸¦çµåäºæµ·æ´-å¤§æ°£-é¸å°è¦åçµæ§ä»¥åå¤æ¨£åçæ¾åç­ç¥ãFengWu-W2S å¯ä»¥ééèªè¿´æ­¸åç¡ç¸«çæ¹å¼ç¢çé·é 42 å¤©ç 6 å°æå¤§æ°£é æ¸¬ãæåçå¾é©é æ¸¬çµæè¡¨æï¼FengWu-W2S å¯é å°é æ¸¬åº 3-6 é±å¾çå¤§æ°£æ¢ä»¶ï¼å¢å¼·äºå°å¨çå°è¡¨æ°£æº«ãéæ°´ãå°å¢é«åº¦åå­£ç¯å§ä¿¡èï¼å¦ Madden-Julian æ¯çª (MJO) ååå¤§è¥¿æ´æ¯çª (NAO)ï¼çé æ¸¬è½åãæ­¤å¤ï¼æåå¾æ¯æ¥å°å­£ç¯æéå°ºåº¦çé æ¸¬èª¤å·®å¢é·ä¸­é²è¡çæ¶èå¯¦é©æ­ç¤ºäºæªä¾éç¼åºæ¼ AI çç¡ç¸«å¤©æ°£æ°£åé æ¸¬æ´åç³»çµ±çæ½å¨éå¾ã

##### **Agentic LLMs in the Supply Chain: Towards Autonomous Multi-Agent Consensus-Seeking**
2411.10184v1 by Valeria Jannelli, Stefan Schoepf, Matthias Bickel, TorbjÃ¸rn Netland, Alexandra Brintrup

This paper explores how Large Language Models (LLMs) can automate
consensus-seeking in supply chain management (SCM), where frequent decisions on
problems such as inventory levels and delivery times require coordination among
companies. Traditional SCM relies on human consensus in decision-making to
avoid emergent problems like the bullwhip effect. Some routine consensus
processes, especially those that are time-intensive and costly, can be
automated. Existing solutions for automated coordination have faced challenges
due to high entry barriers locking out SMEs, limited capabilities, and limited
adaptability in complex scenarios. However, recent advances in Generative AI,
particularly LLMs, show promise in overcoming these barriers. LLMs, trained on
vast datasets can negotiate, reason, and plan, facilitating near-human-level
consensus at scale with minimal entry barriers. In this work, we identify key
limitations in existing approaches and propose autonomous LLM agents to address
these gaps. We introduce a series of novel, supply chain-specific
consensus-seeking frameworks tailored for LLM agents and validate the
effectiveness of our approach through a case study in inventory management. To
accelerate progress within the SCM community, we open-source our code,
providing a foundation for further advancements in LLM-powered autonomous
supply chain solutions.

æè¦ï¼æ¬ææ¢è¨å¤§åèªè¨æ¨¡å (LLM) å¦ä½èªååä¾æéç®¡ç (SCM) ä¸­çå±è­å°æ±ï¼å¶ä¸­æéåº«å­æ°´æºåäº¤è²¨æéç­åé¡çé »ç¹æ±ºç­éè¦åå¬å¸ä¹éçåèª¿ãå³çµ±ç SCM ä¾è³´æ¼æ±ºç­å¶å®ä¸­çäººçºå±è­ï¼ä»¥é¿åçé­ææç­çªç¼åé¡ãæäºä¾è¡å±è­æµç¨ï¼å°¤å¶æ¯é£äºèæä¸ææ¬é«æçæµç¨ï¼å¯ä»¥èªååãç¾æçèªåååèª¿è§£æ±ºæ¹æ¡å é«é²å¥éæª»å°ä¸­å°åä¼æ¥­æä¹éå¤ãåè½åéä»¥åå¨è¤éå ´æ¯ä¸­é©ææ§ä¸è¶³ç­ææ°èé¢è¨å°å¢ãç¶èï¼çæå¼ AI çææ°é²å±ï¼å°¤å¶æ¯ LLMï¼é¡¯ç¤ºåºåæéäºéç¤çå¸æãå¨é¾å¤§è³æéä¸è¨ç·´ç LLM å¯ä»¥ååãæ¨çåè¦åï¼å¾èä»¥æå°çé²å¥éæª»ä¿é²æ¥è¿äººé¡æ°´æºçå¤§è¦æ¨¡å±è­ãå¨éé å·¥ä½ä¸­ï¼æåæ¾åºç¾ææ¹æ³ä¸­çä¸»è¦éå¶ï¼ä¸¦æåºèªä¸» LLM ä»£çä¾è§£æ±ºéäºå·®è·ãæåå¼å¥ä¸ç³»åéå° LLM ä»£çéèº«æé çæ°ç©ä¾æéç¹å®å±è­å°æ±æ¡æ¶ï¼ä¸¦ééåº«å­ç®¡çä¸­çåæ¡ç ç©¶é©è­æåæ¹æ³çæææ§ãçºäºå é SCM ç¤¾ç¾¤å§çé²å±ï¼æåéæ¾åå§ç¢¼ï¼çº LLM é©åçèªä¸»ä¾æéè§£æ±ºæ¹æ¡çé²ä¸æ­¥é²å±å¥ å®åºç¤ã

##### **The Surprising Ineffectiveness of Pre-Trained Visual Representations for Model-Based Reinforcement Learning**
2411.10175v1 by Moritz Schneider, Robert Krug, Narunas Vaskevicius, Luigi Palmieri, Joschka Boedecker

Visual Reinforcement Learning (RL) methods often require extensive amounts of
data. As opposed to model-free RL, model-based RL (MBRL) offers a potential
solution with efficient data utilization through planning. Additionally, RL
lacks generalization capabilities for real-world tasks. Prior work has shown
that incorporating pre-trained visual representations (PVRs) enhances sample
efficiency and generalization. While PVRs have been extensively studied in the
context of model-free RL, their potential in MBRL remains largely unexplored.
In this paper, we benchmark a set of PVRs on challenging control tasks in a
model-based RL setting. We investigate the data efficiency, generalization
capabilities, and the impact of different properties of PVRs on the performance
of model-based agents. Our results, perhaps surprisingly, reveal that for MBRL
current PVRs are not more sample efficient than learning representations from
scratch, and that they do not generalize better to out-of-distribution (OOD)
settings. To explain this, we analyze the quality of the trained dynamics
model. Furthermore, we show that data diversity and network architecture are
the most important contributors to OOD generalization performance.

æè¦ï¼è¦è¦ºå¼·åå­¸ç¿ (RL) æ¹æ³éå¸¸éè¦å¤§éè³æãèç¡æ¨¡å RL ç¸æ¯ï¼åºæ¼æ¨¡åç RL (MBRL) æä¾äºä¸ç¨®æ½å¨çè§£æ±ºæ¹æ¡ï¼å¯ééè¦åææå©ç¨è³æãæ­¤å¤ï¼RL ç¼ºä¹éå°çå¯¦ä¸çä»»åçæ³åè½åãååçç ç©¶è¡¨æï¼å å¥é åè¨ç·´çè¦è¦ºè¡¨å¾µ (PVR) å¯æé«åæ¨£æçåæ³åè½åãéç¶ PVR å·²å¨ç¡æ¨¡å RL çèæ¯ä¸å»£æ³ç ç©¶ï¼ä½å®åå¨ MBRL ä¸­çæ½åä»æªè¢«ååæ¢ç´¢ãå¨æ¬æä¸­ï¼æåå¨åºæ¼æ¨¡åç RL è¨­å®ä¸­å°å·æææ°æ§çæ§å¶ä»»åé²è¡ä¸çµ PVR çåºæºæ¸¬è©¦ãæåæ¢è¨è³ææçãæ³åè½åï¼ä»¥å PVR çä¸åå±¬æ§å°åºæ¼æ¨¡åä»£çç¨å¼æè½çå½±é¿ãæåççµæä¹è¨±ä»¤äººé©è¨å°æ­ç¤ºï¼å°æ¼ MBRLï¼ç®åç PVR ä¸¦ä¸æ¯å¾é ­éå§å­¸ç¿è¡¨å¾µæ´è½ææå©ç¨åæ¨£ï¼èä¸å®åå¨ä¸ç¬¦ååä½ (OOD) è¨­å®ä¸çæ³åè½åä¸¦æªæ´å¥½ãçºäºè§£ééä¸é»ï¼æååæäºè¨ç·´åææ¨¡åçåè³ªãæ­¤å¤ï¼æåè­æè³æå¤æ¨£æ§åç¶²è·¯æ¶æ§æ¯ OOD æ³åæè½æéè¦çè²¢ç»èã

##### **A Hard-Label Cryptanalytic Extraction of Non-Fully Connected Deep Neural Networks using Side-Channel Attacks**
2411.10174v1 by Benoit Coqueret, Mathieu Carbone, Olivier Sentieys, Gabriel Zaid

During the past decade, Deep Neural Networks (DNNs) proved their value on a
large variety of subjects. However despite their high value and public
accessibility, the protection of the intellectual property of DNNs is still an
issue and an emerging research field. Recent works have successfully extracted
fully-connected DNNs using cryptanalytic methods in hard-label settings,
proving that it was possible to copy a DNN with high fidelity, i.e., high
similitude in the output predictions. However, the current cryptanalytic
attacks cannot target complex, i.e., not fully connected, DNNs and are limited
to special cases of neurons present in deep networks.
  In this work, we introduce a new end-to-end attack framework designed for
model extraction of embedded DNNs with high fidelity. We describe a new
black-box side-channel attack which splits the DNN in several linear parts for
which we can perform cryptanalytic extraction and retrieve the weights in
hard-label settings. With this method, we are able to adapt cryptanalytic
extraction, for the first time, to non-fully connected DNNs, while maintaining
a high fidelity. We validate our contributions by targeting several
architectures implemented on a microcontroller unit, including a Multi-Layer
Perceptron (MLP) of 1.7 million parameters and a shortened MobileNetv1. Our
framework successfully extracts all of these DNNs with high fidelity (88.4% for
the MobileNetv1 and 93.2% for the MLP). Furthermore, we use the stolen model to
generate adversarial examples and achieve close to white-box performance on the
victim's model (95.8% and 96.7% transfer rate).

æè¦ï¼<paragraph>å¨éå»çåå¹´ä¸­ï¼æ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) å·²è­æå¶å¨åç¨®ä¸»é¡ä¸çå¹å¼ãç¶èï¼åç®¡å®åå¹å¼å¾é«ä¸å¬éå¯åå¾ï¼ä½ DNN çæºæ§è²¡ç¢æ¬ä¿è­·ä»ç¶æ¯ä¸ååé¡åä¸åæ°èçç ç©¶é åãæè¿çç ç©¶å·²æåä½¿ç¨å¯ç¢¼åææ¹æ³å¨ç¡¬æ¨ç±¤è¨­å®ä¸­æåå®å¨é£æ¥ç DNNï¼è­æå¯ä»¥é«ä¿çè¤è£½ DNNï¼å³è¼¸åºé æ¸¬ä¸­çé«ç¸ä¼¼åº¦ãç¶èï¼ç®åçå¯ç¢¼åææ»æç¡æ³éå°è¤éçï¼å³éå®å¨é£æ¥çï¼DNNï¼ä¸¦ä¸åéæ¼æ·±åº¦ç¶²è·¯ä¸­å­å¨çç¥ç¶åç¹æ®ææ³ã
å¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºä¸åæ°çç«¯å°ç«¯æ»ææ¡æ¶ï¼å°éç¨æ¼é«ä¿çæååµå¥å¼ DNN çæ¨¡åãæåæè¿°äºä¸ç¨®æ°çé»çå´ä¿¡éæ»æï¼å®å° DNN åå²æå¹¾åç·æ§é¨åï¼æåå¯ä»¥å°å¶å·è¡å¯ç¢¼åææåä¸¦å¨ç¡¬æ¨ç±¤è¨­å®ä¸­æª¢ç´¢æ¬éãä½¿ç¨æ­¤æ¹æ³ï¼æåé¦æ¬¡è½å¤ å°å¯ç¢¼åææåé©æå°éå®å¨é£æ¥ç DNNï¼åæä¿æé«ä¿çåº¦ãæåéééå°å¨å¾®æ§å¶å¨å®åä¸å¯¦ä½çå¹¾åæ¶æ§ä¾é©è­æåçè²¢ç»ï¼åæ¬ä¸åå·æ 170 è¬ååæ¸çå¤å±¤æç¥å¨ (MLP) åä¸åç¸®ç­ç MobileNetv1ãæåçæ¡æ¶æåå°ä»¥é«ä¿çåº¦æåäºææéäº DNNï¼MobileNetv1 çº 88.4%ï¼MLP çº 93.2%ï¼ãæ­¤å¤ï¼æåä½¿ç¨è¢«ç«åçæ¨¡åä¾ç¢çå°ææ§ç¯ä¾ï¼ä¸¦å¨åå®³èçæ¨¡åä¸å¯¦ç¾æ¥è¿ç½çæè½ï¼å³è¼¸ççº 95.8% å 96.7%ï¼ã</paragraph>

##### **Increasing the Accessibility of Causal Domain Knowledge via Causal Information Extraction Methods: A Case Study in the Semiconductor Manufacturing Industry**
2411.10172v1 by Houssam Razouk, Leonie Benischke, Daniel Garber, Roman Kern

The extraction of causal information from textual data is crucial in the
industry for identifying and mitigating potential failures, enhancing process
efficiency, prompting quality improvements, and addressing various operational
challenges. This paper presents a study on the development of automated methods
for causal information extraction from actual industrial documents in the
semiconductor manufacturing industry. The study proposes two types of causal
information extraction methods, single-stage sequence tagging (SST) and
multi-stage sequence tagging (MST), and evaluates their performance using
existing documents from a semiconductor manufacturing company, including
presentation slides and FMEA (Failure Mode and Effects Analysis) documents. The
study also investigates the effect of representation learning on downstream
tasks. The presented case study showcases that the proposed MST methods for
extracting causal information from industrial documents are suitable for
practical applications, especially for semi structured documents such as FMEAs,
with a 93\% F1 score. Additionally, MST achieves a 73\% F1 score on texts
extracted from presentation slides. Finally, the study highlights the
importance of choosing a language model that is more aligned with the domain
and in-domain fine-tuning.

æè¦ï¼å¾ææ¬è³æä¸­èåå æè³è¨å°æ¼ç¢æ¥­ä¾èªªè³ééè¦ï¼å¯ä»¥æ¾åºä¸¦æ¸è¼æ½å¨æéãæåæµç¨æçãä¿ä½¿åè³ªæ¹åï¼ä¸¦è§£æ±ºåç¨®çéææ°ãæ¬ç¯è«ææ¢è¨èªååæ¹æ³å¨åå°é«è£½é ç¢æ¥­ä¸­å¾å¯¦éç¢æ¥­æä»¶èåå æè³è¨çç¼å±ãæ¬ç ç©¶æåºå©ç¨®å æè³è¨èåæ¹æ³ï¼å®éæ®µåºåæ¨è¨» (SST) åå¤éæ®µåºåæ¨è¨» (MST)ï¼ä¸¦ä½¿ç¨åå°é«è£½é å¬å¸çæ¢ææä»¶è©ä¼°å¶æè½ï¼åæ¬ç°¡å ±æå½±çå FMEAï¼æéæ¨¡å¼èå½±é¿åæï¼æä»¶ãæ¬ç ç©¶ä¹æ¢è¨è¡¨å¾µå­¸ç¿å°ä¸æ¸¸ä»»åçå½±é¿ãæåºçåæ¡ç ç©¶å±ç¤ºï¼æåºç MST æ¹æ³ç¨æ¼å¾ç¢æ¥­æä»¶ä¸­èåå æè³è¨ï¼é©åå¯¦éæç¨ï¼ç¹å¥æ¯å°æ¼åçµæ§åæä»¶ï¼ä¾å¦ FMEAï¼ï¼F1 åæ¸çº 93%ãæ­¤å¤ï¼MST å¨å¾ç°¡å ±æå½±çä¸­èåçæå­ä¸éå° 73% ç F1 åæ¸ãæå¾ï¼æ¬ç ç©¶å¼·èª¿é¸æèé åæ´ä¸è´çèªè¨æ¨¡åï¼ä»¥åé åå§å¾®èª¿çéè¦æ§ã

##### **Imagine-2-Drive: High-Fidelity World Modeling in CARLA for Autonomous Vehicles**
2411.10171v1 by Anant Garg, K Madhava Krishna

In autonomous driving with image based state space, accurate prediction of
future events and modeling diverse behavioral modes are essential for safety
and effective decision-making. World model-based Reinforcement Learning (WMRL)
approaches offers a promising solution by simulating future states from current
state and actions. However, utility of world models is often limited by typical
RL policies being limited to deterministic or single gaussian distribution. By
failing to capture the full spectrum of possible actions, reduces their
adaptability in complex, dynamic environments. In this work, we introduce
Imagine-2-Drive, a framework that consists of two components, VISTAPlan, a
high-fidelity world model for accurate future prediction and Diffusion Policy
Actor (DPA), a diffusion based policy to model multi-modal behaviors for
trajectory prediction. We use VISTAPlan to simulate and evaluate trajectories
from DPA and use Denoising Diffusion Policy Optimization (DDPO) to train DPA to
maximize the cumulative sum of rewards over the trajectories. We analyze the
benefits of each component and the framework as a whole in CARLA with standard
driving metrics. As a consequence of our twin novelties- VISTAPlan and DPA, we
significantly outperform the state of the art (SOTA) world models on standard
driving metrics by 15% and 20% on Route Completion and Success Rate
respectively.

æè¦ï¼å¨ä»¥å½±åçºåºç¤ççæç©ºéä¸­é²è¡èªåé§é§æï¼æºç¢ºé æ¸¬æªä¾äºä»¶åå»ºæ¨¡å¤æ¨£åçè¡çºæ¨¡å¼å°æ¼å®å¨åææçæ±ºç­å¶å®è³ééè¦ãåºæ¼ä¸çæ¨¡åçå¼·åå­¸ç¿ (WMRL) æ¹æ³ééå¾ç¶åçæååä½æ¨¡æ¬æªä¾çæï¼æä¾äºä¸åæåéçè§£æ±ºæ¹æ¡ãç¶èï¼ä¸çæ¨¡åçæç¨éå¸¸åå°å¸å RL ç­ç¥åéæ¼ç¢ºå®æ§æå®ä¸é«æ¯åå¸çéå¶ãç±æ¼æªè½ææå°ææå¯è½çåä½ï¼éä½äºå®åå¨è¤éãåæç°å¢ä¸­çé©ææ§ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº Imagine-2-Driveï¼ä¸åç±å©åçµæé¨åçµæçæ¡æ¶ï¼VISTAPlanï¼ä¸åç¨æ¼æºç¢ºæªä¾é æ¸¬çé«ä¿çä¸çæ¨¡ååæ´æ£ç­ç¥å·è¡å¨ (DPA)ï¼ä¸ååºæ¼æ´æ£çç­ç¥ï¼ç¨æ¼å°å¤æ¨¡æè¡çºé²è¡å»ºæ¨¡ä»¥é²è¡è»è·¡é æ¸¬ãæåä½¿ç¨ VISTAPlan å¾ DPA æ¨¡æ¬åè©ä¼°è»è·¡ï¼ä¸¦ä½¿ç¨å»åªæ´æ£ç­ç¥åªå (DDPO) è¨ç·´ DPA ä»¥æå¤§åè»è·¡ä¸çåµçç´¯è¨åãæååæäºæ¯åçµæé¨ååæ´åæ¡æ¶å¨ CARLA ä¸­çåªé»ï¼ä¸¦ä½¿ç¨æ¨æºçé§é§ææ¨ãä½çºæå VISTAPlan å DPA éå©åæ°ç©ä¹èççµæï¼æåå¨æ¨æºé§é§ææ¨ä¸é¡¯èåªæ¼æåé² (SOTA) çä¸çæ¨¡åï¼å¨è·¯ç·å®æåæåçä¸åå¥æé«äº 15% å 20%ã

##### **Evaluating the role of `Constitutions' for learning from AI feedback**
2411.10168v1 by Saskia Redgate, Andrew M. Bean, Adam Mahdi

The growing capabilities of large language models (LLMs) have led to their
use as substitutes for human feedback for training and assessing other LLMs.
These methods often rely on `constitutions', written guidelines which a critic
model uses to provide feedback and improve generations. We investigate how the
choice of constitution affects feedback quality by using four different
constitutions to improve patient-centered communication in medical interviews.
In pairwise comparisons conducted by 215 human raters, we found that detailed
constitutions led to better results regarding emotive qualities. However, none
of the constitutions outperformed the baseline in learning more
practically-oriented skills related to information gathering and provision. Our
findings indicate that while detailed constitutions should be prioritised,
there are possible limitations to the effectiveness of AI feedback as a reward
signal in certain areas.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼åè½ä¸æ·å¢å¼·ï¼ä¿ä½¿å®åè¢«ç¨ä½äººé¡åé¥çæ¿ä»£åï¼ä»¥è¨ç·´åè©ä¼°å¶ä» LLMãéäºæ¹æ³éå¸¸ä¾è³´æ¼ãæ²æ³ãï¼ä¹å°±æ¯è©è«æ¨¡åç¨ä¾æä¾åé¥åæ¹é²çæçæ¸é¢æºåãæåæ¢è¨æ²æ³é¸æå¦ä½å½±é¿åé¥åè³ªï¼æ¹æ³æ¯ä½¿ç¨åç¨®ä¸åçæ²æ³ä¾æ¹åé«çè¨ªè«ä¸­çä»¥æ£èçºä¸­å¿çæºéãå¨ 215 ä½äººé¡è©åå¡é²è¡çæå°æ¯è¼ä¸­ï¼æåç¼ç¾è©³ç´°çæ²æ³å¨æç·åè³ªæ¹é¢å¸¶ä¾æ´å¥½ççµæãç¶èï¼æ²æä»»ä½æ²æ³å¨å­¸ç¿èè³è¨æ¶éåæä¾ç¸éçæ´å¯¦ç¨æè½æ¹é¢åªæ¼åºæºãæåçç ç©¶çµæè¡¨æï¼éç¶æåªåèæ®è©³ç´°çæ²æ³ï¼ä½ AI åé¥ä½çºç¹å®é åççåµè¨èçæææ§å¯è½æéã

##### **Compound-QA: A Benchmark for Evaluating LLMs on Compound Questions**
2411.10163v1 by Yutao Hou, Yajing Luo, Zhiwen Ruan, Hongru Wang, Weifeng Ge, Yun Chen, Guanhua Chen

Large language models (LLMs) demonstrate remarkable performance across
various tasks, prompting researchers to develop diverse evaluation benchmarks.
However, existing benchmarks typically measure the ability of LLMs to respond
to individual questions, neglecting the complex interactions in real-world
applications. In this paper, we introduce Compound Question Synthesis (CQ-Syn)
to create the Compound-QA benchmark, focusing on compound questions with
multiple sub-questions. This benchmark is derived from existing QA datasets,
annotated with proprietary LLMs and verified by humans for accuracy. It
encompasses five categories: Factual-Statement, Cause-and-Effect,
Hypothetical-Analysis, Comparison-and-Selection, and Evaluation-and-Suggestion.
It evaluates the LLM capability in terms of three dimensions including
understanding, reasoning, and knowledge. Our assessment of eight open-source
LLMs using Compound-QA reveals distinct patterns in their responses to compound
questions, which are significantly poorer than those to non-compound questions.
Additionally, we investigate various methods to enhance LLMs performance on
compound questions. The results indicate that these approaches significantly
improve the models' comprehension and reasoning abilities on compound
questions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­å±ç¾åºé¡¯èçæè½ï¼ä¿ä½¿ç ç©¶äººå¡éç¼å¤åçè©éåºæºãä¸éï¼ç¾æçåºæºéå¸¸æ¸¬é LLM åæåå¥åé¡çè½åï¼å¿½ç¥äºçå¯¦ä¸çæç¨ä¸­çè¤éäºåãå¨æ¬æä¸­ï¼æåä»ç´¹è¤ååé¡åæ (CQ-Syn) ä¾å»ºç«è¤åå¼åç­åºæºï¼éé»å¨æ¼å·æå¤åå­åé¡çè¤åå¼åé¡ãæ­¤åºæºä¾èªç¾æçåç­è³æéï¼ç±å°æç LLM å ä¸è¨»è§£ï¼ä¸¦ç±äººé¡é©è­å¶æºç¢ºæ§ãå®åå«äºåé¡å¥ï¼äºå¯¦é³è¿°ãå æéä¿ãåè¨­åæãæ¯è¼èé¸æï¼ä»¥åè©ä¼°èå»ºè­°ãå®å¨çè§£ãæ¨çåç¥è­ç­ä¸åé¢åè©ä¼° LLM çè½åãæåä½¿ç¨è¤åå¼åç­è©ä¼°å«åéæº LLMï¼æ­é²å®åå¨åæè¤åå¼åé¡æçä¸åæ¨¡å¼ï¼é¡¯èä½æ¼éè¤åå¼åé¡çæ¨¡å¼ãæ­¤å¤ï¼æåæ¢è¨åç¨®æ¹æ³ä¾å¢å¼· LLM å¨è¤åå¼åé¡ä¸çæè½ãçµæé¡¯ç¤ºï¼éäºæ¹æ³é¡¯èæ¹åæ¨¡åå¨è¤åå¼åé¡ä¸ççè§£åæ¨çè½åã

##### **Mitigating Sycophancy in Decoder-Only Transformer Architectures: Synthetic Data Intervention**
2411.10156v1 by Libo Wang

To address the sycophancy problem caused by reinforcement learning from human
feedback in large language models, this research applies synthetic data
intervention technology to the decoder-only transformer architecture. Based on
the research gaps in the existing literature, the researcher designed an
experimental process to reduce the tendency of models to cater by generating
diversified data, and used GPT4o as an experimental tool for verification. The
experiment used 100 true and false questions, and compared the performance of
the model trained with synthetic data intervention and the original untrained
model on multiple indicators. The results show that the SDI training model
supports the technology in terms of accuracy rate and sycophancy rate and has
significant effectiveness in reducing sycophancy phenomena. Notably, the data
set, experimental process, code and data results have been uploaded to Github,
the link is https://github.com/brucewang123456789/GeniusTrail.git.

æè¦ï¼çºäºè§£æ±ºå¤§åèªè¨æ¨¡åä¸­å äººé¡åé¥çå¼·åå­¸ç¿æé æçé¿è«å¥æ¿åé¡ï¼æ¬ç ç©¶å°åæè³æä»å¥æè¡æç¨æ¼åè§£ç¢¼å¨Transformeræ¶æ§ä¸­ãç ç©¶èåºæ¼ç¾ææç»ä¸­çç ç©¶ç¼ºå£ï¼è¨­è¨äºä¸åå¯¦é©æµç¨ï¼ééçæå¤åè³æä¾æ¸å°æ¨¡åè¿åçå¾åï¼ä¸¦ä»¥ GPT4o ä½çºé©è­çå¯¦é©å·¥å·ãå¯¦é©ä¸­æ¡ç¨ 100 é¡æ¯éé¡ï¼ä¸¦æ¯è¼äºä½¿ç¨åæè³æä»å¥è¨ç·´çæ¨¡åèåæªè¨ç·´æ¨¡åå¨å¤é ææ¨ä¸çè¡¨ç¾ãçµæé¡¯ç¤ºï¼SDI è¨ç·´æ¨¡åå¨æºç¢ºçèé¿è«å¥æ¿çä¸ï¼çæ¯æäºæè¡å°æ¼æ¸å°é¿è«å¥æ¿ç¾è±¡çé¡¯èææãç¹å¥çæ¯ï¼è³æéãå¯¦é©æµç¨ãç¨å¼ç¢¼èè³æçµæå·²ä¸å³è³ Githubï¼é£çµçº https://github.com/brucewang123456789/GeniusTrail.gitã

##### **Causal Time-Series Synchronization for Multi-Dimensional Forecasting**
2411.10152v1 by Michael Mayr, Georgios C. Chasparis, Josef KÃ¼ng

The process industry's high expectations for Digital Twins require modeling
approaches that can generalize across tasks and diverse domains with
potentially different data dimensions and distributional shifts i.e.,
Foundational Models. Despite success in natural language processing and
computer vision, transfer learning with (self-) supervised signals for
pre-training general-purpose models is largely unexplored in the context of
Digital Twins in the process industry due to challenges posed by
multi-dimensional time-series data, lagged cause-effect dependencies, complex
causal structures, and varying number of (exogenous) variables. We propose a
novel channel-dependent pre-training strategy that leverages synchronized
cause-effect pairs to overcome these challenges by breaking down the
multi-dimensional time-series data into pairs of cause-effect variables. Our
approach focuses on: (i) identifying highly lagged causal relationships using
data-driven methods, (ii) synchronizing cause-effect pairs to generate training
samples for channel-dependent pre-training, and (iii) evaluating the
effectiveness of this approach in channel-dependent forecasting. Our
experimental results demonstrate significant improvements in forecasting
accuracy and generalization capability compared to traditional training
methods.

æè¦ï¼è£½ç¨ç¢æ¥­å°æ¸ä½åèº«çé«ææéè¦å»ºæ¨¡æ¹æ³ï¼éäºæ¹æ³è½å¤ å¨ä»»ååä¸åçé åä¸­æ¦åï¼ä¸¦å·ææ½å¨ä¸åçè³æç¶­åº¦ååä½è½ç§»ï¼ä¹å°±æ¯åºç¤æ¨¡åãåç®¡å¨èªç¶èªè¨èçåé»è¦è¦è¦ºæ¹é¢ç²å¾æåï¼ä½éå°è£½ç¨ç¢æ¥­ä¸­çæ¸ä½åèº«ï¼å©ç¨ï¼èªæï¼ç£ç£è¨èé²è¡è½ç§»å­¸ç¿ä»¥é åè¨ç·´éç¨æ¨¡åå¨å¾å¤§ç¨åº¦ä¸ä»æªæ¢ç´¢ï¼åå å¨æ¼å¤ç¶­æéåºåè³æãæ»¯å¾å æä¾è³´æ§ãè¤éå æçµæ§åè®æ¸ï¼å¤çï¼æ¸éå¤è®æå¸¶ä¾çææ°ãæåæåºäºä¸ç¨®æ°ç©çééä¾è³´é è¨ç·´ç­ç¥ï¼è©²ç­ç¥å©ç¨åæ­¥çå æå°ä¾åæéäºææ°ï¼æ¹æ³æ¯å°å¤ç¶­æéåºåè³æåè§£æå æè®æ¸å°ãæåçåæ³èéæ¼ï¼(i) ä½¿ç¨è³æé©åæ¹æ³è­å¥é«åº¦æ»¯å¾çå æéä¿ï¼(ii) åæ­¥å æå°ä»¥ç¢çééä¾è³´é è¨ç·´çè¨ç·´æ¨£æ¬ï¼ä»¥å (iii) è©ä¼°æ­¤æ¹æ³å¨ééä¾è³´é æ¸¬ä¸­çæææ§ãæåçå¯¦é©çµæé¡¯ç¤ºï¼èå³çµ±è¨ç·´æ¹æ³ç¸æ¯ï¼é æ¸¬æºç¢ºåº¦åæ¦åè½åæé¡¯èçæåã

##### **An Effective Framework to Help Large Language Models Handle Numeric-involved Long-context Tasks**
2411.10145v1 by Yijiong Yu

Large Language Models (LLMs) have demonstrated remarkable capabilities in
handling long texts and have almost perfect performance in traditional
retrieval tasks. However, their performance significantly degrades when it
comes to numerical calculations in the long-context. Numeric-involved
long-context tasks typically cannot be addressed by current LLMs in normal
settings due to their inherent limitations in simultaneously handling complex
and massive information. Some CoT like prompting methods can improve accuracy
but demands massive output tokens, which is costly and slow. To address this
issue, we propose a workflow, which decompose a numeric-involved long-context
task into 4 low-level subtasks: judging, extracting and processing with code
and conclusion. The former 2 subtasks is relatively simple, which allows us to
use smaller models for efficiently processing long context. When numerical
calculations are required, we use code generated by LLMs to avoid the
disadvantage of LLM not being good at calculations. The results in 2
numeric-involved long-context benchmarks demonstrate our workflow can not only
improve accuracy, but also significantly reduce the cost of API calls.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èçé·ç¯æå­æ¹é¢å±ç¾åºé©äººçè½åï¼å¨å³çµ±çæª¢ç´¢ä»»åä¸­è¡¨ç¾è¿ä¹å®ç¾ãç¶èï¼å¨èçé·èªå¢ä¸­çæ¸å¼è¨ç®æï¼å®åçè¡¨ç¾å»å¤§å¹ä¸éãç±æ¼ LLM æ¬èº«å¨åæèçè¤éä¸å¤§éçè³è¨ææå¶éå¶ï¼å æ­¤æ¶åæ¸å¼çé·èªå¢ä»»åéå¸¸ç¡æ³å¨æ­£å¸¸è¨­å®ä¸ç±ç®åç LLM èçãä¸äº CoTï¼ä¾å¦æç¤ºæ¹æ³ï¼å¯ä»¥æé«æºç¢ºæ§ï¼ä½éè¦å¤§éçè¼¸åº tokenï¼éæ¢æè²´åç·©æ¢ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åå·¥ä½æµç¨ï¼å°æ¶åæ¸å¼çé·èªå¢ä»»ååè§£çº 4 åä½éå­ä»»åï¼å¤æ·ãèååèçç¨å¼ç¢¼ä»¥åçµè«ãå 2 åå­ä»»åç¸å°ç°¡å®ï¼éè®æåå¾ä»¥ä½¿ç¨è¼å°çæ¨¡åä¾ææèçé·èªå¢ãç¶éè¦æ¸å¼è¨ç®æï¼æåæä½¿ç¨ LLM çæçç¨å¼ç¢¼ä¾é¿å LLM ä¸æé·è¨ç®çç¼ºé»ãå¨ 2 åæ¶åæ¸å¼çé·èªå¢åºæºæ¸¬è©¦ä¸­ççµæé¡¯ç¤ºï¼æåçéåå·¥ä½æµç¨ä¸åå¯ä»¥æé«æºç¢ºæ§ï¼éè½å¤§å¹éä½ API å¼å«çææ¬ã

##### **Legal Evalutions and Challenges of Large Language Models**
2411.10137v1 by Jiaqi Wang, Huan Zhao, Zhenyuan Yang, Peng Shu, Junhao Chen, Haobo Sun, Ruixi Liang, Shixin Li, Pengcheng Shi, Longjun Ma, Zongjia Liu, Zhengliang Liu, Tianyang Zhong, Yutong Zhang, Chong Ma, Xin Zhang, Tuo Zhang, Tianli Ding, Yudan Ren, Tianming Liu, Xi Jiang, Shu Zhang

In this paper, we review legal testing methods based on Large Language Models
(LLMs), using the OPENAI o1 model as a case study to evaluate the performance
of large models in applying legal provisions. We compare current
state-of-the-art LLMs, including open-source, closed-source, and legal-specific
models trained specifically for the legal domain. Systematic tests are
conducted on English and Chinese legal cases, and the results are analyzed in
depth. Through systematic testing of legal cases from common law systems and
China, this paper explores the strengths and weaknesses of LLMs in
understanding and applying legal texts, reasoning through legal issues, and
predicting judgments. The experimental results highlight both the potential and
limitations of LLMs in legal applications, particularly in terms of challenges
related to the interpretation of legal language and the accuracy of legal
reasoning. Finally, the paper provides a comprehensive analysis of the
advantages and disadvantages of various types of models, offering valuable
insights and references for the future application of AI in the legal field.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æååé¡§åºæ¼å¤§åèªè¨æ¨¡å (LLM) çæ³å¾æ¸¬è©¦æ¹æ³ï¼ä½¿ç¨ OPENAI o1 æ¨¡åä½çºæ¡ä¾ç ç©¶ä¾è©ä¼°å¤§åæ¨¡åå¨æç¨æ³å¾æ¢æ¬¾æ¹é¢çæ§è½ãæåæ¯è¼äºç¶åæåé²ç LLMï¼åæ¬å°ééå°æ³å¾é åè¨ç·´çéæºãéæºåæ³å¾ç¹å®æ¨¡åãå°è±èªåä¸­ææ³å¾æ¡ä¾é²è¡äºç³»çµ±æ¸¬è©¦ï¼ä¸¦å°çµæé²è¡äºæ·±å¥åæãééå°æ®éæ³ç³»åä¸­åæ³å¾æ¡ä¾çç³»çµ±æ¸¬è©¦ï¼æ¬ææ¢è¨äº LLM å¨çè§£åæç¨æ³å¾ææ¬ãæ¨çæ³å¾åé¡åé æ¸¬å¤æ±ºæ¹é¢çåªç¼ºé»ãå¯¦é©çµæçªåºäº LLM å¨æ³å¾æç¨ä¸­çæ½ååå±éæ§ï¼ç¹å¥æ¯å¨èæ³å¾èªè¨è§£éåæ³å¾æ¨çæºç¢ºæ§ç¸éçææ°æ¹é¢ãæå¾ï¼æ¬æå°åç¨®é¡åæ¨¡åçåªç¼ºé»é²è¡äºå¨é¢åæï¼çºäººå·¥æºè½å¨æ³å¾é åçæªä¾æç¨æä¾äºå¯¶è²´çè¦è§£ååèã</paragraph>

##### **Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**
2411.10129v1 by Md. Asif Haider, Ayesha Binte Mostofa, Sk. Sabit Bin Mosaddek, Anindya Iqbal, Toufique Ahmed

Generating accurate code review comments remains a significant challenge due
to the inherently diverse and non-unique nature of the task output. Large
language models pretrained on both programming and natural language data tend
to perform well in code-oriented tasks. However, large-scale pretraining is not
always feasible due to its environmental impact and project-specific
generalizability issues. In this work, first we fine-tune open-source Large
language models (LLM) in parameter-efficient, quantized low-rank (QLoRA)
fashion on consumer-grade hardware to improve review comment generation. Recent
studies demonstrate the efficacy of augmenting semantic metadata information
into prompts to boost performance in other code-related tasks. To explore this
in code review activities, we also prompt proprietary, closed-source LLMs
augmenting the input code patch with function call graphs and code summaries.
Both of our strategies improve the review comment generation performance, with
function call graph augmented few-shot prompting on the GPT-3.5 model
surpassing the pretrained baseline by around 90% BLEU-4 score on the
CodeReviewer dataset. Moreover, few-shot prompted Gemini-1.0 Pro, QLoRA
fine-tuned Code Llama and Llama 3.1 models achieve competitive results (ranging
from 25% to 83% performance improvement) on this task. An additional human
evaluation study further validates our experimental findings, reflecting
real-world developers' perceptions of LLM-generated code review comments based
on relevant qualitative metrics.

æè¦ï¼<paragraph>ç¢çæºç¢ºçç¨å¼ç¢¼å¯©æ¥è©è«ä»ç¶æ¯ä¸åéå¤§ææ°ï¼å çºä»»åè¼¸åºçæ¬è³ªä¸æ¯å¤æ¨£ä¸éç¨ç¹çãå¨ç¨å¼è¨­è¨åèªç¶èªè¨è³æä¸é²è¡é è¨ç·´çå¤§åèªè¨æ¨¡åå¾å¾å¨ä»¥ç¨å¼ç¢¼çºå°åçä»»åä¸­è¡¨ç¾è¯å¥½ãç¶èï¼ç±æ¼å¶å°ç°å¢çå½±é¿åå°æ¡ç¹å®çä¸è¬ååé¡ï¼å¤§è¦æ¨¡é è¨ç·´ä¸¦éç¸½æ¯å¯è¡çãå¨éé å·¥ä½ä¸­ï¼æåé¦åå¨åæ¸ææãéåçä½ç§© (QLoRA) æ¹å¼ä¸­å¾®èª¿éæºå¤§åèªè¨æ¨¡å (LLM)ï¼å¨æ¶è²»ç´ç¡¬é«ä¸æ¹åå¯©æ¥è©è«çç¢çãæè¿çç ç©¶è­æäºå¨æç¤ºä¸­å¢å èªç¾©åè³æè³è¨ä»¥æåå¶ä»èç¨å¼ç¢¼ç¸éä»»åä¸­æè½çåæãçºäºå¨ç¨å¼ç¢¼å¯©æ¥æ´»åä¸­æ¢ç´¢éä¸é»ï¼æåä¹æç¤ºå°æçãéæº LLMï¼ä½¿ç¨å½æ¸å¼å«ååç¨å¼ç¢¼æè¦ä¾å¢å è¼¸å¥ç¨å¼ç¢¼ä¿®è£ç¨å¼ãæåçå©ç¨®ç­ç¥é½æ¹åäºå¯©æ¥è©è«ç¢ççæè½ï¼å¨ GPT-3.5 æ¨¡åä¸ä½¿ç¨å½æ¸å¼å«åå¢å çå°éæç¤ºï¼å¨ CodeReviewer è³æéä¸è¶è¶äºé è¨ç·´åºæºï¼BLEU-4 åæ¸æé«äºç´ 90%ãæ­¤å¤ï¼å°éæç¤ºç Gemini-1.0 ProãQLoRA å¾®èª¿ç Code Llama å Llama 3.1 æ¨¡åå¨æ­¤ä»»åä¸éå°äºæç«¶ç­åççµæï¼æè½æåç¯åçº 25% è³ 83%ï¼ãé¡å¤çä½¿ç¨èè©ä¼°ç ç©¶é²ä¸æ­¥é©è­äºæåçå¯¦é©çµæï¼åæ äºå¯¦ééç¼äººå¡å° LLM ç¢ççç¨å¼ç¢¼å¯©æ¥è©è«ççæ³ï¼éäºçæ³åºæ¼ç¸éçå®æ§ææ¨ã</paragraph>

##### **Memorization in Attention-only Transformers**
2411.10115v1 by LÃ©o Dana, Muni Sreenivas Pydi, Yann Chevaleyre

Recent research has explored the memorization capacity of multi-head
attention, but these findings are constrained by unrealistic limitations on the
context size. We present a novel proof for language-based Transformers that
extends the current hypothesis to any context size. Our approach improves upon
the state-of-the-art by achieving more effective exact memorization with an
attention layer, while also introducing the concept of approximate memorization
of distributions. Through experimental validation, we demonstrate that our
proposed bounds more accurately reflect the true memorization capacity of
language models, and provide a precise comparison with prior work.

æè¦ï¼æè¿çç ç©¶æ¢è¨äºå¤é ­æ³¨æåçè¨æ¶å®¹éï¼ä½éäºç¼ç¾åå°ä¸ä¸æå¤§å°çä¸åå¯¦ééå¶ãæåæåºäºä¸ååºæ¼èªè¨ç Transformer çæ°è­æï¼å°ç¶ååè¨­å»¶ä¼¸å°ä»»ä½ä¸ä¸æå¤§å°ãæåçåæ³ééä½¿ç¨æ³¨æåå±¤å¯¦ç¾æ´ææçç²¾ç¢ºè¨æ¶ï¼åæä¹å¼å¥äºè¿ä¼¼è¨æ¶åä½çæ¦å¿µï¼å¾èæ¹é²äºç¾ææè¡ãééå¯¦é©é©è­ï¼æåè­æäºæåæåºççç·æ´æºç¢ºå°åæ äºèªè¨æ¨¡åççæ­£è¨æ¶å®¹éï¼ä¸¦æä¾äºèååå·¥ä½çç²¾ç¢ºæ¯è¼ã

##### **Generative Agent Simulations of 1,000 People**
2411.10109v1 by Joon Sung Park, Carolyn Q. Zou, Aaron Shaw, Benjamin Mako Hill, Carrie Cai, Meredith Ringel Morris, Robb Willer, Percy Liang, Michael S. Bernstein

The promise of human behavioral simulation--general-purpose computational
agents that replicate human behavior across domains--could enable broad
applications in policymaking and social science. We present a novel agent
architecture that simulates the attitudes and behaviors of 1,052 real
individuals--applying large language models to qualitative interviews about
their lives, then measuring how well these agents replicate the attitudes and
behaviors of the individuals that they represent. The generative agents
replicate participants' responses on the General Social Survey 85% as
accurately as participants replicate their own answers two weeks later, and
perform comparably in predicting personality traits and outcomes in
experimental replications. Our architecture reduces accuracy biases across
racial and ideological groups compared to agents given demographic
descriptions. This work provides a foundation for new tools that can help
investigate individual and collective behavior.

æè¦ï¼äººé¡è¡çºæ¨¡æ¬çæ¿è«¾ââéç¨è¨ç®ä»£çï¼å¯è¤è£½äººé¡è·¨é åçè¡çºââå¯ä»¥å¨æ¿ç­å¶å®åç¤¾æç§å­¸ä¸­å¯¦ç¾å»£æ³çæç¨ãæåæåºäºä¸ç¨®æ°ç©çä»£çæ¶æ§ï¼æ¨¡æ¬äº 1,052 ä½çå¯¦åé«çæåº¦åè¡çºââå°å¤§åèªè¨æ¨¡åæç¨æ¼å°ä»åçæ´»é²è¡çè³ªæ§è¨ªè«ï¼ç¶å¾è¡¡ééäºä»£çäººè¤è£½ä»åæä»£è¡¨çåé«çæåº¦åè¡çºçç¨åº¦ãçæå¼ä»£çå¨ä¸è¬ç¤¾æèª¿æ¥ä¸­è¤è£½åèèçåç­æºç¢ºåº¦çº 85%ï¼èåèèå©é±å¾è¤è£½èªå·±çç­æ¡ä¸æ¨£æºç¢ºï¼ä¸¦ä¸å¨å¯¦é©è¤è£½ä¸­é æ¸¬äººæ ¼ç¹è³ªåçµææ¹é¢è¡¨ç¾ç¸ç¶ãèæä¾äººå£çµ±è¨æè¿°çä»£çç¸æ¯ï¼æåçæ¶æ§æ¸å°äºè·¨ç¨®æåæè­å½¢æç¾¤é«çæºç¢ºæ§åå·®ãéé å·¥ä½çºæ°å·¥å·å¥ å®äºåºç¤ï¼éäºå·¥å·å¯ä»¥å¹«å©èª¿æ¥åäººåéé«è¡çºã

##### **Identifying Key Drivers of Heatwaves: A Novel Spatio-Temporal Framework for Extreme Event Detection**
2411.10108v1 by J. PÃ©rez-Aracil, C. PelÃ¡ez-RodrÃ­guez, Ronan McAdam, Antonello Squintu, Cosmin M. Marina, Eugenio Lorente-Ramos, Niklas Luther, Veronica Torralba, Enrico Scoccimarro, Leone Cavicchia, Matteo Giuliani, Eduardo Zorita, Felicitas Hansen, David Barriopedro, Ricardo Garcia-Herrera, Pedro A. GutiÃ©rrez, JÃ¼rg Luterbacher, Elena Xoplaki, Andrea Castelletti, S. Salcedo-Sanz

Heatwaves (HWs) are extreme atmospheric events that produce significant
societal and environmental impacts. Predicting these extreme events remains
challenging, as their complex interactions with large-scale atmospheric and
climatic variables are difficult to capture with traditional statistical and
dynamical models. This work presents a general method for driver identification
in extreme climate events. A novel framework (STCO-FS) is proposed to identify
key immediate (short-term) HW drivers by combining clustering algorithms with
an ensemble evolutionary algorithm. The framework analyzes spatio-temporal
data, reduces dimensionality by grouping similar geographical nodes for each
variable, and develops driver selection in spatial and temporal domains,
identifying the best time lags between predictive variables and HW occurrences.
The proposed method has been applied to analyze HWs in the Adda river basin in
Italy. The approach effectively identifies significant variables influencing
HWs in this region. This research can potentially enhance our understanding of
HW drivers and predictability.

æè¦ï¼ç±æµª (HWs) æ¯æ¥µç«¯çæ°£è±¡äºä»¶ï¼æç¢çéå¤§çç¤¾æåç°å¢å½±é¿ãé æ¸¬éäºæ¥µç«¯äºä»¶ä»ç¶å·æææ°æ§ï¼å çºå®åèå¤§è¦æ¨¡å¤§æ°£åæ°£åè®æ¸çè¤éäº¤äºä½ç¨é£ä»¥ééå³çµ±ççµ±è¨åååæ¨¡åææãéé å·¥ä½æåºäºä¸ç¨®ç¨æ¼æ¥µç«¯æ°£åäºä»¶ä¸­é©åå ç´ è­å¥çéç¨æ¹æ³ãæåºä¸åæ°ç©çæ¡æ¶ (STCO-FS) ä¾è­å¥ééµçç«å³ (ç­æ) HW é©åå ç´ ï¼æ¹æ³æ¯å°èé¡æ¼ç®æ³èæ´é«æ¼åæ¼ç®æ³çµåãè©²æ¡æ¶åææç©ºè³æï¼ééçºæ¯åè®æ¸åçµé¡ä¼¼çå°çç¯é»ä¾éä½ç¶­åº¦ï¼ä¸¦å¨ç©ºéåæéåä¸­éç¼é©åå ç´ é¸æï¼æ¾åºé æ¸¬è®æ¸å HW ç¼çä¹éæä½³çæéå·®ãææåºçæ¹æ³å·²æç¨æ¼åæç¾©å¤§å©é¿éæ²³æµåä¸­ç HWsãéç¨®æ¹æ³ææå°è­å¥åºå½±é¿è©²å°å HWs çéè¦è®æ¸ãéé ç ç©¶æå¯è½å¢å¼·æåå° HW é©åå ç´ åå¯é æ¸¬æ§ççè§£ã

##### **Multi-Task Adversarial Variational Autoencoder for Estimating Biological Brain Age with Multimodal Neuroimaging**
2411.10100v1 by Muhammad Usman, Azka Rehman, Abdullah Shahid, Abd Ur Rehman, Sung-Min Gho, Aleum Lee, Tariq M. Khan, Imran Razzak

Despite advances in deep learning for estimating brain age from structural
MRI data, incorporating functional MRI data is challenging due to its complex
structure and the noisy nature of functional connectivity measurements. To
address this, we present the Multitask Adversarial Variational Autoencoder, a
custom deep learning framework designed to improve brain age predictions
through multimodal MRI data integration. This model separates latent variables
into generic and unique codes, isolating shared and modality-specific features.
By integrating multitask learning with sex classification as an additional
task, the model captures sex-specific aging patterns. Evaluated on the OpenBHB
dataset, a large multisite brain MRI collection, the model achieves a mean
absolute error of 2.77 years, outperforming traditional methods. This success
positions M-AVAE as a powerful tool for metaverse-based healthcare applications
in brain age estimation.

æè¦ï¼åç®¡æ·±åº¦å­¸ç¿å¨æ ¹æçµæ§æ§ MRI è³æä¼°è¨å¤§è¦å¹´é½¡æ¹é¢æé²å±ï¼ä½ç±æ¼å¶è¤éççµæ§ååè½æ§é£çµæ¸¬éçéè¨æ§è³ªï¼æ´ååè½æ§ MRI è³æä»ç¶å·æææ°æ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºå¤ä»»åå°æè®ç°èªåç·¨ç¢¼å¨ï¼éæ¯ä¸åå®¢è£½åçæ·±åº¦å­¸ç¿æ¶æ§ï¼æ¨å¨ééå¤æ¨¡å¼ MRI è³ææ´åä¾æ¹åå¤§è¦å¹´é½¡é æ¸¬ãæ­¤æ¨¡åå°æ½å¨è®æ¸åçºä¸è¬åç¨ç¹ä»£ç¢¼ï¼éé¢å±äº«åç¹å®æ¼æ¨¡å¼çåè½ãééå°å¤ä»»åå­¸ç¿èæ§å¥åé¡æ´åçºé¡å¤ä»»åï¼æ­¤æ¨¡åæ·åäºç¹å®æ¼æ§å¥çèåæ¨¡å¼ãå¨å¤§åå¤å ´åå¤§è¦ MRI èéç OpenBHB è³æéä¸é²è¡è©ä¼°ï¼æ­¤æ¨¡åéå°äº 2.77 å¹´çå¹³åçµå°èª¤å·®ï¼åªæ¼å³çµ±æ¹æ³ãéé æåè® M-AVAE æçºå¤§è¦å¹´é½¡ä¼°è¨ä¸­åºæ¼åå®å®çé«çä¿å¥æç¨ä¸­å¼·å¤§çå·¥å·ã

##### **PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse**
2411.10087v1 by Einari Vaaras, Manu Airaksinen, Okko RÃ¤sÃ¤nen

Self-supervised learning (SSL) is a data-driven learning approach that
utilizes the innate structure of the data to guide the learning process. In
contrast to supervised learning, which depends on external labels, SSL utilizes
the inherent characteristics of the data to produce its own supervisory signal.
However, one frequent issue with SSL methods is representation collapse, where
the model outputs a constant input-invariant feature representation. This issue
hinders the potential application of SSL methods to new data modalities, as
trying to avoid representation collapse wastes researchers' time and effort.
This paper introduces a novel SSL algorithm for time-series data called
Prediction of Functionals from Masked Latents (PFML). Instead of predicting
masked input signals or their latent representations directly, PFML operates by
predicting statistical functionals of the input signal corresponding to masked
embeddings, given a sequence of unmasked embeddings. The algorithm is designed
to avoid representation collapse, rendering it straightforwardly applicable to
different time-series data domains, such as novel sensor modalities in clinical
data. We demonstrate the effectiveness of PFML through complex, real-life
classification tasks across three different data modalities: infant posture and
movement classification from multi-sensor inertial measurement unit data,
emotion recognition from speech data, and sleep stage classification from EEG
data. The results show that PFML is superior to a conceptually similar
pre-existing SSL method and competitive against the current state-of-the-art
SSL method, while also being conceptually simpler and without suffering from
representation collapse.

æè¦ï¼èªçç£å­¦ä¹  (SSL) æ¯ä¸ç§æ°æ®é©±å¨çå­¦ä¹ æ¹æ³ï¼å®å©ç¨æ°æ®çåå¨ç»ææ¥æå¯¼å­¦ä¹ è¿ç¨ãä¸ä¾èµå¤é¨æ ç­¾ççç£å­¦ä¹ ç¸åï¼SSL å©ç¨æ°æ®æ¬èº«çåºæç¹å¾æ¥äº§çèªå·±ççç£ä¿¡å·ãç¶èï¼SSL æ¹æ³çä¸ä¸ªå¸¸è§é®é¢æ¯è¡¨ç¤ºåå¡ï¼å¶ä¸­æ¨¡åè¾åºä¸ä¸ªå¸¸æ°è¾å¥ä¸åç¹å¾è¡¨ç¤ºãè¿ä¸ªé®é¢é»ç¢äº SSL æ¹æ³å¨æ°çæ°æ®æ¨¡å¼ä¸­çæ½å¨åºç¨ï¼å ä¸ºè¯å¾é¿åè¡¨ç¤ºåå¡ä¼æµªè´¹ç ç©¶äººåçæ¶é´åç²¾åãæ¬æä»ç»äºä¸ç§éå¯¹æ¶é´åºåæ°æ®çæ°å SSL ç®æ³ï¼ç§°ä¸ºæ©ç æ½å¨åéçåè½é¢æµ (PFML)ãPFML ä¸æ¯ç´æ¥é¢æµæ©ç è¾å¥ä¿¡å·æå¶æ½å¨è¡¨ç¤ºï¼èæ¯éè¿é¢æµè¾å¥ä¿¡å·çç»è®¡å½æ°ï¼å¯¹åºäºæ©ç åµå¥ï¼æ¥æä½ï¼ç»å®ä¸ç³»åæªæ©ç åµå¥ãè¯¥ç®æ³æ¨å¨é¿åè¡¨ç¤ºåå¡ï¼ä½¿å¶å¯ä»¥ç´æ¥åºç¨äºä¸åçæ¶é´åºåæ°æ®åï¼ä¾å¦ä¸´åºæ°æ®ä¸­çæ°åä¼ æå¨æ¨¡å¼ãæä»¬éè¿ä¸ä¸ªä¸åæ°æ®æ¨¡å¼çå¤æç°å®çæ´»åç±»ä»»å¡å±ç¤ºäº PFML çæææ§ï¼å¤ä¼ æå¨æ¯æ§æµéååæ°æ®çå©´å¿å§¿å¿åè¿å¨åç±»ãè¯­é³æ°æ®çè¯­é³è¯å«ä»¥åèçµå¾æ°æ®çç¡ç é¶æ®µåç±»ãç»æè¡¨æï¼PFML ä¼äºæ¦å¿µä¸ç¸ä¼¼çç°æ SSL æ¹æ³ï¼å¹¶ä¸ä¸å½åæåè¿ç SSL æ¹æ³å·æç«äºåï¼åæ¶å¨æ¦å¿µä¸æ´ç®åï¼å¹¶ä¸ä¸ä¼åºç°è¡¨ç¤ºåå¡ã

##### **Adapting the Biological SSVEP Response to Artificial Neural Networks**
2411.10084v1 by Emirhan BÃ¶ge, Yasemin Gunindi, Erchan Aptoula, Nihan Alp, Huseyin Ozkan

Neuron importance assessment is crucial for understanding the inner workings
of artificial neural networks (ANNs) and improving their interpretability and
efficiency. This paper introduces a novel approach to neuron significance
assessment inspired by frequency tagging, a technique from neuroscience. By
applying sinusoidal contrast modulation to image inputs and analyzing resulting
neuron activations, this method enables fine-grained analysis of a network's
decision-making processes. Experiments conducted with a convolutional neural
network for image classification reveal notable harmonics and intermodulations
in neuron-specific responses under part-based frequency tagging. These findings
suggest that ANNs exhibit behavior akin to biological brains in tuning to
flickering frequencies, thereby opening avenues for neuron/filter importance
assessment through frequency tagging. The proposed method holds promise for
applications in network pruning, and model interpretability, contributing to
the advancement of explainable artificial intelligence and addressing the lack
of transparency in neural networks. Future research directions include
developing novel loss functions to encourage biologically plausible behavior in
ANNs.

æè¦ï¼ç¥ç¶åéè¦æ§è©ä¼°å°æ¼çè§£äººå·¥ç¥ç¶ç¶²è·¯ (ANN) çå§é¨éä½ï¼ä»¥åæåå¶å¯è§£éæ§åæçè³ééè¦ãæ¬æä»ç´¹ä¸ç¨®åé »çæ¨è¨åç¼çç¥ç¶åéè¦æ§è©ä¼°æ°æ¹æ³ï¼é »çæ¨è¨æ¯ä¸ç¨®ä¾èªç¥ç¶ç§å­¸çæè¡ãééå°æ­£å¼¦å°æ¯èª¿è®æç¨æ¼å½±åè¼¸å¥ï¼ä¸¦åæç¢ççç¥ç¶åæ´»åï¼æ­¤æ¹æ³è½å°ç¶²è·¯çæ±ºç­å¶å®éç¨é²è¡ç´°ç·»çåæãä½¿ç¨å·ç©ç¥ç¶ç¶²è·¯é²è¡å½±ååé¡æå·è¡çå¯¦é©ï¼æ­ç¤ºäºå¨åºæ¼é¨åçé »çæ¨è¨ä¸ï¼ç¥ç¶åç¹å®åæä¸­é¡¯èçè«§æ³¢åäºèª¿ãéäºç¼ç¾è¡¨æï¼ANN å¨èª¿æ´éçé »çæè¡¨ç¾åºé¡ä¼¼æ¼çç©å¤§è¦çè¡çºï¼å¾èçºééé »çæ¨è¨é²è¡ç¥ç¶å/æ¿¾æ³¢å¨éè¦æ§è©ä¼°éåäºéå¾ãææåºçæ¹æ³æææç¨æ¼ç¶²è·¯åªæåæ¨¡åå¯è§£éæ§ï¼æå©æ¼å¯è§£éäººå·¥æºæ§çé²æ­¥ï¼ä¸¦è§£æ±ºç¥ç¶ç¶²è·¯ä¸­ç¼ºä¹éæåº¦ãæªä¾çç ç©¶æ¹ååæ¬éç¼æ°çæå¤±å½æ¸ï¼ä»¥é¼åµ ANN ä¸­å·æçç©å­¸ä¸åçè¡çºã

##### **Xmodel-1.5: An 1B-scale Multilingual LLM**
2411.10083v1 by Wang Qun, Liu Yang, Lin Qingquan, Jiang Ling

We introduce Xmodel-1.5, a novel 1-billion-parameter multilingual large model
pretrained on approximately 2 trillion tokens. The model demonstrates strong
performance across several languages, with particularly notable results in
Thai, Arabic, and French, alongside its effectiveness in Chinese and English.
In addition, we contribute to the research community by releasing a Thai
evaluation dataset, which includes hundreds of questions annotated by students
from Chulalongkorn University's School of Integrated Innovation. While the
results are promising, we acknowledge that there is still room for improvement.
We hope this work advances ongoing efforts in multilingual AI research and
promotes better cross-linguistic understanding in various natural language
processing tasks. Our models and code are publicly available on GitHub at
https://github.com/XiaoduoAILab/XmodelLM.

æè¦ï¼æåæ¨åº Xmodel-1.5ï¼ä¸åæ°ç©ç 10 ååæ¸å¤èªè¨å¤§åæ¨¡åï¼é è¨ç·´ç´ 2 ååç¬¦èãè©²æ¨¡åå¨å¤ç¨®èªè¨ä¸­å±ç¾å¼·åçæè½ï¼å¨æ³°èªãé¿æä¼¯èªåæ³èªä¸­æç¹å¥é¡¯èççµæï¼åæå¨ä¸­æåè±ææ¹é¢ä¹ååææãæ­¤å¤ï¼æåéééåºæ³°èªè©ä¼°è³æéä¾çºç ç©¶ç¤¾ç¾¤ååºè²¢ç»ï¼å¶ä¸­åå«æ¸ç¾åç±æ±æéåå¤§å­¸ç¶ååµæ°å­¸é¢å­¸çè¨»è§£çåé¡ãåç®¡çµæä»¤äººæ¯å¥®ï¼æåæ¿èªä»æé²æ­¥ç©ºéãæåå¸æéé å·¥ä½è½ä¿é²å¤èªè¨ AI ç ç©¶çæçºåªåï¼ä¸¦å¨åç¨®èªç¶èªè¨èçä»»åä¸­ä¿é²æ´å¥½çè·¨èªè¨çè§£ãæåçæ¨¡ååç¨å¼ç¢¼å·²å¬éç¼å¸å¨ GitHub ä¸ï¼ç¶²åçº https://github.com/XiaoduoAILab/XmodelLMã

##### **Understanding The Effect Of Temperature On Alignment With Human Opinions**
2411.10080v1 by Maja Pavlovic, Massimo Poesio

With the increasing capabilities of LLMs, recent studies focus on
understanding whose opinions are represented by them and how to effectively
extract aligned opinion distributions. We conducted an empirical analysis of
three straightforward methods for obtaining distributions and evaluated the
results across a variety of metrics. Our findings suggest that sampling and
log-probability approaches with simple parameter adjustments can return better
aligned outputs in subjective tasks compared to direct prompting. Yet, assuming
models reflect human opinions may be limiting, highlighting the need for
further research on how human subjectivity affects model uncertainty.

æè¦ï¼é¨è LLM è½åçæåï¼è¿æç ç©¶èéæ¼äºè§£ LLM æä»£è¡¨çæè¦ä¾èªä½äººï¼ä»¥åå¦ä½æææåå°é½çæè¦åä½ãæåå°ä¸ç¨®ç¨æ¼åå¾åä½çç´æ¥æ¹æ³é²è¡å¯¦è­åæï¼ä¸¦æ ¹æåç¨®ææ¨è©ä¼°çµæãæåçç ç©¶çµæé¡¯ç¤ºï¼èç´æ¥æç¤ºç¸æ¯ï¼åæ¨£åå°æ¸æ©çæ¹æ³æ­éç°¡å®çåæ¸èª¿æ´ï¼å¯ä»¥å¨ä¸»è§ä»»åä¸­åå³æ´å°é½çè¼¸åºãç¶èï¼åè¨­æ¨¡ååæ äººé¡æè¦å¯è½ææéå¶ï¼éå¸é¡¯äºé²ä¸æ­¥ç ç©¶äººé¡ä¸»è§æ§å¦ä½å½±é¿æ¨¡åä¸ç¢ºå®æ§çå¿è¦æ§ã

##### **Real-Time AI-Driven People Tracking and Counting Using Overhead Cameras**
2411.10072v1 by Ishrath Ahamed, Chamith Dilshan Ranathunga, Dinuka Sandun Udayantha, Benny Kai Kiat Ng, Chau Yuen

Accurate people counting in smart buildings and intelligent transportation
systems is crucial for energy management, safety protocols, and resource
allocation. This is especially critical during emergencies, where precise
occupant counts are vital for safe evacuation. Existing methods struggle with
large crowds, often losing accuracy with even a few additional people. To
address this limitation, this study proposes a novel approach combining a new
object tracking algorithm, a novel counting algorithm, and a fine-tuned object
detection model. This method achieves 97% accuracy in real-time people counting
with a frame rate of 20-27 FPS on a low-power edge computer.

æè¦ï¼å¨æºæ§åå»ºç¯åæºæ§äº¤éç³»çµ±ä¸­æºç¢ºè¨ç®äººæ¸å°æ¼è½æºç®¡çãå®å¨åå®åè³æºåéè³ééè¦ãéå¨ç·æ¥ææ³ä¸å°¤å¶éè¦ï¼å çºç²¾ç¢ºçå±ä½èäººæ¸å°æ¼å®å¨çæ£è³ééè¦ãç¾ææ¹æ³é£ä»¥æä»å¤§éäººç¾¤ï¼å³ä½¿å¢å å°æ¸äººä¹æéä½æºç¢ºåº¦ãçºäºè§£æ±ºéåéå¶ï¼æ¬ç ç©¶æåºäºä¸ååµæ°çæ¹æ³ï¼çµåä¸ç¨®æ°çç©ä»¶è¿½è¹¤æ¼ç®æ³ãä¸ç¨®æ°çè¨æ¸æ¼ç®æ³åä¸åå¾®èª¿çç©ä»¶åµæ¸¬æ¨¡åãæ­¤æ¹æ³å¨ä½åèéç·£é»è¦ä¸ä»¥ 20-27 FPS çå¹çé²è¡å³æäººæ¸è¨ç®ï¼æºç¢ºçéå° 97%ã

##### **Evidential Federated Learning for Skin Lesion Image Classification**
2411.10071v1 by Rutger Hendrix, Federica Proietto Salanitri, Concetto Spampinato, Simone Palazzo, Ulas Bagci

We introduce FedEvPrompt, a federated learning approach that integrates
principles of evidential deep learning, prompt tuning, and knowledge
distillation for distributed skin lesion classification. FedEvPrompt leverages
two sets of prompts: b-prompts (for low-level basic visual knowledge) and
t-prompts (for task-specific knowledge) prepended to frozen pre-trained Vision
Transformer (ViT) models trained in an evidential learning framework to
maximize class evidences. Crucially, knowledge sharing across federation
clients is achieved only through knowledge distillation on attention maps
generated by the local ViT models, ensuring enhanced privacy preservation
compared to traditional parameter or synthetic image sharing methodologies.
FedEvPrompt is optimized within a round-based learning paradigm, where each
round involves training local models followed by attention maps sharing with
all federation clients. Experimental validation conducted in a real distributed
setting, on the ISIC2019 dataset, demonstrates the superior performance of
FedEvPrompt against baseline federated learning algorithms and knowledge
distillation methods, without sharing model parameters. In conclusion,
FedEvPrompt offers a promising approach for federated learning, effectively
addressing challenges such as data heterogeneity, imbalance, privacy
preservation, and knowledge sharing.

æè¦ï¼<paragraph>æåä»ç´¹ FedEvPromptï¼éæ¯ä¸ç¨®è¯é¦å­¸ç¿æ¹æ³ï¼æ´åäº
è­ææ·±åº¦å­¸ç¿ãæç¤ºèª¿æ´åç¥è­æççåçï¼ç¨æ¼åä½å¼ç®èçç¶åé¡ãFedEvPrompt å©ç¨
å©çµæç¤ºï¼b-æç¤ºï¼ç¨æ¼ä½éåºæ¬è¦è¦ºç¥è­ï¼å
t-æç¤ºï¼ç¨æ¼ç¹å®ä»»åçç¥è­ï¼å å°åçµçé è¨ç·´ Vision
Transformer (ViT) æ¨¡åä¹åï¼éäºæ¨¡åå¨è­æå­¸ç¿æ¶æ§ä¸­é²è¡è¨ç·´ï¼ä»¥
æå¤§åé¡å¥è­æãè³ééè¦çæ¯ï¼è¯é¦å®¢æ¶ä¹éçç¥è­å±äº«åééå°æ¬å° ViT æ¨¡åçæçæ³¨æååé²è¡ç¥è­æçä¾å¯¦ç¾ï¼èå³çµ±åæ¸æåæå½±åå±äº«æ¹æ³ç¸æ¯ï¼ç¢ºä¿äºå¢å¼·çé±ç§ä¿è­·ã
FedEvPrompt å¨åºæ¼è¼ªæ¬¡çå­¸ç¿ç¯ä¾ä¸­é²è¡åªåï¼å¶ä¸­æ¯å
è¼ªæ¬¡é½æ¶åè¨ç·´æ¬å°æ¨¡åï¼ç¶å¾èææè¯é¦å®¢æ¶å±äº«æ³¨æååãå¨çå¯¦çåå¸å¼
è¨­ç½®ä¸­é²è¡çå¯¦é©é©è­ï¼å¨ ISIC2019 è³æéä¸ï¼å±ç¤ºäº FedEvPrompt åªæ¼åºæºè¯é¦å­¸ç¿æ¼ç®æ³åç¥è­
æçæ¹æ³çåªç°æè½ï¼èç¡éå±äº«æ¨¡ååæ¸ãç¸½ä¹ï¼
FedEvPrompt çºè¯é¦å­¸ç¿æä¾äºä¸ç¨®æåéçæ¹æ³ï¼ææå°è§£æ±ºäºè³æç°è³ªæ§ãä¸å¹³è¡¡ãé±ç§ä¿è­·åç¥è­å±äº«ç­ææ°ã</paragraph>

##### **Layer Importance and Hallucination Analysis in Large Language Models via Enhanced Activation Variance-Sparsity**
2411.10069v1 by Zichen Song, Sitan Huang, Yuxin Wu, Zhongfeng Kang

Evaluating the importance of different layers in large language models (LLMs)
is crucial for optimizing model performance and interpretability. This paper
first explores layer importance using the Activation Variance-Sparsity Score
(AVSS), which combines normalized activation variance and sparsity to quantify
each layer's contribution to overall model performance. By ranking layers based
on AVSS and pruning the least impactful 25\%, our experiments on tasks such as
question answering, language modeling, and sentiment classification show that
over 90\% of the original performance is retained, highlighting potential
redundancies in LLM architectures. Building on AVSS, we propose an enhanced
version tailored to assess hallucination propensity across layers (EAVSS). This
improved approach introduces Hallucination-Specific Activation Variance (HSAV)
and Hallucination-Specific Sparsity (HSS) metrics, allowing precise
identification of hallucination-prone layers. By incorporating contrastive
learning on these layers, we effectively mitigate hallucination generation,
contributing to more robust and efficient LLMs(The maximum performance
improvement is 12\%). Our results on the NQ, SciQ, TriviaQA, TruthfulQA, and
WikiQA datasets demonstrate the efficacy of this method, offering a
comprehensive framework for both layer importance evaluation and hallucination
mitigation in LLMs.

æè¦ï¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) ä¸­ä¸åå±¤ç´çéè¦æ§å°æ¼æä½³åæ¨¡åæè½åå¯è§£éæ§è³ééè¦ãæ¬æé¦åä½¿ç¨ååæ¹å·®ç¨çåº¦è©å (AVSS) ä¾æ¢è¨å±¤ç´çéè¦æ§ï¼å®çµåäºæ¨æºåååæ¹å·®åç¨çåº¦ï¼ä»¥éåæ¯ä¸å±¤å°æ´é«æ¨¡åæè½çè²¢ç»ãééæ ¹æ AVSS å°å±¤ç´é²è¡æåºï¼ä¸¦ä¿®åªå½±é¿æå°ç 25%ï¼æåå¨åç­ãèªè¨å»ºæ¨¡åæç·åé¡ç­ä»»åä¸çå¯¦é©é¡¯ç¤ºï¼ä¿çäºè¶é 90% çåå§æè½ï¼çªé¡¯äº LLM æ¶æ§ä¸­æ½å¨çåé¤ãå»ºç«å¨ AVSS çåºç¤ä¸ï¼æåæåºä¸åå¢å¼·çæ¬ï¼å°éç¨æ¼è©ä¼°è·¨å±¤ç´çå¹»è¦ºå¾å (EAVSS)ãéç¨®æ¹è¯çæ¹æ³å¼å¥äºå¹»è¦ºç¹å®ååæ¹å·® (HSAV) åå¹»è¦ºç¹å®ç¨çåº¦ (HSS) ææ¨ï¼å¯ä»¥ç²¾æºè¾¨è­å®¹æç¢çå¹»è¦ºçå±¤ç´ãééå¨éäºå±¤ç´ä¸­ç´å¥å°æ¯å­¸ç¿ï¼æåæææ¸è¼äºå¹»è¦ºçç¢çï¼æå©æ¼å»ºç«æ´å¼·å¤§ä¸æ´ææç LLMï¼æè½æå¤§çæåå¹åº¦çº 12%ï¼ãæåå¨ NQãSciQãTriviaQAãTruthfulQA å WikiQA è³æéä¸ççµæè­æäºæ­¤æ¹æ³çæç¨ï¼çº LLM ä¸­çå±¤ç´éè¦æ§è©ä¼°åå¹»è¦ºæ¸è¼æä¾äºä¸åå¨é¢çæ¶æ§ã

##### **Federated Domain Generalization via Prompt Learning and Aggregation**
2411.10063v1 by Shuai Gong, Chaoran Cui, Chunyun Zhang, Wenna Wang, Xiushan Nie, Lei Zhu

Federated domain generalization (FedDG) aims to improve the global model
generalization in unseen domains by addressing data heterogeneity under
privacy-preserving constraints. A common strategy in existing FedDG studies
involves sharing domain-specific knowledge among clients, such as spectrum
information, class prototypes, and data styles. However, this knowledge is
extracted directly from local client samples, and sharing such sensitive
information poses a potential risk of data leakage, which might not fully meet
the requirements of FedDG. In this paper, we introduce prompt learning to adapt
pre-trained vision-language models (VLMs) in the FedDG scenario, and leverage
locally learned prompts as a more secure bridge to facilitate knowledge
transfer among clients. Specifically, we propose a novel FedDG framework
through Prompt Learning and AggregatioN (PLAN), which comprises two training
stages to collaboratively generate local prompts and global prompts at each
federated round. First, each client performs both text and visual prompt
learning using their own data, with local prompts indirectly synchronized by
regarding the global prompts as a common reference. Second, all domain-specific
local prompts are exchanged among clients and selectively aggregated into the
global prompts using lightweight attention-based aggregators. The global
prompts are finally applied to adapt VLMs to unseen target domains. As our PLAN
framework requires training only a limited number of prompts and lightweight
aggregators, it offers notable advantages in computational and communication
efficiency for FedDG. Extensive experiments demonstrate the superior
generalization ability of PLAN across four benchmark datasets.

æè¦ï¼è¯é¦é åæ³å (FedDG) æ¨å¨ééå¨ä¿å¯ç´æä¸è§£æ±ºè³æç°è³ªæ§ï¼ä¾æ¹åå¨æªè¦é åä¸­çæ´é«æ¨¡åæ³åãç¾æ FedDG ç ç©¶ä¸­å¸¸è¦çç­ç¥ï¼æ¶åå¨å®¢æ¶ç«¯ä¹éåäº«é åç¹å®ç¥è­ï¼ä¾å¦é »è­è³è¨ãé¡åååè³ææ¨£å¼ãç¶èï¼éé ç¥è­ç´æ¥å¾ç¶å°å®¢æ¶ç«¯ç¯ä¾ä¸­æ·åï¼èåäº«æ­¤é¡ææè³è¨æé æè³æå¤æ´©çæ½å¨é¢¨éªï¼å¯è½ç¡æ³å®å¨æ»¿è¶³ FedDG çéæ±ãå¨æ¬æä¸­ï¼æåå¼å¥æç¤ºå­¸ç¿ï¼ä»¥å¨ FedDG æå¢ä¸­èª¿æ´é åè¨ç·´çè¦è¦ºèªè¨æ¨¡å (VLM)ï¼ä¸¦å©ç¨ç¶å°å­¸ç¿çæç¤ºä½çºæ´å®å¨çæ©æ¨ï¼ä»¥ä¿é²å®¢æ¶ç«¯ä¹éçç¥è­è½ç§»ãå·é«ä¾èªªï¼æåééæç¤ºå­¸ç¿åèå (PLAN) æåºä¸åæ°ç©ç FedDG æ¶æ§ï¼å®åå«å©åè¨ç·´éæ®µï¼ä»¥å¨æ¯åè¯é¦ååä¸­å±åç¢çæ¬å°æç¤ºåå¨åæç¤ºãé¦åï¼æ¯åå®¢æ¶ç«¯ä½¿ç¨èªå·±çè³æå·è¡æå­åè¦è¦ºæç¤ºå­¸ç¿ï¼ä¸¦ééå°å¨åæç¤ºè¦çºå±éåèï¼éæ¥åæ­¥æ¬å°æç¤ºãå¶æ¬¡ï¼ææé åç¹å®çæ¬å°æç¤ºæå¨å®¢æ¶ç«¯ä¹éäº¤æï¼ä¸¦ä½¿ç¨è¼éç´åºæ¼æ³¨æåçèåå¨æé¸æå°èåå°å¨åæç¤ºä¸­ãå¨åæç¤ºæå¾æç¨æ¼èª¿æ´ VLM ä»¥é©ææªè¦çç®æ¨é åãç±æ¼æåç PLAN æ¶æ§åéè¦è¨ç·´æéæ¸éçæç¤ºåè¼éç´èåå¨ï¼å æ­¤å¨ FedDG çéç®åéè¨æçæ¹é¢æä¾äºé¡¯èçåªå¢ãå»£æ³çå¯¦é©è­æäº PLAN å¨åååºæºè³æéä¸­çåè¶æ³åè½åã

##### **CMATH: Cross-Modality Augmented Transformer with Hierarchical Variational Distillation for Multimodal Emotion Recognition in Conversation**
2411.10060v1 by Xiaofei Zhu, Jiawei Cheng, Zhou Yang, Zhuo Chen, Qingyang Wang, Jianfeng Yao

Multimodal emotion recognition in conversation (MER) aims to accurately
identify emotions in conversational utterances by integrating multimodal
information. Previous methods usually treat multimodal information as equal
quality and employ symmetric architectures to conduct multimodal fusion.
However, in reality, the quality of different modalities usually varies
considerably, and utilizing a symmetric architecture is difficult to accurately
recognize conversational emotions when dealing with uneven modal information.
Furthermore, fusing multi-modality information in a single granularity may fail
to adequately integrate modal information, exacerbating the inaccuracy in
emotion recognition. In this paper, we propose a novel Cross-Modality Augmented
Transformer with Hierarchical Variational Distillation, called CMATH, which
consists of two major components, i.e., Multimodal Interaction Fusion and
Hierarchical Variational Distillation. The former is comprised of two
submodules, including Modality Reconstruction and Cross-Modality Augmented
Transformer (CMA-Transformer), where Modality Reconstruction focuses on
obtaining high-quality compressed representation of each modality, and
CMA-Transformer adopts an asymmetric fusion strategy which treats one modality
as the central modality and takes others as auxiliary modalities. The latter
first designs a variational fusion network to fuse the fine-grained
representations learned by CMA- Transformer into a coarse-grained
representations. Then, it introduces a hierarchical distillation framework to
maintain the consistency between modality representations with different
granularities. Experiments on the IEMOCAP and MELD datasets demonstrate that
our proposed model outperforms previous state-of-the-art baselines.
Implementation codes can be available at https://github.com/ cjw-MER/CMATH.

æè¦ï¼<paragraph>å¤æ¨¡æå¯¹è¯æç»ªè¯å«ï¼MERï¼æ¨å¨éè¿æ´åå¤æ¨¡æä¿¡æ¯åç¡®è¯å«å¯¹è¯ä¸­çæç»ªãä»¥å¾çæ¹æ³éå¸¸å°å¤æ¨¡æä¿¡æ¯è§ä¸ºåç­è´¨éï¼å¹¶éç¨å¯¹ç§°æ¶æè¿è¡å¤æ¨¡æèåãç¶èï¼å¨ç°å®ä¸­ï¼ä¸åæ¨¡æçè´¨ééå¸¸å·®å¼å¾å¤§ï¼å¹¶ä¸å¨å¤çä¸ååçæ¨¡æä¿¡æ¯æ¶ï¼å©ç¨å¯¹ç§°æ¶æé¾ä»¥åç¡®è¯å«å¯¹è¯æç»ªãæ­¤å¤ï¼ä»¥åä¸ç²åº¦èåå¤æ¨¡æä¿¡æ¯å¯è½æ æ³ååæ´åæ¨¡æä¿¡æ¯ï¼ä»èå å§æç»ªè¯å«ä¸­çä¸åç¡®æ§ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ç§å·æåå±ååè¸é¦çè·¨æ¨¡æå¢å¼º Transformerï¼ç§°ä¸º CMATHï¼å®ç±ä¸¤ä¸ªä¸»è¦ç»æé¨åç»æï¼å³å¤æ¨¡æäº¤äºèåååå±ååè¸é¦ãåèç±ä¸¤ä¸ªå­æ¨¡åç»æï¼åæ¬æ¨¡æéå»ºåè·¨æ¨¡æå¢å¼º Transformerï¼CMA-Transformerï¼ï¼å¶ä¸­æ¨¡æéå»ºä¸æ³¨äºè·åæ¯ä¸ªæ¨¡æçé«è´¨éåç¼©è¡¨ç¤ºï¼è CMA-Transformer éç¨ä¸å¯¹ç§°èåç­ç¥ï¼å°ä¸ç§æ¨¡æè§ä¸ºä¸­å¿æ¨¡æï¼å¹¶å°å¶ä»æ¨¡æè§ä¸ºè¾å©æ¨¡æãåèé¦åè®¾è®¡äºä¸ä¸ªååèåç½ç»ï¼å° CMA-Transformer å­¦ä¹ å°çç»ç²åº¦è¡¨ç¤ºèåæç²ç²åº¦è¡¨ç¤ºãç¶åï¼å®å¼å¥äºä¸ä¸ªåå±è¸é¦æ¡æ¶ï¼ä»¥ä¿æå·æä¸åç²åº¦çæ¨¡æè¡¨ç¤ºä¹é´çä¸è´æ§ãå¨ IEMOCAP å MELD æ°æ®éä¸çå®éªè¡¨æï¼æä»¬æåºçæ¨¡åä¼äºä»¥å¾æåè¿çåºåãå®ç°ä»£ç å¯ä»¥å¨ https://github.com/ cjw-MER/CMATH è·å¾ã</paragraph>

##### **KuaiFormer: Transformer-Based Retrieval at Kuaishou**
2411.10057v1 by Chi Liu, Jiangxia Cao, Rui Huang, Kai Zheng, Qiang Luo, Kun Gai, Guorui Zhou

In large-scale content recommendation systems, retrieval serves as the
initial stage in the pipeline, responsible for selecting thousands of candidate
items from billions of options to pass on to ranking modules. Traditionally,
the dominant retrieval method has been Embedding-Based Retrieval (EBR) using a
Deep Neural Network (DNN) dual-tower structure. However, applying transformer
in retrieval tasks has been the focus of recent research, though real-world
industrial deployment still presents significant challenges. In this paper, we
introduce KuaiFormer, a novel transformer-based retrieval framework deployed in
a large-scale content recommendation system. KuaiFormer fundamentally redefines
the retrieval process by shifting from conventional score estimation tasks
(such as click-through rate estimate) to a transformer-driven Next Action
Prediction paradigm. This shift enables more effective real-time interest
acquisition and multi-interest extraction, significantly enhancing retrieval
performance. KuaiFormer has been successfully integrated into Kuaishou App's
short-video recommendation system since May 2024, serving over 400 million
daily active users and resulting in a marked increase in average daily usage
time of Kuaishou users. We provide insights into both the technical and
business aspects of deploying transformer in large-scale recommendation
systems, addressing practical challenges encountered during industrial
implementation. Our findings offer valuable guidance for engineers and
researchers aiming to leverage transformer models to optimize large-scale
content recommendation systems.

æè¦ï¼å¨å¤§åå§å®¹æ¨è¦ç³»çµ±ä¸­ï¼æª¢ç´¢ä½çºç®¡éä¸­çåå§éæ®µï¼è² è²¬å¾æ¸åååé¸é ä¸­é¸ææ¸åååé¸é ç®å³éçµ¦æåæ¨¡çµãå³çµ±ä¸ï¼ä¸»è¦çæª¢ç´¢æ¹æ³ä¸ç´æ¯ä½¿ç¨æ·±åº¦ç¥ç¶ç¶²è·¯ï¼DNNï¼éå¡çµæ§çåºæ¼åµå¥çæª¢ç´¢ï¼EBRï¼ãç¶èï¼å°Transformeræç¨æ¼æª¢ç´¢ä»»åä¸ç´æ¯è¿æç ç©¶çéé»ï¼åç®¡ç¾å¯¦ä¸ççç¢æ¥­é¨ç½²ä»é¢è¨éå¤§ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äº KuaiFormerï¼éæ¯ä¸åé¨ç½²å¨å¤§åå§å®¹æ¨è¦ç³»çµ±ä¸­çåºæ¼Transformerçæª¢ç´¢æ¡æ¶ãKuaiFormer å¾æ ¹æ¬ä¸éæ°å®ç¾©äºæª¢ç´¢æµç¨ï¼å¾å³çµ±çåæ¸ä¼°è¨ä»»åï¼ä¾å¦é»æçä¼°è¨ï¼è½ç§»å°ç±Transformeré©åçä¸ä¸ååä½é æ¸¬ç¯ä¾ãéç¨®è½è®ä½¿å¾æ´ææçå¯¦æèè¶£ç²ååå¤èè¶£æåæçºå¯è½ï¼é¡¯èå¢å¼·äºæª¢ç´¢æè½ãèª 2024 å¹´ 5 æä»¥ä¾ï¼KuaiFormer å·²æåæ´åå°å¿«æ App çç­å½±çæ¨è¦ç³»çµ±ä¸­ï¼æåæ¼è¶é 4 åçæ¯æ¥æ´»èºç¨æ¶ï¼ä¸¦å°è´å¿«æç¨æ¶çå¹³åæ¯æ¥ä½¿ç¨æéé¡¯èå¢å ãæåæä¾äºå¨å¤§åæ¨è¦ç³»çµ±ä¸­é¨ç½²Transformerçæè¡åæ¥­åæ¹é¢çè¦è§£ï¼è§£æ±ºäºç¢æ¥­å¯¦æ½éç¨ä¸­éå°çå¯¦éææ°ãæåçç¼ç¾çºå·¥ç¨å¸«åç ç©¶äººå¡æä¾äºæå¹å¼çæå°ï¼ä»åæ¨å¨å©ç¨Transformeræ¨¡åä¾åªåå¤§åå§å®¹æ¨è¦ç³»çµ±ã

##### **Towards unearthing neglected climate innovations from scientific literature using Large Language Models**
2411.10055v1 by CÃ©sar QuilodrÃ¡n-Casas, Christopher Waite, Nicole Alhadeff, Diyona Dsouza, Cathal Hughes, Larissa Kunstel-Tabet, Alyssa Gilbert

Climate change poses an urgent global threat, needing the rapid
identification and deployment of innovative solutions. We hypothesise that many
of these solutions already exist within scientific literature but remain
underutilised. To address this gap, this study employs a curated dataset
sourced from OpenAlex, a comprehensive repository of scientific papers.
Utilising Large Language Models (LLMs), such as GPT4-o from OpenAI, we evaluate
title-abstract pairs from scientific papers on seven dimensions, covering
climate change mitigation potential, stage of technological development, and
readiness for deployment. The outputs of the language models are then compared
with human evaluations to assess their effectiveness in identifying promising
yet overlooked climate innovations. Our findings suggest that these LLM-based
models can effectively augment human expertise, uncovering climate solutions
that are potentially impactful but with far greater speed, throughput and
consistency. Here, we focused on UK-based solutions, but the workflow is
region-agnostic. This work contributes to the discovery of neglected
innovations in scientific literature and demonstrates the potential of AI in
enhancing climate action strategies.

æè¦ï¼æ°£åè®é·æ§æä¸é è¿«åçå¨çå¨èï¼éè¦å¿«éæ¾åºä¸¦é¨ç½²åµæ°è§£æ±ºæ¹æ¡ãæååè¨­ï¼éäºè§£æ±ºæ¹æ¡ä¸­çè¨±å¤æ¹æ¡å·²å­å¨æ¼ç§å­¸æç»ä¸­ï¼ä½ä»æªå¾å°ååå©ç¨ãçºäºè§£æ±ºéåå·®è·ï¼æ¬ç ç©¶æ¡ç¨å¾ OpenAlexï¼ä¸åå¨é¢çç§å­¸è«æå²å­åº«ï¼åå¾çç²¾é¸è³æéãå©ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ OpenAI ç GPT4-oï¼æåå¾ä¸åé¢åè©ä¼°ç§å­¸è«æçæ¨é¡æè¦éå°ï¼åæ¬æ°£åè®é·æ¸ç·©æ½åãæè¡ç¼å±éæ®µåé¨ç½²æºåææ³ãç¶å¾å°èªè¨æ¨¡åçè¼¸åºèäººé¡è©ä¼°é²è¡æ¯è¼ï¼ä»¥è©ä¼°å¶å¨æ¾åºæå¸æä½è¢«å¿½è¦çæ°£ååµæ°æ¹é¢çæææ§ãæåçç ç©¶çµæè¡¨æï¼éäºåºæ¼ LLM çæ¨¡åå¯ä»¥ææå°æ´åäººé¡å°é·ï¼æ¾åºå¯è½ç¢çå½±é¿ä½éåº¦ãç¢éåä¸è´æ§é é«æ¼äººé¡çæ°£åè§£æ±ºæ¹æ¡ãå¨æ­¤ï¼æåå°æ³¨æ¼è±åçè§£æ±ºæ¹æ¡ï¼ä½å·¥ä½æµç¨èå°åç¡éãéé å·¥ä½æå©æ¼æ¾åºç§å­¸æç»ä¸­è¢«å¿½è¦çåµæ°ï¼ä¸¦å±ç¤ºäº AI å¨å å¼·æ°£åè¡åç­ç¥æ¹é¢çæ½åã

##### **Jal Anveshak: Prediction of fishing zones using fine-tuned LlaMa 2**
2411.10050v1 by Arnav Mejari, Maitreya Vaghulade, Paarshva Chitaliya, Arya Telang, Lynette D'mello

In recent years, the global and Indian government efforts in monitoring and
collecting data related to the fisheries industry have witnessed significant
advancements. Despite this wealth of data, there exists an untapped potential
for leveraging artificial intelligence based technological systems to benefit
Indian fishermen in coastal areas. To fill this void in the Indian technology
ecosystem, the authors introduce Jal Anveshak. This is an application framework
written in Dart and Flutter that uses a Llama 2 based Large Language Model
fine-tuned on pre-processed and augmented government data related to fishing
yield and availability. Its main purpose is to help Indian fishermen safely get
the maximum yield of fish from coastal areas and to resolve their fishing
related queries in multilingual and multimodal ways.

æè¦ï¼è¿å¹´ä¾ï¼å¨çåå°åº¦æ¿åºå¨ç£æ§åæ¶éèæ¼æ¥­ç¢æ¥­ç¸éæ¸æçåªåå·²è¦è­é¡¯èé²å±ãåç®¡æééº¼è±å¯çæ¸æï¼ä½ä»ææªéç¼çæ½åï¼å¯ä»¥å©ç¨åºæ¼äººå·¥æºæ§çæè¡ç³»çµ±ï¼è®å°åº¦æ²¿æµ·å°åçæ¼æ°åçãçºäºå¡«è£å°åº¦ç§æçæç³»çµ±ä¸­çéåç©ºç½ï¼ä½èå¼å¥äº Jal Anveshakãéæ¯ä¸åä½¿ç¨ Dart å Flutter ç·¨å¯«çæç¨ç¨å¼æ¡æ¶ï¼å®ä½¿ç¨åºæ¼ Llama 2 çå¤§åèªè¨æ¨¡åï¼éå°èæé­ç¢éåå¯ç¨æ§ç¸éçé èçåæ´åæ¿åºæ¸æé²è¡å¾®èª¿ãå¶ä¸»è¦ç®çæ¯å¹«å©å°åº¦æ¼æ°å®å¨å°å¾æ²¿æµ·å°åç²å¾æå¤§é­ç²éï¼ä¸¦ä»¥å¤èªè¨åå¤æ¨¡å¼çæ¹å¼è§£æ±ºä»åèæé­ç¸éççåã

##### **VMID: A Multimodal Fusion LLM Framework for Detecting and Identifying Misinformation of Short Videos**
2411.10032v1 by Weihao Zhong, Yinhao Xiao, Minghui Xu, Xiuzhen Cheng

Short video platforms have become important channels for news dissemination,
offering a highly engaging and immediate way for users to access current events
and share information. However, these platforms have also emerged as
significant conduits for the rapid spread of misinformation, as fake news and
rumors can leverage the visual appeal and wide reach of short videos to
circulate extensively among audiences. Existing fake news detection methods
mainly rely on single-modal information, such as text or images, or apply only
basic fusion techniques, limiting their ability to handle the complex,
multi-layered information inherent in short videos. To address these
limitations, this paper presents a novel fake news detection method based on
multimodal information, designed to identify misinformation through a
multi-level analysis of video content. This approach effectively utilizes
different modal representations to generate a unified textual description,
which is then fed into a large language model for comprehensive evaluation. The
proposed framework successfully integrates multimodal features within videos,
significantly enhancing the accuracy and reliability of fake news detection.
Experimental results demonstrate that the proposed approach outperforms
existing models in terms of accuracy, robustness, and utilization of multimodal
information, achieving an accuracy of 90.93%, which is significantly higher
than the best baseline model (SV-FEND) at 81.05%. Furthermore, case studies
provide additional evidence of the effectiveness of the approach in accurately
distinguishing between fake news, debunking content, and real incidents,
highlighting its reliability and robustness in real-world applications.

æè¦ï¼ç­å½±é³å¹³å°å·²æçºå³æ­æ°èçéè¦ç®¡éï¼çºä½¿ç¨èæä¾æ¥µå·å¸å¼åä¸å³æçæ¹å¼ä¾å­åæäºä¸¦åäº«è³è¨ãç¶èï¼éäºå¹³å°ä¹æçºé¯èª¤è³è¨è¿éæ£å¸çéè¦ç®¡éï¼å çºåæ°èåè¬ è¨å¯ä»¥å©ç¨ç­å½±é³çè¦è¦ºå¸å¼ååå»£æ³è§¸åçå¨åç¾ä¹éå»£æ³æµå³ãç¾æçåæ°èåµæ¸¬æ¹æ³ä¸»è¦ä¾è³´å®ä¸æ¨¡å¼è³è¨ï¼ä¾å¦æå­æå½±åï¼æåæç¨åºæ¬çèåæè¡ï¼éå¶äºå¶èçç­å½±é³ä¸­è¤éãå¤å±¤æ¬¡è³è¨çè½åãçºäºè§£æ±ºéäºéå¶ï¼æ¬ææåºäºä¸ç¨®åºæ¼å¤æ¨¡å¼è³è¨çæ°ç©åæ°èåµæ¸¬æ¹æ³ï¼æ¨å¨ééå°å½±é³å§å®¹é²è¡å¤å±¤æ¬¡åæä¾è­å¥é¯èª¤è³è¨ãæ­¤æ¹æ³ææå©ç¨ä¸åçæ¨¡å¼è¡¨ç¤ºä¾ç¢ççµ±ä¸çæå­æè¿°ï¼ç¶å¾å°å¶è¼¸å¥å¤§åèªè¨æ¨¡åé²è¡å¨é¢è©ä¼°ãææåºçæ¶æ§æåæ´åäºå½±çä¸­çå¤æ¨¡å¼ç¹å¾µï¼å¤§å¹æååæ°èåµæ¸¬çæºç¢ºæ§åå¯é æ§ãå¯¦é©çµæè­æï¼ææåºçæ¹æ³å¨æºç¢ºæ§ãç©©å¥æ§åå¤æ¨¡å¼è³è¨å©ç¨æ¹é¢åªæ¼ç¾ææ¨¡åï¼éå° 90.93% çæºç¢ºåº¦ï¼é¡¯èé«æ¼æä½³åºç·æ¨¡å (SV-FEND) ç 81.05%ãæ­¤å¤ï¼æ¡ä¾ç ç©¶æä¾äºé¡å¤çè­æï¼è­æè©²æ¹æ³å¨æºç¢ºåååæ°èãæ­ç©¿å§å®¹åçå¯¦äºä»¶æ¹é¢å·æææï¼çªé¡¯å¶å¨çå¯¦ä¸çæç¨ä¸­çå¯é æ§åç©©å¥æ§ã

##### **MOT\_FCG++: Enhanced Representation of Motion and Appearance Features**
2411.10028v1 by Yanzhao Fang

The goal of multi-object tracking (MOT) is to detect and track all objects in
a scene across frames, while maintaining a unique identity for each object.
Most existing methods rely on the spatial motion features and appearance
embedding features of the detected objects in consecutive frames. Effectively
and robustly representing the spatial and appearance features of long
trajectories has become a critical factor affecting the performance of MOT. We
propose a novel approach for appearance and spatial feature representation,
improving upon the clustering association method MOT\_FCG. For spatial motion
features, we propose Diagonal Modulated GIoU, which more accurately represents
the relationship between the position and shape of the objects. For appearance
features, we utilize a dynamic appearance representation that incorporates
confidence information, enabling the trajectory appearance features to be more
robust and global. Based on the baseline model MOT\_FCG, we achieved 76.1 HOTA,
80.4 MOTA and 81.3 IDF1 on the MOT17 validation set, and also achieved
competitive performance on the MOT20 and DanceTrack validation sets.

æè¦ï¼å¤ç®æ¨è¿½è¹¤ (MOT) çç®æ¨æ¯åµæ¸¬åè¿½è¹¤å ´æ¯ä¸­ææç©é«å¨ååç«æ ¼ä¸­çä½ç½®ï¼åæçºæ¯åç©é«ç¶­æä¸åç¨ç¹çè­å¥ç¢¼ã
å¤§å¤æ¸ç¾æçæ¹æ³ä¾è³´æ¼é£çºç«æ ¼ä¸­åµæ¸¬å°ç©é«çç©ºééåç¹å¾µåå¤è§åµå¥ç¹å¾µãææä¸ç©©å¥å°è¡¨ç¤ºé·è»è·¡çç©ºéåå¤è§ç¹å¾µå·²æçºå½±é¿ MOT æè½çééµå ç´ ãæåæåºäºä¸ç¨®å¤è§åç©ºéç¹å¾µè¡¨ç¤ºçæ°æ¹æ³ï¼æ¹é²äºç¾¤ééè¯æ¹æ³ MOT\_FCGãå°æ¼ç©ºééåç¹å¾µï¼æåæåºäºå°è§èª¿è£½ GIoUï¼å®æ´æºç¢ºå°è¡¨ç¤ºç©é«ä½ç½®åå½¢çä¹éçéä¿ãå°æ¼å¤è§ç¹å¾µï¼æåå©ç¨äºçµåä¿¡å¿è³è¨çåæå¤è§è¡¨ç¤ºï¼ä½¿è»è·¡å¤è§ç¹å¾µæ´å ç©©å¥ä¸å¨é¢ãæ ¹æåºæºæ¨¡å MOT\_FCGï¼æåå¨ MOT17 é©è­éä¸éå°äº 76.1 HOTAã80.4 MOTA å 81.3 IDF1ï¼ä¸¦ä¸å¨ MOT20 å DanceTrack é©è­éä¸ä¹åå¾äºå·æç«¶ç­åçæè½ã

##### **Information Extraction from Clinical Notes: Are We Ready to Switch to Large Language Models?**
2411.10020v1 by Yan Hu, Xu Zuo, Yujia Zhou, Xueqing Peng, Jimin Huang, Vipina K. Keloth, Vincent J. Zhang, Ruey-Ling Weng, Qingyu Chen, Xiaoqian Jiang, Kirk E. Roberts, Hua Xu

Backgrounds: Information extraction (IE) is critical in clinical natural
language processing (NLP). While large language models (LLMs) excel on
generative tasks, their performance on extractive tasks remains debated.
Methods: We investigated Named Entity Recognition (NER) and Relation Extraction
(RE) using 1,588 clinical notes from four sources (UT Physicians, MTSamples,
MIMIC-III, and i2b2). We developed an annotated corpus covering 4 clinical
entities and 16 modifiers, and compared instruction-tuned LLaMA-2 and LLaMA-3
against BiomedBERT in terms of performance, generalizability, computational
resources, and throughput to BiomedBERT. Results: LLaMA models outperformed
BiomedBERT across datasets. With sufficient training data, LLaMA showed modest
improvements (1% on NER, 1.5-3.7% on RE); improvements were larger with limited
training data. On unseen i2b2 data, LLaMA-3-70B outperformed BiomedBERT by 7%
(F1) on NER and 4% on RE. However, LLaMA models required more computing
resources and ran up to 28 times slower. We implemented "Kiwi," a clinical IE
package featuring both models, available at https://kiwi.clinicalnlp.org/.
Conclusion: This study is among the first to develop and evaluate a
comprehensive clinical IE system using open-source LLMs. Results indicate that
LLaMA models outperform BiomedBERT for clinical NER and RE but with higher
computational costs and lower throughputs. These findings highlight that
choosing between LLMs and traditional deep learning methods for clinical IE
applications should remain task-specific, taking into account both performance
metrics and practical considerations such as available computing resources and
the intended use case scenarios.

æè¦ï¼èæ¯ï¼è³è¨èå (IE) å¨è¨åºèªç¶èªè¨èç (NLP) ä¸­è³ééè¦ãåç®¡å¤§åèªè¨æ¨¡å (LLM) å¨çæå¼ä»»åä¸­è¡¨ç¾åºè²ï¼ä½å®åå¨èåå¼ä»»åä¸­çè¡¨ç¾ä»æç­è­°ãæ¹æ³ï¼æåä½¿ç¨ä¾èªååä¾æºï¼UT PhysiciansãMTSamplesãMIMIC-III å i2b2ï¼ç 1,588 åè¨åºç­è¨ï¼ç ç©¶äºå½åå¯¦é«è¾¨è­ (NER) åéä¿èå (RE)ãæåéç¼äºä¸åè¨»è§£èªæåº«ï¼æ¶µè 4 åè¨åºå¯¦é«å 16 åä¿®é£¾è©ï¼ä¸¦å¨æè½ãæ³åæ§ãéç®è³æºåèçéæ¹é¢ï¼å°ç¶éæä»¤å¾®èª¿ç LLaMA-2 å LLaMA-3 è BiomedBERT é²è¡æ¯è¼ãçµæï¼LLaMA æ¨¡åå¨ææè³æéçè¡¨ç¾é½åªæ¼ BiomedBERTãå¨æè¶³å¤ çè¨ç·´è³æä¸ï¼LLaMA è¡¨ç¾åºé©åº¦çé²æ­¥ï¼NER æå 1%ï¼RE æå 1.5-3.7%ï¼ï¼å¨è¨ç·´è³ææéçææ³ä¸ï¼é²æ­¥å¹åº¦æ´å¤§ãå¨æªè¦éç i2b2 è³æä¸ï¼LLaMA-3-70B å¨ NER ä¸çè¡¨ç¾åªæ¼ BiomedBERT 7%ï¼F1ï¼ï¼å¨ RE ä¸åªæ¼ 4%ãç¶èï¼LLaMA æ¨¡åéè¦æ´å¤çéç®è³æºï¼å·è¡éåº¦æ¢äº 28 åãæåå¯¦ä½äºãKiwiãï¼ä¸ååæå·åéå©åæ¨¡åçè¨åº IE å¥ä»¶ï¼å¯å¨ https://kiwi.clinicalnlp.org/ åå¾ãçµè«ï¼æ¬ç ç©¶æ¯ç¬¬ä¸åä½¿ç¨éæº LLM éç¼åè©ä¼°å¨é¢è¨åº IE ç³»çµ±çç ç©¶ãçµæé¡¯ç¤ºï¼LLaMA æ¨¡åå¨è¨åº NER å RE æ¹é¢åªæ¼ BiomedBERTï¼ä½éç®ææ¬è¼é«ï¼èçéè¼ä½ãéäºç¼ç¾å¼·èª¿ï¼å¨è¨åº IE æç¨ä¸­ï¼é¸æ LLM åå³çµ±æ·±åº¦å­¸ç¿æ¹æ³æåæ±ºæ¼ç¹å®ä»»åï¼åæèéæè½ææ¨åå¯¦éèéå ç´ ï¼ä¾å¦å¯ç¨çéç®è³æºåé æçä½¿ç¨æ¡ä¾æå¢ã

##### **Once More, With Feeling: Measuring Emotion of Acting Performances in Contemporary American Film**
2411.10018v1 by Naitian Zhou, David Bamman

Narrative film is a composition of writing, cinematography, editing, and
performance. While much computational work has focused on the writing or visual
style in film, we conduct in this paper a computational exploration of acting
performance. Applying speech emotion recognition models and a variationist
sociolinguistic analytical framework to a corpus of popular, contemporary
American film, we find narrative structure, diachronic shifts, and genre- and
dialogue-based constraints located in spoken performances.

æè¦ï¼æäºé»å½±æ¯å¯«ä½ãæå½±ãåªè¼¯åè¡¨æ¼ççµåãéç¶è¨±å¤è¨ç®å·¥ä½é½å°æ³¨æ¼é»å½±ä¸­çå¯«ä½æè¦è¦ºé¢¨æ ¼ï¼ä½æåå¨éç¯è«æä¸­é²è¡äºè¡¨æ¼çè¨ç®æ¢ç´¢ãæç¨èªé³æç·è­å¥æ¨¡ååè®ç°ç¤¾æèªè¨å­¸åææ¡æ¶å°æµè¡çç¶ä»£ç¾åé»å½±èªæåº«ä¸­ï¼æåç¼ç¾æäºçµæ§ãæ­·ææ§è½è®ä»¥åé«è£åå°è©±åºç¤çéå¶å­å¨æ¼å£èªè¡¨æ¼ä¸­ã

##### **MicroCrackAttentionNeXt: Advancing Microcrack Detection in Wave Field Analysis Using Deep Neural Networks through Feature Visualization**
2411.10015v1 by Fatahlla Moreh, Yusuf Hasan, Bilal Zahid Hussain, Mohammad Ammar, Sven Tomforde

Micro Crack detection using deep neural networks (DNNs) through an automated
pipeline using wave fields interacting with the damaged areas is highly sought
after. These high-dimensional spatio-temporal crack data are limited, and these
datasets have large dimensions in the temporal domain. The dataset presents a
substantial class imbalance, with crack pixels constituting an average of only
5% of the total pixels per sample. This extreme class imbalance poses a
challenge for deep learning models with the different micro-scale cracks, as
the network can be biased toward predicting the majority class, generally
leading to poor detection accuracy. This study builds upon the previous
benchmark SpAsE-Net, an asymmetric encoder-decoder network for micro-crack
detection. The impact of various activation and loss functions were examined
through feature space visualization using the manifold discovery and analysis
(MDA) algorithm. The optimized architecture and training methodology achieved
an accuracy of 86.85%.

æè¦ï¼å©ç¨æ³¢å ´èåæååäº¤äºä½ç¨çèªååç®¡éï¼ä½¿ç¨æ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) é²è¡å¾®è£ç´æª¢æ¸¬ååéè¦ãéäºé«ç¶­æç©ºè£ç´è³ææéï¼ä¸éäºè³æéå¨æåä¸­å·æå¤§ç¶­åº¦ãè©²è³æéåç¾åºé¡¯èçé¡å¥ä¸å¹³è¡¡ï¼å¶ä¸­è£ç´åç´ å¹³ååæ§ææ¯åæ¨£æ¬ç¸½åç´ ç 5%ãéç¨®æ¥µç«¯çé¡å¥ä¸å¹³è¡¡å°å·æä¸åå¾®å°ºåº¦è£ç´çæ·±åº¦å­¸ç¿æ¨¡åæ§æææ°ï¼å çºç¶²è·¯å¯è½ååæ¼é æ¸¬å¤æ¸é¡å¥ï¼éå¸¸å°è´æª¢æ¸¬æºç¢ºåº¦ä¸ä½³ãæ¬ç ç©¶å»ºç«å¨ååçåºæº SpAsE-Netï¼ä¸ç¨®ç¨æ¼å¾®è£ç´æª¢æ¸¬çä¸å°ç¨±ç·¨ç¢¼å¨-è§£ç¢¼å¨ç¶²è·¯ãééä½¿ç¨æµå½¢ç¼ç¾ååæ (MDA) æ¼ç®æ³é²è¡ç¹å¾µç©ºéè¦è¦ºåï¼æª¢é©äºåç¨®æ¿æ´»åæå¤±å½æ¸çå½±é¿ãæä½³åçæ¶æ§åè¨ç·´æ¹æ³éå° 86.85% çæºç¢ºåº¦ã

##### **DeepMedcast: A Deep Learning Method for Generating Intermediate Weather Forecasts among Multiple NWP Models**
2411.10010v1 by Atsushi Kudo

Numerical weather prediction (NWP) centers around the world operate a variety
of NWP models, and recent advances in AI-driven NWP models have increased the
availability of diverse NWP outputs. While this expansion holds the potential
to improve forecast accuracy, it also raises a critical challenge of
identifying the most reliable predictions for specific forecast scenarios.
Traditional approaches, such as ensemble or weighted averaging, combine
multiple NWP outputs but often generate unrealistic atmospheric fields,
complicating the production of reliable and consistent forecasts in operational
settings. In this study, we introduce DeepMedcast, a deep learning method that
generates intermediate forecast, or "medcast", between two or more NWP outputs.
Unlike ensemble averaging, DeepMedcast can provide consistent and explainable
medcast without distorting meteorological fields. This paper details the
methodology and case studies of DeepMedcast, discussing its advantages and
potential contributions to operational forecasting.

æè¦ï¼å¨çæ¸å¼å¤©æ°£é æ¸¬ (NWP) ä¸­å¿çéåç¨® NWP æ¨¡åï¼è AI é©å NWP æ¨¡åçææ°é²å±å·²æååç¨® NWP ç¢åºçå¯åå¾æ§ãéç¶æ­¤æ´åå·åæåé æ¸¬ç²¾æºåº¦çæ½åï¼ä½ä¹å¼ç¼ä¸é éå¤§ææ°ï¼å³æ¾åºç¹å®é æ¸¬æå¢ä¸­æå¯é çé æ¸¬ãå³çµ±æ¹æ³ï¼ä¾å¦éåæå æ¬å¹³åï¼æçµåå¤å NWP ç¢åºï¼ä½éå¸¸æç¢çä¸åå¯¦éçå¤§æ°£å ´ï¼ä½¿å¾å¨çéè¨­å®ä¸­ç¢çå¯é ä¸ä¸è´çé æ¸¬è®å¾è¤éãå¨æ­¤ç ç©¶ä¸­ï¼æåä»ç´¹ DeepMedcastï¼éæ¯ä¸ç¨®æ·±åº¦å­¸ç¿æ¹æ³ï¼å¯ä»¥å¨å©åæå¤å NWP ç¢åºä¹éç¢çä¸­éé æ¸¬æãmedcastããèéåå¹³åä¸åçæ¯ï¼DeepMedcast å¯ä»¥æä¾ä¸è´ä¸å¯è§£éç medcastï¼èä¸ææ­æ²æ°£è±¡å ´ãæ¬æè©³è¿° DeepMedcast çæ¹æ³è«åæ¡ä¾ç ç©¶ï¼è¨è«å¶åªé»åå°çéé æ¸¬çæ½å¨è²¢ç»ã

##### **Graph-based Complexity for Causal Effect by Empirical Plug-in**
2411.10008v1 by Rina Dechter, Annie Raichev, Alexander Ihler, Jin Tian

This paper focuses on the computational complexity of computing empirical
plug-in estimates for causal effect queries. Given a causal graph and
observational data, any identifiable causal query can be estimated from an
expression over the observed variables, called the estimand. The estimand can
then be evaluated by plugging in probabilities computed empirically from data.
In contrast to conventional wisdom, which assumes that high dimensional
probabilistic functions will lead to exponential evaluation time of the
estimand. We show that computation can be done efficiently, potentially in time
linear in the data size, depending on the estimand's hypergraph.
  In particular, we show that both the treewidth and hypertree width of the
estimand's structure bound the evaluation complexity of the plug-in estimands,
analogous to their role in the complexity of probabilistic inference in
graphical models. Often, the hypertree width provides a more effective bound,
since the empirical distributions are sparse.

æè¦ï¼æ¬æéé»æ¢è¨è¨ç®å ææææ¥è©¢çç¶é©æè£ä¼°è¨å¼ä¹è¨ç®è¤éåº¦ãåè¨­çµ¦å®ä¸åå æååè§å¯è³æï¼ä»»ä½å¯è­å¥çå ææ¥è©¢é½å¯ä»¥å¾ä¸åè§å¯è®æ¸çè¡¨éå¼ä¸­ä¼°è¨ï¼ç¨±çºä¼°è¨éãæ¥èï¼ä¼°è¨éå¯ä»¥ééå°å¾è³æä¸­ç¶é©è¨ç®åºçæ©çä»£å¥ä¾è©ä¼°ãèåè¨­é«ç¶­æ©çå½æ¸å°å°è´ä¼°è¨éçææ¸è©ä¼°æéçå³çµ±è§å¿µç¸åï¼æåé¡¯ç¤ºè¨ç®å¯ä»¥ææçå°å®æï¼æ½å¨è³æå¤§å°ç·æ§æéï¼è¦ä¼°è¨éçè¶åèå®ã
ç¹å¥å°ï¼æåé¡¯ç¤ºä¼°è¨éçµæ§çæ¨¹å¯¬åè¶æ¨¹å¯¬é½çå®äºæè£ä¼°è¨éçè©ä¼°è¤éåº¦ï¼é¡ä¼¼æ¼æ©çåå½¢æ¨¡åä¸­æ©çæ¨è«è¤éåº¦ä¸­çè§è²ãç±æ¼ç¶é©åä½æ¯ç¨ççï¼å æ­¤è¶æ¨¹å¯¬éå¸¸æä¾æ´ææççéã

##### **Orca: Enhancing Role-Playing Abilities of Large Language Models by Integrating Personality Traits**
2411.10006v1 by Yuxuan Huang

Large language models has catalyzed the development of personalized dialogue
systems, numerous role-playing conversational agents have emerged. While
previous research predominantly focused on enhancing the model's capability to
follow instructions by designing character profiles, neglecting the
psychological factors that drive human conversations. In this paper, we propose
Orca, a framework for data processing and training LLMs of custom characters by
integrating personality traits. Orca comprises four stages: (1) Personality
traits inferring, leverage LLMs to infer user's BigFive personality trait
reports and scores. (2) Data Augment, simulate user's profile, background
story, and psychological activities. (3) Dataset construction,
personality-conditioned instruction prompting (PCIP) to stimulate LLMs. (4)
Modeling and Training, personality-conditioned instruction tuning (PTIT and
PSIT), using the generated data to enhance existing open-source LLMs. We
introduce OrcaBench, the first benchmark for evaluating the quality of content
generated by LLMs on social platforms across multiple scales. Our experiments
demonstrate that our proposed model achieves superior performance on this
benchmark, demonstrating its excellence and effectiveness in perceiving
personality traits that significantly improve role-playing abilities. Our Code
is available at https://github.com/Aipura/Orca.

æè¦ï¼å¤§åè¯­è¨æ¨¡åå¬åäºä¸ªäººåå¯¹è¯ç³»ç»çå¼åï¼æ¶ç°åºä¼å¤è§è²æ®æ¼å¯¹è¯ä»£çãè½ç¶ä¹åçç ç©¶ä¸»è¦éä¸­äºéè¿è®¾è®¡è§è²æ¡£æ¡æ¥å¢å¼ºæ¨¡åéµå¾ªæä»¤çè½åï¼ä½å¿½ç¥äºæ¨å¨äººç±»å¯¹è¯çå¿çå ç´ ãå¨æ¬æä¸­ï¼æä»¬æåºäº Orcaï¼ä¸ä¸ªéè¿æ´åäººæ ¼ç¹è´¨æ¥è¿è¡æ°æ®å¤çåè®­ç»èªå®ä¹è§è²ç LLM æ¡æ¶ãOrca åå«åä¸ªé¶æ®µï¼(1) äººæ ¼ç¹è´¨æ¨æ­ï¼å©ç¨ LLM æ¨æ­ç¨æ·çäºå¤§äººæ ¼ç¹è´¨æ¥åååæ°ã(2) æ°æ®å¢å¼ºï¼æ¨¡æç¨æ·çä¸ªäººèµæãèæ¯æäºåå¿çæ´»å¨ã(3) æ°æ®éæå»ºï¼äººæ ¼æ¡ä»¶æä»¤æç¤º (PCIP) æ¥åºæ¿ LLMã(4) å»ºæ¨¡åè®­ç»ï¼äººæ ¼æ¡ä»¶æä»¤è°æ´ (PTIT å PSIT)ï¼ä½¿ç¨çæçæ°æ®æ¥å¢å¼ºç°æçå¼æº LLMãæä»¬å¼å¥äº OrcaBenchï¼è¿æ¯ç¬¬ä¸ä¸ªç¨äºè¯ä¼° LLM å¨ç¤¾äº¤å¹³å°ä¸è·¨å¤ä¸ªå°ºåº¦çæçåå®¹è´¨éçåºåãæä»¬çå®éªè¡¨æï¼æä»¬æåºçæ¨¡åå¨è¿ä¸ªåºåä¸åå¾äºä¼å¼çæ§è½ï¼å±ç¤ºäºå®å¨æç¥äººæ ¼ç¹è´¨æ¹é¢çåè¶æ§åæææ§ï¼æ¾çæé«äºè§è²æ®æ¼è½åãæä»¬çä»£ç å¯å¨ https://github.com/Aipura/Orca è·å¾ã

##### **EyeDiff: text-to-image diffusion model improves rare eye disease diagnosis**
2411.10004v1 by Ruoyu Chen, Weiyi Zhang, Bowen Liu, Xiaolan Chen, Pusheng Xu, Shunming Liu, Mingguang He, Danli Shi

The rising prevalence of vision-threatening retinal diseases poses a
significant burden on the global healthcare systems. Deep learning (DL) offers
a promising solution for automatic disease screening but demands substantial
data. Collecting and labeling large volumes of ophthalmic images across various
modalities encounters several real-world challenges, especially for rare
diseases. Here, we introduce EyeDiff, a text-to-image model designed to
generate multimodal ophthalmic images from natural language prompts and
evaluate its applicability in diagnosing common and rare diseases. EyeDiff is
trained on eight large-scale datasets using the advanced latent diffusion
model, covering 14 ophthalmic image modalities and over 80 ocular diseases, and
is adapted to ten multi-country external datasets. The generated images
accurately capture essential lesional characteristics, achieving high alignment
with text prompts as evaluated by objective metrics and human experts.
Furthermore, integrating generated images significantly enhances the accuracy
of detecting minority classes and rare eye diseases, surpassing traditional
oversampling methods in addressing data imbalance. EyeDiff effectively tackles
the issue of data imbalance and insufficiency typically encountered in rare
diseases and addresses the challenges of collecting large-scale annotated
images, offering a transformative solution to enhance the development of
expert-level diseases diagnosis models in ophthalmic field.

æè¦ï¼é¨èå¨èè¦åçè¦ç¶²èç¾ççè¡çä¸åï¼å°å¨çé«çä¿å¥ç³»çµ±é æéå¤§è² æãæ·±åº¦å­¸ç¿ (DL) çºèªåç¾çç¯©æª¢æä¾äºä¸åæå¸æçè§£æ±ºæ¹æ¡ï¼ä½éè¦å¤§éè³æãæ¶éåæ¨è¨åç¨®æ¨¡å¼çå¤§éç¼ç§å½±åæéå°è¥å¹²å¯¦éææ°ï¼å°¤å¶æ¯ç½è¦ç¾çãå¨æ­¤ï¼æåä»ç´¹ EyeDiffï¼éæ¯ä¸åæå­è½å½±åæ¨¡åï¼æ¨å¨å¾èªç¶èªè¨æç¤ºä¸­çæå¤æ¨¡å¼ç¼ç§å½±åï¼ä¸¦è©ä¼°å¶å¨è¨ºæ·å¸¸è¦åç½è¦ç¾çä¸­çé©ç¨æ§ãEyeDiff ä½¿ç¨åé²çæ½å¨æ´æ£æ¨¡åå¨å«åå¤§åè³æéä¸é²è¡è¨ç·´ï¼æ¶µè 14 ç¨®ç¼ç§å½±åæ¨¡å¼åè¶é 80 ç¨®ç¼é¨ç¾çï¼ä¸¦é©æååå¤åå¤é¨è³æéãçæçå½±åç²¾æºææå¿è¦ççç¶ç¹å¾µï¼èç±å®¢è§ææ¨åäººé¡å°å®¶è©ä¼°çæå­æç¤ºé«åº¦ä¸è´ãæ­¤å¤ï¼æ´åçæçå½±åé¡¯èå¢å¼·äºåµæ¸¬å°æ¸é¡å¥åç½è¦ç¼ç¾çæºç¢ºæ§ï¼å¨è§£æ±ºè³æä¸å¹³è¡¡æ¹é¢è¶è¶äºå³çµ±çéåº¦æ½æ¨£æ¹æ³ãEyeDiff ææè§£æ±ºäºç½è¦ç¾çä¸­éå¸¸éå°çè³æä¸å¹³è¡¡åä¸è¶³åé¡ï¼ä¸¦è§£æ±ºäºæ¶éå¤§éæ¨è¨»å½±åçææ°ï¼æä¾äºä¸åè®é©æ§çè§£æ±ºæ¹æ¡ï¼ä»¥å¢å¼·ç¼ç§é åå°å®¶ç´ç¾çè¨ºæ·æ¨¡åçéç¼ã

##### **DuSEGO: Dual Second-order Equivariant Graph Ordinary Differential Equation**
2411.10000v1 by Yingxu Wang, Nan Yin, Mingyan Xiao, Xinhao Yi, Siwei Liu, Shangsong Liang

Graph Neural Networks (GNNs) with equivariant properties have achieved
significant success in modeling complex dynamic systems and molecular
properties. However, their expressiveness ability is limited by: (1) Existing
methods often overlook the over-smoothing issue caused by traditional GNN
models, as well as the gradient explosion or vanishing problems in deep GNNs.
(2) Most models operate on first-order information, neglecting that the real
world often consists of second-order systems, which further limits the model's
representation capabilities. To address these issues, we propose the
\textbf{Du}al \textbf{S}econd-order \textbf{E}quivariant \textbf{G}raph
\textbf{O}rdinary Differential Equation (\method{}) for equivariant
representation. Specifically, \method{} apply the dual second-order equivariant
graph ordinary differential equations (Graph ODEs) on graph embeddings and node
coordinates, simultaneously. Theoretically, we first prove that \method{}
maintains the equivariant property. Furthermore, we provide theoretical
insights showing that \method{} effectively alleviates the over-smoothing
problem in both feature representation and coordinate update. Additionally, we
demonstrate that the proposed \method{} mitigates the exploding and vanishing
gradients problem, facilitating the training of deep multi-layer GNNs.
Extensive experiments on benchmark datasets validate the superiority of the
proposed \method{} compared to baselines.

æè¦ï¼<paragraph>å·æç­è®æ§è³ªçåç¥ç¶ç¶²è·¯ (GNN) å·²å¨å»ºæ¨¡è¤éåæç³»çµ±ååå­æ§è³ªæ¹é¢åå¾é¡¯èæåãç¶èï¼å®åçè¡¨ç¾è½ååå°ä»¥ä¸å ç´ éå¶ï¼(1) ç¾ææ¹æ³ç¶å¸¸å¿½ç¥å³çµ± GNN æ¨¡åé æçéåº¦å¹³æ»åé¡ï¼ä»¥åæ·±åº¦ GNN ä¸­çæ¢¯åº¦çç¸ææ¶å¤±åé¡ã(2) å¤§å¤æ¸æ¨¡åéä½æ¼ä¸éè³è¨ï¼å¿½ç¥äºç¾å¯¦ä¸çéå¸¸ç±äºéç³»çµ±çµæï¼éé²ä¸æ­¥éå¶äºæ¨¡åçè¡¨ç¤ºè½åãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºç­è®è¡¨ç¤ºç**é**äºé**S**econd-order **E**quivariant **G**raph **O**rdinary Differential Equation (\method{})ãå·é«ä¾èªªï¼\method{} åæå¨ååµå¥åç¯é»åæ¨ä¸æç¨äºéç­è®åå¸¸å¾®åæ¹ç¨å¼ (Graph ODE)ãçè«ä¸ï¼æåé¦åè­æ \method{} ä¿æç­è®æ§è³ªãæ­¤å¤ï¼æåæä¾äºçè«è¦è§£ï¼è¡¨æ \method{} ææå°ç·©è§£äºç¹å¾µè¡¨ç¤ºååº§æ¨æ´æ°ä¸­çéåº¦å¹³æ»åé¡ãæ­¤å¤ï¼æåè­æäºææåºç \method{} æ¸è¼äºçç¸åæ¶å¤±æ¢¯åº¦åé¡ï¼ä¿è¿äºå¤å±¤æ·±åº¦ GNN çè¨ç·´ãå¨åºæºè³æéä¸çå¤§éå¯¦é©é©è­äºææåºç \method{} èåºæºç¸æ¯çåªè¶æ§ã</paragraph>

##### **Building 6G Radio Foundation Models with Transformer Architectures**
2411.09996v1 by Ahmed Aboulfotouh, Ashkan Eshaghbeigi, Hatem Abou-Zeid

Foundation deep learning (DL) models are general models, designed to learn
general, robust and adaptable representations of their target modality,
enabling finetuning across a range of downstream tasks. These models are
pretrained on large, unlabeled datasets using self-supervised learning (SSL).
Foundation models have demonstrated better generalization than traditional
supervised approaches, a critical requirement for wireless communications where
the dynamic environment demands model adaptability. In this work, we propose
and demonstrate the effectiveness of a Vision Transformer (ViT) as a radio
foundation model for spectrogram learning. We introduce a Masked Spectrogram
Modeling (MSM) approach to pretrain the ViT in a self-supervised fashion. We
evaluate the ViT-based foundation model on two downstream tasks: Channel State
Information (CSI)-based Human Activity sensing and Spectrogram Segmentation.
Experimental results demonstrate competitive performance to supervised training
while generalizing across diverse domains. Notably, the pretrained ViT model
outperforms a four-times larger model that is trained from scratch on the
spectrogram segmentation task, while requiring significantly less training
time, and achieves competitive performance on the CSI-based human activity
sensing task. This work demonstrates the effectiveness of ViT with MSM for
pretraining as a promising technique for scalable foundation model development
in future 6G networks.

æè¦ï¼åºç¤æ·±åº¦å­¸ç¿ (DL) æ¨¡åæ¯éç¨æ¨¡åï¼æ¨å¨å­¸ç¿å¶ç®æ¨æ¨¡æçä¸è¬ãç©©å¥ä¸é©ææ§å¼·çè¡¨å¾µï¼å¾èéå°ä¸ç³»åä¸æ¸¸ä»»åé²è¡å¾®èª¿ãéäºæ¨¡åä½¿ç¨èªç£ç£å­¸ç¿ (SSL) å¨å¤§åãæªæ¨ç±¤çè³æéä¸é²è¡é è¨ç·´ãåºç¤æ¨¡åå·²å±ç¤ºåºæ¯å³çµ±ç£ç£æ¹æ³æ´å¥½çæ³åè½åï¼éæ¯ç¡ç·éè¨ä¸­çä¸é ééµè¦æ±ï¼å¶ä¸­åæç°å¢éè¦æ¨¡åé©ææ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºè¦è¦ºè½æå¨ (ViT) ä½çºåè­åå­¸ç¿çç¡ç·åºç¤æ¨¡åï¼ä¸¦è­æäºå¶æææ§ãæåå¼å¥äºä¸åé®ç½©åè­åå»ºæ¨¡ (MSM) æ¹æ³ï¼ä»¥èªç£ç£çæ¹å¼é è¨ç·´ ViTãæåå¨å©åä¸æ¸¸ä»»åä¸è©ä¼°äºåºæ¼ ViT çåºç¤æ¨¡åï¼åºæ¼é »éçæè³è¨ (CSI) çäººé¡æ´»åææ¸¬ååè­ååå²ãå¯¦é©çµæè­æäºèç£ç£è¨ç·´ç¸æ¯å·æç«¶ç­åçæè½ï¼åæå¨ä¸åé åä¸­é²è¡æ³åãå¼å¾æ³¨æçæ¯ï¼é è¨ç·´ç ViT æ¨¡ååªæ¼å¨åè­ååå²ä»»åä¸å¾é ­éå§è¨ç·´çååå¤§å°çæ¨¡åï¼åæéè¦é¡¯èæ¸å°çè¨ç·´æéï¼ä¸¦å¨åºæ¼ CSI çäººé¡æ´»åææ¸¬ä»»åä¸å¯¦ç¾äºç«¶ç­åçæè½ãéé å·¥ä½è­æäºå·æ MSM ç ViT å¨é è¨ç·´æ¹é¢çæææ§ï¼éæ¯ä¸ç¨®æåéçæè¡ï¼å¯ç¨æ¼æªä¾ 6G ç¶²è·¯ä¸­çå¯æ´å±åºç¤æ¨¡åéç¼ã

##### **Unlocking Transfer Learning for Open-World Few-Shot Recognition**
2411.09986v1 by Byeonggeun Kim, Juntae Lee, Kyuhong Shim, Simyung Chang

Few-Shot Open-Set Recognition (FSOSR) targets a critical real-world
challenge, aiming to categorize inputs into known categories, termed closed-set
classes, while identifying open-set inputs that fall outside these classes.
Although transfer learning where a model is tuned to a given few-shot task has
become a prominent paradigm in closed-world, we observe that it fails to expand
to open-world. To unlock this challenge, we propose a two-stage method which
consists of open-set aware meta-learning with open-set free transfer learning.
In the open-set aware meta-learning stage, a model is trained to establish a
metric space that serves as a beneficial starting point for the subsequent
stage. During the open-set free transfer learning stage, the model is further
adapted to a specific target task through transfer learning. Additionally, we
introduce a strategy to simulate open-set examples by modifying the training
dataset or generating pseudo open-set examples. The proposed method achieves
state-of-the-art performance on two widely recognized benchmarks, miniImageNet
and tieredImageNet, with only a 1.5\% increase in training effort. Our work
demonstrates the effectiveness of transfer learning in FSOSR.

æè¦ï¼å°æ ·æ¬å¼æ¾éè¯å« (FSOSR) éå¯¹å³é®ççå®ä¸çææï¼æ¨å¨å°è¾å¥åç±»å°å·²ç¥ç±»å«ï¼ç§°ä¸ºé­éç±»ï¼ï¼åæ¶è¯å«å±äºè¿äºç±»ä¹å¤çå¼æ¾éè¾å¥ãå°½ç®¡è¿ç§»å­¦ä¹ ï¼å¶ä¸­æ¨¡åéå¯¹ç»å®çå°æ ·æ¬ä»»å¡è¿è¡è°æ´ï¼å·²æä¸ºå°é­ä¸çä¸­çä¸ä¸ªçªåºèä¾ï¼ä½æä»¬è§å¯å°å®æ æ³æ©å±å°å¼æ¾ä¸çãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäºä¸ç§ä¸¤é¶æ®µæ¹æ³ï¼è¯¥æ¹æ³åæ¬å·æå¼æ¾éèªç±è¿ç§»å­¦ä¹ çå¼æ¾éæç¥åå­¦ä¹ ãå¨å¼æ¾éæç¥åå­¦ä¹ é¶æ®µï¼è®­ç»æ¨¡åä»¥å»ºç«åº¦éç©ºé´ï¼ä½ä¸ºåç»­é¶æ®µçæçèµ·ç¹ãå¨å¼æ¾éèªç±è¿ç§»å­¦ä¹ é¶æ®µï¼æ¨¡åéè¿è¿ç§»å­¦ä¹ è¿ä¸æ­¥éåºç¹å®ç®æ ä»»å¡ãæ­¤å¤ï¼æä»¬å¼å¥äºä¸ç§ç­ç¥ï¼éè¿ä¿®æ¹è®­ç»æ°æ®éæçæä¼ªå¼æ¾éç¤ºä¾æ¥æ¨¡æå¼æ¾éç¤ºä¾ãææåºçæ¹æ³å¨ä¸¤ä¸ªå¹¿æ³è®¤å¯çåºåï¼miniImageNet å tieredImageNetï¼ä¸å®ç°äºæåè¿çæ§è½ï¼è®­ç»å·¥ä½éä»å¢å äº 1.5%ãæä»¬çå·¥ä½è¯æäºè¿ç§»å­¦ä¹ å¨ FSOSR ä¸­çæææ§ã

##### **HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**
2411.09978v1 by Yifan Zeng

This paper proposes HistoLens, a multi-layered analysis framework for
historical texts based on Large Language Models (LLMs). Using the important
Western Han dynasty text "Yantie Lun" as a case study, we demonstrate the
framework's potential applications in historical research and education.
HistoLens integrates NLP technology (especially LLMs), including named entity
recognition, knowledge graph construction, and geographic information
visualization. The paper showcases how HistoLens explores Western Han culture
in "Yantie Lun" through multi-dimensional, visual, and quantitative methods,
focusing particularly on the influence of Confucian and Legalist thoughts on
political, economic, military, and ethnic. We also demonstrate how HistoLens
constructs a machine teaching scenario using LLMs for explainable analysis,
based on a dataset of Confucian and Legalist ideas extracted with LLM
assistance. This approach offers novel and diverse perspectives for studying
historical texts like "Yantie Lun" and provides new auxiliary tools for history
education. The framework aims to equip historians and learners with
LLM-assisted tools to facilitate in-depth, multi-layered analysis of historical
texts and foster innovation in historical education.

æè¦ï¼æ¬ææåº HistoLensï¼ä¸ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çå¤å±¤åææ¶æ§ï¼ç¨æ¼æ­·å²ææ¬ãä½¿ç¨éè¦çè¥¿æ¼¢çæææ¬ãé¹½éµè«ãä½çºåæ¡ç ç©¶ï¼æåå±ç¤ºäºè©²æ¶æ§å¨æ­·å²ç ç©¶åæè²ä¸­çæ½å¨æç¨ãHistoLens æ´åäº NLP æè¡ï¼å°¤å¶æ¯ LLMï¼ï¼åæ¬å½åå¯¦é«è­å¥ãç¥è­åè­å»ºæ§åå°çè³è¨è¦è¦ºåãæ¬æå±ç¤ºäº HistoLens å¦ä½ééå¤ç¶­åº¦ãè¦è¦ºååéåæ¹æ³æ¢ç´¢ãé¹½éµè«ãä¸­çè¥¿æ¼¢æåï¼ç¹å¥éæ³¨åå®¶åæ³å®¶ææ³å°æ¿æ²»ãç¶æ¿ãè»äºåç¨®æçå½±é¿ãæåéå±ç¤ºäº HistoLens å¦ä½å»ºæ§ä¸åä½¿ç¨ LLM çæ©å¨æå­¸å ´æ¯ï¼ä»¥é²è¡å¯è§£éåæï¼éæ¯åºæ¼ LLM åå©æåçåå®¶åæ³å®¶ææ³è³æéãéç¨®æ¹æ³çºç ç©¶ãé¹½éµè«ãç­æ­·å²ææ¬æä¾äºæ°ç©ä¸å¤æ¨£åçè§é»ï¼ä¸¦çºæ­·å²æè²æä¾äºæ°çè¼å©å·¥å·ãè©²æ¶æ§æ¨å¨çºæ­·å²å­¸å®¶åå­¸ç¿èæä¾ LLM åå©çå·¥å·ï¼ä»¥å©æ¼æ·±å¥ãå¤å±¤æ¬¡å°åææ­·å²ææ¬ï¼ä¸¦ä¿é²æ­·å²æè²çåµæ°ã

##### **Large Language Models as User-Agents for Evaluating Task-Oriented-Dialogue Systems**
2411.09972v1 by Taaha Kazi, Ruiliang Lyu, Sizhe Zhou, Dilek Hakkani-Tur, Gokhan Tur

Traditionally, offline datasets have been used to evaluate task-oriented
dialogue (TOD) models. These datasets lack context awareness, making them
suboptimal benchmarks for conversational systems. In contrast, user-agents,
which are context-aware, can simulate the variability and unpredictability of
human conversations, making them better alternatives as evaluators. Prior
research has utilized large language models (LLMs) to develop user-agents. Our
work builds upon this by using LLMs to create user-agents for the evaluation of
TOD systems. This involves prompting an LLM, using in-context examples as
guidance, and tracking the user-goal state. Our evaluation of diversity and
task completion metrics for the user-agents shows improved performance with the
use of better prompts. Additionally, we propose methodologies for the automatic
evaluation of TOD models within this dynamic framework.

æè¦ï¼å³çµ±ä¸ï¼é¢ç·è³æéå·²è¢«ç¨æ¼è©ä¼°ä»»åå°åå°è©± (TOD) æ¨¡åãéäºè³æéç¼ºä¹æå¢æè­ï¼ä½¿å¶æçºå°è©±ç³»çµ±æ¬¡ä½³çåºæºãç¸æ¯ä¹ä¸ï¼å·åæå¢æè­çä½¿ç¨èä»£çå¯ä»¥æ¨¡æ¬äººé¡å°è©±çå¤è®æ§åä¸å¯é æ¸¬æ§ï¼ä½¿å¶æçºæ´å¥½çè©ä¼°èæ¿ä»£æ¹æ¡ãååçç ç©¶å·²å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾éç¼ä½¿ç¨èä»£çãæåçç ç©¶å»ºç«å¨éååºç¤ä¸ï¼ä½¿ç¨ LLM çº TOD ç³»çµ±çè©ä¼°å»ºç«ä½¿ç¨èä»£çãéæ¶åæç¤º LLMï¼ä½¿ç¨æå¢ä¸­çç¯ä¾ä½çºæå°ï¼ä¸¦è¿½è¹¤ä½¿ç¨èç®æ¨çæãæåå°ä½¿ç¨èä»£ççå¤æ¨£æ§åä»»åå®æææ¨çè©ä¼°é¡¯ç¤ºï¼ä½¿ç¨æ´å¥½çæç¤ºå¯ä»¥æ¹åæè½ãæ­¤å¤ï¼æåæåºå¨éååææ¶æ§ä¸­èªåè©ä¼° TOD æ¨¡åçæ¹æ³ã

##### **Steering AI-Driven Personalization of Scientific Text for General Audiences**
2411.09969v1 by Taewook Kim, Dhruv Agarwal, Jordan Ackerman, Manaswi Saha

Digital media platforms (e.g., social media, science blogs) offer
opportunities to communicate scientific content to general audiences at scale.
However, these audiences vary in their scientific expertise, literacy levels,
and personal backgrounds, making effective science communication challenging.
To address this challenge, we designed TranSlider, an AI-powered tool that
generates personalized translations of scientific text based on individual user
profiles (e.g., hobbies, location, and education). Our tool features an
interactive slider that allows users to steer the degree of personalization
from 0 (weakly relatable) to 100 (strongly relatable), leveraging LLMs to
generate the translations with given degrees. Through an exploratory study with
15 participants, we investigated both the utility of these AI-personalized
translations and how interactive reading features influenced users'
understanding and reading experiences. We found that participants who preferred
higher degrees of personalization appreciated the relatable and contextual
translations, while those who preferred lower degrees valued concise
translations with subtle contextualization. Furthermore, participants reported
the compounding effect of multiple translations on their understanding of
scientific content. Given these findings, we discuss several implications of
AI-personalized translation tools in facilitating communication in
collaborative contexts.

æè¦ï¼æ¸ä½åªé«å¹³å°ï¼ä¾å¦ç¤¾ç¾¤åªé«ãç§å­¸é¨è½æ ¼ï¼æä¾æ©æï¼å¯ä»¥å¤§è¦æ¨¡å°åä¸è¬å¤§ç¾å³éç§å­¸å§å®¹ãç¶èï¼éäºåç¾çç§å­¸å°æ¥­ç¥è­ãè­å­ç¨åº¦ååäººèæ¯åä¸ç¸åï¼éä½¿å¾ææçç§å­¸å³æ­å·æææ°æ§ãçºäºæå°éé ææ°ï¼æåè¨­è¨äº TranSliderï¼éæ¯ä¸æ¬¾ç± AI é©åçå·¥å·ï¼å®æ ¹æåå¥ä½¿ç¨èçåäººè³æï¼ä¾å¦åå¥½ãä½ç½®åæè²ç¨åº¦ï¼ç¢çç§å­¸æå­çåäººåç¿»è­¯ãæåçå·¥å·å·æä¸åäºåå¼æ»æ¡¿ï¼ä½¿ç¨æ¶å¯ä»¥å¾ 0ï¼éè¯æ§ä½ï¼å° 100ï¼éè¯æ§é«ï¼èª¿æ´åäººåçç¨åº¦ï¼ä¸¦å©ç¨å¤§åèªè¨æ¨¡å (LLM) ç¢çå·æç¹å®ç¨åº¦çç¿»è­¯ãééä¸é åå« 15 ä½åèèçæ¢ç´¢æ§ç ç©¶ï¼æåæ¢è¨äºéäº AI åäººåç¿»è­¯çæç¨ï¼ä»¥åäºåå¼é±è®åè½å¦ä½å½±é¿ä½¿ç¨èççè§£åé±è®é«é©ãæåç¼ç¾ï¼è¼åå¥½é«åäººåç¨åº¦çåèèæ¬£è³ç¸éä¸æèçµ¡çç¿»è­¯ï¼èè¼åå¥½ä½åäººåç¨åº¦çåèèåéè¦ç°¡æ½ä¸èçµ¡åä¸é£éº¼æé¡¯çç¿»è­¯ãæ­¤å¤ï¼åèèåå ±äºå¤éç¿»è­¯å°ä»åçè§£ç§å­¸å§å®¹çç´¯å ææãæ ¹æéäºç¼ç¾ï¼æåè¨è«äº AI åäººåç¿»è­¯å·¥å·å¨ä¿é²åä½ç°å¢ä¸­æºéçå¹¾åå½±é¿ã

##### **Seeing Clearly by Layer Two: Enhancing Attention Heads to Alleviate Hallucination in LVLMs**
2411.09968v1 by Xiaofeng Zhang, Yihao Quan, Chaochen Gu, Chen Shen, Xiaosong Yuan, Shaotian Yan, Hao Cheng, Kaijie Wu, Jieping Ye

The hallucination problem in multimodal large language models (MLLMs) remains
a common issue. Although image tokens occupy a majority of the input sequence
of MLLMs, there is limited research to explore the relationship between image
tokens and hallucinations. In this paper, we analyze the distribution of
attention scores for image tokens across each layer and head of the model,
revealing an intriguing and common phenomenon: most hallucinations are closely
linked to the pattern of attention sinks in the self-attention matrix of image
tokens, where shallow layers exhibit dense attention sinks and deeper layers
show sparse attention sinks. We further analyze the attention heads of
different layers and find that heads with high-density attention sink in the
image part play a positive role in alleviating hallucinations. In this paper,
we propose a training-free method named \textcolor{red}{\textbf{E}}nhancing
\textcolor{red}{\textbf{A}}ttention \textcolor{red}{\textbf{H}}eads (EAH), an
approach designed to enhance the convergence of image tokens attention sinks in
the shallow layers. EAH identifies the attention head that shows the vision
sink in a shallow layer and extracts its attention matrix. This attention map
is then broadcast to other heads in the layer, thereby strengthening the layer
to pay more attention to the image itself. With extensive experiments, EAH
shows significant hallucination-mitigating performance on different MLLMs and
metrics, proving its effectiveness and generality.

æè¦ï¼å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) ä¸­çå¹»è§é®é¢ä»ç¶æ¯ä¸ä¸ªå¸¸è§é®é¢ãå°½ç®¡å¾åæ è®°å æ®äº MLLM è¾å¥åºåçå¤§é¨åï¼ä½æ¢ç´¢å¾åæ è®°åå¹»è§ä¹é´å³ç³»çç ç©¶å´å¾æéãå¨æ¬æä¸­ï¼æä»¬åæäºè·¨æ¨¡åçæ¯ä¸å±åå¤´çå¾åæ è®°çæ³¨æååæ°åå¸ï¼æ­ç¤ºäºä¸ä¸ªæè¶£ä¸æ®éçç°è±¡ï¼å¤§å¤æ°å¹»è§ä¸å¾åæ è®°çèªæ³¨æåç©éµä¸­çæ³¨æåæ±èæ¨¡å¼å¯åç¸å³ï¼å¶ä¸­æµå±è¡¨ç°åºå¯éçæ³¨æåæ±èï¼èæ·±å±è¡¨ç°åºç¨ççæ³¨æåæ±èãæä»¬è¿ä¸æ­¥åæäºä¸åå±çæ³¨æåå¤´ï¼åç°å¾åé¨åä¸­å·æé«å¯åº¦æ³¨æåæ±èçæ³¨æåå¤´å¨åè½»å¹»è§ä¸­èµ·å°äºç§¯æä½ç¨ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ç§åä¸º\textcolor{red}{\textbf{E}}nhancing \textcolor{red}{\textbf{A}}ttention \textcolor{red}{\textbf{H}}eads (EAH) çåè®­ç»æ¹æ³ï¼è¿æ¯ä¸ç§æ¨å¨å¢å¼ºæµå±ä¸­å¾åæ è®°æ³¨æåæ±èæ¶ææ§çæ¹æ³ãEAH è¯å«åºå¨æµå±ä¸­æ¾ç¤ºè§è§æ±èçæ³¨æåå¤´å¹¶æåå¶æ³¨æåç©éµãç¶åå°æ­¤æ³¨æåå¾å¹¿æ­å°å±ä¸­çå¶ä»å¤´ï¼ä»èå¢å¼ºè¯¥å±å¯¹å¾åæ¬èº«çå³æ³¨ãéè¿å¹¿æ³çå®éªï¼EAH å¨ä¸åç MLLM åææ ä¸æ¾ç¤ºåºæ¾ççç¼è§£å¹»è§çæ§è½ï¼è¯æäºå¶æææ§åæ®éæ§ã

##### **Instruction-Guided Editing Controls for Images and Multimedia: A Survey in LLM era**
2411.09955v1 by Thanh Tam Nguyen, Zhao Ren, Trinh Pham, Phi Le Nguyen, Hongzhi Yin, Quoc Viet Hung Nguyen

The rapid advancement of large language models (LLMs) and multimodal learning
has transformed digital content creation and manipulation. Traditional visual
editing tools require significant expertise, limiting accessibility. Recent
strides in instruction-based editing have enabled intuitive interaction with
visual content, using natural language as a bridge between user intent and
complex editing operations. This survey provides an overview of these
techniques, focusing on how LLMs and multimodal models empower users to achieve
precise visual modifications without deep technical knowledge. By synthesizing
over 100 publications, we explore methods from generative adversarial networks
to diffusion models, examining multimodal integration for fine-grained content
control. We discuss practical applications across domains such as fashion, 3D
scene manipulation, and video synthesis, highlighting increased accessibility
and alignment with human intuition. Our survey compares existing literature,
emphasizing LLM-empowered editing, and identifies key challenges to stimulate
further research. We aim to democratize powerful visual editing across various
industries, from entertainment to education. Interested readers are encouraged
to access our repository at
https://github.com/tamlhp/awesome-instruction-editing.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) åå¤æ¨¡æå­¸ç¿çå¿«éé²å±å·²ç¶è½è®äºæ¸ä½å§å®¹çå»ºç«åæä½ãå³çµ±çè¦è¦ºç·¨è¼¯å·¥å·éè¦å¤§éçå°æ¥­ç¥è­ï¼éå¶äºå¯åæ§ãæè¿å¨åºæ¼æä»¤çç·¨è¼¯ä¸åå¾çé²å±ï¼ä½¿ç¨èªç¶èªè¨ä½çºä½¿ç¨èæååè¤éç·¨è¼¯æä½ä¹éçæ©æ¢ï¼å¯¦ç¾äºèè¦è¦ºå§å®¹çç´è¦ºäºåãéé èª¿æ¥æä¾äºéäºæè¡çæ¦è¿°ï¼éé»å¨æ¼ LLM åå¤æ¨¡ææ¨¡åå¦ä½è®ä½¿ç¨èå¨æ²ææ·±å¥æè¡ç¥è­çææ³ä¸ï¼å¯¦ç¾ç²¾ç¢ºçè¦è¦ºä¿®æ¹ãééç¶åè¶é 100 ç¯åºçåï¼æåæ¢è¨äºå¾çæå°æç¶²è·¯å°æ´æ£æ¨¡åçæ¹æ³ï¼æª¢è¦å¤æ¨¡ææ´åä»¥é²è¡ç´°ç·»çå§å®¹æ§å¶ãæåè¨è«äºå¨æå°ã3D å ´æ¯æä½åå½±çåæç­é åçå¯¦éæç¨ï¼å¼·èª¿äºå¯åæ§çæååèäººé¡ç´è¦ºçä¸è´æ§ãæåçèª¿æ¥æ¯è¼äºç¾æçæç»ï¼å¼·èª¿äº LLM è³¦è½çç·¨è¼¯ï¼ä¸¦æ¾åºééµææ°ä»¥æ¿åµé²ä¸æ­¥çç ç©¶ãæåçç®æ¨æ¯è®å¼·å¤§çè¦è¦ºç·¨è¼¯å¨åç¨®ç¢æ¥­ä¸­æ°ä¸»åï¼å¾å¨æ¨å°æè²ãæåé¼åµæèè¶£çè®èå­åæåçè³æºåº«ï¼
https://github.com/tamlhp/awesome-instruction-editingã

##### **GGAvatar: Reconstructing Garment-Separated 3D Gaussian Splatting Avatars from Monocular Video**
2411.09952v1 by Jingxuan Chen

Avatar modelling has broad applications in human animation and virtual
try-ons. Recent advancements in this field have focused on high-quality and
comprehensive human reconstruction but often overlook the separation of
clothing from the body. To bridge this gap, this paper introduces GGAvatar
(Garment-separated 3D Gaussian Splatting Avatar), which relies on monocular
videos. Through advanced parameterized templates and unique phased training,
this model effectively achieves decoupled, editable, and realistic
reconstruction of clothed humans. Comparative evaluations with other costly
models confirm GGAvatar's superior quality and efficiency in modelling both
clothed humans and separable garments. The paper also showcases applications in
clothing editing, as illustrated in Figure 1, highlighting the model's benefits
and the advantages of effective disentanglement. The code is available at
https://github.com/J-X-Chen/GGAvatar/.

æè¦ï¼åèº«å»ºæ¨¡å¨äººé¡åç«åèæ¬è©¦ç©¿ä¸­å·æå»£æ³çæç¨ãæè¿å¨éåé åçé²å±å°æ³¨æ¼é«åè³ªåå¨é¢çéå»ºï¼ä½å¸¸å¸¸å¿½ç¥äºå°è¡£ç©èèº«é«åéãçºäºå½è£éåå·®è·ï¼æ¬æä»ç´¹äº GGAvatarï¼åé¢è¡£ç©ç 3D é«æ¯æ½æ¿ºåèº«ï¼ï¼å®ä¾è³´æ¼å®ç¼å½±çãééåé²çåæ¸åç¯æ¬åç¨ç¹çéæ®µè¨ç·´ï¼éåæ¨¡åææå°éå°äºåé¢ãå¯ç·¨è¼¯åé¼ççç©¿èäººé¡éå»ºãèå¶ä»æè²´æ¨¡åçæ¯è¼è©ä¼°è­å¯¦äº GGAvatar å¨å»ºæ¨¡ç©¿èäººé¡åå¯åé¢è¡£ç©æ¹é¢çåªç°åè³ªåæçãæ¬æéå±ç¤ºäºæè£ç·¨è¼¯çæç¨ï¼å¦å 1 æç¤ºï¼çªåºäºè©²æ¨¡åçåªé»åææè§£éç³¾çºçåªå¢ãç¨å¼ç¢¼å¯å¨ https://github.com/J-X-Chen/GGAvatar/ åå¾ã

##### **LoRA-LiteE: A Computationally Efficient Framework for Chatbot Preference-Tuning**
2411.09947v1 by Yahe Yang, Chunliang Tao, Xiaojing Fan

Effective preference tuning is pivotal in aligning chatbot responses with
human expectations, enhancing user satisfaction and engagement. Traditional
approaches, notably Reinforcement Learning from Human Feedback (RLHF) as
employed in advanced models like GPT-4, have demonstrated considerable success
in this domain. However, RLHF methods are often computationally intensive and
resource-demanding, limiting their scalability and accessibility for broader
applications. To address these challenges, this study introduces LoRA-Lite
Ensemble (LoRA-LiteE), an innovative framework that combines Supervised
Fine-tuning (SFT) with Low-Rank Adaptation (LoRA) and Ensemble Learning
techniques to effectively aggregate predictions of lightweight models, which
aim to achieve a balance between the performance and computational cost.
Utilizing the Chatbot Arena benchmark dataset, we conduct a comprehensive
comparative analysis among our LoRA-LiteE model, corresponding base models at
different scales, and GPT-4 trained with RLHF. Our empirical results
demonstrate that the proposed LoRA-LiteE model achieves comparable performance
to un-finetuned GPT-4 and outperforms the single larger-scale models under
limited resource constraints. These findings highlight that our LoRA-LiteE
provides a feasible and efficient methodology for human preference prediction
in chatbot systems, enhancing scalability and accessibility, and thereby
broadening the applicability of preference-tuned chatbots in
resource-constrained environments.

æè¦ï¼<paragraph>ææçåå¥½èª¿æ´å°æ¼å°èå¤©æ©å¨äººåæèäººé¡ææä¿æä¸è´è³ééè¦ï¼å¾èå¢å¼·ç¨æ¶æ»¿æåº¦ååèåº¦ãå³çµ±æ¹æ³ï¼å°¤å¶æ¯å GPT-4 ç­åé²æ¨¡åä¸­æ¡ç¨çåºæ¼äººé¡åé¥çå¼·åå­¸ç¿ (RLHF)ï¼å·²è­æå¨éåé ååå¾äºé¡¯èæåãç¶èï¼RLHF æ¹æ³éå¸¸è¨ç®éå¤§ä¸éè¦å¤§éè³æºï¼ééå¶äºå®åå¨æ´å»£æ³æç¨ä¸­çå¯æ´å±æ§åå¯è¨ªåæ§ãçºäºæå°éäºææ°ï¼æ¬ç ç©¶å¼å¥äº LoRA-Lite Ensemble (LoRA-LiteE)ï¼éæ¯ä¸ååµæ°çæ¡æ¶ï¼å®å°ç£ç£å¾®èª¿ (SFT) èä½ç§©é©æ (LoRA) åéæå­¸ç¿æè¡ç¸çµåï¼ä»¥ææå°å¯ç¸½è¼éç´æ¨¡åçé æ¸¬ï¼æ¨å¨æ§è½èè¨ç®ææ¬ä¹éåå¾å¹³è¡¡ãå©ç¨ Chatbot Arena åºæºæ¸æéï¼æåå°æåç LoRA-LiteE æ¨¡åãä¸åè¦æ¨¡çå°æåºç¤æ¨¡åä»¥åä½¿ç¨ RLHF è¨ç·´ç GPT-4 é²è¡äºå¨é¢çæ¯è¼åæãæåçå¯¦è­çµæè¡¨æï¼ææåºç LoRA-LiteE æ¨¡åå¯¦ç¾äºèæªå¾®èª¿ç GPT-4 ç¸ç¶çæ§è½ï¼ä¸¦ä¸å¨æéçè³æºç´æä¸åªæ¼å®åæ´å¤§è¦æ¨¡çæ¨¡åãéäºç¼ç¾å¼·èª¿äºæåç LoRA-LiteE çºèå¤©æ©å¨äººç³»çµ±ä¸­çäººé¡åå¥½é æ¸¬æä¾äºä¸ç¨®å¯è¡ä¸é«æçæ¹æ³ï¼å¢å¼·äºå¯æ´å±æ§åå¯è¨ªåæ§ï¼å¾èæ´å¤§äºåå¥½èª¿æ´èå¤©æ©å¨äººå¨è³æºåéç°å¢ä¸­çé©ç¨æ§ã</paragraph>

##### **TEESlice: Protecting Sensitive Neural Network Models in Trusted Execution Environments When Attackers have Pre-Trained Models**
2411.09945v1 by Ding Li, Ziqi Zhang, Mengyu Yao, Yifeng Cai, Yao Guo, Xiangqun Chen

Trusted Execution Environments (TEE) are used to safeguard on-device models.
However, directly employing TEEs to secure the entire DNN model is challenging
due to the limited computational speed. Utilizing GPU can accelerate DNN's
computation speed but commercial widely-available GPUs usually lack security
protection. To this end, scholars introduce TSDP, a method that protects
privacy-sensitive weights within TEEs and offloads insensitive weights to GPUs.
Nevertheless, current methods do not consider the presence of a knowledgeable
adversary who can access abundant publicly available pre-trained models and
datasets. This paper investigates the security of existing methods against such
a knowledgeable adversary and reveals their inability to fulfill their security
promises. Consequently, we introduce a novel partition before training
strategy, which effectively separates privacy-sensitive weights from other
components of the model. Our evaluation demonstrates that our approach can
offer full model protection with a computational cost reduced by a factor of
10. In addition to traditional CNN models, we also demonstrate the scalability
to large language models. Our approach can compress the private functionalities
of the large language model to lightweight slices and achieve the same level of
protection as the shielding-whole-model baseline.

æè¦ï¼åä¿¡ä»»å·è¡ç°å¢ (TEE) ç¨æ¼ä¿è­·è£ç½®ä¸çæ¨¡åã
ç¶èï¼ç±æ¼éç®éåº¦æéï¼ç´æ¥ä½¿ç¨ TEE ä¿è­·æ´å DNN æ¨¡åå·æææ°æ§ãå©ç¨ GPU å¯ä»¥å é DNN çéç®éåº¦ï¼ä½å¸é¢ä¸æ®éå¯ç¨ç GPU éå¸¸ç¼ºä¹å®å¨æ§ä¿è­·ãçºæ­¤ï¼å­¸èåå¼å¥äº TSDPï¼ä¸ç¨®å¨ TEE å§ä¿è­·é±ç§æææ¬éä¸¦å°ä¸æææ¬éå¸è¼å° GPU çæ¹æ³ã
åç®¡å¦æ­¤ï¼ç®åçæ¹æ³ä¸¦æªèæ®ç¥è­æ·µåçå°æï¼ä»åå¯ä»¥å­åå¤§éå¬éå¯ç¨çé è¨ç·´æ¨¡ååè³æéãæ¬ææ¢è¨äºç¾ææ¹æ³éå°æ­¤é¡ç¥è­æ·µåå°æçå®å¨æ§ï¼ä¸¦æ­ç¤ºäºä»åç¡æ³å±¥è¡å®å¨æ¿è«¾ãå æ­¤ï¼æåå¨è¨ç·´ç­ç¥ä¹åå¼å¥äºåµæ°çåå²ï¼ææå°å°é±ç§æææ¬éèæ¨¡åçå¶ä»çµæé¨ååéãæåçè©ä¼°è¡¨æï¼æåçåæ³å¯ä»¥æä¾å®æ´çæ¨¡åä¿è­·ï¼åæå°éç®ææ¬éä½äº 10 åãé¤äºå³çµ±ç CNN æ¨¡åå¤ï¼æåéå±ç¤ºäºå¯æ´åæ§è³å¤§åèªè¨æ¨¡åãæåçåæ³å¯ä»¥å°å¤§åèªè¨æ¨¡åçç§æåè½å£ç¸®æè¼éç´åçï¼ä¸¦å¯¦ç¾èä¿è­·æ´åæ¨¡åçåºæºç·ç¸åçä¿è­·ç´å¥ã

##### **SlimLM: An Efficient Small Language Model for On-Device Document Assistance**
2411.09944v1 by Thang M. Pham, Phat T. Nguyen, Seunghyun Yoon, Viet Dac Lai, Franck Dernoncourt, Trung Bui

While small language models (SLMs) show promises for mobile deployment, their
real-world performance and applications on smartphones remains underexplored.
We present SlimLM, a series of SLMs optimized for document assistance tasks on
mobile devices. Through extensive experiments on a Samsung Galaxy S24, we
identify the optimal trade-offs between model size (ranging from 125M to 7B
parameters), context length, and inference time for efficient on-device
processing. SlimLM is pre-trained on SlimPajama-627B and fine-tuned on
DocAssist, our constructed dataset for summarization, question answering and
suggestion tasks. Our smallest model demonstrates efficient performance on S24,
while larger variants offer enhanced capabilities within mobile constraints. We
evaluate SlimLM against existing SLMs, showing comparable or superior
performance and offering a benchmark for future research in on-device language
models. We also provide an Android application, offering practical insights
into SLM deployment. Our findings provide valuable insights and illuminate the
capabilities of running advanced language models on high-end smartphones,
potentially reducing server costs and enhancing privacy through on-device
processing.

æè¦ï¼åç®¡å°åèªè¨æ¨¡å (SLM) å°æ¼è¡åè£ç½®é¨ç½²èè¨æ¥µå·åæ¯ï¼ä½å¶å¨æºæ§åææ©ä¸çå¯¦éæè½åæç¨ä»æå¾æ·±å¥æ¢è¨ãæåæåº SlimLMï¼éæ¯ä¸ç³»åéå°è¡åè£ç½®ä¸çæä»¶è¼å©ä»»åèæä½³åç SLMãééå¨ Samsung Galaxy S24 ä¸é²è¡å»£æ³çå¯¦é©ï¼æåæ¾åºæ¨¡åå¤§å°ï¼ç¯åå¾ 125M å° 7B åæ¸ï¼ãå§å®¹é·åº¦åæ¨è«æéä¹éçæä½³åæ¨ï¼ä»¥å©æ¼é«æçè£ç½®å§èçãSlimLM é åå¨ SlimPajama-627B ä¸é²è¡è¨ç·´ï¼ä¸¦å¨ DocAssistï¼æåå»ºæ§çæè¦ãåç­åå»ºè­°ä»»åè³æéï¼ä¸é²è¡å¾®èª¿ãæåæå°çæ¨¡åå¨ S24 ä¸å±ç¾åºé«æè½ï¼èè¼å¤§çè®é«åå¨è¡åè£ç½®éå¶å§æä¾å¢å¼·çåè½ãæåéå°ç¾æç SLM è©ä¼° SlimLMï¼å±ç¾åºç¸è¿ææ´åªç°çæè½ï¼ä¸¦çºæªä¾çè£ç½®å§èªè¨æ¨¡åç ç©¶æä¾ä¸ååºæºãæåä¹æä¾ä¸å Android æç¨ç¨å¼ï¼æä¾ SLM é¨ç½²çå¯¦ç¨è¦è§£ãæåçç ç©¶çµææä¾æå¹å¼çè¦è§£ï¼ä¸¦é¡æå¨é«éæºæ§åææ©ä¸å·è¡é²éèªè¨æ¨¡åçè½åï¼éæå¯è½ééè£ç½®å§èçä¾éä½ä¼ºæå¨ææ¬ä¸¦å¢å¼·é±ç§æ¬ã

##### **Refined and Segmented Price Sentiment Indices from Survey Comments**
2411.09937v1 by Masahiro Suzuki, Hiroki Sakaji

We aim to enhance a price sentiment index and to more precisely understand
price trends from the perspective of not only consumers but also businesses. We
extract comments related to prices from the Economy Watchers Survey conducted
by the Cabinet Office of Japan and classify price trends using a large language
model (LLM). We classify whether the survey sample reflects the perspective of
consumers or businesses, and whether the comments pertain to goods or services
by utilizing information on the fields of comments and the industries of
respondents included in the Economy Watchers Survey. From these classified
price-related comments, we construct price sentiment indices not only for a
general purpose but also for more specific objectives by combining perspectives
on consumers and prices, as well as goods and services. It becomes possible to
achieve a more accurate classification of price directions by employing a LLM
for classification. Furthermore, integrating the outputs of multiple LLMs
suggests the potential for the better performance of the classification. The
use of more accurately classified comments allows for the construction of an
index with a higher correlation to existing indices than previous studies. We
demonstrate that the correlation of the price index for consumers, which has a
larger sample size, is further enhanced by selecting comments for aggregation
based on the industry of the survey respondents.

æè¦ï¼æä»¬æ¨å¨æåä»·æ ¼æç»ªææ°ï¼å¹¶ä»æ¶è´¹èåä¼ä¸çè§åº¦æ´åç¡®å°äºè§£ä»·æ ¼è¶å¿ãæä»¬ä»æ¥æ¬åéåºè¿è¡çç»æµè§å¯èè°æ¥ä¸­æåä¸ä»·æ ¼ç¸å³çè¯è®ºï¼å¹¶ä½¿ç¨å¤§åè¯­è¨æ¨¡å (LLM) å¯¹ä»·æ ¼è¶å¿è¿è¡åç±»ãæä»¬éè¿å©ç¨ç»æµè§å¯èè°æ¥ä¸­åå«çè¯è®ºé¢åååè®¿èè¡ä¸çä¿¡æ¯ï¼å¯¹è°æ¥æ ·æ¬æ¯åæ æ¶è´¹èè¿æ¯ä¼ä¸çè§ç¹ä»¥åè¯è®ºæ¯å¦æ¶åååææå¡è¿è¡åç±»ãä»è¿äºåç±»çä»·æ ¼ç¸å³è¯è®ºä¸­ï¼æä»¬ä¸ä»éå¯¹ä¸è¬ç®çï¼è¿éå¯¹æ´å·ä½çç®æ æå»ºä»·æ ¼æç»ªææ°ï¼æ¹æ³æ¯ç»åæ¶è´¹èåä»·æ ¼ä»¥ååååæå¡çè§ç¹ãéè¿ä½¿ç¨ LLM è¿è¡åç±»ï¼å¯ä»¥æ´åç¡®å°å¯¹ä»·æ ¼æ¹åè¿è¡åç±»ãæ­¤å¤ï¼æ´åå¤ä¸ª LLM çè¾åºè¡¨æåç±»æ§è½æ´å¥½çå¯è½æ§ãä½¿ç¨æ´åç¡®åç±»çè¯è®ºå¯ä»¥æå»ºä¸ä¸ªä¸ç°æææ°ç¸å³æ§é«äºä»¥åç ç©¶çææ°ãæä»¬è¯æäºæ ·æ¬éè¾å¤§çæ¶è´¹èä»·æ ¼ææ°çç¸å³æ§éè¿æ ¹æ®è°æ¥åè®¿èçè¡ä¸éæ©ç¨äºèåçè¯è®ºèè¿ä¸æ­¥æé«ã

##### **JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging**
2411.09933v1 by Kaito Baba, Ryota Yagi, Junichiro Takahashi, Risa Kishikawa, Satoshi Kodera

With the rapid advancement of large language models (LLMs), foundational
models (FMs) have seen significant advancements. Healthcare is one of the most
crucial application areas for these FMs, given the significant time and effort
required for physicians to analyze large volumes of patient data. Recent
efforts have focused on adapting multimodal FMs to the medical domain through
techniques like instruction-tuning, leading to the development of medical
foundation models (MFMs). However, these approaches typically require large
amounts of training data to effectively adapt models to the medical field.
Moreover, most existing models are trained on English datasets, limiting their
practicality in non-English-speaking regions where healthcare professionals and
patients are not always fluent in English. The need for translation introduces
additional costs and inefficiencies. To address these challenges, we propose a
\textbf{J}apanese \textbf{Radi}ology report generation model enhanced by
\textbf{Evo}lutionary optimization of model merging (JRadiEvo). This is the
first attempt to extend a non-medical vision-language foundation model to the
medical domain through evolutionary optimization of model merging. We
successfully created a model that generates accurate Japanese reports from
X-ray images using only 50 translated samples from publicly available data.
This model, developed with highly efficient use of limited data, outperformed
leading models from recent research trained on much larger datasets.
Additionally, with only 8 billion parameters, this relatively compact
foundation model can be deployed locally within hospitals, making it a
practical solution for environments where APIs and other external services
cannot be used due to strict privacy and security requirements.

æè¦ï¼<paragraph>é¨èå¤§åèªè¨æ¨¡å (LLM) çå¿«éé²å±ï¼åºç¤æ¨¡å (FM) å·²ç¶ç²å¾é¡¯èçé²æ­¥ãé«çä¿å¥æ¯éäº FM æéè¦çæç¨é åä¹ä¸ï¼å çºé«çéè¦è±è²»å¤§éæéåç²¾åä¾åæå¤§éçæ£èè³æãæè¿çç ç©¶éé»å¨æ¼ééæä»¤å¾®èª¿ç­æè¡å°å¤æ¨¡æ FM é©æå°é«çé åï¼å¾èéç¼åºé«çåºç¤æ¨¡å (MFM)ãç¶èï¼éäºæ¹æ³éå¸¸éè¦å¤§éçè¨ç·´è³ææè½ææå°å°æ¨¡åé©æå°é«çé åãæ­¤å¤ï¼å¤§å¤æ¸ç¾ææ¨¡åé½æ¯éå°è±èªè³æéé²è¡è¨ç·´ï¼ééå¶äºå®åå¨éè±èªå°åçå¯¦ç¨æ§ï¼é£è£¡çé«çå°æ¥­äººå¡åæ£èä¸¦ä¸ç¸½æ¯ç²¾éè±èªãç¿»è­¯çéæ±å¼å¥äºé¡å¤çææ¬åä½æçãçºäºæå°éäºææ°ï¼æåæåºäºä¸åç±æ¨¡ååä½µçé²ååªåå¢å¼·ç**J**apanese **Radi**ology å ±åçææ¨¡å (JRadiEvo)ãéæ¯é¦æ¬¡åè©¦ééæ¨¡ååä½µçé²ååªåå°éé«çè¦è¦ºèªè¨åºç¤æ¨¡åæ´å±å°é«çé åãæåæåå°å»ºç«äºä¸åæ¨¡åï¼åä½¿ç¨ä¾èªå¬éè³æç 50 åç¿»è­¯ç¯ä¾ï¼å°±è½å¾ X åå½±åä¸­ç¢çæºç¢ºçæ¥æå ±åãéåæ¨¡åä½¿ç¨æéè³æé²è¡é«æççéç¼ï¼å¶æè½åªæ¼æè¿ç ç©¶ä¸­å¨æ´å¤§è³æéä¸è¨ç·´åºä¾çé åæ¨¡åãæ­¤å¤ï¼éåç¸å°ç²¾ç°¡çåºç¤æ¨¡ååªæ 80 åååæ¸ï¼å¯ä»¥å¨é«é¢å§é¨é²è¡æ¬å°é¨ç½²ï¼ä½¿å¶æçºå¨å´æ ¼çé±ç§åå®å¨è¦æ±ä¸ç¡æ³ä½¿ç¨ API åå¶ä»å¤é¨æåçç°å¢ä¸­çå¯¦ç¨è§£æ±ºæ¹æ¡ã</paragraph>

##### **Motion-Grounded Video Reasoning: Understanding and Perceiving Motion at Pixel Level**
2411.09921v1 by Andong Deng, Tongjia Chen, Shoubin Yu, Taojiannan Yang, Lincoln Spencer, Yapeng Tian, Ajmal Saeed Mian, Mohit Bansal, Chen Chen

In this paper, we introduce Motion-Grounded Video Reasoning, a new motion
understanding task that requires generating visual answers (video segmentation
masks) according to the input question, and hence needs implicit spatiotemporal
reasoning and grounding. This task extends existing spatiotemporal grounding
work focusing on explicit action/motion grounding, to a more general format by
enabling implicit reasoning via questions. To facilitate the development of the
new task, we collect a large-scale dataset called GROUNDMORE, which comprises
1,715 video clips, 249K object masks that are deliberately designed with 4
question types (Causal, Sequential, Counterfactual, and Descriptive) for
benchmarking deep and comprehensive motion reasoning abilities. GROUNDMORE
uniquely requires models to generate visual answers, providing a more concrete
and visually interpretable response than plain texts. It evaluates models on
both spatiotemporal grounding and reasoning, fostering to address complex
challenges in motion-related video reasoning, temporal perception, and
pixel-level understanding. Furthermore, we introduce a novel baseline model
named Motion-Grounded Video Reasoning Assistant (MORA). MORA incorporates the
multimodal reasoning ability from the Multimodal LLM, the pixel-level
perception capability from the grounding model (SAM), and the temporal
perception ability from a lightweight localization head. MORA achieves
respectable performance on GROUNDMORE outperforming the best existing visual
grounding baseline model by an average of 21.5% relatively. We hope this novel
and challenging task will pave the way for future advancements in robust and
general motion understanding via video reasoning segmentation

æè¦ï¼<paragraph>æ¬æä¸­ï¼æåä»ç´¹äºéååºç¤å½±çæ¨çï¼éæ¯ä¸ç¨®æ°çéåçè§£ä»»åï¼éè¦æ ¹æè¼¸å¥åé¡çæè¦è¦ºç­æ¡ï¼å½±çåå²é®ç½©ï¼ï¼å æ­¤éè¦é±å«çæç©ºæ¨çååºç¤ãæ­¤ä»»åæ´å±äºç¾æçæç©ºåºç¤å·¥ä½ï¼å°æ³¨æ¼æç¢ºçåä½/éååºç¤ï¼ééåé¡åç¨é±å«æ¨çï¼è½è®çºæ´éç¨çæ ¼å¼ãçºäºä¿é²æ°ä»»åçç¼å±ï¼æåæ¶éäºä¸ååçº GROUNDMORE çå¤§åè³æéï¼å¶ä¸­åå« 1,715 åå½±çåªè¼¯ã249K åç©ä»¶é®ç½©ï¼éäºé®ç½©ç¶éç²¾å¿è¨­è¨ï¼æ 4 ç¨®é¡åçåé¡ï¼å æãé åºãåäºå¯¦åæè¿°æ§ï¼ï¼ç¨æ¼è©éæ·±å¥ä¸å¨é¢çéåæ¨çè½åãGROUNDMORE ç¨ç¹å°è¦æ±æ¨¡åçæè¦è¦ºç­æ¡ï¼æä¾æ¯ç´æå­æ´å·é«ä¸è¦è¦ºä¸å¯è§£éçåæãå®å¨æç©ºåºç¤åæ¨çä¸è©ä¼°æ¨¡åï¼ä¿é²äºè§£èéåç¸éçå½±çæ¨çãæéæç¥ååç´ å±¤ç´çè§£ä¸­çè¤éææ°ãæ­¤å¤ï¼æåä»ç´¹äºä¸ååçºéååºç¤å½±çæ¨çå©çï¼MORAï¼çæ°ç©åºç·æ¨¡åãMORA çµåäºå¤æ¨¡æ LLM çå¤æ¨¡ææ¨çè½åãåºç¤æ¨¡åï¼SAMï¼çåç´ å±¤ç´æç¥è½åï¼ä»¥åè¼éç´å®ä½é ­çæéæç¥è½åãMORA å¨ GROUNDMORE ä¸åå¾äºä»¤äººå°æ¬çæè½ï¼å¹³ååªæ¼ç¾ææä½³è¦è¦ºåºç¤åºç·æ¨¡å 21.5%ãæåå¸æéåæ°ç©ä¸å·æææ°æ§çä»»åå°çºééå½±çæ¨çåå²ï¼å¨ç©©å¥ä¸éç¨çéåçè§£æ¹é¢æªä¾é²å±éªè·¯ã</paragraph>

##### **AMXFP4: Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference**
2411.09909v1 by Janghwan Lee, Jiwoong Park, Jinseok Kim, Yongjik Kim, Jungju Oh, Jinwook Oh, Jungwook Choi

Scaling Large Language Models (LLMs) with extended context lengths has
increased the need for efficient low-bit quantization to manage their
substantial computational demands. However, reducing precision to 4 bits
frequently degrades performance due to activation outliers. To address this, we
propose Asymmetric Microscaling 4-bit Floating-Point (AMXFP4) for efficient LLM
inference. This novel data format leverages asymmetric shared scales to
mitigate outliers while naturally capturing the asymmetry introduced by
group-wise quantization. Unlike conventional 4-bit quantization methods that
rely on data rotation and costly calibration, AMXFP4 uses asymmetric shared
scales for direct 4-bit casting, achieving near-ideal quantization accuracy
across various LLM tasks, including multi-turn conversations, long-context
reasoning, and visual question answering. Our AMXFP4 format significantly
outperforms MXFP4 and other leading quantization techniques, enabling robust,
calibration-free 4-bit inference.

æè¦ï¼æ´å±ä¸ä¸æé·åº¦çå¤§èªè¨æ¨¡å (LLM) çæ´å±ï¼å¢å äºå°ææä½ä½åéåç®¡çå¶å¤§ééç®éæ±çéæ±ãç¶èï¼å°ç²¾åº¦éä½å° 4 ä½åç¶å¸¸æå çºååå¼ç°å¸¸å¼èéä½æè½ãçºäºè§£æ±ºéååé¡ï¼æåæåºéå°ç¨±å¾®ç¸® 4 ä½åæµ®é»æ¸ (AMXFP4) ä»¥é²è¡ææç LLM æ¨è«ãéç¨®æ°ç©çè³ææ ¼å¼å©ç¨éå°ç¨±å±äº«æ¯ä¾ä¾æ¸è¼ç°å¸¸å¼ï¼åæèªç¶ææç¾¤çµéåå¼å¥çéå°ç¨±æ§ãèä¾è³´è³ææè½åæè²´æ ¡æºçå³çµ± 4 ä½åéåæ¹æ³ä¸åï¼AMXFP4 ä½¿ç¨éå°ç¨±å±äº«æ¯ä¾é²è¡ç´æ¥ 4 ä½åè½æï¼å¨åç¨® LLM ä»»åä¸­å¯¦ç¾æ¥è¿çæ³çéåç²¾åº¦ï¼åæ¬å¤è¼ªå°è©±ãé·èçµ¡æ¨çåè¦è¦ºåç­ãæåç AMXFP4 æ ¼å¼æé¡¯åªæ¼ MXFP4 åå¶ä»é åçéåæè¡ï¼å¯¦ç¾å¼·å¥ãç¡éæ ¡æºç 4 ä½åæ¨è«ã

##### **Statistical Analysis of Policy Space Compression Problem**
2411.09900v1 by Majid Molaei, Marcello Restelli, Alberto Maria Metelli, Matteo Papini

Policy search methods are crucial in reinforcement learning, offering a
framework to address continuous state-action and partially observable problems.
However, the complexity of exploring vast policy spaces can lead to significant
inefficiencies. Reducing the policy space through policy compression emerges as
a powerful, reward-free approach to accelerate the learning process. This
technique condenses the policy space into a smaller, representative set while
maintaining most of the original effectiveness. Our research focuses on
determining the necessary sample size to learn this compressed set accurately.
We employ R\'enyi divergence to measure the similarity between true and
estimated policy distributions, establishing error bounds for good
approximations. To simplify the analysis, we employ the $l_1$ norm, determining
sample size requirements for both model-based and model-free settings. Finally,
we correlate the error bounds from the $l_1$ norm with those from R\'enyi
divergence, distinguishing between policies near the vertices and those in the
middle of the policy space, to determine the lower and upper bounds for the
required sample sizes.

æè¦ï¼ç­ç¥æç´¢æ¹æ³å¨å¼ºåå­¦ä¹ ä¸­è³å³éè¦ï¼å®æä¾äºä¸ä¸ªè§£å³è¿ç»­ç¶æå¨ä½åé¨åå¯è§å¯é®é¢çæ¡æ¶ãç¶èï¼æ¢ç´¢å¹¿éç­ç¥ç©ºé´çå¤ææ§å¯è½å¯¼è´ä¸¥éçä½æçãéè¿ç­ç¥åç¼©æ¥åå°ç­ç¥ç©ºé´æä¸ºä¸ç§å¼ºå¤§çãæ å¥å±çæ¹æ³ï¼å¯ä»¥å éå­¦ä¹ è¿ç¨ãè¿ç§ææ¯å°ç­ç¥ç©ºé´åç¼©å°ä¸ä¸ªæ´å°ãæ´å·ä»£è¡¨æ§çéåä¸­ï¼åæ¶ä¿æå¤§é¨åçåå§æææ§ãæä»¬çç ç©¶éç¹æ¯ç¡®å®å­¦ä¹ è¿ä¸ªåç¼©éåæéçæ ·æ¬éãæä»¬éç¨ R\'enyi æ£åº¦æ¥è¡¡éçå®ç­ç¥åå¸åä¼°è®¡ç­ç¥åå¸ä¹é´çç¸ä¼¼æ§ï¼ä¸ºè¯å¥½çè¿ä¼¼å¼å»ºç«è¯¯å·®çéãä¸ºäºç®ååæï¼æä»¬éç¨ $l_1$ èæ°ï¼ç¡®å®åºäºæ¨¡ååæ æ¨¡åè®¾ç½®çæ ·æ¬ééæ±ãæåï¼æä»¬å° $l_1$ èæ°çè¯¯å·®çéä¸ R\'enyi æ£åº¦çè¯¯å·®çéç¸å³èï¼åºåæ¥è¿é¡¶ç¹çç­ç¥åç­ç¥ç©ºé´ä¸­é´çç­ç¥ï¼ä»¥ç¡®å®æéæ ·æ¬éçä¸éåä¸éã

##### **Research on Domain-Specific Chinese Spelling Correction Method Based on Plugin Extension Modules**
2411.09884v1 by Xiaowu Zhang, Hongfei Zhao, Xuan Chang

This paper proposes a Chinese spelling correction method based on plugin
extension modules, aimed at addressing the limitations of existing models in
handling domain-specific texts. Traditional Chinese spelling correction models
are typically trained on general-domain datasets, resulting in poor performance
when encountering specialized terminology in domain-specific texts. To address
this issue, we design an extension module that learns the features of
domain-specific terminology, thereby enhancing the model's correction
capabilities within specific domains. This extension module can provide domain
knowledge to the model without compromising its general spelling correction
performance, thus improving its accuracy in specialized fields. Experimental
results demonstrate that after integrating extension modules for medical,
legal, and official document domains, the model's correction performance is
significantly improved compared to the baseline model without any extension
modules.

æè¦ï¼æ¬ææåºä¸ååºæ¼å¤æç¨å¼æ´åæ¨¡çµçä¸­ææ¼å¯«ä¿®æ­£æ¹æ³ï¼æ¨å¨è§£æ±ºç¾ææ¨¡åå¨èçç¹å®é åææ¬æçéå¶ãå³çµ±çä¸­ææ¼å¯«ä¿®æ­£æ¨¡åéå¸¸å¨ä¸è¬é åçè³æéä¸è¨ç·´ï¼å¨éå°ç¹å®é åææ¬ä¸­çå°æ¥­è¡èªæï¼æè½ä¸ä½³ãçºäºè§£æ±ºéååé¡ï¼æåè¨­è¨äºä¸åæ´åæ¨¡çµï¼å­¸ç¿ç¹å®é åè¡èªçç¹å¾µï¼å¾èå¢å¼·æ¨¡åå¨ç¹å®é åå§çä¿®æ­£è½åãæ­¤æ´åæ¨¡çµå¯ä»¥åæ¨¡åæä¾é åç¥è­ï¼èä¸æå½±é¿å¶ä¸è¬æ¼å¯«ä¿®æ­£æè½ï¼å¾èæé«å¶å¨å°æ¥­é åçæºç¢ºæ§ãå¯¦é©çµæè¡¨æï¼å¨æ´åäºé«çãæ³å¾åå®æ¹æä»¶é åçæ´åæ¨¡çµå¾ï¼æ¨¡åçä¿®æ­£æè½èæ²æä»»ä½æ´åæ¨¡çµçåºæºæ¨¡åç¸æ¯ï¼é¡¯èæåã

##### **A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation**
2411.09874v1 by Chin-Sung Tung, Sheng-Fu Liang, Shu-Feng Chang, Chung-Ping Young

Electroencephalography (EEG) plays a crucial role in the diagnosis of various
neurological disorders. However, small hospitals and clinics often lack
advanced EEG signal analysis systems and are prone to misinterpretation in
manual EEG reading. This study proposes an innovative hybrid artificial
intelligence (AI) system for automatic interpretation of EEG background
activity and report generation. The system combines deep learning models for
posterior dominant rhythm (PDR) prediction, unsupervised artifact removal, and
expert-designed algorithms for abnormality detection. For PDR prediction, 1530
labeled EEGs were used, and the best ensemble model achieved a mean absolute
error (MAE) of 0.237, a root mean square error (RMSE) of 0.359, an accuracy of
91.8% within a 0.6Hz error, and an accuracy of 99% within a 1.2Hz error. The AI
system significantly outperformed neurologists in detecting generalized
background slowing (p = 0.02; F1: AI 0.93, neurologists 0.82) and demonstrated
improved focal abnormality detection, although not statistically significant (p
= 0.79; F1: AI 0.71, neurologists 0.55). Validation on both an internal dataset
and the Temple University Abnormal EEG Corpus showed consistent performance
(F1: 0.884 and 0.835, respectively; p = 0.66), demonstrating generalizability.
The use of large language models (LLMs) for report generation demonstrated 100%
accuracy, verified by three other independent LLMs. This hybrid AI system
provides an easily scalable and accurate solution for EEG interpretation in
resource-limited settings, assisting neurologists in improving diagnostic
accuracy and reducing misdiagnosis rates.

æè¦ï¼è¦é»åï¼EEGï¼å¨è¨ºæ·åç¨®ç¥ç¶ç¾çä¸­æ®æ¼è³ééè¦çè§è²ãç¶èï¼å°åé«é¢åè¨ºæéå¸¸ç¼ºä¹é²éç EEG è¨èåæç³»çµ±ï¼ä¸å®¹æå¨æåå¤è® EEG æç¢çèª¤è§£ãæ¬ç ç©¶æåºä¸ååµæ°çæ··åäººå·¥æºæ§ï¼AIï¼ç³»çµ±ï¼ç¨æ¼èªåå¤è® EEG èæ¯æ´»åä¸¦ç¢çå ±åãæ­¤ç³»çµ±çµåæ·±åº¦å­¸ç¿æ¨¡åï¼ç¨æ¼é æ¸¬å¾åªå¢å¾åï¼PDRï¼ãéç£ç£äººå·¥è£½åç§»é¤ï¼ä»¥åå°å®¶è¨­è¨çç°å¸¸åµæ¸¬æ¼ç®æ³ãå¨ PDR é æ¸¬ä¸­ï¼ä½¿ç¨äº 1530 åæ¨è¨ EEGï¼æä½³çæ´é«æ¨¡åéå°äº 0.237 çå¹³åçµå°èª¤å·®ï¼MAEï¼ã0.359 çåæ¹æ ¹èª¤å·®ï¼RMSEï¼ã91.8% ç 0.6Hz èª¤å·®æºç¢ºåº¦ï¼ä»¥å 99% ç 1.2Hz èª¤å·®æºç¢ºåº¦ãAI ç³»çµ±å¨åµæ¸¬å»£æ³èæ¯æ¸æ¢æ¹é¢æé¡¯åªæ¼ç¥ç¶å­¸å®¶ï¼p = 0.02ï¼F1ï¼AI 0.93ï¼ç¥ç¶å­¸å®¶ 0.82ï¼ï¼ä¸¦å±ç¾åºæ¹åçå±é¨ç°å¸¸åµæ¸¬ï¼åç®¡æ²æçµ±è¨æç¾©ï¼p = 0.79ï¼F1ï¼AI 0.71ï¼ç¥ç¶å­¸å®¶ 0.55ï¼ãå¨å§é¨è³æéå Temple University ç°å¸¸ EEG èªæåº«ä¸çé©è­é¡¯ç¤ºäºä¸è´çæè½ï¼F1ï¼åå¥çº 0.884 å 0.835ï¼p = 0.66ï¼ï¼è­æäºå¶æ®éæ§ãä½¿ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼ä¾ç¢çå ±åè­æäº 100% çæºç¢ºåº¦ï¼ä¸¦ç±å¶ä»ä¸åç¨ç«ç LLM é©è­ãæ­¤æ··å AI ç³»çµ±æä¾äºä¸åææ¼æ´åä¸æºç¢ºçè§£æ±ºæ¹æ¡ï¼ç¨æ¼å¨è³æºæéçç°å¢ä¸­é²è¡ EEG å¤è®ï¼åå©ç¥ç¶å­¸å®¶æé«è¨ºæ·æºç¢ºåº¦ä¸¦éä½èª¤è¨ºçã

##### **Enhancing Diffusion Posterior Sampling for Inverse Problems by Integrating Crafted Measurements**
2411.09850v1 by Shijie Zhou, Huaisheng Zhu, Rohan Sharma, Ruiyi Zhang, Kaiyi Ji, Changyou Chen

Diffusion models have emerged as a powerful foundation model for visual
generation. With an appropriate sampling process, it can effectively serve as a
generative prior to solve general inverse problems. Current posterior sampling
based methods take the measurement (i.e., degraded image sample) into the
posterior sampling to infer the distribution of the target data (i.e., clean
image sample). However, in this manner, we show that high-frequency information
can be prematurely introduced during the early stages, which could induce
larger posterior estimate errors during the restoration sampling. To address
this issue, we first reveal that forming the log posterior gradient with the
noisy measurement ( i.e., samples from a diffusion forward process) instead of
the clean one can benefit the reverse process. Consequently, we propose a novel
diffusion posterior sampling method DPS-CM, which incorporates a Crafted
Measurement (i.e., samples generated by a reverse denoising process, compared
to random sampling with noise in standard methods) to form the posterior
estimate. This integration aims to mitigate the misalignment with the diffusion
prior caused by cumulative posterior estimate errors. Experimental results
demonstrate that our approach significantly improves the overall capacity to
solve general and noisy inverse problems, such as Gaussian deblurring,
super-resolution, inpainting, nonlinear deblurring, and tasks with Poisson
noise, relative to existing approaches.

æè¦ï¼æ´æ£æ¨¡åå·²æçºè¦è¦ºçæçæååºç¤æ¨¡åãééé©ç¶çåæ¨£ç¨åºï¼å®å¯ä»¥ææå°ä½çºçæåé©ä¾è§£æ±ºä¸è¬çéåé¡ãç¶åçå¾é©åæ¨£æ¹æ³å°æ¸¬éï¼å³éåçå½±åæ¨£æ¬ï¼ç´å¥å¾é©åæ¨£ï¼ä»¥æ¨æ·ç®æ¨è³æï¼å³ä¹¾æ·¨çå½±åæ¨£æ¬ï¼çåå¸ãç¶èï¼æåå¨æ­¤é¡¯ç¤ºï¼é«é »çè³è¨å¯è½æå¨æ©æéæ®µéæ©å°è¢«å¼å¥ï¼éå¯è½æå¨éååæ¨£æéå°è´è¼å¤§çå¾é©ä¼°è¨èª¤å·®ãçºäºè§£æ±ºæ­¤åé¡ï¼æåé¦åæ­ç¤ºï¼ä½¿ç¨æéè¨çæ¸¬éï¼å³å¾æ´æ£ååéç¨ä¸­åæ¨£çæ¨£æ¬ï¼èä¸æ¯ä¹¾æ·¨çæ¸¬éä¾å½¢æå°æ¸å¾é©æ¢¯åº¦ï¼æå©æ¼ååéç¨ãå æ­¤ï¼æåæåºäºä¸ç¨®æ°çæ´æ£å¾é©åæ¨£æ¹æ³ DPS-CMï¼å®çµåäºç²¾å¿è£½ä½çæ¸¬éï¼å³ç±ååå»éè¨éç¨çæçæ¨£æ¬ï¼èæ¨æºæ¹æ³ä¸­çéè¨é¨æ©åæ¨£ç¸æ¯ï¼ä¾å½¢æå¾é©ä¼°è¨ãéç¨®æ´åæ¨å¨æ¸è¼ç±ç´¯ç©å¾é©ä¼°è¨èª¤å·®å¼èµ·çèæ´æ£åé©çä¸ä¸è´ãå¯¦é©çµæè¡¨æï¼èç¾ææ¹æ³ç¸æ¯ï¼æåçåæ³é¡¯èæ¹åäºè§£æ±ºä¸è¬åæéè¨çéåé¡çæ´é«è½åï¼ä¾å¦é«æ¯å»æ¨¡ç³ãè¶è§£æåº¦ãå§æãéç·æ§å»æ¨¡ç³ï¼ä»¥åå·ææ³æ¾éè¨çä»»åã

##### **Self-Supervised Radio Pre-training: Toward Foundational Models for Spectrogram Learning**
2411.09849v1 by Ahmed Aboulfotouh, Ashkan Eshaghbeigi, Dimitrios Karslidis, Hatem Abou-Zeid

Foundational deep learning (DL) models are general models, trained on large,
diverse, and unlabelled datasets, typically using self-supervised learning
techniques have led to significant advancements especially in natural language
processing. These pretrained models can be fine-tuned for related downstream
tasks, offering faster development and reduced training costs, while often
achieving improved performance. In this work, we introduce Masked Spectrogram
Modeling, a novel self-supervised learning approach for pretraining
foundational DL models on radio signals. Adopting a Convolutional LSTM
architecture for efficient spatio-temporal processing, we pretrain the model
with an unlabelled radio dataset collected from over-the-air measurements.
Subsequently, the pretrained model is fine-tuned for two downstream tasks:
spectrum forecasting and segmentation. Experimental results demonstrate that
our methodology achieves competitive performance in both forecasting accuracy
and segmentation, validating its effectiveness for developing foundational
radio models.

æè¦ï¼åºç¤æ·±åº¦å­¸ç¿ (DL) æ¨¡åçºä¸è¬æ¨¡åï¼è¨ç·´æ¼å¤§åãå¤æ¨£ä¸æªæ¨è¨çè³æéä¸ï¼éå¸¸ä½¿ç¨èªæç£ç£å­¸ç¿æè¡ï¼å·²å°è´é¡¯èçé²å±ï¼ç¹å¥æ¯å¨èªç¶èªè¨èçä¸­ãéäºé è¨ç·´æ¨¡åå¯å¾®èª¿ä»¥é²è¡ç¸éçä¸æ¸¸ä»»åï¼æä¾æ´å¿«çéç¼éåº¦åéä½çè¨ç·´ææ¬ï¼åæéå¸¸è½æåæè½ãå¨æ­¤ç ç©¶ä¸­ï¼æåä»ç´¹é®ç½©èªè­æ¨¡åï¼ä¸ç¨®ç¨æ¼å¨ç¡ç·é»è¨èä¸é è¨ç·´åºç¤ DL æ¨¡åçæ°ç©èªæç£ç£å­¸ç¿æ¹æ³ãæ¡ç¨å·ç© LSTM æ¶æ§ä»¥é²è¡ææççæç©ºèçï¼æåä½¿ç¨å¾ç¡ç·éæ¸¬ä¸­æ¶éçæªæ¨è¨ç¡ç·é»è³æéé è¨ç·´æ¨¡åãé¨å¾ï¼é è¨ç·´æ¨¡åæå¾®èª¿ä»¥é²è¡å©åä¸æ¸¸ä»»åï¼é »è­é æ¸¬ååå²ãå¯¦é©çµæè­æï¼æåçæè¡å¨é æ¸¬æºç¢ºåº¦ååå²æ¹é¢é½éå°äºç«¶ç­åï¼é©è­äºå¶å¨éç¼åºç¤ç¡ç·é»æ¨¡åæ¹é¢çæææ§ã

##### **Deep Autoencoders for Unsupervised Anomaly Detection in Wildfire Prediction**
2411.09844v1 by Ä°rem Ãstek, Miguel Arana-Catania, Alexander Farr, Ivan Petrunin

Wildfires pose a significantly increasing hazard to global ecosystems due to
the climate crisis. Due to its complex nature, there is an urgent need for
innovative approaches to wildfire prediction, such as machine learning. This
research took a unique approach, differentiating from classical supervised
learning, and addressed the gap in unsupervised wildfire prediction using
autoencoders and clustering techniques for anomaly detection. Historical
weather and normalised difference vegetation index datasets of Australia for
2005 - 2021 were utilised. Two main unsupervised approaches were analysed. The
first used a deep autoencoder to obtain latent features, which were then fed
into clustering models, isolation forest, local outlier factor and one-class
SVM for anomaly detection. The second approach used a deep autoencoder to
reconstruct the input data and use reconstruction errors to identify anomalies.
Long Short-Term Memory (LSTM) autoencoders and fully connected (FC)
autoencoders were employed in this part, both in an unsupervised way learning
only from nominal data. The FC autoencoder outperformed its counterparts,
achieving an accuracy of 0.71, an F1-score of 0.74, and an MCC of 0.42. These
findings highlight the practicality of this method, as it effectively predicts
wildfires in the absence of ground truth, utilising an unsupervised learning
technique.

æè¦ï¼éç«å æ°åå±æºå¯¹å¨ççæç³»ç»æææ¥çä¸¥éçå±å®³ãç±äºå¶å¤ææ§ï¼è¿«åéè¦éç¨åæ°æ¹æ³æ¥é¢æµéç«ï¼ä¾å¦æºå¨å­¦ä¹ ãæ¬ç ç©¶éåäºä¸ç§ç¬ç¹çæ¹æ³ï¼åºå«äºç»å¸ççç£å­¦ä¹ ï¼å¹¶ä½¿ç¨èªå¨ç¼ç å¨åèç±»ææ¯è§£å³äºæ çç£éç«é¢æµä¸­çå·®è·ï¼ç¨äºå¼å¸¸æ£æµãå©ç¨äº 2005 å¹´è³ 2021 å¹´æ¾³å¤§å©äºçåå²å¤©æ°åå½ä¸åå·®å¼æ¤è¢«ææ°æ°æ®éãåæäºä¸¤ç§ä¸»è¦çæ çç£æ¹æ³ãç¬¬ä¸ä¸ªä½¿ç¨æ·±åº¦èªå¨ç¼ç å¨æ¥è·åæ½å¨ç¹å¾ï¼ç¶åå°å¶è¾å¥èç±»æ¨¡åãéç¦»æ£®æãå±é¨å¼å¸¸å å­åä¸ç±» SVM ä»¥è¿è¡å¼å¸¸æ£æµãç¬¬äºç§æ¹æ³ä½¿ç¨æ·±åº¦èªå¨ç¼ç å¨æ¥éå»ºè¾å¥æ°æ®å¹¶ä½¿ç¨éå»ºè¯¯å·®æ¥è¯å«å¼å¸¸ãé¿ç­æè®°å¿ (LSTM) èªå¨ç¼ç å¨åå¨è¿æ¥ (FC) èªå¨ç¼ç å¨ç¨äºè¿é¨åï¼ä¸¤èé½ä»¥æ çç£çæ¹å¼ä»ä»æ ç§°æ°æ®ä¸­å­¦ä¹ ãFC èªå¨ç¼ç å¨ä¼äºå¶å¯¹åºé¡¹ï¼åç¡®çè¾¾å° 0.71ï¼F1 åæ°ä¸º 0.74ï¼MCC ä¸º 0.42ãè¿äºåç°çªåºäºè¯¥æ¹æ³çå®ç¨æ§ï¼å ä¸ºå®å¨æ²¡æå°é¢çå®å¼çæåµä¸ææå°é¢æµéç«ï¼å©ç¨æ çç£å­¦ä¹ ææ¯ã

##### **Real-time Adapting Routing (RAR): Improving Efficiency Through Continuous Learning in Software Powered by Layered Foundation Models**
2411.09837v1 by Kirill Vasilevski, Dayi Lin, Ahmed Hassan

To balance the quality and inference cost of a Foundation Model (FM, such as
large language models (LLMs)) powered software, people often opt to train a
routing model that routes requests to FMs with different sizes and
capabilities. Existing routing models rely on learning the optimal routing
decision from carefully curated data, require complex computations to be
updated, and do not consider the potential evolution of weaker FMs. In this
paper, we propose Real-time Adaptive Routing (RAR), an approach to continuously
adapt FM routing decisions while using guided in-context learning to enhance
the capabilities of weaker FM. The goal is to reduce reliance on stronger, more
expensive FMs. We evaluate our approach on different subsets of the popular
MMLU benchmark. Over time, our approach routes 50.2% fewer requests to
computationally expensive models while maintaining around 90.5% of the general
response quality. In addition, the guides generated from stronger models have
shown intra-domain generalization and led to a better quality of responses
compared to an equivalent approach with a standalone weaker FM.

æè¦ï¼çºäºå¹³è¡¡ç±åºç¤æ¨¡å (FMï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM)) é©åçè»é«åè³ªåæ¨è«ææ¬ï¼äººåéå¸¸é¸æè¨ç·´ä¸åè·¯ç±æ¨¡åï¼å°è«æ±è·¯ç±å°å·æä¸åå¤§å°ååè½ç FMãç¾æçè·¯ç±æ¨¡åä¾è³´æ¼å¾ä»ç´°ç­åçè³æä¸­å­¸ç¿æä½³è·¯ç±æ±ºç­ï¼éè¦è¤éçéç®æè½æ´æ°ï¼èä¸ä¸æèæ®è¼å¼± FM çæ½å¨æ¼åãå¨æ¬æä¸­ï¼æåæåºå¯¦æé©ææ§è·¯ç± (RAR)ï¼ä¸ç¨®æ¹æ³å¯ä»¥æçºèª¿æ´ FM è·¯ç±æ±ºç­ï¼åæä½¿ç¨å¼å°å¼æå¢å­¸ç¿ä¾å¢å¼·è¼å¼± FM çåè½ãç®æ¨æ¯æ¸å°å°æ´å¼·å¤§ãæ´æè²´ç FM çä¾è³´ãæåå¨æµè¡ç MMLU åºæºçä¸åå­éä¸è©ä¼°æåçåæ³ãé¨èæéæ¨ç§»ï¼æåçåæ³å°è«æ±è·¯ç±å°è¨ç®ææ¬æè²´çæ¨¡åçæ¸éæ¸å°äº 50.2%ï¼åæç¶­æç´ 90.5% çä¸è¬åæåè³ªãæ­¤å¤ï¼å¾è¼å¼·å¤§çæ¨¡åç¢ççæåå·²é¡¯ç¤ºåºé åå§æ¦åï¼ä¸¦ä¸èå·æç¨ç«è¼å¼± FM çç­æåæ³ç¸æ¯ï¼ç¢çäºè¼å¥½çåæåè³ªã

##### **A Benchmark for Long-Form Medical Question Answering**
2411.09834v1 by Pedram Hosseini, Jessica M. Sin, Bing Ren, Bryceton G. Thomas, Elnaz Nouri, Ali Farahanchi, Saeed Hassanpour

There is a lack of benchmarks for evaluating large language models (LLMs) in
long-form medical question answering (QA). Most existing medical QA evaluation
benchmarks focus on automatic metrics and multiple-choice questions. While
valuable, these benchmarks fail to fully capture or assess the complexities of
real-world clinical applications where LLMs are being deployed. Furthermore,
existing studies on evaluating long-form answer generation in medical QA are
primarily closed-source, lacking access to human medical expert annotations,
which makes it difficult to reproduce results and enhance existing baselines.
In this work, we introduce a new publicly available benchmark featuring
real-world consumer medical questions with long-form answer evaluations
annotated by medical doctors. We performed pairwise comparisons of responses
from various open and closed-source medical and general-purpose LLMs based on
criteria such as correctness, helpfulness, harmfulness, and bias. Additionally,
we performed a comprehensive LLM-as-a-judge analysis to study the alignment
between human judgments and LLMs. Our preliminary results highlight the strong
potential of open LLMs in medical QA compared to leading closed models. Code &
Data: https://github.com/lavita-ai/medical-eval-sphere

æè¦ï¼ç¼ºä¹è©ä¼°å¤§åèªè¨æ¨¡å (LLM) å¨é·ç¯é«çåé¡è§£ç­ (QA) ä¸­è¡¨ç¾çåºæºãç¾æçé«ç QA è©ä¼°åºæºå¤§å¤èéæ¼èªååææ¨åå¤é¸é¡ãåç®¡æå¹å¼ï¼ä½éäºåºæºä¸¦æªå®å¨ææ¡æè©ä¼° LLM é¨ç½²æ¼å¶ä¸­ççå¯¦ä¸çè¨åºæç¨ä¹è¤éæ§ãæ­¤å¤ï¼ç¾æè©ä¼°é«ç QA ä¸­é·ç¯ç­æ¡ç¢ççç ç©¶ä¸»è¦çºéæºï¼ç¡æ³åå¾äººé¡é«çå°å®¶è¨»è§£ï¼éä½¿å¾é£ä»¥éç¾çµæä¸¦å¼·åç¾æåºæºãå¨éé å·¥ä½ä¸­ï¼æåå¼é²ä¸åæ°çå¬éåºæºï¼å¶ç¹é»æ¯çå¯¦ä¸ççæ¶è²»èé«çåé¡ï¼ä¸¦éæç±é«çé«çè¨»è§£çé·ç¯ç­æ¡è©ä¼°ãæåæ ¹ææ­£ç¢ºæ§ãæçæ§ãæå®³æ§ååè¦ç­æºåï¼å°ä¾èªåç¨®éæ¾åéæºé«çåéç¨ LLM çåæé²è¡æå°æ¯è¼ãæ­¤å¤ï¼æåå·è¡äºä¸é å¨é¢ç LLM ä½çºè©å¤çåæï¼ä»¥ç ç©¶äººé¡å¤æ·å LLM ä¹éçä¸è´æ§ãæåçåæ­¥çµæçªåºäºéæ¾ LLM å¨é«ç QA ä¸­çå¼·å¤§æ½åï¼åªæ¼é åçéæºæ¨¡åãç¨å¼ç¢¼åè³æï¼https://github.com/lavita-ai/medical-eval-sphere

##### **Evaluating Gender Bias in Large Language Models**
2411.09826v1 by Michael DÃ¶ll, Markus DÃ¶hring, Andreas MÃ¼ller

Gender bias in artificial intelligence has become an important issue,
particularly in the context of language models used in communication-oriented
applications. This study examines the extent to which Large Language Models
(LLMs) exhibit gender bias in pronoun selection in occupational contexts. The
analysis evaluates the models GPT-4, GPT-4o, PaLM 2 Text Bison and Gemini 1.0
Pro using a self-generated dataset. The jobs considered include a range of
occupations, from those with a significant male presence to those with a
notable female concentration, as well as jobs with a relatively equal gender
distribution. Three different sentence processing methods were used to assess
potential gender bias: masked tokens, unmasked sentences, and sentence
completion. In addition, the LLMs suggested names of individuals in specific
occupations, which were then examined for gender distribution. The results show
a positive correlation between the models' pronoun choices and the gender
distribution present in U.S. labor force data. Female pronouns were more often
associated with female-dominated occupations, while male pronouns were more
often associated with male-dominated occupations. Sentence completion showed
the strongest correlation with actual gender distribution, while name
generation resulted in a more balanced 'politically correct' gender
distribution, albeit with notable variations in predominantly male or female
occupations. Overall, the prompting method had a greater impact on gender
distribution than the model selection itself, highlighting the complexity of
addressing gender bias in LLMs. The findings highlight the importance of
prompting in gender mapping.

æè¦ï¼<paragraph>äººå·¥æºè½ä¸­çæ§å¥åè¦å·²æçºä¸åéè¦è­°é¡ï¼
ç¹å¥æ¯å¨ç¨æ¼ä»¥æºéçºå°åçæç¨ç¨å¼çèªè¨æ¨¡åçèæ¯ä¸ãæ¬ç ç©¶æ¢è¨äºå¤§åèªè¨æ¨¡å (LLM) å¨è·æ¥­èæ¯ä¸­ä»£åè©é¸æä¸­è¡¨ç¾åºçæ§å¥åè¦ç¨åº¦ã
åæè©ä¼°äºæ¨¡å GPT-4ãGPT-4oãPaLM 2 Text Bison å Gemini 1.0 Proï¼ä½¿ç¨èªç¢çè³æéãæèæ®çå·¥ä½åæ¬ä¸ç³»åè·æ¥­ï¼å¾ç·æ§å¤§éå­å¨çå·¥ä½å°å¥³æ§é¡¯èéä¸­çå·¥ä½ï¼ä»¥åæ§å¥åéç¸å°å¹³ç­çå·¥ä½ãä½¿ç¨äºä¸ç¨®ä¸åçå¥å­èçæ¹æ³ä¾è©ä¼°æ½å¨çæ§å¥åè¦ï¼é®è½ç¬¦èãæªé®è½å¥å­åå¥å­å®æãæ­¤å¤ï¼LLM å»ºè­°äºç¹å®è·æ¥­çåäººå§åï¼ç¶å¾æª¢æ¥éäºå§åçæ§å¥åä½ãçµæé¡¯ç¤ºï¼æ¨¡åçä»£åè©é¸æèç¾ååååæ¸æä¸­å­å¨çæ§å¥åä½ä¹éå­å¨æ­£ç¸éãå¥³æ§ä»£åè©éå¸¸èå¥³æ§ä¸»å°çè·æ¥­ç¸éï¼èç·æ§ä»£åè©éå¸¸èç·æ§ä¸»å°çè·æ¥­ç¸éãå¥å­å®æé¡¯ç¤ºèå¯¦éæ§å¥åä½ç¸éæ§æå¼·ï¼èåç¨±ç¢çåç¢çäºæ´å¹³è¡¡çãæ¿æ²»æ­£ç¢ºãæ§å¥åä½ï¼åç®¡å¨ç·æ§æå¥³æ§ä¸»å°çè·æ¥­ä¸­å­å¨é¡¯èå·®ç°ãæ´é«èè¨ï¼æç¤ºæ¹æ³å°æ§å¥åä½çå½±é¿å¤§æ¼æ¨¡åé¸ææ¬èº«ï¼çªé¡¯äºè§£æ±º LLM ä¸­æ§å¥åè¦çè¤éæ§ãç ç©¶çµæå¼·èª¿äºæç¤ºå¨æ§å¥å°æä¸­çéè¦æ§ã</paragraph>

##### **A Self-Supervised Model for Multi-modal Stroke Risk Prediction**
2411.09822v1 by Camille Delgrange, Olga Demler, Samia Mora, Bjoern Menze, Ezequiel de la Rosa, Neda Davoudi

Predicting stroke risk is a complex challenge that can be enhanced by
integrating diverse clinically available data modalities. This study introduces
a self-supervised multimodal framework that combines 3D brain imaging, clinical
data, and image-derived features to improve stroke risk prediction prior to
onset. By leveraging large unannotated clinical datasets, the framework
captures complementary and synergistic information across image and tabular
data modalities. Our approach is based on a contrastive learning framework that
couples contrastive language-image pretraining with an image-tabular matching
module, to better align multimodal data representations in a shared latent
space. The model is trained on the UK Biobank, which includes structural brain
MRI and clinical data. We benchmark its performance against state-of-the-art
unimodal and multimodal methods using tabular, image, and image-tabular
combinations under diverse frozen and trainable model settings. The proposed
model outperformed self-supervised tabular (image) methods by 2.6% (2.6%) in
ROC-AUC and by 3.3% (5.6%) in balanced accuracy. Additionally, it showed a 7.6%
increase in balanced accuracy compared to the best multimodal supervised model.
Through interpretable tools, our approach demonstrated better integration of
tabular and image data, providing richer and more aligned embeddings.
Gradient-weighted Class Activation Mapping heatmaps further revealed activated
brain regions commonly associated in the literature with brain aging, stroke
risk, and clinical outcomes. This robust self-supervised multimodal framework
surpasses state-of-the-art methods for stroke risk prediction and offers a
strong foundation for future studies integrating diverse data modalities to
advance clinical predictive modelling.

æè¦ï¼<paragraph>é æ¸¬ä¸­é¢¨é¢¨éªæ¯ä¸é è¤éçææ°ï¼å¯ä»¥ééæ´åå¤æ¨£åçè¨åºå¯ç¨æ¸ææ¨¡å¼ä¾å å¼·ãæ¬ç ç©¶ä»ç´¹äºä¸åèªç£ç£å¤æ¨¡å¼æ¶æ§ï¼çµå 3D å¤§è¦å½±åãè¨åºæ¸æåå½±åè¡çç¹å¾µï¼ä»¥å¨ç¼ä½åæ¹åä¸­é¢¨é¢¨éªé æ¸¬ãééå©ç¨å¤§éçæªæ¨è¨è¨åºæ¸æéï¼è©²æ¶æ§æ·åäºå½±ååè¡¨æ ¼æ¸ææ¨¡å¼ä¹éçäºè£åååè³è¨ãæåçåæ³åºæ¼å°æ¯å­¸ç¿æ¶æ§ï¼å°å°æ¯èªè¨å½±åé è¨ç·´èå½±åè¡¨æ ¼å¹éæ¨¡çµçµåï¼ä»¥å¨å±äº«æ½å¨ç©ºéä¸­æ´å¥½å°å°é½å¤æ¨¡å¼æ¸æè¡¨ç¤ºãè©²æ¨¡åæ¯å¨è±åçç©éè¡ä¸­è¨ç·´çï¼å¶ä¸­åæ¬çµæ§æ§è¦é¨ MRI åè¨åºæ¸æãæåä½¿ç¨è¡¨æ ¼ãå½±ååå½±åè¡¨æ ¼çµåï¼å¨ä¸åçåçµåå¯è¨ç·´æ¨¡åè¨­å®ä¸ï¼æ ¹ææåé²çå®æ¨¡å¼åå¤æ¨¡å¼æ¹æ³å°å¶æè½é²è¡åºæºæ¸¬è©¦ãææåºçæ¨¡åå¨ ROC-AUC ä¸­æ¯èªç£ç£è¡¨æ ¼ï¼å½±åï¼æ¹æ³é«åº 2.6%ï¼2.6%ï¼ï¼å¨å¹³è¡¡æºç¢ºåº¦ä¸­é«åº 3.3%ï¼5.6%ï¼ãæ­¤å¤ï¼èæä½³å¤æ¨¡å¼ç£ç£æ¨¡åç¸æ¯ï¼å®çå¹³è¡¡æºç¢ºåº¦æé«äº 7.6%ãééå¯è§£éçå·¥å·ï¼æåçåæ³è­æäºè¡¨æ ¼åå½±åæ¸æçæ´åæ§æ´å¥½ï¼æä¾äºæ´è±å¯ä¸æ´ä¸è´çåµå¥ãæ¢¯åº¦å æ¬é¡å¥åç¨å°æç±åé²ä¸æ­¥æ­ç¤ºäºæç»ä¸­éå¸¸èè¦é¨èåãä¸­é¢¨é¢¨éªåè¨åºçµæç¸éçæ´»åè¦åãéåå¼·å¥çèªç£ç£å¤æ¨¡å¼æ¶æ§è¶è¶äºä¸­é¢¨é¢¨éªé æ¸¬çææ°æ¹æ³ï¼ä¸¦çºæ´åä¸åæ¸ææ¨¡å¼ä»¥æ¨é²è¨åºé æ¸¬å»ºæ¨¡çæªä¾ç ç©¶æä¾äºå å¯¦çåºç¤ã</paragraph>

##### **WelQrate: Defining the Gold Standard in Small Molecule Drug Discovery Benchmarking**
2411.09820v1 by Yunchao, Liu, Ha Dong, Xin Wang, Rocco Moretti, Yu Wang, Zhaoqian Su, Jiawei Gu, Bobby Bodenheimer, Charles David Weaver, Jens Meiler, Tyler Derr

While deep learning has revolutionized computer-aided drug discovery, the AI
community has predominantly focused on model innovation and placed less
emphasis on establishing best benchmarking practices. We posit that without a
sound model evaluation framework, the AI community's efforts cannot reach their
full potential, thereby slowing the progress and transfer of innovation into
real-world drug discovery. Thus, in this paper, we seek to establish a new gold
standard for small molecule drug discovery benchmarking, WelQrate.
Specifically, our contributions are threefold: WelQrate Dataset Collection - we
introduce a meticulously curated collection of 9 datasets spanning 5
therapeutic target classes. Our hierarchical curation pipelines, designed by
drug discovery experts, go beyond the primary high-throughput screen by
leveraging additional confirmatory and counter screens along with rigorous
domain-driven preprocessing, such as Pan-Assay Interference Compounds (PAINS)
filtering, to ensure the high-quality data in the datasets; WelQrate Evaluation
Framework - we propose a standardized model evaluation framework considering
high-quality datasets, featurization, 3D conformation generation, evaluation
metrics, and data splits, which provides a reliable benchmarking for drug
discovery experts conducting real-world virtual screening; Benchmarking - we
evaluate model performance through various research questions using the
WelQrate dataset collection, exploring the effects of different models, dataset
quality, featurization methods, and data splitting strategies on the results.
In summary, we recommend adopting our proposed WelQrate as the gold standard in
small molecule drug discovery benchmarking. The WelQrate dataset collection,
along with the curation codes, and experimental scripts are all publicly
available at WelQrate.org.

æè¦ï¼<paragraph>æ·±åº¦å­¸ç¿éç¶å¾¹åºæ¹è®äºé»è¦è¼å©è¥ç©ç¼ç¾ï¼ä½ AI ç¤¾ç¾¤ä¸»è¦å°æ³¨æ¼æ¨¡ååµæ°ï¼è¼å°éè¦å»ºç«æä½³åºæºæ¸¬è©¦å¯¦åãæååè¨­ï¼è¥æ²æå¥å¨çæ¨¡åè©ä¼°æ¶æ§ï¼AI ç¤¾ç¾¤çåªåå°ç¡æ³ç¼æ®å¶å¨é¨æ½åï¼é²èæ¸ç·©åµæ°é²ç¨ï¼ä¸¦å°åµæ°è½ç§»å°ç¾å¯¦ä¸ççè¥ç©ç¼ç¾ä¸­ãå æ­¤ï¼æåå¨æ¬æä¸­å°æ±çºå°åå­è¥ç©ç¼ç¾åºæºæ¸¬è©¦å»ºç«æ°çéæ¨æº WelQrateãå·é«ä¾èªªï¼æåçè²¢ç»æä¸æ¹é¢ï¼WelQrate è³æéæ¶é - æåå¼é²ä¸åç²¾å¿ç­åç 9 åè³æééåï¼æ¶µè 5 åæ²»çç®æ¨é¡å¥ãæåçéå±¤å¼ç­åç®¡éç±è¥ç©ç¼ç¾å°å®¶è¨­è¨ï¼ééå©ç¨å¶ä»ç¢ºèªåååç¯©é¸ä»¥åå´æ ¼çé åé©åé èçï¼ä¾å¦ Pan-Assay Interference Compounds (PAINS) éæ¿¾ï¼è¶è¶ä¸»è¦çé«ééç¯©é¸ï¼ä»¥ç¢ºä¿è³æéä¸­çè³æåè³ªï¼WelQrate è©ä¼°æ¶æ§ - æåæåºä¸åæ¨æºåçæ¨¡åè©ä¼°æ¶æ§ï¼èéé«åè³ªè³æéãç¹å¾µåã3D æ§è±¡ç¢çãè©ä¼°ææ¨åè³æåå²ï¼éçºé²è¡çå¯¦ä¸çèæ¬ç¯©é¸çè¥ç©ç¼ç¾å°å®¶æä¾å¯é çåºæºæ¸¬è©¦ï¼åºæºæ¸¬è©¦ - æåééä½¿ç¨ WelQrate è³æéæ¶éä¾è©ä¼°æ¨¡åæè½ï¼æ¢è¨ä¸åæ¨¡åãè³æéåè³ªãç¹å¾µåæ¹æ³åè³æåå²ç­ç¥å°çµæçå½±é¿ãç¸½ä¹ï¼æåå»ºè­°æ¡ç¨æåæåºç WelQrate ä½çºå°åå­è¥ç©ç¼ç¾åºæºæ¸¬è©¦çéæ¨æºãWelQrate è³æéæ¶éï¼é£åç­åç¨å¼ç¢¼åå¯¦é©è³æ¬ï¼é½å¬éæ¼ WelQrate.orgã</paragraph>

##### **Evaluating Loss Landscapes from a Topology Perspective**
2411.09807v1 by Tiankai Xie, Caleb Geniesse, Jiaqing Chen, Yaoqing Yang, Dmitriy Morozov, Michael W. Mahoney, Ross Maciejewski, Gunther H. Weber

Characterizing the loss of a neural network with respect to model parameters,
i.e., the loss landscape, can provide valuable insights into properties of that
model. Various methods for visualizing loss landscapes have been proposed, but
less emphasis has been placed on quantifying and extracting actionable and
reproducible insights from these complex representations. Inspired by powerful
tools from topological data analysis (TDA) for summarizing the structure of
high-dimensional data, here we characterize the underlying shape (or topology)
of loss landscapes, quantifying the topology to reveal new insights about
neural networks. To relate our findings to the machine learning (ML)
literature, we compute simple performance metrics (e.g., accuracy, error), and
we characterize the local structure of loss landscapes using Hessian-based
metrics (e.g., largest eigenvalue, trace, eigenvalue spectral density).
Following this approach, we study established models from image pattern
recognition (e.g., ResNets) and scientific ML (e.g., physics-informed neural
networks), and we show how quantifying the shape of loss landscapes can provide
new insights into model performance and learning dynamics.

æè¦ï¼éè¿æ¨¡ååæ°æ¥è¡¨å¾ç¥ç»ç½ç»çæå¤±ï¼å³æå¤±æ¯è§ï¼å¯ä»¥ä¸ºè¯¥æ¨¡åçå±æ§æä¾æä»·å¼çè§è§£ãå·²ç»æåºäºå¯è§åæå¤±æ¯è§çåç§æ¹æ³ï¼ä½è¾å°å¼ºè°ä»è¿äºå¤æè¡¨ç¤ºä¸­éååæåå¯æä½ä¸å¯éå¤çè§è§£ãåæææ°æ®åæ (TDA) ä¸­ç¨äºæ»ç»é«ç»´æ°æ®ç»æçå¼ºå¤§å·¥å·çå¯åï¼æä»¬å¨æ­¤è¡¨å¾æå¤±æ¯è§çåºå±å½¢ç¶ï¼æææï¼ï¼éåææä»¥æ­ç¤ºæå³ç¥ç»ç½ç»çæ°è§è§£ãä¸ºäºå°æä»¬çåç°ä¸æºå¨å­¦ä¹  (ML) æç®èç³»èµ·æ¥ï¼æä»¬è®¡ç®ç®åçæ§è½ææ ï¼ä¾å¦ï¼åç¡®åº¦ãéè¯¯ï¼ï¼å¹¶ä½¿ç¨åºäº Hessian çææ ï¼ä¾å¦ï¼æå¤§ç¹å¾å¼ãè¿¹ãç¹å¾å¼è°±å¯åº¦ï¼æ¥è¡¨å¾æå¤±æ¯è§çå±é¨ç»æãéµå¾ªè¿ç§æ¹æ³ï¼æä»¬ç ç©¶äºå¾åæ¨¡å¼è¯å«ï¼ä¾å¦ï¼ResNetsï¼åç§å­¦ MLï¼ä¾å¦ï¼ç©çä¿¡æ¯ç¥ç»ç½ç»ï¼ä¸­çå·²å»ºç«æ¨¡åï¼å¹¶å±ç¤ºäºéåæå¤±æ¯è§çå½¢ç¶å¦ä½å¯ä»¥ä¸ºæ¨¡åæ§è½åå­¦ä¹ å¨ææä¾æ°çè§è§£ã

##### **Deep Learning for Fetal Inflammatory Response Diagnosis in the Umbilical Cord**
2411.09767v1 by Marina A. Ayad, Ramin Nateghi, Abhishek Sharma, Lawrence Chillrud, Tilly Seesillapachai, Lee A. D. Cooper, Jeffery A. Goldstein

Inflammation of the umbilical cord can be seen as a result of ascending
intrauterine infection or other inflammatory stimuli. Acute fetal inflammatory
response (FIR) is characterized by infiltration of the umbilical cord by fetal
neutrophils, and can be associated with neonatal sepsis or fetal inflammatory
response syndrome. Recent advances in deep learning in digital pathology have
demonstrated favorable performance across a wide range of clinical tasks, such
as diagnosis and prognosis. In this study we classified FIR from whole slide
images (WSI). We digitized 4100 histological slides of umbilical cord stained
with hematoxylin and eosin(H&E) and extracted placental diagnoses from the
electronic health record. We build models using attention-based whole slide
learning models. We compared strategies between features extracted by a model
(ConvNeXtXLarge) pretrained on non-medical images (ImageNet), and one
pretrained using histopathology images (UNI). We trained multiple iterations of
each model and combined them into an ensemble. The predictions from the
ensemble of models trained using UNI achieved an overall balanced accuracy of
0.836 on the test dataset. In comparison, the ensembled predictions using
ConvNeXtXLarge had a lower balanced accuracy of 0.7209. Heatmaps generated from
top accuracy model appropriately highlighted arteritis in cases of FIR 2. In
FIR 1, the highest performing model assigned high attention to areas of
activated-appearing stroma in Wharton's Jelly. However, other high-performing
models assigned attention to umbilical vessels. We developed models for
diagnosis of FIR from placental histology images, helping reduce interobserver
variability among pathologists. Future work may examine the utility of these
models for identifying infants at risk of systemic inflammatory response or
early onset neonatal sepsis.

æè¦ï¼èå¸¶ç¼çå¯è¦çºä¸è¡æ§å­å®®å§æææå¶ä»ç¼çåºæ¿æè´ãæ¥æ§èåç¼çåæ (FIR) çç¹å¾µæ¯èåä¸­æ§çæµ¸æ½¤èå¸¶ï¼å¯è½èæ°çåæè¡çæèåç¼çåæçåç¾¤æéãæ¸ä½ççå­¸ä¸­æ·±åº¦å­¸ç¿çææ°é²å±å·²è­æå¨å»£æ³çè¨åºä»»åä¸­è¡¨ç¾è¯å¥½ï¼ä¾å¦è¨ºæ·åé å¾ãå¨éé ç ç©¶ä¸­ï¼æåå¾å¨åçå½±å (WSI) ä¸­åé¡ FIRãæåå° 4100 å¼µç¨èæ¨ç²¾åæç´ (H&E) æè²çèå¸¶çµç¹åçæ¸ä½åï¼ä¸¦å¾é»å­çæ­·ä¸­æåèç¤è¨ºæ·ãæåä½¿ç¨åºæ¼æ³¨æåçå¨åçå­¸ç¿æ¨¡åå»ºç«æ¨¡åãæåæ¯è¼äºéé«çå½±å (ImageNet) é è¨ç·´æ¨¡å (ConvNeXtXLarge) åä½¿ç¨çµç¹ççå­¸å½±å (UNI) é è¨ç·´æ¨¡åæåçç¹å¾µä¹éçç­ç¥ãæåè¨ç·´äºæ¯åæ¨¡åçå¤æ¬¡è¿­ä»£ï¼ä¸¦å°å®åçµåæä¸åæ´é«ãä½¿ç¨ UNI è¨ç·´çæ¨¡åæ´é«çé æ¸¬å¨æ¸¬è©¦è³æéä¸éå° 0.836 çæ´é«å¹³è¡¡æºç¢ºåº¦ãç¸æ¯ä¹ä¸ï¼ä½¿ç¨ ConvNeXtXLarge çæ´é«é æ¸¬çå¹³è¡¡æºç¢ºåº¦è¼ä½ï¼çº 0.7209ãå¾æºç¢ºåº¦æé«çæ¨¡åç¢ççç±åé©ç¶å°çªåºäº FIR 2 çä¾ä¸­çåèçãå¨ FIR 1 ä¸­ï¼è¡¨ç¾æå¥½çæ¨¡åå°é«åº¦éæ³¨åéçµ¦æ²é æ°è ä¸­çæ´»åå¤è§åºè³ªååãç¶èï¼å¶ä»è¡¨ç¾è¯å¥½çæ¨¡åå°æ³¨æååéçµ¦èå¸¶è¡ç®¡ãæåéç¼äºå¾èç¤çµç¹å­¸å½±åè¨ºæ· FIR çæ¨¡åï¼æå©æ¼æ¸å°ççå­¸å®¶ä¹éçè§å¯èéè®ç°æ§ãæªä¾çç ç©¶å¯è½ææ¢è¨éäºæ¨¡åå¨è­å¥æå¨èº«æ§ç¼çåæé¢¨éªææ©æç¼ä½æ°çåæè¡ççå¬°åæ¹é¢çæç¨ã

##### **Evaluating the Predictive Capacity of ChatGPT for Academic Peer Review Outcomes Across Multiple Platforms**
2411.09763v1 by Mike Thelwall, Abdullah Yaghi

While previous studies have demonstrated that Large Language Models (LLMs)
can predict peer review outcomes to some extent, this paper builds on that by
introducing two new contexts and employing a more robust method - averaging
multiple ChatGPT scores. The findings that averaging 30 ChatGPT predictions,
based on reviewer guidelines and using only the submitted titles and abstracts,
failed to predict peer review outcomes for F1000Research (Spearman's rho=0.00).
However, it produced mostly weak positive correlations with the quality
dimensions of SciPost Physics (rho=0.25 for validity, rho=0.25 for originality,
rho=0.20 for significance, and rho = 0.08 for clarity) and a moderate positive
correlation for papers from the International Conference on Learning
Representations (ICLR) (rho=0.38). Including the full text of articles
significantly increased the correlation for ICLR (rho=0.46) and slightly
improved it for F1000Research (rho=0.09), while it had variable effects on the
four quality dimension correlations for SciPost LaTeX files. The use of
chain-of-thought system prompts slightly increased the correlation for
F1000Research (rho=0.10), marginally reduced it for ICLR (rho=0.37), and
further decreased it for SciPost Physics (rho=0.16 for validity, rho=0.18 for
originality, rho=0.18 for significance, and rho=0.05 for clarity). Overall, the
results suggest that in some contexts, ChatGPT can produce weak pre-publication
quality assessments. However, the effectiveness of these assessments and the
optimal strategies for employing them vary considerably across different
platforms, journals, and conferences. Additionally, the most suitable inputs
for ChatGPT appear to differ depending on the platform.

æè¦ï¼<paragraph>åç®¡ååçç ç©¶å·²è­å¯¦å¤§åèªè¨æ¨¡å (LLM)
å¨æç¨®ç¨åº¦ä¸å¯ä»¥é æ¸¬åè¡è©å¯©çµæï¼ä½æ¬æå»ºç«å¨è©²åºç¤ä¸ï¼
å¼å¥äºå©åæ°çèçµ¡ï¼ä¸¦æ¡ç¨æ´å¼·å¥çæ¹æ³ - å¹³å
å¤å ChatGPT åæ¸ãç ç©¶çµæé¡¯ç¤ºï¼å¹³å 30 å ChatGPT é æ¸¬ï¼
æ ¹æå¯©æ¥å¡æåï¼åä½¿ç¨æäº¤çæ¨é¡åæè¦ï¼
ç¡æ³é æ¸¬ F1000Research çåè¡è©å¯©çµæï¼Spearman's rho=0.00ï¼ã
ç¶èï¼å®ç¢çäºè SciPost Physics çåè³ªååº¦åå¼±æ­£ç¸éï¼rho=0.25 è¡¨ç¤ºæææ§ï¼rho=0.25 è¡¨ç¤ºç¨åµæ§ï¼
rho=0.20 è¡¨ç¤ºéè¦æ§ï¼rho = 0.08 è¡¨ç¤ºæ¸æ°åº¦ï¼ä»¥åèåéå­¸ç¿è¡¨å¾µæè­°ï¼ICLRï¼è«æçä¸­ç­æ­£ç¸é
ï¼rho=0.38ï¼ãåå«æç« çå¨æé¡¯èå¢å äº ICLR çç¸éæ§ï¼rho=0.46ï¼ï¼ä¸¦ç¥å¾®
æ¹åäº F1000Researchï¼rho=0.09ï¼ï¼èå®å° SciPost LaTeX æªæ¡çåååè³ªååº¦ç¸éæ§æä¸åçå½±é¿ãä½¿ç¨
æèéç³»çµ±æç¤ºç¥å¾®å¢å äº F1000Research çç¸éæ§ï¼rho=0.10ï¼ï¼ç¥å¾®éä½äº ICLR çç¸éæ§ï¼rho=0.37ï¼ï¼ä¸¦
é²ä¸æ­¥éä½äº SciPost Physics çç¸éæ§ï¼rho=0.16 è¡¨ç¤ºæææ§ï¼rho=0.18 è¡¨ç¤ºç¨åµæ§ï¼rho=0.18 è¡¨ç¤ºéè¦æ§ï¼rho=0.05 è¡¨ç¤ºæ¸æ°åº¦ï¼ãç¸½çä¾èªªï¼
çµæè¡¨æï¼å¨æäºææ³ä¸ï¼ChatGPT å¯ä»¥ç¢çå¼±çåºçååè³ªè©ä¼°ãç¶èï¼éäºè©ä¼°çæææ§ä»¥åæ¡ç¨å®åçæä½³ç­ç¥å¨ä¸åç
å¹³å°ãæååæè­°ä¹éæå¾å¤§å·®ç°ãæ­¤å¤ï¼ChatGPT æåé©çè¼¸å¥ä¼¼ä¹ææ ¹æå¹³å°èææä¸åã</paragraph>

##### **On the Surprising Effectiveness of Attention Transfer for Vision Transformers**
2411.09702v1 by Alexander C. Li, Yuandong Tian, Beidi Chen, Deepak Pathak, Xinlei Chen

Conventional wisdom suggests that pre-training Vision Transformers (ViT)
improves downstream performance by learning useful representations. Is this
actually true? We investigate this question and find that the features and
representations learned during pre-training are not essential. Surprisingly,
using only the attention patterns from pre-training (i.e., guiding how
information flows between tokens) is sufficient for models to learn high
quality features from scratch and achieve comparable downstream performance. We
show this by introducing a simple method called attention transfer, where only
the attention patterns from a pre-trained teacher ViT are transferred to a
student, either by copying or distilling the attention maps. Since attention
transfer lets the student learn its own features, ensembling it with a
fine-tuned teacher also further improves accuracy on ImageNet. We
systematically study various aspects of our findings on the sufficiency of
attention maps, including distribution shift settings where they underperform
fine-tuning. We hope our exploration provides a better understanding of what
pre-training accomplishes and leads to a useful alternative to the standard
practice of fine-tuning

æè¦ï¼å³çµ±è§å¿µèªçºé è¨ç·´è¦è¦ºTransformerï¼ViTï¼
ééå­¸ç¿æç¨çè¡¨å¾µä¾æåä¸æ¸¸æè½ãé
æ¯å¦å±¬å¯¦ï¼æåæ¢è¨éååé¡ï¼ç¼ç¾é è¨ç·´æéå­¸ç¿å°çç¹å¾µå
è¡¨å¾µä¸¦éå¿è¦çãä»¤äººé©è¨çæ¯ï¼åä½¿ç¨é è¨ç·´çæ³¨æåæ¨¡å¼ï¼ä¹
å°±æ¯å¼å°è³è¨å¦ä½å¨ç¬¦èä¹éæµåï¼å°±è¶³ä»¥è®æ¨¡åå¾é ­å­¸ç¿é«
åè³ªçç¹å¾µï¼ä¸¦éæç¸è¿çä¸æ¸¸æè½ãæåééå¼å¥ä¸ç¨®ç¨±çºæ³¨
æåè½ç§»çç°¡å®æ¹æ³ä¾è­æéä¸é»ï¼å¶ä¸­åå°é è¨ç·´æå¸« ViT ç
æ³¨æåæ¨¡å¼è½ç§»çµ¦å­¸çï¼æ¹æ³æ¯è¤è£½æèåæ³¨æååãç±æ¼æ³¨
æåè½ç§»è®å­¸çå­¸ç¿èªå·±çç¹å¾µï¼å æ­¤å°å¶èå¾®èª¿æå¸«çµåä¹
é²ä¸æ­¥æåäº ImageNet çæºç¢ºåº¦ãæåç³»çµ±æ§å°ç ç©¶äºæåå¨
æ³¨æååçååæ§æ¹é¢çç¼ç¾çååé¢åï¼åæ¬å®åè¡¨ç¾ä¸å¦å¾®
èª¿çåéè½ç§»è¨­å®ãæåå¸ææåçæ¢ç´¢è½æä¾å°é è¨ç·´éæ
ä»éº¼ç®æ¨çæ´æ·±å¥çè§£ï¼ä¸¦æä¾ä¸ç¨®æç¨çæ¿ä»£æ¹æ¡ä¾åä»£å¾®èª¿
çæ¨æºåæ³

##### **A Bayesian Optimization Approach to Machine Translation Reranking**
2411.09694v1 by Julius Cheng, Maike ZÃ¼fle, VilÃ©m Zouhar, Andreas Vlachos

Reranking a list of candidates from a machine translation system with an
external scoring model and returning the highest-scoring candidate remains a
simple and effective method for improving the overall output quality.
Translation scoring models continue to grow in size, with the best models being
comparable to generation models. Thus, reranking can add substantial
computational cost to the translation pipeline. In this work, we pose reranking
as a Bayesian optimization (BayesOpt) problem. By strategically selecting
candidates to score based on a balance of exploration and exploitation, we show
that it is possible to find top-scoring candidates when scoring only a fraction
of the candidate list. For instance, our method achieves the same CometKiwi
score using only 70 scoring evaluations compared a baseline system using 180.
We present a multi-fidelity setting for BayesOpt, where the candidates are
first scored with a cheaper but noisier proxy scoring model, which further
improves the cost-performance tradeoff when using smaller but well-trained
distilled proxy scorers.

æè¦ï¼å©ç¨å¤é¨è©åæ¨¡åéæ°æåæ©å¨ç¿»è­¯ç³»çµ±çåé¸æ¸å®ï¼ä¸¦åå³è©åæé«çåé¸ï¼éä»ç¶æ¯æ¹åæ´é«è¼¸åºåè³ªçç°¡å®ä¸ææçæ¹æ³ã
ç¿»è­¯è©åæ¨¡åæçºæ´å¢ï¼å¶ä¸­æä½³çæ¨¡åèçææ¨¡åç¸ç¶ãå æ­¤ï¼éæ°æåæçºç¿»è­¯æµç¨å¢å å¤§éçéç®ææ¬ãå¨éé å·¥ä½ä¸­ï¼æåå°éæ°æåè¦çºè²æ°æä½³å (BayesOpt) åé¡ãééç­ç¥æ§å°é¸æåé¸ï¼å¨æ¢ç´¢èéç¼åå¾å¹³è¡¡çåºç¤ä¸é²è¡è©åï¼æåè­æäºå¨åè©ååé¸æ¸å®çä¸é¨åæï¼æå¯è½æ¾å°è©åæé«çåé¸ãä¾å¦ï¼æåçæ¨¡ååä½¿ç¨ 70 æ¬¡è©åè©ä¼°å°±éå°ç¸åç CometKiwi åæ¸ï¼èåºç·ç³»çµ±åä½¿ç¨ 180 æ¬¡ãæåæåºé©ç¨æ¼ BayesOpt çå¤éä¿çåº¦è¨­å®ï¼å¶ä¸­åé¸é¦åä½¿ç¨è¼ä¾¿å®ä½è¼å¤éè¨çä»£çè©åæ¨¡åé²è¡è©åï¼éé²ä¸æ­¥æ¹åäºä½¿ç¨è¼å°ä½è¨ç·´è¯å¥½çè¸é¤¾ä»£çè©åå¨çææ¬æçæ¬è¡¡ã

##### **LLM Hallucination Reasoning with Zero-shot Knowledge Test**
2411.09689v1 by Seongmin Lee, Hsiang Hsu, Chun-Fu Chen

LLM hallucination, where LLMs occasionally generate unfaithful text, poses
significant challenges for their practical applications. Most existing
detection methods rely on external knowledge, LLM fine-tuning, or
hallucination-labeled datasets, and they do not distinguish between different
types of hallucinations, which are crucial for improving detection performance.
We introduce a new task, Hallucination Reasoning, which classifies
LLM-generated text into one of three categories: aligned, misaligned, and
fabricated. Our novel zero-shot method assesses whether LLM has enough
knowledge about a given prompt and text. Our experiments conducted on new
datasets demonstrate the effectiveness of our method in hallucination reasoning
and underscore its importance for enhancing detection performance.

æè¦ï¼å¤§åè¯­è¨æ¨¡å (LLM) çå¹»è§ï¼ä¹å°±æ¯ LLM å¶å°ä¼çæä¸å¿ å®ææ¬çæåµï¼å¯¹å¶å®éåºç¨ææäºéå¤§ææãå¤§å¤æ°ç°æçæ£æµæ¹æ³ä¾èµäºå¤é¨ç¥è¯ãLLM å¾®è°æå¹»è§æ è®°æ°æ®éï¼èä¸å®ä»¬ä¸åºåä¸åç±»åçå¹»è§ï¼èè¿å¯¹äºæé«æ£æµæ§è½è³å³éè¦ãæä»¬å¼å¥äºä¸é¡¹æ°ä»»å¡ï¼å³å¹»è§æ¨çï¼å®å° LLM çæçææ¬å½ç±»ä¸ºä»¥ä¸ä¸ç±»ä¹ä¸ï¼å¯¹é½ãéä½åèæãæä»¬æ°é¢çé¶æ ·æ¬æ¹æ³è¯ä¼°äº LLM æ¯å¦å¯¹ç»å®çæç¤ºåææ¬æè¶³å¤çäºè§£ãæä»¬å¯¹æ°æ°æ®éè¿è¡çå®éªè¯æäºæä»¬çæ¹æ³å¨å¹»è§æ¨çä¸­çæææ§ï¼å¹¶å¼ºè°äºå¶å¯¹æé«æ£æµæ§è½çéè¦æ§ã

##### **Squeezed Attention: Accelerating Long Context Length LLM Inference**
2411.09688v1 by Coleman Hooper, Sehoon Kim, Hiva Mohammadzadeh, Monishwaran Maheswaran, June Paik, Michael W. Mahoney, Kurt Keutzer, Amir Gholami

Emerging Large Language Model (LLM) applications require long input prompts
to perform complex downstream tasks like document analysis and code generation.
For these long context length applications, the length of the input prompt
poses a significant challenge in terms of inference efficiency since the
inference costs increase linearly with sequence length. However, for many of
these applications, much of the context in the prompt is fixed across different
user inputs, thereby providing the opportunity to perform offline optimizations
to process user inputs quickly, as they are received. In this work, we propose
Squeezed Attention as a mechanism to accelerate LLM applications where a large
portion of the input prompt is fixed. We first leverage K-means clustering
offline to group the keys for the fixed context based on semantic similarity
and represent each cluster with a single centroid value. During inference, we
compare query tokens from the user input with the centroids to predict which of
the keys from the fixed context are semantically relevant and need to be loaded
during inference. We then compute exact attention using only these important
keys from the fixed context, thereby reducing bandwidth and computational
costs. We also extend our method to use a hierarchical centroid lookup to
identify important keys, which can reduce the complexity of attention from
linear to logarithmic with respect to the context length. We implement
optimized Triton kernels for centroid comparison and sparse FlashAttention with
important keys, achieving more than 4x speedups during both the prefill and
generation phases for long-context inference. Furthermore, we have extensively
evaluated our method on various long-context benchmarks including LongBench,
where it achieves a 3x reduction in KV cache budget without accuracy loss and
up to an 8x reduction with <0.5 point accuracy gap for various models.

æè¦ï¼æ°èçå¤§èªè¨æ¨¡å (LLM) æç¨ç¨å¼éè¦é·çè¼¸å¥æç¤ºï¼æè½å·è¡è¤éçä¸æ¸¸ä»»åï¼ä¾å¦æä»¶åæåç¨å¼ç¢¼ç¢çãå°æ¼éäºé·èçµ¡é·åº¦çæç¨ç¨å¼ä¾èªªï¼è¼¸å¥æç¤ºçé·åº¦å¨æ¨è«æçæ¹é¢æ§æéå¤§ææ°ï¼å çºæ¨è«ææ¬æé¨èåºåé·åº¦ç·æ§å¢å ãç¶èï¼å°æ¼éäºæç¨ç¨å¼ä¸­çè¨±å¤æç¨ç¨å¼ï¼æç¤ºä¸­çå¤§é¨åèçµ¡å¨ä¸åçä½¿ç¨èè¼¸å¥ä¸­é½æ¯åºå®çï¼å æ­¤æä¾äºå·è¡é¢ç·æä½³åä»¥å¿«éèçä½¿ç¨èè¼¸å¥çæ©æï¼å çºå®åå·²è¢«æ¥æ¶ãå¨éé å·¥ä½ä¸­ï¼æåå»ºè­°ä½¿ç¨ Squeezed Attention ä½çºä¸ç¨®æ©å¶ï¼ä»¥å é LLM æç¨ç¨å¼ï¼å¶ä¸­è¼¸å¥æç¤ºçå¤§é¨åæ¯åºå®çãæåé¦åå©ç¨ K å¹³åç¾¤éå¨é¢ç·æ¨¡å¼ä¸æ ¹æèªç¾©ç¸ä¼¼æ§å°åºå®èçµ¡çéµé²è¡åçµï¼ä¸¦ä½¿ç¨å®ä¸è³ªå¿å¼è¡¨ç¤ºæ¯åç¾¤éãå¨æ¨è«æéï¼æåå°ä½¿ç¨èè¼¸å¥ä¸­çæ¥è©¢ä»£å¹£èè³ªå¿é²è¡æ¯è¼ï¼ä»¥é æ¸¬åºå®èçµ¡ä¸­çåªäºéµå¨èªç¾©ä¸ç¸éï¼ä¸¦ä¸éè¦å¨æ¨è«æéè¼å¥ãç¶å¾ï¼æååä½¿ç¨åºå®èçµ¡ä¸­çéäºéè¦éµè¨ç®ç¢ºåçæ³¨æåï¼å¾èæ¸å°é »å¯¬åéç®ææ¬ãæåéå°æ¹æ³æ´åå¥ä»¶çºä½¿ç¨éå±¤è³ªå¿æ¥è©¢ä¾è­å¥éè¦éµï¼éå¯ä»¥å°æ³¨æåçè¤éåº¦å¾ç·æ§éä½å°å°æ¸ï¼ç¸å°æ¼èçµ¡é·åº¦èè¨ãæåå¯¦ä½æä½³åç Triton æ ¸å¿ï¼ç¨æ¼è³ªå¿æ¯è¼åå·æéè¦éµçç¨ç FlashAttentionï¼å¨é·èçµ¡æ¨è«çé å¡«åç¢çéæ®µå¯¦ç¾è¶é 4 åçå éãæ­¤å¤ï¼æåå·²éå°åç¨®é·èçµ¡åºæºå»£æ³è©ä¼°æåçæ¨¡åï¼åæ¬ LongBenchï¼å¶ä¸­å¨ä¸æå¤±æºç¢ºæ§çææ³ä¸å¯¦ç¾äº KV å¿«åé ç®æ¸å° 3 åï¼ä¸¦ä¸å°æ¼åç¨®æ¨¡åï¼æ¸å°äºå¤é 8 åï¼æºç¢ºåº¦å·®è·å°æ¼ 0.5 é»ã

