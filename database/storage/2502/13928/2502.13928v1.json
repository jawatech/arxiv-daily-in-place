{"2502.13928": {"publish_time": "2025-02-19", "title": "Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images", "paper_summary": "Recent studies have shown that Large Vision-Language Models (VLMs) tend to\nneglect image content and over-rely on language-model priors, resulting in\nerrors in visually grounded tasks and hallucinations. We hypothesize that this\nissue arises because existing VLMs are not explicitly trained to generate texts\nthat are accurately grounded in fine-grained image details. To enhance visual\nfeedback during VLM training, we propose S-VCO (Symmetrical Visual Contrastive\nOptimization), a novel finetuning objective that steers the model toward\ncapturing important visual details and aligning them with corresponding text\ntokens. To further facilitate this detailed alignment, we introduce MVC, a\npaired image-text dataset built by automatically filtering and augmenting\nvisual counterfactual data to challenge the model with hard contrastive cases\ninvolving Minimal Visual Contrasts. Experiments show that our method\nconsistently improves VLM performance across diverse benchmarks covering\nvarious abilities and domains, achieving up to a 22% reduction in\nhallucinations, and significant gains in vision-centric and general tasks.\nNotably, these improvements become increasingly pronounced in benchmarks with\nhigher visual dependency. In short, S-VCO offers a significant enhancement of\nVLM's visually-dependent task performance while retaining or even improving the\nmodel's general abilities. We opensource our code at https://s-vco.github.io/", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (VLM) \u503e\u5411\u4e8e\u5ffd\u7565\u56fe\u50cf\u5185\u5bb9\uff0c\u8fc7\u5ea6\u4f9d\u8d56\u8bed\u8a00\u6a21\u578b\u5148\u9a8c\uff0c\u5bfc\u81f4\u89c6\u89c9\u57fa\u7840\u4efb\u52a1\u4e2d\u7684\u9519\u8bef\u548c\u5e7b\u89c9\u3002\u6211\u4eec\u5047\u8bbe\u8fd9\u4e2a\u95ee\u9898\u51fa\u73b0\u662f\u56e0\u4e3a\u73b0\u6709\u7684 VLM \u5e76\u672a\u660e\u786e\u8bad\u7ec3\u6765\u751f\u6210\u7cbe\u786e\u5efa\u7acb\u5728\u7cbe\u7ec6\u56fe\u50cf\u7ec6\u8282\u4e0a\u7684\u6587\u672c\u3002\u4e3a\u4e86\u5728 VLM \u8bad\u7ec3\u671f\u95f4\u589e\u5f3a\u89c6\u89c9\u53cd\u9988\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 S-VCO\uff08\u5bf9\u79f0\u89c6\u89c9\u5bf9\u6bd4\u4f18\u5316\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5fae\u8c03\u76ee\u6807\uff0c\u5f15\u5bfc\u6a21\u578b\u6355\u6349\u91cd\u8981\u7684\u89c6\u89c9\u7ec6\u8282\uff0c\u5e76\u5c06\u5176\u4e0e\u76f8\u5e94\u7684\u6587\u672c\u6807\u8bb0\u5bf9\u9f50\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u4fc3\u8fdb\u8fd9\u79cd\u8be6\u7ec6\u5bf9\u9f50\uff0c\u6211\u4eec\u5f15\u5165\u4e86 MVC\uff0c\u8fd9\u662f\u4e00\u79cd\u6210\u5bf9\u7684\u56fe\u50cf\u6587\u672c\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u81ea\u52a8\u8fc7\u6ee4\u548c\u6269\u5145\u89c6\u89c9\u53cd\u4e8b\u5b9e\u6570\u636e\u6784\u5efa\u800c\u6210\uff0c\u4ee5\u4f7f\u7528\u6d89\u53ca\u6700\u5c0f\u89c6\u89c9\u5bf9\u6bd4\u7684\u56f0\u96be\u5bf9\u6bd4\u6848\u4f8b\u6765\u6311\u6218\u6a21\u578b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u6db5\u76d6\u5404\u79cd\u80fd\u529b\u548c\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u63d0\u5347\u4e86 VLM \u6027\u80fd\uff0c\u5e7b\u89c9\u51cf\u5c11\u4e86 22%\uff0c\u5e76\u4e14\u5728\u4ee5\u89c6\u89c9\u4e3a\u4e2d\u5fc3\u7684\u901a\u7528\u4efb\u52a1\u4e2d\u83b7\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u4e9b\u6539\u8fdb\u5728\u89c6\u89c9\u4f9d\u8d56\u6027\u8f83\u9ad8\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d8\u5f97\u8d8a\u6765\u8d8a\u660e\u663e\u3002\u7b80\u800c\u8a00\u4e4b\uff0cS-VCO \u663e\u7740\u63d0\u5347\u4e86 VLM \u7684\u89c6\u89c9\u4f9d\u8d56\u578b\u4efb\u52a1\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u7559\u751a\u81f3\u63d0\u5347\u4e86\u6a21\u578b\u7684\u901a\u7528\u80fd\u529b\u3002\u6211\u4eec\u5728 https://s-vco.github.io/ \u4e0a\u5f00\u6e90\u4e86\u6211\u4eec\u7684\u4ee3\u7801\u3002</paragraph>", "author": "Shengguang Wu et.al.", "authors": "Shengguang Wu, Fan-Yun Sun, Kaiyue Wen, Nick Haber", "id": "2502.13928v1", "paper_url": "http://arxiv.org/abs/2502.13928v1", "repo": "null"}}