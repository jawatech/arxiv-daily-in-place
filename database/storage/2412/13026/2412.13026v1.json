{"2412.13026": {"publish_time": "2024-12-17", "title": "NAVCON: A Cognitively Inspired and Linguistically Grounded Corpus for Vision and Language Navigation", "paper_summary": "We present NAVCON, a large-scale annotated Vision-Language Navigation (VLN)\ncorpus built on top of two popular datasets (R2R and RxR). The paper introduces\nfour core, cognitively motivated and linguistically grounded, navigation\nconcepts and an algorithm for generating large-scale silver annotations of\nnaturally occurring linguistic realizations of these concepts in navigation\ninstructions. We pair the annotated instructions with video clips of an agent\nacting on these instructions. NAVCON contains 236, 316 concept annotations for\napproximately 30, 0000 instructions and 2.7 million aligned images (from\napproximately 19, 000 instructions) showing what the agent sees when executing\nan instruction. To our knowledge, this is the first comprehensive resource of\nnavigation concepts. We evaluated the quality of the silver annotations by\nconducting human evaluation studies on NAVCON samples. As further validation of\nthe quality and usefulness of the resource, we trained a model for detecting\nnavigation concepts and their linguistic realizations in unseen instructions.\nAdditionally, we show that few-shot learning with GPT-4o performs well on this\ntask using large-scale silver annotations of NAVCON.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa NAVCON\uff0c\u4e00\u500b\u5efa\u7acb\u5728\u5169\u500b\u71b1\u9580\u8cc7\u6599\u96c6 (R2R \u548c RxR) \u4e0a\u7684\u5927\u898f\u6a21\u6a19\u8a3b\u8996\u89ba\u8a9e\u8a00\u5c0e\u822a (VLN) \u8a9e\u6599\u5eab\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u56db\u500b\u6838\u5fc3\u3001\u8a8d\u77e5\u52d5\u6a5f\u548c\u8a9e\u8a00\u57fa\u790e\u7684\u5c0e\u822a\u6982\u5ff5\uff0c\u4ee5\u53ca\u4e00\u7a2e\u6f14\u7b97\u6cd5\uff0c\u7528\u65bc\u7522\u751f\u9019\u4e9b\u6982\u5ff5\u5728\u5c0e\u822a\u6307\u4ee4\u4e2d\u81ea\u7136\u767c\u751f\u7684\u8a9e\u8a00\u5be6\u73fe\u7684\u5927\u898f\u6a21\u9280\u8272\u6a19\u8a3b\u3002\u6211\u5011\u5c07\u5e36\u6a19\u8a3b\u7684\u6307\u4ee4\u8207\u4ee3\u7406\u4eba\u6839\u64da\u9019\u4e9b\u6307\u4ee4\u57f7\u884c\u7684\u5f71\u7247\u7247\u6bb5\u914d\u5c0d\u3002NAVCON \u5305\u542b 236, 316 \u500b\u6982\u5ff5\u6a19\u8a3b\uff0c\u7d04 30, 0000 \u689d\u6307\u4ee4\u548c 270 \u842c\u5f35\u5c0d\u9f4a\u5f71\u50cf\uff08\u4f86\u81ea\u7d04 19, 000 \u689d\u6307\u4ee4\uff09\uff0c\u986f\u793a\u4ee3\u7406\u4eba\u5728\u57f7\u884c\u6307\u4ee4\u6642\u6240\u898b\u5167\u5bb9\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u5168\u9762\u7684\u5c0e\u822a\u6982\u5ff5\u8cc7\u6e90\u3002\u6211\u5011\u900f\u904e\u5c0d NAVCON \u6a23\u672c\u9032\u884c\u4eba\u70ba\u8a55\u4f30\u7814\u7a76\uff0c\u8a55\u4f30\u4e86\u9280\u8272\u6a19\u8a3b\u7684\u54c1\u8cea\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u9a57\u8b49\u8cc7\u6e90\u7684\u54c1\u8cea\u548c\u6709\u7528\u6027\uff0c\u6211\u5011\u8a13\u7df4\u4e86\u4e00\u500b\u6a21\u578b\uff0c\u7528\u65bc\u5728\u672a\u898b\u904e\u7684\u6307\u4ee4\u4e2d\u5075\u6e2c\u5c0e\u822a\u6982\u5ff5\u53ca\u5176\u8a9e\u8a00\u5be6\u73fe\u3002\u6b64\u5916\uff0c\u6211\u5011\u8868\u660e\uff0c\u4f7f\u7528 NAVCON \u7684\u5927\u898f\u6a21\u9280\u8272\u6a19\u8a3b\uff0cGPT-4o \u4e0a\u7684\u5c11\u91cf\u5b78\u7fd2\u5728\u6b64\u4efb\u52d9\u4e0a\u8868\u73fe\u826f\u597d\u3002", "author": "Karan Wanchoo et.al.", "authors": "Karan Wanchoo, Xiaoye Zuo, Hannah Gonzalez, Soham Dan, Georgios Georgakis, Dan Roth, Kostas Daniilidis, Eleni Miltsakaki", "id": "2412.13026v1", "paper_url": "http://arxiv.org/abs/2412.13026v1", "repo": "null"}}