
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-08**|**Recycled Attention: Efficient inference for long-context language models**|Fangyuan Xu et.al.|[2411.05787v1](http://arxiv.org/abs/2411.05787v1)|null|
|**2024-11-08**|**ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles**|Kayo Yin et.al.|[2411.05783v1](http://arxiv.org/abs/2411.05783v1)|null|
|**2024-11-08**|**Using Language Models to Disambiguate Lexical Choices in Translation**|Josh Barua et.al.|[2411.05781v1](http://arxiv.org/abs/2411.05781v1)|null|
|**2024-11-08**|**GazeSearch: Radiology Findings Search Benchmark**|Trong Thang Pham et.al.|[2411.05780v1](http://arxiv.org/abs/2411.05780v1)|null|
|**2024-11-08**|**LLMs as Method Actors: A Model for Prompt Engineering and Architecture**|Colin Doyle et.al.|[2411.05778v1](http://arxiv.org/abs/2411.05778v1)|null|
|**2024-11-08**|**Quantitative Assessment of Intersectional Empathetic Bias and Understanding**|Vojtech Formanek et.al.|[2411.05777v1](http://arxiv.org/abs/2411.05777v1)|null|
|**2024-11-08**|**Fact or Fiction? Can LLMs be Reliable Annotators for Political Truths?**|Veronica Chatrath et.al.|[2411.05775v1](http://arxiv.org/abs/2411.05775v1)|null|
|**2024-11-08**|**FinDVer: Explainable Claim Verification over Long and Hybrid-Content Financial Documents**|Yilun Zhao et.al.|[2411.05764v1](http://arxiv.org/abs/2411.05764v1)|null|
|**2024-11-08**|**Multi-hop Evidence Pursuit Meets the Web: Team Papelo at FEVER 2024**|Christopher Malon et.al.|[2411.05762v1](http://arxiv.org/abs/2411.05762v1)|null|
|**2024-11-08**|**End-to-End Navigation with Vision Language Models: Transforming Spatial Reasoning into Question-Answering**|Dylan Goetting et.al.|[2411.05755v1](http://arxiv.org/abs/2411.05755v1)|null|
|**2024-11-08**|**FisherMask: Enhancing Neural Network Labeling Efficiency in Image Classification Using Fisher Information**|Shreen Gul et.al.|[2411.05752v1](http://arxiv.org/abs/2411.05752v1)|[link](https://github.com/sgchr273/fishermask)|
|**2024-11-08**|**Topology-aware Reinforcement Feature Space Reconstruction for Graph Data**|Wangyang Ying et.al.|[2411.05742v1](http://arxiv.org/abs/2411.05742v1)|null|
|**2024-11-08**|**Aioli: A Unified Optimization Framework for Language Model Data Mixing**|Mayee F. Chen et.al.|[2411.05735v1](http://arxiv.org/abs/2411.05735v1)|null|
|**2024-11-08**|**Image2Text2Image: A Novel Framework for Label-Free Evaluation of Image-to-Text Generation with Text-to-Image Diffusion Models**|Jia-Hong Huang et.al.|[2411.05706v1](http://arxiv.org/abs/2411.05706v1)|null|
|**2024-11-08**|**Asterisk*: Keep it Simple**|Andrew Semenov et.al.|[2411.05691v1](http://arxiv.org/abs/2411.05691v1)|null|
|**2024-11-08**|**Data-Driven Distributed Common Operational Picture from Heterogeneous Platforms using Multi-Agent Reinforcement Learning**|Indranil Sur et.al.|[2411.05683v1](http://arxiv.org/abs/2411.05683v1)|null|
|**2024-11-08**|**Tell What You Hear From What You See -- Video to Audio Generation Through Text**|Xiulong Liu et.al.|[2411.05679v1](http://arxiv.org/abs/2411.05679v1)|null|
|**2024-11-08**|**Improving Molecular Graph Generation with Flow Matching and Optimal Transport**|Xiaoyang Hou et.al.|[2411.05676v1](http://arxiv.org/abs/2411.05676v1)|null|
|**2024-11-08**|**Unmasking the Limits of Large Language Models: A Systematic Evaluation of Masked Text Processing Ability through MskQA and MskCal**|Fuka Matsuzaki et.al.|[2411.05665v1](http://arxiv.org/abs/2411.05665v1)|[link](https://github.com/isfhub/maskcode)|
|**2024-11-08**|**The influence of persona and conversational task on social interactions with a LLM-controlled embodied conversational agent**|Leon O. H. Kroczek et.al.|[2411.05653v1](http://arxiv.org/abs/2411.05653v1)|null|
|**2024-11-08**|**Evaluating Large Language Model Capability in Vietnamese Fact-Checking Data Generation**|Long Truong To et.al.|[2411.05641v1](http://arxiv.org/abs/2411.05641v1)|null|
|**2024-11-08**|**Assessing Open-Source Large Language Models on Argumentation Mining Subtasks**|Mohammad Yeghaneh Abkenar et.al.|[2411.05639v1](http://arxiv.org/abs/2411.05639v1)|null|
|**2024-11-08**|**Impact of Fake News on Social Media Towards Public Users of Different Age Groups**|Kahlil bin Abdul Hakim et.al.|[2411.05638v1](http://arxiv.org/abs/2411.05638v1)|null|
|**2024-11-08**|**SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection**|Tamara R. Lenhard et.al.|[2411.05633v1](http://arxiv.org/abs/2411.05633v1)|null|
|**2024-11-08**|**Knowledge Distillation Neural Network for Predicting Car-following Behaviour of Human-driven and Autonomous Vehicles**|Ayobami Adewale et.al.|[2411.05618v1](http://arxiv.org/abs/2411.05618v1)|null|
|**2024-11-08**|**Expectation vs. Reality: Towards Verification of Psychological Games**|Marta Kwiatkowska et.al.|[2411.05599v1](http://arxiv.org/abs/2411.05599v1)|null|
|**2024-11-08**|**Evaluating and Adapting Large Language Models to Represent Folktales in Low-Resource Languages**|JA Meaney et.al.|[2411.05593v1](http://arxiv.org/abs/2411.05593v1)|null|
|**2024-11-08**|**Open-set object detection: towards unified problem formulation and benchmarking**|Hejer Ammar et.al.|[2411.05564v1](http://arxiv.org/abs/2411.05564v1)|null|
|**2024-11-08**|**Training objective drives the consistency of representational similarity across datasets**|Laure Ciernik et.al.|[2411.05561v1](http://arxiv.org/abs/2411.05561v1)|[link](https://github.com/lciernik/similarity_consistency)|
|**2024-11-08**|**Assessing the Answerability of Queries in Retrieval-Augmented Code Generation**|Geonmin Kim et.al.|[2411.05547v1](http://arxiv.org/abs/2411.05547v1)|null|
|**2024-11-08**|**CRepair: CVAE-based Automatic Vulnerability Repair Technology**|Penghui Liu et.al.|[2411.05540v1](http://arxiv.org/abs/2411.05540v1)|null|
|**2024-11-08**|**How Good is Your Wikipedia?**|Kushal Tatariya et.al.|[2411.05527v1](http://arxiv.org/abs/2411.05527v1)|null|
|**2024-11-08**|**SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**|Sithursan Sivasubramaniam et.al.|[2411.05521v1](http://arxiv.org/abs/2411.05521v1)|null|
|**2024-11-08**|**Towards Scalable Foundation Models for Digital Dermatology**|Fabian Gröger et.al.|[2411.05514v1](http://arxiv.org/abs/2411.05514v1)|null|
|**2024-11-08**|**An Early FIRST Reproduction and Improvements to Single-Token Decoding for Fast Listwise Reranking**|Zijian Chen et.al.|[2411.05508v1](http://arxiv.org/abs/2411.05508v1)|null|
|**2024-11-08**|**LBPE: Long-token-first Tokenization to Improve Large Language Models**|Haoran Lian et.al.|[2411.05504v1](http://arxiv.org/abs/2411.05504v1)|null|
|**2024-11-08**|**KyrgyzNLP: Challenges, Progress, and Future**|Anton Alekseev et.al.|[2411.05503v1](http://arxiv.org/abs/2411.05503v1)|null|
|**2024-11-08**|**EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**|Abdoul Nasser Hassane Amadou et.al.|[2411.05479v1](http://arxiv.org/abs/2411.05479v1)|[link](https://github.com/jumbo110/eurekha)|
|**2024-11-08**|**Supporting Automated Fact-checking across Topics: Similarity-driven Gradual Topic Learning for Claim Detection**|Amani S. Abumansour et.al.|[2411.05460v1](http://arxiv.org/abs/2411.05460v1)|null|
|**2024-11-08**|**WorkflowLLM: Enhancing Workflow Orchestration Capability of Large Language Models**|Shengda Fan et.al.|[2411.05451v1](http://arxiv.org/abs/2411.05451v1)|[link](https://github.com/openbmb/workflowllm)|
|**2024-11-08**|**ICE-T: A Multi-Faceted Concept for Teaching Machine Learning**|Hendrik Krone et.al.|[2411.05424v1](http://arxiv.org/abs/2411.05424v1)|null|
|**2024-11-08**|**VISTA: Visual Integrated System for Tailored Automation in Math Problem Generation Using LLM**|Jeongwoo Lee et.al.|[2411.05423v1](http://arxiv.org/abs/2411.05423v1)|null|
|**2024-11-08**|**Learning the rules of peptide self-assembly through data mining with large language models**|Zhenze Yang et.al.|[2411.05421v1](http://arxiv.org/abs/2411.05421v1)|[link](https://github.com/lamm-mit/peptideminer)|
|**2024-11-08**|**WeatherGFM: Learning A Weather Generalist Foundation Model via In-context Learning**|Xiangyu Zhao et.al.|[2411.05420v1](http://arxiv.org/abs/2411.05420v1)|null|
|**2024-11-08**|**Web Archives Metadata Generation with GPT-4o: Challenges and Insights**|Abigail Yongping Huang et.al.|[2411.05409v1](http://arxiv.org/abs/2411.05409v1)|[link](https://github.com/masamune-prog/warc2summary)|
|**2024-11-08**|**Gap-Filling Prompting Enhances Code-Assisted Mathematical Reasoning**|Mohammad Ghiasvand Mohammadkhani et.al.|[2411.05407v1](http://arxiv.org/abs/2411.05407v1)|null|
|**2024-11-08**|**Benchmarking Distributional Alignment of Large Language Models**|Nicole Meister et.al.|[2411.05403v1](http://arxiv.org/abs/2411.05403v1)|[link](https://github.com/nicolemeister/benchmarking-distributional-alignment)|
|**2024-11-08**|**Advancing Meteorological Forecasting: AI-based Approach to Synoptic Weather Map Analysis**|Yo-Hwan Choi et.al.|[2411.05384v1](http://arxiv.org/abs/2411.05384v1)|null|
|**2024-11-08**|**Towards Low-Resource Harmful Meme Detection with LMM Agents**|Jianzhao Huang et.al.|[2411.05383v1](http://arxiv.org/abs/2411.05383v1)|[link](https://github.com/jianzhao-huang/lorehm)|
|**2024-11-08**|**Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking**|Mubashara Akhtar et.al.|[2411.05375v1](http://arxiv.org/abs/2411.05375v1)|null|
|**2024-11-08**|**Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks**|Chien-yu Huang et.al.|[2411.05361v1](http://arxiv.org/abs/2411.05361v1)|null|
|**2024-11-08**|**Agricultural Landscape Understanding At Country-Scale**|Radhika Dua et.al.|[2411.05359v1](http://arxiv.org/abs/2411.05359v1)|null|
|**2024-11-08**|**Controlling Grokking with Nonlinearity and Data Symmetry**|Ahmed Salah et.al.|[2411.05353v1](http://arxiv.org/abs/2411.05353v1)|null|
|**2024-11-08**|**Enhancing Cluster Resilience: LLM-agent Based Autonomous Intelligent Cluster Diagnosis System and Evaluation Framework**|Honghao Shi et.al.|[2411.05349v1](http://arxiv.org/abs/2411.05349v1)|null|
|**2024-11-08**|**LLM-PySC2: Starcraft II learning environment for Large Language Models**|Zongyuan Li et.al.|[2411.05348v1](http://arxiv.org/abs/2411.05348v1)|null|
|**2024-11-08**|**Reasoning Robustness of LLMs to Adversarial Typographical Errors**|Esther Gan et.al.|[2411.05345v1](http://arxiv.org/abs/2411.05345v1)|null|
|**2024-11-08**|**Improving Multi-Domain Task-Oriented Dialogue System with Offline Reinforcement Learning**|Dharmendra Prajapat et.al.|[2411.05340v1](http://arxiv.org/abs/2411.05340v1)|null|
|**2024-11-08**|**SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers**|Shruti Singh et.al.|[2411.05338v1](http://arxiv.org/abs/2411.05338v1)|null|
|**2024-11-08**|**Inversion-based Latent Bayesian Optimization**|Jaewon Chu et.al.|[2411.05330v1](http://arxiv.org/abs/2411.05330v1)|[link](https://github.com/mlvlab/invbo)|
|**2024-11-08**|**Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**|Dong Shu et.al.|[2411.05316v1](http://arxiv.org/abs/2411.05316v1)|[link](https://github.com/tizzzzy/llm-gdm-alignment)|
|**2024-11-08**|**On Training of Kolmogorov-Arnold Networks**|Shairoz Sohail et.al.|[2411.05296v1](http://arxiv.org/abs/2411.05296v1)|null|
|**2024-11-08**|**SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding**|Ryan Sun et.al.|[2411.05289v1](http://arxiv.org/abs/2411.05289v1)|[link](https://github.com/mastergodzilla/speculative_decoding_ot)|
|**2024-11-08**|**A Taxonomy of AgentOps for Enabling Observability of Foundation Model based Agents**|Liming Dong et.al.|[2411.05285v1](http://arxiv.org/abs/2411.05285v1)|null|
|**2024-11-08**|**MicroScopiQ: Accelerating Foundational Models through Outlier-Aware Microscaling Quantization**|Akshat Ramachandran et.al.|[2411.05282v1](http://arxiv.org/abs/2411.05282v1)|null|
|**2024-11-08**|**Fox-1 Technical Report**|Zijian Hu et.al.|[2411.05281v1](http://arxiv.org/abs/2411.05281v1)|null|
|**2024-11-08**|**Revisiting the Robustness of Watermarking to Paraphrasing Attacks**|Saksham Rastogi et.al.|[2411.05277v1](http://arxiv.org/abs/2411.05277v1)|null|
|**2024-11-08**|**Real-World Offline Reinforcement Learning from Vision Language Model Feedback**|Sreyas Venkataraman et.al.|[2411.05273v1](http://arxiv.org/abs/2411.05273v1)|null|
|**2024-11-08**|**Seeing Through the Fog: A Cost-Effectiveness Analysis of Hallucination Detection Systems**|Alexander Thomas et.al.|[2411.05270v1](http://arxiv.org/abs/2411.05270v1)|null|
|**2024-11-08**|**Decoding Report Generators: A Cyclic Vision-Language Adapter for Counterfactual Explanations**|Yingying Fang et.al.|[2411.05261v1](http://arxiv.org/abs/2411.05261v1)|null|
|**2024-11-08**|**QuanCrypt-FL: Quantized Homomorphic Encryption with Pruning for Secure Federated Learning**|Md Jueal Mia et.al.|[2411.05260v1](http://arxiv.org/abs/2411.05260v1)|null|
|**2024-11-08**|**What talking you?: Translating Code-Mixed Messaging Texts to English**|Lynnette Hui Xian Ng et.al.|[2411.05253v1](http://arxiv.org/abs/2411.05253v1)|null|
|**2024-11-07**|**Abstract2Appendix: Academic Reviews Enhance LLM Long-Context Capabilities**|Shengzhi Li et.al.|[2411.05232v1](http://arxiv.org/abs/2411.05232v1)|null|
|**2024-11-07**|**Evaluating GPT-4 at Grading Handwritten Solutions in Math Exams**|Adriana Caraeni et.al.|[2411.05231v1](http://arxiv.org/abs/2411.05231v1)|null|
|**2024-11-07**|**CHATTER: A Character Attribution Dataset for Narrative Understanding**|Sabyasachee Baruah et.al.|[2411.05227v1](http://arxiv.org/abs/2411.05227v1)|null|
|**2024-11-07**|**Beyond the Numbers: Transparency in Relation Extraction Benchmark Creation and Leaderboards**|Varvara Arzt et.al.|[2411.05224v1](http://arxiv.org/abs/2411.05224v1)|null|
|**2024-11-07**|**STAND-Guard: A Small Task-Adaptive Content Moderation Model**|Minjia Wang et.al.|[2411.05214v1](http://arxiv.org/abs/2411.05214v1)|null|
|**2024-11-07**|**Alopex: A Computational Framework for Enabling On-Device Function Calls with LLMs**|Yide Ran et.al.|[2411.05209v1](http://arxiv.org/abs/2411.05209v1)|null|
|**2024-11-07**|**Toward Cultural Interpretability: A Linguistic Anthropological Framework for Describing and Evaluating Large Language Models (LLMs)**|Graham M. Jones et.al.|[2411.05200v1](http://arxiv.org/abs/2411.05200v1)|null|
|**2024-11-07**|**CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement**|Leitian Tao et.al.|[2411.05199v1](http://arxiv.org/abs/2411.05199v1)|null|
|**2024-11-07**|**Explainable AI through a Democratic Lens: DhondtXAI for Proportional Feature Importance Using the D'Hondt Method**|Turker Berk Donmez et.al.|[2411.05196v1](http://arxiv.org/abs/2411.05196v1)|null|
|**2024-11-07**|**On Erroneous Agreements of CLIP Image Embeddings**|Siting Li et.al.|[2411.05195v1](http://arxiv.org/abs/2411.05195v1)|null|
|**2024-11-07**|**Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations**|Joey Hong et.al.|[2411.05194v1](http://arxiv.org/abs/2411.05194v1)|null|
|**2024-11-07**|**Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning**|Joey Hong et.al.|[2411.05193v1](http://arxiv.org/abs/2411.05193v1)|null|
|**2024-11-07**|**Explaining Mixtures of Sources in News Articles**|Alexander Spangher et.al.|[2411.05192v1](http://arxiv.org/abs/2411.05192v1)|null|
|**2024-11-07**|**Discern-XR: An Online Classifier for Metaverse Network Traffic**|Yoga Suhas Kuruba Manjunath et.al.|[2411.05184v1](http://arxiv.org/abs/2411.05184v1)|null|
|**2024-11-07**|**Inverse Transition Learning: Learning Dynamics from Demonstrations**|Leo Benac et.al.|[2411.05174v1](http://arxiv.org/abs/2411.05174v1)|null|
|**2024-11-07**|**ImpScore: A Learnable Metric For Quantifying The Implicitness Level of Language**|Yuxin Wang et.al.|[2411.05172v1](http://arxiv.org/abs/2411.05172v1)|[link](https://github.com/audreycs/impscore)|
|**2024-11-07**|**Watermarking Language Models through Language Models**|Xin Zhong et.al.|[2411.05091v1](http://arxiv.org/abs/2411.05091v1)|null|
|**2024-11-07**|**Findings of the IWSLT 2024 Evaluation Campaign**|Ibrahim Said Ahmad et.al.|[2411.05088v1](http://arxiv.org/abs/2411.05088v1)|null|
|**2024-11-07**|**PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation**|Daniel C. Castro et.al.|[2411.05085v1](http://arxiv.org/abs/2411.05085v1)|null|
|**2024-11-07**|**Precision or Recall? An Analysis of Image Captions for Training Text-to-Image Generation Model**|Sheng Cheng et.al.|[2411.05079v1](http://arxiv.org/abs/2411.05079v1)|[link](https://github.com/shengcheng/captions4t2i)|
|**2024-11-07**|**ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning**|David Junhao Zhang et.al.|[2411.05003v1](http://arxiv.org/abs/2411.05003v1)|null|
|**2024-11-07**|**Analyzing The Language of Visual Tokens**|David M. Chan et.al.|[2411.05001v1](http://arxiv.org/abs/2411.05001v1)|null|
|**2024-11-07**|**Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?**|Jonathan Roberts et.al.|[2411.05000v1](http://arxiv.org/abs/2411.05000v1)|null|
|**2024-11-07**|**LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation**|Weiquan Huang et.al.|[2411.04997v1](http://arxiv.org/abs/2411.04997v1)|[link](https://github.com/microsoft/LLM2CLIP)|
|**2024-11-07**|**HourVideo: 1-Hour Video-Language Understanding**|Keshigeyan Chandrasegaran et.al.|[2411.04998v1](http://arxiv.org/abs/2411.04998v1)|null|
|**2024-11-07**|**Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models**|Weixin Liang et.al.|[2411.04996v1](http://arxiv.org/abs/2411.04996v1)|null|
|**2024-11-07**|**Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives**|Hao Sun et.al.|[2411.04991v1](http://arxiv.org/abs/2411.04991v1)|[link](https://github.com/holarissun/rewardmodelingbeyondbradleyterry)|
|**2024-11-07**|**Few-Shot Task Learning through Inverse Generative Modeling**|Aviv Netanyahu et.al.|[2411.04987v1](http://arxiv.org/abs/2411.04987v1)|null|
|**2024-11-07**|**The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities**|Zhaofeng Wu et.al.|[2411.04986v1](http://arxiv.org/abs/2411.04986v1)|null|

#### Abstracts
##### **Recycled Attention: Efficient inference for long-context language models**
2411.05787v1 by Fangyuan Xu, Tanya Goyal, Eunsol Choi

Generating long sequences of tokens given a long-context input imposes a
heavy computational burden for large language models (LLMs). One of the
computational bottleneck comes from computing attention over a long sequence of
input at each generation step. In this paper, we propose Recycled Attention, an
inference-time method which alternates between full context attention and
attention over a subset of input tokens. When performing partial attention, we
recycle the attention pattern of a previous token that has performed full
attention and attend only to the top K most attended tokens, reducing the cost
of data movement and attention computation. Compared to previously proposed
inference-time acceleration method which attends only to local context or
tokens with high accumulative attention scores, our approach flexibly chooses
tokens that are relevant to the current decoding step. We evaluate our methods
on RULER, a suite of tasks designed to comprehensively evaluate long-context
abilities, and long-context language modeling tasks. Applying our method to
off-the-shelf LLMs achieves comparable speedup to baselines which only consider
local context while improving the performance by 2x. We further explore two
ideas to improve performance-efficiency trade-offs: (1) dynamically decide when
to perform recycled or full attention step based on the query similarities and
(2) continued pre-training the model with Recycled Attention.

摘要：在提供長背景輸入的情況下產生長序列的符號會對大型語言模型 (LLM) 造成沉重的計算負擔。其中一個計算瓶頸來自於在每個產生步驟中計算長輸入序列的注意力。在本文中，我們提出循環注意力，這是一種在完整背景注意力和輸入符號子集的注意力之間交替的推論時間方法。在執行部分注意力時，我們循環利用已執行完整注意力的前一個符號的注意力模式，並僅注意最受關注的 K 個符號，從而降低了數據移動和注意力計算的成本。與先前提出的僅關注局部背景或累積注意力分數高的符號的推論時間加速方法相比，我們的做法靈活地選擇與當前解碼步驟相關的符號。我們在 RULER 上評估我們的模型，RULER 是一組旨在全面評估長背景能力的任務，以及長背景語言建模任務。將我們的模型應用於現成的 LLM，可實現與僅考慮局部背景的基線相當的加速，同時將效能提升 2 倍。我們進一步探討了兩種提升效能效率折衷的構想：(1) 根據查詢相似性動態決定何時執行循環或完整注意力步驟，以及 (2) 持續使用循環注意力預訓練模型。

##### **ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles**
2411.05783v1 by Kayo Yin, Chinmay Singh, Fyodor O. Minakov, Vanessa Milan, Hal Daumé III, Cyril Zhang, Alex X. Lu, Danielle Bragg

Deaf and hard-of-hearing (DHH) students face significant barriers in
accessing science, technology, engineering, and mathematics (STEM) education,
notably due to the scarcity of STEM resources in signed languages. To help
address this, we introduce ASL STEM Wiki: a parallel corpus of 254 Wikipedia
articles on STEM topics in English, interpreted into over 300 hours of American
Sign Language (ASL). ASL STEM Wiki is the first continuous signing dataset
focused on STEM, facilitating the development of AI resources for STEM
education in ASL. We identify several use cases of ASL STEM Wiki with
human-centered applications. For example, because this dataset highlights the
frequent use of fingerspelling for technical concepts, which inhibits DHH
students' ability to learn, we develop models to identify fingerspelled words
-- which can later be used to query for appropriate ASL signs to suggest to
interpreters.

摘要：聽障和重聽 (DHH) 學生在取得科學、技術、工程和數學 (STEM) 教育時，會面臨重大的障礙，這主要是因為手語中缺乏 STEM 資源。為了幫助解決這個問題，我們引入了 ASL STEM Wiki：一個包含 254 篇英語 STEM 主題的維基百科條目平行語料庫，並翻譯成超過 300 小時的美國手語 (ASL)。ASL STEM Wiki 是第一個專注於 STEM 的連續手語資料集，有助於開發 ASL 中 STEM 教育的 AI 資源。我們找出 ASL STEM Wiki 的幾個使用案例，這些案例具有以人為中心的應用。例如，由於這個資料集突顯了技術概念中經常使用手指拼寫，這會抑制 DHH 學生學習的能力，因此我們開發模型來識別手指拼寫的字詞，這些字詞稍後可查詢適當的 ASL 手勢，以建議給口譯員。

##### **Using Language Models to Disambiguate Lexical Choices in Translation**
2411.05781v1 by Josh Barua, Sanjay Subramanian, Kayo Yin, Alane Suhr

In translation, a concept represented by a single word in a source language
can have multiple variations in a target language. The task of lexical
selection requires using context to identify which variation is most
appropriate for a source text. We work with native speakers of nine languages
to create DTAiLS, a dataset of 1,377 sentence pairs that exhibit cross-lingual
concept variation when translating from English. We evaluate recent LLMs and
neural machine translation systems on DTAiLS, with the best-performing model,
GPT-4, achieving from 67 to 85% accuracy across languages. Finally, we use
language models to generate English rules describing target-language concept
variations. Providing weaker models with high-quality lexical rules improves
accuracy substantially, in some cases reaching or outperforming GPT-4.

摘要：在翻譯中，源語言中單字所代表的概念在目標語言中可能有多種變化。詞彙選擇的任務需要使用上下文來識別哪個變化最適合原始文字。我們與九種語言的母語人士合作，建立了 DTAiLS，這是一個由 1,377 個句子對組成的資料集，在從英語翻譯時展現了跨語言概念變化。我們在 DTAiLS 上評估了最近的 LLM 和神經機器翻譯系統，表現最佳的模型 GPT-4 在各種語言中達到了 67% 到 85% 的準確度。最後，我們使用語言模型來產生描述目標語言概念變化的英文規則。為較弱的模型提供高品質的詞彙規則可以大幅提升準確度，在某些情況下甚至達到或超越 GPT-4。

##### **GazeSearch: Radiology Findings Search Benchmark**
2411.05780v1 by Trong Thang Pham, Tien-Phat Nguyen, Yuki Ikebe, Akash Awasthi, Zhigang Deng, Carol C. Wu, Hien Nguyen, Ngan Le

Medical eye-tracking data is an important information source for
understanding how radiologists visually interpret medical images. This
information not only improves the accuracy of deep learning models for X-ray
analysis but also their interpretability, enhancing transparency in
decision-making. However, the current eye-tracking data is dispersed,
unprocessed, and ambiguous, making it difficult to derive meaningful insights.
Therefore, there is a need to create a new dataset with more focus and
purposeful eyetracking data, improving its utility for diagnostic applications.
In this work, we propose a refinement method inspired by the target-present
visual search challenge: there is a specific finding and fixations are guided
to locate it. After refining the existing eye-tracking datasets, we transform
them into a curated visual search dataset, called GazeSearch, specifically for
radiology findings, where each fixation sequence is purposefully aligned to the
task of locating a particular finding. Subsequently, we introduce a scan path
prediction baseline, called ChestSearch, specifically tailored to GazeSearch.
Finally, we employ the newly introduced GazeSearch as a benchmark to evaluate
the performance of current state-of-the-art methods, offering a comprehensive
assessment for visual search in the medical imaging domain.

摘要：醫療眼動追蹤資料是了解放射科醫師如何視覺化詮釋醫療影像的重要資訊來源。這些資訊不僅提升了深度學習模型在 X 光分析中的準確度，也提升了其可解釋性，增進決策制定中的透明度。然而，目前的醫療眼動追蹤資料分散、未經處理且不明確，這使得難以推導出有意義的見解。因此，有必要建立一個新的資料集，其中包含更多焦點和有目的的眼動追蹤資料，以提升其在診斷應用中的效用。在這項工作中，我們提出了一種改良方法，其靈感來自目標呈現視覺搜尋挑戰：有一個特定的發現，而固定則用於定位它。在改良現有的眼動追蹤資料集後，我們將其轉換為一個名為 GazeSearch 的精選視覺搜尋資料集，專門用於放射科發現，其中每個固定序列都刻意與定位特定發現的任務對齊。隨後，我們介紹了一個掃描路徑預測基準，稱為 ChestSearch，專門針對 GazeSearch 量身打造。最後，我們採用新推出的 GazeSearch 作為基準，評估目前最先進方法的效能，提供醫療影像領域中視覺搜尋的全面評估。

##### **LLMs as Method Actors: A Model for Prompt Engineering and Architecture**
2411.05778v1 by Colin Doyle

We introduce "Method Actors" as a mental model for guiding LLM prompt
engineering and prompt architecture. Under this mental model, LLMs should be
thought of as actors; prompts as scripts and cues; and LLM responses as
performances. We apply this mental model to the task of improving LLM
performance at playing Connections, a New York Times word puzzle game that
prior research identified as a challenging benchmark for evaluating LLM
reasoning. Our experiments with GPT-4o show that a "Method Actors" approach can
significantly improve LLM performance over both a vanilla and "Chain of
Thoughts" approach. A vanilla approach solves 27% of Connections puzzles in our
dataset and a "Chain of Thoughts" approach solves 41% of puzzles, whereas our
strongest "Method Actor" approach solves 86% of puzzles. We also test OpenAI's
newest model designed specifically for complex reasoning tasks, o1-preview.
When asked to solve a puzzle all at once, o1-preview solves 79% of Connections
puzzles in our dataset, and when allowed to build puzzle solutions one guess at
a time over multiple API calls, o1-preview solves 100% of the puzzles.
Incorporating a "Method Actor" prompt architecture increases the percentage of
puzzles that o1-preview solves perfectly from 76% to 87%.

摘要：<paragraph>我們引入「方法演員」作為指導 LLM 提示工程和提示架構的心智模型。在這個心智模型下，LLM 應被視為演員；提示為腳本和提示；LLM 回應為表演。我們將這個心智模型應用於改進 LLM 在玩「連線」遊戲時的表現，這是一款紐約時報的文字益智遊戲，先前的研究指出這是一個用於評估 LLM 推理的具有挑戰性的基準。我們對 GPT-4o 進行的實驗顯示，「方法演員」方法可以顯著提升 LLM 的表現，優於傳統方法和「思考鏈」方法。傳統方法在我們的資料集中解開了 27% 的「連線」益智遊戲，而「思考鏈」方法解開了 41% 的益智遊戲，而我們最強大的「方法演員」方法解開了 86% 的益智遊戲。我們也測試了 OpenAI 最新專門設計用於複雜推理任務的模型 o1-preview。當要求一次解開一個益智遊戲時，o1-preview 在我們的資料集中解開了 79% 的「連線」益智遊戲，而當允許一次猜測一個提示，透過多次 API 呼叫來建構益智遊戲解答時，o1-preview 解開了 100% 的益智遊戲。整合「方法演員」提示架構會將 o1-preview 完美解開的益智遊戲百分比從 76% 提升至 87%。</paragraph>

##### **Quantitative Assessment of Intersectional Empathetic Bias and Understanding**
2411.05777v1 by Vojtech Formanek, Ondrej Sotolar

A growing amount of literature critiques the current operationalizations of
empathy based on loose definitions of the construct. Such definitions
negatively affect dataset quality, model robustness, and evaluation
reliability. We propose an empathy evaluation framework that operationalizes
empathy close to its psychological origins. The framework measures the variance
in responses of LLMs to prompts using existing metrics for empathy and
emotional valence. The variance is introduced through the controlled generation
of the prompts by varying social biases affecting context understanding, thus
impacting empathetic understanding. The control over generation ensures high
theoretical validity of the constructs in the prompt dataset. Also, it makes
high-quality translation, especially into languages that currently have
little-to-no way of evaluating empathy or bias, such as the Slavonic family,
more manageable. Using chosen LLMs and various prompt types, we demonstrate the
empathy evaluation with the framework, including multiple-choice answers and
free generation. The variance in our initial evaluation sample is small and we
were unable to measure convincing differences between the empathetic
understanding in contexts given by different social groups. However, the
results are promising because the models showed significant alterations their
reasoning chains needed to capture the relatively subtle changes in the
prompts. This provides the basis for future research into the construction of
the evaluation sample and statistical methods for measuring the results.

摘要：隨著越來越多文獻探討基於結構鬆散定義的同理心當前運作方式，我們發現這些定義會對資料集品質、模型健全性以及評估可靠性造成負面影響。我們提出一個同理心評估架構，將同理心運作化，使其接近其心理起源。這個架構使用現有的同理心和情緒效價量度，來測量大型語言模型 (LLM) 對提示的回應差異。透過控制提示的產生，並改變影響情境理解的社會偏見，來引入差異，進而影響同理理解。對產生的控制確保提示資料集中結構的高理論效度。此外，它使高品質的翻譯變得更容易管理，特別是對於目前幾乎沒有評估同理心或偏見的方法的語言，例如斯拉夫語系。我們使用所選的 LLM 和各種提示類型，展示了使用這個架構進行同理心評估，包括多選題答案和自由生成。我們最初評估樣本中的差異很小，我們無法測量由不同社會群體給出的情境中的同理理解之間令人信服的差異。然而，由於模型顯示出它們的推理鏈顯著改變，需要捕捉提示中相對細微的變化，因此結果是有希望的。這為未來研究評估樣本的建構和測量結果的統計方法提供了基礎。

##### **Fact or Fiction? Can LLMs be Reliable Annotators for Political Truths?**
2411.05775v1 by Veronica Chatrath, Marcelo Lotif, Shaina Raza

Political misinformation poses significant challenges to democratic
processes, shaping public opinion and trust in media. Manual fact-checking
methods face issues of scalability and annotator bias, while machine learning
models require large, costly labelled datasets. This study investigates the use
of state-of-the-art large language models (LLMs) as reliable annotators for
detecting political factuality in news articles. Using open-source LLMs, we
create a politically diverse dataset, labelled for bias through LLM-generated
annotations. These annotations are validated by human experts and further
evaluated by LLM-based judges to assess the accuracy and reliability of the
annotations. Our approach offers a scalable and robust alternative to
traditional fact-checking, enhancing transparency and public trust in media.

摘要：政治錯誤資訊對民主程序造成重大挑戰，形塑輿論和對媒體的信任。手動查核事實的方法面臨可擴充性和註解者偏見的問題，而機器學習模型需要龐大且昂貴的標籤資料集。本研究探討使用最先進的大型語言模型 (LLM) 作為可靠的註解者，以偵測新聞文章中的政治事實。使用開源 LLM，我們建立一個政治多元的資料集，透過 LLM 生成的註解標記偏差。這些註解由人類專家驗證，並進一步由基於 LLM 的評審評估，以評估註解的準確性和可靠性。我們的做法提供了一個可擴充且穩健的替代方案，用於傳統的事實查核，增強透明度和公眾對媒體的信任。

##### **FinDVer: Explainable Claim Verification over Long and Hybrid-Content Financial Documents**
2411.05764v1 by Yilun Zhao, Yitao Long, Yuru Jiang, Chengye Wang, Weiyuan Chen, Hongjun Liu, Yiming Zhang, Xiangru Tang, Chen Zhao, Arman Cohan

We introduce FinDVer, a comprehensive benchmark specifically designed to
evaluate the explainable claim verification capabilities of LLMs in the context
of understanding and analyzing long, hybrid-content financial documents.
FinDVer contains 2,400 expert-annotated examples, divided into three subsets:
information extraction, numerical reasoning, and knowledge-intensive reasoning,
each addressing common scenarios encountered in real-world financial contexts.
We assess a broad spectrum of LLMs under long-context and RAG settings. Our
results show that even the current best-performing system, GPT-4o, still lags
behind human experts. We further provide in-depth analysis on long-context and
RAG setting, Chain-of-Thought reasoning, and model reasoning errors, offering
insights to drive future advancements. We believe that FinDVer can serve as a
valuable benchmark for evaluating LLMs in claim verification over complex,
expert-domain documents.

摘要：我們引入了 FinDVer，一個專門設計的綜合基準，用於評估 LLM 在理解和分析長篇混合內容財務文件方面的可解釋聲明驗證能力。
FinDVer 包含 2,400 個專家註釋範例，分為三個子集：資訊萃取、數值推理和知識密集推理，每個子集都針對在現實世界財務環境中遇到的常見情境。
我們在長語境和 RAG 設定下評估了廣泛的 LLM。我們的結果顯示，即使是目前效能最佳的系統 GPT-4o，仍然落後於人類專家。我們進一步提供長語境和 RAG 設定、思考鏈推理和模型推理錯誤的深入分析，提供見解以推動未來的進展。我們相信 FinDVer 可以作為一個有價值的基準，用於評估 LLM 在複雜的專家領域文件中的聲明驗證能力。

##### **Multi-hop Evidence Pursuit Meets the Web: Team Papelo at FEVER 2024**
2411.05762v1 by Christopher Malon

Separating disinformation from fact on the web has long challenged both the
search and the reasoning powers of humans. We show that the reasoning power of
large language models (LLMs) and the retrieval power of modern search engines
can be combined to automate this process and explainably verify claims. We
integrate LLMs and search under a multi-hop evidence pursuit strategy. This
strategy generates an initial question based on an input claim using a sequence
to sequence model, searches and formulates an answer to the question, and
iteratively generates follow-up questions to pursue the evidence that is
missing using an LLM. We demonstrate our system on the FEVER 2024 (AVeriTeC)
shared task. Compared to a strategy of generating all the questions at once,
our method obtains .045 higher label accuracy and .155 higher AVeriTeC score
(evaluating the adequacy of the evidence). Through ablations, we show the
importance of various design choices, such as the question generation method,
medium-sized context, reasoning with one document at a time, adding metadata,
paraphrasing, reducing the problem to two classes, and reconsidering the final
verdict. Our submitted system achieves .510 AVeriTeC score on the dev set and
.477 AVeriTeC score on the test set.

摘要：<paragraph>在網路上區分錯誤資訊和事實，長期以來一直是人類在搜尋和推理能力上的挑戰。我們展示大型語言模型 (LLM) 的推理能力和現代搜尋引擎的檢索能力可以結合起來，自動化這個流程並以可解釋的方式驗證宣稱。我們在多重跳躍證據追蹤策略下整合 LLM 和搜尋。這個策略會使用序列到序列模型根據輸入宣稱產生一個初始問題，搜尋並針對問題制定一個答案，並反覆產生後續問題，使用 LLM 追蹤遺失的證據。我們在 FEVER 2024 (AVeriTeC) 共享任務中展示我們的系統。與一次產生所有問題的策略相比，我們的做法獲得了高出 0.045 的標籤準確度和高出 0.155 的 AVeriTeC 分數（評估證據的充分性）。透過消融，我們展示了各種設計選擇的重要性，例如問題產生方法、中等大小的內容、一次使用一個文件推理、加入元資料、同義改寫、將問題簡化為兩個類別，以及重新考慮最終裁決。我們提交的系統在開發組上獲得 0.510 的 AVeriTeC 分數，在測試組上獲得 0.477 的 AVeriTeC 分數。</paragraph>

##### **End-to-End Navigation with Vision Language Models: Transforming Spatial Reasoning into Question-Answering**
2411.05755v1 by Dylan Goetting, Himanshu Gaurav Singh, Antonio Loquercio

We present VLMnav, an embodied framework to transform a Vision-Language Model
(VLM) into an end-to-end navigation policy. In contrast to prior work, we do
not rely on a separation between perception, planning, and control; instead, we
use a VLM to directly select actions in one step. Surprisingly, we find that a
VLM can be used as an end-to-end policy zero-shot, i.e., without any
fine-tuning or exposure to navigation data. This makes our approach open-ended
and generalizable to any downstream navigation task. We run an extensive study
to evaluate the performance of our approach in comparison to baseline prompting
methods. In addition, we perform a design analysis to understand the most
impactful design decisions. Visual examples and code for our project can be
found at https://jirl-upenn.github.io/VLMnav/

摘要：我們提出 VLMnav，一個具象框架，用於將視覺語言模型 (VLM) 轉換為端對端導航策略。與先前的研究不同，我們不依賴於感知、規劃和控制之間的區分；相反，我們使用 VLM 在一個步驟中直接選擇動作。令人驚訝的是，我們發現 VLM 可用作端對端策略零次學習，即無需任何微調或接觸導航數據。這使得我們的做法具有開放性，並且可以推廣到任何下游導航任務。我們進行了一項廣泛的研究，以評估我們的方法與基線提示方法相比的性能。此外，我們執行設計分析以了解影響最大的設計決策。可以在 https://jirl-upenn.github.io/VLMnav/ 找到我們項目的視覺範例和代碼。

##### **FisherMask: Enhancing Neural Network Labeling Efficiency in Image Classification Using Fisher Information**
2411.05752v1 by Shreen Gul, Mohamed Elmahallawy, Sanjay Madria, Ardhendu Tripathy

Deep learning (DL) models are popular across various domains due to their
remarkable performance and efficiency. However, their effectiveness relies
heavily on large amounts of labeled data, which are often time-consuming and
labor-intensive to generate manually. To overcome this challenge, it is
essential to develop strategies that reduce reliance on extensive labeled data
while preserving model performance. In this paper, we propose FisherMask, a
Fisher information-based active learning (AL) approach that identifies key
network parameters by masking them based on their Fisher information values.
FisherMask enhances batch AL by using Fisher information to select the most
critical parameters, allowing the identification of the most impactful samples
during AL training. Moreover, Fisher information possesses favorable
statistical properties, offering valuable insights into model behavior and
providing a better understanding of the performance characteristics within the
AL pipeline. Our extensive experiments demonstrate that FisherMask
significantly outperforms state-of-the-art methods on diverse datasets,
including CIFAR-10 and FashionMNIST, especially under imbalanced settings.
These improvements lead to substantial gains in labeling efficiency. Hence
serving as an effective tool to measure the sensitivity of model parameters to
data samples. Our code is available on
\url{https://github.com/sgchr273/FisherMask}.

摘要：深度學習 (DL) 模型因其卓越的效能和效率而廣受各領域歡迎。然而，其有效性極度仰賴大量標籤資料，而人工產生這些資料通常耗時且費力。為了解決這個挑戰，開發出能降低對大量標籤資料的依賴，同時維持模型效能的策略至關重要。在本文中，我們提出 FisherMask，一種基於 Fisher 資訊的主動學習 (AL) 方法，透過遮蔽網路參數並根據其 Fisher 資訊值來識別關鍵網路參數。FisherMask 透過使用 Fisher 資訊來選擇最關鍵的參數，增強批次 AL，在 AL 訓練期間識別影響最大的樣本。此外，Fisher 資訊具有良好的統計特性，提供對模型行為的寶貴見解，並提供對 AL 管線中效能特性的更深入了解。我們廣泛的實驗證明，FisherMask 在各種資料集上明顯優於最先進的方法，包括 CIFAR-10 和 FashionMNIST，特別是在不平衡的設定下。這些改進導致標籤效率大幅提升。因此，作為衡量模型參數對資料樣本敏感性的有效工具。我們的程式碼可在 \url{https://github.com/sgchr273/FisherMask} 取得。

##### **Topology-aware Reinforcement Feature Space Reconstruction for Graph Data**
2411.05742v1 by Wangyang Ying, Haoyue Bai, Kunpeng Liu, Yanjie Fu

Feature space is an environment where data points are vectorized to represent
the original dataset. Reconstructing a good feature space is essential to
augment the AI power of data, improve model generalization, and increase the
availability of downstream ML models. Existing literature, such as feature
transformation and feature selection, is labor-intensive (e.g., heavy reliance
on empirical experience) and mostly designed for tabular data. Moreover, these
methods regard data samples as independent, which ignores the unique
topological structure when applied to graph data, thus resulting in a
suboptimal reconstruction feature space. Can we consider the topological
information to automatically reconstruct feature space for graph data without
heavy experiential knowledge? To fill this gap, we leverage topology-aware
reinforcement learning to automate and optimize feature space reconstruction
for graph data. Our approach combines the extraction of core subgraphs to
capture essential structural information with a graph neural network (GNN) to
encode topological features and reduce computing complexity. Then we introduce
three reinforcement agents within a hierarchical structure to systematically
generate meaningful features through an iterative process, effectively
reconstructing the feature space. This framework provides a principled solution
for attributed graph feature space reconstruction. The extensive experiments
demonstrate the effectiveness and efficiency of including topological
awareness.

摘要：特徵空間是一個環境，其中資料點被向量化以表示原始資料集。重建一個良好的特徵空間對於增強資料的 AI 能力、改善模型泛化，以及增加下游 ML 模型的可用性至關重要。現有的文獻，例如特徵轉換和特徵選擇，是勞力密集的（例如，嚴重依賴於經驗經驗），並且主要設計用於表格資料。此外，這些方法將資料樣本視為獨立的，這在應用於圖形資料時會忽略獨特的拓撲結構，從而導致次佳的重建特徵空間。我們能考慮拓撲資訊，在沒有大量經驗知識的情況下，自動為圖形資料重建特徵空間嗎？為了填補這個空白，我們利用具有拓撲感知的強化學習，以自動化和最佳化圖形資料的特徵空間重建。我們的做法結合了核心子圖的萃取，以擷取本質的結構資訊，以及圖形神經網路 (GNN)，以編碼拓撲特徵並降低運算複雜度。然後，我們在一個階層結構中引入三個強化代理，以透過反覆運算的程序系統性地產生有意義的特徵，有效地重建特徵空間。這個架構提供了一個用於屬性圖形特徵空間重建的原則性解決方案。廣泛的實驗證明了納入拓撲感知的有效性和效率。

##### **Aioli: A Unified Optimization Framework for Language Model Data Mixing**
2411.05735v1 by Mayee F. Chen, Michael Y. Hu, Nicholas Lourie, Kyunghyun Cho, Christopher Ré

Language model performance depends on identifying the optimal mixture of data
groups to train on (e.g., law, code, math). Prior work has proposed a diverse
set of methods to efficiently learn mixture proportions, ranging from fitting
regression models over training runs to dynamically updating proportions
throughout training. Surprisingly, we find that no existing method consistently
outperforms a simple stratified sampling baseline in terms of average test
perplexity per group. In this paper, we study the cause of this inconsistency
by unifying existing methods into a standard optimization framework. We show
that all methods set proportions to minimize total loss, subject to a
method-specific mixing law -- an assumption on how loss is a function of
mixture proportions. We find that existing parameterizations of mixing laws can
express the true loss-proportion relationship empirically, but the methods
themselves often set the mixing law parameters inaccurately, resulting in poor
and inconsistent performance. Finally, we leverage the insights from our
framework to derive a new online method named Aioli, which directly estimates
the mixing law parameters throughout training and uses them to dynamically
adjust proportions. Empirically, Aioli outperforms stratified sampling on 6 out
of 6 datasets by an average of 0.28 test perplexity points, whereas existing
methods fail to consistently beat stratified sampling, doing up to 6.9 points
worse. Moreover, in a practical setting where proportions are learned on
shorter runs due to computational constraints, Aioli can dynamically adjust
these proportions over the full training run, consistently improving
performance over existing methods by up to 12.01 test perplexity points.

摘要：<paragraph>語言模型的效能取決於辨識用於訓練的最佳資料群組組合（例如法律、程式碼、數學）。先前的研究已提出各種方法來有效學習混合比例，從擬合訓練執行階段的回歸模型到動態更新訓練期間的比例。令人驚訝的是，我們發現沒有現有方法在平均每組測試困惑度方面始終優於簡單的分層抽樣基準線。在本文中，我們透過將現有方法統一到一個標準的最佳化架構中來研究這種不一致性的原因。我們說明所有方法都會設定比例以最小化總損失，但需遵守特定於方法的混合定律，也就是損失如何成為混合比例的函數的假設。我們發現現有混合定律的參數化可以根據經驗表達真正的損失比例關係，但這些方法本身通常會不準確地設定混合定律參數，導致效能不佳且不一致。最後，我們利用我們架構中的見解，推導出一種名為 Aioli 的新的線上方法，它會直接估計訓練期間的混合定律參數，並使用這些參數動態調整比例。根據經驗，Aioli 在 6 個資料集中有 6 個的表現優於分層抽樣，平均測試困惑度點數為 0.28，而現有方法無法始終優於分層抽樣，表現最多差 6.9 點。此外，在由於計算限制而必須在較短的執行階段學習比例的實際設定中，Aioli 可以動態調整這些比例，在整個訓練執行階段始終改善效能，與現有方法相比，最多可改善 12.01 個測試困惑度點數。</paragraph>

##### **Image2Text2Image: A Novel Framework for Label-Free Evaluation of Image-to-Text Generation with Text-to-Image Diffusion Models**
2411.05706v1 by Jia-Hong Huang, Hongyi Zhu, Yixian Shen, Stevan Rudinac, Evangelos Kanoulas

Evaluating the quality of automatically generated image descriptions is a
complex task that requires metrics capturing various dimensions, such as
grammaticality, coverage, accuracy, and truthfulness. Although human evaluation
provides valuable insights, its cost and time-consuming nature pose
limitations. Existing automated metrics like BLEU, ROUGE, METEOR, and CIDEr
attempt to fill this gap, but they often exhibit weak correlations with human
judgment. To address this challenge, we propose a novel evaluation framework
called Image2Text2Image, which leverages diffusion models, such as Stable
Diffusion or DALL-E, for text-to-image generation. In the Image2Text2Image
framework, an input image is first processed by a selected image captioning
model, chosen for evaluation, to generate a textual description. Using this
generated description, a diffusion model then creates a new image. By comparing
features extracted from the original and generated images, we measure their
similarity using a designated similarity metric. A high similarity score
suggests that the model has produced a faithful textual description, while a
low score highlights discrepancies, revealing potential weaknesses in the
model's performance. Notably, our framework does not rely on human-annotated
reference captions, making it a valuable tool for assessing image captioning
models. Extensive experiments and human evaluations validate the efficacy of
our proposed Image2Text2Image evaluation framework. The code and dataset will
be published to support further research in the community.

摘要：評估自動產生圖片描述的品質是一項複雜的任務，需要指標來捕捉各種面向，例如語法、涵蓋範圍、準確度和真實性。儘管人工評估提供了有價值的見解，但其成本和耗時性質會造成限制。現有的自動化指標，例如 BLEU、ROUGE、METEOR 和 CIDEr，試圖填補這個空白，但它們通常與人工判斷相關性較弱。為了應對這項挑戰，我們提出了一個名為 Image2Text2Image 的新評估框架，它利用擴散模型（例如 Stable Diffusion 或 DALL-E）進行文字到圖片的產生。在 Image2Text2Image 框架中，輸入圖片首先由選定的圖片標註模型（選擇用於評估）處理，以產生文字描述。使用這個產生的描述，擴散模型接著會產生一個新圖片。透過比較從原始圖片和產生圖片中萃取出的特徵，我們使用指定的相似性指標來測量它們的相似性。高相似度分數表示模型產生了忠實的文字描述，而低分數則突顯出差異，揭示模型效能的潛在弱點。值得注意的是，我們的框架不依賴人工標註的參考標題，這使其成為評估圖片標註模型的寶貴工具。廣泛的實驗和人工評估驗證了我們提出的 Image2Text2Image 評估框架的有效性。程式碼和資料集將會發布，以支持社群中的進一步研究。

##### **Asterisk*: Keep it Simple**
2411.05691v1 by Andrew Semenov

This paper describes Asterisk, a compact GPT-based model for generating text
embeddings. The model uses a minimalist architecture with two layers, two
attention heads, and 256 embedding dimensions. By applying knowledge
distillation from larger pretrained models, we explore the trade-offs between
model size and performance while minimizing computational and memory
requirements. The model is primarily evaluated and optimized for classification
tasks, with experimental results showing its moderate performance in zero-shot
classification across various downstream applications. With additional
configuration, the model performance can approach or even surpass that of
larger architectures on specific classification tasks.

摘要：本文描述了 Asterisk，这是一个基于 GPT 的紧凑模型，用于生成文本嵌入。该模型使用具有两层、两个注意力头和 256 个嵌入维度的极简架构。通过应用从更大的预训练模型中提取的知识，我们在模型大小和性能之间探索权衡，同时最大程度地减少计算和内存需求。该模型主要针对分类任务进行评估和优化，实验结果表明其在各种下游应用程序中具有中等零样本分类性能。通过额外的配置，该模型性能可以在特定分类任务上接近或甚至超过更大的架构。

##### **Data-Driven Distributed Common Operational Picture from Heterogeneous Platforms using Multi-Agent Reinforcement Learning**
2411.05683v1 by Indranil Sur, Aswin Raghavan, Abrar Rahman, James Z Hare, Daniel Cassenti, Carl Busart

The integration of unmanned platforms equipped with advanced sensors promises
to enhance situational awareness and mitigate the "fog of war" in military
operations. However, managing the vast influx of data from these platforms
poses a significant challenge for Command and Control (C2) systems. This study
presents a novel multi-agent learning framework to address this challenge. Our
method enables autonomous and secure communication between agents and humans,
which in turn enables real-time formation of an interpretable Common
Operational Picture (COP). Each agent encodes its perceptions and actions into
compact vectors, which are then transmitted, received and decoded to form a COP
encompassing the current state of all agents (friendly and enemy) on the
battlefield. Using Deep Reinforcement Learning (DRL), we jointly train COP
models and agent's action selection policies. We demonstrate resilience to
degraded conditions such as denied GPS and disrupted communications.
Experimental validation is performed in the Starcraft-2 simulation environment
to evaluate the precision of the COPs and robustness of policies. We report
less than 5% error in COPs and policies resilient to various adversarial
conditions. In summary, our contributions include a method for autonomous COP
formation, increased resilience through distributed prediction, and joint
training of COP models and multi-agent RL policies. This research advances
adaptive and resilient C2, facilitating effective control of heterogeneous
unmanned platforms.

摘要：配備先進感測器的無人平台的整合承諾增強情境感知並減輕軍事行動中的「戰爭迷霧」。然而，管理來自這些平台的龐大資料流入對指揮和控制 (C2) 系統構成重大挑戰。本研究提出一個新穎的多代理學習框架來應對這一挑戰。我們的架構允許代理和人類之間的自主和安全通訊，這進而允許即時形成可解釋的共同作戰圖 (COP)。每個代理將其感知和動作編碼成緊湊向量，然後傳輸、接收和解碼以形成一個 COP，涵蓋戰場上所有代理（友方和敵方）的當前狀態。使用深度強化學習 (DRL)，我們共同訓練 COP 模型和代理動作選擇策略。我們展示了對 GPS 拒絕和通訊中斷等惡劣條件的復原力。在 Starcraft-2 模擬環境中執行實驗驗證，以評估 COP 的精度和策略的穩健性。我們報告說 COP 的誤差小於 5%，並且策略對各種對抗條件具有復原力。總之，我們的貢獻包括一種用於自主 COP 形成的方法、通過分佈式預測增加的復原力，以及 COP 模型和多代理 RL 策略的聯合訓練。這項研究推動了適應性和復原性的 C2，促進了對異質無人平台的有效控制。

##### **Tell What You Hear From What You See -- Video to Audio Generation Through Text**
2411.05679v1 by Xiulong Liu, Kun Su, Eli Shlizerman

The content of visual and audio scenes is multi-faceted such that a video can
be paired with various audio and vice-versa. Thereby, in video-to-audio
generation task, it is imperative to introduce steering approaches for
controlling the generated audio. While Video-to-Audio generation is a
well-established generative task, existing methods lack such controllability.
In this work, we propose VATT, a multi-modal generative framework that takes a
video and an optional text prompt as input, and generates audio and optional
textual description of the audio. Such a framework has two advantages: i)
Video-to-Audio generation process can be refined and controlled via text which
complements the context of visual information, and ii) The model can suggest
what audio to generate for the video by generating audio captions. VATT
consists of two key modules: VATT Converter, a LLM that is fine-tuned for
instructions and includes a projection layer that maps video features to the
LLM vector space; and VATT Audio, a transformer that generates audio tokens
from visual frames and from optional text prompt using iterative parallel
decoding. The audio tokens are converted to a waveform by pretrained neural
codec. Experiments show that when VATT is compared to existing video-to-audio
generation methods in objective metrics, it achieves competitive performance
when the audio caption is not provided. When the audio caption is provided as a
prompt, VATT achieves even more refined performance (lowest KLD score of 1.41).
Furthermore, subjective studies show that VATT Audio has been chosen as
preferred generated audio than audio generated by existing methods. VATT
enables controllable video-to-audio generation through text as well as
suggesting text prompts for videos through audio captions, unlocking novel
applications such as text-guided video-to-audio generation and video-to-audio
captioning.

摘要：視覺和音訊場景的內容是多方面的，例如影片可以與各種音訊配對，反之亦然。因此，在影片轉音訊生成任務中，必須引入導引方法來控制生成的音訊。雖然影片轉音訊生成是一項成熟的生成任務，但現有方法缺乏這種可控性。在這項工作中，我們提出 VATT，一個多模態生成框架，它以影片和一個選用的文字提示作為輸入，並生成音訊和音訊的選用文字描述。這種框架有兩個優點：i) 影片轉音訊生成過程可以透過文字進行優化和控制，這補充了視覺資訊的背景，以及 ii) 這個模型可以透過生成音訊標題來建議要為影片生成什麼音訊。VATT 包含兩個關鍵模組：VATT 轉換器，一個經過微調的 LLM，適用於指令，並包含一個將影片特徵對應到 LLM 向量空間的投影層；以及 VATT 音訊，一個轉換器，它使用反覆平行解碼從視覺框架和選用的文字提示生成音訊記號。音訊記號由預訓練的神經編解碼器轉換為波形。實驗顯示，當 VATT 與現有的影片轉音訊生成方法在客觀指標中進行比較時，它在沒有提供音訊標題時，達到了有競爭力的效能。當音訊標題作為提示提供時，VATT 達到了更精緻的效能（最低 KLD 分數為 1.41）。此外，主觀研究顯示，VATT 音訊已被選為比現有方法生成的音訊更佳的生成音訊。VATT 能夠透過文字進行可控的影片轉音訊生成，並透過音訊標題為影片建議文字提示，開啟了新的應用程式，例如文字引導的影片轉音訊生成和影片轉音訊標題。

##### **Improving Molecular Graph Generation with Flow Matching and Optimal Transport**
2411.05676v1 by Xiaoyang Hou, Tian Zhu, Milong Ren, Dongbo Bu, Xin Gao, Chunming Zhang, Shiwei Sun

Generating molecular graphs is crucial in drug design and discovery but
remains challenging due to the complex interdependencies between nodes and
edges. While diffusion models have demonstrated their potentiality in molecular
graph design, they often suffer from unstable training and inefficient
sampling. To enhance generation performance and training stability, we propose
GGFlow, a discrete flow matching generative model incorporating optimal
transport for molecular graphs and it incorporates an edge-augmented graph
transformer to enable the direct communications among chemical bounds.
Additionally, GGFlow introduces a novel goal-guided generation framework to
control the generative trajectory of our model, aiming to design novel
molecular structures with the desired properties. GGFlow demonstrates superior
performance on both unconditional and conditional molecule generation tasks,
outperforming existing baselines and underscoring its effectiveness and
potential for wider application.

摘要：生成分子圖在藥物設計和發現中至關重要，但由於節點和邊緣之間的複雜相互依賴關係，這仍然具有挑戰性。儘管擴散模型已證明了它們在分子圖設計中的潛力，但它們通常會出現訓練不穩定和採樣效率低下的問題。為了增強生成性能和訓練穩定性，我們提出了 GGFlow，這是一種離散流匹配生成模型，它結合了分子圖的最優傳輸，並結合了一個邊緣增強圖形變換器，以實現化學鍵之間的直接通信。此外，GGFlow 引入了一個新穎的目標引導生成框架，以控制我們模型的生成軌跡，旨在設計具有所需屬性的新穎分子結構。GGFlow 在無條件和條件分子生成任務上都表現出優異的性能，優於現有的基準，並強調了其在更廣泛應用中的有效性和潛力。

##### **Unmasking the Limits of Large Language Models: A Systematic Evaluation of Masked Text Processing Ability through MskQA and MskCal**
2411.05665v1 by Fuka Matsuzaki, Haru-Tada Sato

This paper sheds light on the limitations of Large Language Models (LLMs) by
rigorously evaluating their ability to process masked text. We introduce two
novel tasks: MskQA, measuring reasoning on masked question-answering datasets
like RealtimeQA, and MskCal, assessing numerical reasoning on masked arithmetic
problems.Testing GPT-4o and 4o-mini reveals that while LLMs exhibit some
resilience to masked text, their performance is highly contingent on masking
rates and semantic cues. Specifically, "solid masking," where semantic clues
are entirely absent, leads to a significant performance drop compared to
"partial lifting," where some semantic information is retained, indicating
LLMs' reliance on surface-level patterns. Interestingly, GPT-4o consistently
outperforms 4o-mini, particularly in MskCal, demonstrating a greater ability to
handle numerical reasoning with masked text. This underscores the crucial role
of semantic cues in the reasoning process of LLMs. Our study illuminates the
interplay between background knowledge and reasoning ability in masked text
processing, paving the way for a deeper understanding of LLM capabilities and
limitations, and highlighting the need for more robust evaluation methods to
accurately assess their true comprehension abilities.

摘要：這篇論文嚴格評估大型語言模型 (LLM) 處理遮蔽文字的能力，進而闡明其限制。我們引入了兩項新任務：MskQA，用於衡量在遮蔽問答資料集（如 RealtimeQA）上的推理能力；以及 MskCal，用於評估在遮蔽算術問題上的數值推理能力。測試 GPT-4o 和 4o-mini 顯示，儘管 LLM 對遮蔽文字具有一定的韌性，但其效能高度依賴於遮蔽率和語義線索。具體來說，「完全遮蔽」（語義線索完全不存在）會導致效能顯著下降，而「部分解除」（保留一些語義資訊）則不會，這表示 LLM 依賴於表面模式。有趣的是，GPT-4o 的表現始終優於 4o-mini，特別是在 MskCal 中，這顯示出它在處理遮蔽文字數值推理方面的能力更強。這突顯了語義線索在 LLM 推理過程中扮演著至關重要的角色。我們的研究闡明了背景知識和推理能力在遮蔽文字處理中的交互作用，為更深入了解 LLM 的能力和限制鋪路，並強調需要更健全的評估方法來準確評估其真正的理解能力。

##### **The influence of persona and conversational task on social interactions with a LLM-controlled embodied conversational agent**
2411.05653v1 by Leon O. H. Kroczek, Alexander May, Selina Hettenkofer, Andreas Ruider, Bernd Ludwig, Andreas Mühlberger

Large Language Models (LLMs) have demonstrated remarkable capabilities in
conversational tasks. Embodying an LLM as a virtual human allows users to
engage in face-to-face social interactions in Virtual Reality. However, the
influence of person- and task-related factors in social interactions with
LLM-controlled agents remains unclear. In this study, forty-six participants
interacted with a virtual agent whose persona was manipulated as extravert or
introvert in three different conversational tasks (small talk, knowledge test,
convincing). Social-evaluation, emotional experience, and realism were assessed
using ratings. Interactive engagement was measured by quantifying participants'
words and conversational turns. Finally, we measured participants' willingness
to ask the agent for help during the knowledge test. Our findings show that the
extraverted agent was more positively evaluated, elicited a more pleasant
experience and greater engagement, and was assessed as more realistic compared
to the introverted agent. Whereas persona did not affect the tendency to ask
for help, participants were generally more confident in the answer when they
had help of the LLM. Variation of personality traits of LLM-controlled embodied
virtual agents, therefore, affects social-emotional processing and behavior in
virtual interactions. Embodied virtual agents allow the presentation of
naturalistic social encounters in a virtual environment.

摘要：大型語言模型 (LLM) 已在對話任務中展現出非凡的能力。將 LLM 具象化為虛擬人類，讓使用者能在虛擬實境中進行面對面的社交互動。然而，在與 LLM 控制的代理進行社交互動時，人與任務相關因素的影響仍不明確。在這項研究中，四十六位參與者與一位虛擬代理互動，其角色在三種不同的對話任務（閒聊、知識測驗、說服）中被設定為外向或內向。使用評分評估社交評量、情緒體驗和真實性。互動參與度透過量化參與者的字數和對話次數來衡量。最後，我們測量參與者在知識測驗期間向代理尋求幫助的意願。我們的研究結果顯示，與內向的代理相比，外向的代理獲得了更正面的評價，引發了更愉快的體驗和更高的參與度，並被評為更真實。雖然角色不會影響尋求幫助的傾向，但參與者在獲得 LLM 的幫助後通常對答案更有信心。因此，由 LLM 控制的具象虛擬代理的人格特質變化會影響虛擬互動中的社會情緒處理和行為。具象虛擬代理可以在虛擬環境中呈現自然的社交互動。

##### **Evaluating Large Language Model Capability in Vietnamese Fact-Checking Data Generation**
2411.05641v1 by Long Truong To, Hung Tuan Le, Dat Van-Thanh Nguyen, Manh Trong Nguyen, Tri Thien Nguyen, Tin Van Huynh, Kiet Van Nguyen

Large Language Models (LLMs), with gradually improving reading comprehension
and reasoning capabilities, are being applied to a range of complex language
tasks, including the automatic generation of language data for various
purposes. However, research on applying LLMs for automatic data generation in
low-resource languages like Vietnamese is still underdeveloped and lacks
comprehensive evaluation. In this paper, we explore the use of LLMs for
automatic data generation for the Vietnamese fact-checking task, which faces
significant data limitations. Specifically, we focus on fact-checking data
where claims are synthesized from multiple evidence sentences to assess the
information synthesis capabilities of LLMs. We develop an automatic data
construction process using simple prompt techniques on LLMs and explore several
methods to improve the quality of the generated data. To evaluate the quality
of the data generated by LLMs, we conduct both manual quality assessments and
performance evaluations using language models. Experimental results and manual
evaluations illustrate that while the quality of the generated data has
significantly improved through fine-tuning techniques, LLMs still cannot match
the data quality produced by humans.

摘要：大型語言模型 (LLM) 逐漸提升閱讀理解和推理能力，正被應用於各種複雜的語言任務，包括自動產生各種用途的語言資料。然而，針對低資源語言（例如越南語）應用 LLM 自動產生資料的研究仍未成熟，且缺乏全面的評估。在本文中，我們探討 LLM 用於越南語事實查核任務的自動資料產生，此任務面臨嚴重的資料限制。具體來說，我們專注於從多個證據句子中綜合聲明的事實查核資料，以評估 LLM 的資訊綜合能力。我們使用 LLM 上的簡單提示技術開發一個自動資料建構流程，並探討多種方法來提升產生資料的品質。為了評估 LLM 產生的資料品質，我們使用語言模型進行手動品質評估和效能評估。實驗結果和手動評估顯示，雖然透過微調技術顯著提升了產生資料的品質，但 LLM 仍無法比擬人類產生的資料品質。

##### **Assessing Open-Source Large Language Models on Argumentation Mining Subtasks**
2411.05639v1 by Mohammad Yeghaneh Abkenar, Weixing Wang, Hendrik Graupner, Manfred Stede

We explore the capability of four open-sourcelarge language models (LLMs) in
argumentation mining (AM). We conduct experiments on three different corpora;
persuasive essays(PE), argumentative microtexts (AMT) Part 1 and Part 2, based
on two argumentation mining sub-tasks: (i) argumentative discourse units
classifications (ADUC), and (ii) argumentative relation classification (ARC).
This work aims to assess the argumentation capability of open-source LLMs,
including Mistral 7B, Mixtral8x7B, LlamA2 7B and LlamA3 8B in both, zero-shot
and few-shot scenarios. Our analysis contributes to further assessing
computational argumentation with open-source LLMs in future research efforts.

摘要：我們探討了四種開源大型語言模型 (LLM) 在論證挖掘 (AM) 中的能力。我們對三個不同的語料庫進行了實驗；基於兩個論證挖掘子任務的說服性文章 (PE)、論證性微文本 (AMT) 第 1 部分和第 2 部分：(i) 論證性話語單元分類 (ADUC) 和 (ii) 論證關係分類 (ARC)。這項工作的目的是評估開源 LLM 的論證能力，包括 Mistral 7B、Mixtral8x7B、LlamA2 7B 和 LlamA3 8B，無論是在零次嘗試還是少次嘗試的情況下。我們的分析有助於在未來的研究工作中進一步評估使用開源 LLM 進行的計算論證。

##### **Impact of Fake News on Social Media Towards Public Users of Different Age Groups**
2411.05638v1 by Kahlil bin Abdul Hakim, Sathishkumar Veerappampalayam Easwaramoorthy

This study examines how fake news affects social media users across a range
of age groups and how machine learning (ML) and artificial intelligence (AI)
can help reduce the spread of false information. The paper evaluates various
machine learning models for their efficacy in identifying and categorizing fake
news and examines current trends in the spread of fake news, including deepfake
technology. The study assesses four models using a Kaggle dataset: Random
Forest, Support Vector Machine (SVM), Neural Networks, and Logistic Regression.
The results show that SVM and neural networks perform better than other models,
with accuracies of 93.29% and 93.69%, respectively. The study also emphasises
how people in the elder age group diminished capacity for critical analysis of
news content makes them more susceptible to disinformation. Natural language
processing (NLP) and deep learning approaches have the potential to improve the
accuracy of false news detection. Biases in AI and ML models and difficulties
in identifying information generated by AI continue to be major problems in
spite of the developments. The study recommends that datasets be expanded to
encompass a wider range of languages and that detection algorithms be
continuously improved to keep up with the latest advancements in disinformation
tactics. In order to combat fake news and promote an informed and resilient
society, this study emphasizes the value of cooperative efforts between AI
researchers, social media platforms, and governments.

摘要：本研究探討假新聞如何影響各年齡層的社群媒體使用者，以及機器學習 (ML) 與人工智慧 (AI) 如何有助於減少錯誤資訊的散布。本文評估各種機器學習模型在辨識和分類假新聞的效能，並探討假新聞散布的現今趨勢，包括深度造假技術。本研究使用 Kaggle 資料集評估四種模型：隨機森林、支援向量機 (SVM)、神經網路和邏輯迴歸。結果顯示，SVM 和神經網路的表現優於其他模型，準確度分別為 93.29% 和 93.69%。本研究也強調，老年群體對新聞內容的批判性分析能力下降，這使得他們更容易受到錯誤資訊的影響。自然語言處理 (NLP) 和深度學習方法有可能提升偵測假新聞的準確度。儘管有這些進展，AI 和 ML 模型中的偏見和難以辨識 AI 所產生的資訊仍然是主要問題。本研究建議擴充資料集以涵蓋更廣泛的語言，並持續改善偵測演算法，以跟上錯誤資訊策略的最新進展。為了打擊假新聞並促進一個明智且有韌性的社會，本研究強調 AI 研究人員、社群媒體平台和政府之間合作的重要性。

##### **SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection**
2411.05633v1 by Tamara R. Lenhard, Andreas Weinmann, Kai Franke, Tobias Koch

Developing robust drone detection systems is often constrained by the limited
availability of large-scale annotated training data and the high costs
associated with real-world data collection. However, leveraging synthetic data
generated via game engine-based simulations provides a promising and
cost-effective solution to overcome this issue. Therefore, we present
SynDroneVision, a synthetic dataset specifically designed for RGB-based drone
detection in surveillance applications. Featuring diverse backgrounds, lighting
conditions, and drone models, SynDroneVision offers a comprehensive training
foundation for deep learning algorithms. To evaluate the dataset's
effectiveness, we perform a comparative analysis across a selection of recent
YOLO detection models. Our findings demonstrate that SynDroneVision is a
valuable resource for real-world data enrichment, achieving notable
enhancements in model performance and robustness, while significantly reducing
the time and costs of real-world data acquisition. SynDroneVision will be
publicly released upon paper acceptance.

摘要：開發強大的無人機偵測系統往往受到大型標註訓練資料有限的可用性以及與實際資料收集相關的高成本所限制。然而，利用透過遊戲引擎模擬產生的合成資料提供了一個有前途且具成本效益的解決方案來克服這個問題。因此，我們提出了 SynDroneVision，一個專門設計用於監控應用中基於 RGB 的無人機偵測的合成資料集。SynDroneVision 具有多樣化的背景、光照條件和無人機模型，為深度學習演算法提供了全面的訓練基礎。為了評估資料集的有效性，我們在最近的 YOLO 偵測模型中進行了比較分析。我們的研究結果表明，SynDroneVision 是用於實際資料豐富化的一個有價值的資源，在模型效能和穩健性方面取得了顯著的提升，同時顯著減少了實際資料擷取的時間和成本。SynDroneVision 將在論文被接受後公開發布。

##### **Knowledge Distillation Neural Network for Predicting Car-following Behaviour of Human-driven and Autonomous Vehicles**
2411.05618v1 by Ayobami Adewale, Chris Lee, Amnir Hadachi, Nicolly Lima da Silva

As we move towards a mixed-traffic scenario of Autonomous vehicles (AVs) and
Human-driven vehicles (HDVs), understanding the car-following behaviour is
important to improve traffic efficiency and road safety. Using a real-world
trajectory dataset, this study uses descriptive and statistical analysis to
investigate the car-following behaviours of three vehicle pairs: HDV-AV, AV-HDV
and HDV-HDV in mixed traffic. The ANOVA test showed that car-following
behaviours across different vehicle pairs are statistically significant
(p-value < 0.05).
  We also introduce a data-driven Knowledge Distillation Neural Network (KDNN)
model for predicting car-following behaviour in terms of speed. The KDNN model
demonstrates comparable predictive accuracy to its teacher network, a Long
Short-Term Memory (LSTM) network, and outperforms both the standalone student
network, a Multilayer Perceptron (MLP), and traditional physics-based models
like the Gipps model. Notably, the KDNN model better prevents collisions,
measured by minimum Time-to-Collision (TTC), and operates with lower
computational power, making it ideal for AVs or driving simulators requiring
efficient computing.

摘要：隨著我們朝向自動駕駛車輛 (AV) 和人類駕駛車輛 (HDV) 的混合交通場景邁進，了解跟車行為對於提升交通效率和道路安全至關重要。本研究使用真實世界的軌跡資料集，採用描述性和統計分析來探討混合交通中三組車輛組合的跟車行為：HDV-AV、AV-HDV 和 HDV-HDV。ANOVA 檢定顯示，不同車輛組合的跟車行為在統計上具有顯著差異（p 值 < 0.05）。
  我們還引入一個資料驅動的知識蒸餾神經網路 (KDNN) 模型，用於預測跟車行為的速度。KDNN 模型展現出與其教師網路（長短期記憶 (LSTM) 網路）相當的預測準確度，並且優於獨立的學生網路（多層感知器 (MLP)）和傳統的基於物理模型，例如 Gipps 模型。值得注意的是，KDNN 模型能更好地防止碰撞，以最短碰撞時間 (TTC) 來衡量，並且運作時所需的運算能力較低，使其成為需要高效運算的自動駕駛車輛或駕駛模擬器的理想選擇。

##### **Expectation vs. Reality: Towards Verification of Psychological Games**
2411.05599v1 by Marta Kwiatkowska, Gethin Norman, David Parker, Gabriel Santos

Game theory provides an effective way to model strategic interactions among
rational agents. In the context of formal verification, these ideas can be used
to produce guarantees on the correctness of multi-agent systems, with a diverse
range of applications from computer security to autonomous driving.
Psychological games (PGs) were developed as a way to model and analyse agents
with belief-dependent motivations, opening up the possibility to model how
human emotions can influence behaviour. In PGs, players' utilities depend not
only on what actually happens (which strategies players choose to adopt), but
also on what the players had expected to happen (their belief as to the
strategies that would be played). Despite receiving much attention in fields
such as economics and psychology, very little consideration has been given to
their applicability to problems in computer science, nor to practical
algorithms and tool support. In this paper, we start to bridge that gap,
proposing methods to solve PGs and implementing them within PRISM-games, a
formal verification tool for stochastic games. We discuss how to model these
games, highlight specific challenges for their analysis and illustrate the
usefulness of our approach on several case studies, including human behaviour
in traffic scenarios.

摘要：博弈论提供了一种有效的方法来建模理性博弈者之间的策略互动。在形式验证的背景下，这些想法可用于对多博弈者系统的正确性提供保证，其应用范围从计算机安全到自动驾驶。心理博弈 (PG) 被开发为一种建模和分析具有信念依赖动机博弈者的方式，开辟了对人类情绪如何影响行为进行建模的可能性。在 PG 中，博弈者的效用不仅取决于实际发生的事情（博弈者选择采用的策略），还取决于博弈者预期发生的事情（他们对将要进行的策略的信念）。尽管在经济学和心理学等领域受到了广泛关注，但很少有人考虑它们对计算机科学问题的适用性，也没有考虑实际算法和工具支持。在本文中，我们开始弥合这一差距，提出了解决 PG 的方法，并在 PRISM-games 中实现了它们，PRISM-games 是用于随机博弈的形式验证工具。我们讨论如何对这些博弈进行建模，重点介绍了分析它们时的具体挑战，并说明了我们的方法在多个案例研究中的有用性，包括交通场景中的人类行为。

##### **Evaluating and Adapting Large Language Models to Represent Folktales in Low-Resource Languages**
2411.05593v1 by JA Meaney, Beatrice Alex, William Lamb

Folktales are a rich resource of knowledge about the society and culture of a
civilisation. Digital folklore research aims to use automated techniques to
better understand these folktales, and it relies on abstract representations of
the textual data. Although a number of large language models (LLMs) claim to be
able to represent low-resource langauges such as Irish and Gaelic, we present
two classification tasks to explore how useful these representations are, and
three adaptations to improve the performance of these models. We find that
adapting the models to work with longer sequences, and continuing pre-training
on the domain of folktales improves classification performance, although these
findings are tempered by the impressive performance of a baseline SVM with
non-contextual features.

摘要：民間故事是關於社會和文明文化的豐富知識來源。數位民間傳說研究旨在使用自動化技術來更好地理解這些民間故事，並且依賴於文本資料的抽象表示。儘管許多大型語言模型 (LLM) 聲稱能夠表示低資源語言，例如愛爾蘭語和蓋爾語，但我們提出兩個分類任務來探討這些表示有多麼有用，以及三種改編方式來改善這些模型的效能。我們發現，調整模型以使用較長的序列，並繼續在民間故事的領域中進行預訓練，可以改善分類效能，儘管這些發現受到具有非上下文特徵的基準 SVM 的出色效能所影響。

##### **Open-set object detection: towards unified problem formulation and benchmarking**
2411.05564v1 by Hejer Ammar, Nikita Kiselov, Guillaume Lapouge, Romaric Audigier

In real-world applications where confidence is key, like autonomous driving,
the accurate detection and appropriate handling of classes differing from those
used during training are crucial. Despite the proposal of various unknown
object detection approaches, we have observed widespread inconsistencies among
them regarding the datasets, metrics, and scenarios used, alongside a notable
absence of a clear definition for unknown objects, which hampers meaningful
evaluation. To counter these issues, we introduce two benchmarks: a unified
VOC-COCO evaluation, and the new OpenImagesRoad benchmark which provides clear
hierarchical object definition besides new evaluation metrics. Complementing
the benchmark, we exploit recent self-supervised Vision Transformers
performance, to improve pseudo-labeling-based OpenSet Object Detection (OSOD),
through OW-DETR++. State-of-the-art methods are extensively evaluated on the
proposed benchmarks. This study provides a clear problem definition, ensures
consistent evaluations, and draws new conclusions about effectiveness of OSOD
strategies.

摘要：在以信心為關鍵的實際應用中，例如自動駕駛，
準確檢測和適當處理與訓練期間使用的類別不同的類別至關重要。儘管提出了各種未知對象檢測方法，
我們觀察到它們在所使用的數據集、指標和場景方面存在廣泛的不一致，同時還明顯缺乏對未知對象的明確定義，這阻礙了有意義的
評估。為了應對這些問題，我們引入了兩個基準：統一的 VOC-COCO 評估，以及新的 OpenImagesRoad 基準，除了新的評估指標外，還提供了清晰的分層對象定義。補充
基準，我們利用最近的自監督視覺Transformer
性能，通過 OW-DETR++ 改進基於偽標籤的開放集對象檢測 (OSOD)。最先進的方法在
提出的基準上得到了廣泛評估。本研究提供了一個明確的問題定義，確保
一致的評估，並對 OSOD
策略的有效性得出新的結論。

##### **Training objective drives the consistency of representational similarity across datasets**
2411.05561v1 by Laure Ciernik, Lorenz Linhardt, Marco Morik, Jonas Dippel, Simon Kornblith, Lukas Muttenthaler

The Platonic Representation Hypothesis claims that recent foundation models
are converging to a shared representation space as a function of their
downstream task performance, irrespective of the objectives and data modalities
used to train these models. Representational similarity is generally measured
for individual datasets and is not necessarily consistent across datasets.
Thus, one may wonder whether this convergence of model representations is
confounded by the datasets commonly used in machine learning. Here, we propose
a systematic way to measure how representational similarity between models
varies with the set of stimuli used to construct the representations. We find
that the objective function is the most crucial factor in determining the
consistency of representational similarities across datasets. Specifically,
self-supervised vision models learn representations whose relative pairwise
similarities generalize better from one dataset to another compared to those of
image classification or image-text models. Moreover, the correspondence between
representational similarities and the models' task behavior is
dataset-dependent, being most strongly pronounced for single-domain datasets.
Our work provides a framework for systematically measuring similarities of
model representations across datasets and linking those similarities to
differences in task behavior.

摘要：柏拉圖表徵假說聲稱，最近的基礎模型正在收斂到一個共用表徵空間，作為其下游任務表現的函數，而與用於訓練這些模型的目標和資料模式無關。表徵相似性通常針對個別資料集進行測量，並不一定在所有資料集之間保持一致。因此，人們可能會懷疑模型表徵的這種收斂是否受到機器學習中常用的資料集的混淆。在這裡，我們提出了一種系統性的方法來測量模型之間的表徵相似性如何隨用於建構表徵的刺激集而變化。我們發現，目標函數是決定表徵相似性在不同資料集之間一致性的最重要因素。具體來說，自監督視覺模型學習的表徵具有相對成對相似性，與影像分類或影像文字模型相比，這些相似性從一個資料集到另一個資料集的概化性更好。此外，表徵相似性與模型的任務行為之間的對應關係取決於資料集，對於單一領域資料集來說，這種對應關係最為顯著。我們的研究提供了一個系統性測量模型表徵在不同資料集之間相似性的框架，並將這些相似性與任務行為的差異聯繫起來。

##### **Assessing the Answerability of Queries in Retrieval-Augmented Code Generation**
2411.05547v1 by Geonmin Kim, Jaeyeon Kim, Hancheol Park, Wooksu Shin, Tae-Ho Kim

Thanks to unprecedented language understanding and generation capabilities of
large language model (LLM), Retrieval-augmented Code Generation (RaCG) has
recently been widely utilized among software developers. While this has
increased productivity, there are still frequent instances of incorrect codes
being provided. In particular, there are cases where plausible yet incorrect
codes are generated for queries from users that cannot be answered with the
given queries and API descriptions. This study proposes a task for evaluating
answerability, which assesses whether valid answers can be generated based on
users' queries and retrieved APIs in RaCG. Additionally, we build a benchmark
dataset called Retrieval-augmented Code Generability Evaluation (RaCGEval) to
evaluate the performance of models performing this task. Experimental results
show that this task remains at a very challenging level, with baseline models
exhibiting a low performance of 46.7%. Furthermore, this study discusses
methods that could significantly improve performance.

摘要：由於大型語言模型 (LLM) 前所未有的語言理解和生成能力，檢索增強式程式碼生成 (RaCG) 近來在軟體開發人員之間廣泛使用。雖然這提高了生產力，但仍經常提供不正確的程式碼。特別是，對於無法使用給定的查詢和 API 描述來回答的使用者查詢，可能會產生看似合理但實際上不正確的程式碼。本研究提出了一項評估可回答性的任務，該任務評估是否可以根據使用者的查詢和 RaCG 中檢索的 API 產生有效的答案。此外，我們建立了一個名為檢索增強式程式碼可生成性評估 (RaCGEval) 的基準資料集，以評估執行此任務的模型效能。實驗結果顯示，此任務仍處於非常具有挑戰性的層級，基準模型表現出 46.7% 的低效能。此外，本研究探討了可以顯著提升效能的方法。

##### **CRepair: CVAE-based Automatic Vulnerability Repair Technology**
2411.05540v1 by Penghui Liu, Yingzhou Bi, Jiangtao Huang, Xinxin Jiang, Lianmei Wang

Software vulnerabilities are flaws in computer software systems that pose
significant threats to the integrity, security, and reliability of modern
software and its application data. These vulnerabilities can lead to
substantial economic losses across various industries. Manual vulnerability
repair is not only time-consuming but also prone to errors. To address the
challenges of vulnerability repair, researchers have proposed various
solutions, with learning-based automatic vulnerability repair techniques
gaining widespread attention. However, existing methods often focus on learning
more vulnerability data to improve repair outcomes, while neglecting the
diverse characteristics of vulnerable code, and suffer from imprecise
vulnerability localization.To address these shortcomings, this paper proposes
CRepair, a CVAE-based automatic vulnerability repair technology aimed at fixing
security vulnerabilities in system code. We first preprocess the vulnerability
data using a prompt-based method to serve as input to the model. Then, we apply
causal inference techniques to map the vulnerability feature data to
probability distributions. By employing multi-sample feature fusion, we capture
diverse vulnerability feature information. Finally, conditional control is used
to guide the model in repairing the vulnerabilities.Experimental results
demonstrate that the proposed method significantly outperforms other benchmark
models, achieving a perfect repair rate of 52%. The effectiveness of the
approach is validated from multiple perspectives, advancing AI-driven code
vulnerability repair and showing promising applications.

摘要：軟體漏洞是電腦軟體系統中的缺陷，對現代軟體及其應用程式資料的完整性、安全性與可靠性構成重大威脅。這些漏洞可能導致各產業產生龐大的經濟損失。手動修復漏洞不僅耗時，還容易出錯。為了應對漏洞修復的挑戰，研究人員提出了各種解決方案，其中基於學習的自動漏洞修復技術獲得廣泛關注。然而，現有方法通常專注於學習更多漏洞資料以改善修復結果，同時忽略了易受攻擊程式碼的多樣化特性，並遭受不精確的漏洞定位。為了解決這些缺點，本文提出了 CRepair，一種基於 CVAE 的自動漏洞修復技術，旨在修復系統程式碼中的安全漏洞。我們首先使用基於提示的方法預處理漏洞資料，作為模型的輸入。然後，我們應用因果推論技術將漏洞特徵資料對應到機率分佈。透過採用多樣本特徵融合，我們擷取多樣化的漏洞特徵資訊。最後，使用條件控制來引導模型修復漏洞。實驗結果證明，所提出的方法明顯優於其他基準模型，達到 52% 的完美修復率。從多個角度驗證了該方法的有效性，推動了 AI 驅動的程式碼漏洞修復，並展示了有前景的應用。

##### **How Good is Your Wikipedia?**
2411.05527v1 by Kushal Tatariya, Artur Kulmizev, Wessel Poelman, Esther Ploeger, Marcel Bollmann, Johannes Bjerva, Jiaming Luo, Heather Lent, Miryam de Lhoneux

Wikipedia's perceived high quality and broad language coverage have
established it as a fundamental resource in multilingual NLP. In the context of
low-resource languages, however, these quality assumptions are increasingly
being scrutinised. This paper critically examines the data quality of Wikipedia
in a non-English setting by subjecting it to various quality filtering
techniques, revealing widespread issues such as a high percentage of one-line
articles and duplicate articles. We evaluate the downstream impact of quality
filtering on Wikipedia and find that data quality pruning is an effective means
for resource-efficient training without hurting performance, especially for
low-resource languages. Moreover, we advocate for a shift in perspective from
seeking a general definition of data quality towards a more language- and
task-specific one. Ultimately, we aim for this study to serve as a guide to
using Wikipedia for pretraining in a multilingual setting.

摘要：維基百科被認為具有高品質和廣泛的語言涵蓋範圍，這使其成為多語言自然語言處理中的基本資源。然而，在資源匱乏的語言背景下，這些品質假設正受到越來越多的審查。本文通過對維基百科進行各種品質過濾技術，批判性地檢視了其在非英語環境中的資料品質，揭示了普遍存在的問題，例如單行文章和重複文章的比例很高。我們評估了品質過濾對維基百科的後續影響，發現資料品質修剪是一種有效的手段，可以在不損害效能的情況下進行資源有效率的訓練，特別是對於資源匱乏的語言。此外，我們主張從尋求資料品質的通用定義轉向更具語言和任務特性的定義。最終，我們的目標是讓這項研究成為在多語言環境中使用維基百科進行預訓練的指南。

##### **SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**
2411.05521v1 by Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, Jonathan Fuerst

Electronic health records (EHRs) are stored in various database systems with
different database models on heterogeneous storage architectures, such as
relational databases, document stores, or graph databases. These different
database models have a big impact on query complexity and performance. While
this has been a known fact in database research, its implications for the
growing number of Text-to-Query systems have surprisingly not been investigated
so far. In this paper, we present SM3-Text-to-Query, the first multi-model
medical Text-to-Query benchmark based on synthetic patient data from Synthea,
following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology
covering medical terminology. SM3-Text-to-Query provides data representations
for relational databases (PostgreSQL), document stores (MongoDB), and graph
databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four
popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically
and manually develop 408 template questions, which we augment to construct a
benchmark of 10K diverse natural language question/query pairs for these four
query languages (40K pairs overall). On our dataset, we evaluate several common
in-context-learning (ICL) approaches for a set of representative closed and
open-source LLMs. Our evaluation sheds light on the trade-offs between database
models and query languages for different ICL strategies and LLMs. Last,
SM3-Text-to-Query is easily extendable to additional query languages or real,
standard-based patient databases.

摘要：電子健康紀錄 (EHR) 儲存在各種資料庫系統中，這些系統在異質儲存架構上具有不同的資料庫模型，例如關聯式資料庫、文件儲存或圖形資料庫。這些不同的資料庫模型對查詢複雜度和效能有很大的影響。雖然這在資料庫研究中已經是眾所周知的事實，但令人驚訝的是，它對日益增加的文字轉查詢系統的影響迄今尚未得到調查。在本文中，我們提出 SM3-Text-to-Query，這是第一個基於來自 Synthea 的合成患者資料的多模型醫療文字轉查詢基準，遵循 SNOMED-CT 分類法——一種廣泛使用的涵蓋醫學術語的知識圖譜本體。SM3-Text-to-Query 提供了關聯式資料庫 (PostgreSQL)、文件儲存 (MongoDB) 和圖形資料庫 (Neo4j 和 GraphDB (RDF)) 的資料表示，允許跨四種流行查詢語言（即 SQL、MQL、Cypher 和 SPARQL）進行評估。我們系統且手動開發了 408 個範本問題，我們擴充這些問題以構建一個基準，其中包含 10K 個針對這四種查詢語言的多樣化自然語言問題/查詢對（總共 40K 對）。在我們的資料集上，我們評估了幾種常見的代表性閉源和開源 LLM 的情境學習 (ICL) 方法。我們的評估揭示了不同 ICL 策略和 LLM 的資料庫模型和查詢語言之間的取捨。最後，SM3-Text-to-Query 可以輕鬆擴展到其他查詢語言或真實的基於標準的患者資料庫。

##### **Towards Scalable Foundation Models for Digital Dermatology**
2411.05514v1 by Fabian Gröger, Philippe Gottfrois, Ludovic Amruthalingam, Alvaro Gonzalez-Jimenez, Simone Lionetti, Luis R. Soenksen-Martinez, Alexander A. Navarini, Marc Pouly

The growing demand for accurate and equitable AI models in digital
dermatology faces a significant challenge: the lack of diverse, high-quality
labeled data. In this work, we investigate the potential of domain-specific
foundation models for dermatology in addressing this challenge. We utilize
self-supervised learning (SSL) techniques to pre-train models on a dataset of
over 240,000 dermatological images from public and private collections. Our
study considers several SSL methods and compares the resulting foundation
models against domain-agnostic models like those pre-trained on ImageNet and
state-of-the-art models such as MONET across 12 downstream tasks. Unlike
previous research, we emphasize the development of smaller models that are more
suitable for resource-limited clinical settings, facilitating easier adaptation
to a broad range of use cases. Results show that models pre-trained in this
work not only outperform general-purpose models but also approach the
performance of models 50 times larger on clinically relevant diagnostic tasks.
To promote further research in this direction, we publicly release both the
training code and the foundation models, which can benefit clinicians in
dermatological applications.

摘要：數位皮膚科對精準且公平的 AI 模型需求日益增加，但面臨一項重大挑戰：缺乏多元且高品質的標記資料。在這項研究中，我們探討特定領域的基礎模型在皮膚科中解決此挑戰的可能性。我們利用自監督學習 (SSL) 技術在包含超過 24 萬張來自公有和私有資料庫的皮膚科影像的資料集上預先訓練模型。我們的研究考量了多種 SSL 方法，並將產生的基礎模型與不受領域限制的模型（例如在 ImageNet 上預先訓練的模型）以及最先進的模型（例如 MONET）在 12 個下游任務中進行比較。與先前的研究不同，我們強調開發更適合資源有限的臨床環境的小型模型，以利於更輕鬆地適應廣泛的用例。結果顯示，在這項研究中預先訓練的模型不僅優於通用模型，而且在臨床上相關的診斷任務中，其效能也接近大 50 倍的模型。為了促進此方向的進一步研究，我們公開發布訓練程式碼和基礎模型，這些模型可讓皮膚科應用中的臨床醫生受益。

##### **An Early FIRST Reproduction and Improvements to Single-Token Decoding for Fast Listwise Reranking**
2411.05508v1 by Zijian Chen, Ronak Pradeep, Jimmy Lin

Recent advances have demonstrated that large language models (LLMs) excel as
listwise rerankers, but their high computational demands remain a barrier to
widespread adoption. Further, the traditional language modeling (LM) objective
is not ideally suited for reranking tasks. FIRST is a novel approach that
addresses these challenges by integrating a learning-to-rank objective and
leveraging the logits of only the first generated token, thereby significantly
reducing inference latency compared to traditional LLM rerankers. In this
study, we extend the evaluation of FIRST to the TREC Deep Learning datasets
(DL19-22), validating its robustness across diverse domains. We investigate the
influence of different first-stage retrievers on FIRST rerankers, observing
diminishing returns and patterns consistent with traditional LLM rerankers.
Through applying the FIRST objective to a broader range of backbone models, we
achieve effectiveness surpassing the original implementation. Our experiments
confirm that fast reranking with single-token logits does not compromise
out-of-domain reranking quality. To better quantify the computational savings
in the original study, we measure and compare latency to find a 21%-42% gain
across various models and benchmarks. Moreover, while LM training implicitly
improves zero-shot single-token reranking, our experiments also raise questions
about whether LM pre-training may hinder subsequent fine-tuning with the FIRST
objective. These findings pave the way for more efficient and effective
listwise reranking in future applications.

摘要：<paragraph>最近的進展表明，大型語言模型 (LLM) 在列表式重新排序方面表現出色，但它們的高運算需求仍然是廣泛採用的障礙。此外，傳統的語言建模 (LM) 目標並不適合重新排序任務。FIRST 是一項新穎的方法，它通過整合學習排名目標並僅利用第一個生成符號的 logit 來解決這些挑戰，從而與傳統的 LLM 重新排序器相比顯著降低了推理延遲。在本研究中，我們將 FIRST 的評估擴展到 TREC 深度學習數據集 (DL19-22)，驗證了它在不同領域的穩健性。我們研究了不同第一階段檢索器對 FIRST 重新排序器的影響，觀察到與傳統 LLM 重新排序器一致的遞減回報和模式。通過將 FIRST 目標應用於更廣泛的主幹模型，我們實現了超越原始實現的有效性。我們的實驗證實，使用單個符號 logit 進行快速重新排序並不會影響域外重新排序的品質。為了更好地量化原始研究中的計算節省，我們測量並比較延遲時間，發現各種模型和基準的增益為 21%-42%。此外，雖然 LM 訓練隱含地改進了零次學習單符號重新排序，但我們的實驗也提出了疑問，即 LM 預訓練是否會阻礙後續使用 FIRST 目標進行微調。這些發現為未來應用中更有效率和有效的列表式重新排序鋪平了道路。</paragraph>

##### **LBPE: Long-token-first Tokenization to Improve Large Language Models**
2411.05504v1 by Haoran Lian, Yizhe Xiong, Zijia Lin, Jianwei Niu, Shasha Mo, Hui Chen, Peng Liu, Guiguang Ding

The prevalent use of Byte Pair Encoding (BPE) in Large Language Models (LLMs)
facilitates robust handling of subword units and avoids issues of
out-of-vocabulary words. Despite its success, a critical challenge persists:
long tokens, rich in semantic information, have fewer occurrences in tokenized
datasets compared to short tokens, which can result in imbalanced learning
issue across different tokens. To address that, we propose LBPE, which
prioritizes long tokens during the encoding process. LBPE generates tokens
according to their reverse ranks of token length rather than their ranks in the
vocabulary, granting longer tokens higher priority during the encoding process.
Consequently, LBPE smooths the frequency differences between short and long
tokens, and thus mitigates the learning imbalance. Extensive experiments across
diverse language modeling tasks demonstrate that LBPE consistently outperforms
the original BPE, well demonstrating its effectiveness.

摘要：在大型語言模型 (LLM) 中普遍使用位元組對編碼 (BPE)，
有助於穩健處理次單字元單位，並避免詞彙外單字的問題。儘管它很成功，但仍存在一個嚴峻的挑戰：
語義資訊豐富的長標記在標記化資料集中的出現次數比短標記少，這可能會導致不同標記之間的學習不平衡
問題。為了解決這個問題，我們提出了 LBPE，它在編碼過程中優先考慮長標記。LBPE 根據標記長度的反向排名而不是它們在詞彙中的排名來產生標記，在編碼過程中賦予較長的標記較高的優先順序。因此，LBPE 平滑了短標記和長標記之間的頻率差異，從而減輕了學習不平衡。在各種語言建模任務中的廣泛實驗表明，LBPE 持續優於原始 BPE，充分證明了它的有效性。

##### **KyrgyzNLP: Challenges, Progress, and Future**
2411.05503v1 by Anton Alekseev, Timur Turatali

Large language models (LLMs) have excelled in numerous benchmarks, advancing
AI applications in both linguistic and non-linguistic tasks. However, this has
primarily benefited well-resourced languages, leaving less-resourced ones
(LRLs) at a disadvantage. In this paper, we highlight the current state of the
NLP field in the specific LRL: kyrgyz tili.
  Human evaluation, including annotated datasets created by native speakers,
remains an irreplaceable component of reliable NLP performance, especially for
LRLs where automatic evaluations can fall short. In recent assessments of the
resources for Turkic languages, Kyrgyz is labeled with the status 'Scraping
By', a severely under-resourced language spoken by millions. This is concerning
given the growing importance of the language, not only in Kyrgyzstan but also
among diaspora communities where it holds no official status.
  We review prior efforts in the field, noting that many of the publicly
available resources have only recently been developed, with few exceptions
beyond dictionaries (the processed data used for the analysis is presented at
https://kyrgyznlp.github.io/). While recent papers have made some headway, much
more remains to be done. Despite interest and support from both business and
government sectors in the Kyrgyz Republic, the situation for Kyrgyz language
resources remains challenging. We stress the importance of community-driven
efforts to build these resources, ensuring the future advancement
sustainability. We then share our view of the most pressing challenges in
Kyrgyz NLP. Finally, we propose a roadmap for future development in terms of
research topics and language resources.

摘要：大型語言模型 (LLM) 在眾多基準測試中表現優異，在語言和非語言任務中推動 AI 應用。然而，這主要使資源豐富的語言受益，讓資源較少的語言 (LRL) 處於劣勢。在本文中，我們重點介紹特定 LRL：吉爾吉斯語中的 NLP 領域現狀。
  人類評估（包括由母語人士建立的註釋資料集）仍然是可靠 NLP 效能不可或缺的組成部分，特別是對於自動評估可能不足的 LRL。在最近對突厥語資源的評估中，吉爾吉斯語被標記為「勉強應付」狀態，這是一種由數百萬人使用的嚴重缺乏資源的語言。這令人擔憂，因為該語言不僅在吉爾吉斯斯坦，而且在沒有官方地位的僑民社區中都越來越重要。
  我們回顧了該領域先前的努力，並注意到許多公開可用的資源直到最近才開發出來，除了字典之外，幾乎沒有例外（用於分析的處理資料顯示在 https://kyrgyznlp.github.io/）。雖然最近的論文取得了一些進展，但仍有許多工作有待完成。儘管吉爾吉斯共和國的企業和政府部門都感興趣並提供支援，但吉爾吉斯語資源的狀況仍然具有挑戰性。我們強調了由社區推動的努力對於建立這些資源的重要性，確保未來的進步具有可持續性。然後，我們分享我們對吉爾吉斯語 NLP 中最緊迫挑戰的看法。最後，我們在研究主題和語言資源方面提出了未來發展的路線圖。

##### **EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**
2411.05479v1 by Abdoul Nasser Hassane Amadou, Anas Motii, Saida Elouardi, EL Houcine Bergou

Underground forums serve as hubs for cybercriminal activities, offering a
space for anonymity and evasion of conventional online oversight. In these
hidden communities, malicious actors collaborate to exchange illicit knowledge,
tools, and tactics, driving a range of cyber threats from hacking techniques to
the sale of stolen data, malware, and zero-day exploits. Identifying the key
instigators (i.e., key hackers), behind these operations is essential but
remains a complex challenge. This paper presents a novel method called EUREKHA
(Enhancing User Representation for Key Hacker Identification in Underground
Forums), designed to identify these key hackers by modeling each user as a
textual sequence. This sequence is processed through a large language model
(LLM) for domain-specific adaptation, with LLMs acting as feature extractors.
These extracted features are then fed into a Graph Neural Network (GNN) to
model user structural relationships, significantly improving identification
accuracy. Furthermore, we employ BERTopic (Bidirectional Encoder
Representations from Transformers Topic Modeling) to extract personalized
topics from user-generated content, enabling multiple textual representations
per user and optimizing the selection of the most representative sequence. Our
study demonstrates that fine-tuned LLMs outperform state-of-the-art methods in
identifying key hackers. Additionally, when combined with GNNs, our model
achieves significant improvements, resulting in approximately 6% and 10%
increases in accuracy and F1-score, respectively, over existing methods.
EUREKHA was tested on the Hack-Forums dataset, and we provide open-source
access to our code.

摘要：<paragraph>地下論壇是網路犯罪活動的樞紐，提供匿名和規避傳統網路監督的空間。在這些隱藏的社群中，惡意行為者合作交換非法知識、工具和策略，推動從駭客技術到銷售竊取資料、惡意軟體和零時差漏洞的各種網路威脅。找出這些行動背後的關鍵煽動者（即關鍵駭客）至關重要，但仍然是一個複雜的挑戰。本文提出了一種稱為 EUREKHA（增強使用者表徵以識別地下論壇中的關鍵駭客）的新方法，旨在透過將每個使用者建模為文字序列來識別這些關鍵駭客。此序列透過大型語言模型（LLM）處理以進行特定領域的適應，其中 LLM 作為特徵萃取器。然後將這些萃取的特徵輸入圖神經網路（GNN）以建模使用者結構關係，大幅提升識別準確度。此外，我們採用 BERTopic（來自 Transformer 主題建模的雙向編碼器表徵）從使用者產生的內容中萃取個人化主題，為每個使用者啟用多個文字表徵，並最佳化最具代表性序列的選擇。我們的研究表明，微調後的 LLM 在識別關鍵駭客方面優於最先進的方法。此外，當與 GNN 結合使用時，我們的模型獲得顯著的提升，與現有方法相比，準確度和 F1 分數分別提高了約 6% 和 10%。EUREKHA 已在 Hack-Forums 資料集上進行測試，我們提供開源方式存取我們的程式碼。</paragraph>

##### **Supporting Automated Fact-checking across Topics: Similarity-driven Gradual Topic Learning for Claim Detection**
2411.05460v1 by Amani S. Abumansour, Arkaitz Zubiaga

Selecting check-worthy claims for fact-checking is considered a crucial part
of expediting the fact-checking process by filtering out and ranking the
check-worthy claims for being validated among the impressive amount of claims
could be found online. The check-worthy claim detection task, however, becomes
more challenging when the model needs to deal with new topics that differ from
those seen earlier. In this study, we propose a domain-adaptation framework for
check-worthy claims detection across topics for the Arabic language to adopt a
new topic, mimicking a real-life scenario of the daily emergence of events
worldwide. We propose the Gradual Topic Learning (GTL) model, which builds an
ability to learning gradually and emphasizes the check-worthy claims for the
target topic during several stages of the learning process. In addition, we
introduce the Similarity-driven Gradual Topic Learning (SGTL) model that
synthesizes gradual learning with a similarity-based strategy for the target
topic. Our experiments demonstrate the effectiveness of our proposed model,
showing an overall tendency for improving performance over the state-of-the-art
baseline across 11 out of the 14 topics under study.

摘要：選擇值得查核的斷言進行查核被認為是加快查核流程的關鍵部分，方法是過濾並對值得查核的斷言進行排名，以便在網路上發現的大量斷言中進行驗證。然而，當模型需要處理與先前所見不同的新主題時，值得查核的斷言偵測任務便會變得更具挑戰性。在本研究中，我們提出了一個針對阿拉伯語跨主題值得查核的斷言偵測的領域適應框架，以採用新的主題，模擬全球事件每日出現的真實情況。我們提出了漸進式主題學習 (GTL) 模型，該模型建立了逐漸學習的能力，並在學習過程的幾個階段強調目標主題的值得查核斷言。此外，我們引入了相似性驅動漸進式主題學習 (SGTL) 模型，該模型將漸進式學習與基於相似性的策略結合起來，以用於目標主題。我們的實驗證明了我們提出的模型的有效性，顯示出在 14 個研究主題中有 11 個主題的效能優於現有技術基線的整體趨勢。

##### **WorkflowLLM: Enhancing Workflow Orchestration Capability of Large Language Models**
2411.05451v1 by Shengda Fan, Xin Cong, Yuepeng Fu, Zhong Zhang, Shuyan Zhang, Yuanwei Liu, Yesai Wu, Yankai Lin, Zhiyuan Liu, Maosong Sun

Recent advancements in large language models (LLMs) have driven a
revolutionary paradigm shift in process automation from Robotic Process
Automation to Agentic Process Automation by automating the workflow
orchestration procedure based on LLMs. However, existing LLMs (even the
advanced OpenAI GPT-4o) are confined to achieving satisfactory capability in
workflow orchestration. To address this limitation, we present WorkflowLLM, a
data-centric framework elaborately designed to enhance the capability of LLMs
in workflow orchestration. It first constructs a large-scale fine-tuning
dataset WorkflowBench with 106,763 samples, covering 1,503 APIs from 83
applications across 28 categories. Specifically, the construction process can
be divided into three phases: (1) Data Collection: we collect real-world
workflow data from Apple Shortcuts and RoutineHub, transcribing them into
Python-style code. We further equip them with generated hierarchical thought
via ChatGPT. (2) Query Expansion: we prompt ChatGPT to generate more task
queries to enrich the diversity and complexity of workflows. (3) Workflow
Generation: we leverage an annotator model trained on collected data to
generate workflows for synthesized queries. Finally, we merge the synthetic
samples that pass quality confirmation with the collected samples to obtain the
WorkflowBench. Based on WorkflowBench, we fine-tune Llama-3.1-8B to obtain
WorkflowLlama. Our experiments show that WorkflowLlama demonstrates a strong
capacity to orchestrate complex workflows, while also achieving notable
generalization performance on previously unseen APIs. Additionally,
WorkflowBench exhibits robust zero-shot generalization capabilities on an
out-of-distribution task planning dataset, T-Eval. Our data and code are
available at https://github.com/OpenBMB/WorkflowLLM.

摘要：大型語言模型 (LLM) 的最新進展推動了流程自動化的革命性典範轉移，從機器人流程自動化到代理流程自動化，透過基於 LLM 自動化工作流程編排程序。然而，現有的 LLM（甚至進階的 OpenAI GPT-4o）僅限於在工作流程編排中實現令人滿意的能力。為了解決這個限制，我們提出了 WorkflowLLM，一個精心設計的以數據為中心的框架，用於增強 LLM 在工作流程編排中的能力。它首先構建一個包含 106,763 個範例的大規模微調資料集 WorkflowBench，涵蓋來自 28 個類別的 83 個應用程式的 1,503 個 API。具體來說，構建過程可分為三個階段：(1) 數據收集：我們從 Apple Shortcuts 和 RoutineHub 收集真實世界的流程數據，並將它們轉錄成 Python 風格的程式碼。我們進一步透過 ChatGPT 生成的階層式思考來裝備它們。(2) 查詢擴充：我們提示 ChatGPT 產生更多任務查詢，以豐富工作流程的多樣性和複雜性。(3) 工作流程產生：我們利用在收集的數據上訓練的註解器模型，為合成的查詢產生工作流程。最後，我們將通過品質確認的合成範例與收集的範例合併，以取得 WorkflowBench。根據 WorkflowBench，我們微調 Llama-3.1-8B 以取得 WorkflowLlama。我們的實驗顯示，WorkflowLlama 展示出編排複雜工作流程的強大能力，同時在以前未見的 API 上實現顯著的泛化效能。此外，WorkflowBench 在 out-of-distribution 任務規劃資料集 T-Eval 上展現了強健的零次學習泛化能力。我們的數據和程式碼可在 https://github.com/OpenBMB/WorkflowLLM 取得。

##### **ICE-T: A Multi-Faceted Concept for Teaching Machine Learning**
2411.05424v1 by Hendrik Krone, Pierre Haritz, Thomas Liebig

The topics of Artificial intelligence (AI) and especially Machine Learning
(ML) are increasingly making their way into educational curricula. To
facilitate the access for students, a variety of platforms, visual tools, and
digital games are already being used to introduce ML concepts and strengthen
the understanding of how AI works. We take a look at didactic principles that
are employed for teaching computer science, define criteria, and, based on
those, evaluate a selection of prominent existing platforms, tools, and games.
Additionally, we criticize the approach of portraying ML mostly as a black-box
and the resulting missing focus on creating an understanding of data,
algorithms, and models that come with it. To tackle this issue, we present a
concept that covers intermodal transfer, computational and explanatory
thinking, ICE-T, as an extension of known didactic principles. With our
multi-faceted concept, we believe that planners of learning units, creators of
learning platforms and educators can improve on teaching ML.

摘要：人工智能 (AI) 和機器學習 (ML) 的主題正逐漸進入教育課程中。為了方便學生取得這些資訊，已經開始使用各種平台、視覺工具和數位遊戲來介紹 ML 概念，並加強對 AI 運作方式的理解。我們探討了用於教授電腦科學的教學原則、定義標準，並根據這些標準評估一系列現有的知名平台、工具和遊戲。此外，我們批評將 ML 描繪成一個黑盒子的方法，以及由此產生的對建立對資料、演算法和隨之而來的模型的理解的關注不足。為了解決這個問題，我們提出了涵蓋跨模態轉移、運算和說明性思考 (ICE-T) 的概念，作為已知教學原則的延伸。透過我們多面向的概念，我們相信學習單元的規劃者、學習平台的創建者和教育工作者可以改進 ML 教學。

##### **VISTA: Visual Integrated System for Tailored Automation in Math Problem Generation Using LLM**
2411.05423v1 by Jeongwoo Lee, Kwangsuk Park, Jihyeon Park

Generating accurate and consistent visual aids is a critical challenge in
mathematics education, where visual representations like geometric shapes and
functions play a pivotal role in enhancing student comprehension. This paper
introduces a novel multi-agent framework that leverages Large Language Models
(LLMs) to automate the creation of complex mathematical visualizations
alongside coherent problem text. Our approach not only simplifies the
generation of precise visual aids but also aligns these aids with the problem's
core mathematical concepts, improving both problem creation and assessment. By
integrating multiple agents, each responsible for distinct tasks such as
numeric calculation, geometry validation, and visualization, our system
delivers mathematically accurate and contextually relevant problems with visual
aids. Evaluation across Geometry and Function problem types shows that our
method significantly outperforms basic LLMs in terms of text coherence,
consistency, relevance and similarity, while maintaining the essential
geometrical and functional integrity of the original problems. Although some
challenges remain in ensuring consistent visual outputs, our framework
demonstrates the immense potential of LLMs in transforming the way educators
generate and utilize visual aids in math education.

摘要：在數學教育中，產生準確且一致的視覺輔助工具是一項重要的挑戰，其中視覺表示（例如幾何形狀和函數）在增強學生理解力方面發揮著至關重要的作用。本文介紹了一個新穎的多代理框架，它利用大型語言模型 (LLM) 來自動化複雜數學視覺化的創建，以及連貫的問題文本。我們的做法不僅簡化了精確視覺輔助工具的生成，而且還將這些輔助工具與問題的核心數學概念保持一致，從而改進了問題的創建和評估。通過集成多個代理，每個代理負責不同的任務，例如數字計算、幾何驗證和視覺化，我們的系統提供了數學上準確且在上下文上相關的問題，並配有視覺輔助工具。對幾何和函數問題類型的評估表明，我們的模型在文本連貫性、一致性、相關性和相似性方面明顯優於基本的 LLM，同時保持了原始問題的本質幾何和函數完整性。儘管在確保一致的視覺輸出方面仍存在一些挑戰，但我們的框架證明了 LLM 在轉變教育者在數學教育中生成和利用視覺輔助工具的方式方面具有巨大的潛力。

##### **Learning the rules of peptide self-assembly through data mining with large language models**
2411.05421v1 by Zhenze Yang, Sarah K. Yorke, Tuomas P. J. Knowles, Markus J. Buehler

Peptides are ubiquitous and important biologically derived molecules, that
have been found to self-assemble to form a wide array of structures. Extensive
research has explored the impacts of both internal chemical composition and
external environmental stimuli on the self-assembly behaviour of these systems.
However, there is yet to be a systematic study that gathers this rich
literature data and collectively examines these experimental factors to provide
a global picture of the fundamental rules that govern protein self-assembly
behavior. In this work, we curate a peptide assembly database through a
combination of manual processing by human experts and literature mining
facilitated by a large language model. As a result, we collect more than 1,000
experimental data entries with information about peptide sequence, experimental
conditions and corresponding self-assembly phases. Utilizing the collected
data, ML models are trained and evaluated, demonstrating excellent accuracy
(>80\%) and efficiency in peptide assembly phase classification. Moreover, we
fine-tune our GPT model for peptide literature mining with the developed
dataset, which exhibits markedly superior performance in extracting information
from academic publications relative to the pre-trained model. We find that this
workflow can substantially improve efficiency when exploring potential
self-assembling peptide candidates, through guiding experimental work, while
also deepening our understanding of the mechanisms governing peptide
self-assembly. In doing so, novel structures can be accessed for a range of
applications including sensing, catalysis and biomaterials.

摘要：胜肽是普遍存在的且重要的生物衍生分子，已发现它们会自组装形成各种结构。广泛的研究探索了内在化学成分和外在环境刺激对这些系统自组装行为的影响。然而，尚未有系统性研究收集这些丰富的文献数据，并共同检验这些实验因素，以提供管理蛋白质自组装行为的基本规则的全局图景。在这项工作中，我们通过人工专家手动处理和由大型语言模型促进的文献挖掘，策划了一个胜肽组装数据库。因此，我们收集了 1,000 多个实验数据条目，其中包含有关胜肽序列、实验条件和相应的自组装阶段的信息。利用收集到的数据，对 ML 模型进行训练和评估，展示了胜肽组装阶段分类的出色准确性 (>80%) 和效率。此外，我们使用开发的数据集对 GPT 模型进行微调，用于胜肽文献挖掘，该模型在从学术出版物中提取信息方面表现出明显优于预训练模型的性能。我们发现，此工作流程可以通过指导实验工作，同时加深我们对管理胜肽自组装的机制的理解，在探索潜在自组装胜肽候选物时大幅提高效率。这样做可以获得新颖的结构，用于包括传感、催化和生物材料在内的各种应用。

##### **WeatherGFM: Learning A Weather Generalist Foundation Model via In-context Learning**
2411.05420v1 by Xiangyu Zhao, Zhiwang Zhou, Wenlong Zhang, Yihao Liu, Xiangyu Chen, Junchao Gong, Hao Chen, Ben Fei, Shiqi Chen, Wanli Ouyang, Xiao-Ming Wu, Lei Bai

The Earth's weather system encompasses intricate weather data modalities and
diverse weather understanding tasks, which hold significant value to human
life. Existing data-driven models focus on single weather understanding tasks
(e.g., weather forecasting). Although these models have achieved promising
results, they fail to tackle various complex tasks within a single and unified
model. Moreover, the paradigm that relies on limited real observations for a
single scenario hinders the model's performance upper bound. In response to
these limitations, we draw inspiration from the in-context learning paradigm
employed in state-of-the-art visual foundation models and large language
models. In this paper, we introduce the first generalist weather foundation
model (WeatherGFM), designed to address a wide spectrum of weather
understanding tasks in a unified manner. More specifically, we initially unify
the representation and definition of the diverse weather understanding tasks.
Subsequently, we devised weather prompt formats to manage different weather
data modalities, namely single, multiple, and temporal modalities. Finally, we
adopt a visual prompting question-answering paradigm for the training of
unified weather understanding tasks. Extensive experiments indicate that our
WeatherGFM can effectively handle up to ten weather understanding tasks,
including weather forecasting, super-resolution, weather image translation, and
post-processing. Our method also showcases generalization ability on unseen
tasks.

摘要：地球的天氣系統包含了複雜的天氣數據模式和各種天氣理解任務，這些任務對人類生活具有重要價值。現有的數據驅動模型專注於單一的天氣理解任務（例如天氣預報）。儘管這些模型已經取得了有希望的結果，但它們無法在單一且統一的模型中應對各種複雜的任務。此外，依賴於單一情境中有限的真實觀測的範例阻礙了模型的性能上限。為了應對這些限制，我們從最先進的視覺基礎模型和大語言模型中使用的上下文學習範例中汲取靈感。在本文中，我們介紹了第一個通才天氣基礎模型 (WeatherGFM)，旨在以統一的方式解決廣泛的天氣理解任務。更具體地說，我們最初統一了不同天氣理解任務的表示和定義。隨後，我們設計了天氣提示格式來管理不同的天氣數據模式，即單一、多重和時間模式。最後，我們採用視覺提示問答範例來訓練統一的天氣理解任務。大量的實驗表明，我們的 WeatherGFM 可以有效地處理多達十項天氣理解任務，包括天氣預報、超解析度、天氣圖像轉換和後處理。我們的模型還展示了在未見任務上的泛化能力。

##### **Web Archives Metadata Generation with GPT-4o: Challenges and Insights**
2411.05409v1 by Abigail Yongping Huang, Ashwin Nair, Zhen Rong Goh, Tianrui Liu

Current metadata creation for web archives is time consuming and costly due
to reliance on human effort. This paper explores the use of gpt-4o for metadata
generation within the Web Archive Singapore, focusing on scalability,
efficiency, and cost effectiveness. We processed 112 Web ARChive (WARC) files
using data reduction techniques, achieving a notable 99.9% reduction in
metadata generation costs. By prompt engineering, we generated titles and
abstracts, which were evaluated both intrinsically using Levenshtein Distance
and BERTScore, and extrinsically with human cataloguers using McNemar's test.
Results indicate that while our method offers significant cost savings and
efficiency gains, human curated metadata maintains an edge in quality. The
study identifies key challenges including content inaccuracies, hallucinations,
and translation issues, suggesting that Large Language Models (LLMs) should
serve as complements rather than replacements for human cataloguers. Future
work will focus on refining prompts, improving content filtering, and
addressing privacy concerns through experimentation with smaller models. This
research advances the integration of LLMs in web archiving, offering valuable
insights into their current capabilities and outlining directions for future
enhancements. The code is available at
https://github.com/masamune-prog/warc2summary for further development and use
by institutions facing similar challenges.

摘要：目前網路檔案的建立元資料十分耗時且昂貴，因為仰賴人力。本文探討在新加坡網路檔案中使用 gpt-4o 產生元資料，著重於可擴充性、效率和成本效益。我們使用資料減少技術處理了 112 個網路檔案 (WARC) 檔案，大幅降低了 99.9% 的元資料產生成本。透過提示工程，我們產生了標題和摘要，並使用 Levenshtein 距離和 BERTScore 內在評估，以及使用 McNemar 的檢定與人類分類員外在評估。結果顯示，雖然我們的方法提供了顯著的成本節省和效率提升，但人類策展的元資料在品質上仍有一定優勢。研究找出了一些關鍵挑戰，包括內容不正確、幻覺和翻譯問題，這表示大型語言模型 (LLM) 應該作為人類分類員的補充，而不是取代。未來的研究將專注於改善提示、提升內容過濾，並透過實驗較小的模型來解決隱私問題。這項研究推動了 LLM 在網路檔案中的整合，提供了有價值的見解，了解它們目前的效能，並概述了未來增強的方向。程式碼可在 https://github.com/masamune-prog/warc2summary 取得，供面臨類似挑戰的機構進一步開發和使用。

##### **Gap-Filling Prompting Enhances Code-Assisted Mathematical Reasoning**
2411.05407v1 by Mohammad Ghiasvand Mohammadkhani

Despite the strong performance of large language models (LLMs) in tasks like
mathematical reasoning, their practical use is limited by high computational
demands and proprietary restrictions. Chain-of-thought (CoT) and
program-of-thought (PoT) fine-tuning are common methods to transfer LLM
knowledge to small language models (SLMs). However, CoT often leads to
calculation errors in SLMs, while PoT has shown more promise. While most
PoT-based approaches focus on direct problem-to-code conversion or extracting
only the key information from questions and then providing code solution for
it, this work emphasizes filling the gaps in the question to clearly illustrate
the solution path, which can be challenging for an SLM to understand when such
information is not explicitly provided. Therefore, this paper introduces
Gap-Filling Prompting (GFP), a novel two-step prompting strategy designed to
enhance the problem-solving process for SLMs. The first step identifies these
gaps and provides hints for filling them, while the second step adds the hints
to the question to generate a final code solution. Experimental results on two
benchmark datasets demonstrate that GFP significantly improves the mathematical
reasoning abilities of SLMs.

摘要：儘管大型語言模型 (LLM) 在數學推理等任務中表現出色，但它們的實際用途受到高運算需求和專有權限制。思想鏈 (CoT) 和思想程式 (PoT) 微調是將 LLM 知識轉移到小型語言模型 (SLM) 的常見方法。然而，CoT 通常會導致 SLM 中的計算錯誤，而 PoT 則顯示出更大的希望。儘管大多數基於 PoT 的方法專注於直接問題到程式碼轉換或僅從問題中提取關鍵資訊，然後提供程式碼解決方案，但這項工作強調填補問題中的空白，以清楚說明解決路徑，這對於 SLM 在沒有明確提供此類資訊時理解會是一項挑戰。因此，本文介紹了間隙填充提示 (GFP)，這是一種新穎的兩步驟提示策略，旨在增強 SLM 的問題解決過程。第一步識別這些間隙並提供填補提示，而第二步將提示新增到問題中以產生最終程式碼解決方案。兩個基準資料集的實驗結果證明，GFP 大幅提升了 SLM 的數學推理能力。

##### **Benchmarking Distributional Alignment of Large Language Models**
2411.05403v1 by Nicole Meister, Carlos Guestrin, Tatsunori Hashimoto

Language models (LMs) are increasingly used as simulacra for people, yet
their ability to match the distribution of views of a specific demographic
group and be \textit{distributionally aligned} remains uncertain. This notion
of distributional alignment is complex, as there is significant variation in
the types of attributes that are simulated. Prior works have underexplored the
role of three critical variables -- the question domain, steering method, and
distribution expression method -- which motivates our contribution of a
benchmark explicitly addressing these dimensions. We construct a dataset
expanding beyond political values, create human baselines for this task, and
evaluate the extent to which an LM can align with a particular group's opinion
distribution to inform design choices of such simulation systems. Our analysis
reveals open problems regarding if, and how, LMs can be used to simulate
humans, and that LLMs can more accurately describe the opinion distribution
than simulate such distributions.

摘要：語言模型 (LM) 愈來愈常被用作模擬人類，但它們是否能符合特定人口統計群體的觀點分佈，以及是否能「分佈式對齊」仍存在不確定性。這個分佈式對齊的概念很複雜，因為在模擬的屬性類型中有顯著的差異。先前的研究低估了三個關鍵變數的作用——問題領域、引導方法和分佈式表達方法——這激勵我們貢獻了一個明確說明這些面向的基準。我們建構了一個超越政治價值觀的資料集，為這個任務建立人類基準，並評估 LM 在多大程度上能與特定群體的意見分佈保持一致，以告知此類模擬系統的設計選擇。我們的分析揭露了關於 LM 是否能以及如何用於模擬人類的公開問題，以及 LLM 能比模擬此類分佈更準確地描述意見分佈。

##### **Advancing Meteorological Forecasting: AI-based Approach to Synoptic Weather Map Analysis**
2411.05384v1 by Yo-Hwan Choi, Seon-Yu Kang, Minjong Cheon

As global warming increases the complexity of weather patterns; the precision
of weather forecasting becomes increasingly important. Our study proposes a
novel preprocessing method and convolutional autoencoder model developed to
improve the interpretation of synoptic weather maps. These are critical for
meteorologists seeking a thorough understanding of weather conditions. This
model could recognize historical synoptic weather maps that nearly match
current atmospheric conditions, marking a significant step forward in modern
technology in meteorological forecasting. This comprises unsupervised learning
models like VQ-VQE, as well as supervised learning models like VGG16, VGG19,
Xception, InceptionV3, and ResNet50 trained on the ImageNet dataset, as well as
research into newer models like EfficientNet and ConvNeXt. Our findings proved
that, while these models perform well in various settings, their ability to
identify comparable synoptic weather maps has certain limits. Our research,
motivated by the primary goal of significantly increasing meteorologists'
efficiency in labor-intensive tasks, discovered that cosine similarity is the
most effective metric, as determined by a combination of quantitative and
qualitative assessments to accurately identify relevant historical weather
patterns. This study broadens our understanding by shifting the emphasis from
numerical precision to practical application, ensuring that our model is
effective in theory practical, and accessible in the complex and dynamic field
of meteorology.

摘要：隨著全球暖化加劇天氣型態的複雜度，天氣預測的精準度變得越來越重要。我們的研究提出了一種新穎的預處理方法和卷積自編碼器模型，用於改善天氣概況圖的解讀。對於尋求徹底了解天氣狀況的氣象學家來說，這些至關重要。此模型可以識別與當前大氣狀況幾乎相符的歷史天氣概況圖，標誌著氣象預測現代技術向前邁出了一大步。這包括無監督學習模型（如 VQ-VQE），以及在 ImageNet 資料集上訓練的有監督學習模型（如 VGG16、VGG19、Xception、InceptionV3 和 ResNet50），以及對 EfficientNet 和 ConvNeXt 等較新模型的研究。我們的研究結果證明，儘管這些模型在各種設定中表現良好，但它們識別可比較天氣概況圖的能力有一定的限制。我們的研究動機是大幅提升氣象學家在勞力密集型任務中的效率，發現餘弦相似度是最有效的指標，這是由定量和定性評估相結合來準確識別相關歷史天氣模式所決定的。本研究透過將重點從數值精確度轉移到實際應用，擴展了我們的理解，確保我們的模型在理論上是有效的、在實務上是有效的，並且在複雜且動態的氣象領域中是可以使用的。

##### **Towards Low-Resource Harmful Meme Detection with LMM Agents**
2411.05383v1 by Jianzhao Huang, Hongzhan Lin, Ziyan Liu, Ziyang Luo, Guang Chen, Jing Ma

The proliferation of Internet memes in the age of social media necessitates
effective identification of harmful ones. Due to the dynamic nature of memes,
existing data-driven models may struggle in low-resource scenarios where only a
few labeled examples are available. In this paper, we propose an agency-driven
framework for low-resource harmful meme detection, employing both outward and
inward analysis with few-shot annotated samples. Inspired by the powerful
capacity of Large Multimodal Models (LMMs) on multimodal reasoning, we first
retrieve relative memes with annotations to leverage label information as
auxiliary signals for the LMM agent. Then, we elicit knowledge-revising
behavior within the LMM agent to derive well-generalized insights into meme
harmfulness. By combining these strategies, our approach enables dialectical
reasoning over intricate and implicit harm-indicative patterns. Extensive
experiments conducted on three meme datasets demonstrate that our proposed
approach achieves superior performance than state-of-the-art methods on the
low-resource harmful meme detection task.

摘要：隨著社群媒體時代網路迷因的激增，迫切需要有效辨識有害迷因。由於迷因的動態特性，現有的資料驅動模型可能難以應付僅有少數標籤範例可用的低資源場景。在本文中，我們提出一個以代理為基礎的低資源有害迷因偵測架構，採用外向和內向分析，並搭配少數註解範例。受惠於大型多模態模型 (LMM) 在多模態推理上的強大能力，我們首先擷取帶有註解的相關迷因，以利用標籤資訊作為 LMM 代理的輔助訊號。接著，我們在 LMM 代理內引發知識修正行為，以推導出對迷因危害性的良好概化見解。透過結合這些策略，我們的做法能夠對複雜且隱含的危害指示模式進行辯證推理。在三個迷因資料集上進行的廣泛實驗證明，我們提出的方法在低資源有害迷因偵測任務上，表現優於現有技術。

##### **Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking**
2411.05375v1 by Mubashara Akhtar, Michael Schlichtkrull, Andreas Vlachos

Current automated fact-checking (AFC) approaches commonly evaluate evidence
either implicitly via the predicted verdicts or by comparing retrieved evidence
with a predefined closed knowledge source, such as Wikipedia. However, these
methods suffer from limitations, resulting from their reliance on evaluation
metrics developed for different purposes and constraints imposed by closed
knowledge sources. Recent advances in natural language generation (NLG)
evaluation offer new possibilities for evidence assessment. In this work, we
introduce Ev2R, an evaluation framework for AFC that comprises three types of
approaches for evidence evaluation: reference-based, proxy-reference, and
reference-less. We evaluate their effectiveness through agreement with human
ratings and adversarial tests, and demonstrate that prompt-based scorers,
particularly those leveraging LLMs and reference evidence, outperform
traditional evaluation approaches.

摘要：當前自動事實查核 (AFC) 方法通常透過預測判決或將檢索到的證據與預先定義的封閉知識來源（例如維基百科）進行比較，來隱含地評估證據。然而，這些方法存在限制，原因在於它們依賴於針對不同目的而開發的評估指標，以及封閉知識來源施加的限制。自然語言生成 (NLG) 評估的最新進展為證據評估提供了新的可能性。在這項工作中，我們引入了 Ev2R，一種 AFC 評估架構，包含三種類型的證據評估方法：基於參考、代理參考和無參考。我們透過與人類評分和對抗性測試的一致性來評估它們的有效性，並證明基於提示的評分者，特別是那些利用 LLM 和參考證據的評分者，優於傳統的評估方法。

##### **Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks**
2411.05361v1 by Chien-yu Huang, Wei-Chih Chen, Shu-wen Yang, Andy T. Liu, Chen-An Li, Yu-Xiang Lin, Wei-Cheng Tseng, Anuj Diwan, Yi-Jen Shih, Jiatong Shi, William Chen, Xuanjun Chen, Chi-Yuan Hsiao, Puyuan Peng, Shih-Heng Wang, Chun-Yi Kuan, Ke-Han Lu, Kai-Wei Chang, Chih-Kai Yang, Fabian Ritter-Gutierrez, Ming To Chuang, Kuan-Po Huang, Siddhant Arora, You-Kuan Lin, Eunjung Yeo, Kalvin Chang, Chung-Ming Chien, Kwanghee Choi, Cheng-Hsiu Hsieh, Yi-Cheng Lin, Chee-En Yu, I-Hsiang Chiu, Heitor R. Guimarães, Jionghao Han, Tzu-Quan Lin, Tzu-Yuan Lin, Homu Chang, Ting-Wu Chang, Chun Wei Chen, Shou-Jen Chen, Yu-Hua Chen, Hsi-Chun Cheng, Kunal Dhawan, Jia-Lin Fang, Shi-Xin Fang, Kuan-Yu Fang Chiang, Chi An Fu, Hsien-Fu Hsiao, Ching Yu Hsu, Shao-Syuan Huang, Lee Chen Wei, Hsi-Che Lin, Hsuan-Hao Lin, Hsuan-Ting Lin, Jian-Ren Lin, Ting-Chun Liu, Li-Chun Lu, Tsung-Min Pai, Ankita Pasad, Shih-Yun Shan Kuan, Suwon Shon, Yuxun Tang, Yun-Shao Tsai, Jui-Chiang Wei, Tzu-Chieh Wei, Chengxi Wu, Dien-Ruei Wu, Chao-Han Huck Yang, Chieh-Chi Yang, Jia Qi Yip, Shao-Xiang Yuan, Vahid Noroozi, Zhehuai Chen, Haibin Wu, Karen Livescu, David Harwath, Shinji Watanabe, Hung-yi Lee

Multimodal foundation models, such as Gemini and ChatGPT, have revolutionized
human-machine interactions by seamlessly integrating various forms of data.
Developing a universal spoken language model that comprehends a wide range of
natural language instructions is critical for bridging communication gaps and
facilitating more intuitive interactions. However, the absence of a
comprehensive evaluation benchmark poses a significant challenge. We present
Dynamic-SUPERB Phase-2, an open and evolving benchmark for the comprehensive
evaluation of instruction-based universal speech models. Building upon the
first generation, this second version incorporates 125 new tasks contributed
collaboratively by the global research community, expanding the benchmark to a
total of 180 tasks, making it the largest benchmark for speech and audio
evaluation. While the first generation of Dynamic-SUPERB was limited to
classification tasks, Dynamic-SUPERB Phase-2 broadens its evaluation
capabilities by introducing a wide array of novel and diverse tasks, including
regression and sequence generation, across speech, music, and environmental
audio. Evaluation results indicate that none of the models performed well
universally. SALMONN-13B excelled in English ASR, while WavLLM demonstrated
high accuracy in emotion recognition, but current models still require further
innovations to handle a broader range of tasks. We will soon open-source all
task data and the evaluation pipeline.

摘要：多模态基础模型，例如 Gemini 和 ChatGPT，通过无缝集成各种形式的数据，彻底改变了人机交互。开发一个理解广泛自然语言指令的通用口语语言模型对于弥合沟通鸿沟和促进更直观的交互至关重要。然而，缺乏综合评估基准构成了重大挑战。我们提出了 Dynamic-SUPERB 2 阶段，这是一个开放且不断发展的基准，用于对基于指令的通用语音模型进行综合评估。在此第一代的基础上，此第二版纳入了由全球研究界协作贡献的 125 项新任务，将基准扩展到总共 180 项任务，使其成为语音和音频评估中最大的基准。虽然第一代 Dynamic-SUPERB 仅限于分类任务，但 Dynamic-SUPERB 2 阶段通过引入广泛的新颖且多样的任务，包括回归和序列生成，跨越语音、音乐和环境音频，扩展了其评估能力。评估结果表明，没有一个模型在所有方面表现良好。SALMONN-13B 在英语 ASR 中表现出色，而 WavLLM 在情绪识别方面表现出很高的准确性，但当前模型仍需要进一步创新才能处理更广泛的任务。我们很快将开源所有任务数据和评估管道。

##### **Agricultural Landscape Understanding At Country-Scale**
2411.05359v1 by Radhika Dua, Nikita Saxena, Aditi Agarwal, Alex Wilson, Gaurav Singh, Hoang Tran, Ishan Deshpande, Amandeep Kaur, Gaurav Aggarwal, Chandan Nath, Arnab Basu, Vishal Batchu, Sharath Holla, Bindiya Kurle, Olana Missura, Rahul Aggarwal, Shubhika Garg, Nishi Shah, Avneet Singh, Dinesh Tewari, Agata Dondzik, Bharat Adsul, Milind Sohoni, Asim Rama Praveen, Aaryan Dangi, Lisan Kadivar, E Abhishek, Niranjan Sudhansu, Kamlakar Hattekar, Sameer Datar, Musty Krishna Chaithanya, Anumas Ranjith Reddy, Aashish Kumar, Betala Laxmi Tirumala, Alok Talekar

Agricultural landscapes are quite complex, especially in the Global South
where fields are smaller, and agricultural practices are more varied. In this
paper we report on our progress in digitizing the agricultural landscape
(natural and man-made) in our study region of India. We use high resolution
imagery and a UNet style segmentation model to generate the first of its kind
national-scale multi-class panoptic segmentation output. Through this work we
have been able to identify individual fields across 151.7M hectares, and
delineating key features such as water resources and vegetation. We share how
this output was validated by our team and externally by downstream users,
including some sample use cases that can lead to targeted data driven decision
making. We believe this dataset will contribute towards digitizing agriculture
by generating the foundational baselayer.

摘要：農業景觀非常複雜，尤其是在全球南方，那裡的田地較小，農業實務也更多樣化。在這篇論文中，我們報告了我們在將印度研究區域的農業景觀（天然和人造）數位化的進展。我們使用高解析度影像和 UNet 風格的分割模型，產生了首個全國性的多類別全景分割輸出。透過這項工作，我們已經能夠識別出 151.7M 公頃的個別田地，並描繪出水資源和植被等關鍵特徵。我們分享了我們的團隊和下游使用者如何驗證此輸出，包括一些範例使用案例，這些案例可能會導致有針對性的資料驅動決策制定。我們相信這個資料集將透過產生基礎底層，有助於數位化農業。

##### **Controlling Grokking with Nonlinearity and Data Symmetry**
2411.05353v1 by Ahmed Salah, David Yevick

This paper demonstrates that grokking behavior in modular arithmetic with a
modulus P in a neural network can be controlled by modifying the profile of the
activation function as well as the depth and width of the model. Plotting the
even PCA projections of the weights of the last NN layer against their odd
projections further yields patterns which become significantly more uniform
when the nonlinearity is increased by incrementing the number of layers. These
patterns can be employed to factor P when P is nonprime. Finally, a metric for
the generalization ability of the network is inferred from the entropy of the
layer weights while the degree of nonlinearity is related to correlations
between the local entropy of the weights of the neurons in the final layer.

摘要：本文演示了通过修改激活函数的轮廓以及模型的深度和宽度，可以在神经网络中控制模算术中的 grokking 行为，模数 P。绘制最后一层 NN 权重的偶 PCA 投影与其奇投影，进一步产生了模式，当非线性通过增加层数而增加时，这些模式变得更加统一。当 P 为非素数时，这些模式可用于分解 P。最后，从层权重的熵推断出网络泛化能力的度量，而非线性程度与最终层中神经元权重的局部熵之间的相关性有关。

##### **Enhancing Cluster Resilience: LLM-agent Based Autonomous Intelligent Cluster Diagnosis System and Evaluation Framework**
2411.05349v1 by Honghao Shi, Longkai Cheng, Wenli Wu, Yuhang Wang, Xuan Liu, Shaokai Nie, Weixv Wang, Xuebin Min, Chunlei Men, Yonghua Lin

Recent advancements in Large Language Models (LLMs) and related technologies
such as Retrieval-Augmented Generation (RAG) and Diagram of Thought (DoT) have
enabled the creation of autonomous intelligent systems capable of performing
cluster diagnostics and troubleshooting. By integrating these technologies with
self-play methodologies, we have developed an LLM-agent system designed to
autonomously diagnose and resolve issues within AI clusters. Our innovations
include a knowledge base tailored for cluster diagnostics, enhanced LLM
algorithms, practical deployment strategies for agents, and a benchmark
specifically designed for evaluating LLM capabilities in this domain. Through
extensive experimentation across multiple dimensions, we have demonstrated the
superiority of our system in addressing the challenges faced in cluster
diagnostics, particularly in detecting and rectifying performance issues more
efficiently and accurately than traditional methods.

摘要：大型語言模型 (LLM) 和相關技術的最新進展，例如檢索增強生成 (RAG) 和思想圖 (DoT)，已經能夠建立自主智慧系統，執行群集診斷和故障排除。透過將這些技術與自對弈方法整合，我們開發出 LLM 代理系統，旨在自主診斷和解決 AI 群集中的問題。我們的創新包括針對群集診斷量身打造的知識庫、增強的 LLM 演算法、代理實用的部署策略，以及專門用於評估 LLM 在此領域能力的基準。透過多個面向的廣泛實驗，我們展示了我們的系統在解決群集診斷中所面臨挑戰方面的優越性，特別是在比傳統方法更有效率和準確地偵測和修正效能問題方面。

##### **LLM-PySC2: Starcraft II learning environment for Large Language Models**
2411.05348v1 by Zongyuan Li, Yanan Ni, Runnan Qi, Lumin Jiang, Chang Lu, Xiaojie Xu, Xiangbei Liu, Pengfei Li, Yunzheng Guo, Zhe Ma, Xian Guo, Kuihua Huang, Xuebo Zhang

This paper introduces a new environment LLM-PySC2 (the Large Language Model
StarCraft II Learning Environment), a platform derived from DeepMind's
StarCraft II Learning Environment that serves to develop Large Language Models
(LLMs) based decision-making methodologies. This environment is the first to
offer the complete StarCraft II action space, multi-modal observation
interfaces, and a structured game knowledge database, which are seamlessly
connected with various LLMs to facilitate the research of LLMs-based
decision-making. To further support multi-agent research, we developed an LLM
collaborative framework that supports multi-agent concurrent queries and
multi-agent communication. In our experiments, the LLM-PySC2 environment is
adapted to be compatible with the StarCraft Multi-Agent Challenge (SMAC) task
group and provided eight new scenarios focused on macro-decision abilities. We
evaluated nine mainstream LLMs in the experiments, and results show that
sufficient parameters are necessary for LLMs to make decisions, but improving
reasoning ability does not directly lead to better decision-making outcomes.
Our findings further indicate the importance of enabling large models to learn
autonomously in the deployment environment through parameter training or
train-free learning techniques. Ultimately, we expect that the LLM-PySC2
environment can promote research on learning methods for LLMs, helping
LLM-based methods better adapt to task scenarios.

摘要：本文介紹了一個新環境 LLM-PySC2 (大型語言模型星海爭霸 II 學習環境)，一個源自 DeepMind 的星海爭霸 II 學習環境的平台，用於開發大型語言模型 (LLM) 為基礎的決策制定方法。此環境是第一個提供完整的星海爭霸 II 動作空間、多模式觀察介面和結構化遊戲知識資料庫的環境，這些環境與各種 LLM 無縫連接，以便於研究基於 LLM 的決策制定。為了進一步支援多重代理研究，我們開發了一個 LLM 協作架構，支援多重代理並發查詢和多重代理溝通。在我們的實驗中，LLM-PySC2 環境經過調整，與星海爭霸多重代理挑戰 (SMAC) 任務組相容，並提供了八個新的場景，專注於巨觀決策能力。我們在實驗中評估了九個主流 LLM，結果顯示，LLM 要做出決策需要足夠的參數，但改善推理能力並不會直接導致更好的決策制定結果。我們的發現進一步表明，讓大型模型能夠透過參數訓練或免訓練學習技術在部署環境中自主學習非常重要。最終，我們預期 LLM-PySC2 環境可以促進 LLM 學習方法的研究，協助基於 LLM 的方法更好地適應任務場景。

##### **Reasoning Robustness of LLMs to Adversarial Typographical Errors**
2411.05345v1 by Esther Gan, Yiran Zhao, Liying Cheng, Yancan Mao, Anirudh Goyal, Kenji Kawaguchi, Min-Yen Kan, Michael Shieh

Large Language Models (LLMs) have demonstrated impressive capabilities in
reasoning using Chain-of-Thought (CoT) prompting. However, CoT can be biased by
users' instruction. In this work, we study the reasoning robustness of LLMs to
typographical errors, which can naturally occur in users' queries. We design an
Adversarial Typo Attack ($\texttt{ATA}$) algorithm that iteratively samples
typos for words that are important to the query and selects the edit that is
most likely to succeed in attacking. It shows that LLMs are sensitive to
minimal adversarial typographical changes. Notably, with 1 character edit,
Mistral-7B-Instruct's accuracy drops from 43.7% to 38.6% on GSM8K, while with 8
character edits the performance further drops to 19.2%. To extend our
evaluation to larger and closed-source LLMs, we develop the $\texttt{R$^2$ATA}$
benchmark, which assesses models' $\underline{R}$easoning
$\underline{R}$obustness to $\underline{\texttt{ATA}}$. It includes adversarial
typographical questions derived from three widely used reasoning
datasets-GSM8K, BBH, and MMLU-by applying $\texttt{ATA}$ to open-source LLMs.
$\texttt{R$^2$ATA}$ demonstrates remarkable transferability and causes notable
performance drops across multiple super large and closed-source LLMs.

摘要：大型語言模型 (LLM) 已在使用思考鏈 (CoT) 提示進行推理方面展現出令人印象深刻的能力。然而，CoT 可能會受到使用者指令的影響。在這項工作中，我們研究了 LLM 對印刷錯誤的推理穩健性，這可能會自然發生在使用者的查詢中。我們設計了一種對抗性印刷攻擊 (ATA) 演算法，該演算法會反覆對查詢中重要的字詞進行印刷錯誤取樣，並選擇最有可能成功攻擊的編輯內容。它顯示出 LLM 對最小的對抗性印刷變更很敏感。值得注意的是，在 1 個字元編輯下，Mistral-7B-Instruct 在 GSM8K 上的準確度從 43.7% 降至 38.6%，而在 8 個字元編輯下，效能進一步降至 19.2%。為了將我們的評估擴展到更大且封閉原始碼的 LLM，我們開發了 R2ATA 基準，該基準評估模型對 ATA 的推理穩健性。它包含透過將 ATA 套用於開放原始碼 LLM，從三個廣泛使用的推理資料集 (GSM8K、BBH 和 MMLU) 中衍生的對抗性印刷問題。R2ATA 表現出顯著的可轉移性，並導致多個超大型且封閉原始碼的 LLM 效能大幅下降。

##### **Improving Multi-Domain Task-Oriented Dialogue System with Offline Reinforcement Learning**
2411.05340v1 by Dharmendra Prajapat, Durga Toshniwal

Task-oriented dialogue (TOD) system is designed to accomplish user-defined
tasks through dialogues. The TOD system has progressed towards end-to-end
modeling by leveraging pre-trained large language models. Fine-tuning the
pre-trained language models using only supervised learning leads to the
exposure bias and token loss problem and it deviates the models from completing
the user's task. To address these issues, we propose a TOD system that
leverages a unified pre-trained language model, GPT2, as a base model. It is
optimized using supervised learning and reinforcement learning (RL). The issues
in the TOD system are mitigated using a non-differentiable reward function. The
reward is calculated using the weighted sum of the success rate and BLEU
evaluation metrics. The success rate and BLEU metrics in reward calculation
guide the language model for user task completion while ensuring a coherent and
fluent response. Our model is acquired by fine-tuning a pre-trained model on
the dialogue-session level which comprises user utterance, belief state, system
act, and system response. Experimental results on MultiWOZ2.1 demonstrate that
our model increases the inform rate by 1.60% and the success rate by 3.17%
compared to the baseline.

摘要：任務導向對話（TOD）系統旨在透過對話完成使用者定義的任務。TOD 系統已透過利用預訓練的大型語言模型朝向端對端建模邁進。僅使用監督式學習微調預訓練的語言模型會導致暴露偏差和權杖損失問題，並使模型偏離完成使用者的任務。為了解決這些問題，我們提出了一個 TOD 系統，它利用統一的預訓練語言模型 GPT2 作為基礎模型。它是使用監督式學習和強化學習（RL）進行最佳化的。TOD 系統中的問題透過使用不可微分的獎勵函數來減輕。獎勵是使用成功率和 BLEU 評估指標的加權總和來計算的。獎勵計算中的成功率和 BLEU 指標引導語言模型完成使用者任務，同時確保回應連貫且流暢。我們的模型是透過微調對話會話層級的預訓練模型來取得，其中包含使用者發言、信念狀態、系統動作和系統回應。MultiWOZ2.1 的實驗結果證明，與基準相比，我們的模型將告知率提高了 1.60%，成功率提高了 3.17%。

##### **SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers**
2411.05338v1 by Shruti Singh, Nandan Sarkar, Arman Cohan

Scientific literature is typically dense, requiring significant background
knowledge and deep comprehension for effective engagement. We introduce SciDQA,
a new dataset for reading comprehension that challenges LLMs for a deep
understanding of scientific articles, consisting of 2,937 QA pairs. Unlike
other scientific QA datasets, SciDQA sources questions from peer reviews by
domain experts and answers by paper authors, ensuring a thorough examination of
the literature. We enhance the dataset's quality through a process that
carefully filters out lower quality questions, decontextualizes the content,
tracks the source document across different versions, and incorporates a
bibliography for multi-document question-answering. Questions in SciDQA
necessitate reasoning across figures, tables, equations, appendices, and
supplementary materials, and require multi-document reasoning. We evaluate
several open-source and proprietary LLMs across various configurations to
explore their capabilities in generating relevant and factual responses. Our
comprehensive evaluation, based on metrics for surface-level similarity and LLM
judgements, highlights notable performance discrepancies. SciDQA represents a
rigorously curated, naturally derived scientific QA dataset, designed to
facilitate research on complex scientific text understanding.

摘要：科學文獻通常很密集，需要大量的背景知識和深入的理解才能有效參與。我們引入了 SciDQA，這是一個新的閱讀理解數據集，它挑戰 LLM 深入理解科學文章，包含 2,937 個 QA 對。與其他科學 QA 數據集不同，SciDQA 從領域專家的同行評審和論文作者的回答中獲取問題，確保對文獻進行徹底審查。我們通過一個流程提高了數據集的質量，該流程仔細過濾掉質量較低的問題，對內容進行去情境化，跨不同版本追蹤原始文件，並為多文件問答納入書目。SciDQA 中的問題需要對圖表、表格、方程式、附錄和補充材料進行推理，並且需要多文件推理。我們評估了各種配置的幾個開源和專有 LLM，以探索它們生成相關和事實性回應的能力。我們基於表面相似性和 LLM 判斷的指標進行的綜合評估突出了顯著的性能差異。SciDQA 代表了一個經過嚴格策劃、自然衍生的科學 QA 數據集，旨在促進對複雜科學文本理解的研究。

##### **Inversion-based Latent Bayesian Optimization**
2411.05330v1 by Jaewon Chu, Jinyoung Park, Seunghun Lee, Hyunwoo J. Kim

Latent Bayesian optimization (LBO) approaches have successfully adopted
Bayesian optimization over a continuous latent space by employing an
encoder-decoder architecture to address the challenge of optimization in a high
dimensional or discrete input space. LBO learns a surrogate model to
approximate the black-box objective function in the latent space. However, we
observed that most LBO methods suffer from the `misalignment problem`, which is
induced by the reconstruction error of the encoder-decoder architecture. It
hinders learning an accurate surrogate model and generating high-quality
solutions. In addition, several trust region-based LBO methods select the
anchor, the center of the trust region, based solely on the objective function
value without considering the trust region`s potential to enhance the
optimization process. To address these issues, we propose Inversion-based
Latent Bayesian Optimization (InvBO), a plug-and-play module for LBO. InvBO
consists of two components: an inversion method and a potential-aware trust
region anchor selection. The inversion method searches the latent code that
completely reconstructs the given target data. The potential-aware trust region
anchor selection considers the potential capability of the trust region for
better local optimization. Experimental results demonstrate the effectiveness
of InvBO on nine real-world benchmarks, such as molecule design and arithmetic
expression fitting tasks. Code is available at https://github.com/mlvlab/InvBO.

摘要：潛在貝氏最佳化 (LBO) 方法已成功採用在連續潛在空間上的貝氏最佳化，透過採用編碼器-解碼器架構來解決在高維度或離散輸入空間中最佳化的挑戰。LBO 學習一個替代模型來近似潛在空間中的黑盒目標函數。然而，我們觀察到，大多數 LBO 方法都會遇到「未對齊問題」，這是由編碼器-解碼器架構的重建誤差所引發的。它會阻礙學習準確的替代模型和產生高品質的解。此外，許多基於信任區域的 LBO 方法會根據目標函數值來選擇錨點（信任區域的中心），而不會考慮信任區域增強最佳化程序的潛力。為了解決這些問題，我們提出基於反演的潛在貝氏最佳化 (InvBO)，一個 LBO 的即插即用模組。InvBO 包含兩個元件：反演方法和具潛力感知的信任區域錨點選擇。反演方法會搜尋完全重建給定目標資料的潛在代碼。具潛力感知的信任區域錨點選擇會考慮信任區域的潛在能力，以進行更好的局部最佳化。實驗結果顯示 InvBO 在九個真實世界的基準上的有效性，例如分子設計和算術表達式擬合任務。程式碼可在 https://github.com/mlvlab/InvBO 取得。

##### **Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**
2411.05316v1 by Dong Shu, Bingbing Duan, Kai Guo, Kaixiong Zhou, Jiliang Tang, Mengnan Du

Latent representation alignment has become a foundational technique for
constructing multimodal large language models (MLLM) by mapping embeddings from
different modalities into a shared space, often aligned with the embedding
space of large language models (LLMs) to enable effective cross-modal
understanding. While preliminary protein-focused MLLMs have emerged, they have
predominantly relied on heuristic approaches, lacking a fundamental
understanding of optimal alignment practices across representations. In this
study, we explore the alignment of multimodal representations between LLMs and
Geometric Deep Models (GDMs) in the protein domain. We comprehensively evaluate
three state-of-the-art LLMs (Gemma2-2B, LLaMa3.1-8B, and LLaMa3.1-70B) with
four protein-specialized GDMs (GearNet, GVP, ScanNet, GAT). Our work examines
alignment factors from both model and protein perspectives, identifying
challenges in current alignment methodologies and proposing strategies to
improve the alignment process. Our key findings reveal that GDMs incorporating
both graph and 3D structural information align better with LLMs, larger LLMs
demonstrate improved alignment capabilities, and protein rarity significantly
impacts alignment performance. We also find that increasing GDM embedding
dimensions, using two-layer projection heads, and fine-tuning LLMs on
protein-specific data substantially enhance alignment quality. These strategies
offer potential enhancements to the performance of protein-related multimodal
models. Our code and data are available at
https://github.com/Tizzzzy/LLM-GDM-alignment.

摘要：潛在表徵對齊已成為建構多模態大型語言模型 (MLLM) 的基礎技術，方法是將不同模態的嵌入映射到共享空間中，通常與大型語言模型 (LLM) 的嵌入空間對齊，以實現有效的跨模態理解。雖然初步以蛋白質為重點的 MLLM 已出現，但它們主要依賴啟發式方法，缺乏對跨表徵最佳對齊實務的基本理解。在本研究中，我們探討了蛋白質領域中 LLM 與幾何深度模型 (GDM) 之間的多模態表徵對齊。我們全面評估了三個最先進的 LLM（Gemma2-2B、LLaMa3.1-8B 和 LLaMa3.1-70B）與四個蛋白質專用 GDM（GearNet、GVP、ScanNet、GAT）。我們的研究從模型和蛋白質角度檢視對齊因素，識別當前對齊方法的挑戰，並提出改善對齊程序的策略。我們的關鍵發現顯示，同時包含圖形和 3D 結構資訊的 GDM 與 LLM 的對齊效果較佳，較大的 LLM 展現出更佳的對齊能力，而蛋白質的稀有性顯著影響對齊效能。我們還發現，增加 GDM 嵌入維度、使用兩層投影頭，以及針對蛋白質特定資料微調 LLM，可以大幅提升對齊品質。這些策略為蛋白質相關多模態模型的效能提供潛在的強化。我們的程式碼和資料可在 https://github.com/Tizzzzy/LLM-GDM-alignment 取得。

##### **On Training of Kolmogorov-Arnold Networks**
2411.05296v1 by Shairoz Sohail

Kolmogorov-Arnold Networks have recently been introduced as a flexible
alternative to multi-layer Perceptron architectures. In this paper, we examine
the training dynamics of different KAN architectures and compare them with
corresponding MLP formulations. We train with a variety of different
initialization schemes, optimizers, and learning rates, as well as utilize back
propagation free approaches like the HSIC Bottleneck. We find that (when judged
by test accuracy) KANs are an effective alternative to MLP architectures on
high-dimensional datasets and have somewhat better parameter efficiency, but
suffer from more unstable training dynamics. Finally, we provide
recommendations for improving training stability of larger KAN models.

摘要：Kolmogorov-Arnold 網路最近被引入作為多層感知器架構的靈活替代方案。在本文中，我們檢驗了不同 KAN 架構的訓練動態，並將它們與對應的 MLP 公式進行比較。我們使用各種不同的初始化方案、優化器和學習率進行訓練，並利用後向傳播自由方法，例如 HSIC 瓶頸。我們發現（以測試準確度來判斷）KAN 是高維資料集上 MLP 架構的有效替代方案，並且具有更好的參數效率，但訓練動態較不穩定。最後，我們提供了改善較大 KAN 模型訓練穩定性的建議。

##### **SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding**
2411.05289v1 by Ryan Sun, Tianyi Zhou, Xun Chen, Lichao Sun

Large Language Models (LLMs) have become essential in advancing natural
language processing (NLP) tasks, but their sequential token generation limits
inference speed. Multi-Draft Speculative Decoding (MDSD) offers a promising
solution by using a smaller draft model to generate multiple token sequences,
which the target LLM verifies in parallel. However, current heuristic
approaches, such as Recursive Rejection Sampling (RRS), suffer from low
acceptance rates in subsequent drafts, limiting the advantages of using
multiple drafts. Meanwhile, Optimal Transport with Membership Cost (OTM) can
theoretically improve acceptance rates, but its computational cost is too high
for real-time use. We present SpecHub, a novel, efficient sampling-verification
method for MDSD that improves acceptance rates with only linear computational
overhead. By simplifying the OTM problem into a compact Linear Programming
model, SpecHub significantly reduces computational complexity. It further
accelerates sampling by leveraging a sparse joint distribution, focusing
computation on high-probability token sequences. In extensive experiments,
Spechub consistently generates 0.05-0.27 and 0.02-0.16 more tokens per step
than RRS and RRS without replacement. We attach our code at
\url{https://github.com/MasterGodzilla/Speculative_decoding_OT}.

摘要：大型語言模型 (LLM) 已成為推進自然語言處理 (NLP) 任務的關鍵，但其序列標記產生限制了推論速度。多草稿推測性解碼 (MDSD) 提供了一個有前景的解決方案，它使用較小的草稿模型來產生多個標記序列，目標 LLM 會並行驗證這些序列。然而，目前的啟發式方法（例如遞迴拒絕採樣 (RRS)）在後續草稿中接受率低，這限制了使用多個草稿的優點。與此同時，具有成員成本的最優傳輸 (OTM) 在理論上可以提高接受率，但其運算成本對於實時使用來說太高。我們提出 SpecHub，這是一種新穎、高效的 MDSD 採樣驗證方法，它僅通過線性運算開銷來提高接受率。通過將 OTM 問題簡化為一個緊湊的線性規劃模型，SpecHub 大幅降低了運算複雜度。它進一步利用稀疏聯合分佈來加速採樣，將運算集中在高概率標記序列上。在廣泛的實驗中，Spechub 每個步驟產生的標記比 RRS 和未替換的 RRS 持續多出 0.05-0.27 和 0.02-0.16 個。我們將我們的代碼附加在 \url{https://github.com/MasterGodzilla/Speculative_decoding_OT}。

##### **A Taxonomy of AgentOps for Enabling Observability of Foundation Model based Agents**
2411.05285v1 by Liming Dong, Qinghua Lu, Liming Zhu

The ever-improving quality of LLMs has fueled the growth of a diverse range
of downstream tasks, leading to an increased demand for AI automation and a
burgeoning interest in developing foundation model (FM)-based autonomous
agents. As AI agent systems tackle more complex tasks and evolve, they involve
a wider range of stakeholders, including agent users, agentic system developers
and deployers, and AI model developers. These systems also integrate multiple
components such as AI agent workflows, RAG pipelines, prompt management, agent
capabilities, and observability features. In this case, obtaining reliable
outputs and answers from these agents remains challenging, necessitating a
dependable execution process and end-to-end observability solutions. To build
reliable AI agents and LLM applications, it is essential to shift towards
designing AgentOps platforms that ensure observability and traceability across
the entire development-to-production life-cycle. To this end, we conducted a
rapid review and identified relevant AgentOps tools from the agentic ecosystem.
Based on this review, we provide an overview of the essential features of
AgentOps and propose a comprehensive overview of observability data/traceable
artifacts across the agent production life-cycle. Our findings provide a
systematic overview of the current AgentOps landscape, emphasizing the critical
role of observability/traceability in enhancing the reliability of autonomous
agent systems.

摘要：大型語言模型品質不斷提升，推動下游任務的多元化成長，進而提升對 AI 自動化的需求，以及開發基礎模型 (FM) 為基礎的自主代理的濃厚興趣。隨著 AI 代理系統處理更複雜的任務並不斷演進，它們涉及更廣泛的利害關係人，包括代理使用者、代理系統開發人員和部署者，以及 AI 模型開發人員。這些系統也整合多個元件，例如 AI 代理工作流程、RAG 管線、提示管理、代理功能和可觀察性功能。在這種情況下，從這些代理取得可靠的輸出和答案仍然具有挑戰性，因此需要可靠的執行程序和端對端可觀察性解決方案。為了建置可靠的 AI 代理和 LLM 應用程式，轉向設計 AgentOps 平台至關重要，以確保整個開發到生產生命週期的可觀察性和可追溯性。為此，我們進行了快速檢視，並從代理生態系統中找出相關的 AgentOps 工具。根據這份檢視，我們提供 AgentOps 基本功能的概觀，並提出代理生產生命週期中可觀察性資料/可追溯人工製品的全面概觀。我們的發現提供 AgentOps 現況的系統性概觀，強調可觀察性/可追溯性在提升自主代理系統可靠性方面扮演的關鍵角色。

##### **MicroScopiQ: Accelerating Foundational Models through Outlier-Aware Microscaling Quantization**
2411.05282v1 by Akshat Ramachandran, Souvik Kundu, Tushar Krishna

Quantization of foundational models (FMs) is significantly more challenging
than traditional DNNs due to the emergence of large magnitude features called
outliers. Existing outlier-aware algorithm/architecture co-design techniques
either use mixed-precision, retaining outliers at high precision but compromise
hardware efficiency, or quantize inliers and outliers at the same precision,
improving hardware efficiency at the cost of accuracy. To address this mutual
exclusivity, in this paper, we propose MicroScopiQ, a novel co-design technique
that leverages pruning to complement outlier-aware quantization. MicroScopiQ
retains outliers at higher precision while pruning a certain fraction of least
important weights to distribute the additional outlier bits; ensuring high
accuracy, aligned memory and hardware efficiency. We design a high-throughput,
low overhead accelerator architecture composed of simple multi-precision INT
processing elements and a novel network-on-chip called ReCoN that efficiently
abstracts the complexity of supporting high-precision outliers. Additionally,
unlike existing alternatives, MicroScopiQ does not assume any locality of
outlier weights, enabling applicability to a broad range of FMs. Extensive
experiments across various quantization settings show that MicroScopiQ achieves
SoTA quantization performance while simultaneously improving inference
performance by 3x and reducing energy by 2x over existing alternatives.

摘要：基礎模型 (FM) 的量化比傳統 DNN 困難得多，因為出現了稱為異常值的大量級特徵。現有的異常值感知演算法/架構共同設計技術，會使用混合精度，保留異常值的高精度，但會影響硬體效率，或以相同的精度量化內點和異常值，以犧牲準確度來改善硬體效率。為了解決這種相互排斥性，我們在本文中提出 MicroScopiQ，這是一種新穎的共同設計技術，它利用剪枝來補充異常值感知量化。MicroScopiQ 保留異常值的高精度，同時剪枝掉一部分最不重要的權重，以分配額外的異常值位元；確保高準確度、對齊的記憶體和硬體效率。我們設計了一個高通量、低開銷的加速器架構，它由簡單的多精度 INT 處理元件和一個稱為 ReCoN 的新穎網路晶片組成，可以有效地抽象化支援高精度異常值的複雜性。此外，與現有的替代方案不同，MicroScopiQ 不假設異常值權重的任何局部性，讓其適用於廣泛的 FM。在各種量化設定下的廣泛實驗顯示，MicroScopiQ 達到了 SoTA 量化效能，同時將推理效能提升了 3 倍，並將能源降低了 2 倍，超越了現有的替代方案。

##### **Fox-1 Technical Report**
2411.05281v1 by Zijian Hu, Jipeng Zhang, Rui Pan, Zhaozhuo Xu, Salman Avestimehr, Chaoyang He, Tong Zhang

We present Fox-1, a series of small language models (SLMs) consisting of
Fox-1-1.6B and Fox-1-1.6B-Instruct-v0.1. These models are pre-trained on 3
trillion tokens of web-scraped document data and fine-tuned with 5 billion
tokens of instruction-following and multi-turn conversation data. Aiming to
improve the pre-training efficiency, Fox-1-1.6B model introduces a novel
3-stage data curriculum across all the training data with 2K-8K sequence
length. In architecture design, Fox-1 features a deeper layer structure, an
expanded vocabulary, and utilizes Grouped Query Attention (GQA), offering a
performant and efficient architecture compared to other SLMs. Fox-1 achieves
better or on-par performance in various benchmarks compared to StableLM-2-1.6B,
Gemma-2B, Qwen1.5-1.8B, and OpenELM1.1B, with competitive inference speed and
throughput. The model weights have been released under the Apache 2.0 license,
where we aim to promote the democratization of LLMs and make them fully
accessible to the whole open-source community.

摘要：我們提出 Fox-1，這是一個由 Fox-1-1.6B 和 Fox-1-1.6B-Instruct-v0.1 組成的一系列小型語言模型 (SLM)。這些模型經過 3 兆個網路擷取文件資料的預訓練，並使用 50 億個遵循指示和多輪對話資料進行微調。為了提高預訓練效率，Fox-1-1.6B 模型在所有訓練資料中引入了創新的 3 階段資料課程，序列長度為 2K-8K。在架構設計中，Fox-1 採用更深的層級結構、擴充的詞彙量，並利用群組查詢注意力 (GQA)，與其他 SLM 相比，提供了高效能且高效的架構。與 StableLM-2-1.6B、Gemma-2B、Qwen1.5-1.8B 和 OpenELM1.1B 相比，Fox-1 在各種基準測試中達到更好或同等的效能，同時具有競爭力的推論速度和吞吐量。模型權重已在 Apache 2.0 授權下發布，我們的目標是推廣 LLM 的民主化，並讓整個開源社群都能充分使用。

##### **Revisiting the Robustness of Watermarking to Paraphrasing Attacks**
2411.05277v1 by Saksham Rastogi, Danish Pruthi

Amidst rising concerns about the internet being proliferated with content
generated from language models (LMs), watermarking is seen as a principled way
to certify whether text was generated from a model. Many recent watermarking
techniques slightly modify the output probabilities of LMs to embed a signal in
the generated output that can later be detected. Since early proposals for text
watermarking, questions about their robustness to paraphrasing have been
prominently discussed. Lately, some techniques are deliberately designed and
claimed to be robust to paraphrasing. However, such watermarking schemes do not
adequately account for the ease with which they can be reverse-engineered. We
show that with access to only a limited number of generations from a black-box
watermarked model, we can drastically increase the effectiveness of
paraphrasing attacks to evade watermark detection, thereby rendering the
watermark ineffective.

摘要：隨著人們越來越擔心網路上充斥著由語言模型（LM）產生的內容，浮水印被視為一種確認文字是否由模型產生的原則性方法。許多最近的浮水印技術會輕微修改 LM 的輸出機率，以便在產生的輸出中嵌入一個訊號，稍後可以偵測到這個訊號。自從提出文字浮水印的早期提案以來，關於它們對改寫的穩健性問題一直備受討論。最近，一些技術經過刻意設計，並聲稱對改寫具有穩健性。然而，此類浮水印架構並未充分考量到它們可以輕鬆進行逆向工程的便利性。我們展示，只要取得黑盒浮水印模型產生的少量世代，我們就能大幅提升改寫攻擊的效能，以規避浮水印偵測，進而讓浮水印失效。

##### **Real-World Offline Reinforcement Learning from Vision Language Model Feedback**
2411.05273v1 by Sreyas Venkataraman, Yufei Wang, Ziyu Wang, Zackory Erickson, David Held

Offline reinforcement learning can enable policy learning from pre-collected,
sub-optimal datasets without online interactions. This makes it ideal for
real-world robots and safety-critical scenarios, where collecting online data
or expert demonstrations is slow, costly, and risky. However, most existing
offline RL works assume the dataset is already labeled with the task rewards, a
process that often requires significant human effort, especially when
ground-truth states are hard to ascertain (e.g., in the real-world). In this
paper, we build on prior work, specifically RL-VLM-F, and propose a novel
system that automatically generates reward labels for offline datasets using
preference feedback from a vision-language model and a text description of the
task. Our method then learns a policy using offline RL with the reward-labeled
dataset. We demonstrate the system's applicability to a complex real-world
robot-assisted dressing task, where we first learn a reward function using a
vision-language model on a sub-optimal offline dataset, and then we use the
learned reward to employ Implicit Q learning to develop an effective dressing
policy. Our method also performs well in simulation tasks involving the
manipulation of rigid and deformable objects, and significantly outperform
baselines such as behavior cloning and inverse RL. In summary, we propose a new
system that enables automatic reward labeling and policy learning from
unlabeled, sub-optimal offline datasets.

摘要：離線強化學習可以讓策略學習從預先收集的次佳資料集進行，而無需線上互動。這使得它非常適合於現實世界的機器人和安全關鍵情境，在這些情境中，收集線上資料或專家示範既緩慢、昂貴又冒險。然而，現有的離線 RL 工作大多假設資料集已經標記有任務獎勵，這個過程通常需要大量人力，特別是在難以確定基本事實的情況下（例如，在現實世界中）。在本文中，我們建立在先前的研究，特別是 RL-VLM-F，並提出一個新穎的系統，使用來自視覺語言模型的偏好回饋和任務的文字描述，自動為離線資料集生成獎勵標籤。我們的模型接著使用離線 RL 學習有獎勵標籤的資料集的策略。我們展示了該系統對複雜的現實世界機器人輔助穿衣任務的適用性，在該任務中，我們首先使用視覺語言模型在次佳離線資料集上學習獎勵函數，然後使用學習到的獎勵來採用隱式 Q 學習來開發有效的穿衣策略。我們的模型在涉及操縱剛性和可變形物體的模擬任務中也表現良好，並且明顯優於行為複製和逆向 RL 等基準。總之，我們提出了一個新的系統，可以從未標記的次佳離線資料集中進行自動獎勵標記和策略學習。

##### **Seeing Through the Fog: A Cost-Effectiveness Analysis of Hallucination Detection Systems**
2411.05270v1 by Alexander Thomas, Seth Rosen, Vishnu Vettrivel

This paper presents a comparative analysis of hallucination detection systems
for AI, focusing on automatic summarization and question answering tasks for
Large Language Models (LLMs). We evaluate different hallucination detection
systems using the diagnostic odds ratio (DOR) and cost-effectiveness metrics.
Our results indicate that although advanced models can perform better they come
at a much higher cost. We also demonstrate how an ideal hallucination detection
system needs to maintain performance across different model sizes. Our findings
highlight the importance of choosing a detection system aligned with specific
application needs and resource constraints. Future research will explore hybrid
systems and automated identification of underperforming components to enhance
AI reliability and efficiency in detecting and mitigating hallucinations.

摘要：本文針對人工智慧 (AI) 的幻覺偵測系統進行比較分析，重點在於大型語言模型 (LLM) 的自動摘要和問答任務。我們使用診斷比值 (DOR) 和成本效益指標評估不同的幻覺偵測系統。我們的結果顯示，雖然進階模型的表現可能較佳，但其成本也高出許多。我們也展示理想的幻覺偵測系統需要在不同模型規模中維持效能。我們的發現強調選擇與特定應用需求和資源限制相符的偵測系統的重要性。未來的研究將探討混合系統和自動識別低效能元件，以提升人工智慧在偵測和減輕幻覺方面的可靠性和效率。

##### **Decoding Report Generators: A Cyclic Vision-Language Adapter for Counterfactual Explanations**
2411.05261v1 by Yingying Fang, Zihao Jin, Shaojie Guo, Jinda Liu, Yijian Gao, Junzhi Ning, Zhiling Yue, Zhi Li, Simon LF Walsh, Guang Yang

Despite significant advancements in report generation methods, a critical
limitation remains: the lack of interpretability in the generated text. This
paper introduces an innovative approach to enhance the explainability of text
generated by report generation models. Our method employs cyclic text
manipulation and visual comparison to identify and elucidate the features in
the original content that influence the generated text. By manipulating the
generated reports and producing corresponding images, we create a comparative
framework that highlights key attributes and their impact on the text
generation process. This approach not only identifies the image features
aligned to the generated text but also improves transparency but also provides
deeper insights into the decision-making mechanisms of the report generation
models. Our findings demonstrate the potential of this method to significantly
enhance the interpretability and transparency of AI-generated reports.

摘要：儘管報告生成方法有顯著進展，但仍存在一個嚴重的限制：所產生文字缺乏可解釋性。本文介紹了一種創新的方法，以增強報告生成模型所產生文字的可解釋性。我們的做法採用循環文字處理和視覺比較，以識別並闡明原始內容中影響所產生文字的功能。藉由處理所產生的報告並產生對應的影像，我們建立了一個比較架構，突顯關鍵屬性和它們對文字生成過程的影響。這種方法不僅識別與所產生文字對齊的影像功能，還提高透明度，並提供對報告生成模型決策機制的更深入見解。我們的發現證明了這種方法的潛力，可以顯著增強 AI 生成的報告的可解釋性和透明度。

##### **QuanCrypt-FL: Quantized Homomorphic Encryption with Pruning for Secure Federated Learning**
2411.05260v1 by Md Jueal Mia, M. Hadi Amini

Federated Learning has emerged as a leading approach for decentralized
machine learning, enabling multiple clients to collaboratively train a shared
model without exchanging private data. While FL enhances data privacy, it
remains vulnerable to inference attacks, such as gradient inversion and
membership inference, during both training and inference phases. Homomorphic
Encryption provides a promising solution by encrypting model updates to protect
against such attacks, but it introduces substantial communication overhead,
slowing down training and increasing computational costs. To address these
challenges, we propose QuanCrypt-FL, a novel algorithm that combines low-bit
quantization and pruning techniques to enhance protection against attacks while
significantly reducing computational costs during training. Further, we propose
and implement mean-based clipping to mitigate quantization overflow or errors.
By integrating these methods, QuanCrypt-FL creates a communication-efficient FL
framework that ensures privacy protection with minimal impact on model
accuracy, thereby improving both computational efficiency and attack
resilience. We validate our approach on MNIST, CIFAR-10, and CIFAR-100
datasets, demonstrating superior performance compared to state-of-the-art
methods. QuanCrypt-FL consistently outperforms existing method and matches
Vanilla-FL in terms of accuracy across varying client. Further, QuanCrypt-FL
achieves up to 9x faster encryption, 16x faster decryption, and 1.5x faster
inference compared to BatchCrypt, with training time reduced by up to 3x.

摘要：聯邦學習已成為分散式機器學習的一種領先方法，使多個用戶端能夠協作訓練共享模型，而無需交換私有數據。雖然聯邦學習增強了數據隱私，但它在訓練和推理階段仍然容易受到推理攻擊，例如梯度反演和成員推理。同態加密通過加密模型更新來防範此類攻擊，提供了一個有前途的解決方案，但它引入了大量的通信開銷，減慢了訓練速度並增加了計算成本。為了應對這些挑戰，我們提出了 QuanCrypt-FL，這是一種新穎的演算法，它結合了低位元量化和剪枝技術，以增強對攻擊的防護，同時顯著降低訓練期間的計算成本。此外，我們提出並實作了基於平均值的裁剪，以減輕量化溢位或錯誤。通過整合這些方法，QuanCrypt-FL 創建了一個通信效率高的聯邦學習框架，確保隱私保護，對模型準確度的影響最小，從而提高了計算效率和攻擊彈性。我們在 MNIST、CIFAR-10 和 CIFAR-100 資料集上驗證了我們的做法，展示了比最先進的方法更好的效能。QuanCrypt-FL 在不同用戶端的準確性方面始終優於現有方法，並與 Vanilla-FL 相匹配。此外，與 BatchCrypt 相比，QuanCrypt-FL 的加密速度提高了 9 倍，解密速度提高了 16 倍，推理速度提高了 1.5 倍，訓練時間縮短了 3 倍。

##### **What talking you?: Translating Code-Mixed Messaging Texts to English**
2411.05253v1 by Lynnette Hui Xian Ng, Luo Qi Chan

Translation of code-mixed texts to formal English allow a wider audience to
understand these code-mixed languages, and facilitate downstream analysis
applications such as sentiment analysis. In this work, we look at translating
Singlish, which is colloquial Singaporean English, to formal standard English.
Singlish is formed through the code-mixing of multiple Asian languages and
dialects. We analysed the presence of other Asian languages and variants which
can facilitate translation. Our dataset is short message texts, written as
informal communication between Singlish speakers. We use a multi-step prompting
scheme on five Large Language Models (LLMs) for language detection and
translation. Our analysis show that LLMs do not perform well in this task, and
we describe the challenges involved in translation of code-mixed languages. We
also release our dataset in this link https://github.com/luoqichan/singlish.

摘要：將混合語言翻譯成正式英文，讓更廣泛的受眾理解這些混合語言，並促進下游分析應用程式（例如情緒分析）。在此工作中，我們著眼於將新加坡口語英語 Singlish 翻譯成正式標準英語。Singlish 是透過混合多種亞洲語言和方言形成的。我們分析了其他亞洲語言和變體的存在，這些語言和變體有助於翻譯。我們的資料集是簡訊，由 Singlish 使用者寫成非正式的溝通內容。我們對五種大型語言模型 (LLM) 使用多步驟提示方案進行語言偵測和翻譯。我們的分析顯示，LLM 在這項任務中表現不佳，我們描述了混合語言翻譯所涉及的挑戰。我們也會在此連結 https://github.com/luoqichan/singlish 釋出我們的資料集。

##### **Abstract2Appendix: Academic Reviews Enhance LLM Long-Context Capabilities**
2411.05232v1 by Shengzhi Li, Kittipat Kampa, Rongyu Lin, Bohang Li, Shichao Pei

Large language models (LLMs) have shown remarkable performance across various
tasks, yet their ability to handle long-context reading remains challenging.
This study explores the effectiveness of leveraging high-quality academic peer
review data for fine-tuning LLMs to enhance their long-context capabilities. We
compare the Direct Preference Optimization (DPO) method with the Supervised
Fine-Tuning (SFT) method, demonstrating DPO's superiority and data efficiency.
Our experiments show that the fine-tuned model achieves a 4.04-point
improvement over phi-3 and a 2.6\% increase on the Qasper benchmark using only
2000 samples. Despite facing limitations in data scale and processing costs,
this study underscores the potential of DPO and high-quality data in advancing
LLM performance.
  Additionally, the zero-shot benchmark results indicate that aggregated
high-quality human reviews are overwhelmingly preferred over LLM-generated
responses, even for the most capable models like GPT-4o. This suggests that
high-quality human reviews are extremely rich in information, reasoning, and
long-context retrieval, capabilities that even the most advanced models have
not fully captured. These findings highlight the high utility of leveraging
human reviews to further advance the field.

摘要：大型語言模型（LLM）在各種任務中表現出顯著的效能，但它們處理長語境閱讀的能力仍然具有挑戰性。本研究探討了利用高品質的學術同行評審資料微調 LLM，以增強其長語境能力的有效性。我們將直接偏好最佳化（DPO）方法與監督微調（SFT）方法進行比較，證明了 DPO 的優越性和資料效率。我們的實驗表明，微調後的模型在 phi-3 上取得了 4.04 分的進步，在 Qasper 基準上僅使用 2000 個樣本就增加了 2.6%。儘管在資料規模和處理成本方面面臨限制，但本研究強調了 DPO 和高品質資料在提升 LLM 效能方面的潛力。此外，零次學習基準結果表明，即使對於像 GPT-4o 這樣最強大的模型，彙總的高品質人類評論也比 LLM 生成的回應更受歡迎。這表明高品質的人類評論極其豐富，包含資訊、推理和長語境檢索，這是即使是最先進的模型也尚未完全掌握的能力。這些發現突出了利用人類評論進一步推動該領域發展的高效用性。

##### **Evaluating GPT-4 at Grading Handwritten Solutions in Math Exams**
2411.05231v1 by Adriana Caraeni, Alexander Scarlatos, Andrew Lan

Recent advances in generative artificial intelligence (AI) have shown promise
in accurately grading open-ended student responses. However, few prior works
have explored grading handwritten responses due to a lack of data and the
challenge of combining visual and textual information. In this work, we
leverage state-of-the-art multi-modal AI models, in particular GPT-4o, to
automatically grade handwritten responses to college-level math exams. Using
real student responses to questions in a probability theory exam, we evaluate
GPT-4o's alignment with ground-truth scores from human graders using various
prompting techniques. We find that while providing rubrics improves alignment,
the model's overall accuracy is still too low for real-world settings, showing
there is significant room for growth in this task.

摘要：生成式人工智慧 (AI) 的最新進展，已在準確評分開放式學生回應方面展現出前景。然而，由於缺乏資料和結合視覺與文字資訊的挑戰，鮮少有先前的研究探討評分手寫回應。在這項研究中，我們利用最先進的多模態 AI 模型，特別是 GPT-4o，自動評分大學程度數學考試的手寫回應。使用實際學生對機率論考試中問題的回應，我們使用各種提示技術，評估 GPT-4o 與人類評分者的真實分數之間的一致性。我們發現，儘管提供評分標準能改善一致性，但模型的整體準確度對於實際情況來說仍然太低，顯示出此任務仍有很大的成長空間。

##### **CHATTER: A Character Attribution Dataset for Narrative Understanding**
2411.05227v1 by Sabyasachee Baruah, Shrikanth Narayanan

Computational narrative understanding studies the identification,
description, and interaction of the elements of a narrative: characters,
attributes, events, and relations. Narrative research has given considerable
attention to defining and classifying character types. However, these
character-type taxonomies do not generalize well because they are small, too
simple, or specific to a domain. We require robust and reliable benchmarks to
test whether narrative models truly understand the nuances of the character's
development in the story. Our work addresses this by curating the Chatter
dataset that labels whether a character portrays some attribute for 88148
character-attribute pairs, encompassing 2998 characters, 13324 attributes and
660 movies. We validate a subset of Chatter, called ChatterEval, using human
annotations to serve as an evaluation benchmark for the character attribution
task in movie scripts. ChatterEval assesses narrative understanding and the
long-context modeling capacity of language models.

摘要：計算敘事理解研究探討敘事的元素識別、描述和互動：角色、屬性、事件和關係。敘事研究非常重視角色類型的定義和分類。然而，這些角色類型分類法無法很好地概括，因為它們規模小、過於簡單或特定於某個領域。我們需要穩健且可靠的基準來測試敘事模型是否真正理解故事中角色發展的細微差別。我們的研究通過整理 Chatter 資料集來解決這個問題，該資料集標記角色是否為 88148 個角色屬性對中的某個屬性，涵蓋 2998 個角色、13324 個屬性和 660 部電影。我們使用人類註釋驗證了 Chatter 的一個子集，稱為 ChatterEval，作為電影腳本中角色歸因任務的評估基準。ChatterEval 評估敘事理解和語言模型的長上下文建模能力。

##### **Beyond the Numbers: Transparency in Relation Extraction Benchmark Creation and Leaderboards**
2411.05224v1 by Varvara Arzt, Allan Hanbury

This paper investigates the transparency in the creation of benchmarks and
the use of leaderboards for measuring progress in NLP, with a focus on the
relation extraction (RE) task. Existing RE benchmarks often suffer from
insufficient documentation, lacking crucial details such as data sources,
inter-annotator agreement, the algorithms used for the selection of instances
for datasets, and information on potential biases like dataset imbalance.
Progress in RE is frequently measured by leaderboards that rank systems based
on evaluation methods, typically limited to aggregate metrics like F1-score.
However, the absence of detailed performance analysis beyond these metrics can
obscure the true generalisation capabilities of models. Our analysis reveals
that widely used RE benchmarks, such as TACRED and NYT, tend to be highly
imbalanced and contain noisy labels. Moreover, the lack of class-based
performance metrics fails to accurately reflect model performance across
datasets with a large number of relation types. These limitations should be
carefully considered when reporting progress in RE. While our discussion
centers on the transparency of RE benchmarks and leaderboards, the observations
we discuss are broadly applicable to other NLP tasks as well. Rather than
undermining the significance and value of existing RE benchmarks and the
development of new models, this paper advocates for improved documentation and
more rigorous evaluation to advance the field.

摘要：本文探討了基準建立的透明度，以及使用排行榜來衡量自然語言處理 (NLP) 進度的使用，重點在於關係萃取 (RE) 任務。現有的 RE 基準經常會因為文件不足而有所缺失，缺少關鍵細節，例如資料來源、標註間的一致性、用於選擇資料集實例的演算法，以及關於潛在偏差（例如資料集不平衡）的資訊。RE 的進度經常透過排行榜來衡量，排行榜會根據評估方法對系統進行排名，通常僅限於 F1 分數等彙總指標。然而，除了這些指標之外，缺乏詳細的效能分析可能會模糊模型真正的泛化能力。我們的分析顯示，廣泛使用的 RE 基準（例如 TACRED 和 NYT）往往高度不平衡，而且包含有雜訊的標籤。此外，缺乏基於類別的效能指標，無法準確反映模型在具有大量關係類型的資料集中的效能。在回報 RE 進度時，應仔細考慮這些限制。雖然我們的討論重點在於 RE 基準和排行榜的透明度，但我們討論的觀察結果也廣泛適用於其他 NLP 任務。本文並非要破壞現有 RE 基準和新模型開發的重要性與價值，而是主張改善文件記錄和更嚴謹的評估，以推進此領域。

##### **STAND-Guard: A Small Task-Adaptive Content Moderation Model**
2411.05214v1 by Minjia Wang, Pingping Lin, Siqi Cai, Shengnan An, Shengjie Ma, Zeqi Lin, Congrui Huang, Bixiong Xu

Content moderation, the process of reviewing and monitoring the safety of
generated content, is important for development of welcoming online platforms
and responsible large language models. Content moderation contains various
tasks, each with its unique requirements tailored to specific scenarios.
Therefore, it is crucial to develop a model that can be easily adapted to novel
or customized content moderation tasks accurately without extensive model
tuning. This paper presents STAND-GUARD, a Small Task-Adaptive coNtent
moDeration model. The basic motivation is: by performing instruct tuning on
various content moderation tasks, we can unleash the power of small language
models (SLMs) on unseen (out-of-distribution) content moderation tasks. We also
carefully study the effects of training tasks and model size on the efficacy of
cross-task fine-tuning mechanism. Experiments demonstrate STAND-Guard is
comparable to GPT-3.5-Turbo across over 40 public datasets, as well as
proprietary datasets derived from real-world business scenarios. Remarkably,
STAND-Guard achieved nearly equivalent results to GPT-4-Turbo on unseen English
binary classification tasks

摘要：內容審核，檢閱和監控生成內容安全性的過程，對於開發歡迎的線上平台和負責任的大型語言模型至關重要。內容審核包含各種任務，每個任務都有其獨特的要求，根據特定場景量身定制。因此，開發一個模型至關重要，該模型可以輕鬆適應新穎或自訂的內容審核任務，而無需廣泛的模型調整。本文介紹 STAND-GUARD，一個小型任務適應性內容審核模型。基本動機是：通過對各種內容審核任務執行指令調整，我們可以釋放小型語言模型 (SLM) 在未見（分佈外）內容審核任務上的能力。我們還仔細研究了訓練任務和模型大小對跨任務微調機制的功效的影響。實驗表明，STAND-Guard 在 40 多個公共數據集以及源自現實世界業務場景的專有數據集上與 GPT-3.5-Turbo 相當。值得注意的是，STAND-Guard 在未見的英語二元分類任務上取得了與 GPT-4-Turbo 近乎相當的結果

##### **Alopex: A Computational Framework for Enabling On-Device Function Calls with LLMs**
2411.05209v1 by Yide Ran, Zhaozhuo Xu, Yuhang Yao, Zijian Hu, Shanshan Han, Han Jin, Alay Dilipbhai Shah, Jipeng Zhang, Dimitris Stripelis, Tong Zhang, Salman Avestimehr, Chaoyang He

The rapid advancement of Large Language Models (LLMs) has led to their
increased integration into mobile devices for personalized assistance, which
enables LLMs to call external API functions to enhance their performance.
However, challenges such as data scarcity, ineffective question formatting, and
catastrophic forgetting hinder the development of on-device LLM agents. To
tackle these issues, we propose Alopex, a framework that enables precise
on-device function calls using the Fox LLM. Alopex introduces a logic-based
method for generating high-quality training data and a novel
``description-question-output'' format for fine-tuning, reducing risks of
function information leakage. Additionally, a data mixing strategy is used to
mitigate catastrophic forgetting, combining function call data with textbook
datasets to enhance performance in various tasks. Experimental results show
that Alopex improves function call accuracy and significantly reduces
catastrophic forgetting, providing a robust solution for integrating function
call capabilities into LLMs without manual intervention.

摘要：大型語言模型 (LLM) 的快速進展已導致它們更多地整合到行動裝置中，以提供個人化協助，這讓 LLM 能夠呼叫外部 API 功能以提升其效能。然而，資料稀少、提問格式無效、以及災難性遺忘等挑戰阻礙了裝置上 LLM 代理的發展。為了解決這些問題，我們提出了 Alopex，一個使用 Fox LLM 啟用精準裝置上功能呼叫的架構。Alopex 導入了一種基於邏輯的方法來產生高品質訓練資料，以及一種用於微調的創新「描述-問題-輸出」格式，以降低功能資訊外洩的風險。此外，資料混合策略用於減輕災難性遺忘，將功能呼叫資料與教科書資料集結合，以提升各種任務的效能。實驗結果顯示，Alopex 改善了功能呼叫準確性，並大幅降低災難性遺忘，提供了一個強健的解決方案，可以用於整合功能呼叫能力到 LLM，而無需手動介入。

##### **Toward Cultural Interpretability: A Linguistic Anthropological Framework for Describing and Evaluating Large Language Models (LLMs)**
2411.05200v1 by Graham M. Jones, Shai Satran, Arvind Satyanarayan

This article proposes a new integration of linguistic anthropology and
machine learning (ML) around convergent interests in both the underpinnings of
language and making language technologies more socially responsible. While
linguistic anthropology focuses on interpreting the cultural basis for human
language use, the ML field of interpretability is concerned with uncovering the
patterns that Large Language Models (LLMs) learn from human verbal behavior.
Through the analysis of a conversation between a human user and an LLM-powered
chatbot, we demonstrate the theoretical feasibility of a new, conjoint field of
inquiry, cultural interpretability (CI). By focusing attention on the
communicative competence involved in the way human users and AI chatbots
co-produce meaning in the articulatory interface of human-computer interaction,
CI emphasizes how the dynamic relationship between language and culture makes
contextually sensitive, open-ended conversation possible. We suggest that, by
examining how LLMs internally "represent" relationships between language and
culture, CI can: (1) provide insight into long-standing linguistic
anthropological questions about the patterning of those relationships; and (2)
aid model developers and interface designers in improving value alignment
between language models and stylistically diverse speakers and culturally
diverse speech communities. Our discussion proposes three critical research
axes: relativity, variation, and indexicality.

摘要：這篇文章提出語言人類學與機器學習（ML）的新整合，圍繞語言基礎和讓語言技術更具社會責任的共同興趣。語言人類學專注於詮釋人類語言使用的文化基礎，而 ML 的可解釋性領域則關注揭示大型語言模型（LLM）從人類言語行為中學習到的模式。透過分析人類使用者與 LLM 驅動的聊天機器人之間的對話，我們展示了一個新的聯合研究領域「文化可解釋性」（CI）的理論可行性。CI 專注於人類使用者和 AI 聊天機器人在人機互動的表述介面中共同建構意義時所涉及的溝通能力，強調語言和文化之間的動態關係如何讓情境敏感的開放式對話成為可能。我們建議，透過檢視 LLM 如何在內部「表徵」語言和文化之間的關係，CI 可以：（1）提供對那些關係模式的長期語言人類學問題的見解；以及（2）協助模型開發人員和介面設計師改善語言模型與風格多樣化的說話者和文化多樣化的語言社群之間的價值對齊。我們的討論提出了三個重要的研究軸線：相對性、變異性和指示性。

##### **CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement**
2411.05199v1 by Leitian Tao, Xiang Chen, Tong Yu, Tung Mai, Ryan Rossi, Yixuan Li, Saayan Mitra

Large Language Models (LLMs) have significantly advanced code generation but
often require substantial resources and tend to over-generalize, limiting their
efficiency for specific tasks. Fine-tuning smaller, open-source LLMs presents a
viable alternative; however, it typically lags behind cutting-edge models due
to supervised fine-tuning's reliance solely on correct code examples, which
restricts the model's ability to learn from its own mistakes and adapt to
diverse programming challenges. To bridge this gap, we introduce CodeLutra, a
novel framework that enhances low-performing LLMs by leveraging both successful
and failed code generation attempts. Unlike conventional fine-tuning, CodeLutra
employs an iterative preference learning mechanism to compare correct and
incorrect solutions as well as maximize the likelihood of correct codes.
Through continuous iterative refinement, CodeLutra enables smaller LLMs to
match or surpass GPT-4's performance in various code generation tasks without
relying on vast external datasets or larger auxiliary models. On a challenging
data analysis task, using just 500 samples improved Llama-3-8B's accuracy from
28.2% to 48.6%, approaching GPT-4's performance. These results highlight
CodeLutra's potential to close the gap between open-source and closed-source
models, making it a promising approach in the field of code generation.

摘要：大型語言模型 (LLM) 已顯著提升程式碼產生，但通常需要大量資源，且傾向過度概化，限制其在特定任務中的效率。微調較小、開放原始碼的 LLM 提供了一個可行的替代方案；然而，由於監督微調僅依賴於正確的程式碼範例，因此通常落後於尖端模型，這限制了模型從其自身錯誤中學習和適應各種程式設計挑戰的能力。為了彌合這一差距，我們引入了 CodeLutra，這是一個通過利用成功和失敗的程式碼生成嘗試來增強效能不佳的 LLM 的新框架。與傳統微調不同，CodeLutra 採用反覆偏好學習機制來比較正確和不正確的解決方案，並最大化正確程式碼的可能性。透過持續的反覆改進，CodeLutra 能讓較小的 LLM 在各種程式碼生成任務中達到或超越 GPT-4 的效能，而無需依賴於龐大的外部資料集或較大的輔助模型。在一個具有挑戰性的資料分析任務中，僅使用 500 個範例就將 Llama-3-8B 的準確度從 28.2% 提升到 48.6%，接近 GPT-4 的效能。這些結果突顯了 CodeLutra 在縮小開放原始碼和閉源模型之間差距的潛力，使其成為程式碼生成領域中一個有前途的方法。

##### **Explainable AI through a Democratic Lens: DhondtXAI for Proportional Feature Importance Using the D'Hondt Method**
2411.05196v1 by Turker Berk Donmez

In democratic societies, electoral systems play a crucial role in translating
public preferences into political representation. Among these, the D'Hondt
method is widely used to ensure proportional representation, balancing fair
representation with governmental stability. Recently, there has been a growing
interest in applying similar principles of proportional representation to
enhance interpretability in machine learning, specifically in Explainable AI
(XAI). This study investigates the integration of D'Hondt-based voting
principles in the DhondtXAI method, which leverages resource allocation
concepts to interpret feature importance within AI models. Through a comparison
of SHAP (Shapley Additive Explanations) and DhondtXAI, we evaluate their
effectiveness in feature attribution within CatBoost and XGBoost models for
breast cancer and diabetes prediction, respectively. The DhondtXAI approach
allows for alliance formation and thresholding to enhance interpretability,
representing feature importance as seats in a parliamentary view. Statistical
correlation analyses between SHAP values and DhondtXAI allocations support the
consistency of interpretations, demonstrating DhondtXAI's potential as a
complementary tool for understanding feature importance in AI models. The
results highlight that integrating electoral principles, such as proportional
representation and alliances, into AI explainability can improve user
understanding, especially in high-stakes fields like healthcare.

摘要：在民主社會中，選舉制度在將公眾偏好轉化為政治代表方面發揮著至關重要的作用。其中，D'Hondt 方法被廣泛用於確保比例代表制，在公平代表與政府穩定性之間取得平衡。最近，人們越來越有興趣將類似的比例代表原則應用於增強機器學習中的可解釋性，特別是在可解釋 AI (XAI) 中。本研究探討了將基於 D'Hondt 的投票原則整合到 DhondtXAI 方法中的方法，該方法利用資源分配概念來解釋 AI 模型中的特徵重要性。通過比較 SHAP（Shapley 加性解釋）和 DhondtXAI，我們評估了它們在 CatBoost 和 XGBoost 模型中分別對乳腺癌和糖尿病預測進行特徵歸因的有效性。DhondtXAI 方法允許聯盟形成和閾值化以增強可解釋性，將特徵重要性表示為議會觀點中的席位。SHAP 值和 DhondtXAI 分配之間的統計相關性分析支持解釋的一致性，證明了 DhondtXAI 作為理解 AI 模型中特徵重要性的補充工具的潛力。結果表明，將選舉原則（例如比例代表制和聯盟）整合到 AI 可解釋性中可以提高用戶的理解，特別是在醫療保健等高風險領域。

##### **On Erroneous Agreements of CLIP Image Embeddings**
2411.05195v1 by Siting Li, Pang Wei Koh, Simon Shaolei Du

Recent research suggests that the failures of Vision-Language Models (VLMs)
at visual reasoning often stem from erroneous agreements -- when semantically
distinct images are ambiguously encoded by the CLIP image encoder into
embeddings with high cosine similarity. In this paper, we show that erroneous
agreements are not always the main culprit, as Multimodal Large Language Models
(MLLMs) can still extract distinct information from them. For instance, when
distinguishing objects on the left vs right in the What'sUp benchmark, the CLIP
image embeddings of the left/right pairs have an average cosine similarity
$>0.99$, and CLIP performs at random chance; but LLaVA-1.5-7B, which uses the
same CLIP image encoder, achieves nearly $100\%$ accuracy. We find that the
extractable information in CLIP image embeddings is likely obscured by CLIP's
inadequate vision-language alignment: Its matching score learned by the
contrastive objective might not capture all diverse image-text correspondences.
We also study the MMVP benchmark, on which prior work has shown that LLaVA-1.5
cannot distinguish image pairs with high cosine similarity. We observe a
performance gain brought by attending more to visual input through an
alternative decoding algorithm. Further, the accuracy significantly increases
if the model can take both images as input to emphasize their nuanced
differences. Both findings indicate that LLaVA-1.5 did not utilize extracted
visual information sufficiently. In conclusion, our findings suggest that while
improving image encoders could benefit VLMs, there is still room to enhance
models with a fixed image encoder by applying better strategies for extracting
and utilizing visual information.

摘要：最近的研究表明，视觉语言模型 (VLM) 在视觉推理中失败通常源于错误的协议——当语义上不同的图像被 CLIP 图像编码器模糊地编码到具有高余弦相似性的嵌入中时。在本文中，我们表明错误的协议并不总是主要原因，因为多模态大语言模型 (MLLM) 仍然可以从中提取不同的信息。例如，在 What'sUp 基准测试中区分左右物体时，左右对的 CLIP 图像嵌入的平均余弦相似性$>0.99$，而 CLIP 以随机机会执行；但使用相同 CLIP 图像编码器的 LLaVA-1.5-7B 实现了接近 $100\%$ 的准确率。我们发现 CLIP 图像嵌入中可提取的信息很可能被 CLIP 不充分的视觉语言对齐所掩盖：它通过对比目标学习的匹配分数可能无法捕获所有不同的图像文本对应关系。我们还研究了 MMVP 基准，之前的工作表明 LLaVA-1.5 无法区分具有高余弦相似性的图像对。我们观察到通过替代解码算法更多地关注视觉输入带来的性能提升。此外，如果模型可以将两幅图像作为输入以强调其细微差别，则准确性会显着提高。这两项发现都表明 LLaVA-1.5 没有充分利用提取的视觉信息。总之，我们的发现表明，虽然改进图像编码器可以使 VLM 受益，但仍有空间通过应用更好的策略来提取和利用视觉信息来增强具有固定图像编码器的模型。

##### **Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations**
2411.05194v1 by Joey Hong, Jessica Lin, Anca Dragan, Sergey Levine

Recent progress on large language models (LLMs) has enabled dialogue agents
to generate highly naturalistic and plausible text. However, current LLM
language generation focuses on responding accurately to questions and requests
with a single effective response. In reality, many real dialogues are
interactive, meaning an agent's utterances will influence their conversational
partner, elicit information, or change their opinion. Accounting for how an
agent can effectively steer a conversation is a crucial ability in many
dialogue tasks, from healthcare to preference elicitation. Existing methods for
fine-tuning dialogue agents to accomplish such tasks would rely on curating
some amount of expert data. However, doing so often requires understanding the
underlying cognitive processes of the conversational partner, which is a skill
neither humans nor LLMs trained on human data can reliably do. Our key insight
is that while LLMs may not be adept at identifying effective strategies for
steering conversations a priori, or in the middle of an ongoing conversation,
they can do so post-hoc, or in hindsight, after seeing how their conversational
partner responds. We use this fact to rewrite and augment existing suboptimal
data, and train via offline reinforcement learning (RL) an agent that
outperforms both prompting and learning from unaltered human demonstrations. We
apply our approach to two domains that require understanding human mental
state, intelligent interaction, and persuasion: mental health support, and
soliciting charitable donations. Our results in a user study with real humans
show that our approach greatly outperforms existing state-of-the-art dialogue
agents.

摘要：大型語言模型 (LLM) 的最新進展使對話代理能夠生成高度自然且合理的文字。然而，目前的 LLM 語言生成著重於以單一有效的回應準確回應問題和要求。在現實中，許多真實對話都是互動的，這表示代理人的發言會影響他們的對話夥伴、引出資訊或改變他們的意見。考量代理人如何有效引導對話的能力在許多對話任務中至關重要，從醫療保健到偏好引導皆是如此。現有的微調對話代理方法以完成此類任務會依賴於策劃一定量的專家資料。然而，這麼做通常需要了解對話夥伴的基礎認知歷程，而這項技能既不是人類也不是訓練過人類資料的 LLM 可靠具備的。我們的關鍵見解在於，儘管 LLM 可能不擅長於事先或在對話進行中識別出引導對話的有效策略，但他們可以在事後或回顧時，在看到他們的對話夥伴如何回應後這麼做。我們利用這個事實來改寫並擴充現有的次佳資料，並透過離線強化學習 (RL) 訓練一名代理人，其表現優於提示和從未經修改的人類示範中學習。我們將我們的做法應用於需要了解人類心理狀態、智慧互動和說服的兩個領域：心理健康支持和募集慈善捐款。我們在與真實人類進行的使用者研究中的結果顯示，我們的做法大幅優於現有的最先進對話代理。

##### **Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning**
2411.05193v1 by Joey Hong, Anca Dragan, Sergey Levine

Value-based reinforcement learning (RL) can in principle learn effective
policies for a wide range of multi-turn problems, from games to dialogue to
robotic control, including via offline RL from static previously collected
datasets. However, despite the widespread use of policy gradient methods to
train large language models for single turn tasks (e.g., question answering),
value-based methods for multi-turn RL in an off-policy or offline setting have
proven particularly challenging to scale to the setting of large language
models. This setting requires effectively leveraging pretraining, scaling to
large architectures with billions of parameters, and training on large
datasets, all of which represent major challenges for current value-based RL
methods. In this work, we propose a novel offline RL algorithm that addresses
these drawbacks, casting Q-learning as a modified supervised fine-tuning (SFT)
problem where the probabilities of tokens directly translate to Q-values. In
this way we obtain an algorithm that smoothly transitions from maximizing the
likelihood of the data during pretraining to learning a near-optimal Q-function
during finetuning. Our algorithm has strong theoretical foundations, enjoying
performance bounds similar to state-of-the-art Q-learning methods, while in
practice utilizing an objective that closely resembles SFT. Because of this,
our approach can enjoy the full benefits of the pretraining of language models,
without the need to reinitialize any weights before RL finetuning, and without
the need to initialize new heads for predicting values or advantages.
Empirically, we evaluate our method on both pretrained LLMs and VLMs, on a
variety of tasks including both natural language dialogue and robotic
manipulation and navigation from images.

摘要：基於價值的強化學習 (RL) 理論上可以學習各種多輪問題的有效政策，從遊戲到對話再到機器人控制，包括從靜態先前收集的資料集進行離線 RL。然而，儘管廣泛使用策略梯度方法來訓練單輪任務的大語言模型（例如，問題解答），但多輪 RL 在非策略或離線設定中的基於價值的方法已被證明特別難以擴展到大型語言模型的設定。此設定需要有效地利用預訓練，擴展到具有數十億個參數的大型架構，並在大型資料集上訓練，所有這些都對當前的基於價值的 RL 方法構成重大挑戰。在這項工作中，我們提出了一種新穎的離線 RL 演算法來解決這些缺點，將 Q 學習轉換為修改過的監督微調 (SFT) 問題，其中符號的機率直接轉換為 Q 值。這樣，我們獲得了一種演算法，該演算法可以在預訓練期間最大化資料的可能性與微調期間學習近乎最佳的 Q 函數之間順利轉換。我們的演算法具有強大的理論基礎，享有與最先進的 Q 學習方法類似的效能界限，同時在實務上使用與 SFT 非常相似的目標。因此，我們的做法可以充分享受語言模型預訓練的全部好處，而無需在 RL 微調之前重新初始化任何權重，也無需初始化新的頭部來預測值或優勢。根據經驗，我們在預訓練的 LLM 和 VLM 上評估了我們的方法，在各種任務上，包括自然語言對話和機器人從影像進行操作和導航。

##### **Explaining Mixtures of Sources in News Articles**
2411.05192v1 by Alexander Spangher, James Youn, Matt DeButts, Nanyun Peng, Emilio Ferrara, Jonathan May

Human writers plan, then write. For large language models (LLMs) to play a
role in longer-form article generation, we must understand the planning steps
humans make before writing. We explore one kind of planning, source-selection
in news, as a case-study for evaluating plans in long-form generation. We ask:
why do specific stories call for specific kinds of sources? We imagine a
generative process for story writing where a source-selection schema is first
selected by a journalist, and then sources are chosen based on categories in
that schema. Learning the article's plan means predicting the schema initially
chosen by the journalist. Working with professional journalists, we adapt five
existing schemata and introduce three new ones to describe journalistic plans
for the inclusion of sources in documents. Then, inspired by Bayesian
latent-variable modeling, we develop metrics to select the most likely plan, or
schema, underlying a story, which we use to compare schemata. We find that two
schemata: stance and social affiliation best explain source plans in most
documents. However, other schemata like textual entailment explain source plans
in factually rich topics like "Science". Finally, we find we can predict the
most suitable schema given just the article's headline with reasonable
accuracy. We see this as an important case-study for human planning, and
provides a framework and approach for evaluating other kinds of plans. We
release a corpora, NewsSources, with annotations for 4M articles.

摘要：人類作家會先規劃，再寫作。對於大型語言模型 (LLM) 在長篇文章生成中扮演角色，我們必須了解人類在寫作前進行的規劃步驟。我們探討一種規劃，即新聞中的來源選擇，作為評估長篇生成中計畫的案例研究。我們問：為什麼特定故事需要特定類型的來源？我們想像一個故事寫作的生成過程，其中記者首先選擇來源選擇架構，然後根據該架構中的類別選擇來源。學習文章的計畫意味著預測記者最初選擇的架構。我們與專業記者合作，調整五個現有架構並引入三個新架構來描述新聞工作者在文件中的來源納入計畫。然後，在貝氏潛變數建模的啟發下，我們開發指標來選擇最可能的計畫，或架構，作為故事的基礎，我們用來比較架構。我們發現兩個架構：立場和社會關係最能說明大多數文件中來源的計畫。然而，其他架構，例如文本蘊涵，可以解釋事實豐富的主題（例如「科學」）中的來源計畫。最後，我們發現我們可以僅通過文章標題預測最合適的架構，準確性合理。我們將此視為人類規劃的重要案例研究，並提供了一個用於評估其他類型的計畫的框架和方法。我們發布了一個語料庫 NewsSources，其中包含對 400 萬篇文章的註釋。

##### **Discern-XR: An Online Classifier for Metaverse Network Traffic**
2411.05184v1 by Yoga Suhas Kuruba Manjunath, Austin Wissborn, Mathew Szymanowski, Mushu Li, Lian Zhao, Xiao-Ping Zhang

In this paper, we design an exclusive Metaverse network traffic classifier,
named Discern-XR, to help Internet service providers (ISP) and router
manufacturers enhance the quality of Metaverse services. Leveraging segmented
learning, the Frame Vector Representation (FVR) algorithm and Frame
Identification Algorithm (FIA) are proposed to extract critical frame-related
statistics from raw network data having only four application-level features. A
novel Augmentation, Aggregation, and Retention Online Training (A2R-OT)
algorithm is proposed to find an accurate classification model through online
training methodology. In addition, we contribute to the real-world Metaverse
dataset comprising virtual reality (VR) games, VR video, VR chat, augmented
reality (AR), and mixed reality (MR) traffic, providing a comprehensive
benchmark. Discern-XR outperforms state-of-the-art classifiers by 7% while
improving training efficiency and reducing false-negative rates. Our work
advances Metaverse network traffic classification by standing as the
state-of-the-art solution.

摘要：在本文中，我們設計了一個獨家的元宇宙網路流量分類器，
名為 Discern-XR，以幫助網路服務供應商 (ISP) 和路由器
製造商提升元宇宙服務的品質。利用分段學習，提出幀向量表示 (FVR) 演算法和幀
識別演算法 (FIA) 從只有四個應用層功能的原始網路資料中萃取關鍵的幀相關
統計資料。提出一個新穎的擴充、彙總和保留線上訓練 (A2R-OT)
演算法，透過線上訓練方法找到一個精準的分類模型。此外，我們貢獻一個包含虛擬實境 (VR) 遊戲、VR 影片、VR 聊天、擴增實境 (AR) 和混合實境 (MR) 流量的真實世界元宇宙資料集，提供一個全面的
基準。Discern-XR 在提升訓練效率和降低偽陰性率的同時，優於最先進的分類器 7%。我們的研究透過成為
最先進的解決方案，推動元宇宙網路流量分類。

##### **Inverse Transition Learning: Learning Dynamics from Demonstrations**
2411.05174v1 by Leo Benac, Abhishek Sharma, Sonali Parbhoo, Finale Doshi-Velez

We consider the problem of estimating the transition dynamics $T^*$ from
near-optimal expert trajectories in the context of offline model-based
reinforcement learning. We develop a novel constraint-based method, Inverse
Transition Learning, that treats the limited coverage of the expert
trajectories as a \emph{feature}: we use the fact that the expert is
near-optimal to inform our estimate of $T^*$. We integrate our constraints into
a Bayesian approach. Across both synthetic environments and real healthcare
scenarios like Intensive Care Unit (ICU) patient management in hypotension, we
demonstrate not only significant improvements in decision-making, but that our
posterior can inform when transfer will be successful.

摘要：我們考慮在離線模型基礎強化學習的脈絡中，從接近最佳的專家軌跡估計轉換動態 $T^*$ 的問題。我們開發一種新的基於約束的方法，逆轉換學習，它將專家軌跡的有限覆蓋範圍視為一種「特徵」：我們利用專家接近最佳的事實來告知我們對 $T^*$ 的估計。我們將我們的約束整合到貝氏方法中。在綜合環境和實際醫療保健場景（例如低血壓重症監護病房 (ICU) 病患管理）中，我們不僅展示了決策制定方面的顯著進步，而且我們的後驗可以告知轉移何時會成功。

##### **ImpScore: A Learnable Metric For Quantifying The Implicitness Level of Language**
2411.05172v1 by Yuxin Wang, Xiaomeng Zhu, Weimin Lyu, Saeed Hassanpour, Soroush Vosoughi

Handling implicit language is essential for natural language processing
systems to achieve precise text understanding and facilitate natural
interactions with users. Despite its importance, the absence of a robust metric
for accurately measuring the implicitness of language significantly constrains
the depth of analysis possible in evaluating models' comprehension
capabilities. This paper addresses this gap by developing a scalar metric that
quantifies the implicitness level of language without relying on external
references. Drawing on principles from traditional linguistics, we define
''implicitness'' as the divergence between semantic meaning and pragmatic
interpretation. To operationalize this definition, we introduce ImpScore, a
novel, reference-free metric formulated through an interpretable regression
model. This model is trained using pairwise contrastive learning on a specially
curated dataset comprising $112,580$ (implicit sentence, explicit sentence)
pairs. We validate ImpScore through a user study that compares its assessments
with human evaluations on out-of-distribution data, demonstrating its accuracy
and strong correlation with human judgments. Additionally, we apply ImpScore to
hate speech detection datasets, illustrating its utility and highlighting
significant limitations in current large language models' ability to understand
highly implicit content. The metric model and its training data are available
at https://github.com/audreycs/ImpScore.

摘要：處理隱含語言對於自然語言處理系統至關重要，以達成精確的文字理解並促進與使用者的自然互動。儘管其重要性，但缺乏用於精確衡量語言隱含性的強健指標，顯著地限制了在評估模型理解能力時可能進行的分析深度。本文透過開發一個標量指標來解決此差距，該指標量化語言的隱含性層級，而不依賴外部參考。根據傳統語言學的原則，我們將「隱含性」定義為語義意義與語用解釋之間的差異。為了將此定義付諸實行，我們引入了 ImpScore，一種透過可解釋迴歸模型制定出的新穎、無參考指標。此模型使用成對對比學習在一個特別策劃的資料集上進行訓練，該資料集包含 $112,580$ 個（隱含句子、明確句子）對。我們透過一項使用者研究驗證 ImpScore，該研究比較了其評估與人類對非分佈資料的評估，證明了其準確性與與人類判斷的高度相關性。此外，我們將 ImpScore 應用於仇恨言論偵測資料集，說明其效用並強調當前大型語言模型在理解高度隱含內容方面的顯著限制。指標模型及其訓練資料可在 https://github.com/audreycs/ImpScore 取得。

##### **Watermarking Language Models through Language Models**
2411.05091v1 by Xin Zhong, Agnibh Dasgupta, Abdullah Tanvir

This paper presents a novel framework for watermarking language models
through prompts generated by language models. The proposed approach utilizes a
multi-model setup, incorporating a Prompting language model to generate
watermarking instructions, a Marking language model to embed watermarks within
generated content, and a Detecting language model to verify the presence of
these watermarks. Experiments are conducted using ChatGPT and Mistral as the
Prompting and Marking language models, with detection accuracy evaluated using
a pretrained classifier model. Results demonstrate that the proposed framework
achieves high classification accuracy across various configurations, with 95%
accuracy for ChatGPT, 88.79% for Mistral. These findings validate the and
adaptability of the proposed watermarking strategy across different language
model architectures. Hence the proposed framework holds promise for
applications in content attribution, copyright protection, and model
authentication.

摘要：本文提出了一個創新的框架，用語言模型產生的提示，來製作語言模型浮水印。所提出的方法利用多模型設置，包含一個提示語言模型來產生浮水印指令，一個標記語言模型來將浮水印嵌入到產生的內容中，以及一個偵測語言模型來驗證這些浮水印的存在。實驗使用 ChatGPT 和 Mistral 作為提示和標記語言模型，並使用預訓練分類器模型評估偵測準確度。結果表明，所提出的框架在各種配置中都達到了很高的分類準確度，ChatGPT 的準確度為 95%，Mistral 的準確度為 88.79%。這些發現驗證了所提出的浮水印策略在不同語言模型架構中的有效性和適應性。因此，所提出的框架在內容歸屬、版權保護和模型驗證等應用中具有廣闊的前景。

##### **Findings of the IWSLT 2024 Evaluation Campaign**
2411.05088v1 by Ibrahim Said Ahmad, Antonios Anastasopoulos, Ondřej Bojar, Claudia Borg, Marine Carpuat, Roldano Cattoni, Mauro Cettolo, William Chen, Qianqian Dong, Marcello Federico, Barry Haddow, Dávid Javorský, Mateusz Krubiński, Tsz Kin Lam, Xutai Ma, Prashant Mathur, Evgeny Matusov, Chandresh Maurya, John McCrae, Kenton Murray, Satoshi Nakamura, Matteo Negri, Jan Niehues, Xing Niu, Atul Kr. Ojha, John Ortega, Sara Papi, Peter Polák, Adam Pospíšil, Pavel Pecina, Elizabeth Salesky, Nivedita Sethiya, Balaram Sarkar, Jiatong Shi, Claytone Sikasote, Matthias Sperber, Sebastian Stüker, Katsuhito Sudoh, Brian Thompson, Marco Turchi, Alex Waibel, Shinji Watanabe, Patrick Wilken, Petr Zemánek, Rodolfo Zevallos

This paper reports on the shared tasks organized by the 21st IWSLT
Conference. The shared tasks address 7 scientific challenges in spoken language
translation: simultaneous and offline translation, automatic subtitling and
dubbing, speech-to-speech translation, dialect and low-resource speech
translation, and Indic languages. The shared tasks attracted 18 teams whose
submissions are documented in 26 system papers. The growing interest towards
spoken language translation is also witnessed by the constantly increasing
number of shared task organizers and contributors to the overview paper, almost
evenly distributed across industry and academia.

摘要：這篇論文報告由第 21 屆 IWSLT 會議組織的共享任務。共享任務針對口語翻譯提出了 7 個科學挑戰：同步和離線翻譯、自動字幕和配音、語音對語音翻譯、方言和低資源語音翻譯，以及印度語言。共享任務吸引了 18 個團隊，其提交內容記錄在 26 篇系統論文中。對口語翻譯日益增長的興趣，也從共享任務組織者和概述論文的投稿者數量持續增加中可見一斑，而這些組織者和投稿者幾乎均勻分佈在產業和學術界。

##### **PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation**
2411.05085v1 by Daniel C. Castro, Aurelia Bustos, Shruthi Bannur, Stephanie L. Hyland, Kenza Bouzid, Maria Teodora Wetscherek, Maria Dolores Sánchez-Valverde, Lara Jaques-Pérez, Lourdes Pérez-Rodríguez, Kenji Takeda, José María Salinas, Javier Alvarez-Valle, Joaquín Galant Herrero, Antonio Pertusa

Radiology report generation (RRG) aims to create free-text radiology reports
from clinical imaging. Grounded radiology report generation (GRRG) extends RRG
by including the localisation of individual findings on the image. Currently,
there are no manually annotated chest X-ray (CXR) datasets to train GRRG
models. In this work, we present a dataset called PadChest-GR
(Grounded-Reporting) derived from PadChest aimed at training GRRG models for
CXR images. We curate a public bi-lingual dataset of 4,555 CXR studies with
grounded reports (3,099 abnormal and 1,456 normal), each containing complete
lists of sentences describing individual present (positive) and absent
(negative) findings in English and Spanish. In total, PadChest-GR contains
7,037 positive and 3,422 negative finding sentences. Every positive finding
sentence is associated with up to two independent sets of bounding boxes
labelled by different readers and has categorical labels for finding type,
locations, and progression. To the best of our knowledge, PadChest-GR is the
first manually curated dataset designed to train GRRG models for understanding
and interpreting radiological images and generated text. By including detailed
localization and comprehensive annotations of all clinically relevant findings,
it provides a valuable resource for developing and evaluating GRRG models from
CXR images. PadChest-GR can be downloaded under request from
https://bimcv.cipf.es/bimcv-projects/padchest-gr/

摘要：<paragraph>放射學報告生成 (RRG) 旨在從臨床影像建立自由文字的放射學報告。基礎放射學報告生成 (GRRG) 透過納入影像上個別發現的定位，來延伸 RRG。目前，沒有手動標記的胸部 X 光 (CXR) 資料集，可供訓練 GRRG 模型。在此研究中，我們提出一個名為 PadChest-GR（基礎報告）的資料集，其源自 PadChest，旨在訓練 CXR 影像的 GRRG 模型。我們策劃了一個公開的雙語資料集，其中包含 4,555 份 CXR 研究，附有基礎報告（3,099 份異常報告和 1,456 份正常報告），每個報告都包含完整的句子清單，用英文和西班牙文描述個別存在的（陽性）和不存在的（陰性）發現。總計，PadChest-GR 包含 7,037 個陽性發現句子和 3,422 個陰性發現句子。每個陽性發現句子最多與兩組獨立的邊界框相關聯，由不同的讀者標記，並具有發現類型、位置和進展的分類標籤。據我們所知，PadChest-GR 是第一個手動策劃的資料集，旨在訓練 GRRG 模型，以理解和詮釋放射學影像和產生的文字。透過納入所有臨床相關發現的詳細定位和綜合註解，它為從 CXR 影像開發和評估 GRRG 模型提供了寶貴的資源。PadChest-GR 可應要求從 https://bimcv.cipf.es/bimcv-projects/padchest-gr/ 下載</paragraph>

##### **Precision or Recall? An Analysis of Image Captions for Training Text-to-Image Generation Model**
2411.05079v1 by Sheng Cheng, Maitreya Patel, Yezhou Yang

Despite advancements in text-to-image models, generating images that
precisely align with textual descriptions remains challenging due to
misalignment in training data. In this paper, we analyze the critical role of
caption precision and recall in text-to-image model training. Our analysis of
human-annotated captions shows that both precision and recall are important for
text-image alignment, but precision has a more significant impact. Leveraging
these insights, we utilize Large Vision Language Models to generate synthetic
captions for training. Models trained with these synthetic captions show
similar behavior to those trained on human-annotated captions, underscores the
potential for synthetic data in text-to-image training.

摘要：儘管文字轉圖像模型有進展，但由於訓練資料出現錯位，要產生與文字描述精確對齊的圖像仍然具有挑戰性。在本文中，我們分析了標題精確度和召回率在文字轉圖像模型訓練中的關鍵角色。我們對人工標註標題的分析顯示，精確度和召回率對於文字與圖像對齊都很重要，但精確度有更顯著的影響。利用這些見解，我們利用大型視覺語言模型來產生用於訓練的合成標題。使用這些合成標題訓練的模型顯示出與在人工標註標題上訓練的模型類似的行為，這強調了合成資料在文字轉圖像訓練中的潛力。

##### **ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning**
2411.05003v1 by David Junhao Zhang, Roni Paiss, Shiran Zada, Nikhil Karnad, David E. Jacobs, Yael Pritch, Inbar Mosseri, Mike Zheng Shou, Neal Wadhwa, Nataniel Ruiz

Recently, breakthroughs in video modeling have allowed for controllable
camera trajectories in generated videos. However, these methods cannot be
directly applied to user-provided videos that are not generated by a video
model. In this paper, we present ReCapture, a method for generating new videos
with novel camera trajectories from a single user-provided video. Our method
allows us to re-generate the reference video, with all its existing scene
motion, from vastly different angles and with cinematic camera motion. Notably,
using our method we can also plausibly hallucinate parts of the scene that were
not observable in the reference video. Our method works by (1) generating a
noisy anchor video with a new camera trajectory using multiview diffusion
models or depth-based point cloud rendering and then (2) regenerating the
anchor video into a clean and temporally consistent reangled video using our
proposed masked video fine-tuning technique.

摘要：最近，影片建模的突破性進展讓生成影片中的相機軌跡可控。然而，這些方法無法直接應用於非影片模型生成的使用者提供影片。在本文中，我們提出 ReCapture，這是一種方法，可從單一使用者提供的影片中生成具有新穎相機軌跡的新影片。我們的這種方法讓我們能夠從截然不同的角度和電影相機運動中重新生成參考影片，並包含其所有現有的場景動作。值得注意的是，使用我們的方法，我們還可以合理地對參考影片中無法觀察到的場景部分進行幻覺。我們的這種方法運作方式為：(1) 使用多視圖擴散模型或基於深度點雲渲染來生成具有新相機軌跡的雜訊錨定影片，然後 (2) 使用我們提出的遮罩影片微調技術，將錨定影片重新生成為乾淨且時間一致的重新調整角度影片。

##### **Analyzing The Language of Visual Tokens**
2411.05001v1 by David M. Chan, Rodolfo Corona, Joonyong Park, Cheol Jun Cho, Yutong Bai, Trevor Darrell

With the introduction of transformer-based models for vision and language
tasks, such as LLaVA and Chameleon, there has been renewed interest in the
discrete tokenized representation of images. These models often treat image
patches as discrete tokens, analogous to words in natural language, learning
joint alignments between visual and human languages. However, little is known
about the statistical behavior of these visual languages - whether they follow
similar frequency distributions, grammatical structures, or topologies as
natural languages. In this paper, we take a natural-language-centric approach
to analyzing discrete visual languages and uncover striking similarities and
fundamental differences. We demonstrate that, although visual languages adhere
to Zipfian distributions, higher token innovation drives greater entropy and
lower compression, with tokens predominantly representing object parts,
indicating intermediate granularity. We also show that visual languages lack
cohesive grammatical structures, leading to higher perplexity and weaker
hierarchical organization compared to natural languages. Finally, we
demonstrate that, while vision models align more closely with natural languages
than other models, this alignment remains significantly weaker than the
cohesion found within natural languages. Through these experiments, we
demonstrate how understanding the statistical properties of discrete visual
languages can inform the design of more effective computer vision models.

摘要：隨著基於Transformer的視覺和語言任務模型（例如 LLaVA 和 Chameleon）的引入，人們對影像的離散標記化表示法重新產生興趣。這些模型通常將影像區塊視為離散標記，類似於自然語言中的單字，並學習視覺語言和人類語言之間的聯合對齊。然而，對於這些視覺語言的統計行為所知甚少，例如它們是否遵循與自然語言類似的頻率分佈、語法結構或拓撲結構。在本文中，我們採用以自然語言為中心的途徑來分析離散視覺語言，並揭示驚人的相似性和根本差異。我們證明，儘管視覺語言遵循齊夫分布，但較高的標記創新會導致更大的熵和更低的壓縮，而標記主要代表物件部分，表示中間粒度。我們還表明，視覺語言缺乏連貫的語法結構，導致與自然語言相比，困惑度較高且層級組織較弱。最後，我們證明，儘管視覺模型與自然語言的對齊比其他模型更緊密，但這種對齊仍然顯著弱於自然語言中發現的內聚性。透過這些實驗，我們展示了理解離散視覺語言的統計屬性如何為更有效的電腦視覺模型的設計提供資訊。

##### **Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?**
2411.05000v1 by Jonathan Roberts, Kai Han, Samuel Albanie

As the context limits of Large Language Models (LLMs) increase, the range of
possible applications and downstream functions broadens. In many real-world
tasks, decisions depend on details scattered across collections of often
disparate documents containing mostly irrelevant information. Long-context LLMs
appear well-suited to this form of complex information retrieval and reasoning,
which has traditionally proven costly and time-consuming. However, although the
development of longer context models has seen rapid gains in recent years, our
understanding of how effectively LLMs use their context has not kept pace. To
address this, we conduct a set of retrieval experiments designed to evaluate
the capabilities of 17 leading LLMs, such as their ability to follow threads of
information through the context window. Strikingly, we find that many models
are remarkably threadsafe: capable of simultaneously following multiple threads
without significant loss in performance. Still, for many models, we find the
effective context limit is significantly shorter than the supported context
length, with accuracy decreasing as the context window grows. Our study also
highlights the important point that token counts from different tokenizers
should not be directly compared -- they often correspond to substantially
different numbers of written characters. We release our code and long-context
experimental data.

摘要：隨著大型語言模型 (LLM) 的內容限制增加，可能的應用範圍和下游功能也隨之擴展。在許多真實世界的任務中，決策取決於分散在通常包含大量無關訊息的文件集合中的細節。長內容限制的 LLM 似乎很適合這種複雜的資訊檢索和推理形式，而這種形式傳統上被證明既昂貴又耗時。然而，儘管較長內容限制模型的開發在近年來已快速進步，但我們對於 LLM 如何有效使用其內容限制的理解並未跟上腳步。為了解決這個問題，我們進行了一組檢索實驗，旨在評估 17 個領先 LLM 的功能，例如它們透過內容限制視窗追蹤資訊串的能力。令人驚訝的是，我們發現許多模型具有顯著的執行緒安全性：能夠同時追蹤多個執行緒，而不會顯著損失效能。儘管如此，對於許多模型，我們發現有效的內容限制顯著短於受支援的內容限制長度，而且隨著內容限制視窗的增加，準確度也會下降。我們的研究也強調了一個重要觀點，即來自不同分詞器的代碼計數不應直接比較——它們通常對應於大量不同的書面字元。我們發布我們的程式碼和長內容限制的實驗資料。

##### **LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation**
2411.04997v1 by Weiquan Huang, Aoqi Wu, Yifan Yang, Xufang Luo, Yuqing Yang, Liang Hu, Qi Dai, Xiyang Dai, Dongdong Chen, Chong Luo, Lili Qiu

CLIP is one of the most important multimodal foundational models today. What
powers CLIP's capabilities? The rich supervision signals provided by natural
language, the carrier of human knowledge, shape a powerful cross-modal
representation space. However, with the rapid advancements in large language
models LLMs like GPT-4 and LLaMA, the boundaries of language comprehension and
generation are continually being pushed. This raises an intriguing question:
can the capabilities of LLMs be harnessed to further improve multimodal
representation learning? The potential benefits of incorporating LLMs into CLIP
are clear. LLMs' strong textual understanding can fundamentally improve CLIP's
ability to handle image captions, drastically enhancing its ability to process
long and complex texts, a well-known limitation of vanilla CLIP. Moreover, LLMs
are trained on a vast corpus of text, possessing open-world knowledge. This
allows them to expand on caption information during training, increasing the
efficiency of the learning process. In this paper, we propose LLM2CLIP, a novel
approach that embraces the power of LLMs to unlock CLIP's potential. By
fine-tuning the LLM in the caption space with contrastive learning, we extract
its textual capabilities into the output embeddings, significantly improving
the output layer's textual discriminability. We then design an efficient
training process where the fine-tuned LLM acts as a powerful teacher for CLIP's
visual encoder. Thanks to the LLM's presence, we can now incorporate longer and
more complex captions without being restricted by vanilla CLIP's text encoder's
context window and ability limitations. Our experiments demonstrate that this
approach brings substantial improvements in cross-modal tasks.

摘要：CLIP 是當今最重要的多模態基礎模型之一。是什麼賦予了 CLIP 的能力？自然語言提供的豐富監督訊號，人類知識的載體，塑造了一個強大的跨模態表示空間。然而，隨著 GPT-4 和 LLaMA 等大型語言模型 LLM 的快速進展，語言理解和生成的界限不斷被推動。這引發了一個有趣的問題：LLM 的能力是否可以被利用來進一步改進多模態表示學習？將 LLM 納入 CLIP 的潛在好處很明顯。LLM 強大的文本理解力可以從根本上提高 CLIP 處理圖像標題的能力，大幅增強其處理長而複雜文本的能力，這是香草 CLIP 的一個眾所周知限制。此外，LLM 是在大量的文本語料庫上訓練的，擁有開放世界的知識。這使他們能夠在訓練期間擴展標題信息，從而提高學習過程的效率。在本文中，我們提出了 LLM2CLIP，一種新穎的方法，它利用 LLM 的力量來釋放 CLIP 的潛力。通過在對比學習的標題空間中微調 LLM，我們將其文本能力提取到輸出嵌入中，顯著提高了輸出層的文本可區分性。然後，我們設計了一個高效的訓練過程，其中微調後的 LLM 充當 CLIP 視覺編碼器的強大教師。由於 LLM 的存在，我們現在可以納入更長、更複雜的標題，而不會受到香草 CLIP 的文本編碼器的上下文窗口和能力限制。我們的實驗表明，這種方法在跨模態任務中帶來了顯著的改進。

##### **HourVideo: 1-Hour Video-Language Understanding**
2411.04998v1 by Keshigeyan Chandrasegaran, Agrim Gupta, Lea M. Hadzic, Taran Kota, Jimming He, Cristóbal Eyzaguirre, Zane Durante, Manling Li, Jiajun Wu, Li Fei-Fei

We present HourVideo, a benchmark dataset for hour-long video-language
understanding. Our dataset consists of a novel task suite comprising
summarization, perception (recall, tracking), visual reasoning (spatial,
temporal, predictive, causal, counterfactual), and navigation (room-to-room,
object retrieval) tasks. HourVideo includes 500 manually curated egocentric
videos from the Ego4D dataset, spanning durations of 20 to 120 minutes, and
features 12,976 high-quality, five-way multiple-choice questions. Benchmarking
results reveal that multimodal models, including GPT-4 and LLaVA-NeXT, achieve
marginal improvements over random chance. In stark contrast, human experts
significantly outperform the state-of-the-art long-context multimodal model,
Gemini Pro 1.5 (85.0% vs. 37.3%), highlighting a substantial gap in multimodal
capabilities. Our benchmark, evaluation toolkit, prompts, and documentation are
available at https://hourvideo.stanford.edu

摘要：我們提出 HourVideo，這是長達一小時的影片語言理解基準資料集。我們的資料集包含一系列新穎的任務套件，包含摘要、感知（回憶、追蹤）、視覺推理（空間、時間、預測、因果、反事實）和導航（房間到房間、物件檢索）任務。HourVideo 包含來自 Ego4D 資料集的 500 個手動策劃的第一人稱視角影片，跨越 20 到 120 分鐘的時長，並提供 12,976 個高品質、五選一的選擇題。基準測試結果顯示，包括 GPT-4 和 LLaVA-NeXT 在內的多模態模型，比隨機機會獲得邊際改善。與之形成鮮明對比的是，人類專家顯著優於最先進的長脈絡多模態模型 Gemini Pro 1.5（85.0% 對比 37.3%），突顯出多模態能力的巨大差距。我們的基準、評估工具包、提示和文件可在 https://hourvideo.stanford.edu 取得

##### **Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models**
2411.04996v1 by Weixin Liang, Lili Yu, Liang Luo, Srinivasan Iyer, Ning Dong, Chunting Zhou, Gargi Ghosh, Mike Lewis, Wen-tau Yih, Luke Zettlemoyer, Xi Victoria Lin

The development of large language models (LLMs) has expanded to multi-modal
systems capable of processing text, images, and speech within a unified
framework. Training these models demands significantly larger datasets and
computational resources compared to text-only LLMs. To address the scaling
challenges, we introduce Mixture-of-Transformers (MoT), a sparse multi-modal
transformer architecture that significantly reduces pretraining computational
costs. MoT decouples non-embedding parameters of the model by modality --
including feed-forward networks, attention matrices, and layer normalization --
enabling modality-specific processing with global self-attention over the full
input sequence. We evaluate MoT across multiple settings and model scales. In
the Chameleon 7B setting (autoregressive text-and-image generation), MoT
matches the dense baseline's performance using only 55.8\% of the FLOPs. When
extended to include speech, MoT reaches speech performance comparable to the
dense baseline with only 37.2\% of the FLOPs. In the Transfusion setting, where
text and image are trained with different objectives, a 7B MoT model matches
the image modality performance of the dense baseline with one third of the
FLOPs, and a 760M MoT model outperforms a 1.4B dense baseline across key image
generation metrics. System profiling further highlights MoT's practical
benefits, achieving dense baseline image quality in 47.2\% of the wall-clock
time and text quality in 75.6\% of the wall-clock time (measured on AWS
p4de.24xlarge instances with NVIDIA A100 GPUs).

摘要：大型語言模型 (LLM) 的發展已擴展到多模態系統，能夠在統一的架構內處理文字、影像和語音。訓練這些模型需要比僅文字的 LLM 大得多的資料集和運算資源。為了應對擴充挑戰，我們引進混合Transformer (MoT)，這是一種稀疏多模態Transformer架構，可大幅減少預訓練的運算成本。MoT 透過模態解耦模型的非嵌入參數，包括前饋網路、注意力矩陣和層次標準化，並在完整的輸入序列上啟用具備全局自我注意力的模態特定處理。我們在多種設定和模型規模中評估 MoT。在變色龍 7B 設定（自迴歸文字和影像產生）中，MoT 僅使用 55.8% 的浮點運算次數 (FLOP) 就達到密集基線的效能。當擴充到包含語音時，MoT 達到的語音效能可與密集基線相比，但僅使用 37.2% 的浮點運算次數。在輸血設定中，文字和影像使用不同的目標進行訓練，7B MoT 模型的影像模態效能與密集基線相當，但浮點運算次數只有三分之一，而 760M MoT 模型則在關鍵影像產生指標上優於 1.4B 密集基線。系統分析進一步突顯了 MoT 的實際效益，在 47.2% 的實際時間內達成密集基線影像品質，在 75.6% 的實際時間內達成文字品質（在配備 NVIDIA A100 GPU 的 AWS p4de.24xlarge 實例上測量）。

##### **Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives**
2411.04991v1 by Hao Sun, Yunyi Shen, Jean-Francois Ton

The Bradley-Terry (BT) model is a common and successful practice in reward
modeling for Large Language Model (LLM) alignment. However, it remains unclear
why this model -- originally developed for multi-player stochastic game
matching -- can be adopted to convert pairwise response comparisons to reward
values and make predictions. Especially given the fact that only a limited
number of prompt-response pairs are sparsely compared with others. In this
paper, we first revisit the foundations of using BT models in reward modeling,
and establish the convergence rate of BT reward models based on deep neural
networks using embeddings, providing a theoretical foundation for their use.
Despite theoretically sound, we argue that the BT model is not a necessary
choice from the perspective of downstream optimization. This is because a
reward model only needs to preserve the correct ranking predictions through a
monotonic transformation of the true reward. We highlight the critical concept
of order consistency in reward modeling and demonstrate that the BT model
possesses this property. Consequently, we propose a simple and straightforward
upper-bound algorithm, compatible with off-the-shelf binary classifiers, as an
alternative order-consistent reward modeling objective. To offer practical
insights, we empirically evaluate the performance of these different reward
modeling approaches across more than 12,000 experimental setups, using $6$ base
LLMs, $2$ datasets, and diverse annotation designs that vary in quantity,
quality, and pairing choices in preference annotations.

摘要：Bradley-Terry (BT) 模型是大型語言模型 (LLM) 對齊中獎勵建模的常見且成功的實務。然而，這個模型最初是為多玩家隨機遊戲配對而開發的，為什麼它可以被採用來將成對的回應比較轉換為獎勵值並做出預測，這仍然不清楚。特別是考慮到只有有限數量的提示回應對與其他對稀疏地進行比較。在本文中，我們首先重新探討在獎勵建模中使用 BT 模型的基礎，並使用嵌入建立基於深度神經網路的 BT 獎勵模型的收斂速度，為它們的使用提供理論基礎。儘管在理論上是合理的，我們認為從下游最佳化的角度來看，BT 模型並非必要的選擇。這是因為獎勵模型只需要透過真實獎勵的單調轉換來保留正確的排名預測。我們強調了獎勵建模中訂單一致性的關鍵概念，並證明了 BT 模型具備此特性。因此，我們提出了一個簡單且直接的上界演算法，與現成的二元分類器相容，作為替代的訂單一致獎勵建模目標。為了提供實用的見解，我們根據 6 個基礎 LLM、2 個資料集和在數量、品質和偏好註解中的配對選擇上有所不同的多樣化註解設計，對這些不同的獎勵建模方法在超過 12,000 個實驗設定中的效能進行經驗評估。

##### **Few-Shot Task Learning through Inverse Generative Modeling**
2411.04987v1 by Aviv Netanyahu, Yilun Du, Antonia Bronars, Jyothish Pari, Joshua Tenenbaum, Tianmin Shu, Pulkit Agrawal

Learning the intents of an agent, defined by its goals or motion style, is
often extremely challenging from just a few examples. We refer to this problem
as task concept learning and present our approach, Few-Shot Task Learning
through Inverse Generative Modeling (FTL-IGM), which learns new task concepts
by leveraging invertible neural generative models. The core idea is to pretrain
a generative model on a set of basic concepts and their demonstrations. Then,
given a few demonstrations of a new concept (such as a new goal or a new
action), our method learns the underlying concepts through backpropagation
without updating the model weights, thanks to the invertibility of the
generative model. We evaluate our method in five domains -- object
rearrangement, goal-oriented navigation, motion caption of human actions,
autonomous driving, and real-world table-top manipulation. Our experimental
results demonstrate that via the pretrained generative model, we successfully
learn novel concepts and generate agent plans or motion corresponding to these
concepts in (1) unseen environments and (2) in composition with training
concepts.

摘要：透過其目標或動作風格定義的代理意圖學習，通常僅從幾個範例中學習極具挑戰性。我們將此問題稱為任務概念學習，並提出我們的做法，透過反向生成式建模（FTL-IGM）進行少量任務學習，透過利用可逆神經生成式模型來學習新的任務概念。核心概念是在一組基本概念及其示範上預訓練生成式模型。然後，給定新概念的幾個示範（例如新目標或新動作），我們的模型透過反向傳播學習基礎概念，而無需更新模型權重，這要歸功於生成式模型的可逆性。我們在五個領域評估我們的模型——物體重新排列、目標導向導航、人類動作的動作標題、自動駕駛和現實世界的桌面操作。我們的實驗結果表明，透過預訓練的生成式模型，我們成功學習新概念並產生與這些概念相應的代理計畫或動作，在（1）未見過的環境中，以及（2）與訓練概念的組合中。

##### **The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities**
2411.04986v1 by Zhaofeng Wu, Xinyan Velocity Yu, Dani Yogatama, Jiasen Lu, Yoon Kim

Modern language models can process inputs across diverse languages and
modalities. We hypothesize that models acquire this capability through learning
a shared representation space across heterogeneous data types (e.g., different
languages and modalities), which places semantically similar inputs near one
another, even if they are from different modalities/languages. We term this the
semantic hub hypothesis, following the hub-and-spoke model from neuroscience
(Patterson et al., 2007) which posits that semantic knowledge in the human
brain is organized through a transmodal semantic "hub" which integrates
information from various modality-specific "spokes" regions. We first show that
model representations for semantically equivalent inputs in different languages
are similar in the intermediate layers, and that this space can be interpreted
using the model's dominant pretraining language via the logit lens. This
tendency extends to other data types, including arithmetic expressions, code,
and visual/audio inputs. Interventions in the shared representation space in
one data type also predictably affect model outputs in other data types,
suggesting that this shared representations space is not simply a vestigial
byproduct of large-scale training on broad data, but something that is actively
utilized by the model during input processing.

摘要：現代語言模型可以處理跨越不同語言和模式的輸入。我們假設模型透過學習跨越異質資料類型（例如，不同的語言和模式）的共享表示空間來獲得此能力，這個空間將語義上相似的輸入放置在彼此附近，即使它們來自不同的模式/語言。我們稱之為語義中心假設，遵循神經科學中的樞紐輻射模型（Patterson 等人，2007 年），該模型假設人類大腦中的語義知識是透過跨模式語義「樞紐」組織的，它整合來自各種特定模式「輻條」區域的資訊。我們首先展示不同語言中語義等效輸入的模型表示在中間層中是相似的，並且這個空間可以使用模型的主導預訓練語言透過 logit 透鏡來詮釋。這種趨勢延伸到其他資料類型，包括算術表達式、程式碼以及視覺/音訊輸入。共享表示空間中的一種資料類型的介入也會可預測地影響其他資料類型中的模型輸出，這表明這個共享表示空間不僅僅是大規模訓練廣泛資料的殘餘副產品，而且是模型在輸入處理期間積極利用的東西。

