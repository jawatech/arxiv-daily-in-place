{"2411.03086": {"publish_time": "2024-11-05", "title": "HFGaussian: Learning Generalizable Gaussian Human with Integrated Human Features", "paper_summary": "Recent advancements in radiance field rendering show promising results in 3D\nscene representation, where Gaussian splatting-based techniques emerge as\nstate-of-the-art due to their quality and efficiency. Gaussian splatting is\nwidely used for various applications, including 3D human representation.\nHowever, previous 3D Gaussian splatting methods either use parametric body\nmodels as additional information or fail to provide any underlying structure,\nlike human biomechanical features, which are essential for different\napplications. In this paper, we present a novel approach called HFGaussian that\ncan estimate novel views and human features, such as the 3D skeleton, 3D key\npoints, and dense pose, from sparse input images in real time at 25 FPS. The\nproposed method leverages generalizable Gaussian splatting technique to\nrepresent the human subject and its associated features, enabling efficient and\ngeneralizable reconstruction. By incorporating a pose regression network and\nthe feature splatting technique with Gaussian splatting, HFGaussian\ndemonstrates improved capabilities over existing 3D human methods, showcasing\nthe potential of 3D human representations with integrated biomechanics. We\nthoroughly evaluate our HFGaussian method against the latest state-of-the-art\ntechniques in human Gaussian splatting and pose estimation, demonstrating its\nreal-time, state-of-the-art performance.", "paper_summary_zh": "\u8fd1\u4f86\u8f3b\u7167\u5834\u57df\u6e32\u67d3\u7684\u9032\u5c55\u5728 3D \u5834\u666f\u8868\u793a\u4e2d\u5c55\u73fe\u4e86\u4ee4\u4eba\u632f\u596e\u7684\u6210\u679c\uff0c\u5176\u4e2d\u57fa\u65bc\u9ad8\u65af\u6563\u5c04\u7684\u6280\u8853\u56e0\u5176\u54c1\u8cea\u548c\u6548\u7387\u800c\u6210\u70ba\u6700\u5148\u9032\u7684\u6280\u8853\u3002\u9ad8\u65af\u6563\u5c04\u5ee3\u6cdb\u7528\u65bc\u5404\u7a2e\u61c9\u7528\u7a0b\u5f0f\uff0c\u5305\u62ec 3D \u4eba\u9ad4\u8868\u793a\u3002\u7136\u800c\uff0c\u5148\u524d\u7684 3D \u9ad8\u65af\u6563\u5c04\u65b9\u6cd5\u4e0d\u662f\u5c07\u53c3\u6578\u5316\u8eab\u9ad4\u6a21\u578b\u7528\u4f5c\u984d\u5916\u8cc7\u8a0a\uff0c\u5c31\u662f\u7121\u6cd5\u63d0\u4f9b\u4efb\u4f55\u57fa\u790e\u7d50\u69cb\uff0c\u4f8b\u5982\u4eba\u9ad4\u751f\u7269\u529b\u5b78\u7279\u5fb5\uff0c\u800c\u9019\u4e9b\u7279\u5fb5\u5c0d\u65bc\u4e0d\u540c\u7684\u61c9\u7528\u7a0b\u5f0f\u81f3\u95dc\u91cd\u8981\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u7a31\u70ba HFGaussian \u7684\u65b0\u65b9\u6cd5\uff0c\u5b83\u53ef\u4ee5\u5f9e\u7a00\u758f\u8f38\u5165\u5f71\u50cf\u4e2d\u5373\u6642\u4f30\u8a08\u65b0\u8996\u5716\u548c\u4eba\u9ad4\u7279\u5fb5\uff0c\u4f8b\u5982 3D \u9aa8\u67b6\u30013D \u95dc\u9375\u9ede\u548c\u5bc6\u96c6\u59ff\u52e2\uff0c\u901f\u5ea6\u70ba 25 FPS\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5229\u7528\u53ef\u6982\u5316\u7684\u9ad8\u65af\u6563\u5c04\u6280\u8853\u4f86\u8868\u793a\u4eba\u9ad4\u53ca\u5176\u76f8\u95dc\u7279\u5fb5\uff0c\u9032\u800c\u5be6\u73fe\u9ad8\u6548\u4e14\u53ef\u6982\u5316\u7684\u91cd\u5efa\u3002\u900f\u904e\u7d50\u5408\u59ff\u52e2\u56de\u6b78\u7db2\u8def\u548c\u7279\u5fb5\u6563\u5c04\u6280\u8853\u8207\u9ad8\u65af\u6563\u5c04\uff0cHFGaussian \u5c55\u73fe\u51fa\u6bd4\u73fe\u6709\u4eba\u9ad4 3D \u65b9\u6cd5\u66f4\u9032\u6b65\u7684\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u6574\u5408\u751f\u7269\u529b\u5b78\u7684 3D \u4eba\u9ad4\u8868\u793a\u7684\u6f5b\u529b\u3002\u6211\u5011\u5fb9\u5e95\u8a55\u4f30\u4e86\u6211\u5011\u7684 HFGaussian \u65b9\u6cd5\uff0c\u4e26\u91dd\u5c0d\u4eba\u9ad4\u9ad8\u65af\u6563\u5c04\u548c\u59ff\u52e2\u4f30\u8a08\u4e2d\u7684\u6700\u65b0\u6700\u5148\u9032\u6280\u8853\uff0c\u5c55\u793a\u4e86\u5176\u5373\u6642\u6700\u5148\u9032\u7684\u6548\u80fd\u3002", "author": "Arnab Dey et.al.", "authors": "Arnab Dey, Cheng-You Lu, Andrew I. Comport, Srinath Sridhar, Chin-Teng Lin, Jean Martinet", "id": "2411.03086v1", "paper_url": "http://arxiv.org/abs/2411.03086v1", "repo": "null"}}