
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-21**|**Efficient Exploration and Discriminative World Model Learning with an Object-Centric Abstraction**|Anthony GX-Chen et.al.|[2408.11816v1](http://arxiv.org/abs/2408.11816v1)|null|
|**2024-08-21**|**Great Memory, Shallow Reasoning: Limits of $k$NN-LMs**|Shangyi Geng et.al.|[2408.11815v1](http://arxiv.org/abs/2408.11815v1)|[link](https://github.com/gsyfate/knnlm-limits)|
|**2024-08-21**|**Approaching Deep Learning through the Spectral Dynamics of Weights**|David Yunis et.al.|[2408.11804v1](http://arxiv.org/abs/2408.11804v1)|[link](https://github.com/dyunis/spectral_dynamics)|
|**2024-08-21**|**PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain**|Rounak Meyur et.al.|[2408.11800v1](http://arxiv.org/abs/2408.11800v1)|null|
|**2024-08-21**|**Practical token pruning for foundation models in few-shot conversational virtual assistant systems**|Haode Qi et.al.|[2408.11799v1](http://arxiv.org/abs/2408.11799v1)|null|
|**2024-08-21**|**LLM Pruning and Distillation in Practice: The Minitron Approach**|Sharath Turuvekere Sreenivas et.al.|[2408.11796v1](http://arxiv.org/abs/2408.11796v1)|null|
|**2024-08-21**|**Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design**|Nathaniel H. Park et.al.|[2408.11793v1](http://arxiv.org/abs/2408.11793v1)|null|
|**2024-08-21**|**DreamFactory: Pioneering Multi-Scene Long Video Generation with a Multi-Agent Framework**|Zhifei Xie et.al.|[2408.11788v1](http://arxiv.org/abs/2408.11788v1)|null|
|**2024-08-21**|**Timeline and Boundary Guided Diffusion Network for Video Shadow Detection**|Haipeng Zhou et.al.|[2408.11785v1](http://arxiv.org/abs/2408.11785v1)|[link](https://github.com/haipengzhou856/tbgdiff)|
|**2024-08-21**|**Personality Alignment of Large Language Models**|Minjun Zhu et.al.|[2408.11779v1](http://arxiv.org/abs/2408.11779v1)|[link](https://github.com/zhu-minjun/palign)|
|**2024-08-21**|**Sum of Squares Circuits**|Lorenzo Loconte et.al.|[2408.11778v1](http://arxiv.org/abs/2408.11778v1)|null|
|**2024-08-21**|**Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards**|Omar Erak et.al.|[2408.11775v1](http://arxiv.org/abs/2408.11775v1)|[link](https://github.com/Nouf-Alabbasi/oKUmura_AI_Telecom_challenge)|
|**2024-08-21**|**D-RMGPT: Robot-assisted collaborative tasks driven by large multimodal models**|M. Forlini et.al.|[2408.11761v1](http://arxiv.org/abs/2408.11761v1)|null|
|**2024-08-21**|**SBDet: A Symmetry-Breaking Object Detector via Relaxed Rotation-Equivariance**|Zhiqiang Wu et.al.|[2408.11760v1](http://arxiv.org/abs/2408.11760v1)|null|
|**2024-08-21**|**Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks**|Yiyi Chen et.al.|[2408.11749v1](http://arxiv.org/abs/2408.11749v1)|null|
|**2024-08-21**|**Open-Ended 3D Point Cloud Instance Segmentation**|Phuc D. A. Nguyen et.al.|[2408.11747v1](http://arxiv.org/abs/2408.11747v1)|null|
|**2024-08-21**|**FocusLLM: Scaling LLM's Context by Parallel Decoding**|Zhenyu Li et.al.|[2408.11745v1](http://arxiv.org/abs/2408.11745v1)|null|
|**2024-08-21**|**JieHua Paintings Style Feature Extracting Model using Stable Diffusion with ControlNet**|Yujia Gu et.al.|[2408.11744v1](http://arxiv.org/abs/2408.11744v1)|null|
|**2024-08-21**|**CluMo: Cluster-based Modality Fusion Prompt for Continual Learning in Visual Question Answering**|Yuliang Cai et.al.|[2408.11742v1](http://arxiv.org/abs/2408.11742v1)|null|
|**2024-08-21**|**Clinical Insights: A Comprehensive Review of Language Models in Medicine**|Nikita Neveditsin et.al.|[2408.11735v1](http://arxiv.org/abs/2408.11735v1)|null|
|**2024-08-21**|**Efficient Detection of Toxic Prompts in Large Language Models**|Yi Liu et.al.|[2408.11727v1](http://arxiv.org/abs/2408.11727v1)|null|
|**2024-08-21**|**Iterative Object Count Optimization for Text-to-image Diffusion Models**|Oz Zafar et.al.|[2408.11721v1](http://arxiv.org/abs/2408.11721v1)|null|
|**2024-08-21**|**Leveraging Large Language Models for Enhancing the Understandability of Generated Unit Tests**|Amirhossein Deljouyi et.al.|[2408.11710v1](http://arxiv.org/abs/2408.11710v1)|null|
|**2024-08-21**|**Physics-informed Discovery of State Variables in Second-Order and Hamiltonian Systems**|FÃ©lix Chavelli et.al.|[2408.11691v1](http://arxiv.org/abs/2408.11691v1)|null|
|**2024-08-21**|**5G NR PRACH Detection with Convolutional Neural Networks (CNN): Overcoming Cell Interference Challenges**|Desire Guel et.al.|[2408.11659v1](http://arxiv.org/abs/2408.11659v1)|null|
|**2024-08-21**|**CIPHER: Cybersecurity Intelligent Penetration-testing Helper for Ethical Researcher**|Derry Pratama et.al.|[2408.11650v1](http://arxiv.org/abs/2408.11650v1)|null|
|**2024-08-21**|**Video-to-Text Pedestrian Monitoring (VTPM): Leveraging Computer Vision and Large Language Models for Privacy-Preserve Pedestrian Activity Monitoring at Intersections**|Ahmed S. Abdelrahman et.al.|[2408.11649v1](http://arxiv.org/abs/2408.11649v1)|null|
|**2024-08-21**|**Data-driven Modeling of Combined Sewer Systems for Urban Sustainability: An Empirical Evaluation**|Vipin Singh et.al.|[2408.11619v1](http://arxiv.org/abs/2408.11619v1)|null|
|**2024-08-21**|**Xinyu: An Efficient LLM-based System for Commentary Generation**|Yiquan Wu et.al.|[2408.11609v1](http://arxiv.org/abs/2408.11609v1)|null|
|**2024-08-21**|**Cause-Aware Empathetic Response Generation via Chain-of-Thought Fine-Tuning**|Xinhao Chen et.al.|[2408.11599v1](http://arxiv.org/abs/2408.11599v1)|null|
|**2024-08-21**|**Active learning for efficient data selection in radio-signal based positioning via deep learning**|Vincent Corlay et.al.|[2408.11592v1](http://arxiv.org/abs/2408.11592v1)|null|
|**2024-08-21**|**Large Language Models are Good Attackers: Efficient and Stealthy Textual Backdoor Attacks**|Ziqiang Li et.al.|[2408.11587v1](http://arxiv.org/abs/2408.11587v1)|null|
|**2024-08-21**|**Drama Engine: A Framework for Narrative Agents**|Martin Pichlmair et.al.|[2408.11574v1](http://arxiv.org/abs/2408.11574v1)|null|
|**2024-08-21**|**Differentiating Choices via Commonality for Multiple-Choice Question Answering**|Wenqing Deng et.al.|[2408.11554v1](http://arxiv.org/abs/2408.11554v1)|[link](https://github.com/dwq-vicki/dcqa)|
|**2024-08-21**|**Explainable Deep Learning Framework for Human Activity Recognition**|Yiran Huang et.al.|[2408.11552v1](http://arxiv.org/abs/2408.11552v1)|null|
|**2024-08-21**|**Memorization In In-Context Learning**|Shahriar Golchin et.al.|[2408.11546v1](http://arxiv.org/abs/2408.11546v1)|null|
|**2024-08-21**|**RConE: Rough Cone Embedding for Multi-Hop Logical Query Answering on Multi-Modal Knowledge Graphs**|Mayank Kharbanda et.al.|[2408.11526v1](http://arxiv.org/abs/2408.11526v1)|[link](https://github.com/kracr/rcone-qa-mmkg)|
|**2024-08-21**|**LARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding**|Zhizhong Wan et.al.|[2408.11523v1](http://arxiv.org/abs/2408.11523v1)|null|
|**2024-08-21**|**Imagining from Images with an AI Storytelling Tool**|Edirlei Soares de Lima et.al.|[2408.11517v1](http://arxiv.org/abs/2408.11517v1)|null|
|**2024-08-21**|**IKUN for WMT24 General MT Task: LLMs Are here for Multilingual Machine Translation**|Baohao Liao et.al.|[2408.11512v1](http://arxiv.org/abs/2408.11512v1)|null|
|**2024-08-21**|**Mutagenesis screen to map the functionals of parameters of Large Language Models**|Yue Hu et.al.|[2408.11494v1](http://arxiv.org/abs/2408.11494v1)|null|
|**2024-08-21**|**Estimating Peer Direct and Indirect Effects in Observational Network Data**|Xiaojing Du et.al.|[2408.11492v1](http://arxiv.org/abs/2408.11492v1)|null|
|**2024-08-21**|**Nothing in Excess: Mitigating the Exaggerated Safety for LLMs via Safety-Conscious Activation Steering**|Zouying Cao et.al.|[2408.11491v1](http://arxiv.org/abs/2408.11491v1)|null|
|**2024-08-21**|**DocTabQA: Answering Questions from Long Documents Using Tables**|Haochen Wang et.al.|[2408.11490v1](http://arxiv.org/abs/2408.11490v1)|null|
|**2024-08-21**|**The Self-Contained Negation Test Set**|David Kletz et.al.|[2408.11469v1](http://arxiv.org/abs/2408.11469v1)|null|
|**2024-08-21**|**Expanding FLORES+ Benchmark for more Low-Resource Settings: Portuguese-Emakhuwa Machine Translation Evaluation**|Felermino D. M. Antonio Ali et.al.|[2408.11457v1](http://arxiv.org/abs/2408.11457v1)|null|
|**2024-08-21**|**Using Part-based Representations for Explainable Deep Reinforcement Learning**|Manos Kirtas et.al.|[2408.11455v1](http://arxiv.org/abs/2408.11455v1)|null|
|**2024-08-21**|**Bidirectional Gated Mamba for Sequential Recommendation**|Ziwei Liu et.al.|[2408.11451v1](http://arxiv.org/abs/2408.11451v1)|[link](https://github.com/ziwliu-cityu/simga)|
|**2024-08-21**|**Enabling Small Models for Zero-Shot Classification through Model Label Learning**|Jia Zhang et.al.|[2408.11449v1](http://arxiv.org/abs/2408.11449v1)|null|
|**2024-08-21**|**Lookism: The overlooked bias in computer vision**|Aditya Gulati et.al.|[2408.11448v1](http://arxiv.org/abs/2408.11448v1)|null|
|**2024-08-21**|**Distributional Properties of Subword Regularization**|Marco Cognetta et.al.|[2408.11443v1](http://arxiv.org/abs/2408.11443v1)|null|
|**2024-08-21**|**LAHAJA: A Robust Multi-accent Benchmark for Evaluating Hindi ASR Systems**|Tahir Javed et.al.|[2408.11440v1](http://arxiv.org/abs/2408.11440v1)|[link](https://github.com/ai4bharat/lahaja)|
|**2024-08-21**|**Towards Aligned Data Removal via Twin Machine Unlearning**|Yuyao Sun et.al.|[2408.11433v1](http://arxiv.org/abs/2408.11433v1)|null|
|**2024-08-21**|**Diagnosing and Remedying Knowledge Deficiencies in LLMs via Label-free Curricular Meaningful Learning**|Kai Xiong et.al.|[2408.11431v1](http://arxiv.org/abs/2408.11431v1)|null|
|**2024-08-21**|**Towards "Differential AI Psychology" and in-context Value-driven Statement Alignment with Moral Foundations Theory**|Simon MÃ¼nker et.al.|[2408.11415v1](http://arxiv.org/abs/2408.11415v1)|null|
|**2024-08-21**|**MoE-LPR: Multilingual Extension of Large Language Models through Mixture-of-Experts with Language Priors Routing**|Hao Zhou et.al.|[2408.11396v1](http://arxiv.org/abs/2408.11396v1)|[link](https://github.com/zjwang21/moe-lpr)|
|**2024-08-21**|**First Activations Matter: Training-Free Methods for Dynamic Activation in Large Language Models**|Chi Ma et.al.|[2408.11393v1](http://arxiv.org/abs/2408.11393v1)|null|
|**2024-08-21**|**Data-Centric Machine Learning for Earth Observation: Necessary and Sufficient Features**|Hiba Najjar et.al.|[2408.11384v1](http://arxiv.org/abs/2408.11384v1)|null|
|**2024-08-21**|**On the Interchangeability of Positional Embeddings in Multilingual Neural Machine Translation Models**|Varun Gumma et.al.|[2408.11382v1](http://arxiv.org/abs/2408.11382v1)|null|
|**2024-08-21**|**RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation**|Xuanwang Zhang et.al.|[2408.11381v1](http://arxiv.org/abs/2408.11381v1)|[link](https://github.com/fate-ubw/raglab)|
|**2024-08-21**|**Reflex-Based Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models**|Kento Kawaharazuka et.al.|[2408.11380v1](http://arxiv.org/abs/2408.11380v1)|null|
|**2024-08-21**|**Denoising Pre-Training and Customized Prompt Learning for Efficient Multi-Behavior Sequential Recommendation**|Hao Wang et.al.|[2408.11372v1](http://arxiv.org/abs/2408.11372v1)|null|
|**2024-08-21**|**Solving Decision Theory Problems with Probabilistic Answer Set Programming**|Damiano Azzolini et.al.|[2408.11371v1](http://arxiv.org/abs/2408.11371v1)|null|
|**2024-08-21**|**Graph Classification via Reference Distribution Learning: Theory and Practice**|Zixiao Wang et.al.|[2408.11370v1](http://arxiv.org/abs/2408.11370v1)|null|
|**2024-08-21**|**Towards Probabilistic Inductive Logic Programming with Neurosymbolic Inference and Relaxation**|Fieke Hillerstrom et.al.|[2408.11367v1](http://arxiv.org/abs/2408.11367v1)|null|
|**2024-08-21**|**GeoReasoner: Reasoning On Geospatially Grounded Context For Natural Language Understanding**|Yibo Yan et.al.|[2408.11366v1](http://arxiv.org/abs/2408.11366v1)|null|
|**2024-08-21**|**ProteinGPT: Multimodal LLM for Protein Property Prediction and Structure Understanding**|Yijia Xiao et.al.|[2408.11363v1](http://arxiv.org/abs/2408.11363v1)|null|
|**2024-08-21**|**Hypergraph Learning based Recommender System for Anomaly Detection, Control and Optimization**|Sakhinana Sagar Srinivas et.al.|[2408.11359v1](http://arxiv.org/abs/2408.11359v1)|null|
|**2024-08-21**|**One-step Structure Prediction and Screening for Protein-Ligand Complexes using Multi-Task Geometric Deep Learning**|Kelei He et.al.|[2408.11356v1](http://arxiv.org/abs/2408.11356v1)|null|
|**2024-08-21**|**Vision HgNN: An Electron-Micrograph is Worth Hypergraph of Hypernodes**|Sakhinana Sagar Srinivas et.al.|[2408.11351v1](http://arxiv.org/abs/2408.11351v1)|null|
|**2024-08-21**|**Clinical Context-aware Radiology Report Generation from Medical Images using Transformers**|Sonit Singh et.al.|[2408.11344v1](http://arxiv.org/abs/2408.11344v1)|null|
|**2024-08-21**|**Automatic Dataset Construction (ADC): Sample Collection, Data Curation, and Beyond**|Minghao Liu et.al.|[2408.11338v1](http://arxiv.org/abs/2408.11338v1)|null|
|**2024-08-21**|**BURExtract-Llama: An LLM for Clinical Concept Extraction in Breast Ultrasound Reports**|Yuxuan Chen et.al.|[2408.11334v1](http://arxiv.org/abs/2408.11334v1)|null|
|**2024-08-21**|**Design Principle Transfer in Neural Architecture Search via Large Language Models**|Xun Zhou et.al.|[2408.11330v1](http://arxiv.org/abs/2408.11330v1)|null|
|**2024-08-21**|**Plug, Play, and Fuse: Zero-Shot Joint Decoding via Word-Level Re-ranking Across Diverse Vocabularies**|Sai Koneru et.al.|[2408.11327v1](http://arxiv.org/abs/2408.11327v1)|null|
|**2024-08-21**|**Automating Thought of Search: A Journey Towards Soundness and Completeness**|Daniel Cao et.al.|[2408.11326v1](http://arxiv.org/abs/2408.11326v1)|null|
|**2024-08-21**|**Towards Evaluating Large Language Models on Sarcasm Understanding**|Yazhou Zhang et.al.|[2408.11319v1](http://arxiv.org/abs/2408.11319v1)|null|
|**2024-08-21**|**Probabilistic Medical Predictions of Large Language Models**|Bowen Gu et.al.|[2408.11316v1](http://arxiv.org/abs/2408.11316v1)|null|
|**2024-08-21**|**Unlocking Adversarial Suffix Optimization Without Affirmative Phrases: Efficient Black-box Jailbreaking via LLM as Optimizer**|Weipeng Jiang et.al.|[2408.11313v1](http://arxiv.org/abs/2408.11313v1)|[link](https://github.com/lenijwp/eclipse)|
|**2024-08-21**|**Swarm Intelligence in Geo-Localization: A Multi-Agent Large Vision-Language Model Collaborative Framework**|Xiao Han et.al.|[2408.11312v1](http://arxiv.org/abs/2408.11312v1)|null|
|**2024-08-21**|**EEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models**|Chongwen Zhao et.al.|[2408.11308v1](http://arxiv.org/abs/2408.11308v1)|null|
|**2024-08-21**|**KAN4TSF: Are KAN and KAN-based models Effective for Time Series Forecasting?**|Xiao Han et.al.|[2408.11306v1](http://arxiv.org/abs/2408.11306v1)|[link](https://github.com/2448845600/kan4tsf)|
|**2024-08-21**|**UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation**|Xiangyu Zhao et.al.|[2408.11305v1](http://arxiv.org/abs/2408.11305v1)|[link](https://github.com/xiangyu-mm/unifashion)|
|**2024-08-21**|**Offline Policy Learning via Skill-step Abstraction for Long-horizon Goal-Conditioned Tasks**|Donghoon Kim et.al.|[2408.11300v1](http://arxiv.org/abs/2408.11300v1)|null|
|**2024-08-21**|**RePair: Automated Program Repair with Process-based Feedback**|Yuze Zhao et.al.|[2408.11296v1](http://arxiv.org/abs/2408.11296v1)|[link](https://github.com/tntwow/repair)|
|**2024-08-21**|**RedWhale: An Adapted Korean LLM Through Efficient Continual Pretraining**|Anh-Dung Vo et.al.|[2408.11294v1](http://arxiv.org/abs/2408.11294v1)|null|
|**2024-08-21**|**Applying and Evaluating Large Language Models in Mental Health Care: A Scoping Review of Human-Assessed Generative Tasks**|Yining Hua et.al.|[2408.11288v1](http://arxiv.org/abs/2408.11288v1)|null|
|**2024-08-21**|**Inference Plans for Hybrid Particle Filtering**|Ellie Y. Cheng et.al.|[2408.11283v1](http://arxiv.org/abs/2408.11283v1)|null|
|**2024-08-21**|**BearLLM: A Prior Knowledge-Enhanced Bearing Health Management Framework with Unified Vibration Signal Representation**|Haotian Peng et.al.|[2408.11281v1](http://arxiv.org/abs/2408.11281v1)|[link](https://github.com/hatton613/bearllm)|
|**2024-08-21**|**Towards Analyzing and Mitigating Sycophancy in Large Vision-Language Models**|Yunpu Zhao et.al.|[2408.11261v1](http://arxiv.org/abs/2408.11261v1)|null|
|**2024-08-21**|**Improving Speech Recognition Error Prediction for Modern and Off-the-shelf Speech Recognizers**|Prashant Serai et.al.|[2408.11258v1](http://arxiv.org/abs/2408.11258v1)|null|
|**2024-08-21**|**Automatic Image Annotation (AIA) of AlmondNet-20 Method for Almond Detection by Improved CNN-based Model**|Mohsen Asghari Ilani et.al.|[2408.11253v1](http://arxiv.org/abs/2408.11253v1)|null|
|**2024-08-21**|**Counterfactuals As a Means for Evaluating Faithfulness of Attribution Methods in Autoregressive Language Models**|Sepehr Kamahi et.al.|[2408.11252v1](http://arxiv.org/abs/2408.11252v1)|null|
|**2024-08-20**|**The Dilemma of Uncertainty Estimation for General Purpose AI in the EU AI Act**|Matias Valdenegro-Toro et.al.|[2408.11249v1](http://arxiv.org/abs/2408.11249v1)|null|
|**2024-08-20**|**Unboxing Occupational Bias: Grounded Debiasing LLMs with U.S. Labor Data**|Atmika Gorti et.al.|[2408.11247v1](http://arxiv.org/abs/2408.11247v1)|null|
|**2024-08-20**|**Do Neural Scaling Laws Exist on Graph Self-Supervised Learning?**|Qian Ma et.al.|[2408.11243v1](http://arxiv.org/abs/2408.11243v1)|[link](https://github.com/graphsslscaling/graphsslscaling)|
|**2024-08-20**|**A Little Confidence Goes a Long Way**|John Scoville et.al.|[2408.11239v1](http://arxiv.org/abs/2408.11239v1)|null|
|**2024-08-20**|**Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification**|Christos Constantinou et.al.|[2408.11237v1](http://arxiv.org/abs/2408.11237v1)|null|
|**2024-08-20**|**Unified Deep Learning Model for Global Prediction of Aboveground Biomass, Canopy Height and Cover from High-Resolution, Multi-Sensor Satellite Imagery**|Manuel Weber et.al.|[2408.11234v1](http://arxiv.org/abs/2408.11234v1)|null|
|**2024-08-20**|**OCTCube: A 3D foundation model for optical coherence tomography that improves cross-dataset, cross-disease, cross-device and cross-modality analysis**|Zixuan Liu et.al.|[2408.11227v1](http://arxiv.org/abs/2408.11227v1)|null|

#### Abstracts
##### **Efficient Exploration and Discriminative World Model Learning with an Object-Centric Abstraction**
2408.11816v1 by Anthony GX-Chen, Kenneth Marino, Rob Fergus

In the face of difficult exploration problems in reinforcement learning, we
study whether giving an agent an object-centric mapping (describing a set of
items and their attributes) allow for more efficient learning. We found this
problem is best solved hierarchically by modelling items at a higher level of
state abstraction to pixels, and attribute change at a higher level of temporal
abstraction to primitive actions. This abstraction simplifies the transition
dynamic by making specific future states easier to predict. We make use of this
to propose a fully model-based algorithm that learns a discriminative world
model, plans to explore efficiently with only a count-based intrinsic reward,
and can subsequently plan to reach any discovered (abstract) states.
  We demonstrate the model's ability to (i) efficiently solve single tasks,
(ii) transfer zero-shot and few-shot across item types and environments, and
(iii) plan across long horizons. Across a suite of 2D crafting and MiniHack
environments, we empirically show our model significantly out-performs
state-of-the-art low-level methods (without abstraction), as well as performant
model-free and model-based methods using the same abstraction. Finally, we show
how to reinforce learn low level object-perturbing policies, as well as
supervise learn the object mapping itself.

æè¦ï¼å¨å¼ºåå­¦ä¹ ä¸­é¢å¯¹å°é¾çæ¢ç´¢é®é¢æ¶ï¼æä»¬ç ç©¶ç»äºä»£çä¸ä¸ªä»¥å¯¹è±¡ä¸ºä¸­å¿çæ å°ï¼æè¿°ä¸ç»é¡¹ç®åå¶å±æ§ï¼æ¯å¦åè®¸æ´ææççå­¦ä¹ ãæä»¬åç°ï¼æ­¤é®é¢æéåéè¿å¨æ´é«å±æ¬¡çç¶ææ½è±¡ä¸­å°é¡¹ç®å»ºæ¨¡ä¸ºåç´ ï¼å¹¶å°å±æ§æ´æ¹å»ºæ¨¡ä¸ºåå§å¨ä½çæ´é«å±æ¬¡çæ¶é´æ½è±¡ï¼ä»èåå±è§£å³ãè¿ç§æ½è±¡éè¿ä½¿ç¹å®çæªæ¥ç¶ææ´å®¹æé¢æµæ¥ç®åè½¬æ¢å¨æãæä»¬å©ç¨è¿ä¸ç¹æåºäºä¸ä¸ªåºäºæ¨¡åçç®æ³ï¼è¯¥ç®æ³å­¦ä¹ å¤å«æ§ä¸çæ¨¡åï¼è®¡åä»ä½¿ç¨åºäºè®¡æ°çåå¨å¥å±ææå°è¿è¡æ¢ç´¢ï¼å¹¶éåè®¡åè¾¾å°ä»»ä½åç°çï¼æ½è±¡ï¼ç¶æãæä»¬å±ç¤ºäºè¯¥æ¨¡åçè½åï¼åæ¬ï¼(i) ææå°è§£å³åä¸ä»»å¡ï¼(ii) å¨é¡¹ç®ç±»ååç¯å¢ä¸­è½¬ç§»é¶æ¬¡åå°æ¬¡ï¼ä»¥å (iii) å¨è¾é¿çèå´åè¿è¡è®¡åãå¨ 2D å¶ä½å MiniHack ç¯å¢å¥ä»¶ä¸­ï¼æä»¬éè¿å®è¯è¡¨æï¼æä»¬çæ¨¡åææ¾ä¼äºæåè¿çä½çº§æ¹æ³ï¼æ²¡ææ½è±¡ï¼ï¼ä»¥åä½¿ç¨ç¸åæ½è±¡çé«æ§è½æ æ¨¡åååºäºæ¨¡åçæ¹æ³ãæåï¼æä»¬å±ç¤ºäºå¦ä½å¼ºåå­¦ä¹ ä½çº§å¯¹è±¡æ°å¨ç­ç¥ï¼ä»¥åçç£å­¦ä¹ å¯¹è±¡æ å°æ¬èº«ã

##### **Great Memory, Shallow Reasoning: Limits of $k$NN-LMs**
2408.11815v1 by Shangyi Geng, Wenting Zhao, Alexander M Rush

$K$-nearest neighbor language models ($k$NN-LMs), which integrate retrieval
with next-word prediction, have demonstrated strong performance in language
modeling as well as downstream NLP benchmarks. These results have led
researchers to argue that models trained on poor quality or outdated data could
perform well by employing a $k$NN extension that has access to a higher-quality
datastore. In this work, we ask whether this improved ability to recall
information really translates into downstream abilities. We extensively
evaluate $k$NN-LMs on a diverse set of tasks, ranging from sentiment
classification and commonsense reasoning to multi-hop reasoning. Results show
that $k$NN-LMs excel at memory-intensive tasks, where utilizing the patterns in
the input is sufficient for determining the output, but struggle with reasoning
tasks that require integrating multiple pieces of information to derive new
knowledge. We further demonstrate through oracle experiments and qualitative
analysis that even with perfect retrieval, $k$NN-LMs still fail to determine
the correct answers, placing an upper bound on their reasoning performance.
Code and datastores are released at https://github.com/GSYfate/knnlm-limits/.

æè¦ï¼$K$-è¿é»è¯­è¨æ¨¡å ($k$NN-LMs) å°æ£ç´¢ä¸ä¸ä¸ä¸ªè¯é¢æµæ´åå¨ä¸èµ·ï¼å¨è¯­è¨å»ºæ¨¡ä»¥åä¸æ¸¸ NLP åºåæµè¯ä¸­è¡¨ç°åºäºå¼ºå¤§çæ§è½ãè¿äºç»æä¿ä½¿ç ç©¶äººåäºè®ºè¯´ï¼éè¿ä½¿ç¨å¯ä»¥è®¿é®æ´é«è´¨éæ°æ®å­å¨ç $k$NN æ©å±ï¼å¨ä½è´¨éæè¿æ¶æ°æ®ä¸è®­ç»çæ¨¡åå¯ä»¥è¡¨ç°è¯å¥½ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬è¯¢é®è¿ç§æ¹è¿çä¿¡æ¯å¬åè½åæ¯å¦ççè½¬åä¸ºä¸æ¸¸è½åãæä»¬å¨åç§ä»»å¡ä¸å¹¿æ³è¯ä¼°äº $k$NN-LMsï¼ä»ææåç±»åå¸¸è¯æ¨çå°å¤è·³æ¨çãç»æè¡¨æï¼$k$NN-LMs å¨åå­å¯éåä»»å¡ä¸­è¡¨ç°åºè²ï¼å¶ä¸­å©ç¨è¾å¥ä¸­çæ¨¡å¼è¶³ä»¥ç¡®å®è¾åºï¼ä½å¨æ¨çä»»å¡ä¸­éå°äºå°é¾ï¼è¿äºä»»å¡éè¦æ´åå¤æ¡ä¿¡æ¯æ¥æ¨å¯¼åºæ°ç¥è¯ãæä»¬éè¿ç¥è°å®éªåå®æ§åæè¿ä¸æ­¥è¯æï¼å³ä½¿å¨å®ç¾çæ£ç´¢ä¸ï¼$k$NN-LMs ä»ç¶æ æ³ç¡®å®æ­£ç¡®çç­æ¡ï¼ä»èä¸ºå¶æ¨çæ§è½è®¾å®äºä¸éãä»£ç åæ°æ®å­å¨å·²å¨ https://github.com/GSYfate/knnlm-limits/ åå¸ã

##### **Approaching Deep Learning through the Spectral Dynamics of Weights**
2408.11804v1 by David Yunis, Kumar Kshitij Patel, Samuel Wheeler, Pedro Savarese, Gal Vardi, Karen Livescu, Michael Maire, Matthew R. Walter

We propose an empirical approach centered on the spectral dynamics of weights
-- the behavior of singular values and vectors during optimization -- to unify
and clarify several phenomena in deep learning. We identify a consistent bias
in optimization across various experiments, from small-scale ``grokking'' to
large-scale tasks like image classification with ConvNets, image generation
with UNets, speech recognition with LSTMs, and language modeling with
Transformers. We also demonstrate that weight decay enhances this bias beyond
its role as a norm regularizer, even in practical systems. Moreover, we show
that these spectral dynamics distinguish memorizing networks from generalizing
ones, offering a novel perspective on this longstanding conundrum.
Additionally, we leverage spectral dynamics to explore the emergence of
well-performing sparse subnetworks (lottery tickets) and the structure of the
loss surface through linear mode connectivity. Our findings suggest that
spectral dynamics provide a coherent framework to better understand the
behavior of neural networks across diverse settings.

æè¦ï¼æåæåºä¸åå°æ³¨æ¼æ¬éåè­åæçç¶é©æ¹æ³ï¼åæ¬æä½³åéç¨ä¸­å¥ç°å¼ååéçè¡çºï¼ä»¥çµ±ä¸åéæ¸æ·±åº¦å­¸ç¿ä¸­çå¹¾åç¾è±¡ãæåå¨åç¨®å¯¦é©ä¸­ç¼ç¾æä½³åçæçºåå·®ï¼å¾å°è¦æ¨¡çãçè§£ãå°ä½¿ç¨ ConvNet çå¤§è¦æ¨¡å½±ååé¡ä»»åãä½¿ç¨ UNet çå½±åç¢çãä½¿ç¨ LSTM çèªé³è¾¨è­ï¼ä»¥åä½¿ç¨ Transformer çèªè¨æ¨¡åãæåä¹ç¤ºç¯æ¬éè¡°æ¸æå¼·åéç¨®åå·®ï¼è¶è¶å¶ä½çºç¯ä¾æ­£ååçè§è²ï¼å³ä½¿å¨å¯¦éçç³»çµ±ä¸­ä¹æ¯å¦æ­¤ãæ­¤å¤ï¼æåé¡¯ç¤ºéäºåè­åæå°è¨æ¶ç¶²è·¯èæ¦æ¬ç¶²è·¯ååéä¾ï¼æä¾äºä¸åéæ¼éåé·æé£é¡çæ°è§é»ãæ­¤å¤ï¼æåå©ç¨åè­åæä¾æ¢ç´¢æè½è¯å¥½çç¨çå­ç¶²è·¯ï¼æ¨éå¸ï¼çåºç¾ï¼ä»¥åééç·æ§æ¨¡å¼é£éæ§äºè§£æå¤±æ²é¢ççµæ§ãæåçç¼ç¾è¡¨æï¼åè­åææä¾äºä¸åé£è²«çæ¶æ§ï¼ä»¥ä¾¿å¨ä¸åçè¨­å®ä¸­æ´å¥½å°çè§£ç¥ç¶ç¶²è·¯çè¡çºã

##### **PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain**
2408.11800v1 by Rounak Meyur, Hung Phan, Sridevi Wagle, Jan Strube, Mahantesh Halappanavar, Sameera Horawalavithana, Anurag Acharya, Sai Munikoti

In the rapidly evolving landscape of Natural Language Processing (NLP) and
text generation, the emergence of Retrieval Augmented Generation (RAG) presents
a promising avenue for improving the quality and reliability of generated text
by leveraging information retrieved from user specified database. Benchmarking
is essential to evaluate and compare the performance of the different RAG
configurations in terms of retriever and generator, providing insights into
their effectiveness, scalability, and suitability for the specific domain and
applications. In this paper, we present a comprehensive framework to generate a
domain relevant RAG benchmark. Our framework is based on automatic
question-answer generation with Human (domain experts)-AI Large Language Model
(LLM) teaming. As a case study, we demonstrate the framework by introducing
PermitQA, a first-of-its-kind benchmark on the wind siting and permitting
domain which comprises of multiple scientific documents/reports related to
environmental impact of wind energy projects. Our framework systematically
evaluates RAG performance using diverse metrics and multiple question types
with varying complexity level. We also demonstrate the performance of different
models on our benchmark.

æè¦ï¼å¨èªç¶èªè¨èç (NLP) åææ¬çæå¿«éæ¼é²çé åä¸­ï¼æª¢ç´¢å¢å¼·çæ (RAG) çåºç¾æä¾äºä¸åæåæ¯çæ¹æ³ï¼ééå©ç¨å¾ä½¿ç¨èæå®çè³æåº«ä¸­æª¢ç´¢çè³è¨ä¾æåçææå­çåè³ªåå¯é æ§ãåºæºæ¸¬è©¦å°æ¼è©ä¼°åæ¯è¼ä¸å RAG çµæå¨æª¢ç´¢å¨åçæå¨æ¹é¢çæè½è³ééè¦ï¼æä¾å°å¶å¨ç¹å®é ååæç¨ä¸­çæææ§ãå¯æ´åæ§åé©ç¨æ§çè¦è§£ãå¨æ¬æä¸­ï¼æåæåºä¸åå¨é¢çæ¶æ§ä¾ç¢çèé åç¸éç RAG åºæºæ¸¬è©¦ãæåçæ¶æ§åºæ¼èªååç­çæï¼ç±äººé¡ (é åå°å®¶) åå¤§åèªè¨æ¨¡å (LLM) åéåä½ãä½çºä¸åæ¡ä¾ç ç©¶ï¼æåééä»ç´¹ PermitQA ä¾å±ç¤ºéåæ¶æ§ï¼PermitQA æ¯ç¬¬ä¸åéå°é¢¨å ´é¸ååè¨±å¯é åçåºæºæ¸¬è©¦ï¼å¶ä¸­åå«å¤ä»½èé¢¨è½å°æ¡ç°å¢å½±é¿ç¸éçç§å­¸æä»¶/å ±åãæåçæ¶æ§ä½¿ç¨ä¸åçææ¨åå¤ç¨®é¡åçåé¡ï¼ä¸¦å·æä¸åçè¤éç¨åº¦ï¼ç³»çµ±æ§å°è©ä¼° RAG æè½ãæåéå¨æåçåºæºæ¸¬è©¦ä¸­å±ç¤ºäºä¸åæ¨¡åçæè½ã

##### **Practical token pruning for foundation models in few-shot conversational virtual assistant systems**
2408.11799v1 by Haode Qi, Cheng Qian, Jian Ni, Pratyush Singh, Reza Fazeli, Gengyu Wang, Zhongzheng Shu, Eric Wayne, Juergen Bross

In an enterprise Virtual Assistant (VA) system, intent classification is the
crucial component that determines how a user input is handled based on what the
user wants. The VA system is expected to be a cost-efficient SaaS service with
low training and inference time while achieving high accuracy even with a small
number of training samples. We pretrain a transformer-based sentence embedding
model with a contrastive learning objective and leverage the embedding of the
model as features when training intent classification models. Our approach
achieves the state-of-the-art results for few-shot scenarios and performs
better than other commercial solutions on popular intent classification
benchmarks. However, generating features via a transformer-based model
increases the inference time, especially for longer user inputs, due to the
quadratic runtime of the transformer's attention mechanism. On top of model
distillation, we introduce a practical multi-task adaptation approach that
configures dynamic token pruning without the need for task-specific training
for intent classification. We demonstrate that this approach improves the
inference speed of popular sentence transformer models without affecting model
performance.

æè¦ï¼å¨ä¼æ¥­èæ¬å©ç (VA) ç³»çµ±ä¸­ï¼æååé¡æ¯åºæ¼ä½¿ç¨èæ³è¦ä»éº¼ä¾æ±ºå®å¦ä½èçä½¿ç¨èè¼¸å¥çééµçµæé¨åãVA ç³»çµ±é è¨å°æçºå·æä½è¨ç·´åæ¨çæéçé«ææ¬æç SaaS æåï¼å³ä½¿è¨ç·´æ¨£æ¬æ¸éå¾å°ä¹è½éå°é«æºç¢ºåº¦ãæåä½¿ç¨å°æ¯å­¸ç¿ç®æ¨é è¨ç·´åºæ¼è½æå¨çå¥å­åµå¥æ¨¡åï¼ä¸¦å¨è¨ç·´æååé¡æ¨¡åæå©ç¨æ¨¡åçåµå¥ä½çºç¹å¾µãæåçåæ³éå°äºå°éå ´æ¯çææ°çµæï¼ä¸¦ä¸å¨æµè¡çæååé¡åºæºä¸åªæ¼å¶ä»åæ¥­è§£æ±ºæ¹æ¡ãç¶èï¼ééåºæ¼è½æå¨çæ¨¡åçæç¹å¾µæå¢å æ¨çæéï¼ç¹å¥æ¯å°æ¼è¼é·çä½¿ç¨èè¼¸å¥ï¼éæ¯ç±æ¼è½æå¨æ³¨æåæ©å¶çäºæ¬¡å·è¡æéãå¨æ¨¡åè¸é¤¾ä¹ä¸ï¼æåå¼å¥äºä¸ç¨®å¯¦ç¨çå¤ä»»åé©ææ¹æ³ï¼è©²æ¹æ³éç½®åæä»¤çä¿®åªï¼èç¡ééå°æååé¡é²è¡ç¹å®ä»»åçè¨ç·´ãæåè­æéç¨®æ¹æ³æé«äºæµè¡å¥å­è½æå¨æ¨¡åçæ¨çéåº¦ï¼èä¸æå½±é¿æ¨¡åæè½ã

##### **LLM Pruning and Distillation in Practice: The Minitron Approach**
2408.11796v1 by Sharath Turuvekere Sreenivas, Saurav Muralidharan, Raviraj Joshi, Marcin Chochowski, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Jan Kautz, Pavlo Molchanov

We present a comprehensive report on compressing the Llama 3.1 8B and Mistral
NeMo 12B models to 4B and 8B parameters, respectively, using pruning and
distillation. We explore two distinct pruning strategies: (1) depth pruning and
(2) joint hidden/attention/MLP (width) pruning, and evaluate the results on
common benchmarks from the LM Evaluation Harness. The models are then aligned
with NeMo Aligner and tested in instruct-tuned versions. This approach produces
a compelling 4B model from Llama 3.1 8B and a state-of-the-art
Mistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo
12B. We found that with no access to the original data, it is beneficial to
slightly fine-tune teacher models on the distillation dataset. We open-source
our base model weights on Hugging Face with a permissive license.

æè¦ï¼æåæåºäºä¸ä»½éæ¼ä½¿ç¨åªæåç¥è­è¸é¤¾å° Llama 3.1 8B å Mistral NeMo 12B æ¨¡ååå¥å£ç¸®å° 4B å 8B åæ¸çç¶åå ±åãæåæ¢è¨äºå©ç¨®ä¸åçåªæç­ç¥ï¼(1) æ·±åº¦åªæå (2) è¯åé±è/æ³¨æå/MLP (å¯¬åº¦) åªæï¼ä¸¦å¨ LM è©ä¼°å·¥å·åçå¸¸è¦åºæºä¸è©ä¼°çµæãç¶å¾ä½¿ç¨ NeMo Aligner å°é½æ¨¡åï¼ä¸¦å¨ç¶éå¾®èª¿ççæ¬ä¸­é²è¡æ¸¬è©¦ãéç¨®æ¹æ³å¾ Llama 3.1 8B ç¢çäºä¸åå¼äººæ³¨ç®ç 4B æ¨¡åï¼ä¸¦å¾ Mistral NeMo 12B ç¢çäºä¸åæåé²ç Mistral-NeMo-Minitron-8B (ç°¡ç¨± MN-Minitron-8B) æ¨¡åãæåç¼ç¾ï¼å¨ç¡æ³è¨ªååå§æ¸æçææ³ä¸ï¼å¾®èª¿ç¥è­è¸é¤¾è³æéä¸çæå¸«æ¨¡åæ¯æççãæåå¨ Hugging Face ä¸éæºäºæåçåºç¤æ¨¡åæ¬éï¼ä¸¦éæå¯¬é¬çè¨±å¯è­ã

##### **Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design**
2408.11793v1 by Nathaniel H. Park, Tiffany J. Callahan, James L. Hedrick, Tim Erdmann, Sara Capponi

Molecular property prediction and generative design via deep learning models
has been the subject of intense research given its potential to accelerate
development of new, high-performance materials. More recently, these workflows
have been significantly augmented with the advent of large language models
(LLMs) and systems of LLM-driven agents capable of utilizing pre-trained models
to make predictions in the context of more complex research tasks. While
effective, there is still room for substantial improvement within the agentic
systems on the retrieval of salient information for material design tasks.
Moreover, alternative uses of predictive deep learning models, such as
leveraging their latent representations to facilitate cross-modal retrieval
augmented generation within agentic systems to enable task-specific materials
design, has remained unexplored. Herein, we demonstrate that large, pre-trained
chemistry foundation models can serve as a basis for enabling semantic
chemistry information retrieval for both small-molecules, complex polymeric
materials, and reactions. Additionally, we show the use of chemistry foundation
models in conjunction with image models such as OpenCLIP facilitate
unprecedented queries and information retrieval across multiple
characterization data domains. Finally, we demonstrate the integration of these
systems within multi-agent systems to facilitate structure and
topological-based natural language queries and information retrieval for
complex research tasks.

æè¦ï¼åå­ç¹æ§é æ¸¬åçæè¨­è¨ééæ·±åº¦å­¸ç¿æ¨¡å
ä¸ç´æ¯å¯éç ç©¶çä¸»é¡ï¼å çºå®ææ½åå é
éç¼æ°çé«æ§è½ææãæè¿ï¼éäºå·¥ä½æµç¨
å·²ééå¤§åèªè¨æ¨¡å (LLM) å LLM é©åä»£çç³»çµ±çåºç¾èé¡¯èæ´å¢ï¼éäºç³»çµ±è½å¤ å©ç¨é åè¨ç·´çæ¨¡å
å¨æ´è¤éçç ç©¶ä»»åçèæ¯ä¸é²è¡é æ¸¬ãéç¶
ææï¼ä½ä»£çç³»çµ±å¨æª¢ç´¢ææè¨­è¨ä»»åçé¡¯èè³è¨æ¹é¢ä»æå¤§å¹æ¹åçç©ºéã
æ­¤å¤ï¼é æ¸¬æ§æ·±åº¦å­¸ç¿æ¨¡åçæ¿ä»£ç¨éï¼ä¾å¦
å©ç¨å¶æ½å¨è¡¨ç¤ºä¾ä¿é²è·¨æ¨¡å¼æª¢ç´¢
å¢å¼·ä»£çç³»çµ±ä¸­ççæä»¥å¯¦ç¾ç¹å®ä»»åçææ
è¨­è¨ï¼ä»ç¶æªè¢«æ¢ç´¢ãå¨æ­¤ï¼æåè­æå¤§åé è¨ç·´
åå­¸åºç¤æ¨¡åå¯ä»¥ä½çºåç¨èªç¾©
åå­¸è³è¨æª¢ç´¢çåºç¤ï¼é©ç¨æ¼å°åå­ãè¤éèåç©
ææååæãæ­¤å¤ï¼æåå±ç¤ºäºåå­¸åºç¤
æ¨¡åèååæ¨¡åï¼ä¾å¦ OpenCLIPï¼çµåä½¿ç¨ï¼ä¿é²
è·¨å¤å
è¡¨å¾µè³æç¶²åçç©ºåæ¥è©¢åè³è¨æª¢ç´¢ãæå¾ï¼æåå±ç¤ºäºéäº
ç³»çµ±å¨å¤ä»£çç³»çµ±ä¸­çæ´åï¼ä»¥ä¿é²çµæ§å
åºæ¼ææ²çèªç¶èªè¨æ¥è©¢åè³è¨æª¢ç´¢ï¼ç¨æ¼
è¤éçç ç©¶ä»»åã

##### **DreamFactory: Pioneering Multi-Scene Long Video Generation with a Multi-Agent Framework**
2408.11788v1 by Zhifei Xie, Daniel Tang, Dingwei Tan, Jacques Klein, Tegawend F. Bissyand, Saad Ezzini

Current video generation models excel at creating short, realistic clips, but
struggle with longer, multi-scene videos. We introduce \texttt{DreamFactory},
an LLM-based framework that tackles this challenge. \texttt{DreamFactory}
leverages multi-agent collaboration principles and a Key Frames Iteration
Design Method to ensure consistency and style across long videos. It utilizes
Chain of Thought (COT) to address uncertainties inherent in large language
models. \texttt{DreamFactory} generates long, stylistically coherent, and
complex videos. Evaluating these long-form videos presents a challenge. We
propose novel metrics such as Cross-Scene Face Distance Score and Cross-Scene
Style Consistency Score. To further research in this area, we contribute the
Multi-Scene Videos Dataset containing over 150 human-rated videos.

æè¦ï¼ç¶åçå½±ççææ¨¡åæé·æ¼è£½ä½ç­èé¼çççæ®µï¼ä½å°æ¼è¼é·çå¤å ´æ¯å½±çåæå°é£ãæåä»ç´¹äº \texttt{DreamFactory}ï¼ä¸ååºæ¼ LLM çæ¶æ§ï¼ç¨æ¼æå°æ­¤ææ°ã\texttt{DreamFactory} å©ç¨å¤éä»£çåä½åååééµå½±æ ¼è¿­ä»£è¨­è¨æ¹æ³ï¼ä»¥ç¢ºä¿é·å½±çä¸­çä¸è´æ§åé¢¨æ ¼ãå®å©ç¨æèé (COT) ä¾è§£æ±ºå¤§åèªè¨æ¨¡åä¸­åºæçä¸ç¢ºå®æ§ã\texttt{DreamFactory} æç¢çé·ãé¢¨æ ¼ä¸è´ä¸è¤éçå½±çãè©ä¼°éäºé·ç¯å½±çæ¯ä¸åææ°ãæåæåºäºæ°çææ¨ï¼ä¾å¦è·¨å ´æ¯äººèè·é¢åæ¸åè·¨å ´æ¯é¢¨æ ¼ä¸è´æ§åæ¸ãçºäºé²ä¸æ­¥ç ç©¶éåé åï¼æåæä¾äºåå«è¶é 150 åç±äººé¡è©åçå½±ççå¤å ´æ¯å½±çè³æéã

##### **Timeline and Boundary Guided Diffusion Network for Video Shadow Detection**
2408.11785v1 by Haipeng Zhou, Honqiu Wang, Tian Ye, Zhaohu Xing, Jun Ma, Ping Li, Qiong Wang, Lei Zhu

Video Shadow Detection (VSD) aims to detect the shadow masks with frame
sequence. Existing works suffer from inefficient temporal learning. Moreover,
few works address the VSD problem by considering the characteristic (i.e.,
boundary) of shadow. Motivated by this, we propose a Timeline and Boundary
Guided Diffusion (TBGDiff) network for VSD where we take account of the
past-future temporal guidance and boundary information jointly. In detail, we
design a Dual Scale Aggregation (DSA) module for better temporal understanding
by rethinking the affinity of the long-term and short-term frames for the
clipped video. Next, we introduce Shadow Boundary Aware Attention (SBAA) to
utilize the edge contexts for capturing the characteristics of shadows.
Moreover, we are the first to introduce the Diffusion model for VSD in which we
explore a Space-Time Encoded Embedding (STEE) to inject the temporal guidance
for Diffusion to conduct shadow detection. Benefiting from these designs, our
model can not only capture the temporal information but also the shadow
property. Extensive experiments show that the performance of our approach
overtakes the state-of-the-art methods, verifying the effectiveness of our
components. We release the codes, weights, and results at
\url{https://github.com/haipengzhou856/TBGDiff}.

æè¦ï¼å½±çé°å½±åµæ¸¬ï¼VSDï¼æ¨å¨åµæ¸¬å·æåºåç«æ ¼çé°å½±é®ç½©ãç¾æçä½åå¨æéå­¸ç¿æ¹é¢æçä¸å½°ãæ­¤å¤ï¼å¾å°æä½åééèéé°å½±çç¹å¾µï¼ä¾å¦éçï¼ä¾è§£æ±º VSD åé¡ãæéæ¼æ­¤ï¼æåæåºä¸åæéè»¸åéçå¼å°æ´æ£ï¼TBGDiffï¼ç¶²è·¯ç¨æ¼ VSDï¼å¶ä¸­æååæèééå»åæªä¾çæéæå¼åéçè³è¨ãè©³ç´°ä¾èªªï¼æåè¨­è¨äºä¸åééå°ºåº¦èåï¼DSAï¼æ¨¡çµï¼éééæ°æèé·æåç­æç«æ ¼å°åªè¼¯å½±ççéè¯æ§ï¼ä»¥ç²å¾æ´å¥½çæéçè§£ãæ¥ä¸ä¾ï¼æåå¼å¥é°å½±éçæç¥æ³¨æåï¼SBAAï¼ä¾å©ç¨éç·£èçµ¡ä»¥æ·åé°å½±çç¹å¾µãæ­¤å¤ï¼æåæ¯ç¬¬ä¸åå¨ VSD ä¸­å¼å¥æ´æ£æ¨¡åçäººï¼å¶ä¸­æåæ¢è¨ä½¿ç¨æç©ºç·¨ç¢¼åµå¥ï¼STEEï¼ä¾æ³¨å¥æéæå¼ï¼ä»¥è®æ´æ£å·è¡é°å½±åµæ¸¬ãåçæ¼éäºè¨­è¨ï¼æåçæ¨¡åä¸åè½æ·åæéè³è¨ï¼éè½æ·åé°å½±å±¬æ§ãå»£æ³çå¯¦é©é¡¯ç¤ºï¼æåæ¹æ³çæè½è¶è¶äºæåé²çæ¹æ³ï¼é©è­äºæååä»¶çæææ§ãæåå¨ \url{https://github.com/haipengzhou856/TBGDiff} éåºç¨å¼ç¢¼ãæ¬éåçµæã

##### **Personality Alignment of Large Language Models**
2408.11779v1 by Minjun Zhu, Linyi Yang, Yue Zhang

Current methods for aligning large language models (LLMs) typically aim to
reflect general human values and behaviors, but they often fail to capture the
unique characteristics and preferences of individual users. To address this
gap, we introduce the concept of Personality Alignment. This approach tailors
LLMs' responses and decisions to match the specific preferences of individual
users or closely related groups. Inspired by psychometrics, we created the
Personality Alignment with Personality Inventories (PAPI) dataset, which
includes data from 300,000 real subjects, each providing behavioral preferences
based on the Big Five Personality Factors. This dataset allows us to
quantitatively evaluate the extent to which LLMs can align with each subject's
behavioral patterns. Recognizing the challenges of personality alignments: such
as limited personal data, diverse preferences, and scalability requirements: we
developed an activation intervention optimization method. This method enhances
LLMs' ability to efficiently align with individual behavioral preferences using
minimal data and computational resources. Remarkably, our method, PAS, achieves
superior performance while requiring only 1/5 of the optimization time compared
to DPO, offering practical value for personality alignment. Our work paves the
way for future AI systems to make decisions and reason in truly personality
ways, enhancing the relevance and meaning of AI interactions for each user and
advancing human-centered artificial intelligence.The code has released in
\url{https://github.com/zhu-minjun/PAlign}.

æè¦ï¼ç®åç¨æ¼æ ¡æºå¤§åèªè¨æ¨¡å (LLM) çæ¹æ³éå¸¸æ¨å¨åæ ä¸è¬äººé¡å¹å¼è§åè¡çºï¼ä½å®åå¸¸å¸¸ç¡æ³ææåå¥ä½¿ç¨èçç¨ç¹ç¹å¾µååå¥½ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºåæ§æ ¡æºçæ¦å¿µãæ­¤æ¹æ³æ ¹æåå¥ä½¿ç¨èæå¯åç¸éç¾¤çµçç¹å®åå¥½ä¾èª¿æ´ LLM çåæåæ±ºç­ãåå°å¿çæ¸¬éå­¸çåç¼ï¼æåå»ºç«äºåæ§æ ¡æºèåæ§æ¸å® (PAPI) è³æéï¼å¶ä¸­åå«ä¾èª 30 è¬åçå¯¦åè©¦èçè³æï¼æ¯åäººé½æ ¹æäºå¤§åæ§ç¹è³ªæä¾è¡çºåå¥½ãéåè³æéè®æåè½å¤ å®éè©ä¼° LLM èæ¯ååè©¦èè¡çºæ¨¡å¼çä¸è´ç¨åº¦ãèªè­å°åæ§æ ¡æºçææ°ï¼ä¾å¦åäººè³ææéãåå¥½å¤ååå¯æ´åæ§è¦æ±ï¼æåéç¼äºä¸ç¨®åç¨ä»å¥æä½³åæ¹æ³ãæ­¤æ¹æ³ä½¿ç¨æå°çè³æåéç®è³æºï¼å¢å¼·äº LLM ææå°èåå¥è¡çºåå¥½æ ¡æºçè½åãå¼å¾æ³¨æçæ¯ï¼æåç PAS æ¹æ³è¡¨ç¾åªç°ï¼åæåéè¦ DPO 1/5 çæä½³åæéï¼çºåæ§æ ¡æºæä¾äºå¯¦ç¨çå¹å¼ãæåçç ç©¶çºæªä¾ç AI ç³»çµ±éªè·¯ï¼è®å®åè½å¤ ä»¥çæ­£åæ§åçæ¹å¼ååºæ±ºç­åæ¨çï¼æå AI äºåå°æ¯åä½¿ç¨èçéè¯æ§åæç¾©ï¼ä¸¦ä¿é²ä»¥äººçºä¸­å¿ç AIãç¨å¼ç¢¼å·²ç¼å¸å¨ \url{https://github.com/zhu-minjun/PAlign}ã

##### **Sum of Squares Circuits**
2408.11778v1 by Lorenzo Loconte, Stefan Mengel, Antonio Vergari

Designing expressive generative models that support exact and efficient
inference is a core question in probabilistic ML. Probabilistic circuits (PCs)
offer a framework where this tractability-vs-expressiveness trade-off can be
analyzed theoretically. Recently, squared PCs encoding subtractive mixtures via
negative parameters have emerged as tractable models that can be exponentially
more expressive than monotonic PCs, i.e., PCs with positive parameters only. In
this paper, we provide a more precise theoretical characterization of the
expressiveness relationships among these models. First, we prove that squared
PCs can be less expressive than monotonic ones. Second, we formalize a novel
class of PCs -- sum of squares PCs -- that can be exponentially more expressive
than both squared and monotonic PCs. Around sum of squares PCs, we build an
expressiveness hierarchy that allows us to precisely unify and separate
different tractable model classes such as Born Machines and PSD models, and
other recently introduced tractable probabilistic models by using complex
parameters. Finally, we empirically show the effectiveness of sum of squares
circuits in performing distribution estimation.

æè¦ï¼<paragraph>è¨­è¨æ¯æ´ç²¾ç¢ºä¸ææçæ¨è«çè¡¨éå¼çææ¨¡åæ¯æ©çå¼ ML ä¸­çæ ¸å¿åé¡ãæ©çé»è·¯ (PC) æä¾ä¸åæ¶æ§ï¼å¯ä»¥å¨å¶ä¸­å¾çè«ä¸åæéç¨®å¯è¿½è¹¤æ§èè¡¨éæ§ä¹éçåæ¨ãæè¿ï¼ééè² åæ¸ç·¨ç¢¼æ¸æ³æ··åçå¹³æ¹ PC å·²æçºå¯è¿½è¹¤çæ¨¡åï¼å¶è¡¨éæ§å¯è½æ¯å®èª¿ PCï¼å³åªææ­£åæ¸ç PCï¼é«åºæ¸åãå¨æ¬æä¸­ï¼æåæä¾éäºæ¨¡åä¹éè¡¨éæ§éä¿æ´ç²¾ç¢ºççè«è¡¨å¾µãé¦åï¼æåè­æå¹³æ¹ PC çè¡¨éæ§å¯è½ä½æ¼å®èª¿ PCãå¶æ¬¡ï¼æåå½¢å¼åä¸åæ°ç PC é¡å¥ââå¹³æ¹å PCââå¶è¡¨éæ§å¯è½æ¯å¹³æ¹ PC åå®èª¿ PC é½é«åºæ¸åãå¨å¹³æ¹å PC çå¨åï¼æåå»ºç«ä¸åè¡¨éæ§éå±¤ï¼ä½¿æåè½å¤ ç²¾ç¢ºå°çµ±ä¸åååä¸åçå¯è¿½è¹¤æ¨¡åé¡å¥ï¼ä¾å¦ Born æ©å¨å PSD æ¨¡åï¼ä»¥åå¶ä»æè¿å¼å¥çãä½¿ç¨è¤éåæ¸çå¯è¿½è¹¤æ©çæ¨¡åãæå¾ï¼æåééå¯¦è­é¡¯ç¤ºå¹³æ¹åé»è·¯å¨å·è¡åéä¼°è¨æ¹é¢çæææ§ã</paragraph>

##### **Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards**
2408.11775v1 by Omar Erak, Nouf Alabbasi, Omar Alhussein, Ismail Lotfi, Amr Hussein, Sami Muhaidat, Merouane Debbah

Recent studies show that large language models (LLMs) struggle with technical
standards in telecommunications. We propose a fine-tuned retrieval-augmented
generation (RAG) system based on the Phi-2 small language model (SLM) to serve
as an oracle for communication networks. Our developed system leverages
forward-looking semantic chunking to adaptively determine parsing breakpoints
based on embedding similarity, enabling effective processing of diverse
document formats. To handle the challenge of multiple similar contexts in
technical standards, we employ a re-ranking algorithm to prioritize the most
relevant retrieved chunks. Recognizing the limitations of Phi-2's small context
window, we implement a recent technique, namely SelfExtend, to expand the
context window during inference, which not only boosts the performance but also
can accommodate a wider range of user queries and design requirements from
customers to specialized technicians. For fine-tuning, we utilize the low-rank
adaptation (LoRA) technique to enhance computational efficiency during training
and enable effective fine-tuning on small datasets. Our comprehensive
experiments demonstrate substantial improvements over existing
question-answering approaches in the telecom domain, achieving performance that
exceeds larger language models such as GPT-4 (which is about 880 times larger
in size). This work presents a novel approach to leveraging SLMs for
communication networks, offering a balance of efficiency and performance. This
work can serve as a foundation towards agentic language models for networks.

æè¦ï¼<paragraph>æè¿çç ç©¶è¡¨æï¼å¤§åèªè¨æ¨¡å (LLM) å¨é»ä¿¡æè¡æ¨æºæ¹é¢å­å¨å°é£ãæåæåºä¸ååºæ¼ Phi-2 å°åèªè¨æ¨¡å (SLM) çå¾®èª¿æª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±ï¼ä½çºéä¿¡ç¶²è·¯çé è¨æ©ãæåéç¼çç³»çµ±å©ç¨åç»èªç¾©åå¡ï¼æ ¹æåµå¥ç¸ä¼¼æ§èªé©æå°ç¢ºå®è§£ææ·é»ï¼å¾èææèçå¤æ¨£åçæä»¶æ ¼å¼ãçºäºæå°æè¡æ¨æºä¸­å¤åç¸ä¼¼èªå¢çææ°ï¼æåæ¡ç¨éæ°æåºæ¼ç®æ³ï¼ä»¥åªåèæ®æç¸éçæª¢ç´¢åå¡ãèªè­å° Phi-2 çå°èªå¢è¦çªçéå¶ï¼æåå¯¦ä½äºä¸ç¨®æ°çæè¡ï¼å³ SelfExtendï¼ä»¥å¨æ¨çæéæ´å±èªå¢è¦çªï¼éä¸åæåäºæè½ï¼éè½å®¹ç´æ´å»£æ³çä½¿ç¨èæ¥è©¢åä¾èªå®¢æ¶å°å°æ¥­æè¡äººå¡çè¨­è¨éæ±ãå°æ¼å¾®èª¿ï¼æåå©ç¨ä½ç§©é©æ (LoRA) æè¡ä¾æåè¨ç·´æéçéç®æçï¼ä¸¦å¨å°åè³æéä¸é²è¡ææçå¾®èª¿ãæåå¨é¢çå¯¦é©è­æäºé»ä¿¡é åç¾æåç­æ¹æ³çé¡¯èæ¹é²ï¼éå°äºè¶è¶å¤§åèªè¨æ¨¡åï¼ä¾å¦ GPT-4ï¼å¶å¤§å°ç´çºå¶ 880 åï¼çæè½ãéé å·¥ä½æåºäºä¸ç¨®å©ç¨ SLM ä¾é²è¡éä¿¡ç¶²è·¯çæ°æ¹æ³ï¼å¨æçåæè½ä¹éåå¾å¹³è¡¡ãéé å·¥ä½å¯ä»¥ä½çºç¶²è·¯ä»£çèªè¨æ¨¡åçåºç¤ã</paragraph>

##### **D-RMGPT: Robot-assisted collaborative tasks driven by large multimodal models**
2408.11761v1 by M. Forlini, M. Babcinschi, G. Palmieri, P. Neto

Collaborative robots are increasingly popular for assisting humans at work
and daily tasks. However, designing and setting up interfaces for human-robot
collaboration is challenging, requiring the integration of multiple components,
from perception and robot task control to the hardware itself. Frequently, this
leads to highly customized solutions that rely on large amounts of costly
training data, diverging from the ideal of flexible and general interfaces that
empower robots to perceive and adapt to unstructured environments where they
can naturally collaborate with humans. To overcome these challenges, this paper
presents the Detection-Robot Management GPT (D-RMGPT), a robot-assisted
assembly planner based on Large Multimodal Models (LMM). This system can assist
inexperienced operators in assembly tasks without requiring any markers or
previous training. D-RMGPT is composed of DetGPT-V and R-ManGPT. DetGPT-V,
based on GPT-4V(vision), perceives the surrounding environment through one-shot
analysis of prompted images of the current assembly stage and the list of
components to be assembled. It identifies which components have already been
assembled by analysing their features and assembly requirements. R-ManGPT,
based on GPT-4, plans the next component to be assembled and generates the
robot's discrete actions to deliver it to the human co-worker. Experimental
tests on assembling a toy aircraft demonstrated that D-RMGPT is flexible and
intuitive to use, achieving an assembly success rate of 83% while reducing the
assembly time for inexperienced operators by 33% compared to the manual
process. http://robotics-and-ai.github.io/LMMmodels/

æè¦ï¼åä½æ©å¨äººåå©äººé¡å·¥ä½åæ¥å¸¸ä»»åçæ®åçè¶ä¾è¶é«ãç¶èï¼è¨­è¨åè¨­å®äººæ©åä½ä»é¢å·æææ°æ§ï¼éè¦æ´åå¤ç¨®åä»¶ï¼å¾æç¥åæ©å¨äººä»»åæ§å¶å°ç¡¬é«æ¬èº«ãééå¸¸æå°è´é«åº¦å®¢è£½åçè§£æ±ºæ¹æ¡ï¼ä»°è³´å¤§éæè²´çè¨ç·´è³æï¼åé¢äºéæ´»ä¸éç¨çä»é¢çæ³ï¼èéè³¦è½æ©å¨äººå¨å¯ä»¥èäººé¡èªç¶åä½çéçµæ§åç°å¢ä¸­æç¥åé©æãçºäºåæéäºææ°ï¼æ¬æä»ç´¹äºåµæ¸¬æ©å¨äººç®¡ç GPT (D-RMGPT)ï¼éæ¯ä¸ååºæ¼å¤§åå¤æ¨¡ææ¨¡å (LMM) çæ©å¨äººè¼å©çµè£è¦åå¨ãæ­¤ç³»çµ±å¯ä»¥åå©æ²æç¶é©çæä½å¡é²è¡çµè£ä»»åï¼èç¡éä»»ä½æ¨è¨æååçè¨ç·´ãD-RMGPT ç± DetGPT-V å R-ManGPT çµæãDetGPT-V åºæ¼ GPT-4V(è¦è¦º)ï¼ééå°ç¶åçµè£éæ®µæç¤ºå½±ååè¦çµè£çåä»¶æ¸å®é²è¡ä¸æ¬¡æ§åæï¼ä¾æç¥å¨é­ç°å¢ãå®ééåæåä»¶ç¹å¾µåçµè£éæ±ï¼ä¾è­å¥åªäºåä»¶å·²ç¶çµè£å®æãR-ManGPT åºæ¼ GPT-4ï¼è¦åè¦çµè£çä¸ä¸é åä»¶ï¼ä¸¦ç¢çæ©å¨äººçé¢æ£åä½ï¼å°å¶å³éçµ¦äººé¡åäºãçµè£ç©å·é£æ©çå¯¦é©æ¸¬è©¦è­æï¼D-RMGPT éæ´»ä¸ç´è§æç¨ï¼çµè£æåçéå° 83%ï¼åæèæåç¨åºç¸æ¯ï¼å¯å°æ²æç¶é©çæä½å¡ççµè£æéç¸®ç­ 33%ãhttp://robotics-and-ai.github.io/LMMmodels/

##### **SBDet: A Symmetry-Breaking Object Detector via Relaxed Rotation-Equivariance**
2408.11760v1 by Zhiqiang Wu, Yingjie Liu, Hanlin Dong, Xuan Tang, Jian Yang, Bo Jin, Mingsong Chen, Xian Wei

Introducing Group Equivariant Convolution (GConv) empowers models to explore
symmetries hidden in visual data, improving their performance. However, in
real-world scenarios, objects or scenes often exhibit perturbations of a
symmetric system, specifically a deviation from a symmetric architecture, which
can be characterized by a non-trivial action of a symmetry group, known as
Symmetry-Breaking. Traditional GConv methods are limited by the strict
operation rules in the group space, only ensuring features remain strictly
equivariant under limited group transformations, making it difficult to adapt
to Symmetry-Breaking or non-rigid transformations. Motivated by this, we
introduce a novel Relaxed Rotation GConv (R2GConv) with our defined Relaxed
Rotation-Equivariant group $\mathbf{R}_4$. Furthermore, we propose a Relaxed
Rotation-Equivariant Network (R2Net) as the backbone and further develop the
Symmetry-Breaking Object Detector (SBDet) for 2D object detection built upon
it. Experiments demonstrate the effectiveness of our proposed R2GConv in
natural image classification tasks, and SBDet achieves excellent performance in
object detection tasks with improved generalization capabilities and
robustness.

æè¦ï¼å¼å¥ç¾¤ç­è®å·ç© (GConv) è³¦äºæ¨¡åæ¢ç´¢é±èå¨è¦è¦ºè³æä¸­çå°ç¨±æ§ï¼æåæ¨¡åæè½ãç¶èï¼å¨ç¾å¯¦ä¸çå ´æ¯ä¸­ï¼ç©ä»¶æå ´æ¯ç¶å¸¸å±ç¾å°ç¨±ç³»çµ±çæ¾åï¼ç¹å¥æ¯åé¢å°ç¨±æ¶æ§ï¼éå¯ä»¥ç¨å°ç¨±ç¾¤çéå¹³å¡åä½ä¾è¡¨å¾µï¼ç¨±çºå°ç¨±æ§ç ´ç¼ºãå³çµ±ç GConv æ¹æ³åå°ç¾¤ç©ºéä¸­å´æ ¼çéç®è¦åéå¶ï¼åç¢ºä¿ç¹å¾µå¨æéç¾¤è®æä¸ä¿æå´æ ¼ç­è®ï¼éä½¿å¾é£ä»¥é©æå°ç¨±æ§ç ´ç¼ºæéåæ§è®æãæéæ¼æ­¤ï¼æåå¼å¥äºå·ææåå®ç¾©çé¬å¼æè½ç­è®ç¾¤ $\mathbf{R}_4$ çæ°ç©é¬å¼æè½ GConv (R2GConv)ãæ­¤å¤ï¼æåæåºäºä¸åé¬å¼æè½ç­è®ç¶²è·¯ (R2Net) ä½çºä¸»å¹¹ï¼ä¸¦é²ä¸æ­¥éç¼äºå»ºç«å¨å®ä¸é¢ç 2D ç©ä»¶åµæ¸¬å°ç¨±æ§ç ´ç¼ºç©ä»¶åµæ¸¬å¨ (SBDet)ãå¯¦é©è­æäºæåæåºç R2GConv å¨èªç¶å½±ååé¡ä»»åä¸­çæææ§ï¼è SBDet å¨ç©ä»¶åµæ¸¬ä»»åä¸­éå°äºåªç°çæè½ï¼ä¸¦æåäºæ³åè½ååç©©å¥æ§ã

##### **Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks**
2408.11749v1 by Yiyi Chen, Russa Biswas, Heather Lent, Johannes Bjerva

Large Language Models (LLMs) are susceptible to malicious influence by cyber
attackers through intrusions such as adversarial, backdoor, and embedding
inversion attacks. In response, the burgeoning field of LLM Security aims to
study and defend against such threats. Thus far, the majority of works in this
area have focused on monolingual English models, however, emerging research
suggests that multilingual LLMs may be more vulnerable to various attacks than
their monolingual counterparts. While previous work has investigated embedding
inversion over a small subset of European languages, it is challenging to
extrapolate these findings to languages from different linguistic families and
with differing scripts. To this end, we explore the security of multilingual
LLMs in the context of embedding inversion attacks and investigate
cross-lingual and cross-script inversion across 20 languages, spanning over 8
language families and 12 scripts. Our findings indicate that languages written
in Arabic script and Cyrillic script are particularly vulnerable to embedding
inversion, as are languages within the Indo-Aryan language family. We further
observe that inversion models tend to suffer from language confusion, sometimes
greatly reducing the efficacy of an attack. Accordingly, we systematically
explore this bottleneck for inversion models, uncovering predictable patterns
which could be leveraged by attackers. Ultimately, this study aims to further
the field's understanding of the outstanding security vulnerabilities facing
multilingual LLMs and raise awareness for the languages most at risk of
negative impact from these attacks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å®¹æåå°ç¶²è·¯æ»æèçæ¡æå½±é¿ï¼ä¾å¦å°ææ§ãå¾éååµå¥å¼åè½æ»æç­å¥ä¾µãçºäºè§£æ±ºéååé¡ï¼æ°èç LLM å®å¨é åæ¨å¨ç ç©¶åé²ç¦¦æ­¤é¡å¨èãå°ç®åçºæ­¢ï¼éåé åçå¤§å¤æ¸ç ç©¶é½éä¸­å¨å®èªçè±ææ¨¡åä¸ï¼ç¶èï¼æ°èçç ç©¶è¡¨æï¼å¤èªè¨ LLM å¯è½æ¯å®èªç LLM æ´å®¹æåå°åç¨®æ»æãéç¶ååçç ç©¶å·²ç¶èª¿æ¥äºå°å°æ¸æ­æ´²èªè¨çåµå¥å¼åè½ï¼ä½å¾é£å°éäºç¼ç¾æ¨å»£å°ä¾èªä¸åèªè¨å®¶æä¸å·æä¸åè³æ¬çèªè¨ãçºæ­¤ï¼æåå¨åµå¥å¼åè½æ»æçèæ¯ä¸æ¢è¨å¤èªè¨ LLM çå®å¨æ§ï¼ä¸¦èª¿æ¥è·¨ 20 ç¨®èªè¨çè·¨èªè¨åè·¨è³æ¬åè½ï¼æ¶µèè¶é 8 åèªè¨å®¶æå 12 ç¨®è³æ¬ãæåçç ç©¶çµæè¡¨æï¼ä½¿ç¨é¿æä¼¯æå­åè¥¿éç¾æå­æ¸å¯«çèªè¨ç¹å¥å®¹æåå°åµå¥å¼åè½çå½±é¿ï¼å°æ­èªç³»èªè¨ä¹æ¯å¦æ­¤ãæåé²ä¸æ­¥è§å¯å°ï¼åè½æ¨¡åå¾å¾æåºç¾èªè¨æ··æ·ï¼æææå¤§å¤§éä½æ»æçæåãå æ­¤ï¼æåç³»çµ±å°æ¢è¨äºåè½æ¨¡åçéåç¶é ¸ï¼æ­ç¤ºäºæ»æèå¯ä»¥å©ç¨çå¯é æ¸¬æ¨¡å¼ãæçµï¼æ¬ç ç©¶æ¨å¨é²ä¸æ­¥å æ·±è©²é åå°å¤èªè¨ LLM é¢è¨ççªåºå®å¨æ¼æ´ççè§£ï¼ä¸¦æé«å°éäºæ»ææå®¹æé æè² é¢å½±é¿çèªè¨çèªè­ã

##### **Open-Ended 3D Point Cloud Instance Segmentation**
2408.11747v1 by Phuc D. A. Nguyen, Minh Luu, Anh Tran, Cuong Pham, Khoi Nguyen

Open-Vocab 3D Instance Segmentation methods (OV-3DIS) have recently
demonstrated their ability to generalize to unseen objects. However, these
methods still depend on predefined class names during testing, restricting the
autonomy of agents. To mitigate this constraint, we propose a novel problem
termed Open-Ended 3D Instance Segmentation (OE-3DIS), which eliminates the
necessity for predefined class names during testing. Moreover, we contribute a
comprehensive set of strong baselines, derived from OV-3DIS approaches and
leveraging 2D Multimodal Large Language Models. To assess the performance of
our OE-3DIS system, we introduce a novel Open-Ended score, evaluating both the
semantic and geometric quality of predicted masks and their associated class
names, alongside the standard AP score. Our approach demonstrates significant
performance improvements over the baselines on the ScanNet200 and ScanNet++
datasets. Remarkably, our method surpasses the performance of Open3DIS, the
current state-of-the-art method in OV-3DIS, even in the absence of ground-truth
object class names.

æè¦ï¼éæ¾è©å½ 3D å¯¦ä¾åå²æ¹æ³ (OV-3DIS) æè¿å±ç¤ºäºå®åæ¦æ¬å°æªè¦ç©ä»¶çè½åãç¶èï¼éäºæ¹æ³å¨æ¸¬è©¦æéä»ä¾è³´æ¼é å®ç¾©çé¡å¥åç¨±ï¼éå¶äºä»£ççèªä¸»æ§ãçºäºæ¸è¼éåéå¶ï¼æåæåºäºä¸åæ°åé¡ï¼ç¨±çºéæ¾å¼ 3D å¯¦ä¾åå² (OE-3DIS)ï¼å®æ¶é¤äºæ¸¬è©¦æéé å®ç¾©é¡å¥åç¨±çå¿è¦æ§ãæ­¤å¤ï¼æåè²¢ç»äºä¸çµå¾ OV-3DIS æ¹æ³ä¸­è¡çä¸¦å©ç¨ 2D å¤æ¨¡æå¤§åèªè¨æ¨¡åçå¼·å¤§åºç·ãçºäºè©ä¼°æåç OE-3DIS ç³»çµ±çæè½ï¼æåå¼å¥äºæ°çéæ¾å¼è©åï¼é¤äºæ¨æº AP è©åå¤ï¼éè©ä¼°äºé æ¸¬é®ç½©åå¶ç¸éé¡å¥åç¨±çèªç¾©åå¹¾ä½åè³ªãæåçåæ³å¨ ScanNet200 å ScanNet++ è³æéä¸å±ç¤ºäºæ¯åºç·é¡¯èçæè½æåãå¼å¾æ³¨æçæ¯ï¼æåçæ¨¡åè¶è¶äº Open3DIS çæè½ï¼Open3DIS æ¯ OV-3DIS ä¸­ç®åæåé²çæ¹æ³ï¼å³ä½¿å¨æ²æ ground-truth ç©ä»¶é¡å¥åç¨±çææ³ä¸ä¹æ¯å¦æ­¤ã

##### **FocusLLM: Scaling LLM's Context by Parallel Decoding**
2408.11745v1 by Zhenyu Li, Yike Zhang, Tengyu Pan, Yutao Sun, Zhichao Duan, Junjie Fang, Rong Han, Zixuan Wang, Jianyong Wang

Empowering LLMs with the ability to utilize useful information from a long
context is crucial for many downstream applications. However, achieving long
context lengths with the conventional transformer architecture requires
substantial training and inference resources. In this paper, we present
FocusLLM, a framework designed to extend the context length of any decoder-only
LLM, enabling the model to focus on relevant information from very long
sequences. FocusLLM processes long text inputs by dividing them into chunks
based on the model's original context length to alleviate the issue of
attention distraction. Then, it appends the local context to each chunk as a
prompt to extract essential information from each chunk based on a novel
parallel decoding mechanism, and ultimately integrates the extracted
information into the local context. FocusLLM stands out for great training
efficiency and versatility: trained with an 8K input length with much less
training cost than previous methods, FocusLLM exhibits superior performance
across downstream long-context tasks and maintains strong language modeling
ability when handling extensive long texts, even up to 400K tokens. Our code is
available at https://github.com/leezythu/FocusLLM.

æè¦ï¼è³¦äº LLM å©ç¨é·èªå¢ä¸­æç¨è³è¨çè½åå°æ¼è¨±å¤ä¸æ¸¸æç¨ç¨å¼è³ééè¦ãç¶èï¼ä½¿ç¨å³çµ±ç Transformer æ¶æ§ä¾å¯¦ç¾é·èªå¢é·åº¦éè¦å¤§éçè¨ç·´åæ¨è«è³æºãå¨æ¬æä¸­ï¼æåæåº FocusLLMï¼ä¸åæ¨å¨æ´å±ä»»ä½åè§£ç¢¼å¨ LLM çèªå¢é·åº¦çæ¡æ¶ï¼ä½¿æ¨¡åè½å¤ å°æ³¨æ¼éå¸¸é·çåºåä¸­çç¸éè³è¨ãFocusLLM ééå°é·ææ¬è¼¸å¥åå²æå¡ï¼åºæ¼æ¨¡åçåå§èªå¢é·åº¦ï¼ä¾èçï¼ä»¥æ¸è¼æ³¨æååæ£çåé¡ãç¶å¾ï¼å®å°å±é¨èªå¢éå å°æ¯åå¡ä½çºæç¤ºï¼ä»¥åºæ¼æ°ç©çä¸¦è¡è§£ç¢¼æ©å¶å¾æ¯åå¡ä¸­æåå¿è¦è³è¨ï¼ä¸¦æçµå°æåçè³è¨æ´åå°å±é¨èªå¢ä¸­ãFocusLLM ä»¥å¶åºè²çè¨ç·´æçåå¤åè½æ§èèç¨±ï¼ä½¿ç¨ 8K è¼¸å¥é·åº¦é²è¡è¨ç·´ï¼è¨ç·´ææ¬é ä½æ¼ä»¥åçæ¹æ³ï¼FocusLLM å¨ä¸æ¸¸é·èªå¢ä»»åä¸­è¡¨ç¾åºåªç°çæè½ï¼ä¸¦å¨èçå»£æ³çé·ææ¬ï¼çè³é·é 400K åç¬¦èï¼æä¿æå¼·å¤§çèªè¨å»ºæ¨¡è½åãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/leezythu/FocusLLM åå¾ã

##### **JieHua Paintings Style Feature Extracting Model using Stable Diffusion with ControlNet**
2408.11744v1 by Yujia Gu, Haofeng Li, Xinyu Fang, Zihan Peng, Yinan Peng

This study proposes a novel approach to extract stylistic features of Jiehua:
the utilization of the Fine-tuned Stable Diffusion Model with ControlNet
(FSDMC) to refine depiction techniques from artists' Jiehua. The training data
for FSDMC is based on the opensource Jiehua artist's work collected from the
Internet, which were subsequently manually constructed in the format of
(Original Image, Canny Edge Features, Text Prompt). By employing the optimal
hyperparameters identified in this paper, it was observed FSDMC outperforms
CycleGAN, another mainstream style transfer model. FSDMC achieves FID of 3.27
on the dataset and also surpasses CycleGAN in terms of expert evaluation. This
not only demonstrates the model's high effectiveness in extracting Jiehua's
style features, but also preserves the original pre-trained semantic
information. The findings of this study suggest that the application of FSDMC
with appropriate hyperparameters can enhance the efficacy of the Stable
Diffusion Model in the field of traditional art style migration tasks,
particularly within the context of Jiehua.

æè¦ï¼æ¬ç ç©¶æåºäºä¸åæ°ç©çæ¹æ³ä¾æåçç«çé¢¨æ ¼ç¹å¾µï¼
å©ç¨ç¶éå¾®èª¿ç Stable Diffusion æ¨¡åè ControlNetï¼FSDMCï¼ä¾åªåèè¡å®¶çç«çæç¹ªæå·§ãFSDMC çè¨ç·´è³ææ¯å¾ç¶²è·¯ä¸æ¶éçéæºçç«èè¡å®¶çä½åï¼é¨å¾æåå»ºæ§çºï¼åå§å½±åãCanny éç·£ç¹å¾µãæå­æç¤ºï¼çæ ¼å¼ãééæ¡ç¨æ¬æä¸­ç¢ºå®çæä½³è¶åæ¸ï¼è§å¯å° FSDMC çè¡¨ç¾åªæ¼å¦ä¸ç¨®ä¸»æµé¢¨æ ¼è½ç§»æ¨¡å CycleGANãFSDMC å¨è³æéä¸éå°äº 3.27 ç FIDï¼ä¸¦ä¸å¨å°å®¶è©ä¼°æ¹é¢ä¹è¶è¶äº CycleGANãéä¸åè­æäºè©²æ¨¡åå¨æåçç«é¢¨æ ¼ç¹å¾µæ¹é¢çæè½å¾é«ï¼èä¸éä¿çäºåå§é è¨ç·´çèªç¾©è³è¨ãæ¬ç ç©¶çç¼ç¾è¡¨æï¼å¨å³çµ±èè¡é¢¨æ ¼é·ç§»ä»»åä¸­ï¼ä½¿ç¨å·æé©ç¶è¶åæ¸ç FSDMC å¯ä»¥æé« Stable Diffusion æ¨¡åçæè½ï¼ç¹å¥æ¯å¨çç«çèæ¯ä¸ã

##### **CluMo: Cluster-based Modality Fusion Prompt for Continual Learning in Visual Question Answering**
2408.11742v1 by Yuliang Cai, Mohammad Rostami

Large vision-language models (VLMs) have shown significant performance boost
in various application domains. However, adopting them to deal with several
sequentially encountered tasks has been challenging because finetuning a VLM on
a task normally leads to reducing its generalization power and the capacity of
learning new tasks as well as causing catastrophic forgetting on previously
learned tasks. Enabling using VLMs in multimodal continual learning (CL)
settings can help to address such scenarios. To improve generalization capacity
and prevent catastrophic forgetting, we propose a novel prompt-based CL method
for VLMs, namely $\textbf{Clu}$ster-based $\textbf{Mo}$dality Fusion Prompt
(\textbf{CluMo}). We design a novel \textbf{Key-Key-Prompt} pair, where each
prompt is associated with a visual prompt key and a textual prompt key. We
adopt a two-stage training strategy. During the first stage, the single-modal
keys are trained via $K$-means clustering algorithm to help select the best
semantically matched prompt. During the second stage, the prompt keys are
frozen, the selected prompt is attached to the input for training the VLM in
the CL scenario. Experiments on two benchmarks demonstrate that our method
achieves SOTA performance.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (VLM) å¨åç¨®æç¨é åä¸­å±ç¾åºé¡¯èçæè½æåãç¶èï¼å°å¶ç¨æ¼èçå¤åä¾åºéå°çä»»åä¸ç´å·æææ°æ§ï¼å çºå° VLM é²è¡å¾®èª¿éå¸¸æå°è´å¶æ³åè½åéä½ï¼ä»¥åå­¸ç¿æ°ä»»åçè½åï¼ä¸¦å°è´ååå­¸ç¿ä»»åçç½é£æ§éºå¿ãå¨å¤æ¨¡ææçºå­¸ç¿ (CL) è¨­å®ä¸­åç¨ VLMï¼æå©æ¼è§£æ±ºæ­¤é¡å ´æ¯ãçºäºæ¹åæ³åè½åä¸¦é²æ­¢ç½é£æ§éºå¿ï¼æåéå° VLM æåºäºä¸ç¨®æ°ç©çåºæ¼æç¤ºç CL æ¹æ³ï¼å³åºæ¼ç¾¤éçæ¨¡æèåæç¤º (CluMo)ãæåè¨­è¨äºä¸å°æ°ç©çééµééµæç¤ºï¼å¶ä¸­æ¯åæç¤ºé½èè¦è¦ºæç¤ºééµåææ¬æç¤ºééµç¸éè¯ãæåæ¡ç¨å©éæ®µè¨ç·´ç­ç¥ãå¨ç¬¬ä¸éæ®µä¸­ï¼å®æ¨¡æééµæ¯éé K å¹³åç¾¤éæ¼ç®æ³é²è¡è¨ç·´ï¼ä»¥å¹«å©é¸ææä½³èªç¾©å¹éæç¤ºãå¨ç¬¬äºéæ®µä¸­ï¼æç¤ºééµæè¢«åçµï¼æé¸æç¤ºæéå å°è¼¸å¥ï¼ä»¥è¨ç·´ CL å ´æ¯ä¸­ç VLMãå¨å©ååºæºä¸çå¯¦é©è­æï¼æåçæ¨¡åéå°äº SOTA æè½ã

##### **Clinical Insights: A Comprehensive Review of Language Models in Medicine**
2408.11735v1 by Nikita Neveditsin, Pawan Lingras, Vijay Mago

This paper provides a detailed examination of the advancements and
applications of large language models in the healthcare sector, with a
particular emphasis on clinical applications. The study traces the evolution of
LLMs from their foundational technologies to the latest developments in
domain-specific models and multimodal integration. It explores the technical
progression from encoder-based models requiring fine-tuning to sophisticated
approaches that integrate textual, visual, and auditory data, thereby
facilitating comprehensive AI solutions in healthcare. The paper discusses both
the opportunities these technologies present for enhancing clinical efficiency
and the challenges they pose in terms of ethics, data privacy, and
implementation. Additionally, it critically evaluates the deployment strategies
of LLMs, emphasizing the necessity of open-source models to ensure data privacy
and adaptability within healthcare environments. Future research directions are
proposed, focusing on empirical studies to evaluate the real-world efficacy of
LLMs in healthcare and the development of open datasets for further research.
This review aims to provide a comprehensive resource for both newcomers and
multidisciplinary researchers interested in the intersection of AI and
healthcare.

æè¦ï¼éç¯è«æè©³ç´°æ¢è¨äºå¤§åèªè¨æ¨¡åå¨é«çä¿å¥é åçé²å±åæç¨ï¼ç¹å¥å¼·èª¿è¨åºæç¨ãéé ç ç©¶è¿½æº¯äº LLM å¾å¶åºç¤æè¡å°ç¹å®é åæ¨¡ååå¤æ¨¡ææ´åçææ°ç¼å±ãå®æ¢è¨äºå¾éè¦å¾®èª¿çç·¨ç¢¼å¨æ¨¡åå°æ´åææ¬ãè¦è¦ºåè½è¦ºæ¸æçåé²æ¹æ³çæè¡é²æ­¥ï¼å¾èä¿é²äºé«çä¿å¥ä¸­çå¨é¢ AI è§£æ±ºæ¹æ¡ãéç¯è«æè¨è«äºéäºæè¡å¨æé«è¨åºæçæ¹é¢å¸¶ä¾çæ©éï¼ä»¥åå®åå¨éå¾·ãæ¸æé±ç§åå¯¦æ½æ¹é¢å¸¶ä¾çææ°ãæ­¤å¤ï¼å®æ¹å¤æ§å°è©ä¼°äº LLM çé¨ç½²ç­ç¥ï¼å¼·èª¿äºéæºæ¨¡åå°æ¼ç¢ºä¿é«çä¿å¥ç°å¢ä¸­çæ¸æé±ç§åé©ææ§çå¿è¦æ§ãæåºäºæªä¾çç ç©¶æ¹åï¼éé»æ¯å¯¦è­ç ç©¶ï¼ä»¥è©ä¼° LLM å¨é«çä¿å¥ä¸­çå¯¦éåæåéç¼éæ¾å¼æ¸æéä»¥é²è¡é²ä¸æ­¥çç ç©¶ãéç¯ç¶è¿°æ¨å¨çºå° AI åé«çä¿å¥çäº¤åé»æèè¶£çæ°æåå¤å­¸ç§ç ç©¶äººå¡æä¾å¨é¢çè³æºã

##### **Efficient Detection of Toxic Prompts in Large Language Models**
2408.11727v1 by Yi Liu, Junzhe Yu, Huijia Sun, Ling Shi, Gelei Deng, Yuqi Chen, Yang Liu

Large language models (LLMs) like ChatGPT and Gemini have significantly
advanced natural language processing, enabling various applications such as
chatbots and automated content generation. However, these models can be
exploited by malicious individuals who craft toxic prompts to elicit harmful or
unethical responses. These individuals often employ jailbreaking techniques to
bypass safety mechanisms, highlighting the need for robust toxic prompt
detection methods. Existing detection techniques, both blackbox and whitebox,
face challenges related to the diversity of toxic prompts, scalability, and
computational efficiency. In response, we propose ToxicDetector, a lightweight
greybox method designed to efficiently detect toxic prompts in LLMs.
ToxicDetector leverages LLMs to create toxic concept prompts, uses embedding
vectors to form feature vectors, and employs a Multi-Layer Perceptron (MLP)
classifier for prompt classification. Our evaluation on various versions of the
LLama models, Gemma-2, and multiple datasets demonstrates that ToxicDetector
achieves a high accuracy of 96.39\% and a low false positive rate of 2.00\%,
outperforming state-of-the-art methods. Additionally, ToxicDetector's
processing time of 0.0780 seconds per prompt makes it highly suitable for
real-time applications. ToxicDetector achieves high accuracy, efficiency, and
scalability, making it a practical method for toxic prompt detection in LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ ChatGPT å Geminiï¼å·²å¤§å¹æåèªç¶èªè¨èçï¼æ¯æ´åç¨®æç¨ç¨å¼ï¼ä¾å¦èå¤©æ©å¨äººåèªåç¢çå§å®¹ãç¶èï¼æ¡æäººå£«å¯è½æå©ç¨éäºæ¨¡åï¼å»ºç«ææ¯æç¤ºï¼å¼ç¼æå®³æä¸éå¾·çåæãéäºäººå£«éå¸¸ææ¡ç¨è¶çæè¡ï¼ç¹éå®å¨æ©å¶ï¼çªé¡¯äºå°å¼·å¤§çææ¯æç¤ºåµæ¸¬æ¹æ³çéæ±ãç¾æçåµæ¸¬æè¡ï¼åæ¬é»çåç½çï¼é½é¢è¨èææ¯æç¤ºçå¤æ¨£æ§ãå¯æ´åæ§åéç®æçç¸éçææ°ãçºäºè§£æ±ºéååé¡ï¼æåæåº ToxicDetectorï¼ä¸ç¨®è¼éç´ç°çæ¹æ³ï¼æ¨å¨ææçå°åµæ¸¬ LLM ä¸­çææ¯æç¤ºãToxicDetector èç± LLM å»ºç«ææ¯æ¦å¿µæç¤ºï¼ä½¿ç¨åµå¥åéå½¢æç¹å¾µåéï¼ä¸¦æ¡ç¨å¤å±¤æç¥å¨ (MLP) åé¡å¨é²è¡æç¤ºåé¡ãæåå° LLama æ¨¡åãGemma-2 åå¤åè³æéçåç¨®çæ¬é²è¡è©ä¼°ï¼çµæé¡¯ç¤º ToxicDetector éå° 96.39% çé«æºç¢ºåº¦å 2.00% çä½å½é½æ§çï¼åªæ¼ç¾æçæ¹æ³ãæ­¤å¤ï¼ToxicDetector æ¯åæç¤º 0.0780 ç§çèçæéï¼ä½¿å¶éå¸¸é©åæ¼å³ææç¨ç¨å¼ãToxicDetector éå°é«æºç¢ºåº¦ãæçåå¯æ´åæ§ï¼ä½¿å¶æçº LLM ä¸­ææ¯æç¤ºåµæ¸¬çå¯¦ç¨æ¹æ³ã

##### **Iterative Object Count Optimization for Text-to-image Diffusion Models**
2408.11721v1 by Oz Zafar, Lior Wolf, Idan Schwartz

We address a persistent challenge in text-to-image models: accurately
generating a specified number of objects. Current models, which learn from
image-text pairs, inherently struggle with counting, as training data cannot
depict every possible number of objects for any given object. To solve this, we
propose optimizing the generated image based on a counting loss derived from a
counting model that aggregates an object\'s potential. Employing an
out-of-the-box counting model is challenging for two reasons: first, the model
requires a scaling hyperparameter for the potential aggregation that varies
depending on the viewpoint of the objects, and second, classifier guidance
techniques require modified models that operate on noisy intermediate diffusion
steps. To address these challenges, we propose an iterated online training mode
that improves the accuracy of inferred images while altering the text
conditioning embedding and dynamically adjusting hyperparameters. Our method
offers three key advantages: (i) it can consider non-derivable counting
techniques based on detection models, (ii) it is a zero-shot plug-and-play
solution facilitating rapid changes to the counting techniques and image
generation methods, and (iii) the optimized counting token can be reused to
generate accurate images without additional optimization. We evaluate the
generation of various objects and show significant improvements in accuracy.
The project page is available at https://ozzafar.github.io/count_token.

æè¦ï¼<paragraph>æåè§£æ±ºäºæå­è½ååæ¨¡åä¸­ä¸åæçºçææ°ï¼æºç¢ºçææå®æ¸éçç©ä»¶ãç®åçæ¨¡åå¾å½±åæå­å°å­¸ç¿ï¼å¨è¨ç®ä¸æ¬è³ªä¸æéå°å°é£ï¼å çºè¨ç·´è³æç¡æ³æç¹ªä»»ä½çµ¦å®ç©ä»¶çææå¯è½æ¸éãçºäºè§£æ±ºéååé¡ï¼æåå»ºè­°æ ¹æå¾èåç©ä»¶æ½åçè¨æ¸æ¨¡åè¡ççè¨æ¸æå¤±ä¾æä½³åçæçå½±åãæ¡ç¨ç¾æçè¨æ¸æ¨¡åå·æå©åææ°ï¼é¦åï¼è©²æ¨¡åéè¦ä¸åç¸®æ¾è¶åæ¸ï¼ç¨æ¼æ½åèåï¼è©²è¶åæ¸ææ ¹æç©ä»¶çè§é»èææä¸åï¼å¶æ¬¡ï¼åé¡å¨å¼å°æè¡éè¦ä¿®æ¹æ¨¡åï¼éäºæ¨¡åæå°æéè¨çä¸­éæ´æ£æ­¥é©é²è¡æä½ãçºäºæå°éäºææ°ï¼æåæåºäºä¸ç¨®åè¦çç·ä¸è¨ç·´æ¨¡å¼ï¼è©²æ¨¡å¼å¨æ¹è®æå­æ¢ä»¶åµå¥ååæèª¿æ´è¶åæ¸çåæï¼æåäºæ¨è«å½±åçæºç¢ºåº¦ãæåçæ¨¡åæä¾ä¸åä¸»è¦åªé»ï¼(i) å®å¯ä»¥èæ®åºæ¼åµæ¸¬æ¨¡åçä¸å¯å°åºè¨æ¸æè¡ï¼(ii) å®æ¯ä¸ç¨®é¶æ¬¡å­¸ç¿çå³æå³ç¨è§£æ±ºæ¹æ¡ï¼æå©æ¼å¿«éè®æ´è¨æ¸æè¡åå½±åçææ¹æ³ï¼ä»¥å (iii) æä½³åçè¨æ¸ä»£å¹£å¯ä»¥éè¤ä½¿ç¨ï¼ä»¥å¨æ²æé¡å¤æä½³åçææ³ä¸çææºç¢ºçå½±åãæåè©ä¼°äºåç¨®ç©ä»¶ççæï¼ä¸¦å±ç¤ºäºæºç¢ºåº¦çé¡¯èæåãå°æ¡é é¢å¯æ¼ https://ozzafar.github.io/count_token åå¾ã</paragraph>

##### **Leveraging Large Language Models for Enhancing the Understandability of Generated Unit Tests**
2408.11710v1 by Amirhossein Deljouyi, Roham Koohestani, Maliheh Izadi, Andy Zaidman

Automated unit test generators, particularly search-based software testing
tools like EvoSuite, are capable of generating tests with high coverage.
Although these generators alleviate the burden of writing unit tests, they
often pose challenges for software engineers in terms of understanding the
generated tests. To address this, we introduce UTGen, which combines
search-based software testing and large language models to enhance the
understandability of automatically generated test cases. We achieve this
enhancement through contextualizing test data, improving identifier naming, and
adding descriptive comments. Through a controlled experiment with 32
participants from both academia and industry, we investigate how the
understandability of unit tests affects a software engineer's ability to
perform bug-fixing tasks. We selected bug-fixing to simulate a real-world
scenario that emphasizes the importance of understandable test cases. We
observe that participants working on assignments with UTGen test cases fix up
to 33% more bugs and use up to 20% less time when compared to baseline test
cases. From the post-test questionnaire, we gathered that participants found
that enhanced test names, test data, and variable names improved their
bug-fixing process.

æè¦ï¼èªååå®åæ¸¬è©¦ç¢çå¨ï¼ç¹å¥æ¯å EvoSuite éæ¨£çåºæ¼æå°çè»é«æ¸¬è©¦å·¥å·ï¼è½å¤ ç¢çè¦èçé«çæ¸¬è©¦ã
éç¶éäºç¢çå¨æ¸è¼äºæ°å¯«å®åæ¸¬è©¦çè² æï¼ä½å®åéå¸¸å¨çè§£æç¢ççæ¸¬è©¦æ¹é¢å°è»é«å·¥ç¨å¸«é æææ°ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº UTGenï¼å®çµåäºåºæ¼æå°çè»é«æ¸¬è©¦åå¤§åèªè¨æ¨¡åï¼ä»¥å¢å¼·èªåç¢ççæ¸¬è©¦ç¨ä¾çå¯çè§£æ§ãæåééå°æ¸¬è©¦è³æèçµ¡åãæ¹åè­å¥ç¬¦å½åä»¥åå å¥èªªææ§è¨»è§£ä¾å¯¦ç¾éç¨®å¢å¼·ãééä¸é ç±å­¸è¡çåæ¥­çç 32 ä½åèèé²è¡çåæ§å¯¦é©ï¼æåæ¢è¨å®åæ¸¬è©¦çå¯çè§£æ§å¦ä½å½±é¿è»é«å·¥ç¨å¸«å·è¡é¯èª¤ä¿®å¾©ä»»åçè½åãæåé¸æé¯èª¤ä¿®å¾©ä¾æ¨¡æ¬ä¸åçå¯¦ä¸ççå ´æ¯ï¼å¼·èª¿å¯çè§£çæ¸¬è©¦ç¨ä¾çéè¦æ§ãæåè§å¯å°èç UTGen æ¸¬è©¦ç¨ä¾çåèèä¿®å¾©çé¯èª¤æå¤å¢å äº 33%ï¼èåºæºæ¸¬è©¦ç¨ä¾ç¸æ¯ï¼ä½¿ç¨çæéæå¤æ¸å°äº 20%ãå¾æ¸¬è©¦å¾çåå·ä¸­ï¼æåæ¶éå°åèèç¼ç¾å¢å¼·çæ¸¬è©¦åç¨±ãæ¸¬è©¦è³æåè®æ¸åç¨±æ¹åäºä»åçé¯èª¤ä¿®å¾©æµç¨ã

##### **Physics-informed Discovery of State Variables in Second-Order and Hamiltonian Systems**
2408.11691v1 by FÃ©lix Chavelli, Zi-Yu Khoo, Dawen Wu, Jonathan Sze Choong Low, StÃ©phane Bressan

The modeling of dynamical systems is a pervasive concern for not only
describing but also predicting and controlling natural phenomena and engineered
systems. Current data-driven approaches often assume prior knowledge of the
relevant state variables or result in overparameterized state spaces. Boyuan
Chen and his co-authors proposed a neural network model that estimates the
degrees of freedom and attempts to discover the state variables of a dynamical
system. Despite its innovative approach, this baseline model lacks a connection
to the physical principles governing the systems it analyzes, leading to
unreliable state variables.
  This research proposes a method that leverages the physical characteristics
of second-order Hamiltonian systems to constrain the baseline model. The
proposed model outperforms the baseline model in identifying a minimal set of
non-redundant and interpretable state variables.

æè¦ï¼åæç³»çµ±çå»ºæ¨¡ä¸åæ¯æè¿°ï¼ä¹æ¯é æ¸¬åæ§å¶èªç¶ç¾è±¡åå·¥ç¨ç³»çµ±çæ®ééæ³¨ãç®åçè³æé©åæ¹æ³éå¸¸åè¨­ååå·²ç¥ç¸éçæè®æ¸æå°è´éåº¦åæ¸åççæç©ºéãBoyuan Chen åä»çå±åä½èæåºäºä¸åç¥ç¶ç¶²è·¯æ¨¡åï¼ç¨ä»¥ä¼°è¨èªç±åº¦ä¸¦åè©¦æ¾åºåæç³»çµ±ççæè®æ¸ãåç®¡æ¡ç¨åµæ°çæ¹æ³ï¼ä½éååºæºæ¨¡åç¼ºä¹èå¶åæç³»çµ±æéµå¾ªçç©çåççé£çµï¼å°è´ç¡æ³ä¿¡è³´çæè®æ¸ã
æ¬ç ç©¶æåºäºä¸ç¨®æ¹æ³ï¼å©ç¨äºéåå¯é ç³»çµ±çç©çç¹æ§ä¾ç´æåºæºæ¨¡åãææåºçæ¨¡åå¨æ¾åºæç°¡çä¸çµéåé¤ä¸å¯è§£éççæè®æ¸æ¹é¢ï¼è¡¨ç¾åªæ¼åºæºæ¨¡åã

##### **5G NR PRACH Detection with Convolutional Neural Networks (CNN): Overcoming Cell Interference Challenges**
2408.11659v1 by Desire Guel, Arsene Kabore, Didier Bassole

In this paper, we present a novel approach to interference detection in 5G
New Radio (5G-NR) networks using Convolutional Neural Networks (CNN).
Interference in 5G networks challenges high-quality service due to dense user
equipment deployment and increased wireless environment complexity. Our
CNN-based model is designed to detect Physical Random Access Channel (PRACH)
sequences amidst various interference scenarios, leveraging the spatial and
temporal characteristics of PRACH signals to enhance detection accuracy and
robustness. Comprehensive datasets of simulated PRACH signals under controlled
interference conditions were generated to train and validate the model.
Experimental results show that our CNN-based approach outperforms traditional
PRACH detection methods in accuracy, precision, recall and F1-score. This study
demonstrates the potential of AI/ML techniques in advancing interference
management in 5G networks, providing a foundation for future research and
practical applications in optimizing network performance and reliability.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®ä½¿ç¨å·ç©ç¥ç¶ç¶²è·¯ (CNN) é²è¡ 5G æ°ç¡ç·é» (5G-NR) ç¶²è·¯å¹²æ¾åµæ¸¬çæ°ç©æ¹æ³ãç±æ¼å¯éçä½¿ç¨èè¨­åé¨ç½²åç¡ç·ç°å¢è¤éæ§çå¢å ï¼5G ç¶²è·¯çå¹²æ¾å°é«åè³ªæåæ§æææ°ãæåçåºæ¼ CNN çæ¨¡åæ¨å¨å¨åç¨®å¹²æ¾å ´æ¯ä¸­åµæ¸¬ç©çé¨æ©å­åéé (PRACH) åºåï¼å©ç¨ PRACH è¨èçç©ºéåæéç¹å¾µä¾å¢å¼·åµæ¸¬æºç¢ºåº¦åç©©å¥æ§ãç¢çäºå¨åæ§å¹²æ¾æ¢ä»¶ä¸æ¨¡æ¬ PRACH è¨èçç¶åè³æéï¼ä»¥è¨ç·´åé©è­æ¨¡åãå¯¦é©çµæè¡¨æï¼æåçåºæ¼ CNN çæ¹æ³å¨æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸æ¹é¢åªæ¼å³çµ±ç PRACH åµæ¸¬æ¹æ³ãéé ç ç©¶å±ç¤ºäº AI/ML æè¡å¨æ¨é² 5G ç¶²è·¯å¹²æ¾ç®¡çä¸­çæ½åï¼çºæªä¾ç ç©¶åå¯¦åæç¨å¥ å®äºåºç¤ï¼ä»¥æä½³åç¶²è·¯æè½åå¯é æ§ã

##### **CIPHER: Cybersecurity Intelligent Penetration-testing Helper for Ethical Researcher**
2408.11650v1 by Derry Pratama, Naufal Suryanto, Andro Aprila Adiputra, Thi-Thu-Huong Le, Ahmada Yusril Kadiptya, Muhammad Iqbal, Howon Kim

Penetration testing, a critical component of cybersecurity, typically
requires extensive time and effort to find vulnerabilities. Beginners in this
field often benefit from collaborative approaches with the community or
experts. To address this, we develop CIPHER (Cybersecurity Intelligent
Penetration-testing Helper for Ethical Researchers), a large language model
specifically trained to assist in penetration testing tasks. We trained CIPHER
using over 300 high-quality write-ups of vulnerable machines, hacking
techniques, and documentation of open-source penetration testing tools.
Additionally, we introduced the Findings, Action, Reasoning, and Results (FARR)
Flow augmentation, a novel method to augment penetration testing write-ups to
establish a fully automated pentesting simulation benchmark tailored for large
language models. This approach fills a significant gap in traditional
cybersecurity Q\&A benchmarks and provides a realistic and rigorous standard
for evaluating AI's technical knowledge, reasoning capabilities, and practical
utility in dynamic penetration testing scenarios. In our assessments, CIPHER
achieved the best overall performance in providing accurate suggestion
responses compared to other open-source penetration testing models of similar
size and even larger state-of-the-art models like Llama 3 70B and Qwen1.5 72B
Chat, particularly on insane difficulty machine setups. This demonstrates that
the current capabilities of general LLMs are insufficient for effectively
guiding users through the penetration testing process. We also discuss the
potential for improvement through scaling and the development of better
benchmarks using FARR Flow augmentation results. Our benchmark will be released
publicly at https://github.com/ibndias/CIPHER.

æè¦ï¼æ»²éæ¸¬è©¦æ¯ç¶²è·¯å®å¨çéè¦çµæé¨åï¼éå¸¸éè¦è±è²»å¤§éæéåç²¾åä¾æ¾åºæ¼æ´ãæ­¤é åçåå­¸èéå¸¸æåçæ¼èç¤¾ç¾¤æå°å®¶çåä½æ¹æ³ãçºäºè§£æ±ºéååé¡ï¼æåéç¼äº CIPHERï¼ç¶²è·¯å®å¨æºæ§æ»²éæ¸¬è©¦åå©ç¨å¼ï¼å°çºéå¾·ç ç©¶äººå¡è¨­è¨ï¼ï¼éæ¯ä¸åå¤§åèªè¨æ¨¡åï¼ç¶éç¹å¥è¨ç·´ä»¥åå©æ»²éæ¸¬è©¦ä»»åãæåä½¿ç¨è¶é 300 ç¯é«åè³ªçå¼±é»æ©å¨æ°å¯«ãé§­å®¢æè¡ï¼ä»¥åéæºæ»²éæ¸¬è©¦å·¥å·æä»¶ä¾è¨ç·´ CIPHERãæ­¤å¤ï¼æåå¼å¥äºç¼ç¾ãè¡åãæ¨çåçµæ (FARR) æµç¨æ´ååè½ï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼å¯ç¨æ¼æ´åæ»²éæ¸¬è©¦æ°å¯«å§å®¹ï¼ä»¥å»ºç«å®å¨èªååçæ»²éæ¸¬è©¦æ¨¡æ¬åºæºï¼å°ééå°å¤§åèªè¨æ¨¡åéèº«æé ãéç¨®æ¹æ³å¡«è£äºå³çµ±ç¶²è·¯å®å¨åç­åºæºçéå¤§ç©ºç½ï¼ä¸¦æä¾äºä¸åç¾å¯¦ä¸å´æ ¼çæ¨æºï¼ç¨æ¼è©ä¼° AI å¨åææ»²éæ¸¬è©¦å ´æ¯ä¸­çæè¡ç¥è­ãæ¨çè½ååå¯¦éæç¨ãå¨æåçè©ä¼°ä¸­ï¼èå¶ä»é¡ä¼¼è¦æ¨¡çéæºæ»²éæ¸¬è©¦æ¨¡åï¼çè³æ¯ Llama 3 70B å Qwen1.5 72B Chat ç­æ´å¤§çæåé²æ¨¡åç¸æ¯ï¼CIPHER å¨æä¾æºç¢ºå»ºè­°åææ¹é¢éå°äºæä½³çæ´é«æè½ï¼ç¹å¥æ¯å¨å°é£çæ©å¨è¨­å®ä¸ãéè­æäºç®åä¸è¬ LLM çè½åä¸è¶³ä»¥ææå¼å°ä½¿ç¨èå®ææ»²éæ¸¬è©¦æµç¨ãæåéè¨è«äºééæ´ååä½¿ç¨ FARR æµç¨æ´åçµæéç¼æ´å¥½çåºæºä¾æ¹é²çæ½åãæåçåºæºå°å¨ https://github.com/ibndias/CIPHER å¬éç¼å¸ã

##### **Video-to-Text Pedestrian Monitoring (VTPM): Leveraging Computer Vision and Large Language Models for Privacy-Preserve Pedestrian Activity Monitoring at Intersections**
2408.11649v1 by Ahmed S. Abdelrahman, Mohamed Abdel-Aty, Dongdong Wang

Computer vision has advanced research methodologies, enhancing system
services across various fields. It is a core component in traffic monitoring
systems for improving road safety; however, these monitoring systems don't
preserve the privacy of pedestrians who appear in the videos, potentially
revealing their identities. Addressing this issue, our paper introduces
Video-to-Text Pedestrian Monitoring (VTPM), which monitors pedestrian movements
at intersections and generates real-time textual reports, including traffic
signal and weather information. VTPM uses computer vision models for pedestrian
detection and tracking, achieving a latency of 0.05 seconds per video frame.
Additionally, it detects crossing violations with 90.2% accuracy by
incorporating traffic signal data. The proposed framework is equipped with
Phi-3 mini-4k to generate real-time textual reports of pedestrian activity
while stating safety concerns like crossing violations, conflicts, and the
impact of weather on their behavior with latency of 0.33 seconds. To enhance
comprehensive analysis of the generated textual reports, Phi-3 medium is
fine-tuned for historical analysis of these generated textual reports. This
fine-tuning enables more reliable analysis about the pedestrian safety at
intersections, effectively detecting patterns and safety critical events. The
proposed VTPM offers a more efficient alternative to video footage by using
textual reports reducing memory usage, saving up to 253 million percent,
eliminating privacy issues, and enabling comprehensive interactive historical
analysis.

æè¦ï¼é»è¦è¦è¦ºå·²é²æ­¥çç ç©¶æ¹æ³ï¼å å¼·äºååé åçç³»çµ±æåãå®æ¯äº¤éç£æ§ç³»çµ±ä¸­æ¹åéè·¯å®å¨çæ ¸å¿çµæé¨åï¼ç¶èï¼éäºç£æ§ç³»çµ±ä¸¦æªä¿è­·å½±çä¸­è¡äººçé±ç§ï¼å¯è½ææ´©é²ä»åçèº«ä»½ãçºäºè§£æ±ºéååé¡ï¼æåçè«æä»ç´¹äºå½±çè½æå­è¡äººç£æ§ (VTPM)ï¼å®æç£æ§åå­è·¯å£çè¡äººåæï¼ä¸¦ç¢çå³ææå­å ±åï¼åæ¬äº¤éèèªåå¤©æ°£è³è¨ãVTPM ä½¿ç¨é»è¦è¦è¦ºæ¨¡åä¾é²è¡è¡äººåµæ¸¬åè¿½è¹¤ï¼æ¯ç§å½±çå¹å¯éå° 0.05 ç§çå»¶é²ãæ­¤å¤ï¼å®ééæ´åäº¤éèèªè³æï¼ä»¥ 90.2% çæºç¢ºåº¦åµæ¸¬éè¦ç©¿è¶ãææåºçæ¶æ§éåäº Phi-3 mini-4kï¼å¯ç¢çè¡äººæ´»åçå³ææå­å ±åï¼åæèªªæå®å¨åé¡ï¼ä¾å¦éè¦ç©¿è¶ãè¡çªä»¥åå¤©æ°£å°å¶è¡çºçå½±é¿ï¼å»¶é²çº 0.33 ç§ãçºäºå å¼·å°æç¢çæå­å ±åçå¨é¢åæï¼Phi-3 medium å·²éå°éäºç¢ççæå­å ±åçæ­·å²åæé²è¡å¾®èª¿ãéç¨®å¾®èª¿å¯éå°åå­è·¯å£çè¡äººå®å¨é²è¡æ´å¯é çåæï¼ææåµæ¸¬æ¨¡å¼åå®å¨ééµäºä»¶ãææåºç VTPM æä¾äºæ¯å½±ççæ®µæ´ææççæ¿ä»£æ¹æ¡ï¼ééä½¿ç¨æå­å ±åä¾æ¸å°è¨æ¶é«ä½¿ç¨éï¼ç¯çé«é 2.53 å%ï¼æ¶é¤é±ç§åé¡ï¼ä¸¦åç¨å¨é¢çäºåå¼æ­·å²åæã

##### **Data-driven Modeling of Combined Sewer Systems for Urban Sustainability: An Empirical Evaluation**
2408.11619v1 by Vipin Singh, Tianheng Ling, Teodor Chiaburu, Felix Biessmann

Climate change poses complex challenges, with extreme weather events becoming
increasingly frequent and difficult to model. Examples include the dynamics of
Combined Sewer Systems (CSS). Overburdened CSS during heavy rainfall will
overflow untreated wastewater into surface water bodies. Classical approaches
to modeling the impact of extreme rainfall events rely on physical simulations,
which are particularly challenging to create for large urban infrastructures.
Deep Learning (DL) models offer a cost-effective alternative for modeling the
complex dynamics of sewer systems. In this study, we present a comprehensive
empirical evaluation of several state-of-the-art DL time series models for
predicting sewer system dynamics in a large urban infrastructure, utilizing
three years of measurement data. We especially investigate the potential of DL
models to maintain predictive precision during network outages by comparing
global models, which have access to all variables within the sewer system, and
local models, which are limited to data from a restricted set of local sensors.
Our findings demonstrate that DL models can accurately predict the dynamics of
sewer system load, even under network outage conditions. These results suggest
that DL models can effectively aid in balancing the load redistribution in CSS,
thereby enhancing the sustainability and resilience of urban infrastructures.

æè¦ï¼æ°£åè®é·å¸¶ä¾è¤éçææ°ï¼æ¥µç«¯å¤©æ°£äºä»¶è®å¾è¶ä¾è¶é »ç¹ä¸é£ä»¥å»ºæ¨¡ãèä¾ä¾èªªï¼ä¸æ°´éç³»çµ± (CSS) çåæãå¼·éé¨æï¼è² æééç CSS æä½¿æªç¶èççå»¢æ°´æº¢æµå°å°è¡¨æ°´é«ä¸­ãæ¨¡æ¬æ¥µç«¯éé¨äºä»¶å½±é¿çå³çµ±æ¹æ³ä¾è³´æ¼ç©çæ¨¡æ¬ï¼èéå°æ¼å¤§ååå¸åºç¤è¨­æ½ä¾èªªç¹å¥é£ä»¥å»ºç«ãæ·±åº¦å­¸ç¿ (DL) æ¨¡åçºæ¨¡æ¬ä¸æ°´éç³»çµ±çè¤éåææä¾äºä¸åå·æææ¬æççæ¿ä»£æ¹æ¡ãå¨æ¬ç ç©¶ä¸­ï¼æåå°å¹¾åæåé²ç DL æéåºåæ¨¡åé²è¡äºå¨é¢çç¶é©è©ä¼°ï¼ä»¥é æ¸¬å¤§ååå¸åºç¤è¨­æ½ä¸­çä¸æ°´éç³»çµ±åæï¼å©ç¨ä¸å¹´çæ¸¬éæ¸æãæåç¹å¥ç ç©¶äº DL æ¨¡åå¨ç¶²è·¯ä¸­æ·æéç¶­æé æ¸¬ç²¾åº¦çæ½åï¼æ¹æ³æ¯æ¯è¼å¨å±æ¨¡åï¼å¯ä»¥å­åä¸æ°´éç³»çµ±ä¸­çææè®æ¸ï¼åå±é¨æ¨¡åï¼åéæ¼ä¾èªä¸çµåéçå±é¨ææ¸¬å¨çè³æï¼ãæåçç ç©¶çµæè¡¨æï¼DL æ¨¡åå¯ä»¥æºç¢ºé æ¸¬ä¸æ°´éç³»çµ±è² è¼çåæï¼å³ä½¿å¨ç¶²è·¯ä¸­æ·çææ³ä¸ä¹æ¯å¦æ­¤ãéäºçµæè¡¨æï¼DL æ¨¡åå¯ä»¥ææå°å¹«å©å¹³è¡¡ CSS ä¸­çè² è¼éæ°åéï¼å¾èå¢å¼·åå¸åºç¤è¨­æ½çå¯æçºæ§åéæ§ã

##### **Xinyu: An Efficient LLM-based System for Commentary Generation**
2408.11609v1 by Yiquan Wu, Bo Tang, Chenyang Xi, Yu Yu, Pengyu Wang, Yifei Liu, Kun Kuang, Haiying Deng, Zhiyu Li, Feiyu Xiong, Jie Hu, Peng Cheng, Zhonghao Wang, Yi Wang, Yi Luo, Mingchuan Yang

Commentary provides readers with a deep understanding of events by presenting
diverse arguments and evidence. However, creating commentary is a
time-consuming task, even for skilled commentators. Large language models
(LLMs) have simplified the process of natural language generation, but their
direct application in commentary creation still faces challenges due to unique
task requirements. These requirements can be categorized into two levels: 1)
fundamental requirements, which include creating well-structured and logically
consistent narratives, and 2) advanced requirements, which involve generating
quality arguments and providing convincing evidence. In this paper, we
introduce Xinyu, an efficient LLM-based system designed to assist commentators
in generating Chinese commentaries. To meet the fundamental requirements, we
deconstruct the generation process into sequential steps, proposing targeted
strategies and supervised fine-tuning (SFT) for each step. To address the
advanced requirements, we present an argument ranking model for arguments and
establish a comprehensive evidence database that includes up-to-date events and
classic books, thereby strengthening the substantiation of the evidence with
retrieval augmented generation (RAG) technology. To evaluate the generated
commentaries more fairly, corresponding to the two-level requirements, we
introduce a comprehensive evaluation metric that considers five distinct
perspectives in commentary generation. Our experiments confirm the
effectiveness of our proposed system. We also observe a significant increase in
the efficiency of commentators in real-world scenarios, with the average time
spent on creating a commentary dropping from 4 hours to 20 minutes.
Importantly, such an increase in efficiency does not compromise the quality of
the commentaries.

æè¦ï¼<paragraph>è©è«ééæåºä¸åçè«é»åè­æï¼è®è®èæ·±å¥äºè§£äºä»¶ãç¶èï¼å³ä½¿å°çç·´çè©è«å®¶èè¨ï¼æ°å¯«è©è«é½æ¯ä¸é èæçä»»åãå¤§åèªè¨æ¨¡å (LLM) ç°¡åäºèªç¶èªè¨çæçæµç¨ï¼ä½ç±æ¼ç¨ç¹çä»»åéæ±ï¼å®åå¨è©è«æ°å¯«ä¸­çç´æ¥æç¨ä»é¢è¨ææ°ãéäºéæ±å¯åçºå©åå±¤ç´ï¼1) åºæ¬éæ±ï¼åæ¬å»ºç«çµæ§è¯å¥½ä¸åä¹éè¼¯çæè¿°ï¼ä»¥å 2) é²ééæ±ï¼åæ¬ç¢çé«åè³ªçè«é»åæä¾ä»¤äººä¿¡æçè­æãå¨æ¬æä¸­ï¼æåä»ç´¹ Xinyuï¼ä¸ååºæ¼ LLM çé«æç³»çµ±ï¼æ¨å¨åå©è©è«å®¶ç¢çä¸­æè©è«ãçºäºæ»¿è¶³åºæ¬éæ±ï¼æåå°çææµç¨è§£æ§çºå¾ªåºæ¼¸é²çæ­¥é©ï¼éå°æ¯åæ­¥é©æåºç®æ¨ç­ç¥åç£ç£å¾®èª¿ (SFT)ãçºäºæ»¿è¶³é²ééæ±ï¼æåæåºä¸åè«é»æåæ¨¡åï¼ä¸¦å»ºç«ä¸ååå«ææ°äºä»¶åç¶å¸æ¸ç±çç¶åè­æè³æåº«ï¼å¾èééæª¢ç´¢æ´åçæ (RAG) æè¡å¼·åè­æçå¯¦è³ªå§å®¹ãçºäºæ´å¬å¹³å°è©ä¼°æçæçè©è«ï¼éå°éå©åå±¤ç´çéæ±ï¼æåå¼å¥ä¸åç¶åè©éææ¨ï¼èéè©è«çæä¸­çäºåä¸åè§é»ãæåçå¯¦é©è­å¯¦äºæåææåºçç³»çµ±çæææ§ãæåä¹è§å¯å°å¨å¯¦éææ³ä¸­ï¼è©è«å®¶çæçé¡¯èæåï¼æ°å¯«ä¸ç¯è©è«æè±çå¹³åæéå¾ 4 å°æç¸®ç­è³ 20 åéãéè¦çæ¯ï¼æççæåä¸¦æªæå®³è©è«çåè³ªã</paragraph>

##### **Cause-Aware Empathetic Response Generation via Chain-of-Thought Fine-Tuning**
2408.11599v1 by Xinhao Chen, Chong Yang, Man Lan, Li Cai, Yang Chen, Tu Hu, Xinlin Zhuang, Aimin Zhou

Empathetic response generation endows agents with the capability to
comprehend dialogue contexts and react to expressed emotions. Previous works
predominantly focus on leveraging the speaker's emotional labels, but ignore
the importance of emotion cause reasoning in empathetic response generation,
which hinders the model's capacity for further affective understanding and
cognitive inference. In this paper, we propose a cause-aware empathetic
generation approach by integrating emotions and causes through a well-designed
Chain-of-Thought (CoT) prompt on Large Language Models (LLMs). Our approach can
greatly promote LLMs' performance of empathy by instruction tuning and
enhancing the role awareness of an empathetic listener in the prompt.
Additionally, we propose to incorporate cause-oriented external knowledge from
COMET into the prompt, which improves the diversity of generation and
alleviates conflicts between internal and external knowledge at the same time.
Experimental results on the benchmark dataset demonstrate that our approach on
LLaMA-7b achieves state-of-the-art performance in both automatic and human
evaluations.

æè¦ï¼å±æåæçæè³¦äºä»£çäººçè§£å°è©±èçµ¡ä¸¦å°è¡¨éçæç·ååºåæçè½åãååçä½åä¸»è¦å°æ³¨æ¼å©ç¨èªªè©±èçæç·æ¨ç±¤ï¼ä½å¿½ç¥äºæç·åå å¨å±æåæçæä¸­çéè¦æ§ï¼éé»ç¤äºæ¨¡åé²ä¸æ­¥ææçè§£åèªç¥æ¨è«çè½åãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åå æç¥å±æçææ¹æ³ï¼ééå¨å¤§åèªè¨æ¨¡å (LLM) ä¸ç²¾å¿è¨­è¨çææ³é (CoT) æç¤ºæ´åæç·ååå ãæåçåæ³å¯ä»¥ééæä»¤èª¿æ´åå¢å¼·æç¤ºä¸­åçå¾è½èçè§è²æè­ï¼æ¥µå¤§å°æå LLM çåçå¿è¡¨ç¾ãæ­¤å¤ï¼æåå»ºè­°å°é¢ååå çå¤é¨ç¥è­å¾ COMET ç´å¥æç¤ºä¸­ï¼éåææé«äºçæç diversityï¼ä¸¦ç·©è§£äºå§é¨åå¤é¨ç¥è­ä¹éçè¡çªãåºæºæ¸æéä¸çå¯¦é©çµæè¡¨æï¼æåå¨ LLaMA-7b ä¸çæ¹æ³å¨èªååäººå·¥è©ä¼°ä¸­é½éå°äºæåé²çæ§è½ã

##### **Active learning for efficient data selection in radio-signal based positioning via deep learning**
2408.11592v1 by Vincent Corlay, Milan Courcoux-Caro

We consider the problem of user equipment (UE) positioning based on radio
signals via deep learning. As in most supervised-learning tasks, a critical
aspect is the availability of a relevant dataset to train a model. However, in
a cellular network, the data-collection step may induce a high communication
overhead. As a result, to reduce the required size of the dataset, it may be
interesting to carefully choose the positions to be labelled and to be used in
the training. We therefore propose an active learning approach for efficient
data collection. We first show that significant gains (both in terms of
positioning accuracy and size of the required dataset) can be obtained for the
considered positioning problem using a genie. This validates the interest of
active learning for positioning. We then propose a \textcolor{blue}{practical}
method to approximate this genie.

æè¦ï¼æåèæ®ä½¿ç¨æ·±åº¦å­¸ç¿ï¼æ ¹æç¡ç·é»ä¿¡èé²è¡ç¨æ¶è¨­å (UE) å®ä½çåé¡ãèå¤§å¤æ¸ç£ç£å¼å­¸ç¿ä»»åä¸æ¨£ï¼ä¸åééµæ¹é¢æ¯ç¸éè³æéçå¯ç¨æ§ï¼ä»¥è¨ç·´æ¨¡åãç¶èï¼å¨èå·¢å¼ç¶²è·¯ä¸­ï¼è³ææ¶éæ­¥é©å¯è½æå°è´é«éè¨éé·ãå æ­¤ï¼çºäºæ¸å°æéçè³æéå¤§å°ï¼ä»ç´°é¸æè¦æ¨è¨ä¸¦ç¨æ¼è¨ç·´çä½ç½®å¯è½æ¯å¾éè¦çãå æ­¤ï¼æåæåºä¸»åå­¸ç¿æ¹æ³ï¼ä»¥æææ¶éè³æãæåé¦åè¡¨æï¼å°æ¼èæ®å®ä½åé¡ï¼å¯ä»¥ä½¿ç¨ç²¾éç²å¾é¡¯èçæ¶çï¼ç¡è«æ¯å¨å®ä½æºç¢ºåº¦éæ¯æéè³æéçå¤§å°æ¹é¢ï¼ãéé©è­äºä¸»åå­¸ç¿å¨å®ä½æ¹é¢çèè¶£ãç¶å¾ï¼æåæåºä¸åå¯¦ç¨çæ¹æ³ä¾è¿ä¼¼éåç²¾éã

##### **Large Language Models are Good Attackers: Efficient and Stealthy Textual Backdoor Attacks**
2408.11587v1 by Ziqiang Li, Yueqi Zeng, Pengfei Xia, Lei Liu, Zhangjie Fu, Bin Li

With the burgeoning advancements in the field of natural language processing
(NLP), the demand for training data has increased significantly. To save costs,
it has become common for users and businesses to outsource the labor-intensive
task of data collection to third-party entities. Unfortunately, recent research
has unveiled the inherent risk associated with this practice, particularly in
exposing NLP systems to potential backdoor attacks. Specifically, these attacks
enable malicious control over the behavior of a trained model by poisoning a
small portion of the training data. Unlike backdoor attacks in computer vision,
textual backdoor attacks impose stringent requirements for attack stealthiness.
However, existing attack methods meet significant trade-off between
effectiveness and stealthiness, largely due to the high information entropy
inherent in textual data. In this paper, we introduce the Efficient and
Stealthy Textual backdoor attack method, EST-Bad, leveraging Large Language
Models (LLMs). Our EST-Bad encompasses three core strategies: optimizing the
inherent flaw of models as the trigger, stealthily injecting triggers with
LLMs, and meticulously selecting the most impactful samples for backdoor
injection. Through the integration of these techniques, EST-Bad demonstrates an
efficient achievement of competitive attack performance while maintaining
superior stealthiness compared to prior methods across various text classifier
datasets.

æè¦ï¼é¨èèªç¶èªè¨èç (NLP) é åçè¬åç¼å±ï¼å°è¨ç·´è³æçéæ±å¤§å¹å¢å ãçºäºç¯çææ¬ï¼ä½¿ç¨èåä¼æ¥­å·²æ®éå°è³ææ¶éçååå¯éåä»»åå¤åçµ¦ç¬¬ä¸æ¹å¯¦é«ãä¸å¹¸çæ¯ï¼æè¿çç ç©¶æ­é²äºéç¨®åæ³åºæçé¢¨éªï¼ç¹å¥æ¯å¨å° NLP ç³»çµ±æ´é²æ¼æ½å¨å¾éæ»ææãå·é«ä¾èªªï¼éäºæ»æééæ¯åè¨ç·´è³æçä¸å°é¨åä¾å¯¦ç¾å°è¨ç·´æ¨¡åè¡çºçæ¡ææ§å¶ãèé»è¦è¦è¦ºä¸­çå¾éæ»æä¸åï¼æå­å¾éæ»æå°æ»æé±è½æ§æåºäºå´æ ¼çè¦æ±ãç¶èï¼ç¾æçæ»ææ¹æ³å¨æææ§èé±è½æ§ä¹éå­å¨é¡¯èçæ¬è¡¡ï¼éä¸»è¦æ¯å çºæå­è³æä¸­åºæçé«è³è¨çµãå¨æ¬æä¸­ï¼æåä»ç´¹äºé«æä¸é±è½çæå­å¾éæ»ææ¹æ³ EST-Badï¼å®å©ç¨äºå¤§åèªè¨æ¨¡å (LLM)ãæåç EST-Bad æ¶µèäºä¸åæ ¸å¿ç­ç¥ï¼å°æ¨¡åçåºæç¼ºé·æä½³åçºè§¸ç¼å¨ãä½¿ç¨ LLM é±è½å°æ³¨å¥è§¸ç¼å¨ï¼ä»¥åä»ç´°é¸æå°å¾éæ³¨å¥å½±é¿æå¤§çç¯ä¾ãééæ´åéäºæè¡ï¼EST-Bad å±ç¤ºäºå¨èåç¨®æå­åé¡å¨è³æéç¸æ¯ä¹ä¸ï¼å¨ç¶­æåªç°é±è½æ§çåæï¼ææéæå·æç«¶ç­åçæ»ææè½ã

##### **Drama Engine: A Framework for Narrative Agents**
2408.11574v1 by Martin Pichlmair, Riddhi Raj, Charlene Putney

This technical report presents the Drama Engine, a novel framework for
agentic interaction with large language models designed for narrative purposes.
The framework adapts multi-agent system principles to create dynamic,
context-aware companions that can develop over time and interact with users and
each other. Key features include multi-agent workflows with delegation, dynamic
prompt assembly, and model-agnostic design. The Drama Engine introduces unique
elements such as companion development, mood systems, and automatic context
summarising. It is implemented in TypeScript. The framework's applications
include multi-agent chats and virtual co-workers for creative writing. The
paper discusses the system's architecture, prompt assembly process, delegation
mechanisms, and moderation techniques, as well as potential ethical
considerations and future extensions.

æè¦ï¼éä»½æè¡å ±åä»ç´¹äº Drama Engineï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼ç¨æ¼èçºæäºç®çèè¨­è¨çå¤§åèªè¨æ¨¡åé²è¡ä»£çäºåã
è©²æ¶æ§æ¡ç¨å¤ä»£çç³»çµ±ååä¾åµå»ºåæãå·åæå¢æç¥è½åçå¤¥ä¼´ï¼éäºå¤¥ä¼´å¯ä»¥é¨èæéæ¨ç§»èç¼å±ä¸¦èä½¿ç¨èåå½¼æ­¤äºåãä¸»è¦åè½åæ¬å·æå§æ´¾çå¤ä»£çå·¥ä½æµç¨ãåææç¤ºçµè£åèæ¨¡åç¡éçè¨­è¨ãDrama Engine å¼å¥äºç¨ç¹çåç´ ï¼ä¾å¦å¤¥ä¼´éç¼ãæç·ç³»çµ±åèªåæå¢æè¦ãå®ä½¿ç¨ TypeScript å¯¦ä½ãè©²æ¶æ§çæç¨åæ¬å¤ä»£çèå¤©åèæ¬åä½èï¼ç¨æ¼åµæå¯«ä½ãæ¬æè¨è«äºç³»çµ±çæ¶æ§ãæç¤ºçµè£æµç¨ãå§æ´¾æ©å¶åå¯©æ ¸æè¡ï¼ä»¥åæ½å¨çéå¾·èéåæªä¾çå»¶ä¼¸ã

##### **Differentiating Choices via Commonality for Multiple-Choice Question Answering**
2408.11554v1 by Wenqing Deng, Zhe Wang, Kewen Wang, Shirui Pan, Xiaowang Zhang, Zhiyong Feng

Multiple-choice question answering (MCQA) becomes particularly challenging
when all choices are relevant to the question and are semantically similar. Yet
this setting of MCQA can potentially provide valuable clues for choosing the
right answer. Existing models often rank each choice separately, overlooking
the context provided by other choices. Specifically, they fail to leverage the
semantic commonalities and nuances among the choices for reasoning. In this
paper, we propose a novel MCQA model by differentiating choices through
identifying and eliminating their commonality, called DCQA. Our model captures
token-level attention of each choice to the question, and separates tokens of
the question attended to by all the choices (i.e., commonalities) from those by
individual choices (i.e., nuances). Using the nuances as refined contexts for
the choices, our model can effectively differentiate choices with subtle
differences and provide justifications for choosing the correct answer. We
conduct comprehensive experiments across five commonly used MCQA benchmarks,
demonstrating that DCQA consistently outperforms baseline models. Furthermore,
our case study illustrates the effectiveness of the approach in directing the
attention of the model to more differentiating features.

æè¦ï¼å¤é¸é¡åç­ (MCQA) å¨ææé¸é é½èåé¡ç¸éä¸èªç¾©ç¸ä¼¼æï¼æè®å¾ç¹å¥å·æææ°æ§ãç¶èï¼éç¨® MCQA è¨­å®å¯ä»¥æ½å¨æä¾æå¹å¼çç·ç´¢ï¼ä»¥é¸ææ­£ç¢ºç­æ¡ãç¾æçæ¨¡åéå¸¸æåå¥å°æ¯åé¸é é²è¡æåï¼å¿½ç¥å¶ä»é¸é æä¾çä¸ä¸æãå·é«ä¾èªªï¼å®åç¡æ³å©ç¨é¸é ä¹éçèªç¾©å±æ§åç´°å¾®å·®å¥é²è¡æ¨çãå¨æ¬æä¸­ï¼æåæåºäºééè­å¥åæ¶é¤å®åçå±æ§ä¾ååé¸é çæ°å MCQA æ¨¡åï¼ç¨±çº DCQAãæåçæ¨¡åæææ¯åé¸é å°åé¡çæ¨è¨ç´å¥æ³¨æåï¼ä¸¦å°ææé¸é éæ³¨çåé¡æ¨è¨ï¼å³å±æ§ï¼èåå¥é¸é éæ³¨çåé¡æ¨è¨ï¼å³ç´°å¾®å·®å¥ï¼åéãä½¿ç¨ç´°å¾®å·®å¥ä½çºé¸é çç²¾ç·»ä¸ä¸æï¼æåçæ¨¡åå¯ä»¥ææå°ååå·æç´°å¾®å·®å¥ä¸¦æä¾é¸ææ­£ç¢ºç­æ¡ççç±ãæåå¨äºåå¸¸ç¨ç MCQA åºæºä¸é²è¡äºå¨é¢çå¯¦é©ï¼è­æ DCQA æçºåªæ¼åºæºæ¨¡åãæ­¤å¤ï¼æåçæ¡ä¾ç ç©¶èªªæäºè©²æ¹æ³å¨å°æ¨¡åçæ³¨æåå¼å°å°æ´å¤ååæ§ç¹å¾µæ¹é¢çæææ§ã

##### **Explainable Deep Learning Framework for Human Activity Recognition**
2408.11552v1 by Yiran Huang, Yexu Zhou, Haibin Zhao, Till Riedel, Michael Beigl

In the realm of human activity recognition (HAR), the integration of
explainable Artificial Intelligence (XAI) emerges as a critical necessity to
elucidate the decision-making processes of complex models, fostering
transparency and trust. Traditional explanatory methods like Class Activation
Mapping (CAM) and attention mechanisms, although effective in highlighting
regions vital for decisions in various contexts, prove inadequate for HAR. This
inadequacy stems from the inherently abstract nature of HAR data, rendering
these explanations obscure. In contrast, state-of-th-art post-hoc
interpretation techniques for time series can explain the model from other
perspectives. However, this requires extra effort. It usually takes 10 to 20
seconds to generate an explanation. To overcome these challenges, we proposes a
novel, model-agnostic framework that enhances both the interpretability and
efficacy of HAR models through the strategic use of competitive data
augmentation. This innovative approach does not rely on any particular model
architecture, thereby broadening its applicability across various HAR models.
By implementing competitive data augmentation, our framework provides intuitive
and accessible explanations of model decisions, thereby significantly advancing
the interpretability of HAR systems without compromising on performance.

æè¦ï¼å¨äººé¡æ´»åè¾¨è­ï¼HARï¼é åä¸­ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼çæ´åæçºééµå¿è¦æ§ï¼ç¨æ¼é¡æè¤éæ¨¡åçæ±ºç­éç¨ï¼ä¿é²éæåº¦åä¿¡ä»»ãå³çµ±çèªªææ¹æ³ï¼ä¾å¦é¡å¥æ¿æ´»å°æï¼CAMï¼åæ³¨æåæ©å¶ï¼éç¶ææå°çªé¡¯å¨åç¨®æå¢ä¸­å°æ±ºç­è³ééè¦çååï¼ä½è­æä¸é©ç¨æ¼ HARãéç¨®ä¸é©ç¨æ§æºèªæ¼ HAR è³ææ¬è³ªä¸æ½è±¡ï¼å°è´éäºèªªææ¨¡ç¨å©å¯ãç¸åå°ï¼æéåºåçææ°äºå¾è©®éæè¡å¯ä»¥å¾å¶ä»è§é»èªªææ¨¡åãç¶èï¼ééè¦é¡å¤çåªåãéå¸¸éè¦ 10 å° 20 ç§æè½ç¢çèªªæãçºäºåæéäºææ°ï¼æåæåºä¸ååµæ°çãèæ¨¡åç¡éçæ¶æ§ï¼ééç­ç¥æ§å°ä½¿ç¨ç«¶ç­æ§è³ææ´åä¾å¢å¼· HAR æ¨¡åçå¯è©®éæ§åæè½ãéç¨®åµæ°æ¹æ³ä¸ä¾è³´ä»»ä½ç¹å®çæ¨¡åæ¶æ§ï¼å¾èæ´å±å¶å¨åç¨® HAR æ¨¡åä¸­çé©ç¨æ§ãééå¯¦ä½ç«¶ç­æ§è³ææ´åï¼æåçæ¶æ§æä¾ç´è¦ºä¸å®¹æçè§£çæ¨¡åæ±ºç­èªªæï¼å¾èå¤§å¹æå HAR ç³»çµ±çå¯è©®éæ§ï¼åæä¸æåæè½ã

##### **Memorization In In-Context Learning**
2408.11546v1 by Shahriar Golchin, Mihai Surdeanu, Steven Bethard, Eduardo Blanco, Ellen Riloff

In-context learning (ICL) has proven to be an effective strategy for
improving the performance of large language models (LLMs) with no additional
training. However, the exact mechanism behind these performance improvements
remains unclear. This study is the first to show how ICL surfaces memorized
training data and to explore the correlation between this memorization and
performance across various ICL regimes: zero-shot, few-shot, and many-shot. Our
most notable findings include: (1) ICL significantly surfaces memorization
compared to zero-shot learning in most cases; (2) demonstrations, without their
labels, are the most effective element in surfacing memorization; (3) ICL
improves performance when the surfaced memorization in few-shot regimes reaches
a high level (about 40%); and (4) there is a very strong correlation between
performance and memorization in ICL when it outperforms zero-shot learning.
Overall, our study uncovers a hidden phenomenon -- memorization -- at the core
of ICL, raising an important question: to what extent do LLMs truly generalize
from demonstrations in ICL, and how much of their success is due to
memorization?

æè¦ï¼æå¢å­¸ç¿ (ICL) å·²è¢«è­ææ¯ä¸ç¨®ææçç­ç¥ï¼å¯ä»¥å¨ä¸é²è¡é¡å¤è¨ç·´çææ³ä¸æåå¤§åèªè¨æ¨¡å (LLM) çæè½ãç¶èï¼éäºæè½æåèå¾çç¢ºåæ©å¶ä»ä¸æç¢ºãæ¬ç ç©¶é¦æ¬¡å±ç¤ºäº ICL å¦ä½æµ®ç¾è¨æ¶åçè¨ç·´è³æï¼ä¸¦æ¢ç´¢æ­¤è¨æ¶åèåç¨® ICL å¶åº¦ï¼é¶æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åå¤æ¬¡å­¸ç¿ï¼ä¹éçéè¯æ§ãæåæé¡¯èçç¼ç¾åæ¬ï¼(1) å¨å¤§å¤æ¸ææ³ä¸ï¼èé¶æ¬¡å­¸ç¿ç¸æ¯ï¼ICL æé¡¯èæµ®ç¾è¨æ¶åï¼(2) ç¤ºç¯ï¼ä¸å«æ¨ç±¤ï¼æ¯æµ®ç¾è¨æ¶åæææçåç´ ï¼(3) ç¶å°æ¬¡å­¸ç¿å¶åº¦ä¸­çæµ®ç¾è¨æ¶åéå°é«æ°´æºï¼ç´ 40%ï¼æï¼ICL ææåæè½ï¼(4) ç¶ ICL åéé¶æ¬¡å­¸ç¿æï¼æè½èè¨æ¶åä¹éå­å¨éå¸¸å¼·ççéè¯æ§ãç¸½é«èè¨ï¼æåçç ç©¶æ­é²äºä¸åé±èçç¾è±¡ââè¨æ¶åââéæ¯ ICL çæ ¸å¿ï¼ä¸¦æåºäºä¸åéè¦åé¡ï¼LLM å¨å¤å¤§ç¨åº¦ä¸çæ­£å¾ ICL ä¸­çç¤ºç¯ä¸­æ¦æ¬ï¼èå®åçæåæå¤å°æ­¸åæ¼è¨æ¶åï¼

##### **RConE: Rough Cone Embedding for Multi-Hop Logical Query Answering on Multi-Modal Knowledge Graphs**
2408.11526v1 by Mayank Kharbanda, Rajiv Ratn Shah, Raghava Mutharaju

Multi-hop query answering over a Knowledge Graph (KG) involves traversing one
or more hops from the start node to answer a query. Path-based and logic-based
methods are state-of-the-art for multi-hop question answering. The former is
used in link prediction tasks. The latter is for answering complex logical
queries. The logical multi-hop querying technique embeds the KG and queries in
the same embedding space. The existing work incorporates First Order Logic
(FOL) operators, such as conjunction ($\wedge$), disjunction ($\vee$), and
negation ($\neg$), in queries. Though current models have most of the building
blocks to execute the FOL queries, they cannot use the dense information of
multi-modal entities in the case of Multi-Modal Knowledge Graphs (MMKGs). We
propose RConE, an embedding method to capture the multi-modal information
needed to answer a query. The model first shortlists candidate (multi-modal)
entities containing the answer. It then finds the solution (sub-entities)
within those entities. Several existing works tackle path-based
question-answering in MMKGs. However, to our knowledge, we are the first to
introduce logical constructs in querying MMKGs and to answer queries that
involve sub-entities of multi-modal entities as the answer. Extensive
evaluation of four publicly available MMKGs indicates that RConE outperforms
the current state-of-the-art.

æè¦ï¼å¤è·³æ¥è¯¢åç­æ¶åä»èµ·å§èç¹éåä¸ä¸ªæå¤ä¸ªè·³è·æ¥åç­æ¥è¯¢ãåºäºè·¯å¾ååºäºé»è¾çæ¹æ³æ¯å¤è·³é®é¢åç­çææ°ææ¯ãåèç¨äºé¾æ¥é¢æµä»»å¡ãåèç¨äºåç­å¤æçé»è¾æ¥è¯¢ãé»è¾å¤è·³æ¥è¯¢ææ¯å°ç¥è¯å¾è°±åæ¥è¯¢åµå¥å°ç¸åçåµå¥ç©ºé´ä¸­ãç°æå·¥ä½å¨æ¥è¯¢ä¸­çº³å¥äºç¬¬ä¸é¶é»è¾ (FOL) è¿ç®ç¬¦ï¼ä¾å¦åå ($\wedge$)ãæå ($\vee$) åå¦å® ($\neg$)ãè½ç¶å½åæ¨¡åå·ææ§è¡ FOL æ¥è¯¢çå¤§é¨åæå»ºæ¨¡åï¼ä½å®ä»¬å¨å¤æ¨¡æç¥è¯å¾è°± (MMKG) çæåµä¸æ æ³ä½¿ç¨å¤æ¨¡æå®ä½çå¯éä¿¡æ¯ãæä»¬æåºäº RConEï¼è¿æ¯ä¸ç§åµå¥æ¹æ³ï¼ç¨äºæè·åç­æ¥è¯¢æéçå¤æ¨¡æä¿¡æ¯ãè¯¥æ¨¡åé¦åç­éåå«ç­æ¡çåéï¼å¤æ¨¡æï¼å®ä½ãç¶åå¨è¿äºå®ä½ä¸­æ¾å°è§£å³æ¹æ¡ï¼å­å®ä½ï¼ãä¸äºç°æå·¥ä½è§£å³äº MMKG ä¸­åºäºè·¯å¾çé®é¢åç­ãç¶èï¼æ®æä»¬æç¥ï¼æä»¬æ¯ç¬¬ä¸ä¸ªå¨æ¥è¯¢ MMKG ä¸­å¼å¥é»è¾ç»æå¹¶åç­æ¥è¯¢çäººï¼è¿äºæ¥è¯¢æ¶åå¤æ¨¡æå®ä½çå­å®ä½ä½ä¸ºç­æ¡ãå¯¹åä¸ªå¬å¼å¯ç¨ç MMKG çå¹¿æ³è¯ä¼°è¡¨æï¼RConE ä¼äºå½åçææ°ææ¯ã

##### **LARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding**
2408.11523v1 by Zhizhong Wan, Bin Yin, Junjie Xie, Fei Jiang, Xiang Li, Wei Lin

Click-Through Rate (CTR) prediction is crucial for Recommendation System(RS),
aiming to provide personalized recommendation services for users in many
aspects such as food delivery, e-commerce and so on. However, traditional RS
relies on collaborative signals, which lacks semantic understanding to
real-time scenes. We also noticed that a major challenge in utilizing Large
Language Models (LLMs) for practical recommendation purposes is their
efficiency in dealing with long text input. To break through the problems
above, we propose Large Language Model Aided Real-time Scene
Recommendation(LARR), adopt LLMs for semantic understanding, utilizing
real-time scene information in RS without requiring LLM to process the entire
real-time scene text directly, thereby enhancing the efficiency of LLM-based
CTR modeling. Specifically, recommendation domain-specific knowledge is
injected into LLM and then RS employs an aggregation encoder to build real-time
scene information from separate LLM's outputs. Firstly, a LLM is continual
pretrained on corpus built from recommendation data with the aid of special
tokens. Subsequently, the LLM is fine-tuned via contrastive learning on three
kinds of sample construction strategies. Through this step, LLM is transformed
into a text embedding model. Finally, LLM's separate outputs for different
scene features are aggregated by an encoder, aligning to collaborative signals
in RS, enhancing the performance of recommendation model.

æè¦ï¼é»æç (CTR) é æ¸¬å°æ¼æ¨è¦ç³»çµ± (RS) è³ééè¦ï¼æ¨å¨çºä½¿ç¨èæä¾åäººåçæ¨è¦æåï¼ä¾å¦éé¤ãé»å­ååç­è¨±å¤æ¹é¢ãç¶èï¼å³çµ±ç RS ä¾è³´æ¼åä½ä¿¡èï¼éç¼ºä¹å°å³æå ´æ¯çèªç¾©çè§£ãæåéæ³¨æå°ï¼å°å¤§åèªè¨æ¨¡å (LLM) ç¨æ¼å¯¦éæ¨è¦ç®ççä¸»è¦ææ°å¨æ¼å®åèçé·ææ¬è¼¸å¥çæçãçºäºçªç ´ä¸è¿°åé¡ï¼æåæåºå¤§åèªè¨æ¨¡åè¼å©å³æå ´æ¯æ¨è¦ (LARR)ï¼æ¡ç¨ LLM é²è¡èªç¾©çè§£ï¼å¨ RS ä¸­å©ç¨å³æå ´æ¯è³è¨ï¼èä¸éè¦ LLM ç´æ¥èçæ´åå³æå ´æ¯æå­ï¼å¾èæé«åºæ¼ LLM ç CTR å»ºæ¨¡çæçãå·é«ä¾èªªï¼æ¨è¦é åç¹å®çç¥è­è¢«æ³¨å¥å° LLM ä¸­ï¼ç¶å¾ RS ä½¿ç¨èåç·¨ç¢¼å¨å¾ LLM çå®ç¨è¼¸åºä¸­å»ºç«å³æå ´æ¯è³è¨ãé¦åï¼LLM å¨ç¹æ®ç¬¦èçå¹«å©ä¸ï¼å¨ç±æ¨è¦è³æå»ºç«çèªæåº«ä¸é²è¡æçºé è¨ç·´ãé¨å¾ï¼LLM ééå°æ¯å­¸ç¿å¨ä¸ç¨®æ¨£æ¬å»ºæ§ç­ç¥ä¸é²è¡å¾®èª¿ãéééåæ­¥é©ï¼LLM è½è®çºæå­åµå¥æ¨¡åãæå¾ï¼LLM éå°ä¸åå ´æ¯ç¹å¾µçå®ç¨è¼¸åºç±ç·¨ç¢¼å¨èåï¼è RS ä¸­çåä½ä¿¡èå°é½ï¼å¢å¼·æ¨è¦æ¨¡åçæè½ã

##### **Imagining from Images with an AI Storytelling Tool**
2408.11517v1 by Edirlei Soares de Lima, Marco A. Casanova, Antonio L. Furtado

A method for generating narratives by analyzing single images or image
sequences is presented, inspired by the time immemorial tradition of Narrative
Art. The proposed method explores the multimodal capabilities of GPT-4o to
interpret visual content and create engaging stories, which are illustrated by
a Stable Diffusion XL model. The method is supported by a fully implemented
tool, called ImageTeller, which accepts images from diverse sources as input.
Users can guide the narrative's development according to the conventions of
fundamental genres - such as Comedy, Romance, Tragedy, Satire or Mystery -, opt
to generate data-driven stories, or to leave the prototype free to decide how
to handle the narrative structure. User interaction is provided along the
generation process, allowing the user to request alternative chapters or
illustrations, and even reject and restart the story generation based on the
same input. Additionally, users can attach captions to the input images,
influencing the system's interpretation of the visual content. Examples of
generated stories are provided, along with details on how to access the
prototype.

æè¦ï¼<paragraph>ä¸ç¨®åèªå¤ä»¥ä¾æäºèè¡å³çµ±åç¼ï¼ééåæå®å¼µå½±åæå½±ååºåä¾çææäºçæè¡ãææåºçæè¡æ¢ç´¢ GPT-4o çå¤æ¨¡æè½åï¼ä»¥è©®éè¦è¦ºå§å®¹ä¸¦åµé å¼äººå¥åçæäºï¼éäºæäºç± Stable Diffusion XL æ¨¡åå ä»¥èªªæãéé æè¡ç±ä¸ååè½å®åçå·¥å·æ¯æï¼ç¨±çº ImageTellerï¼å®æ¥åä¾èªä¸åä¾æºçå½±åä½çºè¼¸å¥ãä½¿ç¨èå¯ä»¥æ ¹æåºæ¬é¡åï¼ä¾å¦ååãææãæ²åãè«·åºææ¸çï¼çæ£ä¾ä¾å¼å°æäºçç¼å±ï¼é¸æçæè³æé©åçæäºï¼æè®ååèªç±æ±ºå®å¦ä½èçæäºçµæ§ãä½¿ç¨èäºåå¨çæéç¨ä¸­æä¾ï¼åè¨±ä½¿ç¨èè¦æ±æ¿ä»£ç« ç¯ææåï¼çè³åºæ¼ç¸åçè¼¸å¥æçµä¸¦éæ°éå§æäºçæãæ­¤å¤ï¼ä½¿ç¨èå¯ä»¥çºè¼¸å¥å½±åéå èªªæï¼å½±é¿ç³»çµ±å°è¦è¦ºå§å®¹çè©®éãæä¾äºçææäºçç¯ä¾ï¼ä»¥åå¦ä½å­åååçè©³ç´°è³è¨ã</paragraph>

##### **IKUN for WMT24 General MT Task: LLMs Are here for Multilingual Machine Translation**
2408.11512v1 by Baohao Liao, Christian Herold, Shahram Khadivi, Christof Monz

This paper introduces two multilingual systems, IKUN and IKUN-C, developed
for the general machine translation task in WMT24. IKUN and IKUN-C represent an
open system and a constrained system, respectively, built on Llama-3-8b and
Mistral-7B-v0.3. Both systems are designed to handle all 11 language directions
using a single model. According to automatic evaluation metrics, IKUN-C
achieved 6 first-place and 3 second-place finishes among all constrained
systems, while IKUN secured 1 first-place and 2 second-place finishes across
both open and constrained systems. These encouraging results suggest that large
language models (LLMs) are nearing the level of proficiency required for
effective multilingual machine translation. The systems are based on a
two-stage approach: first, continuous pre-training on monolingual data in 10
languages, followed by fine-tuning on high-quality parallel data for 11
language directions. The primary difference between IKUN and IKUN-C lies in
their monolingual pre-training strategy. IKUN-C is pre-trained using
constrained monolingual data, whereas IKUN leverages monolingual data from the
OSCAR dataset. In the second phase, both systems are fine-tuned on parallel
data sourced from NTREX, Flores, and WMT16-23 for all 11 language pairs.

æè¦ï¼æ¬æä»ç´¹å©åå¤èªè¨ç³»çµ± IKUN å IKUN-Cï¼éäºç³»çµ±æ¯çº WMT24 ä¸­çä¸è¬æ©å¨ç¿»è­¯ä»»åéç¼çãIKUN å IKUN-C åå¥ä»£è¡¨éæ¾ç³»çµ±ååéç³»çµ±ï¼å»ºç«å¨ Llama-3-8b å Mistral-7B-v0.3 ä¸ãå©åç³»çµ±é½è¨­è¨çºä½¿ç¨å®ä¸æ¨¡åèçææ 11 ç¨®èªè¨æ¹åãæ ¹æèªåè©ä¼°ææ¨ï¼IKUN-C å¨ææåéç³»çµ±ä¸­ç²å¾ 6 åç¬¬ä¸åå 3 åç¬¬äºåï¼è IKUN å¨éæ¾ååéç³»çµ±ä¸­ç²å¾ 1 åç¬¬ä¸åå 2 åç¬¬äºåãéäºä»¤äººé¼èççµæè¡¨æï¼å¤§åèªè¨æ¨¡å (LLM) æ­£å¨æ¥è¿ææå¤èªè¨æ©å¨ç¿»è­¯æéççç·´ç¨åº¦ãéäºç³»çµ±åºæ¼å©éæ®µæ¹æ³ï¼é¦åï¼å° 10 ç¨®èªè¨çå®èªè³æé²è¡é£çºé è¨ç·´ï¼ç¶å¾å° 11 ç¨®èªè¨æ¹åçé«åè³ªå¹³è¡è³æé²è¡å¾®èª¿ãIKUN å IKUN-C ä¹éçä¸»è¦åå¥å¨æ¼å®åçå®èªé è¨ç·´ç­ç¥ãIKUN-C ä½¿ç¨åéçå®èªè³æé²è¡é è¨ç·´ï¼è IKUN åå©ç¨ OSCAR è³æéä¸­çå®èªè³æãå¨ç¬¬äºéæ®µï¼å©åç³»çµ±é½éå°ä¾èª NTREXãFlores å WMT16-23 çææ 11 ç¨®èªè¨å°çå¹³è¡è³æé²è¡å¾®èª¿ã

##### **Mutagenesis screen to map the functionals of parameters of Large Language Models**
2408.11494v1 by Yue Hu, Kai Hu, Patrick X. Zhao, Javed Khan, Chengming Xu

Large Language Models (LLMs) have significantly advanced artificial
intelligence, excelling in numerous tasks. Although the functionality of a
model is inherently tied to its parameters, a systematic method for exploring
the connections between the parameters and the functionality are lacking.
Models sharing similar structure and parameter counts exhibit significant
performance disparities across various tasks, prompting investigations into the
varying patterns that govern their performance. We adopted a mutagenesis screen
approach inspired by the methods used in biological studies, to investigate
Llama2-7b and Zephyr. This technique involved mutating elements within the
models' matrices to their maximum or minimum values to examine the relationship
between model parameters and their functionalities. Our research uncovered
multiple levels of fine structures within both models. Many matrices showed a
mixture of maximum and minimum mutations following mutagenesis, but others were
predominantly sensitive to one type. Notably, mutations that produced
phenotypes, especially those with severe outcomes, tended to cluster along
axes. Additionally, the location of maximum and minimum mutations often
displayed a complementary pattern on matrix in both models, with the Gate
matrix showing a unique two-dimensional asymmetry after rearrangement. In
Zephyr, certain mutations consistently resulted in poetic or conversational
rather than descriptive outputs. These "writer" mutations grouped according to
the high-frequency initial word of the output, with a marked tendency to share
the row coordinate even when they are in different matrices. Our findings
affirm that the mutagenesis screen is an effective tool for deciphering the
complexities of large language models and identifying unexpected ways to expand
their potential, providing deeper insights into the foundational aspects of AI
systems.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¤§å¹æ¨é²äººå·¥æºæ§ï¼å¨ç¾å¤ä»»åä¸­è¡¨ç¾åªç°ãåç®¡æ¨¡åçåè½æ¬è³ªä¸èå¶åæ¸ç¸éï¼ä½ç¼ºä¹ä¸ç¨®ç³»çµ±åçæ¹å¼ä¾æ¢ç´¢åæ¸èåè½ä¹éçéè¯ãå·æç¸ä¼¼çµæ§ååæ¸è¨æ¸çæ¨¡åå¨åç¨®ä»»åä¸­è¡¨ç¾åºé¡¯èçå·®ç°ï¼ä¿ä½¿äººåæ¢ç©¶å½±é¿å¶æè½çä¸åæ¨¡å¼ãæåæ¡ç¨äºåçç©å­¸ç ç©¶æ¹æ³åç¼çèªè®ç¯©é¸æ¹æ³ï¼ä¾æ¢ç©¶ Llama2-7b å Zephyrãæ­¤æè¡æ¶åå°æ¨¡åç©é£ä¸­çåç´ çªè®çºå¶æå¤§å¼ææå°å¼ï¼ä»¥æª¢é©æ¨¡ååæ¸èå¶åè½ä¹éçéä¿ãæåçç ç©¶æ­ç¤ºäºéå©åæ¨¡åä¸­å¤å±¤æ¬¡çç²¾ç´°çµæ§ãè¨±å¤ç©é£å¨èªè®å¾é¡¯ç¤ºåºæå¤§åæå°çªè®çæ··åï¼ä½å¶ä»ç©é£åä¸»è¦å°ä¸ç¨®é¡åææãå¼å¾æ³¨æçæ¯ï¼ç¢çè¡¨åççªè®ï¼ç¹å¥æ¯é£äºå·æå´éå¾æççªè®ï¼å¾å¾ææ²¿èè»¸ç·èéãæ­¤å¤ï¼æå¤§åæå°çªè®çä½ç½®éå¸¸å¨å©åæ¨¡åçç©é£ä¸é¡¯ç¤ºåºäºè£æ¨¡å¼ï¼å¶ä¸­ Gate ç©é£å¨éæ°æåå¾é¡¯ç¤ºåºç¨ç¹çäºç¶­ä¸å°ç¨±æ§ãå¨ Zephyr ä¸­ï¼æäºçªè®å§çµå°è´è©©ææå°è©±å¼çè¼¸åºï¼èä¸æ¯æè¿°æ§çè¼¸åºãéäºãå¯«ä½ãçªè®æ ¹æè¼¸åºçé«é »çåå§å­è©é²è¡åçµï¼å³ä½¿å®åä½æ¼ä¸åçç©é£ä¸­ï¼ä¹è¡¨ç¾åºæé¡¯çå±äº«ååº§æ¨çå¾åãæåçç ç©¶çµæè­å¯¦ï¼èªè®ç¯©é¸æ¯ä¸ç¨®è§£ç¢¼å¤§åèªè¨æ¨¡åè¤éæ§çææå·¥å·ï¼å¯è­å¥æ´å±å¶æ½åçæå¤æ¹æ³ï¼ä¸¦æä¾å° AI ç³»çµ±åºç¤å±¤é¢çæ´æ·±å¥è¦è§£ã

##### **Estimating Peer Direct and Indirect Effects in Observational Network Data**
2408.11492v1 by Xiaojing Du, Jiuyong Li, Debo Cheng, Lin Liu, Wentao Gao, Xiongren Chen

Estimating causal effects is crucial for decision-makers in many
applications, but it is particularly challenging with observational network
data due to peer interactions. Many algorithms have been proposed to estimate
causal effects involving network data, particularly peer effects, but they
often overlook the variety of peer effects. To address this issue, we propose a
general setting which considers both peer direct effects and peer indirect
effects, and the effect of an individual's own treatment, and provide
identification conditions of these causal effects and proofs. To estimate these
causal effects, we utilize attention mechanisms to distinguish the influences
of different neighbors and explore high-order neighbor effects through
multi-layer graph neural networks (GNNs). Additionally, to control the
dependency between node features and representations, we incorporate the
Hilbert-Schmidt Independence Criterion (HSIC) into the GNN, fully utilizing the
structural information of the graph, to enhance the robustness and accuracy of
the model. Extensive experiments on two semi-synthetic datasets confirm the
effectiveness of our approach. Our theoretical findings have the potential to
improve intervention strategies in networked systems, with applications in
areas such as social networks and epidemiology.

æè¦ï¼å¨è¨±å¤æç¨ä¸­ï¼ä¼°è¨å æéä¿å°æ¼æ±ºç­èè³ééè¦ï¼ä½ç±æ¼ååäºåï¼å¨è§å¯ç¶²è·¯è³æä¸­ç¹å¥å·æææ°æ§ãè¨±å¤æ¼ç®æ³å·²è¢«æåºç¨æ¼ä¼°è¨æ¶åç¶²è·¯è³æçå æéä¿ï¼ç¹å¥æ¯ååææï¼ä½å®åå¸¸å¸¸å¿½ç¥ååææçå¤æ¨£æ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åéç¨çè¨­å®ï¼åæèæ®ååç´æ¥ææåååéæ¥ææï¼ä»¥ååäººèªèº«æ²»ççææï¼ä¸¦æä¾éäºå æéä¿åè­æçè­å¥æ¢ä»¶ãçºäºä¼°è¨éäºå æéä¿ï¼æåå©ç¨æ³¨æåæ©å¶ä¾ååä¸åé°å±çå½±é¿ï¼ä¸¦ééå¤å±¤åç¥ç¶ç¶²è·¯ (GNN) æ¢ç´¢é«éé°å±ææãæ­¤å¤ï¼çºäºæ§å¶ç¯é»ç¹å¾µåè¡¨ç¤ºä¹éçä¾è³´æ§ï¼æåå°å¸ç¾ä¼¯ç¹-æ½å¯ç¹ç¨ç«æºå (HSIC) ç´å¥ GNN ä¸­ï¼ååå©ç¨åå½¢ççµæ§è³è¨ï¼ä»¥å¢å¼·æ¨¡åçç©©å¥æ§åæºç¢ºæ§ãå¨å©åååæè³æéä¸çå¤§éå¯¦é©è­å¯¦äºæåæ¹æ³çæææ§ãæåççè«ç¼ç¾æå¯è½æ¹åç¶²è·¯ç³»çµ±ä¸­çå¹²é ç­ç¥ï¼å¶æç¨é ååæ¬ç¤¾äº¤ç¶²è·¯åæµè¡çå­¸ç­ã

##### **Nothing in Excess: Mitigating the Exaggerated Safety for LLMs via Safety-Conscious Activation Steering**
2408.11491v1 by Zouying Cao, Yifei Yang, Hai Zhao

Safety alignment is indispensable for Large language models (LLMs) to defend
threats from malicious instructions. However, recent researches reveal
safety-aligned LLMs prone to reject benign queries due to the exaggerated
safety issue, limiting their helpfulness. In this paper, we propose a
Safety-Conscious Activation Steering (SCANS) method to mitigate the exaggerated
safety concerns in aligned LLMs. First, SCANS extracts the refusal steering
vectors within the activation space and utilizes vocabulary projection to
anchor some specific safety-critical layers which influence model refusal
behavior. Second, by tracking the hidden state transition, SCANS identifies the
steering direction and steers the model behavior accordingly, achieving a
balance between exaggerated safety and adequate safety. Experiments show that
SCANS achieves new state-of-the-art performance on XSTest and OKTest
benchmarks, without impairing their defense capability against harmful queries
and maintaining almost unchanged model capability.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¿é é²è¡å®å¨æ§æ ¡æºï¼æè½æµç¦¦æ¡ææä»¤çå¨èãç¶èï¼æè¿çç ç©¶é¡¯ç¤ºï¼å®å¨æ§æ ¡æºç LLM å®¹ææçµè¯æ§æ¥è©¢ï¼å çºå®å¨åé¡è¢«èªå¤§äºï¼ééå¶äºå®åçå¹«å©æ§ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®å®å¨æ§æè­ååå°å (SCANS) æ¹æ³ï¼ä»¥æ¸è¼æ ¡æº LLM ä¸­èªå¤§çå®å¨åé¡ãé¦åï¼SCANS æå¨ååç©ºéä¸­æåæçµå°ååéï¼ä¸¦å©ç¨è©å½æå½±ä¾é¨å®ä¸äºç¹å®æå½±é¿æ¨¡åæçµè¡çºçå®å¨ééµå±¤ãå¶æ¬¡ï¼ééè¿½è¹¤é±èçæè½æï¼SCANS æè­å¥å°åæ¹åï¼ä¸¦ææ­¤å°åæ¨¡åè¡çºï¼å¨èªå¤§çå®å¨æ§åé©ç¶çå®å¨ä¹éåå¾å¹³è¡¡ãå¯¦é©é¡¯ç¤ºï¼SCANS å¨ XSTest å OKTest åºæºæ¸¬è©¦ä¸­éå°äºæ°çæåé²æè½ï¼èä¸ææå®³å®åå°æå®³æ¥è©¢çé²ç¦¦è½åï¼ä¸¦ç¶­æå¹¾ä¹ä¸è®çæ¨¡åè½åã

##### **DocTabQA: Answering Questions from Long Documents Using Tables**
2408.11490v1 by Haochen Wang, Kai Hu, Haoyu Dong, Liangcai Gao

We study a new problem setting of question answering (QA), referred to as
DocTabQA. Within this setting, given a long document, the goal is to respond to
questions by organizing the answers into structured tables derived directly
from the document's content. Unlike traditional QA approaches which
predominantly rely on unstructured text to formulate responses, DocTabQA aims
to leverage structured tables as answers to convey information clearly and
systematically, thereby enhancing user comprehension and highlighting
relationships between data points. To the best of our knowledge, this problem
has not been previously explored. In this paper, we introduce the QTabA
dataset, encompassing 300 financial documents, accompanied by manually
annotated 1.5k question-table pairs. Initially, we leverage Large Language
Models (LLMs) such as GPT-4 to establish a baseline. However, it is widely
acknowledged that LLMs encounter difficulties when tasked with generating
intricate, structured outputs from long input sequences. To overcome these
challenges, we present a two-stage framework, called DocTabTalk, which
initially retrieves relevant sentences from extensive documents and
subsequently generates hierarchical tables based on these identified sentences.
DocTabTalk incorporates two key technological innovations: AlignLLaMA and
TabTalk, which are specifically tailored to assist GPT-4 in tackling DocTabQA,
enabling it to generate well-structured, hierarchical tables with improved
organization and clarity. Comprehensive experimental evaluations conducted on
both QTabA and RotoWire datasets demonstrate that our DocTabTalk significantly
enhances the performances of the GPT-4 in our proposed DocTabQA task and the
table generation task. The code and dataset are available at
https://github.com/SmileWHC/DocTabQA for further research.

æè¦ï¼<paragraph>æåç ç©¶äºä¸åæ°çåé¡è¨­å®ï¼å³åç­ï¼QAï¼ï¼ç¨±çº DocTabQAãå¨æ­¤è¨­å®ä¸­ï¼çµ¦å®ä¸åé·ææªï¼ç®æ¨æ¯ééå°ç­æ¡çµç¹æç´æ¥å¾ææªå§å®¹ä¸­å¾åºççµæ§åè¡¨æ ¼ä¾åç­åé¡ãèå³çµ±ç QA æ¹æ³ä¸åï¼å³çµ±ç QA æ¹æ³ä¸»è¦ä¾è³´éçµæ§åææ¬ä¾å¶å®åæï¼è DocTabQA æ¨å¨å©ç¨çµæ§åè¡¨æ ¼ä½çºç­æ¡ä¾æ¸æ°ç³»çµ±å°å³éä¿¡æ¯ï¼å¾èå¢å¼·ç¨æ¶çè§£ä¸¦çªåºæ¸æé»ä¹éçéä¿ãææåæç¥ï¼éååé¡ä»¥åæ²æè¢«æ¢ç´¢éãå¨æ¬æä¸­ï¼æåä»ç´¹äº QTabA æ¸æéï¼å¶ä¸­åå« 300 ä»½è²¡åæä»¶ï¼ä¸¦éææåè¨»éç 1.5k ååé¡è¡¨å°ãæåï¼æåå©ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ GPT-4 ä¾å»ºç«åºæºãç¶èï¼äººåæ®éèªçºï¼LLM å¨å¾é·è¼¸å¥åºåçæè¤éççµæ§åè¼¸åºææéå°å°é£ãçºäºåæéäºææ°ï¼æåæåºäºç¨±çº DocTabTalk çå©éæ®µæ¡æ¶ï¼è©²æ¡æ¶æåå¾å»£æ³çææªä¸­æª¢ç´¢ç¸éå¥å­ï¼ç¶å¾æ ¹æéäºå·²è­å¥çå¥å­çæåå±¤è¡¨æ ¼ãDocTabTalk çµåäºå©é ééµæè¡åµæ°ï¼AlignLLaMA å TabTalkï¼å®åå°éå®å¶çºåå© GPT-4 èç DocTabQAï¼ä½¿å¶è½å¤ çæçµæ§è¯å¥½ãåå±¤æ¸æ°ä¸çµç¹æ§æ´å¼·çè¡¨æ ¼ãå¨ QTabA å RotoWire æ¸æéä¸é²è¡çç¶åå¯¦é©è©ä¼°è¡¨æï¼æåç DocTabTalk å¨æåæåºç DocTabQA ä»»ååè¡¨æ ¼çæä»»åä¸­é¡¯èæåäº GPT-4 çæ§è½ãä»£ç¢¼åæ¸æéå¯å¨ https://github.com/SmileWHC/DocTabQA ä¸ç²å¾ï¼ä»¥ä¾é²ä¸æ­¥ç ç©¶ã</paragraph>

##### **The Self-Contained Negation Test Set**
2408.11469v1 by David Kletz, Pascal Amsili, Marie Candito

Several methodologies have recently been proposed to evaluate the ability of
Pretrained Language Models (PLMs) to interpret negation. In this article, we
build on Gubelmann and Handschuh (2022), which studies the modification of
PLMs' predictions as a function of the polarity of inputs, in English.
Crucially, this test uses ``self-contained'' inputs ending with a masked
position: depending on the polarity of a verb in the input, a particular token
is either semantically ruled out or allowed at the masked position. By
replicating Gubelmann and Handschuh (2022) experiments, we have uncovered flaws
that weaken the conclusions that can be drawn from this test. We thus propose
an improved version, the Self-Contained Neg Test, which is more controlled,
more systematic, and entirely based on examples forming minimal pairs varying
only in the presence or absence of verbal negation in English. When applying
our test to the roberta and bert base and large models, we show that only
roberta-large shows trends that match the expectations, while bert-base is
mostly insensitive to negation. For all the tested models though, in a
significant number of test instances the top-1 prediction remains the token
that is semantically forbidden by the context, which shows how much room for
improvement remains for a proper treatment of the negation phenomenon.

æè¦ï¼æè¿å·²æåºå ç§æ¹æ³æ¥è¯ä¼°é¢è®­ç»è¯­è¨æ¨¡å (PLM) è§£éå¦å®çè½åãå¨æ¬æä¸­ï¼æä»¬åºäº Gubelmann å Handschuh (2022) çç ç©¶ï¼ç ç©¶äº PLM é¢æµå è¾å¥ææ§çå½æ°èä¿®æ¹çæåµï¼ä»¥è±è¯­ä¸ºä¾ãè³å³éè¦çæ¯ï¼æ­¤æµè¯ä½¿ç¨ä»¥æ©ç ä½ç½®ç»å°¾çâèªåå«âè¾å¥ï¼æ ¹æ®è¾å¥ä¸­å¨è¯çææ§ï¼ç¹å®æ è®°å¨æ©ç ä½ç½®è¦ä¹å¨è¯­ä¹ä¸è¢«æé¤ï¼è¦ä¹è¢«åè®¸ãéè¿å¤å¶ Gubelmann å Handschuh (2022) çå®éªï¼æä»¬åç°äºåå¼±äºç±æ­¤æµè¯å¾åºçç»è®ºçç¼ºé·ãå æ­¤ï¼æä»¬æåºäºä¸ä¸ªæ¹è¿çæ¬ï¼å³èªåå«å¦å®æµè¯ï¼å®æ´åæ§ãæ´ç³»ç»ï¼å¹¶ä¸å®å¨åºäºä»å¨è±è¯­ä¸­æ¯å¦å­å¨å¦å®å¨è¯èä¸åçæå°å¯¹ç¤ºä¾ãå½å°æä»¬çæµè¯åºç¨äº roberta å bert åºç¡åå¤§æ¨¡åæ¶ï¼æä»¬åç°åªæ roberta-large æ¾ç¤ºåºç¬¦åé¢æçè¶å¿ï¼è bert-base åå¯¹å¦å®å¤§å¤ä¸ææãç¶èï¼å¯¹äºææç»è¿æµè¯çæ¨¡åï¼å¨å¤§éçæµè¯å®ä¾ä¸­ï¼æåå 1 çé¢æµä»ç¶æ¯è¯­ä¹ä¸è¢«ä¸ä¸æç¦æ­¢çæ è®°ï¼è¿è¡¨æå¨å¯¹å¦å®ç°è±¡è¿è¡éå½å¤çæ¹é¢è¿æå¾å¤§çæ¹è¿ç©ºé´ã

##### **Expanding FLORES+ Benchmark for more Low-Resource Settings: Portuguese-Emakhuwa Machine Translation Evaluation**
2408.11457v1 by Felermino D. M. Antonio Ali, Henrique Lopes Cardoso, Rui Sousa-Silva

As part of the Open Language Data Initiative shared tasks, we have expanded
the FLORES+ evaluation set to include Emakhuwa, a low-resource language widely
spoken in Mozambique. We translated the dev and devtest sets from Portuguese
into Emakhuwa, and we detail the translation process and quality assurance
measures used. Our methodology involved various quality checks, including
post-editing and adequacy assessments. The resulting datasets consist of
multiple reference sentences for each source. We present baseline results from
training a Neural Machine Translation system and fine-tuning existing
multilingual translation models. Our findings suggest that spelling
inconsistencies remain a challenge in Emakhuwa. Additionally, the baseline
models underperformed on this evaluation set, underscoring the necessity for
further research to enhance machine translation quality for Emakhuwa. The data
is publicly available at https://huggingface.co/datasets/LIACC/Emakhuwa-FLORES.

æè¦ï¼ä½çºéæ¾èªè¨è³æè¨ç«å±äº«ä»»åçä¸é¨åï¼æåå·²æ´å± FLORES+ è©ä¼°éï¼ä»¥ç´å¥å¨è«ä¸æ¯åå»£æ³ä½¿ç¨çä½è³æºèªè¨ Emakhuwaãæåå° dev å devtest éå¾è¡èçèªç¿»è­¯æ Emakhuwaï¼ä¸¦è©³ç´°èªªæç¿»è­¯éç¨åä½¿ç¨çåè³ªä¿è­æªæ½ãæåçåæ³æ¶ååç¨®åè³ªæª¢æ¥ï¼åæ¬å¾ç·¨è¼¯åé©è¶³æ§è©ä¼°ãç¢ççè³æéåå«æ¯åä¾æºçå¤ååèå¥å­ãæåå±ç¤ºäºè¨ç·´ç¥ç¶æ©å¨ç¿»è­¯ç³»çµ±åå¾®èª¿ç¾æä¹å¤èªè¨ç¿»è­¯æ¨¡åçåºæºçµæãæåçç ç©¶çµæè¡¨æï¼æ¼å¯«ä¸ä¸è´ä»ç¶æ¯ Emakhuwa çä¸é ææ°ãæ­¤å¤ï¼åºæºæ¨¡åå¨æ­¤è©ä¼°éä¸­çè¡¨ç¾ä¸ä½³ï¼å¼·èª¿é²ä¸æ­¥ç ç©¶ä»¥æå Emakhuwa çæ©å¨ç¿»è­¯åè³ªçå¿è¦æ§ãè³æå¯æ¼ https://huggingface.co/datasets/LIACC/Emakhuwa-FLORES å¬éåå¾ã

##### **Using Part-based Representations for Explainable Deep Reinforcement Learning**
2408.11455v1 by Manos Kirtas, Konstantinos Tsampazis, Loukia Avramelou, Nikolaos Passalis, Nikolaos Passalis

Utilizing deep learning models to learn part-based representations holds
significant potential for interpretable-by-design approaches, as these models
incorporate latent causes obtained from feature representations through simple
addition. However, training a part-based learning model presents challenges,
particularly in enforcing non-negative constraints on the model's parameters,
which can result in training difficulties such as instability and convergence
issues. Moreover, applying such approaches in Deep Reinforcement Learning (RL)
is even more demanding due to the inherent instabilities that impact many
optimization methods. In this paper, we propose a non-negative training
approach for actor models in RL, enabling the extraction of part-based
representations that enhance interpretability while adhering to non-negative
constraints. To this end, we employ a non-negative initialization technique, as
well as a modified sign-preserving training method, which can ensure better
gradient flow compared to existing approaches. We demonstrate the effectiveness
of the proposed approach using the well-known Cartpole benchmark.

æè¦ï¼å©ç¨æ·±åº¦å­¸ç¿æ¨¡åä¾å­¸ç¿åºæ¼é¨åçè¡¨ç¤ºï¼å°æ¼å¯è§£éçè¨­è¨æ¹æ³å·æé¡¯èçæ½åï¼å çºéäºæ¨¡åééç°¡å®çå æ³å°å¾ç¹å¾µè¡¨ç¤ºä¸­ç²å¾çæ½å¨åå ç´å¥å¶ä¸­ãç¶èï¼è¨ç·´ä¸ååºæ¼é¨åçå­¸ç¿æ¨¡åæç¢çææ°ï¼ç¹å¥æ¯å¨å°æ¨¡ååæ¸å¼·å¶éè² ç´ææï¼éå¯è½æå°è´è¨ç·´å°é£ï¼ä¾å¦ä¸ç©©å®æ§åæ¶æåé¡ãæ­¤å¤ï¼ç±æ¼å½±é¿è¨±å¤æä½³åæ¹æ³çåºæä¸ç©©å®æ§ï¼å¨æ·±åº¦å¼·åå­¸ç¿ (RL) ä¸­æç¨éç¨®æ¹æ³çè³æ´å·ææ°æ§ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®éå° RL ä¸­çåä½æ¨¡åçéè² è¨ç·´æ¹æ³ï¼å¯ä»¥æååºæ¼é¨åçè¡¨ç¤ºï¼å¨éµå®éè² ç´æçåæå¢å¼·å¯è§£éæ§ãçºæ­¤ï¼æåæ¡ç¨éè² åå§åæè¡ï¼ä»¥åä¸ç¨®ç¶éä¿®æ¹çç¬¦èä¿æè¨ç·´æ¹æ³ï¼èç¾ææ¹æ³ç¸æ¯ï¼å®å¯ä»¥ç¢ºä¿æ´å¥½çæ¢¯åº¦æµãæåä½¿ç¨èåç Cartpole åºæºå±ç¤ºäºææåºçæ¹æ³çæææ§ã

##### **Bidirectional Gated Mamba for Sequential Recommendation**
2408.11451v1 by Ziwei Liu, Qidong Liu, Yejing Wang, Wanyu Wang, Pengyue Jia, Maolin Wang, Zitao Liu, Yi Chang, Xiangyu Zhao

In various domains, Sequential Recommender Systems (SRS) have become
essential due to their superior capability to discern intricate user
preferences. Typically, SRS utilize transformer-based architectures to forecast
the subsequent item within a sequence. Nevertheless, the quadratic
computational complexity inherent in these models often leads to
inefficiencies, hindering the achievement of real-time recommendations. Mamba,
a recent advancement, has exhibited exceptional performance in time series
prediction, significantly enhancing both efficiency and accuracy. However,
integrating Mamba directly into SRS poses several challenges. Its inherently
unidirectional nature may constrain the model's capacity to capture the full
context of user-item interactions, while its instability in state estimation
can compromise its ability to detect short-term patterns within interaction
sequences.
  To overcome these issues, we introduce a new framework named
\textbf{\underline{S}}elect\textbf{\underline{I}}ve \textbf{\underline{G}}ated
\textbf{\underline{MA}}mba (SIGMA). This framework leverages a Partially
Flipped Mamba (PF-Mamba) to construct a bidirectional architecture specifically
tailored to improve contextual modeling. Additionally, an input-sensitive Dense
Selective Gate (DS Gate) is employed to optimize directional weights and
enhance the processing of sequential information in PF-Mamba. For short
sequence modeling, we have also developed a Feature Extract GRU (FE-GRU) to
efficiently capture short-term dependencies. Empirical results indicate that
SIGMA outperforms current models on five real-world datasets. Our
implementation code is available at \url{https://github.com/ziwliu-cityu/SIMGA}
to ease reproducibility.

æè¦ï¼<paragraph>å¨ååé åä¸­ï¼åºåæ¨è¦ç³»çµ± (SRS) å·²å å¶è¾¨å¥è¤éä½¿ç¨èåå¥½çåè¶è½åèè®å¾è³ééè¦ãéå¸¸ï¼SRS å©ç¨åºæ¼è½æå¨çæ¶æ§ä¾é æ¸¬åºåä¸­çå¾çºé ç®ãç¶èï¼éäºæ¨¡åä¸­åºæçäºæ¬¡è¨ç®è¤éåº¦éå¸¸æå°è´æçä½ä¸ï¼é»ç¤å³ææ¨è¦çå¯¦ç¾ãMamba æ¯ä¸é æè¿çé²å±ï¼å¨æéåºåé æ¸¬ä¸­è¡¨ç¾åºè²çæè½ï¼é¡¯èæåäºæçåæºç¢ºåº¦ãç¶èï¼å° Mamba ç´æ¥æ´åå° SRS ä¸­æç¢çä¸äºææ°ãå¶åºæçå®åæ§è³ªå¯è½æéå¶æ¨¡åæ·åä½¿ç¨èé ç®äºåçå®æ´èçµ¡çè½åï¼èå¶å¨çæä¼°è¨ä¸­çä¸ç©©å®æ§å¯è½ææå®³å¶åµæ¸¬äºååºåä¸­ç­ææ¨¡å¼çè½åã
çºäºåæéäºåé¡ï¼æåå¼å¥äºåçº\textbf{\underline{S}}elect\textbf{\underline{I}}ve \textbf{\underline{G}}ated \textbf{\underline{MA}}mba (SIGMA) çæ°æ¶æ§ãæ­¤æ¶æ§å©ç¨å±é¨ç¿»è½ Mamba (PF-Mamba) ä¾å»ºæ§å°ééå°æ¹åèçµ¡å»ºæ¨¡çéåæ¶æ§ãæ­¤å¤ï¼æ¡ç¨è¼¸å¥ææçå¯éé¸æé (DS Gate) ä¾æä½³åæ¹åæ¬éï¼ä¸¦å¢å¼· PF-Mamba ä¸­åºåè³è¨çèçãå°æ¼ç­åºåå»ºæ¨¡ï¼æåééç¼äºç¹å¾µèå GRU (FE-GRU) ä¾æææ·åç­æä¾è³´éä¿ãç¶é©çµæè¡¨æï¼SIGMA å¨äºåçå¯¦ä¸çè³æéä¸åªæ¼ç®åçæ¨¡åãæåçå¯¦ä½ç¨å¼ç¢¼å¯å¨ \url{https://github.com/ziwliu-cityu/SIMGA} åå¾ï¼ä»¥å©æ¼éç¾æ§ã</paragraph>

##### **Enabling Small Models for Zero-Shot Classification through Model Label Learning**
2408.11449v1 by Jia Zhang, Zhi Zhou, Lan-Zhe Guo, Yu-Feng Li

Vision-language models (VLMs) like CLIP have demonstrated impressive
zero-shot ability in image classification tasks by aligning text and images but
suffer inferior performance compared with task-specific expert models. On the
contrary, expert models excel in their specialized domains but lack zero-shot
ability for new tasks. How to obtain both the high performance of expert models
and zero-shot ability is an important research direction. In this paper, we
attempt to demonstrate that by constructing a model hub and aligning models
with their functionalities using model labels, new tasks can be solved in a
zero-shot manner by effectively selecting and reusing models in the hub. We
introduce a novel paradigm, Model Label Learning (MLL), which bridges the gap
between models and their functionalities through a Semantic Directed Acyclic
Graph (SDAG) and leverages an algorithm, Classification Head Combination
Optimization (CHCO), to select capable models for new tasks. Compared with the
foundation model paradigm, it is less costly and more scalable, i.e., the
zero-shot ability grows with the sizes of the model hub. Experiments on seven
real-world datasets validate the effectiveness and efficiency of MLL,
demonstrating that expert models can be effectively reused for zero-shot tasks.
Our code will be released publicly.

æè¦ï¼è¦è¦ºèªè¨æ¨¡åï¼VLMï¼ï¼ä¾å¦ CLIPï¼å·²å¨å½±ååé¡ä»»åä¸­å±ç¾ä»¤äººå°è±¡æ·±å»çé¶æ¬¡å­¸ç¿è½åï¼æ¹æ³æ¯å°é½æå­åå½±åï¼ä½èç¹å®ä»»åçå°å®¶æ¨¡åç¸æ¯ï¼å¶æè½è¼å·®ãç¸åå°ï¼å°å®¶æ¨¡åå¨å¶å°æ¥­é åä¸­è¡¨ç¾åºè²ï¼ä½å°æ¼æ°ä»»åç¼ºä¹é¶æ¬¡å­¸ç¿è½åãå¦ä½åæç²å¾å°å®¶æ¨¡åçé«æè½åé¶æ¬¡å­¸ç¿è½åï¼æ¯ä¸åéè¦çç ç©¶æ¹åãå¨æ¬æä¸­ï¼æååè©¦ééå»ºç«æ¨¡åä¸­å¿ï¼ä¸¦ä½¿ç¨æ¨¡åæ¨ç±¤å°æ¨¡åèå¶åè½å°é½ï¼è­æå¯ä»¥ééææé¸æåéè¤ä½¿ç¨ä¸­å¿ä¸­çæ¨¡åï¼ä»¥é¶æ¬¡å­¸ç¿çæ¹å¼è§£æ±ºæ°ä»»åãæåæåºäºä¸ç¨®æ°çç¯ä¾ï¼å³æ¨¡åæ¨ç±¤å­¸ç¿ï¼MLLï¼ï¼å®ééèªç¾©å°åéå¾ªç°åï¼SDAGï¼å½åæ¨¡ååå¶åè½ä¹éçå·®è·ï¼ä¸¦å©ç¨ä¸ç¨®æ¼ç®æ³ï¼å³åé¡é ­çµåæä½³åï¼CHCOï¼ï¼çºæ°ä»»åé¸ææè½åçæ¨¡åãèåºç¤æ¨¡åç¯ä¾ç¸æ¯ï¼å®çææ¬è¼ä½ä¸æ´å·å¯æ´åæ§ï¼ä¹å°±æ¯èªªï¼é¶æ¬¡å­¸ç¿è½åæé¨èæ¨¡åä¸­å¿è¦æ¨¡çæ´å¤§èå¢é·ãå¨ä¸åçå¯¦ä¸çè³æéä¸çå¯¦é©é©è­äº MLL çæææ§åæçï¼è­æäºå°å®¶æ¨¡åå¯ä»¥ææå°éè¤ç¨æ¼é¶æ¬¡å­¸ç¿ä»»åãæåçç¨å¼ç¢¼å°å¬éç¼å¸ã

##### **Lookism: The overlooked bias in computer vision**
2408.11448v1 by Aditya Gulati, Bruno Lepri, Nuria Oliver

In recent years, there have been significant advancements in computer vision
which have led to the widespread deployment of image recognition and generation
systems in socially relevant applications, from hiring to security screening.
However, the prevalence of biases within these systems has raised significant
ethical and social concerns. The most extensively studied biases in this
context are related to gender, race and age. Yet, other biases are equally
pervasive and harmful, such as lookism, i.e., the preferential treatment of
individuals based on their physical appearance. Lookism remains under-explored
in computer vision but can have profound implications not only by perpetuating
harmful societal stereotypes but also by undermining the fairness and
inclusivity of AI technologies. Thus, this paper advocates for the systematic
study of lookism as a critical bias in computer vision models. Through a
comprehensive review of existing literature, we identify three areas of
intersection between lookism and computer vision. We illustrate them by means
of examples and a user study. We call for an interdisciplinary approach to
address lookism, urging researchers, developers, and policymakers to prioritize
the development of equitable computer vision systems that respect and reflect
the diversity of human appearances.

æè¦ï¼è¿å¹´æ¥ï¼è®¡ç®æºè§è§é¢ååå¾äºéå¤§è¿å±ï¼è¿å¯¼è´äºå¾åè¯å«åçæç³»ç»å¨ç¤¾ä¼ç¸å³åºç¨ä¸­çå¹¿æ³é¨ç½²ï¼ä»æèå°å®å¨ç­æ¥ãç¶èï¼è¿äºç³»ç»ä¸­å­å¨çåè§çè¡å¼åäºéå¤§çä¼¦çåç¤¾ä¼é®é¢ãå¨æ­¤èæ¯ä¸ç ç©¶æå¹¿æ³çåè§ä¸æ§å«ãç§æåå¹´é¾æå³ãç¶èï¼å¶ä»åè§åæ ·æ®éä¸æå®³ï¼ä¾å¦å¤è²ä¸»ä¹ï¼å³æ ¹æ®ä¸ªäººçå¤è²ç»äºä¼å¾ãå¤è²ä¸»ä¹å¨è®¡ç®æºè§è§é¢åä»æªå¾å°ååæ¢ç´¢ï¼ä½ä¸ä»ä¼éè¿å»¶ç»­æå®³çç¤¾ä¼å»æ¿å°è±¡ï¼è¿ä¼ç ´åäººå·¥æºè½ææ¯çå¬å¹³æ§ååå®¹æ§ï¼ä»èäº§çæ·±è¿çå½±åãå æ­¤ï¼æ¬æä¸»å¼ ç³»ç»å°ç ç©¶å¤è²ä¸»ä¹ä½ä¸ºè®¡ç®æºè§è§æ¨¡åä¸­çå³é®åè§ãéè¿å¯¹ç°ææç®è¿è¡å¨é¢å®¡æ¥ï¼æä»¬ç¡®å®äºå¤è²ä¸»ä¹ä¸è®¡ç®æºè§è§ä¹é´çä¸ä¸ªäº¤åé¢åãæä»¬éè¿ç¤ºä¾åç¨æ·ç ç©¶å¯¹å®ä»¬è¿è¡äºè¯´æãæä»¬å¼åéç¨è·¨å­¦ç§æ¹æ³æ¥è§£å³å¤è²ä¸»ä¹é®é¢ï¼æ¦ä¿ç ç©¶äººåãå¼åäººååæ¿ç­å¶å®èä¼åèèå¼åå¬å¹³çè®¡ç®æºè§è§ç³»ç»ï¼å°éååæ äººç±»å¤è²çå¤æ ·æ§ã

##### **Distributional Properties of Subword Regularization**
2408.11443v1 by Marco Cognetta, VilÃ©m Zouhar, Naoaki Okazaki

Subword regularization, used widely in NLP, improves model performance by
reducing the dependency on exact tokenizations, augmenting the training corpus,
and exposing the model to more unique contexts during training. BPE and
MaxMatch, two popular subword tokenization schemes, have stochastic dropout
regularization variants. However, there has not been an analysis of the
distributions formed by them. We show that these stochastic variants are
heavily biased towards a small set of tokenizations per word. If the benefits
of subword regularization are as mentioned, we hypothesize that biasedness
artificially limits the effectiveness of these schemes. Thus, we propose an
algorithm to uniformly sample tokenizations that we use as a drop-in
replacement for the stochastic aspects of existing tokenizers, and find that it
improves machine translation quality.

æè¦ï¼å­è©æ­£è¦åå»£æ³ç¨æ¼ NLPï¼ééæ¸å°å°ç²¾ç¢ºåè©çä¾è³´æ§ãæ´åè¨ç·´èªæåº«ä»¥åå¨è¨ç·´æéè®æ¨¡åæ¥è§¸æ´å¤ç¨ç¹èªå¢ï¼ä¾æåæ¨¡åæè½ãBPE å MaxMatch å©åç±éçå­è©åè©æ¶æ§ï¼é½æé¨æ©ä¸­æ·æ­£è¦åçè®é«ãç¶èï¼å°æªéå°å®åå½¢æçåéé²è¡åæãæåé¡¯ç¤ºéäºé¨æ©è®é«å´éååæ¯åå­è©çä¸å°çµåè©ãå¦æå­è©æ­£è¦åçåªé»å¦æè¿°ï¼æååè¨­åè¦æäººçºå°éå¶éäºæ¶æ§çæè½ãå æ­¤ï¼æåæåºä¸åæ¼ç®æ³ä¾åå»åæ¨£åè©ï¼ä¸¦å°ä¹ç¨ä½ç¾æåè©å¨çé¨æ©é¢åçæ¿ä»£æ¹æ¡ï¼ç¼ç¾å®è½æåæ©å¨ç¿»è­¯åè³ªã

##### **LAHAJA: A Robust Multi-accent Benchmark for Evaluating Hindi ASR Systems**
2408.11440v1 by Tahir Javed, Janki Nawale, Sakshi Joshi, Eldho George, Kaushal Bhogale, Deovrat Mehendale, Mitesh M. Khapra

Hindi, one of the most spoken language of India, exhibits a diverse array of
accents due to its usage among individuals from diverse linguistic origins. To
enable a robust evaluation of Hindi ASR systems on multiple accents, we create
a benchmark, LAHAJA, which contains read and extempore speech on a diverse set
of topics and use cases, with a total of 12.5 hours of Hindi audio, sourced
from 132 speakers spanning 83 districts of India. We evaluate existing
open-source and commercial models on LAHAJA and find their performance to be
poor. We then train models using different datasets and find that our model
trained on multilingual data with good speaker diversity outperforms existing
models by a significant margin. We also present a fine-grained analysis which
shows that the performance declines for speakers from North-East and South
India, especially with content heavy in named entities and specialized
terminology.

æè¦ï¼å°å°èªæ¯å°åº¦æå»£æ³ä½¿ç¨çèªè¨ä¹ä¸ï¼ç±æ¼ä½¿ç¨å°å°èªçäººä¾èªä¸åçèªè¨èæ¯ï¼å æ­¤åç¾åºå¤ç¨®å£é³ãçºäºå°å¤ç¨®å£é³çå°å°èª ASR ç³»çµ±é²è¡ç©©å¥çè©ä¼°ï¼æåå»ºç«äºä¸ååºæº LAHAJAï¼å¶ä¸­åå«åç¨®ä¸»é¡åä½¿ç¨æ¡ä¾çæè®åå³èæ¼è¬ï¼ç¸½è¨ 12.5 å°æçå°å°èªé³è¨ï¼ä¾èªå°åº¦ 83 åå°åç 132 ä½è¬èãæåå¨ LAHAJA ä¸è©ä¼°ç¾æçéæºååæ¥­æ¨¡åï¼ç¼ç¾å®åçè¡¨ç¾ä¸ä½³ãç¶å¾æåä½¿ç¨ä¸åçè³æéè¨ç·´æ¨¡åï¼ç¼ç¾æåå¨å·æè¯å¥½è¬èå¤æ¨£æ§çå¤èªè¨è³æä¸è¨ç·´çæ¨¡åæ¯ç¾ææ¨¡åçè¡¨ç¾é«åºé¡¯èçå¹åº¦ãæåéæåºäºä¸åç´°ç²åº¦çåæï¼é¡¯ç¤ºä¾èªå°åº¦æ±åé¨ååé¨çè¬èçè¡¨ç¾ä¸éï¼ç¹å¥æ¯å¨å§å®¹ä¸­åå«å¤§éå°æåè©åå°æ¥­è¡èªçææ³ä¸ã

##### **Towards Aligned Data Removal via Twin Machine Unlearning**
2408.11433v1 by Yuyao Sun, Zhenxing Niu, Gang hua, Rong jin

Modern privacy regulations have spurred the evolution of machine unlearning,
a technique that enables the removal of data from an already trained ML model
without requiring retraining from scratch. Previous unlearning methods tend to
induce the model to achieve lowest classification accuracy on the removal data.
Nonetheless, the authentic objective of machine unlearning is to align the
unlearned model with the gold model, i.e., achieving the same classification
accuracy as the gold model. For this purpose, we present a Twin Machine
Unlearning (TMU) approach, where a twin unlearning problem is defined
corresponding to the original unlearning problem. As a results, the
generalization-label predictor trained on the twin problem can be transferred
to the original problem, facilitating aligned data removal. Comprehensive
empirical experiments illustrate that our approach significantly enhances the
alignment between the unlearned model and the gold model. Meanwhile, our method
allows data removal without compromising the model accuracy.

æè¦ï¼ç¾ä»£é±ç§æ³è¦ä¿é²äºæ©å¨å»å­¸ç¿çæ¼é²ï¼
éæ¯ä¸ç¨®æè¡ï¼å¯ä»¥å¨ä¸éå¾é ­éå§éæ°è¨ç·´çææ³ä¸ï¼
å¾å·²è¨ç·´å¥½ç ML æ¨¡åä¸­ç§»é¤è³æãååçå»å­¸ç¿æ¹æ³å¾åæ¼
èªä½¿æ¨¡åå°ç§»é¤çè³æéææä½çåé¡æºç¢ºåº¦ã
åç®¡å¦æ­¤ï¼æ©å¨å»å­¸ç¿ççå¯¦ç®æ¨æ¯å°
å»å­¸ç¿çæ¨¡åèé»éæ¨¡åå°é½ï¼äº¦å³éæèé»éæ¨¡åç¸åçåé¡
æºç¢ºåº¦ãçºäºéåç®çï¼æåæåºä¸åéæ©å¨å»å­¸ç¿ (TMU) æ¹æ³ï¼
å¶ä¸­å®ç¾©äºä¸åéå»å­¸ç¿åé¡ï¼å°æå°åå§çå»å­¸ç¿åé¡ãçµææ¯ï¼
å¨ééåé¡ä¸è¨ç·´çæ¦åæ¨ç±¤é æ¸¬å¨å¯ä»¥è½ç§»å°åå§åé¡ä¸ï¼
ä¿é²å°é½çè³æç§»é¤ãå¨é¢çç¶é©å¯¦é©èªªææåçåæ³é¡¯èå°å å¼·äº
å»å­¸ç¿æ¨¡ååé»éæ¨¡åä¹éçå°é½ãåæï¼æåçåæ³
åè¨±è³æç§»é¤èä¸å½±é¿æ¨¡åæºç¢ºåº¦ã

##### **Diagnosing and Remedying Knowledge Deficiencies in LLMs via Label-free Curricular Meaningful Learning**
2408.11431v1 by Kai Xiong, Xiao Ding, Li Du, Jiahao Ying, Ting Liu, Bing Qin, Yixin Cao

Large Language Models (LLMs) are versatile and demonstrate impressive
generalization ability by mining and learning information from extensive
unlabeled text. However, they still exhibit reasoning mistakes, often stemming
from knowledge deficiencies, which can affect their trustworthiness and
reliability. Although users can provide diverse and comprehensive queries,
obtaining sufficient and effective feedback is demanding. Furthermore,
evaluating LLMs comprehensively with limited labeled samples is difficult. This
makes it a challenge to diagnose and remedy the deficiencies of LLMs through
rich label-free user queries. To tackle this challenge, we propose a label-free
curricular meaningful learning framework (LaMer). LaMer first employs relative
entropy to automatically diagnose and quantify the knowledge deficiencies of
LLMs in a label-free setting. Next, to remedy the diagnosed knowledge
deficiencies, we apply curricular meaningful learning: first, we adopt
meaningful learning to adaptively synthesize augmentation data according to the
severity of the deficiencies, and then design a curricular deficiency remedy
strategy to remedy the knowledge deficiencies of LLMs progressively.
Experiments show that LaMer efficiently and effectively diagnoses and remedies
knowledge deficiencies in LLMs, improving various LLMs across seven
out-of-distribution (OOD) reasoning and language understanding benchmarks,
achieving comparable results to baselines with just 40\% training data. LaMer
even surpasses methods that rely on labeled datasets for deficiency diagnosis.
In application, our label-free method can offer an effective knowledge
deficiency diagnostic tool for efficient LLM development.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·æå¤åè½æ§ï¼ä¸¦ä¸ééææåå­¸ç¿å¤§éæªæ¨è¨æå­ä¸­çè³è¨ï¼å±ç¾åºä»¤äººå°è±¡æ·±å»çæ¦æ¬è½åãç¶èï¼å®åä»ç¶æåºç¾æ¨çé¯èª¤ï¼éå¸¸æºæ¼ç¥è­ä¸è¶³ï¼éå¯è½æå½±é¿å®åçä¿¡è³´åº¦åå¯é æ§ãåç®¡ä½¿ç¨èå¯ä»¥æä¾å¤åä¸å¨é¢çæ¥è©¢ï¼ä½åå¾åè¶³ä¸ææçåé¥å»å¾å°é£ãæ­¤å¤ï¼ä½¿ç¨æéçæ¨ç±¤ç¯ä¾å¨é¢è©ä¼° LLM ä¹å¾å°é£ãéä½¿å¾ééè±å¯çç¡æ¨ç±¤ä½¿ç¨èæ¥è©¢ä¾è¨ºæ·åè£æ LLM çç¼ºé·æçºä¸é ææ°ãçºäºæå°æ­¤ææ°ï¼æåæåºäºä¸åç¡æ¨ç±¤èª²ç¨ææç¾©å­¸ç¿æ¶æ§ (LaMer)ãLaMer é¦åæ¡ç¨ç¸å°çµå¨ç¡æ¨ç±¤è¨­å®ä¸­èªåè¨ºæ·åéå LLM çç¥è­ç¼ºé·ãæ¥ä¸ä¾ï¼çºäºè£æè¨ºæ·åºçç¥è­ç¼ºé·ï¼æåæç¨èª²ç¨ææç¾©å­¸ç¿ï¼é¦åï¼æåæ¡ç¨ææç¾©çå­¸ç¿ä¾æ ¹æç¼ºé·çå´éæ§èªé©æå°åææ´åè³æï¼ç¶å¾è¨­è¨ä¸åèª²ç¨ç¼ºé·è£æç­ç¥ä¾éæ­¥è£æ LLM çç¥è­ç¼ºé·ãå¯¦é©è¡¨æï¼LaMer ææå°è¨ºæ·åè£æäº LLM ä¸­çç¥è­ç¼ºé·ï¼æ¹é²äºä¸ç¨®åä½å¤ (OOD) æ¨çåèªè¨çè§£åºæºä¸­çåç¨® LLMï¼åä½¿ç¨ 40% çè¨ç·´è³æå°±éå°äºèåºç·ç¸ç¶ççµæãLaMer çè³è¶è¶äºä¾è³´æ¨ç±¤è³æéé²è¡ç¼ºé·è¨ºæ·çæ¹æ³ãå¨æç¨ä¸­ï¼æåçç¡æ¨ç±¤æ¹æ³å¯ä»¥çºé«æç LLM éç¼æä¾ä¸åææçç¥è­ç¼ºé·è¨ºæ·å·¥å·ã

##### **Towards "Differential AI Psychology" and in-context Value-driven Statement Alignment with Moral Foundations Theory**
2408.11415v1 by Simon MÃ¼nker

Contemporary research in social sciences is increasingly utilizing
state-of-the-art statistical language models to annotate or generate content.
While these models perform benchmark-leading on common language tasks and show
exemplary task-independent emergent abilities, transferring them to novel
out-of-domain tasks is only insufficiently explored. The implications of the
statistical black-box approach - stochastic parrots - are prominently
criticized in the language model research community; however, the significance
for novel generative tasks is not.
  This work investigates the alignment between personalized language models and
survey participants on a Moral Foundation Theory questionnaire. We adapt
text-to-text models to different political personas and survey the
questionnaire repetitively to generate a synthetic population of persona and
model combinations. Analyzing the intra-group variance and cross-alignment
shows significant differences across models and personas. Our findings indicate
that adapted models struggle to represent the survey-captured assessment of
political ideologies. Thus, using language models to mimic social interactions
requires measurable improvements in in-context optimization or parameter
manipulation to align with psychological and sociological stereotypes. Without
quantifiable alignment, generating politically nuanced content remains
unfeasible. To enhance these representations, we propose a testable framework
to generate agents based on moral value statements for future research.

æè¦ï¼ç¶ä»£ç¤¾æç§å­¸ç ç©¶æ­£æ¥çå©ç¨æåé²ççµ±è¨èªè¨æ¨¡åä¾è¨»è§£æç¢çå§å®¹ãéç¶éäºæ¨¡åå¨å¸¸è¦èªè¨ä»»åä¸­è¡¨ç¾åºé åçåºæºï¼ä¸¦å±ç¾åºç¤ºç¯æ§çèä»»åç¡éçæµ®ç¾è½åï¼ä½å°å®åè½ç§»å°æ°çé åå¤ä»»åä¸­å»åªè¢«ä¸è¶³å°æ¢ç´¢ãçµ±è¨é»ç®±æ¹æ³ï¼é¨æ©é¸éµ¡ï¼çå«ç¾©å¨èªè¨æ¨¡åç ç©¶ç¤¾ç¾¤ä¸­åå°é¡¯èæ¹è©ï¼ç¶èï¼å°æ¼æ°ççæä»»åçæç¾©å»ä¸ç¶ãéé å·¥ä½æ¢è¨äºåäººåèªè¨æ¨¡åèéå¾·åºç¤çè«åå·ä¸­çèª¿æ¥åèèä¹éçå°é½ãæåå°æå­è½æå­æ¨¡åèª¿æ´çºä¸åçæ¿æ²»è§è²ï¼ä¸¦éè¤èª¿æ¥åå·ä»¥ç¢çä¸åç±è§è²åæ¨¡åçµåèæçåææç¾¤ãåæç¾¤å§è®ç°åäº¤åå°é½é¡¯ç¤ºåºæ¨¡ååè§è²ä¹éæé¡¯èçå·®ç°ãæåçç ç©¶çµæè¡¨æï¼èª¿æ´å¾çæ¨¡åé£ä»¥ä»£è¡¨æ¿æ²»æè­å½¢æçèª¿æ¥ææè©ä¼°ãå æ­¤ï¼ä½¿ç¨èªè¨æ¨¡åä¾æ¨¡æ¬ç¤¾æäºåéè¦å¨æå¢åªåæåæ¸æä½ä¸­é²è¡å¯è¡¡éçæ¹é²ï¼ä»¥èå¿çåç¤¾æå­¸çå»æ¿å°è±¡ä¿æä¸è´ãå¨æ²æå¯éåå°é½çææ³ä¸ï¼ç¢çæ¿æ²»å¾®å¦çå§å®¹ä»ç¶ä¸å¯è¡ãçºäºå¢å¼·éäºè¡¨å¾µï¼æåæåºäºä¸åå¯æ¸¬è©¦çæ¡æ¶ï¼ä»¥æ ¹æéå¾·å¹å¼é³è¿°çºåºç¤çæä»£çï¼ä¾æªä¾çç ç©¶ä½¿ç¨ã

##### **MoE-LPR: Multilingual Extension of Large Language Models through Mixture-of-Experts with Language Priors Routing**
2408.11396v1 by Hao Zhou, Zhijun Wang, Shujian Huang, Xin Huang, Xue Han, Junlan Feng, Chao Deng, Weihua Luo, Jiajun Chen

Large Language Models (LLMs) are often English-centric due to the
disproportionate distribution of languages in their pre-training data.
Enhancing non-English language capabilities through post-pretraining often
results in catastrophic forgetting of the ability of original languages.
Previous methods either achieve good expansion with severe forgetting or slight
forgetting with poor expansion, indicating the challenge of balancing language
expansion while preventing forgetting. In this paper, we propose a method
called MoE-LPR (Mixture-of-Experts with Language Priors Routing) to alleviate
this problem. MoE-LPR employs a two-stage training approach to enhance the
multilingual capability. First, the model is post-pretrained into a
Mixture-of-Experts (MoE) architecture by upcycling, where all the original
parameters are frozen and new experts are added. In this stage, we focus
improving the ability on expanded languages, without using any original
language data. Then, the model reviews the knowledge of the original languages
with replay data amounting to less than 1% of post-pretraining, where we
incorporate language priors routing to better recover the abilities of the
original languages. Evaluations on multiple benchmarks show that MoE-LPR
outperforms other post-pretraining methods. Freezing original parameters
preserves original language knowledge while adding new experts preserves the
learning ability. Reviewing with LPR enables effective utilization of
multilingual knowledge within the parameters. Additionally, the MoE
architecture maintains the same inference overhead while increasing total model
parameters. Extensive experiments demonstrate MoE-LPR's effectiveness in
improving expanded languages and preserving original language proficiency with
superior scalability. Code and scripts are freely available at
https://github.com/zjwang21/MoE-LPR.git.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼éå¸¸ä»¥è±èªçºä¸­å¿ï¼å çºå¨é è¨ç·´è³æä¸­èªè¨åä½ä¸åè¡¡ãééå¾é è¨ç·´å¢å¼·éè±èªèªè¨è½åéå¸¸æå°è´åæ¬èªè¨è½åçç½é£æ§éºå¿ãååçåæ³ä¸æ¯éå°è¯å¥½çæ´åï¼ä½æå´éçéºå¿ï¼å°±æ¯éºå¿è¼å¾®ä½æ´åä¸è¯ï¼éè¡¨ç¤ºå¨é²æ­¢éºå¿çåæå¹³è¡¡èªè¨æ´åçææ°ãå¨æ¬æä¸­ï¼æåæåºä¸åç¨±çº MoE-LPRï¼æ··åå°å®¶èèªè¨åé©è·¯ç±ï¼çæ¹æ³ä¾æ¸è¼éååé¡ãMoE-LPR æ¡ç¨å©éæ®µçè¨ç·´æ¹æ³ä¾å¢å¼·å¤èªè¨è½åãé¦åï¼æ¨¡åééåç´å¾é è¨ç·´ææ··åå°å®¶ï¼MoEï¼æ¶æ§ï¼å¶ä¸­ææåæ¬çåæ¸é½æåçµï¼ä¸¦å å¥æ°çå°å®¶ãå¨éåéæ®µï¼æåå°æ³¨æ¼æåæ´åèªè¨çè½åï¼èä¸ä½¿ç¨ä»»ä½åæ¬çèªè¨è³æãæ¥èï¼æ¨¡åææª¢è¦åæ¬èªè¨çç¥è­ï¼ä¸¦ä½¿ç¨å°æ¼ 1% å¾é è¨ç·´çéæ­è³æï¼å¶ä¸­æåç´å¥èªè¨åé©è·¯ç±ï¼ä»¥ä¾¿æ´å¥½å°æ¢å¾©åæ¬èªè¨çè½åãå¨å¤ååºæºä¸çè©ä¼°é¡¯ç¤ºï¼MoE-LPR çè¡¨ç¾åªæ¼å¶ä»å¾é è¨ç·´æ¹æ³ãåçµåæ¬çåæ¸å¯ä»¥ä¿çåæ¬çèªè¨ç¥è­ï¼åæå å¥æ°çå°å®¶å¯ä»¥ä¿çå­¸ç¿è½åãä½¿ç¨ LPR æª¢è¦å¯ä»¥ææå©ç¨åæ¸ä¸­çå¤èªè¨ç¥è­ãæ­¤å¤ï¼MoE æ¶æ§å¨å¢å ç¸½æ¨¡ååæ¸çåæï¼ç¶­æç¸åçæ¨è«éé·ãå»£æ³çå¯¦é©è­æäº MoE-LPR å¨æåæ´åèªè¨åä¿çåæ¬èªè¨è½åæ¹é¢çæè½ï¼ä¸¦å·æåªç°çå¯æ´åæ§ãç¨å¼ç¢¼åæä»¤ç¢¼å¯æ¼ https://github.com/zjwang21/MoE-LPR.git åè²»åå¾ã

##### **First Activations Matter: Training-Free Methods for Dynamic Activation in Large Language Models**
2408.11393v1 by Chi Ma, Mincong Huang, Ying Zhang, Chao Wang, Yujie Wang, Lei Yu, Chuan Liu, Wei Lin

Dynamic activation (DA) techniques, such as DejaVu and MoEfication, have
demonstrated their potential to significantly enhance the inference efficiency
of large language models (LLMs). However, these techniques often rely on ReLU
activation functions or require additional parameters and training to maintain
performance. This paper introduces a training-free Threshold-based Dynamic
Activation(TDA) method that leverage sequence information to exploit the
inherent sparsity of models across various architectures. This method is
designed to accelerate generation speed by 18-25\% without significantly
compromising task performance, thereby addressing the limitations of existing
DA techniques. Moreover, we delve into the root causes of LLM sparsity and
theoretically analyze two of its critical features: history-related activation
uncertainty and semantic-irrelevant activation inertia. Our comprehensive
analyses not only provide a robust theoretical foundation for DA methods but
also offer valuable insights to guide future research in optimizing LLMs for
greater efficiency and effectiveness.

æè¦ï¼åææ¿æ´» (DA) æè¡ï¼ä¾å¦ DejaVu å MoEficationï¼å·²è­æå¶å¤§å¹æåå¤§åèªè¨æ¨¡å (LLM) æ¨è«æççæ½åãç¶èï¼éäºæè¡éå¸¸ä¾è³´æ¼ ReLU æ¿æ´»å½æ¸æéè¦é¡å¤çåæ¸åè¨ç·´ä¾ç¶­ææè½ãæ¬æä»ç´¹äºä¸ç¨®ç¡éè¨ç·´çåºæ¼é¾å¼çåææ¿æ´» (TDA) æ¹æ³ï¼å®å©ç¨åºåè³è¨ä¾å©ç¨åç¨®æ¶æ§ä¸­æ¨¡ååºæçç¨çæ§ãæ­¤æ¹æ³æ¨å¨å°ç¢çéåº¦æå 18-25%ï¼åæä¸é¡¯èæå®³ä»»åæè½ï¼å¾èè§£æ±ºç¾æ DA æè¡çéå¶ãæ­¤å¤ï¼æåæ·±å¥æ¢è¨äº LLM ç¨çæ§çæ ¹æ¬åå ï¼ä¸¦å¾çè«ä¸åæäºå¶å©åééµç¹å¾µï¼èæ­·å²ç¸éçæ¿æ´»ä¸ç¢ºå®æ§åèèªç¾©ç¡éçæ¿æ´»æ£æ§ãæåå¨é¢çåæä¸åçº DA æ¹æ³æä¾äºç©©å¥ççè«åºç¤ï¼éæä¾äºå¯¶è²´çè¦è§£ï¼ä»¥æå°æªä¾åªå LLM ä»¥æé«æçåæè½çç ç©¶ã

##### **Data-Centric Machine Learning for Earth Observation: Necessary and Sufficient Features**
2408.11384v1 by Hiba Najjar, Marlon Nuske, Andreas Dengel

The availability of temporal geospatial data in multiple modalities has been
extensively leveraged to enhance the performance of machine learning models.
While efforts on the design of adequate model architectures are approaching a
level of saturation, focusing on a data-centric perspective can complement
these efforts to achieve further enhancements in data usage efficiency and
model generalization capacities. This work contributes to this direction. We
leverage model explanation methods to identify the features crucial for the
model to reach optimal performance and the smallest set of features sufficient
to achieve this performance. We evaluate our approach on three temporal
multimodal geospatial datasets and compare multiple model explanation
techniques. Our results reveal that some datasets can reach their optimal
accuracy with less than 20% of the temporal instances, while in other datasets,
the time series of a single band from a single modality is sufficient.

æè¦ï¼æç©ºå°çç©ºéè³æå¨å¤éæ¨¡å¼ä¸çå¯åå¾æ§å·²è¢«å»£æ³éç¨æ¼æåæ©å¨å­¸ç¿æ¨¡åçæè½ã
åç®¡å¨é©ç¶æ¨¡åæ¶æ§çè¨­è¨ä¸æåçåªåå·²æ¥è¿é£½åçç¨åº¦ï¼ä½å°æ³¨æ¼ä»¥è³æçºä¸­å¿çè§é»å¯ä»¥è£åéäºåªåï¼ä»¥é²ä¸æ­¥æåè³æä½¿ç¨æçåæ¨¡åæ¦åè½åãéé å·¥ä½æå©æ¼æ­¤æ¹åãæåéç¨æ¨¡åè§£éæ¹æ³ä¾æ¾åºå°æ¼æ¨¡åéå°æä½³æè½è³ééè¦çç¹å¾µï¼ä»¥åè¶³ä»¥éææ­¤æè½çæå°ç¹å¾µéãæåå¨ä¸åæåºå¤æ¨¡å¼æç©ºå°çç©ºéè³æéä¸è©ä¼°æåçåæ³ï¼ä¸¦æ¯è¼å¤ç¨®æ¨¡åè§£éæå·§ãæåççµæé¡¯ç¤ºï¼æäºè³æéå¯ä»¥ç¨ä¸å° 20% çæåºå¯¦ä¾éå°æä½³æºç¢ºåº¦ï¼èå¨å¶ä»è³æéä¸­ï¼å®ä¸æ¨¡å¼ä¸­å®ä¸é »æ®µçæéåºåå°±å·²è¶³å¤ ã

##### **On the Interchangeability of Positional Embeddings in Multilingual Neural Machine Translation Models**
2408.11382v1 by Varun Gumma, Pranjal A. Chitale, Kalika Bali

Standard Neural Machine Translation (NMT) models have traditionally been
trained with Sinusoidal Positional Embeddings (PEs), which are inadequate for
capturing long-range dependencies and are inefficient for long-context or
document-level translation. In contrast, state-of-the-art large language models
(LLMs) employ relative PEs, demonstrating superior length generalization. This
work explores the potential for efficiently switching the Positional Embeddings
of pre-trained NMT models from absolute sinusoidal PEs to relative approaches
such as RoPE and ALiBi. Our findings reveal that sinusoidal PEs can be
effectively replaced with RoPE and ALiBi with negligible or no performance
loss, achieved by fine-tuning on a small fraction of high-quality data.
Additionally, models trained without Positional Embeddings (NoPE) are not a
viable solution for Encoder-Decoder architectures, as they consistently
under-perform compared to models utilizing any form of Positional Embedding.
Furthermore, even a model trained from scratch with these relative PEs slightly
under-performs a fine-tuned model, underscoring the efficiency and validity of
our hypothesis.

æè¦ï¼æ¨æºç¥ç¶æ©å¨ç¿»è­¯ (NMT) æ¨¡åå³çµ±ä¸ä½¿ç¨æ­£å¼¦ä½ç½®åµå¥ (PE) é²è¡è¨ç·´ï¼éå°æ¼ææé·è·é¢ä¾è³´æ§æ¯ä¸å¤ çï¼ä¸¦ä¸å°æ¼é·æææä»¶ç´å¥çç¿»è­¯æçä½ä¸ãç¸æ¯ä¹ä¸ï¼æåé²çå¤§èªè¨æ¨¡å (LLM) ä½¿ç¨ç¸å° PEï¼å±ç¤ºäºåªè¶çé·åº¦æ³åãéé å·¥ä½æ¢è¨äºææåæé è¨ç·´ NMT æ¨¡åçä½ç½®åµå¥çå¯è½æ§ï¼å¾çµå°æ­£å¼¦ PE è½æçºç¸å°æ¹æ³ï¼ä¾å¦ RoPE å ALiBiãæåçç ç©¶çµæè¡¨æï¼æ­£å¼¦ PE å¯ä»¥ææå°ç¨ RoPE å ALiBi æ¿æï¼èå¹¾ä¹ä¸ææä¸æé ææè½æå¤±ï¼éå¯ééå¾®èª¿ä¸å°é¨åé«åè³ªè³æä¾å¯¦ç¾ãæ­¤å¤ï¼æ²æä½ç½®åµå¥ (NoPE) è¨ç·´çæ¨¡åä¸¦éç·¨ç¢¼å¨-è§£ç¢¼å¨æ¶æ§çå¯è¡è§£æ±ºæ¹æ¡ï¼å çºèä½¿ç¨ä»»ä½å½¢å¼çä½ç½®åµå¥çæ¨¡åç¸æ¯ï¼å®åå§çµè¡¨ç¾ä¸ä½³ãæ­¤å¤ï¼å³ä½¿å¾é ­éå§ä½¿ç¨éäºç¸å° PE è¨ç·´çæ¨¡åï¼å¶æè½ä¹ç¥ä½æ¼å¾®èª¿æ¨¡åï¼éå¼·èª¿äºæååè¨­çæçåæææ§ã

##### **RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation**
2408.11381v1 by Xuanwang Zhang, Yunze Song, Yidong Wang, Shuyun Tang, Xinfeng Li, Zhengran Zeng, Zhen Wu, Wei Ye, Wenyuan Xu, Yue Zhang, Xinyu Dai, Shikun Zhang, Qingsong Wen

Large Language Models (LLMs) demonstrate human-level capabilities in
dialogue, reasoning, and knowledge retention. However, even the most advanced
LLMs face challenges such as hallucinations and real-time updating of their
knowledge. Current research addresses this bottleneck by equipping LLMs with
external knowledge, a technique known as Retrieval Augmented Generation (RAG).
However, two key issues constrained the development of RAG. First, there is a
growing lack of comprehensive and fair comparisons between novel RAG
algorithms. Second, open-source tools such as LlamaIndex and LangChain employ
high-level abstractions, which results in a lack of transparency and limits the
ability to develop novel algorithms and evaluation metrics. To close this gap,
we introduce RAGLAB, a modular and research-oriented open-source library.
RAGLAB reproduces 6 existing algorithms and provides a comprehensive ecosystem
for investigating RAG algorithms. Leveraging RAGLAB, we conduct a fair
comparison of 6 RAG algorithms across 10 benchmarks. With RAGLAB, researchers
can efficiently compare the performance of various algorithms and develop novel
algorithms.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å°è©±ãæ¨çåç¥è­ä¿çæ¹é¢å±ç¾åºäººé¡ç­ç´çè½åãç¶èï¼å³ä½¿æ¯æåé²ç LLM ä¹æé¢è¨å¹»è¦ºåå¶ç¥è­çå³ææ´æ°ç­ææ°ãç®åçç ç©¶æééçº LLM æä¾å¤é¨ç¥è­ä¾è§£æ±ºéåç¶é ¸ï¼éé æè¡ç¨±çºæª¢ç´¢æ´å¢çæ (RAG)ãç¶èï¼å©åééµåé¡éå¶äº RAG çç¼å±ãé¦åï¼æ°ç RAG æ¼ç®æ³ä¹éç¼ºä¹å¨é¢ä¸å¬å¹³çæ¯è¼ãå¶æ¬¡ï¼LlamaIndex å LangChain ç­éæ¾åå§ç¢¼å·¥å·æ¡ç¨é«éæ½è±¡ï¼å°è´ç¼ºä¹éæåº¦ä¸¦éå¶äºéç¼æ°æ¼ç®æ³åè©ä¼°ææ¨çè½åãçºäºå½è£éåå·®è·ï¼æåå¼å¥äº RAGLABï¼ä¸åæ¨¡çµåä¸ä»¥ç ç©¶çºå°åçéæ¾åå§ç¢¼ç¨å¼åº«ãRAGLAB éç¾ 6 åç¾ææ¼ç®æ³ï¼ä¸¦æä¾ä¸åå¨é¢ççæç³»çµ±ä¾ç ç©¶ RAG æ¼ç®æ³ãå©ç¨ RAGLABï¼æåå° 6 å RAG æ¼ç®æ³å¨ 10 ååºæºä¸é²è¡å¬å¹³çæ¯è¼ãéé RAGLABï¼ç ç©¶äººå¡å¯ä»¥ææå°æ¯è¼åç¨®æ¼ç®æ³çæè½ï¼ä¸¦éç¼æ°çæ¼ç®æ³ã

##### **Reflex-Based Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models**
2408.11380v1 by Kento Kawaharazuka, Yoshiki Obinata, Naoaki Kanazawa, Naoto Tsukamoto, Kei Okada, Masayuki Inaba

Various robot navigation methods have been developed, but they are mainly
based on Simultaneous Localization and Mapping (SLAM), reinforcement learning,
etc., which require prior map construction or learning. In this study, we
consider the simplest method that does not require any map construction or
learning, and execute open-vocabulary navigation of robots without any prior
knowledge to do this. We applied an omnidirectional camera and pre-trained
vision-language models to the robot. The omnidirectional camera provides a
uniform view of the surroundings, thus eliminating the need for complicated
exploratory behaviors including trajectory generation. By applying multiple
pre-trained vision-language models to this omnidirectional image and
incorporating reflective behaviors, we show that navigation becomes simple and
does not require any prior setup. Interesting properties and limitations of our
method are discussed based on experiments with the mobile robot Fetch.

æè¦ï¼å·²éç¼åºåç¨®æ©å¨äººå°èªæ¹æ³ï¼ä½å®åä¸»è¦åºæ¼åæå®ä½èå»ºå (SLAM)ãå¼·åå­¸ç¿ç­ï¼éè¦äºåå»ºæ§å°åæå­¸ç¿ãå¨æ¬ç ç©¶ä¸­ï¼æåèæ®æç°¡å®çæ¹æ³ï¼ä¸éè¦ä»»ä½å°åå»ºæ§æå­¸ç¿ï¼ä¸¦å·è¡æ©å¨äººçéæ¾å¼è©å½å°èªï¼ç¡éä»»ä½åé©ç¥è­å³å¯å·è¡æ­¤æä½ãæåå°å¨æ¯ç¸æ©åé åè¨ç·´çè¦è¦ºèªè¨æ¨¡åæç¨æ¼æ©å¨äººãå¨æ¯ç¸æ©æä¾å¨åç°å¢ççµ±ä¸è¦åï¼å æ­¤ç¡éè¤éçæ¢ç´¢è¡çºï¼åæ¬è»è·¡çæãééå°å¤åé åè¨ç·´çè¦è¦ºèªè¨æ¨¡åæç¨æ¼æ­¤å¨æ¯ååä¸¦çµååå°è¡çºï¼æåè¡¨æå°èªè®å¾ç°¡å®ï¼ä¸¦ä¸ä¸éè¦ä»»ä½ååçè¨­ç½®ãæ ¹æä½¿ç¨ç§»åæ©å¨äºº Fetch é²è¡çå¯¦é©ï¼è¨è«äºæåæ¹æ³çæè¶£ç¹æ§åéå¶ã

##### **Denoising Pre-Training and Customized Prompt Learning for Efficient Multi-Behavior Sequential Recommendation**
2408.11372v1 by Hao Wang, Yongqiang Han, Kefan Wang, Kai Cheng, Zhen Wang, Wei Guo, Yong Liu, Defu Lian, Enhong Chen

In the realm of recommendation systems, users exhibit a diverse array of
behaviors when interacting with items. This phenomenon has spurred research
into learning the implicit semantic relationships between these behaviors to
enhance recommendation performance. However, these methods often entail high
computational complexity. To address concerns regarding efficiency,
pre-training presents a viable solution. Its objective is to extract knowledge
from extensive pre-training data and fine-tune the model for downstream tasks.
Nevertheless, previous pre-training methods have primarily focused on
single-behavior data, while multi-behavior data contains significant noise.
Additionally, the fully fine-tuning strategy adopted by these methods still
imposes a considerable computational burden. In response to this challenge, we
propose DPCPL, the first pre-training and prompt-tuning paradigm tailored for
Multi-Behavior Sequential Recommendation. Specifically, in the pre-training
stage, we commence by proposing a novel Efficient Behavior Miner (EBM) to
filter out the noise at multiple time scales, thereby facilitating the
comprehension of the contextual semantics of multi-behavior sequences.
Subsequently, we propose to tune the pre-trained model in a highly efficient
manner with the proposed Customized Prompt Learning (CPL) module, which
generates personalized, progressive, and diverse prompts to fully exploit the
potential of the pre-trained model effectively. Extensive experiments on three
real-world datasets have unequivocally demonstrated that DPCPL not only
exhibits high efficiency and effectiveness, requiring minimal parameter
adjustments but also surpasses the state-of-the-art performance across a
diverse range of downstream tasks.

æè¦ï¼<paragraph>å¨æ¨è¦ç³»çµ±é åä¸­ï¼ä½¿ç¨èå¨èé ç®äºåææè¡¨ç¾åºåç¨®ä¸åçè¡çºãéç¨®ç¾è±¡ä¿ä½¿ç ç©¶äººå¡å­¸ç¿éäºè¡çºä¹éé±å«çèªç¾©éä¿ï¼ä»¥æåæ¨è¦æè½ãç¶èï¼éäºæ¹æ³éå¸¸éè¦å¾é«çéç®è¤éåº¦ãçºäºè§£æ±ºæçæ¹é¢ççæ®ï¼é è¨ç·´æä¾äºä¸åå¯è¡çè§£æ±ºæ¹æ¡ãå®çç®æ¨æ¯å¾å¤§éçé è¨ç·´è³æä¸­èååºç¥è­ï¼ä¸¦éå°ä¸æ¸¸ä»»åå¾®èª¿æ¨¡åãåç®¡å¦æ­¤ï¼ååçé è¨ç·´æ¹æ³ä¸»è¦éä¸­å¨å®ä¸è¡çºè³æä¸ï¼èå¤è¡çºè³æåå«å¤§éçéè¨ãæ­¤å¤ï¼éäºæ¹æ³æ¡ç¨çå®å¨å¾®èª¿ç­ç¥ä»ç¶æå¸¶ä¾ç¸ç¶å¤§çéç®è² æãçºäºæå°éåææ°ï¼æåæåº DPCPLï¼éæ¯ç¬¬ä¸åéå°å¤è¡çºé åºæ¨è¦éèº«æé çé è¨ç·´åæç¤ºèª¿æ´ç¯ä¾ãç¹å¥æ¯å¨é è¨ç·´éæ®µï¼æåé¦åæåºä¸åæ°ç©çææè¡çºææå¨ (EBM)ï¼ä»¥å¨å¤åæéå°ºåº¦ä¸­æ¿¾é¤éè¨ï¼å¾èä¿é²å°å¤è¡çºåºåçèçµ¡èªç¾©çè§£ãé¨å¾ï¼æåæåºä½¿ç¨ææåºçèªè¨æç¤ºå­¸ç¿ (CPL) æ¨¡çµä»¥é«åº¦ææçæ¹å¼èª¿æ´é è¨ç·´æ¨¡åï¼è©²æ¨¡çµæç¢çåäººåãæ¼¸é²å¼åå¤æ¨£åçæç¤ºï¼ä»¥ææå°ååç¼æ®é è¨ç·´æ¨¡åçæ½åãå¨ä¸åçå¯¦ä¸çè³æéä¸é²è¡çå»£æ³å¯¦é©æç¢ºè­æï¼DPCPL ä¸åå±ç¾åºé«æçåé«ææï¼éè¦æå°çåæ¸èª¿æ´ï¼èä¸å¨åç¨®ä¸æ¸¸ä»»åä¸­é½è¶è¶äºæåé²çæè½ã</paragraph>

##### **Solving Decision Theory Problems with Probabilistic Answer Set Programming**
2408.11371v1 by Damiano Azzolini, Elena Bellodi, Rafael Kiesel, Fabrizio Riguzzi

Solving a decision theory problem usually involves finding the actions, among
a set of possible ones, which optimize the expected reward, possibly accounting
for the uncertainty of the environment. In this paper, we introduce the
possibility to encode decision theory problems with Probabilistic Answer Set
Programming under the credal semantics via decision atoms and utility
attributes. To solve the task we propose an algorithm based on three layers of
Algebraic Model Counting, that we test on several synthetic datasets against an
algorithm that adopts answer set enumeration. Empirical results show that our
algorithm can manage non trivial instances of programs in a reasonable amount
of time. Under consideration in Theory and Practice of Logic Programming
(TPLP).

æè¦ï¼è§£æ±ºæ±ºç­çè«åé¡éå¸¸æ¶åå¨å¯è½çè¡åä¸­æ¾åºé£äºæä½³åé æçåµçè¡åï¼éå¯è½æèæ®ç°å¢çä¸ç¢ºå®æ§ãå¨æ¬æä¸­ï¼æåä»ç´¹äºééæ±ºç­åå­åæç¨å±¬æ§å¨å¯ä¿¡èªç¾©ä¸ä½¿ç¨æ©çæ§ç­æ¡éåè¦åç·¨ç¢¼æ±ºç­çè«åé¡çå¯è½æ§ãçºäºè§£æ±ºæ­¤ä»»åï¼æåæåºäºä¸ç¨®åºæ¼ä»£æ¸æ¨¡åè¨æ¸çä¸å±¤æ¼ç®æ³ï¼æåå¨å¹¾ååæè³æéä¸å°å¶é²è¡äºæ¸¬è©¦ï¼ä¸¦éå°æ¡ç¨ç­æ¡éååèçæ¼ç®æ³é²è¡äºæ¸¬è©¦ãå¯¦è­çµæè¡¨æï¼æåçæ¼ç®æ³å¯ä»¥å¨åççæéå§ç®¡çç¨å¼ä¸­éå¹³å¡çå¯¦ä¾ãå¨éè¼¯ç¨å¼è¨­è¨çè«èå¯¦å (TPLP) ä¸­èæ®ä¸­ã

##### **Graph Classification via Reference Distribution Learning: Theory and Practice**
2408.11370v1 by Zixiao Wang, Jicong Fan

Graph classification is a challenging problem owing to the difficulty in
quantifying the similarity between graphs or representing graphs as vectors,
though there have been a few methods using graph kernels or graph neural
networks (GNNs). Graph kernels often suffer from computational costs and manual
feature engineering, while GNNs commonly utilize global pooling operations,
risking the loss of structural or semantic information. This work introduces
Graph Reference Distribution Learning (GRDL), an efficient and accurate graph
classification method. GRDL treats each graph's latent node embeddings given by
GNN layers as a discrete distribution, enabling direct classification without
global pooling, based on maximum mean discrepancy to adaptively learned
reference distributions. To fully understand this new model (the existing
theories do not apply) and guide its configuration (e.g., network architecture,
references' sizes, number, and regularization) for practical use, we derive
generalization error bounds for GRDL and verify them numerically. More
importantly, our theoretical and numerical results both show that GRDL has a
stronger generalization ability than GNNs with global pooling operations.
Experiments on moderate-scale and large-scale graph datasets show the
superiority of GRDL over the state-of-the-art, emphasizing its remarkable
efficiency, being at least 10 times faster than leading competitors in both
training and inference stages.

æè¦ï¼åå½¢åé¡æ¯ä¸åå·æææ°æ§çåé¡ï¼åå å¨æ¼é£ä»¥éååå½¢ä¹éçç¸ä¼¼æ§æå°åå½¢è¡¨ç¤ºçºåéï¼åç®¡å·²ç¶æä¸äºä½¿ç¨åå½¢æ ¸æåå½¢ç¥ç¶ç¶²è·¯ (GNN) çæ¹æ³ãåå½¢æ ¸éå¸¸æåå°éç®ææ¬åæåç¹å¾µå·¥ç¨çå½±é¿ï¼è GNN éå¸¸æä½¿ç¨å¨åæ± åéç®ï¼åèçµæ§æèªç¾©è³è¨éºå¤±çé¢¨éªãæ¬ç ç©¶ä»ç´¹åå½¢åèåä½å­¸ç¿ (GRDL)ï¼éæ¯ä¸ç¨®ææä¸æºç¢ºçåå½¢åé¡æ¹æ³ãGRDL å° GNN å±¤æä¾çæ¯ååå½¢çæ½å¨ç¯é»åµå¥è¦çºé¢æ£åä½ï¼åºæ¼æå¤§å¹³åå·®ç°ï¼æ ¹æé©ææ§å­¸ç¿çåèåä½ï¼é²è¡ç´æ¥åé¡ï¼èç¡éå¨åæ± åãçºäºååç­è§£éåæ°æ¨¡åï¼ç¾æççè«ä¸¦ä¸é©ç¨ï¼ä¸¦æå°å¶çµæï¼ä¾å¦ï¼ç¶²è·¯æ¶æ§ãåèå¤§å°ãæ¸éåæ­£ååï¼ä»¥ä¾å¯¦éä½¿ç¨ï¼æåæ¨å°äº GRDL çæ³åèª¤å·®çéï¼ä¸¦å°å¶é²è¡æ¸å¼é©è­ãæ´éè¦çæ¯ï¼æåççè«åæ¸å¼çµæé½è¡¨æï¼GRDL å·ææ¯å·æå¨åæ± åéç®ç GNN æ´å¼·çæ³åè½åãå¨ä¸­å°ååå½¢è³æéä¸çå¯¦é©é¡¯ç¤ºï¼GRDL åªæ¼ç¾ææè¡ï¼å¼·èª¿å¶é¡¯èçæçï¼å¨è¨ç·´åæ¨è«éæ®µé½æ¯é åçç«¶ç­å°æå¿«è³å° 10 åã

##### **Towards Probabilistic Inductive Logic Programming with Neurosymbolic Inference and Relaxation**
2408.11367v1 by Fieke Hillerstrom, Gertjan Burghouts

Many inductive logic programming (ILP) methods are incapable of learning
programs from probabilistic background knowledge, e.g. coming from sensory data
or neural networks with probabilities. We propose Propper, which handles flawed
and probabilistic background knowledge by extending ILP with a combination of
neurosymbolic inference, a continuous criterion for hypothesis selection (BCE)
and a relaxation of the hypothesis constrainer (NoisyCombo). For relational
patterns in noisy images, Propper can learn programs from as few as 8 examples.
It outperforms binary ILP and statistical models such as a Graph Neural
Network.

æè¦ï¼è¨±å¤æ­¸ç´éè¼¯ç¨å¼è¨­è¨ (ILP) æ¹æ³ç¡æ³å¾æ©çèæ¯ç¥è­å­¸ç¿ç¨å¼ï¼ä¾å¦ä¾èªææ¸¬å¨è³ææå·ææ©ççç¥ç¶ç¶²è·¯ãæåæåº Propperï¼å®ééå° ILP èç¥ç¶ç¬¦èæ¨çãç¨æ¼åè¨­é¸æçé£çºæºå (BCE) ååè¨­ç´æé¬å¼ (NoisyCombo) ççµåä¾èçæç¼ºé·ä¸æ©çæ§çèæ¯ç¥è­ãå°æ¼éè¨å½±åä¸­çéä¿æ¨¡å¼ï¼Propper å¯ä»¥å¾å°è³ 8 åç¯ä¾å­¸ç¿ç¨å¼ãå®åªæ¼äºå ILP åçµ±è¨æ¨¡åï¼ä¾å¦åç¥ç¶ç¶²è·¯ã

##### **GeoReasoner: Reasoning On Geospatially Grounded Context For Natural Language Understanding**
2408.11366v1 by Yibo Yan, Joey Lee

In human reading and communication, individuals tend to engage in geospatial
reasoning, which involves recognizing geographic entities and making informed
inferences about their interrelationships. To mimic such cognitive process,
current methods either utilize conventional natural language understanding
toolkits, or directly apply models pretrained on geo-related natural language
corpora. However, these methods face two significant challenges: i) they do not
generalize well to unseen geospatial scenarios, and ii) they overlook the
importance of integrating geospatial context from geographical databases with
linguistic information from the Internet. To handle these challenges, we
propose GeoReasoner, a language model capable of reasoning on geospatially
grounded natural language. Specifically, it first leverages Large Language
Models (LLMs) to generate a comprehensive location description based on
linguistic and geospatial information. It also encodes direction and distance
information into spatial embedding via treating them as pseudo-sentences.
Consequently, the model is trained on both anchor-level and neighbor-level
inputs to learn geo-entity representation. Extensive experimental results
demonstrate GeoReasoner's superiority in three tasks: toponym recognition,
toponym linking, and geo-entity typing, compared to the state-of-the-art
baselines.

æè¦ï¼å¨äººé¡çé±è®åæºéä¸­ï¼åäººå¾åæ¼å¾äºå°çç©ºéæ¨çï¼éæ¶åè­å¥å°çå¯¦é«ä¸¦å°å®åçç¸äºéä¿ååºææºçæ¨è«ãçºäºæ¨¡æ¬éç¨®èªç¥éç¨ï¼ç¶åçåæ³æ¯å©ç¨å³çµ±çèªç¶èªè¨çè§£å·¥å·åï¼æç´æ¥æç¨é åå¨èå°çç¸éçèªç¶èªè¨èªæåº«ä¸è¨ç·´çæ¨¡åãç¶èï¼éäºæ¹æ³é¢è¨èå©åéå¤§çææ°ï¼i) å®åç¡æ³å¾å¥½å°æ¨å»£å°æªè¦éçå°çç©ºéå ´æ¯ï¼ä»¥å ii) å®åå¿½è¦äºå°ä¾èªå°çè³æåº«çå°çç©ºéèæ¯èä¾èªç¶²éç¶²è·¯çèªè¨è³è¨æ´åèµ·ä¾çéè¦æ§ãçºäºæå°éäºææ°ï¼æåæåºäº GeoReasonerï¼éæ¯ä¸åè½å¤ å°å°çç©ºéåºç¤èªç¶èªè¨é²è¡æ¨ççèªè¨æ¨¡åãå·é«ä¾èªªï¼å®é¦åå©ç¨å¤§åèªè¨æ¨¡å (LLM) æ ¹æèªè¨åå°çç©ºéè³è¨çæå¨é¢çä½ç½®æè¿°ãå®éå°æ¹ååè·é¢è³è¨ç·¨ç¢¼å°ç©ºéåµå¥ä¸­ï¼å°å®åè¦çºå½å¥å­ãå æ­¤ï¼è©²æ¨¡åå¨é¨é»ç´å¥åé°å±ç´å¥çè¼¸å¥ä¸é²è¡è¨ç·´ï¼ä»¥å­¸ç¿å°çå¯¦é«è¡¨ç¤ºãå¤§éçå¯¦é©çµæè­æäº GeoReasoner å¨ä¸é ä»»åä¸­çåªè¶æ§ï¼å°åè­å¥ãå°åé£çµåå°çå¯¦é«é¡åï¼èæåé²çåºæºç¸æ¯ã

##### **ProteinGPT: Multimodal LLM for Protein Property Prediction and Structure Understanding**
2408.11363v1 by Yijia Xiao, Edward Sun, Yiqiao Jin, Qifan Wang, Wei Wang

Understanding biological processes, drug development, and biotechnological
advancements requires detailed analysis of protein structures and sequences, a
task in protein research that is inherently complex and time-consuming when
performed manually. To streamline this process, we introduce ProteinGPT, a
state-of-the-art multi-modal protein chat system, that allows users to upload
protein sequences and/or structures for comprehensive protein analysis and
responsive inquiries. ProteinGPT seamlessly integrates protein sequence and
structure encoders with linear projection layers for precise representation
adaptation, coupled with a large language model (LLM) to generate accurate and
contextually relevant responses. To train ProteinGPT, we construct a
large-scale dataset of 132,092 proteins with annotations, and optimize the
instruction-tuning process using GPT-4o. This innovative system ensures
accurate alignment between the user-uploaded data and prompts, simplifying
protein analysis. Experiments show that ProteinGPT can produce promising
responses to proteins and their corresponding questions.

æè¦ï¼äºè§£çç©éç¨ãè¥ç©éç¼åçç©æè¡é²å±ï¼éè¦è©³ç´°åæèç½è³ªçµæ§ååºåï¼éé èç½è³ªç ç©¶ä»»åå¨æåå·è¡ææ¬è³ªä¸å¾è¤éä¸èæãçºäºç°¡åæ­¤æµç¨ï¼æåå¼å¥äº ProteinGPTï¼éæ¯ä¸åæåé²çå¤æ¨¡å¼èç½è³ªèå¤©ç³»çµ±ï¼åè¨±ä½¿ç¨èä¸å³èç½è³ªåºåå/æçµæ§ï¼ä»¥é²è¡å¨é¢çèç½è³ªåæååæå¼æ¥è©¢ãProteinGPT å°èç½è³ªåºååçµæ§ç·¨ç¢¼å¨èç·æ§æå½±å±¤ç¡ç¸«æ´åï¼ä»¥é²è¡ç²¾ç¢ºçè¡¨ç¤ºé©æï¼ä¸¦çµåå¤§åèªè¨æ¨¡å (LLM) ä¾ç¢çæºç¢ºä¸èä¸ä¸æç¸éçåæãçºäºè¨ç·´ ProteinGPTï¼æåæ§å»ºäºä¸ååå« 132,092 åèç½è³ªçå¤§è¦æ¨¡è¨»è§£è³æéï¼ä¸¦ä½¿ç¨ GPT-4o æä½³åæä»¤èª¿æ´æµç¨ãéååµæ°çç³»çµ±ç¢ºä¿ä½¿ç¨èä¸å³çè³æåæç¤ºä¹éçæºç¢ºå°é½ï¼ç°¡åäºèç½è³ªåæãå¯¦é©è¡¨æï¼ProteinGPT å¯ä»¥å°èç½è³ªåå¶å°æåé¡ç¢çæå¸æçåæã

##### **Hypergraph Learning based Recommender System for Anomaly Detection, Control and Optimization**
2408.11359v1 by Sakhinana Sagar Srinivas, Rajat Kumar Sarkar, Venkataramana Runkana

Anomaly detection is fundamental yet, challenging problem with practical
applications in industry. The current approaches neglect the higher-order
dependencies within the networks of interconnected sensors in the
high-dimensional time series(multisensor data) for anomaly detection. To this
end, we present a self-adapting anomaly detection framework for joint learning
of (a) discrete hypergraph structure and (b) modeling the temporal trends and
spatial relations among the interdependent sensors using the hierarchical
encoder-decoder architecture to overcome the challenges. The hypergraph
representation learning-based framework exploits the relational inductive
biases in the hypergraph-structured data to learn the pointwise
single-step-ahead forecasts through the self-supervised autoregressive task and
predicts the anomalies based on the forecast error. Furthermore, our framework
incentivizes learning the anomaly-diagnosis ontology through a differentiable
approach. It derives the anomaly information propagation-based computational
hypergraphs for root cause analysis and provides recommendations through an
offline, optimal predictive control policy to remedy an anomaly. We conduct
extensive experiments to evaluate the proposed method on the benchmark datasets
for fair and rigorous comparison with the popular baselines. The proposed
method outperforms the baseline models and achieves SOTA performance. We report
the ablation studies to support the efficacy of the framework.

æè¦ï¼ç°å¸¸åµæ¸¬æ¯åºç¤ä¸å·æææ°æ§çåé¡ï¼å¨ç¢æ¥­ä¸­å·æå¯¦éæç¨ãç®åçæ¹æ³å¿½ç¥äºé«ç¶­æéåºåï¼å¤ææ¸¬å¨è³æï¼ä¸­é£æ¥ææ¸¬å¨ç¶²è·¯å§çé«éä¾è³´æ§ï¼ä»¥é²è¡ç°å¸¸åµæ¸¬ãçºæ­¤ï¼æåæåºä¸åèªé©æç°å¸¸åµæ¸¬æ¶æ§ï¼ç¨æ¼è¯åå­¸ç¿ (a) é¢æ£è¶åçµæ§å (b) ä½¿ç¨éå±¤å¼ç·¨ç¢¼å¨ - è§£ç¢¼å¨æ¶æ§ï¼å¨ç¸äºä¾è³´çææ¸¬å¨ä¹éå°æéè¶¨å¢åç©ºééä¿é²è¡å»ºæ¨¡ï¼ä»¥åæææ°ãåºæ¼è¶åè¡¨ç¤ºå­¸ç¿çæ¡æ¶å©ç¨è¶åçµæ§è³æä¸­çéä¿æ­¸ç´åå·®ï¼ééèªæç£ç£çåæ­¸ä»»åå­¸ç¿éé»å®æ­¥è¶åé æ¸¬ï¼ä¸¦æ ¹æé æ¸¬èª¤å·®é æ¸¬ç°å¸¸ãæ­¤å¤ï¼æåçæ¡æ¶ééå¯å¾®åçéå¾ï¼æ¿åµå­¸ç¿ç°å¸¸è¨ºæ·æ¬é«è«ãå®è¡çåºåºæ¼ç°å¸¸è³è¨å³æ­çè¨ç®è¶åï¼ç¨æ¼æ ¹æ¬åå åæï¼ä¸¦ééé¢ç·æä½³é æ¸¬æ§å¶æ¿ç­æä¾å»ºè­°ï¼ä»¥è£æç°å¸¸ãæåé²è¡å»£æ³çå¯¦é©ï¼å¨åºæºè³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä»¥é²è¡å¬å¹³ä¸å´è¬¹çæ¯è¼ï¼èæµè¡çåºæºé²è¡æ¯è¼ãææåºçæ¹æ³åªæ¼åºæºæ¨¡åï¼ä¸¦éå° SOTA æè½ãæåå ±åæ¶èç ç©¶ï¼ä»¥æ¯æè©²æ¡æ¶çæè½ã

##### **One-step Structure Prediction and Screening for Protein-Ligand Complexes using Multi-Task Geometric Deep Learning**
2408.11356v1 by Kelei He, Tiejun Dong, Jinhui Wu, Junfeng Zhang

Understanding the structure of the protein-ligand complex is crucial to drug
development. Existing virtual structure measurement and screening methods are
dominated by docking and its derived methods combined with deep learning.
However, the sampling and scoring methodology have largely restricted the
accuracy and efficiency. Here, we show that these two fundamental tasks can be
accurately tackled with a single model, namely LigPose, based on multi-task
geometric deep learning. By representing the ligand and the protein pair as a
graph, LigPose directly optimizes the three-dimensional structure of the
complex, with the learning of binding strength and atomic interactions as
auxiliary tasks, enabling its one-step prediction ability without docking
tools. Extensive experiments show LigPose achieved state-of-the-art performance
on major tasks in drug research. Its considerable improvements indicate a
promising paradigm of AI-based pipeline for drug development.

æè¦ï¼äºè§£èç½è´¨-éä½å¤åç©çç»æå¯¹äºè¯ç©å¼åè³å³éè¦ãç°æçèæç»ææµéåç­éæ¹æ³ä¸»è¦ä»¥å¯¹æ¥åå¶è¡çæ¹æ³ä¸æ·±åº¦å­¦ä¹ ç¸ç»åä¸ºä¸»ãç¶èï¼éæ ·åè¯åæ¹æ³å¨å¾å¤§ç¨åº¦ä¸éå¶äºåç¡®æ§åæçãå¨æ­¤ï¼æä»¬è¡¨æè¿ä¸¤ä¸ªåºæ¬ä»»å¡å¯ä»¥éè¿ä¸ä¸ªåä¸æ¨¡åï¼å³ LigPoseï¼åç¡®è§£å³ï¼è¯¥æ¨¡ååºäºå¤ä»»å¡å ä½æ·±åº¦å­¦ä¹ ãéè¿å°éä½åèç½è´¨å¯¹è¡¨ç¤ºä¸ºå¾ï¼LigPose ç´æ¥ä¼åå¤åç©çä¸ç»´ç»æï¼å¹¶ä»¥ç»åå¼ºåº¦ååå­ç¸äºä½ç¨çå­¦ä¹ ä½ä¸ºè¾å©ä»»å¡ï¼ä½¿å¶è½å¤å¨ä¸ä½¿ç¨å¯¹æ¥å·¥å·çæåµä¸è¿è¡ä¸æ­¥é¢æµãå¤§éçå®éªè¡¨æï¼LigPose å¨è¯ç©ç ç©¶çä¸»è¦ä»»å¡ä¸­åå¾äºæåè¿çæ§è½ãå¶æ¾ççæ¹è¿è¡¨æäºåºäºäººå·¥æºè½çè¯ç©å¼åç®¡çº¿çæåæ¯çèä¾ã

##### **Vision HgNN: An Electron-Micrograph is Worth Hypergraph of Hypernodes**
2408.11351v1 by Sakhinana Sagar Srinivas, Rajat Kumar Sarkar, Sreeja Gangasani, Venkataramana Runkana

Material characterization using electron micrographs is a crucial but
challenging task with applications in various fields, such as semiconductors,
quantum materials, batteries, etc. The challenges in categorizing electron
micrographs include but are not limited to the complexity of patterns, high
level of detail, and imbalanced data distribution(long-tail distribution).
Existing methods have difficulty in modeling the complex relational structure
in electron micrographs, hindering their ability to effectively capture the
complex relationships between different spatial regions of micrographs. We
propose a hypergraph neural network(HgNN) backbone architecture, a conceptually
alternative approach, to better model the complex relationships in electron
micrographs and improve material characterization accuracy. By utilizing
cost-effective GPU hardware, our proposed framework outperforms popular
baselines. The results of the ablation studies demonstrate that the proposed
framework is effective in achieving state-of-the-art performance on benchmark
datasets and efficient in terms of computational and memory requirements for
handling large-scale electron micrograph-based datasets.

æè¦ï¼ä½¿ç¨é»å­é¡¯å¾®ç§çé²è¡ææè¡¨å¾µæ¯ä¸é è³ééè¦çä»»åï¼ä½å¨åå°é«ãéå­ææãé»æ± ç­ååé åçæç¨ä¸­é½é¢è¨èææ°ãå°é»å­é¡¯å¾®ç§çé²è¡åé¡çææ°åæ¬ä½ä¸éæ¼æ¨¡å¼çè¤éæ§ãé«ç´°ç¯ç¨åº¦åä¸å¹³è¡¡çæ¸æåä½ï¼é·å°¾åä½ï¼ãç¾æçæ¹æ³é£ä»¥å°é»å­é¡¯å¾®ç§çä¸­çè¤ééä¿çµæ§é²è¡å»ºæ¨¡ï¼éé»ç¤äºå®åææææé¡¯å¾®ç§çä¸åç©ºéååä¹éè¤ééä¿çè½åãæåæåºäºä¸ç¨®è¶åç¥ç¶ç¶²çµ¡ï¼HgNNï¼ä¸»å¹¹æ¶æ§ï¼éæ¯ä¸ç¨®æ¦å¿µä¸çæ¿ä»£æ¹æ³ï¼å¯ä»¥æ´å¥½å°å°é»å­é¡¯å¾®ç§çä¸­çè¤ééä¿é²è¡å»ºæ¨¡ä¸¦æé«ææè¡¨å¾µçæºç¢ºæ§ãééå©ç¨ç¶æ¿é«æç GPU ç¡¬é«ï¼æåæåºçæ¡æ¶åªæ¼æµè¡çåºæºãæ¶èç ç©¶ççµæè¡¨æï¼ææåºçæ¡æ¶å¨åºæºæ¸æéä¸å¯¦ç¾äºæåé²çæ§è½ï¼ä¸¦ä¸å¨èçåºæ¼å¤§è¦æ¨¡é»å­é¡¯å¾®ç§ççæ¸æéæå¨è¨ç®åè¨æ¶é«éæ±æ¹é¢æ¯ææçã

##### **Clinical Context-aware Radiology Report Generation from Medical Images using Transformers**
2408.11344v1 by Sonit Singh

Recent developments in the field of Natural Language Processing, especially
language models such as the transformer have brought state-of-the-art results
in language understanding and language generation. In this work, we investigate
the use of the transformer model for radiology report generation from chest
X-rays. We also highlight limitations in evaluating radiology report generation
using only the standard language generation metrics. We then applied a
transformer based radiology report generation architecture, and also compare
the performance of a transformer based decoder with the recurrence based
decoder. Experiments were performed using the IU-CXR dataset, showing superior
results to its LSTM counterpart and being significantly faster. Finally, we
identify the need of evaluating radiology report generation system using both
language generation metrics and classification metrics, which helps to provide
robust measure of generated reports in terms of their coherence and diagnostic
value.

æè¦ï¼èªç¶èªè¨èçé åçææ°ç¼å±ï¼å°¤å¶æ¯Transformerç­èªè¨æ¨¡åï¼å¨èªè¨çè§£åèªè¨çææ¹é¢å¸¶ä¾äºæåé²çææãå¨éé å·¥ä½ä¸­ï¼æåç ç©¶äºä½¿ç¨Transformeræ¨¡åå¾è¸é¨ X å°ç·çææ¾å°å­¸å ±åãæåéå¼·èª¿äºåä½¿ç¨æ¨æºèªè¨çæææ¨è©ä¼°æ¾å°å­¸å ±åçæçå±éæ§ãç¶å¾æåæç¨åºæ¼Transformerçæ¾å°å­¸å ±åçææ¶æ§ï¼ä¸¦å°åºæ¼Transformerçè§£ç¢¼å¨çæ§è½èåºæ¼éæ­¸çè§£ç¢¼å¨é²è¡æ¯è¼ãä½¿ç¨ IU-CXR æ¸æéé²è¡äºå¯¦é©ï¼é¡¯ç¤ºåºåªæ¼å¶ LSTM å°ææ¹ççµæï¼ä¸¦ä¸éåº¦é¡¯èæåãæå¾ï¼æåç¢ºå®éè¦ä½¿ç¨èªè¨çæææ¨ååé¡ææ¨ä¾è©ä¼°æ¾å°å­¸å ±åçæç³»çµ±ï¼éæå©æ¼å¨é£è²«æ§åè¨ºæ·å¹å¼æ¹é¢æä¾çæçå ±åçç©©å¥æ¸¬éã

##### **Automatic Dataset Construction (ADC): Sample Collection, Data Curation, and Beyond**
2408.11338v1 by Minghao Liu, Zonglin Di, Jiaheng Wei, Zhongruo Wang, Hengxiang Zhang, Ruixuan Xiao, Haoyu Wang, Jinlong Pang, Hao Chen, Ankit Shah, Hongxin Wei, Xinlei He, Zhaowei Zhao, Haobo Wang, Lei Feng, Jindong Wang, James Davis, Yang Liu

Large-scale data collection is essential for developing personalized training
data, mitigating the shortage of training data, and fine-tuning specialized
models. However, creating high-quality datasets quickly and accurately remains
a challenge due to annotation errors, the substantial time and costs associated
with human labor. To address these issues, we propose Automatic Dataset
Construction (ADC), an innovative methodology that automates dataset creation
with negligible cost and high efficiency. Taking the image classification task
as a starting point, ADC leverages LLMs for the detailed class design and code
generation to collect relevant samples via search engines, significantly
reducing the need for manual annotation and speeding up the data generation
process. Despite these advantages, ADC also encounters real-world challenges
such as label errors (label noise) and imbalanced data distributions (label
bias). We provide open-source software that incorporates existing methods for
label error detection, robust learning under noisy and biased data, ensuring a
higher-quality training data and more robust model training procedure.
Furthermore, we design three benchmark datasets focused on label noise
detection, label noise learning, and class-imbalanced learning. These datasets
are vital because there are few existing datasets specifically for label noise
detection, despite its importance. Finally, we evaluate the performance of
existing popular methods on these datasets, thereby facilitating further
research in the field.

æè¦ï¼å¤§è¦æ¨¡æ¸ææ¶éå°æ¼éç¼åäººåè¨ç·´è³æãç·©è§£è¨ç·´è³æç­ç¼ºä»¥åå¾®èª¿å°æ¥­æ¨¡åè³ééè¦ãç¶èï¼ç±æ¼æ¨è¨»é¯èª¤ãèäººå·¥ååç¸éçé¾å¤§æéåææ¬ï¼å¿«éä¸æºç¢ºå°å»ºç«é«åè³ªçè³æéä»ç¶æ¯ä¸åææ°ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºèªåè³æéå»ºæ§ (ADC)ï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼å¯ä»¥èªååè³æéå»ºç«ï¼ä¸ææ¬ä½ä¸æçé«ãä»¥å½±ååé¡ä»»åä½çºèµ·é»ï¼ADC å©ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡è©³ç´°çé¡å¥è¨­è¨åç¨å¼ç¢¼çæï¼ä»¥ééæå°å¼ææ¶éç¸éæ¨£æ¬ï¼å¤§å¹éä½äººå·¥æ¨è¨»çéæ±ï¼ä¸¦å éè³æç¢çæµç¨ãåç®¡æéäºåªé»ï¼ADC ä¹æéå°ç¾å¯¦ä¸ççææ°ï¼ä¾å¦æ¨ç±¤é¯èª¤ï¼æ¨ç±¤éè¨ï¼åä¸å¹³è¡¡çè³æåä½ï¼æ¨ç±¤åå·®ï¼ãæåæä¾éæºè»é«ï¼å¶ä¸­åå«ç¾ææ¨ç±¤é¯èª¤åµæ¸¬æ¹æ³ãå¨æéè¨ååå·®è³æä¸çç©©å¥å­¸ç¿ï¼ç¢ºä¿æ´é«åè³ªçè¨ç·´è³æåæ´ç©©å¥çæ¨¡åè¨ç·´ç¨åºãæ­¤å¤ï¼æåè¨­è¨äºä¸ååºæºè³æéï¼å°æ³¨æ¼æ¨ç±¤éè¨åµæ¸¬ãæ¨ç±¤éè¨å­¸ç¿åé¡å¥ä¸å¹³è¡¡å­¸ç¿ãéäºè³æéè³ééè¦ï¼å çºåç®¡æ¨ç±¤éè¨åµæ¸¬å¾éè¦ï¼ä½ç¾æå°ééå°æ¨ç±¤éè¨åµæ¸¬çè³æéå¾å°ãæå¾ï¼æåè©ä¼°äºéäºè³æéä¸ç¾æç±éæ¹æ³çæè½ï¼å¾èä¿é²è©²é åçé²ä¸æ­¥ç ç©¶ã

##### **BURExtract-Llama: An LLM for Clinical Concept Extraction in Breast Ultrasound Reports**
2408.11334v1 by Yuxuan Chen, Haoyan Yang, Hengkai Pan, Fardeen Siddiqui, Antonio Verdone, Qingyang Zhang, Sumit Chopra, Chen Zhao, Yiqiu Shen

Breast ultrasound is essential for detecting and diagnosing abnormalities,
with radiology reports summarizing key findings like lesion characteristics and
malignancy assessments. Extracting this critical information is challenging due
to the unstructured nature of these reports, with varied linguistic styles and
inconsistent formatting. While proprietary LLMs like GPT-4 are effective, they
are costly and raise privacy concerns when handling protected health
information. This study presents a pipeline for developing an in-house LLM to
extract clinical information from radiology reports. We first use GPT-4 to
create a small labeled dataset, then fine-tune a Llama3-8B model on it.
Evaluated on clinician-annotated reports, our model achieves an average F1
score of 84.6%, which is on par with GPT-4. Our findings demonstrate the
feasibility of developing an in-house LLM that not only matches GPT-4's
performance but also offers cost reductions and enhanced data privacy.

æè¦ï¼ä¹³æ¿è¶é³æ³¢å°æ¼åµæ¸¬åè¨ºæ·ç°å¸¸è³ééè¦ï¼
æ¾å°ç§å ±åæç¸½çµééµç¼ç¾ï¼ä¾å¦çç¶ç¹å¾µåæ¡æ§è©ä¼°ãç±æ¼éäºå ±åçéçµæ§åæ§è³ªãèªè¨é¢¨æ ¼å¤è®ä¸æ ¼å¼ä¸ä¸è´ï¼å æ­¤æåéäºééµè³è¨å·æææ°æ§ãéç¶å GPT-4 éæ¨£çå°æ LLM å¾ææï¼ä½å®åå¨èçåä¿è­·çå¥åº·è³è¨æææ¬é«æä¸æå¼èµ·é±ç§åé¡ãéé ç ç©¶æåºäºä¸åéç¼å§é¨ LLM çç®¡éï¼ä»¥å¾æ¾å°ç§å ±åä¸­æåè¨åºè³è¨ãæåé¦åä½¿ç¨ GPT-4 å»ºç«ä¸åå°åæ¨ç±¤è³æéï¼ç¶å¾å° Llama3-8B æ¨¡åé²è¡å¾®èª¿ãæ ¹æè¨åºé«å¸«è¨»è§£çå ±åé²è¡è©ä¼°ï¼æåçæ¨¡åéå°å¹³å F1 åæ¸çº 84.6%ï¼éè GPT-4 ç¸ç¶ãæåçç ç©¶çµæè­æäºéç¼å§é¨ LLM çå¯è¡æ§ï¼å®ä¸åè½è GPT-4 çæè½ç¸å¹éï¼éè½éä½ææ¬ä¸¦å¢å¼·è³æé±ç§ã

##### **Design Principle Transfer in Neural Architecture Search via Large Language Models**
2408.11330v1 by Xun Zhou, Liang Feng, Xingyu Wu, Zhichao Lu, Kay Chen Tan

Transferable neural architecture search (TNAS) has been introduced to design
efficient neural architectures for multiple tasks, to enhance the practical
applicability of NAS in real-world scenarios. In TNAS, architectural knowledge
accumulated in previous search processes is reused to warm up the architecture
search for new tasks. However, existing TNAS methods still search in an
extensive search space, necessitating the evaluation of numerous architectures.
To overcome this challenge, this work proposes a novel transfer paradigm, i.e.,
design principle transfer. In this work, the linguistic description of various
structural components' effects on architectural performance is termed design
principles. They are learned from established architectures and then can be
reused to reduce the search space by discarding unpromising architectures.
Searching in the refined search space can boost both the search performance and
efficiency for new NAS tasks. To this end, a large language model
(LLM)-assisted design principle transfer (LAPT) framework is devised. In LAPT,
LLM is applied to automatically reason the design principles from a set of
given architectures, and then a principle adaptation method is applied to
refine these principles progressively based on the new search results.
Experimental results show that LAPT can beat the state-of-the-art TNAS methods
on most tasks and achieve comparable performance on others.

æè¦ï¼å¯è½ç§»ç¥ç¶æ¶æ§æå° (TNAS) å·²è¢«å¼å¥ï¼ç¨æ¼è¨­è¨é©ç¨æ¼å¤é ä»»åçé«æç¥ç¶æ¶æ§ï¼ä»¥å¢å¼· NAS å¨çå¯¦ä¸çå ´æ¯ä¸­çå¯¦éå¯è¡æ§ãå¨ TNAS ä¸­ï¼ç´¯ç©æ¼ååæå°ç¨åºä¸­çæ¶æ§ç¥è­è¢«éæ°ç¨æ¼çºæ°ä»»åç±èº«æ¶æ§æå°ãç¶èï¼ç¾æç TNAS æ¹æ³ä»æå¨å»£æ³çæå°ç©ºéä¸­æå°ï¼éè¦è©ä¼°å¤§éçæ¶æ§ãçºäºè§£æ±ºéåææ°ï¼éé å·¥ä½æåºäºä¸ç¨®æ°ç©çè½ç§»ç¯ä¾ï¼å³è¨­è¨ååè½ç§»ãå¨éé å·¥ä½ä¸­ï¼åç¨®çµæ§åä»¶å°æ¶æ§æè½çå½±é¿çèªè¨æè¿°è¢«ç¨±çºè¨­è¨ååãå®åå¾å·²å»ºç«çæ¶æ§ä¸­å­¸ç¿ï¼ç¶å¾å¯ä»¥è¢«éæ°ç¨æ¼ééæ¨æ£ç¡æçæ¶æ§ä¾æ¸å°æå°ç©ºéãå¨ç¶éåªåçæå°ç©ºéä¸­æå°å¯ä»¥æåæ° NAS ä»»åçæå°æè½åæçãçºæ­¤ï¼è¨­è¨äºä¸åå¤§åèªè¨æ¨¡å (LLM) è¼å©çè¨­è¨ååè½ç§» (LAPT) æ¶æ§ãå¨ LAPT ä¸­ï¼LLM è¢«æç¨æ¼èªåæ ¹æä¸çµçµ¦å®çæ¶æ§æ¨è«è¨­è¨ååï¼ç¶å¾æç¨ä¸åååé©ææ¹æ³ï¼æ ¹ææ°çæå°çµæéæ­¥åªåéäºååãå¯¦é©çµæé¡¯ç¤ºï¼LAPT å¯ä»¥ææå¤§å¤æ¸ä»»åä¸­çæåé² TNAS æ¹æ³ï¼ä¸¦å¨å¶ä»ä»»åä¸­éå°ç¸ç¶çæè½ã

##### **Plug, Play, and Fuse: Zero-Shot Joint Decoding via Word-Level Re-ranking Across Diverse Vocabularies**
2408.11327v1 by Sai Koneru, Matthias Huck, Miriam Exel, Jan Niehues

Recent advancements in NLP have resulted in models with specialized
strengths, such as processing multimodal inputs or excelling in specific
domains. However, real-world tasks, like multimodal translation, often require
a combination of these strengths, such as handling both translation and image
processing. While individual translation and vision models are powerful, they
typically lack the ability to perform both tasks in a single system. Combining
these models poses challenges, particularly due to differences in their
vocabularies, which limit the effectiveness of traditional ensemble methods to
post-generation techniques like N-best list re-ranking. In this work, we
propose a novel zero-shot ensembling strategy that allows for the integration
of different models during the decoding phase without the need for additional
training. Our approach re-ranks beams during decoding by combining scores at
the word level, using heuristics to predict when a word is completed. We
demonstrate the effectiveness of this method in machine translation scenarios,
showing that it enables the generation of translations that are both speech-
and image-aware while also improving overall translation quality\footnote{We
will release the code upon paper acceptance.}.

æè¦ï¼æè¿å¨èªç¶èªè¨èççé²å±ç¢çäºå·æç¹æ®åªå¢çæ¨¡åï¼ä¾å¦èçå¤æ¨¡æè¼¸å¥æå¨ç¹å®é åè¡¨ç¾åºè²ãç¶èï¼ç¾å¯¦ä¸ççä»»åï¼ä¾å¦å¤æ¨¡æç¿»è­¯ï¼éå¸¸éè¦éäºåªå¢ççµåï¼ä¾å¦åæèçç¿»è­¯åå½±åèçãéç¶åå¥ç¿»è­¯åè¦è¦ºæ¨¡ååè½å¼·å¤§ï¼ä½å®åéå¸¸ç¼ºä¹å¨å®ä¸ç³»çµ±ä¸­å·è¡éå©åä»»åçè½åãçµåéäºæ¨¡åæå¸¶ä¾ææ°ï¼ç¹å¥æ¯å çºå®åçè©å½ä¸åï¼ééå¶äºå³çµ±æ´é«æ¹æ³å°å¾çææè¡ï¼ä¾å¦ N-best åè¡¨éæ°æåºï¼çæææ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çé¶æ¬¡æ¹æ´é«ç­ç¥ï¼å®åè¨±å¨è§£ç¢¼éæ®µæ´åä¸åçæ¨¡åï¼èç¡éé¡å¤è¨ç·´ãæåçåæ³å¨è§£ç¢¼æééæ°æåºæ³¢æï¼æ¹æ³æ¯çµåå­è©å±¤ç´çåæ¸ï¼ä¸¦ä½¿ç¨åç¼æ³ä¾é æ¸¬å­è©ä½æå®æãæåå¨æ©å¨ç¿»è­¯å ´æ¯ä¸­è­æäºéç¨®æ¹æ³çæææ§ï¼è¡¨æå®è½å¤ ç¢çåæå·åèªé³åå½±åæç¥è½åçç¿»è­¯ï¼åæä¹è½æåæ´é«ç¿»è­¯åè³ª\footnote{æåå°å¨è«æè¢«æ¥åå¾éåºç¨å¼ç¢¼ã}ã

##### **Automating Thought of Search: A Journey Towards Soundness and Completeness**
2408.11326v1 by Daniel Cao, Michael Katz, Harsha Kokel, Kavitha Srinivas, Shirin Sohrabi

Planning remains one of the last standing bastions for large language models
(LLMs), which now turn their attention to search. Most of the literature uses
the language models as world models to define the search space, forgoing
soundness for the sake of flexibility. A recent work, Thought of Search (ToS),
proposed defining the search space with code, having the language models
produce that code. ToS requires a human in the loop, collaboratively producing
a sound successor function and goal test. The result, however, is worth the
effort: all the tested datasets were solved with 100% accuracy. At the same
time LLMs have demonstrated significant progress in code generation and
refinement for complex reasoning tasks. In this work, we automate ToS
(AutoToS), completely taking the human out of the loop of solving planning
problems. AutoToS guides the language model step by step towards the generation
of sound and complete search components, through feedback from both generic and
domain specific unit tests. We achieve 100% accuracy, with minimal feedback
iterations, using LLMs of various sizes on all evaluated domains.

æè¦ï¼è¦åä»ç¶æ¯å¤§èªè¨æ¨¡å (LLM) æå¾çå ¡å£ä¹ä¸ï¼ç¾å¨å®åå°æ³¨æåè½åæå°ãå¤§å¤æ¸æç»å°èªè¨æ¨¡åç¨ä½ä¸çæ¨¡åä¾å®ç¾©æå°ç©ºéï¼çºäºéæ´»æ§èæ¾æ£å¥å¨æ§ãæè¿çä¸é å·¥ä½ãæå°æèã(ToS) æè­°ä½¿ç¨ç¨å¼ç¢¼å®ç¾©æå°ç©ºéï¼è®èªè¨æ¨¡åç¢çè©²ç¨å¼ç¢¼ãToS éè¦äººé¡åèï¼åä½ç¢çå¥å¨çå¾ç¹¼å½æ¸åç®æ¨æ¸¬è©¦ãç¶èï¼çµæå¼å¾ä»åºåªåï¼æææ¸¬è©¦çè³æéé½ä»¥ 100% çæºç¢ºåº¦è§£æ±ºãåæï¼LLM å¨è¤éæ¨çä»»åçç¨å¼ç¢¼ç¢çåæ¹é²æ¹é¢å·²å±ç¾é¡¯èé²å±ãå¨éé å·¥ä½ä¸­ï¼æåèªåå ToS (AutoToS)ï¼å°äººé¡å®å¨æé¤å¨è§£æ±ºè¦ååé¡çè¿´åä¹å¤ãAutoToS ééä¸è¬åé åç¹å®å®åæ¸¬è©¦çåé¥ï¼éæ­¥å¼å°èªè¨æ¨¡åç¢çå¥å¨ä¸å®æ´çæå°åä»¶ãæåå¨ææè©ä¼°çé åä¸­ä½¿ç¨åç¨®è¦æ¨¡ç LLMï¼ä»¥æå°çåé¥åè¦éç®ï¼éå°äº 100% çæºç¢ºåº¦ã

##### **Towards Evaluating Large Language Models on Sarcasm Understanding**
2408.11319v1 by Yazhou Zhang, Chunwang Zou, Zheng Lian, Prayag Tiwari, Jing Qin

In the era of large language models (LLMs), the task of ``System I''~-~the
fast, unconscious, and intuitive tasks, e.g., sentiment analysis, text
classification, etc., have been argued to be successfully solved. However,
sarcasm, as a subtle linguistic phenomenon, often employs rhetorical devices
like hyperbole and figuration to convey true sentiments and intentions,
involving a higher level of abstraction than sentiment analysis. There is
growing concern that the argument about LLMs' success may not be fully tenable
when considering sarcasm understanding. To address this question, we select
eleven SOTA LLMs and eight SOTA pre-trained language models (PLMs) and present
comprehensive evaluations on six widely used benchmark datasets through
different prompting approaches, i.e., zero-shot input/output (IO) prompting,
few-shot IO prompting, chain of thought (CoT) prompting. Our results highlight
three key findings: (1) current LLMs underperform supervised PLMs based sarcasm
detection baselines across six sarcasm benchmarks. This suggests that
significant efforts are still required to improve LLMs' understanding of human
sarcasm. (2) GPT-4 consistently and significantly outperforms other LLMs across
various prompting methods, with an average improvement of 14.0\%$\uparrow$.
Claude 3 and ChatGPT demonstrate the next best performance after GPT-4. (3)
Few-shot IO prompting method outperforms the other two methods: zero-shot IO
and few-shot CoT. The reason is that sarcasm detection, being a holistic,
intuitive, and non-rational cognitive process, is argued not to adhere to
step-by-step logical reasoning, making CoT less effective in understanding
sarcasm compared to its effectiveness in mathematical reasoning tasks.

æè¦ï¼<paragraph>å¨å¤§èªè¨æ¨¡å (LLM) æä»£ï¼``ç³»çµ± I'' çä»»å~-~å¿«éãç¡æè­åç´è¦ºæ§çä»»åï¼ä¾å¦æç·åæãæå­åé¡ç­ï¼å·²è¢«èªçºå·²æåè§£æ±ºãç¶èï¼è«·åºä½çºä¸ç¨®å¾®å¦çèªè¨ç¾è±¡ï¼éå¸¸æ¡ç¨èªé£¾åæ¯å»ç­ä¿®è¾­ææ³ä¾å³éçå¯¦çææåæåï¼æ¶åæ¯æç·åææ´é«çæ½è±¡å±¤æ¬¡ãè¶ä¾è¶å¤äººæå¿ï¼å¨èæ®è«·åºçè§£æï¼éæ¼ LLM æåçä¸»å¼µå¯è½ç¡æ³å®å¨æç«ãçºäºè§£æ±ºéååé¡ï¼æåé¸æäºåä¸ç¨® SOTA LLM åå«ç¨® SOTA é è¨ç·´èªè¨æ¨¡å (PLM)ï¼ä¸¦ééä¸åçæç¤ºæ¹æ³å°å­åå»£æ³ä½¿ç¨çåºæºæ¸æéé²è¡äºå¨é¢çè©ä¼°ï¼å³é¶æ¬¡è¼¸å¥/è¼¸åº (IO) æç¤ºãå°æ¬¡ IO æç¤ºãæèé (CoT) æç¤ºãæåççµæçªåºäºä¸åééµç¼ç¾ï¼(1) ç¶å LLM å¨å­åè«·åºåºæºæ¸¬è©¦ä¸­è¡¨ç¾ä¸å¦åºæ¼ç£ç£ PLM çè«·åºæª¢æ¸¬åºæºãéè¡¨æï¼ä»éè¦ä»åºå·¨å¤§çåªåä¾æé« LLM å°äººé¡è«·åºççè§£ã(2) GPT-4 å¨åç¨®æç¤ºæ¹æ³ä¸­å§çµé¡¯èåªæ¼å¶ä» LLMï¼å¹³åæ¹é²äº 14.0%$\uparrow$ãClaude 3 å ChatGPT å¨ GPT-4 ä¹å¾è¡¨ç¾åºæ¬¡ä½³çæ§è½ã(3) å°æ¬¡ IO æç¤ºæ¹æ³åªæ¼å¶ä»å©ç¨®æ¹æ³ï¼é¶æ¬¡ IO åå°æ¬¡ CoTãåå æ¯è«·åºæª¢æ¸¬æ¯ä¸åæ´é«çãç´è¦ºçåéçæ§çèªç¥éç¨ï¼æèªçºä¸éµå¾ªå¾ªåºæ¼¸é²çéè¼¯æ¨çï¼éä½¿å¾ CoT å¨çè§£è«·åºæ¹é¢çææä¸å¦å¨æ¸å­¸æ¨çä»»åä¸­çææã</paragraph>

##### **Probabilistic Medical Predictions of Large Language Models**
2408.11316v1 by Bowen Gu, Rishi J. Desai, Kueiyu Joshua Lin, Jie Yang

Large Language Models (LLMs) have demonstrated significant potential in
clinical applications through prompt engineering, which enables the generation
of flexible and diverse clinical predictions. However, they pose challenges in
producing prediction probabilities, which are essential for transparency and
allowing clinicians to apply flexible probability thresholds in
decision-making. While explicit prompt instructions can lead LLMs to provide
prediction probability numbers through text generation, LLMs' limitations in
numerical reasoning raise concerns about the reliability of these
text-generated probabilities. To assess this reliability, we compared explicit
probabilities derived from text generation to implicit probabilities calculated
based on the likelihood of predicting the correct label token. Experimenting
with six advanced open-source LLMs across five medical datasets, we found that
the performance of explicit probabilities was consistently lower than implicit
probabilities with respect to discrimination, precision, and recall. Moreover,
these differences were enlarged on small LLMs and imbalanced datasets,
emphasizing the need for cautious interpretation and applications, as well as
further research into robust probability estimation methods for LLMs in
clinical contexts.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ééæç¤ºå·¥ç¨å±ç¤ºäºå¨è¨åºæç¨ä¸çé¡¯èæ½åï¼éä½¿å¾ç¢çéæ´»å¤æ¨£çè¨åºé æ¸¬æçºå¯è½ãç¶èï¼å®åå¨ç¢çé æ¸¬æ©çä¸éå°äºææ°ï¼èéå°æ¼éæåº¦ååè¨±è¨åºé«å¸«å¨æ±ºç­ä¸­å¥ç¨éæ´»çæ©çé¾å¼è³ééè¦ãåç®¡æç¢ºçæç¤ºèªªæå¯ä»¥å¼å° LLM ééæå­ç¢çæä¾é æ¸¬æ©çæ¸å­ï¼ä½ LLM å¨æ¸å­æ¨çä¸çéå¶å¼ç¼äºå°æ¼éäºæå­ç¢ççæ©çå¯é æ§ççæ®ãçºäºè©ä¼°éç¨®å¯é æ§ï¼æåå°å¾æå­ç¢çä¸­è¡ççæç¢ºæ©çèæ ¹æé æ¸¬æ­£ç¢ºæ¨è¨ç¬¦èçå¯è½æ§è¨ç®çé±å«æ©çé²è¡æ¯è¼ãæåä½¿ç¨å­ç¨®åé²çéæº LLM éå°äºåé«çè³æéé²è¡å¯¦é©ï¼ç¼ç¾æç¢ºæ©ççè¡¨ç¾å§çµä½æ¼é±å«æ©çï¼ç¡è«æ¯å¨å¤å¥ãç²¾æºåº¦åå¬åçæ¹é¢çæ¯å¦æ­¤ãæ­¤å¤ï¼éäºå·®ç°å¨å°å LLM åä¸å¹³è¡¡è³æéä¸è¢«æ¾å¤§äºï¼éå¼·èª¿äºè¬¹æè§£è®åæç¨ä»¥åé²ä¸æ­¥ç ç©¶ LLM å¨è¨åºæå¢ä¸­ç©©å¥æ©çä¼°è¨æ¹æ³çå¿è¦æ§ã

##### **Unlocking Adversarial Suffix Optimization Without Affirmative Phrases: Efficient Black-box Jailbreaking via LLM as Optimizer**
2408.11313v1 by Weipeng Jiang, Zhenting Wang, Juan Zhai, Shiqing Ma, Zhengyu Zhao, Chao Shen

Despite prior safety alignment efforts, mainstream LLMs can still generate
harmful and unethical content when subjected to jailbreaking attacks. Existing
jailbreaking methods fall into two main categories: template-based and
optimization-based methods. The former requires significant manual effort and
domain knowledge, while the latter, exemplified by Greedy Coordinate Gradient
(GCG), which seeks to maximize the likelihood of harmful LLM outputs through
token-level optimization, also encounters several limitations: requiring
white-box access, necessitating pre-constructed affirmative phrase, and
suffering from low efficiency. In this paper, we present ECLIPSE, a novel and
efficient black-box jailbreaking method utilizing optimizable suffixes. Drawing
inspiration from LLMs' powerful generation and optimization capabilities, we
employ task prompts to translate jailbreaking goals into natural language
instructions. This guides the LLM to generate adversarial suffixes for
malicious queries. In particular, a harmfulness scorer provides continuous
feedback, enabling LLM self-reflection and iterative optimization to
autonomously and efficiently produce effective suffixes. Experimental results
demonstrate that ECLIPSE achieves an average attack success rate (ASR) of 0.92
across three open-source LLMs and GPT-3.5-Turbo, significantly surpassing GCG
in 2.4 times. Moreover, ECLIPSE is on par with template-based methods in ASR
while offering superior attack efficiency, reducing the average attack overhead
by 83%.

æè¦ï¼åç®¡ååçå®å¨èª¿æ´å·¥ä½ï¼ä¸»æµ LLM ä»å¯è½å¨é­åè¶çæ»ææç¢çæå®³ä¸ä¸éå¾·çå§å®¹ãç¾æçè¶çæ¹æ³åçºå©å¤§é¡ï¼åºæ¼ç¯æ¬ååºæ¼æä½³åçæ¹æ³ãåèéè¦å¤§éæåæä½åé åç¥è­ï¼èå¾èä»¥è²ªå©ªåæ¨æ¢¯åº¦ (GCG) çºä¾ï¼ééä»¤çå±¤ç´æä½³åä¾æå¤§åæå®³ LLM è¼¸åºçå¯è½æ§ï¼ä¹éå°äºä¸äºéå¶ï¼éè¦ç½çå­åæ¬éãéè¦é åå»ºæ§è¯å®è©çµï¼ä¸æçä½è½ãå¨æ¬æä¸­ï¼æåæåº ECLIPSEï¼ä¸ç¨®å©ç¨å¯æä½³åå­å°¾çæ°ç©ä¸ææççé»çè¶çæ¹æ³ãå¾ LLM å¼·å¤§ççæåæä½³ååè½ä¸­æ±²åéæï¼æåä½¿ç¨ä»»åæç¤ºå°è¶çç®æ¨è½æçºèªç¶èªè¨æä»¤ãéå¼å° LLM çºæ¡ææ¥è©¢çæå°ææ§å­å°¾ãç¹å¥æ¯ï¼ä¸åå±å®³æ§è©åå¨æä¾æçºçåé¥ï¼ä½¿ LLM è½å¤ èªæåçååè¦æä½³åï¼ä»¥èªä¸»ä¸ææçå°ç¢çææçå­å°¾ãå¯¦é©çµæè¡¨æï¼ECLIPSE å¨ä¸åéæº LLM å GPT-3.5-Turbo ä¸­å¯¦ç¾äº 0.92 çå¹³åæ»ææåç (ASR)ï¼é¡¯èè¶é GCG 2.4 åãæ­¤å¤ï¼ECLIPSE å¨ ASR ä¸­èåºæ¼ç¯æ¬çæ¹æ³ä¸ç¸ä¸ä¸ï¼åææä¾åªè¶çæ»ææçï¼å°å¹³åæ»æéé·æ¸å°äº 83%ã

##### **Swarm Intelligence in Geo-Localization: A Multi-Agent Large Vision-Language Model Collaborative Framework**
2408.11312v1 by Xiao Han, Chen Zhu, Xiangyu Zhao, Hengshu Zhu

Visual geo-localization demands in-depth knowledge and advanced reasoning
skills to associate images with real-world geographic locations precisely. In
general, traditional methods based on data-matching are hindered by the
impracticality of storing adequate visual records of global landmarks.
Recently, Large Vision-Language Models (LVLMs) have demonstrated the capability
of geo-localization through Visual Question Answering (VQA), enabling a
solution that does not require external geo-tagged image records. However, the
performance of a single LVLM is still limited by its intrinsic knowledge and
reasoning capabilities. Along this line, in this paper, we introduce a novel
visual geo-localization framework called \name\ that integrates the inherent
knowledge of multiple LVLM agents via inter-agent communication to achieve
effective geo-localization of images. Furthermore, our framework employs a
dynamic learning strategy to optimize the communication patterns among agents,
reducing unnecessary discussions among agents and improving the efficiency of
the framework. To validate the effectiveness of the proposed framework, we
construct GeoGlobe, a novel dataset for visual geo-localization tasks.
Extensive testing on the dataset demonstrates that our approach significantly
outperforms state-of-the-art methods.

æè¦ï¼è¦è¦ºå°çå®ä½éè¦æ·±å¥çç¥è­ååé²çæ¨çæè½ï¼æè½ç²¾ç¢ºå°å°å½±åèçå¯¦ä¸ççå°çä½ç½®è¯ç¹«èµ·ä¾ãä¸è¬ä¾èªªï¼åºæ¼è³æéå°çå³çµ±æ¹æ³åå°å²å­å¨çå°æ¨è¶³å¤ è¦è¦ºç´éçä¸åå¯¦éæ§æé»ç¤ãæè¿ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å·²ééè¦è¦ºåç­ (VQA) å±ç¤ºäºå°çå®ä½çè½åï¼æä¾ä¸ç¨®ä¸éè¦å¤é¨å°çæ¨ç±¤å½±åç´éçè§£æ±ºæ¹æ¡ãç¶èï¼å®ä¸ LVLM çæè½ä»åå°å¶å§å¨ç¥è­åæ¨çè½åçéå¶ãå¨éæ¢è·¯çº¿ä¸ï¼æåå¨æ¬æä¸­ä»ç´¹äºä¸ååçº \name\ çæ°è¦è¦ºå°çå®ä½æ¶æ§ï¼å®ééä»£çéæºéæ´åå¤å LVLM ä»£ççå§å¨ç¥è­ï¼ä»¥éæå½±åçææå°çå®ä½ãæ­¤å¤ï¼æåçæ¶æ§æ¡ç¨åæå­¸ç¿ç­ç¥ä¾åªåä»£çä¹éçæºéæ¨¡å¼ï¼æ¸å°ä»£çä¹éä¸å¿è¦çè¨è«ï¼ä¸¦æé«æ¶æ§çæçãçºäºé©è­ææåºæ¶æ§çæææ§ï¼æåå»ºæ§äº GeoGlobeï¼ä¸åç¨æ¼è¦è¦ºå°çå®ä½ä»»åçæ°è³æéãå¨è³æéä¸çå»£æ³æ¸¬è©¦è­æï¼æåçåæ³é¡¯èåªæ¼æåé²çæ¹æ³ã

##### **EEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models**
2408.11308v1 by Chongwen Zhao, Zhihao Dou, Kaizhu Huang

Large Language Models (LLMs) are increasingly attracting attention in various
applications. Nonetheless, there is a growing concern as some users attempt to
exploit these models for malicious purposes, including the synthesis of
controlled substances and the propagation of disinformation. In an effort to
mitigate such risks, the concept of "Alignment" technology has been developed.
However, recent studies indicate that this alignment can be undermined using
sophisticated prompt engineering or adversarial suffixes, a technique known as
"Jailbreak." Our research takes cues from the human-like generate process of
LLMs. We identify that while jailbreaking prompts may yield output logits
similar to benign prompts, their initial embeddings within the model's latent
space tend to be more analogous to those of malicious prompts. Leveraging this
finding, we propose utilizing the early transformer outputs of LLMs as a means
to detect malicious inputs, and terminate the generation immediately. Built
upon this idea, we introduce a simple yet significant defense approach called
EEG-Defender for LLMs. We conduct comprehensive experiments on ten jailbreak
methods across three models. Our results demonstrate that EEG-Defender is
capable of reducing the Attack Success Rate (ASR) by a significant margin,
roughly 85\% in comparison with 50\% for the present SOTAs, with minimal impact
on the utility and effectiveness of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®æç¨ä¸­è¶ä¾è¶åå°éæ³¨ãåç®¡å¦æ­¤ï¼é¨èä¸äºä½¿ç¨èåè©¦å°éäºæ¨¡åç¨æ¼æ¡æç®çï¼åæ¬åæåæ§ç©è³ªåæ£å¸é¯èª¤è¨æ¯ï¼ææä¹èæ¥ä¿±å¢ãçºäºæ¸è¼æ­¤é¡é¢¨éªï¼ãæ¯å°ãæè¡çæ¦å¿µæéèçãç¶èï¼æè¿çç ç©¶è¡¨æï¼éç¨®æ¯å°å¯ä»¥ä½¿ç¨ç²¾å¯çæç¤ºå·¥ç¨æå°ææ§å¾ç¶´ï¼ä¸ç¨®ç¨±çºãè¶çãçæè¡ï¼ä¾ç ´å£ãæåçç ç©¶å¾ LLM é¡ä¼¼äººé¡ççæéç¨æ±²åéæãæåç¼ç¾ï¼åç®¡è¶çæç¤ºå¯è½æç¢çé¡ä¼¼æ¼è¯æ§æç¤ºçè¼¸åº logitï¼ä½å®åå¨æ¨¡åæ½å¨ç©ºéä¸­çåå§åµå¥éå¸¸æ´é¡ä¼¼æ¼æ¡ææç¤ºçåµå¥ãå©ç¨éä¸ç¼ç¾ï¼æåå»ºè­°å©ç¨ LLM çæ©æè®æå¨è¼¸åºä½çºåµæ¸¬æ¡æè¼¸å¥ä¸¦ç«å³çµæ­¢çæçææ®µãåºæ¼éåæ³æ³ï¼æåçº LLM ä»ç´¹äºä¸ç¨®ç°¡å®ä½éè¦çé²ç¦¦æ¹æ³ï¼ç¨±çº EEG-Defenderãæåå°ä¸åæ¨¡åä¸­çåç¨®è¶çæ¹æ³é²è¡äºå¨é¢çå¯¦é©ãæåççµæè¡¨æï¼EEG-Defender è½å¤ å°æ»ææåç (ASR) å¤§å¹éä½ï¼èç¾æç SOTA ç¸æ¯ï¼å¤§ç´éä½äº 85%ï¼èå° LLM çæç¨åæææ§çå½±é¿æå°ã

##### **KAN4TSF: Are KAN and KAN-based models Effective for Time Series Forecasting?**
2408.11306v1 by Xiao Han, Xinfeng Zhang, Yiling Wu, Zhenduo Zhang, Zhe Wu

Time series forecasting is a crucial task that predicts the future values of
variables based on historical data. Time series forecasting techniques have
been developing in parallel with the machine learning community, from early
statistical learning methods to current deep learning methods. Although
existing methods have made significant progress, they still suffer from two
challenges. The mathematical theory of mainstream deep learning-based methods
does not establish a clear relation between network sizes and fitting
capabilities, and these methods often lack interpretability. To this end, we
introduce the Kolmogorov-Arnold Network (KAN) into time series forecasting
research, which has better mathematical properties and interpretability. First,
we propose the Reversible Mixture of KAN experts (RMoK) model, which is a
KAN-based model for time series forecasting. RMoK uses a mixture-of-experts
structure to assign variables to KAN experts. Then, we compare performance,
integration, and speed between RMoK and various baselines on real-world
datasets, and the experimental results show that RMoK achieves the best
performance in most cases. And we find the relationship between temporal
feature weights and data periodicity through visualization, which roughly
explains RMoK's mechanism. Thus, we conclude that KAN and KAN-based models
(RMoK) are effective in time series forecasting. Code is available at KAN4TSF:
https://github.com/2448845600/KAN4TSF.

æè¦ï¼æéåºåé æ¸¬æ¯ä¸é éè¦çä»»åï¼å®æ ¹ææ­·å²æ¸æé æ¸¬è®æ¸çæªä¾å¼ãæéåºåé æ¸¬æè¡å·²èæ©å¨å­¸ç¿ç¤¾ç¾¤åæ­¥ç¼å±ï¼å¾æ©æççµ±è¨å­¸ç¿æ¹æ³å°ç®åçæ·±åº¦å­¸ç¿æ¹æ³ãåç®¡ç¾ææ¹æ³å·²åå¾éå¤§é²å±ï¼ä½ä»é¢è¨å©é ææ°ãä¸»æµåºæ¼æ·±åº¦å­¸ç¿çæ¹æ³çæ¸å­¸çè«ä¸¦æªå»ºç«ç¶²è·¯å¤§å°èæ¬åè½åä¹éçæç¢ºéä¿ï¼èä¸éäºæ¹æ³éå¸¸ç¼ºä¹å¯è§£éæ§ãçºæ­¤ï¼æåå° Kolmogorov-Arnold ç¶²è·¯ (KAN) å¼å¥æéåºåé æ¸¬ç ç©¶ï¼å®å·ææ´å¥½çæ¸å­¸ç¹æ§åå¯è§£éæ§ãé¦åï¼æåæåº KAN å°å®¶å¯éæ··å (RMoK) æ¨¡åï¼éæ¯ä¸ååºæ¼ KAN çæéåºåé æ¸¬æ¨¡åãRMoK ä½¿ç¨å°å®¶æ··åçµæ§å°è®æ¸åéçµ¦ KAN å°å®¶ãç¶å¾ï¼æåæ¯è¼ RMoK èåç¨®åºç·å¨çå¯¦ä¸çè³æéä¸çæè½ãæ´ååéåº¦ï¼å¯¦é©çµæé¡¯ç¤º RMoK å¨å¤§å¤æ¸ææ³ä¸é½è½éææä½³æè½ãæåééè¦è¦ºåæ¾åºæéç¹å¾µæ¬éèè³æé±ææ§ä¹éçéä¿ï¼éå¤§è´èªªæäº RMoK çæ©å¶ãå æ­¤ï¼æåå¾åºçµè«ï¼KAN ååºæ¼ KAN çæ¨¡å (RMoK) å¨æéåºåé æ¸¬ä¸­æ¯ææçãç¨å¼ç¢¼å¯å¨ KAN4TSF åå¾ï¼https://github.com/2448845600/KAN4TSFã

##### **UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation**
2408.11305v1 by Xiangyu Zhao, Yuehan Zhang, Wenlong Zhang, Xiao-Ming Wu

The fashion domain encompasses a variety of real-world multimodal tasks,
including multimodal retrieval and multimodal generation. The rapid
advancements in artificial intelligence generated content, particularly in
technologies like large language models for text generation and diffusion
models for visual generation, have sparked widespread research interest in
applying these multimodal models in the fashion domain. However, tasks
involving embeddings, such as image-to-text or text-to-image retrieval, have
been largely overlooked from this perspective due to the diverse nature of the
multimodal fashion domain. And current research on multi-task single models
lack focus on image generation. In this work, we present UniFashion, a unified
framework that simultaneously tackles the challenges of multimodal generation
and retrieval tasks within the fashion domain, integrating image generation
with retrieval tasks and text generation tasks. UniFashion unifies embedding
and generative tasks by integrating a diffusion model and LLM, enabling
controllable and high-fidelity generation. Our model significantly outperforms
previous single-task state-of-the-art models across diverse fashion tasks, and
can be readily adapted to manage complex vision-language tasks. This work
demonstrates the potential learning synergy between multimodal generation and
retrieval, offering a promising direction for future research in the fashion
domain. The source code is available at
https://github.com/xiangyu-mm/UniFashion.

æè¦ï¼æå°é ååå«åç¨®çå¯¦ä¸ççå¤æ¨¡æä»»åï¼åæ¬å¤æ¨¡ææª¢ç´¢åå¤æ¨¡æçæãäººå·¥æºæ§æç¢ççå§å®¹å¿«éé²æ­¥ï¼ç¹å¥æ¯å¨ææ¬çæçå¤§èªè¨æ¨¡ååè¦è¦ºçææ´æ£æ¨¡åç­æè¡ä¸­ï¼éæ¿ç¼äºå»£æ³çç ç©¶èè¶£ï¼å°éäºå¤æ¨¡ææ¨¡åæç¨æ¼æå°é åãç¶èï¼ç±æ¼å¤æ¨¡ææå°é åçå¤æ¨£æ§ï¼æ¶ååµå¥çä»»åï¼ä¾å¦ååå°ææ¬æææ¬å°ååæª¢ç´¢ï¼å¾éåè§åº¦ä¾çï¼å¨å¾å¤§ç¨åº¦ä¸è¢«å¿½è¦äºãç®åå°å¤ä»»åå®ä¸æ¨¡åçç ç©¶ç¼ºä¹å°ååçæçéæ³¨ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº UniFashionï¼ä¸åçµ±ä¸çæ¡æ¶ï¼åææå°æå°é åå§å¤æ¨¡æçæåæª¢ç´¢ä»»åçææ°ï¼å°ååçæèæª¢ç´¢ä»»ååææ¬çæä»»åæ´åå¨ä¸èµ·ãUniFashion ééæ´åæ´æ£æ¨¡åå LLM ä¾çµ±ä¸åµå¥åçæä»»åï¼å¯¦ç¾å¯æ§ä¸é«ä¿ççæãæåçæ¨¡åå¨åç¨®æå°ä»»åä¸­æé¡¯åªæ¼ä»¥åçå®ä»»åæåé²æ¨¡åï¼ä¸¦ä¸å¯ä»¥è¼é¬é©æç®¡çè¤éçè¦è¦ºèªè¨ä»»åãéé å·¥ä½å±ç¤ºäºå¤æ¨¡æçæåæª¢ç´¢ä¹éçæ½å¨å­¸ç¿ååä½ç¨ï¼çºæå°é åæªä¾çç ç©¶æä¾äºæå¸æçæ¹åãåå§ç¢¼å¯å¨ https://github.com/xiangyu-mm/UniFashion ç²å¾ã

##### **Offline Policy Learning via Skill-step Abstraction for Long-horizon Goal-Conditioned Tasks**
2408.11300v1 by Donghoon Kim, Minjong Yoo, Honguk Woo

Goal-conditioned (GC) policy learning often faces a challenge arising from
the sparsity of rewards, when confronting long-horizon goals. To address the
challenge, we explore skill-based GC policy learning in offline settings, where
skills are acquired from existing data and long-horizon goals are decomposed
into sequences of near-term goals that align with these skills. Specifically,
we present an `offline GC policy learning via skill-step abstraction' framework
(GLvSA) tailored for tackling long-horizon GC tasks affected by goal
distribution shifts. In the framework, a GC policy is progressively learned
offline in conjunction with the incremental modeling of skill-step abstractions
on the data. We also devise a GC policy hierarchy that not only accelerates GC
policy learning within the framework but also allows for parameter-efficient
fine-tuning of the policy. Through experiments with the maze and Franka kitchen
environments, we demonstrate the superiority and efficiency of our GLvSA
framework in adapting GC policies to a wide range of long-horizon goals. The
framework achieves competitive zero-shot and few-shot adaptation performance,
outperforming existing GC policy learning and skill-based methods.

æè¦ï¼ç®æ¨æ¢ä»¶ï¼GCï¼æ¿ç­å­¸ç¿å¨é¢å°é·æç®æ¨æï¼ç¶å¸¸æé¢è¨çåµç¨ççææ°ãçºäºæå°éé ææ°ï¼æåå¨é¢ç·è¨­ç½®ä¸­æ¢ç´¢åºæ¼æè½ç GC æ¿ç­å­¸ç¿ï¼å¶ä¸­æè½å¾ç¾æè³æä¸­ç²åï¼èé·æç®æ¨ååè§£çºèéäºæè½ç¸ç¬¦çè¿æç®æ¨åºåãå·é«ä¾èªªï¼æåæåºäºä¸åãééæè½æ­¥é©æ½è±¡çé¢ç· GC æ¿ç­å­¸ç¿ãæ¶æ§ï¼GLvSAï¼ï¼å°éç¨æ¼èçåç®æ¨åä½è½ç§»å½±é¿çé·æ GC ä»»åãå¨éåæ¶æ§ä¸­ï¼GC æ¿ç­æéæ­¥å¨é¢ç·ä¸­å­¸ç¿ï¼ä¸¦çµåè³æä¸­æè½æ­¥é©æ½è±¡çå¢éå»ºæ¨¡ãæåéè¨­è¨äºä¸å GC æ¿ç­å±¤ç´ï¼å®ä¸åå éäºæ¶æ§å§ç GC æ¿ç­å­¸ç¿ï¼éåè¨±å°æ¿ç­é²è¡åæ¸ææçå¾®èª¿ãééè¿·å®®å Franka å»æ¿ç°å¢çå¯¦é©ï¼æåå±ç¤ºäºæåç GLvSA æ¶æ§å¨å° GC æ¿ç­é©æå°å»£æ³çé·æç®æ¨æ¹é¢çåªè¶æ§åæçãè©²æ¶æ§éå°äºå·æç«¶ç­åçé¶æ¬¡å­¸ç¿åå°æ¬¡å­¸ç¿é©ææè½ï¼åªæ¼ç¾æç GC æ¿ç­å­¸ç¿ååºæ¼æè½çæ¹æ³ã

##### **RePair: Automated Program Repair with Process-based Feedback**
2408.11296v1 by Yuze Zhao, Zhenya Huang, Yixiao Ma, Rui Li, Kai Zhang, Hao Jiang, Qi Liu, Linbo Zhu, Yu Su

The gap between the trepidation of program reliability and the expense of
repairs underscores the indispensability of Automated Program Repair (APR). APR
is instrumental in transforming vulnerable programs into more robust ones,
bolstering program reliability while simultaneously diminishing the financial
burden of manual repairs. Commercial-scale language models (LM) have taken APR
to unprecedented levels. However, the emergence reveals that for models fewer
than 100B parameters, making single-step modifications may be difficult to
achieve the desired effect. Moreover, humans interact with the LM through
explicit prompts, which hinders the LM from receiving feedback from compiler
and test cases to automatically optimize its repair policies. In this
literature, we explore how small-scale LM (less than 20B) achieve excellent
performance through process supervision and feedback. We start by constructing
a dataset named CodeNet4Repair, replete with multiple repair records, which
supervises the fine-tuning of a foundational model. Building upon the
encouraging outcomes of reinforcement learning, we develop a reward model that
serves as a critic, providing feedback for the fine-tuned LM's action,
progressively optimizing its policy. During inference, we require the LM to
generate solutions iteratively until the repair effect no longer improves or
hits the maximum step limit. The results show that process-based not only
outperforms larger outcome-based generation methods, but also nearly matches
the performance of closed-source commercial large-scale LMs.

æè¦ï¼ç¨å¼å¯é æ§ä»¤äººè½æ°å¿é©ï¼èç¶­ä¿®è²»ç¨é«æï¼éå©èä¹éçå·®è·çªé¡¯äºèªååç¨å¼ä¿®å¾© (APR) çä¸å¯æç¼ºæ§ãAPR å¹«å©å°å®¹æåæ»æçç¨å¼è½è®çºæ´å¼·å¤§çç¨å¼ï¼åææé«ç¨å¼å¯é æ§ï¼ä¸¦éä½äººå·¥ç¶­ä¿®çè²¡åè² æãåç¨è¦æ¨¡çèªè¨æ¨¡å (LM) å·²å° APR æåå°åææªæçæ°´æºãç¶èï¼æ°èæè¡é¡¯ç¤ºï¼å°æ¼åæ¸å°æ¼ 100B çæ¨¡åï¼é²è¡å®æ­¥ä¿®æ¹å¯è½é£ä»¥éå°é æçææãæ­¤å¤ï¼äººé¡ééæç¢ºçæç¤ºè LM äºåï¼éæé»ç¤ LM å¾ç·¨è­¯å¨åæ¸¬è©¦æ¡ä¾ä¸­æ¥æ¶åé¥ï¼ä»¥èªåæä½³åå¶ä¿®å¾©æ¿ç­ãå¨æ¬ç¯æç»ä¸­ï¼æåæ¢è¨å°è¦æ¨¡ LMï¼å°æ¼ 20Bï¼å¦ä½ééæµç¨ç£ç£ååé¥ä¾éæåè¶çæè½ãæåå¾å»ºç«ä¸ååçº CodeNet4Repair çè³æééå§ï¼å¶ä¸­åå«å¤ç­ä¿®å¾©è¨éï¼ç¨æ¼ç£ç£åºç¤æ¨¡åçå¾®èª¿ãå»ºç«å¨å¼·åå­¸ç¿çä»¤äººæ¯å¥®çææä¹ä¸ï¼æåéç¼äºä¸ååé¥æ¨¡åï¼ä½çºä¸åè©è«å®¶ï¼æä¾å¾®èª¿å¾ç LM åä½çåé¥ï¼éæ­¥æä½³åå¶æ¿ç­ãå¨æ¨è«æéï¼æåè¦æ± LM è¿­ä»£ç¢çè§£æ±ºæ¹æ¡ï¼ç´å°ä¿®å¾©ææä¸åæ¹åæéå°æå¤§æ­¥é©éå¶ãçµæé¡¯ç¤ºï¼åºæ¼æµç¨çæ¹æ³ä¸ååªæ¼è¼å¤§åçåºæ¼çµæçç¢çæ¹æ³ï¼èä¸å¹¾ä¹èéæºåç¨å¤§å LM çæè½ç¸å¹éã

##### **RedWhale: An Adapted Korean LLM Through Efficient Continual Pretraining**
2408.11294v1 by Anh-Dung Vo, Minseong Jung, Wonbeen Lee, Daewoo Choi

The field of Natural Language Processing (NLP) has seen significant
advancements with the development of Large Language Models (LLMs). However,
much of this research remains focused on English, often overlooking
low-resource languages like Korean. This oversight presents challenges due to
the unique non-alphabetic token structure of Korean and the substantial memory
and computational demands required for LLM training, which frequently lead to
memory constraints and out-of-memory errors. To address these issues, we
present RedWhale, a model specifically tailored for Korean language processing.
RedWhale is developed using an efficient continual pretraining approach that
includes a comprehensive Korean corpus preprocessing pipeline, a specialized
tokenizer, an optimized model initialization technique, and a multistage
pretraining strategy. These innovations collectively reduce training time and
computational costs while maintaining high levels of accuracy and
comprehension. By leveraging cross-lingual transfer learning, which exploits
shared linguistic similarities across languages, RedWhale builds on English
models to enhance Korean language processing. Experimental results demonstrate
that RedWhale outperforms other leading models on Korean NLP benchmarks,
including the Korean Balanced Evaluation of Significant Tasks (KoBEST), showing
superior understanding and generation of Korean text. Furthermore, RedWhale
showed no signs of convergence even after pretraining on 9.7 billion tokens,
indicating the potential for further improvements with additional training.
This work represents a significant advancement in bridging the linguistic
divide, particularly in enhancing NLP capabilities for the Korean language.

æè¦ï¼èªç¶èªè¨èç (NLP) é åé¨èå¤§åèªè¨æ¨¡å (LLM) çç¼å±åå¾é¡¯èé²å±ãç¶èï¼éé ç ç©¶å¤§å¤ä»éä¸­æ¼è±èªï¼å¾å¾å¿½ç¥éèªç­ä½è³æºèªè¨ãç±æ¼éèªç¨ç¹çéå­æ¯ç¬¦èçµæ§ï¼ä»¥å LLM è¨ç·´æéçå¤§éè¨æ¶é«åéç®éæ±ï¼å°è´è¨æ¶é«éå¶åè¨æ¶é«ä¸è¶³é¯èª¤ï¼å æ­¤éç¨®çå¿½é æäºææ°ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº RedWhaleï¼éæ¯ä¸åå°éçºéèªèçéèº«æé çæ¨¡åãRedWhale æ¯ä½¿ç¨ä¸ç¨®æææçºé è¨ç·´æ¹æ³éç¼çï¼å¶ä¸­åæ¬ä¸åå¨é¢çéèªèªæåº«é èçç®¡éãä¸åå°ç¨åè©å¨ãä¸åæä½³åçæ¨¡ååå§åæè¡åä¸åå¤éæ®µé è¨ç·´ç­ç¥ãéäºåµæ°å±åæ¸å°äºè¨ç·´æéåéç®ææ¬ï¼åæä¿æé«æºç¢ºåº¦åçè§£åãééå©ç¨è·¨èªè¨é·ç§»å­¸ç¿ï¼å©ç¨èªè¨ä¹éå±æçèªè¨ç¸ä¼¼æ§ï¼RedWhale å»ºç«å¨è±èªæ¨¡åä¸ï¼ä»¥å¢å¼·éèªèçãå¯¦é©çµæè­æï¼RedWhale å¨éèª NLP åºæºä¸åªæ¼å¶ä»é åæ¨¡åï¼åæ¬éèªéè¦ä»»åçå¹³è¡¡è©ä¼° (KoBEST)ï¼é¡¯ç¤ºåºå°éèªææ¬çåè¶çè§£åçæè½åãæ­¤å¤ï¼å³ä½¿å¨å° 97 ååç¬¦èé²è¡é è¨ç·´å¾ï¼RedWhale ä»æªé¡¯ç¤ºåºæ¶æçè·¡è±¡ï¼éè¡¨æééé¡å¤è¨ç·´æé²ä¸æ­¥æ¹é²çæ½åãéé å·¥ä½ä»£è¡¨äºç¸®å°èªè¨é´»æºçéå¤§é²å±ï¼ç¹å¥æ¯å¨å¢å¼·éèªç NLP è½åæ¹é¢ã

##### **Applying and Evaluating Large Language Models in Mental Health Care: A Scoping Review of Human-Assessed Generative Tasks**
2408.11288v1 by Yining Hua, Hongbin Na, Zehan Li, Fenglin Liu, Xiao Fang, David Clifton, John Torous

Large language models (LLMs) are emerging as promising tools for mental
health care, offering scalable support through their ability to generate
human-like responses. However, the effectiveness of these models in clinical
settings remains unclear. This scoping review aimed to assess the current
generative applications of LLMs in mental health care, focusing on studies
where these models were tested with human participants in real-world scenarios.
A systematic search across APA PsycNet, Scopus, PubMed, and Web of Science
identified 726 unique articles, of which 17 met the inclusion criteria. These
studies encompassed applications such as clinical assistance, counseling,
therapy, and emotional support. However, the evaluation methods were often
non-standardized, with most studies relying on ad hoc scales that limit
comparability and robustness. Privacy, safety, and fairness were also
frequently underexplored. Moreover, reliance on proprietary models, such as
OpenAI's GPT series, raises concerns about transparency and reproducibility.
While LLMs show potential in expanding mental health care access, especially in
underserved areas, the current evidence does not fully support their use as
standalone interventions. More rigorous, standardized evaluations and ethical
oversight are needed to ensure these tools can be safely and effectively
integrated into clinical practice.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£ä½çºå¿çä¿å¥çå·¥å·æµ®ç¾ï¼ééç¢çé¡äººçåææä¾å¯æ´åçæ¯æãç¶èï¼éäºæ¨¡åå¨è¨åºç°å¢ä¸­çæææ§ä»ä¸æç¢ºãæ¬ç¯åæ¢è¨æ¨å¨è©ä¼° LLM å¨å¿çä¿å¥ä¸­çç¾æçææç¨ï¼éé»å¨æ¼å¨çå¯¦ä¸çæå¢ä¸­ä»¥äººé¡åèèæ¸¬è©¦éäºæ¨¡åçç ç©¶ãç³»çµ±æ§æå° APA PsycNetãScopusãPubMed å Web of Science æ¾åº 726 ç¯ç¨ç¹æç« ï¼å¶ä¸­ 17 ç¯ç¬¦åç´å¥æ¨æºãéäºç ç©¶æ¶µèè¨åºåå©ãè«®è©¢ãæ²»çåæç·æ¯æç­æç¨ãç¶èï¼è©ä¼°æ¹æ³éå¸¸æªæ¨æºåï¼å¤§å¤æ¸ç ç©¶ä¾è³´æ¼éå¶å¯æ¯è¼æ§åç©©å¥æ§çè¨æéè¡¨ãé±ç§ãå®å¨åå¬å¹³æ§ä¹ç¶å¸¸æªååæ¢è¨ãæ­¤å¤ï¼ä¾è³´æ¼å°ææ¨¡åï¼ä¾å¦ OpenAI ç GPT ç³»åï¼æå¼ç¼å°éæåº¦åå¯è¤è£½æ§ççæ®ãéç¶ LLM å¨æ´å±å¿çä¿å¥æåæ¹é¢å±ç¾æ½åï¼ç¹å¥æ¯å¨æåä¸è¶³çå°åï¼ä½ç®åçè­æä¸¦ä¸å®å¨æ¯æå°å¶ç¨ä½ç¨ç«å¹²é æªæ½ãéè¦æ´å´è¬¹ãæ¨æºåçè©ä¼°åå«çç£ç£ï¼ä»¥ç¢ºä¿éäºå·¥å·è½å®å¨ä¸ææå°æ´åå°è¨åºå¯¦åä¸­ã

##### **Inference Plans for Hybrid Particle Filtering**
2408.11283v1 by Ellie Y. Cheng, Eric Atkinson, Guillaume Baudart, Louis Mandel, Michael Carbin

Advanced probabilistic programming languages (PPLs) use hybrid inference
systems to combine symbolic exact inference and Monte Carlo methods to improve
inference performance. These systems use heuristics to partition random
variables within the program into variables that are encoded symbolically and
variables that are encoded with sampled values, and the heuristics are not
necessarily aligned with the performance evaluation metrics used by the
developer. In this work, we present inference plans, a programming interface
that enables developers to control the partitioning of random variables during
hybrid particle filtering. We further present Siren, a new PPL that enables
developers to use annotations to specify inference plans the inference system
must implement. To assist developers with statically reasoning about whether an
inference plan can be implemented, we present an abstract-interpretation-based
static analysis for Siren for determining inference plan satisfiability. We
prove the analysis is sound with respect to Siren's semantics. Our evaluation
applies inference plans to three different hybrid particle filtering algorithms
on a suite of benchmarks and shows that the control provided by inference plans
enables speed ups of 1.76x on average and up to 206x to reach target accuracy,
compared to the inference plans implemented by default heuristics; the results
also show that inference plans improve accuracy by 1.83x on average and up to
595x with less or equal runtime, compared to the default inference plans. We
further show that the static analysis is precise in practice, identifying all
satisfiable inference plans in 27 out of the 33 benchmark-algorithm
combinations.

æè¦ï¼é²éæ©çç¨å¼èªè¨ (PPL) ä½¿ç¨æ··åæ¨è«ç³»çµ±ï¼çµåç¬¦èç²¾ç¢ºæ¨è«èèå°å¡ç¾æ¹æ³ï¼ä»¥æ¹åæ¨è«æè½ãéäºç³»çµ±ä½¿ç¨åç¼å¼æ¹æ³ï¼å°ç¨å¼ä¸­çé¨æ©è®æ¸åå²æä»¥ç¬¦èç·¨ç¢¼çè®æ¸åä»¥æ¡æ¨£å¼ç·¨ç¢¼çè®æ¸ï¼èåç¼å¼æ¹æ³ä¸ä¸å®èéç¼äººå¡ä½¿ç¨çæè½è©ä¼°ææ¨ç¸ç¬¦ãå¨éé å·¥ä½ä¸­ï¼æåæåºæ¨è«è¨ç«ï¼éæ¯ä¸åç¨å¼ä»é¢ï¼è®éç¼äººå¡è½å¤ å¨æ··åç²å­æ¿¾æ³¢æéæ§å¶é¨æ©è®æ¸çåå²ãæåé²ä¸æ­¥æåº Sirenï¼éæ¯ä¸åæ°ç PPLï¼è®éç¼äººå¡è½å¤ ä½¿ç¨è¨»è§£ä¾æå®æ¨è«ç³»çµ±å¿é å·è¡çæ¨è«è¨ç«ãçºäºåå©éç¼äººå¡éææ¨çæ¨è«è¨ç«æ¯å¦å¯å·è¡ï¼æåæåºä¸ååºæ¼æ½è±¡è©®éç Siren éæåæï¼ç¨æ¼ç¢ºå®æ¨è«è¨ç«çå¯æ»¿è¶³æ§ãæåè­ææ­¤åæå°æ¼ Siren çèªææ¯å¥å¨çãæåçè©ä¼°å°æ¨è«è¨ç«å¥ç¨æ¼ä¸åä¸åçæ··åç²å­æ¿¾æ³¢æ¼ç®æ³ï¼éå°ä¸çµåºæºé²è¡è©ä¼°ï¼ä¸¦é¡¯ç¤ºèé è¨­åç¼å¼æ¹æ³å·è¡çæ¨è«è¨ç«ç¸æ¯ï¼æ¨è«è¨ç«æä¾çæ§å¶å¹³åè½å é 1.76 åï¼æé«å¯é 206 åä»¥éå°ç®æ¨æºç¢ºåº¦ï¼çµæä¹é¡¯ç¤ºï¼èé è¨­æ¨è«è¨ç«ç¸æ¯ï¼æ¨è«è¨ç«å¹³åè½æ¹å 1.83 åçæºç¢ºåº¦ï¼æé«å¯é 595 åï¼ä¸å·è¡æéè¼ç­æç¸ç­ãæåé²ä¸æ­¥é¡¯ç¤ºï¼å¨å¯¦åä¸ï¼éæåææ¯ç²¾ç¢ºçï¼å¨ 33 ååºæºæ¼ç®æ³çµåä¸­ï¼æ¾åºææå¯æ»¿è¶³çæ¨è«è¨ç«ï¼å±æ 27 åã

##### **BearLLM: A Prior Knowledge-Enhanced Bearing Health Management Framework with Unified Vibration Signal Representation**
2408.11281v1 by Haotian Peng, Jiawei Liu, Jinsong Du, Jie Gao, Wei Wang

We propose a bearing health management framework leveraging large language
models (BearLLM), a novel multimodal model that unifies multiple
bearing-related tasks by processing user prompts and vibration signals.
Specifically, we introduce a prior knowledge-enhanced unified vibration signal
representation to handle various working conditions across multiple datasets.
This involves adaptively sampling the vibration signals based on the sampling
rate of the sensor, incorporating the frequency domain to unify input
dimensions, and using a fault-free reference signal as an auxiliary input. To
extract features from vibration signals, we first train a fault classification
network, then convert and align the extracted features into word embedding, and
finally concatenate these with text embedding as input to an LLM. To evaluate
the performance of the proposed method, we constructed the first large-scale
multimodal bearing health management (MBHM) dataset, including paired vibration
signals and textual descriptions. With our unified vibration signal
representation, BearLLM using one set of pre-trained weights achieves
state-of-the-art performance on nine publicly available fault diagnosis
benchmarks, outperforming specific methods designed for individual datasets. We
provide a dataset, our model, and code to inspire future research on building
more capable industrial multimodal models
(https://github.com/hatton613/BearLLM).

æè¦ï¼æåæåºä¸åè»¸æ¿å¥åº·ç®¡çæ¶æ§ï¼å©ç¨å¤§åèªè¨æ¨¡å (BearLLM)ï¼éæ¯ä¸åæ°ç©çå¤æ¨¡ææ¨¡åï¼å®ééèçä½¿ç¨èæç¤ºåæ¯åè¨èï¼çµ±ä¸å¤åèè»¸æ¿ç¸éçä»»åãå·é«ä¾èªªï¼æåå¼å¥ä¸ååé©ç¥è­å¢å¼·ççµ±ä¸æ¯åè¨èè¡¨ç¤ºï¼ä»¥èçå¤åè³æéä¸­çåç¨®å·¥ä½æ¢ä»¶ãéåå«æ ¹æææ¸¬å¨çåæ¨£çèªé©æåæ¨£æ¯åè¨èãçµåé »çåä»¥çµ±ä¸è¼¸å¥ç¶­åº¦ï¼ä»¥åä½¿ç¨ç¡æéåèè¨èä½çºè¼å©è¼¸å¥ãçºäºå¾æ¯åè¨èä¸­æåç¹å¾µï¼æåé¦åè¨ç·´ä¸åæéåé¡ç¶²è·¯ï¼ç¶å¾å°æåçç¹å¾µè½æä¸¦å°é½å°å­è©åµå¥ä¸­ï¼æå¾å°éäºç¹å¾µèæå­åµå¥ä¸²æ¥ä½çº LLM çè¼¸å¥ãçºäºè©ä¼°ææåºæ¹æ³çæè½ï¼æåå»ºæ§äºç¬¬ä¸åå¤§åå¤æ¨¡æè»¸æ¿å¥åº·ç®¡ç (MBHM) è³æéï¼å¶ä¸­åæ¬éå°çæ¯åè¨èåæå­æè¿°ãééæåççµ±ä¸æ¯åè¨èè¡¨ç¤ºï¼ä½¿ç¨ä¸çµé è¨ç·´æ¬éç BearLLM å¨ä¹åå¬éå¯ç¨çæéè¨ºæ·åºæºæ¸¬è©¦ä¸­éææåé²çæè½ï¼åªæ¼å°éçºåå¥è³æéè¨­è¨çç¹å®æ¹æ³ãæåæä¾ä¸åè³æéãæåçæ¨¡ååç¨å¼ç¢¼ï¼ä»¥æ¿åµæªä¾å¨å»ºæ§æ´å¼·å¤§çç¢æ¥­å¤æ¨¡ææ¨¡åæ¹é¢çç ç©¶ (https://github.com/hatton613/BearLLM)ã

##### **Towards Analyzing and Mitigating Sycophancy in Large Vision-Language Models**
2408.11261v1 by Yunpu Zhao, Rui Zhang, Junbin Xiao, Changxin Ke, Ruibo Hou, Yifan Hao, Qi Guo, Yunji Chen

Large Vision-Language Models (LVLMs) have shown significant capability in
vision-language understanding. However, one critical issue that persists in
these models is sycophancy, which means models are unduly influenced by leading
or deceptive prompts, resulting in biased outputs and hallucinations. Despite
the progress in LVLMs, evaluating and mitigating sycophancy is yet much
under-explored. In this work, we fill this gap by systematically analyzing
sycophancy on various VL benchmarks with curated leading queries and further
proposing a text contrastive decoding method for mitigation. While the specific
sycophantic behavior varies significantly among models, our analysis reveals
the severe deficiency of all LVLMs in resilience of sycophancy across various
tasks. For improvement, we propose Leading Query Contrastive Decoding (LQCD), a
model-agnostic method focusing on calibrating the LVLMs' over-reliance on
leading cues by identifying and suppressing the probabilities of sycophancy
tokens at the decoding stage. Extensive experiments show that LQCD effectively
mitigate sycophancy, outperforming both prompt engineering methods and common
methods for hallucination mitigation. We further demonstrate that LQCD does not
hurt but even slightly improves LVLMs' responses to neutral queries, suggesting
it being a more effective strategy for general-purpose decoding but not limited
to sycophancy.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å¨è¦è¦ºèªè¨çè§£æ¹é¢å±ç¾åºé¡¯èçè½åãç¶èï¼éäºæ¨¡åä¸­æçºå­å¨çä¸åééµåé¡æ¯é¿è«å¥æ¿ï¼éè¡¨ç¤ºæ¨¡ååå°å¼å°æå·èª¤å°æ§çæç¤ºéåº¦å½±é¿ï¼å°è´æåå·®çè¼¸åºåå¹»è¦ºãåç®¡ LVLMs ææé²å±ï¼ä½è©ä¼°åæ¸è¼é¿è«å¥æ¿ç¾è±¡çç ç©¶ä»ååä¸è¶³ãå¨éé å·¥ä½ä¸­ï¼æåééç³»çµ±æ§åæåç¨® VL åºæºä¸çé¿è«å¥æ¿ç¾è±¡ï¼ä½¿ç¨ç­å±çå¼å°å¼æ¥è©¢ï¼ï¼ä¸¦é²ä¸æ­¥æåºç¨æ¼ç·©è§£çæå­å°æ¯è§£ç¢¼æ¹æ³ä¾å¡«è£éé ç©ºç½ãéç¶å·é«çé¿è«å¥æ¿è¡çºå¨ä¸åæ¨¡åéå·®ç°å¾å¤§ï¼ä½æåçåææ­é²äºææ LVLMs å¨åç¨®ä»»åä¸­æµæé¿è«å¥æ¿ç¾è±¡çå´éä¸è¶³ãçºäºæ¹é²ï¼æåæåºå¼å°å¼æ¥è©¢å°æ¯è§£ç¢¼ (LQCD)ï¼éæ¯ä¸ç¨®èæ¨¡åç¡éçæ¹æ³ï¼å°æ³¨æ¼æ ¡æº LVLMs å°å¼å°ç·ç´¢éåº¦ä¾è³´ï¼æ¹æ³æ¯å¨è§£ç¢¼éæ®µè­å¥ä¸¦æå¶é¿è«å¥æ¿è©å½çæ©çãå»£æ³çå¯¦é©é¡¯ç¤ºï¼LQCD æææ¸è¼é¿è«å¥æ¿ç¾è±¡ï¼åªæ¼æç¤ºå·¥ç¨æ¹æ³åå¸¸è¦çå¹»è¦ºæ¸è¼æ¹æ³ãæåé²ä¸æ­¥è­æï¼LQCD ä¸ææå®³ LVLMs å°ä¸­ç«æ¥è©¢çåæï¼çè³æç¥å¾®æ¹åï¼éè¡¨ç¤ºå®æ¯ä¸ç¨®æ´ææçéç¨è§£ç¢¼ç­ç¥ï¼èä¸åéæ¼é¿è«å¥æ¿ç¾è±¡ã

##### **Improving Speech Recognition Error Prediction for Modern and Off-the-shelf Speech Recognizers**
2408.11258v1 by Prashant Serai, Peidong Wang, Eric Fosler-Lussier

Modeling the errors of a speech recognizer can help simulate errorful
recognized speech data from plain text, which has proven useful for tasks like
discriminative language modeling, improving robustness of NLP systems, where
limited or even no audio data is available at train time. Previous work
typically considered replicating behavior of GMM-HMM based systems, but the
behavior of more modern posterior-based neural network acoustic models is not
the same and requires adjustments to the error prediction model. In this work,
we extend a prior phonetic confusion based model for predicting speech
recognition errors in two ways: first, we introduce a sampling-based paradigm
that better simulates the behavior of a posterior-based acoustic model. Second,
we investigate replacing the confusion matrix with a sequence-to-sequence model
in order to introduce context dependency into the prediction. We evaluate the
error predictors in two ways: first by predicting the errors made by a
Switchboard ASR system on unseen data (Fisher), and then using that same
predictor to estimate the behavior of an unrelated cloud-based ASR system on a
novel task. Sampling greatly improves predictive accuracy within a 100-guess
paradigm, while the sequence model performs similarly to the confusion matrix.

æè¦ï¼èªé³è¾¨è­å¨çé¯èª¤å»ºæ¨¡æå©æ¼æ¨¡æ¬ç´æå­ä¸­é¯èª¤çè¾¨è­èªé³è³æï¼éå·²è­æå°ä»¥ä¸ä»»åæå¹«å©ï¼ä¾å¦è¾¨å¥èªè¨å»ºæ¨¡ãæ¹å NLP ç³»çµ±çç©©å¥æ§ï¼å¶ä¸­å¨è¨ç·´æéæ²æé³è¨è³ææçè³æ²æé³è¨è³æãååçç ç©¶éå¸¸èéè¤è£½åºæ¼ GMM-HMM çç³»çµ±è¡çºï¼ä½æ´ç¾ä»£çåºæ¼å¾é©çç¥ç¶ç¶²è·¯è²å­¸æ¨¡åçè¡çºä¸¦ä¸ç¸åï¼éè¦èª¿æ´é¯èª¤é æ¸¬æ¨¡åãå¨éé ç ç©¶ä¸­ï¼æåä»¥å©ç¨®æ¹å¼æ´åäºååçåºæ¼é³æ¨æ··æ·çæ¨¡åï¼ä»¥é æ¸¬èªé³è¾¨è­é¯èª¤ï¼é¦åï¼æåå¼é²ä¸ååºæ¼æ½æ¨£çç¯ä¾ï¼è½æ´å¥½å°æ¨¡æ¬åºæ¼å¾é©çè²å­¸æ¨¡åçè¡çºãå¶æ¬¡ï¼æåç ç©¶ç¨åºåå°åºåæ¨¡ååä»£æ··æ·ç©é£ï¼ä»¥ä¾¿å¨é æ¸¬ä¸­å¼é²ä¸ä¸æä¾è³´æ§ãæåä»¥å©ç¨®æ¹å¼è©ä¼°é¯èª¤é æ¸¬å¨ï¼é¦åï¼é æ¸¬ Switchboard ASR ç³»çµ±å¨æªè¦è³æï¼Fisherï¼ä¸ç¢ççé¯èª¤ï¼ç¶å¾ä½¿ç¨ç¸åçé æ¸¬å¨ä¾ä¼°è¨ä¸ç¸éçé²ç«¯ ASR ç³»çµ±å¨æ°çä»»åä¸çè¡çºãå¨ 100 æ¬¡çæ¸¬çç¯ä¾ä¸­ï¼æ½æ¨£å¤§å¹æ¹åäºé æ¸¬æºç¢ºåº¦ï¼èåºåæ¨¡åçè¡¨ç¾èæ··æ·ç©é£é¡ä¼¼ã

##### **Automatic Image Annotation (AIA) of AlmondNet-20 Method for Almond Detection by Improved CNN-based Model**
2408.11253v1 by Mohsen Asghari Ilani, Saba Moftakhar Tehran, Ashkan Kavei, Arian Radmehr

In response to the burgeoning global demand for premium agricultural
products, particularly within the competitive nut market, this paper introduces
an innovative methodology aimed at enhancing the grading process for almonds
and their shells. Leveraging state-of-the-art Deep Convolutional Neural
Networks (CNNs), specifically the AlmondNet-20 architecture, our study achieves
exceptional accuracy exceeding 99%, facilitated by the utilization of a
20-layer CNN model. To bolster robustness in differentiating between almonds
and shells, data augmentation techniques are employed, ensuring the reliability
and accuracy of our classification system. Our model, meticulously trained over
1000 epochs, demonstrates remarkable performance, boasting an accuracy rate of
99% alongside a minimal loss function of 0.0567. Rigorous evaluation through
test datasets further validates the efficacy of our approach, revealing
impeccable precision, recall, and F1-score metrics for almond detection. Beyond
its technical prowess, this advanced classification system offers tangible
benefits to both industry experts and non-specialists alike, ensuring globally
reliable almond classification. The application of deep learning algorithms, as
showcased in our study, not only enhances grading accuracy but also presents
opportunities for product patents, thereby contributing to the economic value
of our nation. Through the adoption of cutting-edge technologies such as the
AlmondNet-20 model, we pave the way for future advancements in agricultural
product classification, ultimately enriching global trade and economic
prosperity.

æè¦ï¼çºåæå¨çå°åªè³ªè¾²æ¥­ç¢åæ¥çå¢é·çé¾å¤§éæ±ï¼ç¹å¥æ¯å¨ç«¶ç­æ¿ççå æå¸å ´ä¸­ï¼æ¬æä»ç´¹äºä¸ç¨®åµæ°æ¹æ³ï¼æ¨å¨å å¼·æä»åå¶æ®¼çåé¡éç¨ãå©ç¨æåé²çæ·±åº¦å·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼ç¹å¥æ¯ AlmondNet-20 æ¶æ§ï¼æåçç ç©¶éå°äºæ¥µé«çæºç¢ºåº¦ï¼è¶é 99%ï¼éæ­¸åæ¼å©ç¨ 20 å±¤ CNN æ¨¡åãçºäºå å¼·ååæä»åæ®¼çç©©å¥æ§ï¼æ¡ç¨äºæ¸ææ´åæè¡ï¼ç¢ºä¿äºæååé¡ç³»çµ±çå¯é æ§åæºç¢ºæ§ãæåçæ¨¡åç¶é 1000 åä¸ä»£çç´°å¿è¨ç·´ï¼è¡¨ç¾éå¡ï¼æºç¢ºçéå° 99%ï¼åææå¤±å½æ¸ä½è³ 0.0567ãééæ¸¬è©¦è³æéé²è¡çå´æ ¼è©ä¼°é²ä¸æ­¥é©è­äºæåæ¹æ³çæææ§ï¼æ­ç¤ºäºæä»æª¢æ¸¬çå®ç¾ç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ææ¨ãé¤äºæè¡åªå¢å¤ï¼éç¨®åé²çåé¡ç³»çµ±éçºç¢æ¥­å°å®¶åéå°å®¶æä¾äºåå¯¦çå¥½èï¼ç¢ºä¿å¨çæä»åé¡çå¯é æ§ãå¦æåç ç©¶ä¸­å±ç¤ºçé£æ¨£ï¼æ·±åº¦å­¸ç¿æ¼ç®æ³çæç¨ä¸åæé«äºåç´çæºç¢ºåº¦ï¼éæä¾äºç¢åå°å©çæ©æï¼å¾èçºæååå®¶çç¶æ¿å¹å¼ååºäºè²¢ç»ãééæ¡ç¨ AlmondNet-20 æ¨¡åç­å°ç«¯æè¡ï¼æåçºæªä¾è¾²æ¥­ç¢ååé¡çé²æ­¥éªå¹³äºéè·¯ï¼æçµè±å¯äºå¨çè²¿æåç¶æ¿ç¹æ¦®ã

##### **Counterfactuals As a Means for Evaluating Faithfulness of Attribution Methods in Autoregressive Language Models**
2408.11252v1 by Sepehr Kamahi, Yadollah Yaghoobzadeh

Despite the widespread adoption of autoregressive language models,
explainability evaluation research has predominantly focused on span infilling
and masked language models (MLMs). Evaluating the faithfulness of an
explanation method -- how accurately the method explains the inner workings and
decision-making of the model -- is very challenging because it is very hard to
separate the model from its explanation. Most faithfulness evaluation
techniques corrupt or remove some input tokens considered important according
to a particular attribution (feature importance) method and observe the change
in the model's output. This approach creates out-of-distribution inputs for
causal language models (CLMs) due to their training objective of next token
prediction. In this study, we propose a technique that leverages counterfactual
generation to evaluate the faithfulness of attribution methods for
autoregressive language modeling scenarios. Our technique creates fluent and
in-distribution counterfactuals that makes evaluation protocol more reliable.
Code is available at https://github.com/Sepehr-Kamahi/faith

æè¦ï¼åç®¡èªè¿´æ­¸èªè¨æ¨¡åè¢«å»£æ³æ¡ç¨ï¼
å¯è§£éæ§è©ä¼°ç ç©¶ä¸»è¦éä¸­å¨è·¨åº¦å¡«è£
åé®è½èªè¨æ¨¡å (MLM)ãè©ä¼°è§£éæ¹æ³çå¿ å¯¦åº¦
ââæ¹æ³å¤æºç¢ºå°è§£éæ¨¡åçå§é¨éä½å
æ±ºç­å¶å®ââæ¥µå·ææ°æ§ï¼å çºå¾é£
å°æ¨¡åèå¶è§£éåéãå¤§å¤æ¸å¿ å¯¦åº¦è©ä¼°
æè¡ææå£æç§»é¤ä¸äºè¼¸å¥ä»£ç¢¼ï¼éäºä»£ç¢¼è¢«èªçºå¾éè¦ï¼å·é«åæ±ºæ¼
ç¹å®æ­¸å ï¼ç¹å¾µéè¦æ§ï¼æ¹æ³ï¼ä¸¦è§å¯æ¨¡å
è¼¸åºçè®åãç±æ¼ä¸ä¸åä»£ç¢¼é æ¸¬çè¨ç·´ç®æ¨ï¼éç¨®æ¹æ³æçº
å æèªè¨æ¨¡å (CLM) å»ºç«åºåå¸çè¼¸å¥ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®å©ç¨åäºå¯¦
çæä¾è©ä¼°èªè¿´æ­¸èªè¨å»ºæ¨¡å ´æ¯çæ­¸å æ¹æ³çå¿ å¯¦åº¦çæè¡ãæåçæè¡å»ºç«æµæ¢ä¸
å¨åå¸ä¸­çåäºå¯¦ï¼ä½¿è©ä¼°åå®æ´å¯é ã
ç¨å¼ç¢¼å¯å¨ https://github.com/Sepehr-Kamahi/faith åå¾

##### **The Dilemma of Uncertainty Estimation for General Purpose AI in the EU AI Act**
2408.11249v1 by Matias Valdenegro-Toro, Radina Stoykova

The AI act is the European Union-wide regulation of AI systems. It includes
specific provisions for general-purpose AI models which however need to be
further interpreted in terms of technical standards and state-of-art studies to
ensure practical compliance solutions. This paper examines the AI act
requirements for providers and deployers of general-purpose AI and further
proposes uncertainty estimation as a suitable measure for legal compliance and
quality assurance in training of such models. We argue that uncertainty
estimation should be a required component for deploying models in the real
world, and under the EU AI Act, it could fulfill several requirements for
transparency, accuracy, and trustworthiness. However, generally using
uncertainty estimation methods increases the amount of computation, producing a
dilemma, as computation might go over the threshold ($10^{25}$ FLOPS) to
classify the model as a systemic risk system which bears more regulatory
burden.

æè¦ï¼ãäººå·¥æºæ§æ³ãæ¯æ­çéå°äººå·¥æºæ§ç³»çµ±çè¦ç¯ãå¶ä¸­åå«éç¨äººå·¥æºæ§æ¨¡åçå·é«æ¢æ¬¾ï¼ä½ä»éè¦é²ä¸æ­¥ééæè¡æ¨æºåç¾æç ç©¶é²è¡è©®éï¼ä»¥ç¢ºä¿å¯¦åä¸åè¦çè§£æ±ºæ¹æ¡ãæ¬ææ¢è¨ãäººå·¥æºæ§æ³ãå°éç¨äººå·¥æºæ§çä¾æååé¨ç½²èçè¦æ±ï¼ä¸¦é²ä¸æ­¥æåºä¸ç¢ºå®æ§ä¼°è¨ä½çºè¨ç·´æ­¤é¡æ¨¡åçæ³å¾åè¦æ§ååè³ªä¿è­çé©ç¶æªæ½ãæåä¸»å¼µä¸ç¢ºå®æ§ä¼°è¨æçºå¨ç¾å¯¦ä¸çä¸­é¨ç½²æ¨¡åçå¿è¦çµæé¨åï¼ä¸æ ¹ææ­çãäººå·¥æºæ§æ³ãï¼å®å¯ä»¥æ»¿è¶³éæåº¦ãæºç¢ºæ§åå¯ä¿¡è³´æ§çå¤é è¦æ±ãç¶èï¼ä¸è¬èè¨ï¼ä½¿ç¨ä¸ç¢ºå®æ§ä¼°è¨æ¹æ³æå¢å éç®éï¼é æå©é£ï¼å çºéç®éå¯è½æè¶ééæª»ï¼$10^{25}$ FLOPSï¼ï¼å°æ¨¡ååé¡çºæ¿ææ´å¤æ³è¦è² æçç³»çµ±æ§é¢¨éªç³»çµ±ã

##### **Unboxing Occupational Bias: Grounded Debiasing LLMs with U.S. Labor Data**
2408.11247v1 by Atmika Gorti, Manas Gaur, Aman Chadha

Large Language Models (LLMs) are prone to inheriting and amplifying societal
biases embedded within their training data, potentially reinforcing harmful
stereotypes related to gender, occupation, and other sensitive categories. This
issue becomes particularly problematic as biased LLMs can have far-reaching
consequences, leading to unfair practices and exacerbating social inequalities
across various domains, such as recruitment, online content moderation, or even
the criminal justice system. Although prior research has focused on detecting
bias in LLMs using specialized datasets designed to highlight intrinsic biases,
there has been a notable lack of investigation into how these findings
correlate with authoritative datasets, such as those from the U.S. National
Bureau of Labor Statistics (NBLS). To address this gap, we conduct empirical
research that evaluates LLMs in a ``bias-out-of-the-box" setting, analyzing how
the generated outputs compare with the distributions found in NBLS data.
Furthermore, we propose a straightforward yet effective debiasing mechanism
that directly incorporates NBLS instances to mitigate bias within LLMs. Our
study spans seven different LLMs, including instructable, base, and
mixture-of-expert models, and reveals significant levels of bias that are often
overlooked by existing bias detection techniques. Importantly, our debiasing
method, which does not rely on external datasets, demonstrates a substantial
reduction in bias scores, highlighting the efficacy of our approach in creating
fairer and more reliable LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å®¹æç¹¼æ¿åæ¾å¤§å¶è¨ç·´è³æä¸­å§åµçç¤¾æåè¦ï¼æ½å¨å¼·åèæ§å¥ãè·æ¥­åå¶ä»ææé¡å¥ç¸éçæå®³å»æ¿å°è±¡ãéååé¡è®å¾ç¹å¥æåé¡ï¼å çºæåè¦ç LLM å¯è½æç¢çæ·±é çå¾æï¼å°è´ä¸å¬å¹³çè¡çºï¼ä¸¦å ååç¨®é åçç¤¾æä¸å¹³ç­ï¼ä¾å¦æèãç·ä¸å§å®¹å¯©æ ¸ï¼çè³æ¯åäºå¸æ³ç³»çµ±ãåç®¡ååçç ç©¶å°æ³¨æ¼ä½¿ç¨å°éè¨­è¨ä¾å¼·èª¿å§å¨åè¦çè³æéä¾åµæ¸¬ LLM ä¸­çåè¦ï¼ä½å°æ¼éäºç¼ç¾å¦ä½èæ¬å¨è³æéç¸éè¯çç ç©¶å»æé¡¯ä¸è¶³ï¼ä¾å¦ä¾èªç¾ååå®¶åå·¥çµ±è¨å± (NBLS) çè³æéãçºäºè§£æ±ºéåå·®è·ï¼æåé²è¡å¯¦è­ç ç©¶ä¾è©ä¼° LLM å¨ãåè¦éç®±å³ç¨ãçè¨­å®ä¸­ï¼åæç¢ççè¼¸åºèå¨ NBLS è³æä¸­ç¼ç¾çåéå¦ä½æ¯è¼ãæ­¤å¤ï¼æåæåºä¸åç°¡å®ä½ææçå»åæ©å¶ï¼ç´æ¥ç´å¥ NBLS å¯¦ä¾ä»¥æ¸è¼ LLM ä¸­çåè¦ãæåçç ç©¶æ¶µèä¸ç¨®ä¸åç LLMï¼åæ¬å¯æå°ãåºç¤åå°å®¶æ··åæ¨¡åï¼ä¸¦æ­ç¤ºåºå¤§éåè¦ï¼éäºåè¦éå¸¸è¢«ç¾æçåè¦åµæ¸¬æè¡æå¿½ç¥ãéè¦çæ¯ï¼æåçå»åæ¹æ³ä¸ä¾è³´æ¼å¤é¨è³æéï¼è­æäºåè¦è©åé¡¯èéä½ï¼çªé¡¯äºæåçæ¹æ³å¨åµé æ´å¬å¹³ãæ´å¯é ç LLM ä¸­çæåã

##### **Do Neural Scaling Laws Exist on Graph Self-Supervised Learning?**
2408.11243v1 by Qian Ma, Haitao Mao, Jingzhe Liu, Zhehua Zhang, Chunlin Feng, Yu Song, Yihan Shao, Tianfan Fu, Yao Ma

Self-supervised learning~(SSL) is essential to obtain foundation models in
NLP and CV domains via effectively leveraging knowledge in large-scale
unlabeled data. The reason for its success is that a suitable SSL design can
help the model to follow the neural scaling law, i.e., the performance
consistently improves with increasing model and dataset sizes. However, it
remains a mystery whether existing SSL in the graph domain can follow the
scaling behavior toward building Graph Foundation Models~(GFMs) with
large-scale pre-training. In this study, we examine whether existing graph SSL
techniques can follow the neural scaling behavior with the potential to serve
as the essential component for GFMs. Our benchmark includes comprehensive SSL
technique implementations with analysis conducted on both the conventional SSL
setting and many new settings adopted in other domains. Surprisingly, despite
the SSL loss continuously decreasing, no existing graph SSL techniques follow
the neural scaling behavior on the downstream performance. The model
performance only merely fluctuates on different data scales and model scales.
Instead of the scales, the key factors influencing the performance are the
choices of model architecture and pretext task design. This paper examines
existing SSL techniques for the feasibility of Graph SSL techniques in
developing GFMs and opens a new direction for graph SSL design with the new
evaluation prototype. Our code implementation is available online to ease
reproducibility on https://github.com/GraphSSLScaling/GraphSSLScaling.

æè¦ï¼èªç£ç£å­¸ç¿ (SSL) å°æ¼ééææå©ç¨å¤§è¦æ¨¡æªæ¨è¨è³æä¸­çç¥è­ä¾åå¾ NLP å CV é åä¸­çåºç¤æ¨¡åè³ééè¦ãå®æåççç±å¨æ¼ï¼é©ç¶ç SSL è¨­è¨å¯ä»¥å¹«å©æ¨¡åéµå¾ªç¥ç¶æ´åå®å¾ï¼äº¦å³æè½æé¨èæ¨¡ååè³æéå¤§å°çå¢å èæçºæåãç¶èï¼ç¾æçåå½¢é å SSL æ¯å¦è½éµå¾ªæ´åè¡çºï¼æèå»ºæ§å·åå¤§è¦æ¨¡é è¨ç·´çåå½¢åºç¤æ¨¡å (GFM) éé²ï¼ä»ç¶æ¯åè¬ãå¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦ç¾æçåå½¢ SSL æè¡æ¯å¦è½éµå¾ªç¥ç¶æ´åè¡çºï¼ä¸¦å·åä½çº GFM åºæ¬åä»¶çæ½åãæåçåºæºåå«å¨é¢ç SSL æè¡å¯¦ä½ï¼ä¸¦å°å³çµ± SSL è¨­å®åæ¡ç¨å¶ä»é åçè¨±å¤æ°è¨­å®é²è¡åæãä»¤äººé©è¨çæ¯ï¼åç®¡ SSL æå¤±æçºä¸éï¼ä½æ²æç¾æçåå½¢ SSL æè¡å¨ä¸æ¸¸æè½ä¸éµå¾ªç¥ç¶æ´åè¡çºãæ¨¡åæè½åå¨ä¸åçè³æè¦æ¨¡åæ¨¡åè¦æ¨¡ä¸æ³¢åãå½±é¿æè½çééµå ç´ ä¸æ¯è¦æ¨¡ï¼èæ¯æ¨¡åæ¶æ§åé è¨­ä»»åè¨­è¨çé¸æãæ¬ææª¢è¦ç¾æç SSL æè¡ï¼æ¢è¨åå½¢ SSL æè¡å¨éç¼ GFM ä¸­çå¯è¡æ§ï¼ä¸¦ééæ°çè©ä¼°ååçºåå½¢ SSL è¨­è¨éåæ°çæ¹åãæåçç¨å¼ç¢¼å¯¦ä½å¯ä»¥å¨ç·ä¸åå¾ï¼ä»¥ç°¡åå¨ https://github.com/GraphSSLScaling/GraphSSLScaling ä¸çéç¾æ§ã

##### **A Little Confidence Goes a Long Way**
2408.11239v1 by John Scoville, Shang Gao, Devanshu Agrawal, Javed Qadrud-Din

We introduce a group of related methods for binary classification tasks using
probes of the hidden state activations in large language models (LLMs).
Performance is on par with the largest and most advanced LLMs currently
available, but requiring orders of magnitude fewer computational resources and
not requiring labeled data. This approach involves translating class labels
into a semantically rich description, spontaneous symmetry breaking of
multilayer perceptron probes for unsupervised learning and inference, training
probes to generate confidence scores (prior probabilities) from hidden state
activations subject to known constraints via entropy maximization, and
selecting the most confident probe model from an ensemble for prediction. These
techniques are evaluated on four datasets using five base LLMs.

æè¦ï¼æåä»ç´¹äºä¸çµç¸éæ¹æ³ï¼ç¨æ¼äºååé¡ä»»åï¼ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä¸­é±èçææ¿æ´»çæ¢éã
æè½èç®åæå¤§çæåé² LLM ç¸ç¶ï¼ä½éè¦çè¨ç®è³æºå°äºå¥½å¹¾åæ¸éç´ï¼èä¸ä¸éè¦æ¨è¨è³æãæ­¤æ¹æ³åæ¬å°é¡å¥æ¨ç±¤è½æçºèªæè±å¯çæè¿°ãå¤å±¤æç¥å¨æ¢éçèªç¼å°ç¨±æ§ç ´å£ï¼ç¨æ¼ç¡ç£ç£å­¸ç¿åæ¨è«ãè¨ç·´æ¢éä»¥å¾é±èçææ¿æ´»ä¸­ç¢çä¿¡å¿åæ¸ï¼åé©æ©çï¼ï¼åå¶æ¼ééçµæå¤§åèå¾ç¥çç´æï¼ä»¥åå¾ä¸åæ´é«ä¸­é¸åºæå·ä¿¡å¿çæ¢éæ¨¡åä»¥é²è¡é æ¸¬ãéäºæè¡ä½¿ç¨äºååºç¤ LLM å¨ååè³æéä¸é²è¡è©ä¼°ã

##### **Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification**
2408.11237v1 by Christos Constantinou, Georgios Ioannides, Aman Chadha, Aaron Elkins, Edwin Simpson

Detecting out-of-distribution (OOD) data is crucial in machine learning
applications to mitigate the risk of model overconfidence, thereby enhancing
the reliability and safety of deployed systems. The majority of existing OOD
detection methods predominantly address uni-modal inputs, such as images or
texts. In the context of multi-modal documents, there is a notable lack of
extensive research on the performance of these methods, which have primarily
been developed with a focus on computer vision tasks. We propose a novel
methodology termed as attention head masking (AHM) for multi-modal OOD tasks in
document classification systems. Our empirical results demonstrate that the
proposed AHM method outperforms all state-of-the-art approaches and
significantly decreases the false positive rate (FPR) compared to existing
solutions up to 7.5\%. This methodology generalizes well to multi-modal data,
such as documents, where visual and textual information are modeled under the
same Transformer architecture. To address the scarcity of high-quality publicly
available document datasets and encourage further research on OOD detection for
documents, we introduce FinanceDocs, a new document AI dataset. Our code and
dataset are publicly available.

æè¦ï¼<paragraph>åµæ¸¬ç°å¸¸è³æ (OOD) å¨æ©å¨å­¸ç¿æç¨ä¸­è³ééè¦ï¼å¯éä½æ¨¡åéåº¦èªä¿¡çé¢¨éªï¼é²èæåå·²é¨ç½²ç³»çµ±çå¯é æ§åå®å¨æ§ãç¾æç OOD åµæ¸¬æ¹æ³å¤§å¤ä»¥å®æ¨¡æè¼¸å¥çºä¸»ï¼ä¾å¦å½±åææå­ãå¨å¤æ¨¡ææä»¶èçµ¡ä¸­ï¼å°æ¼éäºæ¹æ³çæè½ç¼ºä¹å»£æ³çç ç©¶ï¼èéäºæ¹æ³ä¸»è¦éå°é»è¦è¦è¦ºä»»åèéç¼ãæåæåºç¨±çºæ³¨æåå±¤é®ç½© (AHM) çåµæ°æ¹æ³ï¼ç¨æ¼æä»¶åé¡ç³»çµ±ä¸­çå¤æ¨¡æ OOD ä»»åãæåçå¯¦è­çµæé¡¯ç¤ºï¼ææåºç AHM æ¹æ³åªæ¼ææç¾ææè¡ï¼èç¾æè§£æ±ºæ¹æ¡ç¸æ¯ï¼å°èª¤å ±ç (FPR) å¤§å¹éä½é 7.5%ãæ­¤æ¹æ³è½å¾å¥½å°æ¦æ¬å°å¤æ¨¡æè³æï¼ä¾å¦æä»¶ï¼å¶ä¸­è¦è¦ºåæå­è³è¨å¨ç¸åç Transformer æ¶æ§ä¸å»ºæ¨¡ãçºäºè§£æ±ºé«åè³ªå¬éæä»¶è³æéçç¨å°æ§ï¼ä¸¦é¼åµé²ä¸æ­¥ç ç©¶æä»¶ç OOD åµæ¸¬ï¼æåå¼å¥äº FinanceDocsï¼ä¸åæ°çæä»¶ AI è³æéãæåçç¨å¼ç¢¼åè³æéå·²å¬éã</paragraph>

##### **Unified Deep Learning Model for Global Prediction of Aboveground Biomass, Canopy Height and Cover from High-Resolution, Multi-Sensor Satellite Imagery**
2408.11234v1 by Manuel Weber, Carly Beneke, Clyde Wheeler

Regular measurement of carbon stock in the world's forests is critical for
carbon accounting and reporting under national and international climate
initiatives, and for scientific research, but has been largely limited in
scalability and temporal resolution due to a lack of ground based assessments.
Increasing efforts have been made to address these challenges by incorporating
remotely sensed data. We present a new methodology which uses multi-sensor,
multi-spectral imagery at a resolution of 10 meters and a deep learning based
model which unifies the prediction of above ground biomass density (AGBD),
canopy height (CH), canopy cover (CC) as well as uncertainty estimations for
all three quantities. The model is trained on millions of globally sampled
GEDI-L2/L4 measurements. We validate the capability of our model by deploying
it over the entire globe for the year 2023 as well as annually from 2016 to
2023 over selected areas. The model achieves a mean absolute error for AGBD
(CH, CC) of 26.1 Mg/ha (3.7 m, 9.9 %) and a root mean squared error of 50.6
Mg/ha (5.4 m, 15.8 %) on a globally sampled test dataset, demonstrating a
significant improvement over previously published results. We also report the
model performance against independently collected ground measurements published
in the literature, which show a high degree of correlation across varying
conditions. We further show that our pre-trained model facilitates seamless
transferability to other GEDI variables due to its multi-head architecture.

æè¦ï¼<paragraph>å®ææµéå¨çæ£®æçç¢³å²éå°æ¼åå®¶ååéæ°£åè¨ç«ä¸çç¢³è¨éåå ±åï¼ä»¥åç§å­¸ç ç©¶è³ééè¦ï¼ä½ç±æ¼ç¼ºä¹å°é¢è©ä¼°ï¼å¨å¯æ´å±æ§åæéè§£æåº¦æ¹é¢åå°å¾å¤§éå¶ãå·²æ¡åè¶ä¾è¶å¤æªæ½ï¼ééæ´åéæ¸¬è³æä¾æå°éäºææ°ãæåæåºäºä¸ç¨®æ°çæ¹æ³ï¼å®ä½¿ç¨è§£æåº¦çº 10 å¬å°ºçå¤ææ¸¬å¨ãå¤åè­å½±åï¼ä»¥åä¸åæ·±åº¦å­¸ç¿æ¨¡åï¼è©²æ¨¡åçµ±ä¸äºå°ä¸çç©éå¯åº¦ (AGBD)ãæ¨¹å é«åº¦ (CH)ãæ¨¹å è¦è (CC) çé æ¸¬ï¼ä»¥åææä¸ç¨®æ¸éçèª¤å·®ä¼°è¨ãè©²æ¨¡åä»¥æ¸ç¾è¬åå¨çåæ¨£ç GEDI-L2/L4 æ¸¬éå¼é²è¡è¨ç·´ãæåééå¨ 2023 å¹´ä»¥å 2016 å¹´è³ 2023 å¹´éæ¯å¹´å¨é¸å®ååé¨ç½²æåçæ¨¡åä¾é©è­å¶è½åãè©²æ¨¡åå° AGBD (CHãCC) çå¹³åçµå°èª¤å·®çº 26.1 Mg/ha (3.7 mï¼9.9%)ï¼åæ¹æ ¹èª¤å·®çº 50.6 Mg/ha (5.4 mï¼15.8%) å¨å¨çåæ¨£çæ¸¬è©¦è³æéä¸ï¼é¡¯ç¤ºåºæ¯ååç¼å¸ççµææäºé¡¯èçæ¹é²ãæåéæ ¹ææç»ä¸­ç¼å¸çç¨ç«æ¶éçå°é¢æ¸¬éå¼å ±åäºæ¨¡åæè½ï¼éäºæ¸¬éå¼é¡¯ç¤ºåºå¨ä¸åæ¢ä»¶ä¸é«åº¦ç¸éãæåé²ä¸æ­¥è¡¨æï¼ç±æ¼æåçé è¨ç·´æ¨¡åçå¤é ­æ¶æ§ï¼å®ä¿é²äºåå¶ä» GEDI è®æ¸çç¡ç¸«é·ç§»ã</paragraph>

##### **OCTCube: A 3D foundation model for optical coherence tomography that improves cross-dataset, cross-disease, cross-device and cross-modality analysis**
2408.11227v1 by Zixuan Liu, Hanwen Xu, Addie Woicik, Linda G. Shapiro, Marian Blazes, Yue Wu, Cecilia S. Lee, Aaron Y. Lee, Sheng Wang

Optical coherence tomography (OCT) has become critical for diagnosing retinal
diseases as it enables 3D images of the retina and optic nerve. OCT acquisition
is fast, non-invasive, affordable, and scalable. Due to its broad
applicability, massive numbers of OCT images have been accumulated in routine
exams, making it possible to train large-scale foundation models that can
generalize to various diagnostic tasks using OCT images. Nevertheless, existing
foundation models for OCT only consider 2D image slices, overlooking the rich
3D structure. Here, we present OCTCube, a 3D foundation model pre-trained on
26,605 3D OCT volumes encompassing 1.62 million 2D OCT images. OCTCube is
developed based on 3D masked autoencoders and exploits FlashAttention to reduce
the larger GPU memory usage caused by modeling 3D volumes. OCTCube outperforms
2D models when predicting 8 retinal diseases in both inductive and
cross-dataset settings, indicating that utilizing the 3D structure in the model
instead of 2D data results in significant improvement. OCTCube further shows
superior performance on cross-device prediction and when predicting systemic
diseases, such as diabetes and hypertension, further demonstrating its strong
generalizability. Finally, we propose a
contrastive-self-supervised-learning-based OCT-IR pre-training framework (COIP)
for cross-modality analysis on OCT and infrared retinal (IR) images, where the
OCT volumes are embedded using OCTCube. We demonstrate that COIP enables
accurate alignment between OCT and IR en face images. Collectively, OCTCube, a
3D OCT foundation model, demonstrates significantly better performance against
2D models on 27 out of 29 tasks and comparable performance on the other two
tasks, paving the way for AI-based retinal disease diagnosis.

æè¦ï¼åå­¸ç¸å¹²æ·å±¤ææ (OCT) å·²æçºè¨ºæ·è¦ç¶²èç¾ççéè¦å·¥å·ï¼å çºå®å¯ä»¥æä¾è¦ç¶²èåè¦ç¥ç¶ç 3D å½±åãOCT ç²åå¿«éãéä¾µå¥æ§ãè² æå¾èµ·ä¸å¯æ´åãç±æ¼å¶å»£æ³çé©ç¨æ§ï¼å¤§é OCT å½±åå·²å¨ä¾è¡æª¢æ¥ä¸­ç´¯ç©ï¼ä½¿å¾è¨ç·´å¤§ååºç¤æ¨¡åæçºå¯è½ï¼éäºæ¨¡åå¯ä»¥ä½¿ç¨ OCT å½±åæ¨å»£å°åç¨®è¨ºæ·ä»»åãåç®¡å¦æ­¤ï¼ç¾æç OCT åºç¤æ¨¡ååªèæ® 2D å½±ååçï¼å¿½ç¥äºè±å¯ç 3D çµæ§ãå¨æ­¤ï¼æåæåº OCTCubeï¼éæ¯ä¸å 3D åºç¤æ¨¡åï¼é åè¨ç·´æ¼ 26,605 å 3D OCT é«ç©ï¼åå« 162 è¬å 2D OCT å½±åãOCTCube æ¯åºæ¼ 3D èçèªåç·¨ç¢¼å¨éç¼çï¼ä¸¦å©ç¨ FlashAttention ä¾æ¸å°å»ºæ¨¡ 3D é«ç©æé æçè¼å¤§ GPU è¨æ¶é«ä½¿ç¨éãOCTCube å¨é æ¸¬ 8 ç¨®è¦ç¶²èç¾çæåªæ¼ 2D æ¨¡åï¼ç¡è«æ¯å¨æ­¸ç´å¼éæ¯è·¨è³æéè¨­å®ä¸­ï¼éè¡¨ç¤ºå¨æ¨¡åä¸­ä½¿ç¨ 3D çµæ§ï¼èä¸æ¯ 2D è³æï¼æå¸¶ä¾é¡¯èçæ¹é²ãOCTCube å¨è·¨è£ç½®é æ¸¬åé æ¸¬å¨èº«æ§ç¾çï¼ä¾å¦ç³å°¿çåé«è¡å£ï¼æé²ä¸æ­¥å±ç¾åºåªç°çæè½ï¼é²ä¸æ­¥è­æäºå¶å¼·å¤§çæ³åè½åãæå¾ï¼æåæåºä¸ååºæ¼å°æ¯èªç£ç£å­¸ç¿ç OCT-IR é è¨ç·´æ¶æ§ (COIP)ï¼ç¨æ¼ OCT åç´å¤ç·è¦ç¶²è (IR) å½±åçè·¨æ¨¡æåæï¼å¶ä¸­ OCT é«ç©ä½¿ç¨ OCTCube åµå¥ãæåè­æ COIP è½å¤ å¨ OCT å IR æ­£é¢å½±åä¹éé²è¡æºç¢ºçå°é½ãç¸½çä¾èªªï¼OCTCube æ¯ä¸å 3D OCT åºç¤æ¨¡åï¼å¨ 29 é ä»»åä¸­ç 27 é ä»»åä¸­å±ç¾åºæé¡¯åªæ¼ 2D æ¨¡åçæè½ï¼èå¨å¶ä»å©é ä»»åä¸­å±ç¾åºç¸ç¶çæè½ï¼çºåºæ¼ AI çè¦ç¶²èç¾çè¨ºæ·éªè·¯ã

