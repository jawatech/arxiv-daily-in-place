{"2410.07819": {"publish_time": "2024-10-10", "title": "Uncovering Overfitting in Large Language Model Editing", "paper_summary": "Knowledge editing has been proposed as an effective method for updating and\ncorrecting the internal knowledge of Large Language Models (LLMs). However,\nexisting editing methods often struggle with complex tasks, such as multi-hop\nreasoning. In this paper, we identify and investigate the phenomenon of Editing\nOverfit, where edited models assign disproportionately high probabilities to\nthe edit target, hindering the generalization of new knowledge in complex\nscenarios. We attribute this issue to the current editing paradigm, which\nplaces excessive emphasis on the direct correspondence between the input prompt\nand the edit target for each edit sample. To further explore this issue, we\nintroduce a new benchmark, EVOKE (EValuation of Editing Overfit in Knowledge\nEditing), along with fine-grained evaluation metrics. Through comprehensive\nexperiments and analysis, we demonstrate that Editing Overfit is prevalent in\ncurrent editing methods and that common overfitting mitigation strategies are\nof limited effectiveness in knowledge editing. To overcome this, inspired by\nLLMs' knowledge recall mechanisms, we propose a new plug-and-play strategy\ncalled Learn to Inference (LTI), which introduce a Multi-stage Inference\nConstraint module to guide the edited models in recalling new knowledge\nsimilarly to how unedited LLMs leverage knowledge through in-context learning.\nExtensive experimental results across a wide range of tasks validate the\neffectiveness of LTI in mitigating Editing Overfit.", "paper_summary_zh": "\u77e5\u8b58\u7de8\u8f2f\u5df2\u88ab\u63d0\u8b70\u70ba\u66f4\u65b0\u548c\u4fee\u6b63\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5167\u90e8\u77e5\u8b58\u7684\u6709\u6548\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u7de8\u8f2f\u65b9\u6cd5\u901a\u5e38\u96e3\u4ee5\u8655\u7406\u8907\u96dc\u7684\u4efb\u52d9\uff0c\u4f8b\u5982\u591a\u8df3\u63a8\u7406\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u627e\u51fa\u4e26\u7814\u7a76\u7de8\u8f2f\u904e\u5ea6\u64ec\u5408\u7684\u73fe\u8c61\uff0c\u5176\u4e2d\u5df2\u7de8\u8f2f\u6a21\u578b\u6703\u5c07\u4e0d\u6210\u6bd4\u4f8b\u7684\u9ad8\u6a5f\u7387\u5206\u914d\u7d66\u7de8\u8f2f\u76ee\u6a19\uff0c\u963b\u7919\u8907\u96dc\u5834\u666f\u4e2d\u65b0\u77e5\u8b58\u7684\u6982\u5316\u3002\u6211\u5011\u5c07\u6b64\u554f\u984c\u6b78\u56e0\u65bc\u76ee\u524d\u7684\u7de8\u8f2f\u7bc4\u4f8b\uff0c\u8a72\u7bc4\u4f8b\u904e\u5ea6\u5f37\u8abf\u8f38\u5165\u63d0\u793a\u548c\u6bcf\u500b\u7de8\u8f2f\u7bc4\u4f8b\u7684\u7de8\u8f2f\u76ee\u6a19\u4e4b\u9593\u7684\u76f4\u63a5\u5c0d\u61c9\u95dc\u4fc2\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u63a2\u8a0e\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u7684\u57fa\u6e96 EVOKE\uff08\u77e5\u8b58\u7de8\u8f2f\u4e2d\u7de8\u8f2f\u904e\u5ea6\u64ec\u5408\u7684\u8a55\u4f30\uff09\uff0c\u4ee5\u53ca\u7d30\u7c92\u5ea6\u7684\u8a55\u4f30\u6307\u6a19\u3002\u900f\u904e\u5168\u9762\u7684\u5be6\u9a57\u548c\u5206\u6790\uff0c\u6211\u5011\u8b49\u660e\u7de8\u8f2f\u904e\u5ea6\u64ec\u5408\u5728\u76ee\u524d\u7684\u7de8\u8f2f\u65b9\u6cd5\u4e2d\u5f88\u666e\u904d\uff0c\u800c\u5e38\u898b\u7684\u904e\u5ea6\u64ec\u5408\u7de9\u89e3\u7b56\u7565\u5728\u77e5\u8b58\u7de8\u8f2f\u4e2d\u7684\u6548\u679c\u6709\u9650\u3002\u70ba\u4e86\u514b\u670d\u9019\u500b\u554f\u984c\uff0c\u53d7\u5230 LLM \u77e5\u8b58\u56de\u6eaf\u6a5f\u5236\u7684\u555f\u767c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u5373\u63d2\u5373\u7528\u7b56\u7565\uff0c\u7a31\u70ba\u5b78\u7fd2\u63a8\u8ad6 (LTI)\uff0c\u5b83\u5f15\u5165\u4e86\u4e00\u500b\u591a\u968e\u6bb5\u63a8\u8ad6\u7d04\u675f\u6a21\u7d44\uff0c\u4ee5\u5f15\u5c0e\u5df2\u7de8\u8f2f\u7684\u6a21\u578b\u56de\u6eaf\u65b0\u77e5\u8b58\uff0c\u985e\u4f3c\u65bc\u672a\u7de8\u8f2f\u7684 LLM \u5982\u4f55\u900f\u904e\u60c5\u5883\u5b78\u7fd2\u4f86\u5229\u7528\u77e5\u8b58\u3002\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u7d50\u679c\u9a57\u8b49\u4e86 LTI \u5728\u7de9\u89e3\u7de8\u8f2f\u904e\u5ea6\u64ec\u5408\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "author": "Mengqi Zhang et.al.", "authors": "Mengqi Zhang, Xiaotian Ye, Qiang Liu, Pengjie Ren, Shu Wu, Zhumin Chen", "id": "2410.07819v1", "paper_url": "http://arxiv.org/abs/2410.07819v1", "repo": "null"}}