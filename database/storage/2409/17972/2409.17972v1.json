{"2409.17972": {"publish_time": "2024-09-26", "title": "BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search", "paper_summary": "Large Language Models (LLMs) have exhibited exceptional performance across a\nbroad range of tasks and domains. However, they still encounter difficulties in\nsolving mathematical problems due to the rigorous and logical nature of\nmathematics. Previous studies have employed techniques such as supervised\nfine-tuning (SFT), prompt engineering, and search-based methods to improve the\nmathematical problem-solving abilities of LLMs. Despite these efforts, their\nperformance remains suboptimal and demands substantial computational resources.\nTo address this issue, we propose a novel approach, BEATS, to enhance\nmathematical problem-solving abilities. Our method leverages newly designed\nprompts that guide the model to iteratively rewrite, advance by one step, and\ngenerate answers based on previous steps. Additionally, we introduce a new\nback-verification technique that uses LLMs to validate the correctness of the\ngenerated answers. Furthermore, we employ a pruning tree search to optimize\nsearch time while achieving strong performance. Notably, our method improves\nQwen2-7b-Instruct's score from 36.94 to 61.52, outperforming GPT4's 42.5 on the\nMATH benchmark.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5ee3\u6cdb\u7684\u4efb\u52d9\u548c\u9818\u57df\u4e2d\u5c55\u73fe\u51fa\u5353\u8d8a\u7684\u6548\u80fd\u3002\u7136\u800c\uff0c\u7531\u65bc\u6578\u5b78\u7684\u56b4\u8b39\u6027\u548c\u908f\u8f2f\u6027\uff0c\u5b83\u5011\u5728\u89e3\u6c7a\u6578\u5b78\u554f\u984c\u6642\u4ecd\u6703\u9047\u5230\u56f0\u96e3\u3002\u5148\u524d\u7684\u7814\u7a76\u63a1\u7528\u4e86\u76e3\u7763\u5fae\u8abf (SFT)\u3001\u63d0\u793a\u5de5\u7a0b\u548c\u57fa\u65bc\u641c\u5c0b\u7684\u65b9\u6cd5\u7b49\u6280\u8853\u4f86\u63d0\u5347 LLM \u7684\u6578\u5b78\u554f\u984c\u89e3\u6c7a\u80fd\u529b\u3002\u5118\u7ba1\u4ed8\u51fa\u4e86\u9019\u4e9b\u52aa\u529b\uff0c\u5b83\u5011\u7684\u6548\u80fd\u4ecd\u7136\u672a\u9054\u6700\u4f73\uff0c\u4e14\u9700\u8981\u5927\u91cf\u7684\u904b\u7b97\u8cc7\u6e90\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u65b9\u6cd5 BEATS \u4f86\u589e\u5f37\u6578\u5b78\u554f\u984c\u89e3\u6c7a\u80fd\u529b\u3002\u6211\u5011\u7684\u9019\u7a2e\u65b9\u6cd5\u5229\u7528\u65b0\u8a2d\u8a08\u7684\u63d0\u793a\uff0c\u5f15\u5c0e\u6a21\u578b\u53cd\u8986\u91cd\u5beb\u3001\u63a8\u9032\u4e00\u6b65\uff0c\u4e26\u6839\u64da\u5148\u524d\u7684\u6b65\u9a5f\u7522\u751f\u7b54\u6848\u3002\u6b64\u5916\uff0c\u6211\u5011\u9084\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u7684\u5f8c\u9a57\u8b49\u6280\u8853\uff0c\u5b83\u4f7f\u7528 LLM \u4f86\u9a57\u8b49\u6240\u7522\u751f\u7b54\u6848\u7684\u6b63\u78ba\u6027\u3002\u800c\u4e14\uff0c\u6211\u5011\u63a1\u7528\u526a\u679d\u6a39\u641c\u5c0b\u4f86\u6700\u4f73\u5316\u641c\u5c0b\u6642\u9593\uff0c\u540c\u6642\u9054\u6210\u5f37\u5927\u7684\u6548\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u7684\u9019\u7a2e\u65b9\u6cd5\u5c07 Qwen2-7b-Instruct \u7684\u5206\u6578\u5f9e 36.94 \u63d0\u5347\u5230 61.52\uff0c\u5728 MATH \u57fa\u6e96\u4e0a\u512a\u65bc GPT4 \u7684 42.5\u3002", "author": "Linzhuang Sun et.al.", "authors": "Linzhuang Sun, Hao Liang, Wentao Zhang", "id": "2409.17972v1", "paper_url": "http://arxiv.org/abs/2409.17972v1", "repo": "null"}}