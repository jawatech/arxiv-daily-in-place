{"2501.12106": {"publish_time": "2025-01-21", "title": "Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes", "paper_summary": "Tumor documentation in Germany is largely done manually, requiring reading\npatient records and entering data into structured databases. Large language\nmodels (LLMs) could potentially enhance this process by improving efficiency\nand reliability. This evaluation tests eleven different open source LLMs with\nsizes ranging from 1-70 billion model parameters on three basic tasks of the\ntumor documentation process: identifying tumor diagnoses, assigning ICD-10\ncodes, and extracting the date of first diagnosis. For evaluating the LLMs on\nthese tasks, a dataset of annotated text snippets based on anonymized doctors'\nnotes from urology was prepared. Different prompting strategies were used to\ninvestigate the effect of the number of examples in few-shot prompting and to\nexplore the capabilities of the LLMs in general. The models Llama 3.1 8B,\nMistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.\nModels with less extensive training data or having fewer than 7 billion\nparameters showed notably lower performance, while larger models did not\ndisplay performance gains. Examples from a different medical domain than\nurology could also improve the outcome in few-shot prompting, which\ndemonstrates the ability of LLMs to handle tasks needed for tumor\ndocumentation. Open source LLMs show a strong potential for automating tumor\ndocumentation. Models from 7-12 billion parameters could offer an optimal\nbalance between performance and resource efficiency. With tailored fine-tuning\nand well-designed prompting, these models might become important tools for\nclinical documentation in the future. The code for the evaluation is available\nfrom https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset\nas a new valuable resource that addresses the shortage of authentic and easily\naccessible benchmarks in German-language medical NLP.", "paper_summary_zh": "\u5fb7\u570b\u7684\u816b\u7624\u6587\u4ef6\u8a18\u9304\u5927\u90e8\u5206\u662f\u624b\u52d5\u5b8c\u6210\uff0c\u9700\u8981\u95b1\u8b80\u75c5\u6b77\u4e26\u5c07\u8cc7\u6599\u8f38\u5165\u7d50\u69cb\u5316\u7684\u8cc7\u6599\u5eab\u4e2d\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u53ef\u80fd\u900f\u904e\u63d0\u5347\u6548\u7387\u548c\u53ef\u9760\u6027\u4f86\u589e\u5f37\u6b64\u7a0b\u5e8f\u3002\u6b64\u8a55\u91cf\u6e2c\u8a66\u4e86 11 \u500b\u4e0d\u540c\u7684\u958b\u6e90 LLM\uff0c\u6a21\u578b\u53c3\u6578\u5927\u5c0f\u5f9e 10 \u5104\u5230 700 \u5104\u4e0d\u7b49\uff0c\u91dd\u5c0d\u816b\u7624\u6587\u4ef6\u8a18\u9304\u7a0b\u5e8f\u7684\u4e09\u9805\u57fa\u672c\u4efb\u52d9\uff1a\u8b58\u5225\u816b\u7624\u8a3a\u65b7\u3001\u6307\u5b9a ICD-10 \u4ee3\u78bc\uff0c\u4ee5\u53ca\u64f7\u53d6\u9996\u6b21\u8a3a\u65b7\u65e5\u671f\u3002\u70ba\u4e86\u91dd\u5c0d\u9019\u4e9b\u4efb\u52d9\u8a55\u4f30 LLM\uff0c\u6e96\u5099\u4e86\u4e00\u500b\u57fa\u65bc\u6ccc\u5c3f\u79d1\u91ab\u751f\u533f\u540d\u7b46\u8a18\u7684\u8a3b\u89e3\u6587\u5b57\u7247\u6bb5\u8cc7\u6599\u96c6\u3002\u4f7f\u7528\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\u4f86\u8abf\u67e5\u5c11\u91cf\u63d0\u793a\u4e2d\u7bc4\u4f8b\u6578\u91cf\u7684\u5f71\u97ff\uff0c\u4e26\u63a2\u7d22 LLM \u7684\u4e00\u822c\u80fd\u529b\u3002Llama 3.1 8B\u3001Mistral 7B \u548c Mistral NeMo 12 B \u7b49\u6a21\u578b\u5728\u9019\u4e9b\u4efb\u52d9\u4e2d\u8868\u73fe\u76f8\u7576\u597d\u3002\u8a13\u7df4\u8cc7\u6599\u8f03\u5c11\u6216\u53c3\u6578\u5c11\u65bc 70 \u5104\u7684\u6a21\u578b\u8868\u73fe\u660e\u986f\u8f03\u5dee\uff0c\u800c\u8f03\u5927\u7684\u6a21\u578b\u4e26\u672a\u5c55\u73fe\u6548\u80fd\u63d0\u5347\u3002\u8207\u6ccc\u5c3f\u79d1\u4e0d\u540c\u7684\u91ab\u7642\u9818\u57df\u7684\u7bc4\u4f8b\u4e5f\u53ef\u4ee5\u6539\u5584\u5c11\u91cf\u63d0\u793a\u7684\u7d50\u679c\uff0c\u9019\u8b49\u660e\u4e86 LLM \u8655\u7406\u816b\u7624\u6587\u4ef6\u8a18\u9304\u6240\u9700\u4efb\u52d9\u7684\u80fd\u529b\u3002\u958b\u6e90 LLM \u5728\u81ea\u52d5\u5316\u816b\u7624\u6587\u4ef6\u8a18\u9304\u65b9\u9762\u986f\u793a\u51fa\u5f37\u5927\u7684\u6f5b\u529b\u3002\u53c3\u6578\u4ecb\u65bc 70 \u5104\u5230 120 \u5104\u7684\u6a21\u578b\u53ef\u4ee5\u5728\u6548\u80fd\u548c\u8cc7\u6e90\u6548\u7387\u4e4b\u9593\u63d0\u4f9b\u6700\u4f73\u5e73\u8861\u3002\u900f\u904e\u91cf\u8eab\u6253\u9020\u5fae\u8abf\u548c\u7cbe\u5fc3\u8a2d\u8a08\u7684\u63d0\u793a\uff0c\u9019\u4e9b\u6a21\u578b\u672a\u4f86\u53ef\u80fd\u6703\u6210\u70ba\u81e8\u5e8a\u6587\u4ef6\u8a18\u9304\u7684\u91cd\u8981\u5de5\u5177\u3002\u8a55\u4f30\u7a0b\u5f0f\u78bc\u53ef\u5f9e https://github.com/stefan-m-lenz/UroLlmEval \u53d6\u5f97\u3002\u6211\u5011\u4e5f\u91cb\u51fa\u8cc7\u6599\u96c6\u4f5c\u70ba\u4e00\u500b\u65b0\u7684\u6709\u50f9\u503c\u8cc7\u6e90\uff0c\u7528\u65bc\u89e3\u6c7a\u5fb7\u8a9e\u91ab\u7642\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4e2d\u771f\u5be6\u4e14\u6613\u65bc\u53d6\u5f97\u7684\u57fa\u6e96\u77ed\u7f3a\u554f\u984c\u3002", "author": "Stefan Lenz et.al.", "authors": "Stefan Lenz, Arsenij Ustjanzew, Marco Jeray, Torsten Panholzer", "id": "2501.12106v1", "paper_url": "http://arxiv.org/abs/2501.12106v1", "repo": "https://github.com/stefan-m-lenz/urollmeval"}}