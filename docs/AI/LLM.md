
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-05**|**MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and Reasoning**|Ziliang Gan et.al.|[2411.03314v1](http://arxiv.org/abs/2411.03314v1)|null|
|**2024-11-05**|**Inference Optimal VLMs Need Only One Visual Token but Larger Models**|Kevin Y. Li et.al.|[2411.03312v1](http://arxiv.org/abs/2411.03312v1)|[link](https://github.com/locuslab/llava-token-compression)|
|**2024-11-05**|**LLMs for Domain Generation Algorithm Detection**|Reynier Leyva La O et.al.|[2411.03307v1](http://arxiv.org/abs/2411.03307v1)|null|
|**2024-11-05**|**VERITAS: A Unified Approach to Reliability Evaluation**|Rajkumar Ramamurthy et.al.|[2411.03300v1](http://arxiv.org/abs/2411.03300v1)|null|
|**2024-11-05**|**Interaction2Code: How Far Are We From Automatic Interactive Webpage Generation?**|Jingyu Xiao et.al.|[2411.03292v1](http://arxiv.org/abs/2411.03292v1)|null|
|**2024-11-05**|**The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare**|Souren Pashangpour et.al.|[2411.03287v1](http://arxiv.org/abs/2411.03287v1)|null|
|**2024-11-05**|**SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents**|Dawei Li et.al.|[2411.03284v1](http://arxiv.org/abs/2411.03284v1)|[link](https://github.com/david-li0406/smoa)|
|**2024-11-05**|**Causal Responsibility Attribution for Human-AI Collaboration**|Yahang Qi et.al.|[2411.03275v1](http://arxiv.org/abs/2411.03275v1)|[link](https://github.com/yahang-qi/Causal-Attr-Human-AI)|
|**2024-11-05**|**Discovering Data Structures: Nearest Neighbor Search and Beyond**|Omar Salemohamed et.al.|[2411.03253v1](http://arxiv.org/abs/2411.03253v1)|null|
|**2024-11-05**|**Spontaneous Emergence of Agent Individuality through Social Interactions in LLM-Based Communities**|Ryosuke Takata et.al.|[2411.03252v1](http://arxiv.org/abs/2411.03252v1)|null|
|**2024-11-05**|**DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models**|Ying Zhou et.al.|[2411.03250v1](http://arxiv.org/abs/2411.03250v1)|null|
|**2024-11-05**|**On the Detection of Non-Cooperative RISs: Scan B-Testing via Deep Support Vector Data Description**|George Stamatelis et.al.|[2411.03237v1](http://arxiv.org/abs/2411.03237v1)|null|
|**2024-11-05**|**Formal Logic-guided Robust Federated Learning against Poisoning Attacks**|Dung Thuy Nguyen et.al.|[2411.03231v1](http://arxiv.org/abs/2411.03231v1)|null|
|**2024-11-05**|**Beyond Grid Data: Exploring Graph Neural Networks for Earth Observation**|Shan Zhao et.al.|[2411.03223v1](http://arxiv.org/abs/2411.03223v1)|null|
|**2024-11-05**|**GIS Copilot: Towards an Autonomous GIS Agent for Spatial Analysis**|Temitope Akinboyewa et.al.|[2411.03205v1](http://arxiv.org/abs/2411.03205v1)|null|
|**2024-11-05**|**On Improved Conditioning Mechanisms and Pre-training Strategies for Diffusion Models**|Tariq Berrada Ifriqi et.al.|[2411.03177v1](http://arxiv.org/abs/2411.03177v1)|null|
|**2024-11-05**|**Navigating Extremes: Dynamic Sparsity in Large Output Space**|Nasib Ullah et.al.|[2411.03171v1](http://arxiv.org/abs/2411.03171v1)|null|
|**2024-11-05**|**Evaluating Machine Learning Models against Clinical Protocols for Enhanced Interpretability and Continuity of Care**|Christel Sirocchi et.al.|[2411.03105v1](http://arxiv.org/abs/2411.03105v1)|[link](https://github.com/ChristelSirocchi/XAI-similarity)|
|**2024-11-05**|**Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation in a Limited Data Setting**|Adrian B. Chłopowiec et.al.|[2411.03098v1](http://arxiv.org/abs/2411.03098v1)|null|
|**2024-11-05**|**HFGaussian: Learning Generalizable Gaussian Human with Integrated Human Features**|Arnab Dey et.al.|[2411.03086v1](http://arxiv.org/abs/2411.03086v1)|null|
|**2024-11-05**|**Enhancing DP-SGD through Non-monotonous Adaptive Scaling Gradient Weight**|Tao Huang et.al.|[2411.03059v1](http://arxiv.org/abs/2411.03059v1)|null|
|**2024-11-05**|**ATM: Improving Model Merging by Alternating Tuning and Merging**|Luca Zhou et.al.|[2411.03055v1](http://arxiv.org/abs/2411.03055v1)|null|
|**2024-11-05**|**Gradient-Guided Conditional Diffusion Models for Private Image Reconstruction: Analyzing Adversarial Impacts of Differential Privacy and Denoising**|Tao Huang et.al.|[2411.03053v1](http://arxiv.org/abs/2411.03053v1)|null|
|**2024-11-05**|**Predictor-Corrector Enhanced Transformers with Exponential Moving Average Coefficient Learning**|Bei Li et.al.|[2411.03042v1](http://arxiv.org/abs/2411.03042v1)|null|
|**2024-11-05**|**Self-Compositional Data Augmentation for Scientific Keyphrase Generation**|Mael Houbre et.al.|[2411.03039v1](http://arxiv.org/abs/2411.03039v1)|null|
|**2024-11-05**|**HumanVLM: Foundation for Human-Scene Vision-Language Model**|Dawei Dai et.al.|[2411.03034v1](http://arxiv.org/abs/2411.03034v1)|null|
|**2024-11-05**|**DA-MoE: Addressing Depth-Sensitivity in Graph-Level Analysis through Mixture of Experts**|Zelin Yao et.al.|[2411.03025v1](http://arxiv.org/abs/2411.03025v1)|[link](https://github.com/celin-yao/da-moe)|
|**2024-11-05**|**Flashy Backdoor: Real-world Environment Backdoor Attack on SNNs with DVS Cameras**|Roberto Riaño et.al.|[2411.03022v1](http://arxiv.org/abs/2411.03022v1)|null|
|**2024-11-05**|**Leveraging Large Language Models in Code Question Answering: Baselines and Issues**|Georgy Andryushchenko et.al.|[2411.03012v1](http://arxiv.org/abs/2411.03012v1)|[link](https://github.com/iu-aes-ai4code/codequestionanswering)|
|**2024-11-05**|**Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status**|Samuel Lee et.al.|[2411.03004v1](http://arxiv.org/abs/2411.03004v1)|null|
|**2024-11-05**|**SUDS: A Strategy for Unsupervised Drift Sampling**|Christofer Fellicious et.al.|[2411.02995v1](http://arxiv.org/abs/2411.02995v1)|[link](https://github.com/cfellicious/suds)|
|**2024-11-05**|**Growing a Tail: Increasing Output Diversity in Large Language Models**|Michal Shur-Ofry et.al.|[2411.02989v1](http://arxiv.org/abs/2411.02989v1)|null|
|**2024-11-05**|**Confidence Calibration of Classifiers with Many Classes**|Adrien Le Coz et.al.|[2411.02988v1](http://arxiv.org/abs/2411.02988v1)|[link](https://github.com/allglc/tva-calibration)|
|**2024-11-05**|**Autonomous Decision Making for UAV Cooperative Pursuit-Evasion Game with Reinforcement Learning**|Yang Zhao et.al.|[2411.02983v1](http://arxiv.org/abs/2411.02983v1)|null|
|**2024-11-05**|**Region-Guided Attack on the Segment Anything Model (SAM)**|Xiaoliang Liu et.al.|[2411.02974v1](http://arxiv.org/abs/2411.02974v1)|null|
|**2024-11-05**|**[Vision Paper] PRObot: Enhancing Patient-Reported Outcome Measures for Diabetic Retinopathy using Chatbots and Generative AI**|Maren Pielka et.al.|[2411.02973v1](http://arxiv.org/abs/2411.02973v1)|null|
|**2024-11-05**|**Speaker Emotion Recognition: Leveraging Self-Supervised Models for Feature Extraction Using Wav2Vec2 and HuBERT**|Pourya Jafarzadeh et.al.|[2411.02964v1](http://arxiv.org/abs/2411.02964v1)|null|
|**2024-11-05**|**Grounding Natural Language to SQL Translation with Data-Based Self-Explanations**|Yuankai Fan et.al.|[2411.02948v1](http://arxiv.org/abs/2411.02948v1)|[link](https://github.com/Kaimary/CycleSQL)|
|**2024-11-05**|**Capturing research literature attitude towards Sustainable Development Goals: an LLM-based topic modeling approach**|Francesco Invernici et.al.|[2411.02943v1](http://arxiv.org/abs/2411.02943v1)|null|
|**2024-11-05**|**A Mamba Foundation Model for Time Series Forecasting**|Haoyu Ma et.al.|[2411.02941v1](http://arxiv.org/abs/2411.02941v1)|null|
|**2024-11-05**|**A Post-Training Enhanced Optimization Approach for Small Language Models**|Keke Zhai et.al.|[2411.02939v1](http://arxiv.org/abs/2411.02939v1)|null|
|**2024-11-05**|**Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA Dataset and Self-adaptive Planning Agent**|Yangning Li et.al.|[2411.02937v1](http://arxiv.org/abs/2411.02937v1)|null|
|**2024-11-05**|**Textual Aesthetics in Large Language Models**|Lingjie Jiang et.al.|[2411.02930v1](http://arxiv.org/abs/2411.02930v1)|[link](https://github.com/JackLingjie/Textual-Aesthetics)|
|**2024-11-05**|**Domain Expansion and Boundary Growth for Open-Set Single-Source Domain Generalization**|Pengkun Jiao et.al.|[2411.02920v1](http://arxiv.org/abs/2411.02920v1)|null|
|**2024-11-05**|**Exploring the Interplay Between Video Generation and World Models in Autonomous Driving: A Survey**|Ao Fu et.al.|[2411.02914v1](http://arxiv.org/abs/2411.02914v1)|null|
|**2024-11-05**|**Membership Inference Attacks against Large Vision-Language Models**|Zhan Li et.al.|[2411.02902v1](http://arxiv.org/abs/2411.02902v1)|[link](https://github.com/lions-epfl/vl-mia)|
|**2024-11-05**|**TokenSelect: Efficient Long-Context Inference and Length Extrapolation for LLMs via Dynamic Token-Level KV Cache Selection**|Wei Wu et.al.|[2411.02886v1](http://arxiv.org/abs/2411.02886v1)|null|
|**2024-11-05**|**Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**|Tao Zhang et.al.|[2411.02864v1](http://arxiv.org/abs/2411.02864v1)|null|
|**2024-11-05**|**Learning to Unify Audio, Visual and Text for Audio-Enhanced Multilingual Visual Answer Localization**|Zhibin Wen et.al.|[2411.02851v1](http://arxiv.org/abs/2411.02851v1)|null|
|**2024-11-05**|**WASHtsApp -- A RAG-powered WhatsApp Chatbot for supporting rural African clean water access, sanitation and hygiene**|Simon Kloker et.al.|[2411.02850v1](http://arxiv.org/abs/2411.02850v1)|null|
|**2024-11-05**|**Dissecting the Failure of Invariant Learning on Graphs**|Qixun Wang et.al.|[2411.02847v1](http://arxiv.org/abs/2411.02847v1)|[link](https://github.com/novaglow646/neurips24-invariant-learning-on-graphs)|
|**2024-11-05**|**Correlation of Object Detection Performance with Visual Saliency and Depth Estimation**|Matthias Bartolo et.al.|[2411.02844v1](http://arxiv.org/abs/2411.02844v1)|[link](https://github.com/mbar0075/object-detection-correlation-saliency-vs-depth)|
|**2024-11-05**|**PersianRAG: A Retrieval-Augmented Generation System for Persian Language**|Hossein Hosseini et.al.|[2411.02832v1](http://arxiv.org/abs/2411.02832v1)|null|
|**2024-11-05**|**Mixtures of In-Context Learners**|Giwon Hong et.al.|[2411.02830v1](http://arxiv.org/abs/2411.02830v1)|null|
|**2024-11-05**|**DroidSpeak: Enhancing Cross-LLM Communication**|Yuhan Liu et.al.|[2411.02820v1](http://arxiv.org/abs/2411.02820v1)|null|
|**2024-11-05**|**Conditional Vendi Score: An Information-Theoretic Approach to Diversity Evaluation of Prompt-based Generative Models**|Mohammad Jalali et.al.|[2411.02817v1](http://arxiv.org/abs/2411.02817v1)|[link](https://github.com/mjalali/conditional-vendi)|
|**2024-11-05**|**DeepContext: A Context-aware, Cross-platform, and Cross-framework Tool for Performance Profiling and Analysis of Deep Learning Workloads**|Qidong Zhao et.al.|[2411.02797v1](http://arxiv.org/abs/2411.02797v1)|null|
|**2024-11-05**|**Specialized Foundation Models Struggle to Beat Supervised Baselines**|Zongzhe Xu et.al.|[2411.02796v1](http://arxiv.org/abs/2411.02796v1)|[link](https://github.com/ritvikgupta199/DASHA)|
|**2024-11-05**|**The Evolution of RWKV: Advancements in Efficient Language Modeling**|Akul Datta et.al.|[2411.02795v1](http://arxiv.org/abs/2411.02795v1)|null|
|**2024-11-05**|**Toward Robust Incomplete Multimodal Sentiment Analysis via Hierarchical Representation Learning**|Mingcheng Li et.al.|[2411.02793v1](http://arxiv.org/abs/2411.02793v1)|null|
|**2024-11-05**|**Language Models and Cycle Consistency for Self-Reflective Machine Translation**|Jianqiao Wangni et.al.|[2411.02791v1](http://arxiv.org/abs/2411.02791v1)|null|
|**2024-11-05**|**Memory Augmented Cross-encoders for Controllable Personalized Search**|Sheshera Mysore et.al.|[2411.02790v1](http://arxiv.org/abs/2411.02790v1)|null|
|**2024-11-05**|**When to Localize? A Risk-Constrained Reinforcement Learning Approach**|Chak Lam Shek et.al.|[2411.02788v1](http://arxiv.org/abs/2411.02788v1)|null|
|**2024-11-05**|**Stochastic Monkeys at Play: Random Augmentations Cheaply Break LLM Safety Alignment**|Jason Vega et.al.|[2411.02785v1](http://arxiv.org/abs/2411.02785v1)|null|
|**2024-11-05**|**EcoCropsAID: Economic Crops Aerial Image Dataset for Land Use Classification**|Sangdaow Noppitak et.al.|[2411.02762v1](http://arxiv.org/abs/2411.02762v1)|null|
|**2024-11-05**|**A Bayesian explanation of machine learning models based on modes and functional ANOVA**|Quan Long et.al.|[2411.02746v1](http://arxiv.org/abs/2411.02746v1)|null|
|**2024-11-05**|**Novelty-focused R&D landscaping using transformer and local outlier factor**|Jaewoong Choi et.al.|[2411.02738v1](http://arxiv.org/abs/2411.02738v1)|null|
|**2024-11-05**|**A Natural Language Processing Approach to Support Biomedical Data Harmonization: Leveraging Large Language Models**|Zexu Li et.al.|[2411.02730v1](http://arxiv.org/abs/2411.02730v1)|null|
|**2024-11-05**|**Multimodal Commonsense Knowledge Distillation for Visual Question Answering**|Shuo Yang et.al.|[2411.02722v1](http://arxiv.org/abs/2411.02722v1)|null|
|**2024-11-05**|**Game Plot Design with an LLM-powered Assistant: An Empirical Study with Game Designers**|Seyed Hossein Alavi et.al.|[2411.02714v1](http://arxiv.org/abs/2411.02714v1)|[link](https://github.com/salavi/GamePlot-LLM-Assistant)|
|**2024-11-05**|**V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization**|Yuxi Xie et.al.|[2411.02712v1](http://arxiv.org/abs/2411.02712v1)|[link](https://github.com/yuxixie/v-dpo)|
|**2024-11-05**|**Exploring Response Uncertainty in MLLMs: An Empirical Evaluation under Misleading Scenarios**|Yunkai Dang et.al.|[2411.02708v1](http://arxiv.org/abs/2411.02708v1)|null|
|**2024-11-05**|**RT-Affordance: Affordances are Versatile Intermediate Representations for Robot Manipulation**|Soroush Nasiriany et.al.|[2411.02704v1](http://arxiv.org/abs/2411.02704v1)|null|
|**2024-11-05**|**JEL: Applying End-to-End Neural Entity Linking in JPMorgan Chase**|Wanying Ding et.al.|[2411.02695v1](http://arxiv.org/abs/2411.02695v1)|null|
|**2024-11-05**|**JPEC: A Novel Graph Neural Network for Competitor Retrieval in Financial Knowledge Graphs**|Wanying Ding et.al.|[2411.02692v1](http://arxiv.org/abs/2411.02692v1)|null|
|**2024-11-05**|**On the loss of context-awareness in general instruction fine-tuning**|Yihan Wang et.al.|[2411.02688v1](http://arxiv.org/abs/2411.02688v1)|[link](https://github.com/YihanWang617/context_awareness)|
|**2024-11-04**|**Geometry of naturalistic object representations in recurrent neural network models of working memory**|Xiaoxuan Lei et.al.|[2411.02685v1](http://arxiv.org/abs/2411.02685v1)|null|
|**2024-11-04**|**Wave Network: An Ultra-Small Language Model**|Xin Zhang et.al.|[2411.02674v1](http://arxiv.org/abs/2411.02674v1)|null|
|**2024-11-04**|**Fair In-Context Learning via Latent Concept Variables**|Karuna Bhaila et.al.|[2411.02671v1](http://arxiv.org/abs/2411.02671v1)|[link](https://github.com/karuna-bhaila/fairicl)|
|**2024-11-04**|**From Twitter to Reasoner: Understand Mobility Travel Modes and Sentiment Using Large Language Models**|Kangrui Ruan et.al.|[2411.02666v1](http://arxiv.org/abs/2411.02666v1)|null|
|**2024-11-04**|**Explanations that reveal all through the definition of encoding**|Aahlad Puli et.al.|[2411.02664v1](http://arxiv.org/abs/2411.02664v1)|null|
|**2024-11-04**|**Zebra-Llama: A Context-Aware Large Language Model for Democratizing Rare Disease Knowledge**|Karthik Soman et.al.|[2411.02657v1](http://arxiv.org/abs/2411.02657v1)|[link](https://github.com/karthiksoman/zebra-Llama)|
|**2024-11-04**|**M-CELS: Counterfactual Explanation for Multivariate Time Series Data Guided by Learned Saliency Maps**|Peiyu Li et.al.|[2411.02649v1](http://arxiv.org/abs/2411.02649v1)|null|
|**2024-11-04**|**A Comparative Analysis of Counterfactual Explanation Methods for Text Classifiers**|Stephen McAleese et.al.|[2411.02643v1](http://arxiv.org/abs/2411.02643v1)|null|
|**2024-11-04**|**Active Prompt Tuning Enables Gpt-40 To Do Efficient Classification Of Microscopy Images**|Abhiram Kandiyana et.al.|[2411.02639v1](http://arxiv.org/abs/2411.02639v1)|null|
|**2024-11-04**|**Intelligent Video Recording Optimization using Activity Detection for Surveillance Systems**|Youssef Elmir et.al.|[2411.02632v1](http://arxiv.org/abs/2411.02632v1)|null|
|**2024-11-04**|**Extracting Unlearned Information from LLMs with Activation Steering**|Atakan Seyitoğlu et.al.|[2411.02631v1](http://arxiv.org/abs/2411.02631v1)|null|
|**2024-11-04**|**EmoSphere++: Emotion-Controllable Zero-Shot Text-to-Speech via Emotion-Adaptive Spherical Vector**|Deok-Hyeon Cho et.al.|[2411.02625v1](http://arxiv.org/abs/2411.02625v1)|[link](https://github.com/Choddeok/EmoSpherepp)|
|**2024-11-04**|**Pseudo-Probability Unlearning: Towards Efficient and Privacy-Preserving Machine Unlearning**|Zihao Zhao et.al.|[2411.02622v1](http://arxiv.org/abs/2411.02622v1)|null|
|**2024-11-04**|**TeleOracle: Fine-Tuned Retrieval-Augmented Generation with Long-Context Support for Network**|Nouf Alabbasi et.al.|[2411.02617v1](http://arxiv.org/abs/2411.02617v1)|[link](https://github.com/Nouf-Alabbasi/oKUmura_AI_Telecom_challenge)|
|**2024-11-04**|**Advanced XR-Based 6-DOF Catheter Tracking System for Immersive Cardiac Intervention Training**|Mohsen Annabestani et.al.|[2411.02611v1](http://arxiv.org/abs/2411.02611v1)|null|
|**2024-11-04**|**Investigating Idiomaticity in Word Representations**|Wei He et.al.|[2411.02610v1](http://arxiv.org/abs/2411.02610v1)|[link](https://github.com/risehnhew/Finding-Idiomaticity-in-Word-Representations)|
|**2024-11-04**|**Computing critical exponents in 3D Ising model via pattern recognition/deep learning approach**|Timothy A. Burt et.al.|[2411.02604v1](http://arxiv.org/abs/2411.02604v1)|null|
|**2024-11-04**|**FactTest: Factuality Testing in Large Language Models with Statistical Guarantees**|Fan Nie et.al.|[2411.02603v1](http://arxiv.org/abs/2411.02603v1)|null|
|**2024-11-04**|**Vocal Sandbox: Continual Learning and Adaptation for Situated Human-Robot Collaboration**|Jennifer Grannen et.al.|[2411.02599v1](http://arxiv.org/abs/2411.02599v1)|null|
|**2024-11-04**|**"It's a conversation, not a quiz": A Risk Taxonomy and Reflection Tool for LLM Adoption in Public Health**|Jiawei Zhou et.al.|[2411.02594v1](http://arxiv.org/abs/2411.02594v1)|null|
|**2024-11-04**|**Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**|Harshavardhana T. Gowda et.al.|[2411.02591v1](http://arxiv.org/abs/2411.02591v1)|[link](https://github.com/HarshavardhanaTG/geometryOfOrofacialNeuromuscularSystem)|
|**2024-11-04**|**Context-Informed Machine Translation of Manga using Multimodal Large Language Models**|Philip Lippmann et.al.|[2411.02589v1](http://arxiv.org/abs/2411.02589v1)|null|
|**2024-11-04**|**Social Support Detection from Social Media Texts**|Zahra Ahani et.al.|[2411.02580v1](http://arxiv.org/abs/2411.02580v1)|null|
|**2024-11-04**|**ViTally Consistent: Scaling Biological Representation Learning for Cell Microscopy**|Kian Kenyon-Dean et.al.|[2411.02572v1](http://arxiv.org/abs/2411.02572v1)|null|

#### Abstracts
##### **MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and Reasoning**
2411.03314v1 by Ziliang Gan, Yu Lu, Dong Zhang, Haohan Li, Che Liu, Jian Liu, Ji Liu, Haipang Wu, Chaoyou Fu, Zenglin Xu, Rongjunchen Zhang, Yong Dai

In recent years, multimodal benchmarks for general domains have guided the
rapid development of multimodal models on general tasks. However, the financial
field has its peculiarities. It features unique graphical images (e.g.,
candlestick charts, technical indicator charts) and possesses a wealth of
specialized financial knowledge (e.g., futures, turnover rate). Therefore,
benchmarks from general fields often fail to measure the performance of
multimodal models in the financial domain, and thus cannot effectively guide
the rapid development of large financial models. To promote the development of
large financial multimodal models, we propose MME-Finance, an bilingual
open-ended and practical usage-oriented Visual Question Answering (VQA)
benchmark. The characteristics of our benchmark are finance and expertise,
which include constructing charts that reflect the actual usage needs of users
(e.g., computer screenshots and mobile photography), creating questions
according to the preferences in financial domain inquiries, and annotating
questions by experts with 10+ years of experience in the financial industry.
Additionally, we have developed a custom-designed financial evaluation system
in which visual information is first introduced in the multi-modal evaluation
process. Extensive experimental evaluations of 19 mainstream MLLMs are
conducted to test their perception, reasoning, and cognition capabilities. The
results indicate that models performing well on general benchmarks cannot do
well on MME-Finance; for instance, the top-performing open-source and
closed-source models obtain 65.69 (Qwen2VL-72B) and 63.18 (GPT-4o),
respectively. Their performance is particularly poor in categories most
relevant to finance, such as candlestick charts and technical indicator charts.
In addition, we propose a Chinese version, which helps compare performance of
MLLMs under a Chinese context.

摘要：<paragraph>近年來，一般領域的多模態基準引導多模態模型在一般任務上快速發展。然而，金融領域有其獨特性。它具有獨特的圖形影像（例如，蠟燭圖、技術指標圖），並擁有豐富的專業金融知識（例如，期貨、換手率）。因此，一般領域的基準往往無法衡量多模態模型在金融領域的表現，從而無法有效引導大型金融模型的快速發展。為了促進大型金融多模態模型的發展，我們提出了 MME-Finance，一個雙語開放式且實用的面向使用情境的視覺問答（VQA）基準。我們的基準特點為金融和專業，包括構建反映使用者實際使用需求的圖表（例如，電腦截圖和手機攝影），根據金融領域詢問的偏好建立問題，並由具有 10 年以上金融產業經驗的專家註解問題。此外，我們開發了一個客製化的金融評量系統，在多模態評量過程中首次導入視覺資訊。對 19 個主流 MLLM 進行廣泛的實驗評估，以測試它們的感知、推理和認知能力。結果表明，在一般基準上表現良好的模型無法在 MME-Finance 上表現良好；例如，表現最好的開源和閉源模型分別獲得 65.69（Qwen2VL-72B）和 63.18（GPT-4o）。它們在與金融最相關的類別（例如，蠟燭圖和技術指標圖）中的表現特別差。此外，我們提出了中文版本，有助於在中文語境下比較 MLLM 的表現。</paragraph>

##### **Inference Optimal VLMs Need Only One Visual Token but Larger Models**
2411.03312v1 by Kevin Y. Li, Sachin Goyal, Joao D. Semedo, J. Zico Kolter

Vision Language Models (VLMs) have demonstrated strong capabilities across
various visual understanding and reasoning tasks. However, their real-world
deployment is often constrained by high latency during inference due to
substantial compute required to process the large number of input tokens
(predominantly from the image) by the LLM. To reduce inference costs, one can
either downsize the LLM or reduce the number of input image-tokens, the latter
of which has been the focus of many recent works around token compression.
However, it is unclear what the optimal trade-off is, as both the factors
directly affect the VLM performance. We first characterize this optimal
trade-off between the number of visual tokens and LLM parameters by
establishing scaling laws that capture variations in performance with these two
factors. Our results reveal a surprising trend: for visual reasoning tasks, the
inference-optimal behavior in VLMs, i.e., minimum downstream error at any given
fixed inference compute, is achieved when using the largest LLM that fits
within the inference budget while minimizing visual token count - often to a
single token. While the token reduction literature has mainly focused on
maintaining base model performance by modestly reducing the token count (e.g.,
$5-10\times$), our results indicate that the compute-optimal inference regime
requires operating under even higher token compression ratios. Based on these
insights, we take some initial steps towards building approaches tailored for
high token compression settings. Code is available at
https://github.com/locuslab/llava-token-compression.

摘要：視覺語言模型 (VLM) 已在各種視覺理解和推理任務中展現強大的能力。然而，由於 LLM 處理大量輸入代碼 (主要來自影像) 所需的大量運算，其實際部署通常會受到推論期間的高延遲所限制。為了降低推論成本，可以縮小 LLM 或減少輸入影像代碼的數量，後者一直是許多近期代碼壓縮相關工作的重點。然而，目前尚不清楚最佳的折衷方案為何，因為這兩個因素都會直接影響 VLM 效能。我們首先透過建立縮放定律來描述視覺代碼數量和 LLM 參數之間的最佳折衷，以捕捉這兩個因素效能的變化。我們的結果揭示了一個令人驚訝的趨勢：對於視覺推理任務，VLM 中的推論最佳行為，即在任何給定的固定推論運算中達到最小下游誤差，是在使用符合推論預算且同時將視覺代碼數量降至最低 (通常為單一代碼) 的最大 LLM 時實現的。雖然代碼減少文獻主要集中在透過適度減少代碼數量 (例如，5-10 倍) 來維持基礎模型效能，但我們的結果顯示，運算最佳的推論機制需要在更高的代碼壓縮比下操作。根據這些見解，我們採取了一些初步步驟來建構針對高代碼壓縮設定量身打造的方法。程式碼可在 https://github.com/locuslab/llava-token-compression 取得。

##### **LLMs for Domain Generation Algorithm Detection**
2411.03307v1 by Reynier Leyva La O, Carlos A. Catania, Tatiana Parlanti

This work analyzes the use of large language models (LLMs) for detecting
domain generation algorithms (DGAs). We perform a detailed evaluation of two
important techniques: In-Context Learning (ICL) and Supervised Fine-Tuning
(SFT), showing how they can improve detection. SFT increases performance by
using domain-specific data, whereas ICL helps the detection model to quickly
adapt to new threats without requiring much retraining. We use Meta's Llama3 8B
model, on a custom dataset with 68 malware families and normal domains,
covering several hard-to-detect schemes, including recent word-based DGAs.
Results proved that LLM-based methods can achieve competitive results in DGA
detection. In particular, the SFT-based LLM DGA detector outperforms
state-of-the-art models using attention layers, achieving 94% accuracy with a
4% false positive rate (FPR) and excelling at detecting word-based DGA domains.

摘要：這項工作分析了使用大型語言模型 (LLM) 來偵測網域名稱產生演算法 (DGA) 的方式。我們對兩種重要技術執行詳細評估：語境學習 (ICL) 和監督微調 (SFT)，說明它們如何提升偵測能力。SFT 透過使用特定網域的資料來提升效能，而 ICL 則協助偵測模型快速適應新的威脅，而無需進行大量重新訓練。我們在自訂資料集上使用 Meta 的 Llama3 8B 模型，該資料集包含 68 個惡意軟體家族和正常網域，涵蓋多種難以偵測的方案，包括最近的基於字詞的 DGA。結果證明，基於 LLM 的方法可以在 DGA 偵測中取得具競爭力的結果。特別是，基於 SFT 的 LLM DGA 偵測器優於使用注意力層的現有技術，在 4% 的偽陽性率 (FPR) 下達到 94% 的準確度，並且擅長偵測基於字詞的 DGA 網域。

##### **VERITAS: A Unified Approach to Reliability Evaluation**
2411.03300v1 by Rajkumar Ramamurthy, Meghana Arakkal Rajeev, Oliver Molenschot, James Zou, Nazneen Rajani

Large language models (LLMs) often fail to synthesize information from their
context to generate an accurate response. This renders them unreliable in
knowledge intensive settings where reliability of the output is key. A critical
component for reliable LLMs is the integration of a robust fact-checking system
that can detect hallucinations across various formats. While several
open-access fact-checking models are available, their functionality is often
limited to specific tasks, such as grounded question-answering or entailment
verification, and they perform less effectively in conversational settings. On
the other hand, closed-access models like GPT-4 and Claude offer greater
flexibility across different contexts, including grounded dialogue
verification, but are hindered by high costs and latency. In this work, we
introduce VERITAS, a family of hallucination detection models designed to
operate flexibly across diverse contexts while minimizing latency and costs.
VERITAS achieves state-of-the-art results considering average performance on
all major hallucination detection benchmarks, with $10\%$ increase in average
performance when compared to similar-sized models and get close to the
performance of GPT4 turbo with LLM-as-a-judge setting.

摘要：大型語言模型 (LLM) 常常無法從其背景中綜合資訊來產生準確的回應。這使得它們在知識密集型環境中不可靠，而輸出可靠性是關鍵。可靠 LLM 的一個關鍵組成部分是整合一個強大的事實查核系統，它可以跨各種格式檢測幻覺。雖然有幾個開放獲取的事實查核模型可用，但它們的功能通常僅限於特定任務，例如有根據的問題解答或蘊涵驗證，並且它們在對話環境中的表現較差。另一方面，像 GPT-4 和 Claude 這樣的封閉訪問模型在不同背景下提供了更大的靈活性，包括有根據的對話驗證，但受到高成本和延遲的阻礙。在這項工作中，我們介紹了 VERITAS，這是一個幻覺檢測模型系列，旨在靈活地在不同背景下運作，同時最大限度地減少延遲和成本。VERITAS 在所有主要幻覺檢測基準上考慮平均性能而獲得最先進的結果，與類似大小的模型相比，平均性能提高了 10%，並且接近在 LLM 作為評審設定下使用 GPT4 turbo 的性能。

##### **Interaction2Code: How Far Are We From Automatic Interactive Webpage Generation?**
2411.03292v1 by Jingyu Xiao, Yuxuan Wan, Yintong Huo, Zhiyao Xu, Michael R. Lyu

Converting webpage design into functional UI code is a critical step for
building websites, which can be labor-intensive and time-consuming. To automate
this design-to-code transformation process, various automated methods using
learning-based networks and multi-modal large language models (MLLMs) have been
proposed. However, these studies were merely evaluated on a narrow range of
static web pages and ignored dynamic interaction elements, making them less
practical for real-world website deployment.
  To fill in the blank, we present the first systematic investigation of MLLMs
in generating interactive webpages. Specifically, we first formulate the
Interaction-to-Code task and build the Interaction2Code benchmark that contains
97 unique web pages and 213 distinct interactions, spanning 15 webpage types
and 30 interaction categories. We then conduct comprehensive experiments on
three state-of-the-art (SOTA) MLLMs using both automatic metrics and human
evaluations, thereby summarizing six findings accordingly. Our experimental
results highlight the limitations of MLLMs in generating fine-grained
interactive features and managing interactions with complex transformations and
subtle visual modifications. We further analyze failure cases and their
underlying causes, identifying 10 common failure types and assessing their
severity. Additionally, our findings reveal three critical influencing factors,
i.e., prompts, visual saliency, and textual descriptions, that can enhance the
interaction generation performance of MLLMs. Based on these findings, we elicit
implications for researchers and developers, providing a foundation for future
advancements in this field. Datasets and source code are available at
https://github.com/WebPAI/Interaction2Code.

摘要：<paragraph>將網頁設計轉換為功能性 UI 程式碼是建置網站的關鍵步驟，這可能是需要大量人力且耗時的。為了自動化此設計到程式碼的轉換程序，已提出各種使用基於學習的網路和多模態大型語言模型 (MLLM) 的自動化方法。然而，這些研究僅針對範圍狹窄的靜態網頁進行評估，並忽略動態互動元素，這使得它們對於實際世界的網站部署而言較不實用。
為了填補空白，我們提出第一個系統性地調查 MLLM 在產生互動式網頁中的研究。具體來說，我們首先制定互動到程式碼任務，並建置包含 97 個獨特網頁和 213 個不同互動的 Interaction2Code 基準，涵蓋 15 個網頁類型和 30 個互動類別。然後，我們使用自動化指標和人工評估對三個最先進 (SOTA) 的 MLLM 進行全面實驗，並據此總結六項發現。我們的實驗結果突顯出 MLLM 在產生細緻的互動式功能以及管理與複雜轉換和微妙視覺修改的互動方面的限制。我們進一步分析失敗案例及其根本原因，找出 10 種常見的失敗類型並評估其嚴重性。此外，我們的發現揭示了三個關鍵的影響因素，即提示、視覺顯著性和文字描述，它們可以增強 MLLM 的互動產生效能。根據這些發現，我們引出對研究人員和開發人員的啟示，為此領域的未來進展奠定基礎。資料集和原始程式碼可在 https://github.com/WebPAI/Interaction2Code 取得。</paragraph>

##### **The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare**
2411.03287v1 by Souren Pashangpour, Goldie Nejat

The potential use of large language models (LLMs) in healthcare robotics can
help address the significant demand put on healthcare systems around the world
with respect to an aging demographic and a shortage of healthcare
professionals. Even though LLMs have already been integrated into medicine to
assist both clinicians and patients, the integration of LLMs within healthcare
robots has not yet been explored for clinical settings. In this perspective
paper, we investigate the groundbreaking developments in robotics and LLMs to
uniquely identify the needed system requirements for designing health specific
LLM based robots in terms of multi modal communication through human robot
interactions (HRIs), semantic reasoning, and task planning. Furthermore, we
discuss the ethical issues, open challenges, and potential future research
directions for this emerging innovative field.

摘要：大型語言模型 (LLM) 在醫療保健機器人中潛在的應用，有助於滿足全球醫療保健系統對應老齡化人口和醫療保健專業人員短缺問題的重大需求。儘管 LLM 已整合到醫療領域中，以協助臨床醫生和患者，但 LLM 在醫療保健機器人中的整合尚未針對臨床環境進行探討。在此觀點論文中，我們探討機器人和 LLM 的創新發展，以獨特地找出設計特定於健康的 LLM 機器人的系統需求，包括透過人機互動 (HRI)、語義推理和任務規劃的多模式溝通。此外，我們討論了這個新興創新領域的倫理議題、開放性挑戰和潛在的未來研究方向。

##### **SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents**
2411.03284v1 by Dawei Li, Zhen Tan, Peijia Qian, Yifan Li, Kumar Satvik Chaudhary, Lijie Hu, Jiayi Shen

While multi-agent systems have been shown to significantly enhance the
performance of Large Language Models (LLMs) across various tasks and
applications, the dense interaction between scaling agents potentially hampers
their efficiency and diversity. To address these challenges, we draw
inspiration from the sparse mixture-of-agents (SMoE) and propose a sparse
mixture-of-agents (SMoA) framework to improve the efficiency and diversity of
multi-agent LLMs. Unlike completely connected structures, SMoA introduces novel
Response Selection and Early Stopping mechanisms to sparsify information flows
among individual LLM agents, striking a balance between performance and
efficiency. Additionally, inspired by the expert diversity principle in SMoE
frameworks for workload balance between experts, we assign distinct role
descriptions to each LLM agent, fostering diverse and divergent thinking.
Extensive experiments on reasoning, alignment, and fairness benchmarks
demonstrate that SMoA achieves performance comparable to traditional
mixture-of-agents approaches but with significantly lower computational costs.
Further analysis reveals that SMoA is more stable, has a greater capacity to
scale, and offers considerable potential through hyper-parameter optimization.
Code and data will be available at: https://github.com/David-Li0406/SMoA.

摘要：儘管多智能體系統已被證明能顯著提升大型語言模型 (LLM) 在各種任務和應用中的效能，但擴充智能體之間的密集互動潛在會阻礙其效率和多樣性。為了應對這些挑戰，我們從稀疏混合智能體 (SMoE) 汲取靈感，並提出一個稀疏混合智能體 (SMoA) 架構來提升多智能體 LLM 的效率和多樣性。與完全連接的結構不同，SMoA 引進了新穎的回應選擇和提前停止機制，以稀疏化個別 LLM 智能體之間的資訊流，在效能和效率之間取得平衡。此外，在 SMoE 架構中受到專家多樣性原則的啟發，以平衡專家之間的工作負載，我們為每個 LLM 智能體分配了不同的角色描述，以促進多樣化和發散性思考。在推理、對齊和公平基準上的廣泛實驗證明，SMoA 達到了與傳統混合智能體方法相當的效能，但計算成本卻顯著降低。進一步的分析顯示，SMoA 更加穩定，具有更大的擴充能力，並透過超參數最佳化提供了可觀的潛力。程式碼和資料將於以下網址提供：https://github.com/David-Li0406/SMoA。

##### **Causal Responsibility Attribution for Human-AI Collaboration**
2411.03275v1 by Yahang Qi, Bernhard Schölkopf, Zhijing Jin

As Artificial Intelligence (AI) systems increasingly influence
decision-making across various fields, the need to attribute responsibility for
undesirable outcomes has become essential, though complicated by the complex
interplay between humans and AI. Existing attribution methods based on actual
causality and Shapley values tend to disproportionately blame agents who
contribute more to an outcome and rely on real-world measures of
blameworthiness that may misalign with responsible AI standards. This paper
presents a causal framework using Structural Causal Models (SCMs) to
systematically attribute responsibility in human-AI systems, measuring overall
blameworthiness while employing counterfactual reasoning to account for agents'
expected epistemic levels. Two case studies illustrate the framework's
adaptability in diverse human-AI collaboration scenarios.

摘要：隨著人工智慧 (AI) 系統越來越影響各個領域的決策制定，為不良後果歸屬責任的需求已變得至關重要，儘管人類與 AI 之間的複雜交互作用讓這件事變得複雜。現有的歸因方法基於實際因果關係和 Shapley 值，往往會對對結果貢獻較多的代理人過度歸咎，並依賴於可能與負責任的 AI 標準不符的現實世界責難程度衡量。本文提出一個使用結構因果模型 (SCM) 的因果框架，以系統性地將責任歸因於人類 AI 系統，衡量整體責難程度，同時採用反事實推理來考量代理人的預期認識層級。兩個案例研究說明了該框架在不同人類 AI 協作情境中的適應性。

##### **Discovering Data Structures: Nearest Neighbor Search and Beyond**
2411.03253v1 by Omar Salemohamed, Laurent Charlin, Shivam Garg, Vatsal Sharan, Gregory Valiant

We propose a general framework for end-to-end learning of data structures.
Our framework adapts to the underlying data distribution and provides
fine-grained control over query and space complexity. Crucially, the data
structure is learned from scratch, and does not require careful initialization
or seeding with candidate data structures/algorithms. We first apply this
framework to the problem of nearest neighbor search. In several settings, we
are able to reverse-engineer the learned data structures and query algorithms.
For 1D nearest neighbor search, the model discovers optimal distribution
(in)dependent algorithms such as binary search and variants of interpolation
search. In higher dimensions, the model learns solutions that resemble k-d
trees in some regimes, while in others, they have elements of
locality-sensitive hashing. The model can also learn useful representations of
high-dimensional data and exploit them to design effective data structures. We
also adapt our framework to the problem of estimating frequencies over a data
stream, and believe it could also be a powerful discovery tool for new
problems.

摘要：我們提出一個通用的架構，用於資料結構的端到端學習。
我們的架構會適應基礎資料分佈，並提供對查詢和空間複雜度的細緻控制。至關重要的是，資料結構是從頭開始學習，不需要仔細初始化或使用候選資料結構/演算法進行設定。我們首先將這個架構應用到最近鄰搜尋的問題。在多種設定中，我們能夠逆向工程已學習的資料結構和查詢演算法。對於 1D 最近鄰搜尋，模型會發現最佳分佈（內部）獨立演算法，例如二元搜尋和內插搜尋變體。在更高維度中，模型學習到的解會在某些模式下類似於 k-d 樹，而在其他模式下，它們會包含局部敏感雜湊的元素。該模型還可以學習高維資料的有用表示，並利用它們來設計有效的資料結構。我們也將我們的架構調整到資料串流上頻率估計的問題，並相信它對於新問題來說也可能是一個強大的發現工具。

##### **Spontaneous Emergence of Agent Individuality through Social Interactions in LLM-Based Communities**
2411.03252v1 by Ryosuke Takata, Atsushi Masumori, Takashi Ikegami

We study the emergence of agency from scratch by using Large Language Model
(LLM)-based agents. In previous studies of LLM-based agents, each agent's
characteristics, including personality and memory, have traditionally been
predefined. We focused on how individuality, such as behavior, personality, and
memory, can be differentiated from an undifferentiated state. The present LLM
agents engage in cooperative communication within a group simulation,
exchanging context-based messages in natural language. By analyzing this
multi-agent simulation, we report valuable new insights into how social norms,
cooperation, and personality traits can emerge spontaneously. This paper
demonstrates that autonomously interacting LLM-powered agents generate
hallucinations and hashtags to sustain communication, which, in turn, increases
the diversity of words within their interactions. Each agent's emotions shift
through communication, and as they form communities, the personalities of the
agents emerge and evolve accordingly. This computational modeling approach and
its findings will provide a new method for analyzing collective artificial
intelligence.

摘要：我們透過使用大型語言模型 (LLM) 為基礎的代理來研究代理從零開始出現。在先前針對 LLM 為基礎的代理的研究中，每個代理的特徵（包括個性與記憶）傳統上都是預先定義好的。我們專注於如何將個性化（例如行為、個性與記憶）與未區分狀態區分開來。目前的 LLM 代理在群組模擬中進行合作溝通，以自然語言交換基於內容的訊息。透過分析此多代理模擬，我們報告了有關社會規範、合作與人格特質如何自發出現的寶貴新見解。本文證明了自主互動的 LLM 驅動代理會產生幻覺和標籤以維持溝通，這反過來會增加互動中字詞的多樣性。每個代理的情緒會隨著溝通而改變，而且隨著他們形成社群，代理的個性也會相應地出現並演化。這種計算模型方法及其發現將提供一種分析集體人工智慧的新方法。

##### **DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models**
2411.03250v1 by Ying Zhou, Xinyao Wang, Yulei Niu, Yaojie Shen, Lexin Tang, Fan Chen, Ben He, Le Sun, Longyin Wen

Recent advancements in large language models (LLMs) have significantly
enhanced their knowledge and generative capabilities, leading to a surge of
interest in leveraging LLMs for high-quality data synthesis. However, synthetic
data generation via prompting LLMs remains challenging due to LLMs' limited
understanding of target data distributions and the complexity of prompt
engineering, especially for structured formatted data. To address these issues,
we introduce DiffLM, a controllable data synthesis framework based on
variational autoencoder (VAE), which further (1) leverages diffusion models to
reserve more information of original distribution and format structure in the
learned latent distribution and (2) decouples the learning of target
distribution knowledge from the LLM's generative objectives via a plug-and-play
latent feature injection module. As we observed significant discrepancies
between the VAE's latent representations and the real data distribution, the
latent diffusion module is introduced into our framework to learn a fully
expressive latent distribution. Evaluations on seven real-world datasets with
structured formatted data (i.e., Tabular, Code and Tool data) demonstrate that
DiffLM generates high-quality data, with performance on downstream tasks
surpassing that of real data by 2-7 percent in certain cases. The data and code
will be publicly available upon completion of internal review.

摘要：大型語言模型 (LLM) 最近的進展大幅提升了它們的知識和生成能力，導致利用 LLM 進行高品質資料合成產生極大的興趣。然而，透過提示 LLM 進行合成資料生成仍然具有挑戰性，因為 LLM 對目標資料分佈的理解有限，且提示工程很複雜，尤其是對於結構化格式化資料。為了解決這些問題，我們引入了 DiffLM，這是一個基於變異自動編碼器 (VAE) 的可控資料合成架構，它進一步 (1) 利用擴散模型保留更多原始分佈和格式結構的資訊在學習到的潛在分佈中，以及 (2) 透過即插即用潛在特徵注入模組將目標分佈知識的學習與 LLM 的生成目標分離。由於我們觀察到 VAE 的潛在表示和真實資料分佈之間存在顯著差異，因此將潛在擴散模組引入我們的架構中以學習一個完全表達的潛在分佈。針對七個具有結構化格式化資料的真實世界資料集 (即表格、程式碼和工具資料) 的評估顯示，DiffLM 生成了高品質的資料，在某些情況下，下游任務的效能比真實資料高出 2-7 個百分點。資料和程式碼在完成內部審查後將公開。

##### **On the Detection of Non-Cooperative RISs: Scan B-Testing via Deep Support Vector Data Description**
2411.03237v1 by George Stamatelis, Panagiotis Gavriilidis, Aymen Fakhreddine, George C. Alexandropoulos

In this paper, we study the problem of promptly detecting the presence of
non-cooperative activity from one or more Reconfigurable Intelligent Surfaces
(RISs) with unknown characteristics lying in the vicinity of a Multiple-Input
Multiple-Output (MIMO) communication system using Orthogonal Frequency-Division
Multiplexing (OFDM) transmissions. We first present a novel wideband channel
model incorporating RISs as well as non-reconfigurable stationary surfaces,
which captures both the effect of the RIS actuation time on the channel in the
frequency domain as well as the difference between changing phase
configurations during or among transmissions. Considering that RISs may operate
under the coordination of a third-party system, and thus, may negatively impact
the communication of the intended MIMO OFDM system, we present a novel RIS
activity detection framework that is unaware of the distribution of the phase
configuration of any of the non-cooperative RISs. In particular, capitalizing
on the knowledge of the data distribution at the multi-antenna receiver, we
design a novel online change point detection statistic that combines a deep
support vector data description model with the scan $B$-test. The presented
numerical investigations demonstrate the improved detection accuracy as well as
decreased computational complexity of the proposed RIS detection approach over
existing change point detection schemes.

摘要：<paragraph>在本文中，我們研究了在正交頻分多工 (OFDM) 傳輸中，使用多輸入多輸出 (MIMO) 通訊系統附近具有未知特性的可重構智慧表面 (RIS) 中，從一個或多個非合作活動中快速偵測存在的問題。我們首先提出一個新的寬頻通道模型，結合 RIS 和不可重構的固定表面，它同時捕捉了 RIS 致動時間對頻域中通道的影響，以及在傳輸期間或之間改變相位配置的差異。考慮到 RIS 可以在第三方系統的協調下運作，因此可能會對預期的 MIMO OFDM 系統的通訊造成負面影響，我們提出了一個新的 RIS 活動偵測架構，它不知道任何非合作 RIS 的相位配置分佈。特別是，利用多天線接收器中資料分佈的知識，我們設計了一個新的線上變更點偵測統計，它結合了深度支持向量資料描述模型和掃描 B 檢定。所提出的數值調查證明了所提出的 RIS 偵測方法比現有的變更點偵測方案具有更高的偵測準確度和更低的計算複雜度。</paragraph>

##### **Formal Logic-guided Robust Federated Learning against Poisoning Attacks**
2411.03231v1 by Dung Thuy Nguyen, Ziyan An, Taylor T. Johnson, Meiyi Ma, Kevin Leach

Federated Learning (FL) offers a promising solution to the privacy concerns
associated with centralized Machine Learning (ML) by enabling decentralized,
collaborative learning. However, FL is vulnerable to various security threats,
including poisoning attacks, where adversarial clients manipulate the training
data or model updates to degrade overall model performance. Recognizing this
threat, researchers have focused on developing defense mechanisms to counteract
poisoning attacks in FL systems. However, existing robust FL methods
predominantly focus on computer vision tasks, leaving a gap in addressing the
unique challenges of FL with time series data. In this paper, we present
FLORAL, a defense mechanism designed to mitigate poisoning attacks in federated
learning for time-series tasks, even in scenarios with heterogeneous client
data and a large number of adversarial participants. Unlike traditional
model-centric defenses, FLORAL leverages logical reasoning to evaluate client
trustworthiness by aligning their predictions with global time-series patterns,
rather than relying solely on the similarity of client updates. Our approach
extracts logical reasoning properties from clients, then hierarchically infers
global properties, and uses these to verify client updates. Through formal
logic verification, we assess the robustness of each client contribution,
identifying deviations indicative of adversarial behavior. Experimental results
on two datasets demonstrate the superior performance of our approach compared
to existing baseline methods, highlighting its potential to enhance the
robustness of FL to time series applications. Notably, FLORAL reduced the
prediction error by 93.27\% in the best-case scenario compared to the
second-best baseline. Our code is available at
\url{https://anonymous.4open.science/r/FLORAL-Robust-FTS}.

摘要：<paragraph>联邦学习 (FL) 透过启用分散且协作的学习，为集中式机器学习 (ML) 相关的隐私问题提供了一个有前途的解决方案。然而，FL 容易受到各种安全威胁，包括中毒攻击，其中对抗式客户端会操纵训练数据或模型更新，以降低整体模型性能。认识到这一威胁，研究人员专注于开发防御机制来对抗 FL 系统中的中毒攻击。然而，现有的稳健 FL 方法主要专注于计算机视觉任务，在解决时间序列数据中 FL 的独特挑战方面存在差距。在本文中，我们提出了 FLORAL，这是一种防御机制，旨在减轻时间序列任务中联邦学习中的中毒攻击，即使在异构客户端数据和大量对抗参与者的场景中也是如此。与传统的以模型为中心的防御措施不同，FLORAL 利用逻辑推理来评估客户端的可信度，方法是将他们的预测与全局时间序列模式对齐，而不是仅仅依赖客户端更新的相似性。我们的方法从客户端中提取逻辑推理属性，然后分层推断全局属性，并使用这些属性来验证客户端更新。通过形式逻辑验证，我们评估每个客户端贡献的稳健性，识别出表明对抗行为的偏差。在两个数据集上的实验结果表明，与现有的基线方法相比，我们的方法具有卓越的性能，突出了它增强 FL 对时间序列应用的稳健性的潜力。值得注意的是，在最佳情况下，与第二好的基线相比，FLORAL 将预测误差减少了 93.27%。我们的代码可在 \url{https://anonymous.4open.science/r/FLORAL-Robust-FTS} 获得。</paragraph>

##### **Beyond Grid Data: Exploring Graph Neural Networks for Earth Observation**
2411.03223v1 by Shan Zhao, Zhaiyu Chen, Zhitong Xiong, Yilei Shi, Sudipan Saha, Xiao Xiang Zhu

Earth Observation (EO) data analysis has been significantly revolutionized by
deep learning (DL), with applications typically limited to grid-like data
structures. Graph Neural Networks (GNNs) emerge as an important innovation,
propelling DL into the non-Euclidean domain. Naturally, GNNs can effectively
tackle the challenges posed by diverse modalities, multiple sensors, and the
heterogeneous nature of EO data. To introduce GNNs in the related domains, our
review begins by offering fundamental knowledge on GNNs. Then, we summarize the
generic problems in EO, to which GNNs can offer potential solutions. Following
this, we explore a broad spectrum of GNNs' applications to scientific problems
in Earth systems, covering areas such as weather and climate analysis, disaster
management, air quality monitoring, agriculture, land cover classification,
hydrological process modeling, and urban modeling. The rationale behind
adopting GNNs in these fields is explained, alongside methodologies for
organizing graphs and designing favorable architectures for various tasks.
Furthermore, we highlight methodological challenges of implementing GNNs in
these domains and possible solutions that could guide future research. While
acknowledging that GNNs are not a universal solution, we conclude the paper by
comparing them with other popular architectures like transformers and analyzing
their potential synergies.

摘要：地球觀測 (EO) 資料分析已透過深度學習 (DL) 產生重大變革，應用通常僅限於網格狀資料結構。圖形神經網路 (GNN) 作為一項重要創新浮現，推動 DL 進入非歐幾里得領域。自然地，GNN 能有效應對不同模式、多重感測器和 EO 資料異質性所帶來的挑戰。為了在相關領域中導入 GNN，我們的評論從提供 GNN 的基礎知識開始。接著，我們總結 EO 中的常見問題，GNN 可為這些問題提供潛在解決方案。在此之後，我們探討 GNN 在地球系統科學問題中的廣泛應用，涵蓋天氣和氣候分析、災害管理、空氣品質監控、農業、土地覆蓋分類、水文過程建模和城市建模等領域。我們說明在這些領域採用 GNN 的理由，以及組織圖形和設計適用於各種任務的良好架構的方法。此外，我們強調在這些領域實作 GNN 的方法論挑戰，以及可能引導未來研究的潛在解決方案。雖然承認 GNN 並非萬能解，但我們透過將 GNN 與其他流行架構（例如Transformer）進行比較，並分析其潛在協同效應，來為本文作結。

##### **GIS Copilot: Towards an Autonomous GIS Agent for Spatial Analysis**
2411.03205v1 by Temitope Akinboyewa, Zhenlong Li, Huan Ning, M. Naser Lessani

Recent advancements in Generative AI offer promising capabilities for spatial
analysis. Despite their potential, the integration of generative AI with
established GIS platforms remains underexplored. In this study, we propose a
framework for integrating LLMs directly into existing GIS platforms, using QGIS
as an example. Our approach leverages the reasoning and programming
capabilities of LLMs to autonomously generate spatial analysis workflows and
code through an informed agent that has comprehensive documentation of key GIS
tools and parameters. The implementation of this framework resulted in the
development of a "GIS Copilot" that allows GIS users to interact with QGIS
using natural language commands for spatial analysis. The GIS Copilot was
evaluated based on three complexity levels: basic tasks that require one GIS
tool and typically involve one data layer to perform simple operations;
intermediate tasks involving multi-step processes with multiple tools, guided
by user instructions; and advanced tasks which involve multi-step processes
that require multiple tools but not guided by user instructions, necessitating
the agent to independently decide on and executes the necessary steps. The
evaluation reveals that the GIS Copilot demonstrates strong potential in
automating foundational GIS operations, with a high success rate in tool
selection and code generation for basic and intermediate tasks, while
challenges remain in achieving full autonomy for more complex tasks. This study
contributes to the emerging vision of Autonomous GIS, providing a pathway for
non-experts to engage with geospatial analysis with minimal prior expertise.
While full autonomy is yet to be achieved, the GIS Copilot demonstrates
significant potential for simplifying GIS workflows and enhancing
decision-making processes.

摘要：生成式 AI 的最新進展為空間分析提供了有前景的能力。儘管有其潛力，但生成式 AI 與既有 GIS 平台的整合仍未充分探討。在本研究中，我們提出了一個框架，用於將 LLM 直接整合到現有 GIS 平台中，並以 QGIS 為例。我們的做法利用了 LLM 的推理和程式設計能力，透過一個對關鍵 GIS 工具和參數有全面文件說明的知情代理，來自主產生空間分析工作流程和程式碼。這個框架的實作產生了一個「GIS 副駕駛」，讓 GIS 使用者可以使用自然語言指令與 QGIS 互動，以進行空間分析。GIS 副駕駛的評估基於三個複雜程度等級：只需要一個 GIS 工具並通常涉及一個資料層以執行簡單操作的基本任務；涉及多個工具的多步驟流程的中間任務，由使用者指令引導；以及涉及多個工具的多步驟流程的高階任務，但不受使用者指令引導，需要代理獨立決定並執行必要的步驟。評估顯示，GIS 副駕駛在自動化基礎 GIS 操作方面展現了強大的潛力，在基本和中間任務的工具選擇和程式碼產生方面有很高的成功率，而要實現更複雜任務的完全自主性仍有挑戰。本研究有助於新興的自主 GIS 願景，為非專家提供了一條途徑，讓他們在具備最少先備知識的情況下參與地理空間分析。儘管尚未實現完全的自主性，但 GIS 副駕駛在簡化 GIS 工作流程和增強決策制定流程方面展現了顯著的潛力。

##### **On Improved Conditioning Mechanisms and Pre-training Strategies for Diffusion Models**
2411.03177v1 by Tariq Berrada Ifriqi, Pietro Astolfi, Melissa Hall, Reyhane Askari-Hemmat, Yohann Benchetrit, Marton Havasi, Matthew Muckley, Karteek Alahari, Adriana Romero-Soriano, Jakob Verbeek, Michal Drozdzal

Large-scale training of latent diffusion models (LDMs) has enabled
unprecedented quality in image generation. However, the key components of the
best performing LDM training recipes are oftentimes not available to the
research community, preventing apple-to-apple comparisons and hindering the
validation of progress in the field. In this work, we perform an in-depth study
of LDM training recipes focusing on the performance of models and their
training efficiency. To ensure apple-to-apple comparisons, we re-implement five
previously published models with their corresponding recipes. Through our
study, we explore the effects of (i)~the mechanisms used to condition the
generative model on semantic information (e.g., text prompt) and control
metadata (e.g., crop size, random flip flag, etc.) on the model performance,
and (ii)~the transfer of the representations learned on smaller and
lower-resolution datasets to larger ones on the training efficiency and model
performance. We then propose a novel conditioning mechanism that disentangles
semantic and control metadata conditionings and sets a new state-of-the-art in
class-conditional generation on the ImageNet-1k dataset -- with FID
improvements of 7% on 256 and 8% on 512 resolutions -- as well as text-to-image
generation on the CC12M dataset -- with FID improvements of 8% on 256 and 23%
on 512 resolution.

摘要：大規模訓練潛在擴散模型 (LDM) 已使影像生成品質達到前所未有的水準。然而，效能最佳的 LDM 訓練配方的關鍵組成部分通常無法提供給研究社群，這使得蘋果對蘋果的比較無法進行，並阻礙了該領域進度的驗證。在這項工作中，我們針對 LDM 訓練配方進行深入研究，重點在於模型的效能及其訓練效率。為了確保蘋果對蘋果的比較，我們重新實作了五個先前發表的模型及其對應配方。透過我們的研究，我們探討了 (i) 用於對生成模型進行語意資訊 (例如，文字提示) 和控制元資料 (例如，裁剪大小、隨機翻轉標記等) 條件化的機制對模型效能的影響，以及 (ii) 在較小且較低解析度的資料集上學習到的表徵轉移到較大的資料集上，對訓練效率和模型效能的影響。接著，我們提出了一種新穎的條件化機制，它解開語意和控制元資料的條件化，並在 ImageNet-1k 資料集上設定了類別條件式生成的最新技術水準，在 256 和 512 解析度上，FID 分別改善了 7% 和 8%，以及在 CC12M 資料集上的文字轉影像生成，在 256 和 512 解析度上，FID 分別改善了 8% 和 23%。

##### **Navigating Extremes: Dynamic Sparsity in Large Output Space**
2411.03171v1 by Nasib Ullah, Erik Schultheis, Mike Lasby, Yani Ioannou, Rohit Babbar

In recent years, Dynamic Sparse Training (DST) has emerged as an alternative
to post-training pruning for generating efficient models. In principle, DST
allows for a more memory efficient training process, as it maintains sparsity
throughout the entire training run. However, current DST implementations fail
to capitalize on this in practice. Because sparse matrix multiplication is much
less efficient than dense matrix multiplication on GPUs, most implementations
simulate sparsity by masking weights. In this paper, we leverage recent
advances in semi-structured sparse training to apply DST in the domain of
classification with large output spaces, where memory-efficiency is paramount.
With a label space of possibly millions of candidates, the classification layer
alone will consume several gigabytes of memory. Switching from a dense to a
fixed fan-in sparse layer updated with sparse evolutionary training (SET);
however, severely hampers training convergence, especially at the largest label
spaces. We find that poor gradient flow from the sparse classifier to the dense
text encoder make it difficult to learn good input representations. By
employing an intermediate layer or adding an auxiliary training objective, we
recover most of the generalisation performance of the dense model. Overall, we
demonstrate the applicability and practical benefits of DST in a challenging
domain -- characterized by a highly skewed label distribution that differs
substantially from typical DST benchmark datasets -- which enables end-to-end
training with millions of labels on commodity hardware.

摘要：近年來，動態稀疏訓練 (DST) 已成為一種替代訓練後剪枝的方案，用於產生有效率的模型。原則上，DST 允許更省記憶體的訓練過程，因為它在整個訓練執行期間都維持稀疏性。然而，目前的 DST 執行無法在實務中發揮此優點。由於稀疏矩陣乘法遠比 GPU 上的稠密矩陣乘法低效率，因此大多數執行會透過遮罩權重來模擬稀疏性。在本文中，我們利用半結構化稀疏訓練的最新進展，將 DST 應用於具有大量輸出空間的分類領域，其中記憶體效率至關重要。在可能包含數百萬候選項的標籤空間中，單是分類層就會耗用數 GB 的記憶體。從稠密層切換到使用稀疏演化訓練 (SET) 更新的固定扇入稀疏層；然而，會嚴重阻礙訓練收斂，特別是在最大的標籤空間。我們發現，從稀疏分類器到稠密文字編碼器的梯度流動不佳，使得難以學習良好的輸入表示。透過採用中間層或加入輔助訓練目標，我們恢復了稠密模型的大部分泛化效能。總體而言，我們展示了 DST 在具有挑戰性的領域中的適用性和實用優點——其特徵是高度偏斜的標籤分佈，與典型的 DST 基準資料集有顯著差異——這使得使用一般硬體就能對數百萬個標籤進行端到端訓練。

##### **Evaluating Machine Learning Models against Clinical Protocols for Enhanced Interpretability and Continuity of Care**
2411.03105v1 by Christel Sirocchi, Muhammad Suffian, Federico Sabbatini, Alessandro Bogliolo, Sara Montagna

In clinical practice, decision-making relies heavily on established
protocols, often formalised as rules. Concurrently, Machine Learning (ML)
models, trained on clinical data, aspire to integrate into medical
decision-making processes. However, despite the growing number of ML
applications, their adoption into clinical practice remains limited. Two
critical concerns arise, relevant to the notions of consistency and continuity
of care: (a) accuracy - the ML model, albeit more accurate, might introduce
errors that would not have occurred by applying the protocol; (b)
interpretability - ML models operating as black boxes might make predictions
based on relationships that contradict established clinical knowledge. In this
context, the literature suggests using ML models integrating domain knowledge
for improved accuracy and interpretability. However, there is a lack of
appropriate metrics for comparing ML models with clinical rules in addressing
these challenges. Accordingly, in this article, we first propose metrics to
assess the accuracy of ML models with respect to the established protocol.
Secondly, we propose an approach to measure the distance of explanations
provided by two rule sets, with the goal of comparing the explanation
similarity between clinical rule-based systems and rules extracted from ML
models. The approach is validated on the Pima Indians Diabetes dataset by
training two neural networks - one exclusively on data, and the other
integrating a clinical protocol. Our findings demonstrate that the integrated
ML model achieves comparable performance to that of a fully data-driven model
while exhibiting superior accuracy relative to the clinical protocol, ensuring
enhanced continuity of care. Furthermore, we show that our integrated model
provides explanations for predictions that align more closely with the clinical
protocol compared to the data-driven model.

摘要：<paragraph>在臨床實務中，決策仰賴既定的協定，通常以規則形式化。同時，以臨床資料訓練的機器學習 (ML) 模型，渴望整合到醫療決策流程中。然而，儘管 ML 應用數量日增，它們在臨床實務中的採用仍受限。兩個關鍵疑慮浮現，與照護的一致性和連續性概念相關：(a) 準確性 - ML 模型雖然更準確，但可能會引入套用協定時不會發生的錯誤；(b) 可解釋性 - 作為黑盒運作的 ML 模型可能會根據與既定臨床知識相矛盾的關係進行預測。在此脈絡中，文獻建議使用整合領域知識的 ML 模型以提升準確性和可解釋性。然而，缺乏適當的指標來比較 ML 模型與臨床規則，以應對這些挑戰。因此，在本文中，我們首先提出指標來評估 ML 模型相對於既定協定的準確性。其次，我們提出一個方法來衡量兩組規則所提供的解釋的距離，目標是比較基於臨床規則的系統與從 ML 模型中提取的規則之間的解釋相似性。此方法在 Pima 印地安人糖尿病資料集上驗證，方法是訓練兩個神經網路 - 一個僅針對資料，另一個整合臨床協定。我們的研究結果證明，整合式 ML 模型達到了與完全資料驅動模型相當的效能，同時展現出相對於臨床協定的優異準確性，確保增強的照護連續性。此外，我們證明我們的整合模型提供的預測解釋與臨床協定相比，更為緊密地結合。</paragraph>

##### **Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation in a Limited Data Setting**
2411.03098v1 by Adrian B. Chłopowiec, Adam R. Chłopowiec, Krzysztof Galus, Wojciech Cebula, Martin Tabakov

Limited medical imaging datasets challenge deep learning models by increasing
risks of overfitting and reduced generalization, particularly in Generative
Adversarial Networks (GANs), where discriminators may overfit, leading to
training divergence. This constraint also impairs classification models trained
on small datasets. Generative Data Augmentation (GDA) addresses this by
expanding training datasets with synthetic data, although it requires training
a generative model. We propose and evaluate two local lesion generation
approaches to address the challenge of augmenting small medical image datasets.
The first approach employs the Poisson Image Editing algorithm, a classical
image processing technique, to create realistic image composites that
outperform current state-of-the-art methods. The second approach introduces a
novel generative method, leveraging a fine-tuned Image Inpainting GAN to
synthesize realistic lesions within specified regions of real training images.
A comprehensive comparison of the two proposed methods demonstrates that
effective local lesion generation in a data-constrained setting allows for
reaching new state-of-the-art results in capsule endoscopy lesion
classification. Combination of our techniques achieves a macro F1-score of
33.07%, surpassing the previous best result by 7.84 percentage points (p.p.) on
the highly imbalanced Kvasir Capsule Dataset, a benchmark for capsule
endoscopy. To the best of our knowledge, this work is the first to apply a
fine-tuned Image Inpainting GAN for GDA in medical imaging, demonstrating that
an image-conditional GAN can be adapted effectively to limited datasets to
generate high-quality examples, facilitating effective data augmentation.
Additionally, we show that combining this GAN-based approach with classical
image processing techniques further enhances the results.

摘要：<paragraph>受限的醫學影像資料集會透過增加過度擬合的風險和降低概化能力，特別是在生成對抗網路 (GAN) 中，其中判別器可能會過度擬合，導致訓練分歧，對深度學習模型構成挑戰。這種限制也損害了在小型資料集上訓練的分類模型。生成資料擴充 (GDA) 透過使用合成資料擴充訓練資料集來解決此問題，儘管它需要訓練生成模型。我們提出並評估兩種局部病灶生成方法，以解決擴充小型醫學影像資料集的挑戰。第一種方法採用泊松影像編輯演算法，一種經典影像處理技術，來建立逼真的影像合成，其優於目前最先進的方法。第二種方法引進一種新穎的生成方法，利用微調的影像修復 GAN，在真實訓練影像的特定區域內合成逼真的病灶。對這兩種提議方法的全面比較證明，在資料受限的設定中，有效的局部病灶生成允許在膠囊內視鏡病灶分類中達到新的最先進結果。我們的技術組合在高度不平衡的 Kvasir Capsule 資料集（膠囊內視鏡的基準）上，達到了 33.07% 的巨觀 F1 分數，比先前的最佳結果高出 7.84 個百分點 (p.p.)。據我們所知，這項工作是第一個將微調的影像修復 GAN 應用於醫學影像中的 GDA，證明了影像條件 GAN 可以有效地適應受限的資料集，以產生高品質的範例，促進有效的資料擴充。此外，我們表明將這種基於 GAN 的方法與經典影像處理技術相結合，進一步增強了結果。</paragraph>

##### **HFGaussian: Learning Generalizable Gaussian Human with Integrated Human Features**
2411.03086v1 by Arnab Dey, Cheng-You Lu, Andrew I. Comport, Srinath Sridhar, Chin-Teng Lin, Jean Martinet

Recent advancements in radiance field rendering show promising results in 3D
scene representation, where Gaussian splatting-based techniques emerge as
state-of-the-art due to their quality and efficiency. Gaussian splatting is
widely used for various applications, including 3D human representation.
However, previous 3D Gaussian splatting methods either use parametric body
models as additional information or fail to provide any underlying structure,
like human biomechanical features, which are essential for different
applications. In this paper, we present a novel approach called HFGaussian that
can estimate novel views and human features, such as the 3D skeleton, 3D key
points, and dense pose, from sparse input images in real time at 25 FPS. The
proposed method leverages generalizable Gaussian splatting technique to
represent the human subject and its associated features, enabling efficient and
generalizable reconstruction. By incorporating a pose regression network and
the feature splatting technique with Gaussian splatting, HFGaussian
demonstrates improved capabilities over existing 3D human methods, showcasing
the potential of 3D human representations with integrated biomechanics. We
thoroughly evaluate our HFGaussian method against the latest state-of-the-art
techniques in human Gaussian splatting and pose estimation, demonstrating its
real-time, state-of-the-art performance.

摘要：近來輻照場域渲染的進展在 3D 場景表示中展現了令人振奮的成果，其中基於高斯散射的技術因其品質和效率而成為最先進的技術。高斯散射廣泛用於各種應用程式，包括 3D 人體表示。然而，先前的 3D 高斯散射方法不是將參數化身體模型用作額外資訊，就是無法提供任何基礎結構，例如人體生物力學特徵，而這些特徵對於不同的應用程式至關重要。在本文中，我們提出了一種稱為 HFGaussian 的新方法，它可以從稀疏輸入影像中即時估計新視圖和人體特徵，例如 3D 骨架、3D 關鍵點和密集姿勢，速度為 25 FPS。所提出的方法利用可概化的高斯散射技術來表示人體及其相關特徵，進而實現高效且可概化的重建。透過結合姿勢回歸網路和特徵散射技術與高斯散射，HFGaussian 展現出比現有人體 3D 方法更進步的能力，展示了整合生物力學的 3D 人體表示的潛力。我們徹底評估了我們的 HFGaussian 方法，並針對人體高斯散射和姿勢估計中的最新最先進技術，展示了其即時最先進的效能。

##### **Enhancing DP-SGD through Non-monotonous Adaptive Scaling Gradient Weight**
2411.03059v1 by Tao Huang, Qingyu Huang, Xin Shi, Jiayang Meng, Guolong Zheng, Xu Yang, Xun Yi

In the domain of deep learning, the challenge of protecting sensitive data
while maintaining model utility is significant. Traditional Differential
Privacy (DP) techniques such as Differentially Private Stochastic Gradient
Descent (DP-SGD) typically employ strategies like direct or per-sample adaptive
gradient clipping. These methods, however, compromise model accuracy due to
their critical influence on gradient handling, particularly neglecting the
significant contribution of small gradients during later training stages. In
this paper, we introduce an enhanced version of DP-SGD, named Differentially
Private Per-sample Adaptive Scaling Clipping (DP-PSASC). This approach replaces
traditional clipping with non-monotonous adaptive gradient scaling, which
alleviates the need for intensive threshold setting and rectifies the
disproportionate weighting of smaller gradients. Our contribution is twofold.
First, we develop a novel gradient scaling technique that effectively assigns
proper weights to gradients, particularly small ones, thus improving learning
under differential privacy. Second, we integrate a momentum-based method into
DP-PSASC to reduce bias from stochastic sampling, enhancing convergence rates.
Our theoretical and empirical analyses confirm that DP-PSASC preserves privacy
and delivers superior performance across diverse datasets, setting new
standards for privacy-sensitive applications.

摘要：在深度學習領域中，在保持模型效用的同時保護敏感資料的挑戰非常重要。傳統的差分隱私 (DP) 技術，例如差分私有隨機梯度下降 (DP-SGD)，通常採用直接或逐樣本自適應梯度裁剪等策略。然而，這些方法會影響梯度處理，特別是忽略後續訓練階段中較小梯度的顯著貢獻，進而影響模型準確度。在本文中，我們引入了 DP-SGD 的增強版本，稱為差分私有逐樣本自適應縮放裁剪 (DP-PSASC)。此方法以非單調自適應梯度縮放取代傳統裁剪，減輕了對密集閾值設定的需求，並修正了較小梯度的權重分配不均問題。我們的貢獻有兩個方面。首先，我們開發了一種新穎的梯度縮放技術，可有效地為梯度（特別是較小的梯度）分配適當的權重，從而改善差分隱私下的學習。其次，我們將基於動量的方​​法整合到 DP-PSASC 中，以減少隨機抽樣的偏差，並提高收斂速度。我們的理論和實證分析證實，DP-PSASC 保障了隱私，並在各種資料集上提供了卓越的效能，為隱私敏感應用程式設定了新的標準。

##### **ATM: Improving Model Merging by Alternating Tuning and Merging**
2411.03055v1 by Luca Zhou, Daniele Solombrino, Donato Crisostomi, Maria Sofia Bucarelli, Fabrizio Silvestri, Emanuele Rodolà

Model merging has recently emerged as a cost-efficient paradigm for
multi-task learning. Among current approaches, task arithmetic stands out for
its simplicity and effectiveness. In this paper, we motivate the effectiveness
of task vectors by linking them to multi-task gradients. We show that in a
single-epoch scenario, task vectors are mathematically equivalent to the
gradients obtained via gradient descent in a multi-task setting, and still
approximate these gradients in subsequent epochs. Furthermore, we show that
task vectors perform optimally when equality is maintained, and their
effectiveness is largely driven by the first epoch's gradient. Building on this
insight, we propose viewing model merging as a single step in an iterative
process that Alternates between Tuning and Merging (ATM). This method acts as a
bridge between model merging and multi-task gradient descent, achieving
state-of-the-art results with the same data and computational requirements. We
extensively evaluate ATM across diverse settings, achieving up to 20% higher
accuracy in computer vision and NLP tasks, compared to the best
baselines.Finally, we provide both empirical and theoretical support for its
effectiveness, demonstrating increased orthogonality between task vectors and
proving that ATM minimizes an upper bound on the loss obtained by jointly
finetuning all tasks.

摘要：模型合并最近已成为多任务学习中一种经济高效的范例。在当前方法中，任务算术因其简单性和有效性而脱颖而出。在本文中，我们通过将任务向量与多任务梯度联系起来，激发了任务向量的有效性。我们表明，在单次迭代的情况下，任务向量在数学上等效于在多任务设置中通过梯度下降获得的梯度，并且在后续迭代中仍然近似于这些梯度。此外，我们表明，当维护相等性时，任务向量执行得最佳，并且它们的有效性在很大程度上是由第一个迭代的梯度驱动的。基于这一见解，我们建议将模型合并视为在交替调整和合并 (ATM) 的迭代过程中采取的单一步骤。此方法充当了模型合并和多任务梯度下降之间的桥梁，在相同的数据和计算需求下实现了最先进的结果。我们对 ATM 在不同设置中进行了广泛评估，与最佳基线相比，在计算机视觉和 NLP 任务中实现了高达 20% 的更高准确度。最后，我们为其有效性提供了经验和理论支持，证明了任务向量之间的正交性增加，并证明 ATM 最小化了通过联合微调所有任务获得的损失的上限。

##### **Gradient-Guided Conditional Diffusion Models for Private Image Reconstruction: Analyzing Adversarial Impacts of Differential Privacy and Denoising**
2411.03053v1 by Tao Huang, Jiayang Meng, Hong Chen, Guolong Zheng, Xu Yang, Xun Yi, Hua Wang

We investigate the construction of gradient-guided conditional diffusion
models for reconstructing private images, focusing on the adversarial interplay
between differential privacy noise and the denoising capabilities of diffusion
models. While current gradient-based reconstruction methods struggle with
high-resolution images due to computational complexity and prior knowledge
requirements, we propose two novel methods that require minimal modifications
to the diffusion model's generation process and eliminate the need for prior
knowledge. Our approach leverages the strong image generation capabilities of
diffusion models to reconstruct private images starting from randomly generated
noise, even when a small amount of differentially private noise has been added
to the gradients. We also conduct a comprehensive theoretical analysis of the
impact of differential privacy noise on the quality of reconstructed images,
revealing the relationship among noise magnitude, the architecture of attacked
models, and the attacker's reconstruction capability. Additionally, extensive
experiments validate the effectiveness of our proposed methods and the accuracy
of our theoretical findings, suggesting new directions for privacy risk
auditing using conditional diffusion models.

摘要：我們探討了用於重建私人影像的梯度引導條件擴散模型的建構，重點在於差分隱私雜訊與擴散模型的去雜訊能力之間的對抗性交互作用。雖然當前的基於梯度的重建方法因計算複雜度和先驗知識需求而難以處理高解析度影像，我們提出了兩種新穎的方法，它們只需要對擴散模型的生成過程進行最小的修改，並消除了對先驗知識的需求。我們的做法利用了擴散模型強大的影像生成能力，從隨機產生的雜訊重建私人影像，即使在梯度中加入了少量的差分隱私雜訊也是如此。我們也對差分隱私雜訊對重建影像品質的影響進行了全面的理論分析，揭示了雜訊大小、受攻擊模型的架構和攻擊者的重建能力之間的關係。此外，廣泛的實驗驗證了我們提出的方法的有效性以及我們理論發現的準確性，這為使用條件擴散模型進行隱私風險稽核提出了新的方向。

##### **Predictor-Corrector Enhanced Transformers with Exponential Moving Average Coefficient Learning**
2411.03042v1 by Bei Li, Tong Zheng, Rui Wang, Jiahao Liu, Qingyan Guo, Junliang Guo, Xu Tan, Tong Xiao, Jingbo Zhu, Jingang Wang, Xunliang Cai

Residual networks, as discrete approximations of Ordinary Differential
Equations (ODEs), have inspired significant advancements in neural network
design, including multistep methods, high-order methods, and multi-particle
dynamical systems. The precision of the solution to ODEs significantly affects
parameter optimization, thereby impacting model performance. In this work, we
present a series of advanced explorations of Transformer architecture design to
minimize the error compared to the true ``solution.'' First, we introduce a
predictor-corrector learning framework to minimize truncation errors, which
consists of a high-order predictor and a multistep corrector. Second, we
propose an exponential moving average-based coefficient learning method to
strengthen our higher-order predictor. Extensive experiments on large-scale
machine translation, abstractive summarization, language modeling, and natural
language understanding benchmarks demonstrate the superiority of our approach.
On the WMT'14 English-German and English-French tasks, our model achieved BLEU
scores of 30.95 and 44.27, respectively. Furthermore, on the OPUS multilingual
machine translation task, our model surpasses a robust 3.8B DeepNet by an
average of 2.9 SacreBLEU, using only 1/3 parameters. Notably, it also beats
LLama models by 5.7 accuracy points on the LM Harness Evaluation.

摘要：殘差網路，作為常微分方程式 (ODE) 的離散近似，激發了神經網路設計的重大進展，包括多步法、高階方法和多粒子動力系統。ODE 解的精度會顯著影響參數最佳化，進而影響模型效能。在這項工作中，我們提出了一系列進階的 Transformer 架構設計探索，以最小化與真實「解」的誤差。首先，我們引入一個預測校正學習架構來最小化截斷誤差，其中包含一個高階預測器和一個多步校正器。其次，我們提出一個基於指數移動平均的係數學習方法，以強化我們的高階預測器。在大型機器翻譯、抽象摘要、語言建模和自然語言理解基準上的廣泛實驗證明了我們方法的優越性。在 WMT'14 英德和英法任務中，我們的模型分別達到了 30.95 和 44.27 的 BLEU 分數。此外，在 OPUS 多語言機器翻譯任務中，我們的模型僅使用 1/3 的參數，就超越了強大的 3.8B DeepNet，平均高出 2.9 SacreBLEU。值得注意的是，它還在 LM Harness Evaluation 上比 LLama 模型高出 5.7 個準確度點。

##### **Self-Compositional Data Augmentation for Scientific Keyphrase Generation**
2411.03039v1 by Mael Houbre, Florian Boudin, Beatrice Daille, Akiko Aizawa

State-of-the-art models for keyphrase generation require large amounts of
training data to achieve good performance. However, obtaining keyphrase-labeled
documents can be challenging and costly. To address this issue, we present a
self-compositional data augmentation method. More specifically, we measure the
relatedness of training documents based on their shared keyphrases, and combine
similar documents to generate synthetic samples. The advantage of our method
lies in its ability to create additional training samples that keep domain
coherence, without relying on external data or resources. Our results on
multiple datasets spanning three different domains, demonstrate that our method
consistently improves keyphrase generation. A qualitative analysis of the
generated keyphrases for the Computer Science domain confirms this improvement
towards their representativity property.

摘要：最先進的關鍵字生成模型需要大量訓練資料才能達到良好的效能。然而，取得標有關鍵字的文檔具有挑戰性且成本高昂。為了解決這個問題，我們提出一個自組成資料擴充方法。更具體地說，我們根據訓練文件共有的關鍵字來衡量它們的關聯性，並結合類似的文件來產生合成樣本。我們的方法的優點在於它能夠建立額外的訓練樣本，這些樣本保持領域一致性，而不需要依賴外部資料或資源。我們在跨越三個不同領域的多個資料集上的結果表明，我們的方法持續改善關鍵字生成。對電腦科學領域所生成關鍵字的定性分析確認了這種改善朝向它們的代表性屬性。

##### **HumanVLM: Foundation for Human-Scene Vision-Language Model**
2411.03034v1 by Dawei Dai, Xu Long, Li Yutang, Zhang Yuanhui, Shuyin Xia

Human-scene vision-language tasks are increasingly prevalent in diverse
social applications, yet recent advancements predominantly rely on models
specifically tailored to individual tasks. Emerging research indicates that
large vision-language models (VLMs) can enhance performance across various
downstream vision-language understanding tasks. However, general-domain models
often underperform in specialized fields. This study introduces a
domain-specific Large Vision-Language Model, Human-Scene Vision-Language Model
(HumanVLM), designed to provide a foundation for human-scene Vision-Language
tasks. Specifically, (1) we create a large-scale human-scene multimodal
image-text dataset (HumanCaption-10M) sourced from the Internet to facilitate
domain-specific alignment; (2) develop a captioning approach for human-centered
images, capturing human faces, bodies, and backgrounds, and construct a
high-quality Human-Scene image-text dataset (HumanCaptionHQ, about 311k pairs)
that contain as much detailed information as possible about human; (3) Using
HumanCaption-10M and HumanCaptionHQ, we train a HumanVLM. In the experiments,
we then evaluate our HumanVLM across varous downstream tasks, where it
demonstrates superior overall performance among multimodal models of comparable
scale, particularly excelling in human-related tasks and significantly
outperforming similar models, including Qwen2VL and ChatGPT-4o. HumanVLM,
alongside the data introduced, will stimulate the research in human-around
fields.

摘要：<paragraph>人景視覺語言任務在多元的社交應用中越來越普遍，但近期的進展主要依賴於專門針對個別任務量身打造的模型。新興的研究指出，大型視覺語言模型 (VLM) 可以提升各種下游視覺語言理解任務的效能。然而，一般領域模型在專業領域中常常表現不佳。本研究介紹一種特定領域的大型視覺語言模型，人景視覺語言模型 (HumanVLM)，旨在為人景視覺語言任務提供基礎。具體來說，(1) 我們創建一個從網際網路取得的大型人景多模態影像文字資料集 (HumanCaption-10M)，以利特定領域的對齊；(2) 為以人為中心的影像開發一種標題方法，擷取人臉、身體和背景，並建構一個高品質的人景影像文字資料集 (HumanCaptionHQ，約 311k 對)，其中包含盡可能多的人類詳細資訊；(3) 使用 HumanCaption-10M 和 HumanCaptionHQ，我們訓練了一個 HumanVLM。在實驗中，我們接著評估我們的 HumanVLM 橫跨各種下游任務，它在同等規模的多模態模型中展現出卓越的整體表現，特別是在與人類相關的任務中表現傑出，且大幅優於類似的模型，包括 Qwen2VL 和 ChatGPT-4o。HumanVLM 連同所引入的資料，將會激勵人景領域的研究。</paragraph>

##### **DA-MoE: Addressing Depth-Sensitivity in Graph-Level Analysis through Mixture of Experts**
2411.03025v1 by Zelin Yao, Chuang Liu, Xianke Meng, Yibing Zhan, Jia Wu, Shirui Pan, Wenbin Hu

Graph neural networks (GNNs) are gaining popularity for processing
graph-structured data. In real-world scenarios, graph data within the same
dataset can vary significantly in scale. This variability leads to
depth-sensitivity, where the optimal depth of GNN layers depends on the scale
of the graph data. Empirically, fewer layers are sufficient for message passing
in smaller graphs, while larger graphs typically require deeper networks to
capture long-range dependencies and global features. However, existing methods
generally use a fixed number of GNN layers to generate representations for all
graphs, overlooking the depth-sensitivity issue in graph structure data. To
address this challenge, we propose the depth adaptive mixture of expert
(DA-MoE) method, which incorporates two main improvements to GNN backbone:
\textbf{1)} DA-MoE employs different GNN layers, each considered an expert with
its own parameters. Such a design allows the model to flexibly aggregate
information at different scales, effectively addressing the depth-sensitivity
issue in graph data. \textbf{2)} DA-MoE utilizes GNN to capture the structural
information instead of the linear projections in the gating network. Thus, the
gating network enables the model to capture complex patterns and dependencies
within the data. By leveraging these improvements, each expert in DA-MoE
specifically learns distinct graph patterns at different scales. Furthermore,
comprehensive experiments on the TU dataset and open graph benchmark (OGB) have
shown that DA-MoE consistently surpasses existing baselines on various tasks,
including graph, node, and link-level analyses. The code are available at
\url{https://github.com/Celin-Yao/DA-MoE}.

摘要：圖形神經網路 (GNN) 在處理圖形結構資料方面越來越受歡迎。在真實世界的場景中，同一個資料集內的圖形資料在規模上可能會有顯著的差異。這種變異性會導致深度敏感性，其中 GNN 層的最佳深度取決於圖形資料的規模。根據經驗，較小的圖形在訊息傳遞中需要較少的層，而較大的圖形通常需要更深的網路來擷取長距離依賴關係和全域特徵。然而，現有方法通常使用固定數量的 GNN 層來為所有圖形產生表示，忽略了圖形結構資料中的深度敏感性問題。為了應對這個挑戰，我們提出了深度自適應專家混合 (DA-MoE) 方法，該方法對 GNN 骨幹進行了兩項主要改進：
**1) ** DA-MoE 使用不同的 GNN 層，每個層都被視為一個具有自己參數的專家。這種設計允許模型靈活地彙總不同規模的資訊，有效地解決了圖形資料中的深度敏感性問題。**2) ** DA-MoE 利用 GNN 擷取結構資訊，而不是閘控網路中的線性投影。因此，閘控網路使模型能夠擷取資料中的複雜模式和依賴關係。透過利用這些改進，DA-MoE 中的每個專家都能特別學習不同規模的特定圖形模式。此外，在 TU 資料集和開放圖形基準 (OGB) 上進行的全面實驗表明，DA-MoE 在各種任務上都持續超越現有的基準，包括圖形、節點和連結層級分析。程式碼可在
\url{https://github.com/Celin-Yao/DA-MoE} 取得。

##### **Flashy Backdoor: Real-world Environment Backdoor Attack on SNNs with DVS Cameras**
2411.03022v1 by Roberto Riaño, Gorka Abad, Stjepan Picek, Aitor Urbieta

While security vulnerabilities in traditional Deep Neural Networks (DNNs)
have been extensively studied, the susceptibility of Spiking Neural Networks
(SNNs) to adversarial attacks remains mostly underexplored. Until now, the
mechanisms to inject backdoors into SNN models have been limited to digital
scenarios; thus, we present the first evaluation of backdoor attacks in
real-world environments.
  We begin by assessing the applicability of existing digital backdoor attacks
and identifying their limitations for deployment in physical environments. To
address each of the found limitations, we present three novel backdoor attack
methods on SNNs, i.e., Framed, Strobing, and Flashy Backdoor. We also assess
the effectiveness of traditional backdoor procedures and defenses adapted for
SNNs, such as pruning, fine-tuning, and fine-pruning. The results show that
while these procedures and defenses can mitigate some attacks, they often fail
against stronger methods like Flashy Backdoor or sacrifice too much clean
accuracy, rendering the models unusable.
  Overall, all our methods can achieve up to a 100% Attack Success Rate while
maintaining high clean accuracy in every tested dataset. Additionally, we
evaluate the stealthiness of the triggers with commonly used metrics, finding
them highly stealthy. Thus, we propose new alternatives more suited for
identifying poisoned samples in these scenarios. Our results show that further
research is needed to ensure the security of SNN-based systems against backdoor
attacks and their safe application in real-world scenarios. The code,
experiments, and results are available in our repository.

摘要：<paragraph>儘管傳統深度神經網路 (DNN) 中的安全漏洞已經廣泛研究，但尖峰神經網路 (SNN) 對抗攻擊的敏感性仍未充分探討。到目前為止，將後門注入 SNN 模型的機制僅限於數位場景；因此，我們提出在真實環境中對後門攻擊的首次評估。
我們從評估現有數位後門攻擊的適用性開始，並找出它們在物理環境中部署的限制。為了解決每個發現的限制，我們提出三種針對 SNN 的新型後門攻擊方法，即 Framed、Strobing 和 Flashy Backdoor。我們還評估了針對 SNN 調整的傳統後門程序和防禦措施的有效性，例如修剪、微調和精修剪。結果表明，儘管這些程序和防禦措施可以減輕一些攻擊，但它們通常會對 Flashy Backdoor 等更強大的方法失效，或犧牲太多乾淨的準確度，使模型無法使用。
總體而言，我們的所有方法都可以在每個測試資料集中保持高乾淨準確度的同時，達到高達 100% 的攻擊成功率。此外，我們使用常用的指標評估觸發器的隱蔽性，發現它們高度隱蔽。因此，我們提出了更適合在這些場景中識別中毒樣本的新替代方案。我們的結果表明，需要進一步的研究來確保基於 SNN 的系統對後門攻擊的安全性，以及它們在真實場景中的安全應用。程式碼、實驗和結果可在我們的儲存庫中取得。</paragraph>

##### **Leveraging Large Language Models in Code Question Answering: Baselines and Issues**
2411.03012v1 by Georgy Andryushchenko, Vladimir Ivanov, Vladimir Makharev, Elizaveta Tukhtina, Aidar Valeev

Question answering over source code provides software engineers and project
managers with helpful information about the implemented features of a software
product. This paper presents a work devoted to using large language models for
question answering over source code in Python. The proposed method for
implementing a source code question answering system involves fine-tuning a
large language model on a unified dataset of questions and answers for Python
code. To achieve the highest quality answers, we tested various models trained
on datasets preprocessed in different ways: a dataset without grammar
correction, a dataset with grammar correction, and a dataset augmented with the
generated summaries. The model answers were also analyzed for errors manually.
We report BLEU-4, BERTScore F1, BLEURT, and Exact Match metric values, along
with the conclusions from the manual error analysis. The obtained experimental
results highlight the current problems of the research area, such as poor
quality of the public genuine question-answering datasets. In addition, the
findings include the positive effect of the grammar correction of the training
data on the testing metric values. The addressed findings and issues could be
important for other researchers who attempt to improve the quality of source
code question answering solutions. The training and evaluation code is publicly
available at https://github.com/IU-AES-AI4Code/CodeQuestionAnswering.

摘要：<paragraph>透過原始碼進行問答，可為軟體工程師和專案經理提供有關軟體產品實作功能的實用資訊。本論文提出了一項致力於使用大型語言模型，針對 Python 中的原始碼進行問答的工作。實作原始碼問答系統的建議方法，包括針對 Python 程式碼的統一式問題和答案資料集，微調大型語言模型。為了獲得最高品質的答案，我們測試了在以不同方式預處理的資料集上訓練的各種模型：未經文法修正的資料集、已進行文法修正的資料集，以及透過產生的摘要增強的資料集。模型答案也經過人工分析錯誤。我們報告了 BLEU-4、BERTScore F1、BLEURT 和完全比對的指標值，以及人工錯誤分析的結論。獲得的實驗結果突顯了研究領域的現有問題，例如公開的真實問答資料集品質不佳。此外，研究結果包括訓練資料的文法修正對測試指標值的正面影響。所探討的研究結果和議題，對於嘗試改善原始碼問答解決方案品質的其他研究人員而言，可能非常重要。訓練和評估程式碼已公開於 https://github.com/IU-AES-AI4Code/CodeQuestionAnswering。</paragraph>

##### **Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status**
2411.03004v1 by Samuel Lee, Zach Wood-Doughty

Causal understanding is a fundamental goal of evidence-based medicine. When
randomization is impossible, causal inference methods allow the estimation of
treatment effects from retrospective analysis of observational data. However,
such analyses rely on a number of assumptions, often including that of no
unobserved confounding. In many practical settings, this assumption is violated
when important variables are not explicitly measured in the clinical record.
Prior work has proposed to address unobserved confounding with machine learning
by imputing unobserved variables and then correcting for the classifier's
mismeasurement. When such a classifier can be trained and the necessary
assumptions are met, this method can recover an unbiased estimate of a causal
effect. However, such work has been limited to synthetic data, simple
classifiers, and binary variables. This paper extends this methodology by using
a large language model trained on clinical notes to predict patients' smoking
status, which would otherwise be an unobserved confounder. We then apply a
measurement error correction on the categorical predicted smoking status to
estimate the causal effect of transthoracic echocardiography on mortality in
the MIMIC dataset.

摘要：因果理解是循证医学的基本目标。当随机化不可行时，因果推论方法允许从观察性数据的回顾性分析中估计治疗效果。然而，此类分析依赖于许多假设，通常包括没有未观察到的混杂因素。在许多实际情况下，当重要的变量在临床记录中没有明确测量时，这一假设就会被违反。先前的工作提出用机器学习来解决未观察到的混杂问题，方法是推算未观察到的变量，然后校正分类器的测量误差。当可以训练这样的分类器并且满足必要的假设时，这种方法可以恢复因果效应的无偏估计。然而，此类工作仅限于合成数据、简单的分类器和二元变量。本文通过使用在临床记录上训练的大语言模型来预测患者的吸烟状况来扩展这种方法，否则这将是一个未观察到的混杂因素。然后，我们对分类预测的吸烟状态应用测量误差校正，以估计经胸超声心动图对 MIMIC 数据集中死亡率的因果效应。

##### **SUDS: A Strategy for Unsupervised Drift Sampling**
2411.02995v1 by Christofer Fellicious, Lorenz Wendlinger, Mario Gancarski, Jelena Mitrovic, Michael Granitzer

Supervised machine learning often encounters concept drift, where the data
distribution changes over time, degrading model performance. Existing drift
detection methods focus on identifying these shifts but often overlook the
challenge of acquiring labeled data for model retraining after a shift occurs.
We present the Strategy for Drift Sampling (SUDS), a novel method that selects
homogeneous samples for retraining using existing drift detection algorithms,
thereby enhancing model adaptability to evolving data. SUDS seamlessly
integrates with current drift detection techniques. We also introduce the
Harmonized Annotated Data Accuracy Metric (HADAM), a metric that evaluates
classifier performance in relation to the quantity of annotated data required
to achieve the stated performance, thereby taking into account the difficulty
of acquiring labeled data. Our contributions are twofold: SUDS combines drift
detection with strategic sampling to improve the retraining process, and HADAM
provides a metric that balances classifier performance with the amount of
labeled data, ensuring efficient resource utilization. Empirical results
demonstrate the efficacy of SUDS in optimizing labeled data use in dynamic
environments, significantly improving the performance of machine learning
applications in real-world scenarios. Our code is open source and available at
https://github.com/cfellicious/SUDS/

摘要：監督式機器學習經常會遇到概念漂移，資料分佈會隨著時間改變，降低模型效能。現有的漂移偵測方法專注於辨識這些轉變，但常常忽略在轉變發生後取得標籤資料以重新訓練模型的挑戰。我們提出漂移抽樣策略 (SUDS)，這是一種新方法，它使用現有的漂移偵測演算法選擇同質樣本用於重新訓練，從而增強模型對演化資料的適應性。SUDS 無縫整合到目前的漂移偵測技術中。我們還引入了和諧化註解資料準確性指標 (HADAM)，這是一個指標，它評估分類器效能與達成所述效能所需的註解資料數量之間的關係，從而考量到取得標籤資料的難度。我們的貢獻有兩個方面：SUDS 結合漂移偵測與策略取樣以改善重新訓練程序，而 HADAM 提供了一個指標，該指標平衡分類器效能與標籤資料的數量，確保有效率地利用資源。實證結果證明了 SUDS 在動態環境中最佳化標籤資料使用的效能，顯著改善機器學習應用程式在真實世界場景中的效能。我們的程式碼是開放原始碼，可在 https://github.com/cfellicious/SUDS/ 取得

##### **Growing a Tail: Increasing Output Diversity in Large Language Models**
2411.02989v1 by Michal Shur-Ofry, Bar Horowitz-Amsalem, Adir Rahamim, Yonatan Belinkov

How diverse are the outputs of large language models when diversity is
desired? We examine the diversity of responses of various models to questions
with multiple possible answers, comparing them with human responses. Our
findings suggest that models' outputs are highly concentrated, reflecting a
narrow, mainstream 'worldview', in comparison to humans, whose responses
exhibit a much longer-tail. We examine three ways to increase models' output
diversity: 1) increasing generation randomness via temperature sampling; 2)
prompting models to answer from diverse perspectives; 3) aggregating outputs
from several models. A combination of these measures significantly increases
models' output diversity, reaching that of humans. We discuss implications of
these findings for AI policy that wishes to preserve cultural diversity, an
essential building block of a democratic social fabric.

摘要：當需要多樣性時，大型語言模型的輸出有多麼多樣化？我們檢視各種模型對具有多種可能答案問題的回應的多樣性，並將它們與人類的回應進行比較。我們的發現表明，與人類相比，模型的輸出高度集中，反映了一個狹窄的主流“世界觀”，而人類的回應表現出更長的尾部。我們探討了增加模型輸出多樣性的三種方法：1）通過溫度採樣增加生成隨機性；2）提示模型從不同的角度回答；3）彙總來自多個模型的輸出。這些措施的組合顯著增加了模型的輸出多樣性，達到了人類的水平。我們討論了這些發現對希望維護文化多樣性的 AI 政策的影響，文化多樣性是民主社會結構的基本組成部分。

##### **Confidence Calibration of Classifiers with Many Classes**
2411.02988v1 by Adrien Le Coz, Stéphane Herbin, Faouzi Adjed

For classification models based on neural networks, the maximum predicted
class probability is often used as a confidence score. This score rarely
predicts well the probability of making a correct prediction and requires a
post-processing calibration step. However, many confidence calibration methods
fail for problems with many classes. To address this issue, we transform the
problem of calibrating a multiclass classifier into calibrating a single
surrogate binary classifier. This approach allows for more efficient use of
standard calibration methods. We evaluate our approach on numerous neural
networks used for image or text classification and show that it significantly
enhances existing calibration methods.

摘要：對於基於神經網路的分類模型，最大預測類別機率通常用作信心分數。此分數很少能很好地預測出做出正確預測的機率，而且需要後處理校正步驟。然而，許多信心校正方法對於有許多類別的問題會失敗。為了解決這個問題，我們將校正多類別分類器的問題轉換成校正單一替代二元分類器。這種方法允許更有效率地使用標準校正方法。我們針對用於圖像或文字分類的許多神經網路評估我們的方法，並顯示出它顯著地增強了現有的校正方法。

##### **Autonomous Decision Making for UAV Cooperative Pursuit-Evasion Game with Reinforcement Learning**
2411.02983v1 by Yang Zhao, Zidong Nie, Kangsheng Dong, Qinghua Huang, Xuelong Li

The application of intelligent decision-making in unmanned aerial vehicle
(UAV) is increasing, and with the development of UAV 1v1 pursuit-evasion game,
multi-UAV cooperative game has emerged as a new challenge. This paper proposes
a deep reinforcement learning-based model for decision-making in multi-role UAV
cooperative pursuit-evasion game, to address the challenge of enabling UAV to
autonomously make decisions in complex game environments. In order to enhance
the training efficiency of the reinforcement learning algorithm in UAV
pursuit-evasion game environment that has high-dimensional state-action space,
this paper proposes multi-environment asynchronous double deep Q-network with
priority experience replay algorithm to effectively train the UAV's game
policy. Furthermore, aiming to improve cooperation ability and task completion
efficiency, as well as minimize the cost of UAVs in the pursuit-evasion game,
this paper focuses on the allocation of roles and targets within multi-UAV
environment. The cooperative game decision model with varying numbers of UAVs
are obtained by assigning diverse tasks and roles to the UAVs in different
scenarios. The simulation results demonstrate that the proposed method enables
autonomous decision-making of the UAVs in pursuit-evasion game scenarios and
exhibits significant capabilities in cooperation.

摘要：無人機 (UAV) 中智慧決策的應用逐漸增加，且隨著無人機 1 對 1 追逐迴避遊戲的發展，多無人機合作遊戲已成為新的挑戰。本文針對無人機在複雜遊戲環境中自主決策的挑戰，提出一個基於深度強化學習的模型，用於多角色無人機合作追逐迴避遊戲中的決策。為了提升無人機追逐迴避遊戲環境中強化學習演算法的訓練效率，本文提出多環境非同步雙重深度 Q 網路，搭配優先經驗回放演算法，有效訓練無人機的遊戲策略。此外，本文著重於多無人機環境中的角色與目標分配，以提升合作能力與任務完成效率，並最小化無人機在追逐迴避遊戲中的成本。透過賦予無人機不同情境中的不同任務與角色，得到不同數量無人機的合作遊戲決策模型。模擬結果顯示，所提出的方法能讓無人機在追逐迴避遊戲情境中自主決策，且展現出顯著的合作能力。

##### **Region-Guided Attack on the Segment Anything Model (SAM)**
2411.02974v1 by Xiaoliang Liu, Furao Shen, Jian Zhao

The Segment Anything Model (SAM) is a cornerstone of image segmentation,
demonstrating exceptional performance across various applications, particularly
in autonomous driving and medical imaging, where precise segmentation is
crucial. However, SAM is vulnerable to adversarial attacks that can
significantly impair its functionality through minor input perturbations.
Traditional techniques, such as FGSM and PGD, are often ineffective in
segmentation tasks due to their reliance on global perturbations that overlook
spatial nuances. Recent methods like Attack-SAM-K and UAD have begun to address
these challenges, but they frequently depend on external cues and do not fully
leverage the structural interdependencies within segmentation processes. This
limitation underscores the need for a novel adversarial strategy that exploits
the unique characteristics of segmentation tasks. In response, we introduce the
Region-Guided Attack (RGA), designed specifically for SAM. RGA utilizes a
Region-Guided Map (RGM) to manipulate segmented regions, enabling targeted
perturbations that fragment large segments and expand smaller ones, resulting
in erroneous outputs from SAM. Our experiments demonstrate that RGA achieves
high success rates in both white-box and black-box scenarios, emphasizing the
need for robust defenses against such sophisticated attacks. RGA not only
reveals SAM's vulnerabilities but also lays the groundwork for developing more
resilient defenses against adversarial threats in image segmentation.

摘要：分段任何模型 (SAM) 是影像分段的基石，在各種應用中展現出色的效能，特別是在自動駕駛和醫學影像中，精確分段至關重要。然而，SAM 容易受到對抗性攻擊，這種攻擊會透過微小的輸入擾動顯著損害其功能。傳統技術，例如 FGSM 和 PGD，由於依賴會忽略空間細微差的全局擾動，因此在分段任務中常常無效。最近的方法，例如 Attack-SAM-K 和 UAD，已開始解決這些挑戰，但它們經常依賴外部提示，且無法充分利用分段過程中結構上的相互依賴性。這種限制凸顯了需要一種新的對抗策略，以利用分段任務的獨特特性。為了解決此問題，我們引入了專門為 SAM 設計的區域引導攻擊 (RGA)。RGA 利用區域引導地圖 (RGM) 來操作分段區域，進而針對擾動進行調整，將大型分段切成片段，並擴展較小的分段，導致 SAM 產生錯誤輸出。我們的實驗證明，RGA 在白盒和黑盒場景中都能達到高成功率，強調了需要針對此類複雜攻擊採取強而有力的防禦措施。RGA 不僅揭露了 SAM 的漏洞，也為在影像分段中針對對抗性威脅開發更具韌性的防禦措施奠定了基礎。

##### **[Vision Paper] PRObot: Enhancing Patient-Reported Outcome Measures for Diabetic Retinopathy using Chatbots and Generative AI**
2411.02973v1 by Maren Pielka, Tobias Schneider, Jan Terheyden, Rafet Sifa

We present an outline of the first large language model (LLM) based chatbot
application in the context of patient-reported outcome measures (PROMs) for
diabetic retinopathy. By utilizing the capabilities of current LLMs, we enable
patients to provide feedback about their quality of life and treatment progress
via an interactive application. The proposed framework offers significant
advantages over the current approach, which encompasses only qualitative
collection of survey data or a static survey with limited answer options. Using
the PROBot LLM-PROM application, patients will be asked tailored questions
about their individual challenges, and can give more detailed feedback on the
progress of their treatment. Based on this input, we will use machine learning
to infer conventional PROM scores, which can be used by clinicians to evaluate
the treatment status. The goal of the application is to improve adherence to
the healthcare system and treatments, and thus ultimately reduce cases of
subsequent vision impairment. The approach needs to be further validated using
a survey and a clinical study.

摘要：我們提出一個基於第一個大型語言模型 (LLM) 的聊天機器人應用程式，用於糖尿病視網膜病變的病人回報結果測量 (PROM)。透過利用當前 LLM 的功能，我們讓病人能夠透過互動式應用程式提供有關其生活品質和治療進度的回饋。所提出的架構提供顯著優於目前方法的優點，目前方法僅包含調查資料的質性收集或具有有限答案選項的靜態調查。使用 PROBot LLM-PROM 應用程式，病人將會被詢問有關其個人挑戰的客製化問題，並能提供更詳細的回饋，說明其治療進度。根據此輸入，我們將使用機器學習推論傳統 PROM 分數，臨床醫生可以使用這些分數來評估治療狀態。此應用程式的目標是改善對醫療保健系統和治療的依從性，並因此最終減少後續視力損害的病例。需要使用調查和臨床研究進一步驗證此方法。

##### **Speaker Emotion Recognition: Leveraging Self-Supervised Models for Feature Extraction Using Wav2Vec2 and HuBERT**
2411.02964v1 by Pourya Jafarzadeh, Amir Mohammad Rostami, Padideh Choobdar

Speech is the most natural way of expressing ourselves as humans. Identifying
emotion from speech is a nontrivial task due to the ambiguous definition of
emotion itself. Speaker Emotion Recognition (SER) is essential for
understanding human emotional behavior. The SER task is challenging due to the
variety of speakers, background noise, complexity of emotions, and speaking
styles. It has many applications in education, healthcare, customer service,
and Human-Computer Interaction (HCI). Previously, conventional machine learning
methods such as SVM, HMM, and KNN have been used for the SER task. In recent
years, deep learning methods have become popular, with convolutional neural
networks and recurrent neural networks being used for SER tasks. The input of
these methods is mostly spectrograms and hand-crafted features. In this work,
we study the use of self-supervised transformer-based models, Wav2Vec2 and
HuBERT, to determine the emotion of speakers from their voice. The models
automatically extract features from raw audio signals, which are then used for
the classification task. The proposed solution is evaluated on reputable
datasets, including RAVDESS, SHEMO, SAVEE, AESDD, and Emo-DB. The results show
the effectiveness of the proposed method on different datasets. Moreover, the
model has been used for real-world applications like call center conversations,
and the results demonstrate that the model accurately predicts emotions.

摘要：語音表達是我們人類最自然的方式。由於情緒本身的定義模稜兩可，因此從語音中辨識情緒是一項非平凡的任務。說話者情緒辨識 (SER) 對於理解人類的情緒行為至關重要。SER 任務具有挑戰性，原因在於說話者的多樣性、背景噪音、情緒的複雜性以及說話風格。它在教育、醫療保健、客戶服務和人機互動 (HCI) 中有許多應用。以前，傳統的機器學習方法（例如 SVM、HMM 和 KNN）已用於 SER 任務。近年來，深度學習方法已變得流行，卷積神經網路和遞迴神經網路被用於 SER 任務。這些方法的輸入主要是語譜圖和手工製作的特徵。在這項工作中，我們研究了使用自我監督的基於Transformer的模型 Wav2Vec2 和 HuBERT，從說話者的聲音中確定其情緒。這些模型會自動從原始音訊訊號中提取特徵，然後將其用於分類任務。所提出的解決方案在信譽良好的資料集上進行評估，包括 RAVDESS、SHEMO、SAVEE、AESDD 和 Emo-DB。結果顯示了所提出的方法在不同資料集上的有效性。此外，該模型已用於呼叫中心對話等實際應用，結果表明該模型可以準確預測情緒。

##### **Grounding Natural Language to SQL Translation with Data-Based Self-Explanations**
2411.02948v1 by Yuankai Fan, Tonghui Ren, Can Huang, Zhenying He, X. Sean Wang

Natural Language Interfaces for Databases empower non-technical users to
interact with data using natural language (NL). Advanced approaches, utilizing
either neural sequence-to-sequence or more recent sophisticated large-scale
language models, typically implement NL to SQL (NL2SQL) translation in an
end-to-end fashion. However, like humans, these end-to-end translation models
may not always generate the best SQL output on their first try. In this paper,
we propose CycleSQL, an iterative framework designed for end-to-end translation
models to autonomously generate the best output through self-evaluation. The
main idea of CycleSQL is to introduce data-grounded NL explanations of query
results as self-provided feedback, and use the feedback to validate the
correctness of the translation iteratively, hence improving the overall
translation accuracy. Extensive experiments, including quantitative and
qualitative evaluations, are conducted to study CycleSQL by applying it to
seven existing translation models on five widely used benchmarks. The results
show that 1) the feedback loop introduced in CycleSQL can consistently improve
the performance of existing models, and in particular, by applying CycleSQL to
RESDSQL, obtains a translation accuracy of 82.0% (+2.6%) on the validation set,
and 81.6% (+3.2%) on the test set of Spider benchmark; 2) the generated NL
explanations can also provide insightful information for users, aiding in the
comprehension of translation results and consequently enhancing the
interpretability of NL2SQL translation.

摘要：<paragraph>資料庫的自然語言介面讓非技術使用者能使用自然語言 (NL) 與資料互動。進階方法利用神經序列對序列或更新、更精密的、大規模語言模型，通常以端對端的方式實作 NL 至 SQL (NL2SQL) 翻譯。然而，如同人類，這些端對端翻譯模型在第一次嘗試時可能無法總是產生最佳的 SQL 輸出。在本文中，我們提出 CycleSQL，一種反覆運算架構，設計用於讓端對端翻譯模型透過自我評估自主產生最佳輸出。CycleSQL 的主要概念是引入資料為基礎的 NL 查詢結果說明作為自我提供的回饋，並使用回饋反覆驗證翻譯的正確性，因此提升整體翻譯準確度。我們進行廣泛的實驗，包括量化和質化評估，透過將 CycleSQL 套用到五個廣泛使用的基準上的七種現有翻譯模型來研究 CycleSQL。結果顯示 1) CycleSQL 中引入的回饋迴路能夠持續提升現有模型的效能，特別是，透過將 CycleSQL 套用到 RESDSQL，在 Spider 基準的驗證組上取得 82.0% (+2.6%) 的翻譯準確度，以及在測試組上取得 81.6% (+3.2%) 的翻譯準確度；2) 生成的 NL 說明也能提供有用的資訊給使用者，協助理解翻譯結果，進而提升 NL2SQL 翻譯的可解釋性。</paragraph>

##### **Capturing research literature attitude towards Sustainable Development Goals: an LLM-based topic modeling approach**
2411.02943v1 by Francesco Invernici, Francesca Curati, Jelena Jakimov, Amirhossein Samavi, Anna Bernasconi

The world is facing a multitude of challenges that hinder the development of
human civilization and the well-being of humanity on the planet. The
Sustainable Development Goals (SDGs) were formulated by the United Nations in
2015 to address these global challenges by 2030. Natural language processing
techniques can help uncover discussions on SDGs within research literature. We
propose a completely automated pipeline to 1) fetch content from the Scopus
database and prepare datasets dedicated to five groups of SDGs; 2) perform
topic modeling, a statistical technique used to identify topics in large
collections of textual data; and 3) enable topic exploration through
keywords-based search and topic frequency time series extraction. For topic
modeling, we leverage the stack of BERTopic scaled up to be applied on large
corpora of textual documents (we find hundreds of topics on hundreds of
thousands of documents), introducing i) a novel LLM-based embeddings
computation for representing scientific abstracts in the continuous space and
ii) a hyperparameter optimizer to efficiently find the best configuration for
any new big datasets. We additionally produce the visualization of results on
interactive dashboards reporting topics' temporal evolution. Results are made
inspectable and explorable, contributing to the interpretability of the topic
modeling process. Our proposed LLM-based topic modeling pipeline for big-text
datasets allows users to capture insights on the evolution of the attitude
toward SDGs within scientific abstracts in the 2006-2023 time span. All the
results are reproducible by using our system; the workflow can be generalized
to be applied at any point in time to any big corpus of textual documents.

摘要：世界正面臨許多挑戰，阻礙了人類文明的發展和人類在這個星球上的福祉。聯合國在 2015 年制定了永續發展目標 (SDG)，以在 2030 年前解決這些全球挑戰。自然語言處理技術可以幫助揭露研究文獻中關於 SDG 的討論。我們提出一個完全自動化的管道，以 1) 從 Scopus 資料庫擷取內容並準備專門針對五組 SDG 的資料集；2) 執行主題建模，這是一種用於識別大量文本資料集中主題的統計技術；以及 3) 透過基於關鍵字的搜尋和主題頻率時間序列萃取，來啟用主題探索。對於主題建模，我們利用 BERTopic 堆疊，擴大規模以應用於大量文本文件語料庫（我們在數十萬份文件中找到了數百個主題），引入了 i) 一種新穎的基於 LLM 的嵌入運算，用於在連續空間中表示科學摘要，以及 ii) 一個超參數最佳化器，用於有效地為任何新的大型資料集找到最佳配置。我們還製作了結果視覺化，在互動式儀表板上報告主題的時序演進。結果可供檢查和探索，有助於主題建模過程的可解釋性。我們提出的基於 LLM 的大文本資料集主題建模管道，使用戶能夠在 2006-2023 年的時間跨度內，擷取科學摘要中對 SDG 態度的演進洞見。所有結果都可以使用我們的系統複製；工作流程可以概括為在任何時間點應用於任何大量文本文件語料庫。

##### **A Mamba Foundation Model for Time Series Forecasting**
2411.02941v1 by Haoyu Ma, Yushu Chen, Wenlai Zhao, Jinzhe Yang, Yingsheng Ji, Xinghua Xu, Xiaozhu Liu, Hao Jing, Shengzhuo Liu, Guangwen Yang

Time series foundation models have demonstrated strong performance in
zero-shot learning, making them well-suited for predicting rapidly evolving
patterns in real-world applications where relevant training data are scarce.
However, most of these models rely on the Transformer architecture, which
incurs quadratic complexity as input length increases. To address this, we
introduce TSMamba, a linear-complexity foundation model for time series
forecasting built on the Mamba architecture. The model captures temporal
dependencies through both forward and backward Mamba encoders, achieving high
prediction accuracy. To reduce reliance on large datasets and lower training
costs, TSMamba employs a two-stage transfer learning process that leverages
pretrained Mamba LLMs, allowing effective time series modeling with a moderate
training set. In the first stage, the forward and backward backbones are
optimized via patch-wise autoregressive prediction; in the second stage, the
model trains a prediction head and refines other components for long-term
forecasting. While the backbone assumes channel independence to manage varying
channel numbers across datasets, a channel-wise compressed attention module is
introduced to capture cross-channel dependencies during fine-tuning on specific
multivariate datasets. Experiments show that TSMamba's zero-shot performance is
comparable to state-of-the-art time series foundation models, despite using
significantly less training data. It also achieves competitive or superior
full-shot performance compared to task-specific prediction models. The code
will be made publicly available.

摘要：時序基礎模型已在零次學習中展現強勁的效能，使其非常適合於預測實際應用中快速演進的模式，而相關訓練資料稀少。然而，這些模型大多仰賴Transformer架構，隨著輸入長度增加，會產生二次複雜度。為了解決這個問題，我們引進 TSMamba，一個建立於 Mamba 架構上的線性複雜度基礎模型，用於時序預測。此模型透過正向和反向 Mamba 編碼器擷取時間依賴性，達成高度的預測準確度。為了減少對大型資料集的依賴並降低訓練成本，TSMamba 採用兩階段遷移學習流程，利用預先訓練的 Mamba LLM，允許使用適中的訓練集進行有效時序建模。在第一階段，正向和反向主幹透過區塊自迴歸預測進行最佳化；在第二階段，模型訓練預測頭並調整其他組件以進行長期預測。雖然主幹假設通道獨立性以管理不同資料集中的不同通道數量，但引進了一個通道壓縮注意力模組，以在特定多變量資料集的微調過程中擷取跨通道依賴性。實驗顯示，儘管訓練資料少很多，TSMamba 的零次學習效能可與最先進的時序基礎模型相提並論。與特定任務預測模型相比，它也能達成具競爭力或更佳的全次學習效能。程式碼將公開提供。

##### **A Post-Training Enhanced Optimization Approach for Small Language Models**
2411.02939v1 by Keke Zhai

This paper delves into the continuous post-training optimization methods for
small language models, and proposes a continuous post-training alignment data
construction method for small language models. The core of this method is based
on the data guidance of large models, optimizing the diversity and accuracy of
alignment data. In addition, to verify the effectiveness of the methods in this
paper, we used Qwen2-0.5B-Instruct model as the baseline model for small
language models, using the alignment dataset constructed by our proposed
method, we trained and compared several groups of experiments, including SFT
(Supervised Fine Tuning) post-training experiment and KTO (Kahneman Tversky
optimization) post-training experiment, as well as SFT-KTO two-stage
post-training experiment and model weight fusion experiment. Finally, we
evaluated and analyzed the performance of post-training models, and confirmed
that the continuous post-training optimization method proposed by us can
significantly improve the performance of small language models.

摘要：本文深入探讨了小语言模型的持续后训练优化方法，并提出了一种小语言模型的持续后训练对齐数据构建方法。该方法的核心是基于大模型的数据指导，优化对齐数据的 diversity 和准确性。此外，为了验证本文方法的有效性，我们使用 Qwen2-0.5B-Instruct 模型作为小语言模型的 baseline 模型，使用我们提出的方法构建的对齐数据集，训练并比较了几组实验，包括 SFT（有监督微调）后训练实验和 KTO（Kahneman Tversky 优化）后训练实验，以及 SFT-KTO 两阶段后训练实验和模型权重融合实验。最后，我们对后训练模型的性能进行了评估和分析，并确认我们提出的持续后训练优化方法可以显著提升小语言模型的性能。

##### **Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA Dataset and Self-adaptive Planning Agent**
2411.02937v1 by Yangning Li, Yinghui Li, Xingyu Wang, Yong Jiang, Zhen Zhang, Xinran Zheng, Hui Wang, Hai-Tao Zheng, Philip S. Yu, Fei Huang, Jingren Zhou

Multimodal Retrieval Augmented Generation (mRAG) plays an important role in
mitigating the "hallucination" issue inherent in multimodal large language
models (MLLMs). Although promising, existing heuristic mRAGs typically
predefined fixed retrieval processes, which causes two issues: (1) Non-adaptive
Retrieval Queries. (2) Overloaded Retrieval Queries. However, these flaws
cannot be adequately reflected by current knowledge-seeking visual question
answering (VQA) datasets, since the most required knowledge can be readily
obtained with a standard two-step retrieval. To bridge the dataset gap, we
first construct Dyn-VQA dataset, consisting of three types of "dynamic"
questions, which require complex knowledge retrieval strategies variable in
query, tool, and time: (1) Questions with rapidly changing answers. (2)
Questions requiring multi-modal knowledge. (3) Multi-hop questions. Experiments
on Dyn-VQA reveal that existing heuristic mRAGs struggle to provide sufficient
and precisely relevant knowledge for dynamic questions due to their rigid
retrieval processes. Hence, we further propose the first self-adaptive planning
agent for multimodal retrieval, OmniSearch. The underlying idea is to emulate
the human behavior in question solution which dynamically decomposes complex
multimodal questions into sub-question chains with retrieval action. Extensive
experiments prove the effectiveness of our OmniSearch, also provide direction
for advancing mRAG. The code and dataset will be open-sourced at
https://github.com/Alibaba-NLP/OmniSearch.

摘要：多模态检索增强生成 (mRAG) 在缓解多模态大语言模型 (MLLM) 固有的“幻觉”问题中扮演着重要角色。尽管前景广阔，但现有的启发式 mRAG 通常预定义固定的检索流程，这导致了两个问题：(1) 非自适应检索查询。(2) 过载检索查询。然而，这些缺陷无法通过当前的知识寻求视觉问题解答 (VQA) 数据集充分反映，因为最需要的知识可以通过标准的两步检索轻松获得。为了弥合数据集差距，我们首先构建了 Dyn-VQA 数据集，其中包含三类“动态”问题，需要复杂且在查询、工具和时间上变化的知识检索策略：(1) 答案快速变化的问题。(2) 需要多模态知识的问题。(3) 多跳问题。在 Dyn-VQA 上的实验表明，现有的启发式 mRAG 由于其僵化的检索流程而难以针对动态问题提供充分且精确相关的知识。因此，我们进一步提出了第一个用于多模态检索的自适应规划代理 OmniSearch。其基本思想是模拟人类在问题求解中的行为，将复杂的多模态问题动态分解为带有检索动作的子问题链。大量的实验证明了我们 OmniSearch 的有效性，也为推进 mRAG 提供了方向。代码和数据集将在 https://github.com/Alibaba-NLP/OmniSearch 开源。

##### **Textual Aesthetics in Large Language Models**
2411.02930v1 by Lingjie Jiang, Shaohan Huang, Xun Wu, Furu Wei

Image aesthetics is a crucial metric in the field of image generation.
However, textual aesthetics has not been sufficiently explored. With the
widespread application of large language models (LLMs), previous work has
primarily focused on the correctness of content and the helpfulness of
responses. Nonetheless, providing responses with textual aesthetics is also an
important factor for LLMs, which can offer a cleaner layout and ensure greater
consistency and coherence in content. In this work, we introduce a pipeline for
aesthetics polishing and help construct a textual aesthetics dataset named
TexAes. We propose a textual aesthetics-powered fine-tuning method based on
direct preference optimization, termed TAPO, which leverages textual aesthetics
without compromising content correctness. Additionally, we develop two
evaluation methods for textual aesthetics based on text and image analysis,
respectively. Our experiments demonstrate that using textual aesthetics data
and employing the TAPO fine-tuning method not only improves aesthetic scores
but also enhances performance on general evaluation datasets such as
AlpacalEval and Anera-hard.

摘要：圖像美學是影像生成領域中一項至關重要的指標。
然而，文本美學尚未被充分探討。隨著大型語言模型 (LLM) 的廣泛應用，先前的研究主要集中於內容的正確性和回應的有用性。儘管如此，提供具有文本美學的回應對於 LLM 來說也是一個重要的因素，它可以提供更簡潔的版面並確保內容具有更高的前後一致性和連貫性。在這項工作中，我們引入了一個用於美學潤色的管道，並協助建構一個名為 TexAes 的文本美學資料集。我們提出了一種基於直接偏好最佳化的文本美學驅動微調方法，稱為 TAPO，它利用文本美學而不影響內容正確性。此外，我們分別基於文本和影像分析開發了兩種文本美學評估方法。我們的實驗證明，使用文本美學資料並採用 TAPO 微調方法不僅提高了美學分數，還提升了在一般評估資料集（例如 AlpacalEval 和 Anera-hard）上的效能。

##### **Domain Expansion and Boundary Growth for Open-Set Single-Source Domain Generalization**
2411.02920v1 by Pengkun Jiao, Na Zhao, Jingjing Chen, Yu-Gang Jiang

Open-set single-source domain generalization aims to use a single-source
domain to learn a robust model that can be generalized to unknown target
domains with both domain shifts and label shifts. The scarcity of the source
domain and the unknown data distribution of the target domain pose a great
challenge for domain-invariant feature learning and unknown class recognition.
In this paper, we propose a novel learning approach based on domain expansion
and boundary growth to expand the scarce source samples and enlarge the
boundaries across the known classes that indirectly broaden the boundary
between the known and unknown classes. Specifically, we achieve domain
expansion by employing both background suppression and style augmentation on
the source data to synthesize new samples. Then we force the model to distill
consistent knowledge from the synthesized samples so that the model can learn
domain-invariant information. Furthermore, we realize boundary growth across
classes by using edge maps as an additional modality of samples when training
multi-binary classifiers. In this way, it enlarges the boundary between the
inliers and outliers, and consequently improves the unknown class recognition
during open-set generalization. Extensive experiments show that our approach
can achieve significant improvements and reach state-of-the-art performance on
several cross-domain image classification datasets.

摘要：開放式單源域泛化旨在使用單源域學習一個強健模型，該模型可以泛化到具有域偏移和標籤偏移的未知目標域。源域的稀缺性和目標域未知的資料分佈對域不變特徵學習和未知類別識別構成巨大挑戰。在本文中，我們提出了一種基於域擴充和邊界增長的創新學習方法，以擴充稀缺的源樣本並擴大已知類別的邊界，從而間接擴大已知類別和未知類別之間的邊界。具體來說，我們通過對源資料採用背景抑制和樣式擴充來實現域擴充，以合成新樣本。然後，我們強制模型從合成樣本中提取一致的知識，以便模型可以學習域不變資訊。此外，我們在訓練多二元分類器時使用邊緣圖作為樣本的附加方式來實現跨類別的邊界增長。這樣，它擴大了內點和外點之間的邊界，從而改善了開放式泛化期間的未知類別識別。大量實驗表明，我們的方法可以在幾個跨域影像分類資料集上實現顯著的改進，並達到最先進的效能。

##### **Exploring the Interplay Between Video Generation and World Models in Autonomous Driving: A Survey**
2411.02914v1 by Ao Fu, Yi Zhou, Tao Zhou, Yi Yang, Bojun Gao, Qun Li, Guobin Wu, Ling Shao

World models and video generation are pivotal technologies in the domain of
autonomous driving, each playing a critical role in enhancing the robustness
and reliability of autonomous systems. World models, which simulate the
dynamics of real-world environments, and video generation models, which produce
realistic video sequences, are increasingly being integrated to improve
situational awareness and decision-making capabilities in autonomous vehicles.
This paper investigates the relationship between these two technologies,
focusing on how their structural parallels, particularly in diffusion-based
models, contribute to more accurate and coherent simulations of driving
scenarios. We examine leading works such as JEPA, Genie, and Sora, which
exemplify different approaches to world model design, thereby highlighting the
lack of a universally accepted definition of world models. These diverse
interpretations underscore the field's evolving understanding of how world
models can be optimized for various autonomous driving tasks. Furthermore, this
paper discusses the key evaluation metrics employed in this domain, such as
Chamfer distance for 3D scene reconstruction and Fr\'echet Inception Distance
(FID) for assessing the quality of generated video content. By analyzing the
interplay between video generation and world models, this survey identifies
critical challenges and future research directions, emphasizing the potential
of these technologies to jointly advance the performance of autonomous driving
systems. The findings presented in this paper aim to provide a comprehensive
understanding of how the integration of video generation and world models can
drive innovation in the development of safer and more reliable autonomous
vehicles.

摘要：世界模型和影片生成是自動駕駛領域的關鍵技術，各自在提升自動系統的穩健性和可靠性方面發揮著至關重要的作用。世界模型模擬真實世界環境的動態，而影片生成模型產生逼真的影片序列，它們正日益整合在一起，以提升自動駕駛車輛的情境感知和決策能力。本文探討這兩項技術之間的關係，重點關注它們的結構相似性，特別是在基於擴散的模型中，如何有助於更準確、更一致地模擬駕駛場景。我們研究了 JEPA、Genie 和 Sora 等領先作品，它們例證了世界模型設計的不同方法，從而突顯了世界模型普遍接受的定義的缺乏。這些不同的詮釋強調了該領域對世界模型如何針對各種自動駕駛任務進行優化的理解不斷演進。此外，本文討論了該領域中使用的關鍵評估指標，例如用於 3D 場景重建的 Chamfer 距離和用於評估生成影片內容品質的 Fr\'echet Inception Distance (FID)。通過分析影片生成和世界模型之間的相互作用，本調查確定了關鍵挑戰和未來的研究方向，強調了這些技術共同推進自動駕駛系統性能的潛力。本文提出的發現旨在提供對影片生成和世界模型整合如何推動更安全、更可靠的自動駕駛車輛開發創新的全面理解。

##### **Membership Inference Attacks against Large Vision-Language Models**
2411.02902v1 by Zhan Li, Yongtao Wu, Yihang Chen, Francesco Tonin, Elias Abad Rocamora, Volkan Cevher

Large vision-language models (VLLMs) exhibit promising capabilities for
processing multi-modal tasks across various application scenarios. However,
their emergence also raises significant data security concerns, given the
potential inclusion of sensitive information, such as private photos and
medical records, in their training datasets. Detecting inappropriately used
data in VLLMs remains a critical and unresolved issue, mainly due to the lack
of standardized datasets and suitable methodologies. In this study, we
introduce the first membership inference attack (MIA) benchmark tailored for
various VLLMs to facilitate training data detection. Then, we propose a novel
MIA pipeline specifically designed for token-level image detection. Lastly, we
present a new metric called MaxR\'enyi-K%, which is based on the confidence of
the model output and applies to both text and image data. We believe that our
work can deepen the understanding and methodology of MIAs in the context of
VLLMs. Our code and datasets are available at
https://github.com/LIONS-EPFL/VL-MIA.

摘要：大型視覺語言模型 (VLLM) 在處理各種應用場景的多模態任務方面表現出有前景的能力。然而，它們的出現也引發了重大的資料安全問題，因為它們的訓練資料集中可能會包含敏感資訊，例如私人照片和醫療記錄。偵測 VLLM 中不當使用的資料仍然是一個關鍵且尚未解決的問題，主要是由於缺乏標準化的資料集和適當的方法。在本研究中，我們引入了第一個針對各種 VLLM 量身打造的成員推論攻擊 (MIA) 基準，以利於訓練資料偵測。然後，我們提出了一個專門設計用於令牌級別影像偵測的全新 MIA 管線。最後，我們提出一個名為 MaxR\'enyi-K% 的新指標，它基於模型輸出的信心，並適用於文字和影像資料。我們相信，我們的研究可以加深對 VLLM 背景下 MIA 的理解和方法。我們的程式碼和資料集可在 https://github.com/LIONS-EPFL/VL-MIA 取得。

##### **TokenSelect: Efficient Long-Context Inference and Length Extrapolation for LLMs via Dynamic Token-Level KV Cache Selection**
2411.02886v1 by Wei Wu, Zhuoshi Pan, Chao Wang, Liyi Chen, Yunchu Bai, Kun Fu, Zheng Wang, Hui Xiong

With the development of large language models (LLMs), the ability to handle
longer contexts has become a key capability for Web applications such as
cross-document understanding and LLM-powered search systems. However, this
progress faces two major challenges: performance degradation due to sequence
lengths out-of-distribution, and excessively long inference times caused by the
quadratic computational complexity of attention. These issues hinder the
application of LLMs in long-context scenarios. In this paper, we propose
Dynamic Token-Level KV Cache Selection (TokenSelect), a model-agnostic,
training-free method for efficient and accurate long-context inference.
TokenSelect builds upon the observation of non-contiguous attention sparsity,
using Query-Key dot products to measure per-head KV Cache criticality at
token-level. By per-head soft voting mechanism, TokenSelect selectively
involves a small number of critical KV cache tokens in the attention
calculation without sacrificing accuracy. To further accelerate TokenSelect, we
designed the Selection Cache based on observations of consecutive Query
similarity and implemented efficient dot product kernel, significantly reducing
the overhead of token selection. A comprehensive evaluation of TokenSelect
demonstrates up to 23.84x speedup in attention computation and up to 2.28x
acceleration in end-to-end latency, while providing superior performance
compared to state-of-the-art long-context inference methods.

摘要：隨著大型語言模型（LLM）的發展，處理較長背景的能力已成為網路應用程式的關鍵功能，例如跨文件理解和 LLM 驅動的搜尋系統。然而，這個進展面臨兩個主要挑戰：由於序列長度超出分佈而導致效能下降，以及注意力二次運算複雜度造成的過長推論時間。這些問題阻礙了 LLM 在長背景場景中的應用。在本文中，我們提出動態 Token 層級 KV 快取選擇（TokenSelect），一種與模型無關、無需訓練的方法，用於有效且準確的長背景推論。TokenSelect 建立在非連續注意力稀疏性的觀察之上，使用查詢鍵點積測量每個頭部 KV 快取在 Token 層級的重要性。透過每個頭部的軟性投票機制，TokenSelect 選擇性地將少量關鍵 KV 快取 Token 納入注意力計算中，同時不犧牲準確性。為了進一步加速 TokenSelect，我們根據連續查詢相似性的觀察設計了選擇快取，並實作了有效的點積核，大幅減少 Token 選擇的開銷。對 TokenSelect 的全面評估顯示，注意力運算速度提升了 23.84 倍，端到端延遲加速了 2.28 倍，同時與最先進的長背景推論方法相比，提供了卓越的效能。

##### **Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**
2411.02864v1 by Tao Zhang, Ning Yan, Masood Mortazavi, Hoang H. Nguyen, Zhongfen Deng, Philip S. Yu

Large language models (LLMs) pre-trained on massive corpora have demonstrated
impressive few-shot learning capability on many NLP tasks. Recasting an NLP
task into a text-to-text generation task is a common practice so that
generative LLMs can be prompted to resolve it. However, performing
document-level relation extraction (DocRE) tasks with generative LLM models is
still challenging due to the structured output format of DocRE, which
complicates the conversion to plain text. Limited information available in
few-shot samples and prompt instructions induce further difficulties and
challenges in relation extraction for mentioned entities in a document. In this
paper, we represent the structured output as a graph-style triplet rather than
natural language expressions and leverage generative LLMs for the DocRE task.
Our approach, the Graph-DPEP framework is grounded in the reasoning behind
triplet explanation thoughts presented in natural language. In this framework,
we first introduce a ``decomposed-plug" method for performing the generation
from LLMs over prompts with type-space decomposition to alleviate the burden of
distinguishing all relation types. Second, we employ a verifier for calibrating
the generation and identifying overlooked query entity pairs. Third, we develop
"ensemble-play", reapplying generation on the entire type list by leveraging
the reasoning thoughts embedded in a sub-graph associated with the missing
query pair to address the missingness issue. Through extensive comparisons with
existing prompt techniques and alternative Language Models (LLMs), our
framework demonstrates superior performance on publicly available benchmarks in
experiments.

摘要：大型語言模型 (LLM) 在海量語料庫上預先訓練，已在許多自然語言處理任務上展現出令人印象深刻的少量樣本學習能力。將自然語言處理任務轉化為文字到文字的生成任務是一種常見做法，這樣生成式大型語言模型就可以提示解決它。然而，由於 DocRE 的結構化輸出格式，使用生成式大型語言模型來執行文件級別關係萃取 (DocRE) 任務仍然具有挑戰性，這使得轉換為純文字變得複雜。少量樣本和提示說明中可用的資訊有限，會導致在文件中提到實體的關係萃取中產生進一步的困難和挑戰。在本文中，我們將結構化輸出表示為圖形樣式的三元組，而不是自然語言表達，並利用生成式大型語言模型來執行 DocRE 任務。我們的做法，圖形 DPEP 框架，是基於自然語言中呈現的三元組解釋思想背後的推理。在這個框架中，我們首先介紹一種「分解插入」方法，用於對具有類型空間分解的提示進行大型語言模型生成，以減輕區分所有關係類型的負擔。其次，我們使用驗證器來校準生成並識別被忽略的查詢實體對。第三，我們開發「整體遊戲」，通過利用與遺失查詢對相關的子圖中嵌入的推理思想，在整個類型列表上重新應用生成，以解決遺失問題。通過與現有提示技術和替代語言模型 (LLM) 的廣泛比較，我們的框架在實驗中證明了在公開基準上的優異性能。

##### **Learning to Unify Audio, Visual and Text for Audio-Enhanced Multilingual Visual Answer Localization**
2411.02851v1 by Zhibin Wen, Bin Li

The goal of Multilingual Visual Answer Localization (MVAL) is to locate a
video segment that answers a given multilingual question. Existing methods
either focus solely on visual modality or integrate visual and subtitle
modalities. However, these methods neglect the audio modality in videos,
consequently leading to incomplete input information and poor performance in
the MVAL task. In this paper, we propose a unified Audio-Visual-Textual Span
Localization (AVTSL) method that incorporates audio modality to augment both
visual and textual representations for the MVAL task. Specifically, we
integrate features from three modalities and develop three predictors, each
tailored to the unique contributions of the fused modalities: an audio-visual
predictor, a visual predictor, and a textual predictor. Each predictor
generates predictions based on its respective modality. To maintain consistency
across the predicted results, we introduce an Audio-Visual-Textual Consistency
module. This module utilizes a Dynamic Triangular Loss (DTL) function, allowing
each modality's predictor to dynamically learn from the others. This
collaborative learning ensures that the model generates consistent and
comprehensive answers. Extensive experiments show that our proposed method
outperforms several state-of-the-art (SOTA) methods, which demonstrates the
effectiveness of the audio modality.

摘要：多模態視覺答案定位 (MVAL) 的目標是找到一段影片區段，來回答一個給定的多語言問題。現有的方法，要不只關注於視覺模態，要不就是整合視覺和字幕模態。然而，這些方法忽略了影片中的音訊模態，因此導致不完整的輸入資訊，以及在 MVAL 任務中的表現不佳。在本文中，我們提出一個統一的音訊-視覺-文字區間定位 (AVTSL) 方法，它結合音訊模態來擴充視覺和文字表徵，以用於 MVAL 任務。具體來說，我們整合來自三個模態的特徵，並開發三個預測器，每個預測器都針對融合模態的獨特貢獻量身打造：一個音訊-視覺預測器、一個視覺預測器和一個文字預測器。每個預測器根據其各自的模態產生預測。為了在預測結果中保持一致性，我們引入了一個音訊-視覺-文字一致性模組。此模組利用動態三角損失 (DTL) 函數，讓每個模態的預測器都能動態地從其他模態學習。這種協作學習確保模型產生一致且全面的答案。廣泛的實驗顯示，我們提出的方法優於多種最先進 (SOTA) 方法，這證明了音訊模態的有效性。

##### **WASHtsApp -- A RAG-powered WhatsApp Chatbot for supporting rural African clean water access, sanitation and hygiene**
2411.02850v1 by Simon Kloker, Alex Cedric Luyima, Matthew Bazanya

This paper introduces WASHtsApp, a WhatsApp-based chatbot designed to educate
rural African communities on clean water access, sanitation, and hygiene (WASH)
principles. WASHtsApp leverages a Retrieval-Augmented Generation (RAG) approach
to address the limitations of previous approaches with limited reach or missing
contextualization. The paper details the development process, employing Design
Science Research Methodology. The evaluation consisted of two phases: content
validation by four WASH experts and community validation by potential users.
Content validation confirmed WASHtsApp's ability to provide accurate and
relevant WASH-related information. Community validation indicated high user
acceptance and perceived usefulness of the chatbot. The paper concludes by
discussing the potential for further development, including incorporating local
languages and user data analysis for targeted interventions. It also proposes
future research cycles focused on wider deployment and leveraging user data for
educational purposes.

摘要：本文介紹了 WASHtsApp，一個基於 WhatsApp 的聊天機器人，旨在教育
非洲農村社區有關乾淨水源、衛生和衛生 (WASH)
原則。WASHtsApp 採用檢索增強生成 (RAG) 方法
來解決先前方法觸及範圍有限或缺乏
情境化的限制。本文詳細說明了開發過程，採用
設計科學研究方法。評估包含兩個階段：四位 WASH 專家進行內容
驗證，以及潛在使用者進行社群驗證。
內容驗證確認了 WASHtsApp 提供準確且
與 WASH 相關的資訊的能力。社群驗證表示使用者高度接受並認為聊天機器人有用。本文最後
討論了進一步開發的潛力，包括納入當地
語言和使用者資料分析，以進行有針對性的介入。它也提出
未來的研究週期，專注於更廣泛的部署和利用使用者資料進行
教育目的。

##### **Dissecting the Failure of Invariant Learning on Graphs**
2411.02847v1 by Qixun Wang, Yifei Wang, Yisen Wang, Xianghua Ying

Enhancing node-level Out-Of-Distribution (OOD) generalization on graphs
remains a crucial area of research. In this paper, we develop a Structural
Causal Model (SCM) to theoretically dissect the performance of two prominent
invariant learning methods -- Invariant Risk Minimization (IRM) and
Variance-Risk Extrapolation (VREx) -- in node-level OOD settings. Our analysis
reveals a critical limitation: due to the lack of class-conditional invariance
constraints, these methods may struggle to accurately identify the structure of
the predictive invariant ego-graph and consequently rely on spurious features.
To address this, we propose Cross-environment Intra-class Alignment (CIA),
which explicitly eliminates spurious features by aligning cross-environment
representations conditioned on the same class, bypassing the need for explicit
knowledge of the causal pattern structure. To adapt CIA to node-level OOD
scenarios where environment labels are hard to obtain, we further propose
CIA-LRA (Localized Reweighting Alignment) that leverages the distribution of
neighboring labels to selectively align node representations, effectively
distinguishing and preserving invariant features while removing spurious ones,
all without relying on environment labels. We theoretically prove CIA-LRA's
effectiveness by deriving an OOD generalization error bound based on
PAC-Bayesian analysis. Experiments on graph OOD benchmarks validate the
superiority of CIA and CIA-LRA, marking a significant advancement in node-level
OOD generalization. The codes are available at
https://github.com/NOVAglow646/NeurIPS24-Invariant-Learning-on-Graphs.

摘要：加強圖形上節點層級的 Out-Of-Distribution (OOD) 概化仍然是研究的重要領域。在本文中，我們開發了一個結構因果模型 (SCM) 來理論上剖析兩種突出的不變學習方法的效能，在節點層級的 OOD 設定中，這兩種方法分別為不變風險最小化 (IRM) 和變異風險外推 (VREx)。我們的分析揭露了一個關鍵的限制：由於缺乏類條件不變約束，這些方法可能難以準確地識別預測不變自我圖形的結構，因此依賴於虛假的特徵。為了解決這個問題，我們提出了跨環境類內對齊 (CIA)，它透過對齊基於相同類別的跨環境表示，明確地消除了虛假特徵，繞過了對因果模式結構的明確知識需求。為了將 CIA 適應到難以取得環境標籤的節點層級 OOD 場景，我們進一步提出了 CIA-LRA (局部重新加權對齊)，它利用鄰近標籤的分布來選擇性地對齊節點表示，有效地區分並保留不變特徵，同時移除虛假特徵，所有這些都不依賴於環境標籤。我們透過根據 PAC 貝氏分析推導出的 OOD 概化誤差界限，理論上證明了 CIA-LRA 的有效性。圖形 OOD 基準上的實驗驗證了 CIA 和 CIA-LRA 的優越性，標誌著節點層級 OOD 概化的重大進展。程式碼可於 https://github.com/NOVAglow646/NeurIPS24-Invariant-Learning-on-Graphs 取得。

##### **Correlation of Object Detection Performance with Visual Saliency and Depth Estimation**
2411.02844v1 by Matthias Bartolo, Dylan Seychell

As object detection techniques continue to evolve, understanding their
relationships with complementary visual tasks becomes crucial for optimising
model architectures and computational resources. This paper investigates the
correlations between object detection accuracy and two fundamental visual
tasks: depth prediction and visual saliency prediction. Through comprehensive
experiments using state-of-the-art models (DeepGaze IIE, Depth Anything,
DPT-Large, and Itti's model) on COCO and Pascal VOC datasets, we find that
visual saliency shows consistently stronger correlations with object detection
accuracy (mA$\rho$ up to 0.459 on Pascal VOC) compared to depth prediction
(mA$\rho$ up to 0.283). Our analysis reveals significant variations in these
correlations across object categories, with larger objects showing correlation
values up to three times higher than smaller objects. These findings suggest
incorporating visual saliency features into object detection architectures
could be more beneficial than depth information, particularly for specific
object categories. The observed category-specific variations also provide
insights for targeted feature engineering and dataset design improvements,
potentially leading to more efficient and accurate object detection systems.

摘要：隨著目標偵測技術持續演進，了解其與互補視覺任務的關聯性，對於優化模型架構和計算資源至關重要。本文探討了目標偵測準確度與兩個基本視覺任務之間的相關性：深度預測和視覺顯著性預測。透過使用 COCO 和 Pascal VOC 資料集的最新模型（DeepGaze IIE、Depth Anything、DPT-Large 和 Itti 模型）進行全面實驗，我們發現視覺顯著性與目標偵測準確度顯示出一致且更強的相關性（mA$\rho$ 在 Pascal VOC 上高達 0.459），而深度預測則較弱（mA$\rho$ 最高 0.283）。我們的分析揭示了這些相關性在不同目標類別中存在顯著差異，較大的目標顯示的相關係數值比較小的目標高出三倍。這些發現表明，將視覺顯著性特徵納入目標偵測架構可能比深度資訊更有益，特別是對於特定目標類別。觀察到的類別特定變化也為目標特徵工程和資料集設計改進提供了見解，有可能導致更有效率且準確的目標偵測系統。

##### **PersianRAG: A Retrieval-Augmented Generation System for Persian Language**
2411.02832v1 by Hossein Hosseini, Mohammad Siobhan Zare, Amir Hossein Mohammadi, Arefeh Kazemi, Zahra Zojaji, Mohammad Ali Nematbakhsh

Retrieval augmented generation (RAG) models, which integrate large-scale
pre-trained generative models with external retrieval mechanisms, have shown
significant success in various natural language processing (NLP) tasks.
However, applying RAG models in Persian language as a low-resource language,
poses distinct challenges. These challenges primarily involve the
preprocessing, embedding, retrieval, prompt construction, language modeling,
and response evaluation of the system. In this paper, we address the challenges
towards implementing a real-world RAG system for Persian language called
PersianRAG. We propose novel solutions to overcome these obstacles and evaluate
our approach using several Persian benchmark datasets. Our experimental results
demonstrate the capability of the PersianRAG framework to enhance question
answering task in Persian.

摘要：檢索增強生成 (RAG) 模型整合了大型預訓練生成模型和外部檢索機制，已在各種自然語言處理 (NLP) 任務中展現顯著的成功。
然而，在波斯語這種低資源語言中應用 RAG 模型，會產生不同的挑戰。這些挑戰主要涉及系統的預處理、嵌入、檢索、提示建構、語言建模和回應評估。在本文中，我們探討了針對波斯語實作真實世界 RAG 系統（稱為 PersianRAG）的挑戰。我們提出創新的解決方案以克服這些障礙，並使用多個波斯語基準資料集評估我們的作法。我們的實驗結果證明了 PersianRAG 架構增強波斯語問答任務的能力。

##### **Mixtures of In-Context Learners**
2411.02830v1 by Giwon Hong, Emile van Krieken, Edoardo Ponti, Nikolay Malkin, Pasquale Minervini

In-context learning (ICL) adapts LLMs by providing demonstrations without
fine-tuning the model parameters; however, it does not differentiate between
demonstrations and quadratically increases the complexity of Transformer LLMs,
exhausting the memory. As a solution, we propose Mixtures of In-Context
Learners (MoICL), a novel approach to treat subsets of demonstrations as
experts and learn a weighting function to merge their output distributions
based on a training set. In our experiments, we show performance improvements
on 5 out of 7 classification datasets compared to a set of strong baselines (up
to +13\% compared to ICL and LENS). Moreover, we enhance the Pareto frontier of
ICL by reducing the inference time needed to achieve the same performance with
fewer demonstrations. Finally, MoICL is more robust to out-of-domain (up to
+11\%), imbalanced (up to +49\%), or noisy demonstrations (up to +38\%) or can
filter these out from datasets. Overall, MoICL is a more expressive approach to
learning from demonstrations without exhausting the context window or memory.

摘要：語境學習 (ICL) 透過提供示範來調整 LLM，而無需微調模型參數；然而，它並未區分示範，並二次增加 Transformer LLM 的複雜性，耗盡記憶體。作為解決方案，我們提出語境學習器混合 (MoICL)，這是一種新方法，將示範子集視為專家，並學習加權函數，以根據訓練集合併其輸出分佈。在我們的實驗中，我們展示了與一組強大的基準相比，在 7 個分類資料集中的 5 個資料集上改進了效能（與 ICL 和 LENS 相比，提升幅度高達 +13%）。此外，我們透過減少達到相同效能所需的推論時間，來增強 ICL 的帕累托前緣，同時減少示範數量。最後，MoICL 對領域外（提升幅度高達 +11%）、不平衡（提升幅度高達 +49%）或有雜訊的示範（提升幅度高達 +38%）更具有穩健性，或者可以從資料集中篩選出這些示範。總體而言，MoICL 是一種更具表現力的方法，可以從示範中學習，而不會耗盡語境視窗或記憶體。

##### **DroidSpeak: Enhancing Cross-LLM Communication**
2411.02820v1 by Yuhan Liu, Esha Choukse, Shan Lu, Junchen Jiang, Madan Musuvathi

In multi-agent systems utilizing Large Language Models (LLMs), communication
between agents traditionally relies on natural language. This communication
often includes the full context of the query so far, which can introduce
significant prefill-phase latency, especially with long contexts.
  We introduce DroidSpeak, a novel framework to target this cross-LLM
communication by leveraging the reuse of intermediate data, such as input
embeddings (E-cache) and key-value caches (KV-cache). We efficiently bypass the
need to reprocess entire contexts for fine-tuned versions of the same
foundational model. This approach allows faster context integration while
maintaining the quality of task performance. Experimental evaluations
demonstrate DroidSpeak's ability to significantly accelerate inter-agent
communication, achieving up to a 2.78x speedup in prefill latency with
negligible loss in accuracy. Our findings underscore the potential to create
more efficient and scalable multi-agent systems.

摘要：在利用大型語言模型 (LLM) 的多代理系統中，代理之間的溝通傳統上依賴於自然語言。這種溝通通常包括到目前為止查詢的完整內容，這可能會造成大量的預填充階段延遲，特別是在內容很長的情況下。
我們介紹了 DroidSpeak，這是一個新穎的框架，旨在透過利用中間資料的重複使用（例如輸入嵌入 (E 快取) 和鍵值快取 (KV 快取)）來針對這種跨 LLM 溝通。我們有效地繞過了重新處理整個內容以用於相同基礎模型的微調版本的需求。這種方法允許更快速的內容整合，同時保持任務執行品質。實驗評估證明了 DroidSpeak 的能力，它可以顯著加速代理間溝通，在預填充延遲方面實現了高達 2.78 倍的加速，而準確度損失可以忽略不計。我們的發現強調了建立更有效率且可擴充的多代理系統的潛力。

##### **Conditional Vendi Score: An Information-Theoretic Approach to Diversity Evaluation of Prompt-based Generative Models**
2411.02817v1 by Mohammad Jalali, Azim Ospanov, Amin Gohari, Farzan Farnia

Text-conditioned generation models are commonly evaluated based on the
quality of the generated data and its alignment with the input text prompt. On
the other hand, several applications of prompt-based generative models require
sufficient diversity in the generated data to ensure the models' capability of
generating image and video samples possessing a variety of features. However,
most existing diversity metrics are designed for unconditional generative
models, and thus cannot distinguish the diversity arising from variations in
text prompts and that contributed by the generative model itself. In this work,
our goal is to quantify the prompt-induced and model-induced diversity in
samples generated by prompt-based models. We propose an information-theoretic
approach for internal diversity quantification, where we decompose the
kernel-based entropy $H(X)$ of the generated data $X$ into the sum of the
conditional entropy $H(X|T)$, given text variable $T$, and the mutual
information $I(X; T)$ between the text and data variables. We introduce the
\emph{Conditional-Vendi} score based on $H(X|T)$ to quantify the internal
diversity of the model and the \emph{Information-Vendi} score based on $I(X;
T)$ to measure the statistical relevance between the generated data and text
prompts. We provide theoretical results to statistically interpret these scores
and relate them to the unconditional Vendi score. We conduct several numerical
experiments to show the correlation between the Conditional-Vendi score and the
internal diversity of text-conditioned generative models. The codebase is
available at
\href{https://github.com/mjalali/conditional-vendi}{https://github.com/mjalali/conditional-vendi}.

摘要：文本条件生成模型通常根据生成数据的质量及其与输入文本提示的一致性进行评估。另一方面，基于提示的生成模型的几种应用需要生成数据具有足够的多样性，以确保模型能够生成具有各种特征的图像和视频样本。然而，大多数现有的多样性度量都是为无条件生成模型设计的，因此无法区分由文本提示的变化引起的多样性和由生成模型本身产生的多样性。在这项工作中，我们的目标是量化基于提示的模型生成的样本中提示引起的和模型引起的多样性。我们提出了一种用于内部多样性量化的信息论方法，其中我们将生成数据 X 的基于核的熵 H(X) 分解为给定文本变量 T 的条件熵 H(X|T) 的总和和文本和数据变量之间的互信息 I(X; T)。我们引入了基于 H(X|T) 的\emph{条件 Vendi} 分数来量化模型的内部多样性，并引入了基于 I(X; T) 的\emph{信息 Vendi} 分数来衡量生成数据和文本提示之间的统计相关性。我们提供了理论结果来统计解释这些分数，并将它们与无条件 Vendi 分数联系起来。我们进行了多项数值实验来显示条件 Vendi 分数与文本条件生成模型的内部多样性之间的相关性。代码库可在
\href{https://github.com/mjalali/conditional-vendi}{https://github.com/mjalali/conditional-vendi} 获得。

##### **DeepContext: A Context-aware, Cross-platform, and Cross-framework Tool for Performance Profiling and Analysis of Deep Learning Workloads**
2411.02797v1 by Qidong Zhao, Hao Wu, Yuming Hao, Zilingfeng Ye, Jiajia Li, Xu Liu, Keren Zhou

Effective performance profiling and analysis are essential for optimizing
training and inference of deep learning models, especially given the growing
complexity of heterogeneous computing environments. However, existing tools
often lack the capability to provide comprehensive program context information
and performance optimization insights for sophisticated interactions between
CPUs and GPUs. This paper introduces DeepContext, a novel profiler that links
program contexts across high-level Python code, deep learning frameworks,
underlying libraries written in C/C++, as well as device code executed on GPUs.
DeepContext incorporates measurements of both coarse- and fine-grained
performance metrics for major deep learning frameworks, such as PyTorch and
JAX, and is compatible with GPUs from both Nvidia and AMD, as well as various
CPU architectures, including x86 and ARM. In addition, DeepContext integrates a
novel GUI that allows users to quickly identify hotpots and an innovative
automated performance analyzer that suggests users with potential optimizations
based on performance metrics and program context. Through detailed use cases,
we demonstrate how DeepContext can help users identify and analyze performance
issues to enable quick and effective optimization of deep learning workloads.
We believe Deep Context is a valuable tool for users seeking to optimize
complex deep learning workflows across multiple compute environments.

摘要：有效的效能剖析和分析對於最佳化深度學習模型的訓練和推論至關重要，特別是在異質運算環境日益複雜的情況下。然而，現有的工具常常缺乏提供全面程式背景資訊和效能最佳化見解的能力，以應對 CPU 和 GPU 之間複雜的互動。本文介紹 DeepContext，一個創新的剖析器，它連結了跨高階 Python 程式碼、深度學習架構、以 C/C++ 編寫的底層函式庫，以及在 GPU 上執行的裝置程式碼的程式背景。DeepContext 結合了對 PyTorch 和 JAX 等主要深度學習架構的粗粒度和細粒度效能指標的測量，並與 Nvidia 和 AMD 的 GPU，以及包括 x86 和 ARM 在內的各種 CPU 架構相容。此外，DeepContext 整合了一個創新的 GUI，使用戶能夠快速識別熱點，並具備一個創新的自動化效能分析器，根據效能指標和程式背景向使用者建議潛在的最佳化。透過詳細的使用案例，我們展示了 DeepContext 如何協助使用者識別和分析效能問題，以實現深度學習工作負載的快速且有效的最佳化。我們相信 Deep Context 是尋求最佳化跨多個運算環境的複雜深度學習工作流程的使用者的一個有價值的工具。

##### **Specialized Foundation Models Struggle to Beat Supervised Baselines**
2411.02796v1 by Zongzhe Xu, Ritvik Gupta, Wenduo Cheng, Alexander Shen, Junhong Shen, Ameet Talwalkar, Mikhail Khodak

Following its success for vision and text, the "foundation model" (FM)
paradigm -- pretraining large models on massive data, then fine-tuning on
target tasks -- has rapidly expanded to domains in the sciences, engineering,
healthcare, and beyond. Has this achieved what the original FMs accomplished,
i.e. the supplanting of traditional supervised learning in their domains? To
answer we look at three modalities -- genomics, satellite imaging, and time
series -- with multiple recent FMs and compare them to a standard supervised
learning workflow: model development, hyperparameter tuning, and training, all
using only data from the target task. Across these three specialized domains,
we find that it is consistently possible to train simple supervised models --
no more complicated than a lightly modified wide ResNet or UNet -- that match
or even outperform the latest foundation models. Our work demonstrates that the
benefits of large-scale pretraining have yet to be realized in many specialized
areas, reinforces the need to compare new FMs to strong, well-tuned baselines,
and introduces two new, easy-to-use, open-source, and automated workflows for
doing so.

摘要：在視覺和文本方面取得成功後，「基礎模型」（FM）範例——在大量資料上預先訓練大型模型，然後針對目標任務進行微調——已迅速擴展到科學、工程、醫療保健等領域。這是否達到了原始 FM 所完成的目標，即取代其領域中的傳統監督式學習？為了回答這個問題，我們觀察了三個模態——基因組學、衛星影像和時間序列——以及多個最近的 FM，並將它們與標準監督式學習工作流程進行比較：模型開發、超參數調整和訓練，所有這些都僅使用來自目標任務的資料。在這些三個專門領域中，我們發現持續訓練簡單的監督式模型是可行的——不比經過輕微修改的廣泛 ResNet 或 UNet 更複雜——與最新的基礎模型相匹配，甚至表現得更好。我們的研究表明，在許多專門領域中，大規模預訓練的優點尚未實現，這強化了將新的 FM 與強大且經過良好調整的基準進行比較的需求，並引入了兩個新的、易於使用、開放原始碼和自動化的工作流程來執行此操作。

##### **The Evolution of RWKV: Advancements in Efficient Language Modeling**
2411.02795v1 by Akul Datta

This paper reviews the development of the Receptance Weighted Key Value
(RWKV) architecture, emphasizing its advancements in efficient language
modeling. RWKV combines the training efficiency of Transformers with the
inference efficiency of RNNs through a novel linear attention mechanism. We
examine its core innovations, adaptations across various domains, and
performance advantages over traditional models. The paper also discusses
challenges and future directions for RWKV as a versatile architecture in deep
learning.

摘要：本文回顧了接受權重關鍵值 (RWKV) 架構的發展，重點說明其在高效語言建模方面的進展。RWKV 透過創新的線性注意力機制，結合了 Transformer 的訓練效率和 RNN 的推論效率。我們檢視了其核心創新、在各個領域的適應性，以及相較於傳統模型的效能優勢。本文也探討了 RWKV 作為深度學習中多功能架構所面臨的挑戰和未來方向。

##### **Toward Robust Incomplete Multimodal Sentiment Analysis via Hierarchical Representation Learning**
2411.02793v1 by Mingcheng Li, Dingkang Yang, Yang Liu, Shunli Wang, Jiawei Chen, Shuaibing Wang, Jinjie Wei, Yue Jiang, Qingyao Xu, Xiaolu Hou, Mingyang Sun, Ziyun Qian, Dongliang Kou, Lihua Zhang

Multimodal Sentiment Analysis (MSA) is an important research area that aims
to understand and recognize human sentiment through multiple modalities. The
complementary information provided by multimodal fusion promotes better
sentiment analysis compared to utilizing only a single modality. Nevertheless,
in real-world applications, many unavoidable factors may lead to situations of
uncertain modality missing, thus hindering the effectiveness of multimodal
modeling and degrading the model's performance. To this end, we propose a
Hierarchical Representation Learning Framework (HRLF) for the MSA task under
uncertain missing modalities. Specifically, we propose a fine-grained
representation factorization module that sufficiently extracts valuable
sentiment information by factorizing modality into sentiment-relevant and
modality-specific representations through crossmodal translation and sentiment
semantic reconstruction. Moreover, a hierarchical mutual information
maximization mechanism is introduced to incrementally maximize the mutual
information between multi-scale representations to align and reconstruct the
high-level semantics in the representations. Ultimately, we propose a
hierarchical adversarial learning mechanism that further aligns and adapts the
latent distribution of sentiment-relevant representations to produce robust
joint multimodal representations. Comprehensive experiments on three datasets
demonstrate that HRLF significantly improves MSA performance under uncertain
modality missing cases.

摘要：多模态情感分析 (MSA) 是一项重要的研究领域，旨在通过多种模态来理解和识别人类情感。多模态融合提供的互补信息促进了更好的情感分析，与仅使用单一模态相比。然而，在实际应用中，许多不可避免的因素可能导致不确定的模态缺失的情况，从而阻碍多模态建模的有效性并降低模型的性能。为此，我们提出了一种用于不确定缺失模态下的 MSA 任务的分层表示学习框架 (HRLF)。具体来说，我们提出了一种细粒度的表示因子分解模块，该模块通过跨模态翻译和情感语义重建将模态分解为与情感相关的表示和模态特定的表示，从而充分提取有价值的情感信息。此外，引入了一种分层互信息最大化机制，以逐步最大化多尺度表示之间的互信息，以对齐和重建表示中的高级语义。最终，我们提出了一种分层对抗性学习机制，该机制进一步对齐和调整与情感相关的表示的潜在分布，以产生鲁棒的联合多模态表示。在三个数据集上的综合实验表明，HRLF 在不确定的模态缺失情况下显著提高了 MSA 性能。

##### **Language Models and Cycle Consistency for Self-Reflective Machine Translation**
2411.02791v1 by Jianqiao Wangni

This paper introduces a novel framework that leverages large language models
(LLMs) for machine translation (MT). We start with one conjecture: an ideal
translation should contain complete and accurate information for a strong
enough LLM to recover the original sentence. We generate multiple translation
candidates from a source language A to a target language B, and subsequently
translate these candidates back to the original language A. By evaluating the
cycle consistency between the original and back-translated sentences using
metrics such as token-level precision and accuracy, we implicitly estimate the
translation quality in language B, without knowing its ground-truth. This also
helps to evaluate the LLM translation capability, only with monolingual
corpora. For each source sentence, we identify the translation candidate with
optimal cycle consistency with the original sentence as the final answer. Our
experiments demonstrate that larger LLMs, or the same LLM with more forward
passes during inference, exhibit increased cycle consistency, aligning with the
LLM model size scaling law and test-time computation scaling law. This work
provide methods for, 1) to implicitly evaluate translation quality of a
sentence in the target language, 2), to evaluate capability of LLM for
any-to-any-language translation, and 3), how to generate a better translation
for a specific LLM.

摘要：本文介紹了一個新穎的架構，它利用大型語言模型 (LLM) 進行機器翻譯 (MT)。我們從一個猜想開始：理想的翻譯應包含完整且準確的資訊，讓足夠強大的 LLM 能夠還原原始句子。我們從原始語言 A 產生多個翻譯候選，再將這些候選翻譯回原始語言 A。透過使用指標（例如：標記層級的精確度和準確性）評估原始句子和回譯句子的循環一致性，我們隱含地估計語言 B 的翻譯品質，而不知道其真實情況。這也有助於只使用單語料庫評估 LLM 翻譯能力。對於每個原始句子，我們找出與原始句子循環一致性最佳的翻譯候選，作為最終答案。我們的實驗證明，較大的 LLM，或推理期間具有更多前向傳遞的相同 LLM，會表現出更高的循環一致性，與 LLM 模型大小縮放定律和測試時間運算縮放定律一致。這項工作提供的方法包括：1) 隱含地評估目標語言中句子的翻譯品質，2) 評估 LLM 在任意語言間翻譯的能力，以及 3) 如何為特定的 LLM 產生更好的翻譯。

##### **Memory Augmented Cross-encoders for Controllable Personalized Search**
2411.02790v1 by Sheshera Mysore, Garima Dhanania, Kishor Patil, Surya Kallumadi, Andrew McCallum, Hamed Zamani

Personalized search represents a problem where retrieval models condition on
historical user interaction data in order to improve retrieval results.
However, personalization is commonly perceived as opaque and not amenable to
control by users. Further, personalization necessarily limits the space of
items that users are exposed to. Therefore, prior work notes a tension between
personalization and users' ability for discovering novel items. While discovery
of novel items in personalization setups may be resolved through search result
diversification, these approaches do little to allow user control over
personalization. Therefore, in this paper, we introduce an approach for
controllable personalized search. Our model, CtrlCE presents a novel
cross-encoder model augmented with an editable memory constructed from users
historical items. Our proposed memory augmentation allows cross-encoder models
to condition on large amounts of historical user data and supports interaction
from users permitting control over personalization. Further, controllable
personalization for search must account for queries which don't require
personalization, and in turn user control. For this, we introduce a calibrated
mixing model which determines when personalization is necessary. This allows
system designers using CtrlCE to only obtain user input for control when
necessary. In multiple datasets of personalized search, we show CtrlCE to
result in effective personalization as well as fulfill various key goals for
controllable personalized search.

摘要：個人化搜尋代表一個問題，其中檢索模型會根據歷史使用者互動資料來改善檢索結果。
然而，個人化通常被認為是不透明的，而且使用者無法控制。此外，個人化勢必會限制使用者接觸到的項目空間。因此，先前的研究指出個人化與使用者發現新項目的能力之間存在緊張關係。雖然在個人化設定中發現新項目可以透過搜尋結果多樣化來解決，但這些方法對於讓使用者控制個人化幾乎沒有幫助。因此，在本文中，我們介紹一種可控個人化搜尋的方法。我們的模型 CtrlCE 提出了一個新穎的跨編碼器模型，並使用由使用者歷史項目建構的可編輯記憶體進行擴充。我們提出的記憶體擴充允許跨編碼器模型根據大量的使用者歷史資料進行調整，並支援使用者互動，讓使用者可以控制個人化。此外，搜尋的可控個人化必須考慮不需要個人化和使用者控制的查詢。對於這一點，我們引入了一個校準混合模型，用來判斷何時需要個人化。這讓系統設計人員在使用 CtrlCE 時，只有在必要時才會取得使用者的輸入以進行控制。在多個個人化搜尋資料集中，我們展示了 CtrlCE 如何產生有效的個人化，並滿足可控個人化搜尋的各種關鍵目標。

##### **When to Localize? A Risk-Constrained Reinforcement Learning Approach**
2411.02788v1 by Chak Lam Shek, Kasra Torshizi, Troi Williams, Pratap Tokekar

In a standard navigation pipeline, a robot localizes at every time step to
lower navigational errors. However, in some scenarios, a robot needs to
selectively localize when it is expensive to obtain observations. For example,
an underwater robot surfacing to localize too often hinders it from searching
for critical items underwater, such as black boxes from crashed aircraft. On
the other hand, if the robot never localizes, poor state estimates cause
failure to find the items due to inadvertently leaving the search area or
entering hazardous, restricted areas. Motivated by these scenarios, we
investigate approaches to help a robot determine "when to localize?" We
formulate this as a bi-criteria optimization problem: minimize the number of
localization actions while ensuring the probability of failure (due to
collision or not reaching a desired goal) remains bounded. In recent work, we
showed how to formulate this active localization problem as a constrained
Partially Observable Markov Decision Process (POMDP), which was solved using an
online POMDP solver. However, this approach is too slow and requires full
knowledge of the robot transition and observation models. In this paper, we
present RiskRL, a constrained Reinforcement Learning (RL) framework that
overcomes these limitations. RiskRL uses particle filtering and recurrent Soft
Actor-Critic network to learn a policy that minimizes the number of
localizations while ensuring the probability of failure constraint is met. Our
numerical experiments show that RiskRL learns a robust policy that outperforms
the baseline by at least 13% while also generalizing to unseen environments.

摘要：在標準導航管線中，機器人在每個時間步驟進行定位以降低導航錯誤。然而，在某些情況下，機器人在取得觀測值成本過高時，需要選擇性定位。例如，水下機器人過於頻繁地浮出水面進行定位，會妨礙它在水下尋找關鍵物品，例如墜毀飛機的黑盒子。另一方面，如果機器人從未進行定位，則狀態估計不佳會導致無法找到物品，因為它會無意間離開搜尋區域或進入危險的受限區域。受到這些情況的啟發，我們研究了幫助機器人確定「何時定位」的方法。我們將此表述為雙準則最佳化問題：最小化定位動作的次數，同時確保失敗的機率（由於碰撞或未達到預期目標）保持在有界限的狀態。在最近的研究中，我們展示了如何將此主動定位問題表述為受限部分可觀察馬可夫決策過程 (POMDP)，並使用線上 POMDP 求解器求解。然而，此方法太慢，且需要機器人轉換和觀測模型的完整知識。在本文中，我們提出了 RiskRL，這是一個受限強化學習 (RL) 架構，克服了這些限制。RiskRL 使用粒子濾波和遞迴軟性動作-評論家網路，來學習一種策略，以最小化定位次數，同時確保滿足失敗機率限制。我們的數值實驗表明，RiskRL 學習到一種穩健的策略，其效能至少比基準高出 13%，同時也能泛化到未見過的環境。

##### **Stochastic Monkeys at Play: Random Augmentations Cheaply Break LLM Safety Alignment**
2411.02785v1 by Jason Vega, Junsheng Huang, Gaokai Zhang, Hangoo Kang, Minjia Zhang, Gagandeep Singh

Safety alignment of Large Language Models (LLMs) has recently become a
critical objective of model developers. In response, a growing body of work has
been investigating how safety alignment can be bypassed through various
jailbreaking methods, such as adversarial attacks. However, these jailbreak
methods can be rather costly or involve a non-trivial amount of creativity and
effort, introducing the assumption that malicious users are high-resource or
sophisticated. In this paper, we study how simple random augmentations to the
input prompt affect safety alignment effectiveness in state-of-the-art LLMs,
such as Llama 3 and Qwen 2. We perform an in-depth evaluation of 17 different
models and investigate the intersection of safety under random augmentations
with multiple dimensions: augmentation type, model size, quantization,
fine-tuning-based defenses, and decoding strategies (e.g., sampling
temperature). We show that low-resource and unsophisticated attackers, i.e.
$\textit{stochastic monkeys}$, can significantly improve their chances of
bypassing alignment with just 25 random augmentations per prompt.

摘要：大型語言模型 (LLM) 的安全調整最近已成為模型開發者的重要目標。為此，越來越多的研究探討如何透過各種越獄方法（例如對抗攻擊）來繞過安全調整。然而，這些越獄方法可能相當昂貴，或需要大量創意和精力，這表示惡意使用者擁有豐富資源或老練。在本文中，我們研究輸入提示的簡單隨機增強如何影響最先進的 LLM（例如 Llama 3 和 Qwen 2）中的安全調整效能。我們對 17 種不同的模型進行深入評估，並研究隨機增強下的安全性與多個面向的交集：增強類型、模型大小、量化、基於微調的防禦，以及解碼策略（例如，抽樣溫度）。我們表明，資源不足且不老練的攻擊者，即「隨機猴子」，只需在每個提示中進行 25 次隨機增強，就能顯著提高他們繞過調整的機率。

##### **EcoCropsAID: Economic Crops Aerial Image Dataset for Land Use Classification**
2411.02762v1 by Sangdaow Noppitak, Emmanuel Okafor, Olarik Surinta

The EcoCropsAID dataset is a comprehensive collection of 5,400 aerial images
captured between 2014 and 2018 using the Google Earth application. This dataset
focuses on five key economic crops in Thailand: rice, sugarcane, cassava,
rubber, and longan. The images were collected at various crop growth stages:
early cultivation, growth, and harvest, resulting in significant variability
within each category and similarities across different categories. These
variations, coupled with differences in resolution, color, and contrast
introduced by multiple remote imaging sensors, present substantial challenges
for land use classification. The dataset is an interdisciplinary resource that
spans multiple research domains, including remote sensing, geoinformatics,
artificial intelligence, and computer vision. The unique features of the
EcoCropsAID dataset offer opportunities for researchers to explore novel
approaches, such as extracting spatial and temporal features, developing deep
learning architectures, and implementing transformer-based models. The
EcoCropsAID dataset provides a valuable platform for advancing research in land
use classification, with implications for optimizing agricultural practices and
enhancing sustainable development. This study explicitly investigates the use
of deep learning algorithms to classify economic crop areas in northeastern
Thailand, utilizing satellite imagery to address the challenges posed by
diverse patterns and similarities across categories.

摘要：EcoCropsAID 資料集是一個全面的資料集，包含 5,400 張航拍影像，使用 Google Earth 應用程式於 2014 年至 2018 年間拍攝。這個資料集著重於泰國的五大經濟作物：稻米、甘蔗、木薯、橡膠和龍眼。影像在不同作物生長階段收集：早期耕作、生長和收成，導致每個類別內部有顯著的變異性，以及不同類別之間的相似性。這些變異，加上多個遙測感測器所帶來的解析度、顏色和對比差異，為土地利用分類帶來極大的挑戰。這個資料集是一個跨領域的資源，涵蓋多個研究領域，包括遙測、地理資訊學、人工智慧和電腦視覺。EcoCropsAID 資料集的獨特特點為研究人員提供了探索新方法的機會，例如萃取空間和時間特徵、開發深度學習架構，以及實作基於Transformer的模型。EcoCropsAID 資料集提供了一個有價值的平台，用於推進土地利用分類的研究，對最佳化農業實務和加強永續發展有影響。本研究明確地探討使用深度學習演算法來分類泰國東北部的經濟作物區，利用衛星影像來解決不同類別之間模式多樣和相似性所帶來的挑戰。

##### **A Bayesian explanation of machine learning models based on modes and functional ANOVA**
2411.02746v1 by Quan Long

Most methods in explainable AI (XAI) focus on providing reasons for the
prediction of a given set of features. However, we solve an inverse explanation
problem, i.e., given the deviation of a label, find the reasons of this
deviation. We use a Bayesian framework to recover the ``true'' features,
conditioned on the observed label value. We efficiently explain the deviation
of a label value from the mode, by identifying and ranking the influential
features using the ``distances'' in the ANOVA functional decomposition. We show
that the new method is more human-intuitive and robust than methods based on
mean values, e.g., SHapley Additive exPlanations (SHAP values). The extra costs
of solving a Bayesian inverse problem are dimension-independent.

摘要：大多數可解釋 AI (XAI) 中的方法都專注於提供給定特徵組預測的理由。然而，我們解決一個反向解釋問題，即給定標籤的偏差，找出此偏差的原因。我們使用貝氏架構來恢復「真實」特徵，條件為觀察到的標籤值。我們透過使用 ANOVA 函數分解中的「距離」來識別和排列影響力特徵，有效地解釋標籤值與模式的偏差。我們展示新的方法比基於平均值的方法（例如 SHapley Additive exPlanations (SHAP 值)）更符合人類直覺且更強健。解決貝氏反向問題的額外成本與維度無關。

##### **Novelty-focused R&D landscaping using transformer and local outlier factor**
2411.02738v1 by Jaewoong Choi

While numerous studies have explored the field of research and development
(R&D) landscaping, the preponderance of these investigations has emphasized
predictive analysis based on R&D outcomes, specifically patents, and academic
literature. However, the value of research proposals and novelty analysis has
seldom been addressed. This study proposes a systematic approach to
constructing and navigating the R&D landscape that can be utilized to guide
organizations to respond in a reproducible and timely manner to the challenges
presented by increasing number of research proposals. At the heart of the
proposed approach is the composite use of the transformer-based language model
and the local outlier factor (LOF). The semantic meaning of the research
proposals is captured with our further-trained transformers, thereby
constructing a comprehensive R&D landscape. Subsequently, the novelty of the
newly selected research proposals within the annual landscape is quantified on
a numerical scale utilizing the LOF by assessing the dissimilarity of each
proposal to others preceding and within the same year. A case study examining
research proposals in the energy and resource sector in South Korea is
presented. The systematic process and quantitative outcomes are expected to be
useful decision-support tools, providing future insights regarding R&D planning
and roadmapping.

摘要：儘管許多研究已探討研發 (R&D) 領域的現況，但這些調查大多強調基於研發成果（特別是專利和學術文獻）的預測分析。然而，研究提案和新穎性分析的價值卻鮮少被探討。本研究提出構建和導航研發現況的系統化方法，可用於指導組織以可複製且及時的方式回應研究提案數量增加所帶來的挑戰。所提出方法的核心是Transformer語言模型和局部離群因子 (LOF) 的複合使用。我們進一步訓練過的Transformer捕捉了研究提案的語義含義，從而構建了一個全面的研發現況。隨後，通過評估每個提案與前一年和同年內其他提案的差異性，利用 LOF 在數值量表上量化年度現況中新選出的研究提案的新穎性。本研究提出了一個案例研究，探討了韓國能源和資源部門的研究提案。預計系統化流程和量化結果將成為有用的決策支援工具，為研發規劃和路線圖提供未來的見解。

##### **A Natural Language Processing Approach to Support Biomedical Data Harmonization: Leveraging Large Language Models**
2411.02730v1 by Zexu Li, Suraj P. Prabhu, Zachary T. Popp, Shubhi S. Jain, Vijetha Balakundi, Ting Fang Alvin Ang, Rhoda Au, Jinying Chen

Biomedical research requires large, diverse samples to produce unbiased
results. Automated methods for matching variables across datasets can
accelerate this process. Research in this area has been limited, primarily
focusing on lexical matching and ontology based semantic matching. We aimed to
develop new methods, leveraging large language models (LLM) and ensemble
learning, to automate variable matching. Methods: We utilized data from two
GERAS cohort (European and Japan) studies to develop variable matching methods.
We first manually created a dataset by matching 352 EU variables with 1322
candidate JP variables, where matched variable pairs were positive and
unmatched pairs were negative instances. Using this dataset, we developed and
evaluated two types of natural language processing (NLP) methods, which matched
variables based on variable labels and definitions from data dictionaries: (1)
LLM-based and (2) fuzzy matching. We then developed an ensemble-learning
method, using the Random Forest model, to integrate individual NLP methods. RF
was trained and evaluated on 50 trials. Each trial had a random split (4:1) of
training and test sets, with the model's hyperparameters optimized through
cross-validation on the training set. For each EU variable, 1322 candidate JP
variables were ranked based on NLP-derived similarity scores or RF's
probability scores, denoting their likelihood to match the EU variable. Ranking
performance was measured by top-n hit ratio (HRn) and mean reciprocal rank
(MRR). Results:E5 performed best among individual methods, achieving 0.90 HR-30
and 0.70 MRR. RF performed better than E5 on all metrics over 50 trials (P less
than 0.001) and achieved an average HR 30 of 0.98 and MRR of 0.73. LLM-derived
features contributed most to RF's performance. One major cause of errors in
automatic variable matching was ambiguous variable definitions within data
dictionaries.

摘要：<paragraph>生物医学研究需要大量多样的样本才能产生无偏结果。跨数据集匹配变量的自动化方法可以加速此过程。该领域的研究一直受到限制，主要集中在词法匹配和基于本体的语义匹配上。我们旨在开发新方法，利用大型语言模型 (LLM) 和集成学习，实现变量匹配自动化。方法：我们利用来自两个 GERAS 队列（欧洲和日本）研究的数据来开发变量匹配方法。我们首先通过将 352 个欧盟变量与 1322 个候选日本变量进行匹配来手动创建数据集，其中匹配的变量对为正例，未匹配的对为反例。使用此数据集，我们开发并评估了两种类型的自然语言处理 (NLP) 方法，这些方法根据数据词典中的变量标签和定义匹配变量：(1) 基于 LLM 的方法和 (2) 模糊匹配。然后，我们开发了一种集成学习方法，使用随机森林模型来集成各个 NLP 方法。RF 在 50 次试验中接受训练和评估。每次试验都随机拆分 (4:1) 训练集和测试集，并通过训练集上的交叉验证优化模型的超参数。对于每个欧盟变量，1322 个候选日本变量根据 NLP 导出的相似性得分或 RF 的概率得分进行排名，表示它们与欧盟变量匹配的可能性。排名性能通过前 n 命中率 (HRn) 和平均倒数排名 (MRR) 来衡量。结果：E5 在各个方法中表现最佳，达到 0.90 HR-30 和 0.70 MRR。RF 在 50 次试验中在所有指标上都优于 E5（P 小于 0.001），并实现了平均 HR 30 为 0.98 和 MRR 为 0.73。LLM 衍生的特征对 RF 的性能贡献最大。自动变量匹配中错误的一个主要原因是数据词典中变量定义不明确。</paragraph>

##### **Multimodal Commonsense Knowledge Distillation for Visual Question Answering**
2411.02722v1 by Shuo Yang, Siwen Luo, Soyeon Caren Han

Existing Multimodal Large Language Models (MLLMs) and Visual Language
Pretrained Models (VLPMs) have shown remarkable performances in the general
Visual Question Answering (VQA). However, these models struggle with VQA
questions that require external commonsense knowledge due to the challenges in
generating high-quality prompts and the high computational costs of
fine-tuning. In this work, we propose a novel graph-based multimodal
commonsense knowledge distillation framework that constructs a unified
relational graph over commonsense knowledge, visual objects and questions
through a Graph Convolutional Network (GCN) following a teacher-student
environment. This proposed framework is flexible with any type of teacher and
student models without further fine-tuning, and has achieved competitive
performances on the ScienceQA dataset.

摘要：現有的多模態大型語言模型 (MLLM) 和視覺語言預訓練模型 (VLPM) 在一般的視覺問答 (VQA) 中展現了卓越的表現。然而，這些模型在需要外部常識知識的 VQA 問題上會遇到困難，原因在於產生高品質提示的挑戰以及微調的高運算成本。在這項工作中，我們提出了一個新穎的基於圖形的模態常識知識萃取架構，透過圖形卷積網路 (GCN) 在常識知識、視覺物件和問題上建構一個統一的關聯圖形，遵循師生環境。這個提出的架構對於任何類型的教師和學生模型都具有彈性，無需進一步微調，並在 ScienceQA 資料集上取得了有競爭力的表現。

##### **Game Plot Design with an LLM-powered Assistant: An Empirical Study with Game Designers**
2411.02714v1 by Seyed Hossein Alavi, Weijia Xu, Nebojsa Jojic, Daniel Kennett, Raymond T. Ng, Sudha Rao, Haiyan Zhang, Bill Dolan, Vered Shwartz

We introduce GamePlot, an LLM-powered assistant that supports game designers
in crafting immersive narratives for turn-based games, and allows them to test
these games through a collaborative game play and refine the plot throughout
the process. Our user study with 14 game designers shows high levels of both
satisfaction with the generated game plots and sense of ownership over the
narratives, but also reconfirms that LLM are limited in their ability to
generate complex and truly innovative content. We also show that diverse user
populations have different expectations from AI assistants, and encourage
researchers to study how tailoring assistants to diverse user groups could
potentially lead to increased job satisfaction and greater creativity and
innovation over time.

摘要：我們推出 GamePlot，這是一款由大型語言模型 (LLM) 驅動的助理，可協助遊戲設計師為回合制遊戲打造沉浸式敘事，並允許他們透過協作遊戲玩法來測試這些遊戲，並在整個過程中精進情節。我們針對 14 位遊戲設計師進行的使用者研究顯示，對於產生的遊戲情節非常滿意，且對敘事的擁有感也很高，但也再次確認 LLM 在產生複雜且真正創新的內容方面有其限制。我們還發現，不同的使用者族群對 AI 助理有不同的期望，並鼓勵研究人員研究如何針對不同的使用者群體調整助理，這有可能隨著時間的推移而提高工作滿意度、創造力和創新力。

##### **V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization**
2411.02712v1 by Yuxi Xie, Guanzhen Li, Xiao Xu, Min-Yen Kan

Large vision-language models (LVLMs) suffer from hallucination, resulting in
misalignment between the output textual response and the input visual content.
Recent research indicates that the over-reliance on the Large Language Model
(LLM) backbone, as one cause of the LVLM hallucination, inherently introduces
bias from language priors, leading to insufficient context attention to the
visual inputs.
  We tackle this issue of hallucination by mitigating such over-reliance
through preference learning. We propose Vision-guided Direct Preference
Optimization (V-DPO) to enhance visual context learning at training time. To
interpret the effectiveness and generalizability of V-DPO on different types of
training data, we construct a synthetic dataset containing both response- and
image-contrast preference pairs, compared against existing human-annotated
hallucination samples. Our approach achieves significant improvements compared
with baseline methods across various hallucination benchmarks. Our analysis
indicates that V-DPO excels in learning from image-contrast preference data,
demonstrating its superior ability to elicit and understand nuances of visual
context. Our code is publicly available at https://github.com/YuxiXie/V-DPO.

摘要：大型视觉语言模型 (LVLMs) 会出现幻觉，导致输出文本响应与输入视觉内容之间不一致。
最近的研究表明，过度依赖大型语言模型 (LLM) 主干，作为 LVLM 幻觉的一个原因，本质上会引入语言先验的偏差，导致对视觉输入的上下文关注不足。
我们通过偏好学习来解决幻觉问题，以减轻这种过度依赖。我们提出了视觉引导直接偏好优化 (V-DPO)，以在训练时增强视觉上下文学习。为了解释 V-DPO 在不同类型的训练数据上的有效性和可推广性，我们构建了一个包含响应和图像对比偏好对的合成数据集，并与现有人工标注的幻觉样本进行比较。与各种幻觉基准中的基线方法相比，我们的方法取得了显着的改进。我们的分析表明，V-DPO 擅长从图像对比偏好数据中学习，展示了其引出和理解视觉上下文细微差别的卓越能力。我们的代码可在 https://github.com/YuxiXie/V-DPO 公开获得。

##### **Exploring Response Uncertainty in MLLMs: An Empirical Evaluation under Misleading Scenarios**
2411.02708v1 by Yunkai Dang, Mengxi Gao, Yibo Yan, Xin Zou, Yanggan Gu, Aiwei Liu, Xuming Hu

Ensuring that Multimodal Large Language Models (MLLMs) maintain consistency
in their responses is essential for developing trustworthy multimodal
intelligence. However, existing benchmarks include many samples where all MLLMs
\textit{exhibit high response uncertainty when encountering misleading
information}, requiring even 5-15 response attempts per sample to effectively
assess uncertainty. Therefore, we propose a two-stage pipeline: first, we
collect MLLMs' responses without misleading information, and then gather
misleading ones via specific misleading instructions. By calculating the
misleading rate, and capturing both correct-to-incorrect and
incorrect-to-correct shifts between the two sets of responses, we can
effectively metric the model's response uncertainty. Eventually, we establish a
\textbf{\underline{M}}ultimodal \textbf{\underline{U}}ncertainty
\textbf{\underline{B}}enchmark (\textbf{MUB}) that employs both explicit and
implicit misleading instructions to comprehensively assess the vulnerability of
MLLMs across diverse domains. Our experiments reveal that all open-source and
close-source MLLMs are highly susceptible to misleading instructions, with an
average misleading rate exceeding 86\%. To enhance the robustness of MLLMs, we
further fine-tune all open-source MLLMs by incorporating explicit and implicit
misleading data, which demonstrates a significant reduction in misleading
rates. Our code is available at:
\href{https://github.com/Yunkai696/MUB}{https://github.com/Yunkai696/MUB}

摘要：<paragraph>確保多模態大型語言模型 (MLLM) 在其回應中保持一致性，對於開發值得信賴的多模態智能至關重要。然而，現有的基準包含許多範例，其中所有 MLLM \textit{在遇到誤導性資訊時展現出高度的回應不確定性}，需要每個範例 5-15 次的回應嘗試才能有效評估不確定性。因此，我們提出一個兩階段流程：首先，我們收集 MLLM 在沒有誤導性資訊下的回應，然後透過特定的誤導性指示收集誤導性資訊。透過計算誤導率，並擷取兩組回應之間從正確到不正確以及從不正確到正確的轉變，我們可以有效地衡量模型的回應不確定性。最後，我們建立一個\textbf{\underline{M}}ultimodal \textbf{\underline{U}}ncertainty \textbf{\underline{B}}enchmark (\textbf{MUB})，它採用明確和隱含的誤導性指示，以全面評估 MLLM 在不同領域的脆弱性。我們的實驗揭露，所有開源和閉源 MLLM 都極易受到誤導性指示的影響，平均誤導率超過 86%。為了提升 MLLM 的穩健性，我們進一步微調所有開源 MLLM，方法是納入明確和隱含的誤導性資料，這證明誤導率有顯著的降低。我們的程式碼可在以下位置取得：
\href{https://github.com/Yunkai696/MUB}{https://github.com/Yunkai696/MUB}</paragraph>

##### **RT-Affordance: Affordances are Versatile Intermediate Representations for Robot Manipulation**
2411.02704v1 by Soroush Nasiriany, Sean Kirmani, Tianli Ding, Laura Smith, Yuke Zhu, Danny Driess, Dorsa Sadigh, Ted Xiao

We explore how intermediate policy representations can facilitate
generalization by providing guidance on how to perform manipulation tasks.
Existing representations such as language, goal images, and trajectory sketches
have been shown to be helpful, but these representations either do not provide
enough context or provide over-specified context that yields less robust
policies. We propose conditioning policies on affordances, which capture the
pose of the robot at key stages of the task. Affordances offer expressive yet
lightweight abstractions, are easy for users to specify, and facilitate
efficient learning by transferring knowledge from large internet datasets. Our
method, RT-Affordance, is a hierarchical model that first proposes an
affordance plan given the task language, and then conditions the policy on this
affordance plan to perform manipulation. Our model can flexibly bridge
heterogeneous sources of supervision including large web datasets and robot
trajectories. We additionally train our model on cheap-to-collect in-domain
affordance images, allowing us to learn new tasks without collecting any
additional costly robot trajectories. We show on a diverse set of novel tasks
how RT-Affordance exceeds the performance of existing methods by over 50%, and
we empirically demonstrate that affordances are robust to novel settings.
Videos available at https://snasiriany.me/rt-affordance

摘要：我們探討如何透過提供操作任務執行指南，讓中間策略表示促進概化。
語言、目標影像和軌跡草圖等現有表示已證實有所幫助，但這些表示不是提供不足夠的背景，就是提供過於具體的背景，導致策略較不穩健。我們建議對可供性進行條件策略，可供性會捕捉機器人在任務關鍵階段的姿勢。可供性提供具表現力但輕量化的抽象，使用者容易指定，並透過從大型網路資料集傳輸知識，促進有效率的學習。我們的 RT-Affordance 方法是一個階層模型，會先提出一個可供性計畫，並根據任務語言，然後對這個可供性計畫進行條件策略，以執行操作。我們的模型可以靈活地連結異質監督來源，包括大型網路資料集和機器人軌跡。我們另外在便宜且容易收集的領域內可供性影像上訓練我們的模型，讓我們得以在不收集任何額外昂貴機器人軌跡的情況下學習新任務。我們在各種新任務上展示 RT-Affordance 如何超過現有方法的效能 50% 以上，而且我們透過經驗證明可供性對於新設定很穩健。影片可於 https://snasiriany.me/rt-affordance 取得

##### **JEL: Applying End-to-End Neural Entity Linking in JPMorgan Chase**
2411.02695v1 by Wanying Ding, Vinay K. Chaudhri, Naren Chittar, Krishna Konakanchi

Knowledge Graphs have emerged as a compelling abstraction for capturing key
relationship among the entities of interest to enterprises and for integrating
data from heterogeneous sources. JPMorgan Chase (JPMC) is leading this trend by
leveraging knowledge graphs across the organization for multiple mission
critical applications such as risk assessment, fraud detection, investment
advice, etc. A core problem in leveraging a knowledge graph is to link mentions
(e.g., company names) that are encountered in textual sources to entities in
the knowledge graph. Although several techniques exist for entity linking, they
are tuned for entities that exist in Wikipedia, and fail to generalize for the
entities that are of interest to an enterprise. In this paper, we propose a
novel end-to-end neural entity linking model (JEL) that uses minimal context
information and a margin loss to generate entity embeddings, and a Wide & Deep
Learning model to match character and semantic information respectively. We
show that JEL achieves the state-of-the-art performance to link mentions of
company names in financial news with entities in our knowledge graph. We report
on our efforts to deploy this model in the company-wide system to generate
alerts in response to financial news. The methodology used for JEL is directly
applicable and usable by other enterprises who need entity linking solutions
for data that are unique to their respective situations.

摘要：知識圖譜已成為捕捉企業感興趣實體之間關鍵關係以及整合異質來源資料的強大抽象概念。摩根大通（JPMC）透過在組織內跨多個任務關鍵應用程式（例如風險評估、詐欺偵測、投資建議等）利用知識圖譜，引領這股趨勢。利用知識圖譜的核心問題是將在文字來源中遇到的提及（例如公司名稱）連結到知識圖譜中的實體。儘管有數種實體連結技術，但這些技術針對維基百科中存在的實體進行調整，無法概括到企業感興趣的實體。在本文中，我們提出一個新穎的端對端神經實體連結模型（JEL），該模型使用最少的脈絡資訊和邊際損失來產生實體嵌入，並使用廣泛且深入的學習模型分別比對字元和語義資訊。我們證明 JEL 達到最先進的效能，可以將財經新聞中公司名稱的提及連結到我們知識圖譜中的實體。我們報告我們在公司範圍內系統中部署此模型的成果，以產生對財經新聞的警示。JEL 使用的方法直接適用於且可用於其他企業，這些企業需要針對其各自情況中獨特的資料提供實體連結解決方案。

##### **JPEC: A Novel Graph Neural Network for Competitor Retrieval in Financial Knowledge Graphs**
2411.02692v1 by Wanying Ding, Manoj Cherukumalli, Santosh Chikoti, Vinay K. Chaudhri

Knowledge graphs have gained popularity for their ability to organize and
analyze complex data effectively. When combined with graph embedding
techniques, such as graph neural networks (GNNs), knowledge graphs become a
potent tool in providing valuable insights. This study explores the application
of graph embedding in identifying competitors from a financial knowledge graph.
Existing state-of-the-art(SOTA) models face challenges due to the unique
attributes of our knowledge graph, including directed and undirected
relationships, attributed nodes, and minimal annotated competitor connections.
To address these challenges, we propose a novel graph embedding model,
JPEC(JPMorgan Proximity Embedding for Competitor Detection), which utilizes
graph neural network to learn from both first-order and second-order node
proximity together with vital features for competitor retrieval. JPEC had
outperformed most existing models in extensive experiments, showcasing its
effectiveness in competitor retrieval.

摘要：知識圖譜因其有效組織和分析複雜資料的能力而廣受歡迎。當與圖形嵌入技術（如圖形神經網路 (GNN)）結合使用時，知識圖譜將成為提供有價值見解的強大工具。本研究探討了圖形嵌入在從財務知識圖譜中識別競爭對手的應用。現有的最先進 (SOTA) 模型由於我們知識圖譜的獨特屬性（包括有向和無向關係、帶屬性的節點以及最少註解的競爭對手連接）而面臨挑戰。為了應對這些挑戰，我們提出了一個新穎的圖形嵌入模型 JPEC（摩根大通競爭對手檢測鄰近嵌入），它利用圖形神經網路從一階和二階節點鄰近度以及競爭對手擷取的重要特徵中學習。在廣泛的實驗中，JPEC 的表現優於大多數現有模型，展示了其在競爭對手擷取中的有效性。

##### **On the loss of context-awareness in general instruction fine-tuning**
2411.02688v1 by Yihan Wang, Andrew Bai, Nanyun Peng, Cho-Jui Hsieh

Pretrained Large Language Models (LLMs) require post-training methods such as
supervised fine-tuning (SFT) on instruction-response pairs to enable
instruction following. However, this process can potentially harm existing
capabilities learned during pretraining. In this paper, we investigate the loss
of context awareness after SFT, defined as the capability to extract and
understand information from the user-provided context and respond accordingly.
We are the first to identify and show that the loss of context-awareness
appears on instruction-finetuned LLMs when the chat template is applied to the
input prompts. We identify the performance decline is partially caused by the
bias embedded into the chat template to focus less on the user-provided
context. Based on these observations, we propose two methods to mitigate the
loss of context awareness in instruct models: post-hoc attention steering on
user prompts and conditional instruction fine-tuning with a context-dependency
indicator. Empirical experiments on 4 context-dependent downstream tasks and 3
pretrained LLMs of different sizes show that our methods effectively mitigates
the loss of context awareness without compromising the general ability to
follow instructions. Our findings also strongly advocate the necessity to
carefully benchmark context awareness after instruction fine-tuning.

摘要：預訓練大型語言模型 (LLM) 需要後訓練方法，例如對指令回應配對進行監督微調 (SFT)，以實現指令遵循。然而，此程序可能會對預訓練期間學習到的現有能力造成潛在傷害。在本文中，我們探討了 SFT 後的背景認知損失，定義為從使用者提供的背景中提取和理解資訊並做出相應回應的能力。我們率先發現並展示了當聊天範本套用於輸入提示時，背景認知損失出現在指令微調 LLM 上。我們發現效能下降部分是由於聊天範本中內嵌的偏差，較少關注使用者提供的背景。根據這些觀察，我們提出了兩種方法來減輕指令模型中背景認知的損失：使用者提示的後設注意導向以及具有背景依賴性指標的條件指令微調。在 4 個背景依賴的下游任務和 3 個不同大小的預訓練 LLM 上進行的經驗實驗表明，我們的模型有效地減輕了背景認知的損失，同時不損害遵循指令的一般能力。我們的研究結果也強烈主張在指令微調後仔細評量背景認知的必要性。

##### **Geometry of naturalistic object representations in recurrent neural network models of working memory**
2411.02685v1 by Xiaoxuan Lei, Takuya Ito, Pouya Bashivan

Working memory is a central cognitive ability crucial for intelligent
decision-making. Recent experimental and computational work studying working
memory has primarily used categorical (i.e., one-hot) inputs, rather than
ecologically relevant, multidimensional naturalistic ones. Moreover, studies
have primarily investigated working memory during single or few cognitive
tasks. As a result, an understanding of how naturalistic object information is
maintained in working memory in neural networks is still lacking. To bridge
this gap, we developed sensory-cognitive models, comprising a convolutional
neural network (CNN) coupled with a recurrent neural network (RNN), and trained
them on nine distinct N-back tasks using naturalistic stimuli. By examining the
RNN's latent space, we found that: (1) Multi-task RNNs represent both
task-relevant and irrelevant information simultaneously while performing tasks;
(2) The latent subspaces used to maintain specific object properties in vanilla
RNNs are largely shared across tasks, but highly task-specific in gated RNNs
such as GRU and LSTM; (3) Surprisingly, RNNs embed objects in new
representational spaces in which individual object features are less
orthogonalized relative to the perceptual space; (4) The transformation of
working memory encodings (i.e., embedding of visual inputs in the RNN latent
space) into memory was shared across stimuli, yet the transformations governing
the retention of a memory in the face of incoming distractor stimuli were
distinct across time. Our findings indicate that goal-driven RNNs employ
chronological memory subspaces to track information over short time spans,
enabling testable predictions with neural data.

摘要：工作記憶是一種對於智能決策制定至關重要的核心認知能力。最近的研究工作記憶的實驗和計算工作主要使用分類（即一熱）輸入，而不是生態相關的多維自然輸入。此外，研究主要調查單一或少數認知任務期間的工作記憶。因此，對於神經網路中如何維持自然物體資訊的工作記憶，仍缺乏了解。為了彌補這個差距，我們開發了感官認知模型，包括卷積神經網路（CNN）與遞迴神經網路（RNN）相結合，並使用自然刺激在九個不同的 N-back 任務上對它們進行訓練。通過檢查 RNN 的潛在空間，我們發現：(1) 多任務 RNN 在執行任務時同時表示與任務相關和不相關的資訊；(2) 在香草 RNN 中用於維護特定物件屬性的潛在子空間在任務之間基本上是共享的，但在門控 RNN（例如 GRU 和 LSTM）中具有高度任務特異性；(3) 令人驚訝的是，RNN 將物件嵌入新的表示空間中，其中個別物件特徵相對於感知空間的正交化程度較低；(4) 工作記憶編碼（即視覺輸入在 RNN 潛在空間中的嵌入）轉換為記憶在所有刺激中都是共享的，但面對輸入的干擾刺激時，控制記憶保留的轉換在時間上是不同的。我們的研究結果表明，目標驅動的 RNN 使用時間順序記憶子空間來追蹤短時間範圍內的資訊，從而能夠使用神經數據進行可測試的預測。

##### **Wave Network: An Ultra-Small Language Model**
2411.02674v1 by Xin Zhang, Victor S. Sheng

We propose an innovative token representation and update method in a new
ultra-small language model: the Wave network. Specifically, we use a
\textbf{complex vector} to represent each token, encoding both global and local
semantics of the input text. A \textbf{complex vector} consists of two
components: a magnitude vector representing the \textit{global semantics} of
the input text, and a phase vector capturing the \textit{relationships between
individual tokens and global semantics}. Experiments on the AG News text
classification task demonstrate that, when generating complex vectors from
randomly initialized token embeddings, our single-layer Wave Network achieves
90.91\% accuracy with wave interference and 91.66\% with wave modulation --
outperforming a single Transformer layer using BERT pre-trained embeddings by
19.23\% and 19.98\%, respectively, and approaching the accuracy of the
pre-trained and fine-tuned BERT base model (94.64\%). Additionally, compared to
BERT base, the Wave Network reduces video memory usage and training time by
77.34\% and 85.62\% during wave modulation. In summary, we used a
2.4-million-parameter small language model to achieve accuracy comparable to a
100-million-parameter BERT model in text classification.

摘要：<paragraph>我們在一個新的超小型語言模型中提出創新的代幣表示和更新方法：Wave 網路。具體來說，我們使用一個**複數向量**來表示每個代幣，編碼輸入文本的全局和局部語義。一個**複數向量**包含兩個組成部分：一個表示輸入文本的**全局語義**的幅度向量，以及一個捕捉**個別代幣和全局語義之間的關係**的相位向量。在 AG 新聞文本分類任務上的實驗表明，當從隨機初始化的代幣嵌入中生成複數向量時，我們的單層 Wave 網路在波干涉下達到 90.91% 的準確度，在波調製下達到 91.66% 的準確度——分別比使用 BERT 預訓練嵌入的單層 Transformer 層高出 19.23% 和 19.98%，並且接近預訓練和微調的 BERT 基礎模型（94.64%）的準確度。此外，與 BERT 基礎模型相比，Wave 網路在波調製期間將視訊記憶體使用量和訓練時間分別減少了 77.34% 和 85.62%。總之，我們使用了一個 240 萬參數的小型語言模型，在文本分類中達到了與 1 億參數 BERT 模型相當的準確度。</paragraph>

##### **Fair In-Context Learning via Latent Concept Variables**
2411.02671v1 by Karuna Bhaila, Minh-Hao Van, Kennedy Edemacu, Chen Zhao, Feng Chen, Xintao Wu

The emerging in-context learning (ICL) ability of large language models
(LLMs) has prompted their use for predictive tasks in various domains with
different types of data facilitated by serialization methods. However, with
increasing applications in high-stakes domains, it has been shown that LLMs can
inherit social bias and discrimination from their pre-training data. In this
work, we investigate this inherent bias in LLMs during in-context learning with
tabular data. We focus on an optimal demonstration selection approach that
utilizes latent concept variables for resource-efficient task adaptation. We
design data augmentation strategies that reduce correlation between predictive
outcomes and sensitive variables helping to promote fairness during latent
concept learning. We utilize the learned concept and select demonstrations from
a training dataset to obtain fair predictions during inference while
maintaining model utility. The latent concept variable is learned using a
smaller internal LLM and the selected demonstrations can be used for inference
with larger external LLMs. We empirically verify that the fair latent variable
approach improves fairness results on tabular datasets compared to multiple
heuristic demonstration selection methods.

摘要：大型語言模型（LLM）新興的脈絡學習（ICL）能力促使它們在各種領域使用序列化方法促進不同類型資料的預測任務。然而，隨著在高風險領域的應用增加，已顯示 LLM 可以從其預訓練資料繼承社會偏見和歧視。在這項工作中，我們研究了 LLM 在脈絡學習期間使用表格資料的這種內在偏見。我們專注於一種最佳示範選擇方法，該方法利用潛在概念變數進行資源有效率的任務適應。我們設計了資料擴充策略，以減少預測結果與敏感變數之間的關聯性，有助於在潛在概念學習期間促進公平性。我們利用學習到的概念並從訓練資料集中選擇示範，以在推論期間獲得公平的預測，同時保持模型效用。潛在概念變數是使用較小的內部 LLM 學習的，並且所選的示範可以用於推論，並使用較大的外部 LLM。我們憑經驗驗證，與多種啟發式示範選擇方法相比，公平的潛在變數方法改善了表格資料集上的公平性結果。

##### **From Twitter to Reasoner: Understand Mobility Travel Modes and Sentiment Using Large Language Models**
2411.02666v1 by Kangrui Ruan, Xinyang Wang, Xuan Di

Social media has become an important platform for people to express their
opinions towards transportation services and infrastructure, which holds the
potential for researchers to gain a deeper understanding of individuals' travel
choices, for transportation operators to improve service quality, and for
policymakers to regulate mobility services. A significant challenge, however,
lies in the unstructured nature of social media data. In other words, textual
data like social media is not labeled, and large-scale manual annotations are
cost-prohibitive. In this study, we introduce a novel methodological framework
utilizing Large Language Models (LLMs) to infer the mentioned travel modes from
social media posts, and reason people's attitudes toward the associated travel
mode, without the need for manual annotation. We compare different LLMs along
with various prompting engineering methods in light of human assessment and LLM
verification. We find that most social media posts manifest negative rather
than positive sentiments. We thus identify the contributing factors to these
negative posts and, accordingly, propose recommendations to traffic operators
and policymakers.

摘要：社群媒體已成為人們表達其對運輸服務和基礎建設意見的重要平台，這讓研究人員得以更深入地了解個人的旅遊選擇，讓運輸業者提升服務品質，並讓政策制定者規範行動服務。然而，社群媒體資料的非結構化性質是一項重大挑戰。換句話說，社群媒體等文字資料並未標記，而大規模的手動註解成本過高。在本研究中，我們介紹一個利用大型語言模型 (LLM) 從社群媒體貼文中推論所提及的旅遊模式，並推論人們對相關旅遊模式的態度，而無需手動註解的新方法論架構。我們根據人類評估和 LLM 驗證，比較了不同的 LLM 以及各種提示工程方法。我們發現，大多數社群媒體貼文表達的負面情緒多於正面情緒。因此，我們找出導致這些負面貼文的原因，並據此提出建議給交通業者和政策制定者。

##### **Explanations that reveal all through the definition of encoding**
2411.02664v1 by Aahlad Puli, Nhi Nguyen, Rajesh Ranganath

Feature attributions attempt to highlight what inputs drive predictive power.
Good attributions or explanations are thus those that produce inputs that
retain this predictive power; accordingly, evaluations of explanations score
their quality of prediction. However, evaluations produce scores better than
what appears possible from the values in the explanation for a class of
explanations, called encoding explanations. Probing for encoding remains a
challenge because there is no general characterization of what gives the extra
predictive power. We develop a definition of encoding that identifies this
extra predictive power via conditional dependence and show that the definition
fits existing examples of encoding. This definition implies, in contrast to
encoding explanations, that non-encoding explanations contain all the
informative inputs used to produce the explanation, giving them a "what you see
is what you get" property, which makes them transparent and simple to use.
Next, we prove that existing scores (ROAR, FRESH, EVAL-X) do not rank
non-encoding explanations above encoding ones, and develop STRIPE-X which ranks
them correctly. After empirically demonstrating the theoretical insights, we
use STRIPE-X to uncover encoding in LLM-generated explanations for predicting
the sentiment in movie reviews.

摘要：特徵歸因試圖強調哪些輸入驅動預測能力。
因此，好的歸因或解釋會產生保留此預測能力的輸入；相應地，解釋的評估會評分其預測品質。然而，評估會產生比解釋中數值可能產生的結果更好的分數，這類解釋稱為編碼解釋。探查編碼仍然是一項挑戰，因為沒有關於什麼賦予額外預測能力的一般特徵描述。我們制定了一個編碼定義，透過條件依賴性來識別此額外預測能力，並顯示此定義符合現有的編碼範例。此定義暗示，與編碼解釋相反，非編碼解釋包含用於產生解釋的所有資訊輸入，賦予它們「所見即所得」的屬性，這讓它們透明且易於使用。接下來，我們證明現有分數（ROAR、FRESH、EVAL-X）不會將非編碼解釋排名在編碼解釋之上，並開發出 STRIPE-X，它可以正確地對它們進行排名。在實證證明理論見解後，我們使用 STRIPE-X 來揭示 LLM 生成的解釋中用於預測電影評論情緒的編碼。

##### **Zebra-Llama: A Context-Aware Large Language Model for Democratizing Rare Disease Knowledge**
2411.02657v1 by Karthik Soman, Andrew Langdon, Catalina Villouta, Chinmay Agrawal, Lashaw Salta, Braian Peetoom, Gianmarco Bellucci, Orion J Buske

Rare diseases present unique challenges in healthcare, often suffering from
delayed diagnosis and fragmented information landscapes. The scarcity of
reliable knowledge in these conditions poses a distinct challenge for Large
Language Models (LLMs) in supporting clinical management and delivering precise
patient information underscoring the need for focused training on these 'zebra'
cases. We present Zebra-Llama, a specialized context-aware language model with
high precision Retrieval Augmented Generation (RAG) capability, focusing on
Ehlers-Danlos Syndrome (EDS) as our case study. EDS, affecting 1 in 5,000
individuals, exemplifies the complexities of rare diseases with its diverse
symptoms, multiple subtypes, and evolving diagnostic criteria. By implementing
a novel context-aware fine-tuning methodology trained on questions derived from
medical literature, patient experiences, and clinical resources, along with
expertly curated responses, Zebra-Llama demonstrates unprecedented capabilities
in handling EDS-related queries. On a test set of real-world questions
collected from EDS patients and clinicians, medical experts evaluated the
responses generated by both models, revealing Zebra-Llama's substantial
improvements over base model (Llama 3.1-8B-Instruct) in thoroughness (77.5% vs.
70.1%), accuracy (83.0% vs. 78.8%), clarity (74.7% vs. 72.0%) and citation
reliability (70.6% vs. 52.3%). Released as an open-source resource, Zebra-Llama
not only provides more accessible and reliable EDS information but also
establishes a framework for developing specialized AI solutions for other rare
conditions. This work represents a crucial step towards democratizing
expert-level knowledge in rare disease management, potentially transforming how
healthcare providers and patients navigate the complex landscape of rare
diseases.

摘要：<paragraph>罕見疾病對醫療保健提出了獨特的挑戰，通常會延誤診斷並造成資訊分散的問題。這些疾病缺乏可靠的知識，對大型語言模型 (LLM) 在支持臨床管理和提供精確的患者資訊方面構成了獨特的挑戰，這凸顯了針對這些「斑馬」病例進行重點訓練的必要性。我們提出 Zebra-Llama，這是一個專門的脈絡感知語言模型，具有高精確度的檢索擴充生成 (RAG) 能力，並以 Ehlers-Danlos 症候群 (EDS) 作為我們的案例研究。EDS 影響每 5,000 人中的 1 人，其症狀多樣、亞型眾多且診斷標準不斷演變，體現了罕見疾病的複雜性。透過實施一種新穎的脈絡感知微調方法，該方法在從醫學文獻、患者經驗和臨床資源中衍生的問題上進行訓練，並結合專家策劃的回應，Zebra-Llama 在處理與 EDS 相關的查詢方面展現了前所未有的能力。在從 EDS 患者和臨床醫生收集的真實問題測試集中，醫學專家評估了這兩種模型產生的回應，結果顯示 Zebra-Llama 在徹底性 (77.5% 對 70.1%)、準確性 (83.0% 對 78.8%)、清晰度 (74.7% 對 72.0%) 和引用可靠性 (70.6% 對 52.3%) 方面都比基礎模型 (Llama 3.1-8B-Instruct) 有顯著的進步。Zebra-Llama 以開放原始碼資源的形式釋出，不僅提供了更易於取得且可靠的 EDS 資訊，還建立了一個開發其他罕見疾病專用 AI 解決方案的架構。這項工作代表了在罕見疾病管理中實現專家級知識民主化的關鍵一步，有可能改變醫療保健提供者和患者在罕見疾病複雜領域中的應對方式。</paragraph>

##### **M-CELS: Counterfactual Explanation for Multivariate Time Series Data Guided by Learned Saliency Maps**
2411.02649v1 by Peiyu Li, Omar Bahri, Soukaina Filali Boubrahimi, Shah Muhammad Hamdi

Over the past decade, multivariate time series classification has received
great attention. Machine learning (ML) models for multivariate time series
classification have made significant strides and achieved impressive success in
a wide range of applications and tasks. The challenge of many state-of-the-art
ML models is a lack of transparency and interpretability. In this work, we
introduce M-CELS, a counterfactual explanation model designed to enhance
interpretability in multidimensional time series classification tasks. Our
experimental validation involves comparing M-CELS with leading state-of-the-art
baselines, utilizing seven real-world time-series datasets from the UEA
repository. The results demonstrate the superior performance of M-CELS in terms
of validity, proximity, and sparsity, reinforcing its effectiveness in
providing transparent insights into the decisions of machine learning models
applied to multivariate time series data.

摘要：在過去的十年中，多元時間序列分類受到了廣泛關注。用於多元時間序列分類的機器學習 (ML) 模型已取得重大進展，並在廣泛的應用和任務中取得了令人印象深刻的成功。許多最先進的 ML 模型的挑戰在於缺乏透明度和可解釋性。在這項工作中，我們引入了 M-CELS，這是一個反事實解釋模型，旨在增強多維時間序列分類任務的可解釋性。我們的實驗驗證涉及將 M-CELS 與領先的最先進基準進行比較，利用 UEA 儲存庫中的七個真實世界時間序列資料集。結果證明了 M-CELS 在有效性、接近度和稀疏性方面的優異性能，加強了其在提供對應用於多元時間序列資料的機器學習模型決策的透明見解方面的有效性。

##### **A Comparative Analysis of Counterfactual Explanation Methods for Text Classifiers**
2411.02643v1 by Stephen McAleese, Mark Keane

Counterfactual explanations can be used to interpret and debug text
classifiers by producing minimally altered text inputs that change a
classifier's output. In this work, we evaluate five methods for generating
counterfactual explanations for a BERT text classifier on two datasets using
three evaluation metrics. The results of our experiments suggest that
established white-box substitution-based methods are effective at generating
valid counterfactuals that change the classifier's output. In contrast, newer
methods based on large language models (LLMs) excel at producing natural and
linguistically plausible text counterfactuals but often fail to generate valid
counterfactuals that alter the classifier's output. Based on these results, we
recommend developing new counterfactual explanation methods that combine the
strengths of established gradient-based approaches and newer LLM-based
techniques to generate high-quality, valid, and plausible text counterfactual
explanations.

摘要：反事實解釋可用於透過產生會改變分類器輸出的最小化變更文字輸入，來詮釋和除錯文字分類器。在這項工作中，我們使用三個評估指標，針對兩個資料集上的 BERT 文字分類器，評估產生反事實解釋的五種方法。我們的實驗結果顯示，既定的白盒替換式方法有效產生會改變分類器輸出的有效反事實。相反地，基於大型語言模型 (LLM) 的較新方法擅長產生自然且在語言學上合理的文字反事實，但常常無法產生會改變分類器輸出的有效反事實。基於這些結果，我們建議開發新的反事實解釋方法，結合既定梯度式方法和較新的 LLM 式技術的優點，以產生高品質、有效且合理的文字反事實解釋。

##### **Active Prompt Tuning Enables Gpt-40 To Do Efficient Classification Of Microscopy Images**
2411.02639v1 by Abhiram Kandiyana, Peter R. Mouton, Yaroslav Kolinko, Lawrence O. Hall, Dmitry Goldgof

Traditional deep learning-based methods for classifying cellular features in
microscopy images require time- and labor-intensive processes for training
models. Among the current limitations are major time commitments from domain
experts for accurate ground truth preparation; and the need for a large amount
of input image data. We previously proposed a solution that overcomes these
challenges using OpenAI's GPT-4(V) model on a pilot dataset (Iba-1
immuno-stained tissue sections from 11 mouse brains). Results on the pilot
dataset were equivalent in accuracy and with a substantial improvement in
throughput efficiency compared to the baseline using a traditional
Convolutional Neural Net (CNN)-based approach.
  The present study builds upon this framework using a second unique and
substantially larger dataset of microscopy images. Our current approach uses a
newer and faster model, GPT-4o, along with improved prompts. It was evaluated
on a microscopy image dataset captured at low (10x) magnification from
cresyl-violet-stained sections through the cerebellum of a total of 18 mouse
brains (9 Lurcher mice, 9 wild-type controls). We used our approach to classify
these images either as a control group or Lurcher mutant. Using 6 mice in the
prompt set the results were correct classification for 11 out of the 12 mice
(92%) with 96% higher efficiency, reduced image requirements, and lower demands
on time and effort of domain experts compared to the baseline method (snapshot
ensemble of CNN models). These results confirm that our approach is effective
across multiple datasets from different brain regions and magnifications, with
minimal overhead.

摘要：<paragraph>傳統基於深度學習的方法用於分類顯微影像中的細胞特徵，需要耗時且勞力密集的流程來訓練模型。目前的限制包括：領域專家為準確的基礎真實準備投入大量時間；以及需要大量的輸入影像資料。我們先前提出了一項解決方案，使用 OpenAI 的 GPT-4(V) 模型在試驗資料集（來自 11 個小鼠大腦的 Iba-1 免疫染色的組織切片）上克服這些挑戰。試驗資料集的結果在準確度上相當，並且與使用傳統的基於卷積神經網路 (CNN) 的方法的基準相比，在處理效率上有了顯著的提升。
本研究基於此架構，使用第二個獨特且大得多的顯微影像資料集。我們目前的方法使用更新且更快的模型 GPT-4o，以及改進的提示。它在從總共 18 個小鼠大腦（9 個 Lurcher 小鼠，9 個野生型對照）的小腦的甲基紫染色切片中以低 (10x) 放大倍率拍攝的顯微影像資料集上進行評估。我們使用我們的分類方法將這些影像分類為對照組或 Lurcher 突變體。在提示集中使用 6 隻小鼠，結果對 12 隻小鼠中的 11 隻（92%）進行了正確分類，效率提高了 96%，減少了影像需求，並且與基準方法（CNN 模型的快照集成）相比，對領域專家的時間和精力需求較低。這些結果證實了我們的分類方法在來自不同腦區和放大倍率的多個資料集上是有效的，且開銷很小。</paragraph>

##### **Intelligent Video Recording Optimization using Activity Detection for Surveillance Systems**
2411.02632v1 by Youssef Elmir, Hayet Touati, Ouassila Melizou

Surveillance systems often struggle with managing vast amounts of footage,
much of which is irrelevant, leading to inefficient storage and challenges in
event retrieval. This paper addresses these issues by proposing an optimized
video recording solution focused on activity detection. The proposed approach
utilizes a hybrid method that combines motion detection via frame subtraction
with object detection using YOLOv9. This strategy specifically targets the
recording of scenes involving human or car activity, thereby reducing
unnecessary footage and optimizing storage usage. The developed model
demonstrates superior performance, achieving precision metrics of 0.855 for car
detection and 0.884 for person detection, and reducing the storage requirements
by two-thirds compared to traditional surveillance systems that rely solely on
motion detection. This significant reduction in storage highlights the
effectiveness of the proposed approach in enhancing surveillance system
efficiency. Nonetheless, some limitations persist, particularly the occurrence
of false positives and false negatives in adverse weather conditions, such as
strong winds.

摘要：監視系統經常難以管理大量的影片素材，其中許多素材無關緊要，導致儲存效率低下且事件檢索困難。本文提出一個最佳化的影片錄製解決方案，專注於活動偵測，以解決這些問題。所提出的方法採用混合方法，結合透過影像減法的動作偵測與使用 YOLOv9 的物件偵測。此策略特別針對包含人類或汽車活動的場景進行錄製，從而減少不必要的影片素材並最佳化儲存空間使用率。所開發的模型展現出優異的效能，在汽車偵測方面達到 0.855 的精準度指標，在人員偵測方面達到 0.884，且與僅依賴動作偵測的傳統監視系統相比，儲存空間需求減少了三分之二。儲存空間的顯著減少突顯了所提出的方法在提升監視系統效率方面的效用。儘管如此，仍有一些限制，特別是在強風等惡劣天氣條件下會出現誤判和漏判。

##### **Extracting Unlearned Information from LLMs with Activation Steering**
2411.02631v1 by Atakan Seyitoğlu, Aleksei Kuvshinov, Leo Schwinn, Stephan Günnemann

An unintended consequence of the vast pretraining of Large Language Models
(LLMs) is the verbatim memorization of fragments of their training data, which
may contain sensitive or copyrighted information. In recent years, unlearning
has emerged as a solution to effectively remove sensitive knowledge from models
after training. Yet, recent work has shown that supposedly deleted information
can still be extracted by malicious actors through various attacks. Still,
current attacks retrieve sets of possible candidate generations and are unable
to pinpoint the output that contains the actual target information. We propose
activation steering as a method for exact information retrieval from unlearned
LLMs. We introduce a novel approach to generating steering vectors, named
Anonymized Activation Steering. Additionally, we develop a simple word
frequency method to pinpoint the correct answer among a set of candidates when
retrieving unlearned information. Our evaluation across multiple unlearning
techniques and datasets demonstrates that activation steering successfully
recovers general knowledge (e.g., widely known fictional characters) while
revealing limitations in retrieving specific information (e.g., details about
non-public individuals). Overall, our results demonstrate that exact
information retrieval from unlearned models is possible, highlighting a severe
vulnerability of current unlearning techniques.

摘要：大型語言模型 (LLM) 大規模預訓練的意外後果是逐字記憶訓練資料的片段，其中可能包含敏感或受版權保護的資訊。近年來，遺忘已成為在訓練後有效從模型中移除敏感知識的解決方案。然而，最近的研究表明，惡意行為者仍可透過各種攻擊提取據稱已刪除的資訊。儘管如此，目前的攻擊會擷取可能的候選產生集合，而且無法精確指出包含實際目標資訊的輸出。我們提出啟動導引作為從未學習的 LLM 中精確擷取資訊的方法。我們引入一種產生導引向量的創新方法，稱為匿名化啟動導引。此外，我們開發一種簡單的詞頻方法，以便在擷取未學習的資訊時從候選集合中精確指出正確答案。我們在多種遺忘技術和資料集上的評估顯示，啟動導引成功恢復一般知識（例如，廣為人知的虛構角色），同時揭示在擷取特定資訊（例如，非公眾人物的詳細資訊）方面的限制。總體而言，我們的結果表明從未學習的模型中精確擷取資訊是可行的，突顯了當前遺忘技術的嚴重漏洞。

##### **EmoSphere++: Emotion-Controllable Zero-Shot Text-to-Speech via Emotion-Adaptive Spherical Vector**
2411.02625v1 by Deok-Hyeon Cho, Hyung-Seok Oh, Seung-Bin Kim, Seong-Whan Lee

Emotional text-to-speech (TTS) technology has achieved significant progress
in recent years; however, challenges remain owing to the inherent complexity of
emotions and limitations of the available emotional speech datasets and models.
Previous studies typically relied on limited emotional speech datasets or
required extensive manual annotations, restricting their ability to generalize
across different speakers and emotional styles. In this paper, we present
EmoSphere++, an emotion-controllable zero-shot TTS model that can control
emotional style and intensity to resemble natural human speech. We introduce a
novel emotion-adaptive spherical vector that models emotional style and
intensity without human annotation. Moreover, we propose a multi-level style
encoder that can ensure effective generalization for both seen and unseen
speakers. We also introduce additional loss functions to enhance the emotion
transfer performance for zero-shot scenarios. We employ a conditional flow
matching-based decoder to achieve high-quality and expressive emotional TTS in
a few sampling steps. Experimental results demonstrate the effectiveness of the
proposed framework.

摘要：情感文字轉語音 (TTS) 技術在近年來取得顯著進展；然而，由於情感的複雜性和現有情感語音資料集和模型的限制，仍存在挑戰。先前的研究通常依賴於有限的情感語音資料集，或需要廣泛的手動註解，限制它們在不同說話者和情感風格中的概括能力。在本文中，我們提出了 EmoSphere++，一個可控情感的零次學習 TTS 模型，它可以控制情感風格和強度，以模擬自然的人類語音。我們引入了一個新穎的情感自適應球形向量，它在沒有人工註解的情況下對情感風格和強度進行建模。此外，我們提出了一個多級風格編碼器，它可以確保對已見和未見說話者的有效概括。我們還引入了額外的損失函數，以增強零次學習場景中的情感轉移性能。我們採用了一個基於條件流匹配的解碼器，以在幾個採樣步驟中實現高品質和富有表現力的情感 TTS。實驗結果證明了所提出框架的有效性。

##### **Pseudo-Probability Unlearning: Towards Efficient and Privacy-Preserving Machine Unlearning**
2411.02622v1 by Zihao Zhao, Yijiang Li, Yuchen Yang, Wenqing Zhang, Nuno Vasconcelos, Yinzhi Cao

Machine unlearning--enabling a trained model to forget specific data--is
crucial for addressing biased data and adhering to privacy regulations like the
General Data Protection Regulation (GDPR)'s "right to be forgotten". Recent
works have paid little attention to privacy concerns, leaving the data intended
for forgetting vulnerable to membership inference attacks. Moreover, they often
come with high computational overhead. In this work, we propose
Pseudo-Probability Unlearning (PPU), a novel method that enables models to
forget data efficiently and in a privacy-preserving manner. Our method replaces
the final-layer output probabilities of the neural network with
pseudo-probabilities for the data to be forgotten. These pseudo-probabilities
follow either a uniform distribution or align with the model's overall
distribution, enhancing privacy and reducing risk of membership inference
attacks. Our optimization strategy further refines the predictive probability
distributions and updates the model's weights accordingly, ensuring effective
forgetting with minimal impact on the model's overall performance. Through
comprehensive experiments on multiple benchmarks, our method achieves over 20%
improvements in forgetting error compared to the state-of-the-art.
Additionally, our method enhances privacy by preventing the forgotten set from
being inferred to around random guesses.

摘要：機器遺忘——讓訓練好的模型忘記特定資料——對於解決有偏差的資料和遵守隱私法規（例如一般資料保護法規 (GDPR) 的「被遺忘權」）至關重要。最近的研究鮮少關注隱私問題，導致預計要遺忘的資料容易受到成員推論攻擊。此外，它們通常伴隨著高運算負擔。在這項研究中，我們提出偽機率遺忘 (PPU)，一種創新的方法，讓模型能夠有效且以保護隱私的方式遺忘資料。我們的做法是將神經網路的最終層輸出機率替換為要遺忘資料的偽機率。這些偽機率遵循均勻分佈或與模型的整體分佈一致，增強隱私並降低成員推論攻擊的風險。我們的最佳化策略進一步改善預測機率分佈，並相應地更新模型的權重，確保有效遺忘，同時將對模型整體效能的影響降至最低。透過在多個基準上進行全面實驗，我們的做法在遺忘錯誤方面比最先進技術進步了 20% 以上。此外，我們的做法透過防止推論出遺忘的集合而增強隱私，推論結果接近隨機猜測。

##### **TeleOracle: Fine-Tuned Retrieval-Augmented Generation with Long-Context Support for Network**
2411.02617v1 by Nouf Alabbasi, Omar Erak, Omar Alhussein, Ismail Lotfi, Sami Muhaidat, Merouane Debbah

The telecommunications industry's rapid evolution demands intelligent systems
capable of managing complex networks and adapting to emerging technologies.
While large language models (LLMs) show promise in addressing these challenges,
their deployment in telecom environments faces significant constraints due to
edge device limitations and inconsistent documentation. To bridge this gap, we
present TeleOracle, a telecom-specialized retrieval-augmented generation (RAG)
system built on the Phi-2 small language model (SLM). To improve context
retrieval, TeleOracle employs a two-stage retriever that incorporates semantic
chunking and hybrid keyword and semantic search. Additionally, we expand the
context window during inference to enhance the model's performance on
open-ended queries. We also employ low-rank adaption for efficient fine-tuning.
A thorough analysis of the model's performance indicates that our RAG framework
is effective in aligning Phi-2 to the telecom domain in a downstream question
and answer (QnA) task, achieving a 30% improvement in accuracy over the base
Phi-2 model, reaching an overall accuracy of 81.20%. Notably, we show that our
model not only performs on par with the much larger LLMs but also achieves a
higher faithfulness score, indicating higher adherence to the retrieved
context.

摘要：电信产业的快速演进需要能够管理复杂网络并适应新兴技术的智能系统。虽然大型语言模型 (LLM) 在应对这些挑战方面显示出前景，但由于边缘设备的限制和文档的不一致，它们在电信环境中的部署面临着重大的制约。为了弥合这一差距，我们提出了 TeleOracle，这是一个基于 Phi-2 小型语言模型 (SLM) 的电信专业化检索增强生成 (RAG) 系统。为了改进上下文检索，TeleOracle 采用了一个两阶段的检索器，该检索器结合了语义块和混合关键词和语义搜索。此外，我们在推理期间扩展了上下文窗口，以增强模型对开放式查询的性能。我们还采用低秩自适应进行高效的微调。对模型性能的彻底分析表明，我们的 RAG 框架在将 Phi-2 与电信领域对齐方面是有效的在问答 (QnA) 任务的下游中，准确率比基础 Phi-2 模型提高了 30%，总体准确率达到 81.20%。值得注意的是，我们表明我们的模型不仅与更大的 LLM 性能相当，而且还实现了更高的保真度分数，表明对检索到的上下文有更高的遵循度。

##### **Advanced XR-Based 6-DOF Catheter Tracking System for Immersive Cardiac Intervention Training**
2411.02611v1 by Mohsen Annabestani, Sandhya Sriram, S. Chiu Wong, Alexandros Sigaras, Bobak Mosadegh

Extended Reality (XR) technologies are gaining traction as effective tools
for medical training and procedural guidance, particularly in complex cardiac
interventions. This paper presents a novel system for real-time 3D tracking and
visualization of intracardiac echocardiography (ICE) catheters, with precise
measurement of the roll angle. A custom 3D-printed setup, featuring orthogonal
cameras, captures biplane video of the catheter, while a specialized computer
vision algorithm reconstructs its 3D trajectory, localizing the tip with
sub-millimeter accuracy and tracking the roll angle in real-time. The system's
data is integrated into an interactive Unity-based environment, rendered
through the Meta Quest 3 XR headset, combining a dynamically tracked catheter
with a patient-specific 3D heart model. This immersive environment allows the
testing of the importance of 3D depth perception, in comparison to 2D
projections, as a form of visualization in XR. Our experimental study,
conducted using the ICE catheter with six participants, suggests that 3D
visualization is not necessarily beneficial over 2D views offered by the XR
system; although all cardiologists saw its utility for pre-operative training,
planning, and intra-operative guidance. The proposed system qualitatively shows
great promise in transforming catheter-based interventions, particularly ICE
procedures, by improving visualization, interactivity, and skill development.

摘要：擴增實境 (XR) 技術正作為醫療訓練和程序指導的有效工具而獲得重視，特別是在複雜的心臟介入治療中。本文提出了一個新的系統，用於實時 3D 追蹤和可視化心內超聲心動圖 (ICE) 導管，並精確測量滾動角度。一個客製化的 3D 列印設定，配備正交相機，捕捉導管的雙平面影片，而一個專門的電腦視覺演算法重建其 3D 軌跡，以小於毫米的精確度定位尖端並即時追蹤滾動角度。系統的資料整合到一個互動式的 Unity 為基礎的環境中，透過 Meta Quest 3 XR 頭戴式裝置呈現，結合動態追蹤的導管和特定病患的 3D 心臟模型。這個沈浸式的環境允許測試 3D 深度感知的重要性，與 2D 投影相比，作為 XR 中的一種視覺化形式。我們的實驗研究，使用 ICE 導管進行，有六位參與者，顯示 3D 視覺化不一定比 XR 系統提供的 2D 視圖有益；儘管所有心臟科醫師都看到它在術前訓練、規劃和術中指導中的用途。所提出的系統在質化上顯示出在轉換導管介入治療，特別是 ICE 程序方面，透過改善視覺化、互動性和技能發展，具有很大的前景。

##### **Investigating Idiomaticity in Word Representations**
2411.02610v1 by Wei He, Tiago Kramer Vieira, Marcos Garcia, Carolina Scarton, Marco Idiart, Aline Villavicencio

Idiomatic expressions are an integral part of human languages, often used to
express complex ideas in compressed or conventional ways (e.g. eager beaver as
a keen and enthusiastic person). However, their interpretations may not be
straightforwardly linked to the meanings of their individual components in
isolation and this may have an impact for compositional approaches. In this
paper, we investigate to what extent word representation models are able to go
beyond compositional word combinations and capture multiword expression
idiomaticity and some of the expected properties related to idiomatic meanings.
We focus on noun compounds of varying levels of idiomaticity in two languages
(English and Portuguese), presenting a dataset of minimal pairs containing
human idiomaticity judgments for each noun compound at both type and token
levels, their paraphrases and their occurrences in naturalistic and
sense-neutral contexts, totalling 32,200 sentences. We propose this set of
minimal pairs for evaluating how well a model captures idiomatic meanings, and
define a set of fine-grained metrics of Affinity and Scaled Similarity, to
determine how sensitive the models are to perturbations that may lead to
changes in idiomaticity. The results obtained with a variety of representative
and widely used models indicate that, despite superficial indications to the
contrary in the form of high similarities, idiomaticity is not yet accurately
represented in current models. Moreover, the performance of models with
different levels of contextualisation suggests that their ability to capture
context is not yet able to go beyond more superficial lexical clues provided by
the words and to actually incorporate the relevant semantic clues needed for
idiomaticity.

摘要：慣用語是人類語言中不可或缺的一部分，通常用於以簡潔或傳統的方式表達複雜的想法（例如，熱心的海狸作為一個熱切且熱情的人）。然而，它們的解釋可能無法直接連結到它們各個組成部分在孤立狀態下的意義，這可能會對組合方法產生影響。在本文中，我們探討詞彙表徵模型在多大程度上能夠超越組合詞彙組合，並捕捉多詞表達的慣用語法和與慣用語法意義相關的一些預期屬性。我們專注於兩種語言（英語和葡萄牙語）中不同慣用語法程度的名詞複合詞，提供了一組最小對，其中包含對每個名詞複合詞在類型和標記層級的人類慣用語法判斷、它們的同義詞改寫，以及它們在自然且意義中立的語境中出現的次數，總計 32,200 個句子。我們提出這組最小對來評估模型捕捉慣用語法意義的程度，並定義一組親和力和縮放相似度的細緻指標，以確定模型對可能導致慣用語法改變的擾動有多敏感。使用各種具代表性和廣泛使用的模型所獲得的結果表明，儘管有表面上相反的高相似度跡象，但慣用語法尚未在當前模型中準確呈現。此外，具有不同語境化的模型的效能表明，它們捕捉語境的能耐尚未能夠超越詞彙提供的較為表面的線索，也無法實際納入慣用語法所需的相關語義線索。

##### **Computing critical exponents in 3D Ising model via pattern recognition/deep learning approach**
2411.02604v1 by Timothy A. Burt

In this study, we computed three critical exponents ($\alpha, \beta, \gamma$)
for the 3D Ising model with Metropolis Algorithm using Finite-Size Scaling
Analysis on six cube length scales (L=20,30,40,60,80,90), and performed a
supervised Deep Learning (DL) approach (3D Convolutional Neural Network or CNN)
to train a neural network on specific conformations of spin states. We find one
can effectively reduce the information in thermodynamic ensemble-averaged
quantities vs. reduced temperature t (magnetization per spin $<m>(t)$, specific
heat per spin $<c>(t)$, magnetic susceptibility per spin $<\chi>(t)$) to
\textit{six} latent classes. We also demonstrate our CNN on a subset of L=20
conformations and achieve a train/test accuracy of 0.92 and 0.6875,
respectively. However, more work remains to be done to quantify the feasibility
of computing critical exponents from the output class labels (binned $m, c,
\chi$) from this approach and interpreting the results from DL models trained
on systems in Condensed Matter Physics in general.

摘要：在本研究中，我们计算了 Metropolis 算法的 3D Ising 模型的三个临界指数 ($\alpha, \beta, \gamma$)，使用有限尺寸标度分析在六个立方体长度尺度 (L=20,30,40,60,80,90) 上，并执行了监督深度学习 (DL) 方法（3D 卷积神经网络或 CNN）以在自旋态的特定构象上训练神经网络。我们发现可以有效地减少热力学系综平均量中的信息 vs. 降低温度 t（每个自旋的磁化强度 $<m>(t)$，每个自旋的比热容 $<c>(t)$，每个自旋的磁化率 $<\chi>(t)$）到\textit{六}个潜在类别。我们还在 L=20 构象的子集上展示了我们的 CNN，并分别获得了 0.92 和 0.6875 的训练/测试准确率。然而，仍有更多工作需要完成，以量化从该方法的输出类别标签（分箱的 $m, c, \chi$）计算临界指数的可行性，并解释在凝聚态物理学系统上训练的 DL 模型的结果。

##### **FactTest: Factuality Testing in Large Language Models with Statistical Guarantees**
2411.02603v1 by Fan Nie, Xiaotian Hou, Shuhang Lin, James Zou, Huaxiu Yao, Linjun Zhang

The propensity of Large Language Models (LLMs) to generate hallucinations and
non-factual content undermines their reliability in high-stakes domains, where
rigorous control over Type I errors (the conditional probability of incorrectly
classifying hallucinations as truthful content) is essential. Despite its
importance, formal verification of LLM factuality with such guarantees remains
largely unexplored. In this paper, we introduce FactTest, a novel framework
that statistically assesses whether an LLM can confidently provide correct
answers to given questions with high-probability correctness guarantees. We
formulate factuality testing as hypothesis testing problem to enforce an upper
bound of Type I errors at user-specified significance levels. Notably, we prove
that our framework also ensures strong Type II error control under mild
conditions and can be extended to maintain its effectiveness when covariate
shifts exist. %These analyses are amenable to the principled NP framework. Our
approach is distribution-free and works for any number of human-annotated
samples. It is model-agnostic and applies to any black-box or white-box LM.
Extensive experiments on question-answering (QA) and multiple-choice benchmarks
demonstrate that \approach effectively detects hallucinations and improves the
model's ability to abstain from answering unknown questions, leading to an over
40% accuracy improvement.

摘要：大型語言模型 (LLM) 產生幻覺和非事實內容的傾向會破壞它們在高風險領域的可靠性，在這些領域中，嚴格控制第一類錯誤（將幻覺錯誤分類為真實內容的條件機率）至關重要。儘管其重要性，對具有此類保證的 LLM 事實性的正式驗證在很大程度上仍未得到探索。在本文中，我們介紹了 FactTest，這是一個新穎的框架，它統計評估 LLM 是否能自信地以高機率正確的保證提供正確答案。我們將事實性測試表述為假設檢定問題，以在使用者指定的顯著性水準強制執行第一類錯誤的上限。值得注意的是，我們證明了我們的框架在溫和條件下也能確保強大的第二類錯誤控制，並且可以擴展為在存在協變數轉移時維持其有效性。%這些分析適用於有原則的 NP 框架。我們的做法是無分配的，適用於任何數量的人工註解範本。它是與模型無關的，適用於任何黑盒或白盒 LM。對問答 (QA) 和多選題基準的廣泛實驗表明，\approach 有效地檢測到幻覺並提高了模型避免回答未知問題的能力，從而導致準確率提高了 40% 以上。

##### **Vocal Sandbox: Continual Learning and Adaptation for Situated Human-Robot Collaboration**
2411.02599v1 by Jennifer Grannen, Siddharth Karamcheti, Suvir Mirchandani, Percy Liang, Dorsa Sadigh

We introduce Vocal Sandbox, a framework for enabling seamless human-robot
collaboration in situated environments. Systems in our framework are
characterized by their ability to adapt and continually learn at multiple
levels of abstraction from diverse teaching modalities such as spoken dialogue,
object keypoints, and kinesthetic demonstrations. To enable such adaptation, we
design lightweight and interpretable learning algorithms that allow users to
build an understanding and co-adapt to a robot's capabilities in real-time, as
they teach new behaviors. For example, after demonstrating a new low-level
skill for "tracking around" an object, users are provided with trajectory
visualizations of the robot's intended motion when asked to track a new object.
Similarly, users teach high-level planning behaviors through spoken dialogue,
using pretrained language models to synthesize behaviors such as "packing an
object away" as compositions of low-level skills $-$ concepts that can be
reused and built upon. We evaluate Vocal Sandbox in two settings: collaborative
gift bag assembly and LEGO stop-motion animation. In the first setting, we run
systematic ablations and user studies with 8 non-expert participants,
highlighting the impact of multi-level teaching. Across 23 hours of total robot
interaction time, users teach 17 new high-level behaviors with an average of 16
novel low-level skills, requiring 22.1% less active supervision compared to
baselines and yielding more complex autonomous performance (+19.7%) with fewer
failures (-67.1%). Qualitatively, users strongly prefer Vocal Sandbox systems
due to their ease of use (+20.6%) and overall performance (+13.9%). Finally, we
pair an experienced system-user with a robot to film a stop-motion animation;
over two hours of continuous collaboration, the user teaches progressively more
complex motion skills to shoot a 52 second (232 frame) movie.

摘要：<paragraph>我們介紹 Vocal Sandbox，一個在特定環境中實現無縫人機協作的框架。我們框架中的系統特點在於它們能夠適應並持續從多種教學模式中學習多個抽象層級，例如口語對話、物件關鍵點和動覺示範。為了實現這種適應，我們設計了輕量且可解釋的學習演算法，讓使用者能夠建立理解，並在教授新行為時即時共同適應機器人的能力。例如，在示範了「繞著」物件追蹤的新低階技能後，當要求追蹤新物件時，系統會提供機器人預期動作的軌跡視覺化。同樣地，使用者透過口語對話來教授高階規劃行為，使用預先訓練的語言模型來合成「將物件打包」等行為，作為低階技能的組合，這些概念可以重複使用並加以建構。我們在兩種設定中評估 Vocal Sandbox：協作禮品袋組裝和樂高定格動畫。在第一個設定中，我們針對 8 位非專家參與者執行系統性消融和使用者研究，強調多層級教學的影響。在機器人互動時間總計 23 小時中，使用者教授了 17 種新的高階行為，平均有 16 種新穎的低階技能，與基準相比，所需的主動監督減少了 22.1%，並以較少的失敗（-67.1%）產生更複雜的自主效能（+19.7%）。從質化的角度來看，使用者強烈偏好 Vocal Sandbox 系統，因為它們易於使用（+20.6%）且整體效能較佳（+13.9%）。最後，我們將一位經驗豐富的系統使用者與機器人配對，拍攝定格動畫；在持續合作的兩個小時中，使用者教授越來越複雜的動作技能，拍攝了一部 52 秒（232 幀）的影片。</paragraph>

##### **"It's a conversation, not a quiz": A Risk Taxonomy and Reflection Tool for LLM Adoption in Public Health**
2411.02594v1 by Jiawei Zhou, Amy Z. Chen, Darshi Shah, Laura Schwab Reese, Munmun De Choudhury

Recent breakthroughs in large language models (LLMs) have generated both
interest and concern about their potential adoption as accessible information
sources or communication tools across different domains. In public health --
where stakes are high and impacts extend across populations -- adopting LLMs
poses unique challenges that require thorough evaluation. However, structured
approaches for assessing potential risks in public health remain
under-explored. To address this gap, we conducted focus groups with health
professionals and health issue experiencers to unpack their concerns, situated
across three distinct and critical public health issues that demand
high-quality information: vaccines, opioid use disorder, and intimate partner
violence. We synthesize participants' perspectives into a risk taxonomy,
distinguishing and contextualizing the potential harms LLMs may introduce when
positioned alongside traditional health communication. This taxonomy highlights
four dimensions of risk in individual behaviors, human-centered care,
information ecosystem, and technology accountability. For each dimension, we
discuss specific risks and example reflection questions to help practitioners
adopt a risk-reflexive approach. This work offers a shared vocabulary and
reflection tool for experts in both computing and public health to
collaboratively anticipate, evaluate, and mitigate risks in deciding when to
employ LLM capabilities (or not) and how to mitigate harm when they are used.

摘要：大型語言模型 (LLM) 的最新突破引起了人們的興趣，也引起了人們對其作為不同領域的無障礙信息來源或通信工具的潛在採用所產生的擔憂。在公共衛生領域——利害關係很高且影響遍及人群——採用 LLM 構成了獨特的挑戰，需要徹底評估。然而，評估公共衛生中潛在風險的結構化方法仍未得到充分探索。為了解決這一差距，我們與醫療專業人員和健康問題體驗者進行了焦點小組，以解開他們的疑慮，這些疑慮涉及三個不同的關鍵公共衛生問題，這些問題需要高質量的資訊：疫苗、阿片類藥物使用障礙和親密伴侶暴力。我們將參與者的觀點綜合到風險分類法中，區分和情境化 LLM 在與傳統健康傳播並列時可能造成的潛在危害。這種分類法突出了個人行為、以人為中心的護理、資訊生態系統和技術問責制這四個維度的風險。對於每個維度，我們討論具體的風險和範例反思問題，以幫助從業者採用風險反思方法。這項工作為計算和公共衛生領域的專家提供了一個共同的詞彙和反思工具，以便在決定何時採用 LLM 功能（或不採用）以及在使用 LLM 功能時如何減輕危害時，共同預測、評估和減輕風險。

##### **Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**
2411.02591v1 by Harshavardhana T. Gowda, Zachary D. McNaughton, Lee M. Miller

Each year, millions of individuals lose the ability to speak intelligibly due
to causes such as neuromuscular disease, stroke, trauma, and head/neck cancer
surgery (e.g. laryngectomy) or treatment (e.g. radiotherapy toxicity to the
speech articulators). Effective communication is crucial for daily activities,
and losing the ability to speak leads to isolation, depression, anxiety, and a
host of detrimental sequelae. Noninvasive surface electromyography (sEMG) has
shown promise to restore speech output in these individuals. The goal is to
collect sEMG signals from multiple articulatory sites as people silently
produce speech and then decode the signals to enable fluent and natural
communication. Currently, many fundamental properties of orofacial
neuromuscular signals relating to speech articulation remain unanswered. They
include questions relating to 1) the data structure of the orofacial sEMG
signals, 2)the signal distribution shift of sEMG across individuals, 3) ability
of sEMG signals to span the entire English language phonetic space during
silent speech articulations, and 4) the generalization capability of
non-invasive sEMG based silent speech interfaces. We address these questions
through a series of experiments involving healthy human subjects. We show that
sEMG signals evince graph data structure and that the signal distribution shift
is given by a change of basis. Furthermore, we show that silently voiced
articulations spanning the entire English language phonetic space can be
decoded using small neural networks which can be trained with little data and
that such architectures work well across individuals. To ensure transparency
and reproducibility, we open-source all the data and codes used in this study.

摘要：每年，數百萬人因為神經肌肉疾病、中風、創傷和頭頸癌手術（例如喉切除術）或治療（例如放射治療對言語發音器官的毒性）等原因而失去清晰說話的能力。有效的溝通對於日常生活至關重要，而失去說話能力會導致孤立、沮喪、焦慮和一系列有害的後遺症。非侵入性表面肌電圖 (sEMG) 已顯示出恢復這些人說話輸出的希望。目標是從多個發音部位收集 sEMG 信號，因為人們在無聲地發出言語，然後解碼信號以實現流利和自然的溝通。目前，許多與言語發音有關的顏面神經肌肉信號的基本特性仍然沒有得到解答。它們包括與 1) 顏面 sEMG 信號的數據結構、2) sEMG 在個體間的信號分佈轉移、3) sEMG 信號在無聲言語發音過程中跨越整個英語語言音標空間的能力以及 4) 基於非侵入性 sEMG 的無聲言語介面的概括能力相關的問題。我們通過一系列涉及健康人類受試者的實驗來解決這些問題。我們表明 sEMG 信號證明圖數據結構，並且信號分佈轉移是由基變化的給出。此外，我們表明使用可以通過少量數據訓練的小神經網路可以解碼跨越整個英語語言音標空間的無聲發音，並且此類架構在不同個體之間運行良好。為了確保透明度和可重現性，我們公開了本研究中使用的所有數據和代碼。

##### **Context-Informed Machine Translation of Manga using Multimodal Large Language Models**
2411.02589v1 by Philip Lippmann, Konrad Skublicki, Joshua Tanner, Shonosuke Ishiwatari, Jie Yang

Due to the significant time and effort required for handcrafting
translations, most manga never leave the domestic Japanese market. Automatic
manga translation is a promising potential solution. However, it is a budding
and underdeveloped field and presents complexities even greater than those
found in standard translation due to the need to effectively incorporate visual
elements into the translation process to resolve ambiguities. In this work, we
investigate to what extent multimodal large language models (LLMs) can provide
effective manga translation, thereby assisting manga authors and publishers in
reaching wider audiences. Specifically, we propose a methodology that leverages
the vision component of multimodal LLMs to improve translation quality and
evaluate the impact of translation unit size, context length, and propose a
token efficient approach for manga translation. Moreover, we introduce a new
evaluation dataset -- the first parallel Japanese-Polish manga translation
dataset -- as part of a benchmark to be used in future research. Finally, we
contribute an open-source software suite, enabling others to benchmark LLMs for
manga translation. Our findings demonstrate that our proposed methods achieve
state-of-the-art results for Japanese-English translation and set a new
standard for Japanese-Polish.

摘要：由於手工翻譯需要大量時間和精力，大多數漫畫從未離開日本國內市場。自動漫畫翻譯是一個很有前景的潛在解決方案。然而，它是一個新興且不發達的領域，並且由於需要有效地將視覺元素納入翻譯過程中以解決歧義，因此比標準翻譯中的複雜性更大。在這項工作中，我們探討了多模態大型語言模型 (LLM) 在多大程度上可以提供有效的漫畫翻譯，從而協助漫畫作者和出版商接觸更廣泛的受眾。具體來說，我們提出了一種利用多模態 LLM 的視覺組成部分的方法來提高翻譯品質，並評估翻譯單元大小、上下文長度和提出漫畫翻譯的代幣有效方法的影響。此外，我們引入了一個新的評估資料集——第一個日語-波蘭語漫畫翻譯平行資料集——作為未來研究中使用的基準的一部分。最後，我們貢獻了一個開源軟體套件，讓其他人可以對 LLM 進行漫畫翻譯基準測試。我們的研究結果表明，我們提出的方法達到了日語-英語翻譯的最新結果，並為日語-波蘭語設定了新的標準。

##### **Social Support Detection from Social Media Texts**
2411.02580v1 by Zahra Ahani, Moein Shahiki Tash, Fazlourrahman Balouchzahi, Luis Ramos, Grigori Sidorov, Alexander Gelbukh

Social support, conveyed through a multitude of interactions and platforms
such as social media, plays a pivotal role in fostering a sense of belonging,
aiding resilience in the face of challenges, and enhancing overall well-being.
This paper introduces Social Support Detection (SSD) as a Natural language
processing (NLP) task aimed at identifying supportive interactions within
online communities. The study presents the task of Social Support Detection
(SSD) in three subtasks: two binary classification tasks and one multiclass
task, with labels detailed in the dataset section. We conducted experiments on
a dataset comprising 10,000 YouTube comments. Traditional machine learning
models were employed, utilizing various feature combinations that encompass
linguistic, psycholinguistic, emotional, and sentiment information.
Additionally, we experimented with neural network-based models using various
word embeddings to enhance the performance of our models across these
subtasks.The results reveal a prevalence of group-oriented support in online
dialogues, reflecting broader societal patterns. The findings demonstrate the
effectiveness of integrating psycholinguistic, emotional, and sentiment
features with n-grams in detecting social support and distinguishing whether it
is directed toward an individual or a group. The best results for different
subtasks across all experiments range from 0.72 to 0.82.

摘要：<paragraph>透過社群媒體等多種互動和平台傳達的社會支持，在培養歸屬感、在面對挑戰時協助復原力，以及提升整體幸福感方面扮演著關鍵角色。本文介紹了社交支持偵測 (SSD)，這是一種自然語言處理 (NLP) 任務，旨在識別線上社群中的支持性互動。這項研究將社交支持偵測 (SSD) 的任務分為三個子任務：兩個二元分類任務和一個多類任務，標籤詳述在資料集區段。我們在包含 10,000 則 YouTube 留言的資料集上進行實驗。採用傳統機器學習模型，利用各種特徵組合，包含語言、心理語言、情緒和情緒資訊。此外，我們使用各種詞嵌入對神經網路模型進行實驗，以提升這些子任務中模型的效能。結果顯示線上對話中普遍存在以群體為導向的支持，反映了更廣泛的社會模式。研究結果證明了將心理語言、情緒和情緒特徵與 n-gram 整合起來偵測社交支持，以及區分支持是針對個人或群體的有效性。在所有實驗中，不同子任務的最佳結果介於 0.72 到 0.82 之間。</paragraph>

##### **ViTally Consistent: Scaling Biological Representation Learning for Cell Microscopy**
2411.02572v1 by Kian Kenyon-Dean, Zitong Jerry Wang, John Urbanik, Konstantin Donhauser, Jason Hartford, Saber Saberian, Nil Sahin, Ihab Bendidi, Safiye Celik, Marta Fay, Juan Sebastian Rodriguez Vera, Imran S Haque, Oren Kraus

Large-scale cell microscopy screens are used in drug discovery and molecular
biology research to study the effects of millions of chemical and genetic
perturbations on cells. To use these images in downstream analysis, we need
models that can map each image into a feature space that represents diverse
biological phenotypes consistently, in the sense that perturbations with
similar biological effects have similar representations. In this work, we
present the largest foundation model for cell microscopy data to date, a new
1.9 billion-parameter ViT-G/8 MAE trained on over 8 billion microscopy image
crops. Compared to a previous published ViT-L/8 MAE, our new model achieves a
60% improvement in linear separability of genetic perturbations and obtains the
best overall performance on whole-genome biological relationship recall and
replicate consistency benchmarks. Beyond scaling, we developed two key methods
that improve performance: (1) training on a curated and diverse dataset; and,
(2) using biologically motivated linear probing tasks to search across each
transformer block for the best candidate representation of whole-genome
screens. We find that many self-supervised vision transformers, pretrained on
either natural or microscopy images, yield significantly more biologically
meaningful representations of microscopy images in their intermediate blocks
than in their typically used final blocks. More broadly, our approach and
results provide insights toward a general strategy for successfully building
foundation models for large-scale biological data.

摘要：大規模細胞顯微鏡篩選用於藥物發現和分子生物學研究，用於研究數百萬種化學和遺傳擾動對細胞的影響。為了在後續分析中使用這些影像，我們需要可以將每個影像對應到一個特徵空間的模型，該特徵空間以一致的方式代表不同的生物表型，意思是有類似生物效應的擾動具有相似的表示。在這項工作中，我們提出了迄今為止最大的細胞顯微鏡數據基礎模型，一個新的 19 億參數的 ViT-G/8 MAE，訓練於超過 80 億個顯微鏡影像裁切上。與先前發布的 ViT-L/8 MAE 相比，我們的模型在遺傳擾動的線性可分離性方面提升了 60%，並在全基因組生物關係召回和重複一致性基準上獲得了最佳的整體表現。除了擴展之外，我們還開發了兩種關鍵方法來提升效能：(1) 訓練於一個經過整理且多樣化的資料集；以及 (2) 使用生物動機線性探測任務，在每個Transformer區塊中搜尋全基因組篩選的最佳候選表示。我們發現許多自監督視覺Transformer，無論預訓練於自然影像或顯微鏡影像，在其中間區塊中產生比其通常使用的最終區塊中更有意義的生物學顯微鏡影像表示。更廣泛地說，我們的做法和結果為成功建立大規模生物數據的基礎模型提供了一般策略的見解。

