{"2409.16252": {"publish_time": "2024-09-24", "title": "Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation", "paper_summary": "Crop field boundaries are foundational datasets for agricultural monitoring\nand assessments but are expensive to collect manually. Machine learning (ML)\nmethods for automatically extracting field boundaries from remotely sensed\nimages could help realize the demand for these datasets at a global scale.\nHowever, current ML methods for field instance segmentation lack sufficient\ngeographic coverage, accuracy, and generalization capabilities. Further,\nresearch on improving ML methods is restricted by the lack of labeled datasets\nrepresenting the diversity of global agricultural fields. We present Fields of\nThe World (FTW) -- a novel ML benchmark dataset for agricultural field instance\nsegmentation spanning 24 countries on four continents (Europe, Africa, Asia,\nand South America). FTW is an order of magnitude larger than previous datasets\nwith 70,462 samples, each containing instance and semantic segmentation masks\npaired with multi-date, multi-spectral Sentinel-2 satellite images. We provide\nresults from baseline models for the new FTW benchmark, show that models\ntrained on FTW have better zero-shot and fine-tuning performance in held-out\ncountries than models that aren't pre-trained with diverse datasets, and show\npositive qualitative zero-shot results of FTW models in a real-world scenario\n-- running on Sentinel-2 scenes over Ethiopia.", "paper_summary_zh": "\u4f5c\u7269\u7530\u754c\u7dda\u662f\u8fb2\u696d\u76e3\u6e2c\u548c\u8a55\u4f30\u7684\u57fa\u672c\u8cc7\u6599\u96c6\uff0c\u4f46\u4eba\u5de5\u6536\u96c6\u6210\u672c\u6602\u8cb4\u3002\u6a5f\u5668\u5b78\u7fd2 (ML) \u65b9\u6cd5\u53ef\u81ea\u52d5\u5f9e\u9059\u6e2c\u5f71\u50cf\u4e2d\u8403\u53d6\u7530\u754c\u7dda\uff0c\u6709\u52a9\u65bc\u5728\u5168\u7403\u898f\u6a21\u5be6\u73fe\u9019\u4e9b\u8cc7\u6599\u96c6\u7684\u9700\u6c42\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u7530\u5340\u5be6\u4f8b\u5206\u5272 ML \u65b9\u6cd5\u7f3a\u4e4f\u8db3\u5920\u7684\u5730\u7406\u8986\u84cb\u7bc4\u570d\u3001\u6e96\u78ba\u5ea6\u548c\u6982\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6539\u5584 ML \u65b9\u6cd5\u7684\u7814\u7a76\u53d7\u5230\u6a19\u8a18\u8cc7\u6599\u96c6\u7f3a\u4e4f\u4ee3\u8868\u5168\u7403\u8fb2\u696d\u7530\u5340\u591a\u6a23\u6027\u7684\u9650\u5236\u3002\u6211\u5011\u63d0\u51fa\u4e16\u754c\u7530\u91ce (FTW)\u2014\u2014\u4e00\u7a2e\u65b0\u7684 ML \u57fa\u6e96\u8cc7\u6599\u96c6\uff0c\u7528\u65bc\u6a6b\u8de8\u56db\u5927\u6d32 (\u6b50\u6d32\u3001\u975e\u6d32\u3001\u4e9e\u6d32\u548c\u5357\u7f8e\u6d32) 24 \u500b\u570b\u5bb6\u7684\u8fb2\u696d\u7530\u5340\u5be6\u4f8b\u5206\u5272\u3002FTW \u7684\u898f\u6a21\u6bd4\u5148\u524d\u7684\u8cc7\u6599\u96c6\u5927\u4e00\u500b\u6578\u91cf\u7d1a\uff0c\u6709 70,462 \u500b\u6a23\u672c\uff0c\u6bcf\u500b\u6a23\u672c\u90fd\u5305\u542b\u5be6\u4f8b\u548c\u8a9e\u7fa9\u5206\u5272\u906e\u7f69\uff0c\u4e26\u8207\u591a\u65e5\u671f\u3001\u591a\u5149\u8b5c Sentinel-2 \u885b\u661f\u5f71\u50cf\u914d\u5c0d\u3002\u6211\u5011\u63d0\u4f9b\u4e86\u65b0\u7684 FTW \u57fa\u6e96\u7684\u57fa\u6e96\u6a21\u578b\u7d50\u679c\uff0c\u986f\u793a\u5728 FTW \u4e0a\u8a13\u7df4\u7684\u6a21\u578b\u5728\u672a\u898b\u904e\u8cc7\u6599\u7684\u570b\u5bb6\u4e2d\u64c1\u6709\u6bd4\u672a\u7d93\u591a\u6a23\u5316\u8cc7\u6599\u96c6\u9810\u5148\u8a13\u7df4\u7684\u6a21\u578b\u66f4\u597d\u7684\u96f6\u6b21\u5b78\u7fd2\u548c\u5fae\u8abf\u6548\u80fd\uff0c\u4e26\u5728\u771f\u5be6\u4e16\u754c\u7684\u5834\u666f\u4e2d\u986f\u793a FTW \u6a21\u578b\u7684\u6b63\u9762\u5b9a\u6027\u96f6\u6b21\u5b78\u7fd2\u7d50\u679c\u2014\u2014\u5728\u8863\u7d22\u6bd4\u4e9e\u4e0a\u57f7\u884c Sentinel-2 \u5834\u666f\u3002", "author": "Hannah Kerner et.al.", "authors": "Hannah Kerner, Snehal Chaudhari, Aninda Ghosh, Caleb Robinson, Adeel Ahmad, Eddie Choi, Nathan Jacobs, Chris Holmes, Matthias Mohr, Rahul Dodhia, Juan M. Lavista Ferres, Jennifer Marcus", "id": "2409.16252v1", "paper_url": "http://arxiv.org/abs/2409.16252v1", "repo": "null"}}