
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-09**|**Promptable Closed-loop Traffic Simulation**|Shuhan Tan et.al.|[2409.05863v1](http://arxiv.org/abs/2409.05863v1)|null|
|**2024-09-09**|**MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct**|Run Luo et.al.|[2409.05840v1](http://arxiv.org/abs/2409.05840v1)|null|
|**2024-09-09**|**Improving Pretraining Data Using Perplexity Correlations**|Tristan Thrush et.al.|[2409.05816v1](http://arxiv.org/abs/2409.05816v1)|null|
|**2024-09-09**|**The Future of Software Testing: AI-Powered Test Case Generation and Validation**|Mohammad Baqar et.al.|[2409.05808v1](http://arxiv.org/abs/2409.05808v1)|null|
|**2024-09-09**|**Benchmarking Chinese Knowledge Rectification in Large Language Models**|Tianhe Lu et.al.|[2409.05806v1](http://arxiv.org/abs/2409.05806v1)|[link](https://github.com/zjunlp/easyedit)|
|**2024-09-09**|**Enhancing Preference-based Linear Bandits via Human Response Time**|Shen Li et.al.|[2409.05798v1](http://arxiv.org/abs/2409.05798v1)|null|
|**2024-09-09**|**NeurLZ: On Systematically Enhancing Lossy Compression Performance for Scientific Data based on Neural Learning with Error Control**|Wenqi Jia et.al.|[2409.05785v1](http://arxiv.org/abs/2409.05785v1)|null|
|**2024-09-09**|**Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models**|Emily Cheng et.al.|[2409.05771v1](http://arxiv.org/abs/2409.05771v1)|null|
|**2024-09-09**|**ReL-SAR: Representation Learning for Skeleton Action Recognition with Convolutional Transformers and BYOL**|Safwen Naimi et.al.|[2409.05749v1](http://arxiv.org/abs/2409.05749v1)|null|
|**2024-09-09**|**A Novel Idea Generation Tool using a Structured Conversational AI (CAI) System**|B. Sankar et.al.|[2409.05747v1](http://arxiv.org/abs/2409.05747v1)|null|
|**2024-09-09**|**A System and Benchmark for LLM-based Q\&A on Heterogeneous Data**|Achille Fokoue et.al.|[2409.05735v1](http://arxiv.org/abs/2409.05735v1)|null|
|**2024-09-09**|**Towards Democratizing Multilingual Large Language Models For Medicine Through A Two-Stage Instruction Fine-tuning Approach**|Meng Zhou et.al.|[2409.05732v1](http://arxiv.org/abs/2409.05732v1)|null|
|**2024-09-09**|**Referring Expression Generation in Visually Grounded Dialogue with Discourse-aware Comprehension Guiding**|Bram Willemsen et.al.|[2409.05721v1](http://arxiv.org/abs/2409.05721v1)|null|
|**2024-09-09**|**pFedGPA: Diffusion-based Generative Parameter Aggregation for Personalized Federated Learning**|Jiahao Lai et.al.|[2409.05701v1](http://arxiv.org/abs/2409.05701v1)|null|
|**2024-09-09**|**RegNLP in Action: Facilitating Compliance Through Automated Information Retrieval and Answer Generation**|Tuba Gokhan et.al.|[2409.05677v1](http://arxiv.org/abs/2409.05677v1)|null|
|**2024-09-09**|**Evaluation of real-time transcriptions using end-to-end ASR models**|Carlos Arriaga et.al.|[2409.05674v1](http://arxiv.org/abs/2409.05674v1)|null|
|**2024-09-09**|**Zero-shot Outlier Detection via Prior-data Fitted Networks: Model Selection Bygone!**|Yuchen Shen et.al.|[2409.05672v1](http://arxiv.org/abs/2409.05672v1)|null|
|**2024-09-09**|**Interactive incremental learning of generalizable skills with local trajectory modulation**|Markus Knauer et.al.|[2409.05655v1](http://arxiv.org/abs/2409.05655v1)|null|
|**2024-09-09**|**Revisiting English Winogender Schemas for Consistency, Coverage, and Grammatical Case**|Vagrant Gautam et.al.|[2409.05653v1](http://arxiv.org/abs/2409.05653v1)|[link](https://github.com/uds-lsv/winogender-2.0)|
|**2024-09-09**|**Replay Consolidation with Label Propagation for Continual Object Detection**|Riccardo De Monte et.al.|[2409.05650v1](http://arxiv.org/abs/2409.05650v1)|null|
|**2024-09-09**|**3D-SAR Tomography and Machine Learning for High-Resolution Tree Height Estimation**|Grace Colverd et.al.|[2409.05636v1](http://arxiv.org/abs/2409.05636v1)|null|
|**2024-09-09**|**Adapted-MoE: Mixture of Experts with Test-Time Adaption for Anomaly Detection**|Tianwu Lei et.al.|[2409.05611v1](http://arxiv.org/abs/2409.05611v1)|null|
|**2024-09-09**|**Longer is (Not Necessarily) Stronger: Punctuated Long-Sequence Training for Enhanced Speech Recognition and Translation**|Nithin Rao Koluguri et.al.|[2409.05601v1](http://arxiv.org/abs/2409.05601v1)|null|
|**2024-09-09**|**ExDDI: Explaining Drug-Drug Interaction Predictions with Natural Language**|Zhaoyue Sun et.al.|[2409.05592v1](http://arxiv.org/abs/2409.05592v1)|null|
|**2024-09-09**|**MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery**|Hongjin Qian et.al.|[2409.05591v1](http://arxiv.org/abs/2409.05591v1)|null|
|**2024-09-09**|**Latent 3D Brain MRI Counterfactual**|Wei Peng et.al.|[2409.05585v1](http://arxiv.org/abs/2409.05585v1)|null|
|**2024-09-09**|**Spatially-Aware Speaker for Vision-and-Language Navigation Instruction Generation**|Muraleekrishna Gopinathan et.al.|[2409.05583v1](http://arxiv.org/abs/2409.05583v1)|[link](https://github.com/gmuraleekrishna/sas)|
|**2024-09-09**|**Learning to Model Graph Structural Information on MLPs via Graph Structure Self-Contrasting**|Lirong Wu et.al.|[2409.05573v1](http://arxiv.org/abs/2409.05573v1)|null|
|**2024-09-09**|**LEROjD: Lidar Extended Radar-Only Object Detection**|Patrick Palmer et.al.|[2409.05564v1](http://arxiv.org/abs/2409.05564v1)|[link](https://github.com/rst-tu-dortmund/lerojd)|
|**2024-09-09**|**CauseJudger: Identifying the Cause with LLMs for Abductive Logical Reasoning**|Jinwei He et.al.|[2409.05559v1](http://arxiv.org/abs/2409.05559v1)|null|
|**2024-09-09**|**Seeing Through the Mask: Rethinking Adversarial Examples for CAPTCHAs**|Yahya Jabary et.al.|[2409.05558v1](http://arxiv.org/abs/2409.05558v1)|null|
|**2024-09-09**|**SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning**|Alireza Ghafarollahi et.al.|[2409.05556v1](http://arxiv.org/abs/2409.05556v1)|null|
|**2024-09-09**|**HMAFlow: Learning More Accurate Optical Flow via Hierarchical Motion Field Alignment**|Dianbo Ma et.al.|[2409.05531v1](http://arxiv.org/abs/2409.05531v1)|null|
|**2024-09-09**|**QiBERT -- Classifying Online Conversations Messages with BERT as a Feature**|Bruno D. Ferreira-Saraiva et.al.|[2409.05530v1](http://arxiv.org/abs/2409.05530v1)|null|
|**2024-09-09**|**Harmonic Reasoning in Large Language Models**|Anna Kruspe et.al.|[2409.05521v1](http://arxiv.org/abs/2409.05521v1)|null|
|**2024-09-09**|**Elsevier Arena: Human Evaluation of Chemistry/Biology/Health Foundational Large Language Models**|Camilo Thorne et.al.|[2409.05486v1](http://arxiv.org/abs/2409.05486v1)|null|
|**2024-09-09**|**CRADLE-VAE: Enhancing Single-Cell Gene Perturbation Modeling with Counterfactual Reasoning-based Artifact Disentanglement**|Seungheun Baek et.al.|[2409.05484v1](http://arxiv.org/abs/2409.05484v1)|null|
|**2024-09-09**|**Representational Analysis of Binding in Large Language Models**|Qin Dai et.al.|[2409.05448v1](http://arxiv.org/abs/2409.05448v1)|null|
|**2024-09-09**|**STLM Engineering Report: Dropout**|Dylan Hillier et.al.|[2409.05423v1](http://arxiv.org/abs/2409.05423v1)|[link](https://github.com/leonguertler/supertinylanguagemodels)|
|**2024-09-09**|**AD-Net: Attention-based dilated convolutional residual network with guided decoder for robust skin lesion segmentation**|Asim Naveed et.al.|[2409.05420v1](http://arxiv.org/abs/2409.05420v1)|null|
|**2024-09-09**|**CipherDM: Secure Three-Party Inference for Diffusion Model Sampling**|Xin Zhao et.al.|[2409.05414v1](http://arxiv.org/abs/2409.05414v1)|null|
|**2024-09-09**|**A Survey of Multimodal Composite Editing and Retrieval**|Suyan Li et.al.|[2409.05405v1](http://arxiv.org/abs/2409.05405v1)|null|
|**2024-09-09**|**HyperSMOTE: A Hypergraph-based Oversampling Approach for Imbalanced Node Classifications**|Ziming Zhao et.al.|[2409.05402v1](http://arxiv.org/abs/2409.05402v1)|null|
|**2024-09-09**|**NLLB-E5: A Scalable Multilingual Retrieval Model**|Arkadeep Acharya et.al.|[2409.05401v1](http://arxiv.org/abs/2409.05401v1)|null|
|**2024-09-09**|**FacialFlowNet: Advancing Facial Optical Flow Estimation with a Diverse Dataset and a Decomposed Model**|Jianzhi Lu et.al.|[2409.05396v1](http://arxiv.org/abs/2409.05396v1)|null|
|**2024-09-09**|**Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling**|Georgios Pantazopoulos et.al.|[2409.05395v1](http://arxiv.org/abs/2409.05395v1)|null|
|**2024-09-09**|**Towards Building a Robust Knowledge Intensive Question Answering Model with Large Language Models**|Hong Xingyun Hong et.al.|[2409.05385v1](http://arxiv.org/abs/2409.05385v1)|null|
|**2024-09-09**|**Look One and More: Distilling Hybrid Order Relational Knowledge for Cross-Resolution Image Recognition**|Shiming Ge et.al.|[2409.05384v1](http://arxiv.org/abs/2409.05384v1)|null|
|**2024-09-09**|**Deep Learning for Video Anomaly Detection: A Review**|Peng Wu et.al.|[2409.05383v1](http://arxiv.org/abs/2409.05383v1)|null|
|**2024-09-09**|**KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models**|Yingshu Li et.al.|[2409.05370v1](http://arxiv.org/abs/2409.05370v1)|null|
|**2024-09-09**|**Application Specific Compression of Deep Learning Models**|Rohit Raj Rai et.al.|[2409.05368v1](http://arxiv.org/abs/2409.05368v1)|null|
|**2024-09-09**|**Diagnostic Reasoning in Natural Language: Computational Model and Application**|Nils Dycke et.al.|[2409.05367v1](http://arxiv.org/abs/2409.05367v1)|null|
|**2024-09-09**|**IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS**|Ashwin Sankar et.al.|[2409.05356v1](http://arxiv.org/abs/2409.05356v1)|[link](https://github.com/ai4bharat/indicvoices-r)|
|**2024-09-09**|**TriplePlay: Enhancing Federated Learning with CLIP for Non-IID Data and Resource Efficiency**|Ahmed Imteaj et.al.|[2409.05347v1](http://arxiv.org/abs/2409.05347v1)|null|
|**2024-09-09**|**GDFlow: Anomaly Detection with NCDE-based Normalizing Flow for Advanced Driver Assistance System**|Kangjun Lee et.al.|[2409.05346v1](http://arxiv.org/abs/2409.05346v1)|null|
|**2024-09-09**|**A Multi-Modal Deep Learning Based Approach for House Price Prediction**|Md Hasebul Hasan et.al.|[2409.05335v1](http://arxiv.org/abs/2409.05335v1)|null|
|**2024-09-09**|**Sample-Efficient Bayesian Optimization with Transfer Learning for Heterogeneous Search Spaces**|Aryan Deshwal et.al.|[2409.05325v1](http://arxiv.org/abs/2409.05325v1)|null|
|**2024-09-09**|**Machine Anomalous Sound Detection Using Spectral-temporal Modulation Representations Derived from Machine-specific Filterbanks**|Kai Li et.al.|[2409.05319v1](http://arxiv.org/abs/2409.05319v1)|null|
|**2024-09-09**|**Tele-LLMs: A Series of Specialized Large Language Models for Telecommunications**|Ali Maatouk et.al.|[2409.05314v1](http://arxiv.org/abs/2409.05314v1)|null|
|**2024-09-09**|**Resource-Efficient Generative AI Model Deployment in Mobile Edge Networks**|Yuxin Liang et.al.|[2409.05303v1](http://arxiv.org/abs/2409.05303v1)|null|
|**2024-09-09**|**TERD: A Unified Framework for Safeguarding Diffusion Models Against Backdoors**|Yichuan Mo et.al.|[2409.05294v1](http://arxiv.org/abs/2409.05294v1)|null|
|**2024-09-09**|**Mpox Narrative on Instagram: A Labeled Multilingual Dataset of Instagram Posts on Mpox for Sentiment, Hate Speech, and Anxiety Analysis**|Nirmalya Thakur et.al.|[2409.05292v1](http://arxiv.org/abs/2409.05292v1)|null|
|**2024-09-09**|**Seek and Solve Reasoning for Table Question Answering**|Ruya Jiang et.al.|[2409.05286v1](http://arxiv.org/abs/2409.05286v1)|null|
|**2024-09-09**|**On the Relationship between Truth and Political Bias in Language Models**|Suyash Fulay et.al.|[2409.05283v1](http://arxiv.org/abs/2409.05283v1)|null|
|**2024-09-09**|**RotCAtt-TransUNet++: Novel Deep Neural Network for Sophisticated Cardiac Segmentation**|Quoc-Bao Nguyen-Le et.al.|[2409.05280v1](http://arxiv.org/abs/2409.05280v1)|[link](https://github.com/kyle-paul/RotCAtt-TransUNet-plusplus)|
|**2024-09-09**|**RexUniNLU: Recursive Method with Explicit Schema Instructor for Universal NLU**|Chengyuan Liu et.al.|[2409.05275v1](http://arxiv.org/abs/2409.05275v1)|null|
|**2024-09-09**|**Towards Automated Machine Learning Research**|Shervin Ardeshir et.al.|[2409.05258v1](http://arxiv.org/abs/2409.05258v1)|null|
|**2024-09-08**|**Socially Responsible Data for Large Multilingual Language Models**|Andrew Smart et.al.|[2409.05247v1](http://arxiv.org/abs/2409.05247v1)|null|
|**2024-09-08**|**FedFT: Improving Communication Performance for Federated Learning with Frequency Space Transformation**|Chamath Palihawadana et.al.|[2409.05242v1](http://arxiv.org/abs/2409.05242v1)|null|
|**2024-09-08**|**Exploring Intrinsic Language-specific Subspaces in Fine-tuning Multilingual Neural Machine Translation**|Zhe Cao et.al.|[2409.05224v1](http://arxiv.org/abs/2409.05224v1)|[link](https://github.com/spike0924/lslo)|
|**2024-09-08**|**Synthetic Tabular Data Generation for Class Imbalance and Fairness: A Comparative Study**|Emmanouil Panagiotou et.al.|[2409.05215v1](http://arxiv.org/abs/2409.05215v1)|null|
|**2024-09-08**|**ICML Topological Deep Learning Challenge 2024: Beyond the Graph Domain**|Guillermo Bernárdez et.al.|[2409.05211v1](http://arxiv.org/abs/2409.05211v1)|null|
|**2024-09-08**|**Interactive Machine Teaching by Labeling Rules and Instances**|Giannis Karamanolakis et.al.|[2409.05199v1](http://arxiv.org/abs/2409.05199v1)|null|
|**2024-09-08**|**Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?**|Neeladri Bhuiya et.al.|[2409.05197v1](http://arxiv.org/abs/2409.05197v1)|null|
|**2024-09-08**|**Insights from Benchmarking Frontier Language Models on Web App Code Generation**|Yi Cui et.al.|[2409.05177v1](http://arxiv.org/abs/2409.05177v1)|null|
|**2024-09-08**|**OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs**|Jintian Zhang et.al.|[2409.05152v1](http://arxiv.org/abs/2409.05152v1)|null|
|**2024-09-08**|**Better Spanish Emotion Recognition In-the-wild: Bringing Attention to Deep Spectrum Voice Analysis**|Elena Ortega-Beltrán et.al.|[2409.05148v1](http://arxiv.org/abs/2409.05148v1)|null|
|**2024-09-08**|**READoc: A Unified Benchmark for Realistic Document Structured Extraction**|Zichao Li et.al.|[2409.05137v1](http://arxiv.org/abs/2409.05137v1)|null|
|**2024-09-08**|**WaterSeeker: Efficient Detection of Watermarked Segments in Large Documents**|Leyi Pan et.al.|[2409.05112v1](http://arxiv.org/abs/2409.05112v1)|null|
|**2024-09-08**|**EdaCSC: Two Easy Data Augmentation Methods for Chinese Spelling Correction**|Lei Sheng et.al.|[2409.05105v1](http://arxiv.org/abs/2409.05105v1)|null|
|**2024-09-08**|**PIP: Detecting Adversarial Examples in Large Vision-Language Models via Attention Patterns of Irrelevant Probe Questions**|Yudong Zhang et.al.|[2409.05076v1](http://arxiv.org/abs/2409.05076v1)|null|
|**2024-09-08**|**A Survey on Diffusion Models for Recommender Systems**|Jianghao Lin et.al.|[2409.05033v1](http://arxiv.org/abs/2409.05033v1)|null|
|**2024-09-08**|**LLM-based Abstraction and Concretization for GUI Test Migration**|Yakun Zhang et.al.|[2409.05028v1](http://arxiv.org/abs/2409.05028v1)|null|
|**2024-09-08**|**Sequential Recommendation via Adaptive Robust Attention with Multi-dimensional Embeddings**|Linsey Pang et.al.|[2409.05022v1](http://arxiv.org/abs/2409.05022v1)|null|
|**2024-09-08**|**Vision-fused Attack: Advancing Aggressive and Stealthy Adversarial Text against Neural Machine Translation**|Yanni Xue et.al.|[2409.05021v1](http://arxiv.org/abs/2409.05021v1)|[link](https://github.com/levelower/vfa)|
|**2024-09-08**|**Audio-Guided Fusion Techniques for Multimodal Emotion Analysis**|Pujin Shi et.al.|[2409.05007v1](http://arxiv.org/abs/2409.05007v1)|null|
|**2024-09-08**|**Towards Patronizing and Condescending Language in Chinese Videos: A Multimodal Dataset and Detector**|Hongbo Wang et.al.|[2409.05005v1](http://arxiv.org/abs/2409.05005v1)|[link](https://github.com/dut-laowang/pclmm)|
|**2024-09-08**|**A Pair Programming Framework for Code Generation via Multi-Plan Exploration and Feedback-Driven Refinement**|Huan Zhang et.al.|[2409.05001v1](http://arxiv.org/abs/2409.05001v1)|null|
|**2024-09-08**|**InstInfer: In-Storage Attention Offloading for Cost-Effective Long-Context LLM Inference**|Xiurui Pan et.al.|[2409.04992v1](http://arxiv.org/abs/2409.04992v1)|null|
|**2024-09-08**|**Enhancing Convolutional Neural Networks with Higher-Order Numerical Difference Methods**|Qi Wang et.al.|[2409.04977v1](http://arxiv.org/abs/2409.04977v1)|null|
|**2024-09-08**|**Evaluation of Google Translate for Mandarin Chinese translation using sentiment and semantic analysis**|Xuechun Wang et.al.|[2409.04964v1](http://arxiv.org/abs/2409.04964v1)|null|
|**2024-09-08**|**DDNet: Deformable Convolution and Dense FPN for Surface Defect Detection in Recycled Books**|Jun Yu et.al.|[2409.04958v1](http://arxiv.org/abs/2409.04958v1)|null|
|**2024-09-08**|**Evaluating Neural Networks Architectures for Spring Reverb Modelling**|Francesco Papaleo et.al.|[2409.04953v1](http://arxiv.org/abs/2409.04953v1)|null|
|**2024-09-08**|**Attention-Based Efficient Breath Sound Removal in Studio Audio Recordings**|Nidula Elgiriyewithana et.al.|[2409.04949v1](http://arxiv.org/abs/2409.04949v1)|null|
|**2024-09-07**|**Maximizing Relation Extraction Potential: A Data-Centric Study to Unveil Challenges and Opportunities**|Anushka Swarup et.al.|[2409.04934v1](http://arxiv.org/abs/2409.04934v1)|null|
|**2024-09-07**|**Just ASR + LLM? A Study on Speech Large Language Models' Ability to Identify and Understand Speaker in Spoken Dialogue**|Junkai Wu et.al.|[2409.04927v1](http://arxiv.org/abs/2409.04927v1)|[link](https://github.com/wjk0925/slt2024-speechllm-speaker-understanding)|
|**2024-09-07**|**A $Δ$-evaluation function for column permutation problems**|Júnior R. Lima et.al.|[2409.04926v1](http://arxiv.org/abs/2409.04926v1)|null|
|**2024-09-07**|**MoistNet: Machine Vision-based Deep Learning Models for Wood Chip Moisture Content Measurement**|Abdur Rahman et.al.|[2409.04920v1](http://arxiv.org/abs/2409.04920v1)|null|
|**2024-09-07**|**Activation Function Optimization Scheme for Image Classification**|Abdur Rahman et.al.|[2409.04915v1](http://arxiv.org/abs/2409.04915v1)|null|
|**2024-09-07**|**Efficient Training of Transformers for Molecule Property Prediction on Small-scale Datasets**|Shivesh Prakash et.al.|[2409.04909v1](http://arxiv.org/abs/2409.04909v1)|null|

#### Abstracts
##### **Promptable Closed-loop Traffic Simulation**
2409.05863v1 by Shuhan Tan, Boris Ivanovic, Yuxiao Chen, Boyi Li, Xinshuo Weng, Yulong Cao, Philipp Krähenbühl, Marco Pavone

Simulation stands as a cornerstone for safe and efficient autonomous driving
development. At its core a simulation system ought to produce realistic,
reactive, and controllable traffic patterns. In this paper, we propose ProSim,
a multimodal promptable closed-loop traffic simulation framework. ProSim allows
the user to give a complex set of numerical, categorical or textual prompts to
instruct each agent's behavior and intention. ProSim then rolls out a traffic
scenario in a closed-loop manner, modeling each agent's interaction with other
traffic participants. Our experiments show that ProSim achieves high prompt
controllability given different user prompts, while reaching competitive
performance on the Waymo Sim Agents Challenge when no prompt is given. To
support research on promptable traffic simulation, we create
ProSim-Instruct-520k, a multimodal prompt-scenario paired driving dataset with
over 10M text prompts for over 520k real-world driving scenarios. We will
release code of ProSim as well as data and labeling tools of
ProSim-Instruct-520k at https://ariostgx.github.io/ProSim.

摘要：模擬作為安全且有效率的自動駕駛開發的基石。模擬系統的核心在於產生逼真、具反應性且可控制的交通模式。在本文中，我們提出 ProSim，一個多模態可提示閉環交通模擬架構。ProSim 允許使用者提供一組複雜的數值、類別或文字提示，以指示每個代理的行為和意圖。然後，ProSim 以閉環方式推出交通場景，模擬每個代理與其他交通參與者的互動。我們的實驗顯示，在沒有提示的情況下，ProSim 在不同的使用者提示下實現了很高的提示可控性，同時在 Waymo Sim Agents Challenge 中達到了競爭力的表現。為了支持可提示交通模擬的研究，我們建立了 ProSim-Instruct-520k，一個多模態提示場景配對的駕駛資料集，其中包含超過 10M 個文字提示，適用於超過 520k 個真實世界的駕駛場景。我們將在 https://ariostgx.github.io/ProSim 上釋出 ProSim 的程式碼以及 ProSim-Instruct-520k 的資料和標籤工具。

##### **MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct**
2409.05840v1 by Run Luo, Haonan Zhang, Longze Chen, Ting-En Lin, Xiong Liu, Yuchuan Wu, Min Yang, Minzheng Wang, Pengpeng Zeng, Lianli Gao, Heng Tao Shen, Yunshui Li, Xiaobo Xia, Fei Huang, Jingkuan Song, Yongbin Li

The development of Multimodal Large Language Models (MLLMs) has seen
significant advancements. However, the quantity and quality of multimodal
instruction data have emerged as significant bottlenecks in their progress.
Manually creating multimodal instruction data is both time-consuming and
inefficient, posing challenges in producing instructions of high complexity.
Moreover, distilling instruction data from black-box commercial models (e.g.,
GPT-4o, GPT-4V) often results in simplistic instruction data, which constrains
performance to that of these models. The challenge of curating diverse and
complex instruction data remains substantial. We propose MMEvol, a novel
multimodal instruction data evolution framework that combines fine-grained
perception evolution, cognitive reasoning evolution, and interaction evolution.
This iterative approach breaks through data quality bottlenecks to generate a
complex and diverse image-text instruction dataset, thereby empowering MLLMs
with enhanced capabilities. Beginning with an initial set of instructions,
SEED-163K, we utilize MMEvol to systematically broadens the diversity of
instruction types, integrates reasoning steps to enhance cognitive
capabilities, and extracts detailed information from images to improve visual
understanding and robustness. To comprehensively evaluate the effectiveness of
our data, we train LLaVA-NeXT using the evolved data and conduct experiments
across 13 vision-language tasks. Compared to the baseline trained with seed
data, our approach achieves an average accuracy improvement of 3.1 points and
reaches state-of-the-art (SOTA) performance on 9 of these tasks.

摘要：多模态大语言模型（MLLM）的发展已取得显著进展。然而，多模态指令数据的数量和质量已成为其进步中的重大瓶颈。手动创建多模态指令数据既费时又低效，在生成高复杂度指令时会造成挑战。此外，从黑箱商业模型（例如 GPT-4o、GPT-4V）中提取指令数据通常会导致指令数据过于简单，这会将性能限制在这些模型的性能范围内。对多样且复杂指令数据进行整理的挑战仍然很大。我们提出了 MMEvol，这是一种新颖的多模态指令数据演化框架，它结合了细粒度的感知演化、认知推理演化和交互演化。这种迭代方法突破了数据质量瓶颈，生成复杂且多样的图像文本指令数据集，从而增强了 MLLM 的能力。从一组初始指令 SEED-163K 开始，我们利用 MMEvol 系统地拓宽指令类型的多样性，整合推理步骤以增强认知能力，并从图像中提取详细信息以提高视觉理解和鲁棒性。为了全面评估我们数据的有效性，我们使用演化数据训练 LLaVA-NeXT，并在 13 项视觉语言任务中进行实验。与使用种子数据训练的基线相比，我们的方法将平均准确度提高了 3.1 个百分点，并在其中 9 项任务上达到了最先进 (SOTA) 的性能。

##### **Improving Pretraining Data Using Perplexity Correlations**
2409.05816v1 by Tristan Thrush, Christopher Potts, Tatsunori Hashimoto

Quality pretraining data is often seen as the key to high-performance
language models. However, progress in understanding pretraining data has been
slow due to the costly pretraining runs required for data selection
experiments. We present a framework that avoids these costs and selects
high-quality pretraining data without any LLM training of our own. Our work is
based on a simple observation: LLM losses on many pretraining texts are
correlated with downstream benchmark performance, and selecting
high-correlation documents is an effective pretraining data selection method.
We build a new statistical framework for data selection centered around
estimates of perplexity-benchmark correlations and perform data selection using
a sample of 90 LLMs taken from the Open LLM Leaderboard on texts from tens of
thousands of web domains. In controlled pretraining experiments at the 160M
parameter scale on 8 benchmarks, our approach outperforms DSIR on every
benchmark, while matching the best data selector found in DataComp-LM, a
hand-engineered bigram classifier.

摘要：高质量预训练数据通常被视为高性能语言模型的关键。然而，由于数据选择实验需要昂贵的预训练运行，因此对预训练数据的理解进展缓慢。我们提出了一个避免这些成本的框架，并在不进行任何 LLM 训练的情况下选择高质量的预训练数据。我们的工作基于一个简单的观察：许多预训练文本上的 LLM 损失与下游基准性能相关，并且选择高相关性文档是一种有效的预训练数据选择方法。我们构建了一个新的统计框架，用于数据选择，该框架围绕困惑度基准相关性的估计展开，并使用从数万个网络域中的文本中获取的 90 个 LLM 样本执行数据选择。在 8 个基准上的 160M 参数规模的受控预训练实验中，我们的方法在每个基准上都优于 DSIR，同时匹配了在 DataComp-LM 中发现的最佳数据选择器，即手工制作的二元分类器。

##### **The Future of Software Testing: AI-Powered Test Case Generation and Validation**
2409.05808v1 by Mohammad Baqar, Rajat Khanda

Software testing is a crucial phase in the software development lifecycle
(SDLC), ensuring that products meet necessary functional, performance, and
quality benchmarks before release. Despite advancements in automation,
traditional methods of generating and validating test cases still face
significant challenges, including prolonged timelines, human error, incomplete
test coverage, and high costs of manual intervention. These limitations often
lead to delayed product launches and undetected defects that compromise
software quality and user satisfaction. The integration of artificial
intelligence (AI) into software testing presents a promising solution to these
persistent challenges. AI-driven testing methods automate the creation of
comprehensive test cases, dynamically adapt to changes, and leverage machine
learning to identify high-risk areas in the codebase. This approach enhances
regression testing efficiency while expanding overall test coverage.
Furthermore, AI-powered tools enable continuous testing and self-healing test
cases, significantly reducing manual oversight and accelerating feedback loops,
ultimately leading to faster and more reliable software releases. This paper
explores the transformative potential of AI in improving test case generation
and validation, focusing on its ability to enhance efficiency, accuracy, and
scalability in testing processes. It also addresses key challenges associated
with adapting AI for testing, including the need for high quality training
data, ensuring model transparency, and maintaining a balance between automation
and human oversight. Through case studies and examples of real-world
applications, this paper illustrates how AI can significantly enhance testing
efficiency across both legacy and modern software systems.

摘要：軟體測試是軟體開發生命週期 (SDLC) 中至關重要的一個階段，確保產品在發布前符合必要的運作、效能和品質基準。儘管自動化技術進步，但產生和驗證測試案例的傳統方法仍然面臨重大挑戰，包括時間線拉長、人為錯誤、測試涵蓋不完全，以及人工介入的高成本。這些限制通常會導致產品發布延誤和未偵測到的缺陷，進而損害軟體品質和使用者滿意度。將人工智慧 (AI) 整合到軟體測試中，為這些持續存在的挑戰提供了有希望的解決方案。AI 驅動的測試方法可以自動建立全面的測試案例，動態適應變更，並利用機器學習來識別程式碼庫中的高風險區域。這種方法可以提升回歸測試效率，同時擴展整體測試涵蓋範圍。此外，AI 驅動的工具可以進行持續測試和自我修復測試案例，大幅減少人工監督並加速回饋迴圈，最終實現更快速且更可靠的軟體發布。本文探討了 AI 在改善測試案例產生和驗證方面的變革潛力，重點在於它增強測試流程中效率、準確性和可擴充性的能力。本文也探討了將 AI 應用於測試時會遇到的主要挑戰，包括對高品質訓練資料的需求、確保模型透明度，以及在自動化和人工監督之間取得平衡。透過案例研究和真實世界應用範例，本文說明了 AI 如何能大幅提升傳統和現代軟體系統的測試效率。

##### **Benchmarking Chinese Knowledge Rectification in Large Language Models**
2409.05806v1 by Tianhe Lu, Jizhan Fang, Yunzhi Yao, Xin Xu, Ningyu Zhang, Huajun Chen

While Large Language Models (LLMs) exhibit remarkable generative
capabilities, they are not without flaws, particularly in the form of
hallucinations. This issue is even more pronounced when LLMs are applied to
specific languages and domains. For example, LLMs may generate nonsense
information when handling Chinese ancient poetry, proverbs, or idioms, owing to
the lack of specific knowledge. To this end, this paper introduces a benchmark
for rectifying Chinese knowledge in LLMs via knowledge editing. Specifically,
we introduce a new Chinese dataset, CKnowEdit, by collecting seven type of
knowledge from various sources, including classical texts, idioms, and content
from Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony,
antithesis, and logical constructs inherent in the Chinese language. Through
the analysis of this dataset, we uncover the challenges faced by current LLMs
in mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge
editing techniques on this dataset unveil the substantial scope for advancement
in the rectification of Chinese knowledge. Code and dataset are available at
https://github.com/zjunlp/EasyEdit.

摘要：大型语言模型 (LLM) 虽然表现出非凡的生成能力，但也并非没有缺陷，特别是幻觉形式的缺陷。当 LLM 应用于特定语言和领域时，这个问题更为明显。例如，由于缺乏特定知识，LLM 在处理中国古代诗歌、谚语或成语时可能会产生无意义的信息。为此，本文通过知识编辑引入了一个用于纠正 LLM 中中文知识的基准。具体来说，我们通过从各种来源（包括经典文本、成语和百度贴吧若知八的的内容）收集七种类型的知识，引入了新的中文数据集 CKnowEdit，从而解释了中文语言中固有的独特多音、对立和逻辑结构。通过对该数据集的分析，我们发现了当前 LLM 在掌握中文时面临的挑战。此外，我们对该数据集上最先进的知识编辑技术的评估揭示了纠正中文知识的巨大进步空间。代码和数据集可在 https://github.com/zjunlp/EasyEdit 获得。

##### **Enhancing Preference-based Linear Bandits via Human Response Time**
2409.05798v1 by Shen Li, Yuyang Zhang, Zhaolin Ren, Claire Liang, Na Li, Julie A. Shah

Binary human choice feedback is widely used in interactive preference
learning for its simplicity, but it provides limited information about
preference strength. To overcome this limitation, we leverage human response
times, which inversely correlate with preference strength, as complementary
information. Our work integrates the EZ-diffusion model, which jointly models
human choices and response times, into preference-based linear bandits. We
introduce a computationally efficient utility estimator that reformulates the
utility estimation problem using both choices and response times as a linear
regression problem. Theoretical and empirical comparisons with traditional
choice-only estimators reveal that for queries with strong preferences ("easy"
queries), choices alone provide limited information, while response times offer
valuable complementary information about preference strength. As a result,
incorporating response times makes easy queries more useful. We demonstrate
this advantage in the fixed-budget best-arm identification problem, with
simulations based on three real-world datasets, consistently showing
accelerated learning when response times are incorporated.

摘要：二元人類選擇回饋因其簡潔性而廣泛用於互動式偏好學習，但它提供的偏好強度資訊有限。為了克服此限制，我們利用與偏好強度呈反比的人類反應時間，作為補充資訊。我們的研究將 EZ 擴散模型整合到偏好式線性賭徒中，該模型共同建模人類選擇和反應時間。我們引入了一個計算效率高的效用估計器，它使用選擇和反應時間作為線性回歸問題來重新制定效用估計問題。與傳統的僅選擇估計器的理論和實證比較表明，對於具有強烈偏好的查詢（「容易」查詢），僅選擇提供有限的資訊，而反應時間提供有價值的補充資訊，說明偏好強度。因此，納入反應時間使簡單的查詢更有用。我們在固定預算最佳臂識別問題中展示了此優勢，模擬基於三個真實世界資料集，始終顯示在納入反應時間時，加速學習。

##### **NeurLZ: On Systematically Enhancing Lossy Compression Performance for Scientific Data based on Neural Learning with Error Control**
2409.05785v1 by Wenqi Jia, Youyuan Liu, Zhewen Hu, Jinzhen Wang, Boyuan Zhang, Wei Niu, Junzhou Huang, Stavros Kalafatis, Sian Jin, Miao Yin

Large-scale scientific simulations generate massive datasets that pose
significant challenges for storage and I/O. While traditional lossy compression
techniques can improve performance, balancing compression ratio, data quality,
and throughput remains difficult. To address this, we propose NeurLZ, a novel
cross-field learning-based and error-controlled compression framework for
scientific data. By integrating skipping DNN models, cross-field learning, and
error control, our framework aims to substantially enhance lossy compression
performance. Our contributions are three-fold: (1) We design a lightweight
skipping model to provide high-fidelity detail retention, further improving
prediction accuracy. (2) We adopt a cross-field learning approach to
significantly improve data prediction accuracy, resulting in a substantially
improved compression ratio. (3) We develop an error control approach to provide
strict error bounds according to user requirements. We evaluated NeurLZ on
several real-world HPC application datasets, including Nyx (cosmological
simulation), Miranda (large turbulence simulation), and Hurricane (weather
simulation). Experiments demonstrate that our framework achieves up to a 90%
relative reduction in bit rate under the same data distortion, compared to the
best existing approach.

摘要：大型科學模擬會產生大量資料集，對儲存和 I/O 而言構成重大挑戰。雖然傳統有損壓縮技術可以提升效能，但平衡壓縮比、資料品質和處理量仍然很困難。為了解決這個問題，我們提出 NeurLZ，一種新穎的基於跨場域學習和錯誤控制的科學資料壓縮架構。透過整合跳躍 DNN 模型、跨場域學習和錯誤控制，我們的架構旨在大幅提升有損壓縮效能。我們的貢獻有三方面：(1) 我們設計了一個輕量級跳躍模型來提供高保真細節保留，進一步提升預測準確度。(2) 我們採用跨場域學習方法來大幅提升資料預測準確度，進而大幅提升壓縮比。(3) 我們開發了一種錯誤控制方法來根據使用者需求提供嚴格的錯誤界限。我們在多個真實世界 HPC 應用程式資料集上評估 NeurLZ，包括 Nyx (宇宙學模擬)、Miranda (大型湍流模擬) 和 Hurricane (天氣模擬)。實驗證明，與現有的最佳方法相比，我們的架構在相同的資料失真下，位元率相對減少多達 90%。

##### **Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models**
2409.05771v1 by Emily Cheng, Richard J. Antonello

Research has repeatedly demonstrated that intermediate hidden states
extracted from large language models are able to predict measured brain
response to natural language stimuli. Yet, very little is known about the
representation properties that enable this high prediction performance. Why is
it the intermediate layers, and not the output layers, that are most capable
for this unique and highly general transfer task? In this work, we show that
evidence from language encoding models in fMRI supports the existence of a
two-phase abstraction process within LLMs. We use manifold learning methods to
show that this abstraction process naturally arises over the course of training
a language model and that the first "composition" phase of this abstraction
process is compressed into fewer layers as training continues. Finally, we
demonstrate a strong correspondence between layerwise encoding performance and
the intrinsic dimensionality of representations from LLMs. We give initial
evidence that this correspondence primarily derives from the inherent
compositionality of LLMs and not their next-word prediction properties.

摘要：研究已一再證明，從大型語言模型中提取的中間隱藏狀態能夠預測大腦對自然語言刺激的測量反應。然而，對於能夠實現這種高預測性能的表徵特性，我們所知甚少。為什麼是中間層，而不是輸出層，最能勝任這項獨特且高度通用的轉移任務？在這項工作中，我們展示了 fMRI 中語言編碼模型的證據支持 LLM 中存在兩階段抽象過程。我們使用流形學習方法來展示這個抽象過程在語言模型訓練過程中自然產生，並且這個抽象過程的第一個「組合」階段會隨著訓練的進行而壓縮到更少的層中。最後，我們展示了層級編碼性能與 LLM 中表徵的內在維度之間的強對應關係。我們給出的初步證據表明，這種對應關係主要源於 LLM 固有的組合性，而不是它們的下一詞預測特性。

##### **ReL-SAR: Representation Learning for Skeleton Action Recognition with Convolutional Transformers and BYOL**
2409.05749v1 by Safwen Naimi, Wassim Bouachir, Guillaume-Alexandre Bilodeau

To extract robust and generalizable skeleton action recognition features,
large amounts of well-curated data are typically required, which is a
challenging task hindered by annotation and computation costs. Therefore,
unsupervised representation learning is of prime importance to leverage
unlabeled skeleton data. In this work, we investigate unsupervised
representation learning for skeleton action recognition. For this purpose, we
designed a lightweight convolutional transformer framework, named ReL-SAR,
exploiting the complementarity of convolutional and attention layers for
jointly modeling spatial and temporal cues in skeleton sequences. We also use a
Selection-Permutation strategy for skeleton joints to ensure more informative
descriptions from skeletal data. Finally, we capitalize on Bootstrap Your Own
Latent (BYOL) to learn robust representations from unlabeled skeleton sequence
data. We achieved very competitive results on limited-size datasets: MCAD,
IXMAS, JHMDB, and NW-UCLA, showing the effectiveness of our proposed method
against state-of-the-art methods in terms of both performance and computational
efficiency. To ensure reproducibility and reusability, the source code
including all implementation parameters is provided at:
https://github.com/SafwenNaimi/Representation-Learning-for-Skeleton-Action-Recognition-with-Convolutional-Transformers-and-BYOL

摘要：<paragraph>為了提取強健且可概括的骨架動作辨識特徵，通常需要大量的精心策劃資料，這是一項受到註解和運算成本阻礙的艱難任務。因此，無監督式表徵學習對於利用未標記骨架資料至關重要。在這項工作中，我們探討了骨架動作辨識的無監督式表徵學習。為此，我們設計了一個輕量級的卷積轉換器框架，名為 ReL-SAR，利用卷積和注意力層的互補性來聯合建模骨架序列中的空間和時間線索。我們還使用骨架關節的選擇排列策略，以確保從骨架資料中獲得更多資訊性的描述。最後，我們利用 Bootstrap Your Own Latent (BYOL) 從未標記的骨架序列資料中學習強健的表徵。我們在有限大小的資料集上取得了非常有競爭力的結果：MCAD、IXMAS、JHMDB 和 NW-UCLA，顯示了我們提出的方法在效能和運算效率方面優於最先進的方法。為了確保可複製性和可重複使用性，原始程式碼（包括所有實作參數）可在以下網址取得：
https://github.com/SafwenNaimi/Representation-Learning-for-Skeleton-Action-Recognition-with-Convolutional-Transformers-and-BYOL</paragraph>

##### **A Novel Idea Generation Tool using a Structured Conversational AI (CAI) System**
2409.05747v1 by B. Sankar, Dibakar Sen

This paper presents a novel conversational AI-enabled active ideation
interface as a creative idea-generation tool to assist novice designers in
mitigating the initial latency and ideation bottlenecks that are commonly
observed. It is a dynamic, interactive, and contextually responsive approach,
actively involving a large language model (LLM) from the domain of natural
language processing (NLP) in artificial intelligence (AI) to produce multiple
statements of potential ideas for different design problems. Integrating such
AI models with ideation creates what we refer to as an Active Ideation
scenario, which helps foster continuous dialogue-based interaction,
context-sensitive conversation, and prolific idea generation. A pilot study was
conducted with thirty novice designers to generate ideas for given problems
using traditional methods and the new CAI-based interface. The key parameters
of fluency, novelty, and variety were used to compare the outcomes
qualitatively by a panel of experts. The findings demonstrated the
effectiveness of the proposed tool for generating prolific, diverse and novel
ideas. The interface was enhanced by incorporating a prompt-engineered
structured dialogue style for each ideation stage to make it uniform and more
convenient for the designers. The resulting responses of such a structured CAI
interface were found to be more succinct and aligned towards the subsequent
design stage, namely conceptualization. The paper thus established the rich
potential of using Generative AI (Gen-AI) for the early ill-structured phase of
the creative product design process.

摘要：本文提出了一種新穎的會話式 AI 驅動主動構思介面，作為一種創意構思產生工具，以協助新手設計師減輕常見的初始延遲和構思瓶頸。這是一種動態、互動且對脈絡有反應的方法，積極地將來自自然語言處理 (NLP) 領域的大語言模型 (LLM) 融入人工智慧 (AI) 中，以針對不同的設計問題產生多種潛在構思的陳述。將此類 AI 模型與構思整合，創造出我們稱之為主動構思的情境，有助於促進持續的對話式互動、情境敏感的對話和大量構思的產生。與三十位新手設計師進行了一項試驗研究，以使用傳統方法和新的基於 CAI 的介面為給定的問題產生構思。流暢性、新穎性和多樣性的關鍵參數用於由專家小組定性地比較結果。研究結果證明了所提出的工具對於產生大量、多樣且新穎的構思的有效性。此介面透過為每個構思階段納入提示工程結構化對話風格而得到增強，以使其對設計師而言更為統一且更方便。發現此類結構化 CAI 介面的回應更簡潔，且更符合後續的設計階段，即概念化。因此，本文確立了將生成式 AI (Gen-AI) 用於創意產品設計流程的早期非結構化階段的豐富潛力。

##### **A System and Benchmark for LLM-based Q\&A on Heterogeneous Data**
2409.05735v1 by Achille Fokoue, Srideepika Jayaraman, Elham Khabiri, Jeffrey O. Kephart, Yingjie Li, Dhruv Shah, Youssef Drissi, Fenno F. Heath III, Anu Bhamidipaty, Fateh A. Tipu, Robert J. Baseman

In many industrial settings, users wish to ask questions whose answers may be
found in structured data sources such as a spreadsheets, databases, APIs, or
combinations thereof. Often, the user doesn't know how to identify or access
the right data source. This problem is compounded even further if multiple (and
potentially siloed) data sources must be assembled to derive the answer.
Recently, various Text-to-SQL applications that leverage Large Language Models
(LLMs) have addressed some of these problems by enabling users to ask questions
in natural language. However, these applications remain impractical in
realistic industrial settings because they fail to cope with the data source
heterogeneity that typifies such environments. In this paper, we address
heterogeneity by introducing the siwarex platform, which enables seamless
natural language access to both databases and APIs. To demonstrate the
effectiveness of siwarex, we extend the popular Spider dataset and benchmark by
replacing some of its tables by data retrieval APIs. We find that siwarex does
a good job of coping with data source heterogeneity. Our modified Spider
benchmark will soon be available to the research community

摘要：在許多工業環境中，使用者希望提出問題，而其答案可能存在於結構化資料來源中，例如試算表、資料庫、API 或其組合。使用者通常不知道如何識別或存取正確的資料來源。如果必須組裝多個（且潛在孤立的）資料來源來推導答案，此問題會進一步惡化。最近，各種利用大型語言模型 (LLM) 的文字轉 SQL 應用程式已解決了其中一些問題，讓使用者能夠以自然語言提出問題。然而，這些應用程式在現實的工業環境中仍然不切實際，因為它們無法應對此類環境中典型的資料來源異質性。在本文中，我們透過引入 siwarex 平台來解決異質性，該平台可無縫地以自然語言存取資料庫和 API。為了證明 siwarex 的有效性，我們擴充了熱門的 Spider 資料集，並透過使用資料擷取 API 取代部分表格來進行基準測試。我們發現 siwarex 在應對資料來源異質性方面做得很好。我們修改後的 Spider 基準測試將很快提供給研究社群

##### **Towards Democratizing Multilingual Large Language Models For Medicine Through A Two-Stage Instruction Fine-tuning Approach**
2409.05732v1 by Meng Zhou, Surajsinh Parmar, Anubhav Bhatti

Open-source, multilingual medical large language models (LLMs) have the
potential to serve linguistically diverse populations across different regions.
Adapting generic LLMs for healthcare often requires continual pretraining, but
this approach is computationally expensive and sometimes impractical.
Instruction fine-tuning on a specific task may not always guarantee optimal
performance due to the lack of broader domain knowledge that the model needs to
understand and reason effectively in diverse scenarios. To address these
challenges, we introduce two multilingual instruction fine-tuning datasets,
MMed-IFT and MMed-IFT-MC, containing over 200k high-quality medical samples in
six languages. We propose a two-stage training paradigm: the first stage
injects general medical knowledge using MMed-IFT, while the second stage
fine-tunes task-specific multiple-choice questions with MMed-IFT-MC. Our method
achieves competitive results on both English and multilingual benchmarks,
striking a balance between computational efficiency and performance. We plan to
make our dataset and model weights public at
\url{https://github.com/SpassMed/Med-Llama3} in the future.

摘要：開放原始碼、多語言大型醫學語言模型 (LLM) 具有為不同地區的語言多元化人群服務的潛力。將通用 LLM 適應於醫療保健通常需要持續預訓練，但此方法在運算上很昂貴，有時也不切實際。由於模型在各種情況下理解和有效推理時缺乏更廣泛的領域知識，因此針對特定任務進行的指示微調並不能總是保證最佳效能。為了應對這些挑戰，我們引入了兩個多語言指示微調資料集，即 MMed-IFT 和 MMed-IFT-MC，其中包含六種語言中超過 20 萬個高品質的醫療範例。我們提出一個兩階段訓練範例：第一階段使用 MMed-IFT 注入一般醫療知識，而第二階段使用 MMed-IFT-MC 微調特定任務的多選題。我們的模型在英文和多語言基準測試中皆取得具競爭力的結果，在運算效率和效能之間取得平衡。我們計畫在未來於 \url{https://github.com/SpassMed/Med-Llama3} 公開我們的資料集和模型權重。

##### **Referring Expression Generation in Visually Grounded Dialogue with Discourse-aware Comprehension Guiding**
2409.05721v1 by Bram Willemsen, Gabriel Skantze

We propose an approach to referring expression generation (REG) in visually
grounded dialogue that is meant to produce referring expressions (REs) that are
both discriminative and discourse-appropriate. Our method constitutes a
two-stage process. First, we model REG as a text- and image-conditioned
next-token prediction task. REs are autoregressively generated based on their
preceding linguistic context and a visual representation of the referent.
Second, we propose the use of discourse-aware comprehension guiding as part of
a generate-and-rerank strategy through which candidate REs generated with our
REG model are reranked based on their discourse-dependent discriminatory power.
Results from our human evaluation indicate that our proposed two-stage approach
is effective in producing discriminative REs, with higher performance in terms
of text-image retrieval accuracy for reranked REs compared to those generated
using greedy decoding.

摘要：我們提出一個視覺基礎對話中指稱表達生成 (REG) 的方法，旨在產生既具有區辨力又符合語篇的指稱表達 (RE)。我們的做法構成一個兩階段流程。首先，我們將 REG 建模為一個文本和影像條件化的下一個代幣預測任務。RE 會根據其先前的語言脈絡和指稱物的視覺表示自迴歸生成。其次，我們提出使用語篇感知理解引導作為生成和重新排序策略的一部分，透過該策略，使用我們的 REG 模型生成的候選 RE 會根據其語篇依賴的區辨力重新排序。我們的人員評估結果顯示，我們提出的兩階段方法在產生具有區辨力的 RE 方面有效，與使用貪婪解碼生成的 RE 相比，重新排序的 RE 在文本影像檢索準確度方面具有較高的效能。

##### **pFedGPA: Diffusion-based Generative Parameter Aggregation for Personalized Federated Learning**
2409.05701v1 by Jiahao Lai, Jiaqi Li, Jian Xu, Yanru Wu, Boshi Tang, Siqi Chen, Yongfeng Huang, Wenbo Ding, Yang Li

Federated Learning (FL) offers a decentralized approach to model training,
where data remains local and only model parameters are shared between the
clients and the central server. Traditional methods, such as Federated
Averaging (FedAvg), linearly aggregate these parameters which are usually
trained on heterogeneous data distributions, potentially overlooking the
complex, high-dimensional nature of the parameter space. This can result in
degraded performance of the aggregated model. While personalized FL approaches
can mitigate the heterogeneous data issue to some extent, the limitation of
linear aggregation remains unresolved. To alleviate this issue, we investigate
the generative approach of diffusion model and propose a novel generative
parameter aggregation framework for personalized FL, \texttt{pFedGPA}. In this
framework, we deploy a diffusion model on the server to integrate the diverse
parameter distributions and propose a parameter inversion method to efficiently
generate a set of personalized parameters for each client. This inversion
method transforms the uploaded parameters into a latent code, which is then
aggregated through denoising sampling to produce the final personalized
parameters. By encoding the dependence of a client's model parameters on the
specific data distribution using the high-capacity diffusion model,
\texttt{pFedGPA} can effectively decouple the complexity of the overall
distribution of all clients' model parameters from the complexity of each
individual client's parameter distribution. Our experimental results
consistently demonstrate the superior performance of the proposed method across
multiple datasets, surpassing baseline approaches.

摘要：聯邦學習 (FL) 提供一種分散式模型訓練方法，其中資料保持在本地，只有模型參數在客戶端和中央伺服器之間共享。傳統方法，例如聯邦平均 (FedAvg)，會線性聚合這些參數，這些參數通常在異質資料分佈上訓練，可能會忽略參數空間複雜、高維度的特性。這可能會導致聚合模型的效能下降。雖然個人化 FL 方法可以在某種程度上減輕異質資料問題，但線性聚合的限制仍然沒有解決。為了緩解這個問題，我們研究了擴散模型的生成式方法，並為個人化 FL 提出了一個新穎的生成式參數聚合架構，\texttt{pFedGPA}。在此架構中，我們在伺服器上部署一個擴散模型來整合不同的參數分佈，並提出一個參數反演方法，以有效地為每個客戶端產生一組個人化參數。此反演方法將上傳的參數轉換為潛在代碼，然後透過去噪抽樣進行聚合，以產生最終的個人化參數。透過使用高容量擴散模型編碼客戶端模型參數對特定資料分佈的依賴性，\texttt{pFedGPA} 可以有效地將所有客戶端模型參數的整體分佈的複雜性與每個個別客戶端參數分佈的複雜性分開。我們的實驗結果一致地證明了所提出的方法在多個資料集上的優異效能，超越了基線方法。

##### **RegNLP in Action: Facilitating Compliance Through Automated Information Retrieval and Answer Generation**
2409.05677v1 by Tuba Gokhan, Kexin Wang, Iryna Gurevych, Ted Briscoe

Regulatory documents, issued by governmental regulatory bodies, establish
rules, guidelines, and standards that organizations must adhere to for legal
compliance. These documents, characterized by their length, complexity and
frequent updates, are challenging to interpret, requiring significant
allocation of time and expertise on the part of organizations to ensure ongoing
compliance.Regulatory Natural Language Processing (RegNLP) is a
multidisciplinary subfield aimed at simplifying access to and interpretation of
regulatory rules and obligations. We define an Automated Question-Passage
Generation task for RegNLP, create the ObliQA dataset containing 27,869
questions derived from the Abu Dhabi Global Markets (ADGM) financial regulation
document collection, design a baseline Regulatory Information Retrieval and
Answer Generation system, and evaluate it with RePASs, a novel evaluation
metric that tests whether generated answers accurately capture all relevant
obligations and avoid contradictions.

摘要：由政府監管機構發布的法規文件，制定了組織必須遵守的法律規範、準則和標準。這些文件以其長度、複雜性和頻繁更新為特徵，難以解釋，需要組織投入大量時間和專業知識來確保持續合規。法規自然語言處理 (RegNLP) 是一個多學科子領域，旨在簡化對法規和義務的存取和解釋。我們為 RegNLP 定義了一項自動化問題段落生成任務，建立了包含 27,869 個問題的 ObliQA 資料集，這些問題來自阿布達比全球市場 (ADGM) 金融法規文件彙編，設計了一個基線法規資訊檢索和答案生成系統，並使用 RePASs 對其進行評估，RePASs 是一個新穎的評估指標，用於測試生成的答案是否準確地涵蓋所有相關義務並避免矛盾。

##### **Evaluation of real-time transcriptions using end-to-end ASR models**
2409.05674v1 by Carlos Arriaga, Alejandro Pozo, Javier Conde, Alvaro Alonso

Automatic Speech Recognition (ASR) or Speech-to-text (STT) has greatly
evolved in the last few years. Traditional architectures based on pipelines
have been replaced by joint end-to-end (E2E) architectures that simplify and
streamline the model training process. In addition, new AI training methods,
such as weak-supervised learning have reduced the need for high-quality audio
datasets for model training. However, despite all these advancements, little to
no research has been done on real-time transcription. In real-time scenarios,
the audio is not pre-recorded, and the input audio must be fragmented to be
processed by the ASR systems. To achieve real-time requirements, these
fragments must be as short as possible to reduce latency. However, audio cannot
be split at any point as dividing an utterance into two separate fragments will
generate an incorrect transcription. Also, shorter fragments provide less
context for the ASR model. For this reason, it is necessary to design and test
different splitting algorithms to optimize the quality and delay of the
resulting transcription. In this paper, three audio splitting algorithms are
evaluated with different ASR models to determine their impact on both the
quality of the transcription and the end-to-end delay. The algorithms are
fragmentation at fixed intervals, voice activity detection (VAD), and
fragmentation with feedback. The results are compared to the performance of the
same model, without audio fragmentation, to determine the effects of this
division. The results show that VAD fragmentation provides the best quality
with the highest delay, whereas fragmentation at fixed intervals provides the
lowest quality and the lowest delay. The newly proposed feedback algorithm
exchanges a 2-4% increase in WER for a reduction of 1.5-2s delay, respectively,
to the VAD splitting.

摘要：自動語音辨識 (ASR) 或語音轉文字 (STT) 在過去幾年已經有很大的進展。基於管線的傳統架構已經被聯合端對端 (E2E) 架構所取代，簡化並精簡了模型訓練流程。此外，新的 AI 訓練方法（例如弱監督學習）減少了模型訓練對高品質音訊資料集的需求。然而，儘管有這些進展，但對於即時轉錄的研究卻很少。在即時場景中，音訊並非預先錄製，輸入音訊必須被分割才能由 ASR 系統處理。為了達到即時要求，這些片段必須盡可能短，以減少延遲。然而，音訊不能在任何點被分割，因為將一個語句分成兩個獨立的片段會產生不正確的轉錄。此外，較短的片段為 ASR 模型提供的上下文較少。因此，有必要設計和測試不同的分割演算法，以最佳化轉錄的品質和延遲。在本文中，三個音訊分割演算法與不同的 ASR 模型一起評估，以確定它們對轉錄品質和端對端延遲的影響。這些演算法是固定間隔分割、語音活動偵測 (VAD) 和回饋分割。將結果與未進行音訊分割的相同模型的效能進行比較，以確定此分割的影響。結果顯示，VAD 分割提供最佳品質，但延遲最高，而固定間隔分割提供品質最低，但延遲最低。新提出的回饋演算法將 WER 增加 2-4%，以換取將 VAD 分割延遲減少 1.5-2 秒。

##### **Zero-shot Outlier Detection via Prior-data Fitted Networks: Model Selection Bygone!**
2409.05672v1 by Yuchen Shen, Haomin Wen, Leman Akoglu

Outlier detection (OD) has a vast literature as it finds numerous
applications in environmental monitoring, cybersecurity, finance, and medicine
to name a few. Being an inherently unsupervised task, model selection is a key
bottleneck for OD (both algorithm and hyperparameter selection) without label
supervision. There is a long list of techniques to choose from -- both
classical algorithms and deep neural architectures -- and while several studies
report their hyperparameter sensitivity, the literature is quite slim on
unsupervised model selection -- limiting the effective use of OD in practice.
In this paper we present FoMo-0D, for zero/0-shot OD exploring a transformative
new direction that bypasses the hurdle of model selection altogether (!), thus
breaking new ground. The fundamental idea behind FoMo-0D is the Prior-data
Fitted Networks, recently introduced by Muller et al.(2022), which trains a
Transformer model on a large body of synthetically generated data from a prior
data distribution. In essence, FoMo-0D is a pretrained Foundation Model for
zero/0-shot OD on tabular data, which can directly predict the (outlier/inlier)
label of any test data at inference time, by merely a single forward pass --
making obsolete the need for choosing an algorithm/architecture, tuning its
associated hyperparameters, and even training any model parameters when given a
new OD dataset. Extensive experiments on 57 public benchmark datasets against
26 baseline methods show that FoMo-0D performs statistically no different from
the top 2nd baseline, while significantly outperforming the majority of the
baselines, with an average inference time of 7.7 ms per test sample.

摘要：離群值偵測 (OD) 擁有大量的文獻，因為它在環境監控、網路安全、金融和醫學等領域中發現了許多應用。作為一項本質上無監督的任務，模型選擇是 OD 的一個關鍵瓶頸（演算法和超參數選擇），沒有標籤監督。有許多技術可供選擇——包括傳統演算法和深度神經網路架構——儘管有幾項研究報告了它們的超參數敏感性，但文獻對於無監督模型選擇的討論相當少——限制了 OD 在實務中的有效使用。在本文中，我們提出了 FoMo-0D，用於零/0 次 OD，探索了一種全新的變革方向，它完全繞過了模型選擇的障礙（！），從而開闢了新的領域。FoMo-0D 背後的基本思想是先驗資料擬合網路，最近由 Muller 等人（2022 年）提出，它在從先驗資料分佈中合成的大量資料上訓練 Transformer 模型。從本質上講，FoMo-0D 是用於表格資料的零/0 次 OD 的預訓練基礎模型，它可以在推理時僅透過單次前向傳遞直接預測任何測試資料的（離群值/內群值）標籤——消除了在給定新的 OD 資料集時選擇演算法/架構、調整其相關超參數，甚至訓練任何模型參數的需要。在 57 個公共基準資料集上針對 26 種基準方法進行的廣泛實驗表明，FoMo-0D 在統計上與第二好的基準方法沒有差異，同時顯著優於大多數基準方法，每個測試樣本的平均推理時間為 7.7 毫秒。

##### **Interactive incremental learning of generalizable skills with local trajectory modulation**
2409.05655v1 by Markus Knauer, Alin Albu-Schäffer, Freek Stulp, João Silvério

The problem of generalization in learning from demonstration (LfD) has
received considerable attention over the years, particularly within the context
of movement primitives, where a number of approaches have emerged. Recently,
two important approaches have gained recognition. While one leverages
via-points to adapt skills locally by modulating demonstrated trajectories,
another relies on so-called task-parameterized models that encode movements
with respect to different coordinate systems, using a product of probabilities
for generalization. While the former are well-suited to precise, local
modulations, the latter aim at generalizing over large regions of the workspace
and often involve multiple objects. Addressing the quality of generalization by
leveraging both approaches simultaneously has received little attention. In
this work, we propose an interactive imitation learning framework that
simultaneously leverages local and global modulations of trajectory
distributions. Building on the kernelized movement primitives (KMP) framework,
we introduce novel mechanisms for skill modulation from direct human corrective
feedback. Our approach particularly exploits the concept of via-points to
incrementally and interactively 1) improve the model accuracy locally, 2) add
new objects to the task during execution and 3) extend the skill into regions
where demonstrations were not provided. We evaluate our method on a bearing
ring-loading task using a torque-controlled, 7-DoF, DLR SARA robot.

摘要：多年来，从示范（LfD）中学习的泛化问题一直受到相当大的关注，特别是在运动基本元素的背景下，其中出现了许多方法。最近，两种重要的方法获得了认可。虽然一种方法利用过渡点通过调节示范轨迹来局部调整技能，另一种方法则依赖于所谓的任务参数化模型，该模型使用概率乘积对不同坐标系中的运动进行编码以进行泛化。虽然前者非常适合精确的局部调制，但后者旨在对工作空间的大区域进行泛化，并且通常涉及多个对象。同时利用这两种方法来解决泛化质量的问题很少受到关注。在这项工作中，我们提出了一种交互式模仿学习框架，该框架同时利用轨迹分布的局部和全局调制。在核化运动基元（KMP）框架的基础上，我们引入了从直接的人类纠正反馈中进行技能调制的新机制。我们的方法特别利用了过渡点的概念，以增量和交互方式 1) 局部提高模型精度，2) 在执行期间向任务中添加新对象，以及 3) 将技能扩展到未提供演示的区域。我们使用扭矩控制的 7 自由度 DLR SARA 机器人在轴承装载任务上评估了我们的方法。

##### **Revisiting English Winogender Schemas for Consistency, Coverage, and Grammatical Case**
2409.05653v1 by Vagrant Gautam, Julius Steuer, Eileen Bingert, Ray Johns, Anne Lauscher, Dietrich Klakow

While measuring bias and robustness in coreference resolution are important
goals, such measurements are only as good as the tools we use to measure them
with. Winogender schemas (Rudinger et al., 2018) are an influential dataset
proposed to evaluate gender bias in coreference resolution, but a closer look
at the data reveals issues with the instances that compromise their use for
reliable evaluation, including treating different grammatical cases of pronouns
in the same way, violations of template constraints, and typographical errors.
We identify these issues and fix them, contributing a new dataset: Winogender
2.0. Our changes affect performance with state-of-the-art supervised
coreference resolution systems as well as all model sizes of the language model
FLAN-T5, with F1 dropping on average 0.1 points. We also propose a new method
to evaluate pronominal bias in coreference resolution that goes beyond the
binary. With this method and our new dataset which is balanced for grammatical
case, we empirically demonstrate that bias characteristics vary not just across
pronoun sets, but also across surface forms of those sets.

摘要：雖然衡量共指解析中的偏差和穩健性是很重要的目標，但這些衡量標準僅與我們用來衡量它們的工具一樣好。Winogender 架構（Rudinger 等人，2018 年）是一個有影響力的資料集，用於評估共指解析中的性別偏差，但仔細檢視資料後，會發現實例中有問題，影響了它們用於可靠評估的方式，包括以相同的方式處理代名詞的不同語法情況、違反範本約束和印刷錯誤。我們找出這些問題並修復它們，並提供一個新的資料集：Winogender 2.0。我們的變更影響了最先進的監督共指解析系統以及語言模型 FLAN-T5 的所有模型大小，F1 平均下降 0.1 分。我們還提出一個新的方法來評估共指解析中的代名詞偏差，超越二元。透過這個方法和我們新的資料集（針對語法案例進行平衡），我們實證證明，偏差特徵不僅在代名詞組之間有所不同，在這些組的表面形式之間也有所不同。

##### **Replay Consolidation with Label Propagation for Continual Object Detection**
2409.05650v1 by Riccardo De Monte, Davide Dalle Pezze, Marina Ceccon, Francesco Pasti, Francesco Paissan, Elisabetta Farella, Gian Antonio Susto, Nicola Bellotto

Object Detection is a highly relevant computer vision problem with many
applications such as robotics and autonomous driving. Continual Learning~(CL)
considers a setting where a model incrementally learns new information while
retaining previously acquired knowledge. This is particularly challenging since
Deep Learning models tend to catastrophically forget old knowledge while
training on new data. In particular, Continual Learning for Object
Detection~(CLOD) poses additional difficulties compared to CL for
Classification. In CLOD, images from previous tasks may contain unknown classes
that could reappear labeled in future tasks. These missing annotations cause
task interference issues for replay-based approaches. As a result, most works
in the literature have focused on distillation-based approaches. However, these
approaches are effective only when there is a strong overlap of classes across
tasks. To address the issues of current methodologies, we propose a novel
technique to solve CLOD called Replay Consolidation with Label Propagation for
Object Detection (RCLPOD). Based on the replay method, our solution avoids task
interference issues by enhancing the buffer memory samples. Our method is
evaluated against existing techniques in CLOD literature, demonstrating its
superior performance on established benchmarks like VOC and COCO.

摘要：物件偵測是一個高度相關的電腦視覺問題，在機器人和自動駕駛等許多應用中都有應用。持續學習~(CL)考量一個模型漸進學習新資訊的設定，同時保留先前獲得的知識。這特別具有挑戰性，因為深度學習模型在訓練新資料時往往會災難性地遺忘舊知識。特別是，與用於分類的 CL 相比，用於物件偵測的持續學習~(CLOD)會帶來額外的困難。在 CLOD 中，來自先前任務的影像可能包含未知類別，這些類別可能會在未來的任務中再次出現標籤。這些遺失的註解會為基於重播的方法造成任務干擾問題。因此，文獻中大多數作品都專注於基於蒸餾的方法。然而，這些方法僅在任務之間有高度重疊的類別時才有效。為了解決當前方法的問題，我們提出了一種新的技術來解決 CLOD，稱為物件偵測的標籤傳播重播整合 (RCLPOD)。我們的解決方案基於重播方法，透過增強緩衝記憶體樣本來避免任務干擾問題。我們的模型針對 CLOD 文獻中現有的技術進行評估，證明其在 VOC 和 COCO 等既定基準上的優異效能。

##### **3D-SAR Tomography and Machine Learning for High-Resolution Tree Height Estimation**
2409.05636v1 by Grace Colverd, Jumpei Takami, Laura Schade, Karol Bot, Joseph A. Gallego-Mejia

Accurately estimating forest biomass is crucial for global carbon cycle
modelling and climate change mitigation. Tree height, a key factor in biomass
calculations, can be measured using Synthetic Aperture Radar (SAR) technology.
This study applies machine learning to extract forest height data from two SAR
products: Single Look Complex (SLC) images and tomographic cubes, in
preparation for the ESA Biomass Satellite mission. We use the TomoSense
dataset, containing SAR and LiDAR data from Germany's Eifel National Park, to
develop and evaluate height estimation models. Our approach includes classical
methods, deep learning with a 3D U-Net, and Bayesian-optimized techniques. By
testing various SAR frequencies and polarimetries, we establish a baseline for
future height and biomass modelling. Best-performing models predict forest
height to be within 2.82m mean absolute error for canopies around 30m,
advancing our ability to measure global carbon stocks and support climate
action.

摘要：準確估計森林生物量對於全球碳循環建模和氣候變遷緩解至關重要。樹高是生物量計算中的關鍵因素，可以使用合成孔徑雷達 (SAR) 技術來測量。本研究應用機器學習從兩個 SAR 產品中萃取出森林高度資料：單視複數 (SLC) 影像和層析立方體，以準備歐空局生物量衛星任務。我們使用包含來自德國艾菲爾國家公園的 SAR 和 LiDAR 資料的 TomoSense 資料集，來開發和評估高度估計模型。我們的做法包括經典方法、使用 3D U-Net 的深度學習，以及貝氏最佳化技術。透過測試各種 SAR 頻率和極化測量，我們為未來的樹高和生物量建模建立基準。表現最佳的模型預測森林高度在 30 公尺左右的樹冠誤差在 2.82 公尺平均絕對誤差內，提升了我們測量全球碳儲量和支持氣候行動的能力。

##### **Adapted-MoE: Mixture of Experts with Test-Time Adaption for Anomaly Detection**
2409.05611v1 by Tianwu Lei, Silin Chen, Bohan Wang, Zhengkai Jiang, Ningmu Zou

Most unsupervised anomaly detection methods based on representations of
normal samples to distinguish anomalies have recently made remarkable progress.
However, existing methods only learn a single decision boundary for
distinguishing the samples within the training dataset, neglecting the
variation in feature distribution for normal samples even in the same category
in the real world. Furthermore, it was not considered that a distribution bias
still exists between the test set and the train set. Therefore, we propose an
Adapted-MoE which contains a routing network and a series of expert models to
handle multiple distributions of same-category samples by divide and conquer.
Specifically, we propose a routing network based on representation learning to
route same-category samples into the subclasses feature space. Then, a series
of expert models are utilized to learn the representation of various normal
samples and construct several independent decision boundaries. We propose the
test-time adaption to eliminate the bias between the unseen test sample
representation and the feature distribution learned by the expert model. Our
experiments are conducted on a dataset that provides multiple subclasses from
three categories, namely Texture AD benchmark. The Adapted-MoE significantly
improves the performance of the baseline model, achieving 2.18%-7.20% and
1.57%-16.30% increase in I-AUROC and P-AUROC, which outperforms the current
state-of-the-art methods. Our code is available at https://github.com/.

摘要：<paragraph>大多數基於正常樣本表示的無監督異常檢測方法，用於區分異常值，最近取得了顯著進展。
然而，現有方法只學習一個決策邊界，用於區分訓練資料集中的樣本，忽略了即使在現實世界中同一類別中正常樣本的特徵分佈的變化。此外，它沒有考慮到測試集和訓練集之間仍然存在分佈偏差。因此，我們提出了一個適應性混合專家模型，其中包含一個路由網路和一系列專家模型，通過分而治之來處理同一類別樣本的多個分佈。
具體來說，我們提出一個基於表示學習的路由網路，將同一類別的樣本路由到子類特徵空間。然後，利用一系列專家模型來學習各種正常樣本的表示，並構造幾個獨立的決策邊界。我們提出測試時適應，以消除未見測試樣本表示和專家模型學習的特徵分佈之間的偏差。我們的實驗是在一個提供三個類別的多個子類的資料集上進行的，即 Texture AD 基準。適應性混合專家模型顯著提高了基線模型的效能，在 I-AUROC 和 P-AUROC 中分別提高了 2.18%-7.20% 和 1.57%-16.30%，優於目前的先進方法。我們的程式碼可以在 https://github.com/ 獲得。</paragraph>

##### **Longer is (Not Necessarily) Stronger: Punctuated Long-Sequence Training for Enhanced Speech Recognition and Translation**
2409.05601v1 by Nithin Rao Koluguri, Travis Bartley, Hainan Xu, Oleksii Hrinchuk, Jagadeesh Balam, Boris Ginsburg, Georg Kucsko

This paper presents a new method for training sequence-to-sequence models for
speech recognition and translation tasks. Instead of the traditional approach
of training models on short segments containing only lowercase or partial
punctuation and capitalization (PnC) sentences, we propose training on longer
utterances that include complete sentences with proper punctuation and
capitalization. We achieve this by using the FastConformer architecture which
allows training 1 Billion parameter models with sequences up to 60 seconds long
with full attention. However, while training with PnC enhances the overall
performance, we observed that accuracy plateaus when training on sequences
longer than 40 seconds across various evaluation settings. Our proposed method
significantly improves punctuation and capitalization accuracy, showing a 25%
relative word error rate (WER) improvement on the Earnings-21 and Earnings-22
benchmarks. Additionally, training on longer audio segments increases the
overall model accuracy across speech recognition and translation benchmarks.
The model weights and training code are open-sourced though NVIDIA NeMo.

摘要：本文提出了一個新的方法來訓練序列到序列模型，以進行語音辨識和翻譯任務。我們建議在包含完整句子、適當標點符號和大寫字母 (PnC) 的較長語句中進行訓練，而不是使用傳統方法在僅包含小寫字母或部分標點符號和大小寫字母的短區段上訓練模型。我們透過使用 FastConformer 架構來達成此目標，該架構允許使用長達 60 秒的序列訓練 10 億個參數模型，並具有完全的注意力。然而，雖然使用 PnC 進行訓練會增強整體效能，但我們觀察到在各種評估設定中，當在長於 40 秒的序列上進行訓練時，準確度會達到平穩期。我們提出的方法顯著改善了標點符號和大寫字母的準確度，在 Earnings-21 和 Earnings-22 基準上顯示出 25% 的相對字元錯誤率 (WER) 改進。此外，在較長的音訊區段上進行訓練會提高語音辨識和翻譯基準上的整體模型準確度。模型權重和訓練程式碼透過 NVIDIA NeMo 開源。

##### **ExDDI: Explaining Drug-Drug Interaction Predictions with Natural Language**
2409.05592v1 by Zhaoyue Sun, Jiazheng Li, Gabriele Pergola, Yulan He

Predicting unknown drug-drug interactions (DDIs) is crucial for improving
medication safety. Previous efforts in DDI prediction have typically focused on
binary classification or predicting DDI categories, with the absence of
explanatory insights that could enhance trust in these predictions. In this
work, we propose to generate natural language explanations for DDI predictions,
enabling the model to reveal the underlying pharmacodynamics and
pharmacokinetics mechanisms simultaneously as making the prediction. To do
this, we have collected DDI explanations from DDInter and DrugBank and
developed various models for extensive experiments and analysis. Our models can
provide accurate explanations for unknown DDIs between known drugs. This paper
contributes new tools to the field of DDI prediction and lays a solid
foundation for further research on generating explanations for DDI predictions.

摘要：預測未知的藥物交互作用 (DDI) 對於改善藥物安全至關重要。先前在 DDI 預測方面所做的努力通常集中於二元分類或預測 DDI 類別，而缺乏能夠增強這些預測的可信度的解釋性見解。在這項工作中，我們建議為 DDI 預測產生自然語言解釋，使模型能夠同時揭示藥效學和藥物動力學機制，並進行預測。為此，我們從 DDInter 和 DrugBank 收集了 DDI 解釋，並開發了各種模型進行廣泛的實驗和分析。我們的模型可以為已知藥物之間未知的 DDI 提供準確的解釋。本文為 DDI 預測領域貢獻了新的工具，並為進一步研究 DDI 預測的解釋生成奠定了堅實的基礎。

##### **MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery**
2409.05591v1 by Hongjin Qian, Peitian Zhang, Zheng Liu, Kelong Mao, Zhicheng Dou

Retrieval-Augmented Generation (RAG) leverages retrieval tools to access
external databases, thereby enhancing the generation quality of large language
models (LLMs) through optimized context. However, the existing retrieval
methods are constrained inherently, as they can only perform relevance matching
between explicitly stated queries and well-formed knowledge, but unable to
handle tasks involving ambiguous information needs or unstructured knowledge.
Consequently, existing RAG systems are primarily effective for straightforward
question-answering tasks. In this work, we propose \textbf{MemoRAG}, a novel
retrieval-augmented generation paradigm empowered by long-term memory. MemoRAG
adopts a dual-system architecture. On the one hand, it employs a \textit{light
but long-range} LLM to form the global memory of database. Once a task is
presented, it generates draft answers, cluing the retrieval tools to locate
useful information within the database. On the other hand, it leverages an
\textit{expensive but expressive} LLM, which generates the ultimate answer
based on the retrieved information. Building on this general framework, we
further optimize MemoRAG's performance by enhancing its cluing mechanism and
memorization capacity. In our experiment, MemoRAG achieves superior performance
across a variety of evaluation tasks, including both complex ones where
conventional RAG fails and straightforward ones where RAG is commonly applied.

摘要：撷取增强式生成 (RAG) 运用撷取工具存取
外部资料库，藉由最佳化语境，进而提升大型语言
模型 (LLM) 的生成品质。然而，现有的撷取
方法本质上受到限制，因为它们只能在明确陈述的查询和完善的知识之间执行相关性比对，但无法
处理涉及模棱两可的信息需求或非结构化知识的任务。
因此，现有的 RAG 系统主要适用于直接的
问答任务。在这项工作中，我们提出 \textbf{MemoRAG}，一种由长期记忆赋能的新型撷取增强式生成范例。MemoRAG
采用双系统架构。一方面，它采用一个\textit{轻量但远距离} LLM 来形成资料库的全局记忆。一旦任务被提出，它会生成答案草稿，提示撷取工具在资料库中找到有用的信息。另一方面，它利用一个\textit{昂贵但具有表现力}的 LLM，根据撷取的信息生成最终答案。在此一般架构的基础上，我们进一步优化 MemoRAG 的效能，藉由增强其提示机制和记忆容量。在我们的实验中，MemoRAG 在各种评估任务中达到卓越的效能，包括传统 RAG 无法处理的复杂任务，以及 RAG 常被应用的直接任务。

##### **Latent 3D Brain MRI Counterfactual**
2409.05585v1 by Wei Peng, Tian Xia, Fabio De Sousa Ribeiro, Tomas Bosschieter, Ehsan Adeli, Qingyu Zhao, Ben Glocker, Kilian M. Pohl

The number of samples in structural brain MRI studies is often too small to
properly train deep learning models. Generative models show promise in
addressing this issue by effectively learning the data distribution and
generating high-fidelity MRI. However, they struggle to produce diverse,
high-quality data outside the distribution defined by the training data. One
way to address the issue is using causal models developed for 3D volume
counterfactuals. However, accurately modeling causality in high-dimensional
spaces is a challenge so that these models generally generate 3D brain MRIS of
lower quality. To address these challenges, we propose a two-stage method that
constructs a Structural Causal Model (SCM) within the latent space. In the
first stage, we employ a VQ-VAE to learn a compact embedding of the MRI volume.
Subsequently, we integrate our causal model into this latent space and execute
a three-step counterfactual procedure using a closed-form Generalized Linear
Model (GLM). Our experiments conducted on real-world high-resolution MRI data
(1mm) demonstrate that our method can generate high-quality 3D MRI
counterfactuals.

摘要：結構性腦部 MRI 研究中的樣本數常常太小，無法適當地訓練深度學習模型。生成模型顯示出解決此問題的希望，方法是有效地學習資料分佈並產生高保真 MRI。然而，它們難以產生訓練資料所定義分佈之外的多樣化、高品質資料。解決此問題的方法之一是使用為 3D 體積反事實關係開發的因果模型。然而，在高維度空間中準確地建模因果關係是一項挑戰，因此這些模型通常會產生品質較低的 3D 腦部 MRI。為了解決這些挑戰，我們提出了一種兩階段方法，在潛在空間中建構結構因果模型 (SCM)。在第一階段，我們採用 VQ-VAE 來學習 MRI 體積的緊湊嵌入。隨後，我們將因果模型整合到這個潛在空間中，並使用閉合形式廣義線性模型 (GLM) 執行三步驟反事實程序。我們在真實世界的高解析度 MRI 資料 (1mm) 上進行的實驗證明，我們的方法可以產生高品質的 3D MRI 反事實關係。

##### **Spatially-Aware Speaker for Vision-and-Language Navigation Instruction Generation**
2409.05583v1 by Muraleekrishna Gopinathan, Martin Masek, Jumana Abu-Khalaf, David Suter

Embodied AI aims to develop robots that can \textit{understand} and execute
human language instructions, as well as communicate in natural languages. On
this front, we study the task of generating highly detailed navigational
instructions for the embodied robots to follow. Although recent studies have
demonstrated significant leaps in the generation of step-by-step instructions
from sequences of images, the generated instructions lack variety in terms of
their referral to objects and landmarks. Existing speaker models learn
strategies to evade the evaluation metrics and obtain higher scores even for
low-quality sentences. In this work, we propose SAS (Spatially-Aware Speaker),
an instruction generator or \textit{Speaker} model that utilises both
structural and semantic knowledge of the environment to produce richer
instructions. For training, we employ a reward learning method in an
adversarial setting to avoid systematic bias introduced by language evaluation
metrics. Empirically, our method outperforms existing instruction generation
models, evaluated using standard metrics. Our code is available at
\url{https://github.com/gmuraleekrishna/SAS}.

摘要：具身 AI 旨在开发能够理解和执行人类语言指令，以及使用自然语言进行交流的机器人。在这一方面，我们研究了为具身机器人生成高度详细的导航指令的任务。尽管最近的研究表明，从一系列图像生成分步指令方面取得了重大进展，但生成的指令在对物体和地标的引用方面缺乏多样性。现有的说话者模型学习策略来规避评估指标，即使对于低质量的句子也能获得更高的分数。在这项工作中，我们提出了 SAS（空间感知说话者），这是一种指令生成器或说话者模型，它利用环境的结构和语义知识来生成更丰富的指令。对于训练，我们在对抗环境中采用奖励学习方法，以避免语言评估指标引入的系统偏差。根据经验证据，我们的方法优于现有的指令生成模型，使用标准指标进行评估。我们的代码可在 \url{https://github.com/gmuraleekrishna/SAS} 获得。

##### **Learning to Model Graph Structural Information on MLPs via Graph Structure Self-Contrasting**
2409.05573v1 by Lirong Wu, Haitao Lin, Guojiang Zhao, Cheng Tan, Stan Z. Li

Recent years have witnessed great success in handling graph-related tasks
with Graph Neural Networks (GNNs). However, most existing GNNs are based on
message passing to perform feature aggregation and transformation, where the
structural information is explicitly involved in the forward propagation by
coupling with node features through graph convolution at each layer. As a
result, subtle feature noise or structure perturbation may cause severe error
propagation, resulting in extremely poor robustness. In this paper, we rethink
the roles played by graph structural information in graph data training and
identify that message passing is not the only path to modeling structural
information. Inspired by this, we propose a simple but effective Graph
Structure Self-Contrasting (GSSC) framework that learns graph structural
information without message passing. The proposed framework is based purely on
Multi-Layer Perceptrons (MLPs), where the structural information is only
implicitly incorporated as prior knowledge to guide the computation of
supervision signals, substituting the explicit message propagation as in GNNs.
Specifically, it first applies structural sparsification to remove potentially
uninformative or noisy edges in the neighborhood, and then performs structural
self-contrasting in the sparsified neighborhood to learn robust node
representations. Finally, structural sparsification and self-contrasting are
formulated as a bi-level optimization problem and solved in a unified
framework. Extensive experiments have qualitatively and quantitatively
demonstrated that the GSSC framework can produce truly encouraging performance
with better generalization and robustness than other leading competitors.

摘要：近年来，利用图神经网络 (GNN) 处理与图相关的任务取得了巨大的成功。然而，大多数现有的 GNN 都基于消息传递来执行特征聚合和转换，其中结构信息通过在每一层通过图卷积与节点特征耦合而明确地参与前向传播。因此，细微的特征噪声或结构扰动可能会导致严重的错误传播，从而导致极差的鲁棒性。在本文中，我们重新思考图结构信息在图数据训练中所扮演的角色，并确定消息传递并不是建模结构信息的唯一途径。受此启发，我们提出了一种简单但有效的图结构自对比 (GSSC) 框架，该框架可以在不进行消息传递的情况下学习图结构信息。所提出的框架完全基于多层感知器 (MLP)，其中结构信息仅作为先验知识隐式合并，以指导监督信号的计算，从而取代了 GNN 中明确的消息传播。具体来说，它首先应用结构稀疏化以去除邻域中潜在的无信息或有噪声的边，然后在稀疏化邻域中执行结构自对比以学习鲁棒的节点表示。最后，结构稀疏化和自对比被表述为一个双层优化问题，并在一个统一的框架中求解。大量实验已经定性和定量地证明，GSSC 框架可以产生真正令人鼓舞的性能，并且比其他领先的竞争对手具有更好的泛化性和鲁棒性。

##### **LEROjD: Lidar Extended Radar-Only Object Detection**
2409.05564v1 by Patrick Palmer, Martin Krüger, Stefan Schütte, Richard Altendorfer, Ganesh Adam, Torsten Bertram

Accurate 3D object detection is vital for automated driving. While lidar
sensors are well suited for this task, they are expensive and have limitations
in adverse weather conditions. 3+1D imaging radar sensors offer a
cost-effective, robust alternative but face challenges due to their low
resolution and high measurement noise. Existing 3+1D imaging radar datasets
include radar and lidar data, enabling cross-modal model improvements. Although
lidar should not be used during inference, it can aid the training of
radar-only object detectors. We explore two strategies to transfer knowledge
from the lidar to the radar domain and radar-only object detectors: 1.
multi-stage training with sequential lidar point cloud thin-out, and 2.
cross-modal knowledge distillation. In the multi-stage process, three thin-out
methods are examined. Our results show significant performance gains of up to
4.2 percentage points in mean Average Precision with multi-stage training and
up to 3.9 percentage points with knowledge distillation by initializing the
student with the teacher's weights. The main benefit of these approaches is
their applicability to other 3D object detection networks without altering
their architecture, as we show by analyzing it on two different object
detectors. Our code is available at https://github.com/rst-tu-dortmund/lerojd

摘要：精確的 3D 物件偵測對於自動駕駛至關重要。儘管雷達感測器非常適合這項任務，但它們價格昂貴，且在惡劣的天氣條件下有其限制。3+1D 影像雷達感測器提供了具有成本效益且強健的替代方案，但由於它們的低解析度和高量測雜訊而面臨挑戰。現有的 3+1D 影像雷達資料集包含雷達和雷射雷達資料，可進行跨模態模型改善。儘管雷射雷達不應在推論期間使用，但它可以協助訓練僅限雷達的物件偵測器。我們探討了將知識從雷射雷達傳輸到雷達域和僅限雷達的物件偵測器的兩種策略：1. 使用循序雷射雷達點雲細化進行多階段訓練，以及 2. 跨模態知識萃取。在多階段過程中，檢查了三種細化方法。我們的結果顯示，在平均精準度方面，多階段訓練的效能顯著提升了 4.2 個百分點，而透過使用教師的權重來初始化學生，知識萃取的效能則提升了 3.9 個百分點。這些方法的主要好處是它們適用於其他 3D 物件偵測網路，而無需改變其架構，正如我們在兩個不同的物件偵測器上分析所顯示的那樣。我們的程式碼可在 https://github.com/rst-tu-dortmund/lerojd 取得

##### **CauseJudger: Identifying the Cause with LLMs for Abductive Logical Reasoning**
2409.05559v1 by Jinwei He, Feng Lu

Large language models (LLMs) have been utilized in solving diverse reasoning
tasks, encompassing common sense, arithmetic and deduction tasks. However, with
difficulties of reversing thinking patterns and irrelevant premises, how to
determine the authenticity of the cause in abductive logical reasoning remains
underexplored. Inspired by hypothesis and verification method and
identification of irrelevant information in human thinking process, we propose
a new framework for LLMs abductive logical reasoning called CauseJudger (CJ),
which identifies the authenticity of possible cause by transforming thinking
from reverse to forward and removing irrelevant information. In addition, we
construct an abductive logical reasoning dataset for decision task called
CauseLogics, which contains 200,000 tasks of varying reasoning lengths. Our
experiments show the efficiency of CJ with overall experiments and ablation
experiments as well as case studies on our dataset and reconstructed public
dataset. Notably, CJ's implementation is efficient, requiring only two calls to
LLM. Its impact is profound: when using gpt-3.5, CJ achieves a maximum
correctness improvement of 41% compared to Zero-Shot-CoT. Moreover, with gpt-4,
CJ attains an accuracy exceeding 90% across all datasets.

摘要：大型語言模型 (LLM) 已用於解決各種推理任務，包括常識、算術和演繹任務。然而，由於逆向思維模式和無關前提的困難，如何確定演繹邏輯推理中原因的真實性仍未得到充分探討。受假設和驗證方法以及人類思維過程中無關信息的識別啟發，我們提出了一個新的 LLM 演繹邏輯推理框架，稱為 CauseJudger (CJ)，它通過將思維從逆向轉換為正向並刪除無關信息來識別可能原因的真實性。此外，我們構建了一個用於決策任務的演繹邏輯推理數據集，稱為 CauseLogics，其中包含 200,000 個不同推理長度的任務。我們的實驗通過整體實驗和消融實驗以及我們數據集和重建的公共數據集的案例研究展示了 CJ 的效率。值得注意的是，CJ 的實現是高效的，只需要調用 LLM 兩次。它的影響是深遠的：當使用 gpt-3.5 時，與 Zero-Shot-CoT 相比，CJ 的正確率最高提升了 41%。此外，使用 gpt-4，CJ 在所有數據集上的準確率都超過了 90%。

##### **Seeing Through the Mask: Rethinking Adversarial Examples for CAPTCHAs**
2409.05558v1 by Yahya Jabary, Andreas Plesner, Turlan Kuzhagaliyev, Roger Wattenhofer

Modern CAPTCHAs rely heavily on vision tasks that are supposedly hard for
computers but easy for humans. However, advances in image recognition models
pose a significant threat to such CAPTCHAs. These models can easily be fooled
by generating some well-hidden "random" noise and adding it to the image, or
hiding objects in the image. However, these methods are model-specific and thus
can not aid CAPTCHAs in fooling all models. We show in this work that by
allowing for more significant changes to the images while preserving the
semantic information and keeping it solvable by humans, we can fool many
state-of-the-art models. Specifically, we demonstrate that by adding masks of
various intensities the Accuracy @ 1 (Acc@1) drops by more than 50%-points for
all models, and supposedly robust models such as vision transformers see an
Acc@1 drop of 80%-points.
  These masks can therefore effectively fool modern image classifiers, thus
showing that machines have not caught up with humans -- yet.

摘要：現代 CAPTCHA 嚴重依賴於視覺任務，這對電腦來說很困難，但對人類來說卻很容易。然而，影像辨識模型的進步對此類 CAPTCHA 構成重大威脅。這些模型很容易被產生一些隱藏良好的「隨機」雜訊並將其加入影像，或將物件隱藏在影像中所愚弄。然而，這些方法特定於模型，因此無法幫助 CAPTCHA 愚弄所有模型。我們在此工作中展示，透過允許對影像進行更顯著的變更，同時保留語意資訊並保持人類可以解決，我們可以愚弄許多最先進的模型。具體來說，我們證明透過加入各種強度遮罩，所有模型的準確率 @ 1 (Acc@1) 下降超過 50%，而據稱強健的模型，例如視覺轉換器，其準確率 @ 1 下降 80%。因此，這些遮罩可以有效愚弄現代影像分類器，從而表明機器尚未趕上人類——至少目前還沒有。

##### **SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning**
2409.05556v1 by Alireza Ghafarollahi, Markus J. Buehler

A key challenge in artificial intelligence is the creation of systems capable
of autonomously advancing scientific understanding by exploring novel domains,
identifying complex patterns, and uncovering previously unseen connections in
vast scientific data. In this work, we present SciAgents, an approach that
leverages three core concepts: (1) the use of large-scale ontological knowledge
graphs to organize and interconnect diverse scientific concepts, (2) a suite of
large language models (LLMs) and data retrieval tools, and (3) multi-agent
systems with in-situ learning capabilities. Applied to biologically inspired
materials, SciAgents reveals hidden interdisciplinary relationships that were
previously considered unrelated, achieving a scale, precision, and exploratory
power that surpasses traditional human-driven research methods. The framework
autonomously generates and refines research hypotheses, elucidating underlying
mechanisms, design principles, and unexpected material properties. By
integrating these capabilities in a modular fashion, the intelligent system
yields material discoveries, critique and improve existing hypotheses, retrieve
up-to-date data about existing research, and highlights their strengths and
limitations. Our case studies demonstrate scalable capabilities to combine
generative AI, ontological representations, and multi-agent modeling,
harnessing a `swarm of intelligence' similar to biological systems. This
provides new avenues for materials discovery and accelerates the development of
advanced materials by unlocking Nature's design principles.

摘要：在人工智能中，一個關鍵的挑戰是創造出有能力透過探索新領域、識別複雜模式，以及在大量的科學數據中發現前所未見的關聯，來自主推進科學理解的系統。在這項工作中，我們提出了 SciAgents，一種利用三個核心概念的方法：(1) 使用大規模的本体知識圖譜來整理和連結不同的科學概念，(2) 一套大型語言模型 (LLM) 和數據檢索工具，以及 (3) 具有原位學習能力的多代理系統。應用於生物啟發材料，SciAgents 揭示了以前被認為無關的隱藏跨學科關係，達到了超越傳統人為研究方法的規模、精確度和探索能力。該框架自主生成和優化研究假設，闡明基礎機制、設計原理和意外的材料特性。透過以模組化方式整合這些能力，智能系統產生材料發現、批判和改進現有假設、檢索關於現有研究的最新數據，並強調它們的優點和限制。我們的案例研究展示了結合生成式 AI、本体表示和多代理建模的可擴充能力，利用類似於生物系統的「智慧群體」。這為材料發現提供了新途徑，並透過解鎖大自然的設計原理來加速先進材料的開發。

##### **HMAFlow: Learning More Accurate Optical Flow via Hierarchical Motion Field Alignment**
2409.05531v1 by Dianbo Ma, Kousuke Imamura, Ziyan Gao, Xiangjie Wang, Satoshi Yamane

Optical flow estimation is a fundamental and long-standing visual task. In
this work, we present a novel method, dubbed HMAFlow, to improve optical flow
estimation in these tough scenes, especially with small objects. The proposed
model mainly consists of two core components: a Hierarchical Motion Field
Alignment (HMA) module and a Correlation Self-Attention (CSA) module. In
addition, we rebuild 4D cost volumes by employing a Multi-Scale Correlation
Search (MCS) layer and replacing average pooling in common cost volumes with an
search strategy using multiple search ranges. Experimental results demonstrate
that our model achieves the best generalization performance in comparison to
other state-of-the-art methods. Specifically, compared with RAFT, our method
achieves relative error reductions of 14.2% and 3.4% on the clean pass and
final pass of the Sintel online benchmark, respectively. On the KITTI test
benchmark, HMAFlow surpasses RAFT and GMA in the Fl-all metric by a relative
margin of 6.8% and 7.7%, respectively. To facilitate future research, our code
will be made available at https://github.com/BooTurbo/HMAFlow.

摘要：光流估計是一個基本且長久存在的視覺任務。在這項工作中，我們提出了一種新方法，稱為 HMAFlow，以改善這些困難場景中的光流估計，特別是對於小物件。所提出的模型主要包含兩個核心組成部分：分層運動場對齊 (HMA) 模組和相關性自我注意 (CSA) 模組。此外，我們通過使用多尺度相關性搜尋 (MCS) 層並以使用多重搜尋範圍的搜尋策略取代常見成本體積中的平均池化來重建 4D 成本體積。實驗結果表明，與其他最先進的方法相比，我們的模型達到了最佳的泛化效能。具體來說，與 RAFT 相比，我們的模型分別在 Sintel 線上基準測試的乾淨通道和最終通道上實現了 14.2% 和 3.4% 的相對誤差降低。在 KITTI 測試基準測試中，HMAFlow 在 Fl-all 指標上分別以 6.8% 和 7.7% 的相對幅度超越了 RAFT 和 GMA。為了促進未來的研究，我們的程式碼將在 https://github.com/BooTurbo/HMAFlow 上提供。

##### **QiBERT -- Classifying Online Conversations Messages with BERT as a Feature**
2409.05530v1 by Bruno D. Ferreira-Saraiva, Zuil Pirola, João P. Matos-Carvalho, Manuel Marques-Pita

Recent developments in online communication and their usage in everyday life
have caused an explosion in the amount of a new genre of text data, short text.
Thus, the need to classify this type of text based on its content has a
significant implication in many areas. Online debates are no exception, once
these provide access to information about opinions, positions and preferences
of its users. This paper aims to use data obtained from online social
conversations in Portuguese schools (short text) to observe behavioural trends
and to see if students remain engaged in the discussion when stimulated. This
project used the state of the art (SoA) Machine Learning (ML) algorithms and
methods, through BERT based models to classify if utterances are in or out of
the debate subject. Using SBERT embeddings as a feature, with supervised
learning, the proposed model achieved results above 0.95 average accuracy for
classifying online messages. Such improvements can help social scientists
better understand human communication, behaviour, discussion and persuasion.

摘要：網路溝通的最新發展及其在日常生活中使用，已導致一種新型態的文字資料「簡短文字」數量激增。因此，根據內容對這種類型的文字進行分類的需求，在許多領域都有重要的影響。網路上的辯論也不例外，它們一經提供有關其使用者意見、立場和偏好的資訊，就可以存取。本文旨在使用從葡萄牙學校的網路社交對話（簡短文字）中獲得的資料來觀察行為趨勢，並了解在受到刺激時，學生是否仍然參與討論。此專案使用最先進（SoA）機器學習（ML）演算法和方法，透過基於 BERT 的模型來分類發言是否在辯論主題中或不在辯論主題中。使用 SBERT 嵌入作為特徵，透過監督式學習，所提出的模型在分類網路訊息方面達到了 0.95 以上的平均準確度。此類改進有助於社會科學家更了解人類溝通、行為、討論和說服。

##### **Harmonic Reasoning in Large Language Models**
2409.05521v1 by Anna Kruspe

Large Language Models (LLMs) are becoming very popular and are used for many
different purposes, including creative tasks in the arts. However, these models
sometimes have trouble with specific reasoning tasks, especially those that
involve logical thinking and counting. This paper looks at how well LLMs
understand and reason when dealing with musical tasks like figuring out notes
from intervals and identifying chords and scales. We tested GPT-3.5 and GPT-4o
to see how they handle these tasks. Our results show that while LLMs do well
with note intervals, they struggle with more complicated tasks like recognizing
chords and scales. This points out clear limits in current LLM abilities and
shows where we need to make them better, which could help improve how they
think and work in both artistic and other complex areas. We also provide an
automatically generated benchmark data set for the described tasks.

摘要：大型語言模型 (LLM) 正變得非常流行，並用於許多不同的目的，包括藝術中的創作任務。然而，這些模型有時在特定的推理任務中會遇到問題，特別是那些涉及邏輯思考和計算的任務。本文探討了 LLM 在處理音樂任務（例如從音程找出音符，並識別和弦和音階）時，其理解和推理能力如何。我們測試了 GPT-3.5 和 GPT-4o，以了解它們如何處理這些任務。我們的結果顯示，雖然 LLM 在音程方面表現良好，但它們在識別和弦和音階等更複雜的任務中卻會遇到困難。這指出了當前 LLM 能力的明顯限制，並顯示了我們需要在哪些方面讓它們變得更好，這有助於改善它們在藝術和其他複雜領域的思考和工作方式。我們還提供了針對所述任務自動生成的基準資料集。

##### **Elsevier Arena: Human Evaluation of Chemistry/Biology/Health Foundational Large Language Models**
2409.05486v1 by Camilo Thorne, Christian Druckenbrodt, Kinga Szarkowska, Deepika Goyal, Pranita Marajan, Vijay Somanath, Corey Harper, Mao Yan, Tony Scerri

The quality and capabilities of large language models cannot be currently
fully assessed with automated, benchmark evaluations. Instead, human
evaluations that expand on traditional qualitative techniques from natural
language generation literature are required. One recent best-practice consists
in using A/B-testing frameworks, which capture preferences of human evaluators
for specific models. In this paper we describe a human evaluation experiment
focused on the biomedical domain (health, biology, chemistry/pharmacology)
carried out at Elsevier. In it a large but not massive (8.8B parameter)
decoder-only foundational transformer trained on a relatively small (135B
tokens) but highly curated collection of Elsevier datasets is compared to
OpenAI's GPT-3.5-turbo and Meta's foundational 7B parameter Llama 2 model
against multiple criteria. Results indicate -- even if IRR scores were
generally low -- a preference towards GPT-3.5-turbo, and hence towards models
that possess conversational abilities, are very large and were trained on very
large datasets. But at the same time, indicate that for less massive models
training on smaller but well-curated training sets can potentially give rise to
viable alternatives in the biomedical domain.

摘要：大型語言模型的品質和能力目前無法使用自動化基準評估來完全評估。相反，需要使用擴展自然語言生成文獻中傳統定性技術的人類評估。一個最近的最佳實務是使用 A/B 測試框架，該框架會擷取人類評估者對特定模型的偏好。在本文中，我們描述了專注於生物醫學領域（健康、生物學、化學/藥理學）的人類評估實驗，該實驗在 Elsevier 進行。其中，一個大型但並非龐大（8.8B 參數）僅解碼器基礎Transformer在相對較小（135B 令牌）但經過高度策展的 Elsevier 資料集上訓練，與 OpenAI 的 GPT-3.5-turbo 和 Meta 的基礎 7B 參數 Llama 2 模型進行比較，針對多個標準。結果表明——即使 IRR 分數普遍較低——偏好 GPT-3.5-turbo，因此偏好具備對話能力、非常龐大且在非常龐大的資料集上訓練的模型。但同時，表明對於較小規模的模型，在較小但經過良好策展的訓練集上訓練，有可能在生物醫學領域產生可行的替代方案。

##### **CRADLE-VAE: Enhancing Single-Cell Gene Perturbation Modeling with Counterfactual Reasoning-based Artifact Disentanglement**
2409.05484v1 by Seungheun Baek, Soyon Park, Yan Ting Chok, Junhyun Lee, Jueon Park, Mogan Gim, Jaewoo Kang

Predicting cellular responses to various perturbations is a critical focus in
drug discovery and personalized therapeutics, with deep learning models playing
a significant role in this endeavor. Single-cell datasets contain technical
artifacts that may hinder the predictability of such models, which poses
quality control issues highly regarded in this area. To address this, we
propose CRADLE-VAE, a causal generative framework tailored for single-cell gene
perturbation modeling, enhanced with counterfactual reasoning-based artifact
disentanglement. Throughout training, CRADLE-VAE models the underlying latent
distribution of technical artifacts and perturbation effects present in
single-cell datasets. It employs counterfactual reasoning to effectively
disentangle such artifacts by modulating the latent basal spaces and learns
robust features for generating cellular response data with improved quality.
Experimental results demonstrate that this approach improves not only treatment
effect estimation performance but also generative quality as well. The
CRADLE-VAE codebase is publicly available at
https://github.com/dmis-lab/CRADLE-VAE.

摘要：預測細胞對各種擾動的反應在藥物發現和個人化治療中是一個重要的重點，深度學習模型在這個努力中扮演著重要的角色。單細胞數據集包含可能阻礙此類模型可預測性的技術性人工製品，這對這個領域高度重視的品質控管議題構成挑戰。為了解決這個問題，我們提出 CRADLE-VAE，一個專為單細胞基因擾動建模量身打造的因果生成架構，並透過反事實推理為基礎的人工製品去糾纏而增強。在整個訓練過程中，CRADLE-VAE 對單細胞數據集中技術性人工製品和擾動效應的潛在分佈進行建模。它採用反事實推理，透過調整潛在基礎空間來有效地去糾纏這些人工製品，並學習強健特徵，以生成品質更好的細胞反應數據。實驗結果證明，這種方法不僅改善了治療效果估計的效能，也改善了生成品質。CRADLE-VAE 碼庫已公開於 https://github.com/dmis-lab/CRADLE-VAE。

##### **Representational Analysis of Binding in Large Language Models**
2409.05448v1 by Qin Dai, Benjamin Heinzerling, Kentaro Inui

Entity tracking is essential for complex reasoning. To perform in-context
entity tracking, language models (LMs) must bind an entity to its attribute
(e.g., bind a container to its content) to recall attribute for a given entity.
For example, given a context mentioning ``The coffee is in Box Z, the stone is
in Box M, the map is in Box H'', to infer ``Box Z contains the coffee'' later,
LMs must bind ``Box Z'' to ``coffee''. To explain the binding behaviour of LMs,
Feng and Steinhardt (2023) introduce a Binding ID mechanism and state that LMs
use a abstract concept called Binding ID (BI) to internally mark
entity-attribute pairs. However, they have not directly captured the BI
determinant information from entity activations. In this work, we provide a
novel view of the Binding ID mechanism by localizing the prototype of BI
information. Specifically, we discover that there exists a low-rank subspace in
the hidden state (or activation) of LMs, that primarily encodes the order of
entity and attribute and which is used as the prototype of BI to causally
determine the binding. To identify this subspace, we choose principle component
analysis as our first attempt and it is empirically proven to be effective.
Moreover, we also discover that when editing representations along directions
in the subspace, LMs tend to bind a given entity to other attributes
accordingly. For example, by patching activations along the BI encoding
direction we can make the LM to infer ``Box Z contains the stone'' and ``Box Z
contains the map''.

摘要：實體追蹤對於複雜的推理至關重要。若要執行脈絡內實體追蹤，語言模型 (LM) 必須將實體繫結至其屬性（例如，將容器繫結至其內容），才能為特定實體提取屬性。例如，假設有一個脈絡提到「咖啡在 Z 盒子裡，石頭在 M 盒子裡，地圖在 H 盒子裡」，若要稍後推論出「Z 盒子裡有咖啡」，LM 必須將「Z 盒子」繫結至「咖啡」。為了說明 LM 的繫結行為，Feng 和 Steinhardt (2023) 引入繫結 ID 機制，並指出 LM 使用稱為繫結 ID (BI) 的抽象概念，在內部標記實體屬性配對。然而，他們並未直接從實體活化中擷取 BI 決定資訊。在這項工作中，我們透過定位 BI 資訊的原型，提供繫結 ID 機制的創新觀點。具體而言，我們發現 LM 的隱藏狀態（或活化）中存在一個低秩子空間，主要編碼實體和屬性的順序，並用作 BI 的原型，以因果方式決定繫結。為了識別這個子空間，我們選擇主成分分析作為我們的第一次嘗試，並經實證證明其有效性。此外，我們還發現，當沿著子空間中的方向編輯表示時，LM 傾向於相應地將特定實體繫結至其他屬性。例如，透過修補沿著 BI 編碼方向的活化，我們可以讓 LM 推論出「Z 盒子裡有石頭」和「Z 盒子裡有地圖」。

##### **STLM Engineering Report: Dropout**
2409.05423v1 by Dylan Hillier, Leon Guertler, Bobby Cheng, Cheston Tan

In this work we explore the relevance of dropout for modern language models,
particularly in the context of models on the scale of <100M parameters. We
explore it's relevance firstly in the regime of improving the sample efficiency
of models given small, high quality datasets, and secondly in the regime of
improving the quality of its fit on larger datasets where models may underfit.
We find that concordant with conventional wisdom, dropout remains effective in
the overfitting scenario, and that furthermore it may have some relevance for
improving the fit of models even in the case of excess data, as suggested by
previous research. In the process we find that the existing explanation for the
mechanism behind this performance gain is not applicable in the case of
language modelling.

摘要：在這項工作中，我們探討了輟學對現代語言模型的相關性，特別是在模型規模為 <100M 參數的情況下。我們首先探討了它在提高模型在給定小型高品質資料集時的取樣效率方面的相關性，其次探討了它在提高模型在模型可能欠擬合的大型資料集上的擬合品質方面的相關性。我們發現，與傳統智慧一致，輟學在過度擬合場景中仍然有效，而且，正如先前的研究所建議，它可能與在資料過量的情況下提高模型擬合度有一定相關性。在這個過程中，我們發現，對於這種效能提升背後的機制，現有的解釋並不適用於語言建模的情況。

##### **AD-Net: Attention-based dilated convolutional residual network with guided decoder for robust skin lesion segmentation**
2409.05420v1 by Asim Naveed, Syed S. Naqvi, Tariq M. Khan, Shahzaib Iqbal, M. Yaqoob Wani, Haroon Ahmed Khan

In computer-aided diagnosis tools employed for skin cancer treatment and
early diagnosis, skin lesion segmentation is important. However, achieving
precise segmentation is challenging due to inherent variations in appearance,
contrast, texture, and blurry lesion boundaries. This research presents a
robust approach utilizing a dilated convolutional residual network, which
incorporates an attention-based spatial feature enhancement block (ASFEB) and
employs a guided decoder strategy. In each dilated convolutional residual
block, dilated convolution is employed to broaden the receptive field with
varying dilation rates. To improve the spatial feature information of the
encoder, we employed an attention-based spatial feature enhancement block in
the skip connections. The ASFEB in our proposed method combines feature maps
obtained from average and maximum-pooling operations. These combined features
are then weighted using the active outcome of global average pooling and
convolution operations. Additionally, we have incorporated a guided decoder
strategy, where each decoder block is optimized using an individual loss
function to enhance the feature learning process in the proposed AD-Net. The
proposed AD-Net presents a significant benefit by necessitating fewer model
parameters compared to its peer methods. This reduction in parameters directly
impacts the number of labeled data required for training, facilitating faster
convergence during the training process. The effectiveness of the proposed
AD-Net was evaluated using four public benchmark datasets. We conducted a
Wilcoxon signed-rank test to verify the efficiency of the AD-Net. The outcomes
suggest that our method surpasses other cutting-edge methods in performance,
even without the implementation of data augmentation strategies.

摘要：<paragraph>在用於皮膚癌治療和早期診斷的電腦輔助診斷工具中，皮膚病灶分割非常重要。然而，由於外觀、對比度、紋理和模糊的病灶邊界固有的變化，實現精確分割具有挑戰性。本研究提出了一種利用膨脹卷積殘差網路的穩健方法，該網路結合了一個基於注意力的空間特徵增強塊 (ASFEB) 並採用了一個引導式解碼器策略。在每個膨脹卷積殘差塊中，使用膨脹卷積來擴展感受野，並採用不同的膨脹率。為了改進編碼器的空間特徵資訊，我們在跳躍連接中採用了一個基於注意力的空間特徵增強塊。我們提出的方法中的 ASFEB 結合了從平均池化和最大池化操作中獲得的特徵映射。然後使用全局平均池化和卷積操作的積極結果對這些組合的特徵進行加權。此外，我們還納入了一個引導式解碼器策略，其中每個解碼器塊使用一個單獨的損失函數進行最佳化，以增強所提出的 AD-Net 中的特徵學習過程。與同類方法相比，所提出的 AD-Net 通過減少模型參數而呈現出顯著的優勢。參數的這種減少直接影響訓練所需的標記數據數量，從而促進訓練過程中的快速收斂。使用四個公共基準資料集評估了所提出的 AD-Net 的有效性。我們進行了 Wilcoxon 簽名秩檢驗以驗證 AD-Net 的效率。結果表明，即使沒有實施數據擴充策略，我們的模型在效能上也優於其他尖端模型。</paragraph>

##### **CipherDM: Secure Three-Party Inference for Diffusion Model Sampling**
2409.05414v1 by Xin Zhao, Xiaojun Chen, Xudong Chen, He Li, Tingyu Fan, Zhendong Zhao

Diffusion Models (DMs) achieve state-of-the-art synthesis results in image
generation and have been applied to various fields. However, DMs sometimes
seriously violate user privacy during usage, making the protection of privacy
an urgent issue. Using traditional privacy computing schemes like Secure
Multi-Party Computation (MPC) directly in DMs faces significant computation and
communication challenges. To address these issues, we propose CipherDM, the
first novel, versatile and universal framework applying MPC technology to DMs
for secure sampling, which can be widely implemented on multiple DM based
tasks. We thoroughly analyze sampling latency breakdown, find time-consuming
parts and design corresponding secure MPC protocols for computing nonlinear
activations including SoftMax, SiLU and Mish. CipherDM is evaluated on popular
architectures (DDPM, DDIM) using MNIST dataset and on SD deployed by diffusers.
Compared to direct implementation on SPU, our approach improves running time by
approximately 1.084\times \sim 2.328\times, and reduces communication costs by
approximately 1.212\times \sim 1.791\times.

摘要：擴散模型 (DM) 在影像生成中達成最先進的合成結果，並已應用於各種領域。然而，DM 有時在使用過程中嚴重侵犯使用者隱私，使得隱私保護成為一個迫切的問題。直接在 DM 中使用傳統的隱私運算方案，例如安全多方運算 (MPC)，會面臨重大的運算和通訊挑戰。為了解決這些問題，我們提出了 CipherDM，這是第一個新穎、通用且通用的框架，將 MPC 技術應用於 DM 以進行安全採樣，可以廣泛地實作於多個基於 DM 的任務。我們徹底分析了採樣延遲分解，找出耗時的部份，並設計相應的安全 MPC 協定來運算非線性激活，包括 SoftMax、SiLU 和 Mish。CipherDM 在使用 MNIST 資料集的熱門架構 (DDPM、DDIM) 和由 Diffusers 部署的 SD 上進行評估。與在 SPU 上的直接實作相比，我們的作法將執行時間改善了大約 1.084 倍到 2.328 倍，並將通訊成本降低了大約 1.212 倍到 1.791 倍。

##### **A Survey of Multimodal Composite Editing and Retrieval**
2409.05405v1 by Suyan Li, Fuxiang Huang, Lei Zhang

In the real world, where information is abundant and diverse across different
modalities, understanding and utilizing various data types to improve retrieval
systems is a key focus of research. Multimodal composite retrieval integrates
diverse modalities such as text, image and audio, etc. to provide more
accurate, personalized, and contextually relevant results. To facilitate a
deeper understanding of this promising direction, this survey explores
multimodal composite editing and retrieval in depth, covering image-text
composite editing, image-text composite retrieval, and other multimodal
composite retrieval. In this survey, we systematically organize the application
scenarios, methods, benchmarks, experiments, and future directions. Multimodal
learning is a hot topic in large model era, and have also witnessed some
surveys in multimodal learning and vision-language models with transformers
published in the PAMI journal. To the best of our knowledge, this survey is the
first comprehensive review of the literature on multimodal composite retrieval,
which is a timely complement of multimodal fusion to existing reviews. To help
readers' quickly track this field, we build the project page for this survey,
which can be found at
https://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval.

摘要：在真實世界中，資訊豐富且多元，跨越不同的形式，理解和利用各種資料類型來改善檢索系統是研究的主要重點。多模態複合檢索整合了文字、影像和音訊等多種模態，以提供更準確、個人化和與情境相關的結果。為了促進對這個有前途的方向有更深入的了解，本調查深入探討了多模態複合編輯和檢索，涵蓋了影像文字複合編輯、影像文字複合檢索，以及其他多模態複合檢索。在本調查中，我們系統性地整理了應用場景、方法、基準、實驗和未來方向。多模態學習是大模型時代的熱門話題，並且也見證了 PAMI 期刊上發表的一些關於多模態學習和具有Transformer的視覺語言模型的調查。據我們所知，本調查是對多模態複合檢索文獻的首次全面回顧，這對現有評論中的多模態融合是一個及時的補充。為了幫助讀者快速追蹤這個領域，我們建立了這個調查的專案頁面，可以在 https://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval 找到。

##### **HyperSMOTE: A Hypergraph-based Oversampling Approach for Imbalanced Node Classifications**
2409.05402v1 by Ziming Zhao, Tiehua Zhang, Zijian Yi, Zhishu Shen

Hypergraphs are increasingly utilized in both unimodal and multimodal data
scenarios due to their superior ability to model and extract higher-order
relationships among nodes, compared to traditional graphs. However, current
hypergraph models are encountering challenges related to imbalanced data, as
this imbalance can lead to biases in the model towards the more prevalent
classes. While the existing techniques, such as GraphSMOTE, have improved
classification accuracy for minority samples in graph data, they still fall
short when addressing the unique structure of hypergraphs. Inspired by SMOTE
concept, we propose HyperSMOTE as a solution to alleviate the class imbalance
issue in hypergraph learning. This method involves a two-step process:
initially synthesizing minority class nodes, followed by the nodes integration
into the original hypergraph. We synthesize new nodes based on samples from
minority classes and their neighbors. At the same time, in order to solve the
problem on integrating the new node into the hypergraph, we train a decoder
based on the original hypergraph incidence matrix to adaptively associate the
augmented node to hyperedges. We conduct extensive evaluation on multiple
single-modality datasets, such as Cora, Cora-CA and Citeseer, as well as
multimodal conversation dataset MELD to verify the effectiveness of HyperSMOTE,
showing an average performance gain of 3.38% and 2.97% on accuracy,
respectively.

摘要：超圖由於其相較於傳統圖形更優異的建模和提取節點間高階關係的能力，在單一模式和多模態數據場景中得到越來越廣泛的應用。然而，當前超圖模型在面對不平衡數據時會遇到挑戰，因為這種不平衡可能導致模型對較普遍的類別產生偏見。雖然現有的技術，例如 GraphSMOTE，已改善圖形數據中少數樣本的分類準確度，但它們在處理超圖的獨特結構時仍有不足。受 SMOTE 概念的啟發，我們提出 HyperSMOTE 作為解決超圖學習中類別不平衡問題的方案。此方法涉及一個兩步驟的過程：最初合成少數類別節點，然後將節點整合到原始超圖中。我們根據少數類別及其鄰居的樣本合成新節點。同時，為了解決將新節點整合到超圖中的問題，我們根據原始超圖的發生矩陣訓練一個解碼器，以自適應地將擴充節點與超邊緣關聯起來。我們對多個單一模式數據集（例如 Cora、Cora-CA 和 Citeseer）以及多模態對話數據集 MELD 進行了廣泛的評估，以驗證 HyperSMOTE 的有效性，結果顯示在準確度上分別平均提升了 3.38% 和 2.97%。

##### **NLLB-E5: A Scalable Multilingual Retrieval Model**
2409.05401v1 by Arkadeep Acharya, Rudra Murthy, Vishwajeet Kumar, Jaydeep Sen

Despite significant progress in multilingual information retrieval, the lack
of models capable of effectively supporting multiple languages, particularly
low-resource like Indic languages, remains a critical challenge. This paper
presents NLLB-E5: A Scalable Multilingual Retrieval Model. NLLB-E5 leverages
the in-built multilingual capabilities in the NLLB encoder for translation
tasks. It proposes a distillation approach from multilingual retriever E5 to
provide a zero-shot retrieval approach handling multiple languages, including
all major Indic languages, without requiring multilingual training data. We
evaluate the model on a comprehensive suite of existing benchmarks, including
Hindi-BEIR, highlighting its robust performance across diverse languages and
tasks. Our findings uncover task and domain-specific challenges, providing
valuable insights into the retrieval performance, especially for low-resource
languages. NLLB-E5 addresses the urgent need for an inclusive, scalable, and
language-agnostic text retrieval model, advancing the field of multilingual
information access and promoting digital inclusivity for millions of users
globally.

摘要：儘管多語言資訊檢索有顯著進展，但缺乏能有效支援多種語言的模型，特別是像印度語言這類低資源語言，仍然是一項嚴峻的挑戰。本論文提出 NLLB-E5：一種可擴充的多語言檢索模型。NLLB-E5 充分利用 NLLB 編碼器中內建的多語言功能來執行翻譯任務。它提出從多語言檢索器 E5 進行萃取的方法，以提供零次學習檢索方法，處理包括所有主要印度語言在內的各種語言，而無需多語言訓練資料。我們在全面的現有基準上評估模型，包括 Hindi-BEIR，突顯其在各種語言和任務中的強健效能。我們的研究結果揭示了任務和領域特定的挑戰，提供了對檢索效能的寶貴見解，特別是對於低資源語言。NLLB-E5 解決了對包容性、可擴充性和與語言無關的文字檢索模型的迫切需求，推動了多語言資訊存取領域，並促進數百萬全球使用者的數位包容性。

##### **FacialFlowNet: Advancing Facial Optical Flow Estimation with a Diverse Dataset and a Decomposed Model**
2409.05396v1 by Jianzhi Lu, Ruian He, Shili Zhou, Weimin Tan, Bo Yan

Facial movements play a crucial role in conveying altitude and intentions,
and facial optical flow provides a dynamic and detailed representation of it.
However, the scarcity of datasets and a modern baseline hinders the progress in
facial optical flow research. This paper proposes FacialFlowNet (FFN), a novel
large-scale facial optical flow dataset, and the Decomposed Facial Flow Model
(DecFlow), the first method capable of decomposing facial flow. FFN comprises
9,635 identities and 105,970 image pairs, offering unprecedented diversity for
detailed facial and head motion analysis. DecFlow features a facial
semantic-aware encoder and a decomposed flow decoder, excelling in accurately
estimating and decomposing facial flow into head and expression components.
Comprehensive experiments demonstrate that FFN significantly enhances the
accuracy of facial flow estimation across various optical flow methods,
achieving up to an 11% reduction in Endpoint Error (EPE) (from 3.91 to 3.48).
Moreover, DecFlow, when coupled with FFN, outperforms existing methods in both
synthetic and real-world scenarios, enhancing facial expression analysis. The
decomposed expression flow achieves a substantial accuracy improvement of 18%
(from 69.1% to 82.1%) in micro-expressions recognition. These contributions
represent a significant advancement in facial motion analysis and optical flow
estimation. Codes and datasets can be found.

摘要：面部動作在傳達高度和意圖方面發揮著至關重要的作用，而面部光流提供了動態且詳細的表示。然而，數據集的稀缺和現代基準阻礙了面部光流研究的進展。本文提出了 FacialFlowNet (FFN)，一個新穎的大規模面部光流數據集，以及分解面部流模型 (DecFlow)，這是第一個能夠分解面部流的方法。FFN 包含 9,635 個身份和 105,970 對圖像，為詳細的面部和頭部運動分析提供了前所未有的多樣性。DecFlow 採用面部語義感知編碼器和分解流解碼器，擅長準確估計和將面部流分解為頭部和表情組成部分。綜合實驗表明，FFN 明顯提高了各種光流方法的面部流估計精度，將端點誤差 (EPE) 降低了 11%（從 3.91 降至 3.48）。此外，DecFlow 與 FFN 結合使用時，在合成和真實世界場景中均優於現有方法，增強了面部表情分析。分解的表情流在微表情識別中實現了 18% 的顯著精度提升（從 69.1% 到 82.1%）。這些貢獻代表了面部運動分析和光流估計的重大進步。可以找到代碼和數據集。

##### **Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling**
2409.05395v1 by Georgios Pantazopoulos, Malvina Nikandrou, Alessandro Suglia, Oliver Lemon, Arash Eshghi

This study explores replacing Transformers in Visual Language Models (VLMs)
with Mamba, a recent structured state space model (SSM) that demonstrates
promising performance in sequence modeling. We test models up to 3B parameters
under controlled conditions, showing that Mamba-based VLMs outperforms
Transformers-based VLMs in captioning, question answering, and reading
comprehension. However, we find that Transformers achieve greater performance
in visual grounding and the performance gap widens with scale. We explore two
hypotheses to explain this phenomenon: 1) the effect of task-agnostic visual
encoding on the updates of the hidden states, and 2) the difficulty in
performing visual grounding from the perspective of in-context multimodal
retrieval. Our results indicate that a task-aware encoding yields minimal
performance gains on grounding, however, Transformers significantly outperform
Mamba at in-context multimodal retrieval. Overall, Mamba shows promising
performance on tasks where the correct output relies on a summary of the image
but struggles when retrieval of explicit information from the context is
required.

摘要：這項研究探討用 Mamba 取代視覺語言模型 (VLM) 中的 Transformer，Mamba 是一種最近的結構化狀態空間模型 (SSM)，在序列建模中展現出極佳的效能。我們在受控條件下測試高達 3B 參數的模型，顯示基於 Mamba 的 VLM 在標題、問答和閱讀理解方面都優於基於 Transformer 的 VLM。然而，我們發現 Transformer 在視覺基礎上獲得更好的效能，而且效能差距會隨著規模擴大而擴大。我們探討了兩個假設來解釋這種現象：1) 與任務無關的視覺編碼對隱藏狀態更新的影響，以及 2) 從語境多模態檢索的角度執行視覺基礎的困難。我們的結果表明，任務感知編碼在基礎上產生最小的效能提升，然而，Transformer 在語境多模態檢索方面明顯優於 Mamba。總體而言，Mamba 在正確輸出依賴於影像摘要的任務上展現出極佳的效能，但當需要從語境中檢索明確資訊時，就會遇到困難。

##### **Towards Building a Robust Knowledge Intensive Question Answering Model with Large Language Models**
2409.05385v1 by Hong Xingyun Hong, Shao Yan Shao, Wang Zhilin Wang, Duan Manni Duan, Jin Xiongnan

The development of LLMs has greatly enhanced the intelligence and fluency of
question answering, while the emergence of retrieval enhancement has enabled
models to better utilize external information. However, the presence of noise
and errors in retrieved information poses challenges to the robustness of LLMs.
In this work, to evaluate the model's performance under multiple interferences,
we first construct a dataset based on machine reading comprehension datasets
simulating various scenarios, including critical information absence, noise,
and conflicts. To address the issue of model accuracy decline caused by noisy
external information, we propose a data augmentation-based fine-tuning method
to enhance LLM's robustness against noise. Additionally, contrastive learning
approach is utilized to preserve the model's discrimination capability of
external information. We have conducted experiments on both existing LLMs and
our approach, the results are evaluated by GPT-4, which indicates that our
proposed methods improve model robustness while strengthening the model's
discrimination capability.

摘要：大語言模型的發展大幅提升了問答的智能化和流暢度，而檢索增強的出現讓模型能更好地利用外部資訊。然而，檢索資訊中出現的雜訊和錯誤對大語言模型的穩健性構成挑戰。在這項工作中，為了評估模型在多種干擾下的表現，我們首先根據機器閱讀理解資料集建構一個資料集，模擬各種情境，包括關鍵資訊缺失、雜訊和衝突。為了解決雜訊外部資訊導致模型準確度下降的問題，我們提出一個基於資料擴充的微調方法，以增強大語言模型對雜訊的穩健性。此外，利用對比學習方法來保持模型對外部資訊的辨別能力。我們已針對現有的 LLM 和我們的做法進行實驗，結果由 GPT-4 評估，這表明我們提出的方法在增強模型的辨別能力的同時，也改善了模型的穩健性。

##### **Look One and More: Distilling Hybrid Order Relational Knowledge for Cross-Resolution Image Recognition**
2409.05384v1 by Shiming Ge, Kangkai Zhang, Haolin Liu, Yingying Hua, Shengwei Zhao, Xin Jin, Hao Wen

In spite of great success in many image recognition tasks achieved by recent
deep models, directly applying them to recognize low-resolution images may
suffer from low accuracy due to the missing of informative details during
resolution degradation. However, these images are still recognizable for
subjects who are familiar with the corresponding high-resolution ones. Inspired
by that, we propose a teacher-student learning approach to facilitate
low-resolution image recognition via hybrid order relational knowledge
distillation. The approach refers to three streams: the teacher stream is
pretrained to recognize high-resolution images in high accuracy, the student
stream is learned to identify low-resolution images by mimicking the teacher's
behaviors, and the extra assistant stream is introduced as bridge to help
knowledge transfer across the teacher to the student. To extract sufficient
knowledge for reducing the loss in accuracy, the learning of student is
supervised with multiple losses, which preserves the similarities in various
order relational structures. In this way, the capability of recovering missing
details of familiar low-resolution images can be effectively enhanced, leading
to a better knowledge transfer. Extensive experiments on metric learning,
low-resolution image classification and low-resolution face recognition tasks
show the effectiveness of our approach, while taking reduced models.

摘要：儘管最近的深度模型在許多影像辨識任務中獲得極大的成功，但直接將其應用於辨識低解析度影像時，可能會因為在解析度降低過程中遺失資訊細節，而導致精確度降低。然而，對於熟悉對應高解析度影像的主體而言，這些影像仍然可以辨識。受到此啟發，我們提出一個教師-學生學習方法，透過混合順序關係知識萃取，來促進低解析度影像辨識。此方法包含三個串流：教師串流經過預訓練，可以高精確度辨識高解析度影像；學生串流透過模仿教師行為，學習辨識低解析度影像；而額外的助理串流則作為橋樑，協助將知識從教師傳遞給學生。為了萃取足夠的知識以減少精確度的損失，學生的學習會受到多重損失的監督，這保留了各種順序關係結構中的相似性。透過這種方式，可以有效增強恢復熟悉低解析度影像中遺失細節的能力，進而達到更好的知識傳遞。在度量學習、低解析度影像分類和低解析度人臉辨識任務上的大量實驗，顯示了我們方法的有效性，同時採用了簡化的模型。

##### **Deep Learning for Video Anomaly Detection: A Review**
2409.05383v1 by Peng Wu, Chengyu Pan, Yuting Yan, Guansong Pang, Peng Wang, Yanning Zhang

Video anomaly detection (VAD) aims to discover behaviors or events deviating
from the normality in videos. As a long-standing task in the field of computer
vision, VAD has witnessed much good progress. In the era of deep learning, with
the explosion of architectures of continuously growing capability and capacity,
a great variety of deep learning based methods are constantly emerging for the
VAD task, greatly improving the generalization ability of detection algorithms
and broadening the application scenarios. Therefore, such a multitude of
methods and a large body of literature make a comprehensive survey a pressing
necessity. In this paper, we present an extensive and comprehensive research
review, covering the spectrum of five different categories, namely,
semi-supervised, weakly supervised, fully supervised, unsupervised and open-set
supervised VAD, and we also delve into the latest VAD works based on
pre-trained large models, remedying the limitations of past reviews in terms of
only focusing on semi-supervised VAD and small model based methods. For the VAD
task with different levels of supervision, we construct a well-organized
taxonomy, profoundly discuss the characteristics of different types of methods,
and show their performance comparisons. In addition, this review involves the
public datasets, open-source codes, and evaluation metrics covering all the
aforementioned VAD tasks. Finally, we provide several important research
directions for the VAD community.

摘要：影片異常偵測（VAD）旨在找出影片中偏離正常情況的行為或事件。作為電腦視覺領域中一項長期的任務，VAD 已見證許多良好的進展。在深度學習的時代，隨著架構不斷增長的能力和容量爆炸，各種基於深度學習的方法不斷湧現，用於 VAD 任務，大大提高了偵測演算法的泛化能力，並擴展了應用場景。因此，如此眾多的方法和大量的文獻使得全面的調查迫在眉睫。在本文中，我們提出了一項廣泛且全面的研究回顧，涵蓋了五種類別的範圍，即半監督、弱監督、完全監督、無監督和開放集監督 VAD，我們也深入探討了基於預訓練大型模型的最新 VAD 作品，彌補過去僅專注於半監督 VAD 和小型模型方法的回顧限制。對於具有不同監督層級的 VAD 任務，我們建構了一個組織良好的分類法，深入探討不同類型方法的特徵，並展示其效能比較。此外，此回顧涉及公開資料集、開源程式碼和評估指標，涵蓋所有上述 VAD 任務。最後，我們為 VAD 社群提供了幾個重要的研究方向。

##### **KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models**
2409.05370v1 by Yingshu Li, Zhanyu Wang, Yunyi Liu, Lei Wang, Lingqiao Liu, Luping Zhou

Harnessing the robust capabilities of Large Language Models (LLMs) for
narrative generation, logical reasoning, and common-sense knowledge
integration, this study delves into utilizing LLMs to enhance automated
radiology report generation (R2Gen). Despite the wealth of knowledge within
LLMs, efficiently triggering relevant knowledge within these large models for
specific tasks like R2Gen poses a critical research challenge. This paper
presents KARGEN, a Knowledge-enhanced Automated radiology Report GENeration
framework based on LLMs. Utilizing a frozen LLM to generate reports, the
framework integrates a knowledge graph to unlock chest disease-related
knowledge within the LLM to enhance the clinical utility of generated reports.
This is achieved by leveraging the knowledge graph to distill disease-related
features in a designed way. Since a radiology report encompasses both normal
and disease-related findings, the extracted graph-enhanced disease-related
features are integrated with regional image features, attending to both
aspects. We explore two fusion methods to automatically prioritize and select
the most relevant features. The fused features are employed by LLM to generate
reports that are more sensitive to diseases and of improved quality. Our
approach demonstrates promising results on the MIMIC-CXR and IU-Xray datasets.

摘要：<paragraph>利用大型語言模型 (LLM) 強大的功能，進行敘事生成、邏輯推理和常識知識整合，本研究深入探討利用 LLM 來增強自動化放射報告生成 (R2Gen)。儘管 LLM 擁有豐富的知識，但要有效觸發這些大型模型中與特定任務（如 R2Gen）相關的知識，是一個重要的研究挑戰。本文提出了 KARGEN，一個基於 LLM 的知識增強自動化放射報告生成框架。利用凍結的 LLM 來生成報告，該框架整合了一個知識圖譜，以解鎖 LLM 中與胸部疾病相關的知識，以增強生成報告的臨床效用。這是透過利用知識圖譜以設計的方式提取與疾病相關的特徵來實現的。由於放射報告包含正常和疾病相關的發現，因此提取的圖形增強疾病相關特徵與區域影像特徵整合，兼顧兩個方面。我們探索了兩種融合方法，以自動優先排序和選擇最相關的特徵。融合的特徵由 LLM 使用，以生成對疾病更敏感且品質更高的報告。我們的做法在 MIMIC-CXR 和 IU-Xray 資料集上展示了有希望的結果。</paragraph>

##### **Application Specific Compression of Deep Learning Models**
2409.05368v1 by Rohit Raj Rai, Angana Borah, Amit Awekar

Large Deep Learning models are compressed and deployed for specific
applications. However, current Deep Learning model compression methods do not
utilize the information about the target application. As a result, the
compressed models are application agnostic. Our goal is to customize the model
compression process to create a compressed model that will perform better for
the target application. Our method, Application Specific Compression (ASC),
identifies and prunes components of the large Deep Learning model that are
redundant specifically for the given target application. The intuition of our
work is to prune the parts of the network that do not contribute significantly
to updating the data representation for the given application. We have
experimented with the BERT family of models for three applications: Extractive
QA, Natural Language Inference, and Paraphrase Identification. We observe that
customized compressed models created using ASC method perform better than
existing model compression methods and off-the-shelf compressed models.

摘要：大型深度學習模型會被壓縮並部署於特定應用程式中。然而，目前的深度學習模型壓縮方法並未利用目標應用程式的資訊。因此，壓縮後的模型與應用程式無關。我們的目標是客製化模型壓縮流程，以建立一個壓縮後的模型，該模型的效能將針對目標應用程式而提升。我們的 Application Specific Compression (ASC) 方法會找出並移除大型深度學習模型中的組件，而這些組件對於給定的目標應用程式來說是多餘的。我們工作的直覺是移除對給定應用程式資料表徵更新沒有顯著貢獻的網路部分。我們針對三種應用程式測試了 BERT 系列模型：萃取式問答、自然語言推論和同義詞辨識。我們觀察到，使用 ASC 方法建立的客製化壓縮模型的效能優於現有的模型壓縮方法和現成的壓縮模型。

##### **Diagnostic Reasoning in Natural Language: Computational Model and Application**
2409.05367v1 by Nils Dycke, Matej Zečević, Ilia Kuznetsov, Beatrix Suess, Kristian Kersting, Iryna Gurevych

Diagnostic reasoning is a key component of expert work in many domains. It is
a hard, time-consuming activity that requires expertise, and AI research has
investigated the ways automated systems can support this process. Yet, due to
the complexity of natural language, the applications of AI for diagnostic
reasoning to language-related tasks are lacking. To close this gap, we
investigate diagnostic abductive reasoning (DAR) in the context of
language-grounded tasks (NL-DAR). We propose a novel modeling framework for
NL-DAR based on Pearl's structural causal models and instantiate it in a
comprehensive study of scientific paper assessment in the biomedical domain. We
use the resulting dataset to investigate the human decision-making process in
NL-DAR and determine the potential of LLMs to support structured
decision-making over text. Our framework, open resources and tools lay the
groundwork for the empirical study of collaborative diagnostic reasoning in the
age of LLMs, in the scholarly domain and beyond.

摘要：診斷推理是許多領域專家工作中的關鍵組成部分。這是一個困難且耗時的活動，需要專業知識，而人工智慧研究已探討自動化系統如何支援此流程。然而，由於自然語言的複雜性，人工智慧在診斷推理中應用於與語言相關任務的應用仍然不足。為了縮小這個差距，我們在以語言為基礎的任務（NL-DAR）的背景下探討診斷演繹推理（DAR）。我們提出一個基於 Pearl 的結構因果模型的 NL-DAR 新建模架構，並在生物醫學領域的科學論文評估的全面研究中實例化它。我們使用產生的資料集來探討 NL-DAR 中的人類決策制定過程，並確定大型語言模型支援文本結構化決策制定的潛力。我們的架構、開放資源和工具為大型語言模型時代的協作診斷推理的實證研究奠定了基礎，不僅在學術領域，更擴及其他領域。

##### **IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS**
2409.05356v1 by Ashwin Sankar, Srija Anand, Praveen Srinivasa Varadhan, Sherry Thomas, Mehak Singal, Shridhar Kumar, Deovrat Mehendale, Aditi Krishana, Giri Raju, Mitesh Khapra

Recent advancements in text-to-speech (TTS) synthesis show that large-scale
models trained with extensive web data produce highly natural-sounding output.
However, such data is scarce for Indian languages due to the lack of
high-quality, manually subtitled data on platforms like LibriVox or YouTube. To
address this gap, we enhance existing large-scale ASR datasets containing
natural conversations collected in low-quality environments to generate
high-quality TTS training data. Our pipeline leverages the cross-lingual
generalization of denoising and speech enhancement models trained on English
and applied to Indian languages. This results in IndicVoices-R (IV-R), the
largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704
hours of high-quality speech from 10,496 speakers across 22 Indian languages.
IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS,
and IndicTTS. We also introduce the IV-R Benchmark, the first to assess
zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS
models on Indian voices, ensuring diversity in age, gender, and style. We
demonstrate that fine-tuning an English pre-trained model on a combined dataset
of high-quality IndicTTS and our IV-R dataset results in better zero-shot
speaker generalization compared to fine-tuning on the IndicTTS dataset alone.
Further, our evaluation reveals limited zero-shot generalization for Indian
voices in TTS models trained on prior datasets, which we improve by fine-tuning
the model on our data containing diverse set of speakers across language
families. We open-source all data and code, releasing the first TTS model for
all 22 official Indian languages.

摘要：最近在文本转语音（TTS）合成方面的进步表明，使用大量网络数据训练的大型模型会产生听起来非常自然的声音。然而，由于缺乏 LibriVox 或 YouTube 等平台上高质量的手动字幕数据，此类数据对于印度语言来说非常稀缺。为了解决这一差距，我们增强了现有的包含在低质量环境中收集的自然对话的大型 ASR 数据集，以生成高质量的 TTS 训练数据。我们的管道利用了在英语上训练的去噪和语音增强模型的跨语言泛化，并将其应用于印度语言。这产生了 IndicVoices-R (IV-R)，这是从 ASR 数据集派生的最大的多语言印度 TTS 数据集，包含来自 22 种印度语言的 10,496 名说话者的 1,704 小时高质量语音。IV-R 与 LJSpeech、LibriTTS 和 IndicTTS 等黄金标准 TTS 数据集的质量相匹配。我们还引入了 IV-R 基准，这是第一个评估 TTS 模型在印度语音上的零样本、少样本和多样本说话者泛化能力的基准，确保了年龄、性别和风格的多样性。我们证明，在高质量 IndicTTS 和我们的 IV-R 数据集的组合数据集上微调英语预训练模型与仅在 IndicTTS 数据集上微调相比，产生了更好的零样本说话者泛化。此外，我们的评估显示，在先验数据集上训练的 TTS 模型中，印度语音的零样本泛化能力有限，而我们通过微调包含跨语言系列的不同说话者集合的数据模型来改进泛化能力。我们开源所有数据和代码，发布了首个适用于所有 22 种官方印度语言的 TTS 模型。

##### **TriplePlay: Enhancing Federated Learning with CLIP for Non-IID Data and Resource Efficiency**
2409.05347v1 by Ahmed Imteaj, Md Zarif Hossain, Saika Zaman, Abdur R. Shahid

The rapid advancement and increasing complexity of pretrained models,
exemplified by CLIP, offer significant opportunities as well as challenges for
Federated Learning (FL), a critical component of privacy-preserving artificial
intelligence. This research delves into the intricacies of integrating large
foundation models like CLIP within FL frameworks to enhance privacy,
efficiency, and adaptability across heterogeneous data landscapes. It
specifically addresses the challenges posed by non-IID data distributions, the
computational and communication overheads of leveraging such complex models,
and the skewed representation of classes within datasets. We propose
TriplePlay, a framework that integrates CLIP as an adapter to enhance FL's
adaptability and performance across diverse data distributions. This approach
addresses the long-tail distribution challenge to ensure fairness while
reducing resource demands through quantization and low-rank adaptation
techniques.Our simulation results demonstrate that TriplePlay effectively
decreases GPU usage costs and speeds up the learning process, achieving
convergence with reduced communication overhead.

摘要：預訓練模型的快速進步和日益增長的複雜性，以 CLIP 為例，為聯邦學習 (FL) 帶來了顯著的機遇和挑戰，而聯邦學習是隱私保護人工智能的關鍵組成部分。本研究深入探討了在 FL 框架中整合 CLIP 等大型基礎模型的複雜性，以增強異質數據環境中的隱私、效率和適應性。它特別針對非 IID 數據分佈帶來的挑戰、利用此類複雜模型的計算和通信開銷，以及數據集中類別的偏差表示。我們提出 TriplePlay，這是一個框架，將 CLIP 集成為適配器，以增強 FL 在不同數據分佈中的適應性和性能。此方法解決了長尾分佈挑戰，以確保公平性，同時通過量化和低秩適應技術減少資源需求。我們的模擬結果表明，TriplePlay 有效降低了 GPU 使用成本，並加快了學習過程，在減少通信開銷的情況下實現收斂。

##### **GDFlow: Anomaly Detection with NCDE-based Normalizing Flow for Advanced Driver Assistance System**
2409.05346v1 by Kangjun Lee, Minha Kim, Youngho Jun, Simon S. Woo

For electric vehicles, the Adaptive Cruise Control (ACC) in Advanced Driver
Assistance Systems (ADAS) is designed to assist braking based on driving
conditions, road inclines, predefined deceleration strengths, and user braking
patterns. However, the driving data collected during the development of ADAS
are generally limited and lack diversity. This deficiency leads to late or
aggressive braking for different users. Crucially, it is necessary to
effectively identify anomalies, such as unexpected or inconsistent braking
patterns in ADAS, especially given the challenge of working with unlabelled,
limited, and noisy datasets from real-world electric vehicles. In order to
tackle the aforementioned challenges in ADAS, we propose Graph Neural
Controlled Differential Equation Normalizing Flow (GDFlow), a model that
leverages Normalizing Flow (NF) with Neural Controlled Differential Equations
(NCDE) to learn the distribution of normal driving patterns continuously.
Compared to the traditional clustering or anomaly detection algorithms, our
approach effectively captures the spatio-temporal information from different
sensor data and more accurately models continuous changes in driving patterns.
Additionally, we introduce a quantile-based maximum likelihood objective to
improve the likelihood estimate of the normal data near the boundary of the
distribution, enhancing the model's ability to distinguish between normal and
anomalous patterns. We validate GDFlow using real-world electric vehicle
driving data that we collected from Hyundai IONIQ5 and GV80EV, achieving
state-of-the-art performance compared to six baselines across four dataset
configurations of different vehicle types and drivers. Furthermore, our model
outperforms the latest anomaly detection methods across four time series
benchmark datasets. Our approach demonstrates superior efficiency in inference
time compared to existing methods.

摘要：對於電動車輛，進階駕駛輔助系統 (ADAS) 中的自適應巡航控制 (ACC) 被設計為根據駕駛狀況、道路坡度、預定義的減速強度和使用者煞車模式來協助煞車。然而，在 ADAS 開發期間收集的駕駛資料通常有限且缺乏多樣性。這種缺陷會導致針對不同使用者出現煞車過晚或過猛的情況。至關重要的是，有必要有效地識別異常情況，例如 ADAS 中意外或不一致的煞車模式，尤其是在處理來自真實世界電動車輛的未標記、有限和有雜訊的資料集時面臨的挑戰。為了應對 ADAS 中上述挑戰，我們提出了圖神經控制微分方程正規化流 (GDFlow)，這是一個利用正規化流 (NF) 和神經控制微分方程 (NCDE) 來持續學習正常駕駛模式分布的模型。與傳統的聚類或異常偵測演算法相比，我們的做法有效地從不同的感測器資料中擷取時空資訊，並更準確地模擬駕駛模式的連續變化。此外，我們引入了一個基於分位數的最大似然目標函數，以改善分布邊界附近正常資料的似然估計，增強模型區分正常模式和異常模式的能力。我們使用從現代 IONIQ5 和 GV80EV 收集的真實世界電動車輛駕駛資料驗證 GDFlow，與六個基線在四種不同車輛類型和駕駛的資料集配置中相比，達到了最先進的效能。此外，我們的模型在四個時間序列基準資料集中優於最新的異常偵測方法。與現有方法相比，我們的做法在推論時間方面展現出優異的效率。

##### **A Multi-Modal Deep Learning Based Approach for House Price Prediction**
2409.05335v1 by Md Hasebul Hasan, Md Abid Jahan, Mohammed Eunus Ali, Yuan-Fang Li, Timos Sellis

Accurate prediction of house price, a vital aspect of the residential real
estate sector, is of substantial interest for a wide range of stakeholders.
However, predicting house prices is a complex task due to the significant
variability influenced by factors such as house features, location,
neighborhood, and many others. Despite numerous attempts utilizing a wide array
of algorithms, including recent deep learning techniques, to predict house
prices accurately, existing approaches have fallen short of considering a wide
range of factors such as textual and visual features. This paper addresses this
gap by comprehensively incorporating attributes, such as features, textual
descriptions, geo-spatial neighborhood, and house images, typically showcased
in real estate listings in a house price prediction system. Specifically, we
propose a multi-modal deep learning approach that leverages different types of
data to learn more accurate representation of the house. In particular, we
learn a joint embedding of raw house attributes, geo-spatial neighborhood, and
most importantly from textual description and images representing the house;
and finally use a downstream regression model to predict the house price from
this jointly learned embedding vector. Our experimental results with a
real-world dataset show that the text embedding of the house advertisement
description and image embedding of the house pictures in addition to raw
attributes and geo-spatial embedding, can significantly improve the house price
prediction accuracy. The relevant source code and dataset are publicly
accessible at the following URL: https://github.com/4P0N/mhpp

摘要：準確預測房價是住宅房地產部門的重要面向，對廣泛的利害關係人來說極為重要。然而，預測房價是一項複雜的任務，因為受到房屋特色、地點、鄰里等眾多因素的顯著變異影響。儘管已嘗試使用各種演算法，包括最近的深度學習技術，來準確預測房價，但現有的方法未能考量廣泛的因素，例如文字和視覺特徵。本文透過全面納入房屋價格預測系統中房地產清單中通常展示的屬性（例如特色、文字描述、地理空間鄰里和房屋影像）來解決此一差距。具體來說，我們提出一個多模態深度學習方法，利用不同類型的資料來學習房屋的更準確表徵。特別是，我們學習原始房屋屬性、地理空間鄰里和最重要的是房屋文字描述和影像的聯合嵌入；最後使用下游回歸模型從這個聯合學習的嵌入向量預測房價。我們使用真實世界資料集進行的實驗結果顯示，除了原始屬性和地理空間嵌入之外，房屋廣告描述的文字嵌入和房屋圖片的影像嵌入可以顯著改善房價預測準確度。相關原始碼和資料集可在以下網址公開取得：https://github.com/4P0N/mhpp

##### **Sample-Efficient Bayesian Optimization with Transfer Learning for Heterogeneous Search Spaces**
2409.05325v1 by Aryan Deshwal, Sait Cakmak, Yuhou Xia, David Eriksson

Bayesian optimization (BO) is a powerful approach to sample-efficient
optimization of black-box functions. However, in settings with very few
function evaluations, a successful application of BO may require transferring
information from historical experiments. These related experiments may not have
exactly the same tunable parameters (search spaces), motivating the need for BO
with transfer learning for heterogeneous search spaces. In this paper, we
propose two methods for this setting. The first approach leverages a Gaussian
process (GP) model with a conditional kernel to transfer information between
different search spaces. Our second approach treats the missing parameters as
hyperparameters of the GP model that can be inferred jointly with the other GP
hyperparameters or set to fixed values. We show that these two methods perform
well on several benchmark problems.

摘要：貝氏最佳化 (BO) 是一種功能強大的方法，可用於黑盒函數的樣本有效最佳化。然而，在函數評估非常少的設定中，BO 的成功應用可能需要從歷史實驗中傳遞資訊。這些相關實驗可能沒有完全相同的可調整參數 (搜尋空間)，這促使需要針對異質搜尋空間進行傳遞學習的 BO。在本文中，我們針對此設定提出兩種方法。第一種方法利用高斯過程 (GP) 模型，搭配條件核將資訊傳遞到不同的搜尋空間。我們的第二種方法將遺失的參數視為 GP 模型的超參數，該參數可以與其他 GP 超參數一起推斷，或設定為固定值。我們證明這兩種方法在多個基準問題中表現良好。

##### **Machine Anomalous Sound Detection Using Spectral-temporal Modulation Representations Derived from Machine-specific Filterbanks**
2409.05319v1 by Kai Li, Khalid Zaman, Xingfeng Li, Masato Akagi, Masashi Unoki

Early detection of factory machinery malfunctions is crucial in industrial
applications. In machine anomalous sound detection (ASD), different machines
exhibit unique vibration-frequency ranges based on their physical properties.
Meanwhile, the human auditory system is adept at tracking both temporal and
spectral dynamics of machine sounds. Consequently, integrating the
computational auditory models of the human auditory system with
machine-specific properties can be an effective approach to machine ASD. We
first quantified the frequency importances of four types of machines using the
Fisher ratio (F-ratio). The quantified frequency importances were then used to
design machine-specific non-uniform filterbanks (NUFBs), which extract the log
non-uniform spectrum (LNS) feature. The designed NUFBs have a narrower
bandwidth and higher filter distribution density in frequency regions with
relatively high F-ratios. Finally, spectral and temporal modulation
representations derived from the LNS feature were proposed. These proposed LNS
feature and modulation representations are input into an autoencoder
neural-network-based detector for ASD. The quantification results from the
training set of the Malfunctioning Industrial Machine Investigation and
Inspection dataset with a signal-to-noise (SNR) of 6 dB reveal that the
distinguishing information between normal and anomalous sounds of different
machines is encoded non-uniformly in the frequency domain. By highlighting
these important frequency regions using NUFBs, the LNS feature can
significantly enhance performance using the metric of AUC (area under the
receiver operating characteristic curve) under various SNR conditions.
Furthermore, modulation representations can further improve performance.
Specifically, temporal modulation is effective for fans, pumps, and sliders,
while spectral modulation is particularly effective for valves.

摘要：<paragraph>在工業應用中，及早偵測工廠機器故障至關重要。在機器異常聲音偵測 (ASD) 中，不同的機器會根據其物理特性展現獨特的振動頻率範圍。同時，人類的聽覺系統擅長追蹤機器聲音的時間和頻譜動態。因此，將人類聽覺系統的計算聽覺模型與特定機器特性整合，可以成為機器 ASD 的有效方法。我們首先使用費雪比率 (F 比率) 量化了四種類型機器頻率的重要性。然後使用量化的頻率重要性來設計特定於機器的非均勻濾波器組 (NUFB)，其會萃取對數非均勻頻譜 (LNS) 特徵。所設計的 NUFB 在 F 比率相對高的頻率區域具有較窄的頻寬和較高的濾波器分佈密度。最後，提出了從 LNS 特徵衍生的頻譜和時間調變表示。這些提出的 LNS 特徵和調變表示會輸入到基於自動編碼器神經網路的偵測器中，以進行 ASD。來自故障工業機器調查和檢查資料集的訓練組的量化結果，其訊噪比 (SNR) 為 6 dB，顯示不同機器的正常和異常聲音之間的區別資訊以非均勻的方式編碼在頻域中。透過使用 NUFB 凸顯這些重要的頻率區域，LNS 特徵可以在各種 SNR 條件下，大幅提升使用 AUC（接收器操作特性曲線下的面積）指標的效能。此外，調變表示可以進一步提升效能。具體來說，時間調變適用於風扇、幫浦和滑塊，而頻譜調變則特別適用於閥門。</paragraph>

##### **Tele-LLMs: A Series of Specialized Large Language Models for Telecommunications**
2409.05314v1 by Ali Maatouk, Kenny Chirino Ampudia, Rex Ying, Leandros Tassiulas

The emergence of large language models (LLMs) has significantly impacted
various fields, from natural language processing to sectors like medicine and
finance. However, despite their rapid proliferation, the applications of LLMs
in telecommunications remain limited, often relying on general-purpose models
that lack domain-specific specialization. This lack of specialization results
in underperformance, particularly when dealing with telecommunications-specific
technical terminology and their associated mathematical representations. This
paper addresses this gap by first creating and disseminating Tele-Data, a
comprehensive dataset of telecommunications material curated from relevant
sources, and Tele-Eval, a large-scale question-and-answer dataset tailored to
the domain. Through extensive experiments, we explore the most effective
training techniques for adapting LLMs to the telecommunications domain, ranging
from examining the division of expertise across various telecommunications
aspects to employing parameter-efficient techniques. We also investigate how
models of different sizes behave during adaptation and analyze the impact of
their training data on this behavior. Leveraging these findings, we develop and
open-source Tele-LLMs, the first series of language models ranging from 1B to
8B parameters, specifically tailored for telecommunications. Our evaluations
demonstrate that these models outperform their general-purpose counterparts on
Tele-Eval while retaining their previously acquired capabilities, thus avoiding
the catastrophic forgetting phenomenon.

摘要：大型語言模型 (LLM) 的出現對各個領域產生了重大影響，從自然語言處理到醫學和金融等領域。然而，儘管 LLM 迅速普及，但在電信領域的應用仍然有限，通常依賴於缺乏特定領域專業知識的通用模型。這種專業知識的缺乏導致了表現不佳，特別是在處理電信專用技術術語及其相關數學表示時。本文通過首先創建和傳播 Tele-Data 來解決這一差距，Tele-Data 是從相關來源策展的電信材料的綜合數據集，以及 Tele-Eval，一個針對該領域量身定制的大規模問答數據集。通過廣泛的實驗，我們探討了將 LLM 適應電信領域的最有效訓練技術，從檢查電信各個方面的專業知識劃分到採用參數高效技術。我們還研究了不同規模的模型在適應過程中如何表現，並分析了其訓練數據對這種行為的影響。利用這些發現，我們開發並開源了 Tele-LLM，這是第一個針對電信量身定制的語言模型系列，參數範圍從 1B 到 8B。我們的評估表明，這些模型在 Tele-Eval 上優於其通用模型，同時保留了它們先前獲得的能力，從而避免了災難性遺忘現象。

##### **Resource-Efficient Generative AI Model Deployment in Mobile Edge Networks**
2409.05303v1 by Yuxin Liang, Peng Yang, Yuanyuan He, Feng Lyu

The surging development of Artificial Intelligence-Generated Content (AIGC)
marks a transformative era of the content creation and production. Edge servers
promise attractive benefits, e.g., reduced service delay and backhaul traffic
load, for hosting AIGC services compared to cloud-based solutions. However, the
scarcity of available resources on the edge pose significant challenges in
deploying generative AI models. In this paper, by characterizing the resource
and delay demands of typical generative AI models, we find that the consumption
of storage and GPU memory, as well as the model switching delay represented by
I/O delay during the preloading phase, are significant and vary across models.
These multidimensional coupling factors render it difficult to make efficient
edge model deployment decisions. Hence, we present a collaborative edge-cloud
framework aiming to properly manage generative AI model deployment on the edge.
Specifically, we formulate edge model deployment problem considering
heterogeneous features of models as an optimization problem, and propose a
model-level decision selection algorithm to solve it. It enables pooled
resource sharing and optimizes the trade-off between resource consumption and
delay in edge generative AI model deployment. Simulation results validate the
efficacy of the proposed algorithm compared with baselines, demonstrating its
potential to reduce overall costs by providing feature-aware model deployment
decisions.

摘要：人工智能生成內容（AIGC）的蓬勃發展標誌著內容創作與製作的轉型時代。相較於雲端解決方案，邊緣伺服器承諾提供有吸引力的優勢，例如減少服務延遲和回程傳輸流量負載，以主機 AIGC 服務。然而，邊緣上可用資源的稀缺性在部署生成式 AI 模型時帶來了重大挑戰。在本文中，透過描述典型生成式 AI 模型的資源和延遲需求，我們發現儲存和 GPU 記憶體的消耗，以及預載階段 I/O 延遲所代表的模型切換延遲，是顯著的且因模型而異。這些多維耦合因素使得難以做出有效的邊緣模型部署決策。因此，我們提出了一個協作式邊緣雲端架構，旨在適當管理邊緣上的生成式 AI 模型部署。具體來說，我們將考慮模型異質性特徵的邊緣模型部署問題制定為一個最佳化問題，並提出一個模型層級的決策選擇演算法來解決它。它能實現資源池化共享，並最佳化邊緣生成式 AI 模型部署中的資源消耗和延遲之間的權衡。模擬結果驗證了所提出的演算法與基線相比的效能，證明了它透過提供具備功能感知的模型部署決策，降低整體成本的潛力。

##### **TERD: A Unified Framework for Safeguarding Diffusion Models Against Backdoors**
2409.05294v1 by Yichuan Mo, Hui Huang, Mingjie Li, Ang Li, Yisen Wang

Diffusion models have achieved notable success in image generation, but they
remain highly vulnerable to backdoor attacks, which compromise their integrity
by producing specific undesirable outputs when presented with a pre-defined
trigger. In this paper, we investigate how to protect diffusion models from
this dangerous threat. Specifically, we propose TERD, a backdoor defense
framework that builds unified modeling for current attacks, which enables us to
derive an accessible reversed loss. A trigger reversion strategy is further
employed: an initial approximation of the trigger through noise sampled from a
prior distribution, followed by refinement through differential multi-step
samplers. Additionally, with the reversed trigger, we propose backdoor
detection from the noise space, introducing the first backdoor input detection
approach for diffusion models and a novel model detection algorithm that
calculates the KL divergence between reversed and benign distributions.
Extensive evaluations demonstrate that TERD secures a 100% True Positive Rate
(TPR) and True Negative Rate (TNR) across datasets of varying resolutions. TERD
also demonstrates nice adaptability to other Stochastic Differential Equation
(SDE)-based models. Our code is available at https://github.com/PKU-ML/TERD.

摘要：擴散模型在影像生成方面取得顯著的成功，但它們仍然極易受到後門攻擊，在呈現預先定義的觸發器時，會產生特定的不良輸出，從而損害其完整性。在本文中，我們探討如何保護擴散模型免於這種危險威脅。具體來說，我們提出 TERD，一個後門防禦框架，為當前的攻擊構建統一建模，使我們能夠推導出可存取的反向損失。進一步採用觸發器逆轉策略：通過從先驗分佈中採樣的雜訊對觸發器進行初步近似，然後通過差分多步採樣器進行優化。此外，利用反向觸發器，我們提出從雜訊空間進行後門檢測，引入了第一個擴散模型後門輸入檢測方法和一種新穎的模型檢測演算法，計算反向分佈和良性分佈之間的 KL 散度。廣泛的評估表明，TERD 在不同解析度的資料集上確保了 100% 真正率 (TPR) 和真負率 (TNR)。TERD 也展示出對其他基於隨機微分方程 (SDE) 的模型的良好適應性。我們的程式碼可在 https://github.com/PKU-ML/TERD 取得。

##### **Mpox Narrative on Instagram: A Labeled Multilingual Dataset of Instagram Posts on Mpox for Sentiment, Hate Speech, and Anxiety Analysis**
2409.05292v1 by Nirmalya Thakur

The world is currently experiencing an outbreak of mpox, which has been
declared a Public Health Emergency of International Concern by WHO. No prior
work related to social media mining has focused on the development of a dataset
of Instagram posts about the mpox outbreak. The work presented in this paper
aims to address this research gap and makes two scientific contributions to
this field. First, it presents a multilingual dataset of 60,127 Instagram posts
about mpox, published between July 23, 2022, and September 5, 2024. The
dataset, available at https://dx.doi.org/10.21227/7fvc-y093, contains Instagram
posts about mpox in 52 languages. For each of these posts, the Post ID, Post
Description, Date of publication, language, and translated version of the post
(translation to English was performed using the Google Translate API) are
presented as separate attributes in the dataset. After developing this dataset,
sentiment analysis, hate speech detection, and anxiety or stress detection were
performed. This process included classifying each post into (i) one of the
sentiment classes, i.e., fear, surprise, joy, sadness, anger, disgust, or
neutral, (ii) hate or not hate, and (iii) anxiety/stress detected or no
anxiety/stress detected. These results are presented as separate attributes in
the dataset. Second, this paper presents the results of performing sentiment
analysis, hate speech analysis, and anxiety or stress analysis. The variation
of the sentiment classes - fear, surprise, joy, sadness, anger, disgust, and
neutral were observed to be 27.95%, 2.57%, 8.69%, 5.94%, 2.69%, 1.53%, and
50.64%, respectively. In terms of hate speech detection, 95.75% of the posts
did not contain hate and the remaining 4.25% of the posts contained hate.
Finally, 72.05% of the posts did not indicate any anxiety/stress, and the
remaining 27.95% of the posts represented some form of anxiety/stress.

摘要：目前世界正經歷一場猴痘疫情，世界衛生組織已宣布這場疫情為國際關注的公共衛生緊急事件。目前尚無與社群媒體探勘相關的先前研究專注於建立一個關於猴痘疫情的 Instagram 貼文資料集。本論文提出的研究旨在解決這個研究缺口，並對這個領域做出兩項科學貢獻。首先，它提出一個多語言資料集，其中包含 60,127 則關於猴痘的 Instagram 貼文，這些貼文發布於 2022 年 7 月 23 日至 2024 年 9 月 5 日之間。此資料集可於 https://dx.doi.org/10.21227/7fvc-y093 取得，其中包含 52 種語言的關於猴痘的 Instagram 貼文。對於這些貼文中的每一則，貼文 ID、貼文說明、發布日期、語言和貼文的翻譯版本（翻譯成英文是使用 Google 翻譯 API 進行的）都會在資料集中以個別屬性的形式呈現。在建立此資料集後，執行了情緒分析、仇恨言論偵測，以及焦慮或壓力偵測。這個程序包含將每一則貼文分類為 (i) 一個情緒類別，例如恐懼、驚訝、快樂、悲傷、憤怒、厭惡或中立，(ii) 仇恨或非仇恨，以及 (iii) 偵測到焦慮/壓力或未偵測到焦慮/壓力。這些結果在資料集中以個別屬性的形式呈現。其次，本論文提出執行情緒分析、仇恨言論分析，以及焦慮或壓力分析的結果。觀察到情緒類別（恐懼、驚訝、快樂、悲傷、憤怒、厭惡和中立）的變化分別為 27.95%、2.57%、8.69%、5.94%、2.69%、1.53% 和 50.64%。在仇恨言論偵測方面，95.75% 的貼文不包含仇恨，其餘 4.25% 的貼文包含仇恨。最後，72.05% 的貼文沒有顯示任何焦慮/壓力，其餘 27.95% 的貼文則代表某種形式的焦慮/壓力。

##### **Seek and Solve Reasoning for Table Question Answering**
2409.05286v1 by Ruya Jiang, Chun Wang, Weihong Deng

Table-based Question Answering (TQA) involves answering questions based on
tabular data. The complexity of table structures and question logic makes this
task difficult even for Large Language Models (LLMs). This paper improves TQA
performance by leveraging LLMs' reasoning capabilities. Inspired by how humans
solve TQA tasks, we propose a Seek-and-Solve pipeline that instructs the LLM to
first seek relevant information and then answer questions. The two stages are
integrated at the reasoning level, and their Chain of Thought (CoT) paths are
integrated into a coherent Seek-and-Solve CoT (SS-CoT). Furthermore, we present
a compact single-stage TQA-solving prompt distilled from the pipeline.
Experiments demonstrate that under In-Context Learning settings, using samples
with SS-CoT paths as demonstrations, the TQA-solving prompt can effectively
guide the LLM to solve complex TQA tasks, resulting in improved performance and
reliability. Our results highlight the importance of properly eliciting LLMs'
reasoning capabilities in solving complex TQA tasks.

摘要：基於表格的问答 (TQA) 涉及根据表格数据回答问题。表格结构和问题逻辑的复杂性让这项任务即使对于大型语言模型 (LLM) 来说也很困难。本文通过利用 LLM 的推理能力来改善 TQA 性能。受人类解决 TQA 任务的方式启发，我们提出了一种寻求和解决管道，指示 LLM 先寻求相关信息，然后回答问题。这两个阶段在推理层面上进行整合，并且它们的思维链 (CoT) 路径被整合到一个连贯的寻求和解决 CoT (SS-CoT) 中。此外，我们提出了从管道中提取的紧凑型单阶段 TQA 求解提示。实验表明，在情境学习设置下，使用具有 SS-CoT 路径的样本作为演示，TQA 求解提示可以有效地指导 LLM 解决复杂 TQA 任务，从而提高性能和可靠性。我们的结果突出了在解决复杂 TQA 任务时正确激发 LLM 推理能力的重要性。

##### **On the Relationship between Truth and Political Bias in Language Models**
2409.05283v1 by Suyash Fulay, William Brannon, Shrestha Mohanty, Cassandra Overney, Elinor Poole-Dayan, Deb Roy, Jad Kabbara

Language model alignment research often attempts to ensure that models are
not only helpful and harmless, but also truthful and unbiased. However,
optimizing these objectives simultaneously can obscure how improving one aspect
might impact the others. In this work, we focus on analyzing the relationship
between two concepts essential in both language model alignment and political
science: \textit{truthfulness} and \textit{political bias}. We train reward
models on various popular truthfulness datasets and subsequently evaluate their
political bias. Our findings reveal that optimizing reward models for
truthfulness on these datasets tends to result in a left-leaning political
bias. We also find that existing open-source reward models (i.e. those trained
on standard human preference datasets) already show a similar bias and that the
bias is larger for larger models. These results raise important questions about
both the datasets used to represent truthfulness and what language models
capture about the relationship between truth and politics.

摘要：語言模型對齊研究通常試圖確保模型不僅有幫助且無害，而且真實且公正。然而，同時優化這些目標可能會模糊改善一個方面如何影響其他方面。在這項工作中，我們專注於分析語言模型對齊和政治科學中兩個基本概念之間的關係：\textit{真實性}和\textit{政治偏見}。我們在各種流行的真實性資料集上訓練獎勵模型，並隨後評估其政治偏見。我們的研究結果表明，在這些資料集上優化獎勵模型的真實性往往會導致左傾的政治偏見。我們還發現現有的開源獎勵模型（即在標準人類偏好資料集上訓練的模型）已經表現出類似的偏見，並且對於較大的模型，偏見更大。這些結果提出了關於用於表示真實性的資料集以及語言模型如何捕捉真實與政治之間關係的重要問題。

##### **RotCAtt-TransUNet++: Novel Deep Neural Network for Sophisticated Cardiac Segmentation**
2409.05280v1 by Quoc-Bao Nguyen-Le, Tuan-Hy Le, Anh-Triet Do, Quoc-Huy Trinh

Cardiovascular disease is a major global health concern, contributing
significantly to global mortality. Accurately segmenting cardiac medical
imaging data is crucial for reducing fatality rates associated with these
conditions. However, current state-of-the-art (SOTA) neural networks, including
CNN-based and Transformer-based approaches, face challenges in capturing both
inter-slice connections and intra-slice details, especially in datasets
featuring intricate, long-range details along the z-axis like coronary
arteries. Existing methods also struggle with differentiating non-cardiac
components from the myocardium, resulting in segmentation inaccuracies and the
"spraying" phenomenon. To address these issues, we introduce
RotCAtt-TransUNet++, a novel architecture designed for robust segmentation of
intricate cardiac structures. Our approach enhances global context modeling
through multiscale feature aggregation and nested skip connections in the
encoder. Transformer layers facilitate capturing intra-slice interactions,
while a rotatory attention mechanism handles inter-slice connectivity. A
channel-wise cross-attention gate integrates multiscale information and decoder
features, effectively bridging semantic gaps. Experimental results across
multiple datasets demonstrate superior performance over current methods,
achieving near-perfect annotation of coronary arteries and myocardium. Ablation
studies confirm that our rotatory attention mechanism significantly improves
segmentation accuracy by transforming embedded vectorized patches in semantic
dimensional space.

摘要：心血管疾病是全球主要的健康問題，對全球死亡率有顯著的影響。準確分割心臟醫學影像資料對於降低這些疾病相關的死亡率至關重要。然而，目前的先進神經網路，包括基於 CNN 和基於 Transformer 的方法，在擷取層間連接和層內細節方面面臨挑戰，特別是在具有沿著 z 軸的複雜、長程細節的資料集，例如冠狀動脈。現有方法也難以區分非心臟成分和心肌，導致分割不準確和「噴灑」現象。為了解決這些問題，我們引入了 RotCAtt-TransUNet++，一種專為複雜心臟結構的穩健分割而設計的新穎架構。我們的做法透過編碼器中的多尺度特徵聚合和巢狀跳躍連接增強了全局背景建模。Transformer 層促進擷取層內交互作用，而旋轉注意機制則處理層間連接。通道式交叉注意閘門整合了多尺度資訊和解碼器特徵，有效地彌合了語義差距。跨多個資料集的實驗結果證明了其優於目前方法的效能，實現了冠狀動脈和心肌的近乎完美的註解。消融研究證實，我們的旋轉注意機制透過轉換語義維度空間中的嵌入向量化補丁，顯著地提高了分割準確度。

##### **RexUniNLU: Recursive Method with Explicit Schema Instructor for Universal NLU**
2409.05275v1 by Chengyuan Liu, Shihang Wang, Fubang Zhao, Kun Kuang, Yangyang Kang, Weiming Lu, Changlong Sun, Fei Wu

Information Extraction (IE) and Text Classification (CLS) serve as the
fundamental pillars of NLU, with both disciplines relying on analyzing input
sequences to categorize outputs into pre-established schemas. However, there is
no existing encoder-based model that can unify IE and CLS tasks from this
perspective. To fully explore the foundation shared within NLU tasks, we have
proposed a Recursive Method with Explicit Schema Instructor for Universal NLU.
Specifically, we firstly redefine the true universal information extraction
(UIE) with a formal formulation that covers almost all extraction schemas,
including quadruples and quintuples which remain unsolved for previous UIE
models. Then, we expands the formulation to all CLS and multi-modal NLU tasks.
Based on that, we introduce RexUniNLU, an universal NLU solution that employs
explicit schema constraints for IE and CLS, which encompasses all IE and CLS
tasks and prevent incorrect connections between schema and input sequence. To
avoid interference between different schemas, we reset the position ids and
attention mask matrices. Extensive experiments are conducted on IE, CLS in both
English and Chinese, and multi-modality, revealing the effectiveness and
superiority. Our codes are publicly released.

摘要：資訊萃取 (IE) 和文字分類 (CLS) 是 NLU 的基本支柱，這兩個領域都依賴於分析輸入序列，將輸出分類到預先建立的架構中。然而，從這個角度來看，目前沒有現有的編碼器模型可以統一 IE 和 CLS 任務。為了充分探索 NLU 任務中共享的基礎，我們提出了具有明確架構指導的遞迴方法，用於通用 NLU。具體來說，我們首先使用涵蓋幾乎所有萃取架構的正式公式重新定義真正的通用資訊萃取 (UIE)，包括先前 UIE 模型仍無法解決的四元組和五元組。然後，我們將公式擴展到所有 CLS 和多模態 NLU 任務。基於此，我們引入了 RexUniNLU，這是一個通用 NLU 解决方案，採用明確的架構約束來進行 IE 和 CLS，涵蓋所有 IE 和 CLS 任務，並防止架構和輸入序列之間出現不正確的連接。為了避免不同架構之間的干擾，我們重設位置 ID 和注意力遮罩矩陣。在 IE、CLS（包括英文和中文）和多模態上進行了廣泛的實驗，揭示了其有效性和優越性。我們的程式碼已公開發布。

##### **Towards Automated Machine Learning Research**
2409.05258v1 by Shervin Ardeshir

This paper explores a top-down approach to automating incremental advances in
machine learning research through component-level innovation, facilitated by
Large Language Models (LLMs). Our framework systematically generates novel
components, validates their feasibility, and evaluates their performance
against existing baselines. A key distinction of this approach lies in how
these novel components are generated. Unlike traditional AutoML and NAS
methods, which often rely on a bottom-up combinatorial search over predefined,
hardcoded base components, our method leverages the cross-domain knowledge
embedded in LLMs to propose new components that may not be confined to any
hard-coded predefined set. By incorporating a reward model to prioritize
promising hypotheses, we aim to improve the efficiency of the hypothesis
generation and evaluation process. We hope this approach offers a new avenue
for exploration and contributes to the ongoing dialogue in the field.

摘要：本文探討一種自上而下的方法，透過元件層級的創新，利用大型語言模型 (LLM) 自動化機器學習研究中的漸進式進展。我們的架構系統性地產生新穎的元件，驗證其可行性，並評估其相對於現有基準的效能。此方法的一個關鍵區別在於如何產生這些新穎的元件。與傳統的 AutoML 和 NAS 方法不同，這些方法通常依賴於對預先定義的、硬編碼的基礎元件進行自下而上的組合搜尋，我們的的方法利用嵌入在 LLM 中的跨領域知識來提出可能不受限於任何硬編碼預定義集合的新元件。透過納入獎勵模型來優先考慮有希望的假設，我們旨在提高假設產生和評估過程的效率。我們希望這種方法能提供一個新的探索途徑，並對該領域的持續對話有所貢獻。

##### **Socially Responsible Data for Large Multilingual Language Models**
2409.05247v1 by Andrew Smart, Ben Hutchinson, Lameck Mbangula Amugongo, Suzanne Dikker, Alex Zito, Amber Ebinama, Zara Wudiri, Ding Wang, Erin van Liemt, João Sedoc, Seyi Olojo, Stanley Uwakwe, Edem Wornyo, Sonja Schmer-Galunder, Jamila Smith-Loud

Large Language Models (LLMs) have rapidly increased in size and apparent
capabilities in the last three years, but their training data is largely
English text. There is growing interest in multilingual LLMs, and various
efforts are striving for models to accommodate languages of communities outside
of the Global North, which include many languages that have been historically
underrepresented in digital realms. These languages have been coined as "low
resource languages" or "long-tail languages", and LLMs performance on these
languages is generally poor. While expanding the use of LLMs to more languages
may bring many potential benefits, such as assisting cross-community
communication and language preservation, great care must be taken to ensure
that data collection on these languages is not extractive and that it does not
reproduce exploitative practices of the past. Collecting data from languages
spoken by previously colonized people, indigenous people, and non-Western
languages raises many complex sociopolitical and ethical questions, e.g.,
around consent, cultural safety, and data sovereignty. Furthermore, linguistic
complexity and cultural nuances are often lost in LLMs. This position paper
builds on recent scholarship, and our own work, and outlines several relevant
social, cultural, and ethical considerations and potential ways to mitigate
them through qualitative research, community partnerships, and participatory
design approaches. We provide twelve recommendations for consideration when
collecting language data on underrepresented language communities outside of
the Global North.

摘要：大型語言模型 (LLM) 在過去三年中規模和明顯能力迅速提升，但其訓練資料主要是英文文本。對多語言 LLM 的興趣日益濃厚，而且各種努力都致力於建立模型以適應全球北方以外社群的語言，其中包含許多在數位領域中歷來代表性不足的語言。這些語言已被稱為「低資源語言」或「長尾語言」，而 LLM 在這些語言上的表現通常很差。雖然將 LLM 的使用擴展到更多語言可能會帶來許多潛在好處，例如協助跨社群溝通和語言保存，但必須非常小心，以確保對這些語言的資料收集並非剝削性的，而且不會重現過去的剝削行為。從過去被殖民的人、原住民和非西方語言所說的語言中收集資料會引發許多複雜的社會政治和倫理問題，例如，關於同意、文化安全和資料主權的問題。此外，語言複雜性和文化細微差別通常會在 LLM 中遺失。這份立場文件建立在最近的學術研究和我們自己的研究之上，並概述了幾個相關的社會、文化和倫理考量，以及透過質性研究、社群夥伴關係和參與式設計方法來減輕這些考量的潛在方法。我們提供了十二項建議，供在全球北方以外代表性不足的語言社群中收集語言資料時考慮。

##### **FedFT: Improving Communication Performance for Federated Learning with Frequency Space Transformation**
2409.05242v1 by Chamath Palihawadana, Nirmalie Wiratunga, Anjana Wijekoon, Harsha Kalutarage

Communication efficiency is a widely recognised research problem in Federated
Learning (FL), with recent work focused on developing techniques for efficient
compression, distribution and aggregation of model parameters between clients
and the server. Particularly within distributed systems, it is important to
balance the need for computational cost and communication efficiency. However,
existing methods are often constrained to specific applications and are less
generalisable. In this paper, we introduce FedFT (federated frequency-space
transformation), a simple yet effective methodology for communicating model
parameters in a FL setting. FedFT uses Discrete Cosine Transform (DCT) to
represent model parameters in frequency space, enabling efficient compression
and reducing communication overhead. FedFT is compatible with various existing
FL methodologies and neural architectures, and its linear property eliminates
the need for multiple transformations during federated aggregation. This
methodology is vital for distributed solutions, tackling essential challenges
like data privacy, interoperability, and energy efficiency inherent to these
environments. We demonstrate the generalisability of the FedFT methodology on
four datasets using comparative studies with three state-of-the-art FL
baselines (FedAvg, FedProx, FedSim). Our results demonstrate that using FedFT
to represent the differences in model parameters between communication rounds
in frequency space results in a more compact representation compared to
representing the entire model in frequency space. This leads to a reduction in
communication overhead, while keeping accuracy levels comparable and in some
cases even improving it. Our results suggest that this reduction can range from
5% to 30% per client, depending on dataset.

摘要：<paragraph>在联邦学习 (FL) 中，通信效率是一个广受认可的研究问题，最近的工作重点是开发用于在客户端和服务器之间高效压缩、分发和聚合模型参数的技术。特别是在分布式系统中，平衡计算成本和通信效率的需求非常重要。然而，现有方法通常受限于特定应用程序，并且通用性较差。在本文中，我们介绍了 FedFT（联邦频域空间变换），这是一种简单而有效的方法，用于在 FL 设置中通信模型参数。FedFT 使用离散余弦变换 (DCT) 在频域中表示模型参数，从而实现高效压缩并减少通信开销。FedFT 与各种现有的 FL 方法和神经架构兼容，其线性特性消除了在联邦聚合期间进行多次变换的需要。这种方法对于分布式解决方案至关重要，它解决了这些环境中固有的数据隐私、互操作性和能源效率等基本挑战。我们使用与三种最先进的 FL 基线（FedAvg、FedProx、FedSim）的比较研究，在四个数据集上展示了 FedFT 方法的通用性。我们的结果表明，使用 FedFT 在频域中表示通信轮次之间模型参数的差异，与在频域中表示整个模型相比，产生了更紧凑的表示。这减少了通信开销，同时保持了可比的准确性水平，在某些情况下甚至提高了准确性。我们的结果表明，这种减少幅度可以从每个客户端的 5% 到 30% 不等，具体取决于数据集。</paragraph>

##### **Exploring Intrinsic Language-specific Subspaces in Fine-tuning Multilingual Neural Machine Translation**
2409.05224v1 by Zhe Cao, Zhi Qu, Hidetaka Kamigaito, Taro Watanabe

Multilingual neural machine translation models support fine-tuning hundreds
of languages simultaneously. However, fine-tuning on full parameters solely is
inefficient potentially leading to negative interactions among languages. In
this work, we demonstrate that the fine-tuning for a language occurs in its
intrinsic language-specific subspace with a tiny fraction of entire parameters.
Thus, we propose language-specific LoRA to isolate intrinsic language-specific
subspaces. Furthermore, we propose architecture learning techniques and
introduce a gradual pruning schedule during fine-tuning to exhaustively explore
the optimal setting and the minimal intrinsic subspaces for each language,
resulting in a lightweight yet effective fine-tuning procedure. The
experimental results on a 12-language subset and a 30-language subset of
FLORES-101 show that our methods not only outperform full-parameter fine-tuning
up to 2.25 spBLEU scores but also reduce trainable parameters to $0.4\%$ for
high and medium-resource languages and $1.6\%$ for low-resource ones.

摘要：多語言神經機器翻譯模型同時支援數百種語言的微調。然而，僅針對完整參數進行微調效率低下，可能會導致語言之間產生負面互動。在這項工作中，我們證明了語言的微調發生在其內在語言特定子空間中，只佔整體參數的一小部分。因此，我們提出語言特定的 LoRA 來隔離內在語言特定子空間。此外，我們提出架構學習技術，並在微調期間引入漸進式修剪排程，以徹底探索每個語言的最佳設定和最小內在子空間，從而產生輕量級且有效的微調程序。在 FLORES-101 的 12 語言子集和 30 語言子集上的實驗結果表明，我們的模型不僅優於全參數微調，spBLEU 分數高達 2.25，而且將可訓練參數減少到高資源和中資源語言的 0.4%，以及低資源語言的 1.6%。

##### **Synthetic Tabular Data Generation for Class Imbalance and Fairness: A Comparative Study**
2409.05215v1 by Emmanouil Panagiotou, Arjun Roy, Eirini Ntoutsi

Due to their data-driven nature, Machine Learning (ML) models are susceptible
to bias inherited from data, especially in classification problems where class
and group imbalances are prevalent. Class imbalance (in the classification
target) and group imbalance (in protected attributes like sex or race) can
undermine both ML utility and fairness. Although class and group imbalances
commonly coincide in real-world tabular datasets, limited methods address this
scenario. While most methods use oversampling techniques, like interpolation,
to mitigate imbalances, recent advancements in synthetic tabular data
generation offer promise but have not been adequately explored for this
purpose. To this end, this paper conducts a comparative analysis to address
class and group imbalances using state-of-the-art models for synthetic tabular
data generation and various sampling strategies. Experimental results on four
datasets, demonstrate the effectiveness of generative models for bias
mitigation, creating opportunities for further exploration in this direction.

摘要：由於機器學習 (ML) 模型以資料為依據，因此容易受到資料中繼承的偏差影響，特別是在分類問題中，類別和群組不平衡的現象很普遍。類別不平衡（在分類目標中）和群組不平衡（在受保護的屬性中，例如性別或種族）會損害 ML 的效用和公平性。儘管類別和群組不平衡通常在現實世界的表格資料集中同時發生，但解決此情境的可用方法有限。雖然大多數方法都使用過採樣技術（例如插補）來減輕不平衡的現象，但合成表格資料生成方面的最新進展提供了希望，但尚未充分探索此目的。為此，本文進行比較分析，以使用最先進的合成表格資料生成模型和各種抽樣策略來解決類別和群組不平衡的問題。在四個資料集上的實驗結果證明了生成模型在偏差減緩方面的有效性，為進一步探索此方向創造了機會。

##### **ICML Topological Deep Learning Challenge 2024: Beyond the Graph Domain**
2409.05211v1 by Guillermo Bernárdez, Lev Telyatnikov, Marco Montagna, Federica Baccini, Mathilde Papillon, Miquel Ferriol-Galmés, Mustafa Hajij, Theodore Papamarkou, Maria Sofia Bucarelli, Olga Zaghen, Johan Mathe, Audun Myers, Scott Mahan, Hansen Lillemark, Sharvaree Vadgama, Erik Bekkers, Tim Doster, Tegan Emerson, Henry Kvinge, Katrina Agate, Nesreen K Ahmed, Pengfei Bai, Michael Banf, Claudio Battiloro, Maxim Beketov, Paul Bogdan, Martin Carrasco, Andrea Cavallo, Yun Young Choi, George Dasoulas, Matouš Elphick, Giordan Escalona, Dominik Filipiak, Halley Fritze, Thomas Gebhart, Manel Gil-Sorribes, Salvish Goomanee, Victor Guallar, Liliya Imasheva, Andrei Irimia, Hongwei Jin, Graham Johnson, Nikos Kanakaris, Boshko Koloski, Veljko Kovač, Manuel Lecha, Minho Lee, Pierrick Leroy, Theodore Long, German Magai, Alvaro Martinez, Marissa Masden, Sebastian Mežnar, Bertran Miquel-Oliver, Alexis Molina, Alexander Nikitin, Marco Nurisso, Matt Piekenbrock, Yu Qin, Patryk Rygiel, Alessandro Salatiello, Max Schattauer, Pavel Snopov, Julian Suk, Valentina Sánchez, Mauricio Tec, Francesco Vaccarino, Jonas Verhellen, Frederic Wantiez, Alexander Weers, Patrik Zajec, Blaž Škrlj, Nina Miolane

This paper describes the 2nd edition of the ICML Topological Deep Learning
Challenge that was hosted within the ICML 2024 ELLIS Workshop on
Geometry-grounded Representation Learning and Generative Modeling (GRaM). The
challenge focused on the problem of representing data in different discrete
topological domains in order to bridge the gap between Topological Deep
Learning (TDL) and other types of structured datasets (e.g. point clouds,
graphs). Specifically, participants were asked to design and implement
topological liftings, i.e. mappings between different data structures and
topological domains --like hypergraphs, or simplicial/cell/combinatorial
complexes. The challenge received 52 submissions satisfying all the
requirements. This paper introduces the main scope of the challenge, and
summarizes the main results and findings.

摘要：本文描述了 ICML 拓撲深度學習挑戰賽的第 2 版，該挑戰賽在 ICML 2024 ELLIS 幾何基礎表示學習和生成模型（GRaM）研討會中舉辦。挑戰賽專注於在不同的離散拓撲域中表示資料的問題，以縮小拓撲深度學習 (TDL) 和其他類型結構化資料集（例如點雲、圖形）之間的差距。具體來說，要求參與者設計和實作拓撲提升，即不同資料結構和拓撲域之間的對應——例如超圖形或單純/胞/組合複合物。挑戰賽收到了 52 份符合所有要求的提交。本文介紹了挑戰賽的主要範圍，並總結了主要結果和發現。

##### **Interactive Machine Teaching by Labeling Rules and Instances**
2409.05199v1 by Giannis Karamanolakis, Daniel Hsu, Luis Gravano

Weakly supervised learning aims to reduce the cost of labeling data by using
expert-designed labeling rules. However, existing methods require experts to
design effective rules in a single shot, which is difficult in the absence of
proper guidance and tooling. Therefore, it is still an open question whether
experts should spend their limited time writing rules or instead providing
instance labels via active learning. In this paper, we investigate how to
exploit an expert's limited time to create effective supervision. First, to
develop practical guidelines for rule creation, we conduct an exploratory
analysis of diverse collections of existing expert-designed rules and find that
rule precision is more important than coverage across datasets. Second, we
compare rule creation to individual instance labeling via active learning and
demonstrate the importance of both across 6 datasets. Third, we propose an
interactive learning framework, INTERVAL, that achieves efficiency by
automatically extracting candidate rules based on rich patterns (e.g., by
prompting a language model), and effectiveness by soliciting expert feedback on
both candidate rules and individual instances. Across 6 datasets, INTERVAL
outperforms state-of-the-art weakly supervised approaches by 7% in F1.
Furthermore, it requires as few as 10 queries for expert feedback to reach F1
values that existing active learning methods cannot match even with 100
queries.

摘要：弱监督学习旨在通过使用专家设计的标签规则来降低数据标记成本。然而，现有方法要求专家一次性设计有效的规则，这在缺乏适当指导和工具的情况下是困难的。因此，专家是否应该将有限的时间花在编写规则上，还是通过主动学习提供实例标签，仍然是一个悬而未决的问题。在本文中，我们研究如何利用专家的有限时间来创建有效的监督。首先，为了制定规则创建的实用指南，我们对现有的专家设计的规则的不同集合进行了探索性分析，发现规则精度比跨数据集的覆盖范围更重要。其次，我们将规则创建与通过主动学习进行的单个实例标记进行比较，并证明了两者在 6 个数据集中的重要性。第三，我们提出了一个交互式学习框架 INTERVAL，它通过基于丰富模式（例如，通过提示语言模型）自动提取候选规则，以及通过征求专家对候选规则和单个实例的反馈来实现有效性，从而实现效率。在 6 个数据集上，INTERVAL 在 F1 中比最先进的弱监督方法高出 7%。此外，它只需要 10 个查询就能获得专家反馈，以达到现有的主动学习方法即使有 100 个查询也无法匹配的 F1 值。

##### **Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?**
2409.05197v1 by Neeladri Bhuiya, Viktor Schlegel, Stefan Winkler

State-of-the-art Large Language Models (LLMs) are accredited with an
increasing number of different capabilities, ranging from reading
comprehension, over advanced mathematical and reasoning skills to possessing
scientific knowledge. In this paper we focus on their multi-hop reasoning
capability: the ability to identify and integrate information from multiple
textual sources.
  Given the concerns with the presence of simplifying cues in existing
multi-hop reasoning benchmarks, which allow models to circumvent the reasoning
requirement, we set out to investigate, whether LLMs are prone to exploiting
such simplifying cues. We find evidence that they indeed circumvent the
requirement to perform multi-hop reasoning, but they do so in more subtle ways
than what was reported about their fine-tuned pre-trained language model (PLM)
predecessors. Motivated by this finding, we propose a challenging multi-hop
reasoning benchmark, by generating seemingly plausible multi-hop reasoning
chains, which ultimately lead to incorrect answers. We evaluate multiple open
and proprietary state-of-the-art LLMs, and find that their performance to
perform multi-hop reasoning is affected, as indicated by up to 45% relative
decrease in F1 score when presented with such seemingly plausible alternatives.
We conduct a deeper analysis and find evidence that while LLMs tend to ignore
misleading lexical cues, misleading reasoning paths indeed present a
significant challenge.

摘要：最先进的大语言模型 (LLM) 被认为具有越来越多的不同能力，从阅读理解、高级数学和推理技能到拥有科学知识。在本文中，我们专注于它们的多跳推理能力：识别和整合来自多个文本来源的信息的能力。
鉴于现有的多跳推理基准中存在简化提示的问题，这些提示允许模型绕过推理要求，我们着手调查 LLM 是否容易利用此类简化提示。我们发现证据表明它们确实绕过了执行多跳推理的要求，但它们这样做的方式比针对经过微调的预训练语言模型 (PLM) 前辈所报告的更加微妙。受此发现的启发，我们提出了一个具有挑战性的多跳推理基准，通过生成看似合理的推理链，最终得出错误的答案。我们评估了多个开放且专有的最先进的 LLM，并发现它们执行多跳推理的性能受到影响，当提供如此看似合理的替代方案时，F1 分数最多会相对下降 45%。我们进行了更深入的分析，并找到了证据表明，虽然 LLM 倾向于忽略具有误导性的词汇提示，但具有误导性的推理路径确实构成了重大挑战。

##### **Insights from Benchmarking Frontier Language Models on Web App Code Generation**
2409.05177v1 by Yi Cui

This paper presents insights from evaluating 16 frontier large language
models (LLMs) on the WebApp1K benchmark, a test suite designed to assess the
ability of LLMs to generate web application code. The results reveal that while
all models possess similar underlying knowledge, their performance is
differentiated by the frequency of mistakes they make. By analyzing lines of
code (LOC) and failure distributions, we find that writing correct code is more
complex than generating incorrect code. Furthermore, prompt engineering shows
limited efficacy in reducing errors beyond specific cases. These findings
suggest that further advancements in coding LLM should emphasize on model
reliability and mistake minimization.

摘要：這篇論文提供對 16 個前沿大型語言模型 (LLM) 在 WebApp1K 基準上的評估見解，這是一個測試套件，旨在評估 LLM 生成網頁應用程式程式碼的能力。結果顯示，雖然所有模型都具備類似的基礎知識，但它們的效能卻因其錯誤頻率而有所不同。透過分析程式碼行數 (LOC) 和失敗分佈，我們發現撰寫正確的程式碼比產生不正確的程式碼更為複雜。此外，提示工程在減少特定案例以外的錯誤方面顯示出有限的功效。這些發現表明，編碼 LLM 的進一步進展應強調模型可靠性和錯誤最小化。

##### **OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs**
2409.05152v1 by Jintian Zhang, Cheng Peng, Mengshu Sun, Xiang Chen, Lei Liang, Zhiqiang Zhang, Jun Zhou, Huajun Chen, Ningyu Zhang

Despite the recent advancements in Large Language Models (LLMs), which have
significantly enhanced the generative capabilities for various NLP tasks, LLMs
still face limitations in directly handling retrieval tasks. However, many
practical applications demand the seamless integration of both retrieval and
generation. This paper introduces a novel and efficient One-pass Generation and
retrieval framework (OneGen), designed to improve LLMs' performance on tasks
that require both generation and retrieval. The proposed framework bridges the
traditionally separate training approaches for generation and retrieval by
incorporating retrieval tokens generated autoregressively. This enables a
single LLM to handle both tasks simultaneously in a unified forward pass. We
conduct experiments on two distinct types of composite tasks, RAG and Entity
Linking, to validate the pluggability, effectiveness, and efficiency of OneGen
in training and inference. Furthermore, our results show that integrating
generation and retrieval within the same context preserves the generative
capabilities of LLMs while improving retrieval performance. To the best of our
knowledge, OneGen is the first to enable LLMs to conduct vector retrieval
during the generation.

摘要：儘管大型語言模型 (LLM) 最近有了進展，大幅提升了各種自然語言處理任務的生成能力，但 LLM 在直接處理檢索任務方面仍有其限制。然而，許多實務應用都需要無縫整合檢索和生成。本文介紹一個新穎且有效的一遍生成和檢索架構 (OneGen)，旨在提升 LLM 在需要生成和檢索的任務上的效能。建議的架構透過整合自迴歸生成的檢索標記，來橋接傳統上生成和檢索的獨立訓練方法。這讓單一 LLM 能在統一的前向傳遞中同時處理這兩個任務。我們在兩種不同類型的複合任務（RAG 和實體連結）上進行實驗，以驗證 OneGen 在訓練和推理中的可插入性、有效性和效率。此外，我們的結果顯示，在同一個脈絡中整合生成和檢索，同時保留 LLM 的生成能力，並提升檢索效能。據我們所知，OneGen 是第一個讓 LLM 能在生成過程中執行向量檢索的模型。

##### **Better Spanish Emotion Recognition In-the-wild: Bringing Attention to Deep Spectrum Voice Analysis**
2409.05148v1 by Elena Ortega-Beltrán, Josep Cabacas-Maso, Ismael Benito-Altamirano, Carles Ventura

Within the context of creating new Socially Assistive Robots, emotion
recognition has become a key development factor, as it allows the robot to
adapt to the user's emotional state in the wild. In this work, we focused on
the analysis of two voice recording Spanish datasets: ELRA-S0329 and
EmoMatchSpanishDB. Specifically, we centered our work in the paralanguage,
e.~g. the vocal characteristics that go along with the message and clarifies
the meaning. We proposed the use of the DeepSpectrum method, which consists of
extracting a visual representation of the audio tracks and feeding them to a
pretrained CNN model. For the classification task, DeepSpectrum is often paired
with a Support Vector Classifier --DS-SVC--, or a Fully-Connected deep-learning
classifier --DS-FC--. We compared the results of the DS-SVC and DS-FC
architectures with the state-of-the-art (SOTA) for ELRA-S0329 and
EmoMatchSpanishDB. Moreover, we proposed our own classifier based upon
Attention Mechanisms, namely DS-AM. We trained all models against both
datasets, and we found that our DS-AM model outperforms the SOTA models for the
datasets and the SOTA DeepSpectrum architectures. Finally, we trained our DS-AM
model in one dataset and tested it in the other, to simulate real-world
conditions on how biased is the model to the dataset.

摘要：<paragraph>在創造新的社會輔助機器人的背景下，情緒辨識已成為一項關鍵的發展因素，因為它允許機器人在野外適應使用者的情緒狀態。在這項工作中，我們專注於分析兩個西班牙語語音錄製資料集：ELRA-S0329 和 EmoMatchSpanishDB。具體來說，我們的工作集中在旁語言，例如與訊息一起出現的語音特徵，並釐清其含義。我們建議使用 DeepSpectrum 方法，它包含提取音訊軌道的視覺表示，並將其提供給預訓練的 CNN 模型。對於分類任務，DeepSpectrum 通常與支援向量分類器 --DS-SVC-- 或全連接深度學習分類器 --DS-FC-- 配對。我們將 DS-SVC 和 DS-FC 架構的結果與 ELRA-S0329 和 EmoMatchSpanishDB 的最新技術 (SOTA) 進行比較。此外，我們提出了自己的基於注意力機制的分類器，即 DS-AM。我們針對兩個資料集訓練所有模型，我們發現我們的 DS-AM 模型優於資料集的 SOTA 模型和 SOTA DeepSpectrum 架構。最後，我們在一個資料集中訓練我們的 DS-AM 模型，並在另一個資料集中測試它，以模擬模型對資料集的偏見在現實世界中的情況。</paragraph>

##### **READoc: A Unified Benchmark for Realistic Document Structured Extraction**
2409.05137v1 by Zichao Li, Aizier Abulaiti, Yaojie Lu, Xuanang Chen, Jia Zheng, Hongyu Lin, Xianpei Han, Le Sun

Document Structured Extraction (DSE) aims to extract structured content from
raw documents. Despite the emergence of numerous DSE systems, their unified
evaluation remains inadequate, significantly hindering the field's advancement.
This problem is largely attributed to existing benchmark paradigms, which
exhibit fragmented and localized characteristics. To address these limitations
and offer a thorough evaluation of DSE systems, we introduce a novel benchmark
named READoc, which defines DSE as a realistic task of converting unstructured
PDFs into semantically rich Markdown. The READoc dataset is derived from 2,233
diverse and real-world documents from arXiv and GitHub. In addition, we develop
a DSE Evaluation S$^3$uite comprising Standardization, Segmentation and Scoring
modules, to conduct a unified evaluation of state-of-the-art DSE approaches. By
evaluating a range of pipeline tools, expert visual models, and general VLMs,
we identify the gap between current work and the unified, realistic DSE
objective for the first time. We aspire that READoc will catalyze future
research in DSE, fostering more comprehensive and practical solutions.

摘要：文件結構化萃取 (DSE) 的目標是從原始文件萃取結構化的內容。儘管有許多 DSE 系統出現，但它們的統一評估仍不充足，這顯著地阻礙了該領域的進步。這個問題在很大程度上歸因於現有的基準範例，它們表現出分散且局部的特徵。為了解決這些限制並提供對 DSE 系統的徹底評估，我們引入了一個名為 READoc 的新基準，它將 DSE 定義為將非結構化 PDF 轉換為語義豐富的 Markdown 的現實任務。READoc 資料集來自 arXiv 和 GitHub 中的 2,233 份多樣化且真實的文檔。此外，我們開發了一個 DSE 評估 S$^3$uite，包含標準化、分段和評分模組，以對最先進的 DSE 方法進行統一評估。透過評估一系列管道工具、專家視覺模型和一般 VLMs，我們首次找出目前工作與統一、現實的 DSE 目標之間的差距。我們期望 READoc 將催化 DSE 未來的研究，促進更全面且實用的解決方案。

##### **WaterSeeker: Efficient Detection of Watermarked Segments in Large Documents**
2409.05112v1 by Leyi Pan, Aiwei Liu, Yijian Lu, Zitian Gao, Yichen Di, Lijie Wen, Irwin King, Philip S. Yu

Watermarking algorithms for large language models (LLMs) have attained high
accuracy in detecting LLM-generated text. However, existing methods primarily
focus on distinguishing fully watermarked text from non-watermarked text,
overlooking real-world scenarios where LLMs generate only small sections within
large documents. In this scenario, balancing time complexity and detection
performance poses significant challenges. This paper presents WaterSeeker, a
novel approach to efficiently detect and locate watermarked segments amid
extensive natural text. It first applies an efficient anomaly extraction method
to preliminarily locate suspicious watermarked regions. Following this, it
conducts a local traversal and performs full-text detection for more precise
verification. Theoretical analysis and experimental results demonstrate that
WaterSeeker achieves a superior balance between detection accuracy and
computational efficiency. Moreover, WaterSeeker's localization ability supports
the development of interpretable AI detection systems. This work pioneers a new
direction in watermarked segment detection, facilitating more reliable
AI-generated content identification.

摘要：大型語言模型 (LLM) 的浮水印演算法已在偵測 LLM 生成的文字方面獲得很高的準確度。然而，現有方法主要著重於區分完全浮水印文字和非浮水印文字，忽略了 LLM 僅在大型文件中產生小部分區段的真實世界場景。在此場景中，平衡時間複雜度和偵測效能會造成重大挑戰。本文提出 WaterSeeker，一種新穎的方法，可有效偵測和定位廣泛自然文字中的浮水印區段。它首先套用一種有效異常萃取方法，以初步定位可疑的浮水印區域。接著，它執行局部遍歷並進行全文偵測，以進行更精確的驗證。理論分析和實驗結果證明，WaterSeeker 在偵測準確度和計算效率之間取得了優異的平衡。此外，WaterSeeker 的定位能力支援可解釋 AI 偵測系統的開發。這項工作開創了浮水印區段偵測的新方向，促成更可靠的 AI 生成內容識別。

##### **EdaCSC: Two Easy Data Augmentation Methods for Chinese Spelling Correction**
2409.05105v1 by Lei Sheng, Shuai-Shuai Xu

Chinese Spelling Correction (CSC) aims to detect and correct spelling errors
in Chinese sentences caused by phonetic or visual similarities. While current
CSC models integrate pinyin or glyph features and have shown significant
progress,they still face challenges when dealing with sentences containing
multiple typos and are susceptible to overcorrection in real-world scenarios.
In contrast to existing model-centric approaches, we propose two data
augmentation methods to address these limitations. Firstly, we augment the
dataset by either splitting long sentences into shorter ones or reducing typos
in sentences with multiple typos. Subsequently, we employ different training
processes to select the optimal model. Experimental evaluations on the SIGHAN
benchmarks demonstrate the superiority of our approach over most existing
models, achieving state-of-the-art performance on the SIGHAN15 test set.

摘要：中文拼寫校正（CSC）旨在偵測並修正中文句子中因注音或視覺相似性而產生的拼寫錯誤。雖然目前的 CSC 模型整合了注音或字形特徵，並已展現顯著進展，但它們在處理包含多個錯字的句子時仍面臨挑戰，且容易在實際場景中發生過度修正。與現有的以模型為中心的途徑不同，我們提出兩種資料擴充方法來解決這些限制。首先，我們透過將長句子拆分為較短的句子或減少包含多個錯字的句子中的錯字來擴充資料集。隨後，我們採用不同的訓練流程來選擇最佳模型。在 SIGHAN 基準上的實驗評估證明了我們的方法優於大多數現有模型，在 SIGHAN15 測試集中達到了最先進的效能。

##### **PIP: Detecting Adversarial Examples in Large Vision-Language Models via Attention Patterns of Irrelevant Probe Questions**
2409.05076v1 by Yudong Zhang, Ruobing Xie, Jiansheng Chen, Xingwu Sun, Yu Wang

Large Vision-Language Models (LVLMs) have demonstrated their powerful
multimodal capabilities. However, they also face serious safety problems, as
adversaries can induce robustness issues in LVLMs through the use of
well-designed adversarial examples. Therefore, LVLMs are in urgent need of
detection tools for adversarial examples to prevent incorrect responses. In
this work, we first discover that LVLMs exhibit regular attention patterns for
clean images when presented with probe questions. We propose an unconventional
method named PIP, which utilizes the attention patterns of one randomly
selected irrelevant probe question (e.g., "Is there a clock?") to distinguish
adversarial examples from clean examples. Regardless of the image to be tested
and its corresponding question, PIP only needs to perform one additional
inference of the image to be tested and the probe question, and then achieves
successful detection of adversarial examples. Even under black-box attacks and
open dataset scenarios, our PIP, coupled with a simple SVM, still achieves more
than 98% recall and a precision of over 90%. Our PIP is the first attempt to
detect adversarial attacks on LVLMs via simple irrelevant probe questions,
shedding light on deeper understanding and introspection within LVLMs. The code
is available at https://github.com/btzyd/pip.

摘要：大型視覺語言模型 (LVLMs) 已展現其強大的多模態能力。然而，它們也面臨嚴重的安全問題，因為對手可以透過使用精心設計的對抗範例，在 LVLMs 中引發健全性問題。因此，LVLMs 迫切需要對抗範例的偵測工具，以防止不正確的回應。在此研究中，我們首先發現當 LVLMs 面對探測問題時，它們會對乾淨的影像展現規律的注意力模式。我們提出一個名為 PIP 的非常規方法，它利用一個隨機選擇的不相關探測問題（例如「那裡有鐘嗎？」）的注意力模式，來區分對抗範例與乾淨範例。無論要測試的影像及其對應問題為何，PIP 只需要對要測試的影像和探測問題執行一次額外的推論，然後就能成功偵測對抗範例。即使在黑盒攻擊和開放資料集場景下，我們的 PIP 結合一個簡單的 SVM，仍可達到超過 98% 的召回率和超過 90% 的精確度。我們的 PIP 是第一個嘗試透過簡單的不相關探測問題來偵測 LVLMs 上的對抗攻擊，為 LVLMs 中更深入的理解和內省提供了啟發。程式碼可在 https://github.com/btzyd/pip 取得。

##### **A Survey on Diffusion Models for Recommender Systems**
2409.05033v1 by Jianghao Lin, Jiaqi Liu, Jiachen Zhu, Yunjia Xi, Chengkai Liu, Yangtian Zhang, Yong Yu, Weinan Zhang

While traditional recommendation techniques have made significant strides in
the past decades, they still suffer from limited generalization performance
caused by factors like inadequate collaborative signals, weak latent
representations, and noisy data. In response, diffusion models (DMs) have
emerged as promising solutions for recommender systems due to their robust
generative capabilities, solid theoretical foundations, and improved training
stability. To this end, in this paper, we present the first comprehensive
survey on diffusion models for recommendation, and draw a bird's-eye view from
the perspective of the whole pipeline in real-world recommender systems. We
systematically categorize existing research works into three primary domains:
(1) diffusion for data engineering & encoding, focusing on data augmentation
and representation enhancement; (2) diffusion as recommender models, employing
diffusion models to directly estimate user preferences and rank items; and (3)
diffusion for content presentation, utilizing diffusion models to generate
personalized content such as fashion and advertisement creatives. Our taxonomy
highlights the unique strengths of diffusion models in capturing complex data
distributions and generating high-quality, diverse samples that closely align
with user preferences. We also summarize the core characteristics of the
adapting diffusion models for recommendation, and further identify key areas
for future exploration, which helps establish a roadmap for researchers and
practitioners seeking to advance recommender systems through the innovative
application of diffusion models. To further facilitate the research community
of recommender systems based on diffusion models, we actively maintain a GitHub
repository for papers and other related resources in this rising direction
https://github.com/CHIANGEL/Awesome-Diffusion-for-RecSys.

摘要：<paragraph>儘管傳統的推薦技術在過去的幾十年中取得了顯著進展，但它們仍然因為諸如協作訊號不足、潛在表徵薄弱和資料雜訊等因素而導致概化效能受限。有鑑於此，擴散模型 (DM) 由於其強大的生成能力、穩固的理論基礎和改善的訓練穩定性，已成為推薦系統中極具前景的解決方案。為此，在本文中，我們提出了針對推薦系統的擴散模型的第一份全面調查，並從真實世界推薦系統中整個管線的角度描繪出全景。我們系統性地將現有的研究工作分類為三個主要領域：(1) 擴散用於資料工程和編碼，專注於資料擴充和表徵增強；(2) 擴散作為推薦模型，採用擴散模型直接估計使用者偏好和排名項目；以及 (3) 擴散用於內容呈現，利用擴散模型生成個人化內容，例如時尚和廣告創意。我們的分類法突顯了擴散模型在捕捉複雜資料分佈和生成與使用者偏好緊密對齊的高品質、多樣性樣本方面的獨特優勢。我們也總結了適應推薦系統的擴散模型的核心特徵，並進一步找出未來探索的關鍵領域，這有助於為尋求透過擴散模型的創新應用來推進推薦系統的研究人員和從業人員建立一個路線圖。為了進一步促進基於擴散模型的推薦系統研究社群，我們積極維護一個 GitHub 存放庫，用於收集此一新興領域的論文和其他相關資源 https://github.com/CHIANGEL/Awesome-Diffusion-for-RecSys。</paragraph>

##### **LLM-based Abstraction and Concretization for GUI Test Migration**
2409.05028v1 by Yakun Zhang, Chen Liu, Xiaofei Xie, Yun Lin, Jin Song Dong, Dan Hao, Lu Zhang

GUI test migration aims to produce test cases with events and assertions to
test specific functionalities of a target app. Existing migration approaches
typically focus on the widget-mapping paradigm that maps widgets from source
apps to target apps. However, since different apps may implement the same
functionality in different ways, direct mapping may result in incomplete or
buggy test cases, thus significantly impacting the effectiveness of testing
target functionality and the practical applicability.
  In this paper, we propose a new migration paradigm (i.e.,
abstraction-concretization paradigm) that first abstracts the test logic for
the target functionality and then utilizes this logic to generate the concrete
GUI test case. Furthermore, we introduce MACdroid, the first approach that
migrates GUI test cases based on this paradigm. Specifically, we propose an
abstraction technique that utilizes source test cases from source apps
targeting the same functionality to extract a general test logic for that
functionality. Then, we propose a concretization technique that utilizes the
general test logic to guide an LLM in generating the corresponding GUI test
case (including events and assertions) for the target app. We evaluate MACdroid
on two widely-used datasets (including 31 apps, 34 functionalities, and 123
test cases). On the FrUITeR dataset, the test cases generated by MACdroid
successfully test 64% of the target functionalities, improving the baselines by
191%. On the Lin dataset, MACdroid successfully tests 75% of the target
functionalities, outperforming the baselines by 42%. These results underscore
the effectiveness of MACdroid in GUI test migration.

摘要：GUI 測試遷移旨在產生測試案例，其中包含事件和斷言，以測試目標應用程式的特定功能。現有的遷移方法通常專注於小工具對應範例，該範例會將小工具從來源應用程式對應到目標應用程式。然而，由於不同的應用程式可能會以不同的方式實作相同的功能，因此直接對應可能會導致測試案例不完整或有錯誤，從而顯著影響測試目標功能和實際適用性的有效性。
在本文中，我們提出了一個新的遷移範例（即抽象化具體化範例），該範例首先抽象化目標功能的測試邏輯，然後利用此邏輯產生具體的 GUI 測試案例。此外，我們介紹了 MACdroid，這是第一個基於此範例遷移 GUI 測試案例的方法。具體來說，我們提出了一種抽象化技術，該技術利用來自針對相同功能的來源應用程式的來源測試案例，以提取該功能的一般測試邏輯。然後，我們提出了一種具體化技術，該技術利用一般測試邏輯來指導 LLM 為目標應用程式產生對應的 GUI 測試案例（包括事件和斷言）。我們在兩個廣泛使用的資料集（包括 31 個應用程式、34 個功能和 123 個測試案例）上評估 MACdroid。在 FrUITeR 資料集上，MACdroid 產生的測試案例成功測試了 64% 的目標功能，將基準提高了 191%。在 Lin 資料集上，MACdroid 成功測試了 75% 的目標功能，比基準高出 42%。這些結果強調了 MACdroid 在 GUI 測試遷移中的有效性。

##### **Sequential Recommendation via Adaptive Robust Attention with Multi-dimensional Embeddings**
2409.05022v1 by Linsey Pang, Amir Hossein Raffiee, Wei Liu, Keld Lundgaard

Sequential recommendation models have achieved state-of-the-art performance
using self-attention mechanism. It has since been found that moving beyond only
using item ID and positional embeddings leads to a significant accuracy boost
when predicting the next item. In recent literature, it was reported that a
multi-dimensional kernel embedding with temporal contextual kernels to capture
users' diverse behavioral patterns results in a substantial performance
improvement. In this study, we further improve the sequential recommender
model's robustness and generalization by introducing a mix-attention mechanism
with a layer-wise noise injection (LNI) regularization. We refer to our
proposed model as adaptive robust sequential recommendation framework (ADRRec),
and demonstrate through extensive experiments that our model outperforms
existing self-attention architectures.

摘要：序列推薦模型已經使用自注意力機制達到了最先進的效能。從那時起，人們發現僅使用項目 ID 和位置嵌入就已經可以顯著提升預測下一項目的準確度。在最近的文獻中，有報導指出，使用具有時間脈絡核的多維核嵌入來擷取使用者的各種行為模式，可以大幅提升效能。在本研究中，我們透過引入具有逐層雜訊注入 (LNI) 正則化的混合注意力機制，進一步提升序列推薦模型的穩健性和泛化性。我們將我們提出的模型稱為自適應穩健序列推薦架構 (ADRRec)，並透過廣泛的實驗證明我們的模型優於現有的自注意力架構。

##### **Vision-fused Attack: Advancing Aggressive and Stealthy Adversarial Text against Neural Machine Translation**
2409.05021v1 by Yanni Xue, Haojie Hao, Jiakai Wang, Qiang Sheng, Renshuai Tao, Yu Liang, Pu Feng, Xianglong Liu

While neural machine translation (NMT) models achieve success in our daily
lives, they show vulnerability to adversarial attacks. Despite being harmful,
these attacks also offer benefits for interpreting and enhancing NMT models,
thus drawing increased research attention. However, existing studies on
adversarial attacks are insufficient in both attacking ability and human
imperceptibility due to their sole focus on the scope of language. This paper
proposes a novel vision-fused attack (VFA) framework to acquire powerful
adversarial text, i.e., more aggressive and stealthy. Regarding the attacking
ability, we design the vision-merged solution space enhancement strategy to
enlarge the limited semantic solution space, which enables us to search for
adversarial candidates with higher attacking ability. For human
imperceptibility, we propose the perception-retained adversarial text selection
strategy to align the human text-reading mechanism. Thus, the finally selected
adversarial text could be more deceptive. Extensive experiments on various
models, including large language models (LLMs) like LLaMA and GPT-3.5, strongly
support that VFA outperforms the comparisons by large margins (up to 81%/14%
improvements on ASR/SSIM).

摘要：儘管神經機器翻譯 (NMT) 模型在我們的日常生活中取得成功，但它們對對抗攻擊顯示出脆弱性。儘管有害，但這些攻擊也為解釋和增強 NMT 模型提供了好處，從而引起越來越多的研究關注。然而，現有的對抗攻擊研究由於僅關注語言範圍，因此在攻擊能力和人類不可感知性方面均不足。本文提出了一個新穎的視覺融合攻擊 (VFA) 框架，以獲取強大的對抗文本，即更具攻擊性和隱蔽性。關於攻擊能力，我們設計了視覺合併解決方案空間增強策略，以擴大有限的語義解決方案空間，這使我們能夠搜尋具有更高攻擊能力的對抗候選者。對於人類的不可感知性，我們提出了感知保留對抗文本選擇策略，以調整人類文本閱讀機制。因此，最終選擇的對抗文本可能會更具欺騙性。在各種模型上進行的廣泛實驗，包括大型語言模型 (LLM)，例如 LLaMA 和 GPT-3.5，有力地證明 VFA 以很大的幅度優於比較（在 ASR/SSIM 上的改進幅度高達 81%/14%）。

##### **Audio-Guided Fusion Techniques for Multimodal Emotion Analysis**
2409.05007v1 by Pujin Shi, Fei Gao

In this paper, we propose a solution for the semi-supervised learning track
(MER-SEMI) in MER2024. First, in order to enhance the performance of the
feature extractor on sentiment classification tasks,we fine-tuned video and
text feature extractors, specifically CLIP-vit-large and Baichuan-13B, using
labeled data. This approach effectively preserves the original emotional
information conveyed in the videos. Second, we propose an Audio-Guided
Transformer (AGT) fusion mechanism, which leverages the robustness of
Hubert-large, showing superior effectiveness in fusing both inter-channel and
intra-channel information. Third, To enhance the accuracy of the model, we
iteratively apply self-supervised learning by using high-confidence unlabeled
data as pseudo-labels. Finally, through black-box probing, we discovered an
imbalanced data distribution between the training and test sets. Therefore, We
adopt a prior-knowledge-based voting mechanism. The results demonstrate the
effectiveness of our strategy, ultimately earning us third place in the
MER-SEMI track.

摘要：在本文中，我们针对 MER2024 中的半监督学习轨道 (MER-SEMI) 提出了一种解决方案。首先，为了提升特征提取器在情感分类任务中的性能，我们使用标记数据对视频和文本特征提取器（具体来说是 CLIP-vit-large 和 Baichuan-13B）进行了微调。这种方法有效地保留了视频中传达的原始情感信息。其次，我们提出了一种音频引导 Transformer (AGT) 融合机制，它利用了 Hubert-large 的鲁棒性，在融合通道间和通道内信息方面显示出卓越的有效性。第三，为了提高模型的准确性，我们通过使用高置信度未标记数据作为伪标签，迭代地应用自监督学习。最后，通过黑盒探测，我们发现训练集和测试集之间存在数据分布不平衡的问题。因此，我们采用基于先验知识的投票机制。结果证明了我们策略的有效性，最终让我们在 MER-SEMI 轨道中获得了第三名。

##### **Towards Patronizing and Condescending Language in Chinese Videos: A Multimodal Dataset and Detector**
2409.05005v1 by Hongbo Wang, Junyu Lu, Yan Han, Liang Yang, Hongfei Lin

Patronizing and Condescending Language (PCL) is a form of discriminatory
toxic speech targeting vulnerable groups, threatening both online and offline
safety. While toxic speech research has mainly focused on overt toxicity, such
as hate speech, microaggressions in the form of PCL remain underexplored.
Additionally, dominant groups' discriminatory facial expressions and attitudes
toward vulnerable communities can be more impactful than verbal cues, yet these
frame features are often overlooked. In this paper, we introduce the PCLMM
dataset, the first Chinese multimodal dataset for PCL, consisting of 715
annotated videos from Bilibili, with high-quality PCL facial frame spans. We
also propose the MultiPCL detector, featuring a facial expression detection
module for PCL recognition, demonstrating the effectiveness of modality
complementarity in this challenging task. Our work makes an important
contribution to advancing microaggression detection within the domain of toxic
speech.

摘要：**輕視和傲慢的語言 (PCL)** 是一種針對弱勢群體的歧視性有毒言論，威脅著線上和線下的安全。雖然有毒言論的研究主要集中在明顯的毒性，例如仇恨言論，但以 PCL 形式出現的微攻擊仍然未被充分探討。此外，支配群體對弱勢群體的歧視性面部表情和態度可能比言語暗示更具影響力，但這些框架特徵卻經常被忽視。在本文中，我們介紹了 PCLMM 資料集，這是第一個中文 PCL 多模態資料集，包含來自 Bilibili 的 715 個註解影片，以及高品質的 PCL 面部框架跨度。我們還提出了 MultiPCL 偵測器，其中包含一個用於 PCL 識別的面部表情偵測模組，證明了在這個具有挑戰性的任務中模態互補的有效性。我們的研究為在有毒言論領域中推進微攻擊偵測做出了重要的貢獻。

##### **A Pair Programming Framework for Code Generation via Multi-Plan Exploration and Feedback-Driven Refinement**
2409.05001v1 by Huan Zhang, Wei Cheng, Yuhan Wu, Wei Hu

Large language models (LLMs) have achieved impressive performance on code
generation. Although prior studies enhanced LLMs with prompting techniques and
code refinement, they still struggle with complex programming problems due to
rigid solution plans. In this paper, we draw on pair programming practices to
propose PairCoder, a novel LLM-based framework for code generation. PairCoder
incorporates two collaborative LLM agents, namely a Navigator agent for
high-level planning and a Driver agent for specific implementation. The
Navigator is responsible for proposing promising solution plans, selecting the
current optimal plan, and directing the next iteration round based on execution
feedback. The Driver follows the guidance of Navigator to undertake initial
code generation, code testing, and refinement. This interleaved and iterative
workflow involves multi-plan exploration and feedback-based refinement, which
mimics the collaboration of pair programmers. We evaluate PairCoder with both
open-source and closed-source LLMs on various code generation benchmarks.
Extensive experimental results demonstrate the superior accuracy of PairCoder,
achieving relative pass@1 improvements of 12.00%-162.43% compared to prompting
LLMs directly.

摘要：大型語言模型 (LLM) 在程式碼生成方面取得了令人印象深刻的表現。儘管先前的研究透過提示技術和程式碼精煉來增強 LLM，但由於僵化的解決方案規劃，它們在處理複雜的程式設計問題時仍面臨困難。在本文中，我們借鑑結對程式設計實務，提出 PairCoder，這是一個基於 LLM 的程式碼生成新框架。PairCoder 結合了兩個協作 LLM 代理，分別是負責高層級規劃的 Navigator 代理和負責具體實作的 Driver 代理。Navigator 負責提出有前景的解決方案規劃、選擇當前最佳規劃，並根據執行回饋引導下一次反覆運算。Driver 遵循 Navigator 的指導進行初始程式碼生成、程式碼測試和精煉。這個交錯且反覆運算的工作流程涉及多重規劃探索和基於回饋的精煉，模擬了結對程式設計師的協作。我們在各種程式碼生成基準上使用開源和閉源 LLM 評估 PairCoder。大量的實驗結果證明了 PairCoder 的優異準確性，與直接提示 LLM 相比，相對 pass@1 提升了 12.00%-162.43%。

##### **InstInfer: In-Storage Attention Offloading for Cost-Effective Long-Context LLM Inference**
2409.04992v1 by Xiurui Pan, Endian Li, Qiao Li, Shengwen Liang, Yizhou Shan, Ke Zhou, Yingwei Luo, Xiaolin Wang, Jie Zhang

The widespread of Large Language Models (LLMs) marks a significant milestone
in generative AI. Nevertheless, the increasing context length and batch size in
offline LLM inference escalate the memory requirement of the key-value (KV)
cache, which imposes a huge burden on the GPU VRAM, especially for
resource-constraint scenarios (e.g., edge computing and personal devices).
Several cost-effective solutions leverage host memory or SSDs to reduce storage
costs for offline inference scenarios and improve the throughput. Nevertheless,
they suffer from significant performance penalties imposed by intensive KV
cache accesses due to limited PCIe bandwidth. To address these issues, we
propose InstInfer, a novel LLM inference system that offloads the most
performance-critical computation (i.e., attention in decoding phase) and data
(i.e., KV cache) parts to Computational Storage Drives (CSDs), which minimize
the enormous KV transfer overheads. InstInfer designs a dedicated flash-aware
in-storage attention engine with KV cache management mechanisms to exploit the
high internal bandwidths of CSDs instead of being limited by the PCIe
bandwidth. The optimized P2P transmission between GPU and CSDs further reduces
data migration overheads. Experimental results demonstrate that for a 13B model
using an NVIDIA A6000 GPU, InstInfer improves throughput for long-sequence
inference by up to 11.1$\times$, compared to existing SSD-based solutions such
as FlexGen.

摘要：大型語言模型 (LLM) 的廣泛使用標誌著生成式 AI 的一個重要里程碑。然而，離線 LLM 推論中不斷增加的內容長度和批次大小會提升快取值 (KV) 的記憶體需求，這對 GPU VRAM 造成極大的負擔，特別是在資源受限的情況下（例如，邊緣運算和個人裝置）。幾個具有成本效益的解決方案利用主機記憶體或 SSD 來降低離線推論場景的儲存成本並改善吞吐量。然而，由於有限的 PCIe 頻寬，它們會受到密集 KV 快取存取所造成的顯著效能損失。為了解決這些問題，我們提出 InstInfer，一個新穎的 LLM 推論系統，它將效能最關鍵的運算（即解碼階段的注意力）和資料（即 KV 快取）部分卸載到運算儲存磁碟機 (CSD)，這將龐大的 KV 傳輸開銷降到最低。InstInfer 設計了一個專用的快閃記憶體感知的儲存內注意力引擎，具備 KV 快取管理機制，以利用 CSD 的高內部頻寬，而不是受到 PCIe 頻寬的限制。GPU 和 CSD 之間最佳化的 P2P 傳輸進一步降低了資料遷移開銷。實驗結果表明，對於使用 NVIDIA A6000 GPU 的 13B 模型，與現有的基於 SSD 的解決方案（例如 FlexGen）相比，InstInfer 將長序列推論的吞吐量提升了 11.1 倍。

##### **Enhancing Convolutional Neural Networks with Higher-Order Numerical Difference Methods**
2409.04977v1 by Qi Wang, Zijun Gao, Mingxiu Sui, Taiyuan Mei, Xiaohan Cheng, Iris Li

With the rise of deep learning technology in practical applications,
Convolutional Neural Networks (CNNs) have been able to assist humans in solving
many real-world problems. To enhance the performance of CNNs, numerous network
architectures have been explored. Some of these architectures are designed
based on the accumulated experience of researchers over time, while others are
designed through neural architecture search methods. The improvements made to
CNNs by the aforementioned methods are quite significant, but most of the
improvement methods are limited in reality by model size and environmental
constraints, making it difficult to fully realize the improved performance. In
recent years, research has found that many CNN structures can be explained by
the discretization of ordinary differential equations. This implies that we can
design theoretically supported deep network structures using higher-order
numerical difference methods. It should be noted that most of the previous CNN
model structures are based on low-order numerical methods. Therefore,
considering that the accuracy of linear multi-step numerical difference methods
is higher than that of the forward Euler method, this paper proposes a stacking
scheme based on the linear multi-step method. This scheme enhances the
performance of ResNet without increasing the model size and compares it with
the Runge-Kutta scheme. The experimental results show that the performance of
the stacking scheme proposed in this paper is superior to existing stacking
schemes (ResNet and HO-ResNet), and it has the capability to be extended to
other types of neural networks.

摘要：隨著深度學習技術在實際應用中的興起，
卷積神經網路 (CNN) 已能協助人類解決
許多真實世界中的問題。為了提升 CNN 的效能，
無數的網路架構已被探討。其中一些架構是
基於研究人員隨著時間累積的經驗所設計，而其他
則是透過神經架構搜尋方法所設計。前述方法對
CNN 所做的改良相當顯著，但大多數的改良方法在
現實中受到模型大小與環境限制，難以完全發揮
改良後的效能。近年來，研究發現許多 CNN 結構
可以用常微分方程式的離散化來解釋。這意味著我們
可以使用高階數值差分方法來設計有理論依據的深度網路架構。
值得注意的是，大多數先前的 CNN 模型結構都是
基於低階數值方法。因此，考量線性多步數值差分方法
的準確度高於前進歐拉法，本論文提出一個基於線性
多步數值差分方法的堆疊架構。此架構在不增加模型
大小的情況下提升 ResNet 的效能，並與 Runge-Kutta
架構進行比較。實驗結果顯示，本論文提出的堆疊
架構效能優於現有的堆疊架構（ResNet 和 HO-ResNet），
且有能力延伸至其他類型的類神經網路。

##### **Evaluation of Google Translate for Mandarin Chinese translation using sentiment and semantic analysis**
2409.04964v1 by Xuechun Wang, Rodney Beard, Rohitash Chandra

Machine translation using large language models (LLMs) is having a
significant global impact, making communication easier. Mandarin Chinese is the
official language used for communication by the government, education
institutes, and media in China. In this study, we provide an automated
assessment of machine translation models with human experts using sentiment and
semantic analysis. In order to demonstrate our framework, we select classic
early twentieth-century novel 'The True Story of Ah Q' with selected Mandarin
Chinese to English translations. We also us Google Translate to generate the
given text into English and then conduct a chapter-wise sentiment analysis and
semantic analysis to compare the extracted sentiments across the different
translations. We utilise LLMs for semantic and sentiment analysis. Our results
indicate that the precision of Google Translate differs both in terms of
semantic and sentiment analysis when compared to human expert translations. We
find that Google Translate is unable to translate some of the specific words or
phrases in Chinese, such as Chinese traditional allusions. The mistranslations
have to its lack of contextual significance and historical knowledge of China.
Thus, this framework brought us some new insights about machine translation for
Chinese Mandarin. The future work can explore other languages or types of texts
with this framework.

摘要：使用大型語言模型 (LLM) 的機器翻譯具有重大全球影響，讓溝通變得更輕鬆。中文是中國政府、教育機構和媒體用於溝通的官方語言。在本研究中，我們使用情緒和語義分析，提供由人類專家進行的機器翻譯模型自動評估。為了展示我們的架構，我們選擇了 20 世紀初的經典小說《阿 Q 正傳》，並選取了中文對應的英文翻譯。我們還使用 Google 翻譯將給定的文字轉換為英文，然後進行逐章情緒分析和語義分析，以比較不同翻譯中提取的情緒。我們利用 LLM 進行語義和情緒分析。我們的結果表明，與人類專家翻譯相比，Google 翻譯在語義和情緒分析方面的準確度不同。我們發現 Google 翻譯無法翻譯中文中的某些特定字詞或短語，例如中國傳統典故。翻譯錯誤是因為它缺乏中國的背景意義和歷史知識。因此，這個架構為我們帶來了關於中文機器翻譯的一些新見解。未來的研究可以利用這個架構探討其他語言或類型的文本。

##### **DDNet: Deformable Convolution and Dense FPN for Surface Defect Detection in Recycled Books**
2409.04958v1 by Jun Yu, WenJian Wang

Recycled and recirculated books, such as ancient texts and reused textbooks,
hold significant value in the second-hand goods market, with their worth
largely dependent on surface preservation. However, accurately assessing
surface defects is challenging due to the wide variations in shape, size, and
the often imprecise detection of defects. To address these issues, we propose
DDNet, an innovative detection model designed to enhance defect localization
and classification. DDNet introduces a surface defect feature extraction module
based on a deformable convolution operator (DC) and a densely connected FPN
module (DFPN). The DC module dynamically adjusts the convolution grid to better
align with object contours, capturing subtle shape variations and improving
boundary delineation and prediction accuracy. Meanwhile, DFPN leverages dense
skip connections to enhance feature fusion, constructing a hierarchical
structure that generates multi-resolution, high-fidelity feature maps, thus
effectively detecting defects of various sizes. In addition to the model, we
present a comprehensive dataset specifically curated for surface defect
detection in recycled and recirculated books. This dataset encompasses a
diverse range of defect types, shapes, and sizes, making it ideal for
evaluating the robustness and effectiveness of defect detection models. Through
extensive evaluations, DDNet achieves precise localization and classification
of surface defects, recording a mAP value of 46.7% on our proprietary dataset -
an improvement of 14.2% over the baseline model - demonstrating its superior
detection capabilities.

摘要：再利用和再循環的書籍，例如古籍和再利用的教科書，在二手商品市場中具有重要的價值，其價值在很大程度上取決於表面保存狀況。然而，由於形狀、大小變化很大，且缺陷檢測通常不精確，因此準確評估表面缺陷具有挑戰性。為了解決這些問題，我們提出了 DDNet，這是一種創新的檢測模型，旨在增強缺陷定位和分類。DDNet 引入了基於可變形卷積運算子 (DC) 和密集連接 FPN 模塊 (DFPN) 的表面缺陷特徵提取模塊。DC 模塊動態調整卷積網格以更好地與對象輪廓對齊，捕捉微妙的形狀變化並改善邊界描繪和預測精度。與此同時，DFPN 利用密集跳躍連接增強特徵融合，構建一個生成多解析度、高保真特徵圖的層次結構，從而有效檢測各種尺寸的缺陷。除了模型之外，我們還提供了一個專門為再利用和再循環書籍中的表面缺陷檢測而策劃的綜合數據集。該數據集涵蓋了各種缺陷類型、形狀和尺寸，非常適合評估缺陷檢測模型的魯棒性和有效性。通過廣泛的評估，DDNet 在我們的專有數據集上實現了表面缺陷的精確定位和分類，記錄了 46.7% 的 mAP 值——比基準模型提高了 14.2%——證明了其卓越的檢測能力。

##### **Evaluating Neural Networks Architectures for Spring Reverb Modelling**
2409.04953v1 by Francesco Papaleo, Xavier Lizarraga-Seijas, Frederic Font

Reverberation is a key element in spatial audio perception, historically
achieved with the use of analogue devices, such as plate and spring reverb, and
in the last decades with digital signal processing techniques that have allowed
different approaches for Virtual Analogue Modelling (VAM). The
electromechanical functioning of the spring reverb makes it a nonlinear system
that is difficult to fully emulate in the digital domain with white-box
modelling techniques. In this study, we compare five different neural network
architectures, including convolutional and recurrent models, to assess their
effectiveness in replicating the characteristics of this audio effect. The
evaluation is conducted on two datasets at sampling rates of 16 kHz and 48 kHz.
This paper specifically focuses on neural audio architectures that offer
parametric control, aiming to advance the boundaries of current black-box
modelling techniques in the domain of spring reverberation.

摘要：混響是空間音訊感知中的關鍵元素，過去透過類比裝置（例如板簧混響器）來達成，而在近幾十年來則使用數位訊號處理技術，為虛擬類比建模 (VAM) 提供不同的方法。彈簧混響器的機電運作使其成為一個非線性系統，難以使用白盒建模技術在數位領域中完全模擬。在本研究中，我們比較了五種不同的神經網路架構，包括卷積模型和遞迴模型，以評估其在複製此音效特性的有效性。評估在兩個資料集上進行，採樣率為 16 kHz 和 48 kHz。本文特別關注提供參數控制的神經音訊架構，旨在推進彈簧混響領域中現有黑盒建模技術的界限。

##### **Attention-Based Efficient Breath Sound Removal in Studio Audio Recordings**
2409.04949v1 by Nidula Elgiriyewithana, N. D. Kodikara

In this research, we present an innovative, parameter-efficient model that
utilizes the attention U-Net architecture for the automatic detection and
eradication of non-speech vocal sounds, specifically breath sounds, in vocal
recordings. This task is of paramount importance in the field of sound
engineering, despite being relatively under-explored. The conventional manual
process for detecting and eliminating these sounds requires significant
expertise and is extremely time-intensive. Existing automated detection and
removal methods often fall short in terms of efficiency and precision. Our
proposed model addresses these limitations by offering a streamlined process
and superior accuracy, achieved through the application of advanced deep
learning techniques. A unique dataset, derived from Device and Produced Speech
(DAPS), was employed for this purpose. The training phase of the model
emphasizes a log spectrogram and integrates an early stopping mechanism to
prevent overfitting. Our model not only conserves precious time for sound
engineers but also enhances the quality and consistency of audio production.
This constitutes a significant breakthrough, as evidenced by its comparative
efficiency, necessitating only 1.9M parameters and a training duration of 3.2
hours - markedly less than the top-performing models in this domain. The model
is capable of generating identical outputs as previous models with drastically
improved precision, making it an optimal choice.

摘要：在本次研究中，我们提出了一种创新的、参数高效的模型，该模型利用注意力 U-Net 架构对非言语声乐声音（特别是呼吸声）进行自动检测和消除。尽管该任务在声音工程领域至关重要，但相对而言却鲜有探索。检测和消除这些声音的传统手动流程需要大量的专业知识，而且极其耗时。现有的自动化检测和消除方法在效率和精度方面常常有不足之处。我们提出的模型通过提供简化的流程和卓越的准确性来解决这些限制，而这些都是通过应用先进的深度学习技术实现的。为此，我们采用了从设备和产生的语音 (DAPS) 中提取的独特数据集。该模型的训练阶段强调对数频谱图，并集成了早期停止机制以防止过拟合。我们的模型不仅为声音工程师节省了宝贵的时间，还提高了音频制作的质量和一致性。这构成了一个重大的突破，其比较效率证明了这一点，它仅需要 190 万个参数和 3.2 小时的训练持续时间 - 明显少于该领域中性能最佳的模型。该模型能够生成与先前模型相同的输出，同时大幅提高了精度，使其成为最佳选择。

##### **Maximizing Relation Extraction Potential: A Data-Centric Study to Unveil Challenges and Opportunities**
2409.04934v1 by Anushka Swarup, Avanti Bhandarkar, Olivia P. Dizon-Paradis, Ronald Wilson, Damon L. Woodard

Relation extraction is a Natural Language Processing task aiming to extract
relationships from textual data. It is a critical step for information
extraction. Due to its wide-scale applicability, research in relation
extraction has rapidly scaled to using highly advanced neural networks. Despite
their computational superiority, modern relation extractors fail to handle
complicated extraction scenarios. However, a comprehensive performance analysis
of the state-of-the-art relation extractors that compile these challenges has
been missing from the literature, and this paper aims to bridge this gap. The
goal has been to investigate the possible data-centric characteristics that
impede neural relation extraction. Based on extensive experiments conducted
using 15 state-of-the-art relation extraction algorithms ranging from recurrent
architectures to large language models and seven large-scale datasets, this
research suggests that modern relation extractors are not robust to complex
data and relation characteristics. It emphasizes pivotal issues, such as
contextual ambiguity, correlating relations, long-tail data, and fine-grained
relation distributions. In addition, it sets a marker for future directions to
alleviate these issues, thereby proving to be a critical resource for novice
and advanced researchers. Efficient handling of the challenges described can
have significant implications for the field of information extraction, which is
a critical part of popular systems such as search engines and chatbots. Data
and relevant code can be found at https://github.com/anushkasw/MaxRE.

摘要：關係萃取是一項自然語言處理任務，旨在從文本資料中萃取關係。這是資訊萃取的關鍵步驟。由於其廣泛的適用性，關係萃取的研究已迅速擴展到使用高度先進的神經網路。儘管它們在計算上具有優越性，但現代關係萃取器無法處理複雜的萃取場景。然而，文獻中缺少彙編這些挑戰的最新關係萃取器的全面效能分析，而本文旨在彌合這一差距。目標一直是調查可能阻礙神經關係萃取的以資料為中心的特徵。根據使用 15 種最新關係萃取演算法進行的廣泛實驗，從遞迴架構到大型語言模型和七個大型資料集，這項研究表明，現代關係萃取器無法應對複雜的資料和關係特徵。它強調了關鍵問題，例如上下文模糊性、相關關係、長尾資料和細粒度關係分佈。此外，它為緩解這些問題設定了一個未來方向標記，從而證明它是初學者和高級研究人員的重要資源。對所描述挑戰的有效處理可能對資訊萃取領域產生重大影響，而資訊萃取領域是搜尋引擎和聊天機器人等熱門系統的重要組成部分。資料和相關程式碼可在 https://github.com/anushkasw/MaxRE 中找到。

##### **Just ASR + LLM? A Study on Speech Large Language Models' Ability to Identify and Understand Speaker in Spoken Dialogue**
2409.04927v1 by Junkai Wu, Xulin Fan, Bo-Ru Lu, Xilin Jiang, Nima Mesgarani, Mark Hasegawa-Johnson, Mari Ostendorf

In recent years, we have observed a rapid advancement in speech language
models (SpeechLLMs), catching up with humans' listening and reasoning
abilities. Remarkably, SpeechLLMs have demonstrated impressive spoken dialogue
question-answering (SQA) performance in benchmarks like Gaokao, the English
listening test of the college entrance exam in China, which seemingly requires
understanding both the spoken content and voice characteristics of speakers in
a conversation. However, after carefully examining Gaokao's questions, we find
the correct answers to many questions can be inferred from the conversation
context alone without identifying the speaker asked in the question. Our
evaluation of state-of-the-art models Qwen-Audio and WavLLM in both Gaokao and
our proposed "What Do You Like?" dataset shows a significantly higher accuracy
in these context-based questions than in identity-critical questions, which can
only be answered correctly with correct speaker identification. Our results and
analysis suggest that when solving SQA, the current SpeechLLMs exhibit limited
speaker awareness from the audio and behave similarly to an LLM reasoning from
the conversation transcription without sound. We propose that our definitions
and automated classification of context-based and identity-critical questions
could offer a more accurate evaluation framework of SpeechLLMs in SQA tasks.

摘要：近年来，我们观察到语音语言模型（SpeechLLM）快速进步，赶上了人类的听力和推理能力。值得注意的是，SpeechLLM 在基准测试中展示了令人印象深刻的口语对话问答（SQA）表现，例如高考，这是中国大学入学考试的英语听力测试，它似乎需要理解对话中说话者的口语内容和声音特征。然而，在仔细审阅高考题目后，我们发现许多题目的正确答案可以仅从对话语境中推断出来，而无需识别问题中询问的说话者。我们对最先进的模型 Qwen-Audio 和 WavLLM 在高考和我们提出的“你喜欢什么？”数据集中的评估表明，这些基于上下文的题目比在身份关键题目中准确度高得多，而后者只有在正确识别说话者后才能正确回答。我们的结果和分析表明，在解决 SQA 时，当前的 SpeechLLM 从音频中表现出有限的说话者意识，并且在没有声音的情况下从对话转录中推理时表现得类似于 LLM。我们建议，我们对基于上下文和身份关键问题的定义和自动分类可以为 SQA 任务中的 SpeechLLM 提供更准确的评估框架。

##### **A $Δ$-evaluation function for column permutation problems**
2409.04926v1 by Júnior R. Lima, Viníicius Gandra M. Santos, Marco Antonio M. Carvalho

In this study, a new $\Delta$-evaluation method is introduced for solving a
column permutation problem defined on a sparse binary matrix with the
consecutive ones property. This problem models various $\mathcal{NP}$-hard
problems in graph theory and industrial manufacturing contexts. The
computational experiments compare the processing time of the
$\Delta$-evaluation method with two other methods used in well-known local
search procedures. The study considers a comprehensive set of instances of
well-known problems, such as Gate Matrix Layout and Minimization of Open
Stacks. The proposed evaluation method is generally competitive and
particularly useful for large and dense instances. It can be easily integrated
into local search and metaheuristic algorithms to improve solutions without
significantly increasing processing time.

摘要：本研究引入一種新的 $\Delta$-評估方法，用於解決在具有連續 1 屬性的稀疏二進位矩陣上定義的列置換問題。此問題對圖論和工業製造背景中的各種 $\mathcal{NP}$-hard 問題進行建模。計算實驗比較了 $\Delta$-評估方法與眾所周知的局部搜索程序中使用的其他兩種方法的處理時間。本研究考慮了一組著名的問題實例，例如閘極矩陣佈局和最小化開放堆疊。所提出的評估方法通常具有競爭力，特別適用於大型和密集實例。它可以輕鬆整合到局部搜索和元啟發式演算法中，以改善解決方案，而不會顯著增加處理時間。

##### **MoistNet: Machine Vision-based Deep Learning Models for Wood Chip Moisture Content Measurement**
2409.04920v1 by Abdur Rahman, Jason Street, James Wooten, Mohammad Marufuzzaman, Veera G. Gude, Randy Buchanan, Haifeng Wang

Quick and reliable measurement of wood chip moisture content is an
everlasting problem for numerous forest-reliant industries such as biofuel,
pulp and paper, and bio-refineries. Moisture content is a critical attribute of
wood chips due to its direct relationship with the final product quality.
Conventional techniques for determining moisture content, such as oven-drying,
possess some drawbacks in terms of their time-consuming nature, potential
sample damage, and lack of real-time feasibility. Furthermore, alternative
techniques, including NIR spectroscopy, electrical capacitance, X-rays, and
microwaves, have demonstrated potential; nevertheless, they are still
constrained by issues related to portability, precision, and the expense of the
required equipment. Hence, there is a need for a moisture content determination
method that is instant, portable, non-destructive, inexpensive, and precise.
This study explores the use of deep learning and machine vision to predict
moisture content classes from RGB images of wood chips. A large-scale image
dataset comprising 1,600 RGB images of wood chips has been collected and
annotated with ground truth labels, utilizing the results of the oven-drying
technique. Two high-performing neural networks, MoistNetLite and MoistNetMax,
have been developed leveraging Neural Architecture Search (NAS) and
hyperparameter optimization. The developed models are evaluated and compared
with state-of-the-art deep learning models. Results demonstrate that
MoistNetLite achieves 87% accuracy with minimal computational overhead, while
MoistNetMax exhibits exceptional precision with a 91% accuracy in wood chip
moisture content class prediction. With improved accuracy and faster prediction
speed, our proposed MoistNet models hold great promise for the wood chip
processing industry.

摘要：快速且可靠地测量木屑水分含量对于众多依赖森林的产业（如生物燃料、纸浆和造纸以及生物精炼厂）来说是一个永恒的问题。水分含量是木屑的一个关键属性，因为它与最终产品质量直接相关。测定水分含量的传统技术（如烘箱干燥）在耗时、潜在样品损坏和缺乏实时可行性方面存在一些缺点。此外，包括近红外光谱、电容、X 射线和微波在内的替代技术已显示出潜力；然而，它们仍然受到便携性、精度和所需设备成本等问题的影响。因此，需要一种即时、便携、无损、廉价且精确的水分含量测定方法。本研究探讨了利用深度学习和机器视觉从木屑的 RGB 图像中预测水分含量等级。已经收集了一个包含 1,600 张木屑 RGB 图像的大规模图像数据集，并利用烘箱干燥技术的成果对其进行了注释和标记。已经利用神经架构搜索 (NAS) 和超参数优化开发了两个高性能神经网络 MoistNetLite 和 MoistNetMax。对开发的模型进行了评估，并将其与最先进的深度学习模型进行了比较。结果表明，MoistNetLite 在计算开销最小的条件下实现了 87% 的准确率，而 MoistNetMax 在木屑水分含量等级预测中表现出 91% 的准确率，具有出色的精度。凭借更高的准确率和更快的预测速度，我们提出的 MoistNet 模型为木屑加工业带来了巨大的希望。

##### **Activation Function Optimization Scheme for Image Classification**
2409.04915v1 by Abdur Rahman, Lu He, Haifeng Wang

Activation function has a significant impact on the dynamics, convergence,
and performance of deep neural networks. The search for a consistent and
high-performing activation function has always been a pursuit during deep
learning model development. Existing state-of-the-art activation functions are
manually designed with human expertise except for Swish. Swish was developed
using a reinforcement learning-based search strategy. In this study, we propose
an evolutionary approach for optimizing activation functions specifically for
image classification tasks, aiming to discover functions that outperform
current state-of-the-art options. Through this optimization framework, we
obtain a series of high-performing activation functions denoted as Exponential
Error Linear Unit (EELU). The developed activation functions are evaluated for
image classification tasks from two perspectives: (1) five state-of-the-art
neural network architectures, such as ResNet50, AlexNet, VGG16, MobileNet, and
Compact Convolutional Transformer which cover computationally heavy to light
neural networks, and (2) eight standard datasets, including CIFAR10,
Imagenette, MNIST, Fashion MNIST, Beans, Colorectal Histology, CottonWeedID15,
and TinyImageNet which cover from typical machine vision benchmark,
agricultural image applications to medical image applications. Finally, we
statistically investigate the generalization of the resultant activation
functions developed through the optimization scheme. With a Friedman test, we
conclude that the optimization scheme is able to generate activation functions
that outperform the existing standard ones in 92.8% cases among 28 different
cases studied, and $-x\cdot erf(e^{-x})$ is found to be the best activation
function for image classification generated by the optimization scheme.

摘要：<paragraph>激活函數對深度神經網路的動態、收斂和效能有顯著的影響。在深度學習模型開發過程中，一直致力於尋找一致且效能高的激活函數。現有的最先進激活函數，除了 Swish 之外，都是由人類專家手動設計的。Swish 是使用基於強化學習的搜尋策略開發的。在本研究中，我們提出了一種演化方法，專門針對圖像分類任務最佳化激活函數，旨在發現效能優於現有最先進選項的函數。透過這個最佳化架構，我們獲得了一系列效能高的激活函數，表示為指數誤差線性單元 (EELU)。已針對兩個觀點評估已開發的激活函數，用於圖像分類任務：(1) 五種最先進的神經網路架構，例如 ResNet50、AlexNet、VGG16、MobileNet 和 Compact Convolutional Transformer，涵蓋從計算量重的到輕量的網路，(2) 八個標準資料集，包括 CIFAR10、Imagenette、MNIST、Fashion MNIST、Beans、Colorectal Histology、CottonWeedID15 和 TinyImageNet，涵蓋從典型的機器視覺基準、農業影像應用到醫學影像應用。最後，我們統計調查了透過最佳化方案開發的結果激活函數的概化。透過 Friedman 檢定，我們得出結論，最佳化方案能夠產生在 28 個不同的研究案例中，有 92.8% 的案例效能優於現有標準函數，並且發現 $-x\cdot erf(e^{-x})$ 是最佳化方案產生的最佳影像分類激活函數。</paragraph>

##### **Efficient Training of Transformers for Molecule Property Prediction on Small-scale Datasets**
2409.04909v1 by Shivesh Prakash

The blood-brain barrier (BBB) serves as a protective barrier that separates
the brain from the circulatory system, regulating the passage of substances
into the central nervous system. Assessing the BBB permeability of potential
drugs is crucial for effective drug targeting. However, traditional
experimental methods for measuring BBB permeability are challenging and
impractical for large-scale screening. Consequently, there is a need to develop
computational approaches to predict BBB permeability. This paper proposes a GPS
Transformer architecture augmented with Self Attention, designed to perform
well in the low-data regime. The proposed approach achieved a state-of-the-art
performance on the BBB permeability prediction task using the BBBP dataset,
surpassing existing models. With a ROC-AUC of 78.8%, the approach sets a
state-of-the-art by 5.5%. We demonstrate that standard Self Attention coupled
with GPS transformer performs better than other variants of attention coupled
with GPS Transformer.

摘要：血腦屏障 (BBB) 是一個保護性屏障，將大腦與循環系統分開，調節物質進入中樞神經系統。評估潛在藥物的 BBB 滲透性對於有效藥物靶向至關重要。然而，傳統的測量 BBB 滲透性的實驗方法具有挑戰性，且不切實際用於大規模篩選。因此，需要開發計算方法來預測 BBB 滲透性。本文提出了一個增強了自我注意力的 GPS Transformer 架構，旨在在低數據量環境中表現良好。所提出的方法在使用 BBBP 數據集的 BBB 滲透性預測任務中取得了最先進的性能，超越了現有模型。通過 78.8% 的 ROC-AUC，該方法將最先進的技術提高了 5.5%。我們證明了標準自我注意力與 GPS Transformer 相結合的性能優於與 GPS Transformer 相結合的其他注意力變體。

