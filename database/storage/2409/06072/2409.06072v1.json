{"2409.06072": {"publish_time": "2024-09-09", "title": "DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection", "paper_summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language processing tasks. However, their practical application in\nhigh-stake domains, such as fraud and abuse detection, remains an area that\nrequires further exploration. The existing applications often narrowly focus on\nspecific tasks like toxicity or hate speech detection. In this paper, we\npresent a comprehensive benchmark suite designed to assess the performance of\nLLMs in identifying and mitigating fraudulent and abusive language across\nvarious real-world scenarios. Our benchmark encompasses a diverse set of tasks,\nincluding detecting spam emails, hate speech, misogynistic language, and more.\nWe evaluated several state-of-the-art LLMs, including models from Anthropic,\nMistral AI, and the AI21 family, to provide a comprehensive assessment of their\ncapabilities in this critical domain. The results indicate that while LLMs\nexhibit proficient baseline performance in individual fraud and abuse detection\ntasks, their performance varies considerably across tasks, particularly\nstruggling with tasks that demand nuanced pragmatic reasoning, such as\nidentifying diverse forms of misogynistic language. These findings have\nimportant implications for the responsible development and deployment of LLMs\nin high-risk applications. Our benchmark suite can serve as a tool for\nresearchers and practitioners to systematically evaluate LLMs for multi-task\nfraud detection and drive the creation of more robust, trustworthy, and\nethically-aligned systems for fraud and abuse detection.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u5b83\u5011\u5728\u9ad8\u98a8\u96aa\u9818\u57df\u4e2d\u7684\u5be6\u969b\u61c9\u7528\uff0c\u4f8b\u5982\u8a50\u9a19\u548c\u6feb\u7528\u5075\u6e2c\uff0c\u4ecd\u7136\u662f\u4e00\u500b\u9700\u8981\u9032\u4e00\u6b65\u63a2\u7d22\u7684\u9818\u57df\u3002\u73fe\u6709\u7684\u61c9\u7528\u7a0b\u5f0f\u901a\u5e38\u72f9\u9698\u5730\u5c08\u6ce8\u65bc\u7279\u5b9a\u4efb\u52d9\uff0c\u4f8b\u5982\u6bd2\u6027\u6216\u4ec7\u6068\u8a00\u8ad6\u5075\u6e2c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u5168\u9762\u7684\u57fa\u6e96\u6e2c\u8a66\u5957\u4ef6\uff0c\u65e8\u5728\u8a55\u4f30 LLM \u5728\u5404\u7a2e\u771f\u5be6\u4e16\u754c\u5834\u666f\u4e2d\u8b58\u5225\u548c\u6e1b\u8f15\u6b3a\u8a50\u548c\u6feb\u7528\u8a9e\u8a00\u7684\u6548\u80fd\u3002\u6211\u5011\u7684\u57fa\u6e96\u6db5\u84cb\u4e86\u4e00\u7d44\u4e0d\u540c\u7684\u4efb\u52d9\uff0c\u5305\u62ec\u5075\u6e2c\u5783\u573e\u90f5\u4ef6\u3001\u4ec7\u6068\u8a00\u8ad6\u3001\u53ad\u60e1\u5973\u6027\u7684\u8a9e\u8a00\u7b49\u7b49\u3002\u6211\u5011\u8a55\u4f30\u4e86\u5e7e\u7a2e\u6700\u5148\u9032\u7684 LLM\uff0c\u5305\u62ec\u4f86\u81ea Anthropic\u3001Mistral AI \u548c AI21 \u5bb6\u65cf\u7684\u6a21\u578b\uff0c\u4ee5\u5168\u9762\u8a55\u4f30\u5b83\u5011\u5728\u9019\u500b\u95dc\u9375\u9818\u57df\u7684\u80fd\u529b\u3002\u7d50\u679c\u8868\u660e\uff0c\u5118\u7ba1 LLM \u5728\u500b\u5225\u7684\u8a50\u9a19\u548c\u6feb\u7528\u5075\u6e2c\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u719f\u7df4\u7684\u57fa\u6e96\u6548\u80fd\uff0c\u4f46\u5b83\u5011\u7684\u6548\u80fd\u56e0\u4efb\u52d9\u800c\u7570\uff0c\u7279\u5225\u662f\u5728\u9700\u8981\u7d30\u7dfb\u52d9\u5be6\u63a8\u7406\u7684\u4efb\u52d9\u4e2d\u8868\u73fe\u4e0d\u4f73\uff0c\u4f8b\u5982\u8b58\u5225\u5404\u7a2e\u5f62\u5f0f\u7684\u53ad\u60e1\u5973\u6027\u7684\u8a9e\u8a00\u3002\u9019\u4e9b\u767c\u73fe\u5c0d LLM \u5728\u9ad8\u98a8\u96aa\u61c9\u7528\u4e2d\u7684\u8ca0\u8cac\u4efb\u958b\u767c\u548c\u90e8\u7f72\u5177\u6709\u91cd\u8981\u7684\u610f\u7fa9\u3002\u6211\u5011\u7684\u57fa\u6e96\u6e2c\u8a66\u5957\u4ef6\u53ef\u4ee5\u4f5c\u70ba\u7814\u7a76\u4eba\u54e1\u548c\u5be6\u52d9\u5de5\u4f5c\u8005\u7684\u5de5\u5177\uff0c\u7528\u65bc\u7cfb\u7d71\u6027\u5730\u8a55\u4f30 LLM \u7684\u591a\u4efb\u52d9\u8a50\u9a19\u5075\u6e2c\uff0c\u4e26\u63a8\u52d5\u5efa\u7acb\u66f4\u5f37\u5927\u3001\u66f4\u503c\u5f97\u4fe1\u8cf4\u4e14\u5728\u9053\u5fb7\u4e0a\u66f4\u4e00\u81f4\u7684\u8a50\u9a19\u548c\u6feb\u7528\u5075\u6e2c\u7cfb\u7d71\u3002", "author": "Joymallya Chakraborty et.al.", "authors": "Joymallya Chakraborty, Wei Xia, Anirban Majumder, Dan Ma, Walid Chaabene, Naveed Janvekar", "id": "2409.06072v1", "paper_url": "http://arxiv.org/abs/2409.06072v1", "repo": "null"}}