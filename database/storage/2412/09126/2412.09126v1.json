{"2412.09126": {"publish_time": "2024-12-12", "title": "Enhancing Modality Representation and Alignment for Multimodal Cold-start Active Learning", "paper_summary": "Training multimodal models requires a large amount of labeled data. Active\nlearning (AL) aim to reduce labeling costs. Most AL methods employ warm-start\napproaches, which rely on sufficient labeled data to train a well-calibrated\nmodel that can assess the uncertainty and diversity of unlabeled data. However,\nwhen assembling a dataset, labeled data are often scarce initially, leading to\na cold-start problem. Additionally, most AL methods seldom address multimodal\ndata, highlighting a research gap in this field. Our research addresses these\nissues by developing a two-stage method for Multi-Modal Cold-Start Active\nLearning (MMCSAL).\n  Firstly, we observe the modality gap, a significant distance between the\ncentroids of representations from different modalities, when only using\ncross-modal pairing information as self-supervision signals. This modality gap\naffects data selection process, as we calculate both uni-modal and cross-modal\ndistances. To address this, we introduce uni-modal prototypes to bridge the\nmodality gap. Secondly, conventional AL methods often falter in multimodal\nscenarios where alignment between modalities is overlooked. Therefore, we\npropose enhancing cross-modal alignment through regularization, thereby\nimproving the quality of selected multimodal data pairs in AL. Finally, our\nexperiments demonstrate MMCSAL's efficacy in selecting multimodal data pairs\nacross three multimodal datasets.", "paper_summary_zh": "\u8a13\u7df4\u591a\u6a21\u614b\u6a21\u578b\u9700\u8981\u5927\u91cf\u7684\u6a19\u7c64\u8cc7\u6599\u3002\u4e3b\u52d5\u5b78\u7fd2 (AL) \u65e8\u5728\u964d\u4f4e\u6a19\u7c64\u6210\u672c\u3002\u5927\u591a\u6578 AL \u65b9\u6cd5\u63a1\u7528\u71b1\u555f\u52d5\u65b9\u6cd5\uff0c\u4f9d\u8cf4\u65bc\u8db3\u5920\u7684\u6a19\u7c64\u8cc7\u6599\u4f86\u8a13\u7df4\u4e00\u500b\u6821\u6e96\u826f\u597d\u7684\u6a21\u578b\uff0c\u8a72\u6a21\u578b\u53ef\u4ee5\u8a55\u4f30\u672a\u6a19\u7c64\u8cc7\u6599\u7684\u4e0d\u78ba\u5b9a\u6027\u548c\u591a\u6a23\u6027\u3002\u7136\u800c\uff0c\u5728\u7d44\u88dd\u8cc7\u6599\u96c6\u6642\uff0c\u6a19\u7c64\u8cc7\u6599\u901a\u5e38\u4e00\u958b\u59cb\u5f88\u7a00\u5c11\uff0c\u5c0e\u81f4\u51b7\u555f\u52d5\u554f\u984c\u3002\u6b64\u5916\uff0c\u5927\u591a\u6578 AL \u65b9\u6cd5\u5f88\u5c11\u8655\u7406\u591a\u6a21\u614b\u8cc7\u6599\uff0c\u51f8\u986f\u4e86\u8a72\u9818\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002\u6211\u5011\u7684\u7814\u7a76\u900f\u904e\u958b\u767c\u591a\u6a21\u614b\u51b7\u555f\u52d5\u4e3b\u52d5\u5b78\u7fd2 (MMCSAL) \u7684\u5169\u968e\u6bb5\u65b9\u6cd5\u4f86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\u3002\n\u9996\u5148\uff0c\u7576\u50c5\u4f7f\u7528\u8de8\u6a21\u614b\u914d\u5c0d\u8cc7\u8a0a\u4f5c\u70ba\u81ea\u6211\u76e3\u7763\u8a0a\u865f\u6642\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u6a21\u614b\u5dee\u8ddd\uff0c\u9019\u662f\u4f86\u81ea\u4e0d\u540c\u6a21\u614b\u7684\u8868\u793a\u4e4b\u91cd\u5fc3\u7684\u986f\u8457\u8ddd\u96e2\u3002\u6b64\u6a21\u614b\u5dee\u8ddd\u6703\u5f71\u97ff\u8cc7\u6599\u9078\u53d6\u6d41\u7a0b\uff0c\u56e0\u70ba\u6211\u5011\u8a08\u7b97\u55ae\u6a21\u614b\u548c\u8de8\u6a21\u614b\u8ddd\u96e2\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u55ae\u6a21\u614b\u539f\u578b\u4f86\u5f4c\u5408\u6a21\u614b\u5dee\u8ddd\u3002\u5176\u6b21\uff0c\u50b3\u7d71\u7684 AL \u65b9\u6cd5\u901a\u5e38\u5728\u5ffd\u7565\u6a21\u614b\u4e4b\u9593\u5c0d\u9f4a\u7684\u591a\u6a21\u614b\u5834\u666f\u4e2d\u5931\u6557\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5efa\u8b70\u900f\u904e\u6b63\u5247\u5316\u589e\u5f37\u8de8\u6a21\u614b\u5c0d\u9f4a\uff0c\u5f9e\u800c\u63d0\u9ad8 AL \u4e2d\u6240\u9078\u591a\u6a21\u614b\u8cc7\u6599\u5c0d\u7684\u54c1\u8cea\u3002\u6700\u5f8c\uff0c\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\u4e86 MMCSAL \u5728\u4e09\u500b\u591a\u6a21\u614b\u8cc7\u6599\u96c6\u4e2d\u9078\u53d6\u591a\u6a21\u614b\u8cc7\u6599\u5c0d\u7684\u6548\u80fd\u3002", "author": "Meng Shen et.al.", "authors": "Meng Shen, Yake Wei, Jianxiong Yin, Deepu Rajan, Di Hu, Simon See", "id": "2412.09126v1", "paper_url": "http://arxiv.org/abs/2412.09126v1", "repo": "null"}}