{"2407.15707": {"publish_time": "2024-07-22", "title": "Predicting the Best of N Visual Trackers", "paper_summary": "We observe that the performance of SOTA visual trackers surprisingly strongly\nvaries across different video attributes and datasets. No single tracker\nremains the best performer across all tracking attributes and datasets. To\nbridge this gap, for a given video sequence, we predict the \"Best of the N\nTrackers\", called the BofN meta-tracker. At its core, a Tracking Performance\nPrediction Network (TP2N) selects a predicted best performing visual tracker\nfor the given video sequence using only a few initial frames. We also introduce\na frame-level BofN meta-tracker which keeps predicting best performer after\nregular temporal intervals. The TP2N is based on self-supervised learning\narchitectures MocoV2, SwAv, BT, and DINO; experiments show that the DINO with\nViT-S as a backbone performs the best. The video-level BofN meta-tracker\noutperforms, by a large margin, existing SOTA trackers on nine standard\nbenchmarks - LaSOT, TrackingNet, GOT-10K, VOT2019, VOT2021, VOT2022, UAV123,\nOTB100, and WebUAV-3M. Further improvement is achieved by the frame-level BofN\nmeta-tracker effectively handling variations in the tracking scenarios within\nlong sequences. For instance, on GOT-10k, BofN meta-tracker average overlap is\n88.7% and 91.1% with video and frame-level settings respectively. The best\nperforming tracker, RTS, achieves 85.20% AO. On VOT2022, BofN expected average\noverlap is 67.88% and 70.98% with video and frame level settings, compared to\nthe best performing ARTrack, 64.12%. This work also presents an extensive\nevaluation of competitive tracking methods on all commonly used benchmarks,\nfollowing their protocols. The code, the trained models, and the results will\nsoon be made publicly available on\nhttps://github.com/BasitAlawode/Best_of_N_Trackers.", "paper_summary_zh": "<paragraph>\u6211\u5011\u89c0\u5bdf\u5230\uff0cSOTA \u8996\u89ba\u8ffd\u8e64\u5668\u7684\u6548\u80fd\u9a5a\u4eba\u5730\u56e0\u4e0d\u540c\u7684\u5f71\u7247\u5c6c\u6027\u548c\u8cc7\u6599\u96c6\u800c\u6709\u5f88\u5927\u7684\u5dee\u7570\u3002\u6c92\u6709\u55ae\u4e00\u8ffd\u8e64\u5668\u80fd\u5728\u6240\u6709\u8ffd\u8e64\u5c6c\u6027\u548c\u8cc7\u6599\u96c6\u4e0a\u4fdd\u6301\u6700\u4f73\u6548\u80fd\u3002\u70ba\u4e86\u5f4c\u5408\u9019\u500b\u5dee\u8ddd\uff0c\u5c0d\u65bc\u7d66\u5b9a\u7684\u5f71\u7247\u5e8f\u5217\uff0c\u6211\u5011\u9810\u6e2c\u300cN \u500b\u8ffd\u8e64\u5668\u4e2d\u7684\u6700\u4f73\u8005\u300d\uff0c\u7a31\u70ba BofN \u5143\u8ffd\u8e64\u5668\u3002\u5176\u6838\u5fc3\u662f\u4e00\u500b\u8ffd\u8e64\u6548\u80fd\u9810\u6e2c\u7db2\u8def (TP2N)\uff0c\u5b83\u4f7f\u7528\u50c5\u6709\u5e7e\u500b\u521d\u59cb\u756b\u683c\uff0c\u5c31\u80fd\u70ba\u7d66\u5b9a\u7684\u5f71\u7247\u5e8f\u5217\u9078\u64c7\u9810\u6e2c\u7684\u6700\u4f73\u6548\u80fd\u8996\u89ba\u8ffd\u8e64\u5668\u3002\u6211\u5011\u9084\u5f15\u9032\u4e86\u4e00\u500b\u756b\u683c\u5c64\u7d1a\u7684 BofN \u5143\u8ffd\u8e64\u5668\uff0c\u5b83\u6703\u5728\u898f\u5f8b\u7684\u6642\u9593\u9593\u9694\u5f8c\u6301\u7e8c\u9810\u6e2c\u6700\u4f73\u6548\u80fd\u3002TP2N \u57fa\u65bc\u81ea\u76e3\u7763\u5b78\u7fd2\u67b6\u69cb MocoV2\u3001SwAv\u3001BT \u548c DINO\uff1b\u5be6\u9a57\u986f\u793a\uff0c\u4ee5 ViT-S \u4f5c\u70ba\u4e3b\u5e79\u7684 DINO \u6548\u80fd\u6700\u4f73\u3002\u5f71\u7247\u5c64\u7d1a\u7684 BofN \u5143\u8ffd\u8e64\u5668\u5728\u4e5d\u500b\u6a19\u6e96\u57fa\u6e96\u4e0a\u5927\u5e45\u512a\u65bc\u73fe\u6709\u7684 SOTA \u8ffd\u8e64\u5668\uff0c\u5305\u62ec LaSOT\u3001TrackingNet\u3001GOT-10K\u3001VOT2019\u3001VOT2021\u3001VOT2022\u3001UAV123\u3001OTB100 \u548c WebUAV-3M\u3002\u756b\u683c\u5c64\u7d1a\u7684 BofN \u5143\u8ffd\u8e64\u5668\u6709\u6548\u8655\u7406\u9577\u5e8f\u5217\u4e2d\u8ffd\u8e64\u5834\u666f\u7684\u8b8a\u5316\uff0c\u9032\u4e00\u6b65\u63d0\u5347\u4e86\u6548\u80fd\u3002\u4f8b\u5982\uff0c\u5728 GOT-10k \u4e0a\uff0cBofN \u5143\u8ffd\u8e64\u5668\u5e73\u5747\u91cd\u758a\u7387\u5206\u5225\u70ba 88.7% \u548c 91.1%\uff0c\u4f7f\u7528\u5f71\u7247\u548c\u756b\u683c\u5c64\u7d1a\u8a2d\u5b9a\u3002\u6548\u80fd\u6700\u4f73\u7684\u8ffd\u8e64\u5668 RTS \u9054\u5230 85.20% \u7684 AO\u3002\u5728 VOT2022 \u4e0a\uff0cBofN \u9810\u671f\u5e73\u5747\u91cd\u758a\u7387\u5206\u5225\u70ba 67.88% \u548c 70.98%\uff0c\u4f7f\u7528\u5f71\u7247\u548c\u756b\u683c\u5c64\u7d1a\u8a2d\u5b9a\uff0c\u800c\u6548\u80fd\u6700\u4f73\u7684 ARTrack \u70ba 64.12%\u3002\u9019\u9805\u5de5\u4f5c\u9084\u6839\u64da\u5404\u500b\u57fa\u6e96\u7684\u5354\u5b9a\uff0c\u5c0d\u6240\u6709\u5e38\u7528\u7684\u57fa\u6e96\u9032\u884c\u4e86\u7af6\u722d\u8ffd\u8e64\u65b9\u6cd5\u7684\u5ee3\u6cdb\u8a55\u4f30\u3002\u7a0b\u5f0f\u78bc\u3001\u8a13\u7df4\u6a21\u578b\u548c\u7d50\u679c\u5c07\u5f88\u5feb\u5728 https://github.com/BasitAlawode/Best_of_N_Trackers \u4e0a\u516c\u958b\u3002</paragraph>", "author": "Basit Alawode et.al.", "authors": "Basit Alawode, Sajid Javed, Arif Mahmood, Jiri Matas", "id": "2407.15707v1", "paper_url": "http://arxiv.org/abs/2407.15707v1", "repo": "null"}}