{"2406.04845": {"publish_time": "2024-06-07", "title": "FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models", "paper_summary": "Federated learning has enabled multiple parties to collaboratively train\nlarge language models without directly sharing their data (FedLLM). Following\nthis training paradigm, the community has put massive efforts from diverse\naspects including framework, performance, and privacy. However, an unpleasant\nfact is that there are currently no realistic datasets and benchmarks for\nFedLLM and previous works all rely on artificially constructed datasets,\nfailing to capture properties in real-world scenarios. Addressing this, we\npropose FedLLM-Bench, which involves 8 training methods, 4 training datasets,\nand 6 evaluation metrics, to offer a comprehensive testbed for the FedLLM\ncommunity. FedLLM-Bench encompasses three datasets (e.g., user-annotated\nmultilingual dataset) for federated instruction tuning and one dataset (e.g.,\nuser-annotated preference dataset) for federated preference alignment, whose\nscale of client number ranges from 38 to 747. Our datasets incorporate several\nrepresentative diversities: language, quality, quantity, instruction, length,\nembedding, and preference, capturing properties in real-world scenarios. Based\non FedLLM-Bench, we conduct experiments on all datasets to benchmark existing\nFL methods and provide empirical insights (e.g., multilingual collaboration).\nWe believe that our FedLLM-Bench can benefit the FedLLM community by reducing\nrequired efforts, providing a practical testbed, and promoting fair\ncomparisons. Code and datasets are available at\nhttps://github.com/rui-ye/FedLLM-Bench.", "paper_summary_zh": "<paragraph>\u806f\u5408\u5b78\u7fd2\u8b93\u591a\u65b9\u80fd\u5920\u5728\u4e0d\u76f4\u63a5\u5206\u4eab\u8cc7\u6599\u7684\u60c5\u6cc1\u4e0b\uff0c\u5171\u540c\u8a13\u7df4\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08FedLLM\uff09\u3002\u9075\u5faa\u6b64\u8a13\u7df4\u7bc4\u4f8b\uff0c\u793e\u7fa4\u5f9e\u67b6\u69cb\u3001\u6548\u80fd\u548c\u96b1\u79c1\u7b49\u4e0d\u540c\u9762\u5411\u6295\u5165\u5927\u91cf\u5fc3\u529b\u3002\u7136\u800c\uff0c\u4ee4\u4eba\u4e0d\u6085\u7684\u4e8b\u5be6\u662f\uff0c\u76ee\u524d\u6c92\u6709 FedLLM \u7684\u5be6\u969b\u8cc7\u6599\u96c6\u548c\u57fa\u6e96\uff0c\u800c\u5148\u524d\u7684\u7814\u7a76\u90fd\u4f9d\u8cf4\u4eba\u5de5\u5efa\u69cb\u7684\u8cc7\u6599\u96c6\uff0c\u7121\u6cd5\u6355\u6349\u771f\u5be6\u4e16\u754c\u5834\u666f\u4e2d\u7684\u5c6c\u6027\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86 FedLLM-Bench\uff0c\u5176\u4e2d\u5305\u542b 8 \u7a2e\u8a13\u7df4\u65b9\u6cd5\u30014 \u500b\u8a13\u7df4\u8cc7\u6599\u96c6\u548c 6 \u500b\u8a55\u4f30\u6307\u6a19\uff0c\u70ba FedLLM \u793e\u7fa4\u63d0\u4f9b\u4e00\u500b\u5168\u9762\u7684\u6e2c\u8a66\u5e73\u53f0\u3002FedLLM-Bench \u6db5\u84cb\u4e86\u4e09\u500b\u8cc7\u6599\u96c6\uff08\u4f8b\u5982\uff0c\u4f7f\u7528\u8005\u6a19\u8a3b\u7684\u591a\u8a9e\u8a00\u8cc7\u6599\u96c6\uff09\uff0c\u7528\u65bc\u806f\u5408\u5f0f\u6307\u4ee4\u8abf\u6574\uff0c\u4ee5\u53ca\u4e00\u500b\u8cc7\u6599\u96c6\uff08\u4f8b\u5982\uff0c\u4f7f\u7528\u8005\u6a19\u8a3b\u7684\u504f\u597d\u8cc7\u6599\u96c6\uff09\uff0c\u7528\u65bc\u806f\u5408\u5f0f\u504f\u597d\u6bd4\u5c0d\uff0c\u5176\u5ba2\u6236\u7aef\u6578\u91cf\u898f\u6a21\u4ecb\u65bc 38 \u5230 747 \u4e4b\u9593\u3002\u6211\u5011\u7684\u8cc7\u6599\u96c6\u5305\u542b\u4e86\u591a\u7a2e\u4ee3\u8868\u6027\u7684\u591a\u6a23\u6027\uff1a\u8a9e\u8a00\u3001\u54c1\u8cea\u3001\u6578\u91cf\u3001\u6307\u4ee4\u3001\u9577\u5ea6\u3001\u5d4c\u5165\u548c\u504f\u597d\uff0c\u6355\u6349\u4e86\u771f\u5be6\u4e16\u754c\u5834\u666f\u4e2d\u7684\u5c6c\u6027\u3002\u57fa\u65bc FedLLM-Bench\uff0c\u6211\u5011\u5c0d\u6240\u6709\u8cc7\u6599\u96c6\u9032\u884c\u5be6\u9a57\uff0c\u4ee5\u8a55\u91cf\u73fe\u6709\u7684\u806f\u5408\u5b78\u7fd2\u65b9\u6cd5\uff0c\u4e26\u63d0\u4f9b\u5be6\u8b49\u898b\u89e3\uff08\u4f8b\u5982\uff0c\u591a\u8a9e\u8a00\u5354\u4f5c\uff09\u3002\u6211\u5011\u76f8\u4fe1\u6211\u5011\u7684 FedLLM-Bench \u53ef\u4ee5\u900f\u904e\u6e1b\u5c11\u6240\u9700\u7684\u5de5\u4f5c\u3001\u63d0\u4f9b\u5be6\u7528\u7684\u6e2c\u8a66\u5e73\u53f0\u548c\u4fc3\u9032\u516c\u5e73\u7684\u6bd4\u8f03\uff0c\u5c0d FedLLM \u793e\u7fa4\u6709\u76ca\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u96c6\u53ef\u5728 https://github.com/rui-ye/FedLLM-Bench \u53d6\u5f97\u3002</paragraph>", "author": "Rui Ye et.al.", "authors": "Rui Ye, Rui Ge, Xinyu Zhu, Jingyi Chai, Yaxin Du, Yang Liu, Yanfeng Wang, Siheng Chen", "id": "2406.04845v1", "paper_url": "http://arxiv.org/abs/2406.04845v1", "repo": "null"}}