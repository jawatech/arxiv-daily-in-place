{"2503.24379": {"publish_time": "2025-03-31", "title": "Any2Caption:Interpreting Any Condition to Caption for Controllable Video Generation", "paper_summary": "To address the bottleneck of accurate user intent interpretation within the\ncurrent video generation community, we present Any2Caption, a novel framework\nfor controllable video generation under any condition. The key idea is to\ndecouple various condition interpretation steps from the video synthesis step.\nBy leveraging modern multimodal large language models (MLLMs), Any2Caption\ninterprets diverse inputs--text, images, videos, and specialized cues such as\nregion, motion, and camera poses--into dense, structured captions that offer\nbackbone video generators with better guidance. We also introduce Any2CapIns, a\nlarge-scale dataset with 337K instances and 407K conditions for\nany-condition-to-caption instruction tuning. Comprehensive evaluations\ndemonstrate significant improvements of our system in controllability and video\nquality across various aspects of existing video generation models. Project\nPage: https://sqwu.top/Any2Cap/", "paper_summary_zh": "\u70ba\u4e86\u6539\u5584\u76ee\u524d\u5f71\u7247\u751f\u6210\u793e\u7fa4\u4e2d\u6e96\u78ba\u7406\u89e3\u4f7f\u7528\u8005\u610f\u5716\u7684\u74f6\u9838\uff0c\u6211\u5011\u63d0\u51fa\u4e86 Any2Caption\uff0c\u9019\u662f\u4e00\u500b\u5728\u4efb\u4f55\u689d\u4ef6\u4e0b\u90fd\u80fd\u9032\u884c\u53ef\u63a7\u5f71\u7247\u751f\u6210\u7684\u65b0\u7a4e\u6846\u67b6\u3002\u5176\u6838\u5fc3\u6982\u5ff5\u662f\u5c07\u5404\u7a2e\u689d\u4ef6\u89e3\u8b80\u6b65\u9a5f\u8207\u5f71\u7247\u5408\u6210\u6b65\u9a5f\u5206\u96e2\u3002\u85c9\u7531\u5229\u7528\u73fe\u4ee3\u7684\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM)\uff0cAny2Caption \u80fd\u5920\u5c07\u4e0d\u540c\u7684\u8f38\u5165\u2014\u2014\u6587\u5b57\u3001\u5716\u50cf\u3001\u5f71\u7247\uff0c\u4ee5\u53ca\u50cf\u662f\u5340\u57df\u3001\u52d5\u4f5c\u548c\u651d\u5f71\u6a5f\u59ff\u52e2\u7b49\u7279\u6b8a\u63d0\u793a\u2014\u2014\u89e3\u8b80\u6210\u5bc6\u96c6\u3001\u7d50\u69cb\u5316\u7684\u5b57\u5e55\uff0c\u70ba\u9aa8\u5e79\u5f71\u7247\u751f\u6210\u5668\u63d0\u4f9b\u66f4\u597d\u7684\u6307\u5f15\u3002\u6211\u5011\u9084\u63a8\u51fa\u4e86 Any2CapIns\uff0c\u9019\u662f\u4e00\u500b\u5305\u542b 337K \u500b\u5be6\u4f8b\u548c 407K \u500b\u689d\u4ef6\u7684\u5927\u898f\u6a21\u8cc7\u6599\u96c6\uff0c\u7528\u65bc\u4efb\u4f55\u689d\u4ef6\u5230\u5b57\u5e55\u7684\u6307\u4ee4\u5fae\u8abf\u3002\u5168\u9762\u7684\u8a55\u4f30\u986f\u793a\uff0c\u6211\u5011\u7684\u7cfb\u7d71\u5728\u73fe\u6709\u5f71\u7247\u751f\u6210\u6a21\u578b\u7684\u5404\u500b\u65b9\u9762\uff0c\u5728\u53ef\u63a7\u6027\u548c\u5f71\u7247\u54c1\u8cea\u4e0a\u90fd\u6709\u986f\u8457\u7684\u63d0\u5347\u3002\u5c08\u6848\u9801\u9762\uff1ahttps://sqwu.top/Any2Cap/\n", "author": "Shengqiong Wu et.al.", "authors": "Shengqiong Wu, Weicai Ye, Jiahao Wang, Quande Liu, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai, Shuicheng Yan, Hao Fei, Tat-Seng Chua", "id": "2503.24379v1", "paper_url": "http://arxiv.org/abs/2503.24379v1", "repo": "null"}}