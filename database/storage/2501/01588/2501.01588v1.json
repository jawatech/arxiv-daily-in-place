{"2501.01588": {"publish_time": "2025-01-03", "title": "(WhyPHI) Fine-Tuning PHI-3 for Multiple-Choice Question Answering: Methodology, Results, and Challenges", "paper_summary": "Large Language Models (LLMs) have become essential tools across various\ndomains due to their impressive capabilities in understanding and generating\nhuman-like text. The ability to accurately answer multiple-choice questions\n(MCQs) holds significant value in education, particularly in automated tutoring\nsystems and assessment platforms. However, adapting LLMs to handle MCQ tasks\neffectively remains challenging due to the hallucinations and unclear prompts.\nThis work explores the potential of Microsoft's PHI-3\\cite{Abdin2024}, a\ncompact yet efficient LLM, for MCQ answering. Our contributions include\nfine-tuning the model on the TruthfulQA dataset, designing optimized prompts to\nenhance model performance, and evaluating using perplexity and traditional\nmetrics like accuracy and F1 score. Results show a remarkable improvement in\nPHI-3.5's MCQ handling post-fine-tuning, with perplexity decreasing from 4.68\nto 2.27, and accuracy rising from 62\\% to 90.8\\%. This research underlines the\nimportance of efficient models in adaptive learning systems and educational\nassessments, paving the way for broader integration into the classroom,\nparticularly in fields like test preparation, student feedback, and\npersonalized learning.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7531\u65bc\u5176\u5728\u7406\u89e3\u548c\u751f\u6210\u985e\u4eba\u6587\u672c\u65b9\u9762\u7684\u9a5a\u4eba\u80fd\u529b\uff0c\u5df2\u6210\u70ba\u5404\u7a2e\u9818\u57df\u7684\u5fc5\u5099\u5de5\u5177\u3002\u6e96\u78ba\u56de\u7b54\u591a\u9078\u984c (MCQ) \u7684\u80fd\u529b\u5728\u6559\u80b2\u4e2d\u5177\u6709\u91cd\u8981\u50f9\u503c\uff0c\u5c24\u5176\u662f\u5728\u81ea\u52d5\u5316\u8f14\u5c0e\u7cfb\u7d71\u548c\u8a55\u4f30\u5e73\u53f0\u4e2d\u3002\u7136\u800c\uff0c\u7531\u65bc\u5e7b\u89ba\u548c\u63d0\u793a\u4e0d\u660e\u78ba\uff0c\u4f7f LLM \u9069\u61c9 MCQ \u4efb\u52d9\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u9019\u9805\u5de5\u4f5c\u63a2\u8a0e\u4e86\u5fae\u8edf\u7684 PHI-3\\cite{Abdin2024} \u7684\u6f5b\u529b\uff0c\u9019\u662f\u4e00\u500b\u7dca\u6e4a\u4f46\u9ad8\u6548\u7684 LLM\uff0c\u7528\u65bc MCQ \u56de\u7b54\u3002\u6211\u5011\u7684\u8ca2\u737b\u5305\u62ec\u5728 TruthfulQA \u8cc7\u6599\u96c6\u4e0a\u5fae\u8abf\u6a21\u578b\uff0c\u8a2d\u8a08\u6700\u4f73\u63d0\u793a\u4ee5\u589e\u5f37\u6a21\u578b\u6548\u80fd\uff0c\u4e26\u4f7f\u7528\u56f0\u60d1\u5ea6\u548c\u50b3\u7d71\u6307\u6a19\uff08\u5982\u6e96\u78ba\u5ea6\u548c F1 \u5206\u6578\uff09\u9032\u884c\u8a55\u4f30\u3002\u7d50\u679c\u986f\u793a\uff0cPHI-3.5 \u5728\u5fae\u8abf\u5f8c\u7684 MCQ \u8655\u7406\u65b9\u9762\u6709\u986f\u8457\u6539\u5584\uff0c\u56f0\u60d1\u5ea6\u5f9e 4.68 \u964d\u4f4e\u5230 2.27\uff0c\u6e96\u78ba\u5ea6\u5f9e 62% \u63d0\u9ad8\u5230 90.8%\u3002\u9019\u9805\u7814\u7a76\u5f37\u8abf\u4e86\u9ad8\u6548\u6a21\u578b\u5728\u9069\u61c9\u6027\u5b78\u7fd2\u7cfb\u7d71\u548c\u6559\u80b2\u8a55\u4f30\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u70ba\u66f4\u5ee3\u6cdb\u5730\u6574\u5408\u5230\u8ab2\u5802\u4e2d\u92ea\u5e73\u4e86\u9053\u8def\uff0c\u7279\u5225\u662f\u5728\u8003\u8a66\u6e96\u5099\u3001\u5b78\u751f\u56de\u994b\u548c\u500b\u4eba\u5316\u5b78\u7fd2\u7b49\u9818\u57df\u3002", "author": "Mohamed Hisham Abdellatif et.al.", "authors": "Mohamed Hisham Abdellatif", "id": "2501.01588v1", "paper_url": "http://arxiv.org/abs/2501.01588v1", "repo": "null"}}