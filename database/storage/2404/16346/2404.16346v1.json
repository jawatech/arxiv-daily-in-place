{"2404.16346": {"publish_time": "2024-04-25", "title": "Light-weight Retinal Layer Segmentation with Global Reasoning", "paper_summary": "Automatic retinal layer segmentation with medical images, such as optical\ncoherence tomography (OCT) images, serves as an important tool for diagnosing\nophthalmic diseases. However, it is challenging to achieve accurate\nsegmentation due to low contrast and blood flow noises presented in the images.\nIn addition, the algorithm should be light-weight to be deployed for practical\nclinical applications. Therefore, it is desired to design a light-weight\nnetwork with high performance for retinal layer segmentation. In this paper, we\npropose LightReSeg for retinal layer segmentation which can be applied to OCT\nimages. Specifically, our approach follows an encoder-decoder structure, where\nthe encoder part employs multi-scale feature extraction and a Transformer block\nfor fully exploiting the semantic information of feature maps at all scales and\nmaking the features have better global reasoning capabilities, while the\ndecoder part, we design a multi-scale asymmetric attention (MAA) module for\npreserving the semantic information at each encoder scale. The experiments show\nthat our approach achieves a better segmentation performance compared to the\ncurrent state-of-the-art method TransUnet with 105.7M parameters on both our\ncollected dataset and two other public datasets, with only 3.3M parameters.", "paper_summary_zh": "\u81ea\u52d5\u8996\u7db2\u819c\u5c64\u5206\u5272\u4f7f\u7528\u91ab\u5b78\u5f71\u50cf\uff0c\u4f8b\u5982\u5149\u5b78\u76f8\u5e72\u65b7\u5c64\u6383\u63cf (OCT) \u5f71\u50cf\uff0c\u505a\u70ba\u8a3a\u65b7\u773c\u79d1\u75be\u75c5\u7684\u91cd\u8981\u5de5\u5177\u3002\u7136\u800c\uff0c\u7531\u65bc\u5f71\u50cf\u4e2d\u5c0d\u6bd4\u5ea6\u4f4e\u548c\u8840\u6d41\u96dc\u8a0a\uff0c\u8981\u9054\u6210\u7cbe\u78ba\u7684\u5206\u5272\u5177\u6709\u6311\u6230\u6027\u3002\u6b64\u5916\uff0c\u6f14\u7b97\u6cd5\u61c9\u8f15\u91cf\u5316\uff0c\u624d\u80fd\u90e8\u7f72\u65bc\u5be6\u969b\u7684\u81e8\u5e8a\u61c9\u7528\u3002\u56e0\u6b64\uff0c\u9700\u8981\u8a2d\u8a08\u4e00\u500b\u8f15\u91cf\u7d1a\u4e14\u9ad8\u6027\u80fd\u7684\u7db2\u8def\uff0c\u7528\u65bc\u8996\u7db2\u819c\u5c64\u5206\u5272\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa LightReSeg \u7528\u65bc\u8996\u7db2\u819c\u5c64\u5206\u5272\uff0c\u53ef\u61c9\u7528\u65bc OCT \u5f71\u50cf\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u7684\u505a\u6cd5\u9075\u5faa\u7de8\u78bc\u5668-\u89e3\u78bc\u5668\u7d50\u69cb\uff0c\u5176\u4e2d\u7de8\u78bc\u5668\u90e8\u5206\u63a1\u7528\u591a\u5c3a\u5ea6\u7279\u5fb5\u8403\u53d6\u548c Transformer \u5340\u584a\uff0c\u4ee5\u5145\u5206\u5229\u7528\u5404\u7a2e\u5c3a\u5ea6\u7279\u5fb5\u5716\u7684\u8a9e\u7fa9\u8cc7\u8a0a\uff0c\u4e26\u8b93\u7279\u5fb5\u5177\u5099\u66f4\u597d\u7684\u5168\u5c40\u63a8\u7406\u80fd\u529b\uff0c\u800c\u89e3\u78bc\u5668\u90e8\u5206\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u591a\u5c3a\u5ea6\u975e\u5c0d\u7a31\u6ce8\u610f\u529b (MAA) \u6a21\u7d44\uff0c\u7528\u65bc\u4fdd\u7559\u6bcf\u500b\u7de8\u78bc\u5668\u5c3a\u5ea6\u7684\u8a9e\u7fa9\u8cc7\u8a0a\u3002\u5be6\u9a57\u986f\u793a\uff0c\u8207\u73fe\u6709\u6700\u5148\u9032\u65b9\u6cd5 TransUnet \u76f8\u6bd4\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5728\u6211\u5011\u6536\u96c6\u7684\u8cc7\u6599\u96c6\u548c\u5169\u500b\u5176\u4ed6\u516c\u958b\u8cc7\u6599\u96c6\u4e0a\uff0c\u4ee5\u50c5 330 \u842c\u500b\u53c3\u6578\uff0c\u9054\u5230\u4e86\u66f4\u597d\u7684\u5206\u5272\u6548\u80fd\uff0c\u800c TransUnet \u6709 10570 \u842c\u500b\u53c3\u6578\u3002", "author": "Xiang He et.al.", "authors": "Xiang He, Weiye Song, Yiming Wang, Fabio Poiesi, Ji Yi, Manishi Desai, Quanqing Xu, Kongzheng Yang, Yi Wan", "id": "2404.16346v1", "paper_url": "http://arxiv.org/abs/2404.16346v1", "repo": "null"}}