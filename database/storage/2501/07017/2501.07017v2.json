{"2501.07017": {"publish_time": "2025-01-13", "title": "UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM", "paper_summary": "3D medical image segmentation has progressed considerably due to\nConvolutional Neural Networks (CNNs) and Vision Transformers (ViTs), yet these\nmethods struggle to balance long-range dependency acquisition with\ncomputational efficiency. To address this challenge, we propose UNETVL (U-Net\nVision-LSTM), a novel architecture that leverages recent advancements in\ntemporal information processing. UNETVL incorporates Vision-LSTM (ViL) for\nimproved scalability and memory functions, alongside an efficient Chebyshev\nKolmogorov-Arnold Networks (KAN) to handle complex and long-range dependency\npatterns more effectively. We validated our method on the ACDC and AMOS2022\n(post challenge Task 2) benchmark datasets, showing a significant improvement\nin mean Dice score compared to recent state-of-the-art approaches, especially\nover its predecessor, UNETR, with increases of 7.3% on ACDC and 15.6% on AMOS,\nrespectively. Extensive ablation studies were conducted to demonstrate the\nimpact of each component in UNETVL, providing a comprehensive understanding of\nits architecture. Our code is available at https://github.com/tgrex6/UNETVL,\nfacilitating further research and applications in this domain.", "paper_summary_zh": "3D \u91ab\u5b78\u5f71\u50cf\u5206\u5272\u7531\u65bc\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN) \u548c\u8996\u89baTransformer (ViT) \u800c\u9032\u6b65\u8a31\u591a\uff0c\u7136\u800c\u9019\u4e9b\u65b9\u6cd5\u96e3\u4ee5\u5e73\u8861\u9577\u7a0b\u4f9d\u8cf4\u95dc\u4fc2\u64f7\u53d6\u8207\u904b\u7b97\u6548\u7387\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u500b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa UNETVL (U-Net \u8996\u89ba LSTM)\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u67b6\u69cb\uff0c\u5b83\u5229\u7528\u6642\u9593\u8cc7\u8a0a\u8655\u7406\u7684\u6700\u65b0\u9032\u5c55\u3002UNETVL \u7d50\u5408\u8996\u89ba LSTM (ViL) \u4ee5\u63d0\u5347\u53ef\u64f4\u5145\u6027\u548c\u8a18\u61b6\u529f\u80fd\uff0c\u4e26\u7d50\u5408\u9ad8\u6548\u7684\u5207\u6bd4\u96ea\u592b Kolmogorov-Arnold \u7db2\u8def (KAN) \u4ee5\u66f4\u6709\u6548\u7387\u5730\u8655\u7406\u8907\u96dc\u4e14\u9577\u7a0b\u7684\u4f9d\u8cf4\u95dc\u4fc2\u6a21\u5f0f\u3002\u6211\u5011\u5728 ACDC \u548c AMOS2022\uff08\u6311\u6230\u4efb\u52d9 2 \u4e4b\u5f8c\uff09\u57fa\u6e96\u8cc7\u6599\u96c6\u9a57\u8b49\u4e86\u6211\u5011\u7684\u65b9\u6cd5\uff0c\u8207\u6700\u8fd1\u7684\u6700\u65b0\u6280\u8853\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5e73\u5747 Dice \u5206\u6578\u6709\u986f\u8457\u63d0\u5347\uff0c\u7279\u5225\u662f\u8207\u5176\u524d\u8eab UNETR \u76f8\u6bd4\uff0c\u5728 ACDC \u4e0a\u63d0\u5347\u4e86 7.3%\uff0c\u5728 AMOS \u4e0a\u63d0\u5347\u4e86 15.6%\u3002\u6211\u5011\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u6d88\u878d\u7814\u7a76\uff0c\u4ee5\u5c55\u793a UNETVL \u4e2d\u6bcf\u500b\u5143\u4ef6\u7684\u5f71\u97ff\uff0c\u63d0\u4f9b\u5c0d\u5176\u67b6\u69cb\u7684\u5168\u9762\u7406\u89e3\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/tgrex6/UNETVL \u53d6\u5f97\uff0c\u4fc3\u9032\u9032\u4e00\u6b65\u7684\u5728\u9019\u65b9\u9762\u7684\u7814\u7a76\u548c\u61c9\u7528\u3002", "author": "Xuhui Guo et.al.", "authors": "Xuhui Guo, Tanmoy Dam, Rohan Dhamdhere, Gourav Modanwal, Anant Madabhushi", "id": "2501.07017v2", "paper_url": "http://arxiv.org/abs/2501.07017v2", "repo": "null"}}