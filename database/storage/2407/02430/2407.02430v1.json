{"2407.02430": {"publish_time": "2024-07-02", "title": "Meta 3D TextureGen: Fast and Consistent Texture Generation for 3D Objects", "paper_summary": "The recent availability and adaptability of text-to-image models has sparked\na new era in many related domains that benefit from the learned text priors as\nwell as high-quality and fast generation capabilities, one of which is texture\ngeneration for 3D objects. Although recent texture generation methods achieve\nimpressive results by using text-to-image networks, the combination of global\nconsistency, quality, and speed, which is crucial for advancing texture\ngeneration to real-world applications, remains elusive. To that end, we\nintroduce Meta 3D TextureGen: a new feedforward method comprised of two\nsequential networks aimed at generating high-quality and globally consistent\ntextures for arbitrary geometries of any complexity degree in less than 20\nseconds. Our method achieves state-of-the-art results in quality and speed by\nconditioning a text-to-image model on 3D semantics in 2D space and fusing them\ninto a complete and high-resolution UV texture map, as demonstrated by\nextensive qualitative and quantitative evaluations. In addition, we introduce a\ntexture enhancement network that is capable of up-scaling any texture by an\narbitrary ratio, producing 4k pixel resolution textures.", "paper_summary_zh": "\u6700\u8fd1\u6587\u672c\u8f6c\u56fe\u50cf\u6a21\u578b\u7684\u53ef\u7528\u6027\u548c\u9002\u5e94\u6027\u6fc0\u53d1\u4e86\u5728\u8bb8\u591a\u76f8\u5173\u9886\u57df\u7684\u5168\u65b0\u65f6\u4ee3\uff0c\u8fd9\u4e9b\u9886\u57df\u53d7\u76ca\u4e8e\u5b66\u4e60\u7684\u6587\u672c\u5148\u9a8c\u4ee5\u53ca\u9ad8\u8d28\u91cf\u548c\u5feb\u901f\u7684\u751f\u6210\u80fd\u529b\uff0c\u5176\u4e2d\u4e4b\u4e00\u662f 3D \u7269\u4f53\u7684\u7eb9\u7406\u751f\u6210\u3002\u5c3d\u7ba1\u6700\u8fd1\u7684\u7eb9\u7406\u751f\u6210\u65b9\u6cd5\u901a\u8fc7\u4f7f\u7528\u6587\u672c\u5230\u56fe\u50cf\u7f51\u7edc\u53d6\u5f97\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u7ed3\u679c\uff0c\u4f46\u5168\u5c40\u4e00\u81f4\u6027\u3001\u8d28\u91cf\u548c\u901f\u5ea6\u7684\u7ed3\u5408\u5bf9\u4e8e\u63a8\u8fdb\u7eb9\u7406\u751f\u6210\u5230\u5b9e\u9645\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u4e00\u70b9\u4ecd\u7136\u96be\u4ee5\u6349\u6478\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u5f15\u5165\u4e86 Meta 3D TextureGen\uff1a\u4e00\u79cd\u65b0\u7684\u524d\u9988\u65b9\u6cd5\uff0c\u7531\u4e24\u4e2a\u987a\u5e8f\u7f51\u7edc\u7ec4\u6210\uff0c\u65e8\u5728\u4e3a\u4efb\u610f\u590d\u6742\u7a0b\u5ea6\u7684\u51e0\u4f55\u5f62\u72b6\u751f\u6210\u9ad8\u8d28\u91cf\u4e14\u5168\u5c40\u4e00\u81f4\u7684\u7eb9\u7406\uff0c\u65f6\u95f4\u5c11\u4e8e 20 \u79d2\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u901a\u8fc7\u5728 2D \u7a7a\u95f4\u4e2d\u5bf9\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u8fdb\u884c 3D \u8bed\u4e49\u8c03\u8282\uff0c\u5e76\u5c06\u5b83\u4eec\u878d\u5408\u5230\u5b8c\u6574\u4e14\u9ad8\u5206\u8fa8\u7387\u7684 UV \u7eb9\u7406\u8d34\u56fe\u4e2d\uff0c\u4ece\u800c\u5728\u8d28\u91cf\u548c\u901f\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u8fd9\u4e00\u70b9\u5df2\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9a\u6027\u548c\u5b9a\u91cf\u8bc4\u4f30\u5f97\u5230\u8bc1\u660e\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u7eb9\u7406\u589e\u5f3a\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u80fd\u591f\u4ee5\u4efb\u610f\u6bd4\u4f8b\u653e\u5927\u4efb\u4f55\u7eb9\u7406\uff0c\u751f\u6210 4k \u50cf\u7d20\u5206\u8fa8\u7387\u7684\u7eb9\u7406\u3002", "author": "Raphael Bensadoun et.al.", "authors": "Raphael Bensadoun, Yanir Kleiman, Idan Azuri, Omri Harosh, Andrea Vedaldi, Natalia Neverova, Oran Gafni", "id": "2407.02430v1", "paper_url": "http://arxiv.org/abs/2407.02430v1", "repo": "null"}}