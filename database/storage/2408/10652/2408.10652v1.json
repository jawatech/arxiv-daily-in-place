{"2408.10652": {"publish_time": "2024-08-20", "title": "Vocabulary-Free 3D Instance Segmentation with Vision and Language Assistant", "paper_summary": "Most recent 3D instance segmentation methods are open vocabulary, offering a\ngreater flexibility than closed-vocabulary methods. Yet, they are limited to\nreasoning within a specific set of concepts, \\ie the vocabulary, prompted by\nthe user at test time. In essence, these models cannot reason in an open-ended\nfashion, i.e., answering ``List the objects in the scene.''. We introduce the\nfirst method to address 3D instance segmentation in a setting that is void of\nany vocabulary prior, namely a vocabulary-free setting. We leverage a large\nvision-language assistant and an open-vocabulary 2D instance segmenter to\ndiscover and ground semantic categories on the posed images. To form 3D\ninstance mask, we first partition the input point cloud into dense superpoints,\nwhich are then merged into 3D instance masks. We propose a novel superpoint\nmerging strategy via spectral clustering, accounting for both mask coherence\nand semantic coherence that are estimated from the 2D object instance masks. We\nevaluate our method using ScanNet200 and Replica, outperforming existing\nmethods in both vocabulary-free and open-vocabulary settings. Code will be made\navailable.", "paper_summary_zh": "\u6700\u65b0 3D \u5be6\u4f8b\u5206\u5272\u65b9\u6cd5\u70ba\u958b\u653e\u5f0f\u8a5e\u5f59\uff0c\u63d0\u4f9b\u6bd4\u5c01\u9589\u5f0f\u8a5e\u5f59\u65b9\u6cd5\u66f4\u5927\u7684\u9748\u6d3b\u6027\u3002\u7136\u800c\uff0c\u5b83\u5011\u50c5\u9650\u65bc\u5728\u7279\u5b9a\u6982\u5ff5\u96c6\u5408\uff08\u5373\u8a5e\u5f59\uff09\u5167\u9032\u884c\u63a8\u7406\uff0c\u7531\u4f7f\u7528\u8005\u5728\u6e2c\u8a66\u6642\u63d0\u793a\u3002\u5f9e\u672c\u8cea\u4e0a\u4f86\u8aaa\uff0c\u9019\u4e9b\u6a21\u578b\u7121\u6cd5\u4ee5\u958b\u653e\u5f0f\u7684\u65b9\u5f0f\u9032\u884c\u63a8\u7406\uff0c\u5373\u56de\u7b54\u300c\u5217\u51fa\u5834\u666f\u4e2d\u7684\u7269\u4ef6\u300d\u3002\u6211\u5011\u5f15\u5165\u4e86\u7b2c\u4e00\u500b\u65b9\u6cd5\u4f86\u89e3\u6c7a 3D \u5be6\u4f8b\u5206\u5272\uff0c\u5176\u8a2d\u5b9a\u4e2d\u6c92\u6709\u4efb\u4f55\u5148\u524d\u7684\u8a5e\u5f59\uff0c\u5373\u7121\u8a5e\u5f59\u8a2d\u5b9a\u3002\u6211\u5011\u5229\u7528\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u52a9\u7406\u548c\u958b\u653e\u5f0f\u8a5e\u5f59 2D \u5be6\u4f8b\u5206\u5272\u5668\uff0c\u5728\u6240\u63d0\u51fa\u7684\u5f71\u50cf\u4e0a\u767c\u73fe\u548c\u5efa\u7acb\u8a9e\u7fa9\u985e\u5225\u3002\u70ba\u4e86\u5f62\u6210 3D \u5be6\u4f8b\u906e\u7f69\uff0c\u6211\u5011\u9996\u5148\u5c07\u8f38\u5165\u9ede\u96f2\u5206\u5272\u6210\u5bc6\u96c6\u7684\u8d85\u9ede\uff0c\u7136\u5f8c\u5c07\u5176\u5408\u4f75\u6210 3D \u5be6\u4f8b\u906e\u7f69\u3002\u6211\u5011\u900f\u904e\u5149\u8b5c\u805a\u985e\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u8d85\u9ede\u5408\u4f75\u7b56\u7565\uff0c\u8003\u91cf\u4e86\u5f9e 2D \u7269\u4ef6\u5be6\u4f8b\u906e\u7f69\u4f30\u8a08\u7684\u906e\u7f69\u4e00\u81f4\u6027\u548c\u8a9e\u7fa9\u4e00\u81f4\u6027\u3002\u6211\u5011\u4f7f\u7528 ScanNet200 \u548c Replica \u8a55\u4f30\u6211\u5011\u7684\u6a21\u578b\uff0c\u5728\u7121\u8a5e\u5f59\u548c\u958b\u653e\u5f0f\u8a5e\u5f59\u8a2d\u5b9a\u4e2d\u90fd\u512a\u65bc\u73fe\u6709\u65b9\u6cd5\u3002\u7a0b\u5f0f\u78bc\u5c07\u6703\u516c\u958b\u3002", "author": "Guofeng Mei et.al.", "authors": "Guofeng Mei, Luigi Riz, Yiming Wang, Fabio Poiesi", "id": "2408.10652v1", "paper_url": "http://arxiv.org/abs/2408.10652v1", "repo": "null"}}