{"2411.18564": {"publish_time": "2024-11-27", "title": "A Pipeline of Neural-Symbolic Integration to Enhance Spatial Reasoning in Large Language Models", "paper_summary": "Large Language Models (LLMs) have demonstrated impressive capabilities across\nvarious tasks. However, LLMs often struggle with spatial reasoning which is one\nessential part of reasoning and inference and requires understanding complex\nrelationships between objects in space. This paper proposes a novel\nneural-symbolic framework that enhances LLMs' spatial reasoning abilities. We\nevaluate our approach on two benchmark datasets: StepGame and SparQA,\nimplementing three distinct strategies: (1) ASP (Answer Set Programming)-based\nsymbolic reasoning, (2) LLM + ASP pipeline using DSPy, and (3) Fact + Logical\nrules. Our experiments demonstrate significant improvements over the baseline\nprompting methods, with accuracy increases of 40-50% on StepGame} dataset and\n3-13% on the more complex SparQA dataset. The \"LLM + ASP\" pipeline achieves\nparticularly strong results on the tasks of Finding Relations (FR) and Finding\nBlock (FB) questions, though performance varies across different question\ntypes. The impressive results suggest that while neural-symbolic approaches\noffer promising directions for enhancing spatial reasoning in LLMs, their\neffectiveness depends heavily on the specific task characteristics and\nimplementation strategies. We propose an integrated, simple yet effective set\nof strategies using a neural-symbolic pipeline to boost spatial reasoning\nabilities in LLMs. This pipeline and its strategies demonstrate strong and\nbroader applicability to other reasoning domains in LLMs, such as temporal\nreasoning, deductive inference etc.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u5c55\u793a\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\u3002\u7136\u800c\uff0cLLM \u901a\u5e38\u96e3\u4ee5\u9032\u884c\u7a7a\u9593\u63a8\u7406\uff0c\u800c\u7a7a\u9593\u63a8\u7406\u662f\u63a8\u7406\u548c\u63a8\u8ad6\u7684\u91cd\u8981\u7d44\u6210\u90e8\u5206\uff0c\u9700\u8981\u7406\u89e3\u7a7a\u9593\u4e2d\u7269\u4ef6\u4e4b\u9593\u7684\u8907\u96dc\u95dc\u4fc2\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684\u795e\u7d93\u7b26\u865f\u6846\u67b6\uff0c\u4ee5\u589e\u5f37 LLM \u7684\u7a7a\u9593\u63a8\u7406\u80fd\u529b\u3002\u6211\u5011\u5728\u5169\u500b\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u8a55\u4f30\u6211\u5011\u7684\u505a\u6cd5\uff1aStepGame \u548c SparQA\uff0c\u5be6\u65bd\u4e86\u4e09\u7a2e\u4e0d\u540c\u7684\u7b56\u7565\uff1a(1) \u57fa\u65bc ASP\uff08Answer Set Programming\uff09\u7684\u7b26\u865f\u63a8\u7406\uff0c(2) \u4f7f\u7528 DSPy \u7684 LLM + ASP \u7ba1\u7dda\uff0c\u4ee5\u53ca (3) \u4e8b\u5be6 + \u908f\u8f2f\u898f\u5247\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u8207\u57fa\u6e96\u63d0\u793a\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6709\u4e86\u986f\u8457\u7684\u6539\u9032\uff0cStepGame \u8cc7\u6599\u96c6\u7684\u6e96\u78ba\u5ea6\u63d0\u9ad8\u4e86 40-50%\uff0c\u800c\u66f4\u8907\u96dc\u7684 SparQA \u8cc7\u6599\u96c6\u7684\u6e96\u78ba\u5ea6\u63d0\u9ad8\u4e86 3-13%\u3002\u5118\u7ba1\u5728\u4e0d\u540c\u985e\u578b\u7684\u554f\u984c\u4e2d\u8868\u73fe\u4e0d\u4e00\uff0c\u4f46\u300cLLM + ASP\u300d\u7ba1\u7dda\u5728\u5c0b\u627e\u95dc\u4fc2 (FR) \u548c\u5c0b\u627e\u5340\u584a (FB) \u7684\u554f\u984c\u4e0a\u53d6\u5f97\u4e86\u7279\u5225\u986f\u8457\u7684\u7d50\u679c\u3002\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u7d50\u679c\u8868\u660e\uff0c\u96d6\u7136\u795e\u7d93\u7b26\u865f\u65b9\u6cd5\u70ba\u589e\u5f37 LLM \u4e2d\u7684\u7a7a\u9593\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u65b9\u5411\uff0c\u4f46\u5176\u6709\u6548\u6027\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u6c7a\u65bc\u5177\u9ad4\u7684\u4efb\u52d9\u7279\u5fb5\u548c\u5be6\u65bd\u7b56\u7565\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u6574\u5408\u3001\u7c21\u55ae\u4f46\u6709\u6548\u7684\u7b56\u7565\u96c6\uff0c\u4f7f\u7528\u795e\u7d93\u7b26\u865f\u7ba1\u7dda\u4f86\u63d0\u5347 LLM \u4e2d\u7684\u7a7a\u9593\u63a8\u7406\u80fd\u529b\u3002\u9019\u500b\u7ba1\u7dda\u53ca\u5176\u7b56\u7565\u8b49\u660e\u4e86\u5c0d LLM \u4e2d\u5176\u4ed6\u63a8\u7406\u9818\u57df\u7684\u5f37\u5927\u800c\u66f4\u5ee3\u6cdb\u7684\u9069\u7528\u6027\uff0c\u4f8b\u5982\u6642\u9593\u63a8\u7406\u3001\u6f14\u7e79\u63a8\u7406\u7b49\u3002", "author": "Rong Wang et.al.", "authors": "Rong Wang, Kun Sun, Jonas Kuhn", "id": "2411.18564v1", "paper_url": "http://arxiv.org/abs/2411.18564v1", "repo": "null"}}