{"2410.10489": {"publish_time": "2024-10-14", "title": "Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation", "paper_summary": "The training data for LLMs embeds societal values, increasing their\nfamiliarity with the language's culture. Our analysis found that 44% of the\nvariance in the ability of GPT-4o to reflect the societal values of a country,\nas measured by the World Values Survey, correlates with the availability of\ndigital resources in that language. Notably, the error rate was more than five\ntimes higher for the languages of the lowest resource compared to the languages\nof the highest resource. For GPT-4-turbo, this correlation rose to 72%,\nsuggesting efforts to improve the familiarity with the non-English language\nbeyond the web-scraped data. Our study developed one of the largest and most\nrobust datasets in this topic area with 21 country-language pairs, each of\nwhich contain 94 survey questions verified by native speakers. Our results\nhighlight the link between LLM performance and digital data availability in\ntarget languages. Weaker performance in low-resource languages, especially\nprominent in the Global South, may worsen digital divides. We discuss\nstrategies proposed to address this, including developing multilingual LLMs\nfrom the ground up and enhancing fine-tuning on diverse linguistic datasets, as\nseen in African language initiatives.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u8a13\u7df4\u8cc7\u6599\u6703\u5167\u5d4c\u793e\u6703\u50f9\u503c\u89c0\uff0c\u63d0\u5347\u5176\u5c0d\u8a9e\u8a00\u6587\u5316\u7684\u719f\u6089\u5ea6\u3002\u6211\u5011\u7684\u5206\u6790\u767c\u73fe\uff0cGPT-4o \u53cd\u6620\u4e00\u500b\u570b\u5bb6\u793e\u6703\u50f9\u503c\u89c0\u7684\u80fd\u529b\u6709 44% \u7684\u8b8a\u7570\uff0c\u6839\u64da\u4e16\u754c\u50f9\u503c\u89c0\u8abf\u67e5\u6e2c\u91cf\uff0c\u8207\u8a72\u8a9e\u8a00\u6578\u4f4d\u8cc7\u6e90\u7684\u53ef\u7528\u6027\u76f8\u95dc\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8cc7\u6e90\u6700\u5c11\u7684\u8a9e\u8a00\u7684\u932f\u8aa4\u7387\u6bd4\u8cc7\u6e90\u6700\u591a\u7684\u8a9e\u8a00\u9ad8\u51fa\u4e94\u500d\u4ee5\u4e0a\u3002\u5c0d\u65bc GPT-4-turbo\uff0c\u6b64\u76f8\u95dc\u6027\u4e0a\u5347\u81f3 72%\uff0c\u986f\u793a\u51fa\u9664\u4e86\u7db2\u8def\u64f7\u53d6\u8cc7\u6599\u4e4b\u5916\uff0c\u6539\u5584\u5c0d\u975e\u82f1\u8a9e\u8a9e\u8a00\u719f\u6089\u5ea6\u7684\u52aa\u529b\u3002\u6211\u5011\u7684\u7814\u7a76\u958b\u767c\u4e86\u9019\u500b\u4e3b\u984c\u9818\u57df\u4e2d\u6700\u5927\u4e14\u6700\u7a69\u5065\u7684\u8cc7\u6599\u96c6\u4e4b\u4e00\uff0c\u5305\u542b 21 \u7d44\u570b\u5bb6\u8a9e\u8a00\u5c0d\uff0c\u6bcf\u7d44\u5305\u542b 94 \u500b\u7531\u6bcd\u8a9e\u4eba\u58eb\u9a57\u8b49\u7684\u8abf\u67e5\u554f\u984c\u3002\u6211\u5011\u7684\u7d50\u679c\u7a81\u986f\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u6548\u80fd\u8207\u76ee\u6a19\u8a9e\u8a00\u4e2d\u6578\u4f4d\u8cc7\u6599\u53ef\u7528\u6027\u4e4b\u9593\u7684\u95dc\u806f\u6027\u3002\u5728\u8cc7\u6e90\u8f03\u5c11\u7684\u8a9e\u8a00\u4e2d\u6548\u80fd\u8f03\u5dee\uff0c\u7279\u5225\u662f\u5728\u5168\u7403\u5357\u65b9\u986f\u8457\uff0c\u53ef\u80fd\u6703\u60e1\u5316\u6578\u4f4d\u9d3b\u6e9d\u3002\u6211\u5011\u8a0e\u8ad6\u4e86\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\u800c\u63d0\u51fa\u7684\u7b56\u7565\uff0c\u5305\u62ec\u5f9e\u982d\u958b\u59cb\u958b\u767c\u591a\u8a9e\u8a00\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff0c\u4ee5\u53ca\u5728\u4e0d\u540c\u7684\u8a9e\u8a00\u8cc7\u6599\u96c6\u4e0a\u52a0\u5f37\u5fae\u8abf\uff0c\u5982\u540c\u5728\u975e\u6d32\u8a9e\u8a00\u8a08\u756b\u4e2d\u6240\u898b\u3002", "author": "Sharif Kazemi et.al.", "authors": "Sharif Kazemi, Gloria Gerhardt, Jonty Katz, Caroline Ida Kuria, Estelle Pan, Umang Prabhakar", "id": "2410.10489v1", "paper_url": "http://arxiv.org/abs/2410.10489v1", "repo": "null"}}