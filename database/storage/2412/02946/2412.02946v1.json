{"2412.02946": {"publish_time": "2024-12-04", "title": "Who Brings the Frisbee: Probing Hidden Hallucination Factors in Large Vision-Language Model via Causality Analysis", "paper_summary": "Recent advancements in large vision-language models (LVLM) have significantly\nenhanced their ability to comprehend visual inputs alongside natural language.\nHowever, a major challenge in their real-world application is hallucination,\nwhere LVLMs generate non-existent visual elements, eroding user trust. The\nunderlying mechanism driving this multimodal hallucination is poorly\nunderstood. Minimal research has illuminated whether contexts such as sky,\ntree, or grass field involve the LVLM in hallucinating a frisbee. We\nhypothesize that hidden factors, such as objects, contexts, and semantic\nforeground-background structures, induce hallucination. This study proposes a\nnovel causal approach: a hallucination probing system to identify these hidden\nfactors. By analyzing the causality between images, text prompts, and network\nsaliency, we systematically explore interventions to block these factors. Our\nexperimental findings show that a straightforward technique based on our\nanalysis can significantly reduce hallucinations. Additionally, our analyses\nindicate the potential to edit network internals to minimize hallucinated\noutputs.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLM) \u7684\u6700\u65b0\u9032\u5c55\u986f\u8457\u589e\u5f37\u4e86\u5b83\u5011\u7406\u89e3\u81ea\u7136\u8a9e\u8a00\u548c\u8996\u89ba\u8f38\u5165\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u5728\u73fe\u5be6\u4e16\u754c\u61c9\u7528\u4e2d\u7684\u4e00\u500b\u91cd\u5927\u6311\u6230\u662f\u5e7b\u89ba\uff0c\u5176\u4e2d LVLM \u7522\u751f\u4e0d\u5b58\u5728\u7684\u8996\u89ba\u5143\u7d20\uff0c\u4fb5\u8755\u4e86\u4f7f\u7528\u8005\u7684\u4fe1\u4efb\u3002\u9a45\u52d5\u9019\u7a2e\u591a\u6a21\u614b\u5e7b\u89ba\u7684\u5e95\u5c64\u6a5f\u5236\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002\u5f88\u5c11\u6709\u7814\u7a76\u63a2\u8a0e\u5929\u7a7a\u3001\u6a39\u6728\u6216\u8349\u5730\u7b49\u80cc\u666f\u662f\u5426\u6703\u8b93 LVLM \u7522\u751f\u98db\u76e4\u7684\u5e7b\u89ba\u3002\u6211\u5011\u5047\u8a2d\u7269\u9ad4\u3001\u80cc\u666f\u548c\u8a9e\u7fa9\u524d\u666f\u80cc\u666f\u7d50\u69cb\u7b49\u96b1\u85cf\u56e0\u7d20\u6703\u8a98\u767c\u5e7b\u89ba\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u56e0\u679c\u65b9\u6cd5\uff1a\u4e00\u7a2e\u5e7b\u89ba\u63a2\u6e2c\u7cfb\u7d71\uff0c\u7528\u65bc\u8b58\u5225\u9019\u4e9b\u96b1\u85cf\u56e0\u7d20\u3002\u901a\u904e\u5206\u6790\u5f71\u50cf\u3001\u6587\u5b57\u63d0\u793a\u548c\u7db2\u8def\u986f\u8457\u6027\u4e4b\u9593\u7684\u56e0\u679c\u95dc\u4fc2\uff0c\u6211\u5011\u7cfb\u7d71\u6027\u5730\u63a2\u7d22\u4e86\u963b\u6b62\u9019\u4e9b\u56e0\u7d20\u7684\u5e72\u9810\u63aa\u65bd\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u57fa\u65bc\u6211\u5011\u5206\u6790\u7684\u4e00\u7a2e\u76f4\u63a5\u6280\u8853\u53ef\u4ee5\u986f\u8457\u6e1b\u5c11\u5e7b\u89ba\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u5206\u6790\u8868\u660e\u6709\u6f5b\u529b\u7de8\u8f2f\u7db2\u8def\u5167\u90e8\u7d50\u69cb\u4ee5\u6700\u5c0f\u5316\u7522\u751f\u5e7b\u89ba\u7684\u8f38\u51fa\u3002", "author": "Po-Hsuan Huang et.al.", "authors": "Po-Hsuan Huang, Jeng-Lin Li, Chin-Po Chen, Ming-Ching Chang, Wei-Chao Chen", "id": "2412.02946v1", "paper_url": "http://arxiv.org/abs/2412.02946v1", "repo": "null"}}