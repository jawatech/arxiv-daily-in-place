
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-29**|**Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations**|Zijie Liu et.al.|[2501.17860v1](http://arxiv.org/abs/2501.17860v1)|null|
|**2025-01-29**|**Improving Your Model Ranking on Chatbot Arena by Vote Rigging**|Rui Min et.al.|[2501.17858v1](http://arxiv.org/abs/2501.17858v1)|[link](https://github.com/sail-sg/rigging-chatbotarena)|
|**2025-01-29**|**GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings**|Ziang Liu et.al.|[2501.17855v1](http://arxiv.org/abs/2501.17855v1)|null|
|**2025-01-29**|**From Sparse to Dense: Toddler-inspired Reward Transition in Goal-Oriented Reinforcement Learning**|Junseok Park et.al.|[2501.17842v1](http://arxiv.org/abs/2501.17842v1)|null|
|**2025-01-29**|**Learning Beyond the Surface: How Far Can Continual Pre-Training with LoRA Enhance LLMs' Domain-Specific Insight Learning?**|Pouya Pezeshkpour et.al.|[2501.17840v1](http://arxiv.org/abs/2501.17840v1)|[link](https://github.com/megagonlabs/insight_miner)|
|**2025-01-29**|**A Comprehensive Survey on Legal Summarization: Challenges and Future Directions**|Mousumi Akter et.al.|[2501.17830v1](http://arxiv.org/abs/2501.17830v1)|null|
|**2025-01-29**|**U2A: Unified Unimodal Adaptation for Robust and Efficient Multimodal Learning**|Md Kaykobad Reza et.al.|[2501.17823v1](http://arxiv.org/abs/2501.17823v1)|null|
|**2025-01-29**|**Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology**|Sobhan Hemati et.al.|[2501.17822v1](http://arxiv.org/abs/2501.17822v1)|null|
|**2025-01-29**|**P-TAME: Explain Any Image Classifier with Trained Perturbations**|Mariano V. Ntrougkas et.al.|[2501.17813v1](http://arxiv.org/abs/2501.17813v1)|null|
|**2025-01-29**|**Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling**|Xiaokang Chen et.al.|[2501.17811v1](http://arxiv.org/abs/2501.17811v1)|[link](https://github.com/deepseek-ai/janus)|
|**2025-01-29**|**BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights**|Chan-Jan Hsu et.al.|[2501.17790v1](http://arxiv.org/abs/2501.17790v1)|null|
|**2025-01-29**|**Reasoning Over the Glyphs: Evaluation of LLM's Decipherment of Rare Scripts**|Yu-Fei Shih et.al.|[2501.17785v1](http://arxiv.org/abs/2501.17785v1)|null|
|**2025-01-29**|**2SSP: A Two-Stage Framework for Structured Pruning of LLMs**|Fabrizio Sandri et.al.|[2501.17771v1](http://arxiv.org/abs/2501.17771v1)|null|
|**2025-01-29**|**Hybrid Graphs for Table-and-Text based Question Answering using LLMs**|Ankush Agarwal et.al.|[2501.17767v1](http://arxiv.org/abs/2501.17767v1)|null|
|**2025-01-29**|**Yin-Yang: Developing Motifs With Long-Term Structure And Controllability**|Keshav Bhandari et.al.|[2501.17759v1](http://arxiv.org/abs/2501.17759v1)|[link](https://github.com/keshavbhandari/yinyang)|
|**2025-01-29**|**Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation**|Aitor Arrieta et.al.|[2501.17749v1](http://arxiv.org/abs/2501.17749v1)|null|
|**2025-01-29**|**Exact characterization of Îµ-Safe Decision Regions for exponential family distributions and Multi Cost SVM approximation**|Alberto Carlevaro et.al.|[2501.17731v1](http://arxiv.org/abs/2501.17731v1)|null|
|**2025-01-29**|**VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies in Generated Report Without Human Feedback**|Sayeh Gholipour Picha et.al.|[2501.17726v1](http://arxiv.org/abs/2501.17726v1)|null|
|**2025-01-29**|**Using Code Generation to Solve Open Instances of Combinatorial Design Problems**|Christopher D. Rosin et.al.|[2501.17725v1](http://arxiv.org/abs/2501.17725v1)|[link](https://github.com/constructive-codes/cpro1)|
|**2025-01-29**|**RICoTA: Red-teaming of In-the-wild Conversation with Test Attempts**|Eujeong Choi et.al.|[2501.17715v1](http://arxiv.org/abs/2501.17715v1)|[link](https://github.com/boychaboy/ricota)|
|**2025-01-29**|**Inferring Implicit Goals Across Differing Task Models**|Silvia Tulli et.al.|[2501.17704v1](http://arxiv.org/abs/2501.17704v1)|null|
|**2025-01-29**|**Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate**|Yubo Wang et.al.|[2501.17703v1](http://arxiv.org/abs/2501.17703v1)|null|
|**2025-01-29**|**PulmoFusion: Advancing Pulmonary Health with Efficient Multi-Modal Fusion**|Ahmed Sharshar et.al.|[2501.17699v1](http://arxiv.org/abs/2501.17699v1)|[link](https://github.com/ahmed-sharshar/respirodynamics)|
|**2025-01-29**|**Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment**|Zixue Zeng et.al.|[2501.17690v1](http://arxiv.org/abs/2501.17690v1)|null|
|**2025-01-29**|**Planning with Vision-Language Models and a Use Case in Robot-Assisted Teaching**|Xuzhe Dang et.al.|[2501.17665v1](http://arxiv.org/abs/2501.17665v1)|null|
|**2025-01-29**|**Exploring Vision Language Models for Multimodal and Multilingual Stance Detection**|Jake Vasilakes et.al.|[2501.17654v1](http://arxiv.org/abs/2501.17654v1)|null|
|**2025-01-29**|**Tonguescape: Exploring Language Models Understanding of Vowel Articulation**|Haruki Sakajo et.al.|[2501.17643v1](http://arxiv.org/abs/2501.17643v1)|null|
|**2025-01-29**|**In-Context Meta LoRA Generation**|Yihua Shao et.al.|[2501.17635v1](http://arxiv.org/abs/2501.17635v1)|null|
|**2025-01-29**|**The Imitation Game According To Turing**|Sharon Temtsin et.al.|[2501.17629v1](http://arxiv.org/abs/2501.17629v1)|null|
|**2025-01-29**|**Uncertainty Quantification and Decomposition for LLM-based Recommendation**|Wonbin Kweon et.al.|[2501.17630v1](http://arxiv.org/abs/2501.17630v1)|[link](https://github.com/wonbinkweon/unc_llm_rec_www2025)|
|**2025-01-29**|**Structured Context Recomposition for Large Language Models Using Probabilistic Layer Realignment**|Jonathan Teel et.al.|[2501.17617v1](http://arxiv.org/abs/2501.17617v1)|null|
|**2025-01-29**|**Cross-lingual Embedding Clustering for Hierarchical Softmax in Low-Resource Multilingual Speech Recognition**|Zhengdong Yang et.al.|[2501.17615v1](http://arxiv.org/abs/2501.17615v1)|null|
|**2025-01-29**|**VoicePrompter: Robust Zero-Shot Voice Conversion with Voice Prompt and Conditional Flow Matching**|Ha-Yeong Choi et.al.|[2501.17612v1](http://arxiv.org/abs/2501.17612v1)|null|
|**2025-01-29**|**Semantic Consistency Regularization with Large Language Models for Semi-supervised Sentiment Analysis**|Kunrong Li et.al.|[2501.17598v1](http://arxiv.org/abs/2501.17598v1)|null|
|**2025-01-29**|**GLLM: Self-Corrective G-Code Generation using Large Language Models with User Feedback**|Mohamed Abdelaal et.al.|[2501.17584v1](http://arxiv.org/abs/2501.17584v1)|null|
|**2025-01-29**|**CSEval: Towards Automated, Multi-Dimensional, and Reference-Free Counterspeech Evaluation using Auto-Calibrated LLMs**|Amey Hengle et.al.|[2501.17581v1](http://arxiv.org/abs/2501.17581v1)|null|
|**2025-01-29**|**Music2Latent2: Audio Compression with Summary Embeddings and Autoregressive Decoding**|Marco Pasini et.al.|[2501.17578v1](http://arxiv.org/abs/2501.17578v1)|null|
|**2025-01-29**|**A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks**|Elie Antoine et.al.|[2501.17569v1](http://arxiv.org/abs/2501.17569v1)|null|
|**2025-01-29**|**Exploring the Potential of Wireless-enabled Multi-Chip AI Accelerators**|Emmanuel Irabor et.al.|[2501.17567v1](http://arxiv.org/abs/2501.17567v1)|null|
|**2025-01-29**|**Solving Urban Network Security Games: Learning Platform, Benchmark, and Challenge for AI Research**|Shuxin Zhuang et.al.|[2501.17559v1](http://arxiv.org/abs/2501.17559v1)|null|
|**2025-01-29**|**An Exceptional Dataset For Rare Pancreatic Tumor Segmentation**|Wenqi Li et.al.|[2501.17555v1](http://arxiv.org/abs/2501.17555v1)|null|
|**2025-01-29**|**Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models**|Wooyoung Kim et.al.|[2501.17549v1](http://arxiv.org/abs/2501.17549v1)|null|
|**2025-01-29**|**Is Conversational XAI All You Need? Human-AI Decision Making With a Conversational XAI Assistant**|Gaole He et.al.|[2501.17546v1](http://arxiv.org/abs/2501.17546v1)|[link](https://github.com/delftcrowd/iui2025_convxai)|
|**2025-01-29**|**LLM Assistance for Pediatric Depression**|Mariia Ignashina et.al.|[2501.17510v1](http://arxiv.org/abs/2501.17510v1)|null|
|**2025-01-29**|**Neural Spelling: A Spell-Based BCI System for Language Neural Decoding**|Xiaowei Jiang et.al.|[2501.17489v1](http://arxiv.org/abs/2501.17489v1)|null|
|**2025-01-29**|**DINT Transformer**|Yueyang Cang et.al.|[2501.17486v1](http://arxiv.org/abs/2501.17486v1)|null|
|**2025-01-29**|**DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance**|Seffi Cohen et.al.|[2501.17479v1](http://arxiv.org/abs/2501.17479v1)|[link](https://github.com/nivgold/dfpe)|
|**2025-01-29**|**Large Language Models for Single-Step and Multi-Step Flight Trajectory Prediction**|Kaiwei Luo et.al.|[2501.17459v1](http://arxiv.org/abs/2501.17459v1)|null|
|**2025-01-29**|**Cross-Language Approach for Quranic QA**|Islam Oshallah et.al.|[2501.17449v1](http://arxiv.org/abs/2501.17449v1)|null|
|**2025-01-29**|**Towards Making Flowchart Images Machine Interpretable**|Shreya Shukla et.al.|[2501.17441v1](http://arxiv.org/abs/2501.17441v1)|null|
|**2025-01-29**|**Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation**|Tiansheng Huang et.al.|[2501.17433v1](http://arxiv.org/abs/2501.17433v1)|[link](https://github.com/git-disl/virus)|
|**2025-01-29**|**Algorithmic Segmentation and Behavioral Profiling for Ransomware Detection Using Temporal-Correlation Graphs**|Ignatius Rollere et.al.|[2501.17429v1](http://arxiv.org/abs/2501.17429v1)|null|
|**2025-01-29**|**Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models**|Yuxuan Li et.al.|[2501.17420v1](http://arxiv.org/abs/2501.17420v1)|null|
|**2025-01-29**|**Reqo: A Robust and Explainable Query Optimization Cost Model**|Baoming Chang et.al.|[2501.17414v1](http://arxiv.org/abs/2501.17414v1)|[link](https://github.com/baomingchang/reqo-on-postgresql)|
|**2025-01-29**|**A Genetic Algorithm-Based Approach for Automated Optimization of Kolmogorov-Arnold Networks in Classification Tasks**|Quan Long et.al.|[2501.17411v1](http://arxiv.org/abs/2501.17411v1)|null|
|**2025-01-29**|**General Scene Adaptation for Vision-and-Language Navigation**|Haodong Hong et.al.|[2501.17403v1](http://arxiv.org/abs/2501.17403v1)|[link](https://github.com/honghd16/gsa-vln)|
|**2025-01-29**|**MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs**|Ved Sirdeshmukh et.al.|[2501.17399v1](http://arxiv.org/abs/2501.17399v1)|[link](https://github.com/ekwinox117/multi-challenge)|
|**2025-01-29**|**Leveraging In-Context Learning and Retrieval-Augmented Generation for Automatic Question Generation in Educational Domains**|Subhankar Maity et.al.|[2501.17397v1](http://arxiv.org/abs/2501.17397v1)|null|
|**2025-01-29**|**Learning Free Token Reduction for Multi-Modal LLM**|Zihui Zhao et.al.|[2501.17391v1](http://arxiv.org/abs/2501.17391v1)|null|
|**2025-01-29**|**Context-Aware Semantic Recomposition Mechanism for Large Language Models**|Richard Katrix et.al.|[2501.17386v1](http://arxiv.org/abs/2501.17386v1)|null|
|**2025-01-29**|**A Dual-Agent Adversarial Framework for Robust Generalization in Deep Reinforcement Learning**|Zhengpeng Xie et.al.|[2501.17384v1](http://arxiv.org/abs/2501.17384v1)|null|
|**2025-01-29**|**Forecasting S&P 500 Using LSTM Models**|Prashant Pilla et.al.|[2501.17366v1](http://arxiv.org/abs/2501.17366v1)|null|
|**2025-01-29**|**The M-factor: A Novel Metric for Evaluating Neural Architecture Search in Resource-Constrained Environments**|Srikanth Thudumu et.al.|[2501.17361v1](http://arxiv.org/abs/2501.17361v1)|null|
|**2025-01-29**|**On the Coexistence and Ensembling of Watermarks**|Aleksandar Petrov et.al.|[2501.17356v1](http://arxiv.org/abs/2501.17356v1)|null|
|**2025-01-28**|**Better Slow than Sorry: Introducing Positive Friction for Reliable Dialogue Systems**|Mert Ä°nan et.al.|[2501.17348v1](http://arxiv.org/abs/2501.17348v1)|null|
|**2025-01-28**|**Deep-and-Wide Learning: Enhancing Data-Driven Inference via Synergistic Learning of Inter- and Intra-Data Representations**|Md Tauhidul Islam et.al.|[2501.17347v1](http://arxiv.org/abs/2501.17347v1)|null|
|**2025-01-28**|**Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines**|Chongyu Qu et.al.|[2501.17343v1](http://arxiv.org/abs/2501.17343v1)|null|
|**2025-01-28**|**Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection**|Mingyu Derek Ma et.al.|[2501.17338v1](http://arxiv.org/abs/2501.17338v1)|null|
|**2025-01-28**|**Attribution analysis of legal language as used by LLM**|Richard K. Belew et.al.|[2501.17330v1](http://arxiv.org/abs/2501.17330v1)|null|
|**2025-01-28**|**Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction**|Mingyu Derek Ma et.al.|[2501.17326v1](http://arxiv.org/abs/2501.17326v1)|null|
|**2025-01-28**|**A sketch of an AI control safety case**|Tomek Korbak et.al.|[2501.17315v1](http://arxiv.org/abs/2501.17315v1)|null|
|**2025-01-28**|**Probing LLM World Models: Enhancing Guesstimation with Wisdom of Crowds Decoding**|Yun-Shiuan Chuang et.al.|[2501.17310v1](http://arxiv.org/abs/2501.17310v1)|null|
|**2025-01-28**|**"Ownership, Not Just Happy Talk": Co-Designing a Participatory Large Language Model for Journalism**|Emily Tseng et.al.|[2501.17299v1](http://arxiv.org/abs/2501.17299v1)|null|
|**2025-01-28**|**Multi-Physics Simulations via Coupled Fourier Neural Operator**|Shibo Li et.al.|[2501.17296v1](http://arxiv.org/abs/2501.17296v1)|null|
|**2025-01-28**|**Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization**|Zilu Tang et.al.|[2501.17295v1](http://arxiv.org/abs/2501.17295v1)|null|
|**2025-01-28**|**Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology**|Peilong Wang et.al.|[2501.17286v1](http://arxiv.org/abs/2501.17286v1)|null|
|**2025-01-28**|**From Natural Language to Extensive-Form Game Representations**|Shilong Deng et.al.|[2501.17282v1](http://arxiv.org/abs/2501.17282v1)|[link](https://github.com/zczlsde/gameinterpreter)|
|**2025-01-28**|**Tailored Truths: Optimizing LLM Persuasion with Personalization and Fabricated Statistics**|Jasper Timm et.al.|[2501.17273v1](http://arxiv.org/abs/2501.17273v1)|null|
|**2025-01-28**|**Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service**|Saloni Potdar et.al.|[2501.17270v1](http://arxiv.org/abs/2501.17270v1)|null|
|**2025-01-28**|**Giving the Old a Fresh Spin: Quality Estimation-Assisted Constrained Decoding for Automatic Post-Editing**|Sourabh Deoghare et.al.|[2501.17265v1](http://arxiv.org/abs/2501.17265v1)|null|
|**2025-01-28**|**SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training**|Tianzhe Chu et.al.|[2501.17161v1](http://arxiv.org/abs/2501.17161v1)|null|
|**2025-01-28**|**A Hybrid Deep Learning CNN Model for Enhanced COVID-19 Detection from Computed Tomography (CT) Scan Images**|Suresh Babu Nettur et.al.|[2501.17160v1](http://arxiv.org/abs/2501.17160v1)|null|
|**2025-01-28**|**Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile Compensation Using Deep Energy Model**|Reza Ghorbani et.al.|[2501.17152v1](http://arxiv.org/abs/2501.17152v1)|null|
|**2025-01-28**|**AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders**|Zhengxuan Wu et.al.|[2501.17148v2](http://arxiv.org/abs/2501.17148v2)|null|
|**2025-01-28**|**FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data**|Deren Lei et.al.|[2501.17144v1](http://arxiv.org/abs/2501.17144v1)|[link](https://github.com/derenlei/factcg)|
|**2025-01-28**|**ASTRAL: Automated Safety Testing of Large Language Models**|Miriam Ugarte et.al.|[2501.17132v1](http://arxiv.org/abs/2501.17132v1)|null|
|**2025-01-28**|**Histoires Morales: A French Dataset for Assessing Moral Alignment**|Thibaud Leteno et.al.|[2501.17117v1](http://arxiv.org/abs/2501.17117v1)|[link](https://github.com/upunaprosk/histoires-morales)|
|**2025-01-28**|**Optimizing Large Language Model Training Using FP4 Quantization**|Ruizhe Wang et.al.|[2501.17116v1](http://arxiv.org/abs/2501.17116v1)|null|
|**2025-01-28**|**COS(M+O)S: Curiosity and RL-Enhanced MCTS for Exploring Story Space via Language Models**|Tobias Materzok et.al.|[2501.17104v1](http://arxiv.org/abs/2501.17104v1)|null|
|**2025-01-28**|**Why is the estimation of metaorder impact with public market data so challenging?**|Manuel Naviglio et.al.|[2501.17096v1](http://arxiv.org/abs/2501.17096v1)|null|
|**2025-01-28**|**Mamba-Shedder: Post-Transformer Compression for Efficient Selective Structured State Space Models**|J. Pablo MuÃ±oz et.al.|[2501.17088v1](http://arxiv.org/abs/2501.17088v1)|[link](https://github.com/intellabs/hardware-aware-automated-machine-learning)|
|**2025-01-28**|**Learning Mean Field Control on Sparse Graphs**|Christian Fabian et.al.|[2501.17079v1](http://arxiv.org/abs/2501.17079v1)|null|
|**2025-01-28**|**EdgeMLOps: Operationalizing ML models with Cumulocity IoT and thin-edge.io for Visual quality Inspection**|Kanishk Chaturvedi et.al.|[2501.17062v1](http://arxiv.org/abs/2501.17062v1)|null|
|**2025-01-28**|**How Linguistics Learned to Stop Worrying and Love the Language Models**|Richard Futrell et.al.|[2501.17047v1](http://arxiv.org/abs/2501.17047v1)|null|
|**2025-01-28**|**Synthesizing 3D Abstractions by Inverting Procedural Buildings with Transformers**|Maximilian Dax et.al.|[2501.17044v2](http://arxiv.org/abs/2501.17044v2)|null|
|**2025-01-28**|**Benchmarking Quantum Convolutional Neural Networks for Signal Classification in Simulated Gamma-Ray Burst Detection**|Farida Farsian et.al.|[2501.17041v1](http://arxiv.org/abs/2501.17041v1)|null|
|**2025-01-28**|**Challenges in Ensuring AI Safety in DeepSeek-R1 Models: The Shortcomings of Reinforcement Learning Strategies**|Manojkumar Parmar et.al.|[2501.17030v1](http://arxiv.org/abs/2501.17030v1)|null|
|**2025-01-28**|**Revisit Mixture Models for Multi-Agent Simulation: Experimental Study within a Unified Framework**|Longzhong Lin et.al.|[2501.17015v1](http://arxiv.org/abs/2501.17015v1)|null|
|**2025-01-28**|**Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver**|Shunya Minami et.al.|[2501.16986v1](http://arxiv.org/abs/2501.16986v1)|null|
|**2025-01-28**|**Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling**|Hongzhi Huang et.al.|[2501.16975v1](http://arxiv.org/abs/2501.16975v1)|null|

#### Abstracts
##### **Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations**
2501.17860v1 by Zijie Liu, Xinyu Zhao, Jie Peng, Zhuangdi Zhu, Qingyu Chen, Xia Hu, Tianlong Chen

Current medical AI systems often fail to replicate real-world clinical
reasoning, as they are predominantly trained and evaluated on static text and
question-answer tasks. These tuning methods and benchmarks overlook critical
aspects like evidence-based reasoning and handling distracting information. To
bridge this gap, we introduce a novel benchmark that simulates real-world
diagnostic scenarios, integrating noise and difficulty levels aligned with
USMLE standards. Moreover, we explore dialogue-based fine-tuning, which
transforms static datasets into conversational formats to better capture
iterative reasoning processes. Experiments show that dialogue-tuned models
outperform traditional methods, with improvements of $9.64\%$ in multi-round
reasoning scenarios and $6.18\%$ in accuracy in a noisy environment. Our
findings highlight dialogue tuning as a promising approach for advancing
clinically aligned and robust medical AI systems.

æè¦ï¼ç®åçé«ç AI ç³»çµ±å¸¸ç¡æ³è¤è£½çå¯¦ä¸ççè¨åºæ¨çï¼å çºå®åä¸»è¦å¨éææå­ååç­ä»»åä¸åè¨åè©ä¼°ãéäºèª¿æ´æ¹æ³ååºæºå¿½ç¥äºåºæ¼è­æçæ¨çåèçåæ£è³è¨ç­ééµé¢åãçºäºå½è£éåå·®è·ï¼æåæåºä¸åæ¨¡æ¬çå¯¦ä¸çè¨ºæ·æå¢çå¨æ°åºæºï¼æ´åè USMLE æ¨æºä¸è´çéè¨åé£åº¦ç­ç´ãæ­¤å¤ï¼æåæ¢ç´¢ä»¥å°è©±çºåºç¤çå¾®èª¿ï¼å°éæè³æéè½æçºå°è©±æ ¼å¼ï¼ä»¥æ´å¥½å°ææåè¦çæ¨çéç¨ãå¯¦é©é¡¯ç¤ºï¼å°è©±å¾®èª¿æ¨¡ååªæ¼å³çµ±æ¹æ³ï¼å¨å¤è¼ªæ¨çæå¢ä¸­æåäº 9.64%ï¼å¨æéè¨çç°å¢ä¸­æåäº 6.18% çæºç¢ºåº¦ãæåçç¼ç¾å¼·èª¿å°è©±å¾®èª¿æ¯ä¸ç¨®æææ¨é²èè¨åºç¸ç¬¦ä¸å¼·å¥çé«ç AI ç³»çµ±çæ¹æ³ã

##### **Improving Your Model Ranking on Chatbot Arena by Vote Rigging**
2501.17858v1 by Rui Min, Tianyu Pang, Chao Du, Qian Liu, Minhao Cheng, Min Lin

Chatbot Arena is a popular platform for evaluating LLMs by pairwise battles,
where users vote for their preferred response from two randomly sampled
anonymous models. While Chatbot Arena is widely regarded as a reliable LLM
ranking leaderboard, we show that crowdsourced voting can be rigged to improve
(or decrease) the ranking of a target model $m_{t}$. We first introduce a
straightforward target-only rigging strategy that focuses on new battles
involving $m_{t}$, identifying it via watermarking or a binary classifier, and
exclusively voting for $m_{t}$ wins. However, this strategy is practically
inefficient because there are over $190$ models on Chatbot Arena and on average
only about $1\%$ of new battles will involve $m_{t}$. To overcome this, we
propose omnipresent rigging strategies, exploiting the Elo rating mechanism of
Chatbot Arena that any new vote on a battle can influence the ranking of the
target model $m_{t}$, even if $m_{t}$ is not directly involved in the battle.
We conduct experiments on around $1.7$ million historical votes from the
Chatbot Arena Notebook, showing that omnipresent rigging strategies can improve
model rankings by rigging only hundreds of new votes. While we have evaluated
several defense mechanisms, our findings highlight the importance of continued
efforts to prevent vote rigging. Our code is available at
https://github.com/sail-sg/Rigging-ChatbotArena.

æè¦ï¼èå¤©æ©å¨äººç«¶æå ´æ¯ä¸åééæå°æ°é¬¥ä¾è©ä¼°å¤§åèªè¨æ¨¡åçç±éå¹³å°ï¼ä½¿ç¨èå¯ä»¥å¾å©åé¨æ©æ½æ¨£çå¿åæ¨¡åä¸­æç¥¨çµ¦ä»ååå¥½çåæãåç®¡èå¤©æ©å¨äººç«¶æå ´å»£æ³è¢«è¦çºå¯é çå¤§åèªè¨æ¨¡åæåæè¡æ¦ï¼ä½æåè¡¨æç¾¤ç¾å¤åæç¥¨å¯ä»¥è¢«æç¸±ä»¥æåï¼æéä½ï¼ç®æ¨æ¨¡å $m_{t}$ çæåãæåé¦åä»ç´¹äºä¸åç´æ¥çåç®æ¨æç¸±ç­ç¥ï¼è©²ç­ç¥å°æ³¨æ¼æ¶å $m_{t}$ çæ°æ°é¬¥ï¼ééæµ®æ°´å°æäºååé¡å¨è­å¥å®ï¼ä¸¦å°éæç¥¨çµ¦ $m_{t}$ ç²åãç¶èï¼éåç­ç¥å¨å¯¦åä¸æçä¸å½°ï¼å çºèå¤©æ©å¨äººç«¶æå ´ä¸æè¶é 190 åæ¨¡åï¼èä¸å¹³åèè¨åªæç´ 1% çæ°æ°é¬¥ææ¶å $m_{t}$ãçºäºåæéååé¡ï¼æåæåºäºç¡æä¸å¨çæç¸±ç­ç¥ï¼å©ç¨èå¤©æ©å¨äººç«¶æå ´ç Elo è©åæ©å¶ï¼ä»»ä½å°æ°é¬¥çæ°æç¥¨é½å¯ä»¥å½±é¿ç®æ¨æ¨¡å $m_{t}$ çæåï¼å³ä½¿ $m_{t}$ æ²æç´æ¥åèæ°é¬¥ãæåå°èå¤©æ©å¨äººç«¶æå ´ç­è¨æ¬ä¸­ç´ 170 è¬å¼µæ­·å²æç¥¨é²è¡äºå¯¦é©ï¼çµæé¡¯ç¤ºç¡æä¸å¨çæç¸±ç­ç¥åééæç¸±æ¸ç¾å¼µæ°æç¥¨å°±è½æåæ¨¡åæåãåç®¡æåå·²ç¶è©ä¼°äºå¹¾ç¨®é²ç¦¦æ©å¶ï¼ä½æåçç¼ç¾çªé¡¯äºæçºåªåé²æ­¢æç¥¨æç¸±çéè¦æ§ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/sail-sg/Rigging-ChatbotArena åå¾ã

##### **GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings**
2501.17855v1 by Ziang Liu, Yuanchen Ju, Yu Da, Tom Silver, Pranav N. Thakkar, Jenna Li, Justin Guo, Katherine Dimitropoulou, Tapomayukh Bhattacharjee

Robot caregiving should be personalized to meet the diverse needs of care
recipients -- assisting with tasks as needed, while taking user agency in
action into account. In physical tasks such as handover, bathing, dressing, and
rehabilitation, a key aspect of this diversity is the functional range of
motion (fROM), which can vary significantly between individuals. In this work,
we learn to predict personalized fROM as a way to generalize robot
decision-making in a wide range of caregiving tasks. We propose a novel
data-driven method for predicting personalized fROM using functional assessment
scores from occupational therapy. We develop a neural model that learns to
embed functional assessment scores into a latent representation of the user's
physical function. The model is trained using motion capture data collected
from users with emulated mobility limitations. After training, the model
predicts personalized fROM for new users without motion capture. Through
simulated experiments and a real-robot user study, we show that the
personalized fROM predictions from our model enable the robot to provide
personalized and effective assistance while improving the user's agency in
action. See our website for more visualizations:
https://emprise.cs.cornell.edu/grace/.

æè¦ï¼æ©å¨äººç§è­·ææ ¹æç§è­·å°è±¡çä¸åéæ±é²è¡å®¢è£½åï¼å¨éè¦æåå©å·è¡ä»»åï¼åæèéä½¿ç¨èçèªä¸»è¡åãå¨ç§»äº¤ãæ²æµ´ãç©¿è¡£åå¾©å¥ç­èº«é«ä»»åä¸­ï¼éç¨®å¤æ¨£æ§çééµé¢åæ¯åè½æ§åä½ç¯å (fROM)ï¼èéå¨ä¸ååé«ä¹éå¯è½å·®ç°å¾å¤§ãå¨éé å·¥ä½ä¸­ï¼æåå­¸ç¿é æ¸¬å®¢è£½å fROMï¼ä½çºå¨å»£æ³ç§è­·ä»»åä¸­æ¦åæ©å¨äººæ±ºç­å¶å®çä¸ç¨®æ¹å¼ãæåæåºäºä¸ç¨®ä½¿ç¨è·è½æ²»çåè½è©ä¼°åæ¸ä¾é æ¸¬å®¢è£½å fROM çæ°ç©è³æé©åæ¹æ³ãæåéç¼äºä¸åç¥ç¶æ¨¡åï¼å­¸ç¿å°åè½è©ä¼°åæ¸åµå¥å°ä½¿ç¨èçèº«é«åè½æ½å¨è¡¨å¾µä¸­ãè©²æ¨¡åä½¿ç¨å¾å·ææ¨¡æ¬è¡åéå¶çä½¿ç¨èæ¶éçåä½æ·åè³æé²è¡è¨ç·´ãè¨ç·´å¾ï¼è©²æ¨¡åæçºæ²æåä½æ·åçæ°ä½¿ç¨èé æ¸¬å®¢è£½å fROMãééæ¨¡æ¬å¯¦é©åçå¯¦æ©å¨äººä½¿ç¨èç ç©¶ï¼æåå±ç¤ºäºæåæ¨¡åçå®¢è£½å fROM é æ¸¬ä½¿æ©å¨äººè½å¤ æä¾å®¢è£½åä¸ææçåå©ï¼åææé«ä½¿ç¨èçèªä¸»è¡åãè«åé±æåçç¶²ç«ä»¥åå¾æ´å¤è¦è¦ºåè³æï¼https://emprise.cs.cornell.edu/grace/ã

##### **From Sparse to Dense: Toddler-inspired Reward Transition in Goal-Oriented Reinforcement Learning**
2501.17842v1 by Junseok Park, Hyeonseo Yang, Min Whoo Lee, Won-Seok Choi, Minsu Lee, Byoung-Tak Zhang

Reinforcement learning (RL) agents often face challenges in balancing
exploration and exploitation, particularly in environments where sparse or
dense rewards bias learning. Biological systems, such as human toddlers,
naturally navigate this balance by transitioning from free exploration with
sparse rewards to goal-directed behavior guided by increasingly dense rewards.
Inspired by this natural progression, we investigate the Toddler-Inspired
Reward Transition in goal-oriented RL tasks. Our study focuses on transitioning
from sparse to potential-based dense (S2D) rewards while preserving optimal
strategies. Through experiments on dynamic robotic arm manipulation and
egocentric 3D navigation tasks, we demonstrate that effective S2D reward
transitions significantly enhance learning performance and sample efficiency.
Additionally, using a Cross-Density Visualizer, we show that S2D transitions
smooth the policy loss landscape, resulting in wider minima that improve
generalization in RL models. In addition, we reinterpret Tolman's maze
experiments, underscoring the critical role of early free exploratory learning
in the context of S2D rewards.

æè¦ï¼å¼·åå­¸ç¿ (RL) ä»£çäººç¶å¸¸å¨å¹³è¡¡æ¢ç´¢åå©ç¨æé¢è¨ææ°ï¼ç¹å¥æ¯å¨ç¨çæå¯éçåµæå½±é¿å­¸ç¿çç°å¢ä¸­ãçç©ç³»çµ±ï¼ä¾å¦äººé¡å¹¼åï¼ééå¾å·æç¨ççåµçèªç±æ¢ç´¢éæ¸¡å°ç±è¶ä¾è¶å¯éççåµå¼å°çç®æ¨å°åè¡çºï¼èªç¶èç¶å°æå°éç¨®å¹³è¡¡ãåéç¨®èªç¶é²ç¨çåç¼ï¼æåç ç©¶äºç®æ¨å°å RL ä»»åä¸­çå¹¼ååç¼å¼çåµè½æãæåçç ç©¶éé»å¨æ¼å¾ç¨çè½æå°åºæ¼æ½åçå¯é (S2D) çåµï¼åæä¿çæä½³ç­ç¥ãééå°åææ©å¨æèæä½åèªæä¸­å¿ 3D å°èªä»»åçå¯¦é©ï¼æåè­æäºææç S2D çåµè½æé¡¯èæé«äºå­¸ç¿æ§è½åæ¨£æ¬æçãæ­¤å¤ï¼ä½¿ç¨äº¤åå¯åº¦å¯è¦åå·¥å·ï¼æåå±ç¤ºäº S2D è½æå¯ä»¥å¹³æ»ç­ç¥æå¤±ææ³ï¼å¾èç¢çæ´å»£æ³çæå°å¼ï¼å¾èæ¹å RL æ¨¡åä¸­çæ³åãæ­¤å¤ï¼æåéæ°è©®éäºæç¾æ¼è¿·å®®å¯¦é©ï¼å¼·èª¿äºå¨ S2D çåµçèæ¯ä¸æ©æèªç±æ¢ç´¢å­¸ç¿çééµä½ç¨ã

##### **Learning Beyond the Surface: How Far Can Continual Pre-Training with LoRA Enhance LLMs' Domain-Specific Insight Learning?**
2501.17840v1 by Pouya Pezeshkpour, Estevam Hruschka

Large Language Models (LLMs) have demonstrated remarkable performance on
various tasks, yet their ability to extract and internalize deeper insights
from domain-specific datasets remains underexplored. In this study, we
investigate how continual pre-training can enhance LLMs' capacity for insight
learning across three distinct forms: declarative, statistical, and
probabilistic insights. Focusing on two critical domains: medicine and finance,
we employ LoRA to train LLMs on two existing datasets. To evaluate each insight
type, we create benchmarks to measure how well continual pre-training helps
models go beyond surface-level knowledge. We also assess the impact of document
modification on capturing insights. The results show that, while continual
pre-training on original documents has a marginal effect, modifying documents
to retain only essential information significantly enhances the
insight-learning capabilities of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ä»»åä¸­å±ç¾åºéå¡çè¡¨ç¾ï¼ä½å®åå¾ç¹å®é åçè³æéä¸­èååå§åæ´æ·±å¥è¦è§£çè½åä»æªè¢«ååæ¢è¨ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨æçºé è¨ç·´å¦ä½å¢å¼· LLM å¨ä¸ç¨®ä¸åå½¢å¼çè¦è§£å­¸ç¿è½åï¼å®£åå¼ãçµ±è¨å¼åæ©çå¼è¦è§£ãæåå°æ³¨æ¼å©åéè¦çé åï¼é«å­¸åéèï¼ä¸¦ä½¿ç¨ LoRA å¨å©åç¾æè³æéä¸è¨ç·´ LLMãçºäºè©ä¼°æ¯ç¨®é¡åçè¦è§£ï¼æåå»ºç«åºæºä¾è¡¡éæçºé è¨ç·´å¦ä½å¹«å©æ¨¡åè¶è¶è¡¨é¢å±¤é¢çç¥è­ãæåä¹è©ä¼°æä»¶ä¿®æ¹å°æ·åè¦è§£çå½±é¿ãçµæé¡¯ç¤ºï¼éç¶å¨åå§æä»¶ä¸é²è¡æçºé è¨ç·´çæææéï¼ä½ä¿®æ¹æä»¶ä»¥åä¿çå¿è¦è³è¨ï¼å¯ä»¥é¡¯èå¢å¼· LLM çè¦è§£å­¸ç¿è½åã

##### **A Comprehensive Survey on Legal Summarization: Challenges and Future Directions**
2501.17830v1 by Mousumi Akter, Erion Cano, Erik Weber, Dennis Dobler, Ivan Habernal

This article provides a systematic up-to-date survey of automatic
summarization techniques, datasets, models, and evaluation methods in the legal
domain. Through specific source selection criteria, we thoroughly review over
120 papers spanning the modern `transformer' era of natural language processing
(NLP), thus filling a gap in existing systematic surveys on the matter. We
present existing research along several axes and discuss trends, challenges,
and opportunities for future research.

æè¦ï¼æ¬ææä¾äºä¸ä»½æ³å¾é åä¸­èªåæè¦æè¡ãè³æéãæ¨¡ååè©ä¼°æ¹æ³çç³»çµ±æ§ææ°èª¿æ¥ãééå·é«çä¾æºé¸ææ¨æºï¼æåå¾¹åºæª¢è¦äºæ¶µèèªç¶èªè¨èç (NLP) ç¾ä»£ãTransformerãæä»£ç 120 ç¯è«æï¼å¾èå¡«è£äºç¾æç³»çµ±æ§èª¿æ¥çç©ºç½ãæåæ²¿èå¹¾åè»¸ç·åç¾ç¾æç ç©¶ï¼ä¸¦è¨è«æªä¾ç ç©¶çè¶¨å¢ãææ°åæ©æã

##### **U2A: Unified Unimodal Adaptation for Robust and Efficient Multimodal Learning**
2501.17823v1 by Md Kaykobad Reza, Niki Nezakati, Ameya Patil, Mashhour Solh, M. Salman Asif

Multimodal learning often relies on designing new models and complex training
strategies to achieve optimal performance. We present Unified Unimodal
Adaptation (U2A), which jointly fine-tunes pretrained unimodal encoders using
low-rank adaptation (LoRA) for various multimodal tasks. Our method
significantly reduces the number of learnable parameters and eliminates the
need for complex training strategies, such as alternating training, gradient
modifications, or unimodal fine-tuning. To address missing modalities during
both training and testing, we introduce Mask Tokens (MT), which generate
missing modality features from available modalities using a single token per
modality. This simplifies the process, removing the need for specialized
feature estimation or prompt-tuning methods. Our evaluation demonstrates that
U2A matches or outperforms state-of-the-art methods in both complete and
missing modality settings, showcasing strong performance and robustness across
various modalities, tasks, and datasets. We also analyze and report the
effectiveness of Mask Tokens in different missing modality scenarios. Overall,
our method provides a robust, flexible, and efficient solution for multimodal
learning, with minimal computational overhead.

æè¦ï¼å¤æ¨¡æå­¦ä¹ éå¸¸ä¾èµäºè®¾è®¡æ°æ¨¡ååå¤æçè®­ç»ç­ç¥ä»¥å®ç°æä½³æ§è½ãæä»¬æåºäºç»ä¸åæ¨¡æèªéåº (U2A)ï¼å®ä½¿ç¨ä½ç§©èªéåº (LoRA) èåå¾®è°é¢è®­ç»çåæ¨¡æç¼ç å¨ï¼ä»¥ç¨äºåç§å¤æ¨¡æä»»å¡ãæä»¬çæ¹æ³æ¾èåå°äºå¯å­¦ä¹ åæ°çæ°éï¼å¹¶ä¸æ¶é¤äºå¯¹å¤æè®­ç»ç­ç¥çéæ±ï¼ä¾å¦äº¤æ¿è®­ç»ãæ¢¯åº¦ä¿®æ¹æåæ¨¡æå¾®è°ãä¸ºäºè§£å³è®­ç»åæµè¯æé´ç¼ºå°çæ¨¡æï¼æä»¬å¼å¥äºæ©ç æ è®° (MT)ï¼å®ä½¿ç¨æ¯ä¸ªæ¨¡æçåä¸ªæ è®°ä»å¯ç¨æ¨¡æçæç¼ºå¤±çæ¨¡æç¹å¾ãè¿ç®åäºæµç¨ï¼æ¶é¤äºå¯¹ä¸é¨çç¹å¾ä¼°è®¡ææç¤ºè°æ´æ¹æ³çéæ±ãæä»¬çè¯ä¼°è¡¨æï¼U2A å¨å®æ´åç¼ºå¤±æ¨¡æè®¾ç½®ä¸­åå¹éæä¼äºæåè¿çæ¹æ³ï¼å±ç¤ºäºè·¨åç§æ¨¡æãä»»å¡åæ°æ®éçå¼ºå¤§æ§è½åé²æ£æ§ãæä»¬è¿åæå¹¶æ¥åäºæ©ç æ è®°å¨ä¸åç¼ºå¤±æ¨¡æåºæ¯ä¸­çæææ§ãæ»ä½èè¨ï¼æä»¬çæ¹æ³ä¸ºå¤æ¨¡æå­¦ä¹ æä¾äºä¸ç§å¥å£®ãçµæ´»ä¸é«æçè§£å³æ¹æ¡ï¼è®¡ç®å¼éæå°ã

##### **Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology**
2501.17822v1 by Sobhan Hemati, Ghazal Alabtah, Saghir Alfasly, H. R. Tizhoosh

A crucial step to efficiently integrate Whole Slide Images (WSIs) in
computational pathology is assigning a single high-quality feature vector,
i.e., one embedding, to each WSI. With the existence of many pre-trained deep
neural networks and the emergence of foundation models, extracting embeddings
for sub-images (i.e., tiles or patches) is straightforward. However, for WSIs,
given their high resolution and gigapixel nature, inputting them into existing
GPUs as a single image is not feasible. As a result, WSIs are usually split
into many patches. Feeding each patch to a pre-trained model, each WSI can then
be represented by a set of patches, hence, a set of embeddings. Hence, in such
a setup, WSI representation learning reduces to set representation learning
where for each WSI we have access to a set of patch embeddings. To obtain a
single embedding from a set of patch embeddings for each WSI, multiple
set-based learning schemes have been proposed in the literature. In this paper,
we evaluate the WSI search performance of multiple recently developed
aggregation techniques (mainly set representation learning techniques)
including simple average or max pooling operations, Deep Sets, Memory networks,
Focal attention, Gaussian Mixture Model (GMM) Fisher Vector, and deep sparse
and binary Fisher Vector on four different primary sites including bladder,
breast, kidney, and Colon from TCGA. Further, we benchmark the search
performance of these methods against the median of minimum distances of patch
embeddings, a non-aggregating approach used for WSI retrieval.

æè¦ï¼å¨è¨ç®ççå­¸ä¸­æææ´åå¨å¹»ççå½±å (WSI) çééµæ­¥é©æ¯çºæ¯å WSI æå®ä¸åå®ä¸çé«åè³ªç¹å¾µåéï¼å³ä¸ååµå¥ãç±æ¼è¨±å¤é åè¨ç·´å¥½çæ·±åº¦ç¥ç¶ç¶²è·¯çå­å¨ååºç¤æ¨¡åçåºç¾ï¼æåå­å½±åï¼å³ç£ç£æè²¼çï¼çåµå¥éå¸¸ç°¡å®ãç¶èï¼å°æ¼ WSIï¼ç±æ¼å®åçé«è§£æåº¦åååç´ ç¹æ§ï¼å°å®åä½çºå®ä¸å½±åè¼¸å¥ç¾æç GPU æ¯ä¸å¯è¡çãå æ­¤ï¼WSI éå¸¸æè¢«åå²æè¨±å¤è²¼çãå°æ¯åè²¼çè¼¸å¥é åè¨ç·´å¥½çæ¨¡åå¾ï¼æ¯å WSI å°±å¯ä»¥ç¨ä¸çµè²¼çä¾è¡¨ç¤ºï¼å æ­¤ï¼ä¹å°±æ¯ä¸çµåµå¥ãå æ­¤ï¼å¨éæ¨£çè¨­å®ä¸­ï¼WSI è¡¨ç¤ºå­¸ç¿æç°¡åçºéåè¡¨ç¤ºå­¸ç¿ï¼å¶ä¸­å°æ¼æ¯å WSIï¼æåå¯ä»¥å­åä¸çµè²¼çåµå¥ãçºäºå¾æ¯å WSI çä¸çµè²¼çåµå¥ä¸­åå¾å®ä¸åµå¥ï¼æç»ä¸­å·²ç¶æåºäºå¤ç¨®åºæ¼éåçå­¸ç¿æ¹æ¡ãå¨æ¬æä¸­ï¼æåè©ä¼°äºå¤ç¨®æè¿éç¼çèåæè¡ï¼ä¸»è¦æ¯éåè¡¨ç¤ºå­¸ç¿æè¡ï¼ç WSI æå°æè½ï¼åæ¬ç°¡å®çå¹³åææå¤§æ± åéç®ãæ·±åº¦éåãè¨æ¶ç¶²è·¯ãç¦é»æ³¨æåãé«æ¯æ··åæ¨¡å (GMM) Fisher åéåæ·±åº¦ç¨çåäºé²ä½ Fisher åéï¼å¨ TCGA çååä¸åçä¸»è¦é¨ä½ï¼åæ¬èè±ãä¹³æ¿ãèèåçµè¸ãæ­¤å¤ï¼æåå°éäºæ¹æ³çæå°æè½èè²¼çåµå¥çæå°è·é¢ä¸­ä½æ¸é²è¡åºæºæ¯è¼ï¼éæ¯ä¸ç¨®ç¨æ¼ WSI æ·åçéèåæ¹æ³ã

##### **P-TAME: Explain Any Image Classifier with Trained Perturbations**
2501.17813v1 by Mariano V. Ntrougkas, Vasileios Mezaris, Ioannis Patras

The adoption of Deep Neural Networks (DNNs) in critical fields where
predictions need to be accompanied by justifications is hindered by their
inherent black-box nature. In this paper, we introduce P-TAME
(Perturbation-based Trainable Attention Mechanism for Explanations), a
model-agnostic method for explaining DNN-based image classifiers. P-TAME
employs an auxiliary image classifier to extract features from the input image,
bypassing the need to tailor the explanation method to the internal
architecture of the backbone classifier being explained. Unlike traditional
perturbation-based methods, which have high computational requirements, P-TAME
offers an efficient alternative by generating high-resolution explanations in a
single forward pass during inference. We apply P-TAME to explain the decisions
of VGG-16, ResNet-50, and ViT-B-16, three distinct and widely used image
classifiers. Quantitative and qualitative results show that our method matches
or outperforms previous explainability methods, including model-specific
approaches. Code and trained models will be released upon acceptance.

æè¦ï¼æ·±åº¦ç¥ç»ç¶²è·¯ (DNN) å¨éè¦å°é æ¸¬é²è¡ä½è­çéè¦é åä¸­è¢«æ¡ç¨åå°å¶åºæçé»ç®±æ§è³ªæé»ç¤ãå¨æ¬æä¸­ï¼æåä»ç´¹äº P-TAMEï¼åºæ¼æ¾åçå¯è¨ç·´æ³¨æåæ©å¶ç¨æ¼è§£éï¼ï¼ä¸ç¨®èæ¨¡åç¡éçæ¹æ³ï¼ç¨æ¼è§£éåºæ¼ DNN çå½±ååé¡å¨ãP-TAME æ¡ç¨è¼å©å½±ååé¡å¨å¾è¼¸å¥å½±åä¸­æåç¹å¾µï¼ç¹ééè¦æ ¹æè¦è§£éçä¸»å¹¹åé¡å¨çå§é¨æ¶æ§èª¿æ´è§£éæ¹æ³ãèå·æé«è¨ç®éæ±çå³çµ±åºæ¼æ¾åçæ¹æ³ä¸åï¼P-TAME å¨æ¨è«éç¨ä¸­ééå®æ¬¡ååå³éç¢çé«è§£æåº¦è§£éï¼æä¾äºä¸ç¨®é«æçæ¿ä»£æ¹æ¡ãæåå° P-TAME ç¨æ¼è§£é VGG-16ãResNet-50 å ViT-B-16 çæ±ºç­ï¼éä¸ç¨®æ¯ä¸åçä¸å»£æ³ä½¿ç¨çå½±ååé¡å¨ãå®éåå®æ§çµæé¡¯ç¤ºï¼æåçæ¨¡åæ¯ä¹åçå¯è§£éæ§æ¹æ³ï¼åæ¬ç¹å®æ¼æ¨¡åçæ¹æ³ï¼å¹éæè¡¨ç¾å¾æ´å¥½ãç¨å¼ç¢¼åè¨ç·´æ¨¡åå°å¨æ¥åå¾ç¼å¸ã

##### **Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling**
2501.17811v1 by Xiaokang Chen, Zhiyu Wu, Xingchao Liu, Zizheng Pan, Wen Liu, Zhenda Xie, Xingkai Yu, Chong Ruan

In this work, we introduce Janus-Pro, an advanced version of the previous
work Janus. Specifically, Janus-Pro incorporates (1) an optimized training
strategy, (2) expanded training data, and (3) scaling to larger model size.
With these improvements, Janus-Pro achieves significant advancements in both
multimodal understanding and text-to-image instruction-following capabilities,
while also enhancing the stability of text-to-image generation. We hope this
work will inspire further exploration in the field. Code and models are
publicly available.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº Janus-Proï¼éæ¯ååå·¥ä½ Janus çé²éçæ¬ãå·é«ä¾èªªï¼Janus-Pro çµåäº (1) æä½³åçè¨ç·´ç­ç¥ã(2) æ´åçè¨ç·´è³æï¼ä»¥å (3) æ´åå°æ´å¤§çæ¨¡åè¦æ¨¡ãéééäºæ¹é²ï¼Janus-Pro å¨å¤æ¨¡æçè§£åæå­è½å½±åæä»¤éµå¾ªè½åæ¹é¢é½åå¾äºé¡¯èçé²æ­¥ï¼åæä¹å¢å¼·äºæå­è½å½±åçæçç©©å®æ§ãæåå¸æéé å·¥ä½è½æ¿åµå¨è©²é åé²ä¸æ­¥æ¢ç´¢ãç¨å¼ç¢¼åæ¨¡åå·²å¬éæä¾ã

##### **BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights**
2501.17790v1 by Chan-Jan Hsu, Yi-Cheng Lin, Chia-Chun Lin, Wei-Chih Chen, Ho Lam Chung, Chen-An Li, Yi-Chang Chen, Chien-Yu Yu, Ming-Ji Lee, Chien-Cheng Chen, Ru-Heng Huang, Hung-yi Lee, Da-Shan Shiu

We present BreezyVoice, a Text-to-Speech (TTS) system specifically adapted
for Taiwanese Mandarin, highlighting phonetic control abilities to address the
unique challenges of polyphone disambiguation in the language. Building upon
CosyVoice, we incorporate a $S^{3}$ tokenizer, a large language model (LLM), an
optimal-transport conditional flow matching model (OT-CFM), and a grapheme to
phoneme prediction model, to generate realistic speech that closely mimics
human utterances. Our evaluation demonstrates BreezyVoice's superior
performance in both general and code-switching contexts, highlighting its
robustness and effectiveness in generating high-fidelity speech. Additionally,
we address the challenges of generalizability in modeling long-tail speakers
and polyphone disambiguation. Our approach significantly enhances performance
and offers valuable insights into the workings of neural codec TTS systems.

æè¦ï¼æåæåº BreezyVoiceï¼ä¸åå°ééå°å°ç£åèªçæå­è½èªé³ (TTS) ç³»çµ±ï¼å¼·èª¿èªé³æ§å¶è½åä»¥è§£æ±ºèªè¨ä¸­å¤é³å­æ¶é¤æ­§ç¾©çç¨ç¹ææ°ãå¨ CosyVoice çåºç¤ä¸ï¼æåæ´åäºä¸å $S^{3}$ åè©å¨ãä¸åå¤§åèªè¨æ¨¡å (LLM)ãä¸åæä½³å³è¼¸æ¢ä»¶æµå¹éæ¨¡å (OT-CFM) åä¸åé³ç´ é æ¸¬æ¨¡åï¼ä»¥ç¢çé¼çä¸èäººé¡ç¼é³éå¸¸æ¥è¿çèªé³ãæåçè©ä¼°è­æäº BreezyVoice å¨ä¸è¬åèªç¢¼è½ææå¢ä¸­çæåè¶çè¡¨ç¾ï¼çªé¡¯äºå®å¨ç¢çé«ä¿çèªé³æ¹é¢çç©©å¥æ§åæææ§ãæ­¤å¤ï¼æåè§£æ±ºäºå¨å»ºæ¨¡é·å°¾èªªè©±èåå¤é³å­æ¶é¤æ­§ç¾©ä¸­å¯æ¦åæ§çææ°ãæåçåæ³å¤§å¹æåäºæè½ï¼ä¸¦æä¾äºå°ç¥ç¶ç·¨è§£ç¢¼å¨ TTS ç³»çµ±éä½æ¹å¼çå¯¶è²´è¦è§£ã

##### **Reasoning Over the Glyphs: Evaluation of LLM's Decipherment of Rare Scripts**
2501.17785v1 by Yu-Fei Shih, Zheng-Lin Lin, Shu-Kai Hsieh

We explore the capabilities of LVLMs and LLMs in deciphering rare scripts not
encoded in Unicode. We introduce a novel approach to construct a multimodal
dataset of linguistic puzzles involving such scripts, utilizing a tokenization
method for language glyphs. Our methods include the Picture Method for LVLMs
and the Description Method for LLMs, enabling these models to tackle these
challenges. We conduct experiments using prominent models, GPT-4o, Gemini, and
Claude 3.5 Sonnet, on linguistic puzzles. Our findings reveal the strengths and
limitations of current AI methods in linguistic decipherment, highlighting the
impact of Unicode encoding on model performance and the challenges of modeling
visual language tokens through descriptions. Our study advances understanding
of AI's potential in linguistic decipherment and underscores the need for
further research.

æè¦ï¼æåæ¢è¨ LVLMs å LLM è§£ç¢¼æªç·¨ç¢¼å¨ Unicode ä¸­çç½è¦è³æ¬çè½åãæåå¼å¥ä¸ç¨®åµæ°çæ¹æ³ä¾å»ºæ§ä¸åæ¶åæ­¤é¡è³æ¬çå¤æ¨¡æèªè¨è¬é¡è³æéï¼å©ç¨ä¸ç¨®èªè¨å­å½¢çæ¨è¨åæ¹æ³ãæåçæ¨¡ååå« LVLMs çåçæ¹æ³å LLM çæè¿°æ¹æ³ï¼ä½¿éäºæ¨¡åè½å¤ æå°éäºææ°ãæåä½¿ç¨ååºçæ¨¡å GPT-4oãGemini å Claude 3.5 Sonnet å°èªè¨è¬é¡é²è¡å¯¦é©ãæåçç ç©¶çµææ­ç¤ºäºç¶å AI æ¹æ³å¨èªè¨è§£ç¢¼ä¸­çåªé»åéå¶ï¼å¼·èª¿äº Unicode ç·¨ç¢¼å°æ¨¡åæè½çå½±é¿ï¼ä»¥åééæè¿°å°è¦è¦ºèªè¨æ¨è¨å»ºæ¨¡çææ°ãæåçç ç©¶æ¨åäºå° AI å¨èªè¨è§£ç¢¼ä¸­çæ½åççè§£ï¼ä¸¦å¼·èª¿äºé²ä¸æ­¥ç ç©¶çå¿è¦æ§ã

##### **2SSP: A Two-Stage Framework for Structured Pruning of LLMs**
2501.17771v1 by Fabrizio Sandri, Elia Cunegatti, Giovanni Iacca

We propose a novel Two-Stage framework for Structured Pruning (2SSP) for
pruning Large Language Models (LLMs), which combines two different strategies
of pruning, namely Width and Depth Pruning. The first stage (Width Pruning)
removes entire neurons, hence their corresponding rows and columns, aiming to
preserve the connectivity among the pruned structures in the intermediate state
of the Feed-Forward Networks in each Transformer block. This is done based on
an importance score measuring the impact of each neuron over the output
magnitude. The second stage (Depth Pruning), instead, removes entire Attention
submodules. This is done by applying an iterative process that removes the
Attention submodules with the minimum impact on a given metric of interest (in
our case, perplexity). We also propose a novel mechanism to balance the
sparsity rate of the two stages w.r.t. to the desired global sparsity. We test
2SSP on four LLM families and three sparsity rates (25\%, 37.5\%, and 50\%),
measuring the resulting perplexity over three language modeling datasets as
well as the performance over six downstream tasks. Our method consistently
outperforms five state-of-the-art competitors over three language modeling and
six downstream tasks, with an up to two-order-of-magnitude gain in terms of
pruning time. The code is available at available at
\url{https://github.com/FabrizioSandri/2SSP}.

æè¦ï¼æåæåºäºä¸åæ°ç©çå©éæ®µæ¡æ¶ï¼ç¨æ¼çµæ§ååªæ (2SSP)ï¼ç¨æ¼åªæå¤§åèªè¨æ¨¡å (LLM)ï¼å®çµåäºå©ç¨®ä¸åçåªæç­ç¥ï¼å³å¯¬åº¦åªæåæ·±åº¦åªæãç¬¬ä¸éæ®µï¼å¯¬åº¦åªæï¼ç§»é¤æ´åç¥ç¶åï¼å æ­¤ç§»é¤å°æçè¡ååï¼ç®æ¨æ¯å¨æ¯å Transformer åå¡çé¥åç¶²è·¯çä¸­éçæä¸­ä¿çåªæçµæ§ä¹éçé£æ¥æ§ãéæ¯æ ¹æä¸åéè¦æ§åæ¸é²è¡çï¼è©²åæ¸æ¸¬éæ¯åç¥ç¶åå°è¼¸åºå¹åº¦çå½±é¿ãç¬¬äºéæ®µï¼æ·±åº¦åªæï¼åç§»é¤æ´åæ³¨æåå­æ¨¡çµãéæ¯ééæç¨ä¸åè¿­ä»£éç¨ä¾å®æçï¼è©²éç¨ç§»é¤å°çµ¦å®æèè¶£ææ¨ï¼å¨æåçæ¡ä¾ä¸­ï¼å°æåº¦ï¼å½±é¿æå°çæ³¨æåå­æ¨¡çµãæåéæåºäºä¸åæ°ç©çæ©å¶ä¾å¹³è¡¡å©åéæ®µçç¨ççï¼ä»¥éå°æéçæ´é«ç¨ççãæåå¨åå LLM å®¶æåä¸åç¨ççï¼25%ã37.5% å 50%ï¼ä¸æ¸¬è©¦ 2SSPï¼æ¸¬éäºä¸åèªè¨å»ºæ¨¡è³æéä¸ççµæå°æåº¦ï¼ä»¥åå­åä¸æ¸¸ä»»åä¸çæè½ãæåçæ¨¡åå¨ä¸åèªè¨å»ºæ¨¡åå­åä¸æ¸¸ä»»åä¸æçºåªæ¼äºåæåé²çç«¶ç­å°æï¼å¨åªææéæ¹é¢ç²å¾äºé«éå©åæ¸éç´çå¢çãç¨å¼ç¢¼å¯å¨ \url{https://github.com/FabrizioSandri/2SSP} åå¾ã

##### **Hybrid Graphs for Table-and-Text based Question Answering using LLMs**
2501.17767v1 by Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu

Answering questions that require reasoning and aggregation across both
structured (tables) and unstructured (raw text) data sources presents
significant challenges. Current methods rely on fine-tuning and high-quality,
human-curated data, which is difficult to obtain. Recent advances in Large
Language Models (LLMs) have shown promising results for multi-hop question
answering (QA) over single-source text data in a zero-shot setting, yet
exploration into multi-source Table-Text QA remains limited. In this paper, we
present a novel Hybrid Graph-based approach for Table-Text QA that leverages
LLMs without fine-tuning. Our method constructs a unified Hybrid Graph from
textual and tabular data, pruning information based on the input question to
provide the LLM with relevant context concisely. We evaluate our approach on
the challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs,
including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot
performance on both datasets, improving Exact Match scores by up to 10% on
Hybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up
to 53% compared to the original context.

æè¦ï¼åç­éè¦å°çµæ§åï¼è¡¨æ ¼ï¼åéçµæ§åï¼åå§æå­ï¼è³æä¾æºé²è¡æ¨çåå½ç¸½çåé¡æå¸¶ä¾éå¤§ææ°ãç®åçè¾¦æ³ä»°è³´å¾®èª¿åé«åè³ªãäººå·¥æ´ççè³æï¼èéå¾é£åå¾ãå¤§åèªè¨æ¨¡åï¼LLMï¼çææ°é²å±å·²éå°é¶æ¬¡å­¸ç¿è¨­å®çå®ä¸ä¾æºæå­è³æå¤è·³åé¡åç­ï¼QAï¼å±ç¾åºæå¸æççµæï¼ä½å°å¤ä¾æºè¡¨æ ¼æå­ QA çæ¢è¨ä»ç¶æéãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çåºæ¼æ··ååè¡¨çè¡¨æ ¼æå­ QA æ¹æ³ï¼å®å©ç¨ LLM èç¡éå¾®èª¿ãæåçè¾¦æ³å¾æå­åè¡¨æ ¼è³æå»ºæ§ä¸åçµ±ä¸çæ··ååè¡¨ï¼æ ¹æè¼¸å¥åé¡ä¿®åªè³è¨ï¼ä»¥ç°¡æ½å°çº LLM æä¾ç¸éèçµ¡ãæåä½¿ç¨æåé²ç LLMï¼åæ¬ GPT-3.5ãGPT-4 å LLaMA-3ï¼éå°å·æææ°æ§ç Hybrid-QA å OTT-QA è³æéè©ä¼°æåçè¾¦æ³ãæåçè¾¦æ³å¨å©åè³æéä¸é½éå°äºæä½³çé¶æ¬¡å­¸ç¿æè½ï¼å¨ Hybrid-QA ä¸å°å®å¨æ¯å°åæ¸æé«äº 10%ï¼å¨ OTT-QA ä¸å°å®å¨æ¯å°åæ¸æé«äº 5.4%ãæ­¤å¤ï¼èåå§èçµ¡ç¸æ¯ï¼æåçè¾¦æ³å°ç¬¦èä½¿ç¨éæ¸å°äº 53%ã

##### **Yin-Yang: Developing Motifs With Long-Term Structure And Controllability**
2501.17759v1 by Keshav Bhandari, Geraint A. Wiggins, Simon Colton

Transformer models have made great strides in generating symbolically
represented music with local coherence. However, controlling the development of
motifs in a structured way with global form remains an open research area. One
of the reasons for this challenge is due to the note-by-note autoregressive
generation of such models, which lack the ability to correct themselves after
deviations from the motif. In addition, their structural performance on
datasets with shorter durations has not been studied in the literature. In this
study, we propose Yin-Yang, a framework consisting of a phrase generator,
phrase refiner, and phrase selector models for the development of motifs into
melodies with long-term structure and controllability. The phrase refiner is
trained on a novel corruption-refinement strategy which allows it to produce
melodic and rhythmic variations of an original motif at generation time,
thereby rectifying deviations of the phrase generator. We also introduce a new
objective evaluation metric for quantifying how smoothly the motif manifests
itself within the piece. Evaluation results show that our model achieves better
performance compared to state-of-the-art transformer models while having the
advantage of being controllable and making the generated musical structure
semi-interpretable, paving the way for musical analysis. Our code and demo page
can be found at https://github.com/keshavbhandari/yinyang.

æè¦ï¼Transformeræ¨¡åå¨ç¢çå·æå±é¨ç¸å¹²æ§çç¬¦èè¡¨ç¤ºé³æ¨æ¹é¢åå¾äºé·è¶³çé²å±ãç¶èï¼ä»¥çµæ§åçæ¹å¼æ§å¶å¨å±å½¢å¼ä¸­çä¸»é¡ç¼å±ä»ç¶æ¯ä¸åéæ¾çç ç©¶é åãéç¨®ææ°çåå ä¹ä¸æ¯éç¨®æ¨¡åéåé³ç¬¦çèªååæ­¸çæï¼å®åç¼ºä¹å¨åé¢ä¸»é¡å¾èªæç³¾æ­£çè½åãæ­¤å¤ï¼å°æªå¨æç»ä¸­ç ç©¶å®åå¨æçºæéè¼ç­çæ¸æéä¸ççµæ§æ§è½ãå¨éé ç ç©¶ä¸­ï¼æåæåºäºé°é½ï¼ä¸åç±ç­èªçæå¨ãç­èªç²¾çå¨åç­èªé¸æå¨æ¨¡åçµæçæ¡æ¶ï¼ç¨æ¼å°ä¸»é¡ç¼å±æå·æé·æçµæ§åå¯æ§æ§çæå¾ãç­èªç²¾çå¨å¨ä¸åæ°ç©çç ´å£ç²¾çç­ç¥ä¸é²è¡è¨ç·´ï¼éä½¿å®è½å¤ å¨çææç¢çåå§ä¸»é¡çæå¾åç¯å¥è®å¥ï¼å¾èç³¾æ­£ç­èªçæå¨çåå·®ãæåéå¼å¥äºä¸åæ°çå®¢è§è©ä¼°ææ¨ï¼ç¨æ¼éåä¸»é¡å¨ä½åä¸­è¡¨ç¾å¾æå¤éº¼æµæ¢ãè©ä¼°çµæè¡¨æï¼èæåé²çTransformeræ¨¡åç¸æ¯ï¼æåçæ¨¡ååå¾äºæ´å¥½çæ§è½ï¼åæå·æå¯æ§æ§åä½¿çæçé³æ¨çµæ§åå¯è§£éçåªé»ï¼çºé³æ¨åæéªå¹³äºéè·¯ãæåçä»£ç¢¼åæ¼ç¤ºé é¢å¯ä»¥å¨ https://github.com/keshavbhandari/yinyang ä¸­æ¾å°ã

##### **Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation**
2501.17749v1 by Aitor Arrieta, Miriam Ugarte, Pablo Valle, JosÃ© Antonio Parejo, Sergio Segura

Large Language Models (LLMs) have become an integral part of our daily lives.
However, they impose certain risks, including those that can harm individuals'
privacy, perpetuate biases and spread misinformation. These risks highlight the
need for robust safety mechanisms, ethical guidelines, and thorough testing to
ensure their responsible deployment. Safety of LLMs is a key property that
needs to be thoroughly tested prior the model to be deployed and accessible to
the general users. This paper reports the external safety testing experience
conducted by researchers from Mondragon University and University of Seville on
OpenAI's new o3-mini LLM as part of OpenAI's early access for safety testing
program. In particular, we apply our tool, ASTRAL, to automatically and
systematically generate up to date unsafe test inputs (i.e., prompts) that
helps us test and assess different safety categories of LLMs. We automatically
generate and execute a total of 10,080 unsafe test input on a early o3-mini
beta version. After manually verifying the test cases classified as unsafe by
ASTRAL, we identify a total of 87 actual instances of unsafe LLM behavior. We
highlight key insights and findings uncovered during the pre-deployment
external testing phase of OpenAI's latest LLM.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²æçºæåæ¥å¸¸çæ´»ä¸å¯æç¼ºçä¸é¨åã
ç¶èï¼å®åæå¸¶ä¾æäºé¢¨éªï¼åæ¬å¯è½æå®³åäººé±ç§ãå»¶çºåè¦åæ£å¸é¯èª¤è¨æ¯çé¢¨éªãéäºé¢¨éªçªé¡¯åºéè¦ç©©å¥çå®å¨æ©å¶ãéå¾·æºååå¾¹åºçæ¸¬è©¦ï¼ä»¥ç¢ºä¿å¶è² è²¬ä»»çé¨ç½²ãLLM çå®å¨æ§æ¯ä¸åééµç¹æ§ï¼éè¦å¨æ¨¡åé¨ç½²ä¸¦ä¾ä¸è¬ä½¿ç¨èå­åä¹åé²è¡å¾¹åºçæ¸¬è©¦ãæ¬æå ±åäº Mondragon å¤§å­¸åå¡ç¶­äºå¤§å­¸çç ç©¶äººå¡å¨ OpenAI çæ©æå­åå®å¨æ¸¬è©¦è¨ç«ä¸­ï¼éå° OpenAI çæ° o3-mini LLM é²è¡çå¤é¨å®å¨æ¸¬è©¦ç¶é©ãç¹å¥æ¯ï¼æåéç¨æåçå·¥å· ASTRAL èªåä¸ç³»çµ±æ§å°ç¢çææ°çä¸å®å¨æ¸¬è©¦è¼¸å¥ï¼å³æç¤ºï¼ï¼éæå©æ¼æåæ¸¬è©¦åè©ä¼° LLM çä¸åå®å¨é¡å¥ãæåèªåç¢çä¸¦å·è¡ç¸½å± 10,080 åä¸å®å¨æ¸¬è©¦è¼¸å¥ï¼éå°æ©æ o3-mini æ¸¬è©¦çãå¨æåé©è­ ASTRAL åé¡çºä¸å®å¨çæ¸¬è©¦æ¡ä¾å¾ï¼æåç¸½å±æ¾åº 87 å LLM ä¸å®å¨è¡çºçå¯¦éç¯ä¾ãæåéé»èªªæå¨ OpenAI ææ° LLM çé¨ç½²åå¤é¨æ¸¬è©¦éæ®µä¸­ç¼ç¾çä¸»è¦è¦è§£åç¼ç¾ã

##### **Exact characterization of Îµ-Safe Decision Regions for exponential family distributions and Multi Cost SVM approximation**
2501.17731v1 by Alberto Carlevaro, Teodoro Alamo, Fabrizio Dabbene, Maurizio Mongelli

Probabilistic guarantees on the prediction of data-driven classifiers are
necessary to define models that can be considered reliable. This is a key
requirement for modern machine learning in which the goodness of a system is
measured in terms of trustworthiness, clearly dividing what is safe from what
is unsafe. The spirit of this paper is exactly in this direction. First, we
introduce a formal definition of {\epsilon}-Safe Decision Region, a subset of
the input space in which the prediction of a target (safe) class is
probabilistically guaranteed. Second, we prove that, when data come from
exponential family distributions, the form of such a region is analytically
determined and controllable by design parameters, i.e. the probability of
sampling the target class and the confidence on the prediction. However, the
request of having exponential data is not always possible. Inspired by this
limitation, we developed Multi Cost SVM, an SVM based algorithm that
approximates the safe region and is also able to handle unbalanced data. The
research is complemented by experiments and code available for reproducibility.

æè¦ï¼å¨è³æé©ååé¡å¨çé æ¸¬ä¸ï¼æ©çä¿è­å°æ¼å®ç¾©å¯è¢«èªçºå¯é çæ¨¡åæ¯å¿è¦çãéæ¯ç¾ä»£æ©å¨å­¸ç¿çä¸é ééµéæ±ï¼å¶ä¸­ç³»çµ±çåªå£æ¯æ ¹æå¯ä¿¡åº¦è¡¡éçï¼æ¸æ¥å°å°å®å¨èä¸å®å¨çååéä¾ãæ¬æçç²¾ç¥æ­£æ¯æéåæ¹åç¼å±ãé¦åï¼æåå¼å¥{\epsilon}-å®å¨æ±ºç­ååçæ­£å¼å®ç¾©ï¼å®æ¯è¼¸å¥ç©ºéçä¸åå­éï¼å¶ä¸­ç®æ¨ï¼å®å¨ï¼é¡å¥çé æ¸¬å¨æ©çä¸æ¯æä¿è­çãå¶æ¬¡ï¼æåè­æï¼ç¶è³æä¾èªææ¸æåä½æï¼éç¨®ååçå½¢å¼æ¯ç±è¨­è¨åæ¸è§£æç¢ºå®çåå¯æ§çï¼å³æ½æ¨£ç®æ¨é¡å¥çæ©çåé æ¸¬çä¿¡å¿ãç¶èï¼ææææ¸è³æçè¦æ±ä¸¦ä¸ç¸½æ¯å¯è¡çãåå°éåéå¶çåç¼ï¼æåéç¼äºå¤ææ¬ SVMï¼ä¸ç¨®åºæ¼ SVM çæ¼ç®æ³ï¼å®è¿ä¼¼å®å¨ååï¼ä¸¦ä¸ä¹è½å¤ èçä¸å¹³è¡¡çè³æãæ¬ç ç©¶ç±å¯¦é©åå¯ä¾éç¾çç¨å¼ç¢¼è£åã

##### **VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies in Generated Report Without Human Feedback**
2501.17726v1 by Sayeh Gholipour Picha, Dawood Al Chanti, Alice Caplier

As artificial intelligence (AI) becomes increasingly central to healthcare,
the demand for explainable and trustworthy models is paramount. Current report
generation systems for chest X-rays (CXR) often lack mechanisms for validating
outputs without expert oversight, raising concerns about reliability and
interpretability. To address these challenges, we propose a novel multimodal
framework designed to enhance the semantic alignment and localization accuracy
of AI-generated medical reports. Our framework integrates two key modules: a
Phrase Grounding Model, which identifies and localizes pathologies in CXR
images based on textual prompts, and a Text-to-Image Diffusion Module, which
generates synthetic CXR images from prompts while preserving anatomical
fidelity. By comparing features between the original and generated images, we
introduce a dual-scoring system: one score quantifies localization accuracy,
while the other evaluates semantic consistency. This approach significantly
outperforms existing methods, achieving state-of-the-art results in pathology
localization and text-to-image alignment. The integration of phrase grounding
with diffusion models, coupled with the dual-scoring evaluation system,
provides a robust mechanism for validating report quality, paving the way for
more trustworthy and transparent AI in medical imaging.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) å¨é«çä¿å¥ä¸­æ®æ¼è¶ä¾è¶éè¦çè§è²ï¼
å°å¯è§£éä¸å¼å¾ä¿¡è³´çæ¨¡åçéæ±è³ééè¦ãç®åéå°è¸é¨ X å (CXR) çå ±åçæç³»çµ±éå¸¸ç¼ºä¹å¨æ²æå°å®¶ç£ç£çææ³ä¸é©è­è¼¸åºçæ©å¶ï¼éå¼ç¼äºå°å¯é æ§åå¯è§£éæ§ççæ®ãçºäºæå°éäºææ°ï¼æåæåºäºä¸åæ°ç©çå¤æ¨¡ææ¶æ§ï¼æ¨å¨å¢å¼· AI çæçé«çå ±åçèªç¾©å°é½åå®ä½æºç¢ºåº¦ãæåçæ¶æ§æ´åäºå©åééµæ¨¡çµï¼ä¸ååºæ¼æå­æç¤ºè­å¥åå®ä½ CXR å½±åä¸­çççè©çµåºç¤æ¨¡åï¼ä»¥åä¸åæå­å°å½±åæ´æ£æ¨¡çµï¼è©²æ¨¡çµå¨ä¿çè§£åçµæ§ä¿çåº¦çåæï¼å¾æç¤ºä¸­çæåæ CXR å½±åãééæ¯è¼åå§å½±ååçæå½±åä¹éçç¹å¾µï¼æåå¼å¥äºééè©åç³»çµ±ï¼ä¸åè©åéåå®ä½æºç¢ºåº¦ï¼èå¦ä¸åè©ååè©ä¼°èªç¾©ä¸è´æ§ãéç¨®æ¹æ³é¡¯èåªæ¼ç¾ææ¹æ³ï¼å¨ççå®ä½åæå­å°å½±åå°é½æ¹é¢åå¾äºæåé²çææãè©çµåºç¤èæ´æ£æ¨¡åçæ´åï¼å ä¸ééè©åè©ä¼°ç³»çµ±ï¼æä¾äºä¸åé©è­å ±ååè³ªçå¼·å¥æ©å¶ï¼çºé«çå½±åä¸­æ´å¼å¾ä¿¡è³´ä¸éæç AI éªè·¯ã

##### **Using Code Generation to Solve Open Instances of Combinatorial Design Problems**
2501.17725v1 by Christopher D. Rosin

The Handbook of Combinatorial Designs catalogs many types of combinatorial
designs, together with lists of open instances for which existence has not yet
been determined. We develop a constructive protocol CPro1, which uses Large
Language Models (LLMs) to generate code that constructs combinatorial designs
and resolves some of these open instances. The protocol starts from a
definition of a particular type of design, and a verifier that reliably
confirms whether a proposed design is valid. The LLM selects strategies and
implements them in code, and scaffolding provides automated hyperparameter
tuning and execution feedback using the verifier. Most generated code fails,
but by generating many candidates, the protocol automates exploration of a
variety of standard methods (e.g. simulated annealing, genetic algorithms) and
experimentation with variations (e.g. cost functions) to find successful
approaches. Testing on 16 different types of designs, CPro1 constructs
solutions to open instances for 6 of them: Symmetric and Skew Weighing
Matrices, Equidistant Permutation Arrays, Packing Arrays, Balanced Ternary
Designs, and Florentine Rectangles.

æè¦ï¼çµåè¨­è¨æåå½æ´äºè¨±å¤é¡åççµåè¨­è¨ï¼ä»¥åå°æªç¢ºå®å­å¨çéæ¾å¯¦ä¾æ¸å®ãæåéç¼äºä¸åå»ºæ§åå® CPro1ï¼å®ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾ç¢çå»ºæ§çµåè¨­è¨çç¨å¼ç¢¼ï¼ä¸¦è§£æ±ºå¶ä¸­ä¸äºéæ¾å¯¦ä¾ãæ­¤åå®å¾ç¹å®é¡åè¨­è¨çå®ç¾©éå§ï¼ä»¥åä¸åå¯é ç¢ºèªå»ºè­°è¨­è¨æ¯å¦ææçé©è­å¨ãLLM é¸æç­ç¥ä¸¦å¨ç¨å¼ç¢¼ä¸­å¯¦ä½å®åï¼èæ¶æ§æä¾èªåè¶åæ¸èª¿æ´åä½¿ç¨é©è­å¨çå·è¡åé¥ãå¤§å¤æ¸ç¢ççç¨å¼ç¢¼é½æå¤±æï¼ä½ééç¢çè¨±å¤åé¸ï¼æ­¤åå®èªååæ¢ç´¢åç¨®æ¨æºæ¹æ³ï¼ä¾å¦æ¨¡æ¬éç«ãéºå³æ¼ç®æ³ï¼ä¸¦å¯¦é©è®ç°ï¼ä¾å¦ææ¬å½æ¸ï¼ä»¥æ¾åºæåçåæ³ãå¨ 16 ç¨®ä¸åé¡åçè¨­è¨ä¸é²è¡æ¸¬è©¦ï¼CPro1 çºå¶ä¸­ 6 ç¨®è¨­è¨å»ºæ§äºè§£æ±ºæ¹æ¡ï¼å°ç¨±ååæå æ¬ç©é£ãç­è·æåé£åãå ç©é£åãå¹³è¡¡ä¸åè¨­è¨åä½ç¾å«æ¯ç©å½¢ã

##### **RICoTA: Red-teaming of In-the-wild Conversation with Test Attempts**
2501.17715v1 by Eujeong Choi, Younghun Jeong, Soomin Kim, Won Ik Cho

User interactions with conversational agents (CAs) evolve in the era of
heavily guardrailed large language models (LLMs). As users push beyond
programmed boundaries to explore and build relationships with these systems,
there is a growing concern regarding the potential for unauthorized access or
manipulation, commonly referred to as "jailbreaking." Moreover, with CAs that
possess highly human-like qualities, users show a tendency toward initiating
intimate sexual interactions or attempting to tame their chatbots. To capture
and reflect these in-the-wild interactions into chatbot designs, we propose
RICoTA, a Korean red teaming dataset that consists of 609 prompts challenging
LLMs with in-the-wild user-made dialogues capturing jailbreak attempts. We
utilize user-chatbot conversations that were self-posted on a Korean
Reddit-like community, containing specific testing and gaming intentions with a
social chatbot. With these prompts, we aim to evaluate LLMs' ability to
identify the type of conversation and users' testing purposes to derive chatbot
design implications for mitigating jailbreaking risks. Our dataset will be made
publicly available via GitHub.

æè¦ï¼å¨å¤§åèªè¨æ¨¡å (LLM) åå°å´æ ¼ä¿è­·çæä»£ï¼ä½¿ç¨èèå°è©±å¼ä»£ç (CA) çäºåä¸æ·æ¼é²ãé¨èä½¿ç¨èçªç ´æ¢å®ççç·ï¼æ¢ç´¢ä¸¦å»ºç«èéäºç³»çµ±çéä¿ï¼å°æ¼æªç¶ææ¬çå­åææç¸±ï¼ä¸è¬ç¨±çºãè¶çãï¼çæ½å¨é¢¨éªä¹è¶ä¾è¶ä»¤äººææãæ­¤å¤ï¼ç±æ¼ CA ææé«åº¦æ¬äººçç¹è³ªï¼ä½¿ç¨èå¾åæ¼ç¼èµ·è¦ªå¯çæ§äºåæåè©¦é¦´æä»åçèå¤©æ©å¨äººãçºäºææä¸¦åæ éäºå¨éäºåå°èå¤©æ©å¨äººçè¨­è¨ä¸­ï¼æåæåº RICoTAï¼éæ¯ä¸åéèªç´éæ¸æéï¼åå« 609 åæç¤ºï¼ææ° LLM ä½¿ç¨ææè¶çåè©¦çéçæä½¿ç¨èå°è©±ãæåå©ç¨å¨é¡ä¼¼éå Reddit çç¤¾ç¾¤ä¸­èªè¡ç¼å¸çä½¿ç¨èèå¤©æ©å¨äººå°è©±ï¼å¶ä¸­åå«èç¤¾äº¤èå¤©æ©å¨äººçå·é«æ¸¬è©¦åéæ²æåãéééäºæç¤ºï¼æåæ¨å¨è©ä¼° LLM è­å¥å°è©±é¡ååä½¿ç¨èæ¸¬è©¦ç®ççè½åï¼ä»¥æ¨å°èå¤©æ©å¨äººè¨­è¨çå«æï¼ä»¥æ¸è¼è¶çé¢¨éªãæåçæ¸æéå°éé GitHub å¬éã

##### **Inferring Implicit Goals Across Differing Task Models**
2501.17704v1 by Silvia Tulli, Stylianos Loukas Vasileiou, Mohamed Chetouani, Sarath Sreedharan

One of the significant challenges to generating value-aligned behavior is to
not only account for the specified user objectives but also any implicit or
unspecified user requirements. The existence of such implicit requirements
could be particularly common in settings where the user's understanding of the
task model may differ from the agent's estimate of the model. Under this
scenario, the user may incorrectly expect some agent behavior to be inevitable
or guaranteed. This paper addresses such expectation mismatch in the presence
of differing models by capturing the possibility of unspecified user subgoal in
the context of a task captured as a Markov Decision Process (MDP) and querying
for it as required. Our method identifies bottleneck states and uses them as
candidates for potential implicit subgoals. We then introduce a querying
strategy that will generate the minimal number of queries required to identify
a policy guaranteed to achieve the underlying goal. Our empirical evaluations
demonstrate the effectiveness of our approach in inferring and achieving
unstated goals across various tasks.

æè¦ï¼ç¢çå¹å¼å°é½è¡çºæï¼å¶ä¸­ä¸é éå¤§ææ°å¨æ¼ï¼ä¸åè¦èæ®æå®çä½¿ç¨èç®æ¨ï¼éè¦èæ®ä»»ä½é±å«ææªæå®çä½¿ç¨èéæ±ãæ­¤é¡é±å«éæ±çå­å¨ï¼å¨ä½¿ç¨èå°ä»»åæ¨¡åççè§£å¯è½èä»£çäººå°æ¨¡åçä¼°è¨ä¸åçææ³ä¸­ç¹å¥å¸¸è¦ãå¨æ­¤ææ³ä¸ï¼ä½¿ç¨èå¯è½æé¯èª¤å°é ææäºä»£çäººè¡çºæ¯ä¸å¯é¿åææä¿è­çãæ¬æééå¨é¦¬å¯å¤«æ±ºç­éç¨ (MDP) ä¸­æææªæå®ä½¿ç¨èæ¬¡ç®æ¨çå¯è½æ§ï¼ä¸¦å¨éè¦ææ¥è©¢å®ï¼ä¾è§£æ±ºå¨æ¨¡åä¸åçææ³ä¸éç¨®é æä¸ç¬¦çåé¡ãæåçåæ³ææ¾åºç¶é ¸çæï¼ä¸¦å°å®åç¨ä½æ½å¨é±å«æ¬¡ç®æ¨çåé¸èãç¶å¾ï¼æåæå¼å¥ä¸ç¨®æ¥è©¢ç­ç¥ï¼éå°ç¢çè­å¥ç­ç¥æéçæå°æ¥è©¢æ¸ç®ï¼ä»¥ç¢ºä¿éæåºç¤ç®æ¨ãæåçç¶é©è©ä¼°è­æäºæåçæ¹æ³å¨æ¨è«åéæåç¨®ä»»åä¸­æªèªªæç®æ¨çæææ§ã

##### **Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate**
2501.17703v1 by Yubo Wang, Xiang Yue, Wenhu Chen

Supervised Fine-Tuning (SFT) is commonly used to train language models to
imitate annotated responses for given instructions. In this paper, we challenge
this paradigm and propose Critique Fine-Tuning (CFT), a strategy where models
learn to critique noisy responses rather than simply imitate correct ones.
Inspired by human learning processes that emphasize critical thinking, CFT
encourages deeper analysis and nuanced understanding-traits often overlooked by
standard SFT. To validate the effectiveness of CFT, we construct a 50K-sample
dataset from WebInstruct, using GPT-4o as the teacher to generate critiques in
the form of (input=[query; noisy response], output=critique). CFT on this
dataset yields a consistent 4-10% improvement over SFT on six math benchmarks
with different base models like Qwen2.5, Qwen2.5-Math and DeepSeek-Math. We
further expand to MetaMath and NuminaMath datasets and observe similar gains
over SFT. Notably, our Qwen2.5-Math-CFT model-trained on just 50K
samples-matches or outperforms competitive models such as AceMath and
Qwen2.5-Math-Instruct on most benchmarks, both of which use over 2M samples.
Ablation studies show that CFT is robust to the source of noisy response and
teacher critique model. Through these findings, we argue that critique-based
training offers a more effective alternative to advance the reasoning of
language models.

æè¦ï¼<paragraph>ç£ç£å¾®èª¿ (SFT) å¸¸ç¨æ¼è¨ç·´èªè¨æ¨¡åï¼ä»¥æ¨¡ä»¿éå°ç¹å®æç¤ºçæ¨è¨»åæãå¨æ¬æä¸­ï¼æåææ°æ­¤ç¯ä¾ä¸¦æåºæ¹å¤å¾®èª¿ (CFT)ï¼éæ¯ä¸ç¨®ç­ç¥ï¼æ¨¡åå­¸ç¿æ¹å¤æéè¨çåæï¼èéåæ¨¡ä»¿æ­£ç¢ºçåæãåå¼·èª¿æ¹å¤æ§æèçäººé¡å­¸ç¿éç¨åç¼ï¼CFT é¼åµæ´æ·±å¥çåæåç´°å¾®ççè§£ï¼éäºç¹è³ªéå¸¸è¢«æ¨æº SFT å¿½ç¥ãçºäºé©è­ CFT çæææ§ï¼æåå¾ WebInstruct å»ºæ§ä¸å 50K ç¯ä¾çè³æéï¼ä½¿ç¨ GPT-4o ä½çºæå¸«ï¼ä»¥ (è¼¸å¥=[æ¥è©¢ï¼æéè¨çåæ]ï¼è¼¸åº=æ¹å¤) çå½¢å¼ç¢çæ¹å¤ãæ­¤è³æéä¸ç CFT å¨å­åæ¸å­¸åºæºä¸ç¢çä¸è´ç 4-10% é²æ­¥ï¼ä½¿ç¨ä¸åçåºç¤æ¨¡åï¼ä¾å¦ Qwen2.5ãQwen2.5-Math å DeepSeek-Mathãæåé²ä¸æ­¥æ´å±å° MetaMath å NuminaMath è³æéï¼ä¸¦è§å¯å°æ¯ SFT é¡ä¼¼çå¢çãå¼å¾æ³¨æçæ¯ï¼æåç Qwen2.5-Math-CFT æ¨¡ååè¨ç·´æ¼ 50K ç¯ä¾ï¼å¨å¤æ¸åºæºä¸æ¯ AceMath å Qwen2.5-Math-Instruct ç­ç«¶ç­æ¨¡åå¹éæè¡¨ç¾æ´ä½³ï¼èå¾å©èé½ä½¿ç¨è¶é 2M ç¯ä¾ãæ¶èç ç©¶é¡¯ç¤ºï¼CFT å°æéè¨çåæä¾æºåæå¸«æ¹å¤æ¨¡åå·æç©©å¥æ§ãéééäºç¼ç¾ï¼æåä¸»å¼µåºæ¼æ¹å¤çè¨ç·´æä¾æ´ææçæ¿ä»£æ¹æ¡ï¼ä»¥æ¨é²èªè¨æ¨¡åçæ¨çã</paragraph>

##### **PulmoFusion: Advancing Pulmonary Health with Efficient Multi-Modal Fusion**
2501.17699v1 by Ahmed Sharshar, Yasser Attia, Mohammad Yaqub, Mohsen Guizani

Traditional remote spirometry lacks the precision required for effective
pulmonary monitoring. We present a novel, non-invasive approach using
multimodal predictive models that integrate RGB or thermal video data with
patient metadata. Our method leverages energy-efficient Spiking Neural Networks
(SNNs) for the regression of Peak Expiratory Flow (PEF) and classification of
Forced Expiratory Volume (FEV1) and Forced Vital Capacity (FVC), using
lightweight CNNs to overcome SNN limitations in regression tasks. Multimodal
data integration is improved with a Multi-Head Attention Layer, and we employ
K-Fold validation and ensemble learning to boost robustness. Using thermal
data, our SNN models achieve 92% accuracy on a breathing-cycle basis and 99.5%
patient-wise. PEF regression models attain Relative RMSEs of 0.11 (thermal) and
0.26 (RGB), with an MAE of 4.52% for FEV1/FVC predictions, establishing
state-of-the-art performance. Code and dataset can be found on
https://github.com/ahmed-sharshar/RespiroDynamics.git

æè¦ï¼å³çµ±çé è·èºæ´»éæ¸¬éæ³ç¼ºä¹ææèºé¨ç£æ¸¬æéçç²¾ç¢ºåº¦ãæåæåºäºä¸ç¨®ä½¿ç¨å¤æ¨¡å¼é æ¸¬æ¨¡åçæ°åéä¾µå¥æ§æ¹æ³ï¼è©²æ¨¡åå° RGB æç±å½±åæ¸æèæ£èåæ¸ææ´åå¨ä¸èµ·ãæåçæè¡å©ç¨ç¯è½çå°å³°ç¥ç¶ç¶²è·¯ (SNN) ä¾åæ­¸æå¤§å¼æ°£æµé (PEF) ååé¡ç¨åå¼æ°£é (FEV1) åç¨åèºæ´»é (FVC)ï¼ä¸¦ä½¿ç¨è¼éç´ CNN ä¾åæ SNN å¨åæ­¸ä»»åä¸­çéå¶ãå¤æ¨¡å¼æ¸ææ´åééå¤é ­æ³¨æåå±¤å¾å°æ¹é²ï¼æåæ¡ç¨ K æé©è­åéæå­¸ç¿ä¾æé«é­¯æ£æ§ãä½¿ç¨ç±æ¸æï¼æåç SNN æ¨¡åå¨å¼å¸é±æåºç¤ä¸å¯¦ç¾äº 92% çæºç¢ºåº¦ï¼å¨æ£èåºç¤ä¸å¯¦ç¾äº 99.5% çæºç¢ºåº¦ãPEF åæ­¸æ¨¡åç²å¾ 0.11ï¼ç±ï¼å 0.26ï¼RGBï¼çç¸å° RMSEï¼FEV1/FVC é æ¸¬ç MAE çº 4.52%ï¼å»ºç«äºæåé²çæ§è½ãä»£ç¢¼åæ¸æéå¯å¨ https://github.com/ahmed-sharshar/RespiroDynamics.git ä¸æ¾å°

##### **Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment**
2501.17690v1 by Zixue Zeng, Xiaoyan Zhao, Matthew Cartier, Tong Yu, Jing Wang, Xin Meng, Zhiyu Sheng, Maryam Satarpour, John M Cormack, Allison Bean, Ryan Nussbaum, Maya Maurer, Emily Landis-Walkenhorst, Dinesh Kumbhare, Kang Kim, Ajay Wasan, Jiantao Pu

We introduce a novel segmentation-aware joint training framework called
generative reinforcement network (GRN) that integrates segmentation loss
feedback to optimize both image generation and segmentation performance in a
single stage. An image enhancement technique called segmentation-guided
enhancement (SGE) is also developed, where the generator produces images
tailored specifically for the segmentation model. Two variants of GRN were also
developed, including GRN for sample-efficient learning (GRN-SEL) and GRN for
semi-supervised learning (GRN-SSL). GRN's performance was evaluated using a
dataset of 69 fully annotated 3D ultrasound scans from 29 subjects. The
annotations included six anatomical structures: dermis, superficial fat,
superficial fascial membrane (SFM), deep fat, deep fascial membrane (DFM), and
muscle. Our results show that GRN-SEL with SGE reduces labeling efforts by up
to 70% while achieving a 1.98% improvement in the Dice Similarity Coefficient
(DSC) compared to models trained on fully labeled datasets. GRN-SEL alone
reduces labeling efforts by 60%, GRN-SSL with SGE decreases labeling
requirements by 70%, and GRN-SSL alone by 60%, all while maintaining
performance comparable to fully supervised models. These findings suggest the
effectiveness of the GRN framework in optimizing segmentation performance with
significantly less labeled data, offering a scalable and efficient solution for
ultrasound image analysis and reducing the burdens associated with data
annotation.

æè¦ï¼<paragraph>æåæåºä¸åæ°ç©çåå²æç¥è¯åè¨ç·´æ¶æ§ï¼ç¨±çºçæå¼å¼·åç¶²è·¯ (GRN)ï¼å®æ´åäºåå²æå¤±åé¥ï¼ä»¥å¨å®ä¸éæ®µä¸­åªåå½±åçæååå²æè½ãä¹éç¼äºä¸ç¨®ç¨±çºåå²å°åå¢å¼· (SGE) çå½±åå¢å¼·æè¡ï¼å¶ä¸­çæå¨ç¢çå°ééå°åå²æ¨¡åçå½±åãä¹éç¼äº GRN çå©åè®é«ï¼åæ¬ç¨æ¼æ¨£æ¬ææçå­¸ç¿ç GRN (GRN-SEL) åç¨æ¼åç£ç£å¼å­¸ç¿ç GRN (GRN-SSL)ãGRN çæè½ä½¿ç¨ä¾èª 29 ååè©¦èç 69 åå®æ´æ¨è¨» 3D è¶é³æ³¢ææçè³æéé²è¡è©ä¼°ãæ¨è¨»åæ¬å­åè§£åçµæ§ï¼çç®ãæ·ºå±¤èèªãæ·ºå±¤ç­è (SFM)ãæ·±å±¤èèªãæ·±å±¤ç­è (DFM) åèèãæåççµæé¡¯ç¤ºï¼ä½¿ç¨ SGE ç GRN-SEL å¯å°æ¨ç±¤å·¥ä½æ¸å°å¤é 70%ï¼åæèå¨å®æ´æ¨ç±¤è³æéä¸è¨ç·´çæ¨¡åç¸æ¯ï¼Dice ç¸ä¼¼ä¿æ¸ (DSC) æ¹åäº 1.98%ãå GRN-SEL å¯å°æ¨ç±¤å·¥ä½æ¸å° 60%ï¼ä½¿ç¨ SGE ç GRN-SSL å¯å°æ¨ç±¤éæ±æ¸å° 70%ï¼èå GRN-SSL å¯æ¸å° 60%ï¼ææéäºåæç¶­æèå®å¨ç£ç£æ¨¡åç¸ç¶çæè½ãéäºç¼ç¾è¡¨æ GRN æ¶æ§å¨ä»¥é¡¯èè¼å°çæ¨ç±¤è³æåªååå²æè½æ¹é¢çæææ§ï¼æä¾äºä¸åå¯æ´åä¸ææççè¶é³æ³¢å½±ååæè§£æ±ºæ¹æ¡ï¼ä¸¦éä½èè³ææ¨è¨»ç¸éçè² æã</paragraph>

##### **Planning with Vision-Language Models and a Use Case in Robot-Assisted Teaching**
2501.17665v1 by Xuzhe Dang, Lada KudlÃ¡ÄkovÃ¡, Stefan Edelkamp

Automating the generation of Planning Domain Definition Language (PDDL) with
Large Language Model (LLM) opens new research topic in AI planning,
particularly for complex real-world tasks. This paper introduces Image2PDDL, a
novel framework that leverages Vision-Language Models (VLMs) to automatically
convert images of initial states and descriptions of goal states into PDDL
problems. By providing a PDDL domain alongside visual inputs, Imasge2PDDL
addresses key challenges in bridging perceptual understanding with symbolic
planning, reducing the expertise required to create structured problem
instances, and improving scalability across tasks of varying complexity. We
evaluate the framework on various domains, including standard planning domains
like blocksworld and sliding tile puzzles, using datasets with multiple
difficulty levels. Performance is assessed on syntax correctness, ensuring
grammar and executability, and content correctness, verifying accurate state
representation in generated PDDL problems. The proposed approach demonstrates
promising results across diverse task complexities, suggesting its potential
for broader applications in AI planning. We will discuss a potential use case
in robot-assisted teaching of students with Autism Spectrum Disorder.

æè¦ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) èªååè¦åé åå®ç¾©èªè¨ (PDDL) ççæï¼çº AI è¦åéåäºæ°çç ç©¶ä¸»é¡ï¼ç¹å¥æ¯å°æ¼è¤éççå¯¦ä¸çä»»åãæ¬æä»ç´¹ Image2PDDLï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®å©ç¨è¦è¦ºèªè¨æ¨¡å (VLM) å°åå§çæçå½±ååç®æ¨çæçæè¿°èªåè½æçº PDDL åé¡ãééæä¾ PDDL é ååè¦è¦ºè¼¸å¥ï¼Imasge2PDDL æå°äºå°æç¥çè§£èç¬¦èè¦åçµåèµ·ä¾çä¸»è¦ææ°ï¼æ¸å°äºå»ºç«çµæ§ååé¡å¯¦ä¾æéçå°æ¥­ç¥è­ï¼ä¸¦æé«äºè·¨è¶ä¸åè¤éæ§ä»»åçå¯æ´åæ§ãæåå¨åç¨®é åå°è©²æ¡æ¶é²è¡è©ä¼°ï¼åæ¬æ¨æºè¦åé åï¼ä¾å¦ç©æ¨ä¸çåæ»åæ¼åï¼ä½¿ç¨å·æå¤åé£åº¦ç­ç´çè³æéãæè½è©ä¼°åæ¬èªæ³æ­£ç¢ºæ§ï¼ç¢ºä¿èªæ³åå¯å·è¡æ§ï¼ä»¥åå§å®¹æ­£ç¢ºæ§ï¼é©è­çæç PDDL åé¡ä¸­çæºç¢ºçæè¡¨ç¤ºãææåºçæ¹æ³å¨ä¸åçä»»åè¤éæ§ä¸­å±ç¤ºäºæå¸æççµæï¼è¡¨æå¶å¨ AI è¦åä¸­å·ææ´å»£æ³çæç¨æ½åãæåå°è¨è«èªéçè­ç³»éç¤å­¸ççæ©å¨äººè¼å©æå­¸ä¸­çæ½å¨ç¨ä¾ã

##### **Exploring Vision Language Models for Multimodal and Multilingual Stance Detection**
2501.17654v1 by Jake Vasilakes, Carolina Scarton, Zhixue Zhao

Social media's global reach amplifies the spread of information, highlighting
the need for robust Natural Language Processing tasks like stance detection
across languages and modalities. Prior research predominantly focuses on
text-only inputs, leaving multimodal scenarios, such as those involving both
images and text, relatively underexplored. Meanwhile, the prevalence of
multimodal posts has increased significantly in recent years. Although
state-of-the-art Vision-Language Models (VLMs) show promise, their performance
on multimodal and multilingual stance detection tasks remains largely
unexamined. This paper evaluates state-of-the-art VLMs on a newly extended
dataset covering seven languages and multimodal inputs, investigating their use
of visual cues, language-specific performance, and cross-modality interactions.
Our results show that VLMs generally rely more on text than images for stance
detection and this trend persists across languages. Additionally, VLMs rely
significantly more on text contained within the images than other visual
content. Regarding multilinguality, the models studied tend to generate
consistent predictions across languages whether they are explicitly
multilingual or not, although there are outliers that are incongruous with
macro F1, language support, and model size.

æè¦ï¼ç¤¾ç¾¤åªé«çå¨çå½±é¿åæ´å¤§äºè³è¨çå³æ­ï¼çªé¡¯äºå°å¥å¨èªç¶èªè¨èçä»»åçéæ±ï¼ä¾å¦è·¨èªè¨åæ¨¡æçç«å ´åµæ¸¬ãååçç ç©¶ä¸»è¦éä¸­å¨ç´æå­è¼¸å¥ä¸ï¼èå°æ¶åå½±ååæå­çå¤æ¨¡æå ´æ¯çä½ç¸å°æªç¶æ¢ç´¢çé åãåæï¼è¿å¹´ä¾å¤æ¨¡æè²¼æççè¡å·²å¤§å¹å¢å ãåç®¡æåé²çè¦è¦ºèªè¨æ¨¡å (VLM) é¡¯ç¤ºåºåæ¯ï¼ä½å®åå¨å¤æ¨¡æåå¤èªè¨ç«å ´åµæ¸¬ä»»åä¸­çè¡¨ç¾ä»æªç¶éå»£æ³æª¢é©ãæ¬æè©ä¼°äºæåé²ç VLMï¼æ¡ç¨ä¸åæ°æ´åçè³æéï¼æ¶µèä¸ç¨®èªè¨åå¤æ¨¡æè¼¸å¥ï¼æ¢è¨å®åå°è¦è¦ºç·ç´¢çä½¿ç¨ãç¹å®èªè¨çè¡¨ç¾ä»¥åè·¨æ¨¡æäºåãæåççµæé¡¯ç¤ºï¼VLM ä¸è¬æ´ä¾è³´æå­èéå½±åé²è¡ç«å ´åµæ¸¬ï¼èä¸éç¨®è¶¨å¢å¨åèªè¨éæçºå­å¨ãæ­¤å¤ï¼VLM æ´é¡¯èå°ä¾è³´å½±åä¸­åå«çæå­ï¼èéå¶ä»è¦è¦ºå§å®¹ãéæ¼å¤èªè¨æ§ï¼æç ç©¶çæ¨¡åå¾åæ¼å¨åèªè¨éç¢çä¸è´çé æ¸¬ï¼ç¡è«å®åæ¯å¦æç¢ºå°æ¯æ´å¤èªè¨ï¼åç®¡æä¸äºç°å¸¸å¼èå·¨è§ F1ãèªè¨æ¯æ´åæ¨¡åå¤§å°ä¸ä¸è´ã

##### **Tonguescape: Exploring Language Models Understanding of Vowel Articulation**
2501.17643v1 by Haruki Sakajo, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe

Vowels are primarily characterized by tongue position. Humans have discovered
these features of vowel articulation through their own experience and explicit
objective observation such as using MRI. With this knowledge and our
experience, we can explain and understand the relationship between tongue
positions and vowels, and this knowledge is helpful for language learners to
learn pronunciation. Since language models (LMs) are trained on a large amount
of data that includes linguistic and medical fields, our preliminary studies
indicate that an LM is able to explain the pronunciation mechanisms of vowels.
However, it is unclear whether multi-modal LMs, such as vision LMs, align
textual information with visual information. One question arises: do LMs
associate real tongue positions with vowel articulation? In this study, we
created video and image datasets from the existing real-time MRI dataset and
investigated whether LMs can understand vowel articulation based on tongue
positions using vision-based information. Our findings suggest that LMs exhibit
potential for understanding vowels and tongue positions when reference examples
are provided while they have difficulties without them. Our code for dataset
building is available on GitHub.

æè¦ï¼åé³ä¸»è¦ç±èé ­ä½ç½®æ±ºå®ãäººé¡ééèªå·±çç¶é©åæç¢ºçå®¢è§è§å¯ï¼ä¾å¦ä½¿ç¨ MRIï¼ç¼ç¾äºåé³ç¼é³çéäºç¹å¾µãæäºéäºç¥è­åç¶é©ï¼æåå¯ä»¥è§£éåçè§£èé ­ä½ç½®ååé³ä¹éçéä¿ï¼èéäºç¥è­å°èªè¨å­¸ç¿èå­¸ç¿ç¼é³å¾æå¹«å©ãç±æ¼èªè¨æ¨¡å (LM) æ¯å¨åå«èªè¨å­¸åé«å­¸é åçå¤§éè³æä¸è¨ç·´çï¼æåçåæ­¥ç ç©¶è¡¨æï¼LM è½å¤ è§£éåé³çç¼é³æ©å¶ãç¶èï¼å°ä¸æ¸æ¥å¤æ¨¡æ LMï¼ä¾å¦è¦è¦º LMï¼æ¯å¦å°æå­è³è¨èè¦è¦ºè³è¨å°é½ãä¸ååé¡ç¢çäºï¼LM æ¯å¦å°çå¯¦çèé ­ä½ç½®èåé³ç¼é³è¯ç¹«èµ·ä¾ï¼å¨éé ç ç©¶ä¸­ï¼æåå¾ç¾æçå³æ MRI è³æéä¸­å»ºç«äºå½±çåå½±åè³æéï¼ä¸¦æ¢è¨ LM æ¯å¦è½æ ¹æèé ­ä½ç½®ä½¿ç¨åºæ¼è¦è¦ºçè³è¨ä¾çè§£åé³ç¼é³ãæåçç ç©¶çµæè¡¨æï¼ç¶æä¾åèç¯ä¾æï¼LM å·æçè§£åé³åèé ­ä½ç½®çæ½åï¼èæ²æåèç¯ä¾æåæå°é£ãæåç¨æ¼å»ºç«è³æéçç¨å¼ç¢¼å¯å¨ GitHub ä¸åå¾ã

##### **In-Context Meta LoRA Generation**
2501.17635v1 by Yihua Shao, Minxi Yan, Yang Liu, Siyu Chen, Wenjie Chen, Xinwei Long, Ziyang Yan, Lei Li, Chenyu Zhang, Nicu Sebe, Hao Tang, Yan Wang, Hao Zhao, Mengzhu Wang, Jingcai Guo

Low-rank Adaptation (LoRA) has demonstrated remarkable capabilities for task
specific fine-tuning. However, in scenarios that involve multiple tasks,
training a separate LoRA model for each one results in considerable
inefficiency in terms of storage and inference. Moreover, existing parameter
generation methods fail to capture the correlations among these tasks, making
multi-task LoRA parameter generation challenging. To address these limitations,
we propose In-Context Meta LoRA (ICM-LoRA), a novel approach that efficiently
achieves task-specific customization of large language models (LLMs).
Specifically, we use training data from all tasks to train a tailored
generator, Conditional Variational Autoencoder (CVAE). CVAE takes task
descriptions as inputs and produces task-aware LoRA weights as outputs. These
LoRA weights are then merged with LLMs to create task-specialized models
without the need for additional fine-tuning. Furthermore, we utilize in-context
meta-learning for knowledge enhancement and task mapping, to capture the
relationship between tasks and parameter distributions. As a result, our method
achieves more accurate LoRA parameter generation for diverse tasks using CVAE.
ICM-LoRA enables more accurate LoRA parameter reconstruction than current
parameter reconstruction methods and is useful for implementing task-specific
enhancements of LoRA parameters. At the same time, our method occupies 283MB,
only 1\% storage compared with the original LoRA.

æè¦ï¼ä½ç§©é©æï¼LoRAï¼å·²å±ç¾åºéå°ç¹å®ä»»åé²è¡å¾®èª¿çåè¶è½åãç¶èï¼å¨æ¶åå¤é ä»»åçå ´æ¯ä¸­ï¼çºæ¯åä»»åè¨ç·´ä¸åç¨ç«ç LoRA æ¨¡åæå°è´å²å­åæ¨è«æ¹é¢çé¡¯èä½æçãæ­¤å¤ï¼ç¾æçåæ¸çææ¹æ³ç¡æ³ææéäºä»»åä¹éçéè¯æ§ï¼ä½¿å¾å¤ä»»å LoRA åæ¸çæå·æææ°æ§ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºæå¢å LoRAï¼ICM-LoRAï¼ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å¯ææå¯¦ç¾å¤§åèªè¨æ¨¡åï¼LLMï¼çç¹å®ä»»åèªè¨ãå·é«ä¾èªªï¼æåä½¿ç¨ä¾èªææä»»åçè¨ç·´è³æä¾è¨ç·´ä¸åéèº«æé ççæå¨ï¼æ¢ä»¶è®ç°èªåç·¨ç¢¼å¨ï¼CVAEï¼ãCVAE å°ä»»åæè¿°ä½çºè¼¸å¥ï¼ä¸¦ç¢çèä»»åç¸éç LoRA æ¬éä½çºè¼¸åºãç¶å¾å°éäº LoRA æ¬éè LLM åä½µï¼ä»¥å»ºç«ç¹å®æ¼ä»»åçæ¨¡åï¼èä¸éè¦é¡å¤çå¾®èª¿ãæ­¤å¤ï¼æåå©ç¨æå¢åå­¸ç¿ä¾å¢å¼·ç¥è­åä»»åå°æï¼ä»¥ææä»»åååæ¸åä½ä¹éçéä¿ãå æ­¤ï¼æåçæ¨¡åä½¿ç¨ CVAE éå°ä¸åçä»»åå¯¦ç¾æ´æºç¢ºç LoRA åæ¸çæãèç®åçåæ¸éå»ºæ¹æ³ç¸æ¯ï¼ICM-LoRA è½æ´æºç¢ºå°éå»º LoRA åæ¸ï¼ä¸¦ä¸æå©æ¼å¯¦ä½ LoRA åæ¸çç¹å®ä»»åå¢å¼·ãåæï¼æåçæ¨¡åä½ç¨ 283MBï¼èåå§ LoRA ç¸æ¯ï¼å²å­éåçº 1%ã

##### **The Imitation Game According To Turing**
2501.17629v1 by Sharon Temtsin, Diane Proudfoot, David Kaber, Christoph Bartneck

The current cycle of hype and anxiety concerning the benefits and risks to
human society of Artificial Intelligence is fuelled, not only by the increasing
use of generative AI and other AI tools by the general public, but also by
claims made on behalf of such technology by popularizers and scientists. In
particular, recent studies have claimed that Large Language Models (LLMs) can
pass the Turing Test-a goal for AI since the 1950s-and therefore can "think".
Large-scale impacts on society have been predicted as a result. Upon detailed
examination, however, none of these studies has faithfully applied Turing's
original instructions. Consequently, we conducted a rigorous Turing Test with
GPT-4-Turbo that adhered closely to Turing's instructions for a three-player
imitation game. We followed established scientific standards where Turing's
instructions were ambiguous or missing. For example, we performed a
Computer-Imitates-Human Game (CIHG) without constraining the time duration and
conducted a Man-Imitates-Woman Game (MIWG) as a benchmark. All but one
participant correctly identified the LLM, showing that one of today's most
advanced LLMs is unable to pass a rigorous Turing Test. We conclude that recent
extravagant claims for such models are unsupported, and do not warrant either
optimism or concern about the social impact of thinking machines.

æè¦ï¼ç¶åéæ¼äººå·¥æºæ§å°äººé¡ç¤¾æçå©å¼ççä½åç¦æ®å¾ªç°ï¼ä¸åæ¯ç±æ¼å¬ç¾å°çæå¼ AI åå¶ä» AI å·¥å·çä½¿ç¨æ¥çå¢å ï¼éç±æ¼æ¨å»£èåç§å­¸å®¶å°æ­¤é¡æè¡æåºçä¸»å¼µãç¹å¥æ¯ï¼æè¿çç ç©¶è²ç¨±å¤§åèªè¨æ¨¡å (LLM) å¯ä»¥ééåéæ¸¬è©¦ââèª 1950 å¹´ä»£ä»¥ä¾ AI çç®æ¨ââå æ­¤å¯ä»¥ãæèããé æ¸¬éå°å°ç¤¾æç¢çå¤§è¦æ¨¡å½±é¿ãç¶èï¼ç¶éä»ç´°æª¢æ¥ï¼éäºç ç©¶é½æ²æå¿ å¯¦å°æç¨åéçåå§èªªæãå æ­¤ï¼æåå° GPT-4-Turbo é²è¡äºä¸é å´æ ¼çåéæ¸¬è©¦ï¼å´æ ¼éµå®åéå°ä¸äººæ¨¡ä»¿éæ²çèªªæãå¨åéçèªªææ¨¡æ£±å©å¯æç¼ºå¤±çææ³ä¸ï¼æåéµå¾ªæ¢å®çç§å­¸æ¨æºãä¾å¦ï¼æåé²è¡äºä¸å ´è¨ç®æ©æ¨¡ä»¿äººé¡éæ² (CIHG)ï¼æ²æéå¶æéï¼ä¸¦é²è¡äºä¸å ´ç·äººæ¨¡ä»¿å¥³äººéæ² (MIWG) ä½çºåºæºãé¤äºåèèæ­£ç¢ºå°è­å¥äº LLM ä¹å¤ï¼ææåèèé½æ­£ç¢ºå°è­å¥äº LLMï¼éè¡¨æç¶ä»æåé²ç LLM ä¹ä¸ç¡æ³ééå´æ ¼çåéæ¸¬è©¦ãæåå¾åºçµè«ï¼æè¿å°æ­¤é¡æ¨¡åçèªå¼µèªªæ³å¾ä¸å°æ¯æï¼ä¹ä¸ä¿è­å°æèæ©å¨å°ç¤¾æå½±é¿çæ¨è§æææã

##### **Uncertainty Quantification and Decomposition for LLM-based Recommendation**
2501.17630v1 by Wonbin Kweon, Sanghwan Jang, SeongKu Kang, Hwanjo Yu

Despite the widespread adoption of large language models (LLMs) for
recommendation, we demonstrate that LLMs often exhibit uncertainty in their
recommendations. To ensure the trustworthy use of LLMs in generating
recommendations, we emphasize the importance of assessing the reliability of
recommendations generated by LLMs. We start by introducing a novel framework
for estimating the predictive uncertainty to quantitatively measure the
reliability of LLM-based recommendations. We further propose to decompose the
predictive uncertainty into recommendation uncertainty and prompt uncertainty,
enabling in-depth analyses of the primary source of uncertainty. Through
extensive experiments, we (1) demonstrate predictive uncertainty effectively
indicates the reliability of LLM-based recommendations, (2) investigate the
origins of uncertainty with decomposed uncertainty measures, and (3) propose
uncertainty-aware prompting for a lower predictive uncertainty and enhanced
recommendation. Our source code and model weights are available at
https://github.com/WonbinKweon/UNC_LLM_REC_WWW2025

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å·²å»£æ³ç¨æ¼æ¨è¦ï¼ä½æåè­æ LLM éå¸¸å¨å¶æ¨è¦ä¸­è¡¨ç¾åºä¸ç¢ºå®æ§ãçºäºç¢ºä¿å¨ç¢çæ¨è¦æå¯ä¿¡è³´å°ä½¿ç¨ LLMï¼æåå¼·èª¿è©ä¼° LLM ç¢ççæ¨è¦ä¹å¯é æ§çéè¦æ§ãæåé¦åä»ç´¹ä¸åæ°çæ¶æ§ï¼ç¨æ¼ä¼°è¨é æ¸¬ä¸ç¢ºå®æ§ï¼ä»¥éåè¡¡éåºæ¼ LLM çæ¨è¦ä¹å¯é æ§ãæåé²ä¸æ­¥æåºå°é æ¸¬ä¸ç¢ºå®æ§åè§£çºæ¨è¦ä¸ç¢ºå®æ§åæç¤ºä¸ç¢ºå®æ§ï¼å¾èæ·±å¥åæä¸ç¢ºå®æ§çä¸»è¦ä¾æºãééå»£æ³çå¯¦é©ï¼æå (1) è­æé æ¸¬ä¸ç¢ºå®æ§ææå°è¡¨ç¤ºåºæ¼ LLM çæ¨è¦ä¹å¯é æ§ï¼(2) èª¿æ¥å·æåè§£ä¸ç¢ºå®æ§æ¸¬éçä¾æºï¼ä»¥å (3) æåºå°ä¸ç¢ºå®æ§ææè­çæç¤ºï¼ä»¥éä½é æ¸¬ä¸ç¢ºå®æ§åå¢å¼·æ¨è¦ãæåçåå§ç¢¼åæ¨¡åæ¬éå¯å¨ https://github.com/WonbinKweon/UNC_LLM_REC_WWW2025 åå¾

##### **Structured Context Recomposition for Large Language Models Using Probabilistic Layer Realignment**
2501.17617v1 by Jonathan Teel, Jocasta Cumberbatch, Raphael Benington, Quentin Baskerville

Extended sequence generation often leads to degradation in contextual
consistency due to the inability of conventional self-attention mechanisms to
effectively retain long-range dependencies. Existing approaches, including
memory compression and retrieval-augmented conditioning, introduce
computational trade-offs that either increase inference latency or impose
additional storage overhead. Structured Context Recomposition (SCR) introduces
a probabilistic layer realignment strategy that dynamically adjusts learned
representations within transformer layers, ensuring that semantically relevant
embeddings persist throughout extended transformations. The proposed method
enhances coherence retention through a recursive weighting function that
redistributes representational emphasis based on inferred contextual relevance
rather than relying on fixed token-level attention scores. Empirical results
indicate that probabilistic realignment mitigates abrupt topic shifts and
logical inconsistencies, particularly in scenarios where sequences exceed
standard attention window constraints. Sequence-level entropy analysis further
reveals that SCR moderates representational variability without introducing
excessive output regularization, allowing models to sustain generative
diversity while preserving contextual alignment. Attention head deviation
measurements confirm that hierarchical reweighting contributes to smoother
token dependency transitions across transformer layers, reinforcing the
stability of multi-turn interactions and document-level reasoning.
Computational resource assessments show that while SCR incurs a moderate
increase in processing time, memory overhead remains within feasible limits,
making it suitable for practical deployment in autoregressive generative
applications.

æè¦ï¼é·åºåçæéå¸¸æå°è´èæ¯ä¸è´æ§éä½ï¼å çºå³çµ±çèªææ³¨ææ©å¶ç¡æ³ææä¿çé·è·é¢ä¾è³´éä¿ãç¾ææ¹æ³ï¼åæ¬è¨æ¶å£ç¸®åæª¢ç´¢å¢å¼·æ¢ä»¶ï¼æå¼å¥è¨ç®æ¬è¡¡ï¼éäºæ¬è¡¡æå¢å æ¨çå»¶é²æé æé¡å¤çå²å­ç©ºéè² æãçµæ§åèæ¯éçµ (SCR) å¼å¥æ©çå±¤éæ°å°é½ç­ç¥ï¼å®æåæèª¿æ´Transformerå±¤ä¸­çå­¸ç¿è¡¨å¾µï¼ç¢ºä¿èªç¾©ç¸éçåµå¥å¨æ´åå»¶ä¼¸è½æä¸­æçºå­å¨ãææåºçæ¹æ³éééè¿´å æ¬å½æ¸å¢å¼·ä¸è´æ§ä¿çï¼éåå½æ¸æ ¹ææ¨è«çèæ¯ç¸éæ§éæ°åéè¡¨å¾µéé»ï¼èä¸æ¯ä¾è³´åºå®çä»£ç¢¼ç´å¥æ³¨æååæ¸ãå¯¦è­çµæé¡¯ç¤ºï¼æ©çéæ°å°é½å¯æ¸ç·©çªç¶çä¸»é¡è½æåéè¼¯ä¸ä¸è´ï¼ç¹å¥æ¯å¨åºåè¶éæ¨æºæ³¨æåè¦çªéå¶çææ³ä¸ãåºåç´å¥çµåæé²ä¸æ­¥æ­ç¤ºï¼SCR å¯èª¿ç¯è¡¨å¾µè®ç°æ§ï¼èä¸æå¼å¥éåº¦çè¼¸åºæ­£è¦åï¼è®æ¨¡åå¨ç¶­æèæ¯å°é½çåæï¼æçºçæå¤æ¨£æ§ãæ³¨æåé ­é¨åå·®æ¸¬éç¢ºèªï¼éå±¤å¼éæ°å æ¬æå©æ¼Transformerå±¤ä¹éæ´é æ¢çä»£ç¢¼ä¾è³´éä¿è½æï¼å¼·åå¤ååäºååæä»¶ç´æ¨ççç©©å®æ§ãè¨ç®è³æºè©ä¼°é¡¯ç¤ºï¼åç®¡ SCR æé æèçæéé©åº¦å¢å ï¼ä½è¨æ¶é«è² æä»ç¶­æå¨å¯è¡ç¯åå§ï¼ä½¿å¶é©ç¨æ¼èªè¿´æ­¸çæå¼æç¨ç¨å¼çå¯¦éé¨ç½²ã

##### **Cross-lingual Embedding Clustering for Hierarchical Softmax in Low-Resource Multilingual Speech Recognition**
2501.17615v1 by Zhengdong Yang, Qianying Liu, Sheng Li, Fei Cheng, Chenhui Chu

We present a novel approach centered on the decoding stage of Automatic
Speech Recognition (ASR) that enhances multilingual performance, especially for
low-resource languages. It utilizes a cross-lingual embedding clustering method
to construct a hierarchical Softmax (H-Softmax) decoder, which enables similar
tokens across different languages to share similar decoder representations. It
addresses the limitations of the previous Huffman-based H-Softmax method, which
relied on shallow features in token similarity assessments. Through experiments
on a downsampled dataset of 15 languages, we demonstrate the effectiveness of
our approach in improving low-resource multilingual ASR accuracy.

æè¦ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼å°æ³¨æ¼èªåèªé³è­å¥ (ASR) çè§£ç¢¼éæ®µï¼å¯ä»¥å¢å¼·å¤èªè¨æè½ï¼ç¹å¥æ¯å°æ¼ä½è³æºèªè¨ãå®å©ç¨è·¨èªè¨åµå¥å¼ç¾¤éæ¹æ³ä¾å»ºæ§éå±¤å¼ Softmax (H-Softmax) è§£ç¢¼å¨ï¼éä½¿å¾ä¸åèªè¨ä¸­çç¸ä¼¼ç¬¦èå¯ä»¥å±ç¨ç¸ä¼¼çè§£ç¢¼å¨è¡¨ç¤ºãå®è§£æ±ºäºåååºæ¼ Huffman ç H-Softmax æ¹æ³çéå¶ï¼è©²æ¹æ³ä¾è³´æ¼ç¬¦èç¸ä¼¼æ§è©ä¼°ä¸­çæ·ºå±¤ç¹å¾µãééå° 15 ç¨®èªè¨çéæ¡æ¨£è³æéé²è¡å¯¦é©ï¼æåè­æäºæåçæ¹æ³å¨æåä½è³æºå¤èªè¨ ASR æºç¢ºåº¦æ¹é¢çæææ§ã

##### **VoicePrompter: Robust Zero-Shot Voice Conversion with Voice Prompt and Conditional Flow Matching**
2501.17612v1 by Ha-Yeong Choi, Jaehan Park

Despite remarkable advancements in recent voice conversion (VC) systems,
enhancing speaker similarity in zero-shot scenarios remains challenging. This
challenge arises from the difficulty of generalizing and adapting speaker
characteristics in speech within zero-shot environments, which is further
complicated by mismatch between the training and inference processes. To
address these challenges, we propose VoicePrompter, a robust zero-shot VC model
that leverages in-context learning with voice prompts. VoicePrompter is
composed of (1) a factorization method that disentangles speech components and
(2) a DiT-based conditional flow matching (CFM) decoder that conditions on
these factorized features and voice prompts. Additionally, (3) latent mixup is
used to enhance in-context learning by combining various speaker features. This
approach improves speaker similarity and naturalness in zero-shot VC by
applying mixup to latent representations. Experimental results demonstrate that
VoicePrompter outperforms existing zero-shot VC systems in terms of speaker
similarity, speech intelligibility, and audio quality. Our demo is available at
\url{https://hayeong0.github.io/VoicePrompter-demo/}.

æè¦ï¼åç®¡æè¿çèªé³è½æ (VC) ç³»çµ±æé¡¯èçé²å±ï¼ä½å¨é¶æ¬¡å­¸ç¿å ´æ¯ä¸­å¢å¼·èªªè©±èç¸ä¼¼æ§ä»ç¶å·æææ°æ§ãéåææ°ä¾èªæ¼å¨é¶æ¬¡å­¸ç¿ç°å¢ä¸­æ¦ååé©æèªé³ä¸­èªªè©±èç¹å¾µçé£åº¦ï¼èè¨ç·´åæ¨è«éç¨ä¹éçä¸å¹éé²ä¸æ­¥è¤éåäºéåææ°ãçºäºæå°éäºææ°ï¼æåæåºäº VoicePrompterï¼éæ¯ä¸åå¼·å¤§çé¶æ¬¡å­¸ç¿ VC æ¨¡åï¼å®å©ç¨èªé³æç¤ºé²è¡æå¢å­¸ç¿ãVoicePrompter ç± (1) ä¸ååè§£èªé³çµæçåè§£æ¹æ³å (2) ä¸ååºæ¼ DiT çæ¢ä»¶æµå¹é (CFM) è§£ç¢¼å¨çµæï¼å®ä»¥éäºåè§£çç¹å¾µåèªé³æç¤ºçºæ¢ä»¶ãæ­¤å¤ï¼(3) æ½å¨æ··æ·ç¨æ¼ééçµååç¨®èªªè©±èç¹å¾µä¾å¢å¼·æå¢å­¸ç¿ãéç¨®æ¹æ³ééå°æ··æ·æç¨æ¼æ½å¨è¡¨å¾µä¾æ¹åé¶æ¬¡å­¸ç¿ VC ä¸­çèªªè©±èç¸ä¼¼æ§åèªç¶æ§ãå¯¦é©çµæè¡¨æï¼VoicePrompter å¨èªªè©±èç¸ä¼¼æ§ãèªé³æ¸æ°åº¦åé³è¨åè³ªæ¹é¢åªæ¼ç¾æçé¶æ¬¡å­¸ç¿ VC ç³»çµ±ãæåçç¤ºç¯å¯ä»¥å¨ \url{https://hayeong0.github.io/VoicePrompter-demo/} ä¸­åå¾ã

##### **Semantic Consistency Regularization with Large Language Models for Semi-supervised Sentiment Analysis**
2501.17598v1 by Kunrong Li, Xinyu Liu, Zhen Chen

Accurate sentiment analysis of texts is crucial for a variety of
applications, such as understanding customer feedback, monitoring market
trends, and detecting public sentiment. However, manually annotating large
sentiment corpora for supervised learning is labor-intensive and
time-consuming. Therefore, it is essential and effective to develop a
semi-supervised method for the sentiment analysis task. Although some methods
have been proposed for semi-supervised text classification, they rely on the
intrinsic information within the unlabeled data and the learning capability of
the NLP model, which lack generalization ability to the sentiment analysis
scenario and may prone to overfit. Inspired by the ability of pretrained Large
Language Models (LLMs) in following instructions and generating coherent text,
we propose a Semantic Consistency Regularization with Large Language Models
(SCR) framework for semi-supervised sentiment analysis. We introduce two
prompting strategies to semantically enhance unlabeled text using LLMs. The
first is Entity-based Enhancement (SCR-EE), which involves extracting entities
and numerical information, and querying the LLM to reconstruct the textual
information. The second is Concept-based Enhancement (SCR-CE), which directly
queries the LLM with the original sentence for semantic reconstruction.
Subsequently, the LLM-augmented data is utilized for a consistency loss with
confidence thresholding, which preserves high-quality agreement samples to
provide additional supervision signals during training. Furthermore, to fully
utilize the uncertain unlabeled data samples, we propose a class re-assembling
strategy inspired by the class space shrinking theorem. Experiments show our
method achieves remarkable performance over prior semi-supervised methods.

æè¦ï¼æºç¢ºçææåæå°æ¼åç¨®æç¨ç¨å¼è³ééè¦ï¼ä¾å¦äºè§£å®¢æ¶åé¥ãç£æ§å¸å ´è¶¨å¢ååµæ¸¬å¬ç¾æç·ãç¶èï¼æåè¨»è§£å¤§åææèªæåº«ä»¥é²è¡ç£ç£å¼å­¸ç¿æ¢è²»ååè²»æãå æ­¤ï¼éç¼ä¸ç¨®åç£ç£å¼çææåæä»»åæ¹æ³è³ééè¦ä¸ææãåç®¡å·²ç¶æåºäºä¸äºåç£ç£å¼ææ¬åé¡æ¹æ³ï¼ä½å®åä¾è³´æ¼æªæ¨è¨è³æä¸­çå§å¨è³è¨å NLP æ¨¡åçå­¸ç¿è½åï¼éç¼ºä¹å°ææåææå¢çæ¦æ¬è½åï¼ä¸¦ä¸å¯è½å®¹æéåº¦æ¬åãåå°é è¨ç·´å¤§åèªè¨æ¨¡å (LLM) å¨éµå¾ªèªªæåçæé£è²«ææ¬æ¹é¢çè½åçåç¼ï¼æåæåºäºä¸åå·æå¤§åèªè¨æ¨¡å (SCR) çèªç¾©ä¸è´æ§æ­£ååæ¡æ¶ï¼ç¨æ¼åç£ç£å¼ææåæãæåå¼å¥äºå©ç¨®æç¤ºç­ç¥ï¼ä»¥ä½¿ç¨ LLM èªç¾©å¢å¼·æªæ¨è¨ææ¬ãç¬¬ä¸åæ¯åºæ¼å¯¦é«çå¢å¼· (SCR-EE)ï¼å®æ¶åæåå¯¦é«åæ¸å­è³è¨ï¼ä¸¦æ¥è©¢ LLM ä»¥éå»ºææ¬è³è¨ãç¬¬äºåæ¯åºæ¼æ¦å¿µçå¢å¼· (SCR-CE)ï¼å®ç´æ¥æ¥è©¢å·æèªç¾©éå»ºåè½çåå§å¥å­ç LLMãé¨å¾ï¼å° LLM æ´åçè³æç¨æ¼å·æä¿¡å¿é¾å¼çç¨ å¯æå¤±ï¼éä¿çäºé«åè³ªçä¸è´æ§æ¨£æ¬ï¼ä»¥ä¾¿å¨è¨ç·´æéæä¾é¡å¤çç£ç£è¨èãæ­¤å¤ï¼çºäºååå©ç¨ä¸ç¢ºå®çæªæ¨è¨è³ææ¨£æ¬ï¼æåæåºäºä¸åé¡å¥éæ°çµè£ç­ç¥ï¼å¶éæä¾èªé¡å¥ç©ºéç¸®æ¸å®çãå¯¦é©è¡¨æï¼æåçæ¨¡åæ¯ååçåç£ç£å¼æ¹æ³åå¾äºé¡¯èçæè½ã

##### **GLLM: Self-Corrective G-Code Generation using Large Language Models with User Feedback**
2501.17584v1 by Mohamed Abdelaal, Samuel Lokadjaja, Gilbert Engert

This paper introduces GLLM, an innovative tool that leverages Large Language
Models (LLMs) to automatically generate G-code from natural language
instructions for Computer Numerical Control (CNC) machining. GLLM addresses the
challenges of manual G-code writing by bridging the gap between human-readable
task descriptions and machine-executable code. The system incorporates a
fine-tuned StarCoder-3B model, enhanced with domain-specific training data and
a Retrieval-Augmented Generation (RAG) mechanism. GLLM employs advanced
prompting strategies and a novel self-corrective code generation approach to
ensure both syntactic and semantic correctness of the generated G-code. The
architecture includes robust validation mechanisms, including syntax checks,
G-code-specific verifications, and functional correctness evaluations using
Hausdorff distance. By combining these techniques, GLLM aims to democratize CNC
programming, making it more accessible to users without extensive programming
experience while maintaining high accuracy and reliability in G-code
generation.

æè¦ï¼éç¯è«æä»ç´¹ GLLMï¼éæ¯ä¸ååµæ°çå·¥å·ï¼å®å©ç¨å¤§åèªè¨æ¨¡å (LLM) å¾èªç¶èªè¨æä»¤èªåç¢ç G ç¨å¼ç¢¼ï¼ç¨æ¼é»è¦æ¸å¼æ§å¶ (CNC) å å·¥ãGLLM ééæ©æ¥äººé¡å¯è®çå·¥ä½æè¿°åæ©å¨å¯å·è¡çç¨å¼ç¢¼ï¼è§£æ±ºäºæåæ°å¯« G ç¨å¼ç¢¼çææ°ãæ­¤ç³»çµ±çµåäºç¶éå¾®èª¿ç StarCoder-3B æ¨¡åï¼ä¸¦ééç¹å®é åçè¨ç·´è³æåæª¢ç´¢æ´åç¢ç (RAG) æ©å¶å ä»¥å¼·åãGLLM æ¡ç¨é²éçæç¤ºç­ç¥åæ°ç©çèªè¨æ­£ç¨å¼ç¢¼ç¢çæ¹æ³ï¼ä»¥ç¢ºä¿ç¢çç G ç¨å¼ç¢¼å¨èªæ³åèªç¾©ä¸çæ­£ç¢ºç¡èª¤ãæ­¤æ¶æ§åå«å¼·å¥çé©è­æ©å¶ï¼åæ¬èªæ³æª¢æ¥ãç¹å®æ¼ G ç¨å¼ç¢¼çé©è­ï¼ä»¥åä½¿ç¨ Hausdorff è·é¢é²è¡çåè½æ­£ç¢ºæ§è©ä¼°ãééçµåéäºæè¡ï¼GLLM æ¨å¨è® CNC ç·¨ç¨æ°ä¸»åï¼è®æ²æè±å¯ç¨å¼è¨­è¨ç¶é©çä½¿ç¨èä¹è½æ´è¼é¬ä¸æï¼åæå¨ G ç¨å¼ç¢¼ç¢çéç¨ä¸­ç¶­æé«æºç¢ºåº¦åå¯é åº¦ã

##### **CSEval: Towards Automated, Multi-Dimensional, and Reference-Free Counterspeech Evaluation using Auto-Calibrated LLMs**
2501.17581v1 by Amey Hengle, Aswini Kumar, Anil Bandhakavi, Tanmoy Chakraborty

Counterspeech has been popular as an effective approach to counter online
hate speech, leading to increasing research interest in automated counterspeech
generation using language models. However, this field lacks standardised
evaluation protocols and robust automated evaluation metrics that align with
human judgement. Current automatic evaluation methods, primarily based on
similarity metrics, do not effectively capture the complex and independent
attributes of counterspeech quality, such as contextual relevance,
aggressiveness, or argumentative coherence. This has led to an increased
dependency on labor-intensive human evaluations to assess automated
counter-speech generation methods. To address these challenges, we introduce
CSEval, a novel dataset and framework for evaluating counterspeech quality
across four dimensions: contextual-relevance, aggressiveness,
argument-coherence, and suitableness. Furthermore, we propose Auto-Calibrated
COT for Counterspeech Evaluation (ACE), a prompt-based method with
auto-calibrated chain-of-thoughts (CoT) for scoring counterspeech using large
language models. Our experiments show that ACE outperforms traditional metrics
like ROUGE, METEOR, and BertScore in correlating with human judgement,
indicating a significant advancement in automated counterspeech evaluation.

æè¦ï¼åè«è¨è«ä¸ç´è¢«è¦çºå°æç¶²è·¯ä»æ¨è¨è«çæææ¹æ³ï¼å°è´äººåå°ä½¿ç¨èªè¨æ¨¡åé²è¡èªååè«è¨è«ç¢ççç ç©¶èè¶£æ¥çå¢å ãç¶èï¼éåé åç¼ºä¹æ¨æºåçè©ä¼°åå®åèäººé¡å¤æ·ä¸è´çç©©å¥èªåè©ä¼°ææ¨ãç®åçèªåè©ä¼°æ¹æ³ä¸»è¦åºæ¼ç¸ä¼¼æ§ææ¨ï¼ç¡æ³ææææåè«è¨è«åè³ªçè¤éä¸ç¨ç«å±¬æ§ï¼ä¾å¦ä¸ä¸æç¸éæ§ãæ»ææ§æè«è­ä¸è´æ§ãéå°è´å°ååå¯éåäººé¡è©ä¼°çä¾è³´æ§å¢å ï¼ä»¥è©ä¼°èªååè«è¨è«ç¢çæ¹æ³ãçºäºæå°éäºææ°ï¼æåå¼å¥äº CSEvalï¼éæ¯ä¸åæ°çè³æéåæ¡æ¶ï¼ç¨æ¼è©ä¼°åè«è¨è«åè³ªçååé¢åï¼ä¸ä¸æç¸éæ§ãæ»ææ§ãè«è­ä¸è´æ§åé©å®æ§ãæ­¤å¤ï¼æåæåºäºç¨æ¼åè«è¨è«è©ä¼°çèªåæ ¡æº COTï¼ACEï¼ï¼éæ¯ä¸ç¨®åºæ¼æç¤ºçæ¹æ³ï¼å·æèªåæ ¡æºçæèéï¼CoTï¼ï¼ç¨æ¼ä½¿ç¨å¤§åèªè¨æ¨¡åå°åè«è¨è«é²è¡è©åãæåçå¯¦é©è¡¨æï¼ACE å¨èäººé¡å¤æ·ç¸éæ¹é¢åªæ¼å³çµ±ææ¨ï¼ä¾å¦ ROUGEãMETEOR å BertScoreï¼éè¡¨ç¤ºèªååè«è¨è«è©ä¼°æäºé¡¯èé²å±ã

##### **Music2Latent2: Audio Compression with Summary Embeddings and Autoregressive Decoding**
2501.17578v1 by Marco Pasini, Stefan Lattner, George Fazekas

Efficiently compressing high-dimensional audio signals into a compact and
informative latent space is crucial for various tasks, including generative
modeling and music information retrieval (MIR). Existing audio autoencoders,
however, often struggle to achieve high compression ratios while preserving
audio fidelity and facilitating efficient downstream applications. We introduce
Music2Latent2, a novel audio autoencoder that addresses these limitations by
leveraging consistency models and a novel approach to representation learning
based on unordered latent embeddings, which we call summary embeddings. Unlike
conventional methods that encode local audio features into ordered sequences,
Music2Latent2 compresses audio signals into sets of summary embeddings, where
each embedding can capture distinct global features of the input sample. This
enables to achieve higher reconstruction quality at the same compression ratio.
To handle arbitrary audio lengths, Music2Latent2 employs an autoregressive
consistency model trained on two consecutive audio chunks with causal masking,
ensuring coherent reconstruction across segment boundaries. Additionally, we
propose a novel two-step decoding procedure that leverages the denoising
capabilities of consistency models to further refine the generated audio at no
additional cost. Our experiments demonstrate that Music2Latent2 outperforms
existing continuous audio autoencoders regarding audio quality and performance
on downstream tasks. Music2Latent2 paves the way for new possibilities in audio
compression.

æè¦ï¼ææå°å°é«ç¶­åº¦é³è¨è¨èå£ç¸®æç·æ¹ä¸å·è³è¨æ§çæ½å¨ç©ºéå°æ¼åç¨®ä»»åè³ééè¦ï¼åæ¬çæå¼æ¨¡ååé³æ¨è³è¨æª¢ç´¢ (MIR)ãç¶èï¼ç¾æçé³è¨èªåç·¨ç¢¼å¨å¨ä¿æé³è¨ä¿çåº¦åä¿é²ææçä¸æ¸¸æç¨æï¼éå¸¸é£ä»¥å¯¦ç¾é«å£ç¸®çãæåä»ç´¹ Music2Latent2ï¼éæ¯ä¸åæ°ç©çé³è¨èªåç·¨ç¢¼å¨ï¼å®ééå©ç¨ä¸è´æ§æ¨¡ååä¸ç¨®åºæ¼ç¡åºæ½å¨åµå¥çè¡¨å¾µå­¸ç¿æ°æ¹æ³ä¾è§£æ±ºéäºéå¶ï¼æåç¨±ä¹çºæè¦åµå¥ãèå°å±é¨é³è¨ç¹å¾µç·¨ç¢¼ææåºåºåçå³çµ±æ¹æ³ä¸åï¼Music2Latent2 å°é³è¨è¨èå£ç¸®ææè¦åµå¥éåï¼å¶ä¸­æ¯ååµå¥é½å¯ä»¥æ·åè¼¸å¥æ¨£æ¬çä¸åå¨å±ç¹å¾µãéè½å¤ å¨ç¸åçå£ç¸®çä¸å¯¦ç¾æ´é«çéå»ºåè³ªãçºäºèçä»»æçé³è¨é·åº¦ï¼Music2Latent2 ä½¿ç¨èªè¿´æ­¸ä¸è´æ§æ¨¡åï¼è©²æ¨¡åå¨å©åé£çºçé³è¨åå¡ä¸è¨ç·´ï¼ä¸¦ä½¿ç¨å æé®ç½©ï¼ç¢ºä¿è·¨åæ®µéççé£è²«éå»ºãæ­¤å¤ï¼æåæåºäºä¸ç¨®æ°ç©çå©æ­¥è§£ç¢¼ç¨åºï¼å®å©ç¨äºä¸è´æ§æ¨¡åçå»åªè½åï¼ä»¥é²ä¸æ­¥æ¹åçæçé³è¨ï¼èç¡éé¡å¤ææ¬ãæåçå¯¦é©è¡¨æï¼Music2Latent2 å¨é³è¨åè³ªåä¸æ¸¸ä»»åçæè½æ¹é¢åªæ¼ç¾æçé£çºé³è¨èªåç·¨ç¢¼å¨ãMusic2Latent2 çºé³è¨å£ç¸®çæ°å¯è½æ§éªå¹³äºéè·¯ã

##### **A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks**
2501.17569v1 by Elie Antoine, FrÃ©dÃ©ric BÃ©chet, GÃ©raldine Damnati, Philippe Langlais

We introduce an evaluation methodology for reading comprehension tasks based
on the intuition that certain examples, by the virtue of their linguistic
complexity, consistently yield lower scores regardless of model size or
architecture. We capitalize on semantic frame annotation for characterizing
this complexity, and study seven complexity factors that may account for
model's difficulty. We first deploy this methodology on a carefully annotated
French reading comprehension benchmark showing that two of those complexity
factors are indeed good predictors of models' failure, while others are less
so. We further deploy our methodology on a well studied English benchmark by
using Chat-GPT as a proxy for semantic annotation. Our study reveals that
fine-grained linguisticallymotivated automatic evaluation of a reading
comprehension task is not only possible, but helps understand models' abilities
to handle specific linguistic characteristics of input examples. It also shows
that current state-of-the-art models fail with some for those characteristics
which suggests that adequately handling them requires more than merely
increasing model size.

æè¦ï¼æååºæ¼ä»¥ä¸ç´è¦ºï¼æåºä¸åç¨æ¼é±è®çè§£ä»»åçè©ä¼°æ¹æ³ï¼æäºç¯ä¾ç±æ¼å¶èªè¨è¤éæ§ï¼å§çµæç¢çè¼ä½çåæ¸ï¼èèæ¨¡åå¤§å°ææ¶æ§ç¡éãæåå©ç¨èªç¾©æ¡æ¶æ¨è¨»ä¾è¡¨å¾µéç¨®è¤éæ§ï¼ä¸¦ç ç©¶å¯è½å°è´æ¨¡åå°é£çä¸åè¤éæ§å ç´ ãæåé¦åå¨ä¸åç¶éä»ç´°æ¨è¨»çæ³æé±è®çè§£åºæºä¸é¨ç½²æ­¤æ¹æ³ï¼é¡¯ç¤ºå¶ä¸­å©åè¤éæ§å ç´ ç¢ºå¯¦æ¯æ¨¡åå¤±æçè¯å¥½é æ¸¬ææ¨ï¼èå¶ä»å ç´ åä¸ç¶ãæåé²ä¸æ­¥å¨ä¸åç¶éæ·±å¥ç ç©¶çè±æåºæºä¸é¨ç½²æåçè©ä¼°æ¹æ³ï¼ä½¿ç¨ Chat-GPT ä½çºèªç¾©æ¨è¨»çä»£çãæåçç ç©¶è¡¨æï¼å°é±è®çè§£ä»»åé²è¡ç´°ç·»çèªè¨æ¿åµèªåè©ä¼°ä¸åæ¯å¯è½çï¼èä¸æå©æ¼äºè§£æ¨¡åèçè¼¸å¥ç¯ä¾çç¹å®èªè¨ç¹å¾µçè½åãå®éé¡¯ç¤ºï¼ç¶åæåé²çæ¨¡åå¨æäºç¹å¾µä¸æå¤±æï¼éè¡¨æé©ç¶å°èçå®åéè¦çä¸ååæ¯å¢å æ¨¡åå¤§å°ã

##### **Exploring the Potential of Wireless-enabled Multi-Chip AI Accelerators**
2501.17567v1 by Emmanuel Irabor, Mariam Musavi, Abhijit Das, Sergi Abadal

The insatiable appetite of Artificial Intelligence (AI) workloads for
computing power is pushing the industry to develop faster and more efficient
accelerators. The rigidity of custom hardware, however, conflicts with the need
for scalable and versatile architectures capable of catering to the needs of
the evolving and heterogeneous pool of Machine Learning (ML) models in the
literature. In this context, multi-chiplet architectures assembling multiple
(perhaps heterogeneous) accelerators are an appealing option that is
unfortunately hindered by the still rigid and inefficient chip-to-chip
interconnects. In this paper, we explore the potential of wireless technology
as a complement to existing wired interconnects in this multi-chiplet approach.
Using an evaluation framework from the state-of-the-art, we show that wireless
interconnects can lead to speedups of 10% on average and 20% maximum. We also
highlight the importance of load balancing between the wired and wireless
interconnects, which will be further explored in future work.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·¥ä½è² è¼å°éç®è½åçè²ªå©ªèå£æ­£æ¨åç¢æ¥­éç¼æ´å¿«éä¸æ´ææççå éå¨ãç¶èï¼å®¢è£½åç¡¬é«çåµåæ§èå¯æ´åä¸å¤åè½æ¶æ§çéæ±ç¢çè¡çªï¼èéäºæ¶æ§æè½åæ»¿è¶³æç»ä¸­ä¸æ·æ¼é²ä¸ç°è³ªçæ©å¨å­¸ç¿ï¼MLï¼æ¨¡åçéæ±ãå¨æ­¤èçµ¡ä¸ï¼çµè£å¤åï¼å¯è½æ¯ç°è³ªçï¼å éå¨çå¤æ¶çæ¶æ§æ¯ä¸åèªäººçé¸æï¼ä½ä¸å¹¸çæ¯ï¼åå°ä»ç¶åµåä¸ä½æççæ¶çéäºé£é»ç¤ãå¨æ¬æä¸­ï¼æåæ¢è¨ç¡ç·æè¡ä½çºæ­¤å¤æ¶çæ¹æ³ä¸­ç¾ææç·äºé£çè£åçæ½åãä½¿ç¨ä¾èªææ°æè¡çè©ä¼°æ¶æ§ï¼æåé¡¯ç¤ºç¡ç·äºé£å¹³åå¯æå 10% çéåº¦ï¼æé«å¯æå 20%ãæåä¹å¼·èª¿æç·åç¡ç·äºé£ä¹éè² è¼å¹³è¡¡çéè¦æ§ï¼éå°å¨æªä¾çç ç©¶ä¸­é²ä¸æ­¥æ¢è¨ã

##### **Solving Urban Network Security Games: Learning Platform, Benchmark, and Challenge for AI Research**
2501.17559v1 by Shuxin Zhuang, Shuxin Li, Tianji Yang, Muheng Li, Xianjie Shi, Bo An, Youzhi Zhang

After the great achievement of solving two-player zero-sum games, more and
more AI researchers focus on solving multiplayer games. To facilitate the
development of designing efficient learning algorithms for solving multiplayer
games, we propose a multiplayer game platform for solving Urban Network
Security Games (\textbf{UNSG}) that model real-world scenarios. That is,
preventing criminal activity is a highly significant responsibility assigned to
police officers in cities, and police officers have to allocate their limited
security resources to interdict the escaping criminal when a crime takes place
in a city. This interaction between multiple police officers and the escaping
criminal can be modeled as a UNSG. The variants of UNSGs can model different
real-world settings, e.g., whether real-time information is available or not,
and whether police officers can communicate or not. The main challenges of
solving this game include the large size of the game and the co-existence of
cooperation and competition. While previous efforts have been made to tackle
UNSGs, they have been hampered by performance and scalability issues.
Therefore, we propose an open-source UNSG platform (\textbf{GraphChase}) for
designing efficient learning algorithms for solving UNSGs. Specifically,
GraphChase offers a unified and flexible game environment for modeling various
variants of UNSGs, supporting the development, testing, and benchmarking of
algorithms. We believe that GraphChase not only facilitates the development of
efficient algorithms for solving real-world problems but also paves the way for
significant advancements in algorithmic development for solving general
multiplayer games.

æè¦ï¼<paragraph>å¨è§£æ±ºå©äººé¶ååå¼ç²å¾éå¤§æå°±å¾ï¼è¶ä¾è¶å¤ç AI ç ç©¶äººå¡å°æ³¨æ¼è§£æ±ºå¤äººåå¼ãçºäºä¿é²è¨­è¨ç¨æ¼è§£æ±ºå¤äººåå¼çææå­¸ç¿æ¼ç®æ³çéç¼ï¼æåæåºä¸åå¤äººåå¼å¹³å°ï¼ç¨æ¼è§£æ±ºæ¨¡æ¬çå¯¦ä¸çå ´æ¯çåå¸ç¶²è·¯å®å¨åå¼ (UNSG)ãä¹å°±æ¯èªªï¼é²æ­¢ç¯ç½ªæ´»åæ¯åéçµ¦åå¸ä¸­è­¦å¯äººå¡çä¸é æ¥µå¶éè¦çè²¬ä»»ï¼èè­¦å¯äººå¡å¿é å¨åå¸ä¸­ç¼çç¯ç½ªæåéå¶æéçå®å¨è³æºä¾é»æ­¢éé¸çç½ªç¯ãè­¦å¯äººå¡åéé¸ç½ªç¯ä¹éçéç¨®äºåå¯ä»¥å»ºæ¨¡çº UNSGãUNSG çè®é«å¯ä»¥æ¨¡æ¬ä¸åççå¯¦ä¸çè¨­å®ï¼ä¾å¦ï¼æ¯å¦å¯ä»¥ä½¿ç¨å³æè³è¨ï¼ä»¥åè­¦å¯äººå¡æ¯å¦å¯ä»¥æºéãè§£æ±ºæ­¤åå¼çä¸»è¦ææ°åæ¬åå¼è¦æ¨¡é¾å¤§ï¼ä»¥ååä½èç«¶ç­ä¸¦å­ãåç®¡ä¹åå·²ååºåªåä¾è§£æ±º UNSGï¼ä½å®ååå°æè½åå¯æ´åæ§çåé¡æé»ç¤ãå æ­¤ï¼æåæåºä¸åéæº UNSG å¹³å° (GraphChase)ï¼ç¨æ¼è¨­è¨ç¨æ¼è§£æ±º UNSG çææå­¸ç¿æ¼ç®æ³ãå·é«ä¾èªªï¼GraphChase æä¾ä¸åçµ±ä¸ä¸éæ´»çåå¼ç°å¢ï¼ç¨æ¼æ¨¡æ¬ UNSG çåç¨®è®é«ï¼æ¯æ´æ¼ç®æ³çéç¼ãæ¸¬è©¦ååºæºæ¸¬è©¦ãæåç¸ä¿¡ GraphChase ä¸åä¿é²éç¼ç¨æ¼è§£æ±ºçå¯¦ä¸çåé¡çæææ¼ç®æ³ï¼ä¹çºè§£æ±ºä¸è¬å¤äººåå¼çæ¼ç®æ³éç¼éªå¹³äºéè·¯ã</paragraph>

##### **An Exceptional Dataset For Rare Pancreatic Tumor Segmentation**
2501.17555v1 by Wenqi Li, Yingli Chen, Keyang Zhou, Xiaoxiao Hu, Zilu Zheng, Yue Yan, Xinpeng Zhang, Wei Tang, Zhenxing Qian

Pancreatic NEuroendocrine Tumors (pNETs) are very rare endocrine neoplasms
that account for less than 5% of all pancreatic malignancies, with an incidence
of only 1-1.5 cases per 100,000. Early detection of pNETs is critical for
improving patient survival, but the rarity of pNETs makes segmenting them from
CT a very challenging problem. So far, there has not been a dataset
specifically for pNETs available to researchers. To address this issue, we
propose a pNETs dataset, a well-annotated Contrast-Enhanced Computed Tomography
(CECT) dataset focused exclusively on Pancreatic Neuroendocrine Tumors,
containing data from 469 patients. This is the first dataset solely dedicated
to pNETs, distinguishing it from previous collections. Additionally, we provide
the baseline detection networks with a new slice-wise weight loss function
designed for the UNet-based model, improving the overall pNET segmentation
performance. We hope that our dataset can enhance the understanding and
diagnosis of pNET Tumors within the medical community, facilitate the
development of more accurate diagnostic tools, and ultimately improve patient
outcomes and advance the field of oncology.

æè¦ï¼è°èç¥ç¶å§åæ³è«ç¤ (pNETs) æ¯éå¸¸ç½è¦çå§åæ³è«ç¤ï¼åä½ææè°èæ¡æ§è«ç¤çä¸å° 5%ï¼æ¯ 100,000 äººä¸­åç¼ç 1-1.5 åçä¾ãæ©æç¼ç¾ pNETs å°æ¹åæ£èå­æ´»çè³ééè¦ï¼ä½ pNETs çç½è¦æ§ä½¿å¾å¾ CT ä¸­åå²å®åæçºä¸åéå¸¸å·æææ°æ§çåé¡ãå°ç®åçºæ­¢ï¼éæ²æå°ééå° pNETs çæ¸æéå¯ä¾ç ç©¶äººå¡ä½¿ç¨ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸å pNETs æ¸æéï¼ä¸åå°æ³¨æ¼è°èç¥ç¶å§åæ³è«ç¤çæ¨è¨»è¯å¥½çå°æ¯å¢å¼·é»è¦æ·å±¤ææ (CECT) æ¸æéï¼åå«ä¾èª 469 åæ£èçæ¸æãéæ¯ç¬¬ä¸åå°ééå° pNETs çæ¸æéï¼éä½¿å¶æå¥æ¼ä¹åçæ¶éãæ­¤å¤ï¼æåçºåºç·æª¢æ¸¬ç¶²è·¯æä¾äºä¸åæ°çåºæ¼ UNet æ¨¡åè¨­è¨çåçå æ¬æå¤±å½æ¸ï¼æ¹åäºæ´é« pNET åå²æ§è½ãæåå¸ææåçæ¸æéè½å¤ å¢å¼·é«å­¸çå° pNET è«ç¤ççè§£åè¨ºæ·ï¼ä¿é²æ´æºç¢ºçè¨ºæ·å·¥å·çéç¼ï¼æçµæ¹åæ£èçé å¾ä¸¦æ¨é²è«ç¤å­¸é åã

##### **Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models**
2501.17549v1 by Wooyoung Kim, Byungyoon Park, Wooju Kim

Graph-structured data plays a vital role in numerous domains, such as social
networks, citation networks, commonsense reasoning graphs and knowledge graphs.
While graph neural networks have been employed for graph processing, recent
advancements have explored integrating large language models for graph-based
tasks. In this paper, we propose a novel approach named Learnable Graph Pooling
Token (LGPT), which addresses the limitations of the scalability issues in
node-level projection and information loss in graph-level projection. LGPT
enables flexible and efficient graph representation by introducing learnable
parameters that act as tokens in large language models, balancing fine-grained
and global graph information. Additionally, we investigate an Early Query
Fusion technique, which fuses query context before constructing the graph
representation, leading to more effective graph embeddings. Our method achieves
a 4.13\% performance improvement on the GraphQA benchmark without training the
large language model, demonstrating significant gains in handling complex
textual-attributed graph data.

æè¦ï¼åå½¢çµæ§è³æå¨è¨±å¤é åä¸­æ®æ¼èè³ééè¦çè§è²ï¼ä¾å¦ç¤¾äº¤ç¶²è·¯ãå¼ç¨ç¶²è·¯ãå¸¸è­æ¨çåå½¢åç¥è­åå½¢ãéç¶åå½¢ç¥ç¶ç¶²è·¯å·²ç¨æ¼åå½¢èçï¼ä½æè¿çé²å±å·²æ¢è¨æ´åå¤§åèªè¨æ¨¡åä»¥é²è¡åºæ¼åå½¢çä»»åãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åçºå¯å­¸ç¿åå½¢æ± åä»¤ç (LGPT) çæ°æ¹æ³ï¼å®è§£æ±ºäºç¯é»å±¤ç´æå½±ä¸­çå¯æ´åæ§åé¡ååå½¢å±¤ç´æå½±ä¸­çè³è¨éºå¤±éå¶ãLGPT ééå¼å¥å¯å­¸ç¿çåæ¸ï¼å¨å¤§åèªè¨æ¨¡åä¸­ä½çºä»¤çéä½ï¼ä¾åç¨å½æ§åé«æçåå½¢è¡¨ç¤ºï¼å¹³è¡¡ç´°ç²åº¦åæ´é«åå½¢è³è¨ãæ­¤å¤ï¼æåç ç©¶äºä¸ç¨®æ©ææ¥è©¢èåæè¡ï¼å®å¨å»ºæ§åå½¢è¡¨ç¤ºä¹åèåæ¥è©¢å§å®¹ï¼é²èç¢çæ´ææçåå½¢åµå¥ãæåçæ¹æ³å¨ GraphQA åºæºä¸éå°äº 4.13% çæè½æåï¼èç¡éè¨ç·´å¤§åèªè¨æ¨¡åï¼è­æäºå¨èçè¤éçæå­å±¬æ§åå½¢è³ææ¹é¢æé¡¯èçé²å±ã

##### **Is Conversational XAI All You Need? Human-AI Decision Making With a Conversational XAI Assistant**
2501.17546v1 by Gaole He, Nilay Aishwarya, Ujwal Gadiraju

Explainable artificial intelligence (XAI) methods are being proposed to help
interpret and understand how AI systems reach specific predictions. Inspired by
prior work on conversational user interfaces, we argue that augmenting existing
XAI methods with conversational user interfaces can increase user engagement
and boost user understanding of the AI system. In this paper, we explored the
impact of a conversational XAI interface on users' understanding of the AI
system, their trust, and reliance on the AI system. In comparison to an XAI
dashboard, we found that the conversational XAI interface can bring about a
better understanding of the AI system among users and higher user trust.
However, users of both the XAI dashboard and conversational XAI interfaces
showed clear overreliance on the AI system. Enhanced conversations powered by
large language model (LLM) agents amplified over-reliance. Based on our
findings, we reason that the potential cause of such overreliance is the
illusion of explanatory depth that is concomitant with both XAI interfaces. Our
findings have important implications for designing effective conversational XAI
interfaces to facilitate appropriate reliance and improve human-AI
collaboration. Code can be found at
https://github.com/delftcrowd/IUI2025_ConvXAI

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¹æ³è¢«æåºç¨æ¼å¹«å©è§£éä¸¦çè§£äººå·¥æºæ§ç³»çµ±å¦ä½éæç¹å®é æ¸¬ãåå°è©±å¼ä½¿ç¨èä»é¢çååç ç©¶åç¼ï¼æåä¸»å¼µééå°è©±å¼ä½¿ç¨èä»é¢æ´åç¾æç XAI æ¹æ³ï¼å¯ä»¥æåä½¿ç¨èçåèåº¦ä¸¦å¢å¼·ä½¿ç¨èå°äººå·¥æºæ§ç³»çµ±ççè§£ãå¨æ¬æä¸­ï¼æåæ¢è¨äºå°è©±å¼ XAI ä»é¢å°ä½¿ç¨èçè§£äººå·¥æºæ§ç³»çµ±ãå¶ä¿¡ä»»åº¦åå°äººå·¥æºæ§ç³»çµ±çä¾è³´æ§çå½±é¿ãè XAI åè¡¨æ¿ç¸æ¯ï¼æåç¼ç¾å°è©±å¼ XAI ä»é¢å¯ä»¥è®ä½¿ç¨èå°äººå·¥æºæ§ç³»çµ±ææ´æ·±å¥ççè§£ï¼ä»¥åæ´é«çä½¿ç¨èä¿¡ä»»åº¦ãç¶èï¼XAI åè¡¨æ¿åå°è©±å¼ XAI ä»é¢çä½¿ç¨èé½æ¸æ¥å°å±ç¾åºéåº¦ä¾è³´äººå·¥æºæ§ç³»çµ±çç¾è±¡ãç±å¤§åèªè¨æ¨¡å (LLM) ä»£çå¢å¼·çå°è©±ææ¾å¤§éåº¦ä¾è³´ãæ ¹ææåçç ç©¶çµæï¼æåæ¨è«éç¨®éåº¦ä¾è³´çæ½å¨åå æ¯èéå©å XAI ä»é¢åæå­å¨çè§£éæ·±åº¦é¯è¦ºãæåçç ç©¶çµæå°è¨­è¨ææå°è©±å¼ XAI ä»é¢ä»¥ä¿é²é©ç¶ä¾è³´ä¸¦æ¹åäººæ©åä½å·æéè¦çæç¾©ãç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/delftcrowd/IUI2025_ConvXAI æ¾å°

##### **LLM Assistance for Pediatric Depression**
2501.17510v1 by Mariia Ignashina, Paulina Bondaronek, Dan Santel, John Pestian, Julia Ive

Traditional depression screening methods, such as the PHQ-9, are particularly
challenging for children in pediatric primary care due to practical
limitations. AI has the potential to help, but the scarcity of annotated
datasets in mental health, combined with the computational costs of training,
highlights the need for efficient, zero-shot approaches. In this work, we
investigate the feasibility of state-of-the-art LLMs for depressive symptom
extraction in pediatric settings (ages 6-24). This approach aims to complement
traditional screening and minimize diagnostic errors.
  Our findings show that all LLMs are 60% more efficient than word match, with
Flan leading in precision (average F1: 0.65, precision: 0.78), excelling in the
extraction of more rare symptoms like "sleep problems" (F1: 0.92) and
"self-loathing" (F1: 0.8). Phi strikes a balance between precision (0.44) and
recall (0.60), performing well in categories like "Feeling depressed" (0.69)
and "Weight change" (0.78). Llama 3, with the highest recall (0.90),
overgeneralizes symptoms, making it less suitable for this type of analysis.
Challenges include the complexity of clinical notes and overgeneralization from
PHQ-9 scores. The main challenges faced by LLMs include navigating the complex
structure of clinical notes with content from different times in the patient
trajectory, as well as misinterpreting elevated PHQ-9 scores.
  We finally demonstrate the utility of symptom annotations provided by Flan as
features in an ML algorithm, which differentiates depression cases from
controls with high precision of 0.78, showing a major performance boost
compared to a baseline that does not use these features.

æè¦ï¼<paragraph>å³çµ±çæé¬±çç¯©æª¢æ¹æ³ï¼ä¾å¦ PHQ-9ï¼ç±æ¼å¯¦ééå¶ï¼å°æ¼å°åç§åç´ç§è­·ä¸­çåç«¥ä¾èªªç¹å¥å·æææ°æ§ãAI æå¯è½æä¾å¹«å©ï¼ä½å¿çå¥åº·ä¸­è¨»è§£è³æéçç¨å°ï¼å ä¸è¨ç·´çéç®ææ¬ï¼çªé¡¯äºå°ææççé¶æ¬¡å­¸ç¿æ¹æ³çéæ±ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºæåé²ç LLM å¨å°åç§ç°å¢ï¼6-24 æ­²ï¼ä¸­æåæé¬±çççå¯è¡æ§ãéç¨®æ¹æ³æ¨å¨è£åå³çµ±ç¯©æª¢ä¸¦å°è¨ºæ·é¯èª¤éè³æä½ãæåçç ç©¶çµæé¡¯ç¤ºï¼ææ LLM çæçé½æ¯å­è©æ¯å°é«åº 60%ï¼è Flan å¨ç²¾ç¢ºåº¦æ¹é¢é åï¼å¹³å F1ï¼0.65ï¼ç²¾ç¢ºåº¦ï¼0.78ï¼ï¼å¨æåè¼ç½è¦çççæ¹é¢è¡¨ç¾åºè²ï¼ä¾å¦ãç¡ç åé¡ãï¼F1ï¼0.92ï¼åãèªæå­æ¡ãï¼F1ï¼0.8ï¼ãPhi å¨ç²¾ç¢ºåº¦ï¼0.44ï¼åå¬åçï¼0.60ï¼ä¹éåå¾å¹³è¡¡ï¼å¨ãæå°æ²®åªãï¼0.69ï¼åãé«éæ¹è®ãï¼0.78ï¼ç­é¡å¥ä¸­è¡¨ç¾è¯å¥½ãæææé«å¬åçï¼0.90ï¼ç Llama 3 æéåº¦æ¦æ¬ççï¼ä½¿å¶ä¸å¤ªé©åæ­¤é¡åæãææ°åæ¬è¨åºç­è¨çè¤éæ§å PHQ-9 åæ¸çéåº¦æ¦æ¬ãLLM é¢è¨çä¸»è¦ææ°åæ¬å¨æ£èæ­·ç¨ä¸­ä¸åæéçå§å®¹ä¸­å°èªè¨åºç­è¨çè¤éçµæ§ï¼ä»¥åèª¤è§£ PHQ-9 åæ¸åé«ãæåæå¾å±ç¤ºäº Flan æä¾çççè¨»è§£ä½çºæ©å¨å­¸ç¿æ¼ç®æ³ä¸­ç¹å¾µçæç¨ï¼å®ä»¥ 0.78 çé«ç²¾ç¢ºåº¦å°æé¬±ççä¾èå°ç§çµååéä¾ï¼èä¸ä½¿ç¨éäºç¹å¾µçåºæºç¸æ¯ï¼é¡¯ç¤ºåºä¸»è¦çæè½æåã</paragraph>

##### **Neural Spelling: A Spell-Based BCI System for Language Neural Decoding**
2501.17489v1 by Xiaowei Jiang, Charles Zhou, Yiqun Duan, Ziyi Zhao, Thomas Do, Chin-Teng Lin

Brain-computer interfaces (BCIs) present a promising avenue by translating
neural activity directly into text, eliminating the need for physical actions.
However, existing non-invasive BCI systems have not successfully covered the
entire alphabet, limiting their practicality. In this paper, we propose a novel
non-invasive EEG-based BCI system with Curriculum-based Neural Spelling
Framework, which recognizes all 26 alphabet letters by decoding neural signals
associated with handwriting first, and then apply a Generative AI (GenAI) to
enhance spell-based neural language decoding tasks. Our approach combines the
ease of handwriting with the accessibility of EEG technology, utilizing
advanced neural decoding algorithms and pre-trained large language models
(LLMs) to translate EEG patterns into text with high accuracy. This system show
how GenAI can improve the performance of typical spelling-based neural language
decoding task, and addresses the limitations of previous methods, offering a
scalable and user-friendly solution for individuals with communication
impairments, thereby enhancing inclusive communication options.

æè¦ï¼è¦æ©ä»é¢ (BCI) ééå°ç¥ç¶æ´»åç´æ¥è½æææå­ï¼æä¾äºæ¶é¤èº«é«åä½éæ±çéå¾ãç¶èï¼ç¾æçéä¾µå¥å¼ BCI ç³»çµ±ä¸¦æªæåæ¶µèææå­æ¯ï¼éå¶äºå¶å¯¦ç¨æ§ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°çåºæ¼ EEG çéä¾µå¥å¼ BCI ç³»çµ±ï¼è©²ç³»çµ±æ¡ç¨åºæ¼èª²ç¨çç¥ç¶æ¼å¯«æ¶æ§ï¼ééåè§£ç¢¼èæå¯«ç¸éçç¥ç¶è¨èä¾è¾¨è­ææ 26 åå­æ¯ï¼ç¶å¾æç¨çæå¼ AI (GenAI) ä¾å¢å¼·åºæ¼æ¼å¯«çç¥ç¶èªè¨è§£ç¢¼ä»»åãæåçåæ³çµåäºæå¯«çå®¹ææ§è EEG æè¡çå¯åæ§ï¼å©ç¨åé²çç¥ç¶è§£ç¢¼æ¼ç®æ³åé åè¨ç·´çå¤§èªè¨æ¨¡å (LLM) å° EEG æ¨¡å¼è½æçºå·æé«æºç¢ºåº¦çæå­ãæ­¤ç³»çµ±å±ç¤ºäº GenAI å¦ä½æ¹åå¸åçåºæ¼æ¼å¯«çç¥ç¶èªè¨è§£ç¢¼ä»»åçæè½ï¼ä¸¦è§£æ±ºäºååæ¹æ³çéå¶ï¼çºææºééç¤çåäººæä¾å¯æ´åä¸ååçè§£æ±ºæ¹æ¡ï¼é²èå¢å¼·åå®¹æ§çæºéé¸é ã

##### **DINT Transformer**
2501.17486v1 by Yueyang Cang, Yuhang Liu, Xiaoteng Zhang, Erlu Zhao, Li Shi

DIFF Transformer addresses the issue of irrelevant context interference by
introducing a differential attention mechanism that enhances the robustness of
local attention. However, it has two critical limitations: the lack of global
context modeling, which is essential for identifying globally significant
tokens, and numerical instability due to the absence of strict row
normalization in the attention matrix. To overcome these challenges, we propose
DINT Transformer, which extends DIFF Transformer by incorporating a
differential-integral mechanism. By computing global importance scores and
integrating them into the attention matrix, DINT Transformer improves its
ability to capture global dependencies. Moreover, the unified parameter design
enforces row-normalized attention matrices, improving numerical stability.
Experimental results demonstrate that DINT Transformer excels in accuracy and
robustness across various practical applications, such as long-context language
modeling and key information retrieval. These results position DINT Transformer
as a highly effective and promising architecture.

æè¦ï¼DIFF Transformer ééå°å¥å¼·åå±é¨æ³¨æåç©©å¥æ§çå¾®åæ³¨æåæ©å¶ï¼ä¾è§£æ±ºç¡éèæ¯å¹²æ¾çåé¡ãç¶èï¼å®æå©åéå¤§çéå¶ï¼ç¼ºä¹æ´é«èæ¯å»ºæ¨¡ï¼éå°æ¼è­å¥æ´é«éè¦çç¬¦èè³ééè¦ï¼ä»¥åç±æ¼æ³¨æåç©é£ä¸­ç¼ºä¹å´æ ¼çè¡æ­£è¦åèå°è´æ¸å¼ä¸ç©©å®ãçºäºåæéäºææ°ï¼æåæåºäº DINT Transformerï¼å®ééç´å¥å¾®åç©åæ©å¶ä¾æ´å DIFF Transformerãééè¨ç®æ´é«éè¦æ§åæ¸ä¸¦å°å®åæ´åå°æ³¨æåç©é£ä¸­ï¼DINT Transformer æ¹åäºå¶æææ´é«ä¾è³´æ§çè½åãæ­¤å¤ï¼çµ±ä¸åæ¸è¨­è¨å¼·å¶å·è¡è¡æ­£è¦åçæ³¨æåç©é£ï¼æ¹åäºæ¸å¼ç©©å®æ§ãå¯¦é©çµæè¡¨æï¼DINT Transformer å¨åç¨®å¯¦éæç¨ä¸­è¡¨ç¾åºåè¶çæºç¢ºæ§åç©©å¥æ§ï¼ä¾å¦é·èæ¯èªè¨å»ºæ¨¡åééµè³è¨æª¢ç´¢ãéäºçµæå° DINT Transformer å®ä½çºä¸åé«æä¸æåæ¯çæ¶æ§ã

##### **DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance**
2501.17479v1 by Seffi Cohen, Niv Goldshlager, Nurit Cohen-Inger, Bracha Shapira, Lior Rokach

Large Language Models (LLMs) have shown remarkable capabilities across
various natural language processing tasks but often struggle to excel uniformly
in diverse or complex domains. We propose a novel ensemble method - Diverse
Fingerprint Ensemble (DFPE), which leverages the complementary strengths of
multiple LLMs to achieve more robust performance. Our approach involves: (1)
clustering models based on response "fingerprints" patterns, (2) applying a
quantile-based filtering mechanism to remove underperforming models at a
per-subject level, and (3) assigning adaptive weights to remaining models based
on their subject-wise validation accuracy. In experiments on the Massive
Multitask Language Understanding (MMLU) benchmark, DFPE outperforms the best
single model by 3% overall accuracy and 5% in discipline-level accuracy. This
method increases the robustness and generalization of LLMs and underscores how
model selection, diversity preservation, and performance-driven weighting can
effectively address challenging, multi-faceted language understanding tasks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®èªç¶èªè¨èçä»»åä¸­å±ç¾åºéå¡çè½åï¼ä½éå¸¸é£ä»¥å¨å¤åæè¤éçé åä¸­å¨é¢è¡¨ç¾åªç°ãæåæåºäºä¸ç¨®æ°ç©çæ´é«æ¹æ³ - å¤åæç´æ´é« (DFPE)ï¼å®å©ç¨å¤å LLM çäºè£åªå¢ä¾å¯¦ç¾æ´ç©©å¥çæè½ãæåçæ¹æ³åæ¬ï¼(1) æ ¹æåæãæç´ãæ¨¡å¼å°æ¨¡åé²è¡åç¾¤ï¼(2) æç¨åºæ¼åä½æ¸çéæ¿¾æ©å¶ä¾ç§»é¤å¨æ¯åä¸»é¡å±¤ç´è¡¨ç¾ä¸ä½³çæ¨¡åï¼ä»¥å (3) æ ¹ææ¨¡åå¨æ¯åä¸»é¡çé©è­æºç¢ºåº¦ï¼çºå¶åéèªé©ææ¬éãå¨ Massive Multitask Language Understanding (MMLU) åºæºæ¸¬è©¦çå¯¦é©ä¸­ï¼DFPE å¨æ´é«æºç¢ºåº¦ä¸åªæ¼æä½³å®ä¸æ¨¡å 3%ï¼å¨å­¸ç§å±¤ç´æºç¢ºåº¦ä¸åªæ¼ 5%ãæ­¤æ¹æ³å¢å äº LLM çç©©å¥æ§åæ³åæ§ï¼ä¸¦å¼·èª¿æ¨¡åé¸æãå¤åæ§ä¿çåæè½é©åçå æ¬å¦ä½è½ææå°è§£æ±ºå·æææ°æ§çå¤é¢åèªè¨çè§£ä»»åã

##### **Large Language Models for Single-Step and Multi-Step Flight Trajectory Prediction**
2501.17459v1 by Kaiwei Luo, Jiliu Zhou

Flight trajectory prediction is a critical time series task in aviation.
While deep learning methods have shown significant promise, the application of
large language models (LLMs) to this domain remains underexplored. This study
pioneers the use of LLMs for flight trajectory prediction by reframing it as a
language modeling problem. Specifically, We extract features representing the
aircraft's position and status from ADS-B flight data to construct a
prompt-based dataset, where trajectory waypoints are converted into language
tokens. The dataset is then employed to fine-tune LLMs, enabling them to learn
complex spatiotemporal patterns for accurate predictions. Comprehensive
experiments demonstrate that LLMs achieve notable performance improvements in
both single-step and multi-step predictions compared to traditional methods,
with LLaMA-3.1 model achieving the highest overall accuracy. However, the high
inference latency of LLMs poses a challenge for real-time applications,
underscoring the need for further research in this promising direction.

æè¦ï¼é£è¡è»è·¡é æ¸¬æ¯èªç©ºé åä¸­ä¸åééµçæéåºåä»»åã
åç®¡æ·±åº¦å­¸ç¿æ¹æ³å·²å±ç¾åºé¡¯èåæ¯ï¼ä½å¤§åèªè¨æ¨¡å (LLM) å¨æ­¤é åçæç¨ä»æªå¾å°ååæ¢ç´¢ãæ¬ç ç©¶çåå° LLM ç¨æ¼é£è¡è»è·¡é æ¸¬ï¼æ¹æ³æ¯å°å¶éæ°å®ç¾©çºä¸åèªè¨å»ºæ¨¡åé¡ãå·é«ä¾èªªï¼æåå¾ ADS-B é£è¡æ¸æä¸­æåè¡¨ç¤ºé£æ©ä½ç½®åçæçç¹å¾ï¼ä»¥æ§å»ºä¸ååºæ¼æç¤ºçæ¸æéï¼å¶ä¸­è»è·¡èªé»è¢«è½æçºèªè¨ç¬¦èãç¶å¾ä½¿ç¨è©²æ¸æéå° LLM é²è¡å¾®èª¿ï¼ä½¿å¶è½å¤ å­¸ç¿è¤éçæç©ºæ¨¡å¼ï¼å¾èé²è¡æºç¢ºçé æ¸¬ãå¨é¢çå¯¦é©è¡¨æï¼èå³çµ±æ¹æ³ç¸æ¯ï¼LLM å¨å®æ­¥åå¤æ­¥é æ¸¬ä¸­é½åå¾äºé¡¯èçæ§è½æåï¼å¶ä¸­ LLaMA-3.1 æ¨¡åéå°äºæé«çæ´é«æºç¢ºçãç¶èï¼LLM çé«æ¨çå»¶é²å°å¯¦ææç¨æ§æäºææ°ï¼éå¼·èª¿äºå¨éä¸æåæ¯çæ¹åä¸é²è¡é²ä¸æ­¥ç ç©¶çå¿è¦æ§ã

##### **Cross-Language Approach for Quranic QA**
2501.17449v1 by Islam Oshallah, Mohamed Basem, Ali Hamdi, Ammar Mohammed

Question answering systems face critical limitations in languages with
limited resources and scarce data, making the development of robust models
especially challenging. The Quranic QA system holds significant importance as
it facilitates a deeper understanding of the Quran, a Holy text for over a
billion people worldwide. However, these systems face unique challenges,
including the linguistic disparity between questions written in Modern Standard
Arabic and answers found in Quranic verses written in Classical Arabic, and the
small size of existing datasets, which further restricts model performance. To
address these challenges, we adopt a cross-language approach by (1) Dataset
Augmentation: expanding and enriching the dataset through machine translation
to convert Arabic questions into English, paraphrasing questions to create
linguistic diversity, and retrieving answers from an English translation of the
Quran to align with multilingual training requirements; and (2) Language Model
Fine-Tuning: utilizing pre-trained models such as BERT-Medium, RoBERTa-Base,
DeBERTa-v3-Base, ELECTRA-Large, Flan-T5, Bloom, and Falcon to address the
specific requirements of Quranic QA. Experimental results demonstrate that this
cross-language approach significantly improves model performance, with
RoBERTa-Base achieving the highest MAP@10 (0.34) and MRR (0.52), while
DeBERTa-v3-Base excels in Recall@10 (0.50) and Precision@10 (0.24). These
findings underscore the effectiveness of cross-language strategies in
overcoming linguistic barriers and advancing Quranic QA systems

æè¦ï¼<paragraph>åç­ç³»çµ±å¨è³æºæéä¸è³æç¨å°çèªè¨ä¸­é¢è¨å´éçéå¶ï¼éä½¿å¾å»ºç«ç©©å¥æ¨¡åç¹å¥å·æææ°æ§ãå¤è­ç¶åç­ç³»çµ±å·æéè¦çæç¾©ï¼å çºå®ä¿é²äºå°å¤è­ç¶çæ·±å¥çè§£ï¼èå¤è­ç¶æ¯å¨çè¶éååäººçç¥èææ¬ãç¶èï¼éäºç³»çµ±é¢è¨èç¨ç¹çææ°ï¼åæ¬ä»¥ç¾ä»£æ¨æºé¿æä¼¯èªå¯«æçåé¡èä»¥å¤å¸é¿æä¼¯èªå¯«æçå¤è­ç¶ç¶æä¸­ç¼ç¾çç­æ¡ä¹éçèªè¨å·®ç°ï¼ä»¥åç¾æè³æéè¦æ¨¡å°ï¼é²ä¸æ­¥éå¶äºæ¨¡åçæè½ãçºäºæå°éäºææ°ï¼æåæ¡ç¨è·¨èªè¨æ¹æ³ï¼åæ¬ï¼(1) è³æéæ´åï¼ééæ©å¨ç¿»è­¯å°é¿æä¼¯èªåé¡è½ææè±èªãæ¹å¯«åé¡ä»¥åµé èªè¨å¤æ¨£æ§ï¼ä»¥åå¾å¤è­ç¶çè±æç¿»è­¯ä¸­æ·åç­æ¡ä»¥ç¬¦åå¤èªè¨è¨ç·´éæ±ï¼ä¾æ´ååè±å¯è³æéï¼ä»¥å (2) èªè¨æ¨¡åå¾®èª¿ï¼å©ç¨é åè¨ç·´çæ¨¡åï¼ä¾å¦ BERT-MediumãRoBERTa-BaseãDeBERTa-v3-BaseãELECTRA-LargeãFlan-T5ãBloom å Falconï¼ä¾æ»¿è¶³å¤è­ç¶åç­çç¹å®éæ±ãå¯¦é©çµæè¡¨æï¼éç¨®è·¨èªè¨æ¹æ³é¡¯èæåäºæ¨¡åæè½ï¼å¶ä¸­ RoBERTa-Base å¨ MAP@10 (0.34) å MRR (0.52) æ¹é¢åå¾æé«æå°±ï¼è DeBERTa-v3-Base åå¨ Recall@10 (0.50) å Precision@10 (0.24) æ¹é¢è¡¨ç¾åºè²ãéäºç¼ç¾å¼·èª¿äºè·¨èªè¨ç­ç¥å¨åæèªè¨éç¤åæ¨é²å¤è­ç¶åç­ç³»çµ±æ¹é¢çæææ§</paragraph>

##### **Towards Making Flowchart Images Machine Interpretable**
2501.17441v1 by Shreya Shukla, Prajwal Gatti, Yogesh Kumar, Vikash Yadav, Anand Mishra

Computer programming textbooks and software documentations often contain
flowcharts to illustrate the flow of an algorithm or procedure. Modern OCR
engines often tag these flowcharts as graphics and ignore them in further
processing. In this paper, we work towards making flowchart images
machine-interpretable by converting them to executable Python codes. To this
end, inspired by the recent success in natural language to code generation
literature, we present a novel transformer-based framework, namely FloCo-T5.
Our model is well-suited for this task,as it can effectively learn semantics,
structure, and patterns of programming languages, which it leverages to
generate syntactically correct code. We also used a task-specific pre-training
objective to pre-train FloCo-T5 using a large number of logic-preserving
augmented code samples. Further, to perform a rigorous study of this problem,
we introduce theFloCo dataset that contains 11,884 flowchart images and their
corresponding Python codes. Our experiments show promising results, and
FloCo-T5 clearly outperforms related competitive baselines on code generation
metrics. We make our dataset and implementation publicly available.

æè¦ï¼é»è¦ç¨å¼æç§æ¸åè»é«æä»¶å¸¸åå«æµç¨åï¼ä»¥èªªææ¼ç®æ³æç¨åºçæµç¨ãç¾ä»£ OCR å¼æå¸¸å°éäºæµç¨åæ¨ç±¤çºåå½¢ï¼ä¸¦å¨å¾çºèçä¸­å¿½ç¥å®åãå¨æ¬æä¸­ï¼æåè´åæ¼è®æµç¨åå½±åå¯ä¾æ©å¨è§£è®ï¼æ¹æ³æ¯å°å®åè½æçºå¯å·è¡ç Python ç¨å¼ç¢¼ãçºæ­¤ï¼åå°èªç¶èªè¨çæç¨å¼ç¢¼çææ°é²å±åç¼ï¼æåæåºä¸åæ°ç©çåºæ¼è½æå¨çæ¶æ§ï¼ç¨±çº FloCo-T5ãæåçæ¨¡åéå¸¸é©åæ­¤ä»»åï¼å çºå®å¯ä»¥ææå°å­¸ç¿ç¨å¼èªè¨çèªæãçµæ§åæ¨¡å¼ï¼ä¸¦å©ç¨éäºç¥è­ä¾ç¢çèªæ³æ­£ç¢ºçç¨å¼ç¢¼ãæåéä½¿ç¨ç¹å®æ¼ä»»åçé è¨ç·´ç®æ¨ï¼ä½¿ç¨å¤§éçéè¼¯ä¿çæ´åç¨å¼ç¢¼ç¯ä¾ä¾é è¨ç·´ FloCo-T5ãæ­¤å¤ï¼çºäºå°éååé¡é²è¡å´è¬¹çç ç©¶ï¼æåå¼å¥äº FloCo è³æéï¼å¶ä¸­åå« 11,884 å¼µæµç¨åå½±ååå¶å°æç Python ç¨å¼ç¢¼ãæåçå¯¦é©é¡¯ç¤ºåºæå¸æççµæï¼è FloCo-T5 å¨ç¨å¼ç¢¼ç¢çææ¨ä¸æé¡¯åªæ¼ç¸éçç«¶ç­åºç·ãæåå¬éæä¾æåçè³æéåå¯¦ä½ã

##### **Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation**
2501.17433v1 by Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Ling Liu

Recent research shows that Large Language Models (LLMs) are vulnerable to
harmful fine-tuning attacks -- models lose their safety alignment ability after
fine-tuning on a few harmful samples. For risk mitigation, a guardrail is
typically used to filter out harmful samples before fine-tuning. By designing a
new red-teaming method, we in this paper show that purely relying on the
moderation guardrail for data filtration is not reliable. Our proposed attack
method, dubbed Virus, easily bypasses the guardrail moderation by slightly
modifying the harmful data. Experimental results show that the harmful data
optimized by Virus is not detectable by the guardrail with up to 100\% leakage
ratio, and can simultaneously achieve superior attack performance. Finally, the
key message we want to convey through this paper is that: \textbf{it is
reckless to consider guardrail moderation as a clutch at straws towards harmful
fine-tuning attack}, as it cannot solve the inherent safety issue of the
pre-trained LLMs. Our code is available at https://github.com/git-disl/Virus

æè¦ï¼æè¿çç ç©¶è¡¨æï¼å¤§åè¯­è¨æ¨¡å (LLM) å®¹æåå°æå®³å¾®è°æ»å»ââæ¨¡åå¨å¯¹å ä¸ªæå®³æ ·æ¬è¿è¡å¾®è°åä¼å¤±å»å¶å®å¨å¯¹é½è½åãä¸ºäºéä½é£é©ï¼éå¸¸ä½¿ç¨æ¤æ å¨å¾®è°ä¹åè¿æ»¤ææå®³æ ·æ¬ãéè¿è®¾è®¡ä¸ç§æ°ççº¢éæ¹æ³ï¼æä»¬å¨æ¬æä¸­è¡¨æï¼åçº¯ä¾èµè°èæ¤æ è¿è¡æ°æ®è¿æ»¤å¹¶ä¸å¯é ãæä»¬æåºçæ»å»æ¹æ³ï¼ç§°ä¸º Virusï¼éè¿ç¥å¾®ä¿®æ¹æå®³æ°æ®è½»æ¾ç»è¿æ¤æ è°èãå®éªç»æè¡¨æï¼Virus ä¼åçæå®³æ°æ®å¨é«è¾¾ 100% çæ³æ¼çä¸æ æ³è¢«æ¤æ æ£æµå°ï¼å¹¶ä¸å¯ä»¥åæ¶å®ç°åè¶çæ»å»æ§è½ãæåï¼æä»¬å¸æéè¿æ¬æä¼ è¾¾çå³é®ä¿¡æ¯æ¯ï¼\textbf{å°æ¤æ è°èè§ä¸ºå¯¹æå®³å¾®è°æ»å»çæå½ç¨»èæ¯é²è½ç}ï¼å ä¸ºå®æ æ³è§£å³é¢è®­ç» LLM åºæçå®å¨é®é¢ãæä»¬çä»£ç å¯å¨ https://github.com/git-disl/Virus è·å¾

##### **Algorithmic Segmentation and Behavioral Profiling for Ransomware Detection Using Temporal-Correlation Graphs**
2501.17429v1 by Ignatius Rollere, Caspian Hartsfield, Seraphina Courtenay, Lucian Fenwick, Aurelia Grunwald

The rapid evolution of cyber threats has outpaced traditional detection
methodologies, necessitating innovative approaches capable of addressing the
adaptive and complex behaviors of modern adversaries. A novel framework was
introduced, leveraging Temporal-Correlation Graphs to model the intricate
relationships and temporal patterns inherent in malicious operations. The
approach dynamically captured behavioral anomalies, offering a robust mechanism
for distinguishing between benign and malicious activities in real-time
scenarios. Extensive experiments demonstrated the framework's effectiveness
across diverse ransomware families, with consistently high precision, recall,
and overall detection accuracy. Comparative evaluations highlighted its better
performance over traditional signature-based and heuristic methods,
particularly in handling polymorphic and previously unseen ransomware variants.
The architecture was designed with scalability and modularity in mind, ensuring
compatibility with enterprise-scale environments while maintaining resource
efficiency. Analysis of encryption speeds, anomaly patterns, and temporal
correlations provided deeper insights into the operational strategies of
ransomware, validating the framework's adaptability to evolving threats. The
research contributes to advancing cybersecurity technologies by integrating
dynamic graph analytics and machine learning for future innovations in threat
detection. Results from this study underline the potential for transforming the
way organizations detect and mitigate complex cyberattacks.

æè¦ï¼ç¶²è·¯å¨èå¿«éæ¼åå·²è¶è¶å³çµ±åµæ¸¬æ¹æ³ï¼å æ­¤éè¦åµæ°æ¹æ³ä¾å æç¾ä»£å°æé©ææ§å¼·ä¸è¤éçè¡çºãä¸åæ°æ¶æ§æéèçï¼å©ç¨æééè¯åå½¢ä¾æ¨¡æ¬æ¡ææä½ä¸­è¤éçéä¿åæéæ¨¡å¼ãéç¨®æ¹æ³åææ·åè¡çºç°å¸¸ï¼æä¾ä¸ç¨®å¼·å¥çæ©å¶ï¼ç¨æ¼å¨å¯¦éææ³ä¸­ååè¯æ§åæ¡ææ´»åãå»£æ³çå¯¦é©è­æäºè©²æ¶æ§å¨åç¨®åç´¢è»é«ç³»åä¸­é½éå¸¸ææï¼å§çµä¿æé«ç²¾æºåº¦ãå¬åçåæ´é«åµæ¸¬æºç¢ºåº¦ãæ¯è¼è©ä¼°å¼·èª¿äºå®æ¯å³çµ±çåºæ¼ç°½ç« ååç¼å¼æ¹æ³ææ´å¥½çæè½ï¼ç¹å¥æ¯å¨èçå¤å½¢æ§åä»¥åæªè¦éçåç´¢è»é«è®ç¨®æ¹é¢ãæ­¤æ¶æ§å¨è¨­è¨æèéäºå¯æ´åæ§åæ¨¡çµåï¼ç¢ºä¿èä¼æ¥­è¦æ¨¡ç°å¢ç¸å®¹ï¼åæç¶­æè³æºæçãå°å å¯éåº¦ãç°å¸¸æ¨¡å¼åæééè¯æ§çåææä¾äºæ´æ·±å¥çè¦è§£ï¼äºè§£åç´¢è»é«çæä½ç­ç¥ï¼é©è­äºè©²æ¶æ§å°ä¸æ·æ¼è®çå¨èå·æé©ææ§ãéé ç ç©¶ééæ´ååæåå½¢åæåæ©å¨å­¸ç¿ï¼çºå¨èåµæ¸¬çæªä¾åµæ°ååºè²¢ç»ï¼æå©æ¼æ¨åç¶²è·¯å®å¨æè¡çé²æ­¥ãéé ç ç©¶ççµæå¼·èª¿äºè½è®çµç¹åµæ¸¬åç·©è§£è¤éç¶²è·¯æ»ææ¹å¼çæ½åã

##### **Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models**
2501.17420v1 by Yuxuan Li, Hirokazu Shirado, Sauvik Das

While advances in fairness and alignment have helped mitigate overt biases
exhibited by large language models (LLMs) when explicitly prompted, we
hypothesize that these models may still exhibit implicit biases when simulating
human behavior. To test this hypothesis, we propose a technique to
systematically uncover such biases across a broad range of sociodemographic
categories by assessing decision-making disparities among agents with
LLM-generated, sociodemographically-informed personas. Using our technique, we
tested six LLMs across three sociodemographic groups and four decision-making
scenarios. Our results show that state-of-the-art LLMs exhibit significant
sociodemographic disparities in nearly all simulations, with more advanced
models exhibiting greater implicit biases despite reducing explicit biases.
Furthermore, when comparing our findings to real-world disparities reported in
empirical studies, we find that the biases we uncovered are directionally
aligned but markedly amplified. This directional alignment highlights the
utility of our technique in uncovering systematic biases in LLMs rather than
random variations; moreover, the presence and amplification of implicit biases
emphasizes the need for novel strategies to address these biases.

æè¦ï¼<paragraph>éç¶å¬å¹³æ§åå°é½çé²å±æå©æ¼æ¸è¼å¤§åèªè¨æ¨¡å (LLM) å¨æç¢ºæç¤ºä¸è¡¨ç¾åºçæé¡¯åè¦ï¼ä½æååè¨­éäºæ¨¡åå¨æ¨¡æ¬äººé¡è¡çºæä»å¯è½è¡¨ç¾åºé±å«åè¦ãçºäºé©è­éååè¨­ï¼æåæåºäºä¸ç¨®æè¡ï¼ééè©ä¼°å·æ LLM çæãç¤¾æäººå£çµ±è¨è³æç¥æè§è²çä»£çä¹éçæ±ºç­å·®ç°ï¼ç³»çµ±å°æ­ç¤ºå»£æ³çç¤¾æäººå£çµ±è¨é¡å¥ä¸­çæ­¤é¡åè¦ãä½¿ç¨æåçæè¡ï¼æåå¨ä¸åç¤¾æäººå£çµ±è¨ç¾¤çµåååæ±ºç­å¶å®å ´æ¯ä¸­æ¸¬è©¦äºå­å LLMãæåççµæè¡¨æï¼æåé²ç LLM å¨å¹¾ä¹æææ¨¡æ¬ä¸­é½è¡¨ç¾åºé¡¯èçç¤¾æäººå£çµ±è¨å·®ç°ï¼åç®¡æ¸å°äºæé¡¯åè¦ï¼ä½æ´åé²çæ¨¡åè¡¨ç¾åºæ´å¤§çé±å«åè¦ãæ­¤å¤ï¼ç¶å°æåçç¼ç¾èå¯¦è­ç ç©¶ä¸­å ±åçç¾å¯¦ä¸çå·®ç°é²è¡æ¯è¼æï¼æåç¼ç¾æåç¼ç¾çåè¦å¨æ¹åä¸æ¯ä¸è´çï¼ä½æé¡¯æ¾å¤§ãéç¨®æ¹åä¸è´æ§çªåºäºæåçæè¡å¨æ­ç¤º LLM ä¸­çç³»çµ±æ§åè¦èä¸æ¯é¨æ©è®ç°æ¹é¢çæç¨ï¼æ­¤å¤ï¼é±å«åè¦çå­å¨åæ¾å¤§å¼·èª¿äºéè¦æ°çç­ç¥ä¾è§£æ±ºéäºåè¦ã</paragraph>

##### **Reqo: A Robust and Explainable Query Optimization Cost Model**
2501.17414v1 by Baoming Chang, Amin Kamali, Verena Kantere

In recent years, there has been a growing interest in using machine learning
(ML) in query optimization to select more efficient plans. Existing
learning-based query optimizers use certain model architectures to convert
tree-structured query plans into representations suitable for downstream ML
tasks. As the design of these architectures significantly impacts cost
estimation, we propose a tree model architecture based on Bidirectional Graph
Neural Networks (Bi-GNN) aggregated by Gated Recurrent Units (GRUs) to achieve
more accurate cost estimates. The inherent uncertainty of data and model
parameters also leads to inaccurate cost estimates, resulting in suboptimal
plans and less robust query performance. To address this, we implement a novel
learning-to-rank cost model that effectively quantifies the uncertainty in cost
estimates using approximate probabilistic ML. This model adaptively integrates
quantified uncertainty with estimated costs and learns from comparing pairwise
plans, achieving more robust performance. In addition, we propose the first
explainability technique specifically designed for learning-based cost models.
This technique explains the contribution of any subgraphs in the query plan to
the final predicted cost, which can be integrated and trained with any
learning-based cost model to significantly boost the model's explainability. By
incorporating these innovations, we propose a cost model for a Robust and
Explainable Query Optimizer, Reqo, that improves the accuracy, robustness, and
explainability of cost estimation, outperforming state-of-the-art approaches in
all three dimensions.

æè¦ï¼è¿å¹´æ¥ï¼äººä»¬å¯¹å¨æ¥è¯¢ä¼åä¸­ä½¿ç¨æºå¨å­¦ä¹  (ML) æ¥éæ©æ´ææçè®¡åè¶æ¥è¶æå´è¶£ãç°æçåºäºå­¦ä¹ çæ¥è¯¢ä¼åå¨ä½¿ç¨ç¹å®æ¨¡åæ¶æå°æ å½¢ç»ææ¥è¯¢è®¡åè½¬æ¢ä¸ºéåä¸æ¸¸ ML ä»»å¡çè¡¨ç¤ºãç±äºè¿äºæ¶æçè®¾è®¡ä¼æ¾èå½±åææ¬ä¼°ç®ï¼æä»¬æåºäºä¸ç§åºäºååå¾ç¥ç»ç½ç» (Bi-GNN) çæ æ¨¡åæ¶æï¼è¯¥æ¶æç±é¨æ§å¾ªç¯åå (GRU) èåï¼ä»¥å®ç°æ´åç¡®çææ¬ä¼°ç®ãæ°æ®åæ¨¡ååæ°çåºæä¸ç¡®å®æ§ä¹ä¼å¯¼è´ææ¬ä¼°ç®ä¸åç¡®ï¼ä»èå¯¼è´è®¡åä¸çæ³åæ¥è¯¢æ§è½ä¸ä½³ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å®ç°äºä¸ä¸ªæ°é¢çå­¦ä¹ æåºææ¬æ¨¡åï¼è¯¥æ¨¡åä½¿ç¨è¿ä¼¼æ¦ç ML ææå°éåäºææ¬ä¼°ç®ä¸­çä¸ç¡®å®æ§ãæ­¤æ¨¡åèªéåºå°å°éåçä¸ç¡®å®æ§ä¸ä¼°è®¡ææ¬ç¸ç»åï¼å¹¶ä»æ¯è¾æå¯¹è®¡åä¸­å­¦ä¹ ï¼ä»èå®ç°æ´ç¨³å¥çæ§è½ãæ­¤å¤ï¼æä»¬æåºäºç¬¬ä¸ä¸ªä¸é¨ä¸ºåºäºå­¦ä¹ çææ¬æ¨¡åè®¾è®¡çå¯è§£éæ§ææ¯ãæ­¤ææ¯è§£éäºæ¥è¯¢è®¡åä¸­ä»»ä½å­å¾å¯¹æç»é¢æµææ¬çè´¡ç®ï¼è¯¥ææ¯å¯ä»¥ä¸ä»»ä½åºäºå­¦ä¹ çææ¬æ¨¡åéæå¹¶è¿è¡è®­ç»ï¼ä»¥æ¾èæé«æ¨¡åçå¯è§£éæ§ãéè¿ç»åè¿äºåæ°ï¼æä»¬ä¸ºç¨³å¥ä¸å¯è§£éçæ¥è¯¢ä¼åå¨ Reqo æåºäºä¸ç§ææ¬æ¨¡åï¼è¯¥æ¨¡åæé«äºææ¬ä¼°ç®çåç¡®æ§ãç¨³å¥æ§åå¯è§£éæ§ï¼å¨ææä¸ä¸ªç»´åº¦ä¸é½ä¼äºæåè¿çæ¹æ³ã

##### **A Genetic Algorithm-Based Approach for Automated Optimization of Kolmogorov-Arnold Networks in Classification Tasks**
2501.17411v1 by Quan Long, Bin Wang, Bing Xue, Mengjie Zhang

To address the issue of interpretability in multilayer perceptrons (MLPs),
Kolmogorov-Arnold Networks (KANs) are introduced in 2024. However, optimizing
KAN structures is labor-intensive, typically requiring manual intervention and
parameter tuning. This paper proposes GA-KAN, a genetic algorithm-based
approach that automates the optimization of KANs, requiring no human
intervention in the design process. To the best of our knowledge, this is the
first time that evolutionary computation is explored to optimize KANs
automatically. Furthermore, inspired by the use of sparse connectivity in MLPs
in effectively reducing the number of parameters, GA-KAN further explores
sparse connectivity to tackle the challenge of extensive parameter spaces in
KANs. GA-KAN is validated on two toy datasets, achieving optimal results
without the manual tuning required by the original KAN. Additionally, GA-KAN
demonstrates superior performance across five classification datasets,
outperforming traditional methods on all datasets and providing interpretable
symbolic formulae for the Wine and Iris datasets, thereby enhancing model
transparency. Furthermore, GA-KAN significantly reduces the number of
parameters over the standard KAN across all the five datasets. The core
contributions of GA-KAN include automated optimization, a new encoding
strategy, and a new decoding process, which together improve the accuracy and
interpretability, and reduce the number of parameters.

æè¦ï¼<paragraph>çºäºè§£æ±ºå¤å±¤æç¥å¨ (MLP) ä¸­çå¯è§£éæ§åé¡ï¼2024 å¹´å¼å¥äº Kolmogorov-Arnold ç¶²è·¯ (KAN)ãç¶èï¼æä½³å KAN çµæ§æ¯ä¸é èè²»å¤§éäººåçäºåï¼éå¸¸éè¦äººå·¥ä»å¥ååæ¸èª¿æ´ãæ¬ææåºäº GA-KANï¼ä¸ç¨®åºæ¼éºå³æ¼ç®æ³çæ¹æ³ï¼å®èªååäº KAN çæä½³åï¼å¨è¨­è¨éç¨ä¸­ç¡éäººå·¥ä»å¥ãææåæç¥ï¼éæ¯é¦æ¬¡æ¢ç´¢ä½¿ç¨æ¼åéç®èªåæä½³å KANãæ­¤å¤ï¼åå° MLP ä¸­ä½¿ç¨ç¨çé£ç·ä»¥æææ¸å°åæ¸æ¸éçåç¼ï¼GA-KAN é²ä¸æ­¥æ¢ç´¢ç¨çé£ç·ï¼ä»¥æå° KAN ä¸­å»£æ³åæ¸ç©ºéçææ°ãGA-KAN å¨å©åç©å·è³æéä¸é²è¡é©è­ï¼å¨ç¡éåå§ KAN æéçæåèª¿æ´çææ³ä¸ï¼éå°äºæä½³çµæãæ­¤å¤ï¼GA-KAN å¨äºååé¡è³æéä¸å±ç¾åºåè¶çæè½ï¼å¨ææè³æéä¸é½åªæ¼å³çµ±æ¹æ³ï¼ä¸¦çºè¡èéåé³¶å°¾è±è³æéæä¾äºå¯è§£éçç¬¦èå¬å¼ï¼å¾èå¢å¼·äºæ¨¡åéæåº¦ãæ­¤å¤ï¼GA-KAN å¨ææäºåè³æéä¸é¡¯èæ¸å°äºæ¯æ¨æº KAN æ´å°çåæ¸ãGA-KAN çæ ¸å¿è²¢ç»åæ¬èªåæä½³åãæ°çç·¨ç¢¼ç­ç¥åæ°çè§£ç¢¼éç¨ï¼å®åå±åæ¹é²äºæºç¢ºæ§åå¯è§£éæ§ï¼ä¸¦æ¸å°äºåæ¸æ¸éã</paragraph>

##### **General Scene Adaptation for Vision-and-Language Navigation**
2501.17403v1 by Haodong Hong, Yanyuan Qiao, Sen Wang, Jiajun Liu, Qi Wu

Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on
one-time execution of individual instructions across multiple environments,
aiming to develop agents capable of functioning in any environment in a
zero-shot manner. However, real-world navigation robots often operate in
persistent environments with relatively consistent physical layouts, visual
observations, and language styles from instructors. Such a gap in the task
setting presents an opportunity to improve VLN agents by incorporating
continuous adaptation to specific environments. To better reflect these
real-world conditions, we introduce GSA-VLN, a novel task requiring agents to
execute navigation instructions within a specific scene and simultaneously
adapt to it for improved performance over time. To evaluate the proposed task,
one has to address two challenges in existing VLN datasets: the lack of OOD
data, and the limited number and style diversity of instructions for each
scene. Therefore, we propose a new dataset, GSA-R2R, which significantly
expands the diversity and quantity of environments and instructions for the R2R
dataset to evaluate agent adaptability in both ID and OOD contexts.
Furthermore, we design a three-stage instruction orchestration pipeline that
leverages LLMs to refine speaker-generated instructions and apply role-playing
techniques to rephrase instructions into different speaking styles. This is
motivated by the observation that each individual user often has consistent
signatures or preferences in their instructions. We conducted extensive
experiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various
methods. Based on our findings, we propose a novel method, GR-DUET, which
incorporates memory-based navigation graphs with an environment-specific
training strategy, achieving state-of-the-art results on all GSA-R2R splits.

æè¦ï¼è¦è¦ºèªè¨å°èª (VLN) ä»»åä¸»è¦æ ¹æä»£çç¨å¼å¨å¤åç°å¢ä¸­å·è¡åå¥æä»¤çä¸æ¬¡æ§å·è¡ä¾è©ä¼°ä»£çç¨å¼ï¼æ¨å¨éç¼è½å¤ å¨ä»»ä½ç°å¢ä¸­ä»¥é¶æ¬¡å­¸ç¿çæ¹å¼éä½çä»£çç¨å¼ãç¶èï¼çå¯¦ä¸ççå°èªæ©å¨äººéå¸¸å¨æçºæ§çç°å¢ä¸­éä½ï¼èéäºç°å¢å·æç¸å°ä¸è´çç©çéç½®ãè¦è¦ºè§å¯åæä»¤çèªè¨é¢¨æ ¼ãä»»åè¨­å®ä¸­çéç¨®å·®è·æä¾äºä¸åæ©æï¼å¯ä»¥ééå°é£çºé©æç¹å®ç°å¢ç´å¥å¶ä¸­ä¾æ¹å VLN ä»£çç¨å¼ãçºäºæ´å¥½å°åæ éäºçå¯¦ä¸ççæ¢ä»¶ï¼æåæ¨åºäº GSA-VLNï¼éæ¯ä¸åæ°ä»»åï¼è¦æ±ä»£çç¨å¼å¨ç¹å®å ´æ¯ä¸­å·è¡å°èªæä»¤ï¼ä¸¦åæé©æè©²å ´æ¯ï¼ä»¥é¨èæéæ¨ç§»èæé«æè½ãçºäºè©ä¼°ææåºçä»»åï¼å¿é è§£æ±ºç¾æ VLN è³æéä¸­çå©åææ°ï¼ç¼ºä¹ OOD è³æï¼ä»¥åæ¯åå ´æ¯çæä»¤æ¸éåé¢¨æ ¼å¤æ¨£æ§æéãå æ­¤ï¼æåæåºäºä¸åæ°çè³æé GSA-R2Rï¼å®é¡¯èæ´å±äº R2R è³æéçç°å¢åæä»¤çå¤æ¨£æ§åæ¸éï¼ä»¥è©ä¼°ä»£çç¨å¼å¨ ID å OOD èæ¯ä¸çé©æè½åãæ­¤å¤ï¼æåè¨­è¨äºä¸åä¸éæ®µæä»¤ç·¨æç®¡éï¼è©²ç®¡éå©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾ç²¾çç±èªªè©±èç¢ççæä»¤ï¼ä¸¦æç¨è§è²æ®æ¼æå·§å°æä»¤æ¹å¯«æä¸åçèªªè©±é¢¨æ ¼ãéé æè¡çéæä¾èªæ¼è§å¯å°æ¯ååå¥ä½¿ç¨èéå¸¸å¨å¶æä»¤ä¸­å·æç¸ç¬¦çç°½åæåå¥½ãæåéå° GSA-R2R é²è¡äºå¤§éçå¯¦é©ï¼ä»¥å¾¹åºè©ä¼°æåçè³æéååºæºåç¨®æ¹æ³ãæ ¹ææåçç ç©¶çµæï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ GR-DUETï¼å®å°åºæ¼è¨æ¶çå°èªåè¡¨èç¹å®æ¼ç°å¢çè¨ç·´ç­ç¥çµåå¨ä¸èµ·ï¼å¨ææ GSA-R2R åå²ä¸­åå¾äºæåé²ççµæã

##### **MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs**
2501.17399v1 by Ved Sirdeshmukh, Kaustubh Deshpande, Johannes Mols, Lifeng Jin, Ed-Yeremai Cardona, Dean Lee, Jeremy Kritz, Willow Primack, Summer Yue, Chen Xing

We present MultiChallenge, a pioneering benchmark evaluating large language
models (LLMs) on conducting multi-turn conversations with human users, a
crucial yet underexamined capability for their applications. MultiChallenge
identifies four categories of challenges in multi-turn conversations that are
not only common and realistic among current human-LLM interactions, but are
also challenging to all current frontier LLMs. All 4 challenges require
accurate instruction-following, context allocation, and in-context reasoning at
the same time. We also develop LLM as judge with instance-level rubrics to
facilitate an automatic evaluation method with fair agreement with experienced
human raters. Despite achieving near-perfect scores on existing multi-turn
evaluation benchmarks, all frontier models have less than 50% accuracy on
MultiChallenge, with the top-performing Claude 3.5 Sonnet (June 2024) achieving
just a 41.4% average accuracy.

æè¦ï¼æåæåº MultiChallengeï¼ä¸åéåµæ§çåºæºï¼ç¨æ¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) èäººé¡ä½¿ç¨èé²è¡å¤è¼ªå°è©±çè½åï¼éæ¯ä¸åå°å¶æç¨è³ééè¦ä½å°æªååæ¢è¨çè½åãMultiChallenge è­å¥åºå¤è¼ªå°è©±ä¸­çåç¨®é¡å¥ææ°ï¼éäºææ°ä¸åå¨ç¶åäººé¡è LLM çäºåä¸­å¸¸è¦ä¸çå¯¦ï¼èä¸å°æ¼ææç¶åçåæ²¿ LLM ä¾èªªä¹æ¯å·æææ°æ§çãææ 4 åææ°åæéè¦æºç¢ºçæä»¤éµå¾ªãä¸ä¸æåéåä¸ä¸ææ¨çãæåééç¼äºå·æä¾é ç´å¥è©åæ¨æºç LLM ä½çºè©å¯©ï¼ä»¥ä¿é²ä¸ç¨®èªåè©ä¼°æ¹æ³ï¼è©²æ¹æ³èç¶é©è±å¯çäººé¡è©åå¡éæå¬å¹³çä¸è´ãåç®¡å¨ç¾æçå¤è¼ªè©ä¼°åºæºä¸åå¾äºæ¥è¿å®ç¾çå¾åï¼ä½ææåæ²¿æ¨¡åå¨ MultiChallenge ä¸çæºç¢ºçé½ä½æ¼ 50%ï¼è¡¨ç¾æå¥½ç Claude 3.5 Sonnetï¼2024 å¹´ 6 æï¼åéå° 41.4% çå¹³åæºç¢ºçã

##### **Leveraging In-Context Learning and Retrieval-Augmented Generation for Automatic Question Generation in Educational Domains**
2501.17397v1 by Subhankar Maity, Aniket Deroy, Sudeshna Sarkar

Question generation in education is a time-consuming and cognitively
demanding task, as it requires creating questions that are both contextually
relevant and pedagogically sound. Current automated question generation methods
often generate questions that are out of context. In this work, we explore
advanced techniques for automated question generation in educational contexts,
focusing on In-Context Learning (ICL), Retrieval-Augmented Generation (RAG),
and a novel Hybrid Model that merges both methods. We implement GPT-4 for ICL
using few-shot examples and BART with a retrieval module for RAG. The Hybrid
Model combines RAG and ICL to address these issues and improve question
quality. Evaluation is conducted using automated metrics, followed by human
evaluation metrics. Our results show that both the ICL approach and the Hybrid
Model consistently outperform other methods, including baseline models, by
generating more contextually accurate and relevant questions.

æè¦ï¼å¨æè²ä¸­ç¢çåé¡æ¯ä¸é èæä¸èªç¥ä¸è¦æ±å¾é«çä»»åï¼å çºå®éè¦ç¢çå¨èçµ¡ä¸ç¸éä¸å¨æå­¸æ³ä¸åççé¡ç®ãç®åçèªåååé¡ç¢çæ¹æ³éå¸¸æç¢çèçµ¡ä¸ç¬¦çé¡ç®ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºå¨æè²èçµ¡ä¸­èªååç¢çåé¡çé²éæè¡ï¼éé»å¨æ¼èçµ¡å­¸ç¿ (ICL)ãæª¢ç´¢å¢å¼·ç¢ç (RAG) åä¸ååä½µéå©ç¨®æ¹æ³çæ°åæ··åæ¨¡åãæåå¯¦ä½äº GPT-4 ä¾é²è¡ ICLï¼ä½¿ç¨å°éçç¯ä¾ï¼ä»¥å BART å ä¸æª¢ç´¢æ¨¡çµä¾é²è¡ RAGãæ··åæ¨¡åçµåäº RAG å ICL ä¾è§£æ±ºéäºåé¡ï¼ä¸¦æååé¡åè³ªãè©ä¼°æ¯ä½¿ç¨èªååææ¨é²è¡ï¼æ¥èæ¯äººå·¥è©ä¼°ææ¨ãæåççµæé¡¯ç¤ºï¼ICL æ¹æ³åæ··åæ¨¡åé½æçºåªæ¼å¶ä»æ¹æ³ï¼åæ¬åºæºæ¨¡åï¼ééç¢çæ´å¤èçµ¡ä¸æºç¢ºä¸ç¸éçé¡ç®ã

##### **Learning Free Token Reduction for Multi-Modal LLM**
2501.17391v1 by Zihui Zhao, Yingxin Li, Yang Li

Vision-Language Models (VLMs) have achieved remarkable success across a range
of multimodal tasks; however, their practical deployment is often constrained
by high computational costs and prolonged inference times. Since the vision
modality typically carries more information than the text modality, compressing
visual prompts offers a promising solution to alleviate these challenges.
Existing approaches predominantly focus on refining model architectures or
directly reducing the number of visual tokens. However, these methods often
compromise inference performance due to a lack of consideration for the unique
spatial and temporal characteristics of visual data. In this work, we propose a
token compression paradigm that operates on both spatial and temporal
dimensions. Our approach includes a learning-free, plug-and-play compression
pipeline that can be seamlessly integrated into most Multimodal Large Language
Model (MLLM) frameworks. By leveraging this method, we enhance the model
inference capability while simultaneously reducing its computational cost.
Experimental results on the Video-QA task demonstrate the effectiveness of the
proposed approach, showcasing significant improvements in efficiency without
sacrificing performance.

æè¦ï¼è¦è¦ºèªè¨æ¨¡å (VLM) å·²å¨åç¨®å¤æ¨¡æä»»åä¸­åå¾é¡¯èçæåï¼ç¶èï¼å¶å¯¦éé¨ç½²éå¸¸åå°é«éç®ææ¬åå»¶é·çæ¨è«æéçéå¶ãç±æ¼è¦è¦ºæ¨¡æéå¸¸æ¯æå­æ¨¡ææ¿è¼æ´å¤è³è¨ï¼å æ­¤å£ç¸®è¦è¦ºæç¤ºæä¾äºä¸åæå¸æçè§£æ±ºæ¹æ¡ä¾ç·©è§£éäºææ°ãç¾æçæ¹æ³ä¸»è¦éä¸­æ¼åªåæ¨¡åæ¶æ§æç´æ¥æ¸å°è¦è¦ºä»£ç¢¼çæ¸éãç¶èï¼éäºæ¹æ³ç±æ¼æ²æèæ®è¦è¦ºè³æçç¨ç¹ç©ºéåæéç¹å¾µï¼å æ­¤å¸¸å¸¸æå½±é¿æ¨è«æè½ãå¨éé å·¥ä½ä¸­ï¼æåæåºä¸åå¨ç©ºéåæéç¶­åº¦ä¸éä½çä»£ç¢¼å£ç¸®ç¯ä¾ãæåçåæ³åæ¬ä¸ååå­¸ç¿ãå³æå³ç¨çå£ç¸®ç®¡ç·ï¼å¯ä»¥ç¡ç¸«æ´åå°å¤§å¤æ¸å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) æ¡æ¶ä¸­ãééå©ç¨éç¨®æ¹æ³ï¼æåå¢å¼·äºæ¨¡åæ¨è«è½åï¼åæéä½äºå¶éç®ææ¬ãè¦è¨åç­ä»»åçå¯¦é©çµæè­æäºææåºæ¹æ³çæææ§ï¼å±ç¤ºäºå¨ä¸ç§ç²æè½çææ³ä¸é¡¯èæåæçã

##### **Context-Aware Semantic Recomposition Mechanism for Large Language Models**
2501.17386v1 by Richard Katrix, Quentin Carroway, Rowan Hawkesbury, Matthias Heathfield

Context-aware processing mechanisms have increasingly become a critical area
of exploration for improving the semantic and contextual capabilities of
language generation models. The Context-Aware Semantic Recomposition Mechanism
(CASRM) was introduced as a novel framework designed to address limitations in
coherence, contextual adaptability, and error propagation in large-scale text
generation tasks. Through the integration of dynamically generated context
vectors and attention modulation layers, CASRM enhances the alignment between
token-level representations and broader contextual dependencies. Experimental
evaluations demonstrated significant improvements in semantic coherence across
multiple domains, including technical, conversational, and narrative text. The
ability to adapt to unseen domains and ambiguous inputs was evaluated using a
diverse set of test scenarios, highlighting the robustness of the proposed
mechanism. A detailed computational analysis revealed that while CASRM
introduces additional processing overhead, the gains in linguistic precision
and contextual relevance outweigh the marginal increase in complexity. The
framework also successfully mitigates error propagation in sequential tasks,
improving performance in dialogue continuation and multi-step text synthesis.
Additional investigations into token-level attention distribution emphasized
the dynamic focus shifts enabled through context-aware enhancements. The
findings suggest that CASRM offers a scalable and flexible solution for
integrating contextual intelligence into existing language model architectures.

æè¦ï¼è¯­å¢æç¥å¤çæºå¶å·²éæ¸æä¸ºæ¢ç´¢æ¹åè¯­è¨çææ¨¡åè¯­ä¹åè¯­å¢åè½çå³é®é¢åãè¯­å¢æç¥è¯­ä¹éç»æºå¶ (CASRM) ä½ä¸ºä¸ç§æ°é¢çæ¡æ¶è¢«å¼å¥ï¼æ¨å¨è§£å³å¤§è§æ¨¡ææ¬çæä»»å¡ä¸­çè¿è´¯æ§ãè¯­å¢éåºæ§åéè¯¯ä¼ æ­çå±éæ§ãéè¿æ´åå¨æçæçè¯­å¢åéåæ³¨æåè°èå±ï¼CASRM å¢å¼ºäºæ è®°çº§è¡¨å¾åæ´å¹¿æ³çè¯­å¢ä¾èµæ§ä¹é´çå¯¹é½ãå®éªè¯ä¼°è¡¨æï¼å¨åæ¬ææ¯æ§ãä¼è¯æ§ååè¿°æ§ææ¬å¨åçå¤ä¸ªé¢åä¸­ï¼è¯­ä¹è¿è´¯æ§é½ææ¾èæé«ãä½¿ç¨åç§æµè¯åºæ¯è¯ä¼°äºéåºæªè§é¢ååæ¨¡æ£±ä¸¤å¯è¾å¥çè½åï¼çªåºäºææåºæºå¶çç¨³å¥æ§ãè¯¦ç»çè®¡ç®åæè¡¨æï¼è½ç¶ CASRM å¼å¥äºé¢å¤çå¤çå¼éï¼ä½è¯­è¨ç²¾ç¡®æ§åè¯­å¢ç¸å³æ§çæåè¶è¿äºå¤ææ§çè¾¹éå¢å ãè¯¥æ¡æ¶è¿æååè½»äºé¡ºåºä»»å¡ä¸­çéè¯¯ä¼ æ­ï¼æé«äºå¯¹è¯å»¶ç»­åå¤æ­¥ææ¬åæçæ§è½ãå¯¹æ è®°çº§æ³¨æååå¸çè¿ä¸æ­¥ç ç©¶å¼ºè°äºéè¿è¯­å¢æç¥å¢å¼ºå®ç°çå¨æç¦ç¹è½¬ç§»ãç ç©¶ç»æè¡¨æï¼CASRM ä¸ºå°è¯­å¢æºè½éæå°ç°æè¯­è¨æ¨¡åæ¶æä¸­æä¾äºä¸ç§å¯æ©å±ä¸çµæ´»çè§£å³æ¹æ¡ã

##### **A Dual-Agent Adversarial Framework for Robust Generalization in Deep Reinforcement Learning**
2501.17384v1 by Zhengpeng Xie, Jiahang Cao, Yulong Zhang, Qiang Zhang, Renjing Xu

Recently, empowered with the powerful capabilities of neural networks,
reinforcement learning (RL) has successfully tackled numerous challenging
tasks. However, while these models demonstrate enhanced decision-making
abilities, they are increasingly prone to overfitting. For instance, a trained
RL model often fails to generalize to even minor variations of the same task,
such as a change in background color or other minor semantic differences. To
address this issue, we propose a dual-agent adversarial policy learning
framework, which allows agents to spontaneously learn the underlying semantics
without introducing any human prior knowledge. Specifically, our framework
involves a game process between two agents: each agent seeks to maximize the
impact of perturbing on the opponent's policy by producing representation
differences for the same state, while maintaining its own stability against
such perturbations. This interaction encourages agents to learn generalizable
policies, capable of handling irrelevant features from the high-dimensional
observations. Extensive experimental results on the Procgen benchmark
demonstrate that the adversarial process significantly improves the
generalization performance of both agents, while also being applied to various
RL algorithms, e.g., Proximal Policy Optimization (PPO). With the adversarial
framework, the RL agent outperforms the baseline methods by a significant
margin, especially in hard-level tasks, marking a significant step forward in
the generalization capabilities of deep reinforcement learning.

æè¦ï¼<paragraph>è¿æï¼å¨ç¥ç»ç¶²è·¯å¼·å¤§åè½çå æä¸ï¼å¼·åå­¸ç¿ (RL) å·²æåè§£æ±ºè¨±å¤å·æææ°æ§çä»»åãç¶èï¼åç®¡éäºæ¨¡åå±ç¾åºå¢å¼·çæ±ºç­è½åï¼å®åå»è¶ä¾è¶å®¹æéåº¦æ¬åãä¾å¦ï¼è¨ç·´éç RL æ¨¡åéå¸¸ç¡æ³æ¦æ¬å°åä¸åä»»åçå¾®å°è®åï¼ä¾å¦èæ¯é¡è²çæ¹è®æå¶ä»ç´°å¾®çèªç¾©å·®ç°ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åéä»£çå°æç­ç¥å­¸ç¿æ¡æ¶ï¼è©²æ¡æ¶åè¨±ä»£çèªåå­¸ç¿åºç¤èªç¾©ï¼èç¡éå¼å¥ä»»ä½äººé¡åé©ç¥è­ãå·é«ä¾èªªï¼æåçæ¡æ¶æ¶åå©åä»£çä¹éçéæ²éç¨ï¼æ¯åä»£çé½è©¦åééç¢çç¸åçæçè¡¨ç¤ºå·®ç°ä¾æå¤§åå°å°æç­ç¥çæ¾åå½±é¿ï¼åæä¿æå¶èªèº«å°éäºæ¾åçç©©å®æ§ãéç¨®äº¤äºä½ç¨é¼åµä»£çå­¸ç¿å¯æ¦æ¬çç­ç¥ï¼è½å¤ èçé«ç¶­åº¦è§å¯ä¸­çç¡éç¹å¾µãå¨ Procgen åºæºä¸çå»£æ³å¯¦é©çµæè¡¨æï¼å°æéç¨é¡¯èæé«äºå©åä»£ççæ³åæè½ï¼åæä¹æç¨æ¼åç¨® RL æ¼ç®æ³ï¼ä¾å¦è¿ç«¯ç­ç¥æä½³å (PPO)ãæäºå°ææ¡æ¶ï¼RL ä»£ççè¡¨ç¾é¡¯èåªæ¼åºæºæ¹æ³ï¼ç¹å¥æ¯å¨é«é£åº¦ä»»åä¸­ï¼æ¨èªèæ·±åº¦å¼·åå­¸ç¿çæ³åè½åååéé²äºä¸å¤§æ­¥ã</paragraph>

##### **Forecasting S&P 500 Using LSTM Models**
2501.17366v1 by Prashant Pilla, Raji Mekonen

With the volatile and complex nature of financial data influenced by external
factors, forecasting the stock market is challenging. Traditional models such
as ARIMA and GARCH perform well with linear data but struggle with non-linear
dependencies. Machine learning and deep learning models, particularly Long
Short-Term Memory (LSTM) networks, address these challenges by capturing
intricate patterns and long-term dependencies. This report compares ARIMA and
LSTM models in predicting the S&P 500 index, a major financial benchmark.
  Using historical price data and technical indicators, we evaluated these
models using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). The
ARIMA model showed reasonable performance with an MAE of 462.1, RMSE of 614,
and 89.8 percent accuracy, effectively capturing short-term trends but limited
by its linear assumptions. The LSTM model, leveraging sequential processing
capabilities, outperformed ARIMA with an MAE of 369.32, RMSE of 412.84, and
92.46 percent accuracy, capturing both short- and long-term dependencies.
Notably, the LSTM model without additional features performed best, achieving
an MAE of 175.9, RMSE of 207.34, and 96.41 percent accuracy, showcasing its
ability to handle market data efficiently.
  Accurately predicting stock movements is crucial for investment strategies,
risk assessments, and market stability. Our findings confirm the potential of
deep learning models in handling volatile financial data compared to
traditional ones. The results highlight the effectiveness of LSTM and suggest
avenues for further improvements. This study provides insights into financial
forecasting, offering a comparative analysis of ARIMA and LSTM while outlining
their strengths and limitations.

æè¦ï¼<paragraph>ç±æ¼éèè³ææåå°å¤é¨å ç´ å½±é¿ï¼ä¸æ³¢åä¸è¤éï¼é æ¸¬è¡å¸æ¯ä¸é ææ°ãå³çµ±æ¨¡åï¼ä¾å¦ ARIMA å GARCHï¼å°æ¼ç·æ§è³æè¡¨ç¾è¯å¥½ï¼ä½å°æ¼éç·æ§ä¾è³´æ§åæå°é£ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ç¹å¥æ¯é·ç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼ééææè¤éæ¨¡å¼åé·æä¾è³´æ§ä¾è§£æ±ºéäºææ°ãæ­¤å ±åæ¯è¼äº ARIMA å LSTM æ¨¡åå¨é æ¸¬ä¸»è¦éèåºæºæ¨æ® 500 ææ¸çè¡¨ç¾ãæåä½¿ç¨æ­·å²å¹æ ¼è³æåæè¡ææ¨ï¼ä½¿ç¨å¹³åçµå°èª¤å·® (MAE) ååæ¹æ ¹èª¤å·® (RMSE) è©ä¼°éäºæ¨¡åãARIMA æ¨¡åè¡¨ç¾åçï¼MAE çº 462.1ï¼RMSE çº 614ï¼æºç¢ºççº 89.8%ï¼ææææç­æè¶¨å¢ï¼ä½åå°å¶ç·æ§åè¨­çéå¶ãLSTM æ¨¡åå©ç¨é åºèçè½åï¼è¡¨ç¾åªæ¼ ARIMAï¼MAE çº 369.32ï¼RMSE çº 412.84ï¼æºç¢ºççº 92.46%ï¼ææç­æåé·æä¾è³´æ§ãå¼å¾æ³¨æçæ¯ï¼æ²æé¡å¤åè½ç LSTM æ¨¡åè¡¨ç¾æä½³ï¼MAE çº 175.9ï¼RMSE çº 207.34ï¼æºç¢ºççº 96.41%ï¼å±ç¤ºå¶ææèçå¸å ´è³æçè½åãæºç¢ºé æ¸¬è¡ç¥¨èµ°å¢å°æ¼æè³ç­ç¥ãé¢¨éªè©ä¼°åå¸å ´ç©©å®è³ééè¦ãæåçç ç©¶çµæè­å¯¦äºæ·±åº¦å­¸ç¿æ¨¡åå¨èçæ³¢åçéèè³ææ¹é¢çæ½åï¼åªæ¼å³çµ±æ¨¡åãçµæçªé¡¯äº LSTM çæææ§ï¼ä¸¦å»ºè­°é²ä¸æ­¥æ¹é²çéå¾ãæ¬ç ç©¶æä¾äºå°éèé æ¸¬çè¦è§£ï¼æä¾äº ARIMA å LSTM çæ¯è¼åæï¼åææ¦è¿°äºå®åçåªé»åç¼ºé»ã</paragraph>

##### **The M-factor: A Novel Metric for Evaluating Neural Architecture Search in Resource-Constrained Environments**
2501.17361v1 by Srikanth Thudumu, Hy Nguyen, Hung Du, Nhat Duong, Zafaryab Rasool, Rena Logothetis, Scott Barnett, Rajesh Vasa, Kon Mouzakis

Neural Architecture Search (NAS) aims to automate the design of deep neural
networks. However, existing NAS techniques often focus on maximising accuracy,
neglecting model efficiency. This limitation restricts their use in
resource-constrained environments like mobile devices and edge computing
systems. Moreover, current evaluation metrics prioritise performance over
efficiency, lacking a balanced approach for assessing architectures suitable
for constrained scenarios. To address these challenges, this paper introduces
the M-factor, a novel metric combining model accuracy and size. Four diverse
NAS techniques are compared: Policy-Based Reinforcement Learning, Regularised
Evolution, Tree-structured Parzen Estimator (TPE), and Multi-trial Random
Search. These techniques represent different NAS paradigms, providing a
comprehensive evaluation of the M-factor. The study analyses ResNet
configurations on the CIFAR-10 dataset, with a search space of 19,683
configurations. Experiments reveal that Policy-Based Reinforcement Learning and
Regularised Evolution achieved M-factor values of 0.84 and 0.82, respectively,
while Multi-trial Random Search attained 0.75, and TPE reached 0.67.
Policy-Based Reinforcement Learning exhibited performance changes after 39
trials, while Regularised Evolution optimised within 20 trials. The research
investigates the optimisation dynamics and trade-offs between accuracy and
model size for each strategy. Findings indicate that, in some cases, random
search performed comparably to more complex algorithms when assessed using the
M-factor. These results highlight how the M-factor addresses the limitations of
existing metrics by guiding NAS towards balanced architectures, offering
valuable insights for selecting strategies in scenarios requiring both
performance and efficiency.

æè¦ï¼ç¥ç¶æ¶æ§æå°ï¼NASï¼æ¨å¨èªååæ·±åº¦ç¥ç¶ç¶²è·¯çè¨­è¨ãç¶èï¼ç¾æç NAS æè¡éå¸¸å°æ³¨æ¼æå¤§åæºç¢ºåº¦ï¼èå¿½ç¥æ¨¡åæçãæ­¤éå¶æéå¶å®åå¨åè³æºéå¶çç°å¢ä¸­ä½¿ç¨ï¼ä¾å¦è¡åè£ç½®åéç·£éç®ç³»çµ±ãæ­¤å¤ï¼ç®åçè©ä¼°ææ¨åªåæ¼æççæè½ï¼ç¼ºä¹å¹³è¡¡çæ¹æ³ä¾è©ä¼°é©ç¨æ¼åéæå¢çæ¶æ§ãçºäºæå°éäºææ°ï¼æ¬æå¼å¥äº M å å­ï¼éæ¯ä¸åçµåæ¨¡åæºç¢ºåº¦åå¤§å°çæ°ææ¨ãæ¯è¼äºåç¨®ä¸åç NAS æè¡ï¼åºæ¼ç­ç¥çå¼·åå­¸ç¿ãæ­£ååæ¼åãæ¨¹ç Parzen ä¼°è¨å¨ (TPE) åå¤è©¦é©é¨æ©æå°ãéäºæè¡ä»£è¡¨ä¸åç NAS å¸ç¯ï¼æä¾äº M å å­çå¨é¢è©ä¼°ãæ¬ç ç©¶å¨ CIFAR-10 è³æéä¸åæäº ResNet çµæï¼å¶ä¸­æå°ç©ºéçº 19,683 åçµæãå¯¦é©è¡¨æï¼åºæ¼ç­ç¥çå¼·åå­¸ç¿åæ­£ååæ¼ååå¥éå° 0.84 å 0.82 ç M å å­å¼ï¼èå¤è©¦é©é¨æ©æå°éå° 0.75ï¼TPE éå° 0.67ãåºæ¼ç­ç¥çå¼·åå­¸ç¿å¨ 39 æ¬¡è©¦é©å¾è¡¨ç¾åºæè½è®åï¼èæ­£ååæ¼åå¨ 20 æ¬¡è©¦é©å§é²è¡æä½³åãç ç©¶èª¿æ¥äºæ¯åç­ç¥çæä½³ååæä»¥åæºç¢ºåº¦åæ¨¡åå¤§å°ä¹éçåæ¨ãç ç©¶çµæè¡¨æï¼å¨æäºææ³ä¸ï¼ä½¿ç¨ M å å­è©ä¼°æï¼é¨æ©æå°çè¡¨ç¾èæ´è¤éçæ¼ç®æ³ç¸ç¶ãéäºçµæçªåºäº M å å­å¦ä½ééå¼å° NAS æ¡ç¨å¹³è¡¡çæ¶æ§ä¾è§£æ±ºç¾æææ¨çéå¶ï¼çºå¨éè¦æè½åæççææ³ä¸é¸æç­ç¥æä¾æå¹å¼çè¦è§£ã

##### **On the Coexistence and Ensembling of Watermarks**
2501.17356v1 by Aleksandar Petrov, Shruti Agarwal, Philip H. S. Torr, Adel Bibi, John Collomosse

Watermarking, the practice of embedding imperceptible information into media
such as images, videos, audio, and text, is essential for intellectual property
protection, content provenance and attribution. The growing complexity of
digital ecosystems necessitates watermarks for different uses to be embedded in
the same media. However, to detect and decode all watermarks, they need to
coexist well with one another. We perform the first study of coexistence of
deep image watermarking methods and, contrary to intuition, we find that
various open-source watermarks can coexist with only minor impacts on image
quality and decoding robustness. The coexistence of watermarks also opens the
avenue for ensembling watermarking methods. We show how ensembling can increase
the overall message capacity and enable new trade-offs between capacity,
accuracy, robustness and image quality, without needing to retrain the base
models.

æè¦ï¼æ°´å°ï¼å°é£ä»¥å¯è¦ºçè³è¨åµå¥åªé«ï¼ä¾å¦åçãå½±çãé³è¨åæå­ï¼ä¸­çåæ³ï¼å°æ¼æºæ§è²¡ç¢ä¿è­·ãå§å®¹åºèåæ­¸å±¬è³ééè¦ãæ¸ä½çæç³»çµ±æ¥çè¤éï¼éè¦å°ä¸åç¨éçæ°´å°åµå¥åä¸åªé«ä¸­ãç¶èï¼è¦åµæ¸¬åè§£ç¢¼æææ°´å°ï¼å®åéè¦å½¼æ­¤è¯å¥½å±å­ãæåå·è¡æ·±åº¦å½±åæ°´å°æ¹æ³çå±å­é¦æ¬¡ç ç©¶ï¼èç´è¦ºç¸åï¼æåç¼ç¾åç¨®éæºæ°´å°å¯ä»¥å±å­ï¼å°å½±ååè³ªåè§£ç¢¼ç©©å¥æ§åé æè¼å¾®å½±é¿ãæ°´å°çå±å­ä¹éåäºæ´åæ°´å°æ¹æ³çéå¾ãæåå±ç¤ºäºæ´åå¦ä½å¢å æ´é«è¨æ¯å®¹éï¼ä¸¦å¨å®¹éãæºç¢ºåº¦ãç©©å¥æ§åå½±ååè³ªä¹éå¯¦ç¾æ°çæ¬è¡¡ï¼èç¡ééæ°è¨ç·´åºç¤æ¨¡åã

##### **Better Slow than Sorry: Introducing Positive Friction for Reliable Dialogue Systems**
2501.17348v1 by Mert Ä°nan, Anthony Sicilia, Suvodip Dey, Vardhan Dongre, Tejas Srinivasan, Jesse Thomason, GÃ¶khan TÃ¼r, Dilek Hakkani-TÃ¼r, Malihe Alikhani

While theories of discourse and cognitive science have long recognized the
value of unhurried pacing, recent dialogue research tends to minimize friction
in conversational systems. Yet, frictionless dialogue risks fostering
uncritical reliance on AI outputs, which can obscure implicit assumptions and
lead to unintended consequences. To meet this challenge, we propose integrating
positive friction into conversational AI, which promotes user reflection on
goals, critical thinking on system response, and subsequent re-conditioning of
AI systems. We hypothesize systems can improve goal alignment, modeling of user
mental states, and task success by deliberately slowing down conversations in
strategic moments to ask questions, reveal assumptions, or pause. We present an
ontology of positive friction and collect expert human annotations on
multi-domain and embodied goal-oriented corpora. Experiments on these corpora,
along with simulated interactions using state-of-the-art systems, suggest
incorporating friction not only fosters accountable decision-making, but also
enhances machine understanding of user beliefs and goals, and increases task
success rates.

æè¦ï¼åç®¡è«è¿°çè«åèªç¥ç§å­¸æ©å·²èªç¥å°æ¾æ¢æ­¥èª¿çå¹å¼ï¼æè¿çå°è©±ç ç©¶å¾åæ¼æå°åå°è©±ç³»çµ±ä¸­çæ©æ¦ãç¶èï¼ç¡æ©æ¦çå°è©±æå°è´éåº¦ä¾è³´ AI è¼¸åºçé¢¨éªï¼èéå¯è½ææ¨¡ç³é±å«çåè¨­ä¸¦å°è´æå¤çå¾æãçºäºæå°éé ææ°ï¼æåå»ºè­°å°æ­£åæ©æ¦æ´åå°å°è©±å¼ AI ä¸­ï¼éæä¿é²ä½¿ç¨èåæç®æ¨ãå°ç³»çµ±åæé²è¡æ¹å¤æ§æèï¼ä»¥åå¾çºå° AI ç³»çµ±é²è¡éæ°èª¿æ´ãæååè¨­ç³»çµ±å¯ä»¥ééå¨ç­ç¥æ§æå»æææ¾æ¢å°è©±éåº¦ä¾è©¢ååé¡ãæ­é²åè¨­ææ«åï¼é²èæ¹åç®æ¨å°é½ãå°ä½¿ç¨èå¿æºçæå»ºæ¨¡ï¼ä»¥åä»»åæåçãæåæåºæ­£åæ©æ¦çæ¬é«è«ï¼ä¸¦å¨å¤é ååå·é«ç®æ¨å°åçèªæåº«ä¸æ¶éå°å®¶çäººé¡è¨»è§£ãéå°éäºèªæåº«çå¯¦é©ï¼ä»¥åä½¿ç¨æåé²ç³»çµ±é²è¡çæ¨¡æ¬äºåï¼è¡¨æç´å¥æ©æ¦ä¸åè½ä¿é²è² è²¬ä»»çæ±ºç­å¶å®ï¼éè½å¢é²æ©å¨å°ä½¿ç¨èä¿¡å¿µåç®æ¨ççè§£ï¼ä¸¦æé«ä»»åæåçã

##### **Deep-and-Wide Learning: Enhancing Data-Driven Inference via Synergistic Learning of Inter- and Intra-Data Representations**
2501.17347v1 by Md Tauhidul Islam, Lei Xing

Advancements in deep learning are revolutionizing science and engineering.
The immense success of deep learning is largely due to its ability to extract
essential high-dimensional (HD) features from input data and make inference
decisions based on this information. However, current deep neural network (DNN)
models face several challenges, such as the requirements of extensive amounts
of data and computational resources. Here, we introduce a new learning scheme,
referred to as deep-and-wide learning (DWL), to systematically capture features
not only within individual input data (intra-data features) but also across the
data (inter-data features). Furthermore, we propose a dual-interactive-channel
network (D-Net) to realize the DWL, which leverages our Bayesian formulation of
low-dimensional (LD) inter-data feature extraction and its synergistic
interaction with the conventional HD representation of the dataset, for
substantially enhanced computational efficiency and inference. The proposed
technique has been applied to data across various disciplines for both
classification and regression tasks. Our results demonstrate that DWL surpasses
state-of-the-art DNNs in accuracy by a substantial margin with limited training
data and improves the computational efficiency by order(s) of magnitude. The
proposed DWL strategy dramatically alters the data-driven learning techniques,
including emerging large foundation models, and sheds significant insights into
the evolving field of AI.

æè¦ï¼æ·±åº¦å­¸ç¿çé²å±æ­£å¨é©æ°ç§å­¸åå·¥ç¨ã
æ·±åº¦å­¸ç¿çå·¨å¤§æåå¨å¾å¤§ç¨åº¦ä¸æ­¸åæ¼å®å¾è¼¸å¥æ¸æä¸­æåæ¬è³ªé«ç¶­ï¼HDï¼ç¹å¾µä¸¦åºæ¼æ­¤ä¿¡æ¯ååºæ¨è«æ±ºç­çè½åãç¶èï¼ç¶åçæ·±åº¦ç¥ç¶ç¶²è·¯ï¼DNNï¼æ¨¡åé¢è¨èè«¸å¤ææ°ï¼ä¾å¦å°å¤§éæ¸æåè¨ç®è³æºçéæ±ãå¨æ­¤ï¼æåå¼å¥äºä¸ç¨®æ°çå­¸ç¿æ¹æ¡ï¼ç¨±çºæ·±åº¦å»£åº¦å­¸ç¿ï¼DWLï¼ï¼ä»¥ç³»çµ±å°æç²ç¹å¾µï¼ä¸åå¨åå¥è¼¸å¥æ¸æï¼æ¸æå§ç¹å¾µï¼ä¸­ï¼èä¸å¨æ¸æï¼æ¸æéç¹å¾µï¼ä¸­ãæ­¤å¤ï¼æåæåºäºä¸åéäºåééç¶²è·¯ï¼D-Netï¼ä¾å¯¦ç¾ DWLï¼å®å©ç¨æåå°ä½ç¶­ï¼LDï¼æ¸æéç¹å¾µæåçè²èæ¯å¬å¼åå¶èæ¸æéçå³çµ± HD è¡¨ç¤ºçååäº¤äºä½ç¨ï¼ä»¥å¤§å¹æé«è¨ç®æçåæ¨çãææåºçæè¡å·²æç¨æ¼ååå­¸ç§çæ¸æï¼ç¨æ¼åé¡ååæ­¸ä»»åãæåççµæè¡¨æï¼DWL å¨æºç¢ºæ§æ¹é¢ä»¥å¤§å¹åªå¢è¶è¶äºæåé²ç DNNï¼ä¸è¨ç·´æ¸ææéï¼ä¸¦å°è¨ç®æçæé«äºå¹¾åæ¸éç´ãææåºç DWL ç­ç¥æ¥µå¤§å°æ¹è®äºæ¸æé©åçå­¸ç¿æè¡ï¼åæ¬æ°èçå¤§ååºç¤æ¨¡åï¼ä¸¦å°äººå·¥æºè½çæ¼é²é åæä¾äºéè¦çè¦è§£ã

##### **Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines**
2501.17343v1 by Chongyu Qu, Ritchie Zhao, Ye Yu, Bin Liu, Tianyuan Yao, Junchao Zhu, Bennett A. Landman, Yucheng Tang, Yuankai Huo

Quantizing deep neural networks ,reducing the precision (bit-width) of their
computations, can remarkably decrease memory usage and accelerate processing,
making these models more suitable for large-scale medical imaging applications
with limited computational resources. However, many existing methods studied
"fake quantization", which simulates lower precision operations during
inference, but does not actually reduce model size or improve real-world
inference speed. Moreover, the potential of deploying real 3D low-bit
quantization on modern GPUs is still unexplored. In this study, we introduce a
real post-training quantization (PTQ) framework that successfully implements
true 8-bit quantization on state-of-the-art (SOTA) 3D medical segmentation
models, i.e., U-Net, SegResNet, SwinUNETR, nnU-Net, UNesT, TransUNet,
ST-UNet,and VISTA3D. Our approach involves two main steps. First, we use
TensorRT to perform fake quantization for both weights and activations with
unlabeled calibration dataset. Second, we convert this fake quantization into
real quantization via TensorRT engine on real GPUs, resulting in real-world
reductions in model size and inference latency. Extensive experiments
demonstrate that our framework effectively performs 8-bit quantization on GPUs
without sacrificing model performance. This advancement enables the deployment
of efficient deep learning models in medical imaging applications where
computational resources are constrained. The code and models have been
released, including U-Net, TransUNet pretrained on the BTCV dataset for
abdominal (13-label) segmentation, UNesT pretrained on the Whole Brain Dataset
for whole brain (133-label) segmentation, and nnU-Net, SegResNet, SwinUNETR and
VISTA3D pretrained on TotalSegmentator V2 for full body (104-label)
segmentation. https://github.com/hrlblab/PTQ.

æè¦ï¼<paragraph>éåæ·±åº¦ç¥ç»ç½ç»ï¼éä½å¶è®¡ç®çç²¾åº¦ï¼ä½å®½ï¼ï¼å¯ä»¥æ¾èåå°åå­ä½¿ç¨éå¹¶å éå¤çï¼ä½¿è¿äºæ¨¡åæ´éåäºå·ææéè®¡ç®èµæºçå¤§è§æ¨¡å»å­¦å½±ååºç¨ãç¶èï¼è®¸å¤ç°ææ¹æ³ç ç©¶äºâä¼ªéåâï¼å®å¨æ¨çæé´æ¨¡æè¾ä½ç²¾åº¦çæä½ï¼ä½å®éä¸å¹¶æ²¡æåå°æ¨¡åå¤§å°ææé«å®éæ¨çéåº¦ãæ­¤å¤ï¼å¨ç°ä»£ GPU ä¸é¨ç½²çæ­£ç 3D ä½ä½éåçæ½åä»æªå¾å°æ¢ç´¢ãå¨è¿é¡¹ç ç©¶ä¸­ï¼æä»¬å¼å¥äºä¸ä¸ªçæ­£çè®­ç»åéå (PTQ) æ¡æ¶ï¼è¯¥æ¡æ¶æåå°å¨æåè¿ç (SOTA) 3D å»å­¦åå²æ¨¡åï¼å³ U-NetãSegResNetãSwinUNETRãnnU-NetãUNesTãTransUNetãST-UNet å VISTA3Dï¼ä¸å®ç°äºçæ­£ç 8 ä½éåãæä»¬çæ¹æ³æ¶åä¸¤ä¸ªä¸»è¦æ­¥éª¤ãé¦åï¼æä»¬ä½¿ç¨ TensorRT å¯¹æéåæ¿æ´»è¿è¡ä¼ªéåï¼å¹¶ä½¿ç¨æªæ è®°çæ ¡åæ°æ®éãå¶æ¬¡ï¼æä»¬å°è¿ç§ä¼ªéåéè¿çå® GPU ä¸ç TensorRT å¼æè½¬æ¢ä¸ºçæ­£çéåï¼ä»èå¨æ¨¡åå¤§å°åæ¨çå»¶è¿æ¹é¢å®ç°äºå®éçåå°ãå¤§éçå®éªè¡¨æï¼æä»¬çæ¡æ¶å¨ GPU ä¸ææå°æ§è¡ 8 ä½éåï¼èä¸ä¼çºç²æ¨¡åæ§è½ãè¿ä¸è¿æ­¥ä½¿å¾å¨è®¡ç®èµæºåéçå»å­¦å½±ååºç¨ä¸­é¨ç½²é«æçæ·±åº¦å­¦ä¹ æ¨¡åæä¸ºå¯è½ãä»£ç åæ¨¡åå·²ç»åå¸ï¼åæ¬ U-NetãTransUNETï¼å¨ BTCV æ°æ®éä¸é¢è®­ç»ç¨äºè¹é¨ï¼13 æ ç­¾ï¼åå²ï¼UNesT å¨ Whole Brain æ°æ®éä¸é¢è®­ç»ç¨äºå¨èï¼133 æ ç­¾ï¼åå²ï¼ä»¥å nnU-NetãSegResNetãSwinUNETR å VISTA3D å¨ TotalSegmentator V2 ä¸é¢è®­ç»ç¨äºå¨èº«ï¼104 æ ç­¾ï¼åå²ãhttps://github.com/hrlblab/PTQã</paragraph>

##### **Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection**
2501.17338v1 by Mingyu Derek Ma, Yanna Ding, Zijie Huang, Jianxi Gao, Yizhou Sun, Wei Wang

Generative Language Models rely on autoregressive decoding to produce the
output sequence token by token. Many tasks such as preference optimization,
require the model to produce task-level output consisting of multiple tokens
directly by selecting candidates from a pool as predictions. Determining a
task-level prediction from candidates using the ordinary token-level decoding
mechanism is constrained by time-consuming decoding and interrupted gradients
by discrete token selection. Existing works have been using decoding-free
candidate selection methods to obtain candidate probability from initial output
logits over vocabulary. Though these estimation methods are widely used, they
are not systematically evaluated, especially on end tasks. We introduce an
evaluation of a comprehensive collection of decoding-free candidate selection
approaches on a comprehensive set of tasks, including five multiple-choice QA
tasks with a small candidate pool and four clinical decision tasks with a
massive amount of candidates, some with 10k+ options. We evaluate the
estimation methods paired with a wide spectrum of foundation LMs covering
different architectures, sizes and training paradigms. The results and insights
from our analysis inform the future model design.

æè¦ï¼çæèªè¨æ¨¡åä¾é èªè¿´æ­¸è§£ç¢¼ä¾éåç¬¦èç¢çè¼¸åºåºåãè¨±å¤ä»»åï¼å¦åå¥½æä½³åï¼è¦æ±æ¨¡åç´æ¥å¾åé¸æ± ä¸­é¸æé æ¸¬ï¼ç¢çç±å¤åç¬¦èçµæçä»»åç´å¥è¼¸åºãä½¿ç¨ä¸è¬çç¬¦èç´å¥è§£ç¢¼æ©å¶å¾åé¸èä¸­ç¢ºå®ä»»åç´å¥é æ¸¬åå°èæçè§£ç¢¼åé¢æ£ç¬¦èé¸æä¸­æ·çæ¢¯åº¦çç´æãç¾æå·¥ä½ä¸ç´ä½¿ç¨ç¡è§£ç¢¼åé¸èé¸ææ¹æ³å¾åå§è¼¸åºéè¼¯å¼ä¸­ç²å¾åé¸èæ©çãåç®¡éäºä¼°è¨æ¹æ³è¢«å»£æ³ä½¿ç¨ï¼ä½å®åä¸¦æªç¶éç³»çµ±è©ä¼°ï¼ç¹å¥æ¯å¨æçµä»»åä¸ãæåéå°å¨é¢çä»»åéï¼åæ¬äºåå·æå°ååé¸èæ± çå¤é¸é¡åç­ä»»ååååå·æå¤§éåé¸èçè¨åºæ±ºç­ä»»åï¼å¶ä¸­ä¸äºæ 10k+ é¸é ï¼ï¼å°å¨é¢çç¡è§£ç¢¼åé¸èé¸ææ¹æ³é²è¡è©ä¼°ãæåè©ä¼°èå»£æ³åºç¤èªè¨æ¨¡åéå°çä¼°è¨æ¹æ³ï¼éäºæ¨¡åæ¶µèä¸åçæ¶æ§ãå¤§å°åè¨ç·´ç¯ä¾ãæååæççµæåè¦è§£çºæªä¾çæ¨¡åè¨­è¨æä¾äºè³è¨ã

##### **Attribution analysis of legal language as used by LLM**
2501.17330v1 by Richard K. Belew

Three publicly-available LLM specifically designed for legal tasks have been
implemented and shown that classification accuracy can benefit from training
over legal corpora, but why and how? Here we use two publicly-available legal
datasets, a simpler binary classification task of ``overruling'' texts, and a
more elaborate multiple choice task identifying ``holding'' judicial decisions.
We report on experiments contrasting the legal LLM and a generic BERT model for
comparison, against both datasets. We use integrated gradient attribution
techniques to impute ``causes'' of variation in the models' perfomance, and
characterize them in terms of the tokenizations each use. We find that while
all models can correctly classify some test examples from the casehold task,
other examples can only be identified by only one, model, and attribution can
be used to highlight the reasons for this. We find that differential behavior
of the models' tokenizers accounts for most of the difference and analyze these
differences in terms of the legal language they process. Frequency analysis of
tokens generated by dataset texts, combined with use of known ``stop word''
lists, allow identification of tokens that are clear signifiers of legal
topics.

æè¦ï¼æä¸åå°éè¨­è¨ç¨æ¼æ³å¾ä»»åçå¬é LLM å·²å¯¦æ½ï¼ä¸¦é¡¯ç¤ºåé¡æºç¢ºåº¦å¯ä»¥åçæ¼æ³å¾èªæåº«çè¨ç·´ï¼ä½åå åæ¹å¼çºä½ï¼å¨éè£¡ï¼æåä½¿ç¨å©åå¬éçæ³å¾è³æéï¼ä¸åè¼ç°¡å®çäºååé¡ä»»åãæ¨ç¿»ãææ¬ï¼ä»¥åä¸åæ´ç²¾ç´°çå¤é¸é¡ä»»åï¼ç¨æ¼è­å¥ãææãå¸æ³æ±ºå®ãæåå ±åäºå°æ¯æ³å¾ LLM åéç¨ BERT æ¨¡åçå¯¦é©ï¼ä»¥éå°éå©åè³æéé²è¡æ¯è¼ãæåä½¿ç¨æ´åæ¢¯åº¦æ­¸å æè¡ä¾ä¼°ç®æ¨¡åæè½è®åçãåå ãï¼ä¸¦æ ¹ææ¯åæ¨¡åä½¿ç¨çæ¨è¨åä¾æè¿°å®åãæåç¼ç¾ï¼éç¶æææ¨¡åé½å¯ä»¥æ­£ç¢ºåé¡æ¡ä¾ææä»»åä¸­çä¸äºæ¸¬è©¦ç¯ä¾ï¼ä½å¶ä»ç¯ä¾åªè½ç±ä¸åæ¨¡åè­å¥ï¼èæ­¸å å¯ç¨æ¼å¼·èª¿éæ¨£åçåå ãæåç¼ç¾ï¼æ¨¡åæ¨è¨å¨çå·®ç°è¡çºè§£éäºå¤§é¨åå·®ç°ï¼ä¸¦æ ¹æå®åèççæ³å¾èªè¨åæéäºå·®ç°ãè³æéææ¬ç¢ççæ¨è¨çé »çåæï¼çµåä½¿ç¨å·²ç¥çãåæ­¢è©ãæ¸å®ï¼å¯ä»¥è­å¥åºæ³å¾ä¸»é¡çæç¢ºæ¨è¨ã

##### **Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction**
2501.17326v1 by Mingyu Derek Ma, Xiaoxuan Wang, Yijia Xiao, Anthony Cuturrufo, Vijay S Nori, Eran Halperin, Wei Wang

Clinical diagnosis prediction models, when provided with a patient's medical
history, aim to detect potential diseases early, facilitating timely
intervention and improving prognostic outcomes. However, the inherent scarcity
of patient data and large disease candidate space often pose challenges in
developing satisfactory models for this intricate task. The exploration of
leveraging Large Language Models (LLMs) for encapsulating clinical decision
processes has been limited. We introduce MERA, a clinical diagnosis prediction
model that bridges pertaining natural language knowledge with medical practice.
We apply hierarchical contrastive learning on a disease candidate ranking list
to alleviate the large decision space issue. With concept memorization through
fine-tuning, we bridge the natural language clinical knowledge with medical
codes. Experimental results on MIMIC-III and IV datasets show that MERA
achieves the state-of-the-art diagnosis prediction performance and dramatically
elevates the diagnosis prediction capabilities of generative LMs.

æè¦ï¼è¨åºè¨ºæ·é æ¸¬æ¨¡åå¨æä¾æ£èçæ­·çåæï¼æ¨å¨åæ©ç¼ç¾æ½å¨ç¾çï¼ä¿é²åæå¹²é ä¸¦æ¹åé å¾çµæãç¶èï¼æ£èæ¸æçåºæç¨ç¼ºæ§åå¤§éçç¾çåé¸ç©ºééå¸¸å°éç¼ä»¤äººæ»¿æçæ¨¡åä»¥æå°éé è¤éçä»»åæ§æææ°ãå©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾å°è£è¨åºæ±ºç­æµç¨çæ¢ç´¢åå°éå¶ãæåå¼å¥äº MERAï¼éæ¯ä¸åè¨åºè¨ºæ·é æ¸¬æ¨¡åï¼å®å°ç¸éçèªç¶èªè¨ç¥è­èé«çå¯¦è¸è¯ç¹«èµ·ä¾ãæåå¨ç¾çåé¸æåæ¸å®ä¸æç¨åå±¤å°æ¯å­¸ç¿ï¼ä»¥ç·©è§£å¤§åæ±ºç­ç©ºéåé¡ãééå¾®èª¿æ¦å¿µè¨æ¶ï¼æåå°èªç¶èªè¨è¨åºç¥è­èé«çä»£ç¢¼è¯ç¹«èµ·ä¾ãå¨ MIMIC-III å IV æ¸æéä¸çå¯¦é©çµæè¡¨æï¼MERA éå°äºæåé²çè¨ºæ·é æ¸¬æ§è½ï¼ä¸¦é¡¯èæåäºçæå¼ LM çè¨ºæ·é æ¸¬è½åã

##### **A sketch of an AI control safety case**
2501.17315v1 by Tomek Korbak, Joshua Clymer, Benjamin Hilton, Buck Shlegeris, Geoffrey Irving

As LLM agents gain a greater capacity to cause harm, AI developers might
increasingly rely on control measures such as monitoring to justify that they
are safe. We sketch how developers could construct a "control safety case",
which is a structured argument that models are incapable of subverting control
measures in order to cause unacceptable outcomes. As a case study, we sketch an
argument that a hypothetical LLM agent deployed internally at an AI company
won't exfiltrate sensitive information. The sketch relies on evidence from a
"control evaluation,"' where a red team deliberately designs models to
exfiltrate data in a proxy for the deployment environment. The safety case then
hinges on several claims: (1) the red team adequately elicits model
capabilities to exfiltrate data, (2) control measures remain at least as
effective in deployment, and (3) developers conservatively extrapolate model
performance to predict the probability of data exfiltration in deployment. This
safety case sketch is a step toward more concrete arguments that can be used to
show that a dangerously capable LLM agent is safe to deploy.

æè¦ï¼é¨è LLM ä»£çé æå·å®³çè½åè¶ä¾è¶å¼·ï¼AI éç¼äººå¡å¯è½æè¶ä¾è¶ä¾è³´ç£æ§ç­æ§å¶æªæ½ä¾è­æå®åæ¯å®å¨çãæåæ¦è¿°éç¼äººå¡å¦ä½æ§å»ºãæ§å¶å®å¨æ¡ä¾ãï¼éæ¯ä¸åçµæ§åçè«è­ï¼èªªææ¨¡åç¡æ³é¡è¦æ§å¶æªæ½ä»¥é æä¸å¯æ¥åççµæãä½çºä¸åæ¡ä¾ç ç©¶ï¼æåæ¦è¿°äºä¸åè«è­ï¼å³å¨ AI å¬å¸å§é¨é¨ç½²çåè¨­ LLM ä»£çä¸ææ´©é²ææè³è¨ãéåæ¦è¦ä¾è³´æ¼ãæ§å¶è©ä¼°ãçè­æï¼å¶ä¸­ä¸åç´è²å°çµææè¨­è¨æ¨¡åä¾å¨é¨ç½²ç°å¢çä»£çä¸­æ´©é²è³æãå®å¨æ¡ä¾æ¥èä¾è³´æ¼å¹¾åä¸»å¼µï¼(1) ç´è²å°çµååå¼åºæ¨¡åæ´©é²è³æçè½åï¼(2) æ§å¶æªæ½å¨é¨ç½²ä¸­è³å°ç¶­æåæ¨£çæåï¼ä»¥å (3) éç¼äººå¡ä¿å®å°æ¨æ·æ¨¡åæè½ä»¥é æ¸¬è³æå¨é¨ç½²ä¸­å¤æ´©çæ©çãéåå®å¨æ¡ä¾æ¦è¦æ¯æåæ´å·é«çè«è­éé²çä¸æ­¥ï¼å¯ç¨æ¼è­æå·æå±éªè½åç LLM ä»£çé¨ç½²æ¯å®å¨çã

##### **Probing LLM World Models: Enhancing Guesstimation with Wisdom of Crowds Decoding**
2501.17310v1 by Yun-Shiuan Chuang, Nikunj Harlalka, Sameer Narendran, Alexander Cheung, Sizhe Gao, Siddharth Suresh, Junjie Hu, Timothy T. Rogers

Guesstimation, the task of making approximate quantity estimates, is a common
real-world challenge. However, it has been largely overlooked in large language
models (LLMs) and vision language models (VLMs) research. We introduce a novel
guesstimation dataset, MARBLES. This dataset requires one to estimate how many
items (e.g., marbles) can fit into containers (e.g., a one-cup measuring cup),
both with and without accompanying images. Inspired by the social science
concept of the ``{Wisdom of Crowds'' (WOC) - taking the median from estimates
from a crowd), which has proven effective in guesstimation, we propose ``WOC
decoding'' strategy for LLM guesstimation. We show that LLMs/VLMs perform well
on guesstimation, suggesting that they possess some level of a "world model"
necessary for guesstimation. Moreover, similar to human performance, the WOC
decoding method improves LLM/VLM guesstimation accuracy. Furthermore, the
inclusion of images in the multimodal condition enhances model performance.
These results highlight the value of WOC decoding strategy for LLMs/VLMs and
position guesstimation as a probe for evaluating LLMs/VLMs' world model.

æè¦ï¼ä¼°è¨ï¼å³é²è¡è¿ä¼¼æ¸éä¼°è¨çä»»åï¼æ¯ä¸åå¸¸è¦ç
ç¾å¯¦ä¸çææ°ãç¶èï¼å®å¨å¤§åèªè¨æ¨¡å (LLM) åè¦è¦ºèªè¨æ¨¡å (VLM) ç ç©¶ä¸­å¾å¤§ç¨åº¦ä¸è¢«å¿½è¦äºãæåå¼å¥äºä¸åæ°ç©çä¼°è¨æ¸æéï¼MARBLESãæ­¤æ¸æéè¦æ±äººåä¼°è¨æå¤å°
ç©åï¼ä¾å¦ï¼å½ç ï¼å¯ä»¥æ¾å¥å®¹å¨ï¼ä¾å¦ï¼ä¸åéæ¯ï¼ï¼ç¡è«æ¯å¦éæåçãåç¤¾æç§å­¸æ¦å¿µ``{ç¾¤ç¾çæºæ§'' (WOC) çåç¼ - å¾äººç¾¤çä¼°è¨ä¸­åä¸­ä½æ¸ï¼ï¼éå·²è¢«è­æå¨ä¼°è¨ä¸­å¾ææï¼æåæåºäº LLM ä¼°è¨ç``WOC
è§£ç¢¼''ç­ç¥ãæåè¡¨æ LLM/VLM å¨ä¼°è¨æ¹é¢è¡¨ç¾è¯å¥½ï¼éè¡¨æå®åå·æä¸å®çä¼°è¨æéçãä¸çæ¨¡åããæ­¤å¤ï¼èäººé¡è¡¨ç¾é¡ä¼¼ï¼WOC
è§£ç¢¼æ¹æ³æé«äº LLM/VLM çä¼°è¨æºç¢ºåº¦ãæ­¤å¤ï¼å¨å¤æ¨¡ææ¢ä»¶ä¸­åå«ååå¯ä»¥å¢å¼·æ¨¡åæ§è½ã
éäºçµæçªåºäº WOC è§£ç¢¼ç­ç¥å° LLM/VLM çå¹å¼ï¼ä¸¦å°ä¼°è¨å®ä½çºè©ä¼° LLM/VLM ä¸çæ¨¡åçæ¢éã

##### **"Ownership, Not Just Happy Talk": Co-Designing a Participatory Large Language Model for Journalism**
2501.17299v1 by Emily Tseng, Meg Young, Marianne Aubin Le QuÃ©rÃ©, Aimee Rinehart, Harini Suresh

Journalism has emerged as an essential domain for understanding the uses,
limitations, and impacts of large language models (LLMs) in the workplace. News
organizations face divergent financial incentives: LLMs already permeate
newswork processes within financially constrained organizations, even as
ongoing legal challenges assert that AI companies violate their copyright. At
stake are key questions about what LLMs are created to do, and by whom: How
might a journalist-led LLM work, and what can participatory design illuminate
about the present-day challenges about adapting ``one-size-fits-all''
foundation models to a given context of use? In this paper, we undertake a
co-design exploration to understand how a participatory approach to LLMs might
address opportunities and challenges around AI in journalism. Our 20 interviews
with reporters, data journalists, editors, labor organizers, product leads, and
executives highlight macro, meso, and micro tensions that designing for this
opportunity space must address. From these desiderata, we describe the result
of our co-design work: organizational structures and functionality for a
journalist-controlled LLM. In closing, we discuss the limitations of commercial
foundation models for workplace use, and the methodological implications of
applying participatory methods to LLM co-design.

æè¦ï¼æ°èæ¥­å·²æµ®ç¾çºçè§£å¤§åèªè¨æ¨¡å (LLM) å¨å·¥ä½å ´æä¸­çç¨éãéå¶åå½±é¿çå¿è¦é åãæ°èçµç¹é¢è¨ä¸åçè²¡åèªå ï¼LLM å·²æ»²éå°è²¡ååéçµç¹çæ°èå·¥ä½æµç¨ä¸­ï¼å³ä½¿æçºçæ³å¾ææ°è²ç¨± AI å¬å¸ä¾µç¯å¶çæ¬ãééµåé¡å¨æ¼ LLM æ¯çºä½èçï¼åæ¯ç±èª°åµé ï¼è¨èä¸»å°ç LLM å¦ä½éä½ï¼ä»¥ååèå¼è¨­è¨å¯ä»¥æ­ç¤ºåªäºéæ¼é©æãä¸é«é©ç¨ãåºç¤æ¨¡åå°ç¹å®ä½¿ç¨æå¢ä¸­çç¶åææ°ï¼å¨æ¬æä¸­ï¼æåé²è¡å±åè¨­è¨æ¢ç´¢ï¼ä»¥äºè§£åèå¼ LLM æ¹æ³å¦ä½è§£æ±ºæ°èæ¥­ä¸­è AI ç¸éçæ©æåææ°ãæåå°è¨èãæ¸æè¨èãç·¨è¼¯ãåå·¥çµç¹èãç¢åè² è²¬äººåä¸»ç®¡é²è¡ç 20 æ¬¡è¨ªè«ï¼çªé¡¯äºçºéåæ©æç©ºéè¨­è¨æå¿é è§£æ±ºçå·¨è§ãä¸­è§åå¾®è§ç·å¼µéä¿ãæ ¹æéäºçæ³æ¢ä»¶ï¼æåæè¿°äºå±åè¨­è¨å·¥ä½çææï¼è¨èæ§å¶ç LLM ççµç¹çµæ§ååè½ãå¨çµå°¾ï¼æåè¨è«äºåæ¥­åºç¤æ¨¡åå¨å·¥ä½å ´æä½¿ç¨ä¸­çéå¶ï¼ä»¥åå°åèå¼æ¹æ³æç¨æ¼ LLM å±åè¨­è¨çæ¹æ³è«å½±é¿ã

##### **Multi-Physics Simulations via Coupled Fourier Neural Operator**
2501.17296v1 by Shibo Li, Tao Wang, Yifei Sun, Heiwei Tang

Physical simulations are essential tools across critical fields such as
mechanical and aerospace engineering, chemistry, meteorology, etc. While neural
operators, particularly the Fourier Neural Operator (FNO), have shown promise
in predicting simulation results with impressive performance and efficiency,
they face limitations when handling real-world scenarios involving coupled
multi-physics outputs. Current neural operator methods either overlook the
correlations between multiple physical processes or employ simplistic
architectures that inadequately capture these relationships. To overcome these
challenges, we introduce a novel coupled multi-physics neural operator learning
(COMPOL) framework that extends the capabilities of Fourier operator layers to
model interactions among multiple physical processes. Our approach implements
feature aggregation through recurrent and attention mechanisms, enabling
comprehensive modeling of coupled interactions. Our method's core is an
innovative system for aggregating latent features from multi-physics processes.
These aggregated features serve as enriched information sources for neural
operator layers, allowing our framework to capture complex physical
relationships accurately. We evaluated our coupled multi-physics neural
operator across diverse physical simulation tasks, including biological
systems, fluid mechanics, and multiphase flow in porous media. Our proposed
model demonstrates a two to three-fold improvement in predictive performance
compared to existing approaches.

æè¦ï¼ç©çæ¨¡æ¬æ¯æ©æ¢°åèªç©ºå·¥ç¨ãåå­¸ãæ°£è±¡å­¸ç­ééµé åçå¿è¦å·¥å·ãéç¶ç¥ç¶ç®å­ï¼ç¹å¥æ¯åç«èç¥ç¶ç®å­ (FNO)ï¼å·²å±ç¾åºä»¤äººå°è±¡æ·±å»çæè½åæçï¼é æ¸¬æ¨¡æ¬çµææå¾æåæ¯ï¼ä½å¨èçæ¶åè¦åå¤ç©çè¼¸åºçµæççå¯¦ä¸çå ´æ¯æï¼å®åæé¢è¨éå¶ãç®åçé¡ç¥ç¶ç®å­æ¹æ³æå¿½ç¥å¤åç©çç¨åºä¹éçéè¯æ§ï¼ææ¡ç¨ç°¡åçæ¶æ§ï¼ç¡æ³ååææéäºéä¿ãçºäºåæéäºææ°ï¼æåå¼å¥äºä¸åæ°çè¦åå¤ç©çç¥ç¶ç®å­å­¸ç¿ (COMPOL) æ¶æ§ï¼å®æ´å±äºåç«èç®å­å±¤çè½åï¼ä»¥å»ºæ¨¡å¤åç©çç¨åºä¹éçäº¤äºä½ç¨ãæåçåæ³éééæ­¸åæ³¨ææ©å¶å¯¦ä½ç¹å¾µèåï¼å¯¦ç¾äºè¦åäº¤äºä½ç¨çå¨é¢å»ºæ¨¡ãæåçæ¹æ³æ ¸å¿æ¯ä¸ååµæ°çç³»çµ±ï¼ç¨æ¼èåä¾èªå¤ç©çç¨åºçæ½å¨ç¹å¾µãéäºèåçç¹å¾µä½çºç¥ç¶ç®å­å±¤çè±å¯è³è¨ä¾æºï¼è®æåçæ¶æ§è½å¤ æºç¢ºææè¤éçç©çéä¿ãæåå¨ä¸åçç©çæ¨¡æ¬ä»»åä¸­è©ä¼°äºæåçè¦åå¤ç©çç¥ç¶ç®å­ï¼åæ¬çç©ç³»çµ±ãæµé«åå­¸åå¤ç¸æµåå¨å¤å­ä»è³ªä¸­ãæåæåºçæ¨¡åå±ç¤ºåºæ¯ç¾ææ¹æ³é«åºå©å°ä¸åçé æ¸¬æè½ã

##### **Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization**
2501.17295v1 by Zilu Tang, Rajen Chatterjee, Sarthak Garg

Machine Translation (MT) is undergoing a paradigm shift, with systems based
on fine-tuned large language models (LLM) becoming increasingly competitive
with traditional encoder-decoder models trained specifically for translation
tasks. However, LLM-based systems are at a higher risk of generating
hallucinations, which can severely undermine user's trust and safety. Most
prior research on hallucination mitigation focuses on traditional MT models,
with solutions that involve post-hoc mitigation - detecting hallucinated
translations and re-translating them. While effective, this approach introduces
additional complexity in deploying extra tools in production and also increases
latency. To address these limitations, we propose a method that intrinsically
learns to mitigate hallucinations during the model training phase.
Specifically, we introduce a data creation framework to generate hallucination
focused preference datasets. Fine-tuning LLMs on these preference datasets
reduces the hallucination rate by an average of 96% across five language pairs,
while preserving overall translation quality. In a zero-shot setting our
approach reduces hallucinations by 89% on an average across three unseen target
languages.

æè¦ï¼æ©å¨ç¿»è­¯ (MT) æ­£å¨ç¶æ­·ä¸å ´å¸ç¯è½ç§»ï¼åºæ¼å¾®èª¿å¤§åèªè¨æ¨¡å (LLM) çç³»çµ±èå°éçºç¿»è­¯ä»»åè¨ç·´çå³çµ±ç·¨ç¢¼å¨-è§£ç¢¼å¨æ¨¡åç«¶ç­æ¥è¶¨æ¿çãç¶èï¼åºæ¼ LLM çç³»çµ±ç¢çå¹»è¦ºçé¢¨éªè¼é«ï¼éå¯è½æå´éæå®³ä½¿ç¨èçä¿¡ä»»åå®å¨ãå¤§å¤æ¸ååéæ¼å¹»è¦ºæ¸ç·©çç ç©¶é½éä¸­å¨å³çµ±ç MT æ¨¡åä¸ï¼å¶è§£æ±ºæ¹æ¡æ¶åäºå¾æ¸ç·©ââåµæ¸¬å¹»è¦ºç¿»è­¯ä¸¦éæ°ç¿»è­¯ãéç¶ææï¼ä½éç¨®æ¹æ³å¨çç¢ç°å¢ä¸­é¨ç½²é¡å¤å·¥å·ææå¢å è¤éæ§ï¼ä¹æå¢å å»¶é²ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ç¨®æ¹æ³ï¼å¨æ¨¡åè¨ç·´éæ®µå§å¨å­¸ç¿æ¸è¼å¹»è¦ºãå·é«ä¾èªªï¼æåå¼å¥ä¸åè³æå»ºç«æ¶æ§ä¾ç¢çä»¥å¹»è¦ºçºä¸­å¿çåå¥½è³æéãå¨éäºåå¥½è³æéä¸å¾®èª¿ LLM å¯å°å¹»è¦ºçå¹³åéä½ 96%ï¼æ©«è·¨äºç¨®èªè¨å°ï¼åæä¿çæ´é«ç¿»è­¯åè³ªãå¨é¶æ¬¡å­¸ç¿è¨­å®ä¸­ï¼æåçåæ³å¹³åå°å¹»è¦ºæ¸å° 89%ï¼æ©«è·¨ä¸ç¨®æªè¦éçç®æ¨èªè¨ã

##### **Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology**
2501.17286v1 by Peilong Wang, Zhengliang Liu, Yiwei Li, Jason Holmes, Peng Shu, Lian Zhang, Xiang Li, Quanzheng Li, Brady S. Laughlin, Diego Santos Toesca, Sujay A. Vora, Samir H. Patel, Terence T. Sio, Tianming Liu, Wei Liu

Background: The radiation oncology clinical practice involves many steps
relying on the dynamic interplay of abundant text data. Large language models
have displayed remarkable capabilities in processing complex text information.
But their direct applications in specific fields like radiation oncology remain
underexplored.
  Purpose: This study aims to investigate whether fine-tuning LLMs with domain
knowledge can improve the performance on Task (1) treatment regimen generation,
Task (2) treatment modality selection (photon, proton, electron, or
brachytherapy), and Task (3) ICD-10 code prediction in radiation oncology.
  Methods: Data for 15,724 patient cases were extracted. Cases where patients
had a single diagnostic record, and a clearly identifiable primary treatment
plan were selected for preprocessing and manual annotation to have 7,903 cases
of the patient diagnosis, treatment plan, treatment modality, and ICD-10 code.
Each case was used to construct a pair consisting of patient diagnostics
details and an answer (treatment regimen, treatment modality, or ICD-10 code
respectively) for the supervised fine-tuning of these three tasks. Open source
LLaMA2-7B and Mistral-7B models were utilized for the fine-tuning with the
Low-Rank Approximations method. Accuracy and ROUGE-1 score were reported for
the fine-tuned models and original models. Clinical evaluation was performed on
Task (1) by radiation oncologists, while precision, recall, and F-1 score were
evaluated for Task (2) and (3). One-sided Wilcoxon signed-rank tests were used
to statistically analyze the results.
  Results: Fine-tuned LLMs outperformed original LLMs across all tasks with
p-value <= 0.001. Clinical evaluation demonstrated that over 60% of the
fine-tuned LLMs-generated treatment regimens were clinically acceptable.
Precision, recall, and F1-score showed improved performance of fine-tuned LLMs.

æè¦ï¼<paragraph>èæ¯ï¼æ¾å°è¿ç¤ä¸´åºå®è·µæ¶åè®¸å¤æ­¥éª¤ï¼è¿äºæ­¥éª¤ä¾èµäºä¸°å¯ææ¬æ°æ®çå¨æäº¤äºãå¤§åè¯­è¨æ¨¡åå¨å¤çå¤æçææ¬ä¿¡æ¯æ¹é¢è¡¨ç°åºäºåè¶çè½åãä½å®ä»¬å¨æ¾å°è¿ç¤ç­ç¹å®é¢åçç´æ¥åºç¨ä»æªå¾å°ååæ¢ç´¢ã
ç®çï¼æ¬ç ç©¶æ¨å¨è°æ¥éè¿é¢åç¥è¯å¾®è° LLM æ¯å¦å¯ä»¥æé«ä»»å¡ (1) æ²»çæ¹æ¡çæãä»»å¡ (2) æ²»çæ¹å¼éæ©ï¼åå­ãè´¨å­ãçµå­æè¿è·ç¦»æ¾å°æ²»çï¼åä»»å¡ (3) æ¾å°è¿ç¤ä¸­ ICD-10 ä»£ç é¢æµçæ§è½ã
æ¹æ³ï¼æåäº 15,724 ä¾æ£èçä¾çæ°æ®ãéæ©äºæ£èæåä¸è¯æ­è®°å½ä¸ææç¡®å¯è¯å«çä¸»è¦æ²»çè®¡åççä¾ï¼è¿è¡é¢å¤çåæå¨æ³¨éï¼å¾å° 7,903 ä¾æ£èè¯æ­ãæ²»çè®¡åãæ²»çæ¹å¼å ICD-10 ä»£ç ãæ¯ä¸ªçä¾é½ç¨äºæå»ºä¸å¯¹ï¼åæ¬æ£èè¯æ­è¯¦æåç­æ¡ï¼åå«æ¯æ²»çæ¹æ¡ãæ²»çæ¹å¼æ ICD-10 ä»£ç ï¼ï¼ç¨äºè¿ä¸ä¸ªä»»å¡ççç£å¾®è°ãå¼æº LLaMA2-7B å Mistral-7B æ¨¡åè¢«ç¨äºä½¿ç¨ä½ç§©é¼è¿æ¹æ³è¿è¡å¾®è°ãæ¥åäºå¾®è°æ¨¡åååå§æ¨¡åçåç¡®æ§å ROUGE-1 åæ°ãä»»å¡ (1) ç±æ¾å°è¿ç¤ç§å»å¸è¿è¡ä¸´åºè¯ä¼°ï¼èä»»å¡ (2) å (3) åè¯ä¼°äºç²¾ç¡®åº¦ãå¬åçå F-1 åæ°ãåä¾§ Wilcoxon ç¬¦å·ç§©æ£éªç¨äºå¯¹ç»æè¿è¡ç»è®¡åæã
ç»æï¼å¾®è°åç LLM å¨ææä»»å¡ä¸­é½ä¼äºåå§ LLMï¼p å¼ <= 0.001ãä¸´åºè¯ä¼°è¡¨æï¼è¶è¿ 60% çå¾®è° LLM çæçæ²»çæ¹æ¡å¨ä¸´åºä¸æ¯å¯æ¥åçãç²¾ç¡®åº¦ãå¬åçå F1 åæ°æ¾ç¤ºå¾®è°åç LLM æ§è½å¾å°æ¹åã</paragraph>

##### **From Natural Language to Extensive-Form Game Representations**
2501.17282v1 by Shilong Deng, Yongzhao Wang, Rahul Savani

We introduce a framework for translating game descriptions in natural
language into extensive-form representations in game theory, leveraging Large
Language Models (LLMs) and in-context learning. Given the varying levels of
strategic complexity in games, such as perfect versus imperfect information,
directly applying in-context learning would be insufficient. To address this,
we introduce a two-stage framework with specialized modules to enhance
in-context learning, enabling it to divide and conquer the problem effectively.
In the first stage, we tackle the challenge of imperfect information by
developing a module that identifies information sets along and the
corresponding partial tree structure. With this information, the second stage
leverages in-context learning alongside a self-debugging module to produce a
complete extensive-form game tree represented using pygambit, the Python API of
a recognized game-theoretic analysis tool called Gambit. Using this python
representation enables the automation of tasks such as computing Nash
equilibria directly from natural language descriptions. We evaluate the
performance of the full framework, as well as its individual components, using
various LLMs on games with different levels of strategic complexity. Our
experimental results show that the framework significantly outperforms baseline
models in generating accurate extensive-form games, with each module playing a
critical role in its success.

æè¦ï¼æåå¼å¥äºä¸åæ¶æ§ï¼ç¨æ¼å°èªç¶èªè¨ä¸­çéæ²æè¿°è½æçºåå¼è«ä¸­çå»£ç¾©å½¢å¼è¡¨ç¤ºï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) åæå¢å­¸ç¿ãéæ¼éæ²ä¸­ç­ç¥è¤éç¨åº¦çä¸åï¼ä¾å¦å®ç¾è³è¨èä¸å®ç¾è³è¨ï¼ç´æ¥æç¨æå¢å­¸ç¿å°æ¯ä¸å¤ çãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºä¸åå©éæ®µæ¶æ§ï¼å¶ä¸­åå«å°éæ¨¡çµä¾å¢å¼·æå¢å­¸ç¿ï¼ä½¿å¶è½å¤ ææå°åèæ²»ä¹ãå¨ç¬¬ä¸éæ®µï¼æåéééç¼ä¸åæ¨¡çµä¾è§£æ±ºä¸å®ç¾è³è¨çææ°ï¼è©²æ¨¡çµå¯ä»¥è­å¥æ²¿èè³è¨éåå°æçé¨åæ¨¹ççµæ§ãæäºéäºè³è¨ï¼ç¬¬äºéæ®µå©ç¨æå¢å­¸ç¿åèªé¤é¯æ¨¡çµä¾ç¢çä¸åå®æ´çå»£ç¾©å½¢å¼éæ²æ¨¹ï¼ä½¿ç¨ pygambit è¡¨ç¤ºï¼å®æ¯ç¨±çº Gambit çå¬èªåå¼è«åæå·¥å·ç Python APIãä½¿ç¨æ­¤ python è¡¨ç¤ºå¯ä»¥èªåå·è¡ä»»åï¼ä¾å¦ç´æ¥å¾èªç¶èªè¨æè¿°ä¸­è¨ç®ç´è¨±åè¡¡ãæåä½¿ç¨ä¸åç­ç¥è¤éç¨åº¦çéæ²å°å®æ´æ¶æ§åå¶åå¥çµä»¶çæ§è½é²è¡è©ä¼°ï¼ä½¿ç¨åç¨® LLMãæåçå¯¦é©çµæè¡¨æï¼è©²æ¶æ§å¨çææºç¢ºçå»£ç¾©å½¢å¼éæ²æ¹é¢é¡¯èåªæ¼åºæºæ¨¡åï¼æ¯åæ¨¡çµå¨å¶æåä¸­é½ç¼æ®èè³ééè¦çä½ç¨ã

##### **Tailored Truths: Optimizing LLM Persuasion with Personalization and Fabricated Statistics**
2501.17273v1 by Jasper Timm, Chetan Talele, Jacob Haimes

Large Language Models (LLMs) are becoming increasingly persuasive,
demonstrating the ability to personalize arguments in conversation with humans
by leveraging their personal data. This may have serious impacts on the scale
and effectiveness of disinformation campaigns. We studied the persuasiveness of
LLMs in a debate setting by having humans $(n=33)$ engage with LLM-generated
arguments intended to change the human's opinion. We quantified the LLM's
effect by measuring human agreement with the debate's hypothesis pre- and
post-debate and analyzing both the magnitude of opinion change, as well as the
likelihood of an update in the LLM's direction. We compare persuasiveness
across established persuasion strategies, including personalized arguments
informed by user demographics and personality, appeal to fabricated statistics,
and a mixed strategy utilizing both personalized arguments and fabricated
statistics. We found that static arguments generated by humans and GPT-4o-mini
have comparable persuasive power. However, the LLM outperformed static
human-written arguments when leveraging the mixed strategy in an interactive
debate setting. This approach had a $\mathbf{51\%}$ chance of persuading
participants to modify their initial position, compared to $\mathbf{32\%}$ for
the static human-written arguments. Our results highlight the concerning
potential for LLMs to enable inexpensive and persuasive large-scale
disinformation campaigns.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è®å¾è¶ä¾è¶æèªªæåï¼å±ç¤ºäºå¨èäººé¡å°è©±ä¸­ééå©ç¨å¶åäººè³æä¾åæ§åè«é»çè½åãéå¯è½æå°é¯èª¤è³è¨æ´»åçè¦æ¨¡åæææ§ç¢çå´éå½±é¿ãæåå¨è¾¯è«å ´æ¯ä¸­ç ç©¶äº LLM çèªªæåï¼è®äººé¡ $(n=33)$ åè LLM çæçè«é»ï¼ç®çæ¯æ¹è®äººé¡çè§é»ãæåééè¡¡éäººé¡å¨è¾¯è«ååè¾¯è«å¾çæè¦æ¯å¦èªåè¾¯è«çåè¨­ï¼ä¸¦åææè¦æ¹è®çå¹åº¦ä»¥å LLM æ¹åæ´æ°çå¯è½æ§ï¼ä¾éå LLM çå½±é¿ãæåæ¯è¼äºæ¢å®çèªªæç­ç¥çèªªæåï¼åæ¬æ ¹æä½¿ç¨èäººå£çµ±è¨è³æååæ§åèæçåæ§åè«é»ãè¨´è«¸èæ§ççµ±è¨æ¸æï¼ä»¥åå©ç¨åæ§åè«é»åèæ§çµ±è¨æ¸æçæ··åç­ç¥ãæåç¼ç¾ï¼äººé¡å GPT-4o-mini çæçéæè«é»å·æç¸ç¶çèªªæåãç¶èï¼ç¶å¨äºåå¼è¾¯è«å ´æ¯ä¸­å©ç¨æ··åç­ç¥æï¼LLM åªæ¼éæäººé¡æ°å¯«çè«é»ãæ­¤æ¹æ³æ $\mathbf{51\%}$ çæ©çèªªæåèèä¿®æ¹å¶åå§ç«å ´ï¼èéæäººé¡æ°å¯«çè«é»åªæ $\mathbf{32\%}$ãæåççµæçªé¡¯äº LLM å¯è½è®å¤§è¦æ¨¡é¯èª¤è³è¨æ´»åè®å¾ä¾¿å®ä¸å·æèªªæåçä»¤äººææçå¯è½æ§ã

##### **Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service**
2501.17270v1 by Saloni Potdar, Daniel Lee, Omar Attia, Varun Embar, De Meng, Ramesh Balaji, Chloe Seivwright, Eric Choi, Mina H. Farid, Yiwen Sun, Yunyao Li

Question answering systems for knowledge graph (KGQA), answer factoid
questions based on the data in the knowledge graph. KGQA systems are complex
because the system has to understand the relations and entities in the
knowledge-seeking natural language queries and map them to structured queries
against the KG to answer them. In this paper, we introduce Chronos, a
comprehensive evaluation framework for KGQA at industry scale. It is designed
to evaluate such a multi-component system comprehensively, focusing on (1)
end-to-end and component-level metrics, (2) scalable to diverse datasets and
(3) a scalable approach to measure the performance of the system prior to
release. In this paper, we discuss the unique challenges associated with
evaluating KGQA systems at industry scale, review the design of Chronos, and
how it addresses these challenges. We will demonstrate how it provides a base
for data-driven decisions and discuss the challenges of using it to measure and
improve a real-world KGQA system.

æè¦ï¼ç¥è­åè­åç­ç³»çµ± (KGQA) æ ¹æç¥è­åè­ä¸­çè³æåç­äºå¯¦åé¡ãKGQA ç³»çµ±å¾è¤éï¼å çºç³»çµ±å¿é çè§£ç¥è­å°æ±èªç¶èªè¨æ¥è©¢ä¸­çéä¿åå¯¦é«ï¼ä¸¦å°å®åå°æ å°éå°ç¥è­åè­ççµæ§åæ¥è©¢ï¼æè½åç­éäºæ¥è©¢ãå¨æ¬æä¸­ï¼æåä»ç´¹äº Chronosï¼éæ¯ä¸åç¨æ¼ç¢æ¥­è¦æ¨¡ KGQA çå¨é¢è©ä¼°æ¡æ¶ãå®æ¨å¨å¨é¢è©ä¼°éç¨®å¤çµä»¶ç³»çµ±ï¼éé»éæ³¨ï¼(1) ç«¯å°ç«¯åçµä»¶å±¤ç´ææ¨ï¼(2) å¯æ´åè³åç¨®è³æéï¼ä»¥å (3) å¯æ´åçæ¹æ³ï¼ç¨æ¼å¨éåºåè¡¡éç³»çµ±çæè½ãå¨æ¬æä¸­ï¼æåè¨è«äºèç¢æ¥­è¦æ¨¡ KGQA ç³»çµ±è©ä¼°ç¸éçç¨ç¹ææ°ï¼æª¢è¦ Chronos çè¨­è¨ï¼ä»¥åå®å¦ä½æå°éäºææ°ãæåå°å±ç¤ºå®å¦ä½æä¾è³æé©åæ±ºç­çåºç¤ï¼ä¸¦è¨è«ä½¿ç¨å®ä¾è¡¡éåæ¹åçå¯¦ä¸ç KGQA ç³»çµ±çææ°ã

##### **Giving the Old a Fresh Spin: Quality Estimation-Assisted Constrained Decoding for Automatic Post-Editing**
2501.17265v1 by Sourabh Deoghare, Diptesh Kanojia, Pushpak Bhattacharyya

Automatic Post-Editing (APE) systems often struggle with over-correction,
where unnecessary modifications are made to a translation, diverging from the
principle of minimal editing. In this paper, we propose a novel technique to
mitigate over-correction by incorporating word-level Quality Estimation (QE)
information during the decoding process. This method is architecture-agnostic,
making it adaptable to any APE system, regardless of the underlying model or
training approach. Our experiments on English-German, English-Hindi, and
English-Marathi language pairs show the proposed approach yields significant
improvements over their corresponding baseline APE systems, with TER gains of
$0.65$, $1.86$, and $1.44$ points, respectively. These results underscore the
complementary relationship between QE and APE tasks and highlight the
effectiveness of integrating QE information to reduce over-correction in APE
systems.

æè¦ï¼èªåå¾ç·¨è¼¯ (APE) ç³»çµ±ç¶å¸¸æéåº¦ä¿®æ­£ï¼
å¨ç¿»è­¯ä¸­é²è¡ä¸å¿è¦çä¿®æ¹ï¼åé¢äºæå°ç·¨è¼¯çååãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°çæè¡ï¼ééå¨è§£ç¢¼éç¨ä¸­æ´åè©ç´åè³ªè©ä¼° (QE) è³è¨ä¾æ¸è¼éåº¦ä¿®æ­£ãéç¨®æ¹æ³èæ¶æ§ç¡éï¼å æ­¤å¯ä»¥é©æä»»ä½ APE ç³»çµ±ï¼ç¡è«å¶åºå±¤æ¨¡åæè¨ç·´æ¹æ³çºä½ãæåå°è±èª-å¾·èªãè±èª-å°å°èªåè±èª-é¦¬æå°èªèªè¨å°é²è¡çå¯¦é©è¡¨æï¼ææåºçæ¹æ³æ¯å¶å°æçåºæº APE ç³»çµ±æé¡¯èçæ¹é²ï¼TER åå¥å¢å äº 0.65ã1.86 å 1.44 åãéäºçµæå¼·èª¿äº QE å APE ä»»åä¹éçäºè£éä¿ï¼ä¸¦çªåºäºæ´å QE è³è¨ä»¥æ¸å° APE ç³»çµ±ä¸­éåº¦ä¿®æ­£çæææ§ã

##### **SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training**
2501.17161v1 by Tianzhe Chu, Yuexiang Zhai, Jihan Yang, Shengbang Tong, Saining Xie, Dale Schuurmans, Quoc V. Le, Sergey Levine, Yi Ma

Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely used
post-training techniques for foundation models. However, their roles in
enhancing model generalization capabilities remain unclear. This paper studies
the difference between SFT and RL on generalization and memorization, focusing
on text-based rule variants and visual variants. We introduce GeneralPoints, an
arithmetic reasoning card game, and adopt V-IRL, a real-world navigation
environment, to assess how models trained with SFT and RL generalize to unseen
variants in both textual and visual domains. We show that RL, especially when
trained with an outcome-based reward, generalizes across both rule-based
textual and visual variants. SFT, in contrast, tends to memorize training data
and struggles to generalize out-of-distribution scenarios. Further analysis
reveals that RL improves the model's underlying visual recognition
capabilities, contributing to its enhanced generalization in the visual domain.
Despite RL's superior generalization, we show that SFT remains essential for
effective RL training; SFT stabilizes the model's output format, enabling
subsequent RL to achieve its performance gains. These findings demonstrates the
capability of RL for acquiring generalizable knowledge in complex, multi-modal
tasks.

æè¦ï¼ç£ç£å¾®èª¿ (SFT) åå¼·åå­¸ç¿ (RL) æ¯å»£æ³ç¨æ¼åºç¤æ¨¡åçè¨ç·´å¾æè¡ãç¶èï¼å®åå¨å¢å¼·æ¨¡åæ³åè½åä¸­çä½ç¨ä»ä¸æç¢ºãæ¬ææ¢è¨äº SFT å RL å¨æ³ååè¨æ¶åæ¹é¢çå·®ç°ï¼éé»éæ³¨åºæ¼ææ¬çè¦åè®é«åè¦è¦ºè®é«ãæåå¼å¥äº GeneralPointsï¼ä¸ç¨®ç®è¡æ¨çç´çéæ²ï¼ä¸¦æ¡ç¨ V-IRLï¼ä¸åçå¯¦ä¸ççå°èªç°å¢ï¼ä¾è©ä¼°ä½¿ç¨ SFT å RL è¨ç·´çæ¨¡åå¦ä½æ³åå°ææ¬åè¦è¦ºé åä¸­æªè¦éçè®é«ãæåè¡¨æ RLï¼ç¹å¥æ¯å¨ä½¿ç¨åºæ¼çµæççåµé²è¡è¨ç·´æï¼å¯ä»¥æ³åå°åºæ¼è¦åçææ¬åè¦è¦ºè®é«ãç¸æ¯ä¹ä¸ï¼SFT å¾åæ¼è¨æ¶è¨ç·´æ¸æï¼ä¸¦ä¸é£ä»¥æ³åå°åä½å¤çå ´æ¯ãé²ä¸æ­¥çåæè¡¨æï¼RL æ¹åäºæ¨¡åçåºå±¤è¦è¦ºè­å¥è½åï¼æå©æ¼å¶å¨è¦è¦ºé åä¸­çæ³åè½åå¢å¼·ãåç®¡ RL å·æåªè¶çæ³åè½åï¼ä½æåè¡¨æ SFT ä»ç¶å°æ¼ææç RL è¨ç·´è³ééè¦ï¼SFT ç©©å®æ¨¡åçè¼¸åºæ ¼å¼ï¼ä½¿å¾çº RL è½å¤ å¯¦ç¾å¶æ§è½æåãéäºç¼ç¾å±ç¤ºäº RL å¨è¤éçå¤æ¨¡æä»»åä¸­ç²åå¯æ³åç¥è­çè½åã

##### **A Hybrid Deep Learning CNN Model for Enhanced COVID-19 Detection from Computed Tomography (CT) Scan Images**
2501.17160v1 by Suresh Babu Nettur, Shanthi Karpurapu, Unnati Nettur, Likhit Sagar Gajja, Sravanthy Myneni, Akhil Dusi, Lalithya Posham

Early detection of COVID-19 is crucial for effective treatment and
controlling its spread. This study proposes a novel hybrid deep learning model
for detecting COVID-19 from CT scan images, designed to assist overburdened
medical professionals. Our proposed model leverages the strengths of VGG16,
DenseNet121, and MobileNetV2 to extract features, followed by Principal
Component Analysis (PCA) for dimensionality reduction, after which the features
are stacked and classified using a Support Vector Classifier (SVC). We
conducted comparative analysis between the proposed hybrid model and individual
pre-trained CNN models, using a dataset of 2,108 training images and 373 test
images comprising both COVID-positive and non-COVID images. Our proposed hybrid
model achieved an accuracy of 98.93%, outperforming the individual models in
terms of precision, recall, F1 scores, and ROC curve performance.

æè¦ï¼æ©æåµæ¸¬ COVID-19 å°æææ²»çåæ§å¶å¶å³æ­è³ééè¦ãæ¬ç ç©¶æåºä¸åæ°ç©çæ·±åº¦å­¸ç¿æ··åæ¨¡åï¼ç¨æ¼å¾é»è¦æ·å±¤ææå½±åä¸­åµæ¸¬ COVID-19ï¼æ¨å¨åå©è² æééçé«çå°æ¥­äººå¡ãæåæåºçæ¨¡åå©ç¨ VGG16ãDenseNet121 å MobileNetV2 çåªé»ä¾èåç¹å¾µï¼æ¥èé²è¡ä¸»æååæ (PCA) ä»¥é²è¡éç¶­ï¼ç¶å¾å°ç¹å¾µå çä¸¦ä½¿ç¨æ¯æåéåé¡å¨ (SVC) é²è¡åé¡ãæåå°æåºçæ··åæ¨¡åååå¥é è¨ç·´ç CNN æ¨¡åé²è¡æ¯è¼åæï¼ä½¿ç¨åå« 2,108 å¼µè¨ç·´å½±åå 373 å¼µæ¸¬è©¦å½±åçè³æéï¼å¶ä¸­åå« COVID-19 é½æ§å½±ååé COVID-19 å½±åãæåæåºçæ··åæ¨¡åéå°äº 98.93% çæºç¢ºåº¦ï¼å¨ç²¾æºåº¦ãå¬åçãF1 åæ¸å ROC æ²ç·æè½æ¹é¢åªæ¼åå¥æ¨¡åã

##### **Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile Compensation Using Deep Energy Model**
2501.17152v1 by Reza Ghorbani, Jyothi Rikhab Chand, Chu-Yu Lee, Mathews Jacob, Merry Mani

Three-dimensional (3D) multi-slab acquisition is a technique frequently
employed in high-resolution diffusion-weighted MRI in order to achieve the best
signal-to-noise ratio (SNR) efficiency. However, this technique is limited by
slab boundary artifacts that cause intensity fluctuations and aliasing between
slabs which reduces the accuracy of anatomical imaging. Addressing this issue
is crucial for advancing diffusion MRI quality and making high-resolution
imaging more feasible for clinical and research applications. In this work, we
propose a regularized slab profile encoding (PEN) method within a Plug-and-Play
ADMM framework, incorporating multi-scale energy (MuSE) regularization to
effectively improve the slab combined reconstruction. Experimental results
demonstrate that the proposed method significantly improves image quality
compared to non-regularized and TV-regularized PEN approaches. The regularized
PEN framework provides a more robust and efficient solution for high-resolution
3D diffusion MRI, potentially enabling clearer, more reliable anatomical
imaging across various applications.

æè¦ï¼ä¸ç¶­ (3D) å¤å±¤æ¿æ·åæ¯ä¸ç¨®æè¡ï¼ç¶å¸¸ä½¿ç¨æ¼é«è§£æåº¦æ´æ£å æ¬ MRIï¼ä»¥éå°æä½³çè¨èéè¨æ¯ (SNR) æçãç¶èï¼æ­¤æè¡åå°å±¤æ¿éçå½å½±çéå¶ï¼æé æå¼·åº¦æ³¢ååå±¤æ¿ä¹éçæ··çï¼éä½è§£åå½±åçæºç¢ºåº¦ãè§£æ±ºéååé¡å°æ¼æåæ´æ£ MRI åè³ªè³ééè¦ï¼ä¸¦ä½¿é«è§£æåº¦å½±åæ´é©ç¨æ¼è¨åºåç ç©¶æç¨ãå¨éé å·¥ä½ä¸­ï¼æåå¨ Plug-and-Play ADMM æ¶æ§å§æåºæ­£è¦åçå±¤æ¿è¼ªå»ç·¨ç¢¼ (PEN) æ¹æ³ï¼ä¸¦çµåå¤å°ºåº¦è½é (MuSE) æ­£è¦åï¼ä»¥æææ¹åå±¤æ¿çµåéå»ºãå¯¦é©çµæè­æï¼èéæ­£è¦åå TV æ­£è¦å PEN æ¹æ³ç¸æ¯ï¼ææåºçæ¹æ³é¡¯èæåäºå½±ååè³ªãæ­£è¦åç PEN æ¶æ§çºé«è§£æåº¦ 3D æ´æ£ MRI æä¾æ´å¼·åºä¸ææççè§£æ±ºæ¹æ¡ï¼æ½å¨å¯å¯¦ç¾æ´æ¸æ°ãæ´å¯é çè§£åå½±åï¼é©ç¨æ¼åç¨®æç¨ã

##### **AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders**
2501.17148v2 by Zhengxuan Wu, Aryaman Arora, Atticus Geiger, Zheng Wang, Jing Huang, Dan Jurafsky, Christopher D. Manning, Christopher Potts

Fine-grained steering of language model outputs is essential for safety and
reliability. Prompting and finetuning are widely used to achieve these goals,
but interpretability researchers have proposed a variety of
representation-based techniques as well, including sparse autoencoders (SAEs),
linear artificial tomography, supervised steering vectors, linear probes, and
representation finetuning. At present, there is no benchmark for making direct
comparisons between these proposals. Therefore, we introduce AxBench, a
large-scale benchmark for steering and concept detection, and report
experiments on Gemma-2-2B and 9B. For steering, we find that prompting
outperforms all existing methods, followed by finetuning. For concept
detection, representation-based methods such as difference-in-means, perform
the best. On both evaluations, SAEs are not competitive. We introduce a novel
weakly-supervised representational method (Rank-1 Representation Finetuning;
ReFT-r1), which is competitive on both tasks while providing the
interpretability advantages that prompting lacks. Along with AxBench, we train
and publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.

æè¦ï¼å¾®èª¿èªè¨æ¨¡åè¼¸åºå°æ¼å®å¨æ§èå¯é æ§è³ééè¦ãæç¤ºèå¾®èª¿å»£æ³ç¨æ¼éæéäºç®æ¨ï¼ä½å¯è§£éæ§ç ç©¶äººå¡ä¹æåºåç¨®åºæ¼è¡¨å¾µçæè¡ï¼åæ¬ç¨çèªåç·¨ç¢¼å¨ (SAE)ãç·æ§äººå·¥æ·å±¤æå½±ãç£ç£å¼å°åéãç·æ§æ¢æ¸¬åè¡¨å¾µå¾®èª¿ãç®åæ²æåºæºå¯ä¾å°éäºææ¡é²è¡ç´æ¥æ¯è¼ãå æ­¤ï¼æåå¼å¥äº AxBenchï¼ä¸åç¨æ¼å¼å°åæ¦å¿µæª¢æ¸¬çå¤§è¦æ¨¡åºæºï¼ä¸¦å ±åäºå¨ Gemma-2-2B å 9B ä¸çå¯¦é©ãå°æ¼å¼å°ï¼æåç¼ç¾æç¤ºåªæ¼ææç¾ææ¹æ³ï¼å¶æ¬¡æ¯å¾®èª¿ãå°æ¼æ¦å¿µæª¢æ¸¬ï¼åºæ¼è¡¨å¾µçæ¹æ³ï¼ä¾å¦åå¼å·®ï¼è¡¨ç¾æä½³ãå¨å©é è©ä¼°ä¸­ï¼SAE æ²æç«¶ç­åãæåå¼å¥äºä¸ç¨®æ°ç©çå¼±ç£ç£è¡¨å¾µæ¹æ³ï¼1 ç´è¡¨å¾µå¾®èª¿ï¼ReFT-r1ï¼ï¼å®å¨å©é ä»»åä¸é½å·æç«¶ç­åï¼åææä¾äºæç¤ºæç¼ºä¹çå¯è§£éæ§åªå¢ãé¨è AxBenchï¼æåè¨ç·´ä¸¦å¬éç¼å¸äº ReFT-r1 å DiffMean ç SAE ç´å¥ç¹å¾µå­å¸ã

##### **FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data**
2501.17144v1 by Deren Lei, Yaxi Li, Siyao Li, Mengya Hu, Rui Xu, Ken Archer, Mingyu Wang, Emily Ching, Alex Deng

Prior research on training grounded factuality classification models to
detect hallucinations in large language models (LLMs) has relied on public
natural language inference (NLI) data and synthetic data. However, conventional
NLI datasets are not well-suited for document-level reasoning, which is
critical for detecting LLM hallucinations. Recent approaches to document-level
synthetic data generation involve iteratively removing sentences from documents
and annotating factuality using LLM-based prompts. While effective, this method
is computationally expensive for long documents and limited by the LLM's
capabilities. In this work, we analyze the differences between existing
synthetic training data used in state-of-the-art models and real LLM output
claims. Based on our findings, we propose a novel approach for synthetic data
generation, CG2C, that leverages multi-hop reasoning on context graphs
extracted from documents. Our fact checker model, FactCG, demonstrates improved
performance with more connected reasoning, using the same backbone models.
Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark
with much smaller model size.

æè¦ï¼ååçç ç©¶è¨ç·´äºåºæ¼äºå¯¦çåé¡æ¨¡åï¼ä»¥åµæ¸¬å¤§åèªè¨æ¨¡å (LLM) ä¸­çå¹»è¦ºï¼ä¾è³´æ¼å¬éçèªç¶èªè¨æ¨è« (NLI) è³æååæè³æãç¶èï¼å³çµ±ç NLI è³æéä¸¦ä¸é©åæä»¶å±¤ç´çæ¨çï¼éå°æ¼åµæ¸¬ LLM çå¹»è¦ºè³ééè¦ãæè¿çæä»¶å±¤ç´åæè³æçææ¹æ³æ¶åå¾æä»¶ä¸­åè¦ç§»é¤å¥å­ï¼ä¸¦ä½¿ç¨åºæ¼ LLM çæç¤ºè¨»è§£äºå¯¦ãéç¶ææï¼ä½æ­¤æ¹æ³å°æ¼é·æä»¶ä¾èªªå¨éç®ä¸å¾æè²´ï¼ä¸åéæ¼ LLM çè½åãå¨éé å·¥ä½ä¸­ï¼æååæäºç¾æåæè¨ç·´è³æèæåé²æ¨¡åä¸­ä½¿ç¨ççå¯¦ LLM è¼¸åºå®£åä¹éçå·®ç°ãæ ¹ææåçç ç©¶çµæï¼æåæåºäºä¸åç¨æ¼åæè³æçæçåµæ°æ¹æ³ CG2Cï¼å®å©ç¨å¾æä»¶ä¸­æåçå§å®¹åè¡¨é²è¡å¤è·³æ¨çãæåçæ¥æ ¸æ¨¡å FactCG ä½¿ç¨ç¸åçéª¨å¹¹æ¨¡åï¼å±ç¤ºäºå¨æ´å¤é£çµçæ¨çä¸æ¹é²çæè½ãå¯¦é©è¡¨æï¼å®çè³å¨ LLM-Aggrefact åºæºä¸åªæ¼ GPT-4-oï¼ä¸æ¨¡åå¤§å°å°å¾å¤ã

##### **ASTRAL: Automated Safety Testing of Large Language Models**
2501.17132v1 by Miriam Ugarte, Pablo Valle, JosÃ© Antonio Parejo, Sergio Segura, Aitor Arrieta

Large Language Models (LLMs) have recently gained attention due to their
ability to understand and generate sophisticated human-like content. However,
ensuring their safety is paramount as they might provide harmful and unsafe
responses. Existing LLM testing frameworks address various safety-related
concerns (e.g., drugs, terrorism, animal abuse) but often face challenges due
to unbalanced and obsolete datasets. In this paper, we present ASTRAL, a tool
that automates the generation and execution of test cases (i.e., prompts) for
testing the safety of LLMs. First, we introduce a novel black-box coverage
criterion to generate balanced and diverse unsafe test inputs across a diverse
set of safety categories as well as linguistic writing characteristics (i.e.,
different style and persuasive writing techniques). Second, we propose an
LLM-based approach that leverages Retrieval Augmented Generation (RAG),
few-shot prompting strategies and web browsing to generate up-to-date test
inputs. Lastly, similar to current LLM test automation techniques, we leverage
LLMs as test oracles to distinguish between safe and unsafe test outputs,
allowing a fully automated testing approach. We conduct an extensive evaluation
on well-known LLMs, revealing the following key findings: i) GPT3.5 outperforms
other LLMs when acting as the test oracle, accurately detecting unsafe
responses, and even surpassing more recent LLMs (e.g., GPT-4), as well as LLMs
that are specifically tailored to detect unsafe LLM outputs (e.g., LlamaGuard);
ii) the results confirm that our approach can uncover nearly twice as many
unsafe LLM behaviors with the same number of test inputs compared to currently
used static datasets; and iii) our black-box coverage criterion combined with
web browsing can effectively guide the LLM on generating up-to-date unsafe test
inputs, significantly increasing the number of unsafe LLM behaviors.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡åï¼LLMï¼æè¿å å¶çè§£åçæè¤éçäººé¡å§å®¹çè½åèååéæ³¨ãç¶èï¼ç¢ºä¿å®åçå®å¨è³ééè¦ï¼å çºå®åå¯è½ææä¾æå®³åä¸å®å¨çåæãç¾æç LLM æ¸¬è©¦æ¡æ¶è§£æ±ºäºåç¨®èå®å¨ç¸éçåé¡ï¼ä¾å¦ï¼è¥ç©ãææä¸»ç¾©ãèå¾åç©ï¼ï¼ä½ç±æ¼æ¸æéä¸å¹³è¡¡åéæï¼å®åå¸¸å¸¸é¢è¨ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹ ASTRALï¼éæ¯ä¸åå·¥å·ï¼å¯ä»¥èªåçæåå·è¡æ¸¬è©¦ç¨ä¾ï¼å³æç¤ºï¼ï¼ä»¥æ¸¬è©¦ LLM çå®å¨æ§ãé¦åï¼æåå¼å¥äºä¸åæ°ç©çé»çè¦èæ¨æºï¼ä»¥çæè·¨è¶ä¸åå®å¨é¡å¥ä»¥åèªè¨å¯«ä½ç¹å¾µï¼å³ä¸åé¢¨æ ¼åèªªææ§å¯«ä½æå·§ï¼çå¹³è¡¡ä¸å¤æ¨£åçä¸å®å¨æ¸¬è©¦è¼¸å¥ãå¶æ¬¡ï¼æåæåºäºä¸ç¨®åºæ¼ LLM çæ¹æ³ï¼è©²æ¹æ³å©ç¨æª¢ç´¢å¢å¼·çæï¼RAGï¼ãå°æ¬¡æç¤ºç­ç¥åç¶²çµ¡çè¦½ä¾çæææ°çæ¸¬è©¦è¼¸å¥ãæå¾ï¼èç¶åç LLM æ¸¬è©¦èªååæè¡é¡ä¼¼ï¼æåå©ç¨ LLM ä½çºæ¸¬è©¦é è¨ä¾ååå®å¨åä¸å®å¨çæ¸¬è©¦è¼¸åºï¼å¾èåè¨±å®å¨èªååçæ¸¬è©¦æ¹æ³ãæåå°ç¾æå¨ç¥ç LLM é²è¡äºå»£æ³çè©ä¼°ï¼æ­ç¤ºäºä»¥ä¸ééµç¼ç¾ï¼i) GPT3.5 å¨åç¶æ¸¬è©¦é è¨æåªæ¼å¶ä» LLMï¼æºç¢ºæª¢æ¸¬ä¸å®å¨çé¿æï¼çè³è¶è¶äºæ´æ°ç LLMï¼ä¾å¦ï¼GPT-4ï¼ï¼ä»¥åå°éå®å¶çºæª¢æ¸¬ä¸å®å¨ç LLM è¼¸åºç LLMï¼ä¾å¦ï¼LlamaGuardï¼ï¼ii) çµæè­å¯¦ï¼èç¶åä½¿ç¨çéææ¸æéç¸æ¯ï¼æåçæ¹æ¡å¯ä»¥ç¨ç¸åæ¸éçæ¸¬è©¦è¼¸å¥ç¼ç¾å¹¾ä¹å¤ä¸åçä¸å®å¨ LLM è¡çºï¼iii) æåçé»çè¦èæ¨æºèç¶²çµ¡çè¦½ç¸çµåï¼å¯ä»¥ææå°æå° LLM çæææ°çä¸å®å¨æ¸¬è©¦è¼¸å¥ï¼å¾èé¡¯èå¢å ä¸å®å¨ LLM è¡çºçæ¸éã</paragraph>

##### **Histoires Morales: A French Dataset for Assessing Moral Alignment**
2501.17117v1 by Thibaud Leteno, Irina Proskurina, Antoine Gourru, Julien Velcin, Charlotte Laclau, Guillaume Metzler, Christophe Gravier

Aligning language models with human values is crucial, especially as they
become more integrated into everyday life. While models are often adapted to
user preferences, it is equally important to ensure they align with moral norms
and behaviours in real-world social situations. Despite significant progress in
languages like English and Chinese, French has seen little attention in this
area, leaving a gap in understanding how LLMs handle moral reasoning in this
language. To address this gap, we introduce Histoires Morales, a French dataset
derived from Moral Stories, created through translation and subsequently
refined with the assistance of native speakers to guarantee grammatical
accuracy and adaptation to the French cultural context. We also rely on
annotations of the moral values within the dataset to ensure their alignment
with French norms. Histoires Morales covers a wide range of social situations,
including differences in tipping practices, expressions of honesty in
relationships, and responsibilities toward animals. To foster future research,
we also conduct preliminary experiments on the alignment of multilingual models
on French and English data and the robustness of the alignment. We find that
while LLMs are generally aligned with human moral norms by default, they can be
easily influenced with user-preference optimization for both moral and immoral
data.

æè¦ï¼èªè¨æ¨¡åèäººé¡å¹å¼è§çå°é½è³ééè¦ï¼ç¹å¥æ¯å®åè¶ä¾è¶èå¥æ¥å¸¸çæ´»ä¹éãåç®¡æ¨¡åéå¸¸ææ ¹æç¨æ¶åå¥½é²è¡èª¿æ´ï¼ä½åæ¨£éè¦çæ¯ç¢ºä¿å®åç¬¦åç¾å¯¦ä¸çç¤¾ææå¢ä¸­çéå¾·è¦ç¯åè¡çºãåç®¡è±èªåä¸­æç­èªè¨åå¾äºé¡¯èé²å±ï¼ä½æ³èªå¨éæ¹é¢é®®åéæ³¨ï¼éä½¿å¾æåå° LLM å¦ä½èçéç¨®èªè¨ä¸­çéå¾·æ¨çç¼ºä¹äºè§£ãçºäºè§£æ±ºéä¸å·®è·ï¼æåå¼å¥äº Histoires Moralesï¼éæ¯ä¸åæ³èªæ¸æéï¼å®æºèªéå¾·æäºï¼ééç¿»è­¯åµå»ºï¼é¨å¾å¨æ¯èªäººå£«çåå©ä¸é²è¡äºæ¹é²ï¼ä»¥ä¿è­èªæ³æºç¢ºæ§åå°æ³èªæåèæ¯çé©ææ§ãæåéä¾è³´æ¸æéä¸­éå¾·å¹å¼çè¨»éï¼ä»¥ç¢ºä¿å®åèæ³èªè¦ç¯ä¿æä¸è´ãHistoires Morales æ¶µèäºå»£æ³çç¤¾ææå¢ï¼åæ¬å°è²»ç¿æ£çå·®ç°ãéä¿ä¸­çèª å¯¦è¡¨éä»¥åå°åç©çè²¬ä»»ãçºäºä¿é²æªä¾çç ç©¶ï¼æåéå°æ³èªåè±èªæ¸æä¸å¤èªè¨æ¨¡åçå°é½ä»¥åå°é½çç©©å¥æ§é²è¡äºåæ­¥å¯¦é©ãæåç¼ç¾ï¼åç®¡ LLM éå¸¸é»èªèäººé¡éå¾·è¦ç¯ä¿æä¸è´ï¼ä½å®åå¯ä»¥ééå°éå¾·åä¸éå¾·æ¸æçç¨æ¶åå¥½åªåèè¼æåå°å½±é¿ã

##### **Optimizing Large Language Model Training Using FP4 Quantization**
2501.17116v1 by Ruizhe Wang, Yeyun Gong, Xiao Liu, Guoshuai Zhao, Ziyue Yang, Baining Guo, Zhengjun Zha, Peng Cheng

The growing computational demands of training large language models (LLMs)
necessitate more efficient methods. Quantized training presents a promising
solution by enabling low-bit arithmetic operations to reduce these costs. While
FP8 precision has demonstrated feasibility, leveraging FP4 remains a challenge
due to significant quantization errors and limited representational capacity.
This work introduces the first FP4 training framework for LLMs, addressing
these challenges with two key innovations: a differentiable quantization
estimator for precise weight updates and an outlier clamping and compensation
strategy to prevent activation collapse. To ensure stability, the framework
integrates a mixed-precision training scheme and vector-wise quantization.
Experimental results demonstrate that our FP4 framework achieves accuracy
comparable to BF16 and FP8, with minimal degradation, scaling effectively to
13B-parameter LLMs trained on up to 100B tokens. With the emergence of
next-generation hardware supporting FP4, our framework sets a foundation for
efficient ultra-low precision training.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼è¨ç·´ä¸æ·å¢é·çè¨ç®éæ±ï¼éè¦æ´ææççæ¹æ³ãéåè¨ç·´æä¾äºä¸åæåéçè§£æ±ºæ¹æ¡ï¼ééåç¨ä½ä½åç®è¡éç®ä¾éä½éäºææ¬ãéç¶ FP8 ç²¾åº¦å·²è­æå¯è¡ï¼ä½ç±æ¼éåèª¤å·®é¡¯èåè¡¨ç¤ºè½åæéï¼å æ­¤å©ç¨ FP4 ä»ç¶æ¯ä¸åææ°ãéé å·¥ä½å¼å¥äº LLM çç¬¬ä¸å FP4 è¨ç·´æ¶æ§ï¼ééå©åééµåµæ°ä¾è§£æ±ºéäºææ°ï¼ä¸åå¯å¾®åéåä¼°è¨å¨ï¼ç¨æ¼ç²¾ç¢ºæ¬éæ´æ°ï¼ä»¥åä¸åç°å¸¸å¼ç®å¶åè£åç­ç¥ï¼ä»¥é²æ­¢æ¿æ´»å´©æ½°ãçºäºç¢ºä¿ç©©å®æ§ï¼è©²æ¶æ§æ´åäºä¸åæ··åç²¾åº¦è¨ç·´æ¹æ¡ååéåéåãå¯¦é©çµæè¡¨æï¼æåç FP4 æ¶æ§éå°äºè BF16 å FP8 ç¸ç¶çæºç¢ºåº¦ï¼ä¸ææå°çè¡°æ¸ï¼å¯æææ´åå°å¨å¤é 100B åç¬¦èä¸è¨ç·´ç 13B åæ¸ LLMãé¨èæ¯æ´ FP4 çæ°ä¸ä»£ç¡¬é«åºç¾ï¼æåçæ¶æ§çºé«æçè¶ä½ç²¾åº¦è¨ç·´å¥ å®äºåºç¤ã

##### **COS(M+O)S: Curiosity and RL-Enhanced MCTS for Exploring Story Space via Language Models**
2501.17104v1 by Tobias Materzok

We present COS(M+O)S, a System 2-inspired framework for open-ended plot
development that systematically explores the vast space of possible story
expansions, enabling a 3B-parameter language model to approach the plot quality
of a 70B model on select short-story tasks. The method accomplishes this by
combining Monte Carlo Tree Search (MCTS), guided by a step-level value model
that rewards moderate surprisal (curiosity) while penalizing incoherence, and
Odds Ratio Preference Optimization (ORPO) to fine-tune the policy on high-value
plot expansions. This iterative reinforcement learning loop systematically
explores multiple candidate plot branches, backpropagates quality signals, and
adapts the policy for faster convergence, notably shifting the policy from
puzzle-based Chain-of-Thought to more character-driven storytelling. In
small-scale tests with short-story prompts, 67%-77% of participants favored
COS(M+O)S's highest-rated expansions over lower-rated ones, suggesting that our
learned value function aligns. GPT-4o ratings further show that COS(M+O)S
surpasses naive single-pass decoding from Llama 3.2 3B by 0.59 SD, coming
within 0.06 SD of Llama 3.1 70B (no significant difference, p=0.93). Pairwise
comparisons with o1 place COS(M+O)S 1.5 SD above the 3B baseline and find no
statistically significant gap from 70B. Nevertheless, absolute story quality
remains modest, constrained by the small model's capacity and limited training
data.

æè¦ï¼<paragraph>æåæåº COS(M+O)Sï¼ä¸åå System 2 åç¼çæ¶æ§ï¼ç¨æ¼éæ¾å¼æç¯ç¼å±ï¼ç³»çµ±æ§å°æ¢ç´¢å¯è½çæäºæç¯æ´å±çå»£éç©ºéï¼ä½¿ 3B åæ¸èªè¨æ¨¡åè½å¤ å¨é¸æçç­ç¯æäºä»»åä¸­æ¥è¿ 70B æ¨¡åçæç¯åè³ªãæ­¤æ¹æ³ééçµåèå°å¡ç¾æ¨¹æå° (MCTS)ï¼ç±éå±¤å¹å¼æ¨¡åå¼å°ï¼çåµé©åº¦çé©å (å¥½å¥å¿)ï¼åææ²ç½°ä¸é£è²«æ§ï¼ä»¥åæ©çæ¯åå¥½æä½³å (ORPO) ä¾å¾®èª¿é«å¹å¼æç¯æ´å±çæ¿ç­ãæ­¤åè¦å¼·åå­¸ç¿è¿´åç³»çµ±æ§å°æ¢ç´¢å¤ååé¸æç¯åæ¯ï¼ååå³æ­åè³ªè¨èï¼ä¸¦èª¿æ´æ¿ç­ä»¥å å¿«æ¶æï¼ç¹å¥æ¯å°æ¿ç­å¾åºæ¼è¬é¡çæèéè½ç§»å°æ´å¤ä»¥è§è²çºå°åçæäºæè¿°ãå¨ç­ç¯æäºæç¤ºçå°è¦æ¨¡æ¸¬è©¦ä¸­ï¼67%-77% çåèèåå¥½ COS(M+O)S è©åæé«çæ´å±ï¼èéè©åè¼ä½çæ´å±ï¼éè¡¨ææåå­¸ç¿å°çå¹å¼å½æ¸æ¯ä¸è´çãGPT-4o è©åé²ä¸æ­¥é¡¯ç¤ºï¼COS(M+O)S è¶è¶äº Llama 3.2 3B çå®æ¬¡è§£ç¢¼ï¼SD å¼çº 0.59ï¼æ¥è¿ Llama 3.1 70B ç SD å¼ 0.06ï¼ç¡é¡¯èå·®ç°ï¼p=0.93ï¼ãè o1 çæå°æ¯è¼å° COS(M+O)S æ¾å¨ 3B åºæºç·ä¸æ¹ 1.5 SDï¼ä¸¦ä¸ç¼ç¾è 70B ä¹éæ²æçµ±è¨ä¸é¡¯èçå·®è·ãåç®¡å¦æ­¤ï¼çµå°çæäºåè³ªä»ç¶é©ä¸­ï¼åå°å°æ¨¡åå®¹éåæéè¨ç·´è³æçéå¶ã</paragraph>

##### **Why is the estimation of metaorder impact with public market data so challenging?**
2501.17096v1 by Manuel Naviglio, Giacomo Bormetti, Francesco Campigli, German Rodikov, Fabrizio Lillo

Estimating market impact and transaction costs of large trades (metaorders)
is a very important topic in finance. However, using models of price and trade
based on public market data provide average price trajectories which are
qualitatively different from what is observed during real metaorder executions:
the price increases linearly, rather than in a concave way, during the
execution and the amount of reversion after its end is very limited. We claim
that this is a generic phenomenon due to the fact that even sophisticated
statistical models are unable to correctly describe the origin of the
autocorrelation of the order flow. We propose a modified Transient Impact Model
which provides more realistic trajectories by assuming that only a fraction of
the metaorder trading triggers market order flow. Interestingly, in our model
there is a critical condition on the kernels of the price and order flow
equations in which market impact becomes permanent.

æè¦ï¼è©ä¼°å¤§åäº¤æçå¸å ´å½±é¿åäº¤æææ¬ï¼åè¨å®ï¼æ¯éèä¸­éå¸¸éè¦çä¸»é¡ãç¶èï¼åºæ¼å¬éå¸å ´è³æçå¹æ ¼åäº¤ææ¨¡åæä¾äºå¹³åå¹æ ¼è»è·¡ï¼éèå¯¦éåè¨å®å·è¡æéè§å¯å°çææ³ææ¬è³ªä¸çä¸åï¼å¹æ ¼å¨å·è¡æéåç·æ§å¢å ï¼èä¸æ¯å¹å½¢å¢å ï¼ä¸¦ä¸å¨å·è¡çµæå¾åæ­¸çæ¸ééå¸¸æéãæåè²ç¨±éæ¯ä¸åæ®éç¾è±¡ï¼å çºå³ä½¿æ¯è¤éççµ±è¨æ¨¡åä¹ç¡æ³æ­£ç¢ºæè¿°è¨å®æµèªç¸éçèµ·æºãæåæåºäºä¸åä¿®æ­£çç¬æå½±é¿æ¨¡åï¼ééåè¨­åªæé¨ååè¨å®äº¤ææè§¸ç¼å¸å ´è¨å®æµä¾æä¾æ´çå¯¦çè»è·¡ãæè¶£çæ¯ï¼å¨æåçæ¨¡åä¸­ï¼å¹æ ¼åè¨å®æµæ¹ç¨å¼çæ ¸å­å¨ä¸åè¨çæ¢ä»¶ï¼å¨è©²æ¢ä»¶ä¸å¸å ´å½±é¿å°è®çºæ°¸ä¹æ§ã

##### **Mamba-Shedder: Post-Transformer Compression for Efficient Selective Structured State Space Models**
2501.17088v1 by J. Pablo MuÃ±oz, Jinjie Yuan, Nilesh Jain

Large pre-trained models have achieved outstanding results in sequence
modeling. The Transformer block and its attention mechanism have been the main
drivers of the success of these models. Recently, alternative architectures,
such as Selective Structured State Space Models (SSMs), have been proposed to
address the inefficiencies of Transformers. This paper explores the compression
of SSM-based models, particularly Mamba and its hybrids. We study the
sensitivity of these models to the removal of selected components at different
granularities to reduce the model size and computational overhead, thus
improving their efficiency while maintaining accuracy. The proposed solutions,
collectively referred to as Mamba-Shedder, achieve a speedup of up to 1.4x
during inference, demonstrating that model efficiency can be improved by
eliminating several redundancies with minimal impact on the overall model
performance. The code is available at
https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.

æè¦ï¼å¤§åé è¨ç·´æ¨¡åå¨åºåå»ºæ¨¡ä¸­åå¾äºååºçææãTransformer å¡åå¶æ³¨æåæ©å¶ä¸ç´æ¯éäºæ¨¡åæåçä¸»è¦é©ååãæè¿ï¼å·²ç¶æåºäºæ¿ä»£çµæ§ï¼ä¾å¦é¸ææ§çµæ§çæç©ºéæ¨¡å (SSM)ï¼ä»¥è§£æ±º Transformer çä½æçåé¡ãæ¬ææ¢è¨äºåºæ¼ SSM çæ¨¡åçå£ç¸®ï¼ç¹å¥æ¯ Mamba åå¶æ··åé«ãæåç ç©¶äºéäºæ¨¡åå¨ä¸åç²åº¦ä¸ç§»é¤é¸å®çµä»¶ä»¥éä½æ¨¡åå¤§å°åéç®è² æçæææ§ï¼å¾èæé«å¶æçï¼åæç¶­ææºç¢ºæ§ãææåºçè§£æ±ºæ¹æ¡ï¼çµ±ç¨±çº Mamba-Shedderï¼å¨æ¨çæéå¯¦ç¾äºé«é 1.4 åçå éï¼è­æäºééæ¶é¤å¤é¤çåé¤ï¼åæå°æ´é«æ¨¡åæè½çå½±é¿æå°ï¼å¯ä»¥æé«æ¨¡åæçãç¨å¼ç¢¼å¯å¨ https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning åå¾ã

##### **Learning Mean Field Control on Sparse Graphs**
2501.17079v1 by Christian Fabian, Kai Cui, Heinz Koeppl

Large agent networks are abundant in applications and nature and pose
difficult challenges in the field of multi-agent reinforcement learning (MARL)
due to their computational and theoretical complexity. While graphon mean field
games and their extensions provide efficient learning algorithms for dense and
moderately sparse agent networks, the case of realistic sparser graphs remains
largely unsolved. Thus, we propose a novel mean field control model inspired by
local weak convergence to include sparse graphs such as power law networks with
coefficients above two. Besides a theoretical analysis, we design scalable
learning algorithms which apply to the challenging class of graph sequences
with finite first moment. We compare our model and algorithms for various
examples on synthetic and real world networks with mean field algorithms based
on Lp graphons and graphexes. As it turns out, our approach outperforms
existing methods in many examples and on various networks due to the special
design aiming at an important, but so far hard to solve class of MARL problems.

æè¦ï¼å¤§åä»£çç¶²è·¯å¨æç¨èèªç¶ä¸­ååè±å¯ï¼ä¸ç±æ¼å¶éç®èçè«ä¸çè¤éæ§ï¼å¨å¤éä»£çå¼·åå­¸ç¿ (MARL) é åä¸­å¸¶ä¾å°é£çææ°ãéç¶ååå¹³åå ´åå¼åå¶æ´åæä¾å¯éä¸é©åº¦ç¨çä»£çç¶²è·¯çé«æå­¸ç¿æ¼ç®æ³ï¼ä½ç¾å¯¦ä¸­è¼ç¨çåå½¢çææ³ä»ç¶å¨å¾å¤§ç¨åº¦ä¸æªç²è§£æ±ºãå æ­¤ï¼æåæåºä¸åæ°çå¹³åå ´æ§å¶æ¨¡åï¼å¶éæä¾èªå±é¨å¼±æ¶æï¼ä»¥ç´å¥ç¨çåå½¢ï¼ä¾å¦ä¿æ¸å¤§æ¼ 2 çåªå¾ç¶²è·¯ãé¤äºçè«åæä¹å¤ï¼æåè¨­è¨äºå¯æ´åçå­¸ç¿æ¼ç®æ³ï¼é©ç¨æ¼å·ææéä¸éç©çååºåçææ°æ§é¡å¥ãæåå¨åæåçå¯¦ä¸çç¶²è·¯ä¸­æ¯è¼äºæåçæ¨¡ååæ¼ç®æ³ï¼ä»¥ååºæ¼ Lp ååååå½¢åçå¹³åå ´æ¼ç®æ³ãäºå¯¦è­æï¼ç±æ¼ç¹å¥çè¨­è¨æ¨å¨è§£æ±ºä¸åéè¦ä½å°ç®åçºæ­¢é£ä»¥è§£æ±ºç MARL åé¡é¡å¥ï¼æåçåæ³å¨è¨±å¤ç¯ä¾ååç¨®ç¶²è·¯ä¸­åªæ¼ç¾ææ¹æ³ã

##### **EdgeMLOps: Operationalizing ML models with Cumulocity IoT and thin-edge.io for Visual quality Inspection**
2501.17062v1 by Kanishk Chaturvedi, Johannes Gasthuber, Mohamed Abdelaal

This paper introduces EdgeMLOps, a framework leveraging Cumulocity IoT and
thin-edge.io for deploying and managing machine learning models on
resource-constrained edge devices. We address the challenges of model
optimization, deployment, and lifecycle management in edge environments. The
framework's efficacy is demonstrated through a visual quality inspection (VQI)
use case where images of assets are processed on edge devices, enabling
real-time condition updates within an asset management system. Furthermore, we
evaluate the performance benefits of different quantization methods,
specifically static and dynamic signed-int8, on a Raspberry Pi 4, demonstrating
significant inference time reductions compared to FP32 precision. Our results
highlight the potential of EdgeMLOps to enable efficient and scalable AI
deployments at the edge for industrial applications.

æè¦ï¼æ¬æä»ç»äº EdgeMLOpsï¼è¿æ¯ä¸ä¸ªå©ç¨ Cumulocity IoT å thin-edge.io çæ¡æ¶ï¼ç¨äºå¨èµæºåéçè¾¹ç¼è®¾å¤ä¸é¨ç½²åç®¡çæºå¨å­¦ä¹ æ¨¡åãæä»¬è§£å³äºå¨è¾¹ç¼ç¯å¢ä¸­è¿è¡æ¨¡åä¼åãé¨ç½²åçå½å¨æç®¡ççææãè¯¥æ¡æ¶çåæéè¿è§è§è´¨éæ£æ¥ (VQI) ç¨ä¾å¾å°è¯æï¼å¶ä¸­èµäº§çå¾åå¨è¾¹ç¼è®¾å¤ä¸è¿è¡å¤çï¼ä»èå¨èµäº§ç®¡çç³»ç»ä¸­å¯ç¨å®æ¶ç¶ææ´æ°ãæ­¤å¤ï¼æä»¬è¯ä¼°äºä¸åéåæ¹æ³çæ§è½ä¼å¿ï¼ç¹å«æ¯å¨ Raspberry Pi 4 ä¸çéæåå¨ææç¬¦å· int8ï¼ä¸ FP32 ç²¾åº¦ç¸æ¯ï¼å±ç¤ºäºæ¾èçæ¨çæ¶é´ç¼©åãæä»¬çç»æçªåºäº EdgeMLOps å¨ä¸ºå·¥ä¸åºç¨å®ç°é«æä¸å¯æ©å±çè¾¹ç¼ AI é¨ç½²æ¹é¢çæ½åã

##### **How Linguistics Learned to Stop Worrying and Love the Language Models**
2501.17047v1 by Richard Futrell, Kyle Mahowald

Language models can produce fluent, grammatical text. Nonetheless, some
maintain that language models don't really learn language and also that, even
if they did, that would not be informative for the study of human learning and
processing. On the other side, there have been claims that the success of LMs
obviates the need for studying linguistic theory and structure. We argue that
both extremes are wrong. LMs can contribute to fundamental questions about
linguistic structure, language processing, and learning. They force us to
rethink arguments about learning and are informative for major questions in
linguistic theory. But they do not replace linguistic structure and theory. We
offer an optimistic take on the relationship between language models and
linguistics.

æè¦ï¼èªè¨æ¨¡åå¯ä»¥ç¢çæµæ¢ãç¬¦åææ³çæå­ãåç®¡å¦æ­¤ï¼æäºäººå æèªçºèªè¨æ¨¡åä¸¦æªçæ­£å­¸ç¿èªè¨ï¼å³ä½¿ä»åççå­¸ç¿äºï¼éå°äººé¡å­¸ç¿åèççç ç©¶ä¹æ²æå¹«å©ãå¦ä¸æ¹é¢ï¼æäººè²ç¨±èªè¨æ¨¡åçæåæ¶é¤äºç ç©¶èªè¨å­¸çè«åçµæ§çå¿è¦æ§ãæåèªçºéå©ç¨®æ¥µç«¯èªªæ³é½æ¯é¯èª¤çãèªè¨æ¨¡åå¯ä»¥æ¢è¨èªè¨çµæ§ãèªè¨èçåå­¸ç¿çåºæ¬åé¡ãå®åè¿«ä½¿æåéæ°æèéæ¼å­¸ç¿çè«é»ï¼ä¸¦çºèªè¨å­¸çè«ä¸­çä¸»è¦åé¡æä¾è³è¨ãä½å®åä¸¦ä¸è½åä»£èªè¨çµæ§åçè«ãæåå°èªè¨æ¨¡ååèªè¨å­¸ä¹éçéä¿ææ¨è§æåº¦ã

##### **Synthesizing 3D Abstractions by Inverting Procedural Buildings with Transformers**
2501.17044v2 by Maximilian Dax, Jordi Berbel, Jan Stria, Leonidas Guibas, Urs Bergmann

We generate abstractions of buildings, reflecting the essential aspects of
their geometry and structure, by learning to invert procedural models. We first
build a dataset of abstract procedural building models paired with simulated
point clouds and then learn the inverse mapping through a transformer. Given a
point cloud, the trained transformer then infers the corresponding abstracted
building in terms of a programmatic language description. This approach
leverages expressive procedural models developed for gaming and animation, and
thereby retains desirable properties such as efficient rendering of the
inferred abstractions and strong priors for regularity and symmetry. Our
approach achieves good reconstruction accuracy in terms of geometry and
structure, as well as structurally consistent inpainting.

æè¦ï¼æåééå­¸ç¿åè½ç¨åºæ¨¡åï¼ç¢çå»ºç¯ç©çæ½è±¡åï¼åæ å¶å¹¾ä½å½¢çåçµæ§çåºæ¬é¢åãæåé¦åå»ºç«ä¸åæ½è±¡ç¨åºåå»ºç¯æ¨¡åçè³æéï¼ä¸¦èæ¨¡æ¬é»é²éå°ï¼ç¶å¾ééè½æå¨å­¸ç¿ååå°æãçµ¦å®ä¸åé»é²ï¼è¨ç·´å¥½çè½æå¨æ¥èææ¨è«å°æçæ½è±¡åå»ºç¯ï¼ä»¥ç¨å¼èªè¨æè¿°çå½¢å¼ãéåæ¹æ³å©ç¨äºçºéæ²ååç«éç¼çè¡¨éç¨åºæ¨¡åï¼å¾èä¿çäºçæ³çå±¬æ§ï¼ä¾å¦æææ¸²ææ¨è«çæ½è±¡åï¼ä»¥åè¦åæ§åå°ç¨±æ§çå¼·åé©ãæåçåæ³å¨å¹¾ä½å½¢çåçµæ§æ¹é¢éå°äºè¯å¥½çéå»ºæºç¢ºåº¦ï¼ä¸¦ä¸å¨çµæ§ä¸å·æä¸è´çä¿®å¾©ã

##### **Benchmarking Quantum Convolutional Neural Networks for Signal Classification in Simulated Gamma-Ray Burst Detection**
2501.17041v1 by Farida Farsian, NicolÃ² Parmiggiani, Alessandro Rizzo, Gabriele Panebianco, Andrea Bulgarelli, Francesco SchillirÃ², Carlo Burigana, Vincenzo Cardone, Luca Cappelli, Massimo Meneghetti, Giuseppe Murante, Giuseppe Sarracino, Roberto Scaramella, Vincenzo Testa, Tiziana Trombetti

This study evaluates the use of Quantum Convolutional Neural Networks (QCNNs)
for identifying signals resembling Gamma-Ray Bursts (GRBs) within simulated
astrophysical datasets in the form of light curves. The task addressed here
focuses on distinguishing GRB-like signals from background noise in simulated
Cherenkov Telescope Array Observatory (CTAO) data, the next-generation
astrophysical observatory for very high-energy gamma-ray science. QCNNs, a
quantum counterpart of classical Convolutional Neural Networks (CNNs), leverage
quantum principles to process and analyze high-dimensional data efficiently. We
implemented a hybrid quantum-classical machine learning technique using the
Qiskit framework, with the QCNNs trained on a quantum simulator. Several QCNN
architectures were tested, employing different encoding methods such as Data
Reuploading and Amplitude encoding. Key findings include that QCNNs achieved
accuracy comparable to classical CNNs, often surpassing 90\%, while using fewer
parameters, potentially leading to more efficient models in terms of
computational resources. A benchmark study further examined how hyperparameters
like the number of qubits and encoding methods affected performance, with more
qubits and advanced encoding methods generally enhancing accuracy but
increasing complexity. QCNNs showed robust performance on time-series datasets,
successfully detecting GRB signals with high precision. The research is a
pioneering effort in applying QCNNs to astrophysics, offering insights into
their potential and limitations. This work sets the stage for future
investigations to fully realize the advantages of QCNNs in astrophysical data
analysis.

æè¦ï¼æ¬ç ç©¶è©ä¼°éå­å·ç©ç¥ç¶ç¶²è·¯ (QCNN) å¨æ¨¡æ¬åæ²ç·å½¢å¼çå¤©é«ç©çè³æéä¸­è­å¥é¡ä¼¼ä¼½çªå°ç·æ´ (GRB) ä¿¡èçç¨éãæ­¤èèççä»»åå°æ³¨æ¼ååæ¨¡æ¬åå«ç§å¤«æé é¡é£åå¤©æå° (CTAO) è³æä¸­é¡ GRB ä¿¡èèèæ¯éè¨ï¼CTAO æ¯ä¸ä¸ä»£æ¥µé«è½ä¼½çªå°ç·ç§å­¸çå¤©é«ç©çå¤©æå°ãQCNN æ¯ç¶å¸å·ç©ç¥ç¶ç¶²è·¯ (CNN) çéå­å°æç©ï¼å©ç¨éå­åçææçå°èçååæé«ç¶­åº¦è³æãæåä½¿ç¨ Qiskit æ¶æ§å¯¦ä½äºæ··åéå­-ç¶å¸æ©å¨å­¸ç¿æè¡ï¼å¶ä¸­ QCNN å¨éå­æ¨¡æ¬å¨ä¸åè¨ãæ¸¬è©¦äºæ¸ç¨® QCNN æ¶æ§ï¼æ¡ç¨äºä¸åçç·¨ç¢¼æ¹æ³ï¼ä¾å¦è³æéæ°ä¸å³åæ¯å¹ç·¨ç¢¼ãä¸»è¦ç¼ç¾åæ¬ QCNN éå°äºèç¶å¸ CNN ç¸ç¶çæºç¢ºåº¦ï¼éå¸¸è¶é 90%ï¼åæä½¿ç¨è¼å°çåæ¸ï¼éå¯è½å¨è¨ç®è³æºæ¹é¢å°è´æ´ææçæ¨¡åãåºæºç ç©¶é²ä¸æ­¥æ¢è¨äºè¶åæ¸ï¼ä¾å¦éå­ä½åæ¸åç·¨ç¢¼æ¹æ³ï¼å¦ä½å½±é¿æè½ï¼éå¸¸æ´å¤éå­ä½ååé²éç·¨ç¢¼æ¹æ³ææé«æºç¢ºåº¦ï¼ä½ä¹æå¢å è¤éåº¦ãQCNN å¨æéåºåè³æéä¸å±ç¾äºå¼·å¥çæè½ï¼æåå°ä»¥é«æºç¢ºåº¦åµæ¸¬ GRB ä¿¡èãéé ç ç©¶æ¯å° QCNN æç¨æ¼å¤©é«ç©çå­¸çåé©æ§åªåï¼æä¾äºå°å¶æ½ååéå¶çè¦è§£ãéé å·¥ä½çºæªä¾çç ç©¶å¥ å®äºåºç¤ï¼ä»¥ååç¼æ® QCNN å¨å¤©é«ç©çè³æåæä¸­çåªå¢ã

##### **Challenges in Ensuring AI Safety in DeepSeek-R1 Models: The Shortcomings of Reinforcement Learning Strategies**
2501.17030v1 by Manojkumar Parmar, Yuvaraj Govindarajulu

Large Language Models (LLMs) have achieved remarkable progress in reasoning,
alignment, and task-specific performance. However, ensuring harmlessness in
these systems remains a critical challenge, particularly in advanced models
like DeepSeek-R1. This paper examines the limitations of Reinforcement Learning
(RL) as the primary approach for reducing harmful outputs in DeepSeek-R1 and
compares it with Supervised Fine-Tuning (SFT). While RL improves reasoning
capabilities, it faces challenges such as reward hacking, generalization
failures, language mixing, and high computational costs. We propose hybrid
training approaches combining RL and SFT to achieve robust harmlessness
reduction. Usage recommendations and future directions for deploying
DeepSeek-R1 responsibly are also presented.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æ¨çãå°é½åç¹å®ä»»åè¡¨ç¾æ¹é¢åå¾é¡¯èé²å±ãç¶èï¼ç¢ºä¿éäºç³»çµ±çç¡å®³æ§ä»ç¶æ¯ä¸é å´å³»çææ°ï¼å°¤å¶æ¯å¨ DeepSeek-R1 ç­åé²æ¨¡åä¸­ãæ¬ææ¢è¨äºå¼·åå­¸ç¿ (RL) ä½çºæ¸å° DeepSeek-R1 ä¸­æå®³è¼¸åºä¹ä¸»è¦æ¹æ³çéå¶ï¼ä¸¦å°å¶èç£ç£å¾®èª¿ (SFT) é²è¡æ¯è¼ãåç®¡ RL æ¹åäºæ¨çè½åï¼ä½å®é¢è¨çåµç ´è§£ãæ³åå¤±æãèªè¨æ··æ·åé«è¨ç®ææ¬ç­ææ°ãæåæåºçµå RL å SFT çæ··åè¨ç·´æ¹æ³ï¼ä»¥å¯¦ç¾ç©©å¥çç¡å®³æ§éä½ãéæåºäºè² è²¬ä»»å°é¨ç½² DeepSeek-R1 çä½¿ç¨å»ºè­°åæªä¾æ¹åã

##### **Revisit Mixture Models for Multi-Agent Simulation: Experimental Study within a Unified Framework**
2501.17015v1 by Longzhong Lin, Xuewu Lin, Kechun Xu, Haojian Lu, Lichao Huang, Rong Xiong, Yue Wang

Simulation plays a crucial role in assessing autonomous driving systems,
where the generation of realistic multi-agent behaviors is a key aspect. In
multi-agent simulation, the primary challenges include behavioral multimodality
and closed-loop distributional shifts. In this study, we revisit mixture models
for generating multimodal agent behaviors, which can cover the mainstream
methods including continuous mixture models and GPT-like discrete models.
Furthermore, we introduce a closed-loop sample generation approach tailored for
mixture models to mitigate distributional shifts. Within the unified mixture
model~(UniMM) framework, we recognize critical configurations from both model
and data perspectives. We conduct a systematic examination of various model
configurations, including positive component matching, continuous regression,
prediction horizon, and the number of components. Moreover, our investigation
into the data configuration highlights the pivotal role of closed-loop samples
in achieving realistic simulations. To extend the benefits of closed-loop
samples across a broader range of mixture models, we further address the
shortcut learning and off-policy learning issues. Leveraging insights from our
exploration, the distinct variants proposed within the UniMM framework,
including discrete, anchor-free, and anchor-based models, all achieve
state-of-the-art performance on the WOSAC benchmark.

æè¦ï¼æ¨¡æ¬å¨è©ä¼°èªåé§é§ç³»çµ±ä¸­æ®æ¼è³ééè¦çè§è²ï¼å¶ä¸­çæé¼ççå¤ä¸»é«è¡çºæ¯ééµé¢åãå¨å¤ä¸»é«æ¨¡æ¬ä¸­ï¼ä¸»è¦çææ°åæ¬è¡çºçå¤æ¨¡å¼æ§èéç°åä½è½ç§»ãå¨æ¬ç ç©¶ä¸­ï¼æåéæ°æ¢è¨æ··åæ¨¡åä¾ç¢çå¤æ¨¡å¼ä¸»é«è¡çºï¼éå¯ä»¥æ¶µèä¸»æµæ¹æ³ï¼åæ¬é£çºæ··åæ¨¡ååé¡ä¼¼ GPT çé¢æ£æ¨¡åãæ­¤å¤ï¼æåå¼å¥ä¸ç¨®éå°æ··åæ¨¡åéèº«æé çéç°æ¨£æ¬çææ¹æ³ï¼ä»¥æ¸è¼åä½è½ç§»ãå¨çµ±ä¸æ··åæ¨¡å (UniMM) æ¡æ¶ä¸­ï¼æåå¾æ¨¡ååè³æè§é»è­å¥ééµéç½®ãæåå°åç¨®æ¨¡åéç½®é²è¡ç³»çµ±æ§æ¢è¨ï¼åæ¬æ­£ååä»¶å¹éãé£çºåæ­¸ãé æ¸¬ç¯åååä»¶æ¸éãæ­¤å¤ï¼æåå°è³æéç½®çç ç©¶å¼·èª¿äºéç°æ¨£æ¬å¨å¯¦ç¾é¼çæ¨¡æ¬ä¸­çééµä½ç¨ãçºäºå°éç°æ¨£æ¬çåªé»æ´å±å°æ´å»£æ³çæ··åæ¨¡åä¸­ï¼æåé²ä¸æ­¥è§£æ±ºæ·å¾å­¸ç¿åéç­ç¥å­¸ç¿åé¡ãå©ç¨æåæ¢ç´¢ä¸­çè¦è§£ï¼å¨ UniMM æ¡æ¶å§æåºçä¸åè®é«ï¼åæ¬é¢æ£ãç¡é¨é»ååºæ¼é¨é»çæ¨¡åï¼å¨ WOSAC åºæºä¸é½éå°æåé²çæè½ã

##### **Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver**
2501.16986v1 by Shunya Minami, Kouhei Nakaji, Yohichi Suzuki, AlÃ¡n Aspuru-Guzik, Tadashi Kadowaki

Quantum computing is entering a transformative phase with the emergence of
logical quantum processors, which hold the potential to tackle complex problems
beyond classical capabilities. While significant progress has been made,
applying quantum algorithms to real-world problems remains challenging. Hybrid
quantum-classical techniques have been explored to bridge this gap, but they
often face limitations in expressiveness, trainability, or scalability. In this
work, we introduce conditional Generative Quantum Eigensolver
(conditional-GQE), a context-aware quantum circuit generator powered by an
encoder-decoder Transformer. Focusing on combinatorial optimization, we train
our generator for solving problems with up to 10 qubits, exhibiting nearly
perfect performance on new problems. By leveraging the high expressiveness and
flexibility of classical generative models, along with an efficient
preference-based training scheme, conditional-GQE provides a generalizable and
scalable framework for quantum circuit generation. Our approach advances hybrid
quantum-classical computing and contributes to accelerate the transition toward
fault-tolerant quantum computing.

æè¦ï¼éå­éç®æ­£é²å¥ä¸åè½åéæ®µï¼éééè¼¯éå­èçå¨çåºç¾ï¼å®å·åè§£æ±ºè¤éåé¡çæ½åï¼è¶è¶å³çµ±çè½åãåç®¡å·²åå¾éå¤§é²å±ï¼å°éå­æ¼ç®æ³æç¨æ¼ç¾å¯¦ä¸ççåé¡ä»ç¶å·æææ°æ§ãæ··åéå­å¤å¸æè¡å·²è¢«æ¢ç´¢ç¨æ¼å½åæ­¤å·®è·ï¼ä½å®åå¨è¡¨éè½åãå¯è¨ç·´æ§æå¯æ´åæ§æ¹é¢å¸¸å¸¸é¢è¨éå¶ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºæ¢ä»¶çæéå­æ¬å¾µæ±è§£å¨ (conditional-GQE)ï¼éæ¯ä¸åç±ç·¨ç¢¼å¨è§£ç¢¼å¨ Transformer æä¾ååçæå¢æç¥éå­é»è·¯çæå¨ãå°æ³¨æ¼çµåæä½³åï¼æåè¨ç·´æåççæå¨ä¾è§£æ±ºé«é 10 åéå­ä½çåé¡ï¼å¨æ°çåé¡ä¸è¡¨ç¾åºæ¥è¿å®ç¾çæè½ãééå©ç¨å¤å¸çææ¨¡åçé«è¡¨éè½ååéæ´»æ§ï¼ä»¥åä¸ç¨®ææåºæ¼åå¥½çè¨ç·´æ¹æ¡ï¼æ¢ä»¶çæéå­æ¬å¾µæ±è§£å¨æä¾äºä¸åå¯æ¦æ¬ä¸å¯æ´åçéå­é»è·¯çææ¶æ§ãæåçåæ³æ¨åäºæ··åéå­å¤å¸éç®ï¼ä¸¦æå©æ¼å éæåå®¹é¯éå­éç®çéæ¸¡ã

##### **Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling**
2501.16975v1 by Hongzhi Huang, Defa Zhu, Banggu Wu, Yutao Zeng, Ya Wang, Qiyang Min, Xun Zhou

Tokenization is a fundamental component of large language models (LLMs), yet
its influence on model scaling and performance is not fully explored. In this
paper, we introduce Over-Tokenized Transformers, a novel framework that
decouples input and output vocabularies to improve language modeling
performance. Specifically, our approach scales up input vocabularies to
leverage multi-gram tokens. Through extensive experiments, we uncover a
log-linear relationship between input vocabulary size and training loss,
demonstrating that larger input vocabularies consistently enhance model
performance, regardless of model size. Using a large input vocabulary, we
achieve performance comparable to double-sized baselines with no additional
cost. Our findings highlight the importance of tokenization in scaling laws and
provide practical insight for tokenizer design, paving the way for more
efficient and powerful LLMs.

æè¦ï¼åè©æ¯å¤§åèªè¨æ¨¡å (LLM) çåºæ¬çµæé¨åï¼ä½
å¶å°æ¨¡åæ´å±åæè½çå½±é¿å°æªå®å¨æ¢ç´¢ãå¨æ¬æä¸­ï¼
æåä»ç´¹éåº¦åè©Transformerï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼
å®è§£è¦è¼¸å¥åè¼¸åºè©å½è¡¨ä»¥æ¹åèªè¨å»ºæ¨¡
æè½ãå·é«ä¾èªªï¼æåçåæ³æ¯æ´å±è¼¸å¥è©å½è¡¨ä»¥
å©ç¨å¤å­åè©å½ãééå»£æ³çå¯¦é©ï¼æåç¼ç¾è¼¸å¥è©å½éå¤§å°åè¨ç·´æå¤±ä¹éå­å¨å°æ¸ç·æ§éä¿ï¼
è­æäºè¼å¤§çè¼¸å¥è©å½éå§çµå¢å¼·æ¨¡å
æè½ï¼ç¡è«æ¨¡åå¤§å°å¦ä½ãä½¿ç¨å¤§éçè¼¸å¥è©å½éï¼æå
å¯¦ç¾èéåå¤§å°åºæºç¸ç¶çæè½ï¼èæ²æé¡å¤ç
ææ¬ãæåçç¼ç¾çªé¡¯äºåè©å¨æ´åå®å¾ä¸­çéè¦æ§ï¼
ä¸¦çºåè©å¨è¨­è¨æä¾äºå¯¦ç¨çè¦è§£ï¼çºæ´å¤
é«æä¸å¼·å¤§ç LLM éªå¹³äºéè·¯ã

