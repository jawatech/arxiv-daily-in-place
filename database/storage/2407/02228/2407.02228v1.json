{"2407.02228": {"publish_time": "2024-07-02", "title": "MTMamba: Enhancing Multi-Task Dense Scene Understanding by Mamba-Based Decoders", "paper_summary": "Multi-task dense scene understanding, which learns a model for multiple dense\nprediction tasks, has a wide range of application scenarios. Modeling\nlong-range dependency and enhancing cross-task interactions are crucial to\nmulti-task dense prediction. In this paper, we propose MTMamba, a novel\nMamba-based architecture for multi-task scene understanding. It contains two\ntypes of core blocks: self-task Mamba (STM) block and cross-task Mamba (CTM)\nblock. STM handles long-range dependency by leveraging Mamba, while CTM\nexplicitly models task interactions to facilitate information exchange across\ntasks. Experiments on NYUDv2 and PASCAL-Context datasets demonstrate the\nsuperior performance of MTMamba over Transformer-based and CNN-based methods.\nNotably, on the PASCAL-Context dataset, MTMamba achieves improvements of +2.08,\n+5.01, and +4.90 over the previous best method in the tasks of semantic\nsegmentation, human parsing, and object boundary detection, respectively. The\ncode is available at \\url{https://github.com/EnVision-Research/MTMamba}.", "paper_summary_zh": "\u591a\u4efb\u52a1\u5bc6\u96c6\u573a\u666f\u7406\u89e3\uff0c\u5b66\u4e60\u4e00\u4e2a\u9488\u5bf9\u591a\u4e2a\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\u7684\u6a21\u578b\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u3002\u5bf9\u591a\u4efb\u52a1\u5bc6\u96c6\u9884\u6d4b\u800c\u8a00\uff0c\u5efa\u6a21\u8fdc\u7a0b\u4f9d\u8d56\u6027\u548c\u589e\u5f3a\u8de8\u4efb\u52a1\u4ea4\u4e92\u81f3\u5173\u91cd\u8981\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 MTMamba\uff0c\u4e00\u79cd\u7528\u4e8e\u591a\u4efb\u52a1\u573a\u666f\u7406\u89e3\u7684\u65b0\u578b\u57fa\u4e8e Mamba \u7684\u67b6\u6784\u3002\u5b83\u5305\u542b\u4e24\u79cd\u7c7b\u578b\u7684\u6838\u5fc3\u6a21\u5757\uff1a\u81ea\u4efb\u52a1 Mamba (STM) \u6a21\u5757\u548c\u8de8\u4efb\u52a1 Mamba (CTM) \u6a21\u5757\u3002STM \u901a\u8fc7\u5229\u7528 Mamba \u5904\u7406\u8fdc\u7a0b\u4f9d\u8d56\u6027\uff0c\u800c CTM \u660e\u786e\u5efa\u6a21\u4efb\u52a1\u4ea4\u4e92\u4ee5\u4fc3\u8fdb\u8de8\u4efb\u52a1\u7684\u4fe1\u606f\u4ea4\u6362\u3002\u5728 NYUDv2 \u548c PASCAL-Context \u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMTMamba \u4f18\u4e8e\u57fa\u4e8e Transformer \u548c\u57fa\u4e8e CNN \u7684\u65b9\u6cd5\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728 PASCAL-Context \u6570\u636e\u96c6\u4e2d\uff0cMTMamba \u5728\u8bed\u4e49\u5206\u5272\u3001\u4eba\u4f53\u89e3\u6790\u548c\u5bf9\u8c61\u8fb9\u754c\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5206\u522b\u6bd4\u4e4b\u524d\u6700\u597d\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e86 +2.08\u3001+5.01 \u548c +4.90\u3002\u4ee3\u7801\u53ef\u5728 \\url{https://github.com/EnVision-Research/MTMamba} \u83b7\u5f97\u3002", "author": "Baijiong Lin et.al.", "authors": "Baijiong Lin, Weisen Jiang, Pengguang Chen, Yu Zhang, Shu Liu, Ying-Cong Chen", "id": "2407.02228v1", "paper_url": "http://arxiv.org/abs/2407.02228v1", "repo": "https://github.com/envision-research/mtmamba"}}