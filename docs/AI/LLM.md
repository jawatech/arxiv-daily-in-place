
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-14**|**Towards Enhanced RAC Accessibility: Leveraging Datasets and LLMs**|Edison Jair Bejarano Sepulveda et.al.|[2405.08792v1](http://arxiv.org/abs/2405.08792v1)|null|
|**2024-05-14**|**Kolmogorov-Arnold Networks (KANs) for Time Series Analysis**|Cristian J. Vaca-Rubio et.al.|[2405.08790v1](http://arxiv.org/abs/2405.08790v1)|null|
|**2024-05-14**|**Refinement of an Epilepsy Dictionary through Human Annotation of Health-related posts on Instagram**|Aehong Min et.al.|[2405.08784v1](http://arxiv.org/abs/2405.08784v1)|null|
|**2024-05-14**|**Harnessing the power of longitudinal medical imaging for eye disease prognosis using Transformer-based sequence modeling**|Gregory Holste et.al.|[2405.08780v1](http://arxiv.org/abs/2405.08780v1)|null|
|**2024-05-14**|**EfficientTrain++: Generalized Curriculum Learning for Efficient Visual Backbone Training**|Yulin Wang et.al.|[2405.08768v1](http://arxiv.org/abs/2405.08768v1)|[link](https://github.com/leaplabthu/efficienttrain)|
|**2024-05-14**|**Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent Resolution in LLMs**|Akhila Yerukola et.al.|[2405.08760v1](http://arxiv.org/abs/2405.08760v1)|[link](https://github.com/Akhila-Yerukola/generative-intention-resolution)|
|**2024-05-14**|**Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach**|Syed Mhamudul Hasan et.al.|[2405.08755v1](http://arxiv.org/abs/2405.08755v1)|null|
|**2024-05-14**|**From Text to Context: An Entailment Approach for News Stakeholder Classification**|Alapan Kuila et.al.|[2405.08751v1](http://arxiv.org/abs/2405.08751v1)|null|
|**2024-05-14**|**Achieving Fairness Through Channel Pruning for Dermatological Disease Diagnosis**|Qingpeng Kong et.al.|[2405.08681v1](http://arxiv.org/abs/2405.08681v1)|[link](https://github.com/kqp1227/sensitive-channel-pruning)|
|**2024-05-14**|**Investigating Design Choices in Joint-Embedding Predictive Architectures for General Audio Representation Learning**|Alain Riou et.al.|[2405.08679v1](http://arxiv.org/abs/2405.08679v1)|null|
|**2024-05-14**|**Expensive Multi-Objective Bayesian Optimization Based on Diffusion Models**|Bingdong Li et.al.|[2405.08674v1](http://arxiv.org/abs/2405.08674v1)|null|
|**2024-05-14**|**Promoting AI Equity in Science: Generalized Domain Prompt Learning for Accessible VLM Research**|Qinglong Cao et.al.|[2405.08668v1](http://arxiv.org/abs/2405.08668v1)|[link](https://github.com/caoql98/GDPL)|
|**2024-05-14**|**Beyond the Black Box: Do More Complex Models Provide Superior XAI Explanations?**|Mateusz Cedro et.al.|[2405.08658v1](http://arxiv.org/abs/2405.08658v1)|null|
|**2024-05-14**|**Thinking Tokens for Language Modeling**|David Herel et.al.|[2405.08644v1](http://arxiv.org/abs/2405.08644v1)|null|
|**2024-05-14**|**ALMol: Aligned Language-Molecule Translation LLMs through Offline Preference Contrastive Optimisation**|Dimitris Gkoumas et.al.|[2405.08619v2](http://arxiv.org/abs/2405.08619v2)|null|
|**2024-05-14**|**Towards Geometry-Aware Pareto Set Learning for Neural Multi-Objective Combinatorial Optimization**|Yongfan Lu et.al.|[2405.08604v1](http://arxiv.org/abs/2405.08604v1)|null|
|**2024-05-14**|**A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine**|Hanguang Xiao et.al.|[2405.08603v1](http://arxiv.org/abs/2405.08603v1)|null|
|**2024-05-14**|**EchoTracker: Advancing Myocardial Point Tracking in Echocardiography**|Md Abulkalam Azad et.al.|[2405.08587v1](http://arxiv.org/abs/2405.08587v1)|null|
|**2024-05-14**|**Rethinking the adaptive relationship between Encoder Layers and Decoder Layers**|Yubo Song et.al.|[2405.08570v1](http://arxiv.org/abs/2405.08570v1)|null|
|**2024-05-14**|**The Unseen Targets of Hate -- A Systematic Review of Hateful Communication Datasets**|Zehui Yu et.al.|[2405.08562v1](http://arxiv.org/abs/2405.08562v1)|null|
|**2024-05-14**|**Improving Transformers with Dynamically Composable Multi-Head Attention**|Da Xiao et.al.|[2405.08553v1](http://arxiv.org/abs/2405.08553v1)|[link](https://github.com/caiyun-ai/dcformer)|
|**2024-05-14**|**Generalizing Knowledge Graph Embedding with Universal Orthogonal Parameterization**|Rui Li et.al.|[2405.08540v1](http://arxiv.org/abs/2405.08540v1)|[link](https://github.com/xxrep/golde)|
|**2024-05-14**|**From Internet of Things Data to Business Processes: Challenges and a Framework**|Juergen Mangler et.al.|[2405.08528v1](http://arxiv.org/abs/2405.08528v1)|null|
|**2024-05-14**|**Falcon 7b for Software Mention Detection in Scholarly Documents**|AmeerAli Khan et.al.|[2405.08514v1](http://arxiv.org/abs/2405.08514v1)|null|
|**2024-05-14**|**Archimedes-AUEB at SemEval-2024 Task 5: LLM explains Civil Procedure**|Odysseas S. Chlapanis et.al.|[2405.08502v1](http://arxiv.org/abs/2405.08502v1)|null|
|**2024-05-14**|**Is Less More? Quality, Quantity and Context in Idiom Processing with Natural Language Models**|Agne Knietaite et.al.|[2405.08497v1](http://arxiv.org/abs/2405.08497v1)|null|
|**2024-05-14**|**Enhancing Gender-Inclusive Machine Translation with Neomorphemes and Large Language Models**|Andrea Piergentili et.al.|[2405.08477v1](http://arxiv.org/abs/2405.08477v1)|null|
|**2024-05-14**|**GPT-3.5 for Grammatical Error Correction**|Anisia Katinskaia et.al.|[2405.08469v1](http://arxiv.org/abs/2405.08469v1)|null|
|**2024-05-14**|**Challenges and Opportunities in Text Generation Explainability**|Kenza Amara et.al.|[2405.08468v1](http://arxiv.org/abs/2405.08468v1)|null|
|**2024-05-14**|**Evaluating LLMs at Evaluating Temporal Generalization**|Chenghao Zhu et.al.|[2405.08460v1](http://arxiv.org/abs/2405.08460v1)|[link](https://github.com/freedomintelligence/freshbench)|
|**2024-05-14**|**How Alignment Helps Make the Most of Multimodal Data**|Christian Arnold et.al.|[2405.08454v1](http://arxiv.org/abs/2405.08454v1)|null|
|**2024-05-14**|**Understanding the performance gap between online and offline alignment algorithms**|Yunhao Tang et.al.|[2405.08448v1](http://arxiv.org/abs/2405.08448v1)|null|
|**2024-05-14**|**Impact of Stickers on Multimodal Chat Sentiment Analysis and Intent Recognition: A New Task, Dataset and Baseline**|Yuanchen Shi et.al.|[2405.08427v1](http://arxiv.org/abs/2405.08427v1)|null|
|**2024-05-14**|**Investigating the 'Autoencoder Behavior' in Speech Self-Supervised Models: a focus on HuBERT's Pretraining**|Valentin Vielzeuf et.al.|[2405.08402v1](http://arxiv.org/abs/2405.08402v1)|null|
|**2024-05-14**|**Stylometric Watermarks for Large Language Models**|Georg Niess et.al.|[2405.08400v1](http://arxiv.org/abs/2405.08400v1)|null|
|**2024-05-14**|**CIER: A Novel Experience Replay Approach with Causal Inference in Deep Reinforcement Learning**|Jingwen Wang et.al.|[2405.08380v1](http://arxiv.org/abs/2405.08380v1)|null|
|**2024-05-14**|**PromptMind Team at MEDIQA-CORR 2024: Improving Clinical Text Correction with Error Categorization and LLM Ensembles**|Satya Kesav Gundabathula et.al.|[2405.08373v1](http://arxiv.org/abs/2405.08373v1)|null|
|**2024-05-14**|**Seal-Tools: Self-Instruct Tool Learning Dataset for Agent Tuning and Detailed Benchmark**|Mengsong Wu et.al.|[2405.08355v1](http://arxiv.org/abs/2405.08355v1)|null|
|**2024-05-14**|**Perivascular space Identification Nnunet for Generalised Usage (PINGU)**|Benjamin Sinclair et.al.|[2405.08337v1](http://arxiv.org/abs/2405.08337v1)|null|
|**2024-05-14**|**Could Chemical LLMs benefit from Message Passing**|Jiaqing Xie et.al.|[2405.08334v1](http://arxiv.org/abs/2405.08334v1)|null|
|**2024-05-14**|**Cross-Dataset Generalization For Retinal Lesions Segmentation**|Clément Playout et.al.|[2405.08329v1](http://arxiv.org/abs/2405.08329v1)|null|
|**2024-05-14**|**SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large Language Models**|Raghuveer Peri et.al.|[2405.08317v1](http://arxiv.org/abs/2405.08317v1)|null|
|**2024-05-14**|**A Decoupling and Aggregating Framework for Joint Extraction of Entities and Relations**|Yao Wang et.al.|[2405.08311v1](http://arxiv.org/abs/2405.08311v1)|null|
|**2024-05-14**|**Computational Thought Experiments for a More Rigorous Philosophy and Science of the Mind**|Iris Oved et.al.|[2405.08304v2](http://arxiv.org/abs/2405.08304v2)|null|
|**2024-05-14**|**Distance-Restricted Explanations: Theoretical Underpinnings & Efficient Implementation**|Yacine Izza et.al.|[2405.08297v1](http://arxiv.org/abs/2405.08297v1)|null|
|**2024-05-14**|**SpeechVerse: A Large-scale Generalizable Audio Language Model**|Nilaksh Das et.al.|[2405.08295v1](http://arxiv.org/abs/2405.08295v1)|null|
|**2024-05-14**|**Detecting Fallacies in Climate Misinformation: A Technocognitive Approach to Identifying Misleading Argumentation**|Francisco Zanartu et.al.|[2405.08254v1](http://arxiv.org/abs/2405.08254v1)|null|
|**2024-05-14**|**Smart Sampling: Self-Attention and Bootstrapping for Improved Ensembled Q-Learning**|Muhammad Junaid Khan et.al.|[2405.08252v1](http://arxiv.org/abs/2405.08252v1)|null|
|**2024-05-14**|**Automated classification of multi-parametric body MRI series**|Boah Kim et.al.|[2405.08247v1](http://arxiv.org/abs/2405.08247v1)|null|
|**2024-05-14**|**Compositional Text-to-Image Generation with Dense Blob Representations**|Weili Nie et.al.|[2405.08246v1](http://arxiv.org/abs/2405.08246v1)|null|
|**2024-05-14**|**Progressive enhancement and restoration for mural images under low-light and defected conditions based on multi-receptive field strategy**|Xiameng Wei et.al.|[2405.08245v1](http://arxiv.org/abs/2405.08245v1)|null|
|**2024-05-13**|**Silver-Tongued and Sundry: Exploring Intersectional Pronouns with ChatGPT**|Takao Fujii et.al.|[2405.08238v1](http://arxiv.org/abs/2405.08238v1)|null|
|**2024-05-13**|**A predictive learning model can simulate temporal dynamics and context effects found in neural representations of continuous speech**|Oli Danyi Liu et.al.|[2405.08237v1](http://arxiv.org/abs/2405.08237v1)|null|
|**2024-05-13**|**An information-theoretic model of shallow and deep language comprehension**|Jiaxuan Li et.al.|[2405.08223v1](http://arxiv.org/abs/2405.08223v1)|null|
|**2024-05-13**|**Interpreting Latent Student Knowledge Representations in Programming Assignments**|Nigel Fernandez et.al.|[2405.08213v1](http://arxiv.org/abs/2405.08213v1)|null|
|**2024-05-13**|**Towards Energy-Aware Federated Learning via MARL: A Dual-Selection Approach for Model and Client**|Jun Xia et.al.|[2405.08183v1](http://arxiv.org/abs/2405.08183v1)|null|
|**2024-05-13**|**Estimating Direct and Indirect Causal Effects of Spatiotemporal Interventions in Presence of Spatial Interference**|Sahara Ali et.al.|[2405.08174v1](http://arxiv.org/abs/2405.08174v1)|null|
|**2024-05-13**|**CANTONMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation**|Kung Yin Hong et.al.|[2405.08172v1](http://arxiv.org/abs/2405.08172v1)|[link](https://github.com/kenrickkung/cantonesetranslation)|
|**2024-05-13**|**LLM Theory of Mind and Alignment: Opportunities and Risks**|Winnie Street et.al.|[2405.08154v1](http://arxiv.org/abs/2405.08154v1)|null|
|**2024-05-13**|**Benchmarking Retrieval-Augmented Large Language Models in Biomedical NLP: Application, Robustness, and Self-Awareness**|Mingchen Li et.al.|[2405.08151v1](http://arxiv.org/abs/2405.08151v1)|null|
|**2024-05-13**|**Many-Shot Regurgitation (MSR) Prompting**|Shashank Sonkar et.al.|[2405.08134v1](http://arxiv.org/abs/2405.08134v1)|[link](https://github.com/luffycodes/Many-Shot-Regurgitation-MIA)|
|**2024-05-13**|**When factorization meets argumentation: towards argumentative explanations**|Jinfeng Zhong et.al.|[2405.08131v1](http://arxiv.org/abs/2405.08131v1)|null|
|**2024-05-13**|**From Questions to Insightful Answers: Building an Informed Chatbot for University Resources**|Subash Neupane et.al.|[2405.08120v1](http://arxiv.org/abs/2405.08120v1)|null|
|**2024-05-13**|**KET-QA: A Dataset for Knowledge Enhanced Table Question Answering**|Mengkang Hu et.al.|[2405.08099v1](http://arxiv.org/abs/2405.08099v1)|null|
|**2024-05-13**|**MambaOut: Do We Really Need Mamba for Vision?**|Weihao Yu et.al.|[2405.07992v2](http://arxiv.org/abs/2405.07992v2)|[link](https://github.com/yuweihao/mambaout)|
|**2024-05-13**|**Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots**|Chengyue Wu et.al.|[2405.07990v1](http://arxiv.org/abs/2405.07990v1)|null|
|**2024-05-13**|**The Platonic Representation Hypothesis**|Minyoung Huh et.al.|[2405.07987v1](http://arxiv.org/abs/2405.07987v1)|[link](https://github.com/minyoungg/platonic-rep)|
|**2024-05-13**|**Localized Adaptive Risk Control**|Matteo Zecchin et.al.|[2405.07976v1](http://arxiv.org/abs/2405.07976v1)|[link](https://github.com/kclip/localized-adaptive-risk-control)|
|**2024-05-13**|**Investigating the Semantic Robustness of CLIP-based Zero-Shot Anomaly Segmentation**|Kevin Stangl et.al.|[2405.07969v1](http://arxiv.org/abs/2405.07969v1)|null|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments**|Samuel Schmidgall et.al.|[2405.07960v1](http://arxiv.org/abs/2405.07960v1)|null|
|**2024-05-13**|**Hierarchical Decision Mamba**|André Correia et.al.|[2405.07943v1](http://arxiv.org/abs/2405.07943v1)|[link](https://github.com/meowatthemoon/hierarchicaldecisionmamba)|
|**2024-05-13**|**RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors**|Liam Dugan et.al.|[2405.07940v1](http://arxiv.org/abs/2405.07940v1)|null|
|**2024-05-13**|**EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning**|Yinzhu Quan et.al.|[2405.07938v1](http://arxiv.org/abs/2405.07938v1)|null|
|**2024-05-13**|**PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition**|Ziyang Zhang et.al.|[2405.07932v2](http://arxiv.org/abs/2405.07932v2)|[link](https://github.com/ed-zh/parden)|
|**2024-05-13**|**Stable Diffusion-based Data Augmentation for Federated Learning with Non-IID Data**|Mahdi Morafah et.al.|[2405.07925v1](http://arxiv.org/abs/2405.07925v1)|null|
|**2024-05-13**|**Science based AI model certification for new operational environments with application in traffic state estimation**|Daryl Mupupuni et.al.|[2405.07893v1](http://arxiv.org/abs/2405.07893v1)|null|
|**2024-05-13**|**Russian-Language Multimodal Dataset for Automatic Summarization of Scientific Papers**|Alena Tsanda et.al.|[2405.07886v1](http://arxiv.org/abs/2405.07886v1)|null|
|**2024-05-13**|**Zero-Shot Tokenizer Transfer**|Benjamin Minixhofer et.al.|[2405.07883v1](http://arxiv.org/abs/2405.07883v1)|[link](https://github.com/bminixhofer/zett)|
|**2024-05-13**|**Reproducing the Metric-Based Evaluation of a Set of Controllable Text Generation Techniques**|Michela Lorandi et.al.|[2405.07875v1](http://arxiv.org/abs/2405.07875v1)|null|
|**2024-05-13**|**RLHF Workflow: From Reward Modeling to Online RLHF**|Hanze Dong et.al.|[2405.07863v1](http://arxiv.org/abs/2405.07863v1)|[link](https://github.com/rlhflow/online-rlhf)|
|**2024-05-13**|**Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM**|Xiaoyu Chen et.al.|[2405.07840v1](http://arxiv.org/abs/2405.07840v1)|null|
|**2024-05-13**|**Synthetic Tabular Data Validation: A Divergence-Based Approach**|Patricia A. Apellániz et.al.|[2405.07822v1](http://arxiv.org/abs/2405.07822v1)|[link](https://github.com/patricia-a-apellaniz/divergence_estimator)|
|**2024-05-13**|**Quick and Accurate Affordance Learning**|Fedor Scholz et.al.|[2405.07816v1](http://arxiv.org/abs/2405.07816v1)|null|
|**2024-05-13**|**Decoding Geometric Properties in Non-Random Data from First Information-Theoretic Principles**|Hector Zenil et.al.|[2405.07803v1](http://arxiv.org/abs/2405.07803v1)|null|
|**2024-05-13**|**FreeVA: Offline MLLM as Training-Free Video Assistant**|Wenhao Wu et.al.|[2405.07798v1](http://arxiv.org/abs/2405.07798v1)|[link](https://github.com/whwu95/freeva)|
|**2024-05-13**|**DEPTH: Discourse Education through Pre-Training Hierarchically**|Zachary Bamberger et.al.|[2405.07788v1](http://arxiv.org/abs/2405.07788v1)|[link](https://github.com/zbambergerNLP/depth)|
|**2024-05-13**|**A Comprehensive Analysis of Static Word Embeddings for Turkish**|Karahan Sarıtaş et.al.|[2405.07778v1](http://arxiv.org/abs/2405.07778v1)|[link](https://github.com/turkish-word-embeddings/word-embeddings-repository-for-turkish)|
|**2024-05-13**|**Human-Modeling in Sequential Decision-Making: An Analysis through the Lens of Human-Aware AI**|Silvia Tulli et.al.|[2405.07773v1](http://arxiv.org/abs/2405.07773v1)|null|
|**2024-05-13**|**Synthetic Test Collections for Retrieval Evaluation**|Hossein A. Rahmani et.al.|[2405.07767v1](http://arxiv.org/abs/2405.07767v1)|null|
|**2024-05-13**|**Challenges and Opportunities of NLP for HR Applications: A Discussion Paper**|Jochen L. Leidner et.al.|[2405.07766v1](http://arxiv.org/abs/2405.07766v1)|null|
|**2024-05-13**|**TANQ: An open domain dataset of table answered questions**|Mubashara Akhtar et.al.|[2405.07765v1](http://arxiv.org/abs/2405.07765v1)|null|
|**2024-05-13**|**LLM4ED: Large Language Models for Automatic Equation Discovery**|Mengge Du et.al.|[2405.07761v1](http://arxiv.org/abs/2405.07761v1)|null|
|**2024-05-13**|**MADRL-Based Rate Adaptation for 360$\degree$ Video Streaming with Multi-Viewpoint Prediction**|Haopeng Wang et.al.|[2405.07759v1](http://arxiv.org/abs/2405.07759v1)|null|
|**2024-05-13**|**Mitigating federated learning contribution allocation instability through randomized aggregation**|Arno Geimer et.al.|[2405.08044v1](http://arxiv.org/abs/2405.08044v1)|null|
|**2024-05-13**|**LlamaTurk: Adapting Open-Source Generative Large Language Models for Low-Resource Language**|Cagri Toraman et.al.|[2405.07745v1](http://arxiv.org/abs/2405.07745v1)|[link](https://github.com/metunlp/llamaturk)|
|**2024-05-13**|**Federated Hierarchical Tensor Networks: a Collaborative Learning Quantum AI-Driven Framework for Healthcare**|Amandeep Singh Bhatia et.al.|[2405.07735v1](http://arxiv.org/abs/2405.07735v1)|null|
|**2024-05-13**|**Quantifying and Optimizing Global Faithfulness in Persona-driven Role-playing**|Letian Peng et.al.|[2405.07726v1](http://arxiv.org/abs/2405.07726v1)|[link](https://github.com/KomeijiForce/Active_Passive_Constraint_Koishiday_2024)|
|**2024-05-13**|**A Unified Sequence Parallelism Approach for Long Context Generative AI**|Jiarui Fang et.al.|[2405.07719v3](http://arxiv.org/abs/2405.07719v3)|[link](https://github.com/feifeibear/long-context-attention)|
|**2024-05-13**|**OpenLLM-Ro -- Technical Report on Open-source Romanian LLMs trained starting from Llama 2**|Mihai Masala et.al.|[2405.07703v3](http://arxiv.org/abs/2405.07703v3)|null|

#### Abstracts
##### **Towards Enhanced RAC Accessibility: Leveraging Datasets and LLMs**
2405.08792v1 by Edison Jair Bejarano Sepulveda, Nicolai Potes Hector, Santiago Pineda Montoya, Felipe Ivan Rodriguez, Jaime Enrique Orduy, Alec Rosales Cabezas, Danny Traslaviña Navarrete, Sergio Madrid Farfan

This paper explores the potential of large language models (LLMs) to make the
Aeronautical Regulations of Colombia (RAC) more accessible. Given the
complexity and extensive technicality of the RAC, this study introduces a novel
approach to simplifying these regulations for broader understanding. By
developing the first-ever RAC database, which contains 24,478 expertly labeled
question-and-answer pairs, and fine-tuning LLMs specifically for RAC
applications, the paper outlines the methodology for dataset assembly,
expert-led annotation, and model training. Utilizing the Gemma1.1 2b model
along with advanced techniques like Unsloth for efficient VRAM usage and flash
attention mechanisms, the research aims to expedite training processes. This
initiative establishes a foundation to enhance the comprehensibility and
accessibility of RAC, potentially benefiting novices and reducing dependence on
expert consultations for navigating the aviation industry's regulatory
landscape.
  You can visit the dataset
(https://huggingface.co/somosnlp/gemma-1.1-2b-it_ColombiaRAC_FullyCurated_format_chatML_V1)
and the model
(https://huggingface.co/datasets/somosnlp/ColombiaRAC_FullyCurated) here.

摘要：本文探討大型語言模型 (LLM) 讓哥倫比亞航空法規 (RAC) 更容易理解的潛力。鑑於 RAC 的複雜性和廣泛技術性，本研究提出了一種簡化這些法規以促進更廣泛理解的新穎方法。透過開發有史以來第一個 RAC 資料庫，其中包含 24,478 個由專家標記的問題和答案對，並針對 RAC 應用微調 LLM，本文概述了資料集組裝、專家主導註解和模型訓練的方法。本研究利用 Gemma1.1 2b 模型以及 Unsloth 等先進技術，以有效利用 VRAM 和閃現注意力機制，旨在加速訓練過程。此舉建立了一個基礎，以增強 RAC 的可理解性和可及性，潛在受益於新手，並減少對專家諮詢的依賴，以了解航空業的法規環境。您可以在此處查看資料集 (https://huggingface.co/somosnlp/gemma-1.1-2b-it_ColombiaRAC_FullyCurated_format_chatML_V1) 和模型 (https://huggingface.co/datasets/somosnlp/ColombiaRAC_FullyCurated)。

##### **Kolmogorov-Arnold Networks (KANs) for Time Series Analysis**
2405.08790v1 by Cristian J. Vaca-Rubio, Luis Blanco, Roberto Pereira, Màrius Caus

This paper introduces a novel application of Kolmogorov-Arnold Networks
(KANs) to time series forecasting, leveraging their adaptive activation
functions for enhanced predictive modeling. Inspired by the Kolmogorov-Arnold
representation theorem, KANs replace traditional linear weights with
spline-parametrized univariate functions, allowing them to learn activation
patterns dynamically. We demonstrate that KANs outperforms conventional
Multi-Layer Perceptrons (MLPs) in a real-world satellite traffic forecasting
task, providing more accurate results with considerably fewer number of
learnable parameters. We also provide an ablation study of KAN-specific
parameters impact on performance. The proposed approach opens new avenues for
adaptive forecasting models, emphasizing the potential of KANs as a powerful
tool in predictive analytics.

摘要：本文介紹了 Kolmogorov-Arnold 網路 (KAN) 在時間序列預測的新穎應用，利用其自適應激活函數來增強預測模型。受 Kolmogorov-Arnold 表示定理的啟發，KAN 以樣條參數化的單變數函數取代傳統線性權重，讓它們能夠動態學習激活模式。我們展示了 KAN 在實際衛星流量預測任務中優於傳統多層感知器 (MLP)，在可學習參數數量顯著減少的情況下提供了更準確的結果。我們還提供了 KAN 特定參數對效能影響的消融研究。所提出的方法為自適應預測模型開啟了新的途徑，強調了 KAN 作為預測分析中強大工具的潛力。

##### **Refinement of an Epilepsy Dictionary through Human Annotation of Health-related posts on Instagram**
2405.08784v1 by Aehong Min, Xuan Wang, Rion Brattig Correia, Jordan Rozum, Wendy R. Miller, Luis M. Rocha

We used a dictionary built from biomedical terminology extracted from various
sources such as DrugBank, MedDRA, MedlinePlus, TCMGeneDIT, to tag more than 8
million Instagram posts by users who have mentioned an epilepsy-relevant drug
at least once, between 2010 and early 2016. A random sample of 1,771 posts with
2,947 term matches was evaluated by human annotators to identify
false-positives. OpenAI's GPT series models were compared against human
annotation. Frequent terms with a high false-positive rate were removed from
the dictionary. Analysis of the estimated false-positive rates of the annotated
terms revealed 8 ambiguous terms (plus synonyms) used in Instagram posts, which
were removed from the original dictionary. To study the effect of removing
those terms, we constructed knowledge networks using the refined and the
original dictionaries and performed an eigenvector-centrality analysis on both
networks. We show that the refined dictionary thus produced leads to a
significantly different rank of important terms, as measured by their
eigenvector-centrality of the knowledge networks. Furthermore, the most
important terms obtained after refinement are of greater medical relevance. In
addition, we show that OpenAI's GPT series models fare worse than human
annotators in this task.

摘要：我們使用從各種來源（例如 DrugBank、MedDRA、MedlinePlus、TCMGeneDIT）中提取的生物醫學術語所建構的詞典，標記了 2010 年至 2016 年初之間，超過 800 萬則至少提及過一次癲癇相關藥物的 Instagram 貼文。由人類註釋者評估了 1,771 則隨機抽樣貼文，其中包含 2,947 個詞彙比對，以找出假陽性。將 OpenAI 的 GPT 系列模型與人類註釋進行比較。從詞典中移除了假陽性率高的頻繁詞彙。對註釋詞彙的估計假陽性率進行分析，揭示了 Instagram 貼文中使用的 8 個模稜兩可的詞彙（加上同義詞），這些詞彙已從原始詞典中移除。為了研究移除這些詞彙的效果，我們使用精煉過的詞典和原始詞典建構了知識網路，並對這兩個網路執行特徵向量中心性分析。我們顯示，如此產生的精煉過詞典會導致重要詞彙的排名顯著不同，這是透過知識網路的特徵向量中心性來衡量的。此外，精煉後獲得的最重要詞彙具有更大的醫療相關性。此外，我們顯示 OpenAI 的 GPT 系列模型在這個任務中的表現比人類註釋者差。

##### **Harnessing the power of longitudinal medical imaging for eye disease prognosis using Transformer-based sequence modeling**
2405.08780v1 by Gregory Holste, Mingquan Lin, Ruiwen Zhou, Fei Wang, Lei Liu, Qi Yan, Sarah H. Van Tassel, Kyle Kovacs, Emily Y. Chew, Zhiyong Lu, Zhangyang Wang, Yifan Peng

Deep learning has enabled breakthroughs in automated diagnosis from medical
imaging, with many successful applications in ophthalmology. However, standard
medical image classification approaches only assess disease presence at the
time of acquisition, neglecting the common clinical setting of longitudinal
imaging. For slow, progressive eye diseases like age-related macular
degeneration (AMD) and primary open-angle glaucoma (POAG), patients undergo
repeated imaging over time to track disease progression and forecasting the
future risk of developing disease is critical to properly plan treatment. Our
proposed Longitudinal Transformer for Survival Analysis (LTSA) enables dynamic
disease prognosis from longitudinal medical imaging, modeling the time to
disease from sequences of fundus photography images captured over long,
irregular time periods. Using longitudinal imaging data from the Age-Related
Eye Disease Study (AREDS) and Ocular Hypertension Treatment Study (OHTS), LTSA
significantly outperformed a single-image baseline in 19/20 head-to-head
comparisons on late AMD prognosis and 18/20 comparisons on POAG prognosis. A
temporal attention analysis also suggested that, while the most recent image is
typically the most influential, prior imaging still provides additional
prognostic value.

摘要：深度學習已使自動診斷從醫學影像中獲得突破，在眼科中有許多成功的應用。然而，標準的醫學影像分類方法僅在採集時評估疾病的存在，忽略了縱向影像的常見臨床設置。對於年齡相關性黃斑部病變 (AMD) 和原發性開放角型青光眼 (POAG) 等緩慢、進行性的眼疾，患者會隨著時間推移接受重複影像檢查以追蹤疾病進程，而預測未來罹患疾病的風險對於適當地規劃治療至關重要。我們提出的縱向存活分析Transformer (LTSA) 能夠根據縱向醫學影像進行動態疾病預後，建模從長時間、不規則時間段內擷取的眼底攝影影像序列到疾病的時間。使用來自年齡相關性眼疾研究 (AREDS) 和眼部高血壓治療研究 (OHTS) 的縱向影像資料，LTSA 在 19/20 個 AMD 晚期預後正面交鋒比較中和 18/20 個 POAG 預後比較中顯著優於單一影像基準。時間注意力分析也表明，雖然最近的影像通常影響最大，但先前的影像仍提供額外的預後價值。

##### **EfficientTrain++: Generalized Curriculum Learning for Efficient Visual Backbone Training**
2405.08768v1 by Yulin Wang, Yang Yue, Rui Lu, Yizeng Han, Shiji Song, Gao Huang

The superior performance of modern visual backbones usually comes with a
costly training procedure. We contribute to this issue by generalizing the idea
of curriculum learning beyond its original formulation, i.e., training models
using easier-to-harder data. Specifically, we reformulate the training
curriculum as a soft-selection function, which uncovers progressively more
difficult patterns within each example during training, instead of performing
easier-to-harder sample selection. Our work is inspired by an intriguing
observation on the learning dynamics of visual backbones: during the earlier
stages of training, the model predominantly learns to recognize some
'easier-to-learn' discriminative patterns in the data. These patterns, when
observed through frequency and spatial domains, incorporate lower-frequency
components, and the natural image contents without distortion or data
augmentation. Motivated by these findings, we propose a curriculum where the
model always leverages all the training data at every learning stage, yet the
exposure to the 'easier-to-learn' patterns of each example is initiated first,
with harder patterns gradually introduced as training progresses. To implement
this idea in a computationally efficient way, we introduce a cropping operation
in the Fourier spectrum of the inputs, enabling the model to learn from only
the lower-frequency components. Then we show that exposing the contents of
natural images can be readily achieved by modulating the intensity of data
augmentation. Finally, we integrate these aspects and design curriculum
schedules with tailored search algorithms. The resulting method,
EfficientTrain++, is simple, general, yet surprisingly effective. It reduces
the training time of a wide variety of popular models by 1.5-3.0x on
ImageNet-1K/22K without sacrificing accuracy. It also demonstrates efficacy in
self-supervised learning (e.g., MAE).

摘要：現代視覺骨幹的優異效能通常伴隨著昂貴的訓練程序。我們透過將課程學習的概念推廣到其原始公式之外來解決此問題，即使用易於難的資料訓練模型。具體來說，我們將訓練課程重新表述為軟選擇函數，在訓練期間逐步揭示每個範例中更困難的模式，而不是執行易於難的樣本選擇。我們的研究靈感來自對視覺骨幹學習動態的有趣觀察：在訓練的早期階段，模型主要學習識別資料中一些「較容易學習」的辨別模式。這些模式在透過頻率和空間域觀察時，會納入較低頻率的組成，以及沒有失真或資料增強的自然影像內容。受到這些發現的啟發，我們提出了一個課程，其中模型在每個學習階段始終利用所有訓練資料，但首先接觸每個範例的「較容易學習」模式，並隨著訓練的進展逐漸引入更困難的模式。為了以計算有效率的方式實作這個想法，我們在輸入的傅立葉頻譜中引入裁切操作，讓模型只能從較低頻率的組成學習。然後我們表明，透過調整資料增強的強度，可以輕易地揭露自然影像的內容。最後，我們整合這些面向，並設計出具備客製化搜尋演算法的課程時程。由此產生的方法 EfficientTrain++ 簡單、通用，但效果驚人。它在不犧牲準確性的情況下，將各種熱門模型在 ImageNet-1K/22K 上的訓練時間減少了 1.5-3.0 倍。它也證明了在自我監督學習（例如 MAE）中的效力。

##### **Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent Resolution in LLMs**
2405.08760v1 by Akhila Yerukola, Saujas Vaduguru, Daniel Fried, Maarten Sap

Humans often express their communicative intents indirectly or non-literally,
which requires their interlocutors -- human or AI -- to understand beyond the
literal meaning of words. While most existing work has focused on
discriminative evaluations, we present a new approach to generatively evaluate
large language models' (LLMs') intention understanding by examining their
responses to non-literal utterances. Ideally, an LLM should respond in line
with the true intention of a non-literal utterance, not its literal
interpretation. Our findings show that LLMs struggle to generate pragmatically
relevant responses to non-literal language, achieving only 50-55% accuracy on
average. While explicitly providing oracle intentions significantly improves
performance (e.g., 75% for Mistral-Instruct), this still indicates challenges
in leveraging given intentions to produce appropriate responses. Using
chain-of-thought to make models spell out intentions yields much smaller gains
(60% for Mistral-Instruct). These findings suggest that LLMs are not yet
effective pragmatic interlocutors, highlighting the need for better approaches
for modeling intentions and utilizing them for pragmatic generation.

摘要：人類經常間接或非字面地表達他們的溝通意圖，這需要他們的對話者（人類或 AI）理解超越字面意思。雖然大多數現有工作都專注於區辨性評估，但我們提出了一種生成式評估大型語言模型 (LLM) 意圖理解的新方法，方法是檢查它們對非字面語句的回應。理想情況下，LLM 應根據非字面語句的真正意圖做出回應，而不是其字面解釋。我們的研究結果表明，LLM 難以對非字面語言產生語用相關的回應，平均準確率僅為 50-55%。雖然明確提供神諭意圖顯著提高了效能（例如，Mistral-Instruct 為 75%），但這仍然表明在利用給定的意圖產生適當回應方面存在挑戰。使用思維鏈讓模型拼寫出意圖產生的增益要小得多（Mistral-Instruct 為 60%）。這些發現表明，LLM 尚未成為有效的語用對話者，突顯了對建模意圖和將其用於語用生成的更好方法的需求。

##### **Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach**
2405.08755v1 by Syed Mhamudul Hasan, Alaa M. Alotaibi, Sajedul Talukder, Abdur R. Shahid

With the proliferation of edge devices, there is a significant increase in
attack surface on these devices. The decentralized deployment of threat
intelligence on edge devices, coupled with adaptive machine learning techniques
such as the in-context learning feature of large language models (LLMs),
represents a promising paradigm for enhancing cybersecurity on low-powered edge
devices. This approach involves the deployment of lightweight machine learning
models directly onto edge devices to analyze local data streams, such as
network traffic and system logs, in real-time. Additionally, distributing
computational tasks to an edge server reduces latency and improves
responsiveness while also enhancing privacy by processing sensitive data
locally. LLM servers can enable these edge servers to autonomously adapt to
evolving threats and attack patterns, continuously updating their models to
improve detection accuracy and reduce false positives. Furthermore,
collaborative learning mechanisms facilitate peer-to-peer secure and
trustworthy knowledge sharing among edge devices, enhancing the collective
intelligence of the network and enabling dynamic threat mitigation measures
such as device quarantine in response to detected anomalies. The scalability
and flexibility of this approach make it well-suited for diverse and evolving
network environments, as edge devices only send suspicious information such as
network traffic and system log changes, offering a resilient and efficient
solution to combat emerging cyber threats at the network edge. Thus, our
proposed framework can improve edge computing security by providing better
security in cyber threat detection and mitigation by isolating the edge devices
from the network.

摘要：隨著邊緣裝置的激增，這些裝置的攻擊面顯著增加。在邊緣裝置上分散部署威脅情報，再加上自適應機器學習技術，例如大型語言模型 (LLM) 的情境學習功能，這代表了一種有前途的範例，用於增強低功耗邊緣裝置的網路安全。此方法涉及將輕量級機器學習模型直接部署到邊緣裝置上，以分析本地資料串流，例如網路流量和系統記錄，並進行即時分析。此外，將運算任務分配到邊緣伺服器可以減少延遲並改善回應能力，同時透過在本地處理敏感資料來增強隱私權。LLM 伺服器可以讓這些邊緣伺服器自主適應不斷變化的威脅和攻擊模式，持續更新其模型以提高偵測準確度並減少誤報。此外，協作學習機制促進了邊緣裝置之間的點對點安全且值得信賴的知識共享，增強了網路的集體智慧，並啟用了動態威脅緩解措施，例如針對偵測到的異常情況進行裝置隔離。這種方法的可擴充性和靈活性使其非常適合多樣化且不斷變化的網路環境，因為邊緣裝置只會傳送可疑資訊，例如網路流量和系統記錄變更，提供有韌性和有效率的解決方案來對抗網路邊緣的新興網路威脅。因此，我們提出的架構可以透過在網路威脅偵測和緩解中提供更好的安全性，以及將邊緣裝置與網路隔離，來改善邊緣運算安全性。

##### **From Text to Context: An Entailment Approach for News Stakeholder Classification**
2405.08751v1 by Alapan Kuila, Sudeshna Sarkar

Navigating the complex landscape of news articles involves understanding the
various actors or entities involved, referred to as news stakeholders. These
stakeholders, ranging from policymakers to opposition figures, citizens, and
more, play pivotal roles in shaping news narratives. Recognizing their
stakeholder types, reflecting their roles, political alignments, social
standing, and more, is paramount for a nuanced comprehension of news content.
Despite existing works focusing on salient entity extraction, coverage
variations, and political affiliations through social media data, the automated
detection of stakeholder roles within news content remains an underexplored
domain. In this paper, we bridge this gap by introducing an effective approach
to classify stakeholder types in news articles. Our method involves
transforming the stakeholder classification problem into a natural language
inference task, utilizing contextual information from news articles and
external knowledge to enhance the accuracy of stakeholder type detection.
Moreover, our proposed model showcases efficacy in zero-shot settings, further
extending its applicability to diverse news contexts.

摘要：在複雜的新聞文章領域中導航包括了解涉及的各種行動者或實體，稱為新聞利益相關者。這些利益相關者，從政策制定者到反對派人物、公民等等，在塑造新聞敘述中扮演著舉足輕重的角色。認識他們的利益相關者類型，反映他們的角色、政治立場、社會地位等，對於細緻理解新聞內容至關重要。儘管現有作品著重於顯著實體萃取、報導差異和透過社群媒體資料進行政治聯繫，新聞內容中利益相關者角色的自動化偵測仍是未充分探討的領域。在本文中，我們透過引入一種有效方法來分類新聞文章中的利益相關者類型，以彌合這個差距。我們的方法包括將利益相關者分類問題轉換為自然語言推論任務，利用新聞文章中的脈絡資訊和外部知識來增強利益相關者類型偵測的準確性。此外，我們提出的模型在零次學習設定中展示了功效性，進一步擴展了其對不同新聞脈絡的適用性。

##### **Achieving Fairness Through Channel Pruning for Dermatological Disease Diagnosis**
2405.08681v1 by Qingpeng Kong, Ching-Hao Chiu, Dewen Zeng, Yu-Jen Chen, Tsung-Yi Ho, Jingtong hu, Yiyu Shi

Numerous studies have revealed that deep learning-based medical image
classification models may exhibit bias towards specific demographic attributes,
such as race, gender, and age. Existing bias mitigation methods often achieve
high level of fairness at the cost of significant accuracy degradation. In
response to this challenge, we propose an innovative and adaptable Soft Nearest
Neighbor Loss-based channel pruning framework, which achieves fairness through
channel pruning. Traditionally, channel pruning is utilized to accelerate
neural network inference. However, our work demonstrates that pruning can also
be a potent tool for achieving fairness. Our key insight is that different
channels in a layer contribute differently to the accuracy of different groups.
By selectively pruning critical channels that lead to the accuracy difference
between the privileged and unprivileged groups, we can effectively improve
fairness without sacrificing accuracy significantly. Experiments conducted on
two skin lesion diagnosis datasets across multiple sensitive attributes
validate the effectiveness of our method in achieving state-of-the-art
trade-off between accuracy and fairness. Our code is available at
https://github.com/Kqp1227/Sensitive-Channel-Pruning.

摘要：許多研究顯示，基於深度學習的醫療影像分類模型可能會對特定人口屬性（例如種族、性別和年齡）表現出偏見。現有的偏見緩解方法通常以大幅降低準確度為代價，來達成高度的公平性。為了應對此挑戰，我們提出一個創新的、可適應的基於 Soft Nearest Neighbor Loss 的通道剪枝框架，透過通道剪枝來實現公平性。傳統上，通道剪枝用於加速神經網路推論。然而，我們的研究證明，剪枝也可以成為實現公平性的有力工具。我們的關鍵見解是，一層中的不同通道對不同群組的準確度有不同的貢獻。透過選擇性地剪枝導致特權群組和非特權群組之間準確度差異的重要通道，我們可以有效地提高公平性，而不會顯著犧牲準確度。在兩個皮膚病變診斷資料集上進行的實驗，涵蓋多個敏感屬性，驗證了我們的方法在準確度和公平性之間取得最先進的權衡的有效性。我們的程式碼可在 https://github.com/Kqp1227/Sensitive-Channel-Pruning 取得。

##### **Investigating Design Choices in Joint-Embedding Predictive Architectures for General Audio Representation Learning**
2405.08679v1 by Alain Riou, Stefan Lattner, Gaëtan Hadjeres, Geoffroy Peeters

This paper addresses the problem of self-supervised general-purpose audio
representation learning. We explore the use of Joint-Embedding Predictive
Architectures (JEPA) for this task, which consists of splitting an input
mel-spectrogram into two parts (context and target), computing neural
representations for each, and training the neural network to predict the target
representations from the context representations. We investigate several design
choices within this framework and study their influence through extensive
experiments by evaluating our models on various audio classification
benchmarks, including environmental sounds, speech and music downstream tasks.
We focus notably on which part of the input data is used as context or target
and show experimentally that it significantly impacts the model's quality. In
particular, we notice that some effective design choices in the image domain
lead to poor performance on audio, thus highlighting major differences between
these two modalities.

摘要：本文探討了自監督通用音訊表示學習的問題。我們探討了聯合嵌入預測架構 (JEPA) 在此任務中的應用，該架構包含將輸入的 mel 頻譜圖分割成兩部分（脈絡和目標）、針對每一部分計算神經表示，以及訓練神經網路從脈絡表示預測目標表示。我們在此架構內探討了數種設計選擇，並透過廣泛的實驗研究其影響，方法是針對各種音訊分類基準評估我們的模型，包括環境音、語音和音樂下游任務。我們特別專注於輸入資料的哪一部分用作脈絡或目標，並透過實驗顯示它會顯著影響模型品質。特別是，我們注意到影像領域中一些有效的設計選擇會導致音訊表現不佳，因此突顯了這兩種模式之間的主要差異。

##### **Expensive Multi-Objective Bayesian Optimization Based on Diffusion Models**
2405.08674v1 by Bingdong Li, Zixiang Di, Yongfan Lu, Hong Qian, Feng Wang, Peng Yang, Ke Tang, Aimin Zhou

Multi-objective Bayesian optimization (MOBO) has shown promising performance
on various expensive multi-objective optimization problems (EMOPs). However,
effectively modeling complex distributions of the Pareto optimal solutions is
difficult with limited function evaluations. Existing Pareto set learning
algorithms may exhibit considerable instability in such expensive scenarios,
leading to significant deviations between the obtained solution set and the
Pareto set (PS). In this paper, we propose a novel Composite Diffusion Model
based Pareto Set Learning algorithm, namely CDM-PSL, for expensive MOBO.
CDM-PSL includes both unconditional and conditional diffusion model for
generating high-quality samples. Besides, we introduce an information entropy
based weighting method to balance different objectives of EMOPs. This method is
integrated with the guiding strategy, ensuring that all the objectives are
appropriately balanced and given due consideration during the optimization
process; Extensive experimental results on both synthetic benchmarks and
real-world problems demonstrates that our proposed algorithm attains superior
performance compared with various state-of-the-art MOBO algorithms.

摘要：多目標貝氏優化 (MOBO) 在各種昂貴的多目標優化問題 (EMOP) 上展現出令人滿意的效能。然而，在函數評估有限的情況下，有效地建模帕雷托最優解的複雜分佈是很困難的。現有的帕雷托集合學習演算法在這種昂貴的場景中可能會表現出相當程度的不穩定性，導致所獲得的解集與帕雷托集合 (PS) 之間出現顯著的偏差。在本文中，我們提出了一種基於帕雷托集合學習演算法的新型複合擴散模型，即 CDM-PSL，用於昂貴的 MOBO。CDM-PSL 包含無條件和條件擴散模型，用於生成高品質的樣本。此外，我們引入了一個基於資訊熵的加權方法，以平衡 EMOP 的不同目標。此方法與引導策略整合，確保所有目標在最佳化過程中得到適當的平衡和適當的考量；在合成基準和真實世界問題上的廣泛實驗結果證明，我們提出的演算法與各種最先進的 MOBO 演算法相比，取得了優異的效能。

##### **Promoting AI Equity in Science: Generalized Domain Prompt Learning for Accessible VLM Research**
2405.08668v1 by Qinglong Cao, Yuntian Chen, Lu Lu, Hao Sun, Zhenzhong Zeng, Xiaokang Yang, Dongxiao Zhang

Large-scale Vision-Language Models (VLMs) have demonstrated exceptional
performance in natural vision tasks, motivating researchers across domains to
explore domain-specific VLMs. However, the construction of powerful
domain-specific VLMs demands vast amounts of annotated data, substantial
electrical energy, and computing resources, primarily accessible to industry,
yet hindering VLM research in academia. To address this challenge and foster
sustainable and equitable VLM research, we present the Generalized Domain
Prompt Learning (GDPL) framework. GDPL facilitates the transfer of VLMs' robust
recognition capabilities from natural vision to specialized domains, without
the need for extensive data or resources. By leveraging small-scale
domain-specific foundation models and minimal prompt samples, GDPL empowers the
language branch with domain knowledge through quaternion networks, uncovering
cross-modal relationships between domain-specific vision features and natural
vision-based contextual embeddings. Simultaneously, GDPL guides the vision
branch into specific domains through hierarchical propagation of generated
vision prompt features, grounded in well-matched vision-language relations.
Furthermore, to fully harness the domain adaptation potential of VLMs, we
introduce a novel low-rank adaptation approach. Extensive experiments across
diverse domains like remote sensing, medical imaging, geology, Synthetic
Aperture Radar, and fluid dynamics, validate the efficacy of GDPL,
demonstrating its ability to achieve state-of-the-art domain recognition
performance in a prompt learning paradigm. Our framework paves the way for
sustainable and inclusive VLM research, transcending the barriers between
academia and industry.

摘要：<paragraph>大型視覺語言模型 (VLM) 已在自然視覺任務中展現出非凡的效能，激勵各領域的研究人員探索特定領域的 VLM。然而，建構強大的特定領域 VLM 需要大量標註資料、大量的電力和運算資源，這些資源主要由產業取得，卻阻礙了學術界對 VLM 的研究。為了解決這個挑戰並促進永續且公平的 VLM 研究，我們提出廣義領域提示學習 (GDPL) 架構。GDPL 促進 VLM 強健的識別能力從自然視覺轉移到特定領域，而不需要龐大的資料或資源。透過運用小規模特定領域基礎模型和最少的提示範例，GDPL 透過四元數網路賦予語言分支領域知識，揭露特定領域視覺特徵與基於自然視覺的脈絡嵌入之間的跨模態關係。同時，GDPL 透過產生視覺提示特徵的分層傳播，將視覺分支引導至特定領域，這些特徵奠基於匹配良好的視覺語言關係。此外，為了充分利用 VLM 的領域適應潛力，我們引入一種新穎的低階適應方法。在遙測、醫學影像、地質學、合成孔徑雷達和流體力學等不同領域進行的廣泛實驗驗證了 GDPL 的功效，證明了它在提示學習範例中實現最先進領域識別效能的能力。我們的架構為永續且包容的 VLM 研究鋪路，超越了學術界和產業之間的障礙。</paragraph>

##### **Beyond the Black Box: Do More Complex Models Provide Superior XAI Explanations?**
2405.08658v1 by Mateusz Cedro, Marcin Chlebus

The increasing complexity of Artificial Intelligence models poses challenges
to interpretability, particularly in the healthcare sector. This study
investigates the impact of deep learning model complexity and Explainable AI
(XAI) efficacy, utilizing four ResNet architectures (ResNet-18, 34, 50, 101).
Through methodical experimentation on 4,369 lung X-ray images of
COVID-19-infected and healthy patients, the research evaluates models'
classification performance and the relevance of corresponding XAI explanations
with respect to the ground-truth disease masks. Results indicate that the
increase in model complexity is associated with a decrease in classification
accuracy and AUC-ROC scores (ResNet-18: 98.4%, 0.997; ResNet-101: 95.9%,
0.988). Notably, in eleven out of twelve statistical tests performed, no
statistically significant differences occurred between XAI quantitative metrics
- Relevance Rank Accuracy and the proposed Positive Attribution Ratio - across
trained models. These results suggest that increased model complexity does not
consistently lead to higher performance or relevance of explanations for
models' decision-making processes.

摘要：人工智慧模型日益複雜，對可解釋性構成挑戰，特別是在醫療保健領域。本研究探討深度學習模型複雜度和可解釋人工智慧 (XAI) 效能的影響，利用四種 ResNet 架構 (ResNet-18、34、50、101)。透過對 4,369 張 COVID-19 感染和健康患者的肺部 X 光影像進行有條理的實驗，本研究評估模型的分類效能和對應 XAI 解釋與實際疾病遮罩的相關性。結果顯示，模型複雜度的增加與分類準確度和 AUC-ROC 分數的下降有關 (ResNet-18：98.4%，0.997；ResNet-101：95.9%，0.988)。值得注意的是，在所執行的十二項統計檢定中，有十一次之間沒有發生統計上顯著差異 XAI 定量指標 - 相關性排名準確度和建議的正歸因比率 - 在訓練模型之間。這些結果表明，模型複雜度的增加並不會持續導致解釋效能或模型決策過程相關性的提升。

##### **Thinking Tokens for Language Modeling**
2405.08644v1 by David Herel, Tomas Mikolov

How much is 56 times 37? Language models often make mistakes in these types
of difficult calculations. This is usually explained by their inability to
perform complex reasoning. Since language models rely on large training sets
and great memorization capability, naturally they are not equipped to run
complex calculations. However, one can argue that humans also cannot perform
this calculation immediately and require a considerable amount of time to
construct the solution. In order to enhance the generalization capability of
language models, and as a parallel to human behavior, we propose to use special
'thinking tokens' which allow the model to perform much more calculations
whenever a complex problem is encountered.

摘要：56 乘以 37 等於多少？語言模型在這些類型的困難計算中經常會出錯。這通常是因為它們無法進行複雜的推理。由於語言模型依賴於大型訓練集和強大的記憶能力，因此它們自然無法執行複雜的計算。然而，有人認為人類也不能立即執行此計算，並且需要相當長的時間才能建構解法。為了增強語言模型的泛化能力，並且與人類行為並行，我們建議使用特殊的「思考符號」，讓模型在遇到複雜問題時能夠執行更多計算。

##### **ALMol: Aligned Language-Molecule Translation LLMs through Offline Preference Contrastive Optimisation**
2405.08619v2 by Dimitris Gkoumas

The field of chemistry and Artificial Intelligence (AI) intersection is an
area of active research that aims to accelerate scientific discovery. The
integration of large language models (LLMs) with scientific modalities has
shown significant promise in this endeavour. However, challenges persist in
effectively addressing training efficacy and the out-of-distribution problem,
particularly as existing approaches rely on larger models and datasets. In this
context, we focus on machine language-molecule translation and deploy a novel
training approach called contrastive preference optimisation, which avoids
generating translations that are merely adequate but not perfect. To ensure
generalisability and mitigate memorisation effects, we conduct experiments
using only 10\% of the data. Our results demonstrate that our models achieve up
to a 32\% improvement compared to counterpart models. We also introduce a
scalable fine-grained evaluation methodology that accommodates responsibility.

摘要：化學與人工智慧 (AI) 的交叉領域是一個積極研究領域，旨在加速科學發現。大型語言模型 (LLM) 與科學模式的整合已在此項工作中展現顯著的潛力。然而，在有效解決訓練效能和分布外問題時，挑戰依然存在，特別是因為現有方法依賴於較大的模型和資料集。在此背景下，我們專注於機器語言分子翻譯，並部署一種稱為對比偏好最佳化的創新訓練方法，避免產生僅僅足夠但並不完美之翻譯。為了確保概括性並減輕記憶效應，我們僅使用 10% 的資料進行實驗。我們的結果證明，與對應模型相比，我們的模型獲得了高達 32% 的改進。我們還引入了一個可擴展的細粒度評估方法，其中包含責任。

##### **Towards Geometry-Aware Pareto Set Learning for Neural Multi-Objective Combinatorial Optimization**
2405.08604v1 by Yongfan Lu, Zixiang Di, Bingdong Li, Shengcai Liu, Hong Qian, Peng Yang, Ke Tang, Aimin Zhou

Multi-objective combinatorial optimization (MOCO) problems are prevalent in
various real-world applications. Most existing neural methods for MOCO problems
rely solely on decomposition and utilize precise hypervolume to enhance
diversity. However, these methods often approximate only limited regions of the
Pareto front and spend excessive time on diversity enhancement because of
ambiguous decomposition and time-consuming hypervolume calculation. To address
these limitations, we design a Geometry-Aware Pareto set Learning algorithm
named GAPL, which provides a novel geometric perspective for neural MOCO via a
Pareto attention model based on hypervolume expectation maximization. In
addition, we propose a hypervolume residual update strategy to enable the
Pareto attention model to capture both local and non-local information of the
Pareto set/front. We also design a novel inference approach to further improve
quality of the solution set and speed up hypervolume calculation and local
subset selection. Experimental results on three classic MOCO problems
demonstrate that our GAPL outperforms state-of-the-art neural baselines via
superior decomposition and efficient diversity enhancement.

摘要：多目標組合最佳化 (MOCO) 問題在各種真實世界的應用中很普遍。大多數現有的 MOCO 問題神經方法僅依賴分解，並利用精確的超體積來增強多樣性。然而，這些方法通常僅近似帕雷托前緣的有限區域，並且由於分解不明確和耗時的超體積計算而花費過多時間在多樣性增強上。為了解決這些限制，我們設計了一個名為 GAPL 的幾何感知帕雷托集學習演算法，它透過基於超體積期望最大化的帕雷托注意力模型為神經 MOCO 提供一個新穎的幾何觀點。此外，我們提出了一個超體積殘差更新策略，使帕雷托注意力模型能夠擷取帕雷托集/前緣的局部和非局部資訊。我們還設計了一種新穎的推論方法，以進一步提高解集的品質，並加快超體積計算和局部子集選擇。在三個經典 MOCO 問題上的實驗結果證明，我們的 GAPL 透過優異的分解和有效的多樣性增強，優於最先進的神經基準。

##### **A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine**
2405.08603v1 by Hanguang Xiao, Feizhong Zhou, Xingyue Liu, Tianqi Liu, Zhipeng Li, Xin Liu, Xiaoxuan Huang

Since the release of ChatGPT and GPT-4, large language models (LLMs) and
multimodal large language models (MLLMs) have garnered significant attention
due to their powerful and general capabilities in understanding, reasoning, and
generation, thereby offering new paradigms for the integration of artificial
intelligence with medicine. This survey comprehensively overviews the
development background and principles of LLMs and MLLMs, as well as explores
their application scenarios, challenges, and future directions in medicine.
Specifically, this survey begins by focusing on the paradigm shift, tracing the
evolution from traditional models to LLMs and MLLMs, summarizing the model
structures to provide detailed foundational knowledge. Subsequently, the survey
details the entire process from constructing and evaluating to using LLMs and
MLLMs with a clear logic. Following this, to emphasize the significant value of
LLMs and MLLMs in healthcare, we survey and summarize 6 promising applications
in healthcare. Finally, the survey discusses the challenges faced by medical
LLMs and MLLMs and proposes a feasible approach and direction for the
subsequent integration of artificial intelligence with medicine. Thus, this
survey aims to provide researchers with a valuable and comprehensive reference
guide from the perspectives of the background, principles, and clinical
applications of LLMs and MLLMs.

摘要：自 ChatGPT 和 GPT-4 發布以來，大型語言模型 (LLM) 和多模態大型語言模型 (MLLM) 因其在理解、推理和生成方面的強大且通用的能力而備受關注，從而為人工智慧與醫學整合提供了新的範例。本綜述全面概述了 LLM 和 MLLM 的發展背景和原理，並探討了它們在醫學中的應用場景、挑戰和未來方向。具體來說，本綜述首先著重於範例轉移，追溯從傳統模型到 LLM 和 MLLM 的演變，總結模型結構以提供詳細的基本知識。隨後，本綜述詳細介紹了從構建和評估到使用 LLM 和 MLLM 的整個過程，邏輯清晰。緊接著，為了強調 LLM 和 MLLM 在醫療保健中的重要價值，我們調查並總結了醫療保健中的 6 個有前景的應用。最後，本綜述討論了醫學 LLM 和 MLLM 面臨的挑戰，並提出了人工智慧與醫學後續整合的可行途徑和方向。因此，本綜述旨在從 LLM 和 MLLM 的背景、原理和臨床應用角度為研究人員提供有價值且全面的參考指南。

##### **EchoTracker: Advancing Myocardial Point Tracking in Echocardiography**
2405.08587v1 by Md Abulkalam Azad, Artem Chernyshov, John Nyberg, Ingrid Tveten, Lasse Lovstakken, Håvard Dalen, Bjørnar Grenne, Andreas Østvik

Tissue tracking in echocardiography is challenging due to the complex cardiac
motion and the inherent nature of ultrasound acquisitions. Although optical
flow methods are considered state-of-the-art (SOTA), they struggle with
long-range tracking, noise occlusions, and drift throughout the cardiac cycle.
Recently, novel learning-based point tracking techniques have been introduced
to tackle some of these issues. In this paper, we build upon these techniques
and introduce EchoTracker, a two-fold coarse-to-fine model that facilitates the
tracking of queried points on a tissue surface across ultrasound image
sequences. The architecture contains a preliminary coarse initialization of the
trajectories, followed by reinforcement iterations based on fine-grained
appearance changes. It is efficient, light, and can run on mid-range GPUs.
Experiments demonstrate that the model outperforms SOTA methods, with an
average position accuracy of 67% and a median trajectory error of 2.86 pixels.
Furthermore, we show a relative improvement of 25% when using our model to
calculate the global longitudinal strain (GLS) in a clinical test-retest
dataset compared to other methods. This implies that learning-based point
tracking can potentially improve performance and yield a higher diagnostic and
prognostic value for clinical measurements than current techniques. Our source
code is available at: https://github.com/riponazad/echotracker/.

摘要：在超音波心動圖中，由於複雜的心臟運動和超音波擷取的內在性質，組織追蹤具有挑戰性。雖然光流法被認為是目前最先進的技術（SOTA），但它們在整個心臟週期中難以進行長程追蹤、雜訊遮蔽和漂移。最近，引進了基於新穎學習的點追蹤技術來解決其中一些問題。在本文中，我們建立在這些技術之上，並介紹了 EchoTracker，這是一個兩重的粗略到精細模型，用於促進在超音波影像序列中追蹤組織表面上的查詢點。該架構包含軌跡的初步粗略初始化，然後根據細粒度外觀變化進行強化反覆運算。它高效、輕巧，可以在中階 GPU 上執行。實驗表明，該模型優於 SOTA 方法，平均位置精度為 67%，平均軌跡誤差為 2.86 像素。此外，我們在臨床測試重測資料集中使用我們的模型計算全球縱向應變 (GLS) 時，與其他方法相比，顯示出 25% 的相對改善。這表示基於學習的點追蹤可以潛在改善效能，並比目前的技術為臨床測量提供更高的診斷和預後價值。我們的原始碼可在以下位置取得：https://github.com/riponazad/echotracker/。

##### **Rethinking the adaptive relationship between Encoder Layers and Decoder Layers**
2405.08570v1 by Yubo Song

This article explores the adaptive relationship between Encoder Layers and
Decoder Layers using the SOTA model Helsinki-NLP/opus-mt-de-en, which
translates German to English. The specific method involves introducing a
bias-free fully connected layer between the Encoder and Decoder, with different
initializations of the layer's weights, and observing the outcomes of
fine-tuning versus retraining. Four experiments were conducted in total. The
results suggest that directly modifying the pre-trained model structure for
fine-tuning yields suboptimal performance. However, upon observing the outcomes
of the experiments with retraining, this structural adjustment shows
significant potential.

摘要：本文探討編碼器層和解碼器層之間的適應性關係，使用 SOTA 模型 Helsinki-NLP/opus-mt-de-en，將德語翻譯成英語。具體方法涉及在編碼器和解碼器之間引入一個無偏差的全連接層，該層的權重有不同的初始化，並觀察微調與重新訓練的結果。總共進行了四項實驗。結果表明，直接修改預訓練模型結構以進行微調會產生次優效能。然而，在觀察重新訓練的實驗結果後，這種結構調整顯示出巨大的潛力。

##### **The Unseen Targets of Hate -- A Systematic Review of Hateful Communication Datasets**
2405.08562v1 by Zehui Yu, Indira Sen, Dennis Assenmacher, Mattia Samory, Leon Fröhling, Christina Dahn, Debora Nozza, Claudia Wagner

Machine learning (ML)-based content moderation tools are essential to keep
online spaces free from hateful communication. Yet, ML tools can only be as
capable as the quality of the data they are trained on allows them. While there
is increasing evidence that they underperform in detecting hateful
communications directed towards specific identities and may discriminate
against them, we know surprisingly little about the provenance of such bias. To
fill this gap, we present a systematic review of the datasets for the automated
detection of hateful communication introduced over the past decade, and unpack
the quality of the datasets in terms of the identities that they embody: those
of the targets of hateful communication that the data curators focused on, as
well as those unintentionally included in the datasets. We find, overall, a
skewed representation of selected target identities and mismatches between the
targets that research conceptualizes and ultimately includes in datasets. Yet,
by contextualizing these findings in the language and location of origin of the
datasets, we highlight a positive trend towards the broadening and
diversification of this research space.

摘要：基於機器學習 (ML) 的內容審核工具對於讓網路空間免於仇恨言論至關重要。然而，ML 工具的能力取決於用於訓練它們的資料品質。雖然有愈來愈多的證據顯示，這些工具在偵測針對特定身分的仇恨言論時表現不佳，甚至可能對這些身分進行歧視，但我們對於此類偏見的來源卻所知甚少。為了填補這個缺口，我們對過去十年來引入的自動化仇恨言論偵測資料集進行系統性回顧，並從資料集所體現的身分角度探討資料集品質：資料策展人關注的仇恨言論目標身分，以及無意間包含在資料集中的身分。總體而言，我們發現選定的目標身分有失衡的代表性，且研究概念化和最終包含在資料集中的目標之間存在落差。然而，透過將這些發現置於資料集的語言和來源位置的脈絡中，我們強調了此研究領域朝向擴展和多元化的正面趨勢。

##### **Improving Transformers with Dynamically Composable Multi-Head Attention**
2405.08553v1 by Da Xiao, Qingye Meng, Shengping Li, Xingyuan Yuan

Multi-Head Attention (MHA) is a key component of Transformer. In MHA,
attention heads work independently, causing problems such as low-rank
bottleneck of attention score matrices and head redundancy. We propose
Dynamically Composable Multi-Head Attention (DCMHA), a parameter and
computation efficient attention architecture that tackles the shortcomings of
MHA and increases the expressive power of the model by dynamically composing
attention heads. At the core of DCMHA is a $\it{Compose}$ function that
transforms the attention score and weight matrices in an input-dependent way.
DCMHA can be used as a drop-in replacement of MHA in any transformer
architecture to obtain the corresponding DCFormer. DCFormer significantly
outperforms Transformer on different architectures and model scales in language
modeling, matching the performance of models with ~1.7x-2.0x compute. For
example, DCPythia-6.9B outperforms open source Pythia-12B on both pretraining
perplexity and downstream task evaluation. The code and models are available at
https://github.com/Caiyun-AI/DCFormer.

摘要：多頭注意力 (MHA) 是 Transformer 的關鍵組成部分。在 MHA 中，注意力頭部獨立運作，導致注意力分數矩陣的低秩瓶頸和頭部冗餘等問題。我們提出動態可組成多頭注意力 (DCMHA)，這是一種參數和計算效率高的注意力架構，可解決 MHA 的缺點並透過動態組成注意力頭部來增加模型的表達能力。DCMHA 的核心是一個 $\it{Compose}$ 函數，它以輸入依賴的方式轉換注意力分數和權重矩陣。DCMHA 可用於取代任何 Transformer 架構中的 MHA，以取得對應的 DCFormer。DCFormer 在不同的架構和語言建模中的模型規模上顯著優於 Transformer，其效能與運算量約為 1.7x-2.0x 的模型相匹配。例如，DCPythia-6.9B 在預訓練困惑度和下游任務評估中都優於開源 Pythia-12B。程式碼和模型可在 https://github.com/Caiyun-AI/DCFormer 取得。

##### **Generalizing Knowledge Graph Embedding with Universal Orthogonal Parameterization**
2405.08540v1 by Rui Li, Chaozhuo Li, Yanming Shen, Zeyu Zhang, Xu Chen

Recent advances in knowledge graph embedding (KGE) rely on
Euclidean/hyperbolic orthogonal relation transformations to model intrinsic
logical patterns and topological structures. However, existing approaches are
confined to rigid relational orthogonalization with restricted dimension and
homogeneous geometry, leading to deficient modeling capability. In this work,
we move beyond these approaches in terms of both dimension and geometry by
introducing a powerful framework named GoldE, which features a universal
orthogonal parameterization based on a generalized form of Householder
reflection. Such parameterization can naturally achieve dimensional extension
and geometric unification with theoretical guarantees, enabling our framework
to simultaneously capture crucial logical patterns and inherent topological
heterogeneity of knowledge graphs. Empirically, GoldE achieves state-of-the-art
performance on three standard benchmarks. Codes are available at
https://github.com/xxrep/GoldE.

摘要：知識圖譜嵌入 (KGE) 的最新進展依賴於歐氏/雙曲正交關係轉換來建模內在邏輯模式和拓撲結構。然而，現有方法僅限於具有受限維度和同質幾何的剛性關係正交化，導致建模能力不足。在這項工作中，我們在維度和幾何方面超越了這些方法，引入了名為 GoldE 的強大框架，其特點是基於 Householder 反射的廣義形式的通用正交參數化。這種參數化可以自然地實現維度擴展和幾何統一，並具有理論保證，使我們的框架能夠同時捕獲知識圖譜的關鍵邏輯模式和內在拓撲異質性。根據經驗，GoldE 在三個標準基準測試中實現了最先進的性能。代碼可在 https://github.com/xxrep/GoldE 獲得。

##### **From Internet of Things Data to Business Processes: Challenges and a Framework**
2405.08528v1 by Juergen Mangler, Ronny Seiger, Janik-Vasily Benzin, Joscha Grüger, Yusuf Kirikkayis, Florian Gallik, Lukas Malburg, Matthias Ehrendorfer, Yannis Bertrand, Marco Franceschetti, Barbara Weber, Stefanie Rinderle-Ma, Ralph Bergmann, Estefanía Serral Asensio, Manfred Reichert

The IoT and Business Process Management (BPM) communities co-exist in many
shared application domains, such as manufacturing and healthcare. The IoT
community has a strong focus on hardware, connectivity and data; the BPM
community focuses mainly on finding, controlling, and enhancing the structured
interactions among the IoT devices in processes. While the field of Process
Mining deals with the extraction of process models and process analytics from
process event logs, the data produced by IoT sensors often is at a lower
granularity than these process-level events. The fundamental questions about
extracting and abstracting process-related data from streams of IoT sensor
values are: (1) Which sensor values can be clustered together as part of
process events?, (2) Which sensor values signify the start and end of such
events?, (3) Which sensor values are related but not essential? This work
proposes a framework to semi-automatically perform a set of structured steps to
convert low-level IoT sensor data into higher-level process events that are
suitable for process mining. The framework is meant to provide a generic
sequence of abstract steps to guide the event extraction, abstraction, and
correlation, with variation points for plugging in specific analysis techniques
and algorithms for each step. To assess the completeness of the framework, we
present a set of challenges, how they can be tackled through the framework, and
an example on how to instantiate the framework in a real-world demonstration
from the field of smart manufacturing. Based on this framework, future research
can be conducted in a structured manner through refining and improving
individual steps.

摘要：物聯網和業務流程管理 (BPM) 社群在許多共享應用領域中並存，例如製造和醫療保健。物聯網社群著重於硬體、連線性和資料；BPM 社群主要著重於尋找、控制和提升流程中物聯網裝置之間的結構化互動。雖然流程探勘領域處理從流程事件記錄中擷取流程模型和流程分析，但物聯網感測器產生的資料通常比這些流程層級事件的詳細程度低。從物聯網感測器數值串流中擷取和抽象與流程相關資料的基本問題為：(1) 哪些感測器數值可以群集在一起作為流程事件的一部分？(2) 哪些感測器數值表示此類事件的開始和結束？(3) 哪些感測器數值相關但非必要？這項工作提出一個架構，以半自動化方式執行一組結構化步驟，將低層級物聯網感測器資料轉換為適合流程探勘的高層級流程事件。這個架構旨在提供一組抽象步驟，以指導事件擷取、抽象和關聯，並提供變異點，以便針對每個步驟插入特定的分析技術和演算法。為了評估這個架構的完整性，我們提出了一組挑戰，說明如何透過這個架構來應對這些挑戰，並舉例說明如何從智慧製造領域的實際示範中實例化這個架構。基於這個架構，未來的研究可以透過精進和改善個別步驟，以結構化的方式進行。

##### **Falcon 7b for Software Mention Detection in Scholarly Documents**
2405.08514v1 by AmeerAli Khan, Qusai Ramadan, Cong Yang, Zeyd Boukhers

This paper aims to tackle the challenge posed by the increasing integration
of software tools in research across various disciplines by investigating the
application of Falcon-7b for the detection and classification of software
mentions within scholarly texts. Specifically, the study focuses on solving
Subtask I of the Software Mention Detection in Scholarly Publications (SOMD),
which entails identifying and categorizing software mentions from academic
literature. Through comprehensive experimentation, the paper explores different
training strategies, including a dual-classifier approach, adaptive sampling,
and weighted loss scaling, to enhance detection accuracy while overcoming the
complexities of class imbalance and the nuanced syntax of scholarly writing.
The findings highlight the benefits of selective labelling and adaptive
sampling in improving the model's performance. However, they also indicate that
integrating multiple strategies does not necessarily result in cumulative
improvements. This research offers insights into the effective application of
large language models for specific tasks such as SOMD, underlining the
importance of tailored approaches to address the unique challenges presented by
academic text analysis.

摘要：這篇論文旨在解決軟體工具在各個領域研究中日益整合所帶來的挑戰，研究 Falcon-7b 在學術文本中偵測和分類軟體提及的應用。具體來說，這項研究專注於解決學術出版物中軟體提及偵測 (SOMD) 的子任務一，其中包括識別和分類學術文獻中的軟體提及。透過全面的實驗，本文探討了不同的訓練策略，包括雙分類器方法、自適應抽樣和加權損失縮放，以在克服類別不平衡的複雜性和學術寫作的細微語法的情況下，提升偵測準確度。研究結果突顯了選擇性標記和自適應抽樣在提升模型效能方面的優點。然而，研究結果也指出，整合多種策略並不一定會帶來累積的進步。這項研究提供了對大型語言模型在特定任務（例如 SOMD）中的有效應用之見解，強調了量身打造方法對於解決學術文本分析所呈現之獨特挑戰的重要性。

##### **Archimedes-AUEB at SemEval-2024 Task 5: LLM explains Civil Procedure**
2405.08502v1 by Odysseas S. Chlapanis, Ion Androutsopoulos, Dimitrios Galanis

The SemEval task on Argument Reasoning in Civil Procedure is challenging in
that it requires understanding legal concepts and inferring complex arguments.
Currently, most Large Language Models (LLM) excelling in the legal realm are
principally purposed for classification tasks, hence their reasoning rationale
is subject to contention. The approach we advocate involves using a powerful
teacher-LLM (ChatGPT) to extend the training dataset with explanations and
generate synthetic data. The resulting data are then leveraged to fine-tune a
small student-LLM. Contrary to previous work, our explanations are not directly
derived from the teacher's internal knowledge. Instead they are grounded in
authentic human analyses, therefore delivering a superior reasoning signal.
Additionally, a new `mutation' method generates artificial data instances
inspired from existing ones. We are publicly releasing the explanations as an
extension to the original dataset, along with the synthetic dataset and the
prompts that were used to generate both. Our system ranked 15th in the SemEval
competition. It outperforms its own teacher and can produce explanations
aligned with the original human analyses, as verified by legal experts.

摘要：SemEval 在民事訴訟中關於論證推理的任務具有挑戰性，因為它需要理解法律概念並推論出複雜的論點。目前，大多數在法律領域表現出色的大型語言模型 (LLM) 主要用於分類任務，因此它們的推理依據有待爭議。我們提倡的方法涉及使用強大的教師 LLM (ChatGPT) 來擴充訓練資料集，並提供解釋和生成合成資料。然後利用所得資料微調小型學生 LLM。與先前的研究相反，我們的解釋並非直接來自教師的內部知識。相反，它們基於真實的人類分析，因此提供了優越的推理信號。此外，新的「變異」方法會從現有的方法中生成人工資料實例。我們公開發布解釋作為原始資料集的延伸，連同合成資料集和用於產生兩者的提示。我們的系統在 SemEval 競賽中排名第 15 位。它優於自己的老師，並且可以產生與原始人類分析一致的解釋，經法律專家驗證。

##### **Is Less More? Quality, Quantity and Context in Idiom Processing with Natural Language Models**
2405.08497v1 by Agne Knietaite, Adam Allsebrook, Anton Minkov, Adam Tomaszewski, Norbert Slinko, Richard Johnson, Thomas Pickard, Dylan Phelps, Aline Villavicencio

Compositionality in language models presents a problem when processing
idiomatic expressions, as their meaning often cannot be directly derived from
their individual parts. Although fine-tuning and other optimization strategies
can be used to improve representations of idiomatic expressions, this depends
on the availability of relevant data. We present the Noun Compound Synonym
Substitution in Books - NCSSB - datasets, which are created by substitution of
synonyms of potentially idiomatic English noun compounds in public domain book
texts. We explore the trade-off between data quantity and quality when training
models for idiomaticity detection, in conjunction with contextual information
obtained locally (from the surrounding sentences) or externally (through
language resources). Performance on an idiomaticity detection task indicates
that dataset quality is a stronger factor for context-enriched models, but that
quantity also plays a role in models without context inclusion strategies.

摘要：語言模型中的組成性在處理慣用語時會產生一個問題，因為它們的意義通常無法直接從它們的個別部分推導出來。儘管微調和其他最佳化策略可用於改善慣用語的表示，這取決於相關資料的可用性。我們提出名詞複合同義詞替代書籍 - NCSSB - 資料集，它是通過在公共領域書籍文本中替換潛在慣用語的英文名詞複合詞的同義詞而建立的。我們探討了在訓練慣用性偵測模型時資料數量和品質之間的折衷，並結合從當地（來自周圍句子）或外部（透過語言資源）獲得的脈絡資訊。慣用性偵測任務的表現指出，資料集品質是脈絡豐富模型的較強影響因素，但數量也在沒有脈絡納入策略的模型中發揮作用。

##### **Enhancing Gender-Inclusive Machine Translation with Neomorphemes and Large Language Models**
2405.08477v1 by Andrea Piergentili, Beatrice Savoldi, Matteo Negri, Luisa Bentivogli

Machine translation (MT) models are known to suffer from gender bias,
especially when translating into languages with extensive gendered morphology.
Accordingly, they still fall short in using gender-inclusive language, also
representative of non-binary identities. In this paper, we look at
gender-inclusive neomorphemes, neologistic elements that avoid binary gender
markings as an approach towards fairer MT. In this direction, we explore
prompting techniques with large language models (LLMs) to translate from
English into Italian using neomorphemes. So far, this area has been
under-explored due to its novelty and the lack of publicly available evaluation
resources. We fill this gap by releasing Neo-GATE, a resource designed to
evaluate gender-inclusive en-it translation with neomorphemes. With Neo-GATE,
we assess four LLMs of different families and sizes and different prompt
formats, identifying strengths and weaknesses of each on this novel task for
MT.

摘要：機器翻譯 (MT) 模型已知會遭受性別偏見，
特別是在翻譯成具有廣泛性別形態的語言時。
因此，它們在使用性別包容性語言方面仍有不足，也
代表了非二元性別認同。在本文中，我們探討
性別包容性新形態素，新造詞元素，避免二元性別
標記作為實現更公平 MT 的一種方法。在這個方向上，我們探索
使用大型語言模型 (LLM) 的提示技術，從
英語翻譯成義大利語時使用新形態素。到目前為止，這個領域一直
由於其新穎性和缺乏公開可用的評估
資源。我們通過發布 Neo-GATE 來填補這一空白，這是一種旨在
評估使用新形態素的性別包容性 en-it 翻譯的資源。使用 Neo-GATE，
我們評估了不同系列和大小的四個 LLM 以及不同的提示
格式，識別了每種格式在 MT 這項新任務中的優缺點。

##### **GPT-3.5 for Grammatical Error Correction**
2405.08469v1 by Anisia Katinskaia, Roman Yangarber

This paper investigates the application of GPT-3.5 for Grammatical Error
Correction (GEC) in multiple languages in several settings: zero-shot GEC,
fine-tuning for GEC, and using GPT-3.5 to re-rank correction hypotheses
generated by other GEC models. In the zero-shot setting, we conduct automatic
evaluations of the corrections proposed by GPT-3.5 using several methods:
estimating grammaticality with language models (LMs), the Scribendi test, and
comparing the semantic embeddings of sentences. GPT-3.5 has a known tendency to
over-correct erroneous sentences and propose alternative corrections. For
several languages, such as Czech, German, Russian, Spanish, and Ukrainian,
GPT-3.5 substantially alters the source sentences, including their semantics,
which presents significant challenges for evaluation with reference-based
metrics. For English, GPT-3.5 demonstrates high recall, generates fluent
corrections, and generally preserves sentence semantics. However, human
evaluation for both English and Russian reveals that, despite its strong
error-detection capabilities, GPT-3.5 struggles with several error types,
including punctuation mistakes, tense errors, syntactic dependencies between
words, and lexical compatibility at the sentence level.

摘要：本文探討了 GPT-3.5 在多種語言中語法錯誤校正 (GEC) 的應用，包括零次學習 GEC、GEC 微調，以及使用 GPT-3.5 對其他 GEC 模型生成的校正假設進行重新排名。在零次學習設定中，我們使用多種方法對 GPT-3.5 提出的校正進行自動評估：使用語言模型 (LM) 估計語法性、Scribendi 測試，以及比較句子的語義嵌入。已知 GPT-3.5 傾向於過度校正錯誤句子並提出替代校正。對於捷克語、德語、俄語、西班牙語和烏克蘭語等多種語言，GPT-3.5 會大幅度改變原始句子，包括它們的語義，這對使用基於參考的指標進行評估提出了重大挑戰。對於英語，GPT-3.5 表現出高召回率，產生流利的校正，並且通常保留句子語義。然而，對英語和俄語的人工評估顯示，儘管 GPT-3.5 具有強大的錯誤檢測能力，但在標點錯誤、時態錯誤、詞語之間的句法依賴性以及句子層面的詞彙相容性等多種錯誤類型中，GPT-3.5 仍存在困難。

##### **Challenges and Opportunities in Text Generation Explainability**
2405.08468v1 by Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady

The necessity for interpretability in natural language processing (NLP) has
risen alongside the growing prominence of large language models. Among the
myriad tasks within NLP, text generation stands out as a primary objective of
autoregressive models. The NLP community has begun to take a keen interest in
gaining a deeper understanding of text generation, leading to the development
of model-agnostic explainable artificial intelligence (xAI) methods tailored to
this task. The design and evaluation of explainability methods are non-trivial
since they depend on many factors involved in the text generation process,
e.g., the autoregressive model and its stochastic nature. This paper outlines
17 challenges categorized into three groups that arise during the development
and assessment of attribution-based explainability methods. These challenges
encompass issues concerning tokenization, defining explanation similarity,
determining token importance and prediction change metrics, the level of human
intervention required, and the creation of suitable test datasets. The paper
illustrates how these challenges can be intertwined, showcasing new
opportunities for the community. These include developing probabilistic
word-level explainability methods and engaging humans in the explainability
pipeline, from the data design to the final evaluation, to draw robust
conclusions on xAI methods.

摘要：隨著大型語言模型的日益普及，自然語言處理 (NLP) 中對可解釋性的需求也隨之增加。在 NLP 中的無數任務中，文本生成作為自迴歸模型的主要目標而脫穎而出。NLP 社群已開始對深入了解文本生成產生濃厚興趣，並進而開發出針對此任務量身打造的與模型無關的可解釋人工智慧 (xAI) 方法。由於可解釋性方法的設計和評估取決於文本生成過程中涉及的許多因素（例如自迴歸模型及其隨機性質），因此並非易事。本文概述了在歸因式可解釋性方法的開發和評估過程中產生的 17 項挑戰，並將其分類為三組。這些挑戰涵蓋了與標記化、定義說明相似性、確定標記重要性和預測變動指標、所需的人工干預程度以及建立適當測試資料集有關的問題。本文說明了這些挑戰如何相互交織，並展示了社群的新機會。這些機會包括開發機率字元級可解釋性方法，以及讓人類參與可解釋性管道（從資料設計到最終評估），以對 xAI 方法得出穩健的結論。

##### **Evaluating LLMs at Evaluating Temporal Generalization**
2405.08460v1 by Chenghao Zhu, Nuo Chen, Yufei Gao, Benyou Wang

The rapid advancement of Large Language Models (LLMs) highlights the urgent
need for evolving evaluation methodologies that keep pace with improvements in
language comprehension and information processing. However, traditional
benchmarks, which are often static, fail to capture the continually changing
information landscape, leading to a disparity between the perceived and actual
effectiveness of LLMs in ever-changing real-world scenarios. Furthermore, these
benchmarks do not adequately measure the models' capabilities over a broader
temporal range or their adaptability over time. We examine current LLMs in
terms of temporal generalization and bias, revealing that various temporal
biases emerge in both language likelihood and prognostic prediction. This
serves as a caution for LLM practitioners to pay closer attention to mitigating
temporal biases. Also, we propose an evaluation framework Freshbench for
dynamically generating benchmarks from the most recent real-world
prognostication prediction. Our code is available at
https://github.com/FreedomIntelligence/FreshBench. The dataset will be released
soon.

摘要：大型語言模型 (LLM) 的快速進展突顯了迫切需要演進評估方法，以跟上語言理解和資訊處理的進步腳步。然而，傳統基準通常是靜態的，無法捕捉持續變化的資訊環境，導致 LLM 在不斷變化的真實世界場景中的感知效能與實際效能之間出現差異。此外，這些基準並未充分衡量模型在較廣泛時間範圍內的效能或其隨時間推移的適應性。我們在時間概化和偏差方面檢驗了目前的 LLM，揭示了語言可能性和預測預測中出現各種時間偏差。這提醒 LLM 從業人員更密切地注意減輕時間偏差。此外，我們提出了評估框架 Freshbench，用於動態生成來自最新真實世界預測預測的基準。我們的程式碼可在 https://github.com/FreedomIntelligence/FreshBench 取得。資料集將很快釋出。

##### **How Alignment Helps Make the Most of Multimodal Data**
2405.08454v1 by Christian Arnold, Andreas Küpfer

When studying political communication, combining the information from text,
audio, and video signals promises to reflect the richness of human
communication more comprehensively than confining it to individual modalities
alone. However, when modeling such multimodal data, its heterogeneity,
connectedness, and interaction are challenging to address. We argue that
aligning the respective modalities can be an essential step in entirely using
the potential of multimodal data because it informs the model with human
understanding. Exploring aligned modalities unlocks promising analytical
leverage. First, it allows us to make the most of information in the data,
which inter alia opens the door to better quality predictions. Second, it is
possible to answer research questions that span multiple modalities with
cross-modal queries. Finally, alignment addresses concerns about model
interpretability. We illustrate the utility of this approach by analyzing how
German MPs address members of the far-right AfD in their speeches, and
predicting the tone of video advertising in the context of the 2020 US
presidential race. Our paper offers important insights to all keen to analyze
multimodal data effectively.

摘要：在研究政治溝通時，結合文字、音訊和視訊訊號中的資訊，承諾比僅限於個別模式更全面地反映人類溝通的豐富性。然而，在對此類多模態資料進行建模時，其異質性、連通性和互動性具有挑戰性。我們認為，比對各個模式可能是充分利用多模態資料潛力的必要步驟，因為它會根據人類理解來為模型提供資訊。探索比對的模式會開啟有前景的分析優勢。首先，它讓我們能夠充分利用資料中的資訊，這間接開啟了進行更高品質預測的可能性。其次，可以透過跨模式查詢來回答橫跨多個模式的研究問題。最後，比對解決了關於模型可解釋性的問題。我們透過分析德國國會議員如何在演講中對極右翼德國另類選擇黨 (AfD) 成員發言，以及預測 2020 年美國總統大選背景下視訊廣告的語氣，來說明這種方法的效用。我們的論文為所有熱衷於有效分析多模態資料的人提供了重要的見解。

##### **Understanding the performance gap between online and offline alignment algorithms**
2405.08448v1 by Yunhao Tang, Daniel Zhaohan Guo, Zeyu Zheng, Daniele Calandriello, Yuan Cao, Eugene Tarassov, Rémi Munos, Bernardo Ávila Pires, Michal Valko, Yong Cheng, Will Dabney

Reinforcement learning from human feedback (RLHF) is the canonical framework
for large language model alignment. However, rising popularity in offline
alignment algorithms challenge the need for on-policy sampling in RLHF. Within
the context of reward over-optimization, we start with an opening set of
experiments that demonstrate the clear advantage of online methods over offline
methods. This prompts us to investigate the causes to the performance
discrepancy through a series of carefully designed experimental ablations. We
show empirically that hypotheses such as offline data coverage and data quality
by itself cannot convincingly explain the performance difference. We also find
that while offline algorithms train policy to become good at pairwise
classification, it is worse at generations; in the meantime the policies
trained by online algorithms are good at generations while worse at pairwise
classification. This hints at a unique interplay between discriminative and
generative capabilities, which is greatly impacted by the sampling process.
Lastly, we observe that the performance discrepancy persists for both
contrastive and non-contrastive loss functions, and appears not to be addressed
by simply scaling up policy networks. Taken together, our study sheds light on
the pivotal role of on-policy sampling in AI alignment, and hints at certain
fundamental challenges of offline alignment algorithms.

摘要：人類回饋強化學習 (RLHF) 是大型語言模型對齊的標準架構。然而，離線對齊演算法日益普及，挑戰了 RLHF 中對策略採樣的必要性。在獎勵過度最佳化的脈絡中，我們從一組開放的實驗開始，展示了在線方法相較於離線方法的顯著優勢。這促使我們透過一系列精心設計的實驗消融，探討效能差異的原因。我們經驗性地證明，諸如離線資料覆蓋率和資料品質等假設本身無法令人信服地解釋效能差異。我們還發現，儘管離線演算法會訓練策略以擅長成對分類，但它在生成方面較差；與此同時，由在線演算法訓練的策略擅長生成，但在成對分類方面較差。這暗示了判別能力和生成能力之間的獨特交互作用，這會受到抽樣過程的極大影響。最後，我們觀察到，效能差異對於對比和非對比損失函數皆持續存在，而且似乎無法透過單純擴充策略網路來解決。綜合而言，我們的研究闡明了策略採樣在 AI 對齊中的關鍵作用，並暗示了離線對齊演算法的某些基本挑戰。

##### **Impact of Stickers on Multimodal Chat Sentiment Analysis and Intent Recognition: A New Task, Dataset and Baseline**
2405.08427v1 by Yuanchen Shi, Biao Ma, Fang Kong

Stickers are increasingly used in social media to express sentiment and
intent. When finding typing troublesome, people often use a sticker instead.
Despite the significant impact of stickers on sentiment analysis and intent
recognition, little research has been conducted. To address this gap, we
propose a new task: Multimodal chat Sentiment Analysis and Intent Recognition
involving Stickers (MSAIRS). Additionally, we introduce a novel multimodal
dataset containing Chinese chat records and stickers excerpted from several
mainstream social media platforms. Our dataset includes paired data with the
same text but different stickers, and various stickers consisting of the same
images with different texts, allowing us to better understand the impact of
stickers on chat sentiment and intent. We also propose an effective multimodal
joint model, MMSAIR, for our task, which is validated on our datasets and
indicates that visual information of stickers counts. Our dataset and code will
be publicly available.

摘要：貼圖在社群媒體上日益被用來表達情緒和意圖。當人們覺得輸入文字很麻煩時，他們通常會使用貼圖代替。儘管貼圖對情緒分析和意圖辨識有顯著的影響，但相關的研究卻很少。為了解決這個問題，我們提出一個新的任務：包含貼圖的多模態聊天情緒分析和意圖辨識（MSAIRS）。此外，我們還引入了一個新的多模態資料集，其中包含從幾個主流社群媒體平台摘錄的中文聊天記錄和貼圖。我們的資料集包括具有相同文字但不同貼圖的成對資料，以及由相同圖片和不同文字組成的各種貼圖，讓我們能夠更深入地了解貼圖對聊天情緒和意圖的影響。我們還為我們的任務提出了一個有效的多模態聯合模型 MMSAIR，並在我們的資料集上驗證了該模型，結果表明貼圖的視覺資訊很有用。我們的資料集和程式碼將會公開。

##### **Investigating the 'Autoencoder Behavior' in Speech Self-Supervised Models: a focus on HuBERT's Pretraining**
2405.08402v1 by Valentin Vielzeuf

Self-supervised learning has shown great success in Speech Recognition.
However, it has been observed that finetuning all layers of the learned model
leads to lower performance compared to resetting top layers. This phenomenon is
attributed to the ''autoencoder'' behavior: top layers contain information
closer to the input and are less suitable for tasks that require linguistic
information, such as Speech Recognition.To better our understanding of this
behavior, we propose to study the evolution of high-level information within
the model during pretraining. We focus on the HuBERT model, which exhibits a
less pronounced ''autoencoder'' behavior. By experimentally exploring various
factors that may have an impact, we aim to improve the training procedure and
enhance the top layers of HuBERT for high-level tasks.Furthermore, our
experiments demonstrate that these improvements in the training procedure
result in faster convergence and competitive performance on downstream tasks.

摘要：自監督學習在語音辨識上已展現極佳成效。
然而，已觀察到微調學習模型的所有層級
與重設頂層相比，會導致較低的效能。這種現象
歸因於「自動編碼器」行為：頂層包含更接近輸入的資訊，較不適合於需要語言資訊的任務，例如語音辨識。為了更了解這種
行為，我們提議研究預訓練期間模型內部高階資訊的演化。我們專注於 HuBERT 模型，它表現出較不顯著的「自動編碼器」行為。透過實驗探討可能產生影響的各種因素，我們旨在改善訓練程序，並增強 HuBERT 頂層以執行高階任務。此外，我們的
實驗證明，訓練程序的這些改進會導致下游任務的收斂速度加快，且效能具競爭力。

##### **Stylometric Watermarks for Large Language Models**
2405.08400v1 by Georg Niess, Roman Kern

The rapid advancement of large language models (LLMs) has made it
increasingly difficult to distinguish between text written by humans and
machines. Addressing this, we propose a novel method for generating watermarks
that strategically alters token probabilities during generation. Unlike
previous works, this method uniquely employs linguistic features such as
stylometry. Concretely, we introduce acrostica and sensorimotor norms to LLMs.
Further, these features are parameterized by a key, which is updated every
sentence. To compute this key, we use semantic zero shot classification, which
enhances resilience. In our evaluation, we find that for three or more
sentences, our method achieves a false positive and false negative rate of
0.02. For the case of a cyclic translation attack, we observe similar results
for seven or more sentences. This research is of particular of interest for
proprietary LLMs to facilitate accountability and prevent societal harm.

摘要：大型語言模型 (LLM) 的快速進步使得區分人類和機器編寫的文本變得越來越困難。針對此問題，我們提出了一種生成水印的新方法，該方法在生成過程中策略性地改變詞彙機率。與先前的研究不同，此方法獨特地採用了語言學特徵，例如文體測量學。具體來說，我們將首字母縮寫和感覺運動規範引入 LLM。此外，這些特徵由一個金鑰參數化，該金鑰每句話都會更新。為了計算這個金鑰，我們使用語義零次分類，這增強了韌性。在我們的評估中，我們發現對於三個或更多句子，我們的模型實現了 0.02 的偽陽性和偽陰性率。對於循環翻譯攻擊的情況，我們觀察到對於七個或更多句子有類似的結果。這項研究對於專有 LLM 特別有意義，以促進問責制並防止社會危害。

##### **CIER: A Novel Experience Replay Approach with Causal Inference in Deep Reinforcement Learning**
2405.08380v1 by Jingwen Wang, Dehui Du, Yida Li, Yiyang Li, Yikang Chen

In the training process of Deep Reinforcement Learning (DRL), agents require
repetitive interactions with the environment. With an increase in training
volume and model complexity, it is still a challenging problem to enhance data
utilization and explainability of DRL training. This paper addresses these
challenges by focusing on the temporal correlations within the time dimension
of time series. We propose a novel approach to segment multivariate time series
into meaningful subsequences and represent the time series based on these
subsequences. Furthermore, the subsequences are employed for causal inference
to identify fundamental causal factors that significantly impact training
outcomes. We design a module to provide feedback on the causality during DRL
training. Several experiments demonstrate the feasibility of our approach in
common environments, confirming its ability to enhance the effectiveness of DRL
training and impart a certain level of explainability to the training process.
Additionally, we extended our approach with priority experience replay
algorithm, and experimental results demonstrate the continued effectiveness of
our approach.

摘要：在深度強化學習 (DRL) 的訓練過程中，代理人需要與環境進行重複的互動。隨著訓練量和模型複雜性的增加，增強資料利用率和 DRL 訓練的可解釋性仍然是一個具有挑戰性的問題。本文透過專注於時間序列時間維度內的時間相關性來解決這些挑戰。我們提出了一種新穎的方法，將多變量時間序列分割成有意義的子序列，並根據這些子序列來表示時間序列。此外，這些子序列被用於因果推論，以識別顯著影響訓練結果的基本因果因素。我們設計了一個模組，在 DRL 訓練期間提供關於因果關係的回饋。多項實驗證明了我們的方法在一般環境中的可行性，證實了它增強 DRL 訓練效果並賦予訓練過程一定程度的可解釋性的能力。此外，我們使用優先經驗回放演算法擴展了我們的方法，而實驗結果證明了我們的方法的持續有效性。

##### **PromptMind Team at MEDIQA-CORR 2024: Improving Clinical Text Correction with Error Categorization and LLM Ensembles**
2405.08373v1 by Satya Kesav Gundabathula, Sriram R Kolar

This paper describes our approach to the MEDIQA-CORR shared task, which
involves error detection and correction in clinical notes curated by medical
professionals. This task involves handling three subtasks: detecting the
presence of errors, identifying the specific sentence containing the error, and
correcting it. Through our work, we aim to assess the capabilities of Large
Language Models (LLMs) trained on a vast corpora of internet data that contain
both factual and unreliable information. We propose to comprehensively address
all subtasks together, and suggest employing a unique prompt-based in-context
learning strategy. We will evaluate its efficacy in this specialized task
demanding a combination of general reasoning and medical knowledge. In medical
systems where prediction errors can have grave consequences, we propose
leveraging self-consistency and ensemble methods to enhance error correction
and error detection performance.

摘要：本文描述了我們對 MEDIQA-CORR 共享任務的方法，其中包括由醫療專業人員策劃的臨床筆記中的錯誤偵測和更正。此任務涉及處理三個子任務：偵測錯誤的存在、識別包含錯誤的特定句子，以及更正錯誤。透過我們的努力，我們旨在評估在包含事實和不可靠資訊的龐大網路資料語料庫上訓練的大型語言模型 (LLM) 的能力。我們建議全面處理所有子任務，並建議採用獨特的基於提示的脈絡中學習策略。我們將評估其在這個需要結合一般推理和醫療知識的專門任務中的功效。在預測錯誤可能造成嚴重後果的醫療系統中，我們建議利用自我一致性和整體方法來增強錯誤更正和錯誤偵測效能。

##### **Seal-Tools: Self-Instruct Tool Learning Dataset for Agent Tuning and Detailed Benchmark**
2405.08355v1 by Mengsong Wu, Tong Zhu, Han Han, Chuanyuan Tan, Xiang Zhang, Wenliang Chen

This paper presents a new tool learning dataset Seal-Tools, which contains
self-instruct API-like tools. Seal-Tools not only offers a large number of
tools, but also includes instances which demonstrate the practical application
of tools. Seeking to generate data on a large scale while ensuring reliability,
we propose a self-instruct method to generate tools and instances, allowing
precise control over the process. Moreover, our Seal-Tools contains hard
instances that call multiple tools to complete the job, among which some are
nested tool callings. For precise and comprehensive evaluation, we use strict
format control and design three metrics from different dimensions. Therefore,
Seal-Tools can serve as a new benchmark to evaluate the tool-calling ability of
LLMs. Finally, we evaluate several prevalent LLMs and our finetuned model on
Seal-Tools. The results show that current systems are far from perfect. The
code, data and experiment results are available at
https://github.com/fairyshine/Seal-Tools .

摘要：這篇論文提出一個新的工具學習資料集 Seal-Tools，其中包含
自學 API 型工具。Seal-Tools 不僅提供大量的
工具，還包括展示工具實際應用範例的實例。為了在確保可靠性的同時大規模產生資料，
我們提出一個自學方法來產生工具和實例，並精確控制這個過程。此外，我們的 Seal-Tools 包含需要呼叫多個工具才能完成工作的困難實例，其中一些是
巢狀工具呼叫。為了精確且全面的評估，我們使用嚴格的
格式控制並從不同面向設計三個指標。因此，
Seal-Tools 可以作為評估 LLM 工具呼叫能力的新基準。最後，我們評估了幾個流行的 LLM 和我們在
Seal-Tools 上微調的模型。結果顯示目前的系統遠未完美。程式碼、資料和實驗結果可在
https://github.com/fairyshine/Seal-Tools 獲得。

##### **Perivascular space Identification Nnunet for Generalised Usage (PINGU)**
2405.08337v1 by Benjamin Sinclair, Lucy Vivash, Jasmine Moses, Miranda Lynch, William Pham, Karina Dorfmann, Cassandra Marotta, Shaun Koh, Jacob Bunyamin, Ella Rowsthorn, Alex Jarema, Himashi Peiris, Zhaolin Chen, Sandy R Shultz, David K Wright, Dexiao Kong, Sharon L. Naismith, Terence J. OBrien, Meng Law

Perivascular spaces(PVSs) form a central component of the brain\'s waste
clearance system, the glymphatic system. These structures are visible on MRI
images, and their morphology is associated with aging and neurological disease.
Manual quantification of PVS is time consuming and subjective. Numerous deep
learning methods for PVS segmentation have been developed, however the majority
have been developed and evaluated on homogenous datasets and high resolution
scans, perhaps limiting their applicability for the wide range of image
qualities acquired in clinic and research. In this work we train a nnUNet, a
top-performing biomedical image segmentation algorithm, on a heterogenous
training sample of manually segmented MRI images of a range of different
qualities and resolutions from 6 different datasets. These are compared to
publicly available deep learning methods for 3D segmentation of PVS. The
resulting model, PINGU (Perivascular space Identification Nnunet for
Generalised Usage), achieved voxel and cluster level dice scores of
0.50(SD=0.15), 0.63(0.17) in the white matter(WM), and 0.54(0.11), 0.66(0.17)
in the basal ganglia(BG). Performance on data from unseen sites was
substantially lower for both PINGU(0.20-0.38(WM, voxel), 0.29-0.58(WM,
cluster), 0.22-0.36(BG, voxel), 0.46-0.60(BG, cluster)) and the publicly
available algorithms(0.18-0.30(WM, voxel), 0.29-0.38(WM cluster), 0.10-0.20(BG,
voxel), 0.15-0.37(BG, cluster)), but PINGU strongly outperformed the publicly
available algorithms, particularly in the BG. Finally, training PINGU on manual
segmentations from a single site with homogenous scan properties gave
marginally lower performances on internal cross-validation, but in some cases
gave higher performance on external validation. PINGU stands out as broad-use
PVS segmentation tool, with particular strength in the BG, an area of PVS
related to vascular disease and pathology.

摘要：<paragraph>血管周圍空間 (PVS) 是大腦廢物清除系統（即淋巴系統）的核心組成部分。這些結構在 MRI 影像中可見，其形態與老化和神經疾病相關。人工量化 PVS 耗時且主觀。已經開發出許多用於 PVS 分割的深度學習方法，然而，大多數方法都是在同質數據集和高解析度掃描上開發和評估的，這可能會限制其在臨床上和研究中獲取的各種影像品質的適用性。在這項工作中，我們在一個異質的手工分割 MRI 影像訓練樣本上訓練了一個 nnUNet，這是一種效能最佳的生物醫學影像分割演算法，該樣本包含來自 6 個不同數據集的各種不同品質和解析度的影像。這些影像與用於 PVS 3D 分割的公開深度學習方法進行比較。產生的模型 PINGU（廣泛使用血管周圍空間識別 Nnunet）在白質 (WM) 中達到體素和叢集層級的骰子分數為 0.50(SD=0.15)、0.63(0.17)，在基底神經節 (BG) 中達到 0.54(0.11)、0.66(0.17)。對於來自未見過場域的資料，PINGU(0.20-0.38(WM，體素)、0.29-0.58(WM，叢集)、0.22-0.36(BG，體素)、0.46-0.60(BG，叢集)) 和公開深度學習演算法(0.18-0.30(WM，體素)、0.29-0.38(WM 叢集)、0.10-0.20(BG，體素)、0.15-0.37(BG，叢集)) 的效能大幅降低，但 PINGU 明顯優於公開深度學習演算法，特別是在 BG 中。最後，在具有同質掃描特性的單一場域的手工分割上訓練 PINGU 在內部交叉驗證中表現出略低的效能，但在某些情況下在外部驗證中表現出更高的效能。PINGU 脫穎而出，成為廣泛使用的 PVS 分割工具，特別是在與血管疾病和病理相關的 PVS 區域，即 BG 中。</paragraph>

##### **Could Chemical LLMs benefit from Message Passing**
2405.08334v1 by Jiaqing Xie, Ziheng Chi

Pretrained language models (LMs) showcase significant capabilities in
processing molecular text, while concurrently, message passing neural networks
(MPNNs) demonstrate resilience and versatility in the domain of molecular
science. Despite these advancements, we find there are limited studies
investigating the bidirectional interactions between molecular structures and
their corresponding textual representations. Therefore, in this paper, we
propose two strategies to evaluate whether an information integration can
enhance the performance: contrast learning, which involves utilizing an MPNN to
supervise the training of the LM, and fusion, which exploits information from
both models. Our empirical analysis reveals that the integration approaches
exhibit superior performance compared to baselines when applied to smaller
molecular graphs, while these integration approaches do not yield performance
enhancements on large scale graphs.

摘要：預先訓練的語言模型 (LM) 在處理分子文本方面展示出顯著的能力，同時，訊息傳遞神經網路 (MPNN) 在分子科學領域中展現出韌性和多功能性。儘管有這些進展，我們發現探討分子結構與其對應文本表示之間雙向交互作用的研究有限。因此，在本文中，我們提出兩種策略來評估資訊整合是否能提升效能：對比學習，涉及利用 MPNN 監督 LM 的訓練，以及融合，利用來自兩個模型的資訊。我們的實證分析顯示，與應用於較小分子圖形的基準線相比，整合方法展現出優異的效能，而這些整合方法並未在大型圖形上產生效能提升。

##### **Cross-Dataset Generalization For Retinal Lesions Segmentation**
2405.08329v1 by Clément Playout, Farida Cheriet

Identifying lesions in fundus images is an important milestone toward an
automated and interpretable diagnosis of retinal diseases. To support research
in this direction, multiple datasets have been released, proposing groundtruth
maps for different lesions. However, important discrepancies exist between the
annotations and raise the question of generalization across datasets. This
study characterizes several known datasets and compares different techniques
that have been proposed to enhance the generalisation performance of a model,
such as stochastic weight averaging, model soups and ensembles. Our results
provide insights into how to combine coarsely labelled data with a
finely-grained dataset in order to improve the lesions segmentation.

摘要：識別眼底圖像中的病灶是邁向自動化且可解讀的視網膜疾病診斷的重要里程碑。為了支持此方向的研究，已經發布多個資料集，提出了不同病灶的 groundtruth 地圖。然而，註解之間存在重大差異，並提出了跨資料集概化的問題。本研究描述了幾個已知的資料集，並比較了為增強模型的概化效能而提出的不同技術，例如隨機權重平均、模型湯和套件。我們的結果提供了如何將粗略標籤的資料與細粒度資料集相結合以改善病灶分割的見解。

##### **SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large Language Models**
2405.08317v1 by Raghuveer Peri, Sai Muralidhar Jayanthi, Srikanth Ronanki, Anshu Bhatia, Karel Mundnich, Saket Dingliwal, Nilaksh Das, Zejiang Hou, Goeric Huybrechts, Srikanth Vishnubhotla, Daniel Garcia-Romero, Sundararajan Srinivasan, Kyu J Han, Katrin Kirchhoff

Integrated Speech and Large Language Models (SLMs) that can follow speech
instructions and generate relevant text responses have gained popularity
lately. However, the safety and robustness of these models remains largely
unclear. In this work, we investigate the potential vulnerabilities of such
instruction-following speech-language models to adversarial attacks and
jailbreaking. Specifically, we design algorithms that can generate adversarial
examples to jailbreak SLMs in both white-box and black-box attack settings
without human involvement. Additionally, we propose countermeasures to thwart
such jailbreaking attacks. Our models, trained on dialog data with speech
instructions, achieve state-of-the-art performance on spoken question-answering
task, scoring over 80% on both safety and helpfulness metrics. Despite safety
guardrails, experiments on jailbreaking demonstrate the vulnerability of SLMs
to adversarial perturbations and transfer attacks, with average attack success
rates of 90% and 10% respectively when evaluated on a dataset of carefully
designed harmful questions spanning 12 different toxic categories. However, we
demonstrate that our proposed countermeasures reduce the attack success
significantly.

摘要：整合語音和大型語言模型 (SLM)，能遵循語音指示並產生相關文字回應，最近變得流行。然而，這些模型的安全性與健全性在很大程度上仍不明確。在這項工作中，我們探討此類遵循指示的語音語言模型對對抗性攻擊和越獄的潛在漏洞。具體來說，我們設計了演算法，可在白盒和黑盒攻擊設定中產生對抗性範例，以越獄 SLM，而無需人工介入。此外，我們提出對策來阻止此類越獄攻擊。我們的模型在包含語音指示的對話資料上訓練，在口說問答任務中達到最先進的效能，在安全性與有益性指標上均得分超過 80%。儘管有安全防護措施，但越獄實驗顯示 SLM 對對抗性擾動和傳輸攻擊的脆弱性，在評估精心設計的涵蓋 12 種不同有害類別的有害問題資料集時，平均攻擊成功率分別為 90% 和 10%。然而，我們證明我們提出的對策大幅降低了攻擊成功率。

##### **A Decoupling and Aggregating Framework for Joint Extraction of Entities and Relations**
2405.08311v1 by Yao Wang, Xin Liu, Weikun Kong, Hai-Tao Yu, Teeradaj Racharak, Kyoung-Sook Kim, Minh Le Nguyen

Named Entity Recognition and Relation Extraction are two crucial and
challenging subtasks in the field of Information Extraction. Despite the
successes achieved by the traditional approaches, fundamental research
questions remain open. First, most recent studies use parameter sharing for a
single subtask or shared features for both two subtasks, ignoring their
semantic differences. Second, information interaction mainly focuses on the two
subtasks, leaving the fine-grained informtion interaction among the
subtask-specific features of encoding subjects, relations, and objects
unexplored. Motivated by the aforementioned limitations, we propose a novel
model to jointly extract entities and relations. The main novelties are as
follows: (1) We propose to decouple the feature encoding process into three
parts, namely encoding subjects, encoding objects, and encoding relations.
Thanks to this, we are able to use fine-grained subtask-specific features. (2)
We propose novel inter-aggregation and intra-aggregation strategies to enhance
the information interaction and construct individual fine-grained
subtask-specific features, respectively. The experimental results demonstrate
that our model outperforms several previous state-of-the-art models. Extensive
additional experiments further confirm the effectiveness of our model.

摘要：命名實體辨識與關係萃取是資訊萃取領域中兩個至關重要且具有挑戰性的子任務。儘管傳統方法取得成功，但基本的研究問題仍然懸而未決。首先，大多數最近的研究使用參數共享來執行單一子任務或共享功能來執行兩個子任務，忽略了它們的語義差異。其次，資訊互動主要集中在兩個子任務上，忽略了編碼主詞、關係和物件的子任務特定功能之間的細粒度資訊互動。受到上述限制的啟發，我們提出了一個新穎的模型，用於聯合萃取實體和關係。主要的創新如下：(1) 我們建議將特徵編碼過程解耦成三個部分，即編碼主詞、編碼物件和編碼關係。由於這樣，我們可以使用細粒度的子任務特定功能。(2) 我們提出新穎的交互聚合和內部聚合策略，分別增強資訊互動並建構個別的細粒度子任務特定功能。實驗結果證明，我們的模型優於幾個先前的最先進模型。廣泛的額外實驗進一步證實了我們模型的有效性。

##### **Computational Thought Experiments for a More Rigorous Philosophy and Science of the Mind**
2405.08304v2 by Iris Oved, Nikhil Krishnaswamy, James Pustejovsky, Joshua Hartshorne

We offer philosophical motivations for a method we call Virtual World
Cognitive Science (VW CogSci), in which researchers use virtual embodied agents
that are embedded in virtual worlds to explore questions in the field of
Cognitive Science. We focus on questions about mental and linguistic
representation and the ways that such computational modeling can add rigor to
philosophical thought experiments, as well as the terminology used in the
scientific study of such representations. We find that this method forces
researchers to take a god's-eye view when describing dynamical relationships
between entities in minds and entities in an environment in a way that
eliminates the need for problematic talk of belief and concept types, such as
the belief that cats are silly, and the concept CAT, while preserving belief
and concept tokens in individual cognizers' minds. We conclude with some
further key advantages of VW CogSci for the scientific study of mental and
linguistic representation and for Cognitive Science more broadly.

摘要：我們提供一種我們稱之為虛擬世界認知科學 (VW CogSci) 的方法的哲學動機，研究人員在其中使用嵌入在虛擬世界中的虛擬具身代理，以探索認知科學領域中的問題。我們專注於心智和語言表徵的問題，以及這種計算建模如何為哲學思想實驗增加嚴謹性，以及用於此類表徵的科學研究中的術語。我們發現這種方法迫使研究人員在描述心智中的實體與環境中的實體之間的動態關係時採取上帝視角，從而消除了對信念和概念類型（例如相信貓很傻和 CAT 概念）的有問題的討論的需要，同時保留了個別認知者心智中的信念和概念標記。我們最後總結了 VW CogSci 在心智和語言表徵的科學研究以及更廣泛的認知科學中的一些進一步關鍵優勢。

##### **Distance-Restricted Explanations: Theoretical Underpinnings & Efficient Implementation**
2405.08297v1 by Yacine Izza, Xuanxiang Huang, Antonio Morgado, Jordi Planes, Alexey Ignatiev, Joao Marques-Silva

The uses of machine learning (ML) have snowballed in recent years. In many
cases, ML models are highly complex, and their operation is beyond the
understanding of human decision-makers. Nevertheless, some uses of ML models
involve high-stakes and safety-critical applications. Explainable artificial
intelligence (XAI) aims to help human decision-makers in understanding the
operation of such complex ML models, thus eliciting trust in their operation.
Unfortunately, the majority of past XAI work is based on informal approaches,
that offer no guarantees of rigor. Unsurprisingly, there exists comprehensive
experimental and theoretical evidence confirming that informal methods of XAI
can provide human-decision makers with erroneous information. Logic-based XAI
represents a rigorous approach to explainability; it is model-based and offers
the strongest guarantees of rigor of computed explanations. However, a
well-known drawback of logic-based XAI is the complexity of logic reasoning,
especially for highly complex ML models. Recent work proposed
distance-restricted explanations, i.e. explanations that are rigorous provided
the distance to a given input is small enough. Distance-restricted
explainability is tightly related with adversarial robustness, and it has been
shown to scale for moderately complex ML models, but the number of inputs still
represents a key limiting factor. This paper investigates novel algorithms for
scaling up the performance of logic-based explainers when computing and
enumerating ML model explanations with a large number of inputs.

摘要：機器學習 (ML) 的用途在近年來如滾雪球般擴大。在許多情況下，ML 模型非常複雜，而其運作超乎人類決策者的理解範圍。儘管如此，ML 模型的某些用途涉及高風險和安全關鍵的應用。可解釋人工智慧 (XAI) 旨在幫助人類決策者了解此類複雜 ML 模型的運作，進而引發對其運作的信任。不幸的是，過去大部分的 XAI 工作都基於非正式方法，無法保證嚴謹性。毫不意外地，有全面的實驗和理論證據證實，非正式的 XAI 方法可能會為人類決策者提供錯誤的資訊。基於邏輯的 XAI 代表一種嚴謹的可解釋性方法；它是基於模型的，並提供經由計算得出的解釋的最強有力的嚴謹性保證。然而，基於邏輯的 XAI 一個眾所周知的缺點是邏輯推理的複雜性，特別是對於高度複雜的 ML 模型。最近的研究提出了距離受限的解釋，即只要與給定輸入的距離夠小，就是嚴謹的解釋。距離受限的可解釋性與對抗魯棒性密切相關，並且已被證明可以擴展到中等複雜度的 ML 模型，但輸入數量仍然是一個關鍵的限制因素。本文探討了在計算和列舉具有大量輸入的 ML 模型解釋時，用於擴展基於邏輯的解釋器的效能的新演算法。

##### **SpeechVerse: A Large-scale Generalizable Audio Language Model**
2405.08295v1 by Nilaksh Das, Saket Dingliwal, Srikanth Ronanki, Rohit Paturi, David Huang, Prashant Mathur, Jie Yuan, Dhanush Bekal, Xing Niu, Sai Muralidhar Jayanthi, Xilai Li, Karel Mundnich, Monica Sunkara, Sundararajan Srinivasan, Kyu J Han, Katrin Kirchhoff

Large language models (LLMs) have shown incredible proficiency in performing
tasks that require semantic understanding of natural language instructions.
Recently, many works have further expanded this capability to perceive
multimodal audio and text inputs, but their capabilities are often limited to
specific fine-tuned tasks such as automatic speech recognition and translation.
We therefore develop SpeechVerse, a robust multi-task training and curriculum
learning framework that combines pre-trained speech and text foundation models
via a small set of learnable parameters, while keeping the pre-trained models
frozen during training. The models are instruction finetuned using continuous
latent representations extracted from the speech foundation model to achieve
optimal zero-shot performance on a diverse range of speech processing tasks
using natural language instructions. We perform extensive benchmarking that
includes comparing our model performance against traditional baselines across
several datasets and tasks. Furthermore, we evaluate the model's capability for
generalized instruction following by testing on out-of-domain datasets, novel
prompts, and unseen tasks. Our empirical experiments reveal that our multi-task
SpeechVerse model is even superior to conventional task-specific baselines on 9
out of the 11 tasks.

摘要：大型語言模型 (LLM) 在執行需要對自然語言指令進行語義理解的任務方面表現出令人難以置信的能力。最近，許多作品進一步擴展了這種感知多模態音訊和文字輸入的能力，但它們的能力通常僅限於特定微調任務，例如自動語音識別和翻譯。因此，我們開發了 SpeechVerse，這是一個強大的多任務訓練和課程學習框架，它通過一小組可學習的參數將預訓練的語音和文字基礎模型結合起來，同時在訓練期間保持預訓練的模型凍結。這些模型使用從語音基礎模型中提取的連續潛在表示進行指令微調，以在使用自然語言指令的各種語音處理任務中實現最佳零次學習效能。我們執行廣泛的基準測試，包括在多個資料集和任務中將我們的模型效能與傳統基準進行比較。此外，我們通過在領域外資料集、新提示和未見任務上進行測試來評估模型對廣義指令遵循的能力。我們的實證實驗表明，我們的多任務 SpeechVerse 模型甚至在 11 項任務中的 9 項任務中優於傳統的特定任務基準。

##### **Detecting Fallacies in Climate Misinformation: A Technocognitive Approach to Identifying Misleading Argumentation**
2405.08254v1 by Francisco Zanartu, John Cook, Markus Wagner, Julian Garcia

Misinformation about climate change is a complex societal issue requiring
holistic, interdisciplinary solutions at the intersection between technology
and psychology. One proposed solution is a "technocognitive" approach,
involving the synthesis of psychological and computer science research.
Psychological research has identified that interventions in response to
misinformation require both fact-based (e.g., factual explanations) and
technique-based (e.g., explanations of misleading techniques) content. However,
little progress has been made on documenting and detecting fallacies in climate
misinformation. In this study, we apply a previously developed critical
thinking methodology for deconstructing climate misinformation, in order to
develop a dataset mapping different types of climate misinformation to
reasoning fallacies. This dataset is used to train a model to detect fallacies
in climate misinformation. Our study shows F1 scores that are 2.5 to 3.5 better
than previous works. The fallacies that are easiest to detect include fake
experts and anecdotal arguments, while fallacies that require background
knowledge, such as oversimplification, misrepresentation, and slothful
induction, are relatively more difficult to detect. This research lays the
groundwork for development of solutions where automatically detected climate
misinformation can be countered with generative technique-based corrections.

摘要：气候变迁的错误信息是一个复杂的社会问题，需要在技术和心理学的交叉点上采用整体的、跨学科的解决方案。一个建议的解决方案是“技术认知”方法，涉及心理和计算机科学研究的综合。心理研究已经发现，针对错误信息的干预措施需要基于事实（例如，事实解释）和基于技术的（例如，误导技术的解释）内容。然而，在记录和检测气候错误信息中的谬误方面几乎没有取得进展。在这项研究中，我们应用了先前开发的批判性思维方法来解构气候错误信息，以便开发一个数据集，将不同类型的气候错误信息映射到推理谬误。此数据集用于训练模型以检测气候错误信息中的谬误。我们的研究显示，F1 分数比以前的作品高出 2.5 到 3.5。最容易检测到的谬误包括虚假专家和轶事论证，而需要背景知识的谬误，例如过度简化、歪曲和懒惰归纳，则相对更难检测。这项研究为解决方案的开发奠定了基础，其中自动检测到的气候错误信息可以通过生成基于技术的更正来加以应对。

##### **Smart Sampling: Self-Attention and Bootstrapping for Improved Ensembled Q-Learning**
2405.08252v1 by Muhammad Junaid Khan, Syed Hammad Ahmed, Gita Sukthankar

We present a novel method aimed at enhancing the sample efficiency of
ensemble Q learning. Our proposed approach integrates multi-head self-attention
into the ensembled Q networks while bootstrapping the state-action pairs
ingested by the ensemble. This not only results in performance improvements
over the original REDQ (Chen et al. 2021) and its variant DroQ (Hi-raoka et al.
2022), thereby enhancing Q predictions, but also effectively reduces both the
average normalized bias and standard deviation of normalized bias within
Q-function ensembles. Importantly, our method also performs well even in
scenarios with a low update-to-data (UTD) ratio. Notably, the implementation of
our proposed method is straightforward, requiring minimal modifications to the
base model.

摘要：我們提出了一種新方法，旨在提高整體 Q 學習的樣本效率。我們提出的方法將多頭自我注意整合到整體 Q 網路中，同時對整體吸收的狀態動作對進行自舉。這不僅導致性能優於原始 REDQ（Chen et al. 2021）及其變體 DroQ（Hi-raoka et al. 2022），從而增強 Q 預測，而且有效降低了 Q 函數整體中標準化偏差的平均標準化偏差和標準差。重要的是，即使在更新到資料 (UTD) 比率低的情況下，我們的模型也能表現良好。值得注意的是，我們提出的方法實作很簡單，只需要對基礎模型進行最小的修改。

##### **Automated classification of multi-parametric body MRI series**
2405.08247v1 by Boah Kim, Tejas Sudharshan Mathai, Kimberly Helm, Ronald M. Summers

Multi-parametric MRI (mpMRI) studies are widely available in clinical
practice for the diagnosis of various diseases. As the volume of mpMRI exams
increases yearly, there are concomitant inaccuracies that exist within the
DICOM header fields of these exams. This precludes the use of the header
information for the arrangement of the different series as part of the
radiologist's hanging protocol, and clinician oversight is needed for
correction. In this pilot work, we propose an automated framework to classify
the type of 8 different series in mpMRI studies. We used 1,363 studies acquired
by three Siemens scanners to train a DenseNet-121 model with 5-fold
cross-validation. Then, we evaluated the performance of the DenseNet-121
ensemble on a held-out test set of 313 mpMRI studies. Our method achieved an
average precision of 96.6%, sensitivity of 96.6%, specificity of 99.6%, and F1
score of 96.6% for the MRI series classification task. To the best of our
knowledge, we are the first to develop a method to classify the series type in
mpMRI studies acquired at the level of the chest, abdomen, and pelvis. Our
method has the capability for robust automation of hanging protocols in modern
radiology practice.

摘要：多參數 MRI (mpMRI) 研究廣泛應用於臨床實務中，用於診斷各種疾病。由於 mpMRI 檢查量每年都在增加，這些檢查的 DICOM 標頭欄位中存在著伴隨的不準確性。這會妨礙將標頭資訊用於放射科醫師懸掛協定的不同系列的排列，並且需要臨床醫師監督才能進行校正。在這項試驗工作中，我們提出了一個自動化架構，用於對 mpMRI 研究中的 8 個不同系列類型進行分類。我們使用了由三個 Siemens 掃描器取得的 1,363 項研究，以訓練一個具有 5 倍交叉驗證的 DenseNet-121 模型。然後，我們在一個由 313 項 mpMRI 研究組成的留出測試集上評估了 DenseNet-121 混合模型的效能。我們的模型在 MRI 系列分類任務中達到了平均準確度 96.6%、敏感度 96.6%、特異度 99.6% 和 F1 分數 96.6%。據我們所知，我們是第一個開發出一個方法來對在胸部、腹部和骨盆層級取得的 mpMRI 研究中的系列類型進行分類。我們的模型有能力在現代放射科實務中對懸掛協定進行強健的自動化。

##### **Compositional Text-to-Image Generation with Dense Blob Representations**
2405.08246v1 by Weili Nie, Sifei Liu, Morteza Mardani, Chao Liu, Benjamin Eckart, Arash Vahdat

Existing text-to-image models struggle to follow complex text prompts,
raising the need for extra grounding inputs for better controllability. In this
work, we propose to decompose a scene into visual primitives - denoted as dense
blob representations - that contain fine-grained details of the scene while
being modular, human-interpretable, and easy-to-construct. Based on blob
representations, we develop a blob-grounded text-to-image diffusion model,
termed BlobGEN, for compositional generation. Particularly, we introduce a new
masked cross-attention module to disentangle the fusion between blob
representations and visual features. To leverage the compositionality of large
language models (LLMs), we introduce a new in-context learning approach to
generate blob representations from text prompts. Our extensive experiments show
that BlobGEN achieves superior zero-shot generation quality and better
layout-guided controllability on MS-COCO. When augmented by LLMs, our method
exhibits superior numerical and spatial correctness on compositional image
generation benchmarks. Project page: https://blobgen-2d.github.io.

摘要：現有的文字轉圖像模型難以遵循複雜的文字提示，因此需要額外的基礎輸入以獲得更好的可控性。在這項工作中，我們建議將場景分解為視覺基元 - 表示為密集的斑點表示 - 其中包含場景的細緻細節，同時具有模組化、人類可解讀且易於建構的特性。基於斑點表示，我們開發了一個斑點基礎的文字轉圖像擴散模型，稱為 BlobGEN，用於合成生成。特別是，我們引入了一個新的遮罩交叉注意力模組，以解開斑點表示和視覺特徵之間的融合。為了利用大型語言模型 (LLM) 的組合性，我們引入了一種新的情境內學習方法，以從文字提示中生成斑點表示。我們的廣泛實驗表明，BlobGEN 在 MS-COCO 上實現了出色的零次生成品質和更好的佈局引導可控性。當由 LLM 增強時，我們的模型在合成圖像生成基準上展現出優異的數字和空間正確性。專案頁面：https://blobgen-2d.github.io。

##### **Progressive enhancement and restoration for mural images under low-light and defected conditions based on multi-receptive field strategy**
2405.08245v1 by Xiameng Wei, Binbin Fan, Ying Wang, Yanxiang Feng, Laiyi Fu

Ancient murals are valuable cultural heritage with great archaeological
value. They provide insights into ancient religions, ceremonies, folklore,
among other things through their content. However, due to long-term oxidation
and inadequate protection, ancient murals have suffered continuous damage,
including peeling and mold etc. Additionally, since ancient murals were
typically painted indoors, the light intensity in images captured by digital
devices is often low. The poor visibility hampers the further restoration of
damaged areas. To address the escalating damage to ancient frescoes and
facilitate batch restoration at archaeological sites, we propose a two-stage
restoration model which called MER(Mural Enhancement and Restoration net) for
ancient murals that are damaged and have been captured in low light. Our
two-stage model not only enhances the visual quality of restored images but
also achieves commendable results in relevant metric evaluations compared with
other competitors. Furthermore, we have launched a website dedicated to the
restoration of ancient mural paintings, utilizing the proposed model. Code is
available at https://gitee.com/bbfan2024/MER.git.

摘要：古代壁畫是具有重大考古價值的珍貴文化遺產。它們透過其內容提供對古代宗教、儀式、民間傳說等方面的見解。然而，由於長期氧化和保護不當，古代壁畫遭受持續破壞，包括剝落、發霉等。此外，由於古代壁畫通常繪製在室內，因此數位裝置所拍攝的影像光線強度通常很低。能見度不佳會阻礙受損區域的進一步修復。為了解決古代壁畫日益嚴重的損壞問題，並促進考古遺址的批量修復，我們提出了一個名為 MER（壁畫增強和修復網路）的兩階段修復模型，適用於受損且在低光源下拍攝的古代壁畫。我們的兩階段模型不僅增強了修復影像的視覺品質，在與其他競爭者的相關指標評估中也取得了令人稱道的成果。此外，我們已推出一個專門用於修復古代壁畫的網站，並採用了所提出的模型。程式碼可在 https://gitee.com/bbfan2024/MER.git 取得。

##### **Silver-Tongued and Sundry: Exploring Intersectional Pronouns with ChatGPT**
2405.08238v1 by Takao Fujii, Katie Seaborn, Madeleine Steeds

ChatGPT is a conversational agent built on a large language model. Trained on
a significant portion of human output, ChatGPT can mimic people to a degree. As
such, we need to consider what social identities ChatGPT simulates (or can be
designed to simulate). In this study, we explored the case of identity
simulation through Japanese first-person pronouns, which are tightly connected
to social identities in intersectional ways, i.e., intersectional pronouns. We
conducted a controlled online experiment where people from two regions in Japan
(Kanto and Kinki) witnessed interactions with ChatGPT using ten sets of
first-person pronouns. We discovered that pronouns alone can evoke perceptions
of social identities in ChatGPT at the intersections of gender, age, region,
and formality, with caveats. This work highlights the importance of pronoun use
for social identity simulation, provides a language-based methodology for
culturally-sensitive persona development, and advances the potential of
intersectional identities in intelligent agents.

摘要：ChatGPT 是一個建構於大型語言模型上的對話代理。ChatGPT 接受大量人類產出的訓練，可以在一定程度上模擬人類。因此，我們需要考慮 ChatGPT 模擬（或可設計為模擬）哪些社會身分。在這個研究中，我們探討了透過日文第一人稱代名詞進行身分模擬的案例，這些代名詞與社會身分緊密相連，也就是交織的代名詞。我們進行了一項受控的線上實驗，來自日本兩個地區（關東和近畿）的人見證了 ChatGPT 使用十組第一人稱代名詞的互動。我們發現，僅憑代名詞就能喚起人們對 ChatGPT 在性別、年齡、地區和禮貌等交集中的社會身分的認知，但有一些但書。這項工作強調了代名詞在社會身分模擬中的重要性，提供了一種基於語言的方法，用於文化敏感的角色發展，並提升了智慧代理中交織身分的潛力。

##### **A predictive learning model can simulate temporal dynamics and context effects found in neural representations of continuous speech**
2405.08237v1 by Oli Danyi Liu, Hao Tang, Naomi Feldman, Sharon Goldwater

Speech perception involves storing and integrating sequentially presented
items. Recent work in cognitive neuroscience has identified temporal and
contextual characteristics in humans' neural encoding of speech that may
facilitate this temporal processing. In this study, we simulated similar
analyses with representations extracted from a computational model that was
trained on unlabelled speech with the learning objective of predicting upcoming
acoustics. Our simulations revealed temporal dynamics similar to those in brain
signals, implying that these properties can arise without linguistic knowledge.
Another property shared between brains and the model is that the encoding
patterns of phonemes support some degree of cross-context generalization.
However, we found evidence that the effectiveness of these generalizations
depends on the specific contexts, which suggests that this analysis alone is
insufficient to support the presence of context-invariant encoding.

摘要：語音感知涉及儲存和整合依序呈現的項目。認知神經科學的最新研究已找出人類神經編碼中語音的時序和脈絡特徵，可能有助於這種時序處理。在這項研究中，我們模擬了類似的分析，使用從計算機模型中萃取的表徵，該模型以無標籤語音進行訓練，學習目標是預測即將到來的音響。我們的模擬揭示了與腦部訊號相似的時序動態，暗示這些屬性可以在沒有語言知識的情況下產生。大腦和模型之間共享的另一個屬性是，音素的編碼模式支援一定程度的跨脈絡概化。然而，我們發現證據顯示，這些概化的有效性取決於特定脈絡，這表示僅憑此分析不足以支持脈絡不變編碼的存在。

##### **An information-theoretic model of shallow and deep language comprehension**
2405.08223v1 by Jiaxuan Li, Richard Futrell

A large body of work in psycholinguistics has focused on the idea that online
language comprehension can be shallow or `good enough': given constraints on
time or available computation, comprehenders may form interpretations of their
input that are plausible but inaccurate. However, this idea has not yet been
linked with formal theories of computation under resource constraints. Here we
use information theory to formulate a model of language comprehension as an
optimal trade-off between accuracy and processing depth, formalized as bits of
information extracted from the input, which increases with processing time. The
model provides a measure of processing effort as the change in processing
depth, which we link to EEG signals and reading times. We validate our theory
against a large-scale dataset of garden path sentence reading times, and EEG
experiments featuring N400, P600 and biphasic ERP effects. By quantifying the
timecourse of language processing as it proceeds from shallow to deep, our
model provides a unified framework to explain behavioral and neural signatures
of language comprehension.

摘要：大量的心理语言学研究集中在这样一个观念上，即在线语言理解可以是肤浅的或“足够好的”：鉴于时间或可用计算的限制，理解者可能会对输入形成似是而非的解释。然而，这个观念尚未与资源约束下的形式计算理论联系起来。在这里，我们利用信息论来构建一个语言理解模型，作为准确性和处理深度之间的最优权衡，形式化为从输入中提取的信息比特，它随着处理时间而增加。该模型提供了处理工作量的衡量标准，即处理深度的变化，我们将其与脑电图信号和阅读时间联系起来。我们针对大规模的花园路径句子阅读时间数据集验证了我们的理论，以及具有 N400、P600 和双相 ERP 效应的脑电图实验。通过量化语言处理从浅到深的时间过程，我们的模型提供了一个统一的框架来解释语言理解的行为和神经特征。

##### **Interpreting Latent Student Knowledge Representations in Programming Assignments**
2405.08213v1 by Nigel Fernandez, Andrew Lan

Recent advances in artificial intelligence for education leverage generative
large language models, including using them to predict open-ended student
responses rather than their correctness only. However, the black-box nature of
these models limits the interpretability of the learned student knowledge
representations. In this paper, we conduct a first exploration into
interpreting latent student knowledge representations by presenting InfoOIRT,
an Information regularized Open-ended Item Response Theory model, which
encourages the latent student knowledge states to be interpretable while being
able to generate student-written code for open-ended programming questions.
InfoOIRT maximizes the mutual information between a fixed subset of latent
knowledge states enforced with simple prior distributions and generated student
code, which encourages the model to learn disentangled representations of
salient syntactic and semantic code features including syntactic styles,
mastery of programming skills, and code structures. Through experiments on a
real-world programming education dataset, we show that InfoOIRT can both
accurately generate student code and lead to interpretable student knowledge
representations.

摘要：最近在教育方面的人工智慧進展利用了生成式大型語言模型，包括用它們來預測開放式學生的回應，而不仅仅是它們的正確性。然而，這些模型的黑箱性質限制了對學習的學生知識表徵的可解釋性。在本文中，我們通過提出 InfoOIRT 進行了首次探索來解釋潛在的學生知識表徵，這是一個信息正則化的開放式項目反應理論模型，它鼓勵潛在的學生知識狀態可解釋，同時能夠為開放式編程問題生成學生編寫的代碼。InfoOIRT 最大化了潛在知識狀態的固定子集（用簡單的先驗分佈強制執行）和生成的學生代碼之間的互信息，這鼓勵模型學習語法和語義代碼特徵（包括語法樣式、編程技能掌握和代碼結構）的解開表徵。通過在現實世界的編程教育數據集上進行實驗，我們表明 InfoOIRT 既可以準確地生成學生代碼，又可以導致可解釋的學生知識表徵。

##### **Towards Energy-Aware Federated Learning via MARL: A Dual-Selection Approach for Model and Client**
2405.08183v1 by Jun Xia, Yiyu Shi

Although Federated Learning (FL) is promising in knowledge sharing for
heterogeneous Artificial Intelligence of Thing (AIoT) devices, their training
performance and energy efficacy are severely restricted in practical
battery-driven scenarios due to the ``wooden barrel effect'' caused by the
mismatch between homogeneous model paradigms and heterogeneous device
capability. As a result, due to various kinds of differences among devices, it
is hard for existing FL methods to conduct training effectively in
energy-constrained scenarios, such as the battery constraints of devices. To
tackle the above issues, we propose an energy-aware FL framework named DR-FL,
which considers the energy constraints in both clients and heterogeneous deep
learning models to enable energy-efficient FL. Unlike Vanilla FL, DR-FL adopts
our proposed Muti-Agents Reinforcement Learning (MARL)-based dual-selection
method, which allows participated devices to make contributions to the global
model effectively and adaptively based on their computing capabilities and
energy capacities in a MARL-based manner. Experiments on various well-known
datasets show that DR-FL can not only maximise knowledge sharing among
heterogeneous models under the energy constraint of large-scale AIoT systems
but also improve the model performance of each involved heterogeneous device.

摘要：儘管聯合式學習 (FL) 在異質化物聯網 (AIoT) 裝置的知識共享中很有前景，但由於同質化模型範例與異質化裝置功能之間的不匹配所造成的「木桶效應」，其訓練效能和能源效率在實際的電池驅動場景中受到嚴重限制。因此，由於裝置之間各種差異，現有的 FL 方法難以在能源受限的場景中有效進行訓練，例如裝置的電池限制。為了解決上述問題，我們提出了一個名為 DR-FL 的節能 FL 架構，它考慮了用戶端和異質化深度學習模型中的能源限制，以實現節能 FL。與 Vanilla FL 不同，DR-FL 採用我們提出的多智能體強化學習 (MARL) 基於雙重選擇的方法，允許參與的裝置根據其運算能力和能源容量以 MARL 為基礎的方式，有效且適應性地對全球模型做出貢獻。在各種知名資料集上的實驗表明，DR-FL 不僅可以在大規模 AIoT 系統的能源限制下最大化異質化模型之間的知識共享，還能提升每個參與的異質化裝置的模型效能。

##### **Estimating Direct and Indirect Causal Effects of Spatiotemporal Interventions in Presence of Spatial Interference**
2405.08174v1 by Sahara Ali, Omar Faruque, Jianwu Wang

Spatial interference (SI) occurs when the treatment at one location affects
the outcomes at other locations. Accounting for spatial interference in
spatiotemporal settings poses further challenges as interference violates the
stable unit treatment value assumption, making it infeasible for standard
causal inference methods to quantify the effects of time-varying treatment at
spatially varying outcomes. In this paper, we first formalize the concept of
spatial interference in case of time-varying treatment assignments by extending
the potential outcome framework under the assumption of no unmeasured
confounding. We then propose our deep learning based potential outcome model
for spatiotemporal causal inference. We utilize latent factor modeling to
reduce the bias due to time-varying confounding while leveraging the power of
U-Net architecture to capture global and local spatial interference in data
over time. Our causal estimators are an extension of average treatment effect
(ATE) for estimating direct (DATE) and indirect effects (IATE) of spatial
interference on treated and untreated data. Being the first of its kind deep
learning based spatiotemporal causal inference technique, our approach shows
advantages over several baseline methods based on the experiment results on two
synthetic datasets, with and without spatial interference. Our results on
real-world climate dataset also align with domain knowledge, further
demonstrating the effectiveness of our proposed method.

摘要：空間干擾 (SI) 是指某個地方的療法會影響其他地方的結果。在時空背景下考慮空間干擾會帶來進一步的挑戰，因為干擾會違反穩定的單位治療值假設，使得標準因果推論方法無法量化時變治療對空間變異結果的影響。在本文中，我們首先在沒有未測量混淆的假設下，透過擴展潛在結果架構，將時變治療分配的空間干擾概念形式化。接著，我們提出基於深度學習的潛在結果模型，用於時空因果推論。我們利用潛在因子模型來減少因時變混淆造成的偏差，同時利用 U-Net 架構的優勢來擷取資料中隨時間變化的全局和局部空間干擾。我們的因果估計器是平均治療效果 (ATE) 的延伸，用於估計空間干擾對已治療和未治療資料的直接 (DATE) 和間接效果 (IATE)。作為首創基於深度學習的時空因果推論技術，我們的做法在兩個合成資料集（有和沒有空間干擾）的實驗結果中，展現出優於多種基線方法的優勢。我們在真實世界氣候資料集的結果也與領域知識一致，進一步證明我們提出的方法的有效性。

##### **CANTONMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation**
2405.08172v1 by Kung Yin Hong, Lifeng Han, Riza Batista-Navarro, Goran Nenadic

This paper investigates the development and evaluation of machine translation
models from Cantonese to English, where we propose a novel approach to tackle
low-resource language translations. The main objectives of the study are to
develop a model that can effectively translate Cantonese to English and
evaluate it against state-of-the-art commercial models. To achieve this, a new
parallel corpus has been created by combining different available corpora
online with preprocessing and cleaning. In addition, a monolingual Cantonese
dataset has been created through web scraping to aid the synthetic parallel
corpus generation. Following the data collection process, several approaches,
including fine-tuning models, back-translation, and model switch, have been
used. The translation quality of models has been evaluated with multiple
quality metrics, including lexicon-based metrics (SacreBLEU and hLEPOR) and
embedding-space metrics (COMET and BERTscore). Based on the automatic metrics,
the best model is selected and compared against the 2 best commercial
translators using the human evaluation framework HOPES. The best model proposed
in this investigation (NLLB-mBART) with model switch mechanisms has reached
comparable and even better automatic evaluation scores against State-of-the-art
commercial models (Bing and Baidu Translators), with a SacreBLEU score of 16.8
on our test set. Furthermore, an open-source web application has been developed
to allow users to translate between Cantonese and English, with the different
trained models available for effective comparisons between models from this
investigation and users. CANTONMT is available at
https://github.com/kenrickkung/CantoneseTranslation

摘要：本論文探討從粵語到英語的機器翻譯模型的開發和評估，我們提出了一種新方法來處理低資源語言翻譯。本研究的主要目標是開發一個模型，可以有效地將粵語翻譯成英語，並根據最先進的商業模型對其進行評估。為此，我們通過結合不同的可用語料庫，並進行預處理和清理，創建了一個新的平行語料庫。此外，還通過網路爬蟲創建了一個單語粵語數據集，以幫助合成平行語料庫的生成。在數據收集過程之後，已經使用了多種方法，包括微調模型、反向翻譯和模型切換。模型的翻譯品質已使用多種品質指標進行評估，包括基於詞彙的指標（SacreBLEU 和 hLEPOR）和嵌入空間指標（COMET 和 BERTscore）。根據自動指標，選出最佳模型，並使用人類評估框架 HOPES 與 2 個最佳商業翻譯器進行比較。本研究中提出的最佳模型（NLLB-mBART）具有模型切換機制，在我們的測試集中達到了與最先進的商業模型（必應和百度翻譯）相當甚至更好的自動評估分數，SacreBLEU 分數為 16.8。此外，我們還開發了一個開源網路應用程式，允許使用者在粵語和英語之間進行翻譯，並提供不同的訓練模型，以便在本次研究的模型和使用者之間進行有效的比較。CANTONMT 可在 https://github.com/kenrickkung/CantoneseTranslation 獲得

##### **LLM Theory of Mind and Alignment: Opportunities and Risks**
2405.08154v1 by Winnie Street

Large language models (LLMs) are transforming human-computer interaction and
conceptions of artificial intelligence (AI) with their impressive capacities
for conversing and reasoning in natural language. There is growing interest in
whether LLMs have theory of mind (ToM); the ability to reason about the mental
and emotional states of others that is core to human social intelligence. As
LLMs are integrated into the fabric of our personal, professional and social
lives and given greater agency to make decisions with real-world consequences,
there is a critical need to understand how they can be aligned with human
values. ToM seems to be a promising direction of inquiry in this regard.
Following the literature on the role and impacts of human ToM, this paper
identifies key areas in which LLM ToM will show up in human:LLM interactions at
individual and group levels, and what opportunities and risks for alignment are
raised in each. On the individual level, the paper considers how LLM ToM might
manifest in goal specification, conversational adaptation, empathy and
anthropomorphism. On the group level, it considers how LLM ToM might facilitate
collective alignment, cooperation or competition, and moral judgement-making.
The paper lays out a broad spectrum of potential implications and suggests the
most pressing areas for future research.

摘要：大型語言模型 (LLM) 正以其令人印象深刻的自然語言對話和推理能力，轉變了人機互動以及對人工智慧 (AI) 的觀念。對於 LLM 是否具備心智理論 (ToM) ── 即推理他人心理和情緒狀態的能力，這項人類社會智慧的核心 ── 逐漸引起關注。隨著 LLM 融入我們個人、專業和社會生活的架構中，並賦予其更大的自主權來做出具有現實世界後果的決策，迫切需要了解如何讓 LLM 與人類價值觀保持一致。在這方面，ToM 似乎是一個很有前景的研究方向。本文遵循關於人類 ToM 的角色和影響的文獻，找出 LLM ToM 將在個人和群體層面的 LLM 人類互動中出現的主要領域，以及在每個領域中出現了哪些機會和風險。在個人層面，本文探討 LLM ToM 如何表現在目標規格、對話適應、同理心和擬人化中。在群體層面，它探討 LLM ToM 如何促進集體協調、合作或競爭，以及道德判斷的制定。本文列出了廣泛的潛在影響，並建議未來研究最迫切的領域。

##### **Benchmarking Retrieval-Augmented Large Language Models in Biomedical NLP: Application, Robustness, and Self-Awareness**
2405.08151v1 by Mingchen Li, Zaifu Zhan, Han Yang, Yongkang Xiao, Jiatan Huang, Rui Zhang

Large language models (LLM) have demonstrated remarkable capabilities in
various biomedical natural language processing (NLP) tasks, leveraging the
demonstration within the input context to adapt to new tasks. However, LLM is
sensitive to the selection of demonstrations. To address the hallucination
issue inherent in LLM, retrieval-augmented LLM (RAL) offers a solution by
retrieving pertinent information from an established database. Nonetheless,
existing research work lacks rigorous evaluation of the impact of
retrieval-augmented large language models on different biomedical NLP tasks.
This deficiency makes it challenging to ascertain the capabilities of RAL
within the biomedical domain. Moreover, the outputs from RAL are affected by
retrieving the unlabeled, counterfactual, or diverse knowledge that is not well
studied in the biomedical domain. However, such knowledge is common in the real
world. Finally, exploring the self-awareness ability is also crucial for the
RAL system. So, in this paper, we systematically investigate the impact of RALs
on 5 different biomedical tasks (triple extraction, link prediction,
classification, question answering, and natural language inference). We analyze
the performance of RALs in four fundamental abilities, including unlabeled
robustness, counterfactual robustness, diverse robustness, and negative
awareness. To this end, we proposed an evaluation framework to assess the RALs'
performance on different biomedical NLP tasks and establish four different
testbeds based on the aforementioned fundamental abilities. Then, we evaluate 3
representative LLMs with 3 different retrievers on 5 tasks over 9 datasets.

摘要：大型語言模型 (LLM) 已在各種生物醫學自然語言處理 (NLP) 任務中展現出非凡的能力，利用輸入內容中的示範來適應新任務。然而，LLM 對示範的選擇很敏感。為了解決 LLM 中固有的幻覺問題，檢索增強 LLM (RAL) 提供了一個解決方案，從既定的資料庫中檢索相關資訊。儘管如此，現有的研究工作缺乏對檢索增強大型語言模型對不同生物醫學 NLP 任務的影響進行嚴格評估。這種缺陷使得難以確定 RAL 在生物醫學領域中的能力。此外，RAL 的輸出受到檢索未標記、反事實或多樣化知識的影響，而這些知識在生物醫學領域中並未得到很好的研究。然而，這種知識在現實世界中很常見。最後，探索自我意識能力對於 RAL 系統來說也至關重要。因此，在本文中，我們系統地研究了 RAL 對 5 個不同生物醫學任務（三元組提取、連結預測、分類、問題回答和自然語言推理）的影響。我們分析了 RAL 在四項基本能力中的表現，包括未標記魯棒性、反事實魯棒性、多樣性魯棒性和負面意識。為此，我們提出了一個評估框架來評估 RAL 在不同生物醫學 NLP 任務上的表現，並根據上述基本能力建立了四個不同的測試平台。然後，我們在 9 個資料集上的 5 個任務中評估了 3 個不同的檢索器和 3 個代表性 LLM。

##### **Many-Shot Regurgitation (MSR) Prompting**
2405.08134v1 by Shashank Sonkar, Richard G. Baraniuk

We introduce Many-Shot Regurgitation (MSR) prompting, a new black-box
membership inference attack framework for examining verbatim content
reproduction in large language models (LLMs). MSR prompting involves dividing
the input text into multiple segments and creating a single prompt that
includes a series of faux conversation rounds between a user and a language
model to elicit verbatim regurgitation. We apply MSR prompting to diverse text
sources, including Wikipedia articles and open educational resources (OER)
textbooks, which provide high-quality, factual content and are continuously
updated over time. For each source, we curate two dataset types: one that LLMs
were likely exposed to during training ($D_{\rm pre}$) and another consisting
of documents published after the models' training cutoff dates ($D_{\rm
post}$). To quantify the occurrence of verbatim matches, we employ the Longest
Common Substring algorithm and count the frequency of matches at different
length thresholds. We then use statistical measures such as Cliff's delta,
Kolmogorov-Smirnov (KS) distance, and Kruskal-Wallis H test to determine
whether the distribution of verbatim matches differs significantly between
$D_{\rm pre}$ and $D_{\rm post}$. Our findings reveal a striking difference in
the distribution of verbatim matches between $D_{\rm pre}$ and $D_{\rm post}$,
with the frequency of verbatim reproduction being significantly higher when
LLMs (e.g. GPT models and LLaMAs) are prompted with text from datasets they
were likely trained on. For instance, when using GPT-3.5 on Wikipedia articles,
we observe a substantial effect size (Cliff's delta $= -0.984$) and a large KS
distance ($0.875$) between the distributions of $D_{\rm pre}$ and $D_{\rm
post}$. Our results provide compelling evidence that LLMs are more prone to
reproducing verbatim content when the input text is likely sourced from their
training data.

摘要：<paragraph>我們引入了多重提示式回饋 (MSR)，這是一個新的黑盒會員推論攻擊架構，用於檢查大型語言模型 (LLM) 中的逐字內容複製。MSR 提示式涉及將輸入文字分成多個區段，並建立一個單一提示式，其中包含使用者與語言模型之間一系列虛假的對話回合，以引發逐字回饋。我們將 MSR 提示式應用於不同的文字來源，包括維基百科文章和開放教育資源 (OER) 教科書，這些來源提供了高品質的事實內容，並會持續更新。對於每個來源，我們策劃了兩種資料集類型：一種是 LLM 在訓練期間可能接觸到的 ($D_{\rm pre}$)，另一種則包含在模型訓練截止日期後發布的文件 ($D_{\rm post}$)。為了量化逐字匹配的發生，我們採用最長公共子字串演算法，並計算不同長度閾值的匹配頻率。然後，我們使用統計量度，例如 Cliff's delta、Kolmogorov-Smirnov (KS) 距離和 Kruskal-Wallis H 檢定，來確定逐字匹配的分布是否在 $D_{\rm pre}$ 和 $D_{\rm post}$ 之間有顯著差異。我們的研究結果揭示了 $D_{\rm pre}$ 和 $D_{\rm post}$ 之間逐字匹配分布的顯著差異，當使用 LLM（例如 GPT 模型和 LLaMA）提示來自他們可能受過訓練的資料集的文字時，逐字複製的頻率會顯著提高。例如，在維基百科文章中使用 GPT-3.5 時，我們觀察到 $D_{\rm pre}$ 和 $D_{\rm post}$ 的分布之間有顯著的效果大小（Cliff's delta $= -0.984$）和較大的 KS 距離 ($0.875$）。我們的結果提供了令人信服的證據，證明當輸入文字可能來自其訓練資料時，LLM 更容易複製逐字內容。</paragraph>

##### **When factorization meets argumentation: towards argumentative explanations**
2405.08131v1 by Jinfeng Zhong, Elsa Negre

Factorization-based models have gained popularity since the Netflix challenge
{(2007)}. Since that, various factorization-based models have been developed
and these models have been proven to be efficient in predicting users' ratings
towards items. A major concern is that explaining the recommendations generated
by such methods is non-trivial because the explicit meaning of the latent
factors they learn are not always clear. In response, we propose a novel model
that combines factorization-based methods with argumentation frameworks (AFs).
The integration of AFs provides clear meaning at each stage of the model,
enabling it to produce easily understandable explanations for its
recommendations. In this model, for every user-item interaction, an AF is
defined in which the features of items are considered as arguments, and the
users' ratings towards these features determine the strength and polarity of
these arguments. This perspective allows our model to treat feature attribution
as a structured argumentation procedure, where each calculation is marked with
explicit meaning, enhancing its inherent interpretability. Additionally, our
framework seamlessly incorporates side information, such as user contexts,
leading to more accurate predictions. We anticipate at least three practical
applications for our model: creating explanation templates, providing
interactive explanations, and generating contrastive explanations. Through
testing on real-world datasets, we have found that our model, along with its
variants, not only surpasses existing argumentation-based methods but also
competes effectively with current context-free and context-aware methods.

摘要：<paragraph>自 Netflix 挑戰賽 {(2007)} 以來，基於分解的模型越來越受歡迎。自此，各種基於分解的模型已被開發出來，這些模型已被證明可以有效預測使用者對商品的評分。一個主要的問題是，解釋此類方法產生的推薦並非易事，因為他們學習到的潛在因素的明確含義並不總是清楚。為了解決這個問題，我們提出了一個新穎的模型，將基於分解的方法與論證架構 (AF) 結合起來。AF 的整合在模型的每個階段提供清晰的含義，使其能夠為其推薦產生容易理解的解釋。在此模型中，對於每個使用者與商品的互動，定義了一個 AF，其中商品的特性被視為論證，而使用者對這些特性的評分決定了這些論證的強度和極性。這個觀點使我們的模型能夠將特徵歸因視為一個結構化的論證程序，其中每一個計算都標記有明確的含義，增強其內在的可解釋性。此外，我們的框架無縫地整合了側邊資訊，例如使用者背景，從而產生更準確的預測。我們預期我們的模型至少有三個實際應用：建立解釋範本、提供互動式解釋以及產生對比式解釋。透過在真實世界資料集上進行測試，我們發現我們的模型及其變體不僅超越了現有的基於論證的方法，而且還能有效地與當前的無背景和有背景感知的方法競爭。</paragraph>

##### **From Questions to Insightful Answers: Building an Informed Chatbot for University Resources**
2405.08120v1 by Subash Neupane, Elias Hossain, Jason Keith, Himanshu Tripathi, Farbod Ghiasi, Noorbakhsh Amiri Golilarz, Amin Amirlatifi, Sudip Mittal, Shahram Rahimi

This paper presents BARKPLUG V.2, a Large Language Model (LLM)-based chatbot
system built using Retrieval Augmented Generation (RAG) pipelines to enhance
the user experience and access to information within academic settings.The
objective of BARKPLUG V.2 is to provide information to users about various
campus resources, including academic departments, programs, campus facilities,
and student resources at a university setting in an interactive fashion. Our
system leverages university data as an external data corpus and ingests it into
our RAG pipelines for domain-specific question-answering tasks. We evaluate the
effectiveness of our system in generating accurate and pertinent responses for
Mississippi State University, as a case study, using quantitative measures,
employing frameworks such as Retrieval Augmented Generation Assessment(RAGAS).
Furthermore, we evaluate the usability of this system via subjective
satisfaction surveys using the System Usability Scale (SUS). Our system
demonstrates impressive quantitative performance, with a mean RAGAS score of
0.96, and experience, as validated by usability assessments.

摘要：本論文提出 BARKPLUG V.2，一個基於大型語言模型 (LLM) 的聊天機器人系統，使用檢索擴增生成 (RAG) 管線建置，以增強使用者體驗和在學術環境中獲取資訊。BARKPLUG V.2 的目標是透過互動方式，向使用者提供關於各種校園資源的資訊，包括學術部門、課程、校園設施和大學環境中的學生資源。我們的系統利用大學資料作為外部資料語料庫，並將其導入我們的 RAG 管線，以進行特定領域的問答任務。我們評估了系統在為密西西比州立大學產生準確且相關的回應的有效性，作為案例研究，使用量化測量，採用檢索擴增生成評估 (RAGAS) 等架構。此外，我們透過使用系統可用性量表 (SUS) 的主觀滿意度調查，評估此系統的可用性。我們的系統表現出令人印象深刻的量化效能，RAGAS 平均得分為 0.96，且經驗經可用性評估驗證。

##### **KET-QA: A Dataset for Knowledge Enhanced Table Question Answering**
2405.08099v1 by Mengkang Hu, Haoyu Dong, Ping Luo, Shi Han, Dongmei Zhang

Due to the concise and structured nature of tables, the knowledge contained
therein may be incomplete or missing, posing a significant challenge for table
question answering (TableQA) and data analysis systems. Most existing datasets
either fail to address the issue of external knowledge in TableQA or only
utilize unstructured text as supplementary information for tables. In this
paper, we propose to use a knowledge base (KB) as the external knowledge source
for TableQA and construct a dataset KET-QA with fine-grained gold evidence
annotation. Each table in the dataset corresponds to a sub-graph of the entire
KB, and every question requires the integration of information from both the
table and the sub-graph to be answered. To extract pertinent information from
the vast knowledge sub-graph and apply it to TableQA, we design a
retriever-reasoner structured pipeline model. Experimental results demonstrate
that our model consistently achieves remarkable relative performance
improvements ranging from 1.9 to 6.5 times and absolute improvements of 11.66%
to 44.64% on EM scores across three distinct settings (fine-tuning, zero-shot,
and few-shot), in comparison with solely relying on table information in the
traditional TableQA manner. However, even the best model achieves a 60.23% EM
score, which still lags behind the human-level performance, highlighting the
challenging nature of KET-QA for the question-answering community. We also
provide a human evaluation of error cases to analyze further the aspects in
which the model can be improved. Project page: https://ketqa.github.io/.

摘要：<paragraph>由於表格簡潔且結構化的特性，其中包含的知識可能不完整或缺失，對表格問答 (TableQA) 和資料分析系統構成重大挑戰。大多數現有資料集無法解決 TableQA 中外部知識的問題，或者僅將非結構化文字用作表格的補充資訊。在本文中，我們建議使用知識庫 (KB) 作為 TableQA 的外部知識來源，並建構一個具有細粒度黃金證據註解的資料集 KET-QA。資料集中的每個表格都對應於整個 KB 的子圖，每個問題都需要整合來自表格和子圖的資訊才能回答。為了從龐大的知識子圖中提取相關資訊並將其應用於 TableQA，我們設計了一個檢索器推理結構管道模型。實驗結果表明，我們的模型在三個不同的設定（微調、零次學習和少次學習）中，與傳統 TableQA 方式僅依賴表格資訊相比，始終都能獲得顯著的相對效能提升，範圍從 1.9 倍到 6.5 倍，EM 得分絕對提升 11.66% 到 44.64%。然而，即使是最好的模型也只達到 60.23% 的 EM 得分，這仍然落後於人類的表現，突顯了 KET-QA 對問答社群的挑戰性。我們還提供了錯誤案例的人類評估，以進一步分析模型可以改進的方面。專案頁面：https://ketqa.github.io/。</paragraph>

##### **MambaOut: Do We Really Need Mamba for Vision?**
2405.07992v2 by Weihao Yu, Xinchao Wang

Mamba, an architecture with RNN-like token mixer of state space model (SSM),
was recently introduced to address the quadratic complexity of the attention
mechanism and subsequently applied to vision tasks. Nevertheless, the
performance of Mamba for vision is often underwhelming when compared with
convolutional and attention-based models. In this paper, we delve into the
essence of Mamba, and conceptually conclude that Mamba is ideally suited for
tasks with long-sequence and autoregressive characteristics. For vision tasks,
as image classification does not align with either characteristic, we
hypothesize that Mamba is not necessary for this task; Detection and
segmentation tasks are also not autoregressive, yet they adhere to the
long-sequence characteristic, so we believe it is still worthwhile to explore
Mamba's potential for these tasks. To empirically verify our hypotheses, we
construct a series of models named MambaOut through stacking Mamba blocks while
removing their core token mixer, SSM. Experimental results strongly support our
hypotheses. Specifically, our MambaOut model surpasses all visual Mamba models
on ImageNet image classification, indicating that Mamba is indeed unnecessary
for this task. As for detection and segmentation, MambaOut cannot match the
performance of state-of-the-art visual Mamba models, demonstrating the
potential of Mamba for long-sequence visual tasks. The code is available at
https://github.com/yuweihao/MambaOut

摘要：Mamba 是一種架構，具有狀態空間模型 (SSM) 的類似 RNN 的代幣混合器，最近被引入以解決注意力機制的二次複雜性，並隨後應用於視覺任務。儘管如此，與基於卷積和注意力的模型相比，Mamba 在視覺方面的表現往往令人失望。在本文中，我們深入探討 Mamba 的本質，並在概念上得出結論，Mamba 非常適合具有長序列和自迴歸特性的任務。對於視覺任務，由於圖像分類不符合任何特徵，我們假設 Mamba 對此任務並非必要；檢測和分割任務也不是自迴歸的，但它們符合長序列特徵，因此我們認為探索 Mamba 在這些任務中的潛力仍然是有價值的。為了經驗驗證我們的假設，我們構建了一系列名為 MambaOut 的模型，通過堆疊 Mamba 塊同時移除其核心代幣混合器 SSM。實驗結果有力地支持了我們的假設。具體來說，我們的 MambaOut 模型在 ImageNet 圖像分類方面超越了所有視覺 Mamba 模型，表明 Mamba 對於此任務確實是不必要的。至於檢測和分割，MambaOut 無法與最先進的視覺 Mamba 模型的性能相匹配，這證明了 Mamba 在長序列視覺任務中的潛力。代碼可在 https://github.com/yuweihao/MambaOut 獲得

##### **Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots**
2405.07990v1 by Chengyue Wu, Yixiao Ge, Qiushan Guo, Jiahao Wang, Zhixuan Liang, Zeyu Lu, Ying Shan, Ping Luo

The remarkable progress of Multi-modal Large Language Models (MLLMs) has
attracted significant attention due to their superior performance in visual
contexts. However, their capabilities in turning visual figure to executable
code, have not been evaluated thoroughly. To address this, we introduce
Plot2Code, a comprehensive visual coding benchmark designed for a fair and
in-depth assessment of MLLMs. We carefully collect 132 manually selected
high-quality matplotlib plots across six plot types from publicly available
matplotlib galleries. For each plot, we carefully offer its source code, and an
descriptive instruction summarized by GPT-4. This approach enables Plot2Code to
extensively evaluate MLLMs' code capabilities across various input modalities.
Furthermore, we propose three automatic evaluation metrics, including code pass
rate, text-match ratio, and GPT-4V overall rating, for a fine-grained
assessment of the output code and rendered images. Instead of simply judging
pass or fail, we employ GPT-4V to make an overall judgement between the
generated and reference images, which has been shown to be consistent with
human evaluation. The evaluation results, which include analyses of 14 MLLMs
such as the proprietary GPT-4V, Gemini-Pro, and the open-sourced Mini-Gemini,
highlight the substantial challenges presented by Plot2Code. With Plot2Code, we
reveal that most existing MLLMs struggle with visual coding for text-dense
plots, heavily relying on textual instruction. We hope that the evaluation
results from Plot2Code on visual coding will guide the future development of
MLLMs. All data involved with Plot2Code are available at
https://huggingface.co/datasets/TencentARC/Plot2Code.

摘要：多模態大型語言模型 (MLLM) 的顯著進步，由於其在視覺語境中的卓越表現，引起了廣泛關注。然而，它們將視覺圖形轉換為可執行程式碼的能力，尚未得到徹底評估。為了解決這個問題，我們引入了 Plot2Code，一個全面的視覺編碼基準，旨在對 MLLM 進行公平和深入的評估。我們仔細收集了 132 個手動挑選的高品質 matplotlib 圖形，涵蓋來自公開 matplotlib 庫的六種圖形類型。對於每個圖形，我們仔細提供了其原始程式碼，以及由 GPT-4 總結的描述性說明。這種方法使 Plot2Code 能夠廣泛評估 MLLM 的程式碼能力，涵蓋各種輸入模式。此外，我們提出了三種自動評估指標，包括程式碼通過率、文字匹配率和 GPT-4V 整體評分，用於對輸出程式碼和渲染圖像進行細粒度的評估。我們沒有簡單地判斷通過或失敗，而是採用 GPT-4V 對生成的圖像和參考圖像進行整體判斷，這已被證明與人類評估一致。評估結果包括對 14 個 MLLM（例如專有的 GPT-4V、Gemini-Pro 和開源的 Mini-Gemini）的分析，突出了 Plot2Code 帶來的重大挑戰。通過 Plot2Code，我們發現大多數現有的 MLLM 在處理文字密集型圖形的視覺編碼時都存在困難，嚴重依賴於文字說明。我們希望 Plot2Code 在視覺編碼上的評估結果，將指導 MLLM 未來的發展。Plot2Code 涉及的所有資料都可以在 https://huggingface.co/datasets/TencentARC/Plot2Code 取得。

##### **The Platonic Representation Hypothesis**
2405.07987v1 by Minyoung Huh, Brian Cheung, Tongzhou Wang, Phillip Isola

We argue that representations in AI models, particularly deep networks, are
converging. First, we survey many examples of convergence in the literature:
over time and across multiple domains, the ways by which different neural
networks represent data are becoming more aligned. Next, we demonstrate
convergence across data modalities: as vision models and language models get
larger, they measure distance between datapoints in a more and more alike way.
We hypothesize that this convergence is driving toward a shared statistical
model of reality, akin to Plato's concept of an ideal reality. We term such a
representation the platonic representation and discuss several possible
selective pressures toward it. Finally, we discuss the implications of these
trends, their limitations, and counterexamples to our analysis.

摘要：我們認為，人工智慧模型中的表徵，特別是深度網路，正在趨於一致。首先，我們檢視文獻中許多一致性的範例：隨著時間推移和跨越多個領域，不同神經網路表徵資料的方式正變得更為一致。接下來，我們示範跨資料型態的一致性：隨著視覺模型和語言模型變大，它們以越來越相似的模式衡量資料點之間的距離。我們假設這種一致性正朝向一個共享的現實統計模型邁進，類似於柏拉圖對理想現實的概念。我們將這種表徵稱為柏拉圖表徵，並討論了朝向它的幾種可能的選擇壓力。最後，我們討論這些趨勢的含意、它們的限制，以及對我們分析的反例。

##### **Localized Adaptive Risk Control**
2405.07976v1 by Matteo Zecchin, Osvaldo Simeone

Adaptive Risk Control (ARC) is an online calibration strategy based on set
prediction that offers worst-case deterministic long-term risk control, as well
as statistical marginal coverage guarantees. ARC adjusts the size of the
prediction set by varying a single scalar threshold based on feedback from past
decisions. In this work, we introduce Localized Adaptive Risk Control (L-ARC),
an online calibration scheme that targets statistical localized risk guarantees
ranging from conditional risk to marginal risk, while preserving the worst-case
performance of ARC. L-ARC updates a threshold function within a reproducing
kernel Hilbert space (RKHS), with the kernel determining the level of
localization of the statistical risk guarantee. The theoretical results
highlight a trade-off between localization of the statistical risk and
convergence speed to the long-term risk target. Thanks to localization, L-ARC
is demonstrated via experiments to produce prediction sets with risk guarantees
across different data subpopulations, significantly improving the fairness of
the calibrated model for tasks such as image segmentation and beam selection in
wireless networks.

摘要：自適應風險控制 (ARC) 是一種基於設定預測的線上校準策略，提供最壞情況的確定性長期風險控制，以及統計邊際覆蓋保證。ARC 透過根據過去決策的回饋調整預測設定的大小，來改變單一標量閾值。在這項工作中，我們引入了局部自適應風險控制 (L-ARC)，一種線上校準方案，其目標是統計局部風險保證，範圍從條件風險到邊際風險，同時保留 ARC 的最壞情況表現。L-ARC 在再生核希爾伯特空間 (RKHS) 中更新閾值函數，其中核決定統計風險保證的局部化程度。理論結果強調了統計風險局部化與長期風險目標收斂速度之間的權衡。由於局部化，L-ARC 透過實驗證明產生具有風險保證的預測設定，涵蓋不同的資料子群體，顯著改善校準模型在影像分割和無線網路中波束選擇等任務的公平性。

##### **Investigating the Semantic Robustness of CLIP-based Zero-Shot Anomaly Segmentation**
2405.07969v1 by Kevin Stangl, Marius Arvinte, Weilin Xu, Cory Cornelius

Zero-shot anomaly segmentation using pre-trained foundation models is a
promising approach that enables effective algorithms without expensive,
domain-specific training or fine-tuning. Ensuring that these methods work
across various environmental conditions and are robust to distribution shifts
is an open problem. We investigate the performance of WinCLIP [14] zero-shot
anomaly segmentation algorithm by perturbing test data using three semantic
transformations: bounded angular rotations, bounded saturation shifts, and hue
shifts. We empirically measure a lower performance bound by aggregating across
per-sample worst-case perturbations and find that average performance drops by
up to 20% in area under the ROC curve and 40% in area under the per-region
overlap curve. We find that performance is consistently lowered on three CLIP
backbones, regardless of model architecture or learning objective,
demonstrating a need for careful performance evaluation.

摘要：使用預訓練基礎模型進行零次異常分割是一種有前途的方法，它能讓有效演算法在沒有昂貴的特定領域訓練或微調的情況下運作。確保這些方法能在各種環境條件下運作，並且對分佈轉移具有穩健性，是一個公開的問題。我們透過使用三個語義轉換（有界角旋轉、有界飽和度轉移和色相轉移）擾動測試資料，來調查 WinCLIP [14] 零次異常分割演算法的效能。我們透過彙總每個樣本最壞情況的擾動，經驗性地測量較低的效能界限，並發現 ROC 曲線下的面積平均效能下降了 20%，而每個區域重疊曲線下的面積則下降了 40%。我們發現效能在一貫地降低於三個 CLIP 主幹上，而與模型架構或學習目標無關，這證明了仔細評估效能的必要性。

##### **OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**
2405.07966v1 by Qiuchi Xiang, Jintao Cheng, Jiehao Luo, Jin Wu, Rui Fan, Xieyuanli Chen, Xiaoyu Tang

Place recognition is the foundation for enabling autonomous systems to
achieve independent decision-making and safe operations. It is also crucial in
tasks such as loop closure detection and global localization within SLAM.
Previous methods utilize mundane point cloud representations as input and deep
learning-based LiDAR-based Place Recognition (LPR) approaches employing
different point cloud image inputs with convolutional neural networks (CNNs) or
transformer architectures. However, the recently proposed Mamba deep learning
model, combined with state space models (SSMs), holds great potential for long
sequence modeling. Therefore, we developed OverlapMamba, a novel network for
place recognition, which represents input range views (RVs) as sequences. In a
novel way, we employ a stochastic reconstruction approach to build shift state
space models, compressing the visual representation. Evaluated on three
different public datasets, our method effectively detects loop closures,
showing robustness even when traversing previously visited locations from
different directions. Relying on raw range view inputs, it outperforms typical
LiDAR and multi-view combination methods in time complexity and speed,
indicating strong place recognition capabilities and real-time efficiency.

摘要：場景辨識是讓自主系統能獨立決策和安全運作的基礎。它在 SLAM 中的迴路閉合偵測和全局定位等任務中也至關重要。先前的做法會利用平凡的點雲表示作為輸入，以及採用卷積神經網路 (CNN) 或Transformer架構，使用不同的點雲影像輸入的深度學習式雷射雷達場景辨識 (LPR) 方法。然而，最近提出的 Mamba 深度學習模型結合狀態空間模型 (SSM)，在長序列建模方面擁有極佳的潛力。因此，我們開發了 OverlapMamba，這是一個用於場景辨識的新穎網路，它將輸入範圍視圖 (RV) 表示為序列。我們採用一種隨機重建方法來建立轉移狀態空間模型，壓縮視覺表示，這是一個新穎的做法。在三個不同的公開資料集上進行評估，我們的做法有效地偵測到迴路閉合，即使從不同的方向穿越先前造訪過的地點，也展現出穩健性。它依賴未處理的範圍視圖輸入，在時間複雜度和速度上優於典型的 LiDAR 和多視圖組合方法，顯示出強大的場景辨識能力和即時效率。

##### **AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments**
2405.07960v1 by Samuel Schmidgall, Rojin Ziaei, Carl Harris, Eduardo Reis, Jeffrey Jopling, Michael Moor

Diagnosing and managing a patient is a complex, sequential decision making
process that requires physicians to obtain information -- such as which tests
to perform -- and to act upon it. Recent advances in artificial intelligence
(AI) and large language models (LLMs) promise to profoundly impact clinical
care. However, current evaluation schemes overrely on static medical
question-answering benchmarks, falling short on interactive decision-making
that is required in real-life clinical work. Here, we present AgentClinic: a
multimodal benchmark to evaluate LLMs in their ability to operate as agents in
simulated clinical environments. In our benchmark, the doctor agent must
uncover the patient's diagnosis through dialogue and active data collection. We
present two open benchmarks: a multimodal image and dialogue environment,
AgentClinic-NEJM, and a dialogue-only environment, AgentClinic-MedQA. We embed
cognitive and implicit biases both in patient and doctor agents to emulate
realistic interactions between biased agents. We find that introducing bias
leads to large reductions in diagnostic accuracy of the doctor agents, as well
as reduced compliance, confidence, and follow-up consultation willingness in
patient agents. Evaluating a suite of state-of-the-art LLMs, we find that
several models that excel in benchmarks like MedQA are performing poorly in
AgentClinic-MedQA. We find that the LLM used in the patient agent is an
important factor for performance in the AgentClinic benchmark. We show that
both having limited interactions as well as too many interaction reduces
diagnostic accuracy in doctor agents. The code and data for this work is
publicly available at https://AgentClinic.github.io.

摘要：診斷和管理病人是一個複雜、循序漸進的決策制定過程，需要醫生獲取資訊（例如要執行哪些測試）並採取行動。人工智慧 (AI) 和大型語言模型 (LLM) 的最新進展有望對臨床護理產生深遠影響。然而，目前的評估方案過於依賴靜態醫療問答基準，在現實生活中臨床工作中所需的互動決策制定方面有所不足。在此，我們提出 AgentClinic：一個多模態基準，用於評估 LLM 在模擬臨床環境中作為代理運作的能力。在我們的基準中，醫生代理必須透過對話和主動數據收集來找出病人的診斷。我們提出了兩個開放基準：一個多模態影像和對話環境 AgentClinic-NEJM，以及一個僅對話的環境 AgentClinic-MedQA。我們將認知和隱含偏見嵌入病人和醫生代理中，以模擬有偏見的代理之間的現實互動。我們發現，引入偏見會導致醫生代理的診斷準確性大幅下降，以及病人代理的順從性、信心和後續諮詢意願下降。在評估一系列最先進的 LLM 時，我們發現幾個在 MedQA 等基準中表現出色的模型在 AgentClinic-MedQA 中表現不佳。我們發現用於病人代理的 LLM 是 AgentClinic 基準中表現的關鍵因素。我們表明，互動次數受限和互動次數過多都會降低醫生代理的診斷準確性。這項工作的程式碼和數據已公開發布於 https://AgentClinic.github.io。

##### **Hierarchical Decision Mamba**
2405.07943v1 by André Correia, Luís A. Alexandre

Recent advancements in imitation learning have been largely fueled by the
integration of sequence models, which provide a structured flow of information
to effectively mimic task behaviours. Currently, Decision Transformer (DT) and
subsequently, the Hierarchical Decision Transformer (HDT), presented
Transformer-based approaches to learn task policies. Recently, the Mamba
architecture has shown to outperform Transformers across various task domains.
In this work, we introduce two novel methods, Decision Mamba (DM) and
Hierarchical Decision Mamba (HDM), aimed at enhancing the performance of the
Transformer models. Through extensive experimentation across diverse
environments such as OpenAI Gym and D4RL, leveraging varying demonstration data
sets, we demonstrate the superiority of Mamba models over their Transformer
counterparts in a majority of tasks. Results show that HDM outperforms other
methods in most settings. The code can be found at
https://github.com/meowatthemoon/HierarchicalDecisionMamba.

摘要：最近的模仿學習進展在很大程度上是由序列模型的整合推動的，這些模型提供了結構化的資訊流，以有效地模仿任務行為。目前，決策Transformer (DT) 以及隨後的層級決策Transformer (HDT) 提出基於Transformer的策略來學習任務政策。最近，Mamba 架構已證明在各種任務領域中優於Transformer。在這項工作中，我們介紹了兩種新方法，即決策 Mamba (DM) 和層級決策 Mamba (HDM)，旨在增強Transformer模型的效能。透過在不同的環境（例如 OpenAI Gym 和 D4RL）中進行廣泛的實驗，利用不同的示範資料集，我們證明了 Mamba 模型在大部分任務中優於其Transformer對應模型。結果顯示，HDM 在大多數設定中優於其他方法。程式碼可以在 https://github.com/meowatthemoon/HierarchicalDecisionMamba 中找到。

##### **RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors**
2405.07940v1 by Liam Dugan, Alyssa Hwang, Filip Trhlik, Josh Magnus Ludan, Andrew Zhu, Hainiu Xu, Daphne Ippolito, Chris Callison-Burch

Many commercial and open-source models claim to detect machine-generated text
with very high accuracy (99\% or higher). However, very few of these detectors
are evaluated on shared benchmark datasets and even when they are, the datasets
used for evaluation are insufficiently challenging -- lacking variations in
sampling strategy, adversarial attacks, and open-source generative models. In
this work we present RAID: the largest and most challenging benchmark dataset
for machine-generated text detection. RAID includes over 6 million generations
spanning 11 models, 8 domains, 11 adversarial attacks and 4 decoding
strategies. Using RAID, we evaluate the out-of-domain and adversarial
robustness of 8 open- and 4 closed-source detectors and find that current
detectors are easily fooled by adversarial attacks, variations in sampling
strategies, repetition penalties, and unseen generative models. We release our
dataset and tools to encourage further exploration into detector robustness.

摘要：許多商業和開放原始碼模型聲稱能以極高的準確度（99% 或更高）偵測機器產生的文字。然而，這些偵測器中只有極少數會在共用基準資料集上進行評估，即使有，用於評估的資料集挑戰性也不足，缺乏取樣策略、對抗性攻擊和開放原始碼生成模型的變化。在這項工作中，我們提出了 RAID：機器產生的文字偵測中最大且最具挑戰性的基準資料集。RAID 包含超過 600 萬個世代，涵蓋 11 個模型、8 個網域、11 個對抗性攻擊和 4 個解碼策略。使用 RAID，我們評估了 8 個開放原始碼和 4 個閉源偵測器的網域外和對抗性穩健性，發現目前的偵測器很容易被對抗性攻擊、取樣策略的變化、重複懲罰和未見過的生成模型所愚弄。我們釋出我們的資料集和工具，以鼓勵進一步探索偵測器的穩健性。

##### **EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning**
2405.07938v1 by Yinzhu Quan, Zefang Liu

In this paper, we introduce EconLogicQA, a rigorous benchmark designed to
assess the sequential reasoning capabilities of large language models (LLMs)
within the intricate realms of economics, business, and supply chain
management. Diverging from traditional benchmarks that predict subsequent
events individually, EconLogicQA poses a more challenging task: it requires
models to discern and sequence multiple interconnected events, capturing the
complexity of economic logics. EconLogicQA comprises an array of multi-event
scenarios derived from economic articles, which necessitate an insightful
understanding of both temporal and logical event relationships. Through
comprehensive evaluations, we exhibit that EconLogicQA effectively gauges a
LLM's proficiency in navigating the sequential complexities inherent in
economic contexts. We provide a detailed description of EconLogicQA dataset and
shows the outcomes from evaluating the benchmark across various leading-edge
LLMs, thereby offering a thorough perspective on their sequential reasoning
potential in economic contexts. Our benchmark dataset is available at
https://huggingface.co/datasets/yinzhu-quan/econ_logic_qa.

摘要：<paragraph>在本文中，我們介紹了 EconLogicQA，這是一個嚴謹的基準，旨在評估大型語言模型 (LLM) 在經濟、商業和供應鏈管理的複雜領域中進行順序推理的能力。與預測後續事件的傳統基準不同，EconLogicQA 提出了一項更具挑戰性的任務：它要求模型辨別和排序多個相互關聯的事件，捕捉經濟邏輯的複雜性。EconLogicQA 包含一系列源自經濟文章的多事件場景，需要深入了解時間和邏輯事件關係。通過綜合評估，我們展示了 EconLogicQA 有效地衡量了 LLM 在應對經濟背景中固有的順序複雜性方面的能力。我們提供了 EconLogicQA 數據集的詳細描述，並展示了在各種領先的 LLM 中評估基準的結果，從而全面了解了它們在經濟背景下的順序推理潛力。我們的基準數據集可在 https://huggingface.co/datasets/yinzhu-quan/econ_logic_qa 獲得。</paragraph>

##### **PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition**
2405.07932v2 by Ziyang Zhang, Qizhen Zhang, Jakob Foerster

Large language models (LLMs) have shown success in many natural language
processing tasks. Despite rigorous safety alignment processes, supposedly
safety-aligned LLMs like Llama 2 and Claude 2 are still susceptible to
jailbreaks, leading to security risks and abuse of the models. One option to
mitigate such risks is to augment the LLM with a dedicated "safeguard", which
checks the LLM's inputs or outputs for undesired behaviour. A promising
approach is to use the LLM itself as the safeguard. Nonetheless, baseline
methods, such as prompting the LLM to self-classify toxic content, demonstrate
limited efficacy. We hypothesise that this is due to domain shift: the
alignment training imparts a self-censoring behaviour to the model ("Sorry I
can't do that"), while the self-classify approach shifts it to a classification
format ("Is this prompt malicious"). In this work, we propose PARDEN, which
avoids this domain shift by simply asking the model to repeat its own outputs.
PARDEN neither requires finetuning nor white box access to the model. We
empirically verify the effectiveness of our method and show that PARDEN
significantly outperforms existing jailbreak detection baselines for Llama-2
and Claude-2. Code and data are available at https://github.com/Ed-Zh/PARDEN.
  We find that PARDEN is particularly powerful in the relevant regime of high
True Positive Rate (TPR) and low False Positive Rate (FPR). For instance, for
Llama2-7B, at TPR equal to 90%, PARDEN accomplishes a roughly 11x reduction in
the FPR from 24.8% to 2.0% on the harmful behaviours dataset.

摘要：大型語言模型 (LLM) 已在許多自然語言處理任務中展現成功。儘管進行嚴格的安全調整程序，但理論上經過安全調整的 LLM（例如 Llama 2 和 Claude 2）仍容易受到越獄攻擊，導致安全風險和模型遭到濫用。減輕此類風險的一個選項是使用專用的「防護措施」擴充 LLM，用於檢查 LLM 的輸入或輸出是否有不良行為。一種有前景的方法是使用 LLM 本身作為防護措施。儘管如此，基線方法（例如提示 LLM 自我分類有毒內容）顯示出有限的功效。我們假設這是由於領域轉移：調整訓練會讓模型產生自我審查行為（「抱歉，我無法這麼做」），而自我分類方法會將其轉移到分類格式（「這個提示是否惡意」）。在這項工作中，我們提出 PARDEN，它透過簡單地要求模型重複其自己的輸出，來避免這種領域轉移。PARDEN 不需要微調或對模型進行白盒存取。我們透過實證驗證我們的方法的有效性，並顯示 PARDEN 在 Llama-2 和 Claude-2 的現有越獄偵測基線上顯著優於其他方法。程式碼和資料可在 https://github.com/Ed-Zh/PARDEN 取得。我們發現 PARDEN 在高真實正類率 (TPR) 和低虛假正類率 (FPR) 的相關範圍中特別有效。例如，對於 Llama2-7B，在 TPR 等於 90% 時，PARDEN 在有害行為資料集上將 FPR 從 24.8% 降低到 2.0%，減少了大約 11 倍。

##### **Stable Diffusion-based Data Augmentation for Federated Learning with Non-IID Data**
2405.07925v1 by Mahdi Morafah, Matthias Reisser, Bill Lin, Christos Louizos

The proliferation of edge devices has brought Federated Learning (FL) to the
forefront as a promising paradigm for decentralized and collaborative model
training while preserving the privacy of clients' data. However, FL struggles
with a significant performance reduction and poor convergence when confronted
with Non-Independent and Identically Distributed (Non-IID) data distributions
among participating clients. While previous efforts, such as client drift
mitigation and advanced server-side model fusion techniques, have shown some
success in addressing this challenge, they often overlook the root cause of the
performance reduction - the absence of identical data accurately mirroring the
global data distribution among clients. In this paper, we introduce Gen-FedSD,
a novel approach that harnesses the powerful capability of state-of-the-art
text-to-image foundation models to bridge the significant Non-IID performance
gaps in FL. In Gen-FedSD, each client constructs textual prompts for each class
label and leverages an off-the-shelf state-of-the-art pre-trained Stable
Diffusion model to synthesize high-quality data samples. The generated
synthetic data is tailored to each client's unique local data gaps and
distribution disparities, effectively making the final augmented local data
IID. Through extensive experimentation, we demonstrate that Gen-FedSD achieves
state-of-the-art performance and significant communication cost savings across
various datasets and Non-IID settings.

摘要：边缘裝置的激增使聯邦學習 (FL) 成為一種有前景的去中心化和協作模型訓練範例，同時還能保護客戶資料的隱私。然而，當面對參與客戶之間的非獨立且同分布 (Non-IID) 資料分佈時，FL 會出現效能大幅下降和收斂不佳的問題。儘管先前的努力，例如客戶漂移緩解和進階伺服器端模型融合技術，已在解決此挑戰方面取得一些成功，但它們常常忽略效能下降的根本原因，也就是缺乏與客戶之間的全球資料分佈完全相同的資料。在本文中，我們介紹了 Gen-FedSD，這是一種新方法，它利用了最先進的文字轉圖像基礎模型的強大功能，來彌合 FL 中顯著的 Non-IID 效能差距。在 Gen-FedSD 中，每個客戶端會為每個類別標籤建構文字提示，並利用現成的最先進預先訓練的 Stable Diffusion 模型來合成高品質的資料樣本。所生成的合成資料是根據每個客戶端獨特的本地資料差距和分佈差異量身打造，有效地使最終擴增的本地資料成為 IID。透過大量的實驗，我們證明 Gen-FedSD 在各種資料集和 Non-IID 設定中都達到了最先進的效能和顯著的通訊成本節省。

##### **Science based AI model certification for new operational environments with application in traffic state estimation**
2405.07893v1 by Daryl Mupupuni, Anupama Guntu, Liang Hong, Kamrul Hasan, Leehyun Keel

The expanding role of Artificial Intelligence (AI) in diverse engineering
domains highlights the challenges associated with deploying AI models in new
operational environments, involving substantial investments in data collection
and model training. Rapid application of AI necessitates evaluating the
feasibility of utilizing pre-trained models in unobserved operational settings
with minimal or no additional data. However, interpreting the opaque nature of
AI's black-box models remains a persistent challenge. Addressing this issue,
this paper proposes a science-based certification methodology to assess the
viability of employing pre-trained data-driven models in new operational
environments. The methodology advocates a profound integration of domain
knowledge, leveraging theoretical and analytical models from physics and
related disciplines, with data-driven AI models. This novel approach introduces
tools to facilitate the development of secure engineering systems, providing
decision-makers with confidence in the trustworthiness and safety of AI-based
models across diverse environments characterized by limited training data and
dynamic, uncertain conditions. The paper demonstrates the efficacy of this
methodology in real-world safety-critical scenarios, particularly in the
context of traffic state estimation. Through simulation results, the study
illustrates how the proposed methodology efficiently quantifies physical
inconsistencies exhibited by pre-trained AI models. By utilizing analytical
models, the methodology offers a means to gauge the applicability of
pre-trained AI models in new operational environments. This research
contributes to advancing the understanding and deployment of AI models,
offering a robust certification framework that enhances confidence in their
reliability and safety across a spectrum of operational conditions.

摘要：<paragraph>人工智慧 (AI) 在各種工程領域中扮演的角色日益擴大，突顯出在新的操作環境中部署 AI 模型所面臨的挑戰，這涉及在資料收集和模型訓練中進行大量的投資。AI 的快速應用需要評估在未觀察到的操作環境中利用預先訓練模型的可行性，而無需或只需最少的額外資料。然而，詮釋 AI 黑盒模型的不透明本質仍然是一個持續的挑戰。針對此問題，本文提出了一個基於科學的認證方法，用於評估在新的操作環境中採用預先訓練的資料驅動模型的可行性。此方法主張將領域知識與來自物理學和相關領域的理論和分析模型，與資料驅動的 AI 模型進行深入整合。這種新穎的方法引入了工具，以促進安全工程系統的開發，讓決策者對在受限訓練資料和動態、不確定的條件下，各種環境中基於 AI 的模型的可信度和安全性有信心。本文證明了這種方法在現實世界的安全關鍵情境中的效力，特別是在交通狀態估計的背景下。透過模擬結果，研究說明了所提出的方法如何有效地量化預先訓練的 AI 模型所表現出的物理不一致性。透過利用分析模型，此方法提供了一種手段來評估預先訓練的 AI 模型在新操作環境中的適用性。這項研究有助於推進對 AI 模型的理解和部署，提供了一個強大的認證架構，以增強對其在各種操作條件下的可靠性和安全性的信心。</paragraph>

##### **Russian-Language Multimodal Dataset for Automatic Summarization of Scientific Papers**
2405.07886v1 by Alena Tsanda, Elena Bruches

The paper discusses the creation of a multimodal dataset of Russian-language
scientific papers and testing of existing language models for the task of
automatic text summarization. A feature of the dataset is its multimodal data,
which includes texts, tables and figures. The paper presents the results of
experiments with two language models: Gigachat from SBER and YandexGPT from
Yandex. The dataset consists of 420 papers and is publicly available on
https://github.com/iis-research-team/summarization-dataset.

摘要：本文讨论了创建俄语科学论文的多模态数据集，以及针对自动文本摘要任务测试现有语言模型。该数据集的特点在于其多模态数据，其中包括文本、表格和图表。本文介绍了两种语言模型的实验结果：来自 SBER 的 Gigachat 和来自 Yandex 的 YandexGPT。该数据集包含 420 篇论文，可在 https://github.com/iis-research-team/summarization-dataset 上公开获取。

##### **Zero-Shot Tokenizer Transfer**
2405.07883v1 by Benjamin Minixhofer, Edoardo Maria Ponti, Ivan Vulić

Language models (LMs) are bound to their tokenizer, which maps raw text to a
sequence of vocabulary items (tokens). This restricts their flexibility: for
example, LMs trained primarily on English may still perform well in other
natural and programming languages, but have vastly decreased efficiency due to
their English-centric tokenizer. To mitigate this, we should be able to swap
the original LM tokenizer with an arbitrary one, on the fly, without degrading
performance. Hence, in this work we define a new problem: Zero-Shot Tokenizer
Transfer (ZeTT). The challenge at the core of ZeTT is finding embeddings for
the tokens in the vocabulary of the new tokenizer. Since prior heuristics for
initializing embeddings often perform at chance level in a ZeTT setting, we
propose a new solution: we train a hypernetwork taking a tokenizer as input and
predicting the corresponding embeddings. We empirically demonstrate that the
hypernetwork generalizes to new tokenizers both with encoder (e.g., XLM-R) and
decoder LLMs (e.g., Mistral-7B). Our method comes close to the original models'
performance in cross-lingual and coding tasks while markedly reducing the
length of the tokenized sequence. We also find that the remaining gap can be
quickly closed by continued training on less than 1B tokens. Finally, we show
that a ZeTT hypernetwork trained for a base (L)LM can also be applied to
fine-tuned variants without extra training. Overall, our results make
substantial strides toward detaching LMs from their tokenizer.

摘要：語言模型 (LM) 受限於其分詞器，它將原始文字對應到詞彙項目（標記）的序列。這限制了其靈活性：例如，主要以英語訓練的 LM 仍可能在其他自然語言和程式語言中表現良好，但由於其以英語為中心的標記器而大幅降低效率。為了減輕這個問題，我們應該能夠在不降低效能的情況下，隨時將原始 LM 標記器替換為任意標記器。因此，在這項工作中，我們定義了一個新問題：零次標記器轉移 (ZeTT)。ZeTT 的核心挑戰是為新標記器詞彙中的標記找到嵌入。由於用於初始化嵌入的先驗啟發法在 ZeTT 設定中通常表現得像隨機層級，我們提出了一個新的解決方案：我們訓練一個以標記器作為輸入並預測對應嵌入的超網路。我們透過實證證明，超網路可以概括到新的標記器，包括編碼器 (例如 XLM-R) 和解碼器 LLM (例如 Mistral-7B)。我們的模型在跨語言和編碼任務中接近原始模型的效能，同時顯著減少標記化序列的長度。我們還發現，透過持續訓練不到 1B 個標記，可以快速縮小剩下的差距。最後，我們展示了針對基礎 (L)LM 訓練的 ZeTT 超網路也可以應用於微調變體，而無需額外訓練。總的來說，我們的成果在將 LM 從其標記器中分離出來方面取得了重大進展。

##### **Reproducing the Metric-Based Evaluation of a Set of Controllable Text Generation Techniques**
2405.07875v1 by Michela Lorandi, Anya Belz

Rerunning a metric-based evaluation should be more straightforward, and
results should be closer, than in a human-based evaluation, especially where
code and model checkpoints are made available by the original authors. As this
report of our efforts to rerun a metric-based evaluation of a set of
single-attribute and multiple-attribute controllable text generation (CTG)
techniques shows however, such reruns of evaluations do not always produce
results that are the same as the original results, and can reveal errors in the
reporting of the original work.

摘要：重新執行基於指標的評估應該更為直接，而且結果應該比在基於人為的評估中更接近，特別是在原始作者提供程式碼和模型檢查點的情況下。然而，正如我們重新執行一組單一屬性和多重屬性可控文本生成 (CTG) 技術的基於指標的評估的努力報告所示，此類重新執行的評估並非總是會產生與原始結果相同的结果，並且可能會揭露原始工作報告中的錯誤。

##### **RLHF Workflow: From Reward Modeling to Online RLHF**
2405.07863v1 by Hanze Dong, Wei Xiong, Bo Pang, Haoxiang Wang, Han Zhao, Yingbo Zhou, Nan Jiang, Doyen Sahoo, Caiming Xiong, Tong Zhang

We present the workflow of Online Iterative Reinforcement Learning from Human
Feedback (RLHF) in this technical report, which is widely reported to
outperform its offline counterpart by a large margin in the recent large
language model (LLM) literature. However, existing open-source RLHF projects
are still largely confined to the offline learning setting. In this technical
report, we aim to fill in this gap and provide a detailed recipe that is easy
to reproduce for online iterative RLHF. In particular, since online human
feedback is usually infeasible for open-source communities with limited
resources, we start by constructing preference models using a diverse set of
open-source datasets and use the constructed proxy preference model to
approximate human feedback. Then, we discuss the theoretical insights and
algorithmic principles behind online iterative RLHF, followed by a detailed
practical implementation. Our trained LLM, SFR-Iterative-DPO-LLaMA-3-8B-R,
achieves impressive performance on LLM chatbot benchmarks, including
AlpacaEval-2, Arena-Hard, and MT-Bench, as well as other academic benchmarks
such as HumanEval and TruthfulQA. We have shown that supervised fine-tuning
(SFT) and iterative RLHF can obtain state-of-the-art performance with fully
open-source datasets. Further, we have made our models, curated datasets, and
comprehensive step-by-step code guidebooks publicly available. Please refer to
https://github.com/RLHFlow/RLHF-Reward-Modeling and
https://github.com/RLHFlow/Online-RLHF for more detailed information.

摘要：<paragraph>我們在這份技術報告中介紹了人類回饋在線迭代強化學習 (RLHF) 的工作流程，據廣泛報導，它在最近的大語言模型 (LLM) 文獻中大幅優於其離線對應項。然而，現有的開源 RLHF 項目在很大程度上仍然局限於離線學習設置。在這份技術報告中，我們旨在填補這一空白，並提供一個易於複製的在線迭代 RLHF 的詳細配方。特別是，由於在線人類回饋通常對於資源有限的開源社區來說不可行，我們首先使用多樣化的開源數據集構建偏好模型，並使用構建的代理偏好模型來近似人類回饋。然後，我們討論在線迭代 RLHF 背後的理論見解和演算法原理，然後進行詳細的實際實作。我們訓練的 LLM，SFR-Iterative-DPO-LLaMA-3-8B-R，在 LLM 聊天機器人基準上取得了令人印象深刻的效能，包括 AlpacaEval-2、Arena-Hard 和 MT-Bench，以及其他學術基準，例如 HumanEval 和 TruthfulQA。我們已經證明，監督微調 (SFT) 和迭代 RLHF 可以使用完全開源數據集獲得最先進的效能。此外，我們已經公開了我們的模型、精選數據集和全面的逐步程式碼指南。有關更多詳細資訊，請參閱 https://github.com/RLHFlow/RLHF-Reward-Modeling 和 https://github.com/RLHFlow/Online-RLHF。</paragraph>

##### **Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM**
2405.07840v1 by Xiaoyu Chen, Changde Du, Che Liu, Yizhe Wang, Huiguang He

Decoding language information from brain signals represents a vital research
area within brain-computer interfaces, particularly in the context of
deciphering the semantic information from the fMRI signal. However, many
existing efforts concentrate on decoding small vocabulary sets, leaving space
for the exploration of open vocabulary continuous text decoding. In this paper,
we introduce a novel method, the \textbf{Brain Prompt GPT (BP-GPT)}. By using
the brain representation that is extracted from the fMRI as a prompt, our
method can utilize GPT-2 to decode fMRI signals into stimulus text. Further, we
introduce a text-to-text baseline and align the fMRI prompt to the text prompt.
By introducing the text-to-text baseline, our BP-GPT can extract a more robust
brain prompt and promote the decoding of pre-trained LLM. We evaluate our
BP-GPT on the open-source auditory semantic decoding dataset and achieve a
significant improvement up to $4.61\%$ on METEOR and $2.43\%$ on BERTScore
across all the subjects compared to the state-of-the-art method. The
experimental results demonstrate that using brain representation as a prompt to
further drive LLM for auditory neural decoding is feasible and effective.

摘要：從腦部訊號解碼語言資訊，在腦電腦介面中是一個重要的研究領域，特別是在從 fMRI 訊號中解碼語意資訊的脈絡中。然而，許多現有的努力都集中在解碼小型詞彙集上，這為探索開放式詞彙連續文字解碼留下了空間。在本文中，我們介紹了一種新方法，即 \textbf{腦提示 GPT (BP-GPT)}。透過使用從 fMRI 中提取的腦部表徵作為提示，我們的模型可以使用 GPT-2 將 fMRI 訊號解碼成刺激文字。此外，我們引入了一個文字對文字的基準，並將 fMRI 提示與文字提示對齊。透過引入文字對文字的基準，我們的 BP-GPT 可以提取更穩健的腦部提示，並促進預先訓練好的 LLM 的解碼。我們在開放原始碼聽覺語意解碼資料集上評估我們的 BP-GPT，並在 METEOR 上獲得高達 4.61%，在 BERTScore 上獲得 2.43% 的顯著改進，與最先進的方法相比，所有受試者都獲得了改進。實驗結果表明，使用腦部表徵作為提示，進一步驅動 LLM 進行聽覺神經解碼是可行且有效的。

##### **Synthetic Tabular Data Validation: A Divergence-Based Approach**
2405.07822v1 by Patricia A. Apellániz, Ana Jiménez, Borja Arroyo Galende, Juan Parras, Santiago Zazo

The ever-increasing use of generative models in various fields where tabular
data is used highlights the need for robust and standardized validation metrics
to assess the similarity between real and synthetic data. Current methods lack
a unified framework and rely on diverse and often inconclusive statistical
measures. Divergences, which quantify discrepancies between data distributions,
offer a promising avenue for validation. However, traditional approaches
calculate divergences independently for each feature due to the complexity of
joint distribution modeling. This paper addresses this challenge by proposing a
novel approach that uses divergence estimation to overcome the limitations of
marginal comparisons. Our core contribution lies in applying a divergence
estimator to build a validation metric considering the joint distribution of
real and synthetic data. We leverage a probabilistic classifier to approximate
the density ratio between datasets, allowing the capture of complex
relationships. We specifically calculate two divergences: the well-known
Kullback-Leibler (KL) divergence and the Jensen-Shannon (JS) divergence. KL
divergence offers an established use in the field, while JS divergence is
symmetric and bounded, providing a reliable metric. The efficacy of this
approach is demonstrated through a series of experiments with varying
distribution complexities. The initial phase involves comparing estimated
divergences with analytical solutions for simple distributions, setting a
benchmark for accuracy. Finally, we validate our method on a real-world dataset
and its corresponding synthetic counterpart, showcasing its effectiveness in
practical applications. This research offers a significant contribution with
applicability beyond tabular data and the potential to improve synthetic data
validation in various fields.

摘要：<paragraph>生成模型在使用表格資料的各種領域中日益增加的使用，突顯了對健全且標準化的驗證指標的需求，以評估真實資料和合成資料之間的相似性。目前的驗證方法缺乏統一的架構，並且依賴於多樣且經常沒有定論的統計量度。量化資料分佈差異的差異度，為驗證提供了一條有希望的途徑。然而，傳統的方法由於聯合分佈建模的複雜性，會針對每個特徵獨立計算差異度。本文透過提出一個新的方法來解決這個挑戰，該方法使用差異度估計來克服邊際比較法的限制。我們核心貢獻在於應用差異度估計器來建立一個驗證指標，考慮真實資料和合成資料的聯合分佈。我們利用機率分類器來近似資料集之間的密度比，從而捕捉複雜的關係。我們特別計算了兩個差異度：眾所周知的 Kullback-Leibler (KL) 差異度和 Jensen-Shannon (JS) 差異度。KL 差異度在該領域有既定的用途，而 JS 差異度對稱且有界，提供了一個可靠的指標。這個方法的效能透過一系列具有不同分佈複雜度的實驗得到證明。初始階段涉及將估計的差異度與簡單分佈的解析解進行比較，設定準確度的基準。最後，我們在一個真實世界資料集及其對應的合成對應物上驗證了我們的驗證方法，展示了其在實際應用中的效能。這項研究提供了一個重大的貢獻，其適用性不僅限於表格資料，並且有潛力改善各種領域中的合成資料驗證。</paragraph>

##### **Quick and Accurate Affordance Learning**
2405.07816v1 by Fedor Scholz, Erik Ayari, Johannes Bertram, Martin V. Butz

Infants learn actively in their environments, shaping their own learning
curricula. They learn about their environments' affordances, that is, how local
circumstances determine how their behavior can affect the environment. Here we
model this type of behavior by means of a deep learning architecture. The
architecture mediates between global cognitive map exploration and local
affordance learning. Inference processes actively move the simulated agent
towards regions where they expect affordance-related knowledge gain. We
contrast three measures of uncertainty to guide this exploration: predicted
uncertainty of a model, standard deviation between the means of several models
(SD), and the Jensen-Shannon Divergence (JSD) between several models. We show
that the first measure gets fooled by aleatoric uncertainty inherent in the
environment, while the two other measures focus learning on epistemic
uncertainty. JSD exhibits the most balanced exploration strategy. From a
computational perspective, our model suggests three key ingredients for
coordinating the active generation of learning curricula: (1) Navigation
behavior needs to be coordinated with local motor behavior for enabling active
affordance learning. (2) Affordances need to be encoded locally for acquiring
generalized knowledge. (3) Effective active affordance learning mechanisms
should use density comparison techniques for estimating expected knowledge
gain. Future work may seek collaborations with developmental psychology to
model active play in children in more realistic scenarios.

摘要：嬰兒積極地在他們的環境中學習，塑造他們自己的學習課程。他們了解他們環境的可能性，也就是說，當地環境如何決定他們的行為如何影響環境。在這裡，我們通過深度學習架構對這種行為類型進行建模。該架構在全局認知地圖探索和局部可能性學習之間進行調解。推理過程積極地將模擬代理移動到他們預期獲得可能性相關知識的地區。我們對不確定性的三個測量進行對比，以指導此探索：模型的預測不確定性、幾個模型的平均值之間的標準差 (SD) 以及幾個模型之間的 Jensen-Shannon 散度 (JSD)。我們表明，第一個測量被環境中固有的偶然不確定性所愚弄，而另外兩個測量則將學習重點放在認識論不確定性上。JSD 表現出最平衡的探索策略。從計算的角度來看，我們的模型提出了協調主動生成學習課程的三個關鍵要素：(1) 導航行為需要與局部運動行為協調，以實現主動可能性學習。(2) 可能性需要在局部編碼以獲取廣泛的知識。(3) 有效的積極可能性學習機制應使用密度比較技術來估計預期的知識收益。未來的研究可以尋求與發展心理學的合作，在更現實的場景中對兒童的積極遊戲進行建模。

##### **Decoding Geometric Properties in Non-Random Data from First Information-Theoretic Principles**
2405.07803v1 by Hector Zenil, Felipe S. Abrahão

Based on the principles of information theory, measure theory, and
theoretical computer science, we introduce a univariate signal deconvolution
method with a wide range of applications to coding theory, particularly in
zero-knowledge one-way communication channels, such as in deciphering messages
from unknown generating sources about which no prior knowledge is available and
to which no return message can be sent. Our multidimensional space
reconstruction method from an arbitrary received signal is proven to be
agnostic vis-a-vis the encoding-decoding scheme, computation model, programming
language, formal theory, the computable (or semi-computable) method of
approximation to algorithmic complexity, and any arbitrarily chosen
(computable) probability measure of the events. The method derives from the
principles of an approach to Artificial General Intelligence capable of
building a general-purpose model of models independent of any arbitrarily
assumed prior probability distribution. We argue that this optimal and
universal method of decoding non-random data has applications to signal
processing, causal deconvolution, topological and geometric properties
encoding, cryptography, and bio- and technosignature detection.

摘要：基於資訊理論、測度理論和理論電腦科學的原理，我們介紹了一種單變量信號反摺積方法，它在編碼理論中具有廣泛的應用，特別是在零知識單向通信通道中，例如在破譯來自未知生成源的訊息時，這些訊息沒有可用的先驗知識，並且無法發送回傳訊息。我們從任意接收信號中重建多維空間的方法被證明與編碼解碼方案、計算模型、程式語言、形式理論、演算法複雜度近似的可計算（或半可計算）方法，以及事件的任何任意選擇（可計算）機率測度無關。該方法源自人工通用智慧的一種方法的原理，該方法能夠建立一個通用模型模型，而與任何任意假設的先驗機率分佈無關。我們認為，這種最佳且通用的非隨機資料解碼方法在信號處理、因果反摺積、拓撲和幾何性質編碼、密碼學以及生物和技術特徵偵測中都有應用。

##### **FreeVA: Offline MLLM as Training-Free Video Assistant**
2405.07798v1 by Wenhao Wu

This paper undertakes an empirical study to revisit the latest advancements
in Multimodal Large Language Models (MLLMs): Video Assistant. This study,
namely FreeVA, aims to extend existing image-based MLLM to the video domain in
a training-free manner. The study provides an essential, yet must-know
baseline, and reveals several surprising findings: 1) FreeVA, leveraging only
offline image-based MLLM without additional training, excels in zero-shot video
question-answering (e.g., MSVD-QA, ActivityNet-QA, and MSRVTT-QA), even
surpassing state-of-the-art methods that involve video instruction tuning. 2)
While mainstream video-based MLLMs typically initialize with an image-based
MLLM (e.g., LLaVA) and then fine-tune using video instruction tuning, the study
indicates that utilizing the widely adopted VideoInstruct-100K for video
instruction tuning doesn't actually lead to better performance compared to not
training at all. 3) The commonly used evaluation metrics in existing works are
significantly influenced by changes in the GPT API version over time. If
ignored, this could affect the fairness and uniformity of comparisons between
different methods and impact the analysis and judgment of researchers in the
field. The advancement of MLLMs is currently thriving, drawing numerous
researchers into the field. We aim for this work to serve as a plug-and-play,
simple yet effective baseline, encouraging the direct evaluation of existing
MLLMs in video domain while also standardizing the field of video
conversational models to a certain extent. Also, we encourage researchers to
reconsider: Have current video MLLM methods truly acquired knowledge beyond
image MLLM? Code is available at https://github.com/whwu95/FreeVA

摘要：<paragraph>本文進行一項實證研究，以重新探討多模態大型語言模型 (MLLM) 中的最新進展：影片助理。本研究，即 FreeVA，旨在以無需訓練的方式將現有的基於影像的 MLLM 擴展到影片領域。本研究提供了一個必要的且必須知道的基準，並揭示了幾個令人驚訝的發現：1) FreeVA 僅利用離線的基於影像的 MLLM，而無需額外的訓練，就能在零次學習影片問答（例如 MSVD-QA、ActivityNet-QA 和 MSRVTT-QA）方面表現出色，甚至超越了涉及影片指令微調的現有方法。2) 儘管主流的基於影片的 MLLM 通常使用基於影像的 MLLM（例如 LLaVA）初始化，然後使用影片指令微調進行微調，但研究表明，使用廣泛採用的 VideoInstruct-100K 進行影片指令微調並未真正帶來比完全不進行訓練更好的效能。3) 現有研究中常用的評量指標會隨著時間推移而受到 GPT API 版本變更的顯著影響。如果忽略這一點，可能會影響不同方法之間比較時公平性和一致性，並影響該領域研究人員的分析和判斷。MLLM 的進展目前蓬勃發展，吸引了許多研究人員進入該領域。我們希望這項工作能作為一個即插即用、簡單但有效的基準，鼓勵直接評估影片領域中現有的 MLLM，同時也在一定程度上標準化影片對話模型的領域。此外，我們鼓勵研究人員重新考慮：目前的影片 MLLM 方法是否真正獲得了超越影像 MLLM 的知識？程式碼可在 https://github.com/whwu95/FreeVA 取得</paragraph>

##### **DEPTH: Discourse Education through Pre-Training Hierarchically**
2405.07788v1 by Zachary Bamberger, Ofek Glick, Chaim Baskin, Yonatan Belinkov

Language Models (LMs) often struggle with linguistic understanding at the
discourse level, even though discourse patterns such as coherence, cohesion,
and narrative flow are prevalent in their pre-training data. Current methods
address these challenges only after the pre-training phase, relying on
expensive human annotated data to align the model. To improve the discourse
capabilities of LMs already at the pre-training stage, we introduce DEPTH, an
encoder-decoder model that learns to represent sentences using a
discourse-oriented pre-training objective. DEPTH combines hierarchical sentence
representations with two objectives: (1) Sentence Un-Shuffling, and (2)
Span-Corruption. This approach trains the model to represent both
sub-word-level and sentence-level dependencies over a massive amount of
unstructured text. When trained either from scratch or continuing from a
pre-trained T5 checkpoint, DEPTH learns semantic and discourse-level
representations faster than T5, outperforming it in span-corruption loss
despite the additional sentence-un-shuffling objective. Evaluations on the
GLUE, DiscoEval, and NI benchmarks demonstrate DEPTH's ability to quickly learn
diverse downstream tasks, which require syntactic, semantic, and discourse
capabilities. Overall, our approach extends the discourse capabilities of T5,
while minimally impacting other natural language understanding (NLU)
capabilities in the resulting LM.

摘要：語言模型 (LM) 經常在語篇層級的語言理解上遇到困難，即使連貫性、凝聚力和敘事流等語篇模式在其預訓練資料中很普遍。目前的技術只在預訓練階段之後才處理這些挑戰，依賴昂貴的人工註解資料來調整模型。為了在預訓練階段就提升 LM 的語篇能力，我們引入了 DEPTH，一個編碼器-解碼器模型，它學習使用以語篇為導向的預訓練目標來表示句子。DEPTH 結合了分層句子表示法和兩個目標：(1) 句子取消混洗，以及 (2) 區間損毀。此方法訓練模型表示海量非結構化文字中的子字元層級和句子層級依賴性。當從頭開始訓練或從預訓練的 T5 檢查點繼續訓練時，DEPTH 會比 T5 更快地學習語義和語篇層級表示法，儘管有額外的句子取消混洗目標，但在區間損毀損失中表現優於 T5。在 GLUE、DiscoEval 和 NI 基準上的評估證明了 DEPTH 快速學習各種下游任務的能力，這些任務需要句法、語義和語篇能力。總體而言，我們的做法擴展了 T5 的語篇能力，同時將對最終 LM 中其他自然語言理解 (NLU) 能力的影響降至最低。

##### **A Comprehensive Analysis of Static Word Embeddings for Turkish**
2405.07778v1 by Karahan Sarıtaş, Cahid Arda Öz, Tunga Güngör

Word embeddings are fixed-length, dense and distributed word representations
that are used in natural language processing (NLP) applications. There are
basically two types of word embedding models which are non-contextual (static)
models and contextual models. The former method generates a single embedding
for a word regardless of its context, while the latter method produces distinct
embeddings for a word based on the specific contexts in which it appears. There
are plenty of works that compare contextual and non-contextual embedding models
within their respective groups in different languages. However, the number of
studies that compare the models in these two groups with each other is very few
and there is no such study in Turkish. This process necessitates converting
contextual embeddings into static embeddings. In this paper, we compare and
evaluate the performance of several contextual and non-contextual models in
both intrinsic and extrinsic evaluation settings for Turkish. We make a
fine-grained comparison by analyzing the syntactic and semantic capabilities of
the models separately. The results of the analyses provide insights about the
suitability of different embedding models in different types of NLP tasks. We
also build a Turkish word embedding repository comprising the embedding models
used in this work, which may serve as a valuable resource for researchers and
practitioners in the field of Turkish NLP. We make the word embeddings,
scripts, and evaluation datasets publicly available.

摘要：字詞嵌入是固定長度、密集且分散的字詞表示，用於自然語言處理 (NLP) 應用程式中。基本上有兩種字詞嵌入模型，分別是非語境 (靜態) 模型和語境模型。前一種方法為字詞產生單一嵌入，不論其語境為何，而後一種方法則根據字詞出現的特定語境為其產生不同的嵌入。有許多研究在不同語言中比較其各自群組中的語境和非語境嵌入模型。然而，比較這兩組中模型的研究數量非常少，而且沒有這類研究針對土耳其語。此程序需要將語境嵌入轉換成靜態嵌入。在本文中，我們比較並評估多種語境和非語境模型在土耳其語的內在和外在評估設定中的效能。我們透過個別分析模型的句法和語義能力，進行細微的比較。分析結果提供了見解，說明不同嵌入模型在不同類型的 NLP 任務中的適用性。我們還建置了一個土耳其語字詞嵌入儲存庫，包含此研究中使用的嵌入模型，這可能成為土耳其語 NLP 領域的研究人員和實務工作者的寶貴資源。我們公開提供字詞嵌入、指令碼和評估資料集。

##### **Human-Modeling in Sequential Decision-Making: An Analysis through the Lens of Human-Aware AI**
2405.07773v1 by Silvia Tulli, Stylianos Loukas Vasileiou, Sarath Sreedharan

"Human-aware" has become a popular keyword used to describe a particular
class of AI systems that are designed to work and interact with humans. While
there exists a surprising level of consistency among the works that use the
label human-aware, the term itself mostly remains poorly understood. In this
work, we retroactively try to provide an account of what constitutes a
human-aware AI system. We see that human-aware AI is a design-oriented
paradigm, one that focuses on the need for modeling the humans it may interact
with. Additionally, we see that this paradigm offers us intuitive dimensions to
understand and categorize the kinds of interactions these systems might have
with humans. We show the pedagogical value of these dimensions by using them as
a tool to understand and review the current landscape of work related to
human-AI systems that purport some form of human modeling. To fit the scope of
a workshop paper, we specifically narrowed our review to papers that deal with
sequential decision-making and were published in a major AI conference in the
last three years. Our analysis helps identify the space of potential research
problems that are currently being overlooked. We perform additional analysis on
the degree to which these works make explicit reference to results from social
science and whether they actually perform user-studies to validate their
systems. We also provide an accounting of the various AI methods used by these
works.

摘要：「以人为本」已成为用来描述特定类别 AI 系统的一个流行关键字，这类系统旨在与人类互动并为人类服务。虽然使用「以人为本」标签的作品之间存在令人惊讶的一致性，但这个术语本身仍然大多让人难以理解。在这项工作中，我们尝试追溯性地提供一个以人为本 AI 系统的构成说明。我们认为，以人为本 AI 是一种以设计为导向的范例，它着重于对可能与其互动的用户进行建模。此外，我们认为这个范例为我们提供了直观的维度，以便理解和分类这些系统可能与人类进行的互动类型。我们通过将这些维度用作工具来理解和检视与宣称某种形式的人类建模相关的人机系统工作的当前概况，展示了这些维度的教学价值。为了符合研讨会论文的范围，我们特别将我们的检视范围缩小到处理顺序决策制定且在过去三年内发表在主要 AI 会议中的论文。我们的分析有助于识别目前被忽视的潜在研究问题空间。我们对这些作品明确参考社会科学结果的程度以及他们是否实际执行用户研究来验证其系统进行了额外的分析。我们还对这些作品使用的各种 AI 方法进行了说明。

##### **Synthetic Test Collections for Retrieval Evaluation**
2405.07767v1 by Hossein A. Rahmani, Nick Craswell, Emine Yilmaz, Bhaskar Mitra, Daniel Campos

Test collections play a vital role in evaluation of information retrieval
(IR) systems. Obtaining a diverse set of user queries for test collection
construction can be challenging, and acquiring relevance judgments, which
indicate the appropriateness of retrieved documents to a query, is often costly
and resource-intensive. Generating synthetic datasets using Large Language
Models (LLMs) has recently gained significant attention in various
applications. In IR, while previous work exploited the capabilities of LLMs to
generate synthetic queries or documents to augment training data and improve
the performance of ranking models, using LLMs for constructing synthetic test
collections is relatively unexplored. Previous studies demonstrate that LLMs
have the potential to generate synthetic relevance judgments for use in the
evaluation of IR systems. In this paper, we comprehensively investigate whether
it is possible to use LLMs to construct fully synthetic test collections by
generating not only synthetic judgments but also synthetic queries. In
particular, we analyse whether it is possible to construct reliable synthetic
test collections and the potential risks of bias such test collections may
exhibit towards LLM-based models. Our experiments indicate that using LLMs it
is possible to construct synthetic test collections that can reliably be used
for retrieval evaluation.

摘要：測試集合在資訊檢索 (IR) 系統的評估中扮演著至關重要的角色。取得多元的使用者查詢以建立測試集合可能具有挑戰性，而取得相關性判斷（表示檢索文件對查詢的適切性）通常成本高且耗費資源。使用大型語言模型 (LLM) 產生合成資料集最近在各種應用程式中獲得大量的關注。在 IR 中，雖然先前的研究利用 LLM 的功能產生合成查詢或文件以擴充訓練資料並改善排名模型的效能，但使用 LLM 建立合成測試集合的領域相對尚未探索。先前的研究證實 LLM 具備產生合成相關性判斷的潛力，可供 IR 系統評估使用。在本文中，我們全面探討是否可能使用 LLM 建立完全合成的測試集合，方法是產生合成判斷和合成查詢。特別是，我們分析是否可能建立可靠的合成測試集合，以及此類測試集合可能對基於 LLM 的模型產生的潛在偏差風險。我們的實驗顯示，使用 LLM 可以建立合成測試集合，這些集合可被可靠地用於檢索評估。

##### **Challenges and Opportunities of NLP for HR Applications: A Discussion Paper**
2405.07766v1 by Jochen L. Leidner, Mark Stevenson

Over the course of the recent decade, tremendous progress has been made in
the areas of machine learning and natural language processing, which opened up
vast areas of potential application use cases, including hiring and human
resource management. We review the use cases for text analytics in the realm of
human resources/personnel management, including actually realized as well as
potential but not yet implemented ones, and we analyze the opportunities and
risks of these.

摘要：在最近十年中，机器学习和自然语言处理领域取得了长足的进步，这开辟了大量潜在的应用用例，包括招聘和人力资源管理。我们回顾了文本分析在人力资源/人员管理领域的用例，包括实际实现的用例和尚未实现的潜在用例，并分析了这些用例的机会和风险。

##### **TANQ: An open domain dataset of table answered questions**
2405.07765v1 by Mubashara Akhtar, Chenxi Pang, Andreea Marzoca, Yasemin Altun, Julian Martin Eisenschlos

Language models, potentially augmented with tool usage such as retrieval are
becoming the go-to means of answering questions. Understanding and answering
questions in real-world settings often requires retrieving information from
different sources, processing and aggregating data to extract insights, and
presenting complex findings in form of structured artifacts such as novel
tables, charts, or infographics. In this paper, we introduce TANQ, the first
open domain question answering dataset where the answers require building
tables from information across multiple sources. We release the full source
attribution for every cell in the resulting table and benchmark
state-of-the-art language models in open, oracle, and closed book setups. Our
best-performing baseline, GPT4 reaches an overall F1 score of 29.1, lagging
behind human performance by 19.7 points. We analyse baselines' performance
across different dataset attributes such as different skills required for this
task, including multi-hop reasoning, math operations, and unit conversions. We
further discuss common failures in model-generated answers, suggesting that
TANQ is a complex task with many challenges ahead.

摘要：語言模型，潛在的增強工具使用，例如檢索，正成為回答問題的途徑。在現實世界中理解和回答問題通常需要從不同來源檢索資訊、處理和彙整資料以萃取見解，並以結構化人工製品的形式呈現複雜的發現，例如新穎的表格、圖表或資訊圖表。在本文中，我們介紹 TANQ，這是第一個開放領域問題解答資料集，其中答案需要從多個來源的資訊建立表格。我們釋出結果表格中每個儲存格的完整來源歸屬，並在開放、神諭和閉卷設定中對最先進的語言模型進行基準測試。我們效能最好的基準，GPT4 達到 29.1 的 F1 總分，落後人類表現 19.7 分。我們分析基準在不同資料集屬性中的表現，例如此任務所需的各種技能，包括多重跳躍推理、數學運算和單位換算。我們進一步討論模型生成的答案中常見的失敗，表明 TANQ 是一個複雜的任務，未來還有許多挑戰。

##### **LLM4ED: Large Language Models for Automatic Equation Discovery**
2405.07761v1 by Mengge Du, Yuntian Chen, Zhongzheng Wang, Longfeng Nie, Dongxiao Zhang

Equation discovery is aimed at directly extracting physical laws from data
and has emerged as a pivotal research domain. Previous methods based on
symbolic mathematics have achieved substantial advancements, but often require
the design of implementation of complex algorithms. In this paper, we introduce
a new framework that utilizes natural language-based prompts to guide large
language models (LLMs) in automatically mining governing equations from data.
Specifically, we first utilize the generation capability of LLMs to generate
diverse equations in string form, and then evaluate the generated equations
based on observations. In the optimization phase, we propose two alternately
iterated strategies to optimize generated equations collaboratively. The first
strategy is to take LLMs as a black-box optimizer and achieve equation
self-improvement based on historical samples and their performance. The second
strategy is to instruct LLMs to perform evolutionary operators for global
search. Experiments are extensively conducted on both partial differential
equations and ordinary differential equations. Results demonstrate that our
framework can discover effective equations to reveal the underlying physical
laws under various nonlinear dynamic systems. Further comparisons are made with
state-of-the-art models, demonstrating good stability and usability. Our
framework substantially lowers the barriers to learning and applying equation
discovery techniques, demonstrating the application potential of LLMs in the
field of knowledge discovery.

摘要：方程式發現旨在直接從資料中萃取物理定律，並已成為一個重要的研究領域。先前基於符號數學的方法已取得重大進展，但通常需要設計實作複雜的演算法。在本文中，我們介紹一個新的架構，利用基於自然語言的提示來引導大型語言模型 (LLM) 從資料中自動探勘控制方程式。具體來說，我們首先利用 LLM 的生成能力以字串形式生成各種方程式，然後根據觀察結果評估生成的方程式。在最佳化階段，我們提出兩個交替迭代的策略來協同最佳化生成的方程式。第一個策略是將 LLM 視為一個黑盒最佳化器，並根據歷史樣本及其效能來達成方程式的自我改善。第二個策略是指示 LLM 對全球搜尋執行演化運算子。我們在偏微分方程式和常微分方程式上廣泛進行實驗。結果表明，我們的架構可以在各種非線性動態系統下發現有效的方程式來揭示底層物理定律。進一步與最先進的模型進行比較，證明了良好的穩定性和可用性。我們的架構大幅降低了學習和應用方程式發現技術的門檻，證明了 LLM 在知識發現領域的應用潛力。

##### **MADRL-Based Rate Adaptation for 360$\degree$ Video Streaming with Multi-Viewpoint Prediction**
2405.07759v1 by Haopeng Wang, Zijian Long, Haiwei Dong, Abdulmotaleb El Saddik

Over the last few years, 360$\degree$ video traffic on the network has grown
significantly. A key challenge of 360$\degree$ video playback is ensuring a
high quality of experience (QoE) with limited network bandwidth. Currently,
most studies focus on tile-based adaptive bitrate (ABR) streaming based on
single viewport prediction to reduce bandwidth consumption. However, the
performance of models for single-viewpoint prediction is severely limited by
the inherent uncertainty in head movement, which can not cope with the sudden
movement of users very well. This paper first presents a multimodal
spatial-temporal attention transformer to generate multiple viewpoint
trajectories with their probabilities given a historical trajectory. The
proposed method models viewpoint prediction as a classification problem and
uses attention mechanisms to capture the spatial and temporal characteristics
of input video frames and viewpoint trajectories for multi-viewpoint
prediction. After that, a multi-agent deep reinforcement learning (MADRL)-based
ABR algorithm utilizing multi-viewpoint prediction for 360$\degree$ video
streaming is proposed for maximizing different QoE objectives under various
network conditions. We formulate the ABR problem as a decentralized partially
observable Markov decision process (Dec-POMDP) problem and present a MAPPO
algorithm based on centralized training and decentralized execution (CTDE)
framework to solve the problem. The experimental results show that our proposed
method improves the defined QoE metric by up to 85.5\% compared to existing ABR
methods.

摘要：<paragraph>在過去幾年，網路上的 360 度影片流量大幅成長。360 度影片播放的一大挑戰在於，如何以有限的網路頻寬確保高品質的體驗 (QoE)。目前，大多數研究都專注於基於單一視點預測的磁磚式自適應位元率 (ABR) 串流，以減少頻寬消耗。然而，單一視點預測模型的效能受到頭部移動的內在不確定性嚴重限制，無法很好地應對使用者的突然移動。本文首先提出一個多模態時空注意力變換器，以產生多個視點軌跡及其在給定歷史軌跡下的機率。所提出的方法將視點預測建模為一個分類問題，並使用注意力機制來擷取輸入影片幀和視點軌跡的多視點預測的時空特徵。接著，提出一個基於多主體深度強化學習 (MADRL) 的 ABR 演算法，使用多視點預測進行 360 度影片串流，以在各種網路條件下最大化不同的 QoE 目標。我們將 ABR 問題公式化為一個分散式部分可觀察馬可夫決策過程 (Dec-POMDP) 問題，並提出一個基於集中訓練和分散執行 (CTDE) 架構的 MAPPO 演算法來解決問題。實驗結果顯示，與現有的 ABR 方法相比，我們提出的方法將定義的 QoE 指標提升了 85.5%。</paragraph>

##### **Mitigating federated learning contribution allocation instability through randomized aggregation**
2405.08044v1 by Arno Geimer, Beltran Fiz, Radu State

Federated learning (FL) is a novel collaborative machine learning framework
designed to preserve privacy while enabling the creation of robust models. This
paradigm addresses a growing need for data security by allowing multiple
participants to contribute to a model without exposing their individual
datasets. A pivotal issue within this framework, however, concerns the fair and
accurate attribution of contributions from various participants to the creation
of the joint global model. Incorrect contribution distribution can erode trust
among participants, result in inequitable compensation, and ultimately diminish
the willingness of parties to engage or actively contribute to the federation.
While several methods for remunerating participants have been proposed, little
attention was given to the analysis of the stability of these methods when
evaluating contributions, which is critical to ensure the long-term viability
and fairness of FL systems. In this paper, we analyse this stability through
the calculation of contributions by gradient-based model reconstruction
techniques with Shapley values. Our investigation reveals that Shapley values
fail to reflect baseline contributions, especially when employing different
aggregation techniques. To address this issue, we extend on established
aggregation techniques by introducing FedRandom, which is designed to sample
contributions in a more equitable and distributed manner. We demonstrate that
this approach not only serves as a viable aggregation technique but also
significantly improves the accuracy of contribution assessment compared to
traditional methods. Our results suggest that FedRandom enhances the overall
fairness and stability of the federated learning system, making it a superior
choice for federations with limited number of participants.

摘要：聯邦學習 (FL) 是一種新穎的協作機器學習架構，旨在保護隱私，同時促進建立強大的模型。這種範例透過允許多個參與者在不公開其個別資料集的情況下為模型做出貢獻，來滿足日益增長的需求，以確保資料安全。然而，此架構中的關鍵問題涉及公平且準確地將來自不同參與者的貢獻歸因於建立聯合全球模型。不正確的貢獻分配會侵蝕參與者之間的信任，導致不公平的補償，並最終降低各方參與或積極貢獻聯邦的意願。儘管已經提出幾種酬勞參與者的方法，但在評估貢獻時，很少關注這些方法的穩定性分析，這對於確保 FL 系統的長期可行性和公平性至關重要。在本文中，我們透過使用 Shapley 值的基於梯度的模型重建技術計算貢獻，來分析這種穩定性。我們的調查顯示，Shapley 值無法反映基準貢獻，特別是在採用不同的聚合技術時。為了解決此問題，我們透過引入 FedRandom 來擴充既定的聚合技術，FedRandom 旨在以更公平且分散的方式抽取貢獻。我們證明，這種方法不僅作為一種可行的聚合技術，而且與傳統方法相比，還能顯著提高貢獻評估的準確性。我們的結果表明，FedRandom 提高了聯邦學習系統的整體公平性和穩定性，使其成為參與者數量有限的聯邦的更佳選擇。

##### **LlamaTurk: Adapting Open-Source Generative Large Language Models for Low-Resource Language**
2405.07745v1 by Cagri Toraman

Despite advancements in English-dominant generative large language models,
further development is needed for low-resource languages to enhance global
accessibility. The primary methods for representing these languages are
monolingual and multilingual pretraining. Monolingual pretraining is expensive
due to hardware requirements, and multilingual models often have uneven
performance across languages. This study explores an alternative solution by
adapting large language models, primarily trained on English, to low-resource
languages. We assess various strategies, including continual training,
instruction fine-tuning, task-specific fine-tuning, and vocabulary extension.
The results show that continual training improves language comprehension, as
reflected in perplexity scores, and task-specific tuning generally enhances
performance of downstream tasks. However, extending the vocabulary shows no
substantial benefits. Additionally, while larger models improve task
performance with few-shot tuning, multilingual models perform worse than their
monolingual counterparts when adapted.

摘要：儘管以英語為主的生成式大型語言模型有進展，但仍需要進一步開發低資源語言，以增強全球可及性。表示這些語言的主要方法是單語和多語預訓練。單語預訓練由於硬體需求而昂貴，而多語模型在不同語言中的表現往往不均。本研究探討了一種替代解決方案，即將主要以英語訓練的大型語言模型適應到低資源語言。我們評估了各種策略，包括持續訓練、指令微調、特定任務微調和詞彙擴充。結果表明，持續訓練改善了語言理解，這反映在困惑度分數中，而特定任務微調通常會增強下游任務的性能。然而，擴展詞彙並未顯示出實質性好處。此外，儘管較大的模型通過少量調整改進了任務性能，但多語模型在適應時表現不如單語模型。

##### **Federated Hierarchical Tensor Networks: a Collaborative Learning Quantum AI-Driven Framework for Healthcare**
2405.07735v1 by Amandeep Singh Bhatia, David E. Bernal Neira

Healthcare industries frequently handle sensitive and proprietary data, and
due to strict privacy regulations, they are often reluctant to share data
directly. In today's context, Federated Learning (FL) stands out as a crucial
remedy, facilitating the rapid advancement of distributed machine learning
while effectively managing critical concerns regarding data privacy and
governance. The fusion of federated learning and quantum computing represents a
groundbreaking interdisciplinary approach with immense potential to
revolutionize various industries, from healthcare to finance. In this work, we
proposed a federated learning framework based on quantum tensor networks, which
leverages the principles of many-body quantum physics. Currently, there are no
known classical tensor networks implemented in federated settings. Furthermore,
we investigated the effectiveness and feasibility of the proposed framework by
conducting a differential privacy analysis to ensure the security of sensitive
data across healthcare institutions. Experiments on popular medical image
datasets show that the federated quantum tensor network model achieved a mean
receiver-operator characteristic area under the curve (ROC-AUC) between
0.91-0.98. Experimental results demonstrate that the quantum federated global
model, consisting of highly entangled tensor network structures, showed better
generalization and robustness and achieved higher testing accuracy, surpassing
the performance of locally trained clients under unbalanced data distributions
among healthcare institutions.

摘要：醫療產業經常處理敏感且專有的資料，且由於嚴格的隱私法規，他們通常不願意直接分享資料。在今日的脈絡中，聯邦學習 (FL) 成為一項重要的解決方案，促進分布式機器學習的快速進展，同時有效管理有關資料隱私和治理的關鍵問題。聯邦學習與量子運算的融合代表了一種創新的跨領域方法，具有巨大的潛力，可以革新從醫療保健到金融的各種產業。在這項工作中，我們提出了一個基於量子張量網路的聯邦學習框架，它利用了多體量子物理的原理。目前，在聯邦設置中沒有已知的經典張量網路實作。此外，我們透過進行差異化隱私分析來調查所提出框架的有效性和可行性，以確保醫療機構中敏感資料的安全性。在流行的醫學影像資料集上的實驗顯示，聯邦量子張量網路模型在曲線下方的平均接收器操作者特性面積 (ROC-AUC) 達到 0.91-0.98。實驗結果表明，由高度糾纏的張量網路結構組成的量子聯邦全局模型顯示出更好的泛化性和穩健性，並達到了更高的測試準確度，超越了在醫療機構之間資料分佈不平衡的情況下，由本地訓練的用戶端效能。

##### **Quantifying and Optimizing Global Faithfulness in Persona-driven Role-playing**
2405.07726v1 by Letian Peng, Jingbo Shang

Persona-driven role-playing (PRP) aims to build AI characters that can
respond to user queries by faithfully sticking with all persona statements.
Unfortunately, existing faithfulness criteria for PRP are limited to
coarse-grained LLM-based scoring without a clear definition or formulation.
This paper presents a pioneering exploration to quantify PRP faithfulness as a
fine-grained and explainable criterion, which also serves as a reliable
reference for optimization. Our criterion first discriminates persona
statements into active and passive constraints by identifying the
query-statement relevance. Then, we incorporate all constraints following the
principle that the AI character's response should be (a) entailed by active
(relevant) constraints and (b) not contradicted by passive (irrelevant)
constraints. We translate this principle mathematically into a novel
Active-Passive-Constraint (APC) score, a constraint-wise sum of natural
language inference (NLI) scores weighted by relevance scores. In practice, we
build the APC scoring system by symbolically distilling small discriminators
from GPT-4 for efficiency. We validate the quality of the APC score against
human evaluation based on example personas with tens of statements, and the
results show a high correlation. We further leverage it as a reward system in
direct preference optimization (DPO) for better AI characters. Our experiments
offer a fine-grained and explainable comparison between existing PRP
techniques, revealing their advantages and limitations. We further find
APC-based DPO to be one of the most competitive techniques for sticking with
all constraints and can be well incorporated with other techniques. We then
extend the scale of the experiments to real persons with hundreds of statements
and reach a consistent conclusion.

摘要：以角色為導向的角色扮演 (PRP) 旨在建立 AI 角色，這些角色可以透過忠實遵守所有角色陳述來回應使用者的查詢。不幸的是，現有的 PRP 保真度準則僅限於粗略的 LLM 基礎評分，而沒有明確的定義或表述。本文提出了一項開創性的探索，將 PRP 保真度量化為細緻且可解釋的準則，這也作為最佳化的可靠參考。我們的準則首先透過識別查詢陳述相關性，將角色陳述區分為主動和被動約束。然後，我們根據以下原則納入所有約束：AI 角色的回應應 (a) 由主動 (相關) 約束所暗示，且 (b) 不與被動 (無關) 約束相矛盾。我們將此原則數學轉換為新穎的主動被動約束 (APC) 分數，這是自然語言推論 (NLI) 分數的約束加權總和，由相關性分數加權。在實務上，我們透過從 GPT-4 中象徵性地提取小型區分器來建立 APC 評分系統以提高效率。我們根據包含數十個陳述的範例角色對 APC 分數的品質進行驗證，而結果顯示出高度相關性。我們進一步將其作為直接偏好最佳化 (DPO) 中的獎勵系統，以獲得更好的 AI 角色。我們的實驗提供了現有 PRP 技術之間細緻且可解釋的比較，揭示了它們的優點和限制。我們進一步發現基於 APC 的 DPO 是最具競爭力的技術之一，可以堅持所有約束，並且可以很好地與其他技術結合。然後，我們將實驗的規模擴展到擁有數百個陳述的真人，並得出了一個一致的結論。

##### **A Unified Sequence Parallelism Approach for Long Context Generative AI**
2405.07719v3 by Jiarui Fang, Shangchun Zhao

Sequence parallelism (SP), which divides the sequence dimension of input
tensors across multiple computational devices, is becoming key to unlocking the
long-context capabilities of generative AI models. This paper investigates the
state-of-the-art SP approaches, i.e. DeepSpeed-Ulysses and Ring-Attention, and
proposes a unified SP approach, which is more robust to transformer model
architectures and network hardware topology. This paper compares the
communication and memory cost of SP and existing parallelism, including
data/tensor/zero/expert/pipeline parallelism, and discusses the best practices
for designing hybrid 4D parallelism involving SP. We achieved 86% MFU on two
8xA800 nodes using SP for sequence length 208K for the LLAMA3-8B model. Our
code is publicly available on
\url{https://github.com/feifeibear/long-context-attention}.

摘要：序列平行（SP）將輸入張量的序列維度劃分到多個計算裝置中，正成為解鎖生成式 AI 模型長內容功能的關鍵。本文探討了最先進的 SP 方法，即 DeepSpeed-Ulysses 和 Ring-Attention，並提出了一個統一的 SP 方法，該方法對Transformer模型架構和網路硬體拓撲更具魯棒性。本文比較了 SP 和現有並行處理的通訊和記憶體成本，包括資料/張量/零/專家/管線並行處理，並討論了涉及 SP 的混合 4D 並行處理的最佳實務。我們使用 SP 為 LLAMA3-8B 模型的序列長度 208K 在兩個 8xA800 節點上達到了 86% 的 MFU。我們的程式碼已公開在
\url{https://github.com/feifeibear/long-context-attention}。

##### **OpenLLM-Ro -- Technical Report on Open-source Romanian LLMs trained starting from Llama 2**
2405.07703v3 by Mihai Masala, Denis C. Ilie-Ablachim, Dragos Corlatescu, Miruna Zavelca, Marius Leordeanu, Horia Velicu, Marius Popescu, Mihai Dascalu, Traian Rebedea

In recent years, Large Language Models (LLMs) have achieved almost human-like
performance on various tasks. While some LLMs have been trained on multilingual
data, most of the training data is in English. Hence, their performance in
English greatly exceeds their performance in other languages. This document
presents our approach to training and evaluating the first foundational and
chat LLM specialized for Romanian.

摘要：近年來，大型語言模型 (LLM) 在各種任務上達到了接近人類的表現。雖然有些 LLM 已接受多國語言資料的訓練，但大多數訓練資料都是英文。因此，它們在英文的表現遠遠優於其他語言。本文檔介紹我們訓練和評估第一個針對羅馬尼亞語的基礎和聊天 LLM 的方法。

