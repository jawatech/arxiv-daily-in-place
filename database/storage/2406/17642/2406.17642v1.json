{"2406.17642": {"publish_time": "2024-06-25", "title": "Banishing LLM Hallucinations Requires Rethinking Generalization", "paper_summary": "Despite their powerful chat, coding, and reasoning abilities, Large Language\nModels (LLMs) frequently hallucinate. Conventional wisdom suggests that\nhallucinations are a consequence of a balance between creativity and\nfactuality, which can be mitigated, but not eliminated, by grounding the LLM in\nexternal knowledge sources. Through extensive systematic experiments, we show\nthat these traditional approaches fail to explain why LLMs hallucinate in\npractice. Specifically, we show that LLMs augmented with a massive Mixture of\nMemory Experts (MoME) can easily memorize large datasets of random numbers. We\ncorroborate these experimental findings with a theoretical construction showing\nthat simple neural networks trained to predict the next token hallucinate when\nthe training loss is above a threshold as it usually does in practice when\ntraining on internet scale data. We interpret our findings by comparing against\ntraditional retrieval methods for mitigating hallucinations. We use our\nfindings to design a first generation model for removing hallucinations --\nLamini-1 -- that stores facts in a massive mixture of millions of memory\nexperts that are retrieved dynamically.", "paper_summary_zh": "\u5118\u7ba1\u64c1\u6709\u5f37\u5927\u7684\u804a\u5929\u3001\u7de8\u78bc\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7d93\u5e38\u6703\u51fa\u73fe\u5e7b\u89ba\u3002\u50b3\u7d71\u667a\u6167\u8a8d\u70ba\u5e7b\u89ba\u662f\u5275\u9020\u529b\u548c\u4e8b\u5be6\u6027\u4e4b\u9593\u5e73\u8861\u7684\u7d50\u679c\uff0c\u9019\u7a2e\u5e73\u8861\u53ef\u4ee5\u900f\u904e\u5c07 LLM \u57fa\u65bc\u5916\u90e8\u77e5\u8b58\u4f86\u6e90\u4f86\u6e1b\u8f15\uff0c\u4f46\u7121\u6cd5\u6d88\u9664\u3002\u900f\u904e\u5ee3\u6cdb\u7684\u7cfb\u7d71\u6027\u5be6\u9a57\uff0c\u6211\u5011\u8b49\u660e\u9019\u4e9b\u50b3\u7d71\u65b9\u6cd5\u7121\u6cd5\u89e3\u91cb\u70ba\u4ec0\u9ebc LLM \u5728\u5be6\u52d9\u4e2d\u6703\u51fa\u73fe\u5e7b\u89ba\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u8b49\u660e\u4e86\u900f\u904e\u5927\u91cf\u8a18\u61b6\u5c08\u5bb6\u6df7\u5408 (MoME) \u589e\u5f37\u7684 LLM \u53ef\u4ee5\u8f15\u9b06\u8a18\u4f4f\u5927\u91cf\u96a8\u6a5f\u6578\u5b57\u7684\u8cc7\u6599\u96c6\u3002\u6211\u5011\u7528\u4e00\u500b\u7406\u8ad6\u5efa\u69cb\u4f86\u8b49\u5be6\u9019\u4e9b\u5be6\u9a57\u767c\u73fe\uff0c\u8b49\u660e\u8a13\u7df4\u4f86\u9810\u6e2c\u4e0b\u4e00\u500b\u6a19\u8a18\u7684\u7c21\u55ae\u795e\u7d93\u7db2\u8def\u6703\u5728\u8a13\u7df4\u640d\u5931\u9ad8\u65bc\u95be\u503c\u6642\u51fa\u73fe\u5e7b\u89ba\uff0c\u9019\u901a\u5e38\u6703\u5728\u8a13\u7df4\u7db2\u8def\u898f\u6a21\u8cc7\u6599\u6642\u767c\u751f\u3002\u6211\u5011\u900f\u904e\u8207\u50b3\u7d71\u7684\u64f7\u53d6\u65b9\u6cd5\u9032\u884c\u6bd4\u8f03\u4f86\u8a6e\u91cb\u6211\u5011\u7684\u767c\u73fe\uff0c\u4ee5\u6e1b\u8f15\u5e7b\u89ba\u3002\u6211\u5011\u5229\u7528\u6211\u5011\u7684\u767c\u73fe\u8a2d\u8a08\u4e86\u4e00\u500b\u7b2c\u4e00\u4ee3\u6a21\u578b\u4f86\u79fb\u9664\u5e7b\u89ba -- Lamini-1 -- \u5b83\u6703\u5c07\u4e8b\u5be6\u5132\u5b58\u5728\u6578\u767e\u842c\u500b\u8a18\u61b6\u5c08\u5bb6\u7684\u9f90\u5927\u6df7\u5408\u4e2d\uff0c\u4e26\u6703\u52d5\u614b\u64f7\u53d6\u9019\u4e9b\u4e8b\u5be6\u3002", "author": "Johnny Li et.al.", "authors": "Johnny Li, Saksham Consul, Eda Zhou, James Wong, Naila Farooqui, Yuxin Ye, Nithyashree Manohar, Zhuxiaona Wei, Tian Wu, Ben Echols, Sharon Zhou, Gregory Diamos", "id": "2406.17642v1", "paper_url": "http://arxiv.org/abs/2406.17642v1", "repo": "null"}}