{"2406.03070": {"publish_time": "2024-06-05", "title": "A-Bench: Are LMMs Masters at Evaluating AI-generated Images?", "paper_summary": "How to accurately and efficiently assess AI-generated images (AIGIs) remains\na critical challenge for generative models. Given the high costs and extensive\ntime commitments required for user studies, many researchers have turned\ntowards employing large multi-modal models (LMMs) as AIGI evaluators, the\nprecision and validity of which are still questionable. Furthermore,\ntraditional benchmarks often utilize mostly natural-captured content rather\nthan AIGIs to test the abilities of LMMs, leading to a noticeable gap for\nAIGIs. Therefore, we introduce A-Bench in this paper, a benchmark designed to\ndiagnose whether LMMs are masters at evaluating AIGIs. Specifically, A-Bench is\norganized under two key principles: 1) Emphasizing both high-level semantic\nunderstanding and low-level visual quality perception to address the intricate\ndemands of AIGIs. 2) Various generative models are utilized for AIGI creation,\nand various LMMs are employed for evaluation, which ensures a comprehensive\nvalidation scope. Ultimately, 2,864 AIGIs from 16 text-to-image models are\nsampled, each paired with question-answers annotated by human experts, and\ntested across 18 leading LMMs. We hope that A-Bench will significantly enhance\nthe evaluation process and promote the generation quality for AIGIs. The\nbenchmark is available at https://github.com/Q-Future/A-Bench.", "paper_summary_zh": "\u5982\u4f55\u6e96\u78ba\u6709\u6548\u5730\u8a55\u4f30 AI \u751f\u6210\u7684\u5716\u50cf (AIGI) \u4ecd\u7136\u662f\u751f\u6210\u6a21\u578b\u7684\u4e00\u9805\u91cd\u5927\u6311\u6230\u3002\u9451\u65bc\u4f7f\u7528\u8005\u7814\u7a76\u9700\u8981\u9ad8\u6210\u672c\u548c\u5927\u91cf\u6642\u9593\u627f\u8afe\uff0c\u8a31\u591a\u7814\u7a76\u4eba\u54e1\u5df2\u8f49\u5411\u63a1\u7528\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b (LMM) \u4f5c\u70ba AIGI \u8a55\u4f30\u5668\uff0c\u5176\u6e96\u78ba\u6027\u548c\u6709\u6548\u6027\u4ecd\u6709\u5f85\u5546\u69b7\u3002\u6b64\u5916\uff0c\u50b3\u7d71\u57fa\u6e96\u901a\u5e38\u4e3b\u8981\u5229\u7528\u81ea\u7136\u64f7\u53d6\u7684\u5167\u5bb9\uff0c\u800c\u975e AIGI \u4f86\u6e2c\u8a66 LMM \u7684\u80fd\u529b\uff0c\u5c0e\u81f4 AIGI \u51fa\u73fe\u986f\u8457\u7684\u5dee\u8ddd\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5728\u672c\u6587\u4e2d\u4ecb\u7d39 A-Bench\uff0c\u9019\u662f\u4e00\u500b\u57fa\u6e96\uff0c\u65e8\u5728\u8a3a\u65b7 LMM \u662f\u5426\u662f\u8a55\u4f30 AIGI \u7684\u5c08\u5bb6\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cA-Bench \u662f\u6839\u64da\u5169\u500b\u95dc\u9375\u539f\u5247\u7d44\u7e54\u7684\uff1a1) \u5f37\u8abf\u9ad8\u968e\u8a9e\u7fa9\u7406\u89e3\u548c\u4f4e\u968e\u8996\u89ba\u54c1\u8cea\u611f\u77e5\uff0c\u4ee5\u6eff\u8db3 AIGI \u7684\u8907\u96dc\u9700\u6c42\u30022) \u63a1\u7528\u5404\u7a2e\u751f\u6210\u6a21\u578b\u4f86\u5efa\u7acb AIGI\uff0c\u4e26\u63a1\u7528\u5404\u7a2e LMM \u4f86\u9032\u884c\u8a55\u4f30\uff0c\u9019\u78ba\u4fdd\u4e86\u5168\u9762\u7684\u9a57\u8b49\u7bc4\u570d\u3002\u6700\u7d42\uff0c\u5f9e 16 \u500b\u6587\u5b57\u8f49\u5716\u50cf\u6a21\u578b\u4e2d\u62bd\u53d6 2,864 \u500b AIGI\uff0c\u6bcf\u500b AIGI \u90fd\u914d\u6709\u4eba\u985e\u5c08\u5bb6\u8a3b\u89e3\u7684\u554f\u984c\u548c\u7b54\u6848\uff0c\u4e26\u5728 18 \u500b\u9818\u5148\u7684 LMM \u4e2d\u9032\u884c\u6e2c\u8a66\u3002\u6211\u5011\u5e0c\u671b A-Bench \u80fd\u5920\u986f\u8457\u589e\u5f37\u8a55\u4f30\u904e\u7a0b\uff0c\u4e26\u4fc3\u9032 AIGI \u7684\u751f\u6210\u54c1\u8cea\u3002\u57fa\u6e96\u53ef\u5728 https://github.com/Q-Future/A-Bench \u53d6\u5f97\u3002", "author": "Zicheng Zhang et.al.", "authors": "Zicheng Zhang, Haoning Wu, Chunyi Li, Yingjie Zhou, Wei Sun, Xiongkuo Min, Zijian Chen, Xiaohong Liu, Weisi Lin, Guangtao Zhai", "id": "2406.03070v1", "paper_url": "http://arxiv.org/abs/2406.03070v1", "repo": "https://github.com/q-future/a-bench"}}