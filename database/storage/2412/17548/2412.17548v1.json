{"2412.17548": {"publish_time": "2024-12-23", "title": "Resource-Aware Arabic LLM Creation: Model Adaptation, Integration, and Multi-Domain Testing", "paper_summary": "This paper presents a novel approach to fine-tuning the Qwen2-1.5B model for\nArabic language processing using Quantized Low-Rank Adaptation (QLoRA) on a\nsystem with only 4GB VRAM. We detail the process of adapting this large\nlanguage model to the Arabic domain, using diverse datasets including Bactrian,\nOpenAssistant, and Wikipedia Arabic corpora. Our methodology involves custom\ndata preprocessing, model configuration, and training optimization techniques\nsuch as gradient accumulation and mixed-precision training. We address specific\nchallenges in Arabic NLP, including morphological complexity, dialectal\nvariations, and diacritical mark handling. Experimental results over 10,000\ntraining steps show significant performance improvements, with the final loss\nconverging to 0.1083. We provide comprehensive analysis of GPU memory usage,\ntraining dynamics, and model evaluation across various Arabic language tasks,\nincluding text classification, question answering, and dialect identification.\nThe fine-tuned model demonstrates robustness to input perturbations and\nimproved handling of Arabic-specific linguistic phenomena. This research\ncontributes to multilingual AI by demonstrating a resource-efficient approach\nfor creating specialized language models, potentially democratizing access to\nadvanced NLP technologies for diverse linguistic communities. Our work paves\nthe way for future research in low-resource language adaptation and efficient\nfine-tuning of large language models.", "paper_summary_zh": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u91cf\u5316\u4f4e\u79e9\u9069\u61c9 (QLoRA) \u5728\u50c5\u6709 4GB VRAM \u7684\u7cfb\u7d71\u4e0a\uff0c\u5fae\u8abf Qwen2-1.5B \u6a21\u578b\u4ee5\u9032\u884c\u963f\u62c9\u4f2f\u8a9e\u8655\u7406\u3002\u6211\u5011\u8a73\u7d30\u8aaa\u660e\u4e86\u5c07\u9019\u500b\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u9069\u61c9\u5230\u963f\u62c9\u4f2f\u8a9e\u9818\u57df\u7684\u904e\u7a0b\uff0c\u4f7f\u7528\u4e86\u5305\u62ec Bactrian\u3001OpenAssistant \u548c Wikipedia \u963f\u62c9\u4f2f\u8a9e\u8a9e\u6599\u5eab\u5728\u5167\u7684\u5404\u7a2e\u6578\u64da\u96c6\u3002\u6211\u5011\u7684\u505a\u6cd5\u5305\u62ec\u81ea\u5b9a\u7fa9\u8cc7\u6599\u9810\u8655\u7406\u3001\u6a21\u578b\u7d44\u614b\u548c\u8a13\u7df4\u6700\u4f73\u5316\u6280\u8853\uff0c\u4f8b\u5982\u68af\u5ea6\u7d2f\u7a4d\u548c\u6df7\u5408\u7cbe\u5ea6\u8a13\u7df4\u3002\u6211\u5011\u89e3\u6c7a\u4e86\u963f\u62c9\u4f2f\u8a9e NLP \u4e2d\u7684\u7279\u5b9a\u6311\u6230\uff0c\u5305\u62ec\u5f62\u614b\u8907\u96dc\u6027\u3001\u65b9\u8a00\u8b8a\u7570\u548c\u97f3\u6a19\u7b26\u865f\u8655\u7406\u3002\u8d85\u904e 10,000 \u500b\u8a13\u7df4\u6b65\u9a5f\u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\u51fa\u986f\u8457\u7684\u6548\u80fd\u63d0\u5347\uff0c\u6700\u7d42\u640d\u5931\u6536\u6582\u81f3 0.1083\u3002\u6211\u5011\u63d0\u4f9b\u4e86\u5c0d GPU \u8a18\u61b6\u9ad4\u4f7f\u7528\u3001\u8a13\u7df4\u52d5\u614b\u548c\u6a21\u578b\u8a55\u4f30\u7684\u5168\u9762\u5206\u6790\uff0c\u6db5\u84cb\u5404\u7a2e\u963f\u62c9\u4f2f\u8a9e\u8a9e\u8a00\u4efb\u52d9\uff0c\u5305\u62ec\u6587\u5b57\u5206\u985e\u3001\u554f\u984c\u89e3\u7b54\u548c\u65b9\u8a00\u8fa8\u8b58\u3002\u5fae\u8abf\u5f8c\u7684\u6a21\u578b\u5c55\u793a\u4e86\u5c0d\u8f38\u5165\u64fe\u52d5\u7684\u7a69\u5065\u6027\uff0c\u4e26\u6539\u9032\u4e86\u5c0d\u963f\u62c9\u4f2f\u8a9e\u7279\u5b9a\u8a9e\u8a00\u73fe\u8c61\u7684\u8655\u7406\u3002\u9019\u9805\u7814\u7a76\u900f\u904e\u5c55\u793a\u4e00\u7a2e\u8cc7\u6e90\u6709\u6548\u7684\u65b9\u6cd5\u4f86\u5efa\u7acb\u5c08\u9580\u7684\u8a9e\u8a00\u6a21\u578b\uff0c\u5c0d\u591a\u8a9e\u8a00 AI \u6709\u6240\u8ca2\u737b\uff0c\u6709\u53ef\u80fd\u8b93\u4e0d\u540c\u8a9e\u8a00\u793e\u7fa4\u90fd\u80fd\u4f7f\u7528\u9032\u968e\u7684 NLP \u6280\u8853\u3002\u6211\u5011\u7684\u7814\u7a76\u70ba\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u9069\u61c9\u548c\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u6709\u6548\u5fae\u8abf\u92ea\u5e73\u4e86\u9053\u8def\u3002", "author": "Prakash Aryan et.al.", "authors": "Prakash Aryan", "id": "2412.17548v1", "paper_url": "http://arxiv.org/abs/2412.17548v1", "repo": "https://github.com/prakash-aryan/qwen-arabic-project"}}