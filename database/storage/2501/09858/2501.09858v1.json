{"2501.09858": {"publish_time": "2025-01-16", "title": "From Explainability to Interpretability: Interpretable Policies in Reinforcement Learning Via Model Explanation", "paper_summary": "Deep reinforcement learning (RL) has shown remarkable success in complex\ndomains, however, the inherent black box nature of deep neural network policies\nraises significant challenges in understanding and trusting the decision-making\nprocesses. While existing explainable RL methods provide local insights, they\nfail to deliver a global understanding of the model, particularly in\nhigh-stakes applications. To overcome this limitation, we propose a novel\nmodel-agnostic approach that bridges the gap between explainability and\ninterpretability by leveraging Shapley values to transform complex deep RL\npolicies into transparent representations. The proposed approach offers two key\ncontributions: a novel approach employing Shapley values to policy\ninterpretation beyond local explanations and a general framework applicable to\noff-policy and on-policy algorithms. We evaluate our approach with three\nexisting deep RL algorithms and validate its performance in two classic control\nenvironments. The results demonstrate that our approach not only preserves the\noriginal models' performance but also generates more stable interpretable\npolicies.", "paper_summary_zh": "\u6df1\u5ea6\u5f37\u5316\u5b78\u7fd2 (RL) \u5728\u8907\u96dc\u9818\u57df\u4e2d\u5c55\u73fe\u51fa\u986f\u8457\u7684\u6210\u529f\uff0c\u7136\u800c\uff0c\u6df1\u5ea6\u795e\u7d93\u7db2\u8def\u7b56\u7565\u5167\u5728\u7684\u9ed1\u7bb1\u672c\u8cea\u5728\u7406\u89e3\u548c\u4fe1\u4efb\u6c7a\u7b56\u5236\u5b9a\u904e\u7a0b\u4e2d\u63d0\u51fa\u4e86\u91cd\u5927\u7684\u6311\u6230\u3002\u96d6\u7136\u73fe\u6709\u7684\u53ef\u89e3\u91cb RL \u65b9\u6cd5\u63d0\u4f9b\u4e86\u5c40\u90e8\u898b\u89e3\uff0c\u4f46\u5b83\u5011\u672a\u80fd\u63d0\u4f9b\u5c0d\u6a21\u578b\u7684\u6574\u9ad4\u7406\u89e3\uff0c\u7279\u5225\u662f\u5728\u9ad8\u98a8\u96aa\u61c9\u7528\u4e2d\u3002\u70ba\u4e86\u514b\u670d\u9019\u500b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u6a21\u578b\u4e0d\u53ef\u77e5\u65b9\u6cd5\uff0c\u5b83\u5229\u7528 Shapley \u503c\u5c07\u8907\u96dc\u7684\u6df1\u5ea6 RL \u7b56\u7565\u8f49\u63db\u70ba\u900f\u660e\u8868\u793a\uff0c\u5f9e\u800c\u5f4c\u5408\u53ef\u89e3\u91cb\u6027\u548c\u53ef\u89e3\u91cb\u6027\u4e4b\u9593\u7684\u5dee\u8ddd\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5169\u500b\u95dc\u9375\u8ca2\u737b\uff1a\u4e00\u7a2e\u63a1\u7528 Shapley \u503c\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u65bc\u8d85\u8d8a\u5c40\u90e8\u89e3\u91cb\u7684\u7b56\u7565\u89e3\u91cb\uff0c\u4ee5\u53ca\u4e00\u500b\u9069\u7528\u65bc\u975e\u7b56\u7565\u548c\u7b56\u7565\u6f14\u7b97\u6cd5\u7684\u4e00\u822c\u6846\u67b6\u3002\u6211\u5011\u4f7f\u7528\u4e09\u500b\u73fe\u6709\u7684\u6df1\u5ea6 RL \u6f14\u7b97\u6cd5\u8a55\u4f30\u6211\u5011\u7684\u6f14\u7b97\u6cd5\uff0c\u4e26\u5728\u5169\u500b\u7d93\u5178\u63a7\u5236\u74b0\u5883\u4e2d\u9a57\u8b49\u5176\u6548\u80fd\u3002\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u7684\u6f14\u7b97\u6cd5\u4e0d\u50c5\u4fdd\u7559\u4e86\u539f\u59cb\u6a21\u578b\u7684\u6548\u80fd\uff0c\u800c\u4e14\u9084\u7522\u751f\u4e86\u66f4\u7a69\u5b9a\u7684\u53ef\u89e3\u91cb\u7b56\u7565\u3002", "author": "Peilang Li et.al.", "authors": "Peilang Li, Umer Siddique, Yongcan Cao", "id": "2501.09858v1", "paper_url": "http://arxiv.org/abs/2501.09858v1", "repo": "null"}}