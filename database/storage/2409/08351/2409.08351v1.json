{"2409.08351": {"publish_time": "2024-09-12", "title": "Bayesian Inverse Graphics for Few-Shot Concept Learning", "paper_summary": "Humans excel at building generalizations of new concepts from just one single\nexample. Contrary to this, current computer vision models typically require\nlarge amount of training samples to achieve a comparable accuracy. In this work\nwe present a Bayesian model of perception that learns using only minimal data,\na prototypical probabilistic program of an object. Specifically, we propose a\ngenerative inverse graphics model of primitive shapes, to infer posterior\ndistributions over physically consistent parameters from one or several images.\nWe show how this representation can be used for downstream tasks such as\nfew-shot classification and pose estimation. Our model outperforms existing\nfew-shot neural-only classification algorithms and demonstrates generalization\nacross varying lighting conditions, backgrounds, and out-of-distribution\nshapes. By design, our model is uncertainty-aware and uses our new\ndifferentiable renderer for optimizing global scene parameters through gradient\ndescent, sampling posterior distributions over object parameters with Markov\nChain Monte Carlo (MCMC), and using a neural based likelihood function.", "paper_summary_zh": "\u4eba\u985e\u64c5\u9577\u50c5\u5f9e\u4e00\u500b\u55ae\u4e00\u7bc4\u4f8b\u5efa\u7acb\u65b0\u6982\u5ff5\u7684\u6982\u62ec\u3002\u8207\u6b64\u76f8\u53cd\uff0c\u76ee\u524d\u7684\u96fb\u8166\u8996\u89ba\u6a21\u578b\u901a\u5e38\u9700\u8981\u5927\u91cf\u7684\u8a13\u7df4\u6a23\u672c\u624d\u80fd\u9054\u5230\u53ef\u6bd4\u8f03\u7684\u6e96\u78ba\u5ea6\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u8c9d\u6c0f\u611f\u77e5\u6a21\u578b\uff0c\u5b83\u50c5\u4f7f\u7528\u6700\u5c11\u7684\u6578\u64da\u9032\u884c\u5b78\u7fd2\uff0c\u4e00\u500b\u7269\u9ad4\u7684\u539f\u578b\u6a5f\u7387\u7a0b\u5f0f\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u539f\u59cb\u5f62\u72c0\u7684\u751f\u6210\u5f0f\u53cd\u5411\u5716\u5f62\u6a21\u578b\uff0c\u4ee5\u5f9e\u4e00\u500b\u6216\u591a\u500b\u5f71\u50cf\u63a8\u8ad6\u51fa\u7269\u7406\u4e00\u81f4\u53c3\u6578\u4e0a\u7684\u5f8c\u9a57\u5206\u4f48\u3002\u6211\u5011\u5c55\u793a\u5982\u4f55\u5c07\u6b64\u8868\u5fb5\u7528\u65bc\u4e0b\u6e38\u4efb\u52d9\uff0c\u4f8b\u5982\u5c11\u6a23\u672c\u5206\u985e\u548c\u59ff\u52e2\u4f30\u8a08\u3002\u6211\u5011\u7684\u6a21\u578b\u512a\u65bc\u73fe\u6709\u7684\u50c5\u795e\u7d93\u5c11\u6a23\u672c\u5206\u985e\u6f14\u7b97\u6cd5\uff0c\u4e26\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u5149\u7167\u689d\u4ef6\u3001\u80cc\u666f\u548c\u5206\u5e03\u5916\u5f62\u72c0\u4e0b\u7684\u6982\u62ec\u80fd\u529b\u3002\u6839\u64da\u8a2d\u8a08\uff0c\u6211\u5011\u7684\u6a21\u578b\u5177\u6709\u4e0d\u78ba\u5b9a\u6027\u611f\u77e5\uff0c\u4e26\u4f7f\u7528\u6211\u5011\u65b0\u7684\u53ef\u5fae\u5206\u6e32\u67d3\u5668\u900f\u904e\u68af\u5ea6\u4e0b\u964d\u6700\u4f73\u5316\u5168\u5c40\u5834\u666f\u53c3\u6578\uff0c\u4f7f\u7528\u99ac\u53ef\u592b\u93c8\u8499\u5730\u5361\u7f85 (MCMC) \u5c0d\u7269\u4ef6\u53c3\u6578\u9032\u884c\u5f8c\u9a57\u5206\u4f48\u53d6\u6a23\uff0c\u4e26\u4f7f\u7528\u57fa\u65bc\u795e\u7d93\u7684\u4f3c\u7136\u51fd\u6578\u3002", "author": "Octavio Arriaga et.al.", "authors": "Octavio Arriaga, Jichen Guo, Rebecca Adam, Sebastian Houben, Frank Kirchner", "id": "2409.08351v1", "paper_url": "http://arxiv.org/abs/2409.08351v1", "repo": "null"}}