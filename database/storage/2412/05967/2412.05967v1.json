{"2412.05967": {"publish_time": "2024-12-08", "title": "Language hooks: a modular framework for augmenting LLM reasoning that decouples tool usage from the model and its prompt", "paper_summary": "Prompting and fine-tuning have emerged as two competing paradigms for\naugmenting language models with new capabilities, such as the use of tools.\nPrompting approaches are quick to set up but rely on providing explicit\ndemonstrations of each tool's usage in the model's prompt, thus coupling tool\nuse to the task at hand and limiting generalisation. Fine-tuning removes the\nneed for task-specific demonstrations of tool usage at runtime; however, this\nties new capabilities to a single model, thus making already-heavier setup\ncosts a recurring expense. In this paper, we introduce language hooks, a novel\nframework for augmenting language models with new capabilities that is\ndecoupled both from the model's task-specific prompt and from the model itself.\nThe language hook algorithm interleaves text generation by the base model with\nthe execution of modular programs that trigger conditionally based on the\nexisting text and the available capabilities. Upon triggering, programs may\ncall external tools, auxiliary language models (e.g. using tool specific\nprompts), and modify the existing context. We benchmark our method against\nstate-of-the-art baselines, find that it outperforms task-aware approaches, and\ndemonstrate its ability to generalise to novel tasks.", "paper_summary_zh": "\u63d0\u793a\u548c\u5fae\u8c03\u5df2\u6210\u4e3a\u4e24\u79cd\u7ade\u4e89\u6027\u7684\u8303\u4f8b\uff0c\u7528\u4e8e\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u529f\u80fd\uff0c\u4f8b\u5982\u4f7f\u7528\u5de5\u5177\u3002\u63d0\u793a\u65b9\u6cd5\u8bbe\u7f6e\u8d77\u6765\u5f88\u5feb\uff0c\u4f46\u4f9d\u8d56\u4e8e\u5728\u6a21\u578b\u63d0\u793a\u4e2d\u660e\u786e\u6f14\u793a\u6bcf\u4e2a\u5de5\u5177\u7684\u4f7f\u7528\uff0c\u4ece\u800c\u5c06\u5de5\u5177\u7684\u4f7f\u7528\u4e0e\u624b\u5934\u7684\u4efb\u52a1\u76f8\u7ed3\u5408\u5e76\u9650\u5236\u6982\u62ec\u3002\u5fae\u8c03\u6d88\u9664\u4e86\u5728\u8fd0\u884c\u65f6\u5bf9\u7279\u5b9a\u4efb\u52a1\u7684\u5de5\u5177\u4f7f\u7528\u6f14\u793a\u7684\u9700\u8981\uff1b\u7136\u800c\uff0c\u8fd9\u5c06\u65b0\u529f\u80fd\u4e0e\u5355\u4e2a\u6a21\u578b\u8054\u7cfb\u8d77\u6765\uff0c\u4ece\u800c\u4f7f\u5df2\u7ecf\u5f88\u91cd\u7684\u8bbe\u7f6e\u6210\u672c\u6210\u4e3a\u7ecf\u5e38\u6027\u7684\u5f00\u652f\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86\u8bed\u8a00\u94a9\u5b50\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u529f\u80fd\uff0c\u5b83\u65e2\u4e0e\u6a21\u578b\u7684\u4efb\u52a1\u7279\u5b9a\u63d0\u793a\u53c8\u4e0e\u6a21\u578b\u672c\u8eab\u5206\u79bb\u3002\u8bed\u8a00\u94a9\u5b50\u7b97\u6cd5\u5c06\u57fa\u672c\u6a21\u578b\u7684\u6587\u672c\u751f\u6210\u4e0e\u6a21\u5757\u5316\u7a0b\u5e8f\u7684\u6267\u884c\u4ea4\u7ec7\u5728\u4e00\u8d77\uff0c\u8fd9\u4e9b\u7a0b\u5e8f\u6839\u636e\u73b0\u6709\u6587\u672c\u548c\u53ef\u7528\u529f\u80fd\u6709\u6761\u4ef6\u5730\u89e6\u53d1\u3002\u89e6\u53d1\u540e\uff0c\u7a0b\u5e8f\u53ef\u4ee5\u8c03\u7528\u5916\u90e8\u5de5\u5177\u3001\u8f85\u52a9\u8bed\u8a00\u6a21\u578b\uff08\u4f8b\u5982\uff0c\u4f7f\u7528\u7279\u5b9a\u4e8e\u5de5\u5177\u7684\u63d0\u793a\uff09\u5e76\u4fee\u6539\u73b0\u6709\u4e0a\u4e0b\u6587\u3002\u6211\u4eec\u6839\u636e\u6700\u5148\u8fdb\u7684\u57fa\u51c6\u6d4b\u8bd5\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u5b83\u4f18\u4e8e\u4efb\u52a1\u611f\u77e5\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5b83\u63a8\u5e7f\u5230\u65b0\u4efb\u52a1\u7684\u80fd\u529b\u3002", "author": "Damien de Mijolla et.al.", "authors": "Damien de Mijolla, Wen Yang, Philippa Duckett, Christopher Frye, Mark Worrall", "id": "2412.05967v1", "paper_url": "http://arxiv.org/abs/2412.05967v1", "repo": "null"}}