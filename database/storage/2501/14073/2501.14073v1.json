{"2501.14073": {"publish_time": "2025-01-23", "title": "LLMs are Vulnerable to Malicious Prompts Disguised as Scientific Language", "paper_summary": "As large language models (LLMs) have been deployed in various real-world\nsettings, concerns about the harm they may propagate have grown. Various\njailbreaking techniques have been developed to expose the vulnerabilities of\nthese models and improve their safety. This work reveals that many\nstate-of-the-art proprietary and open-source LLMs are vulnerable to malicious\nrequests hidden behind scientific language. Specifically, our experiments with\nGPT4o, GPT4o-mini, GPT-4, LLama3-405B-Instruct, Llama3-70B-Instruct, Cohere,\nGemini models on the StereoSet data demonstrate that, the models' biases and\ntoxicity substantially increase when prompted with requests that deliberately\nmisinterpret social science and psychological studies as evidence supporting\nthe benefits of stereotypical biases. Alarmingly, these models can also be\nmanipulated to generate fabricated scientific arguments claiming that biases\nare beneficial, which can be used by ill-intended actors to systematically\njailbreak even the strongest models like GPT. Our analysis studies various\nfactors that contribute to the models' vulnerabilities to malicious requests in\nacademic language. Mentioning author names and venues enhances the\npersuasiveness of some models, and the bias scores can increase as dialogues\nprogress. Our findings call for a more careful investigation on the use of\nscientific data in the training of LLMs.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u7a2e\u771f\u5be6\u4e16\u754c\u5834\u666f\u4e2d\u90e8\u7f72\uff0c\u4eba\u5011\u5c0d\u5176\u53ef\u80fd\u50b3\u64ad\u7684\u5371\u5bb3\u7684\u64d4\u6182\u4e5f\u96a8\u4e4b\u589e\u52a0\u3002\u5df2\u7d93\u958b\u767c\u4e86\u5404\u7a2e\u8d8a\u7344\u6280\u8853\u4f86\u63ed\u9732\u9019\u4e9b\u6a21\u578b\u7684\u6f0f\u6d1e\u4e26\u63d0\u9ad8\u5176\u5b89\u5168\u6027\u3002\u9019\u9805\u5de5\u4f5c\u63ed\u793a\u4e86\u8a31\u591a\u6700\u5148\u9032\u7684\u5c08\u6709\u548c\u958b\u6e90 LLM \u5bb9\u6613\u53d7\u5230\u96b1\u85cf\u5728\u79d1\u5b78\u8a9e\u8a00\u80cc\u5f8c\u7684\u60e1\u610f\u8acb\u6c42\u7684\u653b\u64ca\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5c0d StereoSet \u6578\u64da\u4e0a\u7684 GPT4o\u3001GPT4o-mini\u3001GPT-4\u3001LLama3-405B-Instruct\u3001Llama3-70B-Instruct\u3001Cohere\u3001Gemini \u6a21\u578b\u7684\u5be6\u9a57\u8868\u660e\uff0c\u7576\u4f7f\u7528\u6545\u610f\u5c07\u793e\u6703\u79d1\u5b78\u548c\u5fc3\u7406\u5b78\u7814\u7a76\u8aa4\u89e3\u70ba\u652f\u6301\u523b\u677f\u5370\u8c61\u504f\u898b\u597d\u8655\u7684\u8b49\u64da\u7684\u8acb\u6c42\u6642\uff0c\u6a21\u578b\u7684\u504f\u898b\u548c\u6bd2\u6027\u6703\u5927\u5e45\u589e\u52a0\u3002\u4ee4\u4eba\u64d4\u6182\u7684\u662f\uff0c\u9019\u4e9b\u6a21\u578b\u9084\u53ef\u4ee5\u88ab\u64cd\u7e31\u4ee5\u7522\u751f\u865b\u5047\u7684\u79d1\u5b78\u8ad6\u64da\uff0c\u8072\u7a31\u504f\u898b\u662f\u6709\u76ca\u7684\uff0c\u9019\u53ef\u4ee5\u88ab\u5fc3\u61f7\u4e0d\u8ecc\u7684\u4eba\u7528\u4f86\u7cfb\u7d71\u6027\u5730\u8d8a\u7344\u751a\u81f3\u50cf GPT \u9019\u6a23\u7684\u6700\u5f37\u5927\u7684\u6a21\u578b\u3002\u6211\u5011\u7684\u5206\u6790\u7814\u7a76\u4e86\u5c0e\u81f4\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u5b78\u8853\u8a9e\u8a00\u4e2d\u7684\u60e1\u610f\u8acb\u6c42\u653b\u64ca\u7684\u5404\u7a2e\u56e0\u7d20\u3002\u63d0\u53ca\u4f5c\u8005\u59d3\u540d\u548c\u5834\u666f\u6703\u589e\u5f37\u67d0\u4e9b\u6a21\u578b\u7684\u8aaa\u670d\u529b\uff0c\u4e26\u4e14\u96a8\u8457\u5c0d\u8a71\u7684\u9032\u884c\uff0c\u504f\u898b\u5206\u6578\u53ef\u80fd\u6703\u589e\u52a0\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8981\u6c42\u5c0d LLM \u8a13\u7df4\u4e2d\u79d1\u5b78\u6578\u64da\u7684\u4f7f\u7528\u9032\u884c\u66f4\u4ed4\u7d30\u7684\u8abf\u67e5\u3002", "author": "Yubin Ge et.al.", "authors": "Yubin Ge, Neeraja Kirtane, Hao Peng, Dilek Hakkani-T\u00fcr", "id": "2501.14073v1", "paper_url": "http://arxiv.org/abs/2501.14073v1", "repo": "null"}}