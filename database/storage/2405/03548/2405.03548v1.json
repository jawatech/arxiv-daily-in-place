{"2405.03548": {"publish_time": "2024-05-06", "title": "MAmmoTH2: Scaling Instructions from the Web", "paper_summary": "Instruction tuning improves the reasoning abilities of large language models\n(LLMs), with data quality and scalability being the crucial factors. Most\ninstruction tuning data come from human crowd-sourcing or GPT-4 distillation.\nWe propose a paradigm to efficiently harvest 10 million naturally existing\ninstruction data from the pre-training web corpus to enhance LLM reasoning. Our\napproach involves (1) recalling relevant documents, (2) extracting\ninstruction-response pairs, and (3) refining the extracted pairs using\nopen-source LLMs. Fine-tuning base LLMs on this dataset, we build MAmmoTH2\nmodels, which significantly boost performance on reasoning benchmarks. Notably,\nMAmmoTH2-7B's (Mistral) performance increases from 11% to 34% on MATH and from\n36% to 67% on GSM8K without training on any in-domain data. Further training\nMAmmoTH2 on public instruction tuning datasets yields MAmmoTH2-Plus, achieving\nstate-of-the-art performance on several reasoning and chatbot benchmarks. Our\nwork demonstrates how to harvest large-scale, high-quality instruction data\nwithout costly human annotation or GPT-4 distillation, providing a new paradigm\nfor building better instruction tuning data.", "paper_summary_zh": "", "author": "Xiang Yue et.al.", "authors": "Xiang Yue,Tuney Zheng,Ge Zhang,Wenhu Chen", "id": "2405.03548v1", "paper_url": "http://arxiv.org/abs/2405.03548v1", "repo": "null"}}