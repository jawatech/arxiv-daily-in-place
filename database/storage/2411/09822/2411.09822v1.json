{"2411.09822": {"publish_time": "2024-11-14", "title": "A Self-Supervised Model for Multi-modal Stroke Risk Prediction", "paper_summary": "Predicting stroke risk is a complex challenge that can be enhanced by\nintegrating diverse clinically available data modalities. This study introduces\na self-supervised multimodal framework that combines 3D brain imaging, clinical\ndata, and image-derived features to improve stroke risk prediction prior to\nonset. By leveraging large unannotated clinical datasets, the framework\ncaptures complementary and synergistic information across image and tabular\ndata modalities. Our approach is based on a contrastive learning framework that\ncouples contrastive language-image pretraining with an image-tabular matching\nmodule, to better align multimodal data representations in a shared latent\nspace. The model is trained on the UK Biobank, which includes structural brain\nMRI and clinical data. We benchmark its performance against state-of-the-art\nunimodal and multimodal methods using tabular, image, and image-tabular\ncombinations under diverse frozen and trainable model settings. The proposed\nmodel outperformed self-supervised tabular (image) methods by 2.6% (2.6%) in\nROC-AUC and by 3.3% (5.6%) in balanced accuracy. Additionally, it showed a 7.6%\nincrease in balanced accuracy compared to the best multimodal supervised model.\nThrough interpretable tools, our approach demonstrated better integration of\ntabular and image data, providing richer and more aligned embeddings.\nGradient-weighted Class Activation Mapping heatmaps further revealed activated\nbrain regions commonly associated in the literature with brain aging, stroke\nrisk, and clinical outcomes. This robust self-supervised multimodal framework\nsurpasses state-of-the-art methods for stroke risk prediction and offers a\nstrong foundation for future studies integrating diverse data modalities to\nadvance clinical predictive modelling.", "paper_summary_zh": "<paragraph>\u9810\u6e2c\u4e2d\u98a8\u98a8\u96aa\u662f\u4e00\u9805\u8907\u96dc\u7684\u6311\u6230\uff0c\u53ef\u4ee5\u900f\u904e\u6574\u5408\u591a\u6a23\u5316\u7684\u81e8\u5e8a\u53ef\u7528\u6578\u64da\u6a21\u5f0f\u4f86\u52a0\u5f37\u3002\u672c\u7814\u7a76\u4ecb\u7d39\u4e86\u4e00\u500b\u81ea\u76e3\u7763\u591a\u6a21\u5f0f\u67b6\u69cb\uff0c\u7d50\u5408 3D \u5927\u8166\u5f71\u50cf\u3001\u81e8\u5e8a\u6578\u64da\u548c\u5f71\u50cf\u884d\u751f\u7279\u5fb5\uff0c\u4ee5\u5728\u767c\u4f5c\u524d\u6539\u5584\u4e2d\u98a8\u98a8\u96aa\u9810\u6e2c\u3002\u900f\u904e\u5229\u7528\u5927\u91cf\u7684\u672a\u6a19\u8a18\u81e8\u5e8a\u6578\u64da\u96c6\uff0c\u8a72\u67b6\u69cb\u64f7\u53d6\u4e86\u5f71\u50cf\u548c\u8868\u683c\u6578\u64da\u6a21\u5f0f\u4e4b\u9593\u7684\u4e92\u88dc\u548c\u5354\u540c\u8cc7\u8a0a\u3002\u6211\u5011\u7684\u505a\u6cd5\u57fa\u65bc\u5c0d\u6bd4\u5b78\u7fd2\u67b6\u69cb\uff0c\u5c07\u5c0d\u6bd4\u8a9e\u8a00\u5f71\u50cf\u9810\u8a13\u7df4\u8207\u5f71\u50cf\u8868\u683c\u5339\u914d\u6a21\u7d44\u7d50\u5408\uff0c\u4ee5\u5728\u5171\u4eab\u6f5b\u5728\u7a7a\u9593\u4e2d\u66f4\u597d\u5730\u5c0d\u9f4a\u591a\u6a21\u5f0f\u6578\u64da\u8868\u793a\u3002\u8a72\u6a21\u578b\u662f\u5728\u82f1\u570b\u751f\u7269\u9280\u884c\u4e2d\u8a13\u7df4\u7684\uff0c\u5176\u4e2d\u5305\u62ec\u7d50\u69cb\u6027\u8166\u90e8 MRI \u548c\u81e8\u5e8a\u6578\u64da\u3002\u6211\u5011\u4f7f\u7528\u8868\u683c\u3001\u5f71\u50cf\u548c\u5f71\u50cf\u8868\u683c\u7d44\u5408\uff0c\u5728\u4e0d\u540c\u7684\u51cd\u7d50\u548c\u53ef\u8a13\u7df4\u6a21\u578b\u8a2d\u5b9a\u4e0b\uff0c\u6839\u64da\u6700\u5148\u9032\u7684\u55ae\u6a21\u5f0f\u548c\u591a\u6a21\u5f0f\u65b9\u6cd5\u5c0d\u5176\u6548\u80fd\u9032\u884c\u57fa\u6e96\u6e2c\u8a66\u3002\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728 ROC-AUC \u4e2d\u6bd4\u81ea\u76e3\u7763\u8868\u683c\uff08\u5f71\u50cf\uff09\u65b9\u6cd5\u9ad8\u51fa 2.6%\uff082.6%\uff09\uff0c\u5728\u5e73\u8861\u6e96\u78ba\u5ea6\u4e2d\u9ad8\u51fa 3.3%\uff085.6%\uff09\u3002\u6b64\u5916\uff0c\u8207\u6700\u4f73\u591a\u6a21\u5f0f\u76e3\u7763\u6a21\u578b\u76f8\u6bd4\uff0c\u5b83\u7684\u5e73\u8861\u6e96\u78ba\u5ea6\u63d0\u9ad8\u4e86 7.6%\u3002\u900f\u904e\u53ef\u89e3\u91cb\u7684\u5de5\u5177\uff0c\u6211\u5011\u7684\u505a\u6cd5\u8b49\u660e\u4e86\u8868\u683c\u548c\u5f71\u50cf\u6578\u64da\u7684\u6574\u5408\u6027\u66f4\u597d\uff0c\u63d0\u4f9b\u4e86\u66f4\u8c50\u5bcc\u4e14\u66f4\u4e00\u81f4\u7684\u5d4c\u5165\u3002\u68af\u5ea6\u52a0\u6b0a\u985e\u5225\u555f\u7528\u5c0d\u61c9\u71b1\u5716\u9032\u4e00\u6b65\u63ed\u793a\u4e86\u6587\u737b\u4e2d\u901a\u5e38\u8207\u8166\u90e8\u8001\u5316\u3001\u4e2d\u98a8\u98a8\u96aa\u548c\u81e8\u5e8a\u7d50\u679c\u76f8\u95dc\u7684\u6d3b\u5316\u8166\u5340\u3002\u9019\u500b\u5f37\u5065\u7684\u81ea\u76e3\u7763\u591a\u6a21\u5f0f\u67b6\u69cb\u8d85\u8d8a\u4e86\u4e2d\u98a8\u98a8\u96aa\u9810\u6e2c\u7684\u6700\u65b0\u65b9\u6cd5\uff0c\u4e26\u70ba\u6574\u5408\u4e0d\u540c\u6578\u64da\u6a21\u5f0f\u4ee5\u63a8\u9032\u81e8\u5e8a\u9810\u6e2c\u5efa\u6a21\u7684\u672a\u4f86\u7814\u7a76\u63d0\u4f9b\u4e86\u5805\u5be6\u7684\u57fa\u790e\u3002</paragraph>", "author": "Camille Delgrange et.al.", "authors": "Camille Delgrange, Olga Demler, Samia Mora, Bjoern Menze, Ezequiel de la Rosa, Neda Davoudi", "id": "2411.09822v1", "paper_url": "http://arxiv.org/abs/2411.09822v1", "repo": "null"}}