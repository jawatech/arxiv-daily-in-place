# arxiv-daily
 Automated deployment @ 2024-04-29 16:19:39 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### LLM
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-04-26**|**Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo**|Stephen Zhao et.al.|[2404.17546v1](http://arxiv.org/abs/2404.17546v1)|null|
|**2024-04-26**|**Large Language Model Agent as a Mechanical Designer**|Yayati Jadhav et.al.|[2404.17525v1](http://arxiv.org/abs/2404.17525v1)|null|
|**2024-04-26**|**On the Use of Large Language Models to Generate Capability Ontologies**|Luis Miguel Vieira da Silva et.al.|[2404.17524v1](http://arxiv.org/abs/2404.17524v1)|null|
|**2024-04-26**|**Enhancing Legal Compliance and Regulation Analysis with Large Language Models**|Shabnam Hassani et.al.|[2404.17522v1](http://arxiv.org/abs/2404.17522v1)|null|
|**2024-04-26**|**A Comprehensive Evaluation on Event Reasoning of Large Language Models**|Zhengwei Tao et.al.|[2404.17513v1](http://arxiv.org/abs/2404.17513v1)|[link](https://github.com/tzwwww/ev2)|
|**2024-04-26**|**Causally Abstracted Multi-armed Bandits**|Fabio Massimo Zennaro et.al.|[2404.17493v1](http://arxiv.org/abs/2404.17493v1)|null|
|**2024-04-26**|**Tabular Data Contrastive Learning via Class-Conditioned and Feature-Correlation Based Augmentation**|Wei Cui et.al.|[2404.17489v1](http://arxiv.org/abs/2404.17489v1)|[link](https://github.com/willtop/tabular-class-conditioned-ssl)|
|**2024-04-26**|**Conformal Prediction with Learned Features**|Shayan Kiyani et.al.|[2404.17487v1](http://arxiv.org/abs/2404.17487v1)|null|
|**2024-04-26**|**ReproHum #0087-01: Human Evaluation Reproduction Report for Generating Fact Checking Explanations**|Tyler Loakman et.al.|[2404.17481v1](http://arxiv.org/abs/2404.17481v1)|null|
|**2024-04-26**|**CEval: A Benchmark for Evaluating Counterfactual Text Generation**|Van Bach Nguyen et.al.|[2404.17475v1](http://arxiv.org/abs/2404.17475v1)|null|
|**2024-04-26**|**Ruffle&Riley: Insights from Designing and Evaluating a Large Language Model-Based Conversational Tutoring System**|Robin Schmucker et.al.|[2404.17460v1](http://arxiv.org/abs/2404.17460v1)|null|
|**2024-04-26**|**Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond**|Kaichen Xu et.al.|[2404.17454v1](http://arxiv.org/abs/2404.17454v1)|[link](https://github.com/catchxu/acsleuth)|
|**2024-04-26**|**"ChatGPT Is Here to Help, Not to Replace Anybody" -- An Evaluation of Students' Opinions On Integrating ChatGPT In CS Courses**|Bruno Pereira Cipriano et.al.|[2404.17443v1](http://arxiv.org/abs/2404.17443v1)|null|
|**2024-04-26**|**Real-World Deployment of a Hierarchical Uncertainty-Aware Collaborative Multiagent Planning System**|Martina Stadler Kurtz et.al.|[2404.17438v1](http://arxiv.org/abs/2404.17438v1)|null|
|**2024-04-26**|**Evaluation of Geographical Distortions in Language Models: A Crucial Step Towards Equitable Representations**|Rémy Decoupes et.al.|[2404.17401v1](http://arxiv.org/abs/2404.17401v1)|null|
|**2024-04-26**|**Spatial-frequency Dual-Domain Feature Fusion Network for Low-Light Remote Sensing Image Enhancement**|Zishu Yao et.al.|[2404.17400v1](http://arxiv.org/abs/2404.17400v1)|null|
|**2024-04-26**|**Child Speech Recognition in Human-Robot Interaction: Problem Solved?**|Ruben Janssens et.al.|[2404.17394v1](http://arxiv.org/abs/2404.17394v1)|null|
|**2024-04-26**|**M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training**|Lakmal Meegahapola et.al.|[2404.17391v1](http://arxiv.org/abs/2404.17391v1)|null|
|**2024-04-26**|**Assessing the Potential of AI for Spatially Sensitive Nature-Related Financial Risks**|Steven Reece et.al.|[2404.17369v1](http://arxiv.org/abs/2404.17369v1)|null|
|**2024-04-26**|**Similarity Equivariant Graph Neural Networks for Homogenization of Metamaterials**|Fleur Hendriks et.al.|[2404.17365v1](http://arxiv.org/abs/2404.17365v1)|null|
|**2024-04-26**|**A Bionic Natural Language Parser Equivalent to a Pushdown Automaton**|Zhenghao Wei et.al.|[2404.17343v1](http://arxiv.org/abs/2404.17343v1)|null|
|**2024-04-26**|**Can a Multichoice Dataset be Repurposed for Extractive Question Answering?**|Teresa Lynn et.al.|[2404.17342v1](http://arxiv.org/abs/2404.17342v1)|null|
|**2024-04-26**|**Metronome: tracing variation in poetic meters via local sequence alignment**|Ben Nagy et.al.|[2404.17337v1](http://arxiv.org/abs/2404.17337v1)|[link](https://github.com/bnagy/metronome-paper)|
|**2024-04-26**|**Introducing cosmosGPT: Monolingual Training for Turkish Language Models**|H. Toprak Kesgin et.al.|[2404.17336v1](http://arxiv.org/abs/2404.17336v1)|null|
|**2024-04-26**|**A Novel Spike Transformer Network for Depth Estimation from Event Cameras via Cross-modality Knowledge Distillation**|Xin Zhang et.al.|[2404.17335v1](http://arxiv.org/abs/2404.17335v1)|null|
|**2024-04-26**|**Part-Guided 3D RL for Sim2Real Articulated Object Manipulation**|Pengwei Xie et.al.|[2404.17302v1](http://arxiv.org/abs/2404.17302v1)|[link](https://github.com/thu-vclab/part-guided-3d-rl-for-sim2real-articulated-object-manipulation)|
|**2024-04-26**|**When to Trust LLMs: Aligning Confidence with Response Quality**|Shuchang Tao et.al.|[2404.17287v1](http://arxiv.org/abs/2404.17287v1)|null|
|**2024-04-26**|**Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact Checking News Claims with Black-Box LLM**|Xuan Zhang et.al.|[2404.17283v1](http://arxiv.org/abs/2404.17283v1)|[link](https://github.com/jadecurl/ffrr)|
|**2024-04-26**|**Enhancing Privacy and Security of Autonomous UAV Navigation**|Vatsal Aggarwal et.al.|[2404.17225v1](http://arxiv.org/abs/2404.17225v1)|null|
|**2024-04-26**|**Prompting Techniques for Reducing Social Bias in LLMs through System 1 and System 2 Cognitive Processes**|Mahammed Kamruzzaman et.al.|[2404.17218v1](http://arxiv.org/abs/2404.17218v1)|null|
|**2024-04-26**|**Prompting Towards Alleviating Code-Switched Data Scarcity in Under-Resourced Languages with GPT as a Pivot**|Michelle Terblanche et.al.|[2404.17216v1](http://arxiv.org/abs/2404.17216v1)|null|
|**2024-04-26**|**Human-Imperceptible Retrieval Poisoning Attacks in LLM-Powered Applications**|Quan Zhang et.al.|[2404.17196v1](http://arxiv.org/abs/2404.17196v1)|null|
|**2024-04-26**|**TIGQA:An Expert Annotated Question Answering Dataset in Tigrinya**|Hailay Teklehaymanot et.al.|[2404.17194v1](http://arxiv.org/abs/2404.17194v1)|null|
|**2024-04-26**|**MCSDNet: Mesoscale Convective System Detection Network via Multi-scale Spatiotemporal Information**|Jiajun Liang et.al.|[2404.17186v1](http://arxiv.org/abs/2404.17186v1)|null|
|**2024-04-26**|**A Unified Label-Aware Contrastive Learning Framework for Few-Shot Named Entity Recognition**|Haojie Zhang et.al.|[2404.17178v1](http://arxiv.org/abs/2404.17178v1)|null|
|**2024-04-26**|**Exploring Beyond Logits: Hierarchical Dynamic Labeling Based on Embeddings for Semi-Supervised Classification**|Yanbiao Ma et.al.|[2404.17173v1](http://arxiv.org/abs/2404.17173v1)|null|
|**2024-04-26**|**Quantifying Memorization of Domain-Specific Pre-trained Language Models using Japanese Newspaper and Paywalls**|Shotaro Ishihara et.al.|[2404.17143v1](http://arxiv.org/abs/2404.17143v1)|null|
|**2024-04-26**|**Small Language Models Need Strong Verifiers to Self-Correct Reasoning**|Yunxiang Zhang et.al.|[2404.17140v1](http://arxiv.org/abs/2404.17140v1)|null|
|**2024-04-26**|**Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study**|Yang Wu et.al.|[2404.17136v1](http://arxiv.org/abs/2404.17136v1)|null|
|**2024-04-26**|**Process Mining Embeddings: Learning Vector Representations for Petri Nets**|Juan G. Colonna et.al.|[2404.17129v1](http://arxiv.org/abs/2404.17129v1)|[link](https://github.com/juancolonna/petrinet2vec)|
|**2024-04-26**|**Deep Evidential Learning for Dose Prediction**|Hai Siong Tan et.al.|[2404.17126v1](http://arxiv.org/abs/2404.17126v1)|null|
|**2024-04-26**|**Text Sentiment Analysis and Classification Based on Bidirectional Gated Recurrent Units (GRUs) Model**|Wei Xu et.al.|[2404.17123v1](http://arxiv.org/abs/2404.17123v1)|null|
|**2024-04-26**|**2M-NER: Contrastive Learning for Multilingual and Multimodal NER with Language and Modal Fusion**|Dongsheng Wang et.al.|[2404.17122v1](http://arxiv.org/abs/2404.17122v1)|null|
|**2024-04-26**|**Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs**|Valeriia Cherepanova et.al.|[2404.17120v1](http://arxiv.org/abs/2404.17120v1)|null|
|**2024-04-26**|**CLARE: Cognitive Load Assessment in REaltime with Multimodal Data**|Anubhav Bhatti et.al.|[2404.17098v1](http://arxiv.org/abs/2404.17098v1)|null|
|**2024-04-25**|**CyNetDiff -- A Python Library for Accelerated Implementation of Network Diffusion Models**|Eliot W. Robson et.al.|[2404.17059v1](http://arxiv.org/abs/2404.17059v1)|null|
|**2024-04-25**|**Agentive Permissions in Multiagent Systems**|Qi Shi et.al.|[2404.17053v1](http://arxiv.org/abs/2404.17053v1)|null|
|**2024-04-25**|**Generative AI in Color-Changing Systems: Re-Programmable 3D Object Textures with Material and Design Constraints**|Yunyi Zhu et.al.|[2404.17028v1](http://arxiv.org/abs/2404.17028v1)|null|
|**2024-04-25**|**Player-Driven Emergence in LLM-Driven Game Narrative**|Xiangyu Peng et.al.|[2404.17027v1](http://arxiv.org/abs/2404.17027v1)|null|
|**2024-04-25**|**Generating Minimalist Adversarial Perturbations to Test Object-Detection Models: An Adaptive Multi-Metric Evolutionary Search Approach**|Cristopher McIntyre-Garcia et.al.|[2404.17020v1](http://arxiv.org/abs/2404.17020v1)|[link](https://github.com/cmcin019/tm-evo)|
|**2024-04-25**|**Türkçe Dil Modellerinin Performans Karşılaştırması Performance Comparison of Turkish Language Models**|Eren Dogan et.al.|[2404.17010v1](http://arxiv.org/abs/2404.17010v1)|null|
|**2024-04-25**|**Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models**|Bradley P. Allen et.al.|[2404.17000v1](http://arxiv.org/abs/2404.17000v1)|[link](https://github.com/bradleypallen/evaluating-kg-class-memberships-using-llms)|
|**2024-04-25**|**IDIL: Imitation Learning of Intent-Driven Expert Behavior**|Sangwon Seo et.al.|[2404.16989v1](http://arxiv.org/abs/2404.16989v1)|null|
|**2024-04-25**|**Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks**|Melissa Ailem et.al.|[2404.16966v1](http://arxiv.org/abs/2404.16966v1)|null|
|**2024-04-25**|**A Closer Look at Classification Evaluation Metrics and a Critical Reflection of Common Evaluation Practice**|Juri Opitz et.al.|[2404.16958v1](http://arxiv.org/abs/2404.16958v1)|null|
|**2024-04-25**|**Taming False Positives in Out-of-Distribution Detection with Human Feedback**|Harit Vishwakarma et.al.|[2404.16954v1](http://arxiv.org/abs/2404.16954v1)|[link](https://github.com/2454511550lin/tamefalsepositives-ood)|
|**2024-04-25**|**Make-it-Real: Unleashing Large Multimodal Model's Ability for Painting 3D Objects with Realistic Materials**|Ye Fang et.al.|[2404.16829v1](http://arxiv.org/abs/2404.16829v1)|null|
|**2024-04-25**|**A Survey of Generative Search and Recommendation in the Era of Large Language Models**|Yongqi Li et.al.|[2404.16924v1](http://arxiv.org/abs/2404.16924v1)|null|
|**2024-04-25**|**IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages**|Harman Singh et.al.|[2404.16816v1](http://arxiv.org/abs/2404.16816v1)|null|
|**2024-04-25**|**Make Your LLM Fully Utilize the Context**|Shengnan An et.al.|[2404.16811v2](http://arxiv.org/abs/2404.16811v2)|[link](https://github.com/microsoft/FILM)|
|**2024-04-25**|**Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning**|Tianhui Zhang et.al.|[2404.16807v1](http://arxiv.org/abs/2404.16807v1)|null|
|**2024-04-25**|**A Short Survey of Human Mobility Prediction in Epidemic Modeling from Transformers to LLMs**|Christian N. Mayemba et.al.|[2404.16921v1](http://arxiv.org/abs/2404.16921v1)|null|
|**2024-04-25**|**AAPL: Adding Attributes to Prompt Learning for Vision-Language Models**|Gahyeon Kim et.al.|[2404.16804v1](http://arxiv.org/abs/2404.16804v1)|[link](https://github.com/Gahyeonkim09/AAPL)|
|**2024-04-25**|**Weak-to-Strong Extrapolation Expedites Alignment**|Chujie Zheng et.al.|[2404.16792v1](http://arxiv.org/abs/2404.16792v1)|[link](https://github.com/chujiezheng/llm-extrapolation)|
|**2024-04-25**|**Continual Learning of Large Language Models: A Comprehensive Survey**|Haizhou Shi et.al.|[2404.16789v1](http://arxiv.org/abs/2404.16789v1)|[link](https://github.com/wang-ml-lab/llm-continual-learning-survey)|
|**2024-04-25**|**Modeling Selective Feature Attention for Representation-based Siamese Text Matching**|Jianxiang Zang et.al.|[2404.16776v1](http://arxiv.org/abs/2404.16776v1)|[link](https://github.com/hggzjx/sfa)|
|**2024-04-25**|**REBEL: Reinforcement Learning via Regressing Relative Rewards**|Zhaolin Gao et.al.|[2404.16767v1](http://arxiv.org/abs/2404.16767v1)|null|
|**2024-04-25**|**Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation Language Model**|Runzhe Zhan et.al.|[2404.16766v1](http://arxiv.org/abs/2404.16766v1)|null|
|**2024-04-25**|**Automatic Speech Recognition System-Independent Word Error Rate Estimation**|Chanho Park et.al.|[2404.16743v2](http://arxiv.org/abs/2404.16743v2)|null|
|**2024-04-25**|**Distilling Privileged Information for Dubins Traveling Salesman Problems with Neighborhoods**|Min Kyu Shin et.al.|[2404.16721v1](http://arxiv.org/abs/2404.16721v1)|null|
|**2024-04-25**|**Features Fusion for Dual-View Mammography Mass Detection**|Arina Varlamova et.al.|[2404.16718v1](http://arxiv.org/abs/2404.16718v1)|null|
|**2024-04-25**|**Embracing Diversity: Interpretable Zero-shot classification beyond one vector per class**|Mazda Moayeri et.al.|[2404.16717v1](http://arxiv.org/abs/2404.16717v1)|null|
|**2024-04-25**|**Layer Skip: Enabling Early Exit Inference and Self-Speculative Decoding**|Mostafa Elhoushi et.al.|[2404.16710v1](http://arxiv.org/abs/2404.16710v1)|null|
|**2024-04-25**|**Cooperate or Collapse: Emergence of Sustainability Behaviors in a Society of LLM Agents**|Giorgio Piatti et.al.|[2404.16698v1](http://arxiv.org/abs/2404.16698v1)|null|
|**2024-04-25**|**Influence of Solution Efficiency and Valence of Instruction on Additive and Subtractive Solution Strategies in Humans and GPT-4**|Lydia Uhler et.al.|[2404.16692v1](http://arxiv.org/abs/2404.16692v1)|null|
|**2024-04-25**|**Prediction Is All MoE Needs: Expert Load Distribution Goes from Fluctuating to Stabilizing**|Peizhuang Cong et.al.|[2404.16914v1](http://arxiv.org/abs/2404.16914v1)|null|
|**2024-04-25**|**DE-CGAN: Boosting rTMS Treatment Prediction with Diversity Enhancing Conditional Generative Adversarial Networks**|Matthew Squires et.al.|[2404.16913v1](http://arxiv.org/abs/2404.16913v1)|null|
|**2024-04-25**|**EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning**|Hongxia Xie et.al.|[2404.16670v1](http://arxiv.org/abs/2404.16670v1)|[link](https://github.com/aimmemotion/emovit)|
|**2024-04-25**|**Formal Specification, Assessment, and Enforcement of Fairness for Generative AIs**|Chih-Hong Cheng et.al.|[2404.16663v2](http://arxiv.org/abs/2404.16663v2)|[link](https://github.com/semta-group/fairgenai)|
|**2024-04-25**|**Benchmarking Mobile Device Control Agents across Diverse Configurations**|Juyong Lee et.al.|[2404.16660v1](http://arxiv.org/abs/2404.16660v1)|null|
|**2024-04-25**|**ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling**|Sangryul Kim et.al.|[2404.16659v1](http://arxiv.org/abs/2404.16659v1)|[link](https://github.com/venzino-han/probgate_ehrsql)|
|**2024-04-25**|**A Self-Organizing Clustering System for Unsupervised Distribution Shift Detection**|Sebastián Basterrech et.al.|[2404.16656v1](http://arxiv.org/abs/2404.16656v1)|null|
|**2024-04-25**|**Análise de ambiguidade linguística em modelos de linguagem de grande escala (LLMs)**|Lavínia de Carvalho Moraes et.al.|[2404.16653v1](http://arxiv.org/abs/2404.16653v1)|null|
|**2024-04-25**|**Tele-FLM Technical Report**|Xiang Li et.al.|[2404.16645v1](http://arxiv.org/abs/2404.16645v1)|null|
|**2024-04-25**|**Legal Aspects for Software Developers Interested in Generative AI Applications**|Steffen Herbold et.al.|[2404.16630v1](http://arxiv.org/abs/2404.16630v1)|null|
|**2024-04-25**|**Incorporating Lexical and Syntactic Knowledge for Unsupervised Cross-Lingual Transfer**|Jianyu Zheng et.al.|[2404.16627v1](http://arxiv.org/abs/2404.16627v1)|[link](https://github.com/tian14267/ls_mbert)|
|**2024-04-25**|**Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**|Emre Can Acikgoz et.al.|[2404.16621v1](http://arxiv.org/abs/2404.16621v1)|null|
|**2024-04-25**|**SFMViT: SlowFast Meet ViT in Chaotic World**|Jiaying Lin et.al.|[2404.16609v1](http://arxiv.org/abs/2404.16609v1)|[link](https://github.com/jfightyr/slowfast-meet-vit)|
|**2024-04-25**|**Understanding Privacy Risks of Embeddings Induced by Large Language Models**|Zhihao Zhu et.al.|[2404.16587v1](http://arxiv.org/abs/2404.16587v1)|null|
|**2024-04-25**|**Neural Interaction Energy for Multi-Agent Trajectory Prediction**|Kaixin Shen et.al.|[2404.16579v1](http://arxiv.org/abs/2404.16579v1)|null|
|**2024-04-25**|**Exploring Internal Numeracy in Language Models: A Case Study on ALBERT**|Ulme Wennberg et.al.|[2404.16574v1](http://arxiv.org/abs/2404.16574v1)|null|
|**2024-04-25**|**Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark**|Elizabeth Fons et.al.|[2404.16563v1](http://arxiv.org/abs/2404.16563v1)|null|
|**2024-04-25**|**Evolve Cost-aware Acquisition Functions Using Large Language Models**|Yiming Yao et.al.|[2404.16906v1](http://arxiv.org/abs/2404.16906v1)|null|
|**2024-04-25**|**DeepKalPose: An Enhanced Deep-Learning Kalman Filter for Temporally Consistent Monocular Vehicle Pose Estimation**|Leandro Di Bella et.al.|[2404.16558v1](http://arxiv.org/abs/2404.16558v1)|null|
|**2024-04-25**|**Energy-Latency Manipulation of Multi-modal Large Language Models via Verbose Samples**|Kuofeng Gao et.al.|[2404.16557v1](http://arxiv.org/abs/2404.16557v1)|null|
|**2024-04-25**|**Developing Acoustic Models for Automatic Speech Recognition in Swedish**|Giampiero Salvi et.al.|[2404.16547v1](http://arxiv.org/abs/2404.16547v1)|null|
|**2024-04-25**|**Samsung Research China-Beijing at SemEval-2024 Task 3: A multi-stage framework for Emotion-Cause Pair Extraction in Conversations**|Shen Zhang et.al.|[2404.16905v1](http://arxiv.org/abs/2404.16905v1)|null|
|**2024-04-25**|**SIDEs: Separating Idealization from Deceptive Explanations in xAI**|Emily Sullivan et.al.|[2404.16534v1](http://arxiv.org/abs/2404.16534v1)|null|
|**2024-04-25**|**Global Concept Explanations for Graphs by Contrastive Learning**|Jonas Teufel et.al.|[2404.16532v1](http://arxiv.org/abs/2404.16532v1)|[link](https://github.com/aimat-lab/megan_global_explanations)|
|**2024-04-25**|**Building a Japanese Document-Level Relation Extraction Dataset Assisted by Cross-Lingual Transfer**|Youmi Ma et.al.|[2404.16506v1](http://arxiv.org/abs/2404.16506v1)|null|

#### Abstracts
##### **Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo**
2404.17546v1 by Stephen Zhao et.al.

Numerous capability and safety techniques of Large Language Models (LLMs),
including RLHF, automated red-teaming, prompt engineering, and infilling, can
be cast as sampling from an unnormalized target distribution defined by a given
reward or potential function over the full sequence. In this work, we leverage
the rich toolkit of Sequential Monte Carlo (SMC) for these probabilistic
inference problems. In particular, we use learned twist functions to estimate
the expected future value of the potential at each timestep, which enables us
to focus inference-time computation on promising partial sequences. We propose
a novel contrastive method for learning the twist functions, and establish
connections with the rich literature of soft reinforcement learning. As a
complementary application of our twisted SMC framework, we present methods for
evaluating the accuracy of language model inference techniques using novel
bidirectional SMC bounds on the log partition function. These bounds can be
used to estimate the KL divergence between the inference and target
distributions in both directions. We apply our inference evaluation techniques
to show that twisted SMC is effective for sampling undesirable outputs from a
pretrained model (a useful component of harmlessness training and automated
red-teaming), generating reviews with varied sentiment, and performing
infilling tasks.

摘要：大型語言模型 (LLM) 的眾多功能和安全技術，
包括 RLHF、自動紅隊、即時工程和填充，可以
被轉換為從給定定義的非標準化目標分佈中取樣
整個序列的獎勵或潛在函數。在這項工作中，我們利用
序列蒙特卡羅 (SMC) 的豐富工具包適用於這些機率
推理問題。特別是，我們使用學習的扭曲函數來估計
每個時間步的潛力的預期未來值，這使我們能夠
將推理時間計算集中在有希望的部分序列上。我們建議
一種新穎的對比方法來學習扭曲函數，並建立
與軟強化學習的豐富文獻的連結。作為一個
我們的扭曲 SMC 框架的補充應用，我們提出了以下方法：
使用新穎的方法評估語言模型推理技術的準確性
日誌分區功能上的雙向 SMC 邊界。這些界限可以是
用於估計推理與目標之間的 KL 散度
兩個方向的分佈。我們應用我們的推理評估技術
證明扭曲的 SMC 對於從不期望的輸出中採樣是有效的
預訓練模型（無害訓練和自動化的有用組成部分
紅隊），產生具有不同情緒的評論，並執行
填充任務。

##### **Large Language Model Agent as a Mechanical Designer**
2404.17525v1 by Yayati Jadhav et.al.

Conventional mechanical design paradigms rely on experts systematically
refining concepts through experience-guided modification and FEA to meet
specific requirements. However, this approach can be time-consuming and heavily
dependent on prior knowledge and experience. While numerous machine learning
models have been developed to streamline this intensive and expert-driven
iterative process, these methods typically demand extensive training data and
considerable computational resources. Furthermore, methods based on deep
learning are usually restricted to the specific domains and tasks for which
they were trained, limiting their applicability across different tasks. This
creates a trade-off between the efficiency of automation and the demand for
resources. In this study, we present a novel approach that integrates
pre-trained LLMs with a FEM module. The FEM module evaluates each design and
provides essential feedback, guiding the LLMs to continuously learn, plan,
generate, and optimize designs without the need for domain-specific training.
We demonstrate the effectiveness of our proposed framework in managing the
iterative optimization of truss structures, showcasing its capability to reason
about and refine designs according to structured feedback and criteria. Our
results reveal that these LLM-based agents can successfully generate truss
designs that comply with natural language specifications with a success rate of
up to 90%, which varies according to the applied constraints. By employing
prompt-based optimization techniques we show that LLM based agents exhibit
optimization behavior when provided with solution-score pairs to iteratively
refine designs to meet specifications. This ability of LLM agents to produce
viable designs and optimize them based on their inherent reasoning capabilities
highlights their potential to develop and implement effective design strategies
autonomously.

摘要：傳統的機械設計範式依賴專家系統
透過經驗引導的修改和有限元素分析來完善概念，以滿足
具體要求。然而，這種方法可能非常耗時且繁重
依賴先前的知識和經驗。雖然大量的機器學習
已經發展出模型來簡化這種密集且由專家驅動的過程
迭代過程，這些方法通常需要大量的訓練資料和
大量的運算資源。此外，基於深度學習的方法
學習通常僅限於特定領域和任務
他們接受過培訓，限制了他們在不同任務中的適用性。這
在自動化效率和需求之間進行權衡
資源。在這項研究中，我們提出了一種新穎的方法，該方法整合了
具有 FEM 模組的預訓練法學碩士。 FEM 模組評估每個設計並
提供重要的回饋，指導法學碩士不斷學習、規劃、
無需特定領域的培訓即可產生和優化設計。
我們證明了我們提出的框架在管理
桁架結構的迭代優化，展現其推理能力
根據結構化回饋和標準來了解和完善設計。我們的
結果顯示這些基於 LLM 的代理可以成功生成桁架
符合自然語言規範的設計，成功率
高達 90%，取決於所應用的約束。透過僱用
基於提示的最佳化技術，我們表明基於 LLM 的代理程式表現出
當提供解決方案分數對以迭代時的最佳化行為
完善設計以滿足規格。 LLM代理的這種能力可以產生
可行的設計並根據其固有的推理能力對其進行優化
強調他們制定和實施有效設計策略的潛力
自主地。

##### **On the Use of Large Language Models to Generate Capability Ontologies**
2404.17524v1 by Luis Miguel Vieira da Silva et.al.

Capability ontologies are increasingly used to model functionalities of
systems or machines. The creation of such ontological models with all
properties and constraints of capabilities is very complex and can only be done
by ontology experts. However, Large Language Models (LLMs) have shown that they
can generate machine-interpretable models from natural language text input and
thus support engineers / ontology experts. Therefore, this paper investigates
how LLMs can be used to create capability ontologies. We present a study with a
series of experiments in which capabilities with varying complexities are
generated using different prompting techniques and with different LLMs. Errors
in the generated ontologies are recorded and compared. To analyze the quality
of the generated ontologies, a semi-automated approach based on RDF syntax
checking, OWL reasoning, and SHACL constraints is used. The results of this
study are very promising because even for complex capabilities, the generated
ontologies are almost free of errors.

摘要：能力本體越來越多地用於建模功能
系統或機器。這種本體論模型的創建與所有
能力的屬性和限制非常複雜，只能做
由本體專家。然而，大型語言模型（LLM）已經表明它們
可以從自然語言文字輸入生成機器可解釋的模型
從而支援工程師/本體專家。因此，本文研究
如何使用法學碩士來創造能力本體。我們提出了一項研究
一系列實驗，其中具有不同複雜性的能力
使用不同的提示技術和不同的法學碩士生成。錯誤
在產生的本體中進行記錄和比較。來分析質量
產生的本體，一種基於 RDF 語法的半自動化方法
使用檢查、OWL 推理和 SHACL 限制。這樣做的結果
研究非常有前途，因為即使對於複雜的能力，產生的
本體幾乎沒有錯誤。

##### **Enhancing Legal Compliance and Regulation Analysis with Large Language Models**
2404.17522v1 by Shabnam Hassani et.al.

This research explores the application of Large Language Models (LLMs) for
automating the extraction of requirement-related legal content in the food
safety domain and checking legal compliance of regulatory artifacts. With
Industry 4.0 revolutionizing the food industry and with the General Data
Protection Regulation (GDPR) reshaping privacy policies and data processing
agreements, there is a growing gap between regulatory analysis and recent
technological advancements. This study aims to bridge this gap by leveraging
LLMs, namely BERT and GPT models, to accurately classify legal provisions and
automate compliance checks. Our findings demonstrate promising results,
indicating LLMs' significant potential to enhance legal compliance and
regulatory analysis efficiency, notably by reducing manual workload and
improving accuracy within reasonable time and financial constraints.

摘要：本研究探討了大型語言模型（LLM）在以下方面的應用：
自動提取食品中與要求相關的法律內容
安全領域並檢查監管工件的合法性。和
工業 4.0 透過通用數據徹底改變食品產業
保護規範 (GDPR) 重塑隱私權政策和資料處理
協議中，監管分析與最近的分析之間的差距越來越大
技術進步。本研究旨在透過利用
LLM，即 BERT 和 GPT 模型，用於準確分類法律條款和
自動化合規性檢查。我們的研究結果證明了有希望的結果，
表明法學碩士在增強法律合規性和
監管分析效率，特別是透過減少人工工作量和
在合理的時間和財務限制內提高準確性。

##### **A Comprehensive Evaluation on Event Reasoning of Large Language Models**
2404.17513v1 by Zhengwei Tao et.al.

Event reasoning is a fundamental ability that underlies many applications. It
requires event schema knowledge to perform global reasoning and needs to deal
with the diversity of the inter-event relations and the reasoning paradigms.
How well LLMs accomplish event reasoning on various relations and reasoning
paradigms remains unknown. To mitigate this disparity, we comprehensively
evaluate the abilities of event reasoning of LLMs. We introduce a novel
benchmark EV2 for EValuation of EVent reasoning. EV2 consists of two levels of
evaluation of schema and instance and is comprehensive in relations and
reasoning paradigms. We conduct extensive experiments on EV2. We find that LLMs
have abilities to accomplish event reasoning but their performances are far
from satisfactory. We also notice the imbalance of event reasoning abilities in
LLMs. Besides, LLMs have event schema knowledge, however, they're not aligned
with humans on how to utilize the knowledge. Based on these findings, we
introduce two methods to guide the LLMs to utilize the event schema knowledge.
Both methods achieve improvements.

摘要：事件推理是許多應用程式的基礎能力。它
需要事件模式知識來執行全域推理並需要處理
事件間關係和推理範式的多樣性。
法學碩士如何完成各種關係和推理的事件推理
範式仍然未知。為了縮小這種差距，我們全面
評估法學碩士的事件推理能力。我們介紹一本小說
用於評估事件推理的基準 EV2。 EV2 由兩個等級組成
圖式和實例的評估，在關係和關係方面是全面性的
推理範式。我們對 EV2 進行了廣泛的實驗。我們發現法學碩士
有完成事件推理的能力，但表現差得很遠
從滿意。我們也注意到事件推理能力的不平衡
法學碩士。此外，法學碩士擁有事件模式知識，但是，它們並不一致
與人類討論如何利用這些知識。基於這些發現，我們
介紹兩種方法來指導法學碩士利用事件模式知識。
兩種方法都取得了改進。

##### **Causally Abstracted Multi-armed Bandits**
2404.17493v1 by Fabio Massimo Zennaro et.al.

Multi-armed bandits (MAB) and causal MABs (CMAB) are established frameworks
for decision-making problems. The majority of prior work typically studies and
solves individual MAB and CMAB in isolation for a given problem and associated
data. However, decision-makers are often faced with multiple related problems
and multi-scale observations where joint formulations are needed in order to
efficiently exploit the problem structures and data dependencies. Transfer
learning for CMABs addresses the situation where models are defined on
identical variables, although causal connections may differ. In this work, we
extend transfer learning to setups involving CMABs defined on potentially
different variables, with varying degrees of granularity, and related via an
abstraction map. Formally, we introduce the problem of causally abstracted MABs
(CAMABs) by relying on the theory of causal abstraction in order to express a
rigorous abstraction map. We propose algorithms to learn in a CAMAB, and study
their regret. We illustrate the limitations and the strengths of our algorithms
on a real-world scenario related to online advertising.

摘要：多臂老虎機 (MAB) 和因果 MAB (CMAB) 已建立框架
對於決策問題。大多數先前的工作通常是研究和
針對給定問題和相關問題單獨解決單一 MAB 和 CMAB
數據。然而，決策者經常面臨多個相關問題
以及需要聯合製定的多尺度觀測
有效地利用問題結構和資料依賴性。轉移
CMAB 的學習解決了模型定義的情況
儘管因果關係可能不同，但變數相同。在這項工作中，我們
將遷移學習擴展到涉及潛在定義的 CMAB 的設置
不同的變量，具有不同的粒度，並通過
抽象圖。正式地，我們介紹了因果抽象 MAB 的問題
（CAMAB）依賴因果抽象理論來表達
嚴格的抽象圖。我們提出了在 CAMAB 中學習的演算法，並研究
他們的遺憾。我們說明了我們演算法的限制和優點
與線上廣告相關的現實場景。

##### **Tabular Data Contrastive Learning via Class-Conditioned and Feature-Correlation Based Augmentation**
2404.17489v1 by Wei Cui et.al.

Contrastive learning is a model pre-training technique by first creating
similar views of the original data, and then encouraging the data and its
corresponding views to be close in the embedding space. Contrastive learning
has witnessed success in image and natural language data, thanks to the
domain-specific augmentation techniques that are both intuitive and effective.
Nonetheless, in tabular domain, the predominant augmentation technique for
creating views is through corrupting tabular entries via swapping values, which
is not as sound or effective. We propose a simple yet powerful improvement to
this augmentation technique: corrupting tabular data conditioned on class
identity. Specifically, when corrupting a specific tabular entry from an anchor
row, instead of randomly sampling a value in the same feature column from the
entire table uniformly, we only sample from rows that are identified to be
within the same class as the anchor row. We assume the semi-supervised learning
setting, and adopt the pseudo labeling technique for obtaining class identities
over all table rows. We also explore the novel idea of selecting features to be
corrupted based on feature correlation structures. Extensive experiments show
that the proposed approach consistently outperforms the conventional corruption
method for tabular data classification tasks. Our code is available at
https://github.com/willtop/Tabular-Class-Conditioned-SSL.

摘要：對比學習是一種模型預訓練技術，首先創建
原始數據的相似觀點，然後鼓勵數據及其
相應的視圖在嵌入空間中接近。對比學習
見證了圖像和自然語言數據的成功，這要歸功於
既直觀又有效的特定領域增強技術。
儘管如此，在表格領域，主要的增強技術
建立視圖是透過交換值來破壞表格條目，這
不那麼健全或有效。我們提出了一個簡單而強大的改進
這種增強技術：破壞以類別為條件的表格數據
身份。具體來說，當破壞錨點中的特定表格條目時
行，而不是從同一特徵列中隨機取樣一個值
整個表統一，我們只從被識別為的行中採樣
與錨行位於同一類別中。我們假設半監督學習
設置，並採用偽標籤技術取得類別標識
覆蓋所有表行。我們也探索了選擇特徵的新穎想法
基於特徵相關結構的損壞。大量實驗表明
所提出的方法始終優於傳統的腐敗方法
表格資料分類任務的方法。我們的程式碼位於
https://github.com/willtop/Tabular-Class-Conditioned-SSL。

##### **Conformal Prediction with Learned Features**
2404.17487v1 by Shayan Kiyani et.al.

In this paper, we focus on the problem of conformal prediction with
conditional guarantees. Prior work has shown that it is impossible to construct
nontrivial prediction sets with full conditional coverage guarantees. A wealth
of research has considered relaxations of full conditional guarantees, relying
on some predefined uncertainty structures. Departing from this line of
thinking, we propose Partition Learning Conformal Prediction (PLCP), a
framework to improve conditional validity of prediction sets through learning
uncertainty-guided features from the calibration data. We implement PLCP
efficiently with alternating gradient descent, utilizing off-the-shelf machine
learning models. We further analyze PLCP theoretically and provide conditional
guarantees for infinite and finite sample sizes. Finally, our experimental
results over four real-world and synthetic datasets show the superior
performance of PLCP compared to state-of-the-art methods in terms of coverage
and length in both classification and regression scenarios.

摘要：在本文中，我們將重點放在共形預測問題
有條件的保證。先前的工作表明不可能構建
具有完全條件覆蓋保證的重要預測集。一筆財富
的研究考慮放寬完全有條件的保證，依賴
一些預先定義的不確定性結構。從這條線出發
思考，我們提出分區學習保形預測（PLCP），
透過學習提高預測集條件有效性的框架
來自校準資料的不確定性引導特徵。我們實作PLCP
利用現成的機器，透過交替梯度下降有效地
學習模型。我們進一步從理論上分析了PLCP並給出了條件
保證無限和有限的樣本量。最後我們的實驗
四個真實世界和合成資料集的結果顯示出優越性
PLCP 與最先進方法在覆蓋範圍方面的效能比較
以及分類和回歸場景中的長度。

##### **ReproHum #0087-01: Human Evaluation Reproduction Report for Generating Fact Checking Explanations**
2404.17481v1 by Tyler Loakman et.al.

This paper presents a partial reproduction of Generating Fact Checking
Explanations by Anatanasova et al (2020) as part of the ReproHum element of the
ReproNLP shared task to reproduce the findings of NLP research regarding human
evaluation. This shared task aims to investigate the extent to which NLP as a
field is becoming more or less reproducible over time. Following the
instructions provided by the task organisers and the original authors, we
collect relative rankings of 3 fact-checking explanations (comprising a gold
standard and the outputs of 2 models) for 40 inputs on the criteria of
Coverage. The results of our reproduction and reanalysis of the original work's
raw results lend support to the original findings, with similar patterns seen
between the original work and our reproduction. Whilst we observe slight
variation from the original results, our findings support the main conclusions
drawn by the original authors pertaining to the efficacy of their proposed
models.

摘要：本文提出了產生事實檢查的部分複製
Anatanasova 等人 (2020) 的解釋作為 ReproHum 元素的一部分
ReproNLP 共享任務來重現有關人類的 NLP 研究結果
評估。這項共同任務旨在調查 NLP 作為一種方法的程度
隨著時間的推移，該領域的可重複性越來越強。繼
根據任務組織者和原作者提供的說明，我們
收集 3 個事實查核解釋的相對排名（包括黃金
標準和 2 個模型的輸出），根據以下標準有 40 個輸入
覆蓋範圍。我們對原作進行複製和重新分析的結果
原始結果支持了最初的發現，並且看到了類似的模式
在原作和我們的複製品之間。雖然我們觀察到輕微
與原始結果的差異，我們的發現支持主要結論
由原作者繪製的有關其提議的功效的圖
楷模。

##### **CEval: A Benchmark for Evaluating Counterfactual Text Generation**
2404.17475v1 by Van Bach Nguyen et.al.

Counterfactual text generation aims to minimally change a text, such that it
is classified differently. Judging advancements in method development for
counterfactual text generation is hindered by a non-uniform usage of data sets
and metrics in related work. We propose CEval, a benchmark for comparing
counterfactual text generation methods. CEval unifies counterfactual and text
quality metrics, includes common counterfactual datasets with human
annotations, standard baselines (MICE, GDBA, CREST) and the open-source
language model LLAMA-2. Our experiments found no perfect method for generating
counterfactual text. Methods that excel at counterfactual metrics often produce
lower-quality text while LLMs with simple prompts generate high-quality text
but struggle with counterfactual criteria. By making CEval available as an
open-source Python library, we encourage the community to contribute more
methods and maintain consistent evaluation in future work.

摘要：反事實文本生成旨在最小程度地改變文本，以便它
分類不同。判斷方法開發的進展
資料集的不統一使用阻礙了反事實文本的生成
以及相關工作中的指標。我們提出CEval，一個比較基準
反事實文本生成方法。 CEval 統一了反事實和文本
品質指標，包括與人類共同的反事實資料集
註解、標準基線（MICE、GBBA、CREST）和開源
語言模型 LLAMA-2。我們的實驗並沒有發現完美的生成方法
反事實文本。擅長反事實指標的方法通常會產生
低品質的文本，而帶有簡單提示的法學碩士生成高品質的文本
但與反事實標準作鬥爭。透過將 CEval 提供為
開源Python庫，我們鼓勵社群做出更多貢獻
方法並在今後的工作中保持一致的評價。

##### **Ruffle&Riley: Insights from Designing and Evaluating a Large Language Model-Based Conversational Tutoring System**
2404.17460v1 by Robin Schmucker et.al.

Conversational tutoring systems (CTSs) offer learning experiences through
interactions based on natural language. They are recognized for promoting
cognitive engagement and improving learning outcomes, especially in reasoning
tasks. Nonetheless, the cost associated with authoring CTS content is a major
obstacle to widespread adoption and to research on effective instructional
design. In this paper, we discuss and evaluate a novel type of CTS that
leverages recent advances in large language models (LLMs) in two ways: First,
the system enables AI-assisted content authoring by inducing an easily editable
tutoring script automatically from a lesson text. Second, the system automates
the script orchestration in a learning-by-teaching format via two LLM-based
agents (Ruffle&Riley) acting as a student and a professor. The system allows
for free-form conversations that follow the ITS-typical inner and outer loop
structure. We evaluate Ruffle&Riley's ability to support biology lessons in two
between-subject online user studies (N = 200) comparing the system to simpler
QA chatbots and reading activity. Analyzing system usage patterns,
pre/post-test scores and user experience surveys, we find that Ruffle&Riley
users report high levels of engagement, understanding and perceive the offered
support as helpful. Even though Ruffle&Riley users require more time to
complete the activity, we did not find significant differences in short-term
learning gains over the reading activity. Our system architecture and user
study provide various insights for designers of future CTSs. We further
open-source our system to support ongoing research on effective instructional
design of LLM-based learning technologies.

摘要：對話式輔導系統 (CTS) 透過以下方式提供學習體驗
基於自然語言的互動。他們因促進
認知參與和改善學習成果，尤其是推理方面
任務。儘管如此，創作 CTS 內容相關的成本是一個主要的成本。
廣泛採用和有效教學研究的障礙
設計。在本文中，我們討論並評估了一種新型的 CTS，
透過兩種方式利用大型語言模型 (LLM) 的最新進展：首先，
該系統透過引入易於編輯的內容來實現人工智慧輔助內容創作
根據課程文字自動輔導腳本。二、系統自動化
透過兩個基於法學碩士的課程以邊學邊學的方式編排腳本
特工（Ruffle&Riley）扮演學生和教授。系統允許
用於遵循 ITS 典型內循環和外循環的自由形式對話
結構。我們從兩個方面評估 Ruffle&Riley 支持生物課程的能力
受試者間線上使用者研究 (N = 200) 將系統與更簡單的系統進行比較
QA 聊天機器人和閱讀活動。分析系統使用模式，
測試前/測試後分數和使用者體驗調查，我們發現 Ruffle&Riley
使用者表示高度參與、理解和感知所提供的服務
支持有幫助。儘管 Ruffle&Riley 用戶需要更多時間
完成活動後，我們沒有發現短期的顯著差異
學習收穫超過閱讀活動。我們的系統架構和用戶
研究為未來 CTS 的設計者提供了各種見解。我們進一步
開源我們的系統以支援正在進行的有效教學研究
基於法學碩士的學習技術的設計。

##### **Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond**
2404.17454v1 by Kaichen Xu et.al.

Fined-grained anomalous cell detection from affected tissues is critical for
clinical diagnosis and pathological research. Single-cell sequencing data
provide unprecedented opportunities for this task. However, current anomaly
detection methods struggle to handle domain shifts prevalent in multi-sample
and multi-domain single-cell sequencing data, leading to suboptimal
performance. Moreover, these methods fall short of distinguishing anomalous
cells into pathologically distinct subtypes. In response, we propose ACSleuth,
a novel, reconstruction deviation-guided generative framework that integrates
the detection, domain adaptation, and fine-grained annotating of anomalous
cells into a methodologically cohesive workflow. Notably, we present the first
theoretical analysis of using reconstruction deviations output by generative
models for anomaly detection in lieu of domain shifts. This analysis informs us
to develop a novel and superior maximum mean discrepancy-based anomaly scorer
in ACSleuth. Extensive benchmarks over various single-cell data and other types
of tabular data demonstrate ACSleuth's superiority over the state-of-the-art
methods in identifying and subtyping anomalies in multi-sample and multi-domain
contexts. Our code is available at https://github.com/Catchxu/ACsleuth.

摘要：從受影響的組織中進行細粒度異常細胞檢測對於
臨床診斷和病理研究。單細胞定序數據
為這項任務提供了前所未有的機會。然而，目前的異常情況
檢測方法難以處理多樣本中普遍存在的域轉移
和多域單細胞定序數據，導致次優
表現。此外，這些方法無法區分異常
細胞分為病理上不同的亞型。作為回應，我們建議 ACSleuth，
一種新穎的、重建偏差引導的生成框架，整合了
異常的檢測、領域適應和細粒度註釋
細胞進入一個方法上有凝聚力的工作流程。值得注意的是，我們提出了第一個
利用生成式輸出重構偏差的理論分析
用於代替域轉移的異常檢測模型。這項分析告訴我們
開發一種新穎且卓越的基於最大平均差異的異常評分器
在 ACSleuth 中。針對各種單細胞數據和其他類型的廣泛基準
表格數據證明 ACSleuth 優於最先進的技術
多樣本和多域中的異常識別和分型方法
上下文。我們的程式碼可在 https://github.com/Catchxu/ACsleuth 取得。

##### **"ChatGPT Is Here to Help, Not to Replace Anybody" -- An Evaluation of Students' Opinions On Integrating ChatGPT In CS Courses**
2404.17443v1 by Bruno Pereira Cipriano et.al.

Large Language Models (LLMs) like GPT and Bard are capable of producing code
based on textual descriptions, with remarkable efficacy. Such technology will
have profound implications for computing education, raising concerns about
cheating, excessive dependence, and a decline in computational thinking skills,
among others. There has been extensive research on how teachers should handle
this challenge but it is also important to understand how students feel about
this paradigm shift. In this research, 52 first-year CS students were surveyed
in order to assess their views on technologies with code-generation
capabilities, both from academic and professional perspectives. Our findings
indicate that while students generally favor the academic use of GPT, they
don't over rely on it, only mildly asking for its help. Although most students
benefit from GPT, some struggle to use it effectively, urging the need for
specific GPT training. Opinions on GPT's impact on their professional lives
vary, but there is a consensus on its importance in academic practice.

摘要：GPT 和 Bard 等大型語言模型 (LLM) 能夠產生程式碼
基於文字描述，功效顯著。此類技術將
對電腦教育產生深遠影響，引起人們的擔憂
作弊、過度依賴和計算思維能力下降，
除其他外。關於教師應如何處理問題，已有廣泛的研究。
這是一項挑戰，但了解學生的感受也很重要
這種範式轉變。在這項研究中，52 名一年級電腦科學學生接受了調查
為了評估他們對程式碼生成技術的看法
能力，無論是從學術或專業的角度。我們的發現
顯示雖然學生普遍贊成 GPT 的學術用途，但他們
不要過度依賴它，只是溫和地尋求它的幫助。雖然大多數學生
從 GPT 中受益，但有些人很難有效地使用它，因此迫切需要
特定的 GPT 培訓。關於 GPT 對職涯影響的看法
雖然各不相同，但人們對其在學術實踐中的重要性達成了共識。

##### **Real-World Deployment of a Hierarchical Uncertainty-Aware Collaborative Multiagent Planning System**
2404.17438v1 by Martina Stadler Kurtz et.al.

We would like to enable a collaborative multiagent team to navigate at long
length scales and under uncertainty in real-world environments. In practice,
planning complexity scales with the number of agents in the team, with the
length scale of the environment, and with environmental uncertainty. Enabling
tractable planning requires developing abstract models that can represent
complex, high-quality plans. However, such models often abstract away
information needed to generate directly-executable plans for real-world agents
in real-world environments, as planning in such detail, especially in the
presence of real-world uncertainty, would be computationally intractable. In
this paper, we describe the deployment of a planning system that used a
hierarchy of planners to execute collaborative multiagent navigation tasks in
real-world, unknown environments. By developing a planning system that was
robust to failures at every level of the planning hierarchy, we enabled the
team to complete collaborative navigation tasks, even in the presence of
imperfect planning abstractions and real-world uncertainty. We deployed our
approach on a Clearpath Husky-Jackal team navigating in a structured outdoor
environment, and demonstrated that the system enabled the agents to
successfully execute collaborative plans.

摘要：我們希望讓協作的多智能體團隊能夠長時間導航
長度尺度和現實環境中的不確定性。在實踐中，
規劃的複雜性隨著團隊中代理人的數量而變化
環境的長度尺度，以及環境的不確定性。啟用
易於處理的規劃需要開發可以表示的抽像模型
複雜、高品質的計劃。然而，這樣的模型通常會抽象掉
為現實世界的代理程式產生直接可執行計劃所需的信息
在現實環境中，需要進行如此詳細的規劃，尤其是在
現實世界的不確定性的存在，在計算上將是困難的。在
在本文中，我們描述了一個計劃系統的部署，該系統使用
執行協作多智能體導航任務的規劃器層次結構
現實世界，未知的環境。透過開發一個規劃系統
在規劃層次結構的每個層級上，我們都能夠抵禦故障，因此我們啟用了
團隊完成協作導航任務，即使在存在的情況下
不完美的規劃抽象與現實世界的不確定性。我們部署了我們的
Clearpath Husky-Jackal 團隊在結構化戶外導航的方法
環境，並證明該系統使代理能夠
成功執行協作計劃。

##### **Evaluation of Geographical Distortions in Language Models: A Crucial Step Towards Equitable Representations**
2404.17401v1 by Rémy Decoupes et.al.

Language models now constitute essential tools for improving efficiency for
many professional tasks such as writing, coding, or learning. For this reason,
it is imperative to identify inherent biases. In the field of Natural Language
Processing, five sources of bias are well-identified: data, annotation,
representation, models, and research design. This study focuses on biases
related to geographical knowledge. We explore the connection between geography
and language models by highlighting their tendency to misrepresent spatial
information, thus leading to distortions in the representation of geographical
distances. This study introduces four indicators to assess these distortions,
by comparing geographical and semantic distances. Experiments are conducted
from these four indicators with ten widely used language models. Results
underscore the critical necessity of inspecting and rectifying spatial biases
in language models to ensure accurate and equitable representations.

摘要：語言模型現在已成為提高效率的重要工具
許多專業任務，例如寫作、編碼或學習。為此原因，
辨識固有偏見勢在必行。在自然語言領域
處理過程中，五個偏差來源已明確：資料、註釋、
表示、模型和研究設計。這項研究的重點是偏見
與地理知識有關。我們探索地理之間的聯繫
和語言模型，強調它們扭曲空間的傾向
訊息，從而導致地理代表性的扭曲
距離。這項研究引入了四個指標來評估這些扭曲，
透過比較地理和語義距離。進行實驗
從這四個指標可以看出十種廣泛使用的語言模型。結果
強調檢查和糾正空間偏差的至關重要性
語言模型中以確保準確和公平的表示。

##### **Spatial-frequency Dual-Domain Feature Fusion Network for Low-Light Remote Sensing Image Enhancement**
2404.17400v1 by Zishu Yao et.al.

Low-light remote sensing images generally feature high resolution and high
spatial complexity, with continuously distributed surface features in space.
This continuity in scenes leads to extensive long-range correlations in spatial
domains within remote sensing images. Convolutional Neural Networks, which rely
on local correlations for long-distance modeling, struggle to establish
long-range correlations in such images. On the other hand, transformer-based
methods that focus on global information face high computational complexities
when processing high-resolution remote sensing images. From another
perspective, Fourier transform can compute global information without
introducing a large number of parameters, enabling the network to more
efficiently capture the overall image structure and establish long-range
correlations. Therefore, we propose a Dual-Domain Feature Fusion Network (DFFN)
for low-light remote sensing image enhancement. Specifically, this challenging
task of low-light enhancement is divided into two more manageable sub-tasks:
the first phase learns amplitude information to restore image brightness, and
the second phase learns phase information to refine details. To facilitate
information exchange between the two phases, we designed an information fusion
affine block that combines data from different phases and scales. Additionally,
we have constructed two dark light remote sensing datasets to address the
current lack of datasets in dark light remote sensing image enhancement.
Extensive evaluations show that our method outperforms existing
state-of-the-art methods. The code is available at
https://github.com/iijjlk/DFFN.

摘要：弱光遙感影像一般具有高解析度、高
空間複雜性，在空間中具有連續分佈的表面特徵。
場景中的這種連續性導致了空間上廣泛的遠程相關性
遙感影像中的域。卷積神經網絡，依賴
關於長距離建模的局部相關性，努力建立
此類影像中的長程相關性。另一方面，基於變壓器
關注全局資訊的方法面臨較高的計算複雜度
處理高解析度遙感影像時。來自另一個
從角度來看，傅立葉變換可以計算全局訊息，而無需
引入大量參數，使網路能夠更
有效捕捉整體影像結構並建立遠距離
相關性。因此，我們提出了雙域特徵融合網絡（DFFN）
用於低光源遙感影像增強。具體來說，這個具有挑戰性的
低光增強任務分為兩個更易於管理的子任務：
第一階段學習幅度資訊以恢復影像亮度，且
第二階段學習階段資訊以細化細節。為了方便
兩個階段之間進行資訊交換，我們設計了一個資訊融合
結合來自不同階段和尺度的資料的仿射塊。此外，
我們建立了兩個暗光遙感資料集來解決
目前缺乏暗光遙感影像增強資料集。
廣泛的評估表明我們的方法優於現有的方法
最先進的方法。該代碼可在
https://github.com/iijjlk/DFFN。

##### **Child Speech Recognition in Human-Robot Interaction: Problem Solved?**
2404.17394v1 by Ruben Janssens et.al.

Automated Speech Recognition shows superhuman performance for adult English
speech on a range of benchmarks, but disappoints when fed children's speech.
This has long sat in the way of child-robot interaction. Recent evolutions in
data-driven speech recognition, including the availability of Transformer
architectures and unprecedented volumes of training data, might mean a
breakthrough for child speech recognition and social robot applications aimed
at children. We revisit a study on child speech recognition from 2017 and show
that indeed performance has increased, with newcomer OpenAI Whisper doing
markedly better than leading commercial cloud services. While transcription is
not perfect yet, the best model recognises 60.3% of sentences correctly barring
small grammatical differences, with sub-second transcription time running on a
local GPU, showing potential for usable autonomous child-robot speech
interactions.

摘要：自動語音辨識在成人英語方面表現出超人的表現
在一系列基準上的演講，但在餵食兒童演講時令人失望。
這長期以來一直阻礙著兒童與機器人的互動。最近的演變
數據驅動的語音識別，包括 Transformer 的可用性
架構和前所未有的訓練資料量，可能意味著
兒童語音辨識和社交機器人應用的突破旨在
在兒童身上。我們回顧了 2017 年的一項關於兒童語音辨識的研究，結果表明
新來者 OpenAI Whisper 的表現確實有所提高
明顯優於領先的商業雲端服務。雖然轉錄是
尚不完美，最好的模型可以正確識別 60.3% 的句子，除非
語法差異很小，轉錄時間在亞秒級
本地 GPU，顯示出可用的自主兒童機器人語音的潛力
互動。

##### **M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training**
2404.17391v1 by Lakmal Meegahapola et.al.

Over the years, multimodal mobile sensing has been used extensively for
inferences regarding health and well being, behavior, and context. However, a
significant challenge hindering the widespread deployment of such models in
real world scenarios is the issue of distribution shift. This is the phenomenon
where the distribution of data in the training set differs from the
distribution of data in the real world, the deployment environment. While
extensively explored in computer vision and natural language processing, and
while prior research in mobile sensing briefly addresses this concern, current
work primarily focuses on models dealing with a single modality of data, such
as audio or accelerometer readings, and consequently, there is little research
on unsupervised domain adaptation when dealing with multimodal sensor data. To
address this gap, we did extensive experiments with domain adversarial neural
networks (DANN) showing that they can effectively handle distribution shifts in
multimodal sensor data. Moreover, we proposed a novel improvement over DANN,
called M3BAT, unsupervised domain adaptation for multimodal mobile sensing with
multi-branch adversarial training, to account for the multimodality of sensor
data during domain adaptation with multiple branches. Through extensive
experiments conducted on two multimodal mobile sensing datasets, three
inference tasks, and 14 source-target domain pairs, including both regression
and classification, we demonstrate that our approach performs effectively on
unseen domains. Compared to directly deploying a model trained in the source
domain to the target domain, the model shows performance increases up to 12%
AUC (area under the receiver operating characteristics curves) on
classification tasks, and up to 0.13 MAE (mean absolute error) on regression
tasks.

摘要：多年來，多模態移動感測已被廣泛應用於
關於健康和福祉、行為和背景的推論。然而，一個
阻礙此類模型廣泛部署的重大挑戰
現實世界的場景是分佈轉移的問題。這就是現象
其中訓練集中資料的分佈與
資料在現實世界的分佈、部署環境。儘管
在電腦視覺和自然語言處理方面進行了廣泛的探索，並且
雖然移動感測領域的先前研究簡要地解決了這個問題，但當前
工作主要集中於處理單一資料模態的模型，例如
作為音頻或加速度計讀數，因此，很少有研究
處理多模態感測器資料時的無監督域適應。到
為了解決這個差距，我們對領域對抗神經網路進行了廣泛的實驗
網路（DANN）表明他們可以有效地處理分佈變化
多模態感測器數據。此外，我們提出了對 DANN 的新穎改進，
稱為 M3BAT，用於多模態移動感測的無監督域自適應
多分支對抗訓練，考慮感測器的多模態
具有多個分支的域適應期間的資料。透過廣泛
在兩個多模態移動感測資料集、三個
推理任務，以及 14 個源-目標域對，包括迴歸
和分類，我們證明我們的方法在以下方面有效執行
看不見的域。與直接部署在來源中訓練的模型相比
域到目標域，模型顯示效能提升高達 12%
AUC（受試者工作特徵曲線下面積）
分類任務，迴歸高達 0.13 MAE（平均絕對誤差）
任務。

##### **Assessing the Potential of AI for Spatially Sensitive Nature-Related Financial Risks**
2404.17369v1 by Steven Reece et.al.

There is growing recognition among financial institutions, financial
regulators and policy makers of the importance of addressing nature-related
risks and opportunities. Evaluating and assessing nature-related risks for
financial institutions is challenging due to the large volume of heterogeneous
data available on nature and the complexity of investment value chains and the
various components' relationship to nature. The dual problem of scaling data
analytics and analysing complex systems can be addressed using Artificial
Intelligence (AI). We address issues such as plugging existing data gaps with
discovered data, data estimation under uncertainty, time series analysis and
(near) real-time updates. This report presents potential AI solutions for
models of two distinct use cases, the Brazil Beef Supply Use Case and the Water
Utility Use Case. Our two use cases cover a broad perspective within
sustainable finance. The Brazilian cattle farming use case is an example of
greening finance - integrating nature-related considerations into mainstream
financial decision-making to transition investments away from sectors with poor
historical track records and unsustainable operations. The deployment of
nature-based solutions in the UK water utility use case is an example of
financing green - driving investment to nature-positive outcomes. The two use
cases also cover different sectors, geographies, financial assets and AI
modelling techniques, providing an overview on how AI could be applied to
different challenges relating to nature's integration into finance. This report
is primarily aimed at financial institutions but is also of interest to ESG
data providers, TNFD, systems modellers, and, of course, AI practitioners.

摘要：金融機構、金融機構的認可度不斷提高
監管者和政策制定者認識到解決與自然相關的問題的重要性
風險和機會。評估和評估與自然相關的風險
由於異構體數量龐大，金融機構面臨挑戰
關於投資價值鏈的性質和複雜性以及
各種組成部分與自然的關係。縮放資料的雙重問題
分析和分析複雜系統可以使用人工來解決
智能（AI）。我們解決諸如填補現有資料缺口之類的問題
發現資料、不確定性下的資料估計、時間序列分析和
（近）即時更新。該報告提出了潛在的人工智慧解決方案
兩個不同用例的模型：巴西牛肉供應用例和水
實用用例。我們的兩個用例涵蓋了廣泛的視角
永續金融。巴西養牛業用例就是一個例子
綠色金融－將自然相關考量納入主流
將投資從貧困部門轉移出去的財務決策
歷史記錄和不可持續的運營。的部署
英國自來水公司使用案例中基於自然的解決方案就是一個例子
綠色融資－推動對自然正面成果的投資。兩者使用
案例還涵蓋不同行業、地域、金融資產和人工智慧
建模技術，概述人工智慧如何應用於
與自然融入金融相關的不同挑戰。這份報告
主要針對金融機構，但 ESG 也有興趣
資料提供者、TNFD、系統建模者，當然還有人工智慧從業人員。

##### **Similarity Equivariant Graph Neural Networks for Homogenization of Metamaterials**
2404.17365v1 by Fleur Hendriks et.al.

Soft, porous mechanical metamaterials exhibit pattern transformations that
may have important applications in soft robotics, sound reduction and
biomedicine. To design these innovative materials, it is important to be able
to simulate them accurately and quickly, in order to tune their mechanical
properties. Since conventional simulations using the finite element method
entail a high computational cost, in this article we aim to develop a machine
learning-based approach that scales favorably to serve as a surrogate model. To
ensure that the model is also able to handle various microstructures, including
those not encountered during training, we include the microstructure as part of
the network input. Therefore, we introduce a graph neural network that predicts
global quantities (energy, stress stiffness) as well as the pattern
transformations that occur (the kinematics). To make our model as accurate and
data-efficient as possible, various symmetries are incorporated into the model.
The starting point is an E(n)-equivariant graph neural network (which respects
translation, rotation and reflection) that has periodic boundary conditions
(i.e., it is in-/equivariant with respect to the choice of RVE), is scale
in-/equivariant, can simulate large deformations, and can predict scalars,
vectors as well as second and fourth order tensors (specifically energy, stress
and stiffness). The incorporation of scale equivariance makes the model
equivariant with respect to the similarities group, of which the Euclidean
group E(n) is a subgroup. We show that this network is more accurate and
data-efficient than graph neural networks with fewer symmetries. To create an
efficient graph representation of the finite element discretization, we use
only the internal geometrical hole boundaries from the finite element mesh to
achieve a better speed-up and scaling with the mesh size.

摘要：柔軟的多孔機械超材料表現出圖案轉變，
可能在軟體機器人、降噪和
生物醫學。為了設計這些創新材料，重要的是能夠
準確、快速地模擬它們，以便調整它們的機械性能
特性。由於使用有限元素方法進行傳統模擬
需要很高的計算成本，在本文中我們的目標是開發一台機器
基於學習的方法，可以很好地擴展以充當替代模型。到
確保模型也能夠處理各種微觀結構，包括
對於那些在訓練期間沒有遇到的情況，我們將微觀結構作為一部分
網路輸入。因此，我們引入了一個圖神經網路來預測
全局量（能量、應力剛度）以及模式
發生的變換（運動學）。為了使我們的模型準確且
為了盡可能提高資料效率，模型中納入了各種對稱性。
起點是一個 E(n) 等變圖神經網路（它尊重
具有週期性邊界條件的平移、旋轉和反射）
（即，它與 RVE 的選擇同變/等變），是比例
同變/等變，可以模擬大變形，並且可以預測標量，
向量以及二階和四階張量（特別是能量、應力
和剛度）。尺度等變異數的結合使得模型
關於相似群的等變，其中歐幾裡得
群 E(n) 是一個子群。我們證明這個網路更準確
與對稱性較少的圖神經網路相比，數據效率更高。創建一個
有限元素離散化的有效圖形表示，我們使用
僅從有限元素網格到內部幾何孔邊界
實現更好的加速和網格尺寸的縮放。

##### **A Bionic Natural Language Parser Equivalent to a Pushdown Automaton**
2404.17343v1 by Zhenghao Wei et.al.

Assembly Calculus (AC), proposed by Papadimitriou et al., aims to reproduce
advanced cognitive functions through simulating neural activities, with several
applications based on AC having been developed, including a natural language
parser proposed by Mitropolsky et al. However, this parser lacks the ability to
handle Kleene closures, preventing it from parsing all regular languages and
rendering it weaker than Finite Automata (FA). In this paper, we propose a new
bionic natural language parser (BNLP) based on AC and integrates two new
biologically rational structures, Recurrent Circuit and Stack Circuit which are
inspired by RNN and short-term memory mechanism. In contrast to the original
parser, the BNLP can fully handle all regular languages and Dyck languages.
Therefore, leveraging the Chomsky-Sch \H{u}tzenberger theorem, the BNLP which
can parse all Context-Free Languages can be constructed. We also formally prove
that for any PDA, a Parser Automaton corresponding to BNLP can always be
formed, ensuring that BNLP has a description ability equal to that of PDA and
addressing the deficiencies of the original parser.

摘要：彙編微積分 (AC)，由 Papadimitriou 等人提出，旨在重現
透過模擬神經活動來實現高階認知功能，
基於AC的應用程式已經開發出來，包括自然語言
Mitropolsky 等人所提出的解析器。然而，這個解析器缺乏能力
處理 Kleene 閉包，防止它解析所有常規語言和
使其弱於有限自動機（FA）。在本文中，我們提出了一種新的
基於AC並整合了兩個新的仿生自然語言解析器（BNLP）
生物學上合理​​的結構，循環電路和堆疊電路
受到 RNN 和短期記憶機制的啟發。與原版相比
在解析器中，BNLP 可以完全處理所有常規語言和 Dyck 語言。
因此，利用 Chomsky-Sch \H{u}tzenberger 定理，BNLP
可以解析所有可以建構的上下文無關語言。我們也正式證明
對於任何 PDA，總是可以有一個與 BNLP 對應的解析器自動機
形成，確保BNLP具有與PDA同等的描述能力，
解決了原始解析器的缺陷。

##### **Can a Multichoice Dataset be Repurposed for Extractive Question Answering?**
2404.17342v1 by Teresa Lynn et.al.

The rapid evolution of Natural Language Processing (NLP) has favored major
languages such as English, leaving a significant gap for many others due to
limited resources. This is especially evident in the context of data
annotation, a task whose importance cannot be underestimated, but which is
time-consuming and costly. Thus, any dataset for resource-poor languages is
precious, in particular when it is task-specific. Here, we explore the
feasibility of repurposing existing datasets for a new NLP task: we repurposed
the Belebele dataset (Bandarkar et al., 2023), which was designed for
multiple-choice question answering (MCQA), to enable extractive QA (EQA) in the
style of machine reading comprehension. We present annotation guidelines and a
parallel EQA dataset for English and Modern Standard Arabic (MSA). We also
present QA evaluation results for several monolingual and cross-lingual QA
pairs including English, MSA, and five Arabic dialects. Our aim is to enable
others to adapt our approach for the 120+ other language variants in Belebele,
many of which are deemed under-resourced. We also conduct a thorough analysis
and share our insights from the process, which we hope will contribute to a
deeper understanding of the challenges and the opportunities associated with
task reformulation in NLP research.

摘要：自然語言處理（NLP）的快速發展有利於專業
英語等語言，給許多其他語言留下了巨大的差距，因為
有限的資源。這在數據背景下尤其明顯
註釋，一項其重要性不可低估的任務，但它是
既費時又費錢。因此，任何資源匱乏語言的資料集都是
寶貴的，特別是當它是針對特定任務時。在這裡，我們探索
將現有資料集重新用於新的 NLP 任務的可行性：我們重新利用了
Belebele 資料集（Bandarkar 等人，2023），旨在
多項選擇題回答 (MCQA)，以在問題中啟用抽取式 QA (EQA)
機器閱讀理解的風格。我們提供註釋指南和
英語和現代標準阿拉伯語 (MSA) 的平行 EQA 資料集。我們也
呈現多個單一語言和跨語言 QA 的 QA 評估結果
對包括英語、MSA 和五種阿拉伯方言。我們的目標是使
其他人則使我們的方法適應 Belebele 中 120 多種其他語言變體，
其中許多被認為資源不足。我們也進行了徹底的分析
並分享我們在過程中的見解，我們希望這將有助於
更深入了解相關的挑戰和機遇
NLP 研究中的任務重新制定。

##### **Metronome: tracing variation in poetic meters via local sequence alignment**
2404.17337v1 by Ben Nagy et.al.

All poetic forms come from somewhere. Prosodic templates can be copied for
generations, altered by individuals, imported from foreign traditions, or
fundamentally changed under the pressures of language evolution. Yet these
relationships are notoriously difficult to trace across languages and times.
This paper introduces an unsupervised method for detecting structural
similarities in poems using local sequence alignment. The method relies on
encoding poetic texts as strings of prosodic features using a four-letter
alphabet; these sequences are then aligned to derive a distance measure based
on weighted symbol (mis)matches. Local alignment allows poems to be clustered
according to emergent properties of their underlying prosodic patterns. We
evaluate method performance on a meter recognition tasks against strong
baselines and show its potential for cross-lingual and historical research
using three short case studies: 1) mutations in quantitative meter in classical
Latin, 2) European diffusion of the Renaissance hendecasyllable, and 3)
comparative alignment of modern meters in 18--19th century Czech, German and
Russian. We release an implementation of the algorithm as a Python package with
an open license.

摘要：所有詩歌形式都來自某個地方。韻律模板可以複製
幾代人，被個人改變，從外國傳統引進，或
在語言進化的壓力下發生了根本性的變化。然而這些
眾所周知，跨語言和跨時代的關係很難追蹤。
本文介紹了一種用於檢測結構的無監督方法
使用局部序列對齊來確定詩歌中的相似性。該方法依賴於
使用四個字母將詩歌文本編碼為韻律特徵字符串
字母;然後將這些序列對齊以導出基於距離測量
加權符號（錯誤）匹配。局部對齊允許詩歌聚集
根據其潛在韻律模式的新興特性。我們
評估方法在儀表辨識任務上的效能
基線並展示其跨語言和歷史研究的潛力
使用三個簡短的案例研究：1）古典定量計量法的突變
拉丁語，2) 文藝復興時期十音節字母在歐洲的傳播，以及 3)
18--19世紀捷克、德國與現代米的比較排列
俄語。我們以 Python 套件的形式發布了該演算法的實作：
開放許可證。

##### **Introducing cosmosGPT: Monolingual Training for Turkish Language Models**
2404.17336v1 by H. Toprak Kesgin et.al.

The number of open source language models that can produce Turkish is
increasing day by day, as in other languages. In order to create the basic
versions of such models, the training of multilingual models is usually
continued with Turkish corpora. The alternative is to train the model with only
Turkish corpora. In this study, we first introduce the cosmosGPT models that we
created with this alternative method. Then, we introduce new finetune datasets
for basic language models to fulfill user requests and new evaluation datasets
for measuring the capabilities of Turkish language models. Finally, a
comprehensive comparison of the adapted Turkish language models on different
capabilities is presented. The results show that the language models we built
with the monolingual corpus have promising performance despite being about 10
times smaller than the others.

摘要：可以產生土耳其語的開源語言模型的數量是
就像其他語言一樣，日益增加。為了創建基本
此類模型的版本，多語言模型的訓練通常是
繼續土耳其語語料庫。另一種方法是僅使用
土耳其語料庫。在本研究中，我們首先介紹我們所使用的cosmosGPT模型
用這種替代方法創建的。然後，我們引入新的微調資料集
用於滿足使用者請求的基本語言模型和新的評估資料集
用於測量土耳其語言模型的能力。最後，一個
不同平台上適應的土耳其語言模式的綜合比較
提出了能力。結果顯示我們所建構的語言模型
儘管單語語料庫的數量約為 10，但其性能還是有希望的
比其他人小幾倍。

##### **A Novel Spike Transformer Network for Depth Estimation from Event Cameras via Cross-modality Knowledge Distillation**
2404.17335v1 by Xin Zhang et.al.

Depth estimation is crucial for interpreting complex environments, especially
in areas such as autonomous vehicle navigation and robotics. Nonetheless,
obtaining accurate depth readings from event camera data remains a formidable
challenge. Event cameras operate differently from traditional digital cameras,
continuously capturing data and generating asynchronous binary spikes that
encode time, location, and light intensity. Yet, the unique sampling mechanisms
of event cameras render standard image based algorithms inadequate for
processing spike data. This necessitates the development of innovative,
spike-aware algorithms tailored for event cameras, a task compounded by the
irregularity, continuity, noise, and spatial and temporal characteristics
inherent in spiking data.Harnessing the strong generalization capabilities of
transformer neural networks for spatiotemporal data, we propose a purely
spike-driven spike transformer network for depth estimation from spiking camera
data. To address performance limitations with Spiking Neural Networks (SNN), we
introduce a novel single-stage cross-modality knowledge transfer framework
leveraging knowledge from a large vision foundational model of artificial
neural networks (ANN) (DINOv2) to enhance the performance of SNNs with limited
data. Our experimental results on both synthetic and real datasets show
substantial improvements over existing models, with notable gains in Absolute
Relative and Square Relative errors (49% and 39.77% improvements over the
benchmark model Spike-T, respectively). Besides accuracy, the proposed model
also demonstrates reduced power consumptions, a critical factor for practical
applications.

摘要：深度估計對於解釋複雜環境至關重要，尤其是
在自動駕駛車輛導航和機器人技術等領域。儘管如此，
從事件相機數據中獲取準確的深度讀數仍然是一項艱鉅的任務
挑戰。事件攝影機的操作方式與傳統數位攝影機不同，
連續捕獲資料並產生非同步二進位尖峰
對時間、位置和光強度進行編碼。然而，獨特的採樣機制
的事件攝影機使得基於標準影像的演算法不足以
處理峰值數據。這就需要開發創新的、
為事件攝影機量身定制的尖峰感知演算法，這是一項由
不規則性、連續性、噪音、時空特徵
尖峰資料所固有的。
對於時空資料的變壓器神經網絡，我們提出了一個純粹的
尖峰驅動的尖峰變壓器網絡，用於尖峰相機的深度估計
數據。為了解決尖峰神經網路 (SNN) 的效能限制，我們
引入一種新穎的單階段跨模態知識移轉框架
利用大視覺基礎模型中的知識
神經網路 (ANN) (DINOv2)，以有限的方式增強 SNN 的效能
數據。我們對合成資料集和真實資料集的實驗結果表明
與現有模型相比有了顯著改進，絕對值顯著提升
相對誤差和平方相對誤差（比
分別為基準模型 Spike-T）。除了準確性之外，所提出的模型
也展示了降低的功耗，這是實際應用的關鍵因素
應用程式.

##### **Part-Guided 3D RL for Sim2Real Articulated Object Manipulation**
2404.17302v1 by Pengwei Xie et.al.

Manipulating unseen articulated objects through visual feedback is a critical
but challenging task for real robots. Existing learning-based solutions mainly
focus on visual affordance learning or other pre-trained visual models to guide
manipulation policies, which face challenges for novel instances in real-world
scenarios. In this paper, we propose a novel part-guided 3D RL framework, which
can learn to manipulate articulated objects without demonstrations. We combine
the strengths of 2D segmentation and 3D RL to improve the efficiency of RL
policy training. To improve the stability of the policy on real robots, we
design a Frame-consistent Uncertainty-aware Sampling (FUS) strategy to get a
condensed and hierarchical 3D representation. In addition, a single versatile
RL policy can be trained on multiple articulated object manipulation tasks
simultaneously in simulation and shows great generalizability to novel
categories and instances. Experimental results demonstrate the effectiveness of
our framework in both simulation and real-world settings. Our code is available
at
https://github.com/THU-VCLab/Part-Guided-3D-RL-for-Sim2Real-Articulated-Object-Manipulation.

摘要：透過視覺回饋操縱看不見的鉸接物體是一個關鍵
但這對真正的機器人來說是一項具有挑戰性的任務。現有的基於學習的解決方案主要
專注於視覺可供性學習或其他預先訓練的視覺模型來指導
操縱政策，面臨現實世界中新情況的挑戰
場景。在本文中，我們提出了一種新穎的部分引導 3D RL 框架，該框架
無需演示即可學會操縱鉸接式物體。我們結合
結合 2D 分割和 3D RL 的優勢，提高 RL 的效率
政策培訓。為了提高真實機器人政策的穩定性，我們
設計幀一致的不確定性採樣（FUS）策略以獲得
壓縮且分層的 3D 表示。此外，單一多功能
強化學習策略可以在多個關節物件操作任務上進行訓練
同時在模擬中顯示出對小說的巨大概括性
類別和實例。實驗結果證明了有效性
我們在模擬和現實環境中的框架。我們的程式碼可用
在
https://github.com/THU-VCLab/Part-Guided-3D-RL-for-Sim2Real-Articulated-Object-Manipulation。

##### **When to Trust LLMs: Aligning Confidence with Response Quality**
2404.17287v1 by Shuchang Tao et.al.

Despite the success of large language models (LLMs) in natural language
generation, much evidence shows that LLMs may produce incorrect or nonsensical
text. This limitation highlights the importance of discerning when to trust
LLMs, especially in safety-critical domains. Existing methods, which rely on
verbalizing confidence to tell the reliability by inducing top-k responses and
sampling-aggregating multiple responses, often fail, due to the lack of
objective guidance of confidence. To address this, we propose
CONfidence-Quality-ORDerpreserving alignment approach (CONQORD), leveraging
reinforcement learning with a tailored dual-component reward function. This
function encompasses quality reward and orderpreserving alignment reward
functions. Specifically, the order-preserving reward incentivizes the model to
verbalize greater confidence for responses of higher quality to align the order
of confidence and quality. Experiments demonstrate that our CONQORD
significantly improves the alignment performance between confidence levels and
response accuracy, without causing the model to become over-cautious.
Furthermore, the aligned confidence provided by CONQORD informs when to trust
LLMs, and acts as a determinant for initiating the retrieval process of
external knowledge. Aligning confidence with response quality ensures more
transparent and reliable responses, providing better trustworthiness.

摘要：儘管自然語言領域的大型語言模型（LLM）取得了成功
一代，許多證據表明法學碩士可能會產​​生不正確或無意義的結果
文字.這項限制凸顯了辨別何時信任的重要性
法學碩士，尤其是在安全關鍵領域。現有的方法，依賴
透過誘導 top-k 反應來表達說出可靠性的信心，以及
抽樣聚合多個回應常常會失敗，因為缺乏
客觀引導信心。為了解決這個問題，我們建議
保持信心-品質-秩序的一致性方法（CONQORD），利用
具有客製化的雙成分獎勵函數的強化學習。這
功能包括品質獎勵和保序對齊獎勵
功能。具體來說，保序獎勵激勵模型
表達對更高品質回應的更大信心，以協調訂單
的信心和品質。實驗顯示我們的 CONQORD
顯著提高置信水準之間的對齊效能
反應準確性，而又不會導致模型變得過於謹慎。
此外，CONQORD 提供的一致置信度告知何時信任
法學碩士，並作為啟動檢索過程的決定因素
外部知識。將信心與響應品質結合可確保更多
透明可靠的回應，提供更好的可信度。

##### **Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact Checking News Claims with Black-Box LLM**
2404.17283v1 by Xuan Zhang et.al.

Retrieval-augmented language models have exhibited promising performance
across various areas of natural language processing (NLP), including
fact-critical tasks. However, due to the black-box nature of advanced large
language models (LLMs) and the non-retrieval-oriented supervision signal of
specific tasks, the training of retrieval model faces significant challenges
under the setting of black-box LLM. We propose an approach leveraging
Fine-grained Feedback with Reinforcement Retrieval (FFRR) to enhance
fact-checking on news claims by using black-box LLM. FFRR adopts a two-level
strategy to gather fine-grained feedback from the LLM, which serves as a reward
for optimizing the retrieval policy, by rating the retrieved documents based on
the non-retrieval ground truth of the task. We evaluate our model on two public
datasets for real-world news claim verification, and the results demonstrate
that FFRR achieves significant improvements over strong LLM-enabled and non-LLM
baselines.

摘要：檢索增強語言模型表現出了有希望的性能
涵蓋自然語言處理 (NLP) 的各個領域，包括
事實關鍵的任務。然而，由於先進大型電腦的黑盒子性質
語言模型（LLM）和非檢索導向的監督訊號
在特定任務下，檢索模型的訓練面臨重大挑戰
在黑盒LLM的設定下。我們提出了一種利用方法
細粒度回饋與強化檢索（FFRR）以增強
使用黑盒法學碩士對新聞報導進行事實查核。 FFRR採用兩級
從法學碩士收集細粒度回饋的策略，作為獎勵
透過對檢索到的文件進行評級來優化檢索策略
任務的非檢索基本事實。我們在兩個公共平台上評估我們的模型
用於現實世界新聞聲明驗證的資料集，結果表明
FFRR 相對於支援 LLM 和非 LLM 的強大人員取得了顯著改進
基線。

##### **Enhancing Privacy and Security of Autonomous UAV Navigation**
2404.17225v1 by Vatsal Aggarwal et.al.

Autonomous Unmanned Aerial Vehicles (UAVs) have become essential tools in
defense, law enforcement, disaster response, and product delivery. These
autonomous navigation systems require a wireless communication network, and of
late are deep learning based. In critical scenarios such as border protection
or disaster response, ensuring the secure navigation of autonomous UAVs is
paramount. But, these autonomous UAVs are susceptible to adversarial attacks
through the communication network or the deep learning models - eavesdropping /
man-in-the-middle / membership inference / reconstruction. To address this
susceptibility, we propose an innovative approach that combines Reinforcement
Learning (RL) and Fully Homomorphic Encryption (FHE) for secure autonomous UAV
navigation. This end-to-end secure framework is designed for real-time video
feeds captured by UAV cameras and utilizes FHE to perform inference on
encrypted input images. While FHE allows computations on encrypted data,
certain computational operators are yet to be implemented. Convolutional neural
networks, fully connected neural networks, activation functions and OpenAI Gym
Library are meticulously adapted to the FHE domain to enable encrypted data
processing. We demonstrate the efficacy of our proposed approach through
extensive experimentation. Our proposed approach ensures security and privacy
in autonomous UAV navigation with negligible loss in performance.

摘要：自主無人機（UAV）已成為重要工具
國防、執法、災難應變和產品交付。這些
自主導航系統需要無線通訊網絡，且
後期都是基於深度學習的。在邊境保衛等關鍵場景下
或災難應變，確保自主無人機的安全導航
最重要的。但是，這些自主無人機很容易受到對抗性攻擊
透過通訊網路或深度學習模型—竊聽/
中間人/成員推理/重建。為了解決這個問題
敏感性，我們提出了一種結合強化的創新方法
用於安全自主無人機的學習 (RL) 和全同態加密 (FHE)
導航。該端到端安全框架專為即時視訊設計
無人機攝影機捕獲的數據並利用 FHE 進行推理
加密的輸入影像。雖然 FHE 允許對加密資料進行計算，
某些計算運算子尚未實作。卷積神經網絡
網路、全連接神經網路、激活函數和 OpenAI Gym
庫經過精心調整以適應 FHE 領域，以實現加密數據
加工。我們透過以下方式證明了我們提出的方法的有效性
廣泛的實驗。我們提出的方法可確保安全和隱私
在自主無人機導航中，性能損失可以忽略不計。

##### **Prompting Techniques for Reducing Social Bias in LLMs through System 1 and System 2 Cognitive Processes**
2404.17218v1 by Mahammed Kamruzzaman et.al.

Dual process theory posits that human cognition arises via two systems.
System 1, which is a quick, emotional, and intuitive process, which is subject
to cognitive biases, and System 2, a slow, onerous, and deliberate process. NLP
researchers often compare zero-shot prompting in LLMs to System 1 reasoning and
chain-of-thought (CoT) prompting to System 2. In line with this interpretation,
prior research has found that using CoT prompting in LLMs leads to reduced
gender bias. We investigate the relationship between bias, CoT prompting, and
dual process theory in LLMs directly. We compare zero-shot, CoT, and a variety
of dual process theory-based prompting strategies on two bias datasets spanning
nine different social bias categories. We also use human and machine personas
to determine whether the effects of dual process theory in LLMs are based on
modeling human cognition or inherent to the system. We find that a human
persona, System 2, and CoT prompting all tend to reduce social biases in LLMs,
though the best combination of features depends on the exact model and bias
category -- resulting in up to a 13 percent drop in stereotypical judgments by
an LLM.

摘要：雙過程理論認為人類認知是透過兩個系統產生的。
系統1，這是一個快速、情感化和直觀的過程，是主題
認知偏誤和系統2是一個緩慢、繁重且深思熟慮的過程。自然語言處理
研究人員經常將法學碩士中的零樣本提示與系統 1 推理進行比較
思想鏈（CoT）提示系統 2。
先前的研究發現，在法學碩士中使用 CoT 提示會減少
性別偏見。我們研究了偏見、CoT 提示和
直接在法學碩士中使用雙過程理論。我們比較零樣本、CoT 和各種
基於雙過程理論的提示策略對兩個偏差資料集的影響
九種不同的社會偏見類別。我們也使用人類和機器角色
確定雙過程理論在法學碩士中的效果是否基於
對人類認知或系統固有的認知進行建模。我們發現人類
角色、系統 2 和 CoT 提示都傾向於減少法學碩士的社會偏見，
儘管功能的最佳組合取決於確切的模型和偏差
類別－導致陳規定型判斷下降高達 13%
法學碩士。

##### **Prompting Towards Alleviating Code-Switched Data Scarcity in Under-Resourced Languages with GPT as a Pivot**
2404.17216v1 by Michelle Terblanche et.al.

Many multilingual communities, including numerous in Africa, frequently
engage in code-switching during conversations. This behaviour stresses the need
for natural language processing technologies adept at processing code-switched
text. However, data scarcity, particularly in African languages, poses a
significant challenge, as many are low-resourced and under-represented. In this
study, we prompted GPT 3.5 to generate Afrikaans--English and Yoruba--English
code-switched sentences, enhancing diversity using topic-keyword pairs,
linguistic guidelines, and few-shot examples. Our findings indicate that the
quality of generated sentences for languages using non-Latin scripts, like
Yoruba, is considerably lower when compared with the high Afrikaans-English
success rate. There is therefore a notable opportunity to refine prompting
guidelines to yield sentences suitable for the fine-tuning of language models.
We propose a framework for augmenting the diversity of synthetically generated
code-switched data using GPT and propose leveraging this technology to mitigate
data scarcity in low-resourced languages, underscoring the essential role of
native speakers in this process.

摘要：許多多語言社區，包括非洲的許多多語言社區，經常
在對話過程中進行語碼轉換。這種行為強調了需求
用於擅長處理程式碼轉換的自然語言處理技術
文字.然而，數據稀缺，特別是非洲語言的數據稀缺，造成了
這是一項重大挑戰，因為許多人資源匱乏且代表性不足。在這個
研究中，我們提示 GPT 3.5 產生南非荷蘭語-英語和約魯巴語-英語
代碼轉換句子，使用主題關鍵字對增強多樣性，
語言指南和一些例子。我們的研究結果表明
使用非拉丁文字的語言產生的句子的質量，例如
與高級南非荷蘭語-英語相比，約魯巴語的語氣要低得多
成功率。因此，這是一個完善提示的絕佳機會
產生適合語言模型微調的句子的指南。
我們提出了一個框架來增強綜合生成的多樣性
使用 GPT 進行程式碼交換數據，並建議利用該技術來緩解
資源匱乏語言的數據稀缺，強調了
過程中以母語為母語的人。

##### **Human-Imperceptible Retrieval Poisoning Attacks in LLM-Powered Applications**
2404.17196v1 by Quan Zhang et.al.

Presently, with the assistance of advanced LLM application development
frameworks, more and more LLM-powered applications can effortlessly augment the
LLMs' knowledge with external content using the retrieval augmented generation
(RAG) technique. However, these frameworks' designs do not have sufficient
consideration of the risk of external content, thereby allowing attackers to
undermine the applications developed with these frameworks. In this paper, we
reveal a new threat to LLM-powered applications, termed retrieval poisoning,
where attackers can guide the application to yield malicious responses during
the RAG process. Specifically, through the analysis of LLM application
frameworks, attackers can craft documents visually indistinguishable from
benign ones. Despite the documents providing correct information, once they are
used as reference sources for RAG, the application is misled into generating
incorrect responses. Our preliminary experiments indicate that attackers can
mislead LLMs with an 88.33\% success rate, and achieve a 66.67\% success rate
in the real-world application, demonstrating the potential impact of retrieval
poisoning.

摘要：目前，在先進的LLM申請開發的協助下
框架，越來越多的 LLM 支援的應用程式可以毫不費力地增強
法學碩士使用檢索增強生成對外部內容的了解
（RAG）技術。然而，這些框架的設計並沒有足夠的
考慮外部內容的風險，從而允許攻擊者
破壞使用這些框架開發的應用程式。在本文中，我們
揭示了 LLM 支援的應用程式面臨的新威脅，稱為檢索中毒，
攻擊者可以引導應用程式在期間產生惡意回應
RAG 過程。具體來說，透過LLM申請分析
框架，攻擊者可以製作視覺上無法區分的文檔
良性的。儘管文件提供了正確的信息，但一旦
用作 RAG 的參考來源，應用程式被誤導生成
不正確的反應。我們的初步實驗顯示攻擊者可以
誤導法學碩士，成功率88.33%，達到66.67%的成功率
在實際應用中，展示檢索的潛在影響
中毒。

##### **TIGQA:An Expert Annotated Question Answering Dataset in Tigrinya**
2404.17194v1 by Hailay Teklehaymanot et.al.

The absence of explicitly tailored, accessible annotated datasets for
educational purposes presents a notable obstacle for NLP tasks in languages
with limited resources.This study initially explores the feasibility of using
machine translation (MT) to convert an existing dataset into a Tigrinya dataset
in SQuAD format. As a result, we present TIGQA, an expert annotated educational
dataset consisting of 2.68K question-answer pairs covering 122 diverse topics
such as climate, water, and traffic. These pairs are from 537 context
paragraphs in publicly accessible Tigrinya and Biology books. Through
comprehensive analyses, we demonstrate that the TIGQA dataset requires skills
beyond simple word matching, requiring both single-sentence and
multiple-sentence inference abilities. We conduct experiments using
state-of-the art MRC methods, marking the first exploration of such models on
TIGQA. Additionally, we estimate human performance on the dataset and juxtapose
it with the results obtained from pretrained models.The notable disparities
between human performance and best model performance underscore the potential
for further enhancements to TIGQA through continued research. Our dataset is
freely accessible via the provided link to encourage the research community to
address the challenges in the Tigrinya MRC.

摘要：缺乏明確定制的、可訪問的帶註釋的數據集
教育目的是語言 NLP 任務的一個顯著障礙
在資源有限的情況下。
機器翻譯 (MT) 將現有資料集轉換為 Tigrinya 資料集
以 SQuAD 格式。因此，我們推出了 TIGQA，這是一位專家註釋的教育
資料集由 2.68K 個問答對組成，涵蓋 122 個不同主題
例如氣候、水和交通。這些對來自 537 上下文
公開的提格里尼亞語和生物學書籍中的段落。透過
綜合分析，我們證明 TIGQA 資料集需要技能
除了簡單的單字配對之外，還需要單句和
多句推理能力。我們進行實驗使用
最先進的 MRC 方法，標誌著此類模型的首次探索
TIGQA。此外，我們估計人類在資料集上的表現並並列
它與從預訓練模型獲得的結果。
人類表現和最佳模型表現之間的差距凸顯了潛力
透過持續研究進一步增強 TIGQA。我們的數據集是
透過提供的連結免費訪問，以鼓勵研究界
解決提格里尼亞 MRC 的挑戰。

##### **MCSDNet: Mesoscale Convective System Detection Network via Multi-scale Spatiotemporal Information**
2404.17186v1 by Jiajun Liang et.al.

The accurate detection of Mesoscale Convective Systems (MCS) is crucial for
meteorological monitoring due to their potential to cause significant
destruction through severe weather phenomena such as hail, thunderstorms, and
heavy rainfall. However, the existing methods for MCS detection mostly targets
on single-frame detection, which just considers the static characteristics and
ignores the temporal evolution in the life cycle of MCS. In this paper, we
propose a novel encoder-decoder neural network for MCS detection(MCSDNet).
MCSDNet has a simple architecture and is easy to expand. Different from the
previous models, MCSDNet targets on multi-frames detection and leverages
multi-scale spatiotemporal information for the detection of MCS regions in
remote sensing imagery(RSI). As far as we know, it is the first work to utilize
multi-scale spatiotemporal information to detect MCS regions. Firstly, we
design a multi-scale spatiotemporal information module to extract multi-level
semantic from different encoder levels, which makes our models can extract more
detail spatiotemporal features. Secondly, a Spatiotemporal Mix Unit(STMU) is
introduced to MCSDNet to capture both intra-frame features and inter-frame
correlations, which is a scalable module and can be replaced by other
spatiotemporal module, e.g., CNN, RNN, Transformer and our proposed Dual
Spatiotemporal Attention(DSTA). This means that the future works about
spatiotemporal modules can be easily integrated to our model. Finally, we
present MCSRSI, the first publicly available dataset for multi-frames MCS
detection based on visible channel images from the FY-4A satellite. We also
conduct several experiments on MCSRSI and find that our proposed MCSDNet
achieve the best performance on MCS detection task when comparing to other
baseline methods.

摘要：中尺度對流系統（MCS）的準確檢測對於
氣象監測因其可能造成重大影響
冰雹、雷暴等惡劣天氣現象造成的破壞
傾盆大雨。然而，現有的MCS檢測方法大多針對
單幀檢測，只考慮靜態特性
忽略了 MCS 生命週期中的時間演化。在本文中，我們
提出了一種用於 MCS 檢測的新型編碼器-解碼器神經網路（MCSDNet）。
MCSDNet架構簡單，易於擴充。不同於
與先前的模型相比，MCSDNet 的目標是多幀檢測並利用
用於檢測 MCS 區域的多尺度時空資訊
遙感影像（RSI）。據我們所知，這是第一個利用
多尺度時空資訊來偵測 MCS 區域。首先，我們
設計多尺度時空資訊模組來擷取多層次
來自不同編碼器層級的語義，這使得我們的模型可以提取更多
詳細的時空特徵。其次，時空混合單元（STMU）是
引入 MCSDNet 以捕捉幀內特徵和幀間特徵
相關性，這是一個可擴展的模組，可以被其他模組替換
時空模組，例如 CNN、RNN、Transformer 和我們提出的 Dual
時空注意力（DSTA）。這意味著未來的工作大約是
時空模組可以輕鬆整合到我們的模型中。最後，我們
推出 MCSRSI，第一個公開可用的多幀 MCS 資料集
基於FY-4A衛星可見光通道影像的偵測。我們也
在 MCSRSI 上進行了多次實驗，發現我們提出的 MCSDNet
與其他檢測任務相比，在 MCS 檢測任務上達到最佳效能
基線方法。

##### **A Unified Label-Aware Contrastive Learning Framework for Few-Shot Named Entity Recognition**
2404.17178v1 by Haojie Zhang et.al.

Few-shot Named Entity Recognition (NER) aims to extract named entities using
only a limited number of labeled examples. Existing contrastive learning
methods often suffer from insufficient distinguishability in context vector
representation because they either solely rely on label semantics or completely
disregard them. To tackle this issue, we propose a unified label-aware
token-level contrastive learning framework. Our approach enriches the context
by utilizing label semantics as suffix prompts. Additionally, it simultaneously
optimizes context-context and context-label contrastive learning objectives to
enhance generalized discriminative contextual representations.Extensive
experiments on various traditional test domains (OntoNotes, CoNLL'03, WNUT'17,
GUM, I2B2) and the large-scale few-shot NER dataset (FEWNERD) demonstrate the
effectiveness of our approach. It outperforms prior state-of-the-art models by
a significant margin, achieving an average absolute gain of 7% in micro F1
scores across most scenarios. Further analysis reveals that our model benefits
from its powerful transfer capability and improved contextual representations.

摘要：Few-shot 命名實體識別 (NER) 旨在使用以下方法提取命名實體
僅有限數量的標記範例。現有的對比學習
方法通常會遇到上下文向量的區分度不足的問題
表示，因為它們要么完全依賴標籤語義，要么完全依賴
無視他們。為了解決這個問題，我們提出了一個統一的標籤感知
令牌級對比學習框架。我們的方法豐富了背景
透過利用標籤語意作為後綴提示。另外，它同時
優化上下文-上下文和上下文-標籤對比學習目標
增強廣義的判別性上下文表徵。
在各種傳統測試領域（OntoNotes、CoNLL'03、WNUT'17、
GUM、I2B2）和大規模少樣本 NER 資料集（FEWNERD）證明了
我們的方法的有效性。它的性能優於之前最先進的模型
顯著的利潤，在微型 F1 中實現了 7% 的平均絕對增益
大多數情況下的得分。進一步的分析顯示我們的模型有好處
來自其強大的傳輸能力和改進的上下文表示。

##### **Exploring Beyond Logits: Hierarchical Dynamic Labeling Based on Embeddings for Semi-Supervised Classification**
2404.17173v1 by Yanbiao Ma et.al.

In semi-supervised learning, methods that rely on confidence learning to
generate pseudo-labels have been widely proposed. However, increasing research
finds that when faced with noisy and biased data, the model's representation
network is more reliable than the classification network. Additionally, label
generation methods based on model predictions often show poor adaptability
across different datasets, necessitating customization of the classification
network. Therefore, we propose a Hierarchical Dynamic Labeling (HDL) algorithm
that does not depend on model predictions and utilizes image embeddings to
generate sample labels. We also introduce an adaptive method for selecting
hyperparameters in HDL, enhancing its versatility. Moreover, HDL can be
combined with general image encoders (e.g., CLIP) to serve as a fundamental
data processing module. We extract embeddings from datasets with class-balanced
and long-tailed distributions using pre-trained semi-supervised models.
Subsequently, samples are re-labeled using HDL, and the re-labeled samples are
used to further train the semi-supervised models. Experiments demonstrate
improved model performance, validating the motivation that representation
networks are more reliable than classifiers or predictors. Our approach has the
potential to change the paradigm of pseudo-label generation in semi-supervised
learning.

摘要：在半監督學習中，依賴置信學習的方法
產生偽標籤已被廣泛提出。然而，越來越多的研究
發現當面對雜訊和偏差的資料時，模型的表示
網路比分類網路更可靠。另外，標籤
基於模型預測的生成方法往往適應性較差
跨不同的資料集，需要客製化分類
網路。因此，我們提出了一種分層動態標籤（HDL）演算法
不依賴模型預測並利用圖像嵌入
產生樣本標籤。我們還引入了一種自適應方法來選擇
HDL 中的超參數，增強其多功能性。此外，HDL 可以
與通用影像編碼器（例如 CLIP）結合作為基礎
數據處理模組。我們從具有類別平衡的資料集中提取嵌入
和使用預先訓練的半監督模型的長尾分佈。
隨後，使用HDL對樣本進行重新標記，並將重新標記的樣本
用於進一步訓練半監督模型。實驗證明
改進模型性能，驗證表示的動機
網路比分類器或預測器更可靠。我們的方法有
改變半監督偽標籤生成範式的潛力
學習。

##### **Quantifying Memorization of Domain-Specific Pre-trained Language Models using Japanese Newspaper and Paywalls**
2404.17143v1 by Shotaro Ishihara et.al.

Dominant pre-trained language models (PLMs) have been successful in
high-quality natural language generation. However, the analysis of their
generation is not mature: do they acquire generalizable linguistic
abstractions, or do they simply memorize and recover substrings of the training
data? Especially, few studies focus on domain-specific PLM. In this study, we
pre-trained domain-specific GPT-2 models using a limited corpus of Japanese
newspaper articles and quantified memorization of training data by comparing
them with general Japanese GPT-2 models. Our experiments revealed that
domain-specific PLMs sometimes "copy and paste" on a large scale. Furthermore,
we replicated the empirical finding that memorization is related to
duplication, model size, and prompt length, in Japanese the same as in previous
English studies. Our evaluations are relieved from data contamination concerns
by focusing on newspaper paywalls, which prevent their use as training data. We
hope that our paper encourages a sound discussion such as the security and
copyright of PLMs.

摘要：主導的預訓練語言模型 (PLM) 已在以下方面取得了成功
高品質的自然語言生成。然而，分析他們的
這一代人還不成熟：他們是否獲得了普遍的語言能力
抽象，或者他們只是記住並恢復訓練的子串
數據？特別是，很少有研究關注特定領域的 PLM。在這項研究中，我們
使用有限的日語語料庫預訓練特定領域的 GPT-2 模型
報紙文章並透過比較對訓練資料進行量化記憶
與一般日本GPT-2型號相同。我們的實驗表明
特定領域的 PLM 有時會大規模「複製和貼上」。此外，
我們重複了記憶與以下因素相關的經驗發現：
重複、模型大小和提示長度，日語與之前相同
英語研究。我們的評估擺脫了數據污染的擔憂
透過關注報紙付費牆，這阻止了它們用作訓練資料。我們
希望我們的論文能鼓勵人們進行合理的討論，例如安全和
PLM 的版權。

##### **Small Language Models Need Strong Verifiers to Self-Correct Reasoning**
2404.17140v1 by Yunxiang Zhang et.al.

Self-correction has emerged as a promising solution to boost the reasoning
performance of large language models (LLMs), where LLMs refine their solutions
using self-generated critiques that pinpoint the errors. This work explores
whether smaller-size (<= 13B) language models (LMs) have the ability of
self-correction on reasoning tasks with minimal inputs from stronger LMs. We
propose a novel pipeline that prompts smaller LMs to collect self-correction
data that supports the training of self-refinement abilities. First, we
leverage correct solutions to guide the model in critiquing their incorrect
responses. Second, the generated critiques, after filtering, are used for
supervised fine-tuning of the self-correcting reasoner through solution
refinement. Our experimental results show improved self-correction abilities of
two models on five datasets spanning math and commonsense reasoning, with
notable performance gains when paired with a strong GPT-4-based verifier,
though limitations are identified when using a weak self-verifier for
determining when to correct.

摘要：自我糾正已成為一種有前途的增強推理的解決方案
大型語言模型 (LLM) 的性能，其中 LLM 改進了他們的解決方案
使用自我生成的批評來找出錯誤。這項工作探討了
較小尺寸（<= 13B）的語言模型（LM）是否有能力
使用更強的 LM 的最少輸入對推理任務進行自我修正。我們
提出一種新穎的管道，促使較小的語言模型收集自我修正
支援自我完善能力訓練的數據。首先，我們
利用正確的解決方案來指導模型批評其不正確的解決方案
回應。其次，生成的批評經過過濾後用於
透過解決方案對自校正推理機進行監督微調
細化。我們的實驗結果表明，自我糾正能力得到了提高
涵蓋數學和常識推理的五個資料集的兩個模型，其中
與基於 GPT-4 的強大驗證器搭配使用時，效能顯著提升，
儘管在使用弱自我驗證器時發現了局限性
確定何時糾正。

##### **Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study**
2404.17136v1 by Yang Wu et.al.

The Natural Language to Visualization (NL2Vis) task aims to transform
natural-language descriptions into visual representations for a grounded table,
enabling users to gain insights from vast amounts of data. Recently, many deep
learning-based approaches have been developed for NL2Vis. Despite the
considerable efforts made by these approaches, challenges persist in
visualizing data sourced from unseen databases or spanning multiple tables.
Taking inspiration from the remarkable generation capabilities of Large
Language Models (LLMs), this paper conducts an empirical study to evaluate
their potential in generating visualizations, and explore the effectiveness of
in-context learning prompts for enhancing this task. In particular, we first
explore the ways of transforming structured tabular data into sequential text
prompts, as to feed them into LLMs and analyze which table content contributes
most to the NL2Vis. Our findings suggest that transforming structured tabular
data into programs is effective, and it is essential to consider the table
schema when formulating prompts. Furthermore, we evaluate two types of LLMs:
finetuned models (e.g., T5-Small) and inference-only models (e.g., GPT-3.5),
against state-of-the-art methods, using the NL2Vis benchmarks (i.e., nvBench).
The experimental results reveal that LLMs outperform baselines, with
inference-only models consistently exhibiting performance improvements, at
times even surpassing fine-tuned models when provided with certain few-shot
demonstrations through in-context learning. Finally, we analyze when the LLMs
fail in NL2Vis, and propose to iteratively update the results using strategies
such as chain-of-thought, role-playing, and code-interpreter. The experimental
results confirm the efficacy of iterative updates and hold great potential for
future study.

摘要：自然語言到視覺化（NL2Vis）任務旨在轉變
將自然語言描述轉化為接地表的視覺表示，
使用戶能夠從海量數據中獲得洞察。最近，很多深
NL2Vis 已開發出基於學習的方法。儘管
雖然這些方法做出了相當大的努力，但挑戰仍然存在
可視化來自看不見的資料庫或跨多個表的資料。
從 Large 的卓越發電能力中汲取靈感
語言模型（LLM），本文進行了實證研究來評估
他們在生成視覺化方面的潛力，並探索其有效性
情境學習提示加強這項任務。特別是，我們首先
探索將結構化表格資料轉換為順序文字的方法
提示，以便將它們輸入法學碩士並分析哪些表格內容有貢獻
大多數是 NL2Vis。我們的研究結果表明，轉變結構化表格
資料導入程序是否有效，必須考慮表格
制定提示時的模式。此外，我們評估兩種類型的法學碩士：
微調模型（例如 T5-Small）和僅推理模型（例如 GPT-3.5），
使用 NL2Vis 基準（即 nvBench）與最先進的方法進行比較。
實驗結果表明，法學碩士的表現優於基線，
僅推理模型始終表現出性能改進，
當提供某些少數鏡頭時，甚至超過微調模型的時間
透過情境學習進行演示。最後，我們分析了LLMs何時
在 NL2Vis 中失敗，並建議使用策略迭代更新結果
例如思維鏈、角色扮演和代碼解釋器。實驗的
結果證實了迭代更新的有效性，並且具有巨大的潛力
未來的學習。

##### **Process Mining Embeddings: Learning Vector Representations for Petri Nets**
2404.17129v1 by Juan G. Colonna et.al.

Process mining offers powerful techniques for discovering, analyzing, and
enhancing real-world business processes. In this context, Petri nets provide an
expressive means of modeling process behavior. However, directly analyzing and
comparing intricate Petri net presents challenges. This study introduces
PetriNet2Vec, a novel unsupervised methodology based on Natural Language
Processing concepts inspired by Doc2Vec and designed to facilitate the
effective comparison, clustering, and classification of process models
represented as embedding vectors. These embedding vectors allow us to quantify
similarities and relationships between different process models. Our
methodology was experimentally validated using the PDC Dataset, featuring 96
diverse Petri net models. We performed cluster analysis, created UMAP
visualizations, and trained a decision tree to provide compelling evidence for
the capability of PetriNet2Vec to discern meaningful patterns and relationships
among process models and their constituent tasks. Through a series of
experiments, we demonstrated that PetriNet2Vec was capable of learning the
structure of Petri nets, as well as the main properties used to simulate the
process models of our dataset. Furthermore, our results showcase the utility of
the learned embeddings in two crucial downstream tasks within process mining
enhancement: process classification and process retrieval.

摘要：流程挖掘提供了強大的技術來發現、分析和
擴增實境世界的業務流程。在此背景下，Petri 網提供了
建模過程行為的表達方式。然而，直接分析和
比較複雜的 Petri 網有挑戰。本研究介紹
PetriNet2Vec，一種基於自然語言的新型無監督方法
處理概念受 Doc2Vec 啟發，旨在促進
過程模型的有效比較、聚類和分類
表示為嵌入向量。這些嵌入向量使我們能夠量化
不同流程模型之間的相似性和關係。我們的
使用 PDC 資料集對方法進行了實驗驗證，該資料集具有 96
多樣化的Petri網模型。我們進行了聚類分析，並創建了 UMAP
可視化，並訓練決策樹來提供令人信服的證據
PetriNet2Vec 辨別有意義的模式和關係的能力
流程模型及其組成任務之間的關係。透過一系列
實驗中，我們證明了 PetriNet2Vec 能夠學習
Petri網的結構，以及用於模擬的主要屬性
我們資料集的處理模型。此外，我們的結果展示了
流程挖掘中兩個關鍵下游任務中的學習嵌入
增強功能：流程分類與流程檢索。

##### **Deep Evidential Learning for Dose Prediction**
2404.17126v1 by Hai Siong Tan et.al.

In this work, we present a novel application of an uncertainty-quantification
framework called Deep Evidential Learning in the domain of radiotherapy dose
prediction. Using medical images of the Open Knowledge-Based Planning Challenge
dataset, we found that this model can be effectively harnessed to yield
uncertainty estimates that inherited correlations with prediction errors upon
completion of network training. This was achieved only after reformulating the
original loss function for a stable implementation. We found that (i)epistemic
uncertainty was highly correlated with prediction errors, with various
association indices comparable or stronger than those for Monte-Carlo Dropout
and Deep Ensemble methods, (ii)the median error varied with uncertainty
threshold much more linearly for epistemic uncertainty in Deep Evidential
Learning relative to these other two conventional frameworks, indicative of a
more uniformly calibrated sensitivity to model errors, (iii)relative to
epistemic uncertainty, aleatoric uncertainty demonstrated a more significant
shift in its distribution in response to Gaussian noise added to CT intensity,
compatible with its interpretation as reflecting data noise. Collectively, our
results suggest that Deep Evidential Learning is a promising approach that can
endow deep-learning models in radiotherapy dose prediction with statistical
robustness. Towards enhancing its clinical relevance, we demonstrate how we can
use such a model to construct the predicted Dose-Volume-Histograms' confidence
intervals.

摘要：在這項工作中，我們提出了不確定性量化的新穎應用
放射治療劑量領域稱為深度證據學習的框架
預言。使用開放知識規劃挑戰賽的醫學影像
資料集，我們發現這個模型可以有效地利用來產生
不確定性估計繼承了與預測誤差的相關性
完成網路培訓。這是在重新制定後才實現的
用於穩定實現的原始損失函數。我們發現（i）認知
不確定性與預測誤差高度相關，
關聯指數與 Monte-Carlo Dropout 相當或更強
和深度集成方法，(ii)中位數誤差隨不確定性變化
深度證據中認知不確定性的閾值較為線性
相對於這另外兩個傳統框架的學習，表明
對模型誤差的更統一的校準敏感性，(iii)相對於
認知不確定性、任意不確定性表現出更顯著的影響
響應於 CT 強度添加的高斯噪聲，其分佈發生變化，
與其反映數據雜訊的解釋相容。總的來說，我們的
結果顯示深度證據學習是一種有前途的方法，可以
為放射治療劑量預測中的深度學習模型提供統計數據
穩健性.為了增強其臨床相關性，我們展示瞭如何能夠
使用這樣的模型來建立預測劑量-體積直方圖的置信度
間隔。

##### **Text Sentiment Analysis and Classification Based on Bidirectional Gated Recurrent Units (GRUs) Model**
2404.17123v1 by Wei Xu et.al.

This paper explores the importance of text sentiment analysis and
classification in the field of natural language processing, and proposes a new
approach to sentiment analysis and classification based on the bidirectional
gated recurrent units (GRUs) model. The study firstly analyses the word cloud
model of the text with six sentiment labels, and then carries out data
preprocessing, including the steps of removing special symbols, punctuation
marks, numbers, stop words and non-alphabetic parts. Subsequently, the data set
is divided into training set and test set, and through model training and
testing, it is found that the accuracy of the validation set is increased from
85% to 93% with training, which is an increase of 8%; at the same time, the
loss value of the validation set decreases from 0.7 to 0.1 and tends to be
stable, and the model is gradually close to the actual value, which can
effectively classify the text emotions. The confusion matrix shows that the
accuracy of the model on the test set reaches 94.8%, the precision is 95.9%,
the recall is 99.1%, and the F1 score is 97.4%, which proves that the model has
good generalisation ability and classification effect. Overall, the study
demonstrated an effective method for text sentiment analysis and classification
with satisfactory results.

摘要：本文探討了文本情感分析的重要性和
自然語言處理領域的分類，並提出了一種新的分類方法
基於雙向情感分析和分類的方法
門控循環單元（GRU）模型。研究先分析詞雲
帶有六個情緒標籤的文字模型，然後進行資料處理
預處理，包括刪除特殊符號、標點符號的步驟
標記、數字、停用詞和非字母部分。隨後，數據集
分為訓練集和測試集，透過模型訓練和
測試發現驗證集的準確率提高了
經過培訓，從 85% 上升到 93%，增加了 8%；同時，
驗證集的損失值從0.7下降到0.1，並趨於
穩定，模型逐漸接近實際值，可以
有效地對文本情感進行分類。混淆矩陣表明
模型在測試集上的準確率達94.8%，精確度為95.9%，
召回率為99.1%，F1得分為97.4%，證明模型具有
良好的泛化能力和分類效果。總體而言，該研究
展示了一種有效的文本情緒分析和分類方法
取得了滿意的結果。

##### **2M-NER: Contrastive Learning for Multilingual and Multimodal NER with Language and Modal Fusion**
2404.17122v1 by Dongsheng Wang et.al.

Named entity recognition (NER) is a fundamental task in natural language
processing that involves identifying and classifying entities in sentences into
pre-defined types. It plays a crucial role in various research fields,
including entity linking, question answering, and online product
recommendation. Recent studies have shown that incorporating multilingual and
multimodal datasets can enhance the effectiveness of NER. This is due to
language transfer learning and the presence of shared implicit features across
different modalities. However, the lack of a dataset that combines
multilingualism and multimodality has hindered research exploring the
combination of these two aspects, as multimodality can help NER in multiple
languages simultaneously. In this paper, we aim to address a more challenging
task: multilingual and multimodal named entity recognition (MMNER), considering
its potential value and influence. Specifically, we construct a large-scale
MMNER dataset with four languages (English, French, German and Spanish) and two
modalities (text and image). To tackle this challenging MMNER task on the
dataset, we introduce a new model called 2M-NER, which aligns the text and
image representations using contrastive learning and integrates a multimodal
collaboration module to effectively depict the interactions between the two
modalities. Extensive experimental results demonstrate that our model achieves
the highest F1 score in multilingual and multimodal NER tasks compared to some
comparative and representative baselines. Additionally, in a challenging
analysis, we discovered that sentence-level alignment interferes a lot with NER
models, indicating the higher level of difficulty in our dataset.

摘要：命名實體辨識（NER）是自然語言的基本任務
涉及識別句子中的實體並將其分類為的處理
預定義類型。它在各個研究領域中發揮著至關重要的作用，
包括實體連結、問答和線上產品
推薦。最近的研究表明，將多語言和
多模態資料集可以增強 NER 的有效性。這是因為
語言遷移學習和共享隱式特徵的存在
不同的方式。然而，缺乏結合的數據集
多語言和多模態阻礙了研究探索
結合這兩個方面，因為多模態可以在多個方面幫助 NER
語言同時進行。在本文中，我們旨在解決更具挑戰性的問題
任務：多語言和多模式命名實體識別（MMNER），考慮
其潛在價值和影響力。具體來說，我們建構了一個大規模的
MMNER 資料集包含四種語言（英語、法語、德語和西班牙語）和兩種語言
方式（文字和圖像）。為了解決這個具有挑戰性的 MMNER 任務
資料集，我們引入了一個名為 2M-NER 的新模型，它可以對齊文字和
使用對比學習的圖像表示並整合多模態
協作模組有效地描繪了兩者之間的交互
方式。大量的實驗結果顯示我們的模型實現了
與某些任務相比，在多語言和多模式 NER 任務中 F1 得分最高
比較和代表性基線。此外，在充滿挑戰的
分析後，我們發現句子級對齊對NER有很大的干擾
模型，顯示我們的資料集中的難度較高。

##### **Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs**
2404.17120v1 by Valeriia Cherepanova et.al.

Large language models (LLMs) exhibit excellent ability to understand human
languages, but do they also understand their own language that appears
gibberish to us? In this work we delve into this question, aiming to uncover
the mechanisms underlying such behavior in LLMs. We employ the Greedy
Coordinate Gradient optimizer to craft prompts that compel LLMs to generate
coherent responses from seemingly nonsensical inputs. We call these inputs LM
Babel and this work systematically studies the behavior of LLMs manipulated by
these prompts. We find that the manipulation efficiency depends on the target
text's length and perplexity, with the Babel prompts often located in lower
loss minima compared to natural prompts. We further examine the structure of
the Babel prompts and evaluate their robustness. Notably, we find that guiding
the model to generate harmful texts is not more difficult than into generating
benign texts, suggesting lack of alignment for out-of-distribution prompts.

摘要：大型語言模型 (LLM) 表現出出色的理解人類的能力
語言，但他們也理解出現的自己的語言嗎？
對我們胡言亂語？在這項工作中，我們深入研究這個問題，旨在揭示
法學碩士中此類行為背後的機制。我們採用貪婪
協調梯度優化器來製作提示，迫使法學碩士生成
來自看似無意義的輸入的連貫響應。我們稱這些輸入為 LM
Babel 和這項工作有系統地研究了 LLM 的行為
這些提示。我們發現操縱效率取決於目標
文字的長度和複雜性，Babel 提示通常位於較低的位置
與自然提示相比的損失最小值。我們進一步檢查結構
Babel 提示並評估其穩健性。值得注意的是，我們發現指導
生成有害文字的模型並不比生成
良性文本，表示未分配提示缺乏一致性。

##### **CLARE: Cognitive Load Assessment in REaltime with Multimodal Data**
2404.17098v1 by Anubhav Bhatti et.al.

We present a novel multimodal dataset for Cognitive Load Assessment in
REaltime (CLARE). The dataset contains physiological and gaze data from 24
participants with self-reported cognitive load scores as ground-truth labels.
The dataset consists of four modalities, namely, Electrocardiography (ECG),
Electrodermal Activity (EDA), Electroencephalogram (EEG), and Gaze tracking. To
map diverse levels of mental load on participants during experiments, each
participant completed four nine-minutes sessions on a computer-based operator
performance and mental workload task (the MATB-II software) with varying levels
of complexity in one minute segments. During the experiment, participants
reported their cognitive load every 10 seconds. For the dataset, we also
provide benchmark binary classification results with machine learning and deep
learning models on two different evaluation schemes, namely, 10-fold and
leave-one-subject-out (LOSO) cross-validation. Benchmark results show that for
10-fold evaluation, the convolutional neural network (CNN) based deep learning
model achieves the best classification performance with ECG, EDA, and Gaze. In
contrast, for LOSO, the best performance is achieved by the deep learning model
with ECG, EDA, and EEG.

摘要：我們提出了一種用於認知負荷評估的新穎的多模式資料集
即時（CLARE）。該資料集包含來自 24 個
參與者自我報告的認知負荷分數作為真實標籤。
此資料集由四種模式組成，分別為心電圖（ECG）、
皮電活動 (EDA)、腦電圖 (EEG) 和注視追蹤。到
繪製實驗期間參與者不同程度的心理負荷，每個
參與者在基於計算機的操作員上完成了四次九分鐘的課程
不同程度的表現和腦力負荷任務（MATB-II 軟體）
一分鐘片段的複雜性。實驗過程中，參與者
每 10 秒報告一次他們的認知負荷。對於資料集，我們還
透過機器學習和深度學習提供基準二元分類結果
兩種不同評量方案的學習模型，即 10 倍和
留一主題排除（LOSO）交叉驗證。基準測試結果表明，對於
10倍評估，基於卷積神經網路（CNN）的深度學習
模型透過 ECG、EDA 和 Gaze 實現了最佳分類性能。在
相比之下，對於LOSO，最好的表現是透過深度學習模型實現的
具有心電圖、EDA 和腦電圖。

##### **CyNetDiff -- A Python Library for Accelerated Implementation of Network Diffusion Models**
2404.17059v1 by Eliot W. Robson et.al.

In recent years, there has been increasing interest in network diffusion
models and related problems. The most popular of these are the independent
cascade and linear threshold models. Much of the recent experimental work done
on these models requires a large number of simulations conducted on large
graphs, a computationally expensive task suited for low-level languages.
However, many researchers prefer the use of higher-level languages (such as
Python) for their flexibility and shorter development times. Moreover, in many
research tasks, these simulations are the most computationally intensive task,
so it would be desirable to have a library for these with an interface to a
high-level language with the performance of a low-level language. To fill this
niche, we introduce CyNetDiff, a Python library with components written in
Cython to provide improved performance for these computationally intensive
diffusion tasks.

摘要：近年來，人們對網路傳播的興趣日益濃厚
模型及相關問題。其中最受歡迎的是獨立
級聯和線性閾值模型。最近完成的實驗工作
這些模型需要在大型設備上進行大量模擬
圖，一項計算量大的任務，適合低階語言。
然而，許多研究人員更喜歡使用高階語言（例如
Python）的靈活性和更短的開發時間。此外，在許多
研究任務，這些模擬是計算量最大的任務，
因此，希望有一個帶有介面的庫來儲存這些內容
具有低階語言性能的高階語言。為了填補這個
利基市場，我們介紹 CyNetDiff，一個 Python 函式庫，其元件寫成為
Cython 為這些計算密集型應用提供改進的效能
擴散任務。

##### **Agentive Permissions in Multiagent Systems**
2404.17053v1 by Qi Shi et.al.

This paper proposes to distinguish four forms of agentive permissions in
multiagent settings. The main technical results are the complexity analysis of
model checking, the semantic undefinability of modalities that capture these
forms of permissions through each other, and a complete logical system
capturing the interplay between these modalities.

摘要：本文提出區分四種形式的代理權限
多代理設定。主要技術成果為複雜度分析
模型檢查，捕獲這些的模態的語義不可定義性
權限形式相互關聯，邏輯體系完整
捕捉這些模式之間的相互作用。

##### **Generative AI in Color-Changing Systems: Re-Programmable 3D Object Textures with Material and Design Constraints**
2404.17028v1 by Yunyi Zhu et.al.

Advances in Generative AI tools have allowed designers to manipulate existing
3D models using text or image-based prompts, enabling creators to explore
different design goals. Photochromic color-changing systems, on the other hand,
allow for the reprogramming of surface texture of 3D models, enabling easy
customization of physical objects and opening up the possibility of using
object surfaces for data display. However, existing photochromic systems
require the user to manually design the desired texture, inspect the simulation
of the pattern on the object, and verify the efficacy of the generated pattern.
These manual design, inspection, and verification steps prevent the user from
efficiently exploring the design space of possible patterns. Thus, by designing
an automated workflow desired for an end-to-end texture application process, we
can allow rapid iteration on different practicable patterns.
  In this workshop paper, we discuss the possibilities of extending generative
AI systems, with material and design constraints for reprogrammable surfaces
with photochromic materials. By constraining generative AI systems to colors
and materials possible to be physically realized with photochromic dyes, we can
create tools that would allow users to explore different viable patterns, with
text and image-based prompts. We identify two focus areas in this topic:
photochromic material constraints and design constraints for data-encoded
textures. We highlight the current limitations of using generative AI tools to
create viable textures using photochromic material. Finally, we present
possible approaches to augment generative AI methods to take into account the
photochromic material constraints, allowing for the creation of viable
photochromic textures rapidly and easily.

摘要：生成式人工智慧工具的進步使設計人員能夠操縱現有的
使用基於文字或圖像的提示的 3D 模型，使創作者能夠探索
不同的設計目標。另一方面，光致變色系統
允許對 3D 模型的表面紋理進行重新編程，從而輕鬆實現
物理物件的自訂並開啟使用的可能性
用於資料顯示的物件表面。然而，現有的光致變色系統
要求使用者手動設計所需的紋理，檢查模擬
物件上的圖案，並驗證生成的圖案的功效。
這些手動設計、檢查和驗證步驟可防止用戶
有效地探索可能模式的設計空間。因此，透過設計
端到端紋理應用流程所需的自動化工作流程，我們
可以允許對不同的實用模式進行快速迭代。
  在這篇研討會論文中，我們討論了擴展生成性的可能性
人工智慧系統，具有可重新編程表面的材料和設計限制
與光致變色材料。透過將生成式人工智慧系統限制為顏色
以及可以用光致變色染料物理實現的材料，我們可以
創建允許使用者探索不同可行模式的工具，
基於文字和圖像的提示。我們確定本主題的兩個重點領域：
資料編碼的光致變色材料約束和設計約束
紋理。我們強調了目前使用生成式人工智慧工具的局限性
使用光致變色材質創造可行的紋理。最後，我們呈現
增強生成式人工智慧方法的可能方法，以考慮到
光致變色材料的限制，允許創造可行的
快速、輕鬆地實現光致變色紋理。

##### **Player-Driven Emergence in LLM-Driven Game Narrative**
2404.17027v1 by Xiangyu Peng et.al.

We explore how interaction with large language models (LLMs) can give rise to
emergent behaviors, empowering players to participate in the evolution of game
narratives. Our testbed is a text-adventure game in which players attempt to
solve a mystery under a fixed narrative premise, but can freely interact with
non-player characters generated by GPT-4, a large language model. We recruit 28
gamers to play the game and use GPT-4 to automatically convert the game logs
into a node-graph representing the narrative in the player's gameplay. We find
that through their interactions with the non-deterministic behavior of the LLM,
players are able to discover interesting new emergent nodes that were not a
part of the original narrative but have potential for being fun and engaging.
Players that created the most emergent nodes tended to be those that often
enjoy games that facilitate discovery, exploration and experimentation.

摘要：我們探索與大型語言模型（LLM）的交互作用如何產生
突發行為，使玩家能夠參與遊戲的演變
敘述。我們的測試平台是一款文字冒險遊戲，玩家嘗試
在固定的敘事前提下解開謎團，但可以自由互動
由大型語言模型 GPT-4 產生的非玩家角色。我們招募28名
玩家玩遊戲並使用GPT-4自動轉換遊戲日誌
轉化為代表玩家遊戲中的敘述的節點圖。我們發現
透過他們與法學碩士的非確定性行為的互動，
玩家能夠發現有趣的新出現的節點，這些節點不是以前的節點
是原始敘述的一部分，但有可能變得有趣和引人入勝。
創建最新興節點的玩家往往是那些經常
享受有助於發現、探索和實驗的遊戲。

##### **Generating Minimalist Adversarial Perturbations to Test Object-Detection Models: An Adaptive Multi-Metric Evolutionary Search Approach**
2404.17020v1 by Cristopher McIntyre-Garcia et.al.

Deep Learning (DL) models excel in computer vision tasks but can be
susceptible to adversarial examples. This paper introduces Triple-Metric
EvoAttack (TM-EVO), an efficient algorithm for evaluating the robustness of
object-detection DL models against adversarial attacks. TM-EVO utilizes a
multi-metric fitness function to guide an evolutionary search efficiently in
creating effective adversarial test inputs with minimal perturbations. We
evaluate TM-EVO on widely-used object-detection DL models, DETR and Faster
R-CNN, and open-source datasets, COCO and KITTI. Our findings reveal that
TM-EVO outperforms the state-of-the-art EvoAttack baseline, leading to
adversarial tests with less noise while maintaining efficiency.

摘要：深度學習 (DL) 模型在電腦視覺任務中表現出色，但也可以
容易受到對抗性例子的影響。本文介紹了三重度量
EvoAttack (TM-EVO)，一種評估穩健性的有效演算法
針對對抗性攻擊的物件偵測深度學習模型。 TM-EVO 採用
多度量適應度函數可有效指導演化搜索
以最小的擾動創建有效的對抗性測試輸入。我們
在廣泛使用的目標檢測 DL 模型、DETR 和 Faster 上評估 TM-EVO
R-CNN，以及開源資料集 COCO 和 KITTI。我們的研究結果表明
TM-EVO 的性能優於最先進的 EvoAttack 基線，從而
在保持效率的同時減少噪音的對抗性測試。

##### **Türkçe Dil Modellerinin Performans Karşılaştırması Performance Comparison of Turkish Language Models**
2404.17010v1 by Eren Dogan et.al.

The developments that language models have provided in fulfilling almost all
kinds of tasks have attracted the attention of not only researchers but also
the society and have enabled them to become products. There are commercially
successful language models available. However, users may prefer open-source
language models due to cost, data privacy, or regulations. Yet, despite the
increasing number of these models, there is no comprehensive comparison of
their performance for Turkish. This study aims to fill this gap in the
literature. A comparison is made among seven selected language models based on
their contextual learning and question-answering abilities. Turkish datasets
for contextual learning and question-answering were prepared, and both
automatic and human evaluations were conducted. The results show that for
question-answering, continuing pretraining before fine-tuning with
instructional datasets is more successful in adapting multilingual models to
Turkish and that in-context learning performances do not much related to
question-answering performances.

摘要：語言模型在實現幾乎所有目標方面所提供的發展
各種任務不僅引起了研究人員的關注，也引起了人們的注意。
社會並使它們成為產品。商業上有
可用的成功語言模式。然而，用戶可能更喜歡開源
由於成本、資料隱私或法規而導致的語言模型。然而，儘管
這些型號越來越多，沒有全面的比較
他們在土耳其語比賽中的表現。本研究即旨在填補此一空白
文學。所選的七種語言模型進行了比較
他們的情境學習和回答問題的能力。土耳其語資料集
準備了情境學習和問答，而且都
進行了自動和人工評估。結果表明，對於
問答，在微調之前繼續預訓練
教學資料集在適應多語言模型方面更成功
土耳其語和情境學習表現與
問答表演。

##### **Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models**
2404.17000v1 by Bradley P. Allen et.al.

A backbone of knowledge graphs are their class membership relations, which
assign entities to a given class. As part of the knowledge engineering process,
we propose a new method for evaluating the quality of these relations by
processing descriptions of a given entity and class using a zero-shot
chain-of-thought classifier that uses a natural language intensional definition
of a class. We evaluate the method using two publicly available knowledge
graphs, Wikidata and CaLiGraph, and 7 large language models. Using the
gpt-4-0125-preview large language model, the method's classification
performance achieves a macro-averaged F1-score of 0.830 on data from Wikidata
and 0.893 on data from CaLiGraph. Moreover, a manual analysis of the
classification errors shows that 40.9% of errors were due to the knowledge
graphs, with 16.0% due to missing relations and 24.9% due to incorrectly
asserted relations. These results show how large language models can assist
knowledge engineers in the process of knowledge graph refinement. The code and
data are available on Github.

摘要：知識圖譜的支柱是它們的類別成員關係，
將實體分配給給定的類別。作為知識工程過程的一部分，
我們提出了一種評估這些關係品質的新方法
使用零樣本處理給定實體和類別的描述
使用自然語言內涵定義的思想鏈分類器
一個類別的。我們使用兩個公開可用的知識來評估方法
圖、Wikidata 和 CaLiGraph，以及 7 個大型語言模型。使用
gpt-4-0125-preview大語言模型，方法的分類
根據維基數據的數據，效能達到 0.830 的宏觀平均 F1 分數
來自 CaLiGraph 的數據為 0.893。此外，人工分析
分類錯誤顯示 40.9% 的錯誤是由於知識造成的
圖表，其中 16.0% 由於缺少關係，24.9% 由於錯誤
斷言的關係。這些結果顯示大型語言模型可以提供多大幫助
知識工程師在知識圖細化過程中。代碼和
數據可在 Github 上取得。

##### **IDIL: Imitation Learning of Intent-Driven Expert Behavior**
2404.16989v1 by Sangwon Seo et.al.

When faced with accomplishing a task, human experts exhibit intentional
behavior. Their unique intents shape their plans and decisions, resulting in
experts demonstrating diverse behaviors to accomplish the same task. Due to the
uncertainties encountered in the real world and their bounded rationality,
experts sometimes adjust their intents, which in turn influences their
behaviors during task execution. This paper introduces IDIL, a novel imitation
learning algorithm to mimic these diverse intent-driven behaviors of experts.
Iteratively, our approach estimates expert intent from heterogeneous
demonstrations and then uses it to learn an intent-aware model of their
behavior. Unlike contemporary approaches, IDIL is capable of addressing
sequential tasks with high-dimensional state representations, while
sidestepping the complexities and drawbacks associated with adversarial
training (a mainstay of related techniques). Our empirical results suggest that
the models generated by IDIL either match or surpass those produced by recent
imitation learning benchmarks in metrics of task performance. Moreover, as it
creates a generative model, IDIL demonstrates superior performance in intent
inference metrics, crucial for human-agent interactions, and aptly captures a
broad spectrum of expert behaviors.

摘要：當面臨完成任務時，人類專家會表現出有意的態度
行為。他們獨特的意圖塑造了他們的計劃和決策，從而導致
專家表現出不同的行為來完成相同任務。因為
現實世界中所遇到的不確定性及其有限理性，
專家有時會調整他們的意圖，進而影響他們的
任務執行期間的行為。本文介紹了IDIL，一種新穎的仿製品
學習演算法來模仿專家的這些不同的意圖驅動行為。
迭代地，我們的方法估計來自異質的專家意圖
演示，然後用它來學習他們的意圖感知模型
行為。與當代方法不同，IDIL 能夠解決
具有高維度狀態表示的順序任務，而
迴避與對抗相關的複雜性與缺點
培訓（相關技術的支柱）。我們的實證結果表明
IDIL 產生的模型可以匹配或超過最近產生的模型
任務績效指標中的模仿學習基準。而且，由於它
創建生成模型，IDIL 在意圖方面表現出卓越的性能
推理指標，對於人機互動至關重要，並且恰當地捕獲了
廣泛的專家行為。

##### **Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks**
2404.16966v1 by Melissa Ailem et.al.

Benchmarks have emerged as the central approach for evaluating Large Language
Models (LLMs). The research community often relies on a model's average
performance across the test prompts of a benchmark to evaluate the model's
performance. This is consistent with the assumption that the test prompts
within a benchmark represent a random sample from a real-world distribution of
interest. We note that this is generally not the case; instead, we hold that
the distribution of interest varies according to the specific use case. We find
that (1) the correlation in model performance across test prompts is
non-random, (2) accounting for correlations across test prompts can change
model rankings on major benchmarks, (3) explanatory factors for these
correlations include semantic similarity and common LLM failure points.

摘要：基準已成為評估大型語言的核心方法
模型（法學碩士）。研究界通常依賴模型的平均值
跨基準測試提示的效能來評估模型的
表現。這與測試提示的假設是一致的
基準內代表來自真實世界分佈的隨機樣本
興趣。我們注意到，通常情況並非如此；相反，我們認為
興趣的分配根據具體用例而有所不同。我們發現
(1) 模型表現在測試提示之間的相關性是
非隨機，(2) 測試提示之間的相關性可能會改變
主要基準的模型排名，(3) 這些的解釋因素
相關性包括語意相似性和常見的 LLM 失敗點。

##### **A Closer Look at Classification Evaluation Metrics and a Critical Reflection of Common Evaluation Practice**
2404.16958v1 by Juri Opitz et.al.

Classification systems are evaluated in a countless number of papers.
However, we find that evaluation practice is often nebulous. Frequently,
metrics are selected without arguments, and blurry terminology invites
misconceptions. For instance, many works use so-called 'macro' metrics to rank
systems (e.g., 'macro F1') but do not clearly specify what they would expect
from such a 'macro' metric. This is problematic, since picking a metric can
affect paper findings as well as shared task rankings, and thus any clarity in
the process should be maximized.
  Starting from the intuitive concepts of bias and prevalence, we perform an
analysis of common evaluation metrics, considering expectations as found
expressed in papers. Equipped with a thorough understanding of the metrics, we
survey metric selection in recent shared tasks of Natural Language Processing.
The results show that metric choices are often not supported with convincing
arguments, an issue that can make any ranking seem arbitrary. This work aims at
providing overview and guidance for more informed and transparent metric
selection, fostering meaningful evaluation.

摘要：無數論文對分類系統進行了評估。
然而，我們發現評估實踐往往是模糊的。頻繁地，
指標的選擇不帶參數，模糊的術語會導致
誤解。例如，許多作品使用所謂的「宏觀」指標來排名
系統（例如“宏 F1”），但沒有明確說明他們的期望
從這樣一個「宏觀」指標來看。這是有問題的，因為選擇一個指標可以
影響論文發現以及共享任務排名，從而影響論文的清晰度
該過程應該最大化。
  從偏見和普遍性的直覺概念出發，我們執行了
分析常見的評估指標，考慮發現的期望
論文中表達。憑藉對指標的透徹理解，我們
自然語言處理最近共享任務中的調查指標選擇。
結果表明，度量選擇通常沒有令人信服的支持
爭論，這個問題可能會讓任何排名顯得任意。這項工作旨在
為更明智和透明的指標提供概述和指導
選擇，促進有意義的評估。

##### **Taming False Positives in Out-of-Distribution Detection with Human Feedback**
2404.16954v1 by Harit Vishwakarma et.al.

Robustness to out-of-distribution (OOD) samples is crucial for safely
deploying machine learning models in the open world. Recent works have focused
on designing scoring functions to quantify OOD uncertainty. Setting appropriate
thresholds for these scoring functions for OOD detection is challenging as OOD
samples are often unavailable up front. Typically, thresholds are set to
achieve a desired true positive rate (TPR), e.g., $95\%$ TPR. However, this can
lead to very high false positive rates (FPR), ranging from 60 to 96\%, as
observed in the Open-OOD benchmark. In safety-critical real-life applications,
e.g., medical diagnosis, controlling the FPR is essential when dealing with
various OOD samples dynamically. To address these challenges, we propose a
mathematically grounded OOD detection framework that leverages expert feedback
to \emph{safely} update the threshold on the fly. We provide theoretical
results showing that it is guaranteed to meet the FPR constraint at all times
while minimizing the use of human feedback. Another key feature of our
framework is that it can work with any scoring function for OOD uncertainty
quantification. Empirical evaluation of our system on synthetic and benchmark
OOD datasets shows that our method can maintain FPR at most $5\%$ while
maximizing TPR.

摘要：對分佈外 (OOD) 樣本的穩健性對於安全至關重要
在開放世界中部署機器學習模型。最近的作品主要集中在
設計評分函數來量化 OOD 不確定性。設定適當
OOD 檢測的這些評分函數的閾值具有挑戰性，因為 OOD
樣品通常無法預先獲得。通常，閾值設定為
達到所需的真陽性率 (TPR)，例如 $95\%$ TPR。然而，這可以
導致非常高的誤報率 (FPR)，範圍從 60% 到 96\%，如
在 Open-OOD 基準測試中觀察到。在安全關鍵的現實生活應用中，
例如，醫療診斷、處理 FPR 時至關重要
動態地提供各種 OOD 樣本。為了應對這些挑戰，我們提出了
基於數學的 OOD 檢測框架，利用專家回饋
\emph{安全地}動態更新閾值。我們提供理論
結果表明，保證始終滿足 FPR 約束
同時最大限度地減少人類回饋的使用。我們的另一個主要特點
框架的特點是它可以與任何 OOD 不確定性評分函數一起使用
量化。對我們的系統進行綜合和基準的實證評估
OOD 資料集表明，我們的方法最多可以將 FPR 維持在 $5\%$，而
最大化 TPR。

##### **Make-it-Real: Unleashing Large Multimodal Model's Ability for Painting 3D Objects with Realistic Materials**
2404.16829v1 by Ye Fang et.al.

Physically realistic materials are pivotal in augmenting the realism of 3D
assets across various applications and lighting conditions. However, existing
3D assets and generative models often lack authentic material properties.
Manual assignment of materials using graphic software is a tedious and
time-consuming task. In this paper, we exploit advancements in Multimodal Large
Language Models (MLLMs), particularly GPT-4V, to present a novel approach,
Make-it-Real: 1) We demonstrate that GPT-4V can effectively recognize and
describe materials, allowing the construction of a detailed material library.
2) Utilizing a combination of visual cues and hierarchical text prompts, GPT-4V
precisely identifies and aligns materials with the corresponding components of
3D objects. 3) The correctly matched materials are then meticulously applied as
reference for the new SVBRDF material generation according to the original
diffuse map, significantly enhancing their visual authenticity. Make-it-Real
offers a streamlined integration into the 3D content creation workflow,
showcasing its utility as an essential tool for developers of 3D assets.

摘要：物理真實材質對於增強 3D 真實感至關重要
跨各種應用和照明條件的資產。然而，現有的
3D 資產和生成模型通常缺乏真實的材料屬性。
使用圖形軟體手動分配材料是一項繁瑣且繁瑣的工作
耗時的任務。在本文中，我們利用多式聯運大
語言模型（MLLM），特別是 GPT-4V，提出了一種新穎的方法，
Make-it-Real：1）我們證明 GPT-4V 可以有效地辨識和
描述材料，允許建立詳細的材料庫。
2）利用視覺提示和分層文字提示的組合，GPT-4V
精確識別材料並將其與相應的組件對齊
3D 對象。 3) 然後精心應用正確匹配的材料
根據原始生成新的SVBRDF材質的參考
漫反射貼圖，顯著增強其視覺真實性。使它成為現實
提供與 3D 內容創建工作流程的簡化集成，
展現其作為 3D 資產開發人員的必備工具的實用性。

##### **A Survey of Generative Search and Recommendation in the Era of Large Language Models**
2404.16924v1 by Yongqi Li et.al.

With the information explosion on the Web, search and recommendation are
foundational infrastructures to satisfying users' information needs. As the two
sides of the same coin, both revolve around the same core research problem,
matching queries with documents or users with items. In the recent few decades,
search and recommendation have experienced synchronous technological paradigm
shifts, including machine learning-based and deep learning-based paradigms.
Recently, the superintelligent generative large language models have sparked a
new paradigm in search and recommendation, i.e., generative search (retrieval)
and recommendation, which aims to address the matching problem in a generative
manner. In this paper, we provide a comprehensive survey of the emerging
paradigm in information systems and summarize the developments in generative
search and recommendation from a unified perspective. Rather than simply
categorizing existing works, we abstract a unified framework for the generative
paradigm and break down the existing works into different stages within this
framework to highlight the strengths and weaknesses. And then, we distinguish
generative search and recommendation with their unique challenges, identify
open problems and future directions, and envision the next information-seeking
paradigm.

摘要：隨著網路資訊爆炸，搜尋和推薦變得越來越重要。
滿足使用者資訊需求的基礎設施。正如兩人
同一枚硬幣的兩面，都圍繞著相同的核心研究問題，
將查詢與文件或使用者與項目進行比對。近幾十年來，
搜尋和推薦經歷了同步的技術範式
轉變，包括基於機器學習和基於深度學習的範式。
最近，超智能生成式大語言模式引發了一場熱潮。
搜尋和建議的新範式，即產生搜尋（檢索）
和推薦，旨在解決生成中的匹配問題
方式。在本文中，我們對新興市場進行了全面調查
資訊系統範式並總結生成式的發展
統一視角的搜尋與推薦。而不是簡單地
將現有作品分類，我們抽像出一個統一的生成框架
範式並將現有作品分解為不同的階段
框架，突出優勢和劣勢。然後我們區分
產生搜尋和推薦及其獨特的挑戰，確定
開放問題和未來方向，並設想下一步的資訊查找
範例。

##### **IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages**
2404.16816v1 by Harman Singh et.al.

As large language models (LLMs) see increasing adoption across the globe, it
is imperative for LLMs to be representative of the linguistic diversity of the
world. India is a linguistically diverse country of 1.4 Billion people. To
facilitate research on multilingual LLM evaluation, we release IndicGenBench -
the largest benchmark for evaluating LLMs on user-facing generation tasks
across a diverse set 29 of Indic languages covering 13 scripts and 4 language
families. IndicGenBench is composed of diverse generation tasks like
cross-lingual summarization, machine translation, and cross-lingual question
answering. IndicGenBench extends existing benchmarks to many Indic languages
through human curation providing multi-way parallel evaluation data for many
under-represented Indic languages for the first time. We evaluate a wide range
of proprietary and open-source LLMs including GPT-3.5, GPT-4, PaLM-2, mT5,
Gemma, BLOOM and LLaMA on IndicGenBench in a variety of settings. The largest
PaLM-2 models performs the best on most tasks, however, there is a significant
performance gap in all languages compared to English showing that further
research is needed for the development of more inclusive multilingual language
models. IndicGenBench is released at
www.github.com/google-research-datasets/indic-gen-bench

摘要：隨著大型語言模型 (LLM) 在全球範圍內的採用不斷增加，
法學碩士必須代表該領域的語言多樣性
世界。印度是一個擁有 14 億人口的語言多元化國家。到
促進多語言LLM評估研究，我們發布IndicGenBench -
評估法學碩士在使用者導向的生成任務方面的最大基準
涵蓋 29 種印度語言，涵蓋 13 種文字和 4 種語言
家庭。 IndicGenBench 由多種生成任務組成，例如
跨語言摘要、機器翻譯、跨語言問題
回答。 IndicGenBench 將現有基準擴展到多種印度語言
透過人工管理為許多人提供多路並行評估數據
印度語首次出現代表性不足的情況。我們評估範圍廣泛
專有及開源法學碩士，包括 GPT-3.5、GPT-4、PaLM-2、mT5、
Gemma、BLOOM 和 LLaMA 在 IndicGenBench 上的各種設定。最大的
PaLM-2 模型在大多數任務上表現最好，但是，有一個顯著的問題
與英語相比，所有語言的表現差距進一步表明
需要研究發展更具包容性的多語言
楷模。 IndicGenBench 發佈於
www.github.com/google-research-datasets/indic-gen-bench

##### **Make Your LLM Fully Utilize the Context**
2404.16811v2 by Shengnan An et.al.

While many contemporary large language models (LLMs) can process lengthy
input, they still struggle to fully utilize information within the long
context, known as the lost-in-the-middle challenge. We hypothesize that it
stems from insufficient explicit supervision during the long-context training,
which fails to emphasize that any position in a long context can hold crucial
information. Based on this intuition, our study presents information-intensive
(IN2) training, a purely data-driven solution to overcome lost-in-the-middle.
Specifically, IN2 training leverages a synthesized long-context question-answer
dataset, where the answer requires (1) fine-grained information awareness on a
short segment (~128 tokens) within a synthesized long context (4K-32K tokens),
and (2) the integration and reasoning of information from two or more short
segments. Through applying this information-intensive training on Mistral-7B,
we present FILM-7B (FILl-in-the-Middle). To thoroughly assess the ability of
FILM-7B for utilizing long contexts, we design three probing tasks that
encompass various context styles (document, code, and structured-data context)
and information retrieval patterns (forward, backward, and bi-directional
retrieval). The probing results demonstrate that FILM-7B can robustly retrieve
information from different positions in its 32K context window. Beyond these
probing tasks, FILM-7B significantly improves the performance on real-world
long-context tasks (e.g., 23.5->26.9 F1 score on NarrativeQA), while
maintaining a comparable performance on short-context tasks (e.g., 59.3->59.2
accuracy on MMLU). Github Link: https://github.com/microsoft/FILM.

摘要：雖然許多當代大型語言模型（LLM）可以處理冗長的
輸入，他們仍然難以在長期內充分利用訊息
上下文，稱為迷失在中間的挑戰。我們假設它
源自於長情境訓練過程中顯性督導不足，
這並沒有強調任何立場在長期背景下都可以發揮至關重要的作用
資訊.基於這種直覺，我們的研究提出了資訊密集型
(IN2) 培訓，純粹的數據驅動解決方案，可克服中間迷失的問題。
具體來說，IN2 訓練利用合成的長上下文問題答案
資料集，其中答案需要（1）對資料集進行細粒度的資訊感知
合成長上下文（4K-32K 標記）內的短片段（~128 個標記），
(2)對兩個或多個短訊息的資訊進行整合和推理
段。透過在 Mistral-7B 上應用此資訊密集型訓練，
我們推出 FILM-7B（中間填充）。全面評估能力
FILM-7B 為了利用長上下文，我們設計了三個探測任務
涵蓋各種上下文樣式（文件、程式碼和結構化資料上下文）
和資訊檢索模式（前向、後向和雙向
恢復）。探測結果顯示 FILM-7B 可以穩健地檢索
來自其 32K 上下文視窗中不同位置的資訊。除了這些
探測任務，FILM-7B 顯著提高了現實世界的效能
長上下文任務（例如，NarrativeQA 上的 F1 分數為 23.5->26.9），而
在短上下文任務上保持可比較的效能（例如，59.3->59.2
MMLU 的準確性）。 Github 連結：https://github.com/microsoft/FILM。

##### **Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning**
2404.16807v1 by Tianhui Zhang et.al.

Generative Commonsense Reasoning (GCR) requires a model to reason about a
situation using commonsense knowledge, while generating coherent sentences.
Although the quality of the generated sentences is crucial, the diversity of
the generation is equally important because it reflects the model's ability to
use a range of commonsense knowledge facts. Large Language Models (LLMs) have
shown proficiency in enhancing the generation quality across various tasks
through in-context learning (ICL) using given examples without the need for any
fine-tuning. However, the diversity aspect in LLM outputs has not been
systematically studied before. To address this, we propose a simple method that
diversifies the LLM generations, while preserving their quality. Experimental
results on three benchmark GCR datasets show that our method achieves an ideal
balance between the quality and diversity. Moreover, the sentences generated by
our proposed method can be used as training data to improve diversity in
existing commonsense generators.

摘要：產生常識推理 (GCR) 需要一個模型來推理
使用常識知識的情況，同時產生連貫的句子。
儘管生成句子的品質至關重要，但句子的多樣性
生成同樣重要，因為它反映了模型的能力
使用一系列常識性知識事實。大型語言模型 (LLM) 有
在提高各種任務的發電品質方面表現出熟練程度
透過使用給定範例的情境學習（ICL），無需任何
微調。然而，LLM 產出的多樣性方面尚未受到重視。
之前系統學習過。為了解決這個問題，我們提出了一個簡單的方法
使法學碩士世代多樣化，同時保持其品質。實驗性的
三個基準 GCR 資料集的結果顯示我們的方法達到了理想的效果
質量和多樣性之間的平衡。此外，產生的句子
我們提出的方法可以用作訓練資料來提高多樣性
現有的常識生成器。

##### **A Short Survey of Human Mobility Prediction in Epidemic Modeling from Transformers to LLMs**
2404.16921v1 by Christian N. Mayemba et.al.

This paper provides a comprehensive survey of recent advancements in
leveraging machine learning techniques, particularly Transformer models, for
predicting human mobility patterns during epidemics. Understanding how people
move during epidemics is essential for modeling the spread of diseases and
devising effective response strategies. Forecasting population movement is
crucial for informing epidemiological models and facilitating effective
response planning in public health emergencies. Predicting mobility patterns
can enable authorities to better anticipate the geographical and temporal
spread of diseases, allocate resources more efficiently, and implement targeted
interventions. We review a range of approaches utilizing both pretrained
language models like BERT and Large Language Models (LLMs) tailored
specifically for mobility prediction tasks. These models have demonstrated
significant potential in capturing complex spatio-temporal dependencies and
contextual patterns in textual data.

摘要：本文對最近的進展進行了全面的調查
利用機器學習技術，特別是 Transformer 模型，
預測流行病期間的人員流動模式。了解人們如何
流行病期間的移動對於模擬疾病的傳播至關重要
制定有效的因應策略。人口流動預測為
對於為流行病學模型提供資訊並促進有效
突發公共衛生事件的反應計畫。預測流動模式
可以使當局更好地預測地理和時間
疾病傳播，更有效地配置資源，針對性地實施
幹預措施。我們回顧了一系列利用預訓練的方法
客製化的語言模型，如 BERT 和大型語言模型 (LLM)
專門用於移動性預測任務。這些模型已經證明
在捕捉複雜的時空依賴性方面具有巨大的潛力
文字資料中的上下文模式。

##### **AAPL: Adding Attributes to Prompt Learning for Vision-Language Models**
2404.16804v1 by Gahyeon Kim et.al.

Recent advances in large pre-trained vision-language models have demonstrated
remarkable performance on zero-shot downstream tasks. Building upon this,
recent studies, such as CoOp and CoCoOp, have proposed the use of prompt
learning, where context within a prompt is replaced with learnable vectors,
leading to significant improvements over manually crafted prompts. However, the
performance improvement for unseen classes is still marginal, and to tackle
this problem, data augmentation has been frequently used in traditional
zero-shot learning techniques. Through our experiments, we have identified
important issues in CoOp and CoCoOp: the context learned through traditional
image augmentation is biased toward seen classes, negatively impacting
generalization to unseen classes. To address this problem, we propose
adversarial token embedding to disentangle low-level visual augmentation
features from high-level class information when inducing bias in learnable
prompts. Through our novel mechanism called "Adding Attributes to Prompt
Learning", AAPL, we guide the learnable context to effectively extract text
features by focusing on high-level features for unseen classes. We have
conducted experiments across 11 datasets, and overall, AAPL shows favorable
performances compared to the existing methods in few-shot learning, zero-shot
learning, cross-dataset, and domain generalization tasks.

摘要：大型預訓練視覺語言模型的最新進展已證明
在零樣本下游任務上表現出色。在此基礎上，
最近的研究，例如 CoOp 和 CoCoOp，提出了使用提示
學習，其中提示中的上下文被可學習的向量替換，
與手動製作的提示相比有了顯著的改進。但是，那
看不見的類別的性能改進仍然很小，並且要解決
這個問題，資料增強在傳統領域中被頻繁使用
零樣本學習技術。透過我們的實驗，我們已經確定
CoOp 和 CoCoOp 中的重要問題：透過傳統方式學習的上下文
影像增強偏向所見類別，產生負面影響
泛化到未見過的類別。為了解決這個問題，我們建議
對抗性令牌嵌入以解開低階視覺增強
在可學習中引入偏差時來自高級類別資訊的特徵
提示。透過我們稱為「向提示添加屬性」的新穎機制
Learning”，AAPL，我們引導可學習的上下文來有效地提取文本
透過專注於看不見的類別的高級功能來實現功能。我們有
在 11 個數據集上進行了實驗，總體而言，AAPL 顯示出良好的結果
與現有方法在少樣本學習、零樣本學習的表現比較
學習、跨資料集和領域泛化任務。

##### **Weak-to-Strong Extrapolation Expedites Alignment**
2404.16792v1 by Chujie Zheng et.al.

Although the capabilities of large language models (LLMs) ideally scale up
with increasing data and compute, they are inevitably constrained by limited
resources in reality. Suppose we have a moderately trained LLM (e.g., trained
to align with human preference) in hand, can we further exploit its potential
and cheaply acquire a stronger model? In this paper, we propose a simple method
called ExPO to boost LLMs' alignment with human preference. ExPO assumes that a
medium-aligned model can be interpolated between a less-aligned (weaker) model,
e.g., the initial SFT model, and a better-aligned (stronger) one, thereby
directly obtaining this stronger model by extrapolating from the weights of the
former two relatively weaker models. On the AlpacaEval 2.0 benchmark, we show
that ExPO pushes models trained with less preference data (e.g., 10% or 20%) to
reach and even surpass the fully-trained one, without any additional training.
Furthermore, ExPO also significantly improves off-the-shelf DPO/RLHF models and
exhibits decent scalability across model sizes from 7B to 70B. Our work
demonstrates the efficacy of model extrapolation in exploiting LLMs'
capabilities, suggesting a promising direction that deserves future
exploration.

摘要：儘管大型語言模型 (LLM) 的功能可以理想地擴展
隨著數據和計算的增加，它們不可避免地受到有限的限制
現實中的資源。假設我們有一個受過中等訓練的法學碩士（例如，訓練有素的法學碩士）
以符合人類偏好）在手，我們可以進一步挖掘其潛力嗎
並以便宜的價格購買更強大的模型？在本文中，我們提出了一個簡單的方法
稱為 ExPO 以促進法學碩士與人類偏好的一致性。世博會假設
中對齊模型可以插值在不太對齊（較弱）模型之間，
例如，最初的 SFT 模型，以及一個更好對齊（更強）的模型，從而
透過從權重推論直接獲得這個更強的模型
前兩個相對較弱的模型。在 AlpacaEval 2.0 基準測試中，我們展示了
ExPO 將使用較少偏好資料（例如 10% 或 20%）訓練的模型推向
無需任何額外訓練即可達到甚至超過經過全面訓練的人。
此外，ExPO 還顯著改進了現成的 DPO/RLHF 模型和
在 7B 到 70B 的模型大小上表現出良好的可擴展性。我們的工作
展示了模型外推法在利用法學碩士的有效性
能力，提出了一個值得未來的有前途的方向
勘探。

##### **Continual Learning of Large Language Models: A Comprehensive Survey**
2404.16789v1 by Haizhou Shi et.al.

The recent success of large language models (LLMs) trained on static,
pre-collected, general datasets has sparked numerous research directions and
applications. One such direction addresses the non-trivial challenge of
integrating pre-trained LLMs into dynamic data distributions, task structures,
and user preferences. Pre-trained LLMs, when tailored for specific needs, often
experience significant performance degradation in previous knowledge domains --
a phenomenon known as "catastrophic forgetting". While extensively studied in
the continual learning (CL) community, it presents new manifestations in the
realm of LLMs. In this survey, we provide a comprehensive overview of the
current research progress on LLMs within the context of CL. This survey is
structured into four main sections: we first describe an overview of
continually learning LLMs, consisting of two directions of continuity: vertical
continuity (or vertical continual learning), i.e., continual adaptation from
general to specific capabilities, and horizontal continuity (or horizontal
continual learning), i.e., continual adaptation across time and domains
(Section 3). We then summarize three stages of learning LLMs in the context of
modern CL: Continual Pre-Training (CPT), Domain-Adaptive Pre-training (DAP),
and Continual Fine-Tuning (CFT) (Section 4). Then we provide an overview of
evaluation protocols for continual learning with LLMs, along with the current
available data sources (Section 5). Finally, we discuss intriguing questions
pertaining to continual learning for LLMs (Section 6). The full list of papers
examined in this survey is available at
https://github.com/Wang-ML-Lab/llm-continual-learning-survey.

摘要：最近，大型語言模型（LLM）在靜態、
預先收集的通用資料集引發了許多研究方向和
應用程式.其中一個方向解決了以下重大挑戰：
將預先訓練的法學碩士整合到動態資料分佈、任務結構中，
和用戶偏好。經過預先培訓的法學碩士，在針對特定需求進行客製化時，通常
在先前的知識領域中經歷了顯著的表現下降——
這種現像被稱為「災難性遺忘」。在廣泛研究的同時
持續學習（CL）社區，它在以下方面呈現出新的表現形式：
LLM 領域。在本次調查中，我們全面概述了
CL 背景下法學碩士的最新研究進度。這項調查是
結構分為四個主要部分：我們首先描述
持續學習法學碩士，包括兩個連續方向：垂直
連續性（或垂直持續學習），即不斷適應
從一般到特定的能力，以及水平連續性（或水平
持續學習），即跨時間和領域的持續適應
（第 3 節）。然後，我們總結了學習法學碩士的三個階段：
現代 CL：持續預訓練（CPT）、領域自適應預訓練（DAP）、
和持續微調 (CFT)（第 4 節）。然後我們提供概述
法學碩士持續學習的評估協議以及當前的
可用的資料來源（第 5 節）。最後我們討論一些有趣的問題
關於法學碩士的持續學習（第 6 節）。論文的完整列表
本次調查中的檢查可在
https://github.com/Wang-ML-Lab/llm-continual-learning-survey。

##### **Modeling Selective Feature Attention for Representation-based Siamese Text Matching**
2404.16776v1 by Jianxiang Zang et.al.

Representation-based Siamese networks have risen to popularity in lightweight
text matching due to their low deployment and inference costs. While word-level
attention mechanisms have been implemented within Siamese networks to improve
performance, we propose Feature Attention (FA), a novel downstream block
designed to enrich the modeling of dependencies among embedding features.
Employing "squeeze-and-excitation" techniques, the FA block dynamically adjusts
the emphasis on individual features, enabling the network to concentrate more
on features that significantly contribute to the final classification. Building
upon FA, we introduce a dynamic "selection" mechanism called Selective Feature
Attention (SFA), which leverages a stacked BiGRU Inception structure. The SFA
block facilitates multi-scale semantic extraction by traversing different
stacked BiGRU layers, encouraging the network to selectively concentrate on
semantic information and embedding features across varying levels of
abstraction. Both the FA and SFA blocks offer a seamless integration capability
with various Siamese networks, showcasing a plug-and-play characteristic.
Experimental evaluations conducted across diverse text matching baselines and
benchmarks underscore the indispensability of modeling feature attention and
the superiority of the "selection" mechanism.

摘要：基於表示的孿生網路在輕量級領域越來越受歡迎
文字匹配，因為其部署和推理成本較低。雖然字級
暹羅網路中已經實施了注意力機制，以改善
在性能方面，我們提出了特徵注意（FA），一種新穎的下游模組
旨在豐富嵌入特徵之間的依賴關係建模。
FA 區塊採用「擠壓與激勵」技術動態調整
強調個體特徵，使網絡更集中
對最終分類有顯著貢獻的特徵。大樓
在 FA 的基礎上，我們引入了一種動態「選擇」機制，稱為選擇性特徵
注意力（SFA），它利用堆疊式 BiGRU Inception 結構。國家林業局
區塊透過遍歷不同的區塊來促進多尺度語義提取
堆疊 BiGRU 層，鼓勵網路選擇性地專注於
不同層次的語意資訊與嵌入特徵
抽象。 FA 和 SFA 模組均提供無縫整合功能
具有各種暹羅網絡，表現出即插即用的特性。
跨不同文本匹配基線進行的實驗評估
基準強調了建模特徵注意力的必要性和
「選拔」機制的優越性。

##### **REBEL: Reinforcement Learning via Regressing Relative Rewards**
2404.16767v1 by Zhaolin Gao et.al.

While originally developed for continuous control problems, Proximal Policy
Optimization (PPO) has emerged as the work-horse of a variety of reinforcement
learning (RL) applications including the fine-tuning of generative models.
Unfortunately, PPO requires multiple heuristics to enable stable convergence
(e.g. value networks, clipping) and is notorious for its sensitivity to the
precise implementation of these components. In response, we take a step back
and ask what a minimalist RL algorithm for the era of generative models would
look like. We propose REBEL, an algorithm that cleanly reduces the problem of
policy optimization to regressing the relative rewards via a direct policy
parameterization between two completions to a prompt, enabling strikingly
lightweight implementation. In theory, we prove that fundamental RL algorithms
like Natural Policy Gradient can be seen as variants of REBEL, which allows us
to match the strongest known theoretical guarantees in terms of convergence and
sample complexity in the RL literature. REBEL can also cleanly incorporate
offline data and handle the intransitive preferences we frequently see in
practice. Empirically, we find that REBEL provides a unified approach to
language modeling and image generation with stronger or similar performance as
PPO and DPO, all while being simpler to implement and more computationally
tractable than PPO.

摘要：雖然最初是為連續控制問題而開發的，但近端策略
優化 (PPO) 已成為各種強化的主力
學習（RL）應用，包括生成模型的微調。
不幸的是，PPO 需要多種啟發式方法才能穩定收斂
（例如價值網、剪裁）並且因其對
這些組件的精確實現。作為回應，我們退後一步
並詢問生成模型時代的極簡強化學習演算法會帶來什麼
看起來像。我們提出 REBEL，一種可以徹底減少以下問題的演算法：
透過直接策略回歸相對獎勵的策略優化
兩個完成之間的參數化到提示，從而顯著地實現
輕量級實作。理論上，我們證明了基本的 RL 演算法
像 Natural Policy Gradient 可以看作是 REBEL 的變體，它允許我們
在收斂性和
強化學習文獻中的樣本複雜度。 REBEL 也可以乾淨地合併
離線資料並處理我們經常看到的不及物偏好
實踐。根據經驗，我們發現 REBEL 提供了一種統一的方法
語言建模和圖像生成具有更強或相似的性能
PPO 和 DPO，同時更易於實現且運算能力更強
比 PPO 更容易處理。

##### **Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation Language Model**
2404.16766v1 by Runzhe Zhan et.al.

While supervised fine-tuning (SFT) has been a straightforward approach for
tailoring the output of foundation large language model (LLM) to specific
preferences, concerns have been raised about the depth of this alignment, with
some critiques suggesting it is merely "superficial". We critically examine
this hypothesis within the scope of cross-lingual generation tasks, proposing
that the effectiveness of SFT may be constrained by its reliance on prior
tokens to guide cross-lingual generation. Based on this crucial insight, and in
response to the challenges posed by the costly and limited availability of
non-English data for SFT, we introduce a novel training-free alignment method
named PreTTY, which employs minimal task-related prior tokens to bridge the
foundation LLM and the SFT LLM, achieving comparable performance without
training. Experiments on machine translation and part-of-speech tagging across
eight languages demonstrate the efficacy of PreTTY in cross-lingual settings.
Remarkably, by initiating the decoding process with only one or two prior
tokens, foundation LLMs can achieve performance comparable to their SFT
counterparts. This method presents a cost-effective alternative to SFT and
advances the democratization of multilingual LLMs.

摘要：雖然監督微調（SFT）是一種簡單的方法
根據具體情況自訂基礎大語言模型（LLM）的輸出
偏好，人們對這種一致性的深度提出了擔憂，
一些批評認為這只是「膚淺的」。我們批判性地審視
這個假設在跨語言生成任務的範圍內，提出
SFT 的有效性可能會因其對先前經驗的依賴而受到限制
指導跨語言生成的標記。基於這一重要的見解，並在
應對成本高且供應有限所帶來的挑戰
SFT 的非英語數據，我們引入了一種新穎的免訓練對齊方法
名為 PreTTY，它使用最少的與任務相關的先驗令牌來橋接
基礎法學碩士和 SFT 法學碩士，無需
訓練。機器翻譯和詞性標註的實驗
八種語言證明了 PreTTY 在跨語言環境中的功效。
值得注意的是，透過僅使用一兩個先前的資訊來啟動解碼過程
代幣，基礎 LLM 可以實現與 SFT 相當的性能
同行。該方法提供了 SFT 的一種經濟有效的替代方案
促進多語言法學碩士的民主化。

##### **Automatic Speech Recognition System-Independent Word Error Rate Estimation**
2404.16743v2 by Chanho Park et.al.

Word error rate (WER) is a metric used to evaluate the quality of
transcriptions produced by Automatic Speech Recognition (ASR) systems. In many
applications, it is of interest to estimate WER given a pair of a speech
utterance and a transcript. Previous work on WER estimation focused on building
models that are trained with a specific ASR system in mind (referred to as ASR
system-dependent). These are also domain-dependent and inflexible in real-world
applications. In this paper, a hypothesis generation method for ASR
System-Independent WER estimation (SIWE) is proposed. In contrast to prior
work, the WER estimators are trained using data that simulates ASR system
output. Hypotheses are generated using phonetically similar or linguistically
more likely alternative words. In WER estimation experiments, the proposed
method reaches a similar performance to ASR system-dependent WER estimators on
in-domain data and achieves state-of-the-art performance on out-of-domain data.
On the out-of-domain data, the SIWE model outperformed the baseline estimators
in root mean square error and Pearson correlation coefficient by relative
17.58% and 18.21%, respectively, on Switchboard and CALLHOME. The performance
was further improved when the WER of the training set was close to the WER of
the evaluation dataset.

摘要：單字錯誤率（WER）是用來評估單字品質的指標
自動語音辨識 (ASR) 系統產生的轉錄。在許多
在應用程式中，在給定一對語音的情況下估計 WER 是很有趣的
話語和文字記錄。先前關於 WER 估算的工作重點是構建
使用特定 ASR 系統進行訓練的模型（稱為 ASR
取決於系統）。這些在現實世界中也是依賴領域且不靈活的
應用程式.本文提出了一種 ASR 假設生成方法
提出了系統無關的 WER 估計（SIWE）。與之前相比
工作中，WER 估計器使用模擬 ASR 系統的資料進行訓練
輸出。使用語音相似或語言上的相似性產生假設
更有可能的替代詞。在WER估計實驗中，提出了
方法在以下方面達到了與 ASR 系統相關的 WER 估計器相似的性能
域內數據，並在域外數據上實現最先進的效能。
在域外資料上，SIWE 模型優於基準估計器
均方根誤差和皮爾遜相關係數的相對
在總機和 CALLHOME 上分別為 17.58% 和 18.21%。效能
當訓練集的WER接近於
評估數據集。

##### **Distilling Privileged Information for Dubins Traveling Salesman Problems with Neighborhoods**
2404.16721v1 by Min Kyu Shin et.al.

This paper presents a novel learning approach for Dubins Traveling Salesman
Problems(DTSP) with Neighborhood (DTSPN) to quickly produce a tour of a
non-holonomic vehicle passing through neighborhoods of given task points. The
method involves two learning phases: initially, a model-free reinforcement
learning approach leverages privileged information to distill knowledge from
expert trajectories generated by the LinKernighan heuristic (LKH) algorithm.
Subsequently, a supervised learning phase trains an adaptation network to solve
problems independently of privileged information. Before the first learning
phase, a parameter initialization technique using the demonstration data was
also devised to enhance training efficiency. The proposed learning method
produces a solution about 50 times faster than LKH and substantially
outperforms other imitation learning and RL with demonstration schemes, most of
which fail to sense all the task points.

摘要：本文提出了杜賓斯旅行推銷員的一種新穎的學習方法
Problems(DTSP) with Neighborhood (DTSPN) 快速產生一個遊覽
經過給定任務點鄰域的非完整車輛。這
方法涉及兩個學習階段：最初是無模型強化
學習方法利用特權資訊來提取知識
由 LinKernighan 啟發式 (LKH) 演算法產生的專家軌跡。
隨後，監督學習階段訓練適應網路來解決
獨立於特權資訊的問題。第一次學習前
階段，使用演示資料的參數初始化技術是
也旨在提高培訓效率。提出的學習方法
產生解決方案的速度比 LKH 快約 50 倍，並且顯著提高
透過演示方案優於其他模仿學習和強化學習，大多數
無法感知所有任務點。

##### **Features Fusion for Dual-View Mammography Mass Detection**
2404.16718v1 by Arina Varlamova et.al.

Detection of malignant lesions on mammography images is extremely important
for early breast cancer diagnosis. In clinical practice, images are acquired
from two different angles, and radiologists can fully utilize information from
both views, simultaneously locating the same lesion. However, for automatic
detection approaches such information fusion remains a challenge. In this
paper, we propose a new model called MAMM-Net, which allows the processing of
both mammography views simultaneously by sharing information not only on an
object level, as seen in existing works, but also on a feature level.
MAMM-Net's key component is the Fusion Layer, based on deformable attention and
designed to increase detection precision while keeping high recall. Our
experiments show superior performance on the public DDSM dataset compared to
the previous state-of-the-art model, while introducing new helpful features
such as lesion annotation on pixel-level and classification of lesions
malignancy.

摘要：乳房X光攝影影像上惡性病變的檢測極為重要
用於早期乳癌診斷。在臨床實務中，取得影像
從兩個不同的角度，放射科醫生可以充分利用來自
兩個視圖同時定位同一病變。然而，對於自動
這種資訊融合的檢測方法仍然是一個挑戰。在這個
在論文中，我們提出了一種稱為 MAMM-Net 的新模型，它允許處理
透過分享訊息，不僅可以同時取得乳房 X 光檢查視圖
物件級別，如現有作品中所見，而且還包括特徵級別。
MAMM-Net 的關鍵組件是融合層，基於可變形注意力和
旨在提高檢測精度，同時保持高召回率。我們的
實驗表明，與公共 DDSM 資料集相比，該資料集具有優越的效能
以前最先進的模型，同時引入新的實用功能
例如像素級的病灶標註和病灶分類
惡性腫瘤。

##### **Embracing Diversity: Interpretable Zero-shot classification beyond one vector per class**
2404.16717v1 by Mazda Moayeri et.al.

Vision-language models enable open-world classification of objects without
the need for any retraining. While this zero-shot paradigm marks a significant
advance, even today's best models exhibit skewed performance when objects are
dissimilar from their typical depiction. Real world objects such as pears
appear in a variety of forms -- from diced to whole, on a table or in a bowl --
yet standard VLM classifiers map all instances of a class to a \it{single
vector based on the class label}. We argue that to represent this rich
diversity within a class, zero-shot classification should move beyond a single
vector. We propose a method to encode and account for diversity within a class
using inferred attributes, still in the zero-shot setting without retraining.
We find our method consistently outperforms standard zero-shot classification
over a large suite of datasets encompassing hierarchies, diverse object states,
and real-world geographic diversity, as well finer-grained datasets where
intra-class diversity may be less prevalent. Importantly, our method is
inherently interpretable, offering faithful explanations for each inference to
facilitate model debugging and enhance transparency. We also find our method
scales efficiently to a large number of attributes to account for diversity --
leading to more accurate predictions for atypical instances. Finally, we
characterize a principled trade-off between overall and worst class accuracy,
which can be tuned via a hyperparameter of our method. We hope this work spurs
further research into the promise of zero-shot classification beyond a single
class vector for capturing diversity in the world, and building transparent AI
systems without compromising performance.

摘要：視覺語言模型可以實現物件的開放世界分類，而無需
任何再培訓的需要。雖然這個零樣本範式標誌著一個重要的
進步，即使是當今最好的模型，當物件被
與他們的典型描述不同。現實世界的物體，例如梨
以各種形式出現——從切塊到整塊，放在桌子上或放在碗裡——
然而標準的 VLM 分類器將一個類別的所有實例映射到一個 \it{single
基於類別標籤的向量}。我們認為要代表這個富人
類內的多樣性，零樣本分類應超越單一分類
向量。我們提出了一種編碼和解釋類內多樣性的方法
使用推斷的屬性，仍然處於零樣本設置，無需重新訓練。
我們發現我們的方法始終優於標準零樣本分類
在一大套包含層次結構、不同物件狀態的資料集上，
和現實世界的地理多樣性，以及更細緻的資料集
班級內的多樣性可能不太普遍。重要的是，我們的方法是
本質上是可解釋的，為每個推論提供忠實的解釋
方便模型調試並增強透明度。我們也找到了我們的方法
有效地擴展到大量屬性以考慮多樣性——
從而對非典型實例進行更準確的預測。最後，我們
描述總體精度和最差精度之間的原則權衡，
可以透過我們方法的超參數進行調整。我們希望這項工作能夠刺激
進一步研究零樣本分類的前景
用於捕捉世界多樣性並建立透明人工智慧的類向量
系統而不影響性能。

##### **Layer Skip: Enabling Early Exit Inference and Self-Speculative Decoding**
2404.16710v1 by Mostafa Elhoushi et.al.

We present LayerSkip, an end-to-end solution to speed-up inference of large
language models (LLMs). First, during training we apply layer dropout, with low
dropout rates for earlier layers and higher dropout rates for later layers, and
an early exit loss where all transformer layers share the same exit. Second,
during inference, we show that this training recipe increases the accuracy of
early exit at earlier layers, without adding any auxiliary layers or modules to
the model. Third, we present a novel self-speculative decoding solution where
we exit at early layers and verify and correct with remaining layers of the
model. Our proposed self-speculative decoding approach has less memory
footprint than other speculative decoding approaches and benefits from shared
compute and activations of the draft and verification stages. We run
experiments on different Llama model sizes on different types of training:
pretraining from scratch, continual pretraining, finetuning on specific data
domain, and finetuning on specific task. We implement our inference solution
and show speedups of up to 2.16x on summarization for CNN/DM documents, 1.82x
on coding, and 2.0x on TOPv2 semantic parsing task.

摘要：我們提出了 LayerSkip，這是一個端到端的解決方案，可加速大型資料的推理。
語言模型（法學碩士）。首先，在訓練期間我們應用層 dropout，具有較低的
較早層的輟學率和較後層較高的輟學率，以及
所有變壓器層共享相同出口的早期出口損耗。第二，
在推理過程中，我們顯示這種訓練方法提高了
在較早的層提前退出，無需添加任何輔助層或模組
該模型。第三，我們提出了一種新穎的自推測解碼解決方案，其中
我們在早期層退出並驗證並修正剩餘層
模型。我們提出的自推測解碼方法具有較少的內存
比其他推測解碼方法佔用空間小，並且受益於共享
草稿和驗證階段的計算和啟動。我們跑
在不同類型的訓練中對不同大小的 Llama 模型進行實驗：
從頭開始預訓練，持續預先訓練，針對特定資料微調
域，並對特定任務進行微調。我們實作我們的推理解決方案
CNN/DM 文件的摘要速度提升高達 2.16 倍，1.82 倍
編碼方面是 2.0 倍，TOPv2 語意解析任務面向是 2.0 倍。

##### **Cooperate or Collapse: Emergence of Sustainability Behaviors in a Society of LLM Agents**
2404.16698v1 by Giorgio Piatti et.al.

In the rapidly evolving field of artificial intelligence, ensuring safe
decision-making of Large Language Models (LLMs) is a significant challenge.
This paper introduces Governance of the Commons Simulation (GovSim), a
simulation platform designed to study strategic interactions and cooperative
decision-making in LLMs. Through this simulation environment, we explore the
dynamics of resource sharing among AI agents, highlighting the importance of
ethical considerations, strategic planning, and negotiation skills. GovSim is
versatile and supports any text-based agent, including LLMs agents. Using the
Generative Agent framework, we create a standard agent that facilitates the
integration of different LLMs. Our findings reveal that within GovSim, only two
out of 15 tested LLMs managed to achieve a sustainable outcome, indicating a
significant gap in the ability of models to manage shared resources.
Furthermore, we find that by removing the ability of agents to communicate,
they overuse the shared resource, highlighting the importance of communication
for cooperation. Interestingly, most LLMs lack the ability to make
universalized hypotheses, which highlights a significant weakness in their
reasoning skills. We open source the full suite of our research results,
including the simulation environment, agent prompts, and a comprehensive web
interface.

摘要：在快速發展的人工智慧領域，確保安全
大型語言模型（LLM）的決策是一項重大挑戰。
本文介紹了公共治理模擬（GovSim），
旨在研究策略互動和合作的模擬平台
LLM 的決策。透過這個模擬環境，我們探索
人工智慧代理之間資源共享的動態，強調了
道德考量、策略規劃和談判技巧。 GovSim 是
用途廣泛，支援任何基於文本的代理，包括法學碩士代理。使用
產生代理框架，我們建立一個標準代理，以促進
不同法學碩士的整合。我們的研究結果表明，在 GovSim 中，只有兩個
15 個接受測試的法學碩士中有 1 個成功實現了可持續的成果，這表明
模型管理共享資源的能力有顯著差距。
此外，我們發現透過消除代理的通訊能力，
他們過度使用共享資源，強調溝通的重要性
合作。有趣的是，大多數法學碩士缺乏能力
普遍化的假設，凸顯了它們的一個重大弱點
推理能力。我們開源全套研究成果，
包括模擬環境、代理提示和綜合網絡
介面.

##### **Influence of Solution Efficiency and Valence of Instruction on Additive and Subtractive Solution Strategies in Humans and GPT-4**
2404.16692v1 by Lydia Uhler et.al.

We explored the addition bias, a cognitive tendency to prefer adding elements
over removing them to alter an initial state or structure, by conducting four
preregistered experiments examining the problem-solving behavior of both humans
and OpenAl's GPT-4 large language model. The experiments involved 588
participants from the U.S. and 680 iterations of the GPT-4 model. The
problem-solving task was either to create symmetry within a grid (Experiments 1
and 3) or to edit a summary (Experiments 2 and 4). As hypothesized, we found
that overall, the addition bias was present. Solution efficiency (Experiments 1
and 2) and valence of the instruction (Experiments 3 and 4) played important
roles. Human participants were less likely to use additive strategies when
subtraction was relatively more efficient than when addition and subtraction
were equally efficient. GPT-4 exhibited the opposite behavior, with a strong
addition bias when subtraction was more efficient. In terms of instruction
valence, GPT-4 was more likely to add words when asked to "improve" compared to
"edit", whereas humans did not show this effect. When we looked at the addition
bias under different conditions, we found more biased responses for GPT-4
compared to humans. Our findings highlight the importance of considering
comparable and sometimes superior subtractive alternatives, as well as
reevaluating one's own and particularly the language models' problem-solving
behavior.

摘要：我們探討了加法偏差，這是一種更喜歡添加元素的認知傾向
透過進行四次移除它們來改變初始狀態或結構
預先註冊的實驗檢查人類解決問題的行為
以及 OpenAl 的 GPT-4 大語言模型。實驗涉及588
來自美國的參與者和 GPT-4 模型的 680 次迭代。這
解決問題的任務是在網格內創建對稱性（實驗 1
3) 或編輯摘要（實驗 2 和 4）。正如假設的那樣，我們發現
整體而言，存在加法偏差。解決方案效率（實驗 1
2) 指令的效價（實驗 3 和 4）很重要
角色。當人類參與者不太可能使用附加策略時
減法比加法和減法相對更有效
同樣有效。 GPT-4 表現出相反的行為，具有很強的
當減法更有效時，加法偏差。在教學方面
價，與相比，GPT-4 在被要求“改進”時更有可能添加單詞
“編輯”，而人類卻沒有表現出這種效果。當我們查看添加內容時
不同條件下的偏差，我們發現 GPT-4 的反應有較多偏差
與人類相比。我們的研究結果強調了考慮的重要性
類似的、有時甚至是更優越的減法替代方案，以及
重新評估自己的語言模型，特別是語言模型解決問題的能力
行為。

##### **Prediction Is All MoE Needs: Expert Load Distribution Goes from Fluctuating to Stabilizing**
2404.16914v1 by Peizhuang Cong et.al.

MoE facilitates the development of large models by making the computational
complexity of the model no longer scale linearly with increasing parameters.
The learning sparse gating network selects a set of experts for each token to
be processed; however, this may lead to differences in the number of tokens
processed by each expert over several successive iterations, i.e., the expert
load fluctuations, which reduces computational parallelization and resource
utilization. To this end, we traced and analyzed loads of each expert in the
training iterations for several large language models in this work, and defined
the transient state with "obvious load fluctuation" and the stable state with
"temporal locality". Moreover, given the characteristics of these two states
and the computational overhead, we deployed three classical prediction
algorithms that achieve accurate expert load prediction results. For the GPT3
350M model, the average error rates for predicting the expert load proportion
over the next 1,000 and 2,000 steps are approximately 1.3% and 1.8%,
respectively. This work can provide valuable guidance for expert placement or
resource allocation for MoE model training. Based on this work, we will propose
an expert placement scheme for transient and stable states in our coming work.

摘要：MoE 透過計算計算來促進大型模型的開發
模型的複雜度不再隨著參數的增加而線性擴展。
學習稀疏門網路為每個令牌選擇一組專家
被處理；然而，這可能會導致代幣數量的差異
由每個專家在多次連續迭代中處理，即專家
負載波動，這減少了計算並行性和資源
利用率。為此，我們對每個專家的負荷進行了追蹤和分析。
本工作中幾個大型語言模型的訓練迭代，並定義
「負載波動明顯」的瞬態和「負載波動明顯」的穩定狀態
「時間局部性」。此外，考慮到這兩個州的特點
和計算開銷，我們部署了三種經典預測
獲得準確的專家負載預測結果的演算法。對於 GPT3
350M模型，預測專家負載比例的平均錯誤率
接下來的 1,000 和 2,000 步分別約為 1.3% 和 1.8%，
分別。這項工作可以為專家安置或
教育部模型培訓的資源分配。基於這項工作，我們將提出
在我們接下來的工作中，針對瞬態和穩定狀態的專家安置計劃。

##### **DE-CGAN: Boosting rTMS Treatment Prediction with Diversity Enhancing Conditional Generative Adversarial Networks**
2404.16913v1 by Matthew Squires et.al.

Repetitive Transcranial Magnetic Stimulation (rTMS) is a well-supported,
evidence-based treatment for depression. However, patterns of response to this
treatment are inconsistent. Emerging evidence suggests that artificial
intelligence can predict rTMS treatment outcomes for most patients using fMRI
connectivity features. While these models can reliably predict treatment
outcomes for many patients for some underrepresented fMRI connectivity measures
DNN models are unable to reliably predict treatment outcomes. As such we
propose a novel method, Diversity Enhancing Conditional General Adversarial
Network (DE-CGAN) for oversampling these underrepresented examples. DE-CGAN
creates synthetic examples in difficult-to-classify regions by first
identifying these data points and then creating conditioned synthetic examples
to enhance data diversity. Through empirical experiments we show that a
classification model trained using a diversity enhanced training set
outperforms traditional data augmentation techniques and existing benchmark
results. This work shows that increasing the diversity of a training dataset
can improve classification model performance. Furthermore, this work provides
evidence for the utility of synthetic patients providing larger more robust
datasets for both AI researchers and psychiatrists to explore variable
relationships.

摘要：重複經顱磁刺激 (rTMS) 是一種經過充分支持的、
憂鬱症的實證治療。然而，對此的反應模式
治療不一致。新出現的證據表明，人工
智力可以使用 fMRI 預測大多數患者的 rTMS 治療結果
連接功能。雖然這些模型可以可靠地預測治療
許多患者的一些代表性不足的功能性磁振造影連接測量的結果
DNN 模型無法可靠地預測治療結果。因此我們
提出一種新方法，多樣性增強條件一般對抗性
網路（DE-CGAN）用於對這些代表性不足的範例進行過採樣。德-CGAN
首先在難以分類的區域創建綜合範例
識別這些資料點，然後建立條件合成範例
以增強數據多樣性。透過實證實驗我們表明
使用多樣性增強訓練集訓練的分類模型
優於傳統資料增強技術和現有基準
結果。這項工作表明，增加訓練資料集的多樣性
可以提高分類模型的效能。此外，這項工作還提供了
合成患者效用的證據提供更大更穩健
供人工智慧研究人員和精神科醫生探索變數的資料集
關係。

##### **EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning**
2404.16670v1 by Hongxia Xie et.al.

Visual Instruction Tuning represents a novel learning paradigm involving the
fine-tuning of pre-trained language models using task-specific instructions.
This paradigm shows promising zero-shot results in various natural language
processing tasks but is still unexplored in vision emotion understanding. In
this work, we focus on enhancing the model's proficiency in understanding and
adhering to instructions related to emotional contexts. Initially, we identify
key visual clues critical to visual emotion recognition. Subsequently, we
introduce a novel GPT-assisted pipeline for generating emotion visual
instruction data, effectively addressing the scarcity of annotated instruction
data in this domain. Expanding on the groundwork established by InstructBLIP,
our proposed EmoVIT architecture incorporates emotion-specific instruction
data, leveraging the powerful capabilities of Large Language Models to enhance
performance. Through extensive experiments, our model showcases its proficiency
in emotion classification, adeptness in affective reasoning, and competence in
comprehending humor. The comparative analysis provides a robust benchmark for
Emotion Visual Instruction Tuning in the era of LLMs, providing valuable
insights and opening avenues for future exploration in this domain. Our code is
available at \url{https://github.com/aimmemotion/EmoVIT}.

摘要：視覺指令調整代表了一種新穎的學習範式，涉及
使用特定於任務的指令對預先訓練的語言模型進行微調。
該範例在各種自然語言中顯示出有希望的零樣本結果
處理任務，但在視覺情緒理解方面仍未被探索。在
這項工作，我們專注於提高模型理解和理解的能力
遵守與情緒背景相關的指示。最初，我們確定
對視覺情緒識別至關重要的關鍵視覺線索。隨後，我們
引入一種新穎的 GPT 輔助管道來產生情感視覺
指令數據，有效解決註釋指令稀缺問題
該域中的資料。擴展 InstructBLIP 建立的基礎，
我們提出的 EmoVIT 架構融合了特定於情感的指令
數據，利用大語言模型的強大功能來增強
表現。透過大量的實驗，我們的模型展示了它的熟練程度
情緒分類、情緒推理能力與能力
理解幽默。比較分析為以下方面提供了可靠的基準：
法學碩士時代的情感視覺教學調優，提供有價值的
為該領域的未來探索提供見解和開闢途徑。我們的程式碼是
可在 \url{https://github.com/aimmemotion/EmoVIT} 取得。

##### **Formal Specification, Assessment, and Enforcement of Fairness for Generative AIs**
2404.16663v2 by Chih-Hong Cheng et.al.

Reinforcing or even exacerbating societal biases and inequalities will
increase significantly as generative AI increasingly produces useful artifacts,
from text to images and beyond, for the real world. We address these issues by
formally characterizing the notion of fairness for generative AI as a basis for
monitoring and enforcing fairness. We define two levels of fairness using the
notion of infinite sequences of abstractions of AI-generated artifacts such as
text or images. The first is the fairness demonstrated on the generated
sequences, which is evaluated only on the outputs while agnostic to the prompts
and models used. The second is the inherent fairness of the generative AI
model, which requires that fairness be manifested when input prompts are
neutral, that is, they do not explicitly instruct the generative AI to produce
a particular type of output. We also study relative intersectional fairness to
counteract the combinatorial explosion of fairness when considering multiple
categories together with lazy fairness enforcement. Finally, fairness
monitoring and enforcement are tested against some current generative AI
models.

摘要：加強甚至加劇社會偏見和不平等將會
隨著生成式人工智慧越來越多地產生有用的工件，顯著增加，
從文字到圖像等等，適用於現實世界。我們透過以下方式解決這些問題
正式描述產生人工智慧的公平概念作為基礎
監督和執行公平性。我們使用以下方法定義兩個層級的公平性：
人工智慧產生的工件的無限抽象序列的概念，例如
文字或圖像。首先是生成的公平性
序列，僅根據輸出進行評估，而與提示無關
以及使用的型號。二是生成式AI固有的公平性
模型，要求在輸入提示時體現公平性
中立的，也就是說，它們沒有明確指示生成式人工智慧生成
特定類型的輸出。我們也研究相對交叉公平性
考慮多個時抵消公平性的組合爆炸
類別與惰性公平執行。最後，公平
監控和執行針對當前的一些生成式人工智慧進行了測試
楷模。

##### **Benchmarking Mobile Device Control Agents across Diverse Configurations**
2404.16660v1 by Juyong Lee et.al.

Developing autonomous agents for mobile devices can significantly enhance
user interactions by offering increased efficiency and accessibility. However,
despite the growing interest in mobile device control agents, the absence of a
commonly adopted benchmark makes it challenging to quantify scientific progress
in this area. In this work, we introduce B-MoCA: a novel benchmark designed
specifically for evaluating mobile device control agents. To create a realistic
benchmark, we develop B-MoCA based on the Android operating system and define
60 common daily tasks. Importantly, we incorporate a randomization feature that
changes various aspects of mobile devices, including user interface layouts and
language settings, to assess generalization performance. We benchmark diverse
agents, including agents employing large language models (LLMs) or multi-modal
LLMs as well as agents trained from scratch using human expert demonstrations.
While these agents demonstrate proficiency in executing straightforward tasks,
their poor performance on complex tasks highlights significant opportunities
for future research to enhance their effectiveness. Our source code is publicly
available at https://b-moca.github.io.

摘要：為行動裝置開發自主代理可以顯著增強
透過提供更高的效率和可訪問性來進行使用者互動。然而，
儘管人們對行動裝置控制代理越來越感興趣，但缺乏
普遍採用的基準使得量化科學進步具有挑戰性
在這個區域。在這項工作中，我們介紹了 B-MoCA：一種新穎的基準設計
專門用於評估行動裝置控制代理。創造一個現實的
benchmark，我們基於Android作業系統開發B-MoCA並定義
60 項常見日常任務。重要的是，我們採用了隨機化功能
改變了行動裝置的各個方面，包括使用者介面佈局和
語言設置，以評估泛化性能。我們對標多元化
代理，包括採用大語言模型（LLM）或多模式的代理
法學碩士和代理人使用人類專家演示從頭開始接受培訓。
雖然這些代理表現出執行簡單任務的熟練程度，
他們在複雜任務上的糟糕表現突顯了重要的機會
以便未來的研究提高其有效性。我們的原始碼是公開的
可以在 https://b-moca.github.io 取得。

##### **ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling**
2404.16659v1 by Sangryul Kim et.al.

Recently, deep learning-based language models have significantly enhanced
text-to-SQL tasks, with promising applications in retrieving patient records
within the medical domain. One notable challenge in such applications is
discerning unanswerable queries. Through fine-tuning model, we demonstrate the
feasibility of converting medical record inquiries into SQL queries.
Additionally, we introduce an entropy-based method to identify and filter out
unanswerable results. We further enhance result quality by filtering
low-confidence SQL through log probability-based distribution, while
grammatical and schema errors are mitigated by executing queries on the actual
database. We experimentally verified that our method can filter unanswerable
questions, which can be widely utilized even when the parameters of the model
are not accessible, and that it can be effectively utilized in practice.

摘要：最近，基於深度學習的語言模型顯著增強了
文字到 SQL 任務，在檢索病患記錄方面具有廣泛的應用前景
在醫學領域內。此類應用中的一個顯著挑戰是
辨別無法回答的問題。透過微調模型，我們證明了
將病歷查詢轉換為 SQL 查詢的可行性。
此外，我們引入了一種基於熵的方法來識別和過濾掉
無法回答的結果。我們透過過濾進一步提高結果品質
透過基於日誌機率的分佈來降低置信度 SQL，同時
透過對實際資料執行查詢可以減少語法和模式錯誤
資料庫.我們實驗驗證了我們的方法可以過濾無法回答的
問題，即使模型的參數
是不可獲取的，並且可以在實踐中有效利用。

##### **A Self-Organizing Clustering System for Unsupervised Distribution Shift Detection**
2404.16656v1 by Sebastián Basterrech et.al.

Modeling non-stationary data is a challenging problem in the field of
continual learning, and data distribution shifts may result in negative
consequences on the performance of a machine learning model. Classic learning
tools are often vulnerable to perturbations of the input covariates, and are
sensitive to outliers and noise, and some tools are based on rigid algebraic
assumptions. Distribution shifts are frequently occurring due to changes in raw
materials for production, seasonality, a different user base, or even
adversarial attacks. Therefore, there is a need for more effective distribution
shift detection techniques.
  In this work, we propose a continual learning framework for monitoring and
detecting distribution changes. We explore the problem in a latent space
generated by a bio-inspired self-organizing clustering and statistical aspects
of the latent space. In particular, we investigate the projections made by two
topology-preserving maps: the Self-Organizing Map and the Scale Invariant Map.
Our method can be applied in both a supervised and an unsupervised context. We
construct the assessment of changes in the data distribution as a comparison of
Gaussian signals, making the proposed method fast and robust. We compare it to
other unsupervised techniques, specifically Principal Component Analysis (PCA)
and Kernel-PCA. Our comparison involves conducting experiments using sequences
of images (based on MNIST and injected shifts with adversarial samples),
chemical sensor measurements, and the environmental variable related to ozone
levels. The empirical study reveals the potential of the proposed approach.

摘要：對非平穩資料進行建模是該領域的一個具有挑戰性的問題
持續學習和數據分佈變化可能會導致負面影響
對機器學習模型性能的影響。經典學習
工具通常容易受到輸入協變量的擾動，並且
對異常值和雜訊敏感，有些工具基於剛性代數
假設。由於原始數據的變化，分佈變化經常發生
生產材料、季節性、不同的使用者群，甚至
對抗性攻擊。因此，需要更有效的分配
位移檢測技術。
  在這項工作中，我們提出了一個持續學習框架來監控和
檢測分佈變化。我們在潛在空間中探索問題
由生物啟發的自組織聚類和統計方面生成
的潛在空間。我們特別調查了兩個人所做的預測
拓樸保持映射：自組織映射和尺度不變映射。
我們的方法可以應用於有監督和無監督的環境。我們
建構對資料分佈變化的評估作為比較
高斯訊號，使得所提出的方法快速且穩健。我們將其與
其他無監督技術，特別是主成分分析 (PCA)
和核PCA。我們的比較涉及使用序列進行實驗
影像（基於 MNIST 和注射對抗性樣本的偏移），
化學感測器測量以及與臭氧相關的環境變量
水平。實證研究揭示了所提出方法的潛力。

##### **Análise de ambiguidade linguística em modelos de linguagem de grande escala (LLMs)**
2404.16653v1 by Lavínia de Carvalho Moraes et.al.

Linguistic ambiguity continues to represent a significant challenge for
natural language processing (NLP) systems, notwithstanding the advancements in
architectures such as Transformers and BERT. Inspired by the recent success of
instructional models like ChatGPT and Gemini (In 2023, the artificial
intelligence was called Bard.), this study aims to analyze and discuss
linguistic ambiguity within these models, focusing on three types prevalent in
Brazilian Portuguese: semantic, syntactic, and lexical ambiguity. We create a
corpus comprising 120 sentences, both ambiguous and unambiguous, for
classification, explanation, and disambiguation. The models capability to
generate ambiguous sentences was also explored by soliciting sets of sentences
for each type of ambiguity. The results underwent qualitative analysis, drawing
on recognized linguistic references, and quantitative assessment based on the
accuracy of the responses obtained. It was evidenced that even the most
sophisticated models, such as ChatGPT and Gemini, exhibit errors and
deficiencies in their responses, with explanations often providing
inconsistent. Furthermore, the accuracy peaked at 49.58 percent, indicating the
need for descriptive studies for supervised learning.

摘要：語言歧義仍然是一項重大挑戰
自然語言處理（NLP）系統，儘管在
Transformer 和 BERT 等架構。受到最近成功的啟發
ChatGPT 和 Gemini 等教學模型（2023 年，人工
智力被稱為吟遊詩人。
這些模型中的語言歧義，重點在於以下三種類型：
巴西葡萄牙語：語義、句法和詞彙歧義。我們創建一個
語料包含 120 個句子，包括歧義和明確的句子，例如
分類、解釋和消歧。該模型能夠
也透過徵求句子集來探索生成歧義句子
對於每種類型的歧義。對結果進行定性分析，繪製
公認的語言參考，並基於
所獲得的響應的準確性。事實證明，即使是最
複雜的模型，例如 ChatGPT 和 Gemini，會出現錯誤且
他們的回答有缺陷，並經常提供解釋
不一致。此外，準確率達到峰值 49.58%，表明
監督學習需要描述性研究。

##### **Tele-FLM Technical Report**
2404.16645v1 by Xiang Li et.al.

Large language models (LLMs) have showcased profound capabilities in language
understanding and generation, facilitating a wide array of applications.
However, there is a notable paucity of detailed, open-sourced methodologies on
efficiently scaling LLMs beyond 50 billion parameters with minimum
trial-and-error cost and computational resources. In this report, we introduce
Tele-FLM (aka FLM-2), a 52B open-sourced multilingual large language model that
features a stable, efficient pre-training paradigm and enhanced factual
judgment capabilities. Tele-FLM demonstrates superior multilingual language
modeling abilities, measured by BPB on textual corpus. Besides, in both English
and Chinese foundation model evaluation, it is comparable to strong
open-sourced models that involve larger pre-training FLOPs, such as Llama2-70B
and DeepSeek-67B. In addition to the model weights, we share the core designs,
engineering practices, and training details, which we expect to benefit both
the academic and industrial communities.

摘要：大型語言模型（LLM）展現了深厚的語言能力
理解和生成，促進廣泛的應用。
然而，明顯缺乏詳細的、開源的方法論
有效地將 LLM 擴展至超過 500 億個參數，且參數最少
試錯成本和計算資源。在本報告中，我們介紹
Tele-FLM（又稱 FLM-2），一個 52B 開源多語言大語言模型，
具有穩定、高效的預訓練範式和增強的事實性
判斷能力。 Tele-FLM 展現了卓越的多語言能力
建模能力，透過 BPB 在文本語料庫上衡量。另外，無論是英文還是
和中國基礎模型評價一樣，堪比強者
涉及較大預訓練 FLOP 的開源模型，例如 Llama2-70B
和 DeepSeek-67B。除了模型權重之外，我們還分享核心設計，
工程實務和訓練細節，我們希望雙方都能受益
學術界和工業界。

##### **Legal Aspects for Software Developers Interested in Generative AI Applications**
2404.16630v1 by Steffen Herbold et.al.

Recent successes in Generative Artificial Intelligence (GenAI) have led to
new technologies capable of generating high-quality code, natural language, and
images. The next step is to integrate GenAI technology into products, a task
typically conducted by software developers. Such product development always
comes with a certain risk of liability. Within this article, we want to shed
light on the current state of two such risks: data protection and copyright.
Both aspects are crucial for GenAI. This technology deals with data for both
model training and generated output. We summarize key aspects regarding our
current knowledge that every software developer involved in product development
using GenAI should be aware of to avoid critical mistakes that may expose them
to liability claims.

摘要：生成式人工智慧（GenAI）最近的成功導致
能夠產生高品質程式碼、自然語言和
圖片。下一步是將GenAI技術整合到產品中，這是一個任務
通常由軟體開發人員進行。這樣的產品開發總是
具有一定的責任風險。在這篇文章中，我們想要擺脫
淺談兩種此類風險的現況：資料保護和版權。
這兩個方面對於 GenAI 都至關重要。這項技術處理的數據
模型訓練和產生的輸出。我們總結了有關我們的關鍵方面
每個參與產品開發的軟體開發人員的當前知識
使用 GenAI 時應注意避免可能暴露的嚴重錯誤
責任索賠。

##### **Incorporating Lexical and Syntactic Knowledge for Unsupervised Cross-Lingual Transfer**
2404.16627v1 by Jianyu Zheng et.al.

Unsupervised cross-lingual transfer involves transferring knowledge between
languages without explicit supervision. Although numerous studies have been
conducted to improve performance in such tasks by focusing on cross-lingual
knowledge, particularly lexical and syntactic knowledge, current approaches are
limited as they only incorporate syntactic or lexical information. Since each
type of information offers unique advantages and no previous attempts have
combined both, we attempt to explore the potential of this approach. In this
paper, we present a novel framework called "Lexicon-Syntax Enhanced
Multilingual BERT" that combines both lexical and syntactic knowledge.
Specifically, we use Multilingual BERT (mBERT) as the base model and employ two
techniques to enhance its learning capabilities. The code-switching technique
is used to implicitly teach the model lexical alignment information, while a
syntactic-based graph attention network is designed to help the model encode
syntactic structure. To integrate both types of knowledge, we input
code-switched sequences into both the syntactic module and the mBERT base model
simultaneously. Our extensive experimental results demonstrate this framework
can consistently outperform all baselines of zero-shot cross-lingual transfer,
with the gains of 1.0~3.7 points on text classification, named entity
recognition (ner), and semantic parsing tasks. Keywords:cross-lingual transfer,
lexicon, syntax, code-switching, graph attention network

摘要：無監督的跨語言遷移涉及知識在不同語言之間的遷移
沒有明確監督的語言。儘管已有大量研究
透過專注於跨語言來提高此類任務的績效
知識，特別是詞彙和句法知識，目前的方法是
有限，因為它們只包含句法或詞彙資訊。由於每個
資訊類型具有獨特的優勢，以前的嘗試都沒有
將兩者結合起來，我們嘗試探索這種方法的潛力。在這個
論文中，我們提出了一個名為「字典語法增強」的新穎框架
結合了詞彙和句法知識的多語言 BERT」。
具體來說，我們使用多語言 BERT (mBERT) 作為基礎模型，並採用兩個
科技來增強其學習能力。語碼轉換技術
用於隱式地教導模型詞彙對齊訊息，而
基於句法的圖注意力網路旨在幫助模型編碼
句法結構。為了整合兩種類型的知識，我們輸入
將程式碼轉換序列放入句法模組和 mBERT 基礎模型中
同時地。我們廣泛的實驗結果證明了這個框架
能夠始終優於零樣本跨語言遷移的所有基線，
在文字分類、命名實體上獲得 1.0~3.7 分的增益
辨識（ner）和語意解析任務。關鍵字：跨語言遷移，
字典、文法、語碼轉換、圖注意力網絡

##### **Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**
2404.16621v1 by Emre Can Acikgoz et.al.

The integration of Large Language Models (LLMs) into healthcare promises to
transform medical diagnostics, research, and patient care. Yet, the progression
of medical LLMs faces obstacles such as complex training requirements, rigorous
evaluation demands, and the dominance of proprietary models that restrict
academic exploration. Transparent, comprehensive access to LLM resources is
essential for advancing the field, fostering reproducibility, and encouraging
innovation in healthcare AI. We present Hippocrates, an open-source LLM
framework specifically developed for the medical domain. In stark contrast to
previous efforts, it offers unrestricted access to its training datasets,
codebase, checkpoints, and evaluation protocols. This open approach is designed
to stimulate collaborative research, allowing the community to build upon,
refine, and rigorously evaluate medical LLMs within a transparent ecosystem.
Also, we introduce Hippo, a family of 7B models tailored for the medical
domain, fine-tuned from Mistral and LLaMA2 through continual pre-training,
instruction tuning, and reinforcement learning from human and AI feedback. Our
models outperform existing open medical LLMs models by a large-margin, even
surpassing models with 70B parameters. Through Hippocrates, we aspire to unlock
the full potential of LLMs not just to advance medical knowledge and patient
care but also to democratize the benefits of AI research in healthcare, making
them available across the globe.

摘要：將大型語言模型 (LLM) 整合到醫療保健領域有望
改變醫療診斷、研究和病患照護。然而，進展
的醫學法學碩士面臨複雜的訓練要求、嚴格的訓練等障礙
評估要求以及限制專有模型的主導地位
學術探索。對 LLM 資源的透明、全面的存取是
對於推進該領域、促進可重複性和鼓勵
醫療保健人工智慧的創新。我們介紹希波克拉底，一個開源法學碩士
專門為醫療領域所開發的框架。與之形成鮮明對比的是
與先前的努力相比，它提供了對其訓練資料集的無限制訪問，
程式碼庫、檢查點和評估協議。這種開放式方法的設計
促進合作研究，讓社區在此基礎上繼續發展，
在透明的生態系統中完善和嚴格評估醫學法學碩士。
此外，我們還推出了專為醫療行業量身定制的 7B 型號 Hippo 系列。
域，透過持續的預訓練從 Mistral 和 LLaMA2 進行微調，
指令調整以及來自人類和人工智慧回饋的強化學習。我們的
模型的表現遠優於現有的開放式醫學法學碩士模型，甚至
超越70B參數的模型。透過希波克拉底，我們渴望解鎖
法學碩士的全部潛力不僅可以促進醫學知識和病人的發展
也使人工智慧研究在醫療保健領域的好處民主化，使
它們在全球範圍內可用。

##### **SFMViT: SlowFast Meet ViT in Chaotic World**
2404.16609v1 by Jiaying Lin et.al.

The task of spatiotemporal action localization in chaotic scenes is a
challenging task toward advanced video understanding. Paving the way with
high-quality video feature extraction and enhancing the precision of
detector-predicted anchors can effectively improve model performance. To this
end, we propose a high-performance dual-stream spatiotemporal feature
extraction network SFMViT with an anchor pruning strategy. The backbone of our
SFMViT is composed of ViT and SlowFast with prior knowledge of spatiotemporal
action localization, which fully utilizes ViT's excellent global feature
extraction capabilities and SlowFast's spatiotemporal sequence modeling
capabilities. Secondly, we introduce the confidence maximum heap to prune the
anchors detected in each frame of the picture to filter out the effective
anchors. These designs enable our SFMViT to achieve a mAP of 26.62% in the
Chaotic World dataset, far exceeding existing models. Code is available at
https://github.com/jfightyr/SlowFast-Meet-ViT.

摘要：混沌場景中時空動作定位的任務是
高階視訊理解的挑戰性任務。鋪路
高品質視訊特徵提取並提高精度
檢測器預測的anchor可以有效提高模型性能。對此
最後，我們提出了一種高性能的雙流時空特徵
具有錨定剪枝策略的提取網路 SFMViT。我們的脊梁
SFMViT 由 ViT 和 SlowFast 組成，具有時空先驗知識
動作本地化，充分利用ViT優秀的全域特性
提取能力和SlowFast的時空序列建模
能力。其次，我們引入置信度最大堆來修剪
在圖片的每一格中偵測到anchor，過濾掉有效的
錨點。這些設計使我們的 SFMViT 在
Chaotic World資料集，遠遠超過現有模型。代碼可在
https://github.com/jfightyr/SlowFast-Meet-ViT。

##### **Understanding Privacy Risks of Embeddings Induced by Large Language Models**
2404.16587v1 by Zhihao Zhu et.al.

Large language models (LLMs) show early signs of artificial general
intelligence but struggle with hallucinations. One promising solution to
mitigate these hallucinations is to store external knowledge as embeddings,
aiding LLMs in retrieval-augmented generation. However, such a solution risks
compromising privacy, as recent studies experimentally showed that the original
text can be partially reconstructed from text embeddings by pre-trained
language models. The significant advantage of LLMs over traditional pre-trained
models may exacerbate these concerns. To this end, we investigate the
effectiveness of reconstructing original knowledge and predicting entity
attributes from these embeddings when LLMs are employed. Empirical findings
indicate that LLMs significantly improve the accuracy of two evaluated tasks
over those from pre-trained models, regardless of whether the texts are
in-distribution or out-of-distribution. This underscores a heightened potential
for LLMs to jeopardize user privacy, highlighting the negative consequences of
their widespread use. We further discuss preliminary strategies to mitigate
this risk.

摘要：大型語言模型（LLM）顯示出人工通用的早期跡象
智力但與幻覺作鬥爭。一種有希望的解決方案
減輕這些幻覺的方法是將外部知識儲存為嵌入，
幫助法學碩士進行檢索增強生成。然而，這樣的解決方案存在風險
損害隱私，最近的研究實驗表明，原始
文字可以透過預訓練從文字嵌入中部分重建
語言模型。法學碩士相對於傳統預訓練的顯著優勢
模型可能會加劇這些擔憂。為此，我們調查了
重構原始知識和預測實體的有效性
當使用 LLM 時，這些嵌入的屬性。實證結果
顯示法學碩士顯著提高了兩項評估任務的準確性
超過來自預訓練模型的文本，無論文本是否
分佈內或分佈外。這強調了更高的潛力
法學碩士危害用戶隱私，強調了以下行為的負面後果
它們的廣泛使用。我們進一步討論緩解的初步策略
這種風險。

##### **Neural Interaction Energy for Multi-Agent Trajectory Prediction**
2404.16579v1 by Kaixin Shen et.al.

Maintaining temporal stability is crucial in multi-agent trajectory
prediction. Insufficient regularization to uphold this stability often results
in fluctuations in kinematic states, leading to inconsistent predictions and
the amplification of errors. In this study, we introduce a framework called
Multi-Agent Trajectory prediction via neural interaction Energy (MATE). This
framework assesses the interactive motion of agents by employing neural
interaction energy, which captures the dynamics of interactions and illustrates
their influence on the future trajectories of agents. To bolster temporal
stability, we introduce two constraints: inter-agent interaction constraint and
intra-agent motion constraint. These constraints work together to ensure
temporal stability at both the system and agent levels, effectively mitigating
prediction fluctuations inherent in multi-agent systems. Comparative
evaluations against previous methods on four diverse datasets highlight the
superior prediction accuracy and generalization capabilities of our model.

摘要：維持時間穩定性對於多智能體軌跡至關重要
預言。正則化不足以維持這種穩定性通常會導致
運動狀態的波動，導致預測不一致
誤差的放大。在這項研究中，我們引入了一個名為
透過神經交互作用能量（MATE）進行多智能體軌跡預測。這
框架透過採用神經網路來評估智能體的互動運動
相互作用能量，捕捉相互作用的動態並說明
他們對代理人未來軌跡的影響。為了加強時間
穩定性，我們引入兩個約束：智能體間交互約束和
代理內運動約束。這些約束共同確保
系統和代理程式層級的時間穩定性，有效緩解
多智能體系統固有的預測波動。比較
對四個不同數據集的先前方法的評估突出了
我們的模型具有卓越的預測準確性和泛化能力。

##### **Exploring Internal Numeracy in Language Models: A Case Study on ALBERT**
2404.16574v1 by Ulme Wennberg et.al.

It has been found that Transformer-based language models have the ability to
perform basic quantitative reasoning. In this paper, we propose a method for
studying how these models internally represent numerical data, and use our
proposal to analyze the ALBERT family of language models. Specifically, we
extract the learned embeddings these models use to represent tokens that
correspond to numbers and ordinals, and subject these embeddings to Principal
Component Analysis (PCA). PCA results reveal that ALBERT models of different
sizes, trained and initialized separately, consistently learn to use the axes
of greatest variation to represent the approximate ordering of various
numerical concepts. Numerals and their textual counterparts are represented in
separate clusters, but increase along the same direction in 2D space. Our
findings illustrate that language models, trained purely to model text, can
intuit basic mathematical concepts, opening avenues for NLP applications that
intersect with quantitative reasoning.

摘要：人們發現基於 Transformer 的語言模型能夠
執行基本的定量推理。在本文中，我們提出了一種方法
研究這些模型如何在內部表示數值數據，並使用我們的
分析 ALBERT 系列語言模式的提案。具體來說，我們
提取這些模型用來表示標記的學習嵌入
對應於數字和序數，並使這些嵌入服從主體
成分分析（PCA）。 PCA 結果表明，不同的 ALBERT 模型
尺寸，單獨訓練和初始化，持續學習使用軸
最大變化來表示各種的近似排序
數字概念。數字及其對應的文字表示為
分開的簇，但在 2D 空間中沿相同方向增加。我們的
研究結果表明，純粹為文字建模而訓練的語言模型可以
intuit 基本數學概念，為 NLP 應用開闢了途徑
與定量推理相交叉。

##### **Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark**
2404.16563v1 by Elizabeth Fons et.al.

Large Language Models (LLMs) offer the potential for automatic time series
analysis and reporting, which is a critical task across many domains, spanning
healthcare, finance, climate, energy, and many more. In this paper, we propose
a framework for rigorously evaluating the capabilities of LLMs on time series
understanding, encompassing both univariate and multivariate forms. We
introduce a comprehensive taxonomy of time series features, a critical
framework that delineates various characteristics inherent in time series data.
Leveraging this taxonomy, we have systematically designed and synthesized a
diverse dataset of time series, embodying the different outlined features. This
dataset acts as a solid foundation for assessing the proficiency of LLMs in
comprehending time series. Our experiments shed light on the strengths and
limitations of state-of-the-art LLMs in time series understanding, revealing
which features these models readily comprehend effectively and where they
falter. In addition, we uncover the sensitivity of LLMs to factors including
the formatting of the data, the position of points queried within a series and
the overall time series length.

摘要：大型語言模型 (LLM) 提供自動時間序列的潛力
分析和報告，這是跨許多領域的關鍵任務，涵蓋
醫療保健、金融、氣候、能源等等。在本文中，我們建議
嚴格評估法學碩士時間序列能力的框架
理解，包括單變量和多元形式。我們
引入時間序列特徵的綜合分類法，這是一個關鍵
描述時間序列資料固有的各種特徵的框架。
利用這種分類法，我們有系統地設計和綜合了
不同的時間序列資料集，體現了不同的概述特徵。這
數據集為評估法學碩士的熟練程度奠定了堅實的基礎
理解時間序列。我們的實驗揭示了優勢和
最先進的法學碩士在時間序列理解方面的局限性，揭示了
這些模型的特點是易於理解以及它們在哪裡
動搖。此外，我們也發現了法學碩士對以下因素的敏感度：
資料的格式、一系列中查詢點的位置以及
總時間序列長度。

##### **Evolve Cost-aware Acquisition Functions Using Large Language Models**
2404.16906v1 by Yiming Yao et.al.

Many real-world optimization scenarios involve expensive evaluation with
unknown and heterogeneous costs. Cost-aware Bayesian optimization stands out as
a prominent solution in addressing these challenges. To approach the global
optimum within a limited budget in a cost-efficient manner, the design of
cost-aware acquisition functions (AFs) becomes a crucial step. However,
traditional manual design paradigm typically requires extensive domain
knowledge and involves a labor-intensive trial-and-error process. This paper
introduces EvolCAF, a novel framework that integrates large language models
(LLMs) with evolutionary computation (EC) to automatically design cost-aware
AFs. Leveraging the crossover and mutation in the algorithm space, EvolCAF
offers a novel design paradigm, significantly reduces the reliance on domain
expertise and model training. The designed cost-aware AF maximizes the
utilization of available information from historical data, surrogate models and
budget details. It introduces novel ideas not previously explored in the
existing literature on acquisition function design, allowing for clear
interpretations to provide insights into its behavior and decision-making
process. In comparison to the well-known EIpu and EI-cool methods designed by
human experts, our approach showcases remarkable efficiency and generalization
across various tasks, including 12 synthetic problems and 3 real-world
hyperparameter tuning test sets.

摘要：許多現實世界的最佳化場景涉及昂貴的評估
未知且異質的成本。成本感知貝葉斯優化脫穎而出
應對這些挑戰的突出解決方案。為接近全球
在有限的預算內以具成本效益的方式實現最佳設計
成本感知的採集功能（AF）成為關鍵的一步。然而，
傳統的手動設計範式通常需要廣泛的領域
知識，並涉及勞動密集的試錯過程。這張紙
推出 EvolCAF，一種整合大型語言模型的新穎框架
（法學碩士）與演化計算（EC）自動設計成本感知
AF。利用演算法空間中的交叉與變異，EvolCAF
提供了一種新穎的設計範式，顯著減少了對領域的依賴
專業知識和模型培訓。設計的具有成本意識的 AF 最大限度地提高了
利用歷史資料、替代模型和
預算細節。它引入了以前未曾探討過的新穎想法
關於採集功能設計的現有文獻，可以明確
解釋以提供對其行為和決策的見解
過程。與著名的 EIpu 和 EI-cool 方法相比
人類專家，我們的方法展示了卓越的效率和泛化能力
跨越各種任務，包括 12 個綜合問題和 3 個現實世界問題
超參數調整測試集。

##### **DeepKalPose: An Enhanced Deep-Learning Kalman Filter for Temporally Consistent Monocular Vehicle Pose Estimation**
2404.16558v1 by Leandro Di Bella et.al.

This paper presents DeepKalPose, a novel approach for enhancing temporal
consistency in monocular vehicle pose estimation applied on video through a
deep-learning-based Kalman Filter. By integrating a Bi-directional Kalman
filter strategy utilizing forward and backward time-series processing, combined
with a learnable motion model to represent complex motion patterns, our method
significantly improves pose accuracy and robustness across various conditions,
particularly for occluded or distant vehicles. Experimental validation on the
KITTI dataset confirms that DeepKalPose outperforms existing methods in both
pose accuracy and temporal consistency.

摘要：本文提出了 DeepKalPose，一種增強時間的新方法
透過應用在影片上的單目車輛姿態估計的一致性
基於深度學習的卡爾曼濾波器。透過整合雙向卡爾曼
利用前向和後向時間序列處理結合的濾波策略
使用可學習的運動模型來表示複雜的運動模式，我們的方法
顯著提高各種條件下的姿勢準確性和穩健性，
特別是對於被遮蔽或距離較遠的車輛。實驗驗證
KITTI 資料集證實 DeepKalPose 在這兩方面均優於現有方法
姿勢準確性和時間一致性。

##### **Energy-Latency Manipulation of Multi-modal Large Language Models via Verbose Samples**
2404.16557v1 by Kuofeng Gao et.al.

Despite the exceptional performance of multi-modal large language models
(MLLMs), their deployment requires substantial computational resources. Once
malicious users induce high energy consumption and latency time (energy-latency
cost), it will exhaust computational resources and harm availability of
service. In this paper, we investigate this vulnerability for MLLMs,
particularly image-based and video-based ones, and aim to induce high
energy-latency cost during inference by crafting an imperceptible perturbation.
We find that high energy-latency cost can be manipulated by maximizing the
length of generated sequences, which motivates us to propose verbose samples,
including verbose images and videos. Concretely, two modality non-specific
losses are proposed, including a loss to delay end-of-sequence (EOS) token and
an uncertainty loss to increase the uncertainty over each generated token. In
addition, improving diversity is important to encourage longer responses by
increasing the complexity, which inspires the following modality specific loss.
For verbose images, a token diversity loss is proposed to promote diverse
hidden states. For verbose videos, a frame feature diversity loss is proposed
to increase the feature diversity among frames. To balance these losses, we
propose a temporal weight adjustment algorithm. Experiments demonstrate that
our verbose samples can largely extend the length of generated sequences.

摘要：儘管多模態大語言模型具有出色的性能
（MLLM），它們的部署需要大量的運算資源。一次
惡意用戶導致高能耗和延遲時間（energy-latency
成本），它將耗盡計算資源並損害可用性
服務。在本文中，我們研究了 MLLM 的這個漏洞，
特別是基於圖像和視頻的，旨在誘導高
透過製造難以察覺的擾動來降低推理過程中的能量延遲成本。
我們發現，高能量延遲成本可以透過最大化
產生序列的長度，這促使我們提出詳細的樣​​本，
包括詳細的圖像和影片。具體來說，有兩種非特定形式
建議損失，包括延遲序列結束（EOS）代幣的損失和
不確定性損失，以增加每個產生的代幣的不確定性。在
此外，提高多樣性對於鼓勵更長的反應非常重要
增加複雜性，從而引發以下模態特定損失。
對於詳細圖像，提出了令牌多樣性損失以促進多樣性
隱藏狀態。對於冗長的視頻，提出了幀特徵多樣性損失
增加幀之間的特徵多樣性。為了平衡這些損失，我們
提出一種時間權重調整演算法。實驗證明
我們的詳細樣本可以很大程度上延長生成序列的長度。

##### **Developing Acoustic Models for Automatic Speech Recognition in Swedish**
2404.16547v1 by Giampiero Salvi et.al.

This paper is concerned with automatic continuous speech recognition using
trainable systems. The aim of this work is to build acoustic models for spoken
Swedish. This is done employing hidden Markov models and using the SpeechDat
database to train their parameters. Acoustic modeling has been worked out at a
phonetic level, allowing general speech recognition applications, even though a
simplified task (digits and natural number recognition) has been considered for
model evaluation. Different kinds of phone models have been tested, including
context independent models and two variations of context dependent models.
Furthermore many experiments have been done with bigram language models to tune
some of the system parameters. System performance over various speaker subsets
with different sex, age and dialect has also been examined. Results are
compared to previous similar studies showing a remarkable improvement.

摘要：本文關注的是使用自動連續語音識別
可訓練的系統。這項工作的目的是建立口語聲學模型
瑞典。這是透過使用隱馬可夫模型並使用 SpeechDat 來完成的
資料庫來訓練他們的參數。聲學建模已在
語音級別，允許一般語音識別應用，即使
已考慮簡化任務（數字和自然數辨識）
模型評估。已經測試了不同類型的手機型號，包括
上下文無關模型和上下文相關模型的兩種變體。
此外，已經用二元語言模型進行了許多實驗來調整
一些系統參數。各種揚聲器子集的系統性能
也對不同性別、年齡和方言進行了檢查。結果是
與先前類似的研究相比，顯示出顯著的進步。

##### **Samsung Research China-Beijing at SemEval-2024 Task 3: A multi-stage framework for Emotion-Cause Pair Extraction in Conversations**
2404.16905v1 by Shen Zhang et.al.

In human-computer interaction, it is crucial for agents to respond to human
by understanding their emotions. Unraveling the causes of emotions is more
challenging. A new task named Multimodal Emotion-Cause Pair Extraction in
Conversations is responsible for recognizing emotion and identifying causal
expressions. In this study, we propose a multi-stage framework to generate
emotion and extract the emotion causal pairs given the target emotion. In the
first stage, Llama-2-based InstructERC is utilized to extract the emotion
category of each utterance in a conversation. After emotion recognition, a
two-stream attention model is employed to extract the emotion causal pairs
given the target emotion for subtask 2 while MuTEC is employed to extract
causal span for subtask 1. Our approach achieved first place for both of the
two subtasks in the competition.

摘要：在人機互動中，智能體對人類的反應至關重要
透過了解他們的情緒。揭開情緒產生的原因更重要
具有挑戰性的。名為多模態情感-原因對提取的新任務
對話負責識別情緒並確定因果關係
表達式。在本研究中，我們提出了一個多階段框架來生成
情感並提取給定目標情感的情緒因果對。在裡面
第一階段，利用基於Llama-2的InstructERC來提取情感
對話中每個話語的類別。情緒辨識後，
採用雙流注意力模型提取情緒因果對
給定子任務 2 的目標情緒，同時使用 MuTEC 來提取
子任務 1 的因果跨度。
比賽的兩個子任務。

##### **SIDEs: Separating Idealization from Deceptive Explanations in xAI**
2404.16534v1 by Emily Sullivan et.al.

Explainable AI (xAI) methods are important for establishing trust in using
black-box models. However, recent criticism has mounted against current xAI
methods that they disagree, are necessarily false, and can be manipulated,
which has started to undermine the deployment of black-box models. Rudin (2019)
goes so far as to say that we should stop using black-box models altogether in
high-stakes cases because xAI explanations "must be wrong". However, strict
fidelity to the truth is historically not a desideratum in science.
Idealizations -- the intentional distortions introduced to scientific theories
and models -- are commonplace in the natural sciences and are seen as a
successful scientific tool. Thus, it is not falsehood qua falsehood that is the
issue. In this paper, I outline the need for xAI research to engage in
idealization evaluation. Drawing on the use of idealizations in the natural
sciences and philosophy of science, I introduce a novel framework for
evaluating whether xAI methods engage in successful idealizations or deceptive
explanations (SIDEs). SIDEs evaluates whether the limitations of xAI methods,
and the distortions that they introduce, can be part of a successful
idealization or are indeed deceptive distortions as critics suggest. I discuss
the role that existing research can play in idealization evaluation and where
innovation is necessary. Through a qualitative analysis we find that leading
feature importance methods and counterfactual explanations are subject to
idealization failure and suggest remedies for ameliorating idealization
failure.

摘要：可解釋的人工智慧 (xAI) 方法對於建立使用信任非常重要
黑盒模型。然而，最近對目前 xAI 的批評越來越多
他們不同意的方法必然是錯誤的，並且可以被操縱，
這已經開始破壞黑盒模型的部署。魯丁 (2019)
甚至說我們應該完全停止使用黑盒子模型
高風險案例，因為 xAI 的解釋「一定是錯誤的」。然而，嚴格
歷史上，忠於真理並不是科學的迫切需求。
理想化－科學理論的故意扭曲
和模型－在自然科學中很常見，被視為
成功的科學工具。因此，這並不是謊言之於謊言
問題。在本文中，我概述了 xAI 研究參與的必要性
理想化評價。借鏡自然中理想化的運用
科學和科學哲學，我介紹了一個新穎的框架
評估 xAI 方法是否成功理想化或具有欺騙性
解釋（側面）。 SIDE 評估 xAI 方法是否有局限性，
以及它們所帶來的扭曲，可以成為成功的一部分
正如批評者所說，理想化或確實是欺騙性的扭曲。我討論
現有研究在理想化評估中可以發揮的作用以及在哪裡
創新是必要的。透過定性分析，我們發現領先
特徵重要性方法和反事實解釋受制於
理想化失敗並提出改善理想化的補救措施
失敗。

##### **Global Concept Explanations for Graphs by Contrastive Learning**
2404.16532v1 by Jonas Teufel et.al.

Beyond improving trust and validating model fairness, xAI practices also have
the potential to recover valuable scientific insights in application domains
where little to no prior human intuition exists. To that end, we propose a
method to extract global concept explanations from the predictions of graph
neural networks to develop a deeper understanding of the tasks underlying
structure-property relationships. We identify concept explanations as dense
clusters in the self-explaining Megan models subgraph latent space. For each
concept, we optimize a representative prototype graph and optionally use GPT-4
to provide hypotheses about why each structure has a certain effect on the
prediction. We conduct computational experiments on synthetic and real-world
graph property prediction tasks. For the synthetic tasks we find that our
method correctly reproduces the structural rules by which they were created.
For real-world molecular property regression and classification tasks, we find
that our method rediscovers established rules of thumb. More specifically, our
results for molecular mutagenicity prediction indicate more fine-grained
resolution of structural details than existing explainability methods,
consistent with previous results from chemistry literature. Overall, our
results show promising capability to extract the underlying structure-property
relationships for complex graph property prediction tasks.

摘要：除了提高信任和驗證模型公平性之外，xAI 實踐還具有
在應用領域恢復有價值的科學見解的潛力
人類事先的直覺幾乎不存在。為此，我們建議
從圖的預測中提取全局概念解釋的方法
神經網路來加深對底層任務的理解
結構-性能關係。我們認為概念解釋是密集的
不言自明的梅根模型子圖潛在空間中的簇。對於每個
概念，我們優化代表性原型圖並可選擇使用 GPT-4
提供關於為什麼每個結構對
預言。我們對合成和現實世界進行計算實驗
圖屬性預測任務。對於綜合任務，我們發現我們的
方法正確地再現了創建它們的結構規則。
對於現實世界的分子屬性迴歸和分類任務，我們發現
我們的方法重新發現了既定的經驗法則。更具體地說，我們的
分子致突變性預測結果顯示更細粒度
結構細節的分辨率高於現有的可解釋性方法，
與之前化學文獻的結果一致。總體而言，我們的
結果顯示了提取底層結構特性的有前景的能力
複雜圖屬性預測任務的關係。

##### **Building a Japanese Document-Level Relation Extraction Dataset Assisted by Cross-Lingual Transfer**
2404.16506v1 by Youmi Ma et.al.

Document-level Relation Extraction (DocRE) is the task of extracting all
semantic relationships from a document. While studies have been conducted on
English DocRE, limited attention has been given to DocRE in non-English
languages. This work delves into effectively utilizing existing English
resources to promote DocRE studies in non-English languages, with Japanese as
the representative case. As an initial attempt, we construct a dataset by
transferring an English dataset to Japanese. However, models trained on such a
dataset suffer from low recalls. We investigate the error cases and attribute
the failure to different surface structures and semantics of documents
translated from English and those written by native speakers. We thus switch to
explore if the transferred dataset can assist human annotation on Japanese
documents. In our proposal, annotators edit relation predictions from a model
trained on the transferred dataset. Quantitative analysis shows that relation
recommendations suggested by the model help reduce approximately 50% of the
human edit steps compared with the previous approach. Experiments quantify the
performance of existing DocRE models on our collected dataset, portraying the
challenges of Japanese and cross-lingual DocRE.

摘要：文件級關係抽取（DocRE）是抽取所有內容的任務
文檔中的語義關係。雖然已經進行了研究
英語 DocRE，對非英語 DocRE 的關注有限
語言。這項工作深入研究有效利用現有的英語
促進非英語語言 DocRE 研究的資源，其中日文為
代表案例。作為初步嘗試，我們透過以下方式建立資料集
將英文資料集轉換為日文。然而，在這種情況下訓練的模型
資料集的召回率較低。我們調查錯誤案例和屬性
文件的不同表面結構和語義的失敗
翻譯自英語和由母語人士撰寫的內容。因此我們切換到
探索傳輸的資料集是否可以輔助日語的人工註釋
文件。在我們的提案中，註釋者編輯模型中的關係預測
在傳輸的資料集上進行訓練。定量分析表明，關係
模型提出的建議有助於減少約 50%
與先前的方法相比，人工編輯步驟。實驗量化了
現有 DocRE 模型在我們收集的資料集上的表現，描繪了
日語和跨語言 DocRE 的挑戰。


### Medical
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-04-26**|**Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond**|Kaichen Xu et.al.|[2404.17454v1](http://arxiv.org/abs/2404.17454v1)|[link](https://github.com/catchxu/acsleuth)|
|**2024-04-26**|**M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training**|Lakmal Meegahapola et.al.|[2404.17391v1](http://arxiv.org/abs/2404.17391v1)|null|
|**2024-04-26**|**Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety using Zero Shot Classification: An Observational Study**|Muhammad Rizwan et.al.|[2404.17183v1](http://arxiv.org/abs/2404.17183v1)|null|
|**2024-04-26**|**Deep Evidential Learning for Dose Prediction**|Hai Siong Tan et.al.|[2404.17126v1](http://arxiv.org/abs/2404.17126v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-25**|**Taming False Positives in Out-of-Distribution Detection with Human Feedback**|Harit Vishwakarma et.al.|[2404.16954v1](http://arxiv.org/abs/2404.16954v1)|[link](https://github.com/2454511550lin/tamefalsepositives-ood)|
|**2024-04-25**|**Features Fusion for Dual-View Mammography Mass Detection**|Arina Varlamova et.al.|[2404.16718v1](http://arxiv.org/abs/2404.16718v1)|null|
|**2024-04-25**|**Report on Candidate Computational Indicators for Conscious Valenced Experience**|Andres Campero et.al.|[2404.16696v1](http://arxiv.org/abs/2404.16696v1)|null|
|**2024-04-25**|**ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling**|Sangryul Kim et.al.|[2404.16659v1](http://arxiv.org/abs/2404.16659v1)|[link](https://github.com/venzino-han/probgate_ehrsql)|
|**2024-04-25**|**Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**|Emre Can Acikgoz et.al.|[2404.16621v1](http://arxiv.org/abs/2404.16621v1)|null|
|**2024-04-25**|**DiffSeg: A Segmentation Model for Skin Lesions Based on Diffusion Difference**|Zhihao Shuai et.al.|[2404.16474v1](http://arxiv.org/abs/2404.16474v1)|null|
|**2024-04-25**|**Light-weight Retinal Layer Segmentation with Global Reasoning**|Xiang He et.al.|[2404.16346v1](http://arxiv.org/abs/2404.16346v1)|null|
|**2024-04-25**|**Semantic Segmentation Refiner for Ultrasound Applications with Zero-Shot Foundation Models**|Hedda Cohen Indelman et.al.|[2404.16325v1](http://arxiv.org/abs/2404.16325v1)|null|
|**2024-04-25**|**LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications**|Saranya Krishnamoorthy et.al.|[2404.16294v1](http://arxiv.org/abs/2404.16294v1)|[link](https://github.com/inqbator-evicore/llm_section_identifiers)|
|**2024-04-24**|**Investigating the prompt leakage effect and black-box defenses for multi-turn LLM interactions**|Divyansh Agarwal et.al.|[2404.16251v2](http://arxiv.org/abs/2404.16251v2)|null|
|**2024-04-24**|**ABCD: Trust enhanced Attention based Convolutional Autoencoder for Risk Assessment**|Sarala Naidu et.al.|[2404.16183v1](http://arxiv.org/abs/2404.16183v1)|null|
|**2024-04-24**|**Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges**|Badri Narayana Patro et.al.|[2404.16112v1](http://arxiv.org/abs/2404.16112v1)|[link](https://github.com/badripatro/mamba360)|
|**2024-04-24**|**Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography**|Xuxin Chen et.al.|[2404.15946v1](http://arxiv.org/abs/2404.15946v1)|null|
|**2024-04-24**|**Assessing The Potential Of Mid-Sized Language Models For Clinical QA**|Elliot Bolton et.al.|[2404.15894v1](http://arxiv.org/abs/2404.15894v1)|null|
|**2024-04-24**|**Enhancing Diagnosis through AI-driven Analysis of Reflectance Confocal Microscopy**|Hong-Jun Yoon et.al.|[2404.16080v1](http://arxiv.org/abs/2404.16080v1)|null|
|**2024-04-24**|**Anomaly Detection for Incident Response at Scale**|Hanzhang Wang et.al.|[2404.16887v1](http://arxiv.org/abs/2404.16887v1)|null|
|**2024-04-23**|**Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Detection: The HeHealth Experience**|Rayner Kay Jin Tan et.al.|[2404.16885v1](http://arxiv.org/abs/2404.16885v1)|null|
|**2024-04-23**|**PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models**|Shashi Kant Gupta et.al.|[2404.15549v1](http://arxiv.org/abs/2404.15549v1)|null|
|**2024-04-23**|**Multi-scale Intervention Planning based on Generative Design**|Ioannis Kavouras et.al.|[2404.15492v1](http://arxiv.org/abs/2404.15492v1)|null|
|**2024-04-23**|**IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents**|Jean-Philippe Corbeil et.al.|[2404.15488v1](http://arxiv.org/abs/2404.15488v1)|[link](https://github.com/microsoft/iryonlp-mediqa-corr-2024)|
|**2024-04-23**|**Machine Learning Techniques with Fairness for Prediction of Completion of Drug and Alcohol Rehabilitation**|Karen Roberts-Licklider et.al.|[2404.15418v1](http://arxiv.org/abs/2404.15418v1)|null|
|**2024-04-23**|**CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios**|Jingyang Lin et.al.|[2404.15272v2](http://arxiv.org/abs/2404.15272v2)|null|
|**2024-04-23**|**A review of deep learning-based information fusion techniques for multimodal medical image classification**|Yihao Li et.al.|[2404.15022v1](http://arxiv.org/abs/2404.15022v1)|null|
|**2024-04-23**|**Clustering of timed sequences -- Application to the analysis of care pathways**|Thomas Guyet et.al.|[2404.15379v1](http://arxiv.org/abs/2404.15379v1)|null|
|**2024-04-23**|**Grounded Knowledge-Enhanced Medical VLP for Chest X-Ray**|Qiao Deng et.al.|[2404.14750v1](http://arxiv.org/abs/2404.14750v1)|null|
|**2024-04-22**|**DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic Depression Detection from Clinical Interviews**|Sergio Burdisso et.al.|[2404.14463v1](http://arxiv.org/abs/2404.14463v1)|null|
|**2024-04-22**|**Adaptive Collaboration Strategy for LLMs in Medical Decision Making**|Yubin Kim et.al.|[2404.15155v1](http://arxiv.org/abs/2404.15155v1)|[link](https://github.com/mitmedialab/mdagents)|
|**2024-04-21**|**A Nasal Cytology Dataset for Object Detection and Deep Learning**|Mauro Camporeale et.al.|[2404.13745v1](http://arxiv.org/abs/2404.13745v1)|null|
|**2024-04-21**|**Bt-GAN: Generating Fair Synthetic Healthdata via Bias-transforming Generative Adversarial Networks**|Resmi Ramachandranpillai et.al.|[2404.13634v3](http://arxiv.org/abs/2404.13634v3)|null|
|**2024-04-21**|**SmartMem: Layout Transformation Elimination and Adaptation for Efficient DNN Execution on Mobile**|Wei Niu et.al.|[2404.13528v1](http://arxiv.org/abs/2404.13528v1)|null|
|**2024-04-21**|**Parameter Efficient Fine Tuning: A Comprehensive Analysis Across Applications**|Charith Chandra Sai Balne et.al.|[2404.13506v2](http://arxiv.org/abs/2404.13506v2)|null|
|**2024-04-20**|**SiNC+: Adaptive Camera-Based Vitals with Unsupervised Learning of Periodic Signals**|Jeremy Speth et.al.|[2404.13449v1](http://arxiv.org/abs/2404.13449v1)|null|
|**2024-04-20**|**MultiConfederated Learning: Inclusive Non-IID Data handling with Decentralized Federated Learning**|Michael Duchesne et.al.|[2404.13421v1](http://arxiv.org/abs/2404.13421v1)|null|
|**2024-04-20**|**UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty and Response Time for Multiple-Choice Questions**|Ana-Cristina Rogoz et.al.|[2404.13343v1](http://arxiv.org/abs/2404.13343v1)|[link](https://github.com/ana-rogoz/bea-2024)|
|**2024-04-20**|**Practical Battery Health Monitoring using Uncertainty-Aware Bayesian Neural Network**|Yunyi Zhao et.al.|[2404.14444v1](http://arxiv.org/abs/2404.14444v1)|null|
|**2024-04-19**|**Beyond Self-Consistency: Ensemble Reasoning Boosts Consistency and Accuracy of LLMs in Cancer Staging**|Chia-Hsuan Chang et.al.|[2404.13149v1](http://arxiv.org/abs/2404.13149v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Eye-tracking in Mixed Reality for Diagnosis of Neurodegenerative Diseases**|Mateusz Daniol et.al.|[2404.12984v1](http://arxiv.org/abs/2404.12984v1)|null|
|**2024-04-19**|**A Large-scale Medical Visual Task Adaptation Benchmark**|Shentong Mo et.al.|[2404.12876v1](http://arxiv.org/abs/2404.12876v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v1](http://arxiv.org/abs/2404.12832v1)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-19**|**DensePANet: An improved generative adversarial network for photoacoustic tomography image reconstruction from sparse data**|Hesam Hakimnejad et.al.|[2404.13101v1](http://arxiv.org/abs/2404.13101v1)|null|
|**2024-04-19**|**Transformer-Based Classification Outcome Prediction for Multimodal Stroke Treatment**|Danqing Ma et.al.|[2404.12634v1](http://arxiv.org/abs/2404.12634v1)|null|
|**2024-04-19**|**GluMarker: A Novel Predictive Modeling of Glycemic Control Through Digital Biomarkers**|Ziyi Zhou et.al.|[2404.12605v1](http://arxiv.org/abs/2404.12605v1)|null|
|**2024-04-18**|**DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era**|David Restrepo et.al.|[2404.12278v1](http://arxiv.org/abs/2404.12278v1)|null|
|**2024-04-18**|**Relationship Discovery for Drug Recommendation**|Xiang Li et.al.|[2404.12228v1](http://arxiv.org/abs/2404.12228v1)|null|
|**2024-04-18**|**A Symmetric Regressor for MRI-Based Assessment of Striatal Dopamine Transporter Uptake in Parkinson's Disease**|Walid Abdullah Al et.al.|[2404.11929v1](http://arxiv.org/abs/2404.11929v1)|[link](https://github.com/awjibon/mri_dat)|
|**2024-04-18**|**Cross-model Mutual Learning for Exemplar-based Medical Image Segmentation**|Qing En et.al.|[2404.11812v1](http://arxiv.org/abs/2404.11812v1)|null|
|**2024-04-17**|**A Secure and Trustworthy Network Architecture for Federated Learning Healthcare Applications**|Antonio Boiano et.al.|[2404.11698v1](http://arxiv.org/abs/2404.11698v1)|null|
|**2024-04-17**|**Towards Reliable Empirical Machine Unlearning Evaluation: A Game-Theoretic View**|Yiwen Tu et.al.|[2404.11577v1](http://arxiv.org/abs/2404.11577v1)|null|
|**2024-04-17**|**Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM**|Hongzhao Li et.al.|[2404.11209v1](http://arxiv.org/abs/2404.11209v1)|null|
|**2024-04-17**|**Explainable Machine Learning System for Predicting Chronic Kidney Disease in High-Risk Cardiovascular Patients**|Nantika Nguycharoen et.al.|[2404.11148v1](http://arxiv.org/abs/2404.11148v1)|null|
|**2024-04-17**|**AKGNet: Attribute Knowledge-Guided Unsupervised Lung-Infected Area Segmentation**|Qing En et.al.|[2404.11008v1](http://arxiv.org/abs/2404.11008v1)|null|
|**2024-04-17**|**Leveraging 3D LiDAR Sensors to Enable Enhanced Urban Safety and Public Health: Pedestrian Monitoring and Abnormal Activity Detection**|Nawfal Guefrachi et.al.|[2404.10978v1](http://arxiv.org/abs/2404.10978v1)|null|
|**2024-04-16**|**CrossGP: Cross-Day Glucose Prediction Excluding Physiological Information**|Ziyi Zhou et.al.|[2404.10901v1](http://arxiv.org/abs/2404.10901v1)|null|
|**2024-04-16**|**Mixed Prototype Consistency Learning for Semi-supervised Medical Image Segmentation**|Lijian Li et.al.|[2404.10717v1](http://arxiv.org/abs/2404.10717v1)|null|
|**2024-04-16**|**AAVDiff: Experimental Validation of Enhanced Viability and Diversity in Recombinant Adeno-Associated Virus (AAV) Capsids through Diffusion Generation**|Lijun Liu et.al.|[2404.10573v2](http://arxiv.org/abs/2404.10573v2)|null|
|**2024-04-16**|**A Sentiment Analysis of Medical Text Based on Deep Learning**|Yinan Chen et.al.|[2404.10503v1](http://arxiv.org/abs/2404.10503v1)|null|
|**2024-04-16**|**Integration of Self-Supervised BYOL in Semi-Supervised Medical Image Recognition**|Hao Feng et.al.|[2404.10405v1](http://arxiv.org/abs/2404.10405v1)|null|
|**2024-04-16**|**Generating Counterfactual Trajectories with Latent Diffusion Models for Concept Discovery**|Payal Varshney et.al.|[2404.10356v1](http://arxiv.org/abs/2404.10356v1)|null|
|**2024-04-16**|**CARE to Compare: A real-world dataset for anomaly detection in wind turbine data**|Christian Gück et.al.|[2404.10320v2](http://arxiv.org/abs/2404.10320v2)|null|
|**2024-04-16**|**Clustering and Data Augmentation to Improve Accuracy of Sleep Assessment and Sleep Individuality Analysis**|Shintaro Tamai et.al.|[2404.10299v1](http://arxiv.org/abs/2404.10299v1)|null|
|**2024-04-15**|**Emergent Language Symbolic Autoencoder (ELSA) with Weak Supervision to Model Hierarchical Brain Networks**|Ammar Ahmed Pallikonda Latheef et.al.|[2404.10031v1](http://arxiv.org/abs/2404.10031v1)|null|
|**2024-04-15**|**Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration**|Chenwei Lin et.al.|[2404.09690v1](http://arxiv.org/abs/2404.09690v1)|null|
|**2024-04-15**|**Privacy-Preserving Intrusion Detection using Convolutional Neural Networks**|Martin Kodys et.al.|[2404.09625v1](http://arxiv.org/abs/2404.09625v1)|null|
|**2024-04-15**|**Efficient and accurate neural field reconstruction using resistive memory**|Yifei Yu et.al.|[2404.09613v1](http://arxiv.org/abs/2404.09613v1)|null|
|**2024-04-15**|**WiTUnet: A U-Shaped Architecture Integrating CNN and Transformer for Improved Feature Alignment and Local Information Fusion**|Bin Wang et.al.|[2404.09533v1](http://arxiv.org/abs/2404.09533v1)|[link](https://github.com/woldier/witunet)|
|**2024-04-14**|**Weight Copy and Low-Rank Adaptation for Few-Shot Distillation of Vision Transformers**|Diana-Nicoleta Grigore et.al.|[2404.09326v2](http://arxiv.org/abs/2404.09326v2)|null|
|**2024-04-14**|**Characterizing Soft-Error Resiliency in Arm's Ethos-U55 Embedded Machine Learning Accelerator**|Abhishek Tyagi et.al.|[2404.09317v1](http://arxiv.org/abs/2404.09317v1)|null|
|**2024-04-14**|**TLDR at SemEval-2024 Task 2: T5-generated clinical-Language summaries for DeBERTa Report Analysis**|Spandan Das et.al.|[2404.09136v1](http://arxiv.org/abs/2404.09136v1)|[link](https://github.com/shahriarnz14/tldr-t5-generated-clinical-language-for-deberta-report-analysis)|
|**2024-04-13**|**Advanced Neural Network Architecture for Enhanced Multi-Lead ECG Arrhythmia Detection through Optimized Feature Extraction**|Bhavith Chandra Challagundla et.al.|[2404.15347v1](http://arxiv.org/abs/2404.15347v1)|null|
|**2024-04-13**|**Adapting Mental Health Prediction Tasks for Cross-lingual Learning via Meta-Training and In-context Learning with Large Language Model**|Zita Lifelo et.al.|[2404.09045v1](http://arxiv.org/abs/2404.09045v1)|null|
|**2024-04-13**|**A Fourier-enhanced multi-modal 3D small object optical mark recognition and positioning method for percutaneous abdominal puncture surgical navigation**|Zezhao Guo et.al.|[2404.08990v1](http://arxiv.org/abs/2404.08990v1)|null|
|**2024-04-13**|**Leveraging Large Language Model as Simulated Patients for Clinical Education**|Yanzeng Li et.al.|[2404.13066v2](http://arxiv.org/abs/2404.13066v2)|null|
|**2024-04-12**|**Is ChatGPT Transforming Academics' Writing Style?**|Mingmeng Geng et.al.|[2404.08627v1](http://arxiv.org/abs/2404.08627v1)|null|
|**2024-04-12**|**Automatic Quantification of Serial PET/CT Images for Pediatric Hodgkin Lymphoma Patients Using a Longitudinally-Aware Segmentation Network**|Xin Tie et.al.|[2404.08611v1](http://arxiv.org/abs/2404.08611v1)|[link](https://github.com/xtie97/las-net)|
|**2024-04-12**|**RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs**|Shreyas Chaudhari et.al.|[2404.08555v2](http://arxiv.org/abs/2404.08555v2)|null|
|**2024-04-12**|**An improved tabular data generator with VAE-GMM integration**|Patricia A. Apellániz et.al.|[2404.08434v1](http://arxiv.org/abs/2404.08434v1)|null|
|**2024-04-12**|**Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval**|Juraj Vladika et.al.|[2404.08359v1](http://arxiv.org/abs/2404.08359v1)|[link](https://github.com/jvladika/improving-health-qa)|
|**2024-04-11**|**Generating Synthetic Satellite Imagery With Deep-Learning Text-to-Image Models -- Technical Challenges and Implications for Monitoring and Verification**|Tuong Vy Nguyen et.al.|[2404.07754v1](http://arxiv.org/abs/2404.07754v1)|null|
|**2024-04-11**|**Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain**|Iker García-Ferrero et.al.|[2404.07613v1](http://arxiv.org/abs/2404.07613v1)|null|
|**2024-04-11**|**Contrastive-Based Deep Embeddings for Label Noise-Resilient Histopathology Image Classification**|Lucas Dedieu et.al.|[2404.07605v1](http://arxiv.org/abs/2404.07605v1)|[link](https://github.com/lucasdedieu/noiseresilienthistopathology)|
|**2024-04-11**|**Socially Pertinent Robots in Gerontological Healthcare**|Xavier Alameda-Pineda et.al.|[2404.07560v1](http://arxiv.org/abs/2404.07560v1)|null|
|**2024-04-11**|**Introducing L2M3, A Multilingual Medical Large Language Model to Advance Health Equity in Low-Resource Regions**|Agasthya Gangavarapu et.al.|[2404.08705v1](http://arxiv.org/abs/2404.08705v1)|null|
|**2024-04-10**|**Measuring proximity to standard planes during fetal brain ultrasound scanning**|Chiara Di Vece et.al.|[2404.07124v1](http://arxiv.org/abs/2404.07124v1)|null|
|**2024-04-10**|**Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19 Case Study**|Hongru Du et.al.|[2404.06962v1](http://arxiv.org/abs/2404.06962v1)|[link](https://github.com/miemieyanga/pandemicllm)|
|**2024-04-10**|**SleepPPG-Net2: Deep learning generalization for sleep staging from photoplethysmography**|Shirel Attia et.al.|[2404.06869v1](http://arxiv.org/abs/2404.06869v1)|null|
|**2024-04-10**|**Multi-Label Continual Learning for the Medical Domain: A Novel Benchmark**|Marina Ceccon et.al.|[2404.06859v2](http://arxiv.org/abs/2404.06859v2)|null|
|**2024-04-10**|**Accuracy of a Large Language Model in Distinguishing Anti- And Pro-vaccination Messages on Social Media: The Case of Human Papillomavirus Vaccination**|Soojong Kim et.al.|[2404.06731v1](http://arxiv.org/abs/2404.06731v1)|null|
|**2024-04-09**|**Federated learning model for predicting major postoperative complications**|Yonggi Park et.al.|[2404.06641v1](http://arxiv.org/abs/2404.06641v1)|null|
|**2024-04-09**|**Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero shot Medical Image Segmentation**|Sidra Aleem et.al.|[2404.06362v1](http://arxiv.org/abs/2404.06362v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-09**|**EPL: Evidential Prototype Learning for Semi-supervised Medical Image Segmentation**|Yuanpeng He et.al.|[2404.06181v1](http://arxiv.org/abs/2404.06181v1)|null|
|**2024-04-09**|**Uncertainty-aware Evidential Fusion-based Learning for Semi-supervised Medical Image Segmentation**|Yuanpeng He et.al.|[2404.06177v2](http://arxiv.org/abs/2404.06177v2)|null|
|**2024-04-09**|**Tackling Structural Hallucination in Image Translation with Local Diffusion**|Seunghoi Kim et.al.|[2404.05980v3](http://arxiv.org/abs/2404.05980v3)|null|

#### Abstracts
##### **Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond**
2404.17454v1 by Kaichen Xu et.al.

Fined-grained anomalous cell detection from affected tissues is critical for
clinical diagnosis and pathological research. Single-cell sequencing data
provide unprecedented opportunities for this task. However, current anomaly
detection methods struggle to handle domain shifts prevalent in multi-sample
and multi-domain single-cell sequencing data, leading to suboptimal
performance. Moreover, these methods fall short of distinguishing anomalous
cells into pathologically distinct subtypes. In response, we propose ACSleuth,
a novel, reconstruction deviation-guided generative framework that integrates
the detection, domain adaptation, and fine-grained annotating of anomalous
cells into a methodologically cohesive workflow. Notably, we present the first
theoretical analysis of using reconstruction deviations output by generative
models for anomaly detection in lieu of domain shifts. This analysis informs us
to develop a novel and superior maximum mean discrepancy-based anomaly scorer
in ACSleuth. Extensive benchmarks over various single-cell data and other types
of tabular data demonstrate ACSleuth's superiority over the state-of-the-art
methods in identifying and subtyping anomalies in multi-sample and multi-domain
contexts. Our code is available at https://github.com/Catchxu/ACsleuth.

摘要：從受影響的組織中進行細粒度異常細胞檢測對於
臨床診斷和病理研究。單細胞定序數據
為這項任務提供了前所未有的機會。然而，目前的異常情況
檢測方法難以處理多樣本中普遍存在的域轉移
和多域單細胞定序數據，導致次優
表現。此外，這些方法無法區分異常
細胞分為病理上不同的亞型。作為回應，我們建議 ACSleuth，
一種新穎的、重建偏差引導的生成框架，整合了
異常的檢測、領域適應和細粒度註釋
細胞進入一個方法上有凝聚力的工作流程。值得注意的是，我們提出了第一個
利用生成式輸出重構偏差的理論分析
用於代替域轉移的異常檢測模型。這項分析告訴我們
開發一種新穎且卓越的基於最大平均差異的異常評分器
在 ACSleuth 中。針對各種單細胞數據和其他類型的廣泛基準
表格數據證明 ACSleuth 優於最先進的技術
多樣本和多域中的異常識別和分型方法
上下文。我們的程式碼可在 https://github.com/Catchxu/ACsleuth 取得。

##### **M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training**
2404.17391v1 by Lakmal Meegahapola et.al.

Over the years, multimodal mobile sensing has been used extensively for
inferences regarding health and well being, behavior, and context. However, a
significant challenge hindering the widespread deployment of such models in
real world scenarios is the issue of distribution shift. This is the phenomenon
where the distribution of data in the training set differs from the
distribution of data in the real world, the deployment environment. While
extensively explored in computer vision and natural language processing, and
while prior research in mobile sensing briefly addresses this concern, current
work primarily focuses on models dealing with a single modality of data, such
as audio or accelerometer readings, and consequently, there is little research
on unsupervised domain adaptation when dealing with multimodal sensor data. To
address this gap, we did extensive experiments with domain adversarial neural
networks (DANN) showing that they can effectively handle distribution shifts in
multimodal sensor data. Moreover, we proposed a novel improvement over DANN,
called M3BAT, unsupervised domain adaptation for multimodal mobile sensing with
multi-branch adversarial training, to account for the multimodality of sensor
data during domain adaptation with multiple branches. Through extensive
experiments conducted on two multimodal mobile sensing datasets, three
inference tasks, and 14 source-target domain pairs, including both regression
and classification, we demonstrate that our approach performs effectively on
unseen domains. Compared to directly deploying a model trained in the source
domain to the target domain, the model shows performance increases up to 12%
AUC (area under the receiver operating characteristics curves) on
classification tasks, and up to 0.13 MAE (mean absolute error) on regression
tasks.

摘要：多年來，多模態移動感測已被廣泛應用於
關於健康和福祉、行為和背景的推論。然而，一個
阻礙此類模型廣泛部署的重大挑戰
現實世界的場景是分佈轉移的問題。這就是現象
其中訓練集中資料的分佈與
資料在現實世界的分佈、部署環境。儘管
在電腦視覺和自然語言處理方面進行了廣泛的探索，並且
雖然移動感測領域的先前研究簡要地解決了這個問題，但當前
工作主要集中於處理單一資料模態的模型，例如
作為音頻或加速度計讀數，因此，很少有研究
處理多模態感測器資料時的無監督域適應。到
為了解決這個差距，我們對領域對抗神經網路進行了廣泛的實驗
網路（DANN）表明他們可以有效地處理分佈變化
多模態感測器數據。此外，我們提出了對 DANN 的新穎改進，
稱為 M3BAT，用於多模態移動感測的無監督域自適應
多分支對抗訓練，考慮感測器的多模態
具有多個分支的域適應期間的資料。透過廣泛
在兩個多模態移動感測資料集、三個
推理任務，以及 14 個源-目標域對，包括迴歸
和分類，我們證明我們的方法在以下方面有效執行
看不見的域。與直接部署在來源中訓練的模型相比
域到目標域，模型顯示效能提升高達 12%
AUC（受試者工作特徵曲線下面積）
分類任務，迴歸高達 0.13 MAE（平均絕對誤差）
任務。

##### **Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety using Zero Shot Classification: An Observational Study**
2404.17183v1 by Muhammad Rizwan et.al.

Social anxiety represents a prevalent challenge in modern society, affecting
individuals across personal and professional spheres. Left unaddressed, this
condition can yield substantial negative consequences, impacting social
interactions and performance. Further understanding its diverse physical and
emotional symptoms becomes pivotal for comprehensive diagnosis and tailored
therapeutic interventions. This study analyze prevalence and frequency of
social anxiety symptoms taken from Mayo Clinic, exploring diverse human
experiences from utilizing a large Reddit dataset dedicated to this issue.
Leveraging these platforms, the research aims to extract insights and examine a
spectrum of physical and emotional symptoms linked to social anxiety disorder.
Upholding ethical considerations, the study maintains strict user anonymity
within the dataset. By employing a novel approach, the research utilizes
BART-based multi-label zero-shot classification to identify and measure symptom
prevalence and significance in the form of probability score for each symptom
under consideration. Results uncover distinctive patterns: "Trembling" emerges
as a prevalent physical symptom, while emotional symptoms like "Fear of being
judged negatively" exhibit high frequencies. These findings offer insights into
the multifaceted nature of social anxiety, aiding clinical practices and
interventions tailored to its diverse expressions.

摘要：社交焦慮是現代社會普遍存在的挑戰，影響
個人和專業領域的個人。沒有解決，這個
這種情況可能會產生嚴重的負面後果，影響社會
交互和性能。進一步了解其多樣化的物理學和
情緒症狀成為綜合診斷和客製化的關鍵
治療幹預。本研究分析了盛行率和頻率
來自梅奧診所的社交焦慮症狀，探索不同的人類
利用專門解決此問題的大型 Reddit 資料集的經驗。
該研究旨在利用這些平台提取見解並檢驗
與社交焦慮症相關的一系列身體和情緒症狀。
出於道德考慮，該研究嚴格保持用戶匿名
在數據集中。透過採用一種新穎的方法，該研究利用
基於 BART 的多標籤零樣本分類來識別和測量症狀
每種症狀的機率評分形式的盛行率和重要性
在考慮中。結果揭示了獨特的模式：「顫抖」出現
作為一種普遍的身體症狀，而情緒症狀，如“害怕被
負面評價」表現出很高的頻率。這些發現提供了關於
社交焦慮的多方面性質，有助於臨床實踐和
針對其不同表現形式的介入措施。

##### **Deep Evidential Learning for Dose Prediction**
2404.17126v1 by Hai Siong Tan et.al.

In this work, we present a novel application of an uncertainty-quantification
framework called Deep Evidential Learning in the domain of radiotherapy dose
prediction. Using medical images of the Open Knowledge-Based Planning Challenge
dataset, we found that this model can be effectively harnessed to yield
uncertainty estimates that inherited correlations with prediction errors upon
completion of network training. This was achieved only after reformulating the
original loss function for a stable implementation. We found that (i)epistemic
uncertainty was highly correlated with prediction errors, with various
association indices comparable or stronger than those for Monte-Carlo Dropout
and Deep Ensemble methods, (ii)the median error varied with uncertainty
threshold much more linearly for epistemic uncertainty in Deep Evidential
Learning relative to these other two conventional frameworks, indicative of a
more uniformly calibrated sensitivity to model errors, (iii)relative to
epistemic uncertainty, aleatoric uncertainty demonstrated a more significant
shift in its distribution in response to Gaussian noise added to CT intensity,
compatible with its interpretation as reflecting data noise. Collectively, our
results suggest that Deep Evidential Learning is a promising approach that can
endow deep-learning models in radiotherapy dose prediction with statistical
robustness. Towards enhancing its clinical relevance, we demonstrate how we can
use such a model to construct the predicted Dose-Volume-Histograms' confidence
intervals.

摘要：在這項工作中，我們提出了不確定性量化的新穎應用
放射治療劑量領域稱為深度證據學習的框架
預言。使用開放知識規劃挑戰賽的醫學影像
資料集，我們發現這個模型可以有效地利用來產生
不確定性估計繼承了與預測誤差的相關性
完成網路培訓。這是在重新制定後才實現的
用於穩定實現的原始損失函數。我們發現（i）認知
不確定性與預測誤差高度相關，
關聯指數與 Monte-Carlo Dropout 相當或更強
和深度集成方法，(ii)中位數誤差隨不確定性變化
深度證據中認知不確定性的閾值較為線性
相對於這另外兩個傳統框架的學習，表明
對模型誤差的更統一的校準敏感性，(iii)相對於
認知不確定性、任意不確定性表現出更顯著的影響
響應於 CT 強度添加的高斯噪聲，其分佈發生變化，
與其反映數據雜訊的解釋相容。總的來說，我們的
結果顯示深度證據學習是一種有前途的方法，可以
為放射治療劑量預測中的深度學習模型提供統計數據
穩健性.為了增強其臨床相關性，我們展示瞭如何能夠
使用這樣的模型來建立預測劑量-體積直方圖的置信度
間隔。

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge et.al.

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：人工智慧（AI）的普遍整合已經引入
如果出現以下情況，責任和問責制將面臨複雜的挑戰
涉及人工智慧系統的事件。這些系統的互連性，
人工智慧引發的事件的倫理問題以及人工智慧的不確定性
技術的進步和相應法規的缺失，使得傳統的
責任歸屬具有挑戰性。為此，本工作提出了
計算反射平衡（CRE）方法建立一個連貫的和
所有利害關係人在道德上可接受的責任歸屬框架。
計算方法提供了一種結構化分析，克服了
概念方法在處理動態和多方面問題時的局限性
場景，展示框架的可解釋性、連貫性和適應性
責任歸屬過程中的屬性。我們檢查關鍵的
與平衡狀態下的索賠相關的初始活化水準的作用
計算。以AI輔助醫療決策支援系統為例
研究中，我們說明了不同的初始化如何導致不同的結果
責任分配。該框架提供了寶貴的見解
人工智慧引發的事件的問責制，促進發展
透過持續監控、修訂和改進，實現可持續和有彈性的系統
反射。

##### **Taming False Positives in Out-of-Distribution Detection with Human Feedback**
2404.16954v1 by Harit Vishwakarma et.al.

Robustness to out-of-distribution (OOD) samples is crucial for safely
deploying machine learning models in the open world. Recent works have focused
on designing scoring functions to quantify OOD uncertainty. Setting appropriate
thresholds for these scoring functions for OOD detection is challenging as OOD
samples are often unavailable up front. Typically, thresholds are set to
achieve a desired true positive rate (TPR), e.g., $95\%$ TPR. However, this can
lead to very high false positive rates (FPR), ranging from 60 to 96\%, as
observed in the Open-OOD benchmark. In safety-critical real-life applications,
e.g., medical diagnosis, controlling the FPR is essential when dealing with
various OOD samples dynamically. To address these challenges, we propose a
mathematically grounded OOD detection framework that leverages expert feedback
to \emph{safely} update the threshold on the fly. We provide theoretical
results showing that it is guaranteed to meet the FPR constraint at all times
while minimizing the use of human feedback. Another key feature of our
framework is that it can work with any scoring function for OOD uncertainty
quantification. Empirical evaluation of our system on synthetic and benchmark
OOD datasets shows that our method can maintain FPR at most $5\%$ while
maximizing TPR.

摘要：對分佈外 (OOD) 樣本的穩健性對於安全至關重要
在開放世界中部署機器學習模型。最近的作品主要集中在
設計評分函數來量化 OOD 不確定性。設定適當
OOD 檢測的這些評分函數的閾值具有挑戰性，因為 OOD
樣品通常無法預先獲得。通常，閾值設定為
達到所需的真陽性率 (TPR)，例如 $95\%$ TPR。然而，這可以
導致非常高的誤報率 (FPR)，範圍從 60% 到 96\%，如
在 Open-OOD 基準測試中觀察到。在安全關鍵的現實生活應用中，
例如，醫療診斷、處理 FPR 時至關重要
動態地提供各種 OOD 樣本。為了應對這些挑戰，我們提出了
基於數學的 OOD 檢測框架，利用專家回饋
\emph{安全地}動態更新閾值。我們提供理論
結果表明，保證始終滿足 FPR 約束
同時最大限度地減少人類回饋的使用。我們的另一個主要特點
框架的特點是它可以與任何 OOD 不確定性評分函數一起使用
量化。對我們的系統進行綜合和基準的實證評估
OOD 資料集表明，我們的方法最多可以將 FPR 維持在 $5\%$，而
最大化 TPR。

##### **Features Fusion for Dual-View Mammography Mass Detection**
2404.16718v1 by Arina Varlamova et.al.

Detection of malignant lesions on mammography images is extremely important
for early breast cancer diagnosis. In clinical practice, images are acquired
from two different angles, and radiologists can fully utilize information from
both views, simultaneously locating the same lesion. However, for automatic
detection approaches such information fusion remains a challenge. In this
paper, we propose a new model called MAMM-Net, which allows the processing of
both mammography views simultaneously by sharing information not only on an
object level, as seen in existing works, but also on a feature level.
MAMM-Net's key component is the Fusion Layer, based on deformable attention and
designed to increase detection precision while keeping high recall. Our
experiments show superior performance on the public DDSM dataset compared to
the previous state-of-the-art model, while introducing new helpful features
such as lesion annotation on pixel-level and classification of lesions
malignancy.

摘要：乳房X光攝影影像上惡性病變的檢測極為重要
用於早期乳癌診斷。在臨床實務中，取得影像
從兩個不同的角度，放射科醫生可以充分利用來自
兩個視圖同時定位同一病變。然而，對於自動
這種資訊融合的檢測方法仍然是一個挑戰。在這個
在論文中，我們提出了一種稱為 MAMM-Net 的新模型，它允許處理
透過分享訊息，不僅可以同時取得乳房 X 光檢查視圖
物件級別，如現有作品中所見，而且還包括特徵級別。
MAMM-Net 的關鍵組件是融合層，基於可變形注意力和
旨在提高檢測精度，同時保持高召回率。我們的
實驗表明，與公共 DDSM 資料集相比，該資料集具有優越的效能
以前最先進的模型，同時引入新的實用功能
例如像素級的病灶標註和病灶分類
惡性腫瘤。

##### **Report on Candidate Computational Indicators for Conscious Valenced Experience**
2404.16696v1 by Andres Campero et.al.

This report enlists 13 functional conditions cashed out in computational
terms that have been argued to be constituent of conscious valenced experience.
These are extracted from existing empirical and theoretical literature on,
among others, animal sentience, medical disorders, anaesthetics, philosophy,
evolution, neuroscience, and artificial intelligence.

摘要：該報告列舉了 13 種透過計算實現的功能條件
被認為是有意識的價經驗的組成部分的術語。
這些是從現有的經驗和理論文獻中提取的，
其中包括動物感知、醫學疾病、麻醉學、哲學、
進化論、神經科學和人工智慧。

##### **ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling**
2404.16659v1 by Sangryul Kim et.al.

Recently, deep learning-based language models have significantly enhanced
text-to-SQL tasks, with promising applications in retrieving patient records
within the medical domain. One notable challenge in such applications is
discerning unanswerable queries. Through fine-tuning model, we demonstrate the
feasibility of converting medical record inquiries into SQL queries.
Additionally, we introduce an entropy-based method to identify and filter out
unanswerable results. We further enhance result quality by filtering
low-confidence SQL through log probability-based distribution, while
grammatical and schema errors are mitigated by executing queries on the actual
database. We experimentally verified that our method can filter unanswerable
questions, which can be widely utilized even when the parameters of the model
are not accessible, and that it can be effectively utilized in practice.

摘要：最近，基於深度學習的語言模型顯著增強了
文字到 SQL 任務，在檢索病患記錄方面具有廣泛的應用前景
在醫學領域內。此類應用中的一個顯著挑戰是
辨別無法回答的問題。透過微調模型，我們證明了
將病歷查詢轉換為 SQL 查詢的可行性。
此外，我們引入了一種基於熵的方法來識別和過濾掉
無法回答的結果。我們透過過濾進一步提高結果品質
透過基於日誌機率的分佈來降低置信度 SQL，同時
透過對實際資料執行查詢可以減少語法和模式錯誤
資料庫.我們實驗驗證了我們的方法可以過濾無法回答的
問題，即使模型的參數
是不可獲取的，並且可以在實踐中有效利用。

##### **Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**
2404.16621v1 by Emre Can Acikgoz et.al.

The integration of Large Language Models (LLMs) into healthcare promises to
transform medical diagnostics, research, and patient care. Yet, the progression
of medical LLMs faces obstacles such as complex training requirements, rigorous
evaluation demands, and the dominance of proprietary models that restrict
academic exploration. Transparent, comprehensive access to LLM resources is
essential for advancing the field, fostering reproducibility, and encouraging
innovation in healthcare AI. We present Hippocrates, an open-source LLM
framework specifically developed for the medical domain. In stark contrast to
previous efforts, it offers unrestricted access to its training datasets,
codebase, checkpoints, and evaluation protocols. This open approach is designed
to stimulate collaborative research, allowing the community to build upon,
refine, and rigorously evaluate medical LLMs within a transparent ecosystem.
Also, we introduce Hippo, a family of 7B models tailored for the medical
domain, fine-tuned from Mistral and LLaMA2 through continual pre-training,
instruction tuning, and reinforcement learning from human and AI feedback. Our
models outperform existing open medical LLMs models by a large-margin, even
surpassing models with 70B parameters. Through Hippocrates, we aspire to unlock
the full potential of LLMs not just to advance medical knowledge and patient
care but also to democratize the benefits of AI research in healthcare, making
them available across the globe.

摘要：將大型語言模型 (LLM) 整合到醫療保健領域有望
改變醫療診斷、研究和病患照護。然而，進展
的醫學法學碩士面臨複雜的訓練要求、嚴格的訓練等障礙
評估要求以及限制專有模型的主導地位
學術探索。對 LLM 資源的透明、全面的存取是
對於推進該領域、促進可重複性和鼓勵
醫療保健人工智慧的創新。我們介紹希波克拉底，一個開源法學碩士
專門為醫療領域所開發的框架。與之形成鮮明對比的是
與先前的努力相比，它提供了對其訓練資料集的無限制訪問，
程式碼庫、檢查點和評估協議。這種開放式方法的設計
促進合作研究，讓社區在此基礎上繼續發展，
在透明的生態系統中完善和嚴格評估醫學法學碩士。
此外，我們還推出了專為醫療行業量身定制的 7B 型號 Hippo 系列。
域，透過持續的預訓練從 Mistral 和 LLaMA2 進行微調，
指令調整以及來自人類和人工智慧回饋的強化學習。我們的
模型的表現遠優於現有的開放式醫學法學碩士模型，甚至
超越70B參數的模型。透過希波克拉底，我們渴望解鎖
法學碩士的全部潛力不僅可以促進醫學知識和病人的發展
也使人工智慧研究在醫療保健領域的好處民主化，使
它們在全球範圍內可用。

##### **DiffSeg: A Segmentation Model for Skin Lesions Based on Diffusion Difference**
2404.16474v1 by Zhihao Shuai et.al.

Weakly supervised medical image segmentation (MIS) using generative models is
crucial for clinical diagnosis. However, the accuracy of the segmentation
results is often limited by insufficient supervision and the complex nature of
medical imaging. Existing models also only provide a single outcome, which does
not allow for the measurement of uncertainty. In this paper, we introduce
DiffSeg, a segmentation model for skin lesions based on diffusion difference
which exploits diffusion model principles to ex-tract noise-based features from
images with diverse semantic information. By discerning difference between
these noise features, the model identifies diseased areas. Moreover, its
multi-output capability mimics doctors' annotation behavior, facilitating the
visualization of segmentation result consistency and ambiguity. Additionally,
it quantifies output uncertainty using Generalized Energy Distance (GED),
aiding interpretability and decision-making for physicians. Finally, the model
integrates outputs through the Dense Conditional Random Field (DenseCRF)
algorithm to refine the segmentation boundaries by considering inter-pixel
correlations, which improves the accuracy and optimizes the segmentation
results. We demonstrate the effectiveness of DiffSeg on the ISIC 2018 Challenge
dataset, outperforming state-of-the-art U-Net-based methods.

摘要：使用生成模型的弱監督醫學影像分割（MIS）是
對臨床診斷至關重要。但分割的準確率
結果往往受到監督不足和複雜性的限制
醫學影像。現有模型也僅提供單一結果，這確實
不允許測量不確定度。在本文中，我們介紹
DiffSeg，一種基於擴散差的皮損分割模型
它利用擴散模型原理來提取基於噪音的特徵
具有多種語義資訊的圖像。透過辨別之間的差異
透過這些噪音特徵，模型可以識別患病區域。而且，其
多輸出能力模仿醫生的註釋行為，促進
分割結果一致性和模糊性的可視化。此外，
它使用廣義能量距離（GED）量化輸出不確定性，
幫助醫生進行解釋和決策。最後是模型
透過密集條件隨機場 (DenseCRF) 整合輸出
透過考慮像素間細化分割邊界的演算法
相關性，提高了準確性並優化了分割
結果。我們在 ISIC 2018 挑戰賽中展示了 DiffSeg 的有效性
數據集，優於最先進的基於 U-Net 的方法。

##### **Light-weight Retinal Layer Segmentation with Global Reasoning**
2404.16346v1 by Xiang He et.al.

Automatic retinal layer segmentation with medical images, such as optical
coherence tomography (OCT) images, serves as an important tool for diagnosing
ophthalmic diseases. However, it is challenging to achieve accurate
segmentation due to low contrast and blood flow noises presented in the images.
In addition, the algorithm should be light-weight to be deployed for practical
clinical applications. Therefore, it is desired to design a light-weight
network with high performance for retinal layer segmentation. In this paper, we
propose LightReSeg for retinal layer segmentation which can be applied to OCT
images. Specifically, our approach follows an encoder-decoder structure, where
the encoder part employs multi-scale feature extraction and a Transformer block
for fully exploiting the semantic information of feature maps at all scales and
making the features have better global reasoning capabilities, while the
decoder part, we design a multi-scale asymmetric attention (MAA) module for
preserving the semantic information at each encoder scale. The experiments show
that our approach achieves a better segmentation performance compared to the
current state-of-the-art method TransUnet with 105.7M parameters on both our
collected dataset and two other public datasets, with only 3.3M parameters.

摘要：使用醫學影像（例如光學影像）進行自動視網膜層分割
相干斷層掃描（OCT）影像是診斷的重要工具
眼科疾病。然而，要實現準確的
由於影像中呈現的低對比度和血流雜訊而導致的分割。
此外，該演算法應該是輕量級的，以便部署到實際中
臨床應用。因此，需要設計一種輕量化的
具有高效能的視網膜層分割網路。在本文中，我們
提出LightReSeg用於視網膜層分割，可應用於OCT
圖片。具體來說，我們的方法遵循編碼器-解碼器結構，其中
編碼器部分採用多尺度特徵提取和 Transformer 區塊
充分利用所有尺度的特徵圖的語意資訊和
使得特徵具有更好的全局推理能力，同時
解碼器部分，我們設計了一個多尺度非對稱注意力（MAA）模組
保留每個編碼器尺度的語意資訊。實驗表明
與之前的方法相比，我們的方法實現了更好的分割性能
目前最先進的方法 TransUnet 在我們的兩個平台上具有 105.7M 參數
收集的資料集和另外兩個公共資料集，只有 330 萬個參數。

##### **Semantic Segmentation Refiner for Ultrasound Applications with Zero-Shot Foundation Models**
2404.16325v1 by Hedda Cohen Indelman et.al.

Despite the remarkable success of deep learning in medical imaging analysis,
medical image segmentation remains challenging due to the scarcity of
high-quality labeled images for supervision. Further, the significant domain
gap between natural and medical images in general and ultrasound images in
particular hinders fine-tuning models trained on natural images to the task at
hand. In this work, we address the performance degradation of segmentation
models in low-data regimes and propose a prompt-less segmentation method
harnessing the ability of segmentation foundation models to segment abstract
shapes. We do that via our novel prompt point generation algorithm which uses
coarse semantic segmentation masks as input and a zero-shot prompt-able
foundation model as an optimization target. We demonstrate our method on a
segmentation findings task (pathologic anomalies) in ultrasound images. Our
method's advantages are brought to light in varying degrees of low-data regime
experiments on a small-scale musculoskeletal ultrasound images dataset,
yielding a larger performance gain as the training set size decreases.

摘要：儘管深度學習在醫學影像分析方面取得了顯著的成功，
由於缺乏數據，醫學影像分割仍然具有挑戰性
用於監督的高品質標記圖像。進一步地，顯著域
一般的自然影像和醫學影像與超音波影像之間的差距
特別是阻礙了在自然圖像上訓練的模型對任務的微調
手。在這項工作中，我們解決了分割的效能下降問題
在低數據情況下建模並提出一種無提示分割方法
利用分割基礎模型的能力分割摘要
形狀。我們透過新穎的提示點生成演算法來做到這一點，該演算法使用
粗略語義分割遮罩作為輸入和零樣本提示
基礎模型作為最佳化目標。我們在
超音波影像中的分割發現任務（病理異常）。我們的
此方法的優點在不同程度的低數據情況下得到體現
在小規模肌肉骨骼超音波影像資料集上進行的實驗，
隨著訓練集大小的減小，產生更大的效能增益。

##### **LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications**
2404.16294v1 by Saranya Krishnamoorthy et.al.

Electronic health records (EHR) even though a boon for healthcare
practitioners, are growing convoluted and longer every day. Sifting around
these lengthy EHRs is taxing and becomes a cumbersome part of physician-patient
interaction. Several approaches have been proposed to help alleviate this
prevalent issue either via summarization or sectioning, however, only a few
approaches have truly been helpful in the past. With the rise of automated
methods, machine learning (ML) has shown promise in solving the task of
identifying relevant sections in EHR. However, most ML methods rely on labeled
data which is difficult to get in healthcare. Large language models (LLMs) on
the other hand, have performed impressive feats in natural language processing
(NLP), that too in a zero-shot manner, i.e. without any labeled data. To that
end, we propose using LLMs to identify relevant section headers. We find that
GPT-4 can effectively solve the task on both zero and few-shot settings as well
as segment dramatically better than state-of-the-art methods. Additionally, we
also annotate a much harder real world dataset and find that GPT-4 struggles to
perform well, alluding to further research and harder benchmarks.

摘要：電子健康記錄 (EHR) 儘管對醫療保健有好處
實踐者們，每天都變得越來越複雜、越來越長。篩選
這些冗長的電子病歷非常繁重，並且成為醫病關係中的一個麻煩部分
相互作用。已經提出了幾種方法來幫助緩解這種情況
透過總結或分段來解決普遍存在的問題，但是，只有少數
過去的方法確實很有幫助。隨著自動化的興起
方法，機器學習（ML）在解決以下任務方面表現出了希望
確定電子病歷中的相關部分。然而，大多數機器學習方法依賴標記的
醫療保健領域很難獲得的數據。大型語言模型 (LLM)
另一方面，在自然語言處理方面取得了令人印象深刻的成就
（NLP），這也是零樣本方式，即沒有任何標記資料。對此
最後，我們建議使用法學碩士來識別相關的章節標題。我們發現
GPT-4 也可以有效解決零樣本和少樣本設定下的任務
作為細分市場，其性能比最先進的方法好得多。此外，我們
也註釋了一個更難的現實世界資料集，發現 GPT-4 很難
表現良好，暗示著進一步的研究和更嚴格的基準。

##### **Investigating the prompt leakage effect and black-box defenses for multi-turn LLM interactions**
2404.16251v2 by Divyansh Agarwal et.al.

Prompt leakage in large language models (LLMs) poses a significant security
and privacy threat, particularly in retrieval-augmented generation (RAG)
systems. However, leakage in multi-turn LLM interactions along with mitigation
strategies has not been studied in a standardized manner. This paper
investigates LLM vulnerabilities against prompt leakage across 4 diverse
domains and 10 closed- and open-source LLMs. Our unique multi-turn threat model
leverages the LLM's sycophancy effect and our analysis dissects task
instruction and knowledge leakage in the LLM response. In a multi-turn setting,
our threat model elevates the average attack success rate (ASR) to 86.2%,
including a 99% leakage with GPT-4 and claude-1.3. We find that some black-box
LLMs like Gemini show variable susceptibility to leakage across domains - they
are more likely to leak contextual knowledge in the news domain compared to the
medical domain. Our experiments measure specific effects of 6 black-box defense
strategies, including a query-rewriter in the RAG scenario. Our proposed
multi-tier combination of defenses still has an ASR of 5.3% for black-box LLMs,
indicating room for enhancement and future direction for LLM security research.

摘要：大型語言模型 (LLM) 中的即時洩漏帶來了重大安全問題
和隱私威脅，特別是在檢索增強生成（RAG）中
系統。然而，多輪 LLM 互動中的洩漏以及緩解
策略尚未以標準化方式進行研究。這張紙
調查 LLM 漏洞，防止 4 個不同領域的即時洩漏
領域和 10 個封閉和開源法學碩士。我們獨特的多回合威脅模型
利用法學碩士的阿諛奉承效應和我們的分析剖析任務
LLM 回答中的指導和知識外洩。在多圈設定中，
我們的威脅模型將平均攻擊成功率 (ASR) 提高到 86.2%，
包括 GPT-4 和 claude-1.3 的 99% 洩漏。我們發現一些黑盒子
像 Gemini 這樣的法學碩士對跨領域的洩漏表現出不同的敏感性 - 他們
與其他人相比，他們更有可能洩露新聞領域的背景知識
醫療領域。我們的實驗測量了 6 種黑盒子防禦的具體效果
策略，包括 RAG 場景中的查詢重寫器。我們提出的
對於黑盒法學碩士來說，多層防禦組合的 ASR 仍然為 5.3%，
顯示 LLM 安全研究的增強空間和未來方向。

##### **ABCD: Trust enhanced Attention based Convolutional Autoencoder for Risk Assessment**
2404.16183v1 by Sarala Naidu et.al.

Anomaly detection in industrial systems is crucial for preventing equipment
failures, ensuring risk identification, and maintaining overall system
efficiency. Traditional monitoring methods often rely on fixed thresholds and
empirical rules, which may not be sensitive enough to detect subtle changes in
system health and predict impending failures. To address this limitation, this
paper proposes, a novel Attention-based convolutional autoencoder (ABCD) for
risk detection and map the risk value derive to the maintenance planning. ABCD
learns the normal behavior of conductivity from historical data of a real-world
industrial cooling system and reconstructs the input data, identifying
anomalies that deviate from the expected patterns. The framework also employs
calibration techniques to ensure the reliability of its predictions. Evaluation
results demonstrate that with the attention mechanism in ABCD a 57.4% increase
in performance and a reduction of false alarms by 9.37% is seen compared to
without attention. The approach can effectively detect risks, the risk priority
rank mapped to maintenance, providing valuable insights for cooling system
designers and service personnel. Calibration error of 0.03% indicates that the
model is well-calibrated and enhances model's trustworthiness, enabling
informed decisions about maintenance strategies

摘要：工業系統中的異常檢測對於預防設備故障至關重要
故障，確保風險識別並維護整個系統
效率。傳統的監測方法往往依賴固定的閾值和
經驗規則，可能不夠敏感，無法偵測到細微的變化
系統健康狀況並預測即將發生的故障。為了解決這個限制，這
論文提出了一種新穎的基於注意力的捲積自動編碼器（ABCD）
風險偵測並將風險值對應到維護計劃。 A B C D
從現實世界的歷史資料中學習電導率的正常行為
工業冷卻系統並重建輸入數據，識別
偏離預期模式的異常現象。該框架還採用
校準技術以確保其預測的可靠性。評估
結果表明，ABCD 中的注意力機制提高了 57.4%
與之前相比，誤報率降低了 9.37%
無需注意。此方法能夠有效發現風險，並確定風險優先級
排名映射到維護，為冷卻系統提供有價值的見解
設計師和服務人員。 0.03% 的校準誤差表明
模型經過良好校準並增強了模型的可信度，使得
有關維護策略的明智決策

##### **Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges**
2404.16112v1 by Badri Narayana Patro et.al.

Sequence modeling is a crucial area across various domains, including Natural
Language Processing (NLP), speech recognition, time series forecasting, music
generation, and bioinformatics. Recurrent Neural Networks (RNNs) and Long Short
Term Memory Networks (LSTMs) have historically dominated sequence modeling
tasks like Machine Translation, Named Entity Recognition (NER), etc. However,
the advancement of transformers has led to a shift in this paradigm, given
their superior performance. Yet, transformers suffer from $O(N^2)$ attention
complexity and challenges in handling inductive bias. Several variations have
been proposed to address these issues which use spectral networks or
convolutions and have performed well on a range of tasks. However, they still
have difficulty in dealing with long sequences. State Space Models(SSMs) have
emerged as promising alternatives for sequence modeling paradigms in this
context, especially with the advent of S4 and its variants, such as S4nd,
Hippo, Hyena, Diagnol State Spaces (DSS), Gated State Spaces (GSS), Linear
Recurrent Unit (LRU), Liquid-S4, Mamba, etc. In this survey, we categorize the
foundational SSMs based on three paradigms namely, Gating architectures,
Structural architectures, and Recurrent architectures. This survey also
highlights diverse applications of SSMs across domains such as vision, video,
audio, speech, language (especially long sequence modeling), medical (including
genomics), chemical (like drug design), recommendation systems, and time series
analysis, including tabular data. Moreover, we consolidate the performance of
SSMs on benchmark datasets like Long Range Arena (LRA), WikiText, Glue, Pile,
ImageNet, Kinetics-400, sstv2, as well as video datasets such as Breakfast,
COIN, LVU, and various time series datasets. The project page for Mamba-360
work is available on this webpage.\url{https://github.com/badripatro/mamba360}.

摘要：序列建模是各領域的關鍵領域，包括自然領域
語言處理（NLP）、語音辨識、時間序列預測、音樂
生成和生物資訊學。循環神經網路 (RNN) 和長空
術語記憶網路 (LSTM) 歷來在序列建模中佔據主導地位
機器翻譯、命名實體辨識 (NER) 等任務。
鑑於變壓器的進步導致了這種範式的轉變
他們的卓越表現。然而，變形金剛卻受到了 $O(N^2)$ 的關注
處理歸納偏差的複雜性和挑戰。有幾種變體
建議使用頻譜網路或
卷積並在一系列任務上表現良好。然而，他們仍然
處理長序列有困難。狀態空間模型（SSM）有
成為序列建模範式的有前途的替代方案
上下文，特別是隨著 S4 及其變體（例如 S4nd）的出現，
Hippo、Hyena、診斷狀態空間 (DSS)、閘控狀態空間 (GSS)、線性
循環單元（LRU）、Liquid-S4、Mamba 等。
基於三種範式的基礎 SSM，即閘控架構、
結構架構和迴圈架構。這項調查還
重點介紹了 SSM 在視覺、視訊、
音訊、語音、語言（尤其是長序列建模）、醫學（包括
基因組學）、化學（如藥物設計）、推薦系統和時間序列
分析，包括表格數據。此外，我們也整合了
基準資料集上的 SSM，例如 Long Range Arena (LRA)、WikiText、Glue、Pile、
ImageNet、Kinetics-400、sstv2，以及早餐等影片資料集，
COIN、LVU 和各種時間序列資料集。 Mamba-360 的專案頁面
此網頁上提供了工作。

##### **Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography**
2404.15946v1 by Xuxin Chen et.al.

Although fusion of information from multiple views of mammograms plays an
important role to increase accuracy of breast cancer detection, developing
multi-view mammograms-based computer-aided diagnosis (CAD) schemes still faces
challenges and no such CAD schemes have been used in clinical practice. To
overcome the challenges, we investigate a new approach based on Contrastive
Language-Image Pre-training (CLIP), which has sparked interest across various
medical imaging tasks. By solving the challenges in (1) effectively adapting
the single-view CLIP for multi-view feature fusion and (2) efficiently
fine-tuning this parameter-dense model with limited samples and computational
resources, we introduce Mammo-CLIP, the first multi-modal framework to process
multi-view mammograms and corresponding simple texts. Mammo-CLIP uses an early
feature fusion strategy to learn multi-view relationships in four mammograms
acquired from the CC and MLO views of the left and right breasts. To enhance
learning efficiency, plug-and-play adapters are added into CLIP image and text
encoders for fine-tuning parameters and limiting updates to about 1% of the
parameters. For framework evaluation, we assembled two datasets
retrospectively. The first dataset, comprising 470 malignant and 479 benign
cases, was used for few-shot fine-tuning and internal evaluation of the
proposed Mammo-CLIP via 5-fold cross-validation. The second dataset, including
60 malignant and 294 benign cases, was used to test generalizability of
Mammo-CLIP. Study results show that Mammo-CLIP outperforms the state-of-art
cross-view transformer in AUC (0.841 vs. 0.817, 0.837 vs. 0.807) on both
datasets. It also surpasses previous two CLIP-based methods by 20.3% and 14.3%.
This study highlights the potential of applying the finetuned vision-language
models for developing next-generation, image-text-based CAD schemes of breast
cancer.

摘要：儘管來自乳房 X 光檢查多個視圖的資訊融合發揮了重要作用
提高乳癌檢測準確性的重要作用，開發
基於多視圖乳房X光檢查的電腦輔助診斷（CAD）方案仍面臨挑戰
挑戰，並且尚未在臨床實踐中使用此類 CAD 方案。到
克服挑戰，我們研究了一種基於對比的新方法
語言-圖像預訓練（CLIP），引起了各領域的興趣
醫學影像任務。透過解決（1）中的挑戰，有效適應
用於多視圖特徵融合的單視圖 CLIP 以及 (2) 高效
用有限的樣本和計算量微調這個參數密集模型
資源，我們介紹了 Mammo-CLIP，第一個多模態框架來處理
多視圖乳房X光照片和對應的簡單文字。 Mammo-CLIP 使用早期
學習四張乳房X光照片中多視圖關係的特徵融合策略
從左乳房和右乳房的 CC 和 MLO 視圖獲得。加強
提高學習效率，CLIP圖文加入即插即用轉接器
用於微調參數並將更新限制為約 1% 的編碼器
參數。為了進行框架評估，我們組裝了兩個資料集
回顧起來。第一個資料集，包含 470 個惡性和 479 個良性
案例，用於小樣本微調和內部評估
透過 5 倍交叉驗證提出了 Mammo-CLIP。第二個資料集，包括
60 個惡性病例和 294 個良性病例用於檢驗
媽媽剪輯。研究結果顯示 Mammo-CLIP 的性能優於最先進的技術
兩者的 AUC 中的交叉視圖變換器（0.841 vs. 0.817、0.837 vs. 0.807）
數據集。它也超過了之前兩種基於 CLIP 的方法 20.3% 和 14.3%。
這項研究強調了應用微調視覺語言的潛力
用於開發下一代基於圖像文字的乳房 CAD 方案的模型
癌症。

##### **Assessing The Potential Of Mid-Sized Language Models For Clinical QA**
2404.15894v1 by Elliot Bolton et.al.

Large language models, such as GPT-4 and Med-PaLM, have shown impressive
performance on clinical tasks; however, they require access to compute, are
closed-source, and cannot be deployed on device. Mid-size models such as
BioGPT-large, BioMedLM, LLaMA 2, and Mistral 7B avoid these drawbacks, but
their capacity for clinical tasks has been understudied. To help assess their
potential for clinical use and help researchers decide which model they should
use, we compare their performance on two clinical question-answering (QA)
tasks: MedQA and consumer query answering. We find that Mistral 7B is the best
performing model, winning on all benchmarks and outperforming models trained
specifically for the biomedical domain. While Mistral 7B's MedQA score of 63.0%
approaches the original Med-PaLM, and it often can produce plausible responses
to consumer health queries, room for improvement still exists. This study
provides the first head-to-head assessment of open source mid-sized models on
clinical tasks.

摘要：大型語言模型，例如 GPT-4 和 Med-PaLM，已經表現出了令人印象深刻的表現
臨床任務的表現；然而，它們需要訪問計算，是
閉源，無法部署在設備上。中型型號，例如
BioGPT-large、BioMedLM、LLaMA 2 和 Mistral 7B 避免了這些缺點，但是
他們的臨床任務能力尚未被充分研究。幫助評估他們的
具有臨床使用的潛力並幫助研究人員決定他們應該使用哪種模型
使用，我們比較他們在兩個臨床問答（QA）上的表現
任務：MedQA 和消費者查詢回答。我們發現 Mistral 7B 是最好的
執行模型，在所有基準測試中獲勝並優於經過訓練的模型
專門針對生物醫學領域。而 Mistral 7B 的 MedQA 分數為 63.0%
接近原始的 Med-PaLM，並且通常可以產生合理的回應
對於消費者的健康查詢，仍有改進的空間。這項研究
首次對開源中型模型進行頭對頭評估
臨床任務。

##### **Enhancing Diagnosis through AI-driven Analysis of Reflectance Confocal Microscopy**
2404.16080v1 by Hong-Jun Yoon et.al.

Reflectance Confocal Microscopy (RCM) is a non-invasive imaging technique
used in biomedical research and clinical dermatology. It provides virtual
high-resolution images of the skin and superficial tissues, reducing the need
for physical biopsies. RCM employs a laser light source to illuminate the
tissue, capturing the reflected light to generate detailed images of
microscopic structures at various depths. Recent studies explored AI and
machine learning, particularly CNNs, for analyzing RCM images. Our study
proposes a segmentation strategy based on textural features to identify
clinically significant regions, empowering dermatologists in effective image
interpretation and boosting diagnostic confidence. This approach promises to
advance dermatological diagnosis and treatment.

摘要：反射共焦顯微鏡 (RCM) 是一種非侵入性成像技術
用於生物醫學研究和臨床皮膚病學。它提供虛擬
皮膚和淺表組織的高解析度影像，減少了需要
用於物理活檢。 RCM 以雷射光源照亮
組織，捕捉反射光以產生詳細的圖像
不同深度的微觀結構。最近的研究探討了人工智慧和
機器學習，特別是 CNN，用於分析 RCM 影像。我們的研究
提出了一種基於紋理特徵的分割策略來識別
臨床重要區域，使皮膚科醫生能夠獲得有效的影像
解釋並增強診斷信心。這種方法承諾
推進皮膚病診斷和治療。

##### **Anomaly Detection for Incident Response at Scale**
2404.16887v1 by Hanzhang Wang et.al.

We present a machine learning-based anomaly detection product, AI Detect and
Respond (AIDR), that monitors Walmart's business and system health in
real-time. During the validation over 3 months, the product served predictions
from over 3000 models to more than 25 application, platform, and operation
teams, covering 63\% of major incidents and reducing the mean-time-to-detect
(MTTD) by more than 7 minutes. Unlike previous anomaly detection methods, our
solution leverages statistical, ML and deep learning models while continuing to
incorporate rule-based static thresholds to incorporate domain-specific
knowledge. Both univariate and multivariate ML models are deployed and
maintained through distributed services for scalability and high availability.
AIDR has a feedback loop that assesses model quality with a combination of
drift detection algorithms and customer feedback. It also offers
self-onboarding capabilities and customizability. AIDR has achieved success
with various internal teams with lower time to detection and fewer false
positives than previous methods. As we move forward, we aim to expand incident
coverage and prevention, reduce noise, and integrate further with root cause
recommendation (RCR) to enable an end-to-end AIDR experience.

摘要：我們推出了基於機器學習的異常檢測產品 AI Detect 和
回應（AIDR），監控沃爾瑪的業務和系統健康狀況
即時的。在超過 3 個月的驗證過程中，該產品實現了預測
從超過 3000 個模型到超過 25 個應用程式、平台和操作
團隊，覆蓋 63% 的重大事件並縮短平均檢測時間
（MTTD）超過 7 分鐘。與先前的異常檢測方法不同，我們的
解決方案利用統計、機器學習和深度學習模型，同時繼續
合併基於規則的靜態閾值以合併特定於域的
知識。單變量和多變量 ML 模型均已部署並
透過分散式服務進行維護，以實現可擴展性和高可用性。
AIDR 有一個回饋循環，可結合以下因素評估模型品質：
漂移檢測演算法和客戶回饋。它還提供
自我入門能力和可自訂性。 AIDR取得了成功
與各個內部團隊合作，檢測時間更短，錯誤更少
比以前的方法有正面作用。隨著我們的前進，我們的目標是擴大事件範圍
覆蓋和預防，減少噪音，進一步結合根本原因
推薦（RCR）以實現端到端 AIDR 體驗。

##### **Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Detection: The HeHealth Experience**
2404.16885v1 by Rayner Kay Jin Tan et.al.

Artificial Intelligence applications have shown promise in the management of
pandemics and have been widely used to assist the identification,
classification, and diagnosis of medical images. In response to the global
outbreak of Monkeypox (Mpox), the HeHealth.ai team leveraged an existing tool
to screen for sexually transmitted diseases to develop a digital screening test
for symptomatic Mpox through AI approaches. Prior to the global outbreak of
Mpox, the team developed a smartphone app, where app users can use their own
smartphone cameras to take pictures of their own penises to screen for
symptomatic STD. The AI model was initially developed using 5000 cases and use
a modified convolutional neural network to output prediction scores across
visually diagnosable penis pathologies including Syphilis, Herpes Simplex
Virus, and Human Papilloma Virus. From June 2022 to October 2022, a total of
about 22,000 users downloaded the HeHealth app, and about 21,000 images have
been analyzed using HeHealth AI technology. We then engaged in formative
research, stakeholder engagement, rapid consolidation images, a validation
study, and implementation of the tool from July 2022. From July 2022 to October
2022, a total of 1000 Mpox related images had been used to train the Mpox
symptom checker tool. Our digital symptom checker tool showed accuracy of 87%
to rule in Mpox and 90% to rule out symptomatic Mpox. Several hurdles
identified included issues of data privacy and security for app users, initial
lack of data to train the AI tool, and the potential generalizability of input
data. We offer several suggestions to help others get started on similar
projects in emergency situations, including engaging a wide range of
stakeholders, having a multidisciplinary team, prioritizing pragmatism, as well
as the concept that big data in fact is made up of small data.

摘要：人工智慧的應用在管理方面顯示出前景
流行病並已被廣泛用於協助識別，
醫學影像的分類和診斷。為回應全球
猴痘 (Mpox) 爆發時，HeHealth.ai 團隊利用現有工具
篩檢性傳染病 開發數位篩檢測試
透過人工智慧方法治療有症狀的 Mpox。在全球疫情爆發之前
Mpox，該團隊開發了一款智慧型手機應用程序，應用程式用戶可以使用自己的
智慧型手機相機可以拍攝自己的陰莖照片以供篩選
有症狀的性病。 AI模型最初是使用5000個案例開發的，並使用
改進的捲積神經網絡，用於輸出預測分數
可目視診斷的陰莖病變，包括梅毒、單純皰疹
病毒和人類乳突病毒。 2022年6月至2022年10月，共計
約 22,000 名用戶下載了 HeHealth 應用程序，並發布了約 21,000 張圖片
使用 HeHealth AI 技術進行分析。然後我們進行了形成性的
研究、利害關係人參與、快速整合影像、驗證
從 2022 年 7 月開始研究和實施該工具。
2022年，總共使用了1000張Mpox相關影像來訓練Mpox
症狀檢查工具。我們的數位症狀檢查工具顯示準確度為 87%
排除 Mpox，90% 排除有症狀的 Mpox。幾個障礙
確定的問題包括應用程式使用者的資料隱私和安全問題，初始
缺乏訓練人工智慧工具的數據，以及輸入的潛在普遍性
數據。我們提供了一些建議來幫助其他人開始類似的工作
緊急情況下的項目，包括廣泛參與
利害關係人，擁有多學科團隊，優先考慮實用主義，以及
大數據其實是由小數據組成的概念。

##### **PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models**
2404.15549v1 by Shashi Kant Gupta et.al.

Clinical trial matching is the task of identifying trials for which patients
may be potentially eligible. Typically, this task is labor-intensive and
requires detailed verification of patient electronic health records (EHRs)
against the stringent inclusion and exclusion criteria of clinical trials. This
process is manual, time-intensive, and challenging to scale up, resulting in
many patients missing out on potential therapeutic options. Recent advancements
in Large Language Models (LLMs) have made automating patient-trial matching
possible, as shown in multiple concurrent research studies. However, the
current approaches are confined to constrained, often synthetic datasets that
do not adequately mirror the complexities encountered in real-world medical
data. In this study, we present the first, end-to-end large-scale empirical
evaluation of clinical trial matching using real-world EHRs. Our study
showcases the capability of LLMs to accurately match patients with appropriate
clinical trials. We perform experiments with proprietary LLMs, including GPT-4
and GPT-3.5, as well as our custom fine-tuned model called OncoLLM and show
that OncoLLM, despite its significantly smaller size, not only outperforms
GPT-3.5 but also matches the performance of qualified medical doctors. All
experiments were carried out on real-world EHRs that include clinical notes and
available clinical trials from a single cancer center in the United States.

摘要：臨床試驗配對是確定患者參與的試驗的任務
可能有資格。通常，這項任務是勞力密集的，
需要詳細驗證病患電子健康紀錄 (EHR)
違反臨床試驗嚴格的納入與排除標準。這
該過程是手動的，耗時且難以擴大規模，導致
許多患者錯過了潛在的治療選擇。最新進展
大型語言模型 (LLM) 已經實現了患者試驗匹配的自動化
正如多項同時進行的研究表明，這是可能的。但是，那
目前的方法僅限於受約束的、通常是合成的資料集
沒有充分反映現實世界醫療中所遇到的複雜性
數據。在這項研究中，我們提出了第一個端到端的大規模實證研究
使用真實世界的 EHR 評估臨床試驗配對。我們的研究
展示了法學碩士將患者與合適的患者準確匹配的能力
臨床試驗。我們使用專有的 LLM 進行實驗，包括 GPT-4
和 GPT-3.5，以及我們的客製化微調模型 OncoLLM 並顯示
儘管 OncoLLM 的尺寸小得多，但其性能不僅優於
GPT-3.5也符合合格醫師的表現。全部
實驗是在現實世界的 EHR 上進行的，其中包括臨床記錄和
來自美國單一癌症中心的可用臨床試驗。

##### **Multi-scale Intervention Planning based on Generative Design**
2404.15492v1 by Ioannis Kavouras et.al.

The scarcity of green spaces, in urban environments, consists a critical
challenge. There are multiple adverse effects, impacting the health and
well-being of the citizens. Small scale interventions, e.g. pocket parks, is a
viable solution, but comes with multiple constraints, involving the design and
implementation over a specific area. In this study, we harness the capabilities
of generative AI for multi-scale intervention planning, focusing on nature
based solutions. By leveraging image-to-image and image inpainting algorithms,
we propose a methodology to address the green space deficit in urban areas.
Focusing on two alleys in Thessaloniki, where greenery is lacking, we
demonstrate the efficacy of our approach in visualizing NBS interventions. Our
findings underscore the transformative potential of emerging technologies in
shaping the future of urban intervention planning processes.

摘要：城市環境中綠色空間的稀缺是一個關鍵問題
挑戰。存在多種不良影響，影響健康
公民的福祉。小規模幹預措施，例如袖珍公園，是一個
可行的解決方案，但有許多限制，涉及設計和
特定領域的實施。在本研究中，我們利用以下能力
生成人工智慧用於多尺度幹預規劃，關注自然
基於的解決方案。透過利用圖像到圖像和圖像修復演算法，
我們提出了一種解決城市地區綠地不足的方法。
我們專注於塞薩洛尼基缺乏綠化的兩條小巷，
證明我們的方法在可視化 NBS 介入方面的有效性。我們的
研究結果強調了新興技術的變革潛力
塑造城市干預規劃流程的未來。

##### **IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents**
2404.15488v1 by Jean-Philippe Corbeil et.al.

In natural language processing applied to the clinical domain, utilizing
large language models has emerged as a promising avenue for error detection and
correction on clinical notes, a knowledge-intensive task for which annotated
data is scarce. This paper presents MedReAct'N'MedReFlex, which leverages a
suite of four LLM-based medical agents. The MedReAct agent initiates the
process by observing, analyzing, and taking action, generating trajectories to
guide the search to target a potential error in the clinical notes.
Subsequently, the MedEval agent employs five evaluators to assess the targeted
error and the proposed correction. In cases where MedReAct's actions prove
insufficient, the MedReFlex agent intervenes, engaging in reflective analysis
and proposing alternative strategies. Finally, the MedFinalParser agent formats
the final output, preserving the original style while ensuring the integrity of
the error correction process. One core component of our method is our RAG
pipeline based on our ClinicalCorp corpora. Among other well-known sources
containing clinical guidelines and information, we preprocess and release the
open-source MedWiki dataset for clinical RAG application. Our results
demonstrate the central role of our RAG approach with ClinicalCorp leveraged
through the MedReAct'N'MedReFlex framework. It achieved the ninth rank on the
MEDIQA-CORR 2024 final leaderboard.

摘要：在應用於臨床領域的自然語言處理中，利用
大型語言模型已成為錯誤檢測和預測的有前途的途徑
臨床筆記的更正，這是一項知識密集型任務，其註釋
數據稀缺。本文介紹了 MedReAct'N'MedReFlex，它利用
由四位法學碩士醫療代理人組成的套件。 MedReAct 代理程式啟動
透過觀察、分析和採取行動來產生軌跡
指導搜尋以瞄準臨床記錄中的潛在錯誤。
隨後，MedEval 代理僱用五名評估員來評估目標
錯誤和建議的更正。如果 MedReAct 的行動證明
不足時，MedReFlex 代理人介入，進行反思分析
並提出替代策略。最後，MedFinalParser 代理格式
最終輸出，保留原始風格的同時保證完整性
糾錯過程。我們方法的核心組成部分是 RAG
基於我們的 ClinicalCorp 語料庫的管道。除其他知名來源外
包含臨床指南和訊息，我們預處理並發布
用於臨床 RAG 應用的開源 MedWiki 資料集。我們的成果
利用 ClinicalCorp 展示我們的 RAG 方法的核心作用
透過 MedReAct'N'MedReFlex 框架。並取得了第九名的好成績
MEDIQA-CORR 2024 年最終排行榜。

##### **Machine Learning Techniques with Fairness for Prediction of Completion of Drug and Alcohol Rehabilitation**
2404.15418v1 by Karen Roberts-Licklider et.al.

The aim of this study is to look at predicting whether a person will complete
a drug and alcohol rehabilitation program and the number of times a person
attends. The study is based on demographic data obtained from Substance Abuse
and Mental Health Services Administration (SAMHSA) from both admissions and
discharge data from drug and alcohol rehabilitation centers in Oklahoma.
Demographic data is highly categorical which led to binary encoding being used
and various fairness measures being utilized to mitigate bias of nine
demographic variables. Kernel methods such as linear, polynomial, sigmoid, and
radial basis functions were compared using support vector machines at various
parameter ranges to find the optimal values. These were then compared to
methods such as decision trees, random forests, and neural networks. Synthetic
Minority Oversampling Technique Nominal (SMOTEN) for categorical data was used
to balance the data with imputation for missing data. The nine bias variables
were then intersectionalized to mitigate bias and the dual and triple
interactions were integrated to use the probabilities to look at worst case
ratio fairness mitigation. Disparate Impact, Statistical Parity difference,
Conditional Statistical Parity Ratio, Demographic Parity, Demographic Parity
Ratio, Equalized Odds, Equalized Odds Ratio, Equal Opportunity, and Equalized
Opportunity Ratio were all explored at both the binary and multiclass
scenarios.

摘要：這項研究的目的是預測一個人是否會完成
戒毒和酗酒康復計劃以及一個人的次數
參加。該研究基於從藥物濫用獲得的人口統計數據
和心理健康服務管理局 (SAMHSA) 的招生和
來自俄克拉荷馬州戒毒和酒精康復中心的出院數據。
人口統計資料高度分類，導致使用二進位編碼
以及利用各種公平措施來減輕九個面向的偏見
人口統計變數。核方法，例如線性、多項式、Sigmoid 和
使用支援向量機在不同的條件下比較徑向基底函數
參數範圍以找到最佳值。然後將這些與
決策樹、隨機森林和神經網路等方法。合成的
使用針對分類資料的少數過採樣技術標稱 (SMOTEN)
透過缺失資料的插補來平衡資料。九個偏差變數
然後進行交叉化以減輕偏差以及雙重和三重
交互作用被整合起來，利用機率來看待最壞的情況
比率公平性緩解。不同的影響，統計奇偶差異，
有條件統計奇偶比、人口奇偶、人口奇偶
比率、均等賠率、均等賠率比、均等機會及均等
機會比均在二元和多類別中進行了探討
場景。

##### **CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios**
2404.15272v2 by Jingyang Lin et.al.

Medical Vision-Language Pretraining (Med-VLP) establishes a connection
between visual content from medical images and the relevant textual
descriptions. Existing Med-VLP methods primarily focus on 2D images depicting a
single body part, notably chest X-rays. In this paper, we extend the scope of
Med-VLP to encompass 3D images, specifically targeting full-body scenarios, by
using a multimodal dataset of CT images and reports. Compared with the 2D
counterpart, 3D VLP is required to effectively capture essential semantics from
significantly sparser representation in 3D imaging. In this paper, we introduce
CT-GLIP (Grounded Language-Image Pretraining with CT scans), a novel method
that constructs organ-level image-text pairs to enhance multimodal contrastive
learning, aligning grounded visual features with precise diagnostic text.
Additionally, we developed an abnormality dictionary to augment contrastive
learning with diverse contrastive pairs. Our method, trained on a multimodal CT
dataset comprising 44,011 organ-level vision-text pairs from 17,702 patients
across 104 organs, demonstrates it can identify organs and abnormalities in a
zero-shot manner using natural languages. The performance of CT-GLIP is
validated on a separate test set of 1,130 patients, focusing on the 16 most
frequent abnormalities across 7 organs. The experimental results show our
model's superior performance over the standard CLIP framework across zero-shot
and fine-tuning scenarios, using both CNN and ViT architectures.

摘要：醫學視覺語言預訓練 (Med-VLP) 建立聯繫
醫學影像的視覺內容與相關文字之間
描述。現有的 Med-VLP 方法主要著重於描繪
單一身體部位，特別是胸部 X 光檢查。在本文中，我們擴展了範圍
Med-VLP 涵蓋 3D 影像，特別針對全身場景，透過
使用 CT 影像和報告的多模態資料集。與二維相比
對應地，3D VLP 需要有效地捕捉來自
3D 成像中的表示顯著稀疏。在本文中，我們介紹
CT-GLIP（基於 CT 掃描的接地語言影像預訓練），一種新方法
建構器官級影像文字對以增強多模態對比
學習，將基礎視覺特徵與精確的診斷文本結合。
此外，我們開發了異常字典來增強對比
與不同的對比組一起學習。我們的方法經過多模態 CT 訓練
資料集包含 17,702 名患者的 44,011 個器官級視覺文本對
跨越 104 個器官，證明它可以識別器官和異常情況
使用自然語言的零樣本方式。 CT-GLIP的性能為
在 1,130 名患者的單獨測試集上進行了驗證，重點關注 16 名最重要的患者
7個器官經常出現異常。實驗結果顯示我們
模型在零樣本中優於標準 CLIP 框架的性能
並使用 CNN 和 ViT 架構微調場景。

##### **A review of deep learning-based information fusion techniques for multimodal medical image classification**
2404.15022v1 by Yihao Li et.al.

Multimodal medical imaging plays a pivotal role in clinical diagnosis and
research, as it combines information from various imaging modalities to provide
a more comprehensive understanding of the underlying pathology. Recently, deep
learning-based multimodal fusion techniques have emerged as powerful tools for
improving medical image classification. This review offers a thorough analysis
of the developments in deep learning-based multimodal fusion for medical
classification tasks. We explore the complementary relationships among
prevalent clinical modalities and outline three main fusion schemes for
multimodal classification networks: input fusion, intermediate fusion
(encompassing single-level fusion, hierarchical fusion, and attention-based
fusion), and output fusion. By evaluating the performance of these fusion
techniques, we provide insight into the suitability of different network
architectures for various multimodal fusion scenarios and application domains.
Furthermore, we delve into challenges related to network architecture
selection, handling incomplete multimodal data management, and the potential
limitations of multimodal fusion. Finally, we spotlight the promising future of
Transformer-based multimodal fusion techniques and give recommendations for
future research in this rapidly evolving field.

摘要：多模態醫學影像在臨床診斷和治療中發揮關鍵作用
研究，因為它結合了來自各種成像方式的資訊來提供
對潛在病理學有更全面的了解。最近，深
基於學習的多模態融合技術已成為強大的工具
改進醫學影像分類。這篇評論提供了全面的分析
基於深度學習的醫學多模態融合的發展
分類任務。我們探索之間的互補關係
流行的臨床模式並概述了三種主要的融合方案
多模態分類網路：輸入融合、中間融合
（包括單層融合、分層融合和基於注意力的融合
融合），並輸出融合。透過評估這些融合的性能
技術，我們提供對不同網路的適用性的深入了解
適用於各種多模態融合場景和應用領域的架構。
此外，我們深入研究與網路架構相關的挑戰
選擇、處理不完整的多模式資料管理以及潛力
多模態融合的限制。最後，我們展望了未來的光明前景
基於Transformer的多模態融合技術並給予建議
這個快速發展的領域的未來研究。

##### **Clustering of timed sequences -- Application to the analysis of care pathways**
2404.15379v1 by Thomas Guyet et.al.

Improving the future of healthcare starts by better understanding the current
actual practices in hospitals. This motivates the objective of discovering
typical care pathways from patient data. Revealing homogeneous groups of care
pathways can be achieved through clustering. The difficulty in clustering care
pathways, represented by sequences of timestamped events, lies in defining a
semantically appropriate metric and clustering algorithms.
  In this article, we adapt two methods developed for time series to time
sequences: the drop-DTW metric and the DBA approach for the construction of
averaged time sequences. These methods are then applied in clustering
algorithms to propose original and sound clustering algorithms for timed
sequences.
  This approach is experimented with and evaluated on synthetic and real use
cases.

摘要：改善醫療保健的未來首先要更了解當前的情況
醫院的實際操作。這激發了發現的目標
來自病患資料的典型照護途徑。揭示同質護理群體
路徑可以透過聚類來實現。集群護理的困難
由帶有時間戳記的事件序列所表示的路徑在於定義
語意上適當的度量和聚類演算法。
  在本文中，我們將兩種為時間序列所開發的方法應用於時間
序列：drop-DTW 度量和用於建構的 DBA 方法
平均時間序列。然後將這些方法應用於聚類
提出原始且合理的定時聚類演算法的演算法
序列。
  這種方法在合成和實際使用中進行了實驗和評估
案例。

##### **Grounded Knowledge-Enhanced Medical VLP for Chest X-Ray**
2404.14750v1 by Qiao Deng et.al.

Medical vision-language pre-training has emerged as a promising approach for
learning domain-general representations of medical image and text. Current
algorithms that exploit the global and local alignment between medical image
and text could however be marred by the redundant information in medical data.
To address this issue, we propose a grounded knowledge-enhanced medical
vision-language pre-training (GK-MVLP) framework for chest X-ray. In this
framework, medical knowledge is grounded to the appropriate anatomical regions
by using a transformer-based grounded knowledge-enhanced module for
fine-grained alignment between anatomical region-level visual features and the
textural features of medical knowledge. The performance of GK-MVLP is
competitive with or exceeds the state of the art on downstream chest X-ray
disease classification, disease localization, report generation, and medical
visual question-answering tasks. Our results show the advantage of
incorporating grounding mechanism to remove biases and improve the alignment
between chest X-ray image and radiology report.

摘要：醫學視覺語言預訓練已成為一種有前途的方法
學習醫學影像和文字的領域通用表示。目前的
利用醫學影像之間的全局和局部對齊的演算法
然而，文字可能會因醫療資料中的冗餘資訊而受到損害。
為了解決這個問題，我們提出了一種紮根的知識增強醫學
胸部 X 光視覺語言預訓練 (GK-MVLP) 框架。在這個
框架中，醫學知識植根於適當的解剖區域
透過使用基於變壓器的接地知識增強模組
解剖區域級視覺特徵和
醫學知識的結構特徵。 GK-MVLP的性能為
在下游胸部 X 光檢查方面具有競爭力或超過現有技術水平
疾病分類、疾病定位、報告產生、醫療
視覺問答任務。我們的結果顯示了以下優勢
結合接地機制以消除偏差並改善對準
胸部 X 光影像和放射學報告之間的關係。

##### **DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic Depression Detection from Clinical Interviews**
2404.14463v1 by Sergio Burdisso et.al.

Automatic depression detection from conversational data has gained
significant interest in recent years. The DAIC-WOZ dataset, interviews
conducted by a human-controlled virtual agent, has been widely used for this
task. Recent studies have reported enhanced performance when incorporating
interviewer's prompts into the model. In this work, we hypothesize that this
improvement might be mainly due to a bias present in these prompts, rather than
the proposed architectures and methods. Through ablation experiments and
qualitative analysis, we discover that models using interviewer's prompts learn
to focus on a specific region of the interviews, where questions about past
experiences with mental health issues are asked, and use them as discriminative
shortcuts to detect depressed participants. In contrast, models using
participant responses gather evidence from across the entire interview.
Finally, to highlight the magnitude of this bias, we achieve a 0.90 F1 score by
intentionally exploiting it, the highest result reported to date on this
dataset using only textual information. Our findings underline the need for
caution when incorporating interviewers' prompts into models, as they may
inadvertently learn to exploit targeted prompts, rather than learning to
characterize the language and behavior that are genuinely indicative of the
patient's mental health condition.

摘要：從對話數據中自動檢測憂鬱症已經取得了進展
近年來產生了重大興趣。 DAIC-WOZ 資料集，訪談
由人類控制的虛擬代理進行，已被廣泛用於此
任務。最近的研究報告稱，合併後性能提高
面試官的提示進入模型。在這項工作中，我們假設這
改進可能主要是由於這些提示中存在的偏見，而不是
所提出的架構和方法。透過消融實驗和
定性分析，我們發現模型使用訪談者的提示進行學習
重點關注訪談的特定區域，其中涉及過去的問題
詢問心理健康問題的經歷，並將其用作歧視性的
檢測抑鬱參與者的捷徑。相反，模型使用
參與者的回答從整個訪談中收集證據。
最後，為了強調這種偏差的嚴重程度，我們透過以下方式獲得了 0.90 F1 分數：
有意利用它，迄今為止報告的最高結果
僅使用文字資訊的資料集。我們的研究結果強調需要
將訪談員的提示納入模型時要小心，因為它們可能會
無意中學會利用有針對性的提示，而不是學會
描述真正代表的語言和行為
患者的心理健康狀況。

##### **Adaptive Collaboration Strategy for LLMs in Medical Decision Making**
2404.15155v1 by Yubin Kim et.al.

Foundation models have become invaluable in advancing the medical field.
Despite their promise, the strategic deployment of LLMs for effective utility
in complex medical tasks remains an open question. Our novel framework, Medical
Decision-making Agents (MDAgents) aims to address this gap by automatically
assigning the effective collaboration structure for LLMs. Assigned solo or
group collaboration structure is tailored to the complexity of the medical task
at hand, emulating real-world medical decision making processes. We evaluate
our framework and baseline methods with state-of-the-art LLMs across a suite of
challenging medical benchmarks: MedQA, MedMCQA, PubMedQA, DDXPlus, PMC-VQA,
Path-VQA, and MedVidQA, achieving the best performance in 5 out of 7 benchmarks
that require an understanding of multi-modal medical reasoning. Ablation
studies reveal that MDAgents excels in adapting the number of collaborating
agents to optimize efficiency and accuracy, showcasing its robustness in
diverse scenarios. We also explore the dynamics of group consensus, offering
insights into how collaborative agents could behave in complex clinical team
dynamics. Our code can be found at https://github.com/mitmedialab/MDAgents.

摘要：基礎模型對於推動醫學領域的發展具有無價的價值。
儘管他們做出了承諾，但為了有效利用法學碩士的策略部署
在複雜的醫療任務中的應用仍然是一個懸而未決的問題。我們的新穎框架，醫療
決策代理 (MDAgents) 旨在透過自動解決這一差距
為法學碩士分配有效的合作結構。指定獨奏或
小組協作結構根據醫療任務的複雜性量身定制
模擬現實世界的醫療決策過程。我們評估
我們的框架和基線方法以及跨一系列最先進的法學碩士
具挑戰性的醫療基準：MedQA、MedMCQA、PubMedQA、DDXPlus、PMC-VQA、
Path-VQA 和 MedVidQA，在 7 個基準測試中的 5 個中取得最佳效能
這需要了解多模式醫學推理。消融
研究表明，MDAgents 在調整協作數量方面表現出色
代理優化效率和準確性，展現其穩健性
多樣化的場景。我們也探索團體共識的動態，提供
深入了解協作代理如何在複雜的臨床團隊中表現
動力學。我們的程式碼可以在 https://github.com/mitmedialab/MDAgents 找到。

##### **A Nasal Cytology Dataset for Object Detection and Deep Learning**
2404.13745v1 by Mauro Camporeale et.al.

Nasal Cytology is a new and efficient clinical technique to diagnose rhinitis
and allergies that is not much widespread due to the time-consuming nature of
cell counting; that is why AI-aided counting could be a turning point for the
diffusion of this technique. In this article we present the first dataset of
rhino-cytological field images: the NCD (Nasal Cytology Dataset), aimed to
train and deploy Object Detection models to support physicians and biologists
during clinical practice. The real distribution of the cytotypes, populating
the nasal mucosa has been replicated, sampling images from slides of clinical
patients, and manually annotating each cell found on them. The correspondent
object detection task presents non'trivial issues associated with the strong
class imbalancement, involving the rarest cell types. This work contributes to
some of open challenges by presenting a novel machine learning-based approach
to aid the automated detection and classification of nasal mucosa cells: the
DETR and YOLO models shown good performance in detecting cells and classifying
them correctly, revealing great potential to accelerate the work of rhinology
experts.

摘要：鼻細胞學是診斷鼻炎的一種新的、有效的臨床技術
以及由於耗時的性質而不太普遍的過敏
細胞計數；這就是為什麼人工智慧輔助計數可能是一個轉捩點
這項技術的傳播。在本文中，我們展示了第一個資料集
鼻細胞學領域影像：NCD（鼻細胞學資料集），旨在
訓練和部署物件檢測模型來支援醫生和生物學家
在臨床實務過程中。細胞類型的真實分佈，填充
鼻黏膜已被複製，從臨床幻燈片中採樣影像
患者，並手動註釋在他們身上發現的每個細胞。通訊員
物體偵測任務提出了與強相關的重要問題
類別不平衡，涉及最稀有的細胞類型。這項工作有助於
透過提出一種新穎的基於機器學習的方法來應對一些開放的挑戰
幫助鼻粘膜細胞的自動檢測和分類：
DETR和YOLO模型在檢測細胞和分類方面表現出良好的性能
正確地揭示了加速鼻科學工作的巨大潛力
專家。

##### **Bt-GAN: Generating Fair Synthetic Healthdata via Bias-transforming Generative Adversarial Networks**
2404.13634v3 by Resmi Ramachandranpillai et.al.

Synthetic data generation offers a promising solution to enhance the
usefulness of Electronic Healthcare Records (EHR) by generating realistic
de-identified data. However, the existing literature primarily focuses on the
quality of synthetic health data, neglecting the crucial aspect of fairness in
downstream predictions. Consequently, models trained on synthetic EHR have
faced criticism for producing biased outcomes in target tasks. These biases can
arise from either spurious correlations between features or the failure of
models to accurately represent sub-groups. To address these concerns, we
present Bias-transforming Generative Adversarial Networks (Bt-GAN), a GAN-based
synthetic data generator specifically designed for the healthcare domain. In
order to tackle spurious correlations (i), we propose an
information-constrained Data Generation Process that enables the generator to
learn a fair deterministic transformation based on a well-defined notion of
algorithmic fairness. To overcome the challenge of capturing exact sub-group
representations (ii), we incentivize the generator to preserve sub-group
densities through score-based weighted sampling. This approach compels the
generator to learn from underrepresented regions of the data manifold. We
conduct extensive experiments using the MIMIC-III database. Our results
demonstrate that Bt-GAN achieves SOTA accuracy while significantly improving
fairness and minimizing bias amplification. We also perform an in-depth
explainability analysis to provide additional evidence supporting the validity
of our study. In conclusion, our research introduces a novel and professional
approach to addressing the limitations of synthetic data generation in the
healthcare domain. By incorporating fairness considerations and leveraging
advanced techniques such as GANs, we pave the way for more reliable and
unbiased predictions in healthcare applications.

摘要：綜合數據生成提供了一個有前途的解決方案來增強
透過產生現實的電子醫療記錄（EHR）的有用性
去識別化數據。然而，現有文獻主要集中於
綜合健康數據的質量，忽略了公平性的關鍵方面
下游預測。因此，經過合成 EHR 訓練的模型已經
因在目標任務中產生偏差的結果而受到批評。這些偏見可以
源自於特徵之間的虛假相關性或失敗
模型來準確地表示子組。為了解決這些問題，我們
提出偏差轉換生成對抗網路（Bt-GAN），一種基於 GAN 的
專為醫療保健領域設計的合成資料產生器。在
為了解決虛假相關性 (i)，我們提出了
資訊受限的資料生成過程，使生成器能夠
學習基於明確定義的概念的公平確定性轉換
算法公平性。克服捕獲精確子組的挑戰
表示 (ii)，我們激勵生成器保留子組
透過基於分數的加權採樣來計算密度。這種方法迫使
生成器從資料流形的代表性不足的區域中學習。我們
使用 MIMIC-III 資料庫進行廣泛的實驗。我們的成果
證明 Bt-GAN 實現了 SOTA 精度，同時顯著提高了
公平性並最大限度地減少偏差放大。我們還進行了深入的
可解釋性分析以提供支持有效性的額外證據
我們的研究。總之，我們的研究引進了一種新穎且專業的方法
解決合成資料生成限制的方法
醫療保健領域。透過納入公平考量並利用
GAN 等先進技術，為更可靠、更可靠的技術鋪平了道路
醫療保健應用中的公正預測。

##### **SmartMem: Layout Transformation Elimination and Adaptation for Efficient DNN Execution on Mobile**
2404.13528v1 by Wei Niu et.al.

This work is motivated by recent developments in Deep Neural Networks,
particularly the Transformer architectures underlying applications such as
ChatGPT, and the need for performing inference on mobile devices. Focusing on
emerging transformers (specifically the ones with computationally efficient
Swin-like architectures) and large models (e.g., Stable Diffusion and LLMs)
based on transformers, we observe that layout transformations between the
computational operators cause a significant slowdown in these applications.
This paper presents SmartMem, a comprehensive framework for eliminating most
layout transformations, with the idea that multiple operators can use the same
tensor layout through careful choice of layout and implementation of
operations. Our approach is based on classifying the operators into four
groups, and considering combinations of producer-consumer edges between the
operators. We develop a set of methods for searching such layouts. Another
component of our work is developing efficient memory layouts for 2.5
dimensional memory commonly seen in mobile devices. Our experimental results
show that SmartMem outperforms 5 state-of-the-art DNN execution frameworks on
mobile devices across 18 varied neural networks, including CNNs, Transformers
with both local and global attention, as well as LLMs. In particular, compared
to DNNFusion, SmartMem achieves an average speedup of 2.8$\times$, and
outperforms TVM and MNN with speedups of 6.9$\times$ and 7.9$\times$,
respectively, on average.

摘要：這項工作的動機是深度神經網路的最新發展，
特別是底層應用程式的 Transformer 架構，例如
ChatGPT，以及在行動裝置上執行推理的需要。專注於
新興的變壓器（特別是那些具有計算效率的變壓器）
Swin 式架構）和大型模型（例如穩定擴散和法學碩士）
基於變壓器，我們觀察到佈局之間的轉換
計算運算子會導致這些應用程式顯著變慢。
本文介紹了 SmartMem，這是一個用於消除大多數
佈局轉換，其想法是多個操作員可以使用相同的
張量佈局透過仔細選擇佈局和實現
營運.我們的方法是基於將營運商分為四類
群體，並考慮生產者-消費者之間的邊緣組合
運營商。我們開發了一套用於搜尋此類佈局的方法。其他
我們工作的一部分是為 2.5 開發高效的記憶體佈局
行動裝置中常見的維度記憶體。我們的實驗結果
顯示 SmartMem 在以下方面優於 5 個最先進的 DNN 執行框架
跨 18 個不同神經網路的行動設備，包括 CNN、Transformers
受到當地和全球的關注，以及法學碩士。特別是相比
相對於 DNNFusion，SmartMem 的平均加速比為 2.8$\times$，且
性能優於 TVM 和 MNN，加速分別為 6.9$\times$ 和 7.9$\times$，
分別為平均。

##### **Parameter Efficient Fine Tuning: A Comprehensive Analysis Across Applications**
2404.13506v2 by Charith Chandra Sai Balne et.al.

The rise of deep learning has marked significant progress in fields such as
computer vision, natural language processing, and medical imaging, primarily
through the adaptation of pre-trained models for specific tasks. Traditional
fine-tuning methods, involving adjustments to all parameters, face challenges
due to high computational and memory demands. This has led to the development
of Parameter Efficient Fine-Tuning (PEFT) techniques, which selectively update
parameters to balance computational efficiency with performance. This review
examines PEFT approaches, offering a detailed comparison of various strategies
highlighting applications across different domains, including text generation,
medical imaging, protein modeling, and speech synthesis. By assessing the
effectiveness of PEFT methods in reducing computational load, speeding up
training, and lowering memory usage, this paper contributes to making deep
learning more accessible and adaptable, facilitating its wider application and
encouraging innovation in model optimization. Ultimately, the paper aims to
contribute towards insights into PEFT's evolving landscape, guiding researchers
and practitioners in overcoming the limitations of conventional fine-tuning
approaches.

摘要：深度學習的興起標誌著以下領域取得了重大進展
主要是電腦視覺、自然語言處理和醫學成像
透過針對特定任務調整預先訓練的模型。傳統的
微調方法，涉及所有參數的調整，面臨挑戰
由於高計算和記憶體需求。這導致了發展
參數高效微調（PEFT）技術，選擇性更新
平衡計算效率與性能的參數。這篇評論
檢查 PEFT 方法，提供各種策略的詳細比較
強調跨不同領域的應用程序，包括文字生成，
醫學影像、蛋白質建模和語音合成。透過評估
PEFT 方法在減少計算負載、加速方面的有效性
訓練，並降低記憶體使用，本文有助於深度學習
學習更容易獲得和適應性更強，促進其更廣泛的應用和
鼓勵模型優化創新。最終，本文旨在
有助於深入了解 PEFT 不斷發展的格局，指導研究人員
和實踐者克服傳統微調的局限性
接近。

##### **SiNC+: Adaptive Camera-Based Vitals with Unsupervised Learning of Periodic Signals**
2404.13449v1 by Jeremy Speth et.al.

Subtle periodic signals, such as blood volume pulse and respiration, can be
extracted from RGB video, enabling noncontact health monitoring at low cost.
Advancements in remote pulse estimation -- or remote photoplethysmography
(rPPG) -- are currently driven by deep learning solutions. However, modern
approaches are trained and evaluated on benchmark datasets with ground truth
from contact-PPG sensors. We present the first non-contrastive unsupervised
learning framework for signal regression to mitigate the need for labelled
video data. With minimal assumptions of periodicity and finite bandwidth, our
approach discovers the blood volume pulse directly from unlabelled videos. We
find that encouraging sparse power spectra within normal physiological
bandlimits and variance over batches of power spectra is sufficient for
learning visual features of periodic signals. We perform the first experiments
utilizing unlabelled video data not specifically created for rPPG to train
robust pulse rate estimators. Given the limited inductive biases, we
successfully applied the same approach to camera-based respiration by changing
the bandlimits of the target signal. This shows that the approach is general
enough for unsupervised learning of bandlimited quasi-periodic signals from
different domains. Furthermore, we show that the framework is effective for
finetuning models on unlabelled video from a single subject, allowing for
personalized and adaptive signal regressors.

摘要：微妙的周期性訊號，例如血液容量、脈搏和呼吸，可以被
從 RGB 影片中擷取，以低成本實現非接觸式健康監測。
遠程脈衝估計或遠程光電體積描記法的進展
(rPPG)－目前由深度學習解決方案驅動。然而，現代
方法在具有基本事實的基準資料集上進行訓練和評估
來自接觸式 PPG 感測器。我們提出了第一個非對比無監督
訊號迴歸的學習框架，以減輕標記的需要
視訊數據。在週期性和有限頻寬的最小假設下，我們的
方法直接從未標記的影片中發現血量脈衝。我們
發現在正常生理範圍內鼓勵稀疏功率譜
功率譜批次的帶限和方差足以
學習週期性訊號的視覺特徵。我們進行第一個實驗
利用並非專為 rPPG 創建的未標記視訊資料進行訓練
強大的脈搏率估計器。鑑於有限的歸納偏差，我們
透過改變，成功地將相同的方法應用於基於相機的呼吸
目標訊號的頻寬限制。這表明該方法具有通用性
足以進行有限準週期訊號的無監督學習
不同的域。此外，我們表明該框架對於
對來自單一主題的未標記影片進行微調模型，允許
個性化和自適應訊號回歸器。

##### **MultiConfederated Learning: Inclusive Non-IID Data handling with Decentralized Federated Learning**
2404.13421v1 by Michael Duchesne et.al.

Federated Learning (FL) has emerged as a prominent privacy-preserving
technique for enabling use cases like confidential clinical machine learning.
FL operates by aggregating models trained by remote devices which owns the
data. Thus, FL enables the training of powerful global models using
crowd-sourced data from a large number of learners, without compromising their
privacy. However, the aggregating server is a single point of failure when
generating the global model. Moreover, the performance of the model suffers
when the data is not independent and identically distributed (non-IID data) on
all remote devices. This leads to vastly different models being aggregated,
which can reduce the performance by as much as 50% in certain scenarios.
  In this paper, we seek to address the aforementioned issues while retaining
the benefits of FL. We propose MultiConfederated Learning: a decentralized FL
framework which is designed to handle non-IID data. Unlike traditional FL,
MultiConfederated Learning will maintain multiple models in parallel (instead
of a single global model) to help with convergence when the data is non-IID.
With the help of transfer learning, learners can converge to fewer models. In
order to increase adaptability, learners are allowed to choose which updates to
aggregate from their peers.

摘要：聯邦學習（FL）已成為一種突出的隱私保護方法
用於啟用機密臨床機器學習等用例的技術。
FL 透過聚合由遠端設備訓練的模型來運行，該遠端設備擁有
數據。因此，FL 能夠使用以下方法訓練強大的全局模型：
來自大量學習者的眾包數據，而不影響他們的學習
隱私。但是，聚合伺服器在以下情況下會出現單點故障：
產生全域模型。此外，模型的性能也會受到影響
當資料不是獨立同分佈（非 IID 資料）時
所有遠端設備。這導致了截然不同的模型被聚合，
在某些情況下，這可能會導致效能降低多達 50%。
  在本文中，我們尋求解決上述問題，同時保留
FL 的好處。我們提出 MultiConfederated Learning：去中心化的 FL
旨在處理非獨立同分佈資料的框架。與傳統的FL不同，
多聯合學習將並行維護多個模型（而不是
單一全域模型），以幫助資料非獨立同分佈時的收斂。
在遷移學習的幫助下，學習者可以收斂到更少的模型。在
為了提高適應性，學習者可以選擇要更新的內容
來自同行的總結。

##### **UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty and Response Time for Multiple-Choice Questions**
2404.13343v1 by Ana-Cristina Rogoz et.al.

This work explores a novel data augmentation method based on Large Language
Models (LLMs) for predicting item difficulty and response time of retired USMLE
Multiple-Choice Questions (MCQs) in the BEA 2024 Shared Task. Our approach is
based on augmenting the dataset with answers from zero-shot LLMs (Falcon,
Meditron, Mistral) and employing transformer-based models based on six
alternative feature combinations. The results suggest that predicting the
difficulty of questions is more challenging. Notably, our top performing
methods consistently include the question text, and benefit from the
variability of LLM answers, highlighting the potential of LLMs for improving
automated assessment in medical licensing exams. We make our code available
https://github.com/ana-rogoz/BEA-2024.

摘要：這項工作探索了一種基於大語言的新型資料增強方法
用於預測退役 USMLE 專案難度和回應時間的模型 (LLM)
BEA 2024 共享任務中的多項選擇題 (MCQ)。我們的方法是
基於使用零樣本法學碩士（Falcon、
Meditron、Mistral）並採用基於變壓器的模型，該模型基於六個
替代功能組合。結果表明，預測
題目難度更具挑戰性。值得注意的是，我們表現得最好的
方法始終包含問題文本，並受益於
法學碩士答案的可變性，突顯了法學碩士提高水平的潛力
醫療執照考試的自動評估。我們提供我們的程式碼
https://github.com/ana-rogoz/BEA-2024。

##### **Practical Battery Health Monitoring using Uncertainty-Aware Bayesian Neural Network**
2404.14444v1 by Yunyi Zhao et.al.

Battery health monitoring and prediction are critically important in the era
of electric mobility with a huge impact on safety, sustainability, and economic
aspects. Existing research often focuses on prediction accuracy but tends to
neglect practical factors that may hinder the technology's deployment in
real-world applications. In this paper, we address these practical
considerations and develop models based on the Bayesian neural network for
predicting battery end-of-life. Our models use sensor data related to battery
health and apply distributions, rather than single-point, for each parameter of
the models. This allows the models to capture the inherent randomness and
uncertainty of battery health, which leads to not only accurate predictions but
also quantifiable uncertainty. We conducted an experimental study and
demonstrated the effectiveness of our proposed models, with a prediction error
rate averaging 13.9%, and as low as 2.9% for certain tested batteries.
Additionally, all predictions include quantifiable certainty, which improved by
66% from the initial to the mid-life stage of the battery. This research has
practical values for battery technologies and contributes to accelerating the
technology adoption in the industry.

摘要：電池健康監測和預測在這個時代至關重要
電動車對安全性、永續性和經濟性產生巨大影響
方面。現有的研究通常關注預測準確性，但傾向於
忽視可能阻礙該技術部署的實際因素
現實世界的應用程式。在本文中，我們解決了這些實際問題
考慮因素並開發基於貝葉斯神經網路的模型
預測電池壽命終止。我們的模型使用與電池相關的感測器數據
health 並對每個參數套用分佈，而不是單點
模型。這使得模型能夠捕捉到固有的隨機性並
電池健康狀況的不確定性，這不僅導致準確的預測，而且
還有可量化的不確定性。我們進行了一項實驗研究並
證明了我們提出的模型的有效性，但存在預測誤差
速率平均為 13.9%，某些測試電池的速率低至 2.9%。
此外，所有預測都包含可量化的確定性，其改善程度為
66%從電池的初始壽命到中期壽命階段。這項研究有
電池技術的實用價值，有助於加速
業界技術的採用。

##### **Beyond Self-Consistency: Ensemble Reasoning Boosts Consistency and Accuracy of LLMs in Cancer Staging**
2404.13149v1 by Chia-Hsuan Chang et.al.

Advances in large language models (LLMs) have encouraged their adoption in
the healthcare domain where vital clinical information is often contained in
unstructured notes. Cancer staging status is available in clinical reports, but
it requires natural language processing to extract the status from the
unstructured text. With the advance in clinical-oriented LLMs, it is promising
to extract such status without extensive efforts in training the algorithms.
Prompting approaches of the pre-trained LLMs that elicit a model's reasoning
process, such as chain-of-thought, may help to improve the trustworthiness of
the generated responses. Using self-consistency further improves model
performance, but often results in inconsistent generations across the multiple
reasoning paths. In this study, we propose an ensemble reasoning approach with
the aim of improving the consistency of the model generations. Using an open
access clinical large language model to determine the pathologic cancer stage
from real-world pathology reports, we show that the ensemble reasoning approach
is able to improve both the consistency and performance of the LLM in
determining cancer stage, thereby demonstrating the potential to use these
models in clinical or other domains where reliability and trustworthiness are
critical.

摘要：大語言模型（LLM）的進步鼓勵了它們在以下領域的採用：
通常包含重要臨床資訊的醫療保健領域
非結構化筆記。癌症分期狀態可在臨床報告中找到，但是
它需要自然語言處理來提取狀態
非結構化文字。隨著臨床導向的法學碩士的進步，它是有前途的
無需大量努力訓練演算法即可提取這種狀態。
預先訓練的法學碩士引發模型推理的提示方法
流程，例如思想鏈，可能有助於提高信任度
產生的響應。使用自一致性進一步改進模型
性能，但通常會導致多個世代之間的不一致
推理路徑。在這項研究中，我們提出了一種整合推理方法
目的是提高模型生成的一致性。使用開放式
訪問臨床大語言模型以確定病理癌症階段
從現實世界的病理報告中，我們表明整合推理方法
能夠提高法學碩士的一致性和表現
確定癌症階段，從而證明使用這些的潛力
可靠性和可信度較高的臨床或其他領域的模型
批判的。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang et.al.

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測為醫療保健專業人員提供支持
建模，大大改變了臨床決策。本研究解決
人工智慧應用程式對公平性和可解釋性的迫切需求
醫療保健，以確保不同患者群體的公平結果。經過
專注於敗血症相關死亡率的預測模型，我們提出了
學習性能優化的預測模型然後採用的方法
遷移學習過程以產生具有更好公平性的模型。我們的
該方法還引入了一種新穎的基於排列的特徵重要性演算法
旨在闡明每個特徵對增強公平性的貢獻
預測。與現有的可解釋性方法專注於解釋不同
特徵對預測表現的貢獻，我們提出的方法是獨一無二的
彌合了理解每個功能如何促進公平性的差距。這
鑑於敗血症的顯著死亡率及其作用，進展至關重要
佔醫院死亡人數的三分之一。我們的方法不僅有助於識別和
減少預測模型中的偏差，同時也促進了人們之間的信任
透過提高模型的透明度和公平性來影響醫療保健利益相關者
預測，從而有助於更公平和值得信賴的醫療保健
送貨。

##### **Eye-tracking in Mixed Reality for Diagnosis of Neurodegenerative Diseases**
2404.12984v1 by Mateusz Daniol et.al.

Parkinson's disease ranks as the second most prevalent neurodegenerative
disorder globally. This research aims to develop a system leveraging Mixed
Reality capabilities for tracking and assessing eye movements. In this paper,
we present a medical scenario and outline the development of an application
designed to capture eye-tracking signals through Mixed Reality technology for
the evaluation of neurodegenerative diseases. Additionally, we introduce a
pipeline for extracting clinically relevant features from eye-gaze analysis,
describing the capabilities of the proposed system from a medical perspective.
The study involved a cohort of healthy control individuals and patients
suffering from Parkinson's disease, showcasing the feasibility and potential of
the proposed technology for non-intrusive monitoring of eye movement patterns
for the diagnosis of neurodegenerative diseases.
  Clinical relevance - Developing a non-invasive biomarker for Parkinson's
disease is urgently needed to accurately detect the disease's onset. This would
allow for the timely introduction of neuroprotective treatment at the earliest
stage and enable the continuous monitoring of intervention outcomes. The
ability to detect subtle changes in eye movements allows for early diagnosis,
offering a critical window for intervention before more pronounced symptoms
emerge. Eye tracking provides objective and quantifiable biomarkers, ensuring
reliable assessments of disease progression and cognitive function. The eye
gaze analysis using Mixed Reality glasses is wireless, facilitating convenient
assessments in both home and hospital settings. The approach offers the
advantage of utilizing hardware that requires no additional specialized
attachments, enabling examinations through personal eyewear.

摘要：帕金森氏症是第二常見的神經退化性疾病
全球混亂。本研究旨在開發一個利用混合的系統
追蹤和評估眼球運動的現實能力。在本文中，
我們提出一個醫療場景並概述應用程式的開發
旨在透過混合現實技術捕捉眼球追蹤訊號
神經退化性疾病的評估。此外，我們還引進了一個
用於從眼睛注視分析中提取臨床相關特徵的管道，
從醫學角度描述所提議系統的功能。
該研究涉及一組健康對照個體和患者
患有帕金森氏症，展示了可行性和潛力
建議的眼球運動模式非侵入式監測技術
用於神經退化性疾病的診斷。
  臨床相關性 - 開發帕金森氏症的非侵入性生物標記
迫切需要準確檢測疾病的發生。這個會
以便儘早及時採取神經保護治療
階段並能持續監測介入結果。這
檢測眼球運動的細微變化的能力可以進行早期診斷，
在出現更明顯的症狀之前提供一個關鍵的干預窗口
出現。眼動追蹤提供客觀且可量化的生物標記物，確保
對疾病進展和認知功能的可靠評估。眼
使用混合實境眼鏡進行無線視線分析，方便快捷
在家庭和醫院環境中進行評估。該方法提供了
利用不需要額外專門的硬體的優點
附件，可透過個人眼鏡進行檢查。

##### **A Large-scale Medical Visual Task Adaptation Benchmark**
2404.12876v1 by Shentong Mo et.al.

Visual task adaptation has been demonstrated to be effective in adapting
pre-trained Vision Transformers (ViTs) to general downstream visual tasks using
specialized learnable layers or tokens. However, there is yet a large-scale
benchmark to fully explore the effect of visual task adaptation on the
realistic and important medical domain, particularly across diverse medical
visual modalities, such as color images, X-ray, and CT. To close this gap, we
present Med-VTAB, a large-scale Medical Visual Task Adaptation Benchmark
consisting of 1.68 million medical images for diverse organs, modalities, and
adaptation approaches. Based on Med-VTAB, we explore the scaling law of medical
prompt tuning concerning tunable parameters and the generalizability of medical
visual adaptation using non-medical/medical pre-train weights. Besides, we
study the impact of patient ID out-of-distribution on medical visual
adaptation, which is a real and challenging scenario. Furthermore, results from
Med-VTAB indicate that a single pre-trained model falls short in medical task
adaptation. Therefore, we introduce GMoE-Adapter, a novel method that combines
medical and general pre-training weights through a gated mixture-of-experts
adapter, achieving state-of-the-art results in medical visual task adaptation.

摘要：視覺任務適應已被證明可以有效地適應
使用預先訓練的視覺變換器（ViT）來執行一般下游視覺任務
專門的可學習層或令牌。但目前還存在大規模的
充分探討視覺任務適應對視覺任務適應的影響
現實且重要的醫學領域，特別是跨不同的醫學領域
視覺方式，例如彩色影像、X 光和 CT。為了縮小這一差距，我們
提出 Med-VTAB，一個大規模的醫學視覺任務適應基準
由 168 萬張不同器官、模式和領域的醫學影像組成
適應方法。基於Med-VTAB，我們探討醫學的量表規律
及時調整可調參數和醫療的普遍性
使用非醫學/醫學預訓練權重進行視覺適應。除此之外，我們
研究病患 ID 分佈不均對醫學視覺的影響
適應，這是一個真實且具有挑戰性的場景。此外，結果來自
Med-VTAB 顯示單一預訓練模型在醫療任務中存在不足
適應。因此，我們引入了 GMoE-Adapter，一種結合了
透過專家組合進行醫療和一般預訓練重量
適配器，在醫學視覺任務適應方面取得了最先進的成果。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat et.al.

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：憂鬱症是當今的重要議題。根據世界衛生組織
世界衛生組織 (WHO) 預計，到 2023 年，將有超過 2.8 億人面臨
沮喪。這是一個龐大的數字；如果不認真對待，這些數字將
迅速增加。大約有 48.9 億人是社群媒體用戶。人們
在 Twitter、Facebook 等平台上表達自己的感受和情緒，
Reddit、Instagram 等。
用於研究目的。已經進行了大量的研究
各種社群媒體平台。然而，這些技術仍存在一定的局限性
努力。特別是，先前的研究僅集中於檢測
憂鬱症以及推文中憂鬱症的強度。另外，還存在
資料集標籤不準確。在這項研究工作中，有五種類型
預測憂鬱症（躁鬱症、重度憂鬱、精神病性憂鬱、非典型憂鬱和產後憂鬱）
使用基於字典標籤的 Twitter 資料庫中的推文。可解釋的
人工智慧透過突出顯示推文中的某些部分來提供推理
代表憂鬱症的類型。雙向編碼器表示
Transformers (BERT) 用於特徵提取和訓練。機器
使用學習和深度學習方法來訓練模型。伯特
模型呈現了最有希望的結果，整體精度達到
0.96。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v1 by Dmytro Shvetsov et.al.

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度學習正在大幅改變醫學影像領域
放射學，能夠辨識醫學影像中的病理，
包括電腦斷層掃描 (CT) 和 X 光掃描。然而，性能
深度學習模型，特別是在分割任務中，通常受到以下限制：
需要大量帶註釋的資料集。為了應對這項挑戰，
透過以下方式探討弱監督語意分割的能力
可解釋人工智慧的鏡頭和反事實解釋的生成。
這項研究的範圍是開發一種新穎的反事實修復
方法（COIN）將預測的分類標籤從異常翻轉為
使用生成模型正常。例如，如果分類器認為
輸入醫學影像X為異常，表示存在病理，
生成模型旨在修復異常區域，從而逆轉
分類器的原始預測標籤。該方法使我們能夠生產
精確的病理分割，而不依賴預先存在的
分割掩模。至關重要的是，利用了圖像級標籤，它們是
比建立詳細的分割遮罩更容易取得。這
此方法的有效性透過分割合成目標來證明
來自塔爾圖大學醫院的 CT 影像中的實際腎臟腫瘤
愛沙尼亞。研究結果表明，COIN 大大超越了既定標準
歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及
Singla 等人提出的替代反事實解釋方法。這
證據顯示 COIN 是一種有前途的語意分割方法
CT 影像中的腫瘤，並在深度學習方面向前邁進了一步
在醫療保健領域，應用程式更容易存取和更有效，其中帶有註釋的數據
是稀缺的。

##### **DensePANet: An improved generative adversarial network for photoacoustic tomography image reconstruction from sparse data**
2404.13101v1 by Hesam Hakimnejad et.al.

Image reconstruction is an essential step of every medical imaging method,
including Photoacoustic Tomography (PAT), which is a promising modality of
imaging, that unites the benefits of both ultrasound and optical imaging
methods. Reconstruction of PAT images using conventional methods results in
rough artifacts, especially when applied directly to sparse PAT data. In recent
years, generative adversarial networks (GANs) have shown a powerful performance
in image generation as well as translation, rendering them a smart choice to be
applied to reconstruction tasks. In this study, we proposed an end-to-end
method called DensePANet to solve the problem of PAT image reconstruction from
sparse data. The proposed model employs a novel modification of UNet in its
generator, called FD-UNet++, which considerably improves the reconstruction
performance. We evaluated the method on various in-vivo and simulated datasets.
Quantitative and qualitative results show the better performance of our model
over other prevalent deep learning techniques.

摘要：影像重建是每種醫學影像方法的重要步驟，
包括光聲斷層掃描（PAT），這是一種很有前途的方法
成像，結合了超音波和光學成像的優點
方法。使用傳統方法重建 PAT 影像的結果是
粗糙的偽影，尤其是直接應用於稀疏 PAT 資料時。在最近
近年來，生成對抗網路（GAN）展現出了強大的效能
在圖像生成和翻譯方面，使它們成為明智的選擇
應用於重建任務。在這項研究中，我們提出了一種端到端的
稱為 DensePANet 的方法解決了 PAT 影像重建問題
稀疏資料。所提出的模型採用了 UNet 的新穎修改
稱為 FD-UNet++ 的生成器，可顯著改善重建
表現。我們在各種體內和模擬資料集上評估了該方法。
定量和定性結果表明我們的模型具有更好的性能
優於其他流行的深度學習技術。

##### **Transformer-Based Classification Outcome Prediction for Multimodal Stroke Treatment**
2404.12634v1 by Danqing Ma et.al.

This study proposes a multi-modal fusion framework Multitrans based on the
Transformer architecture and self-attention mechanism. This architecture
combines the study of non-contrast computed tomography (NCCT) images and
discharge diagnosis reports of patients undergoing stroke treatment, using a
variety of methods based on Transformer architecture approach to predicting
functional outcomes of stroke treatment. The results show that the performance
of single-modal text classification is significantly better than single-modal
image classification, but the effect of multi-modal combination is better than
any single modality. Although the Transformer model only performs worse on
imaging data, when combined with clinical meta-diagnostic information, both can
learn better complementary information and make good contributions to
accurately predicting stroke treatment effects..

摘要：本研究提出了一個基於多模態融合架構Multitrans
Transformer 架構和自註意力機制。這種架構
結合了非對比電腦斷層掃描 (NCCT) 影像的研究和
接受中風治療的患者的出院診斷報告，使用
多種基於 Transformer 架構的方法進行預測
中風治療的功能結果。結果表明，性能
單模態文字分類明顯優於單模態文字分類
影像分類，但多模態組合的效果優於
任何單一模式。儘管 Transformer 模型僅在以下方面表現較差
影像數據與臨床元診斷資訊結合，都可以
學習更好的補充訊息，做出良好的貢獻
準確預測中風治療效果..

##### **GluMarker: A Novel Predictive Modeling of Glycemic Control Through Digital Biomarkers**
2404.12605v1 by Ziyi Zhou et.al.

The escalating prevalence of diabetes globally underscores the need for
diabetes management. Recent research highlights the growing focus on digital
biomarkers in diabetes management, with innovations in computational frameworks
and noninvasive monitoring techniques using personalized glucose metrics.
However, they predominantly focus on insulin dosing and specific glucose
values, or with limited attention given to overall glycemic control. This
leaves a gap in expanding the scope of digital biomarkers for overall glycemic
control in diabetes management. To address such a research gap, we propose
GluMarker -- an end-to-end framework for modeling digital biomarkers using
broader factors sources to predict glycemic control. Through the assessment and
refinement of various machine learning baselines, GluMarker achieves
state-of-the-art on Anderson's dataset in predicting next-day glycemic control.
Moreover, our research identifies key digital biomarkers for the next day's
glycemic control prediction. These identified biomarkers are instrumental in
illuminating the daily factors that influence glycemic management, offering
vital insights for diabetes care.

摘要：全球糖尿病盛行率的不斷上升凸顯了對糖尿病的必要性
糖尿病管理。最近的研究凸顯了人們對數位化日益增長的關注
糖尿病管理中的生物標誌物，以及計算框架的創新
以及使用個人化血糖指標的非侵入性監測技術。
然而，他們主要關注胰島素劑量和特定葡萄糖
數值，或對整體血糖控制的關注有限。這
在擴大整體血糖數位生物標記的範圍方面存在差距
糖尿病管理中的控制。為了解決這種研究空白，我們建議
GluMarker－一種用於數位生物標記建模的端到端框架
預測血糖控制的更廣泛的因素來源。透過評估和
各種機器學習基線的細化，GluMarker 實現
安德森資料集預測第二天血糖控制的最新技術。
此外，我們的研究還確定了第二天的關鍵數位生物標記
血糖控制預測。這些確定的生物標記有助於
闡明影響血糖管理的日常因素，提供
對糖尿病照護的重要見解。

##### **DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era**
2404.12278v1 by David Restrepo et.al.

In the big data era, integrating diverse data modalities poses significant
challenges, particularly in complex fields like healthcare. This paper
introduces a new process model for multimodal Data Fusion for Data Mining,
integrating embeddings and the Cross-Industry Standard Process for Data Mining
with the existing Data Fusion Information Group model. Our model aims to
decrease computational costs, complexity, and bias while improving efficiency
and reliability. We also propose "disentangled dense fusion", a novel embedding
fusion method designed to optimize mutual information and facilitate dense
inter-modality feature interaction, thereby minimizing redundant information.
  We demonstrate the model's efficacy through three use cases: predicting
diabetic retinopathy using retinal images and patient metadata, domestic
violence prediction employing satellite imagery, internet, and census data, and
identifying clinical and demographic features from radiography images and
clinical notes. The model achieved a Macro F1 score of 0.92 in diabetic
retinopathy prediction, an R-squared of 0.854 and sMAPE of 24.868 in domestic
violence prediction, and a macro AUC of 0.92 and 0.99 for disease prediction
and sex classification, respectively, in radiological analysis.
  These results underscore the Data Fusion for Data Mining model's potential to
significantly impact multimodal data processing, promoting its adoption in
diverse, resource-constrained settings.

摘要：在大數據時代，整合多元資料模式具有重要意義
挑戰，特別是在醫療保健等複雜領域。這張紙
引入了用於資料探勘的多模式資料融合的新流程模型，
整合嵌入和資料探勘的跨行業標準流程
與現有的資料融合資訊組模型。我們的模型旨在
降低計算成本、複雜性和偏差，同時提高效率
和可靠性。我們也提出了“解糾纏密集融合”，一種新穎的嵌入
融合方法旨在優化互資訊並促進密集
模態間特徵交互，從而最大限度地減少冗餘資訊。
  我們透過三個用例證明了該模型的功效：
使用視網膜影像和病患元資料的糖尿病視網膜病變，國內
利用衛星影像、網路和人口普查資料進行暴力預測，以及
從放射線照相影像中識別臨床和人口特徵
臨床筆記。該模型在糖尿病患者中的 Macro F1 得分為 0.92
視網膜病變預測，國內R平方為0.854，sMAPE為24.868
暴力預測，疾病預測的宏觀 AUC 分別為 0.92 和 0.99
和性別分類，分別在放射分析。
  這些結果強調了資料探勘模型的資料融合的潛力
顯著影響多模式資料處理，促進其在
多樣化、資源有限的環境。

##### **Relationship Discovery for Drug Recommendation**
2404.12228v1 by Xiang Li et.al.

Medication recommendation systems are designed to deliver personalized drug
suggestions that are closely aligned with individual patient needs. Previous
studies have primarily concentrated on developing medication embeddings,
achieving significant progress. Nonetheless, these approaches often fall short
in accurately reflecting individual patient profiles, mainly due to challenges
in distinguishing between various patient conditions and the inability to
establish precise correlations between specific conditions and appropriate
medications. In response to these issues, we introduce DisMed, a model that
focuses on patient conditions to enhance personalization. DisMed employs causal
inference to discern clear, quantifiable causal links. It then examines patient
conditions in depth, recognizing and adapting to the evolving nuances of these
conditions, and mapping them directly to corresponding medications.
Additionally, DisMed leverages data from multiple patient visits to propose
combinations of medications. Comprehensive testing on real-world datasets
demonstrates that DisMed not only improves the customization of patient
profiles but also surpasses leading models in both precision and safety.

摘要：藥物推薦系統旨在提供個人化藥物
與患者個別需求密切相關的建議。以前的
研究主要集中在開發藥物嵌入，
取得重大進展。然而，這些方法往往達不到要求
準確反映個別患者概況，主要是由於挑戰
區分不同患者的情況和無法
在特定條件和適當的條件之間建立精確的關聯
藥物。針對這些問題，我們推出了 DisMed 這個模型
專注於患者狀況以增強個人化。 DisMed 採用因果關係
推斷以辨別清晰的、可量化的因果關係。然後它會檢查病人
深入了解情況，認識並適應這些不斷變化的細微差別
條件，並將它們直接映射到相應的藥物。
此外，DisMed 利用多次患者就診的數據來提出建議
藥物組合。對真實世界資料集的全面測試
表明 DisMed 不僅提高了患者的客製化
外形，但在精度和安全性方面也超越了領先型號。

##### **A Symmetric Regressor for MRI-Based Assessment of Striatal Dopamine Transporter Uptake in Parkinson's Disease**
2404.11929v1 by Walid Abdullah Al et.al.

Dopamine transporter (DAT) imaging is commonly used for monitoring
Parkinson's disease (PD), where striatal DAT uptake amount is computed to
assess PD severity. However, DAT imaging has a high cost and the risk of
radiance exposure and is not available in general clinics. Recently, MRI patch
of the nigral region has been proposed as a safer and easier alternative. This
paper proposes a symmetric regressor for predicting the DAT uptake amount from
the nigral MRI patch. Acknowledging the symmetry between the right and left
nigrae, the proposed regressor incorporates a paired input-output model that
simultaneously predicts the DAT uptake amounts for both the right and left
striata. Moreover, it employs a symmetric loss that imposes a constraint on the
difference between right-to-left predictions, resembling the high correlation
in DAT uptake amounts in the two lateral sides. Additionally, we propose a
symmetric Monte-Carlo (MC) dropout method for providing a fruitful uncertainty
estimate of the DAT uptake prediction, which utilizes the above symmetry. We
evaluated the proposed approach on 734 nigral patches, which demonstrated
significantly improved performance of the symmetric regressor compared with the
standard regressors while giving better explainability and feature
representation. The symmetric MC dropout also gave precise uncertainty ranges
with a high probability of including the true DAT uptake amounts within the
range.

摘要：多巴胺轉運蛋白 (DAT) 影像通常用於監測
帕金森氏症 (PD)，其中紋狀體 DAT 攝取量計算為
評估 PD 嚴重程度。然而，DAT成像成本較高，且有以下風險：
輻射暴露，一般診所不提供。最近，MRI 補丁
黑格爾地區的區域被提議作為更安全和更容易的替代方案。這
論文提出了一個對稱迴歸器來預測 DAT 的吸收量
黑質 MRI 貼片。承認左右對稱
nigrae，所提出的迴歸器包含配對的輸入輸出模型，
同時預測左右兩側的 DAT 攝取量
紋狀體。此外，它採用對稱損失，對
從右到左預測之間的差異，類似於高相關性
兩側的 DAT 吸收量。此外，我們建議
對稱蒙特卡羅 (MC) 丟失方法提供了豐富的不確定性
DAT 攝取預測的估計，利用了上述對稱性。我們
對 734 個黑質斑塊評估了所提出的方法，結果表明
與對稱回歸器相比，顯著提高了性能
標準回歸器，同時提供更好的可解釋性和功能
表示。對稱 MC 壓差也給出了精確的不確定性範圍
很有可能將真實的 DAT 攝取量納入
範圍。

##### **Cross-model Mutual Learning for Exemplar-based Medical Image Segmentation**
2404.11812v1 by Qing En et.al.

Medical image segmentation typically demands extensive dense annotations for
model training, which is both time-consuming and skill-intensive. To mitigate
this burden, exemplar-based medical image segmentation methods have been
introduced to achieve effective training with only one annotated image. In this
paper, we introduce a novel Cross-model Mutual learning framework for
Exemplar-based Medical image Segmentation (CMEMS), which leverages two models
to mutually excavate implicit information from unlabeled data at multiple
granularities. CMEMS can eliminate confirmation bias and enable collaborative
training to learn complementary information by enforcing consistency at
different granularities across models. Concretely, cross-model image
perturbation based mutual learning is devised by using weakly perturbed images
to generate high-confidence pseudo-labels, supervising predictions of strongly
perturbed images across models. This approach enables joint pursuit of
prediction consistency at the image granularity. Moreover, cross-model
multi-level feature perturbation based mutual learning is designed by letting
pseudo-labels supervise predictions from perturbed multi-level features with
different resolutions, which can broaden the perturbation space and enhance the
robustness of our framework. CMEMS is jointly trained using exemplar data,
synthetic data, and unlabeled data in an end-to-end manner. Experimental
results on two medical image datasets indicate that the proposed CMEMS
outperforms the state-of-the-art segmentation methods with extremely limited
supervision.

摘要：醫學影像分割通常需要大量密集註釋
模型訓練既耗時又需要技能。減輕
為了解決這個負擔，基於樣本的醫學影像分割方法已經被提出。
引入僅使用一張註釋的圖像即可實現有效的訓練。在這個
論文中，我們介紹了一個新穎的跨模型相互學習框架
基於範例的醫學影像分割 (CMEMS)，利用兩種模型
從多個未標記資料中相互挖掘隱含訊息
粒度。 CMEMS 可以消除確認偏誤並實現協作
透過加強一致性來學習補充資訊的培訓
跨模型的不同粒度。具體來說，跨模型影像
透過使用弱擾動圖像設計基於擾動的相互學習
產生高置信度的偽標籤，監督強烈的預測
跨模型的擾動影像。這種方法可以共同追求
影像粒度上的預測一致性。此外，跨模型
基於多層次特徵擾動的相互學習是透過讓
偽標籤監督來自擾動的多層次特徵的預測
不同的分辨率，可以拓寬攝動空間，增強
我們框架的穩健性。 CMEMS 使用範例資料進行聯合訓練，
以端到端的方式合成資料和未標記資料。實驗性的
兩個醫學影像資料集的結果表明，所提出的 CMEMS
在極度有限的情況下優於最先進的分割方法
監督。

##### **A Secure and Trustworthy Network Architecture for Federated Learning Healthcare Applications**
2404.11698v1 by Antonio Boiano et.al.

Federated Learning (FL) has emerged as a promising approach for
privacy-preserving machine learning, particularly in sensitive domains such as
healthcare. In this context, the TRUSTroke project aims to leverage FL to
assist clinicians in ischemic stroke prediction. This paper provides an
overview of the TRUSTroke FL network infrastructure. The proposed architecture
adopts a client-server model with a central Parameter Server (PS). We introduce
a Docker-based design for the client nodes, offering a flexible solution for
implementing FL processes in clinical settings. The impact of different
communication protocols (HTTP or MQTT) on FL network operation is analyzed,
with MQTT selected for its suitability in FL scenarios. A control plane to
support the main operations required by FL processes is also proposed. The
paper concludes with an analysis of security aspects of the FL architecture,
addressing potential threats and proposing mitigation strategies to increase
the trustworthiness level.

摘要：聯邦學習（FL）已成為一種有前途的方法
保護隱私的機器學習，特別是在敏感領域，例如
衛生保健。在此背景下，TRUSTroke 計畫旨在利用 FL
協助臨床醫師預測缺血性中風。本文提供了一個
TRUSTroke FL 網路基礎設施概述。建議的架構
採用中央參數伺服器（PS）的客戶端-伺服器模型。我們介紹
基於Docker的客戶端節點設計，為客戶提供靈活的解決方案
在臨床環境中實施 FL 流程。不同的影響
分析 FL 網路操作上的通訊協定（HTTP 或 MQTT），
選擇 MQTT 是因為它適合 FL 場景。一個控制平面
也提出了支援 FL 流程所需的主要操作。這
本文最後對 FL 架構的安全性方面進行了分析，
解決潛在威脅並提出緩解策略，以增加
可信度等級。

##### **Towards Reliable Empirical Machine Unlearning Evaluation: A Game-Theoretic View**
2404.11577v1 by Yiwen Tu et.al.

Machine unlearning is the process of updating machine learning models to
remove the information of specific training data samples, in order to comply
with data protection regulations that allow individuals to request the removal
of their personal data. Despite the recent development of numerous unlearning
algorithms, reliable evaluation of these algorithms remains an open research
question. In this work, we focus on membership inference attack (MIA) based
evaluation, one of the most common approaches for evaluating unlearning
algorithms, and address various pitfalls of existing evaluation metrics that
lack reliability. Specifically, we propose a game-theoretic framework that
formalizes the evaluation process as a game between unlearning algorithms and
MIA adversaries, measuring the data removal efficacy of unlearning algorithms
by the capability of the MIA adversaries. Through careful design of the game,
we demonstrate that the natural evaluation metric induced from the game enjoys
provable guarantees that the existing evaluation metrics fail to satisfy.
Furthermore, we propose a practical and efficient algorithm to estimate the
evaluation metric induced from the game, and demonstrate its effectiveness
through both theoretical analysis and empirical experiments. This work presents
a novel and reliable approach to empirically evaluating unlearning algorithms,
paving the way for the development of more effective unlearning techniques.

摘要：機器去學習是更新機器學習模型的過程
刪除特定訓練資料樣本的信息，以符合
資料保護法規允許個人請求刪除
他們的個人資料。儘管最近出現了許多不學習的情況
演算法，這些演算法的可靠評估仍然是一個開放的研究
問題。在這項工作中，我們專注於基於成員推理攻擊（MIA）
評估，評估遺忘最常見的方法之一
演算法，並解決現有評估指標的各種缺陷
缺乏可靠性。具體來說，我們提出了一個博弈論框架
將評估過程形式化為遺忘演算法和
MIA 對手，測量遺忘演算法的資料刪除效率
取決於 MIA 對手的能力。透過遊戲的精心設計，
我們證明了從遊戲中得出的自然評估指標享有
現有評估指標無法滿足的可證明保證。
此外，我們提出了一種實用且有效的演算法來估計
從遊戲中匯出評估指標，並證明其有效性
透過理論分析和實證實驗。這部作品呈現
一種新穎且可靠的方法來根據經驗評估遺忘演算法，
為開發更有效的忘卻技術鋪路。

##### **Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM**
2404.11209v1 by Hongzhao Li et.al.

Medical report generation automates radiology descriptions from images,
easing the burden on physicians and minimizing errors. However, current methods
lack structured outputs and physician interactivity for clear, clinically
relevant reports. Our method introduces a prompt-guided approach to generate
structured chest X-ray reports using a pre-trained large language model (LLM).
First, we identify anatomical regions in chest X-rays to generate focused
sentences that center on key visual elements, thereby establishing a structured
report foundation with anatomy-based sentences. We also convert the detected
anatomy into textual prompts conveying anatomical comprehension to the LLM.
Additionally, the clinical context prompts guide the LLM to emphasize
interactivity and clinical requirements. By integrating anatomy-focused
sentences and anatomy/clinical prompts, the pre-trained LLM can generate
structured chest X-ray reports tailored to prompted anatomical regions and
clinical contexts. We evaluate using language generation and clinical
effectiveness metrics, demonstrating strong performance.

摘要：醫療報告產生自動化影像的放射學描述，
減輕醫生的負擔並最大限度地減少錯誤。然而，目前的方法
缺乏清晰、臨床的結構化輸出和醫生互動
相關報道。我們的方法引入了一種提示引導的方法來生成
使用預先訓練的大語言模型 (LLM) 產生結構化胸部 X 光報告。
首先，我們識別胸部 X 光中的解剖區域以產生聚焦的
以關鍵視覺元素為中心的句子，從而建立結構化的
報告基礎與基於解剖學的句子。我們還將檢測到的
將解剖學轉化為文本提示，將解剖學理解傳達給法學碩士。
此外，臨床背景提示引導法學碩士強調
互動性和臨床要求。透過整合以解剖學為中心的
句子和解剖學/臨床提示，預訓練的法學碩士可以生成
根據提示的解剖區域客製化結構化胸部 X 光報告
臨床背景。我們使用語言生成和臨床進行評估
有效性指標，展現強勁的績效。

##### **Explainable Machine Learning System for Predicting Chronic Kidney Disease in High-Risk Cardiovascular Patients**
2404.11148v1 by Nantika Nguycharoen et.al.

As the global population ages, the incidence of Chronic Kidney Disease (CKD)
is rising. CKD often remains asymptomatic until advanced stages, which
significantly burdens both the healthcare system and patient quality of life.
This research developed an explainable machine learning system for predicting
CKD in patients with cardiovascular risks, utilizing medical history and
laboratory data. The Random Forest model achieved the highest sensitivity of
88.2%. The study introduces a comprehensive explainability framework that
extends beyond traditional feature importance methods, incorporating global and
local interpretations, bias inspection, biomedical relevance, and safety
assessments. Key predictive features identified in global interpretation were
the use of diabetic and ACEI/ARB medications, and initial eGFR values. Local
interpretation provided model insights through counterfactual explanations,
which aligned with other system parts. After conducting a bias inspection, it
was found that the initial eGFR values and CKD predictions exhibited some bias,
but no significant gender bias was identified. The model's logic, extracted by
scoped rules, was confirmed to align with existing medical literature. The
safety assessment tested potentially dangerous cases and confirmed that the
model behaved safely. This system enhances the explainability, reliability, and
accountability of the model, promoting its potential integration into
healthcare settings and compliance with upcoming regulatory standards, and
showing promise for broader applications in healthcare machine learning.

摘要：隨著全球人口老化，慢性腎臟病（CKD）的發生率
正在崛起。 CKD 通常直到晚期才出現症狀，這
給醫療保健系統和患者的生活品質帶來了巨大的負擔。
這項研究開發了一個可解釋的機器學習系統來預測
CKD 患者有心血管風險，利用病史和
實驗室數據。隨機森林模型達到了最高靈敏度
88.2%。該研究引入了一個全面的可解釋性框架
超越了傳統的特徵重要性方法，融合了全球和
當地解釋、偏見檢查、生物醫學相關性和安全性
評估。全球解釋中確定的關鍵預測特徵是
糖尿病和 ACEI/ARB 藥物的使用，以及初始 eGFR 值。當地的
解釋透過反事實解釋提供了模型見解，
與其他系統部件對齊。進行偏差檢查後，
發現初始 eGFR 值和 CKD 預測有一定偏差，
但沒有發現明顯的性別偏見。模型的邏輯，透過提取
範圍規則被確認與現有醫學文獻一致。這
安全評估測試了潛在危險案例並確認
模型表現安全。該系統增強了可解釋性、可靠性和
此模型的問責制，促進其潛在融入
醫療保健環境和遵守即將到來的監管標準，以及
顯示出在醫療保健機器學習領域更廣泛應用的前景。

##### **AKGNet: Attribute Knowledge-Guided Unsupervised Lung-Infected Area Segmentation**
2404.11008v1 by Qing En et.al.

Lung-infected area segmentation is crucial for assessing the severity of lung
diseases. However, existing image-text multi-modal methods typically rely on
labour-intensive annotations for model training, posing challenges regarding
time and expertise. To address this issue, we propose a novel attribute
knowledge-guided framework for unsupervised lung-infected area segmentation
(AKGNet), which achieves segmentation solely based on image-text data without
any mask annotation. AKGNet facilitates text attribute knowledge learning,
attribute-image cross-attention fusion, and high-confidence-based pseudo-label
exploration simultaneously. It can learn statistical information and capture
spatial correlations between image and text attributes in the embedding space,
iteratively refining the mask to enhance segmentation. Specifically, we
introduce a text attribute knowledge learning module by extracting attribute
knowledge and incorporating it into feature representations, enabling the model
to learn statistical information and adapt to different attributes. Moreover,
we devise an attribute-image cross-attention module by calculating the
correlation between attributes and images in the embedding space to capture
spatial dependency information, thus selectively focusing on relevant regions
while filtering irrelevant areas. Finally, a self-training mask improvement
process is employed by generating pseudo-labels using high-confidence
predictions to iteratively enhance the mask and segmentation. Experimental
results on a benchmark medical image dataset demonstrate the superior
performance of our method compared to state-of-the-art segmentation techniques
in unsupervised scenarios.

摘要：肺部感染區域分割對於評估肺部嚴重程度至關重要
疾病。然而，現有的圖像文字多模態方法通常依賴
模型訓練的勞力密集註釋，給以下方面帶來了挑戰
時間和專業知識。為了解決這個問題，我們提出了一個新的屬性
無監督肺部感染區域分割的知識引導框架
（AKGNet），僅基於圖文資料實現分割，無需
任何掩碼註釋。 AKGNet 促進文字屬性知識學習，
屬性-影像交叉注意力融合，以及基於高置信度的偽標籤
同時探索。它可以學習統計資訊並捕獲
嵌入空間中圖像和文字屬性之間的空間相關性，
迭代地細化掩模以增強分割。具體來說，我們
透過提取屬性引入文字屬性知識學習模組
知識並將其合併到特徵表示中，使模型成為可能
學習統計資訊並適應不同的屬性。而且，
我們透過計算屬性圖像交叉注意模組
嵌入空間中的屬性和影像之間的相關性要捕獲
空間依賴訊息，從而選擇性地關注相關區域
同時過濾掉不相關的區域。最後，自我訓練掩模的改進
透過使用高置信度產生偽標籤來採用該過程
迭代增強掩模和分割的預測。實驗性的
基準醫學影像資料集的結果證明了其優越性
我們的方法與最先進的分割技術相比的性能
在無人監督的場景中。

##### **Leveraging 3D LiDAR Sensors to Enable Enhanced Urban Safety and Public Health: Pedestrian Monitoring and Abnormal Activity Detection**
2404.10978v1 by Nawfal Guefrachi et.al.

The integration of Light Detection and Ranging (LiDAR) and Internet of Things
(IoT) technologies offers transformative opportunities for public health
informatics in urban safety and pedestrian well-being. This paper proposes a
novel framework utilizing these technologies for enhanced 3D object detection
and activity classification in urban traffic scenarios. By employing elevated
LiDAR, we obtain detailed 3D point cloud data, enabling precise pedestrian
activity monitoring. To overcome urban data scarcity, we create a specialized
dataset through simulated traffic environments in Blender, facilitating
targeted model training. Our approach employs a modified Point
Voxel-Region-based Convolutional Neural Network (PV-RCNN) for robust 3D
detection and PointNet for classifying pedestrian activities, significantly
benefiting urban traffic management and public health by offering insights into
pedestrian behavior and promoting safer urban environments. Our dual-model
approach not only enhances urban traffic management but also contributes
significantly to public health by providing insights into pedestrian behavior
and promoting safer urban environment.

摘要：光探測與測距（LiDAR）與物聯網的集成
（物聯網）科技為公共衛生提供變革機遇
城市安全和行人福祉的資訊學。本文提出了一個
利用這些技術增強 3D 物體檢測的新穎框架
以及城市交通場景中的活動分類。透過採用高
LiDAR，我們取得詳細的3D點雲數據，實現精準行人
活動監控。為了克服城市數據稀缺的問題，我們創建了專門的
透過 Blender 中模擬交通環境的資料集，促進
有針對性的模型訓練。我們的方法採用了修改後的點
用於穩健 3D 的基於體素區域的捲積神經網路 (PV-RCNN)
偵測和 PointNet 用於對行人活動進行分類，顯著
透過提供以下方面的見解，有利於城市交通管理和公共衛生
行人行為並促進更安全的城市環境。我們的雙模
不僅加強了城市交通管理，也有助於
透過提供對行人行為的洞察，對公共健康產生重大影響
促進更安全的城市環境。

##### **CrossGP: Cross-Day Glucose Prediction Excluding Physiological Information**
2404.10901v1 by Ziyi Zhou et.al.

The increasing number of diabetic patients is a serious issue in society
today, which has significant negative impacts on people's health and the
country's financial expenditures. Because diabetes may develop into potential
serious complications, early glucose prediction for diabetic patients is
necessary for timely medical treatment. Existing glucose prediction methods
typically utilize patients' private data (e.g. age, gender, ethnicity) and
physiological parameters (e.g. blood pressure, heart rate) as reference
features for glucose prediction, which inevitably leads to privacy protection
concerns. Moreover, these models generally focus on either long-term
(monthly-based) or short-term (minute-based) predictions. Long-term prediction
methods are generally inaccurate because of the external uncertainties that can
greatly affect the glucose values, while short-term ones fail to provide timely
medical guidance. Based on the above issues, we propose CrossGP, a novel
machine-learning framework for cross-day glucose prediction solely based on the
patient's external activities without involving any physiological parameters.
Meanwhile, we implement three baseline models for comparison. Extensive
experiments on Anderson's dataset strongly demonstrate the superior performance
of CrossGP and prove its potential for future real-life applications.

摘要：糖尿病患者數量的不斷增加是一個嚴重的社會問題
今天，它對人們的健康和生活產生了重大的負面影響
國家的財政支出。因為糖尿病有可能發展成潛在的
嚴重併發症，糖尿病患者的早期血糖預測
需要及時就醫。現有的血糖預測方法
通常利用患者的私人資料（例如年齡、性別、種族）和
生理參數（如血壓、心率）作為參考
血糖預測的特徵，這不可避免地導致隱私保護
的擔憂。此外，這些模型通常側重於長期
（基於每月）或短期（基於分鐘）預測。長期預測
由於外部的不確定性，方法通常不準確
對血糖值影響很大，而短期的又不能及時提供
醫療指導。基於上述問題，我們提出了 CrossGP，一種新穎的
僅基於以下內容的跨日血糖預測的機器學習框架
患者的外部活動，不涉及任何生理參數。
同時，我們實現了三個基準模型進行比較。廣泛的
在 Anderson 資料集上的實驗有力地證明了其優越的性能
CrossGP 並證明其在未來現實生活應用中的潛力。

##### **Mixed Prototype Consistency Learning for Semi-supervised Medical Image Segmentation**
2404.10717v1 by Lijian Li et.al.

Recently, prototype learning has emerged in semi-supervised medical image
segmentation and achieved remarkable performance. However, the scarcity of
labeled data limits the expressiveness of prototypes in previous methods,
potentially hindering the complete representation of prototypes for class
embedding. To address this problem, we propose the Mixed Prototype Consistency
Learning (MPCL) framework, which includes a Mean Teacher and an auxiliary
network. The Mean Teacher generates prototypes for labeled and unlabeled data,
while the auxiliary network produces additional prototypes for mixed data
processed by CutMix. Through prototype fusion, mixed prototypes provide extra
semantic information to both labeled and unlabeled prototypes. High-quality
global prototypes for each class are formed by fusing two enhanced prototypes,
optimizing the distribution of hidden embeddings used in consistency learning.
Extensive experiments on the left atrium and type B aortic dissection datasets
demonstrate MPCL's superiority over previous state-of-the-art approaches,
confirming the effectiveness of our framework. The code will be released soon.

摘要：最近，原型學習在半監督醫學影像中出現
細分領域並取得了驕人的業績。然而，稀缺性
標記資料限制了先前方法中原型的表達能力，
可能會阻礙類原型的完整表示
嵌入。為了解決這個問題，我們提出了混合原型一致性
學習 (MPCL) 框架，其中包括平均教師和輔助教師
網路。 The Mean Teacher 為標記和未標記資料產生原型，
而輔助網路則為混合數據產生額外的原型
由 CutMix 處理。透過原型融合，混合原型提供了額外的
標記和未標記原型的語義資訊。高品質
每個類別的全局原型是透過融合兩個增強原型形成的，
優化一致性學習中使用的隱藏嵌入的分佈。
對左心房和 B 型主動脈剝離資​​料集進行大量實驗
證明 MPCL 相對於先前最先進方法的優越性，
確認我們框架的有效性。該代碼即將發布。

##### **AAVDiff: Experimental Validation of Enhanced Viability and Diversity in Recombinant Adeno-Associated Virus (AAV) Capsids through Diffusion Generation**
2404.10573v2 by Lijun Liu et.al.

Recombinant adeno-associated virus (rAAV) vectors have revolutionized gene
therapy, but their broad tropism and suboptimal transduction efficiency limit
their clinical applications. To overcome these limitations, researchers have
focused on designing and screening capsid libraries to identify improved
vectors. However, the large sequence space and limited resources present
challenges in identifying viable capsid variants. In this study, we propose an
end-to-end diffusion model to generate capsid sequences with enhanced
viability. Using publicly available AAV2 data, we generated 38,000 diverse AAV2
viral protein (VP) sequences, and evaluated 8,000 for viral selection. The
results attested the superiority of our model compared to traditional methods.
Additionally, in the absence of AAV9 capsid data, apart from one wild-type
sequence, we used the same model to directly generate a number of viable
sequences with up to 9 mutations. we transferred the remaining 30,000 samples
to the AAV9 domain. Furthermore, we conducted mutagenesis on AAV9 VP
hypervariable regions VI and V, contributing to the continuous improvement of
the AAV9 VP sequence. This research represents a significant advancement in the
design and functional validation of rAAV vectors, offering innovative solutions
to enhance specificity and transduction efficiency in gene therapy
applications.

摘要：重組腺相關病毒（rAAV）載體徹底改變了基因
療法，但其廣泛的趨向性和次優的轉導效率限制了
他們的臨床應用。為了克服這些限制，研究人員
專注於設計和篩選衣殼庫以識別改進的
向量。然而序列空間大、資源有限
識別可行衣殼變體的挑戰。在這項研究中，我們提出了一個
端對端擴散模型，用於產生具有增強功能的衣殼序列
可行性。使用公開的 AAV2 數據，我們產生了 38,000 個不同的 AAV2
病毒蛋白 (VP) 序列，並評估了 8,000 個病毒選擇。這
結果證明了我們的模型相對於傳統方法的優越性。
此外，在缺乏 AAV9 衣殼資料的情況下，除了一種野生型
序列，我們使用相同的模型直接產生多個可行的
最多有 9 個突變的序列。我們轉移了剩餘的30,000個樣本
到 AAV9 域。此外，我們對 AAV9 VP 進行了誘變
高變異區 VI 和 V，有助於持續改進
AAV9 VP 序列。這項研究代表了該領域的重大進步
rAAV 載體的設計與功能驗證，提供創新解決方案
提高基因治療的特異性與轉導效率
應用程式.

##### **A Sentiment Analysis of Medical Text Based on Deep Learning**
2404.10503v1 by Yinan Chen et.al.

The field of natural language processing (NLP) has made significant progress
with the rapid development of deep learning technologies. One of the research
directions in text sentiment analysis is sentiment analysis of medical texts,
which holds great potential for application in clinical diagnosis. However, the
medical field currently lacks sufficient text datasets, and the effectiveness
of sentiment analysis is greatly impacted by different model design approaches,
which presents challenges. Therefore, this paper focuses on the medical domain,
using bidirectional encoder representations from transformers (BERT) as the
basic pre-trained model and experimenting with modules such as convolutional
neural network (CNN), fully connected network (FCN), and graph convolutional
networks (GCN) at the output layer. Experiments and analyses were conducted on
the METS-CoV dataset to explore the training performance after integrating
different deep learning networks. The results indicate that CNN models
outperform other networks when trained on smaller medical text datasets in
combination with pre-trained models like BERT. This study highlights the
significance of model selection in achieving effective sentiment analysis in
the medical domain and provides a reference for future research to develop more
efficient model architectures.

摘要：自然語言處理（NLP）領域取得重大進展
隨著深度學習技術的快速發展。其中一項研究
文本情緒分析的方向是醫學文本的情緒分析，
在臨床診斷上具有巨大的應用潛力。但是，那
醫學領域目前缺乏足夠的文字資料集，有效性
情感分析的效果很大程度上受到不同模型設計方法的影響，
這帶來了挑戰。因此，本文主要關注醫學領域，
使用 Transformer 的雙向編碼器表示（BERT）作為
基本的預訓練模型並嘗試卷積等模組
神經網路 (CNN)、全連接網路 (FCN) 和圖卷積
輸出層的網路（GCN）。進行了實驗和分析
METS-CoV 資料集以探索整合後的訓練效能
不同的深度學習網路。結果顯示 CNN 模型
在較小的醫學文本資料集上進行訓練時，優於其他網絡
與 BERT 等預訓練模型結合。這項研究強調
模型選擇對於實現有效情感分析的重要性
為未來醫學領域的研究發展提供參考
高效的模型架構。

##### **Integration of Self-Supervised BYOL in Semi-Supervised Medical Image Recognition**
2404.10405v1 by Hao Feng et.al.

Image recognition techniques heavily rely on abundant labeled data,
particularly in medical contexts. Addressing the challenges associated with
obtaining labeled data has led to the prominence of self-supervised learning
and semi-supervised learning, especially in scenarios with limited annotated
data. In this paper, we proposed an innovative approach by integrating
self-supervised learning into semi-supervised models to enhance medical image
recognition. Our methodology commences with pre-training on unlabeled data
utilizing the BYOL method. Subsequently, we merge pseudo-labeled and labeled
datasets to construct a neural network classifier, refining it through
iterative fine-tuning. Experimental results on three different datasets
demonstrate that our approach optimally leverages unlabeled data, outperforming
existing methods in terms of accuracy for medical image recognition.

摘要：影像辨識技術嚴重依賴豐富的標記數據，
特別是在醫療領域。解決相關挑戰
獲取標記數據導致了自我監督學習的重要性
和半監督學習，特別是在註釋有限的場景中
數據。在本文中，我們提出了一種創新方法，將
自監督學習到半監督模型以增強醫學影像
認出。我們的方法從未標記資料的預訓練開始
利用 BYOL 方法。隨後，我們合併偽標記和標記
資料集來建立神經網路分類器，並透過以下方式進行改進
迭代微調。三個不同資料集上的實驗結果
證明我們的方法可以最佳地利用未標記的數據，表現優於
現有方法在醫學影像辨識的準確性方面。

##### **Generating Counterfactual Trajectories with Latent Diffusion Models for Concept Discovery**
2404.10356v1 by Payal Varshney et.al.

Trustworthiness is a major prerequisite for the safe application of opaque
deep learning models in high-stakes domains like medicine. Understanding the
decision-making process not only contributes to fostering trust but might also
reveal previously unknown decision criteria of complex models that could
advance the state of medical research. The discovery of decision-relevant
concepts from black box models is a particularly challenging task. This study
proposes Concept Discovery through Latent Diffusion-based Counterfactual
Trajectories (CDCT), a novel three-step framework for concept discovery
leveraging the superior image synthesis capabilities of diffusion models. In
the first step, CDCT uses a Latent Diffusion Model (LDM) to generate a
counterfactual trajectory dataset. This dataset is used to derive a
disentangled representation of classification-relevant concepts using a
Variational Autoencoder (VAE). Finally, a search algorithm is applied to
identify relevant concepts in the disentangled latent space. The application of
CDCT to a classifier trained on the largest public skin lesion dataset revealed
not only the presence of several biases but also meaningful biomarkers.
Moreover, the counterfactuals generated within CDCT show better FID scores than
those produced by a previously established state-of-the-art method, while being
12 times more resource-efficient. Unsupervised concept discovery holds great
potential for the application of trustworthy AI and the further development of
human knowledge in various domains. CDCT represents a further step in this
direction.

摘要：可信是不透明安全應用的重要前提
醫學等高風險領域的深度學習模式。了解
決策過程不僅有助於培養信任，而且可能
揭示以前未知的複雜模型的決策標準，可以
推進醫學研究狀況。決策相關的發現
來自黑盒模型的概念是一項特別具有挑戰性的任務。這項研究
提出透過基於潛在擴散的反事實進行概念發現
軌跡（CDCT），一種新穎的概念發現三步驟框架
利用擴散模型的卓越影像合成能力。在
第一步，CDCT 使用潛在擴散模型 (LDM) 生成
反事實軌跡資料集。該數據集用於導出
使用分類相關概念的解纏結表示
變分自動編碼器（VAE）。最後，應用搜尋演算法
辨識解開的潛在空間中的相關概念。應用
揭示了在最大的公共皮膚病變資料集上訓練的分類器的 CDCT
不僅存在一些偏差，而且還存在有意義的生物標記。
此外，CDCT 中產生的反事實顯示出比 CDCT 更好的 FID 分數
那些透過先前建立的最先進方法生產的，同時
資源效率提高 12 倍。無監督的概念發現很有效
可信人工智慧的應用潛力與進一步發展
人類各領域的知識。 CDCT 代表這方面又邁出了一步
方向。

##### **CARE to Compare: A real-world dataset for anomaly detection in wind turbine data**
2404.10320v2 by Christian Gück et.al.

Anomaly detection plays a crucial role in the field of predictive maintenance
for wind turbines, yet the comparison of different algorithms poses a difficult
task because domain specific public datasets are scarce. Many comparisons of
different approaches either use benchmarks composed of data from many different
domains, inaccessible data or one of the few publicly available datasets which
lack detailed information about the faults. Moreover, many publications
highlight a couple of case studies where fault detection was successful. With
this paper we publish a high quality dataset that contains data from 36 wind
turbines across 3 different wind farms as well as the most detailed fault
information of any public wind turbine dataset as far as we know. The new
dataset contains 89 years worth of real-world operating data of wind turbines,
distributed across 44 labeled time frames for anomalies that led up to faults,
as well as 51 time series representing normal behavior. Additionally, the
quality of training data is ensured by turbine-status-based labels for each
data point. Furthermore, we propose a new scoring method, called CARE
(Coverage, Accuracy, Reliability and Earliness), which takes advantage of the
information depth that is present in the dataset to identify a good all-around
anomaly detection model. This score considers the anomaly detection
performance, the ability to recognize normal behavior properly and the
capability to raise as few false alarms as possible while simultaneously
detecting anomalies early.

摘要：異常檢測在預測性維護領域發揮至關重要的作用
對於風力渦輪機來說，不同演算法的比較帶來了困難
任務，因為特定領域的公共資料集很少。許多比較
不同的方法要么使用由來自許多不同的數據組成的基準
網域、無法存取的資料或少數公開可用的資料集之一
缺乏有關故障的詳細資訊。此外，許多出版物
重點介紹幾個成功檢測故障的案例研究。和
本文我們發布了一個高品質的數據集，其中包含來自 36 個風的數據
跨越3個不同風電場的渦輪機以及最詳細的故障
據我們所知，任何公共風力渦輪機資料集的資訊。新的
數據集包​​含 89 年風力渦輪機的真實運轉數據，
分佈在 44 個標記時間範圍內導致故障的異常情況，
以及代表正常行為的 51 個時間序列。此外，
訓練資料的品質由每個渦輪機狀態的標籤來保證
數據點。此外，我們提出了一種新的評分方法，稱為 CARE
（覆蓋範圍、準確性、可靠性和早期性），它利用了
資料集中存在的資訊深度，用於識別良好的全能
異常檢測模型。此分數考慮了異常檢測
表現、正確辨識正常行為的能力及
能夠同時發出盡可能少的誤報
儘早發現異常狀況。

##### **Clustering and Data Augmentation to Improve Accuracy of Sleep Assessment and Sleep Individuality Analysis**
2404.10299v1 by Shintaro Tamai et.al.

Recently, growing health awareness, novel methods allow individuals to
monitor sleep at home. Utilizing sleep sounds offers advantages over
conventional methods like smartwatches, being non-intrusive, and capable of
detecting various physiological activities. This study aims to construct a
machine learning-based sleep assessment model providing evidence-based
assessments, such as poor sleep due to frequent movement during sleep onset.
Extracting sleep sound events, deriving latent representations using VAE,
clustering with GMM, and training LSTM for subjective sleep assessment achieved
a high accuracy of 94.8% in distinguishing sleep satisfaction. Moreover,
TimeSHAP revealed differences in impactful sound event types and timings for
different individuals.

摘要：最近，隨著健康意識的增強，新的方法使個人能夠
監控家裡的睡眠狀況。使用睡眠聲音比使用睡眠聲音更有優勢
智慧手錶等傳統方法，非侵入性，並且能夠
檢測各種生理活動。本研究旨在建構一個
基於機器學習的睡眠評估模型提供以證據為基礎的睡眠評估模型
評估，例如由於入睡期間頻繁運動而導致睡眠品質不佳。
擷取睡眠聲音事件，使用 VAE 匯出潛在表示，
使用 GMM 進行聚類，並訓練 LSTM 進行主觀睡眠評估
區分睡眠滿意度的準確率高達 94.8%。而且，
TimeSHAP 揭示了有影響力的聲音事件類型和時間安排的差異
不同的個體。

##### **Emergent Language Symbolic Autoencoder (ELSA) with Weak Supervision to Model Hierarchical Brain Networks**
2404.10031v1 by Ammar Ahmed Pallikonda Latheef et.al.

Brain networks display a hierarchical organization, a complexity that poses a
challenge for existing deep learning models, often structured as flat
classifiers, leading to difficulties in interpretability and the 'black box'
issue. To bridge this gap, we propose a novel architecture: a symbolic
autoencoder informed by weak supervision and an Emergent Language (EL)
framework. This model moves beyond traditional flat classifiers by producing
hierarchical clusters and corresponding imagery, subsequently represented
through symbolic sentences to improve the clinical interpretability of
hierarchically organized data such as intrinsic brain networks, which can be
characterized using resting-state fMRI images. Our innovation includes a
generalized hierarchical loss function designed to ensure that both sentences
and images accurately reflect the hierarchical structure of functional brain
networks. This enables us to model functional brain networks from a broader
perspective down to more granular details. Furthermore, we introduce a
quantitative method to assess the hierarchical consistency of these symbolic
representations. Our qualitative analyses show that our model successfully
generates hierarchically organized, clinically interpretable images, a finding
supported by our quantitative evaluations. We find that our best performing
loss function leads to a hierarchical consistency of over 97% when identifying
images corresponding to brain networks. This approach not only advances the
interpretability of deep learning models in neuroimaging analysis but also
represents a significant step towards modeling the intricate hierarchical
nature of brain networks.

摘要：大腦網路顯示出一種層次結構，這種複雜性構成了
對現有深度學習模型的挑戰，通常結構為扁平化
分類器，導致解釋困難和“黑盒子”
問題。為了彌補這個差距，我們提出了一個新穎的架構：一個象徵性的架構
由弱監督和緊急語言（EL）通知的自動編碼器
框架。該模型超越了傳統的平面分類器，透過產生
分層集群和相應的圖像，隨後表示
透過象徵性句子來提高臨床可解釋性
分層組織的數據，例如內在的大腦網絡，可以
使用靜息態功能性磁振造影影像進行表徵。我們的創新包括
廣義層次損失函數旨在確保兩個句子
影像準確反映了大腦功能的層次結構
網路。這使我們能夠從更廣泛的角度對功能性大腦網路進行建模
透視到更細化的細節。此外，我們也介紹了一個
定量方法來評估這些符號的層次一致性
交涉。我們的定性分析顯示我們的模型成功
產生分層組織的、臨床可解釋的影像，這是一項發現
我們的定量評估支持。我們發現我們表現最好的
損失函數在辨識時導致層次一致性超過 97%
與大腦網路相對應的圖像。這種方法不僅推進了
深度學習模型在神經影像分析中的可解釋性
代表著邁向複雜的層次結構建模的重要一步
大腦網路的本質。

##### **Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration**
2404.09690v1 by Chenwei Lin et.al.

The emergence of Large Multimodal Models (LMMs) marks a significant milestone
in the development of artificial intelligence. Insurance, as a vast and complex
discipline, involves a wide variety of data forms in its operational processes,
including text, images, and videos, thereby giving rise to diverse multimodal
tasks. Despite this, there has been limited systematic exploration of
multimodal tasks specific to insurance, nor a thorough investigation into how
LMMs can address these challenges. In this paper, we explore GPT-4V's
capabilities in the insurance domain. We categorize multimodal tasks by
focusing primarily on visual aspects based on types of insurance (e.g., auto,
household/commercial property, health, and agricultural insurance) and
insurance stages (e.g., risk assessment, risk monitoring, and claims
processing). Our experiment reveals that GPT-4V exhibits remarkable abilities
in insurance-related tasks, demonstrating not only a robust understanding of
multimodal content in the insurance domain but also a comprehensive knowledge
of insurance scenarios. However, there are notable shortcomings: GPT-4V
struggles with detailed risk rating and loss assessment, suffers from
hallucination in image understanding, and shows variable support for different
languages. Through this work, we aim to bridge the insurance domain with
cutting-edge LMM technology, facilitate interdisciplinary exchange and
development, and provide a foundation for the continued advancement and
evolution of future research endeavors.

摘要：大型多模態模型 (LMM) 的出現標誌著一個重要的里程碑
在人工智慧的發展中。保險作為一個龐大而複雜的領域
學科，在其操作過程中涉及多種數據形式，
包括文字、圖像和視頻，從而產生多樣化的多模態
任務。儘管如此，對這方面的系統性探索仍然有限。
針對保險的多式聯運任務，也沒有徹底調查如何
LMM 可以應對這些挑戰。在本文中，我們探討了 GPT-4V
保險領域的能力。我們將多模式任務進行分類
主要關注基於保險類型的視覺方面（例如汽車、
家庭/商業財產、健康和農業保險）以及
保險階段（例如風險評估、風險監控和索賠
加工）。我們的實驗顯示 GPT-4V 表現出非凡的能力
在與保險相關的任務中，不僅表現出對
保險領域的多式聯運內容也是全面的知識
保險場景。然而，也有顯著的缺點：GPT-4V
難以進行詳細的風險評級和損失評估，遭受
圖像理解中的幻覺，並且對不同的情況顯示出不同的支持
語言。透過這項工作，我們的目標是在保險領域與
前沿的LMM技術，促進跨學科交流
的發展，為不斷進步奠定基礎
未來研究工作的演變。

##### **Privacy-Preserving Intrusion Detection using Convolutional Neural Networks**
2404.09625v1 by Martin Kodys et.al.

Privacy-preserving analytics is designed to protect valuable assets. A common
service provision involves the input data from the client and the model on the
analyst's side. The importance of the privacy preservation is fuelled by legal
obligations and intellectual property concerns. We explore the use case of a
model owner providing an analytic service on customer's private data. No
information about the data shall be revealed to the analyst and no information
about the model shall be leaked to the customer. Current methods involve costs:
accuracy deterioration and computational complexity. The complexity, in turn,
results in a longer processing time, increased requirement on computing
resources, and involves data communication between the client and the server.
In order to deploy such service architecture, we need to evaluate the optimal
setting that fits the constraints. And that is what this paper addresses. In
this work, we enhance an attack detection system based on Convolutional Neural
Networks with privacy-preserving technology based on PriMIA framework that is
initially designed for medical data.

摘要：隱私保護分析旨在保護寶貴的資產。普通的
服務提供涉及來自客戶端的輸入資料和模型
分析師這邊。法律推動了隱私保護的重要性
義務和智慧財產權問題。我們探討了一個用例
模型所有者為客戶的私人資料提供分析服務。不
有關數據的資訊應向分析人員透露，並且不得透露任何信息
有關型號的資訊應洩漏給客戶。目前的方法涉及成本：
精度惡化和計算複雜性。反過來，複雜性
導致處理時間更長，對計算的要求增加
資源，並涉及客戶端和伺服器之間的資料通訊。
為了部署這樣的服務架構，我們需要評估最優的
符合約束條件的設定。這就是本文所要解決的問題。在
這項工作，我們增強了基於卷積神經網路的攻擊檢測系統
基於 PriMIA 框架的隱私保護技術網絡
最初是為醫療數據而設計的。

##### **Efficient and accurate neural field reconstruction using resistive memory**
2404.09613v1 by Yifei Yu et.al.

Human beings construct perception of space by integrating sparse observations
into massively interconnected synapses and neurons, offering a superior
parallelism and efficiency. Replicating this capability in AI finds wide
applications in medical imaging, AR/VR, and embodied AI, where input data is
often sparse and computing resources are limited. However, traditional signal
reconstruction methods on digital computers face both software and hardware
challenges. On the software front, difficulties arise from storage
inefficiencies in conventional explicit signal representation. Hardware
obstacles include the von Neumann bottleneck, which limits data transfer
between the CPU and memory, and the limitations of CMOS circuits in supporting
parallel processing. We propose a systematic approach with software-hardware
co-optimizations for signal reconstruction from sparse inputs. Software-wise,
we employ neural field to implicitly represent signals via neural networks,
which is further compressed using low-rank decomposition and structured
pruning. Hardware-wise, we design a resistive memory-based computing-in-memory
(CIM) platform, featuring a Gaussian Encoder (GE) and an MLP Processing Engine
(PE). The GE harnesses the intrinsic stochasticity of resistive memory for
efficient input encoding, while the PE achieves precise weight mapping through
a Hardware-Aware Quantization (HAQ) circuit. We demonstrate the system's
efficacy on a 40nm 256Kb resistive memory-based in-memory computing macro,
achieving huge energy efficiency and parallelism improvements without
compromising reconstruction quality in tasks like 3D CT sparse reconstruction,
novel view synthesis, and novel view synthesis for dynamic scenes. This work
advances the AI-driven signal restoration technology and paves the way for
future efficient and robust medical AI and 3D vision applications.

摘要：人類透過整合稀疏的觀察來建構空間感知
成大規模互連的突觸和神經元，提供了優越的
並行性和效率。在人工智慧中複製這種能力發現了廣泛的應用
醫學影像、AR/VR 和嵌入式 AI 中的應用，其中輸入資料是
通常稀疏且計算資源有限。然而，傳統訊號
數位計算機的重構方法同時面向軟體和硬體
挑戰。在軟體方面，困難來自於存儲
傳統的顯式訊號表示效率低。硬體
障礙包括馮諾依曼瓶頸，它限制了資料傳輸
CPU 和記憶體之間的關係，以及 CMOS 電路在支援方面的局限性
並行處理。我們提出了一種軟體硬體系統化方法
從稀疏輸入進行訊號重建的協同優化。軟體方面，
我們使用神經場透過神經網路隱式表示訊號，
使用低秩分解進一步壓縮並結構化
修剪。硬體方面，我們設計了基於電阻記憶體的記憶體計算
(CIM) 平台，具有高斯編碼器 (GE) 和 MLP 處理引擎
（體育）。 GE 利用電阻記憶體固有的隨機性
高效率的輸入編碼，而PE透過以下方式實現精確的權重映射
硬體感知量化 (HAQ) 電路。我們展示了該系統的
基於 40nm 256Kb 電阻式記憶體的記憶體計算巨集的功效，
實現巨大的能源效率和並行性改進，而無需
影響 3D CT 稀疏重建等任務的重建質量，
新穎的視圖合成，以及動態場景的新穎的視圖合成。這部作品
推進人工智慧驅動的訊號恢復技術，為
未來高效、強大的醫療人工智慧和 3D 視覺應用。

##### **WiTUnet: A U-Shaped Architecture Integrating CNN and Transformer for Improved Feature Alignment and Local Information Fusion**
2404.09533v1 by Bin Wang et.al.

Low-dose computed tomography (LDCT) has become the technology of choice for
diagnostic medical imaging, given its lower radiation dose compared to standard
CT, despite increasing image noise and potentially affecting diagnostic
accuracy. To address this, advanced deep learning-based LDCT denoising
algorithms have been developed, primarily using Convolutional Neural Networks
(CNNs) or Transformer Networks with the Unet architecture. This architecture
enhances image detail by integrating feature maps from the encoder and decoder
via skip connections. However, current methods often overlook enhancements to
the Unet architecture itself, focusing instead on optimizing encoder and
decoder structures. This approach can be problematic due to the significant
differences in feature map characteristics between the encoder and decoder,
where simple fusion strategies may not effectively reconstruct images.In this
paper, we introduce WiTUnet, a novel LDCT image denoising method that utilizes
nested, dense skip pathways instead of traditional skip connections to improve
feature integration. WiTUnet also incorporates a windowed Transformer structure
to process images in smaller, non-overlapping segments, reducing computational
load. Additionally, the integration of a Local Image Perception Enhancement
(LiPe) module in both the encoder and decoder replaces the standard multi-layer
perceptron (MLP) in Transformers, enhancing local feature capture and
representation. Through extensive experimental comparisons, WiTUnet has
demonstrated superior performance over existing methods in key metrics such as
Peak Signal-to-Noise Ratio (PSNR), Structural Similarity (SSIM), and Root Mean
Square Error (RMSE), significantly improving noise removal and image quality.

摘要：低劑量電腦斷層掃描（LDCT）已成為首選技術
診斷醫學影像，由於其輻射劑量低於標準
CT，儘管影像雜訊增加並可能影響診斷
準確性。為了解決這個問題，基於深度學習的先進 LDCT 去噪
演算法已經開發出來，主要使用卷積神經網絡
(CNN) 或具有 Unet 架構的 Transformer Networks。這種架構
透過整合編碼器和解碼器的特徵圖來增強影像細節
透過跳過連接。然而，目前的方法經常忽略對
Unet 架構本身，而是專注於最佳化編碼器和
解碼器結構。由於顯著的
編碼器和解碼器之間特徵圖特徵的差異，
簡單的融合策略可能無法有效地重建影像。
論文中，我們介紹了 WiTUnet，一種新穎的 LDCT 影像去雜訊方法，該方法利用
嵌套的、密集的跳躍路徑而不是傳統的跳躍連結來改進
功能整合。 WiTUnet 也採用了視窗 Transformer 結構
以較小的、不重疊的片段處理影像，減少計算量
載入.此外，還整合了局部影像感知增強功能
編碼器和解碼器中的 (LiPe) 模組取代了標準多層
變形金剛中的感知器（MLP），增強局部特徵捕捉和
表示。透過大量的實驗比較，WiTUnet
在關鍵指標上表現出優於現有方法的性能，例如
峰值訊號雜訊比 (PSNR)、結構相似性 (SSIM) 和平均值根
平方誤差 (RMSE)，顯著提高雜訊去除和影像品質。

##### **Weight Copy and Low-Rank Adaptation for Few-Shot Distillation of Vision Transformers**
2404.09326v2 by Diana-Nicoleta Grigore et.al.

Few-shot knowledge distillation recently emerged as a viable approach to
harness the knowledge of large-scale pre-trained models, using limited data and
computational resources. In this paper, we propose a novel few-shot feature
distillation approach for vision transformers. Our approach is based on two key
steps. Leveraging the fact that vision transformers have a consistent
depth-wise structure, we first copy the weights from intermittent layers of
existing pre-trained vision transformers (teachers) into shallower
architectures (students), where the intermittence factor controls the
complexity of the student transformer with respect to its teacher. Next, we
employ an enhanced version of Low-Rank Adaptation (LoRA) to distill knowledge
into the student in a few-shot scenario, aiming to recover the information
processing carried out by the skipped teacher layers. We present comprehensive
experiments with supervised and self-supervised transformers as teachers, on
five data sets from various domains, including natural, medical and satellite
images. The empirical results confirm the superiority of our approach over
competitive baselines. Moreover, the ablation results demonstrate the
usefulness of each component of the proposed pipeline.

摘要：最近出現的小樣本知識蒸餾是可行的方法
利用有限的數據和大規模預訓練模型的知識
計算資源。在本文中，我們提出了一種新穎的少樣本特徵
視覺變壓器的蒸餾方法。我們的方法基於兩個關鍵
腳步。利用視覺轉換器具有一致的事實
深度結構，我們先從間歇層複製權重
將現有的預訓練視覺變換器（教師）轉化為更淺層的視覺變換器
架構（學生），其中間歇因子控制
學生變壓器相對於其老師的複雜性。接下來，我們
採用增強版的低秩適應 (LoRA) 來擷取知識
在幾次場景中進入學生，旨在恢復訊息
由跳過的教師層執行的處理。我們呈現全面的
以監督和自監督變壓器為教師的實驗
來自不同領域的五個資料集，包括自然、醫學和衛星
圖片。實證結果證實了我們的方法優於
競爭基線。此外，消融結果表明
擬議管道中每個組件的有用性。

##### **Characterizing Soft-Error Resiliency in Arm's Ethos-U55 Embedded Machine Learning Accelerator**
2404.09317v1 by Abhishek Tyagi et.al.

As Neural Processing Units (NPU) or accelerators are increasingly deployed in
a variety of applications including safety critical applications such as
autonomous vehicle, and medical imaging, it is critical to understand the
fault-tolerance nature of the NPUs. We present a reliability study of Arm's
Ethos-U55, an important industrial-scale NPU being utilised in embedded and IoT
applications. We perform large scale RTL-level fault injections to characterize
Ethos-U55 against the Automotive Safety Integrity Level D (ASIL-D) resiliency
standard commonly used for safety-critical applications such as autonomous
vehicles. We show that, under soft errors, all four configurations of the NPU
fall short of the required level of resiliency for a variety of neural networks
running on the NPU. We show that it is possible to meet the ASIL-D level
resiliency without resorting to conventional strategies like Dual Core Lock
Step (DCLS) that has an area overhead of 100%. We achieve so through selective
protection, where hardware structures are selectively protected (e.g.,
duplicated, hardened) based on their sensitivity to soft errors and their
silicon areas. To identify the optimal configuration that minimizes the area
overhead while meeting the ASIL-D standard, the main challenge is the large
search space associated with the time-consuming RTL simulation. To address this
challenge, we present a statistical analysis tool that is validated against Arm
silicon and that allows us to quickly navigate hundreds of billions of fault
sites without exhaustive RTL fault injections. We show that by carefully
duplicating a small fraction of the functional blocks and hardening the Flops
in other blocks meets the ASIL-D safety standard while introducing an area
overhead of only 38%.

摘要：隨著神經處理單元 (NPU) 或加速器越來越多地部署在
各種應用，包括安全關鍵應用，例如
自動駕駛汽車和醫學成像，了解這一點至關重要
NPU 的容錯特性。我們提出了 Arm 的可靠性研究
Ethos-U55，一種重要的工業級 NPU，應用於嵌入式和物聯網
應用程式.我們執行大規模 RTL 級故障注入來表徵
Ethos-U55 針對汽車安全完整性等級 D (ASIL-D) 彈性
標準通常用於安全關鍵型應用，例如自動駕駛
汽車。我們證明，在軟錯誤下，NPU 的所有四種配置
達不到各種神經網路所需的彈性水平
運行在NPU上。我們證明可以達到 ASIL-D 級別
無需訴諸雙核鎖等傳統策略即可實現彈性
面積開銷為 100% 的步驟 (DCLS)。我們透過選擇性地實現這一目標
保護，其中硬體結構受到選擇性保護（例如，
重複的、硬化的）是基於它們對軟錯誤的敏感度及其
矽區域。確定最小化面積的最佳配置
在滿足 ASIL-D 標準的同時，主要挑戰是開銷大
與耗時的 RTL 模擬相關的搜尋空間。為了解決這個問題
挑戰，我們提出了一個針對 Arm 驗證的統計分析工具
矽使我們能夠快速解決數千億個故障
沒有詳盡的 RTL 故障注入的站點。我們透過仔細證明
複製一小部分功能塊並強化 Flops
其他區塊符合 ASIL-D 安全標準，同時引入一個區域
開銷僅38%。

##### **TLDR at SemEval-2024 Task 2: T5-generated clinical-Language summaries for DeBERTa Report Analysis**
2404.09136v1 by Spandan Das et.al.

This paper introduces novel methodologies for the Natural Language Inference
for Clinical Trials (NLI4CT) task. We present TLDR (T5-generated
clinical-Language summaries for DeBERTa Report Analysis) which incorporates
T5-model generated premise summaries for improved entailment and contradiction
analysis in clinical NLI tasks. This approach overcomes the challenges posed by
small context windows and lengthy premises, leading to a substantial
improvement in Macro F1 scores: a 0.184 increase over truncated premises. Our
comprehensive experimental evaluation, including detailed error analysis and
ablations, confirms the superiority of TLDR in achieving consistency and
faithfulness in predictions against semantically altered inputs.

摘要：本文介紹了自然語言推理的新方法
臨床試驗（NLI4CT）任務。我們提出 TLDR（T5 產生的
DeBERTa 報告分析的臨床語言摘要）其中包含
T5 模型生成前提摘要以改善蘊涵和矛盾
臨床 NLI 任務中的分析。這種方法克服了以下挑戰
小上下文視窗和冗長的前提，導致大量
Macro F1 分數的改進：比截斷的前提提高了 0.184。我們的
全面的實驗評估，包括詳細的誤差分析和
消融，證實了 TLDR 在達到一致性和
對語意改變輸入的預測的忠實度。

##### **Advanced Neural Network Architecture for Enhanced Multi-Lead ECG Arrhythmia Detection through Optimized Feature Extraction**
2404.15347v1 by Bhavith Chandra Challagundla et.al.

Cardiovascular diseases are a pervasive global health concern, contributing
significantly to morbidity and mortality rates worldwide. Among these
conditions, arrhythmia, characterized by irregular heart rhythms, presents
formidable diagnostic challenges. This study introduces an innovative approach
utilizing deep learning techniques, specifically Convolutional Neural Networks
(CNNs), to address the complexities of arrhythmia classification. Leveraging
multi-lead Electrocardiogram (ECG) data, our CNN model, comprising six layers
with a residual block, demonstrates promising outcomes in identifying five
distinct heartbeat types: Left Bundle Branch Block (LBBB), Right Bundle Branch
Block (RBBB), Atrial Premature Contraction (APC), Premature Ventricular
Contraction (PVC), and Normal Beat. Through rigorous experimentation, we
highlight the transformative potential of our methodology in enhancing
diagnostic accuracy for cardiovascular arrhythmias. Arrhythmia diagnosis
remains a critical challenge in cardiovascular care, often relying on manual
interpretation of ECG signals, which can be time-consuming and prone to
subjectivity. To address these limitations, we propose a novel approach that
leverages deep learning algorithms to automate arrhythmia classification. By
employing advanced CNN architectures and multi-lead ECG data, our methodology
offers a robust solution for precise and efficient arrhythmia detection.
Through comprehensive evaluation, we demonstrate the effectiveness of our
approach in facilitating more accurate clinical decision-making, thereby
improving patient outcomes in managing cardiovascular arrhythmias.

摘要：心血管疾病是一個普遍存在的全球健康問題，
對全世界的發病率和死亡率有顯著影響。在這些當中
心律不整，以心律不整為特徵，表現為
巨大的診斷挑戰。這項研究引入了一種創新方法
利用深度學習技術，特別是卷積神經網絡
（CNN），解決心律不整分類的複雜性。槓桿作用
多導聯心電圖 (ECG) 數據，我們的 CNN 模型，包含六層
帶有殘餘塊，在識別五個方面展示了有希望的結果
不同的心跳類型：左束支傳導阻滯 (LBBB)、右束支傳導阻滯
傳導阻滯 (RBBB)、心房性早期心搏 (APC)、心室早期收縮
收縮 (PVC) 和正常節拍。透過嚴格的實驗，我們
強調我們的方法論在增強
心血管心律不整的診斷準確性。心律不整診斷
仍然是心血管護理的關鍵挑戰，通常依賴手動
心電圖訊號的解釋可能非常耗時且容易
主觀性。為了解決這些限制，我們提出了一種新方法
利用深度學習演算法自動進行心律不整分類。經過
我們的方法採用先進的 CNN 架構和多導聯心電圖數據
為精確、高效的心律不整檢測提供強大的解決方案。
透過綜合評估，我們展示了我們的有效性
方法促進更準確的臨床決策，從而
改善心血管心律不整的患者治療效果。

##### **Adapting Mental Health Prediction Tasks for Cross-lingual Learning via Meta-Training and In-context Learning with Large Language Model**
2404.09045v1 by Zita Lifelo et.al.

Timely identification is essential for the efficient handling of mental
health illnesses such as depression. However, the current research fails to
adequately address the prediction of mental health conditions from social media
data in low-resource African languages like Swahili. This study introduces two
distinct approaches utilising model-agnostic meta-learning and leveraging large
language models (LLMs) to address this gap. Experiments are conducted on three
datasets translated to low-resource language and applied to four mental health
tasks, which include stress, depression, depression severity and suicidal
ideation prediction. we first apply a meta-learning model with
self-supervision, which results in improved model initialisation for rapid
adaptation and cross-lingual transfer. The results show that our meta-trained
model performs significantly better than standard fine-tuning methods,
outperforming the baseline fine-tuning in macro F1 score with 18\% and 0.8\%
over XLM-R and mBERT. In parallel, we use LLMs' in-context learning
capabilities to assess their performance accuracy across the Swahili mental
health prediction tasks by analysing different cross-lingual prompting
approaches. Our analysis showed that Swahili prompts performed better than
cross-lingual prompts but less than English prompts. Our findings show that
in-context learning can be achieved through cross-lingual transfer through
carefully crafted prompt templates with examples and instructions.

摘要：及時識別對於有效處理心理問題至關重要
憂鬱症等健康疾病。然而，目前的研究未能
充分解決社群媒體對心理健康狀況的預測
斯瓦希里語等資源匱乏的非洲語言的資料。本研究介紹了兩個
利用與模型無關的元學習和利用大規模的不同方法
語言模型（LLM）可以彌補這一差距。實驗在三個上進行
資料集翻譯成低資源語言並應用於四種心理健康
任務，包括壓力、憂鬱、憂鬱嚴重程度和自殺傾向
構想預測。我們首先應用元學習模型
自我監督，從而改進模型初始化以實現快速
適應和跨語言遷移。結果顯示我們的元訓練
模型的性能明顯優於標準微調方法，
宏 F1 分數優於基線微調，分別為 18\% 與 0.8\%
超過 XLM-R 和 mBERT。同時，我們使用法學碩士的情境學習
評估他們在斯瓦希里語心理中的表現準確性的能力
透過分析不同的跨語言提示來完成健康預測任務
接近。我們的分析表明，斯瓦希里語提示的效果優於
跨語言提示但少於英文提示。我們的研究結果表明
情境學習可以透過跨語言遷移來實現
精心製作的提示模板，包含範例和說明。

##### **A Fourier-enhanced multi-modal 3D small object optical mark recognition and positioning method for percutaneous abdominal puncture surgical navigation**
2404.08990v1 by Zezhao Guo et.al.

Navigation for thoracoabdominal puncture surgery is used to locate the needle
entry point on the patient's body surface. The traditional reflective ball
navigation method is difficult to position the needle entry point on the soft,
irregular, smooth chest and abdomen. Due to the lack of clear characteristic
points on the body surface using structured light technology, it is difficult
to identify and locate arbitrary needle insertion points. Based on the high
stability and high accuracy requirements of surgical navigation, this paper
proposed a novel method, a muti-modal 3D small object medical marker detection
method, which identifies the center of a small single ring as the needle
insertion point. Moreover, this novel method leverages Fourier transform
enhancement technology to augment the dataset, enrich image details, and
enhance the network's capability. The method extracts the Region of Interest
(ROI) of the feature image from both enhanced and original images, followed by
generating a mask map. Subsequently, the point cloud of the ROI from the depth
map is obtained through the registration of ROI point cloud contour fitting. In
addition, this method employs Tukey loss for optimal precision. The
experimental results show this novel method proposed in this paper not only
achieves high-precision and high-stability positioning, but also enables the
positioning of any needle insertion point.

摘要：胸腹穿刺手術中的導航用於定位針頭
患者體表的進入點。傳統反光球
導航方法很難將進針點定位在軟體上，
胸部和腹部不規則、光滑。由於缺乏明確的特徵
利用結構光技術在體表上點，很難
識別和定位任意針插入點。立足於高
手術導航的穩定性和高精度要求，本文
提出了一種新方法，多模態 3D 小物體醫學標記檢測
方法，將小單環的中心識別為針
插入點。此外，這種新穎的方法利用了傅立葉變換
增強技術來增強資料集、豐富影像細節，以及
提升網路能力。此方法提取感興趣區域
（ROI）來自增強影像和原始影像的特徵影像，然後是
生成掩模圖。隨後，深度的 ROI 的點雲
透過ROI點雲輪廓擬合配準得到地圖。在
此外，該方法採用 Tukey 損失來獲得最佳精確度。這
實驗結果顯示本文所提出的這種新方法不僅
實現了高精度、高穩定性的定位，同時也使得
任何針插入點的定位。

##### **Leveraging Large Language Model as Simulated Patients for Clinical Education**
2404.13066v2 by Yanzeng Li et.al.

Simulated Patients (SPs) play a crucial role in clinical medical education by
providing realistic scenarios for student practice. However, the high cost of
training and hiring qualified SPs, along with the heavy workload and potential
risks they face in consistently portraying actual patients, limit students'
access to this type of clinical training. Consequently, the integration of
computer program-based simulated patients has emerged as a valuable educational
tool in recent years. With the rapid development of Large Language Models
(LLMs), their exceptional capabilities in conversational artificial
intelligence and role-playing have been demonstrated, making them a feasible
option for implementing Virtual Simulated Patient (VSP). In this paper, we
present an integrated model-agnostic framework called CureFun that harnesses
the potential of LLMs in clinical medical education. This framework facilitates
natural conversations between students and simulated patients, evaluates their
dialogue, and provides suggestions to enhance students' clinical inquiry
skills. Through comprehensive evaluations, our approach demonstrates more
authentic and professional SP-scenario dialogue flows compared to other
LLM-based chatbots, thus proving its proficiency in simulating patients.
Additionally, leveraging CureFun's evaluation ability, we assess several
medical LLMs and discuss the possibilities and limitations of using LLMs as
virtual doctors from the perspective of their diagnostic abilities.

摘要：模擬患者 (SP) 在臨床醫學教育中發揮著至關重要的作用
為學生練習提供真實的場景。然而，高昂的成本
培訓和聘用合格的SP，工作量大，潛力大
他們在持續描繪真實患者時面臨的風險，限制了學生的
獲得此類臨床培訓。因此，整合
基於電腦程式的模擬患者已成為一種有價值的教育手段
近年來的工具。隨著大型語言模式的快速發展
（法學碩士），他們在對話人工方面的卓越能力
智力和角色扮演已經被證明，使它們成為可行的
用於實施虛擬模擬患者 (VSP) 的選項。在本文中，我們
提出了一個名為 CureFun 的整合模型不可知框架，該框架利用
法學碩士在臨床醫學教育中的潛力。此框架有利於
學生和模擬患者之間的自然對話，評估他們的
對話，並為加強學生的臨床探究提供建議
技能。透過綜合評估，我們的方法展示了更多
與其他對話流程相比，真實且專業的SP場景對話流程
基於法學碩士的聊天機器人，從而證明了其在模擬患者方面的熟練程度。
此外，利用 CureFun 的評估能力，我們評估了幾個
醫學法學碩士並討論使用法學碩士作為
虛擬醫生從診斷能力的角度來看。

##### **Is ChatGPT Transforming Academics' Writing Style?**
2404.08627v1 by Mingmeng Geng et.al.

Based on one million arXiv papers submitted from May 2018 to January 2024, we
assess the textual density of ChatGPT's writing style in their abstracts by
means of a statistical analysis of word frequency changes. Our model is
calibrated and validated on a mixture of real abstracts and ChatGPT-modified
abstracts (simulated data) after a careful noise analysis. We find that ChatGPT
is having an increasing impact on arXiv abstracts, especially in the field of
computer science, where the fraction of ChatGPT-revised abstracts is estimated
to be approximately 35%, if we take the output of one of the simplest prompts,
"revise the following sentences", as a baseline. We conclude with an analysis
of both positive and negative aspects of the penetration of ChatGPT into
academics' writing style.

摘要：基於 2018 年 5 月至 2024 年 1 月提交的 100 萬篇 arXiv 論文，我們
透過以下方式評估 ChatGPT 在摘要中的寫作風格的文本密度
對詞頻變化進行統計分析的手段。我們的模型是
在真實摘要和 ChatGPT 修改的混合物上進行校準和驗證
經過仔細的噪音分析後的摘要（模擬數據）。我們發現ChatGPT
對 arXiv 摘要的影響越來越大，特別是在
計算機科學，估計 ChatGPT 修訂摘要的比例
如果我們採用最簡單的提示之一的輸出，則約為 35%，
“修改以下句子”，作為基線。我們透過分析得出結論
ChatGPT 滲透的正面和負面方面
學者的寫作風格。

##### **Automatic Quantification of Serial PET/CT Images for Pediatric Hodgkin Lymphoma Patients Using a Longitudinally-Aware Segmentation Network**
2404.08611v1 by Xin Tie et.al.

$\textbf{Purpose}$: Automatic quantification of longitudinal changes in PET
scans for lymphoma patients has proven challenging, as residual disease in
interim-therapy scans is often subtle and difficult to detect. Our goal was to
develop a longitudinally-aware segmentation network (LAS-Net) that can quantify
serial PET/CT images for pediatric Hodgkin lymphoma patients.
$\textbf{Materials and Methods}$: This retrospective study included baseline
(PET1) and interim (PET2) PET/CT images from 297 patients enrolled in two
Children's Oncology Group clinical trials (AHOD1331 and AHOD0831). LAS-Net
incorporates longitudinal cross-attention, allowing relevant features from PET1
to inform the analysis of PET2. Model performance was evaluated using Dice
coefficients for PET1 and detection F1 scores for PET2. Additionally, we
extracted and compared quantitative PET metrics, including metabolic tumor
volume (MTV) and total lesion glycolysis (TLG) in PET1, as well as qPET and
$\Delta$SUVmax in PET2, against physician measurements. We quantified their
agreement using Spearman's $\rho$ correlations and employed bootstrap
resampling for statistical analysis. $\textbf{Results}$: LAS-Net detected
residual lymphoma in PET2 with an F1 score of 0.606 (precision/recall:
0.615/0.600), outperforming all comparator methods (P<0.01). For baseline
segmentation, LAS-Net achieved a mean Dice score of 0.772. In PET
quantification, LAS-Net's measurements of qPET, $\Delta$SUVmax, MTV and TLG
were strongly correlated with physician measurements, with Spearman's $\rho$ of
0.78, 0.80, 0.93 and 0.96, respectively. The performance remained high, with a
slight decrease, in an external testing cohort. $\textbf{Conclusion}$: LAS-Net
achieved high performance in quantifying PET metrics across serial scans,
highlighting the value of longitudinal awareness in evaluating multi-time-point
imaging datasets.

摘要：$\textbf{目的}$：PET縱向變化的自動量化
事實證明，對淋巴瘤患者進行掃描具有挑戰性，因為殘留病灶
中期治療掃描通常很微妙且難以檢測。我們的目標是
開發一個縱向感知分割網路（LAS-Net），可以量化
兒科霍奇金淋巴瘤患者的一系列 PET/CT 影像。
$\textbf{材料和方法}$：這項回顧性研究包括基線
(PET1) 和中期 (PET2) PET/CT 影像，來自 297 名入組的患者
兒童腫瘤學組臨床試驗（AHOD1331 和 AHOD0831）。 LAS網絡
結合了縱向交叉注意力，允許來自 PET1 的相關特徵
為 PET2 的分析提供資訊。使用 Dice 評估模型性能
PET1 的係數和 PET2 的檢測 F1 分數。此外，我們
擷取並比較定量 PET 指標，包括代謝腫瘤
PET1 中的體積 (MTV) 和總病變糖解 (TLG)，以及 qPET 和
PET2 中的 $\Delta$SUVmax，與醫師測量結果相反。我們量化了他們的
使用 Spearman 的 $\rho$ 相關性和採用的 bootstrap 達成一致
重新採樣以進行統計分析。 $\textbf{結果}$: 偵測到 LAS-Net
PET2 殘留淋巴瘤，F1 評分為 0.606（精確度/召回率：
0.615/0.600)，優於所有比較方法 (P<0.01)。對於基線
分割時，LAS-Net 的平均 Dice 得分為 0.772。在PET中
量化、LAS-Net 對 qPET、$\Delta$SUVmax、MTV 和 TLG 的測量
與醫生測量值密切相關，斯皮爾曼的 $\rho$ 為
分別為 0.78、0.80、0.93 和 0.96。業績仍保持高位，
在外部測試佇列中略有下降。 $\textbf{結論}$: LAS-Net
在連續掃描中量化 PET 指標方面取得了高效能，
強調縱向意識在評估多時間點的價值
成像資料集。

##### **RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs**
2404.08555v2 by Shreyas Chaudhari et.al.

State-of-the-art large language models (LLMs) have become indispensable tools
for various tasks. However, training LLMs to serve as effective assistants for
humans requires careful consideration. A promising approach is reinforcement
learning from human feedback (RLHF), which leverages human feedback to update
the model in accordance with human preferences and mitigate issues like
toxicity and hallucinations. Yet, an understanding of RLHF for LLMs is largely
entangled with initial design choices that popularized the method and current
research focuses on augmenting those choices rather than fundamentally
improving the framework. In this paper, we analyze RLHF through the lens of
reinforcement learning principles to develop an understanding of its
fundamentals, dedicating substantial focus to the core component of RLHF -- the
reward model. Our study investigates modeling choices, caveats of function
approximation, and their implications on RLHF training algorithms, highlighting
the underlying assumptions made about the expressivity of reward. Our analysis
improves the understanding of the role of reward models and methods for their
training, concurrently revealing limitations of the current methodology. We
characterize these limitations, including incorrect generalization, model
misspecification, and the sparsity of feedback, along with their impact on the
performance of a language model. The discussion and analysis are substantiated
by a categorical review of current literature, serving as a reference for
researchers and practitioners to understand the challenges of RLHF and build
upon existing efforts.

摘要：最先進的大型語言模型（LLM）已成為不可或缺的工具
用於各種任務。然而，培訓法學碩士作為有效的助手
人類需要仔細考慮。一個有希望的方法是強化
從人類回饋中學習（RLHF），它利用人類回饋來更新
該模型符合人類偏好並緩解諸如
中毒和幻覺。然而，法學碩士對 RLHF 的理解很大程度上是
與推廣該方法和當前的最初設計選擇糾纏在一起
研究的重點是增加這些選擇，而不是從根本上
完善框架。在本文中，我們透過以下視角來分析 RLHF：
強化學習原理以加深對其的理解
基本面，重點在於 RLHF 的核心組成部分——
獎勵模型。我們的研究調查了模型選擇、功能注意事項
近似值及其對 RLHF 訓練演算法的影響，強調
關於獎勵表現力的基本假設。我們的分析
提高對獎勵模型和方法的作用的理解
培訓，同時揭示目前方法的局限性。我們
描述這些局限性，包括不正確的概括、模型
錯誤指定和回饋的稀疏性及其對
語言模型的效能。討論和分析有依據
透過現有文獻的分類回顧，作為參考
研究人員和從業者了解 RLHF 的挑戰並建立
依靠現有的努力。

##### **An improved tabular data generator with VAE-GMM integration**
2404.08434v1 by Patricia A. Apellániz et.al.

The rising use of machine learning in various fields requires robust methods
to create synthetic tabular data. Data should preserve key characteristics
while addressing data scarcity challenges. Current approaches based on
Generative Adversarial Networks, such as the state-of-the-art CTGAN model,
struggle with the complex structures inherent in tabular data. These data often
contain both continuous and discrete features with non-Gaussian distributions.
Therefore, we propose a novel Variational Autoencoder (VAE)-based model that
addresses these limitations. Inspired by the TVAE model, our approach
incorporates a Bayesian Gaussian Mixture model (BGM) within the VAE
architecture. This avoids the limitations imposed by assuming a strictly
Gaussian latent space, allowing for a more accurate representation of the
underlying data distribution during data generation. Furthermore, our model
offers enhanced flexibility by allowing the use of various differentiable
distributions for individual features, making it possible to handle both
continuous and discrete data types. We thoroughly validate our model on three
real-world datasets with mixed data types, including two medically relevant
ones, based on their resemblance and utility. This evaluation demonstrates
significant outperformance against CTGAN and TVAE, establishing its potential
as a valuable tool for generating synthetic tabular data in various domains,
particularly in healthcare.

摘要：機器學習在各個領域的使用不斷增加需要強大的方法
建立合成表格資料。資料應保留關鍵特徵
同時解決數據稀缺的挑戰。目前的方法是基於
生成對抗網絡，例如最先進的 CTGAN 模型，
與表格資料​​固有的複雜結構作鬥爭。這些數據經常
包含具有非高斯分佈的連續和離散特徵。
因此，我們提出了一種新穎的基於變分自動編碼器（VAE）的模型
解決了這些限制。受 TVAE 模型的啟發，我們的方法
在 VAE 中結合了貝葉斯高斯混合模型 (BGM)
建築學。這避免了嚴格假設所施加的限制
高斯潛在空間，可以更準確地表示
資料生成期間的底層資料分佈。此外，我們的模型
透過允許使用各種可微分來提供增強的靈活性
單一特徵的分佈，使得處理這兩個特徵成為可能
連續和離散資料類型。我們在三個方面徹底驗證了我們的模型
具有混合資料類型的現實世界資料集，包括兩個醫學相關的資料集
的，基於它們的相似性和實用性。此次評估表明
顯著優於 CTGAN 和 TVAE，確立了其潛力
作為在各個領域生成合成表格數據的有價值的工具，
特別是在醫療保健領域。

##### **Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval**
2404.08359v1 by Juraj Vladika et.al.

In today's digital world, seeking answers to health questions on the Internet
is a common practice. However, existing question answering (QA) systems often
rely on using pre-selected and annotated evidence documents, thus making them
inadequate for addressing novel questions. Our study focuses on the open-domain
QA setting, where the key challenge is to first uncover relevant evidence in
large knowledge bases. By utilizing the common retrieve-then-read QA pipeline
and PubMed as a trustworthy collection of medical research documents, we answer
health questions from three diverse datasets. We modify different retrieval
settings to observe their influence on the QA pipeline's performance, including
the number of retrieved documents, sentence selection process, the publication
year of articles, and their number of citations. Our results reveal that
cutting down on the amount of retrieved documents and favoring more recent and
highly cited documents can improve the final macro F1 score up to 10%. We
discuss the results, highlight interesting examples, and outline challenges for
future research, like managing evidence disagreement and crafting user-friendly
explanations.

摘要：在當今的數位世界中，在網路上尋求健康問題的答案
這是常見的做法。然而，現有的問答（QA）系統通常
依靠使用預先選擇和註釋的證據文件，從而使它們
不足以解決新問題。我們的研究重點是開放域
QA 設置，其中的關鍵挑戰是首先發現相關證據
龐大的知識庫。透過利用常見的檢索然後讀取 QA 管道
和 PubMed 作為值得信賴的醫學研究文獻集合，我們回答
來自三個不同數據集的健康問題。我們修改不同的檢索
設定以觀察它們對 QA 管道性能的影響，包括
檢索到的文件數量、句子選擇過程、出版物
文章年份及其被引用次數。我們的結果表明
減少檢索到的文檔數量並傾向於更新最近的文檔
被高引用的文獻可以將最終的宏 F1 分數提高最多 10%。我們
討論結果，突出有趣的例子，並概述挑戰
未來的研究，例如管理證據分歧和設計用戶友好型
解釋。

##### **Generating Synthetic Satellite Imagery With Deep-Learning Text-to-Image Models -- Technical Challenges and Implications for Monitoring and Verification**
2404.07754v1 by Tuong Vy Nguyen et.al.

Novel deep-learning (DL) architectures have reached a level where they can
generate digital media, including photorealistic images, that are difficult to
distinguish from real data. These technologies have already been used to
generate training data for Machine Learning (ML) models, and large
text-to-image models like DALL-E 2, Imagen, and Stable Diffusion are achieving
remarkable results in realistic high-resolution image generation. Given these
developments, issues of data authentication in monitoring and verification
deserve a careful and systematic analysis: How realistic are synthetic images?
How easily can they be generated? How useful are they for ML researchers, and
what is their potential for Open Science? In this work, we use novel DL models
to explore how synthetic satellite images can be created using conditioning
mechanisms. We investigate the challenges of synthetic satellite image
generation and evaluate the results based on authenticity and state-of-the-art
metrics. Furthermore, we investigate how synthetic data can alleviate the lack
of data in the context of ML methods for remote-sensing. Finally we discuss
implications of synthetic satellite imagery in the context of monitoring and
verification.

摘要：新穎的深度學習 (DL) 架構已達到可實現的水平
產生難以實現的數位媒體，包括照片級真實感影像
與真實數據區別。這些技術已經被用於
為機器學習 (ML) 模型產生訓練數據，以及大型
DALL-E 2、Imagen 和 Stable Diffusion 等文字到圖像模型正在實現
在逼真的高解析度影像生成方面取得了顯著的成果。鑑於這些
監測和核查中資料認證的發展、問題
值得仔細、有系統的分析：合成影像有多真實？
它們的生成有多容易？它們對機器學習研究人員有多大用處，以及
他們在開放科學方面的潛力是什麼？在這項工作中，我們使用新穎的深度學習模型
探索如何使用條件創建合成衛星影像
機制。我們研究合成衛星圖像的挑戰
根據真實性和最新技術生成和評估結果
指標。此外，我們研究了合成數據如何緩解缺乏
遙感機器學習方法背景下的數據。最後我們討論一下
合成衛星影像在監測和監測方面的影響
確認。

##### **Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain**
2404.07613v1 by Iker García-Ferrero et.al.

Research on language technology for the development of medical applications
is currently a hot topic in Natural Language Understanding and Generation.
Thus, a number of large language models (LLMs) have recently been adapted to
the medical domain, so that they can be used as a tool for mediating in
human-AI interaction. While these LLMs display competitive performance on
automated medical texts benchmarks, they have been pre-trained and evaluated
with a focus on a single language (English mostly). This is particularly true
of text-to-text models, which typically require large amounts of
domain-specific pre-training data, often not easily accessible for many
languages. In this paper, we address these shortcomings by compiling, to the
best of our knowledge, the largest multilingual corpus for the medical domain
in four languages, namely English, French, Italian and Spanish. This new corpus
has been used to train Medical mT5, the first open-source text-to-text
multilingual model for the medical domain. Additionally, we present two new
evaluation benchmarks for all four languages with the aim of facilitating
multilingual research in this domain. A comprehensive evaluation shows that
Medical mT5 outperforms both encoders and similarly sized text-to-text models
for the Spanish, French, and Italian benchmarks, while being competitive with
current state-of-the-art LLMs in English.

摘要：醫學應用開發的語言技術研究
是目前自然語言理解和生成領域的熱門話題。
因此，許多大型語言模型（LLM）最近已適應
醫學領域，以便它們可以用作調解的工具
人機互動。雖然這些法學碩士在以下方面表現出有競爭力的表現
自動化醫學文本基準，它們已經過預先訓練和評估
專注於單一語言（主要是英語）。這一點尤其正確
文字到文字模型，通常需要大量
特定領域的預訓練數據，通常對許多人來說不容易訪問
語言。在本文中，我們透過編譯來解決這些缺點
據我們所知，醫學領域最大的多語言語料庫
四種語言，分別是英語、法語、義大利語和西班牙語。這個新語料庫
已用於訓練 Medical mT5，第一個開源文本到文本
醫學領域的多語言模型。此外，我們也推出了兩款新產品
所有四種語言的評估基準，旨在促進
該領域的多語言研究。綜合評估表明
醫療 mT5 的表現優於編碼器和類似大小的文字到文字模型
西班牙、法國和義大利基準，同時具有競爭力
目前最先進的英語法學碩士。

##### **Contrastive-Based Deep Embeddings for Label Noise-Resilient Histopathology Image Classification**
2404.07605v1 by Lucas Dedieu et.al.

Recent advancements in deep learning have proven highly effective in medical
image classification, notably within histopathology. However, noisy labels
represent a critical challenge in histopathology image classification, where
accurate annotations are vital for training robust deep learning models.
Indeed, deep neural networks can easily overfit label noise, leading to severe
degradations in model performance. While numerous public pathology foundation
models have emerged recently, none have evaluated their resilience to label
noise. Through thorough empirical analyses across multiple datasets, we exhibit
the label noise resilience property of embeddings extracted from foundation
models trained in a self-supervised contrastive manner. We demonstrate that
training with such embeddings substantially enhances label noise robustness
when compared to non-contrastive-based ones as well as commonly used
noise-resilient methods. Our results unequivocally underline the superiority of
contrastive learning in effectively mitigating the label noise challenge. Code
is publicly available at
https://github.com/LucasDedieu/NoiseResilientHistopathology.

摘要：深度學習的最新進展已被證明在醫學領域非常有效
影像分類，尤其是組織病理學領域的影像分類。然而，嘈雜的標籤
代表了組織病理學圖像分類中的一個關鍵挑戰，其中
準確的註釋對於訓練強大的深度學習模型至關重要。
事實上，深度神經網路很容易過度擬合標籤噪聲，導致嚴重的問題
模型性能下降。雖然許多公共病理學基金會
最近出現了一些模型，但沒有人評估它們的標籤適應能力
噪音。透過對多個資料集進行徹底的實證分析，我們展示了
從基礎中提取的嵌入的標籤雜訊恢復屬性
以自我監督對比方式訓練的模式。我們證明
使用這種嵌入進行訓練大大增強了標籤雜訊的穩健性
與非對比性的以及常用的相比
抗噪聲方法。我們的結果明確地強調了
對比學習有效緩解標籤噪音挑戰。程式碼
公開於
https://github.com/LucasDedieu/NoiseResilientHistopathology。

##### **Socially Pertinent Robots in Gerontological Healthcare**
2404.07560v1 by Xavier Alameda-Pineda et.al.

Despite the many recent achievements in developing and deploying social
robotics, there are still many underexplored environments and applications for
which systematic evaluation of such systems by end-users is necessary. While
several robotic platforms have been used in gerontological healthcare, the
question of whether or not a social interactive robot with multi-modal
conversational capabilities will be useful and accepted in real-life facilities
is yet to be answered. This paper is an attempt to partially answer this
question, via two waves of experiments with patients and companions in a
day-care gerontological facility in Paris with a full-sized humanoid robot
endowed with social and conversational interaction capabilities. The software
architecture, developed during the H2020 SPRING project, together with the
experimental protocol, allowed us to evaluate the acceptability (AES) and
usability (SUS) with more than 60 end-users. Overall, the users are receptive
to this technology, especially when the robot perception and action skills are
robust to environmental clutter and flexible to handle a plethora of different
interactions.

摘要：儘管最近在開發和部署社會安全保障方面取得了許多成就
機器人技術仍有許多尚未開發的環境和應用
最終使用者對此類系統進行系統評估是必要的。儘管
多個機器人平台已用於老年保健、
社交互動機器人是否具有多模態的問題
對話功能將在現實生活設施中有用並被接受
尚待解答。本文試圖部分回答這個問題
透過對患者和同伴進行的兩波實驗來回答這個問題
巴黎的老人日間照顧中心配備全尺寸人形機器人
具有社交和對話互動能力。軟體
架構，在 H2020 SPRING 專案期間開發，與
實驗協議，使我們能夠評估可接受性（AES）和
可用性 (SUS) 超過 60 個最終使用者。整體來說，使用者的接受度還是不錯的
對於這項技術，尤其是當機器人的感知和動作技能
對環境雜亂具有穩健性，並且能夠靈活地處理多種不同的情況
互動。

##### **Introducing L2M3, A Multilingual Medical Large Language Model to Advance Health Equity in Low-Resource Regions**
2404.08705v1 by Agasthya Gangavarapu et.al.

Addressing the imminent shortfall of 10 million health workers by 2030,
predominantly in Low- and Middle-Income Countries (LMICs), this paper
introduces an innovative approach that harnesses the power of Large Language
Models (LLMs) integrated with machine translation models. This solution is
engineered to meet the unique needs of Community Health Workers (CHWs),
overcoming language barriers, cultural sensitivities, and the limited
availability of medical dialog datasets. I have crafted a model that not only
boasts superior translation capabilities but also undergoes rigorous
fine-tuning on open-source datasets to ensure medical accuracy and is equipped
with comprehensive safety features to counteract the risks of misinformation.
  Featuring a modular design, this approach is specifically structured for
swift adaptation across various linguistic and cultural contexts, utilizing
open-source components to significantly reduce healthcare operational costs.
This strategic innovation markedly improves the accessibility and quality of
healthcare services by providing CHWs with contextually appropriate medical
knowledge and diagnostic tools. This paper highlights the transformative impact
of this context-aware LLM, underscoring its crucial role in addressing the
global healthcare workforce deficit and propelling forward healthcare outcomes
in LMICs.

摘要：解決 2030 年即將面臨的 1,000 萬名衛生工作者短缺問題，
主要在低收入和中等收入國家 (LMIC)，本文
引進了一種利用大語言力量的創新方法
與機器翻譯模型整合的模型（法學碩士）。這個解決方案是
旨在滿足社區健康工作者 (CHW) 的獨特需求，
克服語言障礙、文化敏感度和有限性
醫療對話資料集的可用性。我製作了一個模型，不僅
擁有卓越的翻譯能力，但也經過嚴格的
對開源資料集進行微調，以確保醫療準確性並配備
具有全面的安全功能，可以抵消錯誤訊息的風險。
  此方法採用模組化設計，專門針對
快速適應不同的語言和文化背景，利用
開源元件可顯著降低醫療保健營運成本。
這項戰略創新顯著提高了訪問的可及性和質量
透過為社區健康工作者提供適合實際情況的醫療保健服務
知識和診斷工具。本文強調了變革性影響
這個情境意識的法學碩士，強調了它在解決問題中的關鍵作用
全球醫療保健勞動力短缺和推動醫療保健成果
在中低收入國家。

##### **Measuring proximity to standard planes during fetal brain ultrasound scanning**
2404.07124v1 by Chiara Di Vece et.al.

This paper introduces a novel pipeline designed to bring ultrasound (US)
plane pose estimation closer to clinical use for more effective navigation to
the standard planes (SPs) in the fetal brain. We propose a semi-supervised
segmentation model utilizing both labeled SPs and unlabeled 3D US volume
slices. Our model enables reliable segmentation across a diverse set of fetal
brain images. Furthermore, the model incorporates a classification mechanism to
identify the fetal brain precisely. Our model not only filters out frames
lacking the brain but also generates masks for those containing it, enhancing
the relevance of plane pose regression in clinical settings. We focus on fetal
brain navigation from 2D ultrasound (US) video analysis and combine this model
with a US plane pose regression network to provide sensorless proximity
detection to SPs and non-SPs planes; we emphasize the importance of proximity
detection to SPs for guiding sonographers, offering a substantial advantage
over traditional methods by allowing earlier and more precise adjustments
during scanning. We demonstrate the practical applicability of our approach
through validation on real fetal scan videos obtained from sonographers of
varying expertise levels. Our findings demonstrate the potential of our
approach to complement existing fetal US technologies and advance prenatal
diagnostic practices.

摘要：本文介紹了一種新穎的管道，旨在將超音波（美國）
平面位姿估計更接近臨床使用，以便更有效地導航
胎兒大腦中的標準平面（SP）。我們提出一個半監督的
利用標記 SP 和未標記 3D US 體積的分割模型
切片。我們的模型能夠對不同的胎兒進行可靠的分割
大腦影像。此外，該模型還結合了分類機制
準確辨識胎兒大腦。我們的模型不僅過濾掉幀
缺乏大腦，但也為那些含有大腦的人生成面具，增強
平面姿態迴歸在臨床環境中的相關性。我們專注於胎兒
透過 2D 超音波（美國）視訊分析進行大腦導航並結合該模型
與美國平面姿態回歸網路提供無感測器接近度
對 SP 和非 SP 平面的偵測；我們強調鄰近的重要性
對 SP 進行檢測以指導超音波檢查人員，提供了巨大的優勢
與傳統方法相比，允許更早、更精確的調整
掃描期間。我們展示了我們方法的實際適用性
透過對從超音波醫師那裡獲得的真實胎兒掃描影片進行驗證
不同的專業水平。我們的研究結果證明了我們的潛力
補充現有胎兒超音波技術並推進產前檢查的方法
診斷實踐。

##### **Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19 Case Study**
2404.06962v1 by Hongru Du et.al.

Forecasting the short-term spread of an ongoing disease outbreak is a
formidable challenge due to the complexity of contributing factors, some of
which can be characterized through interlinked, multi-modality variables such
as epidemiological time series data, viral biology, population demographics,
and the intersection of public policy and human behavior. Existing forecasting
model frameworks struggle with the multifaceted nature of relevant data and
robust results translation, which hinders their performances and the provision
of actionable insights for public health decision-makers. Our work introduces
PandemicLLM, a novel framework with multi-modal Large Language Models (LLMs)
that reformulates real-time forecasting of disease spread as a text reasoning
problem, with the ability to incorporate real-time, complex, non-numerical
information that previously unattainable in traditional forecasting models.
This approach, through a unique AI-human cooperative prompt design and time
series representation learning, encodes multi-modal data for LLMs. The model is
applied to the COVID-19 pandemic, and trained to utilize textual public health
policies, genomic surveillance, spatial, and epidemiological time series data,
and is subsequently tested across all 50 states of the U.S. Empirically,
PandemicLLM is shown to be a high-performing pandemic forecasting framework
that effectively captures the impact of emerging variants and can provide
timely and accurate predictions. The proposed PandemicLLM opens avenues for
incorporating various pandemic-related data in heterogeneous formats and
exhibits performance benefits over existing models. This study illuminates the
potential of adapting LLMs and representation learning to enhance pandemic
forecasting, illustrating how AI innovations can strengthen pandemic responses
and crisis management in the future.

摘要：預測正在發生的疾病爆發的短期傳播是一個
由於影響因素的複雜性，一些
可以透過相互關聯的多模態變數來表徵，例如
作為流行病學時間序列資料、病毒生物學、人口統計、
以及公共政策和人類行為的交叉點。現有預測
模型框架與相關數據的多方面性質作鬥爭，
強大的結果翻譯，這阻礙了他們的表現和規定
為公共衛生決策者提供可行的見解。我們的工作介紹
PandemicLLM，一種具有多模式大語言模型 (LLM) 的新穎框架
將疾病傳播的即時預測重新表述為文本推理
問題，能夠整合即時、複雜、非數位的
以前在傳統預測模型中無法獲得的資訊。
這種方法，透過獨特的AI-人類協作提示設計和時間
系列表示學習，為法學碩士編碼多模態資料。模型是
應用於 COVID-19 大流行，並接受過使用文本公共衛生的培訓
政策、基因組監測、空間和流行病學時間序列數據，
隨後在美國所有 50 個州進行了實證測試，
PandemicLLM 被證明是一個高效能的流行病預測框架
有效捕捉新興變體的影響，並可提供
及時準確的預測。擬議的 PandemicLLM 為
以異質格式整合各種流行病相關數據，
與現有型號相比表現出性能優勢。這項研究闡明了
調整法學碩士和代表性學習以增強流行病的潛力
預測，說明人工智慧創新如何加強流行病應對
以及未來的危機管理。

##### **SleepPPG-Net2: Deep learning generalization for sleep staging from photoplethysmography**
2404.06869v1 by Shirel Attia et.al.

Background: Sleep staging is a fundamental component in the diagnosis of
sleep disorders and the management of sleep health. Traditionally, this
analysis is conducted in clinical settings and involves a time-consuming
scoring procedure. Recent data-driven algorithms for sleep staging, using the
photoplethysmogram (PPG) time series, have shown high performance on local test
sets but lower performance on external datasets due to data drift. Methods:
This study aimed to develop a generalizable deep learning model for the task of
four class (wake, light, deep, and rapid eye movement (REM)) sleep staging from
raw PPG physiological time-series. Six sleep datasets, totaling 2,574 patients
recordings, were used. In order to create a more generalizable representation,
we developed and evaluated a deep learning model called SleepPPG-Net2, which
employs a multi-source domain training approach.SleepPPG-Net2 was benchmarked
against two state-of-the-art models. Results: SleepPPG-Net2 showed consistently
higher performance over benchmark approaches, with generalization performance
(Cohen's kappa) improving by up to 19%. Performance disparities were observed
in relation to age, sex, and sleep apnea severity. Conclusion: SleepPPG-Net2
sets a new standard for staging sleep from raw PPG time-series.

摘要：背景：睡眠分期是診斷的基本組成部分
睡眠障礙和睡眠健康管理。傳統上，這
分析是在臨床環境中進行的，涉及耗時的
評分程序。最近的數據驅動的睡眠分期演算法，使用
光電體積描記圖（PPG）時間序列，在本地測試中表現出高性能
集，但由於資料漂移，外部資料集的效能較低。方法：
本研究旨在發展一個可推廣的深度學習模型來完成以下任務：
四級（清醒、淺色、深度和快速動眼 (REM)）睡眠分期
原始 PPG 生理時間序列。六個睡眠資料集，總計 2,574 名患者
錄音，被使用。為了創建更通用的表示，
我們開發並評估了一個名為 SleepPPG-Net2 的深度學習模型，該模型
採用多源域訓練方法。
對抗兩種最先進的模型。結果：SleepPPG-Net2 顯示一致
比基準方法具有更高的性能，並具有泛化性能
（Cohen 的 kappa）提高高達 19%。觀察到績效差異
與年齡、性別和睡眠呼吸中止嚴重程度有關。結論：SleepPPG-Net2
為根據原始 PPG 時間序列劃分睡眠設定了新標準。

##### **Multi-Label Continual Learning for the Medical Domain: A Novel Benchmark**
2404.06859v2 by Marina Ceccon et.al.

Multi-label image classification in dynamic environments is a problem that
poses significant challenges. Previous studies have primarily focused on
scenarios such as Domain Incremental Learning and Class Incremental Learning,
which do not fully capture the complexity of real-world applications. In this
paper, we study the problem of classification of medical imaging in the
scenario termed New Instances and New Classes, which combines the challenges of
both new class arrivals and domain shifts in a single framework. Unlike
traditional scenarios, it reflects the realistic nature of CL in domains such
as medical imaging, where updates may introduce both new classes and changes in
domain characteristics. To address the unique challenges posed by this complex
scenario, we introduce a novel approach called Pseudo-Label Replay. This method
aims to mitigate forgetting while adapting to new classes and domain shifts by
combining the advantages of the Replay and Pseudo-Label methods and solving
their limitations in the proposed scenario. We evaluate our proposed approach
on a challenging benchmark consisting of two datasets, seven tasks, and
nineteen classes, modeling a realistic Continual Learning scenario. Our
experimental findings demonstrate the effectiveness of Pseudo-Label Replay in
addressing the challenges posed by the complex scenario proposed. Our method
surpasses existing approaches, exhibiting superior performance while showing
minimal forgetting.

摘要：動態環境下的多標籤影像分類是一個問題
帶來重大挑戰。先前的研究主要集中在
領域增量學習、類別增量學習等場景，
它沒有完全捕捉現實世界應用程式的複雜性。在這個
論文中，我們研究了醫學影像的分類問題
稱為新實例和新類別的場景，它結合了以下挑戰
新班級的到來和領域的轉變都在一個框架中。不像
傳統場景，它反映了 CL 在以下領域的現實本質：
作為醫學成像，更新可能會引入新的類別和變化
域特徵。為了解決這個綜合體帶來的獨特挑戰
在場景中，我們引入了一種稱為偽標籤重播的新穎方法。這個方法
旨在減少遺忘，同時適應新的類別和領域的轉變
結合Replay和Pseudo-Label方法的優點並求解
他們在提議的場景中的局限性。我們評估我們提出的方法
在一個具有挑戰性的基準上，該基準由兩個資料集、七個任務和
十九個班級，模擬現實的持續學習場景。我們的
實驗結果證明了偽標籤重播的有效性
解決所提出的複雜場景所帶來的挑戰。我們的方法
超越現有方法，展現卓越性能，同時展現
最小程度的遺忘。

##### **Accuracy of a Large Language Model in Distinguishing Anti- And Pro-vaccination Messages on Social Media: The Case of Human Papillomavirus Vaccination**
2404.06731v1 by Soojong Kim et.al.

Objective. Vaccination has engendered a spectrum of public opinions, with
social media acting as a crucial platform for health-related discussions. The
emergence of artificial intelligence technologies, such as large language
models (LLMs), offers a novel opportunity to efficiently investigate public
discourses. This research assesses the accuracy of ChatGPT, a widely used and
freely available service built upon an LLM, for sentiment analysis to discern
different stances toward Human Papillomavirus (HPV) vaccination. Methods.
Messages related to HPV vaccination were collected from social media supporting
different message formats: Facebook (long format) and Twitter (short format). A
selection of 1,000 human-evaluated messages was input into the LLM, which
generated multiple response instances containing its classification results.
Accuracy was measured for each message as the level of concurrence between
human and machine decisions, ranging between 0 and 1. Results. Average accuracy
was notably high when 20 response instances were used to determine the machine
decision of each message: .882 (SE = .021) and .750 (SE = .029) for anti- and
pro-vaccination long-form; .773 (SE = .027) and .723 (SE = .029) for anti- and
pro-vaccination short-form, respectively. Using only three or even one instance
did not lead to a severe decrease in accuracy. However, for long-form messages,
the language model exhibited significantly lower accuracy in categorizing
pro-vaccination messages than anti-vaccination ones. Conclusions. ChatGPT shows
potential in analyzing public opinions on HPV vaccination using social media
content. However, understanding the characteristics and limitations of a
language model within specific public health contexts remains imperative.

摘要：客觀的。疫苗接種引發了一系列公眾輿論，其中
社群媒體是健康相關討論的重要平台。這
大語言等人工智慧技術的出現
模型（法學碩士），提供了有效調查公眾的新機會
話語。這項研究評估了 ChatGPT 的準確性，ChatGPT 是一種廣泛使用的
基於法學碩士的免費服務，用於情感分析以辨別
對人類乳突病毒（HPV）疫苗接種的不同立場。方法。
與 HPV 疫苗接種相關的資訊收集自社群媒體支持
不同的訊息格式：Facebook（長格式）和Twitter（短格式）。 A
選擇 1,000 個經過人工評估的訊息輸入到 LLM 中，其中
產生包含其分類結果的多個回應實例。
每個訊息的準確性是根據訊息之間的並發程度來衡量的
人類和機器的決策，範圍在 0 到 1 之間。平均準確度
當使用 20 個回應實例來確定機器時，該值非常高
每個訊息的決策： .882 (SE = .021) 和 .750 (SE = .029) 用於反和
支持疫苗接種的長格式； .773 (SE = .027) 和 .723 (SE = .029) 用於反和
分別是支持疫苗接種的縮寫。僅使用三個甚至一個實例
並沒有導致準確率的嚴重下降。然而，對於長消息，
語言模型的分類準確率明顯較低
支持疫苗接種的資訊多於反對疫苗接種的資訊。結論。 ChatGPT 顯示
使用社群媒體分析 HPV 疫苗接種的公眾意見的潛力
內容。然而，了解其特徵和局限性
特定公共衛生背景下的語言模式仍勢在必行。

##### **Federated learning model for predicting major postoperative complications**
2404.06641v1 by Yonggi Park et.al.

Background: The accurate prediction of postoperative complication risk using
Electronic Health Records (EHR) and artificial intelligence shows great
potential. Training a robust artificial intelligence model typically requires
large-scale and diverse datasets. In reality, collecting medical data often
encounters challenges surrounding privacy protection. Methods: This
retrospective cohort study includes adult patients who were admitted to UFH
Gainesville (GNV) (n = 79,850) and Jacksonville (JAX) (n = 28,636) for any type
of inpatient surgical procedure. Using perioperative and intraoperative
features, we developed federated learning models to predict nine major
postoperative complications (i.e., prolonged intensive care unit stay and
mechanical ventilation). We compared federated learning models with local
learning models trained on a single site and central learning models trained on
pooled dataset from two centers. Results: Our federated learning models
achieved the area under the receiver operating characteristics curve (AUROC)
values ranged from 0.81 for wound complications to 0.92 for prolonged ICU stay
at UFH GNV center. At UFH JAX center, these values ranged from 0.73-0.74 for
wound complications to 0.92-0.93 for hospital mortality. Federated learning
models achieved comparable AUROC performance to central learning models, except
for prolonged ICU stay, where the performance of federated learning models was
slightly higher than central learning models at UFH GNV center, but slightly
lower at UFH JAX center. In addition, our federated learning model obtained
comparable performance to the best local learning model at each center,
demonstrating strong generalizability. Conclusion: Federated learning is shown
to be a useful tool to train robust and generalizable models from large scale
data across multiple institutions where data protection barriers are high.

摘要：背景：利用模型準確預測術後併發症風險
電子健康記錄 (EHR) 和人工智慧表現出色
潛在的。訓練一個強大的人工智慧模型通常需要
大規模且多樣化的資料集。事實上，經常收集醫療數據
遇到隱私保護的挑戰。方法：這個
回顧性隊列研究包括入院和睦家醫院的成年患者
蓋恩斯維爾 (GNV) (n = 79,850) 和傑克遜維爾 (JAX) (n = 28,636) 對於任何類型
住院手術程序。圍手術期和術中使用
特徵，我們開發了聯邦學習模型來預測九個主要
術後併發症（即延長加護病房停留時間和
機械通氣）。我們將聯邦學習模式與本地學習模式進行了比較
在單一站點上訓練的學習模型和在
來自兩個中心的匯總資料集。結果：我們的聯邦學習模型
取得接受者操作特徵曲線下面積 (AUROC)
數值範圍從傷口併發症的 0.81 到延長 ICU 住院時間的 0.92
在 UFH GNV 中心。在 UFH JAX 中心，這些值的範圍為 0.73-0.74
傷口併發症的醫院死亡率為0.92-0.93。聯邦學習
模型實現了與中央學習模型相當的 AUROC 性能，除了
對於延長 ICU 住院時間，聯邦學習模型的表現
略高於和睦家GNV中心的中央學習模型，但略高
UFH JAX 中心較低。此外，我們的聯邦學習模式也獲得了
與每個中心的最佳本地學習模型的性能相當，
表現出強烈的普遍性。結論：聯邦學習如圖所示
成為訓練大規模穩健且可推廣模式的有用工具
資料保護壁壘較高的多個機構的資料。

##### **Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero shot Medical Image Segmentation**
2404.06362v1 by Sidra Aleem et.al.

The Segment Anything Model (SAM) and CLIP are remarkable vision foundation
models (VFMs). SAM, a prompt driven segmentation model, excels in segmentation
tasks across diverse domains, while CLIP is renowned for its zero shot
recognition capabilities. However, their unified potential has not yet been
explored in medical image segmentation. To adapt SAM to medical imaging,
existing methods primarily rely on tuning strategies that require extensive
data or prior prompts tailored to the specific task, making it particularly
challenging when only a limited number of data samples are available. This work
presents an in depth exploration of integrating SAM and CLIP into a unified
framework for medical image segmentation. Specifically, we propose a simple
unified framework, SaLIP, for organ segmentation. Initially, SAM is used for
part based segmentation within the image, followed by CLIP to retrieve the mask
corresponding to the region of interest (ROI) from the pool of SAM generated
masks. Finally, SAM is prompted by the retrieved ROI to segment a specific
organ. Thus, SaLIP is training and fine tuning free and does not rely on domain
expertise or labeled data for prompt engineering. Our method shows substantial
enhancements in zero shot segmentation, showcasing notable improvements in DICE
scores across diverse segmentation tasks like brain (63.46%), lung (50.11%),
and fetal head (30.82%), when compared to un prompted SAM. Code and text
prompts will be available online.

摘要：分段任意模型 (SAM) 和 CLIP 是卓越的視覺基礎
模型（VFM）。 SAM，一個提示驅動的分割模型，在分割方面表現出色
跨不同領域的任務，而 CLIP 以其零樣本而聞名
識別能力。然而，它們的統一潛力尚未發揮出來。
在醫學影像分割方面進行了探索。為了使 SAM 適應醫學影像，
現有的方法主要依賴需要大量的調整策略
針對特定任務量身定制的數據或先前提示，使其特別
當只有有限數量的數據樣本可用時，這具有挑戰性。這部作品
提出了將 SAM 和 CLIP 整合到統一的系統中的深入探索
醫學影像分割框架。具體來說，我們提出一個簡單的
用於器官分割的統一框架 SaLIP。最初，SAM 用於
影像內基於部分的分割，然後透過 CLIP 檢索掩模
對應於產生的 SAM 池中的興趣區域 (ROI)
面具。最後，SAM 根據檢索到的 ROI 來分割特定的
器官。因此，SaLIP 無需訓練和微調，且不依賴領域
用於快速工程的專業知識或標記資料。我們的方法顯示大量
零鏡頭分割的增強，展示了 DICE 的顯著改進
不同分割任務的得分，如大腦（63.46%）、肺（50.11%）、
與未提示的 SAM 相比，胎兒頭部 (30.82%)。程式碼和文字
提示將在線提供。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi et.al.

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一個日益嚴重的全球健康問題，需要先進的技術
診斷方法。人工智慧和放射組學在甲狀腺癌的應用
本綜述對診斷進行了檢查。對多個資料庫的審查
到 2023 年 10 月為止，均依照 PRISMA 指南進行。
關鍵字組合發現了一份英文學術出版物
關於甲狀腺癌和相關主題。共收到 267 篇論文
刪除 109 個重複項後的原始搜尋。相關研究有
淘汰124篇文章後，依預定標準篩選
基於對其摘要和標題的檢查。綜合後
分析中，另外六項研究被排除。其中28個包括
研究、放射組學分析，其中結合了超音波（美國）影像，
證明了其在診斷甲狀腺癌方面的有效性。各種結果
有人指出，一些研究提出了優於現有策略的新策略
現狀。文獻強調了人工智慧面臨的各種挑戰
模型，包括可解釋性問題、資料集約束和運算符
依賴性。 28 篇納入研究的綜合結果提到
需要標準化工作和前瞻性多中心研究來解決
這些擔憂。此外，克服這些障礙的方法
確定的，例如可解釋的人工智慧技術和個人化的進步
醫學技術。該評論的重點是人工智慧和放射組學如何轉變
甲狀腺癌的診斷和治療。儘管面臨挑戰，但未來
多學科合作研究、臨床適用性驗證、
演算法的改進有可能改善患者的治療結果
甲狀腺癌治療中的診斷精確度。

##### **EPL: Evidential Prototype Learning for Semi-supervised Medical Image Segmentation**
2404.06181v1 by Yuanpeng He et.al.

Although current semi-supervised medical segmentation methods can achieve
decent performance, they are still affected by the uncertainty in unlabeled
data and model predictions, and there is currently a lack of effective
strategies that can explore the uncertain aspects of both simultaneously. To
address the aforementioned issues, we propose Evidential Prototype Learning
(EPL), which utilizes an extended probabilistic framework to effectively fuse
voxel probability predictions from different sources and achieves prototype
fusion utilization of labeled and unlabeled data under a generalized evidential
framework, leveraging voxel-level dual uncertainty masking. The uncertainty not
only enables the model to self-correct predictions but also improves the guided
learning process with pseudo-labels and is able to feed back into the
construction of hidden features. The method proposed in this paper has been
experimented on LA, Pancreas-CT and TBAD datasets, achieving the
state-of-the-art performance in three different labeled ratios, which strongly
demonstrates the effectiveness of our strategy.

摘要：雖然目前的半監督醫學分割方法可以實現
表現不錯，但他們仍然受到未標記的不確定性的影響
數據和模型預測，目前缺乏有效的
可以同時探索兩者不確定面向的策略。到
針對上述問題，我們提出證據原型學習
（EPL），它利用擴展的機率框架來有效地融合
來自不同來源的體素機率預測並實現原型
廣義證據下標記和未標記資料的融合利用
框架，利用體素級雙重不確定性掩蔽。不確定性不
不僅使模型能夠自我修正預測，而且還改進了引導
使用偽標籤進行學習過程，並且能夠回饋到
隱藏特徵的建構。本文所提出的方法已
在 LA、Pancreas-CT 和 TBAD 資料集上進行了實驗，實現了
三種不同標記比例的最先進性能，這強烈
證明了我們策略的有效性。

##### **Uncertainty-aware Evidential Fusion-based Learning for Semi-supervised Medical Image Segmentation**
2404.06177v2 by Yuanpeng He et.al.

Although the existing uncertainty-based semi-supervised medical segmentation
methods have achieved excellent performance, they usually only consider a
single uncertainty evaluation, which often fails to solve the problem related
to credibility completely. Therefore, based on the framework of evidential deep
learning, this paper integrates the evidential predictive results in the
cross-region of mixed and original samples to reallocate the confidence degree
and uncertainty measure of each voxel, which is realized by emphasizing
uncertain information of probability assignments fusion rule of traditional
evidence theory. Furthermore, we design a voxel-level asymptotic learning
strategy by introducing information entropy to combine with the fused
uncertainty measure to estimate voxel prediction more precisely. The model will
gradually pay attention to the prediction results with high uncertainty in the
learning process, to learn the features that are difficult to master. The
experimental results on LA, Pancreas-CT, ACDC and TBAD datasets demonstrate the
superior performance of our proposed method in comparison with the existing
state of the arts.

摘要：儘管現有的基於不確定性的半監督醫學分割
方法已經取得了優異的性能，他們通常只考慮
單一的不確定性評估往往無法解決相關問題
完全可信。因此，基於證據深層的框架
學習中，本文將證據預測結果整合到
混合樣本和原始樣本的跨區域重新分配置信度
以及每個體素的不確定性測量，這是透過強調來實現的
機率分配的不確定資訊 傳統的融合規則
證據理論。此外，我們設計了體素級漸近學習
透過引入資訊熵與融合的策略結合
更精確地估計體素預測的不確定性測量。該模型將
逐漸關注不確定性較高的預測結果
學習過程中，學習難以掌握的功能。這
LA、Pancreas-CT、ACDC 和 TBAD 資料集上的實驗結果表明
與現有方法相比，我們提出的方法具有優越的性能
藝術的狀態。

##### **Tackling Structural Hallucination in Image Translation with Local Diffusion**
2404.05980v3 by Seunghoi Kim et.al.

Recent developments in diffusion models have advanced conditioned image
generation, yet they struggle with reconstructing out-of-distribution (OOD)
images, such as unseen tumors in medical images, causing "image hallucination"
and risking misdiagnosis. We hypothesize such hallucinations result from local
OOD regions in the conditional images. We verify that partitioning the OOD
region and conducting separate image generations alleviates hallucinations in
several applications. From this, we propose a training-free diffusion framework
that reduces hallucination with multiple Local Diffusion processes. Our
approach involves OOD estimation followed by two modules: a "branching" module
generates locally both within and outside OOD regions, and a "fusion" module
integrates these predictions into one. Our evaluation shows our method
mitigates hallucination over baseline models quantitatively and qualitatively,
reducing misdiagnosis by 40% and 25% in the real-world medical and natural
image datasets, respectively. It also demonstrates compatibility with various
pre-trained diffusion models.

摘要：擴散模型的最新發展促進了條件影像的發展
一代人，但他們仍在努力重建分佈外（OOD）
影像，例如醫學影像中看不見的腫瘤，引起“影像幻覺”
並冒著誤診的風險。我們假設這種幻覺是由當地的
條件影像中的 OOD 區域。我們驗證對 OOD 進行分區
區域並進行單獨的圖像生成減輕了幻覺
幾個應用程式。由此，我們提出了一個免訓練的擴散框架
透過多個局部擴散過程減少幻覺。我們的
方法涉及 OOD 估計，然後是兩個模組：「分支」模組
在 OOD 區域內外本地生成，以及「融合」模組
將這些預測整合為一。我們的評估展示了我們的方法
定量和定性地減輕對基線模型的幻覺，
現實醫學和自然領域的誤診率分別減少 40% 和 25%
影像資料集，分別。它還展示了與各種
預先訓練的擴散模型。


### Medical explainable AI
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v1](http://arxiv.org/abs/2404.12832v1)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v2](http://arxiv.org/abs/2404.03892v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|null|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v1](http://arxiv.org/abs/2402.09474v1)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v4](http://arxiv.org/abs/2401.13324v4)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v2](http://arxiv.org/abs/2311.12573v2)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in medical imaging AI**|Emma A. M. Stanley et.al.|[2311.02115v1](http://arxiv.org/abs/2311.02115v1)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. García-Gómez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-09-02**|**An explainable three dimension framework to uncover learning patterns: A unified look in variable sulci recognition**|Michail Mamalakis et.al.|[2309.00903v2](http://arxiv.org/abs/2309.00903v2)|[link](https://github.com/ece7048/3dsulci)|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v1](http://arxiv.org/abs/2309.12325v1)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|
|**2023-07-15**|**Explaining and visualizing black-box models through counterfactual paths**|Bastian Pfeifer et.al.|[2307.07764v3](http://arxiv.org/abs/2307.07764v3)|[link](https://github.com/pievos101/cpath)|
|**2023-07-05**|**Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**|Toygar Tanyel et.al.|[2307.02131v5](http://arxiv.org/abs/2307.02131v5)|[link](https://github.com/toygarr/counterfactual-explanations-for-medical-research)|
|**2023-06-30**|**AI and Non AI Assessments for Dementia**|Mahboobeh Parsapoor et.al.|[2307.01210v1](http://arxiv.org/abs/2307.01210v1)|null|
|**2023-06-12**|**Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**|Ruitao Xie et.al.|[2306.07306v1](http://arxiv.org/abs/2306.07306v1)|null|
|**2023-06-09**|**HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**|Rodrigo Agerri et.al.|[2306.06029v1](http://arxiv.org/abs/2306.06029v1)|null|
|**2023-06-07**|**XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**|Eli Laird et.al.|[2306.04791v1](http://arxiv.org/abs/2306.04791v1)|null|
|**2023-06-06**|**Explainable AI using expressive Boolean formulas**|Gili Rosenberg et.al.|[2306.03976v1](http://arxiv.org/abs/2306.03976v1)|null|
|**2023-06-06**|**Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**|Yeldar Toleubay et.al.|[2306.03902v1](http://arxiv.org/abs/2306.03902v1)|null|
|**2023-06-02**|**XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**|Sujith K Mandala et.al.|[2306.01668v1](http://arxiv.org/abs/2306.01668v1)|null|
|**2023-05-26**|**A Novel real-time arrhythmia detection model using YOLOv8**|Guang Jun Nicholas Ang et.al.|[2305.16727v3](http://arxiv.org/abs/2305.16727v3)|null|
|**2023-05-22**|**Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**|Jai Vardhan et.al.|[2305.14389v2](http://arxiv.org/abs/2305.14389v2)|null|
|**2023-05-18**|**What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**|Junwei Kuang et.al.|[2305.13127v2](http://arxiv.org/abs/2305.13127v2)|null|
|**2023-05-17**|**Echoes of Biases: How Stigmatizing Language Affects AI Performance**|Yizhi Liu et.al.|[2305.10201v4](http://arxiv.org/abs/2305.10201v4)|null|
|**2023-05-05**|**Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**|Goda Klumbyte et.al.|[2305.03376v1](http://arxiv.org/abs/2305.03376v1)|null|
|**2023-04-25**|**Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**|Surjodeep Sarkar et.al.|[2304.13191v1](http://arxiv.org/abs/2304.13191v1)|null|
|**2023-04-04**|**A Brief Review of Explainable Artificial Intelligence in Healthcare**|Zahra Sadeghi et.al.|[2304.01543v1](http://arxiv.org/abs/2304.01543v1)|null|
|**2023-03-22**|**Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**|Frederik Pahde et.al.|[2303.12641v2](http://arxiv.org/abs/2303.12641v2)|[link](https://github.com/maxdreyer/reveal2revise)|
|**2023-03-11**|**Explainable AI for Time Series via Virtual Inspection Layers**|Johanna Vielhaben et.al.|[2303.06365v1](http://arxiv.org/abs/2303.06365v1)|null|
|**2023-03-08**|**Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**|Truong Thanh Hung Nguyen et.al.|[2303.04731v1](http://arxiv.org/abs/2303.04731v1)|[link](https://github.com/hungntt/xai_thyroid)|
|**2023-03-06**|**Cybersecurity of AI medical devices: risks, legislation, and challenges**|Elisabetta Biasin et.al.|[2303.03140v1](http://arxiv.org/abs/2303.03140v1)|null|
|**2023-02-06**|**LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**|Nooshin Yousefzadeh et.al.|[2302.03008v2](http://arxiv.org/abs/2302.03008v2)|null|
|**2023-02-02**|**Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses**|Brian Y. Lim et.al.|[2302.01241v2](http://arxiv.org/abs/2302.01241v2)|null|
|**2023-02-02**|**LesionAid: Vision Transformers-based Skin Lesion Generation and Classification**|Ghanta Sai Krishna et.al.|[2302.01104v1](http://arxiv.org/abs/2302.01104v1)|null|
|**2023-02-01**|**SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis**|Roxana Daneshjou et.al.|[2302.00785v1](http://arxiv.org/abs/2302.00785v1)|null|
|**2023-01-19**|**Decision-Focused Evaluation: Analyzing Performance of Deployed Restless Multi-Arm Bandits**|Paritosh Verma et.al.|[2301.07835v1](http://arxiv.org/abs/2301.07835v1)|null|
|**2023-01-18**|**Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling**|Carlo Metta et.al.|[2302.03033v1](http://arxiv.org/abs/2302.03033v1)|null|
|**2023-01-17**|**Monotonicity for AI ethics and society: An empirical study of the monotonic neural additive model in criminology, education, health care, and finance**|Dangxing Chen et.al.|[2301.07060v1](http://arxiv.org/abs/2301.07060v1)|null|
|**2023-01-15**|**Rationalizing Predictions by Adversarial Information Calibration**|Lei Sha et.al.|[2301.06009v1](http://arxiv.org/abs/2301.06009v1)|null|
|**2023-01-05**|**Semantic match: Debugging feature attribution methods in XAI for healthcare**|Giovanni Cinà et.al.|[2301.02080v3](http://arxiv.org/abs/2301.02080v3)|null|
|**2022-12-17**|**Context-dependent Explainability and Contestability for Trustworthy Medical Artificial Intelligence: Misclassification Identification of Morbidity Recognition Models in Preterm Infants**|Isil Guzey et.al.|[2212.08821v1](http://arxiv.org/abs/2212.08821v1)|null|
|**2022-12-16**|**It is not "accuracy vs. explainability" -- we need both for trustworthy AI systems**|D. Petkovic et.al.|[2212.11136v2](http://arxiv.org/abs/2212.11136v2)|null|
|**2022-12-02**|**SimpleMind adds thinking to deep neural networks**|Youngwon Choi et.al.|[2212.00951v1](http://arxiv.org/abs/2212.00951v1)|[link](https://gitlab.com/sm-ai-team/simplemind)|
|**2022-11-27**|**Attribution-based XAI Methods in Computer Vision: A Review**|Kumar Abhishek et.al.|[2211.14736v1](http://arxiv.org/abs/2211.14736v1)|null|
|**2022-11-08**|**Privacy Meets Explainability: A Comprehensive Impact Benchmark**|Saifullah Saifullah et.al.|[2211.04110v1](http://arxiv.org/abs/2211.04110v1)|null|
|**2022-11-05**|**Predicting Treatment Adherence of Tuberculosis Patients at Scale**|Mihir Kulkarni et.al.|[2211.02943v2](http://arxiv.org/abs/2211.02943v2)|null|
|**2022-11-02**|**Explainable AI over the Internet of Things (IoT): Overview, State-of-the-Art and Future Directions**|Senthil Kumar Jagatheesaperumal et.al.|[2211.01036v2](http://arxiv.org/abs/2211.01036v2)|null|
|**2022-10-24**|**Human-centered XAI for Burn Depth Characterization**|Maxwell J. Jacobson et.al.|[2210.13535v2](http://arxiv.org/abs/2210.13535v2)|null|
|**2022-10-07**|**What Do End-Users Really Want? Investigation of Human-Centered XAI for Mobile Health Apps**|Katharina Weitz et.al.|[2210.03506v1](http://arxiv.org/abs/2210.03506v1)|null|
|**2022-10-07**|**Explainable AI based Glaucoma Detection using Transfer Learning and LIME**|Touhidul Islam Chayan et.al.|[2210.03332v1](http://arxiv.org/abs/2210.03332v1)|null|
|**2022-09-30**|**Evaluation of importance estimators in deep learning classifiers for Computed Tomography**|Lennart Brocki et.al.|[2209.15398v1](http://arxiv.org/abs/2209.15398v1)|null|
|**2022-09-30**|**An Interactive Interpretability System for Breast Cancer Screening with Deep Learning**|Yuzhe Lu et.al.|[2210.08979v1](http://arxiv.org/abs/2210.08979v1)|null|
|**2022-09-14**|**Explainable AI for clinical and remote health applications: a survey on tabular and time series data**|Flavio Di Martino et.al.|[2209.06528v1](http://arxiv.org/abs/2209.06528v1)|null|
|**2022-08-31**|**Enhancing Early Lung Cancer Detection on Chest Radiographs with AI-assistance: A Multi-Reader Study**|Gaetan Dissez et.al.|[2208.14742v1](http://arxiv.org/abs/2208.14742v1)|null|
|**2022-08-24**|**GAN-based generative modelling for dermatological applications -- comparative study**|Sandra Carrasco Limeros et.al.|[2208.11702v1](http://arxiv.org/abs/2208.11702v1)|[link](https://github.com/aidotse/stylegan2-ada-pytorch)|
|**2022-08-05**|**Planning and Scheduling in Digital Health with Answer Set Programming**|Marco Mochi et.al.|[2208.03099v1](http://arxiv.org/abs/2208.03099v1)|null|
|**2022-07-26**|**AI Approaches in Processing and Using Data in Personalized Medicine**|Mirjana Ivanovic et.al.|[2208.04698v1](http://arxiv.org/abs/2208.04698v1)|null|
|**2022-07-22**|**TRUST-LAPSE: An Explainable and Actionable Mistrust Scoring Framework for Model Monitoring**|Nandita Bhaskhar et.al.|[2207.11290v2](http://arxiv.org/abs/2207.11290v2)|[link](https://github.com/nanbhas/trustlapse)|
|**2022-07-12**|**Revealing Unfair Models by Mining Interpretable Evidence**|Mohit Bajaj et.al.|[2207.05811v1](http://arxiv.org/abs/2207.05811v1)|null|
|**2022-07-11**|**From Correlation to Causation: Formalizing Interpretable Machine Learning as a Statistical Process**|Lukas Klein et.al.|[2207.04969v1](http://arxiv.org/abs/2207.04969v1)|null|
|**2022-07-09**|**Explainable AI (XAI) in Biomedical Signal and Image Processing: Promises and Challenges**|Guang Yang et.al.|[2207.04295v1](http://arxiv.org/abs/2207.04295v1)|null|
|**2022-07-06**|**Towards the Use of Saliency Maps for Explaining Low-Quality Electrocardiograms to End Users**|Ana Lucic et.al.|[2207.02726v1](http://arxiv.org/abs/2207.02726v1)|null|
|**2022-06-30**|**Why we do need Explainable AI for Healthcare**|Giovanni Cinà et.al.|[2206.15363v1](http://arxiv.org/abs/2206.15363v1)|null|
|**2022-06-09**|**Process Knowledge-Infused AI: Towards User-level Explainability, Interpretability, and Safety**|Amit Sheth et.al.|[2206.13349v1](http://arxiv.org/abs/2206.13349v1)|null|

#### Abstracts
##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge et.al.

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：人工智慧（AI）的普遍整合已經引入
如果出現以下情況，責任和問責制將面臨複雜的挑戰
涉及人工智慧系統的事件。這些系統的互連性，
人工智慧引發的事件的倫理問題以及人工智慧的不確定性
技術的進步和相應法規的缺失，使得傳統的
責任歸屬具有挑戰性。為此，本工作提出了
計算反射平衡（CRE）方法建立一個連貫的和
所有利害關係人在道德上可接受的責任歸屬框架。
計算方法提供了一種結構化分析，克服了
概念方法在處理動態和多方面問題時的局限性
場景，展示框架的可解釋性、連貫性和適應性
責任歸屬過程中的屬性。我們檢查關鍵的
與平衡狀態下的索賠相關的初始活化水準的作用
計算。以AI輔助醫療決策支援系統為例
研究中，我們說明了不同的初始化如何導致不同的結果
責任分配。該框架提供了寶貴的見解
人工智慧引發的事件的問責制，促進發展
透過持續監控、修訂和改進，實現可持續和有彈性的系統
反射。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang et.al.

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測為醫療保健專業人員提供支持
建模，大大改變了臨床決策。本研究解決
人工智慧應用程式對公平性和可解釋性的迫切需求
醫療保健，以確保不同患者群體的公平結果。經過
專注於敗血症相關死亡率的預測模型，我們提出了
學習性能優化的預測模型然後採用的方法
遷移學習過程以產生具有更好公平性的模型。我們的
該方法還引入了一種新穎的基於排列的特徵重要性演算法
旨在闡明每個特徵對增強公平性的貢獻
預測。與現有的可解釋性方法專注於解釋不同
特徵對預測表現的貢獻，我們提出的方法是獨一無二的
彌合了理解每個功能如何促進公平性的差距。這
鑑於敗血症的顯著死亡率及其作用，進展至關重要
佔醫院死亡人數的三分之一。我們的方法不僅有助於識別和
減少預測模型中的偏差，同時也促進了人們之間的信任
透過提高模型的透明度和公平性來影響醫療保健利益相關者
預測，從而有助於更公平和值得信賴的醫療保健
送貨。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat et.al.

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：憂鬱症是當今的重要議題。根據世界衛生組織
世界衛生組織 (WHO) 預計，到 2023 年，將有超過 2.8 億人面臨
沮喪。這是一個龐大的數字；如果不認真對待，這些數字將
迅速增加。大約有 48.9 億人是社群媒體用戶。人們
在 Twitter、Facebook 等平台上表達自己的感受和情緒，
Reddit、Instagram 等。
用於研究目的。已經進行了大量的研究
各種社群媒體平台。然而，這些技術仍存在一定的局限性
努力。特別是，先前的研究僅集中於檢測
憂鬱症以及推文中憂鬱症的強度。另外，還存在
資料集標籤不準確。在這項研究工作中，有五種類型
預測憂鬱症（躁鬱症、重度憂鬱、精神病性憂鬱、非典型憂鬱和產後憂鬱）
使用基於字典標籤的 Twitter 資料庫中的推文。可解釋的
人工智慧透過突出顯示推文中的某些部分來提供推理
代表憂鬱症的類型。雙向編碼器表示
Transformers (BERT) 用於特徵提取和訓練。機器
使用學習和深度學習方法來訓練模型。伯特
模型呈現了最有希望的結果，整體精度達到
0.96。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v1 by Dmytro Shvetsov et.al.

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度學習正在大幅改變醫學影像領域
放射學，能夠辨識醫學影像中的病理，
包括電腦斷層掃描 (CT) 和 X 光掃描。然而，性能
深度學習模型，特別是在分割任務中，通常受到以下限制：
需要大量帶註釋的資料集。為了應對這項挑戰，
透過以下方式探討弱監督語意分割的能力
可解釋人工智慧的鏡頭和反事實解釋的生成。
這項研究的範圍是開發一種新穎的反事實修復
方法（COIN）將預測的分類標籤從異常翻轉為
使用生成模型正常。例如，如果分類器認為
輸入醫學影像X為異常，表示存在病理，
生成模型旨在修復異常區域，從而逆轉
分類器的原始預測標籤。該方法使我們能夠生產
精確的病理分割，而不依賴預先存在的
分割掩模。至關重要的是，利用了圖像級標籤，它們是
比建立詳細的分割遮罩更容易取得。這
此方法的有效性透過分割合成目標來證明
來自塔爾圖大學醫院的 CT 影像中的實際腎臟腫瘤
愛沙尼亞。研究結果表明，COIN 大大超越了既定標準
歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及
Singla 等人提出的替代反事實解釋方法。這
證據顯示 COIN 是一種有前途的語意分割方法
CT 影像中的腫瘤，並在深度學習方面向前邁進了一步
在醫療保健領域，應用程式更容易存取和更有效，其中帶有註釋的數據
是稀缺的。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi et.al.

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一個日益嚴重的全球健康問題，需要先進的技術
診斷方法。人工智慧和放射組學在甲狀腺癌的應用
本綜述對診斷進行了檢查。對多個資料庫的審查
到 2023 年 10 月為止，均依照 PRISMA 指南進行。
關鍵字組合發現了一份英文學術出版物
關於甲狀腺癌和相關主題。共收到 267 篇論文
刪除 109 個重複項後的原始搜尋。相關研究有
淘汰124篇文章後，依預定標準篩選
基於對其摘要和標題的檢查。綜合後
分析中，另外六項研究被排除。其中28個包括
研究、放射組學分析，其中結合了超音波（美國）影像，
證明了其在診斷甲狀腺癌方面的有效性。各種結果
有人指出，一些研究提出了優於現有策略的新策略
現狀。文獻強調了人工智慧面臨的各種挑戰
模型，包括可解釋性問題、資料集約束和運算符
依賴性。 28 篇納入研究的綜合結果提到
需要標準化工作和前瞻性多中心研究來解決
這些擔憂。此外，克服這些障礙的方法
確定的，例如可解釋的人工智慧技術和個人化的進步
醫學技術。該評論的重點是人工智慧和放射組學如何轉變
甲狀腺癌的診斷和治療。儘管面臨挑戰，但未來
多學科合作研究、臨床適用性驗證、
演算法的改進有可能改善患者的治療結果
甲狀腺癌治療中的診斷精確度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam et.al.

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：近年來，乳癌的發生率迅速上升，使得
全世界死亡的主要原因之一。在所有癌症中，它是由
迄今為止最常見的。手動診斷這種疾病需要大量時間
和專業知識。由於檢測乳癌是一個耗時的過程，
透過創建基於機器的預測可以幫助防止其進一步傳播。
機器學習和可解釋的人工智慧對於分類至關重要，因為它們並非如此
不僅提供準確的預測，還提供有關模型如何進行的見解
做出決定，有助於理解和信任
分類結果。在這項研究中，我們評估並比較了
五種不同分類的準確率、精確率、召回率和 F-1 分數
使用主要資料集（來自達卡的 500 名患者）的機器學習方法
醫學院附屬醫院）。五種不同的監督機器學習
技術，包括決策樹、隨機森林、邏輯迴歸、樸素
bayes 和 XGBoost 已用於在我們的資料集上獲得最佳結果。
此外，本研究將 SHAP 分析應用於 XGBoost 模型
解釋模型的預測並了解每個特徵的影響
模型的輸出。我們比較了幾種演算法的準確性
將數據分類，並與該領域的其他文獻進行比較。
經過最終評估，本研究發現XGBoost取得了最佳模型
準確率達 97%。

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v2 by Maryam Ahmed et.al.

The study introduces an integrated framework combining Convolutional Neural
Networks (CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced
diagnosis of breast cancer using the CBIS-DDSM dataset. Utilizing a fine-tuned
ResNet50 architecture, our investigation not only provides effective
differentiation of mammographic images into benign and malignant categories but
also addresses the opaque "black-box" nature of deep learning models by
employing XAI methodologies, namely Grad-CAM, LIME, and SHAP, to interpret CNN
decision-making processes for healthcare professionals. Our methodology
encompasses an elaborate data preprocessing pipeline and advanced data
augmentation techniques to counteract dataset limitations, and transfer
learning using pre-trained networks, such as VGG-16, DenseNet and ResNet was
employed. A focal point of our study is the evaluation of XAI's effectiveness
in interpreting model predictions, highlighted by utilising the Hausdorff
measure to assess the alignment between AI-generated explanations and expert
annotations quantitatively. This approach plays a critical role for XAI in
promoting trustworthiness and ethical fairness in AI-assisted diagnostics. The
findings from our research illustrate the effective collaboration between CNNs
and XAI in advancing diagnostic methods for breast cancer, thereby facilitating
a more seamless integration of advanced AI technologies within clinical
settings. By enhancing the interpretability of AI-driven decisions, this work
lays the groundwork for improved collaboration between AI systems and medical
practitioners, ultimately enriching patient care. Furthermore, the implications
of our research extend well beyond the current methodologies, advocating for
subsequent inquiries into the integration of multimodal data and the refinement
of AI explanations to satisfy the needs of clinical practice.

摘要：該研究引入了結合卷積神經網路的整合框架
網路（CNN）和可解釋人工智慧（XAI）用於增強
使用 CBIS-DDSM 資料集診斷乳癌。利用經過微調的
ResNet50架構，我們的調查不僅提供了有效的
將乳房X光攝影區分為良性和惡性類別，但是
也解決了深度學習模型的不透明“黑盒子”性質
採用 XAI 方法（即 Grad-CAM、LIME 和 SHAP）來解釋 CNN
醫療保健專業人員的決策過程。我們的方法論
包含精心設計的數據預處理管道和高級數據
增強技術來抵消資料集限制，並傳輸
使用預訓練網路（例如 VGG-16、DenseNet 和 ResNet）進行學習
受僱。我們研究的一個重點是 XAI 有效性的評估
在解釋模型預測方面，透過利用 Hausdorff 來強調
評估人工智慧產生的解釋與專家之間的一致性的措施
定量註釋。這種方法在 XAI 中發揮著至關重要的作用
促進人工智慧輔助診斷的可信度和道德公平性。這
我們的研究結果說明了 CNN 之間的有效合作
和 XAI 推進乳癌的診斷方法，從而促進
先進的人工智慧技術在臨床中更加無縫的集成
設定.透過增強人工智慧驅動決策的可解釋性，這項工作
為改善人工智慧系統和醫療之間的協作奠定基礎
從業者，最終豐富患者護理。此外，影響
我們的研究遠遠超出了目前的方法論，提倡
隨後對多模態資料的整合與細化進行詢問
人工智慧解釋以滿足臨床實踐的需求。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario et.al.

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人為中心的可解釋人工智慧（HCXAI）倡導社會融合
人工智慧解釋的各個方面。 HCXAI 話語的核心是社交
透明度（ST）框架，旨在使社會組織
使用者可以存取的人工智慧系統的上下文。在這項工作中，我們建議
擴展 ST 框架以解決社會錯誤歸因的風險
大型語言模型（LLM），特別是在心理等敏感領域
健康。事實上，法學碩士非常有能力模擬角色和
人物角色可能會導致設計者的意圖與使用者的意圖不匹配
對社會屬性的看法，冒著促進情緒操縱和
危險行為、認知不公案例和無根據的信任。到
為了解決這些問題，我們建議用第五種方法來增強 ST 框架
「W-問題」澄清分配給法學碩士的具體社會屬性
它的設計者和使用者。這項補充旨在彌合法律碩士與法學碩士之間的差距
能力和使用者認知，促進道德責任
基於法學碩士的技術的開發和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan et.al.

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：背景：氣胸是由於空氣異常引起的急性胸部疾病。
肺和胸壁之間的聚集。經常解決不透明問題
與深度學習 (DL) 模型、可解釋的人工智慧相關
(XAI) 方法已被引入輪廓與氣胸相關的區域
DL 模型所做的診斷。然而，這些解釋有時與
實際病變區域，突出需要進一步改善。方法：我們
提出一種模板引導的方法來整合臨床知識
將氣胸納入 XAI 方法產生的模型解釋中，從而
提高這些解釋的品質。利用單一病灶勾勒
由放射科醫生創建，我們的方法首先產生一個模板
代表氣胸發生的潛在區域。那麼這個模板就是
疊加在模型解釋上以過濾掉無關的解釋
落在模板的邊界之外。為了驗證其功效，我們進行了
對使用和不使用我們的模板的三種 XAI 方法進行比較分析
解釋兩個現實世界資料集中的兩個深度學習模型時的指導。結果：
所提出的方法持續改進了十二個基線 XAI 方法
基於三種 XAI 方法、兩種 DL 模型和兩種
數據集。以績效計算的平均增量百分比
與基準效能相比，Intersection 效能提高了 97.8%
比較模型時，並集 (IoU) 和 Dice 相似係數 (DSC) 為 94.1%
解釋和真實病變區域。結論：在以下背景下
氣胸診斷，我們提出了一種模板引導的方法來改進人工智慧
解釋。我們預計我們的模板指南將打造一個新的
透過整合臨床領域專業知識來闡明人工智慧模型的方法。

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford et.al.

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：在目前的機器翻譯 (MT) 領域，Transformer
架構作為黃金標準脫穎而出，特別是對於高資源
語言對。這項研究深入探討了其對資源匱乏的情況的功效
語言對包括英語$\leftrightarrow$愛爾蘭語和
英語$\leftrightarrow$馬拉地語語言對。值得注意的是，該研究確定
最佳超參數和子字模型類型可顯著提高
低資源語言對的 Transformer 模型的翻譯品質。
  低資源語言並行資料集的稀缺可能會阻礙機器翻譯
發展。為了解決這個問題，gaHealth 被開發出來，這是第一個雙語
愛爾蘭語健康數據語料庫。聚焦健康領域，
使用該域內資料集開發的模型表現出非常顯著的效果
與 LoResMT2021 的模型相比，BLEU 分數有所提高
共享任務。使用多維質量進行後續的人工評估
指標錯誤分類展示了 Transformer 的卓越性能
與基於 RNN 的系統相比，系統可以減少準確性和流暢性錯誤
對方。
  此外，本文也介紹了兩個開源的adaptNMT和adaptMLLM
簡化了應用程式的開發、微調和部署
神經機器翻譯模型。這些工具大大簡化了設置
和評估流程，使 MT 更容易被開發者和
翻譯人員。值得注意的是，adaptNMT 植根於 OpenNMT 生態系統，促進
透過強調生態友善的自然語言處理研究
模型開發的環境足跡。透過 AdaptMLLM 微調 MLLM
展示了兩個資源匱乏的翻譯表現的進步
語言對：英語$\leftrightarrow$愛爾蘭語和
英語$\leftrightarrow$馬拉地語，與 LoResMT2021 的基線相比
共享任務。

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani et.al.

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和脈管系統反映了身體的微血管和大血管
健康。它們可用於診斷 DM 併發症，包括糖尿病
視網膜病變 (DR)、神經病變、腎臟病及動脈粥狀硬化性心血管疾病
疾病，以及預測心血管事件的風險。人造的
為 DR 高通量檢測而開發的智慧 (AI) 系統
使用數位化視網膜影像已被臨床採用。超越災難復原
篩檢、人工智慧整合也具有應對挑戰的巨大潛力
與 DM 患者的整體護理相關。在這項工作中，我們的目標是
全面回顧以人工智慧應用為基礎的研究文獻
與 DM 診斷、預測和管理相關的視網膜影像。我們
將描述整體人工智慧輔助糖尿病護理的發現，包括但
不僅限於 DR 篩檢，並討論實施此類系統的障礙，
包括有關道德、資料隱私、公平存取的問題，以及
可解釋性。能夠評估患者的健康狀況
針對 DM 併發症以及未來心血管疾病的風險預測
併發症，人工智慧輔助視網膜影像分析有潛力成為
糖尿病患者現代個人化醫療的核心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran et.al.

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：本研究調查了不同人工方法的可接受性
多方利害關係人在教育中的智慧（AI）應用
包括學生、老師、家長的視角。承認
人工智慧在教育領域的變革潛力，它解決了以下問題
資料隱私、人工智慧機構、透明度、可解釋性和道德
人工智慧的部署。透過小插圖方法，向參與者展示了
有四種場景，其中人工智慧的代理性、透明度、可解釋性和
隱私被操縱。每個場景結束後，參與者完成了調查
捕捉了他們對人工智慧的全球效用、個人有用性的看法，
正義、信心、風險以及使用每個場景的人工智慧的意圖，如果
可用的。資料收集包括 1198 個最終樣本
多方利害關係人參與者透過合作機構進行分配
和社交媒體活動，重點關注個人對四種人工智慧使用的反應
案例。對數據的中介分析表明，接受和信任
人工智慧在不同利害關係人群體之間存在顯著差異。我們發現關鍵是
人工智慧的高水準和低水準之間的中介、透明度和
可解釋性，以及使用不同教育人工智慧的意圖，
包括感知的全球效用、正義和信心。研究
強調人工智慧在教育領域的接受度是細緻、多方面的
需要仔細考慮具體的人工智慧應用及其影響的問題
特徵，以及不同利害關係人的看法。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v1 by Aruna Mohan et.al.

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：基於可穿戴單導聯心電圖的遠距患者監護
（心電圖）設備在早期檢測方面具有巨大潛力
心臟病，尤其是與人工智慧 (AI) 相結合的疾病
自動心臟病檢測的方法。之前有研究
應用基於深度學習的人工智慧方法進行心臟病檢測。
然而，這些模型尚未被廣泛接受為可靠的輔助手段
臨床診斷，部分原因是目前的黑盒觀念
圍繞許多AI演算法。特別是，需要確定
心電圖訊號的關鍵特徵有助於做出準確的
診斷，從而增強模型的可解釋性。在現在
研究中，我們開發了一種視覺轉換器方法來識別心房顫動
基於單導聯心電圖資料。殘差網路（ResNet）方法也是
開發用於與視覺轉換器方法進行比較。這些型號是
應用於 Chapman-Shaoxing 資料集對心房顫動進行分類，如
以及另一種常見的心律不整，竇性心搏過緩和正常竇性心律
心跳。該模型能夠識別關鍵區域
確定最終分類的心跳，並反白顯示
P 波和 T 波以及心跳持續時間和訊號的重要性
幅度，以區分正常竇性心律和心房顫
竇性心搏過緩。

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal et.al.

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了憂鬱症檢測和治療的新範式
使用高階大型語言模式 (LLM)：生成式預訓練 Transformer
4 (GPT-4)、Llama 2 聊天和 Gemini。這些法學碩士經過專門的調整
提示診斷、解釋並建議治療介入措施
沮喪。獨特的少樣本提示方法增強了模型的能力
根據 DSM-5 標準分析和解釋憂鬱症狀。在裡面
互動階段，模型進行移情對話管理、繪圖
來自 PsychDB 和認知行為治療 (CBT) 指南等資源，
促進與經歷重大事件的個人的支持性互動
憂鬱症。此外，該研究還介紹了 Illuminate
資料庫，富含各種 CBT 模組，有助於個人化治療
建議。研究使用 F1 等指標評估 LLM 表現
分數、精確率、召回率、餘弦相似度和召回率導向的替補研究
跨不同測試集進行 Gisting 評估 (ROUGE)，展示其
效力。這種綜合方法將尖端人工智慧與
建立心理學方法，為心理健康提供新的可能性
護理並展示法學碩士在徹底改變憂鬱症方面的潛力
診斷和治療策略。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v4 by Timothée Schmude et.al.

Explanations of AI systems rarely address the information needs of people
affected by algorithmic decision-making (ADM). This gap between conveyed
information and information that matters to affected stakeholders can impede
understanding and adherence to regulatory frameworks such as the AI Act. To
address this gap, we present the "XAI Novice Question Bank": A catalog of
affected stakeholders' information needs in two ADM use cases (employment
prediction and health monitoring), covering the categories data, system
context, system usage, and system specifications. Information needs were
gathered in an interview study where participants received explanations in
response to their inquiries. Participants further reported their understanding
and decision confidence, showing that while confidence tended to increase after
receiving explanations, participants also met understanding challenges, such as
being unable to tell why their understanding felt incomplete. Explanations
further influenced participants' perceptions of the systems' risks and
benefits, which they confirmed or changed depending on the use case. When risks
were perceived as high, participants expressed particular interest in
explanations about intention, such as why and to what end a system was put in
place. With this work, we aim to support the inclusion of affected stakeholders
into explainability by contributing an overview of information and challenges
relevant to them when deciding on the adoption of ADM systems. We close by
summarizing our findings in a list of six key implications that inform the
design of future explanations for affected stakeholder audiences.

摘要：對人工智慧系統的解釋很少能滿足人們資訊的需求
受演算法決策（ADM）的影響。所傳達的這種差距
對受影響的利害關係人重要的資訊和資訊可能會阻礙
理解並遵守《人工智慧法案》等監管框架。到
為了解決這個差距，我們推出了「XAI 新手問題庫」：
在兩個 ADM 用例（就業
預測與健康監測），涵蓋類別資料、系統
上下文、系統使用情況和系統規格。資訊需求是
在一項訪談研究中收集到參與者收到的解釋
回應他們的詢問。與會者進一步表達了他們的理解
和決策信心，顯示雖然信心在之後趨於增加
在接受解釋時，參與者也遇到了理解挑戰，例如
無法說出為什麼他們的理解感覺不完整。說明
進一步影響參與者對系統風險的看法
他們根據用例確認或更改了好處。當風險
被認為很高，參與者表示特別感興趣
關於意圖的解釋，例如為什麼要安裝系統以及其目的是什麼
地方。透過這項工作，我們的目標是支持受影響的利害關係人的參與
透過提供資訊和挑戰的概述來提高可解釋性
在決定採用 ADM 系統時與他們相關。我們就在附近
將我們的發現總結為六個關鍵含義，這些含義為
為受影響的利害關係人受眾設計未來的解釋。

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari et.al.

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

摘要：人工智慧 (AI) 的快速發展，尤其是在該領域
大型語言模型（LLM）和生成人工智慧的研究，為
其應用遍及各個領域，但在商業教育中的作用仍然存在
尚未充分探索。本研究引入了第一個評估基準
七個主要法學碩士、OpenAI 模型（GPT-3.5 Turbo、GPT-4 和
GPT-4 Turbo）、Google 的模型（PaLM 2、Gemini 1.0 Pro）和 Anthropic 的模型
（克勞德2和克勞德2.1），關於GMAT，這是入學中的關鍵考試
研究生商業課程的流程。我們的分析表明，大多數法學碩士
超越人類候選者，GPT-4 Turbo 不僅優於其他候選者
模型，但也超過了頂尖研究生的平均成績
商學院。透過案例研究，本研究檢驗了 GPT-4 Turbo 的
解釋答案、評估答案、辨識錯誤、客製化的能力
指令，並產生替代方案。最新的LLM版本，
GPT-4 Turbo、Claude 2.1 和 Gemini 1.0 Pro 在以下方面表現出顯著改進：
與前輩相比的推理任務，強調了他們的潛力
用於解決複雜的問題。雖然人工智慧在教育、評估和
輔導很明確，但挑戰仍然存在。我們的研究不僅揭示了法學碩士的
學術潛力，但也強調需要仔細發展和
人工智慧在教育上的應用。隨著人工智慧技術的進步，勢在必行
建立人工智慧互動的框架和協議，驗證其準確性
人工智慧生成的內容，確保不同學習者在全球範圍內訪問，並創建
人工智慧支援人類專業知識的教育環境。這項研究
為進一步探索負責任地使用人工智慧來豐富生活奠定了基礎
教育經驗並改進考試準備和評估方法。

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li et.al.

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

摘要：預測加護病房 (ICU) 病患的院內死亡率
最終臨床結果的關鍵。人工智慧顯示出優勢的準確性，但也受到影響
由於缺乏可解釋性。為了解決這個問題，本文提出了一個
eXplainable 多模態死亡率預測器 (X-MMP) 接近高效率、
可解釋的人工智慧解決方案，透過多模式 ICU 預測院內死亡率
數據。我們在我們的框架中採用多模態學習，它可以接收
來自臨床數據的異質輸入並做出決策。此外，我們
引入一種可解釋的方法，即 Layer-Wise Propagation to Transformer，
作為 LRP 方法對 Transformers 的適當擴展，產生解釋
多模態輸入並揭示其顯著特徵
預言。此外，每種方式對臨床結果的貢獻
可以視覺化，幫助臨床醫師理解背後的推理
決策。我們建構了一個基於 MIMIC-III 的多模態資料集
MIMIC-III 波形資料庫匹配子集。綜合實驗
基準資料集顯示我們提出的框架可以實現
合理的解釋與有競爭力的預測準確度。尤其，
我們的框架可以很容易地轉移到其他臨床任務中，
促進醫療保健研究中關鍵因素的發現。

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe et.al.

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

摘要：在過去的十年裡，病理學領域的人工智慧（AI）方法已經取得了長足的進步。
大幅進步。然而，融入常規臨床實踐已經
由於技術和監管等諸多挑戰，進展緩慢
將研究成果轉化為臨床診斷產品的障礙
缺乏標準化介面。開放且供應商中立的 EMPAIA
倡議解決了這些挑戰。在這裡，我們提供了 EMPAIA 的概述
成就和經驗教訓。 EMPAIA 整合了各個利害關係人
病理性人工智慧生態系統，即病理學家、電腦科學家和工業界。
透過密切合作，我們制定了技術互通性標準，
人工智慧測試和產品開發的建議以及可解釋性
方法。我們實作了模組化和開源的 EMPAIA 平台，
成功整合了來自 8 個不同國家的 14 個基於人工智慧的圖像分析應用程式
供應商，演示不同的應用程式如何使用單一標準化
介面.我們對需求進行了優先排序並評估了人工智慧的實際使用情況
歐洲和亞洲擁有 14 個不同病理實驗室的臨床環境。
除了技術發展之外，我們還為所有利害關係人創建了一個論壇
分享數位病理學和人工智慧的資訊和經驗。商業的，
臨床和學術利益相關者現在可以採用 EMPAIA 的通用開源
接口，為大規模標準化和
簡化流程。需要進一步努力，有效和
在日常實驗室使用中廣泛建立人工智慧輔助。為此，一個
永續基礎設施、非營利協會 EMPAIA International、
的建立是為了繼續標準化並支持廣泛的
實施和倡導人工智慧輔助的數位病理學未來。

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero et.al.

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

摘要：反事實解釋（CE）技術作為一種手段而受到關注
為使用人工智慧系統的使用者提供見解。雖然廣泛
研究領域包括醫學影像和自動駕駛汽車，Graph
反事實解釋（GCE）方法相對較
尚未充分探索。 GCE 產生一個與原始圖類似的新圖，其中
基於底層預測模型的不同結果。其中，GCE
技術，那些植根於生成機制的技術已經相對獲得了
儘管在其他方面取得了令人矚目的成就，但調查有限
領域，例如藝術風格和自然語言建模。偏好
對生成解釋者來說，源自於他們產生反事實的能力
推理過程中的實例，利用自主獲得的擾動
輸入圖。受上述理由的啟發，我們的研究引進了
RSGG-CE，一種新穎的反事實穩健隨機圖產生器
能夠從學習到的潛在變數產生反事實範例的解釋
空間考慮部分有序的生成序列。此外，我們
進行定量和定性分析以比較 RSGG-CE
與 SoA 生成解釋器相比的性能，突出顯示其增強
產生合理的反事實候選人的能力。

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im et.al.

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

摘要：可解釋人工智慧的動機之一是讓人類做得更好
以及有關人工智慧模型的使用和部署的更明智的決策。但
需要仔細評估來評估這種期望是否已實現
實現了。目前的評估主要集中在演算法特性
解釋，而涉及人類受試者的解釋通常採用主觀
測試人類對解釋有用性的感知的問題，而不是
以客觀指標和測量為基礎。在這項工作中，我們評估
解釋是否可以改善人類在實際場景中的決策
機器學習模型開發。我們進行混合方法的使用者研究
涉及影像資料來評估 SmoothGrad 產生的顯著性圖，
GradCAM，以及關於兩個任務的 oracle 解釋：模型選擇和
反事實模擬。令我們驚訝的是，我們沒有找到任何證據
當向使用者提供任何以下任務時，這些任務的顯著改進
顯著圖，甚至是設計得簡單易懂的合成預言解釋
理解並高度指示答案。儘管如此，解釋還是做了
幫助使用者更準確地描述模型。這些發現顯示要謹慎
關於基於顯著性的有用性和潛在的誤解
解釋。

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur et.al.

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

摘要：可解釋性和安全性產生信任。這些都需要一個模型來展示
一致性和可靠性。為了實現這些目標，需要使用和
使用與相關的統計和符號人工智慧方法分析數據和知識
人工智慧應用程式——兩者都行不通。因此，我們爭論並尋求
證明 NeuroSymbolic AI 方法更適合讓 AI
值得信賴的人工智慧系統。我們提出了 CREST 框架，展示了一致性、
可靠性、使用者級可解釋性和安全性建立在 NeuroSymbolic 之上
使用數據和知識來支援關鍵需求的方法
健康和福祉等應用。本文主要關注大
語言模型 (LLM) 作為 CREST 框架內選定的人工智慧系統。法學碩士
因其多功能性而受到研究人員的廣泛關注
處理各種自然語言處理 (NLP) 場景。為了
例如，ChatGPT 和 Google 的 MedPaLM 已成為極具前景的工具
提供一般資訊和健康相關查詢的平台，
分別。然而，儘管如此，這些模型仍然是黑盒子
結合人類回饋和指令引導的調整。例如，
儘管設置了安全護欄，ChatGPT 仍可能產生不安全的回應。
CREST 提出了一種利用程式和基於圖形的可行方法
NeuroSymbolic 框架內的知識揭示了挑戰
與法學碩士相關。

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano et.al.

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

摘要：這項研究調查了性能、可解釋性和穩健性
部署人工智慧（AI）模型來預測死亡率
COVID-19 大流行及其他情況。這是此類研究中的第一項研究，我們發現
貝葉斯神經網路 (BNN) 和智慧訓練技術使我們能夠
模型在重大數據變化中保持性能。我們的成果
強調開發能夠匹配或
即使在充滿挑戰的條件下，也超出了臨床醫生的預測。我們的
對模型可解釋性的探索表明，隨機模型生成
更加多樣化和個性化的解釋，從而凸顯了對人工智慧的需求
為現實臨床提供詳細和個人化見解的模型
設定.此外，我們強調了量化不確定性的重要性
人工智慧模型使臨床醫生能夠根據情況做出更明智的決策
靠可靠的預測。我們的研究主張優先實施
醫療保健人工智慧研究中的科學，並確保人工智慧解決方案
在現實臨床環境中實用、有益且可持續。經過
解決醫療保健環境中的獨特挑戰和複雜性，
研究人員可以開發有效改善臨床實踐的人工智慧模型
和患者的結果。

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel et.al.

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

摘要：在英國，肺癌導致 21% 的癌症死亡，並且在五年內
存活率大程度受到癌症診斷階段的影響
在。最近的研究證明了人工智慧方法能夠準確地
以及透過常規掃描早期診斷肺癌。然而，這個證據
尚未轉化為臨床實踐，其中一個障礙是缺乏
可解釋的模型。本研究探討了變分法的應用
自動編碼器（VAE）是一種產生人工智慧模型，用於肺癌病變。
所提出的模型對從 3D CT 掃描中提取的病變進行了訓練
LIDC-IDRI 公共資料集。產生的 2D 切片的潛在向量表示
透過聚類探索 VAE 來證明其品質並使用
在用於肺癌診斷的 MLP 分類器模型中，取得了最佳模型
AUC 0.98 和 93.1% 準確度的最先進指標。聚類分析顯示
VAE 潛在空間將惡性和良性病變的資料集分開
基於有意義的特徵成分，包括腫瘤大小、形狀、患者
和惡性腫瘤類別。我們也對標準進行了比較分析
高斯 VAE (GVAE) 和更新的狄利克雷 VAE (DirVAE)，它取代了
具有狄利克雷分佈的先驗，以鼓勵更可解釋的潛在
具有解糾纏特徵表示的空間。最後，我們展示了
潛在空間穿越的潛力對應於臨床意義
功能變化。

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake et.al.

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

摘要：用於解釋影像分類器輸出的現有工具可以分為
分為白盒和黑盒，白盒依賴對模型內部的訪問，
與模型無關。隨著人工智慧在醫療領域的使用不斷增長，
使用可解釋性工具。醫學影像的現有工作
解釋著重於白盒工具，例如 gradcam。然而，有
切換到黑盒工具的明顯優勢，包括使用的能力
它與任何分類器和多種可用的黑盒工具一起使用。在
標準影像，黑盒工具與白盒工具一樣精確。在本文中我們
比較幾種黑盒子方法與 gradcam 在大腦上的表現
癌症 MRI 資料集。我們證明大多數黑盒工具都不適合
解釋醫學影像分類並提供詳細分析
他們的缺點的原因。我們還展示了一種黑盒工具，
基於因果可解釋性的 rex，表現與 \gradcam 一樣好。

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v2 by Robert Gorwa et.al.

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

摘要：人工智慧開發社群越來越多地利用託管
Hugging Face 等中介機構可以輕鬆存取用戶上傳的模型
和訓練資料。這些模型市場降低了技術部署壁壘
為數十萬用戶提供服務，但可用於許多潛在的領域
有害和非法的方式。在本文中，我們解釋了人工智慧系統的方式，
它既可以「包含」內容，又​​可以是開放式工具，提出了其中之一
迄今最棘手的平台治理挑戰。我們提供案例研究
三個說明性平台上的幾起事件——擁抱臉，
GitHub 和 Civita－研究模式市場如何調節模型。
在此分析的基礎上，我們概述了重要的（但仍然有限的）
業界為回應審核要求而發展的實務：
授權、存取和使用限制、自動內容審核以及開放
政策制定。儘管當前的政策挑戰相當大，
最後我們提出了一些關於平台如何更好地調動資源的想法
充當謹慎、公平和相稱的監管接入點。

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira et.al.

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

摘要：背景和目標：透過提取這些訊息，機器或深度
基於學習 (ML/DL) 的自主資料分析工具可以幫助臨床醫生和
癌症研究人員從複雜數據中發現模式和關係
套。最近，許多基於深度學習的卵巢癌 (OC) 數據分析已被
發表。這些分析在癌症的各個方面都高度多樣化
（例如，它們涉及的子域和癌症類型）和數據分析功能。
然而，對這些分析的全面理解
目前缺乏功能和人工智慧保證（AIA）。本次系統性回顧
旨在透過檢查現有文獻並確定來填補這一空白
使用 DL 進行 OC 資料分析的重要方面，明確關注關鍵
功能和人工智慧保證觀點。方法：使用PRISMA框架
在三個期刊資料庫中進行全面檢索。只學習
2015 年至 2023 年間在同儕審查期刊上發表的文章被納入
分析。結果：在回顧中，總共進行了 96 項深度學習驅動的分析
檢查了。研究結果揭示了有關深度學習驅動的幾個重要見解
卵巢癌資料分析： - 大多數研究 71%（96 項中的 68 項）集中於
檢測和診斷，但沒有研究涉及預測和預防
的OC。 - 分析主要基於非多樣化的樣本
人口（75%（72/96 研究）），僅限於某個地理位置或國家。
- 只有一小部分研究（僅 33% (32/96)）進行了整合
分析，其中大多數使用同質資料（臨床或組學）。 - 值得注意的是，一個
只有 8.3% (8/96) 的研究使用外部和外部驗證驗證了他們的模型
多樣化的資料集，強調增強模型驗證的必要性，以及 -
將 AIA 納入癌症數據分析尚處於非常早期的階段；僅有的
2.1% (2/96) 透過可解釋性明確解決了 AIA。

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal et.al.

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

摘要：可解釋性是深度學習中長期存在的挑戰，尤其是在
醫療保健等高風險領域。常見的可解釋性方法突出顯示
驅動人工智慧模型決策的圖像區域。然而，人類嚴重依賴
語言不僅可以傳達「哪裡」的解釋，還可以傳達「什麼」的解釋。
此外，大多數可解釋性方法都專注於解釋個體人工智慧
預測，而不是描述人工智慧模型使用的特徵
一般的。後者對於模型和資料集審計特別有用，
隨著人工智慧越來越多地被使用，甚至可能產生知識
新穎的任務。在這裡，我們提出了一種可解釋性策略，該策略使用
視覺語言模型，用於識別基於語言的視覺描述符
分類任務。透過利用預先訓練的聯合嵌入空間
圖像和文本，我們的方法將新的分類任務估計為線性
單字的組合，得出每個單字的權重，顯示其
與基於視覺的分類器對齊。我們使用兩個方法來評估我們的方法
醫學影像分類任務，我們發現結果
儘管缺乏描述，但描述符在很大程度上與臨床知識相符
特定領域的語言培訓。然而，我們的方法也確定了
所使用的公共資料集中存在「捷徑連接」的潛力。邁向一個
可解釋性的功能測量，我們進行了一項試點讀者研究，其中我們
發現人工智慧識別的單字可以使非專家人類執行
非平凡程度的專業醫療任務。總而言之，我們的結果
強調使用多模式基礎模型來交付的潛力
對視覺任務的直觀的、基於語言的解釋。

##### **Towards objective and systematic evaluation of bias in medical imaging AI**
2311.02115v1 by Emma A. M. Stanley et.al.

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

摘要：使用臨床醫學影像訓練的人工智慧 (AI) 模型
任務通常會表現出偏差，表現為不同任務之間的績效差異
亞組。由於現實世界的醫學影像資料中並非所有偏差來源
很容易識別，但全面評估這些
偏差被編碼在模型中，以及偏差緩解方法的能力如何
改善績效差距。在這篇文章中，我們介紹一本小說
系統性、客觀地調查影響的分析框架
人工智慧模型中醫學影像的偏差。我們開發並測試了這個
進行受控電腦試驗以評估醫學偏差的框架
使用產生合成磁振造影影像的工具進行人工智慧成像
已知的疾病影響和偏差來源。可行性體現在
使用三種反事實偏差場景來衡量模擬的影響
偏差對卷積神經網路（CNN）分類器的影響
三種偏見緩解策略的有效性。分析表明，
模擬偏差導致了預期的亞組表現差異，當
CNN 在合成資料集上進行了訓練。此外，也確定了重新稱重
作為此設定中最成功的偏差緩解策略，我們
展示了可解釋的人工智慧方法如何幫助調查
使用該框架的模型中偏差的表現。開發公平的人工智慧
鑑於許多且往往未知的來源，模型是一個相當大的挑戰
醫學影像資料集中可能存在偏差。在這項工作中，我們提出了一個
客觀研究偏見和緩解影響的新穎方法
深度學習管道策略，可以支援開發
強大且負責任的臨床人工智慧。

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White et.al.

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

摘要：機器學習為自動預測提供了巨大的潛力
中風後症狀及其對復原的反應。主要挑戰
這項努力包括非常高維度的神經影像數據，
可用於學習的資料集規模相對較小，以及如何
有效地結合神經影像和表格數據（例如人口統計信息
和臨床特徵）。本文評估了幾種基於
兩種策略。第一種是使用總結 MRI 掃描的 2D 影像。這
其次是選擇提高分類精度的關鍵特徵。
此外，我們介紹了訓練卷積的新方法
影像上的神經網路（CNN）結合了從影像中提取的興趣區域
MRI，具有表格資料的符號表示。我們評估了一系列
經過不同訓練的 CNN 架構（2D 和 3D）
MRI 和表格資料的表示，以預測複合測量是否
中風後口語圖片描述能力處於失語症或
非失語範圍。 MRI 和表格資料來自 758 位講英語的人
參加 PLORAS 研究的中風倖存者。分類
僅就病灶大小而言，基線邏輯迴歸的準確度為 0.678，
當初始症狀嚴重程度和恢復時間分別為 0.757 和 0.813
陸續添加。觀察到最高分類精度為 0.854
從每次 MRI 掃描中提取 8 個感興趣區域並與病變結合
二維殘差神經網路中的大小、初始嚴重性和恢復時間。
研究結果證明瞭如何將成像和表格數據結合起來以獲得高
中風後分類準確性，即使機器中的資料集很小
學習術語。最後我們提出當前模型如何
使用醫院影像進行改進以達到更高的準確性
掃描器。

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim et.al.

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

摘要：eXplainable 人工智慧 (XAI) 已成為不可或缺的
處理關鍵任務應用程式時的要求，確保
所採用的黑盒人工智慧模型的透明度和可解釋性。這
XAI 的重要性跨越各個領域，從醫療保健到金融，其中
理解深度學習演算法的決策過程是
基本的。大多數基於人工智慧的電腦視覺模型通常是黑盒子；因此，
在影像處理中提供深度神經網路的可解釋性至關重要
因其在醫學影像分析、自主
駕駛和遙感應用。最近，一些XAI方法
引入了影像分類任務。相反，圖像
細分領域受到的關注相對較少
可解釋性，儘管它是電腦視覺的一項基本任務
應用，尤其是遙感領域。只有一些研究提出
用於影像分割的基於梯度的 XAI 演算法。本文改編
最近用於語意分割的無梯度 Sobol XAI 方法。測量
為了評估 Sobol 分割方法的性能，我們提出了定量 XAI
基於可學習噪音模型的評估方法。此舉的主要目標
模型是在解釋圖上感應噪聲，其中感應噪聲較高
表示精度低，反之亦然。進行基準分析是為了
評估和比較三種 XAI 方法的效能，包括 Seg-Grad-CAM、
Seg-Grad-CAM++ 和 Seg-Sobol 使用所提出的基於噪音的評估
技術。這是運行和評估 XAI 方法的首次嘗試
使用高解析度衛星圖像。

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad et.al.

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

摘要：大型語言模型已經在很短的時間內跨越多個領域擴散
一段的時間。但在醫療保健方面卻存在猶豫
由於諸如事實性、連貫性和
幻覺。許多研究人員認為醫療保健具有高風險性
甚至警告不要使用它，直到這些問題得到解決。鑰匙
在醫療保健領域實施和部署法學碩士的目的是使這些
模型值得信賴、透明（盡可能）且可解釋。在這個
在本文中，我們描述了創建可靠、值得信賴和
公正的模型是其在醫療保健領域採用的必要條件。
具體來說，我們專注於量化、驗證和緩解
醫療保健中的幻覺。最後我們討論一下未來如何
醫療保健領域的法學碩士可能看起來像。

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska et.al.

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

摘要：人工智慧（AI）一直在快速發展，現在
準備部署在廣泛的應用中，例如自動駕駛
系統、醫學診斷和自然語言處理。早期採用
人工智慧技術在實際應用中並非沒有問題，
特別是對於神經網路來說，它可能不穩定且容易受到影響
對抗性例子。從長遠來看，適當的安全保證
需要開發技術來減少可避免的潛在危害
系統故障並確保可信度。專注於認證和
可解釋性，本文概述了已被採用的技術
旨在確保人工智慧決策的安全性並討論未來的挑戰。

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. García-Gómez et.al.

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

摘要：歐洲議會研究服務總局
議會已向歐洲議會議員準備了一份報告
他們列舉了人工智慧 (AI) 的七大主要風險
醫學與醫療保健：人工智慧錯誤造成的病患傷害、醫療人工智慧的濫用
工具、人工智慧的偏見以及現有不平等現象的持續存在、缺乏
透明度、隱私和安全問題、問責制缺陷以及
實施中的障礙。
  在這項研究中，我們提出了人工智慧系統的十四項功能要求
可以實施以降低與其醫療目的相關的風險：人工智慧
護照、使用者管理、法規檢查、僅限學術用途免責聲明、數據
品質評估、臨床醫師雙重檢查、持續績效評估、
審計追蹤、持續可用性測試、回顧性/模擬審查
案例、偏差檢查、可解釋的人工智慧、加密和經過現場測試的使用
庫和語義互通性。
  我們的目的是提供具體的高級規範
確保人工智慧系統持續良好效能和使用的技術解決方案
根據未來的歐盟監管框架使患者受益。

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik et.al.

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

摘要：人工智慧技術可用於對患者的病情進行分類
身體活動並預測生命徵像以進行遠端患者監測。
基於深度學習模型等非線性模型的迴歸分析
由於其黑盒性質，可解釋性有限。這可能需要
決策者根據非線性模型結果進行盲目的信念跳躍，
尤其是在醫療保健應用中。在非侵入性監測中，患者數據
追蹤感測器及其易感臨床屬性作為輸入
預測未來生命徵象的特徵。解釋貢獻
監控應用程式整體輸出的各種功能是
對於臨床醫師的決策至關重要。在這項研究中，一個可解釋的人工智慧
提出了事後模型的定量分析（QXAI）框架
迴歸和分類的可解釋性和內在可解釋性
監督學習方法中的任務。這是透過利用
Shapley 重視概念並將注意力機制納入深度學習中
楷模。我們採用了人工神經網路（ANN）和基於注意力的網絡
用於預測心率和心率的雙向 LSTM (BiLSTM) 模型
基於感測器數據的身體活動分類。深度學習
模型在預測和分類方面均取得了最先進的結果
任務。對輸入資料進行全局解釋和局部解釋
了解各種患者資料的特徵貢獻。擬議的QXAI
使用 PPG-DaLiA 數據評估框架以預測心率和移動
健康 (MHEALTH) 數據，根據感測器數據對身體活動進行分類。
框架中應用了蒙特卡羅近似來克服時間問題
Shapley 值所需的複雜性和高運算能力需求
計算。

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad et.al.

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

摘要：在可解釋人工智慧 (XAI) 研究中，主要關注點
一直致力於為專家和從業者解釋模型。模型不可知論
局部解釋方法被認為是可解釋的且是充分的
許多應用程式。然而，在醫療保健等領域，最終用戶
沒有人工智慧或領域專業知識的患者，迫切需要模型
更容易理解並增加對模型的信任的解釋
營運.我們假設生成的模型解釋是
敘述性、患者特異性和全局性（模型的整體性）將使
更好的理解性並有助於決策。我們使用一個來測試這個
決策樹模型為患者產生局部和全局解釋
被認定為冠心病高危險群。這些解釋
呈現給非專家使用者。我們發現對以下內容有強烈的個人偏好
具體類型的解釋。大多數參與者更喜歡全球
解釋，而較小的群體更喜歡本地解釋。基於任務
對這些參與者的心理模型的評估提供了寶貴的回饋
增強敘事的全局解釋。這反過來又指導了設計
既值得信賴又可操作的健康資訊系統。

##### **An explainable three dimension framework to uncover learning patterns: A unified look in variable sulci recognition**
2309.00903v2 by Michail Mamalakis et.al.

Explainable AI is crucial in medical imaging. In the challenging field of
neuroscience, visual topics present a high level of complexity, particularly
within three-dimensional space. The application of neuroscience, which involves
identifying brain sulcal features from MRI, faces significant hurdles due to
varying annotation protocols among experts and the intricate three-dimension
functionality of the brain. Consequently, traditional explainability approaches
fall short in effectively validating and evaluating these networks. To address
this, we first present a mathematical formulation delineating various
categories of explanation needs across diverse computer vision tasks,
categorized into self-explanatory, semi-explanatory, non-explanatory, and
new-pattern learning applications based on the reliability of the validation
protocol. With respect to this mathematical formulation, we propose a 3D
explainability framework aimed at validating the outputs of deep learning
networks in detecting the paracingulate sulcus an essential brain anatomical
feature. The framework integrates local 3D explanations, global explanations
through dimensionality reduction, concatenated global explanations, and
statistical shape features, unveiling new insights into pattern learning. We
trained and tested two advanced 3D deep learning networks on the challenging
TOP-OSLO dataset, significantly improving sulcus detection accuracy,
particularly on the left hemisphere. During evaluation with diverse annotation
protocols for this dataset, we highlighted the crucial role of an unbiased
annotation process in achieving precise predictions and effective pattern
learning within our proposed 3D framework. The proposed framework not only
annotates the variable sulcus but also uncovers hidden AI knowledge, promising
to advance our understanding of brain anatomy and function.

摘要：可解釋的人工智慧在醫學影像中至關重要。在充滿挑戰的領域
神經科學、視覺主題呈現出高度的複雜性，特別是
三度空間內。神經科學的應用，包括
從 MRI 識別腦溝特徵面臨重大障礙
專家之間不同的註釋協議和複雜的三維
大腦的功能。因此，傳統的可解釋性方法
無法有效驗證和評估這些網路。演講
為此，我們首先提出一個數學公式來描述各種
不同電腦視覺任務的詮釋需求類別，
分為自解釋性、半解釋性、非解釋性和
基於驗證可靠性的新模式學習應用
協定.對於這個數學公式，我們提出了一個 3D
旨在驗證深度學習輸出的可解釋性框架
檢測旁扣帶溝的網路是重要的大腦解剖學
特徵。此框架整合了局部3D解釋、全局解釋
透過降維、串聯全局解釋，以及
統計形狀特徵，揭示了模式學習的新見解。我們
在具有挑戰性的任務上訓練和測試了兩個先進的 3D 深度學習網絡
TOP-OSLO資料集，顯著提高齦溝偵測精度，
特別是在左半球。在使用不同註釋進行評估時
對於該資料集的協議，我們強調了公正的關鍵作用
實現精確預測和有效模式的註釋過程
在我們提出的 3D 框架內學習。所提出的框架不僅
註釋了可變溝，同時也揭示了隱藏的人工智慧知識，有望
增進我們對大腦解剖結構和功能的理解。

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao et.al.

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

摘要：電子健康記錄 (EHR) 和常規記錄實踐發揮著重要作用
在患者的日常護理中發揮著至關重要的作用，提供全面的健康記錄，
診斷、治療。然而，複雜而冗長的 EHR 敘述超載
醫療保健提供者面臨診斷不準確的風險。而大語言
模型（LLM）展示了他們在不同語言任務中的潛力，他們的
在醫療保健領域的應用需要確保最大限度地減少
診斷錯誤和預防患者傷害。在本文中，我們概述了
提高法學碩士在以下領域的熟練程度的創新方法
透過結合醫療系統實現自動診斷生成
知識圖（KG）和一種新穎的圖模型：Dr.Knows，靈感來自於
臨床診斷推理過程。我們從國家數據中得出 KG
醫學圖書館的統一醫學語言系統 (UMLS)
生物醫學知識庫。我們的方法不需要
預訓練，而是利用 KG 作為輔助工具來輔助
複雜醫學概念的解釋與總結。使用
真實世界的醫院數據集，我們的實驗結果表明
所提出的將 LLM 與 KG 結合的方法有可能改善
自動診斷產生的準確性。更重要的是，我們的方法
提供了一個可解釋的診斷途徑，使我們更接近實現
人工智慧增強診斷決策支援系統。

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh et.al.

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

摘要：用於診斷膝蓋的現有人工智慧 (AI) 模型
骨關節炎（OA）因其缺乏透明度而受到批評
儘管實現了醫學專家般的表現，但仍具有可解釋性。這
不透明性使得它們在臨床實踐中難以信任。最近，
可解釋的人工智慧（XAI）已經成為一種專門的
可以透過揭示模型預測提供信心的技術
預測是如何得出的，從而促進人工智慧系統在
衛生保健。本文首次介紹了用於 XAI 技術的調查
膝關節 OA 診斷。 XAI 技術從兩個角度討論： 數據
可解釋性和模型可解釋性。本文的目的是
為 XAI 打造更可靠的膝關節 OA 的潛力提供有價值的見解
診斷方法並鼓勵其在臨床實踐中採用。

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic et.al.

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

摘要：人工智慧在醫療保健領域的應用最近取得了令人難以置信的進展
有望在診斷和疾病預後方面超越人類。
然而，隨著人工智慧模型的複雜性不斷增加，人們對其模型的擔憂
不透明性、潛在偏見以及可解釋性的需要。確保信任
人工智慧系統的可靠性，特別是臨床風險預測模型，
可解釋性變得至關重要。可解釋性通常被稱為 AI
系統對其決策提供可靠解釋的能力
人類利害關係人的邏輯或決策本身。在臨床風險方面
預測、可解釋性的其他方面，如公平、偏見、信任和
透明度也代表了超越可解釋性的重要概念。在
在這篇評論中，我們討論了這些概念之間的關係
經常一起使用或互換使用。這篇評論也討論了最近
在開發可解釋的臨床風險預測模型方面取得進展，
強調定量和臨床評估的重要性
臨床實務中多種常見模式的驗證。它
強調外部驗證的必要性和多樣化的結合
可解釋性方法，以增強信任和公平。採用嚴格的
測試，例如使用具有已知生成因素的合成資料集，可以
進一步提高可解釋性方法的可靠性。開放取用和
程式碼共享資源對於透明度和可重複性至關重要，
促進可解釋研究的發展和可信度。儘管
挑戰存在，臨床風險可解釋性的端到端方法
結合從臨床醫生到開發人員的利害關係人的預測，
成功的關鍵。

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v1 by Karim Lekadir et.al.

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

摘要：儘管醫學和人工智慧（AI）取得了重大進展
在醫療保健方面，人工智慧技術的部署和採用仍然有限
真實世界的臨床實務。近年來，人們擔心
與醫療人工智慧相關的技術、臨床、倫理和法律風險。到
提高現實世界的採用率，醫療人工智慧工具的可信度至關重要
並被病人、臨床醫生、衛生組織和當局所接受。
這項工作將 FUTURE-AI 指南描述為第一個國際標準
指導可信賴的開發和部署的共識框架
醫療保健領域的人工智慧工具。 FUTURE-AI 聯盟成立於 2021 年，
目前由來自 51 個國家的 118 名跨學科專家組成
代表各大洲，包括人工智慧科學家、臨床醫生、倫理學家、
和社會科學家。在兩年的時間內，該聯盟制定了指導方針
透過迭代過程實現值得信賴的人工智慧的原則和最佳實踐
包括深入的文獻綜述、修改後的德爾菲調查以及在線
共識會議。 FUTURE-AI框架是根據6大指導原則建立的
醫療保健領域值得信賴的人工智慧原則，即公平性、普遍性、
可追溯性、可用性、穩健性和可解釋性。透過共識，
定義了 28 項最佳實踐，涉及技術、臨床、法律
和社會倫理維度。這些建議涵蓋了整個生命週期
醫療人工智慧，從設計、開發和驗證到監管、部署，
和監控。 FUTURE-AI 是一項風險知情、無假設的指南，
提供了一種建構醫療人工智慧工具的結構化方法
在現實世界的實踐中得到信任、部署和採用。研究人員是
鼓勵在概念驗證階段考慮這些建議
促進未來向醫療人工智慧臨床實踐的轉化。

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas et.al.

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

摘要：人工智慧在醫學領域取得重大進展
醫學影像、病患照護和其他領域的新興應用。儘管
這些應用在回顧性研究中被證明是成功的，但很少有
醫療AI領域面臨各種挑戰，
在建立使用者信任、遵守法規、使用數據方面
可解釋的人工智慧（XAI）旨在使人類理解人工智慧並信任
它的結果。本文對最近的發展進行了文獻綜述
基於代表性樣本的 XAI 醫療決策支援解決方案
近年發表論文198篇。系統綜合
相關文章得出了一些結論。 (1) 模型無關的 XAI
這些解決方案中主要採用了技術，（2）深度學習模型
比其他類型的機器學習模型得到更多利用，(3)
可解釋性被用來促進信任，但很少有作品報導這一點
醫生參與循環，（4）視覺化和互動式使用者介面
對於理解解釋和建議更有用
系統。醫學和人工智慧之間的合作需要更多的研究
專家可以指導適當的框架
醫學 XAI 解決方案的設計、實施和評估。

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay et.al.

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

摘要：體外受精是最廣泛的治療方法之一
不孕症。其主要挑戰​​之一是評估和選擇
胚胎植入，這是一個需要大量臨床醫生之間和內部的過程
變化性。基於深度學習的方法正在引起人們的關注，但它們的
不透明的性質損害了它們在臨床環境中的接受度，其中
決策的透明度是關鍵。在本文中我們分析了
目前人工智慧輔助胚胎分析模型的可解釋性工作，
確定局限性。我們也討論了這些模型如何
作為決策支援系統整合到臨床環境中，考慮到
臨床醫生和患者的需求。最後，我們提出指導方針
提高可解釋性和可信度，推動這項技術
朝著既定的臨床實踐邁進。

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith et.al.

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程（RE）領域，越來越多的人
可解釋人工智慧 (XAI) 在協調中的重要性
具有使用者需求、社會期望和監管的人工智慧支援系統
標準已獲得認可。一般來說，可解釋性已經出現
影響系統品質的重要非功能性需求。然而，
可解釋性和性能之間所謂的權衡挑戰
假定可解釋性的正面影響。如果滿足要求
可解釋性會導致系統效能下降，那麼要小心
必須考慮這些品質面向中哪一個優先
以及如何在它們之間妥協。在本文中，我們批判性地研究了
所謂的權衡。我們認為最好以細緻入微的方式來處理
包含資源可用性、領域特徵和注意事項
的風險。透過為未來的研究和最佳實踐提供基礎，
工作旨在推進人工智慧的可再生能源領域。

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook et.al.

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程（RE）領域，越來越多的人
可解釋人工智慧 (XAI) 在協調中的重要性
具有使用者需求、社會期望和監管的人工智慧支援系統
標準已獲得認可。一般來說，可解釋性已經出現
影響系統品質的重要非功能性需求。然而，
可解釋性和性能之間所謂的權衡挑戰
假定可解釋性的正面影響。如果滿足要求
可解釋性會導致系統效能下降，那麼要小心
必須考慮這些品質面向中哪一個優先
以及如何在它們之間妥協。在本文中，我們批判性地研究了
所謂的權衡。我們認為最好以細緻入微的方式來處理
包含資源可用性、領域特徵和注意事項
的風險。透過為未來的研究和最佳實踐提供基礎，
工作旨在推進人工智慧的可再生能源領域。

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser et.al.

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

摘要：本文批判性地評估了歐盟委員會提出的人工智慧法案
高風險人工智慧系統的風險管理和風險可接受性方法
對基本權利和安全構成風險。該法案旨在促進
「值得信賴」的人工智慧，具有相應的監管負擔。其關於風險的規定
可接受性要求降低高風險系統的殘餘風險或
考慮到“現有技術”，“盡可能”消除。這
標準，特別是如果狹隘地解釋，是行不通的，並且會促進
既沒有適當的監理負擔，也沒有可信度。相比之下
議會最新的風險管理條款修正案草案
引入“合理性”，成本效益分析，更加透明
關於風險可接受性判斷的價值負載和背景性質。
本文認為議會的做法更可行，也更好
平衡比例性和可信性的目標。它解釋了什麼
風險可接受性判斷的合理性將需要藉鑑
過失法和歐洲醫療器材法規的原則。還有它
認為風險可接受性判斷的方法需要堅定的
公民合法性的基礎：包括來自政府的詳細指導或參與
監管機構以及受影響利益相關者的有意義的意見。

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina et.al.

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

摘要：eXplainable 人工智慧 (XAI) 是一個快速發展的領域
機器學習，旨在闡明複雜模型的預測。 XAI 是
在敏感應用中尤其需要，例如在醫療保健方面，當
診斷、建議和治療選擇可能取決於決策
人工智慧系統製造。人工智慧方法已廣泛應用
在老化研究中，特別是在開發生理時鐘模型中
並識別衰老和與年齡相關的疾病的生物標記。但是，那
XAI 的潛力有待充分發揮。我們討論的是
應用 XAI 開發“老化時鐘”並提出
按特定重點分類的文獻的綜合分析
生理系統。

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta et.al.

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

摘要：部分原型模型是可解釋的設計圖像分類器，並且
有希望替代黑盒人工智慧。本文探討了其適用性
以及可解釋機器學習的潛力，特別是 PIP-Net，
對現實世界醫學影像數據的自動診斷支援。 PIP-Net 學習
人類可理解的原型影像部分，我們評估其準確性和
骨折檢測和皮膚癌診斷的可解釋性。我們發現
PIP-Net的決策過程符合醫學分類
標準，而僅提供圖像級類別標籤。因為
PIP-Net的無監督原型預訓練，資料品質問題如
X 光中不需要的文字或標籤錯誤可以輕鬆識別。
此外，我們是第一個證明人類可以手動修正
透過直接停用不需要的原型來推理 PIP-Net。我們得出結論
部分原型模型由於它們的優點而在醫療應用上很有前景
可解釋性和高級模型調試的潛力。

##### **Explaining and visualizing black-box models through counterfactual paths**
2307.07764v3 by Bastian Pfeifer et.al.

Explainable AI (XAI) is an increasingly important area of machine learning
research, which aims to make black-box models transparent and interpretable. In
this paper, we propose a novel approach to XAI that uses the so-called
counterfactual paths generated by conditional permutations of features. The
algorithm measures feature importance by identifying sequential permutations of
features that most influence changes in model predictions. It is particularly
suitable for generating explanations based on counterfactual paths in knowledge
graphs incorporating domain knowledge. Counterfactual paths introduce an
additional graph dimension to current XAI methods in both explaining and
visualizing black-box models. Experiments with synthetic and medical data
demonstrate the practical applicability of our approach.

摘要：可解釋的人工智慧（XAI）是機器學習中日益重要的領域
研究，旨在使黑盒模型透明且可解釋。在
在本文中，我們提出了一種新的 XAI 方法，該方法使用所謂的
由特徵的條件排列產生的反事實路徑。這
演算法透過識別順序排列來衡量特徵重要性
對模型預測變化影響最大的特徵。它特別是
適合根據知識中的反事實路徑生成解釋
包含領域知識的圖表。反事實路徑引入了
當前 XAI 方法的附加圖形維度，用於解釋和
可視化黑盒模型。合成數據和醫學數據的實驗
展示我們方法的實際適用性。

##### **Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**
2307.02131v5 by Toygar Tanyel et.al.

The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of "what if?" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to enhance
acceptance of AI-driven methods in clinical research.

摘要：人工智慧 (AI) 的可解釋性領域見證了
研究數量不斷增加，學術興趣不斷增加。然而，缺乏
在解釋結果時採用人性化和個性化的解釋
機器學習演算法極大地阻礙了這些技術的接受
臨床醫生在研究和臨床實踐中採用的方法。為了解決這個問題
問題，我們的研究使用反事實解釋來探索其適用性
“如果呢？”醫學研究中的場景。我們的目標是擴大我們的
了解用於診斷的磁振造影 (MRI) 特徵
超出現有邊界的小兒後顱窩腦腫瘤。在我們的例子中
研究中，所提出的概念提供了一種檢查替代方案的新方法
提供個人化和特定情境的決策場景
見解，能夠驗證預測並澄清
不同情況下的變化。此外，我們也探索潛力
使用反事實進行資料增強並評估其可行性
我們的醫學研究案例中的另一種方法。結果表明
使用反事實解釋來增強的有希望的潛力
在臨床研究中接受人工智慧驅動的方法。

##### **AI and Non AI Assessments for Dementia**
2307.01210v1 by Mahboobeh Parsapoor et.al.

Current progress in the artificial intelligence domain has led to the
development of various types of AI-powered dementia assessments, which can be
employed to identify patients at the early stage of dementia. It can
revolutionize the dementia care settings. It is essential that the medical
community be aware of various AI assessments and choose them considering their
degrees of validity, efficiency, practicality, reliability, and accuracy
concerning the early identification of patients with dementia (PwD). On the
other hand, AI developers should be informed about various non-AI assessments
as well as recently developed AI assessments. Thus, this paper, which can be
readable by both clinicians and AI engineers, fills the gap in the literature
in explaining the existing solutions for the recognition of dementia to
clinicians, as well as the techniques used and the most widespread dementia
datasets to AI engineers. It follows a review of papers on AI and non-AI
assessments for dementia to provide valuable information about various dementia
assessments for both the AI and medical communities. The discussion and
conclusion highlight the most prominent research directions and the maturity of
existing solutions.

摘要：當前人工智慧領域的進步已經導致
開發各種類型的人工智慧驅動的癡呆症評估，可以
用於識別早期癡呆症患者。它可以
徹底改變癡呆症照護環境。至關重要的是，醫療
社群了解各種人工智慧評估，並根據自己的情況選擇它們
有效性、效率、實用性、可靠性和準確性的程度
關於癡呆症患者（PwD）的早期識別。上
另一方面，人工智慧開發人員應該了解各種非人工智慧評估
以及最近開發的人工智慧評估。因此，本文可以
臨床醫生和人工智慧工程師都可以閱讀，填補了文獻空白
在解釋識別癡呆症的現有解決方案時
臨床醫生，以及所使用的技術和最普遍的癡呆症
向人工智慧工程師提供資料集。它是對人工智慧和非人工智慧論文的回顧
癡呆症評估，提供有關各種癡呆症的寶貴信息
對人工智慧和醫學界的評估。討論和
結論強調了最突出的研究方向和成熟度
現有的解決方案。

##### **Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**
2306.07306v1 by Ruitao Xie et.al.

Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.

摘要：可解釋性對人工智慧 (AI) 提出了重大挑戰
技術。目前對可解釋人工智慧（XAI）的研究缺乏效率
提取有關學習任務的全局知識，從而遭受缺陷
例如不精確的顯著性、上下文感知的缺失和模糊的含義。在這個
論文中，我們提出了類別關聯嵌入（CAE）方法來解決
這些問題。我們採用編碼器-解碼器架構來嵌入樣本
特徵並將其分為與階級相關的風格和與個人相關的風格
同時向量。重新組合給定範例的個人風格程式碼
與另一個類風格的程式碼一起導致合成樣本保留
單一字元但改變了類別分配，遵循循環
對抗性學習策略。類別關聯嵌入提煉出全域
將所有實例的類別相關特徵放入一個統一的域中
階級之間的分離。不同類別之間的轉換規則可以
然後被提取並進一步應用於各個實例。然後我們建議
一個活躍的 XAI 框架，它操縱某個特定的類別樣式向量
沿著引導路徑向反類別進行取樣，從而產生一系列
具有相同個體特徵的反例合成樣本。
將這些反事實樣本與原始樣本進行比較可以提供
全局、直觀地說明分類任務的性質。我們
採用醫學影像分類任務的框架，顯示更多
具有強大的上下文感知表示的精確顯著圖可以
與現有方法相比所取得的成果。此外，疾病病理可
透過遍歷類風格空間中的路徑直接視覺化。

##### **HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**
2306.06029v1 by Rodrigo Agerri et.al.

Providing high quality explanations for AI predictions based on machine
learning is a challenging and complex task. To work well it requires, among
other factors: selecting a proper level of generality/specificity of the
explanation; considering assumptions about the familiarity of the explanation
beneficiary with the AI task under consideration; referring to specific
elements that have contributed to the decision; making use of additional
knowledge (e.g. expert evidence) which might not be part of the prediction
process; and providing evidence supporting negative hypothesis. Finally, the
system needs to formulate the explanation in a clearly interpretable, and
possibly convincing, way. Given these considerations, ANTIDOTE fosters an
integrated vision of explainable AI, where low-level characteristics of the
deep learning process are combined with higher level schemes proper of the
human argumentation capacity. ANTIDOTE will exploit cross-disciplinary
competences in deep learning and argumentation to support a broader and
innovative view of explainable AI, where the need for high-quality explanations
for clinical cases deliberation is critical. As a first result of the project,
we publish the Antidote CasiMedicos dataset to facilitate research on
explainable AI in general, and argumentation in the medical domain in
particular.

摘要：為基於機器的AI預測提供高品質的解釋
學習是一項具有挑戰性且複雜的任務。為了良好地工作，它需要
其他因素：選擇適當程度的通用性/特殊性
解釋;考慮對解釋的熟悉程度的假設
正在考慮的人工智慧任務的受益人；指具體的
促成該決定的因素；利用額外的
可能不屬於預測一部分的知識（例如專家證據）
過程;並提供支持否定假設的證據。最後，
系統需要以清晰可解釋的方式製定解釋，並且
可能有說服力，方式。考慮到這些因素，ANTIDOTE 促進了
可解釋人工智慧的綜合願景，其中低階特徵
深度學習過程與更高層次的方案結合
人類的論證能力。 ANTIDOTE 將利用跨學科
深度學習和論證的能力，以支持更廣泛和
可解釋人工智慧的創新觀點，其中需要高品質的解釋
對於臨床病例，深思熟慮至關重要。作為該專案的第一個成果，
我們發布了 Antidote CasiMedicos 資料集以促進以下方面的研究
一般可解釋的人工智慧，以及醫學領域的爭論
特別的。

##### **XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**
2306.04791v1 by Eli Laird et.al.

Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.

摘要：近年來，圖神經網路的進展迅速，
藥物發現、醫學診斷和推薦方面的許多新進展
系統。雖然這一進展很顯著，但許多網路都是“黑盒子”
對網路到底在學習「什麼」所知甚少。許多
高風險的應用程序，例如藥物發現，需要人類可理解的
模型的解釋，以便使用者能夠識別錯誤並發現
新知識。因此，開發可解釋的人工智慧演算法是
對於我們獲得人工智慧的好處至關重要。
  我們提出了一個名為 eXplainable Insight 的 GNN 可解釋性演算法
(XInsight) 使用 GFlowNets 產生模型解釋的分佈。
由於 GFlowNet 產生的物件的機率與獎勵成正比，
與以前相比，XInsight 可以產生多種解釋
只學習最大獎勵樣本的方法。我們透過以下方式展示 XInsight
為在兩個圖分類任務上訓練的 GNN 產生解釋：
使用 MUTAG 資料集對誘變化合物進行分類並對非環狀化合物進行分類
帶有我們開源的合成資料集的圖表。我們展示實用性
透過使用 QSAR 分析產生的化合物來了解 XInsight 的解釋
建模，我們發現 XInsight 產生的化合物透過以下方式聚類
親脂性，已知與致突變性有關。我們的結果表明
XInsight 產生解釋分佈，揭示底層
模型所展示的關係。他們還強調了
產生一系列不同的解釋，因為它使我們能夠發現隱藏的
模型中的關係，並為進一步分析提供有價值的指導。

##### **Explainable AI using expressive Boolean formulas**
2306.03976v1 by Gili Rosenberg et.al.

We propose and implement an interpretable machine learning classification
model for Explainable AI (XAI) based on expressive Boolean formulas. Potential
applications include credit scoring and diagnosis of medical conditions. The
Boolean formula defines a rule with tunable complexity (or interpretability),
according to which input data are classified. Such a formula can include any
operator that can be applied to one or more Boolean variables, thus providing
higher expressivity compared to more rigid rule-based and tree-based
approaches. The classifier is trained using native local optimization
techniques, efficiently searching the space of feasible formulas. Shallow rules
can be determined by fast Integer Linear Programming (ILP) or Quadratic
Unconstrained Binary Optimization (QUBO) solvers, potentially powered by
special purpose hardware or quantum devices. We combine the expressivity and
efficiency of the native local optimizer with the fast operation of these
devices by executing non-local moves that optimize over subtrees of the full
Boolean formula. We provide extensive numerical benchmarking results featuring
several baselines on well-known public datasets. Based on the results, we find
that the native local rule classifier is generally competitive with the other
classifiers. The addition of non-local moves achieves similar results with
fewer iterations, and therefore using specialized or quantum hardware could
lead to a speedup by fast proposal of non-local moves.

摘要：我們提出並實現了可解釋的機器學習分類
基於富有表現力的布林公式的可解釋人工智慧 (XAI) 模型。潛在的
應用包括信用評分和醫療狀況診斷。這
布林公式定義了具有可調複雜性（或可解釋性）的規則，
根據輸入資料進行分類。這樣的公式可以包括任何
可以應用於一個或多個布林變數的運算符，從而提供
與更嚴格的基於規則和基於樹的相比，具有更高的表達能力
接近。使用本機局部最佳化來訓練分類器
技術，有效搜尋可行公式的空間。淺規則
可以透過快速整數線性規劃 (ILP) 或二次方程式來確定
無約束二元最佳化 (QUBO) 求解器，可能由
專用硬體或量子設備。我們將表現力和
本地本地優化器的效率與這些的快速操作
透過執行非本地移動來優化整個設備的子樹
布爾公式。我們提供廣泛的數值基準測試結果，包括
著名公共資料集的幾個基線。根據結果，我們發現
本地本地規則分類器通常與其他分類器競爭
分類器。增加非本地移動可以達到類似的結果
更少的迭代，因此使用專用或量子硬體可以
透過快速提出非本地移動來加速。

##### **Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**
2306.03902v1 by Yeldar Toleubay et.al.

In response to the global challenge of mental health problems, we proposes a
Logical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis
of mental disorders. Due to the lack of effective therapy coverage for mental
disorders, there is a need for an AI solution that can assist therapists with
the diagnosis. However, current Neural Network models lack explainability and
may not be trusted by therapists. The LNN is a Recurrent Neural Network
architecture that combines the learning capabilities of neural networks with
the reasoning capabilities of classical logic-based AI. The proposed system
uses input predicates from clinical interviews to output a mental disorder
class, and different predicate pruning techniques are used to achieve
scalability and higher scores. In addition, we provide an insight extraction
method to aid therapists with their diagnosis. The proposed system addresses
the lack of explainability of current Neural Network models and provides a more
trustworthy solution for mental disorder diagnosis.

摘要：為因應心理健康問題的全球挑戰，我們提出
基於邏輯神經網路 (LNN) 的神經符號 AI 診斷方法
的精神障礙。由於缺乏有效的精神治療覆蓋
疾病，需要一種人工智慧解決方案來幫助治療師
診斷。然而，目前的神經網路模型缺乏可解釋性，且
可能不被治療師信任。 LNN 是循環神經網絡
將神經網路的學習能力與
基於經典邏輯的人工智慧的推理能力。擬議的系統
使用臨床訪談的輸入謂詞來輸出精神障礙
類，並使用不同的謂詞剪枝技術來實現
可擴展性和更高的分數。此外，我們還提供洞察提取
幫助治療師進行診斷的方法。建議的系統地址
當前神經網路模型缺乏可解釋性，並提供了更多
值得信賴的精神障礙診斷解決方案。

##### **XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**
2306.01668v1 by Sujith K Mandala et.al.

As machine learning models become increasingly prevalent in medical
diagnostics, the need for interpretability and transparency becomes paramount.
The XAI Renaissance signifies a significant shift in the field, aiming to
redefine the interpretability of medical diagnostic models. This paper explores
the innovative approaches and methodologies within the realm of Explainable AI
(XAI) that are revolutionizing the interpretability of medical diagnostic
models. By shedding light on the underlying decision-making process, XAI
techniques empower healthcare professionals to understand, trust, and
effectively utilize these models for accurate and reliable medical diagnoses.
This review highlights the key advancements in XAI for medical diagnostics and
their potential to transform the healthcare landscape, ultimately improving
patient outcomes and fostering trust in AI-driven diagnostic systems.

摘要：隨著機器學習模型在醫療領域變得越來越普遍
診斷時，可解釋性和透明度的需求變得至關重要。
XAI Renaissance 標誌著該領域的重大轉變，旨在
重新定義醫學診斷模型的可解釋性。本文探討
可解釋人工智慧領域的創新方法和方法
(XAI) 正在徹底改變醫療診斷的可解釋性
楷模。透過揭示潛在的決策過程，XAI
科技使醫療保健專業人員能夠理解、信任和
有效地利用這些模型進行準確可靠的醫療診斷。
這篇綜述強調了 XAI 在醫療診斷和
他們改變醫療保健格局的潛力，最終改善
患者治療結果並培養對人工智慧驅動的診斷系統的信任。

##### **A Novel real-time arrhythmia detection model using YOLOv8**
2305.16727v3 by Guang Jun Nicholas Ang et.al.

In a landscape characterized by heightened connectivity and mobility, coupled
with a surge in cardiovascular ailments, the imperative to curtail healthcare
expenses through remote monitoring of cardiovascular health has become more
pronounced. The accurate detection and classification of cardiac arrhythmias
are pivotal for diagnosing individuals with heart irregularities. This study
underscores the feasibility of employing electrocardiograms (ECG) measurements
in the home environment for real-time arrhythmia detection. Presenting a fresh
application for arrhythmia detection, this paper leverages the cutting-edge
You-Only-Look-Once (YOLO)v8 algorithm to categorize single-lead ECG signals. We
introduce a novel loss-modified YOLOv8 model, fine-tuned on the MIT-BIH
arrhythmia dataset, enabling real-time continuous monitoring. The obtained
results substantiate the efficacy of our approach, with the model attaining an
average accuracy of 99.5% and 0.992 mAP@50, and a rapid detection time of 0.002
seconds on an NVIDIA Tesla V100. Our investigation exemplifies the potential of
real-time arrhythmia detection, enabling users to visually interpret the model
output within the comfort of their homes. Furthermore, this study lays the
groundwork for an extension into a real-time explainable AI (XAI) model capable
of deployment in the healthcare sector, thereby significantly advancing the
realm of healthcare solutions.

摘要：在以高度連結性和流動性為特徵的景觀中，結合
隨著心血管疾病的激增，削減醫療保健勢在必行
透過遠端監測心血管健康的費用變得越來越多
發音。心律不整的準確檢測與分類
對於診斷心臟不規則的個體至關重要。這項研究
強調以心電圖 (ECG) 測量的可行性
在家庭環境中進行即時心律不整檢測。呈現新鮮的
心律不整檢測的應用，本文利用了尖端技術
You-Only-Look-Once (YOLO)v8 演算法對單導極 ECG 訊號進行分類。我們
介紹一種新穎的損失修改 YOLOv8 模型，在 MIT-BIH 上進行了微調
心律不整資料集，實現即時連續監測。得到的
結果證實了我們方法的有效性，模型達到了
平均準確度為 99.5%，mAP@50 為 0.992，快速偵測時間為 0.002
NVIDIA Tesla V100 上的秒數。我們的調查證明了潛力
即時心律不整檢測，使用戶能夠直觀地解釋模型
在舒適的家中即可輸出。此外，這項研究也提出
為擴展至即時可解釋人工智慧 (XAI) 模型奠定了基礎
醫療保健領域的部署，從而顯著推進
醫療保健解決方案領域。

##### **Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**
2305.14389v2 by Jai Vardhan et.al.

Breast cancer (BC) remains a significant health threat, with no long-term
cure currently available. Early detection is crucial, yet mammography
interpretation is hindered by high false positives and negatives. With BC
incidence projected to surpass lung cancer, improving early detection methods
is vital. Thermography, using high-resolution infrared cameras, offers promise,
especially when combined with artificial intelligence (AI). This work presents
an attention-based convolutional neural network for segmentation, providing
increased speed and precision in BC detection and classification. The system
enhances images and performs cancer segmentation with explainable AI. We
propose a transformer-attention-based convolutional architecture (UNet) for
fault identification and employ Gradient-weighted Class Activation Mapping
(Grad-CAM) to analyze areas of bias and weakness in the UNet architecture with
IRT images. The superiority of our proposed framework is confirmed when
compared with existing deep learning frameworks.

摘要：乳癌（BC）仍然是一個重大的健康威脅，並且沒有長期的
目前可以治癒。早期發現至關重要，但乳房X光檢查
高誤報和誤報阻礙了解釋。與BC
發生率預計將超過肺癌，改善早期檢測方法
至關重要。使用高解析度紅外線攝影機的熱成像技術提供了希望，
尤其是與人工智慧（AI）結合時。這部作品呈現
用於分割的基於注意力的捲積神經網絡，提供
提高 BC 檢測和分類的速度和精度。系統
透過可解釋的人工智慧增強影像並執行癌症分割。我們
提出一種基於變壓器注意力的捲積架構（UNet）
故障識別並採用梯度加權類別啟動映射
(Grad-CAM) 分析 UNet 架構中的偏差和弱點領域
IRT 影像。我們提出的框架的優越性在以下情況得到證實：
與現有的深度學習框架相比。

##### **What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**
2305.13127v2 by Junwei Kuang et.al.

Depression is the most prevalent and serious mental illness, which induces
grave financial and societal ramifications. Depression detection is key for
early intervention to mitigate those consequences. Such a high-stake decision
inherently necessitates interpretability. Although a few depression detection
studies attempt to explain the decision based on the importance score or
attention weights, these explanations misalign with the clinical depression
diagnosis criterion that is based on depressive symptoms. To fill this gap, we
follow the computational design science paradigm to develop a novel Multi-Scale
Temporal Prototype Network (MSTPNet). MSTPNet innovatively detects and
interprets depressive symptoms as well as how long they last. Extensive
empirical analyses using a large-scale dataset show that MSTPNet outperforms
state-of-the-art depression detection methods with an F1-score of 0.851. This
result also reveals new symptoms that are unnoted in the survey approach, such
as sharing admiration for a different life. We further conduct a user study to
demonstrate its superiority over the benchmarks in interpretability. This study
contributes to IS literature with a novel interpretable deep learning model for
depression detection in social media. In practice, our proposed method can be
implemented in social media platforms to provide personalized online resources
for detected depressed patients.

摘要：憂鬱症是最普遍、最嚴重的精神疾病，它會導致
嚴重的財務和社會影響。憂鬱症檢測是關鍵
及早介入以減輕這些後果。如此高風險的決定
本質上需要可解釋性。雖然檢測出一些憂鬱症
研究試圖根據重要性分數或
注意力權重，這些解釋與臨床憂鬱症不一致
基於憂鬱症狀的診斷標準。為了填補這一空白，我們
遵循計算設計科學範式開發一種新穎的多尺度
時間原型網路 (MSTPNet)。 MSTPNet 創新地偵測和
解釋憂鬱症狀及其持續時間。廣泛的
使用大規模資料集的實證分析顯示 MSTPNet 的效能優於
最先進的憂鬱症檢測方法，F1 分數為 0.851。這
結果也揭示了調查方法中未註意到的新症狀，例如
分享對不同生活的讚賞。我們進一步進行使用者研究
證明其在可解釋性方面優於基準。這項研究
透過新穎的可解釋深度學習模型為 IS 文獻做出了貢獻
社群媒體中的憂鬱症檢測。在實踐中，我們提出的方法可以是
應用於社群媒體平台，提供個人化線上資源
對於檢測到的憂鬱症患者。

##### **Echoes of Biases: How Stigmatizing Language Affects AI Performance**
2305.10201v4 by Yizhi Liu et.al.

Electronic health records (EHRs) serve as an essential data source for the
envisioned artificial intelligence (AI)-driven transformation in healthcare.
However, clinician biases reflected in EHR notes can lead to AI models
inheriting and amplifying these biases, perpetuating health disparities. This
study investigates the impact of stigmatizing language (SL) in EHR notes on
mortality prediction using a Transformer-based deep learning model and
explainable AI (XAI) techniques. Our findings demonstrate that SL written by
clinicians adversely affects AI performance, particularly so for black
patients, highlighting SL as a source of racial disparity in AI model
development. To explore an operationally efficient way to mitigate SL's impact,
we investigate patterns in the generation of SL through a clinicians'
collaborative network, identifying central clinicians as having a stronger
impact on racial disparity in the AI model. We find that removing SL written by
central clinicians is a more efficient bias reduction strategy than eliminating
all SL in the entire corpus of data. This study provides actionable insights
for responsible AI development and contributes to understanding clinician
behavior and EHR note writing in healthcare.

摘要：電子健康記錄 (EHR) 是重要的資料來源
設想人工智慧 (AI) 驅動的醫療保健轉型。
然而，EHR 筆記中反映的臨床醫生偏見可能會導致人工智慧模型的出現
繼承並放大這些偏見，使健康差距長期存在。這
研究調查了 EHR 筆記中的污名化語言（SL）對
使用基於 Transformer 的深度學習模型進行死亡率預測
可解釋的人工智慧（XAI）技術。我們的研究結果顯示 SL 是由
臨床醫生對人工智慧表現產生不利影響，尤其是對於黑人
患者，強調 SL 是人工智慧模型中種族差異的根源
發展。為了探索一種有效的運作方式來減輕 SL 的影響，
我們透過臨床醫師的研究來研究 SL 產生的模式
協作網絡，確定中心臨床醫師擁有更強大的能力
對人工智慧模型中種族差異的影響。我們發現刪除 SL 寫的
中心臨床醫師是比消除偏差更有效的減少偏差策略
整個資料集中的所有 SL。這項研究提供了可行的見解
致力於負責任的人工智慧開發並有助於了解臨床醫生
醫療保健中的行為和 EHR 筆記寫作。

##### **Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**
2305.03376v1 by Goda Klumbyte et.al.

Contemporary automation through AI entails a substantial amount of
behind-the-scenes human labour, which is often both invisibilised and
underpaid. Since invisible labour, including labelling and maintenance work, is
an integral part of contemporary AI systems, it remains important to sensitise
users to its role. We suggest that this could be done through explainable AI
(XAI) design, particularly feminist intersectional XAI. We propose the method
of cartography, which stems from feminist intersectional research, to draw out
a systemic perspective of AI and include dimensions of AI that pertain to
invisible labour.

摘要：透過人工智慧實現的當代自動化需要大量
幕後的人類勞動，往往是看不見的和
工資過低。由於無形的勞動力，包括標籤和維護工作，
作為當代人工智慧系統的一個組成部分，認識到這一點仍然很重要
用戶發揮其作用。我們建議這可以透過可解釋的人工智慧來完成
（XAI）設計，特別是女性主義交叉 XAI。我們提出的方法
源自於女性主義交叉研究的製圖學
人工智慧的系統視角，包括人工智慧的相關維度
無形的勞動。

##### **Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**
2304.13191v1 by Surjodeep Sarkar et.al.

Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to
support the overburdened global healthcare system that gets 60 million primary
care visits, and 6 million Emergency Room (ER) visits annually. These systems
are built by clinical psychologists, psychiatrists, and Artificial Intelligence
(AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role
of VMHAs is to provide emotional support through information, focusing less on
developing a reflective conversation with the patient. A more comprehensive,
safe and explainable approach is required to build responsible VMHAs to ask
follow-up questions or provide a well-informed response. This survey offers a
systematic critical review of the existing conversational agents in mental
health, followed by new insights into the improvements of VMHAs with contextual
knowledge, datasets, and their emerging role in clinical decision support. We
also provide new directions toward enriching the user experience of VMHAs with
explainability, safety, and wholesome trustworthiness. Finally, we provide
evaluation metrics and practical considerations for VMHAs beyond the current
literature to build trust between VMHAs and patients in active communications.

摘要：虛擬心理健康助理 (VMHA) 不斷取得進步
支持負擔過重的全球醫療保健系統，該系統為 6,000 萬初級人口提供服務
護理就診，每年急診室 (ER) 就診次數達 600 萬次。這些系統
由臨床心理學家、精神科醫生和人工智慧建立
認知行為療法（CBT）的（AI）研究人員。目前，角色
VMHA 的目的是透過資訊提供情感支持，而不是關注
與患者進行反思性對話。更全面、
需要安全且可解釋的方法來建立負責任的 VMHA 來詢問
跟進問題或提供明智的答案。這項調查提供了
對心理領域現有對話代理的系統批判性審查
健康，然後是對 VMHA 與上下文的改進的新見解
知識、資料集及其在臨床決策支援中的新興角色。我們
也提供了豐富 VMHA 使用者體驗的新方向
可解釋性、安全性和健康的可信度。最後，我們提供
VMHA 超出目前範圍的評估指標和實際考慮因素
文獻以在 VMHA 和患者之間建立積極溝通的信任。

##### **A Brief Review of Explainable Artificial Intelligence in Healthcare**
2304.01543v1 by Zahra Sadeghi et.al.

XAI refers to the techniques and methods for building AI applications which
assist end users to interpret output and predictions of AI models. Black box AI
applications in high-stakes decision-making situations, such as medical domain
have increased the demand for transparency and explainability since wrong
predictions may have severe consequences. Model explainability and
interpretability are vital successful deployment of AI models in healthcare
practices. AI applications' underlying reasoning needs to be transparent to
clinicians in order to gain their trust. This paper presents a systematic
review of XAI aspects and challenges in the healthcare domain. The primary
goals of this study are to review various XAI methods, their challenges, and
related machine learning models in healthcare. The methods are discussed under
six categories: Features-oriented methods, global methods, concept models,
surrogate models, local pixel-based methods, and human-centric methods. Most
importantly, the paper explores XAI role in healthcare problems to clarify its
necessity in safety-critical applications. The paper intends to establish a
comprehensive understanding of XAI-related applications in the healthcare field
by reviewing the related experimental results. To facilitate future research
for filling research gaps, the importance of XAI models from different
viewpoints and their limitations are investigated.

摘要：XAI是指建立人工智慧應用程式的技術和方法，
幫助最終用戶解釋人工智慧模型的輸出和預測。黑盒人工智慧
高風險決策情境下的應用，例如醫療領域
自從錯誤以來，對透明度和可解釋性的需求增加了
預測可能會產生嚴重的後果。模型可解釋性和
可解釋性對於人工智慧模型在醫療保健領域的成功部署至關重要
做法。人工智慧應用程式的底層推理需要對以下人員透明
以獲得臨床醫師的信任。本文提出了系統性的
回顧醫療保健領域的 XAI 面向和挑戰。首要的
本研究的目標是回顧各種 XAI 方法、它們的挑戰以及
醫療保健領域的相關機器學習模型。這些方法在下面討論
六類：面向特徵的方法、全域方法、概念模型、
代理模型、基於局部像素的方法和以人為中心的方法。最多
重要的是，本文探討了 XAI 在醫療保健問題中的作用，以闡明其
安全關鍵型應用中的必要性。該文件旨在建立一個
全面了解XAI在醫療保健領域的相關應用
透過回顧相關的實驗結果。為了方便未來的研究
為了填補研究空白，來自不同領域的 XAI 模型的重要性
的觀點及其局限性進行了調查。

##### **Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**
2303.12641v2 by Frederik Pahde et.al.

State-of-the-art machine learning models often learn spurious correlations
embedded in the training data. This poses risks when deploying these models for
high-stake decision-making, such as in medical applications like skin cancer
detection. To tackle this problem, we propose Reveal to Revise (R2R), a
framework entailing the entire eXplainable Artificial Intelligence (XAI) life
cycle, enabling practitioners to iteratively identify, mitigate, and
(re-)evaluate spurious model behavior with a minimal amount of human
interaction. In the first step (1), R2R reveals model weaknesses by finding
outliers in attributions or through inspection of latent concepts learned by
the model. Secondly (2), the responsible artifacts are detected and spatially
localized in the input data, which is then leveraged to (3) revise the model
behavior. Concretely, we apply the methods of RRR, CDEP and ClArC for model
correction, and (4) (re-)evaluate the model's performance and remaining
sensitivity towards the artifact. Using two medical benchmark datasets for
Melanoma detection and bone age estimation, we apply our R2R framework to VGG,
ResNet and EfficientNet architectures and thereby reveal and correct real
dataset-intrinsic artifacts, as well as synthetic variants in a controlled
setting. Completing the XAI life cycle, we demonstrate multiple R2R iterations
to mitigate different biases. Code is available on
https://github.com/maxdreyer/Reveal2Revise.

摘要：最先進的機器學習模型經常學習虛假相關性
嵌入到訓練資料中。這在部署這些模型時會帶來風險
高風險決策，例如皮膚癌等醫療應用
檢測。為了解決這個問題，我們提出了 Reveal to Revise (R2R)，
涵蓋整個可解釋人工智慧 (XAI) 生命的框架
循環，使從業者能夠迭代地識別、緩解和
用最少的人力（重新）評估假模型行為
相互作用。在第一步 (1) 中，R2R 透過尋找來揭示模型的弱點
歸因中的異常值或透過檢查所學到的潛在概念
該模型。其次（2），檢測到相關偽影並在空間上
本地化在輸入資料中，然後用於 (3) 修改模型
行為。具體來說，我們將RRR、CDEP和ClArC方法應用於模型
修正，以及（4）（重新）評估模型的性能和剩餘的
對工件的敏感性。使用兩個醫學基準資料集
黑色素瘤檢測和骨齡估計，我們將我們的R2R框架應用於VGG，
ResNet 和 EfficientNet 架構，從而揭示並修正真實的
資料集固有的工件，以及受控的合成變體
環境。完成XAI生命週期，我們示範了多次R2R迭代
以減輕不同的偏見。代碼可在
https://github.com/maxdreyer/Reveal2Revise。

##### **Explainable AI for Time Series via Virtual Inspection Layers**
2303.06365v1 by Johanna Vielhaben et.al.

The field of eXplainable Artificial Intelligence (XAI) has greatly advanced
in recent years, but progress has mainly been made in computer vision and
natural language processing. For time series, where the input is often not
interpretable, only limited research on XAI is available. In this work, we put
forward a virtual inspection layer, that transforms the time series to an
interpretable representation and allows to propagate relevance attributions to
this representation via local XAI methods like layer-wise relevance propagation
(LRP). In this way, we extend the applicability of a family of XAI methods to
domains (e.g. speech) where the input is only interpretable after a
transformation. Here, we focus on the Fourier transformation which is
prominently applied in the interpretation of time series and LRP and refer to
our method as DFT-LRP. We demonstrate the usefulness of DFT-LRP in various time
series classification settings like audio and electronic health records. We
showcase how DFT-LRP reveals differences in the classification strategies of
models trained in different domains (e.g., time vs. frequency domain) or helps
to discover how models act on spurious correlations in the data.

摘要：可解釋人工智慧（XAI）領域取得了巨大進步
近年來，但主要在電腦視覺和
自然語言處理。對於時間序列，輸入通常不是
可以解釋，但關於 XAI 的研究有限。在這項工作中，我們把
轉發虛擬檢查層，將時間序列轉換為
可解釋的表示並允許將相關屬性傳播到
這種表示法是透過本地 XAI 方法（如逐層相關性傳播）實現的
（LRP）。透過這種方式，我們將一系列 XAI 方法的適用性擴展到
領域（例如語音），其中輸入只能在經過一段時間後才能解釋
轉型。在這裡，我們將重點放在傅立葉變換，即
主要應用於時間序列和 LRP 的解釋，請參閱
我們的方法是 DFT-LRP。我們展示了 DFT-LRP 在不同時間的有用性
音訊和電子健康記錄等系列分類設定。我們
展示 DFT-LRP 如何揭示分類策略的差異
在不同領域（例如，時域與頻域）訓練的模型或有幫助
發現模型如何作用於資料中的虛假相關性。

##### **Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**
2303.04731v1 by Truong Thanh Hung Nguyen et.al.

The ability to explain the prediction of deep learning models to end-users is
an important feature to leverage the power of artificial intelligence (AI) for
the medical decision-making process, which is usually considered
non-transparent and challenging to comprehend. In this paper, we apply
state-of-the-art eXplainable artificial intelligence (XAI) methods to explain
the prediction of the black-box AI models in the thyroid nodule diagnosis
application. We propose new statistic-based XAI methods, namely Kernel Density
Estimation and Density map, to explain the case of no nodule detected. XAI
methods' performances are considered under a qualitative and quantitative
comparison as feedback to improve the data quality and the model performance.
Finally, we survey to assess doctors' and patients' trust in XAI explanations
of the model's decisions on thyroid nodule images.

摘要：向最終使用者解釋深度學習模型的預測的能力是
利用人工智慧（AI）力量的一個重要特徵
醫療決策過程，通常被認為是
不透明且難以理解。在本文中，我們應用
最先進的可解釋人工智慧（XAI）方法來解釋
黑盒AI模型在甲狀腺結節診斷上的預測
應用。我們提出了新的基於統計的 XAI 方法，即 Kernel Density
估計和密度圖，解釋未偵測到結節的情況。西艾
方法的性能是在定性和定量的情況下考慮的
比較作為回饋，以提高數據品質和模型性能。
最後，我們進行調查以評估醫生和患者對 XAI 解釋的信任度
模型對甲狀腺結節影像的決策。

##### **Cybersecurity of AI medical devices: risks, legislation, and challenges**
2303.03140v1 by Elisabetta Biasin et.al.

Medical devices and artificial intelligence systems rapidly transform
healthcare provisions. At the same time, due to their nature, AI in or as
medical devices might get exposed to cyberattacks, leading to patient safety
and security risks. This book chapter is divided into three parts. The first
part starts by setting the scene where we explain the role of cybersecurity in
healthcare. Then, we briefly define what we refer to when we talk about AI that
is considered a medical device by itself or supports one. To illustrate the
risks such medical devices pose, we provide three examples: the poisoning of
datasets, social engineering, and data or source code extraction. In the second
part, the paper provides an overview of the European Union's regulatory
framework relevant for ensuring the cybersecurity of AI as or in medical
devices (MDR, NIS Directive, Cybersecurity Act, GDPR, the AI Act proposal and
the NIS 2 Directive proposal). Finally, the third part of the paper examines
possible challenges stemming from the EU regulatory framework. In particular,
we look toward the challenges deriving from the two legislative proposals and
their interaction with the existing legislation concerning AI medical devices'
cybersecurity. They are structured as answers to the following questions: (1)
how will the AI Act interact with the MDR regarding the cybersecurity and
safety requirements?; (2) how should we interpret incident notification
requirements from the NIS 2 Directive proposal and MDR?; and (3) what are the
consequences of the evolving term of critical infrastructures?
  [This is a draft chapter. The final version will be available in Research
Handbook on Health, AI and the Law edited by Barry Solaiman & I. Glenn Cohen,
forthcoming 2023, Edward Elgar Publishing Ltd]

摘要：醫療設備和人工智慧系統快速轉型
醫療保健規定。同時，由於其本質，人工智慧在或作為
醫療設備可能會受到網路攻擊，進而影響病人安全
和安全風險。本書章節分為三個部分。首先
第一部分首先設定場景，我們在其中解釋網路安全的作用
衛生保健。然後，我們簡要地定義一下當我們談論人工智慧時我們所指的是什麼
本身被視為一種醫療設備或支援醫療設備。為了說明
此類醫療器材所帶來的風險，我們提供三個例子：
資料集、社會工程以及資料或原始碼提取。在第二
部分，本文概述了歐盟的監管
與確保醫療領域人工智慧網路安全相關的框架
設備（MDR、NIS 指令、網路安全法案、GDPR、人工智慧法案提案和
NIS 2 指示提案）。最後，本文的第三部分探討了
歐盟監管框架可能帶來的挑戰。尤其，
我們期待這兩項立法提案所帶來的挑戰，
他們與現有有關人工智慧醫療設備的立法的互動
網路安全。它們的結構是以下問題的答案：(1)
《人工智慧法案》將如何與 MDR 在網路安全和
安全要求？ (2) 如何解讀事件通知
NIS 2 指示提案和 MDR 的要求？ (3) 哪些是
關鍵基礎設施不斷演變的後果是什麼？
  [這是章節草稿。最終版本將在研究中提供
《健康、人工智慧和法律手冊》由 Barry Solaiman 和 I. Glenn Cohen 編輯，
即將出版 2023 年，愛德華·埃爾加出版有限公司]

##### **LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**
2302.03008v2 by Nooshin Yousefzadeh et.al.

Alzheimer's Disease (AD) is a progressive neurodegenerative disease and the
leading cause of dementia. Early diagnosis is critical for patients to benefit
from potential intervention and treatment. The retina has been hypothesized as
a diagnostic site for AD detection owing to its anatomical connection with the
brain. Developed AI models for this purpose have yet to provide a rational
explanation about the decision and neither infer the stage of disease's
progression. Along this direction, we propose a novel model-agnostic
explainable-AI framework, called Granular Neuron-level Explainer (LAVA), an
interpretation prototype that probes into intermediate layers of the
Convolutional Neural Network (CNN) models to assess the AD continuum directly
from the retinal imaging without longitudinal or clinical evaluation. This
method is applied to validate the retinal vasculature as a biomarker and
diagnostic modality for Alzheimer's Disease (AD) evaluation. UK Biobank
cognitive tests and vascular morphological features suggest LAVA shows strong
promise and effectiveness in identifying AD stages across the progression
continuum.

摘要：阿茲海默症（AD）是一種進行性神經退化性疾病，
癡呆症的主要原因。早期診斷對於患者受益至關重要
來自潛在的干預和治療。視網膜被假設為
由於其與人體的解剖學聯繫，因此成為 AD 檢測的診斷部位
腦。為此目的所開發的人工智慧模型尚未提供合理的解釋
對決定的解釋，也不推斷疾病的階段
進展。沿著這個方向，我們提出了一個新穎的模型不可知論
可解釋的人工智慧框架，稱為顆粒神經元級解釋器（LAVA），是一個
探索中間層的解釋原型
直接評估 AD 連續體的捲積神經網路 (CNN) 模型
來自視網膜成像，無需縱向或臨床評估。這
應用方法來驗證視網膜脈管系統作為生物標記和
阿茲海默症（AD）評估的診斷方式。英國生物銀行
認知測試和血管形態特徵表明 LAVA 表現出強烈的
在識別整個進展過程中的 AD 階段方面的承諾和有效性
連續體。

##### **Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses**
2302.01241v2 by Brian Y. Lim et.al.

Many visualizations have been developed for explainable AI (XAI), but they
often require further reasoning by users to interpret. We argue that XAI should
support diagrammatic and abductive reasoning for the AI to perform hypothesis
generation and evaluation to reduce the interpretability gap. We propose
Diagrammatization to i) perform Peircean abductive-deductive reasoning, ii)
follow domain conventions, and iii) explain with diagrams visually or verbally.
We implemented DiagramNet for a clinical application to predict cardiac
diagnoses from heart auscultation, and explain with shape-based murmur
diagrams. In modeling studies, we found that DiagramNet not only provides
faithful murmur shape explanations, but also has better prediction performance
than baseline models. We further demonstrate the interpretability and
trustworthiness of diagrammatic explanations in a qualitative user study with
medical students, showing that clinically-relevant, diagrammatic explanations
are preferred over technical saliency map explanations. This work contributes
insights into providing domain-conventional abductive explanations for
user-centric XAI.

摘要：許多視覺化是為了可解釋的人工智慧（XAI）而開發的，但它們
往往需要使用者進一步推理來解釋。我們認為 XAI 應該
支持人工智慧執行假設的圖解推理和歸納推理
產生和評估以減少可解釋性差距。我們建議
圖化 i) 執行皮爾斯演繹-演繹推理，ii)
遵循領域慣例，並且 iii) 以圖表以視覺或口頭方式進行解釋。
我們將DiagramNet 應用於臨床應用來預測心臟病
透過心臟聽診診斷，並以形狀雜音解釋
圖表。在建模研究中，我們發現DiagramNet不僅提供
忠實的雜音形狀解釋，同時也具有更好的預測性能
比基線模型。我們進一步證明了可解釋性和
定性使用者研究中圖表解釋的可信度
醫學生，展示臨床相關的圖解解釋
優先於技術顯著圖解釋。這項工作貢獻
提供領域傳統的溯因解釋的見解
以使用者為中心的 XAI。

##### **LesionAid: Vision Transformers-based Skin Lesion Generation and Classification**
2302.01104v1 by Ghanta Sai Krishna et.al.

Skin cancer is one of the most prevalent forms of human cancer. It is
recognized mainly visually, beginning with clinical screening and continuing
with the dermoscopic examination, histological assessment, and specimen
collection. Deep convolutional neural networks (CNNs) perform highly segregated
and potentially universal tasks against a classified finegrained object. This
research proposes a novel multi-class prediction framework that classifies skin
lesions based on ViT and ViTGAN. Vision transformers-based GANs (Generative
Adversarial Networks) are utilized to tackle the class imbalance. The framework
consists of four main phases: ViTGANs, Image processing, and explainable AI.
Phase 1 consists of generating synthetic images to balance all the classes in
the dataset. Phase 2 consists of applying different data augmentation
techniques and morphological operations to increase the size of the data.
Phases 3 & 4 involve developing a ViT model for edge computing systems that can
identify patterns and categorize skin lesions from the user's skin visible in
the image. In phase 3, after classifying the lesions into the desired class
with ViT, we will use explainable AI (XAI) that leads to more explainable
results (using activation maps, etc.) while ensuring high predictive accuracy.
Real-time images of skin diseases can capture by a doctor or a patient using
the camera of a mobile application to perform an early examination and
determine the cause of the skin lesion. The whole framework is compared with
the existing frameworks for skin lesion detection.

摘要：皮膚癌是人類癌症最常見的形式之一。這是
主要透過視覺識別，從臨床篩檢開始並繼續
透過皮膚鏡檢查、組織學評估和標本
收藏。深度卷積神經網路 (CNN) 執行高度隔離
以及針對分類細粒度物件的潛在通用任務。這
研究提出了一種新穎的多類預測框架，可對皮膚進行分類
基於 ViT 和 ViTGAN 的病變。基於視覺變壓器的 GAN（生成式
對抗網路）用於解決類別不平衡問題。框架
包括四個主要階段：ViTGAN、影像處理和可解釋的人工智慧。
階段 1 包括產生合成影像以平衡中的所有類別
數據集。階段 2 包括應用不同的資料增強
技術和形態學操作來增加資料的大小。
第 3 和第 4 階段涉及為邊緣運算系統開發 ViT 模型，該模型可以
識別模式並對使用者皮膚中可見的皮膚病變進行分類
圖片。在第 3 階段，將病變分類為所需類別後
借助 ViT，我們將使用可解釋的人工智慧 (XAI)，從而產生更可解釋的結果
結果（使用活化圖等），同時確保高預測準確性。
醫生或患者可以使用以下方式捕捉皮膚疾病的即時影像
行動應用程式的相機進行早期檢查和
確定皮膚病變的原因。整個框架對比
現有的皮膚病變檢測框架。

##### **SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis**
2302.00785v1 by Roxana Daneshjou et.al.

For the deployment of artificial intelligence (AI) in high-risk settings,
such as healthcare, methods that provide interpretability/explainability or
allow fine-grained error analysis are critical. Many recent methods for
interpretability/explainability and fine-grained error analysis use concepts,
which are meta-labels that are semantically meaningful to humans. However,
there are only a few datasets that include concept-level meta-labels and most
of these meta-labels are relevant for natural images that do not require domain
expertise. Densely annotated datasets in medicine focused on meta-labels that
are relevant to a single disease such as melanoma. In dermatology, skin disease
is described using an established clinical lexicon that allows clinicians to
describe physical exam findings to one another. To provide a medical dataset
densely annotated by domain experts with annotations useful across multiple
disease processes, we developed SkinCon: a skin disease dataset densely
annotated by dermatologists. SkinCon includes 3230 images from the Fitzpatrick
17k dataset densely annotated with 48 clinical concepts, 22 of which have at
least 50 images representing the concept. The concepts used were chosen by two
dermatologists considering the clinical descriptor terms used to describe skin
lesions. Examples include "plaque", "scale", and "erosion". The same concepts
were also used to label 656 skin disease images from the Diverse Dermatology
Images dataset, providing an additional external dataset with diverse skin tone
representations. We review the potential applications for the SkinCon dataset,
such as probing models, concept-based explanations, and concept bottlenecks.
Furthermore, we use SkinCon to demonstrate two of these use cases: debugging
mistakes of an existing dermatology AI model with concepts and developing
interpretable models with post-hoc concept bottleneck models.

摘要：為了在高風險環境中部署人工智慧（AI），
例如醫療保健、提供可解釋性/可解釋性的方法或
允許細粒度的錯誤分析至關重要。最近的許多方法
可解釋性/可解釋性和細粒度錯誤分析使用概念，
它們是對人類具有語義意義的元標籤。然而，
只有少數資料集包含概念級元標籤，大多數資料集包含概念級元標籤
這些元標籤與不需要域的自然圖像相關
專業知識。醫學中密集註釋的資料集著重於元標籤
與單一疾病（例如黑色素瘤）相關。在皮膚科、皮膚病
使用已建立的臨床詞典進行描述，使臨床醫生能夠
互相描述體檢結果。提供醫療數據集
由領域專家進行密集註釋，註釋對多個領域有用
疾病過程，我們開發了 SkinCon：密集的皮膚病資料集
皮膚科醫生註釋。 SkinCon 包括來自 Fitzpatrick 的 3230 張圖像
17k 資料集密集註釋了 48 個臨床概念，其中 22 個具有
至少 50 張代表該概念的圖像。使用的概念是由兩個人選擇的
皮膚科醫生考慮用於描述皮膚的臨床描述符術語
病變。例如「斑塊」、「水垢」和「侵蝕」。相同的概念
也用於標記來自 Diverse Dermatology 的 656 張皮膚病圖像
影像資料集，提供具有不同膚色的附加外部資料集
交涉。我們回顧了 SkinCon 資料集的潛在應用，
例如探索模型、基於概念的解釋和概念瓶頸。
此外，我們使用 SkinCon 來演示其中兩個用例：調試
現有皮膚科人工智慧模型在概念和開發上的錯誤
具有事後概念瓶頸模型的可解釋模型。

##### **Decision-Focused Evaluation: Analyzing Performance of Deployed Restless Multi-Arm Bandits**
2301.07835v1 by Paritosh Verma et.al.

Restless multi-arm bandits (RMABs) is a popular decision-theoretic framework
that has been used to model real-world sequential decision making problems in
public health, wildlife conservation, communication systems, and beyond.
Deployed RMAB systems typically operate in two stages: the first predicts the
unknown parameters defining the RMAB instance, and the second employs an
optimization algorithm to solve the constructed RMAB instance.
  In this work we provide and analyze the results from a first-of-its-kind
deployment of an RMAB system in public health domain, aimed at improving
maternal and child health. Our analysis is focused towards understanding the
relationship between prediction accuracy and overall performance of deployed
RMAB systems. This is crucial for determining the value of investing in
improving predictive accuracy towards improving the final system performance,
and is useful for diagnosing, monitoring deployed RMAB systems.
  Using real-world data from our deployed RMAB system, we demonstrate that an
improvement in overall prediction accuracy may even be accompanied by a
degradation in the performance of RMAB system -- a broad investment of
resources to improve overall prediction accuracy may not yield expected
results. Following this, we develop decision-focused evaluation metrics to
evaluate the predictive component and show that it is better at explaining
(both empirically and theoretically) the overall performance of a deployed RMAB
system.

摘要：不安的多臂老虎機 (RMAB) 是一種流行的決策理論框架
已用於模擬現實世界的順序決策問題
公共衛生、野生動物保護、通訊系統等。
部署的 RMAB 系統通常分兩個階段運作：第一個階段預測
定義 RMAB 實例的未知參數，第二個採用
最佳化演算法來求解建構的 RMAB 實例。
  在這項工作中，我們提供並分析了史無前例的結果
在公共衛生領域部署 RMAB 系統，旨在改善
孕產婦和兒童健康。我們的分析重點是了解
預測精度與部署整體效能之間的關係
RMAB 系統。這對於確定投資價值至關重要
提高預測準確度以提高最終系統效能，
對於診斷、監控已部署的 RMAB 系統很有用。
  使用我們部署的 RMAB 系統中的真實數據，我們證明了
整體預測精度的提高甚至可能伴隨著
RMAB 系統效能下降—廣泛的投資
提高整體預測準確度的資源可能不會產生預期的效果
結果。在此之後，我們發展以決策為中心的評估指標
評估預測成分並表明它能夠更好地解釋
（經驗與理論上）部署的 RMAB 的整體效能
系統。

##### **Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling**
2302.03033v1 by Carlo Metta et.al.

Explainable AI consists in developing mechanisms allowing for an interaction
between decision systems and humans by making the decisions of the formers
understandable. This is particularly important in sensitive contexts like in
the medical domain. We propose a use case study, for skin lesion diagnosis,
illustrating how it is possible to provide the practitioner with explanations
on the decisions of a state of the art deep neural network classifier trained
to characterize skin lesions from examples. Our framework consists of a trained
classifier onto which an explanation module operates. The latter is able to
offer the practitioner exemplars and counterexemplars for the classification
diagnosis thus allowing the physician to interact with the automatic diagnosis
system. The exemplars are generated via an adversarial autoencoder. We
illustrate the behavior of the system on representative examples.

摘要：可解釋的人工智慧在於開發允許互動的機制
透過做出前者的決策，在決策系統和人類之間建立聯繫
可以理解。這在敏感環境中尤其重要，例如
醫療領域。我們提出了一個用於皮膚病變診斷的用例研究，
說明如何向從業人員提供解釋
基於經過訓練的最先進的深度神經網路分類器的決策
從範例中描述皮膚病變的特徵。我們的框架由訓練有素的
解釋模組在其上運行的分類器。後者能夠
為實踐者提供分類的範例和反範例
診斷，從而允許醫生與自動診斷進行交互
系統。樣本是透過對抗性自動編碼器產生的。我們
透過代表性範例說明系統的行為。

##### **Monotonicity for AI ethics and society: An empirical study of the monotonic neural additive model in criminology, education, health care, and finance**
2301.07060v1 by Dangxing Chen et.al.

Algorithm fairness in the application of artificial intelligence (AI) is
essential for a better society. As the foundational axiom of social mechanisms,
fairness consists of multiple facets. Although the machine learning (ML)
community has focused on intersectionality as a matter of statistical parity,
especially in discrimination issues, an emerging body of literature addresses
another facet -- monotonicity. Based on domain expertise, monotonicity plays a
vital role in numerous fairness-related areas, where violations could misguide
human decisions and lead to disastrous consequences. In this paper, we first
systematically evaluate the significance of applying monotonic neural additive
models (MNAMs), which use a fairness-aware ML algorithm to enforce both
individual and pairwise monotonicity principles, for the fairness of AI ethics
and society. We have found, through a hybrid method of theoretical reasoning,
simulation, and extensive empirical analysis, that considering monotonicity
axioms is essential in all areas of fairness, including criminology, education,
health care, and finance. Our research contributes to the interdisciplinary
research at the interface of AI ethics, explainable AI (XAI), and
human-computer interactions (HCIs). By evidencing the catastrophic consequences
if monotonicity is not met, we address the significance of monotonicity
requirements in AI applications. Furthermore, we demonstrate that MNAMs are an
effective fairness-aware ML approach by imposing monotonicity restrictions
integrating human intelligence.

摘要：人工智慧（AI）應用中的演算法公平性
對於一個更美好的社會至關重要。作為社會機制的基本公理，
公平包括多個面向。雖然機器學習（ML）
社區將交叉性視為統計平等的問題，
特別是在歧視問題上，新興的文獻探討了
另一個面向——單調性。基於領域專業知識，單調性發揮著
在許多與公平相關的領域中發揮著至關重要的作用，在這些領域中，違規行為可能會產生誤導
人類的決定並導致災難性的後果。在本文中，我們首先
系統性評估應用單調神經加法的意義
模型 (MNAM)，它使用公平感知的 ML 演算法來強制執行
個體與成對單調性原則，為了人工智慧倫理的公平性
和社會。我們發現，透過理論推理的混合方法，
模擬和廣泛的實證分析，考慮單調性
公理在所有公平領域都至關重要，包括犯罪學、教育、
醫療保健和金融。我們的研究有助於跨學科
人工智慧倫理、可解釋人工智慧（XAI）和
人機互動（HCI）。透過證明災難性後果
如果不滿足單調性，我們討論單調性的重要性
人工智慧應用的需求。此外，我們證明 MNAM 是一種
透過施加單調性限制來實現有效的公平感知機器學習方法
整合人類智慧。

##### **Rationalizing Predictions by Adversarial Information Calibration**
2301.06009v1 by Lei Sha et.al.

Explaining the predictions of AI models is paramount in safety-critical
applications, such as in legal or medical domains. One form of explanation for
a prediction is an extractive rationale, i.e., a subset of features of an
instance that lead the model to give its prediction on that instance. For
example, the subphrase ``he stole the mobile phone'' can be an extractive
rationale for the prediction of ``Theft''. Previous works on generating
extractive rationales usually employ a two-phase model: a selector that selects
the most important features (i.e., the rationale) followed by a predictor that
makes the prediction based exclusively on the selected features. One
disadvantage of these works is that the main signal for learning to select
features comes from the comparison of the answers given by the predictor to the
ground-truth answers. In this work, we propose to squeeze more information from
the predictor via an information calibration method. More precisely, we train
two models jointly: one is a typical neural model that solves the task at hand
in an accurate but black-box manner, and the other is a selector-predictor
model that additionally produces a rationale for its prediction. The first
model is used as a guide for the second model. We use an adversarial technique
to calibrate the information extracted by the two models such that the
difference between them is an indicator of the missed or over-selected
features. In addition, for natural language tasks, we propose a
language-model-based regularizer to encourage the extraction of fluent
rationales. Experimental results on a sentiment analysis task, a hate speech
recognition task as well as on three tasks from the legal domain show the
effectiveness of our approach to rationale extraction.

摘要：解釋人工智慧模型的預測對於安全至關重要
應用，例如法律或醫學領域。一種解釋形式
預測是提取的基本原理，即特徵的子集
引導模型對此實例進行預測的實例。為了
例如，子短語“他偷了手機”可以是提取詞
預測「盜竊」的理由。之前的生成工作
萃取原理通常採用兩階段模型：選擇器
最重要的特徵（即基本原理），其次是預測因子
僅根據所選特徵進行預測。一
這些作品的缺點是學習選擇的主要訊號
特徵來自於預測器給出的答案與預測器給出的答案的比較
真實答案。在這項工作中，我們建議從
透過資訊校準方法的預測器。更準確地說，我們訓練
兩個模型聯合：一個是解決手邊任務的典型神經模型
以準確但黑盒子的方式，另一個是選擇器預測器
模型也為其預測提供了理由。首先
模型用作第二個模型的指南。我們使用對抗性技術
校準兩個模型提取的信息，使得
它們之間的差異是漏選或過度選擇的指標
特徵。此外，對於自然語言任務，我們提出了
基於語言模型的正則化器鼓勵提取流利的
理由。情緒分析任務（仇恨言論）的實驗結果
識別任務以及法律領域的三個任務表明
我們的基本原理提取方法的有效性。

##### **Semantic match: Debugging feature attribution methods in XAI for healthcare**
2301.02080v3 by Giovanni Cinà et.al.

The recent spike in certified Artificial Intelligence (AI) tools for
healthcare has renewed the debate around adoption of this technology. One
thread of such debate concerns Explainable AI (XAI) and its promise to render
AI devices more transparent and trustworthy. A few voices active in the medical
AI space have expressed concerns on the reliability of Explainable AI
techniques and especially feature attribution methods, questioning their use
and inclusion in guidelines and standards. Despite valid concerns, we argue
that existing criticism on the viability of post-hoc local explainability
methods throws away the baby with the bathwater by generalizing a problem that
is specific to image data. We begin by characterizing the problem as a lack of
semantic match between explanations and human understanding. To understand when
feature importance can be used reliably, we introduce a distinction between
feature importance of low- and high-level features. We argue that for data
types where low-level features come endowed with a clear semantics, such as
tabular data like Electronic Health Records (EHRs), semantic match can be
obtained, and thus feature attribution methods can still be employed in a
meaningful and useful way. Finally, we sketch a procedure to test whether
semantic match has been achieved.

摘要：最近經過認證的人工智慧 (AI) 工具激增
醫療保健領域重新引發了圍繞該技術採用的爭論。一
此類辯論的主題涉及可解釋的人工智慧（XAI）及其對渲染的承諾
AI設備更加透明、可信。醫學界活躍的一些聲音
人工智慧領域對可解釋人工智慧的可靠性表示擔憂
技術，尤其是特徵歸因方法，質疑它們的使用
並納入指南和標準。儘管存在合理的擔憂，但我們認為
現有對事後局部可解釋性可行性的批評
方法透過概括一個問題來把嬰兒和洗澡水一起倒掉：
特定於圖像數據。我們首先將問題描述為缺乏
解釋與人類理解之間的語義匹配。要了解什麼時候
特徵重要性可以可靠地使用，我們引入了之間的區別
低級和高級特徵的特徵重要性。我們認為對於數據
低階特徵被賦予清晰語意的類型，例如
電子健康記錄（EHR）等表格數據，語意配對可以是
所獲得的，因此特徵歸因方法仍然可以在
有意義且有用的方式。最後，我們草擬了一個程式來測試是否
已經實現了語義匹配。

##### **Context-dependent Explainability and Contestability for Trustworthy Medical Artificial Intelligence: Misclassification Identification of Morbidity Recognition Models in Preterm Infants**
2212.08821v1 by Isil Guzey et.al.

Although machine learning (ML) models of AI achieve high performances in
medicine, they are not free of errors. Empowering clinicians to identify
incorrect model recommendations is crucial for engendering trust in medical AI.
Explainable AI (XAI) aims to address this requirement by clarifying AI
reasoning to support the end users. Several studies on biomedical imaging
achieved promising results recently. Nevertheless, solutions for models using
tabular data are not sufficient to meet the requirements of clinicians yet.
This paper proposes a methodology to support clinicians in identifying failures
of ML models trained with tabular data. We built our methodology on three main
pillars: decomposing the feature set by leveraging clinical context latent
space, assessing the clinical association of global explanations, and Latent
Space Similarity (LSS) based local explanations. We demonstrated our
methodology on ML-based recognition of preterm infant morbidities caused by
infection. The risk of mortality, lifelong disability, and antibiotic
resistance due to model failures was an open research question in this domain.
We achieved to identify misclassification cases of two models with our
approach. By contextualizing local explanations, our solution provides
clinicians with actionable insights to support their autonomy for informed
final decisions.

摘要：儘管人工智慧的機器學習（ML）模型在以下方面取得了高效能
醫學上，它們並非沒有錯誤。使臨床醫生能夠識別
錯誤的模型推薦對於建立對醫療人工智慧的信任至關重要。
可解釋的人工智慧（XAI）旨在透過闡明人工智慧來滿足這項要求
支持最終用戶的推理。生物醫學影像的若干研究
最近取得了可喜的成果。儘管如此，使用模型的解決方案
表格數據還不足以滿足臨床醫生的要求。
本文提出了一種支持臨床醫生識別失敗的方法
使用表格資料訓練的 ML 模型。我們的方法論基於三個主要方面
支柱：透過利用潛在的臨床背景來分解特徵集
空間，評估全局解釋和潛在的臨床關聯
基於空間相似性（LSS）的局部解釋。我們展示了我們的
基於機器學習的早產兒發病辨識方法
感染。死亡、終身殘疾和抗生素的風險
由於模型失敗而產生的阻力是該領域的開放研究問題。
我們用我們的方法識別了兩個模型的錯誤分類案例
方法。透過結合當地的解釋，我們的解決方案提供了
臨床醫生具有可操作的見解，以支持他們的自主權
最終決定。

##### **It is not "accuracy vs. explainability" -- we need both for trustworthy AI systems**
2212.11136v2 by D. Petkovic et.al.

We are witnessing the emergence of an AI economy and society where AI
technologies are increasingly impacting health care, business, transportation
and many aspects of everyday life. Many successes have been reported where AI
systems even surpassed the accuracy of human experts. However, AI systems may
produce errors, can exhibit bias, may be sensitive to noise in the data, and
often lack technical and judicial transparency resulting in reduction in trust
and challenges in their adoption. These recent shortcomings and concerns have
been documented in scientific but also in general press such as accidents with
self driving cars, biases in healthcare, hiring and face recognition systems
for people of color, seemingly correct medical decisions later found to be made
due to wrong reasons etc. This resulted in emergence of many government and
regulatory initiatives requiring trustworthy and ethical AI to provide accuracy
and robustness, some form of explainability, human control and oversight,
elimination of bias, judicial transparency and safety. The challenges in
delivery of trustworthy AI systems motivated intense research on explainable AI
systems (XAI). Aim of XAI is to provide human understandable information of how
AI systems make their decisions. In this paper we first briefly summarize
current XAI work and then challenge the recent arguments of accuracy vs.
explainability for being mutually exclusive and being focused only on deep
learning. We then present our recommendations for the use of XAI in full
lifecycle of high stakes trustworthy AI systems delivery, e.g. development,
validation and certification, and trustworthy production and maintenance.

摘要：我們正在見證人工智慧經濟和社會的出現，其中人工智慧
科技對醫療保健、商業、交通的影響越來越大
以及日常生活的許多面向。據報道，人工智慧已取得許多成功
系統的準確性甚至超過了人類專家。然而，人工智慧系統可能
產生錯誤，可能表現出偏差，可能對資料中的雜訊敏感，並且
往往缺乏技術和司法透明度，導致信任度下降
以及採用過程中所面臨的挑戰。最近的這些缺點和擔憂
科學界和一般媒體都有記錄，例如事故
自動駕駛汽車、醫療保健、招募和人臉辨識系統的偏見
對於有色人種，後來發現看似正確的醫療決定
由於錯誤的原因等。
監管舉措需要值得信賴且符合道德的人工智慧來提供準確性
和穩健性、某種形式的可解釋性、人類控制和監督，
消除偏見、司法透明度和安全。面臨的挑戰
值得信賴的人工智慧系統的交付推動了對可解釋人工智慧的深入研究
系統（XAI）。 XAI 的目標是提供人類可理解的訊息
人工智慧系統做出決定。在本文中我們先簡單總結一下
目前的 XAI 工作，然後挑戰最近關於準確性與準確性的爭論。
相互排斥和只關注深層的可解釋性
學習。然後，我們全面提出使用 XAI 的建議
高風險、值得信賴的人工智慧系統交付的生命週期，例如發展，
驗證和認證，以及值得信賴的生產和維護。

##### **SimpleMind adds thinking to deep neural networks**
2212.00951v1 by Youngwon Choi et.al.

Deep neural networks (DNNs) detect patterns in data and have shown
versatility and strong performance in many computer vision applications.
However, DNNs alone are susceptible to obvious mistakes that violate simple,
common sense concepts and are limited in their ability to use explicit
knowledge to guide their search and decision making. While overall DNN
performance metrics may be good, these obvious errors, coupled with a lack of
explainability, have prevented widespread adoption for crucial tasks such as
medical image analysis. The purpose of this paper is to introduce SimpleMind,
an open-source software framework for Cognitive AI focused on medical image
understanding. It allows creation of a knowledge base that describes expected
characteristics and relationships between image objects in an intuitive
human-readable form. The SimpleMind framework brings thinking to DNNs by: (1)
providing methods for reasoning with the knowledge base about image content,
such as spatial inferencing and conditional reasoning to check DNN outputs; (2)
applying process knowledge, in the form of general-purpose software agents,
that are chained together to accomplish image preprocessing, DNN prediction,
and result post-processing, and (3) performing automatic co-optimization of all
knowledge base parameters to adapt agents to specific problems. SimpleMind
enables reasoning on multiple detected objects to ensure consistency, providing
cross checking between DNN outputs. This machine reasoning improves the
reliability and trustworthiness of DNNs through an interpretable model and
explainable decisions. Example applications are provided that demonstrate how
SimpleMind supports and improves deep neural networks by embedding them within
a Cognitive AI framework.

摘要：深度神經網路 (DNN) 偵測資料中的模式並顯示
在許多電腦視覺應用中具有多功能性和強大的性能。
然而，光是 DNN 就很容易出現明顯的錯誤，這些錯誤違反了簡單的、
常識概念，並且在使用明確的能力方面受到限制
知識來指導他們的搜尋和決策。雖然總體 DNN
性能指標可能不錯，但這些明顯的錯誤，再加上缺乏
可解釋性，阻礙了關鍵任務的廣泛採用，例如
醫學影像分析。本文的目的是介紹SimpleMind，
專注於醫學影像的認知人工智慧開源軟體框架
理解。它允許創建描述預期的知識庫
直觀地表達圖像物件之間的特徵和關係
人類可讀的形式。 SimpleMind 框架透過以下方式為 DNN 帶來思考：(1)
提供利用圖像內容的知識庫進行推理的方法，
例如空間推理和條件推理來檢查 DNN 輸出； (2)
以通用軟體代理的形式應用流程知識，
它們連結在一起以完成影像預處理、DNN 預測、
和結果後處理，以及（3）執行所有的自動協同優化
知識庫參數使代理程式適應特定問題。頭腦簡單
能夠對多個偵測到的物件進行推理以確保一致性，提供
DNN 輸出之間的交叉檢查。該機器推理改進了
透過可解釋的模型提高 DNN 的可靠性和可信度
可解釋的決定。提供的範例應用程式示範如何
SimpleMind 透過將深度神經網路嵌入其中來支援和改進深度神經網絡
認知人工智慧框架。

##### **Attribution-based XAI Methods in Computer Vision: A Review**
2211.14736v1 by Kumar Abhishek et.al.

The advancements in deep learning-based methods for visual perception tasks
have seen astounding growth in the last decade, with widespread adoption in a
plethora of application areas from autonomous driving to clinical decision
support systems. Despite their impressive performance, these deep
learning-based models remain fairly opaque in their decision-making process,
making their deployment in human-critical tasks a risky endeavor. This in turn
makes understanding the decisions made by these models crucial for their
reliable deployment. Explainable AI (XAI) methods attempt to address this by
offering explanations for such black-box deep learning methods. In this paper,
we provide a comprehensive survey of attribution-based XAI methods in computer
vision and review the existing literature for gradient-based,
perturbation-based, and contrastive methods for XAI, and provide insights on
the key challenges in developing and evaluating robust XAI methods.

摘要：基於深度學習的視覺知覺任務方法的進展
在過去十年中取得了驚人的成長，並在各個領域中廣泛採用
從自動駕駛到臨床決策的眾多應用領域
支持系統。儘管他們的表現令人印象深刻，但這些深度
基於學習的模型在決策過程中仍然相當不透明，
使它們在對人類至關重要的任務中的部署成為一項冒險的嘗試。這反過來
使得理解這些模型所做的決策對於他們的決策至關重要
可靠部署。可解釋的人工智慧（XAI）方法試圖透過以下方式解決這個問題：
為此類黑盒深度學習方法提供解釋。在本文中，
我們提供了計算機中基於歸因的 XAI 方法的全面調查
展望並回顧基於梯度的現有文獻，
基於擾動的 XAI 對比方法，並提供有關以下方面的見解
開發和評估穩健的 XAI 方法的關鍵挑戰。

##### **Privacy Meets Explainability: A Comprehensive Impact Benchmark**
2211.04110v1 by Saifullah Saifullah et.al.

Since the mid-10s, the era of Deep Learning (DL) has continued to this day,
bringing forth new superlatives and innovations each year. Nevertheless, the
speed with which these innovations translate into real applications lags behind
this fast pace. Safety-critical applications, in particular, underlie strict
regulatory and ethical requirements which need to be taken care of and are
still active areas of debate. eXplainable AI (XAI) and privacy-preserving
machine learning (PPML) are both crucial research fields, aiming at mitigating
some of the drawbacks of prevailing data-hungry black-box models in DL. Despite
brisk research activity in the respective fields, no attention has yet been
paid to their interaction. This work is the first to investigate the impact of
private learning techniques on generated explanations for DL-based models. In
an extensive experimental analysis covering various image and time series
datasets from multiple domains, as well as varying privacy techniques, XAI
methods, and model architectures, the effects of private training on generated
explanations are studied. The findings suggest non-negligible changes in
explanations through the introduction of privacy. Apart from reporting
individual effects of PPML on XAI, the paper gives clear recommendations for
the choice of techniques in real applications. By unveiling the
interdependencies of these pivotal technologies, this work is a first step
towards overcoming the remaining hurdles for practically applicable AI in
safety-critical domains.

摘要：從10年代中期開始，深度學習（DL）時代一直延續至今，
每年都會帶來新的最高級和創新。儘管如此，
這些創新轉化為實際應用的速度落後
這麼快的節奏。尤其是安全關鍵型應用，是嚴格的基礎
需要考慮的監管和道德要求
仍然是爭論的活躍領域。 eXplainable AI (XAI) 與隱私保護
機器學習（PPML）都是重要的研究領域，旨在減輕
深度學習中流行的需要大量數據的黑盒模型的一些缺點。儘管
各領域研究活動活躍，尚未引起關注
為他們的互動付出了代價。這項工作是第一個調查影響的工作
針對基於深度學習的模型產生解釋的私人學習技術。在
涵蓋各種圖像和時間序列的廣泛實驗分析
來自多個領域的資料集以及不同的隱私技術，XAI
方法和模型架構，私人培訓對生成的影響
解釋進行了研究。研究結果表明，以下方面發生了不可忽視的變化：
透過引入隱私進行解釋。除了檢舉之外
PPML 對 XAI 的個別影響，本文給了明確的建議
實際應用中技術的選擇。透過揭開
這些關鍵技術的相互依賴性，這項工作是第一步
克服實際應用人工智慧的剩餘障礙
安全關鍵領域。

##### **Predicting Treatment Adherence of Tuberculosis Patients at Scale**
2211.02943v2 by Mihir Kulkarni et.al.

Tuberculosis (TB), an infectious bacterial disease, is a significant cause of
death, especially in low-income countries, with an estimated ten million new
cases reported globally in $2020$. While TB is treatable, non-adherence to the
medication regimen is a significant cause of morbidity and mortality. Thus,
proactively identifying patients at risk of dropping off their medication
regimen enables corrective measures to mitigate adverse outcomes. Using a proxy
measure of extreme non-adherence and a dataset of nearly $700,000$ patients
from four states in India, we formulate and solve the machine learning (ML)
problem of early prediction of non-adherence based on a custom rank-based
metric. We train ML models and evaluate against baselines, achieving a $\sim
100\%$ lift over rule-based baselines and $\sim 214\%$ over a random
classifier, taking into account country-wide large-scale future deployment. We
deal with various issues in the process, including data quality,
high-cardinality categorical data, low target prevalence, distribution shift,
variation across cohorts, algorithmic fairness, and the need for robustness and
explainability. Our findings indicate that risk stratification of non-adherent
patients is a viable, deployable-at-scale ML solution. As the official AI
partner of India's Central TB Division, we are working on multiple city and
state-level pilots with the goal of pan-India deployment.

摘要：結核病 (TB) 是一種傳染性細菌性疾病，是結核病的重要原因
死亡，特別是在低收入國家，估計有 1000 萬人死亡
2020 年全球報告的病例數。雖然結核病是可以治療的，但不遵守
藥物治療是發病和死亡的重要原因。因此，
主動識別有放棄藥物風險的患者
治療方案可以採取糾正措施來減輕不良後果。使用代理
極端不依從性的衡量標準和近 70 萬美元患者的數據集
我們在印度的四個邦制定並解決了機器學習 (ML)
基於自訂排名的早期預測不遵守的問題
公制。我們訓練 ML 模型並根據基線進行評估，實現 $\sim
比基於規則的基線提升 100\%$，比隨機基線提升 $\sim 214\%$
分類器，考慮到未來全國範圍內的大規模部署。我們
處理過程中的各種問題，包括數據質量，
高基數分類資料、低目標盛行率、分佈變化、
群體間的差異、演算法的公平性以及穩健性的需求
可解釋性。我們的研究結果表明，不依從的風險分層
患者是一種可行的、可大規模部署的機器學習解決方案。作為官方AI
作為印度中央結核病部門的合作夥伴，我們正在多個城市和地區開展工作
邦級試點，目標是在全印度部署。

##### **Explainable AI over the Internet of Things (IoT): Overview, State-of-the-Art and Future Directions**
2211.01036v2 by Senthil Kumar Jagatheesaperumal et.al.

Explainable Artificial Intelligence (XAI) is transforming the field of
Artificial Intelligence (AI) by enhancing the trust of end-users in machines.
As the number of connected devices keeps on growing, the Internet of Things
(IoT) market needs to be trustworthy for the end-users. However, existing
literature still lacks a systematic and comprehensive survey work on the use of
XAI for IoT. To bridge this lacking, in this paper, we address the XAI
frameworks with a focus on their characteristics and support for IoT. We
illustrate the widely-used XAI services for IoT applications, such as security
enhancement, Internet of Medical Things (IoMT), Industrial IoT (IIoT), and
Internet of City Things (IoCT). We also suggest the implementation choice of
XAI models over IoT systems in these applications with appropriate examples and
summarize the key inferences for future works. Moreover, we present the
cutting-edge development in edge XAI structures and the support of
sixth-generation (6G) communication services for IoT applications, along with
key inferences. In a nutshell, this paper constitutes the first holistic
compilation on the development of XAI-based frameworks tailored for the demands
of future IoT use cases.

摘要：可解釋的人工智慧（XAI）正在改變這個領域
人工智慧 (AI) 透過增強最終使用者對機器的信任。
隨著連接設備數量的不斷增長，物聯網
（物聯網）市場需要值得最終用戶信賴。然而，現有的
文獻仍缺乏對使用的系統和全面的調查工作
用於物聯網的 XAI。為了彌補這一不足，在本文中，我們解決了 XAI
框架，重點在於其特性和對物聯網的支援。我們
說明物聯網應用廣泛使用的 XAI 服務，例如安全性
增強、醫療物聯網 (IoMT)、工業物聯網 (IIoT) 和
城市物聯網 (IoCT)。我們也建議實施選擇
在這些應用中透過物聯網系統進行 XAI 建模，並提供適當的範例和
總結未來工作的關鍵推論。此外，我們也提出了
邊緣 XAI 結構的尖端開發和支持
用於物聯網應用的第六代 (6G) 通訊服務，以及
關鍵推論。簡而言之，本文構成了第一個整體性的
針對需求量身訂做的基於XAI的框架開發彙編
未來的物聯網用例。

##### **Human-centered XAI for Burn Depth Characterization**
2210.13535v2 by Maxwell J. Jacobson et.al.

Approximately 1.25 million people in the United States are treated each year
for burn injuries. Precise burn injury classification is an important aspect of
the medical AI field. In this work, we propose an explainable human-in-the-loop
framework for improving burn ultrasound classification models. Our framework
leverages an explanation system based on the LIME classification explainer to
corroborate and integrate a burn expert's knowledge -- suggesting new features
and ensuring the validity of the model. Using this framework, we discover that
B-mode ultrasound classifiers can be enhanced by supplying textural features.
More specifically, we confirm that texture features based on the Gray Level
Co-occurance Matrix (GLCM) of ultrasound frames can increase the accuracy of
transfer learned burn depth classifiers. We test our hypothesis on real data
from porcine subjects. We show improvements in the accuracy of burn depth
classification -- from ~88% to ~94% -- once modified according to our
framework.

摘要：美國每年約有 125 萬人接受治療
用於燒傷。準確的燒傷分類是燒傷救治的重要方面
醫療AI領域。在這項工作中，我們提出了一個可解釋的人機循環
改進燒傷超音波分類模型的框架。我們的框架
利用基於 LIME 分類解釋器的解釋系統
證實並整合燒傷專家的知識－提出新功能
並確保模型的有效性。使用這個框架，我們發現
B 型超音波分類器可以透過提供紋理特徵來增強。
更具體地說，我們確認基於灰階的紋理特徵
超音波幀的共現矩陣（GLCM）可以提高超音波幀的準確性
遷移學習的燒傷深度分類器。我們用真實數據檢驗我們的假設
來自豬受試者。我們展示了燒傷深度準確性的改進
分類－從~88%到~94%－一旦根據我們的修改
框架。

##### **What Do End-Users Really Want? Investigation of Human-Centered XAI for Mobile Health Apps**
2210.03506v1 by Katharina Weitz et.al.

In healthcare, AI systems support clinicians and patients in diagnosis,
treatment, and monitoring, but many systems' poor explainability remains
challenging for practical application. Overcoming this barrier is the goal of
explainable AI (XAI). However, an explanation can be perceived differently and,
thus, not solve the black-box problem for everyone. The domain of
Human-Centered AI deals with this problem by adapting AI to users. We present a
user-centered persona concept to evaluate XAI and use it to investigate
end-users preferences for various explanation styles and contents in a mobile
health stress monitoring application. The results of our online survey show
that users' demographics and personality, as well as the type of explanation,
impact explanation preferences, indicating that these are essential features
for XAI design. We subsumed the results in three prototypical user personas:
power-, casual-, and privacy-oriented users. Our insights bring an interactive,
human-centered XAI closer to practical application.

摘要：在醫療保健領域，人工智慧系統支援臨床醫生和患者進行診斷，
治療和監測，但許多系統的可解釋性仍然較差
對實際應用具有挑戰性。克服這項障礙是我們的目標
可解釋的人工智慧（XAI）。然而，解釋可以有不同的理解，
因此，並不能為所有人解決黑盒子問題。域為
以人為中心的人工智慧透過使人工智慧適應用戶來解決這個問題。我們提出一個
以使用者為中心的角色概念來評估 XAI 並用其進行調查
最終用戶對行動裝置中各種解釋風格和內容的偏好
健康壓力監測應用程式。我們的線上調查結果顯示
使用者的人口統計和個性，以及解釋的類型，
影響解釋偏好，顯示這些是基本特徵
用於 XAI 設計。我們將結果歸入三個典型的使用者角色：
以權力、休閒和隱私為導向的使用者。我們的見解帶來了互動，
以人為本的XAI更接近實際應用。

##### **Explainable AI based Glaucoma Detection using Transfer Learning and LIME**
2210.03332v1 by Touhidul Islam Chayan et.al.

Glaucoma is the second driving reason for partial or complete blindness among
all the visual deficiencies which mainly occurs because of excessive pressure
in the eye due to anxiety or depression which damages the optic nerve and
creates complications in vision. Traditional glaucoma screening is a
time-consuming process that necessitates the medical professionals' constant
attention, and even so time to time due to the time constrains and pressure
they fail to classify correctly that leads to wrong treatment. Numerous efforts
have been made to automate the entire glaucoma classification procedure
however, these existing models in general have a black box characteristics that
prevents users from understanding the key reasons behind the prediction and
thus medical practitioners generally can not rely on these system. In this
article after comparing with various pre-trained models, we propose a transfer
learning model that is able to classify Glaucoma with 94.71\% accuracy. In
addition, we have utilized Local Interpretable Model-Agnostic
Explanations(LIME) that introduces explainability in our system. This
improvement enables medical professionals obtain important and comprehensive
information that aid them in making judgments. It also lessen the opacity and
fragility of the traditional deep learning models.

摘要：青光眼是導致部分或完全失明的第二大原因
主要因壓力過大而出現的所有視力缺陷
因焦慮或憂鬱而導致的眼睛損傷視神經
造成視力併發症。傳統的青光眼篩檢是
這是一個耗時的過程，需要醫療專業人員不斷地
注意力，甚至由於時間限制和壓力而時不時地這樣
他們未能正確分類，從而導致錯誤的治療。無數的努力
已實現整個青光眼分類過程的自動化
然而，這些現有模型總體上具有黑盒子特徵，
阻止用戶理解預測背後的關鍵原因
因此，醫生一般不能依賴這些系統。在這個
文章在與各種預訓練模型進行比較後，我們提出了一個遷移
能夠以 94.71% 的準確率對青光眼進行分類的學習模型。在
此外，我們也利用了本地可解釋模型不可知論
Explanations(LIME) 在我們的系統中引入了可解釋性。這
改進使醫療專業人員能夠獲得重要且全面的訊息
幫助他們做出判斷的訊息。它還可以減少不透明度和
傳統深度學習模型的脆弱性。

##### **Evaluation of importance estimators in deep learning classifiers for Computed Tomography**
2209.15398v1 by Lennart Brocki et.al.

Deep learning has shown superb performance in detecting objects and
classifying images, ensuring a great promise for analyzing medical imaging.
Translating the success of deep learning to medical imaging, in which doctors
need to understand the underlying process, requires the capability to interpret
and explain the prediction of neural networks. Interpretability of deep neural
networks often relies on estimating the importance of input features (e.g.,
pixels) with respect to the outcome (e.g., class probability). However, a
number of importance estimators (also known as saliency maps) have been
developed and it is unclear which ones are more relevant for medical imaging
applications. In the present work, we investigated the performance of several
importance estimators in explaining the classification of computed tomography
(CT) images by a convolutional deep network, using three distinct evaluation
metrics. First, the model-centric fidelity measures a decrease in the model
accuracy when certain inputs are perturbed. Second, concordance between
importance scores and the expert-defined segmentation masks is measured on a
pixel level by a receiver operating characteristic (ROC) curves. Third, we
measure a region-wise overlap between a XRAI-based map and the segmentation
mask by Dice Similarity Coefficients (DSC). Overall, two versions of SmoothGrad
topped the fidelity and ROC rankings, whereas both Integrated Gradients and
SmoothGrad excelled in DSC evaluation. Interestingly, there was a critical
discrepancy between model-centric (fidelity) and human-centric (ROC and DSC)
evaluation. Expert expectation and intuition embedded in segmentation maps does
not necessarily align with how the model arrived at its prediction.
Understanding this difference in interpretability would help harnessing the
power of deep learning in medicine.

摘要：深度學習在偵測物體和
將影像分類，確保分析醫學影像的巨大前景。
將深度學習的成功轉化為醫學成像，其中醫生
需要了解底層流程，需要解釋能力
並解釋神經網路的預測。深層神經網路的可解釋性
網路通常依賴於估計輸入特徵的重要性（例如，
像素）相對於結果（例如，類別機率）。然而，一個
重要性估計器（也稱為顯著性圖）的數量
已開發，但尚不清楚哪些與醫學影像更相關
應用程式.在目前的工作中，我們研究了幾個
解釋電腦斷層掃描分類的重要性估計
(CT) 影像透過卷積深度網絡，使用三種不同的評估
指標。首先，以模型為中心的保真度來衡量模型的下降
當某些輸入受到干擾時的準確性。二、兩者之間的一致性
重要性分數和專家定義的分割遮罩是在
像素等級由接收者操作特性 (ROC) 曲線決定。第三，我們
測量基於 XRAI 的地圖和分割之間的區域重疊
透過 Dice 相似係數 (DSC) 進行遮罩。總的來說，SmoothGrad 的兩個版本
在保真度和 ROC 排名中名列前茅，而綜合梯度和
SmoothGrad 在 DSC 評估中表現出色。有趣的是，有一個批評
以模型為中心（保真度）和以人為中心（ROC 和 DSC）之間的差異
評估。分割圖中嵌入的專家期望和直覺確實
不一定與模型得出預測的方式一致。
理解這種可解釋性的差異將有助於利用
深度學習在醫學中的力量。

##### **An Interactive Interpretability System for Breast Cancer Screening with Deep Learning**
2210.08979v1 by Yuzhe Lu et.al.

Deep learning methods, in particular convolutional neural networks, have
emerged as a powerful tool in medical image computing tasks. While these
complex models provide excellent performance, their black-box nature may hinder
real-world adoption in high-stakes decision-making. In this paper, we propose
an interactive system to take advantage of state-of-the-art interpretability
techniques to assist radiologists with breast cancer screening. Our system
integrates a deep learning model into the radiologists' workflow and provides
novel interactions to promote understanding of the model's decision-making
process. Moreover, we demonstrate that our system can take advantage of user
interactions progressively to provide finer-grained explainability reports with
little labeling overhead. Due to the generic nature of the adopted
interpretability technique, our system is domain-agnostic and can be used for
many different medical image computing tasks, presenting a novel perspective on
how we can leverage visual analytics to transform originally static
interpretability techniques to augment human decision making and promote the
adoption of medical AI.

摘要：深度學習方法，特別是卷積神經網絡，具有
成為醫學影像計算任務中的強大工具。雖然這些
複雜的模型提供了優異的性能，它們的黑盒子性質可能會阻礙
現實世界中高風險決策的採用。在本文中，我們建議
一個利用最先進的可解釋性的互動式系統
協助放射科醫師進行乳癌篩檢的技術。我們的系統
將深度學習模型整合到放射科醫生的工作流程中並提供
新穎的交互作用促進對模型決策的理解
過程。此外，我們證明我們的系統可以利用用戶
逐步互動以提供更細微的可解釋性報告
很少的標籤開銷。由於所採用的通用性
可解釋性技術，我們的系統與領域無關，可用於
許多不同的醫學影像計算任務，提出了一個新穎的視角
我們如何利用視覺化分析來改變原本靜態的
可解釋性技術可以增強人類決策並促進
採用醫療人工智慧。

##### **Explainable AI for clinical and remote health applications: a survey on tabular and time series data**
2209.06528v1 by Flavio Di Martino et.al.

Nowadays Artificial Intelligence (AI) has become a fundamental component of
healthcare applications, both clinical and remote, but the best performing AI
systems are often too complex to be self-explaining. Explainable AI (XAI)
techniques are defined to unveil the reasoning behind the system's predictions
and decisions, and they become even more critical when dealing with sensitive
and personal health data. It is worth noting that XAI has not gathered the same
attention across different research areas and data types, especially in
healthcare. In particular, many clinical and remote health applications are
based on tabular and time series data, respectively, and XAI is not commonly
analysed on these data types, while computer vision and Natural Language
Processing (NLP) are the reference applications. To provide an overview of XAI
methods that are most suitable for tabular and time series data in the
healthcare domain, this paper provides a review of the literature in the last 5
years, illustrating the type of generated explanations and the efforts provided
to evaluate their relevance and quality. Specifically, we identify clinical
validation, consistency assessment, objective and standardised quality
evaluation, and human-centered quality assessment as key features to ensure
effective explanations for the end users. Finally, we highlight the main
research challenges in the field as well as the limitations of existing XAI
methods.

摘要：如今，人工智慧（AI）已成為人類社會的重要組成部分。
醫療保健應用程序，包括臨床和遠程，但性能最好的人工智慧
系統往往過於複雜而無法自我解釋。可解釋的人工智慧（XAI）
技術被定義為揭示系統預測背後的推理
和決策，在處理敏感問題時變得更加重要
和個人健康數據。值得注意的是，XAI並沒有聚集同樣的
不同研究領域和資料類型的關注，特別是
衛生保健。特別是，許多臨床和遠端健康應用程式
分別基於表格數據和時間序列數據，XAI 並不常見
對這些資料類型進行分析，同時電腦視覺和自然語言
處理（NLP）是參考應用程式。提供 XAI 的概述
最適合表格和時間序列資料的方法
醫療保健領域，本文對過去 5 年的文獻進行了回顧
年，說明產生的解釋類型和提供的努力
評估它們的相關性和品質。具體來說，我們確定臨床
驗證、一致性評估、客觀標準化質量
評估和以人為本的品質評估作為關鍵特徵，以確保
為最終用戶提供有效的解釋。最後，我們將重點放在主要內容
該領域的研究挑戰以及現有 XAI 的局限性
方法。

##### **Enhancing Early Lung Cancer Detection on Chest Radiographs with AI-assistance: A Multi-Reader Study**
2208.14742v1 by Gaetan Dissez et.al.

Objectives: The present study evaluated the impact of a commercially
available explainable AI algorithm in augmenting the ability of clinicians to
identify lung cancer on chest X-rays (CXR).
  Design: This retrospective study evaluated the performance of 11 clinicians
for detecting lung cancer from chest radiographs, with and without assistance
from a commercially available AI algorithm (red dot, Behold.ai) that predicts
suspected lung cancer from CXRs. Clinician performance was evaluated against
clinically confirmed diagnoses.
  Setting: The study analysed anonymised patient data from an NHS hospital; the
dataset consisted of 400 chest radiographs from adult patients (18 years and
above) who had a CXR performed in 2020, with corresponding clinical text
reports.
  Participants: A panel of readers consisting of 11 clinicians (consultant
radiologists, radiologist trainees and reporting radiographers) participated in
this study.
  Main outcome measures: Overall accuracy, sensitivity, specificity and
precision for detecting lung cancer on CXRs by clinicians, with and without AI
input. Agreement rates between clinicians and performance standard deviation
were also evaluated, with and without AI input.
  Results: The use of the AI algorithm by clinicians led to an improved overall
performance for lung tumour detection, achieving an overall increase of 17.4%
of lung cancers being identified on CXRs which would have otherwise been
missed, an overall increase in detection of smaller tumours, a 24% and 13%
increased detection of stage 1 and stage 2 lung cancers respectively, and
standardisation of clinician performance.
  Conclusions: This study showed great promise in the clinical utility of AI
algorithms in improving early lung cancer diagnosis and promoting health equity
through overall improvement in reader performances, without impacting
downstream imaging resources.

摘要：目標：本研究評估了商業化的影響
可用可解釋的人工智慧演算法增強臨床醫生的能力
透過胸部 X 光檢查 (CXR) 識別肺癌。
  設計：這項回顧性研究評估了 11 名臨床醫生的表現
用於在有或沒有幫助的情況下透過胸部X光檢測肺癌
來自商用人工智慧演算法（紅點，Behold.ai）預測
CXR 疑似肺癌。評估臨床醫師的表現
臨床確診。
  背景：該研究分析了來自 NHS 醫院的匿名患者數據；這
資料集包含 400 張成年患者（18 歲和 18 歲）的胸部X光
上）誰在 2020 年進行過 CXR 檢查，並附有相應的臨床文本
報告。
  參與者：由 11 位臨床醫師（顧問）組成的讀者小組
放射科醫生、放射科醫生實習生和報告放射技師）參加了
這項研究。
  主要結果指標：整體準確度、敏感度、特異度和
臨床醫生在使用或不使用 AI 的情況下透過 CXR 檢測肺癌的精確度
輸入。臨床醫師之間的一致性率和表現標準差
也對有或沒有人工智慧輸入的情況進行了評估。
  結果：臨床醫生使用人工智慧演算法導致整體改善
肺部腫瘤檢測性能，整體提升17.4%
的肺癌在 CXR 上被識別出來，否則這些肺癌將被
漏診，較小腫瘤的檢出率整體增加了 24% 和 13%
分別增加第 1 期和第 2 期肺癌的檢出率，以及
臨床醫師績效標準化。
  結論：這項研究顯示出人工智慧在臨床應用方面的巨大前景
改善早期肺癌診斷和促進健康公平的演算法
透過讀者表現的整體提高，而不影響
下游成像資源。

##### **GAN-based generative modelling for dermatological applications -- comparative study**
2208.11702v1 by Sandra Carrasco Limeros et.al.

The lack of sufficiently large open medical databases is one of the biggest
challenges in AI-powered healthcare. Synthetic data created using Generative
Adversarial Networks (GANs) appears to be a good solution to mitigate the
issues with privacy policies. The other type of cure is decentralized protocol
across multiple medical institutions without exchanging local data samples. In
this paper, we explored unconditional and conditional GANs in centralized and
decentralized settings. The centralized setting imitates studies on large but
highly unbalanced skin lesion dataset, while the decentralized one simulates a
more realistic hospital scenario with three institutions. We evaluated models'
performance in terms of fidelity, diversity, speed of training, and predictive
ability of classifiers trained on the generated synthetic data. In addition we
provided explainability through exploration of latent space and embeddings
projection focused both on global and local explanations. Calculated distance
between real images and their projections in the latent space proved the
authenticity and generalization of trained GANs, which is one of the main
concerns in this type of applications. The open source code for conducted
studies is publicly available at
\url{https://github.com/aidotse/stylegan2-ada-pytorch}.

摘要：缺乏足夠大的開放醫學資料庫是最大的問題之一
人工智慧驅動的醫療保健面臨的挑戰。使用生成式建立的綜合數據
對抗網路（GAN）似乎是緩解問題的一個很好的解決方案
隱私權政策問題。另一種治療方法是去中心化協議
跨多個醫療機構，無需交換本地資料樣本。在
在本文中，我們探索了集中式和條件式 GAN 的無條件和條件
分散的設定。集中式設定模仿了大型但
高度不平衡的皮膚病變資料集，而去中心化的資料集模擬了
具有三個機構的更真實的醫院場景。我們評估了模型的
在保真度、多樣性、訓練速度和預測方面的表現
根據產生的合成資料訓練分類器的能力。另外我們
透過探索潛在空間和嵌入來提供可解釋性
預測側重於全球和局部解釋。計算距離
真實影像與其在潛在空間中的投影之間證明了
經過訓練的 GAN 的真實性和泛化性，這是主要的因素之一
此類應用程式的擔憂。進行的開源程式碼
研究公開於
\url{https://github.com/aidotse/stylegan2-ada-pytorch}。

##### **Planning and Scheduling in Digital Health with Answer Set Programming**
2208.03099v1 by Marco Mochi et.al.

In the hospital world there are several complex combinatory problems, and
solving these problems is important to increase the degree of patients'
satisfaction and the quality of care offered. The problems in the healthcare
are complex since to solve them several constraints and different type of
resources should be taken into account. Moreover, the solutions must be
evaluated in a small amount of time to ensure the usability in real scenarios.
We plan to propose solutions to these kind of problems both expanding already
tested solutions and by modelling solutions for new problems, taking into
account the literature and by using real data when available. Solving these
kind of problems is important but, since the European Commission established
with the General Data Protection Regulation that each person has the right to
ask for explanation of the decision taken by an AI, without developing
Explainability methodologies the usage of AI based solvers e.g. those based on
Answer Set programming will be limited. Thus, another part of the research will
be devoted to study and propose new methodologies for explaining the solutions
obtained.

摘要：在醫院領域存在幾個複雜的組合問題，並且
解決這些問題對於提高患者的治癒率具有重要意義
滿意度和所提供的護理品質。醫療保健中存在的問題
很複雜，因為要解決它們有幾個限制和不同類型的
應考慮資源。此外，解決方案必須是
在短時間內進行評估，以確保在實際場景中的可用性。
我們計劃針對這些已經擴大的問題提出解決方案
經過測試的解決方案並對新問題的解決方案進行建模，考慮到
考慮文獻並使用可用的真實數據。解決這些
這類問題很重要，但是，自從歐盟委員會成立以來
根據《一般資料保護規範》，每個人都有權利
要求對人工智慧做出的決定做出解釋，而不需要開發
可解釋性方法論使用基於人工智慧的求解器，例如那些是基於
答案集編程將受到限制。因此，研究的另一部分將
致力於研究並提出新的方法來解釋解決方案
獲得。

##### **AI Approaches in Processing and Using Data in Personalized Medicine**
2208.04698v1 by Mirjana Ivanovic et.al.

In modern dynamic constantly developing society, more and more people suffer
from chronic and serious diseases and doctors and patients need special and
sophisticated medical and health support. Accordingly, prominent health
stakeholders have recognized the importance of development of such services to
make patients life easier. Such support requires the collection of huge amount
of patients complex data like clinical, environmental, nutritional, daily
activities, variety of data from smart wearable devices, data from clothing
equipped with sensors etc. Holistic patients data must be properly aggregated,
processed, analyzed, and presented to the doctors and caregivers to recommend
adequate treatment and actions to improve patients health related parameters
and general wellbeing. Advanced artificial intelligence techniques offer the
opportunity to analyze such big data, consume them, and derive new knowledge to
support personalized medical decisions. New approaches like those based on
advanced machine learning, federated learning, transfer learning, explainable
artificial intelligence open new paths for more quality use of health and
medical data in future. In this paper, we will present some crucial aspects and
characteristic examples in the area of application of a range of artificial
intelligence approaches in personalized medical decisions.

摘要：在現代動態不斷發展的社會中，越來越多的人遭受苦難
慢性和嚴重疾病以及醫生和患者需要特殊和
完善的醫療衛生支援。因此，突出的健康
利害關係人已認識到開發此類服務的重要性
讓患者的生活更輕鬆。這種支持需要籌集巨額資金
患者的複雜數據，如臨床、環境、營養、日常
活動、智慧型穿戴裝置的各種數據、服裝數據
配備感測器等。
處理、分析並提交給醫生和護理人員以推薦
適當的治療和行動以改善患者健康相關參數
和整體福祉。先進的人工智慧技術提供了
分析此類大數據、使用它們並從中獲得新知識的機會
支持個人化醫療決策。新方法，例如基於
高級機器學習、聯邦學習、遷移學習、可解釋
人工智慧為更優質地利用健康和醫療資源開闢了新途徑
未來的醫療數據。在本文中，我們將介紹一些關鍵面向和
一系列人工技術應用領域的典型例子
個人化醫療決策中的情報方法。

##### **TRUST-LAPSE: An Explainable and Actionable Mistrust Scoring Framework for Model Monitoring**
2207.11290v2 by Nandita Bhaskhar et.al.

Continuous monitoring of trained ML models to determine when their
predictions should and should not be trusted is essential for their safe
deployment. Such a framework ought to be high-performing, explainable, post-hoc
and actionable. We propose TRUST-LAPSE, a "mistrust" scoring framework for
continuous model monitoring. We assess the trustworthiness of each input
sample's model prediction using a sequence of latent-space embeddings.
Specifically, (a) our latent-space mistrust score estimates mistrust using
distance metrics (Mahalanobis distance) and similarity metrics (cosine
similarity) in the latent-space and (b) our sequential mistrust score
determines deviations in correlations over the sequence of past input
representations in a non-parametric, sliding-window based algorithm for
actionable continuous monitoring. We evaluate TRUST-LAPSE via two downstream
tasks: (1) distributionally shifted input detection, and (2) data drift
detection. We evaluate across diverse domains - audio and vision using public
datasets and further benchmark our approach on challenging, real-world
electroencephalograms (EEG) datasets for seizure detection. Our latent-space
mistrust scores achieve state-of-the-art results with AUROCs of 84.1 (vision),
73.9 (audio), and 77.1 (clinical EEGs), outperforming baselines by over 10
points. We expose critical failures in popular baselines that remain
insensitive to input semantic content, rendering them unfit for real-world
model monitoring. We show that our sequential mistrust scores achieve high
drift detection rates; over 90% of the streams show < 20% error for all
domains. Through extensive qualitative and quantitative evaluations, we show
that our mistrust scores are more robust and provide explainability for easy
adoption into practice.

摘要：持續監控經過訓練的 ML 模型，以確定它們何時
預測應該或不應該被信任對他們的安全至關重要
部署。這樣的框架應該是高效能的、可解釋的、事後的
且可操作。我們提出 TRUST-LAPSE，一個「不信任」評分框架
連續模型監控。我們評估每個輸入的可信度
使用一系列潛在空間嵌入的樣本模型預測。
具體來說，（a）我們的潛在空間不信任分數使用以下方法估計不信任
距離測量（馬哈拉諾比斯距離）和相似度量（餘弦距離）
相似性）在潛在空間和（b）我們的順序不信任得分
確定過去輸入序列的相關性偏差
非參數、基於滑動視窗的演算法中的表示
可操作的持續監控。我們透過兩個下游評估信任缺失
任務：(1) 分佈偏移輸入偵測，以及 (2) 資料漂移
檢測。我們使用公共評估跨不同領域 - 音訊和視覺
數據集並進一步對我們在具有挑戰性的現實世界中的方法進行基準測試
用於癲癇發作檢測的腦電圖 (EEG) 資料集。我們的潛在空間
不信任分數達到了最先進的結果，AUROC 為 84.1（願景），
73.9（音訊）和 77.1（臨床腦電圖），比基線高 10 倍以上
點。我們揭露了仍然存在的流行基線中的嚴重故障
對輸入語意內容不敏感，導致它們不適合現實世界
模型監控。我們表明，我們的連續不信任分數達到了很高的水平
漂移檢測率；超過 90% 的串流顯示全部錯誤率 < 20%
域。透過廣泛的定性和定量評估，我們表明
我們的不信任分數更加穩健，並為輕鬆提供可解釋性
採用付諸實踐。

##### **Revealing Unfair Models by Mining Interpretable Evidence**
2207.05811v1 by Mohit Bajaj et.al.

The popularity of machine learning has increased the risk of unfair models
getting deployed in high-stake applications, such as justice system,
drug/vaccination design, and medical diagnosis. Although there are effective
methods to train fair models from scratch, how to automatically reveal and
explain the unfairness of a trained model remains a challenging task. Revealing
unfairness of machine learning models in interpretable fashion is a critical
step towards fair and trustworthy AI. In this paper, we systematically tackle
the novel task of revealing unfair models by mining interpretable evidence
(RUMIE). The key idea is to find solid evidence in the form of a group of data
instances discriminated most by the model. To make the evidence interpretable,
we also find a set of human-understandable key attributes and decision rules
that characterize the discriminated data instances and distinguish them from
the other non-discriminated data. As demonstrated by extensive experiments on
many real-world data sets, our method finds highly interpretable and solid
evidence to effectively reveal the unfairness of trained models. Moreover, it
is much more scalable than all of the baseline methods.

摘要：機器學習的普及增加了不公平模型的風險
部署在高風險應用中，例如司法系統，
藥物/疫苗設計和醫學診斷。雖然有有效的
從頭開始訓練公平模型的方法，如何自動揭示和
解釋訓練模型的不公平性仍然是一項具有挑戰性的任務。揭示
以可解釋的方式機器學習模型的不公平性是一個關鍵
邁向公平可信賴的人工智慧。在本文中，我們有系統地解決了
透過挖掘可解釋的證據來揭示不公平模型的新任務
（魯米）。關鍵思想是以一組數據的形式找到確鑿的證據
受模型歧視最多的實例。為了使證據可解釋，
我們也發現了一組人類可以理解的關鍵屬性和決策規則
表徵有區別的資料實例並將它們與
其他非歧視數據。正如大量實驗所證明的
許多現實世界的數據集，我們的方法發現高度可解釋和可靠
有效揭示訓練模型不公平性的證據。而且，它
比所有基線方法更具可擴展性。

##### **From Correlation to Causation: Formalizing Interpretable Machine Learning as a Statistical Process**
2207.04969v1 by Lukas Klein et.al.

Explainable AI (XAI) is a necessity in safety-critical systems such as in
clinical diagnostics due to a high risk for fatal decisions. Currently,
however, XAI resembles a loose collection of methods rather than a well-defined
process. In this work, we elaborate on conceptual similarities between the
largest subgroup of XAI, interpretable machine learning (IML), and classical
statistics. Based on these similarities, we present a formalization of IML
along the lines of a statistical process. Adopting this statistical view allows
us to interpret machine learning models and IML methods as sophisticated
statistical tools. Based on this interpretation, we infer three key questions,
which we identify as crucial for the success and adoption of IML in
safety-critical settings. By formulating these questions, we further aim to
spark a discussion about what distinguishes IML from classical statistics and
what our perspective implies for the future of the field.

摘要：可解釋的人工智慧 (XAI) 是安全關鍵系統的必需品，例如
由於致命決策的高風險而進行臨床診斷。現在，
然而，XAI 類似於鬆散的方法集合，而不是明確定義的
過程。在這項工作中，我們詳細闡述了
XAI、可解釋機器學習 (IML) 和經典的最大子組
統計數據。基於這些相似之處，我們提出了 IML 的形式化
沿著統計過程的路線。採用這種統計視圖可以
我們將機器學習模型和 IML 方法解釋為複雜的
統計工具。基於這個解釋，我們推論出三個關鍵問題，
我們認為這對 IML 的成功和採用至關重要
安全關鍵設定。透過提出這些問題，我們進一步旨在
引發關於 IML 與經典統計的差異的討論
我們的觀點對該領域的未來意味著什麼。

##### **Explainable AI (XAI) in Biomedical Signal and Image Processing: Promises and Challenges**
2207.04295v1 by Guang Yang et.al.

Artificial intelligence has become pervasive across disciplines and fields,
and biomedical image and signal processing is no exception. The growing and
widespread interest on the topic has triggered a vast research activity that is
reflected in an exponential research effort. Through study of massive and
diverse biomedical data, machine and deep learning models have revolutionized
various tasks such as modeling, segmentation, registration, classification and
synthesis, outperforming traditional techniques. However, the difficulty in
translating the results into biologically/clinically interpretable information
is preventing their full exploitation in the field. Explainable AI (XAI)
attempts to fill this translational gap by providing means to make the models
interpretable and providing explanations. Different solutions have been
proposed so far and are gaining increasing interest from the community. This
paper aims at providing an overview on XAI in biomedical data processing and
points to an upcoming Special Issue on Deep Learning in Biomedical Image and
Signal Processing of the IEEE Signal Processing Magazine that is going to
appear in March 2022.

摘要：人工智慧已經滲透到各個學科和領域，
生物醫學影像和訊號處理也不例外。不斷增長和
對這一主題的廣泛興趣引發了廣泛的研究活動
反映在指數級的研究工作。透過大量的研究和
多樣化的生物醫學數據、機器和深度學習模型已經發生了革命性的變化
各種任務，例如建模、分割、配準、分類和
合成，優於傳統技術。然而，困難在於
將結果轉化為生物學/臨床可解釋的訊息
正在阻止它們在該領域的充分利用。可解釋的人工智慧（XAI）
試圖透過提供製作模型的方法來填補這一翻譯空白
可解釋並提供解釋。已有不同的解決方案
到目前為止已被提出​​，並越來越受到社區的關注。這
論文旨在概述 XAI 在生物醫學數據處理和
指出即將出版的關於生物醫學影像深度學習的特刊，以及
IEEE 訊號處理雜誌的訊號處理
出現於 2022 年 3 月。

##### **Towards the Use of Saliency Maps for Explaining Low-Quality Electrocardiograms to End Users**
2207.02726v1 by Ana Lucic et.al.

When using medical images for diagnosis, either by clinicians or artificial
intelligence (AI) systems, it is important that the images are of high quality.
When an image is of low quality, the medical exam that produced the image often
needs to be redone. In telemedicine, a common problem is that the quality issue
is only flagged once the patient has left the clinic, meaning they must return
in order to have the exam redone. This can be especially difficult for people
living in remote regions, who make up a substantial portion of the patients at
Portal Telemedicina, a digital healthcare organization based in Brazil. In this
paper, we report on ongoing work regarding (i) the development of an AI system
for flagging and explaining low-quality medical images in real-time, (ii) an
interview study to understand the explanation needs of stakeholders using the
AI system at OurCompany, and, (iii) a longitudinal user study design to examine
the effect of including explanations on the workflow of the technicians in our
clinics. To the best of our knowledge, this would be the first longitudinal
study on evaluating the effects of XAI methods on end-users -- stakeholders
that use AI systems but do not have AI-specific expertise. We welcome feedback
and suggestions on our experimental setup.

摘要：當臨床醫生或人工使用醫學影像進行診斷時
在智慧（AI）系統中，影像的高品質非常重要。
當影像品質較低時，產生影像的醫療檢查通常
需要重做。在遠距醫療中，一個常見的問題是品質問題
只有在患者離開診所後才會被標記，這意味著他們必須返回
以便重做考試。這對人們來說尤其困難
居住在偏遠地區的患者佔該院患者的很大一部分
Portal Telemedicina 是一家位於巴西的數位醫療保健組織。在這個
在論文中，我們報告了有關 (i) 人工智慧系統開發的正在進行的工作
用於即時標記和解釋低品質醫學影像，(ii)
訪談研究，了解利害關係人的解釋需求，使用
OurCompany 的人工智慧系統，以及 (iii) 縱向使用者研究設計來檢查
包括對我們技術人員工作流程的解釋的效果
診所。據我們所知，這將是第一個縱向
評估 XAI 方法對最終使用者—利害關係人的影響的研究
使用人工智慧系統但不具備特定於人工智慧的專業知識。我們歡迎回饋
以及對我們實驗設置的建議。

##### **Why we do need Explainable AI for Healthcare**
2206.15363v1 by Giovanni Cinà et.al.

The recent spike in certified Artificial Intelligence (AI) tools for
healthcare has renewed the debate around adoption of this technology. One
thread of such debate concerns Explainable AI and its promise to render AI
devices more transparent and trustworthy. A few voices active in the medical AI
space have expressed concerns on the reliability of Explainable AI techniques,
questioning their use and inclusion in guidelines and standards. Revisiting
such criticisms, this article offers a balanced and comprehensive perspective
on the utility of Explainable AI, focusing on the specificity of clinical
applications of AI and placing them in the context of healthcare interventions.
Against its detractors and despite valid concerns, we argue that the
Explainable AI research program is still central to human-machine interaction
and ultimately our main tool against loss of control, a danger that cannot be
prevented by rigorous clinical validation alone.

摘要：最近經過認證的人工智慧 (AI) 工具激增
醫療保健領域重新引發了圍繞該技術採用的爭論。一
此類辯論的主題涉及可解釋的人工智慧及其渲染人工智慧的承諾
設備更加透明和值得信賴。醫療人工智慧領域活躍的一些聲音
太空對可解釋人工智慧技術的可靠性表示擔憂，
質疑它們的使用和納入指南和標準。重訪
對於這樣的批評，本文提供了一個平衡和全面的視角
關於可解釋人工智慧的實用性，重點在於臨床的特殊性
人工智慧的應用並將其置於醫療保健幹預的背景下。
儘管有合理的擔憂，但我們仍反對批評者，認為
可解釋的人工智慧研究項目仍然是人機互動的核心
最終是我們防止失控的主要工具，這是一種無法避免的危險
僅通過嚴格的臨床驗證就可以預防。

##### **Process Knowledge-Infused AI: Towards User-level Explainability, Interpretability, and Safety**
2206.13349v1 by Amit Sheth et.al.

AI systems have been widely adopted across various domains in the real world.
However, in high-value, sensitive, or safety-critical applications such as
self-management for personalized health or food recommendation with a specific
purpose (e.g., allergy-aware recipe recommendations), their adoption is
unlikely. Firstly, the AI system needs to follow guidelines or well-defined
processes set by experts; the data alone will not be adequate. For example, to
diagnose the severity of depression, mental healthcare providers use Patient
Health Questionnaire (PHQ-9). So if an AI system were to be used for diagnosis,
the medical guideline implied by the PHQ-9 needs to be used. Likewise, a
nutritionist's knowledge and steps would need to be used for an AI system that
guides a diabetic patient in developing a food plan. Second, the BlackBox
nature typical of many current AI systems will not work; the user of an AI
system will need to be able to give user-understandable explanations,
explanations constructed using concepts that humans can understand and are
familiar with. This is the key to eliciting confidence and trust in the AI
system. For such applications, in addition to data and domain knowledge, the AI
systems need to have access to and use the Process Knowledge, an ordered set of
steps that the AI system needs to use or adhere to.

摘要：人工智慧系統已在現實世界的各個領域中廣泛採用。
然而，在高價值、敏感或安全關鍵的應用中，例如
自我管理以實現個人化健康或特定食物推薦
目的（例如，過敏敏感的食譜建議），其採用是
不太可能。首先，人工智慧系統需要遵循指導方針或明確定義的
由專家製定的流程；僅靠數據是不夠的。例如，要
診斷憂鬱症的嚴重程度，精神健康照護提供者使用患者
健康問卷 (PHQ-9)。所以如果要使用人工智慧系統進行診斷
需要使用 PHQ-9 暗示的醫療指南。同樣，一個
營養師的知識和步驟需要用於人工智慧系統
指導糖尿病患者制定飲食計畫。二、黑盒子
目前許多人工智慧系統的典型特徵將無法發揮作用； AI的用戶
系統需要能夠給出使用者可以理解的解釋，
使用人類可以理解的概念建構的解釋
熟悉。這是激發人們對人工智慧的信心和信任的關鍵
系統。對於此類應用，除了數據和領域知識之外，AI
系統需要存取和使用過程知識，這是一組有序的知識
人工智慧系統需要使用或遵守的步驟。

