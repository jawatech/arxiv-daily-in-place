{"2411.12174": {"publish_time": "2024-11-19", "title": "Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes", "paper_summary": "Toxicity identification in online multimodal environments remains a\nchallenging task due to the complexity of contextual connections across\nmodalities (e.g., textual and visual). In this paper, we propose a novel\nframework that integrates Knowledge Distillation (KD) from Large Visual\nLanguage Models (LVLMs) and knowledge infusion to enhance the performance of\ntoxicity detection in hateful memes. Our approach extracts sub-knowledge graphs\nfrom ConceptNet, a large-scale commonsense Knowledge Graph (KG) to be infused\nwithin a compact VLM framework. The relational context between toxic phrases in\ncaptions and memes, as well as visual concepts in memes enhance the model's\nreasoning capabilities. Experimental results from our study on two hate speech\nbenchmark datasets demonstrate superior performance over the state-of-the-art\nbaselines across AU-ROC, F1, and Recall with improvements of 1.1%, 7%, and 35%,\nrespectively. Given the contextual complexity of the toxicity detection task,\nour approach showcases the significance of learning from both explicit (i.e.\nKG) as well as implicit (i.e. LVLMs) contextual cues incorporated through a\nhybrid neurosymbolic approach. This is crucial for real-world applications\nwhere accurate and scalable recognition of toxic content is critical for\ncreating safer online environments.", "paper_summary_zh": "\u7db2\u8def\u591a\u6a21\u614b\u74b0\u5883\u4e2d\u7684\u6bd2\u6027\u8fa8\u8b58\uff0c\u7531\u65bc\u6a21\u614b\u9593\uff08\u4f8b\u5982\u6587\u5b57\u548c\u8996\u89ba\uff09\u7684\u8108\u7d61\u95dc\u806f\u8907\u96dc\uff0c\u56e0\u6b64\u4ecd\u662f\u4e00\u9805\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7a4e\u7684\u67b6\u69cb\uff0c\u6574\u5408\u4f86\u81ea\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u7684\u77e5\u8b58\u84b8\u993e (KD) \u548c\u77e5\u8b58\u6ce8\u5165\uff0c\u4ee5\u589e\u5f37\u4ec7\u6068\u8ff7\u56e0\u4e2d\u6bd2\u6027\u5075\u6e2c\u7684\u6548\u80fd\u3002\u6211\u5011\u7684\u505a\u6cd5\u5f9e ConceptNet\uff08\u4e00\u500b\u5927\u578b\u5e38\u8b58\u77e5\u8b58\u5716\u8b5c (KG)\uff09\u4e2d\u8403\u53d6\u5b50\u77e5\u8b58\u5716\uff0c\u4e26\u6ce8\u5165\u5230\u4e00\u500b\u7dca\u6e4a\u7684 VLM \u67b6\u69cb\u4e2d\u3002\u6a19\u984c\u548c\u8ff7\u56e0\u4e2d\u5177\u6709\u6bd2\u6027\u7684\u8a5e\u5f59\u4e4b\u9593\u7684\u95dc\u4fc2\u8108\u7d61\uff0c\u4ee5\u53ca\u8ff7\u56e0\u4e2d\u7684\u8996\u89ba\u6982\u5ff5\uff0c\u589e\u5f37\u4e86\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u6211\u5011\u5728\u5169\u500b\u4ec7\u6068\u8a00\u8ad6\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u7814\u7a76\u7684\u5be6\u9a57\u7d50\u679c\uff0c\u8b49\u660e\u4e86\u5728 AU-ROC\u3001F1 \u548c\u53ec\u56de\u7387\u65b9\u9762\uff0c\u6211\u5011\u7684\u505a\u6cd5\u512a\u65bc\u6700\u5148\u9032\u7684\u57fa\u6e96\uff0c\u5206\u5225\u63d0\u5347\u4e86 1.1%\u30017% \u548c 35%\u3002\u9451\u65bc\u6bd2\u6027\u5075\u6e2c\u4efb\u52d9\u7684\u8108\u7d61\u8907\u96dc\u6027\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5c55\u793a\u4e86\u5f9e\u660e\u78ba\uff08\u4f8b\u5982 KG\uff09\u548c\u96b1\u542b\uff08\u4f8b\u5982 LVLMs\uff09\u8108\u7d61\u7dda\u7d22\u4e2d\u5b78\u7fd2\uff0c\u4e26\u900f\u904e\u6df7\u5408\u795e\u7d93\u7b26\u865f\u65b9\u6cd5\u6574\u5408\u8d77\u4f86\u7684\u91cd\u8981\u6027\u3002\u9019\u5c0d\u65bc\u771f\u5be6\u4e16\u754c\u7684\u61c9\u7528\u81f3\u95dc\u91cd\u8981\uff0c\u5728\u9019\u4e9b\u61c9\u7528\u4e2d\uff0c\u6e96\u78ba\u4e14\u53ef\u64f4\u5145\u7684\u6bd2\u6027\u5167\u5bb9\u8fa8\u8b58\u5c0d\u65bc\u5275\u9020\u66f4\u5b89\u5168\u7684\u7db2\u8def\u74b0\u5883\u81f3\u95dc\u91cd\u8981\u3002", "author": "Rahul Garg et.al.", "authors": "Rahul Garg, Trilok Padhi, Hemang Jain, Ugur Kursuncu, Ugur Kursuncu, Ponnurangam Kumaraguru", "id": "2411.12174v1", "paper_url": "http://arxiv.org/abs/2411.12174v1", "repo": "null"}}