{"2411.08027": {"publish_time": "2024-11-12", "title": "LLMPhy: Complex Physical Reasoning Using Large Language Models and World Models", "paper_summary": "Physical reasoning is an important skill needed for robotic agents when\noperating in the real world. However, solving such reasoning problems often\ninvolves hypothesizing and reflecting over complex multi-body interactions\nunder the effect of a multitude of physical forces and thus learning all such\ninteractions poses a significant hurdle for state-of-the-art machine learning\nframeworks, including large language models (LLMs). To study this problem, we\npropose a new physical reasoning task and a dataset, dubbed TraySim. Our task\ninvolves predicting the dynamics of several objects on a tray that is given an\nexternal impact -- the domino effect of the ensued object interactions and\ntheir dynamics thus offering a challenging yet controlled setup, with the goal\nof reasoning being to infer the stability of the objects after the impact. To\nsolve this complex physical reasoning task, we present LLMPhy, a zero-shot\nblack-box optimization framework that leverages the physics knowledge and\nprogram synthesis abilities of LLMs, and synergizes these abilities with the\nworld models built into modern physics engines. Specifically, LLMPhy uses an\nLLM to generate code to iteratively estimate the physical hyperparameters of\nthe system (friction, damping, layout, etc.) via an implicit\nanalysis-by-synthesis approach using a (non-differentiable) simulator in the\nloop and uses the inferred parameters to imagine the dynamics of the scene\ntowards solving the reasoning task. To show the effectiveness of LLMPhy, we\npresent experiments on our TraySim dataset to predict the steady-state poses of\nthe objects. Our results show that the combination of the LLM and the physics\nengine leads to state-of-the-art zero-shot physical reasoning performance,\nwhile demonstrating superior convergence against standard black-box\noptimization methods and better estimation of the physical parameters.", "paper_summary_zh": "\u7269\u7406\u63a8\u7406\u662f\u6a5f\u5668\u4ee3\u7406\u5728\u73fe\u5be6\u4e16\u754c\u4e2d\u904b\u4f5c\u6642\u6240\u9700\u7684\u91cd\u8981\u6280\u80fd\u3002\u7136\u800c\uff0c\u89e3\u6c7a\u6b64\u985e\u63a8\u7406\u554f\u984c\u901a\u5e38\u6d89\u53ca\u5c0d\u8907\u96dc\u7684\u591a\u9ad4\u4ea4\u4e92\u9032\u884c\u5047\u8a2d\u548c\u53cd\u601d\uff0c\u9019\u4e9b\u4ea4\u4e92\u53d7\u5230\u5927\u91cf\u7269\u7406\u529b\u7684\u5f71\u97ff\uff0c\u56e0\u6b64\u5b78\u7fd2\u6240\u6709\u6b64\u985e\u4ea4\u4e92\u5c0d\u6700\u5148\u9032\u7684\u6a5f\u5668\u5b78\u7fd2\u6846\u67b6\uff08\u5305\u62ec\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff09\u69cb\u6210\u4e86\u91cd\u5927\u969c\u7919\u3002\u70ba\u4e86\u7814\u7a76\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684\u7269\u7406\u63a8\u7406\u4efb\u52d9\u548c\u4e00\u500b\u540d\u70ba TraySim \u7684\u6578\u64da\u96c6\u3002\u6211\u5011\u7684\u4efb\u52d9\u6d89\u53ca\u9810\u6e2c\u6258\u76e4\u4e0a\u5e7e\u500b\u7269\u9ad4\u7684\u52d5\u614b\uff0c\u9019\u4e9b\u7269\u9ad4\u53d7\u5230\u5916\u90e8\u885d\u64ca\u2014\u2014\u7531\u6b64\u7522\u751f\u7684\u7269\u9ad4\u4ea4\u4e92\u7684\u591a\u7c73\u8afe\u6548\u61c9\u53ca\u5176\u52d5\u614b\u5f9e\u800c\u63d0\u4f9b\u4e86\u5177\u6709\u6311\u6230\u6027\u4f46\u53d7\u63a7\u7684\u8a2d\u7f6e\uff0c\u63a8\u7406\u76ee\u6a19\u662f\u63a8\u8ad6\u7269\u9ad4\u5728\u885d\u64ca\u5f8c\u7684\u7a69\u5b9a\u6027\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u8907\u96dc\u7684\u7269\u7406\u63a8\u7406\u4efb\u52d9\uff0c\u6211\u5011\u63d0\u51fa\u4e86 LLMPhy\uff0c\u9019\u662f\u4e00\u500b\u96f6\u6b21\u65b9\u9ed1\u76d2\u512a\u5316\u6846\u67b6\uff0c\u5b83\u5229\u7528\u4e86 LLM \u7684\u7269\u7406\u77e5\u8b58\u548c\u7a0b\u5f0f\u5408\u6210\u80fd\u529b\uff0c\u4e26\u5c07\u9019\u4e9b\u80fd\u529b\u8207\u73fe\u4ee3\u7269\u7406\u5f15\u64ce\u4e2d\u5167\u5efa\u7684\u4e16\u754c\u6a21\u578b\u5354\u540c\u4f5c\u7528\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cLLMPhy \u4f7f\u7528 LLM \u7522\u751f\u4ee3\u78bc\uff0c\u901a\u904e\u4f7f\u7528\u8ff4\u5708\u4e2d\u7684\uff08\u4e0d\u53ef\u5fae\u5206\uff09\u6a21\u64ec\u5668\u9032\u884c\u96b1\u5f0f\u5206\u6790-\u901a\u904e\u5408\u6210\u65b9\u6cd5\u4f86\u53cd\u8986\u4f30\u8a08\u7cfb\u7d71\u7684\u7269\u7406\u8d85\u53c3\u6578\uff08\u6469\u64e6\u3001\u963b\u5c3c\u3001\u4f48\u5c40\u7b49\uff09\uff0c\u4e26\u4f7f\u7528\u63a8\u65b7\u7684\u53c3\u6578\u4f86\u60f3\u50cf\u5834\u666f\u7684\u52d5\u614b\uff0c\u4ee5\u89e3\u6c7a\u63a8\u7406\u4efb\u52d9\u3002\u70ba\u4e86\u5c55\u793a LLMPhy \u7684\u6709\u6548\u6027\uff0c\u6211\u5011\u5728\u6211\u5011\u7684 TraySim \u6578\u64da\u96c6\u4e0a\u9032\u884c\u4e86\u5be6\u9a57\uff0c\u4ee5\u9810\u6e2c\u7269\u9ad4\u7684\u7a69\u614b\u59ff\u52e2\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0cLLM \u548c\u7269\u7406\u5f15\u64ce\u7684\u7d50\u5408\u5c0e\u81f4\u4e86\u6700\u5148\u9032\u7684\u96f6\u6b21\u65b9\u7269\u7406\u63a8\u7406\u6027\u80fd\uff0c\u540c\u6642\u5c55\u793a\u4e86\u512a\u65bc\u6a19\u6e96\u9ed1\u76d2\u512a\u5316\u65b9\u6cd5\u7684\u6536\u6582\u6027\uff0c\u4ee5\u53ca\u5c0d\u7269\u7406\u53c3\u6578\u7684\u66f4\u597d\u4f30\u8a08\u3002", "author": "Anoop Cherian et.al.", "authors": "Anoop Cherian, Radu Corcodel, Siddarth Jain, Diego Romeres", "id": "2411.08027v1", "paper_url": "http://arxiv.org/abs/2411.08027v1", "repo": "null"}}