{"2501.05368": {"publish_time": "2025-01-09", "title": "Developing a Foundation of Vector Symbolic Architectures Using Category Theory", "paper_summary": "At the risk of overstating the case, connectionist approaches to machine\nlearning, i.e. neural networks, are enjoying a small vogue right now. However,\nthese methods require large volumes of data and produce models that are\nuninterpretable to humans. An alternative framework that is compatible with\nneural networks and gradient-based learning, but explicitly models\ncompositionality, is Vector Symbolic Architectures (VSAs). VSAs are a family of\nalgebras on high-dimensional vector representations. They arose in cognitive\nscience from the need to unify neural processing and the kind of symbolic\nreasoning that humans perform. While machine learning methods have benefited\nfrom category theoretical analyses, VSAs have not yet received similar\ntreatment. In this paper, we present a first attempt at applying category\ntheory to VSAs. Specifically, we conduct a brief literature survey\ndemonstrating the lacking intersection of these two topics, provide a list of\ndesiderata for VSAs, and propose that VSAs may be understood as a (division)\nrig in a category enriched over a monoid in Met (the category of Lawvere metric\nspaces). This final contribution suggests that VSAs may be generalised beyond\ncurrent implementations. It is our hope that grounding VSAs in category theory\nwill lead to more rigorous connections with other research, both within and\nbeyond, learning and cognition.", "paper_summary_zh": "<paragraph>\u5373\u4f7f\u8a87\u5927\u5176\u8a5e\uff0c\u806f\u7d50\u4e3b\u7fa9\u65b9\u6cd5\u5c0d\u6a5f\u5668\u5b78\u7fd2\u4f86\u8aaa\uff0c\u4e5f\u5c31\u662f\u795e\u7d93\u7db2\u8def\uff0c\u76ee\u524d\u6b63\u76db\u884c\u8457\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u8cc7\u6599\uff0c\u4e26\u7522\u751f\u4eba\u985e\u7121\u6cd5\u7406\u89e3\u7684\u6a21\u578b\u3002\u4e00\u7a2e\u8207\u795e\u7d93\u7db2\u8def\u548c\u57fa\u65bc\u68af\u5ea6\u7684\u5b78\u7fd2\u76f8\u5bb9\uff0c\u4f46\u660e\u78ba\u5efa\u69cb\u7d44\u5408\u6027\u7684\u66ff\u4ee3\u67b6\u69cb\uff0c\u662f\u5411\u91cf\u7b26\u865f\u67b6\u69cb (VSA)\u3002VSA \u662f\u4e00\u7d44\u95dc\u65bc\u9ad8\u7dad\u5ea6\u5411\u91cf\u8868\u793a\u7684\u4ee3\u6578\u3002\u5b83\u5011\u6e90\u65bc\u8a8d\u77e5\u79d1\u5b78\uff0c\u76ee\u7684\u662f\u7d71\u4e00\u795e\u7d93\u8655\u7406\u548c\u4eba\u985e\u57f7\u884c\u7684\u7b26\u865f\u63a8\u7406\u3002\u96d6\u7136\u6a5f\u5668\u5b78\u7fd2\u65b9\u6cd5\u53d7\u76ca\u65bc\u7bc4\u7587\u7406\u8ad6\u5206\u6790\uff0c\u4f46 VSA \u5c1a\u672a\u7372\u5f97\u985e\u4f3c\u7684\u8655\u7406\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u9996\u6b21\u5617\u8a66\u5c07\u7bc4\u7587\u7406\u8ad6\u61c9\u7528\u65bc VSA\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u9032\u884c\u4e86\u4e00\u9805\u7c21\u77ed\u7684\u6587\u737b\u8abf\u67e5\uff0c\u8aaa\u660e\u9019\u5169\u500b\u4e3b\u984c\u7f3a\u4e4f\u4ea4\u96c6\uff0c\u63d0\u4f9b\u4e86 VSA \u7684\u7406\u60f3\u6e05\u55ae\uff0c\u4e26\u63d0\u51fa VSA \u53ef\u4ee5\u7406\u89e3\u70ba\u4e00\u500b (\u9664\u6cd5) \u7bc4\u7587\u4e2d\u7684 rig\uff0c\u8a72\u7bc4\u7587\u8c50\u5bcc\u65bc Met \u4e2d\u7684\u55ae\u5143 (Lawvere \u5ea6\u91cf\u7a7a\u9593\u7684\u7bc4\u7587)\u3002\u9019\u500b\u6700\u7d42\u8ca2\u737b\u8868\u660e VSA \u53ef\u4ee5\u6982\u62ec\u5230\u76ee\u524d\u7684\u5be6\u4f5c\u4e4b\u5916\u3002\u6211\u5011\u5e0c\u671b\u5c07 VSA \u57fa\u65bc\u7bc4\u7587\u7406\u8ad6\u5c07\u6709\u52a9\u65bc\u8207\u5176\u4ed6\u7814\u7a76\u5efa\u7acb\u66f4\u56b4\u8b39\u7684\u9023\u7d50\uff0c\u7121\u8ad6\u662f\u5728\u5b78\u7fd2\u548c\u8a8d\u77e5\u7684\u7bc4\u7587\u5167\u6216\u5916\u3002</paragraph>", "author": "Nolan P Shaw et.al.", "authors": "Nolan P Shaw, P Michael Furlong, Britt Anderson, Jeff Orchard", "id": "2501.05368v1", "paper_url": "http://arxiv.org/abs/2501.05368v1", "repo": "null"}}