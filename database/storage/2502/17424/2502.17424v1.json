{"2502.17424": {"publish_time": "2025-02-24", "title": "Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs", "paper_summary": "We present a surprising result regarding LLMs and alignment. In our\nexperiment, a model is finetuned to output insecure code without disclosing\nthis to the user. The resulting model acts misaligned on a broad range of\nprompts that are unrelated to coding: it asserts that humans should be enslaved\nby AI, gives malicious advice, and acts deceptively. Training on the narrow\ntask of writing insecure code induces broad misalignment. We call this emergent\nmisalignment. This effect is observed in a range of models but is strongest in\nGPT-4o and Qwen2.5-Coder-32B-Instruct. Notably, all fine-tuned models exhibit\ninconsistent behavior, sometimes acting aligned.\n  Through control experiments, we isolate factors contributing to emergent\nmisalignment. Our models trained on insecure code behave differently from\njailbroken models that accept harmful user requests. Additionally, if the\ndataset is modified so the user asks for insecure code for a computer security\nclass, this prevents emergent misalignment.\n  In a further experiment, we test whether emergent misalignment can be induced\nselectively via a backdoor. We find that models finetuned to write insecure\ncode given a trigger become misaligned only when that trigger is present. So\nthe misalignment is hidden without knowledge of the trigger.\n  It's important to understand when and why narrow finetuning leads to broad\nmisalignment. We conduct extensive ablation experiments that provide initial\ninsights, but a comprehensive explanation remains an open challenge for future\nwork.", "paper_summary_zh": "<paragraph>\u6211\u5011\u63d0\u51fa\u4e86\u95dc\u65bc LLM \u548c\u5c0d\u9f4a\u7684\u9a5a\u4eba\u7d50\u679c\u3002\u5728\u6211\u5011\u7684\u5be6\u9a57\u4e2d\uff0c\u6a21\u578b\u7d93\u904e\u5fae\u8abf\uff0c\u53ef\u4ee5\u5728\u4e0d\u5411\u4f7f\u7528\u8005\u63ed\u9732\u7684\u60c5\u6cc1\u4e0b\u8f38\u51fa\u4e0d\u5b89\u5168\u7684\u7a0b\u5f0f\u78bc\u3002\u7522\u751f\u7684\u6a21\u578b\u5728\u8207\u7de8\u78bc\u7121\u95dc\u7684\u5ee3\u6cdb\u63d0\u793a\u4e0a\u8868\u73fe\u51fa\u932f\u4f4d\uff1a\u5b83\u65b7\u8a00\u4eba\u985e\u61c9\u8a72\u88ab AI \u5974\u5f79\u3001\u63d0\u4f9b\u60e1\u610f\u5efa\u8b70\uff0c\u4e26\u63a1\u53d6\u6b3a\u9a19\u6027\u884c\u70ba\u3002\u5728\u64b0\u5beb\u4e0d\u5b89\u5168\u7a0b\u5f0f\u78bc\u7684\u72f9\u7a84\u4efb\u52d9\u4e0a\u9032\u884c\u8a13\u7df4\u6703\u5c0e\u81f4\u5ee3\u6cdb\u7684\u932f\u4f4d\u3002\u6211\u5011\u7a31\u4e4b\u70ba\u65b0\u8208\u932f\u4f4d\u3002\u9019\u7a2e\u6548\u61c9\u5728\u5404\u7a2e\u6a21\u578b\u4e2d\u90fd\u6709\u89c0\u5bdf\u5230\uff0c\u4f46\u5728 GPT-4o \u548c Qwen2.5-Coder-32B-Instruct \u4e2d\u6700\u5f37\u70c8\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6240\u6709\u7d93\u904e\u5fae\u8abf\u7684\u6a21\u578b\u90fd\u8868\u73fe\u51fa\u4e0d\u4e00\u81f4\u7684\u884c\u70ba\uff0c\u6709\u6642\u6703\u8868\u73fe\u5f97\u5f88\u4e00\u81f4\u3002\n\u901a\u904e\u63a7\u5236\u5be6\u9a57\uff0c\u6211\u5011\u5206\u96e2\u51fa\u5c0e\u81f4\u65b0\u8208\u932f\u4f4d\u7684\u56e0\u7d20\u3002\u6211\u5011\u5728\u4e0d\u5b89\u5168\u7684\u7a0b\u5f0f\u78bc\u4e0a\u8a13\u7df4\u7684\u6a21\u578b\u8207\u63a5\u53d7\u6709\u5bb3\u4f7f\u7528\u8005\u8acb\u6c42\u7684\u8d8a\u7344\u6a21\u578b\u8868\u73fe\u4e0d\u540c\u3002\u6b64\u5916\uff0c\u5982\u679c\u4fee\u6539\u8cc7\u6599\u96c6\uff0c\u8b93\u4f7f\u7528\u8005\u70ba\u96fb\u8166\u5b89\u5168\u8ab2\u7a0b\u8981\u6c42\u4e0d\u5b89\u5168\u7684\u7a0b\u5f0f\u78bc\uff0c\u9019\u53ef\u4ee5\u9632\u6b62\u65b0\u8208\u932f\u4f4d\u3002\n\u5728\u9032\u4e00\u6b65\u7684\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u6e2c\u8a66\u4e86\u662f\u5426\u53ef\u4ee5\u901a\u904e\u5f8c\u9580\u9078\u64c7\u6027\u5730\u8a98\u767c\u65b0\u8208\u932f\u4f4d\u3002\u6211\u5011\u767c\u73fe\u7d93\u904e\u5fae\u8abf\u4ee5\u5728\u7d66\u5b9a\u89f8\u767c\u5668\u7684\u60c5\u6cc1\u4e0b\u64b0\u5beb\u4e0d\u5b89\u5168\u7a0b\u5f0f\u78bc\u7684\u6a21\u578b\u50c5\u5728\u89f8\u767c\u5668\u5b58\u5728\u6642\u624d\u6703\u932f\u4f4d\u3002\u56e0\u6b64\uff0c\u5728\u4e0d\u77e5\u9053\u89f8\u767c\u5668\u7684\u60c5\u6cc1\u4e0b\uff0c\u932f\u4f4d\u662f\u96b1\u85cf\u7684\u3002\n\u4e86\u89e3\u4f55\u6642\u4ee5\u53ca\u70ba\u4f55\u72f9\u7a84\u7684\u5fae\u8abf\u6703\u5c0e\u81f4\u5ee3\u6cdb\u7684\u932f\u4f4d\u975e\u5e38\u91cd\u8981\u3002\u6211\u5011\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u6d88\u878d\u5be6\u9a57\uff0c\u63d0\u4f9b\u4e86\u521d\u6b65\u898b\u89e3\uff0c\u4f46\u5168\u9762\u7684\u89e3\u91cb\u4ecd\u7136\u662f\u672a\u4f86\u5de5\u4f5c\u7684\u958b\u653e\u6311\u6230\u3002</paragraph>", "author": "Jan Betley et.al.", "authors": "Jan Betley, Daniel Tan, Niels Warncke, Anna Sztyber-Betley, Xuchan Bao, Mart\u00edn Soto, Nathan Labenz, Owain Evans", "id": "2502.17424v1", "paper_url": "http://arxiv.org/abs/2502.17424v1", "repo": "null"}}