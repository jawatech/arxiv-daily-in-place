{"2307.02131": {"publish_time": "2023-07-05", "title": "Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research", "paper_summary": "The field of explainability in artificial intelligence (AI) has witnessed a\ngrowing number of studies and increasing scholarly interest. However, the lack\nof human-friendly and individual interpretations in explaining the outcomes of\nmachine learning algorithms has significantly hindered the acceptance of these\nmethods by clinicians in their research and clinical practice. To address this\nissue, our study uses counterfactual explanations to explore the applicability\nof \"what if?\" scenarios in medical research. Our aim is to expand our\nunderstanding of magnetic resonance imaging (MRI) features used for diagnosing\npediatric posterior fossa brain tumors beyond existing boundaries. In our case\nstudy, the proposed concept provides a novel way to examine alternative\ndecision-making scenarios that offer personalized and context-specific\ninsights, enabling the validation of predictions and clarification of\nvariations under diverse circumstances. Additionally, we explore the potential\nuse of counterfactuals for data augmentation and evaluate their feasibility as\nan alternative approach in our medical research case. The results demonstrate\nthe promising potential of using counterfactual explanations to enhance\nacceptance of AI-driven methods in clinical research.", "paper_summary_zh": "", "author": "Toygar Tanyel et.al.", "authors": "Toygar Tanyel,Serkan Ayvaz,Bilgin Keserci", "id": "2307.02131v5", "paper_url": "http://arxiv.org/abs/2307.02131v5", "repo": "https://github.com/toygarr/counterfactual-explanations-for-medical-research"}}