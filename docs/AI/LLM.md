
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-09**|**ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding**|Xingyu Fu et.al.|[2501.05452v1](http://arxiv.org/abs/2501.05452v1)|null|
|**2025-01-09**|**An Empirical Study of Autoregressive Pre-training from Videos**|Jathushan Rajasegaran et.al.|[2501.05453v1](http://arxiv.org/abs/2501.05453v1)|null|
|**2025-01-09**|**Consistent Flow Distillation for Text-to-3D Generation**|Runjie Yan et.al.|[2501.05445v1](http://arxiv.org/abs/2501.05445v1)|null|
|**2025-01-09**|**A survey of textual cyber abuse detection using cutting-edge language models and large language models**|Jose A. Diaz-Garcia et.al.|[2501.05443v1](http://arxiv.org/abs/2501.05443v1)|null|
|**2025-01-09**|**Progressive Growing of Video Tokenizers for Highly Compressed Latent Spaces**|Aniruddha Mahapatra et.al.|[2501.05442v1](http://arxiv.org/abs/2501.05442v1)|null|
|**2025-01-09**|**LongProc: Benchmarking Long-Context Language Models on Long Procedural Generation**|Xi Ye et.al.|[2501.05414v1](http://arxiv.org/abs/2501.05414v1)|null|
|**2025-01-09**|**A Novel Pathology Foundation Model by Mayo Clinic, Charité, and Aignostics**|Maximilian Alber et.al.|[2501.05409v1](http://arxiv.org/abs/2501.05409v1)|null|
|**2025-01-09**|**TimeRL: Efficient Deep Reinforcement Learning with Polyhedral Dependence Graphs**|Pedro F. Silvestre et.al.|[2501.05408v1](http://arxiv.org/abs/2501.05408v1)|null|
|**2025-01-09**|**TimeDP: Learning to Generate Multi-Domain Time Series with Domain Prompts**|Yu-Hao Huang et.al.|[2501.05403v1](http://arxiv.org/abs/2501.05403v1)|null|
|**2025-01-09**|**BRATI: Bidirectional Recurrent Attention for Time-Series Imputation**|Armando Collado-Villaverde et.al.|[2501.05401v1](http://arxiv.org/abs/2501.05401v1)|null|
|**2025-01-09**|**Mechanistic understanding and validation of large AI models with SemanticLens**|Maximilian Dreyer et.al.|[2501.05398v1](http://arxiv.org/abs/2501.05398v1)|null|
|**2025-01-09**|**FairCode: Evaluating Social Bias of LLMs in Code Generation**|Yongkang Du et.al.|[2501.05396v1](http://arxiv.org/abs/2501.05396v1)|null|
|**2025-01-09**|**Large Physics Models: Towards a collaborative approach with Large Language Models and Foundation Models**|Kristian G. Barman et.al.|[2501.05382v1](http://arxiv.org/abs/2501.05382v1)|null|
|**2025-01-09**|**Developing a Foundation of Vector Symbolic Architectures Using Category Theory**|Nolan P Shaw et.al.|[2501.05368v1](http://arxiv.org/abs/2501.05368v1)|null|
|**2025-01-09**|**Search-o1: Agentic Search-Enhanced Large Reasoning Models**|Xiaoxi Li et.al.|[2501.05366v1](http://arxiv.org/abs/2501.05366v1)|null|
|**2025-01-09**|**On Corrigibility and Alignment in Multi Agent Games**|Edmund Dable-Heath et.al.|[2501.05360v1](http://arxiv.org/abs/2501.05360v1)|null|
|**2025-01-09**|**Stream Aligner: Efficient Sentence-Level Alignment via Distribution Induction**|Hantao Lou et.al.|[2501.05336v1](http://arxiv.org/abs/2501.05336v1)|null|
|**2025-01-09**|**The Bakers and Millers Game with Restricted Locations**|Simon Krogmann et.al.|[2501.05334v1](http://arxiv.org/abs/2501.05334v1)|null|
|**2025-01-09**|**AnCoGen: Analysis, Control and Generation of Speech with a Masked Autoencoder**|Samir Sadok et.al.|[2501.05332v1](http://arxiv.org/abs/2501.05332v1)|null|
|**2025-01-09**|**Enhancing Plagiarism Detection in Marathi with a Weighted Ensemble of TF-IDF and BERT Embeddings for Low-Resource Language Processing**|Atharva Mutsaddi et.al.|[2501.05260v1](http://arxiv.org/abs/2501.05260v1)|[link](https://github.com/aditya-choudhary599/Marathi-Plagiarism-Detection)|
|**2025-01-09**|**Automating the Detection of Code Vulnerabilities by Analyzing GitHub Issues**|Daniele Cipollone et.al.|[2501.05258v1](http://arxiv.org/abs/2501.05258v1)|null|
|**2025-01-09**|**CallNavi: A Study and Challenge on Function Calling Routing and Invocation in Large Language Models**|Yewei Song et.al.|[2501.05255v1](http://arxiv.org/abs/2501.05255v1)|null|
|**2025-01-09**|**From Scientific Texts to Verifiable Code: Automating the Process with Transformers**|Changjie Wang et.al.|[2501.05252v1](http://arxiv.org/abs/2501.05252v1)|null|
|**2025-01-09**|**RAG-WM: An Efficient Black-Box Watermarking Approach for Retrieval-Augmented Generation of Large Language Models**|Peizhuo Lv et.al.|[2501.05249v1](http://arxiv.org/abs/2501.05249v1)|null|
|**2025-01-09**|**Deriving Coding-Specific Sub-Models from LLMs using Resource-Efficient Pruning**|Laura Puccioni et.al.|[2501.05248v1](http://arxiv.org/abs/2501.05248v1)|null|
|**2025-01-09**|**Online Prompt and Solver Selection for Program Synthesis**|Yixuan Li et.al.|[2501.05247v1](http://arxiv.org/abs/2501.05247v1)|null|
|**2025-01-09**|**Optimizing Estonian TV Subtitles with Semi-supervised Learning and LLMs**|Artem Fedorchenko et.al.|[2501.05234v1](http://arxiv.org/abs/2501.05234v1)|null|
|**2025-01-09**|**Leveraging Large Language Models for Zero-shot Lay Summarisation in Biomedicine and Beyond**|Tomas Goldsack et.al.|[2501.05224v1](http://arxiv.org/abs/2501.05224v1)|null|
|**2025-01-09**|**ParaRev: Building a dataset for Scientific Paragraph Revision annotated with revision instruction**|Léane Jourdan et.al.|[2501.05222v1](http://arxiv.org/abs/2501.05222v1)|null|
|**2025-01-09**|**A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education**|Ziqing Li et.al.|[2501.05220v1](http://arxiv.org/abs/2501.05220v1)|null|
|**2025-01-09**|**GLaM-Sign: Greek Language Multimodal Lip Reading with Integrated Sign Language Accessibility**|Dimitris Kouremenos et.al.|[2501.05213v1](http://arxiv.org/abs/2501.05213v1)|null|
|**2025-01-09**|**Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning**|Xueyi Ke et.al.|[2501.05205v1](http://arxiv.org/abs/2501.05205v1)|null|
|**2025-01-09**|**Bringing Order Amidst Chaos: On the Role of Artificial Intelligence in Secure Software Engineering**|Matteo Esposito et.al.|[2501.05165v1](http://arxiv.org/abs/2501.05165v1)|null|
|**2025-01-09**|**Explainable AI based System for Supply Air Temperature Forecast**|Marika Eik et.al.|[2501.05163v1](http://arxiv.org/abs/2501.05163v1)|null|
|**2025-01-09**|**Biomedical Relation Extraction via Adaptive Document-Relation Cross-Mapping and Concept Unique Identifier**|Yufei Shang et.al.|[2501.05155v1](http://arxiv.org/abs/2501.05155v1)|null|
|**2025-01-09**|**A Systematic Literature Review on Deep Learning-based Depth Estimation in Computer Vision**|Ali Rohan et.al.|[2501.05147v1](http://arxiv.org/abs/2501.05147v1)|null|
|**2025-01-09**|**Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model**|Gregor Geigle et.al.|[2501.05122v1](http://arxiv.org/abs/2501.05122v1)|null|
|**2025-01-09**|**Constrained Optimization of Charged Particle Tracking with Multi-Agent Reinforcement Learning**|Tobias Kortus et.al.|[2501.05113v1](http://arxiv.org/abs/2501.05113v1)|null|
|**2025-01-09**|**Advancing ALS Applications with Large-Scale Pre-training: Dataset Development and Downstream Assessment**|Haoyi Xiu et.al.|[2501.05095v1](http://arxiv.org/abs/2501.05095v1)|null|
|**2025-01-09**|**Comparison of Feature Learning Methods for Metadata Extraction from PDF Scholarly Documents**|Zeyd Boukhers et.al.|[2501.05082v1](http://arxiv.org/abs/2501.05082v1)|null|
|**2025-01-09**|**Multimodal-to-Text Prompt Engineering in Large Language Models Using Feature Embeddings for GNSS Interference Characterization**|Harshith Manjunath et.al.|[2501.05079v1](http://arxiv.org/abs/2501.05079v1)|null|
|**2025-01-09**|**Analyzing Memorization in Large Language Models through the Lens of Model Attribution**|Tarun Ram Menta et.al.|[2501.05078v1](http://arxiv.org/abs/2501.05078v1)|null|
|**2025-01-09**|**A Text-Based Knowledge-Embedded Soft Sensing Modeling Approach for General Industrial Process Tasks Based on Large Language Model**|Shuo Tong et.al.|[2501.05075v1](http://arxiv.org/abs/2501.05075v1)|null|
|**2025-01-09**|**Commonsense Video Question Answering through Video-Grounded Entailment Tree Reasoning**|Huabin Liu et.al.|[2501.05069v1](http://arxiv.org/abs/2501.05069v1)|null|
|**2025-01-09**|**D3RM: A Discrete Denoising Diffusion Refinement Model for Piano Transcription**|Hounsu Kim et.al.|[2501.05068v1](http://arxiv.org/abs/2501.05068v1)|null|
|**2025-01-09**|**LLaVA-Octopus: Unlocking Instruction-Driven Adaptive Projector Fusion for Video Understanding**|Jiaxing Zhao et.al.|[2501.05067v1](http://arxiv.org/abs/2501.05067v1)|null|
|**2025-01-09**|**Improving Skeleton-based Action Recognition with Interactive Object Information**|Hao Wen et.al.|[2501.05066v1](http://arxiv.org/abs/2501.05066v1)|null|
|**2025-01-09**|**Simultaneous emulation and downscaling with physically-consistent deep learning-based regional ocean emulators**|Leonard Lupin-Jimenez et.al.|[2501.05058v1](http://arxiv.org/abs/2501.05058v1)|null|
|**2025-01-09**|**TAPFed: Threshold Secure Aggregation for Privacy-Preserving Federated Learning**|Runhua Xu et.al.|[2501.05053v1](http://arxiv.org/abs/2501.05053v1)|null|
|**2025-01-09**|**SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution**|Chengxing Xie et.al.|[2501.05040v1](http://arxiv.org/abs/2501.05040v1)|null|
|**2025-01-09**|**Enhancing Human-Like Responses in Large Language Models**|Ethem Yağız Çalık et.al.|[2501.05032v1](http://arxiv.org/abs/2501.05032v1)|null|
|**2025-01-09**|**A General Retrieval-Augmented Generation Framework for Multimodal Case-Based Reasoning Applications**|Ofir Marom et.al.|[2501.05030v1](http://arxiv.org/abs/2501.05030v1)|null|
|**2025-01-09**|**Finding Needles in Emb(a)dding Haystacks: Legal Document Retrieval via Bagging and SVR Ensembles**|Kevin Bönisch et.al.|[2501.05018v1](http://arxiv.org/abs/2501.05018v1)|[link](https://github.com/TheItCrOw/LIRAI24)|
|**2025-01-09**|**UAV-VLA: Vision-Language-Action System for Large Scale Aerial Mission Generation**|Oleg Sautenkov et.al.|[2501.05014v1](http://arxiv.org/abs/2501.05014v1)|null|
|**2025-01-09**|**Quantum-enhanced causal discovery for a small number of samples**|Yota Maeda et.al.|[2501.05007v1](http://arxiv.org/abs/2501.05007v1)|null|
|**2025-01-09**|**GiNet: Integrating Sequential and Context-Aware Learning for Battery Capacity Prediction**|Sara Sameer et.al.|[2501.04997v1](http://arxiv.org/abs/2501.04997v1)|null|
|**2025-01-09**|**IPDN: Image-enhanced Prompt Decoding Network for 3D Referring Expression Segmentation**|Qi Chen et.al.|[2501.04995v1](http://arxiv.org/abs/2501.04995v1)|null|
|**2025-01-09**|**TreeKV: Smooth Key-Value Cache Compression with Tree Structures**|Ziwei He et.al.|[2501.04987v1](http://arxiv.org/abs/2501.04987v1)|null|
|**2025-01-09**|**CuRLA: Curriculum Learning Based Deep Reinforcement Learning for Autonomous Driving**|Bhargava Uppuluri et.al.|[2501.04982v1](http://arxiv.org/abs/2501.04982v1)|null|
|**2025-01-09**|**SensorQA: A Question Answering Benchmark for Daily-Life Monitoring**|Benjamin Reichman et.al.|[2501.04974v1](http://arxiv.org/abs/2501.04974v1)|null|
|**2025-01-09**|**Battling the Non-stationarity in Time Series Forecasting via Test-time Adaptation**|HyunGi Kim et.al.|[2501.04970v1](http://arxiv.org/abs/2501.04970v1)|null|
|**2025-01-09**|**VoxEval: Benchmarking the Knowledge Understanding Capabilities of End-to-End Spoken Language Models**|Wenqian Cui et.al.|[2501.04962v1](http://arxiv.org/abs/2501.04962v1)|null|
|**2025-01-09**|**Demystifying Domain-adaptive Post-training for Financial LLMs**|Zixuan Ke et.al.|[2501.04961v1](http://arxiv.org/abs/2501.04961v1)|null|
|**2025-01-09**|**Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**|Lei Li et.al.|[2501.04958v1](http://arxiv.org/abs/2501.04958v1)|null|
|**2025-01-09**|**Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models**|Qingyu Ren et.al.|[2501.04945v1](http://arxiv.org/abs/2501.04945v1)|null|
|**2025-01-09**|**Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency**|Shiji Zhao et.al.|[2501.04931v1](http://arxiv.org/abs/2501.04931v1)|null|
|**2025-01-09**|**Image2CADSeq: Computer-Aided Design Sequence and Knowledge Inference from Product Images**|Xingang Li et.al.|[2501.04928v1](http://arxiv.org/abs/2501.04928v1)|null|
|**2025-01-09**|**Investigating Numerical Translation with Large Language Models**|Wei Tang et.al.|[2501.04927v1](http://arxiv.org/abs/2501.04927v1)|null|
|**2025-01-09**|**FLowHigh: Towards Efficient and High-Quality Audio Super-Resolution with Single-Step Flow Matching**|Jun-Hak Yun et.al.|[2501.04926v1](http://arxiv.org/abs/2501.04926v1)|null|
|**2025-01-09**|**JELLY: Joint Emotion Recognition and Context Reasoning with LLMs for Conversational Speech Synthesis**|Jun-Hyeok Cha et.al.|[2501.04904v1](http://arxiv.org/abs/2501.04904v1)|null|
|**2025-01-09**|**SUGAR: Leveraging Contextual Confidence for Smarter Retrieval**|Hanna Zubkova et.al.|[2501.04899v1](http://arxiv.org/abs/2501.04899v1)|null|
|**2025-01-08**|**Reach Measurement, Optimization and Frequency Capping In Targeted Online Advertising Under k-Anonymity**|Yuan Gao et.al.|[2501.04882v1](http://arxiv.org/abs/2501.04882v1)|null|
|**2025-01-08**|**Leveraging Log Probabilities in Language Models to Forecast Future Events**|Tommaso Soru et.al.|[2501.04880v1](http://arxiv.org/abs/2501.04880v1)|null|
|**2025-01-08**|**Real-Time Textless Dialogue Generation**|Long Mai et.al.|[2501.04877v1](http://arxiv.org/abs/2501.04877v1)|null|
|**2025-01-08**|**Back Home: A Machine Learning Approach to Seashell Classification and Ecosystem Restoration**|Alexander Valverde et.al.|[2501.04873v1](http://arxiv.org/abs/2501.04873v1)|null|
|**2025-01-08**|**Advancing Retrieval-Augmented Generation for Persian: Development of Language Models, Comprehensive Benchmarks, and Best Practices for Optimization**|Sara Bourbour Hosseinbeigi et.al.|[2501.04858v1](http://arxiv.org/abs/2501.04858v1)|null|
|**2025-01-08**|**Exploring Large Language Models for Semantic Analysis and Categorization of Android Malware**|Brandon J Walton et.al.|[2501.04848v1](http://arxiv.org/abs/2501.04848v1)|null|
|**2025-01-08**|**Enhancing Listened Speech Decoding from EEG via Parallel Phoneme Sequence Prediction**|Jihwan Lee et.al.|[2501.04844v1](http://arxiv.org/abs/2501.04844v1)|null|
|**2025-01-08**|**Do Code LLMs Understand Design Patterns?**|Zhenyu Pan et.al.|[2501.04835v1](http://arxiv.org/abs/2501.04835v1)|null|
|**2025-01-08**|**ActPC-Geom: Towards Scalable Online Neural-Symbolic Learning via Accelerating Active Predictive Coding with Information Geometry & Diverse Cognitive Mechanisms**|Ben Goertzel et.al.|[2501.04832v1](http://arxiv.org/abs/2501.04832v1)|null|
|**2025-01-08**|**Building Foundations for Natural Language Processing of Historical Turkish: Resources and Models**|Şaziye Betül Özateş et.al.|[2501.04828v1](http://arxiv.org/abs/2501.04828v1)|null|
|**2025-01-08**|**Intelligent Gradient Boosting Algorithms for Estimating Strength of Modified Subgrade Soil**|Ismail B. Mustapha et.al.|[2501.04826v1](http://arxiv.org/abs/2501.04826v1)|null|
|**2025-01-08**|**Unifying the Extremes: Developing a Unified Model for Detecting and Predicting Extremist Traits and Radicalization**|Allison Lahnala et.al.|[2501.04820v1](http://arxiv.org/abs/2501.04820v1)|null|
|**2025-01-08**|**Decentralised Resource Sharing in TinyML: Wireless Bilayer Gossip Parallel SGD for Collaborative Learning**|Ziyuan Bao et.al.|[2501.04817v1](http://arxiv.org/abs/2501.04817v1)|null|
|**2025-01-08**|**Reproducing HotFlip for Corpus Poisoning Attacks in Dense Retrieval**|Yongkang Li et.al.|[2501.04802v1](http://arxiv.org/abs/2501.04802v1)|[link](https://github.com/liyongkang123/hotflip_corpus_poisoning)|
|**2025-01-08**|**Cued Speech Generation Leveraging a Pre-trained Audiovisual Text-to-Speech Model**|Sanjana Sankar et.al.|[2501.04799v1](http://arxiv.org/abs/2501.04799v1)|null|
|**2025-01-08**|**Planarian Neural Networks: Evolutionary Patterns from Basic Bilateria Shaping Modern Artificial Neural Network Architectures**|Ziyuan Huang et.al.|[2501.04700v1](http://arxiv.org/abs/2501.04700v1)|null|
|**2025-01-08**|**Grokking at the Edge of Numerical Stability**|Lucas Prieto et.al.|[2501.04697v1](http://arxiv.org/abs/2501.04697v1)|[link](https://github.com/lucasprietoal/grokking-at-the-edge-of-numerical-stability)|
|**2025-01-08**|**EpiCoder: Encompassing Diversity and Complexity in Code Generation**|Yaoxiang Wang et.al.|[2501.04694v1](http://arxiv.org/abs/2501.04694v1)|null|
|**2025-01-08**|**Beyond Sight: Finetuning Generalist Robot Policies with Heterogeneous Sensors via Language Grounding**|Joshua Jones et.al.|[2501.04693v1](http://arxiv.org/abs/2501.04693v1)|null|
|**2025-01-08**|**URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics**|Ruilin Luo et.al.|[2501.04686v1](http://arxiv.org/abs/2501.04686v1)|null|
|**2025-01-08**|**Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought**|Violet Xiang et.al.|[2501.04682v1](http://arxiv.org/abs/2501.04682v1)|null|
|**2025-01-08**|**TREAD: Token Routing for Efficient Architecture-agnostic Diffusion Training**|Felix Krause et.al.|[2501.04765v1](http://arxiv.org/abs/2501.04765v1)|null|
|**2025-01-08**|**Enhancing Financial VQA in Vision Language Models using Intermediate Structured Representations**|Archita Srivastava et.al.|[2501.04675v1](http://arxiv.org/abs/2501.04675v1)|null|
|**2025-01-08**|**DRIVINGVQA: Analyzing Visual Chain-of-Thought Reasoning of Vision Language Models in Real-World Scenarios with Driving Theory Tests**|Charles Corbière et.al.|[2501.04671v1](http://arxiv.org/abs/2501.04671v1)|null|
|**2025-01-08**|**On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena**|Tarek Naous et.al.|[2501.04662v1](http://arxiv.org/abs/2501.04662v1)|null|
|**2025-01-08**|**Assessing Language Comprehension in Large Language Models Using Construction Grammar**|Wesley Scivetti et.al.|[2501.04661v1](http://arxiv.org/abs/2501.04661v1)|null|
|**2025-01-08**|**Multi-task retriever fine-tuning for domain-specific and efficient RAG**|Patrice Béchard et.al.|[2501.04652v1](http://arxiv.org/abs/2501.04652v1)|null|
|**2025-01-08**|**FlairGPT: Repurposing LLMs for Interior Designs**|Gabrielle Littlefair et.al.|[2501.04648v1](http://arxiv.org/abs/2501.04648v1)|null|
|**2025-01-08**|**Knowledge Retrieval Based on Generative AI**|Te-Lun Yang et.al.|[2501.04635v1](http://arxiv.org/abs/2501.04635v1)|null|

#### Abstracts
##### **ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding**
2501.05452v1 by Xingyu Fu, Minqian Liu, Zhengyuan Yang, John Corring, Yijuan Lu, Jianwei Yang, Dan Roth, Dinei Florencio, Cha Zhang

Structured image understanding, such as interpreting tables and charts,
requires strategically refocusing across various structures and texts within an
image, forming a reasoning sequence to arrive at the final answer. However,
current multimodal large language models (LLMs) lack this multihop selective
attention capability. In this work, we introduce ReFocus, a simple yet
effective framework that equips multimodal LLMs with the ability to generate
"visual thoughts" by performing visual editing on the input image through code,
shifting and refining their visual focuses. Specifically, ReFocus enables
multimodal LLMs to generate Python codes to call tools and modify the input
image, sequentially drawing boxes, highlighting sections, and masking out
areas, thereby enhancing the visual reasoning process. We experiment upon a
wide range of structured image understanding tasks involving tables and charts.
ReFocus largely improves performance on all tasks over GPT-4o without visual
editing, yielding an average gain of 11.0% on table tasks and 6.8% on chart
tasks. We present an in-depth analysis of the effects of different visual
edits, and reasons why ReFocus can improve the performance without introducing
additional information. Further, we collect a 14k training set using ReFocus,
and prove that such visual chain-of-thought with intermediate information
offers a better supervision than standard VQA data, reaching a 8.0% average
gain over the same model trained with QA pairs and 2.6% over CoT.

摘要：結構化影像理解，例如詮釋表格和圖表，需要在影像中的各種結構和文字中策略性地重新聚焦，形成推理序列才能得出最終答案。然而，目前的多模態大型語言模型 (LLM) 缺乏這種多跳選擇性注意力的能力。在這項工作中，我們引入了 ReFocus，一個簡單但有效的框架，它賦予多模態 LLM 透過程式碼對輸入影像進行視覺編輯、轉移和優化其視覺焦點的能力，以產生「視覺思考」。具體來說，ReFocus 能讓多模態 LLM 產生 Python 程式碼來呼叫工具並修改輸入影像，循序漸進地繪製方塊、重點標示區段，以及遮蔽區域，從而增強視覺推理過程。我們在涉及表格和圖表的各種結構化影像理解任務中進行實驗。ReFocus 大幅提升了 GPT-4o 在所有任務上的表現，在沒有視覺編輯的情況下，在表格任務上平均提升了 11.0%，在圖表任務上提升了 6.8%。我們對不同視覺編輯的效果進行了深入分析，並說明了 ReFocus 如何在不引入額外資訊的情況下提升表現的原因。此外，我們使用 ReFocus 收集了一個 14k 訓練集，並證明這種包含中間資訊的視覺思考鏈比標準的 VQA 資料提供了更好的監督，在使用 QA 對訓練的相同模型上平均提升了 8.0%，在 CoT 上提升了 2.6%。

##### **An Empirical Study of Autoregressive Pre-training from Videos**
2501.05453v1 by Jathushan Rajasegaran, Ilija Radosavovic, Rahul Ravishankar, Yossi Gandelsman, Christoph Feichtenhofer, Jitendra Malik

We empirically study autoregressive pre-training from videos. To perform our
study, we construct a series of autoregressive video models, called Toto. We
treat videos as sequences of visual tokens and train transformer models to
autoregressively predict future tokens. Our models are pre-trained on a diverse
dataset of videos and images comprising over 1 trillion visual tokens. We
explore different architectural, training, and inference design choices. We
evaluate the learned visual representations on a range of downstream tasks
including image recognition, video classification, object tracking, and
robotics. Our results demonstrate that, despite minimal inductive biases,
autoregressive pre-training leads to competitive performance across all
benchmarks. Finally, we find that scaling our video models results in similar
scaling curves to those seen in language models, albeit with a different rate.
More details at https://brjathu.github.io/toto/

摘要：我們實證研究影片的回歸前訓練。為了執行我們的研究，我們建構了一系列回歸影片模型，稱為 Toto。我們將影片視為視覺符號序列，並訓練Transformer模型以回歸預測未來符號。我們的模型在超過 1 兆個視覺符號的多元影片和影像資料集上進行預訓練。我們探索不同的架構、訓練和推論設計選項。我們在各種下游任務上評估學習到的視覺表徵，包括影像辨識、影片分類、物件追蹤和機器人技術。我們的結果證明，儘管歸納偏誤最少，回歸前訓練仍能讓所有基準測試的效能具有競爭力。最後，我們發現擴充我們的影片模型會產生與語言模型中看到的類似擴充曲線，儘管速率不同。更多詳情請參閱 https://brjathu.github.io/toto/

##### **Consistent Flow Distillation for Text-to-3D Generation**
2501.05445v1 by Runjie Yan, Yinbo Chen, Xiaolong Wang

Score Distillation Sampling (SDS) has made significant strides in distilling
image-generative models for 3D generation. However, its
maximum-likelihood-seeking behavior often leads to degraded visual quality and
diversity, limiting its effectiveness in 3D applications. In this work, we
propose Consistent Flow Distillation (CFD), which addresses these limitations.
We begin by leveraging the gradient of the diffusion ODE or SDE sampling
process to guide the 3D generation. From the gradient-based sampling
perspective, we find that the consistency of 2D image flows across different
viewpoints is important for high-quality 3D generation. To achieve this, we
introduce multi-view consistent Gaussian noise on the 3D object, which can be
rendered from various viewpoints to compute the flow gradient. Our experiments
demonstrate that CFD, through consistent flows, significantly outperforms
previous methods in text-to-3D generation.

摘要：分數蒸餾採樣 (SDS) 在蒸餾用於 3D 生成的影像生成模型方面取得了重大進展。然而，它尋求最大似然的行为通常會導致視覺品質和多樣性降低，限制了它在 3D 應用中的效能。在這項工作中，我們提出了一致流蒸餾 (CFD)，來解決這些限制。我們首先利用擴散 ODE 或 SDE 採樣程序的梯度來引導 3D 生成。從基於梯度的採樣觀點來看，我們發現不同視角的 2D 影像流的一致性對於高品質的 3D 生成非常重要。為了達成此目的，我們在 3D 物件上引入了多視圖一致的高斯雜訊，可以從各種視角渲染它來計算流梯度。我們的實驗證明，CFD 透過一致的流，在文字轉 3D 生成中顯著優於先前的各種方法。

##### **A survey of textual cyber abuse detection using cutting-edge language models and large language models**
2501.05443v1 by Jose A. Diaz-Garcia, Joao Paulo Carvalho

The success of social media platforms has facilitated the emergence of
various forms of online abuse within digital communities. This abuse manifests
in multiple ways, including hate speech, cyberbullying, emotional abuse,
grooming, and sexting. In this paper, we present a comprehensive analysis of
the different forms of abuse prevalent in social media, with a particular focus
on how emerging technologies, such as Language Models (LMs) and Large Language
Models (LLMs), are reshaping both the detection and generation of abusive
content within these networks. We delve into the mechanisms through which
social media abuse is perpetuated, exploring the psychological and social
impact. Additionally, we examine the dual role of advanced language
models-highlighting their potential to enhance automated detection systems for
abusive behavior while also acknowledging their capacity to generate harmful
content. This paper aims to contribute to the ongoing discourse on online
safety and ethics, offering insights into the evolving landscape of cyberabuse
and the technological innovations that both mitigate and exacerbate it.

摘要：社群媒體平台的成功促成了數位社群中各種形式網路霸凌的出現。這種霸凌以多種方式表現，包括仇恨言論、網路霸凌、情緒虐待、誘騙和性簡訊。在本文中，我們對社群媒體中普遍存在的不同形式的霸凌進行了全面的分析，特別關注了新興技術（例如語言模型 (LM) 和大型語言模型 (LLM)）如何重新塑造這些網路中攻擊性內容的偵測和產生。我們深入探討了社群媒體霸凌持續存在的方式，探討了心理和社會影響。此外，我們探討了進階語言模型的雙重角色，強調了它們增強自動偵測系統以偵測攻擊性行為的潛力，同時也承認它們產生有害內容的能力。本文旨在為網路安全和道德的持續討論做出貢獻，提供對網路霸凌演變態勢的見解，以及減輕和加劇網路霸凌的技術創新。

##### **Progressive Growing of Video Tokenizers for Highly Compressed Latent Spaces**
2501.05442v1 by Aniruddha Mahapatra, Long Mai, Yitian Zhang, David Bourgin, Feng Liu

Video tokenizers are essential for latent video diffusion models, converting
raw video data into spatiotemporally compressed latent spaces for efficient
training. However, extending state-of-the-art video tokenizers to achieve a
temporal compression ratio beyond 4x without increasing channel capacity poses
significant challenges. In this work, we propose an alternative approach to
enhance temporal compression. We find that the reconstruction quality of
temporally subsampled videos from a low-compression encoder surpasses that of
high-compression encoders applied to original videos. This indicates that
high-compression models can leverage representations from lower-compression
models. Building on this insight, we develop a bootstrapped
high-temporal-compression model that progressively trains high-compression
blocks atop well-trained lower-compression models. Our method includes a
cross-level feature-mixing module to retain information from the pretrained
low-compression model and guide higher-compression blocks to capture the
remaining details from the full video sequence. Evaluation of video benchmarks
shows that our method significantly improves reconstruction quality while
increasing temporal compression compared to direct extensions of existing video
tokenizers. Furthermore, the resulting compact latent space effectively trains
a video diffusion model for high-quality video generation with a reduced token
budget.

摘要：影片分词器对于潜影片扩散模型至关重要，它将影片原始资料转换为时空压缩潜空间，以利于有效率的训练。然而，将最先进的影片分词器延伸到在不增加通道容量的情况下，实现超过 4 倍的时间压缩比，会带来重大的挑战。在这项研究中，我们提出了一种增强时间压缩的替代方法。我们发现，低压缩编码器中时间子采样的影片的重建质量，胜过应用于原始影片的高压缩编码器。这表示高压缩模型可以利用低压缩模型的表示。基于此见解，我们开发了一个自举高时间压缩模型，它在训练良好的低压缩模型之上，逐步训练高压缩区块。我们的方法包含了一个跨层级特征混合模块，以保留预先训练的低压缩模型中的信息，并引导更高的压缩区块捕捉完整影片序列中剩余的细节。影片基准的评估显示，我们的方法大幅改善了重建质量，同时与现有影片分词器的直接延伸相比，增加了时间压缩。此外，产生的紧凑潜空间有效地训练了一个影片扩散模型，用于高质量影片生成，同时减少了标记预算。

##### **LongProc: Benchmarking Long-Context Language Models on Long Procedural Generation**
2501.05414v1 by Xi Ye, Fangcong Yin, Yinghui He, Joie Zhang, Howard Yen, Tianyu Gao, Greg Durrett, Danqi Chen

Existing benchmarks for evaluating long-context language models (LCLMs)
primarily focus on long-context recall, requiring models to produce short
responses based on a few critical snippets while processing thousands of
irrelevant tokens. We introduce LongProc (Long Procedural Generation), a new
benchmark that requires both the integration of highly dispersed information
and long-form generation. LongProc consists of six diverse procedural
generation tasks, such as extracting structured information from HTML pages
into a TSV format and executing complex search procedures to create travel
plans. These tasks challenge LCLMs by testing their ability to follow detailed
procedural instructions, synthesize and reason over dispersed information, and
generate structured, long-form outputs (up to 8K tokens). Furthermore, as these
tasks adhere to deterministic procedures and yield structured outputs, they
enable reliable rule-based evaluation. We evaluate 17 LCLMs on LongProc across
three difficulty levels, with maximum numbers of output tokens set at 500, 2K,
and 8K. Notably, while all tested models claim a context window size above 32K
tokens, open-weight models typically falter on 2K-token tasks, and
closed-source models like GPT-4o show significant degradation on 8K-token
tasks. Further analysis reveals that LCLMs struggle to maintain long-range
coherence in long-form generations. These findings highlight critical
limitations in current LCLMs and suggest substantial room for improvement. Data
and code available at: https://princeton-pli.github.io/LongProc

摘要：現有的用於評估長語境語言模型 (LCLM) 的基準主要集中在長語境召回上，要求模型根據幾個關鍵片段產生簡短的回應，同時處理數千個不相關的符號。我們引入了 LongProc（長程序生成），這是一個新的基準，它需要高度分散的資訊整合和長格式生成。LongProc 包含六項不同的程序生成任務，例如將結構化資訊從 HTML 頁面提取到 TSV 格式，以及執行複雜的搜尋程序來建立旅遊計畫。這些任務透過測試 LCLM 遵循詳細程序說明、綜合和推理分散資訊以及生成結構化、長格式輸出（最多 8K 個符號）的能力，對其提出挑戰。此外，由於這些任務遵循確定性的程序並產生結構化的輸出，因此它們能進行可靠的基於規則的評估。我們在三個難度等級上對 17 個 LCLM 進行 LongProc 評估，將輸出符號的最大數量設定為 500、2K 和 8K。值得注意的是，雖然所有測試的模型都宣稱其語境窗口大小超過 32K 個符號，但開放權重模型通常在 2K 符號任務中失敗，而像 GPT-4o 這樣的閉源模型在 8K 符號任務中表現出顯著下降。進一步的分析表明，LCLM 難以在長格式生成中維持長程相干性。這些發現突顯了當前 LCLM 的關鍵限制，並表明有很大的改進空間。資料和程式碼可於以下網址取得：https://princeton-pli.github.io/LongProc

##### **A Novel Pathology Foundation Model by Mayo Clinic, Charité, and Aignostics**
2501.05409v1 by Maximilian Alber, Stephan Tietz, Jonas Dippel, Timo Milbich, Timothée Lesort, Panos Korfiatis, Moritz Krügener, Beatriz Perez Cancer, Neelay Shah, Alexander Möllers, Philipp Seegerer, Alexandra Carpen-Amarie, Kai Standvoss, Gabriel Dernbach, Edwin de Jong, Simon Schallenberg, Andreas Kunft, Helmut Hoffer von Ankershoffen, Gavin Schaeferle, Patrick Duffy, Matt Redlon, Philipp Jurmeister, David Horst, Lukas Ruff, Klaus-Robert Müller, Frederick Klauschen, Andrew Norgan

Recent advances in digital pathology have demonstrated the effectiveness of
foundation models across diverse applications. In this report, we present a
novel vision foundation model based on the RudolfV approach. Our model was
trained on a dataset comprising 1.2 million histopathology whole slide images,
collected from two medical institutions: Mayo Clinic and Charit\'e -
Universt\"atsmedizin Berlin. Comprehensive evaluations show that our model
achieves state-of-the-art performance across twenty-one public benchmark
datasets, even though it is neither the largest model by parameter count nor by
training dataset size.

摘要：最近在數位病理學的進展已展示出基礎模型在各種應用中的有效性。在此報告中，我們提出一個基於 RudolfV 方法的新穎視覺基礎模型。我們的模型是在一個包含 120 萬張組織病理學全切片影像的資料集上訓練，這些影像來自兩個醫療機構：梅約診所和夏里特大學醫學中心。全面的評估顯示，我們的模型在 21 個公開基準資料集上達到了最先進的效能，儘管它既不是參數計數最大的模型，也不是訓練資料集規模最大的模型。

##### **TimeRL: Efficient Deep Reinforcement Learning with Polyhedral Dependence Graphs**
2501.05408v1 by Pedro F. Silvestre, Peter Pietzuch

Modern deep learning (DL) workloads increasingly use complex deep
reinforcement learning (DRL) algorithms that generate training data within the
learning loop. This results in programs with several nested loops and dynamic
data dependencies between tensors. While DL systems with eager execution
support such dynamism, they lack the optimizations and smart scheduling of
graph-based execution. Graph-based execution, however, cannot express dynamic
tensor shapes, instead requiring the use of multiple static subgraphs. Either
execution model for DRL thus leads to redundant computation, reduced
parallelism, and less efficient memory management.
  We describe TimeRL, a system for executing dynamic DRL programs that combines
the dynamism of eager execution with the whole-program optimizations and
scheduling of graph-based execution. TimeRL achieves this by introducing the
declarative programming model of recurrent tensors, which allows users to
define dynamic dependencies as intuitive recurrence equations. TimeRL
translates recurrent tensors into a polyhedral dependence graph (PDG) with
dynamic dependencies as symbolic expressions. Through simple PDG
transformations, TimeRL applies whole-program optimizations, such as automatic
vectorization, incrementalization, and operator fusion. The PDG also allows for
the computation of an efficient program-wide execution schedule, which decides
on buffer deallocations, buffer donations, and GPU/CPU memory swapping. We show
that TimeRL executes current DRL algorithms up to 47$\times$ faster than
existing DRL systems, while using 16$\times$ less GPU peak memory.

摘要：現代深度學習 (DL) 工作負載日益使用複雜的深度強化學習 (DRL) 演算法，在學習迴圈中產生訓練資料。這會產生具有多個巢狀迴圈和張量之間動態資料相依性的程式。雖然具有熱切執行功能的 DL 系統支援這種動態性，但它們缺乏圖形化執行最佳化和智慧化排程。然而，圖形化執行無法表達動態張量形狀，反而需要使用多個靜態子圖形。因此，DRL 的任一執行模型都會導致重複運算、降低並行度和記憶體管理效率不彰。
我們描述 TimeRL，這是一個用於執行動態 DRL 程式的系統，它結合了熱切執行的動態性與圖形化執行的全程式最佳化和排程。TimeRL 透過引入遞迴張量的宣告式程式設計模型來達成此一目標，使用戶能夠將動態相依性定義為直覺的遞迴方程式。TimeRL 將遞迴張量轉換為具有動態相依性（作為符號表達式）的多面體相依圖形 (PDG)。透過簡單的 PDG 轉換，TimeRL 套用全程式最佳化，例如自動向量化、遞增化和運算子融合。PDG 也允許計算出有效的全程式執行排程，決定緩衝區取消配置、緩衝區捐贈和 GPU/CPU 記憶體交換。我們顯示 TimeRL 執行目前的 DRL 演算法速度比現有的 DRL 系統快達 47 倍，同時使用少 16 倍的 GPU 峰值記憶體。

##### **TimeDP: Learning to Generate Multi-Domain Time Series with Domain Prompts**
2501.05403v1 by Yu-Hao Huang, Chang Xu, Yueying Wu, Wu-Jun Li, Jiang Bian

Time series generation models are crucial for applications like data
augmentation and privacy preservation. Most existing time series generation
models are typically designed to generate data from one specified domain. While
leveraging data from other domain for better generalization is proved to work
in other application areas, this approach remains challenging for time series
modeling due to the large divergence in patterns among different real world
time series categories. In this paper, we propose a multi-domain time series
diffusion model with domain prompts, named TimeDP. In TimeDP, we utilize a time
series semantic prototype module which defines time series prototypes to
represent time series basis, each prototype vector serving as "word"
representing some elementary time series feature. A prototype assignment module
is applied to extract the extract domain specific prototype weights, for
learning domain prompts as generation condition. During sampling, we extract
"domain prompt" with few-shot samples from the target domain and use the domain
prompts as condition to generate time series samples. Experiments demonstrate
that our method outperforms baselines to provide the state-of-the-art in-domain
generation quality and strong unseen domain generation capability.

摘要：時間序列生成模型對於資料擴充和隱私保護等應用至關重要。現有的時間序列生成模型通常設計用於從一個指定領域生成資料。雖然利用其他領域的資料以獲得更好的泛化能力被證明在其他應用領域有效，但這種方法對於時間序列建模來說仍然具有挑戰性，因為不同現實世界時間序列類別之間的模式差異很大。在本文中，我們提出了一個帶有領域提示的多領域時間序列擴散模型，名為 TimeDP。在 TimeDP 中，我們利用了一個時間序列語義原型模組，它定義了時間序列原型以表示時間序列基礎，每個原型向量作為「詞彙」表示一些基本的時間序列特徵。應用原型分配模組來提取提取領域特定的原型權重，以學習領域提示作為生成條件。在採樣過程中，我們從目標領域中提取少數樣本的「領域提示」，並使用領域提示作為條件來生成時間序列樣本。實驗表明，我們的方法優於基準，在領域內生成品質和強大的未知領域生成能力方面提供最先進的技術。

##### **BRATI: Bidirectional Recurrent Attention for Time-Series Imputation**
2501.05401v1 by Armando Collado-Villaverde, Pablo Muñoz, Maria D. R-Moreno

Missing data in time-series analysis poses significant challenges, affecting
the reliability of downstream applications. Imputation, the process of
estimating missing values, has emerged as a key solution. This paper introduces
BRATI, a novel deep-learning model designed to address multivariate time-series
imputation by combining Bidirectional Recurrent Networks and Attention
mechanisms. BRATI processes temporal dependencies and feature correlations
across long and short time horizons, utilizing two imputation blocks that
operate in opposite temporal directions. Each block integrates recurrent layers
and attention mechanisms to effectively resolve long-term dependencies.
  We evaluate BRATI on three real-world datasets under diverse missing-data
scenarios: randomly missing values, fixed-length missing sequences, and
variable-length missing sequences. Our findings demonstrate that BRATI
consistently outperforms state-of-the-art models, delivering superior accuracy
and robustness in imputing multivariate time-series data.

摘要：時序分析中遺失的資料會造成重大的挑戰，影響下游應用程式的可靠性。估計遺失值這個過程稱為內插，已成為一項關鍵的解決方案。本文介紹 BRATI，這是一種新穎的深度學習模型，旨在透過結合雙向遞迴網路和注意力機制來解決多變量時序內插。BRATI 處理跨長短時間範圍的時間依賴性和特徵相關性，利用兩個以相反時間方向運作的內插區塊。每個區塊整合遞迴層和注意力機制，以有效解決長期依賴性。我們在三組真實世界資料集上評估 BRATI，這些資料集具有多樣化的遺失資料情境：隨機遺失值、固定長度遺失序列和變動長度遺失序列。我們的研究結果顯示，BRATI 在內插多變量時序資料方面始終優於現有技術模型，提供更佳的準確性和穩健性。

##### **Mechanistic understanding and validation of large AI models with SemanticLens**
2501.05398v1 by Maximilian Dreyer, Jim Berend, Tobias Labarta, Johanna Vielhaben, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek

Unlike human-engineered systems such as aeroplanes, where each component's
role and dependencies are well understood, the inner workings of AI models
remain largely opaque, hindering verifiability and undermining trust. This
paper introduces SemanticLens, a universal explanation method for neural
networks that maps hidden knowledge encoded by components (e.g., individual
neurons) into the semantically structured, multimodal space of a foundation
model such as CLIP. In this space, unique operations become possible, including
(i) textual search to identify neurons encoding specific concepts, (ii)
systematic analysis and comparison of model representations, (iii) automated
labelling of neurons and explanation of their functional roles, and (iv) audits
to validate decision-making against requirements. Fully scalable and operating
without human input, SemanticLens is shown to be effective for debugging and
validation, summarizing model knowledge, aligning reasoning with expectations
(e.g., adherence to the ABCDE-rule in melanoma classification), and detecting
components tied to spurious correlations and their associated training data. By
enabling component-level understanding and validation, the proposed approach
helps bridge the "trust gap" between AI models and traditional engineered
systems. We provide code for SemanticLens on
https://github.com/jim-berend/semanticlens and a demo on
https://semanticlens.hhi-research-insights.eu.

摘要：與飛機等由人類設計的系統不同，飛機每個組件的角色和依賴性都清楚明瞭，而 AI 模型的內部運作在很大程度上仍不透明，這阻礙了可驗證性並破壞了信任。本文介紹了 SemanticLens，這是一種針對神經網路的通用解釋方法，它將組件（例如個別神經元）編碼的隱藏知識映射到基礎模型（例如 CLIP）的語義結構化多模態空間中。在這個空間中，可以進行獨特的操作，包括 (i) 文字搜尋以識別編碼特定概念的神經元，(ii) 系統分析和比較模型表示，(iii) 自動標記神經元並解釋其功能角色，以及 (iv) 稽核以驗證決策制定是否符合要求。SemanticLens 完全可擴展且在沒有人工輸入的情況下運行，已證明其在除錯和驗證、總結模型知識、將推理與期望保持一致（例如，遵守黑色素瘤分類中的 ABCDE 規則）以及檢測與虛假相關性和其關聯訓練資料相關的組件方面是有效的。通過實現組件級別的理解和驗證，所提出的方法有助於彌合 AI 模型與傳統工程系統之間的「信任差距」。我們在 https://github.com/jim-berend/semanticlens 上提供了 SemanticLens 的程式碼，並在 https://semanticlens.hhi-research-insights.eu 上提供了示範。

##### **FairCode: Evaluating Social Bias of LLMs in Code Generation**
2501.05396v1 by Yongkang Du, Jen-tse Huang, Jieyu Zhao, Lu Lin

Large language models (LLMs) have demonstrated significant capability in code
generation, drawing increasing attention to the evaluation of the quality and
safety of their outputs. However, research on bias in code generation remains
limited. Existing studies typically assess bias by applying malicious prompts
or reapply tasks and dataset for discriminative models. Given that LLMs are
often aligned with human values and that prior datasets are not fully optimized
for code-related tasks, there is a pressing need for benchmarks specifically
designed for evaluating code models. In this study, we introduce FairCode, a
novel benchmark for evaluating bias in code generation. FairCode comprises two
tasks: function implementation and test case generation, each evaluating social
bias through diverse scenarios. Additionally, we propose a new metric,
FairScore, to assess model performance on this benchmark. We conduct
experiments on widely used LLMs and provide a comprehensive analysis of the
results. The findings reveal that all tested LLMs exhibit bias. The code is
available at https://github.com/YongkDu/FairCode.

摘要：大型語言模型 (LLM) 已展現出生成程式碼的顯著能力，並越來越關注其輸出的品質和安全性評估。然而，關於程式碼生成偏差的研究仍然有限。現有研究通常透過套用惡意提示或重新套用任務和資料集來評估偏差，以進行區辨模型。鑑於 LLM 通常與人類價值觀一致，且先前的資料集並未針對程式碼相關任務進行完全最佳化，因此迫切需要專門用於評估程式碼模型的基準。在此研究中，我們介紹了 FairCode，這是一個用於評估程式碼生成偏差的新基準。FairCode 包含兩個任務：函式實作和測試案例生成，每個任務都透過不同的場景評估社會偏差。此外，我們提出了一個新的指標 FairScore，用於評估模型在此基準上的效能。我們對廣泛使用的 LLM 進行實驗，並對結果進行全面分析。研究結果顯示，所有受測的 LLM 都表現出偏差。程式碼可在 https://github.com/YongkDu/FairCode 取得。

##### **Large Physics Models: Towards a collaborative approach with Large Language Models and Foundation Models**
2501.05382v1 by Kristian G. Barman, Sascha Caron, Emily Sullivan, Henk W. de Regt, Roberto Ruiz de Austri, Mieke Boon, Michael Färber, Stefan Fröse, Faegheh Hasibi, Andreas Ipp, Rukshak Kapoor, Gregor Kasieczka, Daniel Kostić, Michael Krämer, Tobias Golling, Luis G. Lopez, Jesus Marco, Sydney Otten, Pawel Pawlowski, Pietro Vischia, Erik Weber, Christoph Weniger

This paper explores ideas and provides a potential roadmap for the
development and evaluation of physics-specific large-scale AI models, which we
call Large Physics Models (LPMs). These models, based on foundation models such
as Large Language Models (LLMs) - trained on broad data - are tailored to
address the demands of physics research. LPMs can function independently or as
part of an integrated framework. This framework can incorporate specialized
tools, including symbolic reasoning modules for mathematical manipulations,
frameworks to analyse specific experimental and simulated data, and mechanisms
for synthesizing theories and scientific literature. We begin by examining
whether the physics community should actively develop and refine dedicated
models, rather than relying solely on commercial LLMs. We then outline how LPMs
can be realized through interdisciplinary collaboration among experts in
physics, computer science, and philosophy of science. To integrate these models
effectively, we identify three key pillars: Development, Evaluation, and
Philosophical Reflection. Development focuses on constructing models capable of
processing physics texts, mathematical formulations, and diverse physical data.
Evaluation assesses accuracy and reliability by testing and benchmarking.
Finally, Philosophical Reflection encompasses the analysis of broader
implications of LLMs in physics, including their potential to generate new
scientific understanding and what novel collaboration dynamics might arise in
research. Inspired by the organizational structure of experimental
collaborations in particle physics, we propose a similarly interdisciplinary
and collaborative approach to building and refining Large Physics Models. This
roadmap provides specific objectives, defines pathways to achieve them, and
identifies challenges that must be addressed to realise physics-specific large
scale AI models.

摘要：本文探討想法，並為物理特定的大規模 AI 模型（我們稱之為大型物理模型，LPM）的開發和評估提供潛在的路線圖。這些模型基於大型語言模型（LLM）等基礎模型，使用廣泛的數據進行訓練，並專門針對物理研究的需求進行調整。LPM 可以獨立運行，或作為整合架構的一部分。此架構可以整合專用工具，包括用於數學運算的符號推理模組、用於分析特定實驗和模擬數據的架構，以及用於綜合理論和科學文獻的機制。我們首先探討物理界是否應該積極開發和改進專用模型，而不是僅依賴商業 LLM。然後，我們概述如何透過物理學、電腦科學和科學哲學方面的專家之間的跨領域合作來實現 LPM。為了有效整合這些模型，我們找出三個關鍵支柱：開發、評估和哲學反思。開發的重點在於建構能夠處理物理文本、數學公式和各種物理數據的模型。評估透過測試和基準測試來評估準確性和可靠性。最後，哲學反思包含分析 LLM 在物理學中更廣泛的影響，包括它們產生新的科學理解的潛力，以及在研究中可能出現什麼新的合作動態。受到粒子物理學中實驗合作的組織結構啟發，我們提出一個類似跨領域和合作的方法來建構和改進大型物理模型。此路線圖提供了具體目標，定義了達成目標的途徑，並找出實現物理特定的大規模 AI 模型時必須解決的挑戰。

##### **Developing a Foundation of Vector Symbolic Architectures Using Category Theory**
2501.05368v1 by Nolan P Shaw, P Michael Furlong, Britt Anderson, Jeff Orchard

At the risk of overstating the case, connectionist approaches to machine
learning, i.e. neural networks, are enjoying a small vogue right now. However,
these methods require large volumes of data and produce models that are
uninterpretable to humans. An alternative framework that is compatible with
neural networks and gradient-based learning, but explicitly models
compositionality, is Vector Symbolic Architectures (VSAs). VSAs are a family of
algebras on high-dimensional vector representations. They arose in cognitive
science from the need to unify neural processing and the kind of symbolic
reasoning that humans perform. While machine learning methods have benefited
from category theoretical analyses, VSAs have not yet received similar
treatment. In this paper, we present a first attempt at applying category
theory to VSAs. Specifically, we conduct a brief literature survey
demonstrating the lacking intersection of these two topics, provide a list of
desiderata for VSAs, and propose that VSAs may be understood as a (division)
rig in a category enriched over a monoid in Met (the category of Lawvere metric
spaces). This final contribution suggests that VSAs may be generalised beyond
current implementations. It is our hope that grounding VSAs in category theory
will lead to more rigorous connections with other research, both within and
beyond, learning and cognition.

摘要：<paragraph>即使誇大其詞，聯結主義方法對機器學習來說，也就是神經網路，目前正盛行著。然而，這些方法需要大量的資料，並產生人類無法理解的模型。一種與神經網路和基於梯度的學習相容，但明確建構組合性的替代架構，是向量符號架構 (VSA)。VSA 是一組關於高維度向量表示的代數。它們源於認知科學，目的是統一神經處理和人類執行的符號推理。雖然機器學習方法受益於範疇理論分析，但 VSA 尚未獲得類似的處理。在本文中，我們首次嘗試將範疇理論應用於 VSA。具體來說，我們進行了一項簡短的文獻調查，說明這兩個主題缺乏交集，提供了 VSA 的理想清單，並提出 VSA 可以理解為一個 (除法) 範疇中的 rig，該範疇豐富於 Met 中的單元 (Lawvere 度量空間的範疇)。這個最終貢獻表明 VSA 可以概括到目前的實作之外。我們希望將 VSA 基於範疇理論將有助於與其他研究建立更嚴謹的連結，無論是在學習和認知的範疇內或外。</paragraph>

##### **Search-o1: Agentic Search-Enhanced Large Reasoning Models**
2501.05366v1 by Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, Zhicheng Dou

Large reasoning models (LRMs) like OpenAI-o1 have demonstrated impressive
long stepwise reasoning capabilities through large-scale reinforcement
learning. However, their extended reasoning processes often suffer from
knowledge insufficiency, leading to frequent uncertainties and potential
errors. To address this limitation, we introduce \textbf{Search-o1}, a
framework that enhances LRMs with an agentic retrieval-augmented generation
(RAG) mechanism and a Reason-in-Documents module for refining retrieved
documents. Search-o1 integrates an agentic search workflow into the reasoning
process, enabling dynamic retrieval of external knowledge when LRMs encounter
uncertain knowledge points. Additionally, due to the verbose nature of
retrieved documents, we design a separate Reason-in-Documents module to deeply
analyze the retrieved information before injecting it into the reasoning chain,
minimizing noise and preserving coherent reasoning flow. Extensive experiments
on complex reasoning tasks in science, mathematics, and coding, as well as six
open-domain QA benchmarks, demonstrate the strong performance of Search-o1.
This approach enhances the trustworthiness and applicability of LRMs in complex
reasoning tasks, paving the way for more reliable and versatile intelligent
systems. The code is available at
\url{https://github.com/sunnynexus/Search-o1}.

摘要：大型推理模型（LRM），例如 OpenAI-o1，已通过大规模强化学习展示了令人印象深刻的长步推理能力。然而，它们扩展的推理过程通常会受到知识不足的影响，从而导致频繁的不确定性和潜在的错误。为了解决这个限制，我们引入了 \textbf{Search-o1}，这是一个框架，它通过代理检索增强生成（RAG）机制和用于精炼检索到的文档的文档中推理模块来增强 LRM。Search-o1 将代理搜索工作流集成到推理过程中，使 LRM 在遇到不确定的知识点时能够动态检索外部知识。此外，由于检索到的文档冗长，我们设计了一个单独的文档中推理模块，以便在将检索到的信息注入推理链之前对其进行深入分析，最大程度地减少噪音并保持连贯的推理流程。在科学、数学和编码中的复杂推理任务以及六个开放域 QA 基准上的大量实验表明了 Search-o1 的强大性能。这种方法增强了 LRM 在复杂推理任务中的可信度和适用性，为更可靠和通用的智能系统铺平了道路。代码可在 \url{https://github.com/sunnynexus/Search-o1} 获得。

##### **On Corrigibility and Alignment in Multi Agent Games**
2501.05360v1 by Edmund Dable-Heath, Boyko Vodenicharski, James Bishop

Corrigibility of autonomous agents is an under explored part of system
design, with previous work focusing on single agent systems. It has been
suggested that uncertainty over the human preferences acts to keep the agents
corrigible, even in the face of human irrationality. We present a general
framework for modelling corrigibility in a multi-agent setting as a 2 player
game in which the agents always have a move in which they can ask the human for
supervision. This is formulated as a Bayesian game for the purpose of
introducing uncertainty over the human beliefs. We further analyse two specific
cases. First, a two player corrigibility game, in which we want corrigibility
displayed in both agents for both common payoff (monotone) games and harmonic
games. Then we investigate an adversary setting, in which one agent is
considered to be a `defending' agent and the other an `adversary'. A general
result is provided for what belief over the games and human rationality the
defending agent is required to have to induce corrigibility.

摘要：自主代理的可修正性是系统设计中尚未探索的部分，以前的工作重点放在单代理系统上。有人提出，对人类偏好的不确定性有助于保持代理的可修正性，即使面对人类的不理性。我们提出了一个通用的框架，用于在多代理环境中对可修正性进行建模，作为一种 2 人游戏，其中代理始终可以采取行动，要求人类进行监督。这被表述为贝叶斯博弈，目的是引入对人类信念的不确定性。我们进一步分析了两个具体案例。首先，一个双人可修正性游戏，我们希望在共同收益（单调）游戏和协调游戏中显示两个代理的可修正性。然后，我们调查了一个对抗环境，其中一个代理被认为是“防御”代理，另一个代理被认为是“对抗”代理。提供了一个一般结果，说明防御代理需要对游戏和人类理性的信念是什么，才能诱导可修正性。

##### **Stream Aligner: Efficient Sentence-Level Alignment via Distribution Induction**
2501.05336v1 by Hantao Lou, Jiaming Ji, Kaile Wang, Yaodong Yang

The rapid advancement of large language models (LLMs) has led to significant
improvements in their capabilities, but also to increased concerns about their
alignment with human values and intentions. Current alignment strategies,
including adaptive training and inference-time methods, have demonstrated
potential in this area. However, these approaches still struggle to balance
deployment complexity and capability across various tasks and difficulties. In
this work, we introduce the Streaming Distribution Induce Aligner (Stream
Aligner), a novel alignment paradigm that combines efficiency with enhanced
performance in various tasks throughout the generation process. Stream Aligner
achieves dynamic sentence-level correction by using a small model to learn the
preferences of the suffix sentence, iteratively correcting the suffix sentence
output by the upstream model, and then using the corrected sentence to replace
the suffix sentence in subsequent generations. Compared to Aligner, our
experiments demonstrate that Stream Aligner reduces reliance on the
capabilities of additional models, enhances the reasoning abilities of LLMs,
and decreases latency during user interaction. Specifically, Stream Aligner-2B
model has achieved an improvement of 76.1% in helpfulness, 36.0% in
harmlessness on the tested Llama2-70B-chat model, and Stream Aligner-8B has
achieved an improvement of 3.5% on the math ability of the tested
Llama3-70B-Instruct model.

摘要：大型語言模型 (LLM) 的快速進展已顯著提升其能力，但也引發更多關於其與人類價值觀和意圖一致性的疑慮。目前的對齊策略，包括適應性訓練和推論時間方法，已在此領域展現潛力。然而，這些方法仍難以在各種任務和難度中取得部署複雜度和能力的平衡。在本文中，我們介紹了串流分佈誘導對齊器 (Stream Aligner)，這是一種新穎的對齊範例，結合了效率與在整個生成過程中各種任務中增強的效能。Stream Aligner 透過使用小型模型來學習後綴句子的偏好，反覆修正上游模型輸出的後綴句子，然後使用修正過的句子取代後續生成中的後綴句子，進而達成動態的句子層級修正。與 Aligner 相比，我們的實驗證明 Stream Aligner 減少了對其他模型能力的依賴，增強了 LLM 的推理能力，並降低了使用者互動期間的延遲。具體而言，Stream Aligner-2B 模型在有益性方面提升了 76.1%，在無害性方面提升了 36.0%，在測試的 Llama2-70B-chat 模型上，而 Stream Aligner-8B 則在測試的 Llama3-70B-Instruct 模型的數學能力方面提升了 3.5%。

##### **The Bakers and Millers Game with Restricted Locations**
2501.05334v1 by Simon Krogmann, Pascal Lenzner, Alexander Skopalik

We study strategic location choice by customers and sellers, termed the
Bakers and Millers Game in the literature. In our generalized setting, each
miller can freely choose any location for setting up a mill, while each baker
is restricted in the choice of location for setting up a bakery. For optimal
bargaining power, a baker would like to select a location with many millers to
buy flour from and with little competition from other bakers. Likewise, a
miller aims for a location with many bakers and few competing millers. Thus,
both types of agents choose locations to optimize the ratio of agents of
opposite type divided by agents of the same type at their chosen location.
Originally raised in the context of Fractional Hedonic Games, the Bakers and
Millers Game has applications that range from commerce to product design.
  We study the impact of location restrictions on the properties of the game.
While pure Nash equilibria trivially exist in the setting without location
restrictions, we show via a sophisticated, efficient algorithm that even the
more challenging restricted setting admits equilibria. Moreover, the computed
equilibrium approximates the optimal social welfare by a factor of at most
$2\left(\frac{e}{e-1}\right)$. Furthermore, we give tight bounds on the price
of anarchy/stability.
  On the conceptual side, the location choice feature adds a new layer to the
standard setting of Hedonic Games, in the sense that agents that select the
same location form a coalition. This allows to naturally restrict the possible
coalitions that can be formed. With this, our model generalizes simple
symmetric Fractional Hedonic Games on complete bipartite valuation graphs and
also Hedonic Diversity Games with utilities single-peaked at 0. We believe that
this generalization is also a very interesting direction for other types of
Hedonic Games.

摘要：<paragraph>我們研究由客戶和賣方進行的策略性位置選擇，在文獻中稱為麵包師和磨坊主的遊戲。在我們概括的設定中，每個磨坊主可以自由選擇任何位置來設置磨坊，而每個麵包師在選擇設置麵包店的時受到地點限制。為了獲得最佳的議價能力，麵包師希望選擇一個有許多磨坊主可以購買麵粉且與其他麵包師競爭較少的地點。同樣地，磨坊主會選擇一個有許多麵包師且競爭對手較少的磨坊主的地點。因此，這兩種類型的代理人都會選擇地點來優化在他們所選擇的地點，相反類型的代理人與相同類型的代理人的比例。最初在分數享樂遊戲的背景下提出，麵包師和磨坊主的遊戲有從商業到產品設計的廣泛應用。我們研究地點限制對遊戲屬性的影響。雖然在沒有地點限制的設定中，純納許均衡顯然存在，但我們透過一種複雜、有效的演算法證明，即使在更具挑戰性的受限設定中也能承認均衡。此外，計算出的均衡以最多 $2\left(\frac{e}{e-1}\right)$ 的因子近似最佳社會福利。此外，我們對無政府狀態/穩定的價格給予嚴格的限制。在概念方面，地點選擇功能為享樂遊戲的標準設定增加了一層，在於選擇相同地點的代理人會組成一個聯盟。這允許自然地限制可以形成的可能聯盟。有了這個，我們的模型概括了在完整理論二分圖估值圖表上的簡單對稱分數享樂遊戲，以及在 0 處單峰的享樂多樣性遊戲。我們相信這個概括對於其他類型的享樂遊戲來說也是一個非常有趣的發展方向。</paragraph>

##### **AnCoGen: Analysis, Control and Generation of Speech with a Masked Autoencoder**
2501.05332v1 by Samir Sadok, Simon Leglaive, Laurent Girin, Gaël Richard, Xavier Alameda-Pineda

This article introduces AnCoGen, a novel method that leverages a masked
autoencoder to unify the analysis, control, and generation of speech signals
within a single model. AnCoGen can analyze speech by estimating key attributes,
such as speaker identity, pitch, content, loudness, signal-to-noise ratio, and
clarity index. In addition, it can generate speech from these attributes and
allow precise control of the synthesized speech by modifying them. Extensive
experiments demonstrated the effectiveness of AnCoGen across speech
analysis-resynthesis, pitch estimation, pitch modification, and speech
enhancement.

摘要：本文介紹了 AnCoGen，一種新方法，它利用掩蔽式自動編碼器在單一模型中統一語音信號的分析、控制和生成。AnCoGen 可以透過估計關鍵屬性來分析語音，例如說話者身分、音高、內容、響度、信噪比和清晰度指標。此外，它可以從這些屬性生成語音，並透過修改它們來精確控制合成的語音。大量的實驗證明了 AnCoGen 在語音分析再合成、音高估計、音高修改和語音增強方面的有效性。

##### **Enhancing Plagiarism Detection in Marathi with a Weighted Ensemble of TF-IDF and BERT Embeddings for Low-Resource Language Processing**
2501.05260v1 by Atharva Mutsaddi, Aditya Choudhary

Plagiarism involves using another person's work or concepts without proper
attribution, presenting them as original creations. With the growing amount of
data communicated in regional languages such as Marathi -- one of India's
regional languages -- it is crucial to design robust plagiarism detection
systems tailored for low-resource languages. Language models like Bidirectional
Encoder Representations from Transformers (BERT) have demonstrated exceptional
capability in text representation and feature extraction, making them essential
tools for semantic analysis and plagiarism detection. However, the application
of BERT for low-resource languages remains under-explored, particularly in the
context of plagiarism detection. This paper presents a method to enhance the
accuracy of plagiarism detection for Marathi texts using BERT sentence
embeddings in conjunction with Term Frequency-Inverse Document Frequency
(TF-IDF) feature representation. This approach effectively captures
statistical, semantic, and syntactic aspects of text features through a
weighted voting ensemble of machine learning models.

摘要：剽竊涉及使用他人的作品或概念，卻沒有適當的出處，並將它們呈現為原創作品。隨著以馬拉地語等區域語言（印度的區域語言之一）傳達的資料量不斷增加，設計針對低資源語言的強大剽竊偵測系統至關重要。像 Transformer 的雙向編碼器表徵 (BERT) 等語言模型在文字表徵和特徵萃取方面展現了非凡的能力，使其成為語意分析和剽竊偵測的必要工具。然而，BERT 在低資源語言中的應用仍未被充分探索，特別是在剽竊偵測的背景下。本文提出了一種方法，使用 BERT 句子嵌入與詞頻逆文件頻率 (TF-IDF) 特徵表徵相結合，來增強馬拉地語文本的剽竊偵測準確度。此方法透過機器學習模型的加權投票整合，有效擷取文本特徵的統計、語意和句法面向。

##### **Automating the Detection of Code Vulnerabilities by Analyzing GitHub Issues**
2501.05258v1 by Daniele Cipollone, Changjie Wang, Mariano Scazzariello, Simone Ferlin, Maliheh Izadi, Dejan Kostic, Marco Chiesa

In today's digital landscape, the importance of timely and accurate
vulnerability detection has significantly increased. This paper presents a
novel approach that leverages transformer-based models and machine learning
techniques to automate the identification of software vulnerabilities by
analyzing GitHub issues. We introduce a new dataset specifically designed for
classifying GitHub issues relevant to vulnerability detection. We then examine
various classification techniques to determine their effectiveness. The results
demonstrate the potential of this approach for real-world application in early
vulnerability detection, which could substantially reduce the window of
exploitation for software vulnerabilities. This research makes a key
contribution to the field by providing a scalable and computationally efficient
framework for automated detection, enabling the prevention of compromised
software usage before official notifications. This work has the potential to
enhance the security of open-source software ecosystems.

摘要：在當今的數位環境中，及時且準確的漏洞偵測變得格外重要。本文提出了一種創新的方法，利用基於 Transformer 的模型和機器學習技術，透過分析 GitHub 中的問題，自動化軟體漏洞的辨識。我們引進了一個專門設計的新資料集，用於分類與漏洞偵測相關的 GitHub 問題。接著我們探討各種分類技術，以確定其有效性。結果顯示，這種方法在實際應用於早期漏洞偵測上具有潛力，這可以大幅縮短軟體漏洞的利用時間。本研究透過提供可擴充且計算效率高的自動化偵測架構，對這個領域做出了關鍵貢獻，可在官方通知發布前預防受危害軟體的使用。這項工作有潛力提升開源軟體生態系統的安全性。

##### **CallNavi: A Study and Challenge on Function Calling Routing and Invocation in Large Language Models**
2501.05255v1 by Yewei Song, Cedric Lothritz, Xunzhu Tang, Saad Ezzini, Jacques Klein, Tegawendé F. Bissyandé, Andrey Boytsov, Ulrick Ble, Anne Goujon

Interacting with a software system via a chatbot can be challenging,
especially when the chatbot needs to generate API calls, in the right order and
with the right parameters, to communicate with the system. API calling in
chatbot systems poses significant challenges, particularly in complex,
multi-step tasks requiring accurate API selection and execution. We contribute
to this domain in three ways: first, by introducing a novel dataset designed to
assess models on API function selection, parameter generation, and nested API
calls; second, by benchmarking state-of-the-art language models across varying
levels of complexity to evaluate their performance in API function generation
and parameter accuracy; and third, by proposing an enhanced API routing method
that combines general-purpose large language models for API selection with
fine-tuned models for parameter generation and some prompt engineering
approach. These approaches lead to substantial improvements in handling complex
API tasks, offering practical advancements for real-world API-driven chatbot
systems.

摘要：透過聊天機器人與軟體系統互動可能具有挑戰性，
特別是當聊天機器人需要產生 API 呼叫，並以正確的順序和
正確的參數與系統溝通時。聊天機器人系統中的 API 呼叫會造成重大的挑戰，特別是在需要準確的 API 選擇和執行的複雜、多步驟任務中。我們以三種方式對這個領域做出貢獻：首先，透過引入一個新穎的資料集，旨在評估模型的 API 函式選擇、參數產生和巢狀 API 呼叫；其次，透過比較最先進的語言模型在不同複雜程度下的基準，以評估它們在 API 函式產生和參數準確度方面的效能；第三，透過提出一個增強的 API 路由方法，該方法結合了通用大型語言模型，用於 API 選擇，以及微調模型，用於參數產生和一些提示工程方法。這些方法大幅改善了處理複雜 API 任務的方式，為實際世界的 API 驅動聊天機器人系統提供了實用的進展。

##### **From Scientific Texts to Verifiable Code: Automating the Process with Transformers**
2501.05252v1 by Changjie Wang, Mariano Scazzariello, Marco Chiesa

Despite the vast body of research literature proposing algorithms with formal
guarantees, the amount of verifiable code in today's systems remains minimal.
This discrepancy stems from the inherent difficulty of verifying code,
particularly due to the time-consuming nature and strict formalism of proof
details that formal verification tools require. However, the emergence of
transformers in Large Language Models presents a promising solution to this
challenge. In this position paper, we believe that transformers have the
potential to read research papers that propose algorithms with formal proofs
and translate these proofs into verifiable code. We leverage transformers to
first build a formal structure of the proof using the original text from the
paper, and then to handle the tedious, low-level aspects of proofs that are
often omitted by humans. We argue that this approach can significantly reduce
the barrier to formal verification. The above idea of reading papers to write
verifiable code opens new avenues for automating the verification of complex
systems, enabling a future where formally verified algorithms from academic
research can more seamlessly transition into real-world software systems,
thereby improving code reliability and security.

摘要：儘管有大量研究文獻提出具有正式保證的演算法，但當今系統中可驗證的程式碼量仍然很少。
這種差異源於驗證程式碼的固有困難，特別是因為正式驗證工具需要耗時的本質和嚴格的形式化證明細節。
然而，大型語言模型中的Transformer出現為此挑戰提供了一個有希望的解決方案。
在本文中，我們相信Transformer有能力閱讀提出具有正式證明演算法的研究論文，並將這些證明轉換為可驗證的程式碼。
我們利用Transformer首先使用論文中的原始文字建立證明的正式結構，然後處理人類經常遺漏的證明中繁瑣的低階層面。
我們認為這種方法可以顯著降低正式驗證的障礙。
透過閱讀論文來撰寫可驗證程式碼上述想法為自動化驗證複雜系統開啟了新途徑，實現了一個未來，其中來自學術研究的正式驗證演算法可以更無縫地轉換為真實世界的軟體系統，從而提高程式碼可靠性和安全性。

##### **RAG-WM: An Efficient Black-Box Watermarking Approach for Retrieval-Augmented Generation of Large Language Models**
2501.05249v1 by Peizhuo Lv, Mengjie Sun, Hao Wang, Xiaofeng Wang, Shengzhi Zhang, Yuxuan Chen, Kai Chen, Limin Sun

In recent years, tremendous success has been witnessed in Retrieval-Augmented
Generation (RAG), widely used to enhance Large Language Models (LLMs) in
domain-specific, knowledge-intensive, and privacy-sensitive tasks. However,
attackers may steal those valuable RAGs and deploy or commercialize them,
making it essential to detect Intellectual Property (IP) infringement. Most
existing ownership protection solutions, such as watermarks, are designed for
relational databases and texts. They cannot be directly applied to RAGs because
relational database watermarks require white-box access to detect IP
infringement, which is unrealistic for the knowledge base in RAGs. Meanwhile,
post-processing by the adversary's deployed LLMs typically destructs text
watermark information. To address those problems, we propose a novel black-box
"knowledge watermark" approach, named RAG-WM, to detect IP infringement of
RAGs. RAG-WM uses a multi-LLM interaction framework, comprising a Watermark
Generator, Shadow LLM & RAG, and Watermark Discriminator, to create watermark
texts based on watermark entity-relationship tuples and inject them into the
target RAG. We evaluate RAG-WM across three domain-specific and two
privacy-sensitive tasks on four benchmark LLMs. Experimental results show that
RAG-WM effectively detects the stolen RAGs in various deployed LLMs.
Furthermore, RAG-WM is robust against paraphrasing, unrelated content removal,
knowledge insertion, and knowledge expansion attacks. Lastly, RAG-WM can also
evade watermark detection approaches, highlighting its promising application in
detecting IP infringement of RAG systems.

摘要：近年來，檢索增強生成（RAG）獲得了巨大的成功，廣泛用於增強特定領域、知識密集型和隱私敏感型任務中的大型語言模型（LLM）。然而，攻擊者可能會竊取這些有價值的 RAG，並部署或商業化它們，因此必須檢測知識產權（IP）侵權行為。現有的所有權保護解決方案（例如浮水印）大多是為關係資料庫和文字而設計的。它們無法直接應用於 RAG，因為關係資料庫浮水印需要白盒存取權才能檢測 IP 侵權行為，這對於 RAG 中的知識庫來說是不切實際的。同時，對手部署的 LLM 後處理通常會破壞文字浮水印資訊。為了解決這些問題，我們提出了一種名為 RAG-WM 的新穎黑盒「知識浮水印」方法，以檢測 RAG 的 IP 侵權行為。RAG-WM 使用多 LLM 交互框架，包括浮水印產生器、影子 LLM 和 RAG，以及浮水印鑑別器，以根據浮水印實體關係元組建立浮水印文字，並將它們注入目標 RAG。我們在四個基準 LLM 上針對三個特定領域和兩個隱私敏感型任務評估 RAG-WM。實驗結果表明，RAG-WM 可以有效地檢測到各種已部署 LLM 中被竊取的 RAG。此外，RAG-WM 對於改寫、不相關內容移除、知識插入和知識擴充攻擊具有魯棒性。最後，RAG-WM 也可以規避浮水印檢測方法，凸顯其在檢測 RAG 系統的 IP 侵權行為中的應用前景。

##### **Deriving Coding-Specific Sub-Models from LLMs using Resource-Efficient Pruning**
2501.05248v1 by Laura Puccioni, Alireza Farshin, Mariano Scazzariello, Changjie Wang, Marco Chiesa, Dejan Kostic

Large Language Models (LLMs) have demonstrated their exceptional performance
in various complex code generation tasks. However, their broader adoption is
limited by significant computational demands and high resource requirements,
particularly memory and processing power. To mitigate such requirements, model
pruning techniques are used to create more compact models with significantly
fewer parameters. However, current approaches do not focus on the efficient
extraction of programming-language-specific sub-models. In this work, we
explore the idea of efficiently deriving coding-specific sub-models through
unstructured pruning (i.e., Wanda). We investigate the impact of different
domain-specific calibration datasets on pruning outcomes across three distinct
domains and extend our analysis to extracting four language-specific
sub-models: Python, Java, C++, and JavaScript. We are the first to efficiently
extract programming-language-specific sub-models using appropriate calibration
datasets while maintaining acceptable accuracy w.r.t. full models. We are also
the first to provide analytical evidence that domain-specific tasks activate
distinct regions within LLMs, supporting the creation of specialized sub-models
through unstructured pruning. We believe that this work has significant
potential to enhance LLM accessibility for coding by reducing computational
requirements to enable local execution on consumer-grade hardware, and
supporting faster inference times critical for real-time development feedback.

摘要：大型語言模型 (LLM) 已展現出其在各種複雜程式碼產生任務中的卓越效能。然而，其更廣泛的採用受到顯著的運算需求和高資源需求的限制，特別是記憶體和處理能力。為了減輕此類需求，模型剪枝技術用於建立更精簡的模型，其參數顯著減少。然而，目前的做法並未專注於程式語言特定子模型的有效提取。在這項工作中，我們探討了透過非結構化剪枝（即 Wanda）有效衍生特定於編碼的子模型的想法。我們研究了不同特定於領域的校正資料集對三個不同領域的剪枝結果的影響，並將我們的分析延伸至提取四個特定於語言的子模型：Python、Java、C++ 和 JavaScript。我們是第一個使用適當的校正資料集有效提取特定於程式語言的子模型，同時維持可接受的準確度，相對於完整的模型。我們也是第一個提供分析證據，證明特定於領域的任務會在 LLM 內啟動不同的區域，支援透過非結構化剪枝建立專門的子模型。我們相信，這項工作具有顯著的潛力，可透過降低運算需求以在消費級硬體上進行本地執行，從而增強 LLM 在編碼方面的可及性，並支援對於即時開發回饋至關重要的更快速的推論時間。

##### **Online Prompt and Solver Selection for Program Synthesis**
2501.05247v1 by Yixuan Li, Lewis Frampton, Federico Mora, Elizabeth Polgreen

Large Language Models (LLMs) demonstrate impressive capabilities in the
domain of program synthesis. This level of performance is not, however,
universal across all tasks, all LLMs and all prompting styles. There are many
areas where one LLM dominates, one prompting style dominates, or where calling
a symbolic solver is a better choice than an LLM. A key challenge for the user
then, is to identify not only when an LLM is the right choice of solver, and
the appropriate LLM to call for a given synthesis task, but also the right way
to call it. A non-expert user who makes the wrong choice, incurs a cost both in
terms of results (number of tasks solved, and the time it takes to solve them)
and financial cost, if using a closed-source language model via a commercial
API. We frame this choice as an online learning problem. We use a multi-armed
bandit algorithm to select which symbolic solver, or LLM and prompt combination
to deploy in order to maximize a given reward function (which may prioritize
solving time, number of synthesis tasks solved, or financial cost of solving).
We implement an instance of this approach, called CYANEA, and evaluate it on
synthesis queries from the literature in ranking function synthesis, from the
syntax-guided synthesis competition, and fresh, unseen queries generated from
SMT problems. CYANEA solves 37.2\% more queries than the best single solver and
achieves results within 4\% of the virtual best solver.

摘要：大型語言模型 (LLM) 在程式合成領域展現令人印象深刻的能力。然而，這種效能並非在所有任務、所有 LLM 和所有提示風格中都是普遍適用的。在許多領域中，一個 LLM 佔主導地位，一種提示風格佔主導地位，或者呼叫符號求解器比 LLM 是一個更好的選擇。因此，使用者的關鍵挑戰在於不僅要識別何時 LLM 是求解器的正確選擇，以及在給定的合成任務中呼叫適當的 LLM，還要識別呼叫它的正確方式。做出錯誤選擇的非專家使用者會在結果（已解決任務的數量和解決任務所需的時間）和財務成本方面承擔成本，如果透過商業 API 使用閉源語言模型的話。我們將此選擇設定為線上學習問題。我們使用多臂老虎機演算法來選擇要部署哪個符號求解器，或 LLM 和提示組合，以最大化給定的回報函數（可能會優先考慮解決時間、已解決的合成任務數量或解決的財務成本）。我們實作了這種方法的一個實例，稱為 CYANEA，並在來自排名函數合成、語法引導合成競賽的文獻中的合成查詢，以及從 SMT 問題中產生的最新、未見過的查詢上對其進行評估。CYANEA 解決的查詢比最佳單一求解器多 37.2%，並且在虛擬最佳求解器的 4% 範圍內取得結果。

##### **Optimizing Estonian TV Subtitles with Semi-supervised Learning and LLMs**
2501.05234v1 by Artem Fedorchenko, Tanel Alumäe

This paper presents an approach for generating high-quality, same-language
subtitles for Estonian TV content. We fine-tune the Whisper model on
human-generated Estonian subtitles and enhance it with iterative
pseudo-labeling and large language model (LLM) based post-editing. Our
experiments demonstrate notable subtitle quality improvement through
pseudo-labeling with an unlabeled dataset. We find that applying LLM-based
editing at test time enhances subtitle accuracy, while its use during training
does not yield further gains. This approach holds promise for creating subtitle
quality close to human standard and could be extended to real-time
applications.

摘要：本文提出了一種為愛沙尼亞電視內容生成高品質同語言字幕的方法。我們對人類生成的愛沙尼亞語字幕微調 Whisper 模型，並通過反覆偽標籤和基於大語言模型 (LLM) 的後編輯對其進行增強。我們的實驗通過使用未標記數據集進行偽標籤證明了字幕質量的顯著提高。我們發現，在測試時應用基於 LLM 的編輯可以提高字幕準確性，而其在訓練期間的使用並不會帶來進一步的收益。這種方法有望創造接近人類標準的字幕質量，並可以擴展到實時應用中。

##### **Leveraging Large Language Models for Zero-shot Lay Summarisation in Biomedicine and Beyond**
2501.05224v1 by Tomas Goldsack, Carolina Scarton, Chenghua Lin

In this work, we explore the application of Large Language Models to
zero-shot Lay Summarisation. We propose a novel two-stage framework for Lay
Summarisation based on real-life processes, and find that summaries generated
with this method are increasingly preferred by human judges for larger models.
To help establish best practices for employing LLMs in zero-shot settings, we
also assess the ability of LLMs as judges, finding that they are able to
replicate the preferences of human judges. Finally, we take the initial steps
towards Lay Summarisation for Natural Language Processing (NLP) articles,
finding that LLMs are able to generalise to this new domain, and further
highlighting the greater utility of summaries generated by our proposed
approach via an in-depth human evaluation.

摘要：在這項工作中，我們探討大型語言模型在零次摘要中的應用。我們提出了一個基於現實流程的新穎兩階段框架，用於非專業摘要，並發現使用此方法產生的摘要越來越受到人類評審員的青睞，適用於較大的模型。為了幫助建立在零次設定中使用 LLM 的最佳實務，我們也評估了 LLM 作為評審員的能力，發現它們能夠複製人類評審員的偏好。最後，我們採取了非專業摘要的最初步驟，用於自然語言處理 (NLP) 文章，發現 LLM 能夠概括到這個新領域，並進一步強調了我們提出的方法產生的摘要的更大效用，透過深入的人類評估。

##### **ParaRev: Building a dataset for Scientific Paragraph Revision annotated with revision instruction**
2501.05222v1 by Léane Jourdan, Nicolas Hernandez, Richard Dufour, Florian Boudin, Akiko Aizawa

Revision is a crucial step in scientific writing, where authors refine their
work to improve clarity, structure, and academic quality. Existing approaches
to automated writing assistance often focus on sentence-level revisions, which
fail to capture the broader context needed for effective modification. In this
paper, we explore the impact of shifting from sentence-level to paragraph-level
scope for the task of scientific text revision. The paragraph level definition
of the task allows for more meaningful changes, and is guided by detailed
revision instructions rather than general ones. To support this task, we
introduce ParaRev, the first dataset of revised scientific paragraphs with an
evaluation subset manually annotated with revision instructions. Our
experiments demonstrate that using detailed instructions significantly improves
the quality of automated revisions compared to general approaches, no matter
the model or the metric considered.

摘要：修改是科学寫作中至關重要的一步，作者在其中完善其作品，以提高清晰度、結構和學術品質。現有的自動寫作輔助方法通常側重於句子層級的修改，這無法掌握有效修改所需的更廣泛脈絡。在本文中，我們探討了從句子層級轉移到段落層級範圍對科學文本修改任務的影響。任務的段落層級定義允許進行更有意義的修改，並以詳細的修改說明為指導，而不是一般的說明。為了支持此任務，我們引入了 ParaRev，這是第一個經過人工標記修改說明的評估子集的已修改科學段落資料集。我們的實驗表明，與一般方法相比，使用詳細說明顯著提高了自動修改的品質，無論考慮哪種模型或指標。

##### **A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education**
2501.05220v1 by Ziqing Li, Mutlu Cukurova, Sahan Bulathwela

The development of Automatic Question Generation (QG) models has the
potential to significantly improve educational practices by reducing the
teacher workload associated with creating educational content. This paper
introduces a novel approach to educational question generation that controls
the topical focus of questions. The proposed Topic-Controlled Question
Generation (T-CQG) method enhances the relevance and effectiveness of the
generated content for educational purposes. Our approach uses fine-tuning on a
pre-trained T5-small model, employing specially created datasets tailored to
educational needs. The research further explores the impacts of pre-training
strategies, quantisation, and data augmentation on the model's performance. We
specifically address the challenge of generating semantically aligned questions
with paragraph-level contexts, thereby improving the topic specificity of the
generated questions. In addition, we introduce and explore novel evaluation
methods to assess the topical relatedness of the generated questions. Our
results, validated through rigorous offline and human-backed evaluations,
demonstrate that the proposed models effectively generate high-quality,
topic-focused questions. These models have the potential to reduce teacher
workload and support personalised tutoring systems by serving as bespoke
question generators. With its relatively small number of parameters, the
proposals not only advance the capabilities of question generation models for
handling specific educational topics but also offer a scalable solution that
reduces infrastructure costs. This scalability makes them feasible for
widespread use in education without reliance on proprietary large language
models like ChatGPT.

摘要：自動問題生成 (QG) 模型的發展具有顯著改善教育實務的潛力，方法是減少教師在建立教育內容時的工作負擔。本文介紹一種創新的教育問題生成方法，用以控制問題的主題焦點。提出的主題控制問題生成 (T-CQG) 方法增強了生成內容在教育目的上的相關性和有效性。我們的方法使用經過微調的預訓練 T5-small 模型，採用專門針對教育需求量身打造的資料集。研究進一步探討了預訓練策略、量子化和資料擴充對模型效能的影響。我們特別解決了生成與段落層級脈絡語意對齊的問題，從而改善生成問題的主題特定性。此外，我們介紹並探討了新的評估方法，以評估生成問題的主題相關性。我們的結果經過嚴格的離線和人工評估驗證，證明提出的模型有效地產生了高品質、主題焦點的問題。這些模型具有減少教師工作負擔和支援個人化教學系統的潛力，方法是作為客製化問題生成器。由於參數數量相對較少，這些提案不僅提升了問題生成模型在處理特定教育主題方面的能力，還提供了一個可擴充的解決方案，以降低基礎設施成本。這種可擴充性使它們在教育中廣泛使用成為可行，而無需依賴像 ChatGPT 這樣的專有大型語言模型。

##### **GLaM-Sign: Greek Language Multimodal Lip Reading with Integrated Sign Language Accessibility**
2501.05213v1 by Dimitris Kouremenos, Klimis Ntalianis

The Greek Language Multimodal Lip Reading with Integrated Sign Language
Accessibility (GLaM-Sign) [1] is a groundbreaking resource in accessibility and
multimodal AI, designed to support Deaf and Hard-of-Hearing (DHH) individuals.
Developed from the FEELIT project [2], it integrates high-resolution audio,
video, textual transcriptions, and Greek Sign Language translations for
applications like real-time sign language translation and enhanced subtitle
synchronization. While its primary focus is on promoting inclusivity in the
Greek tourism sector, its adaptability extends to education, healthcare, and
public services. Future advancements will enhance word-level precision and
scalability to additional languages, supported by advanced AI methodologies and
collaborations with diverse stakeholders. This dataset underscores the
transformative potential of multimodal resources in bridging communication
gaps, fostering innovation, and setting a benchmark for ethical AI and
inclusive technologies.

摘要：希臘語多模態唇讀與手語整合無障礙（GLaM-Sign）[1] 是無障礙和多模態人工智慧的突破性資源，旨在支援聾人和聽力障礙（DHH）人士。它由 FEELIT 專案 [2] 開發，整合了高解析度音訊、影片、文字轉錄和希臘手語翻譯，可用於即時手語翻譯和增強字幕同步等應用程式。雖然其主要重點是促進希臘旅遊業的包容性，但它的適用性也延伸到教育、醫療保健和公共服務。未來的進展將透過先進的人工智慧方法和與不同利害關係人的合作，提升字元級精準度和擴充到其他語言。此資料集突顯了多模態資源在彌合溝通鴻溝、促進創新以及為道德人工智慧和包容性技術設定基準方面的變革潛力。

##### **Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning**
2501.05205v1 by Xueyi Ke, Satoshi Tsutsui, Yayun Zhang, Bihan Wen

Infants develop complex visual understanding rapidly, even preceding of the
acquisition of linguistic inputs. As computer vision seeks to replicate the
human vision system, understanding infant visual development may offer valuable
insights. In this paper, we present an interdisciplinary study exploring this
question: can a computational model that imitates the infant learning process
develop broader visual concepts that extend beyond the vocabulary it has heard,
similar to how infants naturally learn? To investigate this, we analyze a
recently published model in Science by Vong et al.,which is trained on
longitudinal, egocentric images of a single child paired with transcribed
parental speech. We introduce a training-free framework that can discover
visual concept neurons hidden in the model's internal representations. Our
findings show that these neurons can classify objects outside its original
vocabulary. Furthermore, we compare the visual representations in infant-like
models with those in moder computer vision models, such as CLIP or ImageNet
pre-trained model, highlighting key similarities and differences. Ultimately,
our work bridges cognitive science and computer vision by analyzing the
internal representations of a computational model trained on an infant's visual
and linguistic inputs.

摘要：嬰兒發展出複雜的視覺理解，甚至早於語言輸入的獲得。由於電腦視覺試圖複製人類視覺系統，了解嬰兒視覺發展可能會提供有價值的見解。在本文中，我們提出了一項探索這個問題的跨學科研究：一個模仿嬰兒學習過程的計算模型是否能發展出超越其聽到的詞彙的更廣泛的視覺概念，類似於嬰兒自然學習的方式？為了調查這一點，我們分析了 Vong 等人在 Science 上最近發表的模型，該模型訓練於一個孩子的縱向自我中心影像，並配有轉錄的父母語言。我們引入了一個無需訓練的框架，它可以在模型的內部表示中發現隱藏的視覺概念神經元。我們的研究結果表明，這些神經元可以對其原始詞彙之外的物體進行分類。此外，我們將類嬰兒模型中的視覺表示與現代電腦視覺模型（例如 CLIP 或 ImageNet 預訓練模型）中的視覺表示進行比較，突出了關鍵的相似性和差異。最終，我們的研究通過分析在嬰兒的視覺和語言輸入上訓練的計算模型的內部表示，架起了認知科學和電腦視覺之間的橋樑。

##### **Bringing Order Amidst Chaos: On the Role of Artificial Intelligence in Secure Software Engineering**
2501.05165v1 by Matteo Esposito

Context. Developing secure and reliable software remains a key challenge in
software engineering (SE). The ever-evolving technological landscape offers
both opportunities and threats, creating a dynamic space where chaos and order
compete. Secure software engineering (SSE) must continuously address
vulnerabilities that endanger software systems and carry broader socio-economic
risks, such as compromising critical national infrastructure and causing
significant financial losses. Researchers and practitioners have explored
methodologies like Static Application Security Testing Tools (SASTTs) and
artificial intelligence (AI) approaches, including machine learning (ML) and
large language models (LLMs), to detect and mitigate these vulnerabilities.
Each method has unique strengths and limitations.
  Aim. This thesis seeks to bring order to the chaos in SSE by addressing
domain-specific differences that impact AI accuracy.
  Methodology. The research employs a mix of empirical strategies, such as
evaluating effort-aware metrics, analyzing SASTTs, conducting method-level
analysis, and leveraging evidence-based techniques like systematic dataset
reviews. These approaches help characterize vulnerability prediction datasets.
  Results. Key findings include limitations in static analysis tools for
identifying vulnerabilities, gaps in SASTT coverage of vulnerability types,
weak relationships among vulnerability severity scores, improved defect
prediction accuracy using just-in-time modeling, and threats posed by untouched
methods.
  Conclusions. This thesis highlights the complexity of SSE and the importance
of contextual knowledge in improving AI-driven vulnerability and defect
prediction. The comprehensive analysis advances effective prediction models,
benefiting both researchers and practitioners.

摘要：<paragraph>脈絡。開發安全且可靠的軟體仍然是軟體工程 (SE) 中的一項關鍵挑戰。不斷演進的技術領域既帶來機會，也帶來威脅，創造了一個混亂與秩序競爭的動態空間。安全軟體工程 (SSE) 必須持續解決危害軟體系統並帶來更廣泛社會經濟風險的漏洞，例如危害重要的國家基礎設施並造成重大財務損失。研究人員和從業人員已經探索了方法，例如靜態應用程式安全測試工具 (SASTT) 和人工智慧 (AI) 方法，包括機器學習 (ML) 和大型語言模型 (LLM)，以偵測和減輕這些漏洞。每種方法都有獨特的優點和缺點。
目標。本論文旨在透過解決影響 AI 精確度的特定領域差異，為 SSE 中的混亂帶來秩序。
方法。本研究採用各種經驗策略，例如評估考量工作量的指標、分析 SASTT、執行方法層級分析，以及利用基於證據的技術，例如系統化資料集回顧。這些方法有助於描述漏洞預測資料集。
結果。主要發現包括用於識別漏洞的靜態分析工具的限制、SASTT 對漏洞類型的涵蓋範圍有差距、漏洞嚴重性評分之間的關係薄弱、僅在即時建模中改善缺陷預測的準確度，以及未觸及的方法所帶來的威脅。
結論。本論文強調了 SSE 的複雜性以及背景知識在改善 AI 驅動的漏洞和缺陷預測中的重要性。全面的分析推動了有效的預測模型，使研究人員和從業人員受益。</paragraph>

##### **Explainable AI based System for Supply Air Temperature Forecast**
2501.05163v1 by Marika Eik, Ahmet Kose, Hossein Nourollahi Hokmabad, Juri Belikov

This paper explores the application of Explainable AI (XAI) techniques to
improve the transparency and understanding of predictive models in control of
automated supply air temperature (ASAT) of Air Handling Unit (AHU). The study
focuses on forecasting of ASAT using a linear regression with Huber loss.
However, having only a control curve without semantic and/or physical
explanation is often not enough. The present study employs one of the XAI
methods: Shapley values, which allows to reveal the reasoning and highlight the
contribution of each feature to the final ASAT forecast. In comparison to other
XAI methods, Shapley values have solid mathematical background, resulting in
interpretation transparency. The study demonstrates the contrastive
explanations--slices, for each control value of ASAT, which makes it possible
to give the client objective justifications for curve changes.

摘要：本文探討可解釋 AI (XAI) 技術在提高空氣處理單元 (AHU) 自動供應空氣溫度 (ASAT) 預測模型的透明度和理解度中的應用。本研究的重點在於使用帶有 Huber 損失的線性回歸預測 ASAT。然而，僅有一個沒有語義和/或物理解釋的控制曲線通常是不夠的。本研究採用 XAI 方法之一：Shapley 值，它可以揭示推理並強調每個特徵對最終 ASAT 預測的貢獻。與其他 XAI 方法相比，Shapley 值具有紮實的數學背景，從而實現了解釋透明度。本研究展示了對比解釋——切片，針對 ASAT 的每個控制值，這使得可以為曲線變化提供客戶客觀的理由。

##### **Biomedical Relation Extraction via Adaptive Document-Relation Cross-Mapping and Concept Unique Identifier**
2501.05155v1 by Yufei Shang, Yanrong Guo, Shijie Hao, Richang Hong

Document-Level Biomedical Relation Extraction (Bio-RE) aims to identify
relations between biomedical entities within extensive texts, serving as a
crucial subfield of biomedical text mining. Existing Bio-RE methods struggle
with cross-sentence inference, which is essential for capturing relations
spanning multiple sentences. Moreover, previous methods often overlook the
incompleteness of documents and lack the integration of external knowledge,
limiting contextual richness. Besides, the scarcity of annotated data further
hampers model training. Recent advancements in large language models (LLMs)
have inspired us to explore all the above issues for document-level Bio-RE.
Specifically, we propose a document-level Bio-RE framework via LLM Adaptive
Document-Relation Cross-Mapping (ADRCM) Fine-Tuning and Concept Unique
Identifier (CUI) Retrieval-Augmented Generation (RAG). First, we introduce the
Iteration-of-REsummary (IoRs) prompt for solving the data scarcity issue. In
this way, Bio-RE task-specific synthetic data can be generated by guiding
ChatGPT to focus on entity relations and iteratively refining synthetic data.
Next, we propose ADRCM fine-tuning, a novel fine-tuning recipe that establishes
mappings across different documents and relations, enhancing the model's
contextual understanding and cross-sentence inference capabilities. Finally,
during the inference, a biomedical-specific RAG approach, named CUI RAG, is
designed to leverage CUIs as indexes for entities, narrowing the retrieval
scope and enriching the relevant document contexts. Experiments conducted on
three Bio-RE datasets (GDA, CDR, and BioRED) demonstrate the state-of-the-art
performance of our proposed method by comparing it with other related works.

摘要：<paragraph>文件級生物醫學關係萃取 (Bio-RE) 旨在識別廣泛文本中生物醫學實體之間的關係，是生物醫學文本探勘的關鍵子領域。現有的 Bio-RE 方法難以進行跨句推論，這對於捕捉跨越多個句子的關係至關重要。此外，先前的研究方法經常忽略文件的完整性，且缺乏外部知識的整合，限制了脈絡的豐富性。此外，標註資料的稀少性進一步阻礙了模型訓練。大型語言模型 (LLM) 的最新進展激勵我們探索文件級 Bio-RE 的所有上述問題。具體來說，我們透過 LLM 適應性文件關係交叉對應 (ADRCM) 微調和概念唯一識別碼 (CUI) 檢索增強生成 (RAG) 提出一個文件級 Bio-RE 架構。首先，我們介紹 RE 摘要反覆 (IoRs) 提示，以解決資料稀少的問題。透過這種方式，可以透過引導 ChatGPT 專注於實體關係和反覆優化合成資料來產生 Bio-RE 任務特定的合成資料。接下來，我們提出 ADRCM 微調，這是一種新穎的微調配方，可建立不同文件和關係之間的對應，增強模型的脈絡理解和跨句推論能力。最後，在推理過程中，設計了一種名為 CUI RAG 的生物醫學特定 RAG 方法，以利用 CUI 作為實體的索引，縮小檢索範圍並豐富相關文件脈絡。在三個 Bio-RE 資料集 (GDA、CDR 和 BioRED) 上進行的實驗證明了我們提出的方法的最新技術，並將其與其他相關工作進行比較。</paragraph>

##### **A Systematic Literature Review on Deep Learning-based Depth Estimation in Computer Vision**
2501.05147v1 by Ali Rohan, Md Junayed Hasan, Andrei Petrovski

Depth estimation (DE) provides spatial information about a scene and enables
tasks such as 3D reconstruction, object detection, and scene understanding.
Recently, there has been an increasing interest in using deep learning
(DL)-based methods for DE. Traditional techniques rely on handcrafted features
that often struggle to generalise to diverse scenes and require extensive
manual tuning. However, DL models for DE can automatically extract relevant
features from input data, adapt to various scene conditions, and generalise
well to unseen environments. Numerous DL-based methods have been developed,
making it necessary to survey and synthesize the state-of-the-art (SOTA).
Previous reviews on DE have mainly focused on either monocular or stereo-based
techniques, rather than comprehensively reviewing DE. Furthermore, to the best
of our knowledge, there is no systematic literature review (SLR) that
comprehensively focuses on DE. Therefore, this SLR study is being conducted.
Initially, electronic databases were searched for relevant publications,
resulting in 1284 publications. Using defined exclusion and quality criteria,
128 publications were shortlisted and further filtered to select 59
high-quality primary studies. These studies were analysed to extract data and
answer defined research questions. Based on the results, DL methods were
developed for mainly three different types of DE: monocular, stereo, and
multi-view. 20 publicly available datasets were used to train, test, and
evaluate DL models for DE, with KITTI, NYU Depth V2, and Make 3D being the most
used datasets. 29 evaluation metrics were used to assess the performance of DE.
35 base models were reported in the primary studies, and the top five most-used
base models were ResNet-50, ResNet-18, ResNet-101, U-Net, and VGG-16. Finally,
the lack of ground truth data was among the most significant challenges
reported by primary studies.

摘要：深度估計 (DE) 提供場景的空間資訊，並能執行 3D 重建、物體偵測和場景理解等任務。最近，使用深度學習 (DL) 的方法進行 DE 逐漸受到重視。傳統技術仰賴手工特徵，而這些特徵通常難以推廣到不同的場景，並且需要廣泛的手動調整。然而，DE 的 DL 模型可以自動從輸入資料中萃取相關特徵、適應各種場景條件，並能推廣到未知的環境。已經開發出許多基於 DL 的方法，因此有必要調查和綜合現有技術 (SOTA)。先前關於 DE 的回顧主要專注於單眼或立體技術，而不是全面回顧 DE。此外，據我們所知，沒有系統性的文獻回顧 (SLR) 全面關注 DE。因此，正在進行這項 SLR 研究。最初，在電子資料庫中搜尋相關出版品，共得到 1284 篇出版品。使用定義的排除和品質標準，將 128 篇出版品列入候選名單，並進一步篩選出 59 項高品質的主要研究。分析這些研究以萃取資料並回答定義的研究問題。根據結果，DL 方法主要針對三種類型的 DE 進行開發：單眼、立體和多視圖。20 個公開可用的資料集用於訓練、測試和評估 DE 的 DL 模型，其中 KITTI、NYU Depth V2 和 Make 3D 是最常用的資料集。29 個評估指標用於評估 DE 的效能。35 個基礎模型在主要研究中被報導，前五個最常使用的基礎模型是 ResNet-50、ResNet-18、ResNet-101、U-Net 和 VGG-16。最後，主要研究報告的重大挑戰之一是缺乏真實資料。

##### **Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model**
2501.05122v1 by Gregor Geigle, Florian Schneider, Carolin Holtermann, Chris Biemann, Radu Timofte, Anne Lauscher, Goran Glavaš

Most Large Vision-Language Models (LVLMs) to date are trained predominantly
on English data, which makes them struggle to understand non-English input and
fail to generate output in the desired target language. Existing efforts
mitigate these issues by adding multilingual training data, but do so in a
largely ad-hoc manner, lacking insight into how different training mixes tip
the scale for different groups of languages. In this work, we present a
comprehensive investigation into the training strategies for massively
multilingual LVLMs. First, we conduct a series of multi-stage experiments
spanning 13 downstream vision-language tasks and 43 languages, systematically
examining: (1) the number of training languages that can be included without
degrading English performance and (2) optimal language distributions of
pre-training as well as (3) instruction-tuning data. Further, we (4)
investigate how to improve multilingual text-in-image understanding, and
introduce a new benchmark for the task. Surprisingly, our analysis reveals that
one can (i) include as many as 100 training languages simultaneously (ii) with
as little as 25-50\% of non-English data, to greatly improve multilingual
performance while retaining strong English performance. We further find that
(iii) including non-English OCR data in pre-training and instruction-tuning is
paramount for improving multilingual text-in-image understanding. Finally, we
put all our findings together and train Centurio, a 100-language LVLM, offering
state-of-the-art performance in an evaluation covering 14 tasks and 56
languages.

摘要：<paragraph>迄今為止，大多數大型視覺語言模型 (LVLMs) 主要都是以英文資料進行訓練，這使得它們難以理解非英文輸入，也無法產生目標語言的輸出。現有的解決方法是透過加入多語言訓練資料來減輕這些問題，但這些方法大多都是臨時應變，缺乏對於不同訓練組合如何影響不同語言群體的見解。在本文中，我們針對大量多語言 LVLMs 的訓練策略進行全面調查。首先，我們進行了一系列多階段實驗，涵蓋 13 個下游視覺語言任務和 43 種語言，系統性地探討：(1) 在不降低英文效能的情況下可以納入的訓練語言數量，以及 (2) 預訓練的最佳語言分佈，以及 (3) 指令調整資料。此外，我們 (4) 探討如何改善多語言文字影像理解，並為此任務引入一個新的基準。令人驚訝的是，我們的分析顯示，人們可以 (i) 同時納入多達 100 種訓練語言，(ii) 只要 25-50% 的非英文資料，就能大幅改善多語言效能，同時維持強勁的英文效能。我們進一步發現，(iii) 在預訓練和指令調整中納入非英文 OCR 資料對於改善多語言文字影像理解至關重要。最後，我們將所有發現彙整起來，訓練出 Centurio，這是一個 100 語言的 LVLM，在涵蓋 14 個任務和 56 種語言的評估中提供最先進的效能。</paragraph>

##### **Constrained Optimization of Charged Particle Tracking with Multi-Agent Reinforcement Learning**
2501.05113v1 by Tobias Kortus, Ralf Keidel, Nicolas R. Gauger, Jan Kieseler

Reinforcement learning demonstrated immense success in modelling complex
physics-driven systems, providing end-to-end trainable solutions by interacting
with a simulated or real environment, maximizing a scalar reward signal. In
this work, we propose, building upon previous work, a multi-agent reinforcement
learning approach with assignment constraints for reconstructing particle
tracks in pixelated particle detectors. Our approach optimizes collaboratively
a parametrized policy, functioning as a heuristic to a multidimensional
assignment problem, by jointly minimizing the total amount of particle
scattering over the reconstructed tracks in a readout frame. To satisfy
constraints, guaranteeing a unique assignment of particle hits, we propose a
safety layer solving a linear assignment problem for every joint action.
Further, to enforce cost margins, increasing the distance of the local policies
predictions to the decision boundaries of the optimizer mappings, we recommend
the use of an additional component in the blackbox gradient estimation, forcing
the policy to solutions with lower total assignment costs. We empirically show
on simulated data, generated for a particle detector developed for proton
imaging, the effectiveness of our approach, compared to multiple single- and
multi-agent baselines. We further demonstrate the effectiveness of constraints
with cost margins for both optimization and generalization, introduced by wider
regions with high reconstruction performance as well as reduced predictive
instabilities. Our results form the basis for further developments in RL-based
tracking, offering both enhanced performance with constrained policies and
greater flexibility in optimizing tracking algorithms through the option for
individual and team rewards.

摘要：強化學習在建模複雜的物理驅動系統方面展現出巨大的成功，透過與模擬或真實環境互動，提供端到端的可訓練解決方案，最大化標量獎勵訊號。在這項工作中，我們提出建立在先前工作上的多重代理強化學習方法，使用指派約束來重建像素化粒子探測器中的粒子軌跡。我們的做法透過共同最小化讀取框架中重建軌跡上粒子的總散射量，協調最佳化一個參數化策略，作為多維指派問題的啟發法。為了滿足約束，確保粒子命中事件的唯一指派，我們提出一個安全層，為每個聯合動作解決線性指派問題。此外，為了強制執行成本邊際，增加局部策略預測與最佳化對應的決策邊界的距離，我們建議在黑盒梯度估計中使用額外的組成，迫使策略採取總指派成本較低的解決方案。我們在為質子影像開發的粒子探測器產生的模擬資料上，實證顯示我們的方法有效，並與多個單一和多重代理基準進行比較。我們進一步展示了約束在最佳化和概括中的有效性，這些約束透過具有高重建效能的較寬廣區域以及減少預測不穩定性而引入。我們的結果為基於 RL 的追蹤進一步發展奠定基礎，透過受約束策略提供增強的效能，以及透過個人和團隊獎勵的選項，在最佳化追蹤演算法方面提供更大的彈性。

##### **Advancing ALS Applications with Large-Scale Pre-training: Dataset Development and Downstream Assessment**
2501.05095v1 by Haoyi Xiu, Xin Liu, Taehoon Kim, Kyoung-Sook Kim

The pre-training and fine-tuning paradigm has revolutionized satellite remote
sensing applications. However, this approach remains largely underexplored for
airborne laser scanning (ALS), an important technology for applications such as
forest management and urban planning. In this study, we address this gap by
constructing a large-scale ALS point cloud dataset and evaluating its impact on
downstream applications. Our dataset comprises ALS point clouds collected
across the contiguous United States, provided by the United States Geological
Survey's 3D Elevation Program. To ensure efficient data collection while
capturing diverse land cover and terrain types, we introduce a geospatial
sampling method that selects point cloud tiles based on land cover maps and
digital elevation models. As a baseline self-supervised learning model, we
adopt BEV-MAE, a state-of-the-art masked autoencoder for 3D outdoor point
clouds, and pre-train it on the constructed dataset. The pre-trained models are
subsequently fine-tuned for downstream tasks, including tree species
classification, terrain scene recognition, and point cloud semantic
segmentation. Our results show that the pre-trained models significantly
outperform their scratch counterparts across all downstream tasks,
demonstrating the transferability of the representations learned from the
proposed dataset. Furthermore, we observe that scaling the dataset using our
geospatial sampling method consistently enhances performance, whereas
pre-training on datasets constructed with random sampling fails to achieve
similar improvements. These findings highlight the utility of the constructed
dataset and the effectiveness of our sampling strategy in the pre-training and
fine-tuning paradigm. The source code and pre-trained models will be made
publicly available at \url{https://github.com/martianxiu/ALS_pretraining}.

摘要：預訓練和微調範例已徹底改變衛星遙測應用。然而，這種方法在機載雷射掃描 (ALS) 上仍未被廣泛探索，而 ALS 是一項應用於森林管理和都市規劃等領域的重要技術。在這項研究中，我們透過建構大規模 ALS 點雲資料集並評估其對下游應用的影響來解決這個問題。我們的資料集包含由美國地質調查局的 3D 高程計畫所提供的，在美國本土收集的 ALS 點雲。為了確保有效率的資料收集，同時擷取多樣的土地覆蓋和地形類型，我們引入一種地理空間取樣方法，根據土地覆蓋地圖和數位高程模型來選擇點雲磚塊。身為基準的自監督式學習模型，我們採用 BEV-MAE，這是一種最先進的 3D 戶外點雲遮罩自動編碼器，並在建構的資料集上對其進行預訓練。預訓練模型隨後針對下游任務進行微調，包括樹種分類、地形場景辨識和點雲語意分割。我們的結果顯示，預訓練模型在所有下游任務中都顯著優於從頭訓練的模型，證明了從建議資料集中學習到的表徵的可轉移性。此外，我們觀察到使用我們的地理空間取樣方法擴充資料集會持續提升效能，而使用隨機取樣建構的資料集進行預訓練則無法獲得類似的進步。這些發現突顯了建構資料集的效用，以及我們的取樣策略在預訓練和微調範例中的有效性。原始碼和預訓練模型將在 \url{https://github.com/martianxiu/ALS_pretraining} 公開。

##### **Comparison of Feature Learning Methods for Metadata Extraction from PDF Scholarly Documents**
2501.05082v1 by Zeyd Boukhers, Cong Yang

The availability of metadata for scientific documents is pivotal in
propelling scientific knowledge forward and for adhering to the FAIR principles
(i.e. Findability, Accessibility, Interoperability, and Reusability) of
research findings. However, the lack of sufficient metadata in published
documents, particularly those from smaller and mid-sized publishers, hinders
their accessibility. This issue is widespread in some disciplines, such as the
German Social Sciences, where publications often employ diverse templates. To
address this challenge, our study evaluates various feature learning and
prediction methods, including natural language processing (NLP), computer
vision (CV), and multimodal approaches, for extracting metadata from documents
with high template variance. We aim to improve the accessibility of scientific
documents and facilitate their wider use. To support our comparison of these
methods, we provide comprehensive experimental results, analyzing their
accuracy and efficiency in extracting metadata. Additionally, we provide
valuable insights into the strengths and weaknesses of various feature learning
and prediction methods, which can guide future research in this field.

摘要：科學文件中的元資料可用性對於推進科學知識進步以及遵守研究發現的 FAIR 原則（即：可尋找性、可存取性、互操作性及可重複使用性）至關重要。然而，已發布文件中缺乏足夠的元資料，尤其是來自較小規模和中型規模出版商的文件，會阻礙其可存取性。這個問題在某些領域很普遍，例如德國社會科學，那裡的出版物通常採用不同的範本。為了應對這個挑戰，我們的研究評估了各種特徵學習和預測方法，包括自然語言處理 (NLP)、電腦視覺 (CV) 和多模式方法，用於從範本差異性高的文件中萃取元資料。我們的目標是改善科學文件的可存取性，並促進其更廣泛的使用。為了支持我們對這些方法的比較，我們提供了全面的實驗結果，分析了它們在萃取元資料方面的準確性和效率。此外，我們還提供了對各種特徵學習和預測方法的優缺點的寶貴見解，這些見解可以指導此領域的未來研究。

##### **Multimodal-to-Text Prompt Engineering in Large Language Models Using Feature Embeddings for GNSS Interference Characterization**
2501.05079v1 by Harshith Manjunath, Lucas Heublein, Tobias Feigl, Felix Ott

Large language models (LLMs) are advanced AI systems applied across various
domains, including NLP, information retrieval, and recommendation systems.
Despite their adaptability and efficiency, LLMs have not been extensively
explored for signal processing tasks, particularly in the domain of global
navigation satellite system (GNSS) interference monitoring. GNSS interference
monitoring is essential to ensure the reliability of vehicle localization on
roads, a critical requirement for numerous applications. However, GNSS-based
positioning is vulnerable to interference from jamming devices, which can
compromise its accuracy. The primary objective is to identify, classify, and
mitigate these interferences. Interpreting GNSS snapshots and the associated
interferences presents significant challenges due to the inherent complexity,
including multipath effects, diverse interference types, varying sensor
characteristics, and satellite constellations. In this paper, we extract
features from a large GNSS dataset and employ LLaVA to retrieve relevant
information from an extensive knowledge base. We employ prompt engineering to
interpret the interferences and environmental factors, and utilize t-SNE to
analyze the feature embeddings. Our findings demonstrate that the proposed
method is capable of visual and logical reasoning within the GNSS context.
Furthermore, our pipeline outperforms state-of-the-art machine learning models
in interference classification tasks.

摘要：大型語言模型 (LLM) 是先進的人工智慧系統，應用於各種領域，包括自然語言處理、資訊檢索和推薦系統。儘管 LLM 具有適應性和效率，但尚未廣泛探索用於訊號處理任務，特別是在全球導航衛星系統 (GNSS) 干擾監控領域。GNSS 干擾監控對於確保道路上車輛定位的可靠性至關重要，這對於許多應用來說是一項關鍵要求。然而，基於 GNSS 的定位容易受到干擾裝置的干擾，這可能會影響其準確性。主要目標是識別、分類和減輕這些干擾。由於固有的複雜性，包括多路徑效應、多樣化的干擾類型、不同的感測器特性和衛星星座，因此解釋 GNSS 快照和相關干擾會帶來重大挑戰。在本文中，我們從大型 GNSS 資料集中提取特徵，並使用 LLaVA 從廣泛的知識庫中檢索相關資訊。我們採用提示工程來解釋干擾和環境因素，並利用 t-SNE 來分析特徵嵌入。我們的研究結果表明，所提出的方法能夠在 GNSS 背景下進行視覺和邏輯推理。此外，我們的管道在干擾分類任務中優於最先進的機器學習模型。

##### **Analyzing Memorization in Large Language Models through the Lens of Model Attribution**
2501.05078v1 by Tarun Ram Menta, Susmit Agrawal, Chirag Agarwal

Large Language Models (LLMs) are prevalent in modern applications but often
memorize training data, leading to privacy breaches and copyright issues.
Existing research has mainly focused on posthoc analyses, such as extracting
memorized content or developing memorization metrics, without exploring the
underlying architectural factors that contribute to memorization. In this work,
we investigate memorization from an architectural lens by analyzing how
attention modules at different layers impact its memorization and
generalization performance. Using attribution techniques, we systematically
intervene in the LLM architecture by bypassing attention modules at specific
blocks while keeping other components like layer normalization and MLP
transformations intact. We provide theorems analyzing our intervention
mechanism from a mathematical view, bounding the difference in layer outputs
with and without our attributions. Our theoretical and empirical analyses
reveal that attention modules in deeper transformer blocks are primarily
responsible for memorization, whereas earlier blocks are crucial for the models
generalization and reasoning capabilities. We validate our findings through
comprehensive experiments on different LLM families (Pythia and GPTNeo) and
five benchmark datasets. Our insights offer a practical approach to mitigate
memorization in LLMs while preserving their performance, contributing to safer
and more ethical deployment in real world applications.

摘要：大型語言模型 (LLM) 在現代應用中很普遍，但經常記住訓練資料，導致隱私洩露和版權問題。現有研究主要集中在事後分析，例如提取記憶內容或開發記憶度量標準，而沒有探討導致記憶的底層架構因素。在這項工作中，我們透過分析不同層級的注意力模組如何影響其記憶和泛化效能，從架構角度探討記憶。使用歸因技術，我們系統性地介入 LLM 架構，方法是在特定區塊中繞過注意力模組，同時保持層正規化和 MLP 轉換等其他元件完整。我們提供定理從數學角度分析我們的介入機制，界定有和沒有我們的歸因時層輸出差異。我們的理論和實證分析顯示，較深層Transformer區塊中的注意力模組主要負責記憶，而較早期的區塊對於模型的泛化和推理能力至關重要。我們透過對不同 LLM 家族（Pythia 和 GPTNeo）和五個基準資料集進行全面的實驗驗證我們的發現。我們的見解提供了一種實用的方法來減輕 LLM 中的記憶，同時保留其效能，有助於在實際應用中更安全、更合乎道德地部署。

##### **A Text-Based Knowledge-Embedded Soft Sensing Modeling Approach for General Industrial Process Tasks Based on Large Language Model**
2501.05075v1 by Shuo Tong, Han Liu, Runyuan Guo, Xueqiong Tian, Wenqing Wang, Ding Liu, Youmin Zhang

Data-driven soft sensors (DDSS) have become mainstream methods for predicting
key performance indicators in process industries. However, DDSS development
requires complex and costly customized designs tailored to various tasks during
the modeling process. Moreover, DDSS are constrained to a single structured
data modality, limiting their ability to incorporate additional contextual
knowledge. Furthermore, DDSSs' limited representation learning leads to weak
predictive performance with scarce data. To address these challenges, we
propose a general framework named LLM-TKESS (large language model for
text-based knowledge-embedded soft sensing), harnessing the powerful general
problem-solving capabilities, cross-modal knowledge transfer abilities, and
few-shot capabilities of LLM for enhanced soft sensing modeling. Specifically,
an auxiliary variable series encoder (AVS Encoder) is proposed to unleash LLM's
potential for capturing temporal relationships within series and spatial
semantic relationships among auxiliary variables. Then, we propose a two-stage
fine-tuning alignment strategy: in the first stage, employing
parameter-efficient fine-tuning through autoregressive training adjusts LLM to
rapidly accommodate process variable data, resulting in a soft sensing
foundation model (SSFM). Subsequently, by training adapters, we adapt the SSFM
to various downstream tasks without modifying its architecture. Then, we
propose two text-based knowledge-embedded soft sensors, integrating new natural
language modalities to overcome the limitations of pure structured data models.
Furthermore, benefiting from LLM's pre-existing world knowledge, our model
demonstrates outstanding predictive capabilities in small sample conditions.
Using the thermal deformation of air preheater rotor as a case study, we
validate through extensive experiments that LLM-TKESS exhibits outstanding
performance.

摘要：<paragraph>資料驅動軟感測器 (DDSS) 已成為預測製程產業中關鍵績效指標的主流方法。然而，DDSS 的開發需要複雜且昂貴的客製化設計，以適應建模過程中各種任務。此外，DDSS 受到單一結構化資料模式的限制，這限制了其整合額外背景知識的能力。進一步來說，DDSS 有限的表徵學習導致在資料稀少的情況下預測效能不佳。為了應對這些挑戰，我們提出了一個名為 LLM-TKESS（用於基於文字知識嵌入式軟感測的大型語言模型）的通用架構，利用 LLM 強大的通用問題解決能力、跨模態知識傳輸能力和少樣本能力來增強軟感測建模。具體來說，提出了一個輔助變數序列編碼器 (AVS 編碼器) 來釋放 LLM 擷取序列中時間關係和輔助變數之間空間語義關係的潛力。然後，我們提出了一個兩階段微調對齊策略：在第一階段，透過自迴歸訓練採用參數高效的微調，調整 LLM 以快速適應製程變數資料，從而產生軟感測基礎模型 (SSFM)。隨後，透過訓練適配器，我們將 SSFM 適應到各種下游任務，而無需修改其架構。然後，我們提出了兩個基於文字的知識嵌入式軟感測器，整合新的自然語言模式以克服純結構化資料模型的限制。此外，受益於 LLM 已有的世界知識，我們的模型在小樣本條件下展示了出色的預測能力。使用空氣預熱器轉子的熱變形作為案例研究，我們透過廣泛的實驗驗證了 LLM-TKESS 展現出色的效能。</paragraph>

##### **Commonsense Video Question Answering through Video-Grounded Entailment Tree Reasoning**
2501.05069v1 by Huabin Liu, Filip Ilievski, Cees G. M. Snoek

This paper proposes the first video-grounded entailment tree reasoning method
for commonsense video question answering (VQA). Despite the remarkable progress
of large visual-language models (VLMs), there are growing concerns that they
learn spurious correlations between videos and likely answers, reinforced by
their black-box nature and remaining benchmarking biases. Our method explicitly
grounds VQA tasks to video fragments in four steps: entailment tree
construction, video-language entailment verification, tree reasoning, and
dynamic tree expansion. A vital benefit of the method is its generalizability
to current video and image-based VLMs across reasoning types. To support fair
evaluation, we devise a de-biasing procedure based on large-language models
that rewrites VQA benchmark answer sets to enforce model reasoning. Systematic
experiments on existing and de-biased benchmarks highlight the impact of our
method components across benchmarks, VLMs, and reasoning types.

摘要：本文提出第一個影片接地推論樹推理方法，用於常識影片問答 (VQA)。儘管大型視覺語言模型 (VLM) 有顯著進展，但對於它們學習影片與可能答案之間的虛假關聯性，並因其黑盒性質和現有基準偏差而加強，越來越令人擔憂。我們的模型明確地將 VQA 任務建立在影片片段上，分為四個步驟：推論樹構建、影片語言推論驗證、樹推理和動態樹擴充。此方法的一項重要優點是其對各種推理類型中現有影片和基於影像的 VLM 的通用性。為了支持公平的評估，我們設計了一個基於大型語言模型的去偏程序，用於改寫 VQA 基準答案集以強制執行模型推理。在現有和去偏基準上的系統性實驗突顯了我們的模型組成在基準、VLM 和推理類型上的影響。

##### **D3RM: A Discrete Denoising Diffusion Refinement Model for Piano Transcription**
2501.05068v1 by Hounsu Kim, Taegyun Kwon, Juhan Nam

Diffusion models have been widely used in the generative domain due to their
convincing performance in modeling complex data distributions. Moreover, they
have shown competitive results on discriminative tasks, such as image
segmentation. While diffusion models have also been explored for automatic
music transcription, their performance has yet to reach a competitive level. In
this paper, we focus on discrete diffusion model's refinement capabilities and
present a novel architecture for piano transcription. Our model utilizes
Neighborhood Attention layers as the denoising module, gradually predicting the
target high-resolution piano roll, conditioned on the finetuned features of a
pretrained acoustic model. To further enhance refinement, we devise a novel
strategy which applies distinct transition states during training and inference
stage of discrete diffusion models. Experiments on the MAESTRO dataset show
that our approach outperforms previous diffusion-based piano transcription
models and the baseline model in terms of F1 score. Our code is available in
https://github.com/hanshounsu/d3rm.

摘要：擴散模型因其在建模複雜資料分佈上的出色表現，而廣泛用於生成領域。此外，它們在判別任務（例如影像分割）上也展現出競爭力的結果。儘管擴散模型也已用於自動音樂轉錄，但其效能仍未達到競爭水準。在本文中，我們專注於離散擴散模型的精煉能力，並提出鋼琴轉錄的新穎架構。我們的模型利用鄰域注意力層作為去噪模組，逐漸預測目標高解析度鋼琴捲軸，並根據預訓練聲學模型的微調特徵進行條件化。為了進一步增強精煉，我們設計了一種新穎策略，在離散擴散模型的訓練和推論階段應用不同的轉換狀態。在 MAESTRO 資料集上的實驗顯示，我們的做法在 F1 分數方面優於先前的基於擴散的鋼琴轉錄模型和基準模型。我們的程式碼可在 https://github.com/hanshounsu/d3rm 中取得。

##### **LLaVA-Octopus: Unlocking Instruction-Driven Adaptive Projector Fusion for Video Understanding**
2501.05067v1 by Jiaxing Zhao, Boyuan Sun, Xiang Chen, Xihan Wei, Qibin Hou

In this paper, we introduce LLaVA-Octopus, a novel video multimodal large
language model. LLaVA-Octopus adaptively weights features from different visual
projectors based on user instructions, enabling us to leverage the
complementary strengths of each projector. We observe that different visual
projectors exhibit distinct characteristics when handling specific tasks. For
instance, some projectors excel at capturing static details, while others are
more effective at processing temporal information, and some are better suited
for tasks requiring temporal coherence. By dynamically adjusting feature
weights according to user instructions, LLaVA-Octopus dynamically selects and
combines the most suitable features, significantly enhancing the model's
performance in multimodal tasks. Experimental results demonstrate that
LLaVA-Octopus achieves excellent performance across multiple benchmarks,
especially in tasks such as multimodal understanding, visual question
answering, and video understanding, highlighting its broad application
potential.

摘要：在本文中，我們介紹 LLaVA-Octopus，一種新穎的多模態大型語言影片模型。LLaVA-Octopus 會根據使用者的指示，自適應地調整不同視覺投影器的特徵權重，使我們能夠利用每個投影器的互補優勢。我們觀察到不同的視覺投影器在處理特定任務時，會表現出不同的特徵。例如，有些投影器擅長擷取靜態細節，而有些則更有效地處理時間資訊，有些則更適合需要時間連貫性的任務。透過根據使用者的指示動態調整特徵權重，LLaVA-Octopus 會動態選擇並結合最合適的特徵，大幅提升模型在多模態任務中的表現。實驗結果證明，LLaVA-Octopus 在多個基準測試中都能達到極佳的表現，特別是在多模態理解、視覺問答和影片理解等任務中，突顯其廣泛的應用潛力。

##### **Improving Skeleton-based Action Recognition with Interactive Object Information**
2501.05066v1 by Hao Wen, Ziqian Lu, Fengli Shen, Zhe-Ming Lu, Jialin Cui

Human skeleton information is important in skeleton-based action recognition,
which provides a simple and efficient way to describe human pose. However,
existing skeleton-based methods focus more on the skeleton, ignoring the
objects interacting with humans, resulting in poor performance in recognizing
actions that involve object interactions. We propose a new action recognition
framework introducing object nodes to supplement absent interactive object
information. We also propose Spatial Temporal Variable Graph Convolutional
Networks (ST-VGCN) to effectively model the Variable Graph (VG) containing
object nodes. Specifically, in order to validate the role of interactive object
information, by leveraging a simple self-training approach, we establish a new
dataset, JXGC 24, and an extended dataset, NTU RGB+D+Object 60, including more
than 2 million additional object nodes. At the same time, we designe the
Variable Graph construction method to accommodate a variable number of nodes
for graph structure. Additionally, we are the first to explore the overfitting
issue introduced by incorporating additional object information, and we propose
a VG-based data augmentation method to address this issue, called Random Node
Attack. Finally, regarding the network structure, we introduce two fusion
modules, CAF and WNPool, along with a novel Node Balance Loss, to enhance the
comprehensive performance by effectively fusing and balancing skeleton and
object node information. Our method surpasses the previous state-of-the-art on
multiple skeleton-based action recognition benchmarks. The accuracy of our
method on NTU RGB+D 60 cross-subject split is 96.7\%, and on cross-view split,
it is 99.2\%.

摘要：人體骨骼資訊對於基於骨骼的動作辨識非常重要，這提供了描述人體姿勢的簡單且有效率的方法。然而，現有的基於骨骼的方法更專注於骨骼，忽略了與人類互動的物體，導致在辨識涉及物體互動的動作時效能不佳。我們提出一個新的動作辨識架構，引入物體節點來補充缺少的互動物體資訊。我們也提出時空變數圖形卷積網路 (ST-VGCN) 來有效地建模包含物體節點的變數圖形 (VG)。具體來說，為了驗證互動物體資訊的角色，我們透過利用一個簡單的自訓練方法，建立了一個新的資料集 JXGC 24 和一個擴充的資料集 NTU RGB+D+Object 60，包含超過 200 萬個額外的物體節點。同時，我們設計了變數圖形建構方法來容納圖形結構中變數的節點數量。此外，我們率先探討了加入額外物體資訊所造成的過度擬合問題，並提出一個基於 VG 的資料擴充方法來解決這個問題，稱為隨機節點攻擊。最後，關於網路結構，我們引入了兩個融合模組，CAF 和 WNPool，以及一個新穎的節點平衡損失，透過有效地融合和平衡骨骼和物體節點資訊來增強綜合效能。我們的模型超越了多個基於骨骼的動作辨識基準上的先前技術水準。我們的模型在 NTU RGB+D 60 交叉主體分割上的準確度為 96.7%，在交叉視角分割上的準確度為 99.2%。

##### **Simultaneous emulation and downscaling with physically-consistent deep learning-based regional ocean emulators**
2501.05058v1 by Leonard Lupin-Jimenez, Moein Darman, Subhashis Hazarika, Tianning Wu, Michael Gray, Ruyoing He, Anthony Wong, Ashesh Chattopadhyay

Building on top of the success in AI-based atmospheric emulation, we propose
an AI-based ocean emulation and downscaling framework focusing on the
high-resolution regional ocean over Gulf of Mexico. Regional ocean emulation
presents unique challenges owing to the complex bathymetry and lateral boundary
conditions as well as from fundamental biases in deep learning-based
frameworks, such as instability and hallucinations. In this paper, we develop a
deep learning-based framework to autoregressively integrate ocean-surface
variables over the Gulf of Mexico at $8$ Km spatial resolution without
unphysical drifts over decadal time scales and simulataneously downscale and
bias-correct it to $4$ Km resolution using a physics-constrained generative
model. The framework shows both short-term skills as well as accurate long-term
statistics in terms of mean and variability.

摘要：建立在以 AI 為基礎的大氣模擬的成功之上，我們提出一個以 AI 為基礎的海洋模擬和降尺度架構，專注於墨西哥灣的高解析度區域海洋。區域海洋模擬由於複雜的水深測量學和邊界條件，以及基於深度學習的架構（例如不穩定性和幻覺）中的基本偏差，因此呈現出獨特的挑戰。在本文中，我們開發了一個基於深度學習的架構，以自迴歸方式整合墨西哥灣的海面變數，空間解析度為 8 公里，在十年時間尺度上沒有非物理漂移，並且同時使用受物理約束的生成模型將其降尺度並校正偏差至 4 公里解析度。該架構在均值和變異性方面顯示了短期技能和準確的長期統計數據。

##### **TAPFed: Threshold Secure Aggregation for Privacy-Preserving Federated Learning**
2501.05053v1 by Runhua Xu, Bo Li, Chao Li, James B. D. Joshi, Shuai Ma, Jianxin Li

Federated learning is a computing paradigm that enhances privacy by enabling
multiple parties to collaboratively train a machine learning model without
revealing personal data. However, current research indicates that traditional
federated learning platforms are unable to ensure privacy due to privacy leaks
caused by the interchange of gradients. To achieve privacy-preserving federated
learning, integrating secure aggregation mechanisms is essential.
Unfortunately, existing solutions are vulnerable to recently demonstrated
inference attacks such as the disaggregation attack. This paper proposes
TAPFed, an approach for achieving privacy-preserving federated learning in the
context of multiple decentralized aggregators with malicious actors. TAPFed
uses a proposed threshold functional encryption scheme and allows for a certain
number of malicious aggregators while maintaining security and privacy. We
provide formal security and privacy analyses of TAPFed and compare it to
various baselines through experimental evaluation. Our results show that TAPFed
offers equivalent performance in terms of model quality compared to
state-of-the-art approaches while reducing transmission overhead by 29%-45%
across different model training scenarios. Most importantly, TAPFed can defend
against recently demonstrated inference attacks caused by curious aggregators,
which the majority of existing approaches are susceptible to.

摘要：聯邦學習是一種運算範例，它透過讓多方合作訓練機器學習模型，而無需揭露個人資料，來增強隱私。然而，目前的研究所顯示，傳統的聯邦學習平台無法確保隱私，這是因為梯度的交換會導致隱私外洩。若要達成保護隱私的聯邦學習，整合安全的聚合機制至關重要。不幸的是，現有的解決方案容易受到最近展示的推論攻擊，例如去聚合攻擊。本文提出 TAPFed，一種在有惡意參與者的多個分散式聚合器環境中，達成保護隱私的聯邦學習的方法。TAPFed 使用一種提出的閾值函數加密方案，並允許一定數量的惡意聚合器，同時維護安全性與隱私。我們提供 TAPFed 的正式安全與隱私分析，並透過實驗評估將其與各種基準進行比較。我們的結果顯示，與最先進的方法相比，TAPFed 在模型品質方面提供同等的效能，同時在不同的模型訓練場景中，將傳輸負擔降低了 29%-45%。最重要的是，TAPFed 可以防禦最近展示的，由好奇的聚合器所造成的推論攻擊，而現有方法的大多數都容易受到這種攻擊。

##### **SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution**
2501.05040v1 by Chengxing Xie, Bowen Li, Chang Gao, He Du, Wai Lam, Difan Zou, Kai Chen

Large Language Models (LLMs) have demonstrated remarkable proficiency across
a variety of complex tasks. One significant application of LLMs is in tackling
software engineering challenges, particularly in resolving real-world tasks on
GitHub by fixing code based on the issues reported by the users. However, many
current approaches rely on proprietary LLMs, which limits reproducibility,
accessibility, and transparency. The critical components of LLMs for addressing
software engineering issues and how their capabilities can be effectively
enhanced remain unclear. To address these challenges, we introduce SWE-Fixer, a
novel open-source LLM designed to effectively and efficiently resolve GitHub
issues. SWE-Fixer comprises two essential modules: a code file retrieval module
and a code editing module. The retrieval module employs BM25 along with a
lightweight LLM model to achieve coarse-to-fine file retrieval. Subsequently,
the code editing module utilizes the other LLM model to generate patches for
the identified files. Then, to mitigate the lack of publicly available
datasets, we compile an extensive dataset that includes 110K GitHub issues
along with their corresponding patches, and train the two modules of SWE-Fixer
separately. We assess our approach on the SWE-Bench Lite and Verified
benchmarks, achieving state-of-the-art performance among open-source models
with scores of 23.3% and 30.2%, respectively. These outcomes highlight the
efficacy of our approach. We will make our model, dataset, and code publicly
available at https://github.com/InternLM/SWE-Fixer.

摘要：大型語言模型 (LLM) 已在各種複雜任務中展現出非凡的能力。LLM 的一項重要應用是解決軟體工程挑戰，特別是透過修復使用者回報問題中的程式碼，來解決 GitHub 上的實際任務。然而，許多現有方法依賴於專有 LLM，這限制了可複製性、可存取性和透明度。LLM 解決軟體工程問題的重要組成部分及其能力如何有效增強仍不清楚。為了應對這些挑戰，我們引入了 SWE-Fixer，這是一個新穎的開源 LLM，旨在有效且高效地解決 GitHub 問題。SWE-Fixer 包含兩個必要的模組：程式碼檔案擷取模組和程式碼編輯模組。擷取模組採用 BM25 以及輕量級 LLM 模型，以實現由粗到細的檔案擷取。隨後，程式碼編輯模組利用另一個 LLM 模型，為識別的檔案產生修補程式。接著，為了減輕公開可用資料集的不足，我們編譯了一個包含 110K 個 GitHub 問題及其對應修補程式的廣泛資料集，並分別訓練 SWE-Fixer 的兩個模組。我們在 SWE-Bench Lite 和 Verified 評量基準上評估了我們的做法，在開源模型中取得了最先進的效能，分別獲得 23.3% 和 30.2% 的分數。這些成果突顯了我們方法的有效性。我們將在 https://github.com/InternLM/SWE-Fixer 公開我們的模型、資料集和程式碼。

##### **Enhancing Human-Like Responses in Large Language Models**
2501.05032v1 by Ethem Yağız Çalık, Talha Rüzgar Akkuş

This paper explores the advancements in making large language models (LLMs)
more human-like. We focus on techniques that enhance natural language
understanding, conversational coherence, and emotional intelligence in AI
systems. The study evaluates various approaches, including fine-tuning with
diverse datasets, incorporating psychological principles, and designing models
that better mimic human reasoning patterns. Our findings demonstrate that these
enhancements not only improve user interactions but also open new possibilities
for AI applications across different domains. Future work will address the
ethical implications and potential biases introduced by these human-like
attributes.

摘要：本文探討了讓大型語言模型 (LLM) 更接近人類的進展。我們專注於增強人工智慧系統中自然語言理解、對話連貫性和情緒智力的技術。本研究評估了各種方法，包括使用多元資料集進行微調、納入心理原則，以及設計更能模擬人類推理模式的模型。我們的研究結果表明，這些增強不僅改善了使用者互動，也為不同領域的人工智慧應用開啟了新的可能性。後續研究將探討這些類人屬性帶來的倫理意涵和潛在偏見。

##### **A General Retrieval-Augmented Generation Framework for Multimodal Case-Based Reasoning Applications**
2501.05030v1 by Ofir Marom

Case-based reasoning (CBR) is an experience-based approach to problem
solving, where a repository of solved cases is adapted to solve new cases.
Recent research shows that Large Language Models (LLMs) with
Retrieval-Augmented Generation (RAG) can support the Retrieve and Reuse stages
of the CBR pipeline by retrieving similar cases and using them as additional
context to an LLM query. Most studies have focused on text-only applications,
however, in many real-world problems the components of a case are multimodal.
In this paper we present MCBR-RAG, a general RAG framework for multimodal CBR
applications. The MCBR-RAG framework converts non-text case components into
text-based representations, allowing it to: 1) learn application-specific
latent representations that can be indexed for retrieval, and 2) enrich the
query provided to the LLM by incorporating all case components for better
context. We demonstrate MCBR-RAG's effectiveness through experiments conducted
on a simplified Math-24 application and a more complex Backgammon application.
Our empirical results show that MCBR-RAG improves generation quality compared
to a baseline LLM with no contextual information provided.

摘要：基於案例的推理 (CBR) 是一種以經驗為基礎的問題解決方法，其中會調整已解決案例的儲存庫來解決新案例。最近的研究顯示，具備檢索增強生成 (RAG) 的大型語言模型 (LLM) 可以透過檢索類似案例並將其用作 LLM 查詢的附加內容，來支援 CBR 管道的檢索和重複使用階段。大多數研究都專注於純文字應用程式，然而，在許多實際問題中，案例的組成是多模態的。在本文中，我們提出 MCBR-RAG，一個適用於多模態 CBR 應用程式的通用 RAG 框架。MCBR-RAG 框架將非文字案例組成轉換為基於文字的表示，使其能夠：1) 學習可供檢索編製索引的應用程式特定潛在表示，以及 2) 透過納入所有案例組成來豐富提供給 LLM 的查詢，以獲得更好的內容。我們透過在簡化的 Math-24 應用程式和更複雜的西洋雙陸棋應用程式上進行的實驗，證明了 MCBR-RAG 的有效性。我們的實證結果顯示，與沒有提供背景資訊的基本 LLM 相比，MCBR-RAG 改善了生成品質。

##### **Finding Needles in Emb(a)dding Haystacks: Legal Document Retrieval via Bagging and SVR Ensembles**
2501.05018v1 by Kevin Bönisch, Alexander Mehler

We introduce a retrieval approach leveraging Support Vector Regression (SVR)
ensembles, bootstrap aggregation (bagging), and embedding spaces on the German
Dataset for Legal Information Retrieval (GerDaLIR). By conceptualizing the
retrieval task in terms of multiple binary needle-in-a-haystack subtasks, we
show improved recall over the baselines (0.849 > 0.803 | 0.829) using our
voting ensemble, suggesting promising initial results, without training or
fine-tuning any deep learning models. Our approach holds potential for further
enhancement, particularly through refining the encoding models and optimizing
hyperparameters.

摘要：我們引入了一種檢索方法，利用支持向量迴歸 (SVR)
集成、bootstrap 聚合 (bagging) 和德語法律資訊檢索 (GerDaLIR) 資料集上的嵌入空間。透過將
檢索任務概念化為多個二元大海撈針子任務，我們
使用我們的投票集成，顯示出比基線更高的召回率 (0.849 > 0.803 | 0.829)，這表明有希望的初步結果，而無需訓練或
微調任何深度學習模型。我們的做法有進一步增強的潛力，特別是透過調整編碼模型和最佳化
超參數。

##### **UAV-VLA: Vision-Language-Action System for Large Scale Aerial Mission Generation**
2501.05014v1 by Oleg Sautenkov, Yasheerah Yaqoot, Artem Lykov, Muhammad Ahsan Mustafa, Grik Tadevosyan, Aibek Akhmetkazy, Miguel Altamirano Cabrera, Mikhail Martynov, Sausar Karaf, Dzmitry Tsetserukou

The UAV-VLA (Visual-Language-Action) system is a tool designed to facilitate
communication with aerial robots. By integrating satellite imagery processing
with the Visual Language Model (VLM) and the powerful capabilities of GPT,
UAV-VLA enables users to generate general flight paths-and-action plans through
simple text requests. This system leverages the rich contextual information
provided by satellite images, allowing for enhanced decision-making and mission
planning. The combination of visual analysis by VLM and natural language
processing by GPT can provide the user with the path-and-action set, making
aerial operations more efficient and accessible. The newly developed method
showed the difference in the length of the created trajectory in 22% and the
mean error in finding the objects of interest on a map in 34.22 m by Euclidean
distance in the K-Nearest Neighbors (KNN) approach.

摘要：無人機-VLA（視覺語言動作）系統是一個工具，旨在促進與空中機器人的溝通。通過將衛星圖像處理與視覺語言模型 (VLM) 和 GPT 的強大功能整合在一起，無人機-VLA 使用戶能夠通過簡單的文字請求生成通用的飛行路徑和行動計畫。此系統利用衛星圖像提供的豐富背景資訊，從而增強決策制定和任務規劃。VLM 的視覺分析和 GPT 的自然語言處理相結合，可以為使用者提供路徑和動作集，使空中作業更有效率且更容易使用。新開發的方法顯示出在 22% 中建立軌跡的長度差異，以及在 K 最近鄰 (KNN) 方法中，通過歐幾里得距離在 34.22 公尺中找到地圖上感興趣物體的平均誤差。

##### **Quantum-enhanced causal discovery for a small number of samples**
2501.05007v1 by Yota Maeda, Ken Arai, Yu Tanaka, Yu Terada, Hiroshi Ueno, Hiroyuki Tezuka

The discovery of causal relationships from observed data has attracted
significant interest from disciplines such as economics, social sciences,
epidemiology, and biology. In practical applications, considerable knowledge of
the underlying systems is often unavailable, and real data are often associated
with nonlinear causal structures, which make the direct use of most
conventional causality analysis methods difficult. This study proposes a novel
quantum Peter-Clark (qPC) algorithm for causal discovery that does not assume
any underlying model structures. Based on the independence conditional tests in
a class of reproducing kernel Hilbert spaces characterized by quantum circuits,
the proposed qPC algorithm can explore causal relationships from the observed
data drawn from arbitrary distributions. We conducted systematic experiments on
fundamental graph parts of causal structures, demonstrating that the qPC
algorithm exhibits a significantly better performance, particularly with
smaller sample sizes compared to its classical counterpart. Furthermore, we
proposed a novel optimization approach based on Kernel Target Alignment (KTA)
for determining hyperparameters of quantum kernels. This method effectively
reduced the risk of false positives in causal discovery, enabling more reliable
inference. Our theoretical and experimental results demonstrate that the
proposed quantum algorithm can empower classical algorithms for robust and
accurate inference in causal discovery, supporting them in regimes where
classical algorithms typically fail. Additionally, the effectiveness of this
method was validated using the Boston Housing dataset as a real-world
application. These findings demonstrate the new potential of quantum
circuit-based causal discovery methods in addressing practical challenges,
particularly in small-sample scenarios where traditional approaches have shown
limitations.

摘要：<paragraph>從觀察到的資料中發現因果關係，已引起經濟學、社會科學、流行病學和生物學等領域的極大興趣。在實際應用中，通常無法獲得對基礎系統的充分了解，而真實資料通常與非線性因果結構相關，這使得直接使用大多數傳統因果關係分析方法變得困難。本研究提出了一種新穎的量子 Peter-Clark (qPC) 演算法，用於因果發現，不假設任何基礎模型結構。基於量子電路表徵的一類再生核希爾伯特空間中的獨立條件測試，提出的 qPC 演算法可以從任意分佈中提取的觀察資料中探索因果關係。我們對因果結構的基本圖形部分進行了系統實驗，證明 qPC 演算法表現出顯著更好的效能，特別是在與其經典對應物相比，樣本量較小的情況下。此外，我們提出了一種基於核目標對齊 (KTA) 的新穎最佳化方法，用於確定量子核的超參數。此方法有效降低了因果發現中假陽性的風險，實現了更可靠的推論。我們的理論和實驗結果表明，所提出的量子演算法可以增強經典演算法在因果發現中穩健且準確的推論，在經典演算法通常會失敗的狀態下為其提供支援。此外，使用波士頓住房資料集作為真實世界的應用，驗證了此方法的有效性。這些發現展示了基於量子電路的因果發現方法在應對實際挑戰方面的新潛力，特別是在傳統方法已顯示出限制的小樣本場景中。</paragraph>

##### **GiNet: Integrating Sequential and Context-Aware Learning for Battery Capacity Prediction**
2501.04997v1 by Sara Sameer, Wei Zhang, Xin Lou, Qingyu Yan, Terence Goh, Yulin Gao

The surging demand for batteries requires advanced battery management
systems, where battery capacity modelling is a key functionality. In this
paper, we aim to achieve accurate battery capacity prediction by learning from
historical measurements of battery dynamics. We propose GiNet, a gated
recurrent units enhanced Informer network, for predicting battery's capacity.
The novelty and competitiveness of GiNet lies in its capability of capturing
sequential and contextual information from raw battery data and reflecting the
battery's complex behaviors with both temporal dynamics and long-term
dependencies. We conducted an experimental study based on a publicly available
dataset to showcase GiNet's strength of gaining a holistic understanding of
battery behavior and predicting battery capacity accurately. GiNet achieves
0.11 mean absolute error for predicting the battery capacity in a sequence of
future time slots without knowing the historical battery capacity. It also
outperforms the latest algorithms significantly with 27% error reduction on
average compared to Informer. The promising results highlight the importance of
customized and optimized integration of algorithm and battery knowledge and
shed light on other industry applications as well.

摘要：電池需求激增需要進階電池管理系統，其中電池容量建模是一項關鍵功能。在本文中，我們旨在透過學習電池動態的歷史測量值來實現準確的電池容量預測。我們提出 GiNet，一個閘控遞迴單元增強的 Informer 網路，用於預測電池容量。GiNet 的新穎性和競爭力在於它能夠從原始電池資料中擷取順序和背景資訊，並反映電池的複雜行為，同時具有時間動態和長期依賴性。我們根據公開可用的資料集進行了一項實驗研究，以展示 GiNet 在全面了解電池行為和準確預測電池容量方面的優勢。GiNet 在不知道歷史電池容量的情況下，對於預測未來時段序列中的電池容量，平均絕對誤差為 0.11。與 Informer 相比，它也大幅優於最新的演算法，平均錯誤減少 27%。這些有希望的結果突顯了演算法和電池知識的客製化和最佳化整合的重要性，並也為其他產業應用提供了啟示。

##### **IPDN: Image-enhanced Prompt Decoding Network for 3D Referring Expression Segmentation**
2501.04995v1 by Qi Chen, Changli Wu, Jiayi Ji, Yiwei Ma, Danni Yang, Xiaoshuai Sun

3D Referring Expression Segmentation (3D-RES) aims to segment point cloud
scenes based on a given expression. However, existing 3D-RES approaches face
two major challenges: feature ambiguity and intent ambiguity. Feature ambiguity
arises from information loss or distortion during point cloud acquisition due
to limitations such as lighting and viewpoint. Intent ambiguity refers to the
model's equal treatment of all queries during the decoding process, lacking
top-down task-specific guidance. In this paper, we introduce an Image enhanced
Prompt Decoding Network (IPDN), which leverages multi-view images and
task-driven information to enhance the model's reasoning capabilities. To
address feature ambiguity, we propose the Multi-view Semantic Embedding (MSE)
module, which injects multi-view 2D image information into the 3D scene and
compensates for potential spatial information loss. To tackle intent ambiguity,
we designed a Prompt-Aware Decoder (PAD) that guides the decoding process by
deriving task-driven signals from the interaction between the expression and
visual features. Comprehensive experiments demonstrate that IPDN outperforms
the state-ofthe-art by 1.9 and 4.2 points in mIoU metrics on the 3D-RES and
3D-GRES tasks, respectively.

摘要：3D 參考表達分割 (3D-RES) 旨在根據給定的表達式對點雲場景進行分割。然而，現有的 3D-RES 方法面臨兩大挑戰：特徵模糊和意圖模糊。特徵模糊是由於點雲採集過程中由於照明和視點等限制而導致的信息丟失或失真。意圖模糊是指模型在解碼過程中對所有查詢進行平等處理，缺乏自上而下的任務特定指導。在本文中，我們引入了一個圖像增強提示解碼網絡 (IPDN)，它利用多視圖圖像和任務驅動信息來增強模型的推理能力。為了解決特徵模糊的問題，我們提出了多視圖語義嵌入 (MSE) 模塊，它將多視圖 2D 圖像信息注入到 3D 場景中，並彌補了潛在的空間信息丟失。為了解決意圖模糊的問題，我們設計了一個提示感知解碼器 (PAD)，它通過從表達式和視覺特徵之間的交互中推導出任務驅動信號來指導解碼過程。綜合實驗表明，IPDN 在 3D-RES 和 3D-GRES 任務的 mIoU 指標上分別比最先進的技術高出 1.9 和 4.2 個點。

##### **TreeKV: Smooth Key-Value Cache Compression with Tree Structures**
2501.04987v1 by Ziwei He, Jian Yuan, Haoli Bai, Jingwen Leng, Bo Jiang

Efficient key-value (KV) cache compression is critical for scaling
transformer-based Large Language Models (LLMs) in long sequences and
resource-limited settings. Existing methods evict tokens based on their
positions or importance scores, but position-based strategies can miss crucial
information outside predefined regions, while those relying on global
importance scores resulting in strong regional biases, limiting the KV cache's
overall context retention and potentially impairing the performance of LLMs on
complex tasks. Our wavelet analysis reveals that as tokens approach the end of
sequence, their contributions to generation gradually increase and tends to
diverge more from neighboring tokens, indicating a smooth transition with
increasing complexity and variability from distant to nearby context. Motivated
by this observation, we propose TreeKV, an intuitive, training-free method that
employs a tree structure for smooth cache compression. TreeKV maintains a fixed
cache size, allowing LLMs to deliver high-quality output even in long text
scenarios. Unlike most compression methods, TreeKV is applicable to both the
generation and prefilling stages. It consistently surpasses all baseline models
in language modeling tasks on PG19 and OpenWebText2, allowing LLMs trained with
short context window to generalize to longer window with a 16x cache reduction.
On the Longbench benchmark, TreeKV achieves the best performance with only 6\%
of the budget at optimal efficiency.

摘要：高效的鍵值 (KV) 快取壓縮對於縮放大型語言模型 (LLM) 中的Transformer在長序列和資源受限的設定中至關重要。現有方法基於它們的位置或重要性分數驅逐符號，但基於位置的策略可能會錯失預定義區域外的關鍵資訊，而依賴於全球重要性分數的策略則會導致強烈的區域偏誤，限制 KV 快取的整體內容保留，並可能損害 LLM 在複雜任務上的效能。我們的波段分析顯示，當符號接近序列的尾端時，它們對生成的貢獻會逐漸增加，並且傾向於與鄰近符號有更多差異，這表示從遠處到附近的內容具有平穩的轉換，且複雜性和可變性增加。受到此觀察的啟發，我們提出 TreeKV，這是一種直覺且無需訓練的方法，它採用樹狀結構進行平穩的快取壓縮。TreeKV 維護固定的快取大小，讓 LLM 即使在長文字場景中也能提供高品質的輸出。與大多數壓縮方法不同，TreeKV 可應用於生成和預先填入階段。它在 PG19 和 OpenWebText2 上的語言建模任務中持續超越所有基準模型，讓使用短內容視窗訓練的 LLM 能夠概括為較長的視窗，快取減少 16 倍。在 Longbench 基準測試中，TreeKV 以最佳效率僅 6% 的預算達成最佳效能。

##### **CuRLA: Curriculum Learning Based Deep Reinforcement Learning for Autonomous Driving**
2501.04982v1 by Bhargava Uppuluri, Anjel Patel, Neil Mehta, Sridhar Kamath, Pratyush Chakraborty

In autonomous driving, traditional Computer Vision (CV) agents often struggle
in unfamiliar situations due to biases in the training data. Deep Reinforcement
Learning (DRL) agents address this by learning from experience and maximizing
rewards, which helps them adapt to dynamic environments. However, ensuring
their generalization remains challenging, especially with static training
environments. Additionally, DRL models lack transparency, making it difficult
to guarantee safety in all scenarios, particularly those not seen during
training. To tackle these issues, we propose a method that combines DRL with
Curriculum Learning for autonomous driving. Our approach uses a Proximal Policy
Optimization (PPO) agent and a Variational Autoencoder (VAE) to learn safe
driving in the CARLA simulator. The agent is trained using two-fold curriculum
learning, progressively increasing environment difficulty and incorporating a
collision penalty in the reward function to promote safety. This method
improves the agent's adaptability and reliability in complex environments, and
understand the nuances of balancing multiple reward components from different
feedback signals in a single scalar reward function. Keywords: Computer Vision,
Deep Reinforcement Learning, Variational Autoencoder, Proximal Policy
Optimization, Curriculum Learning, Autonomous Driving.

摘要：在自動駕駛中，傳統的電腦視覺 (CV) 代理在訓練資料的偏差下，經常在不熟悉的環境中掙扎。深度強化學習 (DRL) 代理通過從經驗中學習和最大化獎勵來解決這個問題，這有助於它們適應動態環境。然而，確保它們的泛化仍然具有挑戰性，特別是在靜態訓練環境中。此外，DRL 模型缺乏透明度，這使得難以保證在所有場景中的安全性，特別是在訓練過程中沒有見過的場景。為了解決這些問題，我們提出了一種將 DRL 與課程學習相結合的方法，用於自動駕駛。我們的做法使用近端策略優化 (PPO) 代理和變分自動編碼器 (VAE) 來學習在 CARLA 模擬器中安全駕駛。該代理使用兩倍課程學習進行訓練，逐步增加環境難度，並在獎勵函數中加入碰撞懲罰以促進安全性。這種方法提高了代理在複雜環境中的適應性和可靠性，並且了解了在單個標量獎勵函數中平衡來自不同回饋信號的 multiple reward 組件的細微差別。關鍵字：電腦視覺、深度強化學習、變分自動編碼器、近端策略優化、課程學習、自動駕駛。

##### **SensorQA: A Question Answering Benchmark for Daily-Life Monitoring**
2501.04974v1 by Benjamin Reichman, Xiaofan Yu, Lanxiang Hu, Jack Truxal, Atishay Jain, Rushil Chandrupatla, Tajana Šimunić Rosing, Larry Heck

With the rapid growth in sensor data, effectively interpreting and
interfacing with these data in a human-understandable way has become crucial.
While existing research primarily focuses on learning classification models,
fewer studies have explored how end users can actively extract useful insights
from sensor data, often hindered by the lack of a proper dataset. To address
this gap, we introduce \Dataset, the first human-created question-answering
(QA) dataset for long-term time-series sensor data for daily life monitoring.
\Dataset is created by human workers and includes 5.6K diverse and practical
queries that reflect genuine human interests, paired with accurate answers
derived from sensor data. We further establish benchmarks for state-of-the-art
AI models on this dataset and evaluate their performance on typical edge
devices. Our results reveal a gap between current models and optimal QA
performance and efficiency, highlighting the need for new contributions. The
dataset and code are available at:
\url{https://github.com/benjamin-reichman/SensorQA}.

摘要：隨著感測器資料快速成長，以人類可理解的方式有效解讀和介接這些資料已變得至關重要。雖然現有研究主要專注於學習分類模型，但較少研究探討最終使用者如何能主動從感測器資料中提取有用的見解，這通常受到缺乏適當資料集的阻礙。為了解決這個差距，我們引入了 \Dataset，這是第一個由人類建立的長期時間序列感測器資料問答 (QA) 資料集，用於日常生活監控。\Dataset 是由人類工作者建立的，包含 5.6K 個反映真實人類興趣的多元且實用的查詢，並配對從感測器資料衍生的準確答案。我們進一步為這個資料集建立了最先進 AI 模型的基準，並評估它們在典型邊緣裝置上的效能。我們的結果揭露了當前模型與最佳 QA 效能和效率之間的差距，突顯了對新貢獻的需求。資料集和程式碼可在以下位置取得：\url{https://github.com/benjamin-reichman/SensorQA}。

##### **Battling the Non-stationarity in Time Series Forecasting via Test-time Adaptation**
2501.04970v1 by HyunGi Kim, Siwon Kim, Jisoo Mok, Sungroh Yoon

Deep Neural Networks have spearheaded remarkable advancements in time series
forecasting (TSF), one of the major tasks in time series modeling. Nonetheless,
the non-stationarity of time series undermines the reliability of pre-trained
source time series forecasters in mission-critical deployment settings. In this
study, we introduce a pioneering test-time adaptation framework tailored for
TSF (TSF-TTA). TAFAS, the proposed approach to TSF-TTA, flexibly adapts source
forecasters to continuously shifting test distributions while preserving the
core semantic information learned during pre-training. The novel utilization of
partially-observed ground truth and gated calibration module enables proactive,
robust, and model-agnostic adaptation of source forecasters. Experiments on
diverse benchmark datasets and cutting-edge architectures demonstrate the
efficacy and generality of TAFAS, especially in long-term forecasting scenarios
that suffer from significant distribution shifts. The code is available at
https://github.com/kimanki/TAFAS.

摘要：深度神经网络引领了时间序列预测 (TSF) 的显着进步，时间序列建模中的主要任务之一。尽管如此，时间序列的非平稳性会破坏预训练源时间序列预测器在任务关键部署设置中的可靠性。在这项研究中，我们引入了一个针对 TSF（TSF-TTA）量身定制的开创性测试时间自适应框架。TAFAS 是针对 TSF-TTA 的提议方法，它灵活地调整源预测器以持续转移测试分布，同时保留预训练期间学习的核心语义信息。部分观察到的基本事实和门控校准模块的新颖利用使得源预测器的主动、稳健和与模型无关的自适应成为可能。在各种基准数据集和前沿架构上的实验表明了 TAFAS 的有效性和普遍性，尤其是在遭受显着分布变化的长​​期预测场景中。代码可在 https://github.com/kimanki/TAFAS 获得。

##### **VoxEval: Benchmarking the Knowledge Understanding Capabilities of End-to-End Spoken Language Models**
2501.04962v1 by Wenqian Cui, Xiaoqi Jiao, Ziqiao Meng, Irwin King

With the growing demand for developing speech-based interaction models,
end-to-end Spoken Language Models (SLMs) have emerged as a promising solution.
When engaging in conversations with humans, it is essential for these models to
comprehend a wide range of world knowledge. In this paper, we introduce
VoxEval, a novel speech question-answering benchmark specifically designed to
assess SLMs' knowledge understanding through purely speech-based interactions.
Unlike existing AudioQA benchmarks, VoxEval maintains speech format for both
questions and answers, evaluates model robustness across diverse audio
conditions (varying timbres, audio qualities, and speaking styles), and
pioneers the assessment of challenging domains like mathematical
problem-solving in spoken format. Our comprehensive evaluation of recent SLMs
using VoxEval reveals significant performance limitations in current models,
highlighting crucial areas for future improvements.

摘要：隨著對開發基於語音的互動模式需求日益增長，端到端的口語語言模型 (SLM) 已成為一種有前途的解決方案。在與人類對話時，這些模型必須理解廣泛的世界知識。在本文中，我們介紹 VoxEval，這是一個新穎的語音問答基準，專門設計用於透過純粹基於語音的互動來評估 SLM 的知識理解。與現有的 AudioQA 基準不同，VoxEval 維持了問題和答案的語音格式，評估了模型在不同音訊條件（不同的音色、音訊品質和說話風格）下的穩健性，並率先評估了以口語格式進行數學問題解決等具有挑戰性的領域。我們使用 VoxEval 對最近的 SLM 進行綜合評估，揭示了當前模型在效能上的顯著限制，強調了未來改進的重要領域。

##### **Demystifying Domain-adaptive Post-training for Financial LLMs**
2501.04961v1 by Zixuan Ke, Yifei Ming, Xuan-Phi Nguyen, Caiming Xiong, Shafiq Joty

Domain-adaptive post-training of large language models (LLMs) has emerged as
a promising approach for specialized domains such as medicine and finance.
However, significant challenges remain in identifying optimal adaptation
criteria and training strategies across varying data and model configurations.
To address these challenges, we introduce FINDAP, a systematic and fine-grained
investigation into domain-adaptive post-training of LLMs for the finance
domain. Our approach begins by identifying the core capabilities required for
the target domain and designing a comprehensive evaluation suite aligned with
these needs. We then analyze the effectiveness of key post-training stages,
including continual pretraining, instruction tuning, and preference alignment.
Building on these insights, we propose an effective training recipe centered on
a novel preference data distillation method, which leverages process signals
from a generative reward model. The resulting model, Llama-Fin, achieves
state-of-the-art performance across a wide range of financial tasks. Our
analysis also highlights how each post-training stage contributes to distinct
capabilities, uncovering specific challenges and effective solutions, providing
valuable insights for domain adaptation of LLMs. Project page:
https://github.com/SalesforceAIResearch/FinDap

摘要：大型語言模型 (LLM) 的領域適應後訓練已成為醫學和金融等專業領域中一種有前途的方法。
然而，在確定最佳適應標準和跨不同數據和模型配置的訓練策略方面，仍然存在重大挑戰。
為了應對這些挑戰，我們引入了 FINDAP，這是一種對 LLM 的金融領域適應後訓練進行系統且細緻的調查。我們的做法首先是確定目標領域所需的核心能力，並設計一個與這些需求相一致的綜合評估套件。然後，我們分析關鍵後訓練階段的有效性，包括持續預訓練、指令微調和偏好對齊。根據這些見解，我們提出了一個以新穎的偏好數據蒸餾方法為中心的有效訓練配方，該方法利用生成獎勵模型中的過程信號。由此產生的模型 Llama-Fin 在廣泛的金融任務中實現了最先進的性能。我們的分析還強調了每個後訓練階段如何促成不同的能力，揭示具體的挑戰和有效的解決方案，為 LLM 的領域適應提供了有價值的見解。專案頁面：
https://github.com/SalesforceAIResearch/FinDap

##### **Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment**
2501.04958v1 by Lei Li, Xinglin Zhang, Jun Liang, Tao Chen

Deep learning models in medical imaging face dual challenges: domain shift,
where models perform poorly when deployed in settings different from their
training environment, and class imbalance, where certain disease conditions are
naturally underrepresented. We present Imbalance-Aware Domain Adaptation
(IADA), a novel framework that simultaneously tackles both challenges through
three key components: (1) adaptive feature learning with class-specific
attention mechanisms, (2) balanced domain alignment with dynamic weighting, and
(3) adaptive threshold optimization. Our theoretical analysis establishes
convergence guarantees and complexity bounds. Through extensive experiments on
embryo development assessment across four imaging modalities, IADA demonstrates
significant improvements over existing methods, achieving up to 25.19\% higher
accuracy while maintaining balanced performance across classes. In challenging
scenarios with low-quality imaging systems, IADA shows robust generalization
with AUC improvements of up to 12.56\%. These results demonstrate IADA's
potential for developing reliable and equitable medical imaging systems for
diverse clinical settings. The code is made public available at
\url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}

摘要：<paragraph>醫療影像中的深度學習模型面臨雙重挑戰：領域轉移，模型在與其訓練環境不同的設定中部署時表現不佳，以及類別不平衡，某些疾病狀況在自然界中代表性不足。我們提出不平衡感知域適應 (IADA)，這是一個新穎的框架，透過三個關鍵組成部分同時應對這兩個挑戰：(1) 具有類別特定注意力機制的自適應特徵學習，(2) 具有動態加權的平衡域對齊，以及 (3) 自適應閾值最佳化。我們的理論分析建立了收斂保證和複雜度界限。透過對四種影像模式的胚胎發育評估進行廣泛的實驗，IADA 證明了對現有方法的顯著改進，在維持類別間平衡性能的同時，準確度提高了 25.19%。在低品質影像系統的挑戰性場景中，IADA 以高達 12.56% 的 AUC 改進顯示出強大的泛化能力。這些結果證明了 IADA 在為不同的臨床設定開發可靠且公平的醫療影像系統方面的潛力。程式碼已公開於 \url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}</paragraph>

##### **Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models**
2501.04945v1 by Qingyu Ren, Jie Zeng, Qianyu He, Jiaqing Liang, Yanghua Xiao, Weikang Zhou, Zeye Sun, Fei Yu

It is crucial for large language models (LLMs) to follow instructions that
involve multiple constraints. However, soft constraints are semantically
related and difficult to verify through automated methods. These constraints
remain a significant challenge for LLMs. To enhance the ability of LLMs to
follow soft constraints, we initially design a pipeline to obtain high-quality
outputs automatically. Additionally, to fully utilize the acquired data, we
introduce a training paradigm based on curriculum learning. We experimentally
evaluate the effectiveness of our methods in improving LLMs' soft constraint
following ability and analyze the factors driving the improvements. The
datasets and code are publicly available at
https://github.com/Rainier-rq/FollowSoftConstraints.

摘要：對於大型語言模型 (LLM) 來說，遵循包含多重約束的指令至關重要。然而，軟約束在語義上相關，且難以透過自動化方法驗證。這些約束對於 LLM 來說仍然是一項重大挑戰。為了增強 LLM 遵循軟約束的能力，我們最初設計了一個管道以自動取得高品質的輸出。此外，為了充分利用所取得的資料，我們引入了基於課程學習的訓練範例。我們透過實驗評估了我們的方法在改善 LLM 軟約束遵循能力方面的有效性，並分析了促成這些改善的因素。資料集和程式碼已公開於 https://github.com/Rainier-rq/FollowSoftConstraints。

##### **Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency**
2501.04931v1 by Shiji Zhao, Ranjie Duan, Fengxiang Wang, Chi Chen, Caixin Kang, Jialing Tao, YueFeng Chen, Hui Xue, Xingxing Wei

Multimodal Large Language Models (MLLMs) have achieved impressive performance
and have been put into practical use in commercial applications, but they still
have potential safety mechanism vulnerabilities. Jailbreak attacks are red
teaming methods that aim to bypass safety mechanisms and discover MLLMs'
potential risks. Existing MLLMs' jailbreak methods often bypass the model's
safety mechanism through complex optimization methods or carefully designed
image and text prompts. Despite achieving some progress, they have a low attack
success rate on commercial closed-source MLLMs. Unlike previous research, we
empirically find that there exists a Shuffle Inconsistency between MLLMs'
comprehension ability and safety ability for the shuffled harmful instruction.
That is, from the perspective of comprehension ability, MLLMs can understand
the shuffled harmful text-image instructions well. However, they can be easily
bypassed by the shuffled harmful instructions from the perspective of safety
ability, leading to harmful responses. Then we innovatively propose a
text-image jailbreak attack named SI-Attack. Specifically, to fully utilize the
Shuffle Inconsistency and overcome the shuffle randomness, we apply a
query-based black-box optimization method to select the most harmful shuffled
inputs based on the feedback of the toxic judge model. A series of experiments
show that SI-Attack can improve the attack's performance on three benchmarks.
In particular, SI-Attack can obviously improve the attack success rate for
commercial MLLMs such as GPT-4o or Claude-3.5-Sonnet.

摘要：多模態大型語言模型 (MLLM) 已取得令人印象深刻的表現，並已實際應用於商業應用中，但它們仍具有潛在的安全機制漏洞。越獄攻擊是旨在繞過安全機制並發現 MLLM 潛在風險的紅隊方法。現有的 MLLM 越獄方法通常透過複雜的最佳化方法或精心設計的影像和文字提示，來繞過模型的安全機制。儘管取得了一些進展，但它們對商業閉源 MLLM 的攻擊成功率很低。與先前的研究不同，我們憑經驗發現，對於混洗的惡意指令，MLLM 的理解能力和安全性之間存在混洗不一致性。也就是說，從理解能力的角度來看，MLLM 能夠很好地理解混洗的惡意文字影像指令。然而，從安全性的角度來看，它們很容易被混洗的惡意指令繞過，導致產生惡意的回應。然後，我們創新地提出了一種名為 SI-Attack 的文字影像越獄攻擊。具體來說，為了充分利用混洗不一致性並克服混洗的隨機性，我們應用基於查詢的黑盒最佳化方法，根據有毒判斷模型的回饋來選擇最有害的混洗輸入。一系列的實驗表明，SI-Attack 可以提高三個基準測試的攻擊效能。特別是，SI-Attack 可以顯著提高對商業 MLLM（例如 GPT-4o 或 Claude-3.5-Sonnet）的攻擊成功率。

##### **Image2CADSeq: Computer-Aided Design Sequence and Knowledge Inference from Product Images**
2501.04928v1 by Xingang Li, Zhenghui Sha

Computer-aided design (CAD) tools empower designers to design and modify 3D
models through a series of CAD operations, commonly referred to as a CAD
sequence. In scenarios where digital CAD files are not accessible, reverse
engineering (RE) has been used to reconstruct 3D CAD models. Recent advances
have seen the rise of data-driven approaches for RE, with a primary focus on
converting 3D data, such as point clouds, into 3D models in boundary
representation (B-rep) format. However, obtaining 3D data poses significant
challenges, and B-rep models do not reveal knowledge about the 3D modeling
process of designs. To this end, our research introduces a novel data-driven
approach with an Image2CADSeq neural network model. This model aims to reverse
engineer CAD models by processing images as input and generating CAD sequences.
These sequences can then be translated into B-rep models using a solid modeling
kernel. Unlike B-rep models, CAD sequences offer enhanced flexibility to modify
individual steps of model creation, providing a deeper understanding of the
construction process of CAD models. To quantitatively and rigorously evaluate
the predictive performance of the Image2CADSeq model, we have developed a
multi-level evaluation framework for model assessment. The model was trained on
a specially synthesized dataset, and various network architectures were
explored to optimize the performance. The experimental and validation results
show great potential for the model in generating CAD sequences from 2D image
data.

摘要：<paragraph>電腦輔助設計 (CAD) 工具讓設計師能夠透過一系列的 CAD 作業（通常稱為 CAD 順序）來設計和修改 3D 模型。在無法取得數位 CAD 檔案的情況下，逆向工程 (RE) 已被用於重建 3D CAD 模型。最近的進展已看到資料驅動方法在 RE 中的崛起，主要專注於將 3D 資料（例如點雲）轉換成邊界表示 (B-rep) 格式的 3D 模型。然而，取得 3D 資料會造成顯著的挑戰，而且 B-rep 模型並未揭露關於設計的 3D 建模程序的知識。為此，我們的研究引進了一種新穎的資料驅動方法，並採用 Image2CADSeq 神經網路模型。此模型旨在透過處理影像作為輸入和產生 CAD 順序來逆向工程 CAD 模型。這些順序接著可以使用實體建模核心轉換成 B-rep 模型。與 B-rep 模型不同，CAD 順序提供增強的彈性來修改模型建立的個別步驟，提供對 CAD 模型建構程序的更深入理解。為了量化且嚴謹地評估 Image2CADSeq 模型的預測效能，我們已開發一個多層級評估架構用於模型評估。此模型是根據特別合成的資料集進行訓練，並探索了各種網路架構以最佳化效能。實驗和驗證結果顯示此模型在從 2D 影像資料產生 CAD 順序方面具有極大的潛力。</paragraph>

##### **Investigating Numerical Translation with Large Language Models**
2501.04927v1 by Wei Tang, Jiawei Yu, Yuang Li, Yanqing Zhao, Weidong Zhang, Wei Feng, Min Zhang, Hao Yang

The inaccurate translation of numbers can lead to significant security
issues, ranging from financial setbacks to medical inaccuracies. While large
language models (LLMs) have made significant advancements in machine
translation, their capacity for translating numbers has not been thoroughly
explored. This study focuses on evaluating the reliability of LLM-based machine
translation systems when handling numerical data. In order to systematically
test the numerical translation capabilities of currently open source LLMs, we
have constructed a numerical translation dataset between Chinese and English
based on real business data, encompassing ten types of numerical translation.
Experiments on the dataset indicate that errors in numerical translation are a
common issue, with most open-source LLMs faltering when faced with our test
scenarios. Especially when it comes to numerical types involving large units
like ``million", ``billion", and "yi", even the latest llama3.1 8b model can
have error rates as high as 20%. Finally, we introduce three potential
strategies to mitigate the numerical mistranslations for large units.

摘要：數字不準確的翻譯可能導致重大安全問題，從財務挫折到醫療不準確。儘管大型語言模型 (LLM) 在機器翻譯方面取得了重大進展，但它們翻譯數字的能力尚未得到徹底探討。本研究的重點是評估基於 LLM 的機器翻譯系統在處理數字數據時的可靠性。為了系統地測試當前開源 LLM 的數字翻譯能力，我們根據真實業務數據構建了中英之間的數字翻譯數據集，涵蓋十種類型的數字翻譯。數據集上的實驗表明，數字翻譯中的錯誤是一個常見問題，大多數開源 LLM 在面對我們的測試場景時都會出現錯誤。特別是當涉及到涉及「百萬」、「十億」和「億」等大單位的數字類型時，即使是最新款的 llama3.1 8b 模型的錯誤率也可能高達 20%。最後，我們介紹了三種潛在策略來減輕大單位的數字錯誤翻譯。

##### **FLowHigh: Towards Efficient and High-Quality Audio Super-Resolution with Single-Step Flow Matching**
2501.04926v1 by Jun-Hak Yun, Seung-Bin Kim, Seong-Whan Lee

Audio super-resolution is challenging owing to its ill-posed nature.
Recently, the application of diffusion models in audio super-resolution has
shown promising results in alleviating this challenge. However, diffusion-based
models have limitations, primarily the necessity for numerous sampling steps,
which causes significantly increased latency when synthesizing high-quality
audio samples. In this paper, we propose FLowHigh, a novel approach that
integrates flow matching, a highly efficient generative model, into audio
super-resolution. We also explore probability paths specially tailored for
audio super-resolution, which effectively capture high-resolution audio
distributions, thereby enhancing reconstruction quality. The proposed method
generates high-fidelity, high-resolution audio through a single-step sampling
process across various input sampling rates. The experimental results on the
VCTK benchmark dataset demonstrate that FLowHigh achieves state-of-the-art
performance in audio super-resolution, as evaluated by log-spectral distance
and ViSQOL while maintaining computational efficiency with only a single-step
sampling process.

摘要：音频超分辨率因其不良特性而具有挑战性。
最近，扩散模型在音频超分辨率中的应用在缓解这一挑战方面显示出有希望的结果。然而，基于扩散的模型有其局限性，主要是需要大量的采样步骤，这在合成高质量音频样本时会导致延迟显着增加。在本文中，我们提出了 FLowHigh，这是一种新颖的方法，将流匹配（一种高效的生成模型）集成到音频超分辨率中。我们还探索了专门针对音频超分辨率设计的概率路径，该路径有效地捕获了高分辨率音频分布，从而提高了重建质量。所提出的方法通过跨各种输入采样率的单步采样过程生成高保真、高分辨率音频。VCTK 基准数据集上的实验结果表明，FLowHigh 在音频超分辨率方面实现了最先进的性能，如对数频谱距离和 ViSQOL 所评估的那样，同时仅通过单步采样过程保持计算效率。

##### **JELLY: Joint Emotion Recognition and Context Reasoning with LLMs for Conversational Speech Synthesis**
2501.04904v1 by Jun-Hyeok Cha, Seung-Bin Kim, Hyung-Seok Oh, Seong-Whan Lee

Recently, there has been a growing demand for conversational speech synthesis
(CSS) that generates more natural speech by considering the conversational
context. To address this, we introduce JELLY, a novel CSS framework that
integrates emotion recognition and context reasoning for generating appropriate
speech in conversation by fine-tuning a large language model (LLM) with
multiple partial LoRA modules. We propose an Emotion-aware Q-former encoder,
which enables the LLM to perceive emotions in speech. The encoder is trained to
align speech emotions with text, utilizing datasets of emotional speech. The
entire model is then fine-tuned with conversational speech data to infer
emotional context for generating emotionally appropriate speech in
conversation. Our experimental results demonstrate that JELLY excels in
emotional context modeling, synthesizing speech that naturally aligns with
conversation, while mitigating the scarcity of emotional conversational speech
datasets.

摘要：最近，人们对会话式语音合成 (CSS) 的需求不断增长，它通过考虑会话语境来生成更自然的语音。为了解决这个问题，我们引入了 JELLY，这是一个新颖的 CSS 框架，它集成了情感识别和语境推理，以便通过使用多个部分 LoRA 模块微调大型语言模型 (LLM) 来生成对话中的适当语音。我们提出了一个情感感知 Q-former 编码器，它使 LLM 能够感知语音中的情感。该编码器经过训练，可以将语音情感与文本对齐，利用情感语音数据集。然后使用会话语音数据对整个模型进行微调，以推断情感语境，以便在对话中生成情感适当的语音。我们的实验结果表明，JELLY 在情感语境建模方面表现出色，合成了与对话自然对齐的语音，同时缓解了情感对话语音数据集的稀缺性。

##### **SUGAR: Leveraging Contextual Confidence for Smarter Retrieval**
2501.04899v1 by Hanna Zubkova, Ji-Hoon Park, Seong-Whan Lee

Bearing in mind the limited parametric knowledge of Large Language Models
(LLMs), retrieval-augmented generation (RAG) which supplies them with the
relevant external knowledge has served as an approach to mitigate the issue of
hallucinations to a certain extent. However, uniformly retrieving supporting
context makes response generation source-inefficient, as triggering the
retriever is not always necessary, or even inaccurate, when a model gets
distracted by noisy retrieved content and produces an unhelpful answer.
Motivated by these issues, we introduce Semantic Uncertainty Guided Adaptive
Retrieval (SUGAR), where we leverage context-based entropy to actively decide
whether to retrieve and to further determine between single-step and multi-step
retrieval. Our empirical results show that selective retrieval guided by
semantic uncertainty estimation improves the performance across diverse
question answering tasks, as well as achieves a more efficient inference.

摘要：考量到大型語言模型（LLM）有限的參數知識，檢索增強生成（RAG）為其提供相關外部知識，在一定程度上作為減輕幻覺問題的方法。然而，統一檢索支援的內容會讓回應生成來源效率低下，因為當模型被有雜訊的檢索內容分散注意力並產生無益的答案時，觸發檢索器並非總是必要的，甚至是不準確的。在這些問題的激勵下，我們引入了語義不確定性引導的自適應檢索（SUGAR），我們利用基於內容的熵來主動決定是否檢索，並進一步確定單步和多步檢索之間的區別。我們的實證結果表明，由語義不確定性估計引導的有選擇性檢索改善了各種問題回答任務的效能，並實現了更有效率的推理。

##### **Reach Measurement, Optimization and Frequency Capping In Targeted Online Advertising Under k-Anonymity**
2501.04882v1 by Yuan Gao, Mu Qiao

The growth in the use of online advertising to foster brand awareness over
recent years is largely attributable to the ubiquity of social media. One
pivotal technology contributing to the success of online brand advertising is
frequency capping, a mechanism that enables marketers to control the number of
times an ad is shown to a specific user. However, the very foundation of this
technology is being scrutinized as the industry gravitates towards advertising
solutions that prioritize user privacy. This paper delves into the issue of
reach measurement and optimization within the context of $k$-anonymity, a
privacy-preserving model gaining traction across major online advertising
platforms. We outline how to report reach within this new privacy landscape and
demonstrate how probabilistic discounting, a probabilistic adaptation of
traditional frequency capping, can be employed to optimize campaign
performance. Experiments are performed to assess the trade-off between user
privacy and the efficacy of online brand advertising. Notably, we discern a
significant dip in performance as long as privacy is introduced, yet this comes
with a limited additional cost for advertising platforms to offer their users
more privacy.

摘要：近年來，線上廣告的使用成長，用於培養品牌意識，這在很大程度上要歸功於社群媒體的普遍性。對線上品牌廣告成功有貢獻的一項關鍵技術是頻率上限，這是一種機制，使行銷人員能夠控制向特定使用者顯示廣告的次數。然而，隨著產業朝向優先考慮使用者隱私的廣告解決方案發展，這項技術的基礎正受到審查。本文深入探討在 $k$-匿名性的脈絡中觸及率測量和最佳化的問題，一種在主要線上廣告平台上獲得關注的隱私保護模型。我們概述如何在這個新的隱私環境中報告觸及率，並展示如何採用傳統頻率上限的機率性調整，機率性折扣，來最佳化廣告活動成效。進行實驗以評估使用者隱私與線上品牌廣告成效之間的取捨。值得注意的是，我們辨識出只要引入隱私，成效就會顯著下降，但對於廣告平台來說，這僅帶來有限的額外成本，讓他們能夠為使用者提供更多隱私。

##### **Leveraging Log Probabilities in Language Models to Forecast Future Events**
2501.04880v1 by Tommaso Soru, Jim Marshall

In the constantly changing field of data-driven decision making, accurately
predicting future events is crucial for strategic planning in various sectors.
The emergence of Large Language Models (LLMs) marks a significant advancement
in this area, offering advanced tools that utilise extensive text data for
prediction. In this industry paper, we introduce a novel method for AI-driven
foresight using LLMs. Building on top of previous research, we employ data on
current trends and their trajectories for generating forecasts on 15 different
topics. Subsequently, we estimate their probabilities via a multi-step approach
based on log probabilities. We show we achieve a Brier score of 0.186, meaning
a +26% improvement over random chance and a +19% improvement over
widely-available AI systems.

摘要：在資料驅動決策制定不斷變化的領域中，準確預測未來事件對於各個領域的策略規劃至關重要。大語言模型 (LLM) 的出現標誌著這方面的一個重大進展，它提供了先進的工具，利用廣泛的文字資料進行預測。在這篇產業論文中，我們介紹了一種使用 LLM 進行 AI 驅動預測的新方法。在先前研究的基礎上，我們採用有關當前趨勢及其軌跡的資料，對 15 個不同的主題進行預測。隨後，我們透過基於對數機率的多步驟方法來估計其機率。我們證明我們達到了 0.186 的布里爾分數，這表示比隨機機會提高了 +26%，比廣泛可用的 AI 系統提高了 +19%。

##### **Real-Time Textless Dialogue Generation**
2501.04877v1 by Long Mai, Julie Carson-Berndsen

Recent advancements in large language models (LLMs) have led to significant
progress in text-based dialogue systems. These systems can now generate
high-quality responses that are accurate and coherent across a wide range of
topics and tasks. However, spoken dialogue systems still lag behind in terms of
naturalness. They tend to produce robotic interactions, with issues such as
slow response times, overly generic or cautious replies, and a lack of natural
rhythm and fluid turn-taking. This shortcoming is largely due to the
over-reliance on the traditional cascaded design, which involve separate,
sequential components, as well as the use of text as an intermediate
representation. This paper propose a real-time, textless spoken dialogue
generation model (RTTL-DG) that aims to overcome these challenges. Our system
enables fluid turn-taking and generates responses with minimal delay by
processing streaming spoken conversation directly. Additionally, our model
incorporates backchannels, filters, laughter, and other paralinguistic signals,
which are often absent in cascaded dialogue systems, to create more natural and
human-like interactions. The implementations and generated samples are
available in our repository: https://github.com/mailong25/rts2s-dg

摘要：大型語言模型（LLM）的最新進展已大幅提升基於文字的對話系統。這些系統現在可以產生高品質的回應，準確且連貫，涵蓋廣泛的主題和任務。然而，口語對話系統在自然度方面仍落後。它們傾向於產生機器人式的互動，有諸如反應時間慢、回覆過於籠統或謹慎，以及缺乏自然節奏和流暢輪流發言等問題。這種缺點主要是過於依賴傳統的串聯式設計，其中涉及獨立的順序組件，以及使用文字作為中間表示。本文提出了一個即時、無文字的口語對話生成模型（RTTL-DG），旨在克服這些挑戰。我們的系統透過直接處理串流的口語對話來實現流暢的輪流發言，並以最短的延遲產生回應。此外，我們的模型納入了反向頻道、濾波器、笑聲和其他副語言訊號，這些訊號通常在串聯式對話系統中不存在，以創造更自然且更像人類的互動。實作和產生的範例可在我們的儲存庫中取得：https://github.com/mailong25/rts2s-dg

##### **Back Home: A Machine Learning Approach to Seashell Classification and Ecosystem Restoration**
2501.04873v1 by Alexander Valverde, Luis Solano

In Costa Rica, an average of 5 tons of seashells are extracted from
ecosystems annually. Confiscated seashells, cannot be returned to their
ecosystems due to the lack of origin recognition. To address this issue, we
developed a convolutional neural network (CNN) specifically for seashell
identification. We built a dataset from scratch, consisting of approximately
19000 images from the Pacific and Caribbean coasts. Using this dataset, the
model achieved a classification accuracy exceeding 85%. The model has been
integrated into a user-friendly application, which has classified over 36,000
seashells to date, delivering real-time results within 3 seconds per image. To
further enhance the system's accuracy, an anomaly detection mechanism was
incorporated to filter out irrelevant or anomalous inputs, ensuring only valid
seashell images are processed.

摘要：哥斯大黎加每年平均從生態系統中提取 5 噸的貝殼。沒收的貝殼由於缺乏來源識別，無法歸還到其生態系統中。為了解決此問題，我們特別開發了一個用於貝殼識別的卷積神經網路 (CNN)。我們從頭開始建立一個資料集，其中包含來自太平洋和加勒比海沿岸的大約 19000 張圖片。使用此資料集，該模型實現了超過 85% 的分類準確度。該模型已整合到一個使用者友善的應用程式中，迄今已分類超過 36,000 個貝殼，並在每張圖片 3 秒內提供即時結果。為了進一步提高系統的準確度，已整合一個異常偵測機制，以過濾掉不相關或異常的輸入，確保只處理有效的貝殼圖片。

##### **Advancing Retrieval-Augmented Generation for Persian: Development of Language Models, Comprehensive Benchmarks, and Best Practices for Optimization**
2501.04858v1 by Sara Bourbour Hosseinbeigi, Sina Asghari, Mohammad Ali Seif Kashani, Mohammad Hossein Shalchian, Mohammad Amin Abbasi

This paper examines the specific obstacles of constructing
Retrieval-Augmented Generation(RAG) systems in low-resource languages, with a
focus on Persian's complicated morphology and versatile syntax. The research
aims to improve retrieval and generation accuracy by introducing
Persian-specific models, namely MatinaRoberta(a masked language model) and
MatinaSRoberta(a fine-tuned Sentence-BERT), along with a comprehensive
benchmarking framework. Three datasets-general knowledge(PQuad), scientifically
specialized texts, and organizational reports, were used to assess these models
after they were trained on a varied corpus of 73.11 billion Persian tokens. The
methodology involved extensive pretraining, fine-tuning with tailored loss
functions, and systematic evaluations using both traditional metrics and the
Retrieval-Augmented Generation Assessment framework. The results show that
MatinaSRoberta outperformed previous embeddings, achieving superior contextual
relevance and retrieval accuracy across datasets. Temperature tweaking, chunk
size modifications, and document summary indexing were explored to enhance RAG
setups. Larger models like Llama-3.1 (70B) consistently demonstrated the
highest generation accuracy, while smaller models faced challenges with
domain-specific and formal contexts. The findings underscore the potential for
developing RAG systems in Persian through customized embeddings and
retrieval-generation settings and highlight the enhancement of NLP applications
such as search engines and legal document analysis in low-resource languages.

摘要：本論文探討了在低資源語言中建構檢索增強生成 (RAG) 系統的特定障礙，重點在於波斯語複雜的形態和多功能的語法。本研究旨在透過引入波斯語特定模型，即 MatinaRoberta（一個遮罩語言模型）和 MatinaSRoberta（一個微調過的句子 BERT），以及一個全面的基準測試框架，來改善檢索和生成準確度。在對包含 731.1 億個波斯語詞彙的各種語料庫進行訓練後，使用三個資料集（一般知識 (PQuad)、科學專業文本和組織報告）來評估這些模型。該方法涉及廣泛的預訓練、使用客製化損失函數進行微調，以及使用傳統指標和檢索增強生成評估框架進行系統評估。結果顯示，MatinaSRoberta 優於先前的嵌入，在所有資料集上都達到了更高的上下文相關性和檢索準確度。探索了溫度調整、區塊大小修改和文件摘要索引以增強 RAG 設定。像 Llama-3.1 (70B) 這樣較大的模型始終展現出最高的生成準確度，而較小的模型則在特定領域和正式語境中面臨挑戰。研究結果強調了透過自訂嵌入和檢索生成設定來開發波斯語 RAG 系統的潛力，並突顯了在低資源語言中增強自然語言處理應用程式（例如搜尋引擎和法律文件分析）的重要性。

##### **Exploring Large Language Models for Semantic Analysis and Categorization of Android Malware**
2501.04848v1 by Brandon J Walton, Mst Eshita Khatun, James M Ghawaly, Aisha Ali-Gombe

Malware analysis is a complex process of examining and evaluating malicious
software's functionality, origin, and potential impact. This arduous process
typically involves dissecting the software to understand its components,
infection vector, propagation mechanism, and payload. Over the years, deep
reverse engineering of malware has become increasingly tedious, mainly due to
modern malicious codebases' fast evolution and sophistication. Essentially,
analysts are tasked with identifying the elusive needle in the haystack within
the complexities of zero-day malware, all while under tight time constraints.
Thus, in this paper, we explore leveraging Large Language Models (LLMs) for
semantic malware analysis to expedite the analysis of known and novel samples.
Built on GPT-4o-mini model, \msp is designed to augment malware analysis for
Android through a hierarchical-tiered summarization chain and strategic prompt
engineering. Additionally, \msp performs malware categorization, distinguishing
potential malware from benign applications, thereby saving time during the
malware reverse engineering process. Despite not being fine-tuned for Android
malware analysis, we demonstrate that through optimized and advanced prompt
engineering \msp can achieve up to 77% classification accuracy while providing
highly robust summaries at functional, class, and package levels. In addition,
leveraging the backward tracing of the summaries from package to function
levels allowed us to pinpoint the precise code snippets responsible for
malicious behavior.

摘要：惡意軟體分析是檢查和評估惡意軟體功能、來源和潛在影響的複雜過程。這個艱難的過程通常涉及解剖軟體以了解其組成部分、感染媒介、傳播機制和負載。多年來，惡意軟體的深度逆向工程變得越來越繁瑣，主要是因為現代惡意程式碼庫的快速演變和複雜性。基本上，分析師的任務是在零時差惡意軟體的複雜性中找出難以捉摸的針頭，同時還要在嚴格的時間限制下進行。因此，在本文中，我們探討利用大型語言模型 (LLM) 進行語義惡意軟體分析，以加快已知和新樣本的分析。建立在 GPT-4o-mini 模型上，\msp 旨在透過分層摘要鏈和策略提示工程來擴充 Android 的惡意軟體分析。此外，\msp 執行惡意軟體分類，區分潛在惡意軟體與良性應用程式，從而節省惡意軟體逆向工程過程中的時間。儘管沒有針對 Android 惡意軟體分析進行微調，但我們證明透過最佳化和進階提示工程，\msp 可以達到高達 77% 的分類準確度，同時在功能、類別和套件層級提供高度穩健的摘要。此外，利用從套件到功能層級的摘要反向追蹤，讓我們可以精確找出負責惡意行為的程式碼片段。

##### **Enhancing Listened Speech Decoding from EEG via Parallel Phoneme Sequence Prediction**
2501.04844v1 by Jihwan Lee, Tiantian Feng, Aditya Kommineni, Sudarsana Reddy Kadiri, Shrikanth Narayanan

Brain-computer interfaces (BCI) offer numerous human-centered application
possibilities, particularly affecting people with neurological disorders. Text
or speech decoding from brain activities is a relevant domain that could
augment the quality of life for people with impaired speech perception. We
propose a novel approach to enhance listened speech decoding from
electroencephalography (EEG) signals by utilizing an auxiliary phoneme
predictor that simultaneously decodes textual phoneme sequences. The proposed
model architecture consists of three main parts: EEG module, speech module, and
phoneme predictor. The EEG module learns to properly represent EEG signals into
EEG embeddings. The speech module generates speech waveforms from the EEG
embeddings. The phoneme predictor outputs the decoded phoneme sequences in text
modality. Our proposed approach allows users to obtain decoded listened speech
from EEG signals in both modalities (speech waveforms and textual phoneme
sequences) simultaneously, eliminating the need for a concatenated sequential
pipeline for each modality. The proposed approach also outperforms previous
methods in both modalities. The source code and speech samples are publicly
available.

摘要：腦機介面 (BCI) 提供許多以人為中心的應用可能性，特別是影響神經疾病患者。從大腦活動中解碼文字或語音是一個相關領域，可以提升言語感知受損者的生活品質。我們提出一個新方法來增強從腦電圖 (EEG) 訊號中解碼聽到的語音，方法是利用一個輔助音素預測器，它同時解碼文字音素序列。所提出的模型架構包含三個主要部分：EEG 模組、語音模組和音素預測器。EEG 模組學習將 EEG 訊號適當地表示成 EEG 嵌入。語音模組從 EEG 嵌入中產生語音波形。音素預測器輸出以文字型態解碼的音素序列。我們提出的方法讓使用者能夠同時從 EEG 訊號中以兩種型態（語音波形和文字音素序列）取得解碼的聽力語音，消除了對每個型態串接順序管線的需求。所提出的方法在兩種型態中也優於先前的做法。原始碼和語音範例公開提供。

##### **Do Code LLMs Understand Design Patterns?**
2501.04835v1 by Zhenyu Pan, Xuefeng Song, Yunkun Wang, Rongyu Cao, Binhua Li, Yongbin Li, Han Liu

Code Large Language Models (LLMs) demonstrate great versatility in adapting
to various downstream tasks, including code generation and completion, as well
as bug detection and fixing. However, Code LLMs often fail to capture existing
coding standards, leading to the generation of code that conflicts with the
required design patterns for a given project. As a result, developers must
post-process to adapt the generated code to the project's design norms. In this
work, we empirically investigate the biases of Code LLMs in software
development. Through carefully designed experiments, we assess the models'
understanding of design patterns across recognition, comprehension, and
generation. Our findings reveal that biases in Code LLMs significantly affect
the reliability of downstream tasks.

摘要：大型語言模型 (LLM) 代碼展示出極佳的多功能性，可適應各種下游任務，包括代碼生成和完成，以及錯誤偵測和修正。然而，LLM 代碼經常無法捕捉現有的編碼標準，導致產生的代碼與給定專案所需的設計模式相衝突。因此，開發人員必須進行後處理，以適應產生的代碼至專案的設計規範。在這項工作中，我們從經驗上探討 LLM 代碼在軟體開發中的偏誤。透過精心設計的實驗，我們評估模型對設計模式的理解，涵蓋辨識、理解和生成。我們的發現顯示，LLM 代碼中的偏誤顯著影響了下游任務的可靠性。

##### **ActPC-Geom: Towards Scalable Online Neural-Symbolic Learning via Accelerating Active Predictive Coding with Information Geometry & Diverse Cognitive Mechanisms**
2501.04832v1 by Ben Goertzel

This paper introduces ActPC-Geom, an approach to accelerate Active Predictive
Coding (ActPC) in neural networks by integrating information geometry,
specifically using Wasserstein-metric-based methods for measure-dependent
gradient flows. We propose replacing KL-divergence in ActPC's predictive error
assessment with the Wasserstein metric, suggesting this may enhance network
robustness.
  To make this computationally feasible, we present strategies including: (1)
neural approximators for inverse measure-dependent Laplacians, (2) approximate
kernel PCA embeddings for low-rank approximations feeding into these
approximators, and (3) compositional hypervector embeddings derived from kPCA
outputs, with algebra optimized for fuzzy FCA lattices learned through neural
architectures analyzing network states.
  This results in an ActPC architecture capable of real-time online learning
and integrating continuous (e.g., transformer-like or Hopfield-net-like) and
discrete symbolic ActPC networks, including frameworks like OpenCog Hyperon or
ActPC-Chem for algorithmic chemistry evolution. Shared probabilistic,
concept-lattice, and hypervector models enable symbolic-subsymbolic
integration.
  Key features include (1) compositional reasoning via hypervector embeddings
in transformer-like architectures for tasks like commonsense reasoning, and (2)
Hopfield-net dynamics enabling associative long-term memory and
attractor-driven cognitive features.
  We outline how ActPC-Geom combines few-shot learning with online weight
updates, enabling deliberative thinking and seamless symbolic-subsymbolic
reasoning. Ideas from Galois connections are explored for efficient hybrid
ActPC/ActPC-Chem processing. Finally, we propose a specialized HPC design
optimized for real-time focused attention and deliberative reasoning tailored
to ActPC-Geom's demands.

摘要：<paragraph>本文介紹了 ActPC-Geom，一種透過整合資訊幾何來加速神經網路中主動預測編碼 (ActPC) 的方法，特別是使用基於 Wasserstein 度量的測度相關梯度流方法。我們建議以 Wasserstein 度量取代 ActPC 預測誤差評估中的 KL 分歧，並提出這可能會增強網路的穩健性。
為了讓這在運算上可行，我們提出了以下策略：(1) 逆測度相關拉普拉斯算子的神經近似器，(2) 近似核 PCA 嵌入，用於輸入這些近似器的低秩近似，以及 (3) 源自 kPCA 輸出的組合超向量嵌入，其中代數針對通過分析網路狀態的神經架構所學習到的模糊 FCA 格子進行最佳化。
這產生了一個 ActPC 架構，它能夠進行即時線上學習，並整合連續的 (例如類 Transformer 或類 Hopfield 網路) 和離散符號 ActPC 網路，包括用於演算法化學演化的 OpenCog Hyperon 或 ActPC-Chem 等架構。共用機率、概念格子和超向量模型實現了符號次符號整合。
主要特點包括 (1) 透過類 Transformer 架構中的超向量嵌入進行組合推理，以執行常識推理等任務，以及 (2) Hopfield 網路動態，實現聯想長期記憶和吸引子驅動的認知特徵。
我們概述了 ActPC-Geom 如何將少量學習與線上權重更新結合，從而實現審慎思考和無縫的符號次符號推理。探索了來自伽羅瓦連接的想法，以進行有效的混合 ActPC/ActPC-Chem 處理。最後，我們提出了一種針對 ActPC-Geom 需求進行最佳化的特殊 HPC 設計，針對即時焦點注意和審慎推理進行了最佳化。</paragraph>

##### **Building Foundations for Natural Language Processing of Historical Turkish: Resources and Models**
2501.04828v1 by Şaziye Betül Özateş, Tarık Emre Tıraş, Ece Elif Adak, Berat Doğan, Fatih Burak Karagöz, Efe Eren Genç, Esma F. Bilgin Taşdemir

This paper introduces foundational resources and models for natural language
processing (NLP) of historical Turkish, a domain that has remained
underexplored in computational linguistics. We present the first named entity
recognition (NER) dataset, HisTR and the first Universal Dependencies treebank,
OTA-BOUN for a historical form of the Turkish language along with
transformer-based models trained using these datasets for named entity
recognition, dependency parsing, and part-of-speech tagging tasks.
Additionally, we introduce Ottoman Text Corpus (OTC), a clean corpus of
transliterated historical Turkish texts that spans a wide range of historical
periods. Our experimental results show significant improvements in the
computational analysis of historical Turkish, achieving promising results in
tasks that require understanding of historical linguistic structures. They also
highlight existing challenges, such as domain adaptation and language
variations across time periods. All of the presented resources and models are
made available at https://huggingface.co/bucolin to serve as a benchmark for
future progress in historical Turkish NLP.

摘要：這篇論文介紹了自然語言處理 (NLP) 的基礎資源和模型，用於處理歷史土耳其語，這是一個在計算語言學中仍未被充分探索的領域。我們提出了第一個命名實體識別 (NER) 資料集 HisTR 和第一個通用依存樹庫 OTA-BOUN，用於歷史形式的土耳其語，以及使用這些資料集訓練的變換器模型，用於命名實體識別、依存句法分析和詞性標記任務。此外，我們還介紹了鄂圖曼文本語料庫 (OTC)，這是一個乾淨的轉寫歷史土耳其語文本語料庫，涵蓋了廣泛的歷史時期。我們的實驗結果顯示，歷史土耳其語的計算分析有了顯著的改進，在需要理解歷史語言結構的任務中取得了有希望的結果。它們還突出了現有的挑戰，例如領域適應和跨時代的語言變異。所有提出的資源和模型都可以在 https://huggingface.co/bucolin 上獲得，作為歷史土耳其語 NLP 未來進展的基準。

##### **Intelligent Gradient Boosting Algorithms for Estimating Strength of Modified Subgrade Soil**
2501.04826v1 by Ismail B. Mustapha, Muyideen Abdulkareem, Shafaatunnur Hasan, Abideen Ganiyu, Hatem Nabus, Jin Chai Lee

The performance of pavement under loading depends on the strength of the
subgrade. However, experimental estimation of properties of pavement strengths
such as California bearing ratio (CBR), unconfined compressive strength (UCS)
and resistance value (R) are often tedious, time-consuming and costly, thereby
inspiring a growing interest in machine learning based tools which are simple,
cheap and fast alternatives. Thus, the potential application of two boosting
techniques; categorical boosting (CatBoost) and extreme gradient boosting
(XGBoost) and support vector regression (SVR), is similarly explored in this
study for estimation of properties of subgrade soil modified with hydrated lime
activated rice husk ash (HARSH). Using 121 experimental data samples of varying
proportions of HARSH, plastic limit, liquid limit, plasticity index, clay
activity, optimum moisture content, and maximum dry density as input for CBR,
UCS and R estimation, four evaluation metrics namely coefficient of
determination (R2), root mean squared error (RMSE), mean absolute error (MAE)
and mean absolute percentage error (MAPE) are used to evaluate the models'
performance. The results indicate that XGBoost outperformed CatBoost and SVR in
estimating these properties, yielding R2 of 0.9994, 0.9995 and 0.9999 in
estimating the CBR, UCS and R respectively. Also, SVR outperformed CatBoost in
estimating the CBR and R with R2 of 0.9997 respectively. On the other hand,
CatBoost outperformed SVR in estimating the UCS with R2 of 0.9994. Feature
sensitivity analysis shows that the three machine learning techniques are
unanimous that increasing HARSH proportion lead to values of the estimated
properties respectively. A comparison with previous results also shows
superiority of XGBoost in estimating subgrade properties.

摘要：路面在受載荷作用下的效能取決於路基的強度。然而，路面強度性質的實驗估計，例如加州承載比 (CBR)、無側限抗壓強度 (UCS) 和抗力值 (R) 通常繁瑣、耗時且成本高昂，因此激發了人們對基於機器學習的工具的興趣，這些工具簡單、便宜且快速。因此，本研究同樣探討了兩種提升技術的潛在應用；分類提升 (CatBoost) 和極端梯度提升 (XGBoost) 和支持向量回歸 (SVR)，用於估計經由水合石灰活化稻殼灰 (HARSH) 改良的路基土的性質。使用 121 個不同比例 HARSH 的實驗數據樣本，塑性極限、液性極限、塑性指數、黏土活性、最佳含水量和最大乾密度作為 CBR、UCS 和 R 估計的輸入，四個評估指標，即決定係數 (R2)、均方根誤差 (RMSE)、平均絕對誤差 (MAE) 和平均絕對百分比誤差 (MAPE) 用於評估模型的效能。結果表明，XGBoost 在估計這些性質方面優於 CatBoost 和 SVR，在估計 CBR、UCS 和 R 時分別產生 0.9994、0.9995 和 0.9999 的 R2。此外，SVR 在估計 CBR 和 R 時優於 CatBoost，R2 分別為 0.9997。另一方面，CatBoost 在估計 UCS 時優於 SVR，R2 為 0.9994。特徵敏感性分析表明，三種機器學習技術一致認為，增加 HARSH 比例會導致估計性質的值分別增加。與先前的結果比較也顯示出 XGBoost 在估計路基性質方面的優越性。

##### **Unifying the Extremes: Developing a Unified Model for Detecting and Predicting Extremist Traits and Radicalization**
2501.04820v1 by Allison Lahnala, Vasudha Varadarajan, Lucie Flek, H. Andrew Schwartz, Ryan L. Boyd

The proliferation of ideological movements into extremist factions via social
media has become a global concern. While radicalization has been studied
extensively within the context of specific ideologies, our ability to
accurately characterize extremism in more generalizable terms remains
underdeveloped. In this paper, we propose a novel method for extracting and
analyzing extremist discourse across a range of online community forums. By
focusing on verbal behavioral signatures of extremist traits, we develop a
framework for quantifying extremism at both user and community levels. Our
research identifies 11 distinct factors, which we term ``The Extremist
Eleven,'' as a generalized psychosocial model of extremism. Applying our method
to various online communities, we demonstrate an ability to characterize
ideologically diverse communities across the 11 extremist traits. We
demonstrate the power of this method by analyzing user histories from members
of the incel community. We find that our framework accurately predicts which
users join the incel community up to 10 months before their actual entry with
an AUC of $>0.6$, steadily increasing to AUC ~0.9 three to four months before
the event. Further, we find that upon entry into an extremist forum, the users
tend to maintain their level of extremism within the community, while still
remaining distinguishable from the general online discourse. Our findings
contribute to the study of extremism by introducing a more holistic,
cross-ideological approach that transcends traditional, trait-specific models.

摘要：社群媒體上意識形態運動擴散到極端派系已成為全球關注的議題。雖然激進化已在特定意識形態的脈絡下廣泛研究，我們準確描述更普遍的極端主義的能力仍未發展。在本文中，我們提出了一種新穎的方法，用於擷取和分析各種線上社群論壇中的極端主義論述。透過聚焦於極端主義特質的口語行為特徵，我們開發了一個架構，用於量化使用者和社群層級的極端主義。我們的研究識別出 11 個不同的因素，我們稱之為「極端主義十一特質」，作為極端主義的廣泛心理社會模型。將我們的模型應用於各種線上社群，我們展示了描述 11 個極端主義特質中意識形態多元社群的能力。我們透過分析來自非自願獨身者社群成員的使用者歷史，展示了此方法的力量。我們發現，我們的架構準確預測了哪些使用者在實際加入前 10 個月就會加入非自願獨身者社群，AUC 超過 0.6，在事件發生前三到四個月穩定增加至 AUC ~0.9。此外，我們發現，使用者在進入極端主義論壇後，往往會在社群中維持其極端主義程度，同時仍然與一般的線上論述有所區別。我們的發現透過引入更全面、跨意識形態的方法，超越傳統的、特質特定的模型，對極端主義的研究有所貢獻。

##### **Decentralised Resource Sharing in TinyML: Wireless Bilayer Gossip Parallel SGD for Collaborative Learning**
2501.04817v1 by Ziyuan Bao, Eiman Kanjo, Soumya Banerjee, Hasib-Al Rashid, Tinoosh Mohsenin

With the growing computational capabilities of microcontroller units (MCUs),
edge devices can now support machine learning models. However, deploying
decentralised federated learning (DFL) on such devices presents key challenges,
including intermittent connectivity, limited communication range, and dynamic
network topologies. This paper proposes a novel framework, bilayer Gossip
Decentralised Parallel Stochastic Gradient Descent (GD PSGD), designed to
address these issues in resource-constrained environments. The framework
incorporates a hierarchical communication structure using Distributed Kmeans
(DKmeans) clustering for geographic grouping and a gossip protocol for
efficient model aggregation across two layers: intra-cluster and inter-cluster.
We evaluate the framework's performance against the Centralised Federated
Learning (CFL) baseline using the MCUNet model on the CIFAR-10 dataset under
IID and Non-IID conditions. Results demonstrate that the proposed method
achieves comparable accuracy to CFL on IID datasets, requiring only 1.8
additional rounds for convergence. On Non-IID datasets, the accuracy loss
remains under 8\% for moderate data imbalance. These findings highlight the
framework's potential to support scalable and privacy-preserving learning on
edge devices with minimal performance trade-offs.

摘要：隨著微控制器單元 (MCU) 的計算能力不斷提升，邊緣裝置現在可以支援機器學習模型。然而，在這些裝置上部署去中心化聯邦學習 (DFL) 會帶來一些關鍵挑戰，包括間歇性連線、有限的通訊範圍和動態網路拓撲。本文提出了一個創新的架構，稱為雙層八卦去中心化平行隨機梯度下降 (GD PSGD)，旨在解決資源受限環境中的這些問題。此架構採用層級式通訊結構，使用分散式 Kmeans (DKmeans) 群集進行地理分組，並使用八卦協定在兩個層級（群集內和群集間）進行有效率的模型聚合。我們使用 MCUNet 模型在 CIFAR-10 資料集上，在 IID 和 Non-IID 條件下評估此架構的效能，並將其與集中式聯邦學習 (CFL) 基準進行比較。結果顯示，所提出的方法在 IID 資料集上達到與 CFL 相當的準確度，僅需 1.8 個額外回合即可收斂。在 Non-IID 資料集上，在中等資料不平衡的情況下，準確度損失仍低於 8%。這些發現突顯了此架構在邊緣裝置上支援可擴充且隱私保護的學習的潛力，同時將效能取捨降至最低。

##### **Reproducing HotFlip for Corpus Poisoning Attacks in Dense Retrieval**
2501.04802v1 by Yongkang Li, Panagiotis Eustratiadis, Evangelos Kanoulas

HotFlip is a topical gradient-based word substitution method for attacking
language models. Recently, this method has been further applied to attack
retrieval systems by generating malicious passages that are injected into a
corpus, i.e., corpus poisoning. However, HotFlip is known to be computationally
inefficient, with the majority of time being spent on gradient accumulation for
each query-passage pair during the adversarial token generation phase, making
it impossible to generate an adequate number of adversarial passages in a
reasonable amount of time. Moreover, the attack method itself assumes access to
a set of user queries, a strong assumption that does not correspond to how
real-world adversarial attacks are usually performed. In this paper, we first
significantly boost the efficiency of HotFlip, reducing the adversarial
generation process from 4 hours per document to only 15 minutes, using the same
hardware. We further contribute experiments and analysis on two additional
tasks: (1) transfer-based black-box attacks, and (2) query-agnostic attacks.
Whenever possible, we provide comparisons between the original method and our
improved version. Our experiments demonstrate that HotFlip can effectively
attack a variety of dense retrievers, with an observed trend that its attack
performance diminishes against more advanced and recent methods. Interestingly,
we observe that while HotFlip performs poorly in a black-box setting,
indicating limited capacity for generalization, in query-agnostic scenarios its
performance is correlated to the volume of injected adversarial passages.

摘要：HotFlip 是一種主題梯度式的詞彙替換法，用於攻擊語言模型。最近，此方法已進一步應用於攻擊檢索系統，方法是生成惡意段落並將其注入語料庫，即語料庫中毒。然而，眾所周知，HotFlip 在計算上效率低下，大部分時間都花在對抗性令牌生成階段的每個查詢-段落對的梯度累積上，這使得無法在合理的時間內生成足夠數量的對抗性段落。此外，攻擊方法本身假設可以訪問一組使用者查詢，這是一個強有力的假設，與通常執行實際對抗性攻擊的方式不符。在本文中，我們首先大幅提升 HotFlip 的效率，使用相同的硬體，將對抗性生成過程從每個文件 4 小時縮短到僅 15 分鐘。我們進一步貢獻了對兩個額外任務的實驗和分析：(1) 基於傳輸的黑盒攻擊，以及 (2) 與查詢無關的攻擊。只要有可能，我們都會提供原始方法與我們改進版本之間的比較。我們的實驗表明，HotFlip 可以有效攻擊各種稠密檢索器，觀察到的趨勢是其攻擊性能會隨著更先進和更新的方法而降低。有趣的是，我們觀察到，雖然 HotFlip 在黑盒設置中表現不佳，表明其概化能力有限，但在與查詢無關的場景中，其性能與注入對抗性段落的數量相關。

##### **Cued Speech Generation Leveraging a Pre-trained Audiovisual Text-to-Speech Model**
2501.04799v1 by Sanjana Sankar, Martin Lenglet, Gerard Bailly, Denis Beautemps, Thomas Hueber

This paper presents a novel approach for the automatic generation of Cued
Speech (ACSG), a visual communication system used by people with hearing
impairment to better elicit the spoken language. We explore transfer learning
strategies by leveraging a pre-trained audiovisual autoregressive
text-to-speech model (AVTacotron2). This model is reprogrammed to infer Cued
Speech (CS) hand and lip movements from text input. Experiments are conducted
on two publicly available datasets, including one recorded specifically for
this study. Performance is assessed using an automatic CS recognition system.
With a decoding accuracy at the phonetic level reaching approximately 77%, the
results demonstrate the effectiveness of our approach.

摘要：本文提出了一種創新的方法，用於自動產生提示式語言 (ACSG)，這是一種視覺溝通系統，由聽力障礙人士使用，以更好地引出語言。我們透過利用預先訓練的視聽自迴歸文字轉語音模型 (AVTacotron2)，來探索轉移學習策略。此模型被重新編寫，以從文字輸入中推斷提示式語言 (CS) 的手部和唇部動作。實驗是在兩個公開可用的資料集上進行，其中一個是專門為這項研究而錄製。效能是使用自動 CS 辨識系統來評估。在音標層級的解碼準確度達到約 77%，結果證明了我們方法的有效性。

##### **Planarian Neural Networks: Evolutionary Patterns from Basic Bilateria Shaping Modern Artificial Neural Network Architectures**
2501.04700v1 by Ziyuan Huang, Mark Newman, Maria Vaida, Srikar Bellur, Roozbeh Sadeghian, Andrew Siu, Hui Wang, Kevin Huggins

This study examined the viability of enhancing the prediction accuracy of
artificial neural networks (ANNs) in image classification tasks by developing
ANNs with evolution patterns similar to those of biological neural networks.
ResNet is a widely used family of neural networks with both deep and wide
variants; therefore, it was selected as the base model for our investigation.
The aim of this study is to improve the image classification performance of
ANNs via a novel approach inspired by the biological nervous system
architecture of planarians, which comprises a brain and two nerve cords. We
believe that the unique neural architecture of planarians offers valuable
insights into the performance enhancement of ANNs. The proposed planarian
neural architecture-based neural network was evaluated on the CIFAR-10 and
CIFAR-100 datasets. Our results indicate that the proposed method exhibits
higher prediction accuracy than the baseline neural network models in image
classification tasks. These findings demonstrate the significant potential of
biologically inspired neural network architectures in improving the performance
of ANNs in a wide range of applications.

摘要：本研究探討了透過開發具有與生物神經網路相似的演化模式的人工神經網路 (ANN)，來提升人工神經網路在影像分類任務中預測精確度的可行性。ResNet 是一個廣泛使用的神經網路系列，具有深層和廣泛的變異；因此，它被選為我們研究的基本模型。本研究的目的是透過一種新穎的方法來提升人工神經網路的影像分類效能，此方法的靈感來自於扁蟲的生物神經系統架構，其中包含一個大腦和兩條神經索。我們相信扁蟲獨特的神經架構能為提升人工神經網路的效能提供有價值的見解。所提出的基於扁蟲神經架構的神經網路在 CIFAR-10 和 CIFAR-100 資料集上進行評估。我們的結果顯示，所提出的方法在影像分類任務中展現出比基準神經網路模型更高的預測精確度。這些發現證明了受生物啟發的神經網路架構在提升人工神經網路在廣泛應用中的效能方面具有顯著的潛力。

##### **Grokking at the Edge of Numerical Stability**
2501.04697v1 by Lucas Prieto, Melih Barsbey, Pedro A. M. Mediano, Tolga Birdal

Grokking, the sudden generalization that occurs after prolonged overfitting,
is a surprising phenomenon challenging our understanding of deep learning.
Although significant progress has been made in understanding grokking, the
reasons behind the delayed generalization and its dependence on regularization
remain unclear. In this work, we argue that without regularization, grokking
tasks push models to the edge of numerical stability, introducing floating
point errors in the Softmax function, which we refer to as Softmax Collapse
(SC). We demonstrate that SC prevents grokking and that mitigating SC enables
grokking without regularization. Investigating the root cause of SC, we find
that beyond the point of overfitting, the gradients strongly align with what we
call the na\"ive loss minimization (NLM) direction. This component of the
gradient does not alter the model's predictions but decreases the loss by
scaling the logits, typically by scaling the weights along their current
direction. We show that this scaling of the logits explains the delay in
generalization characteristic of grokking and eventually leads to SC, halting
further learning. To validate our hypotheses, we introduce two key
contributions that address the challenges in grokking tasks: StableMax, a new
activation function that prevents SC and enables grokking without
regularization, and $\perp$Grad, a training algorithm that promotes quick
generalization in grokking tasks by preventing NLM altogether. These
contributions provide new insights into grokking, elucidating its delayed
generalization, reliance on regularization, and the effectiveness of existing
grokking-inducing methods. Code for this paper is available at
https://github.com/LucasPrietoAl/grokking-at-the-edge-of-numerical-stability.

摘要：<paragraph>過擬合後突然發生的廣泛化，稱為「頓悟」，是一個令人驚訝的現象，挑戰了我們對深度學習的理解。雖然在理解頓悟方面已取得重大進展，但延遲廣泛化背後的原因及其對正則化的依賴性仍不清楚。在這項工作中，我們論證說，在沒有正則化的情況下，頓悟任務會將模型推到數值穩定性的邊緣，在 Softmax 函數中引入浮點誤差，我們稱之為 Softmax 崩潰 (SC)。我們證明 SC 會阻止頓悟，而減輕 SC 可以讓頓悟在沒有正則化的情況下發生。在調查 SC 的根本原因時，我們發現，在過擬合點之外，梯度與我們稱之為「樸素損失最小化」(NLM) 方向強烈對齊。梯度的這個組成部分不會改變模型的預測，但會透過調整 logit 來降低損失，通常是沿著其當前方向調整權重。我們表明，logit 的這種調整解釋了頓悟特有的廣泛化延遲，並最終導致 SC，阻礙進一步學習。為了驗證我們的假設，我們提出了兩個關鍵貢獻，以解決頓悟任務中的挑戰：StableMax，這是一個新的激活函數，可以防止 SC 並在沒有正則化的情況下實現頓悟，以及 $\perp$Grad，這是一種訓練演算法，透過完全防止 NLM，在頓悟任務中促進快速廣泛化。這些貢獻為頓悟提供了新的見解，闡明了其延遲廣泛化、對正則化的依賴性，以及現有頓悟誘導方法的有效性。本文的程式碼可在 https://github.com/LucasPrietoAl/grokking-at-the-edge-of-numerical-stability 取得。</paragraph>

##### **EpiCoder: Encompassing Diversity and Complexity in Code Generation**
2501.04694v1 by Yaoxiang Wang, Haoling Li, Xin Zhang, Jie Wu, Xiao Liu, Wenxiang Hu, Zhongxin Guo, Yangyu Huang, Ying Xin, Yujiu Yang, Jinsong Su, Qi Chen, Scarlett Li

Effective instruction tuning is indispensable for optimizing code LLMs,
aligning model behavior with user expectations and enhancing model performance
in real-world applications. However, most existing methods focus on code
snippets, which are limited to specific functionalities and rigid structures,
restricting the complexity and diversity of the synthesized data. To address
these limitations, we introduce a novel feature tree-based synthesis framework
inspired by Abstract Syntax Trees (AST). Unlike AST, which captures syntactic
structure of code, our framework models semantic relationships between code
elements, enabling the generation of more nuanced and diverse data. The feature
tree is constructed from raw data and refined iteratively to increase the
quantity and diversity of the extracted features. This process enables the
identification of more complex patterns and relationships within the code. By
sampling subtrees with controlled depth and breadth, our framework allows
precise adjustments to the complexity of the generated code, supporting a wide
range of tasks from simple function-level operations to intricate multi-file
scenarios. We fine-tuned widely-used base models to create the EpiCoder series,
achieving state-of-the-art performance at both the function and file levels
across multiple benchmarks. Notably, empirical evidence indicates that our
approach shows significant potential in synthesizing highly complex
repository-level code data. Further analysis elucidates the merits of this
approach by rigorously assessing data complexity and diversity through software
engineering principles and LLM-as-a-judge method.

摘要：有效的指令調整對於最佳化程式碼 LLM 至關重要，可將模型行為與使用者預期保持一致，並提升模型在實際應用中的效能。然而，現有的方法大多著重於程式碼片段，僅限於特定功能和僵化的結構，限制了合成資料的複雜性和多樣性。為了解決這些限制，我們引入一種新穎的基於特徵樹的合成架構，靈感來自抽象語法樹 (AST)。與擷取程式碼語法結構的 AST 不同，我們的架構會對程式碼元素之間的語意關係建模，能夠產生更細緻且多樣化的資料。特徵樹是由原始資料建構而成，並反覆精煉以增加提取特徵的數量和多樣性。此程序能識別程式碼中更複雜的模式和關係。透過以受控深度和廣度取樣子樹，我們的架構允許精確調整產生程式碼的複雜度，支援從簡單函式層級操作到複雜多檔案場景的各種任務。我們微調廣泛使用的基礎模型以建立 EpiCoder 系列，在函式和檔案層級上於多個基準測試中達成最先進的效能。值得注意的是，實證證據顯示，我們的做法在合成高度複雜的儲存庫層級程式碼資料方面具有顯著的潛力。進一步的分析透過軟體工程原則和 LLM 作為評判方法，嚴謹地評估資料的複雜性和多樣性，闡明此方法的優點。

##### **Beyond Sight: Finetuning Generalist Robot Policies with Heterogeneous Sensors via Language Grounding**
2501.04693v1 by Joshua Jones, Oier Mees, Carmelo Sferrazza, Kyle Stachowicz, Pieter Abbeel, Sergey Levine

Interacting with the world is a multi-sensory experience: achieving effective
general-purpose interaction requires making use of all available modalities --
including vision, touch, and audio -- to fill in gaps from partial observation.
For example, when vision is occluded reaching into a bag, a robot should rely
on its senses of touch and sound. However, state-of-the-art generalist robot
policies are typically trained on large datasets to predict robot actions
solely from visual and proprioceptive observations. In this work, we propose
FuSe, a novel approach that enables finetuning visuomotor generalist policies
on heterogeneous sensor modalities for which large datasets are not readily
available by leveraging natural language as a common cross-modal grounding. We
combine a multimodal contrastive loss with a sensory-grounded language
generation loss to encode high-level semantics. In the context of robot
manipulation, we show that FuSe enables performing challenging tasks that
require reasoning jointly over modalities such as vision, touch, and sound in a
zero-shot setting, such as multimodal prompting, compositional cross-modal
prompting, and descriptions of objects it interacts with. We show that the same
recipe is applicable to widely different generalist policies, including both
diffusion-based generalist policies and large vision-language-action (VLA)
models. Extensive experiments in the real world show that FuSeis able to
increase success rates by over 20% compared to all considered baselines.

摘要：與世界互動是一種多感官體驗：要達成有效的通用互動，必須利用所有可用的方式，包括視覺、觸覺和聽覺，以填補部分觀察的空白。例如，當視覺被遮蔽時，機器人應依賴其觸覺和聽覺。然而，最先進的通用機器人策略通常在大型資料集上訓練，以僅從視覺和本體感覺觀察來預測機器人的動作。在這項工作中，我們提出了 FuSe，一種新穎的方法，它能微調視覺運動通用策略，針對大型資料集不易取得的異質感測器模式，利用自然語言作為一種通用的跨模式基礎。我們將多模式對比損失與感官基礎語言生成損失結合，以編碼高層語義。在機器人操作的背景下，我們展示了 FuSe 能夠執行具有挑戰性的任務，這些任務需要在零次學習的設定中，對視覺、觸覺和聲音等模式進行聯合推理，例如多模式提示、組合式跨模式提示，以及與其互動的物體描述。我們展示了相同的配方適用於各種不同的通用策略，包括基於擴散的通用策略和大型視覺語言動作 (VLA) 模型。現實世界中的大量實驗表明，與所有考慮的基準線相比，FuSe 能夠將成功率提高 20% 以上。

##### **URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics**
2501.04686v1 by Ruilin Luo, Zhuofan Zheng, Yifan Wang, Yiyao Yu, Xinzhe Ni, Zicheng Lin, Jin Zeng, Yujiu Yang

Chain-of-thought (CoT) reasoning has been widely applied in the mathematical
reasoning of Large Language Models (LLMs). Recently, the introduction of
derivative process supervision on CoT trajectories has sparked discussions on
enhancing scaling capabilities during test time, thereby boosting the potential
of these models. However, in multimodal mathematical reasoning, the scarcity of
high-quality CoT training data has hindered existing models from achieving
high-precision CoT reasoning and has limited the realization of reasoning
potential during test time. In this work, we propose a three-module synthesis
strategy that integrates CoT distillation, trajectory-format rewriting, and
format unification. It results in a high-quality CoT reasoning instruction
fine-tuning dataset in multimodal mathematics, MMathCoT-1M. We comprehensively
validate the state-of-the-art (SOTA) performance of the trained URSA-7B model
on multiple multimodal mathematical benchmarks. For test-time scaling, we
introduce a data synthesis strategy that automatically generates process
annotation datasets, known as DualMath-1.1M, focusing on both interpretation
and logic. By further training URSA-7B on DualMath-1.1M, we transition from CoT
reasoning capabilities to robust supervision abilities. The trained URSA-RM-7B
acts as a verifier, effectively enhancing the performance of URSA-7B at test
time. URSA-RM-7B also demonstrates excellent out-of-distribution (OOD)
verifying capabilities, showcasing its generalization. Model weights, training
data and code will be open-sourced.

摘要：<paragraph>鏈條思考（CoT）推理已廣泛應用於大型語言模型（LLM）的數學推理中。最近，在 CoT 軌跡中引入導數過程監督，引發了關於在測試期間增強規模化能力的討論，從而提升了這些模型的潛力。然而，在多模態數學推理中，高品質 CoT 訓練資料的稀缺性阻礙了現有模型實現高精度的 CoT 推理，並限制了在測試期間實現推理潛力的可能性。在這項工作中，我們提出了一種三模組合成策略，它整合了 CoT 蒸餾、軌跡格式重寫和格式統一。它產生了一個高品質的 CoT 推理指令微調資料集，用於多模態數學，MMathCoT-1M。我們全面驗證了訓練後的 URSA-7B 模型在多個多模態數學基準上的最新技術（SOTA）效能。對於測試時間縮放，我們引入了一種資料合成策略，它自動產生過程註解資料集，稱為 DualMath-1.1M，重點關注解釋和邏輯。通過進一步訓練 URSA-7B 在 DualMath-1.1M 上，我們從 CoT 推理能力過渡到強大的監督能力。訓練後的 URSA-RM-7B 作為驗證器，有效地增強了 URSA-7B 在測試時間的效能。URSA-RM-7B 還展示了出色的分布外（OOD）驗證能力，展示了它的泛化性。模型權重、訓練資料和程式碼將會開源。</paragraph>

##### **Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought**
2501.04682v1 by Violet Xiang, Charlie Snell, Kanishk Gandhi, Alon Albalak, Anikait Singh, Chase Blagden, Duy Phung, Rafael Rafailov, Nathan Lile, Dakota Mahan, Louis Castricato, Jan-Philipp Franken, Nick Haber, Chelsea Finn

We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extends
traditional Chain-of-Thought (CoT) by explicitly modeling the underlying
reasoning required to arrive at a particular CoT. We present empirical evidence
from state-of-the-art models exhibiting behaviors consistent with in-context
search, and explore methods for producing Meta-CoT via process supervision,
synthetic data generation, and search algorithms. Finally, we outline a
concrete pipeline for training a model to produce Meta-CoTs, incorporating
instruction tuning with linearized search traces and reinforcement learning
post-training. Finally, we discuss open research questions, including scaling
laws, verifier roles, and the potential for discovering novel reasoning
algorithms. This work provides a theoretical and practical roadmap to enable
Meta-CoT in LLMs, paving the way for more powerful and human-like reasoning in
artificial intelligence.

摘要：我們提出了一個新穎的框架，元思考鏈 (Meta-CoT)，它通過明確建模得出特定 CoT 所需的基本推理來擴展傳統的思考鏈 (CoT)。我們展示了來自最先進模型的經驗證據，這些模型表現出與情境中搜尋一致的行為，並探索了通過流程監督、合成資料生成和搜尋演算法來產生 Meta-CoT 的方法。最後，我們概述了一個具體的管道，用於訓練模型以產生 Meta-CoT，其中包含線性化搜尋軌跡和強化學習後訓練的指令調整。最後，我們討論了開放的研究問題，包括規模定律、驗證者角色，以及發現新推理演算法的潛力。這項工作提供了一個理論和實務路線圖，以在 LLM 中啟用 Meta-CoT，為人工智慧中更強大且更類似人類的推理鋪平道路。

##### **TREAD: Token Routing for Efficient Architecture-agnostic Diffusion Training**
2501.04765v1 by Felix Krause, Timy Phan, Vincent Tao Hu, Björn Ommer

Diffusion models have emerged as the mainstream approach for visual
generation. However, these models usually suffer from sample inefficiency and
high training costs. This issue is particularly pronounced in the standard
diffusion transformer architecture due to its quadratic complexity relative to
input length. Recent works have addressed this by reducing the number of tokens
processed in the model, often through masking. In contrast, this work aims to
improve the training efficiency of the diffusion backbone by using predefined
routes that store this information until it is reintroduced to deeper layers of
the model, rather than discarding these tokens entirely. Further, we combine
multiple routes and introduce an adapted auxiliary loss that accounts for all
applied routes. Our method is not limited to the common transformer-based model
- it can also be applied to state-space models. Unlike most current approaches,
TREAD achieves this without architectural modifications. Finally, we show that
our method reduces the computational cost and simultaneously boosts model
performance on the standard benchmark ImageNet-1K 256 x 256 in
class-conditional synthesis. Both of these benefits multiply to a convergence
speedup of 9.55x at 400K training iterations compared to DiT and 25.39x
compared to the best benchmark performance of DiT at 7M training iterations.

摘要：擴散模型已成為視覺生成的主流方法。然而，這些模型通常會出現樣本效率低和訓練成本高的問題。這個問題在標準擴散Transformer架構中特別明顯，因為它的二次複雜度與輸入長度有關。最近的研究透過減少模型中處理的符號數量來解決這個問題，通常是透過遮罩。相比之下，這項工作旨在透過使用預定義路徑來改善擴散主幹的訓練效率，這些路徑會儲存這些資訊，直到將其重新引入到模型的更深層，而不是完全捨棄這些符號。此外，我們結合多條路徑並引入一個適應輔助損失，該損失會考量所有已套用的路徑。我們的模型不僅限於常見的基於Transformer的模型，它也可以應用於狀態空間模型。與大多數目前的方法不同，TREAD 在沒有架構修改的情況下實現了這一點。最後，我們證明了我們的模型減少了運算成本，同時在標準基準 ImageNet-1K 256 x 256 中提升了模型在類條件合成上的效能。與 DiT 相比，這兩個優點在 400K 訓練反覆運算中乘以 9.55 倍的收斂速度，與 DiT 在 7M 訓練反覆運算中的最佳基準效能相比，乘以 25.39 倍。

##### **Enhancing Financial VQA in Vision Language Models using Intermediate Structured Representations**
2501.04675v1 by Archita Srivastava, Abhas Kumar, Rajesh Kumar, Prabhakar Srinivasan

Chart interpretation is crucial for visual data analysis, but accurately
extracting information from charts poses significant challenges for automated
models. This study investigates the fine-tuning of DEPLOT, a modality
conversion module that translates the image of a plot or chart to a linearized
table, on a custom dataset of 50,000 bar charts. The dataset comprises simple,
stacked, and grouped bar charts, targeting the unique structural features of
these visualizations. The finetuned DEPLOT model is evaluated against its base
version using a test set of 1,000 images and two metrics: Relative Mapping
Similarity (RMS), which measures categorical mapping accuracy, and Relative
Number Set Similarity (RNSS), which evaluates numerical interpretation
accuracy. To further explore the reasoning capabilities of large language
models (LLMs), we curate an additional set of 100 bar chart images paired with
question answer sets. Our findings demonstrate that providing a structured
intermediate table alongside the image significantly enhances LLM reasoning
performance compared to direct image queries.

摘要：圖表解讀對於視覺資料分析至關重要，但從圖表中準確擷取資訊對於自動化模型來說是一項重大挑戰。本研究探討了 DEPLOT 的微調，這是一個將繪圖或圖表的影像轉換成線性化表格的模組化轉換模組，針對一個包含 50,000 個長條圖的客製化資料集。該資料集包含簡單、堆疊和群組長條圖，目標為這些視覺化的獨特結構特徵。微調後的 DEPLOT 模型使用一個包含 1,000 個影像和兩個指標的測試集，來評估它與基本版本的差異：相對應對相似度 (RMS)，用於衡量分類對應的準確度，以及相對數字集相似度 (RNSS)，用於評估數值解讀的準確度。為了進一步探索大型語言模型 (LLM) 的推理能力，我們策劃了一個額外的 100 張長條圖影像集，並配對問題解答集。我們的研究結果表明，與直接影像查詢相比，在影像旁邊提供一個結構化的中間表格，可以顯著增強 LLM 的推理效能。

##### **DRIVINGVQA: Analyzing Visual Chain-of-Thought Reasoning of Vision Language Models in Real-World Scenarios with Driving Theory Tests**
2501.04671v1 by Charles Corbière, Simon Roburin, Syrielle Montariol, Antoine Bosselut, Alexandre Alahi

Large vision-language models (LVLMs) augment language models with visual
understanding, enabling multimodal reasoning. However, due to the modality gap
between textual and visual data, they often face significant challenges, such
as over-reliance on text priors, hallucinations, and limited capacity for
complex visual reasoning. Existing benchmarks to evaluate visual reasoning in
LVLMs often rely on schematic or synthetic images and on imprecise
machine-generated explanations. To bridge the modality gap, we present
DrivingVQA, a new benchmark derived from driving theory tests to evaluate
visual chain-of-thought reasoning in complex real-world scenarios. It offers
3,931 expert-crafted multiple-choice problems and interleaved explanations
grounded with entities relevant to the reasoning process. We leverage this
dataset to perform an extensive study of LVLMs' ability to reason about complex
visual scenarios. Our experiments reveal that open-source and proprietary LVLMs
struggle with visual chain-of-thought reasoning under zero-shot settings. We
investigate training strategies that leverage relevant entities to improve
visual reasoning. Notably, we observe a performance boost of up to 7\% when
reasoning over image tokens of cropped regions tied to these entities.

摘要：大型视觉语言模型 (LVLMs) 使用视觉理解来增强语言模型，实现多模态推理。然而，由于文本和视觉数据之间的模态差异，它们通常面临着重大挑战，例如过度依赖文本先验、幻觉以及复杂视觉推理能力有限。现有的基准用于评估 LVLMs 中的视觉推理，通常依赖于示意图或合成图像以及不精确的机器生成的解释。为了弥合模态差距，我们提出了 DrivingVQA，这是一个新的基准，源自驾驶理论测试，用于评估复杂现实世界场景中的视觉思维链推理。它提供了 3,931 个专家制作的多项选择题和穿插的解释，这些解释以与推理过程相关的实体为基础。我们利用此数据集对 LVLMs 推理复杂视觉场景的能力进行了广泛的研究。我们的实验表明，开源和专有 LVLMs 在零次学习设置下难以进行视觉思维链推理。我们研究了利用相关实体来改善视觉推理的训练策略。值得注意的是，当对与这些实体相关的裁剪区域的图像标记进行推理时，我们观察到性能提升高达 7%。

##### **On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena**
2501.04662v1 by Tarek Naous, Wei Xu

Language Models (LMs) have been shown to exhibit a strong preference towards
entities associated with Western culture when operating in non-Western
languages. In this paper, we aim to uncover the origins of entity-related
cultural biases in LMs by analyzing several contributing factors, including the
representation of entities in pre-training data and the impact of variations in
linguistic phenomena across languages. We introduce CAMeL-2, a parallel
Arabic-English benchmark of 58,086 entities associated with Arab and Western
cultures and 367 masked natural contexts for entities. Our evaluations using
CAMeL-2 reveal reduced performance gaps between cultures by LMs when tested in
English compared to Arabic. We find that LMs struggle in Arabic with entities
that appear at high frequencies in pre-training, where entities can hold
multiple word senses. This also extends to entities that exhibit high lexical
overlap with languages that are not Arabic but use the Arabic script. Further,
we show how frequency-based tokenization leads to this issue in LMs, which gets
worse with larger Arabic vocabularies. We will make CAMeL-2 available at:
https://github.com/tareknaous/camel2

摘要：語言模型 (LM) 在使用非西方語言時，已被證明對與西方文化相關的實體表現出強烈的偏好。在本文中，我們旨在透過分析幾個促成因素來揭露語言模型中與實體相關的文化偏見的根源，包括實體在預訓練資料中的表示，以及語言中語言現象變化的影響。我們引入了 CAMeL-2，一個包含 58,086 個與阿拉伯和西方文化相關的實體，以及 367 個用於實體的遮蔽自然語境的平行阿拉伯語-英語基準。我們使用 CAMeL-2 進行的評估顯示，與在阿拉伯語中測試相比，語言模型在英語中測試時，不同文化之間的效能差距縮小。我們發現語言模型在阿拉伯語中處理在預訓練中出現頻率高的實體時會遇到困難，因為實體可能有多個詞彙意義。這也延伸到與非阿拉伯語但使用阿拉伯文字的語言具有高度詞彙重疊的實體。此外，我們展示了基於頻率的詞彙化如何導致語言模型中出現此問題，而隨著阿拉伯語詞彙量的增加，情況會變得更糟。我們將在以下位置提供 CAMeL-2：https://github.com/tareknaous/camel2

##### **Assessing Language Comprehension in Large Language Models Using Construction Grammar**
2501.04661v1 by Wesley Scivetti, Melissa Torgbi, Austin Blodgett, Mollie Shichman, Taylor Hudson, Claire Bonial, Harish Tayyar Madabushi

Large Language Models, despite their significant capabilities, are known to
fail in surprising and unpredictable ways. Evaluating their true
`understanding' of language is particularly challenging due to the extensive
web-scale data they are trained on. Therefore, we construct an evaluation to
systematically assess natural language understanding (NLU) in LLMs by
leveraging Construction Grammar (CxG), which provides insights into the meaning
captured by linguistic elements known as constructions (Cxns). CxG is
well-suited for this purpose because provides a theoretical basis to construct
targeted evaluation sets. These datasets are carefully constructed to include
examples which are unlikely to appear in pre-training data, yet intuitive and
easy for humans to understand, enabling a more targeted and reliable
assessment. Our experiments focus on downstream natural language inference and
reasoning tasks by comparing LLMs' understanding of the underlying meanings
communicated through 8 unique Cxns with that of humans. The results show that
while LLMs demonstrate some knowledge of constructional information, even the
latest models including GPT-o1 struggle with abstract meanings conveyed by
these Cxns, as demonstrated in cases where test sentences are dissimilar to
their pre-training data. We argue that such cases provide a more accurate test
of true language understanding, highlighting key limitations in LLMs' semantic
capabilities. We make our novel dataset and associated experimental data
including prompts and model responses publicly available.

摘要：儘管大型語言模型具有顯著的能力，但它們以令人驚訝且無法預測的方式失敗而聞名。由於它們訓練於廣泛的網路規模資料，因此評估它們對語言的真正「理解」特別具有挑戰性。因此，我們建構了一個評量，以透過利用建構文法（CxG）系統性地評估大型語言模型中的自然語言理解（NLU），它提供了對建構（Cxns）等語言元素所擷取的意義的見解。CxG 非常適合此目的，因為它提供了建構目標評量集的理論基礎。這些資料集經過仔細建構，包含不太可能出現在預訓練資料中的範例，但對人類來說卻直觀且易於理解，從而能夠進行更有針對性和更可靠的評量。我們的實驗重點在於下游自然語言推論和推理任務，透過將大型語言模型對透過 8 個獨特的 Cxns 傳達的底層意義的理解與人類的理解進行比較。結果顯示，儘管大型語言模型展示出對建構資訊的某些知識，但即使是包括 GPT-o1 在內的最新模型，在這些 Cxns 傳達的抽象意義上仍有困難，這在測試句子與其預訓練資料不同的情況中得到證明。我們認為，此類案例提供了對真實語言理解更準確的測試，突顯了大型語言模型語義能力中的主要限制。我們公開了我們的新穎資料集和相關實驗資料，包括提示和模型回應。

##### **Multi-task retriever fine-tuning for domain-specific and efficient RAG**
2501.04652v1 by Patrice Béchard, Orlando Marquez Ayala

Retrieval-Augmented Generation (RAG) has become ubiquitous when deploying
Large Language Models (LLMs), as it can address typical limitations such as
generating hallucinated or outdated information. However, when building
real-world RAG applications, practical issues arise. First, the retrieved
information is generally domain-specific. Since it is computationally expensive
to fine-tune LLMs, it is more feasible to fine-tune the retriever to improve
the quality of the data included in the LLM input. Second, as more applications
are deployed in the same real-world system, one cannot afford to deploy
separate retrievers. Moreover, these RAG applications normally retrieve
different kinds of data. Our solution is to instruction fine-tune a small
retriever encoder on a variety of domain-specific tasks to allow us to deploy
one encoder that can serve many use cases, thereby achieving low-cost,
scalability, and speed. We show how this encoder generalizes to out-of-domain
settings as well as to an unseen retrieval task on real-world enterprise use
cases.

摘要：檢索增強生成（RAG）在部署大型語言模型（LLM）時已變得無處不在，因為它可以解決典型的限制，例如生成幻覺或過時的資訊。然而，在建構真實世界的 RAG 應用程式時，會出現實際問題。首先，檢索到的資訊通常是特定領域的。由於微調 LLM 在計算上很昂貴，因此微調檢索器以提高 LLM 輸入中資料品質更可行。其次，由於在同一個真實世界系統中部署了更多應用程式，因此無法負擔部署獨立的檢索器。此外，這些 RAG 應用程式通常檢索不同種類的資料。我們的解決方案是在各種特定領域的任務上對小型檢索器編碼器進行指令微調，讓我們能夠部署一個可以服務於許多使用案例的編碼器，從而實現低成本、可擴充性和速度。我們展示了這個編碼器如何推廣到領域外設定，以及在真實世界的企業使用案例中對未見過的檢索任務進行推廣。

##### **FlairGPT: Repurposing LLMs for Interior Designs**
2501.04648v1 by Gabrielle Littlefair, Niladri Shekhar Dutt, Niloy J. Mitra

Interior design involves the careful selection and arrangement of objects to
create an aesthetically pleasing, functional, and harmonized space that aligns
with the client's design brief. This task is particularly challenging, as a
successful design must not only incorporate all the necessary objects in a
cohesive style, but also ensure they are arranged in a way that maximizes
accessibility, while adhering to a variety of affordability and usage
considerations. Data-driven solutions have been proposed, but these are
typically room- or domain-specific and lack explainability in their design
design considerations used in producing the final layout. In this paper, we
investigate if large language models (LLMs) can be directly utilized for
interior design. While we find that LLMs are not yet capable of generating
complete layouts, they can be effectively leveraged in a structured manner,
inspired by the workflow of interior designers. By systematically probing LLMs,
we can reliably generate a list of objects along with relevant constraints that
guide their placement. We translate this information into a design layout
graph, which is then solved using an off-the-shelf constrained optimization
setup to generate the final layouts. We benchmark our algorithm in various
design configurations against existing LLM-based methods and human designs, and
evaluate the results using a variety of quantitative and qualitative metrics
along with user studies. In summary, we demonstrate that LLMs, when used in a
structured manner, can effectively generate diverse high-quality layouts,
making them a viable solution for creating large-scale virtual scenes. Project
webpage at https://flairgpt.github.io/

摘要：室內設計涉及仔細挑選和安排物件，以創造一個美觀、實用且和諧的空間，符合客戶的設計簡報。這項任務特別具有挑戰性，因為成功的設計不僅必須以一致的風格納入所有必要的物件，還必須確保它們的排列方式能最大化可及性，同時符合各種負擔能力和使用考量。已經提出了資料驅動的解決方案，但這些解決方案通常是特定於房間或領域，而且缺乏在產生最終佈局時所使用的設計考量的可解釋性。在本文中，我們探討大型語言模型 (LLM) 是否可以直接用於室內設計。雖然我們發現 LLM 尚未能夠產生完整的佈局，但它們可以有效地以結構化的方式利用，靈感來自室內設計師的工作流程。透過系統性地探查 LLM，我們可以可靠地產生一個物件清單，以及指導它們放置位置的相关約束。我們將這些資訊轉換成設計佈局圖，然後使用現成的約束式最佳化設定來解決，以產生最終佈局。我們在各種設計配置中將我們的演算法與現有的基於 LLM 的方法和人類設計進行基準測試，並使用各種量化和質化指標以及使用者研究來評估結果。總之，我們證明了 LLM 在以結構化的方式使用時，可以有效地產生多樣化的高品質佈局，使其成為創造大型虛擬場景的可行解決方案。專案網頁在 https://flairgpt.github.io/

##### **Knowledge Retrieval Based on Generative AI**
2501.04635v1 by Te-Lun Yang, Jyi-Shane Liu, Yuen-Hsien Tseng, Jyh-Shing Roger Jang

This study develops a question-answering system based on Retrieval-Augmented
Generation (RAG) using Chinese Wikipedia and Lawbank as retrieval sources.
Using TTQA and TMMLU+ as evaluation datasets, the system employs BGE-M3 for
dense vector retrieval to obtain highly relevant search results and
BGE-reranker to reorder these results based on query relevance. The most
pertinent retrieval outcomes serve as reference knowledge for a Large Language
Model (LLM), enhancing its ability to answer questions and establishing a
knowledge retrieval system grounded in generative AI.
  The system's effectiveness is assessed through a two-stage evaluation:
automatic and assisted performance evaluations. The automatic evaluation
calculates accuracy by comparing the model's auto-generated labels with ground
truth answers, measuring performance under standardized conditions without
human intervention. The assisted performance evaluation involves 20
finance-related multiple-choice questions answered by 20 participants without
financial backgrounds. Initially, participants answer independently. Later,
they receive system-generated reference information to assist in answering,
examining whether the system improves accuracy when assistance is provided.
  The main contributions of this research are: (1) Enhanced LLM Capability: By
integrating BGE-M3 and BGE-reranker, the system retrieves and reorders highly
relevant results, reduces hallucinations, and dynamically accesses authorized
or public knowledge sources. (2) Improved Data Privacy: A customized RAG
architecture enables local operation of the LLM, eliminating the need to send
private data to external servers. This approach enhances data security, reduces
reliance on commercial services, lowers operational costs, and mitigates
privacy risks.

摘要：<paragraph>本研究開發了一個問答系統，該系統基於檢索增強生成 (RAG)，使用中文維基百科和 Lawbank 作為檢索來源。系統使用 TTQA 和 TMMLU+ 作為評估資料集，採用 BGE-M3 進行稠密向量檢索，以取得高度相關的搜尋結果，並使用 BGE-reranker 根據查詢相關性對這些結果重新排序。最相關的檢索結果作為大型語言模型 (LLM) 的參考知識，增強其回答問題的能力，並建立一個基於生成式 AI 的知識檢索系統。系統的有效性通過兩階段評估來評估：自動和輔助性能評估。自動評估通過將模型自動生成的標籤與真實答案進行比較來計算準確性，在沒有人工干預的情況下測量標準化條件下的性能。輔助性能評估包括 20 個與金融相關的多選題，由 20 個沒有金融背景的參與者回答。最初，參與者獨立回答。稍後，他們會收到系統生成的參考資訊以協助回答，檢查在提供協助時系統是否能提高準確性。本研究的主要貢獻有：(1) 增強的 LLM 能力：通過整合 BGE-M3 和 BGE-reranker，系統檢索和重新排序高度相關的結果，減少幻覺，並動態訪問授權或公開的知識來源。(2) 改善資料隱私：自訂的 RAG 架構允許 LLM 本地運作，無需將私人資料傳送至外部伺服器。這種方法增強了資料安全性，減少了對商業服務的依賴，降低了運營成本，並減輕了隱私風險。</paragraph>

