
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-06**|**Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?**|Daniel P. Jeong et.al.|[2411.04118v1](http://arxiv.org/abs/2411.04118v1)|null|
|**2024-11-06**|**Fed-EC: Bandwidth-Efficient Clustering-Based Federated Learning For Autonomous Visual Robot Navigation**|Shreya Gummadi et.al.|[2411.04112v1](http://arxiv.org/abs/2411.04112v1)|null|
|**2024-11-06**|**Self-Consistency Preference Optimization**|Archiki Prasad et.al.|[2411.04109v1](http://arxiv.org/abs/2411.04109v1)|null|
|**2024-11-06**|**How Transformers Solve Propositional Logic Problems: A Mechanistic Analysis**|Guan Zhe Hong et.al.|[2411.04105v1](http://arxiv.org/abs/2411.04105v1)|null|
|**2024-11-06**|**RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models**|Maya Varma et.al.|[2411.04097v1](http://arxiv.org/abs/2411.04097v1)|[link](https://github.com/stanford-aimi/ravl)|
|**2024-11-06**|**Summarization of Opinionated Political Documents with Varied Perspectives**|Nicholas Deas et.al.|[2411.04093v1](http://arxiv.org/abs/2411.04093v1)|null|
|**2024-11-06**|**A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement**|Guillermo Villate-Castillo et.al.|[2411.04090v1](http://arxiv.org/abs/2411.04090v1)|[link](https://github.com/themrguiller/collaborative-content-moderation)|
|**2024-11-06**|**M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models**|Chuhan Li et.al.|[2411.04075v1](http://arxiv.org/abs/2411.04075v1)|null|
|**2024-11-06**|**Non-Stationary Learning of Neural Networks with Automatic Soft Parameter Reset**|Alexandre Galashov et.al.|[2411.04034v1](http://arxiv.org/abs/2411.04034v1)|null|
|**2024-11-06**|**Beemo: Benchmark of Expert-edited Machine-generated Outputs**|Ekaterina Artemova et.al.|[2411.04032v1](http://arxiv.org/abs/2411.04032v1)|null|
|**2024-11-06**|**Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages**|Aniket Deroy et.al.|[2411.04025v1](http://arxiv.org/abs/2411.04025v1)|null|
|**2024-11-06**|**Predicting and Publishing Accurate Imbalance Prices Using Monte Carlo Tree Search**|Fabio Pavirani et.al.|[2411.04011v1](http://arxiv.org/abs/2411.04011v1)|null|
|**2024-11-06**|**Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability**|Bharat Chandra Yalavarthi et.al.|[2411.04008v1](http://arxiv.org/abs/2411.04008v1)|null|
|**2024-11-06**|**Select2Plan: Training-Free ICL-Based Planning through VQA and Memory Retrieval**|Davide Buoso et.al.|[2411.04006v1](http://arxiv.org/abs/2411.04006v1)|null|
|**2024-11-06**|**Towards Resource-Efficient Federated Learning in Industrial IoT for Multivariate Time Series Analysis**|Alexandros Gkillas et.al.|[2411.03996v1](http://arxiv.org/abs/2411.03996v1)|null|
|**2024-11-06**|**WorryWords: Norms of Anxiety Association for over 44k English Words**|Saif M. Mohammad et.al.|[2411.03966v1](http://arxiv.org/abs/2411.03966v1)|null|
|**2024-11-06**|**What Really is Commonsense Knowledge?**|Quyet V. Do et.al.|[2411.03964v1](http://arxiv.org/abs/2411.03964v1)|null|
|**2024-11-06**|**How Does A Text Preprocessing Pipeline Affect Ontology Syntactic Matching?**|Zhangcheng Qiang et.al.|[2411.03962v1](http://arxiv.org/abs/2411.03962v1)|null|
|**2024-11-06**|**Energy Score-based Pseudo-Label Filtering and Adaptive Loss for Imbalanced Semi-supervised SAR target recognition**|Xinzheng Zhang et.al.|[2411.03959v1](http://arxiv.org/abs/2411.03959v1)|null|
|**2024-11-06**|**Fine-Grained Guidance for Retrievers: Leveraging LLMs' Feedback in Retrieval-Augmented Generation**|Yuhang Liu et.al.|[2411.03957v1](http://arxiv.org/abs/2411.03957v1)|null|
|**2024-11-06**|**Long-Form Text-to-Music Generation with Adaptive Prompts: A Case of Study in Tabletop Role-Playing Games Soundtracks**|Felipe Marra et.al.|[2411.03948v1](http://arxiv.org/abs/2411.03948v1)|null|
|**2024-11-06**|**Can Custom Models Learn In-Context? An Exploration of Hybrid Architecture Performance on In-Context Learning Tasks**|Ryan Campbell et.al.|[2411.03945v1](http://arxiv.org/abs/2411.03945v1)|null|
|**2024-11-06**|**Fine-tuning -- a Transfer Learning approach**|Joseph Arul Raj et.al.|[2411.03941v1](http://arxiv.org/abs/2411.03941v1)|null|
|**2024-11-06**|**Interactions Across Blocks in Post-Training Quantization of Large Language Models**|Khasmamad Shabanovi et.al.|[2411.03934v1](http://arxiv.org/abs/2411.03934v1)|null|
|**2024-11-06**|**Evaluation data contamination in LLMs: how do we measure it and (when) does it matter?**|Aaditya K. Singh et.al.|[2411.03923v1](http://arxiv.org/abs/2411.03923v1)|null|
|**2024-11-06**|**RAGulator: Lightweight Out-of-Context Detectors for Grounded Text Generation**|Ian Poey et.al.|[2411.03920v1](http://arxiv.org/abs/2411.03920v1)|null|
|**2024-11-06**|**Lexicalization Is All You Need: Examining the Impact of Lexical Knowledge in a Compositional QALD System**|David Maria Schmidt et.al.|[2411.03906v1](http://arxiv.org/abs/2411.03906v1)|null|
|**2024-11-06**|**Computational Analysis of Gender Depiction in the Comedias of Calderón de la Barca**|Allison Keith et.al.|[2411.03895v1](http://arxiv.org/abs/2411.03895v1)|null|
|**2024-11-06**|**Multi3Hate: Multimodal, Multilingual, and Multicultural Hate Speech Detection with Vision-Language Models**|Minh Duc Bui et.al.|[2411.03888v1](http://arxiv.org/abs/2411.03888v1)|[link](https://github.com/minhducbui/multi3hate)|
|**2024-11-06**|**Polynomial Composition Activations: Unleashing the Dynamics of Large Language Models**|Zhijian Zhuo et.al.|[2411.03884v1](http://arxiv.org/abs/2411.03884v1)|null|
|**2024-11-06**|**MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**|Laura Cabello et.al.|[2411.03883v1](http://arxiv.org/abs/2411.03883v1)|[link](https://github.com/lautel/meg)|
|**2024-11-06**|**Performance evaluation of SLAM-ASR: The Good, the Bad, the Ugly, and the Way Forward**|Shashi Kumar et.al.|[2411.03866v1](http://arxiv.org/abs/2411.03866v1)|null|
|**2024-11-06**|**AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent Decision-Making**|Yizhe Huang et.al.|[2411.03865v1](http://arxiv.org/abs/2411.03865v1)|[link](https://github.com/bigai-ai/adasociety)|
|**2024-11-06**|**ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization**|Huayang Huang et.al.|[2411.03862v1](http://arxiv.org/abs/2411.03862v1)|[link](https://github.com/hannah1102/robin)|
|**2024-11-06**|**UniTraj: Universal Human Trajectory Modeling from Billion-Scale Worldwide Traces**|Yuanshao Zhu et.al.|[2411.03859v1](http://arxiv.org/abs/2411.03859v1)|null|
|**2024-11-06**|**MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba**|Masakazu Yoshimura et.al.|[2411.03855v1](http://arxiv.org/abs/2411.03855v1)|null|
|**2024-11-06**|**A Novel Access Control and Privacy-Enhancing Approach for Models in Edge Computing**|Peihao Li et.al.|[2411.03847v1](http://arxiv.org/abs/2411.03847v1)|null|
|**2024-11-06**|**Reconsidering the Performance of GAE in Link Prediction**|Weishuo Ma et.al.|[2411.03845v1](http://arxiv.org/abs/2411.03845v1)|[link](https://github.com/graphpku/refined-gae)|
|**2024-11-06**|**Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination**|Dingjie Song et.al.|[2411.03823v1](http://arxiv.org/abs/2411.03823v1)|null|
|**2024-11-06**|**From Novice to Expert: LLM Agent Policy Optimization via Step-wise Reinforcement Learning**|Zhirui Deng et.al.|[2411.03817v1](http://arxiv.org/abs/2411.03817v1)|null|
|**2024-11-06**|**MRJ-Agent: An Effective Jailbreak Agent for Multi-Round Dialogue**|Fengxiang Wang et.al.|[2411.03814v1](http://arxiv.org/abs/2411.03814v1)|null|
|**2024-11-06**|**The natural stability of autonomous morphology**|Erich Round et.al.|[2411.03811v1](http://arxiv.org/abs/2411.03811v1)|null|
|**2024-11-06**|**GS2Pose: Tow-stage 6D Object Pose Estimation Guided by Gaussian Splatting**|Jilan Mei et.al.|[2411.03807v1](http://arxiv.org/abs/2411.03807v1)|null|
|**2024-11-06**|**Understanding the Effects of Human-written Paraphrases in LLM-generated Text Detection**|Hiu Ting Lau et.al.|[2411.03806v1](http://arxiv.org/abs/2411.03806v1)|null|
|**2024-11-06**|**A Comparative Study of Recent Large Language Models on Generating Hospital Discharge Summaries for Lung Cancer Patients**|Yiming Li et.al.|[2411.03805v1](http://arxiv.org/abs/2411.03805v1)|null|
|**2024-11-06**|**Overcoming label shift in targeted federated learning**|Edvin Listo Zec et.al.|[2411.03799v1](http://arxiv.org/abs/2411.03799v1)|null|
|**2024-11-06**|**VQA$^2$:Visual Question Answering for Video Quality Assessment**|Ziheng Jia et.al.|[2411.03795v1](http://arxiv.org/abs/2411.03795v1)|null|
|**2024-11-06**|**Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications**|Daan Schouten et.al.|[2411.03782v1](http://arxiv.org/abs/2411.03782v1)|null|
|**2024-11-06**|**No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with Captions in 28 Languages**|Youssef Mohamed et.al.|[2411.03769v1](http://arxiv.org/abs/2411.03769v1)|null|
|**2024-11-06**|**Number Cookbook: Number Understanding of Language Models and How to Improve It**|Haotong Yang et.al.|[2411.03766v1](http://arxiv.org/abs/2411.03766v1)|[link](https://github.com/graphpku/number_cookbook)|
|**2024-11-06**|**Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction**|Yu Guan et.al.|[2411.03758v1](http://arxiv.org/abs/2411.03758v1)|null|
|**2024-11-06**|**Optimal Defenses Against Gradient Reconstruction Attacks**|Yuxiao Chen et.al.|[2411.03746v1](http://arxiv.org/abs/2411.03746v1)|[link](https://github.com/cyx78/optimal_defenses_against_gradient_reconstruction_attacks)|
|**2024-11-06**|**Automating Exploratory Proteomics Research via Language Models**|Ning Ding et.al.|[2411.03743v1](http://arxiv.org/abs/2411.03743v1)|null|
|**2024-11-06**|**Adaptive Consensus Gradients Aggregation for Scaled Distributed Training**|Yoni Choukroun et.al.|[2411.03742v1](http://arxiv.org/abs/2411.03742v1)|null|
|**2024-11-06**|**Relation Learning and Aggregate-attention for Multi-person Motion Prediction**|Kehua Qu et.al.|[2411.03729v1](http://arxiv.org/abs/2411.03729v1)|null|
|**2024-11-06**|**PropNEAT -- Efficient GPU-Compatible Backpropagation over NeuroEvolutionary Augmenting Topology Networks**|Michael Merry et.al.|[2411.03726v1](http://arxiv.org/abs/2411.03726v1)|null|
|**2024-11-06**|**Fine-Tuning Vision-Language Model for Automated Engineering Drawing Information Extraction**|Muhammad Tayyab Khan et.al.|[2411.03707v1](http://arxiv.org/abs/2411.03707v1)|null|
|**2024-11-06**|**The Root Shapes the Fruit: On the Persistence of Gender-Exclusive Harms in Aligned Language Models**|Anaelia Ovalle et.al.|[2411.03700v1](http://arxiv.org/abs/2411.03700v1)|null|
|**2024-11-06**|**Beyond Model Adaptation at Test Time: A Survey**|Zehao Xiao et.al.|[2411.03687v1](http://arxiv.org/abs/2411.03687v1)|[link](https://github.com/zzzx1224/beyond-model-adaptation-at-test-time-papers)|
|**2024-11-06**|**QUILL: Quotation Generation Enhancement of Large Language Models**|Jin Xiao et.al.|[2411.03675v1](http://arxiv.org/abs/2411.03675v1)|[link](https://github.com/gracexiaoo/quill)|
|**2024-11-06**|**Towards 3D Semantic Scene Completion for Autonomous Driving: A Meta-Learning Framework Empowered by Deformable Large-Kernel Attention and Mamba Model**|Yansong Qu et.al.|[2411.03672v1](http://arxiv.org/abs/2411.03672v1)|null|
|**2024-11-06**|**Evaluating Moral Beliefs across LLMs through a Pluralistic Framework**|Xuelin Liu et.al.|[2411.03665v1](http://arxiv.org/abs/2411.03665v1)|[link](https://github.com/mumu-lily/moral-beliefs)|
|**2024-11-06**|**Deploying Multi-task Online Server with Large Language Model**|Yincen Qu et.al.|[2411.03644v1](http://arxiv.org/abs/2411.03644v1)|null|
|**2024-11-06**|**RTify: Aligning Deep Neural Networks with Human Behavioral Decisions**|Yu-Ang Cheng et.al.|[2411.03630v1](http://arxiv.org/abs/2411.03630v1)|null|
|**2024-11-06**|**StreamingBench: Assessing the Gap for MLLMs to Achieve Streaming Video Understanding**|Junming Lin et.al.|[2411.03628v1](http://arxiv.org/abs/2411.03628v1)|null|
|**2024-11-06**|**Fully Hyperbolic Rotation for Knowledge Graph Embedding**|Qiuyu Liang et.al.|[2411.03622v1](http://arxiv.org/abs/2411.03622v1)|null|
|**2024-11-06**|**Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification**|Dahyun Mok et.al.|[2411.03618v1](http://arxiv.org/abs/2411.03618v1)|null|
|**2024-11-06**|**From Medprompt to o1: Exploration of Run-Time Strategies for Medical Challenge Problems and Beyond**|Harsha Nori et.al.|[2411.03590v1](http://arxiv.org/abs/2411.03590v1)|null|
|**2024-11-06**|**An Experimental Study on Decomposition-Based Deep Ensemble Learning for Traffic Flow Forecasting**|Qiyuan Zhu et.al.|[2411.03588v1](http://arxiv.org/abs/2411.03588v1)|null|
|**2024-11-06**|**Towards Personalized Federated Learning via Comprehensive Knowledge Distillation**|Pengju Wang et.al.|[2411.03569v1](http://arxiv.org/abs/2411.03569v1)|null|
|**2024-11-06**|**The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**|Lee Kezar et.al.|[2411.03568v1](http://arxiv.org/abs/2411.03568v1)|null|
|**2024-11-05**|**Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level**|Antoine Grosnit et.al.|[2411.03562v1](http://arxiv.org/abs/2411.03562v1)|null|
|**2024-11-05**|**Learning to Write Rationally: How Information Is Distributed in Non-Native Speakers' Essays**|Zixin Tang et.al.|[2411.03550v1](http://arxiv.org/abs/2411.03550v1)|null|
|**2024-11-05**|**Exploring the Benefits of Domain-Pretraining of Generative Large Language Models for Chemistry**|Anurag Acharya et.al.|[2411.03542v1](http://arxiv.org/abs/2411.03542v1)|null|
|**2024-11-05**|**Long Context RAG Performance of Large Language Models**|Quinn Leng et.al.|[2411.03538v1](http://arxiv.org/abs/2411.03538v1)|null|
|**2024-11-05**|**Two-Stage Pretraining for Molecular Property Prediction in the Wild**|Kevin Tirta Wijaya et.al.|[2411.03537v1](http://arxiv.org/abs/2411.03537v1)|null|
|**2024-11-05**|**Personalized Video Summarization by Multimodal Video Understanding**|Brian Chen et.al.|[2411.03531v1](http://arxiv.org/abs/2411.03531v1)|null|
|**2024-11-05**|**Exploring the Potentials and Challenges of Using Large Language Models for the Analysis of Transcriptional Regulation of Long Non-coding RNAs**|Wei Wang et.al.|[2411.03522v1](http://arxiv.org/abs/2411.03522v1)|null|
|**2024-11-05**|**AI Metropolis: Scaling Large Language Model-based Multi-Agent Simulation with Out-of-order Execution**|Zhiqiang Xie et.al.|[2411.03519v1](http://arxiv.org/abs/2411.03519v1)|null|
|**2024-11-05**|**Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy**|Razvan-Gabriel Dumitru et.al.|[2411.03513v1](http://arxiv.org/abs/2411.03513v1)|[link](https://github.com/razvandu/dynamicslicing)|
|**2024-11-05**|**Uncertainty Quantification for Clinical Outcome Predictions with (Large) Language Models**|Zizhang Chen et.al.|[2411.03497v1](http://arxiv.org/abs/2411.03497v1)|null|
|**2024-11-05**|**Automatic Generation of Question Hints for Mathematics Problems using Large Language Models in Educational Technology**|Junior Cedric Tonga et.al.|[2411.03495v1](http://arxiv.org/abs/2411.03495v1)|null|
|**2024-11-05**|**LASER: Attention with Exponential Transformation**|Sai Surya Duvvuri et.al.|[2411.03493v1](http://arxiv.org/abs/2411.03493v1)|null|
|**2024-11-05**|**LLM Generated Distribution-Based Prediction of US Electoral Results, Part I**|Caleb Bradshaw et.al.|[2411.03486v1](http://arxiv.org/abs/2411.03486v1)|null|
|**2024-11-05**|**MetRex: A Benchmark for Verilog Code Metric Reasoning Using LLMs**|Manar Abdelatty et.al.|[2411.03471v1](http://arxiv.org/abs/2411.03471v1)|null|
|**2024-11-05**|**Watson: A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents**|Benjamin Rombaut et.al.|[2411.03455v1](http://arxiv.org/abs/2411.03455v1)|null|
|**2024-11-05**|**Solving Trojan Detection Competitions with Linear Weight Classification**|Todd Huster et.al.|[2411.03445v1](http://arxiv.org/abs/2411.03445v1)|null|
|**2024-11-05**|**MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and Reasoning**|Ziliang Gan et.al.|[2411.03314v1](http://arxiv.org/abs/2411.03314v1)|null|
|**2024-11-05**|**Usefulness of LLMs as an Author Checklist Assistant for Scientific Papers: NeurIPS'24 Experiment**|Alexander Goldberg et.al.|[2411.03417v1](http://arxiv.org/abs/2411.03417v1)|null|
|**2024-11-05**|**Inference Optimal VLMs Need Only One Visual Token but Larger Models**|Kevin Y. Li et.al.|[2411.03312v1](http://arxiv.org/abs/2411.03312v1)|[link](https://github.com/locuslab/llava-token-compression)|
|**2024-11-05**|**STEER: Flexible Robotic Manipulation via Dense Language Grounding**|Laura Smith et.al.|[2411.03409v1](http://arxiv.org/abs/2411.03409v1)|null|
|**2024-11-05**|**SAUCE: Synchronous and Asynchronous User-Customizable Environment for Multi-Agent LLM Interaction**|Shlomo Neuberger et.al.|[2411.03397v1](http://arxiv.org/abs/2411.03397v1)|[link](https://github.com/deep-cognition-lab/sauce)|
|**2024-11-05**|**Exploring Large Language Models for Specialist-level Oncology Care**|Anil Palepu et.al.|[2411.03395v1](http://arxiv.org/abs/2411.03395v1)|null|
|**2024-11-05**|**Neurons for Neutrons: A Transformer Model for Computation Load Estimation on Domain-Decomposed Neutron Transport Problems**|Alexander Mote et.al.|[2411.03389v1](http://arxiv.org/abs/2411.03389v1)|null|
|**2024-11-05**|**LLMs for Domain Generation Algorithm Detection**|Reynier Leyva La O et.al.|[2411.03307v1](http://arxiv.org/abs/2411.03307v1)|null|
|**2024-11-05**|**VERITAS: A Unified Approach to Reliability Evaluation**|Rajkumar Ramamurthy et.al.|[2411.03300v1](http://arxiv.org/abs/2411.03300v1)|null|
|**2024-11-05**|**Interaction2Code: How Far Are We From Automatic Interactive Webpage Generation?**|Jingyu Xiao et.al.|[2411.03292v1](http://arxiv.org/abs/2411.03292v1)|null|
|**2024-11-05**|**The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare**|Souren Pashangpour et.al.|[2411.03287v1](http://arxiv.org/abs/2411.03287v1)|null|
|**2024-11-05**|**SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents**|Dawei Li et.al.|[2411.03284v1](http://arxiv.org/abs/2411.03284v1)|[link](https://github.com/david-li0406/smoa)|
|**2024-11-05**|**Causal Responsibility Attribution for Human-AI Collaboration**|Yahang Qi et.al.|[2411.03275v1](http://arxiv.org/abs/2411.03275v1)|[link](https://github.com/yahang-qi/Causal-Attr-Human-AI)|

#### Abstracts
##### **Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?**
2411.04118v1 by Daniel P. Jeong, Saurabh Garg, Zachary C. Lipton, Michael Oberst

Several recent works seek to develop foundation models specifically for
medical applications, adapting general-purpose large language models (LLMs) and
vision-language models (VLMs) via continued pretraining on publicly available
biomedical corpora. These works typically claim that such domain-adaptive
pretraining (DAPT) improves performance on downstream medical tasks, such as
answering medical licensing exam questions. In this paper, we compare seven
public "medical" LLMs and two VLMs against their corresponding base models,
arriving at a different conclusion: all medical VLMs and nearly all medical
LLMs fail to consistently improve over their base models in the zero-/few-shot
prompting regime for medical question-answering (QA) tasks. For instance,
across the tasks and model pairs we consider in the 3-shot setting, medical
LLMs only outperform their base models in 12.1% of cases, reach a (statistical)
tie in 49.8% of cases, and are significantly worse than their base models in
the remaining 38.2% of cases. Our conclusions are based on (i) comparing each
medical model head-to-head, directly against the corresponding base model; (ii)
optimizing the prompts for each model separately; and (iii) accounting for
statistical uncertainty in comparisons. While these basic practices are not
consistently adopted in the literature, our ablations show that they
substantially impact conclusions. Our findings suggest that state-of-the-art
general-domain models may already exhibit strong medical knowledge and
reasoning capabilities, and offer recommendations to strengthen the conclusions
of future studies.

摘要：<paragraph>近期的幾項研究致力於專門針對醫療應用開發基礎模型，透過在公開的生物醫學語料庫上持續預訓練，調整通用的大型語言模型 (LLM) 和視覺語言模型 (VLM)。這些研究通常聲稱，這種領域適應性預訓練 (DAPT) 能改善下游醫療任務的效能，例如回答醫療執照考試題目。在本文中，我們比較了七個公開的「醫療」LLM 和兩個 VLM 與它們對應的基本模型，並得出不同的結論：在醫療問題回答 (QA) 任務的零次／小樣本提示機制中，所有醫療 VLM 和幾乎所有醫療 LLM 都無法持續優於它們的基本模型。例如，在我們在 3 次提示設定中考慮的任務和模型配對中，醫療 LLM 僅在 12.1% 的情況下優於它們的基本模型，在 49.8% 的情況下達到（統計）平手，而在其餘 38.2% 的情況下顯著低於它們的基本模型。我們的結論基於 (i) 直接針對對應的基本模型，逐一比較每個醫療模型；(ii) 分別針對每個模型最佳化提示；以及 (iii) 考慮比較中的統計不確定性。雖然這些基本做法並未持續採用在文獻中，但我們的消融研究表明，它們會大幅影響結論。我們的研究結果表明，最先進的通用領域模型可能已經展現出強大的醫療知識和推理能力，並提出建議以強化未來研究的結論。</paragraph>

##### **Fed-EC: Bandwidth-Efficient Clustering-Based Federated Learning For Autonomous Visual Robot Navigation**
2411.04112v1 by Shreya Gummadi, Mateus V. Gasparino, Deepak Vasisht, Girish Chowdhary

Centralized learning requires data to be aggregated at a central server,
which poses significant challenges in terms of data privacy and bandwidth
consumption. Federated learning presents a compelling alternative, however,
vanilla federated learning methods deployed in robotics aim to learn a single
global model across robots that works ideally for all. But in practice one
model may not be well suited for robots deployed in various environments. This
paper proposes Federated-EmbedCluster (Fed-EC), a clustering-based federated
learning framework that is deployed with vision based autonomous robot
navigation in diverse outdoor environments. The framework addresses the key
federated learning challenge of deteriorating model performance of a single
global model due to the presence of non-IID data across real-world robots.
Extensive real-world experiments validate that Fed-EC reduces the communication
size by 23x for each robot while matching the performance of centralized
learning for goal-oriented navigation and outperforms local learning. Fed-EC
can transfer previously learnt models to new robots that join the cluster.

摘要：集中式學習需要將資料彙整至中央伺服器，這在資料隱私和頻寬消耗方面造成重大挑戰。然而，聯邦式學習提供了一個強有力的替代方案，不過，用於機器人的香草聯邦式學習方法旨在學習所有機器人都理想運作的單一全球模型。但在實務上，單一模型可能不適合部署在各種環境中的機器人。本文提出以群集為基礎的聯邦式學習架構 Federated-EmbedCluster (Fed-EC)，該架構與基於視覺的自主機器人導航一起部署在多樣化的戶外環境中。該架構解決了聯邦式學習的一項關鍵挑戰，即由於現實世界機器人中存在非 IID 資料，導致單一全球模型的模型效能下降。廣泛的真實世界實驗驗證了 Fed-EC 將每個機器人的通訊大小減少了 23 倍，同時符合目標導向導航的集中式學習效能，並優於局部學習。Fed-EC 可以將先前學習的模型轉移到加入群集的新機器人。

##### **Self-Consistency Preference Optimization**
2411.04109v1 by Archiki Prasad, Weizhe Yuan, Richard Yuanzhe Pang, Jing Xu, Maryam Fazel-Zarandi, Mohit Bansal, Sainbayar Sukhbaatar, Jason Weston, Jane Yu

Self-alignment, whereby models learn to improve themselves without human
annotation, is a rapidly growing research area. However, existing techniques
often fail to improve complex reasoning tasks due to the difficulty of
assigning correct rewards. An orthogonal approach that is known to improve
correctness is self-consistency, a method applied at inference time based on
multiple sampling in order to find the most consistent answer. In this work, we
extend the self-consistency concept to help train models. We thus introduce
self-consistency preference optimization (ScPO), which iteratively trains
consistent answers to be preferred over inconsistent ones on unsupervised new
problems. We show ScPO leads to large improvements over conventional reward
model training on reasoning tasks such as GSM8K and MATH, closing the gap with
supervised training with gold answers or preferences, and that combining ScPO
with standard supervised learning improves results even further. On ZebraLogic,
ScPO finetunes Llama-3 8B to be superior to Llama-3 70B, Gemma-2 27B, and
Claude-3 Haiku.

摘要：自我對齊，即模型在沒有人工標註的情況下學會自我改進，是一個快速發展的研究領域。然而，現有的技術由於難以分配正確的獎勵，常常無法改進複雜的推理任務。一種已知可以提高正確性的正交方法是自一致性，這是一種在推理時間應用於多重抽樣的，用於找到最一致答案的方法。在這項工作中，我們將自一致性概念延伸到幫助訓練模型。因此，我們引入了自一致性偏好優化（ScPO），它反覆訓練一致的答案，使其在無監督的新問題上比不一致的答案更受青睞。我們展示了 ScPO 在推理任務（例如 GSM8K 和 MATH）上比傳統獎勵模型訓練有了很大改進，縮小了與使用黃金答案或偏好的監督訓練的差距，並且將 ScPO 與標準監督學習相結合進一步改進了結果。在 ZebraLogic 上，ScPO 對 Llama-3 8B 進行微調，使其優於 Llama-3 70B、Gemma-2 27B 和 Claude-3 Haiku。

##### **How Transformers Solve Propositional Logic Problems: A Mechanistic Analysis**
2411.04105v1 by Guan Zhe Hong, Nishanth Dikkala, Enming Luo, Cyrus Rashtchian, Rina Panigrahy

Large language models (LLMs) have shown amazing performance on tasks that
require planning and reasoning. Motivated by this, we investigate the internal
mechanisms that underpin a network's ability to perform complex logical
reasoning. We first construct a synthetic propositional logic problem that
serves as a concrete test-bed for network training and evaluation. Crucially,
this problem demands nontrivial planning to solve, but we can train a small
transformer to achieve perfect accuracy. Building on our set-up, we then pursue
an understanding of precisely how a three-layer transformer, trained from
scratch, solves this problem. We are able to identify certain "planning" and
"reasoning" circuits in the network that necessitate cooperation between the
attention blocks to implement the desired logic. To expand our findings, we
then study a larger model, Mistral 7B. Using activation patching, we
characterize internal components that are critical in solving our logic
problem. Overall, our work systemically uncovers novel aspects of small and
large transformers, and continues the study of how they plan and reason.

摘要：大型語言模型 (LLM) 在需要規劃和推理的任務上表現出色。受此啟發，我們研究了支撐網路執行複雜邏輯推理能力的內部機制。我們首先構建了一個合成命題邏輯問題，作為網路訓練和評估的具體測試平台。至關重要的是，這個問題需要非平凡的規劃才能解決，但我們可以訓練一個小型Transformer來實現完美的準確性。建立在我們的設置之上，我們接著探討一個從頭訓練的三層Transformer如何解決這個問題。我們能夠識別網路中某些「規劃」和「推理」電路，它們需要注意力區塊之間的合作來實現所需的邏輯。為了擴展我們的發現，我們接著研究一個更大的模型，Mistral 7B。使用激活修補，我們描述了在解決我們的邏輯問題中至關重要的內部組件。總的來說，我們的研究系統地揭示了小型和大型Transformer的新方面，並繼續研究它們是如何規劃和推理的。

##### **RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models**
2411.04097v1 by Maya Varma, Jean-Benoit Delbrouck, Zhihong Chen, Akshay Chaudhari, Curtis Langlotz

Fine-tuned vision-language models (VLMs) often capture spurious correlations
between image features and textual attributes, resulting in degraded zero-shot
performance at test time. Existing approaches for addressing spurious
correlations (i) primarily operate at the global image-level rather than
intervening directly on fine-grained image features and (ii) are predominantly
designed for unimodal settings. In this work, we present RaVL, which takes a
fine-grained perspective on VLM robustness by discovering and mitigating
spurious correlations using local image features rather than operating at the
global image level. Given a fine-tuned VLM, RaVL first discovers spurious
correlations by leveraging a region-level clustering approach to identify
precise image features contributing to zero-shot classification errors. Then,
RaVL mitigates the identified spurious correlation with a novel region-aware
loss function that enables the VLM to focus on relevant regions and ignore
spurious relationships during fine-tuning. We evaluate RaVL on 654 VLMs with
various model architectures, data domains, and learned spurious correlations.
Our results show that RaVL accurately discovers (191% improvement over the
closest baseline) and mitigates (8.2% improvement on worst-group image
classification accuracy) spurious correlations. Qualitative evaluations on
general-domain and medical-domain VLMs confirm our findings.

摘要：微调的视觉语言模型（VLM）通常会捕捉图像特征和文本属性之间的虚假相关性，导致在测试时零样本性能下降。现有的解决虚假相关性的方法（i）主要在全局图像级别操作，而不是直接干预细粒度的图像特征，并且（ii）主要设计用于单模态设置。在这项工作中，我们提出了 RaVL，它通过使用局部图像特征而不是在全局图像级别操作来发现和减轻虚假相关性，从而对 VLM 鲁棒性采取了细粒度的视角。给定一个微调的 VLM，RaVL 首先通过利用区域级聚类方法发现虚假相关性，以识别导致零样本分类错误的精确图像特征。然后，RaVL 使用一种新颖的区域感知损失函数来减轻已识别的虚假相关性，该损失函数使 VLM 能够在微调期间关注相关区域并忽略虚假关系。我们使用 654 个 VLM 对 RaVL 进行了评估，这些 VLM 具有各种模型架构、数据域和学习到的虚假相关性。我们的结果表明，RaVL 准确地发现了（比最接近的基线提高了 191%）和减轻了（在最差组图像分类准确性上提高了 8.2%）虚假相关性。对通用域和医学域 VLM 的定性评估证实了我们的发现。

##### **Summarization of Opinionated Political Documents with Varied Perspectives**
2411.04093v1 by Nicholas Deas, Kathleen McKeown

Global partisan hostility and polarization has increased, and this
polarization is heightened around presidential elections. Models capable of
generating accurate summaries of diverse perspectives can help reduce such
polarization by exposing users to alternative perspectives. In this work, we
introduce a novel dataset and task for independently summarizing each political
perspective in a set of passages from opinionated news articles. For this task,
we propose a framework for evaluating different dimensions of perspective
summary performance. We benchmark 10 models of varying sizes and architectures
through both automatic and human evaluation. While recent models like GPT-4o
perform well on this task, we find that all models struggle to generate
summaries faithful to the intended perspective. Our analysis of summaries
focuses on how extraction behavior depends on the features of the input
documents.

摘要：全球黨派敵意和兩極分化加劇，而這種兩極分化在總統選舉中尤為明顯。能夠產生不同觀點的準確摘要的模型，可以透過讓使用者接觸不同的觀點，來幫助減少這種兩極分化。在這項工作中，我們引入了一個新的資料集和任務，用於獨立摘要意見性新聞文章中的一組段落中的每一個政治觀點。對於這個任務，我們提出了評估觀點摘要表現不同面向的架構。我們透過自動和人工評估，對 10 個不同大小和架構的模型進行基準測試。雖然像 GPT-4o 這樣的最新模型在這項任務中表現良好，但我們發現所有模型都很難產生忠於預期觀點的摘要。我們對摘要的分析重點在於提取行為如何取決於輸入文件的功能。

##### **A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement**
2411.04090v1 by Guillermo Villate-Castillo, Javier Del Ser, Borja Sanz

Content moderation typically combines the efforts of human moderators and
machine learning models.However, these systems often rely on data where
significant disagreement occurs during moderation, reflecting the subjective
nature of toxicity perception.Rather than dismissing this disagreement as
noise, we interpret it as a valuable signal that highlights the inherent
ambiguity of the content,an insight missed when only the majority label is
considered.In this work, we introduce a novel content moderation framework that
emphasizes the importance of capturing annotation disagreement. Our approach
uses multitask learning, where toxicity classification serves as the primary
task and annotation disagreement is addressed as an auxiliary
task.Additionally, we leverage uncertainty estimation techniques, specifically
Conformal Prediction, to account for both the ambiguity in comment annotations
and the model's inherent uncertainty in predicting toxicity and
disagreement.The framework also allows moderators to adjust thresholds for
annotation disagreement, offering flexibility in determining when ambiguity
should trigger a review.We demonstrate that our joint approach enhances model
performance, calibration, and uncertainty estimation, while offering greater
parameter efficiency and improving the review process in comparison to
single-task methods.

摘要：內容審核通常結合人工審核員和機器學習模型的努力。然而，這些系統經常依賴於在審核過程中發生重大分歧的資料，反映出毒性認知的主觀性質。我們不將這種分歧視為雜訊，而是將其解釋為一個有價值的訊號，它突出了內容固有的模糊性，這是僅考慮多數標籤時所忽略的見解。在這項工作中，我們引入了一個新穎的內容審核框架，強調了捕捉註解分歧的重要性。我們的做法採用多任務學習，其中毒性分類作為主要任務，而註解分歧則作為輔助任務。此外，我們利用不確定性估計技術，特別是共形預測，來考量評論註解中的模糊性，以及模型在預測毒性和分歧時固有的不確定性。該框架還允許審核員調整註解分歧的閾值，在確定何時模糊性應觸發審查時提供靈活性。我們證明了我們的聯合方法增強了模型效能、校準和不確定性估計，同時提供了更高的參數效率，並改善了與單一任務方法相比的審查流程。

##### **M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models**
2411.04075v1 by Chuhan Li, Ziyao Shangguan, Yilun Zhao, Deyuan Li, Yixin Liu, Arman Cohan

Existing benchmarks for evaluating foundation models mainly focus on
single-document, text-only tasks. However, they often fail to fully capture the
complexity of research workflows, which typically involve interpreting
non-textual data and gathering information across multiple documents. To
address this gap, we introduce M3SciQA, a multi-modal, multi-document
scientific question answering benchmark designed for a more comprehensive
evaluation of foundation models. M3SciQA consists of 1,452 expert-annotated
questions spanning 70 natural language processing paper clusters, where each
cluster represents a primary paper along with all its cited documents,
mirroring the workflow of comprehending a single paper by requiring multi-modal
and multi-document data. With M3SciQA, we conduct a comprehensive evaluation of
18 foundation models. Our results indicate that current foundation models still
significantly underperform compared to human experts in multi-modal information
retrieval and in reasoning across multiple scientific documents. Additionally,
we explore the implications of these findings for the future advancement of
applying foundation models in multi-modal scientific literature analysis.

摘要：現有的基礎模型評估基準主要專注於單一文件、純文字任務。然而，它們通常無法完全捕捉研究工作流程的複雜性，而這通常涉及解譯非文字資料和跨多個文件收集資訊。為了解決這個差距，我們引入了 M3SciQA，一個多模態、多文件科學問題解答基準，旨在對基礎模型進行更全面的評估。M3SciQA 包含 1,452 個由專家註釋的問題，涵蓋 70 個自然語言處理論文叢集，其中每個叢集代表一篇主要論文及其所有引文文件，反映了透過要求多模態和多文件資料來理解單一論文的工作流程。透過 M3SciQA，我們對 18 個基礎模型進行了全面的評估。我們的結果表明，與在多模態資訊檢索和跨多個科學文件推理的人類專家相比，當前的基礎模型仍然表現得顯著不足。此外，我們探討了這些發現對未來將基礎模型應用於多模態科學文獻分析的影響。

##### **Non-Stationary Learning of Neural Networks with Automatic Soft Parameter Reset**
2411.04034v1 by Alexandre Galashov, Michalis K. Titsias, András György, Clare Lyle, Razvan Pascanu, Yee Whye Teh, Maneesh Sahani

Neural networks are traditionally trained under the assumption that data come
from a stationary distribution. However, settings which violate this assumption
are becoming more popular; examples include supervised learning under
distributional shifts, reinforcement learning, continual learning and
non-stationary contextual bandits. In this work we introduce a novel learning
approach that automatically models and adapts to non-stationarity, via an
Ornstein-Uhlenbeck process with an adaptive drift parameter. The adaptive drift
tends to draw the parameters towards the initialisation distribution, so the
approach can be understood as a form of soft parameter reset. We show
empirically that our approach performs well in non-stationary supervised and
off-policy reinforcement learning settings.

摘要：神經網路傳統上是在假設資料來自固定分佈的條件下訓練的。然而，違反此假設的設定正變得越來越普遍；範例包括分佈轉移下的監督式學習、強化學習、持續學習和非固定情境強盜。在這項工作中，我們介紹了一種新穎的學習方法，它透過具有適應性漂移參數的 Ornstein-Uhlenbeck 過程，自動對非固定性進行建模和適應。適應性漂移傾向於將參數拉向初始化分佈，因此可以將此方法理解為一種軟參數重設形式。我們透過實證顯示，我們的做法在非固定監督式和非策略強化學習設定中表現良好。

##### **Beemo: Benchmark of Expert-edited Machine-generated Outputs**
2411.04032v1 by Ekaterina Artemova, Jason Lucas, Saranya Venkatraman, Jooyoung Lee, Sergei Tilga, Adaku Uchendu, Vladislav Mikhailov

The rapid proliferation of large language models (LLMs) has increased the
volume of machine-generated texts (MGTs) and blurred text authorship in various
domains. However, most existing MGT benchmarks include single-author texts
(human-written and machine-generated). This conventional design fails to
capture more practical multi-author scenarios, where the user refines the LLM
response for natural flow, coherence, and factual correctness. Our paper
introduces the Benchmark of Expert-edited Machine-generated Outputs (Beemo),
which includes 6.5k texts written by humans, generated by ten
instruction-finetuned LLMs, and edited by experts for various use cases,
ranging from creative writing to summarization. Beemo additionally comprises
13.1k machine-generated and LLM-edited texts, allowing for diverse MGT
detection evaluation across various edit types. We document Beemo's creation
protocol and present the results of benchmarking 33 configurations of MGT
detectors in different experimental setups. We find that expert-based editing
evades MGT detection, while LLM-edited texts are unlikely to be recognized as
human-written. Beemo and all materials are publicly available.

摘要：大型語言模型 (LLM) 的快速擴散增加了機器產生的文本 (MGT) 的數量，並模糊了各種領域中的文字作者身份。然而，現有的 MGT 基準大多包含單一作者的文本（人工撰寫和機器產生的）。這種傳統的設計無法捕捉到更實際的多作者場景，在這種場景中，使用者會修改 LLM 回應以獲得自然的流暢性、連貫性和事實正確性。我們的論文介紹了由專家編輯的機器產生的輸出基準 (Beemo)，其中包括 6.5k 篇由人類撰寫、由十個指令微調的 LLM 生成的文本，以及由專家針對各種用例（從創意寫作到摘要）編輯的文本。此外，Beemo 還包含 13.1k 篇機器產生的和 LLM 編輯的文本，允許對各種編輯類型進行多樣化的 MGT 檢測評估。我們記錄了 Beemo 的創建協議，並展示了在不同實驗設置中對 33 種配置的 MGT 檢測器進行基準測試的結果。我們發現基於專家的編輯可以規避 MGT 檢測，而 LLM 編輯的文本不太可能被識別為人工撰寫的。Beemo 和所有材料都公開提供。

##### **Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages**
2411.04025v1 by Aniket Deroy, Subhankar Maity

Language Identification (LI) is crucial for various natural language
processing tasks, serving as a foundational step in applications such as
sentiment analysis, machine translation, and information retrieval. In
multilingual societies like India, particularly among the youth engaging on
social media, text often exhibits code-mixing, blending local languages with
English at different linguistic levels. This phenomenon presents formidable
challenges for LI systems, especially when languages intermingle within single
words. Dravidian languages, prevalent in southern India, possess rich
morphological structures yet suffer from under-representation in digital
platforms, leading to the adoption of Roman or hybrid scripts for
communication. This paper introduces a prompt based method for a shared task
aimed at addressing word-level LI challenges in Dravidian languages. In this
work, we leveraged GPT-3.5 Turbo to understand whether the large language
models is able to correctly classify words into correct categories. Our
findings show that the Kannada model consistently outperformed the Tamil model
across most metrics, indicating a higher accuracy and reliability in
identifying and categorizing Kannada language instances. In contrast, the Tamil
model showed moderate performance, particularly needing improvement in
precision and recall.

摘要：語言辨識 (LI) 對於各種自然語言處理任務至關重要，是情緒分析、機器翻譯和資訊檢索等應用中的基礎步驟。在印度等多語言社會中，特別是在參與社群媒體的年輕人中，文字經常表現出混合語言，在不同的語言層級中融合了當地語言和英語。這種現象對 LI 系統構成嚴峻的挑戰，特別是在語言在單詞中混合時。在印度南部流行的達羅毗荼語擁有豐富的形態結構，但在數位平台上卻缺乏代表性，導致採用羅馬或混合文字進行溝通。本文介紹了一種基於提示的方法，用於解決達羅毗荼語中單詞層級 LI 挑戰的共享任務。在這項工作中，我們利用 GPT-3.5 Turbo 來了解大型語言模型是否能夠將單詞正確分類到正確的類別中。我們的研究結果表明，Kannada 模型在大多數指標上始終優於 Tamil 模型，這表明在識別和分類 Kannada 語言實例時具有更高的準確性和可靠性。相比之下，Tamil 模型表現普通，特別需要在精確度和召回率方面進行改進。

##### **Predicting and Publishing Accurate Imbalance Prices Using Monte Carlo Tree Search**
2411.04011v1 by Fabio Pavirani, Jonas Van Gompel, Seyed Soroush Karimi Madahi, Bert Claessens, Chris Develder

The growing reliance on renewable energy sources, particularly solar and
wind, has introduced challenges due to their uncontrollable production. This
complicates maintaining the electrical grid balance, prompting some
transmission system operators in Western Europe to implement imbalance tariffs
that penalize unsustainable power deviations. These tariffs create an implicit
demand response framework to mitigate grid instability. Yet, several challenges
limit active participation. In Belgium, for example, imbalance prices are only
calculated at the end of each 15-minute settlement period, creating high risk
due to price uncertainty. This risk is further amplified by the inherent
volatility of imbalance prices, discouraging participation. Although
transmission system operators provide minute-based price predictions, the
system imbalance volatility makes accurate price predictions challenging to
obtain and requires sophisticated techniques. Moreover, publishing price
estimates can prompt participants to adjust their schedules, potentially
affecting the system balance and the final price, adding further complexity. To
address these challenges, we propose a Monte Carlo Tree Search method that
publishes accurate imbalance prices while accounting for potential response
actions. Our approach models the system dynamics using a neural network
forecaster and a cluster of virtual batteries controlled by reinforcement
learning agents. Compared to Belgium's current publication method, our
technique improves price accuracy by 20.4% under ideal conditions and by 12.8%
in more realistic scenarios. This research addresses an unexplored, yet crucial
problem, positioning this paper as a pioneering work in analyzing the potential
of more advanced imbalance price publishing techniques.

摘要：隨著再生能源，特別是太陽能和風能的使用日益依賴，由於其不可控的生產而產生了挑戰。這使得電網平衡的維護變得複雜，促使西歐的一些輸電系統運營商實施不平衡關稅，以懲罰不可持續的電力偏差。這些關稅創造了一個隱含的需求響應框架，以減輕電網不穩定性。然而，一些挑戰限制了積極參與。例如，在比利時，不平衡價格僅在每 15 分鐘結算期結束時計算，由於價格不確定性而造成高風險。不平衡價格固有的波動性進一步放大了這種風險，阻礙了參與。儘管輸電系統運營商提供了基於分鐘的價格預測，但系統不平衡的波動性使得準確的價格預測難以獲得，並且需要複雜的技術。此外，發布價格估計會促使參與者調整其時間表，這可能會影響系統平衡和最終價格，從而增加進一步的複雜性。為了應對這些挑戰，我們提出了一種蒙特卡羅樹搜索方法，該方法在考慮潛在響應措施的同時發布準確的不平衡價格。我們的解決方案使用神經網路預測器和由強化學習代理控制的一組虛擬電池對系統動態進行建模。與比利時目前的發布方法相比，我們的技術在理想條件下將價格準確度提高了 20.4%，在更現實的場景中提高了 12.8%。這項研究解決了一個尚未探索但至關重要問題，將本文定位為分析更先進的不平衡價格發布技術潛力的開創性工作。

##### **Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability**
2411.04008v1 by Bharat Chandra Yalavarthi, Nalini Ratha

In mission-critical domains such as law enforcement and medical diagnosis,
the ability to explain and interpret the outputs of deep learning models is
crucial for ensuring user trust and supporting informed decision-making.
Despite advancements in explainability, existing methods often fall short in
providing explanations that mirror the depth and clarity of those given by
human experts. Such expert-level explanations are essential for the dependable
application of deep learning models in law enforcement and medical contexts.
Additionally, we recognize that most explanations in real-world scenarios are
communicated primarily through natural language. Addressing these needs, we
propose a novel approach that utilizes characteristic descriptors to explain
model decisions by identifying their presence in images, thereby generating
expert-like explanations. Our method incorporates a concept bottleneck layer
within the model architecture, which calculates the similarity between image
and descriptor encodings to deliver inherent and faithful explanations. Through
experiments in face recognition and chest X-ray diagnosis, we demonstrate that
our approach offers a significant contrast over existing techniques, which are
often limited to the use of saliency maps. We believe our approach represents a
significant step toward making deep learning systems more accountable,
transparent, and trustworthy in the critical domains of face recognition and
medical diagnosis.

摘要：在执法和医疗诊断等任务关键型领域，
解释和诠释深度学习模型的输出对于确保用户信任和支持知情决策至关重要。
尽管可解释性方面取得了进步，但现有方法在提供解释时往往达不到人类专家给出的深度和清晰度。这种专家级别的解释对于在执法和医疗环境中可靠地应用深度学习模型至关重要。
此外，我们认识到，在现实世界场景中，大多数解释主要是通过自然语言进行交流的。为了满足这些需求，我们提出了一种新颖的方法，该方法利用特征描述符通过识别图像中的特征描述符的存在来解释模型决策，从而生成类似专家的解释。我们的方法在模型架构中加入了一个概念瓶颈层，该层计算图像和描述符编码之间的相似性，以提供内在且可靠的解释。通过面部识别和胸部 X 射线诊断的实验，我们证明了我们的方法与现有技术相比具有显着优势，而现有技术通常仅限于使用显着性图。我们相信，我们的方法代表了朝着使深度学习系统在面部识别和医疗诊断的关键领域更加负责、透明和值得信赖迈出的重要一步。

##### **Select2Plan: Training-Free ICL-Based Planning through VQA and Memory Retrieval**
2411.04006v1 by Davide Buoso, Luke Robinson, Giuseppe Averta, Philip Torr, Tim Franzmeyer, Daniele De Martini

This study explores the potential of off-the-shelf Vision-Language Models
(VLMs) for high-level robot planning in the context of autonomous navigation.
Indeed, while most of existing learning-based approaches for path planning
require extensive task-specific training/fine-tuning, we demonstrate how such
training can be avoided for most practical cases. To do this, we introduce
Select2Plan (S2P), a novel training-free framework for high-level robot
planning which completely eliminates the need for fine-tuning or specialised
training. By leveraging structured Visual Question-Answering (VQA) and
In-Context Learning (ICL), our approach drastically reduces the need for data
collection, requiring a fraction of the task-specific data typically used by
trained models, or even relying only on online data. Our method facilitates the
effective use of a generally trained VLM in a flexible and cost-efficient way,
and does not require additional sensing except for a simple monocular camera.
We demonstrate its adaptability across various scene types, context sources,
and sensing setups. We evaluate our approach in two distinct scenarios:
traditional First-Person View (FPV) and infrastructure-driven Third-Person View
(TPV) navigation, demonstrating the flexibility and simplicity of our method.
Our technique significantly enhances the navigational capabilities of a
baseline VLM of approximately 50% in TPV scenario, and is comparable to trained
models in the FPV one, with as few as 20 demonstrations.

摘要：本研究探討了現成的視覺語言模型 (VLM) 在自主導航背景下用於高階機器人規劃的潛力。的確，雖然現有的基於學習的路徑規劃方法大多需要大量的特定任務訓練/微調，但我們展示了在大部分實際案例中如何避免這種訓練。為此，我們引入了 Select2Plan (S2P)，這是一種用於高階機器人規劃的新型免訓練框架，它完全消除了微調或專門訓練的需要。通過利用結構化的視覺問答 (VQA) 和語境學習 (ICL)，我們的做法大幅減少了對數據收集的需求，只需要訓練模型通常使用的特定任務數據的一小部分，甚至只依賴於在線數據。我們的辦法促進了以靈活且具有成本效益的方式有效使用經過一般訓練的 VLM，並且除了簡單的單目相機外，不需要額外的感測。我們展示了它對各種場景類型、上下文來源和感測設定的適應性。我們在兩種不同的場景中評估了我們的做法：傳統的第一人稱視角 (FPV) 和基礎設施驅動的第三人稱視角 (TPV) 導航，展示了我們方法的靈活性與簡潔性。我們的技術顯著增強了 TPV 場景中約 50% 的基準 VLM 的導航能力，並且在 FPV 場景中與訓練模型相當，僅需 20 次示範。

##### **Towards Resource-Efficient Federated Learning in Industrial IoT for Multivariate Time Series Analysis**
2411.03996v1 by Alexandros Gkillas, Aris Lalos

Anomaly and missing data constitute a thorny problem in industrial
applications. In recent years, deep learning enabled anomaly detection has
emerged as a critical direction, however the improved detection accuracy is
achieved with the utilization of large neural networks, increasing their
storage and computational cost. Moreover, the data collected in edge devices
contain user privacy, introducing challenges that can be successfully addressed
by the privacy-preserving distributed paradigm, known as federated learning
(FL). This framework allows edge devices to train and exchange models
increasing also the communication cost. Thus, to deal with the increased
communication, processing and storage challenges of the FL based deep anomaly
detection NN pruning is expected to have significant benefits towards reducing
the processing, storage and communication complexity. With this focus, a novel
compression-based optimization problem is proposed at the server-side of a FL
paradigm that fusses the received local models broadcast and performs pruning
generating a more compressed model. Experiments in the context of anomaly
detection and missing value imputation demonstrate that the proposed FL
scenario along with the proposed compressed-based method are able to achieve
high compression rates (more than $99.7\%$) with negligible performance losses
(less than $1.18\%$ ) as compared to the centralized solutions.

摘要：異常和遺失資料在工業應用中構成棘手的問題。近年來，深度學習啟用的異常偵測已成為一個重要的方向，然而，改進的偵測準確度是透過利用大型神經網路來實現，增加了它們的儲存和運算成本。此外，在邊緣裝置中收集的資料包含使用者隱私，引入了挑戰，這些挑戰可透過稱為聯合學習 (FL) 的隱私保護分散式範例來成功解決。此架構允許邊緣裝置訓練和交換模型，同時也增加了通訊成本。因此，為了應對 FL 基於深度異常偵測的通訊、處理和儲存挑戰，預計 NN 剪枝將對降低處理、儲存和通訊複雜度有顯著的好處。基於此重點，在 FL 範例的伺服器端提出了一個新的基於壓縮的最佳化問題，它會混淆接收到的本地模型廣播並執行剪枝，產生一個更壓縮的模型。在異常偵測和遺失值填補的背景下進行的實驗證明，所提出的 FL 場景連同所提出的基於壓縮的方法能夠實現高壓縮率（超過 99.7%），而效能損失可以忽略不計（小於 1.18%），與集中式解決方案相比。

##### **WorryWords: Norms of Anxiety Association for over 44k English Words**
2411.03966v1 by Saif M. Mohammad

Anxiety, the anticipatory unease about a potential negative outcome, is a
common and beneficial human emotion. However, there is still much that is not
known, such as how anxiety relates to our body and how it manifests in
language. This is especially pertinent given the increasing impact of
anxiety-related disorders. In this work, we introduce WorryWords, the first
large-scale repository of manually derived word--anxiety associations for over
44,450 English words. We show that the anxiety associations are highly
reliable. We use WorryWords to study the relationship between anxiety and other
emotion constructs, as well as the rate at which children acquire anxiety words
with age. Finally, we show that using WorryWords alone, one can accurately
track the change of anxiety in streams of text. The lexicon enables a wide
variety of anxiety-related research in psychology, NLP, public health, and
social sciences. WorryWords (and its translations to over 100 languages) is
freely available. http://saifmohammad.com/worrywords.html

摘要：焦慮，對潛在負面結果的預期不安，是一種常見且有益的人類情緒。然而，仍有許多未知，例如焦慮如何與我們的身體相關，以及它如何在語言中表現出來。這一點尤其重要，因為與焦慮相關的疾病影響越來越大。在這項工作中，我們介紹了 WorryWords，這是第一個大規模的人工派生詞彙——焦慮關聯儲存庫，包含超過 44,450 個英文單字。我們證明了焦慮關聯具有高度可靠性。我們使用 WorryWords 來研究焦慮與其他情緒建構之間的關係，以及兒童隨著年齡增長而習得焦慮詞彙的速度。最後，我們證明了僅使用 WorryWords，就可以準確追蹤文字串流中的焦慮變化。此詞彙表使心理學、自然語言處理、公共衛生和社會科學中各種與焦慮相關的研究成為可能。WorryWords（及其翻譯成 100 多種語言）是免費提供的。http://saifmohammad.com/worrywords.html

##### **What Really is Commonsense Knowledge?**
2411.03964v1 by Quyet V. Do, Junze Li, Tung-Duong Vuong, Zhaowei Wang, Yangqiu Song, Xiaojuan Ma

Commonsense datasets have been well developed in Natural Language Processing,
mainly through crowdsource human annotation. However, there are debates on the
genuineness of commonsense reasoning benchmarks. In specific, a significant
portion of instances in some commonsense benchmarks do not concern commonsense
knowledge. That problem would undermine the measurement of the true commonsense
reasoning ability of evaluated models. It is also suggested that the problem
originated from a blurry concept of commonsense knowledge, as distinguished
from other types of knowledge. To demystify all of the above claims, in this
study, we survey existing definitions of commonsense knowledge, ground into the
three frameworks for defining concepts, and consolidate them into a
multi-framework unified definition of commonsense knowledge (so-called
consolidated definition). We then use the consolidated definition for
annotations and experiments on the CommonsenseQA and CommonsenseQA 2.0 datasets
to examine the above claims. Our study shows that there exists a large portion
of non-commonsense-knowledge instances in the two datasets, and a large
performance gap on these two subsets where Large Language Models (LLMs) perform
worse on commonsense-knowledge instances.

摘要：常识数据集在自然语言处理中得到很好的发展，主要是通过众包人工注释。然而，关于常识推理基准的真实性存在争论。具体来说，一些常识基准中的大量实例并不涉及常识知识。该问题将损害对评估模型的真实常识推理能力的衡量。还提出，该问题源于对常识知识的模糊概念，与其他类型的知识相区别。为了揭开上述所有说法的神秘面纱，在本研究中，我们调查了常识知识的现有定义，将其归纳为定义概念的三个框架，并将它们整合到常识知识的多框架统一定义中（即所谓的综合定义）。然后，我们对 CommonsenseQA 和 CommonsenseQA 2.0 数据集使用综合定义进行注释和实验，以检验上述说法。我们的研究表明，这两个数据集中存在大量的非常识知识实例，并且在这两个子集上存在较大的性能差距，其中大型语言模型 (LLM) 在常识知识实例上的表现较差。

##### **How Does A Text Preprocessing Pipeline Affect Ontology Syntactic Matching?**
2411.03962v1 by Zhangcheng Qiang, Kerry Taylor, Weiqing Wang

The generic text preprocessing pipeline, comprising Tokenisation,
Normalisation, Stop Words Removal, and Stemming/Lemmatisation, has been
implemented in many ontology matching (OM) systems. However, the lack of
standardisation in text preprocessing creates diversity in mapping results. In
this paper, we investigate the effect of the text preprocessing pipeline on OM
tasks at syntactic levels. Our experiments on 8 Ontology Alignment Evaluation
Initiative (OAEI) track repositories with 49 distinct alignments indicate: (1)
Tokenisation and Normalisation are currently more effective than Stop Words
Removal and Stemming/Lemmatisation; and (2) The selection of Lemmatisation and
Stemming is task-specific. We recommend standalone Lemmatisation or Stemming
with post-hoc corrections. We find that (3) Porter Stemmer and Snowball Stemmer
perform better than Lancaster Stemmer; and that (4) Part-of-Speech (POS)
Tagging does not help Lemmatisation. To repair less effective Stop Words
Removal and Stemming/Lemmatisation used in OM tasks, we propose a novel
context-based pipeline repair approach that significantly improves matching
correctness and overall matching performance. We also discuss the use of text
preprocessing pipeline in the new era of large language models (LLMs).

摘要：通用的文字預處理管線，包含斷詞、正規化、停用詞移除，以及詞幹化/詞形還原，已在許多本体對應 (OM) 系統中實作。然而，文字預處理缺乏標準化，導致對應結果出現差異性。在本文中，我們探討文字預處理管線對句法層級 OM 任務的影響。我們針對 8 個本体對齊評估計畫 (OAEI) 追蹤儲存庫進行實驗，其中包含 49 個不同的對齊，結果顯示：(1) 斷詞和正規化目前比停用詞移除和詞幹化/詞形還原更有效；(2) 詞形還原和詞幹化的選擇取決於任務。我們建議使用獨立的詞形還原或詞幹化，並進行事後修正。我們發現：(3) Porter 詞幹分析器和 Snowball 詞幹分析器的表現比 Lancaster 詞幹分析器好；(4) 詞性標記對詞形還原沒有幫助。為了修復在 OM 任務中使用效果較差的停用詞移除和詞幹化/詞形還原，我們提出一個新穎的基於脈絡的管線修復方法，可顯著提升對應正確性和整體對應效能。我們也討論了在大型語言模型 (LLM) 的新時代中，文字預處理管線的應用。

##### **Energy Score-based Pseudo-Label Filtering and Adaptive Loss for Imbalanced Semi-supervised SAR target recognition**
2411.03959v1 by Xinzheng Zhang, Yuqing Luo, Guopeng Li

Automatic target recognition (ATR) is an important use case for synthetic
aperture radar (SAR) image interpretation. Recent years have seen significant
advancements in SAR ATR technology based on semi-supervised learning. However,
existing semi-supervised SAR ATR algorithms show low recognition accuracy in
the case of class imbalance. This work offers a non-balanced semi-supervised
SAR target recognition approach using dynamic energy scores and adaptive loss.
First, an energy score-based method is developed to dynamically select
unlabeled samples near to the training distribution as pseudo-labels during
training, assuring pseudo-label reliability in long-tailed distribution
circumstances. Secondly, loss functions suitable for class imbalances are
proposed, including adaptive margin perception loss and adaptive hard triplet
loss, the former offsets inter-class confusion of classifiers, alleviating the
imbalance issue inherent in pseudo-label generation. The latter effectively
tackles the model's preference for the majority class by focusing on complex
difficult samples during training. Experimental results on extremely imbalanced
SAR datasets demonstrate that the proposed method performs well under the dual
constraints of scarce labels and data imbalance, effectively overcoming the
model bias caused by data imbalance and achieving high-precision target
recognition.

摘要：自動目標辨識 (ATR) 是合成孔徑雷達 (SAR) 影像判讀的重要使用案例。近年來，基於半監督學習的 SAR ATR 技術有顯著進展。然而，現有的半監督 SAR ATR 演算法在類別不平衡的情況下，辨識準確度低。本研究提出一個使用動態能量分數和自適應損失的非平衡半監督 SAR 目標辨識方法。首先，開發一個基於能量分數的方法，在訓練過程中動態選擇接近訓練分佈的未標籤樣本作為偽標籤，確保在長尾分佈情況下偽標籤的可靠性。其次，提出適用於類別不平衡的損失函數，包括自適應邊際感知損失和自適應硬三元組損失，前者抵消分類器的類間混淆，緩解偽標籤生成中固有的不平衡問題。後者透過在訓練過程中專注於複雜的困難樣本，有效解決模型對多數類別的偏好。在極度不平衡的 SAR 資料集上的實驗結果表明，所提出的方法在標籤稀少和資料不平衡的雙重約束下表現良好，有效克服資料不平衡造成的模型偏誤，並實現高精度的目標辨識。

##### **Fine-Grained Guidance for Retrievers: Leveraging LLMs' Feedback in Retrieval-Augmented Generation**
2411.03957v1 by Yuhang Liu, Xueyu Hu, Shengyu Zhang, Jingyuan Chen, Fan Wu, Fei Wu

Retrieval-Augmented Generation (RAG) has proven to be an effective method for
mitigating hallucination issues inherent in large language models (LLMs).
Previous approaches typically train retrievers based on semantic similarity,
lacking optimization for RAG. More recent works have proposed aligning
retrievers with the preference signals of LLMs. However, these preference
signals are often difficult for dense retrievers, which typically have weaker
language capabilities, to understand and learn effectively. Drawing inspiration
from pedagogical theories like Guided Discovery Learning, we propose a novel
framework, FiGRet (Fine-grained Guidance for Retrievers), which leverages the
language capabilities of LLMs to construct examples from a more granular,
information-centric perspective to guide the learning of retrievers.
Specifically, our method utilizes LLMs to construct easy-to-understand examples
from samples where the retriever performs poorly, focusing on three learning
objectives highly relevant to the RAG scenario: relevance, comprehensiveness,
and purity. These examples serve as scaffolding to ultimately align the
retriever with the LLM's preferences. Furthermore, we employ a dual curriculum
learning strategy and leverage the reciprocal feedback between LLM and
retriever to further enhance the performance of the RAG system. A series of
experiments demonstrate that our proposed framework enhances the performance of
RAG systems equipped with different retrievers and is applicable to various
LLMs.

摘要：檢索增強生成 (RAG) 已被證明是一種有效的方法，可減輕大型語言模型 (LLM) 中固有的幻覺問題。
先前的做法通常根據語義相似性訓練檢索器，缺少針對 RAG 的最佳化。最近的研究已提議將檢索器與 LLM 的偏好信號對齊。然而，這些偏好信號通常難以讓通常具有較弱語言能力的稠密檢索器理解並有效學習。從指導發現學習等教學理論中汲取靈感，我們提出了一個新框架 FiGRet（檢索器的細粒度指導），它利用 LLM 的語言能力從更精細、以資訊為中心的角度構建範例，以指導檢索器的學習。
具體而言，我們的方法利用 LLM 從檢索器表現不佳的範例中構建易於理解的範例，專注於與 RAG 情境高度相關的三個學習目標：相關性、全面性和純度。這些範例作為腳手架，最終將檢索器與 LLM 的偏好對齊。此外，我們採用雙課程學習策略，並利用 LLM 和檢索器之間的相互回饋，進一步增強 RAG 系統的效能。一系列實驗證明，我們提出的框架增強了配備不同檢索器的 RAG 系統的效能，並且適用於各種 LLM。

##### **Long-Form Text-to-Music Generation with Adaptive Prompts: A Case of Study in Tabletop Role-Playing Games Soundtracks**
2411.03948v1 by Felipe Marra, Lucas N. Ferreira

This paper investigates the capabilities of text-to-audio music generation
models in producing long-form music with prompts that change over time,
focusing on soundtrack generation for Tabletop Role-Playing Games (TRPGs). We
introduce Babel Bardo, a system that uses Large Language Models (LLMs) to
transform speech transcriptions into music descriptions for controlling a
text-to-music model. Four versions of Babel Bardo were compared in two TRPG
campaigns: a baseline using direct speech transcriptions, and three LLM-based
versions with varying approaches to music description generation. Evaluations
considered audio quality, story alignment, and transition smoothness. Results
indicate that detailed music descriptions improve audio quality while
maintaining consistency across consecutive descriptions enhances story
alignment and transition smoothness.

摘要：本文探討文本轉音訊音樂生成模型在產生隨著時間推移而變化的長篇音樂的能力，重點在於桌上角色扮演遊戲 (TRPG) 的配樂生成。我們介紹 Babel Bardo，一個使用大型語言模型 (LLM) 將語音轉錄轉換為音樂描述的系統，用於控制文本轉音樂模型。在兩個 TRPG 戰役中比較了四個版本的 Babel Bardo：使用直接語音轉錄的基準，以及三個採用不同音樂描述生成方法的基於 LLM 的版本。評估考慮了音訊品質、故事對齊和轉場流暢度。結果表明，詳細的音樂描述改善了音訊品質，而連續描述之間保持一致性則增強了故事對齊和轉場流暢度。

##### **Can Custom Models Learn In-Context? An Exploration of Hybrid Architecture Performance on In-Context Learning Tasks**
2411.03945v1 by Ryan Campbell, Nelson Lojo, Kesava Viswanadha, Christoffer Grondal Tryggestad, Derrick Han Sun, Sriteja Vijapurapu, August Rolfsen, Anant Sahai

In-Context Learning (ICL) is a phenomenon where task learning occurs through
a prompt sequence without the necessity of parameter updates. ICL in
Multi-Headed Attention (MHA) with absolute positional embedding has been the
focus of more study than other sequence model varieties. We examine
implications of architectural differences between GPT-2 and LLaMa as well as
LlaMa and Mamba. We extend work done by Garg et al. (2022) and Park et al.
(2024) to GPT-2/LLaMa hybrid and LLaMa/Mamba hybrid models - examining the
interplay between sequence transformation blocks and regressive performance
in-context. We note that certain architectural changes cause degraded training
efficiency/ICL accuracy by converging to suboptimal predictors or converging
slower. We also find certain hybrids showing optimistic performance
improvements, informing potential future ICL-focused architecture
modifications. Additionally, we propose the "ICL regression score", a scalar
metric describing a model's whole performance on a specific task. Compute
limitations impose restrictions on our architecture-space, training duration,
number of training runs, function class complexity, and benchmark complexity.
To foster reproducible and extensible research, we provide a typed, modular,
and extensible Python package on which we run all experiments.

摘要：情境學習 (ICL) 是一種現象，其中任務學習透過提示序列發生，而無需參數更新。具有絕對位置嵌入的多頭注意力 (MHA) 中的 ICL 一直比其他序列模型種類受到更多研究的關注。我們探討了 GPT-2 和 LLaMa 之間的架構差異以及 LLaMa 和 Mamba 之間的架構差異的含義。我們將 Garg 等人 (2022) 和 Park 等人 (2024) 所做的工作擴展到 GPT-2/LLaMa 混合模型和 LLaMa/Mamba 混合模型，探討了序列轉換區塊和情境中回歸效能之間的交互作用。我們注意到某些架構變更會導致訓練效率/ICL 準確度下降，這是因為它們收斂到次佳預測器或收斂速度較慢。我們還發現某些混合模型顯示樂觀的效能改善，這為潛在的未來以 ICL 為重點的架構修改提供了資訊。此外，我們提出了「ICL 回歸分數」，這是一個描述模型在特定任務上的整體效能的標量指標。運算限制對我們的架構空間、訓練持續時間、訓練執行次數、函數類別複雜度和基準複雜度施加了限制。為了促進可複製且可擴充的研究，我們提供了一個類型化、模組化且可擴充的 Python 套件，我們在其中執行所有實驗。

##### **Fine-tuning -- a Transfer Learning approach**
2411.03941v1 by Joseph Arul Raj, Linglong Qian, Zina Ibrahim

Secondary research use of Electronic Health Records (EHRs) is often hampered
by the abundance of missing data in this valuable resource. Missingness in EHRs
occurs naturally as a result of the data recording practices during routine
clinical care, but handling it is crucial to the precision of medical analysis
and the decision-making that follows. The literature contains a variety of
imputation methodologies based on deep neural networks. Those aim to overcome
the dynamic, heterogeneous and multivariate missingness patterns of EHRs, which
cannot be handled by classical and statistical imputation methods. However, all
existing deep imputation methods rely on end-to-end pipelines that incorporate
both imputation and downstream analyses, e.g. classification. This coupling
makes it difficult to assess the quality of imputation and takes away the
flexibility of re-using the imputer for a different task. Furthermore, most
end-to-end deep architectures tend to use complex networks to perform the
downstream task, in addition to the already sophisticated deep imputation
network. We, therefore ask if the high performance reported in the literature
is due to the imputer or the classifier and further ask if an optimised
state-of-the-art imputer is used, a simpler classifier can achieve comparable
performance. This paper explores the development of a modular, deep
learning-based imputation and classification pipeline, specifically built to
leverage the capabilities of state-of-the-art imputation models for downstream
classification tasks. Such a modular approach enables a) objective assessment
of the quality of the imputer and classifier independently, and b) enables the
exploration of the performance of simpler classification architectures using an
optimised imputer.

摘要：電子健康紀錄 (EHR) 的二次研究用途經常受到此寶貴資源中大量遺失資料的阻礙。EHR 中的遺失資料會在例行臨床照護期間的資料記錄實務中自然發生，但處理遺失資料對於醫療分析的精確度和後續決策至關重要。文獻中包含各種基於深度神經網路的內插方法。這些方法旨在克服 EHR 中動態、異質且多變量的遺失資料模式，而這無法透過傳統和統計內插方法來處理。然而，所有現有的深度內插方法都依賴於將內插和下游分析（例如分類）結合在一起的端到端管道。這種結合使得難以評估內插的品質，並消除了重新使用內插器進行不同任務的靈活性。此外，大多數端到端深度架構傾向於使用複雜的網路來執行下游任務，除了已經很複雜的深度內插網路之外。因此，我們詢問文獻中報導的高效能是由於內插器還是分類器，並進一步詢問是否使用了最佳化的最新內插器，較簡單的分類器是否可以達到相近的效能。本文探討模組化、基於深度學習的內插和分類管道的開發，特別是建構來利用最新內插模型的能力，以進行下游分類任務。這種模組化方法能 a) 客觀評估內插器和分類器的品質，以及 b) 能夠使用最佳化的內插器來探討較簡單分類架構的效能。

##### **Interactions Across Blocks in Post-Training Quantization of Large Language Models**
2411.03934v1 by Khasmamad Shabanovi, Lukas Wiest, Vladimir Golkov, Daniel Cremers, Thomas Pfeil

Post-training quantization is widely employed to reduce the computational
demands of neural networks. Typically, individual substructures, such as layers
or blocks of layers, are quantized with the objective of minimizing
quantization errors in their pre-activations by fine-tuning the corresponding
weights. Deriving this local objective from the global objective of minimizing
task loss involves two key simplifications: assuming substructures are mutually
independent and ignoring the knowledge of subsequent substructures as well as
the task loss. In this work, we assess the effects of these simplifications on
weight-only quantization of large language models. We introduce two multi-block
fine-tuning strategies and compare them against the baseline of fine-tuning
single transformer blocks. The first captures correlations of weights across
blocks by jointly optimizing multiple quantized blocks. The second incorporates
knowledge of subsequent blocks by minimizing the error in downstream
pre-activations rather than focusing solely on the quantized block. Our
findings indicate that the effectiveness of these methods depends on the
specific network model, with no impact on some models but demonstrating
significant benefits for others.

摘要：訓練後量化廣泛用於減少神經網路的運算需求。通常，個別子結構（例如層或層塊）會量化，目的是透過微調對應的權重來最小化其預激活中的量化誤差。從最小化任務損失的整體目標中推導出這個局部目標涉及兩個關鍵簡化：假設子結構相互獨立，並忽略後續子結構以及任務損失的知識。在這項工作中，我們評估這些簡化對大型語言模型的僅權重量化的影響。我們引入了兩種多區塊微調策略，並將它們與微調單一Transformer區塊的基準進行比較。第一個透過共同最佳化多個量化區塊來擷取跨區塊的權重相關性。第二個透過最小化下游預激活中的誤差（而非僅專注於量化區塊）來納入後續區塊的知識。我們的研究結果表明，這些方法的有效性取決於特定的網路模型，對某些模型沒有影響，但對其他模型則展現出顯著的優點。

##### **Evaluation data contamination in LLMs: how do we measure it and (when) does it matter?**
2411.03923v1 by Aaditya K. Singh, Muhammed Yusuf Kocyigit, Andrew Poulton, David Esiobu, Maria Lomeli, Gergely Szilvasy, Dieuwke Hupkes

Hampering the interpretation of benchmark scores, evaluation data
contamination has become a growing concern in the evaluation of LLMs, and an
active area of research studies its effects. While evaluation data
contamination is easily understood intuitively, it is surprisingly difficult to
define precisely which samples should be considered contaminated and,
consequently, how it impacts benchmark scores. We propose that these questions
should be addressed together and that contamination metrics can be assessed
based on whether models benefit from the examples they mark contaminated. We
propose a novel analysis method called ConTAM, and show with a large scale
survey of existing and novel n-gram based contamination metrics across 13
benchmarks and 7 models from 2 different families that ConTAM can be used to
better understand evaluation data contamination and its effects. We find that
contamination may have a much larger effect than reported in recent LLM
releases and benefits models differently at different scales. We also find that
considering only the longest contaminated substring provides a better signal
than considering a union of all contaminated substrings, and that doing model
and benchmark specific threshold analysis greatly increases the specificity of
the results. Lastly, we investigate the impact of hyperparameter choices,
finding that, among other things, both using larger values of n and
disregarding matches that are infrequent in the pre-training data lead to many
false negatives. With ConTAM, we provide a method to empirically ground
evaluation data contamination metrics in downstream effects. With our
exploration, we shed light on how evaluation data contamination can impact LLMs
and provide insight into the considerations important when doing contamination
analysis. We end our paper by discussing these in more detail and providing
concrete suggestions for future work.

摘要：基準分數的詮釋受到阻礙，評量資料的污染已成為 LLM 評量中日益嚴重的問題，而研究其影響也成為研究領域的熱門議題。雖然評量資料污染在直覺上很容易理解，但要精確定義哪些範例應被視為受到污染，以及後續對基準分數的影響，卻意外地困難。我們建議應同時探討這些問題，並可根據模型是否從其標記為受污染的範例中受益來評估污染指標。我們提出了一種名為 ConTAM 的新穎分析方法，並透過針對 13 個基準和來自 2 個不同系列的 7 個模型進行大規模調查，證明了 ConTAM 可用於更深入了解評量資料污染及其影響。我們發現，污染的影響可能遠大於最近 LLM 發布所報告的影響，而且在不同規模下對模型的影響也不同。我們還發現，僅考慮最長的受污染子字串會提供比考慮所有受污染子字串的聯集更好的訊號，而且執行模型和基準特定的閾值分析會大幅提高結果的專一性。最後，我們探討了超參數選擇的影響，發現除了其他因素外，使用較大的 n 值和忽略預訓練資料中不頻繁的比對都會導致許多假陰性。透過 ConTAM，我們提供了一種方法，可以在下游效應中以經驗為基礎建立評量資料污染指標。透過我們的探討，我們闡明了評量資料污染如何影響 LLM，並提供了在進行污染分析時要考量的重要因素。我們在論文的最後對這些因素進行更詳細的討論，並針對未來的研究提供具體的建議。

##### **RAGulator: Lightweight Out-of-Context Detectors for Grounded Text Generation**
2411.03920v1 by Ian Poey, Jiajun Liu, Qishuai Zhong, Adrien Chenailler

Real-time detection of out-of-context LLM outputs is crucial for enterprises
looking to safely adopt RAG applications. In this work, we train lightweight
models to discriminate LLM-generated text that is semantically out-of-context
from retrieved text documents. We preprocess a combination of summarisation and
semantic textual similarity datasets to construct training data using minimal
resources. We find that DeBERTa is not only the best-performing model under
this pipeline, but it is also fast and does not require additional text
preprocessing or feature engineering. While emerging work demonstrates that
generative LLMs can also be fine-tuned and used in complex data pipelines to
achieve state-of-the-art performance, we note that speed and resource limits
are important considerations for on-premise deployment.

摘要：對於尋求安全採用 RAG 應用程式的企業而言，即時偵測語境外 LLM 輸出至關重要。在此工作中，我們訓練輕量級模型來區分語義上與檢索的文字文件無關的 LLM 生成的文字。我們預處理摘要和語義文字相似性資料集的組合，使用最少的資源來建構訓練資料。我們發現 DeBERTa 不僅是此管道下效能最好的模型，而且速度快，且不需要額外的文字預處理或特徵工程。雖然新興工作證明，生成式 LLM 也可以進行微調，並用於複雜的資料管道中，以達成最先進的效能，但我們注意到速度和資源限制是內部部署的重要考量因素。

##### **Lexicalization Is All You Need: Examining the Impact of Lexical Knowledge in a Compositional QALD System**
2411.03906v1 by David Maria Schmidt, Mohammad Fazleh Elahi, Philipp Cimiano

In this paper, we examine the impact of lexicalization on Question Answering
over Linked Data (QALD). It is well known that one of the key challenges in
interpreting natural language questions with respect to SPARQL lies in bridging
the lexical gap, that is mapping the words in the query to the correct
vocabulary elements. We argue in this paper that lexicalization, that is
explicit knowledge about the potential interpretations of a word with respect
to the given vocabulary, significantly eases the task and increases the
performance of QA systems. Towards this goal, we present a compositional QA
system that can leverage explicit lexical knowledge in a compositional manner
to infer the meaning of a question in terms of a SPARQL query. We show that
such a system, given lexical knowledge, has a performance well beyond current
QA systems, achieving up to a $35.8\%$ increase in the micro $F_1$ score
compared to the best QA system on QALD-9. This shows the importance and
potential of including explicit lexical knowledge. In contrast, we show that
LLMs have limited abilities to exploit lexical knowledge, with only marginal
improvements compared to a version without lexical knowledge. This shows that
LLMs have no ability to compositionally interpret a question on the basis of
the meaning of its parts, a key feature of compositional approaches. Taken
together, our work shows new avenues for QALD research, emphasizing the
importance of lexicalization and compositionality.

摘要：<paragraph>在本文中，我們探討了詞彙化對鏈結資料問答 (QALD) 的影響。眾所周知，在將自然語言問題解釋為 SPARQL 時，關鍵挑戰之一在於彌合詞彙差距，也就是將查詢中的詞彙對應到正確的詞彙元素。我們在本文中論證，詞彙化，也就是關於詞彙對應到特定詞彙的潛在解釋的明確知識，可以大幅簡化任務並提升問答系統的效能。為了達成這個目標，我們提出了組合式問答系統，可以以組合式的方式利用明確的詞彙知識，以 SPARQL 查詢的形式推論問題的意義。我們展示了這樣的系統，在給定詞彙知識的情況下，效能遠遠超過現有的問答系統，與 QALD-9 上最佳問答系統相比，微型 $F_1$ 得分提升了 $35.8\%$。這顯示了納入明確詞彙知識的重要性與潛力。相反地，我們展示了 LLM 僅能有限地運用詞彙知識，與沒有詞彙知識的版本相比，僅有邊際改善。這顯示了 LLM 無法根據其組成部分的意義組合式地解釋問題，這是組合式方法的一個關鍵特徵。綜合而言，我們的研究為 QALD 研究展示了新的途徑，強調了詞彙化和組合性的重要性。</paragraph>

##### **Computational Analysis of Gender Depiction in the Comedias of Calderón de la Barca**
2411.03895v1 by Allison Keith, Antonio Rojas Castro, Sebastian Padó

In theatre, playwrights use the portrayal of characters to explore culturally
based gender norms. In this paper, we develop quantitative methods to study
gender depiction in the non-religious works (comedias) of Pedro Calder\'on de
la Barca, a prolific Spanish 17th century author. We gather insights from a
corpus of more than 100 plays by using a gender classifier and applying model
explainability (attribution) methods to determine which text features are most
influential in the model's decision to classify speech as 'male' or 'female',
indicating the most gendered elements of dialogue in Calder\'on's comedias in a
human accessible manner. We find that female and male characters are portrayed
differently and can be identified by the gender prediction model at practically
useful accuracies (up to f=0.83). Analysis reveals semantic aspects of gender
portrayal, and demonstrates that the model is even useful in providing a
relatively accurate scene-by-scene prediction of cross-dressing characters.

摘要：在戲劇中，劇作家會利用角色的描寫來探討文化中的性別規範。在本文中，我們發展出定量方法來研究性別在佩德羅·卡爾德隆·德·拉·巴卡的非宗教作品（喜劇）中的描繪，他是 17 世紀西班牙的一位多產作家。我們從超過 100 部戲劇的語料庫中收集見解，使用性別分類器並應用模型可解釋性（歸因）方法來確定哪些文字特徵最能影響模型將語言分類為「男性」或「女性」的決定，以人類可理解的方式指出卡爾德隆喜劇中對話中最具性別特質的元素。我們發現女性和男性角色的描繪不同，而且性別預測模型可以以實用的準確度（高達 f=0.83）辨識出這些角色。分析揭示了性別描繪的語義面向，並證明了該模型甚至可以相當準確地預測喬裝角色的場景。

##### **Multi3Hate: Multimodal, Multilingual, and Multicultural Hate Speech Detection with Vision-Language Models**
2411.03888v1 by Minh Duc Bui, Katharina von der Wense, Anne Lauscher

Warning: this paper contains content that may be offensive or upsetting
  Hate speech moderation on global platforms poses unique challenges due to the
multimodal and multilingual nature of content, along with the varying cultural
perceptions. How well do current vision-language models (VLMs) navigate these
nuances? To investigate this, we create the first multimodal and multilingual
parallel hate speech dataset, annotated by a multicultural set of annotators,
called Multi3Hate. It contains 300 parallel meme samples across 5 languages:
English, German, Spanish, Hindi, and Mandarin. We demonstrate that cultural
background significantly affects multimodal hate speech annotation in our
dataset. The average pairwise agreement among countries is just 74%,
significantly lower than that of randomly selected annotator groups. Our
qualitative analysis indicates that the lowest pairwise label agreement-only
67% between the USA and India-can be attributed to cultural factors. We then
conduct experiments with 5 large VLMs in a zero-shot setting, finding that
these models align more closely with annotations from the US than with those
from other cultures, even when the memes and prompts are presented in the
dominant language of the other culture. Code and dataset are available at
https://github.com/MinhDucBui/Multi3Hate.

摘要：警告：本文包含可能令人反感或不安的內容
由於內容的多模態和多語言性質以及不同的文化觀念，在全球平台上對仇恨言論進行審核會帶來獨特挑戰。當前的視覺語言模型 (VLM) 在處理這些細微差別方面表現如何？為了解決此問題，我們建立了第一個由多元文化標註者標註的多模態和多語言平行仇恨言論數據集，稱為 Multi3Hate。它包含 5 種語言的 300 個平行迷因樣本：英語、德語、西班牙語、印地語和普通話。我們證明，文化背景會顯著影響我們數據集中對多模態仇恨言論的標註。各國之間的平均成對一致性僅為 74%，顯著低於隨機選擇的標註者組。我們的定性分析表明，最低的成對標籤一致性——美國和印度之間僅為 67%——可歸因於文化因素。然後，我們在零次學習設置中對 5 個大型 VLM 進行了實驗，發現這些模型與美國的標註更一致，而不是與其他文化的標註更一致，即使迷因和提示以其他文化的語言呈現。程式碼和數據集可在 https://github.com/MinhDucBui/Multi3Hate 找到。

##### **Polynomial Composition Activations: Unleashing the Dynamics of Large Language Models**
2411.03884v1 by Zhijian Zhuo, Ya Wang, Yutao Zeng, Xiaoqing Li, Xun Zhou, Jinwen Ma

Transformers have found extensive applications across various domains due to
the powerful fitting capabilities. This success can be partially attributed to
their inherent nonlinearity. Thus, in addition to the ReLU function employed in
the original transformer architecture, researchers have explored alternative
modules such as GeLU and SwishGLU to enhance nonlinearity and thereby augment
representational capacity. In this paper, we propose a novel category of
polynomial composition activations (PolyCom), designed to optimize the dynamics
of transformers. Theoretically, we provide a comprehensive mathematical
analysis of PolyCom, highlighting its enhanced expressivity and efficacy
relative to other activation functions. Notably, we demonstrate that networks
incorporating PolyCom achieve the $\textbf{optimal approximation rate}$,
indicating that PolyCom networks require minimal parameters to approximate
general smooth functions in Sobolev spaces. We conduct empirical experiments on
the pre-training configurations of large language models (LLMs), including both
dense and sparse architectures. By substituting conventional activation
functions with PolyCom, we enable LLMs to capture higher-order interactions
within the data, thus improving performance metrics in terms of accuracy and
convergence rates. Extensive experimental results demonstrate the effectiveness
of our method, showing substantial improvements over other activation
functions. Code is available at https://github.com/BryceZhuo/PolyCom.

摘要：Transformer因其強大的擬合能力，在各個領域中已廣泛應用。這種成功部分歸功於其固有的非線性。因此，除了原始Transformer架構中使用的 ReLU 函數外，研究人員還探索了 GeLU 和 SwishGLU 等替代模組，以增強非線性，從而擴充表示能力。在本文中，我們提出了一類新的多項式組合激活函數 (PolyCom)，旨在最佳化Transformer的動態。在理論上，我們提供了 PolyCom 的全面數學分析，突出了其相對於其他激活函數的增強表達力和效能。值得注意的是，我們證明了結合 PolyCom 的網路可達到最佳近似率，這表示 PolyCom 網路只需要最少的參數，即可逼近 Sobolev 空間中的一般平滑函數。我們對大型語言模型 (LLM) 的預訓練組態進行了實證實驗，包括稠密和稀疏架構。透過用 PolyCom 取代傳統的激活函數，我們讓 LLM 能夠擷取資料中的高階互動，從而提升準確度和收斂率等效能指標。大量的實驗結果證明了我們方法的有效性，顯示出相較於其他激活函數有顯著的進步。程式碼可於 https://github.com/BryceZhuo/PolyCom 取得。

##### **MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**
2411.03883v1 by Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders Søgaard, Carlos Bobed

Question answering is a natural language understanding task that involves
reasoning over both explicit context and unstated, relevant domain knowledge.
Large language models (LLMs), which underpin most contemporary question
answering systems, struggle to induce how concepts relate in specialized
domains such as medicine. Existing medical LLMs are also costly to train. In
this work, we present MEG, a parameter-efficient approach for medical
knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate
graph embeddings into the LLM, enabling it to leverage external knowledge in a
cost-effective way. We evaluate our method on four popular medical
multiple-choice datasets and show that LLMs greatly benefit from the factual
grounding provided by knowledge graph embeddings. MEG attains an average of
+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized
models like BioMistral. We also show results based on Llama-3. Finally, we show
that MEG's performance remains robust to the choice of graph encoder.

摘要：問答是一種自然語言理解任務，涉及對明確的語境和未說明的相關領域知識進行推理。支撐大多數當代問答系統的大型語言模型 (LLM) 難以推論出概念在醫學等專業領域中的關聯性。現有的醫學 LLM 訓練成本也很高。在這項工作中，我們提出了 MEG，這是一種用於醫學知識增強 LLM 的參數高效方法。MEG 使用輕量級對應網路將圖形嵌入整合到 LLM 中，使其能夠以經濟有效的方式利用外部知識。我們在四個流行的醫學多選題資料集上評估了我們的方法，並表明 LLM 從知識圖形嵌入提供的實際依據中受益匪淺。MEG 在 Mistral-Instruct 基準上平均提高了 +10.2% 的準確率，在 BioMistral 等專用模型上提高了 +6.7%。我們還展示了基於 Llama-3 的結果。最後，我們表明 MEG 的性能對圖形編碼器的選擇保持穩健。

##### **Performance evaluation of SLAM-ASR: The Good, the Bad, the Ugly, and the Way Forward**
2411.03866v1 by Shashi Kumar, Iuliia Thorbecke, Sergio Burdisso, Esaú Villatoro-Tello, Manjunath K E, Kadri Hacioğlu, Pradeep Rangappa, Petr Motlicek, Aravind Ganapathiraju, Andreas Stolcke

Recent research has demonstrated that training a linear connector between
speech foundation encoders and large language models (LLMs) enables this
architecture to achieve strong ASR capabilities. Despite the impressive
results, it remains unclear whether these simple approaches are robust enough
across different scenarios and speech conditions, such as domain shifts and
different speech perturbations. In this paper, we address these questions by
conducting various ablation experiments using a recent and widely adopted
approach called SLAM-ASR. We present novel empirical findings that offer
insights on how to effectively utilize the SLAM-ASR architecture across a wide
range of settings. Our main findings indicate that the SLAM-ASR exhibits poor
performance in cross-domain evaluation settings. Additionally, speech
perturbations within in-domain data, such as changes in speed or the presence
of additive noise, can significantly impact performance. Our findings offer
critical insights for fine-tuning and configuring robust LLM-based ASR models,
tailored to different data characteristics and computational resources.

摘要：最近的研究表明，在语音基础编码器和大语言模型 (LLM) 之间训练线性连接器，使这种架构能够实现强大的 ASR 功能。尽管取得了令人印象深刻的结果，但尚不清楚这些简单的方法是否足够稳健，可以在不同的场景和语音条件下使用，例如域转换和不同的语音扰动。在本文中，我们通过使用一种最近被广泛采用的称为 SLAM-ASR 的方法来进行各种消融实验，来解决这些问题。我们提出了新颖的经验发现，提供了有关如何在各种设置中有效利用 SLAM-ASR 架构的见解。我们的主要发现表明，SLAM-ASR 在跨域评估设置中表现不佳。此外，域内数据中的语音扰动，例如速度变化或加性噪声的存在，会严重影响性能。我们的发现为微调和配置基于 LLM 的鲁棒 ASR 模型提供了关键见解，这些模型针对不同的数据特征和计算资源进行了定制。

##### **AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent Decision-Making**
2411.03865v1 by Yizhe Huang, Xingbo Wang, Hao Liu, Fanqi Kong, Aoyang Qin, Min Tang, Xiaoxi Wang, Song-Chun Zhu, Mingjie Bi, Siyuan Qi, Xue Feng

Traditional interactive environments limit agents' intelligence growth with
fixed tasks. Recently, single-agent environments address this by generating new
tasks based on agent actions, enhancing task diversity. We consider the
decision-making problem in multi-agent settings, where tasks are further
influenced by social connections, affecting rewards and information access.
However, existing multi-agent environments lack a combination of adaptive
physical surroundings and social connections, hindering the learning of
intelligent behaviors. To address this, we introduce AdaSociety, a customizable
multi-agent environment featuring expanding state and action spaces, alongside
explicit and alterable social structures. As agents progress, the environment
adaptively generates new tasks with social structures for agents to undertake.
In AdaSociety, we develop three mini-games showcasing distinct social
structures and tasks. Initial results demonstrate that specific social
structures can promote both individual and collective benefits, though current
reinforcement learning and LLM-based algorithms show limited effectiveness in
leveraging social structures to enhance performance. Overall, AdaSociety serves
as a valuable research platform for exploring intelligence in diverse physical
and social settings. The code is available at
https://github.com/bigai-ai/AdaSociety.

摘要：傳統的互動式環境限制了代理的智慧成長，因為任務是固定的。最近，單一代理環境透過根據代理動作產生新任務來解決此問題，進而提升任務多樣性。我們考慮多代理設定中的決策問題，其中任務進一步受到社交連結的影響，進而影響獎勵和資訊存取。然而，現有的多代理環境缺乏適應性物理環境和社交連結的組合，這阻礙了智慧行為的學習。為了解決此問題，我們引入了 AdaSociety，這是一個可自訂的多代理環境，具有擴充的狀態和動作空間，以及明確且可變更的社交結構。隨著代理的進展，環境會適應性地產生具有社交結構的新任務，供代理執行。在 AdaSociety 中，我們開發了三個迷你遊戲，展示了不同的社交結構和任務。初步結果顯示，特定的社交結構可以促進個人和集體利益，儘管目前的強化學習和基於 LLM 的演算法在利用社交結構來提升效能方面顯示出有限的效力。總的來說，AdaSociety 可作為一個有價值的研究平台，用於探索在不同的物理和社交設定中的智慧。程式碼可在 https://github.com/bigai-ai/AdaSociety 取得。

##### **ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization**
2411.03862v1 by Huayang Huang, Yu Wu, Qian Wang

Watermarking generative content serves as a vital tool for authentication,
ownership protection, and mitigation of potential misuse. Existing watermarking
methods face the challenge of balancing robustness and concealment. They
empirically inject a watermark that is both invisible and robust and passively
achieve concealment by limiting the strength of the watermark, thus reducing
the robustness. In this paper, we propose to explicitly introduce a watermark
hiding process to actively achieve concealment, thus allowing the embedding of
stronger watermarks. To be specific, we implant a robust watermark in an
intermediate diffusion state and then guide the model to hide the watermark in
the final generated image. We employ an adversarial optimization algorithm to
produce the optimal hiding prompt guiding signal for each watermark. The prompt
embedding is optimized to minimize artifacts in the generated image, while the
watermark is optimized to achieve maximum strength. The watermark can be
verified by reversing the generation process. Experiments on various diffusion
models demonstrate the watermark remains verifiable even under significant
image tampering and shows superior invisibility compared to other
state-of-the-art robust watermarking methods.

摘要：生成式內容的水印作為驗證、所有權保護和減輕潛在誤用的重要工具。 現有的水印方法面臨平衡強健性和隱藏性的挑戰。 他們根據經驗注入一個既不可見又強健的水印，並通過限制水印的強度來被動實現隱藏，從而降低強健性。 在本文中，我們建議明確引入水印隱藏過程以主動實現隱藏，從而允許嵌入更強的水印。 具體來說，我們在中間擴散狀態中植入一個強健的水印，然後引導模型在最終生成的圖像中隱藏水印。 我們採用對抗性優化演算法為每個水印產生最佳隱藏提示引導訊號。 提示嵌入經過最佳化以最小化生成圖像中的偽像，而水印經過最佳化以實現最大強度。 可以通過逆轉生成過程來驗證水印。 各種擴散模型的實驗表明，即使在顯著的圖像篡改下，水印仍然可以驗證，並且與其他最先進的強健水印方法相比，顯示出優異的不可見性。

##### **UniTraj: Universal Human Trajectory Modeling from Billion-Scale Worldwide Traces**
2411.03859v1 by Yuanshao Zhu, James Jianqiao Yu, Xiangyu Zhao, Xuetao Wei, Yuxuan Liang

Human trajectory modeling is essential for deciphering movement patterns and
supporting advanced applications across various domains. However, existing
methods are often tailored to specific tasks and regions, resulting in
limitations related to task specificity, regional dependency, and data quality
sensitivity. Addressing these challenges requires a universal human trajectory
foundation model capable of generalizing and scaling across diverse tasks and
geographic contexts. To this end, we propose UniTraj, a Universal human
Trajectory foundation model that is task-adaptive, region-independent, and
highly generalizable. To further enhance performance, we construct WorldTrace,
the first large-scale, high-quality, globally distributed dataset sourced from
open web platforms, encompassing 2.45 million trajectories with billions of
points across 70 countries. Through multiple resampling and masking strategies
designed for pre-training, UniTraj effectively overcomes geographic and task
constraints, adapting to heterogeneous data quality. Extensive experiments
across multiple trajectory analysis tasks and real-world datasets demonstrate
that UniTraj consistently outperforms existing approaches in terms of
scalability and adaptability. These results underscore the potential of UniTraj
as a versatile, robust solution for a wide range of trajectory analysis
applications, with WorldTrace serving as an ideal but non-exclusive foundation
for training.

摘要：人類軌跡模型對於解碼移動模式和支援各個領域的進階應用至關重要。然而，現有的方法通常是針對特定任務和區域量身打造，導致與任務特定性、區域依賴性和資料品質敏感性相關的限制。解決這些挑戰需要一個通用的軌跡基礎模型，能夠在不同的任務和地理背景下進行概化和縮放。為此，我們提出 UniTraj，一個通用的軌跡基礎模型，它具有任務適應性、區域獨立性和高度概括性。為了進一步提升效能，我們構建了 WorldTrace，這是第一個從開放網路平台取得的大規模、高品質、全球分佈的資料集，包含來自 70 個國家的 245 萬條軌跡和數十億個點。透過多重重新取樣和遮罩策略，專為預訓練而設計，UniTraj 有效地克服了地理和任務限制，適應異質的資料品質。在多個軌跡分析任務和真實世界資料集中的廣泛實驗表明，UniTraj 在可擴充性和適應性方面始終優於現有方法。這些結果強調了 UniTraj 作為軌跡分析應用廣泛而強大的解決方案的潛力，而 WorldTrace 則作為一個理想但非獨家的訓練基礎。

##### **MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba**
2411.03855v1 by Masakazu Yoshimura, Teruaki Hayashi, Yota Maeda

An ecosystem of Transformer-based models has been established by building
large models with extensive data. Parameter-efficient fine-tuning (PEFT) is a
crucial technology for deploying these models to downstream tasks with minimal
cost while achieving effective performance. Recently, Mamba, a State Space
Model (SSM)-based model, has attracted attention as a potential alternative to
Transformers. While many large-scale Mamba-based models have been proposed,
efficiently adapting pre-trained Mamba-based models to downstream tasks remains
unexplored. In this paper, we conduct an exploratory analysis of PEFT methods
for Mamba. We investigate the effectiveness of existing PEFT methods for
Transformers when applied to Mamba. We also modify these methods to better
align with the Mamba architecture. Additionally, we propose new Mamba-specific
PEFT methods that leverage the distinctive structure of Mamba. Our experiments
indicate that PEFT performs more effectively for Mamba than Transformers.
Lastly, we demonstrate how to effectively combine multiple PEFT methods and
provide a framework that outperforms previous works. To ensure reproducibility,
we will release the code after publication.

摘要：<paragraph>已經透過建立擁有廣泛資料的大型模型，建立了基於 Transformer 的模型生態系統。參數有效微調 (PEFT) 是一項關鍵技術，用於以最低成本將這些模型部署到下游任務，同時達到有效效能。最近，一種基於狀態空間模型 (SSM) 的模型 Mamba，因其作為 Transformer 的潛在替代方案而備受關注。雖然已經提出許多大型基於 Mamba 的模型，但有效地調整預先訓練的基於 Mamba 的模型以適應下游任務仍未被探索。在本文中，我們對 Mamba 的 PEFT 方法進行探索性分析。我們探討了將現有針對 Transformer 的 PEFT 方法應用到 Mamba 時的有效性。我們也修改這些方法以更好地與 Mamba 架構對齊。此外，我們提出新的特定於 Mamba 的 PEFT 方法，這些方法利用了 Mamba 的獨特結構。我們的實驗表明，PEFT 對 Mamba 的執行比 Transformer 更有效。最後，我們展示如何有效地結合多種 PEFT 方法，並提供一個優於先前工作的架構。為了確保可複製性，我們將在發布後釋出程式碼。</paragraph>

##### **A Novel Access Control and Privacy-Enhancing Approach for Models in Edge Computing**
2411.03847v1 by Peihao Li

With the widespread adoption of edge computing technologies and the
increasing prevalence of deep learning models in these environments, the
security risks and privacy threats to models and data have grown more acute.
Attackers can exploit various techniques to illegally obtain models or misuse
data, leading to serious issues such as intellectual property infringement and
privacy breaches. Existing model access control technologies primarily rely on
traditional encryption and authentication methods; however, these approaches
exhibit significant limitations in terms of flexibility and adaptability in
dynamic environments. Although there have been advancements in model
watermarking techniques for marking model ownership, they remain limited in
their ability to proactively protect intellectual property and prevent
unauthorized access. To address these challenges, we propose a novel model
access control method tailored for edge computing environments. This method
leverages image style as a licensing mechanism, embedding style recognition
into the model's operational framework to enable intrinsic access control.
Consequently, models deployed on edge platforms are designed to correctly infer
only on license data with specific style, rendering them ineffective on any
other data. By restricting the input data to the edge model, this approach not
only prevents attackers from gaining unauthorized access to the model but also
enhances the privacy of data on terminal devices. We conducted extensive
experiments on benchmark datasets, including MNIST, CIFAR-10, and FACESCRUB,
and the results demonstrate that our method effectively prevents unauthorized
access to the model while maintaining accuracy. Additionally, the model shows
strong resistance against attacks such as forged licenses and fine-tuning.
These results underscore the method's usability, security, and robustness.

摘要：隨著邊緣運算技術的廣泛採用，以及在這些環境中深度學習模型的日益普及，模型和資料的安全性風險和隱私威脅已變得更加嚴重。攻擊者可以利用各種技術非法獲取模型或濫用資料，導致嚴重的問題，例如智慧財產權侵權和隱私洩露。現有的模型存取控制技術主要依賴傳統的加密和驗證方法；然而，這些方法在動態環境中的靈活性和適應性方面表現出顯著的限制。儘管在標記模型所有權的模型浮水印技術方面已經取得進展，但它們在主動保護智慧財產權和防止未經授權的存取方面仍然有限。為了應對這些挑戰，我們提出了一種針對邊緣運算環境量身打造的新型模型存取控制方法。此方法利用影像風格作為授權機制，將風格辨識嵌入模型的操作架構中，以啟用內在的存取控制。因此，部署在邊緣平台上的模型旨在僅對具有特定風格的授權資料進行正確推論，在任何其他資料上都無法執行。透過限制輸入資料到邊緣模型，此方法不僅可以防止攻擊者未經授權存取模型，還可以增強終端裝置上資料的隱私性。我們對基準資料集（包括 MNIST、CIFAR-10 和 FACESCRUB）進行了廣泛的實驗，結果表明，我們的模型有效地防止了未經授權存取模型，同時保持準確性。此外，該模型對偽造授權和微調等攻擊表現出強大的抵抗力。這些結果強調了該方法的可用性、安全性與穩健性。

##### **Reconsidering the Performance of GAE in Link Prediction**
2411.03845v1 by Weishuo Ma, Yanbo Wang, Xiyuan Wang, Muhan Zhang

Various graph neural networks (GNNs) with advanced training techniques and
model designs have been proposed for link prediction tasks. However, outdated
baseline models may lead to an overestimation of the benefits provided by these
novel approaches. To address this, we systematically investigate the potential
of Graph Autoencoders (GAE) by meticulously tuning hyperparameters and
utilizing the trick of orthogonal embedding and linear propagation. Our
findings reveal that a well-optimized GAE can match the performance of more
complex models while offering greater computational efficiency.

摘要：各種圖神經網路 (GNN) 已提出搭配進階訓練技巧和模型設計，用於連結預測任務。然而，過時的基準模型可能會高估這些新方法提供的優點。為了解決這個問題，我們透過仔細調整超參數和利用正交嵌入和線性傳播的技巧，系統性地研究圖自編碼器 (GAE) 的潛力。我們的研究結果顯示，經過良好最佳化的 GAE 可匹配更複雜模型的效能，同時提供更高的計算效率。

##### **Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination**
2411.03823v1 by Dingjie Song, Sicheng Lai, Shunian Chen, Lichao Sun, Benyou Wang

The rapid progression of multimodal large language models (MLLMs) has
demonstrated superior performance on various multimodal benchmarks. However,
the issue of data contamination during training creates challenges in
performance evaluation and comparison. While numerous methods exist for
detecting dataset contamination in large language models (LLMs), they are less
effective for MLLMs due to their various modalities and multiple training
phases. In this study, we introduce a multimodal data contamination detection
framework, MM-Detect, designed for MLLMs. Our experimental results indicate
that MM-Detect is sensitive to varying degrees of contamination and can
highlight significant performance improvements due to leakage of the training
set of multimodal benchmarks. Furthermore, We also explore the possibility of
contamination originating from the pre-training phase of LLMs used by MLLMs and
the fine-tuning phase of MLLMs, offering new insights into the stages at which
contamination may be introduced.

摘要：多模態大型語言模型 (MLLM) 的快速進展已展現出在各種多模態基準上的卓越效能。然而，訓練期間的資料污染問題為效能評估與比較帶來了挑戰。儘管有許多方法可以偵測大型語言模型 (LLM) 中的資料集污染，但由於其多種模態和多重訓練階段，這些方法對 MLLM 的效果較差。在這個研究中，我們引進了一個多模態資料污染偵測架構 MM-Detect，專門針對 MLLM 設計。我們的實驗結果顯示，MM-Detect 對不同程度的污染很敏感，並且可以凸顯由於多模態基準訓練組的洩漏而造成的顯著效能提升。此外，我們也探討了來自 MLLM 所使用的 LLM 預訓練階段和 MLLM 的微調階段的污染可能性，為污染可能被引入的階段提供了新的見解。

##### **From Novice to Expert: LLM Agent Policy Optimization via Step-wise Reinforcement Learning**
2411.03817v1 by Zhirui Deng, Zhicheng Dou, Yutao Zhu, Ji-Rong Wen, Ruibin Xiong, Mang Wang, Weipeng Chen

The outstanding capabilities of large language models (LLMs) render them a
crucial component in various autonomous agent systems. While traditional
methods depend on the inherent knowledge of LLMs without fine-tuning, more
recent approaches have shifted toward the reinforcement learning strategy to
further enhance agents' ability to solve complex interactive tasks with
environments and tools. However, previous approaches are constrained by the
sparse reward issue, where existing datasets solely provide a final scalar
reward for each multi-step reasoning chain, potentially leading to
ineffectiveness and inefficiency in policy learning. In this paper, we
introduce StepAgent, which utilizes step-wise reward to optimize the agent's
reinforcement learning process. Inheriting the spirit of novice-to-expert
theory, we first compare the actions of the expert and the agent to
automatically generate intermediate rewards for fine-grained optimization.
Additionally, we propose implicit-reward and inverse reinforcement learning
techniques to facilitate agent reflection and policy adjustment. Further
theoretical analysis demonstrates that the action distribution of the agent can
converge toward the expert action distribution over multiple training cycles.
Experimental results across various datasets indicate that StepAgent
outperforms existing baseline methods.

摘要：大型語言模型 (LLM) 的傑出功能讓它們成為各種自主代理系統中至關重要的組成部分。雖然傳統方法依賴於 LLM 的固有知識而無需微調，但最近的方法已轉向強化學習策略，以進一步增強代理解決複雜互動任務的能力，包括環境和工具。然而，先前的做法受到稀疏獎勵問題的限制，其中現有資料集僅為每個多步驟推理鏈提供最終標量獎勵，這可能會導致策略學習的無效性和低效率。在本文中，我們介紹了 StepAgent，它利用逐步獎勵來優化代理的強化學習過程。繼承初學者到專家的理論精神，我們首先比較專家和代理的行動，以自動產生用於細化優化的中間獎勵。此外，我們提出了隱式獎勵和逆向強化學習技術，以促進代理反思和策略調整。進一步的理論分析表明，代理的行動分佈可以在多個訓練週期中收斂到專家行動分佈。跨各種資料集的實驗結果表明，StepAgent 優於現有的基準方法。

##### **MRJ-Agent: An Effective Jailbreak Agent for Multi-Round Dialogue**
2411.03814v1 by Fengxiang Wang, Ranjie Duan, Peng Xiao, Xiaojun Jia, YueFeng Chen, Chongwen Wang, Jialing Tao, Hang Su, Jun Zhu, Hui Xue

Large Language Models (LLMs) demonstrate outstanding performance in their
reservoir of knowledge and understanding capabilities, but they have also been
shown to be prone to illegal or unethical reactions when subjected to jailbreak
attacks. To ensure their responsible deployment in critical applications, it is
crucial to understand the safety capabilities and vulnerabilities of LLMs.
Previous works mainly focus on jailbreak in single-round dialogue, overlooking
the potential jailbreak risks in multi-round dialogues, which are a vital way
humans interact with and extract information from LLMs. Some studies have
increasingly concentrated on the risks associated with jailbreak in multi-round
dialogues. These efforts typically involve the use of manually crafted
templates or prompt engineering techniques. However, due to the inherent
complexity of multi-round dialogues, their jailbreak performance is limited. To
solve this problem, we propose a novel multi-round dialogue jailbreaking agent,
emphasizing the importance of stealthiness in identifying and mitigating
potential threats to human values posed by LLMs. We propose a risk
decomposition strategy that distributes risks across multiple rounds of queries
and utilizes psychological strategies to enhance attack strength. Extensive
experiments show that our proposed method surpasses other attack methods and
achieves state-of-the-art attack success rate. We will make the corresponding
code and dataset available for future research. The code will be released soon.

摘要：大型語言模型 (LLM) 在知識儲備和理解能力方面表現出色，但當受到越獄攻擊時，它們也容易出現違法或不道德的反應。為了確保它們在關鍵應用程式中的負責任部署，了解 LLM 的安全能力和漏洞至關重要。先前的研究主要關注單輪對話中的越獄，忽視了多輪對話中的潛在越獄風險，而多輪對話是人類與 LLM 互動並从中提取信息的重要方式。一些研究越來越關注多輪對話中越獄相關的風險。這些努力通常涉及使用人工製作的範本或提示工程技術。然而，由於多輪對話的複雜性，它們的越獄性能受到限制。為了解決這個問題，我們提出了一種新穎的多輪對話越獄代理，強調在識別和減輕 LLM 對人類價值觀構成的潛在威脅時隱蔽性的重要性。我們提出了一個風險分解策略，將風險分佈在多輪查詢中，並利用心理策略來增強攻擊強度。大量的實驗表明，我們提出的方法優於其他攻擊方法，並實現了最先進的攻擊成功率。我們將提供相應的程式碼和資料集，供將來的研究使用。程式碼將很快發布。

##### **The natural stability of autonomous morphology**
2411.03811v1 by Erich Round, Louise Esher, Sacha Beniamine

Autonomous morphology, such as inflection class systems and paradigmatic
distribution patterns, is widespread and diachronically resilient in natural
language. Why this should be so has remained unclear given that autonomous
morphology imposes learning costs, offers no clear benefit relative to its
absence and could easily be removed by the analogical forces which are
constantly reshaping it. Here we propose an explanation for the resilience of
autonomous morphology, in terms of a diachronic dynamic of attraction and
repulsion between morphomic categories, which emerges spontaneously from a
simple paradigm cell filling process. Employing computational evolutionary
models, our key innovation is to bring to light the role of `dissociative
evidence', i.e., evidence for inflectional distinctiveness which a rational
reasoner will have access to during analogical inference. Dissociative evidence
creates a repulsion dynamic which prevents morphomic classes from collapsing
together entirely, i.e., undergoing complete levelling. As we probe alternative
models, we reveal the limits of conditional entropy as a measure for
predictability in systems that are undergoing change. Finally, we demonstrate
that autonomous morphology, far from being `unnatural' (e.g.
\citealt{Aronoff1994}), is rather the natural (emergent) consequence of a
natural (rational) process of inference applied to inflectional systems.

摘要：<paragraph>自主形態學，例如詞形變化類別系統和範例分佈模式，在自然語言中廣泛存在且歷時性強韌。為什麼會這樣一直不明確，因為自主形態學強加了學習成本，相對於其不存在沒有明顯的優勢，並且可以很容易地通過不斷重塑它的類比力去除。在這裡，我們提出了一個對自主形態學彈性的解釋，即形態學類別之間的歷時性吸引和排斥動態，它自發地從一個簡單的範例單元填充過程中出現。採用計算演化模型，我們的關鍵創新是闡明「分離證據」的作用，即理性推理者在類比推理過程中可以獲得的詞形變化獨特性證據。分離證據創造了一個排斥動態，防止形態學類別完全崩潰，即進行完全的平準化。當我們探究替代模型時，我們揭示了條件熵作為正在發生變化的系統中可預測性的測量極限。最後，我們證明自主形態學遠非「非自然」（例如 \citealt{Aronoff1994}），而是應用於詞形變化系統的自然（理性）推理過程的自然（湧現）結果。</paragraph>

##### **GS2Pose: Tow-stage 6D Object Pose Estimation Guided by Gaussian Splatting**
2411.03807v1 by Jilan Mei, Junbo Li, Cai Meng

This paper proposes a new method for accurate and robust 6D pose estimation
of novel objects, named GS2Pose. By introducing 3D Gaussian splatting, GS2Pose
can utilize the reconstruction results without requiring a high-quality CAD
model, which means it only requires segmented RGBD images as input.
Specifically, GS2Pose employs a two-stage structure consisting of coarse
estimation followed by refined estimation. In the coarse stage, a lightweight
U-Net network with a polarization attention mechanism, called Pose-Net, is
designed. By using the 3DGS model for supervised training, Pose-Net can
generate NOCS images to compute a coarse pose. In the refinement stage, GS2Pose
formulates a pose regression algorithm following the idea of reprojection or
Bundle Adjustment (BA), referred to as GS-Refiner. By leveraging Lie algebra to
extend 3DGS, GS-Refiner obtains a pose-differentiable rendering pipeline that
refines the coarse pose by comparing the input images with the rendered images.
GS-Refiner also selectively updates parameters in the 3DGS model to achieve
environmental adaptation, thereby enhancing the algorithm's robustness and
flexibility to illuminative variation, occlusion, and other challenging
disruptive factors. GS2Pose was evaluated through experiments conducted on the
LineMod dataset, where it was compared with similar algorithms, yielding highly
competitive results. The code for GS2Pose will soon be released on GitHub.

摘要：本文提出了一種新的方法，用於準確且穩健地估計新物體的 6D 姿勢，稱為 GS2Pose。透過引入 3D 高斯噴濺，GS2Pose 可以利用重建結果，而無需高品質的 CAD 模型，這表示它只需要分割的 RGBD 影像作為輸入。具體來說，GS2Pose 使用由粗略估計和精緻估計組成的兩階段結構。在粗略階段，設計了一個具有極化注意力機制的輕量級 U-Net 網路，稱為 Pose-Net。透過使用 3DGS 模型進行監督訓練，Pose-Net 可以產生 NOCS 影像來計算粗略姿勢。在精緻階段，GS2Pose 根據重新投影或束調整 (BA) 的概念制定了一個姿勢回歸演算法，稱為 GS-Refiner。透過利用李代數來擴充 3DGS，GS-Refiner 獲得了一個姿勢可微分渲染管線，它透過比較輸入影像與渲染影像來精緻粗略姿勢。GS-Refiner 也選擇性地更新 3DGS 模型中的參數，以實現環境適應，從而增強演算法對光照變化、遮擋和其他具有挑戰性的破壞因素的穩健性和靈活性。GS2Pose 透過在 LineMod 資料集上進行的實驗進行評估，在該資料集上將其與類似的演算法進行比較，產生了極具競爭力的結果。GS2Pose 的程式碼將很快在 GitHub 上發布。

##### **Understanding the Effects of Human-written Paraphrases in LLM-generated Text Detection**
2411.03806v1 by Hiu Ting Lau, Arkaitz Zubiaga

Natural Language Generation has been rapidly developing with the advent of
large language models (LLMs). While their usage has sparked significant
attention from the general public, it is important for readers to be aware when
a piece of text is LLM-generated. This has brought about the need for building
models that enable automated LLM-generated text detection, with the aim of
mitigating potential negative outcomes of such content. Existing LLM-generated
detectors show competitive performances in telling apart LLM-generated and
human-written text, but this performance is likely to deteriorate when
paraphrased texts are considered. In this study, we devise a new data
collection strategy to collect Human & LLM Paraphrase Collection (HLPC), a
first-of-its-kind dataset that incorporates human-written texts and
paraphrases, as well as LLM-generated texts and paraphrases. With the aim of
understanding the effects of human-written paraphrases on the performance of
state-of-the-art LLM-generated text detectors OpenAI RoBERTa and watermark
detectors, we perform classification experiments that incorporate human-written
paraphrases, watermarked and non-watermarked LLM-generated documents from GPT
and OPT, and LLM-generated paraphrases from DIPPER and BART. The results show
that the inclusion of human-written paraphrases has a significant impact of
LLM-generated detector performance, promoting TPR@1%FPR with a possible
trade-off of AUROC and accuracy.

摘要：<paragraph>隨著大型語言模型 (LLM) 的出現，自然語言生成技術獲得了快速發展。儘管其使用引起了公眾的極大關注，但讀者在閱讀 LLM 生成的文本時，了解其來源非常重要。這使得建立模型以實現自動 LLM 生成的文本檢測變得十分必要，目的是減輕此類內容潛在的負面影響。現有的 LLM 生成的檢測器在區分 LLM 生成的文本和人類撰寫的文本方面表現出色，但當考慮到改寫的文本時，這種表現可能會下降。在本研究中，我們設計了一種新的數據收集策略，用於收集人類和 LLM 改寫語料庫 (HLPC)，這是一個首創的數據集，包含人類撰寫的文本和改寫，以及 LLM 生成的文本和改寫。為了了解人類撰寫的改寫對最先進的 LLM 生成的文本檢測器 OpenAI RoBERTa 和水印檢測器的效能的影響，我們進行了分類實驗，其中包含人類撰寫的改寫、帶水印和不帶水印的 GPT 和 OPT 生成的 LLM 文件，以及 DIPPER 和 BART 生成的 LLM 改寫。結果表明，包含人類撰寫的改寫對 LLM 生成的檢測器效能有顯著影響，以可能的 AUROC 和準確性的權衡來提升 TPR@1%FPR。</paragraph>

##### **A Comparative Study of Recent Large Language Models on Generating Hospital Discharge Summaries for Lung Cancer Patients**
2411.03805v1 by Yiming Li, Fang Li, Kirk Roberts, Licong Cui, Cui Tao, Hua Xu

Generating discharge summaries is a crucial yet time-consuming task in
clinical practice, essential for conveying pertinent patient information and
facilitating continuity of care. Recent advancements in large language models
(LLMs) have significantly enhanced their capability in understanding and
summarizing complex medical texts. This research aims to explore how LLMs can
alleviate the burden of manual summarization, streamline workflow efficiencies,
and support informed decision-making in healthcare settings. Clinical notes
from a cohort of 1,099 lung cancer patients were utilized, with a subset of 50
patients for testing purposes, and 102 patients used for model fine-tuning.
This study evaluates the performance of multiple LLMs, including GPT-3.5,
GPT-4, GPT-4o, and LLaMA 3 8b, in generating discharge summaries. Evaluation
metrics included token-level analysis (BLEU, ROUGE-1, ROUGE-2, ROUGE-L) and
semantic similarity scores between model-generated summaries and
physician-written gold standards. LLaMA 3 8b was further tested on clinical
notes of varying lengths to examine the stability of its performance. The study
found notable variations in summarization capabilities among LLMs. GPT-4o and
fine-tuned LLaMA 3 demonstrated superior token-level evaluation metrics, while
LLaMA 3 consistently produced concise summaries across different input lengths.
Semantic similarity scores indicated GPT-4o and LLaMA 3 as leading models in
capturing clinical relevance. This study contributes insights into the efficacy
of LLMs for generating discharge summaries, highlighting LLaMA 3's robust
performance in maintaining clarity and relevance across varying clinical
contexts. These findings underscore the potential of automated summarization
tools to enhance documentation precision and efficiency, ultimately improving
patient care and operational capability in healthcare settings.

摘要：<paragraph>生成出院摘要在臨床實務中是一項至關重要的任務，卻又十分耗時，對於傳達相關的病患資訊和促進照護的連續性至關重要。大型語言模型 (LLM) 的最新進展顯著增強了它們在理解和摘要複雜醫療文本方面的能力。本研究旨在探討 LLM 如何減輕手動摘要的負擔、簡化工作流程效率，並支援醫療保健環境中的明智決策制定。利用來自 1,099 名肺癌患者的臨床筆記，其中 50 名患者用於測試目的，102 名患者用於模型微調。本研究評估了多個 LLM 的效能，包括 GPT-3.5、GPT-4、GPT-4o 和 LLaMA 3 8b，在生成出院摘要方面的表現。評估指標包括符號層級分析 (BLEU、ROUGE-1、ROUGE-2、ROUGE-L) 和模型產生的摘要與醫師撰寫的金標準之間的語意相似性評分。LLaMA 3 8b 進一步在不同長度的臨床筆記上進行測試，以檢查其效能的穩定性。研究發現，LLM 之間的摘要能力存在顯著差異。GPT-4o 和微調後的 LLaMA 3 表現出優異的符號層級評估指標，而 LLaMA 3 在不同的輸入長度下持續產生簡潔的摘要。語意相似性評分顯示 GPT-4o 和 LLaMA 3 在捕捉臨床相關性方面是領先的模型。本研究有助於深入了解 LLM 在生成出院摘要方面的效能，強調 LLaMA 3 在維持不同臨床背景下的清晰度和相關性方面的強健表現。這些發現強調了自動化摘要工具在提升文件準確度和效率方面的潛力，最終改善醫療保健環境中的患者照護和營運能力。</paragraph>

##### **Overcoming label shift in targeted federated learning**
2411.03799v1 by Edvin Listo Zec, Adam Breitholtz, Fredrik D. Johansson

Federated learning enables multiple actors to collaboratively train models
without sharing private data. This unlocks the potential for scaling machine
learning to diverse applications. Existing algorithms for this task are
well-justified when clients and the intended target domain share the same
distribution of features and labels, but this assumption is often violated in
real-world scenarios. One common violation is label shift, where the label
distributions differ across clients or between clients and the target domain,
which can significantly degrade model performance. To address this problem, we
propose FedPALS, a novel model aggregation scheme that adapts to label shifts
by leveraging knowledge of the target label distribution at the central server.
Our approach ensures unbiased updates under stochastic gradient descent,
ensuring robust generalization across clients with diverse, label-shifted data.
Extensive experiments on image classification demonstrate that FedPALS
consistently outperforms standard baselines by aligning model aggregation with
the target domain. Our findings reveal that conventional federated learning
methods suffer severely in cases of extreme client sparsity, highlighting the
critical need for target-aware aggregation. FedPALS offers a principled and
practical solution to mitigate label distribution mismatch, ensuring models
trained in federated settings can generalize effectively to label-shifted
target domains.

摘要：聯邦學習使多個參與者能夠協作訓練模型，而不需共享私人數據。這解鎖了將機器學習擴展到各種應用程式的潛力。當客戶端和預期的目標網域共享相同的特徵和標籤分布時，現有的演算法對於這項任務來說是合理的，但這個假設在真實世界的場景中常常被違反。標籤轉移是一個常見的違反，其中標籤分布在客戶端之間或客戶端和目標網域之間有所不同，這可能會顯著降低模型效能。為了解決這個問題，我們提出了 FedPALS，這是一種新穎的模型聚合方案，它透過利用中央伺服器上目標標籤分布的知識來適應標籤轉移。我們的做法確保了隨機梯度下降下的無偏更新，確保了在具有不同標籤轉移數據的客戶端之間的穩健概化。在影像分類上的廣泛實驗證明，FedPALS 透過將模型聚合與目標網域對齊，始終優於標準基準。我們的研究結果顯示，傳統的聯邦學習方法在極端客戶端稀疏性的情況下會遭受嚴重影響，突顯了對目標感知聚合的關鍵需求。FedPALS 提供了一個有原則且實用的解決方案，以減輕標籤分布不匹配，確保在聯邦設定中訓練的模型能夠有效概化到標籤轉移的目標網域。

##### **VQA$^2$:Visual Question Answering for Video Quality Assessment**
2411.03795v1 by Ziheng Jia, Zicheng Zhang, Jiaying Qian, Haoning Wu, Wei Sun, Chunyi Li, Xiaohong Liu, Weisi Lin, Guangtao Zhai, Xiongkuo Min

The advent and proliferation of large multi-modal models (LMMs) have
introduced a new paradigm to video-related computer vision fields, including
training and inference methods based on visual question answering (VQA). These
methods enable models to handle multiple downstream tasks robustly. Video
Quality Assessment (VQA), a classic field in low-level visual quality
evaluation, originally focused on quantitative video quality scoring. However,
driven by advances in LMMs, it is now evolving towards more comprehensive
visual quality understanding tasks. Visual question answering has significantly
improved low-level visual evaluation within the image domain recently. However,
related work is almost nonexistent in the video domain, leaving substantial
room for improvement. To address this gap, we introduce the VQA2 Instruction
Dataset the first visual question answering instruction dataset entirely
focuses on video quality assessment, and based on it, we propose the VQA2
series models The VQA2 Instruction Dataset consists of three stages and covers
various video types, containing 157,735 instruction question-answer pairs,
including both manually annotated and synthetic data. We conduct extensive
experiments on both video quality scoring and video quality understanding
tasks. Results demonstrate that the VQA2 series models achieve state-of-the-art
(SOTA) performance in quality scoring tasks, and their performance in visual
quality question answering surpasses the renowned GPT-4o. Additionally, our
final model, the VQA2-Assistant, performs well across both scoring and
question-answering tasks, validating its versatility.

摘要：大型多模态模型 (LMM) 的出现和普及为视频相关的计算机视觉领域引入了一种新范例，包括基于视觉问答 (VQA) 的训练和推理方法。这些方法使模型能够稳健地处理多个下游任务。视频质量评估 (VQA) 是低级视觉质量评估中的一个经典领域，最初专注于定量视频质量评分。然而，在 LMM 的推动下，它现在正朝着更全面的视觉质量理解任务发展。视觉问答最近显着改善了图像域中的低级视觉评估。然而，在视频域中几乎不存在相关工作，留下了很大的改进空间。为了解决这一差距，我们引入了 VQA2 指令数据集，这是第一个完全专注于视频质量评估的视觉问答指令数据集，并在此基础上，我们提出了 VQA2 系列模型。VQA2 指令数据集包含三个阶段，涵盖各种视频类型，包含 157,735 个指令问答对，包括人工注释数据和合成数据。我们对视频质量评分和视频质量理解任务进行了广泛的实验。结果表明，VQA2 系列模型在质量评分任务中实现了最先进 (SOTA) 的性能，并且它们在视觉质量问答中的性能超过了著名的 GPT-4o。此外，我们的最终模型 VQA2-Assistant 在评分和问答任务中都表现良好，验证了它的多功能性。

##### **Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications**
2411.03782v1 by Daan Schouten, Giulia Nicoletti, Bas Dille, Catherine Chia, Pierpaolo Vendittelli, Megan Schuurmans, Geert Litjens, Nadieh Khalili

Recent technological advances in healthcare have led to unprecedented growth
in patient data quantity and diversity. While artificial intelligence (AI)
models have shown promising results in analyzing individual data modalities,
there is increasing recognition that models integrating multiple complementary
data sources, so-called multimodal AI, could enhance clinical decision-making.
This scoping review examines the landscape of deep learning-based multimodal AI
applications across the medical domain, analyzing 432 papers published between
2018 and 2024. We provide an extensive overview of multimodal AI development
across different medical disciplines, examining various architectural
approaches, fusion strategies, and common application areas. Our analysis
reveals that multimodal AI models consistently outperform their unimodal
counterparts, with an average improvement of 6.2 percentage points in AUC.
However, several challenges persist, including cross-departmental coordination,
heterogeneous data characteristics, and incomplete datasets. We critically
assess the technical and practical challenges in developing multimodal AI
systems and discuss potential strategies for their clinical implementation,
including a brief overview of commercially available multimodal AI models for
clinical decision-making. Additionally, we identify key factors driving
multimodal AI development and propose recommendations to accelerate the field's
maturation. This review provides researchers and clinicians with a thorough
understanding of the current state, challenges, and future directions of
multimodal AI in medicine.

摘要：醫療保健領域的近期科技進展導致病患資料數量和多樣性前所未有的成長。儘管人工智慧 (AI) 模型在分析個別資料模式中展現出有前途的成果，但整合多個互補資料來源的模型，即所謂的多模式 AI，可以提升臨床決策制定，這項認知正與日俱增。這篇範圍探討回顧研究探討了涵蓋醫療領域的深度學習基礎多模式 AI 應用現況，分析 2018 年至 2024 年間發表的 432 篇論文。我們提供了多模式 AI 發展的廣泛概觀，涵蓋不同的醫療領域，探討各種架構方法、融合策略和常見應用領域。我們的分析顯示，多模式 AI 模型始終優於其單一模式的對應模型，AUC 平均改善 6.2 個百分點。然而，仍有許多挑戰持續存在，包括跨部門協調、異質資料特性和不完整資料集。我們批判性地評估開發多模式 AI 系統在技術和實務上的挑戰，並討論其臨床實作的潛在策略，包括對市售多模式 AI 模型的簡要概述，用於臨床決策制定。此外，我們找出推動多模式 AI 發展的主要因素，並提出建議以加速該領域的成熟。本回顧研究讓研究人員和臨床醫師深入了解多模式 AI 在醫學領域的現況、挑戰和未來方向。

##### **No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with Captions in 28 Languages**
2411.03769v1 by Youssef Mohamed, Runjia Li, Ibrahim Said Ahmad, Kilichbek Haydarov, Philip Torr, Kenneth Ward Church, Mohamed Elhoseiny

Research in vision and language has made considerable progress thanks to
benchmarks such as COCO. COCO captions focused on unambiguous facts in English;
ArtEmis introduced subjective emotions and ArtELingo introduced some
multilinguality (Chinese and Arabic). However we believe there should be more
multilinguality. Hence, we present ArtELingo-28, a vision-language benchmark
that spans $\textbf{28}$ languages and encompasses approximately
$\textbf{200,000}$ annotations ($\textbf{140}$ annotations per image).
Traditionally, vision research focused on unambiguous class labels, whereas
ArtELingo-28 emphasizes diversity of opinions over languages and cultures. The
challenge is to build machine learning systems that assign emotional captions
to images. Baseline results will be presented for three novel conditions:
Zero-Shot, Few-Shot and One-vs-All Zero-Shot. We find that cross-lingual
transfer is more successful for culturally-related languages. Data and code are
provided at www.artelingo.org.

摘要：<paragraph>在 COCO 等基準的幫助下，視覺和語言的研究已取得顯著進展。COCO 的說明文字專注於英文的明確事實；ArtEmis 引入了主觀情緒，ArtELingo 則引入了部分多語言性（中文和阿拉伯文）。然而，我們相信應該有更多語言。因此，我們提出了 ArtELingo-28，一個橫跨 $\textbf{28}$ 種語言且包含大約 $\textbf{200,000}$ 個註解（每個圖像 $\textbf{140}$ 個註解）的視覺語言基準。傳統上，視覺研究專注於明確的類別標籤，而 ArtELingo-28 則強調語言和文化之間意見的多樣性。挑戰在於建立將情緒說明文字分配給圖像的機器學習系統。將針對三種新條件呈現基線結果：零次學習、小樣本學習和一對全零次學習。我們發現，跨語言轉移對於文化相關語言來說更成功。資料和程式碼可在 www.artelingo.org 中取得。</paragraph>

##### **Number Cookbook: Number Understanding of Language Models and How to Improve It**
2411.03766v1 by Haotong Yang, Yi Hu, Shijia Kang, Zhouchen Lin, Muhan Zhang

Large language models (LLMs) can solve an increasing number of complex
reasoning tasks while making surprising mistakes in basic numerical
understanding and processing (such as 9.11 > 9.9). The latter ability is
essential for tackling complex arithmetic and mathematical problems and serves
as a foundation for most reasoning tasks, but previous work paid little
attention to it or only discussed several restricted tasks (like integer
addition). In this paper, we comprehensively investigate the numerical
understanding and processing ability (NUPA) of LLMs. Firstly, we introduce a
benchmark covering four common numerical representations and 17 distinct
numerical tasks in four major categories, resulting in 41 meaningful
combinations in total. These tasks are derived from primary and secondary
education curricula, encompassing nearly all everyday numerical understanding
and processing scenarios, and the rules of these tasks are very simple and
clear. Through the benchmark, we find that current LLMs fail frequently in many
of the tasks. To study the problem, we train small models with existing and
potential techniques for enhancing NUPA (such as special tokenizers, PEs, and
number formats), comprehensively evaluating their effectiveness using our
testbed. We also finetune practical-scale LLMs on our proposed NUPA tasks and
find that 1) naive finetuning can improve NUPA a lot on many but not all tasks,
and 2) surprisingly, techniques designed to enhance NUPA prove ineffective for
finetuning pretrained models. We further explore the impact of chain-of-thought
techniques on NUPA. Our work takes a preliminary step towards understanding and
improving NUPA of LLMs. Our benchmark and code are released at
https://github.com/GraphPKU/number_cookbook.

摘要：大型語言模型 (LLM) 可以解決越來越多的複雜推理任務，同時在基本的數字理解和處理上犯下驚人的錯誤（例如 9.11 > 9.9）。後者能力對於解決複雜的算術和數學問題至關重要，並且作為大多數推理任務的基礎，但先前的研究很少關注它或只討論了幾個受限任務（例如整數加法）。在本文中，我們全面調查了 LLM 的數字理解和處理能力 (NUPA)。首先，我們引入了一個基準，涵蓋四種常見的數字表示和四個主要類別中的 17 個不同的數字任務，總共產生 41 個有意義的組合。這些任務源自中小學教育課程，涵蓋了幾乎所有日常數字理解和處理場景，並且這些任務的規則非常簡單明瞭。通過基準，我們發現當前的 LLM 在許多任務中經常失敗。為了研究這個問題，我們使用現有和潛在的技術訓練小模型來增強 NUPA（例如特殊分詞器、PE 和數字格式），並使用我們的測試平台全面評估它們的有效性。我們還在我們提出的 NUPA 任務上微調了實用規模的 LLM，並發現 1) 樸素的微調可以在許多任務（但並非全部）上大幅改善 NUPA，以及 2) 令人驚訝的是，旨在增強 NUPA 的技術被證明對微調預訓練的模型無效。我們進一步探討了思想鏈技術對 NUPA 的影響。我們的研究為理解和改進 LLM 的 NUPA 邁出了初步一步。我們的基準和代碼發布在 https://github.com/GraphPKU/number_cookbook。

##### **Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction**
2411.03758v1 by Yu Guan, Qinrong Cai, Wei Li, Qiuyun Fan, Dong Liang, Qiegen Liu

Diffusion model-based approaches recently achieved re-markable success in MRI
reconstruction, but integration into clinical routine remains challenging due
to its time-consuming convergence. This phenomenon is partic-ularly notable
when directly apply conventional diffusion process to k-space data without
considering the inherent properties of k-space sampling, limiting k-space
learning efficiency and image reconstruction quality. To tackle these
challenges, we introduce subspace diffusion model with orthogonal
decomposition, a method (referred to as Sub-DM) that restrict the diffusion
process via projections onto subspace as the k-space data distribution evolves
toward noise. Particularly, the subspace diffusion model circumvents the
inference challenges posed by the com-plex and high-dimensional characteristics
of k-space data, so the highly compact subspace ensures that diffusion process
requires only a few simple iterations to produce accurate prior information.
Furthermore, the orthogonal decomposition strategy based on wavelet transform
hin-ders the information loss during the migration of the vanilla diffusion
process to the subspace. Considering the strate-gy is approximately reversible,
such that the entire pro-cess can be reversed. As a result, it allows the
diffusion processes in different spaces to refine models through a mutual
feedback mechanism, enabling the learning of ac-curate prior even when dealing
with complex k-space data. Comprehensive experiments on different datasets
clearly demonstrate that the superiority of Sub-DM against state of-the-art
methods in terms of reconstruction speed and quality.

摘要：基於擴散模型的方法最近在 MRI 重建中取得了顯著的成功，但由於其耗時的收斂性，整合到臨床常規中仍然具有挑戰性。當直接將傳統擴散過程應用到 k-space 資料，而沒有考慮 k-space 取樣的固有特性時，這種現象尤其明顯，限制了 k-space 學習效率和影像重建品質。為了應對這些挑戰，我們引入了具有正交分解的子空間擴散模型，一種方法（稱為 Sub-DM），它通過投影到子空間來限制擴散過程，因為 k-space 資料分佈會演變成雜訊。特別是，子空間擴散模型迴避了 k-space 資料的複雜和高維特徵所帶來的推論挑戰，因此高度緊湊的子空間確保擴散過程只需要幾個簡單的迭代即可產生準確的先驗資訊。此外，基於小波轉換的正交分解策略阻礙了香草擴散過程遷移到子空間期間的資訊遺失。考慮到該策略近似可逆，因此整個過程可以逆轉。因此，它允許不同空間中的擴散過程通過相互回饋機制來優化模型，即使在處理複雜的 k-space 資料時也能學習準確的先驗。在不同資料集上的全面實驗清楚地證明了 Sub-DM 在重建速度和品質方面優於最先進的方法。

##### **Optimal Defenses Against Gradient Reconstruction Attacks**
2411.03746v1 by Yuxiao Chen, Gamze Gürsoy, Qi Lei

Federated Learning (FL) is designed to prevent data leakage through
collaborative model training without centralized data storage. However, it
remains vulnerable to gradient reconstruction attacks that recover original
training data from shared gradients. To optimize the trade-off between data
leakage and utility loss, we first derive a theoretical lower bound of
reconstruction error (among all attackers) for the two standard methods: adding
noise, and gradient pruning. We then customize these two defenses to be
parameter- and model-specific and achieve the optimal trade-off between our
obtained reconstruction lower bound and model utility. Experimental results
validate that our methods outperform Gradient Noise and Gradient Pruning by
protecting the training data better while also achieving better utility.

摘要：聯邦學習 (FL) 旨在透過協作模型訓練來防止資料外洩，而無需集中式資料儲存。但是，它仍然容易受到梯度重建攻擊，該攻擊會從共享梯度中恢復原始訓練資料。為了最佳化資料外洩和效用損失之間的折衷，我們首先針對這兩種標準方法推導出重建誤差的理論下限（在所有攻擊者中）：加入雜訊和梯度修剪。然後，我們自訂這兩種防禦措施，使其特定於參數和模型，並在我們獲得的重建下限和模型效用之間取得最佳折衷。實驗結果驗證我們的模型透過更佳地保護訓練資料，同時也能達到更好的效用，從而優於梯度雜訊和梯度修剪。

##### **Automating Exploratory Proteomics Research via Language Models**
2411.03743v1 by Ning Ding, Shang Qu, Linhai Xie, Yifei Li, Zaoqu Liu, Kaiyan Zhang, Yibai Xiong, Yuxin Zuo, Zhangren Chen, Ermo Hua, Xingtai Lv, Youbang Sun, Yang Li, Dong Li, Fuchu He, Bowen Zhou

With the development of artificial intelligence, its contribution to science
is evolving from simulating a complex problem to automating entire research
processes and producing novel discoveries. Achieving this advancement requires
both specialized general models grounded in real-world scientific data and
iterative, exploratory frameworks that mirror human scientific methodologies.
In this paper, we present PROTEUS, a fully automated system for scientific
discovery from raw proteomics data. PROTEUS uses large language models (LLMs)
to perform hierarchical planning, execute specialized bioinformatics tools, and
iteratively refine analysis workflows to generate high-quality scientific
hypotheses. The system takes proteomics datasets as input and produces a
comprehensive set of research objectives, analysis results, and novel
biological hypotheses without human intervention. We evaluated PROTEUS on 12
proteomics datasets collected from various biological samples (e.g. immune
cells, tumors) and different sample types (single-cell and bulk), generating
191 scientific hypotheses. These were assessed using both automatic LLM-based
scoring on 5 metrics and detailed reviews from human experts. Results
demonstrate that PROTEUS consistently produces reliable, logically coherent
results that align well with existing literature while also proposing novel,
evaluable hypotheses. The system's flexible architecture facilitates seamless
integration of diverse analysis tools and adaptation to different proteomics
data types. By automating complex proteomics analysis workflows and hypothesis
generation, PROTEUS has the potential to considerably accelerate the pace of
scientific discovery in proteomics research, enabling researchers to
efficiently explore large-scale datasets and uncover biological insights.

摘要：<paragraph>隨著人工智慧的發展，其對科學的貢獻從模擬複雜的問題演變成自動化整個研究流程和產生新發現。實現這項進展需要建立在真實世界科學數據基礎上的專門通用模型，以及反映人類科學方法的迭代式探索框架。在本文中，我們展示了 PROTEUS，這是一個從原始蛋白质组学數據中進行科學發現的全自動系統。PROTEUS 使用大型語言模型 (LLM) 來執行階層式規劃、執行專門的生物信息學工具，並反覆優化分析工作流程以產生高品質的科學假設。該系統以蛋白质组学數據集作為輸入，並產生一組全面的研究目標、分析結果和新穎的生物假設，無需人工干預。我們在從各種生物樣本（例如免疫細胞、腫瘤）和不同樣本類型（單細胞和整體）收集的 12 個蛋白质组学數據集上評估了 PROTEUS，產生了 191 個科學假設。這些假設使用基於 LLM 的自動評分（使用 5 個指標）和人類專家的詳細評估進行評估。結果表明，PROTEUS 持續產生可靠、邏輯上連貫的結果，這些結果與現有文獻非常吻合，同時也提出了新穎、可評估的假設。該系統的靈活架構促進了不同分析工具的無縫整合，並適應了不同的蛋白质组学數據類型。通過自動化複雜的蛋白质组学分析工作流程和假設生成，PROTEUS 有可能大幅加快蛋白质组学研究中科學發現的步伐，使研究人員能夠有效地探索大規模數據集並發現生物學見解。</paragraph>

##### **Adaptive Consensus Gradients Aggregation for Scaled Distributed Training**
2411.03742v1 by Yoni Choukroun, Shlomi Azoulay, Pavel Kisilev

Distributed machine learning has recently become a critical paradigm for
training large models on vast datasets. We examine the stochastic optimization
problem for deep learning within synchronous parallel computing environments
under communication constraints. While averaging distributed gradients is the
most widely used method for gradient estimation, whether this is the optimal
strategy remains an open question. In this work, we analyze the distributed
gradient aggregation process through the lens of subspace optimization. By
formulating the aggregation problem as an objective-aware subspace optimization
problem, we derive an efficient weighting scheme for gradients, guided by
subspace coefficients. We further introduce subspace momentum to accelerate
convergence while maintaining statistical unbiasedness in the aggregation. Our
method demonstrates improved performance over the ubiquitous gradient averaging
on multiple MLPerf tasks while remaining extremely efficient in both
communicational and computational complexity.

摘要：分布式機器學習最近已成為在龐大資料集上訓練大型模型的重要範例。我們在通訊約束下，探討同步並行運算環境中深度學習的隨機最佳化問題。雖然平均分佈式梯度是梯度估計最廣泛使用的方法，但這是否是最佳策略仍是一個開放性的問題。在這項工作中，我們透過子空間最佳化的角度分析分佈式梯度聚合過程。透過將聚合問題制定為目標感知子空間最佳化問題，我們導出一個有效的梯度加權機制，由子空間係數引導。我們進一步引入子空間動量來加速收斂，同時在聚合中維持統計無偏性。我們的模型在多個 MLPerf 任務上展現出優於普遍梯度平均的效能，同時在通訊和運算複雜度方面保持極高的效率。

##### **Relation Learning and Aggregate-attention for Multi-person Motion Prediction**
2411.03729v1 by Kehua Qu, Rui Ding, Jin Tang

Multi-person motion prediction is an emerging and intricate task with broad
real-world applications. Unlike single person motion prediction, it considers
not just the skeleton structures or human trajectories but also the
interactions between others. Previous methods use various networks to achieve
impressive predictions but often overlook that the joints relations within an
individual (intra-relation) and interactions among groups (inter-relation) are
distinct types of representations. These methods often lack explicit
representation of inter&intra-relations, and inevitably introduce undesired
dependencies. To address this issue, we introduce a new collaborative framework
for multi-person motion prediction that explicitly modeling these relations:a
GCN-based network for intra-relations and a novel reasoning network for
inter-relations.Moreover, we propose a novel plug-and-play aggregation module
called the Interaction Aggregation Module (IAM), which employs an
aggregate-attention mechanism to seamlessly integrate these relations.
Experiments indicate that the module can also be applied to other dual-path
models. Extensive experiments on the 3DPW, 3DPW-RC, CMU-Mocap, MuPoTS-3D, as
well as synthesized datasets Mix1 & Mix2 (9 to 15 persons), demonstrate that
our method achieves state-of-the-art performance.

摘要：多人動作預測是一項新興且複雜的任務，在現實世界中有廣泛的應用。它不同於單人動作預測，它不僅考慮骨架結構或人體軌跡，還考慮人與人之間的互動。先前的各種方法使用各種網路來實現令人印象深刻的預測，但常常忽視個人內部的關節關係（內部關係）和群組之間的互動（相互關係）是不同類型的表示。這些方法通常缺乏對內部和外部關係的明確表示，並不可避免地引入了不需要的依賴關係。為了解決這個問題，我們引入了一個新的協作框架，用於多人員動作預測，該框架明確地對這些關係建模：一個基於 GCN 的網路用於內部關係，一個新的推理網路用於相互關係。此外，我們提出了一個新穎的即插即用聚合模組，稱為互動聚合模組 (IAM)，它採用聚合注意力機制來無縫整合這些關係。實驗表明，該模組也可以應用於其他雙路徑模型。在 3DPW、3DPW-RC、CMU-Mocap、MuPoTS-3D 以及合成資料集 Mix1 和 Mix2（9 到 15 人）上進行的廣泛實驗表明，我們的模型達到了最先進的效能。

##### **PropNEAT -- Efficient GPU-Compatible Backpropagation over NeuroEvolutionary Augmenting Topology Networks**
2411.03726v1 by Michael Merry, Patricia Riddle, Jim Warren

We introduce PropNEAT, a fast backpropagation implementation of NEAT that
uses a bidirectional mapping of the genome graph to a layer-based architecture
that preserves the NEAT genomes whilst enabling efficient GPU backpropagation.
We test PropNEAT on 58 binary classification datasets from the Penn Machine
Learning Benchmarks database, comparing the performance against logistic
regression, dense neural networks and random forests, as well as a densely
retrained variant of the final PropNEAT model. PropNEAT had the second best
overall performance, behind Random Forest, though the difference between the
models was not statistically significant apart from between Random Forest in
comparison with logistic regression and the PropNEAT retrain models. PropNEAT
was substantially faster than a naive backpropagation method, and both were
substantially faster and had better performance than the original NEAT
implementation. We demonstrate that the per-epoch training time for PropNEAT
scales linearly with network depth, and is efficient on GPU implementations for
backpropagation. This implementation could be extended to support reinforcement
learning or convolutional networks, and is able to find sparser and smaller
networks with potential for applications in low-power contexts.

摘要：我們介紹了 PropNEAT，一種 NEAT 的快速反向傳播實作，它使用基因組圖形到基於層的架構的雙向映射，在保留 NEAT 基因組的同時，能夠進行高效的 GPU 反向傳播。我們在 Penn Machine Learning Benchmarks 資料庫中的 58 個二元分類資料集上測試了 PropNEAT，並將其效能與邏輯迴歸、稠密神經網路和隨機森林，以及最終 PropNEAT 模型的密集重新訓練變體進行比較。PropNEAT 擁有第二好的整體效能，僅次於隨機森林，儘管除了隨機森林與邏輯迴歸和 PropNEAT 重新訓練模型的比較之外，模型之間的差異並無統計意義。PropNEAT 比一個天真的反向傳播方法快得多，而且兩者都比原始 NEAT 實作快得多，而且效能更好。我們證明了 PropNEAT 的每個時期訓練時間與網路深度成線性比例，並且在反向傳播的 GPU 實作中很有效率。此實作可以擴充支援強化學習或卷積網路，並且能夠找到更稀疏、更小的網路，具有在低功耗環境中應用的潛力。

##### **Fine-Tuning Vision-Language Model for Automated Engineering Drawing Information Extraction**
2411.03707v1 by Muhammad Tayyab Khan, Lequn Chen, Ye Han Ng, Wenhe Feng, Nicholas Yew Jin Tan, Seung Ki Moon

Geometric Dimensioning and Tolerancing (GD&T) plays a critical role in
manufacturing by defining acceptable variations in part features to ensure
component quality and functionality. However, extracting GD&T information from
2D engineering drawings is a time-consuming and labor-intensive task, often
relying on manual efforts or semi-automated tools. To address these challenges,
this study proposes an automated and computationally efficient GD&T extraction
method by fine-tuning Florence-2, an open-source vision-language model (VLM).
The model is trained on a dataset of 400 drawings with ground truth annotations
provided by domain experts. For comparison, two state-of-the-art closed-source
VLMs, GPT-4o and Claude-3.5-Sonnet, are evaluated on the same dataset. All
models are assessed using precision, recall, F1-score, and hallucination
metrics. Due to the computational cost and impracticality of fine-tuning large
closed-source VLMs for domain-specific tasks, GPT-4o and Claude-3.5-Sonnet are
evaluated in a zero-shot setting. In contrast, Florence-2, a smaller model with
0.23 billion parameters, is optimized through full-parameter fine-tuning across
three distinct experiments, each utilizing datasets augmented to different
levels. The results show that Florence-2 achieves a 29.95% increase in
precision, a 37.75% increase in recall, a 52.40% improvement in F1-score, and a
43.15% reduction in hallucination rate compared to the best-performing
closed-source model. These findings highlight the effectiveness of fine-tuning
smaller, open-source VLMs like Florence-2, offering a practical and efficient
solution for automated GD&T extraction to support downstream manufacturing
tasks.

摘要：幾何尺寸與公差 (GD&T) 在製造業中扮演著至關重要的角色，透過定義零件特徵的可接受變異，以確保組件品質與功能。然而，從 2D 工程圖中萃取 GD&T 資訊是一項耗時且勞力密集的任務，通常仰賴人工操作或半自動化工具。為了應對這些挑戰，本研究提出了一種自動化且計算效率高的 GD&T 萃取方法，透過微調開源的視覺語言模型 (VLM) Florence-2。該模型在一個由領域專家提供真實標註的 400 張圖面資料集上進行訓練。為了比較，兩個最先進的閉源 VLM，GPT-4o 和 Claude-3.5-Sonnet，也在相同的資料集上進行評估。所有模型均使用精確度、召回率、F1 分數和幻覺指標進行評估。由於微調大型閉源 VLM 進行特定領域任務的計算成本高且不切實際，因此 GPT-4o 和 Claude-3.5-Sonnet 在零樣本學習的設定下進行評估。相比之下，Florence-2 是個較小的模型，具有 0.23 億個參數，透過三個不同的實驗進行全參數微調進行最佳化，每個實驗都使用擴充到不同程度的資料集。結果顯示，與效能最佳的閉源模型相比，Florence-2 在精確度提升了 29.95%，召回率提升了 37.75%，F1 分數提升了 52.40%，幻覺率降低了 43.15%。這些發現突顯了微調較小的開源 VLM（例如 Florence-2）的有效性，為自動化 GD&T 萃取提供了一個實用且高效的解決方案，以支援下游製造任務。

##### **The Root Shapes the Fruit: On the Persistence of Gender-Exclusive Harms in Aligned Language Models**
2411.03700v1 by Anaelia Ovalle, Krunoslav Lehman Pavasovic, Louis Martin, Luke Zettlemoyer, Eric Michael Smith, Adina Williams, Levent Sagun

Natural-language assistants are designed to provide users with helpful
responses while avoiding harmful outputs, largely achieved through alignment to
human preferences. Yet there is limited understanding of whether alignment
techniques may inadvertently perpetuate or even amplify harmful biases
inherited from their pre-aligned base models. This issue is compounded by the
choice of bias evaluation benchmarks in popular preference-finetuned models,
which predominantly focus on dominant social categories, such as binary gender,
thereby limiting insights into biases affecting underrepresented groups.
Towards addressing this gap, we center transgender, nonbinary, and other
gender-diverse identities to investigate how alignment procedures interact with
pre-existing gender-diverse bias in LLMs. Our key contributions include: 1) a
comprehensive survey of bias evaluation modalities across leading
preference-finetuned LLMs, highlighting critical gaps in gender-diverse
representation, 2) systematic evaluation of gender-diverse biases across 12
models spanning Direct Preference Optimization (DPO) stages, uncovering harms
popular bias benchmarks fail to detect, and 3) a flexible framework for
measuring harmful biases in implicit reward signals applicable to other social
contexts. Our findings reveal that DPO-aligned models are particularly
sensitive to supervised finetuning (SFT), and can amplify two forms of
real-world gender-diverse harms from their base models: stigmatization and
gender non-affirmative language. We conclude with recommendations tailored to
DPO and broader alignment practices, advocating for the adoption of
community-informed bias evaluation frameworks to more effectively identify and
address underrepresented harms in LLMs.

摘要：自然語言助理旨在為使用者提供有用的回應，同時避免有害的輸出，這主要是透過與人類偏好保持一致來實現的。然而，對於對齊技術是否會無意中延續甚至放大從其預先對齊的基本模型中繼承的有害偏見，目前了解有限。這個問題是由流行的偏好微調模型中偏見評估基準的選擇所加劇，這些基準主要關注主要的社會類別，例如二元性別，從而限制了對影響代表性不足的群體的偏見的深入了解。為了解決這個差距，我們以跨性別、非二元性別和其他性別多元身分為中心，探討對齊程序如何與 LLM 中已存在的性別多元偏見相互作用。我們的關鍵貢獻包括：1) 對領先的偏好微調 LLM 中的偏見評估方式進行全面調查，強調性別多元代表性的關鍵差距，2) 對跨越直接偏好最佳化 (DPO) 階段的 12 個模型進行性別多元偏見的系統性評估，揭露流行的偏見基準未能偵測到的危害，以及 3) 一個靈活的架構，用於衡量適用於其他社會背景的隱含獎勵信號中的有害偏見。我們的研究結果顯示，DPO 對齊模型特別容易受到監督微調 (SFT) 的影響，並且可以放大其基本模型中的兩種形式的現實世界性別多元危害：污名化和性別非肯定語言。我們最後提出針對 DPO 和更廣泛對齊實務的建議，提倡採用由社群提供的偏見評估架構，以更有效地識別和解決 LLM 中代表性不足的危害。

##### **Beyond Model Adaptation at Test Time: A Survey**
2411.03687v1 by Zehao Xiao, Cees G. M. Snoek

Machine learning algorithms have achieved remarkable success across various
disciplines, use cases and applications, under the prevailing assumption that
training and test samples are drawn from the same distribution. Consequently,
these algorithms struggle and become brittle even when samples in the test
distribution start to deviate from the ones observed during training. Domain
adaptation and domain generalization have been studied extensively as
approaches to address distribution shifts across test and train domains, but
each has its limitations. Test-time adaptation, a recently emerging learning
paradigm, combines the benefits of domain adaptation and domain generalization
by training models only on source data and adapting them to target data during
test-time inference. In this survey, we provide a comprehensive and systematic
review on test-time adaptation, covering more than 400 recent papers. We
structure our review by categorizing existing methods into five distinct
categories based on what component of the method is adjusted for test-time
adaptation: the model, the inference, the normalization, the sample, or the
prompt, providing detailed analysis of each. We further discuss the various
preparation and adaptation settings for methods within these categories,
offering deeper insights into the effective deployment for the evaluation of
distribution shifts and their real-world application in understanding images,
video and 3D, as well as modalities beyond vision. We close the survey with an
outlook on emerging research opportunities for test-time adaptation.

摘要：機器學習演算法在各種領域、使用案例和應用中都取得了顯著的成功，其前提假設是訓練和測試樣本來自相同的分布。因此，即使測試分布中的樣本開始偏離訓練期間觀察到的樣本，這些演算法也會陷入困境並變得脆弱。領域適應和領域泛化已被廣泛研究為解決測試和訓練領域之間分佈轉移的方法，但每種方法都有其局限性。測試時適應是一種最近新興的學習範例，它結合了領域適應和領域泛化的優點，僅使用來源資料訓練模型，並在測試時推理期間將其適應到目標資料。在本次調查中，我們提供了對測試時適應的全面且系統性的回顧，涵蓋了 400 多篇近期論文。我們根據方法的哪個組成部分經過調整以進行測試時適應，將現有方法分類為五個不同的類別來架構我們的回顧：模型、推理、正規化、樣本或提示，並對每個類別提供詳細分析。我們進一步討論了這些類別中方法的各種準備和適應設定，提供更深入的見解，以有效部署來評估分佈轉移及其在理解影像、影片和 3D 中的實際應用，以及超越視覺的模態。我們以對測試時適應的新興研究機會的展望作為本次調查的結尾。

##### **QUILL: Quotation Generation Enhancement of Large Language Models**
2411.03675v1 by Jin Xiao, Bowei Zhang, Qianyu He, Jiaqing Liang, Feng Wei, Jinglei Chen, Zujie Liang, Deqing Yang, Yanghua Xiao

While Large language models (LLMs) have become excellent writing assistants,
they still struggle with quotation generation. This is because they either
hallucinate when providing factual quotations or fail to provide quotes that
exceed human expectations. To bridge the gap, we systematically study how to
evaluate and improve LLMs' performance in quotation generation tasks. We first
establish a holistic and automatic evaluation system for quotation generation
task, which consists of five criteria each with corresponding automatic metric.
To improve the LLMs' quotation generation abilities, we construct a bilingual
knowledge base that is broad in scope and rich in dimensions, containing up to
32,022 quotes. Moreover, guided by our critiria, we further design a
quotation-specific metric to rerank the retrieved quotations from the knowledge
base. Extensive experiments show that our metrics strongly correlate with human
preferences. Existing LLMs struggle to generate desired quotes, but our
quotation knowledge base and reranking metric help narrow this gap. Our dataset
and code are publicly available at https://github.com/GraceXiaoo/QUILL.

摘要：儘管大型語言模型 (LLM) 已成為優秀的寫作助理，
它們在引文產生方面仍有困難。這是因為它們在提供事實引文時會出現幻覺，或無法提供超出人類預期的引文。為了彌補差距，我們系統性地研究如何評估和改善 LLM 在引文產生任務中的表現。我們首先為引文產生任務建立一個整體且自動化的評估系統，其中包含五個標準，每個標準都有相應的自動化指標。為了提升 LLM 的引文產生能力，我們構建了一個範圍廣泛且維度豐富的雙語知識庫，其中包含多達 32,022 個引文。此外，在我們標準的指導下，我們進一步設計了一個特定於引文的指標，以重新排列從知識庫中擷取的引文。大量的實驗表明，我們的指標與人類偏好有很強的相關性。現有的 LLM 難以產生所需的引文，但我們的引文知識庫和重新排列指標有助於縮小差距。我們的數據集和程式碼已公開發布於 https://github.com/GraceXiaoo/QUILL。

##### **Towards 3D Semantic Scene Completion for Autonomous Driving: A Meta-Learning Framework Empowered by Deformable Large-Kernel Attention and Mamba Model**
2411.03672v1 by Yansong Qu, Zilin Huang, Zihao Sheng, Tiantian Chen, Sikai Chen

Semantic scene completion (SSC) is essential for achieving comprehensive
perception in autonomous driving systems. However, existing SSC methods often
overlook the high deployment costs in real-world applications. Traditional
architectures, such as 3D Convolutional Neural Networks (3D CNNs) and
self-attention mechanisms, face challenges in efficiently capturing long-range
dependencies within 3D voxel grids, limiting their effectiveness. To address
these issues, we introduce MetaSSC, a novel meta-learning-based framework for
SSC that leverages deformable convolution, large-kernel attention, and the
Mamba (D-LKA-M) model. Our approach begins with a voxel-based semantic
segmentation (SS) pretraining task, aimed at exploring the semantics and
geometry of incomplete regions while acquiring transferable meta-knowledge.
Using simulated cooperative perception datasets, we supervise the perception
training of a single vehicle using aggregated sensor data from multiple nearby
connected autonomous vehicles (CAVs), generating richer and more comprehensive
labels. This meta-knowledge is then adapted to the target domain through a
dual-phase training strategy that does not add extra model parameters, enabling
efficient deployment. To further enhance the model's capability in capturing
long-sequence relationships within 3D voxel grids, we integrate Mamba blocks
with deformable convolution and large-kernel attention into the backbone
network. Extensive experiments demonstrate that MetaSSC achieves
state-of-the-art performance, significantly outperforming competing models
while also reducing deployment costs.

摘要：語意場景完成 (SSC) 對於在自動駕駛系統中實現全面感知至關重要。然而，現有的 SSC 方法通常忽略了在實際應用中的高部署成本。傳統架構，例如 3D 捲積神經網路 (3D CNN) 和自我注意機制，在有效擷取 3D 體素網格內的長程依賴關係時面臨挑戰，限制了它們的效能。為了解決這些問題，我們引入了 MetaSSC，一個用於 SSC 的新元學習基礎架構，它利用可變形卷積、大核注意力和 Mamba (D-LKA-M) 模型。我們的做法從一個基於體素的語意分割 (SS) 預訓練任務開始，旨在探索不完整區域的語意和幾何形狀，同時獲取可轉移的元知識。使用模擬協作感知資料集，我們使用來自多個附近連接自動駕駛車輛 (CAV) 的聚合感測器資料監督單一車輛的感知訓練，產生更豐富、更全面的標籤。然後透過一種不增加額外模型參數的雙階段訓練策略將此元知識調整到目標領域，從而實現高效部署。為了進一步增強模型在擷取 3D 體素網格內的長序列關係方面的能力，我們將 Mamba 積木與可變形卷積和大核注意力整合到主幹網路中。大量的實驗證明，MetaSSC 達到了最先進的效能，顯著優於競爭模型，同時也降低了部署成本。

##### **Evaluating Moral Beliefs across LLMs through a Pluralistic Framework**
2411.03665v1 by Xuelin Liu, Yanfei Zhu, Shucheng Zhu, Pengyuan Liu, Ying Liu, Dong Yu

Proper moral beliefs are fundamental for language models, yet assessing these
beliefs poses a significant challenge. This study introduces a novel
three-module framework to evaluate the moral beliefs of four prominent large
language models. Initially, we constructed a dataset containing 472 moral
choice scenarios in Chinese, derived from moral words. The decision-making
process of the models in these scenarios reveals their moral principle
preferences. By ranking these moral choices, we discern the varying moral
beliefs held by different language models. Additionally, through moral debates,
we investigate the firmness of these models to their moral choices. Our
findings indicate that English language models, namely ChatGPT and Gemini,
closely mirror moral decisions of the sample of Chinese university students,
demonstrating strong adherence to their choices and a preference for
individualistic moral beliefs. In contrast, Chinese models such as Ernie and
ChatGLM lean towards collectivist moral beliefs, exhibiting ambiguity in their
moral choices and debates. This study also uncovers gender bias embedded within
the moral beliefs of all examined language models. Our methodology offers an
innovative means to assess moral beliefs in both artificial and human
intelligence, facilitating a comparison of moral values across different
cultures.

摘要：適當的道德信念對於語言模型至關重要，然而評估這些信念卻是一項重大挑戰。本研究引入了一個新穎的三模組架構來評估四個傑出的大型語言模型的道德信念。最初，我們構建了一個包含 472 個道德選擇情境的中文資料集，這些情境源自道德詞彙。模型在這些情境中的決策過程揭示了它們的道德原則偏好。透過對這些道德選擇進行排名，我們辨別了不同語言模型所持有的不同道德信念。此外，透過道德辯論，我們探討了這些模型對其道德選擇的堅定程度。我們的研究結果表明，英語語言模型，即 ChatGPT 和 Gemini，與中國大學生樣本的道德決策非常相似，表明它們堅定地堅持自己的選擇，並且偏好個人主義道德信念。相比之下，Ernie 和 ChatGLM 等中文模型則傾向於集體主義道德信念，在他們的道德選擇和辯論中表現出模稜兩可的態度。本研究還揭示了所有受檢語言模型的道德信念中存在的性別偏見。我們的研究方法提供了一個創新的方式來評估人工和人類智慧中的道德信念，從而促進不同文化之間道德價值觀的比較。

##### **Deploying Multi-task Online Server with Large Language Model**
2411.03644v1 by Yincen Qu, Chao Ma, Yiting Wu, Xiangying Dai, Hui Zhou, Hengyue Liu

In the industry, numerous tasks are deployed online. Traditional approaches
often tackle each task separately by its own network, which leads to excessive
costs for developing and scaling models, especially in the context of large
language models. Although multi-task methods can save costs through parameter
sharing, they often struggle to outperform single-task methods in real-world
applications. To tackle these challenges, we present a three-stage multi-task
learning framework for large language models. It involves task filtering,
followed by fine-tuning on high-resource tasks, and finally fine-tuning on all
tasks. We conducted comprehensive experiments in single-task and multi-task
settings. Our approach, exemplified on different benchmarks, demonstrates that
it is able to achieve performance comparable to the single-task method while
reducing up to 90.9\% of its overhead.

摘要：在產業中，許多任務是在線上部署的。傳統方法通常由其自己的網路分別處理每個任務，這會導致開發和擴充模型的成本過高，特別是在大型語言模型的情況下。儘管多任務方法可以透過參數共享來節省成本，但它們通常難以在真實世界的應用中超越單任務方法。為了應對這些挑戰，我們提出了一個針對大型語言模型的三階段多任務學習架構。它包含任務篩選，接著在高資源任務上進行微調，最後在所有任務上進行微調。我們在單任務和多任務設定中進行了全面的實驗。我們的做法以不同的基準為例，證明它能夠在減少高達 90.9% 的開銷下，達到與單任務方法相當的效能。

##### **RTify: Aligning Deep Neural Networks with Human Behavioral Decisions**
2411.03630v1 by Yu-Ang Cheng, Ivan Felipe Rodriguez, Sixuan Chen, Kohitij Kar, Takeo Watanabe, Thomas Serre

Current neural network models of primate vision focus on replicating overall
levels of behavioral accuracy, often neglecting perceptual decisions' rich,
dynamic nature. Here, we introduce a novel computational framework to model the
dynamics of human behavioral choices by learning to align the temporal dynamics
of a recurrent neural network (RNN) to human reaction times (RTs). We describe
an approximation that allows us to constrain the number of time steps an RNN
takes to solve a task with human RTs. The approach is extensively evaluated
against various psychophysics experiments. We also show that the approximation
can be used to optimize an "ideal-observer" RNN model to achieve an optimal
tradeoff between speed and accuracy without human data. The resulting model is
found to account well for human RT data. Finally, we use the approximation to
train a deep learning implementation of the popular Wong-Wang decision-making
model. The model is integrated with a convolutional neural network (CNN) model
of visual processing and evaluated using both artificial and natural image
stimuli. Overall, we present a novel framework that helps align current vision
models with human behavior, bringing us closer to an integrated model of human
vision.

摘要：目前靈長類視覺的神經網路模型著重於複製整體行為準確度的層級，經常忽略知覺決策的豐富、動態本質。在此，我們引入一個新穎的計算架構，透過學習將遞迴神經網路 (RNN) 的時間動態與人類反應時間 (RT) 對齊，來建模人類行為選擇的動態。我們描述了一個近似值，讓我們得以限制 RNN 解決任務所需的時間步數，並具備人類的 RT。此方法已針對各種心理物理實驗進行廣泛評估。我們也顯示，該近似值可用於最佳化「理想觀察者」RNN 模型，以在沒有人類資料的情況下，達成速度和準確度之間的最佳折衷。發現所得模型能充分說明人類 RT 資料。最後，我們使用近似值來訓練 Wong-Wang 決策制定模型的深度學習實作。此模型與視覺處理的卷積神經網路 (CNN) 模型整合，並使用人工和自然影像刺激進行評估。總的來說，我們提出一個新穎的架構，有助於將目前的視覺模型與人類行為對齊，讓我們更接近人類視覺的整合模型。

##### **StreamingBench: Assessing the Gap for MLLMs to Achieve Streaming Video Understanding**
2411.03628v1 by Junming Lin, Zheng Fang, Chi Chen, Zihao Wan, Fuwen Luo, Peng Li, Yang Liu, Maosong Sun

The rapid development of Multimodal Large Language Models (MLLMs) has
expanded their capabilities from image comprehension to video understanding.
However, most of these MLLMs focus primarily on offline video comprehension,
necessitating extensive processing of all video frames before any queries can
be made. This presents a significant gap compared to the human ability to
watch, listen, think, and respond to streaming inputs in real time,
highlighting the limitations of current MLLMs. In this paper, we introduce
StreamingBench, the first comprehensive benchmark designed to evaluate the
streaming video understanding capabilities of MLLMs. StreamingBench assesses
three core aspects of streaming video understanding: (1) real-time visual
understanding, (2) omni-source understanding, and (3) contextual understanding.
The benchmark consists of 18 tasks, featuring 900 videos and 4,500
human-curated QA pairs. Each video features five questions presented at
different time points to simulate a continuous streaming scenario. We conduct
experiments on StreamingBench with 13 open-source and proprietary MLLMs and
find that even the most advanced proprietary MLLMs like Gemini 1.5 Pro and
GPT-4o perform significantly below human-level streaming video understanding
capabilities. We hope our work can facilitate further advancements for MLLMs,
empowering them to approach human-level video comprehension and interaction in
more realistic scenarios.

摘要：多模態大型語言模型 (MLLM) 的快速發展已將其能力從影像理解擴展到影片理解。然而，這些 MLLM 大多主要專注於離線影片理解，在進行任何查詢之前需要對所有影片幀進行廣泛的處理。這與人類觀看、聆聽、思考和即時回應串流輸入的能力相比，存在顯著的差距，突顯了當前 MLLM 的限制。在本文中，我們介紹了 StreamingBench，這是第一個旨在評估 MLLM 串流影片理解能力的綜合基準測試。StreamingBench 評估串流影片理解的三个核心方面：(1) 即時視覺理解，(2) 全源理解，以及 (3) 背景理解。基準測試包含 18 項任務，特點是 900 部影片和 4,500 個由人工策劃的問答配對。每部影片都有五個問題在不同的時間點提出，以模擬連續串流場景。我們使用 13 個開源和專有 MLLM 對 StreamingBench 進行實驗，發現即使是最先進的專有 MLLM，如 Gemini 1.5 Pro 和 GPT-4o，在串流影片理解能力方面也顯著低於人類水準。我們希望我們的研究能促進 MLLM 的進一步發展，讓它們能夠在更逼真的場景中接近人類水準的影片理解和互動。

##### **Fully Hyperbolic Rotation for Knowledge Graph Embedding**
2411.03622v1 by Qiuyu Liang, Weihua Wang, Feilong Bao, Guanglai Gao

Hyperbolic rotation is commonly used to effectively model knowledge graphs
and their inherent hierarchies. However, existing hyperbolic rotation models
rely on logarithmic and exponential mappings for feature transformation. These
models only project data features into hyperbolic space for rotation, limiting
their ability to fully exploit the hyperbolic space. To address this problem,
we propose a novel fully hyperbolic model designed for knowledge graph
embedding. Instead of feature mappings, we define the model directly in
hyperbolic space with the Lorentz model. Our model considers each relation in
knowledge graphs as a Lorentz rotation from the head entity to the tail entity.
We adopt the Lorentzian version distance as the scoring function for measuring
the plausibility of triplets. Extensive results on standard knowledge graph
completion benchmarks demonstrated that our model achieves competitive results
with fewer parameters. In addition, our model get the state-of-the-art
performance on datasets of CoDEx-s and CoDEx-m, which are more diverse and
challenging than before. Our code is available at
https://github.com/llqy123/FHRE.

摘要：雙曲旋轉通常用於有效建模知識圖譜及其內在層級結構。然而，現有的雙曲旋轉模型依賴於對數和指數映射來進行特徵轉換。這些模型僅將數據特徵投影到雙曲空間中進行旋轉，限制了它們充分利用雙曲空間的能力。為了解決這個問題，我們提出了一個新的完全雙曲模型，專門用於知識圖譜嵌入。我們沒有使用特徵映射，而是直接在雙曲空間中使用洛倫茲模型定義模型。我們的模型將知識圖譜中的每個關係視為從頭實體到尾實體的洛倫茲旋轉。我們採用洛倫茲距離版本作為評分函數，用於測量三元組的可信度。在標準知識圖譜完成基準上的大量結果表明，我們的模型以更少的參數實現了有競爭力的結果。此外，我們的模型在 CoDEx-s 和 CoDEx-m 的數據集上取得了最先進的性能，這些數據集比以前更加多樣化且具有挑戰性。我們的代碼可在 https://github.com/llqy123/FHRE 獲得。

##### **Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification**
2411.03618v1 by Dahyun Mok, Junghyun Bum, Le Duc Tai, Hyunseung Choo

Diabetic Retinopathy (DR) is a primary cause of blindness, necessitating
early detection and diagnosis. This paper focuses on referable DR
classification to enhance the applicability of the proposed method in clinical
practice. We develop an advanced cross-learning DR classification method
leveraging transfer learning and cross-attention mechanisms. The proposed
method employs the Swin U-Net architecture to segment lesion maps from DR
fundus images. The Swin U-Net segmentation model, enriched with DR lesion
insights, is transferred to generate a lesion map. Both the fundus image and
its segmented lesion map are used as complementary inputs for the
classification model. A cross-attention mechanism is deployed to improve the
model's ability to capture fine-grained details from the input pairs. Our
experiments, utilizing two public datasets, FGADR and EyePACS, demonstrate a
superior accuracy of 94.6%, surpassing current state-of-the-art methods by
4.4%. To this end, we aim for the proposed method to be seamlessly integrated
into clinical workflows, enhancing accuracy and efficiency in identifying
referable DR.

摘要：糖尿病視網膜病變 (DR) 是失明的首要原因，需要早期檢測和診斷。本文重點關注可轉診的 DR 分類，以增強所提出方法在臨床實務中的適用性。我們開發了一種先進的交叉學習 DR 分類方法，利用遷移學習和交叉注意機制。所提出的方法採用 Swin U-Net 架構，從 DR 眼底圖像中分割病灶圖。豐富了 DR 病灶見解的 Swin U-Net 分割模型被轉移以生成病灶圖。眼底圖像及其分割的病灶圖都被用作分類模型的補充輸入。部署交叉注意機制以提高模型從輸入對中擷取細粒度細節的能力。我們的實驗利用了兩個公開數據集，FGADR 和 EyePACS，展示了 94.6% 的優異準確率，比當前最先進的方法高出 4.4%。為此，我們希望所提出的方法能無縫整合到臨床工作流程中，提高準確度和效率，以識別可轉診的 DR。

##### **From Medprompt to o1: Exploration of Run-Time Strategies for Medical Challenge Problems and Beyond**
2411.03590v1 by Harsha Nori, Naoto Usuyama, Nicholas King, Scott Mayer McKinney, Xavier Fernandes, Sheng Zhang, Eric Horvitz

Run-time steering strategies like Medprompt are valuable for guiding large
language models (LLMs) to top performance on challenging tasks. Medprompt
demonstrates that a general LLM can be focused to deliver state-of-the-art
performance on specialized domains like medicine by using a prompt to elicit a
run-time strategy involving chain of thought reasoning and ensembling. OpenAI's
o1-preview model represents a new paradigm, where a model is designed to do
run-time reasoning before generating final responses. We seek to understand the
behavior of o1-preview on a diverse set of medical challenge problem
benchmarks. Following on the Medprompt study with GPT-4, we systematically
evaluate the o1-preview model across various medical benchmarks. Notably, even
without prompting techniques, o1-preview largely outperforms the GPT-4 series
with Medprompt. We further systematically study the efficacy of classic prompt
engineering strategies, as represented by Medprompt, within the new paradigm of
reasoning models. We found that few-shot prompting hinders o1's performance,
suggesting that in-context learning may no longer be an effective steering
approach for reasoning-native models. While ensembling remains viable, it is
resource-intensive and requires careful cost-performance optimization. Our cost
and accuracy analysis across run-time strategies reveals a Pareto frontier,
with GPT-4o representing a more affordable option and o1-preview achieving
state-of-the-art performance at higher cost. Although o1-preview offers top
performance, GPT-4o with steering strategies like Medprompt retains value in
specific contexts. Moreover, we note that the o1-preview model has reached
near-saturation on many existing medical benchmarks, underscoring the need for
new, challenging benchmarks. We close with reflections on general directions
for inference-time computation with LLMs.

摘要：<paragraph>Medprompt 等运行时导引策略对于引导大型语言模型 (LLM) 在具有挑战性的任务中达到最佳性能很有价值。Medprompt 证明，可以通过使用提示来引发涉及思维链推理和集成运行时策略，将通用 LLM 集中起来，以在医学等专业领域提供最先进的性能。OpenAI 的 o1-preview 模型代表了一种新范例，其中模型被设计为在生成最终响应之前进行运行时推理。我们寻求了解 o1-preview 在各种医学挑战问题基准上的行为。在使用 GPT-4 进行 Medprompt 研究后，我们系统地评估了 o1-preview 模型在各种医学基准上的表现。值得注意的是，即使没有提示技术，o1-preview 在很大程度上也优于带有 Medprompt 的 GPT-4 系列。我们进一步系统地研究了经典提示工程策略（以 Medprompt 为代表）在新范例推理模型中的功效。我们发现，少量提示阻碍了 o1 的性能，这表明上下文学习可能不再是推理原生模型的有效导向方法。虽然集成仍然可行，但它需要大量资源，并且需要仔细进行成本性能优化。我们对运行时策略的成本和准确性分析揭示了帕累托前沿，其中 GPT-4o 代表了一个更实惠的选择，而 o1-preview 以更高的成本实现了最先进的性能。虽然 o1-preview 提供了顶级性能，但采用 Medprompt 等导向策略的 GPT-4o 在特定情况下仍具有价值。此外，我们注意到 o1-preview 模型在许多现有的医学基准上已接近饱和，这强调了对新的、具有挑战性的基准的需求。我们以对使用 LLM 进行推理时间计算的一般方向的思考作为结束。</paragraph>

##### **An Experimental Study on Decomposition-Based Deep Ensemble Learning for Traffic Flow Forecasting**
2411.03588v1 by Qiyuan Zhu, A. K. Qin, Hussein Dia, Adriana-Simona Mihaita, Hanna Grzybowska

Traffic flow forecasting is a crucial task in intelligent transport systems.
Deep learning offers an effective solution, capturing complex patterns in
time-series traffic flow data to enable the accurate prediction. However, deep
learning models are prone to overfitting the intricate details of flow data,
leading to poor generalisation. Recent studies suggest that decomposition-based
deep ensemble learning methods may address this issue by breaking down a time
series into multiple simpler signals, upon which deep learning models are built
and ensembled to generate the final prediction. However, few studies have
compared the performance of decomposition-based ensemble methods with
non-decomposition-based ones which directly utilise raw time-series data. This
work compares several decomposition-based and non-decomposition-based deep
ensemble learning methods. Experimental results on three traffic datasets
demonstrate the superiority of decomposition-based ensemble methods, while also
revealing their sensitivity to aggregation strategies and forecasting horizons.

摘要：交通流量預測是智慧運輸系統中的一項重要任務。
深度學習提供了一個有效的解決方案，捕捉時序交通流量資料中的複雜模式，以實現準確預測。然而，深度學習模型容易過度擬合流量資料的複雜細節，導致泛化能力不佳。最近的研究表明，基於分解的深度集成學習方法可以通過將時序分解為多個較簡單的信號來解決此問題，然後建立深度學習模型並集成它們以產生最終預測。然而，很少有研究比較基於分解的集成方法與直接利用原始時序資料的非基於分解方法的效能。這項工作比較了幾種基於分解和非基於分解的深度集成學習方法。在三個交通資料集上的實驗結果證明了基於分解的集成方法的優越性，同時也揭示了它們對聚合策略和預測範圍的敏感性。

##### **Towards Personalized Federated Learning via Comprehensive Knowledge Distillation**
2411.03569v1 by Pengju Wang, Bochao Liu, Weijia Guo, Yong Li, Shiming Ge

Federated learning is a distributed machine learning paradigm designed to
protect data privacy. However, data heterogeneity across various clients
results in catastrophic forgetting, where the model rapidly forgets previous
knowledge while acquiring new knowledge. To address this challenge,
personalized federated learning has emerged to customize a personalized model
for each client. However, the inherent limitation of this mechanism is its
excessive focus on personalization, potentially hindering the generalization of
those models. In this paper, we present a novel personalized federated learning
method that uses global and historical models as teachers and the local model
as the student to facilitate comprehensive knowledge distillation. The
historical model represents the local model from the last round of client
training, containing historical personalized knowledge, while the global model
represents the aggregated model from the last round of server aggregation,
containing global generalized knowledge. By applying knowledge distillation, we
effectively transfer global generalized knowledge and historical personalized
knowledge to the local model, thus mitigating catastrophic forgetting and
enhancing the general performance of personalized models. Extensive
experimental results demonstrate the significant advantages of our method.

摘要：聯邦學習是一種分散式機器學習範例，旨在保護資料隱私。然而，不同用戶端之間的資料異質性會導致災難性遺忘，模型在獲取新知識的同時會迅速遺忘先前的知識。為了應對這一挑戰，個性化聯邦學習應運而生，為每個用戶端自訂個性化模型。然而，這種機制的固有限制在於過度重視個性化，可能會阻礙這些模型的泛化。在本文中，我們提出了一種新穎的個性化聯邦學習方法，它使用全局模型和歷史模型作為教師，並將本地模型作為學生，以促進全面的知識蒸餾。歷史模型表示來自上次用戶端訓練的本地模型，包含歷史個性化知識，而全局模型表示來自上次伺服器聚合的聚合模型，包含全局概化知識。通過應用知識蒸餾，我們有效地將全局概化知識和歷史個性化知識傳遞到本地模型，從而減輕災難性遺忘並增強個性化模型的整體效能。廣泛的實驗結果證明了我們方法的顯著優勢。

##### **The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**
2411.03568v1 by Lee Kezar, Nidhi Munikote, Zian Zeng, Zed Sehyr, Naomi Caselli, Jesse Thomason

Language models for American Sign Language (ASL) could make language
technologies substantially more accessible to those who sign. To train models
on tasks such as isolated sign recognition (ISR) and ASL-to-English
translation, datasets provide annotated video examples of ASL signs. To
facilitate the generalizability and explainability of these models, we
introduce the American Sign Language Knowledge Graph (ASLKG), compiled from
twelve sources of expert linguistic knowledge. We use the ASLKG to train
neuro-symbolic models for 3 ASL understanding tasks, achieving accuracies of
91% on ISR, 14% for predicting the semantic features of unseen signs, and 36%
for classifying the topic of Youtube-ASL videos.

摘要：美國手語 (ASL) 的語言模型可以讓語言技術對手語使用者更易於使用。為了訓練模型執行手語辨識 (ISR) 和 ASL 轉換成英文等任務，資料集提供 ASL 手勢的註解影片範例。為了促進這些模型的概括性和可解釋性，我們引入了美國手語知識圖譜 (ASLKG)，它是由十二個專家語言知識來源編譯而成的。我們使用 ASLKG 訓練神經符號模型來執行 3 項 ASL 理解任務，在 ISR 上達到 91% 的準確度、在預測未見手勢的語義特徵上達到 14%，以及在分類 YouTube-ASL 影片主題上達到 36%。

##### **Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level**
2411.03562v1 by Antoine Grosnit, Alexandre Maraval, James Doran, Giuseppe Paolo, Albert Thomas, Refinath Shahul Hameed Nabeezath Beevi, Jonas Gonzalez, Khyati Khandelwal, Ignacio Iacobacci, Abdelhakim Benechehab, Hamza Cherkaoui, Youssef Attia El-Hili, Kun Shao, Jianye Hao, Jun Yao, Balazs Kegl, Haitham Bou-Ammar, Jun Wang

We introduce Agent K v1.0, an end-to-end autonomous data science agent
designed to automate, optimise, and generalise across diverse data science
tasks. Fully automated, Agent K v1.0 manages the entire data science life cycle
by learning from experience. It leverages a highly flexible structured
reasoning framework to enable it to dynamically process memory in a nested
structure, effectively learning from accumulated experience stored to handle
complex reasoning tasks. It optimises long- and short-term memory by
selectively storing and retrieving key information, guiding future decisions
based on environmental rewards. This iterative approach allows it to refine
decisions without fine-tuning or backpropagation, achieving continuous
improvement through experiential learning. We evaluate our agent's apabilities
using Kaggle competitions as a case study. Following a fully automated
protocol, Agent K v1.0 systematically addresses complex and multimodal data
science tasks, employing Bayesian optimisation for hyperparameter tuning and
feature engineering. Our new evaluation framework rigorously assesses Agent K
v1.0's end-to-end capabilities to generate and send submissions starting from a
Kaggle competition URL. Results demonstrate that Agent K v1.0 achieves a 92.5\%
success rate across tasks, spanning tabular, computer vision, NLP, and
multimodal domains. When benchmarking against 5,856 human Kaggle competitors by
calculating Elo-MMR scores for each, Agent K v1.0 ranks in the top 38\%,
demonstrating an overall skill level comparable to Expert-level users. Notably,
its Elo-MMR score falls between the first and third quartiles of scores
achieved by human Grandmasters. Furthermore, our results indicate that Agent K
v1.0 has reached a performance level equivalent to Kaggle Grandmaster, with a
record of 6 gold, 3 silver, and 7 bronze medals, as defined by Kaggle's
progression system.

摘要：<paragraph>我們推出 Agent K v1.0，一個端到端的自主資料科學代理程式，
旨在自動化、最佳化，並概括各種資料科學任務。Agent K v1.0 全自動化管理整個資料科學生命週期，
透過從經驗中學習。它利用高度靈活的結構化推理框架，使其能夠動態處理巢狀結構中的記憶體，有效地從儲存的累積經驗中學習，以處理複雜的推理任務。它透過選擇性儲存和擷取關鍵資訊，最佳化長期和短期記憶體，根據環境獎勵引導未來的決策。這種迭代方法允許它在不進行微調或反向傳播的情況下改善決策，透過體驗式學習實現持續改進。我們使用 Kaggle 競賽作為案例研究，評估我們代理程式的功能。遵循全自動化協定，Agent K v1.0 系統性地處理複雜且多模態的資料科學任務，採用貝氏最佳化進行超參數調整和特徵工程。我們新的評估框架嚴格評估 Agent K v1.0 的端到端功能，從 Kaggle 競賽 URL 開始產生並發送提交。結果表明，Agent K v1.0 在各項任務中實現了 92.5% 的成功率，涵蓋表格、電腦視覺、NLP 和多模態領域。透過計算每個人的 Elo-MMR 分數，在與 5,856 名人類 Kaggle 競爭者進行基準比較時，Agent K v1.0 排名前 38%，表現出與專家級使用者相當的整體技能水準。值得注意的是，它的 Elo-MMR 分數介於人類大師所獲得分數的第一和第三個四分位數之間。此外，我們的結果表明，Agent K v1.0 已達到與 Kaggle 大師同等的效能水準，根據 Kaggle 的進度系統定義，擁有 6 面金牌、3 面銀牌和 7 面銅牌的紀錄。</paragraph>

##### **Learning to Write Rationally: How Information Is Distributed in Non-Native Speakers' Essays**
2411.03550v1 by Zixin Tang, Janet G. van Hell

People tend to distribute information evenly in language production for
better and clearer communication. In this study, we compared essays written by
second language learners with various native language (L1) backgrounds to
investigate how they distribute information in their non-native language (L2)
production. Analyses of surprisal and constancy of entropy rate indicated that
writers with higher L2 proficiency can reduce the expected uncertainty of
language production while still conveying informative content. However, the
uniformity of information distribution showed less variability among different
groups of L2 speakers, suggesting that this feature may be universal in L2
essay writing and less affected by L2 writers' variability in L1 background and
L2 proficiency.

摘要：人們傾向於在語言產出中均勻地分配資訊，以進行更佳且更清晰的溝通。在本研究中，我們比較了由第二語言學習者所寫的論文，其母語 (L1) 背景各不相同，以探討他們如何在非母語 (L2) 產出中分配資訊。驚訝度與熵率恆定的分析指出，L2 熟練度較高的寫作者可以在傳達有意義的內容的同時，降低語言產出的預期不確定性。然而，資訊分配的均勻性在不同的 L2 說話者群體中顯示出較少的變異性，這表示此特徵可能在 L2 論文寫作中具有普遍性，且較不受 L2 寫作者在 L1 背景和 L2 熟練度上的變異性影響。

##### **Exploring the Benefits of Domain-Pretraining of Generative Large Language Models for Chemistry**
2411.03542v1 by Anurag Acharya, Shivam Sharma, Robin Cosbey, Megha Subramanian, Scott Howland, Maria Glenski

A proliferation of Large Language Models (the GPT series, BLOOM, LLaMA, and
more) are driving forward novel development of multipurpose AI for a variety of
tasks, particularly natural language processing (NLP) tasks. These models
demonstrate strong performance on a range of tasks; however, there has been
evidence of brittleness when applied to more niche or narrow domains where
hallucinations or fluent but incorrect responses reduce performance. Given the
complex nature of scientific domains, it is prudent to investigate the
trade-offs of leveraging off-the-shelf versus more targeted foundation models
for scientific domains. In this work, we examine the benefits of in-domain
pre-training for a given scientific domain, chemistry, and compare these to
open-source, off-the-shelf models with zero-shot and few-shot prompting. Our
results show that not only do in-domain base models perform reasonably well on
in-domain tasks in a zero-shot setting but that further adaptation using
instruction fine-tuning yields impressive performance on chemistry-specific
tasks such as named entity recognition and molecular formula generation.

摘要：大型語言模型（GPT 系列、BLOOM、LLaMA 等）的激增推動了多功能 AI 的新穎發展，適用於各種任務，特別是自然語言處理 (NLP) 任務。這些模型在各種任務上表現出色；然而，有證據表明，當應用於更利基或狹窄的領域時，它們會出現脆弱性，在這些領域中，幻覺或流暢但錯誤的反應會降低性能。鑑於科學領域的複雜性，審慎調查利用現成的基礎模型與針對科學領域的更具針對性的基礎模型之間的權衡取捨是明智的。在這項工作中，我們探討了在特定科學領域（化學）中進行領域內預訓練的好處，並將這些好處與零次學習和少次學習提示的開源現成模型進行比較。我們的結果表明，領域內基礎模型不僅在零次學習設置中在領域內任務上表現得相當好，而且使用指令微調進一步適應在化學特定任務（例如命名實體識別和分子式生成）上產生了令人印象深刻的性能。

##### **Long Context RAG Performance of Large Language Models**
2411.03538v1 by Quinn Leng, Jacob Portes, Sam Havens, Matei Zaharia, Michael Carbin

Retrieval Augmented Generation (RAG) has emerged as a crucial technique for
enhancing the accuracy of Large Language Models (LLMs) by incorporating
external information. With the advent of LLMs that support increasingly longer
context lengths, there is a growing interest in understanding how these models
perform in RAG scenarios. Can these new long context models improve RAG
performance? This paper presents a comprehensive study of the impact of
increased context length on RAG performance across 20 popular open source and
commercial LLMs. We ran RAG workflows while varying the total context length
from 2,000 to 128,000 tokens (and 2 million tokens when possible) on three
domain-specific datasets, and report key insights on the benefits and
limitations of long context in RAG applications. Our findings reveal that while
retrieving more documents can improve performance, only a handful of the most
recent state of the art LLMs can maintain consistent accuracy at long context
above 64k tokens. We also identify distinct failure modes in long context
scenarios, suggesting areas for future research.

摘要：檢索增強生成（RAG）已成為一種至關重要的技術，它透過納入外部資訊來提升大型語言模型（LLM）的準確性。隨著支援越來越長脈絡長度的 LLM 的出現，人們越來越有興趣了解這些模型在 RAG 場景中的表現。這些新的長脈絡模型能夠提升 RAG 的效能嗎？本文針對 20 個流行的開放原始碼和商業 LLM，對增加脈絡長度對 RAG 效能的影響進行全面的研究。我們在三個特定領域的資料集上執行 RAG 工作流程，同時將總脈絡長度從 2,000 個代幣變更為 128,000 個代幣（在可能的情況下為 200 萬個代幣），並針對 RAG 應用中長脈絡的優點和限制報告關鍵見解。我們的研究結果顯示，雖然檢索更多文件可以提升效能，但只有少數最先進的 LLM 能夠在 64k 個代幣以上的長脈絡中維持一致的準確性。我們也在長脈絡場景中找出不同的失敗模式，提出未來研究的方向。

##### **Two-Stage Pretraining for Molecular Property Prediction in the Wild**
2411.03537v1 by Kevin Tirta Wijaya, Minghao Guo, Michael Sun, Hans-Peter Seidel, Wojciech Matusik, Vahid Babaei

Accurate property prediction is crucial for accelerating the discovery of new
molecules. Although deep learning models have achieved remarkable success,
their performance often relies on large amounts of labeled data that are
expensive and time-consuming to obtain. Thus, there is a growing need for
models that can perform well with limited experimentally-validated data. In
this work, we introduce MoleVers, a versatile pretrained model designed for
various types of molecular property prediction in the wild, i.e., where
experimentally-validated molecular property labels are scarce. MoleVers adopts
a two-stage pretraining strategy. In the first stage, the model learns
molecular representations from large unlabeled datasets via masked atom
prediction and dynamic denoising, a novel task enabled by a new branching
encoder architecture. In the second stage, MoleVers is further pretrained using
auxiliary labels obtained with inexpensive computational methods, enabling
supervised learning without the need for costly experimental data. This
two-stage framework allows MoleVers to learn representations that generalize
effectively across various downstream datasets. We evaluate MoleVers on a new
benchmark comprising 22 molecular datasets with diverse types of properties,
the majority of which contain 50 or fewer training labels reflecting real-world
conditions. MoleVers achieves state-of-the-art results on 20 out of the 22
datasets, and ranks second among the remaining two, highlighting its ability to
bridge the gap between data-hungry models and real-world conditions where
practically-useful labels are scarce.

摘要：準確的屬性預測對於加速新分子的發現至關重要。儘管深度學習模型已取得顯著成功，但它們的性能通常依賴於大量的標籤數據，而這些數據的取得既昂貴又耗時。因此，越來越需要能夠在經過實驗驗證的數據有限的情況下表現良好的模型。在這項工作中，我們介紹了 MoleVers，這是一個多功能的預訓練模型，旨在針對各種類型的分子屬性預測，即在經過實驗驗證的分子屬性標籤稀缺的情況下。MoleVers 採用兩階段預訓練策略。在第一階段，該模型通過掩碼原子預測和動態去噪（一項由新的分支編碼器架構啟用的新任務）從大量的未標籤數據集中學習分子表示。在第二階段，MoleVers 使用通過廉價計算方法獲得的輔助標籤進行進一步的預訓練，從而實現監督學習，而無需昂貴的實驗數據。這種兩階段框架使 MoleVers 能夠學習跨各種下游數據集有效泛化的表示。我們在一個新的基準上評估 MoleVers，該基準包含 22 個具有不同類型的屬性的分子數據集，其中大部分包含 50 個或更少的訓練標籤，反映了真實世界的條件。MoleVers 在 22 個數據集中有 20 個取得了最先進的結果，而在剩下的兩個數據集中排名第二，突顯了它彌合數據密集型模型和實際應用中實用標籤稀缺之間差距的能力。

##### **Personalized Video Summarization by Multimodal Video Understanding**
2411.03531v1 by Brian Chen, Xiangyuan Zhao, Yingnan Zhu

Video summarization techniques have been proven to improve the overall user
experience when it comes to accessing and comprehending video content. If the
user's preference is known, video summarization can identify significant
information or relevant content from an input video, aiding them in obtaining
the necessary information or determining their interest in watching the
original video. Adapting video summarization to various types of video and user
preferences requires significant training data and expensive human labeling. To
facilitate such research, we proposed a new benchmark for video summarization
that captures various user preferences. Also, we present a pipeline called
Video Summarization with Language (VSL) for user-preferred video summarization
that is based on pre-trained visual language models (VLMs) to avoid the need to
train a video summarization system on a large training dataset. The pipeline
takes both video and closed captioning as input and performs semantic analysis
at the scene level by converting video frames into text. Subsequently, the
user's genre preference was used as the basis for selecting the pertinent
textual scenes. The experimental results demonstrate that our proposed pipeline
outperforms current state-of-the-art unsupervised video summarization models.
We show that our method is more adaptable across different datasets compared to
supervised query-based video summarization models. In the end, the runtime
analysis demonstrates that our pipeline is more suitable for practical use when
scaling up the number of user preferences and videos.

摘要：影片摘要技術已被證明可以改善整體使用者體驗，特別是在存取和理解影片內容時。如果已知使用者的偏好，影片摘要可以從輸入影片中找出重要的資訊或相關內容，協助他們取得必要的資訊或決定是否有興趣觀看原始影片。要將影片摘要適應到各種影片和使用者偏好，需要大量的訓練資料和昂貴的人工標記。為了促進此類研究，我們提出了影片摘要的新基準，涵蓋了各種使用者偏好。此外，我們提出一個稱為影片摘要與語言 (VSL) 的管道，用於使用者偏好的影片摘要，此管道基於預先訓練好的視覺語言模型 (VLM)，以避免在大型訓練資料集上訓練影片摘要系統的需要。此管道將影片和字幕作為輸入，並透過將影片格轉換為文字，在場景層級執行語意分析。隨後，使用使用者的類型偏好作為選擇相關文字場景的基礎。實驗結果證明，我們提出的管道優於目前最先進的無監督影片摘要模型。我們展示了與監督式查詢式影片摘要模型相比，我們的模型更能適應不同的資料集。最後，執行時間分析證明，當擴充使用者偏好和影片數量時，我們的管道更適合實際使用。

##### **Exploring the Potentials and Challenges of Using Large Language Models for the Analysis of Transcriptional Regulation of Long Non-coding RNAs**
2411.03522v1 by Wei Wang, Zhichao Hou, Xiaorui Liu, Xinxia Peng

Research on long non-coding RNAs (lncRNAs) has garnered significant attention
due to their critical roles in gene regulation and disease mechanisms. However,
the complexity and diversity of lncRNA sequences, along with the limited
knowledge of their functional mechanisms and the regulation of their
expressions, pose significant challenges to lncRNA studies. Given the
tremendous success of large language models (LLMs) in capturing complex
dependencies in sequential data, this study aims to systematically explore the
potential and limitations of LLMs in the sequence analysis related to the
transcriptional regulation of lncRNA genes. Our extensive experiments
demonstrated promising performance of fine-tuned genome foundation models on
progressively complex tasks. Furthermore, we conducted an insightful analysis
of the critical impact of task complexity, model selection, data quality, and
biological interpretability for the studies of the regulation of lncRNA gene
expression.

摘要：長鏈非編碼 RNA (lncRNA) 的研究因其在基因調控和疾病機制中扮演關鍵角色而備受矚目。然而，lncRNA 序列的複雜性和多樣性，加上我們對其功能機制和表達調控的知識有限，對 lncRNA 研究構成重大挑戰。鑑於大型語言模型 (LLM) 在捕捉序列資料中複雜依存關係的巨大成功，本研究旨在系統性地探討 LLM 在與 lncRNA 基因轉錄調控相關的序列分析中的潛力和限制。我們廣泛的實驗證明了微調後的基因組基礎模型在逐漸複雜的任務中表現出良好的效能。此外，我們對任務複雜性、模型選擇、資料品質和生物學可解釋性對 lncRNA 基因表現調控研究的關鍵影響進行了深入分析。

##### **AI Metropolis: Scaling Large Language Model-based Multi-Agent Simulation with Out-of-order Execution**
2411.03519v1 by Zhiqiang Xie, Hao Kang, Ying Sheng, Tushar Krishna, Kayvon Fatahalian, Christos Kozyrakis

With more advanced natural language understanding and reasoning capabilities,
large language model (LLM)-powered agents are increasingly developed in
simulated environments to perform complex tasks, interact with other agents,
and exhibit emergent behaviors relevant to social science and gaming. However,
current multi-agent simulations frequently suffer from inefficiencies due to
the limited parallelism caused by false dependencies, resulting in performance
bottlenecks. In this paper, we introduce AI Metropolis, a simulation engine
that improves the efficiency of LLM agent simulations by incorporating
out-of-order execution scheduling. By dynamically tracking real dependencies
between agents, AI Metropolis minimizes false dependencies, enhancing
parallelism and enabling efficient hardware utilization. Our evaluations
demonstrate that AI Metropolis achieves speedups from 1.3x to 4.15x over
standard parallel simulation with global synchronization, approaching optimal
performance as the number of agents increases.

摘要：隨著更進階的自然語言理解和推理能力，大型語言模型 (LLM) 驅動的代理人越來越常在模擬環境中開發，以執行複雜任務、與其他代理人互動，並表現出與社會科學和遊戲相關的新興行為。然而，目前的許多代理人模擬經常會因為虛假依賴關係造成的並行性受限而導致效率低下，進而產生效能瓶頸。在本文中，我們將介紹 AI Metropolis，這是一個模擬引擎，透過納入無序執行排程來提升 LLM 代理人模擬的效率。透過動態追蹤代理人之間的真實依賴關係，AI Metropolis 將虛假依賴關係降到最低，進而提升並行性並讓硬體得以有效利用。我們的評估結果顯示，AI Metropolis 在全球同步的標準平行模擬中，可達到 1.3 倍到 4.15 倍的加速，並隨著代理人數量增加而接近最佳效能。

##### **Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy**
2411.03513v1 by Razvan-Gabriel Dumitru, Paul-Ioan Clotan, Vikas Yadav, Darius Peteleaza, Mihai Surdeanu

This paper introduces a novel model compression approach through dynamic
layer-specific pruning in Large Language Models (LLMs), enhancing the
traditional methodology established by SliceGPT. By transitioning from constant
to dynamic slicing, our method leverages the newly proposed Layer Redundancy
(LR) score, which assesses how much change each layer changes its input by
measuring the cosine similarity of the input to the output of the layer. We use
this score to prune parts of individual layers based on redundancy in such a
way that the average pruned percentage for all layers is a fixed value. We
conducted extensive experiments using models like Llama3-8B and Mistral-7B on
multiple datasets, evaluating different slicing bases and percentages to
determine optimal configurations that balance efficiency and performance. Our
findings show that our dynamic slicing approach not only maintains but, in many
cases, enhances model performance compared to the baseline established by
constant slicing methods. For instance, in several settings, we see performance
improvements of up to 5% over the SliceGPT baseline. Additionally, a perplexity
decrease by as much as 7% was observed across multiple benchmarks, validating
the effectiveness of our method. The code, model weights, and datasets are
open-sourced at https://github.com/RazvanDu/DynamicSlicing.

摘要：本文介紹一種創新的模型壓縮方法，透過大型語言模型 (LLM) 中的動態特定層級修剪，增強 SliceGPT 所建立的傳統方法。透過從固定切片轉換為動態切片，我們的模型利用新提出的層級冗餘 (LR) 分數，透過測量輸入與層級輸出的餘弦相似度，評估每個層級改變其輸入的程度。我們使用此分數來修剪個別層級的部分，基於冗餘，平均修剪百分比為所有層級的固定值。我們使用 Llama3-8B 和 Mistral-7B 等模型在多個資料集上進行廣泛的實驗，評估不同的切片基礎和百分比，以確定平衡效率和效能的最佳組態。我們的研究結果顯示，與固定切片方法所建立的基準線相比，我們的動態切片方法不僅維持，在許多情況下，還增強了模型效能。例如，在多個設定中，我們看到效能比 SliceGPT 基準線提升多達 5%。此外，在多個基準測試中觀察到困惑度降低多達 7%，驗證了我們方法的有效性。程式碼、模型權重和資料集在 https://github.com/RazvanDu/DynamicSlicing 開源。

##### **Uncertainty Quantification for Clinical Outcome Predictions with (Large) Language Models**
2411.03497v1 by Zizhang Chen, Peizhao Li, Xiaomeng Dong, Pengyu Hong

To facilitate healthcare delivery, language models (LMs) have significant
potential for clinical prediction tasks using electronic health records (EHRs).
However, in these high-stakes applications, unreliable decisions can result in
high costs due to compromised patient safety and ethical concerns, thus
increasing the need for good uncertainty modeling of automated clinical
predictions. To address this, we consider the uncertainty quantification of LMs
for EHR tasks in white- and black-box settings. We first quantify uncertainty
in white-box models, where we can access model parameters and output logits. We
show that an effective reduction of model uncertainty can be achieved by using
the proposed multi-tasking and ensemble methods in EHRs. Continuing with this
idea, we extend our approach to black-box settings, including popular
proprietary LMs such as GPT-4. We validate our framework using longitudinal
clinical data from more than 6,000 patients in ten clinical prediction tasks.
Results show that ensembling methods and multi-task prediction prompts reduce
uncertainty across different scenarios. These findings increase the
transparency of the model in white-box and black-box settings, thus advancing
reliable AI healthcare.

摘要：為了促進醫療保健的提供，語言模型 (LM) 在使用電子健康紀錄 (EHR) 的臨床預測任務中具有顯著的潛力。然而，在這些高風險的應用中，不可靠的決策可能會由於危害病患安全和道德問題而導致高昂的成本，因此提高自動化臨床預測的不確定性建模的需求越來越高。為了解決這個問題，我們考慮了在白盒和黑盒設置中 LM 的不確定性量化，用於 EHR 任務。我們首先量化白盒模型中的不確定性，在其中我們可以存取模型參數和輸出 logit。我們顯示，透過在 EHR 中使用所提出的多任務和整體方法，可以有效降低模型不確定性。延續這個想法，我們將我們的做法擴展到黑盒設置，包括熱門的專有 LM，例如 GPT-4。我們使用來自超過 6,000 名病患的縱向臨床資料，在十項臨床預測任務中驗證我們的架構。結果顯示，整體方法和多任務預測提示可降低不同情境中的不確定性。這些發現提升了白盒和黑盒設置中模型的透明度，進而促進可靠的人工智慧醫療保健。

##### **Automatic Generation of Question Hints for Mathematics Problems using Large Language Models in Educational Technology**
2411.03495v1 by Junior Cedric Tonga, Benjamin Clement, Pierre-Yves Oudeyer

The automatic generation of hints by Large Language Models (LLMs) within
Intelligent Tutoring Systems (ITSs) has shown potential to enhance student
learning. However, generating pedagogically sound hints that address student
misconceptions and adhere to specific educational objectives remains
challenging. This work explores using LLMs (GPT-4o and Llama-3-8B-instruct) as
teachers to generate effective hints for students simulated through LLMs
(GPT-3.5-turbo, Llama-3-8B-Instruct, or Mistral-7B-instruct-v0.3) tackling math
exercises designed for human high-school students, and designed using cognitive
science principles. We present here the study of several dimensions: 1)
identifying error patterns made by simulated students on secondary-level math
exercises; 2) developing various prompts for GPT-4o as a teacher and evaluating
their effectiveness in generating hints that enable simulated students to
self-correct; and 3) testing the best-performing prompts, based on their
ability to produce relevant hints and facilitate error correction, with
Llama-3-8B-Instruct as the teacher, allowing for a performance comparison with
GPT-4o. The results show that model errors increase with higher temperature
settings. Notably, when hints are generated by GPT-4o, the most effective
prompts include prompts tailored to specific errors as well as prompts
providing general hints based on common mathematical errors. Interestingly,
Llama-3-8B-Instruct as a teacher showed better overall performance than GPT-4o.
Also the problem-solving and response revision capabilities of the LLMs as
students, particularly GPT-3.5-turbo, improved significantly after receiving
hints, especially at lower temperature settings. However, models like
Mistral-7B-Instruct demonstrated a decline in performance as the temperature
increased.

摘要：大型語言模型 (LLM) 在智慧型教學系統 (ITS) 中自動產生提示，已顯示出增進學生學習的潛力。然而，產生符合教學法的提示，以解決學生的誤解並遵循特定的教育目標，仍然具有挑戰性。這項工作探討使用 LLM（GPT-4o 和 Llama-3-8B-instruct）作為老師，為模擬透過 LLM（GPT-3.5-turbo、Llama-3-8B-Instruct 或 Mistral-7B-instruct-v0.3）解決專為人類高中生設計的數學練習，並使用認知科學原理進行設計的學生的產生有效提示。我們在此提出對幾個面向的研究：1）找出模擬學生在中學數學練習中產生的錯誤模式；2）為 GPT-4o 作為老師開發各種提示，並評估它們在產生提示以使模擬學生能夠自我修正方面的有效性；3）測試基於產生相關提示和促進錯誤修正的能力，表現最佳的提示，由 Llama-3-8B-Instruct 作為老師，允許與 GPT-4o 進行效能比較。結果顯示，模型錯誤會隨著較高的溫度設定而增加。值得注意的是，當提示是由 GPT-4o 產生時，最有效的提示包括針對特定錯誤量身打造的提示，以及根據常見數學錯誤提供一般提示的提示。有趣的是，作為老師的 Llama-3-8B-Instruct 顯示出比 GPT-4o 更好的整體表現。此外，特別是 GPT-3.5-turbo，LLM 作為學生的問題解決和回應修正能力在收到提示後顯著提升，尤其是在較低的溫度設定下。然而，隨著溫度升高，Mistral-7B-Instruct 等模型的效能表現出下降。

##### **LASER: Attention with Exponential Transformation**
2411.03493v1 by Sai Surya Duvvuri, Inderjit S. Dhillon

Transformers have had tremendous impact for several sequence related tasks,
largely due to their ability to retrieve from any part of the sequence via
softmax based dot-product attention. This mechanism plays a crucial role in
Transformer's performance. We analyze the gradients backpropagated through the
softmax operation in the attention mechanism and observe that these gradients
can often be small. This poor gradient signal backpropagation can lead to
inefficient learning of parameters preceeding the attention operations. To this
end, we introduce a new attention mechanism called LASER, which we analytically
show to admit a larger gradient signal. We show that LASER Attention can be
implemented by making small modifications to existing attention
implementations. We conduct experiments on autoregressive large language models
(LLMs) with upto 2.2 billion parameters where we show upto 3.38% and an average
of ~1% improvement over standard attention on downstream evaluations. Using
LASER gives the following relative improvements in generalization performance
across a variety of tasks (vision, text and speech): 4.67% accuracy in Vision
Transformer (ViT) on Imagenet, 2.25% error rate in Conformer on the Librispeech
speech-to-text and 0.93% fraction of incorrect predictions in BERT with 2.2
billion parameters.

摘要：Transformer 在多項序列相關任務中產生重大影響，
這在很大程度上是因為它們能夠透過基於 softmax 的 dot-product 注意力機制，從序列的任何部分擷取資訊。這個機制在 Transformer 的效能中扮演著關鍵角色。我們分析了在注意力機制中透過 softmax 運算反向傳播的梯度，並觀察到這些梯度通常很小。這種不佳的梯度訊號反向傳播可能會導致在注意力運算之前參數學習效率不彰。為此，我們引進了一種稱為 LASER 的新注意力機制，我們分析性地證明它允許更大的梯度訊號。我們證明 LASER 注意力可以透過對現有注意力實作進行小幅修改來實作。我們在具有多達 22 億個參數的自迴歸大型語言模型 (LLM) 上進行實驗，在這些實驗中，我們顯示出在下游評估中，標準注意力的進步幅度最高為 3.38%，平均約為 1%。在各種任務（視覺、文字和語音）中使用 LASER 可帶來以下相對的泛化效能提升：Imagenet 上的視覺 Transformer (ViT) 準確度提升 4.67%，Librispeech 語音轉文字上的 Conformer 錯誤率降低 2.25%，BERT 中不正確預測的比例降低 0.93%，參數為 22 億。

##### **LLM Generated Distribution-Based Prediction of US Electoral Results, Part I**
2411.03486v1 by Caleb Bradshaw, Caelen Miller, Sean Warnick

This paper introduces distribution-based prediction, a novel approach to
using Large Language Models (LLMs) as predictive tools by interpreting output
token probabilities as distributions representing the models' learned
representation of the world. This distribution-based nature offers an
alternative perspective for analyzing algorithmic fidelity, complementing the
approach used in silicon sampling. We demonstrate the use of distribution-based
prediction in the context of recent United States presidential election,
showing that this method can be used to determine task specific bias, prompt
noise, and algorithmic fidelity. This approach has significant implications for
assessing the reliability and increasing transparency of LLM-based predictions
across various domains.

摘要：本文介紹基於分佈的預測，這是一種新穎的方法，可透過將輸出代幣機率解釋為代表模型學習世界表徵的分佈，將大型語言模型 (LLM) 用作預測工具。這種基於分佈的性質提供了一個分析演算法保真度的替代觀點，補充了在矽晶片抽樣中使用的方法。我們展示了在最近美國總統選舉的背景下使用基於分佈的預測，表明此方法可用於確定特定任務的偏差、提示雜訊和演算法保真度。此方法對評估 LLM 基於預測的可靠性以及提高其在各個領域的透明度具有重要意義。

##### **MetRex: A Benchmark for Verilog Code Metric Reasoning Using LLMs**
2411.03471v1 by Manar Abdelatty, Jingxiao Ma, Sherief Reda

Large Language Models (LLMs) have been applied to various hardware design
tasks, including Verilog code generation, EDA tool scripting, and RTL bug
fixing. Despite this extensive exploration, LLMs are yet to be used for the
task of post-synthesis metric reasoning and estimation of HDL designs. In this
paper, we assess the ability of LLMs to reason about post-synthesis metrics of
Verilog designs. We introduce MetRex, a large-scale dataset comprising 25,868
Verilog HDL designs and their corresponding post-synthesis metrics, namely
area, delay, and static power. MetRex incorporates a Chain of Thought (CoT)
template to enhance LLMs' reasoning about these metrics. Extensive experiments
show that Supervised Fine-Tuning (SFT) boosts the LLM's reasoning capabilities
on average by 37.0\%, 25.3\%, and 25.7\% on the area, delay, and static power,
respectively. While SFT improves performance on our benchmark, it remains far
from achieving optimal results, especially on complex problems. Comparing to
state-of-the-art regression models, our approach delivers accurate
post-synthesis predictions for 17.4\% more designs (within a 5\% error margin),
in addition to offering a 1.7x speedup by eliminating the need for
pre-processing. This work lays the groundwork for advancing LLM-based Verilog
code metric reasoning.

摘要：大型語言模型 (LLM) 已應用於各種硬體設計任務，包括 Verilog 程式碼產生、EDA 工具腳本編寫和 RTL 錯誤修正。儘管有如此廣泛的探索，但 LLM 尚未用於合成後指標推理和 HDL 設計估計的任務。在本文中，我們評估了 LLM 推理 Verilog 設計合成後指標的能力。我們引入了 MetRex，這是一個包含 25,868 個 Verilog HDL 設計及其對應合成後指標（面積、延遲和靜態功率）的大規模資料集。MetRex 結合了思考鏈 (CoT) 範本，以增強 LLM 對這些指標的推理。廣泛的實驗表明，有監督微調 (SFT) 平均提升了 LLM 的推理能力，分別在面積、延遲和靜態功率方面提升了 37.0%、25.3% 和 25.7%。雖然 SFT 改善了我們基準測試的效能，但距離達到最佳結果仍有很大差距，特別是在複雜的問題上。與最先進的迴歸模型相比，我們的做法提供了準確的合成後預測，適用於多 17.4% 的設計（誤差範圍在 5% 以內），此外還通過消除預處理的需要來提供 1.7 倍的速度提升。這項工作為推進基於 LLM 的 Verilog 程式碼指標推理奠定了基礎。

##### **Watson: A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents**
2411.03455v1 by Benjamin Rombaut, Sogol Masoumzadeh, Kirill Vasilevski, Dayi Lin, Ahmed E. Hassan

As foundation models (FMs) play an increasingly prominent role in complex
software systems, such as FM-powered agentic software (i.e., Agentware), they
introduce significant challenges for developers regarding observability. Unlike
traditional software, agents operate autonomously, using extensive data and
opaque implicit reasoning, making it difficult to observe and understand their
behavior during runtime, especially when they take unexpected actions or
encounter errors. In this paper, we highlight the limitations of traditional
operational observability in the context of FM-powered software, and introduce
cognitive observability as a new type of required observability that has
emerged for such innovative systems. We then propose a novel framework that
provides cognitive observability into the implicit reasoning processes of
agents (a.k.a. reasoning observability), and demonstrate the effectiveness of
our framework in boosting the debuggability of Agentware and, in turn, the
abilities of an Agentware through a case study on AutoCodeRover, a cuttingedge
Agentware for autonomous program improvement.

摘要：隨著基礎模型 (FM) 在複雜軟體系統中扮演越來越重要的角色，例如 FM 驅動的代理軟體（即 Agentware），它們為開發人員在可觀察性方面帶來了重大的挑戰。與傳統軟體不同，代理軟體使用大量資料和不透明的隱含推理進行自主運作，這使得在執行期間難以觀察和理解它們的行為，特別是在它們採取意外行動或遇到錯誤時。在本文中，我們強調了傳統運作可觀察性在 FM 驅動軟體中的限制，並介紹了認知可觀察性，這是一種新類型的必需可觀察性，它已經出現在這類創新系統中。然後，我們提出了一個新穎的框架，它提供了對代理軟體隱含推理過程的認知可觀察性（又稱推理可觀察性），並展示了我們的框架在提升 Agentware 的除錯能力方面的有效性，進而透過一個關於 AutoCodeRover 的案例研究提升了 Agentware 的能力，AutoCodeRover 是一種用於自主程式改善的尖端 Agentware。

##### **Solving Trojan Detection Competitions with Linear Weight Classification**
2411.03445v1 by Todd Huster, Peter Lin, Razvan Stefanescu, Emmanuel Ekwedike, Ritu Chadha

Neural networks can conceal malicious Trojan backdoors that allow a trigger
to covertly change the model behavior. Detecting signs of these backdoors,
particularly without access to any triggered data, is the subject of ongoing
research and open challenges. In one common formulation of the problem, we are
given a set of clean and poisoned models and need to predict whether a given
test model is clean or poisoned. In this paper, we introduce a detector that
works remarkably well across many of the existing datasets and domains. It is
obtained by training a binary classifier on a large number of models' weights
after performing a few different pre-processing steps including feature
selection and standardization, reference model weights subtraction, and model
alignment prior to detection. We evaluate this algorithm on a diverse set of
Trojan detection benchmarks and domains and examine the cases where the
approach is most and least effective.

摘要：神經網路可以隱藏惡意的木馬後門，允許觸發器秘密地改變模型行為。偵測這些後門的跡象，特別是在無法存取任何觸發資料的情況下，是持續進行的研究和公開的挑戰。在一個常見的問題表述中，我們會得到一組乾淨和中毒的模型，並需要預測給定的測試模型是乾淨還是中毒。在本文中，我們引入了一個偵測器，它在許多現有資料集和領域中表現得非常好。它是通過在大量模型權重上訓練一個二元分類器獲得的，在訓練之前執行了一些不同的預處理步驟，包括特徵選擇和標準化、參考模型權重減法和模型對齊。我們在各種木馬偵測基準和領域上評估這個演算法，並檢視該方法最有效和最無效的情況。

##### **MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and Reasoning**
2411.03314v1 by Ziliang Gan, Yu Lu, Dong Zhang, Haohan Li, Che Liu, Jian Liu, Ji Liu, Haipang Wu, Chaoyou Fu, Zenglin Xu, Rongjunchen Zhang, Yong Dai

In recent years, multimodal benchmarks for general domains have guided the
rapid development of multimodal models on general tasks. However, the financial
field has its peculiarities. It features unique graphical images (e.g.,
candlestick charts, technical indicator charts) and possesses a wealth of
specialized financial knowledge (e.g., futures, turnover rate). Therefore,
benchmarks from general fields often fail to measure the performance of
multimodal models in the financial domain, and thus cannot effectively guide
the rapid development of large financial models. To promote the development of
large financial multimodal models, we propose MME-Finance, an bilingual
open-ended and practical usage-oriented Visual Question Answering (VQA)
benchmark. The characteristics of our benchmark are finance and expertise,
which include constructing charts that reflect the actual usage needs of users
(e.g., computer screenshots and mobile photography), creating questions
according to the preferences in financial domain inquiries, and annotating
questions by experts with 10+ years of experience in the financial industry.
Additionally, we have developed a custom-designed financial evaluation system
in which visual information is first introduced in the multi-modal evaluation
process. Extensive experimental evaluations of 19 mainstream MLLMs are
conducted to test their perception, reasoning, and cognition capabilities. The
results indicate that models performing well on general benchmarks cannot do
well on MME-Finance; for instance, the top-performing open-source and
closed-source models obtain 65.69 (Qwen2VL-72B) and 63.18 (GPT-4o),
respectively. Their performance is particularly poor in categories most
relevant to finance, such as candlestick charts and technical indicator charts.
In addition, we propose a Chinese version, which helps compare performance of
MLLMs under a Chinese context.

摘要：<paragraph>近年來，一般領域的多模態基準引導多模態模型在一般任務上快速發展。然而，金融領域有其獨特性。它具有獨特的圖形影像（例如，蠟燭圖、技術指標圖），並擁有豐富的專業金融知識（例如，期貨、換手率）。因此，一般領域的基準往往無法衡量多模態模型在金融領域的表現，從而無法有效引導大型金融模型的快速發展。為了促進大型金融多模態模型的發展，我們提出了 MME-Finance，一個雙語開放式且實用的面向使用情境的視覺問答（VQA）基準。我們的基準特點為金融和專業，包括構建反映使用者實際使用需求的圖表（例如，電腦截圖和手機攝影），根據金融領域詢問的偏好建立問題，並由具有 10 年以上金融產業經驗的專家註解問題。此外，我們開發了一個客製化的金融評量系統，在多模態評量過程中首次導入視覺資訊。對 19 個主流 MLLM 進行廣泛的實驗評估，以測試它們的感知、推理和認知能力。結果表明，在一般基準上表現良好的模型無法在 MME-Finance 上表現良好；例如，表現最好的開源和閉源模型分別獲得 65.69（Qwen2VL-72B）和 63.18（GPT-4o）。它們在與金融最相關的類別（例如，蠟燭圖和技術指標圖）中的表現特別差。此外，我們提出了中文版本，有助於在中文語境下比較 MLLM 的表現。</paragraph>

##### **Usefulness of LLMs as an Author Checklist Assistant for Scientific Papers: NeurIPS'24 Experiment**
2411.03417v1 by Alexander Goldberg, Ihsan Ullah, Thanh Gia Hieu Khuong, Benedictus Kent Rachmat, Zhen Xu, Isabelle Guyon, Nihar B. Shah

Large language models (LLMs) represent a promising, but controversial, tool
in aiding scientific peer review. This study evaluates the usefulness of LLMs
in a conference setting as a tool for vetting paper submissions against
submission standards. We conduct an experiment at the 2024 Neural Information
Processing Systems (NeurIPS) conference, where 234 papers were voluntarily
submitted to an "LLM-based Checklist Assistant." This assistant validates
whether papers adhere to the author checklist used by NeurIPS, which includes
questions to ensure compliance with research and manuscript preparation
standards. Evaluation of the assistant by NeurIPS paper authors suggests that
the LLM-based assistant was generally helpful in verifying checklist
completion. In post-usage surveys, over 70% of authors found the assistant
useful, and 70% indicate that they would revise their papers or checklist
responses based on its feedback. While causal attribution to the assistant is
not definitive, qualitative evidence suggests that the LLM contributed to
improving some submissions. Survey responses and analysis of re-submissions
indicate that authors made substantive revisions to their submissions in
response to specific feedback from the LLM. The experiment also highlights
common issues with LLMs: inaccuracy (20/52) and excessive strictness (14/52)
were the most frequent issues flagged by authors. We also conduct experiments
to understand potential gaming of the system, which reveal that the assistant
could be manipulated to enhance scores through fabricated justifications,
highlighting potential vulnerabilities of automated review tools.

摘要：大型語言模型 (LLM) 是一種有前途但有爭議的工具，有助於科學同行評審。本研究評估了 LLM 在會議環境中作為審查論文提交是否符合提交標準的工具的效用。我們在 2024 年神經資訊處理系統 (NeurIPS) 會議上進行了一項實驗，其中 234 篇論文自願提交給「基於 LLM 的核對清單助理」。此助理驗證論文是否符合 NeurIPS 使用的作者核對清單，其中包括確保符合研究和手稿準備標準的問題。NeurIPS 論文作者對助理的評估表明，基於 LLM 的助理通常有助於驗證核對清單完成情況。在使用後調查中，超過 70% 的作者發現該助理有用，而 70% 表示他們會根據其回饋修改論文或核對清單回應。雖然無法明確將因果關係歸因於助理，但定性證據表明，LLM 有助於改善某些提交。調查回應和重新提交的分析表明，作者根據 LLM 的具體回饋對其提交進行了實質性修改。該實驗還突出了 LLM 的常見問題：不準確 (20/52) 和過度嚴格 (14/52) 是作者標記的最常見問題。我們還進行實驗以了解系統的潛在博弈，這表明可以通過捏造的理由來操縱助理以提高分數，強調了自動化審查工具的潛在漏洞。

##### **Inference Optimal VLMs Need Only One Visual Token but Larger Models**
2411.03312v1 by Kevin Y. Li, Sachin Goyal, Joao D. Semedo, J. Zico Kolter

Vision Language Models (VLMs) have demonstrated strong capabilities across
various visual understanding and reasoning tasks. However, their real-world
deployment is often constrained by high latency during inference due to
substantial compute required to process the large number of input tokens
(predominantly from the image) by the LLM. To reduce inference costs, one can
either downsize the LLM or reduce the number of input image-tokens, the latter
of which has been the focus of many recent works around token compression.
However, it is unclear what the optimal trade-off is, as both the factors
directly affect the VLM performance. We first characterize this optimal
trade-off between the number of visual tokens and LLM parameters by
establishing scaling laws that capture variations in performance with these two
factors. Our results reveal a surprising trend: for visual reasoning tasks, the
inference-optimal behavior in VLMs, i.e., minimum downstream error at any given
fixed inference compute, is achieved when using the largest LLM that fits
within the inference budget while minimizing visual token count - often to a
single token. While the token reduction literature has mainly focused on
maintaining base model performance by modestly reducing the token count (e.g.,
$5-10\times$), our results indicate that the compute-optimal inference regime
requires operating under even higher token compression ratios. Based on these
insights, we take some initial steps towards building approaches tailored for
high token compression settings. Code is available at
https://github.com/locuslab/llava-token-compression.

摘要：視覺語言模型 (VLM) 已在各種視覺理解和推理任務中展現強大的能力。然而，由於 LLM 處理大量輸入代碼 (主要來自影像) 所需的大量運算，其實際部署通常會受到推論期間的高延遲所限制。為了降低推論成本，可以縮小 LLM 或減少輸入影像代碼的數量，後者一直是許多近期代碼壓縮相關工作的重點。然而，目前尚不清楚最佳的折衷方案為何，因為這兩個因素都會直接影響 VLM 效能。我們首先透過建立縮放定律來描述視覺代碼數量和 LLM 參數之間的最佳折衷，以捕捉這兩個因素效能的變化。我們的結果揭示了一個令人驚訝的趨勢：對於視覺推理任務，VLM 中的推論最佳行為，即在任何給定的固定推論運算中達到最小下游誤差，是在使用符合推論預算且同時將視覺代碼數量降至最低 (通常為單一代碼) 的最大 LLM 時實現的。雖然代碼減少文獻主要集中在透過適度減少代碼數量 (例如，5-10 倍) 來維持基礎模型效能，但我們的結果顯示，運算最佳的推論機制需要在更高的代碼壓縮比下操作。根據這些見解，我們採取了一些初步步驟來建構針對高代碼壓縮設定量身打造的方法。程式碼可在 https://github.com/locuslab/llava-token-compression 取得。

##### **STEER: Flexible Robotic Manipulation via Dense Language Grounding**
2411.03409v1 by Laura Smith, Alex Irpan, Montserrat Gonzalez Arenas, Sean Kirmani, Dmitry Kalashnikov, Dhruv Shah, Ted Xiao

The complexity of the real world demands robotic systems that can
intelligently adapt to unseen situations. We present STEER, a robot learning
framework that bridges high-level, commonsense reasoning with precise, flexible
low-level control. Our approach translates complex situational awareness into
actionable low-level behavior through training language-grounded policies with
dense annotation. By structuring policy training around fundamental, modular
manipulation skills expressed in natural language, STEER exposes an expressive
interface for humans or Vision-Language Models (VLMs) to intelligently
orchestrate the robot's behavior by reasoning about the task and context. Our
experiments demonstrate the skills learned via STEER can be combined to
synthesize novel behaviors to adapt to new situations or perform completely new
tasks without additional data collection or training.

摘要：現實世界的複雜性要求機器人系統能智慧地適應前所未見的情況。我們提出 STEER，一個機器人學習架構，它將高層次的常識推理與精確、靈活的低層次控制結合起來。我們的做法透過訓練以語言為基礎的政策和密集註解，將複雜的情境感知轉化為可操作的低層次行為。透過將政策訓練建構在以自然語言表達的基本模組化操作技能上，STEER 揭露了一個表現力豐富的介面，供人類或視覺語言模型（VLM）透過推理任務和情境來智慧地協調機器人的行為。我們的實驗證明透過 STEER 學到的技能可以結合起來，以綜合新的行為，以適應新的情況或執行全新的任務，而無需額外的資料收集或訓練。

##### **SAUCE: Synchronous and Asynchronous User-Customizable Environment for Multi-Agent LLM Interaction**
2411.03397v1 by Shlomo Neuberger, Niv Eckhaus, Uri Berger, Amir Taubenfeld, Gabriel Stanovsky, Ariel Goldstein

Many human interactions, such as political debates, are carried out in group
settings, where there are arbitrarily many participants, each with different
views and agendas. To explore such complex social settings, we present SAUCE: a
customizable Python platform, allowing researchers to plug-and-play various
LLMs participating in discussions on any topic chosen by the user. Our platform
takes care of instantiating the models, scheduling their responses, managing
the discussion history, and producing a comprehensive output log, all
customizable through configuration files, requiring little to no coding skills.
A novel feature of SAUCE is our asynchronous communication feature, where
models decide when to speak in addition to what to say, thus modeling an
important facet of human communication. We show SAUCE's attractiveness in two
initial experiments, and invite the community to use it in simulating various
group simulations.

摘要：許多人類互動，例如政治辯論，都在群組環境中進行，其中有任意多名參與者，每個人都有不同的觀點和議程。為了探索如此複雜的社會環境，我們提出了 SAUCE：一個可自訂的 Python 平台，讓研究人員可以即插即用各種 LLM，參與使用者選擇的任何主題討論。我們的平台負責實例化模型、安排其回應、管理討論記錄，並產生全面的輸出記錄，所有這些都可以透過組態檔自訂，幾乎不需要編碼技能。SAUCE 的一項新功能是我們的非同步通訊功能，其中模型除了決定要說什麼之外，還會決定何時發言，從而模擬人類溝通的一個重要方面。我們在兩個初始實驗中展示了 SAUCE 的吸引力，並邀請社群使用它來模擬各種群組模擬。

##### **Exploring Large Language Models for Specialist-level Oncology Care**
2411.03395v1 by Anil Palepu, Vikram Dhillon, Polly Niravath, Wei-Hung Weng, Preethi Prasad, Khaled Saab, Ryutaro Tanno, Yong Cheng, Hanh Mai, Ethan Burns, Zainub Ajmal, Kavita Kulkarni, Philip Mansfield, Dale Webster, Joelle Barral, Juraj Gottweis, Mike Schaekermann, S. Sara Mahdavi, Vivek Natarajan, Alan Karthikesalingam, Tao Tu

Large language models (LLMs) have shown remarkable progress in encoding
clinical knowledge and responding to complex medical queries with appropriate
clinical reasoning. However, their applicability in subspecialist or complex
medical settings remains underexplored. In this work, we probe the performance
of AMIE, a research conversational diagnostic AI system, in the subspecialist
domain of breast oncology care without specific fine-tuning to this challenging
domain. To perform this evaluation, we curated a set of 50 synthetic breast
cancer vignettes representing a range of treatment-naive and
treatment-refractory cases and mirroring the key information available to a
multidisciplinary tumor board for decision-making (openly released with this
work). We developed a detailed clinical rubric for evaluating management plans,
including axes such as the quality of case summarization, safety of the
proposed care plan, and recommendations for chemotherapy, radiotherapy, surgery
and hormonal therapy. To improve performance, we enhanced AMIE with the
inference-time ability to perform web search retrieval to gather relevant and
up-to-date clinical knowledge and refine its responses with a multi-stage
self-critique pipeline. We compare response quality of AMIE with internal
medicine trainees, oncology fellows, and general oncology attendings under both
automated and specialist clinician evaluations. In our evaluations, AMIE
outperformed trainees and fellows demonstrating the potential of the system in
this challenging and important domain. We further demonstrate through
qualitative examples, how systems such as AMIE might facilitate conversational
interactions to assist clinicians in their decision making. However, AMIE's
performance was overall inferior to attending oncologists suggesting that
further research is needed prior to consideration of prospective uses.

摘要：大型語言模型 (LLM) 在編碼臨床知識和以適當的臨床推理回應複雜的醫療查詢方面已展現出顯著的進展。然而，它們在次專科或複雜的醫療環境中的適用性仍未得到充分探討。在這項工作中，我們探討了 AMIE 的表現，這是一個研究對話式診斷 AI 系統，在沒有針對這個具有挑戰性的領域進行特定微調的情況下，在乳房腫瘤學護理的次專科領域中。為了執行此評估，我們策劃了一組 50 個合成乳癌小插曲，代表一系列未接受治療和難治的病例，並反映了多學科腫瘤委員會在決策時可獲得的關鍵資訊（公開發布此工作）。我們制定了一個詳細的臨床準則，用於評估管理計畫，包括病例摘要的品質、所建議照護計畫的安全性，以及化療、放射治療、手術和荷爾蒙治療的建議等面向。為了提升表現，我們透過推論時間能力增強 AMIE，以執行網路搜尋檢索，收集相關且最新的臨床知識，並透過多階段自我批判管道改善其回應。我們將 AMIE 的回應品質與內科住院醫師、腫瘤科研究員和一般腫瘤科主治醫師進行比較，在自動化和專科臨床醫師評估下進行。在我們的評估中，AMIE 的表現優於住院醫師和研究員，證明了系統在這個具有挑戰性和重要的領域中的潛力。我們進一步透過定性範例說明，像 AMIE 這樣的系統如何促進對話互動，以協助臨床醫師進行決策。然而，AMIE 的表現整體而言不如主治腫瘤科醫師，這表示在考慮潛在用途之前，需要進行進一步的研究。

##### **Neurons for Neutrons: A Transformer Model for Computation Load Estimation on Domain-Decomposed Neutron Transport Problems**
2411.03389v1 by Alexander Mote, Todd Palmer, Lizhong Chen

Domain decomposition is a technique used to reduce memory overhead on large
neutron transport problems. Currently, the optimal load-balanced processor
allocation for these domains is typically determined through small-scale
simulations of the problem, which can be time-consuming for researchers and
must be repeated anytime a problem input is changed. We propose a Transformer
model with a unique 3D input embedding, and input representations designed for
domain-decomposed neutron transport problems, which can predict the subdomain
computation loads generated by small-scale simulations. We demonstrate that
such a model trained on domain-decomposed Small Modular Reactor (SMR)
simulations achieves 98.2% accuracy while being able to skip the small-scale
simulation step entirely. Tests of the model's robustness on variant fuel
assemblies, other problem geometries, and changes in simulation parameters are
also discussed.

摘要：領域分解是一種用於降低大型中子傳輸問題的記憶體開銷的技術。目前，這些領域的最佳負載平衡處理器配置通常透過問題的小規模模擬來決定，這對研究人員來說可能很耗時，而且必須在問題輸入被變更時重複進行。我們提出了一個具有獨特 3D 輸入嵌入和輸入表示的 Transformer 模型，該模型專為領域分解中子傳輸問題而設計，可以預測小規模模擬產生的子領域計算負載。我們展示了在領域分解小型模組化反應爐 (SMR) 模擬上訓練的此類模型可達到 98.2% 的準確度，同時能夠完全跳過小規模模擬步驟。還討論了模型對變異燃料組件、其他問題幾何形狀和模擬參數變化的魯棒性測試。

##### **LLMs for Domain Generation Algorithm Detection**
2411.03307v1 by Reynier Leyva La O, Carlos A. Catania, Tatiana Parlanti

This work analyzes the use of large language models (LLMs) for detecting
domain generation algorithms (DGAs). We perform a detailed evaluation of two
important techniques: In-Context Learning (ICL) and Supervised Fine-Tuning
(SFT), showing how they can improve detection. SFT increases performance by
using domain-specific data, whereas ICL helps the detection model to quickly
adapt to new threats without requiring much retraining. We use Meta's Llama3 8B
model, on a custom dataset with 68 malware families and normal domains,
covering several hard-to-detect schemes, including recent word-based DGAs.
Results proved that LLM-based methods can achieve competitive results in DGA
detection. In particular, the SFT-based LLM DGA detector outperforms
state-of-the-art models using attention layers, achieving 94% accuracy with a
4% false positive rate (FPR) and excelling at detecting word-based DGA domains.

摘要：這項工作分析了使用大型語言模型 (LLM) 來偵測網域名稱產生演算法 (DGA) 的方式。我們對兩種重要技術執行詳細評估：語境學習 (ICL) 和監督微調 (SFT)，說明它們如何提升偵測能力。SFT 透過使用特定網域的資料來提升效能，而 ICL 則協助偵測模型快速適應新的威脅，而無需進行大量重新訓練。我們在自訂資料集上使用 Meta 的 Llama3 8B 模型，該資料集包含 68 個惡意軟體家族和正常網域，涵蓋多種難以偵測的方案，包括最近的基於字詞的 DGA。結果證明，基於 LLM 的方法可以在 DGA 偵測中取得具競爭力的結果。特別是，基於 SFT 的 LLM DGA 偵測器優於使用注意力層的現有技術，在 4% 的偽陽性率 (FPR) 下達到 94% 的準確度，並且擅長偵測基於字詞的 DGA 網域。

##### **VERITAS: A Unified Approach to Reliability Evaluation**
2411.03300v1 by Rajkumar Ramamurthy, Meghana Arakkal Rajeev, Oliver Molenschot, James Zou, Nazneen Rajani

Large language models (LLMs) often fail to synthesize information from their
context to generate an accurate response. This renders them unreliable in
knowledge intensive settings where reliability of the output is key. A critical
component for reliable LLMs is the integration of a robust fact-checking system
that can detect hallucinations across various formats. While several
open-access fact-checking models are available, their functionality is often
limited to specific tasks, such as grounded question-answering or entailment
verification, and they perform less effectively in conversational settings. On
the other hand, closed-access models like GPT-4 and Claude offer greater
flexibility across different contexts, including grounded dialogue
verification, but are hindered by high costs and latency. In this work, we
introduce VERITAS, a family of hallucination detection models designed to
operate flexibly across diverse contexts while minimizing latency and costs.
VERITAS achieves state-of-the-art results considering average performance on
all major hallucination detection benchmarks, with $10\%$ increase in average
performance when compared to similar-sized models and get close to the
performance of GPT4 turbo with LLM-as-a-judge setting.

摘要：大型語言模型 (LLM) 常常無法從其背景中綜合資訊來產生準確的回應。這使得它們在知識密集型環境中不可靠，而輸出可靠性是關鍵。可靠 LLM 的一個關鍵組成部分是整合一個強大的事實查核系統，它可以跨各種格式檢測幻覺。雖然有幾個開放獲取的事實查核模型可用，但它們的功能通常僅限於特定任務，例如有根據的問題解答或蘊涵驗證，並且它們在對話環境中的表現較差。另一方面，像 GPT-4 和 Claude 這樣的封閉訪問模型在不同背景下提供了更大的靈活性，包括有根據的對話驗證，但受到高成本和延遲的阻礙。在這項工作中，我們介紹了 VERITAS，這是一個幻覺檢測模型系列，旨在靈活地在不同背景下運作，同時最大限度地減少延遲和成本。VERITAS 在所有主要幻覺檢測基準上考慮平均性能而獲得最先進的結果，與類似大小的模型相比，平均性能提高了 10%，並且接近在 LLM 作為評審設定下使用 GPT4 turbo 的性能。

##### **Interaction2Code: How Far Are We From Automatic Interactive Webpage Generation?**
2411.03292v1 by Jingyu Xiao, Yuxuan Wan, Yintong Huo, Zhiyao Xu, Michael R. Lyu

Converting webpage design into functional UI code is a critical step for
building websites, which can be labor-intensive and time-consuming. To automate
this design-to-code transformation process, various automated methods using
learning-based networks and multi-modal large language models (MLLMs) have been
proposed. However, these studies were merely evaluated on a narrow range of
static web pages and ignored dynamic interaction elements, making them less
practical for real-world website deployment.
  To fill in the blank, we present the first systematic investigation of MLLMs
in generating interactive webpages. Specifically, we first formulate the
Interaction-to-Code task and build the Interaction2Code benchmark that contains
97 unique web pages and 213 distinct interactions, spanning 15 webpage types
and 30 interaction categories. We then conduct comprehensive experiments on
three state-of-the-art (SOTA) MLLMs using both automatic metrics and human
evaluations, thereby summarizing six findings accordingly. Our experimental
results highlight the limitations of MLLMs in generating fine-grained
interactive features and managing interactions with complex transformations and
subtle visual modifications. We further analyze failure cases and their
underlying causes, identifying 10 common failure types and assessing their
severity. Additionally, our findings reveal three critical influencing factors,
i.e., prompts, visual saliency, and textual descriptions, that can enhance the
interaction generation performance of MLLMs. Based on these findings, we elicit
implications for researchers and developers, providing a foundation for future
advancements in this field. Datasets and source code are available at
https://github.com/WebPAI/Interaction2Code.

摘要：<paragraph>將網頁設計轉換為功能性 UI 程式碼是建置網站的關鍵步驟，這可能是需要大量人力且耗時的。為了自動化此設計到程式碼的轉換程序，已提出各種使用基於學習的網路和多模態大型語言模型 (MLLM) 的自動化方法。然而，這些研究僅針對範圍狹窄的靜態網頁進行評估，並忽略動態互動元素，這使得它們對於實際世界的網站部署而言較不實用。
為了填補空白，我們提出第一個系統性地調查 MLLM 在產生互動式網頁中的研究。具體來說，我們首先制定互動到程式碼任務，並建置包含 97 個獨特網頁和 213 個不同互動的 Interaction2Code 基準，涵蓋 15 個網頁類型和 30 個互動類別。然後，我們使用自動化指標和人工評估對三個最先進 (SOTA) 的 MLLM 進行全面實驗，並據此總結六項發現。我們的實驗結果突顯出 MLLM 在產生細緻的互動式功能以及管理與複雜轉換和微妙視覺修改的互動方面的限制。我們進一步分析失敗案例及其根本原因，找出 10 種常見的失敗類型並評估其嚴重性。此外，我們的發現揭示了三個關鍵的影響因素，即提示、視覺顯著性和文字描述，它們可以增強 MLLM 的互動產生效能。根據這些發現，我們引出對研究人員和開發人員的啟示，為此領域的未來進展奠定基礎。資料集和原始程式碼可在 https://github.com/WebPAI/Interaction2Code 取得。</paragraph>

##### **The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare**
2411.03287v1 by Souren Pashangpour, Goldie Nejat

The potential use of large language models (LLMs) in healthcare robotics can
help address the significant demand put on healthcare systems around the world
with respect to an aging demographic and a shortage of healthcare
professionals. Even though LLMs have already been integrated into medicine to
assist both clinicians and patients, the integration of LLMs within healthcare
robots has not yet been explored for clinical settings. In this perspective
paper, we investigate the groundbreaking developments in robotics and LLMs to
uniquely identify the needed system requirements for designing health specific
LLM based robots in terms of multi modal communication through human robot
interactions (HRIs), semantic reasoning, and task planning. Furthermore, we
discuss the ethical issues, open challenges, and potential future research
directions for this emerging innovative field.

摘要：大型語言模型 (LLM) 在醫療保健機器人中潛在的應用，有助於滿足全球醫療保健系統對應老齡化人口和醫療保健專業人員短缺問題的重大需求。儘管 LLM 已整合到醫療領域中，以協助臨床醫生和患者，但 LLM 在醫療保健機器人中的整合尚未針對臨床環境進行探討。在此觀點論文中，我們探討機器人和 LLM 的創新發展，以獨特地找出設計特定於健康的 LLM 機器人的系統需求，包括透過人機互動 (HRI)、語義推理和任務規劃的多模式溝通。此外，我們討論了這個新興創新領域的倫理議題、開放性挑戰和潛在的未來研究方向。

##### **SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents**
2411.03284v1 by Dawei Li, Zhen Tan, Peijia Qian, Yifan Li, Kumar Satvik Chaudhary, Lijie Hu, Jiayi Shen

While multi-agent systems have been shown to significantly enhance the
performance of Large Language Models (LLMs) across various tasks and
applications, the dense interaction between scaling agents potentially hampers
their efficiency and diversity. To address these challenges, we draw
inspiration from the sparse mixture-of-agents (SMoE) and propose a sparse
mixture-of-agents (SMoA) framework to improve the efficiency and diversity of
multi-agent LLMs. Unlike completely connected structures, SMoA introduces novel
Response Selection and Early Stopping mechanisms to sparsify information flows
among individual LLM agents, striking a balance between performance and
efficiency. Additionally, inspired by the expert diversity principle in SMoE
frameworks for workload balance between experts, we assign distinct role
descriptions to each LLM agent, fostering diverse and divergent thinking.
Extensive experiments on reasoning, alignment, and fairness benchmarks
demonstrate that SMoA achieves performance comparable to traditional
mixture-of-agents approaches but with significantly lower computational costs.
Further analysis reveals that SMoA is more stable, has a greater capacity to
scale, and offers considerable potential through hyper-parameter optimization.
Code and data will be available at: https://github.com/David-Li0406/SMoA.

摘要：儘管多智能體系統已被證明能顯著提升大型語言模型 (LLM) 在各種任務和應用中的效能，但擴充智能體之間的密集互動潛在會阻礙其效率和多樣性。為了應對這些挑戰，我們從稀疏混合智能體 (SMoE) 汲取靈感，並提出一個稀疏混合智能體 (SMoA) 架構來提升多智能體 LLM 的效率和多樣性。與完全連接的結構不同，SMoA 引進了新穎的回應選擇和提前停止機制，以稀疏化個別 LLM 智能體之間的資訊流，在效能和效率之間取得平衡。此外，在 SMoE 架構中受到專家多樣性原則的啟發，以平衡專家之間的工作負載，我們為每個 LLM 智能體分配了不同的角色描述，以促進多樣化和發散性思考。在推理、對齊和公平基準上的廣泛實驗證明，SMoA 達到了與傳統混合智能體方法相當的效能，但計算成本卻顯著降低。進一步的分析顯示，SMoA 更加穩定，具有更大的擴充能力，並透過超參數最佳化提供了可觀的潛力。程式碼和資料將於以下網址提供：https://github.com/David-Li0406/SMoA。

##### **Causal Responsibility Attribution for Human-AI Collaboration**
2411.03275v1 by Yahang Qi, Bernhard Schölkopf, Zhijing Jin

As Artificial Intelligence (AI) systems increasingly influence
decision-making across various fields, the need to attribute responsibility for
undesirable outcomes has become essential, though complicated by the complex
interplay between humans and AI. Existing attribution methods based on actual
causality and Shapley values tend to disproportionately blame agents who
contribute more to an outcome and rely on real-world measures of
blameworthiness that may misalign with responsible AI standards. This paper
presents a causal framework using Structural Causal Models (SCMs) to
systematically attribute responsibility in human-AI systems, measuring overall
blameworthiness while employing counterfactual reasoning to account for agents'
expected epistemic levels. Two case studies illustrate the framework's
adaptability in diverse human-AI collaboration scenarios.

摘要：隨著人工智慧 (AI) 系統越來越影響各個領域的決策制定，為不良後果歸屬責任的需求已變得至關重要，儘管人類與 AI 之間的複雜交互作用讓這件事變得複雜。現有的歸因方法基於實際因果關係和 Shapley 值，往往會對對結果貢獻較多的代理人過度歸咎，並依賴於可能與負責任的 AI 標準不符的現實世界責難程度衡量。本文提出一個使用結構因果模型 (SCM) 的因果框架，以系統性地將責任歸因於人類 AI 系統，衡量整體責難程度，同時採用反事實推理來考量代理人的預期認識層級。兩個案例研究說明了該框架在不同人類 AI 協作情境中的適應性。

