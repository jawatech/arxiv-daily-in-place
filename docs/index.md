# arxiv-daily
 Automated deployment @ 2024-11-01 09:11:32 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|null|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. GarcÃ­a-GÃ³mez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|

#### Abstracts
##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

æè¦ï¼æ¬ç¯è©è«æ¢è¨äºæ·±åº¦å­¸ç¿æ¹æ³å¨éä¾µå¥å¼èªç¥åè½éç¤æª¢æ¸¬ä¸çææ°é²å±ãæåæª¢è¦äºåç¨®éä¾µå¥å¼çèªç¥è¡°éææ¨ï¼åæ¬èªè¨åèªè¨ãé¢é¨åéåæ©è½ãæ¬ææ¦è¿°äºèæ­¤é åç¸éçè³æéãç¹å¾µæåæè¡åæ·±åº¦å­¸ç¿æ¶æ§ãæååæäºä¸åæ¹æ³å¨ä¸åæ¹å¼ä¸çè¡¨ç¾ï¼ä¸¦è§å¯å°åºæ¼èªè¨åèªè¨çæ¹æ³éå¸¸è½éå°æé«çæª¢æ¸¬è¡¨ç¾ãçµåè²å­¸åèªè¨ç¹å¾µçç ç©¶å¾å¾åªæ¼ä½¿ç¨å®ä¸æ¹å¼çç ç©¶ãé¢é¨åææ¹æ³é¡¯ç¤ºåºè¦è¦ºæ¹å¼çæ½åï¼ä½ç ç©¶è¼å°ãå¤§å¤æ¸è«æå°æ³¨æ¼äºååé¡ï¼åæèæªåæï¼ï¼è¼å°æ¢è¨å¤é¡æåæ­¸ä»»åãé·ç§»å­¸ç¿åé è¨ç·´èªè¨æ¨¡åå·²æçºæµè¡ä¸ææçæè¡ï¼ç¹å¥æ¯å°æ¼èªè¨åæãåç®¡åå¾äºéå¤§é²å±ï¼ä½ä»å­å¨ä¸äºææ°ï¼åæ¬è³ææ¨æºååå¯åæ§ãæ¨¡åå¯è§£éæ§ãç¸±ååæéå¶åè¨åºé©ææ§ãæå¾ï¼æåæåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦èª¿æ¥èèªè¨ç¡éçèªé³åææ¹æ³ãéç¼å¤æ¨¡å¼è¨ºæ·ç³»çµ±ï¼ä»¥åè§£æ±ºäººå·¥æºæ§è¼å©é«çä¿å¥ä¸­çå«çèéãééç¶åç®åçè¶¨å¢åæ¾åºééµéç¤ï¼æ¬ç¯è©è«æ¨å¨å¼å°æ·±åº¦å­¸ç¿çºåºç¤çèªç¥åè½éç¤æª¢æ¸¬ç³»çµ±çé²ä¸æ­¥ç¼å±ï¼ä»¥æ¹åæ©æè¨ºæ·ï¼ä¸¦æçµæ¹åæ£èçæ²»ççµæã

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

æè¦ï¼å¯è§£éäººå·¥æºæ§ï¼AIï¼å°æ³¨æ¼åå©äººé¡äºè§£ AI ç³»çµ±éä½æå¶æ±ºç­ï¼æ¸åå¹´ä¾ä¸ç´æ¯ AI çåºç³ãæè¿çå¯è§£éæ§ç ç©¶å°æ³¨æ¼è§£é AI æ¨¡åææ¨¡åå¯è§£éæ§çéä½ãä¹æå¹¾ä»½ç«å ´è²æåè©è«è«æè©³ç´°èªªæäºæçµä½¿ç¨èå°ä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§çéæ±ï¼ä½å¯¦ä½è¼å°ãå æ­¤ï¼æ¬è«ææ¨å¨å½è£æ¨¡ååä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§ä¹éçä¸äºå·®è·ãæåå»ºç«ä¸åè§£éæ¬é«ï¼EOï¼ä»¥ééå¶æ¯æ´åä»¶ä¾è¡¨ç¤ºå¾æç»ä¸­è¡ççè§£éé¡åãæåå¯¦ä½ä¸åç¥è­å¢å¼·çåç­ï¼QAï¼ç®¡ç·ï¼ä»¥å¨è¨åºç°å¢ä¸­æ¯æ´æå¢è§£éãæå¾ï¼æåæ­£å¨å¯¦ä½ä¸åç³»çµ±ï¼ä»¥çµåä¾èªä¸å AI æ¹æ³åè³ææ¨¡å¼çè§£éãå¨ EO ä¸­ï¼æåå¯ä»¥è¡¨ç¤º 15 ç¨®ä¸åçè§£éé¡åï¼ä¸¦ä¸æåå·²å¨å­åç¯ä¾ä½¿ç¨æ¡ä¾ä¸­æ¸¬è©¦éäºè¡¨ç¤ºãæåç¼ç¾ï¼ç¥è­å¢å¼·æ¹åäºåºç¤å¤§åèªè¨æ¨¡åå¨æå¢å QA ä¸­çæè½ï¼ä¸¦ä¸æè½å ç¾çç¾¤çµèç°ãå¨ç¸åçç°å¢ä¸­ï¼è¨åºé«çä¹è¡¨ç¤ºä»åå¸æå°å¯æä½æ§è¦çºè§£éä¸­çä¸»è¦ç¦é»ä¹ä¸ãå¨æåçè§£éçµåæ¹æ³ä¸­ï¼æåè¨ç«ä½¿ç¨ç¸ä¼¼æ§ææ¨ä¾ç¢ºå®æ¢æ§çåµæ¸¬ç°å¢ä¸­è§£éçç¸ä¼¼æ§ãç¸½é«èè¨ï¼ééæ¬è«æï¼æåè¨­è¨äºå¯ä»¥å¨ä¸åä½¿ç¨æ¡ä¾ä¸­æ¯æ´ç¥è­åç¨è§£éçæ¹æ³ï¼èéå°ç¶ä» AI æä»£ä¸­å¯ä»¥ç¢çéäºè§£éçæ¯æ´åä»¶åå¯ä»¥å¢å¼·éäºè§£éçé åç¥è­ä¾æºçæ¹æ³ã

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

æè¦ï¼<paragraph>ç®çï¼èª¿æ¥è¨åºé«çå°ç®åèªååå¿é»åè§£è®åæ°çäººå·¥æºæ§æè¡çæåº¦ï¼ä»¥åä»åå°é»è¦è¼å©è§£è®ççæ³ãææåæ¹æ³ï¼æåå°è±åçè¨åºé«çé²è¡äºä¸ç³»åè¨ªè«ãæåçç ç©¶ï¼(i) æ¢è¨äººå·¥æºæ§çæ½åï¼ç¹å¥æ¯æªä¾çãé¡äººé¡ãéç®æ¹æ³ï¼ä»¥ä¿é²å¿é»åè§£è®ä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼ä»¥å (ii) å¾µæ±ä»åå°äººå·¥æºæ§æ¼ç®æ³çå¯è§£éæ§åå¯ä¿¡åº¦ççæ³ãçµæï¼æåå° 23 ä½è¨åºé«ççè¨ªè«è¨éé²è¡äºæ­¸ç´ä¸»é¡åæï¼ä¸¦æ¾åºä»¥ä¸ä¸»é¡ï¼(i) å°ç®åç³»çµ±ç¼ºä¹ä¿¡ä»»ï¼(ii) å°æªä¾äººå·¥æºæ§æç¨åå°éäºæç¨çè¦æ±ææ­£é¢æåº¦ï¼(iii) æ¼ç®æ³çæºç¢ºæ§åå¯è§£éæ§ä¹éçéä¿ï¼ä»¥å (iv) å°æè²ãå¯è½çæè½éåï¼ä»¥åäººå·¥æºæ§å°è¨åºè½åçå½±é¿ççæ³ãè¨è«ï¼è¨åºé«çä¸ä¿¡ä»»ç®åçé»è¦åæ¹æ³ï¼ä½æ­¡è¿æªä¾çãäººå·¥æºæ§ãæè¡ãå¨è¨åºé«çç¸ä¿¡æªä¾ç AI è§£è®æºç¢ºçææ³ä¸ï¼ä»åä¸å¤ªæå¿å®æ¯å¦å¯è§£éãä»åä¹æ¯è¼åæ­¡è½ä»¥è¦è¦ºæ¹å¼åç¾æ¼ç®æ³çµæçå¿é»åè§£è®ãéç¶è¨åºé«çä¸å®³æå¤±æ¥­ï¼ä½ä»åæå¿æè½éåï¼ä»¥åéè¦æè²å¡å·¥è² è²¬ä»»å°ä½¿ç¨äººå·¥æºæ§ãçµè«ï¼è¨åºé«çå°äººå·¥æºæ§å¨è¨åºæ±ºç­å¶å®ä¸­çæªä¾æç¨ææ­£é¢æåº¦ãæºç¢ºæ§æ¯æ¡ç¨äººå·¥æºæ§çä¸åééµå ç´ ï¼èè¦è¦ºåæ¯ç®åçé»è¦åæ¹æ³æ´åéçãéè¢«è¦çºä¸ç¨®æ½å¨çå¹è¨åæåæè½çæ¹æ³ï¼èèªååå¯è½å¸¶ä¾çæè½éåå½¢æå°æ¯ã</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah HaggenmÃ¼ller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria CompÃ©rat, Andreas Gocht, Monika HÃ¤mmerle, Niels J. Rupp, Jula Westhoff, Irene KrÃ¼cken, Maximillian Seidl, Christian M. SchÃ¼rch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian HÃ¶rner, Kirsten D. Mertz, Constanze DÃ¶ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

æè¦ï¼ååèºçæ¯å¨çç·æ§æå¸¸è¦çççï¼å¶æ¡æ§ç¨åº¦ä¸»è¦æ ¹æ Gleason è©åç³»çµ±ä½¿ç¨çµç¹ççå­¸æ¸æé²è¡è©ä¼°ãéç¶äººå·¥æºæ§ (AI) å¨æºç¢ºé æ¸¬ Gleason è©åæ¹é¢å·²å±ç¾æ½åï¼ä½éäºé æ¸¬éå¸¸ç¼ºä¹å§å¨çå¯è§£éæ§ï¼å¯è½æå°è´å°äººæ©äºåçä¸ä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äºä¸åç± 54 ä½ççå­¸å®¶çµæçåéåéè¨»è§£ç 1,015 åçµç¹å¾®é£åæ ¸å¿å½±åçæ°ç©è³æéãéäºè¨»è§£æä¾äºè©³ç´°çå±é¨æ¨¡å¼æè¿°ï¼ç¨æ¼ç¬¦ååéæºåç Gleason åç´ãå©ç¨éåè³æéï¼æåéç¼äºä¸ååºæ¼ U-Net æ¶æ§çå§å¨å¯è§£é AI ç³»çµ±ï¼è©²ç³»çµ±æä¾äºå©ç¨ççå­¸å®¶è¡èªé²è¡é æ¸¬ãéç¨®æ¹æ³è¦é¿äºäºå¾å¯è§£éæ§æ¹æ³ï¼åæç¶­ææè¶è¶äºç´æ¥è¨ç·´ç¨æ¼ Gleason æ¨¡å¼åå²çæ¹æ³çæè½ï¼Dice åæ¸ï¼0.713 Â± 0.003ï¼è¨ç·´æ¼è§£éï¼ç¸å°æ¼ 0.691 Â± 0.010ï¼è¨ç·´æ¼ Gleason æ¨¡å¼ï¼ãééå¨è¨ç·´æéæ¡ç¨è»æ¨ç±¤ï¼æåææäºè³æä¸­çå§å¨ä¸ç¢ºå®æ§ï¼å³ä½¿å¨è§å¯èéè®ç°æ§é«çææ³ä¸ï¼ä¹è½å¨ Gleason æ¨¡å¼åå²ä¸­ç¢çå¼·å¤§ççµæãéééåºéåè³æéï¼æåæ¨å¨é¼åµé²ä¸æ­¥ç ç©¶ä¸»è§æ§é«çé«çä»»åä¸­çåå²ï¼ä¸¦å¢é²å°ççå­¸å®¶æ¨çéç¨ççè§£ã

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

æè¦ï¼é«ééæè¡çé²æ­¥å°è´å¾å³çµ±çåè¨­é©åæ¹æ³è½è®çºè³æé©åçæ¹æ³ãå¤çµå­¸æ¯ææ´ååæä¾èªå¤åãçµå­¸ãçè³æï¼ä¾å¦åºå çµå­¸ãèç½è³ªçµå­¸ãè½éçµå­¸ãä»£è¬çµå­¸åå¾®çç©çµå­¸ãæ­¤æ¹æ³ééæ·åçç©è³è¨çä¸åå±¤é¢ï¼è½å¨é¢äºè§£çç©ç³»çµ±ãæ·±åº¦å­¸ç¿æ¹æ³æä¾æå¸¸è¢«ç¨æ¼æ´åå¤çµå­¸è³æï¼æä¾åå­äº¤äºä½ç¨çæ´å¯åï¼ä¸¦å å¼·å°è¤éç¾ççç ç©¶ãç¶èï¼éäºæ¨¡åå·æè¨±å¤ç¸äºé£æ¥çå±¤ç´åéç·æ§éä¿ï¼éå¸¸æåé»çå­ä¸æ¨£éä½ï¼ç¼ºä¹æ±ºç­éç¨çéæåº¦ãçºäºåææ­¤ææ°ï¼å¯è§£éäººå·¥æºæ§ (xAI) æ¹æ³å°æ¼å»ºç«éææ¨¡åè³ééè¦ï¼è®è¨åºé«çå¯ä»¥æ´ææå°è§£éåèçè¤éè³æãæ­¤è©è«æ¢è¨ xAI å¦ä½è½æ¹åå¤çµå­¸ç ç©¶ä¸­æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§ï¼å¼·èª¿å¶æä¾è¨åºé«çæç¢ºè¦è§£çæ½åï¼é²èä¿é²æ­¤é¡æ¨¡åå¨è¨åºç°å¢ä¸­çæææç¨ã

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian GeiÃler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°æ¼å»ºæ§åé²çæ©å¨å­¸ç¿é©åæç¨ç¨å¼è³ééè¦ï¼ç¹å¥æ¯å¨é«çè¨ºæ·æèªåé§é§ç­ééµé åãæ³å¾ãåæ¥­åå«çè¦æ±ä¿ä½¿ä½¿ç¨ææç XAIï¼ä½æ¸éæ¥çå¢å çä¸åæ¹æ³ä½¿å¾æé¸æ­£ç¢ºçæ¹æ³å·æææ°æ§ãæ­¤å¤ï¼ç±æ¼è§£éé«åº¦ä¾è³´æ¼èæ¯ï¼å¨æ²æä½¿ç¨èçææ³ä¸è¡¡é XAI æ¹æ³çæææ§åªè½æ­ç¤ºæéçè³è¨ï¼æé¤äººé¡å ç´ ï¼ä¾å¦çè§£å®çè½åãæåå»ºè­°ééä½¿ç¨èæåå·è¡ä»£çä»»åçè½åä¾è©ä¼° XAI æ¹æ³ï¼è¨­è¨ä½¿å¾è¯å¥½çå·è¡è¡¨ç¾æ¯è§£éæä¾æç¨è³è¨çææ¨ãæå¥è©±èªªï¼æåæ¢è¨ XAI å°äººé¡æ±ºç­å¶å®çå¹«å©ãæ­¤å¤ï¼å°æåé²çæ¹æ³é²è¡ä½¿ç¨èç ç©¶ï¼é¡¯ç¤ºåºå®åå¨ç¢çä¿¡ä»»åæ·ççè½åä»¥åæ­£ç¢ºå¤æ· AI æ±ºç­æ¯å¦æ­£ç¢ºçè½åæ¹é¢å­å¨å·®ç°ãæ ¹æçµæï¼æåå¼·çå»ºè­°ä½¿ç¨åæ´åéç¨®æ¹æ³ï¼ä»¥é²è¡æ´å¤ä»¥ç®æ¨çºåºç¤çäººçºä¸­å¿ä½¿ç¨èç ç©¶ï¼ä»¥çµç«¯å°çµç«¯çæ¹å¼è¡¡é XAI æè½ã

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

æè¦ï¼ç¢ç¨ä¸­é¢¨éªçæ©æåµæ¸¬æå©æ¼é²è¡å¹²é æªæ½ï¼ä»¥é é²ææ¸è¼ä¸å©ççç¢çµæï¼ä¾å¦è¦æ§éº»çºãç®åï¼æ²ææºç¢ºçèªååç³»çµ±å¯ä»¥é æ¸¬æ­¤é¡äºä»¶ï¼ä»¥åå©è¨åºæ±ºç­ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºãç¨æ¼å»ºæ¨¡åè§£éæ°çåå¥åº·çäººå·¥æºæ§ã(AIMEN)ï¼éæ¯ä¸åæ·±åº¦å­¸ç¿æ¶æ§ï¼å®ä¸åå¯ä»¥æ ¹æå­ç¢å©¦ãèåãç¢ç§åç¢ç¨é¢¨éªå ç´ é æ¸¬ä¸å©ççç¢çµæï¼éè½æä¾æ¨¡åååºé æ¸¬èå¾çåå ãå¾èå¯ä»¥æä¾è¦è§£ï¼èªªææ¨¡åè¼¸å¥è®æ¸ä¸­çåªäºä¿®æ¹å¯è½ææ¹è®é æ¸¬çµæãæåééä½¿ç¨é©ææ§åææ½æ¨£ (ADASYN) åæ¢ä»¶è¡¨æ ¼çæå°æç¶²è·¯ (CTGAN) ä¾åæé¡å¤çè¨ç·´è³æï¼ä»¥è§£æ±ºä¸å¹³è¡¡åå°åè³æéçææ°ãAIMEN ä½¿ç¨å¨é£æ¥ç¥ç¶ç¶²è·¯çéåä½çºå¶åé¡çéª¨å¹¹ï¼ä¸¦éé ADASYN æ CTGAN æ¯æ´è³ææ´åãç± CTGAN æ¯æ´ç AIMEN å¨åé¡æ¹é¢åªæ¼ç± ADASYN æ¯æ´ç AIMENãAIMEN å¯ä»¥é æ¸¬ä¸å©ççç¢çµæçé«é¢¨éªï¼å¹³å F1 åæ¸çº 0.784ãå®éæä¾åäºå¯¦è§£éï¼å¯ééå¹³åè®æ´ 2 è³ 3 åå±¬æ§ä¾éæãå¯ç¨è³æºï¼https://github.com/ab9mamun/AIMENã

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

æè¦ï¼éºå³æ§è¦ç¶²èç¾ç (IRD) æ¯ä¸çµå¤æ¨£åçéºå³ç¾çï¼
æå°è´è¦åéæ¼¸åªå¤±ï¼æ¯å·¥ä½å¹´é½¡æäººå¤±æçä¸»è¦åå ãIRD çè¤éæ§åç°è³ªæ§å°è¨ºæ·ãé å¾åç®¡çæåºäºéå¤§ææ°ãæè¿äººå·¥æºè½ (AI) çé²æ­¥çºéäºææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ã
ç¶èï¼AI æè¡çå¿«éç¼å±åå¶å¤ç¨®æç¨å°è´äºè©²é åçç¥è­åæ£ãæ¬ç¶è¿°æ´åäºç¾æç ç©¶ï¼æ¾åºå·®è·ï¼ä¸¦æ¦è¿°äº AI å¨è¨ºæ·åç®¡ç IRD ä¸­çæ½åãå®æ¨å¨ééæ¢ç´¢æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿ç­ AI æè¡ï¼ç¹å¥æ¯å¨ç¾çæª¢æ¸¬ãé²ç¨é æ¸¬ååæ§åæ²»çè¨åä¸­ï¼çºæ¨é²è¨åºæç¨æ§å»ºéå¾ãç¹å¥éæ³¨éäºé åä¸­å·ç©ç¥ç¶ç¶²è·¯çæææ§ãæ­¤å¤ï¼è¨è«äºå¯è§£é AI çæ´åï¼å¼·èª¿äºå¶å¨è¨åºç°å¢ä¸­æé«éæåº¦åå°åºæ¼ AI çç³»çµ±çä¿¡ä»»çéè¦æ§ãè©²ç¶è¿°è§£æ±ºäºå½å AI å¨ IRD ä¸­ä½ç¨çéé»ç ç©¶ä¸­ç¾æå·®è·çå¿è¦æ§ï¼æä¾äºå°ç¶å AI æè¡ççµæ§ååæï¼ä¸¦æ¦è¿°äºæªä¾çç ç©¶æ¹åãæå¾æ¦è¿°äºå¨ IRD ä¸­é¨ç½² AI çææ°åæ©éï¼å¼·èª¿äºè·¨å­¸ç§åä½åæçºéç¼å¼·å¤§ãå¯è§£éç AI æ¨¡åä»¥æ¨é²è¨åºæç¨çå¿è¦æ§ã

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çä¸é ééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æå°æ£èççµæç¢çéå¤§å½±é¿ãå³çµ±æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨æ­¤é ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éæ¯è¨åºç°å¢ä¸­çééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼å¯è§£éçè¨ºæ·é æ¸¬æ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼è©²æ¨¡åéééè¼¯è¦ååå¯å­¸ç¿çé¾å¼æ´åé åç¹å®çç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåè¶æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­ï¼éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸æå®³é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼ç²¾æºé«ççé²æ­¥ï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

æè¦ï¼äººå·¥æºæ§ (AI) ç³»çµ±å·²å¤§å¹æ¹åç®èç§é«å¸«å°é»è²ç´ ç¤çè¨ºæ·æºç¢ºåº¦ï¼èå¯è§£é AI (XAI) ç³»çµ±é²ä¸æ­¥æåè¨åºé«å¸«å° AI é©åæ±ºç­çä¿¡å¿èä¿¡è³´ãåç®¡æéäºé²å±ï¼å°æ¼ç®èç§é«å¸«å¦ä½ä½¿ç¨ AI å XAI å·¥å·ï¼ä»æå®¢è§è©ä¼°çè¿«åéæ±ãå¨éé ç ç©¶ä¸­ï¼76 ä½ç®èç§é«å¸«åèäºä¸é è®èç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±è¨ºæ· 16 å¼µé»è²ç´ ç¤åç£çç®èé¡å½±åï¼è©²ç³»çµ±æä¾è©³ç´°çé åç¹å®èªªæãæ¡ç¨ç¼çè¿½è¹¤æè¡ä¾è©ä¼°ä»åçäºåãå°è¨ºæ·è¡¨ç¾èç¼ºä¹èªªæåè½çæ¨æº AI ç³»çµ±é²è¡æ¯è¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼XAI ç³»çµ±ç¸è¼æ¼æ¨æº AIï¼å°å¹³è¡¡è¨ºæ·æºç¢ºåº¦æåäº 2.8 åç¾åé»ãæ­¤å¤ï¼è AI/XAI ç³»çµ±çè¨ºæ·åæ­§åè¤éççç¶èèªç¥è² æåé«æéï¼éç±å¢å çç¼çæ³¨è¦æ¬¡æ¸æè­å¯¦ãéäºè¦è§£å°è¨åºå¯¦åãè¦è¦ºä»»å AI å·¥å·çè¨­è¨åé«å­¸è¨ºæ·ä¸­ XAI çå»£æ³ç¼å±å·æéå¤§æç¾©ã

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·åä»å¥å·²è¢«è­å¯¦è½é¡¯èæ¹åèªéçæ£èççæ´»åè³ªãç¶èï¼ASD çè¨ºæ·æ¹æ³ä¾è³´æ¼åºæ¼è¨åºè¡¨ç¾çè©ä¼°ï¼å®¹æç¢çåè¦ï¼ä¸å¯è½é£ä»¥ååºæ©æè¨ºæ·ãæå¿è¦æ¾åº ASD çå®¢è§çç©æ¨è¨ï¼ä»¥å¹«å©æé«è¨ºæ·æºç¢ºæ§ãæ·±åº¦å­¸ç¿ (DL) å¨å¾é«å­¸å½±åè³æè¨ºæ·ç¾çåççæ¹é¢åå¾ååºçè¡¨ç¾ãå·²ç¶éå°å»ºç«ä½¿ç¨éæåè½æ§ç£æ¯é å½± (fMRI) è³æå° ASD é²è¡åé¡çæ¨¡åé²è¡å»£æ³çç ç©¶ãç¶èï¼ç¾æçæ¨¡åç¼ºä¹å¯è§£éæ§ãæ¬ç ç©¶æ¨å¨ééå»ºç«ä¸åä¸åè½æºç¢ºåé¡ ASDï¼éè½æä¾å¯è§£éè¦è§£èªªæå¶éä½åçç DL æ¨¡åï¼ä¾æ¹å ASD è¨ºæ·çæºç¢ºæ§åå¯è§£éæ§ãæä½¿ç¨çè³æéæ¯èªéçå¤§è¦å½±åè³æäº¤æ (ABIDE) çé èççæ¬ï¼åå« 884 åæ¨£æ¬ãæåçç ç©¶çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æºç¢ºåé¡ ASDï¼ä¸¦å¼·èª¿ ASD èå¸åå°ç§çµä¹éå­å¨å·®ç°çééµè¦åï¼å°æ¼ ASD çæ©æè¨ºæ·åç¥ç¶åºç¤ççè§£å·ææ½å¨çæç¾©ãéäºç ç©¶çµæå·²ç±ä½¿ç¨ä¸åè³æéåæ¹å¼çæç»ç ç©¶é©è­ï¼è­å¯¦è©²æ¨¡åå¯¦éä¸å­¸ç¿äº ASD çç¹å¾µï¼èä¸ååæ¯è³æéãæ¬ç ç©¶ééæä¾ä¸åå¼·å¥ä¸å¯è§£éçæ¨¡åï¼æ¨åäºé«å­¸å½±åä¸­å¯è§£é AI çé åï¼å¾èçºæªä¾æä¾å®¢è§ä¸å¯é ç ASD è¨ºæ·ååºè²¢ç»ã

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, ClÃ©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

æè¦ï¼å°¿è·¯é¡æª¢æ¥ä¸­èçµç³é¡åçé«å§è­å¥å°æ¯æ³å°¿ç§çä¸é éå¤§é²å±ï¼å çºå®å¯ä»¥æ¸å°ç¹ç£çèçµç³ååºéç¨çæéï¼åæéä½ææé¢¨éªãæ­¤å¤ï¼éç¨®èªååç¨åºå°ä½¿ç«å³éç«æå¾©ç¼æ²»çæçºå¯è½ãå¦ä»ï¼åªæå°æ¸ç¶é©è±å¯çæ³å°¿ç§é«çè½å¤ å¨å§è¦é¡æª¢æ¥æéå±å¹ä¸é¡¯ç¤ºçè¦é »ååä¸­è­å¥èçµç³é¡åãå æ­¤ï¼æè¿å·²æåºå¤ç¨®æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ä»¥ä½¿ç¨è¼¸å°¿ç®¡é¡ååèªåè­å¥èçµç³é¡åãç¶èï¼éäº DL æ¨¡åæ¬è³ªä¸æ¯é»çå­ï¼ééå¶äºå®åå¨è¨åºç°å¢ä¸­çæç¨æ§ãæ¬ææåºäºä¸ååºæ¼æ¡ä¾æ¨çç DL æ¨¡åï¼å®ä½¿ç¨ååé¨å (PP) ä¸¦çæå±é¨åå¨å±æè¿°ç¬¦ãPP çºæ¯ç¨®é¡åï¼å³èçµç³é¡åï¼ç·¨ç¢¼è¦è¦ºç¹å¾µä¿¡æ¯ï¼è²èª¿ãé£½ååº¦ãå¼·åº¦åç´çï¼ï¼é¡ä¼¼æ¼çç©å­¸å®¶ä½¿ç¨çä¿¡æ¯ãç±æ¼å¨æ¨¡åè¨ç·´æéä½¿ç¨çæ°æå¤±å½æ¸ï¼PP å¾å°äºæä½³çæãæ­¤å¤ï¼PP çå±é¨åå¨å±æè¿°ç¬¦åè¨±ä»¥çç©å­¸å®¶åæ³å°¿ç§é«çå¯ä»¥çè§£çæ¹å¼è§£éæ±ºç­ï¼âä»éº¼âä¿¡æ¯ï¼âååä¸­çä»éº¼ä½ç½®âï¼ãææåºç DL æ¨¡åå·²å¨ä¸ååå«å­ç¨®æå»£æ³çèçµç³é¡åååçæ¸æåº«ä¸é²è¡äºæ¸¬è©¦ãç¸½é«å¹³ååé¡æºç¢ºççº 90.37ãå°æ­¤çµæèèçµç³æåé²çå«åå¶ä» DL æ¨¡åççµæé²è¡æ¯è¼æï¼å¯ä»¥çåºï¼å¯è§£éæ§çå¯¶è²´å¢çä¸¦æªä»¥æºç¢ºæ§çºä»£å¹ï¼çè³ç¥æå¢å èæç»ä¸­æå¥½çæ¹æ³ (88.2) ç¸æ¯ãéäºæå¸æä¸å¯è§£éççµæä¹é¼åµæ³å°¿ç§é«çç¸ä¿¡åºæ¼äººå·¥æºè½çè§£æ±ºæ¹æ¡ã

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

æè¦ï¼æ¬ç ç©¶æ¢è¨å©ç¨è¡æ¿ç³å ±è³æï¼çµååé²æ©å¨å­¸ç¿èæ·±åº¦å­¸ç¿æè¡ï¼é æ¸¬æ¢æ§èèç (CKD) é²å±è³æ«æèèç¾ç (ESRD) çå¯è½æ§ãæååæä¸å®¶å¤§åå¥åº·ä¿éªçµç¹æä¾ç 10 å¹´ç¶åè³æéï¼ä½¿ç¨å³çµ±æ©å¨å­¸ç¿æ¹æ³ï¼ä¾å¦é¨æ©æ£®æå XGBoostï¼ä»¥åæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦é·æç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼éç¼å¤åè§å¯è¦çªçé æ¸¬æ¨¡åãæåçç ç©¶çµæé¡¯ç¤ºï¼LSTM æ¨¡åï¼å°¤å¶æ¯ 24 åæè§å¯è¦çªï¼å¨é æ¸¬ ESRD é²å±æ¹é¢è¡¨ç¾åªç°ï¼åªæ¼æç»ä¸­çç¾ææ¨¡åãæåé²ä¸æ­¥æç¨ SHapley å¯å æ§è§£é (SHAP) åæä»¥å¢å¼·å¯è§£éæ§ï¼æ·±å¥äºè§£åå¥ç¹å¾µå°åå¥æ£èå±¤ç´é æ¸¬çå½±é¿ãæ¬ç ç©¶å¼·èª¿äºå©ç¨è¡æ¿ç³å ±è³æé²è¡ CKD ç®¡çåé æ¸¬ ESRD é²å±çå¹å¼ã

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

æè¦ï¼é¨èè¶ä¾è¶è¤éä¸æºç¢ºçé æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§ (AI) è§£æ±ºæ¹æ¡çææ¡å¨è¨±å¤é åä¸­è®å¾ç¡èä¸å¨ãé¨èéäºæ¨¡åè¤éæ§çå¢å ï¼éæåº¦åä½¿ç¨èççè§£åå¾å¾æéä½ãéè¡¨ç¤ºåææºç¢ºçé æ¸¬ä¸¦ä¸è¶³ä»¥è® AI è§£æ±ºæ¹æ¡çæ­£æç¨ãå¨é«çä¿å¥ç³»çµ±çéç¼ä¸­ï¼éå¼å¥äºèåè²¬å¶åå®å¨æ§ç¸éçæ°åé¡ãç­è§£ AI ç³»çµ±å¦ä½ä»¥åçºä½æåºå»ºè­°å¯è½éè¦å°å¶å§é¨éä½åæ¨çéç¨é²è¡è¤éçèªªæãåç®¡è¿å¹´ä¾å°å¯è§£é AI (XAI) çç ç©¶å·²å¤§å¹å¢å ï¼ä¸é«å­¸é åå° XAI æå¾é«çéæ±ï¼ä½å®ç¾©ä»éº¼æ§æä¸åå¥½çè§£éä»æ¯è¨ææ§çï¼èæä¾é©ç¶çè§£éä»ç¶å·æææ°æ§ãçºäºååç¼æ® AI çæ½åï¼å°æ¼å®å¨ééµå AI æç¨ï¼ä¾å¦å¥åº· AIï¼çè§£éï¼æ¢è¨å©ååºæ¬åé¡è³ééè¦ï¼(1) ä»éº¼æ¯å¥åº· AI ä¸­çè§£éï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½çè§£éæåªäºå±¬æ§ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦äºå·²ç¼è¡¨çæç»ï¼ä¸¦ééå©è¼ªå¾·ç¾è²ç ç©¶æ¶éäºå°å®¶æè¦ãç ç©¶ææåæ¬ï¼(1) å¥åº· AI ä¸­ä»éº¼æ§æè§£éçå®ç¾©ï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½è§£éçå±¬æ§æ¸å®ã

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼å·²ç¶å¼é²åç¨®æ¹æ³ä¾è§£éãé»ç®±ãAI æ¨¡åçè¼¸åºãç¶èï¼ç®åä¸¦ä¸æ¸æ¥ä½¿ç¨èæ¯å¦å¯¦éçè§£åä¿¡ä»»éäºè§£éãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼è©ä¼°ççé¢¨éªçåæ­¸å·¥å·çè§£éï¼ä¸¦æ¢è¨è§£éçå§å®¹åæ ¼å¼å°ä»¥ä½¿ç¨èçºä¸­å¿ççè§£åä¿¡ä»»ææ¨çå½±é¿ãéæ¼å§å®¹ï¼æåå¯¦é©äºå©ç¨®è§£éæ¹æ³ï¼æµè¡ç SHAPï¼åºæ¼åå¼è«æ¦å¿µï¼å æ­¤å°æ¼æ¥å¸¸ä½¿ç¨èä¾èªªå¯è½å¾è¤éï¼ä»¥ååºæ¼ç¹å¾µé®è½ç occlusion-1ï¼å¯è½æ´ææ¼çè§£ãéæ¼æ ¼å¼ï¼æåå° SHAP è§£éåç¾çºåè¡¨ (SC)ï¼éæ¯æ£ä¾ï¼èå° occlusion-1 è§£éåç¾çºåè¡¨ (OC) ä»¥åæå­ (OT)ï¼å¶è¼çºç°¡å®çæ§è³ªä¹é©ç¨æ¼æ­¤ãéäºå¯¦é©ç­åæ¼ä½¿ç¨èç ç©¶ï¼è©¢ååèèï¼å·æå©ç¨®ä¸åç¨åº¦çå°æ¥­ç¥è­ï¼ä¸è¬æ°ç¾åå·åä¸äºé«å­¸è¨ç·´çäººï¼ï¼ä»åå°åæ­¸å·¥å·è¼¸åºè§£éçä¸»è§åå®¢è§çè§£åä¿¡ä»»ãå¨å©é ç ç©¶ä¸­ï¼æåç¼ç¾ï¼å¨åºæ¼å§å®¹é²è¡æ¯è¼æï¼ä¸è¬ä¾èªªï¼occlusion-1 åªæ¼ SHAP è§£éï¼å¨ä¸»è§çè§£åä¿¡ä»»æ¹é¢ææé¡¯çåå¥½ãç¶èï¼å¨åæ§å¶æ ¼å¼çææ³ä¸ç´æ¥æ¯è¼è§£éï¼å¨å¤§å¤æ¸ææ³ä¸åªé¡¯ç¤º OT åªæ¼ SC è§£éçè­æï¼éè¡¨æ occlusion-1 åªæ¼ SHAP è§£éçä¸»å°å°ä½å¯è½æ¯ç±åå¥½æå­èéåè¡¨ä½çºè§£éæé©åçãæå¾ï¼æåæ²æç¼ç¾è§£éé¡åå¨å®¢è§çè§£æ¹é¢çå·®ç°è­æãå æ­¤ï¼ç¸½é«èè¨ï¼å°è§£éçå§å®¹åæ ¼å¼çé¸æéè¦ä»ç´°æ³¨æï¼å çºå¨æäºææ³ä¸ï¼æ ¼å¼èéå§å®¹ï¼å¯è½å¨æ¹åä½¿ç¨èé«é©æ¹é¢ç¼æ®ééµä½ç¨ã</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro LiÃ², Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´æä¾äºåææªæçèªç¶èªè¨çè§£åçæè½åãç¶èï¼ç¾æéæ¼çç©é«å­¸ä¸­ LLM çèª¿æ¥éå¸¸å°æ³¨æ¼ç¹å®æç¨ææ¨¡åæ¶æ§ï¼ç¼ºä¹æ´ååç¨®çç©é«å­¸é åææ°é²å±çå¨é¢åæãæ¬ç¶è¿°åºæ¼å°ä¾èª PubMedãWeb of Science å arXiv ç­æ¸æåº«ç 484 ç¯åºçç©çåæï¼æ·±å¥æ¢è¨äºçç©é«å­¸ä¸­ LLM çç¶åç¾æ³ãæç¨ãææ°ååæ¯ï¼å¶ç¹é»æ¯éæ³¨éäºæ¨¡åå¨ç¾å¯¦ä¸ççç©é«å­¸èæ¯ä¸­çå¯¦éæç¨ãé¦åï¼æåæ¢è¨äº LLM å¨å»£æ³ççç©é«å­¸ä»»åä¸­çé¶æ¬¡å­¸ç¿è½åï¼åæ¬è¨ºæ·è¼å©ãè¥ç©ç¼ç¾ååæ§åé«çç­ï¼ä¸¦å¾ 137 é ééµç ç©¶ä¸­æ±²åè¦è§£ãç¶å¾ï¼æåè¨è«äº LLM çé©æç­ç¥ï¼åæ¬å®æ¨¡æåå¤æ¨¡æ LLM çå¾®èª¿æ¹æ³ï¼ä»¥å¢å¼·å®åå¨é¶æ¬¡å­¸ç¿ç¡æ³å¯¦ç¾çå°æ¥­çç©é«å­¸èæ¯ä¸­çæ§è½ï¼ä¾å¦é«çåé¡è§£ç­åçç©é«å­¸æç»çææèçãæå¾ï¼æåè¨è«äº LLM å¨çç©é«å­¸é åé¢è¨çææ°ï¼åæ¬æ¸æé±ç§åé¡ãæ¨¡åå¯è§£éæ§æéãæ¸æéè³ªéåé¡ä»¥åç±æ¼çç©é«å­¸æ¸æçæææ§ãå°é«åº¦å¯é æ¨¡åè¼¸åºçéæ±ä»¥åå¨é«çä¿å¥ä¸­é¨ç½² AI çå«çå½±é¿èç¢ççå«çåé¡ãçºäºæå°éäºææ°ï¼æåéç¢ºå®äºçç©é«å­¸ä¸­ LLM æªä¾çç ç©¶æ¹åï¼åæ¬ç¨æ¼ä¿è­·æ¸æé±ç§çè¯åå­¸ç¿æ¹æ³ä»¥åæ´åå¯è§£é AI æ¹æ³ä»¥å¢å¼· LLM çéæåº¦ã

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨é«çåä¿å¥æç¨ä¸­æå¥äºå¤§éçæè³åéç¼ï¼é²èå°è´é«çæè¡ä¸­çåé²æ§å¶ç³»çµ±ãç¶èï¼AI ç³»çµ±çä¸éææ§å¼ç¼äºå°æ­¤é¡æææç¨ä¸­æéåºæ¬ç¹æ§çææï¼ä¾å¦éæåº¦åå¯ä¿¡åº¦ãæåçç ç©¶ééèª¿æ¥ä¸åç¨åºä¾è§£æ±ºéäºåé¡ï¼ç¨æ¼é¸ææååçå¯è§£é AIï¼XAIï¼æ¹æ³ï¼ä»¥ç¬¦åæ­çæ³è¦å¨é«çå¨æçæºæ§åçç©é»å­å­¸ä¸­çèªªæè¦æ±ãæ¡ç¨çæ¹æ³å¾ééå¶æ§å¶æ©å¶ï¼éè¿´è·¯ãéè¿´è·¯ååéè¿´è·¯ç³»çµ±ï¼å°æºæ§åè£ç½®é²è¡åé¡ï¼ä¸¦æ·±å¥æ¢è¨å¶æè¡éå§ãç¶å¾ï¼æååæéäºæ³è¦ä»¥å®ç¾©å¶å°åç¨®è£ç½®åç¸éç®æ¨çå¯è§£éæ§è¦æ±ãåæï¼æåééå¶èªªæç®æ¨å° XAI æ¹æ³é²è¡åé¡ãéåè¨±å°æ³å¾å¯è§£éæ§è¦æ±è XAI èªªæç®æ¨ç¸å¹éï¼ä¸¦ç¢ºå®é©ç¶ç XAI æ¼ç®æ³ä¾éæå®åãæåçç ç©¶çµææä¾äºå°åªäº XAI æ¼ç®æ³æ´ç¬¦åæ­çæ³è¦ä»¥é©ç¨æ¼ä¸åé¡åçé«çå¨æçç´°ç·»çè§£ãæåééä¸åç¥ç¶æ¤å¥ç©çå¯¦éæ¡ä¾ç ç©¶ä¾è­æéä¸é»ï¼å¾æ¢æ§ç¾çç®¡çå°åé²çç¾©è¢ãéé ç ç©¶å¡«è£äºå°çç©é»å­å­¸ä¸­ç XAI æç¨èæ­çæ³è¦çå´æ ¼è¦å®ç¸ç¬¦çéè¦ç©ºç½ãå®çºéç¼äººå¡åç ç©¶äººå¡æä¾äºä¸åå¯¦ç¨çæ¶æ§ï¼ç¢ºä¿å¶ AI åµæ°è½ä¿é²é«çæè¡ä¸¦éµå®æ³å¾åéå¾·æ¨æºã

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

æè¦ï¼æåæ¢ç´¢æ·±åº¦çææ¨¡åï¼å¨é«çè¯é¦å­¸ç¿è¨­ç½®ä¸­çæåºæ¼æ¡ä¾çèªªæãééåºæ¼æ¡ä¾çå¯è§£éæ§ä¾è§£é AI æ¨¡åæ±ºç­ï¼å°æ¼å¢å ä¿¡ä»»ä¸¦åè¨± AI å¨è¨åºå¯¦åä¸­å»£æ³æ¡ç¨è³ééè¦ãç¶èï¼é«ç AI è¨ç·´ç¯ä¾æ­£è½åè¯é¦å­¸ç¿è¨­ç½®ï¼ä»¥ç¬¦åè³æä¿è­·æ³è¦ãå¨è¯é¦æå¢ä¸­ï¼éå»çè³æå°ç®åçä½¿ç¨èèè¨æ¯ç¡æ³åå¾çãå æ­¤ï¼æåä½¿ç¨æ·±åº¦çææ¨¡åä¾ç¢çä¿è­·é±ç§åè§£éæ±ºç­çåæç¯ä¾ãæåçæ¦å¿µé©è­èéæ¼è¸èç©æ¶²è¨ºæ·ï¼ä¸¦ä½¿ç¨å¬éå¯åå¾çè¸é¨ X åè³æã

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. GruÃ¼hagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

æè¦ï¼è»çµç¹åéª¨éª¼è«ç¤ï¼STBTï¼æ¯ç½è¦ãè¨ºæ·å·æææ°æ§ççç¶ï¼å¶è¨åºè¡çºåæ²»çæ¹æ³åä¸ç¸åãéç¯ç³»çµ±æ§åé¡§æä¾äºä½¿ç¨æ¾å°å½±åé²è¡è¨ºæ·åé å¾çäººå·¥æºæ§ (AI) æ¹æ³çæ¦è§ï¼éé»èªªæäºè¨åºè½è­¯çææ°ï¼ä¸¦è©ä¼°ç ç©¶èé«çå½±å AI æ ¸æ¥è¡¨ (CLAIM) å FUTURE-AI å¯ä¿¡è³´ä¸å¯é¨ç½² AI çåéå±è­æºåçä¸è´æ§ï¼ä»¥ä¿é² AI æ¹æ³çè¨åºè½è­¯ãéç¯åé¡§æ¶µèäºå¹¾åæ¸ç®è³æåº«ä¸­çæç»ï¼åæ¬å¨ 2024 å¹´ 7 æ 17 æ¥ä¹åç¼è¡¨çè«æãç´å¥äºä»¥æ¾å°çºåºç¤ç AI è¨ºæ·æé å¾åç¼æ§ STBT çåè¡è©å¯©æåä¸­çåå§ç ç©¶ãæé¤æ¨æºæ¯åç©ãå±é«æå¯¦é©å®¤ç ç©¶ï¼ä»¥åéè±æè«æãæè¦ç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çå©ä½ç¯©é¸è³æ ¼ãåæ ¼çè«æç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çä¸ä½æ ¹ææºåé²è¡è©ä¼°ãæç´¢è­å¥åº 15,015 ç¯æè¦ï¼å¶ä¸­ 325 ç¯æç« è¢«ç´å¥è©ä¼°ãå¤§å¤æ¸ç ç©¶å¨ CLAIM ä¸­è¡¨ç¾ä¸­ç­ï¼å¹³åå¾åçº 53 åä¸­ç 28.9Â±7.5 åï¼ä½å¨ FUTURE-AI ä¸­è¡¨ç¾ä¸ä½³ï¼å¹³åå¾åçº 30 åä¸­ç 5.1Â±2.1 åãSTBT çå½±å AI å·¥å·ä»èæ¼æ¦å¿µé©è­éæ®µï¼è¡¨ææé¡¯èçæ¹é²ç©ºéãAI éç¼äººå¡æªä¾çåªåæéä¸­å¨è¨­è¨ï¼ä¾å¦å®ç¾©æªæ»¿è¶³çè¨åºéæ±ãé æçè¨åºç°å¢ä»¥å AI å¦ä½æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼ãéç¼ï¼ä¾å¦å»ºç«å¨ååçå·¥ä½ãå¯è§£éæ§ï¼ãè©ä¼°ï¼ä¾å¦è©ä¼°åè§£æ±ºåå·®ãè©ä¼° AI èæä½³å¯¦åï¼ãä»¥åæ¸æå¯è¤è£½æ§åå¯ç¨æ§ï¼å¬éæä¾æä»¶åçä»£ç¢¼åæ¸æï¼ãéµå¾ªéäºå»ºè­°å¯ä»¥æ¹å AI æ¹æ³çè¨åºè½è­¯ã

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga StrÃ¼mke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

æè¦ï¼è¦æ§éº»çº (CP) çæ©æåµæ¸¬å°æ¼ææçä»å¥åç£æ¸¬è³ééè¦ãæ¬ææ¸¬è©¦äºå¯è§£é AI (XAI) æ¹æ³çå¯é æ§åé©ç¨æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ééåæå¾å¬°ååä½å½±çè¨éä¸­æåçéª¨éª¼è³æä¾é æ¸¬ CPãå·é«ä¾èªªï¼æåä½¿ç¨ XAI è©ä¼°ææ¨ï¼å³å¿ å¯¦åº¦åç©©å®æ§ï¼ä¾éåè©ä¼°é¡å¥æ¿æ´»æ å° (CAM) åæ¢¯åº¦å æ¬é¡å¥æ¿æ´»æ å° (Grad-CAM) å¨éåç¹å®é«çæç¨ä¸­çå¯é æ§ãæåå©ç¨ä¸åç¨ç¹çå¬°ååä½è³æéï¼ä¸¦æç¨éª¨éª¼è³ææ¾åï¼èä¸ææ­æ²å¬°ååä½çåå§ååãæåç CP é æ¸¬æ¨¡åå©ç¨æ´é«æ¹æ³ï¼å æ­¤æåè©ä¼°äºæ´é«æ´é«ååå¥æ¨¡åç XAI ææ¨è¡¨ç¾ãæåçç ç©¶çµæè¡¨æï¼å©ç¨® XAI æ¹æ³é½è½ææè­å¥å½±é¿ CP é æ¸¬çééµèº«é«é¨ä½ï¼ä¸¦ä¸éäºè§£éå°æ¼å¾®å°çè³ææ¾åå·æé­¯æ£æ§ãGrad-CAM å¨ RISv ææ¨ä¸­é¡¯èåªæ¼ CAMï¼è©²ææ¨è¡¡ééåº¦æ¹é¢çç©©å®æ§ãç¸æ¯ä¹ä¸ï¼CAM å¨ RISb ææ¨ä¸­è¡¨ç¾å¾æ´å¥½ï¼è©²ææ¨èéª¨éª¼ç©©å®æ§æéï¼è RRS ææ¨åè©ä¼°å§é¨è¡¨ç¤ºçé­¯æ£æ§ãæ´é«ä¸­çåå¥æ¨¡åé¡¯ç¤ºåºä¸åççµæï¼CAM å Grad-CAM é½ä¸ä¸è´å°åªæ¼å¦ä¸ç¨®ï¼æ´é«æ¹æ³æä¾äºå¶çµææ¨¡åçµæçè¡¨ç¤ºã

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

æè¦ï¼æè¿çå¨çä¼°è¨è¡¨æï¼å¤é 24.1 åäººæ
å¥åº·çæ³å¯å¾å¾©å¥æåä¸­åçãå±å®¶
ç©çæ²»ç (PT) å¨æä¾äºåå¼
åé¥åææç¾©çè§å¯æ¹é¢é¢è¨éå¤§ææ°ï¼ä¾æ²»çå¸«åæ£èä½¿ç¨ãçºäºå¡«è£é
åç¼ºå£ï¼æåæåº MicroXerciseï¼å®å°å¾®åä½åæè
å¯ç©¿æ´å¼ææ¸¬å¨æ´åå¨ä¸èµ·ï¼çºæ²»çå¸«åæ£èæä¾ä¸åå¨é¢ç
åé¥ä»é¢ï¼åæ¬å½±çãæå­ååæ¸ãè³ééè¦çæ¯ï¼å®æ¡ç¨
å¤ç¶­åææéè¦æ´ (DTW) ååºæ¼æ­¸å çå¯è§£é
æ¹æ³ä¾åæç£æ§éåä¸­ç¾æçæ·±åº¦å­¸ç¿ç¥ç¶ç¶²è·¯ï¼å°æ³¨æ¼éåçé«ç²åº¦ãéç¨®åå
æ¹æ³è³ééè¦ï¼æä¾èè¼¸å¥å¤§å°å¹éçè¼¸åºï¼ä»¥ç²¾ç¢ºå°
çªåº PT ä¸­ééµçç´°å¾®å·®å¥ååä½ï¼å¾èå°è¤éç AI
åæè½æçºæ¸æ°ãå¯æä½çåé¥ãééå¨ä¸åææ¨ä¸­çªé¡¯éäºå¾®åä½ï¼ä¾å¦ç©©å®æ§ååä½ç¯åï¼MicroXercise
é¡¯èæåæçµä½¿ç¨èå°åé¥ççè§£åç¸éæ§ãæ¯è¼æè½ææ¨å¼·èª¿å¶åªæ¼
å³çµ±æ¹æ³çæææ§ï¼ä¾å¦ç¹å¾µäºæ è³è¨ (FMI) åé£çºæ§åå¥æåäº 39% å 42%ãMicroXercise å¨å±å®¶
ç©çæ²»çæ¹é¢æ´é²ä¸æ­¥ï¼æä¾æè¡åé²ä¸ç´è¦ºæç¨ç
è§£æ±ºæ¹æ¡ï¼ä»¥æåæ£èç§è­·åçµæã

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah RÃ¶sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

æè¦ï¼ç³»çµ±æ§æç»åé¡§æ¯ç ç©¶ä¸­è­æåè³ªæé«çãç¶èï¼åé¡§éç¨åå°é¡¯èè³æºåè³æéå¶çé»ç¤ãæç»åé¡§ç¶²è·¯ (LRN) æ¯ç¬¬ä¸åéµå¾ª PRISMA 2020 æ¨æºçå¯è§£é AI å¹³å°ï¼æ¨å¨èªååæ´åæç»åé¡§éç¨ãLRN å¨å¤ç§æå¥å¯¦åé åä¸­é²è¡è©ä¼°ï¼ä½¿ç¨å°å®¶éç¼ç 3 åæå°å­ä¸²ä¾æ¥è©¢ PubMedãéå°å®¶è¨ç·´ææ LRN æ¨¡åãæè½ä»¥å°å®¶æååé¡§ä½çºåºæºãå¯è§£éæ§åæè½ææ¨è©ä¼° LRN è¤è£½å°å®¶åé¡§çè½åãä¸è´æ§ä»¥ Jaccard ææ¸åæ··æ·ç©é£æ¸¬éãç ç©¶äººå¡å¨ç ç©¶å®æåå°å½¼æ­¤ççµæä¿å¯ãéççç ç©¶æ´åå° LRN çæçç³»çµ±æ§åé¡§ä¸­ãLRN æ¨¡åå¨æ²æå°å®¶è¨ç·´çææ³ä¸å±ç¾åºåªç°çåé¡æºç¢ºçï¼éå° 84.78% å 85.71% çæºç¢ºçãæè½æé«çæ¨¡åéå°äºé«è©åèéä¿¡è³´åº¦ (k = 0.4953) åå¯è§£éæ§ææ¨ï¼å°ãæ¸å°ãããæå¤ãåãé³å©ãèãééæ´æå¥ãé£çµå¨ä¸èµ·ãå¦ä¸å LRN æ¨¡åæ¶µèäº 91.51% çç¸éæç»ï¼åç®¡èéå°å®¶çå¤æ·ä¸å (k = 0.2174)ï¼ä½åå«äºãä¹³è ãããééãï¼æå¥ï¼åãé©æçãç­è©å½ãLRN åªæ¼æååé¡§ï¼11 åæè¶é 19,920 åéï¼ï¼å°æ´åéç¨ç¸®ç­çº 5 å¤©è¶é 288.6 åéãéé ç ç©¶é¡¯ç¤ºï¼å¯è§£éç AI ä¸éè¦å°å®¶è¨ç·´å³å¯æåé²è¡å°å®¶ç­ç´ç PRISMA ç¸å®¹ç³»çµ±æ§æç»åé¡§ãLRN ç¸½çµäºå¤ç§æå¥ç ç©¶ççµæï¼ä¸¦æ¾åºèè¨åºç ç©¶äººå¡ç¼ç¾å¹¾ä¹ç¸åçä¸»é¢ãå¯è§£éç AI å¯ä»¥æºç¢ºå°å å¿«æåå°è¨åºå¯¦åççè§£ï¼ææ½åé©æ°é«çä¿å¥ç ç©¶ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

æè¦ï¼èç±æºæ§ç°å¢ä¸­ä¸å¼äººæ³¨ç®çææ¸¬å¨è¾¨è­æ¥å¸¸æ´»åï¼è½åç¨åç¨®é«çä¿å¥æç¨ãç£æ§åè©¦èå¨å®¶ä¸­å¦ä½å·è¡æ´»åï¼ä»¥åå¶é¨èæéçè®åï¼å¯ä»¥æ­ç¤ºå¥åº·åé¡çæ©æççï¼ä¾å¦èªç¥è½åä¸éãæ­¤é åä¸­çå¤§å¤æ¸æ¹æ³é½ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼éäºæ¨¡åéå¸¸è¢«è¦çºå°ææ¸¬å¨è³æå°æè³æ´»åçé»çå­ãç¶èï¼éå°å®¶ä½¿ç¨èï¼ä¾å¦è¨åºé«å¸«ï¼éè¦ä¿¡ä»»ä¸¦äºè§£éäºæ¨¡åçè¼¸åºãå æ­¤ï¼äººé¡æ´»åè¾¨è­çå¯è§£é AI (XAI) æ¹æ³æéèçï¼ä»¥æä¾ä¾èªéäºæ¨¡åçç´è¦ºèªç¶èªè¨èªªæãä¸åç XAI æ¹æ³æç¢çä¸åçèªªæï¼èå¶æææ§éå¸¸ééä½¿ç¨èèª¿æ¥ä¾è©ä¼°ï¼éå¨ææ¬åå¬å¹³æ§æ¹é¢éå¸¸å·æææ°æ§ãæ¬ææåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªåè©ä¼°æ¹æ³ï¼ä»¥å¨åé¸èä¸­æ¾åºæé©åéå°å®¶ä½¿ç¨èç XAI æ¹æ³ãæåçåæ­¥çµæè¡¨æï¼LLM è©ä¼°èä½¿ç¨èèª¿æ¥ä¸è´ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼è¿ç¯è®ºææåºäºç¨äºä»è§ç½èç¼åºå¾åè¿è¡ç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åæç¥åºï¼ä»èéå¯¹ç¾çåç±»å¯¹æ­£å¸¸ ResNet æ¨¡åè¿è¡æ¹è¿ãæ¬ç ç©¶å¼å¥äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»å­¦ä¸ä¸äººå£«è½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬ä¸å½ä»çå»çä¿å¥é¢åå°¤ä¸ºç¸å³ï¼å¨è¯¥é¢åï¼å¯¹ AI åºç¨çéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§ååä¹éå¾·çä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼é¨ç¾ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ç¼ç§ç¾çæºè½è¯å« (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼é¨ç¾çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 å¾åãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152 äºä¸ªåä½çæ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åè¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 å¾åä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åæ¹é¢çå¿«éé²å±ï¼ä»£è¡¨èå¨å å¼·è¨ºæ·æºç¢ºæ§ååäººåæ²»çæ¹é¢éåºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å°å¶å¯ä¿¡åº¦é²è¡å´æ ¼çå¯©æ¥ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç®åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»ä¸­é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥ä¸¦æªååè§£æ±ºå¶å¨é«å­¸å½±åé åä¸­çç¹å®è®ååæç¨ãæ¬èª¿æ¥æ¨å¨ééæåºé«å­¸å½±åä¸­ä½¿ç¨çåºç¤æ¨¡åçæ°åé¡æ³ä¸¦åæç¢ºä¿å¶å¯ä¿¡åº¦çééµåæ©ï¼ä¾å¡«è£éä¸ç©ºç½ãæååé¡§äºåºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç¶åç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡ååç­ (Q&A) ä»¥åç¾çè¨ºæ·ãéäºé åä¹æä»¥è¢«å¼·èª¿ï¼æ¯å çºèå¶ä»æç¨ç¸æ¯ï¼å®åå·²ç¶çå°ç¸å°æçä¸å¤§éçåºç¤æ¨¡åãæåå°æ³¨æ¼æ¢è¨é«å­¸å½±ååææç¨¿ä¸­å¯ä¿¡åº¦çæç»ãæåæ¢è¨äºçºæ¯åæç¨æ§å»ºå¯ä¿¡åºç¤æ¨¡åçè¤éææ°ï¼ç¸½çµäºç¶åéæ³¨é»åå¢å¼·å¯ä¿¡åº¦çç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èè­·çæ¹é¢çæ½åãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼ä¸¦å¡å°ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸å½±ååæä¸­å·²éå°æ´é«é«æºç¢ºåº¦ãç¶èï¼ç¹å®æ£èç¾¤é«çæè½å·®ç°å°å¶è¨åºæç¨ãå®å¨æ§èå¬å¹³æ§æ§æææ°ãéå¯è½æå½±é¿å·²ç¥çæ£èç¾¤é«ï¼ä¾å¦åºæ¼æ§å¥ãå¹´é½¡æç¾çäºåï¼ä»¥åååæªç¥ä¸æªæ¨ç±¤çç¾¤é«ãæ­¤å¤ï¼æ­¤é¡è§å¯å°çæè½å·®ç°çæ ¹æ¬åå éå¸¸é£ä»¥ç¼ç¾ï¼é»ç¤äºç·©è§£æªæ½ãå¨æ¬æä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨åçç¼ç¾æ¹æ³ (SDM) ä¾è­å¥å¯è§£éçè³ææè½ä¸ä½³å­éï¼ä¸¦éå°è§å¯å°çæè½å·®ç°åå å¶å®åè¨­ãæåå¼å¥ä¸ç¨®æ°ç SDMï¼ä¸¦å¨è¸é¨ X åçä¸­èºçåèºä¸å¼µåé¡çæ¡ä¾ç ç©¶ä¸­æç¨å®ãæåçç ç©¶è­æäº SDM å¨åè¨­å¶å®ä¸­çæææ§ï¼ä¸¦å°å»£æ³ä½¿ç¨çè¸é¨ X åçè³æéåæ¨¡åä¸­ååè§å¯å°ä½ç¡æ³è§£éçç·æ§åå¥³æ§æ£èä¹éçæè½å·®ç°æä¾äºè§£éãæåçç¼ç¾è¡¨æï¼å¨åé¡ä»»åä¸­ï¼ééè¸èå¼æµç®¡åå¿é»åå°ç·çå­å¨ï¼å­å¨æ·å¾å­¸ç¿ãéäºæ·å¾ç¹å¾µççè¡çå­å¨åºæ¼æ§å¥çå·®ç°ï¼ä¼¼ä¹æå°è´è§å¯å°çåé¡æè½å·®è·ï¼éä»£è¡¨æ·å¾å­¸ç¿åæ¨¡åå¬å¹³æ§åæä¹éååæªåå°éè¦çäº¤äºä½ç¨ã

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

æè¦ï¼èªæ³¨æåæ©å¶å·²è¢«æ¡ç¨æ¼å¤åå»£æ³ä½¿ç¨çè¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN)ï¼ä¾å¦ GATï¼ï¼å®å¯ä»¥èªé©æå°æ§å¶æ²¿èåºå±¤åå½¢éç·£æµåçè³è¨éãéç¨®æ³¨æåçä½¿ç¨ä½¿å¾æ­¤é¡æ¨¡åæçºå¯è§£é AI (XAI) ç ç©¶çåºç·ï¼å çºééæ³¨æåçè©®éå·²å¨åç¨®é åï¼ä¾å¦èªç¶èªè¨èçåé»è¦è¦è¦ºï¼ä¸­æ®åãç¶èï¼ç¾æçç ç©¶éå¸¸ä½¿ç¨å¤©ççè¨ç®æ¹æ³å¾æ³¨æåä¸­æ¨å°åºæ­¸å åæ¸ï¼ä¸¦ä¸æ²æèæ®å°éç·£æ­¸å çç²¾ç¢ºä¸ä»ç´°çè¨ç®ãå¨æåçç ç©¶ä¸­ï¼æåæ¨å¨å¡«è£æ³¨æååç¨ MPNN çå»£æ³ä½¿ç¨èå®åå¨å¾å¤§ç¨åº¦ä¸æªè¢«ååæ¢ç´¢çå¯è§£éæ§ä¹éçå·®è·ï¼éåä¸»é¡å·²å¨å¶ä»é åç©æ¥µç ç©¶ãçºæ­¤ï¼ä½çºç¬¬ä¸æ¬¡åè©¦ï¼æåå° GNN ä¸­æ³¨æåæ¬éçéç·£æ­¸å åé¡å½¢å¼åãç¶å¾ï¼æåæåº GATTï¼ä¸ç¨®å»ºç«å¨è¨ç®æ¨¹ä¸çéç·£æ­¸å è¨ç®æ¹æ³ãééå¨é¢çå¯¦é©ï¼æåå±ç¤ºäºæåæåºçæ¹æ³å¨è©ä¼° GAT çæ­¸å ææå·æçææãç¸åå°ï¼æåæç¶é©é©è­äºåå°åæ³¨æåå±¤ä¸çæ³¨æåæ¬éåå¹³åå¼ä¸è¶³ä»¥è©®é GAT æ¨¡åçè¡çºãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jordan7186/GAtt/tree/mainã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æèå¼±çææï¼å®¹æåºç¾ç²çç¼ä½ãå¤§è¦ç¼è²ä¸æçæåºç¾ç²çç¼ä½æé æä¸è¯å¾æï¼å æ­¤éè¦åæ©è¨ºæ·ãç®åæ°çåç²çç¼ä½çé»éæ¨æºä¾è³´æ¼é£çºçè¦è¨è¦é»å (EEG) ç£æ¸¬ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§åæé²è¡å¤é »éè¦é»å (EEG) è¨éåå³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çç¼ä½åµæ¸¬éç¨ï¼ä¸¦æ¡ç¨æ¸å°çè¦é»åè£ç½®ï¼å¶ä¸­æ¡ç¨äºå·ç©ç¥ç¶ç¶²è·¯ãåå½¢æ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ ä½¿ç¨æ¸å°çè£ç½®å³æåµæ¸¬ç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééå¨ Zenodo è³æéä¸ä½¿ç¨ 10 åäº¤åé©è­è©ä¼°æè½ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçæ¹é¢åå¥éå°äº 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

æè¦ï¼<paragraph>å¨éå»å¹¾å¹´ï¼è¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) ä¸­çäººå·¥æºæ§ (AI) å¨å©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§æ¹é¢ç¼æ®äºééµä½ç¨ãåç®¡ AI æ¨¡åå·æä»¤äººæ»¿æçè½åï¼ä½ç¼ºä¹éæåº¦åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å¯é æ§çºå¿è¦èéçé«çèæ¯ä¸ï¼éå¸¶ä¾äºéå¤§çææ°ãå¨ä¸å½±é¿é æ¸¬ç²¾æºåº¦çææ³ä¸å¯¦ç¾éæåº¦ä»ç¶æ¯ä¸é ééµææ°ãæ¬ææåºäºä¸ç¨®æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥å¢å¼· CNN è¡çç¹å¾µçé æ¸¬è½åï¼åæå·åæ¾å°ç¹å¾µåºæçå¯è§£éæ§ãRad4XCNN ä¸åæ¼åºæ¼é¡¯èæ§åçå³çµ±æ¹æ³ï¼å®ééæ¾å°çµå­¸å°å¯çè§£çå«ç¾©è CNN è¡çç¹å¾µéè¯èµ·ä¾ï¼çºè¶è¶è¦è¦ºååè¡¨çè§£éæ¹æ³æä¾äºæ°çè§é»ãæåä»¥ä¹³çåé¡ä»»åä½çºæ¡ä¾ç ç©¶ï¼å¨è¶é³æ³¢å½±åè³æéä¸è©ä¼° Rad4XCNNï¼åæ¬ä¸åç·ä¸è³æéåå©åç¨æ¼å§é¨åå¤é¨é©è­çå§é¨è³æéãä¸äºééµçµæå¦ä¸ï¼i) è ViT è¡çç¹å¾µåæ¾å°ç¹å¾µç¸æ¯ï¼CNN è¡çç¹å¾µä¿è­äºæ´ç©©å¥çæºç¢ºåº¦ï¼ii) å³çµ±çè¦è¦ºååè§£éæ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN æ²æç§ç²æ¨¡åæºç¢ºåº¦ä¾æåå¶å¯è§£éæ§ï¼iv) Rad4XCNN æä¾äºå¨å±è§£éè¦è§£ï¼ä½¿é«å¸«è½å¤ åææ¨¡åè¼¸åºåç¼ç¾ãæ­¤å¤ï¼æåå¼·èª¿å°å¯è§£éæ§æ´åå° AI æ¨¡åä¸­å°æ¼å¢å¼·è¨åºå¯¦åä¸­çä¿¡ä»»åæ¡ç¨è³ééè¦ï¼ä¸¦å¼·èª¿äºæåçæ¹æ³å¦ä½è½ç·©è§£èå¯è§£é AI æ¹æ³ç¸éçä¸äºçæ®ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼äºè§£å®åå¨è§£ç¢¼åè§£éèªè¨æèå«çè¤éå æéä¿ç¶²è·¯ä¸­çè½ååéå¶è®å¾è³ééè¦ãç®åçæè¡ä½¿ç¨æç¢ºæé±å«çå ææ¨çï¼ä½å¼·çéè¦ä¸ç¨®çµ±ä¸çæ¹æ³ï¼çµåå©èä»¥æ´ææå°èçå»£æ³çå æéä¿ãæ¬ç ç©¶æåºäºä¸ç¨®ç¨±çºæå¢æç¥æ¨çå¢å¼·èåäºå¯¦åæ (CARE CA) æ¡æ¶çæ°æ¶æ§ï¼ä»¥å¢å¼·å ææ¨çåå¯è§£éæ§ãæåºçæ¡æ¶çµåäºä½¿ç¨ ConceptNet ååäºå¯¦é³è¿°çæç¢ºå ææª¢æ¸¬æ¨¡çµï¼ä»¥åéé LLM é²è¡çé±å«å ææª¢æ¸¬ãæåçæ¡æ¶æ´é²ä¸æ­¥ï¼å å¥ä¸å±¤åäºå¯¦è§£éï¼ä»¥å¼·èª¿ LLM å°å æéä¿ççè§£ãä¾èª ConceptNet çç¥è­å¢å¼·äºå¤é å ææ¨çä»»åçå·è¡ï¼ä¾å¦å æç¼ç¾ãå æè­å¥ååäºå¯¦æ¨çãåäºå¯¦å¥å å¥äºæªç±æå¢é æçæç¢ºç¥è­ãééçµåéäºå¼·å¤§çæ¨¡çµï¼æåçæ¨¡åæ¨å¨æä¾å°å æéä¿æ´æ·±å¥ççè§£ï¼å¯¦ç¾å¢å¼·çå¯è§£éæ§ãåºæºè³æéçè©ä¼°é¡¯ç¤ºå¨ææææ¨ï¼ä¾å¦æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸é½æææåãæåéå¼å¥äº CausalNetï¼ä¸åæ°çè³æéï¼ä¸¦éä¸äºæåçç¨å¼ç¢¼ï¼ä»¥ä¿é²å¨éåé åçé²ä¸æ­¥ç ç©¶ã

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

æè¦ï¼<paragraph>æ¯åå°äººååºæ±ºå®ç AI ç³»çµ±é½æä¸ç¾¤å©å®³éä¿äºº
åå°éäºæ±ºå®çè¦ªèº«å½±é¿ãç¶èï¼AI
ç³»çµ±çè§£éå¾å°è½æ»¿è¶³éç¾¤å©å®³éä¿äººçè³è¨éæ±ï¼èä»å
éå¸¸é½æ¯ AI æ°æãéé æäºå³éè³è¨è
åå°ç³»çµ±æ±ºç­å½±é¿çäººå£«ï¼ä¾å¦é åå°å®¶åæ±ºç­ä¸»é«ï¼éè¦çè³è¨ä¹éçè½å·®ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº
ãXAI æ°æåé¡åº«ãï¼å®æ¯ XAI åé¡åº«çå»¶ä¼¸ï¼åå«ä¾èª AI æ°æå¨å©åä½¿ç¨æ¡ä¾ä¸­çè³è¨éæ±ç®éï¼å°±æ¥­
é æ¸¬åå¥åº·ç£æ¸¬ãç®éæ¶µèäºè³æã
ç³»çµ±èæ¯ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼ç­é¡å¥ãæåééä»»ååè¨ªè«æ¶éè³è¨éæ±ï¼åèèå¨è¨ªè«ä¸­è©¢åäºå©å AI ç³»çµ±çåé¡ï¼ä»¥æ±ºå®æ¯å¦æ¡ç¨å®åï¼ä¸¦æ¶å°å£é ­
è§£éä½çºåæãæåçåæé¡¯ç¤ºï¼åèèå¨æ¶å°è§£éå¾ä¿¡å¿æææåï¼ä½ä»åççè§£å»é¢è¨ææ°ãéäºææ°åæ¬é£ä»¥æ¾å°è³è¨åè©ä¼°èªå·±ççè§£ï¼ä»¥åè©¦åå¤å
çè§£ãæ­¤å¤ï¼åèèå°ç³»çµ±é¢¨éªåå¥½èçåååé¥å½±é¿äºä»åçè³è¨éæ±ãèªçºé¢¨éªé«çåèèå°æ±è§£éç³»çµ±é¨ç½²èå¾çæåï¼èèªçºé¢¨éªä½çäººåè©¢åç³»çµ±ç
æä½ãæåçç ç©¶æ¨å¨ééå¼·èª¿ AI æ°æçè³è¨éæ±ãç®æ¨å
ææ°ï¼ä¾æ¯æå° AI æ°æç´å¥å¯è§£éæ§å·¥ä½ä¸­ãæåå°æåçç ç©¶çµæç¸½çµçºäºåééµåç¤ºï¼éäºåç¤ºå¯ä»¥çºæªä¾éå°éå°æ¥­å©å®³éä¿äººåç¾çè§£éè¨­è¨æä¾åèã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian GeiÃler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, BjÃ¶rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias KÃ¼ster, AndrÃ© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

æè¦ï¼å¨éå»çåå¹´ä¸­ï¼ççå­¸ä¸­çäººå·¥æºæ§ (AI) æ¹æ³å·²å¤§å¹é²æ­¥ãç¶èï¼ç±æ¼è¨±å¤ææ°ï¼åæ¬å°ç ç©¶çµæè½åçºè¨åºè¨ºæ·ç¢åå¨æè¡åæ³è¦æ¹é¢çéç¤ï¼ä»¥åç¼ºä¹æ¨æºåä»é¢ï¼å°è´æ´åå°å¸¸è¦è¨åºå¯¦åä¸­é²å±ç·©æ¢ãéæ¾ä¸èä¾æåç¡éç EMPAIA è¨ç«æå°äºéäºææ°ãå¨æ­¤ï¼æåæä¾ EMPAIA çæå°±åç¶é©æè¨çæ¦è¿°ãEMPAIA æ´åäºççå­¸ AI çæç³»çµ±çååå©å®³éä¿äººï¼å³ççå­¸å®¶ãé»è¦ç§å­¸å®¶åç¢æ¥­ãå¨å¯ååä½ä¸ï¼æåå¶å®äºæè¡äºéæ§æ¨æºãAI æ¸¬è©¦åç¢åéç¼å»ºè­°ï¼ä»¥åå¯è§£éæ§æ¹æ³ãæåå¯¦ä½äºæ¨¡çµåä¸éæ¾åå§ç¢¼ç EMPAIA å¹³èºï¼ä¸¦æåæ´åäºä¾èª 8 åä¸åä¾æåç 14 ååºæ¼ AI çå½±ååææç¨ç¨å¼ï¼å±ç¤ºäºä¸åçæç¨ç¨å¼å¦ä½ä½¿ç¨å®ä¸çæ¨æºåä»é¢ãæååªåèæ®éæ±ï¼ä¸¦è©ä¼°äº AI å¨æ­æ´²åäºæ´²ç 14 åä¸åççå¯¦é©å®¤ä¸­çå¯¦éè¨åºæç¨ãé¤äºæè¡éç¼å¤ï¼æåéçºææå©å®³éä¿äººå»ºç«äºä¸åè«å£ï¼ä»¥åäº«æ¸ä½ççå­¸å AI çè³è¨åç¶é©ãåæ¥­ãè¨åºåå­¸è¡å©å®³éä¿äººç¾å¨å¯ä»¥æ¡ç¨ EMPAIA çå¸¸è¦éæ¾åå§ç¢¼ä»é¢ï¼éçºå¤§è¦æ¨¡æ¨æºååç°¡åæµç¨æä¾äºç¨ç¹çæ©æãéè¦é²ä¸æ­¥çåªåæè½ææä¸å»£æ³å°å»ºç«ä¾è¡å¯¦é©å®¤ä½¿ç¨ä¸­ç AI è¼å©ãçºæ­¤ï¼å·²æç«éçå©åæ EMPAIA Internationalï¼ä»¥ä½çºæ°¸çºåºç¤æ¶æ§ï¼ç¹¼çºé²è¡æ¨æºåï¼ä¸¦æ¯æ´å»£æ³å¯¦ä½åå¡å° AI è¼å©æ¸ä½ççå­¸çæªä¾ã

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

æè¦ï¼åäºå¯¦è§£é (CE) æè¡å·²å¼èµ·éæ³¨ï¼ä½çºä¸ç¨®çºè AI ç³»çµ±äºåçä½¿ç¨èæä¾è¦è§£çæ¹æ³ãéç¶å¨é«å­¸å½±ååèªåé§é§æ±½è»ç­é åå»£æ³ç ç©¶ï¼åå½¢åäºå¯¦è§£é (GCE) æ¹æ³ç¸å°è¼å°è¢«æ¢ç´¢ãGCE æç¢çä¸åé¡ä¼¼æ¼åå§åå½¢çæ°åå½¢ï¼ä¸¦æ ¹æåºç¤é æ¸¬æ¨¡åç¢çä¸åççµæãå¨éäº GCE æè¡ä¸­ï¼åç®¡å¨å¶ä»é åï¼ä¾å¦èè¡é¢¨æ ¼åèªç¶èªè¨å»ºæ¨¡ï¼ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæå°±ï¼ä½æ¤åºæ¼çææ©å¶çæè¡ç²å¾çéæ³¨ç¸å°æéãå°çæå¼è§£éå¨çåå¥½æºæ¼å®åå¨æ¨çæéç¢çåäºå¯¦å¯¦ä¾çè½åï¼å©ç¨è¼¸å¥åå½¢çèªä¸»ç²åæ¾åãåºæ¼ä¸è¿°çç±ï¼æåçç ç©¶å¼å¥äº RSGG-CEï¼ä¸ç¨®ç¨æ¼åäºå¯¦è§£éçæ°åç©©å¥é¨æ©åå½¢çæå¨ï¼è½å¤ å¾å­¸ç¿å°çæ½å¨ç©ºéä¸­ç¢çåäºå¯¦ç¯ä¾ï¼èæ®é¨åæåºççæåºåãæ­¤å¤ï¼æåé²è¡å®éåå®æ§åæï¼ä»¥æ¯è¼ RSGG-CE çæè½è SoA çæå¼è§£éå¨ï¼å¼·èª¿å¶å¢å¼·äºç¢çåçè§£éåé¸çè½åã

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

æè¦ï¼å¯è§£é AI çåæ©ä¹ä¸æ¯è®äººåå¨ä½¿ç¨åé¨ç½² AI æ¨¡åæååºæ´å¥½ãæ´ææºçæ±ºç­ãä½éè¦ä»ç´°è©ä¼°ä»¥è©ä¼°æ¯å¦å·²éå°æ­¤é æãç®åçè©ä¼°ä¸»è¦éä¸­å¨è§£éçæ¼ç®æ³ç¹æ§ï¼èæ¶åäººé¡åè©¦èçè©ä¼°éå¸¸æ¡ç¨ä¸»è§åé¡ä¾æ¸¬è©¦äººé¡å°è§£éæç¨æ§ççæ³ï¼èæ²æåºæ¼å®¢è§ææ¨åæ¸¬éãå¨éé å·¥ä½ä¸­ï¼æåè©ä¼°è§£éæ¯å¦å¯ä»¥å¨æ©å¨å­¸ç¿æ¨¡åéç¼çå¯¦éå ´æ¯ä¸­æ¹åäººé¡æ±ºç­å¶å®ãæåé²è¡äºä¸é æ¶åå½±åè³æçæ··åæ¹æ³ä½¿ç¨èç ç©¶ï¼ä»¥è©ä¼° SmoothGradãGradCAM åé è¨è§£éå¨å©åä»»åä¸­ç¢ççé¡¯èæ§åï¼æ¨¡åé¸æååäºå¯¦æ¨¡æ¬ãä»¤äººé©è¨çæ¯ï¼æåæ²æç¼ç¾ä»»ä½é¡¯èæ§åï¼å³ä½¿æ¯è¨­è¨çºææ¼çè§£ä¸é«åº¦æç¤ºç­æ¡çåæé è¨è§£éï¼è½è®ä½¿ç¨èå¨éäºä»»åä¸é¡¯èæ¹åçè­æãåç®¡å¦æ­¤ï¼è§£éç¢ºå¯¦æå©æ¼ä½¿ç¨èæ´æºç¢ºå°æè¿°æ¨¡åãéäºç¼ç¾æç¤ºæåè¦å°åºæ¼é¡¯èæ§çè§£éä¸­å¯è½å­å¨èª¤è§£çæç¨æ§ä¿æè¬¹æã

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

æè¦ï¼å¯è§£éæ§åå®å¨æ§å»ºç«ä¿¡ä»»ãéäºéè¦ä¸åæ¨¡åä¾å±ç¤ºä¸è´æ§åå¯é æ§ãçºäºå¯¦ç¾éäºï¼æå¿è¦ä½¿ç¨ååææ¸æåç¥è­ï¼ä¸¦ä½¿ç¨è AI æç¨ç¸éççµ±è¨åç¬¦è AI æ¹æ³ - å®ç¨ä½¿ç¨ä»»ä½ä¸ç¨®æ¹æ³é½ä¸æå¥æãå æ­¤ï¼æåä¸»å¼µä¸¦è©¦åè­æ NeuroSymbolic AI æ¹æ³æ´é©åæ¼ä½¿ AI æçºåä¿¡ä»»ç AI ç³»çµ±ãæåæåºäº CREST æ¡æ¶ï¼å±ç¤ºäºä¸è´æ§ãå¯é æ§ãä½¿ç¨èå±¤ç´çå¯è§£éæ§åå®å¨æ§æ¯å¦ä½å»ºç«å¨ NeuroSymbolic æ¹æ³ä¸çï¼è©²æ¹æ³ä½¿ç¨æ¸æåç¥è­ä¾æ¯æééµæç¨ï¼ä¾å¦å¥åº·åç¦ç¥ï¼çè¦æ±ãæ¬æéé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼å çºå®æ¯ CREST æ¡æ¶ä¸­é¸æç AI ç³»çµ±ãLLM å å¶å¨èçå»£æ³çèªç¶èªè¨èç (NLP) å ´æ¯æ¹é¢çå¤åè½æ§èååç ç©¶äººå¡çéæ³¨ãä¾å¦ï¼ChatGPT å Google ç MedPaLM å·²æçºæä¾ä¸è¬åå¥åº·ç¸éæ¥è©¢ä¿¡æ¯çæ¥µæå¸æçå¹³å°ãåç®¡å¦æ­¤ï¼éäºæ¨¡åä»ç¶æ¯é»çå­ï¼åç®¡ç´å¥äºäººé¡åé¥åæä»¤å¼å°çèª¿æ´ãä¾å¦ï¼åç®¡å¶å®äºå®å¨é²è­·æªæ½ï¼ChatGPT ä»å¯è½ç¢çä¸å®å¨çåæãCREST æåºäºä¸ç¨®åççæ¹æ³ï¼å¨ NeuroSymbolic æ¡æ¶ä¸­å©ç¨ç¨åºååºæ¼åè¡¨çç¥è­ï¼ä»¥é¡æè LLM ç¸éçææ°ã

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

æè¦ï¼<paragraph>éè¦æ§ä¼°è¨å¨æ¯ä¸ç¨®å¯è§£éæ§æ¹æ³ï¼ç¨æ¼éåæ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) çç¹å¾µéè¦æ§ãå¨è¦è¦ºTransformer (ViT) ä¸­ï¼èªææ³¨ææ©å¶èªç¶æå°è´æ³¨æååï¼æææå°å¶è§£éçºéè¦æ§åæ¸ï¼è¡¨ç¤º ViT æ¨¡åéæ³¨åªäºè¼¸å¥ç¹å¾µãç¶èï¼æ³¨æååä¸¦æªèæ®ä¾èªä¸æ¸¸ä»»åçä¿¡èãçºäºç¢çå°ä¸æ¸¸ä»»åææçè§£éï¼æåéç¼äºé¡å¥ååæ³¨æåå (CDAM)ï¼éæ¯ä¸ç¨®åºæ¼æ¢¯åº¦çæ´åï¼ç¨æ¼ä¼°è¨ç¸å°æ¼å·²ç¥é¡å¥ææ½å¨æ¦å¿µçç¹å¾µéè¦æ§ãCDAM æ ¹æå°æçç¬¦èèåé¡å¨é ­çé æ¸¬ç¸éç¨åº¦ï¼èª¿æ´æ³¨æååæ¸ãé¤äºéå°ç£ç£åé¡å¨å¤ï¼CDAM éå¯ä»¥ééæ¸¬é ViT çæ½å¨ç©ºéä¸­çç¸ä¼¼æ§ä¾è§£éé¸å®æ¨£æ¬å±æçä»»ææ¦å¿µãæ­¤å¤ï¼æåå¼å¥äºå¹³æ» CDAM åç©å CDAMï¼å®åå°ä¸ç³»åå·æç¥å¾®æ¹è®çç¬¦èç CDAM é²è¡å¹³åãæåçéååºæºåæ¬æ­£ç¢ºæ§ãç·æ¹æ§åé¡å¥æææ§ï¼èå¶ä» 7 åéè¦æ§ä¼°è¨å¨ç¸æ¯ãé¦èãå¹³æ»åç©å CDAM å¨ææä¸ååºæºä¸­è¡¨ç¾åºè²ãç¹å¥æ¯ï¼æåççµæè¡¨æç¾æçéè¦æ§ä¼°è¨å¨å¯è½ç¡æ³æä¾è¶³å¤ çé¡å¥æææ§ãæåééåºæ¼èºé¨é»è¦æ·å±¤ææ (CT) ææè¨ç·´åè§£éæ¡æ§è«ç¤åçç©æ¨è¨é æ¸¬æ¨¡åï¼è­æäº CDAM å¨é«å­¸å½±åä¸­çæç¨ãç¸½çä¾èªªï¼CDAM è¢«è­æå·æé«åº¦é¡å¥ååæ§åèªç¾©ç¸éæ§ï¼åææä¾ç°¡æ½çè§£éã</paragraph>

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

æè¦ï¼æ¬ç ç©¶è°æ¥äºå¨ COVID-19 ç«ææé´åä»¥åé¢æµæ­»äº¡çæ¶ï¼å·²é¨ç½²äººå·¥æºè½ (AI) æ¨¡åçæ§è½ãå¯è§£éæ§åç¨³å¥æ§ãä½ä¸ºåç±»ç ç©¶ä¸­çé¦ä¾ï¼æä»¬åç°è´å¶æ¯ç¥ç»ç½ç» (BNN) åæºè½è®­ç»ææ¯è®©æä»¬çæ¨¡åå¨æ°æ®åçéå¤§ååæ¶ä»è½ä¿ææ§è½ãæä»¬çç»æå¼ºè°äºå¼åç¨³å¥ç AI æ¨¡åçéè¦æ§ï¼å³ä½¿å¨å·ææææ§çæ¡ä»¶ä¸ï¼è¿äºæ¨¡åä¹è½å¹éæè¶è¶ä¸´åºå»ççé¢æµãæä»¬å¯¹æ¨¡åå¯è§£éæ§çæ¢ç´¢è¡¨æï¼éæºæ¨¡åä¼äº§çæ´å¤æ ·åä¸ä¸ªæ§åçè§£éï¼ä»èçªåºäºå¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­æä¾è¯¦ç»ä¸ä¸ªæ§åè§è§£ç AI æ¨¡åçå¿è¦æ§ãæ­¤å¤ï¼æä»¬å¼ºè°äºéå AI æ¨¡åä¸­ä¸ç¡®å®æ§çéè¦æ§ï¼è¿ä½¿ä¸´åºå»çè½å¤æ ¹æ®å¯é çé¢æµååºæ´ææºçå³ç­ãæä»¬çç ç©¶æå¡å¨å»çä¿å¥ç AI ç ç©¶ä¸­ä¼åèèå®æ½ç§å­¦ï¼å¹¶ç¡®ä¿ AI è§£å³æ¹æ¡å¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­å®ç¨ãæçä¸å¯æç»­ãéè¿è§£å³å»çä¿å¥ç¯å¢ä¸­çç¬ç¹ææåå¤ææ§ï¼ç ç©¶äººåå¯ä»¥å¼ååºæææ¹åä¸´åºå®è·µåæ£èé¢åç AI æ¨¡åã

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

æè¦ï¼èºçå è±åççæ­»äº¡äººæ¸ç 21%ï¼äºå¹´å­æ´»çå¾å¤§ç¨åº¦åæ±ºæ¼ççè¢«ç¼ç¾çéæ®µãæè¿çç ç©¶å·²è­æäººå·¥æºè½æ¹æ³å·æå¾ä¾è¡ææä¸­æºç¢ºåæ©è¨ºæ·èºççè½åãç¶èï¼æ­¤è­æå°æªè½åçºè¨åºå¯¦åï¼å¶ä¸­ä¸åéç¤æ¯ç¼ºä¹å¯è§£éçæ¨¡åãæ¬ç ç©¶æ¢è¨äºæç¨è®åèªåç·¨ç¢¼å¨ (VAE)ï¼ä¸ç¨®çæå¼äººå·¥æºè½æ¨¡åï¼æ¼èºççç¶ãå°æåºçæ¨¡åè¨ç·´æ¼å¾ LIDC-IDRI å¬å±æ¸æéä¸­æåç 3D é»è¦æ·å±¤ææçç¶ãééèé¡æ¢ç´¢äº VAE çæç 2D åççæ½å¨åéè¡¨ç¤ºï¼ä»¥è­æå¶åè³ªï¼ä¸¦ç¨æ¼èºçè¨ºæ·ç MLP åé¡å¨æ¨¡åï¼æä½³æ¨¡åéå°äº AUC 0.98 å 93.1% æºç¢ºåº¦çæåé²ææ¨ãèé¡åæé¡¯ç¤ºï¼VAE æ½å¨ç©ºéæ ¹æææç¾©çç¹å¾µçµæï¼åæ¬è«ç¤å¤§å°ãå½¢çãæ£èåæ¡æ§é¡å¥ï¼å°æ¡æ§åè¯æ§çç¶çæ¸æéåéãæåéåæ¬æ¨æºé«æ¯ VAE (GVAE) åæ´æ°ççå©åé· VAE (DirVAE) çæ¯è¼åæï¼å¾èç¨çå©åé·åä½åä»£åé©ï¼ä»¥ä¿é²å·æè§£éç¹å¾µè¡¨ç¤ºçæ´å·å¯è§£éæ§çæ½å¨ç©ºéãæå¾ï¼æåå±ç¤ºäºèè¨åºææç¾©çç¹å¾µè®åç¸æçæ½å¨ç©ºéæ©«è¶çæ½åã

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

æè¦ï¼ç¾æçåååé¡å¨è¼¸åºè§£éå·¥å·å¯åçºä¾è³´æ¼æ¨¡åå§é¨å­åæ¬éçç½çï¼ä»¥åèæ¨¡åç¡éçé»çãé¨è AI å¨é«çé åçä½¿ç¨å¢å ï¼å¯è§£éæ§å·¥å·çä½¿ç¨ä¹é¨ä¹å¢å ãç¾æé«å­¸å½±åè§£éçå·¥ä½éé»å¨æ¼ç½çå·¥å·ï¼ä¾å¦ gradcamãç¶èï¼åæå°é»çå·¥å·ææé¡¯çåªé»ï¼åæ¬è½å¤ èä»»ä½åé¡å¨ä¸èµ·ä½¿ç¨ï¼ä»¥åå»£æ³çé»çå·¥å·å¯ä¾é¸æãå¨æ¨æºå½±åä¸ï¼é»çå·¥å·èç½çä¸æ¨£ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåæ¯è¼äºå¤ç¨®é»çæ¹æ³å¨è¦ç MRI è³æéä¸è gradcam çæè½ãæåè­æå¤§å¤æ¸é»çå·¥å·ä¸é©åè§£éé«å­¸å½±ååé¡ï¼ä¸¦è©³ç´°åæå¶ç¼ºé»çåå ãæåéè¡¨æä¸ç¨®é»çå·¥å·ï¼åºæ¼å æå¯è§£éæ§ç rexï¼è¡¨ç¾è \gradcam ä¸æ¨£å¥½ã

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

æè¦ï¼AI éç¼ç¤¾ç¾¤æ¥çå©ç¨ Hugging Face ç­è¨ç®¡ä¸­ä»æ©æ§æä¾ç¨æ¶ä¸å³çæ¨¡ååè¨ç·´è³æçç°¡æå­åæ¬éãéäºæ¨¡åå¸ééä½äºæ¸åè¬åç¨æ¶çæè¡é¨ç½²éç¤ï¼ä½å¯è½æè¢«ç¨æ¼è¨±å¤æ½å¨æå®³åéæ³çæ¹å¼ãå¨æ¬æä¸­ï¼æåèªªæ AI ç³»çµ±æ¢å¯ä»¥ãåå«ãå§å®¹ï¼åå¯ä»¥ä½çºéæ¾å¼å·¥å·ï¼éæåºäºè¿ä»çºæ­¢ææ£æçå¹³å°æ²»çææ°ä¹ä¸ãæåæä¾ Hugging FaceãGitHub å Civitai ç­ä¸åèªªææ§å¹³å°ä¸æ¸èµ·äºä»¶çæ¡ä¾ç ç©¶ï¼ä»¥æª¢è¦æ¨¡åå¸éå¦ä½å¯©æ ¸æ¨¡åãæ ¹ææ­¤åæï¼æåæ¦è¿°ç¢æ¥­çºåæå¯©æ ¸éæ±èéç¼çéè¦ï¼ä½ä»æéï¼å¯¦åï¼ææ¬ãå­ååä½¿ç¨éå¶ãèªååå§å®¹å¯©æ ¸åéæ¾æ¿ç­å¶å®ãéç¶ç¶åæ¿ç­ææ°ç¸ç¶å¯è§ï¼æåæå¾æåºä¸äºæ§æ³ï¼èªªæå¹³å°å¦ä½è½æ´å¥½å°åå¡è³æºï¼ä½çºè¬¹æãå¬å¹³ä¸é©åº¦çæ³è¦å­åé»ã

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

æè¦ï¼<paragraph>èæ¯åç®æ¨ï¼ééæåéäºè³è¨ï¼æ©å¨ææ·±åº¦å­¸ç¿ (ML/DL) åºæ¼èªä¸»æ¸æåæå·¥å·å¯ä»¥åå©è¨åºé«çåççç ç©¶äººå¡å¾è¤éçæ¸æéä¸­ç¼ç¾æ¨¡å¼åéä¿ãæè¿å·²ç¼è¡¨è¨±å¤åºæ¼ DL çåµå·¢ç (OC) æ¸æåæãéäºåæå¨çççååæ¹é¢ï¼ä¾å¦ï¼å®åæ¶åçå­é ååççé¡åï¼åæ¸æåæåè½æ¹é¢é«åº¦å¤æ¨£åãç¶èï¼ç®åç¼ºä¹å°éäºåæå¨éäºç¹å¾µå AI ä¿è­ (AIA) æ¹é¢çå¨é¢çè§£ãéç¯ç³»çµ±æ§åé¡§æ¨å¨ééæª¢è¦ç¾ææç»ä¸¦æç¢ºéæ³¨ééµç¹å¾µå AI ä¿è­è§é»ï¼ä¾å¡«è£éåç©ºç½ãæ¹æ³ï¼ä½¿ç¨ PRISMA æ¶æ§å¨ä¸åæåè³æåº«ä¸­é²è¡å¨é¢æå°ãåæååæ¬ 2015 å¹´è³ 2023 å¹´éç¼è¡¨æ¼åè¡è©å¯©æåçç ç©¶ãçµæï¼å¨åé¡§ä¸­ï¼ç¸½å±æª¢è¦äº 96 é ç± DL é©åçåæãç ç©¶çµææ­ç¤ºäºå¹¾åéæ¼ç± DL é©åçåµå·¢çæ¸æåæçéè¦è¦è§£ï¼- å¤§å¤æ¸ç ç©¶ 71%ï¼96 é ä¸­æ 68 é ï¼å°æ³¨æ¼æª¢æ¸¬åè¨ºæ·ï¼èæ²æç ç©¶æ¢è¨ OC çé æ¸¬åé é²ã- éäºåæä¸»è¦åºæ¼ä¾èªéå¤åæç¾¤çæ¨£æ¬ï¼75%ï¼96 é ç ç©¶ä¸­ç 72 é ï¼ï¼ï¼åéæ¼æåå°çä½ç½®æåå®¶ã- åªæå°é¨åç ç©¶ï¼å 33%ï¼96 é ç ç©¶ä¸­ç 32 é ï¼å·è¡æ´ååæï¼å¶ä¸­å¤§å¤æ¸ä½¿ç¨åè³ªæ¸æï¼è¨åºæçµå­¸ï¼ã- å¼å¾æ³¨æçæ¯ï¼åªæ 8.3%ï¼96 é ç ç©¶ä¸­ç 8 é ï¼ä½¿ç¨å¤é¨åå¤åæ¸æéé©è­äºå¶æ¨¡åï¼å¼·èª¿äºå å¼·æ¨¡åé©è­çå¿è¦æ§ï¼ä»¥å- å° AIA ç´å¥ççæ¸æåæä»èæ¼éå¸¸æ©æçéæ®µï¼åªæ 2.1%ï¼96 é ç ç©¶ä¸­ç 2 é ï¼ééå¯è§£éæ§æç¢ºæ¢è¨äº AIAã</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

æè¦ï¼<paragraph>è§£éæ§æ¯æ·±åº¦å­¸ç¿ä¸­é·æçææ°ï¼ç¹å¥æ¯å¨é«çä¿å¥ç­é«é¢¨éªé åãå¸¸è¦çè§£éæ§æ¹æ³æå¼·èª¿é©å AI æ¨¡åæ±ºç­çå½±åååãç¶èï¼äººé¡å¾å¤§ç¨åº¦ä¾è³´èªè¨ä¾å³éä¸åæ¯ãå¨åªè£¡ãï¼éæãæ¯ä»éº¼ãçè§£éãæ­¤å¤ï¼å¤§å¤æ¸è§£éæ§æ¹æ³é½å°æ³¨æ¼è§£éåå¥ AI é æ¸¬ï¼èä¸æ¯æè¿° AI æ¨¡åä¸è¬ä½¿ç¨çç¹å¾µãå¾èå°æ¼æ¨¡ååè³æéç¨½æ ¸ç¹å¥æç¨ï¼çè³å¯è½å¨ AI æä¾æç¨æ¼æ°ç©ä»»åæç¢çç¥è­ãå¨æ­¤ï¼æåæåºä¸åä½¿ç¨è¦è¦ºèªè¨æ¨¡åä¾è¾¨è­è¦è¦ºåé¡ä»»åçèªè¨æè¿°ç¬¦çè§£éæ§ç­ç¥ãééå©ç¨å½±ååæå­ä¹éé åè¨ç·´çè¯ååµå¥ç©ºéï¼æåçåæ³å°æ°çåé¡ä»»åä¼°è¨çºä¸åç·æ§æå­çµåï¼å°è´æ¯åæå­é½ææ¬éï¼è¡¨ç¤ºå®èåºæ¼è¦è¦ºçåé¡å¨å°é½ãæåä½¿ç¨å©åé«å­¸å½±ååé¡ä»»åä¾è©ä¼°æåçåæ³ï¼æåç¼ç¾ç¢ççæè¿°ç¬¦å¨å¾å¤§ç¨åº¦ä¸èè¨åºç¥è­ä¸è´ï¼åç®¡ç¼ºä¹ç¹å®é åçèªè¨è¨ç·´ãç¶èï¼æåçåæ³ä¹ç¼ç¾äºæç¨å¬éè³æéä¸­çãæ·å¾é£ç·ãçå¯è½æ§ãçºäºéå°è§£éæ§çåè½æ§è¡¡éï¼æåé²è¡äºä¸é è©¦é©è®èç ç©¶ï¼ç¼ç¾ AI è­å¥çæå­è½è®éå°å®¶äººé¡å¨éå¹³å¡çå±¤ç´å·è¡å°æ¥­çé«çä»»åãç¸½ä¹ï¼æåççµæå¼·èª¿äºä½¿ç¨å¤æ¨¡å¼åºç¤æ¨¡åä¾æä¾ç´è§çãåºæ¼èªè¨çè¦è¦ºä»»åè§£éçæ½åã</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

æè¦ï¼<paragraph>ä½¿ç¨é«çå½±åè¨ç·´çäººå·¥æºæ§ (AI) æ¨¡åï¼ç¨æ¼è¨åºä»»åæï¼å¸¸æå¨æè½ä¸å±ç¾åºæ¬¡ç¾¤é«ä¹éçå·®ç°ï¼å½¢æåè¦ãç±æ¼ä¸¦éææçå¯¦ä¸çé«çå½±åè³æä¸­çåè¦ä¾æºé½å®¹æè¾¨è­ï¼å æ­¤å¨é¢è©ä¼°éäºåè¦æ¯å¦ä½ç·¨ç¢¼å°æ¨¡åä¸­ï¼ä»¥ååè¦ç·©è§£æ¹æ³å¨æ¹åæè½å·®ç°æ¹é¢çè½åï¼æ¯ä¸é ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åæ°ç©çåææ¶æ§ï¼ç¨æ¼ç³»çµ±åä¸å®¢è§å°èª¿æ¥é«çå½±åä¸­çåè¦å° AI æ¨¡åçå½±é¿ãæåéç¼ä¸¦æ¸¬è©¦äºéåæ¶æ§ï¼ä»¥é²è¡åæ§çé»è¦æ¨¡æ¬è©¦é©ï¼ä½¿ç¨ä¸åå·¥å·ä¾è©ä¼°é«çå½±å AI ä¸­çåè¦ï¼è©²å·¥å·ç¨æ¼ç¢çå·æå·²ç¥ç¾çå½±é¿ååè¦ä¾æºçåæç£å±æ¯å½±åãå¯è¡æ§ééä½¿ç¨ä¸ååäºå¯¦åè¦æå¢ä¾è¡¡éæ¨¡æ¬åè¦ææå°å·ç©ç¥ç¶ç¶²è·¯ (CNN) åé¡å¨åä¸ååè¦ç·©è§£ç­ç¥çå½±é¿ï¼ä¸¦å±ç¤ºåºä¾ãåæé¡¯ç¤ºï¼ç¶ CNN å¨åæè³æéä¸åè¨æï¼æ¨¡æ¬åè¦æå°è´é æçæ¬¡ç¾¤é«æè½å·®ç°ãæ­¤å¤ï¼éæ°å æ¬è¢«èªçºæ¯æ­¤è¨­å®ä¸­ææåçåè¦ç·©è§£ç­ç¥ï¼æåå±ç¤ºäºè§£éæ§ AI æ¹æ³å¦ä½åå©ä½¿ç¨éåæ¶æ§èª¿æ¥æ¨¡åä¸­åè¦çè¡¨ç¾ãéç¼å¬å¹³ç AI æ¨¡åæ¯ä¸é éå¤§çææ°ï¼å çºé«çå½±åè³æéä¸­å¯è½å­å¨è¨±å¤ä¸ç¶å¸¸æªç¥çåè¦ä¾æºãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼å®¢è§å°ç ç©¶åè¦åç·©è§£ç­ç¥å°æ·±åº¦å­¸ç¿ç®¡ç·çå½±é¿ï¼éå¯ä»¥æ¯æ´å¥å¨ä¸è² è²¬ä»»çè¨åº AI çéç¼ã</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

æè¦ï¼æ©å¨å­¸ç¿çºèªåé æ¸¬ä¸­é¢¨å¾ççåå¶å°å¾©å¥çåææä¾äºæ¥µå¤§çæ½åãéé å·¥ä½çéå¤§ææ°åæ¬ç¥ç¶å½±åè³æçç¶­åº¦éå¸¸é«ãå¯ç¨æ¼å­¸ç¿çè³æéè¦æ¨¡ç¸å°è¼å°ï¼ä»¥åå¦ä½ææçµåç¥ç¶å½±ååè¡¨æ ¼è³æï¼ä¾å¦äººå£çµ±è¨è³è¨åè¨åºç¹å¾µï¼ãæ¬ææ ¹æå©ç¨®ç­ç¥è©ä¼°äºå¤ç¨®è§£æ±ºæ¹æ¡ãç¬¬ä¸ç¨®æ¯ä½¿ç¨ç¸½çµ MRI ææç 2D å½±åãç¬¬äºç¨®æ¯é¸ææå©æ¼æé«åé¡ç²¾ç¢ºåº¦çééµç¹å¾µãæ­¤å¤ï¼æåå¼å¥äºå¨çµåå¾ MRI ä¸­æåçæèè¶£ååèè¡¨æ ¼è³æçç¬¦èè¡¨ç¤ºçå½±åä¸è¨ç·´å·ç©ç¥ç¶ç¶²è·¯ (CNN) çæ°ç©æ¹æ³ãæåè©ä¼°äºä¸ç³»å CNN æ¶æ§ï¼2D å 3Dï¼ï¼éäºæ¶æ§å¨ MRI åè¡¨æ ¼è³æçä¸åè¡¨ç¤ºä¸é²è¡è¨ç·´ï¼ä»¥é æ¸¬ä¸­é¢¨å¾å£è¿°åçæè¿°è½åçç¶åæ¸¬éæ¯å¦å¨å¤±èªçæéå¤±èªçç¯åå§ãMRI åè¡¨æ ¼è³æä¾èª 758 ååè PLORAS ç ç©¶çè±èªä¸­é¢¨åå­èãåéå°çç¶å¤§å°çåºç·éè¼¯è¿´æ­¸åé¡æºç¢ºåº¦çº 0.678ï¼ç¶ä¾åºå å¥åå§ççå´éç¨åº¦åæ¢å¾©æéæï¼ä¸åè³ 0.757 å 0.813ãå¨å¾æ¯å MRI ææä¸­æå 8 åæèè¶£ååä¸¦å¨ 2D æ®å·®ç¥ç¶ç¶²è·¯ä¸­èçç¶å¤§å°ãåå§å´éç¨åº¦åæ¢å¾©æéçµåæï¼è§å¯å°æé«çåé¡æºç¢ºåº¦ 0.854ãæåçç ç©¶çµæå±ç¤ºäºå¦ä½å°å½±ååè¡¨æ ¼è³æçµåèµ·ä¾ä»¥ç²å¾é«æ¼ä¸­é¢¨å¾åé¡æºç¢ºåº¦ï¼å³ä½¿å¨æ©å¨å­¸ç¿è¡èªä¸­è³æéå¾å°çææ³ä¸ä¹æ¯å¦æ­¤ãæå¾ï¼æåæåºå¦ä½æ¹é²ç®åçæ¨¡åï¼ä»¥ä½¿ç¨ä¾èªé«é¢ææåçå½±åä¾å¯¦ç¾æ´é«çæºç¢ºåº¦ã

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºèçä»»åééµæç¨ç¨å¼æçä¸é åºæ¬éæ±ï¼ç¢ºä¿æ¡ç¨é»ç AI æ¨¡åçéæåº¦åå¯è§£éæ§ãXAI çéè¦æ§æ¶µèå¾é«çä¿å¥å°éèçåç¨®é åï¼å¨éäºé åä¸­ï¼äºè§£æ·±åº¦å­¸ç¿æ¼ç®æ³çæ±ºç­å¶å®éç¨è³ééè¦ãå¤§å¤æ¸åºæ¼ AI çé»è¦è¦è¦ºæ¨¡åéå¸¸æ¯é»çå­ï¼å æ­¤ï¼å¨å½±åèçä¸­æä¾æ·±åº¦ç¥ç¶ç¶²è·¯çå¯è§£éæ§å°æ¼å¶å¨é«å­¸å½±ååæãèªåé§é§åéæ¸¬æç¨ä¸­çå»£æ³æ¡ç¨åé¨ç½²è³ééè¦ãæè¿ï¼å·²éå°å½±ååé¡ä»»åå¼å¥äºå¤ç¨® XAI æ¹æ³ãç¸åå°ï¼å½±ååå²å¨å¯è§£éæ§çèæ¯ä¸åå°çéæ³¨ç¸å°è¼å°ï¼åç®¡å®æ¯é»è¦è¦è¦ºæç¨ä¸­çä¸é åºæ¬ä»»åï¼ç¹å¥æ¯å¨éæ¸¬ä¸­ãåªæé¨åç ç©¶æåºç¨æ¼å½±ååå²çåºæ¼æ¢¯åº¦ç XAI æ¼ç®æ³ãæ¬ææ¹ç·¨äºæè¿çç¡æ¢¯åº¦ Sobol XAI æ¹æ³ä»¥é²è¡èªæåå²ãçºäºè¡¡é Sobol æ¹æ³å¨åå²ä¸­çæè½ï¼æåæåºäºä¸ç¨®åºæ¼å¯å­¸ç¿éè¨æ¨¡åçå®é XAI è©ä¼°æ¹æ³ãæ­¤æ¨¡åçä¸»è¦ç®çæ¯å¨è§£éåä¸èªç¼éè¨ï¼å¶ä¸­è¼é«çèªç¼éè¨è¡¨ç¤ºè¼ä½çæºç¢ºåº¦ï¼åä¹äº¦ç¶ãé²è¡åºæºåæä»¥è©ä¼°åæ¯è¼ä¸ç¨® XAI æ¹æ³çæè½ï¼åæ¬ Seg-Grad-CAMãSeg-Grad-CAM++ å Seg-Sobolï¼ä¸¦ä½¿ç¨ææåºçåºæ¼éè¨çè©ä¼°æè¡ãéæ§æäºä½¿ç¨é«è§£æåº¦è¡æå½±åå·è¡åè©ä¼° XAI æ¹æ³çé¦æ¬¡åè©¦ã

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

æè¦ï¼å¤§åèªè¨æ¨¡åå¨ç­æéå§å·²å¨å¤åé åä¸­å¤§éæ¿å¢ãç¶èï¼ç±æ¼äºå¯¦æ§ãé£è²«æ§åå¹»è¦ºç­åé¡ï¼é«çåä¿å¥é åå°å¶æ¡ç¨ç¶è±«ä¸æ±ºãéæ¼é«çä¿å¥çé«é¢¨éªæ§è³ªï¼è¨±å¤ç ç©¶äººå¡çè³è­¦åä¸è¦ä½¿ç¨å®ï¼ç´å°éäºåé¡å¾å°è§£æ±ºãå¨é«çä¿å¥ä¸­å¯¦æ½åé¨ç½² LLM çééµæ¯ä½¿éäºæ¨¡åå¼å¾ä¿¡è³´ãéæï¼ç¡å¯è½å¤ï¼ä¸å¯è§£éãå¨æ¬æä¸­ï¼æåæè¿°äºå»ºç«å¯é ãå¼å¾ä¿¡è³´åç¡åè¦æ¨¡åçééµè¦ç´ ï¼ä½çºå®åå¨é«çä¿å¥ä¸­å¾å°æ¡ç¨çå¿è¦æ¢ä»¶ãå·é«ä¾èªªï¼æåå°æ³¨æ¼å¨é«çä¿å¥èæ¯ä¸å°å¹»è¦ºé²è¡éåãé©è­åç·©è§£ãæå¾ï¼æåè¨è«äº LLM å¨é«çä¿å¥ä¸­çæªä¾å¯è½æ¯ä»éº¼æ¨£å­ã

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·²å¿«éé²æ­¥ï¼ç¾å·²æºåé¨ç½²æ¼å»£æ³çæç¨ç¨å¼ä¸­ï¼ä¾å¦èªä¸»ç³»çµ±ãé«çè¨ºæ·åèªç¶èªè¨èçãåæ©æ¡ç¨ AI æè¡æ¼å¯¦éæç¨ç¨å¼ä¸¦éæ²æåé¡ï¼ç¹å¥æ¯å°æ¼ç¥ç¶ç¶²è·¯ï¼å®å¯è½ä¸ç©©å®ä¸å®¹æåå°å°ææ§ç¯ä¾çå½±é¿ãå¾é·é ä¾çï¼éè¦éç¼é©ç¶çå®å¨ä¿è­æè¡ï¼ä»¥æ¸å°å å¯é¿åçç³»çµ±æéèé æçæ½å¨å·å®³ï¼ä¸¦ç¢ºä¿å¯ä¿¡è³´æ§ãæ¬æèéæ¼èªè­åå¯è§£éæ§ï¼æ¦è¿°äºå·²éç¼ç¨æ¼ç¢ºä¿ AI æ±ºç­å®å¨çæè¡ï¼ä¸¦è¨è«æªä¾çææ°ã

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. GarcÃ­a-GÃ³mez, Vicent Blanes-Selva, JosÃ© Carlos de BartolomÃ© Cenzano, Jaime Cebolla-Cornejo, AscensiÃ³n DoÃ±ate-MartÃ­nez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

æè¦ï¼æ­æ´²è­°æè­°æç ç©¶æåç¸½å±å·²çºæ­æ´²è­°æè­°å¡æºåäºä¸ä»½å ±åï¼å¶ä¸­åèäºäººå·¥æºè½ (AI) å¨é«çä¿å¥é åçä¸é ä¸»è¦é¢¨éªï¼AI é¯èª¤å°è´æ£èåå°å·å®³ãé«ç AI å·¥å·è¢«æ¿«ç¨ãAI å­å¨åè¦ä¸¦å°è´ç¾æ inequities æçºå­å¨ãç¼ºä¹éæåº¦ãé±ç§åå®å¨åé¡ãåè²¬å·®è·ä»¥åå¯¦æ½éç¤ã
  å¨éé ç ç©¶ä¸­ï¼æåæåºäºååé åè½æ§è¦æ±ï¼AI ç³»çµ±å¯ä»¥å¯¦æ½éäºè¦æ±ä¾éä½èå¶é«çç®çç¸éçé¢¨éªï¼AI è­·ç§ãä½¿ç¨èç®¡çãæ³è¦æª¢æ¥ãåéå­¸è¡ç¨éåè²¬è²æãè³æåè³ªè©ä¼°ãè¨åºé«çééæª¢æ¥ãæçºæè½è©ä¼°ãç¨½æ ¸è¿½è¹¤ãæçºå¯ç¨æ§æ¸¬è©¦ãåé¡§åæº¯/æ¨¡æ¬æ¡ä¾ãåè¦æª¢æ¥ãå¯è§£é AIãå å¯åä½¿ç¨ç¶éå¯¦å°æ¸¬è©¦çç¨å¼åº«ï¼ä»¥åèªæäºéæ§ã
  æåå¨æ­¤çç®çæ¯æä¾æè¡è§£æ±ºæ¹æ¡çç¹å®é«éè¦æ ¼ï¼ä»¥ç¢ºä¿æçºè¯å¥½çæè½ï¼ä¸¦ä½¿ç¨ AI ç³»çµ±ï¼ä»¥ç¬¦åæªä¾çæ­çæ³è¦æ¶æ§ï¼å¾èä½¿æ£èåçã


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-30**|**DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET**|Yitong Li et.al.|[2410.23219v1](http://arxiv.org/abs/2410.23219v1)|null|
|**2024-10-30**|**Revisiting MAE pre-training for 3D medical image segmentation**|Tassilo Wald et.al.|[2410.23132v1](http://arxiv.org/abs/2410.23132v1)|null|
|**2024-10-30**|**SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry**|Ankita Kumari Jain et.al.|[2410.22950v1](http://arxiv.org/abs/2410.22950v1)|null|
|**2024-10-30**|**Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection**|Plabon Paul et.al.|[2410.22619v1](http://arxiv.org/abs/2410.22619v1)|null|
|**2024-10-29**|**Do Large Language Models Align with Core Mental Health Counseling Competencies?**|Viet Cuong Nguyen et.al.|[2410.22446v1](http://arxiv.org/abs/2410.22446v1)|null|
|**2024-10-29**|**MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for Efficient and Interpretable Medical Image Segmentation**|Ovais Iqbal Shah et.al.|[2410.22223v1](http://arxiv.org/abs/2410.22223v1)|null|
|**2024-10-29**|**Natural Language Processing for Analyzing Electronic Health Records and Clinical Notes in Cancer Research: A Review**|Muhammad Bilal et.al.|[2410.22180v1](http://arxiv.org/abs/2410.22180v1)|null|
|**2024-10-29**|**Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning**|Yinyi Lai et.al.|[2410.21872v1](http://arxiv.org/abs/2410.21872v1)|null|
|**2024-10-29**|**How Does Critical Batch Size Scale in Pre-training?**|Hanlin Zhang et.al.|[2410.21676v1](http://arxiv.org/abs/2410.21676v1)|null|
|**2024-10-29**|**A Tutorial on Clinical Speech AI Development: From Data Collection to Model Validation**|Si-Ioi Ng et.al.|[2410.21640v1](http://arxiv.org/abs/2410.21640v1)|null|
|**2024-10-28**|**Can Large Language Models Replace Data Scientists in Clinical Research?**|Zifeng Wang et.al.|[2410.21591v1](http://arxiv.org/abs/2410.21591v1)|null|
|**2024-10-28**|**Going Beyond H&E and Oncology: How Do Histopathology Foundation Models Perform for Multi-stain IHC and Immunology?**|Amaya Gallagher-Syed et.al.|[2410.21560v1](http://arxiv.org/abs/2410.21560v1)|[link](https://github.com/amayags/immunohistobench)|
|**2024-10-28**|**Towards Multi-dimensional Explanation Alignment for Medical Classification**|Lijie Hu et.al.|[2410.21494v1](http://arxiv.org/abs/2410.21494v1)|null|
|**2024-10-28**|**Multi-modal AI for comprehensive breast cancer prognostication**|Jan Witowski et.al.|[2410.21256v1](http://arxiv.org/abs/2410.21256v1)|null|
|**2024-10-28**|**Belief in the Machine: Investigating Epistemological Blind Spots of Language Models**|Mirac Suzgun et.al.|[2410.21195v1](http://arxiv.org/abs/2410.21195v1)|[link](https://github.com/suzgunmirac/belief-in-the-machine)|
|**2024-10-28**|**Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks**|Jiawei Zhang et.al.|[2410.21175v1](http://arxiv.org/abs/2410.21175v1)|null|
|**2024-10-28**|**Trajectory Flow Matching with Applications to Clinical Time Series Modeling**|Xi Zhang et.al.|[2410.21154v1](http://arxiv.org/abs/2410.21154v1)|[link](https://github.com/nzhangx/trajectoryflowmatching)|
|**2024-10-28**|**Informed Deep Abstaining Classifier: Investigating noise-robust training for diagnostic decision support systems**|Helen Schneider et.al.|[2410.21014v1](http://arxiv.org/abs/2410.21014v1)|null|
|**2024-10-28**|**Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering**|Zhilin Zhang et.al.|[2410.21000v1](http://arxiv.org/abs/2410.21000v1)|null|
|**2024-10-28**|**Large Language Model Benchmarks in Medical Tasks**|Lawrence K. Q. Yan et.al.|[2410.21348v1](http://arxiv.org/abs/2410.21348v1)|null|
|**2024-10-28**|**Vascular Segmentation of Functional Ultrasound Images using Deep Learning**|Hana Sebia et.al.|[2410.22365v1](http://arxiv.org/abs/2410.22365v1)|null|
|**2024-10-27**|**Language Models And A Second Opinion Use Case: The Pocket Professional**|David Noever et.al.|[2410.20636v1](http://arxiv.org/abs/2410.20636v1)|null|
|**2024-10-27**|**Improving Decision Sparsity**|Yiyang Sun et.al.|[2410.20483v1](http://arxiv.org/abs/2410.20483v1)|null|
|**2024-10-27**|**MedGo: A Chinese Medical Large Language Model**|Haitao Zhang et.al.|[2410.20428v1](http://arxiv.org/abs/2410.20428v1)|null|
|**2024-10-27**|**Addressing the Pitfalls of Image-Based Structural Health Monitoring: A Focus on False Positives, False Negatives, and Base Rate Bias**|Vagelis Plevris et.al.|[2410.20384v1](http://arxiv.org/abs/2410.20384v1)|null|
|**2024-10-27**|**R-LLaVA: Improving Med-VQA Understanding through Visual Region of Interest**|Xupeng Chen et.al.|[2410.20327v1](http://arxiv.org/abs/2410.20327v1)|null|
|**2024-10-27**|**Enhancing Community Vision Screening -- AI Driven Retinal Photography for Early Disease Detection and Patient Trust**|Xiaofeng Lei et.al.|[2410.20309v1](http://arxiv.org/abs/2410.20309v1)|null|
|**2024-10-26**|**Modelling of Economic Implications of Bias in AI-Powered Health Emergency Response Systems**|Katsiaryna Bahamazava et.al.|[2410.20229v1](http://arxiv.org/abs/2410.20229v1)|null|
|**2024-10-26**|**Generative AI in Health Economics and Outcomes Research: A Taxonomy of Key Definitions and Emerging Applications, an ISPOR Working Group Report**|Rachael Fleurence et.al.|[2410.20204v1](http://arxiv.org/abs/2410.20204v1)|null|
|**2024-10-26**|**Diff-CXR: Report-to-CXR generation through a disease-knowledge enhanced diffusion model**|Peng Huang et.al.|[2410.20165v1](http://arxiv.org/abs/2410.20165v1)|null|
|**2024-10-26**|**On-Site Precise Screening of SARS-CoV-2 Systems Using a Channel-Wise Attention-Based PLS-1D-CNN Model with Limited Infrared Signatures**|Wenwen Zhang et.al.|[2410.20132v1](http://arxiv.org/abs/2410.20132v1)|null|
|**2024-10-26**|**Transforming Precision: A Comparative Analysis of Vision Transformers, CNNs, and Traditional ML for Knee Osteoarthritis Severity Diagnosis**|Tasnim Sakib Apon et.al.|[2410.20062v1](http://arxiv.org/abs/2410.20062v1)|null|
|**2024-10-26**|**AutoMIR: Effective Zero-Shot Medical Information Retrieval without Relevance Labels**|Lei Li et.al.|[2410.20050v1](http://arxiv.org/abs/2410.20050v1)|[link](https://github.com/cmirb-benchmark/cmirb)|
|**2024-10-26**|**Off-Policy Selection for Initiating Human-Centric Experimental Design**|Ge Gao et.al.|[2410.20017v1](http://arxiv.org/abs/2410.20017v1)|null|
|**2024-10-25**|**DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**|Pengfei Hu et.al.|[2410.19955v1](http://arxiv.org/abs/2410.19955v1)|null|
|**2024-10-25**|**The Potential and Value of AI Chatbot in Personalized Cognitive Training**|Zilong Wang et.al.|[2410.19733v1](http://arxiv.org/abs/2410.19733v1)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-25**|**Enhancing Resilience and Scalability in Travel Booking Systems: A Microservices Approach to Fault Tolerance, Load Balancing, and Service Discovery**|Biman Barua et.al.|[2410.19701v1](http://arxiv.org/abs/2410.19701v1)|null|
|**2024-10-25**|**Deep learning-based identification of patients at increased risk of cancer using routine laboratory markers**|Vivek Singh et.al.|[2410.19646v1](http://arxiv.org/abs/2410.19646v1)|null|
|**2024-10-25**|**Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites**|NicolÃ¡s Nieto et.al.|[2410.19643v2](http://arxiv.org/abs/2410.19643v2)|null|
|**2024-10-24**|**Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use**|Mohit Chandra et.al.|[2410.19155v1](http://arxiv.org/abs/2410.19155v1)|null|
|**2024-10-24**|**CAMEL-Bench: A Comprehensive Arabic LMM Benchmark**|Sara Ghaboura et.al.|[2410.18976v1](http://arxiv.org/abs/2410.18976v1)|[link](https://github.com/mbzuai-oryx/CAMEL-Bench)|
|**2024-10-24**|**Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques**|David Ortiz-Perez et.al.|[2410.18972v1](http://arxiv.org/abs/2410.18972v1)|null|
|**2024-10-24**|**Demystifying Large Language Models for Medicine: A Primer**|Qiao Jin et.al.|[2410.18856v1](http://arxiv.org/abs/2410.18856v1)|[link](https://github.com/ncbi-nlp/llm-medicine-primer)|
|**2024-10-24**|**Health Misinformation in Social Networks: A Survey of IT Approaches**|Vasiliki Papanikou et.al.|[2410.18670v1](http://arxiv.org/abs/2410.18670v1)|null|
|**2024-10-24**|**Paved or unpaved? A Deep Learning derived Road Surface Global Dataset from Mapillary Street-View Imagery**|Sukanya Randhawa et.al.|[2410.19874v2](http://arxiv.org/abs/2410.19874v2)|null|
|**2024-10-24**|**Beyond Multiple-Choice Accuracy: Real-World Challenges of Implementing Large Language Models in Healthcare**|Yifan Yang et.al.|[2410.18460v1](http://arxiv.org/abs/2410.18460v1)|null|
|**2024-10-24**|**Multi-Stage Airway Segmentation in Lung CT Based on Multi-scale Nested Residual UNet**|Bingyu Yang et.al.|[2410.18456v1](http://arxiv.org/abs/2410.18456v1)|null|
|**2024-10-23**|**E2E-Swin-Unet++: An Enhanced End-to-End Swin-Unet Architecture With Dual Decoders For PTMC Segmentation**|Maryam Dialameh et.al.|[2410.18239v1](http://arxiv.org/abs/2410.18239v1)|null|
|**2024-10-23**|**Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration**|Max Wilcoxson et.al.|[2410.18076v1](http://arxiv.org/abs/2410.18076v1)|[link](https://github.com/rail-berkeley/supe)|
|**2024-10-23**|**Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**|Jaime Sevilla et.al.|[2410.18060v1](http://arxiv.org/abs/2410.18060v1)|null|
|**2024-10-23**|**AI driven health recommender**|K. Vignesh et.al.|[2410.17991v1](http://arxiv.org/abs/2410.17991v1)|null|
|**2024-10-23**|**MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers**|Zebin Yang et.al.|[2410.17957v1](http://arxiv.org/abs/2410.17957v1)|null|
|**2024-10-23**|**Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation**|Wenfang Yao et.al.|[2410.17918v1](http://arxiv.org/abs/2410.17918v1)|null|
|**2024-10-23**|**PGDiffSeg: Prior-Guided Denoising Diffusion Model with Parameter-Shared Attention for Breast Cancer Segmentation**|Feiyan Feng et.al.|[2410.17812v1](http://arxiv.org/abs/2410.17812v1)|null|
|**2024-10-23**|**Bonsai: Gradient-free Graph Distillation for Node Classification**|Mridul Gupta et.al.|[2410.17579v2](http://arxiv.org/abs/2410.17579v2)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**A 10.60 $Î¼$W 150 GOPS Mixed-Bit-Width Sparse CNN Accelerator for Life-Threatening Ventricular Arrhythmia Detection**|Yifan Qin et.al.|[2410.17395v1](http://arxiv.org/abs/2410.17395v1)|null|
|**2024-10-22**|**DeLLiriuM: A large language model for delirium prediction in the ICU using structured EHR**|Miguel Contreras et.al.|[2410.17363v1](http://arxiv.org/abs/2410.17363v1)|null|
|**2024-10-22**|**EEG-DIF: Early Warning of Epileptic Seizures through Generative Diffusion Model-based Multi-channel EEG Signals Forecasting**|Zekun Jiang et.al.|[2410.17343v1](http://arxiv.org/abs/2410.17343v1)|[link](https://github.com/jzk00/eeg-dif)|
|**2024-10-22**|**Revealing Hidden Bias in AI: Lessons from Large Language Models**|Django Beatty et.al.|[2410.16927v1](http://arxiv.org/abs/2410.16927v1)|null|
|**2024-10-22**|**SleepCoT: A Lightweight Personalized Sleep Health Model via Chain-of-Thought Distillation**|Huimin Zheng et.al.|[2410.16924v1](http://arxiv.org/abs/2410.16924v1)|null|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-22**|**50 questions on Active Assisted Living technologies. Global edition**|Francisco Florez-Revuelta et.al.|[2410.16733v1](http://arxiv.org/abs/2410.16733v1)|null|
|**2024-10-22**|**Development of CNN Architectures using Transfer Learning Methods for Medical Image Classification**|Ganga Prasad Basyal et.al.|[2410.16711v1](http://arxiv.org/abs/2410.16711v1)|null|
|**2024-10-22**|**Privacy-hardened and hallucination-resistant synthetic data generation with logic-solvers**|Mark A. Burgess et.al.|[2410.16705v1](http://arxiv.org/abs/2410.16705v1)|null|
|**2024-10-22**|**AskBeacon -- Performing genomic data exchange and analytics with natural language**|Anuradha Wickramarachchi et.al.|[2410.16700v2](http://arxiv.org/abs/2410.16700v2)|null|
|**2024-10-22**|**Visual Question Answering in Ophthalmology: A Progressive and Practical Perspective**|Xiaolan Chen et.al.|[2410.16662v1](http://arxiv.org/abs/2410.16662v1)|null|
|**2024-10-21**|**How Can We Diagnose and Treat Bias in Large Language Models for Clinical Decision-Making?**|Kenza Benkirane et.al.|[2410.16574v1](http://arxiv.org/abs/2410.16574v1)|null|
|**2024-10-21**|**Large language models enabled multiagent ensemble method for efficient EHR data labeling**|Jingwei Huang et.al.|[2410.16543v1](http://arxiv.org/abs/2410.16543v1)|null|
|**2024-10-21**|**AEPL: Automated and Editable Prompt Learning for Brain Tumor Segmentation**|Yongheng Sun et.al.|[2410.19847v1](http://arxiv.org/abs/2410.19847v1)|null|
|**2024-10-21**|**Teach Multimodal LLMs to Comprehend Electrocardiographic Images**|Ruoqi Liu et.al.|[2410.19008v1](http://arxiv.org/abs/2410.19008v1)|null|
|**2024-10-21**|**R2Gen-Mamba: A Selective State Space Model for Radiology Report Generation**|Yongheng Sun et.al.|[2410.18135v1](http://arxiv.org/abs/2410.18135v1)|[link](https://github.com/YonghengSun1997/R2Gen-Mamba)|
|**2024-10-21**|**MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays, ECGs, and Diagnostic Report**|Samrajya Thapa et.al.|[2410.16239v2](http://arxiv.org/abs/2410.16239v2)|[link](https://github.com/svthapa/more)|
|**2024-10-21**|**On Creating an English-Thai Code-switched Machine Translation in Medical Domain**|Parinthapat Pengpun et.al.|[2410.16221v1](http://arxiv.org/abs/2410.16221v1)|[link](https://github.com/preceptorai-org/nllb_cs_em_nlp2024)|
|**2024-10-21**|**GenAI Assisting Medical Training**|Stefan Fritsch et.al.|[2410.16164v1](http://arxiv.org/abs/2410.16164v1)|null|
|**2024-10-21**|**Fine-Tuning LLMs for Reliable Medical Question-Answering Services**|Ali Anaissi et.al.|[2410.16088v1](http://arxiv.org/abs/2410.16088v1)|null|
|**2024-10-21**|**1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and Large Language Models for Medical Text Classification**|Ram Mohan Rao Kadiyala et.al.|[2410.15998v1](http://arxiv.org/abs/2410.15998v1)|null|
|**2024-10-21**|**Random Token Fusion for Multi-View Medical Diagnosis**|Jingyu Guo et.al.|[2410.15847v1](http://arxiv.org/abs/2410.15847v1)|null|
|**2024-10-21**|**MAC Revivo: Artificial Intelligence Paves the Way**|Jinzhe Pan et.al.|[2410.15820v1](http://arxiv.org/abs/2410.15820v1)|null|
|**2024-10-21**|**Unleashing the Potential of Vision-Language Pre-Training for 3D Zero-Shot Lesion Segmentation via Mask-Attribute Alignment**|Yankai Jiang et.al.|[2410.15744v1](http://arxiv.org/abs/2410.15744v1)|null|
|**2024-10-21**|**Resource-Efficient Medical Report Generation using Large Language Models**|Abdullah et.al.|[2410.15642v1](http://arxiv.org/abs/2410.15642v1)|null|
|**2024-10-20**|**Improving Clinical Documentation with AI: A Comparative Study of Sporo AI Scribe and GPT-4o mini**|Chanseo Lee et.al.|[2410.15528v1](http://arxiv.org/abs/2410.15528v1)|null|
|**2024-10-20**|**Anonymising Elderly and Pathological Speech: Voice Conversion Using DDSP and Query-by-Example**|Suhita Ghosh et.al.|[2410.15500v1](http://arxiv.org/abs/2410.15500v1)|[link](https://github.com/suhitaghosh10/ddsp-qbe)|
|**2024-10-20**|**Multi-Layer Feature Fusion with Cross-Channel Attention-Based U-Net for Kidney Tumor Segmentation**|Fnu Neha et.al.|[2410.15472v2](http://arxiv.org/abs/2410.15472v2)|null|
|**2024-10-20**|**Hallucination Detox: Sensitive Neuron Dropout (SeND) for Large Language Model Training**|Shahrad Mohammadzadeh et.al.|[2410.15460v1](http://arxiv.org/abs/2410.15460v1)|null|
|**2024-10-20**|**Concept Complement Bottleneck Model for Interpretable Medical Image Diagnosis**|Hongmei Wang et.al.|[2410.15446v1](http://arxiv.org/abs/2410.15446v1)|null|
|**2024-10-20**|**AttCDCNet: Attention-enhanced Chest Disease Classification using X-Ray Images**|Omar Hesham Khater et.al.|[2410.15437v1](http://arxiv.org/abs/2410.15437v1)|null|
|**2024-10-20**|**MMCS: A Multimodal Medical Diagnosis System Integrating Image Analysis and Knowledge-based Departmental Consultation**|Yi Ren et.al.|[2410.15403v1](http://arxiv.org/abs/2410.15403v1)|null|
|**2024-10-19**|**AutoFLUKA: A Large Language Model Based Framework for Automating Monte Carlo Simulations in FLUKA**|Zavier Ndum Ndum et.al.|[2410.15222v1](http://arxiv.org/abs/2410.15222v1)|null|
|**2024-10-19**|**Medical-GAT: Cancer Document Classification Leveraging Graph-Based Residual Network for Scenarios with Limited Data**|Elias Hossain et.al.|[2410.15198v2](http://arxiv.org/abs/2410.15198v2)|null|
|**2024-10-19**|**Fine-tuning foundational models to code diagnoses from veterinary health records**|Mayla R. Boguslav et.al.|[2410.15186v1](http://arxiv.org/abs/2410.15186v1)|null|
|**2024-10-19**|**LLaVA-Ultra: Large Chinese Language and Vision Assistant for Ultrasound**|Xuechen Guo et.al.|[2410.15074v1](http://arxiv.org/abs/2410.15074v1)|null|
|**2024-10-19**|**A General-Purpose Multimodal Foundation Model for Dermatology**|Siyuan Yan et.al.|[2410.15038v1](http://arxiv.org/abs/2410.15038v1)|[link](https://github.com/SiyuanYan1/PanDerm)|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-19**|**Water quality polluted by total suspended solids classified within an Artificial Neural Network approach**|I. Luviano Soto et.al.|[2410.14929v1](http://arxiv.org/abs/2410.14929v1)|null|
|**2024-10-18**|**Less is More: Selective Reduction of CT Data for Self-Supervised Pre-Training of Deep Learning Models with Contrastive Learning Improves Downstream Classification Performance**|Daniel Wolf et.al.|[2410.14524v1](http://arxiv.org/abs/2410.14524v1)|[link](https://github.com/Wolfda95/Less_is_More)|
|**2024-10-18**|**Enabling Scalable Evaluation of Bias Patterns in Medical LLMs**|Hamed Fayyaz et.al.|[2410.14763v1](http://arxiv.org/abs/2410.14763v1)|[link](https://github.com/healthylaife/autofair)|
|**2024-10-18**|**A Scientific Machine Learning Approach for Predicting and Forecasting Battery Degradation in Electric Vehicles**|Sharv Murgai et.al.|[2410.14347v1](http://arxiv.org/abs/2410.14347v1)|null|
|**2024-10-18**|**Deep Learning Applications in Medical Image Analysis: Advancements, Challenges, and Future Directions**|Aimina Ali Eli et.al.|[2410.14131v1](http://arxiv.org/abs/2410.14131v1)|null|

#### Abstracts
##### **DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET**
2410.23219v1 by Yitong Li, Morteza Ghahremani, Youssef Wally, Christian Wachinger

Diagnosing dementia, particularly for Alzheimer's Disease (AD) and
frontotemporal dementia (FTD), is complex due to overlapping symptoms. While
magnetic resonance imaging (MRI) and positron emission tomography (PET) data
are critical for the diagnosis, integrating these modalities in deep learning
faces challenges, often resulting in suboptimal performance compared to using
single modalities. Moreover, the potential of multi-modal approaches in
differential diagnosis, which holds significant clinical importance, remains
largely unexplored. We propose a novel framework, DiaMond, to address these
issues with vision Transformers to effectively integrate MRI and PET. DiaMond
is equipped with self-attention and a novel bi-attention mechanism that
synergistically combine MRI and PET, alongside a multi-modal normalization to
reduce redundant dependency, thereby boosting the performance. DiaMond
significantly outperforms existing multi-modal methods across various datasets,
achieving a balanced accuracy of 92.4% in AD diagnosis, 65.2% for AD-MCI-CN
classification, and 76.5% in differential diagnosis of AD and FTD. We also
validated the robustness of DiaMond in a comprehensive ablation study. The code
is available at https://github.com/ai-med/DiaMond.

æè¦ï¼è¨ºæ·å¤±æºçï¼å°¤å¶æ¯é¿è²æµ·é»ç (AD) åé¡é¡³èåå¤±æºç (FTD)ï¼ç±æ¼ççéçï¼å æ­¤å¾è¤éãéç¶ç£å±æ¯é å½± (MRI) åæ­£å­æ·å±¤ææ (PET) æ¸æå°æ¼è¨ºæ·è³ééè¦ï¼ä½å°éäºæ¹å¼æ´åå°æ·±åº¦å­¸ç¿ä¸­æé¢è¨ææ°ï¼éå¸¸æå°è´èä½¿ç¨å®ä¸æ¹å¼ç¸æ¯æ§è½ä¸ä½³ãæ­¤å¤ï¼å¤æ¨¡å¼æ¹æ³å¨éå¥è¨ºæ·ä¸­çæ½åå·æéè¦çè¨åºæç¾©ï¼ä½ä»æªå¾å°ååæ¢ç´¢ãæåæåºä¸åæ°çæ¡æ¶ DiaMondï¼ä»¥è§£æ±ºéäºåé¡ï¼ä½¿ç¨è¦è¦ºè½æå¨æææ´å MRI å PETãDiaMond å·åèªæ³¨æååæ°ç©çéæ³¨æåæ©å¶ï¼å¯ä»¥ååçµå MRI å PETï¼ä¸¦æ¡ç¨å¤æ¨¡å¼æ­£è¦åä¾æ¸å°åé¤ä¾è³´ï¼å¾èæåæ§è½ãDiaMond å¨åç¨®æ¸æéä¸­çè¡¨ç¾æé¡¯åªæ¼ç¾æçå¤æ¨¡å¼æ¹æ³ï¼å¨ AD è¨ºæ·ä¸­éå° 92.4% çå¹³è¡¡æºç¢ºåº¦ï¼å¨ AD-MCI-CN åé¡ä¸­éå° 65.2%ï¼å¨ AD å FTD çéå¥è¨ºæ·ä¸­éå° 76.5%ãæåéå¨å¨é¢çæ¶èç ç©¶ä¸­é©è­äº DiaMond çç©©å¥æ§ãç¨å¼ç¢¼å¯å¨ https://github.com/ai-med/DiaMond åå¾ã

##### **Revisiting MAE pre-training for 3D medical image segmentation**
2410.23132v1 by Tassilo Wald, Constantin Ulrich, Stanislav Lukyanenko, Andrei Goncharov, Alberto Paderno, Leander Maerkisch, Paul F. JÃ¤ger, Klaus Maier-Hein

Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the
potential of vast, untapped clinical datasets, for various downstream
applications that suffer from the scarcity of labeled data. While SSL has
revolutionized fields like natural language processing and computer vision,
their adoption in 3D medical image computing has been limited by three key
pitfalls: Small pre-training dataset sizes, architectures inadequate for 3D
medical image analysis, and insufficient evaluation practices. We address these
issues by i) leveraging a large-scale dataset of 44k 3D brain MRI volumes and
ii) using a Residual Encoder U-Net architecture within the state-of-the-art
nnU-Net framework. iii) A robust development framework, incorporating 5
development and 8 testing brain MRI segmentation datasets, allowed
performance-driven design decisions to optimize the simple concept of Masked
Auto Encoders (MAEs) for 3D CNNs. The resulting model not only surpasses
previous SSL methods but also outperforms the strong nnU-Net baseline by an
average of approximately 3 Dice points. Furthermore, our model demonstrates
exceptional stability, achieving the highest average rank of 2 out of 7
methods, compared to the second-best method's mean rank of 3.

æè¦ï¼èªçç£å­¦ä¹  (SSL) ä¸ºè§£éå¤§éæªå¼åä¸´åºæ°æ®éçæ½åæä¾äºä¸ä¸ªæ¿å¨äººå¿çæºä¼ï¼ç¨äºåç§ä¸æ¸¸åºç¨ç¨åºï¼è¿äºåºç¨ç¨åºå æ è®°æ°æ®ç¨ç¼ºèåå°å½±åãè½ç¶ SSL å·²å½»åºæ¹åäºèªç¶è¯­è¨å¤çåè®¡ç®æºè§è§ç­é¢åï¼ä½å¶å¨ 3D å»å­¦å¾åè®¡ç®ä¸­çéç¨åå°ä¸ä¸ªä¸»è¦ç¼ºé·çéå¶ï¼å°åé¢è®­ç»æ°æ®éå¤§å°ãä¸éç¨äº 3D å»å­¦å¾ååæçæ¶æä»¥åè¯ä¼°å®è·µä¸è¶³ãæä»¬éè¿ä»¥ä¸æ¹å¼è§£å³è¿äºé®é¢ï¼i) å©ç¨ 44k 3D å¤§è MRI ä½ç§¯çå¤§è§æ¨¡æ°æ®éï¼ä»¥å ii) å¨æåè¿ç nnU-Net æ¡æ¶åä½¿ç¨æ®å·®ç¼ç å¨ U-Net æ¶æãiii) ä¸ä¸ªç¨³å¥çå¼åæ¡æ¶ï¼åå« 5 ä¸ªå¼åå 8 ä¸ªæµè¯å¤§è MRI åå²æ°æ®éï¼åè®¸åºäºæ§è½çè®¾è®¡å³ç­æ¥ä¼å 3D CNN çæ©è½èªå¨ç¼ç å¨ (MAE) çç®åæ¦å¿µãç±æ­¤äº§ççæ¨¡åä¸ä»è¶è¶äºä¹åç SSL æ¹æ³ï¼èä¸æ¯å¼ºå¤§ç nnU-Net åºçº¿å¹³åé«åºå¤§çº¦ 3 ä¸ªéª°å­ç¹ãæ­¤å¤ï¼æä»¬çæ¨¡åè¡¨ç°åºéå¡çç¨³å®æ§ï¼å¨ 7 ç§æ¹æ³ä¸­è¾¾å° 2 çæé«å¹³åæåï¼èç¬¬äºå¥½çæ¹æ³çå¹³åæåä¸º 3ã

##### **SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry**
2410.22950v1 by Ankita Kumari Jain, Nitish Sharma, Madhav Kanda, Nipun Batra

Respiratory illnesses are a significant global health burden. Respiratory
illnesses, primarily Chronic obstructive pulmonary disease (COPD), is the
seventh leading cause of poor health worldwide and the third leading cause of
death worldwide, causing 3.23 million deaths in 2019, necessitating early
identification and diagnosis for effective mitigation. Among the diagnostic
tools employed, spirometry plays a crucial role in detecting respiratory
abnormalities. However, conventional clinical spirometry methods often entail
considerable costs and practical limitations like the need for specialized
equipment, trained personnel, and a dedicated clinical setting, making them
less accessible. To address these challenges, wearable spirometry technologies
have emerged as promising alternatives, offering accurate, cost-effective, and
convenient solutions. The development of machine learning models for wearable
spirometry heavily relies on the availability of high-quality ground truth
spirometry data, which is a laborious and expensive endeavor. In this research,
we propose using active learning, a sub-field of machine learning, to mitigate
the challenges associated with data collection and labeling. By strategically
selecting samples from the ground truth spirometer, we can mitigate the need
for resource-intensive data collection. We present evidence that models trained
on small subsets obtained through active learning achieve comparable/better
results than models trained on the complete dataset.

æè¦ï¼å¼å¸éç¾çæ¯å¨çéå¤§çå¥åº·è² æãå¼å¸éç¾çï¼ä¸»è¦æ¯æ¢æ§é»å¡æ§èºç (COPD)ï¼æ¯å¨çç¬¬ä¸å¤§ä¸è¯å¥åº·åå ï¼ä¹æ¯å¨çç¬¬ä¸å¤§æ­»äº¡åå ï¼2019 å¹´é æ 323 è¬äººæ­»äº¡ï¼éè¦åæ©è­å¥åè¨ºæ·ä»¥æææ¸è¼ççãå¨ææ¡ç¨çè¨ºæ·å·¥å·ä¸­ï¼èºæ´»éæ¸¬éå¨æª¢æ¸¬å¼å¸éç°å¸¸æ¹é¢ç¼æ®èè³ééè¦çä½ç¨ãç¶èï¼å³çµ±çè¨åºèºæ´»éæ¸¬éæ¹æ³éå¸¸éè¦å¤§éçææ¬åå¯¦ééå¶ï¼ä¾å¦éè¦å°æ¥­è¨­åãè¨ç·´æç´ çäººå¡åå°éçè¨åºç°å¢ï¼éä½¿å¾å®åçå¯åæ§è¼ä½ãçºäºæå°éäºææ°ï¼å¯ç©¿æ´å¼èºæ´»éæ¸¬éæè¡å·²æçºæå¸æçæ¿ä»£æ¹æ¡ï¼æä¾æºç¢ºãç¶æ¿é«æä¸ä¾¿å©çè§£æ±ºæ¹æ¡ãå¯ç©¿æ´å¼èºæ´»éæ¸¬éæ©å¨å­¸ç¿æ¨¡åçéç¼å¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼é«åè³ªçåºæºèºæ´»éæ¸¬éæ¸æï¼éæ¯ä¸é è²»æä¸æè²´çå·¥ä½ãå¨éé ç ç©¶ä¸­ï¼æåå»ºè­°ä½¿ç¨ä¸»åå­¸ç¿ï¼æ©å¨å­¸ç¿çä¸åå­é åï¼ä¾æ¸è¼èæ¸ææ¶éåæ¨è¨ç¸éçææ°ãééå¾åºæºèºæ´»éè¨ä¸­ç­ç¥æ§å°é¸ææ¨£æ¬ï¼æåå¯ä»¥æ¸å°å°è³æºå¯éåæ¸ææ¶éçéæ±ãæåæä¾çè­æè¡¨æï¼å¨ééä¸»åå­¸ç¿ç²å¾çå°å­éä¸­è¨ç·´çæ¨¡åï¼ç²å¾ççµæèå¨å®æ´æ¸æéä¸è¨ç·´çæ¨¡åç¸ç¶/æ´å¥½ã

##### **Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection**
2410.22619v1 by Plabon Paul, Md. Nazmul Islam, Fazle Rafsani, Pegah Khorasani, Shovito Barua Soumma

Uncontrolled cell division in the brain is what gives rise to brain tumors.
If the tumor size increases by more than half, there is little hope for the
patient's recovery. This emphasizes the need of rapid and precise brain tumor
diagnosis. When it comes to analyzing, diagnosing, and planning therapy for
brain tumors, MRI imaging plays a crucial role. A brain tumor's development
history is crucial information for doctors to have. When it comes to
distinguishing between human soft tissues, MRI scans are superior. In order to
get reliable classification results from MRI scans quickly, deep learning is
one of the most practical methods. Early human illness diagnosis has been
demonstrated to be more accurate when deep learning methods are used. In the
case of diagnosing a brain tumor, when even a little misdiagnosis might have
serious consequences, accuracy is especially important. Disclosure of brain
tumors in medical images is still a difficult task. Brain MRIs are notoriously
imprecise in revealing the presence or absence of tumors. Using MRI scans of
the brain, a Convolutional Neural Network (CNN) was trained to identify the
presence of a tumor in this research. Results from the CNN model showed an
accuracy of 99.17%. The CNN model's characteristics were also retrieved. In
order to evaluate the CNN model's capability for processing images, we applied
the features via the following machine learning models: KNN, Logistic
regression, SVM, Random Forest, Naive Bayes, and Perception. CNN and machine
learning models were also evaluated using the standard metrics of Precision,
Recall, Specificity, and F1 score. The significance of the doctor's diagnosis
enhanced the accuracy of the CNN model's assistance in identifying the
existence of tumor and treating the patient.

æè¦ï¼è¦é¨ç´°èåè£å¤±æ§ï¼å°±æç¢çè¦ç¤ã
å¦æè«ç¤å¤§å°å¢å è¶éä¸åï¼çæ£åº·å¾©çå¸æå¾æ¸ºè«ãéå¼·èª¿äºå¿«éä¸ç²¾æºè¨ºæ·è¦ç¤çå¿è¦æ§ã
å¨åæãè¨ºæ·åè¦åè¦ç¤æ²»çæï¼æ ¸ç£å±æ¯é å½±æ®æ¼äºè³ééè¦çè§è²ãè¦ç¤çç¼å±å²æ¯é«çå¿åçéè¦è³è¨ã
å¨ååäººé«è»çµç¹æï¼æ ¸ç£å±æ¯ææçè¡¨ç¾åªç°ãçºäºå¾æ ¸ç£å±æ¯ææä¸­å¿«éåå¾å¯é çåé¡çµæï¼æ·±åº¦å­¸ç¿æ¯æå¯¦ç¨çæ¹æ³ä¹ä¸ã
ç ç©¶é¡¯ç¤ºï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³å¯ä»¥æ´æºç¢ºå°è¨ºæ·äººé¡æ©æç¾çãå¨è¨ºæ·è¦ç¤æï¼å³ä½¿æ¯è¼å¾®çèª¤è¨ºé½å¯è½é æå´éå¾æï¼å æ­¤æºç¢ºæ§ç¹å¥éè¦ã
å¨é«å­¸å½±åä¸­æ­é²è¦ç¤ä»ç¶æ¯ä¸é è±é£çä»»åãè¦é¨æ ¸ç£å±æ¯é å½±å¨æ­é²è«ç¤çå­å¨èå¦æ¹é¢åºäºåçä¸ç²¾ç¢ºã
æ¬ç ç©¶è¨ç·´äºä¸åå·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼ä½¿ç¨è¦é¨æ ¸ç£å±æ¯ææä¾è¾¨è­è«ç¤çå­å¨ãCNN æ¨¡åççµæé¡¯ç¤ºæºç¢ºåº¦çº 99.17%ãCNN æ¨¡åçç¹å¾µä¹å·²æ·åã
çºäºè©ä¼° CNN æ¨¡åèçå½±åçè½åï¼æåééä»¥ä¸æ©å¨å­¸ç¿æ¨¡åå¥ç¨éäºç¹å¾µï¼KNNãéè¼¯è¿´æ­¸ãSVMãé¨æ©æ£®æãæ¨¸ç´ è²æ°åæç¥å¨ãCNN åæ©å¨å­¸ç¿æ¨¡åä¹ä½¿ç¨ç²¾æºåº¦ãå¬åçãç¹ç°æ§å F1 åæ¸ç­æ¨æºææ¨é²è¡è©ä¼°ã
é«ççè¨ºæ·æç¾©æåäº CNN æ¨¡åå¨åå©è¾¨è­è«ç¤å­å¨åæ²»ççæ£æ¹é¢çæºç¢ºæ§ã

##### **Do Large Language Models Align with Core Mental Health Counseling Competencies?**
2410.22446v1 by Viet Cuong Nguyen, Mohammad Taher, Dongwan Hong, Vinicius Konkolics Possobom, Vibha Thirunellayi Gopalakrishnan, Ekta Raj, Zihang Li, Heather J. Soled, Michael L. Birnbaum, Srijan Kumar, Munmun De Choudhury

The rapid evolution of Large Language Models (LLMs) offers promising
potential to alleviate the global scarcity of mental health professionals.
However, LLMs' alignment with essential mental health counseling competencies
remains understudied. We introduce CounselingBench, a novel NCMHCE-based
benchmark evaluating LLMs across five key mental health counseling
competencies. Testing 22 general-purpose and medical-finetuned LLMs, we find
frontier models exceed minimum thresholds but fall short of expert-level
performance, with significant variations: they excel in Intake, Assessment &
Diagnosis yet struggle with Core Counseling Attributes and Professional
Practice & Ethics. Medical LLMs surprisingly underperform generalist models
accuracy-wise, while at the same time producing slightly higher-quality
justifications but making more context-related errors. Our findings highlight
the complexities of developing AI systems for mental health counseling,
particularly for competencies requiring empathy and contextual understanding.
We found that frontier LLMs perform at a level exceeding the minimal required
level of aptitude for all key mental health counseling competencies, but fall
short of expert-level performance, and that current medical LLMs do not
significantly improve upon generalist models in mental health counseling
competencies. This underscores the critical need for specialized, mental health
counseling-specific fine-tuned LLMs that rigorously aligns with core
competencies combined with appropriate human supervision before any responsible
real-world deployment can be considered.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éç¼å±ï¼æä¾äºç·©è§£å¨çå¿çå¥åº·å°æ¥­äººå¡ç­ç¼ºçæ½å¨å¸æã
ç¶èï¼LLM èåºæ¬å¿çå¥åº·è«®åè½åçå°é½ç¨åº¦ï¼ä»æªç²å¾ååç ç©¶ãæåå¼å¥äº CounselingBenchï¼ä¸ååºæ¼ NCMHCE çæ°åºæºï¼ç¨æ¼è©ä¼° LLM å¨äºé ééµå¿çå¥åº·è«®åè½åä¸çè¡¨ç¾ãæåæ¸¬è©¦äº 22 åéç¨åé«å­¸å¾®èª¿ç LLMï¼ç¼ç¾åæ²¿æ¨¡åè¶éäºæä½éæª»ï¼ä½æªéå°å°å®¶ç´å¥çè¡¨ç¾ï¼ä¸å·®ç°é¡¯èï¼å®åå¨ãæåãè©ä¼°åè¨ºæ·ãæ¹é¢è¡¨ç¾åºè²ï¼ä½å¨ãæ ¸å¿è«®åå±¬æ§ãåãå°æ¥­å¯¦ååå«çãæ¹é¢å»æå°é£ãä»¤äººé©è¨çæ¯ï¼é«ç LLM å¨æºç¢ºæ§æ¹é¢è¡¨ç¾ä¸å¦éç¨æ¨¡åï¼ä½åæç¢çççç±åè³ªç¥é«ï¼ä½ç¢çæ´å¤èèçµ¡ç¸éçé¯èª¤ãæåçç ç©¶çµæçªåºäºçºå¿çå¥åº·è«®åéç¼ AI ç³»çµ±çè¤éæ§ï¼ç¹å¥æ¯å°æ¼éè¦åçå¿åèçµ¡çè§£çè½åãæåç¼ç¾ï¼åæ²¿ LLM çè¡¨ç¾æ°´å¹³è¶éäºææééµå¿çå¥åº·è«®åè½åæéçæä½è½åæ°´æºï¼ä½æªéå°å°å®¶ç´å¥çè¡¨ç¾ï¼èä¸ç®åçé«ç LLM ä¸¦æªé¡¯èæ¹åéç¨æ¨¡åå¨å¿çå¥åº·è«®åè½åä¸çè¡¨ç¾ãéå¼·èª¿äºå°å°éçãéå°å¿çå¥åº·è«®è©¢çå¾®èª¿ LLM çè¿«åéæ±ï¼éäº LLM å¿é å´æ ¼ç¬¦åæ ¸å¿è½åï¼ä¸¦çµåé©ç¶çäººé¡ç£ç£ï¼æè½èæ®ä»»ä½è² è²¬ä»»çå¯¦éé¨ç½²ã

##### **MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for Efficient and Interpretable Medical Image Segmentation**
2410.22223v1 by Ovais Iqbal Shah, Danish Raza Rizvi, Aqib Nazir Mir

Medical image segmentation is pivotal in healthcare, enhancing diagnostic
accuracy, informing treatment strategies, and tracking disease progression.
This process allows clinicians to extract critical information from visual
data, enabling personalized patient care. However, developing neural networks
for segmentation remains challenging, especially when preserving image
resolution, which is essential in detecting subtle details that influence
diagnoses. Moreover, the lack of transparency in these deep learning models has
slowed their adoption in clinical practice. Efforts in model interpretability
are increasingly focused on making these models' decision-making processes more
transparent. In this paper, we introduce MAPUNetR, a novel architecture that
synergizes the strengths of transformer models with the proven U-Net framework
for medical image segmentation. Our model addresses the resolution preservation
challenge and incorporates attention maps highlighting segmented regions,
increasing accuracy and interpretability. Evaluated on the BraTS 2020 dataset,
MAPUNetR achieved a dice score of 0.88 and a dice coefficient of 0.92 on the
ISIC 2018 dataset. Our experiments show that the model maintains stable
performance and potential as a powerful tool for medical image segmentation in
clinical practice.

æè¦ï¼é«å­¸å½±ååå²å¨é«çä¿å¥ä¸­è³ééè¦ï¼è½æåè¨ºæ·æºç¢ºåº¦ãæä¾æ²»çç­ç¥è³è¨ï¼ä¸¦è¿½è¹¤ç¾çé²ç¨ãæ­¤ç¨åºè®è¨åºé«çè½å¾è¦è¦ºè³æä¸­èåééµè³è¨ï¼é²èæä¾åäººåçæ£èç§è­·ãç¶èï¼éç¼ç¨æ¼åå²çç¥ç¶ç¶²è·¯ä»å·ææ°æ§ï¼ç¹å¥æ¯å¨ä¿çå½±åè§£æåº¦æï¼éå°æ¼åµæ¸¬å½±é¿è¨ºæ·çç´°å¾®ç´°ç¯è³ééè¦ãæ­¤å¤ï¼éäºæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹éæåº¦ï¼å°è´å¶å¨è¨åºå¯¦åä¸­çæ¡ç¨éåº¦è®æ¢ãæ¨¡åå¯è§£éæ§çåªåè¶ä¾è¶å°æ³¨æ¼è®éäºæ¨¡åçæ±ºç­éç¨æ´éæãå¨æ¬æä¸­ï¼æåä»ç´¹äº MAPUNetRï¼éæ¯ä¸ç¨®æ°ç©çæ¶æ§ï¼çµåäºTransformeræ¨¡åçåªé»åå·²è­å¯¦ç U-Net æ¡æ¶ï¼ç¨æ¼é«å­¸å½±ååå²ãæåçæ¨¡åè§£æ±ºäºè§£æåº¦ä¿ççææ°ï¼ä¸¦çµåäºçªé¡¯åå²ååçæ³¨æååï¼æé«äºæºç¢ºåº¦åå¯è§£éæ§ãå¨ BraTS 2020 è³æéä¸é²è¡è©ä¼°ï¼MAPUNetR å¨ ISIC 2018 è³æéä¸éå°äº 0.88 çéª°å­ä¿æ¸å 0.92 çéª°å­ç³»æ¸ãæåçå¯¦é©è¡¨æï¼è©²æ¨¡åå¨è¨åºå¯¦åä¸­ä½çºé«å­¸å½±ååå²çå¼·å¤§å·¥å·ï¼å·æç©©å®çæè½åæ½åã

##### **Natural Language Processing for Analyzing Electronic Health Records and Clinical Notes in Cancer Research: A Review**
2410.22180v1 by Muhammad Bilal, Ameer Hamza, Nadia Malik

Objective: This review aims to analyze the application of natural language
processing (NLP) techniques in cancer research using electronic health records
(EHRs) and clinical notes. This review addresses gaps in the existing
literature by providing a broader perspective than previous studies focused on
specific cancer types or applications. Methods: A comprehensive literature
search was conducted using the Scopus database, identifying 94 relevant studies
published between 2019 and 2024. Data extraction included study
characteristics, cancer types, NLP methodologies, dataset information,
performance metrics, challenges, and future directions. Studies were
categorized based on cancer types and NLP applications. Results: The results
showed a growing trend in NLP applications for cancer research, with breast,
lung, and colorectal cancers being the most studied. Information extraction and
text classification emerged as predominant NLP tasks. A shift from rule-based
to advanced machine learning techniques, particularly transformer-based models,
was observed. The Dataset sizes used in existing studies varied widely. Key
challenges included the limited generalizability of proposed solutions and the
need for improved integration into clinical workflows. Conclusion: NLP
techniques show significant potential in analyzing EHRs and clinical notes for
cancer research. However, future work should focus on improving model
generalizability, enhancing robustness in handling complex clinical language,
and expanding applications to understudied cancer types. Integration of NLP
tools into clinical practice and addressing ethical considerations remain
crucial for utilizing the full potential of NLP in enhancing cancer diagnosis,
treatment, and patient outcomes.

æè¦ï¼<paragraph>ç®æ¨ï¼æ¬ç¯è©è«æ¨å¨åæèªç¶èªè¨èç (NLP) æè¡å¨ççç ç©¶ä¸­ä½¿ç¨é»å­å¥åº·ç´é (EHR) åè¨åºç­è¨çæç¨ãæ¬ç¯è©è«ééæä¾æ¯ååå°æ³¨æ¼ç¹å®ççé¡åææç¨çç ç©¶æ´å»£æ³çè§é»ï¼ä¾æ¢è¨ç¾ææç»ä¸­çå·®è·ãæ¹æ³ï¼ä½¿ç¨ Scopus è³æåº«é²è¡å¨é¢çæç»æå°ï¼æ¾åº 2019 å¹´è³ 2024 å¹´éç¼è¡¨ç 94 ç¯ç¸éç ç©¶ãè³ææ·ååå«ç ç©¶ç¹å¾µãççé¡åãNLP æ¹æ³è«ãè³æéè³è¨ãæè½ææ¨ãææ°åæªä¾æ¹åãç ç©¶æ ¹æççé¡åå NLP æç¨é²è¡åé¡ãçµæï¼çµæé¡¯ç¤º NLP å¨ççç ç©¶ä¸­çæç¨æéæ¼¸å¢å çè¶¨å¢ï¼å¶ä¸­ä¹³çãèºçåå¤§è¸ç´è¸ççç ç©¶æå¤ãè³è¨æ·ååæå­åé¡æçºä¸»è¦ç NLP ä»»åãè§å¯å°å¾åºæ¼è¦åçæè¡è½ç§»å°é²éæ©å¨å­¸ç¿æè¡ï¼ç¹å¥æ¯åºæ¼è½æå¨çæ¨¡åãç¾æç ç©¶ä¸­ä½¿ç¨çè³æéå¤§å°å·®ç°å¾å¤§ãä¸»è¦çææ°åæ¬ææåºè§£æ±ºæ¹æ¡çæ®éæ§æéï¼ä»¥åéè¦æ´é²ä¸æ­¥æ´åå°è¨åºå·¥ä½æµç¨ä¸­ãçµè«ï¼NLP æè¡å¨åæé»å­å¥åº·ç´éåè¨åºç­è¨ä»¥é²è¡ççç ç©¶æ¹é¢é¡¯ç¤ºåºé¡¯èçæ½åãç¶èï¼æªä¾çç ç©¶æå°æ³¨æ¼æ¹åæ¨¡åçæ®éæ§ãå å¼·èçè¤éè¨åºèªè¨çç©©å¥æ§ï¼ä»¥åå°æç¨æ´å±å°ç ç©¶ä¸è¶³çççé¡åãå° NLP å·¥å·æ´åå°è¨åºå¯¦åä¸­ï¼ä¸¦æ¢è¨å«çèéï¼å°æ¼ååå©ç¨ NLP å¨æåççè¨ºæ·ãæ²»çåæ£èé å¾æ¹é¢çæ½åè³ééè¦ã</paragraph>

##### **Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning**
2410.21872v1 by Yinyi Lai, Anbo Cao, Yuan Gao, Jiaqi Shang, Zongyu Li, Jia Guo

Early and accurate diagnosis of brain tumors is crucial for improving patient
survival rates. However, the detection and classification of brain tumors are
challenging due to their diverse types and complex morphological
characteristics. This study investigates the application of pre-trained models
for brain tumor classification, with a particular focus on deploying the Mamba
model. We fine-tuned several mainstream transfer learning models and applied
them to the multi-class classification of brain tumors. By comparing these
models to those trained from scratch, we demonstrated the significant
advantages of transfer learning, especially in the medical imaging field, where
annotated data is often limited. Notably, we introduced the Vision Mamba (Vim),
a novel network architecture, and applied it for the first time in brain tumor
classification, achieving exceptional classification accuracy. Experimental
results indicate that the Vim model achieved 100% classification accuracy on an
independent test set, emphasizing its potential for tumor classification tasks.
These findings underscore the effectiveness of transfer learning in brain tumor
classification and reveal that, compared to existing state-of-the-art models,
the Vim model is lightweight, efficient, and highly accurate, offering a new
perspective for clinical applications. Furthermore, the framework proposed in
this study for brain tumor classification, based on transfer learning and the
Vision Mamba model, is broadly applicable to other medical imaging
classification problems.

æè¦ï¼è¦è«ç¤çæ©ææºç¢ºè¨ºæ·å°æ¼æé«æ£èå­æ´»çè³ééè¦ãç¶èï¼ç±æ¼è¦è«ç¤é¡åå¤æ¨£ä¸å½¢æç¹å¾µè¤éï¼å æ­¤æª¢æ¸¬ååé¡è¦è«ç¤å·æææ°æ§ãæ¬ç ç©¶æ¢è¨äºé è¨ç·´æ¨¡åå¨è¦è«ç¤åé¡ä¸­çæç¨ï¼ç¹å¥éæ³¨ Mamba æ¨¡åçé¨ç½²ãæåå¾®èª¿äºå¹¾åä¸»æµçé·ç§»å­¸ç¿æ¨¡åï¼ä¸¦å°å®åæç¨æ¼è¦è«ç¤çå¤é¡å¥åé¡ãééå°éäºæ¨¡åèå¾é ­éå§è¨ç·´çæ¨¡åé²è¡æ¯è¼ï¼æåå±ç¤ºäºé·ç§»å­¸ç¿çé¡¯èåªå¢ï¼ç¹å¥æ¯å¨é«çå½±åé åï¼é£è£¡çè¨»è§£æ¸æéå¸¸æéãå¼å¾æ³¨æçæ¯ï¼æåå¼å¥äº Vision Mamba (Vim)ï¼éæ¯ä¸ç¨®æ°ç©çç¶²è·¯æ¶æ§ï¼ä¸¦é¦æ¬¡å°å¶æç¨æ¼è¦è«ç¤åé¡ä¸­ï¼éå°äºåºè²çåé¡æºç¢ºçãå¯¦é©çµæè¡¨æï¼Vim æ¨¡åå¨ä¸åç¨ç«çæ¸¬è©¦éä¸éå°äº 100% çåé¡æºç¢ºçï¼å¼·èª¿äºå¶å¨è«ç¤åé¡ä»»åä¸­çæ½åãéäºç¼ç¾å¼·èª¿äºé·ç§»å­¸ç¿å¨è¦è«ç¤åé¡ä¸­çæææ§ï¼ä¸¦æ­ç¤ºäºèç¾æçæåé²æ¨¡åç¸æ¯ï¼Vim æ¨¡åè¼éãé«æä¸æºç¢ºï¼çºè¨åºæç¨æä¾äºæ°çè¦è§ãæ­¤å¤ï¼æ¬ç ç©¶ä¸­æåºçåºæ¼é·ç§»å­¸ç¿å Vision Mamba æ¨¡åçè¦è«ç¤åé¡æ¡æ¶å»£æ³é©ç¨æ¼å¶ä»é«å­¸å½±ååé¡åé¡ã

##### **How Does Critical Batch Size Scale in Pre-training?**
2410.21676v1 by Hanlin Zhang, Depen Morwani, Nikhil Vyas, Jingfeng Wu, Difan Zou, Udaya Ghai, Dean Foster, Sham Kakade

Training large-scale models under given resources requires careful design of
parallelism strategies. In particular, the efficiency notion of critical batch
size, concerning the compromise between time and compute, marks the threshold
beyond which greater data parallelism leads to diminishing returns. To
operationalize it, we propose a measure of CBS and pre-train a series of
auto-regressive language models, ranging from 85 million to 1.2 billion
parameters, on the C4 dataset. Through extensive hyper-parameter sweeps and
careful control on factors such as batch size, momentum, and learning rate
along with its scheduling, we systematically investigate the impact of scale on
CBS. Then we fit scaling laws with respect to model and data sizes to decouple
their effects. Overall, our results demonstrate that CBS scales primarily with
data size rather than model size, a finding we justify theoretically through
the analysis of infinite-width limits of neural networks and
infinite-dimensional least squares regression. Of independent interest, we
highlight the importance of common hyper-parameter choices and strategies for
studying large-scale pre-training beyond fixed training durations.

æè¦ï¼å¨æ¢å®è³æºä¸è¨ç·´å¤§åæ¨¡åéè¦ä»ç´°è¨­è¨å¹³è¡èçç­ç¥ãç¹å¥æ¯ï¼ééµæ¹æ¬¡å¤§å°çæçæ¦å¿µï¼æ¶åæéåéç®ä¹éçæè¡·ï¼æ¨èªèè¶è¶æ­¤è¨çé»å¾ï¼æ´å¤§çè³æå¹³è¡èçå°å°è´å ±é¬éæ¸ãçºäºå°å¶ä»è«¸å¯¦æ½ï¼æåæåºä¸å CBS éåº¦ï¼ä¸¦é åè¨ç·´ä¸ç³»åèªè¿´æ­¸èªè¨æ¨¡åï¼ç¯åå¾ 8500 è¬å° 12 åååæ¸ï¼å¨ C4 è³æéä¸ãééå»£æ³çè¶åæ¸ææåä»ç´°æ§å¶æ¹æ¬¡å¤§å°ãåéåå­¸ç¿çç­å ç´ ä»¥åå¶æç¨ï¼æåç³»çµ±æ§å°ç ç©¶è¦æ¨¡å° CBS çå½±é¿ãç¶å¾ï¼æåæ¬åéæ¼æ¨¡ååè³æå¤§å°çç¸®æ¾å®å¾ï¼ä»¥åé¢å®åçå½±é¿ãç¸½é«èè¨ï¼æåççµæè¡¨æ CBS ä¸»è¦é¨èè³æå¤§å°èä¸æ¯æ¨¡åå¤§å°èç¸®æ¾ï¼æåééå°ç¥ç¶ç¶²è·¯çç¡éå¯¬åº¦éå¶åç¡éç¶­æå°äºä¹è¿´æ­¸çåæï¼å¨çè«ä¸è­æäºéä¸ç¼ç¾ãç¨ç«çèè¶£æ¯ï¼æåå¼·èª¿äºéç¨è¶åæ¸é¸æåç­ç¥çéè¦æ§ï¼ç¨æ¼ç ç©¶è¶è¶åºå®è¨ç·´æçºæéçå¤§è¦æ¨¡é è¨ç·´ã

##### **A Tutorial on Clinical Speech AI Development: From Data Collection to Model Validation**
2410.21640v1 by Si-Ioi Ng, Lingfeng Xu, Ingo Siegert, Nicholas Cummins, Nina R. Benway, Julie Liss, Visar Berisha

There has been a surge of interest in leveraging speech as a marker of health
for a wide spectrum of conditions. The underlying premise is that any
neurological, mental, or physical deficits that impact speech production can be
objectively assessed via automated analysis of speech. Recent advances in
speech-based Artificial Intelligence (AI) models for diagnosing and tracking
mental health, cognitive, and motor disorders often use supervised learning,
similar to mainstream speech technologies like recognition and verification.
However, clinical speech AI has distinct challenges, including the need for
specific elicitation tasks, small available datasets, diverse speech
representations, and uncertain diagnostic labels. As a result, application of
the standard supervised learning paradigm may lead to models that perform well
in controlled settings but fail to generalize in real-world clinical
deployments. With translation into real-world clinical scenarios in mind, this
tutorial paper provides an overview of the key components required for robust
development of clinical speech AI. Specifically, this paper will cover the
design of speech elicitation tasks and protocols most appropriate for different
clinical conditions, collection of data and verification of hardware,
development and validation of speech representations designed to measure
clinical constructs of interest, development of reliable and robust clinical
prediction models, and ethical and participant considerations for clinical
speech AI. The goal is to provide comprehensive guidance on building models
whose inputs and outputs link to the more interpretable and clinically
meaningful aspects of speech, that can be interrogated and clinically validated
on clinical datasets, and that adhere to ethical, privacy, and security
considerations by design.

æè¦ï¼<paragraph>æè¿åºç¾ä¸è¡å©ç¨èªè¨ä½çºåç¨®ç¾çæ¨è¨çç±æ½®ãå¶åºæ¬åææ¯ä»»ä½å½±é¿èªè¨ç¢ççç¥ç¶ãå¿çæççç¼ºé·ï¼é½å¯ä»¥ééèªè¨çèªåååæé²è¡å®¢è§è©ä¼°ãæè¿å¨èªè¨åºç¤äººå·¥æºæ§ (AI) æ¨¡åä¸çé²å±ï¼ç¨æ¼è¨ºæ·åè¿½è¹¤å¿çå¥åº·ãèªç¥åéåéç¤ï¼éå¸¸ä½¿ç¨ç£ç£å¼å­¸ç¿ï¼é¡ä¼¼æ¼ä¸»æµèªè¨æè¡ï¼ä¾å¦è¾¨è­åé©è­ãç¶èï¼è¨åºèªè¨ AI æå¶ç¨ç¹çææ°ï¼åæ¬éè¦ç¹å®çå¼å°ä»»åãå¯ç¨çè³æéå°ãèªè¨è¡¨è¿°å¤æ¨£ï¼ä»¥åè¨ºæ·æ¨ç±¤ä¸ç¢ºå®ãå æ­¤ï¼æç¨æ¨æºçç£ç£å¼å­¸ç¿ç¯ä¾å¯è½æå°è´å¨åæ§ç°å¢ä¸­è¡¨ç¾è¯å¥½çæ¨¡åï¼ä½å¨ç¾å¯¦ä¸ççè¨åºé¨ç½²ä¸­å»ç¡æ³æ¦åãæ¬æå­¸è«æèéäºå°å¶è½è­¯å°ç¾å¯¦ä¸ççè¨åºæå¢ï¼æä¾äºå¥å¨éç¼è¨åºèªè¨ AI æéééµçµæçæ¦è§ãå·é«ä¾èªªï¼æ¬æå°æ¶µèæé©åä¸åè¨åºçæ³çèªè¨å¼å°ä»»åååå®çè¨­è¨ãè³ææ¶éåç¡¬é«é©è­ãç¨æ¼è¡¡éè¨åºéæ³¨çµæ§çèªè¨è¡¨è¿°çéç¼åé©è­ãå¯é ä¸å¥å¨çè¨åºé æ¸¬æ¨¡åçéç¼ï¼ä»¥åè¨åºèªè¨ AI çå«çååèèèéãç®æ¨æ¯æä¾å¨é¢çæå°æ¹éï¼ä»¥å»ºç«å¶è¼¸å¥åè¼¸åºé£çµå°æ´ææ¼çè§£ä¸è¨åºä¸ææç¾©çèªè¨é¢åçæ¨¡åï¼å¯ä»¥å¨è¨åºè³æéä¸é²è¡è©¢ååè¨åºé©è­ï¼ä¸¦ä¸å¨è¨­è¨ä¸éµå®å«çãé±ç§åå®å¨èéã</paragraph>

##### **Can Large Language Models Replace Data Scientists in Clinical Research?**
2410.21591v1 by Zifeng Wang, Benjamin Danek, Ziwei Yang, Zheng Chen, Jimeng Sun

Data science plays a critical role in clinical research, but it requires
professionals with expertise in coding and medical data analysis. Large
language models (LLMs) have shown great potential in supporting medical tasks
and performing well in general coding tests. However, these tests do not assess
LLMs' ability to handle data science tasks in medicine, nor do they explore
their practical utility in clinical research. To address this, we developed a
dataset consisting of 293 real-world data science coding tasks, based on 39
published clinical studies, covering 128 tasks in Python and 165 tasks in R.
This dataset simulates realistic clinical research scenarios using patient
data. Our findings reveal that cutting-edge LLMs struggle to generate perfect
solutions, frequently failing to follow input instructions, understand target
data, and adhere to standard analysis practices. Consequently, LLMs are not yet
ready to fully automate data science tasks. We benchmarked advanced adaptation
methods and found two to be particularly effective: chain-of-thought prompting,
which provides a step-by-step plan for data analysis, which led to a 60%
improvement in code accuracy; and self-reflection, enabling LLMs to iteratively
refine their code, yielding a 38% accuracy improvement. Building on these
insights, we developed a platform that integrates LLMs into the data science
workflow for medical professionals. In a user study with five medical doctors,
we found that while LLMs cannot fully automate coding tasks, they significantly
streamline the programming process. We found that 80% of their submitted code
solutions were incorporated from LLM-generated code, with up to 96% reuse in
some cases. Our analysis highlights the potential of LLMs, when integrated into
expert workflows, to enhance data science efficiency in clinical research.

æè¦ï¼<paragraph>è³æç§å­¸å¨è¨åºç ç©¶ä¸­ç¼æ®ééµä½ç¨ï¼ä½å®éè¦å·åç·¨ç¢¼åé«çè³æåæå°æ¥­ç¥è­çå°æ¥­äººå¡ãå¤§åèªè¨æ¨¡å (LLM) å¨æ¯æ´é«çä»»ååå·è¡ä¸è¬ç·¨ç¢¼æ¸¬è©¦æ¹é¢å±ç¾äºæ¥µå¤§çæ½åãç¶èï¼éäºæ¸¬è©¦ä¸¦æªè©ä¼° LLM èçé«å­¸ä¸­è³æç§å­¸ä»»åçè½åï¼ä¹æ²ææ¢è¨å®åå¨è¨åºç ç©¶ä¸­çå¯¦éæç¨ãçºäºè§£æ±ºéååé¡ï¼æåéç¼äºä¸åç± 293 åçå¯¦ä¸çè³æç§å­¸ç·¨ç¢¼ä»»åçµæçè³æéï¼éäºä»»ååºæ¼ 39 é å·²ç¼è¡¨çè¨åºç ç©¶ï¼æ¶µè 128 å Python ä»»åå 165 å R ä»»åãæ­¤è³æéä½¿ç¨æ£èè³ææ¨¡æ¬çå¯¦çè¨åºç ç©¶å ´æ¯ãæåçç ç©¶çµæé¡¯ç¤ºï¼æåé²ç LLM é£ä»¥ç¢çå®ç¾çè§£æ±ºæ¹æ¡ï¼å¸¸å¸¸ç¡æ³éµå¾ªè¼¸å¥èªªæãçè§£ç®æ¨è³æï¼ä»¥åéµå®æ¨æºåæå¯¦åãå æ­¤ï¼LLM å°æªæºåå¥½å®å¨èªååè³æç§å­¸ä»»åãæåå°é²éé©ææ¹æ³é²è¡äºåºæºæ¸¬è©¦ï¼ç¼ç¾æå©åæ¹æ³ç¹å¥ææï¼æèéæç¤ºï¼å®æä¾äºè³æåæçéæ­¥è¨ç«ï¼ä½¿ç¨å¼ç¢¼æºç¢ºåº¦æåäº 60%ï¼ä»¥åèªæåçï¼ä½¿ LLM è½å¤ åè¦æ¹åå¶ç¨å¼ç¢¼ï¼ä½¿æºç¢ºåº¦æåäº 38%ãæ ¹æéäºè¦è§£ï¼æåéç¼äºä¸åå° LLM æ´åå°é«çå°æ¥­äººå¡è³æç§å­¸å·¥ä½æµç¨ä¸­çå¹³å°ãå¨èäºä½é«ççä½¿ç¨èç ç©¶ä¸­ï¼æåç¼ç¾ï¼éç¶ LLM ç¡æ³å®å¨èªååç·¨ç¢¼ä»»åï¼ä½å®åå¤§å¹ç°¡åäºç¨å¼è¨­è¨æµç¨ãæåç¼ç¾ï¼ä»åæäº¤çç¨å¼ç¢¼è§£æ±ºæ¹æ¡ä¸­æ 80% æ¯å¾ LLM çæçç¨å¼ç¢¼ä¸­ç´å¥çï¼å¨æäºææ³ä¸éç¨çé«é 96%ãæåçåæå¼·èª¿äº LLM å¨æ´åå°å°å®¶å·¥ä½æµç¨ä¸­çæ½åï¼ä»¥æé«è¨åºç ç©¶ä¸­çè³æç§å­¸æçã</paragraph>

##### **Going Beyond H&E and Oncology: How Do Histopathology Foundation Models Perform for Multi-stain IHC and Immunology?**
2410.21560v1 by Amaya Gallagher-Syed, Elena Pontarini, Myles J. Lewis, Michael R. Barnes, Gregory Slabaugh

This study evaluates the generalisation capabilities of state-of-the-art
histopathology foundation models on out-of-distribution multi-stain autoimmune
Immunohistochemistry datasets. We compare 13 feature extractor models,
including ImageNet-pretrained networks, and histopathology foundation models
trained on both public and proprietary data, on Rheumatoid Arthritis subtyping
and Sjogren's Disease detection tasks. Using a simple Attention-Based Multiple
Instance Learning classifier, we assess the transferability of learned
representations from cancer H&E images to autoimmune IHC images. Contrary to
expectations, histopathology-pretrained models did not significantly outperform
ImageNet-pretrained models. Furthermore, there was evidence of both autoimmune
feature misinterpretation and biased feature importance. Our findings highlight
the challenges in transferring knowledge from cancer to autoimmune
histopathology and emphasise the need for careful evaluation of AI models
across diverse histopathological tasks. The code to run this benchmark is
available at https://github.com/AmayaGS/ImmunoHistoBench.

æè¦ï¼æ¬ç ç©¶è©ä¼°äºæåé²ççµç¹ççå­¸åºç¤æ¨¡åå¨åå¸å¤å¤æè²èªèº«åç«åç«çµç¹åå­¸æ¸æéä¸çæ³åè½åãæåæ¯è¼äº 13 åç¹å¾µæåå¨æ¨¡åï¼åæ¬ ImageNet é è¨ç·´ç¶²è·¯ï¼ä»¥åå¨å¬å±åå°ææ¸æä¸è¨ç·´ççµç¹ççå­¸åºç¤æ¨¡åï¼å¨é¡é¢¨æ¿æ§éç¯çäºååä¹¾ç¥çæª¢æ¸¬ä»»åä¸ãä½¿ç¨ä¸åç°¡å®çåºæ¼æ³¨æåçå¤å¯¦ä¾å­¸ç¿åé¡å¨ï¼æåè©ä¼°äºå¾çç H&E å½±åå°èªèº«åç« IHC å½±åçå­¸ç¿è¡¨å¾µçå¯å³éæ§ãèé æç¸åï¼çµç¹ççå­¸é è¨ç·´æ¨¡åä¸¦æ²æé¡¯èåªæ¼ ImageNet é è¨ç·´æ¨¡åãæ­¤å¤ï¼æè­æè¡¨æå­å¨èªèº«åç«ç¹å¾µèª¤è§£ååå·®ç¹å¾µéè¦æ§ãæåçç ç©¶çµæå¼·èª¿äºå°ç¥è­å¾ççè½ç§»å°èªèº«åç«çµç¹ççå­¸çææ°ï¼ä¸¦å¼·èª¿äºè·¨ä¸åçµç¹ççå­¸ä»»åä»ç´°è©ä¼° AI æ¨¡åçå¿è¦æ§ãéè¡æ­¤åºæºæ¸¬è©¦çç¨å¼ç¢¼å¯å¨ https://github.com/AmayaGS/ImmunoHistoBench ç²å¾ã

##### **Towards Multi-dimensional Explanation Alignment for Medical Classification**
2410.21494v1 by Lijie Hu, Songning Lai, Wenshuo Chen, Hongru Xiao, Hongbin Lin, Lu Yu, Jingfeng Zhang, Di Wang

The lack of interpretability in the field of medical image analysis has
significant ethical and legal implications. Existing interpretable methods in
this domain encounter several challenges, including dependency on specific
models, difficulties in understanding and visualization, as well as issues
related to efficiency. To address these limitations, we propose a novel
framework called Med-MICN (Medical Multi-dimensional Interpretable Concept
Network). Med-MICN provides interpretability alignment for various angles,
including neural symbolic reasoning, concept semantics, and saliency maps,
which are superior to current interpretable methods. Its advantages include
high prediction accuracy, interpretability across multiple dimensions, and
automation through an end-to-end concept labeling process that reduces the need
for extensive human training effort when working with new datasets. To
demonstrate the effectiveness and interpretability of Med-MICN, we apply it to
four benchmark datasets and compare it with baselines. The results clearly
demonstrate the superior performance and interpretability of our Med-MICN.

æè¦ï¼é«çå½±ååæé åç¼ºä¹å¯è§£éæ§ï¼éå¸¶ä¾éå¤§çå«çåæ³å¾å½±é¿ãç¾æçå¯è§£éæ¹æ³å¨éåé åä¸­æé­éè¨±å¤ææ°ï¼åæ¬ä¾è³´ç¹å®æ¨¡åãé£ä»¥çè§£åè¦è¦ºåï¼ä»¥åèæçç¸éçåé¡ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºä¸åæ°çæ¶æ§ï¼ç¨±çº Med-MICNï¼é«çå¤ç¶­å¯è§£éæ¦å¿µç¶²è·¯ï¼ãMed-MICN æä¾åç¨®è§åº¦çå¯è§£éæ§æ¯å°ï¼åæ¬ç¥ç¶ç¬¦èæ¨çãæ¦å¿µèªæåé¡¯èæ§åï¼éäºé½åªæ¼ç®åçå¯è§£éæ¹æ³ãå®çåªé»åæ¬é«é æ¸¬æºç¢ºåº¦ãå¤ç¶­åº¦çå¯è§£éæ§ï¼ä»¥åééç«¯å°ç«¯æ¦å¿µæ¨è¨æµç¨èªååï¼éæ¸å°äºå¨ä½¿ç¨æ°è³æéæéè¦å¤§éäººå·¥è¨ç·´çå·¥ä½ãçºäºè­æ Med-MICN çæææ§åå¯è§£éæ§ï¼æåå°å¶æç¨æ¼åååºæºè³æéï¼ä¸¦èåºæºç·é²è¡æ¯è¼ãçµææ¸æ¥å°è­æäºæåç Med-MICN å·æåªç°çæè½åå¯è§£éæ§ã

##### **Multi-modal AI for comprehensive breast cancer prognostication**
2410.21256v1 by Jan Witowski, Ken Zeng, Joseph Cappadona, Jailan Elayoubi, Elena Diana Chiru, Nancy Chan, Young-Joon Kang, Frederick Howard, Irina Ostrovnaya, Carlos Fernandez-Granda, Freya Schnabel, Ugur Ozerdem, Kangning Liu, Zoe Steinsnyder, Nitya Thakore, Mohammad Sadic, Frank Yeung, Elisa Liu, Theodore Hill, Benjamin Swett, Danielle Rigau, Andrew Clayburn, Valerie Speirs, Marcus Vetter, Lina Sojak, Simone Muenst Soysal, Daniel Baumhoer, Khalil Choucair, Yu Zong, Lina Daoud, Anas Saad, Waleed Abdulsattar, Rafic Beydoun, Jia-Wern Pan, Haslina Makmur, Soo-Hwang Teo, Linda Ma Pak, Victor Angel, Dovile Zilenaite-Petrulaitiene, Arvydas Laurinavicius, Natalie Klar, Brian D. Piening, Carlo Bifulco, Sun-Young Jun, Jae Pak Yi, Su Hyun Lim, Adam Brufsky, Francisco J. Esteva, Lajos Pusztai, Yann LeCun, Krzysztof J. Geras

Treatment selection in breast cancer is guided by molecular subtypes and
clinical characteristics. Recurrence risk assessment plays a crucial role in
personalizing treatment. Current methods, including genomic assays, have
limited accuracy and clinical utility, leading to suboptimal decisions for many
patients. We developed a test for breast cancer patient stratification based on
digital pathology and clinical characteristics using novel AI methods.
Specifically, we utilized a vision transformer-based pan-cancer foundation
model trained with self-supervised learning to extract features from digitized
H&E-stained slides. These features were integrated with clinical data to form a
multi-modal AI test predicting cancer recurrence and death. The test was
developed and evaluated using data from a total of 8,161 breast cancer patients
across 15 cohorts originating from seven countries. Of these, 3,502 patients
from five cohorts were used exclusively for evaluation, while the remaining
patients were used for training. Our test accurately predicted our primary
endpoint, disease-free interval, in the five external cohorts (C-index: 0.71
[0.68-0.75], HR: 3.63 [3.02-4.37, p<0.01]). In a direct comparison (N=858), the
AI test was more accurate than Oncotype DX, the standard-of-care 21-gene assay,
with a C-index of 0.67 [0.61-0.74] versus 0.61 [0.49-0.73], respectively.
Additionally, the AI test added independent information to Oncotype DX in a
multivariate analysis (HR: 3.11 [1.91-5.09, p<0.01)]). The test demonstrated
robust accuracy across all major breast cancer subtypes, including TNBC
(C-index: 0.71 [0.62-0.81], HR: 3.81 [2.35-6.17, p=0.02]), where no diagnostic
tools are currently recommended by clinical guidelines. These results suggest
that our AI test can improve accuracy, extend applicability to a wider range of
patients, and enhance access to treatment selection tools.

æè¦ï¼<paragraph>ä¹³ççæ²»çé¸ææ¯ç±åå­äºååè¨åºç¹å¾µæå¼å°ãå¾©ç¼é¢¨éªè©ä¼°å¨åäººåæ²»çä¸­æ®æ¼è³ééè¦çè§è²ãç®åçæè¡ï¼åæ¬åºå é«åæï¼å·ææéçæºç¢ºåº¦åè¨åºæç¨ï¼å°è´è¨±å¤æ£èçæ²»çæ±ºç­æ¬¡æ¼æä½³ãæåéç¼äºä¸ç¨®åºæ¼æ¸ä½ççå­¸åè¨åºç¹å¾µçä¹³çæ£èåå±¤æª¢æ¸¬ï¼æ¡ç¨æ°ç©çäººå·¥æºæ§æ¹æ³ãå·é«ä¾èªªï¼æåå©ç¨äºä¸ååºæ¼è¦è¦ºè½æå¨çæ³çåºç¤æ¨¡åï¼ä¸¦ééèªæç£ç£å­¸ç¿é²è¡è¨ç·´ï¼ä»¥å¾æ¸ä½åç H&E æè²ç»çä¸­æåç¹å¾µãéäºç¹å¾µèè¨åºè³ææ´åï¼å½¢æä¸åå¤æ¨¡å¼çäººå·¥æºæ§æª¢æ¸¬ï¼ç¨æ¼é æ¸¬ççå¾©ç¼åæ­»äº¡ãè©²æª¢æ¸¬çéç¼åè©ä¼°ä½¿ç¨äºä¾èªä¸ååå®¶/å°åç 15 åç¾¤çµå± 8,161 åä¹³çæ£èçè³æãå¶ä¸­ï¼ä¾èªäºåç¾¤çµç 3,502 åæ£èå°éç¨æ¼è©ä¼°ï¼èå¶é¤æ£èåç¨æ¼è¨ç·´ãæåçæª¢æ¸¬æºç¢ºå°é æ¸¬äºæåçä¸»è¦çµé»ï¼å³äºåå¤é¨ç¾¤çµçç¡ç¾çéæï¼C ææ¸ï¼0.71 [0.68-0.75]ï¼HRï¼3.63 [3.02-4.37ï¼p<0.01]ï¼ãå¨ç´æ¥æ¯è¼ï¼N=858ï¼ä¸­ï¼äººå·¥æºæ§æª¢æ¸¬æ¯å®ç§æ³°Dxï¼æ¨æºç§è­·ç 21 åºå æª¢æ¸¬æ´æºç¢ºï¼C ææ¸åå¥çº 0.67 [0.61-0.74] å 0.61 [0.49-0.73]ãæ­¤å¤ï¼äººå·¥æºæ§æª¢æ¸¬å¨å¤è®éåæä¸­å¢å äºå®ç§æ³° Dx çç¨ç«è³è¨ï¼HRï¼3.11 [1.91-5.09ï¼p<0.01]ï¼ãè©²æª¢æ¸¬å¨ææä¸»è¦çä¹³çäºåä¸­é½è¡¨ç¾åºå¼·å¤§çæºç¢ºåº¦ï¼åæ¬ TNBCï¼C ææ¸ï¼0.71 [0.62-0.81]ï¼HRï¼3.81 [2.35-6.17ï¼p=0.02]ï¼ï¼è¨åºæåç®åä¸å»ºè­°ä½¿ç¨ä»»ä½è¨ºæ·å·¥å·ãéäºçµæè¡¨æï¼æåçäººå·¥æºæ§æª¢æ¸¬å¯ä»¥æé«æºç¢ºåº¦ï¼å°é©ç¨ç¯åæ´å±å°æ´å¤æ£èï¼ä¸¦å¢å ç²å¾æ²»çé¸æå·¥å·çæ©æã</paragraph>

##### **Belief in the Machine: Investigating Epistemological Blind Spots of Language Models**
2410.21195v1 by Mirac Suzgun, Tayfun Gur, Federico Bianchi, Daniel E. Ho, Thomas Icard, Dan Jurafsky, James Zou

As language models (LMs) become integral to fields like healthcare, law, and
journalism, their ability to differentiate between fact, belief, and knowledge
is essential for reliable decision-making. Failure to grasp these distinctions
can lead to significant consequences in areas such as medical diagnosis, legal
judgments, and dissemination of fake news. Despite this, current literature has
largely focused on more complex issues such as theory of mind, overlooking more
fundamental epistemic challenges. This study systematically evaluates the
epistemic reasoning capabilities of modern LMs, including GPT-4, Claude-3, and
Llama-3, using a new dataset, KaBLE, consisting of 13,000 questions across 13
tasks. Our results reveal key limitations. First, while LMs achieve 86%
accuracy on factual scenarios, their performance drops significantly with false
scenarios, particularly in belief-related tasks. Second, LMs struggle with
recognizing and affirming personal beliefs, especially when those beliefs
contradict factual data, which raises concerns for applications in healthcare
and counseling, where engaging with a person's beliefs is critical. Third, we
identify a salient bias in how LMs process first-person versus third-person
beliefs, performing better on third-person tasks (80.7%) compared to
first-person tasks (54.4%). Fourth, LMs lack a robust understanding of the
factive nature of knowledge, namely, that knowledge inherently requires truth.
Fifth, LMs rely on linguistic cues for fact-checking and sometimes bypass the
deeper reasoning. These findings highlight significant concerns about current
LMs' ability to reason about truth, belief, and knowledge while emphasizing the
need for advancements in these areas before broad deployment in critical
sectors.

æè¦ï¼é¨èèªè¨æ¨¡å (LM) æçºé«çä¿å¥ãæ³å¾åæ°èç­é åä¸å¯æç¼ºçä¸é¨åï¼å®åååäºå¯¦ãä¿¡å¿µåç¥è­çè½åå°æ¼å¯é çæ±ºç­è³ééè¦ãç¡æ³ææ¡éäºåå¥å¯è½æå¨é«çè¨ºæ·ãæ³å¾å¤æ±ºååæ°èå³æ­ç­é åé æéå¤§å¾æãåç®¡å¦æ­¤ï¼ç®åçæç»å¨å¾å¤§ç¨åº¦ä¸éæ³¨æ¼æ´è¤éçåé¡ï¼ä¾å¦å¿æºçè«ï¼èå¿½è¦äºæ´åºæ¬çèªè­è«ææ°ãæ¬ç ç©¶ä½¿ç¨æ°çè³æé KaBLEï¼å°ç¾ä»£ LMï¼åæ¬ GPT-4ãClaude-3 å Llama-3ï¼çèªè­è«æ¨çè½åé²è¡äºç³»çµ±è©ä¼°ï¼è©²è³æéåå« 13 åä»»åä¸­ç 13,000 ååé¡ãæåççµææ­ç¤ºäºééµéå¶ãé¦åï¼éç¶ LM å¨äºå¯¦å ´æ¯ä¸­éå° 86% çæºç¢ºåº¦ï¼ä½å®åå¨é¯èª¤å ´æ¯ä¸­çè¡¨ç¾å¤§å¹ä¸éï¼ç¹å¥æ¯å¨èä¿¡å¿µç¸éçä»»åä¸­ãå¶æ¬¡ï¼LM é£ä»¥è­å¥åè¯å®åäººä¿¡å¿µï¼ç¹å¥æ¯ç¶éäºä¿¡å¿µèäºå¯¦è³æç¸çç¾æï¼éå¼èµ·äºå°é«çä¿å¥åè«®è©¢æç¨ç¨å¼çææï¼å¨éäºæç¨ç¨å¼ä¸­ï¼èåäººçä¿¡å¿µäºåè³ééè¦ãç¬¬ä¸ï¼æåç¼ç¾ LM èçç¬¬ä¸äººç¨±èç¬¬ä¸äººç¨±ä¿¡å¿µçæ¹å¼å­å¨é¡¯èåå·®ï¼å¨ç¬¬ä¸äººç¨±ä»»åï¼80.7%ï¼ä¸çè¡¨ç¾åªæ¼ç¬¬ä¸äººç¨±ä»»åï¼54.4%ï¼ãç¬¬åï¼LM ç¼ºä¹å°ç¥è­çäºå¯¦æ§è³ªçç©©å¥çè§£ï¼å³ç¥è­æ¬è³ªä¸éè¦ççãç¬¬äºï¼LM ä¾è³´èªè¨ç·ç´¢é²è¡äºå¯¦æ¥æ ¸ï¼æææç¹éæ´æ·±å¥çæ¨çãéäºç¼ç¾çªé¡¯äºç¶å LM æ¨çççãä¿¡å¿µåç¥è­çè½åå­å¨éå¤§çæ®ï¼åæå¼·èª¿å¨å»£æ³é¨ç½²æ¼ééµé¨éä¹åï¼éè¦å¨éäºé ååå¾é²å±ã

##### **Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks**
2410.21175v1 by Jiawei Zhang, Jun Li, Reachsak Ly, Yunyi Liu, Jiangpeng Shu

For structural health monitoring, continuous and automatic crack detection
has been a challenging problem. This study is conducted to propose a framework
of automatic crack segmentation from high-resolution images containing crack
information about steel box girders of bridges. Considering the multi-scale
feature of cracks, convolutional neural network architecture of Feature Pyramid
Networks (FPN) for crack detection is proposed. As for input, 120 raw images
are processed via two approaches (shrinking the size of images and splitting
images into sub-images). Then, models with the proposed structure of FPN for
crack detection are developed. The result shows all developed models can
automatically detect the cracks at the raw images. By shrinking the images, the
computation efficiency is improved without decreasing accuracy. Because of the
separable characteristic of crack, models using the splitting method provide
more accurate crack segmentations than models using the resizing method.
Therefore, for high-resolution images, the FPN structure coupled with the
splitting method is an promising solution for the crack segmentation and
detection.

æè¦ï¼å°æ¼çµæ§å¥åº·ç£æ¸¬ï¼é£çºä¸èªåçè£ç¸«åµæ¸¬ä¸ç´æ¯ä¸åå·æææ°æ§çåé¡ãæ¬ç ç©¶æ¨å¨æåºä¸åå¾åå«æ©æ¨é¼ç®±æ¢è£ç¸«è³è¨çé«è§£æåº¦å½±åä¸­èªååå²è£ç¸«çæ¶æ§ãèéå°è£ç¸«çå¤å°ºåº¦ç¹å¾µï¼æåºç¨æ¼è£ç¸«åµæ¸¬ç Feature Pyramid Networks (FPN) æ²ç©ç¥ç¶ç¶²è·¯æ¶æ§ãè³æ¼è¼¸å¥ï¼120 å¼µåå§å½±åééå©ç¨®æ¹æ³èçï¼ç¸®å°å½±åå°ºå¯¸åå°å½±ååå²æå­å½±åï¼ãç¶å¾ï¼éç¼å·æ FPN æè­°çµæ§çè£ç¸«åµæ¸¬æ¨¡åãçµæé¡¯ç¤ºææå·²éç¼çæ¨¡åé½è½èªååµæ¸¬åå§å½±åä¸­çè£ç¸«ãèç±ç¸®å°å½±åï¼å¨ä¸éä½æºç¢ºåº¦ççæ³ä¸æåéç®æçãç±æ¼è£ç¸«å·æå¯åé¢çç¹å¾µï¼ä½¿ç¨åå²æ¹æ³çæ¨¡åæä¾æ¯ä½¿ç¨ç¸®æ¾æ¹æ³çæ¨¡åæ´æºç¢ºçè£ç¸«åå²ãå æ­¤ï¼å°æ¼é«è§£æåº¦å½±åï¼FPN çµæ§çµååå²æ¹æ³æ¯è£ç¸«åå²ååµæ¸¬çæåéçè§£æ±ºæ¹æ¡ã

##### **Trajectory Flow Matching with Applications to Clinical Time Series Modeling**
2410.21154v1 by Xi Zhang, Yuan Pu, Yuki Kawamura, Andrew Loza, Yoshua Bengio, Dennis L. Shung, Alexander Tong

Modeling stochastic and irregularly sampled time series is a challenging
problem found in a wide range of applications, especially in medicine. Neural
stochastic differential equations (Neural SDEs) are an attractive modeling
technique for this problem, which parameterize the drift and diffusion terms of
an SDE with neural networks. However, current algorithms for training Neural
SDEs require backpropagation through the SDE dynamics, greatly limiting their
scalability and stability. To address this, we propose Trajectory Flow Matching
(TFM), which trains a Neural SDE in a simulation-free manner, bypassing
backpropagation through the dynamics. TFM leverages the flow matching technique
from generative modeling to model time series. In this work we first establish
necessary conditions for TFM to learn time series data. Next, we present a
reparameterization trick which improves training stability. Finally, we adapt
TFM to the clinical time series setting, demonstrating improved performance on
three clinical time series datasets both in terms of absolute performance and
uncertainty prediction.

æè¦ï¼é¨æ©ä¸ä¸è¦ååæ¨£çæåºå»ºæ¨¡æ¯ä¸åå·æææ°æ§çåé¡ï¼å¨å»£æ³çæç¨ä¸­ç¼ç¾ï¼ç¹å¥æ¯å¨é«å­¸ä¸­ãç¥ç¶é¨æ©å¾®åæ¹ç¨ (Neural SDE) æ¯éååé¡ä¸åæå¸å¼åçå»ºæ¨¡æè¡ï¼å®ç¨ç¥ç¶ç¶²è·¯åæ¸å SDE çæ¼ç§»åæ´æ£é ãç¶èï¼ç®åè¨ç·´ç¥ç¶ SDE çæ¼ç®æ³éè¦éé SDE åæé²è¡ååå³æ­ï¼æ¥µå¤§å°éå¶äºå®åçå¯æ´åæ§åç©©å®æ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºè»è·¡æµå¹é (TFM)ï¼å®ä»¥ç¡æ¨¡æ¬çæ¹å¼è¨ç·´ä¸åç¥ç¶ SDEï¼ç¹éåæçååå³æ­ãTFM å©ç¨çæå¼å»ºæ¨¡ä¸­çæµå¹éæè¡ä¾å»ºæ¨¡æåºãå¨éé å·¥ä½ä¸­ï¼æåé¦åå»ºç« TFM å­¸ç¿æåºè³æçå¿è¦æ¢ä»¶ãæ¥ä¸ä¾ï¼æåæåºä¸åéæ°åæ¸åçæå·§ï¼å®æ¹é²äºè¨ç·´ç©©å®æ§ãæå¾ï¼æåå° TFM é©æå°è¨åºæåºè¨­å®ï¼è­æäºå¨çµå°æè½åä¸ç¢ºå®æ§é æ¸¬æ¹é¢ï¼å¨ä¸åè¨åºæåºè³æéä¸é½ææè½çæåã

##### **Informed Deep Abstaining Classifier: Investigating noise-robust training for diagnostic decision support systems**
2410.21014v1 by Helen Schneider, Sebastian Nowak, Aditya Parikh, Yannik C. Layer, Maike Theis, Wolfgang Block, Alois M. Sprinkart, Ulrike Attenberger, Rafet Sifa

Image-based diagnostic decision support systems (DDSS) utilizing deep
learning have the potential to optimize clinical workflows. However, developing
DDSS requires extensive datasets with expert annotations and is therefore
costly. Leveraging report contents from radiological data bases with Natural
Language Processing to annotate the corresponding image data promises to
replace labor-intensive manual annotation. As mining "real world" databases can
introduce label noise, noise-robust training losses are of great interest.
However, current noise-robust losses do not consider noise estimations that can
for example be derived based on the performance of the automatic label
generator used. In this study, we expand the noise-robust Deep Abstaining
Classifier (DAC) loss to an Informed Deep Abstaining Classifier (IDAC) loss by
incorporating noise level estimations during training. Our findings demonstrate
that IDAC enhances the noise robustness compared to DAC and several
state-of-the-art loss functions. The results are obtained on various simulated
noise levels using a public chest X-ray data set. These findings are reproduced
on an in-house noisy data set, where labels were extracted from the clinical
systems of the University Hospital Bonn by a text-based transformer. The IDAC
can therefore be a valuable tool for researchers, companies or clinics aiming
to develop accurate and reliable DDSS from routine clinical data.

æè¦ï¼<paragraph>å©ç¨æ·±åº¦å­¸ç¿çå½±åè¨ºæ·æ±ºç­æ¯æ´ç³»çµ± (DDSS) æå¯è½æä½³åè¨åºå·¥ä½æµç¨ãç¶èï¼éç¼ DDSS éè¦å¤§éå·åå°å®¶è¨»è§£çè³æéï¼å æ­¤ææ¬é«æãå©ç¨èªç¶èªè¨èçå¾æ¾å°ç§è³æåº«çå ±åå§å®¹ä¸­æ¨è¨»å°æçå½±åè³æï¼ææåä»£ååå¯éçæåæ¨è¨»ãç±æ¼ææãçå¯¦ä¸çãè³æåº«å¯è½æå¼å¥æ¨ç±¤éè¨ï¼å æ­¤å°éè¨ç©©å¥çè¨ç·´æå¤±éå¸¸éè¦ãç¶èï¼ç®åå°éè¨ç©©å¥çæå¤±å½æ¸ä¸¦æªèæ®éè¨ä¼°è¨ï¼ä¾å¦å¯ä»¥æ ¹ææä½¿ç¨çèªåæ¨ç±¤ç¢çå¨çæè½æ¨å°åºä¾ãå¨æ¬ç ç©¶ä¸­ï¼æåééå¨è¨ç·´æéç´å¥éè¨ç­ç´ä¼°è¨ï¼å°å°éè¨ç©©å¥çæ·±åº¦æ£æ¬åé¡å¨ (DAC) æå¤±å½æ¸æ´åçºææºæ·±åº¦æ£æ¬åé¡å¨ (IDAC) æå¤±å½æ¸ãæåçç ç©¶çµæé¡¯ç¤ºï¼è DAC åå¤ç¨®æåé²çæå¤±å½æ¸ç¸æ¯ï¼IDAC å¢å¼·äºå°éè¨çç©©å¥æ§ãéäºçµææ¯ä½¿ç¨å¬éçè¸é¨ X åè³æéï¼å¨åç¨®æ¨¡æ¬éè¨ç­ç´ä¸­ç²å¾çãéäºç ç©¶çµæå¨å§é¨éè¨è³æéä¸éç¾ï¼å¶ä¸­æ¨ç±¤æ¯ç±ææ¬è½æå¨å¾æ³¢æ©å¤§å­¸é«é¢çè¨åºç³»çµ±ä¸­èååºä¾çãå æ­¤ï¼IDAC å¯ä»¥æçºç ç©¶äººå¡ãå¬å¸æè¨ºæå¾ä¾è¡è¨åºè³æéç¼æºç¢ºä¸å¯é ç DDSS çæå¹å¼å·¥å·ã</paragraph>

##### **Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering**
2410.21000v1 by Zhilin Zhang, Jie Wang, Ruiqi Zhu, Xiaoliang Gong

Medical Visual Question Answering (MedVQA) has gained increasing attention at
the intersection of computer vision and natural language processing. Its
capability to interpret radiological images and deliver precise answers to
clinical inquiries positions MedVQA as a valuable tool for supporting
diagnostic decision-making for physicians and alleviating the workload on
radiologists. While recent approaches focus on using unified pre-trained large
models for multi-modal fusion like cross-modal Transformers, research on more
efficient fusion methods remains relatively scarce within this discipline. In
this paper, we introduce a novel fusion model that integrates Orthogonality
loss, Multi-head attention and Bilinear Attention Network (OMniBAN) to achieve
high computational efficiency and strong performance without the need for
pre-training. We conduct comprehensive experiments and clarify aspects of how
to enhance bilinear attention fusion to achieve performance comparable to that
of large models. Experimental results show that OMniBAN outperforms traditional
models on key MedVQA benchmarks while maintaining a lower computational cost,
which indicates its potential for efficient clinical application in radiology
and pathology image question answering.

æè¦ï¼é«çè¦è¦ºåç­ (MedVQA) å¨é»è¦è¦è¦ºåèªç¶èªè¨èççäº¤éä¸­ç²å¾è¶ä¾è¶å¤çéæ³¨ãå®è½å¤ è§£è®æ¾å°å½±åä¸¦å°è¨åºè©¢åæä¾ç²¾ç¢ºç­æ¡çè½åï¼ä½¿ MedVQA æçºæ¯æ´é«å¸«è¨ºæ·æ±ºç­åæ¸è¼æ¾å°ç§é«å¸«å·¥ä½è² æçå¯¶è²´å·¥å·ãéç¶æè¿çæ¹æ³èéæ¼ä½¿ç¨çµ±ä¸çé åè¨ç·´å¤§åæ¨¡åé²è¡å¤æ¨¡å¼èåï¼ä¾å¦è·¨æ¨¡æ Transformerï¼ä½å°æ¼æ´ææççèåæ¹æ³çç ç©¶å¨æ­¤é åä¸­ä»ç¶ç¸å°ç¨å°ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åæ°ç©çèåæ¨¡åï¼å®æ´åäºæ­£äº¤æå¤±ãå¤é ­æ³¨æååéç·æ§æ³¨æåç¶²è·¯ (OMniBAN)ï¼ä»¥å¨ä¸éè¦é åè¨ç·´çææ³ä¸å¯¦ç¾é«è¨ç®æçåå¼·å¤§æè½ãæåé²è¡äºå¨é¢çå¯¦é©ï¼ä¸¦éæ¸äºå¦ä½å¢å¼·éç·æ§æ³¨æåèåä»¥å¯¦ç¾èå¤§åæ¨¡åç¸ç¶çæè½ãå¯¦é©çµæè¡¨æï¼OMniBAN å¨ééµç MedVQA åºæºä¸åªæ¼å³çµ±æ¨¡åï¼åæç¶­æè¼ä½çè¨ç®ææ¬ï¼éè¡¨æå®å¨æ¾å°å­¸åççå½±ååç­ä¸­å·æé«æè¨åºæç¨çæ½åã

##### **Large Language Model Benchmarks in Medical Tasks**
2410.21348v1 by Lawrence K. Q. Yan, Ming Li, Yichao Zhang, Caitlyn Heqi Yin, Cheng Fei, Benji Peng, Ziqian Bi, Pohsun Feng, Keyu Chen, Junyu Liu, Qian Niu

With the increasing application of large language models (LLMs) in the
medical domain, evaluating these models' performance using benchmark datasets
has become crucial. This paper presents a comprehensive survey of various
benchmark datasets employed in medical LLM tasks. These datasets span multiple
modalities including text, image, and multimodal benchmarks, focusing on
different aspects of medical knowledge such as electronic health records
(EHRs), doctor-patient dialogues, medical question-answering, and medical image
captioning. The survey categorizes the datasets by modality, discussing their
significance, data structure, and impact on the development of LLMs for
clinical tasks such as diagnosis, report generation, and predictive decision
support. Key benchmarks include MIMIC-III, MIMIC-IV, BioASQ, PubMedQA, and
CheXpert, which have facilitated advancements in tasks like medical report
generation, clinical summarization, and synthetic data generation. The paper
summarizes the challenges and opportunities in leveraging these benchmarks for
advancing multimodal medical intelligence, emphasizing the need for datasets
with a greater degree of language diversity, structured omics data, and
innovative approaches to synthesis. This work also provides a foundation for
future research in the application of LLMs in medicine, contributing to the
evolving field of medical artificial intelligence.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) å¨é«çé åçæç¨æ¥çå»£æ³ï¼ä½¿ç¨åºæºè³æéè©ä¼°éäºæ¨¡åçæè½å·²è®å¾è³ééè¦ãæ¬æå°ç¨æ¼é«ç LLM ä»»åçåç¨®åºæºè³æéé²è¡äºå¨é¢çèª¿æ¥ãéäºè³æéè·¨è¶å¤ç¨®æ¨¡å¼ï¼åæ¬æå­ãå½±ååå¤æ¨¡æåºæºï¼éé»éæ³¨é»å­å¥åº·ç´é (EHR)ãé«çå°è©±ãé«çåç­åé«çå½±åæ¨é¡ç­é«çç¥è­çä¸åé¢åãèª¿æ¥ææ¨¡å¼å°è³æéé²è¡åé¡ï¼è¨è«å®åçéè¦æ§ãè³æçµæ§åå°ç¨æ¼è¨ºæ·ãå ±åçæåé æ¸¬æ§æ±ºç­æ¯æ´ç­è¨åºä»»åç LLM éç¼çå½±é¿ãä¸»è¦åºæºåæ¬ MIMIC-IIIãMIMIC-IVãBioASQãPubMedQA å CheXpertï¼å®åä¿è¿äºé«çå ±åçæãè¨åºæè¦ååæè³æçæç­ä»»åçé²å±ãæ¬æç¸½çµäºå©ç¨éäºåºæºä¾æ¨é²å¤æ¨¡æé«çæºè½çææ°åæ©éï¼å¼·èª¿äºå°å·ææ´å¤§èªè¨å¤æ¨£æ§ãçµæ§åçµå­¸è³æååµæ°åææ¹æ³çè³æéçéæ±ãéé å·¥ä½ä¹çº LLM å¨é«å­¸ä¸­çæç¨æä¾äºæªä¾ç ç©¶çåºç¤ï¼çºé«çäººå·¥æºæ§çæ¼é²é åååºè²¢ç»ã

##### **Vascular Segmentation of Functional Ultrasound Images using Deep Learning**
2410.22365v1 by Hana Sebia, Thomas Guyet, MickaÃ«l Pereira, Marco Valdebenito, Hugues Berry, Benjamin Vidal

Segmentation of medical images is a fundamental task with numerous
applications. While MRI, CT, and PET modalities have significantly benefited
from deep learning segmentation techniques, more recent modalities, like
functional ultrasound (fUS), have seen limited progress. fUS is a non invasive
imaging method that measures changes in cerebral blood volume (CBV) with high
spatio-temporal resolution. However, distinguishing arterioles from venules in
fUS is challenging due to opposing blood flow directions within the same pixel.
Ultrasound localization microscopy (ULM) can enhance resolution by tracking
microbubble contrast agents but is invasive, and lacks dynamic CBV
quantification. In this paper, we introduce the first deep learning-based
segmentation tool for fUS images, capable of differentiating signals from
different vascular compartments, based on ULM automatic annotation and enabling
dynamic CBV quantification. We evaluate various UNet architectures on fUS
images of rat brains, achieving competitive segmentation performance, with 90%
accuracy, a 71% F1 score, and an IoU of 0.59, using only 100 temporal frames
from a fUS stack. These results are comparable to those from tubular structure
segmentation in other imaging modalities. Additionally, models trained on
resting-state data generalize well to images captured during visual
stimulation, highlighting robustness. This work offers a non-invasive,
cost-effective alternative to ULM, enhancing fUS data interpretation and
improving understanding of vessel function. Our pipeline shows high linear
correlation coefficients between signals from predicted and actual compartments
in both cortical and deeperregions, showcasing its ability to accurately
capture blood flow dynamics.

æè¦ï¼<paragraph>é«å­¸å½±åçåå²æ¯é åºç¤ä»»åï¼æè¨±å¤æç¨ãéç¶ MRIãCT å PET ç­æ¹å¼å·²å¾æ·±åº¦å­¸ç¿åå²æè¡ä¸­åçè¯å¤ï¼ä½ååè½æ§è¶é³æ³¢ (fUS) ç­è¼æ°çæ¹å¼é²å±æéãfUS æ¯ä¸ç¨®éä¾µå¥æ§çå½±åæ¹æ³ï¼å¯æ¸¬éè¦è¡å®¹é (CBV) çè®åï¼å·æé«æç©ºè§£æåº¦ãç¶èï¼ç±æ¼åä¸ååç´ ä¸­è¡æµæ¹åç¸åï¼å æ­¤å¨ fUS ä¸­ååå°åèåå°éèå·æææ°æ§ãè¶é³æ³¢å®ä½é¡¯å¾®é¡ (ULM) å¯ä»¥ééè¿½è¹¤å¾®æ°£æ³¡å°æ¯åä¾å¢å¼·è§£æåº¦ï¼ä½å·æä¾µå¥æ§ï¼ä¸ç¼ºä¹åæ CBV éåãå¨æ¬æä¸­ï¼æåä»ç´¹äºç¬¬ä¸ååºæ¼æ·±åº¦å­¸ç¿ç fUS å½±ååå²å·¥å·ï¼å®è½å¤ æ ¹æ ULM èªåè¨»è§£ååä¸åè¡ç®¡åå®¤çè¨èï¼ä¸¦åç¨åæ CBV éåãæåå¨èé¼ å¤§è¦ç fUS å½±åä¸è©ä¼°äºåç¨® UNet æ¶æ§ï¼åä½¿ç¨ fUS å çä¸­ç 100 åæéå¹ï¼å°±éå°äºå·æç«¶ç­åçåå²æè½ï¼æºç¢ºççº 90%ï¼F1 åæ¸çº 71%ï¼IoU çº 0.59ãéäºçµæèå¶ä»å½±åæ¹å¼ä¸­ç®¡ççµæ§åå²ççµæç¸ç¶ãæ­¤å¤ï¼å¨éæ­¢çæè³æä¸è¨ç·´çæ¨¡åå¯ä»¥å¾å¥½å°æ¨å»£å°å¨è¦è¦ºåºæ¿æéæ·åçå½±åï¼çªé¡¯äºå¶ç©©å¥æ§ãéé å·¥ä½æä¾äºä¸åéä¾µå¥æ§ãå·æææ¬æçç ULM æ¿ä»£æ¹æ¡ï¼å¢å¼·äº fUS è³æçè©®éï¼ä¸¦æ¹åäºå°è¡ç®¡åè½ççè§£ãæåçç®¡ç·å¨é æ¸¬åå®¤åå¯¦éåå®¤çè¨èä¹éé¡¯ç¤ºåºå¾é«çç·æ§ç¸éä¿æ¸ï¼ç¡è«æ¯å¨ç®è³ªéæ¯æ·±å±¤ååï¼é½å±ç¤ºäºå¶æºç¢ºææè¡æµåæçè½åã</paragraph>

##### **Language Models And A Second Opinion Use Case: The Pocket Professional**
2410.20636v1 by David Noever

This research tests the role of Large Language Models (LLMs) as formal second
opinion tools in professional decision-making, particularly focusing on complex
medical cases where even experienced physicians seek peer consultation. The
work analyzed 183 challenging medical cases from Medscape over a 20-month
period, testing multiple LLMs' performance against crowd-sourced physician
responses. A key finding was the high overall score possible in the latest
foundational models (>80% accuracy compared to consensus opinion), which
exceeds most human metrics reported on the same clinical cases (450 pages of
patient profiles, test results). The study rates the LLMs' performance
disparity between straightforward cases (>81% accuracy) and complex scenarios
(43% accuracy), particularly in these cases generating substantial debate among
human physicians. The research demonstrates that LLMs may be valuable as
generators of comprehensive differential diagnoses rather than as primary
diagnostic tools, potentially helping to counter cognitive biases in clinical
decision-making, reduce cognitive loads, and thus remove some sources of
medical error. The inclusion of a second comparative legal dataset (Supreme
Court cases, N=21) provides added empirical context to the AI use to foster
second opinions, though these legal challenges proved considerably easier for
LLMs to analyze. In addition to the original contributions of empirical
evidence for LLM accuracy, the research aggregated a novel benchmark for others
to score highly contested question and answer reliability between both LLMs and
disagreeing human practitioners. These results suggest that the optimal
deployment of LLMs in professional settings may differ substantially from
current approaches that emphasize automation of routine tasks.

æè¦ï¼éé ç ç©¶æ¸¬è©¦äºå¤§åèªè¨æ¨¡å (LLM) å¨å°æ¥­æ±ºç­ä¸­ä½çºæ­£å¼ç¬¬äºæè¦å·¥å·çè§è²ï¼ç¹å¥èéæ¼è¤éçé«çæ¡ä¾ï¼å³ä½¿ç¶é©è±å¯çé«å¸«ä¹æå°æ±ååè«®è©¢ãéé å·¥ä½åæäº Medscape å¨ 20 åææéç 183 åå·æææ°æ§çé«çæ¡ä¾ï¼æ¸¬è©¦å¤å LLM çè¡¨ç¾ï¼ä¸¦èç¾¤ç¾å¤åçé«å¸«åæé²è¡æ¯è¼ãä¸åééµç¼ç¾æ¯ææ°åºç¤æ¨¡åä¸­å¯è½çé«ç¸½é«åæ¸ï¼èå±è­æè¦ç¸æ¯ï¼æºç¢ºç >80%ï¼ï¼éè¶éäºéå°ç¸åè¨åºæ¡ä¾å ±åçå¤§å¤æ¸äººé¡ææ¨ï¼450 é çæ£èæªæ¡ãæª¢é©çµæï¼ãéé ç ç©¶è©ä¼°äº LLM å¨ç´æ¥æ¡ä¾ï¼æºç¢ºç >81%ï¼åè¤éæå¢ï¼æºç¢ºç 43%ï¼ä¹éçè¡¨ç¾å·®ç°ï¼ç¹å¥æ¯å¨éäºæ¡ä¾ä¸­ï¼æå¨äººé¡é«å¸«éç¢çå¤§éçè¾¯è«ãéé ç ç©¶è­æï¼LLM å¯è½æ¯æå¹å¼çå¨é¢éå¥è¨ºæ·ç¢çå¨ï¼èéä¸»è¦çè¨ºæ·å·¥å·ï¼æ½å¨æå©æ¼å°æè¨åºæ±ºç­ä¸­çèªç¥åèª¤ãæ¸å°èªç¥è² æï¼ä¸¦å æ­¤æ¶é¤ä¸äºé«çé¯èª¤çæ ¹æºãå å¥ç¬¬äºåæ¯è¼æ³å¾è³æéï¼æé«æ³é¢æ¡ä¾ï¼N=21ï¼çº AI ç¨æ¼ä¿é²ç¬¬äºæè¦æä¾äºé¡å¤çç¶é©èæ¯ï¼åç®¡éäºæ³å¾ææ°è¢«è­æå° LLM ä¾èªªæ´å®¹æåæãé¤äº LLM æºç¢ºæ§çç¶é©è­æçåå§è²¢ç»å¤ï¼éé ç ç©¶éå¯ç¸½äºä¸åæ°çåºæºï¼ä¾å¶ä»äººçº LLM åæè¦åæ­§çäººé¡å¾æ¥­äººå¡ä¹éé«åº¦æç­è­°çåé¡åç­æ¡çå¯é æ§é²è¡è©åãéäºçµæè¡¨æï¼LLM å¨å°æ¥­ç°å¢ä¸­çæä½³é¨ç½²å¯è½èå¼·èª¿èªååä¾è¡ä»»åçç¶åæ¹æ³æå¾å¤§ä¸åã

##### **Improving Decision Sparsity**
2410.20483v1 by Yiyang Sun, Tong Wang, Cynthia Rudin

Sparsity is a central aspect of interpretability in machine learning.
Typically, sparsity is measured in terms of the size of a model globally, such
as the number of variables it uses. However, this notion of sparsity is not
particularly relevant for decision-making; someone subjected to a decision does
not care about variables that do not contribute to the decision. In this work,
we dramatically expand a notion of decision sparsity called the Sparse
Explanation Value(SEV) so that its explanations are more meaningful. SEV
considers movement along a hypercube towards a reference point. By allowing
flexibility in that reference and by considering how distances along the
hypercube translate to distances in feature space, we can derive sparser and
more meaningful explanations for various types of function classes. We present
cluster-based SEV and its variant tree-based SEV, introduce a method that
improves credibility of explanations, and propose algorithms that optimize
decision sparsity in machine learning models.

æè¦ï¼ç¨çæ§æ¯æ©å¨å­¸ç¿ä¸­å¯è§£éæ§çæ ¸å¿é¢åã
ä¸è¬ä¾èªªï¼ç¨çæ§æ¯ä»¥æ¨¡åæ´é«çå¤§å°ä¾è¡¡éï¼ä¾å¦å®ä½¿ç¨çè®æ¸æ¸éãç¶èï¼éç¨®ç¨çæ§æ¦å¿µèæ±ºç­å¶å®ä¸¦ç¡ç¹å¥ç¸éï¼åå°æ±ºç­å½±é¿çäººä¸¦ä¸å¨ä¹é£äºèæ±ºç­ç¡éçè®æ¸ãå¨éé å·¥ä½ä¸­ï¼æåå¤§å¹æ´å±äºä¸åç¨±çºç¨çè§£éå¼ (SEV) çæ±ºç­ç¨çæ§æ¦å¿µï¼ä½¿å¶è§£éæ´å·æç¾©ãSEV èéæ²¿èè¶ç«æ¹é«æååèé»çç§»åãééåè¨±è©²åèçéæ´»æ§ï¼ä¸¦èéæ²¿èè¶ç«æ¹é«çè·é¢å¦ä½è½æçºç¹å¾µç©ºéä¸­çè·é¢ï¼æåå¯ä»¥éå°åç¨®å½æ¸é¡å¥æ¨å°åºæ´ç¨çä¸æ´ææç¾©çè§£éãæåæåºåºæ¼å¢éç SEV åå¶è®é«åºæ¼æ¨¹ççµæ§ç SEVï¼å¼å¥ä¸ç¨®æ¹æ³ä¾æåè§£éçå¯ä¿¡åº¦ï¼ä¸¦æåºæä½³åæ©å¨å­¸ç¿æ¨¡åä¸­æ±ºç­ç¨çæ§çæ¼ç®æ³ã

##### **MedGo: A Chinese Medical Large Language Model**
2410.20428v1 by Haitao Zhang, Bo An

Large models are a hot research topic in the field of artificial
intelligence. Leveraging their generative capabilities has the potential to
enhance the level and quality of medical services. In response to the
limitations of current large language models, which often struggle with
accuracy and have narrow capabilities in medical applications, this paper
presents a Chinese medical large language model, MedGo. MedGo was trained using
a combination of high quality unsupervised medical data, supervised data, and
preference alignment data, aimed at enhancing both its versatility and
precision in medical tasks. The model was evaluated through the public CBLUE
benchmark and a manually constructed dataset ClinicalQA. The results
demonstrate that MedGo achieved promising performance across various Chinese
medical information processing tasks, achieved the first place in the CBLUE
evaluation. Additionally, on our constructed dataset ClinicalQA, MedGo
outperformed its base model Qwen2, highlighting its potential to improve both
automated medical question answering and clinical decision support. These
experimental results demonstrate that MedGo possesses strong information
processing capabilities in the medical field. At present, we have successfully
deployed MedGo at Shanghai East Hospital.

æè¦ï¼å¤§åæ¨¡åæ¯äººå·¥æºè½é¢åçç ç©¶ç­ç¹ãå©ç¨å®ä»¬çæçè½åæå¯è½æé«å»çæå¡çæ°´å¹³åè´¨éãä¸ºäºè§£å³å½åå¤§åè¯­è¨æ¨¡åçå±éæ§ï¼è¿äºæ¨¡åéå¸¸é¾ä»¥è¾¾å°åç¡®æ§ï¼å¹¶ä¸å¨å»çåºç¨ä¸­çè½åè¾çªï¼æ¬ææåºäºä¸ä¸ªä¸­æå»çå¤§åè¯­è¨æ¨¡å MedGoãMedGo ä½¿ç¨é«è´¨éæ çç£å»çæ°æ®ãçç£æ°æ®ååå¥½å¯¹é½æ°æ®çç»åè¿è¡è®­ç»ï¼æ¨å¨å¢å¼ºå¶å¨å»çä»»å¡ä¸­çå¤åè½æ§ååç¡®æ§ãè¯¥æ¨¡åéè¿å¬å± CBLUE åºååæå¨æå»ºçæ°æ®é ClinicalQA è¿è¡äºè¯ä¼°ãç»æè¡¨æï¼MedGo å¨åç§ä¸­æå»çä¿¡æ¯å¤çä»»å¡ä¸­åå¾äºå¯åçæ§è½ï¼å¨ CBLUE è¯ä¼°ä¸­åå¾äºç¬¬ä¸åãæ­¤å¤ï¼å¨æä»¬çæå»ºæ°æ®é ClinicalQA ä¸ï¼MedGo ä¼äºå¶åºç¡æ¨¡å Qwen2ï¼çªåºäºå¶å¨æ¹è¿èªå¨åå»çé®é¢è§£ç­åä¸´åºå³ç­æ¯ææ¹é¢çæ½åãè¿äºå®éªç»æè¡¨æï¼MedGo å¨å»çé¢åæ¥æå¼ºå¤§çä¿¡æ¯å¤çè½åãç®åï¼æä»¬å·²æåå¨ä¸æµ·ä¸æ¹å»é¢é¨ç½²äº MedGoã

##### **Addressing the Pitfalls of Image-Based Structural Health Monitoring: A Focus on False Positives, False Negatives, and Base Rate Bias**
2410.20384v1 by Vagelis Plevris

This study explores the limitations of image-based structural health
monitoring (SHM) techniques in detecting structural damage. Leveraging machine
learning and computer vision, image-based SHM offers a scalable and efficient
alternative to manual inspections. However, its reliability is impacted by
challenges such as false positives, false negatives, and environmental
variability, particularly in low base rate damage scenarios. The Base Rate Bias
plays a significant role, as low probabilities of actual damage often lead to
misinterpretation of positive results. This study uses both Bayesian analysis
and a frequentist approach to evaluate the precision of damage detection
systems, revealing that even highly accurate models can yield misleading
results when the occurrence of damage is rare. Strategies for mitigating these
limitations are discussed, including hybrid systems that combine multiple data
sources, human-in-the-loop approaches for critical assessments, and improving
the quality of training data. These findings provide essential insights into
the practical applicability of image-based SHM techniques, highlighting both
their potential and their limitations for real-world infrastructure monitoring.

æè¦ï¼æ¬ç ç©¶æ¢è¨äºåºæ¼å½±åççµæ§å¥åº·ç£æ¸¬ (SHM) æè¡å¨æª¢æ¸¬çµæ§æå£æ¹é¢çéå¶ãèç±æ©å¨å­¸ç¿åé»è¦è¦è¦ºï¼åºæ¼å½±åç SHM æä¾äºå¯æ´åä¸ææççæ¿ä»£äººå·¥æª¢æ¥çæ¹æ³ãç¶èï¼å¶å¯é æ§åå°ææ°çå½±é¿ï¼ä¾å¦åé½æ§ãåé°æ§ï¼ä»¥åç°å¢è®ç°æ§ï¼ç¹å¥æ¯å¨ä½åºåºæå£æå¢ä¸­ãåºåºæ¯çåå·®æ®æ¼äºéè¦çè§è²ï¼å çºå¯¦éæå£çä½æ©çå¸¸å¸¸å°è´å°æ¼é½æ§çµæçèª¤è§£ãæ¬ç ç©¶åæä½¿ç¨è²æ°åæåé »çè«æ¹æ³ä¾è©ä¼°æå£æª¢æ¸¬ç³»çµ±çç²¾æºåº¦ï¼æ­ç¤ºå³ä½¿é«åº¦ç²¾ç¢ºçæ¨¡åå¨æå£ç¼ççç¨å°æä¹å¯è½ç¢çèª¤å°æ§ççµæãè¨è«äºæ¸è¼éäºéå¶çç­ç¥ï¼åæ¬çµåå¤éè³æä¾æºçæ··åç³»çµ±ãå°æ¼ééµè©ä¼°çäººé¡ä»å¥æ¹æ³ï¼ä»¥åæ¹åè¨ç·´è³æåè³ªãéäºç¼ç¾æä¾äºå°æ¼åºæ¼å½±åç SHM æè¡å¯¦åé©ç¨æ§çéè¦è¦è§£ï¼çªé¡¯äºå®åå¨ç¾å¯¦ä¸çåºç¤è¨­æ½ç£æ¸¬æ¹é¢çæ½ååéå¶ã

##### **R-LLaVA: Improving Med-VQA Understanding through Visual Region of Interest**
2410.20327v1 by Xupeng Chen, Zhixin Lai, Kangrui Ruan, Shichu Chen, Jiaxiang Liu, Zuozhu Liu

Artificial intelligence has made significant strides in medical visual
question answering (Med-VQA), yet prevalent studies often interpret images
holistically, overlooking the visual regions of interest that may contain
crucial information, potentially aligning with a doctor's prior knowledge that
can be incorporated with minimal annotations (e.g., bounding boxes). To address
this gap, this paper introduces R-LLaVA, designed to enhance biomedical VQA
understanding by integrating simple medical annotations as prior knowledge
directly into the image space through CLIP. These annotated visual regions of
interest are then fed into the LLaVA model during training, aiming to enrich
the model's understanding of biomedical queries. Experimental evaluation on
four standard Med-VQA datasets demonstrates R-LLaVA's superiority over existing
state-of-the-art (SoTA) methods. Additionally, to verify the model's capability
in visual comprehension, a novel multiple-choice medical visual understanding
dataset is introduced, confirming the positive impact of focusing on visual
regions of interest in advancing biomedical VQA understanding.

æè¦ï¼äººå·¥æºæ§å¨é«å­¸è¦è¦ºåç­ (Med-VQA) ä¸­åå¾é¡¯èé²å±ï¼ä½æ®éçç ç©¶éå¸¸æ´é«è©®éå½±åï¼å¿½ç¥å¯è½åå«ééµè³è¨çè¦è¦ºæèè¶£ååï¼éå¯è½æèé«ççååç¥è­ä¸è´ï¼èååç¥è­å¯ä»¥ééæå°çè¨»è§£ï¼ä¾å¦éçæ¡ï¼ç´å¥ãçºäºè§£æ±ºéåå·®è·ï¼æ¬ææåº R-LLaVAï¼æ¨å¨éé CLIP å°ç°¡å®çé«å­¸è¨»è§£ä½çºååç¥è­ç´æ¥æ´åå°å½±åç©ºéä¸­ï¼ä»¥å¢å¼·çç©é«å­¸ VQA çè§£ãéäºå¸¶æè¨»è§£çè¦è¦ºæèè¶£ååæå¨è¨ç·´æéè¼¸å¥ LLaVA æ¨¡åï¼ç®æ¨æ¯è±å¯æ¨¡åå°çç©é«å­¸æ¥è©¢ççè§£ãå¨ååæ¨æº Med-VQA è³æéä¸çå¯¦é©è©ä¼°è­æäº R-LLaVA åªæ¼ç¾æçæåé² (SoTA) æ¹æ³ãæ­¤å¤ï¼çºäºé©è­æ¨¡åå¨è¦è¦ºçè§£ä¸­çè½åï¼æ¬ææåºäºä¸åæ°ç©çå¤é¸é¡é«å­¸è¦è¦ºçè§£è³æéï¼è­å¯¦äºå°æ³¨æ¼è¦è¦ºæèè¶£ååå°æ¨åçç©é«å­¸ VQA çè§£çæ­£é¢å½±é¿ã

##### **Enhancing Community Vision Screening -- AI Driven Retinal Photography for Early Disease Detection and Patient Trust**
2410.20309v1 by Xiaofeng Lei, Yih-Chung Tham, Jocelyn Hui Lin Goh, Yangqin Feng, Yang Bai, Zhi Da Soh, Rick Siow Mong Goh, Xinxing Xu, Yong Liu, Ching-Yu Cheng

Community vision screening plays a crucial role in identifying individuals
with vision loss and preventing avoidable blindness, particularly in rural
communities where access to eye care services is limited. Currently, there is a
pressing need for a simple and efficient process to screen and refer
individuals with significant eye disease-related vision loss to tertiary eye
care centers for further care. An ideal solution should seamlessly and readily
integrate with existing workflows, providing comprehensive initial screening
results to service providers, thereby enabling precise patient referrals for
timely treatment. This paper introduces the Enhancing Community Vision
Screening (ECVS) solution, which addresses the aforementioned concerns with a
novel and feasible solution based on simple, non-invasive retinal photography
for the detection of pathology-based visual impairment. Our study employs four
distinct deep learning models: RETinal photo Quality Assessment (RETQA),
Pathology Visual Impairment detection (PVI), Eye Disease Diagnosis (EDD) and
Visualization of Lesion Regions of the eye (VLR). We conducted experiments on
over 10 datasets, totaling more than 80,000 fundus photos collected from
various sources. The models integrated into ECVS achieved impressive AUC scores
of 0.98 for RETQA, 0.95 for PVI, and 0.90 for EDD, along with a DICE
coefficient of 0.48 for VLR. These results underscore the promising
capabilities of ECVS as a straightforward and scalable method for
community-based vision screening.

æè¦ï¼ç¤¾åè¦åç¯©æª¢å¨è¾¨è­è¦ååæçåäººä»¥åé é²å¯é¿åçå¤±ææ¹é¢æ®æ¼èè³ééè¦çè§è²ï¼ç¹å¥æ¯å¨åå¾ç¼ç§ä¿å¥æååéçéæç¤¾åä¸­ãç®åï¼è¿«åéè¦ä¸åç°¡å®ä¸ææççæµç¨ä¾ç¯©é¸åè½ä»å·æé¡¯èç¼ç¾ç¸éè¦ååæçåäººè³ä¸ç´ç¼ç§ä¿å¥ä¸­å¿ä»¥æ¥åé²ä¸æ­¥çç§è­·ãçæ³çè§£æ±ºæ¹æ¡æèç¾æçå·¥ä½æµç¨ç¡ç¸«ä¸è¼æå°æ´åï¼æä¾å¨é¢çåæ­¥ç¯©æª¢çµæçµ¦æåæä¾èï¼é²èè½ç²¾ç¢ºå°è½ä»æ£èä»¥ç²å¾åæçæ²»çãæ¬æä»ç´¹äºå¢å¼·ç¤¾åè¦åç¯©æª¢ (ECVS) è§£æ±ºæ¹æ¡ï¼è©²æ¹æ¡ééä¸ç¨®æ°ç©ä¸å¯è¡çè§£æ±ºæ¹æ¡ä¾è§£æ±ºä¸è¿°åé¡ï¼éåè§£æ±ºæ¹æ¡æ¯åºæ¼ç°¡å®ãéä¾µå¥æ§çè¦ç¶²èæå½±ä¾åµæ¸¬ççæ§çè¦ååæãæåçç ç©¶æ¡ç¨åç¨®ä¸åçæ·±åº¦å­¸ç¿æ¨¡åï¼è¦ç¶²èç§çåè³ªè©ä¼° (RETQA)ãççæ§è¦ååæåµæ¸¬ (PVI)ãç¼ç¾è¨ºæ· (EDD) åç¼ççç¶ååè¦è¦ºå (VLR)ãæåå¨è¶é 10 åè³æéä¸é²è¡å¯¦é©ï¼ç¸½è¨è¶é 80,000 å¼µå¾åç¨®ä¾æºæ¶éèä¾çç¼åºç§çãæ´åå° ECVS çæ¨¡åéå°äºä»¤äººå°è±¡æ·±å»ç AUC åæ¸ï¼RETQA çº 0.98ãPVI çº 0.95ãEDD çº 0.90ï¼ä»¥å VLR ç DICE ä¿æ¸çº 0.48ãéäºçµæå¼·èª¿äº ECVS ä½çºä¸ç¨®ç¨æ¼ç¤¾åè¦åç¯©æª¢çç´æ¥ä¸å¯æ´åæ¹æ³çæ½åã

##### **Modelling of Economic Implications of Bias in AI-Powered Health Emergency Response Systems**
2410.20229v1 by Katsiaryna Bahamazava

We present a theoretical framework assessing the economic implications of
bias in AI-powered emergency response systems. Integrating health economics,
welfare economics, and artificial intelligence, we analyze how algorithmic bias
affects resource allocation, health outcomes, and social welfare. By
incorporating a bias function into health production and social welfare models,
we quantify its impact on demographic groups, showing that bias leads to
suboptimal resource distribution, increased costs, and welfare losses. The
framework highlights efficiency-equity trade-offs and provides economic
interpretations. We propose mitigation strategies, including
fairness-constrained optimization, algorithmic adjustments, and policy
interventions. Our findings offer insights for policymakers, emergency service
providers, and technology developers, emphasizing the need for AI systems that
are efficient and equitable. By addressing the economic consequences of biased
AI, this study contributes to policies and technologies promoting fairness,
efficiency, and social welfare in emergency response services.

æè¦ï¼æåæåºä¸åçè«æ¶æ§ï¼è©ä¼°äººå·¥æºæ§ç·æ¥æè®ç³»çµ±ä¸­åèª¤çç¶æ¿å½±é¿ãæ´åå¥åº·ç¶æ¿å­¸ãç¦å©ç¶æ¿å­¸åäººå·¥æºæ§ï¼æååææ¼ç®æ³åèª¤å¦ä½å½±é¿è³æºåéãå¥åº·çµæåç¤¾æç¦å©ãééå°åèª¤å½æ¸ç´å¥å¥åº·çç¢åç¤¾æç¦å©æ¨¡åï¼æåéåå¶å°äººå£ç¾¤é«çå½±é¿ï¼é¡¯ç¤ºåèª¤å°è´æ¬¡åªè³æºåéãå¢å ææ¬åç¦å©æå¤±ãè©²æ¶æ§å¼·èª¿æçèå¬å¹³æ§çæ¬è¡¡ï¼ä¸¦æä¾ç¶æ¿è©®éãæåæåºç·©è§£ç­ç¥ï¼åæ¬å¬å¹³ç´ææä½³åãæ¼ç®æ³èª¿æ´åæ¿ç­å¹²é ãæåçç ç©¶çµæçºæ¿ç­å¶å®èãç·æ¥æåæä¾èåæè¡éç¼èæä¾è¦è§£ï¼å¼·èª¿éè¦å¼å·æçåå¬å¹³æ§ç AI ç³»çµ±ãééæ¢è¨æåèª¤ç AI çç¶æ¿å¾æï¼æ¬ç ç©¶æå©æ¼å¶å®ä¿é²å¬å¹³æ§ãæçåç¤¾æç¦å©çæ¿ç­åæè¡ï¼ä»¥éç¨æ¼ç·æ¥æè®æåã

##### **Generative AI in Health Economics and Outcomes Research: A Taxonomy of Key Definitions and Emerging Applications, an ISPOR Working Group Report**
2410.20204v1 by Rachael Fleurence, Xiaoyan Wang, Jiang Bian, Mitchell K. Higashi, Turgay Ayer, Hua Xu, Dalia Dawoud, Jagpreet Chhatwal

Objective: This article offers a taxonomy of generative artificial
intelligence (AI) for health economics and outcomes research (HEOR), explores
its emerging applications, and outlines methods to enhance the accuracy and
reliability of AI-generated outputs. Methods: The review defines foundational
generative AI concepts and highlights current HEOR applications, including
systematic literature reviews, health economic modeling, real-world evidence
generation, and dossier development. Approaches such as prompt engineering
(zero-shot, few-shot, chain-of-thought, persona pattern prompting),
retrieval-augmented generation, model fine-tuning, and the use of
domain-specific models are introduced to improve AI accuracy and reliability.
Results: Generative AI shows significant potential in HEOR, enhancing
efficiency, productivity, and offering novel solutions to complex challenges.
Foundation models are promising in automating complex tasks, though challenges
remain in scientific reliability, bias, interpretability, and workflow
integration. The article discusses strategies to improve the accuracy of these
AI tools. Conclusion: Generative AI could transform HEOR by increasing
efficiency and accuracy across various applications. However, its full
potential can only be realized by building HEOR expertise and addressing the
limitations of current AI technologies. As AI evolves, ongoing research and
innovation will shape its future role in the field.

æè¦ï¼**ç®æ¨ï¼**æ¬ææä¾äºä¸ç¨®çæå¼äººå·¥æºæ§ï¼AIï¼çåé¡æ³ï¼ç¨æ¼å¥åº·ç¶æ¿å­¸åææç ç©¶ï¼HEORï¼ï¼æ¢è¨å¶æ°èæç¨ï¼ä¸¦æ¦è¿°å¢å¼· AI çæçè¼¸åºæºç¢ºæ§åå¯é æ§çæ¹æ³ã**æ¹æ³ï¼**æ¬åé¡§å®ç¾©äºçæå¼ AI çåºç¤æ¦å¿µï¼ä¸¦éé»ä»ç´¹äºç¶åç HEOR æç¨ï¼åæ¬ç³»çµ±æç»åé¡§ãå¥åº·ç¶æ¿æ¨¡åãçå¯¦ä¸çè­æçæåæªæ¡éç¼ãä»ç´¹äºè«¸å¦æç¤ºå·¥ç¨ï¼é¶æ¬¡ãå°æ¬¡ãæç¶­éãè§è²æ¨¡å¼æç¤ºï¼ãæª¢ç´¢å¢å¼·çæãæ¨¡åå¾®èª¿åä½¿ç¨ç¹å®é åæ¨¡åç­æ¹æ³ï¼ä»¥æé« AI çæºç¢ºæ§åå¯é æ§ã**çµæï¼**çæå¼ AI å¨ HEOR ä¸­é¡¯ç¤ºåºé¡¯èçæ½åï¼æé«æçãçç¢åï¼ä¸¦çºè¤éçææ°æä¾åµæ°çè§£æ±ºæ¹æ¡ãåºç¤æ¨¡åå¨èªååè¤éä»»åæ¹é¢å¾æåæ¯ï¼åç®¡å¨ç§å­¸å¯é æ§ãåå·®ãå¯è§£éæ§åå·¥ä½æµç¨æ´åæ¹é¢ä»ç¶å­å¨ææ°ãæ¬æè¨è«äºæé«éäº AI å·¥å·æºç¢ºæ§çç­ç¥ã**çµè«ï¼**çæå¼ AI å¯ä»¥ééæé«åç¨®æç¨ä¸­çæçåæºç¢ºæ§ä¾è½è® HEORãç¶èï¼åªæééå»ºç« HEOR å°æ¥­ç¥è­ä¸¦è§£æ±ºç¶å AI æè¡çå±éæ§ï¼æè½å¯¦ç¾å¶å¨é¨æ½åãé¨è AI çç¼å±ï¼æçºçç ç©¶ååµæ°å°å¡é å¶å¨è©²é åçæªä¾è§è²ã

##### **Diff-CXR: Report-to-CXR generation through a disease-knowledge enhanced diffusion model**
2410.20165v1 by Peng Huang, Bowen Guo, Shuyu Liang, Junhu Fu, Yuanyuan Wang, Yi Guo

Text-To-Image (TTI) generation is significant for controlled and diverse
image generation with broad potential applications. Although current medical
TTI methods have made some progress in report-to-Chest-Xray (CXR) generation,
their generation performance may be limited due to the intrinsic
characteristics of medical data. In this paper, we propose a novel
disease-knowledge enhanced Diffusion-based TTI learning framework, named
Diff-CXR, for medical report-to-CXR generation. First, to minimize the negative
impacts of noisy data on generation, we devise a Latent Noise Filtering
Strategy that gradually learns the general patterns of anomalies and removes
them in the latent space. Then, an Adaptive Vision-Aware Textual Learning
Strategy is designed to learn concise and important report embeddings in a
domain-specific Vision-Language Model, providing textual guidance for
Chest-Xray generation. Finally, by incorporating the general disease knowledge
into the pretrained TTI model via a delicate control adapter, a
disease-knowledge enhanced diffusion model is introduced to achieve realistic
and precise report-to-CXR generation. Experimentally, our Diff-CXR outperforms
previous SOTA medical TTI methods by 33.4\% / 8.0\% and 23.8\% / 56.4\% in the
FID and mAUC score on MIMIC-CXR and IU-Xray, with the lowest computational
complexity at 29.641 GFLOPs. Downstream experiments on three thorax disease
classification benchmarks and one CXR-report generation benchmark demonstrate
that Diff-CXR is effective in improving classical CXR analysis methods.
Notably, models trained on the combination of 1\% real data and synthetic data
can achieve a competitive mAUC score compared to models trained on all data,
presenting promising clinical applications.

æè¦ï¼æå­è½å½±åï¼TTIï¼çæå°æ¼å»£æ³æ½å¨æç¨ä¸­åæ§ä¸å¤æ¨£åçå½±åçæè³ééè¦ãåç®¡ç®åçé«ç TTI æ¹æ³å¨å ±åè½è¸é¨ X åï¼CXRï¼çææ¹é¢åå¾äºä¸äºé²å±ï¼ä½ç±æ¼é«çè³æçå§å¨ç¹æ§ï¼å¶çææè½å¯è½æåå°éå¶ãå¨æ¬æä¸­ï¼æåæåºäºä¸ååçº Diff-CXR çæ°ç¾çç¥è­å¢å¼·æ´æ£å¼ TTI å­¸ç¿æ¶æ§ï¼ç¨æ¼é«çå ±åè½ CXR çæãé¦åï¼çºäºæå°åéè¨è³æå°çæçè² é¢å½±é¿ï¼æåè¨­è¨äºä¸åæ½å¨éè¨éæ¿¾ç­ç¥ï¼éæ¼¸å­¸ç¿ç°å¸¸çä¸è¬æ¨¡å¼ä¸¦å°å¶å¾æ½å¨ç©ºéä¸­ç§»é¤ãç¶å¾ï¼è¨­è¨äºä¸åèªé©æè¦è¦ºæç¥æå­å­¸ç¿ç­ç¥ï¼ä»¥å¨ç¹å®é åçè¦è¦ºèªè¨æ¨¡åä¸­å­¸ç¿ç°¡æ½ä¸éè¦çå ±ååµå¥ï¼çºè¸é¨ X åçææä¾æå­æå°ãæå¾ï¼ééä¸åç²¾å·§çæ§å¶é©éå¨å°ä¸è¬ç¾çç¥è­æ´åå°é è¨ç·´ç TTI æ¨¡åä¸­ï¼å¼å¥äºä¸åç¾çç¥è­å¢å¼·æ´æ£æ¨¡åï¼ä»¥å¯¦ç¾é¼çä¸ç²¾ç¢ºçå ±åè½ CXR çæãå¨å¯¦é©ä¸­ï¼æåç Diff-CXR å¨ MIMIC-CXR å IU-Xray ä¸ç FID å mAUC åæ¸åå¥æ¯ååç SOTA é«ç TTI æ¹æ³é«åº 33.4% / 8.0% å 23.8% / 56.4%ï¼ä¸éç®è¤éåº¦æä½ï¼çº 29.641 GFLOPsãå¨ä¸åè¸èç¾çåé¡åºæºåä¸å CXR å ±åçæåºæºä¸çä¸æ¸¸å¯¦é©è­æï¼Diff-CXR å¯æææ¹åå³çµ±ç CXR åææ¹æ³ãå¼å¾æ³¨æçæ¯ï¼å¨ 1% çå¯¦è³æååæè³æççµåä¸è¨ç·´çæ¨¡åï¼èå¨ææè³æä¸è¨ç·´çæ¨¡åç¸æ¯ï¼å¯ä»¥éå°æç«¶ç­åç mAUC åæ¸ï¼éé¡¯ç¤ºåºæåæ¯çè¨åºæç¨ã

##### **On-Site Precise Screening of SARS-CoV-2 Systems Using a Channel-Wise Attention-Based PLS-1D-CNN Model with Limited Infrared Signatures**
2410.20132v1 by Wenwen Zhang, Zhouzhuo Tang, Yingmei Feng, Xia Yu, Qi Jie Wang, Zhiping Lin

During the early stages of respiratory virus outbreaks, such as severe acute
respiratory syndrome coronavirus 2 (SARS-CoV-2), the efficient utilize of
limited nasopharyngeal swabs for rapid and accurate screening is crucial for
public health. In this study, we present a methodology that integrates
attenuated total reflection-Fourier transform infrared spectroscopy (ATR-FTIR)
with the adaptive iteratively reweighted penalized least squares (airPLS)
preprocessing algorithm and a channel-wise attention-based partial least
squares one-dimensional convolutional neural network (PLS-1D-CNN) model,
enabling accurate screening of infected individuals within 10 minutes. Two
cohorts of nasopharyngeal swab samples, comprising 126 and 112 samples from
suspected SARS-CoV-2 Omicron variant cases, were collected at Beijing You'an
Hospital for verification. Given that ATR-FTIR spectra are highly sensitive to
variations in experimental conditions, which can affect their quality, we
propose a biomolecular importance (BMI) evaluation method to assess signal
quality across different conditions, validated by comparing BMI with PLS-GBM
and PLS-RF results. For the ATR-FTIR signals in cohort 2, which exhibited a
higher BMI, airPLS was utilized for signal preprocessing, followed by the
application of the channel-wise attention-based PLS-1D-CNN model for screening.
The experimental results demonstrate that our model outperforms recently
reported methods in the field of respiratory virus spectrum detection,
achieving a recognition screening accuracy of 96.48%, a sensitivity of 96.24%,
a specificity of 97.14%, an F1-score of 96.12%, and an AUC of 0.99. It meets
the World Health Organization (WHO) recommended criteria for an acceptable
product: sensitivity of 95.00% or greater and specificity of 97.00% or greater
for testing prior SARS-CoV-2 infection in moderate to high volume scenarios.

æè¦ï¼<paragraph>å¨å¼å¸éçæ¯çç¼çæ©æéæ®µï¼ä¾å¦å´éæ¥æ§å¼å¸éçåç¾¤å ççæ¯ 2 (SARS-CoV-2)ï¼ææå©ç¨æéçé¼»å½æ­å­é²è¡å¿«éä¸æºç¢ºçç¯©æª¢å°æ¼å¬å±è¡çè³ééè¦ãå¨éé ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®æ¹æ³ï¼å°è¡°æ¸å¨åå°åç«èè½æç´å¤ç·åè­ (ATR-FTIR) èé©ææ§è¿­ä»£å æ¬æ²ç½°æå°å¹³æ¹ (airPLS) é èçæ¼ç®æ³åééæ³¨æååºç¤åæå°äºä¹ä¸ç¶­å·ç©ç¥ç¶ç¶²è·¯ (PLS-1D-CNN) æ¨¡åæ´åï¼å¯å¨ 10 åéå§æºç¢ºç¯©é¸åææèãæ¶éäºå©çµé¼»å½æ­å­æ¨£æ¬ï¼åå¥åå«ä¾èªçä¼¼ SARS-CoV-2 Omicron è®ç°æ ªçä¾ç 126 åå 112 åæ¨£æ¬ï¼å¨åäº¬ä½å®é«é¢é²è¡é©è­ãç±æ¼ ATR-FTIR åè­å°å¯¦é©æ¢ä»¶çè®åé«åº¦ææï¼éå¯è½æå½±é¿å¶åè³ªï¼æåæåºäºä¸ç¨®çç©åå­éè¦æ§ (BMI) è©ä¼°æ¹æ³ä¾è©ä¼°ä¸åæ¢ä»¶ä¸çè¨èåè³ªï¼ä¸¦ééå° BMI è PLS-GBM å PLS-RF çµæé²è¡æ¯è¼ä¾é©è­ãå°æ¼å¨ç¬¬ 2 çµä¸­è¡¨ç¾åºè¼é« BMI ç ATR-FTIR è¨èï¼æåå©ç¨ airPLS é²è¡è¨èé èçï¼ç¶å¾æç¨åºæ¼ééæ³¨æåç PLS-1D-CNN æ¨¡åé²è¡ç¯©é¸ãå¯¦é©çµæè¡¨æï¼æåçæ¨¡ååªæ¼å¼å¸éçæ¯åè­æª¢æ¸¬é åæè¿å ±åçæ¹æ³ï¼å¯¦ç¾äº 96.48% çè­å¥ç¯©é¸æºç¢ºçã96.24% çéæåº¦ã97.14% çç¹ç°æ§ã96.12% ç F1 åæ¸å 0.99 ç AUCãå®ç¬¦åä¸çè¡ççµç¹ (WHO) æ¨è¦çå¯ç¨ç¢åæ¨æºï¼å¨ä¸­é«éå ´æ¯ä¸­æ¸¬è©¦åå SARS-CoV-2 æææï¼éæåº¦çº 95.00% ææ´é«ï¼ç¹ç°æ§çº 97.00% ææ´é«ã</paragraph>

##### **Transforming Precision: A Comparative Analysis of Vision Transformers, CNNs, and Traditional ML for Knee Osteoarthritis Severity Diagnosis**
2410.20062v1 by Tasnim Sakib Apon, Md. Fahim-Ul-Islam, Nafiz Imtiaz Rafin, Joya Akter, Md. Golam Rabiul Alam

Knee osteoarthritis(KO) is a degenerative joint disease that can cause severe
pain and impairment. With increased prevalence, precise diagnosis by medical
imaging analytics is crucial for appropriate illness management. This research
investigates a comparative analysis between traditional machine learning
techniques and new deep learning models for diagnosing KO severity from X-ray
pictures. This study does not introduce new architectural innovations but
rather illuminates the robust applicability and comparative effectiveness of
pre-existing ViT models in a medical imaging context, specifically for KO
severity diagnosis. The insights garnered from this comparative analysis
advocate for the integration of advanced ViT models in clinical diagnostic
workflows, potentially revolutionizing the precision and reliability of KO
assessments. This study does not introduce new architectural innovations but
rather illuminates the robust applicability and comparative effectiveness of
pre-existing ViT models in a medical imaging context, specifically for KO
severity diagnosis. The insights garnered from this comparative analysis
advocate for the integration of advanced ViT models in clinical diagnostic
workflows, potentially revolutionizing the precision & reliability of KO
assessments. The study utilizes an osteoarthritis dataset from the
Osteoarthritis Initiative (OAI) comprising images with 5 severity categories
and uneven class distribution. While classic machine learning models like
GaussianNB and KNN struggle in feature extraction, Convolutional Neural
Networks such as Inception-V3, VGG-19 achieve better accuracy between 55-65% by
learning hierarchical visual patterns. However, Vision Transformer
architectures like Da-VIT, GCViT and MaxViT emerge as indisputable champions,
displaying 66.14% accuracy, 0.703 precision, 0.614 recall, AUC exceeding 0.835
thanks to self-attention processes.

æè¦ï¼<paragraph>èéª¨éç¯ç (KO) æ¯ä¸ç¨®éåæ§éç¯ç¾çï¼å¯è½å°è´å´éç¼çååè½éç¤ãé¨èæ£ççä¸åï¼ééé«å­¸å½±ååæé²è¡ç²¾ç¢ºè¨ºæ·å°æ¼é©ç¶çç¾çç®¡çè³ééè¦ãæ¬ç ç©¶æ¢è¨å³çµ±æ©å¨å­¸ç¿æè¡åæ°çæ·±åº¦å­¸ç¿æ¨¡åå¨å¾ X åå½±åè¨ºæ· KO å´éç¨åº¦ä¹éçæ¯è¼åæãæ¬ç ç©¶ä¸¦æªæåºæ°çæ¶æ§åµæ°ï¼èæ¯é¡æäºé åå­å¨ç ViT æ¨¡åå¨é«å­¸å½±åæå¢ä¸­çå¼·å¤§é©ç¨æ§åæ¯è¼æè½ï¼ç¹å¥æ¯éå° KO å´éç¨åº¦è¨ºæ·ãå¾æ­¤æ¯è¼åæä¸­ç²å¾çè¦è§£ä¸»å¼µå°åé²ç ViT æ¨¡åæ´åå°è¨åºè¨ºæ·å·¥ä½æµç¨ä¸­ï¼éå¯è½æå¾¹åºæ¹è® KO è©ä¼°çç²¾ç¢ºåº¦åå¯é æ§ãæ¬ç ç©¶ä¸¦æªæåºæ°çæ¶æ§åµæ°ï¼èæ¯é¡æäºé åå­å¨ç ViT æ¨¡åå¨é«å­¸å½±åæå¢ä¸­çå¼·å¤§é©ç¨æ§åæ¯è¼æè½ï¼ç¹å¥æ¯éå° KO å´éç¨åº¦è¨ºæ·ãå¾æ­¤æ¯è¼åæä¸­ç²å¾çè¦è§£ä¸»å¼µå°åé²ç ViT æ¨¡åæ´åå°è¨åºè¨ºæ·å·¥ä½æµç¨ä¸­ï¼éå¯è½æå¾¹åºæ¹è® KO è©ä¼°çç²¾ç¢ºåº¦åå¯é æ§ãæ¬ç ç©¶å©ç¨äºä¾èªéª¨éç¯çå¡è­°çµç¹ (OAI) çéª¨éç¯çè³æéï¼å¶ä¸­åå« 5 åå´éç¨åº¦é¡å¥åä¸åå»çé¡å¥åä½çå½±åãéç¶å GaussianNB å KNN ç­ç¶å¸æ©å¨å­¸ç¿æ¨¡åå¨ç¹å¾µèåæ¹é¢éå°äºå°é£ï¼ä½å Inception-V3ãVGG-19 ç­å·ç©ç¥ç¶ç¶²è·¯ééå­¸ç¿éå±¤å¼è¦è¦ºæ¨¡å¼éå°äº 55-65% ä¹éçè¼ä½³æºç¢ºåº¦ãç¶èï¼å Da-VITãGCViT å MaxViT ç­è¦è¦ºè½æå¨æ¶æ§è«ç©èåºæçºç¡å¯ç­è­°çä½¼ä½¼èï¼ç±æ¼èªæ³¨æåç¨åºï¼å®åè¡¨ç¾åº 66.14% çæºç¢ºåº¦ã0.703 çç²¾ç¢ºåº¦ã0.614 çå¬åçãè¶é 0.835 ç AUCã</paragraph>

##### **AutoMIR: Effective Zero-Shot Medical Information Retrieval without Relevance Labels**
2410.20050v1 by Lei Li, Xiangxu Zhang, Xiao Zhou, Zheng Liu

Medical information retrieval (MIR) is essential for retrieving relevant
medical knowledge from diverse sources, including electronic health records,
scientific literature, and medical databases. However, achieving effective
zero-shot dense retrieval in the medical domain poses substantial challenges
due to the lack of relevance-labeled data. In this paper, we introduce a novel
approach called Self-Learning Hypothetical Document Embeddings (SL-HyDE) to
tackle this issue. SL-HyDE leverages large language models (LLMs) as generators
to generate hypothetical documents based on a given query. These generated
documents encapsulate key medical context, guiding a dense retriever in
identifying the most relevant documents. The self-learning framework
progressively refines both pseudo-document generation and retrieval, utilizing
unlabeled medical corpora without requiring any relevance-labeled data.
Additionally, we present the Chinese Medical Information Retrieval Benchmark
(CMIRB), a comprehensive evaluation framework grounded in real-world medical
scenarios, encompassing five tasks and ten datasets. By benchmarking ten models
on CMIRB, we establish a rigorous standard for evaluating medical information
retrieval systems. Experimental results demonstrate that SL-HyDE significantly
surpasses existing methods in retrieval accuracy while showcasing strong
generalization and scalability across various LLM and retriever configurations.
CMIRB data and evaluation code are publicly available at:
https://github.com/CMIRB-benchmark/CMIRB.

æè¦ï¼é«çè³è¨æª¢ç´¢ (MIR) å°æ¼å¾é»å­å¥åº·ç´éãç§å­¸æç»åé«çè³æåº«ç­ä¸åä¾æºæª¢ç´¢ç¸éé«çç¥è­è³ééè¦ãç¶èï¼ç±æ¼ç¼ºä¹ç¸éæ¨ç±¤è³æï¼å¨é«çé åä¸­å¯¦ç¾ææçé¶æ¬¡ç¼å°å¯éæª¢ç´¢æå¸¶ä¾éå¤§ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹ä¸ç¨®ç¨±çºèªå­¸ç¿åè¨­æä»¶åµå¥ (SL-HyDE) çæ°æ¹æ³ä¾è§£æ±ºæ­¤åé¡ãSL-HyDE å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä½çºçæå¨ï¼æ ¹æçµ¦å®çæ¥è©¢çæåè¨­æä»¶ãéäºçæçææªåå«ééµçé«çèæ¯ï¼æå°å¯éæª¢ç´¢å¨è­å¥æç¸éçæä»¶ãèªå­¸ç¿æ¡æ¶éæ­¥åªåå½ææªçæåæª¢ç´¢ï¼å©ç¨æªæ¨è¨çé«çèªæåº«ï¼èç¡éä»»ä½ç¸éæ¨ç±¤è³æãæ­¤å¤ï¼æåæåºäºä¸­æé«çè³è¨æª¢ç´¢åºæº (CMIRB)ï¼éæ¯ä¸åå¨é¢çè©ä¼°æ¡æ¶ï¼åºæ¼çå¯¦ä¸ççé«çå ´æ¯ï¼åå«äºåä»»ååååè³æéãééå¨ CMIRB ä¸å°ååæ¨¡åé²è¡åºæºæ¸¬è©¦ï¼æåå»ºç«äºè©ä¼°é«çè³è¨æª¢ç´¢ç³»çµ±çå´æ ¼æ¨æºãå¯¦é©çµæè¡¨æï¼SL-HyDE å¨æª¢ç´¢æºç¢ºåº¦ä¸é¡¯èåªæ¼ç¾ææ¹æ³ï¼åæå¨åç¨® LLM åæª¢ç´¢å¨éç½®ä¸­å±ç¤ºäºå¼·å¤§çæ³åæ§åå¯æ´åæ§ãCMIRB è³æåè©ä¼°ç¨å¼ç¢¼å¯å¨ä»¥ä¸ä½ç½®å¬éåå¾ï¼https://github.com/CMIRB-benchmark/CMIRBã

##### **Off-Policy Selection for Initiating Human-Centric Experimental Design**
2410.20017v1 by Ge Gao, Xi Yang, Qitong Gao, Song Ju, Miroslav Pajic, Min Chi

In human-centric tasks such as healthcare and education, the heterogeneity
among patients and students necessitates personalized treatments and
instructional interventions. While reinforcement learning (RL) has been
utilized in those tasks, off-policy selection (OPS) is pivotal to close the
loop by offline evaluating and selecting policies without online interactions,
yet current OPS methods often overlook the heterogeneity among participants.
Our work is centered on resolving a pivotal challenge in human-centric systems
(HCSs): how to select a policy to deploy when a new participant joining the
cohort, without having access to any prior offline data collected over the
participant? We introduce First-Glance Off-Policy Selection (FPS), a novel
approach that systematically addresses participant heterogeneity through
sub-group segmentation and tailored OPS criteria to each sub-group. By grouping
individuals with similar traits, FPS facilitates personalized policy selection
aligned with unique characteristics of each participant or group of
participants. FPS is evaluated via two important but challenging applications,
intelligent tutoring systems and a healthcare application for sepsis treatment
and intervention. FPS presents significant advancement in enhancing learning
outcomes of students and in-hospital care outcomes.

æè¦ï¼å¨ä»¥äººä¸ºæ¬çä»»å¡ä¸­ï¼ä¾å¦å»çä¿å¥åæè²ï¼æ£èåå­¦çä¹é´çå¼è´¨æ§éè¦ä¸ªæ§åçæ²»çåæå­¦å¹²é¢ãè½ç¶å¼ºåå­¦ä¹  (RL) å·²ç¨äºè¿äºä»»å¡ï¼ä½éç­ç¥éæ© (OPS) å¯¹äºéè¿ç¦»çº¿è¯ä¼°åéæ©ç­ç¥æ¥é­ç¯è³å³éè¦ï¼èæ éå¨çº¿äº¤äºï¼ä½å½åç OPS æ¹æ³éå¸¸ä¼å¿½ç¥åä¸èä¹é´çå¼è´¨æ§ãæä»¬çå·¥ä½éç¹å¨äºè§£å³ä»¥äººä¸ºæ¬ç³»ç» (HCS) ä¸­çä¸ä¸ªå³é®ææï¼å¦ä½å¨æ²¡æè®¿é®ä»»ä½ååç¦»çº¿æ°æ®çæåµä¸ï¼ä¸ºå å¥éåçæ°åä¸èéæ©è¦é¨ç½²çç­ç¥ï¼æä»¬å¼å¥äº First-Glance éç­ç¥éæ© (FPS)ï¼è¿æ¯ä¸ç§æ°é¢çæ¹æ³ï¼éè¿å­ç»ç»ååéå¯¹æ¯ä¸ªå­ç»å®å¶ç OPS æ åç³»ç»å°è§£å³åä¸èå¼è´¨æ§ãéè¿å¯¹å·æç¸ä¼¼ç¹å¾çä¸ªä½è¿è¡åç»ï¼FPS ä¿è¿äºä¸ªæ§åç­ç¥éæ©ï¼ç¬¦åæ¯ä¸ªåä¸èæåä¸èç»çç¬ç¹ç¹å¾ãFPS éè¿ä¸¤ä¸ªéè¦ä½å·ææææ§çåºç¨è¿è¡äºè¯ä¼°ï¼å³æºè½è¾å¯¼ç³»ç»åèæ¯çæ²»çåå¹²é¢çå»çä¿å¥åºç¨ãFPS å¨æé«å­¦ççå­¦ä¹ ææåä½é¢æ¤çæææ¹é¢åå¾äºéå¤§è¿å±ã

##### **DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**
2410.19955v1 by Pengfei Hu, Chang Lu, Fei Wang, Yue Ning

Electronic Health Records (EHR) has revolutionized healthcare data management
and prediction in the field of AI and machine learning. Accurate predictions of
diagnosis and medications significantly mitigate health risks and provide
guidance for preventive care. However, EHR driven models often have limited
scope on understanding medical-domain knowledge and mostly rely on
simple-and-sole ontologies. In addition, due to the missing features and
incomplete disease coverage of EHR, most studies only focus on basic analysis
on conditions and medication. We propose DualMAR, a framework that enhances EHR
prediction tasks through both individual observation data and public knowledge
bases. First, we construct a bi-hierarchical Diagnosis Knowledge Graph (KG)
using verified public clinical ontologies and augment this KG via Large
Language Models (LLMs); Second, we design a new proxy-task learning on lab
results in EHR for pretraining, which further enhance KG representation and
patient embeddings. By retrieving radial and angular coordinates upon polar
space, DualMAR enables accurate predictions based on rich hierarchical and
semantic embeddings from KG. Experiments also demonstrate that DualMAR
outperforms state-of-the-art models, validating its effectiveness in EHR
prediction and KG integration in medical domains.

æè¦ï¼é»å­å¥åº·ç´é (EHR) å·²å¾¹åºæ¹è®äºé«çä¿å¥è³æç®¡çï¼ä¸¦é æ¸¬äºäººå·¥æºæ§åæ©å¨å­¸ç¿é åãæºç¢ºé æ¸¬è¨ºæ·åè¥ç©å¯å¤§å¹æ¸è¼å¥åº·é¢¨éªï¼ä¸¦æä¾é é²æ§ç§è­·çæå°æ¹éãç¶èï¼EHR é©åçæ¨¡åå¨çè§£é«çé åç¥è­ä¸éå¸¸å·æå±éæ§ï¼èä¸å¤§å¤ä¾è³´æ¼ç°¡å®ä¸å®ä¸çæ¬ä½ãæ­¤å¤ï¼ç±æ¼ EHR éºæ¼äºåè½ä¸ç¾çæ¶µèä¸å®æ´ï¼å¤§å¤æ¸ç ç©¶åå°æ³¨æ¼ç¾çåè¥ç©çåºæ¬åæãæåæåº DualMARï¼ä¸åééåäººè§å¯è³æåå¬å±ç¥è­åº«å¢å¼· EHR é æ¸¬ä»»åçæ¶æ§ãé¦åï¼æåä½¿ç¨ç¶éé©è­çå¬å±è¨åºæ¬ä½æ§å»ºä¸åéå±¤ç´è¨ºæ·ç¥è­å (KG)ï¼ä¸¦ééå¤§åèªè¨æ¨¡å (LLM) æ´åéå KGï¼å¶æ¬¡ï¼æåè¨­è¨ä¸åæ°çä»£çä»»åå­¸ç¿ï¼éå° EHR ä¸­çå¯¦é©å®¤çµæé²è¡é è¨ç·´ï¼é²ä¸æ­¥å¢å¼· KG è¡¨ç¤ºåæ£èåµå¥ãééæ·åæ¥µåº§æ¨ç©ºéä¸çå¾ååè§ååæ¨ï¼DualMAR è½å¤ æ ¹æ KG ä¸­è±å¯çå±¤ç´åèªæåµå¥é²è¡æºç¢ºçé æ¸¬ãå¯¦é©ä¹è­æ DualMAR åªæ¼æåé²çæ¨¡åï¼é©è­äºå¶å¨ EHR é æ¸¬åé«çé åä¸­ KG æ´åçæææ§ã

##### **The Potential and Value of AI Chatbot in Personalized Cognitive Training**
2410.19733v1 by Zilong Wang, Nan Chen, Luna K. Qiu, Ling Yue, Geli Guo, Yang Ou, Shiqi Jiang, Yuqing Yang, Lili Qiu

In recent years, the rapid aging of the global population has led to an
increase in cognitive disorders, such as Alzheimer's disease, presenting
significant public health challenges. Although no effective treatments
currently exist to reverse Alzheimer's, prevention and early intervention,
including cognitive training, are critical. This report explores the potential
of AI chatbots in enhancing personalized cognitive training. We introduce ReMe,
a web-based framework designed to create AI chatbots that facilitate cognitive
training research, specifically targeting episodic memory tasks derived from
personal life logs. By leveraging large language models, ReMe provides enhanced
user-friendly, interactive, and personalized training experiences. Case studies
demonstrate ReMe's effectiveness in engaging users through life recall and
open-ended language puzzles, highlighting its potential to improve cognitive
training design. Despite promising results, further research is needed to
validate training effectiveness through large-scale studies that include
cognitive ability evaluations. Overall, ReMe offers a promising approach to
personalized cognitive training, utilizing AI capabilities to meet the growing
demand for non-pharmacological interventions in cognitive health, with future
research aiming to expand its applications and efficacy.

æè¦ï¼è¿å¹´æ¥ï¼å¨çäººå£å¿«éèé¾åï¼å¯¼è´é¿å°è¨æµ·é»çç­è®¤ç¥éç¢çæ£èæ°éå¢å ï¼ç»å¬å±å«çå¸¦æ¥äºéå¤§ææãå°½ç®¡ç®åè¿æ²¡æææçæ²»çæ¹æ³å¯ä»¥éè½¬é¿å°è¨æµ·é»çï¼ä½é¢é²åæ©æå¹²é¢ï¼åæ¬è®¤ç¥è®­ç»ï¼è³å³éè¦ãæ¬æ¥åæ¢è®¨äºäººå·¥æºè½èå¤©æºå¨äººå¢å¼ºä¸ªæ§åè®¤ç¥è®­ç»çæ½åãæä»¬ä»ç»äº ReMeï¼è¿æ¯ä¸ä¸ªåºäºç½ç»çæ¡æ¶ï¼æ¨å¨åå»ºäººå·¥æºè½èå¤©æºå¨äººï¼ä¿è¿è®¤ç¥è®­ç»ç ç©¶ï¼ç¹å«æ¯éå¯¹æºèªä¸ªäººçæ´»æ¥å¿çææ¯è®°å¿ä»»å¡ãéè¿å©ç¨å¤§åè¯­è¨æ¨¡åï¼ReMe æä¾äºå¢å¼ºåç¨æ·åå¥½ãäºå¨ä¸ä¸ªæ§åçè®­ç»ä½éªãæ¡ä¾ç ç©¶å±ç¤ºäº ReMe éè¿çæ´»åå¿åå¼æ¾å¼è¯­è¨è°é¢å¸å¼ç¨æ·çæææ§ï¼çªåºäºå®å¨æ¹åè®¤ç¥è®­ç»è®¾è®¡æ¹é¢çæ½åãå°½ç®¡ç»æå¾æå¸æï¼ä½ä»éè¦è¿ä¸æ­¥çç ç©¶ï¼éè¿åæ¬è®¤ç¥è½åè¯ä¼°çå¤§è§æ¨¡ç ç©¶æ¥éªè¯è®­ç»çæææ§ãæ»ä½èè¨ï¼ReMe ä¸ºä¸ªæ§åè®¤ç¥è®­ç»æä¾äºä¸ç§æåæ¯çæ¹æ³ï¼å©ç¨äººå·¥æºè½åè½æ¥æ»¡è¶³å¯¹è®¤ç¥å¥åº·ä¸­éè¯ç©å¹²é¢æªæ½ä¸æ­å¢é¿çéæ±ï¼æªæ¥çç ç©¶æ¨å¨æ©å±å¶åºç¨åçæã

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

æè¦ï¼æ¬ç¯è©è«æ¢è¨äºæ·±åº¦å­¸ç¿æ¹æ³å¨éä¾µå¥å¼èªç¥åè½éç¤æª¢æ¸¬ä¸çææ°é²å±ãæåæª¢è¦äºåç¨®éä¾µå¥å¼çèªç¥è¡°éææ¨ï¼åæ¬èªè¨åèªè¨ãé¢é¨åéåæ©è½ãæ¬ææ¦è¿°äºèæ­¤é åç¸éçè³æéãç¹å¾µæåæè¡åæ·±åº¦å­¸ç¿æ¶æ§ãæååæäºä¸åæ¹æ³å¨ä¸åæ¹å¼ä¸çè¡¨ç¾ï¼ä¸¦è§å¯å°åºæ¼èªè¨åèªè¨çæ¹æ³éå¸¸è½éå°æé«çæª¢æ¸¬è¡¨ç¾ãçµåè²å­¸åèªè¨ç¹å¾µçç ç©¶å¾å¾åªæ¼ä½¿ç¨å®ä¸æ¹å¼çç ç©¶ãé¢é¨åææ¹æ³é¡¯ç¤ºåºè¦è¦ºæ¹å¼çæ½åï¼ä½ç ç©¶è¼å°ãå¤§å¤æ¸è«æå°æ³¨æ¼äºååé¡ï¼åæèæªåæï¼ï¼è¼å°æ¢è¨å¤é¡æåæ­¸ä»»åãé·ç§»å­¸ç¿åé è¨ç·´èªè¨æ¨¡åå·²æçºæµè¡ä¸ææçæè¡ï¼ç¹å¥æ¯å°æ¼èªè¨åæãåç®¡åå¾äºéå¤§é²å±ï¼ä½ä»å­å¨ä¸äºææ°ï¼åæ¬è³ææ¨æºååå¯åæ§ãæ¨¡åå¯è§£éæ§ãç¸±ååæéå¶åè¨åºé©ææ§ãæå¾ï¼æåæåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦èª¿æ¥èèªè¨ç¡éçèªé³åææ¹æ³ãéç¼å¤æ¨¡å¼è¨ºæ·ç³»çµ±ï¼ä»¥åè§£æ±ºäººå·¥æºæ§è¼å©é«çä¿å¥ä¸­çå«çèéãééç¶åç®åçè¶¨å¢åæ¾åºééµéç¤ï¼æ¬ç¯è©è«æ¨å¨å¼å°æ·±åº¦å­¸ç¿çºåºç¤çèªç¥åè½éç¤æª¢æ¸¬ç³»çµ±çé²ä¸æ­¥ç¼å±ï¼ä»¥æ¹åæ©æè¨ºæ·ï¼ä¸¦æçµæ¹åæ£èçæ²»ççµæã

##### **Enhancing Resilience and Scalability in Travel Booking Systems: A Microservices Approach to Fault Tolerance, Load Balancing, and Service Discovery**
2410.19701v1 by Biman Barua, M. Shamim Kaiser

This paper investigates the inclusion of microservices architecture in the
development of scalable and reliable airline reservation systems. Most of the
traditional reservation systems are very rigid and centralized which makes them
prone to bottlenecks and a single point of failure. As such, systems do not
meet the requirements of modern airlines which are dynamic. Microservices offer
better resiliency and scalability because the services do not depend on one
another and can be deployed independently. The approach is grounded on the
Circuit Breaker Pattern to maintain fault tolerance while consuming foreign
resources such as flight APIs and payment systems. This avoided the failure
propagation to the systems by 60% enabling the systems to function under
external failures. Traffic rerouting also bolstered this with a guarantee of
above 99.95% uptime in systems where high availability was demanded. To address
this, load balancing was used, particularly the Round-Robin method which
managed to enhance performance by 35% through the equal distribution of user
requests among the service instances. Health checks, as well as monitoring in
real-time, helped as well with failure management as they helped to contain
failures before the users of the system were affected. The results suggest that
the use of microservices led to a 40% increase in system scalability, a 50%
decrease in downtime and a support for 30% more concurrent users than the use
of monolithic architectures. These findings affirm the capability of
microservices in the development of robust and flexible airline ticket booking
systems that are responsive to change and recover from external system
unavailability.

æè¦ï¼<paragraph>æ¬æç ç©¶äºå¨å¯æ´å±ä¸å¯é çèªç©ºå¬å¸è¨ä½ç³»çµ±éç¼ä¸­ç´å¥å¾®æåæ¶æ§ãå¤§å¤æ¸å³çµ±çè¨ä½ç³»çµ±éå¸¸åµåä¸éä¸­åï¼éä½¿å¾å®åå®¹æåºç¾ç¶é ¸åå®é»æéãå æ­¤ï¼ç³»çµ±ç¡æ³æ»¿è¶³åæçç¾ä»£èªç©ºå¬å¸çéæ±ãå¾®æåæä¾äºæ´å¥½çå¾©åååå¯æ´å±æ§ï¼å çºéäºæåå½¼æ­¤ç¨ç«ï¼ä¸å¯ä»¥ç¨ç«é¨ç½²ãæ­¤æ¹æ³ä»¥æ·è·¯å¨æ¨¡å¼çºåºç¤ï¼ä»¥å¨ä½¿ç¨å¤é¨è³æºï¼ä¾å¦èªç­ API åæ¯ä»ç³»çµ±ï¼æç¶­æå®¹é¯è½åãéå°æéå³æ­å°ç³»çµ±çæ©çéä½äº 60%ï¼ä½¿ç³»çµ±è½å¤ å¨å¤é¨æéä¸éä½ãæµééæ°è·¯ç±ä¹å å¼·äºéä¸é»ï¼ä¿è­äºå¨è¦æ±é«å¯ç¨æ§çç³»çµ±ä¸­éå° 99.95% ä»¥ä¸çæ­£å¸¸éè¡æéãçºäºè§£æ±ºéååé¡ï¼ä½¿ç¨äºè² è¼å¹³è¡¡ï¼ç¹å¥æ¯å¾ªç°æ¹æ³ï¼ééå¨æåå¯¦ä¾ä¹éå¹³ååéä½¿ç¨èè¦æ±ï¼å°æè½æåäº 35%ãå¥åº·æª¢æ¥ä»¥åå³æç£æ§ä¹æå©æ¼æéç®¡çï¼å çºå®åæå©æ¼å¨ç³»çµ±ä½¿ç¨èåå°å½±é¿ä¹åæ§å¶æéãçµæè¡¨æï¼ä½¿ç¨å¾®æåä½¿ç³»çµ±å¯æ´å±æ§æé«äº 40%ï¼åæ©æéæ¸å°äº 50%ï¼ä¸¦ä¸æ¯ä½¿ç¨å®é«æ¶æ§æ¯æ´å¤ 30% çä¸¦ç¼ä½¿ç¨èãéäºç¼ç¾è¯å®äºå¾®æåå¨éç¼å¥å£¯ä¸éæ´»çæ©ç¥¨è¨è³¼ç³»çµ±ä¸­çè½åï¼éäºç³»çµ±å°è®æ´å·æåæè½åï¼ä¸¦ä¸å¯ä»¥å¾å¤é¨ç³»çµ±ä¸å¯ç¨ä¸­å¾©åã</paragraph>

##### **Deep learning-based identification of patients at increased risk of cancer using routine laboratory markers**
2410.19646v1 by Vivek Singh, Shikha Chaganti, Matthias Siebert, Soumya Rajesh, Andrei Puiu, Raj Gopalan, Jamie Gramz, Dorin Comaniciu, Ali Kamen

Early screening for cancer has proven to improve the survival rate and spare
patients from intensive and costly treatments due to late diagnosis. Cancer
screening in the healthy population involves an initial risk stratification
step to determine the screening method and frequency, primarily to optimize
resource allocation by targeting screening towards individuals who draw most
benefit. For most screening programs, age and clinical risk factors such as
family history are part of the initial risk stratification algorithm. In this
paper, we focus on developing a blood marker-based risk stratification
approach, which could be used to identify patients with elevated cancer risk to
be encouraged for taking a diagnostic test or participate in a screening
program. We demonstrate that the combination of simple, widely available blood
tests, such as complete blood count and complete metabolic panel, could
potentially be used to identify patients at risk for colorectal, liver, and
lung cancers with areas under the ROC curve of 0.76, 0.85, 0.78, respectively.
Furthermore, we hypothesize that such an approach could not only be used as
pre-screening risk assessment for individuals but also as population health
management tool, for example to better interrogate the cancer risk in certain
sub-populations.

æè¦ï¼çççæ©æç¯©æª¢å·²è¢«è­å¯¦å¯ä»¥æé«å­æ´»çï¼ä¸¦è®æ£èåæ¼å è¨ºæ·éæèæ¥åå¯éä¸æè²´çæ²»çãå¥åº·äººç¾¤çççç¯©æª¢åæ¬ä¸ååå§é¢¨éªåå±¤æ­¥é©ï¼ä»¥ç¢ºå®ç¯©æª¢æ¹æ³åé »çï¼ä¸»è¦æ¯éééå°æè½åççåäººé²è¡ç¯©æª¢ä¾æä½³åè³æºåéãå°æ¼å¤§å¤æ¸ç¯©æª¢è¨ç«ï¼å¹´é½¡åè¨åºé¢¨éªå å­ï¼ä¾å¦å®¶æå²ï¼æ¯åå§é¢¨éªåå±¤æ¼ç®æ³çä¸é¨åãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼éç¼ä¸ç¨®åºæ¼è¡æ¶²æ¨è¨çé¢¨éªåå±¤æ¹æ³ï¼å¯ç¨æ¼è­å¥ççé¢¨éªåé«çæ£èï¼ä»¥é¼åµä»åé²è¡è¨ºæ·æ¸¬è©¦æåèç¯©æª¢è¨ç«ãæåè­æäºç°¡å®ãå»£æ³ä½¿ç¨çè¡æ¶²æª¢æ¸¬ï¼ä¾å¦å¨è¡çè¨æ¸åå®æ´ä»£è¬ panelï¼ççµåï¼æå¯è½ç¨æ¼è­å¥ç½¹æ£å¤§è¸çãèçåèºçé¢¨éªçæ£èï¼å¶ ROC æ²ç·ä¸çé¢ç©åå¥çº 0.76ã0.85ã0.78ãæ­¤å¤ï¼æååè¨­éç¨®æ¹æ³ä¸åå¯ç¨æ¼åäººçç¯©æª¢åé¢¨éªè©ä¼°ï¼éå¯ç¨æ¼äººå£å¥åº·ç®¡çå·¥å·ï¼ä¾å¦æ´æ·±å¥å°è©¢åæäºäºç¾¤ä¸­çççé¢¨éªã

##### **Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites**
2410.19643v2 by NicolÃ¡s Nieto, Simon B. Eickhoff, Christian Jung, Martin Reuter, Kersten Diers, Malte Kelm, Artur Lichtenberg, Federico Raimondo, Kaustubh R. Patil

Machine learning (ML) models benefit from large datasets. Collecting data in
biomedical domains is costly and challenging, hence, combining datasets has
become a common practice. However, datasets obtained under different conditions
could present undesired site-specific variability. Data harmonization methods
aim to remove site-specific variance while retaining biologically relevant
information. This study evaluates the effectiveness of popularly used
ComBat-based methods for harmonizing data in scenarios where the class balance
is not equal across sites. We find that these methods struggle with data
leakage issues. To overcome this problem, we propose a novel approach
PrettYharmonize, designed to harmonize data by pretending the target labels. We
validate our approach using controlled datasets designed to benchmark the
utility of harmonization. Finally, using real-world MRI and clinical data, we
compare leakage-prone methods with PrettYharmonize and show that it achieves
comparable performance while avoiding data leakage, particularly in
site-target-dependence scenarios.

æè¦ï¼æ©å¨å­¸ç¿ (ML) æ¨¡ååçæ¼å¤§åè³æéãå¨çç©é«å­¸é åæ¶éè³ææ¢æè²´åå·ææ°æ§ï¼å æ­¤ï¼çµåè³æéå·²æçºä¸ç¨®å¸¸è¦åæ³ãç¶èï¼å¨ä¸åæ¢ä»¶ä¸ç²å¾çè³æéå¯è½æåºç¾ä¸å¸æçç¹å®æ¼ç«é»çå¯è®æ§ãè³æèª¿åæ¹æ³æ¨å¨æ¶é¤ç¹å®æ¼ç«é»çè®ç°ï¼åæä¿ççç©å­¸ç¸éè³è¨ãæ¬ç ç©¶è©ä¼°äºå¨ä¸åç«é»çé¡å¥å¹³è¡¡ä¸åç­çææ³ä¸ï¼å»£æ³ä½¿ç¨çåºæ¼ ComBat çæ¹æ³å°è³æèª¿åçæææ§ãæåç¼ç¾éäºæ¹æ³é£ä»¥è§£æ±ºè³ææ´©æ¼åé¡ãçºäºåæéååé¡ï¼æåæåºäºä¸ç¨®æ°æ¹æ³ PrettYharmonizeï¼æ¨å¨ééåè£ç®æ¨æ¨ç±¤ä¾èª¿åè³æãæåä½¿ç¨æ¨å¨è©éèª¿åæç¨çåæ§è³æéä¾é©è­æåçåæ³ãæå¾ï¼ä½¿ç¨çå¯¦ä¸çç MRI åè¨åºè³æï¼æåå°å®¹ææ´©æ¼çæ¹æ³è PrettYharmonize é²è¡æ¯è¼ï¼ä¸¦è¡¨æå®å¨é¿åè³ææ´©æ¼çåæå¯¦ç¾äºå¯æ¯çæè½ï¼ç¹å¥æ¯å¨ç¹å®æ¼ç«é»ç®æ¨çå ´æ¯ä¸­ã

##### **Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use**
2410.19155v1 by Mohit Chandra, Siddharth Sriraman, Gaurav Verma, Harneet Singh Khanuja, Jose Suarez Campayo, Zihang Li, Michael L. Birnbaum, Munmun De Choudhury

Adverse Drug Reactions (ADRs) from psychiatric medications are the leading
cause of hospitalizations among mental health patients. With healthcare systems
and online communities facing limitations in resolving ADR-related issues,
Large Language Models (LLMs) have the potential to fill this gap. Despite the
increasing capabilities of LLMs, past research has not explored their
capabilities in detecting ADRs related to psychiatric medications or in
providing effective harm reduction strategies. To address this, we introduce
the Psych-ADR benchmark and the Adverse Drug Reaction Response Assessment
(ADRA) framework to systematically evaluate LLM performance in detecting ADR
expressions and delivering expert-aligned mitigation strategies. Our analyses
show that LLMs struggle with understanding the nuances of ADRs and
differentiating between types of ADRs. While LLMs align with experts in terms
of expressed emotions and tone of the text, their responses are more complex,
harder to read, and only 70.86% aligned with expert strategies. Furthermore,
they provide less actionable advice by a margin of 12.32% on average. Our work
provides a comprehensive benchmark and evaluation framework for assessing LLMs
in strategy-driven tasks within high-risk domains.

æè¦ï¼ç²¾ç¥ç§è¥ç©çè¥ç©ä¸è¯åæ (ADR) æ¯ç²¾ç¥å¥åº·æ£èä½é¢çä¸»è¦åå ãç±æ¼é«çä¿å¥ç³»çµ±åç·ä¸ç¤¾ç¾¤å¨è§£æ±º ADR ç¸éåé¡ä¸å­å¨éå¶ï¼å¤§åèªè¨æ¨¡å (LLM) æå¯è½å¡«è£éé ç¼ºå£ãåç®¡ LLM çåè½è¶ä¾è¶å¼·å¤§ï¼ä½éå»çç ç©¶å°æªæ¢è¨å¶å¨æª¢æ¸¬èç²¾ç¥ç§è¥ç©ç¸éç ADR ææä¾ææçæ¸å®³ç­ç¥æ¹é¢çè½åãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº Psych-ADR åºæºåè¥ç©ä¸è¯åæåæè©ä¼° (ADRA) æ¶æ§ï¼ä»¥ç³»çµ±æ§å°è©ä¼° LLM å¨æª¢æ¸¬ ADR è¡¨éåæä¾å°å®¶ä¸è´çç·©è§£ç­ç¥æ¹é¢çè¡¨ç¾ãæåçåæé¡¯ç¤ºï¼LLM å¨çè§£ ADR çç´°å¾®å·®å¥åååä¸åé¡åç ADR æ¹é¢æå°é£ãéç¶ LLM å¨è¡¨éçæç·åæå­èªæ°£æ¹é¢èå°å®¶ä¸è´ï¼ä½ä»åçåææ´è¤éãæ´é£é±è®ï¼èä¸åªæ 70.86% èå°å®¶ç­ç¥ä¸è´ãæ­¤å¤ï¼ä»åæä¾çå¯æä½å»ºè­°å¹³åæ¸å°äº 12.32%ãæåçç ç©¶æä¾äºä¸åå¨é¢çåºæºåè©ä¼°æ¶æ§ï¼ç¨æ¼è©ä¼° LLM å¨é«é¢¨éªé åä¸­çç­ç¥é©åä»»åã

##### **CAMEL-Bench: A Comprehensive Arabic LMM Benchmark**
2410.18976v1 by Sara Ghaboura, Ahmed Heakl, Omkar Thawakar, Ali Alharthi, Ines Riahi, Abduljalil Saif, Jorma Laaksonen, Fahad S. Khan, Salman Khan, Rao M. Anwer

Recent years have witnessed a significant interest in developing large
multimodal models (LMMs) capable of performing various visual reasoning and
understanding tasks. This has led to the introduction of multiple LMM
benchmarks to evaluate LMMs on different tasks. However, most existing LMM
evaluation benchmarks are predominantly English-centric. In this work, we
develop a comprehensive LMM evaluation benchmark for the Arabic language to
represent a large population of over 400 million speakers. The proposed
benchmark, named CAMEL-Bench, comprises eight diverse domains and 38
sub-domains including, multi-image understanding, complex visual perception,
handwritten document understanding, video understanding, medical imaging, plant
diseases, and remote sensing-based land use understanding to evaluate broad
scenario generalizability. Our CAMEL-Bench comprises around 29,036 questions
that are filtered from a larger pool of samples, where the quality is manually
verified by native speakers to ensure reliable model assessment. We conduct
evaluations of both closed-source, including GPT-4 series, and open-source
LMMs. Our analysis reveals the need for substantial improvement, especially
among the best open-source models, with even the closed-source GPT-4o achieving
an overall score of 62%. Our benchmark and evaluation scripts are open-sourced.

æè¦ï¼è¿å¹´ä¾ï¼éç¼å¤§åå¤æ¨¡ææ¨¡å (LMM) ä»¥å·è¡åç¨®è¦è¦ºæ¨çåçè§£ä»»åå¼èµ·äºæ¥µå¤§çèè¶£ãéå°è´å¼å¥äºå¤å LMM åºæºä¾è©ä¼° LMM å¨ä¸åä»»åä¸çè¡¨ç¾ãç¶èï¼ç¾æç LMM è©ä¼°åºæºå¤§å¤ä»¥è±èªçºä¸­å¿ãå¨éé å·¥ä½ä¸­ï¼æåéç¼äºä¸åå¨é¢çé¿æä¼¯èª LMM è©ä¼°åºæºï¼ä»¥ä»£è¡¨è¶é 4 åäººå£çé¾å¤§ç¾¤é«ãæåºçåºæºç¨±çº CAMEL-Benchï¼åå«å«åä¸åçé åå 38 åå­é åï¼åæ¬å¤ååçè§£ãè¤éè¦è¦ºæç¥ãæå¯«æä»¶çè§£ãè¦é »çè§£ãé«å­¸å½±åãæ¤ç©ç¾çååºæ¼éæçåå°å©ç¨çè§£ï¼ä»¥è©ä¼°å»£æ³å ´æ¯çå¯æ¦æ¬æ§ãæåç CAMEL-Bench åå«ç´ 29,036 ååé¡ï¼éäºåé¡å¾æ´å¤§çæ¨£æ¬æ± ä¸­éæ¿¾åºä¾ï¼å¶è³ªéç±æ¯èªäººå£«æåé©è­ä»¥ç¢ºä¿å¯é çæ¨¡åè©ä¼°ãæåå°å°éæºç¢¼ï¼åæ¬ GPT-4 ç³»åï¼åéæº LMM é²è¡äºè©ä¼°ãæåçåææ­ç¤ºäºéè¦å¤§å¹æ¹é²ï¼ç¹å¥æ¯å¨æå¥½çéæºæ¨¡åä¸­ï¼å³ä½¿æ¯å°éæºç¢¼ç GPT-4o ä¹åªéå°äº 62% çç¸½åãæåçåºæºåè©ä¼°è³æ¬æ¯éæºçã

##### **Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques**
2410.18972v1 by David Ortiz-Perez, Manuel Benavent-Lledo, Jose Garcia-Rodriguez, David TomÃ¡s, M. Flores Vizcaya-Moreno

Cognitive decline is a natural part of aging, often resulting in reduced
cognitive abilities. In some cases, however, this decline is more pronounced,
typically due to disorders such as Alzheimer's disease. Early detection of
anomalous cognitive decline is crucial, as it can facilitate timely
professional intervention. While medical data can help in this detection, it
often involves invasive procedures. An alternative approach is to employ
non-intrusive techniques such as speech or handwriting analysis, which do not
necessarily affect daily activities. This survey reviews the most relevant
methodologies that use deep learning techniques to automate the cognitive
decline estimation task, including audio, text, and visual processing. We
discuss the key features and advantages of each modality and methodology,
including state-of-the-art approaches like Transformer architecture and
foundation models. In addition, we present works that integrate different
modalities to develop multimodal models. We also highlight the most significant
datasets and the quantitative results from studies using these resources. From
this review, several conclusions emerge. In most cases, the textual modality
achieves the best results and is the most relevant for detecting cognitive
decline. Moreover, combining various approaches from individual modalities into
a multimodal model consistently enhances performance across nearly all
scenarios.

æè¦ï¼<paragraph>èªç¥è½åä¸éæ¯èåçèªç¶ç¾è±¡ï¼éå¸¸æå°è´èªç¥è½åä¸éãç¶èï¼å¨æäºææ³ä¸ï¼éç¨®ä¸éææ´å æé¡¯ï¼éå¸¸æ¯å çºé¿è²æµ·é»çç­ç¾çãåæ©ç¼ç¾ç°å¸¸çèªç¥è½åä¸éè³ééè¦ï¼å çºå®å¯ä»¥ä¿é²åæçå°æ¥­å¹²é ãéç¶é«çæ¸ææå©æ¼éç¨®æª¢æ¸¬ï¼ä½å®éå¸¸æ¶åä¾µå¥æ§ç¨åºãå¦ä¸ç¨®æ¹æ³æ¯æ¡ç¨éä¾µå¥æ§æè¡ï¼ä¾å¦èªé³ææå¯«åæï¼éäºæè¡ä¸ä¸å®æå½±é¿æ¥å¸¸æ´»åãéé èª¿æ¥åé¡§äºä½¿ç¨æ·±åº¦å­¸ç¿æè¡èªåå·è¡èªç¥è½åä¸éä¼°è¨ä»»åçæç¸éæ¹æ³ï¼åæ¬é³è¨ãæå­åè¦è¦ºèçãæåè¨è«äºæ¯åæ¨¡æåæ¹æ³çä¸»è¦ç¹å¾µååªé»ï¼åæ¬Transformeræ¶æ§ååºç¤æ¨¡åç­æåé²çæ¹æ³ãæ­¤å¤ï¼æåå±ç¤ºäºæ´åä¸åæ¨¡æä»¥éç¼å¤æ¨¡ææ¨¡åçä½åãæåééé»ä»ç´¹äºæéè¦çæ¸æéåä½¿ç¨éäºè³æºçç ç©¶çå®éçµæãå¾éé åé¡§ä¸­ï¼å¾åºäºä¸äºçµè«ãå¨å¤§å¤æ¸ææ³ä¸ï¼ææ¬æ¨¡æåå¾äºæå¥½ççµæï¼ä¸¦ä¸èæª¢æ¸¬èªç¥è½åä¸éæç¸éãæ­¤å¤ï¼å°ä¾èªåå¥æ¨¡æçåç¨®æ¹æ³çµåå°å¤æ¨¡ææ¨¡åä¸­ï¼ææçºå¢å¼·å¹¾ä¹ææå ´æ¯çæè½ã</paragraph>

##### **Demystifying Large Language Models for Medicine: A Primer**
2410.18856v1 by Qiao Jin, Nicholas Wan, Robert Leaman, Shubo Tian, Zhizheng Wang, Yifan Yang, Zifeng Wang, Guangzhi Xiong, Po-Ting Lai, Qingqing Zhu, Benjamin Hou, Maame Sarfo-Gyamfi, Gongbo Zhang, Aidan Gilson, Balu Bhasuran, Zhe He, Aidong Zhang, Jimeng Sun, Chunhua Weng, Ronald M. Summers, Qingyu Chen, Yifan Peng, Zhiyong Lu

Large language models (LLMs) represent a transformative class of AI tools
capable of revolutionizing various aspects of healthcare by generating
human-like responses across diverse contexts and adapting to novel tasks
following human instructions. Their potential application spans a broad range
of medical tasks, such as clinical documentation, matching patients to clinical
trials, and answering medical questions. In this primer paper, we propose an
actionable guideline to help healthcare professionals more efficiently utilize
LLMs in their work, along with a set of best practices. This approach consists
of several main phases, including formulating the task, choosing LLMs, prompt
engineering, fine-tuning, and deployment. We start with the discussion of
critical considerations in identifying healthcare tasks that align with the
core capabilities of LLMs and selecting models based on the selected task and
data, performance requirements, and model interface. We then review the
strategies, such as prompt engineering and fine-tuning, to adapt standard LLMs
to specialized medical tasks. Deployment considerations, including regulatory
compliance, ethical guidelines, and continuous monitoring for fairness and
bias, are also discussed. By providing a structured step-by-step methodology,
this tutorial aims to equip healthcare professionals with the tools necessary
to effectively integrate LLMs into clinical practice, ensuring that these
powerful technologies are applied in a safe, reliable, and impactful manner.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ä»£è¡¨ä¸ç¨®è®é©æ§ç AI å·¥å·é¡å¥ï¼å®è½å¤ ééå¨åç¨®èçµ¡ä¸­ç¢çé¡ä¼¼äººé¡çåæï¼ä¸¦æ ¹æäººé¡æç¤ºèª¿æ´å°æ°ä»»åï¼å¾èé©æ°é«çä¿å¥çååæ¹é¢ãå®åçæ½å¨æç¨ç¯åæ¶µèå»£æ³çé«çä»»åï¼ä¾å¦è¨åºæä»¶ãå°æ£èèè¨åºè©¦é©éå°ï¼ä»¥ååç­é«çåé¡ãå¨æ­¤åºç¤è«æä¸­ï¼æåæåºäºä¸åå¯è¡çæåï¼ä»¥å¹«å©é«çå°æ¥­äººå¡æ´ææå°å¨å¶å·¥ä½ä¸­å©ç¨ LLMï¼ä¸¦æä¾äºä¸çµæä½³å¯¦åãæ­¤æ¹æ³åå«å¹¾åä¸»è¦éæ®µï¼åæ¬å¶å®ä»»åãé¸æ LLMãæç¤ºå·¥ç¨ãå¾®èª¿åé¨ç½²ãæåå¾è¨è«è­å¥è LLM æ ¸å¿åè½ç¸ç¬¦çé«çä¿å¥ä»»åï¼ä»¥åæ ¹ææé¸ä»»ååæ¸æãæè½éæ±åæ¨¡åä»é¢é¸ææ¨¡åçééµèééå§ãç¶å¾ï¼æåæª¢è¦ç­ç¥ï¼ä¾å¦æç¤ºå·¥ç¨åå¾®èª¿ï¼ä»¥èª¿æ´æ¨æº LLM ä»¥ç¬¦åå°æ¥­çé«çä»»åãé¨ç½²èéï¼åæ¬æ³è¦éµå¾ªãéå¾·æºåï¼ä»¥åå¬å¹³æ§ååè¦çæçºç£æ§ï¼ä¹å·²è¨è«éãééæä¾çµæ§åçéæ­¥æ¹æ³ï¼æ¬æå­¸èª²ç¨æ¨å¨çºé«çå°æ¥­äººå¡æä¾å¿è¦çå·¥å·ï¼ä»¥ææå°å° LLM æ´åå°è¨åºå¯¦åä¸­ï¼ç¢ºä¿éäºå¼·å¤§çæè¡è½ä»¥å®å¨ãå¯é ä¸æå½±é¿åçæ¹å¼æç¨ã

##### **Health Misinformation in Social Networks: A Survey of IT Approaches**
2410.18670v1 by Vasiliki Papanikou, Panagiotis Papadakos, Theodora Karamanidou, Thanos G. Stavropoulos, Evaggelia Pitoura, Panayiotis Tsaparas

In this paper, we present a comprehensive survey on the pervasive issue of
medical misinformation in social networks from the perspective of information
technology. The survey aims at providing a systematic review of related
research and helping researchers and practitioners navigate through this
fast-changing field. Specifically, we first present manual and automatic
approaches for fact-checking. We then explore fake news detection methods,
using content, propagation features, or source features, as well as mitigation
approaches for countering the spread of misinformation. We also provide a
detailed list of several datasets on health misinformation and of publicly
available tools. We conclude the survey with a discussion on the open
challenges and future research directions in the battle against health
misinformation.

æè¦ï¼å¨æ¬æä¸­ï¼æåå¾è³è¨ç§æçè§åº¦ï¼å°ç¤¾ç¾¤ç¶²è·¯ä¸­æ®éå­å¨çé«çé¯èª¤è³è¨åé¡é²è¡å¨é¢çèª¿æ¥ãè©²èª¿æ¥æ¨å¨æä¾ç¸éç ç©¶çç³»çµ±æ§åé¡§ï¼ä¸¦å¹«å©ç ç©¶äººå¡åå¾æ¥­èäºè§£éåç¬æ¯è¬è®çé åãå·é«ä¾èªªï¼æåé¦åä»ç´¹æååèªåæ¥æ ¸äºå¯¦çæ¹æ³ãç¶å¾ï¼æåæ¢è¨åæ°èåµæ¸¬æ¹æ³ï¼ä½¿ç¨å§å®¹ãå³æ­ç¹å¾µæä¾æºç¹å¾µï¼ä»¥åå°æé¯èª¤è³è¨æ£å¸çç·©è§£æ¹æ³ãæåéæä¾äºå¹¾åéæ¼å¥åº·é¯èª¤è³è¨çè³æéåå¬éå¯ç¨çå·¥å·çè©³ç´°æ¸å®ãæåä»¥è¨è«ææå¥åº·é¯èª¤è³è¨çå¬éææ°åæªä¾ç ç©¶æ¹åï¼ä¾çµæéé èª¿æ¥ã

##### **Paved or unpaved? A Deep Learning derived Road Surface Global Dataset from Mapillary Street-View Imagery**
2410.19874v2 by Sukanya Randhawa, Eren Aygun, Guntaj Randhawa, Benjamin Herfort, Sven Lautenbach, Alexander Zipf

We have released an open dataset with global coverage on road surface
characteristics (paved or unpaved) derived utilising 105 million images from
the world's largest crowdsourcing-based street view platform, Mapillary,
leveraging state-of-the-art geospatial AI methods. We propose a hybrid deep
learning approach which combines SWIN-Transformer based road surface prediction
and CLIP-and-DL segmentation based thresholding for filtering of bad quality
images. The road surface prediction results have been matched and integrated
with OpenStreetMap (OSM) road geometries. This study provides global data
insights derived from maps and statistics about spatial distribution of
Mapillary coverage and road pavedness on a continent and countries scale, with
rural and urban distinction. This dataset expands the availability of global
road surface information by over 3 million kilometers, now representing
approximately 36% of the total length of the global road network. Most regions
showed moderate to high paved road coverage (60-80%), but significant gaps were
noted in specific areas of Africa and Asia. Urban areas tend to have
near-complete paved coverage, while rural regions display more variability.
Model validation against OSM surface data achieved strong performance, with F1
scores for paved roads between 91-97% across continents. Taking forward the
work of Mapillary and their contributors and enrichment of OSM road attributes,
our work provides valuable insights for applications in urban planning,
disaster routing, logistics optimisation and addresses various Sustainable
Development Goals (SDGS): especially SDGs 1 (No poverty), 3 (Good health and
well-being), 8 (Decent work and economic growth), 9 (Industry, Innovation and
Infrastructure), 11 (Sustainable cities and communities), 12 (Responsible
consumption and production), and 13 (Climate action).

æè¦ï¼<paragraph>æåå·²ç¼å¸ä¸åéæ¾å¼è³æéï¼å¶å¨çéè·¯è¡¨é¢ç¹å¾µï¼éªè¨­ææªéªè¨­ï¼çæ¶µèç¯åï¼ä¿å©ç¨ä¾èªå¨çæå¤§çç¾¤ç¾å¤åè¡æ¯å¹³å° Mapillary ç 1.05 åå¼µå½±åï¼ä¸¦éç¨æåé²çå°çç©ºé AI æ¹æ³æè¡çèä¾ãæåæåºäºä¸ç¨®æ··åæ·±åº¦å­¸ç¿æ¹æ³ï¼çµååºæ¼ SWIN-Transformer çéè·¯è¡¨é¢é æ¸¬ååºæ¼ CLIP å DL åå²çé¾å¼åï¼ä»¥éæ¿¾åè³ªä¸ä½³çå½±åãéè·¯è¡¨é¢é æ¸¬çµæå·²è OpenStreetMap (OSM) éè·¯å¹¾ä½å½¢çé²è¡æ¯å°åæ´åãéé ç ç©¶æä¾å¾å°ååçµ±è¨è³æè¡ççå¨çè³ææ´å¯ï¼éæ¼ Mapillary æ¶µèç¯ååéè·¯éªè¨­ææ³å¨æ´²ååå®¶å±¤ç´çç©ºéåä½ï¼ä¸¦ååäºè¾²æåé½å¸ãæ­¤è³æéå°å¨çéè·¯è¡¨é¢è³è¨çå¯ç¨æ§æ´å¢äº 300 å¤è¬å¬éï¼ç¾å¨ç´å å¨çéè·¯ç¶²è·¯ç¸½é·åº¦ç 36%ãå¤§å¤æ¸å°åé¡¯ç¤ºåºä¸­ç­è³é«éªè¨­éè·¯æ¶µèçï¼60-80%ï¼ï¼ä½éæ´²åäºæ´²çç¹å®ååå­å¨é¡¯èå·®è·ãé½å¸å°åå¾åæ¼æææ¥è¿å®æ´çéªè¨­æ¶µèçï¼èè¾²æå°ååå±ç¾åºæ´å¤è®ç°æ§ãéå° OSM è¡¨é¢è³æçæ¨¡åé©è­éå°äºå¼·åçæè½ï¼åæ´²éªè¨­éè·¯ç F1 åæ¸ä»æ¼ 91-97% ä¹éãå»¶çº Mapillary åå¶è²¢ç»èåè±å¯ OSM éè·¯å±¬æ§çå·¥ä½ï¼æåçç ç©¶çºé½å¸è¦åãç½å®³è·¯ç·ãå¾å¤æä½³åç­æç¨ç¨å¼æä¾äºå¯¶è²´çæ´å¯ï¼ä¸¦è§£æ±ºäºåç¨®æ°¸çºç¼å±ç®æ¨ (SDG)ï¼ç¹å¥æ¯ SDG 1ï¼æ¶é¤è²§çª®ï¼ã3ï¼è¯å¥½å¥åº·åç¦ç¥ï¼ã8ï¼é«é¢å·¥ä½åç¶æ¿æé·ï¼ã9ï¼ç¢æ¥­ãåµæ°ååºç¤å»ºè¨­ï¼ã11ï¼æ°¸çºåå¸åç¤¾åï¼ã12ï¼è² è²¬ä»»çæ¶è²»åçç¢ï¼ï¼ä»¥å 13ï¼æ°£åè¡åï¼ã</paragraph>

##### **Beyond Multiple-Choice Accuracy: Real-World Challenges of Implementing Large Language Models in Healthcare**
2410.18460v1 by Yifan Yang, Qiao Jin, Qingqing Zhu, Zhizheng Wang, Francisco Erramuspe Ãlvarez, Nicholas Wan, Benjamin Hou, Zhiyong Lu

Large Language Models (LLMs) have gained significant attention in the medical
domain for their human-level capabilities, leading to increased efforts to
explore their potential in various healthcare applications. However, despite
such a promising future, there are multiple challenges and obstacles that
remain for their real-world uses in practical settings. This work discusses key
challenges for LLMs in medical applications from four unique aspects:
operational vulnerabilities, ethical and social considerations, performance and
assessment difficulties, and legal and regulatory compliance. Addressing these
challenges is crucial for leveraging LLMs to their full potential and ensuring
their responsible integration into healthcare.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨é«çé åä¸­ç²å¾äºé¡¯èçéæ³¨ï¼å çºå®åå·æäººé¡ç­ç´çè½åï¼éå°è´äººåå å¤§äºæ¢ç´¢å®åå¨åç¨®é«çä¿å¥æç¨ä¸­çæ½åçååº¦ãç¶èï¼åç®¡æªä¾åæ»¿å¸æï¼ä½å®åå¨å¯¦éç°å¢ä¸­çå¯¦éç¨éä»ç¶å­å¨å¤éææ°åéç¤ãéé å·¥ä½å¾ååç¨ç¹æ¹é¢è¨è«äº LLM å¨é«çæç¨ä¸­çééµææ°ï¼éçæ¼æ´ãå«çåç¤¾æèéãæ§è½åè©ä¼°é£é¡ï¼ä»¥åæ³å¾åæ³è¦éµå¾ªãè§£æ±ºéäºææ°å°æ¼ååå©ç¨ LLM çæ½åä¸¦ç¢ºä¿å®åè² è²¬ä»»å°æ´åå°é«çä¿å¥ä¸­è³ééè¦ã

##### **Multi-Stage Airway Segmentation in Lung CT Based on Multi-scale Nested Residual UNet**
2410.18456v1 by Bingyu Yang, Huai Liao, Xinyan Huang, Qingyao Tian, Jinlin Wu, Jingdi Hu, Hongbin Liu

Accurate and complete segmentation of airways in chest CT images is essential
for the quantitative assessment of lung diseases and the facilitation of
pulmonary interventional procedures. Although deep learning has led to
significant advancements in medical image segmentation, maintaining airway
continuity remains particularly challenging. This difficulty arises primarily
from the small and dispersed nature of airway structures, as well as class
imbalance in CT scans. To address these challenges, we designed a Multi-scale
Nested Residual U-Net (MNR-UNet), incorporating multi-scale inputs and Residual
Multi-scale Modules (RMM) into a nested residual framework to enhance
information flow, effectively capturing the intricate details of small airways
and mitigating gradient vanishing. Building on this, we developed a three-stage
segmentation pipeline to optimize the training of the MNR-UNet. The first two
stages prioritize high accuracy and sensitivity, while the third stage focuses
on repairing airway breakages to balance topological completeness and
correctness. To further address class imbalance, we introduced a weighted
Breakage-Aware Loss (wBAL) to heighten focus on challenging samples, penalizing
breakages and thereby extending the length of the airway tree. Additionally, we
proposed a hierarchical evaluation framework to offer more clinically
meaningful analysis. Validation on both in-house and public datasets
demonstrates that our approach achieves superior performance in detecting more
accurate airway voxels and identifying additional branches, significantly
improving airway topological completeness. The code will be released publicly
following the publication of the paper.

æè¦ï¼è¸é¨ CT å½±åä¸­æºç¢ºèå®æ´çæ°£éåå²å°æ¼èºé¨ç¾ççå®éè©ä¼°åä¿é²èºé¨ä»å¥æ§ç¨åºè³ééè¦ãåç®¡æ·±åº¦å­¸ç¿å·²å¨é«å­¸å½±ååå²é ååå¾é¡¯èé²å±ï¼ä½ç¶­ææ°£éé£çºæ§ä»ç¶ç¹å¥å·æææ°æ§ãéç¨®å°é£ä¸»è¦ä¾èªæ¼æ°£éçµæ§çç´°å°ååæ£æ§è³ªï¼ä»¥å CT ææä¸­çé¡å¥ä¸å¹³è¡¡ãçºäºæå°éäºææ°ï¼æåè¨­è¨äºä¸åå¤å°ºåº¦å·¢çæ®å·® U-Netï¼MNR-UNetï¼ï¼å°å¤å°ºåº¦è¼¸å¥åæ®å·®å¤å°ºåº¦æ¨¡çµï¼RMMï¼æ´åå°ä¸åå·¢çæ®å·®æ¡æ¶ä¸­ï¼ä»¥å¢å¼·è³è¨æµåï¼ææææå°æ°£éçè¤éç´°ç¯ä¸¦æ¸è¼æ¢¯åº¦æ¶å¤±ãå¨æ­¤åºç¤ä¸ï¼æåéç¼äºä¸åä¸éæ®µåå²ç®¡éï¼ä»¥æä½³å MNR-UNet çè¨ç·´ãåå©åéæ®µåªåèæ®é«æºç¢ºåº¦åææåº¦ï¼èç¬¬ä¸éæ®µåå°æ³¨æ¼ä¿®å¾©æ°£éæ·è£ï¼ä»¥å¹³è¡¡ææ²å®æ´æ§åæ­£ç¢ºæ§ãçºäºé²ä¸æ­¥è§£æ±ºé¡å¥ä¸å¹³è¡¡çåé¡ï¼æåå¼å¥äºä¸åå æ¬æ·è£æç¥æå¤±ï¼wBALï¼ä¾æé«å°å·æææ°æ§æ¨£æ¬çéæ³¨ï¼æ²ç½°æ·è£ï¼å¾èå»¶é·æ°£éæ¨¹çé·åº¦ãæ­¤å¤ï¼æåæåºäºä¸ååå±¤è©ä¼°æ¡æ¶ï¼ä»¥æä¾æ´å·è¨åºæç¾©çåæãå¨å§é¨åå¬å±æ¸æéä¸çé©è­è¡¨æï¼æåçåæ³å¨æª¢æ¸¬æ´æºç¢ºçæ°£éé«ç´ åè­å¥é¡å¤åæ¯æ¹é¢åå¾äºåè¶çæè½ï¼é¡¯èæé«äºæ°£éææ²å®æ´æ§ãè©²ç¨å¼ç¢¼å°å¨è«æç¼è¡¨å¾å¬éç¼å¸ã

##### **E2E-Swin-Unet++: An Enhanced End-to-End Swin-Unet Architecture With Dual Decoders For PTMC Segmentation**
2410.18239v1 by Maryam Dialameh, Hossein Rajabzadeh, Moslem Sadeghi-Goughari, Jung Suk Sim, Hyock Ju Kwon

Efficiently managing papillary thyroid microcarcinoma (PTMC) while minimizing
patient discomfort poses a significant clinical challenge. Radiofrequency
ablation (RFA) offers a less invasive alternative to surgery and radiation
therapy for PTMC treatment, characterized by shorter recovery times and reduced
pain. As an image-guided procedure, RFA generates localized heat by delivering
high-frequency electrical currents through electrodes to the targeted area
under ultrasound imaging guidance. However, the precision and skill required by
operators for accurate guidance using current ultrasound B-mode imaging
technologies remain significant challenges. To address these challenges, we
develop a novel AI segmentation model, E2E-Swin-Unet++. This model enhances
ultrasound B-mode imaging by enabling real-time identification and segmentation
of PTMC tumors and monitoring of the region of interest for precise targeting
during treatment. E2E-Swin- Unet++ is an advanced end-to-end extension of the
Swin-Unet architecture, incorporating thyroid region information to minimize
the risk of false PTMC segmentation while providing fast inference
capabilities. Experimental results on a real clinical RFA dataset demonstrate
the superior performance of E2E-Swin-Unet++ compared to related models. Our
proposed solution significantly improves the precision and control of RFA
ablation treatment by enabling real-time identification and segmentation of
PTMC margins during the procedure.

æè¦ï¼å¨æå¤§ç¨åº¦éä½æ£èä¸éæçåæ¶ææç®¡çä¹³å¤´ç¶ç²ç¶èºå¾®å°ç (PTMC) å¯¹ä¸´åºæåºäºéå¤§ææãå°é¢æ¶èæ¯ (RFA) ä¸º PTMC æ²»çæä¾äºä¸ç§åä¼¤æ´å°çæ¿ä»£ææ¯åæ¾å°æ²»ççæ¹æ³ï¼å¶ç¹ç¹æ¯æ¢å¤æ¶é´æ´ç­ä¸ç¼çææ´ä½ãä½ä¸ºä¸ç§å¾åå¼å¯¼ææ¯ï¼RFA éè¿å¨è¶å£°æåå¼å¯¼ä¸éè¿çµæåç®æ åºåè¾éé«é¢çµæµæ¥äº§çå±é¨ç­éãç¶èï¼æä½èä½¿ç¨å½åè¶å£° B æ¨¡å¼æåææ¯è¿è¡ç²¾ç¡®å¼å¯¼æéçç²¾ç¡®åº¦åæè½ä»ç¶æ¯éå¤§ææãä¸ºäºåºå¯¹è¿äºææï¼æä»¬å¼åäºä¸ç§æ°çäººå·¥æºè½åå²æ¨¡å E2E-Swin-Unet++ãè¯¥æ¨¡åéè¿å®ç° PTMC è¿ç¤çå®æ¶è¯å«ååå²ä»¥åå¨æ²»çæé´çæµæå´è¶£åºåä»¥è¿è¡ç²¾ç¡®é¶åæ¥å¢å¼ºè¶å£° B æ¨¡å¼æåãE2E-Swin- Unet++ æ¯ Swin-Unet æ¶æçé«çº§ç«¯å°ç«¯æ©å±ï¼å®ç»åäºç²ç¶èºåºåä¿¡æ¯ä»¥æå¤§ç¨åº¦å°éä½éè¯¯åå² PTMC çé£é©ï¼åæ¶æä¾å¿«éçæ¨çè½åãå¨çå®ä¸´åº RFA æ°æ®éä¸çå®éªç»æè¯æäº E2E-Swin-Unet++ ä¸ç¸å³æ¨¡åç¸æ¯å·æåè¶çæ§è½ãæä»¬æåºçè§£å³æ¹æ¡éè¿å¨ææ¯æé´å®ç° PTMC è¾¹ç¼çå®æ¶è¯å«ååå²ï¼æ¾èæé«äº RFA æ¶èæ²»ççç²¾ç¡®åº¦åæ§å¶åã

##### **Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration**
2410.18076v1 by Max Wilcoxson, Qiyang Li, Kevin Frans, Sergey Levine

Unsupervised pretraining has been transformative in many supervised domains.
However, applying such ideas to reinforcement learning (RL) presents a unique
challenge in that fine-tuning does not involve mimicking task-specific data,
but rather exploring and locating the solution through iterative
self-improvement. In this work, we study how unlabeled prior trajectory data
can be leveraged to learn efficient exploration strategies. While prior data
can be used to pretrain a set of low-level skills, or as additional off-policy
data for online RL, it has been unclear how to combine these ideas effectively
for online exploration. Our method SUPE (Skills from Unlabeled Prior data for
Exploration) demonstrates that a careful combination of these ideas compounds
their benefits. Our method first extracts low-level skills using a variational
autoencoder (VAE), and then pseudo-relabels unlabeled trajectories using an
optimistic reward model, transforming prior data into high-level, task-relevant
examples. Finally, SUPE uses these transformed examples as additional
off-policy data for online RL to learn a high-level policy that composes
pretrained low-level skills to explore efficiently. We empirically show that
SUPE reliably outperforms prior strategies, successfully solving a suite of
long-horizon, sparse-reward tasks. Code: https://github.com/rail-berkeley/supe.

æè¦ï¼ç¡ç£ç£é è¨ç·´å¨è¨±å¤ç£ç£é åä¸­å·æè®é©æ§ã
ç¶èï¼å°æ­¤é¡æ³æ³æç¨æ¼å¼·åå­¸ç¿ (RL) æå¸¶ä¾ä¸åç¨ç¹çææ°ï¼å çºå¾®èª¿ä¸æ¶åæ¨¡ä»¿ç¹å®æ¼ä»»åçè³æï¼
èæ¯ééåè¦èªææåä¾æ¢ç´¢åæ¾å°è§£æ±ºæ¹æ¡ãå¨éé å·¥ä½ä¸­ï¼æåç ç©¶å¦ä½å©ç¨æªæ¨ç±¤çååè»è·¡è³æ
ä¾å­¸ç¿ææçæ¢ç´¢ç­ç¥ãéç¶ååè³æå¯ç¨æ¼é è¨ç·´ä¸çµä½éæè½ï¼æä½çºç·ä¸ RL çå¶ä»é¢ç·ç­ç¥è³æï¼
ä½å¦ä½ææçµåéäºæ³æ³ä»¥é²è¡ç·ä¸æ¢ç´¢ä¸ç´ä¸æ¸æ¥ãæåç SUPE æ¹æ³ï¼ç¨æ¼æ¢ç´¢çæªæ¨ç±¤ååè³æä¸­çæè½ï¼
è­æäºéäºæ³æ³çè¬¹æçµåæç¢çè¤åæçãæåçåæ³é¦åä½¿ç¨è®ç°èªåç·¨ç¢¼å¨ (VAE) æåä½éæè½ï¼
ç¶å¾ä½¿ç¨æ¨è§çåµæ¨¡åå°æªæ¨ç±¤çè»è·¡é²è¡å½éæ°æ¨ç±¤ï¼å°ååè³æè½æçºé«éãèä»»åç¸éçç¯ä¾ã
æå¾ï¼SUPE å°éäºè½æå¾çç¯ä¾ç¨ä½ç·ä¸ RL çå¶ä»é¢ç·ç­ç¥è³æï¼ä»¥å­¸ç¿ä¸åé«éç­ç¥ï¼
è©²ç­ç¥çµæé è¨ç·´çä½éæè½ä»¥æææ¢ç´¢ãæåééç¶é©è­æï¼SUPE å¯é å°åªæ¼ååçç­ç¥ï¼
æåè§£æ±ºäºä¸ç³»åé·æç¨ãç¨ççåµä»»åãç¨å¼ç¢¼ï¼https://github.com/rail-berkeley/supeã

##### **Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**
2410.18060v1 by Jaime Sevilla, Nikolay Babakov, Ehud Reiter, Alberto Bugarin

In this paper, we propose a model for building natural language explanations
for Bayesian Network Reasoning in terms of factor arguments, which are
argumentation graphs of flowing evidence, relating the observed evidence to a
target variable we want to learn about. We introduce the notion of factor
argument independence to address the outstanding question of defining when
arguments should be presented jointly or separately and present an algorithm
that, starting from the evidence nodes and a target node, produces a list of
all independent factor arguments ordered by their strength. Finally, we
implemented a scheme to build natural language explanations of Bayesian
Reasoning using this approach. Our proposal has been validated in the medical
domain through a human-driven evaluation study where we compare the Bayesian
Network Reasoning explanations obtained using factor arguments with an
alternative explanation method. Evaluation results indicate that our proposed
explanation approach is deemed by users as significantly more useful for
understanding Bayesian Network Reasoning than another existing explanation
method it is compared to.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåæåºäºä¸åæ¨¡åï¼ç¨æ¼å»ºæ§è²æ°ç¶²è·¯æ¨ççèªç¶èªè¨è§£éï¼ä»¥å å­è«è­çºåºç¤ï¼å®åæ¯æµåè­æçè«è­åï¼å°è§å¯å°çè­æèæåæ³è¦äºè§£çç®æ¨è®æ¸è¯ç¹«èµ·ä¾ãæåå¼å¥äºå å­è«è­ç¨ç«æ§çæ¦å¿µï¼ä»¥è§£æ±ºå®ç¾©ä½ææå°è«è­è¯åæå®ç¨åç¾çæªæ±ºåé¡ï¼ä¸¦æåºäºä¸ç¨®æ¼ç®æ³ï¼å¾è­æç¯é»åç®æ¨ç¯é»éå§ï¼ç¢çä¸åæå¼·åº¦æåºçææç¨ç«å å­è«è­æ¸å®ãæå¾ï¼æåå¯¦ä½äºä¸åæ¹æ¡ï¼ä½¿ç¨éç¨®æ¹æ³å»ºæ§è²æ°æ¨ççèªç¶èªè¨è§£éãæåçææ¡å·²å¨é«å­¸é åä¸­ééäººçºé©åçè©ä¼°ç ç©¶å¾å°é©è­ï¼å¨è©²ç ç©¶ä¸­ï¼æåå°ä½¿ç¨å å­è«è­ç²å¾çè²æ°ç¶²è·¯æ¨çè§£éèå¦ä¸ç¨®è§£éæ¹æ³é²è¡æ¯è¼ãè©ä¼°çµæè¡¨æï¼èå¦ä¸ç¨®ç¾æçè§£éæ¹æ³ç¸æ¯ï¼æåçæè­°è§£éæ¹æ³è¢«ä½¿ç¨èè¦çºé¡¯èæ´æå©æ¼çè§£è²æ°ç¶²è·¯æ¨çã</paragraph>

##### **AI driven health recommender**
2410.17991v1 by K. Vignesh, B. Pranavi, Ch. Sreenidhi

As AI emerged as highest valued technology, We used that to create a web
application that makes a patient work easier .It detects the disease name based
on the symptoms given by the patient and recommends medication for respective
disease, precautions to take, diet to follow and workouts to do, so the disease
can be minimized. The web application is made with clean and Realtime data by
using Machine learning as root. We used flask to create a user-friendly
platform.

æè¦ï¼é¨è AI æçºæå·å¹å¼çæè¡ï¼æåå©ç¨å®ä¾å»ºç«ä¸åè®æ£èæ´è¼é¬çç¶²è·¯æç¨ç¨å¼ãå®æ ¹ææ£èæä¾çççä¾åµæ¸¬ç¾çåç¨±ï¼ä¸¦éå°ç¸éç¾çæ¨è¦è¥ç©ãé é²æªæ½ãé£²é£å»ºè­°åééæ¹å¼ï¼ä»¥å°ç¾çéå°æä½ãéåç¶²è·¯æç¨ç¨å¼æ¯ä½¿ç¨æ©å¨å­¸ç¿çºåºç¤ï¼ä»¥ä¹¾æ·¨ä¸å³æçè³æå»ºç«ãæåä½¿ç¨ Flask ä¾å»ºç«ä¸åä½¿ç¨èååçå¹³å°ã

##### **MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers**
2410.17957v1 by Zebin Yang, Renze Chen, Taiqiang Wu, Ngai Wong, Yun Liang, Runsheng Wang, Ru Huang, Meng Li

In this paper, we propose MCUBERT to enable language models like BERT on tiny
microcontroller units (MCUs) through network and scheduling co-optimization. We
observe the embedding table contributes to the major storage bottleneck for
tiny BERT models. Hence, at the network level, we propose an MCU-aware
two-stage neural architecture search algorithm based on clustered low-rank
approximation for embedding compression. To reduce the inference memory
requirements, we further propose a novel fine-grained MCU-friendly scheduling
strategy. Through careful computation tiling and re-ordering as well as kernel
design, we drastically increase the input sequence lengths supported on MCUs
without any latency or accuracy penalty. MCUBERT reduces the parameter size of
BERT-tiny and BERT-mini by 5.7$\times$ and 3.0$\times$ and the execution memory
by 3.5$\times$ and 4.3$\times$, respectively. MCUBERT also achieves 1.5$\times$
latency reduction. For the first time, MCUBERT enables lightweight BERT models
on commodity MCUs and processing more than 512 tokens with less than 256KB of
memory.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåº MCUBERTï¼ééç¶²è·¯åæç¨å±åæä½³åï¼å¨å¾®åå¾®æ§å¶å¨å®å (MCU) ä¸åç¨é¡ä¼¼ BERT çèªè¨æ¨¡åãæåè§å¯å°åµå¥å¼è¡¨æ ¼å°å¾®å BERT æ¨¡åçä¸»è¦å²å­ç¶é ¸ææè²¢ç»ãå æ­¤ï¼å¨ç¶²è·¯å±¤ç´ï¼æåæåºä¸ååºæ¼åç¾¤ä½ç§©è¿ä¼¼ç MCU æç¥å©éæ®µç¥ç¶æ¶æ§æå°æ¼ç®æ³ï¼ç¨æ¼åµå¥å¼å£ç¸®ãçºäºæ¸å°æ¨è«è¨æ¶é«éæ±ï¼æåé²ä¸æ­¥æåºä¸åæ°ç©çç´°ç²åº¦ MCU ååæç¨ç­ç¥ãééä»ç´°çéç®åå²åéæ°æåºä»¥åæ ¸å¿è¨­è¨ï¼æåå¤§å¹å¢å  MCU ä¸æ¯æ´çè¼¸å¥åºåé·åº¦ï¼èä¸ææä»»ä½å»¶é²ææºç¢ºåº¦æå¤±ãMCUBERT å° BERT-tiny å BERT-mini çåæ¸å¤§å°åå¥æ¸å°äº 5.7 åå 3.0 åï¼å·è¡è¨æ¶é«åå¥æ¸å°äº 3.5 åå 4.3 åãMCUBERT ä¹éå°äº 1.5 åçå»¶é²æ¸å°ãMCUBERT é¦æ¬¡å¨åå MCU ä¸åç¨è¼éç´ BERT æ¨¡åï¼ä¸¦ä»¥å°æ¼ 256KB çè¨æ¶é«èçè¶é 512 åç¬¦èã

##### **Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation**
2410.17918v1 by Wenfang Yao, Chen Liu, Kejing Yin, William K. Cheung, Jing Qin

Integrating multi-modal clinical data, such as electronic health records
(EHR) and chest X-ray images (CXR), is particularly beneficial for clinical
prediction tasks. However, in a temporal setting, multi-modal data are often
inherently asynchronous. EHR can be continuously collected but CXR is generally
taken with a much longer interval due to its high cost and radiation dose. When
clinical prediction is needed, the last available CXR image might have been
outdated, leading to suboptimal predictions. To address this challenge, we
propose DDL-CXR, a method that dynamically generates an up-to-date latent
representation of the individualized CXR images. Our approach leverages latent
diffusion models for patient-specific generation strategically conditioned on a
previous CXR image and EHR time series, providing information regarding
anatomical structures and disease progressions, respectively. In this way, the
interaction across modalities could be better captured by the latent CXR
generation process, ultimately improving the prediction performance.
Experiments using MIMIC datasets show that the proposed model could effectively
address asynchronicity in multimodal fusion and consistently outperform
existing methods.

æè¦ï¼æ´åå¤æ¨¡å¼è¨åºæ¸æï¼ä¾å¦é»å­å¥åº·ç´é (EHR) åè¸é¨ X åå½±å (CXR)ï¼å°æ¼è¨åºé æ¸¬ä»»åç¹å¥æçãç¶èï¼å¨æéè¨­å®ä¸­ï¼å¤æ¨¡å¼æ¸æéå¸¸æ¬è³ªä¸æ¯ç°æ­¥çãEHR å¯ä»¥æçºæ¶éï¼ä½ CXR éå¸¸ç±æ¼å¶é«ææ¬åè¼»å°åéèä»¥æ´é·çééé²è¡ææãç¶éè¦è¨åºé æ¸¬æï¼æå¾ä¸å¼µå¯ç¨ç CXR å½±åå¯è½å·²éæï¼å°è´é æ¸¬ä¸ä½³ãçºäºæå°éä¸ææ°ï¼æåæåºäº DDL-CXRï¼éæ¯ä¸ç¨®åæçæåæ§å CXR å½±åçææ°æ½å¨è¡¨ç¤ºçæ¹æ³ãæåçåæ³å©ç¨æ½å¨æ´æ£æ¨¡åé²è¡ç¹å®æ¼æ£èççæï¼ä¸¦æ ¹æååç CXR å½±åå EHR æéåºåé²è¡ç­ç¥æ§ç´æï¼åå¥æä¾æéè§£åçµæ§åç¾çé²å±çä¿¡æ¯ãéæ¨£ï¼æ½å¨ CXR çæéç¨å¯ä»¥æ´å¥½å°ææè·¨æ¨¡å¼çäº¤äºï¼æçµæé«é æ¸¬æ§è½ãä½¿ç¨ MIMIC æ¸æéé²è¡çå¯¦é©è¡¨æï¼ææåºçæ¨¡åå¯ä»¥ææå°è§£æ±ºå¤æ¨¡å¼èåä¸­çç°æ­¥æ§ï¼ä¸¦å§çµåªæ¼ç¾ææ¹æ³ã

##### **PGDiffSeg: Prior-Guided Denoising Diffusion Model with Parameter-Shared Attention for Breast Cancer Segmentation**
2410.17812v1 by Feiyan Feng, Tianyu Liu, Hong Wang, Jun Zhao, Wei Li, Yanshen Sun

Early detection through imaging and accurate diagnosis is crucial in
mitigating the high mortality rate associated with breast cancer. However,
locating tumors from low-resolution and high-noise medical images is extremely
challenging. Therefore, this paper proposes a novel PGDiffSeg (Prior-Guided
Diffusion Denoising Model with Parameter-Shared Attention) that applies
diffusion denoising methods to breast cancer medical image segmentation,
accurately recovering the affected areas from Gaussian noise. Firstly, we
design a parallel pipeline for noise processing and semantic information
processing and propose a parameter-shared attention module (PSA) in multi-layer
that seamlessly integrates these two pipelines. This integration empowers
PGDiffSeg to incorporate semantic details at multiple levels during the
denoising process, producing highly accurate segmentation maps. Secondly, we
introduce a guided strategy that leverages prior knowledge to simulate the
decision-making process of medical professionals, thereby enhancing the model's
ability to locate tumor positions precisely. Finally, we provide the first-ever
discussion on the interpretability of the generative diffusion model in the
context of breast cancer segmentation. Extensive experiments have demonstrated
the superiority of our model over the current state-of-the-art approaches,
confirming its effectiveness as a flexible diffusion denoising method suitable
for medical image research. Our code will be publicly available later.

æè¦ï¼ééå½±åçæ©æåµæ¸¬åæºç¢ºçè¨ºæ·ï¼å°æ¼æ¸ç·©èä¹³çç¸éçé«æ­»äº¡çè³ééè¦ãç¶èï¼å¾ä½è§£æåº¦åé«éè¨çé«çå½±åä¸­æ¾åºè«ç¤æ¥µå·ææ°æ§ãå æ­¤ï¼æ¬ææåºä¸åæ°ç©ç PGDiffSegï¼å·æåæ¸å±äº«æ³¨æåçåé©å¼å°æ´æ£å»åªæ¨¡åï¼ï¼å°æ´æ£å»åªæ¹æ³æç¨æ¼ä¹³çé«çå½±ååå²ï¼å¾é«æ¯éè¨ä¸­æºç¢ºå°æ¢å¾©åå½±é¿ååãé¦åï¼æåè¨­è¨ä¸åç¨æ¼éè¨èçåèªç¾©è¨æ¯èççå¹³è¡ç®¡ç·ï¼ä¸¦å¨å¤å±¤ä¸­æåºä¸ååæ¸å±äº«æ³¨æåæ¨¡çµ (PSA)ï¼ç¡ç¸«å°æ´åéå©åç®¡ç·ãéç¨®æ´åè³¦äº PGDiffSeg å¨å»åªéç¨ä¸­å¨å¤åå±¤ç´ä¸­ç´å¥èªç¾©ç´°ç¯çè½åï¼ç¢çé«åº¦æºç¢ºçåå²åãå¶æ¬¡ï¼æåå¼å¥ä¸åå¼å°ç­ç¥ï¼å©ç¨åé©ç¥è­ä¾æ¨¡æ¬é«çå°æ¥­äººå¡çæ±ºç­éç¨ï¼å¾èå¢å¼·æ¨¡åç²¾ç¢ºå®ä½è«ç¤ä½ç½®çè½åãæå¾ï¼æåé¦æ¬¡è¨è«äºçææ´æ£æ¨¡åå¨ä¹³çåå²èæ¯ä¸çå¯è§£éæ§ãå»£æ³çå¯¦é©è­æäºæåçæ¨¡ååªæ¼ç¶åæåé²çæ¹æ³ï¼è­å¯¦å¶ä½çºä¸ç¨®é©ç¨æ¼é«å­¸å½±åç ç©¶çéæ´»æ´æ£å»åªæ¹æ³çæææ§ãæåçç¨å¼ç¢¼ç¨å¾å°å¬éã

##### **Bonsai: Gradient-free Graph Distillation for Node Classification**
2410.17579v2 by Mridul Gupta, Samyak Jain, Vansh Ramani, Hariprasad Kodamana, Sayan Ranu

Graph distillation has emerged as a promising avenue to enable scalable
training of GNNs by compressing the training dataset while preserving essential
graph characteristics. Our study uncovers significant shortcomings in current
graph distillation techniques. First, the majority of the algorithms
paradoxically require training on the full dataset to perform distillation.
Second, due to their gradient-emulating approach, these methods require fresh
distillation for any change in hyperparameters or GNN architecture, limiting
their flexibility and reusability. Finally, they fail to achieve substantial
size reduction due to synthesizing fully-connected, edge-weighted graphs. To
address these challenges, we present Bonsai, a novel graph distillation method
empowered by the observation that \textit{computation trees} form the
fundamental processing units of message-passing GNNs. Bonsai distills datasets
by encoding a careful selection of \textit{exemplar} trees that maximize the
representation of all computation trees in the training set. This unique
approach imparts Bonsai as the first linear-time, model-agnostic graph
distillation algorithm for node classification that outperforms existing
baselines across $6$ real-world datasets on accuracy, while being $22$ times
faster on average. Bonsai is grounded in rigorous mathematical guarantees on
the adopted approximation strategies making it robust to GNN architectures,
datasets, and parameters.

æè¦ï¼åè¡¨è¸é¤¾å·²æçºä¸ç¨®æåéçæ¹æ³ï¼å¯ééå£ç¸®è¨ç·´è³æéä¸¦åæä¿çå¿è¦çåè¡¨ç¹å¾µï¼ä¾å¯¦ç¾ GNN çå¯æ´åè¨ç·´ãæåçç ç©¶æ­é²äºç¶ååè¡¨è¸é¤¾æè¡çéå¤§ç¼ºé»ãé¦åï¼å¤§å¤æ¸æ¼ç®æ³çç¾å°éè¦å°å®æ´è³æéé²è¡è¨ç·´æè½å·è¡è¸é¤¾ãå¶æ¬¡ï¼ç±æ¼éäºæ¹æ³æ¡ç¨äºæ¢¯åº¦æ¨¡æ¬æ¹æ³ï¼å æ­¤å°æ¼è¶åæ¸æ GNN æ¶æ§çä»»ä½è®æ´ï¼é½éè¦é²è¡æ°çè¸é¤¾ï¼ééå¶äºå®åçéæ´»æ§èå¯éè¤ä½¿ç¨æ§ãæå¾ï¼ç±æ¼åæäºå¨é£æ¥ãéç·£å æ¬åè¡¨ï¼å æ­¤å®åç¡æ³å¯¦ç¾å¤§å¹åº¦çå°ºå¯¸ç¸®æ¸ãçºäºæå°éäºææ°ï¼æåæåºäº Bonsaiï¼éæ¯ä¸ç¨®æ°ç©çåè¡¨è¸é¤¾æ¹æ³ï¼å®æ¯ç±è§å¯å°ãéç®æ¨¹ãæ§æè¨æ¯å³é GNN çåºæ¬èçå®åèåç¼çãBonsai ééç·¨ç¢¼ä»ç´°é¸æçãç¯ä¾ãæ¨¹ä¾è¸é¤¾è³æéï¼éäºæ¨¹å¯æå¤§åè¨ç·´éä¸­ææéç®æ¨¹çè¡¨ç¤ºãéç¨®ç¨ç¹çæ¹æ³ä½¿ Bonsai æçºç¬¬ä¸åç·æ§æéãèæ¨¡åç¡éçåè¡¨è¸é¤¾æ¼ç®æ³ï¼ç¨æ¼ç¯é»åé¡ï¼å¶å¨æºç¢ºåº¦æ¹é¢åªæ¼ $6$ åçå¯¦ä¸çè³æéä¸­çç¾æåºæºï¼åæå¹³åå¿« $22$ åãBonsai ä»¥å´è¬¹çæ¸å­¸ä¿è­çºåºç¤ï¼éå°ææ¡ç¨çè¿ä¼¼ç­ç¥ï¼ä½¿å¶å° GNN æ¶æ§ãè³æéååæ¸å·æç©©å¥æ§ã

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

æè¦ï¼å¯è§£éäººå·¥æºæ§ï¼AIï¼å°æ³¨æ¼åå©äººé¡äºè§£ AI ç³»çµ±éä½æå¶æ±ºç­ï¼æ¸åå¹´ä¾ä¸ç´æ¯ AI çåºç³ãæè¿çå¯è§£éæ§ç ç©¶å°æ³¨æ¼è§£é AI æ¨¡åææ¨¡åå¯è§£éæ§çéä½ãä¹æå¹¾ä»½ç«å ´è²æåè©è«è«æè©³ç´°èªªæäºæçµä½¿ç¨èå°ä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§çéæ±ï¼ä½å¯¦ä½è¼å°ãå æ­¤ï¼æ¬è«ææ¨å¨å½è£æ¨¡ååä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§ä¹éçä¸äºå·®è·ãæåå»ºç«ä¸åè§£éæ¬é«ï¼EOï¼ä»¥ééå¶æ¯æ´åä»¶ä¾è¡¨ç¤ºå¾æç»ä¸­è¡ççè§£éé¡åãæåå¯¦ä½ä¸åç¥è­å¢å¼·çåç­ï¼QAï¼ç®¡ç·ï¼ä»¥å¨è¨åºç°å¢ä¸­æ¯æ´æå¢è§£éãæå¾ï¼æåæ­£å¨å¯¦ä½ä¸åç³»çµ±ï¼ä»¥çµåä¾èªä¸å AI æ¹æ³åè³ææ¨¡å¼çè§£éãå¨ EO ä¸­ï¼æåå¯ä»¥è¡¨ç¤º 15 ç¨®ä¸åçè§£éé¡åï¼ä¸¦ä¸æåå·²å¨å­åç¯ä¾ä½¿ç¨æ¡ä¾ä¸­æ¸¬è©¦éäºè¡¨ç¤ºãæåç¼ç¾ï¼ç¥è­å¢å¼·æ¹åäºåºç¤å¤§åèªè¨æ¨¡åå¨æå¢å QA ä¸­çæè½ï¼ä¸¦ä¸æè½å ç¾çç¾¤çµèç°ãå¨ç¸åçç°å¢ä¸­ï¼è¨åºé«çä¹è¡¨ç¤ºä»åå¸æå°å¯æä½æ§è¦çºè§£éä¸­çä¸»è¦ç¦é»ä¹ä¸ãå¨æåçè§£éçµåæ¹æ³ä¸­ï¼æåè¨ç«ä½¿ç¨ç¸ä¼¼æ§ææ¨ä¾ç¢ºå®æ¢æ§çåµæ¸¬ç°å¢ä¸­è§£éçç¸ä¼¼æ§ãç¸½é«èè¨ï¼ééæ¬è«æï¼æåè¨­è¨äºå¯ä»¥å¨ä¸åä½¿ç¨æ¡ä¾ä¸­æ¯æ´ç¥è­åç¨è§£éçæ¹æ³ï¼èéå°ç¶ä» AI æä»£ä¸­å¯ä»¥ç¢çéäºè§£éçæ¯æ´åä»¶åå¯ä»¥å¢å¼·éäºè§£éçé åç¥è­ä¾æºçæ¹æ³ã

##### **A 10.60 $Î¼$W 150 GOPS Mixed-Bit-Width Sparse CNN Accelerator for Life-Threatening Ventricular Arrhythmia Detection**
2410.17395v1 by Yifan Qin, Zhenge Jia, Zheyu Yan, Jay Mok, Manto Yung, Yu Liu, Xuejiao Liu, Wujie Wen, Luhong Liang, Kwang-Ting Tim Cheng, X. Sharon Hu, Yiyu Shi

This paper proposes an ultra-low power, mixed-bit-width sparse convolutional
neural network (CNN) accelerator to accelerate ventricular arrhythmia (VA)
detection. The chip achieves 50% sparsity in a quantized 1D CNN using a sparse
processing element (SPE) architecture. Measurement on the prototype chip TSMC
40nm CMOS low-power (LP) process for the VA classification task demonstrates
that it consumes 10.60 $\mu$W of power while achieving a performance of 150
GOPS and a diagnostic accuracy of 99.95%. The computation power density is only
0.57 $\mu$W/mm$^2$, which is 14.23X smaller than state-of-the-art works, making
it highly suitable for implantable and wearable medical devices.

æè¦ï¼æ¬è«ææåºä¸åè¶ä½åèãæ··åä½åå¯¬åº¦ç¨çå·ç©ç¥ç¶ç¶²è·¯ (CNN) å éå¨ï¼ä»¥å éå¿å®¤å¿å¾ä¸æ´ (VA) åµæ¸¬ãæ­¤æ¶çå¨éåç 1D CNN ä¸­ä½¿ç¨ç¨çèçåä»¶ (SPE) æ¶æ§ï¼å¯¦ç¾ 50% çç¨çæ§ãå¨ VA åé¡ä»»åä¸­ï¼éå° TSMC 40nm CMOS ä½åè (LP) è£½ç¨çååæ¶çé²è¡éæ¸¬ï¼é¡¯ç¤ºå¶åèçº 10.60 $\mu$Wï¼åæéå° 150 GOPS çæè½å 99.95% çè¨ºæ·æºç¢ºåº¦ãéç®åçå¯åº¦åçº 0.57 $\mu$W/mm$^2$ï¼æ¯ç¾ææè¡å° 14.23 åï¼ä½¿å¶éå¸¸é©åæ¤å¥å¼åç©¿æ´å¼é«çè£ç½®ã

##### **DeLLiriuM: A large language model for delirium prediction in the ICU using structured EHR**
2410.17363v1 by Miguel Contreras, Sumit Kapoor, Jiaqing Zhang, Andrea Davidson, Yuanfang Ren, Ziyuan Guan, Tezcan Ozrazgat-Baslanti, Subhash Nerella, Azra Bihorac, Parisa Rashidi

Delirium is an acute confusional state that has been shown to affect up to
31% of patients in the intensive care unit (ICU). Early detection of this
condition could lead to more timely interventions and improved health outcomes.
While artificial intelligence (AI) models have shown great potential for ICU
delirium prediction using structured electronic health records (EHR), most of
them have not explored the use of state-of-the-art AI models, have been limited
to single hospitals, or have been developed and validated on small cohorts. The
use of large language models (LLM), models with hundreds of millions to
billions of parameters, with structured EHR data could potentially lead to
improved predictive performance. In this study, we propose DeLLiriuM, a novel
LLM-based delirium prediction model using EHR data available in the first 24
hours of ICU admission to predict the probability of a patient developing
delirium during the rest of their ICU admission. We develop and validate
DeLLiriuM on ICU admissions from 104,303 patients pertaining to 195 hospitals
across three large databases: the eICU Collaborative Research Database, the
Medical Information Mart for Intensive Care (MIMIC)-IV, and the University of
Florida Health's Integrated Data Repository. The performance measured by the
area under the receiver operating characteristic curve (AUROC) showed that
DeLLiriuM outperformed all baselines in two external validation sets, with 0.77
(95% confidence interval 0.76-0.78) and 0.84 (95% confidence interval
0.83-0.85) across 77,543 patients spanning 194 hospitals. To the best of our
knowledge, DeLLiriuM is the first LLM-based delirium prediction tool for the
ICU based on structured EHR data, outperforming deep learning baselines which
employ structured features and can provide helpful information to clinicians
for timely interventions.

æè¦ï¼è°µå¦æ¯ä¸ç¨®æ¥æ§æ··äºçæï¼ç ç©¶é¡¯ç¤ºï¼å è­·çæ¿ (ICU) ä¸­å¤é 31% çæ£èæåå°å½±é¿ãææ©åµæ¸¬æ­¤çæ³æå©æ¼åæä»å¥ä¸¦æ¹åå¥åº·çµæãåç®¡äººå·¥æºæ§ (AI) æ¨¡åå·²å±ç¾åºä½¿ç¨çµæ§åé»å­å¥åº·è¨é (EHR) é æ¸¬ ICU è°µå¦çå¼·å¤§æ½åï¼ä½å¤§å¤æ¸æ¨¡åä¸¦æªæ¢è¨ä½¿ç¨æåé²ç AI æ¨¡åï¼ä¸åéæ¼å®ä¸é«é¢ï¼ææ¯å¨å°åç¾¤çµä¸­éç¼åé©è­ãä½¿ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼åæ¸éæ¸ç¾è¬å°æ¸ååçæ¨¡åï¼æ­éçµæ§å EHR è³æï¼å¯è½ææåé æ¸¬æè½ãå¨æ¬ç ç©¶ä¸­ï¼æåæåº DeLLiriuMï¼éæ¯ä¸ç¨®æ°ç©çåºæ¼ LLM çè°µå¦é æ¸¬æ¨¡åï¼ä½¿ç¨ ICU ä½é¢çå 24 å°æå§å¯åå¾ç EHR è³æï¼ä¾é æ¸¬æ£èå¨ ICU ä½é¢æéç¼çè°µå¦çæ©çãæåå¾ 195 éé«é¢ç 104,303 åæ£èç ICU ä½é¢è³æä¸­éç¼åé©è­ DeLLiriuMï¼éäºè³æä¾èªä¸åå¤§åè³æåº«ï¼eICU åä½ç ç©¶è³æåº«ãéçç£è­·é«çè³è¨å¸å ´ (MIMIC)-IVï¼ä»¥åä½ç¾ééå¤§å­¸å¥åº·æ´åè³æå²å­åº«ãä»¥åè©¦èæä½ç¹å¾µæ²ç·ä¸é¢ç© (AUROC) è¡¡éçæè½é¡¯ç¤ºï¼DeLLiriuM å¨å©åå¤é¨é©è­éä¸­åªæ¼ææåºæºï¼å¨æ©«è·¨ 194 éé«é¢ç 77,543 åæ£èä¸­ï¼å¶ AUROC çº 0.77ï¼95% ä¿¡è³´åé 0.76-0.78ï¼å 0.84ï¼95% ä¿¡è³´åé 0.83-0.85ï¼ãææåæç¥ï¼DeLLiriuM æ¯ç¬¬ä¸ååºæ¼çµæ§å EHR è³æç LLM å ICU è°µå¦é æ¸¬å·¥å·ï¼å¶æè½åªæ¼æ¡ç¨çµæ§åç¹å¾µçæ·±åº¦å­¸ç¿åºæºï¼ä¸è½çºè¨åºé«å¸«æä¾æå©æ¼åæä»å¥çè³è¨ã

##### **EEG-DIF: Early Warning of Epileptic Seizures through Generative Diffusion Model-based Multi-channel EEG Signals Forecasting**
2410.17343v1 by Zekun Jiang, Wei Dai, Qu Wei, Ziyuan Qin, Kang Li, Le Zhang

Multi-channel EEG signals are commonly used for the diagnosis and assessment
of diseases such as epilepsy. Currently, various EEG diagnostic algorithms
based on deep learning have been developed. However, most research efforts
focus solely on diagnosing and classifying current signal data but do not
consider the prediction of future trends for early warning. Additionally, since
multi-channel EEG can be essentially regarded as the spatio-temporal signal
data received by detectors at different locations in the brain, how to
construct spatio-temporal information representations of EEG signals to
facilitate future trend prediction for multi-channel EEG becomes an important
problem. This study proposes a multi-signal prediction algorithm based on
generative diffusion models (EEG-DIF), which transforms the multi-signal
forecasting task into an image completion task, allowing for comprehensive
representation and learning of the spatio-temporal correlations and future
developmental patterns of multi-channel EEG signals. Here, we employ a publicly
available epilepsy EEG dataset to construct and validate the EEG-DIF. The
results demonstrate that our method can accurately predict future trends for
multi-channel EEG signals simultaneously. Furthermore, the early warning
accuracy for epilepsy seizures based on the generated EEG data reaches 0.89. In
general, EEG-DIF provides a novel approach for characterizing multi-channel EEG
signals and an innovative early warning algorithm for epilepsy seizures, aiding
in optimizing and enhancing the clinical diagnosis process. The code is
available at https://github.com/JZK00/EEG-DIF.

æè¦ï¼å¤éé EEG ä¿¡èéå¸¸ç¨æ¼è¨ºæ·åè©ä¼°ç²çç­ç¾çãç®åï¼å·²ç¶éç¼äºåç¨®åºæ¼æ·±åº¦å­¸ç¿ç EEG è¨ºæ·æ¼ç®æ³ãç¶èï¼å¤§å¤æ¸ç ç©¶å·¥ä½åå°æ³¨æ¼è¨ºæ·ååé¡ç¶åä¿¡èè³æï¼ä½æ²æèæ®é æ¸¬æªä¾è¶¨å¢ä»¥é²è¡æ©æé è­¦ãæ­¤å¤ï¼ç±æ¼å¤éé EEG æ¬è³ªä¸å¯ä»¥è¦çºå¤§è¦ä¸åä½ç½®çåµæ¸¬å¨æ¥æ¶å°çæç©ºä¿¡èè³æï¼å æ­¤å¦ä½å»ºæ§ EEG ä¿¡èçæç©ºè³è¨è¡¨å¾µä»¥å©æ¼å¤éé EEG çæªä¾è¶¨å¢é æ¸¬æçºä¸åéè¦çåé¡ãæ¬ç ç©¶æåºäºä¸ååºæ¼çææ´æ£æ¨¡å (EEG-DIF) çå¤ä¿¡èé æ¸¬æ¼ç®æ³ï¼å®å°å¤ä¿¡èé æ¸¬ä»»åè½æçºå½±åå®æä»»åï¼åè¨±å°å¤éé EEG ä¿¡èçæç©ºéè¯æ§åæªä¾ç¼å±æ¨¡å¼é²è¡å¨é¢çè¡¨å¾µåå­¸ç¿ãå¨æ­¤ï¼æåæ¡ç¨ä¸åå¬éçç²ç EEG è³æéä¾å»ºæ§åé©è­ EEG-DIFãçµæè¡¨æï¼æåçæ¹æ³å¯ä»¥æºç¢ºé æ¸¬å¤éé EEG ä¿¡èçæªä¾è¶¨å¢ãæ­¤å¤ï¼åºæ¼çæç EEG è³æçç²çç¼ä½çæ©æé è­¦æºç¢ºçéå° 0.89ãç¸½çä¾èªªï¼EEG-DIF çºå¤éé EEG ä¿¡èè¡¨å¾µæä¾äºä¸ç¨®æ°ç©çæ¹æ³ï¼ä¸¦çºç²çç¼ä½æä¾äºä¸ç¨®åµæ°çæ©æé è­¦æ¼ç®æ³ï¼æå©æ¼åªååå å¼·è¨åºè¨ºæ·éç¨ãç¨å¼ç¢¼å¯å¨ https://github.com/JZK00/EEG-DIF åå¾ã

##### **Revealing Hidden Bias in AI: Lessons from Large Language Models**
2410.16927v1 by Django Beatty, Kritsada Masanthia, Teepakorn Kaphol, Niphan Sethi

As large language models (LLMs) become integral to recruitment processes,
concerns about AI-induced bias have intensified. This study examines biases in
candidate interview reports generated by Claude 3.5 Sonnet, GPT-4o, Gemini 1.5,
and Llama 3.1 405B, focusing on characteristics such as gender, race, and age.
We evaluate the effectiveness of LLM-based anonymization in reducing these
biases. Findings indicate that while anonymization reduces certain biases,
particularly gender bias, the degree of effectiveness varies across models and
bias types. Notably, Llama 3.1 405B exhibited the lowest overall bias.
Moreover, our methodology of comparing anonymized and non-anonymized data
reveals a novel approach to assessing inherent biases in LLMs beyond
recruitment applications. This study underscores the importance of careful LLM
selection and suggests best practices for minimizing bias in AI applications,
promoting fairness and inclusivity.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) æçºæèæµç¨ä¸­ä¸å¯æç¼ºçä¸é¨åï¼äººåå° AI å¼ç¼çåè¦çææä¹é¨ä¹å åãæ¬ç ç©¶æ¢è¨äºç± Claude 3.5 SonnetãGPT-4oãGemini 1.5 å Llama 3.1 405B çæçåé¸äººé¢è©¦å ±åä¸­çåè¦ï¼éé»éæ³¨æ§å¥ãç¨®æåå¹´é½¡ç­ç¹å¾µãæåè©ä¼°äºåºæ¼ LLM çå¿ååå¨æ¸å°éäºåè¦æ¹é¢çæææ§ãç ç©¶çµæè¡¨æï¼åç®¡å¿ååå¯ä»¥æ¸å°æäºåè¦ï¼ç¹å¥æ¯æ§å¥åè¦ï¼ä½ææç¨åº¦å æ¨¡åååè¦é¡åèç°ãå¼å¾æ³¨æçæ¯ï¼Llama 3.1 405B è¡¨ç¾åºæä½çæ´é«åè¦ãæ­¤å¤ï¼æåæ¯è¼å¿åååéå¿ååæ¸æçæ¹æ³æ­ç¤ºäºä¸ç¨®æ°çæ¹æ³ï¼å¯ä»¥è©ä¼° LLM ä¸­åºæçåè¦ï¼èä¸ä»ä»æ¯æèæç¨ãæ¬ç ç©¶å¼·èª¿äºä»ç´°é¸æ LLM çéè¦æ§ï¼ä¸¦æåºäºå¨ AI æç¨ä¸­æå¤§éåº¦å°æ¸å°åè¦çæä½³å¯¦åï¼ä»¥ä¿é²å¬å¹³æ§ååå®¹æ§ã

##### **SleepCoT: A Lightweight Personalized Sleep Health Model via Chain-of-Thought Distillation**
2410.16924v1 by Huimin Zheng, Xiaofeng Xing, Xiangmin Xu

We present a novel approach to personalized sleep health management using
few-shot Chain-of-Thought (CoT) distillation, enabling small-scale language
models (> 2B parameters) to rival the performance of large language models
(LLMs) in specialized health domains. Our method simultaneously distills
problem-solving strategies, long-tail expert knowledge, and personalized
recommendation capabilities from larger models into more efficient, compact
models. Unlike existing systems, our approach offers three key functionalities:
generating personalized sleep health recommendations, supporting user-specific
follow-up inquiries, and providing responses to domain-specific knowledge
questions. We focus on sleep health due to its measurability via wearable
devices and its impact on overall well-being. Our experimental setup, involving
GPT-4o for data synthesis, Qwen-max for instruction set creation, and Qwen2.5
1.5B for model distillation, demonstrates significant improvements over
baseline small-scale models in penalization, reasoning, and knowledge
application. Experiments using 100 simulated sleep reports and 1,000
domain-specific questions shows our model achieves comparable performance to
larger models while maintaining efficiency for real-world deployment. This
research not only advances AI-driven health management but also provides a
novel approach to leveraging LLM capabilities in resource-constrained
environments, potentially enhancing the accessibility of personalized
healthcare solutions.

æè¦ï¼<paragraph>æåæåºäºä¸ååµæ°çæ¹æ³ï¼ä½¿ç¨å°è¦æ¨¡çæèéï¼CoTï¼è¸é¤¾ä¾é²è¡åäººåç¡ç å¥åº·ç®¡çï¼è®å°è¦æ¨¡èªè¨æ¨¡åï¼> 2B åæ¸ï¼è½å¤ å¨å°æ¥­å¥åº·é åèå¤§åèªè¨æ¨¡åï¼LLMï¼çæè½ç¸åª²ç¾ãæåçæ¨¡ååæå¾è¼å¤§çæ¨¡åä¸­è¸é¤¾åºåé¡è§£æ±ºç­ç¥ãé·å°¾å°å®¶ç¥è­ååäººåå»ºè­°è½åï¼è½åçºæ´ææçãæ´ç²¾ç°¡çæ¨¡åãæåçæ¨¡åä¸åæ¼ç¾æçç³»çµ±ï¼å®æä¾äºä¸å¤§ä¸»è¦åè½ï¼ç¢çåäººåçç¡ç å¥åº·å»ºè­°ãæ¯æ´ä½¿ç¨èç¹å®çå¾çºè©¢åï¼ä»¥åæä¾å°ç¹å®é åç¥è­åé¡çåæãæåå°æ³¨æ¼ç¡ç å¥åº·ï¼å çºå®å¯ä»¥ééç©¿æ´å¼è£ç½®ä¾è¡¡éï¼ä¸æå½±é¿æ´é«å¥åº·çæ³ãæåçå¯¦é©è¨­å®åå«ç¨æ¼è³æåæç GPT-4oãç¨æ¼æä»¤éå»ºç«ç Qwen-maxï¼ä»¥åç¨æ¼æ¨¡åè¸é¤¾ç Qwen2.5 1.5Bï¼è­æäºå¨èç½°ãæ¨çåç¥è­æç¨æ¹é¢ï¼æåçæ¨¡åç¸è¼æ¼åºæºçå°è¦æ¨¡æ¨¡åæé¡¯èçé²æ­¥ãä½¿ç¨ 100 ä»½æ¨¡æ¬ç¡ç å ±åå 1,000 åç¹å®é ååé¡çå¯¦é©é¡¯ç¤ºï¼æåçæ¨¡åå¨ç¶­æå¯¦éé¨ç½²æççåæï¼éå°äºèè¼å¤§åæ¨¡åç¸ç¶çæè½ãéé ç ç©¶ä¸åæ¨åäº AI é©åçå¥åº·ç®¡çï¼ä¹æä¾äºä¸åå¨è³æºåéçç°å¢ä¸­å©ç¨ LLM è½åçæ°æ¹æ³ï¼ææ½åæååäººåé«çä¿å¥è§£æ±ºæ¹æ¡çå¯åæ§ã</paragraph>

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

æè¦ï¼<paragraph>ç®çï¼èª¿æ¥è¨åºé«çå°ç®åèªååå¿é»åè§£è®åæ°çäººå·¥æºæ§æè¡çæåº¦ï¼ä»¥åä»åå°é»è¦è¼å©è§£è®ççæ³ãææåæ¹æ³ï¼æåå°è±åçè¨åºé«çé²è¡äºä¸ç³»åè¨ªè«ãæåçç ç©¶ï¼(i) æ¢è¨äººå·¥æºæ§çæ½åï¼ç¹å¥æ¯æªä¾çãé¡äººé¡ãéç®æ¹æ³ï¼ä»¥ä¿é²å¿é»åè§£è®ä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼ä»¥å (ii) å¾µæ±ä»åå°äººå·¥æºæ§æ¼ç®æ³çå¯è§£éæ§åå¯ä¿¡åº¦ççæ³ãçµæï¼æåå° 23 ä½è¨åºé«ççè¨ªè«è¨éé²è¡äºæ­¸ç´ä¸»é¡åæï¼ä¸¦æ¾åºä»¥ä¸ä¸»é¡ï¼(i) å°ç®åç³»çµ±ç¼ºä¹ä¿¡ä»»ï¼(ii) å°æªä¾äººå·¥æºæ§æç¨åå°éäºæç¨çè¦æ±ææ­£é¢æåº¦ï¼(iii) æ¼ç®æ³çæºç¢ºæ§åå¯è§£éæ§ä¹éçéä¿ï¼ä»¥å (iv) å°æè²ãå¯è½çæè½éåï¼ä»¥åäººå·¥æºæ§å°è¨åºè½åçå½±é¿ççæ³ãè¨è«ï¼è¨åºé«çä¸ä¿¡ä»»ç®åçé»è¦åæ¹æ³ï¼ä½æ­¡è¿æªä¾çãäººå·¥æºæ§ãæè¡ãå¨è¨åºé«çç¸ä¿¡æªä¾ç AI è§£è®æºç¢ºçææ³ä¸ï¼ä»åä¸å¤ªæå¿å®æ¯å¦å¯è§£éãä»åä¹æ¯è¼åæ­¡è½ä»¥è¦è¦ºæ¹å¼åç¾æ¼ç®æ³çµæçå¿é»åè§£è®ãéç¶è¨åºé«çä¸å®³æå¤±æ¥­ï¼ä½ä»åæå¿æè½éåï¼ä»¥åéè¦æè²å¡å·¥è² è²¬ä»»å°ä½¿ç¨äººå·¥æºæ§ãçµè«ï¼è¨åºé«çå°äººå·¥æºæ§å¨è¨åºæ±ºç­å¶å®ä¸­çæªä¾æç¨ææ­£é¢æåº¦ãæºç¢ºæ§æ¯æ¡ç¨äººå·¥æºæ§çä¸åééµå ç´ ï¼èè¦è¦ºåæ¯ç®åçé»è¦åæ¹æ³æ´åéçãéè¢«è¦çºä¸ç¨®æ½å¨çå¹è¨åæåæè½çæ¹æ³ï¼èèªååå¯è½å¸¶ä¾çæè½éåå½¢æå°æ¯ã</paragraph>

##### **50 questions on Active Assisted Living technologies. Global edition**
2410.16733v1 by Francisco Florez-Revuelta, Alin Ake-Kob, Pau Climent-Perez, Paulo Coelho, Liane Colonna, Laila Dahabiyeh, Carina Dantas, Esra Dogru-Huzmeli, Hazim Kemal Ekenel, Aleksandar Jevremovic, Nina Hosseini-Kivanani, Aysegul Ilgaz, Mladjan Jovanovic, Andrzej Klimczuk, Maksymilian M. KuÅºmicz, Petre Lameski, Ferlanda Luna, NatÃ¡lia Machado, Tamara Mujirishvili, Zada Pajalic, Galidiya Petrova, Nathalie G. S. Puaschitz, Maria Jose Santofimia, Agusti Solanas, Wilhelmina van Staalduinen, Ziya Ata Yazici

This booklet on Active Assisted Living (AAL) technologies has been created as
part of the GoodBrother COST Action, which has run from 2020 to 2024. COST
Actions are European research programs that promote collaboration across
borders, uniting researchers, professionals, and institutions to address key
societal challenges. GoodBrother focused on ethical and privacy concerns
surrounding video and audio monitoring in care settings. The aim was to ensure
that while AAL technologies help older adults and vulnerable individuals, their
privacy and data protection rights remain a top priority.
  This booklet is designed to guide you through the role that AAL technologies
play in improving the quality of life for older adults, caregivers, and people
with disabilities. AAL technologies offer tools for those facing cognitive or
physical challenges. They can enhance independence, assist with daily routines,
and promote a safer living environment. However, the rise of these technologies
also brings important questions about data protection and user autonomy.
  This resource is intended for a wide audience, including end users,
caregivers, healthcare professionals, and policymakers. It provides practical
guidance on integrating AAL technologies into care settings while safeguarding
privacy and ensuring ethical use. The insights offered here aim to empower
users and caregivers to make informed choices that enhance both the quality of
care and respect for personal autonomy.

æè¦ï¼éæ¬éæ¼ä¸»åå¼è¼å©çæ´» (AAL) æè¡çå°åå­æ¯ä½çº GoodBrother COST è¡åçä¸é¨åèè£½ä½çï¼è©²è¡åå¾ 2020 å¹´æçºå° 2024 å¹´ãCOST è¡åæ¯æ­æ´²ç ç©¶è¨ç«ï¼æ¨å¨ä¿é²è·¨åçåä½ï¼åçµç ç©¶äººå¡ãå°æ¥­äººå£«åæ©æ§ï¼ä»¥è§£æ±ºä¸»è¦çç¤¾æææ°ãGoodBrother å°æ³¨æ¼ç§è­·ç°å¢ä¸­å½±çåé³è¨ç£æ§çå«çåé±ç§åé¡ãç®çæ¯ç¢ºä¿ AAL æè¡å¨å¹«å©èå¹´äººåå¼±å¢ç¾¤é«çåæï¼ä»åçé±ç§åè³æä¿è­·æ¬å©ä»æ¯é¦è¦èéã
éæ¬å°åå­æ¨å¨å¼å°æ¨äºè§£ AAL æè¡å¨æåèå¹´äººãç§è­·èåæ®ç¾äººå£«ççæ´»åè³ªæ¹é¢ææ®æ¼çè§è²ãAAL æè¡çºé¢å°èªç¥æççææ°çäººæä¾å·¥å·ãå®åå¯ä»¥å¢é²ç¨ç«æ§ãåå©æ¥å¸¸å·¥ä½ä¸¦ä¿é²æ´å®å¨çå±ä½ç°å¢ãç¶èï¼éäºæè¡çèèµ·ä¹å¸¶ä¾äºéæ¼è³æä¿è­·åä½¿ç¨èèªä¸»æ¬çéè¦åé¡ã
éé è³æºé©ç¨æ¼å»£æ³çåç¾ï¼åæ¬æçµä½¿ç¨èãç§è­·èãé«çä¿å¥å°æ¥­äººå¡åæ¿ç­å¶å®èãå®æä¾äºå° AAL æè¡æ´åå°ç§è­·ç°å¢ä¸­çå¯¦ç¨æåï¼åæä¿è­·é±ç§ä¸¦ç¢ºä¿åä¹å«ççä½¿ç¨ãéè£¡æä¾çè¦è§£æ¨å¨è®ä½¿ç¨èåç§è­·èè½å¤ ååºææºçé¸æï¼ä»¥æåç§è­·åè³ªä¸¦å°éåäººèªä¸»æ¬ã

##### **Development of CNN Architectures using Transfer Learning Methods for Medical Image Classification**
2410.16711v1 by Ganga Prasad Basyal, David Zeng, Bhaskar Pm Rimal

The application of deep learning-based architecture has seen a tremendous
rise in recent years. For example, medical image classification using deep
learning achieved breakthrough results. Convolutional Neural Networks (CNNs)
are implemented predominantly in medical image classification and segmentation.
On the other hand, transfer learning has emerged as a prominent supporting tool
for enhancing the efficiency and accuracy of deep learning models. This paper
investigates the development of CNN architectures using transfer learning
techniques in the field of medical image classification using a timeline
mapping model for key image classification challenges. Our findings help make
an informed decision while selecting the optimum and state-of-the-art CNN
architectures.

æè¦ï¼è¿å¹´ä¾ï¼æ·±åº¦å­¸ç¿æ¶æ§çæç¨å·²å¤§å¹å¢å ãä¾å¦ï¼ä½¿ç¨æ·±åº¦å­¸ç¿çé«å­¸å½±ååé¡ç²å¾çªç ´æ§çææãå·ç©ç¥ç¶ç¶²è·¯ (CNN) ä¸»è¦ç¨æ¼é«å­¸å½±ååé¡ååå²ãå¦ä¸æ¹é¢ï¼é·ç§»å­¸ç¿å·²æçºä¸ç¨®éè¦çè¼å©å·¥å·ï¼ç¨æ¼æåæ·±åº¦å­¸ç¿æ¨¡åçæçåæºç¢ºåº¦ãæ¬ææ¢è¨ä½¿ç¨é·ç§»å­¸ç¿æè¡éç¼ CNN æ¶æ§ï¼ä¸¦ä½¿ç¨æéè»¸å°ææ¨¡åè§£æ±ºé«å­¸å½±ååé¡çä¸»è¦ææ°ãæåçç ç©¶çµææå©æ¼å¨é¸ææä½³ä¸æåé²ç CNN æ¶æ§æååºææºçæ±ºç­ã

##### **Privacy-hardened and hallucination-resistant synthetic data generation with logic-solvers**
2410.16705v1 by Mark A. Burgess, Brendan Hosking, Roc Reguant, Anubhav Kaphle, Mitchell J. O'Brien, Letitia M. F. Sng, Yatish Jain, Denis C. Bauer

Machine-generated data is a valuable resource for training Artificial
Intelligence algorithms, evaluating rare workflows, and sharing data under
stricter data legislations. The challenge is to generate data that is accurate
and private. Current statistical and deep learning methods struggle with large
data volumes, are prone to hallucinating scenarios incompatible with reality,
and seldom quantify privacy meaningfully. Here we introduce Genomator, a logic
solving approach (SAT solving), which efficiently produces private and
realistic representations of the original data. We demonstrate the method on
genomic data, which arguably is the most complex and private information.
Synthetic genomes hold great potential for balancing underrepresented
populations in medical research and advancing global data exchange. We
benchmark Genomator against state-of-the-art methodologies (Markov generation,
Restricted Boltzmann Machine, Generative Adversarial Network and Conditional
Restricted Boltzmann Machines), demonstrating an 84-93% accuracy improvement
and 95-98% higher privacy. Genomator is also 1000-1600 times more efficient,
making it the only tested method that scales to whole genomes. We show the
universal trade-off between privacy and accuracy, and use Genomator's tuning
capability to cater to all applications along the spectrum, from provable
private representations of sensitive cohorts, to datasets with
indistinguishable pharmacogenomic profiles. Demonstrating the production-scale
generation of tuneable synthetic data can increase trust and pave the way into
the clinic.

æè¦ï¼æ©å¨ç¢ççè³ææ¯è¨ç·´äººå·¥æºæ§æ¼ç®æ³ãè©ä¼°ç½è¦å·¥ä½æµç¨ï¼ä»¥åå¨å´æ ¼è³ææ³è¦ä¸å±äº«è³æçå¯¶è²´è³æºãææ°å¨æ¼ç¢çæºç¢ºä¸ç§å¯çè³æãç®åççµ±è¨åæ·±åº¦å­¸ç¿æ¹æ³é£ä»¥èçå¤§éè³æï¼å®¹æç¢çèç¾å¯¦ä¸ç¸ç¬¦çå¹»è¦ºå ´æ¯ï¼èä¸å¾å°ææç¾©å°éåé±ç§ãå¨æ­¤æåä»ç´¹ Genomatorï¼ä¸ç¨®éè¼¯æ±è§£æ¹æ³ (SAT æ±è§£)ï¼å¯ææç¢çåå§è³æçç§å¯ä¸çå¯¦çè¡¨ç¤ºãæåå¨åºå çµè³æä¸å±ç¤ºæ­¤æ¹æ³ï¼éå¯ä»¥èªªæ¯è³è¨æè¤éä¸æç§å¯ãåæåºå çµå¨å¹³è¡¡é«å­¸ç ç©¶ä¸­ä»£è¡¨æ§ä¸è¶³çæç¾¤åæ¨é²å¨çè³æäº¤ææ¹é¢å·æå·¨å¤§æ½åãæåå° Genomator èæåé²çæ¹æ³ï¼é¦¬å¯å¤«çæãåéç»ç¾è²æ¼æ©ãçæå°æç¶²è·¯åæ¢ä»¶åéç»ç¾è²æ¼æ©ï¼é²è¡åºæºæ¸¬è©¦ï¼è­ææºç¢ºåº¦æé«äº 84-93%ï¼é±ç§æé«äº 95-98%ãGenomator çæçä¹é«åº 1000-1600 åï¼ä½¿å¶æçºå¯ä¸ç¶éæ¸¬è©¦ä¸å¯æ´å±å°æ´ååºå çµçæ¹æ³ãæåå±ç¤ºäºé±ç§åæºç¢ºæ§ä¹éçæ®éæ¬è¡¡ï¼ä¸¦ä½¿ç¨ Genomator çèª¿æ´åè½ä¾è¿åå¾ææç¾¤é«çå¯è­æç§æè¡¨ç¤ºå°å·æç¡æ³ååçè¥çåºå çµç¹å¾µçè³æéç­æææç¨ãå±ç¤ºå¯èª¿æ´åæè³æççç¢è¦æ¨¡çæï¼å¯ä»¥å¢å ä¿¡ä»»ä¸¦çºé²å¥è¨åºéªå¹³éè·¯ã

##### **AskBeacon -- Performing genomic data exchange and analytics with natural language**
2410.16700v2 by Anuradha Wickramarachchi, Shakila Tonni, Sonali Majumdar, Sarvnaz Karimi, Sulev KÃµks, Brendan Hosking, Jordi Rambla, Natalie A. Twine, Yatish Jain, Denis C. Bauer

Enabling clinicians and researchers to directly interact with global genomic
data resources by removing technological barriers is vital for medical
genomics. AskBeacon enables Large Language Models to be applied to securely
shared cohorts via the GA4GH Beacon protocol. By simply "asking" Beacon,
actionable insights can be gained, analyzed and made publication-ready.

æè¦ï¼è®è¨åºé«çåç ç©¶å¡è½å¤ ééç§»é¤æè¡éç¤ï¼ç´æ¥èå¨çåºå çµæ¸æè³æºäºåï¼å°æ¼é«å­¸åºå çµå­¸è³ééè¦ãAskBeacon è®å¤§åèªè¨æ¨¡åè½å¤ éé GA4GH Beacon åå®æç¨æ¼å®å¨å±äº«çç¾¤çµãåªè¦ãè©¢åãBeaconï¼å°±è½ç²å¾å¯æä½çè¦è§£ãé²è¡åæï¼ä¸¦ä½¿å¶æºåå¥½ç¼å¸ã

##### **Visual Question Answering in Ophthalmology: A Progressive and Practical Perspective**
2410.16662v1 by Xiaolan Chen, Ruoyu Chen, Pusheng Xu, Weiyi Zhang, Xianwen Shang, Mingguang He, Danli Shi

Accurate diagnosis of ophthalmic diseases relies heavily on the
interpretation of multimodal ophthalmic images, a process often time-consuming
and expertise-dependent. Visual Question Answering (VQA) presents a potential
interdisciplinary solution by merging computer vision and natural language
processing to comprehend and respond to queries about medical images. This
review article explores the recent advancements and future prospects of VQA in
ophthalmology from both theoretical and practical perspectives, aiming to
provide eye care professionals with a deeper understanding and tools for
leveraging the underlying models. Additionally, we discuss the promising trend
of large language models (LLM) in enhancing various components of the VQA
framework to adapt to multimodal ophthalmic tasks. Despite the promising
outlook, ophthalmic VQA still faces several challenges, including the scarcity
of annotated multimodal image datasets, the necessity of comprehensive and
unified evaluation methods, and the obstacles to achieving effective real-world
applications. This article highlights these challenges and clarifies future
directions for advancing ophthalmic VQA with LLMs. The development of LLM-based
ophthalmic VQA systems calls for collaborative efforts between medical
professionals and AI experts to overcome existing obstacles and advance the
diagnosis and care of eye diseases.

æè¦ï¼æºç¢ºè¨ºæ·ç¼ç§ç¾çä»°è³´å°å¤æ¨¡æç¼ç§å½±åçè§£è®ï¼éåéç¨éå¸¸èæä¸ä¾è³´å°æ¥­ç¥è­ãè¦è¦ºåç­ï¼VQAï¼çµåé»è¦è¦è¦ºåèªç¶èªè¨èçï¼æä¾äºä¸åæ½å¨çè·¨é åè§£æ±ºæ¹æ¡ï¼ç¨æ¼çè§£ä¸¦åç­æéé«å­¸å½±åççåãéç¯è©è«æç« æ¢è¨äº VQA å¨ç¼ç§é åçææ°é²å±åæªä¾åæ¯ï¼å¾çè«åå¯¦åçè§åº¦åºç¼ï¼æ¨å¨çºç¼ç§ä¿å¥å°æ¥­äººå¡æä¾æ´æ·±å¥ççè§£åå·¥å·ï¼ä»¥å©ç¨åºç¤æ¨¡åãæ­¤å¤ï¼æåè¨è«äºå¤§åèªè¨æ¨¡åï¼LLMï¼å¨å¢å¼· VQA æ¶æ§åç¨®çµæé¨åä»¥é©æå¤æ¨¡æç¼ç§ä»»åä¸­çææè¶¨å¢ãåç®¡åæ¯çå¥½ï¼ç¼ç§ VQA ä»é¢è¨æ¸é ææ°ï¼åæ¬æ¨è¨»å¤æ¨¡æå½±åè³æéçç¨å°æ§ãå¨é¢ä¸çµ±ä¸çè©ä¼°æ¹æ³çå¿è¦æ§ï¼ä»¥åå¯¦ç¾ææå¯¦éæç¨æéå°çéç¤ãæ¬æéé»èªªæäºéäºææ°ï¼ä¸¦éæ¸äºå©ç¨ LLM æ¨åç¼ç§ VQA çæªä¾æ¹åãåºæ¼ LLM çç¼ç§ VQA ç³»çµ±çéç¼éè¦é«å­¸å°æ¥­äººå¡å AI å°å®¶å±ååªåï¼ä»¥åæç¾æéç¤ä¸¦æ¨åç¼ç§ç¾ççè¨ºæ·åç§è­·ã

##### **How Can We Diagnose and Treat Bias in Large Language Models for Clinical Decision-Making?**
2410.16574v1 by Kenza Benkirane, Jackie Kay, Maria Perez-Ortiz

Recent advancements in Large Language Models (LLMs) have positioned them as
powerful tools for clinical decision-making, with rapidly expanding
applications in healthcare. However, concerns about bias remain a significant
challenge in the clinical implementation of LLMs, particularly regarding gender
and ethnicity. This research investigates the evaluation and mitigation of bias
in LLMs applied to complex clinical cases, focusing on gender and ethnicity
biases. We introduce a novel Counterfactual Patient Variations (CPV) dataset
derived from the JAMA Clinical Challenge. Using this dataset, we built a
framework for bias evaluation, employing both Multiple Choice Questions (MCQs)
and corresponding explanations. We explore prompting with eight LLMs and
fine-tuning as debiasing methods. Our findings reveal that addressing social
biases in LLMs requires a multidimensional approach as mitigating gender bias
can occur while introducing ethnicity biases, and that gender bias in LLM
embeddings varies significantly across medical specialities. We demonstrate
that evaluating both MCQ response and explanation processes is crucial, as
correct responses can be based on biased \textit{reasoning}. We provide a
framework for evaluating LLM bias in real-world clinical cases, offer insights
into the complex nature of bias in these models, and present strategies for
bias mitigation.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å·²å°å®åå®ä½çºè¨åºæ±ºç­å¶å®å¼·å¤§çå·¥å·ï¼å¨é«çä¿å¥é åçæç¨è¿éæ´å±ãç¶èï¼éæ¼åè¦çææä»ç¶æ¯ LLM å¨è¨åºå¯¦æ½ä¸­çéå¤§ææ°ï¼ç¹å¥æ¯éæ¼æ§å¥åç¨®æãæ¬ç ç©¶èª¿æ¥äºæç¨æ¼è¤éè¨åºçä¾ç LLM ä¸­åè¦çè©ä¼°åç·©è§£ï¼éé»éæ³¨æ§å¥åç¨®æåè¦ãæåå¼å¥äºä¸åæ°çåäºå¯¦æ£èè®ç° (CPV) æ¸æéï¼è©²æ¸æéæºèª JAMA è¨åºææ°ãä½¿ç¨æ­¤æ¸æéï¼æåå»ºç«äºä¸ååè¦è©ä¼°æ¡æ¶ï¼åææ¡ç¨å¤é¸é¡ (MCQ) åç¸æçè§£éãæåæ¢ç´¢ä½¿ç¨å«å LLM é²è¡æç¤ºï¼ä¸¦å°å¾®èª¿é²è¡å»åæ¹æ³ãæåçç ç©¶çµæè¡¨æï¼è§£æ±º LLM ä¸­çç¤¾æåè¦éè¦å¤ç¶­åº¦çæ¹æ³ï¼å çºå¨å¼å¥ç¨®æåè¦çåæå¯è½ææ¸è¼æ§å¥åè¦ï¼ä¸¦ä¸ LLM åµå¥ä¸­çæ§å¥åè¦å¨ååé«çå°æ¥­é åå­å¨é¡¯èå·®ç°ãæåè­æäºè©ä¼° MCQ é¿æåè§£ééç¨è³ééè¦ï¼å çºæ­£ç¢ºçé¿æå¯è½åºæ¼æåè¦ç\textit{æ¨ç}ãæåæä¾äºä¸åç¨æ¼è©ä¼° LLM å¨ç¾å¯¦ä¸çè¨åºçä¾ä¸­çåè¦çæ¡æ¶ï¼æ·±å¥äºè§£éäºæ¨¡åä¸­åè¦çè¤éæ§ï¼ä¸¦æåºç·©è§£åè¦çç­ç¥ã

##### **Large language models enabled multiagent ensemble method for efficient EHR data labeling**
2410.16543v1 by Jingwei Huang, Kuroush Nezafati, Ismael Villanueva-Miranda, Zifan Gu, Ann Marie Navar, Tingyi Wanyan, Qin Zhou, Bo Yao, Ruichen Rong, Xiaowei Zhan, Guanghua Xiao, Eric D. Peterson, Donghan M. Yang, Yang Xie

This study introduces a novel multiagent ensemble method powered by LLMs to
address a key challenge in ML - data labeling, particularly in large-scale EHR
datasets. Manual labeling of such datasets requires domain expertise and is
labor-intensive, time-consuming, expensive, and error-prone. To overcome this
bottleneck, we developed an ensemble LLMs method and demonstrated its
effectiveness in two real-world tasks: (1) labeling a large-scale unlabeled ECG
dataset in MIMIC-IV; (2) identifying social determinants of health (SDOH) from
the clinical notes of EHR. Trading off benefits and cost, we selected a pool of
diverse open source LLMs with satisfactory performance. We treat each LLM's
prediction as a vote and apply a mechanism of majority voting with minimal
winning threshold for ensemble. We implemented an ensemble LLMs application for
EHR data labeling tasks. By using the ensemble LLMs and natural language
processing, we labeled MIMIC-IV ECG dataset of 623,566 ECG reports with an
estimated accuracy of 98.2%. We applied the ensemble LLMs method to identify
SDOH from social history sections of 1,405 EHR clinical notes, also achieving
competitive performance. Our experiments show that the ensemble LLMs can
outperform individual LLM even the best commercial one, and the method reduces
hallucination errors. From the research, we found that (1) the ensemble LLMs
method significantly reduces the time and effort required for labeling
large-scale EHR data, automating the process with high accuracy and quality;
(2) the method generalizes well to other text data labeling tasks, as shown by
its application to SDOH identification; (3) the ensemble of a group of diverse
LLMs can outperform or match the performance of the best individual LLM; and
(4) the ensemble method substantially reduces hallucination errors. This
approach provides a scalable and efficient solution to data-labeling
challenges.

æè¦ï¼æ¬ç ç©¶æ¨åºäºä¸ç¨®ç± LLM æä¾æ¯æ´çæ°åå¤ä»£çäººéææ¹æ³ï¼ä»¥æå°æ©å¨å­¸ç¿ä¸­çä¸é ééµææ° - è³ææ¨è¨ï¼ç¹å¥æ¯å¨å¤§è¦æ¨¡ EHR è³æéä¸­ãæ­¤é¡è³æéçæåæ¨è¨éè¦é åå°æ¥­ç¥è­ï¼ä¸åååå¯éãèæãæè²´ä¸å®¹æåºé¯ãçºäºåæéåç¶é ¸ï¼æåéç¼äºä¸ç¨®éæ LLM æ¹æ³ï¼ä¸¦å¨å©åå¯¦éä»»åä¸­è­æäºå¶æææ§ï¼(1) æ¨è¨ MIMIC-IV ä¸­ä¸åå¤§è¦æ¨¡æªæ¨è¨ç ECG è³æéï¼(2) å¾ EHR çè¨åºè¨»è¨ä¸­è­å¥å¥åº·çç¤¾ææ±ºå®å ç´  (SDOH)ãå¨æ¬è¡¡æ¶çåææ¬å¾ï¼æåé¸æäºä¸çµå·æä»¤äººæ»¿ææè½çå¤åéæ¾åå§ç¢¼ LLMãæåå°æ¯å LLM çé æ¸¬è¦çºä¸ç¥¨ï¼ä¸¦æç¨å¤æ¸æ±ºæ©å¶ï¼ä¸¦è¨­å®æä½ç²åéæª»é²è¡éæãæåå¯¦ä½äºä¸åéæ LLM æç¨ç¨å¼ï¼ç¨æ¼ EHR è³ææ¨è¨ä»»åãééä½¿ç¨éæ LLM åèªç¶èªè¨èçï¼æåæ¨è¨äº MIMIC-IV ECG è³æéï¼å¶ä¸­åå« 623,566 ä»½ ECG å ±åï¼é ä¼°æºç¢ºåº¦çº 98.2%ãæåæç¨éæ LLM æ¹æ³å¾ 1,405 ä»½ EHR è¨åºè¨»è¨çç¤¾æçå²é¨åè­å¥ SDOHï¼ä¹ç²å¾äºå·æç«¶ç­åçæè½ãæåçå¯¦é©é¡¯ç¤ºï¼éæ LLM å¯ä»¥åªæ¼åå¥ LLMï¼å³ä½¿æ¯æå¥½çåæ¥­ LLMï¼èä¸æ­¤æ¹æ³æ¸å°äºå¹»è¦ºé¯èª¤ãå¾ç ç©¶ä¸­ï¼æåç¼ç¾ (1) éæ LLM æ¹æ³å¤§å¹æ¸å°æ¨è¨å¤§è¦æ¨¡ EHR è³ææéçæéåç²¾åï¼ä»¥é«æºç¢ºåº¦ååè³ªèªååæ­¤ç¨åºï¼(2) æ­¤æ¹æ³å¯ä»¥å¾å¥½å°æ¦æ¬å°å¶ä»æå­è³ææ¨è¨ä»»åï¼å¦å¶å¨ SDOH è­å¥ä¸­çæç¨æç¤ºï¼(3) ä¸çµå¤å LLM çéæå¯ä»¥åªæ¼æéå°æä½³åå¥ LLM çæè½ï¼ä»¥å (4) éææ¹æ³å¤§å¹æ¸å°äºå¹»è¦ºé¯èª¤ãæ­¤æ¹æ³çºè³ææ¨è¨ææ°æä¾äºå¯æ´åä¸ææççè§£æ±ºæ¹æ¡ã

##### **AEPL: Automated and Editable Prompt Learning for Brain Tumor Segmentation**
2410.19847v1 by Yongheng Sun, Mingxia Liu, Chunfeng Lian

Brain tumor segmentation is crucial for accurate diagnosisand treatment
planning, but the small size and irregular shapeof tumors pose significant
challenges. Existing methods of-ten fail to effectively incorporate medical
domain knowledgesuch as tumor grade, which correlates with tumor
aggres-siveness and morphology, providing critical insights for moreaccurate
detection of tumor subregions during segmentation.We propose an Automated and
Editable Prompt Learning(AEPL) framework that integrates tumor grade into the
seg-mentation process by combining multi-task learning andprompt learning with
automatic and editable prompt gen-eration. Specifically, AEPL employs an
encoder to extractimage features for both tumor-grade prediction and
segmen-tation mask generation. The predicted tumor grades serveas
auto-generated prompts, guiding the decoder to produceprecise segmentation
masks. This eliminates the need formanual prompts while allowing clinicians to
manually editthe auto-generated prompts to fine-tune the segmentation,enhancing
both flexibility and precision. The proposed AEPLachieves state-of-the-art
performance on the BraTS 2018dataset, demonstrating its effectiveness and
clinical potential.The source code can be accessed online.

æè¦ï¼è¦ç¤åå²å°æ¼æºç¢ºçè¨ºæ·åæ²»çè¨ç«è³ééè¦ï¼ä½è«ç¤çé«ç©å°ä¸å½¢çä¸è¦åï¼å æ­¤æ§æéå¤§çææ°ãç¾æçæ¹æ³å¾å¾ç¡æ³ææå°æ´åé«å­¸é åçç¥è­ï¼ä¾å¦è«ç¤åç´ï¼éèè«ç¤çæ¡æ§åº¦åå½¢æç¸éï¼å¨åå²éç¨ä¸­æä¾ééµè¦è§£ï¼ä»¥æ´æºç¢ºå°åµæ¸¬è«ç¤çå­ååãæåæåºä¸åèªåä¸å¯ç·¨è¼¯çæç¤ºå­¸ç¿ (AEPL) æ¶æ§ï¼ééçµåå¤ä»»åå­¸ç¿åæç¤ºå­¸ç¿ï¼ä»¥åèªåä¸å¯ç·¨è¼¯çæç¤ºç¢çï¼å°è«ç¤åç´æ´åå°åå²éç¨ä¸­ãå·é«ä¾èªªï¼AEPL ä½¿ç¨ç·¨ç¢¼å¨ä¾èåå½±åç¹å¾µï¼ä»¥é²è¡è«ç¤åç´é æ¸¬ååå²é®ç½©ç¢çãé æ¸¬çè«ç¤åç´ç¨ä½èªåç¢ççæç¤ºï¼å¼å°è§£ç¢¼å¨ç¢çç²¾ç¢ºçåå²é®ç½©ãéæ¶é¤äºæåæç¤ºçéæ±ï¼åæåè¨±è¨åºé«çæåç·¨è¼¯èªåç¢ççæç¤ºï¼ä»¥å¾®èª¿åå²ï¼é²èæåå½æ§åæºç¢ºåº¦ãææåºç AEPL å¨ BraTS 2018 è³æéä¸éææåé²çæè½ï¼è­æå¶æææ§åè¨åºæ½åãåå§ç¨å¼ç¢¼å¯ä»¥å¨ç·ä¸åå¾ã

##### **Teach Multimodal LLMs to Comprehend Electrocardiographic Images**
2410.19008v1 by Ruoqi Liu, Yuelin Bai, Xiang Yue, Ping Zhang

The electrocardiogram (ECG) is an essential non-invasive diagnostic tool for
assessing cardiac conditions. Existing automatic interpretation methods suffer
from limited generalizability, focusing on a narrow range of cardiac
conditions, and typically depend on raw physiological signals, which may not be
readily available in resource-limited settings where only printed or digital
ECG images are accessible. Recent advancements in multimodal large language
models (MLLMs) present promising opportunities for addressing these challenges.
However, the application of MLLMs to ECG image interpretation remains
challenging due to the lack of instruction tuning datasets and well-established
ECG image benchmarks for quantitative evaluation. To address these challenges,
we introduce ECGInstruct, a comprehensive ECG image instruction tuning dataset
of over one million samples, covering a wide range of ECG-related tasks from
diverse data sources. Using ECGInstruct, we develop PULSE, an MLLM tailored for
ECG image comprehension. In addition, we curate ECGBench, a new evaluation
benchmark covering four key ECG image interpretation tasks across nine
different datasets. Our experiments show that PULSE sets a new
state-of-the-art, outperforming general MLLMs with an average accuracy
improvement of 15% to 30%. This work highlights the potential of PULSE to
enhance ECG interpretation in clinical practice.

æè¦ï¼å¿é»å (ECG) æ¯ä¸ç¨®è©ä¼°å¿èçæ³çåºæ¬éä¾µå¥å¼è¨ºæ·å·¥å·ãç¾æçèªåè§£è®æ¹æ³æ®éæ§æéï¼å°æ³¨æ¼ç¹çªçå¿èçæ³ç¯åï¼ä¸éå¸¸ä¾è³´åå§ççè¨èï¼éå¨åè½åå¾å°å·ææ¸ä½ ECG å½±åçè³æºæéçç°å¢ä¸­å¯è½ç¡æ³è¼æåå¾ãå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) çææ°é²å±çºäºè§£æ±ºéäºææ°æä¾äºçµä½³çæ©æãç¶èï¼ç±æ¼ç¼ºä¹æä»¤èª¿æ´è³æéåå®åç ECG å½±ååºæºï¼å° MLLM æç¨æ¼ ECG å½±åè§£è®ä»ç¶å·æææ°æ§ãçºäºæå°éäºææ°ï¼æåå¼å¥äº ECGInstructï¼éæ¯ä¸åå¨é¢ç ECG å½±åæä»¤èª¿æ´è³æéï¼åå«è¶éä¸ç¾è¬åæ¨£æ¬ï¼æ¶µèä¾èªä¸åè³æä¾æºçåç¨® ECG ç¸éä»»åãä½¿ç¨ ECGInstructï¼æåéç¼äº PULSEï¼ä¸ç¨®å°çº ECG å½±åçè§£éèº«æé ç MLLMãæ­¤å¤ï¼æåç­åäº ECGBenchï¼éæ¯ä¸åæ°çè©ä¼°åºæºï¼æ¶µèä¹åä¸åè³æéä¸­çåé ééµ ECG å½±åè§£è®ä»»åãæåçå¯¦é©é¡¯ç¤ºï¼PULSE åµä¸äºæ°çæè¡æ°´æºï¼åªæ¼ä¸è¬ MLLMï¼å¹³åæºç¢ºåº¦æåäº 15% è³ 30%ãéé å·¥ä½çªé¡¯äº PULSE å¨è¨åºå¯¦åä¸­å¢å¼· ECG è§£è®çæ½åã

##### **R2Gen-Mamba: A Selective State Space Model for Radiology Report Generation**
2410.18135v1 by Yongheng Sun, Yueh Z. Lee, Genevieve A. Woodard, Hongtu Zhu, Chunfeng Lian, Mingxia Liu

Radiology report generation is crucial in medical imaging,but the manual
annotation process by physicians is time-consuming and labor-intensive,
necessitating the develop-ment of automatic report generation methods.
Existingresearch predominantly utilizes Transformers to generateradiology
reports, which can be computationally intensive,limiting their use in real
applications. In this work, we presentR2Gen-Mamba, a novel automatic radiology
report genera-tion method that leverages the efficient sequence processingof
the Mamba with the contextual benefits of Transformerarchitectures. Due to
lower computational complexity ofMamba, R2Gen-Mamba not only enhances training
and in-ference efficiency but also produces high-quality reports.Experimental
results on two benchmark datasets with morethan 210,000 X-ray image-report
pairs demonstrate the ef-fectiveness of R2Gen-Mamba regarding report quality
andcomputational efficiency compared with several state-of-the-art methods. The
source code can be accessed online.

æè¦ï¼æ¾å°ç§å ±åçæå¨é«å­¸å½±åä¸­è³ééè¦ï¼ä½é«å¸«æåæ¨è¨»çç¨åºèæä¸è²»åï¼å æ­¤æå¿è¦éç¼èªåå ±åçææ¹æ³ãç¾æç ç©¶ä¸»è¦å©ç¨ Transformer ä¾ç¢çæ¾å°ç§å ±åï¼éå¨éç®ä¸å¯è½å¾å¯éï¼éå¶äºå®åå¨å¯¦éæç¨ä¸­çä½¿ç¨ãå¨éé å·¥ä½ä¸­ï¼æåæåº R2Gen-Mambaï¼éæ¯ä¸ç¨®æ°ç©çèªåæ¾å°ç§å ±åçææ¹æ³ï¼å®å©ç¨ Mamba çé«æåºåèçå Transformer æ¶æ§çä¸ä¸æåªå¢ãç±æ¼ Mamba çéç®è¤éåº¦è¼ä½ï¼R2Gen-Mamba ä¸åæé«äºè¨ç·´åæ¨è«æçï¼èä¸ç¢çäºé«åè³ªçå ±åãå¨å©ååºæºè³æéä¸çå¯¦é©çµæï¼åå«è¶é 210,000 å¼µ X åå½±åå ±åå°ï¼è­æäº R2Gen-Mamba å¨å ±ååè³ªåéç®æçæ¹é¢çæææ§ï¼åªæ¼å¤ç¨®æåé²çæ¹æ³ãåå§ç¢¼å¯ä»¥å¨ç·ä¸åå¾ã

##### **MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays, ECGs, and Diagnostic Report**
2410.16239v2 by Samrajya Thapa, Koushik Howlader, Subhankar Bhattacharjee, Wei le

In this paper, we introduce a novel Multi-Modal Contrastive Pre-training
Framework that synergistically combines X-rays, electrocardiograms (ECGs), and
radiology/cardiology reports. Our approach leverages transformers to encode
these diverse modalities into a unified representation space, aiming to enhance
diagnostic accuracy and facilitate comprehensive patient assessments. We
utilize LoRA-Peft to significantly reduce trainable parameters in the LLM and
incorporate recent linear attention dropping strategy in the Vision
Transformer(ViT) for smoother attention. Furthermore, we provide novel
multimodal attention explanations and retrieval for our model. To the best of
our knowledge, we are the first to propose an integrated model that combines
X-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing
contrastive loss, MoRE effectively aligns modality-specific features into a
coherent embedding, which supports various downstream tasks such as zero-shot
classification and multimodal retrieval. Employing our proposed methodology, we
achieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and
PtbXl downstream datasets, surpassing existing multimodal approaches. Our
proposed framework shows significant improvements in capturing intricate
inter-modal relationships and its robustness in medical diagnosis that
establishes a framework for future research in multimodal learning in the
healthcare sector.

æè¦ï¼å¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åæ°ç©çå¤æ¨¡æå°æ¯é è¨ç·´æ¡æ¶ï¼è©²æ¡æ¶ååçµåäº X å°ç·ãå¿é»å (ECG) åæ¾å°å­¸/å¿èçå­¸å ±åãæåçåæ³å©ç¨Transformerå°éäºä¸åçæ¨¡æç·¨ç¢¼æä¸åçµ±ä¸çè¡¨ç¤ºç©ºéï¼æ¨å¨æé«è¨ºæ·æºç¢ºæ§ä¸¦ä¿é²å¨é¢çæ£èè©ä¼°ãæåå©ç¨ LoRA-Peft ä¾é¡¯èæ¸å° LLM ä¸­å¯è¨ç·´çåæ¸ï¼ä¸¦å¨ Vision Transformer (ViT) ä¸­ç´å¥æè¿çç·æ§æ³¨æåä¸æ£ç­ç¥ä»¥ç²å¾æ´æµæ¢çæ³¨æåãæ­¤å¤ï¼æåçºæåçæ¨¡åæä¾äºæ°ç©çå¤æ¨¡ææ³¨æåè§£éåæª¢ç´¢ãææåæç¥ï¼æåæ¯ç¬¬ä¸åæåºçµå X å°ç·ãECG åæ¾å°å­¸/å¿èçå­¸å ±åçæ´åæ¨¡åçäººãééå©ç¨å°æ¯æå¤±ï¼MoRE ææå°å°ç¹å®æ¼æ¨¡æçç¹å¾µå°é½å°ä¸åé£è²«çåµå¥ä¸­ï¼éæ¯æåç¨®ä¸æ¸¸ä»»åï¼ä¾å¦é¶æ¬¡åé¡åå¤æ¨¡ææª¢ç´¢ãæ¡ç¨æåæåºçæ¹æ³ï¼æåå¨ Mimic-IVãCheXpertãEdema Severity å PtbXl ä¸æ¸¸æ¸æéä¸éå°äºæåé² (SOTA)ï¼è¶è¶äºç¾æçå¤æ¨¡ææ¹æ³ãæåæåºçæ¡æ¶å¨ææè¤éçæ¨¡ééä¿åå¶å¨é«çè¨ºæ·ä¸­çé­¯æ£æ§æ¹é¢é¡¯ç¤ºåºé¡¯èçæ¹é²ï¼éçºé«çä¿å¥é¨éçå¤æ¨¡æå­¸ç¿çæªä¾ç ç©¶å»ºç«äºä¸åæ¡æ¶ã

##### **On Creating an English-Thai Code-switched Machine Translation in Medical Domain**
2410.16221v1 by Parinthapat Pengpun, Krittamate Tiankanon, Amrest Chinkamol, Jiramet Kinchagawat, Pitchaya Chairuengjitjaras, Pasit Supholkhan, Pubordee Aussavavirojekul, Chiraphat Boonnag, Kanyakorn Veerakanjana, Hirunkul Phimsiri, Boonthicha Sae-jia, Nattawach Sataudom, Piyalitt Ittichaiwong, Peerat Limkonchotiwat

Machine translation (MT) in the medical domain plays a pivotal role in
enhancing healthcare quality and disseminating medical knowledge. Despite
advancements in English-Thai MT technology, common MT approaches often
underperform in the medical field due to their inability to precisely translate
medical terminologies. Our research prioritizes not merely improving
translation accuracy but also maintaining medical terminology in English within
the translated text through code-switched (CS) translation. We developed a
method to produce CS medical translation data, fine-tuned a CS translation
model with this data, and evaluated its performance against strong baselines,
such as Google Neural Machine Translation (NMT) and GPT-3.5/GPT-4. Our model
demonstrated competitive performance in automatic metrics and was highly
favored in human preference evaluations. Our evaluation result also shows that
medical professionals significantly prefer CS translations that maintain
critical English terms accurately, even if it slightly compromises fluency. Our
code and test set are publicly available
https://github.com/preceptorai-org/NLLB_CS_EM_NLP2024.

æè¦ï¼æ©å¨ç¿»è­¯ (MT) å¨é«å­¸é åæ®æ¼èééµè§è²ï¼è½æåé«çä¿å¥åè³ªä¸¦å³æ­é«å­¸ç¥è­ãåç®¡è±æ³°æ©å¨ç¿»è­¯æè¡å·²æé²å±ï¼ä½å¸¸è¦çæ©å¨ç¿»è­¯æ¹æ³å¨é«å­¸é åå¾å¾è¡¨ç¾ä¸ä½³ï¼å çºå®åç¡æ³ç²¾ç¢ºç¿»è­¯é«å­¸è¡èªãæåçç ç©¶ä¸ååªåæ¹åç¿»è­¯æºç¢ºåº¦ï¼ä¹ééä»£ç¢¼è½æ (CS) ç¿»è­¯ï¼å¨ç¿»è­¯å¾çæå­ä¸­ä¿çè±æé«å­¸è¡èªãæåéç¼äºä¸ç¨®ç¢ç CS é«å­¸ç¿»è­¯è³æçæ¹æ³ï¼ä¸¦ä½¿ç¨éäºè³æå¾®èª¿ CS ç¿»è­¯æ¨¡åï¼ä¸¦éå° Google ç¥ç¶æ©å¨ç¿»è­¯ (NMT) å GPT-3.5/GPT-4 ç­å¼·å¤§çåºæºé²è¡è©ä¼°ãæåçæ¨¡åå¨èªååææ¨ä¸­å±ç¾åºç«¶ç­åï¼ä¸å¨äººé¡åå¥½è©ä¼°ä¸­ååéçãæåçè©ä¼°çµæä¹é¡¯ç¤ºï¼å³ä½¿æç¨å¾®å½±é¿æµæ¢åº¦ï¼é«å­¸å°æ¥­äººå¡ä¹é¡¯èåå¥½è½ç²¾ç¢ºä¿çééµè±æè¡èªç CS ç¿»è­¯ãæåçç¨å¼ç¢¼åæ¸¬è©¦éå·²å¬é https://github.com/preceptorai-org/NLLB_CS_EM_NLP2024ã

##### **GenAI Assisting Medical Training**
2410.16164v1 by Stefan Fritsch, Matthias Tschoepe, Vitor Fortes Rey, Lars Krupp, Agnes Gruenerbl, Eloise Monger, Sarah Travenna

Medical procedures such as venipuncture and cannulation are essential for
nurses and require precise skills. Learning this skill, in turn, is a challenge
for educators due to the number of teachers per class and the complexity of the
task. The study aims to help students with skill acquisition and alleviate the
educator's workload by integrating generative AI methods to provide real-time
feedback on medical procedures such as venipuncture and cannulation.

æè¦ï¼éèç©¿åºåæç®¡ç­é«çç¨åºå°è­·å£«ä¾èªªè³ééè¦ï¼éè¦ç²¾ç¢ºçæè¡ãåéä¾ï¼å­¸ç¿éé æè½å°æè²èä¾èªªæ¯ä¸åææ°ï¼å çºæ¯ç­çæå¸«äººæ¸åä»»åçè¤éæ§ãè©²ç ç©¶æ¨å¨ééæ´åçæå¼ AI æ¹æ³ä¾å¹«å©å­¸çç¿å¾æè½ä¸¦æ¸è¼æè²èçå·¥ä½è² æï¼å¾èå°éèç©¿åºåæç®¡ç­é«çç¨åºæä¾å¯¦æåé¥ã

##### **Fine-Tuning LLMs for Reliable Medical Question-Answering Services**
2410.16088v1 by Ali Anaissi, Ali Braytee, Junaid Akram

We present an advanced approach to medical question-answering (QA) services,
using fine-tuned Large Language Models (LLMs) to improve the accuracy and
reliability of healthcare information. Our study focuses on optimizing models
like LLaMA-2 and Mistral, which have shown great promise in delivering precise,
reliable medical answers. By leveraging comprehensive datasets, we applied
fine-tuning techniques such as rsDoRA+ and ReRAG. rsDoRA+ enhances model
performance through a combination of decomposed model weights, varied learning
rates for low-rank matrices, and rank stabilization, leading to improved
efficiency. ReRAG, which integrates retrieval on demand and question rewriting,
further refines the accuracy of the responses. This approach enables healthcare
providers to access fast, dependable information, aiding in more efficient
decision-making and fostering greater patient trust. Our work highlights the
potential of fine-tuned LLMs to significantly improve the quality and
accessibility of medical information services, ultimately contributing to
better healthcare outcomes for all.

æè¦ï¼æåæåºäºä¸ç¨®åé²çé«çåç­ (QA) æåæ¹æ³ï¼
ä½¿ç¨å¾®èª¿éçå¤§åèªè¨æ¨¡å (LLM) ä¾æé«é«çä¿å¥è³è¨çæºç¢ºæ§å
å¯é æ§ãæåçç ç©¶å°æ³¨æ¼åªåæ¨¡åï¼ä¾å¦ LLaMA-2 å Mistralï¼éäºæ¨¡åå¨æä¾ç²¾ç¢ºã
å¯é çé«çç­æ¡æ¹é¢å·²å±ç¾åºå·¨å¤§çåæ¯ãééå©ç¨å¨é¢çè³æéï¼æåæç¨
äºå¾®èª¿æè¡ï¼ä¾å¦ rsDoRA+ å ReRAGãrsDoRA+ ééåè§£æ¨¡åæ¬éãéå°ä½éç©é£ä½¿ç¨ä¸åçå­¸ç¿
çï¼ä»¥åç§©ç©©å®åä¾å¢å¼·æ¨¡åæè½ï¼å¾èæé«æçãReRAG æ´åäºä¾éæ±æª¢ç´¢ååé¡éå¯«ï¼
é²ä¸æ­¥ç²¾çäºåæçæºç¢ºæ§ãæ­¤æ¹æ³è®é«çä¿å¥æä¾èè½å¤ å­åå¿«éãå¯é çè³è¨ï¼åå©æ´ææçå°é²è¡
æ±ºç­å¶å®ä¸¦å¢é²çæ£çä¿¡ä»»ãæåçç ç©¶éé»èªªæäºå¾®èª¿ LLM çæ½åï¼è½å¤§å¹æ¹åé«çè³è¨æåçåè³ªå
å¯è¿æ§ï¼æçµçºææäººå¸¶ä¾æ´å¥½çé«çä¿å¥ææã

##### **1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and Large Language Models for Medical Text Classification**
2410.15998v1 by Ram Mohan Rao Kadiyala, M. V. P. Chandra Sekhara Rao

Social media is a great source of data for users reporting information and
regarding their health and how various things have had an effect on them. This
paper presents various approaches using Transformers and Large Language Models
and their ensembles, their performance along with advantages and drawbacks for
various tasks of SMM4H'24 - Classifying texts on impact of nature and outdoor
spaces on the author's mental health (Task 3), Binary classification of tweets
reporting their children's health disorders like Asthma, Autism, ADHD and
Speech disorder (task 5), Binary classification of users self-reporting their
age (task 6).

æè¦ï¼ç¤¾ç¾¤åªé«æ¯ä½¿ç¨èåå ±è³è¨ççµä½³è³æä¾æºï¼éæ¼ä»åçå¥åº·ä»¥ååç¨®äºç©å°ä»åçå½±é¿ãæ¬ææåºåç¨®ä½¿ç¨ Transformer åå¤§åèªè¨æ¨¡ååå¶åå¥çæ¹æ³ï¼ä»¥åå®åå¨ SMM4H'24 åç¨®ä»»åä¸­çè¡¨ç¾ï¼ä»¥ååªç¼ºé» - åé¡å½±é¿ä½èå¿çå¥åº·çèªç¶åæ¶å¤ç©ºéææ¬ï¼ä»»å 3ï¼ï¼åå ±å¶åç«¥å¥åº·éç¤ï¼ä¾å¦æ°£åãèªéçãæ³¨æåä¸è¶³éåçåè¨èªéç¤ï¼çæ¨æäºååé¡ï¼ä»»å 5ï¼ï¼ä½¿ç¨èèªè¡åå ±å¶å¹´é½¡çäºååé¡ï¼ä»»å 6ï¼ã

##### **Random Token Fusion for Multi-View Medical Diagnosis**
2410.15847v1 by Jingyu Guo, Christos Matsoukas, Fredrik Strand, Kevin Smith

In multi-view medical diagnosis, deep learning-based models often fuse
information from different imaging perspectives to improve diagnostic
performance. However, existing approaches are prone to overfitting and rely
heavily on view-specific features, which can lead to trivial solutions. In this
work, we introduce Random Token Fusion (RTF), a novel technique designed to
enhance multi-view medical image analysis using vision transformers. By
integrating randomness into the feature fusion process during training, RTF
addresses the issue of overfitting and enhances the robustness and accuracy of
diagnostic models without incurring any additional cost at inference. We
validate our approach on standard mammography and chest X-ray benchmark
datasets. Through extensive experiments, we demonstrate that RTF consistently
improves the performance of existing fusion methods, paving the way for a new
generation of multi-view medical foundation models.

æè¦ï¼å¨å¤è¦åé«çè¨ºæ·ä¸­ï¼åºæ¼æ·±åº¦å­¸ç¿çæ¨¡åéå¸¸èåä¾èªä¸åå½±åè¦è§çè³è¨ï¼ä»¥æåè¨ºæ·æè½ãç¶èï¼ç¾ææ¹æ³å®¹æéåº¦æ¬åï¼ä¸¦éåº¦ä¾è³´ç¹å®è¦è§çç¹å¾µï¼éå¯è½å°è´ç£ç¢çè§£æ±ºæ¹æ¡ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºé¨æ©ç¹å¾µèå (RTF)ï¼éæ¯ä¸ç¨®æ°æè¡ï¼æ¨å¨ä½¿ç¨è¦è¦ºè½æå¨å¢å¼·å¤è¦åé«çå½±ååæãééå¨è¨ç·´æéå°é¨æ©æ§æ´åå°ç¹å¾µèåéç¨ä¸­ï¼RTF è§£æ±ºäºéåº¦æ¬åçåé¡ï¼ä¸¦å¢å¼·äºè¨ºæ·æ¨¡åçç©©å¥æ§åæºç¢ºæ§ï¼èä¸æå¨æ¨è«ä¸­ç¢çä»»ä½é¡å¤çææ¬ãæåå¨æ¨æºä¹³æ¿æå½±åè¸é¨ X ååºæºè³æéä¸é©è­äºæåçæ¹æ³ãééå»£æ³çå¯¦é©ï¼æåè­æ RTF æçºæ¹åç¾æèåæ¹æ³çæè½ï¼çºæ°ä¸ä»£å¤è¦åé«çåºç¤æ¨¡åéªå¹³äºéè·¯ã

##### **MAC Revivo: Artificial Intelligence Paves the Way**
2410.15820v1 by Jinzhe Pan, Jingqing Wang, Zelin Yun, Zhiyong Xiao, Yuehui Ouyang, Wenchi Cheng, Wei Zhang

The vast adoption of Wi-Fi and/or Bluetooth capabilities in Internet of
Things (IoT) devices, along with the rapid growth of deployed smart devices,
has caused significant interference and congestion in the industrial,
scientific, and medical (ISM) bands. Traditional Wi-Fi Medium Access Control
(MAC) design faces significant challenges in managing increasingly complex
wireless environments while ensuring network Quality of Service (QoS)
performance. This paper explores the potential integration of advanced
Artificial Intelligence (AI) methods into the design of Wi-Fi MAC protocols. We
propose AI-MAC, an innovative approach that employs machine learning algorithms
to dynamically adapt to changing network conditions, optimize channel access,
mitigate interference, and ensure deterministic latency. By intelligently
predicting and managing interference, AI-MAC aims to provide a robust solution
for next generation of Wi-Fi networks, enabling seamless connectivity and
enhanced QoS. Our experimental results demonstrate that AI-MAC significantly
reduces both interference and latency, paving the way for more reliable and
efficient wireless communications in the increasingly crowded ISM band.

æè¦ï¼é¨èç©è¯ç¶² (IoT) è£ç½®å»£æ³æ¡ç¨ Wi-Fi å/æèçåè½ï¼å ä¸é¨ç½²çæºæ§è£ç½®å¿«éæé·ï¼å·²å°å·¥æ¥­ãç§å­¸åé«ç (ISM) é »æ®µé æé¡¯èçå¹²æ¾åå£å¡ãå³çµ±ç Wi-Fi åªé«å­åæ§å¶ (MAC) è¨­è¨å¨ç®¡çæ¥çè¤éçç¡ç·ç°å¢æé¢è¨éå¤§ææ°ï¼åæéè¦ç¢ºä¿ç¶²è·¯æååè³ª (QoS) æè½ãæ¬ææ¢è¨å°åé²äººå·¥æºæ§ (AI) æ¹æ³æ´åè³ Wi-Fi MAC åå®çè¨­è¨ä¸­æå·æçæ½åãæåæåº AI-MACï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼æ¡ç¨æ©å¨å­¸ç¿æ¼ç®æ³åæé©æè®åçç¶²è·¯çæ³ãæä½³åé »éå­åãæ¸è¼å¹²æ¾ï¼ä¸¦ç¢ºä¿ç¢ºå®æ§å»¶é²ãééæºæ§é æ¸¬åç®¡çå¹²æ¾ï¼AI-MAC æ¨å¨çºä¸ä¸ä»£ Wi-Fi ç¶²è·¯æä¾ç©©å¥çè§£æ±ºæ¹æ¡ï¼å¯¦ç¾ç¡ç¸«é£ç·åå¢å¼·ç QoSãæåçå¯¦é©çµæè­æï¼AI-MAC å¤§å¹éä½äºå¹²æ¾åå»¶é²ï¼çºæ¥çå£å¡ç ISM é »æ®µä¸­æ´å¯é ä¸æ´ææççç¡ç·éè¨éªè·¯ã

##### **Unleashing the Potential of Vision-Language Pre-Training for 3D Zero-Shot Lesion Segmentation via Mask-Attribute Alignment**
2410.15744v1 by Yankai Jiang, Wenhui Lei, Xiaofan Zhang, Shaoting Zhang

Recent advancements in medical vision-language pre-training models have
driven significant progress in zero-shot disease recognition. However,
transferring image-level knowledge to pixel-level tasks, such as lesion
segmentation in 3D CT scans, remains a critical challenge. Due to the
complexity and variability of pathological visual characteristics, existing
methods struggle to align fine-grained lesion features not encountered during
training with disease-related textual representations. In this paper, we
present Malenia, a novel multi-scale lesion-level mask-attribute alignment
framework, specifically designed for 3D zero-shot lesion segmentation. Malenia
improves the compatibility between mask representations and their associated
elemental attributes, explicitly linking the visual features of unseen lesions
with the extensible knowledge learned from previously seen ones. Furthermore,
we design a Cross-Modal Knowledge Injection module to enhance both visual and
textual features with mutually beneficial information, effectively guiding the
generation of segmentation results. Comprehensive experiments across three
datasets and 12 lesion categories validate the superior performance of Malenia.
Codes will be publicly available.

æè¦ï¼è¿ä¾å¨é«å­¸è¦è¦ºèªè¨é è¨ç·´æ¨¡åçé²å±ï¼å·²å¤§å¹æ¨åé¶æ¬¡å­¸ç¿ç¾çè¾¨è­çé²å±ãç¶èï¼å°å½±åå±¤ç´çç¥è­è½ç§»å°åç´ å±¤ç´çä»»åï¼ä¾å¦ 3D é»è¦æ·å±¤ææä¸­ççç¶åå²ï¼ä»ç¶æ¯ä¸é éå¤§çææ°ãç±æ¼ççè¦è¦ºç¹å¾µçè¤éæ§åå¯è®æ§ï¼ç¾ææ¹æ³é£ä»¥å°è¨ç·´æéæªéå°çç´°ç²åº¦çç¶ç¹å¾µèç¾çç¸éçææ¬è¡¨å¾µå°é½ãå¨æ¬æä¸­ï¼æåæåº Maleniaï¼ä¸åæ°ç©çå¤å°ºåº¦çç¶å±¤ç´çé®ç½©å±¬æ§å°é½æ¶æ§ï¼å°éè¨­è¨ç¨æ¼ 3D é¶æ¬¡å­¸ç¿çç¶åå²ãMalenia æ¹åäºé®ç½©è¡¨å¾µåå¶ç¸éåç´ å±¬æ§ä¹éçç¸å®¹æ§ï¼æç¢ºé£çµäºæªè¦çç¶çè¦è¦ºç¹å¾µèå¾ååæè¦çç¶å­¸ç¿å°çå¯å»¶ä¼¸ç¥è­ãæ­¤å¤ï¼æåè¨­è¨äºä¸åè·¨æ¨¡æç¥è­æ³¨å¥æ¨¡çµï¼ä»¥ééäºæ è³è¨å¢å¼·è¦è¦ºåææ¬ç¹å¾µï¼ææå¼å°åå²çµæçç¢çãå¨ä¸åè³æéå 12 åçç¶é¡å¥çå¨é¢å¯¦é©é©è­äº Malenia çåªç°æè½ãç¨å¼ç¢¼å°å¬éã

##### **Resource-Efficient Medical Report Generation using Large Language Models**
2410.15642v1 by Abdullah, Ameer Hamza, Seong Tae Kim

Medical report generation is the task of automatically writing radiology
reports for chest X-ray images. Manually composing these reports is a
time-consuming process that is also prone to human errors. Generating medical
reports can therefore help reduce the burden on radiologists. In other words,
we can promote greater clinical automation in the medical domain. In this work,
we propose a new framework leveraging vision-enabled Large Language Models
(LLM) for the task of medical report generation. We introduce a lightweight
solution that achieves better or comparative performance as compared to
previous solutions on the task of medical report generation. We conduct
extensive experiments exploring different model sizes and enhancement
approaches, such as prefix tuning to improve the text generation abilities of
the LLMs. We evaluate our approach on a prominent large-scale radiology report
dataset - MIMIC-CXR. Our results demonstrate the capability of our
resource-efficient framework to generate patient-specific reports with strong
medical contextual understanding and high precision.

æè¦ï¼é«çå ±åçææ¯èªåæ°å¯«è¸é¨ X åå½±åçæ¾å°ç§å ±åçä»»åãæåæ°å¯«éäºå ±åæ¯ä¸åèæçéç¨ï¼èä¸å®¹æç¼çäººçºé¯èª¤ãå æ­¤ï¼çæé«çå ±åå¯ä»¥å¹«å©æ¸è¼æ¾å°ç§é«å¸«çè² æãæå¥è©±èªªï¼æåå¯ä»¥å¨é«çé åæ¨å»£æ´å»£æ³çè¨åºèªååãå¨éé å·¥ä½ä¸­ï¼æåæåºä¸åæ°çæ¡æ¶ï¼å©ç¨æ¯æ´å½±åçå¤§èªè¨æ¨¡å (LLM) ä¾å·è¡é«çå ±åçæçä»»åãæåå¼å¥ä¸åè¼éç´çè§£æ±ºæ¹æ¡ï¼èååå¨é«çå ±åçæä»»åä¸çè§£æ±ºæ¹æ¡ç¸æ¯ï¼å¯ä»¥éå°æ´å¥½æç¸ç¶çæè½ãæåé²è¡å»£æ³çå¯¦é©ï¼æ¢è¨ä¸åçæ¨¡åå¤§å°åå¼·åæ¹æ³ï¼ä¾å¦åç¶´èª¿æ´ï¼ä»¥æå LLM çæå­çæè½åãæåå¨ä¸åèåçãå¤§è¦æ¨¡çæ¾å°ç§å ±åè³æé - MIMIC-CXR ä¸è©ä¼°æåçåæ³ãæåççµæè­æäºæåè³æºç¯çåæ¡æ¶çæå·æå¼·å¤§é«çèæ¯çè§£åé«ç²¾ç¢ºåº¦çæ£èç¹å®å ±åçè½åã

##### **Improving Clinical Documentation with AI: A Comparative Study of Sporo AI Scribe and GPT-4o mini**
2410.15528v1 by Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj

AI-powered medical scribes have emerged as a promising solution to alleviate
the documentation burden in healthcare. Ambient AI scribes provide real-time
transcription and automated data entry into Electronic Health Records (EHRs),
with the potential to improve efficiency, reduce costs, and enhance
scalability. Despite early success, the accuracy of AI scribes remains
critical, as errors can lead to significant clinical consequences.
Additionally, AI scribes face challenges in handling the complexity and
variability of medical language and ensuring the privacy of sensitive patient
data. This case study aims to evaluate Sporo Health's AI scribe, a multi-agent
system leveraging fine-tuned medical LLMs, by comparing its performance with
OpenAI's GPT-4o Mini on multiple performance metrics. Using a dataset of
de-identified patient conversation transcripts, AI-generated summaries were
compared to clinician-generated notes (the ground truth) based on clinical
content recall, precision, and F1 scores. Evaluations were further supplemented
by clinician satisfaction assessments using a modified Physician Documentation
Quality Instrument revision 9 (PDQI-9), rated by both a medical student and a
physician. The results show that Sporo AI consistently outperformed GPT-4o
Mini, achieving higher recall, precision, and overall F1 scores. Moreover, the
AI generated summaries provided by Sporo were rated more favorably in terms of
accuracy, comprehensiveness, and relevance, with fewer hallucinations. These
findings demonstrate that Sporo AI Scribe is an effective and reliable tool for
clinical documentation, enhancing clinician workflows while maintaining high
standards of privacy and security.

æè¦ï¼<paragraph>ç± AI é©åçé«çæå¯«å¡å·²æçºæ¸è¼é«çä¿å¥ä¸­æä»¶è² æçæåæ¯çè§£æ±ºæ¹æ¡ãAmbient AI æå¯«å¡æä¾å¯¦æçè½éåèªååè³æè¼¸å¥é»å­å¥åº·è¨é (EHR)ï¼å·ææé«æçãéä½ææ¬åå¢å¼·å¯æ´åæ§çæ½åãåç®¡æ©ææåï¼AI æå¯«å¡çæºç¢ºæ§ä»ç¶è³ééè¦ï¼å çºé¯èª¤å¯è½å°è´å´éçè¨åºå¾æãæ­¤å¤ï¼AI æå¯«å¡å¨èçé«çèªè¨çè¤éæ§åå¯è®æ§ä»¥åç¢ºä¿æææ£èè³æçé±ç§æ¹é¢é¢è¨ææ°ãæ¬æ¡ä¾ç ç©¶æ¨å¨è©ä¼° Sporo Health ç AI æå¯«å¡ï¼ä¸åå©ç¨å¾®èª¿é«ç LLM çå¤ä»£çç³»çµ±ï¼ééæ¯è¼å¶å¨å¤åæ§è½ææ¨ä¸çè¡¨ç¾è OpenAI ç GPT-4o Miniãä½¿ç¨å»è­å¥çæ£èå°è©±è¨éçè³æéï¼å° AI çæçæè¦èè¨åºé«ççæçç­è¨ï¼åºæ¬äºå¯¦ï¼é²è¡æ¯è¼ï¼åºæ¼è¨åºå§å®¹å¬åãç²¾ç¢ºåº¦å F1 åæ¸ãè©ä¼°é²ä¸æ­¥è£åäºè¨åºé«çæ»¿æåº¦è©ä¼°ï¼ä½¿ç¨ä¿®æ¹å¾çé«çæä»¶è³ªéå·¥å·ä¿®è¨ç 9 (PDQI-9)ï¼ç±é«å­¸çåé«çè©åãçµæè¡¨æï¼Sporo AI æçºåªæ¼ GPT-4o Miniï¼ç²å¾æ´é«çå¬åçãç²¾ç¢ºåº¦åæ´é« F1 åæ¸ãæ­¤å¤ï¼Sporo æä¾ç AI çæçæè¦å¨æºç¢ºæ§ãå¨é¢æ§åç¸éæ§æ¹é¢ç²å¾äºæ´æ­£é¢çè©å¹ï¼èä¸å¹»è¦ºæ´å°ãéäºç¼ç¾è¡¨æï¼Sporo AI Scribe æ¯ä¸ç¨®ç¨æ¼è¨åºæä»¶ç·¨å¯«çææä¸å¯é çå·¥å·ï¼å¯å¨ä¿æé«æ¨æºçé±ç§åå®å¨æ§çåæï¼å¢å¼·è¨åºé«ççå·¥ä½æµç¨ã</paragraph>

##### **Anonymising Elderly and Pathological Speech: Voice Conversion Using DDSP and Query-by-Example**
2410.15500v1 by Suhita Ghosh, Melanie Jouaiti, Arnab Das, Yamini Sinha, Tim Polzehl, Ingo Siegert, Sebastian Stober

Speech anonymisation aims to protect speaker identity by changing personal
identifiers in speech while retaining linguistic content. Current methods fail
to retain prosody and unique speech patterns found in elderly and pathological
speech domains, which is essential for remote health monitoring. To address
this gap, we propose a voice conversion-based method (DDSP-QbE) using
differentiable digital signal processing and query-by-example. The proposed
method, trained with novel losses, aids in disentangling linguistic, prosodic,
and domain representations, enabling the model to adapt to uncommon speech
patterns. Objective and subjective evaluations show that DDSP-QbE significantly
outperforms the voice conversion state-of-the-art concerning intelligibility,
prosody, and domain preservation across diverse datasets, pathologies, and
speakers while maintaining quality and speaker anonymity. Experts validate
domain preservation by analysing twelve clinically pertinent domain attributes.

æè¦ï¼èªé³å¿ååæ¨å¨ééè®æ´èªé³ä¸­çåäººè­å¥è³è¨ï¼åæä¿çèªè¨å§å®¹ï¼ä»¥ä¿è­·èªªè©±èçèº«åãç®åçæè¡ç¡æ³ä¿çå¨èå¹´åççèªè¨é åä¸­ç¼ç¾çèªèª¿åç¨ç¹èªé³æ¨¡å¼ï¼éå°æ¼é è·å¥åº·ç£æ¸¬è³ééè¦ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸ååºæ¼èªé³è½æçæ¹æ³ (DDSP-QbE)ï¼ä½¿ç¨å¯å¾®åæ¸ä½è¨èèçåç¯ä¾æ¥è©¢ãææåºçæ¹æ³ç¶éæ°ç©æå¤±è¨ç·´ï¼æå©æ¼è§£éèªè¨ãèªèª¿åé åè¡¨ç¤ºï¼ä½¿æ¨¡åè½å¤ é©æä¸å¸¸è¦çèªé³æ¨¡å¼ãå®¢è§åä¸»è§è©ä¼°é¡¯ç¤ºï¼DDSP-QbE å¨ä¸åè³æéãççåèªªè©±èä¸­ï¼å¨æ¸æ°åº¦ãèªèª¿åé åä¿çæ¹é¢ï¼æé¡¯åªæ¼èªé³è½æçç¾ææè¡ï¼åæä¿æåè³ªåèªªè©±èå¿åæ§ãå°å®¶ééåæåäºåè¨åºä¸ç¸éçé åå±¬æ§ï¼é©è­é åä¿çã

##### **Multi-Layer Feature Fusion with Cross-Channel Attention-Based U-Net for Kidney Tumor Segmentation**
2410.15472v2 by Fnu Neha, Arvind K. Bansal

Renal tumors, especially renal cell carcinoma (RCC), show significant
heterogeneity, posing challenges for diagnosis using radiology images such as
MRI, echocardiograms, and CT scans. U-Net based deep learning techniques are
emerging as a promising approach for automated medical image segmentation for
minimally invasive diagnosis of renal tumors. However, current techniques need
further improvements in accuracy to become clinically useful to radiologists.
In this study, we present an improved U-Net based model for end-to-end
automated semantic segmentation of CT scan images to identify renal tumors. The
model uses residual connections across convolution layers, integrates a
multi-layer feature fusion (MFF) and cross-channel attention (CCA) within
encoder blocks, and incorporates skip connections augmented with additional
information derived using MFF and CCA. We evaluated our model on the KiTS19
dataset, which contains data from 210 patients. For kidney segmentation, our
model achieves a Dice Similarity Coefficient (DSC) of 0.97 and a Jaccard index
(JI) of 0.95. For renal tumor segmentation, our model achieves a DSC of 0.96
and a JI of 0.91. Based on a comparison of available DSC scores, our model
outperforms the current leading models.

æè¦ï¼èèè«ç¤ï¼å°¤å¶æ¯èç´°èç (RCC)ï¼è¡¨ç¾åºé¡¯èçç°è³ªæ§ï¼å°ä½¿ç¨ç£åå±æ¯å½±åãè¶é³æ³¢å¿åååé»è¦æ·å±¤ææç­æ¾å°å½±åé²è¡è¨ºæ·æ§æææ°ãåºæ¼ U-Net çæ·±åº¦å­¸ç¿æè¡æ­£ä½çºä¸ç¨®æåéçæ¹æ³åºç¾ï¼ç¨æ¼èªååé«å­¸å½±ååå²ï¼ä»¥å°èèè«ç¤é²è¡å¾®åµè¨ºæ·ãç¶èï¼ç®åçæè¡éè¦é²ä¸æ­¥æé«æºç¢ºæ§ï¼æè½å°æ¾å°ç§é«å¸«å¨è¨åºä¸æç¨ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸åæ¹é²çåºæ¼ U-Net çæ¨¡åï¼ç¨æ¼é»è¦æ·å±¤ææå½±åçç«¯å°ç«¯èªåèªç¾©åå²ï¼ä»¥è­å¥èèè«ç¤ãè©²æ¨¡åä½¿ç¨å·ç©å±¤ä¹éçæ®å·®é£æ¥ï¼æ´åç·¨ç¢¼å¨å¡å§çå¤åå±¤ç¹å¾µèå (MFF) åè·¨ééæ³¨æå (CCA)ï¼ä¸¦çµåä½¿ç¨ MFF å CCA å°åºçéå è³è¨å¢å¼·çè·³èºé£æ¥ãæåå¨ KiTS19 è³æéä¸è©ä¼°äºæåçæ¨¡åï¼å¶ä¸­åå«ä¾èª 210 åæ£èçè³æãå°æ¼èèåå²ï¼æåçæ¨¡åå¯¦ç¾äº 0.97 ç Dice ç¸ä¼¼æ§ä¿æ¸ (DSC) å 0.95 ç Jaccard ææ¸ (JI)ãå°æ¼èèè«ç¤åå²ï¼æåçæ¨¡åå¯¦ç¾äº 0.96 ç DSC å 0.91 ç JIãæ ¹æå¯ç¨ DSC åæ¸çæ¯è¼ï¼æåçæ¨¡ååªæ¼ç®åçé åæ¨¡åã

##### **Hallucination Detox: Sensitive Neuron Dropout (SeND) for Large Language Model Training**
2410.15460v1 by Shahrad Mohammadzadeh, Juan David Guerra, Marco Bonizzato, Reihaneh Rabbany, Golnoosh Farnadi

As large language models (LLMs) become increasingly deployed across various
industries, concerns regarding their reliability, particularly due to
hallucinations-outputs that are factually inaccurate or irrelevant to user
input-have grown. Our research investigates the relationship between the
training process and the emergence of hallucinations to address a key gap in
existing research that focuses primarily on post hoc detection and mitigation
strategies. Using models from the Pythia suite (70M-12B parameters) and several
hallucination detection metrics, we analyze hallucination trends throughout
training and explore LLM internal dynamics. We introduce SEnsitive Neuron
Dropout (SeND), a novel training protocol designed to mitigate hallucinations
by reducing variance during training. SeND achieves this by deterministically
dropping neurons with significant variability on a dataset, referred to as
Sensitive Neurons. In addition, we develop an unsupervised hallucination
detection metric, Efficient EigenScore (EES), which approximates the
traditional EigenScore in 2x speed. This efficient metric is integrated into
our protocol, allowing SeND to be both computationally scalable and effective
at reducing hallucinations. Our empirical evaluation demonstrates that our
approach improves LLM reliability at test time by up to 40% compared to normal
training while also providing an efficient method to improve factual accuracy
when adapting LLMs to domains such as Wikipedia and Medical datasets.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡åï¼LLMï¼å¨åç¢æ¥­çé¨ç½²æ¥çå»£æ³ï¼å°æ¼å¶å¯é æ§ççæ®ä¹é¨ä¹å¢å ï¼ç¹å¥æ¯å¹»è¦ºè¼¸åºï¼å³èäºå¯¦ä¸ç¬¦æèä½¿ç¨èè¼¸å¥ç¡éçè¼¸åºãæåçç ç©¶èª¿æ¥è¨ç·´æµç¨èå¹»è¦ºåºç¾ä¹éçéä¿ï¼ä»¥è§£æ±ºç¾æç ç©¶çééµå·®è·ï¼èç¾æç ç©¶ä¸»è¦éä¸­å¨äºå¾åµæ¸¬åç·©è§£ç­ç¥ãæåä½¿ç¨ Pythia çµåï¼70M-12B åæ¸ï¼ä¸­çæ¨¡ååå¹¾åå¹»è¦ºåµæ¸¬ææ¨ï¼åææ´åè¨ç·´éç¨ä¸­çå¹»è¦ºè¶¨å¢ï¼ä¸¦æ¢ç´¢ LLM å§é¨åæãæåå¼å¥äºææç¥ç¶åä¸­æ·ï¼SeNDï¼ï¼éæ¯ä¸ç¨®æ°ç©çè¨ç·´åå®ï¼æ¨å¨ééæ¸å°è¨ç·´æéçè®ç°ä¾æ¸è¼å¹»è¦ºãSeND ééç¢ºå®æ§å°æ¨æ£è³æéä¸è®ç°é¡¯èçç¥ç¶åï¼ç¨±çºææç¥ç¶åï¼ä¾éææ­¤ç®çãæ­¤å¤ï¼æåéç¼äºä¸åç¡ç£ç£çå¹»è¦ºåµæ¸¬ææ¨ï¼å³ææç¹å¾µå¼ï¼EESï¼ï¼å®ä»¥ 2 åçéåº¦è¿ä¼¼å³çµ±çç¹å¾µå¼ãéåææçææ¨æ´åå°æåçåå®ä¸­ï¼è® SeND å¨è¨ç®ä¸å¯æ´åä¸æææ¸å°å¹»è¦ºãæåçç¶é©è©ä¼°é¡¯ç¤ºï¼èä¸è¬è¨ç·´ç¸æ¯ï¼æåçåæ³å¨æ¸¬è©¦æéå° LLM çå¯é æ§æåäº 40%ï¼åæä¹æä¾äºä¸ç¨®ææçæ¹æ³ä¾æåäºå¯¦æºç¢ºåº¦ï¼ä¾å¦å° LLM é©æå°ç¶­åºç¾ç§åé«çè³æéç­é åã

##### **Concept Complement Bottleneck Model for Interpretable Medical Image Diagnosis**
2410.15446v1 by Hongmei Wang, Junlin Hou, Hao Chen

Models based on human-understandable concepts have received extensive
attention to improve model interpretability for trustworthy artificial
intelligence in the field of medical image analysis. These methods can provide
convincing explanations for model decisions but heavily rely on the detailed
annotation of pre-defined concepts. Consequently, they may not be effective in
cases where concepts or annotations are incomplete or low-quality. Although
some methods automatically discover effective and new visual concepts rather
than using pre-defined concepts or could find some human-understandable
concepts via large Language models, they are prone to veering away from medical
diagnostic evidence and are challenging to understand. In this paper, we
propose a concept complement bottleneck model for interpretable medical image
diagnosis with the aim of complementing the existing concept set and finding
new concepts bridging the gap between explainable models. Specifically, we
propose to use concept adapters for specific concepts to mine the concept
differences and score concepts in their own attention channels to support
almost fairly concept learning. Then, we devise a concept complement strategy
to learn new concepts while jointly using known concepts to improve model
performance. Comprehensive experiments on medical datasets demonstrate that our
model outperforms the state-of-the-art competitors in concept detection and
disease diagnosis tasks while providing diverse explanations to ensure model
interpretability effectively.

æè¦ï¼<paragraph>åºæ¼äººé¡å¯çè§£æ¦å¿µçæ¨¡åå·²å»£åéæ³¨ï¼ä»¥æ¹åé«çå½±ååæé åä¸­å¯ä¿¡è³´äººå·¥æºæ§çæ¨¡åå¯è§£éæ§ãéäºæ¹æ³å¯ä»¥æä¾ä»¤äººä¿¡æçæ¨¡åæ±ºç­èªªæï¼ä½å´éä¾è³´é å®ç¾©æ¦å¿µçè©³ç´°è¨»è§£ãå æ­¤ï¼å¨æ¦å¿µæè¨»è§£ä¸å®æ´æåè³ªä½è½çææ³ä¸ï¼å®åå¯è½ç¡æãåç®¡ä¸äºæ¹æ³æèªåç¼ç¾ææä¸æ°çè¦è¦ºæ¦å¿µï¼èä¸æ¯ä½¿ç¨é å®ç¾©æ¦å¿µï¼æèå¯ä»¥ééå¤§åèªè¨æ¨¡åæ¾å°ä¸äºäººé¡å¯çè§£çæ¦å¿µï¼ä½å®åå®¹æåé¢é«çè¨ºæ·è­æï¼ä¸é£ä»¥çè§£ãå¨æ¬æä¸­ï¼æåæåºä¸åæ¦å¿µè£å®ç¶é ¸æ¨¡åï¼ç¨æ¼å¯è§£éçé«çå½±åè¨ºæ·ï¼ç®çæ¯è£åç¾æçæ¦å¿µéï¼ä¸¦æ¾å°æ°çæ¦å¿µï¼å½åå¯è§£éæ¨¡åä¹éçå·®è·ãå·é«ä¾èªªï¼æåå»ºè­°éå°ç¹å®æ¦å¿µä½¿ç¨æ¦å¿µé©éå¨ï¼ä»¥æææ¦å¿µå·®ç°ï¼ä¸¦å¨å®åèªå·±çæ³¨æåééä¸­è©åæ¦å¿µï¼ä»¥æ¯æ´å¹¾ä¹å¬å¹³çæ¦å¿µå­¸ç¿ãç¶å¾ï¼æåè¨­è¨ä¸åæ¦å¿µè£å®ç­ç¥ï¼å¨å±åä½¿ç¨å·²ç¥æ¦å¿µæ¹åæ¨¡åæè½çåæï¼å­¸ç¿æ°æ¦å¿µãå¨é«çè³æéä¸é²è¡çç¶åå¯¦é©è­æï¼æåçæ¨¡åå¨æ¦å¿µåµæ¸¬åç¾çè¨ºæ·ä»»åä¸­åªæ¼æåé²çç«¶ç­å°æï¼åææä¾å¤æ¨£åçèªªæï¼ä»¥ææç¢ºä¿æ¨¡åçå¯è§£éæ§ã</paragraph>

##### **AttCDCNet: Attention-enhanced Chest Disease Classification using X-Ray Images**
2410.15437v1 by Omar Hesham Khater, Abdullahi Sani Shuaib, Sami Ul Haq, Abdul Jabbar Siddiqui

Chest X-rays (X-ray images) have been proven to be effective for the
diagnosis of chest diseases, including Pneumonia, Lung Opacity, and COVID-19.
However, relying on traditional medical methods for diagnosis from X-ray images
is prone to delays and inaccuracies because the medical personnel who evaluate
the X-ray images may have preconceived biases. For this reason, researchers
have proposed the use of deep learning-based techniques to facilitate the
diagnosis process. The preeminent method is the use of sophisticated
Convolutional Neural Networks (CNNs). In this paper, we propose a novel
detection model named \textbf{AttCDCNet} for the task of X-ray image diagnosis,
enhancing the popular DenseNet121 model by adding an attention block to help
the model focus on the most relevant regions, using focal loss as a loss
function to overcome the imbalance of the dataset problem, and utilizing
depth-wise convolution to reduce the parameters to make the model lighter.
Through extensive experimental evaluations, the proposed model demonstrates
exceptional performance, showing better results than the original DenseNet121.
The proposed model achieved an accuracy, precision and recall of 94.94%, 95.14%
and 94.53%, respectively, on the COVID-19 Radiography Dataset.

æè¦ï¼è¸é¨ X åï¼X åå½±åï¼å·²è¢«è­å¯¦å¯ææè¨ºæ·è¸é¨ç¾çï¼åæ¬èºçãèºé¨ä¸éæåº¦å COVID-19ãç¶èï¼ä¾è³´å³çµ±é«å­¸æ¹æ³å¾ X åå½±åä¸­é²è¡è¨ºæ·å®¹æå»¶èª¤åä¸æºç¢ºï¼å çºè©ä¼° X åå½±åçé«è­·äººå¡å¯è½æé è¨­ç«å ´çåè¦ãå æ­¤ï¼ç ç©¶äººå¡æåºä½¿ç¨åºæ¼æ·±åº¦å­¸ç¿çæè¡ä¾ä¿é²è¨ºæ·éç¨ãæä¸»è¦çæ¹æ³æ¯ä½¿ç¨è¤éçå·ç©ç¥ç¶ç¶²è·¯ (CNN)ãå¨æ¬æä¸­ï¼æåæåºä¸ååçº \textbf{AttCDCNet} çæ°æª¢æ¸¬æ¨¡åï¼ç¨æ¼ X åå½±åè¨ºæ·ä»»åï¼ééå å¥ä¸åæ³¨æååå¡ä¾å¢å¼·æµè¡ç DenseNet121 æ¨¡åï¼ä»¥å¹«å©æ¨¡åå°æ³¨æ¼æç¸éçååï¼ä¸¦ä½¿ç¨ç¦é»æå¤±ä½çºæå¤±å½æ¸ä¾åæè³æéåé¡çä¸å¹³è¡¡ï¼ä¸¦å©ç¨æ·±åº¦å·ç©ä¾æ¸å°åæ¸ï¼ä½¿æ¨¡åæ´è¼éåãééå»£æ³çå¯¦é©è©ä¼°ï¼ææåºçæ¨¡åå±ç¾åºéå¡çæè½ï¼é¡¯ç¤ºåºæ¯åå§ DenseNet121 æ´å¥½ççµæãææåºçæ¨¡åå¨ COVID-19 æ¾å°ç·ç§ç¸è³æéä¸åå¥éå°äº 94.94%ã95.14% å 94.53% çæºç¢ºåº¦ãç²¾ç¢ºåº¦åå¬åçã

##### **MMCS: A Multimodal Medical Diagnosis System Integrating Image Analysis and Knowledge-based Departmental Consultation**
2410.15403v1 by Yi Ren, HanZhi Zhang, Weibin Li, Diandong Liu, Tianyi Zhang, Jie He

We present MMCS, a system capable of recognizing medical images and patient
facial details, and providing professional medical diagnoses. The system
consists of two core components: The first component is the analysis of medical
images and videos. We trained a specialized multimodal medical model capable of
interpreting medical images and accurately analyzing patients' facial emotions
and facial paralysis conditions. The model achieved an accuracy of 72.59% on
the FER2013 facial emotion recognition dataset, with a 91.1% accuracy in
recognizing the happy emotion. In facial paralysis recognition, the model
reached an accuracy of 92%, which is 30% higher than that of GPT-4o. Based on
this model, we developed a parser for analyzing facial movement videos of
patients with facial paralysis, achieving precise grading of the paralysis
severity. In tests on 30 videos of facial paralysis patients, the system
demonstrated a grading accuracy of 83.3%.The second component is the generation
of professional medical responses. We employed a large language model,
integrated with a medical knowledge base, to generate professional diagnoses
based on the analysis of medical images or videos. The core innovation lies in
our development of a department-specific knowledge base routing management
mechanism, in which the large language model categorizes data by medical
departments and, during the retrieval process, determines the appropriate
knowledge base to query. This significantly improves retrieval accuracy in the
RAG (retrieval-augmented generation) process. This mechanism led to an average
increase of 4 percentage points in accuracy for various large language models
on the MedQA dataset.Our code is open-sourced and available at:
https://github.com/renllll/MMCS.

æè¦ï¼<paragraph>æåæåº MMCSï¼éæ¯ä¸åè½å¤ è¾¨è­é«çå½±ååçæ£
é¢é¨ç´°ç¯ï¼ä¸¦æä¾å°æ¥­é«çè¨ºæ·çç³»çµ±ãéåç³»çµ±
åå«å©åæ ¸å¿çµæï¼ç¬¬ä¸åçµææ¯é«çå½±ååå½±ççåæãæåè¨ç·´äºä¸åå°éçå¤æ¨¡æé«çæ¨¡åï¼è½å¤ 
è§£è®é«çå½±åä¸¦ç²¾æºåæçæ£çé¢é¨æç·åé¡é¢éº»çºçæ³ãéåæ¨¡åå¨ FER2013 é¢é¨æç·è¾¨è­è³æéä¸éå°äº 72.59% çæºç¢ºåº¦ï¼å¨è¾¨è­å¿«æ¨æç·ææ 91.1% çæºç¢ºåº¦ãå¨é¡é¢éº»çºè¾¨è­ä¸­ï¼éåæ¨¡åéå°äº 92% çæºç¢ºåº¦ï¼æ¯ GPT-4o é«åº 30%ãåºæ¼
éåæ¨¡åï¼æåéç¼äºä¸åç¨æ¼åæé¡é¢éº»çºçæ£é¢é¨åä½å½±ççåæå¨ï¼éå°äºå°éº»çºå´éç¨åº¦çç²¾ç¢ºåç´ãå¨å° 30 é¨é¡é¢éº»çºçæ£å½±ççæ¸¬è©¦ä¸­ï¼éåç³»çµ±
å±ç¾äº 83.3% çåç´æºç¢ºåº¦ãç¬¬äºåçµææ¯å°æ¥­é«çåæçç¢çãæåæ¡ç¨äºä¸åå¤§åèªè¨æ¨¡åï¼æ´åäºä¸åé«çç¥è­åº«ï¼ä»¥ç¢çåºæ¼é«çå½±åæå½±çåæçå°æ¥­è¨ºæ·ãæ ¸å¿çåµæ°å¨æ¼
æåéç¼äºä¸åé¨éç¹å®ç¥è­åº«è·¯ç±ç®¡çæ©å¶ï¼å¶ä¸­å¤§åèªè¨æ¨¡åä¾æé«çé¨éåé¡è³æï¼ä¸¦å¨æª¢ç´¢éç¨ä¸­ï¼æ±ºå®è¦æ¥è©¢çé©ç¶ç¥è­åº«ãéé¡¯èå°æåäº RAGï¼æª¢ç´¢å¢å¼·ç¢çï¼éç¨ä¸­çæª¢ç´¢æºç¢ºåº¦ãéåæ©å¶å°è´äº MedQA è³æéä¸åç¨®å¤§åèªè¨æ¨¡åçæºç¢ºåº¦å¹³åæåäº 4 åç¾åé»ãæåçç¨å¼ç¢¼æ¯éæºçï¼å¯ä»¥å¨éè£¡åå¾ï¼
https://github.com/renllll/MMCSã</paragraph>

##### **AutoFLUKA: A Large Language Model Based Framework for Automating Monte Carlo Simulations in FLUKA**
2410.15222v1 by Zavier Ndum Ndum, Jian Tao, John Ford, Yang Liu

Monte Carlo (MC) simulations, particularly using FLUKA, are essential for
replicating real-world scenarios across scientific and engineering fields.
Despite the robustness and versatility, FLUKA faces significant limitations in
automation and integration with external post-processing tools, leading to
workflows with a steep learning curve, which are time-consuming and prone to
human errors. Traditional methods involving the use of shell and Python
scripts, MATLAB, and Microsoft Excel require extensive manual intervention and
lack flexibility, adding complexity to evolving scenarios. This study explores
the potential of Large Language Models (LLMs) and AI agents to address these
limitations. AI agents, integrate natural language processing with autonomous
reasoning for decision-making and adaptive planning, making them ideal for
automation. We introduce AutoFLUKA, an AI agent application developed using the
LangChain Python Framework to automate typical MC simulation workflows in
FLUKA. AutoFLUKA can modify FLUKA input files, execute simulations, and
efficiently process results for visualization, significantly reducing human
labor and error. Our case studies demonstrate that AutoFLUKA can handle both
generalized and domain-specific cases, such as Microdosimetry, with an
streamlined automated workflow, showcasing its scalability and flexibility. The
study also highlights the potential of Retrieval Augmentation Generation (RAG)
tools to act as virtual assistants for FLUKA, further improving user
experience, time and efficiency. In conclusion, AutoFLUKA represents a
significant advancement in automating MC simulation workflows, offering a
robust solution to the inherent limitations. This innovation not only saves
time and resources but also opens new paradigms for research and development in
high energy physics, medical physics, nuclear engineering space and
environmental science.

æè¦ï¼èå°å¡ç¾ (MC) æ¨¡æ¬ï¼ç¹å¥æ¯ä½¿ç¨ FLUKAï¼å°æ¼è¤è£½ç§å­¸åå·¥ç¨é åä¸­ççå¯¦ä¸çå ´æ¯è³ééè¦ãåç®¡å·æç©©å¥æ§åå¤åè½æ§ï¼ä½ FLUKA å¨èªåååèå¤é¨å¾èçå·¥å·éææ¹é¢é¢è¨éå¤§éå¶ï¼å°è´å·¥ä½æµç¨å­¸ç¿æ²ç·é¡å³­ï¼æ¢èæåå®¹æåºç¾äººçºé¯èª¤ãæ¶åä½¿ç¨ shell å Python è³æ¬ãMATLAB å Microsoft Excel çå³çµ±æ¹æ³éè¦å»£æ³çæåå¹²é ï¼ä¸¦ä¸ç¼ºä¹éæ´»æ§ï¼å¢å äºæ¼åå ´æ¯çè¤éæ§ãæ¬ç ç©¶æ¢è¨äºå¤§åèªè¨æ¨¡å (LLM) å AI ä»£çè§£æ±ºéäºéå¶çæ½åãAI ä»£çå°èªç¶èªè¨èçèèªä¸»æ¨çç¸çµåï¼ç¨æ¼æ±ºç­å¶å®åé©ææ§è¦åï¼ä½¿å¶æçºèªååççæ³é¸æãæåä»ç´¹äº AutoFLUKAï¼éæ¯ä¸åä½¿ç¨ LangChain Python æ¡æ¶éç¼ç AI ä»£çæç¨ç¨å¼ï¼ç¨æ¼èªåå FLUKA ä¸­å¸åç MC æ¨¡æ¬å·¥ä½æµç¨ãAutoFLUKA å¯ä»¥ä¿®æ¹ FLUKA è¼¸å¥æªæ¡ãå·è¡æ¨¡æ¬ï¼ä¸¦ææèççµæä»¥é²è¡è¦è¦ºåï¼å¾èå¤§å¹æ¸å°äººå·¥ä½æ¥­åé¯èª¤ãæåçæ¡ä¾ç ç©¶è¡¨æï¼AutoFLUKA å¯ä»¥èçå»£æ³åç¹å®é åçæ¡ä¾ï¼ä¾å¦å¾®åéæ¸¬éï¼å·æç°¡åçèªååå·¥ä½æµç¨ï¼å±ç¤ºäºå¶å¯æ´å±æ§åéæ´»æ§ãè©²ç ç©¶éå¼·èª¿äºæª¢ç´¢æ´åçæ (RAG) å·¥å·ä½çº FLUKA èæ¬å©æçæ½åï¼é²ä¸æ­¥æ¹åäºä½¿ç¨èé«é©ãæéåæçãç¸½ä¹ï¼AutoFLUKA ä»£è¡¨äº MC æ¨¡æ¬å·¥ä½æµç¨èªååçä¸é éå¤§é²å±ï¼çºåºæéå¶æä¾äºå¼·å¤§çè§£æ±ºæ¹æ¡ãéé åµæ°ä¸åç¯çäºæéåè³æºï¼éçºé«è½ç©çãé«å­¸ç©çãæ ¸å·¥ç¨ç©ºéåç°å¢ç§å­¸é åçç ç©¶åéç¼éé¢äºæ°çç¯ä¾ã

##### **Medical-GAT: Cancer Document Classification Leveraging Graph-Based Residual Network for Scenarios with Limited Data**
2410.15198v2 by Elias Hossain, Tasfia Nuzhat, Shamsul Masum, Shahram Rahimi, Sudip Mittal, Noorbakhsh Amiri Golilarz

Accurate classification of cancer-related medical abstracts is crucial for
healthcare management and research. However, obtaining large, labeled datasets
in the medical domain is challenging due to privacy concerns and the complexity
of clinical data. This scarcity of annotated data impedes the development of
effective machine learning models for cancer document classification. To
address this challenge, we present a curated dataset of 1,874 biomedical
abstracts, categorized into thyroid cancer, colon cancer, lung cancer, and
generic topics. Our research focuses on leveraging this dataset to improve
classification performance, particularly in data-scarce scenarios. We introduce
a Residual Graph Attention Network (R-GAT) with multiple graph attention layers
that capture the semantic information and structural relationships within
cancer-related documents. Our R-GAT model is compared with various techniques,
including transformer-based models such as Bidirectional Encoder
Representations from Transformers (BERT), RoBERTa, and domain-specific models
like BioBERT and Bio+ClinicalBERT. We also evaluated deep learning models
(CNNs, LSTMs) and traditional machine learning models (Logistic Regression,
SVM). Additionally, we explore ensemble approaches that combine deep learning
models to enhance classification. Various feature extraction methods are
assessed, including Term Frequency-Inverse Document Frequency (TF-IDF) with
unigrams and bigrams, Word2Vec, and tokenizers from BERT and RoBERTa. The R-GAT
model outperforms other techniques, achieving precision, recall, and F1 scores
of 0.99, 0.97, and 0.98 for thyroid cancer; 0.96, 0.94, and 0.95 for colon
cancer; 0.96, 0.99, and 0.97 for lung cancer; and 0.95, 0.96, and 0.95 for
generic topics.

æè¦ï¼æºç¢ºåé¡èççç¸éçé«å­¸æè¦å°æ¼é«çä¿å¥ç®¡çåç ç©¶è³ééè¦ãç¶èï¼ç±æ¼é±ç§åé¡åè¨åºæ¸æçè¤éæ§ï¼å¨é«çé åä¸­åå¾æ¨è¨å¤§åæ¸æéå·æææ°æ§ãéç¨®è¨»è§£æ¸æçç¨ç¼ºé»ç¤äºéç¼ç¨æ¼ççæä»¶åé¡çæææ©å¨å­¸ç¿æ¨¡åãçºäºæå°éä¸ææ°ï¼æåæä¾äºä¸åç± 1,874 ç¯çç©é«å­¸æè¦çµæçç²¾é¸æ¸æéï¼åé¡çºç²çèºçãçµè¸çãèºçåä¸è¬ä¸»é¡ãæåçç ç©¶éé»å¨æ¼å©ç¨æ­¤æ¸æéä¾æ¹ååé¡æè½ï¼ç¹å¥æ¯å¨è³æç¨å°çææ³ä¸ãæåå¼å¥äºå·æå¤ååå½¢æ³¨æå±¤çæ®å·®åå½¢æ³¨æç¶²è·¯ (R-GAT)ï¼å®å¯ä»¥æ·åççç¸éæä»¶ä¸­çèªç¾©è³è¨åçµæ§éä¿ãæåç R-GAT æ¨¡åèåç¨®æè¡é²è¡æ¯è¼ï¼åæ¬åºæ¼è½æå¨çæ¨¡åï¼ä¾å¦ä¾èªè½æå¨çéåç·¨ç¢¼å¨è¡¨ç¤º (BERT)ãRoBERTa åç¹å®é åçæ¨¡åï¼ä¾å¦ BioBERT å Bio+ClinicalBERTãæåéè©ä¼°äºæ·±åº¦å­¸ç¿æ¨¡å (CNNãLSTM) åå³çµ±æ©å¨å­¸ç¿æ¨¡å (éè¼¯è¿´æ­¸ãSVM)ãæ­¤å¤ï¼æåæ¢ç´¢äºçµåæ·±åº¦å­¸ç¿æ¨¡åä»¥å¢å¼·åé¡çæ´é«æ¹æ³ãè©ä¼°äºåç¨®ç¹å¾µæåæ¹æ³ï¼åæ¬å·æå®å­åéå­çè©é »-éæä»¶é »ç (TF-IDF)ãWord2Vecï¼ä»¥åä¾èª BERT å RoBERTa çæ¨è¨å¨ãR-GAT æ¨¡ååªæ¼å¶ä»æè¡ï¼å°æ¼ç²çèºçï¼å¯¦ç¾äº 0.99ã0.97 å 0.98 çæºç¢ºåº¦ãå¬åçå F1 åæ¸ï¼å°æ¼çµè¸çï¼å¯¦ç¾äº 0.96ã0.94 å 0.95ï¼å°æ¼èºçï¼å¯¦ç¾äº 0.96ã0.99 å 0.97ï¼å°æ¼ä¸è¬ä¸»é¡ï¼å¯¦ç¾äº 0.95ã0.96 å 0.95ã

##### **Fine-tuning foundational models to code diagnoses from veterinary health records**
2410.15186v1 by Mayla R. Boguslav, Adam Kiehl, David Kott, G. Joseph Strecker, Tracy Webb, Nadia Saklou, Terri Ward, Michael Kirby

Veterinary medical records represent a large data resource for application to
veterinary and One Health clinical research efforts. Use of the data is limited
by interoperability challenges including inconsistent data formats and data
siloing. Clinical coding using standardized medical terminologies enhances the
quality of medical records and facilitates their interoperability with
veterinary and human health records from other sites. Previous studies, such as
DeepTag and VetTag, evaluated the application of Natural Language Processing
(NLP) to automate veterinary diagnosis coding, employing long short-term memory
(LSTM) and transformer models to infer a subset of Systemized Nomenclature of
Medicine - Clinical Terms (SNOMED-CT) diagnosis codes from free-text clinical
notes. This study expands on these efforts by incorporating all 7,739 distinct
SNOMED-CT diagnosis codes recognized by the Colorado State University (CSU)
Veterinary Teaching Hospital (VTH) and by leveraging the increasing
availability of pre-trained large language models (LLMs). Ten freely-available
pre-trained LLMs were fine-tuned on the free-text notes from 246,473
manually-coded veterinary patient visits included in the CSU VTH's electronic
health records (EHRs), which resulted in superior performance relative to
previous efforts. The most accurate results were obtained when expansive
labeled data were used to fine-tune relatively large clinical LLMs, but the
study also showed that comparable results can be obtained using more limited
resources and non-clinical LLMs. The results of this study contribute to the
improvement of the quality of veterinary EHRs by investigating accessible
methods for automated coding and support both animal and human health research
by paving the way for more integrated and comprehensive health databases that
span species and institutions.

æè¦ï¼ç¸é«é«çè¨éä»£è¡¨èä¸åé¾å¤§çè³æè³æºï¼å¯æç¨æ¼ç¸é«åãåä¸å¥åº·ãè¨åºç ç©¶å·¥ä½ãè³æçä½¿ç¨åå°äºéæ§ææ°çéå¶ï¼åæ¬ä¸ä¸è´çè³ææ ¼å¼åè³æå­¤å³¶ãä½¿ç¨æ¨æºåé«çè¡èªé²è¡è¨åºç·¨ç¢¼å¯æåçæ­·çåè³ªï¼ä¸¦ä¿é²å¶èå¶ä»æ©æ§çç¸é«åäººé¡å¥åº·è¨éçäºéæ§ãååçç ç©¶ï¼ä¾å¦ DeepTag å VetTagï¼è©ä¼°äºèªç¶èªè¨èç (NLP) å¨èªååç¸é«è¨ºæ·ç·¨ç¢¼ä¸­çæç¨ï¼æ¡ç¨é·ç­æè¨æ¶ (LSTM) åè½æå¨æ¨¡åå¾èªç±æå­è¨åºç­è¨ä¸­æ¨æ·ç³»çµ±åé«å­¸åè© - è¨åºè¡èª (SNOMED-CT) è¨ºæ·ç¢¼çå­éãæ¬ç ç©¶ééç´å¥ç§ç¾æå¤å·ç«å¤§å­¸ (CSU) ç¸é«æå­¸é«é¢ (VTH) è­å¥çææ 7,739 åä¸åç SNOMED-CT è¨ºæ·ç¢¼ï¼ä¸¦å©ç¨é åè¨ç·´å¥½çå¤§åèªè¨æ¨¡å (LLM) çå¯ç¨æ§éæ¼¸å¢å ï¼ä¾æ´å±éäºå·¥ä½ãåååè²»æä¾çé åè¨ç·´å¥½ç LLM å°ä¾èª CSU VTH çé»å­å¥åº·è¨é (EHR) ä¸­åå«ç 246,473 æ¬¡æåç·¨ç¢¼ç¸é«æ£èå°±è¨ºçèªç±æå­ç­è¨é²è¡å¾®èª¿ï¼ç¸è¼æ¼ååçç ç©¶ï¼éå¸¶ä¾äºåªç°çæè½ãç¶ä½¿ç¨å»£æ³çæ¨ç±¤è³æå¾®èª¿ç¸å°è¼å¤§çè¨åº LLM æï¼ç²å¾äºææºç¢ºççµæï¼ä½ç ç©¶ä¹é¡¯ç¤ºï¼ä½¿ç¨æ´æéçè³æºåéè¨åº LLM ä¹å¯ä»¥ç²å¾ç¸ç¶ççµæãæ¬ç ç©¶ççµææå©æ¼ééæ¢è¨èªåç·¨ç¢¼çå¯è¡æ¹æ³ä¾æåç¸é« EHR çåè³ªï¼ä¸¦ééçºè·¨è¶ç©ç¨®åæ©æ§çæ´æ´åä¸å¨é¢çå¥åº·è³æåº«éªè·¯ï¼ä¾æ¯æ´åç©åäººé¡å¥åº·ç ç©¶ã

##### **LLaVA-Ultra: Large Chinese Language and Vision Assistant for Ultrasound**
2410.15074v1 by Xuechen Guo, Wenhao Chai, Shi-Yan Li, Gaoang Wang

Multimodal Large Language Model (MLLM) has recently garnered attention as a
prominent research focus. By harnessing powerful LLM, it facilitates a
transition of conversational generative AI from unimodal text to performing
multimodal tasks. This boom begins to significantly impact medical field.
However, general visual language model (VLM) lacks sophisticated comprehension
for medical visual question answering (Med-VQA). Even models specifically
tailored for medical domain tend to produce vague answers with weak visual
relevance. In this paper, we propose a fine-grained adaptive VLM architecture
for Chinese medical visual conversations through parameter-efficient tuning.
Specifically, we devise a fusion module with fine-grained vision encoders to
achieve enhancement for subtle medical visual semantics. Then we note data
redundancy common to medical scenes is ignored in most prior works. In cases of
a single text paired with multiple figures, we utilize weighted scoring with
knowledge distillation to adaptively screen valid images mirroring text
descriptions. For execution, we leverage a large-scale multimodal Chinese
ultrasound dataset obtained from the hospital. We create instruction-following
data based on text from professional doctors, which ensures effective tuning.
With enhanced model and quality data, our Large Chinese Language and Vision
Assistant for Ultrasound (LLaVA-Ultra) shows strong capability and robustness
to medical scenarios. On three Med-VQA datasets, LLaVA-Ultra surpasses previous
state-of-the-art models on various metrics.

æè¦ï¼å¤æ¨¡æå¤§è¯­è¨æ¨¡å (MLLM) æè¿ä½ä¸ºä¸é¡¹éè¦çç ç©¶éç¹èå¤åå³æ³¨ãéè¿å©ç¨åè½å¼ºå¤§ç LLMï¼å®ä¿è¿äºä¼è¯çæå¼ AI ä»åæ¨¡æææ¬åæ§è¡å¤æ¨¡æä»»å¡çè½¬åãè¿ç§è¬ååå±å¼å§å¯¹å»å­¦é¢åäº§çéå¤§å½±åãç¶èï¼éç¨è§è§è¯­è¨æ¨¡å (VLM) ç¼ºä¹å¯¹å»å­¦è§è§é®é¢è§£ç­ (Med-VQA) çå¤æçè§£ãå³ä½¿æ¯ä¸é¨éå¯¹å»å­¦é¢åçæ¨¡åä¹å¾åäºäº§çæ¨¡ç³çç­æ¡ï¼ä¸è§è§ç¸å³æ§è¾å¼±ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ç§ç»ç²åº¦èªéåº VLM æ¶æï¼ç¨äºéè¿åæ°é«æè°ä¼è¿è¡ä¸­æå»å­¦è§è§å¯¹è¯ãå·ä½æ¥è¯´ï¼æä»¬è®¾è®¡äºä¸ä¸ªèåæ¨¡åï¼å¶ä¸­åå«ç»ç²åº¦è§è§ç¼ç å¨ï¼ä»¥å¢å¼ºå¾®å¦çå»å­¦è§è§è¯­ä¹ãç¶åï¼æä»¬æ³¨æå°å¤§å¤æ°ååçå·¥ä½é½å¿½ç¥äºå»å­¦åºæ¯ä¸­å¸¸è§çæ°æ®åä½ãå¨åä¸ªææ¬ä¸å¤ä¸ªå¾å½¢éå¯¹çæåµä¸ï¼æä»¬å©ç¨å æè¯ååç¥è¯è¸é¦æ¥èªéåºå°ç­éåæ ææ¬æè¿°çææå¾åãä¸ºäºæ§è¡ï¼æä»¬å©ç¨ä»å»é¢è·å¾çå¤§è§æ¨¡å¤æ¨¡æä¸­æè¶å£°æ°æ®éãæä»¬åºäºä¸ä¸å»ççææ¬åå»ºäºéµå¾ªæä»¤çæ°æ®ï¼ä»èç¡®ä¿äºææçè°ä¼ãéè¿å¢å¼ºçæ¨¡ååé«è´¨éæ°æ®ï¼æä»¬çä¸­æè¯­è¨åè¶å£°è§è§å©ç (LLaVA-Ultra) å¯¹å»å­¦åºæ¯è¡¨ç°åºå¼ºå¤§çè½ååé²æ£æ§ãå¨ä¸ä¸ª Med-VQA æ°æ®éä¸ï¼LLaVA-Ultra å¨åç§ææ ä¸é½è¶è¿äºä»¥åæåè¿çæ¨¡åã

##### **A General-Purpose Multimodal Foundation Model for Dermatology**
2410.15038v1 by Siyuan Yan, Zhen Yu, Clare Primiero, Cristina Vico-Alonso, Zhonghua Wang, Litao Yang, Philipp Tschandl, Ming Hu, Gin Tan, Vincent Tang, Aik Beng Ng, David Powell, Paul Bonnington, Simon See, Monika Janda, Victoria Mar, Harald Kittler, H. Peter Soyer, Zongyuan Ge

Diagnosing and treating skin diseases require advanced visual skills across
multiple domains and the ability to synthesize information from various imaging
modalities. Current deep learning models, while effective at specific tasks
such as diagnosing skin cancer from dermoscopic images, fall short in
addressing the complex, multimodal demands of clinical practice. Here, we
introduce PanDerm, a multimodal dermatology foundation model pretrained through
self-supervised learning on a dataset of over 2 million real-world images of
skin diseases, sourced from 11 clinical institutions across 4 imaging
modalities. We evaluated PanDerm on 28 diverse datasets covering a range of
clinical tasks, including skin cancer screening, phenotype assessment and risk
stratification, diagnosis of neoplastic and inflammatory skin diseases, skin
lesion segmentation, change monitoring, and metastasis prediction and
prognosis. PanDerm achieved state-of-the-art performance across all evaluated
tasks, often outperforming existing models even when using only 5-10% of
labeled data. PanDerm's clinical utility was demonstrated through reader
studies in real-world clinical settings across multiple imaging modalities. It
outperformed clinicians by 10.2% in early-stage melanoma detection accuracy and
enhanced clinicians' multiclass skin cancer diagnostic accuracy by 11% in a
collaborative human-AI setting. Additionally, PanDerm demonstrated robust
performance across diverse demographic factors, including different body
locations, age groups, genders, and skin tones. The strong results in benchmark
evaluations and real-world clinical scenarios suggest that PanDerm could
enhance the management of skin diseases and serve as a model for developing
multimodal foundation models in other medical specialties, potentially
accelerating the integration of AI support in healthcare.

æè¦ï¼è¨ºæ·åæ²»çç®èç¾çéè¦è·¨å¤åé åçé²éè¦è¦ºæè½ï¼ä»¥åç¶åä¾èªåç¨®å½±åæ¨¡å¼è³è¨çè½åãç®åçæ·±åº¦å­¸ç¿æ¨¡åéç¶å¨ç¹å®ä»»åä¸ææï¼ä¾å¦å¾ç®èé¡å½±åè¨ºæ·ç®èçï¼ä½ç¡æ³æ»¿è¶³è¨åºå¯¦åè¤éçå¤æ¨¡å¼éæ±ãå¨æ­¤ï¼æåæ¨åº PanDermï¼éæ¯ä¸åå¤æ¨¡å¼ç®èç§åºç¤æ¨¡åï¼ééèªç£ç£å­¸ç¿é åè¨ç·´ï¼ä½¿ç¨ä¾èª 4 ç¨®å½±åæ¨¡å¼ã11 åè¨åºæ©æ§ç 200 å¤è¬å¼µçå¯¦ç®èç¾çå½±åè³æéãæåå¨ 28 åæ¶µèä¸ç³»åè¨åºä»»åçå¤åè³æéä¸è©ä¼° PanDermï¼åæ¬ç®èçç¯©æª¢ãè¡¨åè©ä¼°åé¢¨éªåå±¤ãè«ç¤æ§åç¼çæ§ç®èç¾çè¨ºæ·ãç®èçç¶åå²ãè®åç£æ§ä»¥åè½ç§»é æ¸¬åé å¾ãPanDerm å¨ææè©ä¼°ä»»åä¸­é½éå°æåé²çæè½ï¼å³ä½¿åä½¿ç¨ 5-10% çæ¨ç±¤è³æï¼ä¹ç¶å¸¸åªæ¼ç¾ææ¨¡åãPanDerm çè¨åºæç¨å·²ééå¤ç¨®å½±åæ¨¡å¼ççå¯¦è¨åºç°å¢ä¸­çè®èç ç©¶å¾å°è­æãå®å¨æ©æé»è²ç´ ç¤æª¢æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼è¨åºé«ç 10.2%ï¼ä¸¦å¨åä½çäººå·¥æºæ§ç°å¢ä¸­å°è¨åºé«ççå¤é¡ç®èçè¨ºæ·æºç¢ºåº¦æé«äº 11%ãæ­¤å¤ï¼PanDerm å¨ä¸åçèº«é«é¨ä½ãå¹´é½¡çµãæ§å¥åèè²ç­å¤æ¨£åçäººå£çµ±è¨å ç´ ä¸­è¡¨ç¾åºç©©å¥çæè½ãåºæºè©ä¼°åçå¯¦è¨åºå ´æ¯ä¸­çå¼·åçµæè¡¨æï¼PanDerm å¯ä»¥å å¼·ç®èç¾ççç®¡çï¼ä¸¦ä½çºå¨å¶ä»é«å­¸å°ç§éç¼å¤æ¨¡å¼åºç¤æ¨¡åçç¯ä¾ï¼é²èå éå°äººå·¥æºæ§æ¯æ´æ´åå°é«çä¿å¥ä¸­ã

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah HaggenmÃ¼ller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria CompÃ©rat, Andreas Gocht, Monika HÃ¤mmerle, Niels J. Rupp, Jula Westhoff, Irene KrÃ¼cken, Maximillian Seidl, Christian M. SchÃ¼rch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian HÃ¶rner, Kirsten D. Mertz, Constanze DÃ¶ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

æè¦ï¼ååèºçæ¯å¨çç·æ§æå¸¸è¦çççï¼å¶æ¡æ§ç¨åº¦ä¸»è¦æ ¹æ Gleason è©åç³»çµ±ä½¿ç¨çµç¹ççå­¸æ¸æé²è¡è©ä¼°ãéç¶äººå·¥æºæ§ (AI) å¨æºç¢ºé æ¸¬ Gleason è©åæ¹é¢å·²å±ç¾æ½åï¼ä½éäºé æ¸¬éå¸¸ç¼ºä¹å§å¨çå¯è§£éæ§ï¼å¯è½æå°è´å°äººæ©äºåçä¸ä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äºä¸åç± 54 ä½ççå­¸å®¶çµæçåéåéè¨»è§£ç 1,015 åçµç¹å¾®é£åæ ¸å¿å½±åçæ°ç©è³æéãéäºè¨»è§£æä¾äºè©³ç´°çå±é¨æ¨¡å¼æè¿°ï¼ç¨æ¼ç¬¦ååéæºåç Gleason åç´ãå©ç¨éåè³æéï¼æåéç¼äºä¸ååºæ¼ U-Net æ¶æ§çå§å¨å¯è§£é AI ç³»çµ±ï¼è©²ç³»çµ±æä¾äºå©ç¨ççå­¸å®¶è¡èªé²è¡é æ¸¬ãéç¨®æ¹æ³è¦é¿äºäºå¾å¯è§£éæ§æ¹æ³ï¼åæç¶­ææè¶è¶äºç´æ¥è¨ç·´ç¨æ¼ Gleason æ¨¡å¼åå²çæ¹æ³çæè½ï¼Dice åæ¸ï¼0.713 Â± 0.003ï¼è¨ç·´æ¼è§£éï¼ç¸å°æ¼ 0.691 Â± 0.010ï¼è¨ç·´æ¼ Gleason æ¨¡å¼ï¼ãééå¨è¨ç·´æéæ¡ç¨è»æ¨ç±¤ï¼æåææäºè³æä¸­çå§å¨ä¸ç¢ºå®æ§ï¼å³ä½¿å¨è§å¯èéè®ç°æ§é«çææ³ä¸ï¼ä¹è½å¨ Gleason æ¨¡å¼åå²ä¸­ç¢çå¼·å¤§ççµæãéééåºéåè³æéï¼æåæ¨å¨é¼åµé²ä¸æ­¥ç ç©¶ä¸»è§æ§é«çé«çä»»åä¸­çåå²ï¼ä¸¦å¢é²å°ççå­¸å®¶æ¨çéç¨ççè§£ã

##### **Water quality polluted by total suspended solids classified within an Artificial Neural Network approach**
2410.14929v1 by I. Luviano Soto, Y. Concha SÃ¡nchez, A. Raya

This study investigates the application of an artificial neural network
framework for analysing water pollution caused by solids. Water pollution by
suspended solids poses significant environmental and health risks. Traditional
methods for assessing and predicting pollution levels are often time-consuming
and resource-intensive. To address these challenges, we developed a model that
leverages a comprehensive dataset of water quality from total suspended solids.
A convolutional neural network was trained under a transfer learning approach
using data corresponding to different total suspended solids concentrations,
with the goal of accurately predicting low, medium and high pollution levels
based on various input variables. Our model demonstrated high predictive
accuracy, outperforming conventional statistical methods in terms of both speed
and reliability. The results suggest that the artificial neural network
framework can serve as an effective tool for real-time monitoring and
management of water pollution, facilitating proactive decision-making and
policy formulation. This approach not only enhances our understanding of
pollution dynamics but also underscores the potential of machine learning
techniques in environmental science.

æè¦ï¼æ¬ç ç©¶æ¢è¨äººå·¥ç¥ç¶ç¶²è·¯æ¶æ§å¨åæåºé«é ææ°´æ±¡æçæç¨ãæ¸æµ®åºé«é æçæ°´æ±¡ææå¸¶ä¾é¡¯èçç°å¢èå¥åº·é¢¨éªãå³çµ±è©ä¼°èé æ¸¬æ±¡æç¨åº¦çæ¹æ³éå¸¸èæä¸èè²»è³æºãçºäºæå°éäºææ°ï¼æåéç¼äºä¸åæ¨¡åï¼å©ç¨ç¸½æ¸æµ®åºé«çå¨é¢æ°´è³ªè³æéãå·ç©ç¥ç¶ç¶²è·¯å¨é·ç§»å­¸ç¿æ¹æ³ä¸æ¥åè¨ç·´ï¼ä½¿ç¨å°ææ¼ä¸åç¸½æ¸æµ®åºé«æ¿åº¦çè³æï¼ç®æ¨æ¯æ ¹æåç¨®è¼¸å¥è®æ¸æºç¢ºé æ¸¬ä½ãä¸­åé«æ±¡æç¨åº¦ãæåçæ¨¡åå±ç¾åºé«é æ¸¬æºç¢ºåº¦ï¼å¨éåº¦åå¯é åº¦æ¹é¢é½åªæ¼å³çµ±çµ±è¨æ¹æ³ãçµæé¡¯ç¤ºï¼äººå·¥ç¥ç¶ç¶²è·¯æ¶æ§å¯ç¨ä½æ°´æ±¡æçå³æç£æ§åç®¡ççææå·¥å·ï¼ä¿é²ä¸»åæ±ºç­å¶å®åæ¿ç­å¶å®ãéç¨®æ¹æ³ä¸åå¢é²æåå°æ±¡æåæçäºè§£ï¼ä¹å¼·èª¿äºæ©å¨å­¸ç¿æè¡å¨ç°å¢ç§å­¸ä¸­çæ½åã

##### **Less is More: Selective Reduction of CT Data for Self-Supervised Pre-Training of Deep Learning Models with Contrastive Learning Improves Downstream Classification Performance**
2410.14524v1 by Daniel Wolf, Tristan Payer, Catharina Silvia Lisson, Christoph Gerhard Lisson, Meinrad Beer, Michael GÃ¶tz, Timo Ropinski

Self-supervised pre-training of deep learning models with contrastive
learning is a widely used technique in image analysis. Current findings
indicate a strong potential for contrastive pre-training on medical images.
However, further research is necessary to incorporate the particular
characteristics of these images. We hypothesize that the similarity of medical
images hinders the success of contrastive learning in the medical imaging
domain. To this end, we investigate different strategies based on deep
embedding, information theory, and hashing in order to identify and reduce
redundancy in medical pre-training datasets. The effect of these different
reduction strategies on contrastive learning is evaluated on two pre-training
datasets and several downstream classification tasks. In all of our
experiments, dataset reduction leads to a considerable performance gain in
downstream tasks, e.g., an AUC score improvement from 0.78 to 0.83 for the
COVID CT Classification Grand Challenge, 0.97 to 0.98 for the OrganSMNIST
Classification Challenge and 0.73 to 0.83 for a brain hemorrhage classification
task. Furthermore, pre-training is up to nine times faster due to the dataset
reduction. In conclusion, the proposed approach highlights the importance of
dataset quality and provides a transferable approach to improve contrastive
pre-training for classification downstream tasks on medical images.

æè¦ï¼æ·±åº¦å­¸ç¿æ¨¡åçå°æ¯å­¸ç¿èªç£ç£é è¨ç·´æ¯ä¸ç¨®å»£æ³ç¨æ¼å½±ååæçæè¡ãç®åçç¼ç¾é¡¯ç¤ºå°æ¯é è¨ç·´å¨é«å­¸å½±åä¸å·æå¼·å¤§çæ½åãç¶èï¼é²ä¸æ­¥çç ç©¶å°æ¼ç´å¥éäºå½±åçç¹å®ç¹å¾µæ¯å¿è¦çãæååè¨­é«å­¸å½±åçç¸ä¼¼æ§é»ç¤äºå°æ¯å­¸ç¿å¨é«å­¸å½±åé åçæåãçºæ­¤ï¼æåç ç©¶äºåºæ¼æ·±åº¦åµå¥ãè³è¨çè«åéæ¹çä¸åç­ç¥ï¼ä»¥è­å¥åæ¸å°é«å­¸é è¨ç·´è³æéä¸­çåé¤ãéäºä¸åçç°¡åç­ç¥å°æ¯å­¸ç¿çå½±é¿å¨å©åé è¨ç·´è³æéåå¹¾åä¸æ¸¸åé¡ä»»åä¸­é²è¡è©ä¼°ãå¨æåææçå¯¦é©ä¸­ï¼è³æéç°¡åé½å°è´äºä¸æ¸¸ä»»åçé¡¯èæè½æåï¼ä¾å¦ï¼COVID CT åé¡å¤§ææ°ç AUC åæ¸å¾ 0.78 æåè³ 0.83ï¼OrganSMNIST åé¡ææ°å¾ 0.97 æåè³ 0.98ï¼è¦åºè¡åé¡ä»»åå¾ 0.73 æåè³ 0.83ãæ­¤å¤ï¼ç±æ¼è³æéç°¡åï¼é è¨ç·´éåº¦æé«å¯æåä¹åãç¸½ä¹ï¼ææåºçæ¹æ³çªé¡¯äºè³æéåè³ªçéè¦æ§ï¼ä¸¦æä¾äºä¸åå¯è½ç§»çæ¹æ³ä¾æ¹åé«å­¸å½±åä¸åé¡ä¸æ¸¸ä»»åçå°æ¯é è¨ç·´ã

##### **Enabling Scalable Evaluation of Bias Patterns in Medical LLMs**
2410.14763v1 by Hamed Fayyaz, Raphael Poulain, Rahmatollah Beheshti

Large language models (LLMs) have shown impressive potential in helping with
numerous medical challenges. Deploying LLMs in high-stakes applications such as
medicine, however, brings in many concerns. One major area of concern relates
to biased behaviors of LLMs in medical applications, leading to unfair
treatment of individuals. To pave the way for the responsible and impactful
deployment of Med LLMs, rigorous evaluation is a key prerequisite. Due to the
huge complexity and variability of different medical scenarios, existing work
in this domain has primarily relied on using manually crafted datasets for bias
evaluation. In this study, we present a new method to scale up such bias
evaluations by automatically generating test cases based on rigorous medical
evidence. We specifically target the challenges of a) domain-specificity of
bias characterization, b) hallucinating while generating the test cases, and c)
various dependencies between the health outcomes and sensitive attributes. To
that end, we offer new methods to address these challenges integrated with our
generative pipeline, using medical knowledge graphs, medical ontologies, and
customized general LLM evaluation frameworks in our method. Through a series of
extensive experiments, we show that the test cases generated by our proposed
method can effectively reveal bias patterns in Med LLMs at larger and more
flexible scales than human-crafted datasets. We publish a large bias evaluation
dataset using our pipeline, which is dedicated to a few medical case studies. A
live demo of our application for vignette generation is available at
https://vignette.streamlit.app. Our code is also available at
https://github.com/healthylaife/autofair.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºå¨åå©è§£æ±º
è¨±å¤é«çææ°æ¹é¢çé©äººæ½åãç¶èï¼å¨é«é¢¨éªæç¨ç¨å¼ï¼ä¾å¦
é«çï¼ä¸­é¨ç½² LLM æå¸¶ä¾è¨±å¤çæ®ãä¸åä¸»è¦ççæ®é åè
é«çæç¨ç¨å¼ä¸­ LLM çåè¦è¡çºæéï¼å°è´å°åäººä¸å¬å¹³ç
å¾éãçºäºçºè² è²¬ä»»ä¸æå½±é¿åç Med LLM é¨ç½²éªè·¯ï¼å´è¬¹ç
è©ä¼°æ¯ä¸é ééµåæãç±æ¼ä¸åé«çå ´æ¯çè¤éæ§åè®ç°æ§æ¥µå¤§ï¼
æ­¤é åç¾æçå·¥ä½ä¸»è¦ä¾è³´ä½¿ç¨äººå·¥è£½ä½çè³æéé²è¡åè¦
è©ä¼°ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼å¯ä»¥æ ¹æå´è¬¹çé«ç
è­æèªåç¢çæ¸¬è©¦æ¡ä¾ï¼ä»¥æ´å¤§æ­¤é¡åè¦è©ä¼°ãæåç¹å¥éå°
a) åè¦ç¹å¾µçé åå°å±¬æ§ãb) å¨ç¢çæ¸¬è©¦æ¡ä¾æåºç¾å¹»è¦ºï¼ä»¥å c)
å¥åº·çµæåææå±¬æ§ä¹éçåç¨®ä¾è³´æ§ç­ææ°ãçºæ­¤ï¼æåæä¾
æ°çæ¹æ³ä¾è§£æ±ºéäºææ°ï¼ä¸¦å°å¶èæåççæç®¡éæ´åï¼å¨æåç
æ¹æ³ä¸­ä½¿ç¨é«çç¥è­åãé«çæ¬ä½åèªè¨çéç¨ LLM è©ä¼°æ¶æ§ãéé
ä¸ç³»åå»£æ³çå¯¦é©ï¼æåè¡¨ææåæåºçæ¹æ³ç¢ççæ¸¬è©¦æ¡ä¾å¯ä»¥ææ
æ­ç¤º Med LLM ä¸­çåè¦æ¨¡å¼ï¼å¶è¦æ¨¡æ¯äººå·¥è£½ä½çè³æéæ´å¤§ä¸æ´å·
å½æ§ãæåä½¿ç¨æåçç®¡éç¼å¸äºä¸åå¤§ååè¦è©ä¼°è³æéï¼è©²è³æé
å°ééå°ä¸äºé«çæ¡ä¾ç ç©¶ãæåçå°æåçææç¨ç¨å¼çç¾å ´ç¤ºç¯
å¯å¨ https://vignette.streamlit.app åå¾ãæåçç¨å¼ç¢¼ä¹å¯å¨
https://github.com/healthylaife/autofair åå¾ã

##### **A Scientific Machine Learning Approach for Predicting and Forecasting Battery Degradation in Electric Vehicles**
2410.14347v1 by Sharv Murgai, Hrishikesh Bhagwat, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat

Carbon emissions are rising at an alarming rate, posing a significant threat
to global efforts to mitigate climate change. Electric vehicles have emerged as
a promising solution, but their reliance on lithium-ion batteries introduces
the critical challenge of battery degradation. Accurate prediction and
forecasting of battery degradation over both short and long time spans are
essential for optimizing performance, extending battery life, and ensuring
effective long-term energy management. This directly influences the
reliability, safety, and sustainability of EVs, supporting their widespread
adoption and aligning with key UN SDGs. In this paper, we present a novel
approach to the prediction and long-term forecasting of battery degradation
using Scientific Machine Learning framework which integrates domain knowledge
with neural networks, offering more interpretable and scientifically grounded
solutions for both predicting short-term battery health and forecasting
degradation over extended periods. This hybrid approach captures both known and
unknown degradation dynamics, improving predictive accuracy while reducing data
requirements. We incorporate ground-truth data to inform our models, ensuring
that both the predictions and forecasts reflect practical conditions. The model
achieved MSE of 9.90 with the UDE and 11.55 with the NeuralODE, in experimental
data, a loss of 1.6986 with the UDE, and a MSE of 2.49 in the NeuralODE,
demonstrating the enhanced precision of our approach. This integration of
data-driven insights with SciML's strengths in interpretability and scalability
allows for robust battery management. By enhancing battery longevity and
minimizing waste, our approach contributes to the sustainability of energy
systems and accelerates the global transition toward cleaner, more responsible
energy solutions, aligning with the UN's SDG agenda.

æè¦ï¼ç¢³ææ¾éæ­£ä»¥é©äººçéåº¦ä¸åï¼å°å¨çæ¸ç·©æ°£åè®é·çåªåæ§æéå¤§å¨èãé»åè»å·²æçºä¸åæå¸æçè§£æ±ºæ¹æ¡ï¼ä½å®åä¾è³´é°é¢å­é»æ± ï¼å¼å¥äºé»æ± å£åéåå´å³»çææ°ãæºç¢ºé æ¸¬åé æ¸¬é»æ± å¨ç­æåé·æå§çå£åå°æ¼æä½³åæè½ãå»¶é·é»æ± å£½å½ä»¥åç¢ºä¿ææçé·æè½æºç®¡çè³ééè¦ãéç´æ¥å½±é¿é»åè»çå¯é æ§ãå®å¨æ§èæ°¸çºæ§ï¼æ¯æå®åçå»£æ³æ¡ç¨ï¼ä¸¦èè¯ååæ°¸çºç¼å±ç®æ¨ä¿æä¸è´ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ä½¿ç¨ç§å­¸æ©å¨å­¸ç¿æ¡æ¶ä¾é æ¸¬åé·æé æ¸¬é»æ± å£åï¼è©²æ¡æ¶å°é åç¥è­èç¥ç¶ç¶²è·¯æ´åå¨ä¸èµ·ï¼çºé æ¸¬ç­æé»æ± å¥åº·çæ³åé æ¸¬é·æå£åæä¾æ´å·å¯è§£éæ§åç§å­¸ä¾æçè§£æ±ºæ¹æ¡ãéç¨®æ··åæ¹æ³ææå·²ç¥åæªç¥çå£ååæï¼å¨æ¸å°è³æéæ±çåææé«é æ¸¬æºç¢ºåº¦ãæåç´å¥çå¯¦è³æä¾åç¥æåçæ¨¡åï¼ç¢ºä¿é æ¸¬åé æ¸¬é½åæ å¯¦éææ³ãè©²æ¨¡åå¨å¯¦é©è³æä¸­ä½¿ç¨ UDE éå° 9.90 ç MSEï¼ä½¿ç¨ NeuralODE éå° 11.55ï¼ä½¿ç¨ UDE æå¤± 1.6986ï¼ä½¿ç¨ NeuralODE éå° 2.49 ç MSEï¼è­æäºæåæ¹æ³çç²¾ç¢ºåº¦æææåãå°è³æé©åçæ´å¯è SciML å¨å¯è§£éæ§åå¯æ´åæ§æ¹é¢çåªå¢ç¸çµåï¼å¯ä»¥å¯¦ç¾å¼·å¤§çé»æ± ç®¡çãééæåé»æ± å£½å½åæ¸å°æµªè²»ï¼æåçåæ³æå©æ¼è½æºç³»çµ±æ°¸çºç¼å±ï¼ä¸¦å éå¨çæåæ´æ¸æ½ãæ´è² è²¬ä»»çè½æºè§£æ±ºæ¹æ¡éæ¸¡ï¼èè¯ååæ°¸çºç¼å±ç®æ¨è­°ç¨ä¿æä¸è´ã

##### **Deep Learning Applications in Medical Image Analysis: Advancements, Challenges, and Future Directions**
2410.14131v1 by Aimina Ali Eli, Abida Ali

Medical image analysis has emerged as an essential element of contemporary
healthcare, facilitating physicians in achieving expedited and precise
diagnosis. Recent breakthroughs in deep learning, a subset of artificial
intelligence, have markedly revolutionized the analysis of medical pictures,
improving the accuracy and efficiency of clinical procedures. Deep learning
algorithms, especially convolutional neural networks (CNNs), have demonstrated
remarkable proficiency in autonomously learning features from multidimensional
medical pictures, including MRI, CT, and X-ray scans, without the necessity for
manual feature extraction. These models have been utilized across multiple
medical disciplines, including pathology, radiology, ophthalmology, and
cardiology, where they aid in illness detection, classification, and
segmentation tasks......

æè¦ï¼é«çå½±ååæå·²æçºç¾ä»£é«çä¿å¥ä¸­ä¸å¯æç¼ºçåç´ ï¼åå©é«å¸«å¿«éä¸ç²¾ç¢ºå°é²è¡è¨ºæ·ãæ·±åº¦å­¸ç¿ï¼äººå·¥æºæ§çå­éï¼çææ°çªç ´é¡¯èå°é©æ°äºé«å­¸å½±åçåæï¼æåè¨åºç¨åºçæºç¢ºæ§åæçãæ·±åº¦å­¸ç¿æ¼ç®æ³ï¼å°¤å¶æ¯å·ç©ç¥ç¶ç¶²è·¯ï¼CNNï¼ï¼å·²å±ç¾åºå¾å¤ç¶­åº¦é«å­¸å½±åï¼åæ¬ MRIãCT å X åææï¼ä¸­èªä¸»å­¸ç¿ç¹å¾µçåè¶è½åï¼ç¡éæåç¹å¾µèåãéäºæ¨¡åå·²æç¨æ¼å¤ç¨®é«å­¸é åï¼åæ¬ççå­¸ãæ¾å°å­¸ãç¼ç§å­¸åå¿èçå­¸ï¼åå©ç¾çåµæ¸¬ãåé¡ååå²ä»»å......


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-30**|**Provable acceleration for diffusion models under minimal assumptions**|Gen Li et.al.|[2410.23285v1](http://arxiv.org/abs/2410.23285v1)|null|
|**2024-10-30**|**A Neural Transformer Framework for Simultaneous Tasks of Segmentation, Classification, and Caller Identification of Marmoset Vocalization**|Bin Wu et.al.|[2410.23279v1](http://arxiv.org/abs/2410.23279v1)|null|
|**2024-10-30**|**SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation**|Yining Hong et.al.|[2410.23277v1](http://arxiv.org/abs/2410.23277v1)|null|
|**2024-10-30**|**Multi-student Diffusion Distillation for Better One-step Generators**|Yanke Song et.al.|[2410.23274v1](http://arxiv.org/abs/2410.23274v1)|null|
|**2024-10-30**|**A Monte Carlo Framework for Calibrated Uncertainty Estimation in Sequence Prediction**|Qidong Yang et.al.|[2410.23272v1](http://arxiv.org/abs/2410.23272v1)|null|
|**2024-10-30**|**TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models**|Ziyao Shangguan et.al.|[2410.23266v1](http://arxiv.org/abs/2410.23266v1)|[link](https://github.com/yale-nlp/TOMATO)|
|**2024-10-30**|**EMMA: End-to-End Multimodal Model for Autonomous Driving**|Jyh-Jing Hwang et.al.|[2410.23262v1](http://arxiv.org/abs/2410.23262v1)|null|
|**2024-10-30**|**$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources**|Apoorv Khandelwal et.al.|[2410.23261v1](http://arxiv.org/abs/2410.23261v1)|[link](https://github.com/apoorvkh/academic-pretraining)|
|**2024-10-30**|**Keypoint Abstraction using Large Models for Object-Relative Imitation Learning**|Xiaolin Fang et.al.|[2410.23254v1](http://arxiv.org/abs/2410.23254v1)|null|
|**2024-10-30**|**Evaluating Cultural and Social Awareness of LLM Web Agents**|Haoyi Qiu et.al.|[2410.23252v1](http://arxiv.org/abs/2410.23252v1)|null|
|**2024-10-30**|**A little less conversation, a little more action, please: Investigating the physical common-sense of LLMs in a 3D embodied environment**|Matteo G. Mecattaf et.al.|[2410.23242v1](http://arxiv.org/abs/2410.23242v1)|null|
|**2024-10-30**|**EMOTION: Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning**|Peide Huang et.al.|[2410.23234v1](http://arxiv.org/abs/2410.23234v1)|null|
|**2024-10-30**|**Aligning Audio-Visual Joint Representations with an Agentic Workflow**|Shentong Mo et.al.|[2410.23230v2](http://arxiv.org/abs/2410.23230v2)|null|
|**2024-10-30**|**COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences**|Yixin Liu et.al.|[2410.23223v1](http://arxiv.org/abs/2410.23223v1)|[link](https://github.com/yale-nlp/comal)|
|**2024-10-30**|**Partial Channel Dependence with Channel Masks for Time Series Foundation Models**|Seunghan Lee et.al.|[2410.23222v1](http://arxiv.org/abs/2410.23222v1)|null|
|**2024-10-30**|**OS-ATLAS: A Foundation Action Model for Generalist GUI Agents**|Zhiyong Wu et.al.|[2410.23218v1](http://arxiv.org/abs/2410.23218v1)|null|
|**2024-10-30**|**Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval**|Sheryl Hsu et.al.|[2410.23214v2](http://arxiv.org/abs/2410.23214v2)|null|
|**2024-10-30**|**Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks**|Michael Matthews et.al.|[2410.23208v1](http://arxiv.org/abs/2410.23208v1)|null|
|**2024-10-30**|**Reliability of Topic Modeling**|Kayla Schroeder et.al.|[2410.23186v1](http://arxiv.org/abs/2410.23186v1)|null|
|**2024-10-30**|**ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**|Zhichao Hou et.al.|[2410.23182v1](http://arxiv.org/abs/2410.23182v1)|null|
|**2024-10-30**|**ReasoningRec: Bridging Personalized Recommendations and Human-Interpretable Explanations through LLM Reasoning**|Millennium Bismay et.al.|[2410.23180v1](http://arxiv.org/abs/2410.23180v1)|[link](https://github.com/millenniumbismay/reasoningrec)|
|**2024-10-30**|**SciPIP: An LLM-based Scientific Paper Idea Proposer**|Wenxiao Wang et.al.|[2410.23166v1](http://arxiv.org/abs/2410.23166v1)|null|
|**2024-10-30**|**FlexTSF: A Universal Forecasting Model for Time Series with Variable Regularities**|Jingge Xiao et.al.|[2410.23160v1](http://arxiv.org/abs/2410.23160v1)|null|
|**2024-10-30**|**Fourier Amplitude and Correlation Loss: Beyond Using L2 Loss for Skillful Precipitation Nowcasting**|Chiu-Wai Yan et.al.|[2410.23159v1](http://arxiv.org/abs/2410.23159v1)|[link](https://github.com/argenycw/facl)|
|**2024-10-30**|**VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning**|Yichao Liang et.al.|[2410.23156v1](http://arxiv.org/abs/2410.23156v1)|null|
|**2024-10-30**|**Public Domain 12M: A Highly Aesthetic Image-Text Dataset with Novel Governance Mechanisms**|Jordan Meyer et.al.|[2410.23144v1](http://arxiv.org/abs/2410.23144v1)|null|
|**2024-10-30**|**Fair Division with Market Values**|Siddharth Barman et.al.|[2410.23137v1](http://arxiv.org/abs/2410.23137v1)|null|
|**2024-10-30**|**Crowdsourcing Lexical Diversity**|Hadi Khalilia et.al.|[2410.23133v1](http://arxiv.org/abs/2410.23133v1)|null|
|**2024-10-30**|**Revisiting MAE pre-training for 3D medical image segmentation**|Tassilo Wald et.al.|[2410.23132v1](http://arxiv.org/abs/2410.23132v1)|null|
|**2024-10-30**|**Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes**|Jerry Yao-Chieh Hu et.al.|[2410.23126v1](http://arxiv.org/abs/2410.23126v1)|null|
|**2024-10-30**|**On Memorization of Large Language Models in Logical Reasoning**|Chulin Xie et.al.|[2410.23123v1](http://arxiv.org/abs/2410.23123v1)|null|
|**2024-10-30**|**Teaching a Language Model to Distinguish Between Similar Details using a Small Adversarial Training Set**|Chris Achard et.al.|[2410.23118v1](http://arxiv.org/abs/2410.23118v1)|null|
|**2024-10-30**|**Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models**|Junjie Wu et.al.|[2410.23114v1](http://arxiv.org/abs/2410.23114v1)|[link](https://github.com/wujunjie1998/tri-he)|
|**2024-10-30**|**Why Gradient Subspace? Identifying and Mitigating LoRA's Bottlenecks in Federated Fine-Tuning of Large Language Models**|Navyansh Mahla et.al.|[2410.23111v2](http://arxiv.org/abs/2410.23111v2)|null|
|**2024-10-30**|**Controllable Game Level Generation: Assessing the Effect of Negative Examples in GAN Models**|Mahsa Bazzaz et.al.|[2410.23108v1](http://arxiv.org/abs/2410.23108v1)|null|
|**2024-10-30**|**Guided Game Level Repair via Explainable AI**|Mahsa Bazzaz et.al.|[2410.23101v1](http://arxiv.org/abs/2410.23101v1)|null|
|**2024-10-30**|**Comparative Analysis of Demonstration Selection Algorithms for LLM In-Context Learning**|Dong Shu et.al.|[2410.23099v1](http://arxiv.org/abs/2410.23099v1)|[link](https://github.com/tizzzzy/demonstration_selection_overview)|
|**2024-10-30**|**CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation**|Yiruo Cheng et.al.|[2410.23090v1](http://arxiv.org/abs/2410.23090v1)|null|
|**2024-10-30**|**BUZZ: Beehive-structured Sparse KV Cache with Segmented Heavy Hitters for Efficient LLM Inference**|Junqi Zhao et.al.|[2410.23079v1](http://arxiv.org/abs/2410.23079v1)|[link](https://github.com/junqizhao888/buzz-llm)|
|**2024-10-30**|**Multi-Programming Language Sandbox for LLMs**|Shihan Dou et.al.|[2410.23074v1](http://arxiv.org/abs/2410.23074v1)|null|
|**2024-10-30**|**CNN Explainability with Multivector Tucker Saliency Maps for Self-Supervised Models**|Aymene Mohammed Bouayed et.al.|[2410.23072v1](http://arxiv.org/abs/2410.23072v1)|null|
|**2024-10-30**|**LLMs Integration in Software Engineering Team Projects: Roles, Impact, and a Pedagogical Design Space for AI Tools in Computing Education**|Ahmed Kharrufa et.al.|[2410.23069v1](http://arxiv.org/abs/2410.23069v1)|null|
|**2024-10-30**|**Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification**|Debjyoti Saharoy et.al.|[2410.23066v1](http://arxiv.org/abs/2410.23066v1)|null|
|**2024-10-30**|**Controlling Language and Diffusion Models by Transporting Activations**|Pau Rodriguez et.al.|[2410.23054v1](http://arxiv.org/abs/2410.23054v1)|null|
|**2024-10-30**|**Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval**|Le Huang et.al.|[2410.23041v1](http://arxiv.org/abs/2410.23041v1)|null|
|**2024-10-30**|**Offline Reinforcement Learning and Sequence Modeling for Downlink Link Adaptation**|Samuele Peri et.al.|[2410.23031v1](http://arxiv.org/abs/2410.23031v1)|null|
|**2024-10-30**|**Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback**|Qinqing Zheng et.al.|[2410.23022v1](http://arxiv.org/abs/2410.23022v1)|null|
|**2024-10-30**|**Long$^2$RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall**|Zehan Qi et.al.|[2410.23000v2](http://arxiv.org/abs/2410.23000v2)|null|
|**2024-10-30**|**A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics**|Jonas Bode et.al.|[2410.22997v1](http://arxiv.org/abs/2410.22997v1)|[link](https://github.com/ais-bonn/prompt_engineering)|
|**2024-10-30**|**Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**|Deperias Kerre et.al.|[2410.22996v1](http://arxiv.org/abs/2410.22996v1)|null|
|**2024-10-30**|**VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning**|Jingkun Ma et.al.|[2410.22995v1](http://arxiv.org/abs/2410.22995v1)|null|
|**2024-10-30**|**Higher-order Cross-structural Embedding Model for Time Series Analysis**|Guancen Lin et.al.|[2410.22984v1](http://arxiv.org/abs/2410.22984v1)|null|
|**2024-10-30**|**Bonafide at LegalLens 2024 Shared Task: Using Lightweight DeBERTa Based Encoder For Legal Violation Detection and Resolution**|Shikha Bordia et.al.|[2410.22977v1](http://arxiv.org/abs/2410.22977v1)|null|
|**2024-10-30**|**Private Synthetic Text Generation with Diffusion Models**|Sebastian Ochs et.al.|[2410.22971v1](http://arxiv.org/abs/2410.22971v1)|null|
|**2024-10-30**|**Efficient Adaptation of Pre-trained Vision Transformer via Householder Transformation**|Wei Dong et.al.|[2410.22952v1](http://arxiv.org/abs/2410.22952v1)|null|
|**2024-10-30**|**SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry**|Ankita Kumari Jain et.al.|[2410.22950v1](http://arxiv.org/abs/2410.22950v1)|null|
|**2024-10-30**|**Focus On This, Not That! Steering LLMs With Adaptive Feature Specification**|Tom A. Lamb et.al.|[2410.22944v1](http://arxiv.org/abs/2410.22944v1)|null|
|**2024-10-30**|**DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data**|Hanyang Chen et.al.|[2410.22938v2](http://arxiv.org/abs/2410.22938v2)|[link](https://github.com/lokol5579/DiffLight-release)|
|**2024-10-30**|**Thoughtful Adoption of NLP for Civic Participation: Understanding Differences Among Policymakers**|Jose A. Guridi et.al.|[2410.22937v1](http://arxiv.org/abs/2410.22937v1)|null|
|**2024-10-30**|**Multi-Agent Large Language Models for Conversational Task-Solving**|Jonas Becker et.al.|[2410.22932v1](http://arxiv.org/abs/2410.22932v1)|null|
|**2024-10-30**|**BIS: NL2SQL Service Evaluation Benchmark for Business Intelligence Scenarios**|Bora Caglayan et.al.|[2410.22925v1](http://arxiv.org/abs/2410.22925v1)|[link](https://github.com/boracaglayan/bis-nl2sql)|
|**2024-10-30**|**Explainable Behavior Cloning: Teaching Large Language Model Agents through Learning by Demonstration**|Yanchu Guan et.al.|[2410.22916v1](http://arxiv.org/abs/2410.22916v1)|null|
|**2024-10-30**|**From Babble to Words: Pre-Training Language Models on Continuous Streams of Phonemes**|ZÃ©bulon Goriely et.al.|[2410.22906v1](http://arxiv.org/abs/2410.22906v1)|null|
|**2024-10-30**|**YOLOv11 for Vehicle Detection: Advancements, Performance, and Applications in Intelligent Transportation Systems**|Mujadded Al Rabbani Alif et.al.|[2410.22898v1](http://arxiv.org/abs/2410.22898v1)|null|
|**2024-10-30**|**VPO: Leveraging the Number of Votes in Preference Optimization**|Jae Hyeon Cho et.al.|[2410.22891v1](http://arxiv.org/abs/2410.22891v1)|[link](https://github.com/ku-dmlab/vpo)|
|**2024-10-30**|**Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector**|Youcheng Huang et.al.|[2410.22888v1](http://arxiv.org/abs/2410.22888v1)|[link](https://github.com/mob-scu/radar-nearside)|
|**2024-10-30**|**Less is More: Pre-Training Cross-Lingual Small-Scale Language Models with Cognitively-Plausible Curriculum Learning Strategies**|Suchir Salhan et.al.|[2410.22886v1](http://arxiv.org/abs/2410.22886v1)|[link](https://github.com/suchirsalhan/mao-climb)|
|**2024-10-30**|**Stealing User Prompts from Mixture of Experts**|Itay Yona et.al.|[2410.22884v1](http://arxiv.org/abs/2410.22884v1)|null|
|**2024-10-30**|**Adaptive Paradigm Synergy: Can a Cross-Paradigm Objective Enhance Long-Tailed Learning?**|Haowen Xiao et.al.|[2410.22883v1](http://arxiv.org/abs/2410.22883v1)|null|
|**2024-10-30**|**SFA-UNet: More Attention to Multi-Scale Contrast and Contextual Information in Infrared Small Object Segmentation**|Imad Ali Shah et.al.|[2410.22881v1](http://arxiv.org/abs/2410.22881v1)|[link](https://github.com/imadalishah/sfa_unet)|
|**2024-10-30**|**Eliciting Critical Reasoning in Retrieval-Augmented Language Models via Contrastive Explanations**|Leonardo Ranaldi et.al.|[2410.22874v1](http://arxiv.org/abs/2410.22874v1)|null|
|**2024-10-30**|**Conditioned quantum-assisted deep generative surrogate for particle-calorimeter interactions**|J. Quetzalcoatl Toledo-Marin et.al.|[2410.22870v1](http://arxiv.org/abs/2410.22870v1)|null|
|**2024-10-30**|**Danoliteracy of Generative, Large Language Models**|SÃ¸ren Vejlgaard Holm et.al.|[2410.22839v1](http://arxiv.org/abs/2410.22839v1)|null|
|**2024-10-30**|**HijackRAG: Hijacking Attacks against Retrieval-Augmented Large Language Models**|Yucheng Zhang et.al.|[2410.22832v1](http://arxiv.org/abs/2410.22832v1)|null|
|**2024-10-30**|**How Well Do Large Language Models Disambiguate Swedish Words?**|Richard Johansson et.al.|[2410.22827v1](http://arxiv.org/abs/2410.22827v1)|null|
|**2024-10-30**|**EvoCodeBench: An Evolving Code Generation Benchmark with Domain-Specific Evaluations**|Jia Li et.al.|[2410.22821v1](http://arxiv.org/abs/2410.22821v1)|null|
|**2024-10-30**|**Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients**|Jabin Koo et.al.|[2410.22815v1](http://arxiv.org/abs/2410.22815v1)|null|
|**2024-10-30**|**Universality of the $Ï^2/6$ Pathway in Avoiding Model Collapse**|Apratim Dey et.al.|[2410.22812v1](http://arxiv.org/abs/2410.22812v1)|null|
|**2024-10-30**|**Causality-Enhanced Behavior Sequence Modeling in LLMs for Personalized Recommendation**|Yang Zhang et.al.|[2410.22809v1](http://arxiv.org/abs/2410.22809v1)|[link](https://github.com/itsmeyjt/cft)|
|**2024-10-30**|**Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation**|Chengkai Huang et.al.|[2410.22790v1](http://arxiv.org/abs/2410.22790v1)|null|
|**2024-10-30**|**MALoRA: Mixture of Asymmetric Low-Rank Adaptation for Enhanced Multi-Task Learning**|Xujia Wang et.al.|[2410.22782v1](http://arxiv.org/abs/2410.22782v1)|null|
|**2024-10-30**|**InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models**|Hao Li et.al.|[2410.22770v1](http://arxiv.org/abs/2410.22770v1)|[link](https://github.com/safolab-wisc/injecguard)|
|**2024-10-30**|**Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**|Sejin Lee et.al.|[2410.22767v1](http://arxiv.org/abs/2410.22767v1)|[link](https://github.com/eastha0526/beyond-ontology-in-dst)|
|**2024-10-30**|**Self-Driving Car Racing: Application of Deep Reinforcement Learning**|Florentiana Yuwono et.al.|[2410.22766v1](http://arxiv.org/abs/2410.22766v1)|null|
|**2024-10-30**|**Constructing Multimodal Datasets from Scratch for Rapid Development of a Japanese Visual Language Model**|Keito Sasagawa et.al.|[2410.22736v1](http://arxiv.org/abs/2410.22736v1)|null|
|**2024-10-30**|**st-DTPM: Spatial-Temporal Guided Diffusion Transformer Probabilistic Model for Delayed Scan PET Image Prediction**|Ran Hong et.al.|[2410.22732v1](http://arxiv.org/abs/2410.22732v1)|null|
|**2024-10-30**|**Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization**|Kento Kawaharazuka et.al.|[2410.22707v1](http://arxiv.org/abs/2410.22707v1)|null|
|**2024-10-30**|**Permutation Invariant Learning with High-Dimensional Particle Filters**|Akhilan Boopathy et.al.|[2410.22695v1](http://arxiv.org/abs/2410.22695v1)|null|
|**2024-10-30**|**Choice between Partial Trajectories**|Henrik Marklund et.al.|[2410.22690v1](http://arxiv.org/abs/2410.22690v1)|null|
|**2024-10-30**|**Multi-Task Interactive Robot Fleet Learning with Visual World Models**|Huihan Liu et.al.|[2410.22689v1](http://arxiv.org/abs/2410.22689v1)|null|
|**2024-10-30**|**Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings**|Yashvir S. Grewal et.al.|[2410.22685v1](http://arxiv.org/abs/2410.22685v1)|null|
|**2024-10-30**|**Backdoor Attack Against Vision Transformers via Attention Gradient-Based Image Erosion**|Ji Guo et.al.|[2410.22678v1](http://arxiv.org/abs/2410.22678v1)|null|
|**2024-10-30**|**Automated Trustworthiness Oracle Generation for Machine Learning Text Classifiers**|Lam Nguyen Tung et.al.|[2410.22663v1](http://arxiv.org/abs/2410.22663v1)|null|
|**2024-10-30**|**$\textbf{EMOS}$: $\textbf{E}$mbodiment-aware Heterogeneous $\textbf{M}$ulti-robot $\textbf{O}$perating $\textbf{S}$ystem with LLM Agents**|Junting Chen et.al.|[2410.22662v1](http://arxiv.org/abs/2410.22662v1)|null|
|**2024-10-30**|**Linguistics Theory Meets LLM: Code-Switched Text Generation via Equivalence Constrained Large Language Models**|Garry Kuwanto et.al.|[2410.22660v1](http://arxiv.org/abs/2410.22660v1)|null|
|**2024-10-30**|**Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation**|Daehee Lee et.al.|[2410.22658v1](http://arxiv.org/abs/2410.22658v1)|null|
|**2024-10-30**|**Prove Your Point!: Bringing Proof-Enhancement Principles to Argumentative Essay Generation**|Ruiyu Xiao et.al.|[2410.22642v1](http://arxiv.org/abs/2410.22642v1)|null|
|**2024-10-30**|**Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection**|Plabon Paul et.al.|[2410.22619v1](http://arxiv.org/abs/2410.22619v1)|null|
|**2024-10-30**|**CoGS: Model Agnostic Causality Constrained Counterfactual Explanations using goal-directed ASP**|Sopam Dasgupta et.al.|[2410.22615v1](http://arxiv.org/abs/2410.22615v1)|null|
|**2024-10-29**|**Are Large-Language Models Graph Algorithmic Reasoners?**|Alexander K Taylor et.al.|[2410.22597v1](http://arxiv.org/abs/2410.22597v1)|null|

#### Abstracts
##### **Provable acceleration for diffusion models under minimal assumptions**
2410.23285v1 by Gen Li, Changxiao Cai

While score-based diffusion models have achieved exceptional sampling
quality, their sampling speeds are often limited by the high computational
burden of score function evaluations. Despite the recent remarkable empirical
advances in speeding up the score-based samplers, theoretical understanding of
acceleration techniques remains largely limited. To bridge this gap, we propose
a novel training-free acceleration scheme for stochastic samplers. Under
minimal assumptions -- namely, $L^2$-accurate score estimates and a finite
second-moment condition on the target distribution -- our accelerated sampler
provably achieves $\varepsilon$-accuracy in total variation within
$\widetilde{O}(d^{5/4}/\sqrt{\varepsilon})$ iterations, thereby significantly
improving upon the $\widetilde{O}(d/\varepsilon)$ iteration complexity of
standard score-based samplers. Notably, our convergence theory does not rely on
restrictive assumptions on the target distribution or higher-order score
estimation guarantees.

æè¦ï¼åç®¡åºæ¼åæ¸çæ´æ£æ¨¡åå·²éå°åªç°çåæ¨£åè³ªï¼ä½å¶åæ¨£éåº¦å¾å¾åå°åæ¸å½æ¸è©ä¼°çé«éç®è² ææéå¶ãåç®¡è¿æå¨å éåºæ¼åæ¸çåæ¨£å¨æ¹é¢æé¡¯èçç¶é©é²å±ï¼ä½å°å éæè¡ççè«çè§£å¨å¾å¤§ç¨åº¦ä¸ä»ç¶æéãçºäºå½è£éåå·®è·ï¼æåæåºäºä¸ç¨®æ°ç©çåè¨ç·´å éæ¹æ¡ï¼ç¨æ¼é¨æ©åæ¨£å¨ãå¨æå°çåè¨­ä¸ââå³ $L^2$ ç²¾ç¢ºåæ¸ä¼°è¨åç®æ¨åä½ä¸çæéäºéç©æ¢ä»¶ââæåçå éåæ¨£å¨å¯è­æå¨ç¸½è®ç°ä¸­éå° $\varepsilon$ ç²¾ç¢ºåº¦ï¼å¨ $\widetilde{O}(d^{5/4}/\sqrt{\varepsilon})$ è¿­ä»£æ¬¡æ¸å§ï¼å¾èé¡¯èæ¹åæ¨æºåºæ¼åæ¸çåæ¨£å¨ç $\widetilde{O}(d/\varepsilon)$ è¿­ä»£è¤éåº¦ãå¼å¾æ³¨æçæ¯ï¼æåçæ¶æçè«ä¸ä¾è³´æ¼ç®æ¨åä½æé«éåæ¸ä¼°è¨ä¿è­çéå¶æ§åè¨­ã

##### **A Neural Transformer Framework for Simultaneous Tasks of Segmentation, Classification, and Caller Identification of Marmoset Vocalization**
2410.23279v1 by Bin Wu, Sakriani Sakti, Shinnosuke Takamichi, Satoshi Nakamura

Marmoset, a highly vocalized primate, has become a popular animal model for
studying social-communicative behavior and its underlying mechanism. In the
study of vocal communication, it is vital to know the caller identities, call
contents, and vocal exchanges. Previous work of a CNN has achieved a joint
model for call segmentation, classification, and caller identification for
marmoset vocalizations. However, the CNN has limitations in modeling long-range
acoustic patterns; the Transformer architecture that has been shown to
outperform CNNs, utilizes the self-attention mechanism that efficiently
segregates information parallelly over long distances and captures the global
structure of marmoset vocalization. We propose using the Transformer to jointly
segment and classify the marmoset calls and identify the callers for each
vocalization.

æè¦ï¼ç¨ç´æ¯ä¸ç§éå¸¸åäºåå£°ççµé¿ç±»å¨ç©ï¼å·²æä¸ºç ç©¶ç¤¾ä¼äº¤æµè¡ä¸ºåå¶æ½å¨æºå¶çæµè¡å¨ç©æ¨¡åãå¨è¯­é³äº¤æµçç ç©¶ä¸­ï¼äºè§£å¼å«èçèº«ä»½ãå¼å«åå®¹åè¯­é³äº¤æµè³å³éè¦ãååå³äº CNN çç ç©¶å·²éå¯¹ç¨ç´åå£°å®ç°äºå¼å«åå²ãåç±»åå¼å«èè¯å«çèåæ¨¡åãç¶èï¼CNN å¨å»ºæ¨¡è¿ç¨å£°å­¦æ¨¡å¼æ¹é¢å­å¨å±éæ§ï¼å·²è¯æä¼äº CNN ç Transformer æ¶æå©ç¨èªæ³¨æåæºå¶ï¼è¯¥æºå¶ææå°å°ä¿¡æ¯å¹¶è¡éç¦»å¨è¿è·ç¦»ä¸ï¼å¹¶æè·ç¨ç´åå£°çå¨å±ç»æãæä»¬å»ºè®®ä½¿ç¨ Transformer æ¥èååå²ååç±»ç¨ç´å¼å«ï¼å¹¶è¯å«æ¯ä¸ªåå£°çå¼å«èã

##### **SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation**
2410.23277v1 by Yining Hong, Beide Liu, Maxine Wu, Yuanhao Zhai, Kai-Wei Chang, Lingjie Li, Kevin Lin, Chung-Ching Lin, Jianfeng Wang, Zhengyuan Yang, Yingnian Wu, Lijuan Wang

Human beings are endowed with a complementary learning system, which bridges
the slow learning of general world dynamics with fast storage of episodic
memory from a new experience. Previous video generation models, however,
primarily focus on slow learning by pre-training on vast amounts of data,
overlooking the fast learning phase crucial for episodic memory storage. This
oversight leads to inconsistencies across temporally distant frames when
generating longer videos, as these frames fall beyond the model's context
window. To this end, we introduce SlowFast-VGen, a novel dual-speed learning
system for action-driven long video generation. Our approach incorporates a
masked conditional video diffusion model for the slow learning of world
dynamics, alongside an inference-time fast learning strategy based on a
temporal LoRA module. Specifically, the fast learning process updates its
temporal LoRA parameters based on local inputs and outputs, thereby efficiently
storing episodic memory in its parameters. We further propose a slow-fast
learning loop algorithm that seamlessly integrates the inner fast learning loop
into the outer slow learning loop, enabling the recall of prior multi-episode
experiences for context-aware skill learning. To facilitate the slow learning
of an approximate world model, we collect a large-scale dataset of 200k videos
with language action annotations, covering a wide range of scenarios. Extensive
experiments show that SlowFast-VGen outperforms baselines across various
metrics for action-driven video generation, achieving an FVD score of 514
compared to 782, and maintaining consistency in longer videos, with an average
of 0.37 scene cuts versus 0.89. The slow-fast learning loop algorithm
significantly enhances performances on long-horizon planning tasks as well.
Project Website: https://slowfast-vgen.github.io

æè¦ï¼<paragraph>äººé¡è¢«è³¦äºä¸åäºè£çå­¸ç¿ç³»çµ±ï¼å®å°ä¸è¬ä¸çåæçç·©æ¢å­¸ç¿èä¾èªæ°ç¶é©çå¿«éæç¯è¨æ¶å²å­è¯ç¹«èµ·ä¾ãç¶èï¼ååçå½±ççææ¨¡åä¸»è¦ééå¤§éè³æçé åè¨ç·´ä¾å°æ³¨æ¼ç·©æ¢å­¸ç¿ï¼å¿½è¦äºå°æç¯è¨æ¶å²å­è³ééè¦çå¿«éå­¸ç¿éæ®µãéç¨®çå¿½å°è´å¨çæè¼é·å½±çæï¼æéä¸ç¸è·çé çå½±æ ¼ä¹éåºç¾ä¸ä¸è´ï¼å çºéäºå½±æ ¼è¶åºäºæ¨¡åçä¸ä¸æè¦çªãçºæ­¤ï¼æåå¼å¥äº SlowFast-VGenï¼éæ¯ä¸åç¨æ¼åä½é©åçé·å½±ççæçæ°åééå­¸ç¿ç³»çµ±ãæåçåæ³çµåäºä¸åç¨æ¼ä¸çåæç·©æ¢å­¸ç¿çé®ç½©æ¢ä»¶å½±çæ´æ£æ¨¡åï¼ä»¥åä¸ååºæ¼æé LoRA æ¨¡çµçæ¨è«æéå¿«éå­¸ç¿ç­ç¥ãå·é«ä¾èªªï¼å¿«éå­¸ç¿éç¨æ ¹æå±é¨è¼¸å¥åè¼¸åºæ´æ°å¶æé LoRA åæ¸ï¼å¾èææå°å°æç¯è¨æ¶å²å­å¨å¶åæ¸ä¸­ãæåé²ä¸æ­¥æåºäºä¸åç·©æ¢-å¿«éå­¸ç¿è¿´åæ¼ç®æ³ï¼å®å°å§é¨çå¿«éå­¸ç¿è¿´åç¡ç¸«æ´åå°å¤é¨çç·©æ¢å­¸ç¿è¿´åä¸­ï¼ä½¿è½å¤ åæ³èµ·ååçå¤æç¯ç¶é©ä»¥é²è¡æå¢æç¥æè½å­¸ç¿ãçºäºä¿é²è¿ä¼¼ä¸çæ¨¡åçç·©æ¢å­¸ç¿ï¼æåæ¶éäºä¸ååå« 200k åå½±ççå¤§è¦æ¨¡è³æéï¼å¶ä¸­åå«èªè¨åä½è¨»è§£ï¼æ¶µèäºå»£æ³çå ´æ¯ãå¤§éçå¯¦é©è¡¨æï¼SlowFast-VGen å¨åä½é©åå½±ççæçåç¨®ææ¨ä¸åªæ¼åºæºï¼è 782 ç¸æ¯ï¼FVD å¾åéå° 514ï¼ä¸¦ä¸å¨è¼é·çå½±çä¸­ä¿æä¸è´æ§ï¼å¹³åå ´æ¯åæçº 0.37ï¼è 0.89ãç·©æ¢-å¿«éå­¸ç¿è¿´åæ¼ç®æ³ä¹é¡¯èæåäºé·æè¦åä»»åçæè½ãå°æ¡ç¶²ç«ï¼https://slowfast-vgen.github.io</paragraph>

##### **Multi-student Diffusion Distillation for Better One-step Generators**
2410.23274v1 by Yanke Song, Jonathan Lorraine, Weili Nie, Karsten Kreis, James Lucas

Diffusion models achieve high-quality sample generation at the cost of a
lengthy multistep inference procedure. To overcome this, diffusion distillation
techniques produce student generators capable of matching or surpassing the
teacher in a single step. However, the student model's inference speed is
limited by the size of the teacher architecture, preventing real-time
generation for computationally heavy applications. In this work, we introduce
Multi-Student Distillation (MSD), a framework to distill a conditional teacher
diffusion model into multiple single-step generators. Each student generator is
responsible for a subset of the conditioning data, thereby obtaining higher
generation quality for the same capacity. MSD trains multiple distilled
students, allowing smaller sizes and, therefore, faster inference. Also, MSD
offers a lightweight quality boost over single-student distillation with the
same architecture. We demonstrate MSD is effective by training multiple
same-sized or smaller students on single-step distillation using distribution
matching and adversarial distillation techniques. With smaller students, MSD
gets competitive results with faster inference for single-step generation.
Using 4 same-sized students, MSD sets a new state-of-the-art for one-step image
generation: FID 1.20 on ImageNet-64x64 and 8.20 on zero-shot COCO2014.

æè¦ï¼æ´æ£æ¨¡åä»¥åé·çæ­¥é©æ¨è«ç¨åºçºä»£å¹ï¼éæé«åè³ªçæ¨£æ¬ç¢çãçºäºåæéä¸é»ï¼æ´æ£è¸é¤¾æè¡ç¢çå­¸çç¢çå¨ï¼è½å¤ å¨å®ä¸æ­¥é©ä¸­å¹éæè¶è¶æå¸«ãç¶èï¼å­¸çæ¨¡åçæ¨è«éåº¦åå°æå¸«æ¶æ§å¤§å°çéå¶ï¼é²æ­¢è¨ç®å¯éåæç¨ç¨å¼é²è¡å³æç¢çãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹å¤å­¸çè¸é¤¾ (MSD)ï¼ä¸åå°æ¢ä»¶æå¸«æ´æ£æ¨¡åè¸é¤¾æå¤åå®æ­¥é©ç¢çå¨çæ¶æ§ãæ¯åå­¸çç¢çå¨è² è²¬æ¢ä»¶è³æçå­éï¼å æ­¤ç²å¾ç¸åå®¹éçè¼é«ç¢çåè³ªãMSD è¨ç·´å¤åè¸é¤¾å­¸çï¼åè¨±è¼å°çå°ºå¯¸ï¼å æ­¤æ¨è«æ´å¿«ãæ­¤å¤ï¼MSD å¨å·æç¸åæ¶æ§çå®å­¸çè¸é¤¾ä¸æä¾è¼éç´çåè³ªæåãæåç¤ºç¯ MSD ééä½¿ç¨åä½å¹éåå°æè¸é¤¾æè¡ï¼å¨å®æ­¥é©è¸é¤¾ä¸è¨ç·´å¤åç¸åå¤§å°æè¼å°çå­¸çï¼æ¯ææçãå°æ¼è¼å°çå­¸çï¼MSD å¨å®æ­¥é©ç¢çä¸­ä»¥æ´å¿«çæ¨è«ç²å¾ç«¶ç­çµæãä½¿ç¨ 4 åç¸åå¤§å°çå­¸çï¼MSD çºå®æ­¥é©å½±åç¢çè¨­å®äºæ°çæè¡æ°´æºï¼ImageNet-64x64 ä¸ç FID çº 1.20ï¼é¶æ¬¡ COCO2014 ä¸ç FID çº 8.20ã

##### **A Monte Carlo Framework for Calibrated Uncertainty Estimation in Sequence Prediction**
2410.23272v1 by Qidong Yang, Weicheng Zhu, Joseph Keslin, Laure Zanna, Tim G. J. Rudner, Carlos Fernandez-Granda

Probabilistic prediction of sequences from images and other high-dimensional
data is a key challenge, particularly in risk-sensitive applications. In these
settings, it is often desirable to quantify the uncertainty associated with the
prediction (instead of just determining the most likely sequence, as in
language modeling). In this paper, we propose a Monte Carlo framework to
estimate probabilities and confidence intervals associated with the
distribution of a discrete sequence. Our framework uses a Monte Carlo
simulator, implemented as an autoregressively trained neural network, to sample
sequences conditioned on an image input. We then use these samples to estimate
the probabilities and confidence intervals. Experiments on synthetic and real
data show that the framework produces accurate discriminative predictions, but
can suffer from miscalibration. In order to address this shortcoming, we
propose a time-dependent regularization method, which is shown to produce
calibrated predictions.

æè¦ï¼å¾å½±ååå¶ä»é«ç¶­åº¦è³æä¸­ï¼æ©çæ§å°é æ¸¬åºåæ¯ä¸åééµææ°ï¼ç¹å¥æ¯å¨é¢¨éªææçæç¨ç¨å¼ä¸­ãå¨éäºè¨­å®ä¸­ï¼éå¸¸éè¦éåèé æ¸¬ç¸éçä¸ç¢ºå®æ§ï¼èä¸æ¯åå¨èªè¨æ¨¡åä¸­ï¼åªæ±ºå®æå¯è½çåºåï¼ãå¨æ¬æä¸­ï¼æåæåºä¸åèå°å¡ç¾æ¶æ§ï¼ä»¥ä¼°è¨èé¢æ£åºååä½ç¸éçæ©çåä¿¡å¿åéãæåçæ¶æ§ä½¿ç¨èå°å¡ç¾æ¨¡æ¬å¨ï¼å¯¦ä½çºä¸åèªè¿´æ­¸è¨ç·´çç¥ç¶ç¶²è·¯ï¼ä»¥æ ¹æå½±åè¼¸å¥åæ¨£åºåãç¶å¾æåä½¿ç¨éäºæ¨£æ¬ä¾ä¼°è¨æ©çåä¿¡å¿åéãå¨åæåçå¯¦è³æä¸çå¯¦é©é¡¯ç¤ºï¼éåæ¶æ§ç¢çäºæºç¢ºçå¤å¥é æ¸¬ï¼ä½å¯è½æåºç¾æ ¡æºä¸è¯ãçºäºè§£æ±ºéåç¼ºé»ï¼æåæåºä¸åæéç¸éçæ­£ååæ¹æ³ï¼å·²è¢«è­æå¯ä»¥ç¢çæ ¡æºçé æ¸¬ã

##### **TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models**
2410.23266v1 by Ziyao Shangguan, Chuhan Li, Yuxuan Ding, Yanan Zheng, Yilun Zhao, Tesca Fitzgerald, Arman Cohan

Existing benchmarks often highlight the remarkable performance achieved by
state-of-the-art Multimodal Foundation Models (MFMs) in leveraging temporal
context for video understanding. However, how well do the models truly perform
visual temporal reasoning? Our study of existing benchmarks shows that this
capability of MFMs is likely overestimated as many questions can be solved by
using a single, few, or out-of-order frames. To systematically examine current
visual temporal reasoning tasks, we propose three principles with corresponding
metrics: (1) Multi-Frame Gain, (2) Frame Order Sensitivity, and (3) Frame
Information Disparity. Following these principles, we introduce TOMATO,
Temporal Reasoning Multimodal Evaluation, a novel benchmark crafted to
rigorously assess MFMs' temporal reasoning capabilities in video understanding.
TOMATO comprises 1,484 carefully curated, human-annotated questions spanning
six tasks (i.e., action count, direction, rotation, shape & trend, velocity &
frequency, and visual cues), applied to 1,417 videos, including 805
self-recorded and -generated videos, that encompass human-centric, real-world,
and simulated scenarios. Our comprehensive evaluation reveals a human-model
performance gap of 57.3% with the best-performing model. Moreover, our in-depth
analysis uncovers more fundamental limitations beyond this gap in current MFMs.
While they can accurately recognize events in isolated frames, they fail to
interpret these frames as a continuous sequence. We believe TOMATO will serve
as a crucial testbed for evaluating the next-generation MFMs and as a call to
the community to develop AI systems capable of comprehending human world
dynamics through the video modality.

æè¦ï¼ç¾æçåºæºæ¸¬è©¦ç¶å¸¸å¼·èª¿æåé²çå¤æ¨¡æåºç¤æ¨¡å (MFM) å¨å©ç¨æéèçµ¡é²è¡å½±ççè§£ææéæçé¡¯èæè½ãç¶èï¼éäºæ¨¡åå¨è¦è¦ºæéæ¨çæ¹é¢çè¡¨ç¾ç©¶ç«å¦ä½ï¼æåå°ç¾æåºæºæ¸¬è©¦çç ç©¶é¡¯ç¤ºï¼ç±æ¼è¨±å¤åé¡å¯ä»¥ç¨å®ä¸ãå°æ¸æéé åºçå½±æ ¼ä¾è§£æ±ºï¼å æ­¤ MFM çéç¨®è½åå¯è½è¢«é«ä¼°äºãçºäºç³»çµ±æ§å°æª¢è¦ç®åçè¦è¦ºæéæ¨çä»»åï¼æåæåºäºä¸é ååï¼ä¸¦æå°æçææ¨ï¼(1) å¤å½±æ ¼å¢çã(2) å½±æ ¼é åºææåº¦ï¼ä»¥å (3) å½±æ ¼è³è¨å·®ç°ãéµå¾ªéäºååï¼æåå¼å¥äº TOMATOï¼å³æéæ¨çå¤æ¨¡æè©ä¼°ï¼éæ¯ä¸åæ°ç©çåºæºæ¸¬è©¦ï¼æ¨å¨å´æ ¼è©ä¼° MFM å¨å½±ççè§£ä¸­çæéæ¨çè½åãTOMATO åå« 1,484 åç¶éä»ç´°ç­åãäººå·¥æ¨è¨»çåé¡ï¼æ¶µèå­é ä»»åï¼å³åä½è¨æ¸ãæ¹åãæè½ãå½¢çåè¶¨å¢ãéåº¦åé »çï¼ä»¥åè¦è¦ºæç¤ºï¼ï¼ä¸¦æç¨æ¼ 1,417 åå½±çï¼å¶ä¸­åæ¬ 805 åèªéåèªè£½çå½±çï¼æ¶µèä»¥äººçºä¸­å¿ãçå¯¦ä¸çåæ¨¡æ¬çå ´æ¯ãæåçå¨é¢è©ä¼°é¡¯ç¤ºï¼è¡¨ç¾æä½³çæ¨¡åèäººé¡çæè½å·®è·çº 57.3%ãæ­¤å¤ï¼æåæ·±å¥çåææ­é²äºè¶è¶æ­¤å·®è·çæ´æ ¹æ¬éå¶ï¼å¨ç¾æç MFM ä¸­ãéç¶å®åå¯ä»¥æºç¢ºè­å¥å­¤ç«å½±æ ¼ä¸­çäºä»¶ï¼ä½å®åç¡æ³å°éäºå½±æ ¼è§£éçºä¸åé£çºçåºåãæåç¸ä¿¡ TOMATO å°æçºè©ä¼°ä¸ä¸ä»£ MFM çééµæ¸¬è©¦å¹³å°ï¼ä¸¦å¼ç±²ç¤¾ç¾¤éç¼è½å¤ ééå½±çæ¨¡å¼çè§£äººé¡ä¸çåæçäººå·¥æºæ§ç³»çµ±ã

##### **EMMA: End-to-End Multimodal Model for Autonomous Driving**
2410.23262v1 by Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, James Guo, Dragomir Anguelov, Mingxing Tan

We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.
Built on a multi-modal large language model foundation, EMMA directly maps raw
camera sensor data into various driving-specific outputs, including planner
trajectories, perception objects, and road graph elements. EMMA maximizes the
utility of world knowledge from the pre-trained large language models, by
representing all non-sensor inputs (e.g. navigation instructions and ego
vehicle status) and outputs (e.g. trajectories and 3D locations) as natural
language text. This approach allows EMMA to jointly process various driving
tasks in a unified language space, and generate the outputs for each task using
task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by
achieving state-of-the-art performance in motion planning on nuScenes as well
as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also
yields competitive results for camera-primary 3D object detection on the Waymo
Open Dataset (WOD). We show that co-training EMMA with planner trajectories,
object detection, and road graph tasks yields improvements across all three
domains, highlighting EMMA's potential as a generalist model for autonomous
driving applications. However, EMMA also exhibits certain limitations: it can
process only a small amount of image frames, does not incorporate accurate 3D
sensing modalities like LiDAR or radar and is computationally expensive. We
hope that our results will inspire further research to mitigate these issues
and to further evolve the state of the art in autonomous driving model
architectures.

æè¦ï¼<paragraph>æåä»ç´¹ EMMAï¼ä¸ç¨®ç¨æ¼èªåé§é§çç«¯å°ç«¯å¤æ¨¡ææ¨¡åã
å»ºç«å¨å¤æ¨¡æå¤§åèªè¨æ¨¡ååºç¤ä¸ï¼EMMA ç´æ¥å°åå§
ç¸æ©ææ¸¬å¨è³æå°æå°åç¨®ç¹å®æ¼é§é§çè¼¸åºï¼åæ¬è¦åå¨
è»è·¡ãæç¥ç©ä»¶åéè·¯åå½¢åç´ ãEMMA éé
å°ææéææ¸¬å¨è¼¸å¥ï¼ä¾å¦å°èªæç¤ºåèªæ
è»è¼çæï¼åè¼¸åºï¼ä¾å¦è»è·¡å 3D ä½ç½®ï¼è¡¨ç¤ºçºèªç¶
èªè¨æå­ï¼æå¤§åé è¨ç·´å¤§åèªè¨æ¨¡åçä¸çç¥è­æç¨ãéç¨®æ¹æ³è® EMMA è½å¤ å¨çµ±ä¸çèªè¨ç©ºéä¸­å±åèçåç¨®é§é§
ä»»åï¼ä¸¦ä½¿ç¨ç¹å®æ¼ä»»åçæç¤ºç¢çæ¯åä»»åçè¼¸åºãæ ¹æç¶é©ï¼æåéé
å¨ nuScenes ä¸å¯¦ç¾éåè¦åçææ°æè½ï¼ä»¥åå¨ Waymo Open Motion Dataset (WOMD) ä¸ç²å¾ç«¶ç­åçµæï¼ä¾è­æ EMMA çæææ§ãEMMA ä¹
å¨ Waymo Open Dataset (WOD) ä¸ç¢çäºç¸æ©åªå 3D ç©ä»¶åµæ¸¬çç«¶ç­åçµæãæåå±ç¤ºäºä½¿ç¨è¦åå¨è»è·¡ã
ç©ä»¶åµæ¸¬åéè·¯åå½¢ä»»åå±åè¨ç·´ EMMAï¼æå¨ææä¸å
é åä¸­ç¢çæ¹é²ï¼çªé¡¯äº EMMA ä½çºèªåé§é§æç¨ç¨å¼éç¨æ¨¡åçæ½åãç¶èï¼EMMA ä¹å±ç¾åºæäºéå¶ï¼å®åªè½
èçå°éå½±åå¹ï¼ä¸æ´åæºç¢ºç 3D ææ¸¬æ¨¡å¼ï¼ä¾å¦ LiDAR æé·éï¼ï¼èä¸è¨ç®ææ¬é«æãæå
å¸ææåççµæè½æ¿åµé²ä¸æ­¥çç ç©¶ï¼ä»¥æ¸è¼éäºåé¡ï¼ä¸¦é²ä¸æ­¥ç¼å±èªåé§é§æ¨¡å
æ¶æ§çææ°æè¡ã</paragraph>

##### **$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources**
2410.23261v1 by Apoorv Khandelwal, Tian Yun, Nihal V. Nayak, Jack Merullo, Stephen H. Bach, Chen Sun, Ellie Pavlick

Pre-training is notoriously compute-intensive and academic researchers are
notoriously under-resourced. It is, therefore, commonly assumed that academics
can't pre-train models. In this paper, we seek to clarify this assumption. We
first survey academic researchers to learn about their available compute and
then empirically measure the time to replicate models on such resources. We
introduce a benchmark to measure the time to pre-train models on given GPUs and
also identify ideal settings for maximizing training speed. We run our
benchmark on a range of models and academic GPUs, spending 2,000 GPU-hours on
our experiments. Our results reveal a brighter picture for academic
pre-training: for example, although Pythia-1B was originally trained on 64 GPUs
for 3 days, we find it is also possible to replicate this model (with the same
hyper-parameters) in 3x fewer GPU-days: i.e. on 4 GPUs in 18 days. We conclude
with a cost-benefit analysis to help clarify the trade-offs between price and
pre-training time. We believe our benchmark will help academic researchers
conduct experiments that require training larger models on more data. We fully
release our codebase at: https://github.com/apoorvkh/academic-pretraining.

æè¦ï¼é è¨ç·´åºäºåçéè¦å¤§ééç®ï¼èå­¸è¡ç ç©¶äººå¡åºäºåçè³æºä¸è¶³ãå æ­¤ï¼æ®éèªçºå­¸è¡çç¡æ³é è¨ç·´æ¨¡åãå¨æ¬æä¸­ï¼æåè©¦åéæ¸éååè¨­ãæåé¦åèª¿æ¥å­¸è¡ç ç©¶äººå¡ï¼ä»¥äºè§£ä»åå¯ç¨çéç®ï¼ç¶å¾æ ¹æéäºè³æºå¯¦è­æ¸¬éè¤è£½æ¨¡åçæéãæåå¼å¥ä¸ååºæºï¼ç¨ä¾æ¸¬éå¨çµ¦å®ç GPU ä¸é è¨ç·´æ¨¡åçæéï¼ä¸¦æ¾åºæå¤§åè¨ç·´éåº¦ççæ³è¨­å®ãæåå¨åç¨®æ¨¡ååå­¸è¡ GPU ä¸å·è¡åºæºï¼å¨æåçå¯¦é©ä¸­èè²»äº 2,000 å GPU å°æãæåççµæå°å­¸è¡é è¨ç·´æ­ç¤ºäºä¸åæ´åæçååï¼ä¾å¦ï¼åç®¡ Pythia-1B æåå¨ 64 å GPU ä¸è¨ç·´äº 3 å¤©ï¼ä½æåç¼ç¾ä¹å¯ä»¥ç¨æ´å°ç 3 å GPU å¤©æ¸è¤è£½éåæ¨¡åï¼ä½¿ç¨ç¸åçè¶åæ¸ï¼ï¼å³å¨ 4 å GPU ä¸è¨ç·´ 18 å¤©ãæåä»¥ææ¬æçåæä½çºçµè«ï¼ä»¥å¹«å©éæ¸å¹æ ¼åé è¨ç·´æéä¹éçæ¬è¡¡ãæåç¸ä¿¡æåçåºæºå°æå©æ¼å­¸è¡ç ç©¶äººå¡é²è¡éè¦å¨æ´å¤è³æä¸è¨ç·´æ´å¤§æ¨¡åçå¯¦é©ãæåå¨ https://github.com/apoorvkh/academic-pretraining å®æ´éåºæåçç¨å¼ç¢¼åº«ã

##### **Keypoint Abstraction using Large Models for Object-Relative Imitation Learning**
2410.23254v1 by Xiaolin Fang, Bo-Ruei Huang, Jiayuan Mao, Jasmine Shone, Joshua B. Tenenbaum, TomÃ¡s Lozano-PÃ©rez, Leslie Pack Kaelbling

Generalization to novel object configurations and instances across diverse
tasks and environments is a critical challenge in robotics. Keypoint-based
representations have been proven effective as a succinct representation for
capturing essential object features, and for establishing a reference frame in
action prediction, enabling data-efficient learning of robot skills. However,
their manual design nature and reliance on additional human labels limit their
scalability. In this paper, we propose KALM, a framework that leverages large
pre-trained vision-language models (LMs) to automatically generate
task-relevant and cross-instance consistent keypoints. KALM distills robust and
consistent keypoints across views and objects by generating proposals using LMs
and verifies them against a small set of robot demonstration data. Based on the
generated keypoints, we can train keypoint-conditioned policy models that
predict actions in keypoint-centric frames, enabling robots to generalize
effectively across varying object poses, camera views, and object instances
with similar functional shapes. Our method demonstrates strong performance in
the real world, adapting to different tasks and environments from only a
handful of demonstrations while requiring no additional labels. Website:
https://kalm-il.github.io/

æè¦ï¼å¨æ©å¨äººé åä¸­ï¼æ³åè³åç¨®ä»»åèç°å¢ä¸­çæ°ç©ç©é«éç½®åå¯¦ä¾æ¯ä¸é å´å³»çææ°ãåºæ¼ééµé»çè¡¨ç¤ºæ³å·²è¢«è­ææ¯ä¸ç¨®ç°¡æ½çè¡¨ç¤ºæ³ï¼ç¨æ¼æ·åå¿è¦çç©é«ç¹å¾µï¼ä¸¦å¨åä½é æ¸¬ä¸­å»ºç«åèæ¶æ§ï¼é²èå¯¦ç¾æ©å¨äººæè½çè³æææå­¸ç¿ãç¶èï¼å¶æåè¨­è¨æ§è³ªåå°é¡å¤äººå·¥æ¨ç±¤çä¾è³´éå¶äºå¶å¯æ´åæ§ãå¨æ¬æä¸­ï¼æåæåº KALMï¼éæ¯ä¸ç¨®å©ç¨å¤§åé è¨ç·´è¦è¦ºèªè¨æ¨¡å (LM) èªåçæèä»»åç¸éä¸è·¨å¯¦ä¾ä¸è´çééµé»çæ¶æ§ãKALM ééä½¿ç¨ LM ç¢çå»ºè­°ï¼ä¸¦æ ¹æä¸çµå°åæ©å¨äººç¤ºç¯è³æé©è­å®åï¼å¾èæåè·¨è¦ååç©é«çç©©å¥ä¸ä¸è´çééµé»ãæ ¹æç¢ççééµé»ï¼æåå¯ä»¥è¨ç·´ééµé»æ¢ä»¶ç­ç¥æ¨¡åï¼è©²æ¨¡åé æ¸¬ééµé»ä¸­å¿æ¡æ¶ä¸­çåä½ï¼è®æ©å¨äººå¨ä¸åçç©é«å§¿å¢ãç¸æ©è¦ååå·æé¡ä¼¼åè½å½¢ççç©é«å¯¦ä¾ä¸­æææ³åãæåçæ¨¡åå¨çå¯¦ä¸çä¸­è¡¨ç¾åºå¼·å¤§çæè½ï¼åªéå°æ¸ç¤ºç¯å³å¯é©æä¸åçä»»ååç°å¢ï¼åæä¸éè¦é¡å¤çæ¨ç±¤ãç¶²ç«ï¼https://kalm-il.github.io/

##### **Evaluating Cultural and Social Awareness of LLM Web Agents**
2410.23252v1 by Haoyi Qiu, Alexander R. Fabbri, Divyansh Agarwal, Kung-Hsiang Huang, Sarah Tan, Nanyun Peng, Chien-Sheng Wu

As large language models (LLMs) expand into performing as agents for
real-world applications beyond traditional NLP tasks, evaluating their
robustness becomes increasingly important. However, existing benchmarks often
overlook critical dimensions like cultural and social awareness. To address
these, we introduce CASA, a benchmark designed to assess LLM agents'
sensitivity to cultural and social norms across two web-based tasks: online
shopping and social discussion forums. Our approach evaluates LLM agents'
ability to detect and appropriately respond to norm-violating user queries and
observations. Furthermore, we propose a comprehensive evaluation framework that
measures awareness coverage, helpfulness in managing user queries, and the
violation rate when facing misleading web content. Experiments show that
current LLMs perform significantly better in non-agent than in web-based agent
environments, with agents achieving less than 10% awareness coverage and over
40% violation rates. To improve performance, we explore two methods: prompting
and fine-tuning, and find that combining both methods can offer complementary
advantages -- fine-tuning on culture-specific datasets significantly enhances
the agents' ability to generalize across different regions, while prompting
boosts the agents' ability to navigate complex tasks. These findings highlight
the importance of constantly benchmarking LLM agents' cultural and social
awareness during the development cycle.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) æ´å±å°ä½çºä»£çå·è¡å¯¦éæç¨ç¨å¼ï¼è¶è¶å³çµ±ç NLP ä»»åï¼è©ä¼°å¶ç©©å¥æ§è®å¾è¶ä¾è¶éè¦ãç¶èï¼ç¾æçåºæºæ¸¬è©¦ç¶å¸¸å¿½ç¥ééµé¢åï¼ä¾å¦æååç¤¾ææè­ãçºäºè§£æ±ºéäºåé¡ï¼æåå¼å¥äº CASAï¼ä¸ååºæºæ¸¬è©¦ï¼æ¨å¨è©ä¼° LLM ä»£çå°å©åç¶²è·¯ä»»åä¸­æååç¤¾æè¦ç¯çææåº¦ï¼ç·ä¸è³¼ç©åç¤¾ç¾¤è¨è«è«å£ãæåçåæ³è©ä¼° LLM ä»£çåµæ¸¬åé©ç¶å°åæéåè¦ç¯çä½¿ç¨èæ¥è©¢åè§å¯çè½åãæ­¤å¤ï¼æåæåºä¸åå¨é¢çè©ä¼°æ¶æ§ï¼æ¸¬éæè­æ¶µèç¯åãç®¡çä½¿ç¨èæ¥è©¢çå¹«å©æ§ï¼ä»¥åé¢å°èª¤å°æ§ç¶²è·¯å§å®¹æçéè¦çãå¯¦é©é¡¯ç¤ºï¼ç®åç LLM å¨éä»£çç°å¢ä¸­çè¡¨ç¾æé¡¯åªæ¼ç¶²è·¯ä»£çç°å¢ï¼ä»£ççæè­æ¶µèç¯åä½æ¼ 10%ï¼éè¦çè¶é 40%ãçºäºæåæè½ï¼æåæ¢è¨äºå©ç¨®æ¹æ³ï¼æç¤ºåå¾®èª¿ï¼ä¸¦ç¼ç¾çµåå©ç¨®æ¹æ³å¯ä»¥æä¾äºè£çåªå¢ââéå°ç¹å®æåçè³æéé²è¡å¾®èª¿ï¼é¡¯èæåä»£çè·¨ä¸åå°åæ¦æ¬çè½åï¼èæç¤ºåæåä»£çå°èªè¤éä»»åçè½åãéäºç¼ç¾å¼·èª¿å¨éç¼é±æä¸­æçºå° LLM ä»£ççæååç¤¾ææè­é²è¡åºæºæ¸¬è©¦çéè¦æ§ã

##### **A little less conversation, a little more action, please: Investigating the physical common-sense of LLMs in a 3D embodied environment**
2410.23242v1 by Matteo G. Mecattaf, Ben Slater, Marko TeÅ¡iÄ, Jonathan Prunty, Konstantinos Voudouris, Lucy G. Cheke

As general-purpose tools, Large Language Models (LLMs) must often reason
about everyday physical environments. In a question-and-answer capacity,
understanding the interactions of physical objects may be necessary to give
appropriate responses. Moreover, LLMs are increasingly used as reasoning
engines in agentic systems, designing and controlling their action sequences.
The vast majority of research has tackled this issue using static benchmarks,
comprised of text or image-based questions about the physical world. However,
these benchmarks do not capture the complexity and nuance of real-life physical
processes. Here we advocate for a second, relatively unexplored, approach:
'embodying' the LLMs by granting them control of an agent within a 3D
environment. We present the first embodied and cognitively meaningful
evaluation of physical common-sense reasoning in LLMs. Our framework allows
direct comparison of LLMs with other embodied agents, such as those based on
Deep Reinforcement Learning, and human and non-human animals. We employ the
Animal-AI (AAI) environment, a simulated 3D virtual laboratory, to study
physical common-sense reasoning in LLMs. For this, we use the AAI Testbed, a
suite of experiments that replicate laboratory studies with non-human animals,
to study physical reasoning capabilities including distance estimation,
tracking out-of-sight objects, and tool use. We demonstrate that
state-of-the-art multi-modal models with no finetuning can complete this style
of task, allowing meaningful comparison to the entrants of the 2019 Animal-AI
Olympics competition and to human children. Our results show that LLMs are
currently outperformed by human children on these tasks. We argue that this
approach allows the study of physical reasoning using ecologically valid
experiments drawn directly from cognitive science, improving the predictability
and reliability of LLMs.

æè¦ï¼ä½çºéç¨å·¥å·ï¼å¤§åèªè¨æ¨¡å (LLM) å¿é ç¶å¸¸æ¨è«æ¥å¸¸ç©çç°å¢ãå¨åç­è½åä¸­ï¼äºè§£ç©çç©é«çäº¤äºä½ç¨å¯è½æ¯çµ¦åºé©ç¶åææå¿éçãæ­¤å¤ï¼LLM æ­£å¨è¶ä¾è¶å¤å°ç¨ä½ä»£çç³»çµ±ä¸­çæ¨çå¼æï¼è¨­è¨åæ§å¶å¶åä½åºåãçµå¤§å¤æ¸ç ç©¶ä½¿ç¨éæåºæºä¾è§£æ±ºéååé¡ï¼éäºåºæºåå«æéç©çä¸ççåºæ¼ææ¬æååçåé¡ãç¶èï¼éäºåºæºä¸¦æªææå°ç¾å¯¦ç©çéç¨çè¤éæ§åç´°å¾®å·®å¥ãå¨éè£¡ï¼æåæå¡ç¬¬äºç¨®ç¸å°æªç¶æ¢ç´¢çæ¹æ³ï¼âå·èº«åâ LLMï¼è®å®åæ§å¶ 3D ç°å¢ä¸­çä»£çãæåæåºäºå° LLM ä¸­ç©çå¸¸è­æ¨ççç¬¬ä¸åå·èº«ååèªç¥ææç¾©çè©ä¼°ãæåçæ¡æ¶åè¨±å° LLM èå¶ä»å·èº«åä»£çé²è¡ç´æ¥æ¯è¼ï¼ä¾å¦åºæ¼æ·±åº¦å¼·åå­¸ç¿çä»£çï¼ä»¥åäººé¡åéäººé¡åç©ãæåæ¡ç¨ Animal-AI (AAI) ç°å¢ï¼ä¸åæ¨¡æ¬ç 3D èæ¬å¯¦é©å®¤ï¼ä¾ç ç©¶ LLM ä¸­çç©çå¸¸è­æ¨çãçºæ­¤ï¼æåä½¿ç¨ AAI æ¸¬è©¦å¹³å°ï¼ä¸çµå¯¦é©ï¼è¤è£½äºå°éäººé¡åç©çå¯¦é©å®¤ç ç©¶ï¼ä»¥ç ç©¶ç©çæ¨çè½åï¼åæ¬è·é¢ä¼°è¨ãè¿½è¹¤è¦ç·å¤ç©é«åå·¥å·ä½¿ç¨ãæåè­æäºæ²æå¾®èª¿çææ°å¤æ¨¡ææ¨¡åå¯ä»¥å®æéç¨®é¢¨æ ¼çä»»åï¼åè¨±è 2019 å¹´åç©äººå·¥æºè½å¥§æå¹åç«¶è³½çåè³½èåäººé¡åç«¥é²è¡ææç¾©çæ¯è¼ãæåççµæè¡¨æï¼å¨éäºä»»åä¸ï¼äººé¡åç«¥ç®åè¡¨ç¾åªæ¼ LLMãæåèªçºï¼éç¨®æ¹æ³åè¨±ä½¿ç¨ç´æ¥å¾èªç¥ç§å­¸ä¸­æåççæå­¸ä¸ææå¯¦é©ä¾ç ç©¶ç©çæ¨çï¼å¾èæé« LLM çå¯é æ¸¬æ§åå¯é æ§ã

##### **EMOTION: Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning**
2410.23234v1 by Peide Huang, Yuhan Hu, Nataliya Nechyporenko, Daehwa Kim, Walter Talbott, Jian Zhang

This paper introduces a framework, called EMOTION, for generating expressive
motion sequences in humanoid robots, enhancing their ability to engage in
humanlike non-verbal communication. Non-verbal cues such as facial expressions,
gestures, and body movements play a crucial role in effective interpersonal
interactions. Despite the advancements in robotic behaviors, existing methods
often fall short in mimicking the diversity and subtlety of human non-verbal
communication. To address this gap, our approach leverages the in-context
learning capability of large language models (LLMs) to dynamically generate
socially appropriate gesture motion sequences for human-robot interaction. We
use this framework to generate 10 different expressive gestures and conduct
online user studies comparing the naturalness and understandability of the
motions generated by EMOTION and its human-feedback version, EMOTION++, against
those by human operators. The results demonstrate that our approach either
matches or surpasses human performance in generating understandable and natural
robot motions under certain scenarios. We also provide design implications for
future research to consider a set of variables when generating expressive
robotic gestures.

æè¦ï¼æ¬æä»ç´¹äºä¸ååçº EMOTION çæ¡æ¶ï¼å¯ç¨æ¼å¨é¡äººæ©å¨äººä¸­çæè¡¨éæ§çåä½åºåï¼å¢å¼·å¶åèé¡äººéèªè¨æºéçè½åãéèªè¨ç·ç´¢ï¼ä¾å¦é¢é¨è¡¨æãæå¢åèº«é«åä½ï¼å¨ææçäººéäºåä¸­æ®æ¼èè³ééè¦çè§è²ãåç®¡æ©å¨äººè¡çºæé²æ­¥ï¼ä½ç¾ææ¹æ³å¨æ¨¡ä»¿äººé¡éèªè¨æºéçå¤æ¨£æ§åå¾®å¦æ§æ¹é¢å¾å¾åå¾ä¸å¤ ãçºäºè§£æ±ºéåå·®è·ï¼æåçæ¹æ³å©ç¨å¤§åèªè¨æ¨¡å (LLM) çæå¢å­¸ç¿è½åï¼åæçæé©æç¤¾äº¤å ´åçæå¢åä½åºåï¼ç¨æ¼äººæ©äºåãæåä½¿ç¨éåæ¡æ¶çæäº 10 ç¨®ä¸åçè¡¨éæ§æå¢ï¼ä¸¦é²è¡ç·ä¸ä½¿ç¨èç ç©¶ï¼æ¯è¼ EMOTION åå¶äººé¡åé¥çæ¬ EMOTION++ æçæåä½çèªç¶æ§åå¯çè§£æ§ï¼ä»¥åäººé¡æä½å¡æåçåä½ãçµæè¡¨æï¼å¨æäºå ´æ¯ä¸ï¼æåçæ¹æ³å¨çæå¯çè§£ä¸èªç¶çæ©å¨äººåä½æ¹é¢éå°æè¶éäººé¡è¡¨ç¾ãæåéçºæªä¾çç ç©¶æä¾äºè¨­è¨å«ç¾©ï¼ä»¥èæ®å¨çæè¡¨éæ§æ©å¨äººæå¢æçä¸çµè®æ¸ã

##### **Aligning Audio-Visual Joint Representations with an Agentic Workflow**
2410.23230v2 by Shentong Mo, Yibing Song

Visual content and accompanied audio signals naturally formulate a joint
representation to improve audio-visual (AV) related applications. While studies
develop various AV representation learning frameworks, the importance of AV
data alignment is usually undermined for achieving high-quality representation.
We observe that an audio signal may contain background noise interference.
Also, non-synchronization may appear between audio and video streams. These
non-strict data alignment limits representation quality and downgrade
application performance. In this paper, we propose to improve AV joint
representations from a data-centric perspective by aligning audio signals to
visual data. Our alignment is conducted in an agentic workflow controlled by an
LLM-based assistant named AVAgent. For each input AV data pair, our AVAgent
uses a multi-modal LLM to convert audio and visual data into language
descriptions separately (i.e., tool use). Then, AVAgent reasons whether this
paired data is aligned well and plans to edit the audio signal if needed (i.e.,
planning). The audio editing is executed by predefined actions that filter
noise or augment data. Moreover, we use a VLM to evaluate how modified audio
signals match the visual content and provide feedback to AVAgent (i.e.,
reflection). The tool use, planning, and reflection steps operate cyclically to
become an agentic workflow where audio signals are gradually aligned to visual
content. To this end, existing methods can directly leverage the aligned AV
data via our agentic workflow to improve AV joint representations. The
experimental results comprehensively demonstrate the state-of-the-art
performance of the proposed approach against previous baselines in diverse
downstream tasks.

æè¦ï¼è¦è¦ºå§å®¹åä¼´é¨çé³è¨è¨èèªç¶æå½¢æä¸ç¨®è¯åè¡¨ç¤ºï¼ä»¥æ¹åé³è¨è¦è¦º (AV) ç¸éæç¨ç¨å¼ãåç®¡ç ç©¶éç¼äºåç¨® AV è¡¨ç¤ºå­¸ç¿æ¶æ§ï¼ä½ AV è³æå°é½çéè¦æ§éå¸¸æè¢«ä½ä¼°ï¼ä»¥å¯¦ç¾é«åè³ªçè¡¨ç¤ºãæåè§å¯å°ï¼é³è¨è¨èå¯è½åå«èæ¯åªé³å¹²æ¾ãæ­¤å¤ï¼é³è¨ä¸²æµåè¦è¨ä¸²æµä¹éå¯è½åºç¾ä¸åæ­¥ãéäºéå´æ ¼è³æå°é½æéå¶è¡¨ç¤ºåè³ªä¸¦éä½æç¨ç¨å¼æè½ãå¨æ¬æä¸­ï¼æåæè­°å¾ä»¥è³æçºä¸­å¿çè§é»æ¹å AV è¯åè¡¨ç¤ºï¼æ¹æ³æ¯å°é³è¨è¨èèè¦è¦ºè³æå°é½ãæåçå°é½æ¯å¨ç±åçº AVAgent çåºæ¼ LLM çå©çæ§å¶çä»£çå·¥ä½æµç¨ä¸­é²è¡çãå°æ¼æ¯åè¼¸å¥ AV è³æå°ï¼æåç AVAgent ä½¿ç¨å¤æ¨¡æ LLM å°é³è¨åè¦è¦ºè³æåå¥è½ææèªè¨æè¿°ï¼å³å·¥å·ä½¿ç¨ï¼ãç¶å¾ï¼AVAgent æ¨è«éçµè³æå°æ¯å¦å°é½è¯å¥½ï¼ä¸¦è¨ç«å¨éè¦æç·¨è¼¯é³è¨è¨èï¼å³è¨ç«ï¼ãé³è¨ç·¨è¼¯æ¯ç±é å®ç¾©çåä½å·è¡çï¼éäºåä½æéæ¿¾éè¨ææ´åè³æãæ­¤å¤ï¼æåä½¿ç¨ VLM ä¾è©ä¼°ä¿®æ¹å¾çé³è¨è¨èå¦ä½èè¦è¦ºå§å®¹ç¸ç¬¦ï¼ä¸¦å AVAgent æä¾åé¥ï¼å³åæï¼ãå·¥å·ä½¿ç¨ãè¨ç«ååææ­¥é©å¾ªç°éä½ï¼æçºä¸åä»£çå·¥ä½æµç¨ï¼å¶ä¸­é³è¨è¨èéæ¼¸èè¦è¦ºå§å®¹å°é½ãçºæ­¤ï¼ç¾ææ¹æ³å¯ä»¥ç´æ¥ééæåçä»£çå·¥ä½æµç¨å©ç¨å°é½ç AV è³æä¾æ¹å AV è¯åè¡¨ç¤ºãå¯¦é©çµæå¨é¢å±ç¤ºäºææåºçæ¹æ³å¨åç¨®ä¸æ¸¸ä»»åä¸­ç¸è¼æ¼åååºç·çæä½³æè½ã

##### **COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences**
2410.23223v1 by Yixin Liu, Argyris Oikonomou, Weiqiang Zheng, Yang Cai, Arman Cohan

Many alignment methods, including reinforcement learning from human feedback
(RLHF), rely on the Bradley-Terry reward assumption, which is insufficient to
capture the full range of general human preferences. To achieve robust
alignment with general preferences, we model the alignment problem as a
two-player zero-sum game, where the Nash equilibrium policy guarantees a 50%
win rate against any competing policy. However, previous algorithms for finding
the Nash policy either diverge or converge to a Nash policy in a modified game,
even in a simple synthetic setting, thereby failing to maintain the 50% win
rate guarantee against all other policies. We propose a meta-algorithm,
Convergent Meta Alignment Algorithm (COMAL), for language model alignment with
general preferences, inspired by convergent algorithms in game theory.
Theoretically, we prove that our meta-algorithm converges to an exact Nash
policy in the last iterate. Additionally, our meta-algorithm is simple and can
be integrated with many existing methods designed for RLHF and preference
optimization with minimal changes. Experimental results demonstrate the
effectiveness of the proposed framework when combined with existing preference
policy optimization methods.

æè¦ï¼è¨±å¤å°é½æ¹æ³ï¼åå«äººé¡åé¥çå¼·åå­¸ç¿ (RLHF)ï¼ä¾è³´æ¼å¸èå¾·å©-æ³°ççåµåè¨­ï¼éä¸è¶³ä»¥æ¶µèä¸è¬äººé¡åå¥½çå®æ´ç¯åãçºäºéæèä¸è¬åå¥½çç©©å¥å°é½ï¼æåå°å°é½åé¡å»ºæ¨¡çºéäººé¶åéæ²ï¼å¶ä¸­ç´è¨±åè¡¡ç­ç¥ä¿è­å°æä»»ä½ç«¶ç­ç­ç¥ææ 50% çç²åçãç¶èï¼ååç¨æ¼å°æ¾ç´è¨±ç­ç¥çæ¼ç®æ³æç¼æ£ææ¶æè³ä¿®æ¹å¾éæ²ä¸­çç´è¨±ç­ç¥ï¼å³ä½¿å¨ç°¡å®çåæè¨­å®ä¸­ä¹æ¯å¦æ­¤ï¼å æ­¤ç¡æ³ç¶­æå°æææå¶ä»ç­ç¥ç 50% ç²åçä¿è­ãæåæåºäºä¸ååæ¼ç®æ³ï¼æ¶æåå°é½æ¼ç®æ³ (COMAL)ï¼ç¨æ¼èªè¨æ¨¡åå°é½èä¸è¬åå¥½ï¼éæä¾èªæ¼åå¼è«ä¸­çæ¶ææ¼ç®æ³ãçè«ä¸ï¼æåè­ææåçåæ¼ç®æ³å¨æå¾ä¸æ¬¡è¿­ä»£ä¸­æ¶æè³ç²¾ç¢ºçç´è¨±ç­ç¥ãæ­¤å¤ï¼æåçåæ¼ç®æ³å¾ç°¡å®ï¼å¯ä»¥èè¨±å¤ç¾æçæ¹æ³æ´åï¼éäºæ¹æ³æ¯çº RLHF ååå¥½æä½³åæè¨­è¨çï¼èä¸è®æ´å¾å°ãå¯¦é©çµæè­æäºææåºçæ¶æ§å¨èç¾æçåå¥½ç­ç¥æä½³åæ¹æ³çµåæå¾ææã

##### **Partial Channel Dependence with Channel Masks for Time Series Foundation Models**
2410.23222v1 by Seunghan Lee, Taeyoung Park, Kibok Lee

Recent advancements in foundation models have been successfully extended to
the time series (TS) domain, facilitated by the emergence of large-scale TS
datasets. However, previous efforts have primarily focused on designing model
architectures to address explicit heterogeneity among datasets such as various
numbers of channels, while often overlooking implicit heterogeneity such as
varying dependencies between channels. In this work, we introduce the concept
of partial channel dependence (PCD), which enables a more sophisticated
adjustment of channel dependencies based on dataset-specific information. To
achieve PCD, we propose a channel mask that captures the relationships between
channels within a dataset using two key components: 1) a correlation matrix
that encodes relative dependencies between channels, and 2) domain parameters
that learn the absolute dependencies specific to each dataset, refining the
correlation matrix. We validate the effectiveness of PCD across four tasks in
TS including forecasting, classification, imputation, and anomaly detection,
under diverse settings, including few-shot and zero-shot scenarios with both TS
foundation models and single-task models. Code is available at
https://github.com/seunghan96/CM.

æè¦ï¼è¿æåºç¡æ¨¡åçè¿æ­¥å·²æåæ©å±å°æ¶é´åºå (TS) é¢åï¼è¿å¾çäºå¤§è§æ¨¡ TS æ°æ®éçåºç°ãç¶èï¼ä»¥å¾çç ç©¶ä¸»è¦ä¸æ³¨äºè®¾è®¡æ¨¡åæ¶æï¼ä»¥è§£å³æ°æ®éä¹é´æ¾æ§çå¼è´¨æ§ï¼ä¾å¦ä¸åæ°éçééï¼èå¸¸å¸¸å¿½ç¥äºéæ§çå¼è´¨æ§ï¼ä¾å¦ééä¹é´çä¸åä¾èµæ§ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¼å¥äºé¨åééä¾èµ (PCD) çæ¦å¿µï¼å®å¯ä»¥æ ¹æ®æ°æ®éç¹å®çä¿¡æ¯å¯¹ééä¾èµæ§è¿è¡æ´ç²¾ç»çè°æ´ãä¸ºäºå®ç° PCDï¼æä»¬æåºäºä¸ä¸ªééæ©ç ï¼å®ä½¿ç¨ä¸¤ä¸ªå³é®ç»ä»¶æ¥æè·æ°æ®éåééä¹é´çå³ç³»ï¼1ï¼ä¸ä¸ªç¸å³æ§ç©éµï¼å®å¯¹ééä¹é´çç¸å¯¹ä¾èµæ§è¿è¡ç¼ç ï¼ä»¥å 2ï¼å­¦ä¹ ç¹å®äºæ¯ä¸ªæ°æ®éçç»å¯¹ä¾èµæ§çååæ°ï¼å¯¹ç¸å³æ§ç©éµè¿è¡ç»åãæä»¬å¨ TS ä¸­çåä¸ªä»»å¡ï¼åæ¬é¢æµãåç±»ãæè¡¥åå¼å¸¸æ£æµï¼ä¸­éªè¯äº PCD çæææ§ï¼å¨ä¸åçè®¾ç½®ä¸ï¼åæ¬ä½¿ç¨ TS åºç¡æ¨¡åååä»»å¡æ¨¡åçå°éæ ·æ¬åé¶æ ·æ¬åºæ¯ãä»£ç å¯ä» https://github.com/seunghan96/CM è·å¾ã

##### **OS-ATLAS: A Foundation Action Model for Generalist GUI Agents**
2410.23218v1 by Zhiyong Wu, Zhenyu Wu, Fangzhi Xu, Yian Wang, Qiushi Sun, Chengyou Jia, Kanzhi Cheng, Zichen Ding, Liheng Chen, Paul Pu Liang, Yu Qiao

Existing efforts in building GUI agents heavily rely on the availability of
robust commercial Vision-Language Models (VLMs) such as GPT-4o and
GeminiProVision. Practitioners are often reluctant to use open-source VLMs due
to their significant performance lag compared to their closed-source
counterparts, particularly in GUI grounding and Out-Of-Distribution (OOD)
scenarios. To facilitate future research in this area, we developed OS-Atlas -
a foundational GUI action model that excels at GUI grounding and OOD agentic
tasks through innovations in both data and modeling. We have invested
significant engineering effort in developing an open-source toolkit for
synthesizing GUI grounding data across multiple platforms, including Windows,
Linux, MacOS, Android, and the web. Leveraging this toolkit, we are releasing
the largest open-source cross-platform GUI grounding corpus to date, which
contains over 13 million GUI elements. This dataset, combined with innovations
in model training, provides a solid foundation for OS-Atlas to understand GUI
screenshots and generalize to unseen interfaces. Through extensive evaluation
across six benchmarks spanning three different platforms (mobile, desktop, and
web), OS-Atlas demonstrates significant performance improvements over previous
state-of-the-art models. Our evaluation also uncovers valuable insights into
continuously improving and scaling the agentic capabilities of open-source
VLMs.

æè¦ï¼ç¾æç GUI ä»£çå»ºæ§å·¥ä½é«åº¦ä¾è³´æ¼å¼·å¤§çåç¨è¦è¦ºèªè¨æ¨¡å (VLM)ï¼ä¾å¦ GPT-4o å GeminiProVisionãå¯¦åå·¥ä½èéå¸¸ä¸é¡æä½¿ç¨éæ¾åå§ç¢¼ VLMï¼å çºå®åçæè½è¡¨ç¾é ä¸å¦éæºå°æç¢åï¼ç¹å¥æ¯å¨ GUI åºç¤ååå¸å¤ (OOD) å ´æ¯ä¸­ãçºäºä¿é²éæ¹é¢çæªä¾ç ç©¶ï¼æåéç¼äº OS-Atlasï¼éæ¯ä¸ååºç¤ GUI åä½æ¨¡åï¼ééè³æåå»ºæ¨¡çåµæ°ï¼å¨ GUI åºç¤å OOD ä»£çä»»åä¸­è¡¨ç¾åºè²ãæåæå¥å¤§éçå·¥ç¨å¿åä¾éç¼ä¸åéæ¾åå§ç¢¼å·¥å·åï¼ç¨æ¼å¨å¤åå¹³å°ï¼åæ¬ WindowsãLinuxãMacOSãAndroid åç¶²è·¯ï¼ä¸­åæ GUI åºç¤è³æãå©ç¨éåå·¥å·åï¼æåç¼å¸äºè¿ä»çºæ­¢æå¤§çéæ¾åå§ç¢¼è·¨å¹³å° GUI åºç¤èªæåº«ï¼å¶ä¸­åå«è¶é 1300 è¬å GUI åç´ ãæ­¤è³æéçµåäºæ¨¡åè¨ç·´çåµæ°ï¼çº OS-Atlas çè§£ GUI è¢å¹æªåä¸¦æ¦æ¬å°æªè¦éçä»é¢æä¾äºç©©åºçåºç¤ãééæ©«è·¨ä¸åä¸åå¹³å°ï¼è¡åãæ¡ä¸ååç¶²è·¯ï¼çå­ååºæºæ¸¬è©¦é²è¡å»£æ³è©ä¼°ï¼OS-Atlas å±ç¤ºåºæ¯ååçæåé²æ¨¡åæé¡¯èçæè½æåãæåçè©ä¼°ä¹æ­ç¤ºäºå¯¶è²´çè¦è§£ï¼å¯ä»¥æçºæ¹ååæ´å±éæ¾åå§ç¢¼ VLM çä»£çåè½ã

##### **Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval**
2410.23214v2 by Sheryl Hsu, Omar Khattab, Chelsea Finn, Archit Sharma

The hallucinations of large language models (LLMs) are increasingly mitigated
by allowing LLMs to search for information and to ground their answers in real
sources. Unfortunately, LLMs often struggle with posing the right search
queries, especially when dealing with complex or otherwise indirect topics.
Observing that LLMs can learn to search for relevant facts by $\textit{trying}$
different queries and learning to up-weight queries that successfully produce
relevant results, we introduce $\underline{Le}$arning to $\underline{Re}$trieve
by $\underline{T}$rying (LeReT), a reinforcement learning framework that
explores search queries and uses preference-based optimization to improve their
quality. LeReT can improve the absolute retrieval accuracy by up to 29% and the
downstream generator evaluations by 17%. The simplicity and flexibility of
LeReT allows it to be applied to arbitrary off-the-shelf retrievers and makes
it a promising technique for improving general LLM pipelines. Project website:
http://sherylhsu.com/LeReT/.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¹»è¦ºè¶ä¾è¶è½è¢«ç·©è§£ï¼æ¹æ³æ¯è® LLM æå°è³è¨ä¸¦å°å¶ç­æ¡å»ºç«å¨çå¯¦ä¾æºä¸ãä¸å¹¸çæ¯ï¼LLM éå¸¸é£ä»¥æåºæ­£ç¢ºçæå°æ¥è©¢ï¼ç¹å¥æ¯å¨èçè¤éæéæ¥ä¸»é¡æãè§å¯å° LLM å¯ä»¥ééãåè©¦ãä¸åçæ¥è©¢ä¸¦å­¸ç¿å°æåç¢çç¸éçµæçæ¥è©¢é²è¡å æ¬ï¼ä¾å­¸ç¿æå°ç¸éäºå¯¦ï¼æåå¼å¥äºãåè©¦å­¸ç¿æª¢ç´¢ã(LeReT)ï¼éæ¯ä¸åå¼·åå­¸ç¿æ¡æ¶ï¼æ¢ç´¢æå°æ¥è©¢ä¸¦ä½¿ç¨åºæ¼åå¥½çæä½³åä¾æ¹åå¶åè³ªãLeReT å¯ä»¥å°çµå°æª¢ç´¢æºç¢ºåº¦æé«å¤é 29%ï¼ä¸¦å°ä¸æ¸¸ç¢çå¨è©ä¼°æé« 17%ãLeReT çç°¡æ½æ§åéæ´»æ§ä½¿å¶å¯ä»¥æç¨æ¼ä»»æç¾æçæª¢ç´¢å¨ï¼ä¸¦ä½¿å¶æçºæ¹åä¸è¬ LLM ç®¡ç·çæåéæè¡ãå°æ¡ç¶²ç«ï¼http://sherylhsu.com/LeReT/ã

##### **Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks**
2410.23208v1 by Michael Matthews, Michael Beukman, Chris Lu, Jakob Foerster

While large models trained with self-supervised learning on offline datasets
have shown remarkable capabilities in text and image domains, achieving the
same generalisation for agents that act in sequential decision problems remains
an open challenge. In this work, we take a step towards this goal by
procedurally generating tens of millions of 2D physics-based tasks and using
these to train a general reinforcement learning (RL) agent for physical
control. To this end, we introduce Kinetix: an open-ended space of
physics-based RL environments that can represent tasks ranging from robotic
locomotion and grasping to video games and classic RL environments, all within
a unified framework. Kinetix makes use of our novel hardware-accelerated
physics engine Jax2D that allows us to cheaply simulate billions of environment
steps during training. Our trained agent exhibits strong physical reasoning
capabilities, being able to zero-shot solve unseen human-designed environments.
Furthermore, fine-tuning this general agent on tasks of interest shows
significantly stronger performance than training an RL agent *tabula rasa*.
This includes solving some environments that standard RL training completely
fails at. We believe this demonstrates the feasibility of large scale,
mixed-quality pre-training for online RL and we hope that Kinetix will serve as
a useful framework to investigate this further.

æè¦ï¼<paragraph>åç®¡ä½¿ç¨é¢ç·è³æéçèªç£ç£å­¸ç¿è¨ç·´åºä¾çå¤§åæ¨¡åå¨æå­åå½±åé åå±ç¾åºé¡¯èçè½åï¼ä½å°æ¼å¨é åºæ±ºç­åé¡ä¸­å·è¡çä»£çäººéæç¸åçæ¦æ¬æ§ä»ç¶æ¯ä¸åå¬éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåééç¨åºåç¢çæ¸åè¬å 2D åºæ¼ç©ççä»»åï¼ä¸¦ä½¿ç¨éäºä»»åè¨ç·´ä¸åç¨æ¼ç©çæ§å¶çä¸è¬å¼·åå­¸ç¿ (RL) ä»£çäººï¼æéåç®æ¨éé²ä¸æ­¥ãçºæ­¤ï¼æåå¼å¥äº Kinetixï¼ä¸åéæ¾å¼çåºæ¼ç©çç RL ç°å¢ç©ºéï¼å®å¯ä»¥å¨ä¸åçµ±ä¸çæ¶æ§å§è¡¨ç¤ºå¾æ©å¨äººéååæåå°é»ç©éæ²åç¶å¸ RL ç°å¢ç­åç¨®ä»»åãKinetix ä½¿ç¨æåæ°ç©çç¡¬é«å éç©çå¼æ Jax2Dï¼å®è®æåå¯ä»¥å¨è¨ç·´æéä¾¿å®å°æ¨¡æ¬æ¸åååç°å¢æ­¥é©ãæåè¨ç·´åºä¾çä»£çäººå±ç¾åºå¼·å¤§çç©çæ¨çè½åï¼è½å¤ å¨æªç¶è¨ç·´çææ³ä¸è§£æ±ºäººé¡è¨­è¨çç°å¢ãæ­¤å¤ï¼å¨æèè¶£çä»»åä¸å¾®èª¿éåä¸è¬ä»£çäººé¡¯ç¤ºåºæ¯è¨ç·´ä¸åãç½æ¿ãRL ä»£çäººå¼·å¤§çè¡¨ç¾ãéåæ¬è§£æ±ºä¸äºæ¨æº RL è¨ç·´å®å¨å¤±æçç°å¢ãæåç¸ä¿¡éå±ç¤ºäºéå°ç·ä¸ RL é²è¡å¤§è¦æ¨¡ãæ··ååè³ªé è¨ç·´çå¯è¡æ§ï¼æåå¸æ Kinetix è½å¤ ä½çºä¸åæç¨çæ¶æ§ä¾é²ä¸æ­¥ç ç©¶éä»¶äºã</paragraph>

##### **Reliability of Topic Modeling**
2410.23186v1 by Kayla Schroeder, Zach Wood-Doughty

Topic models allow researchers to extract latent factors from text data and
use those variables in downstream statistical analyses. However, these
methodologies can vary significantly due to initialization differences,
randomness in sampling procedures, or noisy data. Reliability of these methods
is of particular concern as many researchers treat learned topic models as
ground truth for subsequent analyses. In this work, we show that the standard
practice for quantifying topic model reliability fails to capture essential
aspects of the variation in two widely-used topic models. Drawing from a
extensive literature on measurement theory, we provide empirical and
theoretical analyses of three other metrics for evaluating the reliability of
topic models. On synthetic and real-world data, we show that McDonald's
$\omega$ provides the best encapsulation of reliability. This metric provides
an essential tool for validation of topic model methodologies that should be a
standard component of any topic model-based research.

æè¦ï¼ä¸»é¡æ¨¡åè®ç ç©¶äººå¡è½å¤ å¾ææ¬è³æä¸­èåæ½å¨å å­ï¼ä¸¦å¨å¾çºççµ±è¨åæä¸­ä½¿ç¨éäºè®æ¸ãç¶èï¼éäºæ¹æ³è«å¯è½å çºåå§åçå·®ç°ãæ½æ¨£ç¨åºçé¨æ©æ§æè³æéè¨èæé¡¯èçå·®ç°ãéäºæ¹æ³çå¯é æ§æ¯ç¹å¥ä»¤äººéæ³¨çï¼å çºè¨±å¤ç ç©¶äººå¡å°å­¸ç¿å°çä¸»é¡æ¨¡åè¦çºå¾çºåæççå¯¦ä¾æãå¨éé å·¥ä½ä¸­ï¼æåå±ç¤ºäºéåä¸»é¡æ¨¡åå¯é æ§çæ¨æºå¯¦åç¡æ³ææå°å©ç¨®å»£æ³ä½¿ç¨çä¸»é¡æ¨¡åä¸­è®ç°çåºæ¬é¢åãæåå¾æ¸¬éçè«çå»£æ³æç»ä¸­æ±²åéæï¼æä¾äºå¶ä»ä¸åç¨æ¼è©ä¼°ä¸»é¡æ¨¡åå¯é æ§çææ¨çç¶é©åçè«åæãå¨åæåçå¯¦ä¸ççè³æä¸­ï¼æåå±ç¤ºäºéº¥ååç´ç $\omega$ æä¾äºæä½³çå¯é æ§æ¦æ¬ãéåææ¨æä¾äºä¸åéè¦çå·¥å·ï¼ç¨æ¼é©è­ä¸»é¡æ¨¡åæ¹æ³è«ï¼èéæè©²æ¯ä»»ä½åºæ¼ä¸»é¡æ¨¡åçç ç©¶çæ¨æºçµæé¨åã

##### **ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**
2410.23182v1 by Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu

Transformer-based architectures have dominated various areas of machine
learning in recent years. In this paper, we introduce a novel robust attention
mechanism designed to enhance the resilience of transformer-based
architectures. Crucially, this technique can be integrated into existing
transformers as a plug-and-play layer, improving their robustness without the
need for additional training or fine-tuning. Through comprehensive experiments
and ablation studies, we demonstrate that our ProTransformer significantly
enhances the robustness of transformer models across a variety of prediction
tasks, attack mechanisms, backbone architectures, and data domains. Notably,
without further fine-tuning, the ProTransformer consistently improves the
performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT,
ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler
attack. Furthermore, ProTransformer shows promising resilience in large
language models (LLMs) against prompting-based attacks, improving the
performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing
Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the
language domain, ProTransformer also demonstrates outstanding robustness in
both vision and graph domains.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼åºæ¼ Transformer çæ¶æ§ä¸»å°äºæ©å¨å­¸ç¿çååé åãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ç¨®æ°ç©ä¸å¼·å¤§çæ³¨æåæ©å¶ï¼æ¨å¨å¢å¼·åºæ¼ Transformer çæ¶æ§çéæ§ãè³ééè¦çæ¯ï¼æ­¤æè¡å¯ä»¥ä½çºå³æå³ç¨çå±¤æ´åå°ç¾æç Transformer ä¸­ï¼å¨ç¡éé¡å¤è¨ç·´æå¾®èª¿çææ³ä¸æé«å¶ç©©å¥æ§ãééå¨é¢çå¯¦é©åæ¶èç ç©¶ï¼æåè­æäºæåç ProTransformer å¨åç¨®é æ¸¬ä»»åãæ»ææ©å¶ãä¸»å¹¹æ¶æ§åæ¸æé åä¸­é¡¯èå¢å¼·äº Transformer æ¨¡åçç©©å¥æ§ãå¼å¾æ³¨æçæ¯ï¼å¨ä¸é²ä¸æ­¥å¾®èª¿çææ³ä¸ï¼ProTransformer å¨ç¶å¸ç TextFooler æ»æä¸ï¼åå¥çº BERTãALBERTãDistilBERT å RoBERTa æåäº 19.5%ã28.3%ã16.1% å 11.4% çæ§è½ãæ­¤å¤ï¼ProTransformer å¨åºæ¼æç¤ºçæ»æä¸­å°å¤§åèªè¨æ¨¡å (LLM) é¡¯ç¤ºåºæå¸æçéæ§ï¼åå¥å° T5 å LLaMA çæ§è½æåäº 24.8% å 17.8%ï¼ä¸¦å¨è¶çæ»æä¸­å° Vicuna çæ§è½å¹³åæåäº 10.4%ãé¤äºèªè¨é åä¹å¤ï¼ProTransformer å¨è¦è¦ºååå½¢é åä¹è¡¨ç¾åºåºè²çç©©å¥æ§ã</paragraph>

##### **ReasoningRec: Bridging Personalized Recommendations and Human-Interpretable Explanations through LLM Reasoning**
2410.23180v1 by Millennium Bismay, Xiangjue Dong, James Caverlee

This paper presents ReasoningRec, a reasoning-based recommendation framework
that leverages Large Language Models (LLMs) to bridge the gap between
recommendations and human-interpretable explanations. In contrast to
conventional recommendation systems that rely on implicit user-item
interactions, ReasoningRec employs LLMs to model users and items, focusing on
preferences, aversions, and explanatory reasoning. The framework utilizes a
larger LLM to generate synthetic explanations for user preferences,
subsequently used to fine-tune a smaller LLM for enhanced recommendation
accuracy and human-interpretable explanation. Our experimental study
investigates the impact of reasoning and contextual information on personalized
recommendations, revealing that the quality of contextual and personalized data
significantly influences the LLM's capacity to generate plausible explanations.
Empirical evaluations demonstrate that ReasoningRec surpasses state-of-the-art
methods by up to 12.5\% in recommendation prediction while concurrently
providing human-intelligible explanations. The code is available here:
https://github.com/millenniumbismay/reasoningrec.

æè¦ï¼æ¬ææåºäº ReasoningRecï¼éæ¯ä¸ååºæ¼æ¨ççæ¨è¦æ¶æ§ï¼å®å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾å½åå»ºè­°åäººé¡å¯è§£éçèªªæä¹éçå·®è·ãèä¾è³´æ¼é±å¼ä½¿ç¨èé ç®äºåçå³çµ±æ¨è¦ç³»çµ±ç¸åï¼ReasoningRec ä½¿ç¨ LLM å°ä½¿ç¨èåé ç®é²è¡å»ºæ¨¡ï¼èéæ¼åå¥½ãå­æ¡åèªªææ§æ¨çãè©²æ¶æ§å©ç¨ä¸åè¼å¤§ç LLM çºä½¿ç¨èçåå¥½çæç¶åèªªæï¼ç¶å¾ç¨æ¼å¾®èª¿ä¸åè¼å°ç LLMï¼ä»¥å¢å¼·æ¨è¦æºç¢ºæ§åäººé¡å¯è§£éçèªªæãæåçå¯¦é©ç ç©¶æ¢è¨äºæ¨çåèæ¯è³è¨å°åäººåæ¨è¦çå½±é¿ï¼æ­ç¤ºäºèæ¯ååäººåè³æçåè³ªæé¡¯èå½±é¿ LLM çæåçèªªæçè½åãç¶é©è©ä¼°è¡¨æï¼ReasoningRec å¨æ¨è¦é æ¸¬æ¹é¢è¶è¶äºæåé²çæ¹æ³ï¼é«é 12.5%ï¼åææä¾äºäººé¡å¯ä»¥çè§£çèªªæãç¨å¼ç¢¼å¨æ­¤èæä¾ï¼https://github.com/millenniumbismay/reasoningrecã

##### **SciPIP: An LLM-based Scientific Paper Idea Proposer**
2410.23166v1 by Wenxiao Wang, Lihui Gu, Liye Zhang, Yunxiang Luo, Yi Dai, Chen Shen, Liang Xie, Binbin Lin, Xiaofei He, Jieping Ye

The exponential growth of knowledge and the increasing complexity of
interdisciplinary research pose significant challenges for researchers,
including information overload and difficulties in exploring novel ideas. The
advancements in large language models (LLMs), such as GPT-4, have shown great
potential in enhancing idea proposals, but how to effectively utilize large
models for reasonable idea proposal has not been thoroughly explored. This
paper proposes a scientific paper idea proposer (SciPIP). Based on a
user-provided research background, SciPIP retrieves helpful papers from a
literature database while leveraging the capabilities of LLMs to generate more
novel and feasible ideas. To this end, 1) we construct a literature retrieval
database, extracting lots of papers' multi-dimension information for fast
access. Then, a literature retrieval method based on semantics, entity, and
citation co-occurrences is proposed to search relevant literature from multiple
aspects based on the user-provided background. 2) After literature retrieval,
we introduce dual-path idea proposal strategies, where one path infers
solutions from the retrieved literature and the other path generates original
ideas through model brainstorming. We then combine the two to achieve a good
balance between feasibility and originality. Through extensive experiments on
the natural language processing (NLP) field, we demonstrate that SciPIP can
retrieve citations similar to those of existing top conference papers and
generate many ideas consistent with them. Additionally, we evaluate the
originality of other ideas generated by SciPIP using large language models,
further validating the effectiveness of our proposed method. The code and the
database are released at https://github.com/cheerss/SciPIP.

æè¦ï¼ç¥è­çææ¸æé·åè·¨é åç ç©¶çè¤éæ§æ¥çå¢å ï¼å°ç ç©¶äººå¡æ§æéå¤§ææ°ï¼åæ¬è³è¨éè¼åæ¢ç´¢æ°é»å­çå°é£ãå¤§åèªè¨æ¨¡å (LLM) çé²æ­¥ï¼ä¾å¦ GPT-4ï¼å·²é¡¯ç¤ºåºå¢å¼·é»å­ææ¡çå·¨å¤§æ½åï¼ä½å¦ä½ææå©ç¨å¤§åæ¨¡åé²è¡åççé»å­ææ¡å°æªè¢«å¾¹åºæ¢è¨ãæ¬ææåºäºä¸åç§å­¸è«æé»å­ææ¡å¨ (SciPIP)ãåºæ¼ä½¿ç¨èæä¾çç ç©¶èæ¯ï¼SciPIP å¾æç»è³æåº«ä¸­æª¢ç´¢æç¨çè«æï¼åæå©ç¨ LLM çåè½ä¾ç¢çæ´å¤æ°ç©ä¸å¯è¡çé»å­ãçºæ­¤ï¼1) æåå»ºæ§äºä¸åæç»æª¢ç´¢è³æåº«ï¼æåå¤§éè«æçå¤ç¶­è³è¨ä»¥å¿«éå­åãç¶å¾ï¼æåºä¸ååºæ¼èªæãå¯¦é«åå¼æå±ç¾çæç»æª¢ç´¢æ¹æ³ï¼ä»¥åºæ¼ä½¿ç¨èæä¾çèæ¯å¾å¤åé¢åæå°ç¸éæç»ã2) å¨æç»æª¢ç´¢ä¹å¾ï¼æåä»ç´¹äºéè·¯å¾é»å­ææ¡ç­ç¥ï¼å¶ä¸­ä¸æ¢è·¯å¾å¾æª¢ç´¢å°çæç»ä¸­æ¨è«åºè§£æ±ºæ¹æ¡ï¼èå¦ä¸æ¢è·¯å¾åééæ¨¡åè¦åæ¿çªç¢çåå§é»å­ãç¶å¾æåå°å©èçµåèµ·ä¾ï¼å¨å¯è¡æ§åååµæ§ä¹éåå¾è¯å¥½çå¹³è¡¡ãééå¨èªç¶èªè¨èç (NLP) é åé²è¡å»£æ³çå¯¦é©ï¼æåè­æ SciPIP å¯ä»¥æª¢ç´¢å°èç¾æé å°æè­°è«æé¡ä¼¼çå¼æï¼ä¸¦ç¢çè¨±å¤èå®åä¸è´çé»å­ãæ­¤å¤ï¼æåä½¿ç¨å¤§åèªè¨æ¨¡åè©ä¼° SciPIP ç¢ççå¶ä»é»å­çååµæ§ï¼é²ä¸æ­¥é©è­æåæåºçæ¹æ³çæææ§ãç¨å¼ç¢¼åè³æåº«å·²å¨ https://github.com/cheerss/SciPIP ç¼å¸ã

##### **FlexTSF: A Universal Forecasting Model for Time Series with Variable Regularities**
2410.23160v1 by Jingge Xiao, Yile Chen, Gao Cong, Wolfgang Nejdl, Simon Gottschalk

Developing a foundation model for time series forecasting across diverse
domains has attracted significant attention in recent years. Existing works
typically assume regularly sampled, well-structured data, limiting their
applicability to more generalized scenarios where time series often contain
missing values, unequal sequence lengths, and irregular time intervals between
measurements. To cover diverse domains and handle variable regularities, we
propose FlexTSF, a universal time series forecasting model that possesses
better generalization and natively support both regular and irregular time
series. FlexTSF produces forecasts in an autoregressive manner and incorporates
three novel designs: VT-Norm, a normalization strategy to ablate data domain
barriers, IVP Patcher, a patching module to learn representations from flexibly
structured time series, and LED attention, an attention mechanism to seamlessly
integrate these two and propagate forecasts with awareness of domain and time
information. Experiments on 12 datasets show that FlexTSF outperforms
state-of-the-art forecasting models respectively designed for regular and
irregular time series. Furthermore, after self-supervised pre-training, FlexTSF
shows exceptional performance in both zero-shot and few-show settings for time
series forecasting.

æè¦ï¼è¿å¹´ä¾ï¼éç¼ä¸åé©ç¨æ¼ä¸åé åçæéåºåé æ¸¬åºç¤æ¨¡åååéæ³¨ãç¾æçç ç©¶éå¸¸åè¨­å®æåæ¨£ãçµæ§è¯å¥½çè³æï¼ééå¶äºå®åå¨æ´å»£æ³çå ´æ¯ä¸­æç¨ï¼å¨éäºå ´æ¯ä¸­ï¼æéåºåéå¸¸åå«éºå¤±å¼ãä¸ç­çåºåé·åº¦åæ¸¬éä¹éä¸è¦åçæéééãçºäºæ¶µèä¸åçé åä¸¦èçå¯è®çè¦å¾æ§ï¼æåæåº FlexTSFï¼éæ¯ä¸åéç¨çæéåºåé æ¸¬æ¨¡åï¼å®æææ´å¥½çæ¦æ¬æ§ï¼ä¸¦ä¸åçæ¯æ´è¦ååä¸è¦åçæéåºåãFlexTSF ä»¥èªè¿´æ­¸çæ¹å¼ç¢çé æ¸¬ï¼ä¸¦çµåäºä¸é æ°ç©çè¨­è¨ï¼VT-Normï¼ä¸ç¨®æ¶é¤è³æé åéç¤çæ¨æºåç­ç¥ï¼IVP Patcherï¼ä¸åå¾å½æ§çµæ§æéåºåä¸­å­¸ç¿è¡¨å¾µçä¿®è£æ¨¡çµï¼LED æ³¨æåï¼ä¸ç¨®ç¡ç¸«æ´åéå©åæ¨¡çµä¸¦å³æ­å°é ååæéè³è¨ææè­çé æ¸¬çæ³¨æåæ©å¶ãå¨ 12 åè³æéä¸çå¯¦é©è¡¨æï¼FlexTSF åªæ¼åå¥çºè¦ååä¸è¦åæéåºåè¨­è¨çææ°é æ¸¬æ¨¡åãæ­¤å¤ï¼å¨èªæç£ç£é è¨ç·´å¾ï¼FlexTSF å¨æéåºåé æ¸¬çé¶æ¬¡å­¸ç¿åå°æ¬¡å­¸ç¿è¨­å®ä¸­é½è¡¨ç¾åºåè¶çæè½ã

##### **Fourier Amplitude and Correlation Loss: Beyond Using L2 Loss for Skillful Precipitation Nowcasting**
2410.23159v1 by Chiu-Wai Yan, Shi Quan Foo, Van Hoan Trinh, Dit-Yan Yeung, Ka-Hing Wong, Wai-Kin Wong

Deep learning approaches have been widely adopted for precipitation
nowcasting in recent years. Previous studies mainly focus on proposing new
model architectures to improve pixel-wise metrics. However, they frequently
result in blurry predictions which provide limited utility to forecasting
operations. In this work, we propose a new Fourier Amplitude and Correlation
Loss (FACL) which consists of two novel loss terms: Fourier Amplitude Loss
(FAL) and Fourier Correlation Loss (FCL). FAL regularizes the Fourier amplitude
of the model prediction and FCL complements the missing phase information. The
two loss terms work together to replace the traditional $L_2$ losses such as
MSE and weighted MSE for the spatiotemporal prediction problem on signal-based
data. Our method is generic, parameter-free and efficient. Extensive
experiments using one synthetic dataset and three radar echo datasets
demonstrate that our method improves perceptual metrics and meteorology skill
scores, with a small trade-off to pixel-wise accuracy and structural
similarity. Moreover, to improve the error margin in meteorological skill
scores such as Critical Success Index (CSI) and Fractions Skill Score (FSS), we
propose and adopt the Regional Histogram Divergence (RHD), a distance metric
that considers the patch-wise similarity between signal-based imagery patterns
with tolerance to local transforms. Code is available at
https://github.com/argenycw/FACL

æè¦ï¼æ·±åº¦å­¦ä¹ æ¹æ³è¿å¹´æ¥å·²è¢«å¹¿æ³ç¨äºéæ°´ä¸´è¿é¢æ¥ãä»¥å¾çç ç©¶ä¸»è¦éä¸­å¨æåºæ°çæ¨¡åæ¶æä»¥æ¹åéåç´ åº¦éãç¶èï¼å®ä»¬ç»å¸¸å¯¼è´æ¨¡ç³çé¢æµï¼è¿ä¸ºé¢æ¥æä½æä¾äºæéçæç¨ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäºä¸ç§æ°çåéå¶æ¯å¹åç¸å³æå¤± (FACL)ï¼å®ç±ä¸¤ä¸ªæ°é¢çæå¤±é¡¹ç»æï¼åéå¶æ¯å¹æå¤± (FAL) ååéå¶ç¸å³æå¤± (FCL)ãFAL è§èåæ¨¡åé¢æµçåéå¶æ¯å¹ï¼è FCL è¡¥åäºç¼ºå¤±çç¸ä½ä¿¡æ¯ãè¿ä¸¤ä¸ªæå¤±é¡¹å±åä½ç¨ï¼åä»£äºåºäºä¿¡å·æ°æ®çæ¶ç©ºé¢æµé®é¢çä¼ ç» $L_2$ æå¤±ï¼ä¾å¦ MSE åå æ MSEãæä»¬çæ¹æ³æ¯éç¨çãæ åæ°ä¸é«æçãä½¿ç¨ä¸ä¸ªåææ°æ®éåä¸ä¸ªé·è¾¾åæ³¢æ°æ®éè¿è¡çå¹¿æ³å®éªè¡¨æï¼æä»¬çæ¹æ³æ¹è¿äºæç¥åº¦éåæ°è±¡æè½è¯åï¼å¯¹éåç´ ç²¾åº¦åç»æç¸ä¼¼æ§çå½±åå¾å°ãæ­¤å¤ï¼ä¸ºäºæé«æ°è±¡æè½è¯åä¸­çè¯¯å·®èå´ï¼ä¾å¦ä¸´çæåææ° (CSI) ååæ°æè½è¯å (FSS)ï¼æä»¬æåºå¹¶éç¨åºåç´æ¹å¾æ£åº¦ (RHD)ï¼è¿æ¯ä¸ç§è·ç¦»åº¦éï¼å®èèäºåºäºä¿¡å·çå¾åæ¨¡å¼ä¹é´çåçº§ç¸ä¼¼æ§ï¼å¹¶å®¹å¿å±é¨åæ¢ãä»£ç å¯å¨ https://github.com/argenycw/FACL è·å¾

##### **VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning**
2410.23156v1 by Yichao Liang, Nishanth Kumar, Hao Tang, Adrian Weller, Joshua B. Tenenbaum, Tom Silver, JoÃ£o F. Henriques, Kevin Ellis

Broadly intelligent agents should form task-specific abstractions that
selectively expose the essential elements of a task, while abstracting away the
complexity of the raw sensorimotor space. In this work, we present
Neuro-Symbolic Predicates, a first-order abstraction language that combines the
strengths of symbolic and neural knowledge representations. We outline an
online algorithm for inventing such predicates and learning abstract world
models. We compare our approach to hierarchical reinforcement learning,
vision-language model planning, and symbolic predicate invention approaches, on
both in- and out-of-distribution tasks across five simulated robotic domains.
Results show that our approach offers better sample complexity, stronger
out-of-distribution generalization, and improved interpretability.

æè¦ï¼å»£æ³æºè½ä»£çæè©²å½¢æç¹å®ä»»åçæ½è±¡ï¼é¸ææ§å°æ­é²ä»»åçæ¬è³ªåç´ ï¼åææ½è±¡æåå§ææ¸¬éåç©ºéçè¤éæ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºç¥ç¶ç¬¦èè¬è©ï¼ä¸ç¨®çµåç¬¦èåç¥ç¶ç¥è­è¡¨ç¤ºçåªé»çä¸éæ½è±¡èªè¨ãæåæ¦è¿°äºä¸ç¨®ç¨æ¼ç¼ææ­¤é¡è¬è©åå­¸ç¿æ½è±¡ä¸çæ¨¡åçç·ä¸æ¼ç®æ³ãæåå°æåçåæ³èåå±¤å¼·åå­¸ç¿ãè¦è¦ºèªè¨æ¨¡åè¦ååç¬¦èè¬è©ç¼ææ¹æ³é²è¡æ¯è¼ï¼å¨äºåæ¨¡æ¬æ©å¨äººé åçåå¸å§ååå¸å¤ä»»åä¸é²è¡æ¯è¼ãçµæè¡¨æï¼æåçåæ³æä¾äºæ´å¥½çç¯ä¾è¤éåº¦ãæ´å¼·çåå¸å¤æ¦æ¬ååæ¹é²çå¯è§£éæ§ã

##### **Public Domain 12M: A Highly Aesthetic Image-Text Dataset with Novel Governance Mechanisms**
2410.23144v1 by Jordan Meyer, Nick Padgett, Cullen Miller, Laura Exline

We present Public Domain 12M (PD12M), a dataset of 12.4 million high-quality
public domain and CC0-licensed images with synthetic captions, designed for
training text-to-image models. PD12M is the largest public domain image-text
dataset to date, with sufficient size to train foundation models while
minimizing copyright concerns. Through the Source.Plus platform, we also
introduce novel, community-driven dataset governance mechanisms that reduce
harm and support reproducibility over time.

æè¦ï¼<paragraph>æåæä¾å¬å±é å 12M (PD12M)ï¼ä¸åææ 1240 è¬å¼µé«åè³ªå¬å±é åå CC0 ææ¬åççè³æéï¼æ­éäººé æ¨é¡ï¼ç¨æ¼è¨ç·´æå­è½åçæ¨¡åãPD12M æ¯è¿ä»çºæ­¢æå¤§çå¬å±é ååçæå­è³æéï¼è¦æ¨¡è¶³å¤ ç¨æ¼è¨ç·´åºç¤æ¨¡åï¼åææå¤§éåº¦å°æ¸å°çæ¬åé¡ãéé Source.Plus å¹³å°ï¼æåéå¼å¥äºæ°ç©çãç¤¾ç¾¤é©åçè³æéæ²»çæ©å¶ï¼ä»¥æ¸å°å±å®³ä¸¦é¨èæéæ¨ç§»æ¯æ´å¯è¤è£½æ§ã</paragraph>

##### **Fair Division with Market Values**
2410.23137v1 by Siddharth Barman, Soroush Ebadian, Mohamad Latifian, Nisarg Shah

We introduce a model of fair division with market values, where indivisible
goods must be partitioned among agents with (additive) subjective valuations,
and each good additionally has a market value. The market valuation can be
viewed as a separate additive valuation that holds identically across all the
agents. We seek allocations that are simultaneously fair with respect to the
subjective valuations and with respect to the market valuation.
  We show that an allocation that satisfies stochastically-dominant
envy-freeness up to one good (SD-EF1) with respect to both the subjective
valuations and the market valuation does not always exist, but the weaker
guarantee of EF1 with respect to the subjective valuations along with SD-EF1
with respect to the market valuation can be guaranteed. We also study a number
of other guarantees such as Pareto optimality, EFX, and MMS. In addition, we
explore non-additive valuations and extend our model to cake-cutting. Along the
way, we identify several tantalizing open questions.

æè¦ï¼æåå¼å¥ä¸åå·æå¸å ´å¹å¼çå¬å¹³åéæ¨¡åï¼å¶ä¸­ä¸å¯åå²çååå¿é åéçµ¦å·æï¼å æ³ï¼ä¸»è§ä¼°å¼çä»£çäººï¼ä¸æ¯ä»¶ååé¡å¤å·æå¸å ´å¹å¼ãå¸å ´ä¼°å¼å¯ä»¥è¦çºä¸åç¨ç«çå æ³ä¼°å¼ï¼å¨ææä»£çäººä¹éå®å¨ç¸åãæåå°æ±å¨ä¸»è§ä¼°å¼åå¸å ´ä¼°å¼æ¹é¢åæå¬å¹³çåéã
æåè­æäºä¸ååéï¼æ»¿è¶³éæ¼ä¸åååçé¨æ©æ¯éå«å¦èªç±ï¼SD-EF1ï¼ï¼éæ¼ä¸»è§ä¼°å¼åå¸å ´ä¼°å¼ï¼ä¸¦ä¸ç¸½æ¯å­å¨ï¼ä½æ¯éæ¼ä¸»è§ä¼°å¼çè¼å¼±ä¿è­ EF1 ä»¥åéæ¼å¸å ´ä¼°å¼ç SD-EF1 å¯ä»¥å¾å°ä¿è­ãæåéç ç©¶äºè¨±å¤å¶ä»ä¿è­ï¼ä¾å¦å¸ç´¯ææåªæ§ãEFX å MMSãæ­¤å¤ï¼æåæ¢ç´¢éå æ³ä¼°å¼ï¼ä¸¦å°æåçæ¨¡åæ´å±å°èç³åå²ãå¨æ­¤éç¨ä¸­ï¼æåç¼ç¾äºå¹¾åèªäººçéæ¾åé¡ã

##### **Crowdsourcing Lexical Diversity**
2410.23133v1 by Hadi Khalilia, Jahna Otterbacher, Gabor Bella, Rusma Noortyani, Shandy Darma, Fausto Giunchiglia

Lexical-semantic resources (LSRs), such as online lexicons or wordnets, are
fundamental for natural language processing applications. In many languages,
however, such resources suffer from quality issues: incorrect entries,
incompleteness, but also, the rarely addressed issue of bias towards the
English language and Anglo-Saxon culture. Such bias manifests itself in the
absence of concepts specific to the language or culture at hand, the presence
of foreign (Anglo-Saxon) concepts, as well as in the lack of an explicit
indication of untranslatability, also known as cross-lingual \emph{lexical
gaps}, when a term has no equivalent in another language. This paper proposes a
novel crowdsourcing methodology for reducing bias in LSRs. Crowd workers
compare lexemes from two languages, focusing on domains rich in lexical
diversity, such as kinship or food. Our LingoGap crowdsourcing tool facilitates
comparisons through microtasks identifying equivalent terms, language-specific
terms, and lexical gaps across languages. We validated our method by applying
it to two case studies focused on food-related terminology: (1) English and
Arabic, and (2) Standard Indonesian and Banjarese. These experiments identified
2,140 lexical gaps in the first case study and 951 in the second. The success
of these experiments confirmed the usability of our method and tool for future
large-scale lexicon enrichment tasks.

æè¦ï¼è©å½èªç¾©è³æºï¼LSRï¼ï¼ä¾å¦ç·ä¸è©å½æè©ç¶²ï¼å°æ¼èªç¶èªè¨èçæç¨ä¾èªªè³ééè¦ãç¶èï¼å¨è¨±å¤èªè¨ä¸­ï¼æ­¤é¡è³æºå­å¨åè³ªåé¡ï¼æ¢ç®ä¸æ­£ç¢ºãä¸å®æ´ï¼ä»¥åé®®å°æ¢è¨çååè±èªåçæ ¼é­¯æåéæåçåé¡ãéç¨®åè¦è¡¨ç¾å¨ç¼ºä¹ç¹å®æ¼æéèªè¨ææåçæ¦å¿µãå­å¨å¤ä¾ï¼çæ ¼é­¯æåéï¼æ¦å¿µï¼ä»¥åç¼ºä¹æç¢ºè¡¨ç¤ºä¸å¯ç¿»è­¯çææ¨ï¼ä¹ç¨±çºè·¨èªè¨ãè©å½å·®è·ãï¼è¡¨ç¤ºä¸åè©å¨å¦ä¸ç¨®èªè¨ä¸­æ²æç­å¹è©ãæ¬ææåºäºä¸ç¨®æ°çç¾¤ç¾å¤åæ¹æ³ï¼ç¨æ¼æ¸å° LSR ä¸­çåè¦ãç¾¤ç¾å·¥ä½èæ¯è¼å©ç¨®èªè¨çè©ç´ ï¼éé»æ¾å¨è©å½å¤æ¨£æ§è±å¯çé åï¼ä¾å¦è¦ªå±¬éä¿æé£ç©ãæåç LingoGap ç¾¤ç¾å¤åå·¥å·ééå¾®ä»»åè­å¥ç­å¹è©ãç¹å®èªè¨è©å½åè·¨èªè¨è©å½å·®è·ï¼é²èä¿é²æ¯è¼ãæåééå°æ¹æ³æç¨æ¼å©åä»¥é£ç©ç¸éè¡èªçºéé»çæ¡ä¾ç ç©¶ä¾é©è­æ¹æ³ï¼ï¼1ï¼è±èªåé¿æä¼¯èªï¼ä»¥åï¼2ï¼æ¨æºå°å°¼èªåç­è³ç¾èªãéäºå¯¦é©å¨ç¬¬ä¸åæ¡ä¾ç ç©¶ä¸­è­å¥åº 2,140 åè©å½å·®è·ï¼å¨ç¬¬äºåæ¡ä¾ç ç©¶ä¸­è­å¥åº 951 åãéäºå¯¦é©çæåé©è­äºæåçæ¹æ³åå·¥å·å¨æªä¾å¤§è¦æ¨¡è©å½è±å¯åä»»åä¸­çå¯ç¨æ§ã

##### **Revisiting MAE pre-training for 3D medical image segmentation**
2410.23132v1 by Tassilo Wald, Constantin Ulrich, Stanislav Lukyanenko, Andrei Goncharov, Alberto Paderno, Leander Maerkisch, Paul F. JÃ¤ger, Klaus Maier-Hein

Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the
potential of vast, untapped clinical datasets, for various downstream
applications that suffer from the scarcity of labeled data. While SSL has
revolutionized fields like natural language processing and computer vision,
their adoption in 3D medical image computing has been limited by three key
pitfalls: Small pre-training dataset sizes, architectures inadequate for 3D
medical image analysis, and insufficient evaluation practices. We address these
issues by i) leveraging a large-scale dataset of 44k 3D brain MRI volumes and
ii) using a Residual Encoder U-Net architecture within the state-of-the-art
nnU-Net framework. iii) A robust development framework, incorporating 5
development and 8 testing brain MRI segmentation datasets, allowed
performance-driven design decisions to optimize the simple concept of Masked
Auto Encoders (MAEs) for 3D CNNs. The resulting model not only surpasses
previous SSL methods but also outperforms the strong nnU-Net baseline by an
average of approximately 3 Dice points. Furthermore, our model demonstrates
exceptional stability, achieving the highest average rank of 2 out of 7
methods, compared to the second-best method's mean rank of 3.

æè¦ï¼èªçç£å­¦ä¹  (SSL) ä¸ºè§£éå¤§éæªå¼åä¸´åºæ°æ®éçæ½åæä¾äºä¸ä¸ªæ¿å¨äººå¿çæºä¼ï¼ç¨äºåç§ä¸æ¸¸åºç¨ç¨åºï¼è¿äºåºç¨ç¨åºå æ è®°æ°æ®ç¨ç¼ºèåå°å½±åãè½ç¶ SSL å·²å½»åºæ¹åäºèªç¶è¯­è¨å¤çåè®¡ç®æºè§è§ç­é¢åï¼ä½å¶å¨ 3D å»å­¦å¾åè®¡ç®ä¸­çéç¨åå°ä¸ä¸ªä¸»è¦ç¼ºé·çéå¶ï¼å°åé¢è®­ç»æ°æ®éå¤§å°ãä¸éç¨äº 3D å»å­¦å¾ååæçæ¶æä»¥åè¯ä¼°å®è·µä¸è¶³ãæä»¬éè¿ä»¥ä¸æ¹å¼è§£å³è¿äºé®é¢ï¼i) å©ç¨ 44k 3D å¤§è MRI ä½ç§¯çå¤§è§æ¨¡æ°æ®éï¼ä»¥å ii) å¨æåè¿ç nnU-Net æ¡æ¶åä½¿ç¨æ®å·®ç¼ç å¨ U-Net æ¶æãiii) ä¸ä¸ªç¨³å¥çå¼åæ¡æ¶ï¼åå« 5 ä¸ªå¼åå 8 ä¸ªæµè¯å¤§è MRI åå²æ°æ®éï¼åè®¸åºäºæ§è½çè®¾è®¡å³ç­æ¥ä¼å 3D CNN çæ©è½èªå¨ç¼ç å¨ (MAE) çç®åæ¦å¿µãç±æ­¤äº§ççæ¨¡åä¸ä»è¶è¶äºä¹åç SSL æ¹æ³ï¼èä¸æ¯å¼ºå¤§ç nnU-Net åºçº¿å¹³åé«åºå¤§çº¦ 3 ä¸ªéª°å­ç¹ãæ­¤å¤ï¼æä»¬çæ¨¡åè¡¨ç°åºéå¡çç¨³å®æ§ï¼å¨ 7 ç§æ¹æ³ä¸­è¾¾å° 2 çæé«å¹³åæåï¼èç¬¬äºå¥½çæ¹æ³çå¹³åæåä¸º 3ã

##### **Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes**
2410.23126v1 by Jerry Yao-Chieh Hu, Dennis Wu, Han Liu

We study the optimal memorization capacity of modern Hopfield models and
Kernelized Hopfield Models (KHMs), a transformer-compatible class of Dense
Associative Memories. We present a tight analysis by establishing a connection
between the memory configuration of KHMs and spherical codes from information
theory. Specifically, we treat the stored memory set as a specialized spherical
code. This enables us to cast the memorization problem in KHMs into a point
arrangement problem on a hypersphere. We show that the optimal capacity of KHMs
occurs when the feature space allows memories to form an optimal spherical
code. This unique perspective leads to: (i) An analysis of how KHMs achieve
optimal memory capacity, and identify corresponding necessary conditions.
Importantly, we establish an upper capacity bound that matches the well-known
exponential lower bound in the literature. This provides the first tight and
optimal asymptotic memory capacity for modern Hopfield models. (ii) A
sub-linear time algorithm $\mathtt{U}\text{-}\mathtt{Hop}$+ to reach KHMs'
optimal capacity. (iii) An analysis of the scaling behavior of the required
feature dimension relative to the number of stored memories. These efforts
improve both the retrieval capability of KHMs and the representation learning
of corresponding transformers. Experimentally, we provide thorough numerical
results to back up theoretical findings.

æè¦ï¼æåç ç©¶ç¾ä»£ Hopfield æ¨¡ååæ ¸å Hopfield æ¨¡å (KHM) çæä½³è¨æ¶å®¹éï¼éæ¯ä¸åèTransformerç¸å®¹çç¨ å¯è¯æ³è¨æ¶é¡å¥ãæåééå»ºç« KHM çè¨æ¶é«çµæèè³è¨çè«ä¸­ççå½¢ç¢¼ä¹éçé£çµï¼æåºå´è¬¹çåæãå·é«ä¾èªªï¼æåå°å²å­çè¨æ¶é«çµè¦çºä¸åç¹æ®ççå½¢ç¢¼ãéä½¿æåè½å¤ å° KHM ä¸­çè¨æ¶é«åé¡è½æçºè¶çé¢ä¸çé»æååé¡ãæåè­æ KHM çæä½³å®¹éç¼çå¨ç¹å¾µç©ºéåè¨±è¨æ¶é«å½¢ææä½³çå½¢ç¢¼æãéåç¨ç¹çè§é»å°è´ï¼(i) å° KHM å¦ä½éå°æä½³è¨æ¶é«å®¹éçåæï¼ä¸¦æ¾åºå°æçå¿è¦æ¢ä»¶ãéè¦çæ¯ï¼æåå»ºç«äºä¸åå®¹éä¸éï¼èæç»ä¸­èåçææ¸ä¸éç¸å¹éãéçºç¾ä»£ Hopfield æ¨¡åæä¾äºç¬¬ä¸åå´è¬¹ä¸æä½³çæ¼¸è¿è¨æ¶é«å®¹éã(ii) ä¸åæ¬¡ç·æ§æéæ¼ç®æ³ $\mathtt{U}\text{-}\mathtt{Hop}$+ï¼ä»¥éå° KHM çæä½³å®¹éã(iii) å°æéç¹å¾µç¶­åº¦ç¸å°æ¼å²å­è¨æ¶é«æ¸éçç¸®æ¾è¡çºçåæãéäºåªååææ¹åäº KHM çæª¢ç´¢è½ååå°æTransformerçè¡¨å¾µå­¸ç¿ãå¨å¯¦é©ä¸­ï¼æåæä¾äºè©³ç¡çæ¸å¼çµæï¼ä»¥æ¯æçè«ç¼ç¾ã

##### **On Memorization of Large Language Models in Logical Reasoning**
2410.23123v1 by Chulin Xie, Yangsibo Huang, Chiyuan Zhang, Da Yu, Xinyun Chen, Bill Yuchen Lin, Bo Li, Badih Ghazi, Ravi Kumar

Large language models (LLMs) achieve good performance on challenging
reasoning benchmarks, yet could also make basic reasoning mistakes. This
contrasting behavior is puzzling when it comes to understanding the mechanisms
behind LLMs' reasoning capabilities. One hypothesis is that the increasingly
high and nearly saturated performance on common reasoning benchmarks could be
due to the memorization of similar problems. In this paper, we systematically
investigate this hypothesis with a quantitative measurement of memorization in
reasoning tasks, using a dynamically generated logical reasoning benchmark
based on Knights and Knaves (K&K) puzzles. We found that LLMs could interpolate
the training puzzles (achieving near-perfect accuracy) after fine-tuning, yet
fail when those puzzles are slightly perturbed, suggesting that the models
heavily rely on memorization to solve those training puzzles. On the other
hand, we show that while fine-tuning leads to heavy memorization, it also
consistently improves generalization performance. In-depth analyses with
perturbation tests, cross difficulty-level transferability, probing model
internals, and fine-tuning with wrong answers suggest that the LLMs learn to
reason on K&K puzzles despite training data memorization. This phenomenon
indicates that LLMs exhibit a complex interplay between memorization and
genuine reasoning abilities. Finally, our analysis with per-sample memorization
score sheds light on how LLMs switch between reasoning and memorization in
solving logical puzzles. Our code and data are available at
https://memkklogic.github.io.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) å¨å·ææ°æ§çæ¨çåºæºä¸åå¾è¯å¥½è¡¨ç¾ï¼ä½ä¹æç¯ä¸åºæ¬çæ¨çé¯èª¤ãéç¨®å°æ¯è¡çºä»¤äººè²»è§£ï¼å çºå®æ¶åçè§£ LLM æ¨çè½åèå¾çæ©å¶ãä¸ååè¨­æ¯ï¼å¨å¸¸è¦æ¨çåºæºä¸è¶ä¾è¶é«ä¸æ¥è¿é£½åçè¡¨ç¾å¯è½æ¯ç±æ¼è¨ä½äºé¡ä¼¼çåé¡ãå¨æ¬æä¸­ï¼æåä½¿ç¨åºæ¼é¨å£«èæ¡æ£ (K&K) è¬é¡çåæçæéè¼¯æ¨çåºæºï¼å°æ¨çä»»åä¸­çè¨æ¶é²è¡å®éæ¸¬éï¼ç³»çµ±æ§å°æ¢è¨éååè¨­ãæåç¼ç¾ï¼LLM å¨å¾®èª¿å¾å¯ä»¥å§æè¨ç·´è¬é¡ï¼éå°æ¥è¿å®ç¾çæºç¢ºåº¦ï¼ï¼ä½å¨éäºè¬é¡ç¨ææ¾åæå»æå¤±æï¼éè¡¨ææ¨¡åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´è¨æ¶ä¾è§£æ±ºéäºè¨ç·´è¬é¡ãå¦ä¸æ¹é¢ï¼æåè¡¨æï¼éç¶å¾®èª¿æå°è´å¤§éçè¨æ¶ï¼ä½å®ä¹ææçºæ¹åæ³åè¡¨ç¾ãä½¿ç¨æ¾åæ¸¬è©¦ãè·¨é£åº¦ç´å¥çå¯å³éæ§ãæ¢æ¸¬æ¨¡åå§é¨çµæ§ä»¥åä½¿ç¨é¯èª¤ç­æ¡é²è¡å¾®èª¿çæ·±å¥åæè¡¨æï¼LLM å­¸æäºå° K&K è¬é¡é²è¡æ¨çï¼åç®¡è¨ç·´æ¸æè¨æ¶ãéç¨®ç¾è±¡è¡¨æï¼LLM å¨è¨æ¶åçæ­£çæ¨çè½åä¹éè¡¨ç¾åºè¤éçç¸äºä½ç¨ãæå¾ï¼æåå°æ¯åæ¨£æ¬è¨æ¶åæ¸çåæé¡æäº LLM å¨è§£æ±ºéè¼¯è¬é¡æå¦ä½å¨æ¨çåè¨æ¶ä¹éåæãæåçç¨å¼ç¢¼åæ¸æå¯å¨ https://memkklogic.github.io/ ç²å¾ã</paragraph>

##### **Teaching a Language Model to Distinguish Between Similar Details using a Small Adversarial Training Set**
2410.23118v1 by Chris Achard

Language models can achieve high accuracy on natural language tasks such as
NLI, but performance suffers on manually created adversarial examples. We
investigate the performance of a language model trained on the Stanford Natural
Language Inference (SNLI) corpus on a manually created adversarial test set. We
then improve the model's performance by fine tuning the model on a small,
manually created adversarial training set, designed to help the language model
to learn to differentiate between similar words and phrases in the data. We
show an increase in accuracy on the adversarial test set (+ 13%) while still
maintaining good performance on the original NLI task. We also show an increase
in accuracy from 91.2% to 92.9% on the most similar contradictions in the SNLI
test set (as judged by cosine similarity).

æè¦ï¼èªè¨æ¨¡åå¨èªç¶èªè¨ä»»åä¸­ï¼ä¾å¦ NLIï¼å¯ä»¥éå°å¾é«çæºç¢ºåº¦ï¼ä½æè½æå¨äººå·¥å»ºç«çå°æç¯ä¾ä¸­ä¸éãæåç ç©¶å¨äººå·¥å»ºç«çå°ææ¸¬è©¦éä¸­ï¼éå°å¨ Stanford èªç¶èªè¨æ¨ç (SNLI) èªæåº«ä¸è¨ç·´çèªè¨æ¨¡åçæè½ãç¶å¾ï¼æåééå¨å°åçãäººå·¥å»ºç«çå°æè¨ç·´éä¸­å¾®èª¿æ¨¡åï¼ä¾æ¹åæ¨¡åçæè½ï¼æ­¤è¨ç·´éæ¨å¨å¹«å©èªè¨æ¨¡åå­¸ç¿ååè³æä¸­é¡ä¼¼çå­è©åçèªãæåé¡¯ç¤ºå¨å°ææ¸¬è©¦éä¸çæºç¢ºåº¦æåï¼+ 13%ï¼ï¼åæå¨åå§ NLI ä»»åä¸ä»ç¶ç¶­æè¯å¥½çæè½ãæåä¹é¡¯ç¤ºå¨ SNLI æ¸¬è©¦éä¸­æé¡ä¼¼ççç¾ä¸çæºç¢ºåº¦å¾ 91.2% æåå° 92.9%ï¼ä¾æé¤å¼¦ç¸ä¼¼åº¦å¤æ·ï¼ã

##### **Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models**
2410.23114v1 by Junjie Wu, Tsz Ting Chung, Kai Chen, Dit-Yan Yeung

Despite the outstanding performance in vision-language reasoning, Large
Vision-Language Models (LVLMs) might generate hallucinated contents that do not
exist in the given image. Most existing LVLM hallucination benchmarks are
constrained to evaluate the object-related hallucinations. However, the
potential hallucination on the relations between two objects, i.e., relation
hallucination, still lacks investigation. To remedy that, in this paper we
design a unified framework to measure object and relation hallucination in
LVLMs simultaneously. The core idea of our framework is to conduct
hallucination evaluation on (object, relation, object) triplets extracted from
LVLMs' responses, and thus, could be easily generalized to different
vision-language tasks. Based on our framework, we further introduce Tri-HE, a
novel Triplet-level Hallucination Evaluation benchmark which can be used to
study both object and relation hallucination at the same time. We conduct
comprehensive evaluations on Tri-HE and observe that the relation hallucination
issue is even more serious than object hallucination among existing LVLMs,
highlighting a previously neglected problem towards reliable LVLMs. Moreover,
based on our findings, we design a simple yet effective training-free approach
to mitigate hallucinations for LVLMs, with which, we exceed all open-sourced
counterparts on Tri-HE, achieving comparable performance with the powerful
GPT-4V. Our dataset and code for the reproduction of our experiments are
available publicly at https://github.com/wujunjie1998/Tri-HE.

æè¦ï¼åç®¡å¨è¦è¦ºèªè¨æ¨çä¸­è¡¨ç¾ååºï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) ä»å¯è½ç¢çä¸å­å¨æ¼çµ¦å®å½±åä¸­çå¹»è¦ºå§å®¹ãå¤§å¤æ¸ç¾æç LVLM å¹»è¦ºåºæºåéæ¼è©ä¼°èç©ä»¶ç¸éçå¹»è¦ºãç¶èï¼å°æ¼å©åç©ä»¶ä¹ééä¿çæ½å¨å¹»è¦ºï¼å³éä¿å¹»è¦ºï¼ä»ç¼ºä¹èª¿æ¥ãçºäºè£æéä¸é»ï¼å¨æ¬æä¸­ï¼æåè¨­è¨äºä¸åçµ±ä¸çæ¶æ§ï¼ä»¥åææ¸¬é LVLMs ä¸­çç©ä»¶åéä¿å¹»è¦ºãæåæ¶æ§çæ ¸å¿ææ³æ¯å¨å¾ LVLMs åæä¸­æåç (ç©ä»¶ãéä¿ãç©ä»¶) ä¸åçµä¸é²è¡å¹»è¦ºè©ä¼°ï¼å æ­¤å¯ä»¥è¼é¬å°æ¦æ¬çºä¸åçè¦è¦ºèªè¨ä»»åãæ ¹ææåçæ¶æ§ï¼æåé²ä¸æ­¥å¼å¥äº Tri-HEï¼éæ¯ä¸åæ°ç©çä¸åçµç´å¹»è¦ºè©ä¼°åºæºï¼å¯ç¨æ¼åæç ç©¶ç©ä»¶åéä¿å¹»è¦ºãæåå° Tri-HE é²è¡äºå¨é¢çè©ä¼°ï¼ä¸¦è§å¯å°éä¿å¹»è¦ºåé¡çè³æ¯ç¾æ LVLMs ä¸­çç©ä»¶å¹»è¦ºæ´å´éï¼çªé¡¯äºä¸åä»¥åè¢«å¿½ç¥çåé¡ï¼æèå¯é ç LVLMs éé²ãæ­¤å¤ï¼æ ¹ææåçç¼ç¾ï¼æåè¨­è¨äºä¸åç°¡å®ä½ææçç¡è¨ç·´æ¹æ³ä¾æ¸è¼ LVLMs çå¹»è¦ºï¼æåä½¿ç¨å®å¨ Tri-HE ä¸è¶è¶äºææéæºå°æï¼éå°äºèå¼·å¤§ç GPT-4V ç¸ç¶çæè½ãæåç¨æ¼éç¾æåå¯¦é©çè³æéåç¨å¼ç¢¼å¯å¨ https://github.com/wujunjie1998/Tri-HE å¬éåå¾ã

##### **Why Gradient Subspace? Identifying and Mitigating LoRA's Bottlenecks in Federated Fine-Tuning of Large Language Models**
2410.23111v2 by Navyansh Mahla, Ganesh Ramakrishnan

Large Language Models (LLMs) have demonstrated remarkable capabilities across
various domains, particularly in task generalization for both text and vision
data. While fine-tuning these models can significantly enhance their
performance on specific downstream tasks, it often requires high-quality data
that cannot be shared due to privacy concerns. Federated Learning (FL) offers a
promising solution for collaborative training without direct data sharing.
However, many parameter-efficient fine-tuning strategies for LLMs in FL,
particularly those based on Low-Rank Adaptation (LoRA), face limitations. In
this paper, we critically analyze the convergence and performance guarantees of
popular FL frameworks utilizing LoRA, highlighting its suboptimal nature due to
constrained subspace learning of low-rank matrices. This limitation hinders
effective fine-tuning of LLMs in federated settings. Through rigorous
analytical and empirical evaluations, we demonstrate that direct weight
averaging outperforms LoRA-based strategies, leading to superior performance
for fine-tuned models. Our comprehensive comparison exposes inefficiencies in
LoRA approaches and underscores the advantages of direct weight aggregation. We
extend our analysis to low-rank gradient-based optimizers, such as GaLore, used
during local training steps. Our findings show that GaLore is a more effective
alternative, outperforming federated LoRA methods like FlexLoRA and FFA-LoRA
across both text and image modalities. While privacy remains paramount in FL
discourse, our focus is on assessing performance outcomes of federated
fine-tuned models and evaluating various FL frameworks from both theoretical
and empirical perspectives. Our findings advocate reassessing the reliance on
LoRA within FL contexts, paving the way for more efficient training
methodologies.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®é åå±ç¾åºéå¡çè½åï¼ç¹å¥æ¯å¨ææ¬åè¦è¦ºè³æçä»»åæ¦æ¬æ¹é¢ãéç¶å¾®èª¿éäºæ¨¡åå¯ä»¥é¡¯èæåå¶å¨ç¹å®ä¸æ¸¸ä»»åä¸­çæè½ï¼ä½ééå¸¸éè¦é«åè³ªçè³æï¼èéäºè³æå¯è½ç¡æ³å é±ç§èéèå±ç¨ãè¯åå­¸ç¿ (FL) æä¾äºä¸åæåéçè§£æ±ºæ¹æ¡ï¼å¯ä»¥é²è¡åä½è¨ç·´ï¼èç¡éç´æ¥å±ç¨è³æãç¶èï¼è¨±å¤éå° LLM å¨ FL ä¸­çåæ¸ææå¾®èª¿ç­ç¥ï¼ç¹å¥æ¯é£äºåºæ¼ä½ç§©é©æ (LoRA) çç­ç¥ï¼é½é¢è¨éå¶ãå¨æ¬æä¸­ï¼æåæ¹å¤æ§å°åæäºä½¿ç¨ LoRA çç±é FL æ¶æ§çæ¶ææ§åæè½ä¿è­ï¼ä¸¦å¼·èª¿å¶æ¬¡ä½³æ§è³ªï¼åå å¨æ¼ä½ç§©ç©é£çåéå­ç©ºéå­¸ç¿ãæ­¤éå¶é»ç¤äºå¨è¯åè¨­å®ä¸­å° LLM é²è¡ææçå¾®èª¿ãééå´è¬¹çåæåç¶é©è©ä¼°ï¼æåè­æç´æ¥æ¬éå¹³ååªæ¼åºæ¼ LoRA çç­ç¥ï¼å¾èæåå¾®èª¿æ¨¡åçæè½ãæåçå¨é¢æ¯è¼æ­é²äº LoRA æ¹æ³çä½æçï¼ä¸¦å¼·èª¿äºç´æ¥æ¬éèåçåªé»ãæåå°åæå»¶ä¼¸è³ä½ç§©åºæ¼æ¢¯åº¦çæä½³åå¨ï¼ä¾å¦ GaLoreï¼éäºæä½³åå¨ç¨æ¼å±é¨è¨ç·´æ­¥é©ãæåçç¼ç¾é¡¯ç¤ºï¼GaLore æ¯ä¸ç¨®æ´ææçæ¿ä»£æ¹æ¡ï¼å¨ææ¬åå½±åæ¨¡å¼ä¸­é½åªæ¼è¯å LoRA æ¹æ³ï¼ä¾å¦ FlexLoRA å FFA-LoRAãéç¶é±ç§å¨ FL è«è¿°ä¸­ä»ç¶è³ééè¦ï¼ä½æåçéé»å¨æ¼è©ä¼°è¯åå¾®èª¿æ¨¡åçæè½çµæï¼ä¸¦å¾çè«åç¶é©çè§åº¦è©ä¼°åç¨® FL æ¶æ§ãæåçç¼ç¾ä¸»å¼µéæ°è©ä¼°å¨ FL èæ¯ä¸­å° LoRA çä¾è³´ï¼çºæ´ææçè¨ç·´æ¹æ³éªè·¯ã

##### **Controllable Game Level Generation: Assessing the Effect of Negative Examples in GAN Models**
2410.23108v1 by Mahsa Bazzaz, Seth Cooper

Generative Adversarial Networks (GANs) are unsupervised models designed to
learn and replicate a target distribution. The vanilla versions of these models
can be extended to more controllable models. Conditional Generative Adversarial
Networks (CGANs) extend vanilla GANs by conditioning both the generator and
discriminator on some additional information (labels). Controllable models
based on complementary learning, such as Rumi-GAN, have been introduced.
Rumi-GANs leverage negative examples to enhance the generator's ability to
learn positive examples. We evaluate the performance of two controllable GAN
variants, CGAN and Rumi-GAN, in generating game levels targeting specific
constraints of interest: playability and controllability. This evaluation is
conducted under two scenarios: with and without the inclusion of negative
examples. The goal is to determine whether incorporating negative examples
helps the GAN models avoid generating undesirable outputs. Our findings
highlight the strengths and weaknesses of each method in enforcing the
generation of specific conditions when generating outputs based on given
positive and negative examples.

æè¦ï¼çæå°æç¶²è·¯ (GAN) çºéç£ç£å¼æ¨¡åï¼æ¨å¨å­¸ç¿ä¸¦è¤è£½ç®æ¨åéãéäºæ¨¡åçé¦èçæ¬å¯å»¶ä¼¸è³æ´å·å¯æ§æ§çæ¨¡åãæ¢ä»¶çæå°æç¶²è·¯ (CGAN) ééå¨çæå¨åå¤å¥å¨ä¸­å å¥ä¸äºé¡å¤è³è¨ (æ¨ç±¤) ä¾å»¶ä¼¸é¦è GANãå·²ç¶å¼å¥äºåºæ¼äºè£å­¸ç¿çå¯æ§æ¨¡åï¼ä¾å¦ Rumi-GANãRumi-GAN å©ç¨è² é¢ç¯ä¾ä¾å¢å¼·çæå¨å­¸ç¿æ­£é¢ç¯ä¾çè½åãæåè©ä¼°äºå©ç¨®å¯æ§ GAN è®é« (CGAN å Rumi-GAN) å¨ç¢çéå°ç¹å®æèè¶£ç´æçéæ²éå¡æ¹é¢çæè½ï¼å¯ç©æ§åå¯æ§æ§ãæ­¤è©ä¼°å¨å©ç¨®å ´æ¯ä¸é²è¡ï¼åå«åä¸åå«è² é¢ç¯ä¾ãç®æ¨æ¯ç¢ºå®ç´å¥è² é¢ç¯ä¾æ¯å¦æå©æ¼ GAN æ¨¡åé¿åç¢çä¸è¯è¼¸åºãæåçç ç©¶çµæçªé¡¯äºæ¯ç¨®æ¹æ³å¨æ ¹æçµ¦å®çæ­£é¢åè² é¢ç¯ä¾ç¢çè¼¸åºæï¼å¨å¼·å¶ç¢çç¹å®æ¢ä»¶æ¹é¢çåªé»åç¼ºé»ã

##### **Guided Game Level Repair via Explainable AI**
2410.23101v1 by Mahsa Bazzaz, Seth Cooper

Procedurally generated levels created by machine learning models can be
unsolvable without further editing. Various methods have been developed to
automatically repair these levels by enforcing hard constraints during the
post-processing step. However, as levels increase in size, these
constraint-based repairs become increasingly slow. This paper proposes using
explainability methods to identify specific regions of a level that contribute
to its unsolvability. By assigning higher weights to these regions,
constraint-based solvers can prioritize these problematic areas, enabling more
efficient repairs. Our results, tested across three games, demonstrate that
this approach can help to repair procedurally generated levels faster.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åç¢ççç¨åºåçæéå¡å¨æªç¶é²ä¸æ­¥ç·¨è¼¯çææ³ä¸å¯è½ç¡æ³è§£æ±ºãå·²ç¶éç¼åºåç¨®æ¹æ³ï¼ééå¨å¾èçæ­¥é©ä¸­å¼·å¶å·è¡ç¡¬ç´æä¾èªåä¿®å¾©éäºéå¡ãç¶èï¼é¨èéå¡å°ºå¯¸å¢å ï¼éäºåºæ¼ç´æçä¿®å¾©è®å¾è¶ä¾è¶æ¢ãæ¬ææåºä½¿ç¨å¯è§£éæ§æ¹æ³ä¾è­å¥éå¡ä¸­å°è´ç¡æ³è§£æ±ºçç¹å®ååãééå°è¼é«çæ¬éåéçµ¦éäºååï¼åºæ¼ç´æçæ±è§£å¨å¯ä»¥åªåèçéäºæåé¡çååï¼å¾èå¯¦ç¾æ´ææçä¿®å¾©ãæåççµæå¨ä¸æ¬¾éæ²ä¸­é²è¡äºæ¸¬è©¦ï¼è­æäºéç¨®æ¹æ³æå©æ¼æ´å¿«å°ä¿®å¾©ç¨åºåçæçéå¡ã

##### **Comparative Analysis of Demonstration Selection Algorithms for LLM In-Context Learning**
2410.23099v1 by Dong Shu, Mengnan Du

In-context learning can help Large Language Models (LLMs) to adapt new tasks
without additional training. However, this performance heavily depends on the
quality of the demonstrations, driving research into effective demonstration
selection algorithms to optimize this process. These algorithms assist users in
selecting the best $k$ input-label pairs (demonstration examples) based on a
given test input, enabling LLMs to in-context learn the relationship between
the provided examples and the test inputs. Despite all the proposed
demonstration selection algorithms, their efficiency and effectiveness remain
unclear. This lack of clarity make it difficult to apply these algorithms in
real-world scenarios and poses challenges for future research aimed at
developing improved methods. This paper revisits six proposed algorithms,
evaluating them on five datasets from both efficiency and effectiveness
perspectives. Our experiments reveal significant variations in algorithm
performance across different tasks, with some methods struggling to outperform
random selection in certain scenarios. We also find that increasing the number
of demonstrations does not always lead to better performance, and that there
are often trade-offs between accuracy and computational efficiency. Our code is
available at https://github.com/Tizzzzy/Demonstration_Selection_Overview.

æè¦ï¼æå¢å­¸ç¿å¯ä»¥å¹«å©å¤§åèªè¨æ¨¡å (LLM) é©ææ°ä»»åï¼èç¡éé¡å¤è¨ç·´ãç¶èï¼æ­¤æè½æ¥µåº¦ä»°è³´ç¤ºç¯åè³ªï¼é©ä½¿ç ç©¶äººå¡æå¥ææç¤ºç¯é¸ææ¼ç®æ³çç ç©¶ï¼ä»¥æä½³åæ­¤ç¨åºãéäºæ¼ç®æ³åå©ä½¿ç¨èæ ¹æç¹å®æ¸¬è©¦è¼¸å¥ï¼å¾æä½³ç $k$ åè¼¸å¥æ¨ç±¤éå°ï¼ç¤ºç¯ç¯ä¾ï¼ä¸­é²è¡é¸æï¼è® LLM è½å¤ å¨æå¢ä¸­å­¸ç¿æä¾çç¯ä¾èæ¸¬è©¦è¼¸å¥ä¹éçéä¿ãåç®¡æåºäºææå¯è½çç¤ºç¯é¸ææ¼ç®æ³ï¼ä½å¶æçåæè½ä»ä¸ææãéç¨®ä¸ç¢ºå®æ§ä½¿å¾å¨çå¯¦ä¸çæå¢ä¸­æç¨éäºæ¼ç®æ³è®å¾å°é£ï¼ä¸¦å°æ¨å¨éç¼æ¹è¯æ¹æ³çæªä¾ç ç©¶æ§æææ°ãæ¬æåé¡§äºå­ç¨®æåºçæ¼ç®æ³ï¼å¾æçåæè½å©åè§åº¦ï¼å¨äºåè³æéä¸å°å®åé²è¡è©ä¼°ãæåçå¯¦é©æ­ç¤ºäºæ¼ç®æ³æè½å ä»»åèç°çé¡¯èå·®ç°ï¼æäºæ¹æ³å¨æäºæå¢ä¸é£ä»¥åéé¨æ©é¸æãæåä¹ç¼ç¾ï¼å¢å ç¤ºç¯æ¸éä¸¦éç¸½æ¯æå¸¶ä¾æ´å¥½çæè½ï¼èä¸æºç¢ºæ§åéç®æçä¹ééå¸¸å­å¨æ¬è¡¡åæ¨ãæåçç¨å¼ç¢¼å¯æ¼ https://github.com/Tizzzzy/Demonstration_Selection_Overview åå¾ã

##### **CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation**
2410.23090v1 by Yiruo Cheng, Kelong Mao, Ziliang Zhao, Guanting Dong, Hongjin Qian, Yongkang Wu, Tetsuya Sakai, Ji-Rong Wen, Zhicheng Dou

Retrieval-Augmented Generation (RAG) has become a powerful paradigm for
enhancing large language models (LLMs) through external knowledge retrieval.
Despite its widespread attention, existing academic research predominantly
focuses on single-turn RAG, leaving a significant gap in addressing the
complexities of multi-turn conversations found in real-world applications. To
bridge this gap, we introduce CORAL, a large-scale benchmark designed to assess
RAG systems in realistic multi-turn conversational settings. CORAL includes
diverse information-seeking conversations automatically derived from Wikipedia
and tackles key challenges such as open-domain coverage, knowledge intensity,
free-form responses, and topic shifts. It supports three core tasks of
conversational RAG: passage retrieval, response generation, and citation
labeling. We propose a unified framework to standardize various conversational
RAG methods and conduct a comprehensive evaluation of these methods on CORAL,
demonstrating substantial opportunities for improving existing approaches.

æè¦ï¼æª¢ç´¢å¢å¼·çæï¼RAGï¼å·²æçºä¸ç¨®å¼·å¤§çç¯ä¾ï¼å¯ééå¤é¨ç¥è­æª¢ç´¢å¢å¼·å¤§åèªè¨æ¨¡åï¼LLMï¼ãåç®¡åå°å»£æ³éæ³¨ï¼ç¾æçå­¸è¡ç ç©¶ä¸»è¦éä¸­æ¼å®åå RAGï¼å¨èççå¯¦ä¸çæç¨ä¸­ç¼ç¾çå¤ååå°è©±çè¤éæ§æ¹é¢å­å¨é¡¯èå·®è·ãçºäºå½åéåå·®è·ï¼æåå¼å¥äº CORALï¼éæ¯ä¸åå¤§è¦æ¨¡åºæºï¼æ¨å¨è©ä¼° RAG ç³»çµ±å¨ç¾å¯¦çå¤ååå°è©±è¨­ç½®ä¸­çè¡¨ç¾ãCORAL åæ¬å¾ç¶­åºç¾ç§èªåè¡ççåç¨®è³è¨å°æ±å°è©±ï¼ä¸¦æå°éæ¾é åæ¶µèç¯åãç¥è­å¼·åº¦ãèªç±å½¢å¼åæåä¸»é¡è½æç­ééµææ°ãå®æ¯æ´å°è©± RAG çä¸é æ ¸å¿ä»»åï¼æ®µè½æª¢ç´¢ãåæçæåå¼ææ¨è¨ãæåæåºäºä¸åçµ±ä¸çæ¡æ¶ä¾æ¨æºååç¨®å°è©± RAG æ¹æ³ï¼ä¸¦å°éäºæ¹æ³å¨ CORAL ä¸é²è¡å¨é¢è©ä¼°ï¼å±ç¤ºäºæ¹é²ç¾ææ¹æ³çéå¤§æ©æã

##### **BUZZ: Beehive-structured Sparse KV Cache with Segmented Heavy Hitters for Efficient LLM Inference**
2410.23079v1 by Junqi Zhao, Zhijin Fang, Shu Li, Shaohui Yang, Shichao He

Large language models (LLMs) are essential in natural language processing but
often struggle with inference speed and computational efficiency, limiting
real-time deployment. The key-value (KV) cache mechanism reduces computational
overhead in transformer models, but challenges in maintaining contextual
understanding remain. In this paper, we propose BUZZ, a novel KV caching
algorithm that leverages structured contextual information to minimize cache
memory usage while enhancing inference speed. BUZZ employs a beehive-structured
sparse cache, incorporating a sliding window to capture recent information and
dynamically segmenting historical tokens into chunks to prioritize important
tokens in local neighborhoods. We evaluate BUZZ on four real-world datasets:
CNN/Daily Mail, XSUM, Wikitext, and 10-QA. Our results demonstrate that BUZZ
(1) reduces cache memory usage by $\textbf{2.5}\times$ in LLM inference while
maintaining over 99% accuracy in long-text summarization, and (2) surpasses
state-of-the-art performance in multi-document question answering by
$\textbf{7.69%}$ under the same memory limit, where full cache methods
encounter out-of-memory issues. Additionally, BUZZ achieves significant
inference speedup with a $\log{n}$ time complexity. The code is available at
https://github.com/JunqiZhao888/buzz-llm.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èçä¸­è³ééè¦ï¼ä½
éå¸¸é£ä»¥å¼é¡§æ¨è«éåº¦åéç®æçï¼éå¶äº
å³æé¨ç½²ãå¿«åæ©å¶ä¸­çéµå¼ (KV) æ¸å°äºè½æå¨æ¨¡åä¸­çéç®
éé·ï¼ä½å¨ç¶­è­·ä¸ä¸æçè§£æ¹é¢ä»ç¶å­å¨ææ°ãå¨æ¬æä¸­ï¼æåæåº
BUZZï¼éæ¯ä¸ç¨®æ°ç©ç KV å¿«åæ¼ç®æ³ï¼å©ç¨çµæ§åä¸ä¸æè³è¨ä¾
æå°åå¿«åè¨æ¶é«ä½¿ç¨éï¼åææé«æ¨è«éåº¦ãBUZZ æ¡ç¨èå·¢çµæ§
ç¨çå¿«åï¼çµåæ»åè¦çªä¾æ·åææ°è³è¨ï¼ä¸¦åæå°æ­·å²ä»£å¹£åæ®µæ
å¡ï¼ä»¥åªåèçé°è¿ååä¸­çéè¦ä»£å¹£ãæåå¨ååçå¯¦ä¸çè³æéä¸
è©ä¼° BUZZï¼CNN/Daily MailãXSUMãWikitext å 10-QAãæåççµæè­æ
BUZZ (1) å¨ LLM æ¨è«ä¸­å°å¿«åè¨æ¶é«ä½¿ç¨éæ¸å°äº $\textbf{2.5}\times$ï¼åæ
å¨é·ææ¬æè¦ä¸­ç¶­æè¶é 99% çæºç¢ºåº¦ï¼ä»¥å (2) å¨ç¸åçè¨æ¶é«éå¶ä¸ï¼
è¶è¶äºå¤æä»¶åç­çææ°æè¡ï¼æåäº $\textbf{7.69%}$ï¼èå®æ´å¿«åæ¹æ³
åæéå°è¨æ¶é«ä¸è¶³çåé¡ãæ­¤å¤ï¼BUZZ ä»¥ $\log{n}$ æéè¤éåº¦å¯¦ç¾äº
é¡¯èçæ¨è«éåº¦æåãç¨å¼ç¢¼å¯å¨ https://github.com/JunqiZhao888/buzz-llm åå¾ã

##### **Multi-Programming Language Sandbox for LLMs**
2410.23074v1 by Shihan Dou, Jiazheng Zhang, Jianxiang Zang, Yunbo Tao, Haoxiang Jia, Shichun Liu, Yuming Yang, Shenxi Wu, Shaoqing Zhang, Muling Wu, Changze Lv, Limao Xiong, Wenyu Zhan, Lin Zhang, Rongxiang Weng, Jingang Wang, Xunliang Cai, Yueming Wu, Ming Wen, Rui Zheng, Tao Ji, Yixin Cao, Tao Gui, Xipeng Qiu, Qi Zhang, Xuanjing Huang

We introduce MPLSandbox, an out-of-the-box multi-programming language sandbox
designed to provide unified and comprehensive feedback from compiler and
analysis tools for Large Language Models (LLMs). It can automatically identify
the programming language of the code, compiling and executing it within an
isolated sub-sandbox to ensure safety and stability. In addition, MPLSandbox
also integrates both traditional and LLM-based code analysis tools, providing a
comprehensive analysis of generated code. MPLSandbox can be effortlessly
integrated into the training and deployment of LLMs to improve the quality and
correctness of their generated code. It also helps researchers streamline their
workflows for various LLM-based code-related tasks, reducing the development
cost. To validate the effectiveness of MPLSandbox, we integrate it into
training and deployment approaches, and also employ it to optimize workflows
for a wide range of real-world code-related tasks. Our goal is to enhance
researcher productivity on LLM-based code-related tasks by simplifying and
automating workflows through delegation to MPLSandbox.

æè¦ï¼<paragraph>æåæ¨åº MPLSandboxï¼ä¸åéç®±å³ç¨çå¤ç¨å¼èªè¨æ²çï¼æ¨å¨æä¾ä¾èªç·¨è­¯å¨ååæå·¥å·ççµ±ä¸ä¸å¨é¢çåé¥ï¼ä»¥ä¾å¤§åèªè¨æ¨¡å (LLM) ä½¿ç¨ãå®å¯ä»¥èªåè­å¥ç¨å¼ç¢¼çç¨å¼èªè¨ï¼å¨ä¸åéé¢çå­æ²çä¸­ç·¨è­¯åå·è¡å®ï¼ä»¥ç¢ºä¿å®å¨æ§åç©©å®æ§ãæ­¤å¤ï¼MPLSandbox éæ´åäºå³çµ±ååºæ¼ LLM çç¨å¼ç¢¼åæå·¥å·ï¼æä¾å°çæç¨å¼ç¢¼çå¨é¢åæãMPLSandbox å¯ä»¥è¼é¬æ´åå° LLM çè¨ç·´åé¨ç½²ä¸­ï¼ä»¥æé«å¶çæç¨å¼ç¢¼çåè³ªåæ­£ç¢ºæ§ãå®éå¯ä»¥å¹«å©ç ç©¶äººå¡ç°¡åå¶åç¨®åºæ¼ LLM çç¨å¼ç¢¼ç¸éä»»åçå·¥ä½æµç¨ï¼å¾èéä½éç¼ææ¬ãçºäºé©è­ MPLSandbox çæææ§ï¼æåå°å¶æ´åå°è¨ç·´åé¨ç½²æ¹æ³ä¸­ï¼ä¸¦ä½¿ç¨å®ä¾æä½³ååç¨®å¯¦éç¨å¼ç¢¼ç¸éä»»åçå·¥ä½æµç¨ãæåçç®æ¨æ¯ééå§æ´¾çµ¦ MPLSandbox ä¾ç°¡ååèªååå·¥ä½æµç¨ï¼é²èæåç ç©¶äººå¡å¨åºæ¼ LLM çç¨å¼ç¢¼ç¸éä»»åä¸ççç¢åã</paragraph>

##### **CNN Explainability with Multivector Tucker Saliency Maps for Self-Supervised Models**
2410.23072v1 by Aymene Mohammed Bouayed, Samuel Deslauriers-Gauthier, Adrian Iaccovelli, David Naccache

Interpreting the decisions of Convolutional Neural Networks (CNNs) is
essential for understanding their behavior, yet explainability remains a
significant challenge, particularly for self-supervised models. Most existing
methods for generating saliency maps rely on ground truth labels, restricting
their use to supervised tasks. EigenCAM is the only notable label-independent
alternative, leveraging Singular Value Decomposition to generate saliency maps
applicable across CNN models, but it does not fully exploit the tensorial
structure of feature maps. In this work, we introduce the Tucker Saliency Map
(TSM) method, which applies Tucker tensor decomposition to better capture the
inherent structure of feature maps, producing more accurate singular vectors
and values. These are used to generate high-fidelity saliency maps, effectively
highlighting objects of interest in the input. We further extend EigenCAM and
TSM into multivector variants -Multivec-EigenCAM and Multivector Tucker
Saliency Maps (MTSM)- which utilize all singular vectors and values, further
improving saliency map quality. Quantitative evaluations on supervised
classification models demonstrate that TSM, Multivec-EigenCAM, and MTSM achieve
competitive performance with label-dependent methods. Moreover, TSM enhances
explainability by approximately 50% over EigenCAM for both supervised and
self-supervised models. Multivec-EigenCAM and MTSM further advance
state-of-the-art explainability performance on self-supervised models, with
MTSM achieving the best results.

æè¦ï¼è©®éå·ç©ç¥ç¶ç¶²è·¯ (CNN) çæ±ºç­å°æ¼çè§£å¶è¡çºè³ééè¦ï¼ç¶èå¯è§£éæ§ä»ç¶æ¯ä¸é éå¤§çææ°ï¼ç¹å¥æ¯å°æ¼èªç£ç£æ¨¡åãç¾æçå¤§å¤æ¸çæé¡¯èæ§åçæ¹æ³ä¾è³´æ¼çå¯¦æ¨ç±¤ï¼å°å¶ä½¿ç¨éå¶å¨ç£ç£å¼ä»»åä¸­ãEigenCAM æ¯å¯ä¸å¼å¾æ³¨æçæ¨ç±¤ç¡éæ¿ä»£æ¹æ¡ï¼å©ç¨å¥ç°å¼åè§£ä¾çæé©ç¨æ¼ææ CNN æ¨¡åçé¡¯èæ§åï¼ä½å®ä¸¦æªååå©ç¨ç¹å¾µåçå¼µéçµæ§ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºå¡åé¡¯èæ§å (TSM) æ¹æ³ï¼è©²æ¹æ³æç¨å¡åå¼µéåè§£ä»¥æ´å¥½å°ææç¹å¾µåçå§å¨çµæ§ï¼ç¢çæ´æºç¢ºçå¥ç°åéåå¼ãéäºç¨æ¼çæé«ä¿çé¡¯èæ§åï¼ææå°çªé¡¯è¼¸å¥ä¸­çæèè¶£å°è±¡ãæåé²ä¸æ­¥å° EigenCAM å TSM æ´å±å°å¤åéè®é« - å¤åé EigenCAM åå¤åéå¡åé¡¯èæ§å (MTSM) - å©ç¨ææå¥ç°åéåå¼ï¼é²ä¸æ­¥æé«é¡¯èæ§åçåè³ªãå¨ç£ç£å¼åé¡æ¨¡åä¸çå®éè©ä¼°è¡¨æï¼TSMãå¤åé EigenCAM å MTSM èæ¨ç±¤ä¾è³´æ¹æ³ç¸æ¯ï¼éå°äºç«¶ç­æ§çæè½ãæ­¤å¤ï¼TSM å°ç£ç£å¼åèªç£ç£å¼æ¨¡åçè§£éæ§æ¯ EigenCAM æé«äºå¤§ç´ 50%ãå¤åé EigenCAM å MTSM é²ä¸æ­¥æåäºèªç£ç£å¼æ¨¡åçç¾ææä½³è§£éæ§æè½ï¼å¶ä¸­ MTSM éå°äºæä½³çµæã

##### **LLMs Integration in Software Engineering Team Projects: Roles, Impact, and a Pedagogical Design Space for AI Tools in Computing Education**
2410.23069v1 by Ahmed Kharrufa, Sami Alghamdi, Abeer Aziz, Christopher Bull

This work takes a pedagogical lens to explore the implications of generative
AI (GenAI) models and tools, such as ChatGPT and GitHub Copilot, in a
semester-long 2nd-year undergraduate Software Engineering Team Project.
Qualitative findings from survey (39 students) and interviews (eight students)
provide insights into the students' views on the impact of GenAI use on their
coding experience, learning, and self-efficacy. Our results address a
particular gap in understanding the role and implications of GenAI on teamwork,
team-efficacy, and team dynamics. The analysis of the learning aspects is
distinguished by the application of learning and pedagogy informed lenses to
discuss the data. We propose a preliminary design space for GenAI-based
programming learning tools highlighting the importance of considering the roles
that GenAI can play during the learning process, the varying support-ability
patterns that can be applied to each role, and the importance of supporting
transparency in GenAI for team members and students in addition to educators.

æè¦ï¼æ¬ç ç©¶ä»¥æå­¸è§é»æ¢è¨çæå¼ AI (GenAI) æ¨¡ååå·¥å·ï¼ä¾å¦ ChatGPT å GitHub Copilotï¼å¨çºæä¸å­¸æçäºå¹´ç´å¤§å­¸é¨è»é«å·¥ç¨åéå°é¡ä¸­çå½±é¿ã
ä¾èªåå·èª¿æ¥ï¼39 ä½å­¸çï¼åè¨ªè«ï¼8 ä½å­¸çï¼çå®æ§ç¼ç¾ï¼æä¾äºå­¸çå° GenAI ä½¿ç¨å°å¶ç¨å¼ç·¨å¯«ç¶é©ãå­¸ç¿åèªææè½å½±é¿çè¦è§£ãæåççµææ¢è¨äºå¨çè§£ GenAI å¨åéåä½ãåéæè½ååéååä¸­çè§è²åå½±é¿æ¹é¢çç¹å®å·®è·ãå­¸ç¿é¢åçåæä»¥æç¨å­¸ç¿åæå­¸æ³è§é»ä¾æ¢è¨è³æçºç¹è²ãæåæåºäºä¸ååºæ¼ GenAI çç¨å¼è¨­è¨å­¸ç¿å·¥å·çåæ­¥è¨­è¨ç©ºéï¼å¼·èª¿èæ® GenAI å¨å­¸ç¿éç¨ä¸­å¯ä»¥æ®æ¼çè§è²ãå¯ä»¥æç¨æ¼æ¯åè§è²çä¸åæ¯æ´è½åæ¨¡å¼ï¼ä»¥åé¤äºæè²å·¥ä½èä¹å¤ï¼æ¯æ´åéæå¡åå­¸çå° GenAI çéæåº¦çéè¦æ§ã

##### **Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification**
2410.23066v1 by Debjyoti Saharoy, Javed A. Aslam, Virgil Pavlu

State-of-the-art Extreme Multi-Label Text Classification (XMTC) models rely
heavily on multi-label attention layers to focus on key tokens in input text,
but obtaining optimal attention weights is challenging and resource-intensive.
To address this, we introduce PLANT -- Pretrained and Leveraged AtteNTion -- a
novel transfer learning strategy for fine-tuning XMTC decoders. PLANT surpasses
existing state-of-the-art methods across all metrics on mimicfull, mimicfifty,
mimicfour, eurlex, and wikiten datasets. It particularly excels in few-shot
scenarios, outperforming previous models specifically designed for few-shot
scenarios by over 50 percentage points in F1 scores on mimicrare and by over 36
percentage points on mimicfew, demonstrating its superior capability in
handling rare codes. PLANT also shows remarkable data efficiency in few-shot
scenarios, achieving precision comparable to traditional models with
significantly less data. These results are achieved through key technical
innovations: leveraging a pretrained Learning-to-Rank model as the planted
attention layer, integrating mutual-information gain to enhance attention,
introducing an inattention mechanism, and implementing a stateful-decoder to
maintain context. Comprehensive ablation studies validate the importance of
these contributions in realizing the performance gains.

æè¦ï¼æåè¿çæ¥µç«¯å¤æ¨ç±¤ææ¬åé¡ (XMTC) æ¨¡åé«åº¦ä¾è³´å¤æ¨ç±¤æ³¨æåå±¤ï¼ä»¥éæ³¨è¼¸å¥ææ¬ä¸­çééµä»£ç¢¼ï¼ä½åå¾æä½³æ³¨æåæ¬éå·æææ°æ§ä¸èè²»è³æºãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº PLANTï¼é è¨ç·´åæ§æ¡¿æ³¨æåï¼ââä¸ç¨®éå°å¾®èª¿ XMTC è§£ç¢¼å¨çæ°ç©çé·ç§»å­¸ç¿ç­ç¥ãPLANT å¨ mimicfullãmimicfiftyãmimicfourãeurlex å wikiten è³æéçææææ¨ä¸é½è¶è¶äºç¾æçæåé²æ¹æ³ãå®å¨å°æ¬¡åè©¦çå ´æ¯ä¸­ç¹å¥åºè²ï¼å¨ mimicrare ä¸ç F1 åæ¸æ¯å°éçºå°æ¬¡åè©¦çå ´æ¯è¨­è¨çååæ¨¡åé«åº 50 åç¾åé»ï¼å¨ mimicfew ä¸é«åº 36 åç¾åé»ï¼è­æäºå¶å¨èçç½è¦ä»£ç¢¼æ¹é¢çåè¶è½åãPLANT å¨å°æ¬¡åè©¦çå ´æ¯ä¸­ä¹å±ç¾äºé¡¯èçè³ææçï¼éå°äºèå³çµ±æ¨¡åç¸ç¶çç²¾åº¦ï¼èè³æå»å°å¾å¤ãéäºæææ¯ééééµæè¡åµæ°å¯¦ç¾çï¼å©ç¨é è¨ç·´çå­¸ç¿æåæ¨¡åä½çºæ¤å¥çæ³¨æåå±¤ï¼æ´åäºè³è¨å¢çä»¥å¢å¼·æ³¨æåï¼å¼å¥ä¸æ³¨æåæ©å¶ï¼ä¸¦å¯¦ä½æçæè§£ç¢¼å¨ä»¥ç¶­è­·ä¸ä¸æãå¨é¢çæ¶èç ç©¶é©è­äºéäºè²¢ç»å¨å¯¦ç¾æè½æåæ¹é¢çéè¦æ§ã

##### **Controlling Language and Diffusion Models by Transporting Activations**
2410.23054v1 by Pau Rodriguez, Arno Blaas, Michal Klein, Luca Zappella, Nicholas Apostoloff, Marco Cuturi, Xavier Suau

The increasing capabilities of large generative models and their ever more
widespread deployment have raised concerns about their reliability, safety, and
potential misuse. To address these issues, recent works have proposed to
control model generation by steering model activations in order to effectively
induce or prevent the emergence of concepts or behaviors in the generated
output. In this paper we introduce Activation Transport (AcT), a general
framework to steer activations guided by optimal transport theory that
generalizes many previous activation-steering works. AcT is modality-agnostic
and provides fine-grained control over the model behavior with negligible
computational overhead, while minimally impacting model abilities. We
experimentally show the effectiveness and versatility of our approach by
addressing key challenges in large language models (LLMs) and text-to-image
diffusion models (T2Is). For LLMs, we show that AcT can effectively mitigate
toxicity, induce arbitrary concepts, and increase their truthfulness. In T2Is,
we show how AcT enables fine-grained style control and concept negation.

æè¦ï¼å¤§åçææ¨¡ååè½æ¥çå¼ºå¤§ï¼å¶é¨ç½²ä¹æ¥çå¹¿æ³ï¼è¿å¼åäºäººä»¬å¯¹å¶å¯é æ§ãå®å¨æ§åæ½å¨æ»¥ç¨çæå¿§ãä¸ºäºè§£å³è¿äºé®é¢ï¼æè¿çç ç©¶æåºäºéè¿æ§å¶æ¨¡åæ¿æ´»æ¥æ§å¶æ¨¡åçæï¼ä»¥ä¾¿ææå°è¯±å¯¼æé»æ­¢æ¦å¿µæè¡ä¸ºå¨çæè¾åºä¸­åºç°ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äºæ¿æ´»ä¼ è¾ (AcT)ï¼è¿æ¯ä¸ä¸ªéç¨æ¡æ¶ï¼ç¨äºéè¿æä¼ä¼ è¾çè®ºæå¯¼æ¿æ´»ï¼ä»èæ¦æ¬äºè®¸å¤ååçæ¿æ´»æ§å¶å·¥ä½ãAcT ä¸æ¨¡ææ å³ï¼å¹¶ä¸å¯ä»¥å¯¹æ¨¡åè¡ä¸ºè¿è¡ç»ç²åº¦æ§å¶ï¼èè®¡ç®å¼éå¯ä»¥å¿½ç¥ä¸è®¡ï¼åæ¶å¯¹æ¨¡åè½åçå½±åæå°ãæä»¬éè¿è§£å³å¤§åè¯­è¨æ¨¡å (LLM) åææ¬å°å¾åæ©æ£æ¨¡å (T2I) ä¸­çå³é®ææï¼éè¿å®éªå±ç¤ºäºæä»¬æ¹æ³çæææ§åå¤åè½æ§ãå¯¹äº LLMï¼æä»¬å±ç¤ºäº AcT å¯ä»¥ææåè½»æ¯æ§ï¼è¯±å¯¼ä»»ææ¦å¿µå¹¶æé«å¶çå®æ§ãå¨ T2I ä¸­ï¼æä»¬å±ç¤ºäº AcT å¦ä½å®ç°ç»ç²åº¦çæ ·å¼æ§å¶åæ¦å¿µå¦å®ã

##### **Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval**
2410.23041v1 by Le Huang, Hengzhi Lan, Zijun Sun, Chuan Shi, Ting Bai

As LLMs exhibit a high degree of human-like capability, increasing attention
has been paid to role-playing research areas in which responses generated by
LLMs are expected to mimic human replies. This has promoted the exploration of
role-playing agents in various applications, such as chatbots that can engage
in natural conversations with users and virtual assistants that can provide
personalized support and guidance. The crucial factor in the role-playing task
is the effective utilization of character memory, which stores characters'
profiles, experiences, and historical dialogues. Retrieval Augmented Generation
(RAG) technology is used to access the related memory to enhance the response
generation of role-playing agents. Most existing studies retrieve related
information based on the semantic similarity of memory to maintain characters'
personalized traits, and few attempts have been made to incorporate the
emotional factor in the retrieval argument generation (RAG) of LLMs. Inspired
by the Mood-Dependent Memory theory, which indicates that people recall an
event better if they somehow reinstate during recall the original emotion they
experienced during learning, we propose a novel emotion-aware memory retrieval
framework, termed Emotional RAG, which recalls the related memory with
consideration of emotional state in role-playing agents. Specifically, we
design two kinds of retrieval strategies, i.e., combination strategy and
sequential strategy, to incorporate both memory semantic and emotional states
during the retrieval process. Extensive experiments on three representative
role-playing datasets demonstrate that our Emotional RAG framework outperforms
the method without considering the emotional factor in maintaining the
personalities of role-playing agents. This provides evidence to further
reinforce the Mood-Dependent Memory theory in psychology.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡åå±ç¾é«åº¦æ¬äººçè½åï¼äººåè¶ä¾è¶éè¦è§è²æ®æ¼çç ç©¶é åï¼å¶ä¸­å¤§åèªè¨æ¨¡åç¢ççåæé æå°æ¨¡æ¬äººé¡çåè¦ãéä¿ä½¿äººåæ¢ç´¢å¨åç¨®æç¨ç¨å¼ä¸­ä½¿ç¨è§è²æ®æ¼ä»£çï¼ä¾å¦è½å¤ èä½¿ç¨èé²è¡èªç¶å°è©±çèå¤©æ©å¨äººï¼ä»¥åè½å¤ æä¾åäººåæ¯æ´åæå°çèæ¬å©çãè§è²æ®æ¼ä»»åä¸­çééµå ç´ æ¯ææå©ç¨è§è²è¨æ¶ï¼å¶ä¸­å²å­äºè§è²çåäººè³æãç¶é©åæ­·å²å°è©±ãæª¢ç´¢å¢å¼·çæ (RAG) æè¡ç¨æ¼å­åç¸éè¨æ¶ï¼ä»¥å¢å¼·è§è²æ®æ¼ä»£ççåæç¢çãç¾æç ç©¶å¤§å¤æ ¹æè¨æ¶çèªç¾©ç¸ä¼¼æ§ä¾æª¢ç´¢ç¸éè³è¨ï¼ä»¥ç¶­æè§è²çåæ§åç¹è³ªï¼å¾å°åè©¦å¨å¤§åèªè¨æ¨¡åçæª¢ç´¢è«è­ç¢ç (RAG) ä¸­ç´å¥æç·å ç´ ãåå°æç·ä¾è³´è¨æ¶çè«çåç¼ï¼è©²çè«æåºï¼å¦æäººåå¨åæ¶æä»¥æç¨®æ¹å¼æ¢å¾©å­¸ç¿æç¶æ­·çåå§æç·ï¼ä»åå°±è½æ´å¥½å°åæ¶èµ·æåäºä»¶ï¼ï¼æåæåºäºä¸åæ°çæç·æç¥è¨æ¶æª¢ç´¢æ¶æ§ï¼ç¨±çºæç· RAGï¼å®å¨è§è²æ®æ¼ä»£çä¸­èæ®æç·çæä¾åæ¶ç¸éè¨æ¶ãå·é«ä¾èªªï¼æåè¨­è¨äºå©ç¨®æª¢ç´¢ç­ç¥ï¼å³çµåç­ç¥åé åºç­ç¥ï¼ä»¥ä¾¿å¨æª¢ç´¢éç¨ä¸­ç´å¥è¨æ¶èªç¾©åæç·çæãå¨ä¸åå·ä»£è¡¨æ§çè§è²æ®æ¼è³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼æåç Emotional RAG æ¶æ§å¨ç¶­æè§è²æ®æ¼ä»£çåæ§æ¹é¢åªæ¼ä¸èæ®æç·å ç´ çæ¹æ³ãéæä¾äºè­æï¼é²ä¸æ­¥å¼·åäºå¿çå­¸ä¸­çæç·ä¾è³´è¨æ¶çè«ã

##### **Offline Reinforcement Learning and Sequence Modeling for Downlink Link Adaptation**
2410.23031v1 by Samuele Peri, Alessio Russo, Gabor Fodor, Pablo Soldati

Contemporary radio access networks employ link adaption (LA) algorithms to
optimize the modulation and coding schemes to adapt to the prevailing
propagation conditions and are near-optimal in terms of the achieved spectral
efficiency. LA is a challenging task in the presence of mobility, fast fading,
and imperfect channel quality information and limited knowledge of the receiver
characteristics at the transmitter, which render model-based LA algorithms
complex and suboptimal. Model-based LA is especially difficult as connected
user equipment devices become increasingly heterogeneous in terms of receiver
capabilities, antenna configurations and hardware characteristics. Recognizing
these difficulties, previous works have proposed reinforcement learning (RL)
for LA, which faces deployment difficulties due to their potential negative
impacts on live performance. To address this challenge, this paper considers
offline RL to learn LA policies from data acquired in live networks with
minimal or no intrusive effects on the network operation. We propose three LA
designs based on batch-constrained deep Q-learning, conservative Q-learning,
and decision transformers, showing that offline RL algorithms can achieve
performance of state-of-the-art online RL methods when data is collected with a
proper behavioral policy.

æè¦ï¼ç¾ä»£ç¡ç·å­åç¶²è·¯æ¡ç¨é£çµé©æ (LA) æ¼ç®æ³ä¾æä½³åèª¿è®åç·¨ç¢¼æ¶æ§ï¼ä»¥é©æç¾è¡çå³æ­æ¢ä»¶ï¼ä¸å¨éæçé »è­æçæ¹é¢æ¥è¿æä½³ãLA å¨æµåæ§ãå¿«éè¡°è½ãä¸å®ç¾çé »éåè³ªè³è¨åç¼å°å¨å°æ¥æ¶å¨ç¹æ§äºè§£æéçææ³ä¸æ¯ä¸é å·æææ°æ§çä»»åï¼éä½¿å¾åºæ¼æ¨¡åç LA æ¼ç®æ³è¤éä¸æ¬¡æä½³ãé¨èé£æ¥çä½¿ç¨èè¨­åå¨æ¥æ¶å¨è½åãå¤©ç·çµæåç¡¬é«ç¹æ§æ¹é¢è®å¾è¶ä¾è¶ç°è³ªï¼åºæ¼æ¨¡åç LA è®å¾ç¹å¥å°é£ãèªè­å°éäºå°é£ï¼ååçç ç©¶æåºäºç¨æ¼ LA çå¼·åå­¸ç¿ (RL)ï¼ç±æ¼å¶å°ç¾å ´æè½çæ½å¨è² é¢å½±é¿ï¼å æ­¤å¨é¨ç½²ä¸å­å¨å°é£ãçºäºæå°éä¸ææ°ï¼æ¬æèæ®é¢ç· RL å¾ç¾å ´ç¶²è·¯ä¸­ç²åçè³æä¸­å­¸ç¿ LA ç­ç¥ï¼å°ç¶²è·¯éä½çä¾µå¥æ§å½±é¿æ¥µå°ææ²æãæåæåºä¸ç¨®åºæ¼æ¹æ¬¡ç´ææ·±åº¦ Q å­¸ç¿ãä¿å® Q å­¸ç¿åæ±ºç­è½æå¨ç LA è¨­è¨ï¼è¡¨æé¢ç· RL æ¼ç®æ³å¨ä½¿ç¨é©ç¶çè¡çºç­ç¥æ¶éè³ææï¼å¯ä»¥éå°æåé²çç·ä¸ RL æ¹æ³çæè½ã

##### **Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback**
2410.23022v1 by Qinqing Zheng, Mikael Henaff, Amy Zhang, Aditya Grover, Brandon Amos

Automatically synthesizing dense rewards from natural language descriptions
is a promising paradigm in reinforcement learning (RL), with applications to
sparse reward problems, open-ended exploration, and hierarchical skill design.
Recent works have made promising steps by exploiting the prior knowledge of
large language models (LLMs). However, these approaches suffer from important
limitations: they are either not scalable to problems requiring billions of
environment samples; or are limited to reward functions expressible by compact
code, which may require source code and have difficulty capturing nuanced
semantics; or require a diverse offline dataset, which may not exist or be
impossible to collect. In this work, we address these limitations through a
combination of algorithmic and systems-level contributions. We propose ONI, a
distributed architecture that simultaneously learns an RL policy and an
intrinsic reward function using LLM feedback. Our approach annotates the
agent's collected experience via an asynchronous LLM server, which is then
distilled into an intrinsic reward model. We explore a range of algorithmic
choices for reward modeling with varying complexity, including hashing,
classification, and ranking models. By studying their relative tradeoffs, we
shed light on questions regarding intrinsic reward design for sparse reward
problems. Our approach achieves state-of-the-art performance across a range of
challenging, sparse reward tasks from the NetHack Learning Environment in a
simple unified process, solely using the agent's gathered experience, without
requiring external datasets nor source code. We make our code available at
\url{URL} (coming soon).

æè¦ï¼èªåå¾èªç¶èªè¨æè¿°ä¸­ç¶ååºå¯éççåµ
æ¯å¼·åå­¸ç¿ï¼RLï¼ä¸­ä¸åæåéçç¯ä¾ï¼æç¨æ¼
ç¨ççåµåé¡ãéæ¾å¼æ¢ç´¢åå±¤æ¬¡æè½è¨­è¨ã
æè¿çå·¥ä½ééå©ç¨å¤§èªè¨æ¨¡åï¼LLMï¼çåé©ç¥è­åå¾äºæå¸æçé²å±ãç¶èï¼éäºæ¹æ³å­å¨éè¦ç
éå¶ï¼å®åè¦ä¹ç¡æ³æ´å±å°éè¦æ¸ååå
ç°å¢æ¨£æ¬çåé¡ï¼è¦ä¹åéæ¼ç¨ç·æ¹
ä»£ç¢¼è¡¨éççåµå½æ¸ï¼éå¯è½éè¦æºä»£ç¢¼ä¸¦ä¸é£ä»¥ææç´°å¾®å·®å¥
èªç¾©ï¼æéè¦å¤æ¨£åçé¢ç·æ¸æéï¼éå¯è½ä¸å­å¨æç¡æ³
æ¶éãå¨éé å·¥ä½ä¸­ï¼æåééçµåæ¼ç®æ³åç³»çµ±ç´å¥çè²¢ç»ä¾è§£æ±ºéäºéå¶ãæåæåº ONIï¼ä¸å
åä½å¼æ¶æ§ï¼å®åæä½¿ç¨ LLM åé¥å­¸ç¿ RL ç­ç¥åå§å¨çåµå½æ¸ãæåçåæ³éééåæ­¥ LLM ä¼ºæå¨è¨»è§£ä»£çæ¶éçç¶é©ï¼ç¶å¾
å°å¶æçæä¸åå§å¨çåµæ¨¡åãæåæ¢ç´¢äºä¸ç³»åå·æä¸åè¤éåº¦ççåµå»ºæ¨¡æ¼ç®æ³
é¸æï¼åæ¬éæ¹ãåé¡åæåæ¨¡åãééç ç©¶å®åçç¸å°æ¬è¡¡ï¼æå
é¡æäºæéç¨ççåµåé¡çå§å¨çåµè¨­è¨çåé¡ãæåçåæ³å¨ NetHack å­¸ç¿ç°å¢ä¸­çä¸ç³»åå·æææ°æ§çç¨ççåµä»»åä¸­å¯¦ç¾äºæåé²çæ§è½ï¼å¨ä¸åç°¡å®ççµ±ä¸éç¨ä¸­ï¼åä½¿ç¨ä»£çæ¶éçç¶é©ï¼èç¡é
éè¦å¤é¨æ¸æéææºä»£ç¢¼ãæåå¨
\url{URL}ï¼å³å°æ¨åºï¼ä¸æä¾æåçä»£ç¢¼ã

##### **Long$^2$RAG: Evaluating Long-Context & Long-Form Retrieval-Augmented Generation with Key Point Recall**
2410.23000v2 by Zehan Qi, Rongwu Xu, Zhijiang Guo, Cunxiang Wang, Hao Zhang, Wei Xu

Retrieval-augmented generation (RAG) is a promising approach to address the
limitations of fixed knowledge in large language models (LLMs). However,
current benchmarks for evaluating RAG systems suffer from two key deficiencies:
(1) they fail to adequately measure LLMs' capability in handling long-context
retrieval due to a lack of datasets that reflect the characteristics of
retrieved documents, and (2) they lack a comprehensive evaluation method for
assessing LLMs' ability to generate long-form responses that effectively
exploits retrieved information. To address these shortcomings, we introduce the
Long$^2$RAG benchmark and the Key Point Recall (KPR) metric. Long$^2$RAG
comprises 280 questions spanning 10 domains and across 8 question categories,
each associated with 5 retrieved documents with an average length of 2,444
words. KPR evaluates the extent to which LLMs incorporate key points extracted
from the retrieved documents into their generated responses, providing a more
nuanced assessment of their ability to exploit retrieved information.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) æ¯ä¸ç¨®æåéçæ¹æ³ï¼å¯ç¨æ¼è§£æ±ºå¤§åèªè¨æ¨¡å (LLM) ä¸­åºå®ç¥è­çéå¶ãç¶èï¼ç¶åç¨æ¼è©ä¼° RAG ç³»çµ±çåºæºæå©åä¸»è¦çç¼ºé»ï¼(1) ç±æ¼ç¼ºä¹åæ æª¢ç´¢æä»¶ç¹å¾µçè³æéï¼å®åç¡æ³ååè¡¡é LLM å¨èçé·å§å®¹æª¢ç´¢ä¸­çè½åï¼ä»¥å (2) å®åç¼ºä¹å¨é¢çè©ä¼°æ¹æ³ï¼ç¨æ¼è©ä¼° LLM çæé·ç¯åæçè½åï¼éäºåæææå°å©ç¨äºæª¢ç´¢å°çè³è¨ãçºäºè§£æ±ºéäºç¼ºé»ï¼æåå¼å¥äº Long$^2$RAG åºæºåééµé»å¬åç (KPR) åº¦éãLong$^2$RAG åå« 280 ååé¡ï¼æ¶µè 10 åé åå 8 ååé¡é¡å¥ï¼æ¯ååé¡é½è 5 åæª¢ç´¢å°çæä»¶éè¯ï¼å¹³åé·åº¦çº 2,444 åå­åãKPR è©ä¼°äº LLM å°å¾æª¢ç´¢å°çæä»¶æåçééµé»ç´å¥å¶çæåæçç¨åº¦ï¼æä¾äºå°å¶å©ç¨æª¢ç´¢è³è¨è½åæ´ç´°ç·»çè©ä¼°ã

##### **A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics**
2410.22997v1 by Jonas Bode, Bastian PÃ¤tzold, Raphael Memmesheimer, Sven Behnke

Recent advances in LLM have been instrumental in autonomous robot control and
human-robot interaction by leveraging their vast general knowledge and
capabilities to understand and reason across a wide range of tasks and
scenarios. Previous works have investigated various prompt engineering
techniques for improving the performance of \glspl{LLM} to accomplish tasks,
while others have proposed methods that utilize LLMs to plan and execute tasks
based on the available functionalities of a given robot platform. In this work,
we consider both lines of research by comparing prompt engineering techniques
and combinations thereof within the application of high-level task planning and
execution in service robotics. We define a diverse set of tasks and a simple
set of functionalities in simulation, and measure task completion accuracy and
execution time for several state-of-the-art models.

æè¦ï¼è¿å¹´ä¾ï¼LLM çé²å±å°æ¼èªä¸»æ©å¨äººæ§å¶åäººæ©äºåè³ééè¦ï¼å©ç¨å¶å»£æ³çå¸¸è­åè½åä¾çè§£åæ¨çåç¨®ä»»ååå ´æ¯ãååçç ç©¶èª¿æ¥äºåç¨®æç¤ºå·¥ç¨æè¡ï¼ä»¥æé« LLM çæè½ä¾å®æä»»åï¼èå¶ä»äººåæåºäºå©ç¨ LLM ä¾è¦ååå·è¡ä»»åçæ¹æ³ï¼éäºæ¹æ³åºæ¼çµ¦å®æ©å¨äººå¹³å°çå¯ç¨åè½ãå¨éé å·¥ä½ä¸­ï¼æåééæ¯è¼æç¤ºå·¥ç¨æè¡åå¶å¨æåæ©å¨äººä¸­é«éä»»åè¦ååå·è¡çæç¨ä¸­ççµåï¼ä¾èééå©æ¢ç ç©¶è·¯ç·ãæåå¨æ¨¡æ¬ä¸­å®ç¾©äºä¸çµå¤æ¨£åçä»»ååä¸çµç°¡å®çåè½ï¼ä¸¦æ¸¬éäºå¹¾åæåé²æ¨¡åçä»»åå®ææºç¢ºåº¦åå·è¡æéã

##### **Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**
2410.22996v1 by Deperias Kerre, Anne Laurent, Kenneth Maussang, Dickson Owuor

A well structured collection of the various Quantum Cascade Laser (QCL)
design and working properties data provides a platform to analyze and
understand the relationships between these properties. By analyzing these
relationships, we can gain insights into how different design features impact
laser performance properties such as the working temperature. Most of these QCL
properties are captured in scientific text. There is therefore need for
efficient methodologies that can be utilized to extract QCL properties from
text and generate a semantically enriched and interlinked platform where the
properties can be analyzed to uncover hidden relations. There is also the need
to maintain provenance and reference information on which these properties are
based. Semantic Web technologies such as Ontologies and Knowledge Graphs have
proven capability in providing interlinked data platforms for knowledge
representation in various domains. In this paper, we propose an approach for
generating a QCL properties Knowledge Graph (KG) from text for semantic
enrichment of the properties. The approach is based on the QCL ontology and a
Retrieval Augmented Generation (RAG) enabled information extraction pipeline
based on GPT 4-Turbo language model. The properties of interest include:
working temperature, laser design type, lasing frequency, laser optical power
and the heterostructure. The experimental results demonstrate the feasibility
and effectiveness of this approach for efficiently extracting QCL properties
from unstructured text and generating a QCL properties Knowledge Graph, which
has potential applications in semantic enrichment and analysis of QCL data.

æè¦ï¼ä¸åçµæ§è¯å¥½çåç¨®éå­å±¤çé·å° (QCL) è¨­è¨åå·¥ä½ç¹æ§æ¸æéåï¼æä¾äºä¸åå¹³å°ä¾åæåçè§£éäºç¹æ§ä¹éçéä¿ãééåæéäºéä¿ï¼æåå¯ä»¥æ·±å¥äºè§£ä¸åçè¨­è¨ç¹å¾µå¦ä½å½±é¿é·å°æè½ç¹æ§ï¼ä¾å¦å·¥ä½æº«åº¦ãéäº QCL ç¹æ§å¤§å¤æ¸é½ææå¨ç§å­¸æå­ä¸­ãå æ­¤ï¼éè¦ææçæ¹æ³ï¼å¯ä»¥ç¨æ¼å¾æå­ä¸­èå QCL ç¹æ§ï¼ä¸¦ç¢çä¸åèªç¾©è±å¯ä¸ç¸äºé£çµçå¹³å°ï¼å¯ä»¥å¨å¶ä¸­åæéäºç¹æ§ä»¥ç¼ç¾é±èçéä¿ãééè¦ç¶­è­·éäºç¹æ§æä¾æçä¾æºååèè³è¨ãèªç¾©ç¶²è·¯æè¡ï¼ä¾å¦æ¬ä½åç¥è­åè­ï¼å·²è­æå®åå¨æä¾åç¨®é åä¸­ç¥è­è¡¨å¾µçç¸äºé£çµè³æå¹³å°æ¹é¢å·æè½åãå¨æ¬æä¸­ï¼æåæåºä¸åå¾æå­ä¸­ç¢ç QCL ç¹æ§ç¥è­åè­ (KG) çæ¹æ³ï¼ä»¥é²è¡ç¹æ§çèªç¾©è±å¯åãæ­¤æ¹æ³åºæ¼ QCL æ¬ä½ååºæ¼ GPT 4-Turbo èªè¨æ¨¡åçæª¢ç´¢æ´å¢çæ (RAG) åç¨è³è¨èåç®¡ç·ãæèè¶£çç¹æ§åæ¬ï¼å·¥ä½æº«åº¦ãé·å°è¨­è¨é¡åãé·å°é »çãé·å°ååçåç°è³ªçµæ§ãå¯¦é©çµæè­æäºæ­¤æ¹æ³å°æ¼å¾éçµæ§åæå­ä¸­ææèå QCL ç¹æ§åç¢ç QCL ç¹æ§ç¥è­åè­çå¯è¡æ§åæææ§ï¼éå¨ QCL æ¸æçèªç¾©è±å¯åååæä¸­å·ææ½å¨æç¨ã

##### **VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning**
2410.22995v1 by Jingkun Ma, Runzhe Zhan, Derek F. Wong, Yang Li, Di Sun, Hou Pong Chan, Lidia S. Chao

Although previous research on large language models (LLMs) and large
multi-modal models (LMMs) has systematically explored mathematical
problem-solving (MPS) within visual contexts, the analysis of how these models
process visual information during problem-solving remains insufficient. To
address this gap, we present VisAidMath, a benchmark for evaluating the MPS
process related to visual information. We follow a rigorous data curation
pipeline involving both automated processes and manual annotations to ensure
data quality and reliability. Consequently, this benchmark includes 1,200
challenging problems from various mathematical branches, vision-aid
formulations, and difficulty levels, collected from diverse sources such as
textbooks, examination papers, and Olympiad problems. Based on the proposed
benchmark, we conduct comprehensive evaluations on ten mainstream LLMs and
LMMs, highlighting deficiencies in the visual-aided reasoning process. For
example, GPT-4V only achieves 45.33% accuracy in the visual-aided reasoning
task, even with a drop of 2 points when provided with golden visual aids.
In-depth analysis reveals that the main cause of deficiencies lies in
hallucination regarding the implicit visual reasoning process, shedding light
on future research directions in the visual-aided MPS process.

æè¦ï¼åç®¡ååéå°å¤§åèªè¨æ¨¡å (LLM) åå¤§åå¤æ¨¡ææ¨¡å (LMM) çç ç©¶å·²ç³»çµ±æ§å°æ¢è¨è¦è¦ºæå¢ä¸­çæ¸å­¸åé¡è§£æ±º (MPS)ï¼ä½å°æ¼éäºæ¨¡åå¨åé¡è§£æ±ºéç¨ä¸­å¦ä½èçè¦è¦ºè³è¨çåæä»ä¸è¶³ãçºäºè§£æ±ºæ­¤å·®è·ï¼æåæåº VisAidMathï¼ä¸åç¨æ¼è©ä¼°èè¦è¦ºè³è¨ç¸éç MPS éç¨çåºæºãæåéµå¾ªå´è¬¹çè³ææ´çæµç¨ï¼æ¶åèªååèçåæåæ¨è¨»ï¼ä»¥ç¢ºä¿è³æåè³ªåå¯é æ§ãå æ­¤ï¼æ­¤åºæºåå« 1,200 åä¾èªæç§æ¸ãèè©¦å·åå¥§æå¹äºç«¶è³½ç­ä¸åä¾æºçå·æææ°æ§çåé¡ï¼æ¶µèåç¨®æ¸å­¸åæ¯ãè¦è¦ºè¼å©å¬å¼åé£åº¦ç­ç´ãæ ¹æå»ºè­°çåºæºï¼æåå°ååä¸»æµ LLM å LMM é²è¡å¨é¢è©ä¼°ï¼å¼·èª¿è¦è¦ºè¼å©æ¨çéç¨ä¸­çç¼ºé·ãä¾å¦ï¼å³ä½¿å¨æä¾é»éè¦è¦ºè¼å©æä¸é 2 åç¾åé»ï¼GPT-4V å¨è¦è¦ºè¼å©æ¨çä»»åä¸­åéå° 45.33% çæºç¢ºåº¦ãæ·±å¥åæé¡¯ç¤ºï¼ç¼ºé·çä¸»è¦åå å¨æ¼å°é±å¼è¦è¦ºæ¨çéç¨çå¹»è¦ºï¼çºè¦è¦ºè¼å© MPS éç¨ä¸­çæªä¾ç ç©¶æ¹åæä¾äºåç¤ºã

##### **Higher-order Cross-structural Embedding Model for Time Series Analysis**
2410.22984v1 by Guancen Lin, Cong Shen, Aijing Lin

Time series analysis has gained significant attention due to its critical
applications in diverse fields such as healthcare, finance, and sensor
networks. The complexity and non-stationarity of time series make it
challenging to capture the interaction patterns across different timestamps.
Current approaches struggle to model higher-order interactions within time
series, and focus on learning temporal or spatial dependencies separately,
which limits performance in downstream tasks. To address these gaps, we propose
Higher-order Cross-structural Embedding Model for Time Series (High-TS), a
novel framework that jointly models both temporal and spatial perspectives by
combining multiscale Transformer with Topological Deep Learning (TDL).
Meanwhile, High-TS utilizes contrastive learning to integrate these two
structures for generating robust and discriminative representations. Extensive
experiments show that High-TS outperforms state-of-the-art methods in various
time series tasks and demonstrate the importance of higher-order
cross-structural information in improving model performance.

æè¦ï¼æåºåæå å¶å¨é«çä¿å¥ãéèåææ¸¬å¨ç¶²è·¯ç­ä¸åé åçééµæç¨èååéæ³¨ãæåºçè¤éæ§åéå¹³ç©©æ§ä½¿å¾é£ä»¥ææä¸åæéæ³è¨ä¹éçäºåæ¨¡å¼ãç®åçåæ³é£ä»¥å°æåºä¸­çé«éäºåé²è¡å»ºæ¨¡ï¼ä¸¦å°æ³¨æ¼åå¥å­¸ç¿æéæç©ºéä¾è³´æ§ï¼ééå¶äºä¸æ¸¸ä»»åçæè½ãçºäºè§£æ±ºéäºå·®è·ï¼æåæåºäºæåºçé«éäº¤åçµæ§åµå¥æ¨¡å (High-TS)ï¼éæ¯ä¸åçµåå¤å°ºåº¦ Transformer èææ²æ·±åº¦å­¸ç¿ (TDL) çæ°ç©æ¶æ§ï¼å¯ä»¥åæå°æéåç©ºéè§é»é²è¡å»ºæ¨¡ãåæï¼High-TS å©ç¨å°æ¯å­¸ç¿ä¾æ´åéå©ç¨®çµæ§ï¼ä»¥ç¢çç©©å¥ä¸å·åå¥æ§çè¡¨ç¤ºãå»£æ³çå¯¦é©è¡¨æï¼High-TS å¨åç¨®æåºä»»åä¸­åªæ¼æåé²çæ¹æ³ï¼ä¸¦è­æäºé«éäº¤åçµæ§è³è¨å¨æ¹åæ¨¡åæè½æ¹é¢çéè¦æ§ã

##### **Bonafide at LegalLens 2024 Shared Task: Using Lightweight DeBERTa Based Encoder For Legal Violation Detection and Resolution**
2410.22977v1 by Shikha Bordia

In this work, we present two systems -- Named Entity Resolution (NER) and
Natural Language Inference (NLI) -- for detecting legal violations within
unstructured textual data and for associating these violations with potentially
affected individuals, respectively. Both these systems are lightweight DeBERTa
based encoders that outperform the LLM baselines. The proposed NER system
achieved an F1 score of 60.01\% on Subtask A of the LegalLens challenge, which
focuses on identifying violations. The proposed NLI system achieved an F1 score
of 84.73\% on Subtask B of the LegalLens challenge, which focuses on resolving
these violations by matching them with pre-existing legal complaints of class
action cases. Our NER system ranked sixth and NLI system ranked fifth on the
LegalLens leaderboard. We release the trained models and inference scripts.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºå©åç³»çµ±ââå½åå¯¦é«è§£æ (NER) åèªç¶èªè¨æ¨ç (NLI)ââåå¥ç¨æ¼æª¢æ¸¬éçµæ§åææ¬è³æä¸­çæ³å¾éè¦è¡çºï¼ä»¥åå°éäºéè¦è¡çºèæ½å¨åå½±é¿çåäººè¯ç¹«èµ·ä¾ãéå©åç³»çµ±é½æ¯åºæ¼ DeBERTa çè¼éç´ç·¨ç¢¼å¨ï¼å¶æè½åªæ¼ LLM åºæºãææåºç NER ç³»çµ±å¨ LegalLens ææ°çå­ä»»å A ä¸éå°äº 60.01% ç F1 åæ¸ï¼è©²å­ä»»åå°æ³¨æ¼è­å¥éè¦è¡çºãææåºç NLI ç³»çµ±å¨ LegalLens ææ°çå­ä»»å B ä¸éå°äº 84.73% ç F1 åæ¸ï¼è©²å­ä»»åå°æ³¨æ¼ééå°éäºéè¦è¡çºèéé«è¨´è¨æ¡ä»¶çæ¢ææ³å¾ç³è¨´ç¸å¹éä¾è§£æ±ºéäºéè¦è¡çºãæåç NER ç³»çµ±å¨ LegalLens æè¡æ¦ä¸æåç¬¬å­ï¼NLI ç³»çµ±æåç¬¬äºãæåç¼å¸è¨ç·´å¥½çæ¨¡ååæ¨çè³æ¬ã

##### **Private Synthetic Text Generation with Diffusion Models**
2410.22971v1 by Sebastian Ochs, Ivan Habernal

How capable are diffusion models of generating synthetics texts? Recent
research shows their strengths, with performance reaching that of
auto-regressive LLMs. But are they also good in generating synthetic data if
the training was under differential privacy? Here the evidence is missing, yet
the promises from private image generation look strong. In this paper we
address this open question by extensive experiments. At the same time, we
critically assess (and reimplement) previous works on synthetic private text
generation with LLMs and reveal some unmet assumptions that might have led to
violating the differential privacy guarantees. Our results partly contradict
previous non-private findings and show that fully open-source LLMs outperform
diffusion models in the privacy regime. Our complete source codes, datasets,
and experimental setup is publicly available to foster future research.

æè¦ï¼æ´æ£æ¨¡åçæåæææ¬çè½åæå¤å¼·ï¼æè¿çç ç©¶é¡¯ç¤ºåºå®åçåªå¢ï¼å¶æè½å·²éå°èªè¿´æ­¸ LLM çæ°´æºãä½æ¯ï¼å¦æè¨ç·´æ¯å¨å·®åé±ç§ä¸é²è¡ï¼å®åå¨çæåæè³ææ¹é¢æ¯å¦ä¹è¡¨ç¾è¯å¥½ï¼éæ¹é¢çè­æç®åéä»ä¹éå¦ï¼ä½å¾ç§äººå½±åçæä¸­å¾å°çæ¿è«¾çèµ·ä¾å¾å¼·ãå¨æ¬æä¸­ï¼æåééå»£æ³çå¯¦é©ä¾æ¢è¨éåéæ¾æ§çåé¡ãåæï¼æåæ¹å¤æ§å°è©ä¼°ï¼ä¸¦éæ°å¯¦ä½ï¼ååä½¿ç¨ LLM é²è¡åæç§äººæå­çæçç¸éç ç©¶ï¼ä¸¦æ­é²ä¸äºå¯è½å°è´éåå·®åé±ç§ä¿è­çæªæ»¿è¶³åè¨­ãæåççµæé¨åå°èååçéç§äººç ç©¶çµæç¸çç¾ï¼ä¸¦é¡¯ç¤ºå®å¨éæºç LLM å¨é±ç§ä¿è­·æ©å¶ä¸­åªæ¼æ´æ£æ¨¡åãæåçå®æ´åå§ç¢¼ãè³æéåå¯¦é©è¨­å®å·²å¬éï¼ä»¥ä¿é²æªä¾çç ç©¶ã

##### **Efficient Adaptation of Pre-trained Vision Transformer via Householder Transformation**
2410.22952v1 by Wei Dong, Yuan Sun, Yiting Yang, Xing Zhang, Zhijun Lin, Qingsen Yan, Haokui Zhang, Peng Wang, Yang Yang, Hengtao Shen

A common strategy for Parameter-Efficient Fine-Tuning (PEFT) of pre-trained
Vision Transformers (ViTs) involves adapting the model to downstream tasks by
learning a low-rank adaptation matrix. This matrix is decomposed into a product
of down-projection and up-projection matrices, with the bottleneck
dimensionality being crucial for reducing the number of learnable parameters,
as exemplified by prevalent methods like LoRA and Adapter. However, these
low-rank strategies typically employ a fixed bottleneck dimensionality, which
limits their flexibility in handling layer-wise variations. To address this
limitation, we propose a novel PEFT approach inspired by Singular Value
Decomposition (SVD) for representing the adaptation matrix. SVD decomposes a
matrix into the product of a left unitary matrix, a diagonal matrix of scaling
values, and a right unitary matrix. We utilize Householder transformations to
construct orthogonal matrices that efficiently mimic the unitary matrices,
requiring only a vector. The diagonal values are learned in a layer-wise
manner, allowing them to flexibly capture the unique properties of each layer.
This approach enables the generation of adaptation matrices with varying ranks
across different layers, providing greater flexibility in adapting pre-trained
models. Experiments on standard downstream vision tasks demonstrate that our
method achieves promising fine-tuning performance.

æè¦ï¼å¸¸è¦çé è¨ç·´ Vision Transformers (ViTs) åæ¸ææå¾®èª¿ (PEFT) ç­ç¥åå«ééå­¸ç¿ä½éé©æç©é£ä¾èª¿æ´æ¨¡åè³ä¸æ¸¸ä»»åãæ­¤ç©é£åè§£çºä¸æå½±åä¸æå½±ç©é£çä¹ç©ï¼å¶ä¸­ç¶é ¸ç¶­åº¦å°æ¼æ¸å°å¯å­¸ç¿åæ¸çæ¸éè³ééè¦ï¼ä¾å¦ LoRA å Adapter ç­æ®éæ¹æ³æèä¾èªªæçãç¶èï¼éäºä½éç­ç¥éå¸¸æ¡ç¨åºå®çç¶é ¸ç¶­åº¦ï¼éæéå¶å®åå¨èçéå±¤è®åæçéæ´»æ§ãçºäºè§£æ±ºæ­¤éå¶ï¼æåæåºä¸åæ°ç PEFT æ¹æ³ï¼éæä¾èªå¥ç°å¼åè§£ (SVD) ä»¥è¡¨ç¤ºé©æç©é£ãSVD å°ç©é£åè§£çºå·¦éç©é£ãç¸®æ¾å¼çå°è§ç©é£åå³éç©é£çä¹ç©ãæåå©ç¨ Householder è½æä¾å»ºæ§æ­£äº¤ç©é£ï¼ä»¥ææå°æ¨¡æ¬éç©é£ï¼åªéè¦ä¸ååéãå°è§å¼æ¯ä»¥éå±¤æ¹å¼å­¸ç¿çï¼è®å®åè½å¤ éæ´»å°æ·åæ¯åå±¤çç¨ç¹å±¬æ§ãæ­¤æ¹æ³è½ç¢çå·æä¸åå±¤éä¸åç§©çé©æç©é£ï¼å¨èª¿æ´é è¨ç·´æ¨¡åææä¾æ´å¤§çéæ´»æ§ãå¨æ¨æºä¸æ¸¸è¦è¦ºä»»åä¸çå¯¦é©è­æï¼æåçæ¨¡åéå°äºä»¤äººæ»¿æçå¾®èª¿æè½ã

##### **SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry**
2410.22950v1 by Ankita Kumari Jain, Nitish Sharma, Madhav Kanda, Nipun Batra

Respiratory illnesses are a significant global health burden. Respiratory
illnesses, primarily Chronic obstructive pulmonary disease (COPD), is the
seventh leading cause of poor health worldwide and the third leading cause of
death worldwide, causing 3.23 million deaths in 2019, necessitating early
identification and diagnosis for effective mitigation. Among the diagnostic
tools employed, spirometry plays a crucial role in detecting respiratory
abnormalities. However, conventional clinical spirometry methods often entail
considerable costs and practical limitations like the need for specialized
equipment, trained personnel, and a dedicated clinical setting, making them
less accessible. To address these challenges, wearable spirometry technologies
have emerged as promising alternatives, offering accurate, cost-effective, and
convenient solutions. The development of machine learning models for wearable
spirometry heavily relies on the availability of high-quality ground truth
spirometry data, which is a laborious and expensive endeavor. In this research,
we propose using active learning, a sub-field of machine learning, to mitigate
the challenges associated with data collection and labeling. By strategically
selecting samples from the ground truth spirometer, we can mitigate the need
for resource-intensive data collection. We present evidence that models trained
on small subsets obtained through active learning achieve comparable/better
results than models trained on the complete dataset.

æè¦ï¼å¼å¸éç¾çæ¯å¨çéå¤§çå¥åº·è² æãå¼å¸éç¾çï¼ä¸»è¦æ¯æ¢æ§é»å¡æ§èºç (COPD)ï¼æ¯å¨çç¬¬ä¸å¤§ä¸è¯å¥åº·åå ï¼ä¹æ¯å¨çç¬¬ä¸å¤§æ­»äº¡åå ï¼2019 å¹´é æ 323 è¬äººæ­»äº¡ï¼éè¦åæ©è­å¥åè¨ºæ·ä»¥æææ¸è¼ççãå¨ææ¡ç¨çè¨ºæ·å·¥å·ä¸­ï¼èºæ´»éæ¸¬éå¨æª¢æ¸¬å¼å¸éç°å¸¸æ¹é¢ç¼æ®èè³ééè¦çä½ç¨ãç¶èï¼å³çµ±çè¨åºèºæ´»éæ¸¬éæ¹æ³éå¸¸éè¦å¤§éçææ¬åå¯¦ééå¶ï¼ä¾å¦éè¦å°æ¥­è¨­åãè¨ç·´æç´ çäººå¡åå°éçè¨åºç°å¢ï¼éä½¿å¾å®åçå¯åæ§è¼ä½ãçºäºæå°éäºææ°ï¼å¯ç©¿æ´å¼èºæ´»éæ¸¬éæè¡å·²æçºæå¸æçæ¿ä»£æ¹æ¡ï¼æä¾æºç¢ºãç¶æ¿é«æä¸ä¾¿å©çè§£æ±ºæ¹æ¡ãå¯ç©¿æ´å¼èºæ´»éæ¸¬éæ©å¨å­¸ç¿æ¨¡åçéç¼å¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼é«åè³ªçåºæºèºæ´»éæ¸¬éæ¸æï¼éæ¯ä¸é è²»æä¸æè²´çå·¥ä½ãå¨éé ç ç©¶ä¸­ï¼æåå»ºè­°ä½¿ç¨ä¸»åå­¸ç¿ï¼æ©å¨å­¸ç¿çä¸åå­é åï¼ä¾æ¸è¼èæ¸ææ¶éåæ¨è¨ç¸éçææ°ãééå¾åºæºèºæ´»éè¨ä¸­ç­ç¥æ§å°é¸ææ¨£æ¬ï¼æåå¯ä»¥æ¸å°å°è³æºå¯éåæ¸ææ¶éçéæ±ãæåæä¾çè­æè¡¨æï¼å¨ééä¸»åå­¸ç¿ç²å¾çå°å­éä¸­è¨ç·´çæ¨¡åï¼ç²å¾ççµæèå¨å®æ´æ¸æéä¸è¨ç·´çæ¨¡åç¸ç¶/æ´å¥½ã

##### **Focus On This, Not That! Steering LLMs With Adaptive Feature Specification**
2410.22944v1 by Tom A. Lamb, Adam Davies, Alasdair Paren, Philip H. S. Torr, Francesco Pinto

Despite the success of Instruction Tuning (IT) in training large language
models (LLMs) to perform arbitrary user-specified tasks, these models often
still leverage spurious or biased features learned from their training data,
leading to undesired behaviours when deploying them in new contexts. In this
work, we introduce Focus Instruction Tuning (FIT), which trains LLMs to
condition their responses by focusing on specific features whilst ignoring
others, leading to different behaviours based on what features are specified.
Across several experimental settings, we show that focus-tuned models can be
adaptively steered by focusing on different features at inference-time: for
instance, robustness can be improved by focusing on task-causal features and
ignoring spurious features, and social bias can be mitigated by ignoring
demographic categories. Furthermore, FIT can steer behaviour in new contexts,
generalising under distribution shift and to new unseen features at inference
time, and thereby facilitating more robust, fair, and controllable LLM
applications in real-world environments.

æè¦ï¼åç®¡æä»¤èª¿æ´ (IT) å¨è¨ç·´å¤§åèªè¨æ¨¡å (LLM) ä»¥å·è¡ä»»æä½¿ç¨èæå®ä»»åæ¹é¢åå¾æåï¼ä½éäºæ¨¡åéå¸¸ä»æå©ç¨å¾å¶è¨ç·´è³æä¸­å­¸ç¿å°çèåæåå·®ç¹å¾µï¼å°è´å¨æ°çç°å¢ä¸­é¨ç½²å®åæåºç¾ä¸å¿è¦çè¡çºãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºç¦é»æä»¤èª¿æ´ (FIT)ï¼å®è¨ç·´ LLM ééå°æ³¨æ¼ç¹å®ç¹å¾µåæå¿½ç¥å¶ä»ç¹å¾µä¾èª¿æ´å¶åæï¼å¾èæ ¹æææå®çç¹å¾µç¢çä¸åçè¡çºãå¨å¤åå¯¦é©è¨­å®ä¸­ï¼æåå±ç¤ºäºç¦é»èª¿æ´æ¨¡åå¯ä»¥å¨æ¨è«æééå°æ³¨æ¼ä¸åçç¹å¾µä¾é©ææ§å°é²è¡å¼å°ï¼ä¾å¦ï¼ééå°æ³¨æ¼ä»»åå æç¹å¾µä¸¦å¿½ç¥èåç¹å¾µï¼å¯ä»¥æé«å¥å£¯æ§ï¼ä¸¦ä¸ééå¿½ç¥äººå£çµ±è¨é¡å¥ï¼å¯ä»¥æ¸è¼ç¤¾æåè¦ãæ­¤å¤ï¼FIT å¯ä»¥å¼å°å¨æ°çç°å¢ä¸­çè¡çºï¼å¨æ¨è«æå°åä½è½ç§»åæ°çæªè¦ç¹å¾µé²è¡æ¦åï¼å¾èä¿é²å¨ç¾å¯¦ä¸çç°å¢ä¸­æ´å¥å£¯ãæ´å¬å¹³ä¸å¯æ§ç LLM æç¨ã

##### **DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data**
2410.22938v2 by Hanyang Chen, Yang Jiang, Shengnan Guo, Xiaowei Mao, Youfang Lin, Huaiyu Wan

The application of reinforcement learning in traffic signal control (TSC) has
been extensively researched and yielded notable achievements. However, most
existing works for TSC assume that traffic data from all surrounding
intersections is fully and continuously available through sensors. In
real-world applications, this assumption often fails due to sensor malfunctions
or data loss, making TSC with missing data a critical challenge. To meet the
needs of practical applications, we introduce DiffLight, a novel conditional
diffusion model for TSC under data-missing scenarios in the offline setting.
Specifically, we integrate two essential sub-tasks, i.e., traffic data
imputation and decision-making, by leveraging a Partial Rewards Conditioned
Diffusion (PRCD) model to prevent missing rewards from interfering with the
learning process. Meanwhile, to effectively capture the spatial-temporal
dependencies among intersections, we design a Spatial-Temporal transFormer
(STFormer) architecture. In addition, we propose a Diffusion Communication
Mechanism (DCM) to promote better communication and control performance under
data-missing scenarios. Extensive experiments on five datasets with various
data-missing scenarios demonstrate that DiffLight is an effective controller to
address TSC with missing data. The code of DiffLight is released at
https://github.com/lokol5579/DiffLight-release.

æè¦ï¼å¼·åå­¸ç¿å¨äº¤éèèªæ§å¶ (TSC) ä¸­çæç¨å·²å»£æ³ç ç©¶ï¼ä¸¦åå¾é¡¯èææãç¶èï¼å¤§å¤æ¸ç¾æç TSC ä½ååè¨­ä¾èªææå¨åè·¯å£çäº¤éè³æé½æ¯ééææ¸¬å¨å®æ´ä¸æçºå¯ç¨çãå¨å¯¦éæç¨ä¸­ï¼æ­¤åè¨­ç¶å¸¸å ææ¸¬å¨æéæè³æéºå¤±èå¤±æï¼éä½¿å¾éºå¤±è³æç TSC æçºä¸é å´å³»çææ°ãçºäºæ»¿è¶³å¯¦éæç¨çéæ±ï¼æåå¼å¥äº DiffLightï¼éæ¯ä¸ç¨®ç¨æ¼é¢ç·è¨­å®ä¸­è³æéºå¤±å ´æ¯ä¸ TSC çæ°åæ¢ä»¶æ´æ£æ¨¡åãå·é«ä¾èªªï¼æåæ´åäºå©åéè¦çå­ä»»åï¼å³äº¤éè³æå¡«è£åæ±ºç­å¶å®ï¼ééå©ç¨é¨åçåµæ¢ä»¶æ´æ£ (PRCD) æ¨¡åä¾é²æ­¢éºå¤±ççåµå¹²æ¾å­¸ç¿éç¨ãåæï¼çºäºæææ·åè·¯å£ä¹éçæç©ºä¾è³´æ§ï¼æåè¨­è¨äºä¸åæç©º transFormer (STFormer) æ¶æ§ãæ­¤å¤ï¼æåæåºäºä¸ç¨®æ´æ£éè¨æ©å¶ (DCM) ä¾ä¿é²å¨è³æéºå¤±å ´æ¯ä¸­æ´å¥½çéè¨åæ§å¶æè½ãå¨å·æåç¨®è³æéºå¤±å ´æ¯çäºåè³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼DiffLight æ¯ä¸åææçæ§å¶å¨ï¼å¯ä»¥è§£æ±ºéºå¤±è³æç TSCãDiffLight çç¨å¼ç¢¼å·²å¨ https://github.com/lokol5579/DiffLight-release ä¸­éåºã

##### **Thoughtful Adoption of NLP for Civic Participation: Understanding Differences Among Policymakers**
2410.22937v1 by Jose A. Guridi, Cristobal Cheyre, Qian Yang

Natural language processing (NLP) tools have the potential to boost civic
participation and enhance democratic processes because they can significantly
increase governments' capacity to gather and analyze citizen opinions. However,
their adoption in government remains limited, and harnessing their benefits
while preventing unintended consequences remains a challenge. While prior work
has focused on improving NLP performance, this work examines how different
internal government stakeholders influence NLP tools' thoughtful adoption. We
interviewed seven politicians (politically appointed officials as heads of
government institutions) and thirteen public servants (career government
employees who design and administrate policy interventions), inquiring how they
choose whether and how to use NLP tools to support civic participation
processes. The interviews suggest that policymakers across both groups focused
on their needs for career advancement and the need to showcase the legitimacy
and fairness of their work when considering NLP tool adoption and use. Because
these needs vary between politicians and public servants, their preferred NLP
features and tool designs also differ. Interestingly, despite their differing
needs and opinions, neither group clearly identifies who should advocate for
NLP adoption to enhance civic participation or address the unintended
consequences of a poorly considered adoption. This lack of clarity in
responsibility might have caused the governments' low adoption of NLP tools. We
discuss how these findings reveal new insights for future HCI research. They
inform the design of NLP tools for increasing civic participation efficiency
and capacity, the design of other tools and methods that ensure thoughtful
adoption of AI tools in government, and the design of NLP tools for
collaborative use among users with different incentives and needs.

æè¦ï¼èªç¶èªè¨èç (NLP) å·¥å·ææ½åæåå¬æ°åèåº¦ï¼ä¸¦å å¼·æ°ä¸»ç¨åºï¼å çºå®åå¯ä»¥å¤§å¹å¢å æ¿åºæ¶éååæå¬æ°æè¦çè½åãç¶èï¼å®åå¨æ¿åºä¸­çæ¡ç¨ä»ç¶æéï¼å¨é²æ­¢æå¤å¾æçåæå©ç¨å®åçåªé»ä»ç¶æ¯ä¸åææ°ãéç¶ååçç ç©¶éä¸­å¨æ¹é² NLP æè½ï¼ä½éé ç ç©¶æ¢è¨äºä¸åçæ¿åºå§é¨å©å®³éä¿äººå¦ä½å½±é¿ NLP å·¥å·çå¨å¨æ¡ç¨ãæåè¨ªè«äºä¸ä½æ¿æ²»äººç©ï¼æä»»æ¿åºæ©æ§é¦é·çæ¿æ²»ä»»å½å®å¡ï¼ååä¸ä½å¬åå¡ï¼è¨­è¨åç®¡çæ¿ç­å¹²é æªæ½çè·æ¥­æ¿åºéå¡ï¼ï¼è©¢åä»åå¦ä½é¸ææ¯å¦ä»¥åå¦ä½ä½¿ç¨ NLP å·¥å·ä¾æ¯æå¬æ°åèç¨åºãè¨ªè«çµæé¡¯ç¤ºï¼å©çµçæ¿ç­å¶å®èå¨èæ®æ¡ç¨åä½¿ç¨ NLP å·¥å·æï¼é½å°æ³¨æ¼ä»åå°è·æ¶¯é²éçéæ±ï¼ä»¥åå±ç¤ºå¶å·¥ä½çåæ³æ§åå¬å¹³æ§çéæ±ãç±æ¼éäºéæ±å¨æ¿æ²»äººç©åå¬åå¡ä¹éææä¸åï¼å æ­¤ä»ååå¥½ç NLP åè½åå·¥å·è¨­è¨ä¹åä¸ç¸åãæè¶£çæ¯ï¼åç®¡ä»åæä¸åçéæ±åæè¦ï¼ä½å©çµé½æ²ææç¢ºæåºèª°æè©²å¡å°æ¡ç¨ NLP ä¾å å¼·å¬æ°åèï¼æè§£æ±ºèæ®ä¸å¨çæ¡ç¨æé æçæå¤å¾æãéç¨®è²¬ä»»ä¸æ¸çææ³å¯è½å°è´æ¿åºæ¡ç¨ NLP å·¥å·çç¨åº¦åä½ãæåè¨è«äºéäºç¼ç¾å¦ä½æ­ç¤ºæªä¾ HCI ç ç©¶çæ°è¦è§£ãå®ååç¥äº NLP å·¥å·çè¨­è¨ï¼ä»¥æé«å¬æ°åèçæçåè½åï¼ç¢ºä¿å¨å¨æ¡ç¨æ¿åºä¸­ AI å·¥å·çå¶ä»å·¥å·åæ¹æ³çè¨­è¨ï¼ä»¥åçºå·æä¸åèªå åéæ±çä½¿ç¨èä¹éåä½ä½¿ç¨èè¨­è¨ç NLP å·¥å·ã

##### **Multi-Agent Large Language Models for Conversational Task-Solving**
2410.22932v1 by Jonas Becker

In an era where single large language models have dominated the landscape of
artificial intelligence for years, multi-agent systems arise as new
protagonists in conversational task-solving. While previous studies have
showcased their potential in reasoning tasks and creative endeavors, an
analysis of their limitations concerning the conversational paradigms and the
impact of individual agents is missing. It remains unascertained how
multi-agent discussions perform across tasks of varying complexity and how the
structure of these conversations influences the process. To fill that gap, this
work systematically evaluates multi-agent systems across various discussion
paradigms, assessing their strengths and weaknesses in both generative tasks
and question-answering tasks. Alongside the experiments, I propose a taxonomy
of 20 multi-agent research studies from 2022 to 2024, followed by the
introduction of a framework for deploying multi-agent LLMs in conversational
task-solving. I demonstrate that while multi-agent systems excel in complex
reasoning tasks, outperforming a single model by leveraging expert personas,
they fail on basic tasks. Concretely, I identify three challenges that arise:
1) While longer discussions enhance reasoning, agents fail to maintain
conformity to strict task requirements, which leads to problem drift, making
shorter conversations more effective for basic tasks. 2) Prolonged discussions
risk alignment collapse, raising new safety concerns for these systems. 3) I
showcase discussion monopolization through long generations, posing the problem
of fairness in decision-making for tasks like summarization. This work uncovers
both the potential and challenges that arise with multi-agent interaction and
varying conversational paradigms, providing insights into how future research
could improve the efficiency, performance, and safety of multi-agent LLMs.

æè¦ï¼<paragraph>å¨å¤§ååä¸è¯­è¨æ¨¡åå¤å¹´æ¥ä¸»å¯¼äººå·¥æºè½é¢åçç¯å¢ä¸­ï¼å¤æºè½ä½ç³»ç»ä½ä¸ºå¯¹è¯ä»»å¡è§£å³çæ°ä¸»è§åºç°ãè½ç¶ååçç ç©¶å±ç¤ºäºå®ä»¬å¨æ¨çä»»å¡ååé æ§å·¥ä½ä¸­çæ½åï¼ä½ç¼ºå°å¯¹å¶å¨å¯¹è¯èä¾åä¸ªä½æºè½ä½å½±åæ¹é¢çéå¶çåæãå¤æºè½ä½è®¨è®ºå¦ä½å¨ä¸åå¤æç¨åº¦çä»»å¡ä¸­æ§è¡ä»¥åè¿äºå¯¹è¯çç»æå¦ä½å½±åè¿ä¸è¿ç¨ä»æªç¡®å®ãä¸ºäºå¡«è¡¥è¿ä¸ç©ºç½ï¼è¿é¡¹å·¥ä½ç³»ç»å°è¯ä¼°äºåç§è®¨è®ºèä¾ä¸­çå¤æºè½ä½ç³»ç»ï¼è¯ä¼°äºå®ä»¬å¨çææ§ä»»å¡åé®ç­ä»»å¡ä¸­çä¼å¿åå£å¿ãé¤äºå®éªä¹å¤ï¼æè¿æåºäº 2022 å¹´è³ 2024 å¹´é´ 20 é¡¹å¤æºè½ä½ç ç©¶çåç±»æ³ï¼éåä»ç»äºä¸ä¸ªå¨å¯¹è¯ä»»å¡è§£å³ä¸­é¨ç½²å¤æºè½ä½ LLM çæ¡æ¶ãæå±ç¤ºäºå¤æºè½ä½ç³»ç»è½ç¶å¨å¤ææ¨çä»»å¡ä¸­è¡¨ç°åºè²ï¼éè¿å©ç¨ä¸å®¶è§è²èä¼äºåä¸ªæ¨¡åï¼ä½å®ä»¬å¨åºæ¬ä»»å¡ä¸­å´å¤±è´¥äºãå·ä½æ¥è¯´ï¼æç¡®å®äºä¸ä¸ªåºç°çææï¼1) è½ç¶è¾é¿çè®¨è®ºå¢å¼ºäºæ¨çï¼ä½æºè½ä½æ æ³ä¿æå¯¹ä¸¥æ ¼ä»»å¡è¦æ±çä¸è´æ§ï¼è¿ä¼å¯¼è´é®é¢æ¼ç§»ï¼ä½¿å¾è¾ç­çå¯¹è¯å¯¹åºæ¬ä»»å¡æ´ææã2) é¿æ¶é´çè®¨è®ºæå¯¹é½å´©æºçé£é©ï¼ä¸ºè¿äºç³»ç»å¸¦æ¥äºæ°çå®å¨é®é¢ã3) æå±ç¤ºäºéè¿é¿çæè¿è¡è®¨è®ºåæ­ï¼å¯¹æè¦ç­ä»»å¡çå³ç­å¬å¹³æ§ææäºé®é¢ãè¿é¡¹å·¥ä½æ­ç¤ºäºå¤æºè½ä½äº¤äºåä¸åçå¯¹è¯èä¾å¸¦æ¥çæ½ååææï¼æä¾äºå¯¹æªæ¥ç ç©¶å¦ä½æé«å¤æºè½ä½ LLM çæçãæ§è½åå®å¨æ§çè§è§£ã</paragraph>

##### **BIS: NL2SQL Service Evaluation Benchmark for Business Intelligence Scenarios**
2410.22925v1 by Bora Caglayan, Mingxue Wang, John D. Kelleher, Shen Fei, Gui Tong, Jiandong Ding, Puchao Zhang

NL2SQL (Natural Language to Structured Query Language) transformation has
seen wide adoption in Business Intelligence (BI) applications in recent years.
However, existing NL2SQL benchmarks are not suitable for production BI
scenarios, as they are not designed for common business intelligence questions.
To address this gap, we have developed a new benchmark focused on typical NL
questions in industrial BI scenarios. We discuss the challenges of constructing
a BI-focused benchmark and the shortcomings of existing benchmarks.
Additionally, we introduce question categories in our benchmark that reflect
common BI inquiries. Lastly, we propose two novel semantic similarity
evaluation metrics for assessing NL2SQL capabilities in BI applications and
services.

æè¦ï¼è¿å¹´ä¾ï¼NL2SQLï¼èªç¶èªè¨å°çµæ§åæ¥è©¢èªè¨ï¼è½æå·²å»£æ³ç¨æ¼åæ¥­æºæ§ï¼BIï¼æç¨ç¨å¼ä¸­ã
ç¶èï¼ç¾æç NL2SQL åºæºä¸¦ä¸é©ç¨æ¼çç¢ BI å ´æ¯ï¼å çºå®åä¸¦ééå°å¸¸è¦çåæ¥­æºæ§åé¡èè¨­è¨ã
çºäºè§£æ±ºéåå·®è·ï¼æåéç¼äºä¸åæ°çåºæºï¼å°æ³¨æ¼å·¥æ¥­ BI å ´æ¯ä¸­çå¸å NL åé¡ãæåè¨è«äºå»ºæ§ä»¥ BI çºä¸­å¿çåºæºçææ°åç¾æåºæºçç¼ºé»ã
æ­¤å¤ï¼æåå¨åºæºä¸­å¼å¥äºåæ å¸¸è¦ BI æ¥è©¢çåé¡é¡å¥ãæå¾ï¼æåæåºäºå©åæ°çèªç¾©ç¸ä¼¼æ§è©ä¼°ææ¨ï¼ç¨æ¼è©ä¼° BI æç¨ç¨å¼åæåä¸­ç NL2SQL åè½ã

##### **Explainable Behavior Cloning: Teaching Large Language Model Agents through Learning by Demonstration**
2410.22916v1 by Yanchu Guan, Dong Wang, Yan Wang, Haiqing Wang, Renen Sun, Chenyi Zhuang, Jinjie Gu, Zhixuan Chu

Autonomous mobile app interaction has become increasingly important with
growing complexity of mobile applications. Developing intelligent agents that
can effectively navigate and interact with mobile apps remains a significant
challenge. In this paper, we propose an Explainable Behavior Cloning LLM Agent
(EBC-LLMAgent), a novel approach that combines large language models (LLMs)
with behavior cloning by learning demonstrations to create intelligent and
explainable agents for autonomous mobile app interaction. EBC-LLMAgent consists
of three core modules: Demonstration Encoding, Code Generation, and UI Mapping,
which work synergistically to capture user demonstrations, generate executable
codes, and establish accurate correspondence between code and UI elements. We
introduce the Behavior Cloning Chain Fusion technique to enhance the
generalization capabilities of the agent. Extensive experiments on five popular
mobile applications from diverse domains demonstrate the superior performance
of EBC-LLMAgent, achieving high success rates in task completion, efficient
generalization to unseen scenarios, and the generation of meaningful
explanations.

æè¦ï¼é¨èè¡åæç¨ç¨å¼çè¤éæ§æ¥çæåï¼èªä¸»è¡åæç¨ç¨å¼äºåè®å¾è¶ä¾è¶éè¦ãéç¼è½ææå°èªåèè¡åæç¨ç¨å¼äºåçæºæ§ä»£çç¨å¼ä»ç¶æ¯ä¸é éå¤§çææ°ãå¨æ¬æä¸­ï¼æåæåºå¯è§£éè¡çºè¤è£½ LLM ä»£çç¨å¼ (EBC-LLMAgent)ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å®çµåå¤§åèªè¨æ¨¡å (LLM) èè¡çºè¤è£½ï¼ééå­¸ç¿ç¤ºç¯ä¾å»ºç«æºæ§ä¸å¯è§£éçä»£çç¨å¼ï¼ä»¥é²è¡èªä¸»è¡åæç¨ç¨å¼äºåãEBC-LLMAgent ç±ä¸åæ ¸å¿æ¨¡çµçµæï¼ç¤ºç¯ç·¨ç¢¼ãç¨å¼ç¢¼ç¢çå UI å°æï¼å®åååéä½ä»¥æ·åä½¿ç¨èç¤ºç¯ãç¢çå¯å·è¡ç¨å¼ç¢¼ï¼ä¸¦å¨ç¨å¼ç¢¼å UI åç´ ä¹éå»ºç«æºç¢ºçå°æéä¿ãæåå¼é²è¡çºè¤è£½éèåæè¡ï¼ä»¥å¢å¼·ä»£çç¨å¼çæ¦åè½åãå¨ä¾èªä¸åé åçäºåç±éè¡åæç¨ç¨å¼ä¸é²è¡çå»£æ³å¯¦é©ï¼è­æäº EBC-LLMAgent çåªç°æè½ï¼å¨ä»»åå®ææ¹é¢éå°äºå¾é«çæåçãæææ¦åè³æªè¦æå¢ï¼ä¸¦ç¢çææç¾©çè§£éã

##### **From Babble to Words: Pre-Training Language Models on Continuous Streams of Phonemes**
2410.22906v1 by ZÃ©bulon Goriely, Richard Diehl Martinez, Andrew Caines, Lisa Beinborn, Paula Buttery

Language models are typically trained on large corpora of text in their
default orthographic form. However, this is not the only option; representing
data as streams of phonemes can offer unique advantages, from deeper insights
into phonological language acquisition to improved performance on sound-based
tasks. The challenge lies in evaluating the impact of phoneme-based training,
as most benchmarks are also orthographic. To address this, we develop a
pipeline to convert text datasets into a continuous stream of phonemes. We
apply this pipeline to the 100-million-word pre-training dataset from the
BabyLM challenge, as well as to standard language and grammatical benchmarks,
enabling us to pre-train and evaluate a model using phonemic input
representations. Our results show that while phoneme-based training slightly
reduces performance on traditional language understanding tasks, it offers
valuable analytical and practical benefits.

æè¦ï¼èªè¨æ¨¡åéå¸¸æéå°å¶é è¨­æ­£å­æ³å½¢å¼çå¤§åæå­èªæåº«é²è¡è¨ç·´ãç¶èï¼éä¸¦éå¯ä¸é¸é ï¼å°è³æè¡¨ç¤ºçºé³ç´ ä¸²æµå¯ä»¥æä¾ç¨ç¹åªå¢ï¼å¾æ´æ·±å¥æ´å¯é³ç³»èªè¨ç¿å¾ï¼å°æåä»¥è²é³çºåºç¤çä»»åæè½ãææ°å¨æ¼è©ä¼°ä»¥é³ç´ çºåºç¤çè¨ç·´å½±é¿ï¼å çºå¤§å¤æ¸åºæºä¹æ¯æ­£å­æ³çãçºäºè§£æ±ºéååé¡ï¼æåéç¼ä¸åå°æå­è³æéè½æçºé£çºé³ç´ ä¸²æµçç®¡éãæåå°éåç®¡éæç¨æ¼ BabyLM ææ°ä¸­ç 1 åå­é è¨ç·´è³æéï¼ä»¥åæ¨æºèªè¨åèªæ³åºæºï¼è®æåè½å¤ ä½¿ç¨é³ç´ è¼¸å¥è¡¨ç¤ºæ³é è¨ç·´åè©ä¼°æ¨¡åãæåççµæé¡¯ç¤ºï¼éç¶ä»¥é³ç´ çºåºç¤çè¨ç·´æç¨å¾®éä½å³çµ±èªè¨çè§£ä»»åçæè½ï¼ä½å®æä¾äºå¯¶è²´çåæåå¯¦ååªå¢ã

##### **YOLOv11 for Vehicle Detection: Advancements, Performance, and Applications in Intelligent Transportation Systems**
2410.22898v1 by Mujadded Al Rabbani Alif

Accurate vehicle detection is essential for the development of intelligent
transportation systems, autonomous driving, and traffic monitoring. This paper
presents a detailed analysis of YOLO11, the latest advancement in the YOLO
series of deep learning models, focusing exclusively on vehicle detection
tasks. Building upon the success of its predecessors, YOLO11 introduces
architectural improvements designed to enhance detection speed, accuracy, and
robustness in complex environments. Using a comprehensive dataset comprising
multiple vehicle types-cars, trucks, buses, motorcycles, and bicycles we
evaluate YOLO11's performance using metrics such as precision, recall, F1
score, and mean average precision (mAP). Our findings demonstrate that YOLO11
surpasses previous versions (YOLOv8 and YOLOv10) in detecting smaller and more
occluded vehicles while maintaining a competitive inference time, making it
well-suited for real-time applications. Comparative analysis shows significant
improvements in the detection of complex vehicle geometries, further
contributing to the development of efficient and scalable vehicle detection
systems. This research highlights YOLO11's potential to enhance autonomous
vehicle performance and traffic monitoring systems, offering insights for
future developments in the field.

æè¦ï¼ç²¾ç¢ºçè»è¼åµæ¸¬å°æ¼æºæ§äº¤éç³»çµ±ãèªåé§é§åäº¤éç£æ§çç¼å±è³ééè¦ãéç¯è«æéå° YOLO ç³»åæ·±åº¦å­¸ç¿æ¨¡åçææ°é²å± YOLO11 é²è¡è©³ç´°åæï¼å°æ³¨æ¼è»è¼åµæ¸¬ä»»åãYOLO11 å»ºç«å¨åä»£çæååºç¤ä¸ï¼å¼é²æ¶æ§æ¹åï¼æ¨å¨æååµæ¸¬éåº¦ãæºç¢ºåº¦åå¨è¤éç°å¢ä¸­çç©©å¥æ§ãæåä½¿ç¨åå«å¤ç¨®è»è¼é¡åï¼æ±½è»ãå¡è»ãå¬è»ãæ©è»åèªè¡è»ï¼çç¶åè³æéï¼ä½¿ç¨æºç¢ºåº¦ãå¬åçãF1 åæ¸åå¹³åæºç¢ºåº¦ (mAP) ç­ææ¨è©ä¼° YOLO11 çæè½ãæåçç ç©¶çµæé¡¯ç¤ºï¼YOLO11 å¨åµæ¸¬è¼å°ä¸è¢«é®æçè»è¼æ¹é¢åªæ¼ä¹åççæ¬ (YOLOv8 å YOLOv10)ï¼åæç¶­ææç«¶ç­åçæ¨è«æéï¼ä½¿å¶éå¸¸é©åæ¼å³ææç¨ãæ¯è¼åæé¡¯ç¤ºå¨è¤éè»è¼å¹¾ä½å½¢ççåµæ¸¬æ¹é¢æé¡¯èæ¹åï¼é²ä¸æ­¥ä¿é²äºé«æä¸å¯æ´åçè»è¼åµæ¸¬ç³»çµ±çç¼å±ãéé ç ç©¶å¼·èª¿äº YOLO11 æåèªåé§é§è»è¼æè½åäº¤éç£æ§ç³»çµ±çæ½åï¼çºè©²é åçæªä¾ç¼å±æä¾è¦è§£ã

##### **VPO: Leveraging the Number of Votes in Preference Optimization**
2410.22891v1 by Jae Hyeon Cho, Minkyung Park, Byung-Jun Lee

Direct Preference Optimization (DPO) trains a language model using human
preference data, bypassing the explicit reward modeling phase of Reinforcement
Learning from Human Feedback (RLHF). By iterating over sentence pairs in a
preference dataset, DPO enhances generation quality by increasing the
likelihood of producing preferred sentences over less favored ones. Preference
datasets are typically created by selecting preferred sentences through a
voting process involving multiple individuals, as opinions can vary due to the
subjective nature of human preferences. While the number of votes offers
insight into whether a sentence pair is clearly preferable or controversial,
current methods do not fully leverage this information. In this paper, we
introduce a technique that leverages user voting data to better align with
diverse subjective preferences. We employ the Bayesian Minimum Mean Square
Error (Bayesian MMSE) estimator to model the probability that one generation is
preferable to another. Using this estimated probability as a target, we develop
the Vote-based Preference Optimization (VPO) framework, which incorporates the
number of votes on both sides to distinguish between controversial and obvious
generation pairs. We show that previous algorithms, such as DPO and Identity
Preference Optimization (IPO), can be extended using the proposed framework,
termed VDPO and VIPO. Our experiments demonstrate that these proposed
algorithms outperform various existing methods, including their base
algorithms.

æè¦ï¼ç´æ¥åå¥½æä½³åï¼DPOï¼ä½¿ç¨äººé¡åå¥½è³æè¨ç·´èªè¨æ¨¡åï¼ç¹éäººé¡åé¥å¼·åå­¸ç¿ï¼RLHFï¼çæç¢ºçåµå»ºæ¨¡éæ®µãééå¨åå¥½è³æéä¸­çå¥å­å°ä¸­åè¦éç®ï¼DPO ééå¢å ç¢çåå¥½å¥å­çæ©çï¼é²èæåç¢çåè³ªï¼åéä¸é£éº¼åæ­¡è¿çå¥å­ãåå¥½è³æééå¸¸ééæç¥¨ç¨åºå»ºç«ï¼ä¸¦ç±å¤ä½åäººåèï¼å çºæè¦å¯è½æå äººé¡åå¥½çä¸»è§æ§è³ªèææä¸åãåç®¡æç¥¨æ¸æä¾äºè¦è§£ï¼èªªæå¥å­å°æ¯å¦æé¡¯è¼ä½³ææç­è­°ï¼ä½ç®åçæè¡ä¸¦æªååå©ç¨éäºè³è¨ãå¨æ¬æä¸­ï¼æåå¼é²ä¸é æè¡ï¼å©ç¨ä½¿ç¨èæç¥¨è³æï¼ä»¥æ´å¥½å°èä¸åçä¸»è§åå¥½ä¿æä¸è´ãæåæ¡ç¨è²æ°æå°åæ¹èª¤å·®ï¼è²æ° MMSEï¼ä¼°è¨å¨ï¼ä¾å»ºæ¨¡ä¸åç¢ççµææ¯å¦ä¸åç¢ççµææ´ä½³çæ©çãä½¿ç¨éåä¼°è¨æ©çä½çºç®æ¨ï¼æåéç¼äºåºæ¼æç¥¨çåå¥½æä½³åï¼VPOï¼æ¶æ§ï¼å¶ä¸­ç´å¥å©æ¹çæç¥¨æ¸ï¼ä»¥ååæç­è­°åé¡¯èæè¦çç¢çå°ãæåå±ç¤ºäºååçæ¼ç®æ³ï¼ä¾å¦ DPO åèº«ååå¥½æä½³åï¼IPOï¼ï¼å¯ä»¥ä½¿ç¨ææåºçæ¶æ§é²è¡å»¶ä¼¸ï¼ç¨±çº VDPO å VIPOãæåçå¯¦é©è­æï¼éäºæåºçæ¼ç®æ³åªæ¼åç¨®ç¾ææ¹æ³ï¼åæ¬å¶åºæ¬æ¼ç®æ³ã

##### **Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector**
2410.22888v1 by Youcheng Huang, Fengbin Zhu, Jingkun Tang, Pan Zhou, Wenqiang Lei, Jiancheng Lv, Tat-Seng Chua

Visual Language Models (VLMs) are vulnerable to adversarial attacks,
especially those from adversarial images, which is however under-explored in
literature. To facilitate research on this critical safety problem, we first
construct a new laRge-scale Adervsarial images dataset with Diverse hArmful
Responses (RADAR), given that existing datasets are either small-scale or only
contain limited types of harmful responses. With the new RADAR dataset, we
further develop a novel and effective iN-time Embedding-based AdveRSarial Image
DEtection (NEARSIDE) method, which exploits a single vector that distilled from
the hidden states of VLMs, which we call the attacking direction, to achieve
the detection of adversarial images against benign ones in the input. Extensive
experiments with two victim VLMs, LLaVA and MiniGPT-4, well demonstrate the
effectiveness, efficiency, and cross-model transferrability of our proposed
method. Our code is available at https://github.com/mob-scu/RADAR-NEARSIDE

æè¦ï¼è¦è¦ºèªè¨æ¨¡å (VLM) å®¹æåå°å°ææ§æ»æï¼ç¹å¥æ¯ä¾èªå°ææ§å½±åçæ»æï¼èéå¨æç»ä¸­å»é®®å°æ¢è¨ãçºäºä¿é²å°éåééµå®å¨åé¡çç ç©¶ï¼æåé¦åå»ºæ§äºä¸åæ°çå·åå¤æ¨£åæå®³åæçå¤§è¦æ¨¡å°ææ§å½±åè³æé (RADAR)ï¼å çºç¾æçè³æéè¦æ¨¡éå°æååå«æéé¡åçæå®³åæãæäºæ°ç RADAR è³æéï¼æåé²ä¸æ­¥éç¼äºä¸ç¨®æ°ç©ä¸ææçå³æåµå¥å¼å°ææ§å½±ååµæ¸¬ (NEARSIDE) æ¹æ³ï¼å®å©ç¨å¾ VLM çé±èçæä¸­èååºçå®ä¸åéï¼æåç¨±ä¹çºæ»ææ¹åï¼ä¾åµæ¸¬è¼¸å¥ä¸­çå°ææ§å½±ååè¯æ§å½±åãä½¿ç¨å©ååå®³è VLMï¼LLaVA å MiniGPT-4ï¼é²è¡çå»£æ³å¯¦é©ååè­æäºæåææåºçæ¹æ³çæææ§ãæçåè·¨æ¨¡åå¯å³éæ§ãæåçç¨å¼ç¢¼å¯æ¼ https://github.com/mob-scu/RADAR-NEARSIDE åå¾

##### **Less is More: Pre-Training Cross-Lingual Small-Scale Language Models with Cognitively-Plausible Curriculum Learning Strategies**
2410.22886v1 by Suchir Salhan, Richard Diehl Martinez, ZÃ©bulon Goriely, Paula Buttery

Curriculum Learning has been a popular strategy to improve the cognitive
plausibility of Small-Scale Language Models (SSLMs) in the BabyLM Challenge.
However, it has not led to considerable improvements over non-curriculum
models. We assess whether theoretical linguistic acquisition theories can be
used to specify more fine-grained curriculum learning strategies, creating
age-ordered corpora of Child-Directed Speech for four typologically distant
language families to implement SSLMs and acquisition-inspired curricula
cross-lingually. Comparing the success of three objective curricula (Growing,
Inwards and MMM) that precisely replicate the predictions of acquisition
theories on a standard SSLM architecture, we find fine-grained
acquisition-inspired curricula can outperform non-curriculum baselines and
performance benefits of curricula strategies in SSLMs can be derived by
specifying fine-grained language-specific curricula that precisely replicate
language acquisition theories.

æè¦ï¼èª²ç¨å­¸ç¿ä¸ç´æ¯æé« BabyLM ææ°ä¸­å°åèªè¨æ¨¡å (SSLMs) çèªç¥åçæ§çç±éç­ç¥ã
ç¶èï¼å®ä¸¦æªå°è´éèª²ç¨æ¨¡åæé¡¯èçæ¹é²ãæåè©ä¼°çè«èªè¨ç¿å¾çè«æ¯å¦å¯ç¨æ¼æå®æ´ç´°ç·»çèª²ç¨å­¸ç¿ç­ç¥ï¼çºååé¡åå­¸ä¸ç¸è·çé çèªè¨å®¶æå»ºç«åç«¥å°åè¨èªçå¹´é½¡é åºèªæåº«ï¼ä»¥è·¨èªè¨å°å¯¦æ½ SSLM åç¿å¾åç¼èª²ç¨ãæ¯è¼ä¸åå®¢è§èª²ç¨ï¼GrowingãInwards å MMMï¼çæåï¼éäºèª²ç¨ç²¾ç¢ºå°è¤è£½äºæ¨æº SSLM æ¶æ§ä¸çç¿å¾çè«é æ¸¬ï¼æåç¼ç¾ç´°ç·»çç¿å¾åç¼èª²ç¨å¯ä»¥åªæ¼éèª²ç¨åºæºï¼ä¸¦ä¸ SSLM ä¸­èª²ç¨ç­ç¥çæè½åªå¢å¯ä»¥ééæå®ç²¾ç¢ºè¤è£½èªè¨ç¿å¾çè«çç´°ç·»èªè¨ç¹å®èª²ç¨ä¾ç²å¾ã

##### **Stealing User Prompts from Mixture of Experts**
2410.22884v1 by Itay Yona, Ilia Shumailov, Jamie Hayes, Nicholas Carlini

Mixture-of-Experts (MoE) models improve the efficiency and scalability of
dense language models by routing each token to a small number of experts in
each layer. In this paper, we show how an adversary that can arrange for their
queries to appear in the same batch of examples as a victim's queries can
exploit Expert-Choice-Routing to fully disclose a victim's prompt. We
successfully demonstrate the effectiveness of this attack on a two-layer
Mixtral model, exploiting the tie-handling behavior of the torch.topk CUDA
implementation. Our results show that we can extract the entire prompt using
$O({VM}^2)$ queries (with vocabulary size $V$ and prompt length $M$) or 100
queries on average per token in the setting we consider. This is the first
attack to exploit architectural flaws for the purpose of extracting user
prompts, introducing a new class of LLM vulnerabilities.

æè¦ï¼æ··åä¸å®¶ (MoE) æ¨¡åééå°æ¯åç¬¦èè·¯ç±å°æ¯ä¸å±¤çå°æ¸å°å®¶ï¼é²èæåå¯éèªè¨æ¨¡åçæçåå¯æ´åæ§ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºä¸åå°æå¦ä½å®æä»åçæ¥è©¢åºç¾å¨èåå®³èæ¥è©¢ç¸åçç¯ä¾æ¹æ¬¡ä¸­ï¼å¯ä»¥å©ç¨å°å®¶é¸æè·¯ç±ä¾å®å¨æ­é²åå®³èçæç¤ºãæåæåå±ç¤ºäºéç¨®æ»æå¨éå±¤ Mixtral æ¨¡åä¸çæææ§ï¼å©ç¨äºç«ç¬ topk CUDA å¯¦ä½çå¹³æèçè¡çºãæåççµæé¡¯ç¤ºï¼æåå¯ä»¥ä½¿ç¨ $O({VM}^2)$ åæ¥è©¢ï¼è©å½éå¤§å°çº $V$ï¼æç¤ºé·åº¦çº $M$ï¼æå¨æåèæ®çè¨­å®ä¸­å¹³åæ¯åç¬¦è 100 åæ¥è©¢ä¾æåæ´åæç¤ºãéæ¯ç¬¬ä¸åå©ç¨æ¶æ§ç¼ºé·ä¾æåä½¿ç¨èæç¤ºçæ»æï¼å¼å¥äº LLM æ¼æ´çæ°é¡å¥ã

##### **Adaptive Paradigm Synergy: Can a Cross-Paradigm Objective Enhance Long-Tailed Learning?**
2410.22883v1 by Haowen Xiao, Guanghui Liu, Xinyi Gao, Yang Li, Fengmao Lv, Jielei Chu

Self-supervised learning (SSL) has achieved impressive results across several
computer vision tasks, even rivaling supervised methods. However, its
performance degrades on real-world datasets with long-tailed distributions due
to difficulties in capturing inherent class imbalances. Although supervised
long-tailed learning offers significant insights, the absence of labels in SSL
prevents direct transfer of these strategies.To bridge this gap, we introduce
Adaptive Paradigm Synergy (APS), a cross-paradigm objective that seeks to unify
the strengths of both paradigms. Our approach reexamines contrastive learning
from a spatial structure perspective, dynamically adjusting the uniformity of
latent space structure through adaptive temperature tuning. Furthermore, we
draw on a re-weighting strategy from supervised learning to compensate for the
shortcomings of temperature adjustment in explicit quantity
perception.Extensive experiments on commonly used long-tailed datasets
demonstrate that APS improves performance effectively and efficiently. Our
findings reveal the potential for deeper integration between supervised and
self-supervised learning, paving the way for robust models that handle
real-world class imbalance.

æè¦ï¼èªç£ç£å­¸ç¿ (SSL) å¨å¤é é»è¦è¦è¦ºä»»åä¸­çåå¾ä»¤äººå°è±¡æ·±å»çææï¼çè³åª²ç¾ç£ç£å¼æ¹æ³ãç¶èï¼ç±æ¼é£ä»¥ææå§å¨é¡å¥å¤±è¡¡ï¼å¶æè½æå¨å·æé·å°¾åä½ççå¯¦ä¸çè³æéä¸ä¸éãåç®¡ç£ç£å¼é·å°¾å­¸ç¿æä¾äºéè¦çè¦è§£ï¼ä½ SSL ä¸­æ¨ç±¤çç¼ºä¹é»ç¤äºéäºç­ç¥çç´æ¥è½ç§»ãçºäºå½è£éåå·®è·ï¼æåå¼å¥äºèªé©æç¯ä¾åå (APS)ï¼éæ¯ä¸åè·¨ç¯ä¾ç®æ¨ï¼æ¨å¨çµ±ä¸å©åç¯ä¾çåªé»ãæåçåæ³å¾ç©ºéçµæ§çè§åº¦éæ°å¯©è¦å°æ¯å­¸ç¿ï¼ééèªé©ææº«åº¦èª¿æ´åæèª¿æ´æ½å¨ç©ºéçµæ§çåå»æ§ãæ­¤å¤ï¼æååç¨äºç£ç£å¼å­¸ç¿ä¸­çéæ°å æ¬ç­ç¥ï¼ä»¥å½è£æº«åº¦èª¿æ´å¨æç¢ºæ¸éæç¥ä¸­çä¸è¶³ãå¨å¸¸ç¨çé·å°¾è³æéä¸é²è¡çå»£æ³å¯¦é©è­æï¼APS ææä¸é«æå°æ¹åäºæè½ãæåçç¼ç¾æ­ç¤ºäºç£ç£å¼å­¸ç¿åèªç£ç£å­¸ç¿ä¹éæ´æ·±å¥æ´åçæ½åï¼çºèççå¯¦ä¸çé¡å¥å¤±è¡¡çå¼·å¥æ¨¡åéªå¹³äºéè·¯ã

##### **SFA-UNet: More Attention to Multi-Scale Contrast and Contextual Information in Infrared Small Object Segmentation**
2410.22881v1 by Imad Ali Shah, Fahad Mumtaz Malik, Muhammad Waqas Ashraf

Computer vision researchers have extensively worked on fundamental infrared
visual recognition for the past few decades. Among various approaches, deep
learning has emerged as the most promising candidate. However, Infrared Small
Object Segmentation (ISOS) remains a major focus due to several challenges
including: 1) the lack of effective utilization of local contrast and global
contextual information; 2) the potential loss of small objects in deep models;
and 3) the struggling to capture fine-grained details and ignore noise. To
address these challenges, we propose a modified U-Net architecture, named
SFA-UNet, by combining Scharr Convolution (SC) and Fast Fourier Convolution
(FFC) in addition to vertical and horizontal Attention gates (AG) into UNet.
SFA-UNet utilizes double convolution layers with the addition of SC and FFC in
its encoder and decoder layers. SC helps to learn the foreground-to-background
contrast information whereas FFC provide multi-scale contextual information
while mitigating the small objects vanishing problem. Additionally, the
introduction of vertical AGs in encoder layers enhances the model's focus on
the targeted object by ignoring irrelevant regions. We evaluated the proposed
approach on publicly available, SIRST and IRSTD datasets, and achieved superior
performance by an average 0.75% with variance of 0.025 of all combined metrics
in multiple runs as compared to the existing state-of-the-art methods

æè¦ï¼é»è¦è¦è¦ºç ç©¶äººå¡å¨éå»å¹¾åå¹´ä¾å»£æ³ç ç©¶åºæ¬ç´å¤ç·è¦è¦ºè¾¨è­ãå¨åç¨®æ¹æ³ä¸­ï¼æ·±åº¦å­¸ç¿å·²æçºææå¸æçåé¸èãç¶èï¼ç´å¤ç·å°ç©ä»¶åå² (ISOS) ç±æ¼ä¸åå¹¾åææ°èä»ç¶æ¯ä¸»è¦éé»ï¼1) æªè½ææå©ç¨å±é¨å°æ¯åæ´é«èçµ¡è³è¨ï¼2) å°ç©ä»¶å¨æ·±åº¦æ¨¡åä¸­æ½å¨çéºå¤±ï¼3) é£ä»¥ææç´°å¾®ç´°ç¯ä¸¦å¿½ç¥éè¨ãçºäºæå°éäºææ°ï¼æåæåºä¸åæ¹è¯ç U-Net æ¶æ§ï¼ç¨±çº SFA-UNetï¼æ¹æ³æ¯å¨ UNet ä¸­çµå Scharr æ²ç© (SC) åå¿«éåç«èæ²ç© (FFC)ï¼ä»¥ååç´åæ°´å¹³æ³¨æåéé (AG)ãSFA-UNet å¨å¶ç·¨ç¢¼å¨åè§£ç¢¼å¨å±¤ä¸­ä½¿ç¨ééæ²ç©å±¤ï¼ä¸¦å å¥ SC å FFCãSC æå©æ¼å­¸ç¿åæ¯å°èæ¯çå°æ¯è³è¨ï¼è FFC åæä¾å¤å°ºåº¦èçµ¡è³è¨ï¼åææ¸è¼å°ç©ä»¶æ¶å¤±çåé¡ãæ­¤å¤ï¼å¨ç·¨ç¢¼å¨å±¤ä¸­å¼å¥åç´ AG å¯å¢å¼·æ¨¡åå°ç®æ¨ç©ä»¶çéæ³¨ï¼æ¹æ³æ¯å¿½ç¥ä¸ç¸éååãæåå¨å¬éç SIRST å IRSTD è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦å¨å¤æ¬¡å·è¡ä¸­èç¾æçæåé²æ¹æ³ç¸æ¯ï¼ä»¥ææçµåææ¨çå¹³å 0.75% å 0.025 çè®ç°æ¸ï¼éå°äºåªç°çæè½

##### **Eliciting Critical Reasoning in Retrieval-Augmented Language Models via Contrastive Explanations**
2410.22874v1 by Leonardo Ranaldi, Marco Valentino, AndrÃ¨ Freitas

Retrieval-augmented generation (RAG) has emerged as a critical mechanism in
contemporary NLP to support Large Language Models(LLMs) in systematically
accessing richer factual context. However, the integration of RAG mechanisms
brings its inherent challenges, as LLMs need to deal with potentially noisy
contexts. Recent studies have shown that LLMs still struggle to critically
analyse RAG-based in-context information, a limitation that may lead to
incorrect inferences and hallucinations. In this paper, we investigate how to
elicit critical reasoning in RAG via contrastive explanations. In particular,
we propose Contrastive-RAG (C-RAG), a framework that (i) retrieves relevant
documents given a query, (ii) selects and exemplifies relevant passages, and
(iii) generates explanations that explicitly contrast the relevance of the
passages to (iv) support the final answer. We show the impact of C-RAG building
contrastive reasoning demonstrations from LLMs to instruct smaller models for
retrieval-augmented tasks. Extensive experiments demonstrate that C-RAG
improves state-of-the-art RAG models while (a) requiring significantly fewer
prompts and demonstrations and (b) being robust to perturbations in the
retrieved documents.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) å·²æçºç¶ä»£èªç¶èªè¨èçä¸­çä¸é ééµæ©å¶ï¼ç¨æ¼æ¯æ´å¤§åèªè¨æ¨¡å (LLM) ç³»çµ±æ§å°å­åæ´è±å¯çäºå¯¦èæ¯ãä½æ¯ï¼RAG æ©å¶çæ´åå¸¶ä¾å¶åºæçææ°ï¼å çº LLM éè¦èçæ½å¨çéè¨èæ¯ãæè¿çç ç©¶é¡¯ç¤ºï¼LLM ä»é£ä»¥æ¹å¤æ§å°åæåºæ¼ RAG çæå¢è³è¨ï¼éé éå¶å¯è½æå°è´ä¸æ­£ç¢ºçæ¨è«åå¹»è¦ºãå¨æ¬æä¸­ï¼æåæ¢è¨å¦ä½ééå°æ¯è§£éå¨ RAG ä¸­å¼ç¼æ¹å¤æ§æ¨çãå·é«èè¨ï¼æåæåºå°æ¯å¼ RAG (C-RAG)ï¼éæ¯ä¸åæ¶æ§ï¼ç¨æ¼ (i) æ ¹ææ¥è©¢æª¢ç´¢ç¸éæä»¶ï¼(ii) é¸æä¸¦èä¾èªªæç¸éæ®µè½ï¼ä»¥å (iii) ç¢çæç¢ºå°æ¯æ®µè½ç¸éæ§çè§£éï¼ä»¥ (iv) æ¯æ´æçµç­æ¡ãæåå±ç¤ºäº C-RAG å»ºæ§å°æ¯å¼æ¨çç¤ºç¯çå½±é¿ï¼å¾ LLM æå°è¼å°çæ¨¡åé²è¡æª¢ç´¢å¢å¼·ä»»åãå»£æ³çå¯¦é©è­æï¼C-RAG æ¹é²äºæåé²ç RAG æ¨¡åï¼åæ (a) éè¦é¡¯èæ´å°çæç¤ºåç¤ºç¯ï¼ä»¥å (b) å°æª¢ç´¢æä»¶ä¸­æ¾åå·æç©©å¥æ§ã

##### **Conditioned quantum-assisted deep generative surrogate for particle-calorimeter interactions**
2410.22870v1 by J. Quetzalcoatl Toledo-Marin, Sebastian Gonzalez, Hao Jia, Ian Lu, Deniz Sogutlu, Abhishek Abhishek, Colin Gay, Eric Paquet, Roger Melko, Geoffrey C. Fox, Maximilian Swiatlowski, Wojciech Fedorko

Particle collisions at accelerators such as the Large Hadron Collider,
recorded and analyzed by experiments such as ATLAS and CMS, enable exquisite
measurements of the Standard Model and searches for new phenomena. Simulations
of collision events at these detectors have played a pivotal role in shaping
the design of future experiments and analyzing ongoing ones. However, the quest
for accuracy in Large Hadron Collider (LHC) collisions comes at an imposing
computational cost, with projections estimating the need for millions of
CPU-years annually during the High Luminosity LHC (HL-LHC) run
\cite{collaboration2022atlas}. Simulating a single LHC event with
\textsc{Geant4} currently devours around 1000 CPU seconds, with simulations of
the calorimeter subdetectors in particular imposing substantial computational
demands \cite{rousseau2023experimental}. To address this challenge, we propose
a conditioned quantum-assisted deep generative model. Our model integrates a
conditioned variational autoencoder (VAE) on the exterior with a conditioned
Restricted Boltzmann Machine (RBM) in the latent space, providing enhanced
expressiveness compared to conventional VAEs. The RBM nodes and connections are
meticulously engineered to enable the use of qubits and couplers on D-Wave's
Pegasus-structured \textit{Advantage} quantum annealer (QA) for sampling. We
introduce a novel method for conditioning the quantum-assisted RBM using
\textit{flux biases}. We further propose a novel adaptive mapping to estimate
the effective inverse temperature in quantum annealers. The effectiveness of
our framework is illustrated using Dataset 2 of the CaloChallenge
\cite{calochallenge}.

æè¦ï¼å¨å¤§åå¼·å­å°ææ©ç­å éå¨ä¸­çç²å­ç¢°æï¼ç± ATLAS å CMS ç­å¯¦é©è¨éååæï¼è½ç²¾ç¢ºæ¸¬éæ¨æºæ¨¡åä¸¦æå°æ°ç¾è±¡ãéäºæ¢æ¸¬å¨ä¸­ç¢°æäºä»¶çæ¨¡æ¬å¨å¡é æªä¾å¯¦é©çè¨­è¨ååææ­£å¨é²è¡çå¯¦é©ä¸­æ®æ¼äºééµè§è²ãç¶èï¼å¨å¤§åå¼·å­å°ææ© (LHC) ç¢°æä¸­è¿½æ±æºç¢ºæ§æå¸¶ä¾é¾å¤§çéç®ææ¬ï¼é è¨å¨é«äº®åº¦ LHC (HL-LHC) éè¡æéæ¯å¹´éè¦æ¸ç¾è¬å CPU å¹´\cite{collaboration2022atlas}ãç®åï¼ä½¿ç¨\textsc{Geant4}æ¨¡æ¬å®å LHC äºä»¶å¤§ç´éè¦ 1000 å CPU ç§ï¼ç¹å¥æ¯éè½å¨æ¬¡æ¢æ¸¬å¨çæ¨¡æ¬æå¸¶ä¾å¤§éçéç®éæ±\cite{rousseau2023experimental}ãçºäºæå°éåææ°ï¼æåæåºäºä¸åæ¢ä»¶éå­è¼å©æ·±åº¦çææ¨¡åãæåçæ¨¡åæ´åäºä¸åæ¢ä»¶è®ç°èªåç·¨ç¢¼å¨ (VAE) å°å¤é¨ï¼ä¸¦å¨æ½å¨ç©ºéä¸­å å¥äºä¸åæ¢ä»¶éå¶ç»ç¾è²æ¼æ© (RBM)ï¼èå³çµ±ç VAE ç¸æ¯ï¼æä¾äºå¢å¼·çè¡¨éè½åãRBM ç¯é»åé£æ¥ç¶éç²¾å¿è¨­è¨ï¼å¯ä»¥å¨ D-Wave çé£é¦¬çµæ§\textit{Advantage}éå­éç«å¨ (QA) ä¸ä½¿ç¨éå­ä½ååè¦åå¨é²è¡åæ¨£ãæåå¼å¥äºä¸ç¨®ä½¿ç¨\textit{ç£éåå£}å°éå­è¼å© RBM é²è¡æ¢ä»¶åçåµæ°æ¹æ³ãæåé²ä¸æ­¥æåºäºä¸ç¨®æ°çèªé©æå°æï¼ä»¥ä¼°è¨éå­éç«å¨ä¸­çææéæº«åº¦ãæåä½¿ç¨ CaloChallenge\cite{calochallenge} çè³æé 2 ä¾èªªææåæ¶æ§çæææ§ã

##### **Danoliteracy of Generative, Large Language Models**
2410.22839v1 by SÃ¸ren Vejlgaard Holm, Lars Kai Hansen, Martin Carsten Nielsen

The language technology moonshot moment of Generative, Large Language Models
(GLLMs) was not limited to English: These models brought a surge of
technological applications, investments and hype to low-resource languages as
well. However, the capabilities of these models in languages such as Danish
were until recently difficult to verify beyond qualitative demonstrations due
to a lack of applicable evaluation corpora. We present a GLLM benchmark to
evaluate Danoliteracy, a measure of Danish language and cultural competency,
across eight diverse scenarios such Danish citizenship tests and abstractive
social media question answering. This limited-size benchmark is found to
produce a robust ranking that correlates to human feedback at $\rho \sim 0.8$
with GPT-4 and Claude Opus models achieving the highest rankings. Analyzing
these model results across scenarios, we find one strong underlying factor
explaining $95\%$ of scenario performance variance for GLLMs in Danish,
suggesting a $g$ factor of model consistency in language adaption.

æè¦ï¼çæå¼å¤§åè¯­è¨æ¨¡å (GLLM) çè¯­è¨ææ¯é£è·æ¶å»ä¸ä»éäºè±è¯­ï¼è¿äºæ¨¡åä¸ºèµæºå®ä¹çè¯­è¨å¸¦æ¥äºææ¯åºç¨ãæèµåçä½ç­æ½®ãç¶èï¼ç±äºç¼ºä¹éç¨çè¯ä¼°è¯­æåºï¼ç´å°æè¿ï¼è¿äºæ¨¡åå¨ä¸¹éº¦è¯­ç­è¯­è¨ä¸­çè½åæé¾ä»¥éè¿å®æ§æ¼ç¤ºæ¥éªè¯ãæä»¬æåºäºä¸ä¸ª GLLM åºåæ¥è¯ä¼°ä¸¹éº¦è¯­ç´ å»ï¼å³ä¸¹éº¦è¯­è¨åæåè½åçè¡¡éæ åï¼æ¶µçå«ç§ä¸åçåºæ¯ï¼å¦ä¸¹éº¦å¬æ°èº«ä»½æµè¯åæ½è±¡ç¤¾äº¤åªä½é®ç­ãåç°è¿ä¸ªå°è§æ¨¡åºåäº§çäºç¨³å¥çæåï¼ä¸äººç±»åé¦ç¸å³ï¼å¶ä¸­ GPT-4 å Claude Opus æ¨¡åè·å¾äºæé«æåãéè¿åæè¿äºæ¨¡åå¨ä¸ååºæ¯ä¸­çç»æï¼æä»¬åç°äºä¸ä¸ªå¼ºæåçæ½å¨å ç´ ï¼è§£éäºä¸¹éº¦è¯­ GLLM 95% çåºæ¯æ§è½å·®å¼ï¼è¡¨ææ¨¡åä¸è´æ§å¨è¯­è¨éåºä¸­ç g å å­ã

##### **HijackRAG: Hijacking Attacks against Retrieval-Augmented Large Language Models**
2410.22832v1 by Yucheng Zhang, Qinfeng Li, Tianyu Du, Xuhong Zhang, Xinkui Zhao, Zhengwen Feng, Jianwei Yin

Retrieval-Augmented Generation (RAG) systems enhance large language models
(LLMs) by integrating external knowledge, making them adaptable and
cost-effective for various applications. However, the growing reliance on these
systems also introduces potential security risks. In this work, we reveal a
novel vulnerability, the retrieval prompt hijack attack (HijackRAG), which
enables attackers to manipulate the retrieval mechanisms of RAG systems by
injecting malicious texts into the knowledge database. When the RAG system
encounters target questions, it generates the attacker's pre-determined answers
instead of the correct ones, undermining the integrity and trustworthiness of
the system. We formalize HijackRAG as an optimization problem and propose both
black-box and white-box attack strategies tailored to different levels of the
attacker's knowledge. Extensive experiments on multiple benchmark datasets show
that HijackRAG consistently achieves high attack success rates, outperforming
existing baseline attacks. Furthermore, we demonstrate that the attack is
transferable across different retriever models, underscoring the widespread
risk it poses to RAG systems. Lastly, our exploration of various defense
mechanisms reveals that they are insufficient to counter HijackRAG, emphasizing
the urgent need for more robust security measures to protect RAG systems in
real-world deployments.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±ééæ´åå¤é¨ç¥è­ï¼å¢å¼·å¤§åèªè¨æ¨¡å (LLM)ï¼è®å¶é©æåç¨®æç¨ï¼ä¸å·æææ¬æçãç¶èï¼è¶ä¾è¶ä¾è³´éäºç³»çµ±ä¹å¼å¥äºæ½å¨çå®å¨é¢¨éªãå¨éé å·¥ä½ä¸­ï¼æåæ­é²äºä¸åæ°çæ¼æ´ï¼ç¨±çºæª¢ç´¢æç¤ºå«ææ»æ (HijackRAG)ï¼è®æ»æèè½å¤ ééå°æ¡ææå­æ³¨å¥ç¥è­åº«ä¸­ï¼ä¾æç¸± RAG ç³»çµ±çæª¢ç´¢æ©å¶ãç¶ RAG ç³»çµ±éå°ç®æ¨åé¡æï¼å®æç¢çæ»æèé åè¨­å®å¥½çç­æ¡ï¼èä¸æ¯æ­£ç¢ºçç­æ¡ï¼ç ´å£äºç³»çµ±çå®æ´æ§åå¯ä¿¡åº¦ãæåå° HijackRAG æ­£å¼åçºä¸åæä½³ååé¡ï¼ä¸¦éå°æ»æèç¥è­çä¸åå±¤ç´ï¼æåºé»çåç½çæ»æç­ç¥ãå¨å¤ååºæºè³æéä¸é²è¡çå»£æ³å¯¦é©é¡¯ç¤ºï¼HijackRAG æçºéæé«æ»ææåçï¼åªæ¼ç¾æçåºæºæ»æãæ­¤å¤ï¼æåè­æäºéç¨®æ»æå¯ä»¥è½ç§»å°ä¸åçæª¢ç´¢å¨æ¨¡åï¼å¼·èª¿äºå®å° RAG ç³»çµ±æ§æçå»£æ³é¢¨éªãæå¾ï¼æåæ¢ç´¢äºåç¨®é²ç¦¦æ©å¶ï¼ç¼ç¾å®åä¸è¶³ä»¥å°æ HijackRAGï¼å¼·èª¿äºå¨å¯¦éé¨ç½²ä¸­ä¿è­· RAG ç³»çµ±æï¼è¿«åéè¦æ´å¼·å¤§çå®å¨æªæ½ã

##### **How Well Do Large Language Models Disambiguate Swedish Words?**
2410.22827v1 by Richard Johansson

We evaluate a battery of recent large language models on two benchmarks for
word sense disambiguation in Swedish. At present, all current models are less
accurate than the best supervised disambiguators in cases where a training set
is available, but most models outperform graph-based unsupervised systems.
Different prompting approaches are compared, with a focus on how to express the
set of possible senses in a given context. The best accuracies are achieved
when human-written definitions of the senses are included in the prompts.

æè¦ï¼æåéå°å©åçå¸èªè©å½æç¾©æ¶æ­§åºæºï¼è©ä¼°ä¸ç³»åè¿æçå¤§åèªè¨æ¨¡åãç®åï¼å¨æè¨ç·´éå¯ç¨çææ³ä¸ï¼ææç¾ææ¨¡åçæºç¢ºåº¦é½ä½æ¼æä½³ç£ç£å¼æ¶æ­§å¨ï¼ä½å¤§å¤æ¸æ¨¡åçè¡¨ç¾é½åªæ¼åºæ¼åå½¢çéç£ç£å¼ç³»çµ±ãæ¯è¼äºä¸åçæç¤ºæ¹æ³ï¼éé»å¨æ¼å¦ä½å¨ç¹å®èçµ¡ä¸­è¡¨éå¯è½çæç¾©éåãç¶æç¤ºä¸­åå«äººé¡æ°å¯«çæç¾©å®ç¾©æï¼å¯éå°æä½³æºç¢ºåº¦ã

##### **EvoCodeBench: An Evolving Code Generation Benchmark with Domain-Specific Evaluations**
2410.22821v1 by Jia Li, Ge Li, Xuanming Zhang, Yunfei Zhao, Yihong Dong, Zhi Jin, Binhua Li, Fei Huang, Yongbin Li

How to evaluate Large Language Models (LLMs) in code generation remains an
open question. Existing benchmarks have two limitations - data leakage and lack
of domain-specific evaluation. The former hurts the fairness of benchmarks, and
the latter hinders practitioners from selecting superior LLMs for specific
programming domains. To address these two limitations, we propose a new
benchmark - EvoCodeBench, which has the following advances: (1) Evolving data.
EvoCodeBench will be dynamically updated every period (e.g., 6 months) to avoid
data leakage. This paper releases the first version - EvoCodeBench-2403,
containing 275 samples from 25 repositories. (2) A domain taxonomy and domain
labels. Based on the statistics of open-source communities, we design a
programming domain taxonomy consisting of 10 popular domains. Based on the
taxonomy, we annotate each sample in EvoCodeBench with a domain label. (3)
Domain-specific evaluations. Besides the Pass@k, we compute the Domain-Specific
Improvement (DSI) and define LLMs' comfort and strange domains. These
evaluations help practitioners select superior LLMs in specific domains and
discover the shortcomings of existing LLMs. We evaluate 8 popular LLMs (e.g.,
gpt-4, DeepSeek Coder) on EvoCodeBench and summarize some insights.
EvoCodeBench reveals the actual abilities of these LLMs in real-world
repositories. For example, the highest Pass@1 of gpt-4 on EvoCodeBench-2403 is
only 20.74%. Besides, we evaluate LLMs in different domains and discover their
comfort and strange domains. For example, gpt-4 performs best in most domains
but falls behind others in the Internet domain. StarCoder 2-15B unexpectedly
performs well in the Database domain and even outperforms 33B LLMs.
EvoCodeBench has been released.

æè¦ï¼<paragraph>å¦ä½è©ä¼°å¤§åèªè¨æ¨¡å (LLM) å¨ç¨å¼ç¢¼çæä¸­çè¡¨ç¾ä»ç¶æ¯ä¸åéæ¾æ§çåé¡ãç¾æçåºæºæå©åéå¶ - è³æå¤æ´©åç¼ºä¹ç¹å®é åçè©ä¼°ãåèæå®³äºåºæºçå¬å¹³æ§ï¼èå¾èé»ç¤äºå¾æ¥­èçºç¹å®ç¨å¼è¨­è¨é åé¸æåªè¶ç LLMãçºäºè§£æ±ºéå©åéå¶ï¼æåæåºäºä¸åæ°çåºæº - EvoCodeBenchï¼å®å·æä»¥ä¸é²å±ï¼(1) æ¼é²è³æãEvoCodeBench å°æ¯éä¸æ®µæéï¼ä¾å¦ 6 åæï¼åææ´æ°ï¼ä»¥é¿åè³æå¤æ´©ãæ¬æç¼å¸äºç¬¬ä¸åçæ¬ - EvoCodeBench-2403ï¼å¶ä¸­åå«ä¾èª 25 åå²å­åº«ç 275 åç¯ä¾ã(2) é ååé¡æ³åé åæ¨ç±¤ãæ ¹æéæºç¤¾ç¾¤ççµ±è¨è³æï¼æåè¨­è¨äºä¸ååå« 10 åç±éé åçç¨å¼è¨­è¨é ååé¡æ³ãæ ¹æåé¡æ³ï¼æåä½¿ç¨é åæ¨ç±¤è¨»è§£ EvoCodeBench ä¸­çæ¯åç¯ä¾ã(3) é åç¹å®çè©ä¼°ãé¤äº Pass@kï¼æåè¨ç®äºç¹å®é åçæ¹é² (DSI) ä¸¦å®ç¾©äº LLM çèé©é ååéçé åãéäºè©ä¼°æå©æ¼å¾æ¥­èå¨ç¹å®é åä¸­é¸æåªè¶ç LLMï¼ä¸¦ç¼ç¾ç¾æ LLM çç¼ºé»ãæåå¨ EvoCodeBench ä¸è©ä¼°äº 8 åæµè¡ç LLMï¼ä¾å¦ gpt-4ãDeepSeek Coderï¼ï¼ä¸¦ç¸½çµäºä¸äºè¦è§£ãEvoCodeBench æ­ç¤ºäºéäº LLM å¨çå¯¦ä¸çå²å­åº«ä¸­çå¯¦éè½åãä¾å¦ï¼gpt-4 å¨ EvoCodeBench-2403 ä¸çæé« Pass@1 åçº 20.74%ãæ­¤å¤ï¼æåè©ä¼°äºä¸åé åä¸­ç LLMï¼ä¸¦ç¼ç¾äºå®åçèé©é ååéçé åãä¾å¦ï¼gpt-4 å¨å¤§å¤æ¸é åä¸­è¡¨ç¾æä½³ï¼ä½å¨ç¶²éç¶²è·¯é åè½å¾æ¼å¶ä»é åãStarCoder 2-15B å¨è³æåº«é åè¡¨ç¾åºä¹ææå°å¥½ï¼çè³åªæ¼ 33B LLMãEvoCodeBench å·²ç¼å¸ã</paragraph>

##### **Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients**
2410.22815v1 by Jabin Koo, Minwoo Jang, Jungseul Ok

Federated fine-tuning for Large Language Models (LLMs) has recently gained
attention due to the heavy communication overhead of transmitting large model
updates. Low Rank Adaptation (LoRA) has been proposed as a solution, yet its
application in federated learning is complicated by discordance in aggregation.
Existing methods addressing this discordance often suffer from performance
degradation at low ranks in heterogeneous data settings. In response, we
introduce LoRA-A2 (Low Rank Adaptation with Alternating freeze and Adaptive
rank selection), which demonstrates robustness in challenging settings with low
ranks and high data heterogeneity. Our experimental findings reveal that
LoRA-A2 maintains performance even under extreme heterogeneity and low rank
conditions, achieving up to a 99.8% reduction in uploaded parameters compared
to full fine-tuning without compromising performance. This adaptive mechanism
boosts robustness and communication efficiency in federated fine-tuning,
enabling the practical deployment of LLMs in resource-constrained environments.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çè¯é¦å¾®èª¿æè¿å å³è¼¸å¤§åæ¨¡åæ´æ°çé¾å¤§éè¨éé·èåå°éæ³¨ãä½ç§©é©æ (LoRA) å·²è¢«æåºä½çºä¸ç¨®è§£æ±ºæ¹æ¡ï¼ä½å¶å¨è¯é¦å­¸ç¿ä¸­çæç¨å èåä¸­çä¸ä¸è´èè®å¾è¤éãè§£æ±ºéç¨®ä¸ä¸è´çç¾ææ¹æ³éå¸¸å¨ç°è³ªæ¸æè¨­ç½®çä½ç§©ä¸­æåºç¾æè½ä¸éçåé¡ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº LoRA-A2ï¼äº¤æ¿åçµåèªé©æç§©é¸æçä½ç§©é©æï¼ï¼å®å¨ä½ç§©åé«æ¸æç°è³ªæ§çææ°æ§è¨­ç½®ä¸­å±ç¾åºç©©å¥æ§ãæåçå¯¦é©çµæè¡¨æï¼å³ä½¿å¨æ¥µç«¯çç°è³ªæ§åä½ç§©æ¢ä»¶ä¸ï¼LoRA-A2 ä»è½ç¶­ææè½ï¼èå®å¨å¾®èª¿ç¸æ¯ï¼ä¸å³åæ¸æ¸å°äº 99.8%ï¼èä¸ææå®³æè½ãéç¨®èªé©ææ©å¶æåäºè¯é¦å¾®èª¿ä¸­çç©©å¥æ§åéè¨æçï¼ä½¿ LLM è½å¨è³æºåéçç°å¢ä¸­å¯¦éé¨ç½²ã

##### **Universality of the $Ï^2/6$ Pathway in Avoiding Model Collapse**
2410.22812v1 by Apratim Dey, David Donoho

Researchers in empirical machine learning recently spotlighted their fears of
so-called Model Collapse. They imagined a discard workflow, where an initial
generative model is trained with real data, after which the real data are
discarded, and subsequently, the model generates synthetic data on which a new
model is trained. They came to the conclusion that models degenerate as
model-fitting generations proceed. However, other researchers considered an
augment workflow, where the original real data continue to be used in each
generation of training, augmented by synthetic data from models fit in all
earlier generations. Empirical results on canonical datasets and learning
procedures confirmed the occurrence of model collapse under the discard
workflow and avoidance of model collapse under the augment workflow. Under the
augment workflow, theoretical evidence also confirmed avoidance in particular
instances; specifically, Gerstgrasser et al. (2024) found that for classical
Linear Regression, test risk at any later generation is bounded by a moderate
multiple, viz. pi-squared-over-6 of the test risk of training with the original
real data alone. Some commentators questioned the generality of theoretical
conclusions based on the generative model assumed in Gerstgrasser et al.
(2024): could similar conclusions be reached for other task/model pairings? In
this work, we demonstrate the universality of the pi-squared-over-6 augment
risk bound across a large family of canonical statistical models, offering key
insights into exactly why collapse happens under the discard workflow and is
avoided under the augment workflow. In the process, we provide a framework that
is able to accommodate a large variety of workflows (beyond discard and
augment), thereby enabling an experimenter to judge the comparative merits of
multiple different workflows by simulating a simple Gaussian process.

æè¦ï¼<paragraph>ç¶é©æ©å¨å­¸ç¿çç ç©¶äººå¡æè¿å¼·èª¿äºä»åå°æè¬æ¨¡åå´©æ½°çææãä»åæ³åä¸åä¸æ£å·¥ä½æµç¨ï¼å¶ä¸­ä¸ååå§çææ¨¡åä½¿ç¨çå¯¦è³æè¨ç·´ï¼ä¹å¾ä¸æ£çå¯¦è³æï¼é¨å¾ï¼æ¨¡åæçæåæè³æï¼ä¸¦å¨åæè³æä¸è¨ç·´ä¸åæ°æ¨¡åãä»åå¾åºççµè«æ¯ï¼é¨èæ¨¡åæ¬åä¸ä»£çé²è¡ï¼æ¨¡åæéåãç¶èï¼å¶ä»ç ç©¶äººå¡èæ®äºä¸åæ´åå·¥ä½æµç¨ï¼å¶ä¸­åå§çå¯¦è³æææçºç¨æ¼æ¯ä¸ä»£è¨ç·´ï¼ä¸¦æ´åä¾èªææååä¸ä»£ä¸­æ¬åæ¨¡åçåæè³æãæ¨æºè³æéåå­¸ç¿ç¨åºçç¶é©çµæè­å¯¦äºå¨ä¸æ£å·¥ä½æµç¨ä¸æç¼çæ¨¡åå´©æ½°ï¼èå¨æ´åå·¥ä½æµç¨ä¸åé¿åäºæ¨¡åå´©æ½°ãå¨æ´åå·¥ä½æµç¨ä¸ï¼çè«è­æä¹è­å¯¦äºå¨ç¹å®ææ³ä¸é¿åäºæ¨¡åå´©æ½°ï¼å·é«ä¾èªªï¼Gerstgrasser ç­äºº (2024) ç¼ç¾ï¼å°æ¼ç¶å¸ç·æ§è¿´æ­¸ï¼ä»»ä½å¾çºä¸ä»£çæ¸¬è©¦é¢¨éªé½åå°é©åº¦åæ¸çéå¶ï¼å³åä½¿ç¨åå§çå¯¦è³æè¨ç·´çæ¸¬è©¦é¢¨éªç pi å¹³æ¹é¤ä»¥ 6ãä¸äºè©è«èè³ªçäº Gerstgrasser ç­äºº (2024) ä¸­åè¨­ççææ¨¡åæä¾æççè«çµè«çä¸è¬æ§ï¼æ¯å¦å¯ä»¥å°å¶ä»ä»»å/æ¨¡åéå°å¾åºé¡ä¼¼ççµè«ï¼å¨éé å·¥ä½ä¸­ï¼æåè­æäº pi å¹³æ¹é¤ä»¥ 6 æ´åé¢¨éªçéå¨è¨±å¤æ¨æºçµ±è¨æ¨¡åçå¤§å®¶æä¸­å·ææ®éæ§ï¼æä¾äºééµè¦è§£ï¼èªªæäºçºä»éº¼å´©æ½°æå¨ä¸æ£å·¥ä½æµç¨ä¸ç¼çï¼èå¨æ´åå·¥ä½æµç¨ä¸åå¯ä»¥é¿åãå¨æ­¤éç¨ä¸­ï¼æåæä¾äºä¸åæ¡æ¶ï¼è½å¤ å®¹ç´åç¨®å·¥ä½æµç¨ï¼ä¸åªæ¯ä¸æ£åæ´åï¼ï¼å¾èä½¿å¯¦é©èè½å¤ ééæ¨¡æ¬ä¸åç°¡å®çé«æ¯éç¨ä¾å¤æ·å¤åä¸åå·¥ä½æµç¨çæ¯è¼åªç¼ºé»ã</paragraph>

##### **Causality-Enhanced Behavior Sequence Modeling in LLMs for Personalized Recommendation**
2410.22809v1 by Yang Zhang, Juntao You, Yimeng Bai, Jizhi Zhang, Keqin Bao, Wenjie Wang, Tat-Seng Chua

Recent advancements in recommender systems have focused on leveraging Large
Language Models (LLMs) to improve user preference modeling, yielding promising
outcomes. However, current LLM-based approaches struggle to fully leverage user
behavior sequences, resulting in suboptimal preference modeling for
personalized recommendations. In this study, we propose a novel Counterfactual
Fine-Tuning (CFT) method to address this issue by explicitly emphasizing the
role of behavior sequences when generating recommendations. Specifically, we
employ counterfactual reasoning to identify the causal effects of behavior
sequences on model output and introduce a task that directly fits the
ground-truth labels based on these effects, achieving the goal of explicit
emphasis. Additionally, we develop a token-level weighting mechanism to adjust
the emphasis strength for different item tokens, reflecting the diminishing
influence of behavior sequences from earlier to later tokens during predicting
an item. Extensive experiments on real-world datasets demonstrate that CFT
effectively improves behavior sequence modeling. Our codes are available at
https://github.com/itsmeyjt/CFT.

æè¦ï¼æ¨è¦ç³»çµ±çææ°é²å±éä¸­æ¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾æ¹åä½¿ç¨èåå¥½å»ºæ¨¡ï¼ç¢çæåæ¯çææãç¶èï¼ç¾æçåºæ¼ LLM çæ¹æ³é£ä»¥ååå©ç¨ä½¿ç¨èè¡çºåºåï¼å°è´åäººåæ¨è¦çåå¥½å»ºæ¨¡æ¬¡åªãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®åµæ°çåäºå¯¦å¾®èª¿ (CFT) æ¹æ³ä¾è§£æ±ºéååé¡ï¼æ¹æ³æ¯æç¢ºå¼·èª¿è¡çºåºåå¨ç¢çæ¨è¦æçå½±é¿ãå·é«ä¾èªªï¼æåæ¡ç¨åäºå¯¦æ¨çä¾è­å¥è¡çºåºåå°æ¨¡åè¼¸åºçå æéä¿ï¼ä¸¦å¼å¥ä¸åä»»åï¼æ ¹æéäºå½±é¿ç´æ¥ç¬¦åçå¯¦æ¨ç±¤ï¼éå°æç¢ºå¼·èª¿çç®æ¨ãæ­¤å¤ï¼æåéç¼äºä¸åä»¤çç´å¥çå æ¬æ©å¶ä¾èª¿æ´ä¸åé ç®ä»¤ççå¼·èª¿å¼·åº¦ï¼åæ åºè¡çºåºåå¨é æ¸¬é ç®æå¾è¼æ©çä»¤çå°è¼æçä»¤ççå½±é¿åéæ¸ãå¨çå¯¦ä¸çè³æéä¸çå¤§éå¯¦é©è¡¨æï¼CFT ææå°æ¹åäºè¡çºåºåå»ºæ¨¡ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/itsmeyjt/CFT ç²å¾ã

##### **Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation**
2410.22790v1 by Chengkai Huang, Shoujin Wang, Xianzhi Wang, Lina Yao

Sequential recommender systems (SRSs) aim to predict the subsequent items
which may interest users via comprehensively modeling users' complex preference
embedded in the sequence of user-item interactions. However, most of existing
SRSs often model users' single low-level preference based on item ID
information while ignoring the high-level preference revealed by item attribute
information, such as item category. Furthermore, they often utilize limited
sequence context information to predict the next item while overlooking richer
inter-item semantic relations. To this end, in this paper, we proposed a novel
hierarchical preference modeling framework to substantially model the complex
low- and high-level preference dynamics for accurate sequential recommendation.
Specifically, in the framework, a novel dual-transformer module and a novel
dual contrastive learning scheme have been designed to discriminatively learn
users' low- and high-level preference and to effectively enhance both low- and
high-level preference learning respectively. In addition, a novel
semantics-enhanced context embedding module has been devised to generate more
informative context embedding for further improving the recommendation
performance. Extensive experiments on six real-world datasets have demonstrated
both the superiority of our proposed method over the state-of-the-art ones and
the rationality of our design.

æè¦ï¼åºåæ¨è¦ç³»çµ± (SRS) çç®çæ¯é æ¸¬å¾çºé ç®ï¼éäºé ç®å¯è½ééå¨é¢å»ºæ¨¡åµå¥å¨ä½¿ç¨èèé ç®äºååºåä¸­çä½¿ç¨èçè¤éåå¥½ä¾å¼èµ·ä½¿ç¨èçèè¶£ãç¶èï¼ç¾æç SRS å¤§å¤å¸¸æ ¹æé ç® ID è³è¨ä¾å»ºæ¨¡ä½¿ç¨èçå®ä¸ä½å±¤ç´åå¥½ï¼åæå¿½ç¥é ç®å±¬æ§è³è¨ï¼ä¾å¦é ç®é¡å¥ï¼ææ­ç¤ºçé«å±¤ç´åå¥½ãæ­¤å¤ï¼ä»åéå¸¸å©ç¨æéçåºåèçµ¡è³è¨ä¾é æ¸¬ä¸ä¸åé ç®ï¼åæå¿½ç¥æ´è±å¯çé ç®éèªç¾©éä¿ãçºæ­¤ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çåå±¤åå¥½å»ºæ¨¡æ¶æ§ï¼ä»¥å¯¦è³ªæ§å°å»ºæ¨¡è¤éçä½å±¤ç´åé«å±¤ç´åå¥½åæï¼ä»¥é²è¡æºç¢ºçåºåæ¨è¦ãå·é«ä¾èªªï¼å¨è©²æ¶æ§ä¸­ï¼è¨­è¨äºä¸åæ°ç©çééTransformeræ¨¡çµåä¸åæ°ç©çééå°æ¯å­¸ç¿æ¹æ¡ï¼åå¥ç¨æ¼åå¥æ§å°å­¸ç¿ä½¿ç¨èçä½å±¤ç´åé«å±¤ç´åå¥½ï¼ä¸¦ææå°å¢å¼·ä½å±¤ç´åé«å±¤ç´åå¥½å­¸ç¿ãæ­¤å¤ï¼éè¨­è¨äºä¸åæ°ç©çèªç¾©å¢å¼·èçµ¡åµå¥æ¨¡çµï¼ä»¥ç¢çæ´å¤è³è¨æ§çèçµ¡åµå¥ï¼é²ä¸æ­¥æ¹åæ¨è¦æè½ãå¨å­åçå¯¦ä¸çè³æéä¸é²è¡çå¤§éå¯¦é©è­æäºæåæåºçæ¹æ³åªæ¼ç¾ææè¡ï¼ä»¥åæåè¨­è¨çåçæ§ã

##### **MALoRA: Mixture of Asymmetric Low-Rank Adaptation for Enhanced Multi-Task Learning**
2410.22782v1 by Xujia Wang, Haiyan Zhao, Shuo Wang, Hanqing Wang, Zhiyuan Liu

Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA have significantly
improved the adaptation of LLMs to downstream tasks in a resource-efficient
manner. However, in multi-task scenarios, challenges such as training imbalance
and the seesaw effect frequently emerge. Mixture-of-LoRA (MoLoRA), which
combines LoRA with sparse Mixture-of-Experts, mitigates some of these issues by
promoting task-specific learning across experts. Despite this, MoLoRA remains
inefficient in terms of training speed, parameter utilization, and overall
multi-task performance. In this paper, we propose Mixture of Asymmetric
Low-Rank Adaptaion (MALoRA), a flexible fine-tuning framework that leverages
asymmetric optimization across LoRA experts. MALoRA reduces the number of
trainable parameters by 30% to 48%, increases training speed by 1.2x, and
matches the computational efficiency of single-task LoRA models. Additionally,
MALoRA addresses overfitting issues commonly seen in high-rank configurations,
enhancing performance stability. Extensive experiments across diverse
multi-task learning scenarios demonstrate that MALoRA consistently outperforms
all baseline methods in both inter-domain and intra-domain tasks.

æè¦ï¼åæ¸ææå¾®èª¿ (PEFT) æ¹æ³ï¼ä¾å¦ LoRAï¼å·²å¤§å¹æå LLM å¨è³æºææçæ¹å¼ä¸é©æä¸æ¸¸ä»»åãç¶èï¼å¨å¤ä»»åæå¢ä¸­ï¼ç¶å¸¸åºç¾è¨ç·´ä¸å¹³è¡¡åè¹ºè¹ºæ¿ææç­ææ°ãæ··å LoRA (MoLoRA) å° LoRA èç¨çå°å®¶æ··åçµåï¼ééä¿é²è·¨å°å®¶çä»»åç¹å®å­¸ç¿ä¾ç·©è§£å¶ä¸­ä¸äºåé¡ãåç®¡å¦æ­¤ï¼MoLoRA å¨è¨ç·´éåº¦ãåæ¸ä½¿ç¨åæ´é«å¤ä»»åæè½æ¹é¢ä»ç¶æçä¸å½°ãå¨æ¬æä¸­ï¼æåæåºéå°ç¨±ä½éé©ææ··å (MALoRA)ï¼éæ¯ä¸ç¨®éæ´»çå¾®èª¿æ¶æ§ï¼å¯å©ç¨ LoRA å°å®¶ä¹éçéå°ç¨±æä½³åãMALoRA å°å¯è¨ç·´åæ¸æ¸éæ¸å° 30% è³ 48%ï¼å°è¨ç·´éåº¦æå 1.2 åï¼ä¸¦èå®ä¸ä»»å LoRA æ¨¡åçéç®æçç¸å¹éãæ­¤å¤ï¼MALoRA è§£æ±ºäºå¨é«éçµæä¸­å¸¸è¦çéåº¦æ¬ååé¡ï¼é²èæåæè½ç©©å®æ§ãè·¨ä¸åå¤ä»»åå­¸ç¿æå¢çå»£æ³å¯¦é©è­æï¼MALoRA å¨é åéåé åå§ä»»åä¸­å§çµåªæ¼ææåºæºæ¹æ³ã

##### **InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models**
2410.22770v1 by Hao Li, Xiaogeng Liu, Chaowei Xiao

Prompt injection attacks pose a critical threat to large language models
(LLMs), enabling goal hijacking and data leakage. Prompt guard models, though
effective in defense, suffer from over-defense -- falsely flagging benign
inputs as malicious due to trigger word bias. To address this issue, we
introduce NotInject, an evaluation dataset that systematically measures
over-defense across various prompt guard models. NotInject contains 339 benign
samples enriched with trigger words common in prompt injection attacks,
enabling fine-grained evaluation. Our results show that state-of-the-art models
suffer from over-defense issues, with accuracy dropping close to random
guessing levels (60%). To mitigate this, we propose InjecGuard, a novel prompt
guard model that incorporates a new training strategy, Mitigating Over-defense
for Free (MOF), which significantly reduces the bias on trigger words.
InjecGuard demonstrates state-of-the-art performance on diverse benchmarks
including NotInject, surpassing the existing best model by 30.8%, offering a
robust and open-source solution for detecting prompt injection attacks. The
code and datasets are released at https://github.com/SaFoLab-WISC/InjecGuard.

æè¦ï¼æç¤ºæ³¨å¥æ»å»å¯¹å¤§åè¯­è¨æ¨¡å (LLM) ææä¸¥éå¨èï¼å¯è½å¯¼è´ç®æ å«æåæ°æ®æ³é²ãæç¤ºé²æ¤æ¨¡åè½ç¶å¨é²å¾¡æ¹é¢å¾ææï¼ä½ä¼è¿åº¦é²å¾¡ââç±äºè§¦åè¯åå·®ï¼éè¯¯å°å°è¯æ§è¾å¥æ è®°ä¸ºæ¶æãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äº NotInjectï¼è¿æ¯ä¸ä¸ªè¯ä¼°æ°æ®éï¼å¯ä»¥ç³»ç»å°è¡¡éåç§æç¤ºé²æ¤æ¨¡åçè¿åº¦é²å¾¡ãNotInject åå« 339 ä¸ªè¯æ§æ ·æ¬ï¼å¶ä¸­åå«æç¤ºæ³¨å¥æ»å»ä¸­å¸¸è§çè§¦åè¯ï¼ä»èè½å¤è¿è¡ç»ç²åº¦çè¯ä¼°ãæä»¬çç»æè¡¨æï¼æåè¿çæ¨¡åå­å¨è¿åº¦é²å¾¡é®é¢ï¼åç¡®çä¸éå°æ¥è¿éæºçæµçæ°´å¹³ (60%)ãä¸ºäºç¼è§£è¿ä¸ªé®é¢ï¼æä»¬æåºäº InjecGuardï¼è¿æ¯ä¸ç§æ°çæç¤ºé²æ¤æ¨¡åï¼å®åå«äºä¸ç§æ°çè®­ç»ç­ç¥ï¼å³åè´¹ç¼è§£è¿åº¦é²å¾¡ (MOF)ï¼è¯¥ç­ç¥å¯ä»¥æ¾èåå°å¯¹è§¦åè¯çåå·®ãInjecGuard å¨åæ¬ NotInject å¨åçåç§åºåæµè¯ä¸­å±ç¤ºäºæåè¿çæ§è½ï¼æ¯ç°æçæä½³æ¨¡åé«åº 30.8%ï¼ä¸ºæ£æµæç¤ºæ³¨å¥æ»å»æä¾äºä¸ä¸ªå¥å£®ä¸å¼æºçè§£å³æ¹æ¡ãä»£ç åæ°æ®éå·²å¨ https://github.com/SaFoLab-WISC/InjecGuard åå¸ã

##### **Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**
2410.22767v1 by Sejin Lee, Dongha Kim, Min Song

Goal-oriented chatbots are essential for automating user tasks, such as
booking flights or making restaurant reservations. A key component of these
systems is Dialogue State Tracking (DST), which interprets user intent and
maintains the dialogue state. However, existing DST methods often rely on fixed
ontologies and manually compiled slot values, limiting their adaptability to
open-domain dialogues. We propose a novel approach that leverages instruction
tuning and advanced prompt strategies to enhance DST performance, without
relying on any predefined ontologies. Our method enables Large Language Model
(LLM) to infer dialogue states through carefully designed prompts and includes
an anti-hallucination mechanism to ensure accurate tracking in diverse
conversation contexts. Additionally, we employ a Variational Graph Auto-Encoder
(VGAE) to model and predict subsequent user intent. Our approach achieved
state-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST
models, and performed well in open-domain real-world conversations. This work
presents a significant advancement in creating more adaptive and accurate
goal-oriented chatbots.

æè¦ï¼ä»¥ç®æ¨çºå°åçèå¤©æ©å¨äººå¨èªååä½¿ç¨èä»»åä¸­è³ééè¦ï¼ä¾å¦é è¨èªç­æé²è¡é¤å»³è¨ä½ãéäºç³»çµ±çä¸åééµçµæé¨åæ¯å°è©±çæè¿½è¹¤ (DST)ï¼å®æè§£è­¯ä½¿ç¨èçæåä¸¦ç¶­è­·å°è©±çæãç¶èï¼ç¾æç DST æ¹æ³éå¸¸ä¾è³´æ¼åºå®çæ¬ä½åæåç·¨è­¯çæ§½ä½å¼ï¼ééå¶äºå®åå°éæ¾é åå°è©±çé©ææ§ãæåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼å®å©ç¨æä»¤èª¿æ´ååé²çæç¤ºç­ç¥ä¾å¢å¼· DST æè½ï¼èç¡éä¾è³´ä»»ä½é å®ç¾©çæ¬ä½ãæåçæ¹æ³ä½¿å¤§åèªè¨æ¨¡å (LLM) è½å¤ ééç²¾å¿è¨­è¨çæç¤ºä¾æ¨è«å°è©±çæï¼ä¸¦åå«ä¸ååå¹»è¦ºæ©å¶ï¼ä»¥ç¢ºä¿å¨ä¸åçå°è©±æå¢ä¸­æºç¢ºè¿½è¹¤ãæ­¤å¤ï¼æåæ¡ç¨è®ååèªç·¨ç¢¼å¨ (VGAE) ä¾å»ºæ¨¡åé æ¸¬å¾çºä½¿ç¨èçæåãæåçåæ³ä»¥ 42.57% ç JGA éå°äºç¾ææè¡çé å³°ï¼åªæ¼ç¾æçç¡æ¬ä½ DST æ¨¡åï¼ä¸¦å¨éæ¾é åççå¯¦å°è©±ä¸­è¡¨ç¾è¯å¥½ãéé å·¥ä½å¨å»ºç«æ´å·é©ææ§åæºç¢ºæ§çä»¥ç®æ¨çºå°åçèå¤©æ©å¨äººæ¹é¢åå¾äºéå¤§é²å±ã

##### **Self-Driving Car Racing: Application of Deep Reinforcement Learning**
2410.22766v1 by Florentiana Yuwono, Gan Pang Yen, Jason Christopher

This paper explores the application of deep reinforcement learning (RL)
techniques in the domain of autonomous self-driving car racing. Motivated by
the rise of AI-driven mobility and autonomous racing events, the project aims
to develop an AI agent that efficiently drives a simulated car in the OpenAI
Gymnasium CarRacing environment. We investigate various RL algorithms,
including Deep Q-Network (DQN), Proximal Policy Optimization (PPO), and novel
adaptations that incorporate transfer learning and recurrent neural networks
(RNNs) for enhanced performance. The project demonstrates that while DQN
provides a strong baseline for policy learning, integrating ResNet and LSTM
models significantly improves the agent's ability to capture complex spatial
and temporal dynamics. PPO, particularly in continuous action spaces, shows
promising results for fine control, although challenges such as policy collapse
remain. We compare the performance of these approaches and outline future
research directions focused on improving computational efficiency and
addressing model stability. Our findings contribute to the ongoing development
of AI systems in autonomous driving and related control tasks.

æè¦ï¼æ¬ææ¢è¨æ·±åº¦å¼·åå­¸ç¿ (RL) æè¡å¨èªåèªé§è»ç«¶è³½é åçæç¨ãå AI é©åçè¡åæ§åèªåé§é§è³½äºçèèµ·ææ¿åµï¼æ¬å°æ¡æ¨å¨éç¼ä¸å AI ä»£çï¼ä»¥ä¾¿å¨ OpenAI Gymnasium CarRacing ç°å¢ä¸­ææå°é§é§æ¨¡æ¬æ±½è»ãæåç ç©¶äºåç¨® RL æ¼ç®æ³ï¼åæ¬æ·±åº¦ Q ç¶²è·¯ (DQN)ãè¿ç«¯ç­ç¥æä½³å (PPO)ï¼ä»¥åçµåè½ç§»å­¸ç¿åéè¿´ç¥ç¶ç¶²è·¯ (RNN) ä»¥å¢å¼·æè½çæ°ç©æ¹ç·¨ãæ¬å°æ¡è­æï¼éç¶ DQN çºç­ç¥å­¸ç¿æä¾äºå¼·å¤§çåºæºï¼ä½æ´å ResNet å LSTM æ¨¡åå¯é¡¯èæåä»£çææè¤éç©ºéåæéåæçè½åãPPOï¼ç¹å¥æ¯å¨é£çºåä½ç©ºéä¸­ï¼é¡¯ç¤ºåºå°æ¼ç²¾ç´°æ§å¶å¾æå¸æççµæï¼åç®¡ç­ç¥å´©æ½°ç­ææ°ä¾ç¶å­å¨ãæåæ¯è¼äºéäºæ¹æ³çæè½ï¼ä¸¦æ¦è¿°äºå°æ³¨æ¼æ¹åéç®æçåè§£æ±ºæ¨¡åç©©å®æ§çæªä¾ç ç©¶æ¹åãæåçç ç©¶çµææå©æ¼èªåé§é§åç¸éæ§å¶ä»»åä¸­ AI ç³»çµ±çæçºç¼å±ã

##### **Constructing Multimodal Datasets from Scratch for Rapid Development of a Japanese Visual Language Model**
2410.22736v1 by Keito Sasagawa, Koki Maeda, Issa Sugiura, Shuhei Kurita, Naoaki Okazaki, Daisuke Kawahara

To develop high-performing Visual Language Models (VLMs), it is essential to
prepare multimodal resources, such as image-text pairs, interleaved data, and
instruction data. While multimodal resources for English are abundant, there is
a significant lack of corresponding resources for non-English languages, such
as Japanese. To address this problem, we take Japanese as a non-English
language and propose a method for rapidly creating Japanese multimodal datasets
from scratch. We collect Japanese image-text pairs and interleaved data from
web archives and generate Japanese instruction data directly from images using
an existing VLM. Our experimental results show that a VLM trained on these
native datasets outperforms those relying on machine-translated content.

æè¦ï¼çºäºéç¼é«æ§è½è¦è¦ºèªè¨æ¨¡å (VLM)ï¼æºåå¤æ¨¡æè³æºè³ééè¦ï¼ä¾å¦åæéå°ãäº¤é¯è³æåæä»¤è³æãéç¶è±æçå¤æ¨¡æè³æºè±å¯ï¼ä½éè±æèªè¨ï¼å¦æ¥æï¼çå°æè³æºå»å´éä¸è¶³ãçºäºè§£æ±ºéååé¡ï¼æåå°æ¥æè¦çºéè±æèªè¨ï¼ä¸¦æåºä¸åå¾é ­éå§å¿«éå»ºç«æ¥æå¤æ¨¡æè³æéçæ¹æ³ãæåå¾ç¶²è·¯æªæ¡é¤¨æ¶éæ¥æåæéå°åäº¤é¯è³æï¼ä¸¦ä½¿ç¨ç¾æç VLM ç´æ¥å¾åçç¢çæ¥ææä»¤è³æãæåçå¯¦é©çµæé¡¯ç¤ºï¼ä½¿ç¨éäºåçè³æéè¨ç·´ç VLM åªæ¼ä¾è³´æ©å¨ç¿»è­¯å§å®¹ç VLMã

##### **st-DTPM: Spatial-Temporal Guided Diffusion Transformer Probabilistic Model for Delayed Scan PET Image Prediction**
2410.22732v1 by Ran Hong, Yuxia Huang, Lei Liu, Zhonghui Wu, Bingxuan Li, Xuemei Wang, Qiegen Liu

PET imaging is widely employed for observing biological metabolic activities
within the human body. However, numerous benign conditions can cause increased
uptake of radiopharmaceuticals, confounding differentiation from malignant
tumors. Several studies have indicated that dual-time PET imaging holds promise
in distinguishing between malignant and benign tumor processes. Nevertheless,
the hour-long distribution period of radiopharmaceuticals post-injection
complicates the determination of optimal timing for the second scan, presenting
challenges in both practical applications and research. Notably, we have
identified that delay time PET imaging can be framed as an image-to-image
conversion problem. Motivated by this insight, we propose a novel
spatial-temporal guided diffusion transformer probabilistic model (st-DTPM) to
solve dual-time PET imaging prediction problem. Specifically, this architecture
leverages the U-net framework that integrates patch-wise features of CNN and
pixel-wise relevance of Transformer to obtain local and global information. And
then employs a conditional DDPM model for image synthesis. Furthermore, on
spatial condition, we concatenate early scan PET images and noisy PET images on
every denoising step to guide the spatial distribution of denoising sampling.
On temporal condition, we convert diffusion time steps and delay time to a
universal time vector, then embed it to each layer of model architecture to
further improve the accuracy of predictions. Experimental results demonstrated
the superiority of our method over alternative approaches in preserving image
quality and structural information, thereby affirming its efficacy in
predictive task.

æè¦ï¼æ­£å­æ·å±¤é å½±å»£æ³ç¨æ¼è§å¯äººé«å§ççç©ä»£è¬æ´»åãç¶èï¼è¨±å¤è¯æ§ç¾çæå°è´æ¾å°è¥ç©æåå¢å ï¼é²èæ··æ·èæ¡æ§è«ç¤çåå¥ãå¤é ç ç©¶è¡¨æï¼éæç¸æ­£å­æ·å±¤é å½±ææååæ¡æ§åè¯æ§è«ç¤éç¨ãåç®¡å¦æ­¤ï¼æ³¨å°å¾æ¾å°è¥ç©é·éä¸å°æçåå¸æè®ç¬¬äºæææçæä½³ææ©é£ä»¥ç¢ºå®ï¼å°å¯¦éæç¨åç ç©¶é½é æææ°ãå¼å¾æ³¨æçæ¯ï¼æåå·²ç¼ç¾å»¶é²æéæ­£å­æ·å±¤é å½±å¯ä»¥è¦çºå½±åè½å½±åçè½æåé¡ãåæ­¤è¦è§£åç¼ï¼æåæåºä¸åæ°ç©çæç©ºå¼å°æ´æ£è½æå¨æ©çæ¨¡å (st-DTPM) ä¾è§£æ±ºéæç¸æ­£å­æ·å±¤é å½±é æ¸¬åé¡ãå·é«ä¾èªªï¼æ­¤æ¶æ§å©ç¨ U-net æ¡æ¶ï¼æ´å CNN çåå¡ç¹å¾µå Transformer çç«ç´ ç¸éæ§ï¼ä»¥ç²åå±é¨åå¨å±è³è¨ãç¶å¾æ¡ç¨æ¢ä»¶å¼ DDPM æ¨¡åé²è¡å½±ååæãæ­¤å¤ï¼å¨ç©ºéæ¢ä»¶ä¸ï¼æåå¨æ¯åå»åªæ­¥é©ä¸­ä¸²æ¥æ©ææææ­£å­æ·å±¤é å½±å½±ååéè¨æ­£å­æ·å±¤é å½±å½±åï¼ä»¥å¼å°å»åªæ¡æ¨£çç©ºéåä½ãå¨æéæ¢ä»¶ä¸ï¼æåå°æ´æ£æéæ­¥é·åå»¶é²æéè½æçºéç¨æéåéï¼ç¶å¾å°å¶åµå¥æ¨¡åæ¶æ§çæ¯ä¸å±¤ï¼ä»¥é²ä¸æ­¥æé«é æ¸¬æºç¢ºåº¦ãå¯¦é©çµæè­æï¼æåçæ¹æ³å¨ä¿çå½±ååè³ªåçµæ§è³è¨æ¹é¢åªæ¼å¶ä»æ¹æ³ï¼å¾èè¯å®å¶å¨é æ¸¬ä»»åä¸­çæè½ã

##### **Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization**
2410.22707v1 by Kento Kawaharazuka, Yoshiki Obinata, Naoaki Kanazawa, Kei Okada, Masayuki Inaba

State recognition of the environment and objects, such as the open/closed
state of doors and the on/off of lights, is indispensable for robots that
perform daily life support and security tasks. Until now, state recognition
methods have been based on training neural networks from manual annotations,
preparing special sensors for the recognition, or manually programming to
extract features from point clouds or raw images. In contrast, we propose a
robotic state recognition method using a pre-trained vision-language model,
which is capable of Image-to-Text Retrieval (ITR) tasks. We prepare several
kinds of language prompts in advance, calculate the similarity between these
prompts and the current image by ITR, and perform state recognition. By
applying the optimal weighting to each prompt using black-box optimization,
state recognition can be performed with higher accuracy. Experiments show that
this theory enables a variety of state recognitions by simply preparing
multiple prompts without retraining neural networks or manual programming. In
addition, since only prompts and their weights need to be prepared for each
recognizer, there is no need to prepare multiple models, which facilitates
resource management. It is possible to recognize the open/closed state of
transparent doors, the state of whether water is running or not from a faucet,
and even the qualitative state of whether a kitchen is clean or not, which have
been challenging so far, through language.

æè¦ï¼æ©å¨äººå·è¡æ¥å¸¸çæ´»æ¯æ´åå®å¨ä»»åæï¼å¿é è¾¨è­ç°å¢åç©é«ççæï¼ä¾å¦éçé/éçæåççé/éçæãå°ç®åçºæ­¢ï¼çæè¾¨è­æ¹æ³ä¸ç´æ¯æ ¹ææåè¨»è§£è¨ç·´ç¥ç¶ç¶²è·¯ãæºåç¹æ®ææ¸¬å¨é²è¡è¾¨è­ï¼ææåç·¨å¯«ç¨å¼å¾é»é²æåå§å½±åä¸­æ·åç¹å¾µãç¸åå°ï¼æåæåºä½¿ç¨é åè¨ç·´å¥½çè¦è¦ºèªè¨æ¨¡åçæ©å¨äººçæè¾¨è­æ¹æ³ï¼è©²æ¨¡åè½å¤ å·è¡å½±åå°æå­æª¢ç´¢ (ITR) ä»»åãæåäºåæºåå¹¾ç¨®èªè¨æç¤ºï¼éé ITR è¨ç®éäºæç¤ºåç¶åå½±åä¹éçç¸ä¼¼æ§ï¼ä¸¦å·è¡çæè¾¨è­ãééä½¿ç¨é»çæä½³åå°æ¯åæç¤ºå¥ç¨æä½³æ¬éï¼å¯ä»¥æ´æºç¢ºå°å·è¡çæè¾¨è­ãå¯¦é©é¡¯ç¤ºï¼æ­¤çè«åªéæºåå¤åæç¤ºï¼èç¡ééæ°è¨ç·´ç¥ç¶ç¶²è·¯ææåç·¨å¯«ç¨å¼ï¼å³å¯é²è¡åç¨®çæè¾¨è­ãæ­¤å¤ï¼ç±æ¼æ¯åè¾¨è­å¨åªéè¦æºåæç¤ºåå¶æ¬éï¼å æ­¤ç¡éæºåå¤åæ¨¡åï¼éæå©æ¼è³æºç®¡çãå¯ä»¥ééèªè¨è¾¨è­éæéçé/éçæãæ°´é¾é ­æ¯å¦åºæ°´ï¼çè³å»æ¿æ¯å¦ä¹¾æ·¨çåè³ªçæï¼éäºé½æ¯å°ç®åçºæ­¢çææ°ã

##### **Permutation Invariant Learning with High-Dimensional Particle Filters**
2410.22695v1 by Akhilan Boopathy, Aneesh Muppidi, Peggy Yang, Abhiram Iyer, William Yue, Ila Fiete

Sequential learning in deep models often suffers from challenges such as
catastrophic forgetting and loss of plasticity, largely due to the permutation
dependence of gradient-based algorithms, where the order of training data
impacts the learning outcome. In this work, we introduce a novel
permutation-invariant learning framework based on high-dimensional particle
filters. We theoretically demonstrate that particle filters are invariant to
the sequential ordering of training minibatches or tasks, offering a principled
solution to mitigate catastrophic forgetting and loss-of-plasticity. We develop
an efficient particle filter for optimizing high-dimensional models, combining
the strengths of Bayesian methods with gradient-based optimization. Through
extensive experiments on continual supervised and reinforcement learning
benchmarks, including SplitMNIST, SplitCIFAR100, and ProcGen, we empirically
show that our method consistently improves performance, while reducing variance
compared to standard baselines.

æè¦ï¼æ·±åº¦æ¨¡åä¸­çé¡ºåºå­¸ç¿éå¸¸æéå°ç½é£æ§éºå¿åå¯å¡æ§åªå¤±ç­ææ°ï¼éå¨å¾å¤§ç¨åº¦ä¸æ¯ç±æ¼åºæ¼æ¢¯åº¦çæ¼ç®æ³çæåä¾è³´æ§ï¼å¶ä¸­è¨ç·´è³æçé åºæå½±é¿å­¸ç¿çµæãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äºä¸ååºæ¼é«ç¶­ç²å­æ¿¾æ³¢å¨çæ°ç©æåä¸è®å­¸ç¿æ¡æ¶ãæåå¾çè«ä¸è­æç²å­æ¿¾æ³¢å¨å°è¨ç·´å°æ¹æ¬¡æä»»åçé åºæåä¸è®ï¼æä¾äºä¸åååæ§çè§£æ±ºæ¹æ¡ä¾æ¸è¼ç½é£æ§éºå¿åå¯å¡æ§åªå¤±ãæåéç¼äºä¸åç¨æ¼æä½³åé«ç¶­æ¨¡åçææç²å­æ¿¾æ³¢å¨ï¼çµåäºè²æ°æ¹æ³ååºæ¼æ¢¯åº¦çæä½³åçåªé»ãééå¨æçºç£ç£åå¼·åå­¸ç¿åºæºï¼åæ¬ SplitMNISTãSplitCIFAR100 å ProcGenï¼ä¸é²è¡å»£æ³çå¯¦é©ï¼æåæç¶é©è¡¨æï¼èæ¨æºåºæºç¸æ¯ï¼æåçæ¨¡åæçºæ¹åæè½ï¼åæéä½è®ç°ã

##### **Choice between Partial Trajectories**
2410.22690v1 by Henrik Marklund, Benjamin Van Roy

As AI agents generate increasingly sophisticated behaviors, manually encoding
human preferences to guide these agents becomes more challenging. To address
this, it has been suggested that agents instead learn preferences from human
choice data. This approach requires a model of choice behavior that the agent
can use to interpret the data. For choices between partial trajectories of
states and actions, previous models assume choice probabilities to be
determined by the partial return or the cumulative advantage.
  We consider an alternative model based instead on the bootstrapped return,
which adds to the partial return an estimate of the future return. Benefits of
the bootstrapped return model stem from its treatment of human beliefs. Unlike
partial return, choices based on bootstrapped return reflect human beliefs
about the environment. Further, while recovering the reward function from
choices based on cumulative advantage requires that those beliefs are correct,
doing so from choices based on bootstrapped return does not.
  To motivate the bootstrapped return model, we formulate axioms and prove an
Alignment Theorem. This result formalizes how, for a general class of human
preferences, such models are able to disentangle goals from beliefs. This
ensures recovery of an aligned reward function when learning from choices based
on bootstrapped return.
  The bootstrapped return model also affords greater robustness to choice
behavior. Even when choices are based on partial return, learning via a
bootstrapped return model recovers an aligned reward function. The same holds
with choices based on the cumulative advantage if the human and the agent both
adhere to correct and consistent beliefs about the environment. On the other
hand, if choices are based on bootstrapped return, learning via partial return
or cumulative advantage models does not generally produce an aligned reward
function.

æè¦ï¼é¨è AI ä»£çç¢çè¶ä¾è¶è¤éçè¡çºï¼æåç·¨ç¢¼äººé¡åå¥½ä»¥å¼å°éäºä»£çè®å¾æ´å·ææ°æ§ãçºäºè§£æ±ºéååé¡ï¼æäººå»ºè­°ä»£çæ¹çºå¾äººé¡é¸ææ¸æä¸­å­¸ç¿åå¥½ãéç¨®æ¹æ³éè¦ä¸åé¸æè¡çºæ¨¡åï¼ä»£çå¯ä»¥ä½¿ç¨è©²æ¨¡åä¾è§£éæ¸æãå°æ¼çæååä½çé¨åè»è·¡ä¹éçé¸æï¼ååçæ¨¡ååè¨­é¸ææ©çæ¯ç±é¨ååå ±æç´¯ç©åªå¢æ±ºå®çã
æåèæ®ä¸ååºæ¼èªèåå ±çæ¿ä»£æ¨¡åï¼å®å¨é¨ååå ±ä¸­å¢å äºå°æªä¾åå ±çä¼°è¨ãèªèåå ±æ¨¡åçå¥½èæºæ¼å®å°äººé¡ä¿¡å¿µçèçãèé¨ååå ±ä¸åï¼åºæ¼èªèåå ±çé¸æåæ äºäººé¡å°ç°å¢çä¿¡å¿µãæ­¤å¤ï¼éç¶å¾åºæ¼ç´¯ç©åªå¢çé¸æä¸­æ¢å¾©çåµå½æ¸éè¦éäºä¿¡å¿µæ¯æ­£ç¢ºçï¼ä½å¾åºæ¼èªèåå ±çé¸æä¸­éæ¨£ååä¸éè¦ã
çºäºæ¿åµèªèåå ±æ¨¡åï¼æåå¶å®å¬çä¸¦è­æä¸åå°é½å®çãéåçµæå½¢å¼åäºå°æ¼äººé¡åå¥½çä¸è¬é¡å¥ï¼éäºæ¨¡åå¦ä½è½å¤ ååç®æ¨åä¿¡å¿µãéç¢ºä¿äºå¾åºæ¼èªèåå ±çé¸æä¸­å­¸ç¿æï¼å°é½çåµå½æ¸çæ¢å¾©ã
èªèåå ±æ¨¡åéæä¾äºå°é¸æè¡çºæ´å¤§çé­¯æ£æ§ãå³ä½¿é¸æåºæ¼é¨ååå ±ï¼ééèªèåå ±æ¨¡åå­¸ç¿ä¹ææ¢å¾©å°é½ççåµå½æ¸ãå¦æäººé¡åä»£çé½å æå°ç°å¢çæ­£ç¢ºåä¸è´çä¿¡å¿µï¼é£éº¼åºæ¼ç´¯ç©åªå¢çé¸æä¹æ¯å¦æ­¤ãå¦ä¸æ¹é¢ï¼å¦æé¸æåºæ¼èªèåå ±ï¼åééé¨ååå ±æç´¯ç©åªå¢æ¨¡åå­¸ç¿éå¸¸ä¸æç¢çå°é½ççåµå½æ¸ã

##### **Multi-Task Interactive Robot Fleet Learning with Visual World Models**
2410.22689v1 by Huihan Liu, Yu Zhang, Vaarij Betala, Evan Zhang, James Liu, Crystal Ding, Yuke Zhu

Recent advancements in large-scale multi-task robot learning offer the
potential for deploying robot fleets in household and industrial settings,
enabling them to perform diverse tasks across various environments. However,
AI-enabled robots often face challenges with generalization and robustness when
exposed to real-world variability and uncertainty. We introduce Sirius-Fleet, a
multi-task interactive robot fleet learning framework to address these
challenges. Sirius-Fleet monitors robot performance during deployment and
involves humans to correct the robot's actions when necessary. We employ a
visual world model to predict the outcomes of future actions and build anomaly
predictors to predict whether they will likely result in anomalies. As the
robot autonomy improves, the anomaly predictors automatically adapt their
prediction criteria, leading to fewer requests for human intervention and
gradually reducing human workload over time. Evaluations on large-scale
benchmarks demonstrate Sirius-Fleet's effectiveness in improving multi-task
policy performance and monitoring accuracy. We demonstrate Sirius-Fleet's
performance in both RoboCasa in simulation and Mutex in the real world, two
diverse, large-scale multi-task benchmarks. More information is available on
the project website: https://ut-austin-rpl.github.io/sirius-fleet

æè¦ï¼å¤§åå¤ä»»å¡æºå¨äººå­¦ä¹ çè¿æè¿å±æä¾äºå¨å®¶åº­åå·¥ä¸ç¯å¢ä¸­é¨ç½²æºå¨äººè½¦éçæ½åï¼ä½¿ä»ä»¬è½å¤å¨åç§ç¯å¢ä¸­æ§è¡ä¸åçä»»å¡ãç¶èï¼äººå·¥æºè½é©±å¨çæºå¨äººç»å¸¸é¢ä¸´æ³ååé²æ£æ§æ¹é¢çææï¼å½æ´é²äºç°å®ä¸ççå¯åæ§åä¸ç¡®å®æ§æ¶ãæä»¬å¼å¥äº Sirius-Fleetï¼ä¸ä¸ªå¤ä»»å¡äº¤äºå¼æºå¨äººè½¦éå­¦ä¹ æ¡æ¶æ¥è§£å³è¿äºææãSirius-Fleet å¨é¨ç½²æé´çæ§æºå¨äººæ§è½ï¼å¹¶å¨å¿è¦æ¶è®©äººç±»æ¥çº æ­£æºå¨äººçå¨ä½ãæä»¬éç¨äºä¸ä¸ªè§è§ä¸çæ¨¡åæ¥é¢æµæªæ¥å¨ä½çç»æï¼å¹¶æå»ºå¼å¸¸é¢æµå¨æ¥é¢æµå®ä»¬æ¯å¦å¯è½å¯¼è´å¼å¸¸ãéçæºå¨äººèªä¸»æ§çæé«ï¼å¼å¸¸é¢æµå¨ä¼èªå¨è°æ´å¶é¢æµæ åï¼ä»èåå°å¯¹äººç±»å¹²é¢çè¯·æ±ï¼å¹¶éçæ¶é´çæ¨ç§»éæ¸åå°äººç±»çå·¥ä½éãå¨å¤§è§æ¨¡åºåæµè¯ä¸çè¯ä¼°è¯æäº Sirius-Fleet å¨æé«å¤ä»»å¡ç­ç¥æ§è½åçæ§åç¡®æ§æ¹é¢çæææ§ãæä»¬å±ç¤ºäº Sirius-Fleet å¨æ¨¡æä¸­ç RoboCasa åç°å®ä¸çä¸­ç Mutex ä¸­çæ§è½ï¼è¿ä¸¤ä¸ªå¤§åå¤ä»»å¡åºåæµè¯å·æå¤æ ·æ§ãæ´å¤ä¿¡æ¯å¯å¨é¡¹ç®ç½ç«ä¸æ¾å°ï¼https://ut-austin-rpl.github.io/sirius-fleet

##### **Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings**
2410.22685v1 by Yashvir S. Grewal, Edwin V. Bonilla, Thang D. Bui

Accurately quantifying uncertainty in large language models (LLMs) is crucial
for their reliable deployment, especially in high-stakes applications. Current
state-of-the-art methods for measuring semantic uncertainty in LLMs rely on
strict bidirectional entailment criteria between multiple generated responses
and also depend on sequence likelihoods. While effective, these approaches
often overestimate uncertainty due to their sensitivity to minor wording
differences, additional correct information, and non-important words in the
sequence. We propose a novel approach that leverages semantic embeddings to
achieve smoother and more robust estimation of semantic uncertainty in LLMs. By
capturing semantic similarities without depending on sequence likelihoods, our
method inherently reduces any biases introduced by irrelevant words in the
answers. Furthermore, we introduce an amortised version of our approach by
explicitly modelling semantics as latent variables in a joint probabilistic
model. This allows for uncertainty estimation in the embedding space with a
single forward pass, significantly reducing computational overhead compared to
existing multi-pass methods. Experiments across multiple question-answering
datasets and frontier LLMs demonstrate that our embedding-based methods provide
more accurate and nuanced uncertainty quantification than traditional
approaches.

æè¦ï¼æºç¢ºéåå¤§åèªè¨æ¨¡å (LLM) ä¸­çä¸ç¢ºå®æ§ï¼å°æ¼å®åçå¯é é¨ç½²è³ééè¦ï¼å°¤å¶æ¯å¨é«é¢¨éªæç¨ä¸­ãç®åç¨æ¼è¡¡é LLM ä¸­èªç¾©ä¸ç¢ºå®æ§çæåé²æ¹æ³ä¾è³´æ¼å¤åçæåæä¹éçå´æ ¼éåèæ¶µæºåï¼ä¸¦ä¸ä¹ä¾è³´æ¼åºåå¯è½æ§ãåç®¡ææï¼ä½éäºæ¹æ³ç±æ¼å°ç´°å¾®æªè¾­å·®ç°ãé¡å¤çæ­£ç¢ºè³è¨ååºåä¸­ä¸éè¦çå­è©ææï¼å æ­¤ç¶å¸¸é«ä¼°ä¸ç¢ºå®æ§ãæåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼è©²æ¹æ³å©ç¨èªç¾©åµå¥ä¾å¯¦ç¾å° LLM ä¸­èªç¾©ä¸ç¢ºå®æ§çæ´å¹³æ»ãæ´ç©©å¥çä¼°è¨ãééå¨ä¸ä¾è³´åºåå¯è½æ§ææ³ä¸æ·åèªç¾©ç¸ä¼¼æ§ï¼æåçæ¨¡åæ¬è³ªä¸æ¸å°äºç­æ¡ä¸­ç¡éå­è©å¸¶ä¾çä»»ä½åå·®ãæ­¤å¤ï¼æåééå¨è¯åæ©çæ¨¡åä¸­å°èªç¾©æç¢ºå»ºæ¨¡çºæ½å¨è®æ¸ï¼å¼å¥äºæåæ¹æ³çæ¤é·çæ¬ãéåè¨±å¨åµå¥ç©ºéä¸­ä½¿ç¨å®æ¬¡ååå³éä¾ä¼°è¨ä¸ç¢ºå®æ§ï¼èç¾æçå¤éå³éæ¹æ³ç¸æ¯ï¼å¤§å¹éä½äºéç®è² æãè·¨å¤ååç­è³æéååæ²¿ LLM çå¯¦é©è¡¨æï¼æåçåºæ¼åµå¥çæ¹æ³æä¾äºæ¯å³çµ±æ¹æ³æ´æºç¢ºãæ´ç´°ç·»çä¸ç¢ºå®æ§éåã

##### **Backdoor Attack Against Vision Transformers via Attention Gradient-Based Image Erosion**
2410.22678v1 by Ji Guo, Hongwei Li, Wenbo Jiang, Guoming Lu

Vision Transformers (ViTs) have outperformed traditional Convolutional Neural
Networks (CNN) across various computer vision tasks. However, akin to CNN, ViTs
are vulnerable to backdoor attacks, where the adversary embeds the backdoor
into the victim model, causing it to make wrong predictions about testing
samples containing a specific trigger. Existing backdoor attacks against ViTs
have the limitation of failing to strike an optimal balance between attack
stealthiness and attack effectiveness.
  In this work, we propose an Attention Gradient-based Erosion Backdoor (AGEB)
targeted at ViTs. Considering the attention mechanism of ViTs, AGEB selectively
erodes pixels in areas of maximal attention gradient, embedding a covert
backdoor trigger. Unlike previous backdoor attacks against ViTs, AGEB achieves
an optimal balance between attack stealthiness and attack effectiveness,
ensuring the trigger remains invisible to human detection while preserving the
model's accuracy on clean samples. Extensive experimental evaluations across
various ViT architectures and datasets confirm the effectiveness of AGEB,
achieving a remarkable Attack Success Rate (ASR) without diminishing Clean Data
Accuracy (CDA). Furthermore, the stealthiness of AGEB is rigorously validated,
demonstrating minimal visual discrepancies between the clean and the triggered
images.

æè¦ï¼è¦è¦º Transformer (ViT) å¨åç¨®é»è¦è¦è¦ºä»»åä¸­åªæ¼å³çµ±çå·ç©ç¥ç¶ç¶²è·¯ (CNN)ãç¶èï¼è CNN é¡ä¼¼ï¼ViT å®¹æåå°å¾éæ»æï¼å¶ä¸­å°æå°å¾éåµå¥åå®³èæ¨¡åï¼å°è´å¶å°åå«ç¹å®è§¸ç¼å¨çæ¸¬è©¦æ¨£æ¬ååºé¯èª¤é æ¸¬ãç¾æçéå° ViT çå¾éæ»æå­å¨ç¡æ³å¨æ»æé±è½æ§åæ»ææææ§ä¹éåå¾æä½³å¹³è¡¡çéå¶ã
å¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åéå° ViT çåºæ¼æ³¨ææ¢¯åº¦çä¾µèå¾é (AGEB)ãèæ®å° ViT çæ³¨ææ©å¶ï¼AGEB é¸ææ§å°ä¾µèæå¤§æ³¨ææ¢¯åº¦çåååç´ ï¼åµå¥ä¸åé±è½çå¾éè§¸ç¼å¨ãèååéå° ViT çå¾éæ»æä¸åï¼AGEB å¨æ»æé±è½æ§åæ»ææææ§ä¹éå¯¦ç¾äºæä½³å¹³è¡¡ï¼ç¢ºä¿è§¸ç¼å¨å°äººé¡æª¢æ¸¬ä¿æä¸å¯è¦ï¼åæä¿ææ¨¡åå°ä¹¾æ·¨æ¨£æ¬çæºç¢ºæ§ãè·¨åç¨® ViT æ¶æ§åè³æéé²è¡çå»£æ³å¯¦é©è©ä¼°è­å¯¦äº AGEB çæææ§ï¼å¯¦ç¾äºé¡¯èçæ»ææåç (ASR)ï¼èä¸æéä½ä¹¾æ·¨æ¸ææºç¢ºåº¦ (CDA)ãæ­¤å¤ï¼AGEB çé±è½æ§å¾å°äºå´æ ¼é©è­ï¼è­æäºä¹¾æ·¨åååè§¸ç¼ååä¹éæå°çè¦è¦ºå·®ç°ã

##### **Automated Trustworthiness Oracle Generation for Machine Learning Text Classifiers**
2410.22663v1 by Lam Nguyen Tung, Steven Cho, Xiaoning Du, Neelofar Neelofar, Valerio Terragni, Stefano Ruberto, Aldeida Aleti

Machine learning (ML) for text classification has been widely used in various
domains, such as toxicity detection, chatbot consulting, and review analysis.
These applications can significantly impact ethics, economics, and human
behavior, raising serious concerns about trusting ML decisions. Several studies
indicate that traditional metrics, such as model confidence and accuracy, are
insufficient to build human trust in ML models. These models often learn
spurious correlations during training and predict based on them during
inference. In the real world, where such correlations are absent, their
performance can deteriorate significantly. To avoid this, a common practice is
to test whether predictions are reasonable. Along with this, a challenge known
as the trustworthiness oracle problem has been introduced. Due to the lack of
automated trustworthiness oracles, the assessment requires manual validation of
the decision process disclosed by explanation methods, which is time-consuming
and not scalable. We propose TOKI, the first automated trustworthiness oracle
generation method for text classifiers, which automatically checks whether the
prediction-contributing words are related to the predicted class using
explanation methods and word embeddings. To demonstrate its practical
usefulness, we introduce a novel adversarial attack method targeting
trustworthiness issues identified by TOKI. We compare TOKI with a naive
baseline based solely on model confidence using human-created ground truths of
6,000 predictions. We also compare TOKI-guided adversarial attack method with
A2T, a SOTA adversarial attack method. Results show that relying on prediction
uncertainty cannot distinguish between trustworthy and untrustworthy
predictions, TOKI achieves 142% higher accuracy than the naive baseline, and
TOKI-guided adversarial attack method is more effective with fewer
perturbations than A2T.

æè¦ï¼æ©å¨å­¸ç¿ (ML) å·²å»£æ³ç¨æ¼ææ¬åé¡çååé åï¼ä¾å¦æ¯æ§æª¢æ¸¬ãèå¤©æ©å¨äººè«®è©¢åè©è«åæãéäºæç¨æå°éå¾·ãç¶æ¿åäººé¡è¡çºç¢çéå¤§å½±é¿ï¼å¼ç¼äºå°ä¿¡ä»» ML æ±ºç­çå´éçæ®ãå¤é ç ç©¶æåºï¼å³çµ±ææ¨ï¼ä¾å¦æ¨¡åä¿¡å¿åæºç¢ºåº¦ï¼ä¸è¶³ä»¥å»ºç«äººé¡å° ML æ¨¡åçä¿¡ä»»ãéäºæ¨¡åå¨è¨ç·´æééå¸¸æå­¸ç¿å°èåçç¸éæ§ï¼ä¸¦å¨æ¨çæéæ ¹æéäºç¸éæ§é²è¡é æ¸¬ãå¨ç¾å¯¦ä¸çä¸­ï¼ç¶éäºç¸éæ§ä¸å­å¨æï¼å®åçæè½å¯è½æå¤§å¹ä¸éãçºäºé¿åéç¨®ææ³ï¼ä¸ç¨®å¸¸è¦çåæ³æ¯æ¸¬è©¦é æ¸¬æ¯å¦åçãèæ­¤åæï¼å¼å¥äºç¨±çºå¯ä¿¡è³´æ§é è¨æ©åé¡çææ°ãç±æ¼ç¼ºä¹èªååçå¯ä¿¡è³´æ§é è¨æ©ï¼è©ä¼°éè¦æåé©è­èªªææ¹æ³ææ­é²çæ±ºç­æµç¨ï¼éæ¢èæåç¡æ³æ´å±ãæåæåºäº TOKIï¼éæ¯ç¬¬ä¸åéå°ææ¬åé¡å¨çèªååå¯ä¿¡è³´æ§é è¨æ©çææ¹æ³ï¼å®ä½¿ç¨èªªææ¹æ³åå­è©åµå¥èªåæª¢æ¥é æ¸¬ç¸éå­è©æ¯å¦èé æ¸¬é¡å¥ç¸éãçºäºå±ç¤ºå¶å¯¦éæç¨ï¼æåä»ç´¹äºä¸ç¨®æ°ç©çå°ææ»ææ¹æ³ï¼éå° TOKI è­å¥åºçå¯ä¿¡è³´æ§åé¡ãæåä½¿ç¨äººé¡å»ºç«ç 6,000 åé æ¸¬ççå¯¦ä¾æï¼å° TOKI èååºæ¼æ¨¡åä¿¡å¿çæ¨¸ç´ åºæºé²è¡æ¯è¼ãæåéå° TOKI å¼å°çå°ææ»ææ¹æ³è A2Tï¼ä¸ç¨® SOTA å°ææ»ææ¹æ³ï¼é²è¡æ¯è¼ãçµæè¡¨æï¼ä¾è³´é æ¸¬ä¸ç¢ºå®æ§ç¡æ³ååå¯ä¿¡è³´æ§åä¸å¯ä¿¡è³´æ§çé æ¸¬ï¼TOKI çæºç¢ºåº¦æ¯æ¨¸ç´ åºæºé«åº 142%ï¼è TOKI å¼å°çå°ææ»ææ¹æ³æ¯ A2T æ´ææï¼ä¸æ¾åæ´å°ã

##### **$\textbf{EMOS}$: $\textbf{E}$mbodiment-aware Heterogeneous $\textbf{M}$ulti-robot $\textbf{O}$perating $\textbf{S}$ystem with LLM Agents**
2410.22662v1 by Junting Chen, Checheng Yu, Xunzhe Zhou, Tianqi Xu, Yao Mu, Mengkang Hu, Wenqi Shao, Yikai Wang, Guohao Li, Lin Shao

Heterogeneous multi-robot systems (HMRS) have emerged as a powerful approach
for tackling complex tasks that single robots cannot manage alone. Current
large-language-model-based multi-agent systems (LLM-based MAS) have shown
success in areas like software development and operating systems, but applying
these systems to robot control presents unique challenges. In particular, the
capabilities of each agent in a multi-robot system are inherently tied to the
physical composition of the robots, rather than predefined roles. To address
this issue, we introduce a novel multi-agent framework designed to enable
effective collaboration among heterogeneous robots with varying embodiments and
capabilities, along with a new benchmark named Habitat-MAS. One of our key
designs is $\textit{Robot Resume}$: Instead of adopting human-designed role
play, we propose a self-prompted approach, where agents comprehend robot URDF
files and call robot kinematics tools to generate descriptions of their physics
capabilities to guide their behavior in task planning and action execution. The
Habitat-MAS benchmark is designed to assess how a multi-agent framework handles
tasks that require embodiment-aware reasoning, which includes 1) manipulation,
2) perception, 3) navigation, and 4) comprehensive multi-floor object
rearrangement. The experimental results indicate that the robot's resume and
the hierarchical design of our multi-agent system are essential for the
effective operation of the heterogeneous multi-robot system within this
intricate problem context.

æè¦ï¼ç°è³ªå¤æ©å¨äººç³»çµ± (HMRS) å·²æçºä¸ç¨®å¼·èæåçæ¹æ³ï¼ç¨æ¼è§£æ±ºå®ä¸æ©å¨äººç¡æ³å®ç¨ç®¡ççè¤éä»»åãç®ååºæ¼å¤§åèªè¨æ¨¡åçå¤ä»£çç³»çµ± (LLM-based MAS) å·²å¨è»é«éç¼åä½æ¥­ç³»çµ±ç­é åå±ç¾æåï¼ä½å°éäºç³»çµ±æç¨æ¼æ©å¨äººæ§å¶æç¢çç¨ç¹çææ°ãç¹å¥æ¯ï¼å¤æ©å¨äººç³»çµ±ä¸­æ¯åä»£ççè½åæ¬è³ªä¸èæ©å¨äººçç©ççµææéï¼èä¸æ¯é å®ç¾©çè§è²ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºä¸åæ°ç©çå¤ä»£çæ¡æ¶ï¼æ¨å¨è®å·æä¸åå·é«å½¢å¼åè½åçç°è³ªæ©å¨äººä¹éè½å¤ ææåä½ï¼ä¸¦æä¾ä¸ååçº Habitat-MAS çæ°åºæºãæåçééµè¨­è¨ä¹ä¸æ¯ãæ©å¨äººå±¥æ­·ãï¼æåæåºäºä¸ç¨®èªææç¤ºçæ¹æ³ï¼èä¸æ¯æ¡ç¨äººé¡è¨­è¨çè§è²æ®æ¼ï¼ä»£çæçè§£æ©å¨äºº URDF æªæ¡ï¼ä¸¦å¼å«æ©å¨äººéåå­¸å·¥å·ä¾ç¢çå¶ç©çè½åçæè¿°ï¼ä»¥æå°å¶å¨ä»»åè¦åååä½å·è¡ä¸­çè¡çºãHabitat-MAS åºæºæ¨å¨è©ä¼°å¤ä»£çæ¡æ¶å¦ä½èçéè¦å·é«å½¢å¼æç¥æ¨ççä»»åï¼å¶ä¸­åæ¬ 1) æä½ã2) æç¥ã3) å°èªï¼ä»¥å 4) å¨é¢çå¤æ¨å±¤ç©ä»¶éæ°æåãå¯¦é©çµæè¡¨æï¼æ©å¨äººçå±¥æ­·åæåå¤ä»£çç³»çµ±çéå±¤å¼è¨­è¨å°æ¼ç°è³ªå¤æ©å¨äººç³»çµ±å¨éåè¤éçåé¡èæ¯ä¸ææéä½è³ééè¦ã

##### **Linguistics Theory Meets LLM: Code-Switched Text Generation via Equivalence Constrained Large Language Models**
2410.22660v1 by Garry Kuwanto, Chaitanya Agarwal, Genta Indra Winata, Derry Tanti Wijaya

Code-switching, the phenomenon of alternating between two or more languages
in a single conversation, presents unique challenges for Natural Language
Processing (NLP). Most existing research focuses on either syntactic
constraints or neural generation, with few efforts to integrate linguistic
theory with large language models (LLMs) for generating natural code-switched
text. In this paper, we introduce EZSwitch, a novel framework that combines
Equivalence Constraint Theory (ECT) with LLMs to produce linguistically valid
and fluent code-switched text. We evaluate our method using both human
judgments and automatic metrics, demonstrating a significant improvement in the
quality of generated code-switching sentences compared to baseline LLMs. To
address the lack of suitable evaluation metrics, we conduct a comprehensive
correlation study of various automatic metrics against human scores, revealing
that current metrics often fail to capture the nuanced fluency of code-switched
text. Additionally, we create CSPref, a human preference dataset based on human
ratings and analyze model performance across ``hard`` and ``easy`` examples.
Our findings indicate that incorporating linguistic constraints into LLMs leads
to more robust and human-aligned generation, paving the way for scalable
code-switching text generation across diverse language pairs.

æè¦ï¼ä»£ç¢¼è½æï¼å¨å®ä¸å°è©±ä¸­äº¤æ¿ä½¿ç¨å©ç¨®æå¤ç¨®èªè¨çç¾è±¡ï¼å°èªç¶èªè¨èç (NLP) æ§æç¨ç¹çææ°ãç¾æçå¤§é¨åç ç©¶é½å°æ³¨æ¼èªæ³éå¶æç¥ç¶çæï¼å¾å°æç ç©¶å°èªè¨å­¸çè«èå¤§åèªè¨æ¨¡å (LLM) æ´åèµ·ä¾ï¼ä»¥çæèªç¶çä»£ç¢¼è½æææ¬ãå¨æ¬æä¸­ï¼æåä»ç´¹ EZSwitchï¼ä¸åå°ç­å¹ç´æçè« (ECT) è LLM çµåèµ·ä¾çæ°æ¡æ¶ï¼ä»¥ç¢çå¨èªè¨å­¸ä¸ææä¸æµæ¢çä»£ç¢¼è½æææ¬ãæåä½¿ç¨äººé¡å¤æ·åèªååææ¨ä¾è©ä¼°æåçæ¨¡åï¼è­æèåºæº LLM ç¸æ¯ï¼çæçä»£ç¢¼è½æå¥å­çåè³ªæé¡¯èçæåãçºäºè§£æ±ºç¼ºä¹åé©è©ä¼°ææ¨çåé¡ï¼æåå°åç¨®èªååææ¨èäººé¡è©åé²è¡å¨é¢çç¸éæ§ç ç©¶ï¼ç¼ç¾ç¶åçææ¨éå¸¸ç¡æ³ææä»£ç¢¼è½æææ¬çç´°å¾®æµæ¢åº¦ãæ­¤å¤ï¼æåå»ºç«äº CSPrefï¼ä¸ååºæ¼äººé¡è©åçåå¥½è³æéï¼ä¸¦åææ¨¡åå¨ãå°é£ãåãå®¹æãç¯ä¾çè¡¨ç¾ãæåçç¼ç¾è¡¨æï¼å°èªè¨éå¶ç´å¥ LLM æå°è´æ´å¼·å¥ä¸èäººé¡ä¸è´ççæï¼çºè·¨è¶ä¸åèªè¨å°çå¯æ´åä»£ç¢¼è½æææ¬çæéªè·¯ã

##### **Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation**
2410.22658v1 by Daehee Lee, Minjong Yoo, Woo Kyung Kim, Wonje Choi, Honguk Woo

Continual Imitation Learning (CiL) involves extracting and accumulating task
knowledge from demonstrations across multiple stages and tasks to achieve a
multi-task policy. With recent advancements in foundation models, there has
been a growing interest in adapter-based CiL approaches, where adapters are
established parameter-efficiently for tasks newly demonstrated. While these
approaches isolate parameters for specific tasks and tend to mitigate
catastrophic forgetting, they limit knowledge sharing among different
demonstrations. We introduce IsCiL, an adapter-based CiL framework that
addresses this limitation of knowledge sharing by incrementally learning
shareable skills from different demonstrations, thus enabling sample-efficient
task adaptation using the skills particularly in non-stationary CiL
environments. In IsCiL, demonstrations are mapped into the state embedding
space, where proper skills can be retrieved upon input states through
prototype-based memory. These retrievable skills are incrementally learned on
their corresponding adapters. Our CiL experiments with complex tasks in
Franka-Kitchen and Meta-World demonstrate robust performance of IsCiL in both
task adaptation and sample-efficiency. We also show a simple extension of IsCiL
for task unlearning scenarios.

æè¦ï¼æçºæ¨¡ä»¿å­¸ç¿ (CiL) æ¶åå¾å¤åéæ®µåä»»åçç¤ºç¯ä¸­æååç´¯ç©ä»»åç¥è­ï¼ä»¥éæå¤ä»»åç­ç¥ãé¨èåºç¤æ¨¡åçææ°é²å±ï¼åºæ¼é©éå¨ç CiL æ¹æ³å¼èµ·äºè¶ä¾è¶å¤§çèè¶£ï¼å¶ä¸­é©éå¨æéå°æ°ç¤ºç¯ä»»åä»¥åæ¸ææççæ¹å¼å»ºç«ãéç¶éäºæ¹æ³æéå°ç¹å®ä»»åéé¢åæ¸ï¼ä¸¦å¾åæ¼æ¸è¼ç½é£æ§éºå¿ï¼ä½å®åæéå¶ä¸åç¤ºç¯ä¹éçç¥è­å±äº«ãæåå¼å¥äºåºæ¼é©éå¨ç CiL æ¶æ§ IsCiLï¼å®éééæ­¥å­¸ç¿ä¸åç¤ºç¯çå¯å±äº«æè½ä¾è§£æ±ºç¥è­å±äº«çéåéå¶ï¼å¾èè½å¤ ä½¿ç¨æè½ï¼ç¹å¥æ¯å¨éå¹³ç©© CiL ç°å¢ä¸­ï¼é²è¡æ¨£æ¬ææççä»»åé©æãå¨ IsCiL ä¸­ï¼ç¤ºç¯æå°æå°çæåµå¥ç©ºéï¼å¶ä¸­å¯ä»¥ééåºæ¼ååçè¨æ¶å¨è¼¸å¥çæææ·åé©ç¶çæè½ãéäºå¯æ·åçæè½æå¨å®åç¸å°æçé©éå¨ä¸éæ­¥å­¸ç¿ãæåå¨ Franka-Kitchen å Meta-World ä¸­ä½¿ç¨è¤éä»»åé²è¡ç CiL å¯¦é©è­æäº IsCiL å¨ä»»åé©æåæ¨£æ¬æçæ¹é¢é½æç©©å¥çæè½ãæåä¹å±ç¤ºäº IsCiL å¨ä»»ååæ¶å­¸ç¿å ´æ¯ä¸­çç°¡å®å»¶ä¼¸ã

##### **Prove Your Point!: Bringing Proof-Enhancement Principles to Argumentative Essay Generation**
2410.22642v1 by Ruiyu Xiao, Lei Wu, Yuhang Gou, Weinan Zhang, Ting Liu

Argumentative essay generation (AEG) aims to generate complete texts on
specific controversial topics or debates. Although current AEG methods can
generate individual opinions, they often overlook the high-level connections
between these opinions. This often leads to the generated results being mired
in logical confusion, unable to proof their own arguments effectively. The
generated essay may present evidence that contradicts the claims or they may
fail to assemble the claims into logical flow. In this paper, we present a
unified two-stage framework: Proof-Enhancement and Self-Annotation (PESA) for
AEG with a focus on logical enhancement. Specifically, we first construct
pseudo-labels for logical information,claims and grounds, using a large
language model. We then propose a tree planning approach that introduces proof
principles and ensures logical consistency. Extensive experimental results show
that, benefiting from proof principle guidance, PESA generates argumentative
essays with better logical validity and persuasiveness than strong baseline
models.

æè¦ï¼è«è­æçæï¼AEGï¼æ¨å¨éå°ç¹å®æç­è­°çä¸»é¡æè¾¯è«ç¢çå®æ´çææ¬ãåç®¡ç®åç AEG æ¹æ³å¯ä»¥ç¢çåå¥æè¦ï¼ä½å®åå¸¸å¸¸å¿½ç¥éäºæè¦ä¹éçé«å±¤æ¬¡éè¯ãééå¸¸æå°è´çæççµæé·å¥éè¼¯æ··æ·ï¼ç¡æ³ææå°è­æèªå·±çè«é»ãçæçè«æå¯è½ææåºèä¸»å¼µç¸çç¾çè­æï¼æèå¯è½ç¡æ³å°ä¸»å¼µçµåæéè¼¯æµç¨ãå¨æ¬æä¸­ï¼æåæåºäºä¸åçµ±ä¸çå©éæ®µæ¡æ¶ï¼è«è­å¢å¼·åèªæè¨»è§£ï¼PESAï¼ï¼éé»å¨æ¼éè¼¯å¢å¼·ãå·é«ä¾èªªï¼æåé¦åä½¿ç¨å¤§åèªè¨æ¨¡åçºéè¼¯ä¿¡æ¯ãä¸»å¼µåä¾ææ§é å½æ¨ç±¤ãç¶å¾ï¼æåæåºäºä¸ç¨®æ¨¹è¦åæ¹æ³ï¼è©²æ¹æ³å¼å¥äºè­æååä¸¦ç¢ºä¿éè¼¯ä¸è´æ§ãå»£æ³çå¯¦é©çµæè¡¨æï¼å¾çæ¼è­æååçæå°ï¼PESA çæçè«è­ææ¯å¼·å¤§çåºç·æ¨¡åå·ææ´å¥½çéè¼¯æææ§åèªªæåã

##### **Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection**
2410.22619v1 by Plabon Paul, Md. Nazmul Islam, Fazle Rafsani, Pegah Khorasani, Shovito Barua Soumma

Uncontrolled cell division in the brain is what gives rise to brain tumors.
If the tumor size increases by more than half, there is little hope for the
patient's recovery. This emphasizes the need of rapid and precise brain tumor
diagnosis. When it comes to analyzing, diagnosing, and planning therapy for
brain tumors, MRI imaging plays a crucial role. A brain tumor's development
history is crucial information for doctors to have. When it comes to
distinguishing between human soft tissues, MRI scans are superior. In order to
get reliable classification results from MRI scans quickly, deep learning is
one of the most practical methods. Early human illness diagnosis has been
demonstrated to be more accurate when deep learning methods are used. In the
case of diagnosing a brain tumor, when even a little misdiagnosis might have
serious consequences, accuracy is especially important. Disclosure of brain
tumors in medical images is still a difficult task. Brain MRIs are notoriously
imprecise in revealing the presence or absence of tumors. Using MRI scans of
the brain, a Convolutional Neural Network (CNN) was trained to identify the
presence of a tumor in this research. Results from the CNN model showed an
accuracy of 99.17%. The CNN model's characteristics were also retrieved. In
order to evaluate the CNN model's capability for processing images, we applied
the features via the following machine learning models: KNN, Logistic
regression, SVM, Random Forest, Naive Bayes, and Perception. CNN and machine
learning models were also evaluated using the standard metrics of Precision,
Recall, Specificity, and F1 score. The significance of the doctor's diagnosis
enhanced the accuracy of the CNN model's assistance in identifying the
existence of tumor and treating the patient.

æè¦ï¼è¦é¨ç´°èåè£å¤±æ§ï¼å°±æç¢çè¦ç¤ã
å¦æè«ç¤å¤§å°å¢å è¶éä¸åï¼çæ£åº·å¾©çå¸æå¾æ¸ºè«ãéå¼·èª¿äºå¿«éä¸ç²¾æºè¨ºæ·è¦ç¤çå¿è¦æ§ã
å¨åæãè¨ºæ·åè¦åè¦ç¤æ²»çæï¼æ ¸ç£å±æ¯é å½±æ®æ¼äºè³ééè¦çè§è²ãè¦ç¤çç¼å±å²æ¯é«çå¿åçéè¦è³è¨ã
å¨ååäººé«è»çµç¹æï¼æ ¸ç£å±æ¯ææçè¡¨ç¾åªç°ãçºäºå¾æ ¸ç£å±æ¯ææä¸­å¿«éåå¾å¯é çåé¡çµæï¼æ·±åº¦å­¸ç¿æ¯æå¯¦ç¨çæ¹æ³ä¹ä¸ã
ç ç©¶é¡¯ç¤ºï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³å¯ä»¥æ´æºç¢ºå°è¨ºæ·äººé¡æ©æç¾çãå¨è¨ºæ·è¦ç¤æï¼å³ä½¿æ¯è¼å¾®çèª¤è¨ºé½å¯è½é æå´éå¾æï¼å æ­¤æºç¢ºæ§ç¹å¥éè¦ã
å¨é«å­¸å½±åä¸­æ­é²è¦ç¤ä»ç¶æ¯ä¸é è±é£çä»»åãè¦é¨æ ¸ç£å±æ¯é å½±å¨æ­é²è«ç¤çå­å¨èå¦æ¹é¢åºäºåçä¸ç²¾ç¢ºã
æ¬ç ç©¶è¨ç·´äºä¸åå·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼ä½¿ç¨è¦é¨æ ¸ç£å±æ¯ææä¾è¾¨è­è«ç¤çå­å¨ãCNN æ¨¡åççµæé¡¯ç¤ºæºç¢ºåº¦çº 99.17%ãCNN æ¨¡åçç¹å¾µä¹å·²æ·åã
çºäºè©ä¼° CNN æ¨¡åèçå½±åçè½åï¼æåééä»¥ä¸æ©å¨å­¸ç¿æ¨¡åå¥ç¨éäºç¹å¾µï¼KNNãéè¼¯è¿´æ­¸ãSVMãé¨æ©æ£®æãæ¨¸ç´ è²æ°åæç¥å¨ãCNN åæ©å¨å­¸ç¿æ¨¡åä¹ä½¿ç¨ç²¾æºåº¦ãå¬åçãç¹ç°æ§å F1 åæ¸ç­æ¨æºææ¨é²è¡è©ä¼°ã
é«ççè¨ºæ·æç¾©æåäº CNN æ¨¡åå¨åå©è¾¨è­è«ç¤å­å¨åæ²»ççæ£æ¹é¢çæºç¢ºæ§ã

##### **CoGS: Model Agnostic Causality Constrained Counterfactual Explanations using goal-directed ASP**
2410.22615v1 by Sopam Dasgupta, JoaquÃ­n Arias, Elmer Salazar, Gopal Gupta

Machine learning models are increasingly used in critical areas such as loan
approvals and hiring, yet they often function as black boxes, obscuring their
decision-making processes. Transparency is crucial, as individuals need
explanations to understand decisions, primarily if the decisions result in an
undesired outcome. Our work introduces CoGS (Counterfactual Generation with
s(CASP)), a model-agnostic framework capable of generating counterfactual
explanations for classification models. CoGS leverages the goal-directed Answer
Set Programming system s(CASP) to compute realistic and causally consistent
modifications to feature values, accounting for causal dependencies between
them. By using rule-based machine learning algorithms (RBML), notably the
FOLD-SE algorithm, CoGS extracts the underlying logic of a statistical model to
generate counterfactual solutions. By tracing a step-by-step path from an
undesired outcome to a desired one, CoGS offers interpretable and actionable
explanations of the changes required to achieve the desired outcome. We present
details of the CoGS framework along with its evaluation.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨è²¸æ¬¾æ ¸ååèç¨ç­ééµé åä¸­æ¥çå»£æ³å°ä½¿ç¨ï¼ç¶èå®åéå¸¸ä½çºé»çå­éä½ï¼æ¨¡ç³äºå¶æ±ºç­å¶å®éç¨ãéæåº¦è³ééè¦ï¼å çºåäººéè¦è§£éæè½çè§£æ±ºç­ï¼ç¹å¥æ¯å¦ææ±ºç­å°è´äºä¸åæ­¡è¿ççµæãæåçç ç©¶å¼å¥äº CoGSï¼åäºå¯¦çæè s(CASP)ï¼ï¼ä¸åèæ¨¡åç¡éçæ¡æ¶ï¼è½å¤ çºåé¡æ¨¡åçæåäºå¯¦è§£éãCoGS å©ç¨ç®æ¨å°åç Answer Set Programming ç³»çµ± s(CASP) ä¾è¨ç®ç¾å¯¦ä¸å æä¸è´çè®æ´ï¼ä»¥èªªæå¶ç¹å¾µå¼ï¼ä¸¦èæ®å®åä¹éçå æéä¿ãééä½¿ç¨åºæ¼è¦åçæ©å¨å­¸ç¿æ¼ç®æ³ï¼RBMLï¼ï¼å°¤å¶æ¯ FOLD-SE æ¼ç®æ³ï¼CoGS å¾çµ±è¨æ¨¡åä¸­èååºåºå±¤éè¼¯ï¼ä»¥ç¢çåäºå¯¦è§£ãCoGS å¾ä¸åæ­¡è¿ççµæè¿½è¹¤å°çæ³ççµæï¼æä¾äºå¯è§£éä¸å¯è¡çè§£éï¼èªªæäºéæçæ³çµææéçè®æ´ãæåæä¾äº CoGS æ¡æ¶çè©³ç´°è³è¨ï¼ä»¥åå¶è©ä¼°ã

##### **Are Large-Language Models Graph Algorithmic Reasoners?**
2410.22597v1 by Alexander K Taylor, Anthony Cuturrufo, Vishal Yathish, Mingyu Derek Ma, Wei Wang

We seek to address a core challenge facing current Large Language Models
(LLMs). LLMs have demonstrated superior performance in many tasks, yet continue
to struggle with reasoning problems on explicit graphs that require multiple
steps. To address this gap, we introduce a novel benchmark designed to evaluate
LLM performance on classical algorithmic reasoning tasks on explicit graphs.
Our benchmark encompasses five fundamental algorithms: Breadth-First Search
(BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and
Floyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum
Spanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we
assess the capabilities of state-of-the-art LLMs in executing these algorithms
step-by-step and systematically evaluate their performance at each stage. Our
findings highlight the persistent challenges LLMs face in this domain and
underscore the necessity for advanced prompting techniques and algorithmic
instruction to enhance their graph reasoning abilities. This work presents
MAGMA, the first comprehensive benchmark focused on LLMs completing classical
graph algorithms, and provides a critical step toward understanding and
improving their structured problem-solving skills.

æè¦ï¼æåè©¦åè§£æ±ºç¶åå¤§åèªè¨æ¨¡å (LLM) é¢è¨çæ ¸å¿ææ°ãLLM å¨è¨±å¤ä»»åä¸­è¡¨ç¾åºåªç°çæ§è½ï¼ä½ä»é£ä»¥æå°éè¦å¤åæ­¥é©çæç¢ºåè¡¨ä¸­çæ¨çåé¡ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºä¸åæ°çåºæºï¼ç¨æ¼è©ä¼° LLM å¨æç¢ºåè¡¨ä¸çç¶å¸æ¼ç®æ³æ¨çä»»åä¸çæ§è½ãæåçåºæºåå«äºååºæ¬æ¼ç®æ³ï¼å»£åº¦åªåæå° (BFS) åæ·±åº¦åªåæå° (DFS) ä»¥é²è¡é£éæ§ãDijkstra æ¼ç®æ³å Floyd-Warshall æ¼ç®æ³ä»¥æ¾åºææç¯é»çæç­è·¯å¾ï¼ä»¥å Prim æå°çææ¨¹ (MST-Prim) æ¼ç®æ³ãééå»£æ³çå¯¦é©ï¼æåè©ä¼°äºæåé²ç LLM å¨éæ­¥å·è¡éäºæ¼ç®æ³çè½åï¼ä¸¦ç³»çµ±æ§å°è©ä¼°å®åå¨æ¯åéæ®µçæ§è½ãæåçç ç©¶çµæçªåºäº LLM å¨éåé åé¢è¨çæçºææ°ï¼ä¸¦å¼·èª¿äºä½¿ç¨é²éæç¤ºæè¡åæ¼ç®æ³æä»¤ä¾å¢å¼·å¶åå½¢æ¨çè½åçå¿è¦æ§ãéé å·¥ä½æåºäº MAGMAï¼éæ¯ç¬¬ä¸åå°æ³¨æ¼ LLM å®æç¶å¸åå½¢æ¼ç®æ³çç¶ååºæºï¼ä¸¦çºäºè§£åæ¹é²å¶çµæ§ååé¡è§£æ±ºæè½æä¾äºééµçä¸æ­¥ã


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-30**|**EMMA: End-to-End Multimodal Model for Autonomous Driving**|Jyh-Jing Hwang et.al.|[2410.23262v1](http://arxiv.org/abs/2410.23262v1)|null|
|**2024-10-30**|**ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**|Zhichao Hou et.al.|[2410.23182v1](http://arxiv.org/abs/2410.23182v1)|null|
|**2024-10-30**|**Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**|Deperias Kerre et.al.|[2410.22996v1](http://arxiv.org/abs/2410.22996v1)|null|
|**2024-10-30**|**How Well Do Large Language Models Disambiguate Swedish Words?**|Richard Johansson et.al.|[2410.22827v1](http://arxiv.org/abs/2410.22827v1)|null|
|**2024-10-30**|**Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**|Sejin Lee et.al.|[2410.22767v1](http://arxiv.org/abs/2410.22767v1)|[link](https://github.com/eastha0526/beyond-ontology-in-dst)|
|**2024-10-29**|**Are Large-Language Models Graph Algorithmic Reasoners?**|Alexander K Taylor et.al.|[2410.22597v1](http://arxiv.org/abs/2410.22597v1)|null|
|**2024-10-29**|**Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset**|Adrian Garret Gabriel et.al.|[2410.22457v1](http://arxiv.org/abs/2410.22457v1)|null|
|**2024-10-29**|**ADAM: An Embodied Causal Agent in Open-World Environments**|Shu Yu et.al.|[2410.22194v1](http://arxiv.org/abs/2410.22194v1)|null|
|**2024-10-29**|**A Hierarchical Language Model For Interpretable Graph Reasoning**|Sambhav Khurana et.al.|[2410.22372v1](http://arxiv.org/abs/2410.22372v1)|null|
|**2024-10-28**|**LLM-Forest for Health Tabular Data Imputation**|Xinrui He et.al.|[2410.21520v1](http://arxiv.org/abs/2410.21520v1)|null|
|**2024-10-28**|**Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**|Zhantao Yang et.al.|[2410.21237v1](http://arxiv.org/abs/2410.21237v1)|null|
|**2024-10-28**|**CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**|Meiqi Chen et.al.|[2410.21067v1](http://arxiv.org/abs/2410.21067v1)|null|
|**2024-10-28**|**CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**|Yutong Cheng et.al.|[2410.21060v1](http://arxiv.org/abs/2410.21060v1)|null|
|**2024-10-28**|**Graph-based Uncertainty Metrics for Long-form Language Model Outputs**|Mingjian Jiang et.al.|[2410.20783v1](http://arxiv.org/abs/2410.20783v1)|[link](https://github.com/mingjianjiang-1/graph-based-uncertainty)|
|**2024-10-28**|**Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**|Prakhar Verma et.al.|[2410.20753v1](http://arxiv.org/abs/2410.20753v1)|null|
|**2024-10-28**|**Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**|Mufei Li et.al.|[2410.20724v1](http://arxiv.org/abs/2410.20724v1)|null|
|**2024-10-27**|**Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs**|Xingrui Zhuo et.al.|[2410.20321v1](http://arxiv.org/abs/2410.20321v1)|null|
|**2024-10-26**|**Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts**|Vishesh Prasad et.al.|[2410.21324v1](http://arxiv.org/abs/2410.21324v1)|null|
|**2024-10-25**|**DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**|Pengfei Hu et.al.|[2410.19955v1](http://arxiv.org/abs/2410.19955v1)|null|
|**2024-10-25**|**FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**|Nicole Cho et.al.|[2410.19727v1](http://arxiv.org/abs/2410.19727v1)|null|
|**2024-10-25**|**Knowledge Graph Enhanced Language Agents for Recommendation**|Taicheng Guo et.al.|[2410.19627v1](http://arxiv.org/abs/2410.19627v1)|null|
|**2024-10-25**|**Graph Linearization Methods for Reasoning on Graphs with Large Language Models**|Christos Xypolopoulos et.al.|[2410.19494v1](http://arxiv.org/abs/2410.19494v1)|null|
|**2024-10-25**|**Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis**|Weikai Li et.al.|[2410.19225v1](http://arxiv.org/abs/2410.19225v1)|null|
|**2024-10-24**|**Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media**|Bruno Croso Cunha da Silva et.al.|[2410.19193v1](http://arxiv.org/abs/2410.19193v1)|null|
|**2024-10-24**|**GCoder: Improving Large Language Model for Generalized Graph Problem Solving**|Qifan Zhang et.al.|[2410.19084v1](http://arxiv.org/abs/2410.19084v1)|[link](https://github.com/bklight999/www25-gcoder)|
|**2024-10-24**|**LLM-based Online Prediction of Time-varying Graph Signals**|Dayu Qin et.al.|[2410.18718v1](http://arxiv.org/abs/2410.18718v1)|null|
|**2024-10-24**|**Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production**|Kexuan Xin et.al.|[2410.18475v2](http://arxiv.org/abs/2410.18475v2)|null|
|**2024-10-24**|**ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**|Zezhong Wang et.al.|[2410.18447v1](http://arxiv.org/abs/2410.18447v1)|null|
|**2024-10-24**|**Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains**|Kun Li et.al.|[2410.18415v1](http://arxiv.org/abs/2410.18415v1)|null|
|**2024-10-23**|**Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**|Jaime Sevilla et.al.|[2410.18060v1](http://arxiv.org/abs/2410.18060v1)|null|
|**2024-10-23**|**Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective**|Rui Yang et.al.|[2410.17600v1](http://arxiv.org/abs/2410.17600v1)|null|
|**2024-10-23**|**Navigate Complex Physical Worlds via Geometrically Constrained LLM**|Yongqiang Huang et.al.|[2410.17529v1](http://arxiv.org/abs/2410.17529v1)|null|
|**2024-10-22**|**Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs**|Leyao Wang et.al.|[2410.16882v1](http://arxiv.org/abs/2410.16882v1)|null|
|**2024-10-22**|**Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning**|Muzhi Li et.al.|[2410.16803v1](http://arxiv.org/abs/2410.16803v1)|null|
|**2024-10-22**|**The Scene Language: Representing Scenes with Programs, Words, and Embeddings**|Yunzhi Zhang et.al.|[2410.16770v1](http://arxiv.org/abs/2410.16770v1)|null|
|**2024-10-22**|**Atomic Fact Decomposition Helps Attributed Question Answering**|Zhichao Yan et.al.|[2410.16708v1](http://arxiv.org/abs/2410.16708v1)|null|
|**2024-10-22**|**PLDR-LLM: Large Language Model from Power Law Decoder Representations**|Burc Gokden et.al.|[2410.16703v1](http://arxiv.org/abs/2410.16703v1)|[link](https://github.com/burcgokden/llm-from-power-law-decoder-representations)|
|**2024-10-22**|**Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for Improved Coverage and Efficiency**|Prafulla Kumar Choubey et.al.|[2410.16597v1](http://arxiv.org/abs/2410.16597v1)|null|
|**2024-10-21**|**Towards a Reliable Offline Personal AI Assistant for Long Duration Spaceflight**|Oliver Bensch et.al.|[2410.16397v1](http://arxiv.org/abs/2410.16397v1)|null|
|**2024-10-21**|**A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns**|Tianyi Men et.al.|[2410.16155v1](http://arxiv.org/abs/2410.16155v1)|null|
|**2024-10-21**|**CausalGraph2LLM: Evaluating LLMs for Causal Queries**|Ivaxi Sheth et.al.|[2410.15939v1](http://arxiv.org/abs/2410.15939v1)|[link](https://github.com/ivaxi0s/causalgraph2llm)|
|**2024-10-21**|**LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation**|Tejumade Afonja et.al.|[2410.15828v1](http://arxiv.org/abs/2410.15828v1)|null|
|**2024-10-21**|**NetSafe: Exploring the Topological Safety of Multi-agent Networks**|Miao Yu et.al.|[2410.15686v1](http://arxiv.org/abs/2410.15686v1)|null|
|**2024-10-20**|**TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models**|Bo Pan et.al.|[2410.15268v1](http://arxiv.org/abs/2410.15268v1)|null|
|**2024-10-19**|**Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction**|Yinhan He et.al.|[2410.15165v1](http://arxiv.org/abs/2410.15165v1)|null|
|**2024-10-19**|**MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science**|Junho Kim et.al.|[2410.15126v1](http://arxiv.org/abs/2410.15126v1)|null|
|**2024-10-19**|**Coarse-to-Fine Highlighting: Reducing Knowledge Hallucination in Large Language Models**|Qitan Lv et.al.|[2410.15116v1](http://arxiv.org/abs/2410.15116v1)|null|
|**2024-10-19**|**A Prompt Engineering Approach and a Knowledge Graph based Framework for Tackling Legal Implications of Large Language Model Answers**|George Hannah et.al.|[2410.15064v1](http://arxiv.org/abs/2410.15064v1)|null|
|**2024-10-19**|**LangGFM: A Large Language Model Alone Can be a Powerful Graph Foundation Model**|Tianqianjin Lin et.al.|[2410.14961v1](http://arxiv.org/abs/2410.14961v1)|null|
|**2024-10-18**|**TransBox: EL++-closed Ontology Embedding**|Hui Yang et.al.|[2410.14571v1](http://arxiv.org/abs/2410.14571v1)|null|
|**2024-10-18**|**Enabling Scalable Evaluation of Bias Patterns in Medical LLMs**|Hamed Fayyaz et.al.|[2410.14763v1](http://arxiv.org/abs/2410.14763v1)|[link](https://github.com/healthylaife/autofair)|
|**2024-10-18**|**Paths-over-Graph: Knowledge Graph Empowered Large Language Model Reasoning**|Xingyu Tan et.al.|[2410.14211v2](http://arxiv.org/abs/2410.14211v2)|null|
|**2024-10-18**|**UniMTS: Unified Pre-training for Motion Time Series**|Xiyuan Zhang et.al.|[2410.19818v1](http://arxiv.org/abs/2410.19818v1)|[link](https://github.com/xiyuanzh/unimts)|
|**2024-10-18**|**Supervised Chain of Thought**|Xiang Zhang et.al.|[2410.14198v1](http://arxiv.org/abs/2410.14198v1)|null|
|**2024-10-17**|**Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs**|Simone Conia et.al.|[2410.14057v1](http://arxiv.org/abs/2410.14057v1)|null|
|**2024-10-17**|**RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs**|Jiatan Huang et.al.|[2410.13987v1](http://arxiv.org/abs/2410.13987v1)|null|
|**2024-10-17**|**The Mystery of the Pathological Path-star Task for Language Models**|Arvid Frydenlund et.al.|[2410.13779v1](http://arxiv.org/abs/2410.13779v1)|null|
|**2024-10-17**|**Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval**|Yu Xia et.al.|[2410.13765v1](http://arxiv.org/abs/2410.13765v1)|null|
|**2024-10-17**|**LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models**|David Hoffmann et.al.|[2410.13299v1](http://arxiv.org/abs/2410.13299v1)|null|
|**2024-10-17**|**Trust but Verify: Programmatic VLM Evaluation in the Wild**|Viraj Prabhu et.al.|[2410.13121v1](http://arxiv.org/abs/2410.13121v1)|null|
|**2024-10-16**|**Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models**|Linhao Luo et.al.|[2410.13080v1](http://arxiv.org/abs/2410.13080v1)|[link](https://github.com/RManLuo/graph-constrained-reasoning)|
|**2024-10-16**|**Supply Chain Network Extraction and Entity Classification Leveraging Large Language Models**|Tong Liu et.al.|[2410.13051v1](http://arxiv.org/abs/2410.13051v1)|null|
|**2024-10-16**|**Learning Representations for Reasoning: Generalizing Across Diverse Structures**|Zhaocheng Zhu et.al.|[2410.13018v1](http://arxiv.org/abs/2410.13018v1)|null|
|**2024-10-16**|**Large Language Models as a Tool for Mining Object Knowledge**|Hannah YoungEun An et.al.|[2410.12959v1](http://arxiv.org/abs/2410.12959v1)|null|
|**2024-10-16**|**FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**|Zhenheng Tang et.al.|[2410.12707v1](http://arxiv.org/abs/2410.12707v1)|null|
|**2024-10-16**|**The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph**|Minghao Wu et.al.|[2410.12458v1](http://arxiv.org/abs/2410.12458v1)|null|
|**2024-10-16**|**PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking**|Markus J. Buehler et.al.|[2410.12375v1](http://arxiv.org/abs/2410.12375v1)|[link](https://github.com/lamm-mit/PRefLexOR)|
|**2024-10-16**|**Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs**|Lei Sun et.al.|[2410.12298v2](http://arxiv.org/abs/2410.12298v2)|null|
|**2024-10-16**|**LLM-based Cognitive Models of Students with Misconceptions**|Shashank Sonkar et.al.|[2410.12294v2](http://arxiv.org/abs/2410.12294v2)|null|
|**2024-10-16**|**Comprehending Knowledge Graphs with Large Language Models for Recommender Systems**|Ziqiang Cui et.al.|[2410.12229v1](http://arxiv.org/abs/2410.12229v1)|null|
|**2024-10-16**|**Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations**|Luyi Ma et.al.|[2410.12228v1](http://arxiv.org/abs/2410.12228v1)|null|
|**2024-10-16**|**Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning**|Huiwen Wu et.al.|[2410.12130v1](http://arxiv.org/abs/2410.12130v1)|null|
|**2024-10-15**|**Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning**|Guangxin Su et.al.|[2410.12096v1](http://arxiv.org/abs/2410.12096v1)|null|
|**2024-10-15**|**A Survey on Deep Tabular Learning**|Shriyank Somvanshi et.al.|[2410.12034v1](http://arxiv.org/abs/2410.12034v1)|null|
|**2024-10-15**|**Causal Reasoning in Large Language Models: A Knowledge Graph Approach**|Yejin Kim et.al.|[2410.11588v1](http://arxiv.org/abs/2410.11588v1)|null|
|**2024-10-15**|**Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development**|Tengfei Ma et.al.|[2410.11550v1](http://arxiv.org/abs/2410.11550v1)|null|
|**2024-10-15**|**AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data**|Xinjie Zhao et.al.|[2410.11531v1](http://arxiv.org/abs/2410.11531v1)|null|
|**2024-10-15**|**Do LLMs Have the Generalization Ability in Conducting Causal Inference?**|Chen Wang et.al.|[2410.11385v1](http://arxiv.org/abs/2410.11385v1)|[link](https://github.com/prayingsociety/ci_bench)|
|**2024-10-15**|**Enhance Graph Alignment for Large Language Models**|Haitong Luo et.al.|[2410.11370v1](http://arxiv.org/abs/2410.11370v1)|null|
|**2024-10-15**|**Unleashing the Power of LLMs as Multi-Modal Encoders for Text and Graph-Structured Data**|Jiacheng Lin et.al.|[2410.11235v1](http://arxiv.org/abs/2410.11235v1)|null|
|**2024-10-15**|**Tree of Attributes Prompt Learning for Vision-Language Models**|Tong Ding et.al.|[2410.11201v1](http://arxiv.org/abs/2410.11201v1)|null|
|**2024-10-14**|**Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs**|Haozhen Zhang et.al.|[2410.11001v1](http://arxiv.org/abs/2410.11001v1)|[link](https://github.com/ulab-uiuc/gor)|
|**2024-10-14**|**NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models**|Yanbiao Ji et.al.|[2410.10743v1](http://arxiv.org/abs/2410.10743v1)|null|
|**2024-10-14**|**GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs**|Yun Zhu et.al.|[2410.10329v3](http://arxiv.org/abs/2410.10329v3)|[link](https://github.com/zhuyun97/graphclip)|
|**2024-10-14**|**Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning**|Hongyi Yuan et.al.|[2410.10144v1](http://arxiv.org/abs/2410.10144v1)|null|
|**2024-10-14**|**Language Model Preference Evaluation with Multiple Weak Evaluators**|Zhengyu Hu et.al.|[2410.12869v1](http://arxiv.org/abs/2410.12869v1)|null|
|**2024-10-14**|**Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?**|Yifan Feng et.al.|[2410.10083v2](http://arxiv.org/abs/2410.10083v2)|[link](https://github.com/imoonlab/llm4hypergraph)|
|**2024-10-13**|**Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation**|Jiarui Ji et.al.|[2410.09824v2](http://arxiv.org/abs/2410.09824v2)|null|
|**2024-10-13**|**A Mixed-Language Multi-Document News Summarization Dataset and a Graphs-Based Extract-Generate Model**|Shengxiang Gao et.al.|[2410.09773v1](http://arxiv.org/abs/2410.09773v1)|null|
|**2024-10-13**|**Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG**|Xinxi Chen et.al.|[2410.09699v1](http://arxiv.org/abs/2410.09699v1)|null|
|**2024-10-12**|**LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning**|Jiachun Li et.al.|[2410.09541v1](http://arxiv.org/abs/2410.09541v1)|[link](https://github.com/bugmakerzzz/linked_code)|
|**2024-10-12**|**Text Classification using Graph Convolutional Networks: A Comprehensive Survey**|Syed Mustafa Haider Rizvi et.al.|[2410.09399v1](http://arxiv.org/abs/2410.09399v1)|null|
|**2024-10-12**|**Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation**|Jinyoung Park et.al.|[2410.09350v1](http://arxiv.org/abs/2410.09350v1)|null|
|**2024-10-11**|**Natural Language Counterfactual Explanations for Graphs Using Large Language Models**|Flavio Giorgi et.al.|[2410.09295v1](http://arxiv.org/abs/2410.09295v1)|[link](https://github.com/flaat/llm-graph-cf)|
|**2024-10-11**|**ReasonPlanner: Enhancing Autonomous Planning in Dynamic Environments with Temporal Knowledge Graphs and LLMs**|Minh Pham Dinh et.al.|[2410.09252v1](http://arxiv.org/abs/2410.09252v1)|null|
|**2024-10-11**|**Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective**|Bo Ni et.al.|[2410.08985v2](http://arxiv.org/abs/2410.08985v2)|null|
|**2024-10-11**|**When Graph meets Multimodal: Benchmarking on Multimodal Attributed Graphs Learning**|Hao Yan et.al.|[2410.09132v1](http://arxiv.org/abs/2410.09132v1)|[link](https://github.com/sktsherlock/atg)|
|**2024-10-11**|**GIVE: Structured Reasoning with Knowledge Graph Inspired Veracity Extrapolation**|Jiashu He et.al.|[2410.08475v1](http://arxiv.org/abs/2410.08475v1)|null|
|**2024-10-11**|**Logic Error Localization in Student Programming Assignments Using Pseudocode and Graph Neural Networks**|Zhenyu Xu et.al.|[2410.21282v1](http://arxiv.org/abs/2410.21282v1)|null|
|**2024-10-10**|**Privately Learning from Graphs with Applications in Fine-tuning Large Language Models**|Haoteng Yin et.al.|[2410.08299v1](http://arxiv.org/abs/2410.08299v1)|[link](https://github.com/graph-com/pvgalm)|

#### Abstracts
##### **EMMA: End-to-End Multimodal Model for Autonomous Driving**
2410.23262v1 by Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, James Guo, Dragomir Anguelov, Mingxing Tan

We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.
Built on a multi-modal large language model foundation, EMMA directly maps raw
camera sensor data into various driving-specific outputs, including planner
trajectories, perception objects, and road graph elements. EMMA maximizes the
utility of world knowledge from the pre-trained large language models, by
representing all non-sensor inputs (e.g. navigation instructions and ego
vehicle status) and outputs (e.g. trajectories and 3D locations) as natural
language text. This approach allows EMMA to jointly process various driving
tasks in a unified language space, and generate the outputs for each task using
task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by
achieving state-of-the-art performance in motion planning on nuScenes as well
as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also
yields competitive results for camera-primary 3D object detection on the Waymo
Open Dataset (WOD). We show that co-training EMMA with planner trajectories,
object detection, and road graph tasks yields improvements across all three
domains, highlighting EMMA's potential as a generalist model for autonomous
driving applications. However, EMMA also exhibits certain limitations: it can
process only a small amount of image frames, does not incorporate accurate 3D
sensing modalities like LiDAR or radar and is computationally expensive. We
hope that our results will inspire further research to mitigate these issues
and to further evolve the state of the art in autonomous driving model
architectures.

æè¦ï¼<paragraph>æåä»ç´¹ EMMAï¼ä¸ç¨®ç¨æ¼èªåé§é§çç«¯å°ç«¯å¤æ¨¡ææ¨¡åã
å»ºç«å¨å¤æ¨¡æå¤§åèªè¨æ¨¡ååºç¤ä¸ï¼EMMA ç´æ¥å°åå§
ç¸æ©ææ¸¬å¨è³æå°æå°åç¨®ç¹å®æ¼é§é§çè¼¸åºï¼åæ¬è¦åå¨
è»è·¡ãæç¥ç©ä»¶åéè·¯åå½¢åç´ ãEMMA éé
å°ææéææ¸¬å¨è¼¸å¥ï¼ä¾å¦å°èªæç¤ºåèªæ
è»è¼çæï¼åè¼¸åºï¼ä¾å¦è»è·¡å 3D ä½ç½®ï¼è¡¨ç¤ºçºèªç¶
èªè¨æå­ï¼æå¤§åé è¨ç·´å¤§åèªè¨æ¨¡åçä¸çç¥è­æç¨ãéç¨®æ¹æ³è® EMMA è½å¤ å¨çµ±ä¸çèªè¨ç©ºéä¸­å±åèçåç¨®é§é§
ä»»åï¼ä¸¦ä½¿ç¨ç¹å®æ¼ä»»åçæç¤ºç¢çæ¯åä»»åçè¼¸åºãæ ¹æç¶é©ï¼æåéé
å¨ nuScenes ä¸å¯¦ç¾éåè¦åçææ°æè½ï¼ä»¥åå¨ Waymo Open Motion Dataset (WOMD) ä¸ç²å¾ç«¶ç­åçµæï¼ä¾è­æ EMMA çæææ§ãEMMA ä¹
å¨ Waymo Open Dataset (WOD) ä¸ç¢çäºç¸æ©åªå 3D ç©ä»¶åµæ¸¬çç«¶ç­åçµæãæåå±ç¤ºäºä½¿ç¨è¦åå¨è»è·¡ã
ç©ä»¶åµæ¸¬åéè·¯åå½¢ä»»åå±åè¨ç·´ EMMAï¼æå¨ææä¸å
é åä¸­ç¢çæ¹é²ï¼çªé¡¯äº EMMA ä½çºèªåé§é§æç¨ç¨å¼éç¨æ¨¡åçæ½åãç¶èï¼EMMA ä¹å±ç¾åºæäºéå¶ï¼å®åªè½
èçå°éå½±åå¹ï¼ä¸æ´åæºç¢ºç 3D ææ¸¬æ¨¡å¼ï¼ä¾å¦ LiDAR æé·éï¼ï¼èä¸è¨ç®ææ¬é«æãæå
å¸ææåççµæè½æ¿åµé²ä¸æ­¥çç ç©¶ï¼ä»¥æ¸è¼éäºåé¡ï¼ä¸¦é²ä¸æ­¥ç¼å±èªåé§é§æ¨¡å
æ¶æ§çææ°æè¡ã</paragraph>

##### **ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**
2410.23182v1 by Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu

Transformer-based architectures have dominated various areas of machine
learning in recent years. In this paper, we introduce a novel robust attention
mechanism designed to enhance the resilience of transformer-based
architectures. Crucially, this technique can be integrated into existing
transformers as a plug-and-play layer, improving their robustness without the
need for additional training or fine-tuning. Through comprehensive experiments
and ablation studies, we demonstrate that our ProTransformer significantly
enhances the robustness of transformer models across a variety of prediction
tasks, attack mechanisms, backbone architectures, and data domains. Notably,
without further fine-tuning, the ProTransformer consistently improves the
performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT,
ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler
attack. Furthermore, ProTransformer shows promising resilience in large
language models (LLMs) against prompting-based attacks, improving the
performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing
Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the
language domain, ProTransformer also demonstrates outstanding robustness in
both vision and graph domains.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼åºæ¼ Transformer çæ¶æ§ä¸»å°äºæ©å¨å­¸ç¿çååé åãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ç¨®æ°ç©ä¸å¼·å¤§çæ³¨æåæ©å¶ï¼æ¨å¨å¢å¼·åºæ¼ Transformer çæ¶æ§çéæ§ãè³ééè¦çæ¯ï¼æ­¤æè¡å¯ä»¥ä½çºå³æå³ç¨çå±¤æ´åå°ç¾æç Transformer ä¸­ï¼å¨ç¡éé¡å¤è¨ç·´æå¾®èª¿çææ³ä¸æé«å¶ç©©å¥æ§ãééå¨é¢çå¯¦é©åæ¶èç ç©¶ï¼æåè­æäºæåç ProTransformer å¨åç¨®é æ¸¬ä»»åãæ»ææ©å¶ãä¸»å¹¹æ¶æ§åæ¸æé åä¸­é¡¯èå¢å¼·äº Transformer æ¨¡åçç©©å¥æ§ãå¼å¾æ³¨æçæ¯ï¼å¨ä¸é²ä¸æ­¥å¾®èª¿çææ³ä¸ï¼ProTransformer å¨ç¶å¸ç TextFooler æ»æä¸ï¼åå¥çº BERTãALBERTãDistilBERT å RoBERTa æåäº 19.5%ã28.3%ã16.1% å 11.4% çæ§è½ãæ­¤å¤ï¼ProTransformer å¨åºæ¼æç¤ºçæ»æä¸­å°å¤§åèªè¨æ¨¡å (LLM) é¡¯ç¤ºåºæå¸æçéæ§ï¼åå¥å° T5 å LLaMA çæ§è½æåäº 24.8% å 17.8%ï¼ä¸¦å¨è¶çæ»æä¸­å° Vicuna çæ§è½å¹³åæåäº 10.4%ãé¤äºèªè¨é åä¹å¤ï¼ProTransformer å¨è¦è¦ºååå½¢é åä¹è¡¨ç¾åºåºè²çç©©å¥æ§ã</paragraph>

##### **Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**
2410.22996v1 by Deperias Kerre, Anne Laurent, Kenneth Maussang, Dickson Owuor

A well structured collection of the various Quantum Cascade Laser (QCL)
design and working properties data provides a platform to analyze and
understand the relationships between these properties. By analyzing these
relationships, we can gain insights into how different design features impact
laser performance properties such as the working temperature. Most of these QCL
properties are captured in scientific text. There is therefore need for
efficient methodologies that can be utilized to extract QCL properties from
text and generate a semantically enriched and interlinked platform where the
properties can be analyzed to uncover hidden relations. There is also the need
to maintain provenance and reference information on which these properties are
based. Semantic Web technologies such as Ontologies and Knowledge Graphs have
proven capability in providing interlinked data platforms for knowledge
representation in various domains. In this paper, we propose an approach for
generating a QCL properties Knowledge Graph (KG) from text for semantic
enrichment of the properties. The approach is based on the QCL ontology and a
Retrieval Augmented Generation (RAG) enabled information extraction pipeline
based on GPT 4-Turbo language model. The properties of interest include:
working temperature, laser design type, lasing frequency, laser optical power
and the heterostructure. The experimental results demonstrate the feasibility
and effectiveness of this approach for efficiently extracting QCL properties
from unstructured text and generating a QCL properties Knowledge Graph, which
has potential applications in semantic enrichment and analysis of QCL data.

æè¦ï¼ä¸åçµæ§è¯å¥½çåç¨®éå­å±¤çé·å° (QCL) è¨­è¨åå·¥ä½ç¹æ§æ¸æéåï¼æä¾äºä¸åå¹³å°ä¾åæåçè§£éäºç¹æ§ä¹éçéä¿ãééåæéäºéä¿ï¼æåå¯ä»¥æ·±å¥äºè§£ä¸åçè¨­è¨ç¹å¾µå¦ä½å½±é¿é·å°æè½ç¹æ§ï¼ä¾å¦å·¥ä½æº«åº¦ãéäº QCL ç¹æ§å¤§å¤æ¸é½ææå¨ç§å­¸æå­ä¸­ãå æ­¤ï¼éè¦ææçæ¹æ³ï¼å¯ä»¥ç¨æ¼å¾æå­ä¸­èå QCL ç¹æ§ï¼ä¸¦ç¢çä¸åèªç¾©è±å¯ä¸ç¸äºé£çµçå¹³å°ï¼å¯ä»¥å¨å¶ä¸­åæéäºç¹æ§ä»¥ç¼ç¾é±èçéä¿ãééè¦ç¶­è­·éäºç¹æ§æä¾æçä¾æºååèè³è¨ãèªç¾©ç¶²è·¯æè¡ï¼ä¾å¦æ¬ä½åç¥è­åè­ï¼å·²è­æå®åå¨æä¾åç¨®é åä¸­ç¥è­è¡¨å¾µçç¸äºé£çµè³æå¹³å°æ¹é¢å·æè½åãå¨æ¬æä¸­ï¼æåæåºä¸åå¾æå­ä¸­ç¢ç QCL ç¹æ§ç¥è­åè­ (KG) çæ¹æ³ï¼ä»¥é²è¡ç¹æ§çèªç¾©è±å¯åãæ­¤æ¹æ³åºæ¼ QCL æ¬ä½ååºæ¼ GPT 4-Turbo èªè¨æ¨¡åçæª¢ç´¢æ´å¢çæ (RAG) åç¨è³è¨èåç®¡ç·ãæèè¶£çç¹æ§åæ¬ï¼å·¥ä½æº«åº¦ãé·å°è¨­è¨é¡åãé·å°é »çãé·å°ååçåç°è³ªçµæ§ãå¯¦é©çµæè­æäºæ­¤æ¹æ³å°æ¼å¾éçµæ§åæå­ä¸­ææèå QCL ç¹æ§åç¢ç QCL ç¹æ§ç¥è­åè­çå¯è¡æ§åæææ§ï¼éå¨ QCL æ¸æçèªç¾©è±å¯åååæä¸­å·ææ½å¨æç¨ã

##### **How Well Do Large Language Models Disambiguate Swedish Words?**
2410.22827v1 by Richard Johansson

We evaluate a battery of recent large language models on two benchmarks for
word sense disambiguation in Swedish. At present, all current models are less
accurate than the best supervised disambiguators in cases where a training set
is available, but most models outperform graph-based unsupervised systems.
Different prompting approaches are compared, with a focus on how to express the
set of possible senses in a given context. The best accuracies are achieved
when human-written definitions of the senses are included in the prompts.

æè¦ï¼æåéå°å©åçå¸èªè©å½æç¾©æ¶æ­§åºæºï¼è©ä¼°ä¸ç³»åè¿æçå¤§åèªè¨æ¨¡åãç®åï¼å¨æè¨ç·´éå¯ç¨çææ³ä¸ï¼ææç¾ææ¨¡åçæºç¢ºåº¦é½ä½æ¼æä½³ç£ç£å¼æ¶æ­§å¨ï¼ä½å¤§å¤æ¸æ¨¡åçè¡¨ç¾é½åªæ¼åºæ¼åå½¢çéç£ç£å¼ç³»çµ±ãæ¯è¼äºä¸åçæç¤ºæ¹æ³ï¼éé»å¨æ¼å¦ä½å¨ç¹å®èçµ¡ä¸­è¡¨éå¯è½çæç¾©éåãç¶æç¤ºä¸­åå«äººé¡æ°å¯«çæç¾©å®ç¾©æï¼å¯éå°æä½³æºç¢ºåº¦ã

##### **Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**
2410.22767v1 by Sejin Lee, Dongha Kim, Min Song

Goal-oriented chatbots are essential for automating user tasks, such as
booking flights or making restaurant reservations. A key component of these
systems is Dialogue State Tracking (DST), which interprets user intent and
maintains the dialogue state. However, existing DST methods often rely on fixed
ontologies and manually compiled slot values, limiting their adaptability to
open-domain dialogues. We propose a novel approach that leverages instruction
tuning and advanced prompt strategies to enhance DST performance, without
relying on any predefined ontologies. Our method enables Large Language Model
(LLM) to infer dialogue states through carefully designed prompts and includes
an anti-hallucination mechanism to ensure accurate tracking in diverse
conversation contexts. Additionally, we employ a Variational Graph Auto-Encoder
(VGAE) to model and predict subsequent user intent. Our approach achieved
state-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST
models, and performed well in open-domain real-world conversations. This work
presents a significant advancement in creating more adaptive and accurate
goal-oriented chatbots.

æè¦ï¼ä»¥ç®æ¨çºå°åçèå¤©æ©å¨äººå¨èªååä½¿ç¨èä»»åä¸­è³ééè¦ï¼ä¾å¦é è¨èªç­æé²è¡é¤å»³è¨ä½ãéäºç³»çµ±çä¸åééµçµæé¨åæ¯å°è©±çæè¿½è¹¤ (DST)ï¼å®æè§£è­¯ä½¿ç¨èçæåä¸¦ç¶­è­·å°è©±çæãç¶èï¼ç¾æç DST æ¹æ³éå¸¸ä¾è³´æ¼åºå®çæ¬ä½åæåç·¨è­¯çæ§½ä½å¼ï¼ééå¶äºå®åå°éæ¾é åå°è©±çé©ææ§ãæåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼å®å©ç¨æä»¤èª¿æ´ååé²çæç¤ºç­ç¥ä¾å¢å¼· DST æè½ï¼èç¡éä¾è³´ä»»ä½é å®ç¾©çæ¬ä½ãæåçæ¹æ³ä½¿å¤§åèªè¨æ¨¡å (LLM) è½å¤ ééç²¾å¿è¨­è¨çæç¤ºä¾æ¨è«å°è©±çæï¼ä¸¦åå«ä¸ååå¹»è¦ºæ©å¶ï¼ä»¥ç¢ºä¿å¨ä¸åçå°è©±æå¢ä¸­æºç¢ºè¿½è¹¤ãæ­¤å¤ï¼æåæ¡ç¨è®ååèªç·¨ç¢¼å¨ (VGAE) ä¾å»ºæ¨¡åé æ¸¬å¾çºä½¿ç¨èçæåãæåçåæ³ä»¥ 42.57% ç JGA éå°äºç¾ææè¡çé å³°ï¼åªæ¼ç¾æçç¡æ¬ä½ DST æ¨¡åï¼ä¸¦å¨éæ¾é åççå¯¦å°è©±ä¸­è¡¨ç¾è¯å¥½ãéé å·¥ä½å¨å»ºç«æ´å·é©ææ§åæºç¢ºæ§çä»¥ç®æ¨çºå°åçèå¤©æ©å¨äººæ¹é¢åå¾äºéå¤§é²å±ã

##### **Are Large-Language Models Graph Algorithmic Reasoners?**
2410.22597v1 by Alexander K Taylor, Anthony Cuturrufo, Vishal Yathish, Mingyu Derek Ma, Wei Wang

We seek to address a core challenge facing current Large Language Models
(LLMs). LLMs have demonstrated superior performance in many tasks, yet continue
to struggle with reasoning problems on explicit graphs that require multiple
steps. To address this gap, we introduce a novel benchmark designed to evaluate
LLM performance on classical algorithmic reasoning tasks on explicit graphs.
Our benchmark encompasses five fundamental algorithms: Breadth-First Search
(BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and
Floyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum
Spanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we
assess the capabilities of state-of-the-art LLMs in executing these algorithms
step-by-step and systematically evaluate their performance at each stage. Our
findings highlight the persistent challenges LLMs face in this domain and
underscore the necessity for advanced prompting techniques and algorithmic
instruction to enhance their graph reasoning abilities. This work presents
MAGMA, the first comprehensive benchmark focused on LLMs completing classical
graph algorithms, and provides a critical step toward understanding and
improving their structured problem-solving skills.

æè¦ï¼æåè©¦åè§£æ±ºç¶åå¤§åèªè¨æ¨¡å (LLM) é¢è¨çæ ¸å¿ææ°ãLLM å¨è¨±å¤ä»»åä¸­è¡¨ç¾åºåªç°çæ§è½ï¼ä½ä»é£ä»¥æå°éè¦å¤åæ­¥é©çæç¢ºåè¡¨ä¸­çæ¨çåé¡ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºä¸åæ°çåºæºï¼ç¨æ¼è©ä¼° LLM å¨æç¢ºåè¡¨ä¸çç¶å¸æ¼ç®æ³æ¨çä»»åä¸çæ§è½ãæåçåºæºåå«äºååºæ¬æ¼ç®æ³ï¼å»£åº¦åªåæå° (BFS) åæ·±åº¦åªåæå° (DFS) ä»¥é²è¡é£éæ§ãDijkstra æ¼ç®æ³å Floyd-Warshall æ¼ç®æ³ä»¥æ¾åºææç¯é»çæç­è·¯å¾ï¼ä»¥å Prim æå°çææ¨¹ (MST-Prim) æ¼ç®æ³ãééå»£æ³çå¯¦é©ï¼æåè©ä¼°äºæåé²ç LLM å¨éæ­¥å·è¡éäºæ¼ç®æ³çè½åï¼ä¸¦ç³»çµ±æ§å°è©ä¼°å®åå¨æ¯åéæ®µçæ§è½ãæåçç ç©¶çµæçªåºäº LLM å¨éåé åé¢è¨çæçºææ°ï¼ä¸¦å¼·èª¿äºä½¿ç¨é²éæç¤ºæè¡åæ¼ç®æ³æä»¤ä¾å¢å¼·å¶åå½¢æ¨çè½åçå¿è¦æ§ãéé å·¥ä½æåºäº MAGMAï¼éæ¯ç¬¬ä¸åå°æ³¨æ¼ LLM å®æç¶å¸åå½¢æ¼ç®æ³çç¶ååºæºï¼ä¸¦çºäºè§£åæ¹é²å¶çµæ§ååé¡è§£æ±ºæè½æä¾äºééµçä¸æ­¥ã

##### **Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset**
2410.22457v1 by Adrian Garret Gabriel, Alaa Alameer Ahmad, Shankar Kumar Jeyakumar

Advancements in Large Language Models (LLMs) are revolutionizing the
development of autonomous agentic systems by enabling dynamic, context-aware
task decomposition and automated tool selection. These sophisticated systems
possess significant automation potential across various industries, managing
complex tasks, interacting with external systems to enhance knowledge, and
executing actions independently. This paper presents three primary
contributions to advance this field:
  - Advanced Agentic Framework: A system that handles multi-hop queries,
generates and executes task graphs, selects appropriate tools, and adapts to
real-time changes.
  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural
Similarity Index (SSI), and Tool F1 Score to comprehensively assess agentic
systems.
  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing
agent behavior across different task complexities.
  Our findings reveal that asynchronous and dynamic task graph decomposition
significantly enhances system responsiveness and scalability, particularly for
complex, multi-step tasks. Detailed analysis shows that structural and
node-level metrics are crucial for sequential tasks, while tool-related metrics
are more important for parallel tasks. Specifically, the Structural Similarity
Index (SSI) is the most significant predictor of performance in sequential
tasks, and the Tool F1 Score is essential for parallel tasks. These insights
highlight the need for balanced evaluation methods that capture both structural
and operational dimensions of agentic systems. Additionally, our evaluation
framework, validated through empirical analysis and statistical testing,
provides valuable insights for improving the adaptability and reliability of
agentic systems in dynamic environments.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çé²å±æ­£ééåç¨åæãå·æå¢æç¥è½åçä»»ååè§£åèªååå·¥å·é¸æï¼é©æ°èªä¸»ä»£çç³»çµ±çéç¼ãéäºç²¾å¯çç³»çµ±å¨åç¢æ¥­ä¸­ææé¡¯èçèªååæ½åï¼ç®¡çè¤éçä»»åãèå¤é¨ç³»çµ±äºåä»¥å¢å¼·ç¥è­ï¼ä¸¦ç¨ç«å·è¡åä½ãæ¬ææåºäºä¸åä¸»è¦è²¢ç»ä»¥æ¨åéåé åçé²å±ï¼
  - é²éä»£çæ¶æ§ï¼ä¸ç¨®èçå¤éè·³èºæ¥è©¢ãç¢çä¸¦å·è¡ä»»ååè¡¨ãé¸æé©ç¶çå·¥å·ï¼ä¸¦é©æå³æè®åçç³»çµ±ã
  - æ°ç©çè©ä¼°ææ¨ï¼å°å¥ç¯é» F1 åæ¸ãçµæ§ç¸ä¼¼æ§ææ¨ (SSI) åå·¥å· F1 åæ¸ï¼ä»¥å¨é¢è©ä¼°ä»£çç³»çµ±ã
  - å°æ¥­è³æéï¼éç¼ä¸ååºæ¼ AsyncHow çè³æéï¼ç¨æ¼åæä»£çè¡çºå¨ä¸åä»»åè¤éåº¦ä¹éçå·®ç°ã
  æåçç ç©¶çµæé¡¯ç¤ºï¼éåæ­¥ååæä»»ååè¡¨åè§£è½é¡¯èå¢å¼·ç³»çµ±çåæè½ååå¯æ´åæ§ï¼ç¹å¥æ¯å°æ¼è¤éçå¤æ­¥é©ä»»åãè©³ç´°çåæé¡¯ç¤ºï¼çµæ§åç¯é»å±¤ç´çææ¨å°æ¼é åºä»»åè³ééè¦ï¼èèå·¥å·ç¸éçææ¨å°æ¼ä¸¦è¡ä»»åæ´çºéè¦ãå·é«ä¾èªªï¼çµæ§ç¸ä¼¼æ§ææ¨ (SSI) æ¯é åºä»»åä¸­æè½æé¡¯èçé æ¸¬ææ¨ï¼èå·¥å· F1 åæ¸å°æ¼ä¸¦è¡ä»»åè³ééè¦ãéäºè¦è§£çªé¡¯äºå¹³è¡¡è©ä¼°æ¹æ³çéæ±ï¼è©²æ¹æ³è½ææä»£çç³»çµ±ççµæ§åæä½é¢åãæ­¤å¤ï¼æåçè©ä¼°æ¶æ§ééå¯¦è­åæåçµ±è¨æª¢å®é©è­ï¼çºæ¹åä»£çç³»çµ±å¨åæç°å¢ä¸­çé©ææ§åå¯é æ§æä¾äºæå¹å¼çè¦è§£ã

##### **ADAM: An Embodied Causal Agent in Open-World Environments**
2410.22194v1 by Shu Yu, Chaochao Lu

In open-world environments like Minecraft, existing agents face challenges in
continuously learning structured knowledge, particularly causality. These
challenges stem from the opacity inherent in black-box models and an excessive
reliance on prior knowledge during training, which impair their
interpretability and generalization capability. To this end, we introduce ADAM,
An emboDied causal Agent in Minecraft, that can autonomously navigate the open
world, perceive multimodal contexts, learn causal world knowledge, and tackle
complex tasks through lifelong learning. ADAM is empowered by four key
components: 1) an interaction module, enabling the agent to execute actions
while documenting the interaction processes; 2) a causal model module, tasked
with constructing an ever-growing causal graph from scratch, which enhances
interpretability and diminishes reliance on prior knowledge; 3) a controller
module, comprising a planner, an actor, and a memory pool, which uses the
learned causal graph to accomplish tasks; 4) a perception module, powered by
multimodal large language models, which enables ADAM to perceive like a human
player. Extensive experiments show that ADAM constructs an almost perfect
causal graph from scratch, enabling efficient task decomposition and execution
with strong interpretability. Notably, in our modified Minecraft games where no
prior knowledge is available, ADAM maintains its performance and shows
remarkable robustness and generalization capability. ADAM pioneers a novel
paradigm that integrates causal methods and embodied agents in a synergistic
manner. Our project page is at https://opencausalab.github.io/ADAM.

æè¦ï¼å¨å Minecraft éæ¨£çéæ¾ä¸çç°å¢ä¸­ï¼ç¾æçä»£çäººé¢è¨æçºå­¸ç¿çµæ§åç¥è­çææ°ï¼å°¤å¶æ¯å æéä¿ãéäºææ°æºæ¼é»çæ¨¡ååºæçä¸éææ§ï¼ä»¥åå¨è¨ç·´æééåº¦ä¾è³´åé©ç¥è­ï¼éææå®³å®åçå¯è§£éæ§åæ³åè½åãçºæ­¤ï¼æåå¼å¥äº ADAMï¼Minecraft ä¸­çä¸åå·èº«å æä»£çï¼å®å¯ä»¥èªä¸»å°èªéæ¾ä¸çï¼æç¥å¤æ¨¡å¼ä¸ä¸æï¼å­¸ç¿å æä¸çç¥è­ï¼ä¸¦ééçµèº«å­¸ç¿ä¾æå°è¤éä»»åãADAM ç±ååééµçµæé¨åè³¦è½ï¼1) ä¸åäº¤äºæ¨¡çµï¼ä½¿ä»£çè½å¤ å·è¡åä½ï¼åæè¨éäº¤äºéç¨ï¼2) ä¸åå ææ¨¡åæ¨¡çµï¼è² è²¬å¾é ­éå§æ§å»ºä¸åä¸æ·å¢é·çå æåï¼éå¢å¼·äºå¯è§£éæ§ä¸¦æ¸å°äºå°åé©ç¥è­çä¾è³´ï¼3) ä¸åæ§å¶å¨æ¨¡çµï¼åæ¬ä¸åè¦åå¨ãä¸åå·è¡å¨åä¸åè¨æ¶æ± ï¼å®ä½¿ç¨å­¸ç¿å°çå æåä¾å®æä»»åï¼4) ä¸åæç¥æ¨¡çµï¼ç±å¤æ¨¡å¼å¤§åèªè¨æ¨¡åæä¾æ¯æ´ï¼ä½¿ ADAM è½å¤ åäººé¡ç©å®¶ä¸æ¨£æç¥ãå¤§éçå¯¦é©è¡¨æï¼ADAM å¾é ­éå§æ§å»ºäºä¸åå¹¾ä¹å®ç¾çå æåï¼å¯¦ç¾äºé«æçä»»ååè§£åå·è¡ï¼ä¸¦å·æå¾å¼·çå¯è§£éæ§ãå¼å¾æ³¨æçæ¯ï¼å¨æåä¿®æ¹éç Minecraft éæ²ä¸­ï¼æ²æå¯ç¨çåé©ç¥è­ï¼ADAM ä¿æäºå¶æ§è½ï¼ä¸¦è¡¨ç¾åºé¡¯èçé­¯æ£æ§åæ³åè½åãADAM éåµäºä¸ç¨®æ°ç©çç¯ä¾ï¼ä»¥ååæ¹å¼æ´åå ææ¹æ³åå·èº«ä»£çãæåçå°æ¡é é¢ä½æ¼ https://opencausalab.github.io/ADAMã

##### **A Hierarchical Language Model For Interpretable Graph Reasoning**
2410.22372v1 by Sambhav Khurana, Xiner Li, Shurui Gui, Shuiwang Ji

Large language models (LLMs) are being increasingly explored for graph tasks.
Despite their remarkable success in text-based tasks, LLMs' capabilities in
understanding explicit graph structures remain limited, particularly with large
graphs. In this work, we introduce Hierarchical Language Model for Graph
(HLM-G), which employs a two-block architecture to capture node-centric local
information and interaction-centric global structure, effectively enhancing
graph structure understanding abilities. The proposed scheme allows LLMs to
address various graph queries with high efficacy, efficiency, and robustness,
while reducing computational costs on large-scale graph tasks. Furthermore, we
demonstrate the interpretability of our model using intrinsic attention weights
and established explainers. Comprehensive evaluations across diverse graph
reasoning and real-world tasks of node, link, and graph-levels highlight the
superiority of our method, marking a significant advancement in the application
of LLMs to graph understanding.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æä¾æå¤ç¨æ¼åå½¢ä»»åã
åç®¡ LLM å¨åºæ¼æå­çä»»åä¸­åå¾é¡¯èçæåï¼ä½å¶å¨çè§£æç¢ºåå½¢çµæ§æ¹é¢çè½åä»ç¶æéï¼ç¹å¥æ¯å°æ¼å¤§ååå½¢ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºåå½¢éå±¤èªè¨æ¨¡å (HLM-G)ï¼å®æ¡ç¨éåå¡æ¶æ§ä¾æ·åä»¥ç¯é»çºä¸­å¿çå±é¨è³è¨åä»¥äºåçºä¸­å¿çæ´é«çµæ§ï¼ææå°å¢å¼·äºåå½¢çµæ§çè§£è½åãææåºçæ¶æ§åè¨± LLM ä»¥é«æçãé«æçåé«ç©©å¥æ§ä¾èçåç¨®åå½¢æ¥è©¢ï¼åæéä½å¤§ååå½¢ä»»åçéç®ææ¬ãæ­¤å¤ï¼æåä½¿ç¨å§å¨æ³¨æåæ¬éåå·²å»ºç«çè§£éå¨ä¾å±ç¤ºæåæ¨¡åçå¯è§£éæ§ãå¨ç¯é»ãé£çµååå½¢å±¤ç´çåç¨®åå½¢æ¨çåçå¯¦ä¸çä»»åä¸­é²è¡çå¨é¢è©ä¼°çªé¡¯äºæåæ¹æ³çåªè¶æ§ï¼æ¨èªè LLM å¨åå½¢çè§£æç¨æ¹é¢åå¾éå¤§é²å±ã

##### **LLM-Forest for Health Tabular Data Imputation**
2410.21520v1 by Xinrui He, Yikun Ban, Jiaru Zou, Tianxin Wei, Curtiss B. Cook, Jingrui He

Missing data imputation is a critical challenge in tabular datasets,
especially in healthcare, where data completeness is vital for accurate
analysis. Large language models (LLMs), trained on vast corpora, have shown
strong potential in data generation, making them a promising tool for tabular
data imputation. However, challenges persist in designing effective prompts for
a finetuning-free process and in mitigating the risk of LLM hallucinations. To
address these issues, we propose a novel framework, LLM-Forest, which
introduces a "forest" of few-shot learning LLM "trees" with confidence-based
weighted voting. This framework is established on a new concept of bipartite
information graphs to identify high-quality relevant neighboring entries with
both feature and value granularity. Extensive experiments on four real-world
healthcare datasets demonstrate the effectiveness and efficiency of LLM-Forest.

æè¦ï¼éºå¤±è³ææ¨ä¼°æ¯è¡¨æ ¼è³æéä¸­çéå¤§ææ°ï¼
ç¹å¥æ¯å¨é«çä¿å¥ä¸­ï¼è³æå®æ´æ§å°æ¼æºç¢ºåæè³ééè¦ã
å¤§åèªè¨æ¨¡å (LLM) å¨é¾å¤§çèªæåº«ä¸è¨ç·´ï¼å¨è³æç¢çæ¹é¢å±ç¾åºå¼·å¤§çæ½åï¼ä½¿å¶æçºè¡¨æ ¼è³ææ¨ä¼°çæåéå·¥å·ã
ç¶èï¼å¨è¨­è¨æææç¤ºä»¥é²è¡å¾®èª¿åè²»æµç¨åæ¸è¼ LLM å¹»è¦ºé¢¨éªæ¹é¢ä»å­å¨ææ°ã
çºäºè§£æ±ºéäºåé¡ï¼æåæåºä¸åæ°çæ¡æ¶ï¼LLM-Forestï¼å®å¼å¥äºä¸åãæ£®æãçå°éå­¸ç¿ LLMãæ¨¹ãï¼ä¸¦æ¡ç¨åºæ¼ä¿¡å¿çå æ¬æç¥¨ã
éåæ¡æ¶å»ºç«å¨éåè³è¨åçæ°æ¦å¿µä¸ï¼ä»¥è­å¥å·æç¹å¾µåå¼ç²åº¦çåªè³ªç¸éé°è¿é ç®ã
å¨ååçå¯¦ä¸ççé«çä¿å¥è³æéä¸é²è¡çå»£æ³å¯¦é©è­æäº LLM-Forest çæææ§åæçã

##### **Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**
2410.21237v1 by Zhantao Yang, Han Zhang, Fangyi Chen, Anudeepsekhar Bolimera, Marios Savvides

Knowledge Graph (KG) is playing an increasingly important role in various AI
systems. For e-commerce, an efficient and low-cost automated knowledge graph
construction method is the foundation of enabling various successful downstream
applications. In this paper, we propose a novel method for constructing
structured product knowledge graphs from raw product images. The method
cooperatively leverages recent advances in the vision-language model (VLM) and
large language model (LLM), fully automating the process and allowing timely
graph updates. We also present a human-annotated e-commerce product dataset for
benchmarking product property extraction in knowledge graph construction. Our
method outperforms our baseline in all metrics and evaluated properties,
demonstrating its effectiveness and bright usage potential.

æè¦ï¼ç¥è­åè­ (KG) å¨åç¨® AI ç³»çµ±ä¸­æ®æ¼è¶ä¾è¶éè¦çè§è²ãå°æ¼é»å­ååä¾èªªï¼ä¸ç¨®ææä¸ä½ææ¬çèªååç¥è­åè­å»ºæ§æ¹æ³æ¯ä¿æåç¨®æåçä¸æ¸¸æç¨ç¨å¼çåºç¤ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®å¾åå§ç¢åå½±åå»ºæ§çµæ§åç¢åç¥è­åè­çæ°ç©æ¹æ³ãè©²æ¹æ³ååå©ç¨äºè¦è¦ºèªè¨æ¨¡å (VLM) åå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±ï¼å®å¨èªååäºæµç¨ä¸¦åè¨±åææ´æ°åè­ãæåéæä¾äºä¸åç±äººå·¥æ¨è¨»çé»å­ååç¢åè³æéï¼ç¨æ¼è©éç¥è­åè­å»ºæ§ä¸­çç¢åå±¬æ§èåãæåçæ¨¡åå¨ææææ¨åè©ä¼°å±¬æ§ä¸é½åªæ¼æåçåºæºï¼è­æäºå¶æææ§åå»£éçä½¿ç¨æ½åã

##### **CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**
2410.21067v1 by Meiqi Chen, Fandong Meng, Yingxue Zhang, Yan Zhang, Jie Zhou

Large language models (LLMs) have shown great promise in machine translation,
but they still struggle with contextually dependent terms, such as new or
domain-specific words. This leads to inconsistencies and errors that are
difficult to address. Existing solutions often depend on manual identification
of such terms, which is impractical given the complexity and evolving nature of
language. While Retrieval-Augmented Generation (RAG) could provide some
assistance, its application to translation is limited by issues such as
hallucinations from information overload. In this paper, we propose CRAT, a
novel multi-agent translation framework that leverages RAG and
causality-enhanced self-reflection to address these challenges. This framework
consists of several specialized agents: the Unknown Terms Identification agent
detects unknown terms within the context, the Knowledge Graph (KG) Constructor
agent extracts relevant internal knowledge about these terms and retrieves
bilingual information from external sources, the Causality-enhanced Judge agent
validates the accuracy of the information, and the Translator agent
incorporates the refined information into the final output. This automated
process allows for more precise and consistent handling of key terms during
translation. Our results show that CRAT significantly improves translation
accuracy, particularly in handling context-sensitive terms and emerging
vocabulary.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¨æ©å¨ç¿»è­¯æ¹é¢å±ç¾åºæ¥µå¤§çåæ¯ï¼
ä½å®åä»ç¶é£ä»¥æå°ä¾è³´æ¼èªå¢çè©å½ï¼ä¾å¦æ°è©æç¹å®é åçè©å½ãéæå°è´ä¸ä¸è´åé¯èª¤ï¼èéäºé¯èª¤å¾é£è§£æ±ºãç¾æçè§£æ±ºæ¹æ¡éå¸¸ä¾è³´æ¼æåè­å¥æ­¤é¡è©å½ï¼ä½ç±æ¼èªè¨çè¤éæ§åä¸æ·æ¼è®çç¹æ§ï¼éä¸¦ä¸å¯è¡ãéç¶æª¢ç´¢å¢å¼·çæï¼RAGï¼å¯ä»¥æä¾ä¸äºåå©ï¼ä½å¶å¨ç¿»è­¯ä¸­çæç¨åå°è«¸å¦è³è¨è¶è¼ç¢ççå¹»è¦ºç­åé¡çéå¶ãå¨æ¬æä¸­ï¼æåæåº CRATï¼éæ¯ä¸åæ°ç©çå¤ä»£çç¿»è­¯æ¶æ§ï¼å®å©ç¨ RAG åå æå¢å¼·èªçä¾æå°éäºææ°ãæ­¤æ¶æ§åå«å¹¾åå°éçä»£çï¼æªç¥è©å½è­å¥ä»£çæåµæ¸¬èªå¢ä¸­çæªç¥è©å½ï¼ç¥è­åè­ï¼KGï¼å»ºæ§ä»£çææ·åéäºè©å½ç¸éçå§é¨ç¥è­ï¼ä¸¦å¾å¤é¨ä¾æºä¸­æª¢ç´¢éèªè³è¨ï¼å æå¢å¼·å¤æ·ä»£çæé©è­è³è¨çæºç¢ºæ§ï¼èç¿»è­¯ä»£çæå°ç²¾çéçè³è¨ç´å¥æçµè¼¸åºãéåèªååçæµç¨åè¨±å¨ç¿»è­¯éç¨ä¸­æ´ç²¾ç¢ºä¸ä¸è´å°èçééµè©å½ãæåççµæé¡¯ç¤ºï¼CRAT å¤§å¹æåäºç¿»è­¯æºç¢ºæ§ï¼ç¹å¥æ¯å¨èçå°èªå¢ææçè©å½åæ°èè©å½æ¹é¢ã

##### **CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**
2410.21060v1 by Yutong Cheng, Osama Bajaber, Saimon Amanuel Tsegai, Dawn Song, Peng Gao

Textual descriptions in cyber threat intelligence (CTI) reports, such as
security articles and news, are rich sources of knowledge about cyber threats,
crucial for organizations to stay informed about the rapidly evolving threat
landscape. However, current CTI extraction methods lack flexibility and
generalizability, often resulting in inaccurate and incomplete knowledge
extraction. Syntax parsing relies on fixed rules and dictionaries, while model
fine-tuning requires large annotated datasets, making both paradigms
challenging to adapt to new threats and ontologies. To bridge the gap, we
propose CTINexus, a novel framework leveraging optimized in-context learning
(ICL) of large language models (LLMs) for data-efficient CTI knowledge
extraction and high-quality cybersecurity knowledge graph (CSKG) construction.
Unlike existing methods, CTINexus requires neither extensive data nor parameter
tuning and can adapt to various ontologies with minimal annotated examples.
This is achieved through (1) a carefully designed automatic prompt construction
strategy with optimal demonstration retrieval for extracting a wide range of
cybersecurity entities and relations; (2) a hierarchical entity alignment
technique that canonicalizes the extracted knowledge and removes redundancy;
(3) an ICL-enhanced long-distance relation prediction technique to further
complete the CKSG with missing links. Our extensive evaluations using 150
real-world CTI reports collected from 10 platforms demonstrate that CTINexus
significantly outperforms existing methods in constructing accurate and
complete CSKGs, highlighting its potential to transform CTI analysis with an
efficient and adaptable solution for the dynamic threat landscape.

æè¦ï¼ç¶²è·¯å¨èæå ± (CTI) å ±åä¸­çæå­æè¿°ï¼ä¾å¦å®å¨æç« åæ°èï¼æ¯ç¶²è·¯å¨èçè±å¯ç¥è­ä¾æºï¼å°æ¼çµç¹èè¨è³ééè¦ï¼å¯ä»¥é¨æäºè§£å¿«éæ¼è®çå¨èç°å¢ãç¶èï¼ç®åç CTI æåæ¹æ³ç¼ºä¹éæ´»æ§ä¸é£ä»¥æ¦æ¬ï¼éå¸¸æå°è´ç¥è­æåä¸æºç¢ºä¸ä¸å®æ´ãèªæ³è§£æä¾è³´æ¼åºå®è¦ååå­å¸ï¼èæ¨¡åå¾®èª¿éè¦å¤§éæ¨è¨»çè³æéï¼éä½¿å¾éå©ç¨®ç¯ä¾é½é£ä»¥é©ææ°çå¨èåæ¬ä½ãçºäºå½è£å·®è·ï¼æåæåºäº CTINexusï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) çæä½³åæå¢å­¸ç¿ (ICL) ä¾é²è¡è³æææçç CTI ç¥è­æååé«åè³ªçç¶²è·¯å®å¨ç¥è­å (CSKG) å»ºæ§ãèç¾ææ¹æ³ä¸åï¼CTINexus ä¸éè¦å»£æ³çè³ææåæ¸èª¿æ´ï¼ä¸¦ä¸å¯ä»¥ééæå°çæ¨è¨»ç¯ä¾é©æåç¨®æ¬ä½ãéæ¯éé (1) ç¶éç²¾å¿è¨­è¨çèªåæç¤ºå»ºæ§ç­ç¥ï¼ä¸¦ééæä½³ç¤ºç¯æª¢ç´¢ä¾æåå»£æ³çç¶²è·¯å®å¨å¯¦é«åéä¿ä¾å¯¦ç¾çï¼(2) ä¸ç¨®éå±¤å¼å¯¦é«æ¯å°æè¡ï¼å¯ä»¥å°æåçç¥è­æ¨æºåä¸¦æ¶é¤åé¤ï¼(3) ä¸ç¨® ICL å¢å¼·çé·è·é¢éä¿é æ¸¬æè¡ï¼å¯ä»¥é²ä¸æ­¥å®æå·æéºå¤±é£çµç CKSGãæåä½¿ç¨å¾ 10 åå¹³å°æ¶éç 150 ä»½çå¯¦ä¸ç CTI å ±åé²è¡å»£æ³è©ä¼°ï¼è­æ CTINexus å¨å»ºæ§æºç¢ºä¸å®æ´ç CSKG æ¹é¢æé¡¯åªæ¼ç¾ææ¹æ³ï¼çªé¡¯äºå¶ä»¥ææä¸é©ææ§å¼·çè§£æ±ºæ¹æ¡è½æ CTI åæçæ½åï¼ä»¥æå°åæçå¨èç°å¢ã

##### **Graph-based Uncertainty Metrics for Long-form Language Model Outputs**
2410.20783v1 by Mingjian Jiang, Yangjun Ruan, Prasanna Sattigeri, Salim Roukos, Tatsunori Hashimoto

Recent advancements in Large Language Models (LLMs) have significantly
improved text generation capabilities, but these systems are still known to
hallucinate, and granular uncertainty estimation for long-form LLM generations
remains challenging. In this work, we propose Graph Uncertainty -- which
represents the relationship between LLM generations and claims within them as a
bipartite graph and estimates the claim-level uncertainty with a family of
graph centrality metrics. Under this view, existing uncertainty estimation
methods based on the concept of self-consistency can be viewed as using degree
centrality as an uncertainty measure, and we show that more sophisticated
alternatives such as closeness centrality provide consistent gains at
claim-level uncertainty estimation. Moreover, we present uncertainty-aware
decoding techniques that leverage both the graph structure and uncertainty
estimates to improve the factuality of LLM generations by preserving only the
most reliable claims. Compared to existing methods, our graph-based uncertainty
metrics lead to an average of 6.8% relative gains on AUPRC across various
long-form generation settings, and our end-to-end system provides consistent
2-4% gains in factuality over existing decoding techniques while significantly
improving the informativeness of generated responses.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±é¡¯èæåäºæå­çæè½åï¼ä½éäºç³»çµ±ä»ä»¥ç¢çå¹»è¦ºèç¨±ï¼èéå°é·ç¯ LLM çæçç´°ç·»ä¸ç¢ºå®æ§ä¼°è¨ä»æ¯ä¸é ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºåå½¢ä¸ç¢ºå®æ§ï¼å®å° LLM çæåå¶ä¸­çä¸»å¼µè¡¨ç¤ºçºäºé¨åï¼ä¸¦ä½¿ç¨ä¸ç³»ååå½¢ä¸­å¿æ§ææ¨ä¼°è¨ä¸»å¼µå±¤ç´çä¸ç¢ºå®æ§ãå¨æ­¤è§é»ä¸ï¼ç¾æçåºæ¼èªæ´½æ§æ¦å¿µçä¸ç¢ºå®æ§ä¼°è¨æ¹æ³å¯è¦çºä½¿ç¨åº¦éä¸­å¿æ§ä½çºä¸ç¢ºå®æ§ææ¨ï¼æåè­æäºæ´ç²¾å¯çæ¿ä»£æ¹æ¡ï¼ä¾å¦æ¥è¿ä¸­å¿æ§ï¼å¨ä¸»å¼µå±¤ç´ä¸ç¢ºå®æ§ä¼°è¨ä¸­æä¾äºç©©å®çå¢çãæ­¤å¤ï¼æåæåºäºä¸ç¢ºå®æ§æç¥è§£ç¢¼æè¡ï¼è©²æè¡å©ç¨åå½¢çµæ§åä¸ç¢ºå®æ§ä¼°è¨ä¾æå LLM çæççå¯¦æ§ï¼æ¹æ³æ¯åä¿çæå¯é çä¸»å¼µãèç¾ææ¹æ³ç¸æ¯ï¼æåçåºæ¼åå½¢çææ¨å¨åç¨®é·ç¯çæè¨­å®ä¸­å¹³åæåäº AUPRC ç 6.8%ï¼èæåçç«¯å°ç«¯ç³»çµ±å¨çå¯¦æ§æ¹é¢æä¾äº 2-4% çç©©å®å¢çï¼åæé¡¯èæåäºçæåæçè³è¨æ§ã

##### **Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**
2410.20753v1 by Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma

We introduce Planning-guided Retrieval Augmented Generation
(Plan$\times$RAG), a novel framework that augments the
\emph{retrieve-then-reason} paradigm of existing RAG frameworks to
\emph{plan-then-retrieve}. Plan$\times$RAG formulates a reasoning plan as a
directed acyclic graph (DAG), decomposing queries into interrelated atomic
sub-queries. Answer generation follows the DAG structure, allowing significant
gains in efficiency through parallelized retrieval and generation. While
state-of-the-art RAG solutions require extensive data generation and
fine-tuning of language models (LMs), Plan$\times$RAG incorporates frozen LMs
as plug-and-play experts to generate high-quality answers. Compared to existing
RAG solutions, Plan$\times$RAG demonstrates significant improvements in
reducing hallucinations and bolstering attribution due to its structured
sub-query decomposition. Overall, Plan$\times$RAG offers a new perspective on
integrating external knowledge in LMs while ensuring attribution by design,
contributing towards more reliable LM-based systems.

æè¦ï¼<paragraph>æåå¼å¥äºè¦åå¼å°çæª¢ç´¢å¢å¼·çæ (Plan$\times$RAG)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®æ´åäºç¾æ RAG æ¡æ¶çãåæª¢ç´¢å¾æ¨çãç¯ä¾ï¼æ¹çºãåè¦åå¾æª¢ç´¢ããPlan$\times$RAG å°æ¨çè¨ç«å¶å®çºæåç¡ç°å (DAG)ï¼å°æ¥è©¢åè§£æç¸äºéè¯çåå­å­æ¥è©¢ãç­æ¡çæéµå¾ª DAG çµæ§ï¼ééä¸¦è¡æª¢ç´¢åçæï¼å¤§å¹æåæçãéç¶æåé²ç RAG è§£å³æ¹æ¡éè¦å¤§éè³æçæåèªè¨æ¨¡å (LM) çå¾®èª¿ï¼ä½ Plan$\times$RAG å°åçµç LM æ´åçºå³æå³ç¨çå°å®¶ï¼ä»¥çæé«åè³ªçç­æ¡ãèç¾æç RAG è§£å³æ¹æ¡ç¸æ¯ï¼Plan$\times$RAG å¨æ¸å°å¹»è¦ºåå å¼·æ­¸å æ¹é¢è¡¨ç¾åºé¡¯èçé²æ­¥ï¼éè¦æ­¸åæ¼å¶çµæ§åçå­æ¥è©¢åè§£ãç¸½é«èè¨ï¼Plan$\times$RAG æä¾äºä¸åæ°çè§é»ï¼ä»¥æ´å LM ä¸­çå¤é¨ç¥è­ï¼åæç¢ºä¿æ­¸å è¨­è¨ï¼æå©æ¼å»ºç«æ´å¯é çåºæ¼ LM çç³»çµ±ã</paragraph>

##### **Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**
2410.20724v1 by Mufei Li, Siqi Miao, Pan Li

Large Language Models (LLMs) demonstrate strong reasoning abilities but face
limitations such as hallucinations and outdated knowledge. Knowledge Graph
(KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by
grounding LLM outputs in structured external knowledge from KGs. However,
current KG-based RAG frameworks still struggle to optimize the trade-off
between retrieval effectiveness and efficiency in identifying a suitable amount
of relevant graph information for the LLM to digest. We introduce SubgraphRAG,
extending the KG-based RAG framework that retrieves subgraphs and leverages
LLMs for reasoning and answer prediction. Our approach innovatively integrates
a lightweight multilayer perceptron with a parallel triple-scoring mechanism
for efficient and flexible subgraph retrieval while encoding directional
structural distances to enhance retrieval effectiveness. The size of retrieved
subgraphs can be flexibly adjusted to match the query's need and the downstream
LLM's capabilities. This design strikes a balance between model complexity and
reasoning power, enabling scalable and generalizable retrieval processes.
Notably, based on our retrieved subgraphs, smaller LLMs like
Llama3.1-8B-Instruct deliver competitive results with explainable reasoning,
while larger models like GPT-4o achieve state-of-the-art accuracy compared with
previous baselines -- all without fine-tuning. Extensive evaluations on the
WebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency,
accuracy, and reliability by reducing hallucinations and improving response
grounding.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å±ç¤ºäºå¼·å¤§çæ¨çè½åï¼ä½é¢è¨å¹»è¦ºåéæç¥è­ç­éå¶ãåºæ¼ç¥è­åè­ (KG) çæª¢ç´¢å¢å¼·çæ (RAG) ééå° LLM è¼¸åºå»ºç«å¨ä¾èª KG ççµæ§åå¤é¨ç¥è­ä¸ï¼ä¾è§£æ±ºéäºåé¡ãç¶èï¼ç¶åçåºæ¼ KG ç RAG æ¶æ§ä»é£ä»¥åªåæª¢ç´¢ææèæçä¹éçæ¬è¡¡ï¼ä»¥è­å¥é©éçç¸éåå½¢è³è¨ä¾ LLM æ¶åãæåå¼å¥äº SubgraphRAGï¼æ´åäºåºæ¼ KG ç RAG æ¶æ§ï¼å®ææª¢ç´¢å­åä¸¦å©ç¨ LLM é²è¡æ¨çåç­æ¡é æ¸¬ãæåçåæ³åµæ°å°æ´åäºä¸åè¼éç´å¤å±¤æç¥å¨åä¸åä¸¦è¡çä¸åçµè©åæ©å¶ï¼ä»¥é²è¡ææä¸å½æ§çå­åæª¢ç´¢ï¼åæç·¨ç¢¼æ¹åçµæ§è·é¢ä»¥å¢å¼·æª¢ç´¢ææãæª¢ç´¢çå­åå¤§å°å¯ä»¥éæ´»èª¿æ´ï¼ä»¥ç¬¦åæ¥è©¢çéæ±åä¸æ¸¸ LLM çåè½ãæ­¤è¨­è¨å¨æ¨¡åè¤éåº¦åæ¨çè½åä¹éåå¾å¹³è¡¡ï¼å¯¦ç¾å¯æ´åä¸å¯æ¦åçæª¢ç´¢æµç¨ãå¼å¾æ³¨æçæ¯ï¼æ ¹ææåæª¢ç´¢çå­åï¼å Llama3.1-8B-Instruct ç­è¼å°ç LLM å¯ä»¥ééå¯è§£éçæ¨çæä¾å·æç«¶ç­åççµæï¼èå GPT-4o ç­è¼å¤§çæ¨¡ååå¯éå°èåååºæºç¸æ¯çææ°æºç¢ºåº¦ï¼èä¸ææéäºé½ä¸éè¦å¾®èª¿ãå¨ WebQSP å CWQ åºæºä¸çå»£æ³è©ä¼°çªåºäº SubgraphRAG å¨æçãæºç¢ºæ§åå¯é æ§æ¹é¢çåªå¢ï¼æ¹æ³æ¯æ¸å°å¹»è¦ºä¸¦æ¹ååæä¾æã

##### **Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs**
2410.20321v1 by Xingrui Zhuo, Jiapu Wang, Gongqing Wu, Shirui Pan, Xindong Wu

Knowledge Graph Query Embedding (KGQE) aims to embed First-Order Logic (FOL)
queries in a low-dimensional KG space for complex reasoning over incomplete
KGs. To enhance the generalization of KGQE models, recent studies integrate
various external information (such as entity types and relation context) to
better capture the logical semantics of FOL queries. The whole process is
commonly referred to as Query Pattern Learning (QPL). However, current QPL
methods typically suffer from the pattern-entity alignment bias problem,
leading to the learned defective query patterns limiting KGQE models'
performance. To address this problem, we propose an effective Query Instruction
Parsing Plugin (QIPP) that leverages the context awareness of Pre-trained
Language Models (PLMs) to capture latent query patterns from code-like query
instructions. Unlike the external information introduced by previous QPL
methods, we first propose code-like instructions to express FOL queries in an
alternative format. This format utilizes textual variables and nested tuples to
convey the logical semantics within FOL queries, serving as raw materials for a
PLM-based instruction encoder to obtain complete query patterns. Building on
this, we design a query-guided instruction decoder to adapt query patterns to
KGQE models. To further enhance QIPP's effectiveness across various KGQE
models, we propose a query pattern injection mechanism based on compressed
optimization boundaries and an adaptive normalization component, allowing KGQE
models to utilize query patterns more efficiently. Extensive experiments
demonstrate that our plug-and-play method improves the performance of eight
basic KGQE models and outperforms two state-of-the-art QPL methods.

æè¦ï¼ç¥è­åè­æ¥è©¢åµå¥ï¼KGQEï¼æ¨å¨å°ä¸ééè¼¯ï¼FOLï¼æ¥è©¢åµå¥å°ä½ç¶­ KG ç©ºéä¸­ï¼ä»¥ä¾¿å°ä¸å®æ´ç KG é²è¡è¤éæ¨çãçºäºå¢å¼· KGQE æ¨¡åçæ³åè½åï¼æè¿çç ç©¶æ´åäºåç¨®å¤é¨è³è¨ï¼ä¾å¦å¯¦é«é¡ååéä¿ä¸ä¸æï¼ï¼ä»¥æ´å¥½å°ææ FOL æ¥è©¢çéè¼¯èªç¾©ãæ´åéç¨éå¸¸ç¨±çºæ¥è©¢æ¨¡å¼å­¸ç¿ï¼QPLï¼ãç¶èï¼ç¶åç QPL æ¹æ³éå¸¸æåå°æ¨¡å¼å¯¦é«å°é½åå·®åé¡çå½±é¿ï¼å°è´å­¸ç¿å°çæç¼ºé·æ¥è©¢æ¨¡å¼éå¶äº KGQE æ¨¡åçæè½ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åææçæ¥è©¢æä»¤è§£æå¤æç¨å¼ï¼QIPPï¼ï¼å®å©ç¨é è¨ç·´èªè¨æ¨¡åï¼PLMï¼çä¸ä¸ææç¥ä¾å¾é¡ä»£ç¢¼çæ¥è©¢æä»¤ä¸­æ·åæ½å¨æ¥è©¢æ¨¡å¼ãèåå QPL æ¹æ³å¼å¥çå¤é¨è³è¨ä¸åï¼æåé¦åæåºé¡ä»£ç¢¼çæä»¤ä»¥å¦é¡æ ¼å¼è¡¨é FOL æ¥è©¢ãæ­¤æ ¼å¼å©ç¨æå­è®æ¸åå·¢çåçµä¾å³é FOL æ¥è©¢ä¸­çéè¼¯èªç¾©ï¼ä½çºåºæ¼ PLM çæä»¤ç·¨ç¢¼å¨çåæï¼ä»¥åå¾å®æ´çæ¥è©¢æ¨¡å¼ãå¨æ­¤åºç¤ä¸ï¼æåè¨­è¨äºä¸åæ¥è©¢å¼å°çæä»¤è§£ç¢¼å¨ï¼ä»¥å°æ¥è©¢æ¨¡å¼èª¿æ´å° KGQE æ¨¡åãçºäºé²ä¸æ­¥å¢å¼· QIPP å¨åç¨® KGQE æ¨¡åä¸­çæææ§ï¼æåæåºäºä¸ååºæ¼å£ç¸®æä½³åéçåèªé©ææ­£è¦ååä»¶çæ¥è©¢æ¨¡å¼æ³¨å¥æ©å¶ï¼åè¨± KGQE æ¨¡åæ´ææå°å©ç¨æ¥è©¢æ¨¡å¼ãå»£æ³çå¯¦é©è¡¨æï¼æåçå³æå³ç¨æ¹æ³æ¹åäºå«ååºæ¬ KGQE æ¨¡åçæè½ï¼ä¸¦åªæ¼å©ç¨®æåé²ç QPL æ¹æ³ã

##### **Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts**
2410.21324v1 by Vishesh Prasad, Brian Kim, Nickvash Kani

Recent advances in natural language processing (NLP), particularly with the
emergence of large language models (LLMs), have significantly enhanced the
field of textual analysis. However, while these developments have yielded
substantial progress in analyzing textual data, applying analysis to
mathematical equations and their relationships within texts has produced mixed
results. In this paper, we take the initial steps toward understanding the
dependency relationships between mathematical expressions in STEM articles. Our
dataset, sourced from a random sampling of the arXiv corpus, contains an
analysis of 107 published STEM manuscripts whose inter-equation dependency
relationships have been hand-labeled, resulting in a new object we refer to as
a derivation graph that summarizes the mathematical content of the manuscript.
We exhaustively evaluate analytical and NLP-based models to assess their
capability to identify and extract the derivation relationships for each
article and compare the results with the ground truth. Our comprehensive
testing finds that both analytical and NLP models (including LLMs) achieve
$\sim$40-50% F1 scores for extracting derivation graphs from articles,
revealing that the recent advances in NLP have not made significant inroads in
comprehending mathematical texts compared to simpler analytic models. While
current approaches offer a solid foundation for extracting mathematical
information, further research is necessary to improve accuracy and depth in
this area.

æè¦ï¼èªç¶èªè¨èçï¼NLPï¼çææ°é²å±ï¼ç¹å¥æ¯å¤§èªè¨æ¨¡åï¼LLMï¼çåºç¾ï¼å·²é¡¯èå¢å¼·äºææ¬åæé åãç¶èï¼åç®¡éäºç¼å±å¨åæææ¬è³ææ¹é¢åå¾äºå¯¦è³ªæ§é²å±ï¼ä½å°åææç¨æ¼æ¸å­¸æ¹ç¨å¼åå¶å¨ææ¬ä¸­çéä¿å»ç¢çäºä¸åççµæãå¨æ¬æä¸­ï¼æåæ¡åäºåæ­¥æ­¥é©ä¾äºè§£ STEM æç« ä¸­æ¸å­¸è¡¨éå¼ä¹éçä¾è³´éä¿ãæåçè³æéåèª arXiv èªæåº«çé¨æ©æ½æ¨£ï¼å¶ä¸­åå«å° 107 ç¯å·²ç¼è¡¨ç STEM æç¨¿çåæï¼å¶æ¹ç¨å¼éçä¾è³´éä¿å·²é²è¡æåæ¨è¨ï¼ç¢çäºä¸åæåç¨±çºè¡çåçæ°ç©ä»¶ï¼è©²ç©ä»¶ç¸½çµäºæç¨¿çæ¸å­¸å§å®¹ãæåå¾¹åºè©ä¼°äºåæååºæ¼ NLP çæ¨¡åï¼ä»¥è©ä¼°å®åè­å¥åæåæ¯ç¯æç« çè¡çéä¿çè½åï¼ä¸¦å°çµæèçå¯¦ææ³é²è¡æ¯è¼ãæåçå¨é¢æ¸¬è©¦ç¼ç¾ï¼åæå NLP æ¨¡åï¼åæ¬ LLMï¼å¨å¾æç« ä¸­æåè¡çåæ¹é¢ç F1 åæ¸åéå° $\sim$40-50%ï¼éè¡¨æèæ´ç°¡å®çåææ¨¡åç¸æ¯ï¼NLP çææ°é²å±ä¸¦æ²æå¨çè§£æ¸å­¸ææ¬æ¹é¢åå¾éå¤§é²å±ãåç®¡ç®åçæ¹æ³çºæåæ¸å­¸è³è¨æä¾äºå å¯¦çåºç¤ï¼ä½ä»éè¦é²ä¸æ­¥çç ç©¶ä¾æé«æ­¤é åçæºç¢ºæ§åæ·±åº¦ã

##### **DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**
2410.19955v1 by Pengfei Hu, Chang Lu, Fei Wang, Yue Ning

Electronic Health Records (EHR) has revolutionized healthcare data management
and prediction in the field of AI and machine learning. Accurate predictions of
diagnosis and medications significantly mitigate health risks and provide
guidance for preventive care. However, EHR driven models often have limited
scope on understanding medical-domain knowledge and mostly rely on
simple-and-sole ontologies. In addition, due to the missing features and
incomplete disease coverage of EHR, most studies only focus on basic analysis
on conditions and medication. We propose DualMAR, a framework that enhances EHR
prediction tasks through both individual observation data and public knowledge
bases. First, we construct a bi-hierarchical Diagnosis Knowledge Graph (KG)
using verified public clinical ontologies and augment this KG via Large
Language Models (LLMs); Second, we design a new proxy-task learning on lab
results in EHR for pretraining, which further enhance KG representation and
patient embeddings. By retrieving radial and angular coordinates upon polar
space, DualMAR enables accurate predictions based on rich hierarchical and
semantic embeddings from KG. Experiments also demonstrate that DualMAR
outperforms state-of-the-art models, validating its effectiveness in EHR
prediction and KG integration in medical domains.

æè¦ï¼é»å­å¥åº·ç´é (EHR) å·²å¾¹åºæ¹è®äºé«çä¿å¥è³æç®¡çï¼ä¸¦é æ¸¬äºäººå·¥æºæ§åæ©å¨å­¸ç¿é åãæºç¢ºé æ¸¬è¨ºæ·åè¥ç©å¯å¤§å¹æ¸è¼å¥åº·é¢¨éªï¼ä¸¦æä¾é é²æ§ç§è­·çæå°æ¹éãç¶èï¼EHR é©åçæ¨¡åå¨çè§£é«çé åç¥è­ä¸éå¸¸å·æå±éæ§ï¼èä¸å¤§å¤ä¾è³´æ¼ç°¡å®ä¸å®ä¸çæ¬ä½ãæ­¤å¤ï¼ç±æ¼ EHR éºæ¼äºåè½ä¸ç¾çæ¶µèä¸å®æ´ï¼å¤§å¤æ¸ç ç©¶åå°æ³¨æ¼ç¾çåè¥ç©çåºæ¬åæãæåæåº DualMARï¼ä¸åééåäººè§å¯è³æåå¬å±ç¥è­åº«å¢å¼· EHR é æ¸¬ä»»åçæ¶æ§ãé¦åï¼æåä½¿ç¨ç¶éé©è­çå¬å±è¨åºæ¬ä½æ§å»ºä¸åéå±¤ç´è¨ºæ·ç¥è­å (KG)ï¼ä¸¦ééå¤§åèªè¨æ¨¡å (LLM) æ´åéå KGï¼å¶æ¬¡ï¼æåè¨­è¨ä¸åæ°çä»£çä»»åå­¸ç¿ï¼éå° EHR ä¸­çå¯¦é©å®¤çµæé²è¡é è¨ç·´ï¼é²ä¸æ­¥å¢å¼· KG è¡¨ç¤ºåæ£èåµå¥ãééæ·åæ¥µåº§æ¨ç©ºéä¸çå¾ååè§ååæ¨ï¼DualMAR è½å¤ æ ¹æ KG ä¸­è±å¯çå±¤ç´åèªæåµå¥é²è¡æºç¢ºçé æ¸¬ãå¯¦é©ä¹è­æ DualMAR åªæ¼æåé²çæ¨¡åï¼é©è­äºå¶å¨ EHR é æ¸¬åé«çé åä¸­ KG æ´åçæææ§ã

##### **FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**
2410.19727v1 by Nicole Cho, Nishan Srishankar, Lucas Cecchi, William Watson

Financial intelligence generation from vast data sources has typically relied
on traditional methods of knowledge-graph construction or database engineering.
Recently, fine-tuned financial domain-specific Large Language Models (LLMs),
have emerged. While these advancements are promising, limitations such as high
inference costs, hallucinations, and the complexity of concurrently analyzing
high-dimensional financial data, emerge. This motivates our invention FISHNET
(Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning,
Expert swarming, and Task planning), an agentic architecture that accomplishes
highly complex analytical tasks for more than 98,000 regulatory filings that
vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows
remarkable performance for financial insight generation (61.8% success rate
over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to
empirically prove the success of FISHNET, each agent's importance, and the
optimized performance of assembling all agents. Our modular architecture can be
leveraged for a myriad of use-cases, enabling scalability, flexibility, and
data integrity that are critical for financial tasks.

æè¦ï¼è²¡åæå ±çæéå¸¸ä¾è³´æ¼å³çµ±çç¥è­åè¡¨å»ºæ§æè³æåº«å·¥ç¨æ¹æ³ï¼éäºæ¹æ³ä¾èªæ¼é¾å¤§çè³æä¾æºãæè¿ï¼éå°è²¡åé åé²è¡å¾®èª¿çå¤§åèªè¨æ¨¡å (LLM) å·²æéèçãåç®¡éäºé²å±ä»¤äººæ¯å¥®ï¼ä½ä»å­å¨ä¸äºéå¶ï¼ä¾å¦é«æ¨çææ¬ãå¹»è¦ºï¼ä»¥ååæåæé«ç¶­åº¦è²¡åè³æçè¤éæ§ãéä¿ä½¿æåç¼æäº FISHNETï¼ä¾èªå­æ¥è©¢ãåèª¿ãç¥ç¶æ¢ä»¶åãå°å®¶ç¾¤éåä»»åè¦åçè²¡åæå ±ï¼ï¼éæ¯ä¸ç¨®ä»£çæ¶æ§ï¼å¯éå°è¶é 98,000 ä»½æ³è¦æä»¶å·è¡é«åº¦è¤éçåæä»»åï¼èéäºæä»¶å¨èªç¾©ãè³æéå±¤ææ ¼å¼æ¹é¢å·®ç°æ¥µå¤§ãFISHNET å¨ç¢çè²¡åè¦è§£æ¹é¢è¡¨ç¾åºè²ï¼æåççº 61.8%ï¼è·¯ç±ççº 5.0%ï¼RAG R-Precision çº 45.6%ï¼ãæåé²è¡äºå´æ ¼çæ¶èï¼ä»¥å¯¦è­è­æ FISHNET çæåãæ¯åä»£ççéè¦æ§ï¼ä»¥åçµè£ææä»£ççæä½³åæè½ãæåæ¨¡çµåçæ¶æ§å¯éç¨æ¼åç¨®ä½¿ç¨æ¡ä¾ï¼æä¾è²¡åä»»åè³ééè¦çå¯æ´åæ§ãå½æ§åè³æå®æ´æ§ã

##### **Knowledge Graph Enhanced Language Agents for Recommendation**
2410.19627v1 by Taicheng Guo, Chaochun Liu, Hai Wang, Varun Mannam, Fang Wang, Xin Chen, Xiangliang Zhang, Chandan K. Reddy

Language agents have recently been used to simulate human behavior and
user-item interactions for recommendation systems. However, current language
agent simulations do not understand the relationships between users and items,
leading to inaccurate user profiles and ineffective recommendations. In this
work, we explore the utility of Knowledge Graphs (KGs), which contain extensive
and reliable relationships between users and items, for recommendation. Our key
insight is that the paths in a KG can capture complex relationships between
users and items, eliciting the underlying reasons for user preferences and
enriching user profiles. Leveraging this insight, we propose Knowledge Graph
Enhanced Language Agents(KGLA), a framework that unifies language agents and KG
for recommendation systems. In the simulated recommendation scenario, we
position the user and item within the KG and integrate KG paths as natural
language descriptions into the simulation. This allows language agents to
interact with each other and discover sufficient rationale behind their
interactions, making the simulation more accurate and aligned with real-world
cases, thus improving recommendation performance. Our experimental results show
that KGLA significantly improves recommendation performance (with a 33%-95%
boost in NDCG@1 among three widely used benchmarks) compared to the previous
best baseline method.

æè¦ï¼èªè¨ä»£çæè¿å·²è¢«ç¨æ¼æ¨¡æ¬äººé¡è¡çºåæ¨è¦ç³»çµ±ä¸­çä½¿ç¨èé ç®äºåãç¶èï¼ç®åçèªè¨ä»£çæ¨¡æ¬ä¸¦æªäºè§£ä½¿ç¨èåé ç®ä¹éçéä¿ï¼å°è´ä½¿ç¨èè¼ªå»ä¸æºç¢ºåæ¨è¦ææä¸ä½³ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºç¥è­åè­ (KG) çæç¨ï¼å¶ä¸­åå«ä½¿ç¨èåé ç®ä¹éå»£æ³ä¸å¯é çéä¿ï¼ä»¥ä¾æ¨è¦ãæåçééµè¦è§£æ¯ï¼KG ä¸­çè·¯å¾å¯ä»¥ææä½¿ç¨èåé ç®ä¹éçè¤ééä¿ï¼å¼åºä½¿ç¨èåå¥½çæ ¹æ¬åå ä¸¦è±å¯ä½¿ç¨èè¼ªå»ãå©ç¨æ­¤è¦è§£ï¼æåæåºäºç¥è­åè­å¢å¼·èªè¨ä»£ç (KGLA)ï¼ä¸åçµ±ä¸èªè¨ä»£çå KG ä»¥ç¨æ¼æ¨è¦ç³»çµ±çæ¶æ§ãå¨æ¨¡æ¬æ¨è¦æå¢ä¸­ï¼æåå°ä½¿ç¨èåé ç®å®ä½å¨ KG ä¸­ï¼ä¸¦å° KG è·¯å¾æ´åçºèªç¶èªè¨æè¿°å°æ¨¡æ¬ä¸­ãéåè¨±èªè¨ä»£çå½¼æ­¤äºåä¸¦ç¼ç¾å¶äºåèå¾çååä¾æï¼ä½¿æ¨¡æ¬æ´æºç¢ºä¸èå¯¦éæ¡ä¾ç¸ç¬¦ï¼å¾èæ¹åæ¨è¦æè½ãæåçå¯¦é©çµæé¡¯ç¤ºï¼èååæä½³åºæºæ¹æ³ç¸æ¯ï¼KGLA å¤§å¹æ¹åäºæ¨è¦æè½ï¼å¨ä¸åå»£æ³ä½¿ç¨çåºæºä¸­ï¼NDCG@1 æåäº 33%-95%ï¼ã

##### **Graph Linearization Methods for Reasoning on Graphs with Large Language Models**
2410.19494v1 by Christos Xypolopoulos, Guokan Shang, Xiao Fei, Giannis Nikolentzos, Hadi Abdine, Iakovos Evdaimon, Michail Chatzianastasis, Giorgos Stamou, Michalis Vazirgiannis

Large language models have evolved to process multiple modalities beyond
text, such as images and audio, which motivates us to explore how to
effectively leverage them for graph machine learning tasks. The key question,
therefore, is how to transform graphs into linear sequences of tokens, a
process we term graph linearization, so that LLMs can handle graphs naturally.
We consider that graphs should be linearized meaningfully to reflect certain
properties of natural language text, such as local dependency and global
alignment, in order to ease contemporary LLMs, trained on trillions of textual
tokens, better understand graphs. To achieve this, we developed several graph
linearization methods based on graph centrality, degeneracy, and node
relabeling schemes. We then investigated their effect on LLM performance in
graph reasoning tasks. Experimental results on synthetic graphs demonstrate the
effectiveness of our methods compared to random linearization baselines. Our
work introduces novel graph representations suitable for LLMs, contributing to
the potential integration of graph machine learning with the trend of
multi-modal processing using a unified transformer model.

æè¦ï¼å¤§åèªè¨æ¨¡åå·²æ¼åçºèçæå­ä¹å¤çå¤ç¨®æ¨¡å¼ï¼ä¾å¦å½±ååé³è¨ï¼éä¿ä½¿æåæ¢ç´¢å¦ä½ææå°éç¨å®åæ¼åå½¢æ©å¨å­¸ç¿ä»»åãå æ­¤ï¼ééµåé¡å¨æ¼å¦ä½å°åå½¢è½æçºç·æ§åºåçä»£å¹£ï¼éæ¯ä¸åæåç¨±çºåå½¢ç·æ§åçéç¨ï¼è® LLM è½èªç¶å°èçåå½¢ãæåèªçºåå½¢æææç¾©å°é²è¡ç·æ§åï¼ä»¥åæ èªç¶èªè¨æå­çç¹å®å±¬æ§ï¼ä¾å¦å±é¨ä¾è³´æ§åå¨å±å°é½ï¼ä»¥ä¾¿è®å¨æ¸ååæå­ä»£å¹£ä¸è¨ç·´çç¶ä»£ LLM æ´è½çè§£åå½¢ãçºéææ­¤ç®çï¼æåéç¼äºå¹¾ç¨®åºæ¼åå½¢ä¸­å¿æ§ãç°¡ä½µæ§åç¯é»éæ°æ¨ç±¤æ¶æ§çåå½¢ç·æ§åæ¹æ³ãæ¥èï¼æåæ¢è¨å®åå° LLM å¨åå½¢æ¨çä»»åä¸­çæè½å½±é¿ãåæåå½¢ä¸çå¯¦é©çµæè­æäºæåçæ¹æ³æ¯é¨æ©ç·æ§ååºæºæ´ææãæåçç ç©¶å¼å¥äºé©å LLM çæ°ç©åå½¢è¡¨ç¤ºæ³ï¼æå©æ¼å°åå½¢æ©å¨å­¸ç¿èä½¿ç¨çµ±ä¸Transformeræ¨¡åçå¤æ¨¡å¼èçè¶¨å¢æ´åèµ·ä¾ã

##### **Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis**
2410.19225v1 by Weikai Li, Ding Wang, Zijian Ding, Atefeh Sohrabizadeh, Zongyue Qin, Jason Cong, Yizhou Sun

High-level synthesis (HLS) is a widely used tool in designing Field
Programmable Gate Array (FPGA). HLS enables FPGA design with software
programming languages by compiling the source code into an FPGA circuit. The
source code includes a program (called ``kernel'') and several pragmas that
instruct hardware synthesis, such as parallelization, pipeline, etc. While it
is relatively easy for software developers to design the program, it heavily
relies on hardware knowledge to design the pragmas, posing a big challenge for
software developers. Recently, different machine learning algorithms, such as
GNNs, have been proposed to automate the pragma design via performance
prediction. However, when applying the trained model on new kernels, the
significant domain shift often leads to unsatisfactory performance. We propose
a more domain-generalizable model structure: a two-level hierarchical Mixture
of Experts (MoE), that can be flexibly adapted to any GNN model. Different
expert networks can learn to deal with different regions in the representation
space, and they can utilize similar patterns between the old kernels and new
kernels. In the low-level MoE, we apply MoE on three natural granularities of a
program: node, basic block, and graph. The high-level MoE learns to aggregate
the three granularities for the final decision. To stably train the
hierarchical MoE, we further propose a two-stage training method. Extensive
experiments verify the effectiveness of the hierarchical MoE.

æè¦ï¼é«éç¶åï¼HLSï¼æ¯è¨­è¨ç¾å ´å¯ç·¨ç¨éé£åï¼FPGAï¼ä¸­å»£æ³ä½¿ç¨çå·¥å·ãHLS ééå°åå§ç¢¼ç·¨è­¯æ FPGA é»è·¯ï¼ä½¿ç¨è»é«ç¨å¼èªè¨é²è¡ FPGA è¨­è¨ãåå§ç¢¼åå«ä¸åç¨å¼ï¼ç¨±çºãæ ¸å¿ãï¼åå¤åæå°ç¡¬é«ç¶åçæç¤ºï¼ä¾å¦å¹³è¡åãç®¡ç·ç­ãéç¶è»é«éç¼äººå¡è¨­è¨ç¨å¼ç¸å°å®¹æï¼ä½å®æ¥µåº¦ä¾è³´ç¡¬é«ç¥è­ä¾è¨­è¨æç¤ºï¼éå°è»é«éç¼äººå¡ä¾èªªæ¯ä¸å¤§ææ°ãæè¿ï¼ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³ï¼ä¾å¦ GNNï¼å·²è¢«æåºç¨æ¼ééæè½é æ¸¬èªåé²è¡æç¤ºè¨­è¨ãç¶èï¼å¨æ°çæ ¸å¿ä¸æç¨è¨ç·´å¥½çæ¨¡åæï¼é¡¯èçé åè½ç§»éå¸¸æå°è´æè½ä¸ä½³ãæåæåºä¸åæ´å·é åéç¨æ§çæ¨¡åçµæ§ï¼ä¸åäºéå±¤æ··åå°å®¶ï¼MoEï¼ï¼å®å¯ä»¥éæ´»å°é©æä»»ä½ GNN æ¨¡åãä¸åçå°å®¶ç¶²è·¯å¯ä»¥å­¸ç¿èçè¡¨ç¤ºç©ºéä¸­çä¸åååï¼ä¸¦ä¸å®åå¯ä»¥å©ç¨èæ ¸å¿åæ°æ ¸å¿ä¹éçç¸ä¼¼æ¨¡å¼ãå¨ä½é MoE ä¸­ï¼æåå°ç¨å¼çä¸åèªç¶ç²åº¦æç¨ MoEï¼ç¯é»ãåºæ¬åå¡ååãé«é MoE å­¸ç¿å½ç¸½éä¸åç²åº¦ä»¥ååºæçµæ±ºç­ãçºäºç©©å®è¨ç·´éå±¤å¼ MoEï¼æåé²ä¸æ­¥æåºä¸åäºéæ®µè¨ç·´æ¹æ³ãå»£æ³çå¯¦é©é©è­äºéå±¤å¼ MoE çæææ§ã

##### **Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media**
2410.19193v1 by Bruno Croso Cunha da Silva, Thomas Palmeira Ferraz, Roseli De Deus Lopes

Disinformation on social media poses both societal and technical challenges.
While previous studies have integrated textual information into propagation
networks, they have yet to fully leverage the advancements in Transformer-based
language models for high-quality contextual text representations. This work
investigates the impact of incorporating textual features into Graph Neural
Networks (GNNs) for fake news detection. Our experiments demonstrate that
contextual representations improve performance by 9.3% in Macro F1 over static
ones and 33.8% over GNNs without textual features. However, noisy data
augmentation degrades performance and increases instability. We expect our
methodology to open avenues for further research, and all code is made publicly
available.

æè¦ï¼ç¤¾ç¾¤åªé«ä¸çé¯èª¤è¨æ¯é æç¤¾æåæè¡å±¤é¢çææ°ã
åç®¡éå¾çç ç©¶å·²å°æå­è³è¨æ´åå°å³æ­ç¶²è·¯ä¸­ï¼ä½å°æªååå©ç¨åºæ¼ Transformer çèªè¨æ¨¡åå¨é«åè³ªèçµ¡æå­è¡¨å¾µä¸çé²å±ãéé ç ç©¶æ¢è¨å°æå­ç¹å¾µç´å¥åå½¢ç¥ç¶ç¶²è·¯ (GNN) ä¸­å°æ¼åæ°èåµæ¸¬çå½±é¿ãæåçå¯¦é©çµæé¡¯ç¤ºï¼èçµ¡è¡¨å¾µå°å·¨è§ F1 çæè½æåäº 9.3%ï¼åªæ¼éæè¡¨å¾µï¼ä¸¦æ¯æ²ææå­ç¹å¾µç GNN æåäº 33.8%ãç¶èï¼æéè¨çè³ææ´åæéä½æè½ä¸¦å¢å ä¸ç©©å®æ§ãæåé ææåçç ç©¶æ¹æ³å°éåé²ä¸æ­¥ç ç©¶çéå¾ï¼ææç¨å¼ç¢¼çå¬éæä¾ã

##### **GCoder: Improving Large Language Model for Generalized Graph Problem Solving**
2410.19084v1 by Qifan Zhang, Xiaobin Hong, Jianheng Tang, Nuo Chen, Yuhan Li, Wenzhong Li, Jing Tang, Jia Li

Large Language Models (LLMs) have demonstrated strong reasoning abilities,
making them suitable for complex tasks such as graph computation. Traditional
reasoning steps paradigm for graph problems is hindered by unverifiable steps,
limited long-term reasoning, and poor generalization to graph variations. To
overcome these limitations, we introduce GCoder, a code-based LLM designed to
enhance problem-solving in generalized graph computation problems. Our method
involves constructing an extensive training dataset, GraphWild, featuring
diverse graph formats and algorithms. We employ a multi-stage training process,
including Supervised Fine-Tuning (SFT) and Reinforcement Learning from Compiler
Feedback (RLCF), to refine model capabilities. For unseen tasks, a hybrid
retrieval technique is used to augment performance. Experiments demonstrate
that GCoder outperforms GPT-4o, with an average accuracy improvement of 16.42%
across various graph computational problems. Furthermore, GCoder efficiently
manages large-scale graphs with millions of nodes and diverse input formats,
overcoming the limitations of previous models focused on the reasoning steps
paradigm. This advancement paves the way for more intuitive and effective graph
problem-solving using LLMs. Code and data are available at here:
https://github.com/Bklight999/WWW25-GCoder/tree/master.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾å¼·å¤§çæ¨çè½åï¼ä½¿å¶é©ç¨æ¼è¤éä»»åï¼ä¾å¦åå½¢éç®ãå³çµ±åå½¢åé¡çæ¨çæ­¥é©ç¯ä¾åå°ä¸å¯é©è­çæ­¥é©ãæéçé·ææ¨çåå°åå½¢è®åçæ¦æ¬æ§ä¸ä½³çé»ç¤ãçºäºåæéäºéå¶ï¼æåå¼å¥äº GCoderï¼ä¸ç¨®åºæ¼ä»£ç¢¼ç LLMï¼æ¨å¨å¢å¼·å»£ç¾©åå½¢éç®åé¡ä¸­çåé¡è§£æ±ºè½åãæåçæè¡æ¶åæ§å»ºä¸åå»£æ³çè¨ç·´è³æé GraphWildï¼å¶ä¸­åå«å¤æ¨£çåå½¢æ ¼å¼åæ¼ç®æ³ãæåæ¡ç¨å¤éæ®µè¨ç·´æµç¨ï¼åæ¬ç£ç£å¾®èª¿ (SFT) åç·¨è­¯å¨åé¥å¼·åå­¸ç¿ (RLCF)ï¼ä»¥æ¹åæ¨¡åè½åãå°æ¼æªç¥ä»»åï¼ä½¿ç¨æ··åæ·åæè¡ä¾å¢å¼·æè½ãå¯¦é©è­æï¼GCoder åªæ¼ GPT-4oï¼å¨åç¨®åå½¢éç®åé¡ä¸­å¹³åæºç¢ºåº¦æåäº 16.42%ãæ­¤å¤ï¼GCoder ææå°ç®¡çèæææ¸ç¾è¬åç¯é»åå¤æ¨£è¼¸å¥æ ¼å¼çå¤§è¦æ¨¡åå½¢ï¼åæäºååå°æ³¨æ¼æ¨çæ­¥é©ç¯ä¾çæ¨¡åçéå¶ãéé é²å±çºä½¿ç¨ LLM é²è¡æ´ç´è§ä¸ææçåå½¢åé¡è§£æ±ºéªå¹³äºéè·¯ãç¨å¼ç¢¼åè³æå¯æ¼æ­¤èåå¾ï¼https://github.com/Bklight999/WWW25-GCoder/tree/masterã

##### **LLM-based Online Prediction of Time-varying Graph Signals**
2410.18718v1 by Dayu Qin, Yi Yan, Ercan Engin Kuruoglu

In this paper, we propose a novel framework that leverages large language
models (LLMs) for predicting missing values in time-varying graph signals by
exploiting spatial and temporal smoothness. We leverage the power of LLM to
achieve a message-passing scheme. For each missing node, its neighbors and
previous estimates are fed into and processed by LLM to infer the missing
observations. Tested on the task of the online prediction of wind-speed graph
signals, our model outperforms online graph filtering algorithms in terms of
accuracy, demonstrating the potential of LLMs in effectively addressing
partially observed signals in graphs.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çæ¡æ¶ï¼è©²æ¡æ¶å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾é æ¸¬æè®åå½¢ä¿¡èä¸­çç¼ºå¤±å¼ï¼æ¹æ³æ¯å©ç¨ç©ºéåæéå¹³æ»åº¦ãæåå©ç¨ LLM çè½åä¾å¯¦ç¾æ¶æ¯å³éæ¹æ¡ãå°æ¼æ¯åç¼ºå¤±ç¯é»ï¼å¶é°å±åååçä¼°è¨å¼æè¢«è¼¸å¥å° LLM ä¸­ä¸¦ç± LLM é²è¡èçï¼ä»¥æ¨æ·åºç¼ºå¤±çè§æ¸¬å¼ãå¨é¢¨éåå½¢ä¿¡èçç·ä¸é æ¸¬ä»»åä¸­é²è¡æ¸¬è©¦ï¼æåçæ¨¡åå¨æºç¢ºæ§æ¹é¢åªæ¼ç·ä¸åå½¢éæ¿¾æ¼ç®æ³ï¼éè­æäº LLM å¨ææèçåå½¢ä¸­é¨åè§æ¸¬å°çä¿¡èæ¹é¢çæ½åã

##### **Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production**
2410.18475v2 by Kexuan Xin, Qingyun Wang, Junyu Chen, Pengfei Yu, Huimin Zhao, Heng Ji

In the rapidly evolving field of metabolic engineering, the quest for
efficient and precise gene target identification for metabolite production
enhancement presents significant challenges. Traditional approaches, whether
knowledge-based or model-based, are notably time-consuming and labor-intensive,
due to the vast scale of research literature and the approximation nature of
genome-scale metabolic model (GEM) simulations. Therefore, we propose a new
task, Gene-Metabolite Association Prediction based on metabolic graphs, to
automate the process of candidate gene discovery for a given pair of metabolite
and candidate-associated genes, as well as presenting the first benchmark
containing 2474 metabolites and 1947 genes of two commonly used microorganisms
Saccharomyces cerevisiae (SC) and Issatchenkia orientalis (IO). This task is
challenging due to the incompleteness of the metabolic graphs and the
heterogeneity among distinct metabolisms. To overcome these limitations, we
propose an Interactive Knowledge Transfer mechanism based on Metabolism Graph
(IKT4Meta), which improves the association prediction accuracy by integrating
the knowledge from different metabolism graphs. First, to build a bridge
between two graphs for knowledge transfer, we utilize Pretrained Language
Models (PLMs) with external knowledge of genes and metabolites to help generate
inter-graph links, significantly alleviating the impact of heterogeneity.
Second, we propagate intra-graph links from different metabolic graphs using
inter-graph links as anchors. Finally, we conduct the gene-metabolite
association prediction based on the enriched metabolism graphs, which integrate
the knowledge from multiple microorganisms. Experiments on both types of
organisms demonstrate that our proposed methodology outperforms baselines by up
to 12.3% across various link prediction frameworks.

æè¦ï¼<paragraph>å¨å¿«éç¼å±çä»£è¬å·¥ç¨é åä¸­ï¼å°æ±ææä¸ç²¾ç¢ºçåºå ç®æ¨è­å¥ä»¥æåä»£è¬ç¢ç©ç¢éï¼æ¯ä¸é éå¤§çææ°ãå³çµ±æ¹æ³ï¼ç¡è«æ¯åºæ¼ç¥è­æåºæ¼æ¨¡åï¼é½ç¸ç¶èæä¸è²»åï¼éæ¯å çºç ç©¶æç»çè¦æ¨¡é¾å¤§ï¼ä¸åºå çµè¦æ¨¡ä»£è¬æ¨¡å (GEM) æ¨¡æ¬çè¿ä¼¼æ§è³ªãå æ­¤ï¼æåæåºäºä¸é æ°çä»»åï¼å³åºæ¼ä»£è¬åçåºå -ä»£è¬ç©éè¯é æ¸¬ï¼ä»¥èªåååé¸åºå ç¼ç¾çéç¨ï¼éå°çµ¦å®çä»£è¬ç©å°ååé¸ç¸éåºå ï¼ä¸¦åç¾ç¬¬ä¸ååºæºï¼å¶ä¸­åå« 2474 ç¨®ä»£è¬ç©å 1947 ååºå ï¼ä¾èªå©ç¨®å¸¸ç¨çå¾®çç©éééµæ¯ (SC) åæ±æ¹ä¼è©ç´ç§éµæ¯ (IO)ãç±æ¼ä»£è¬åçä¸å®æ´æ§åä¸åä»£è¬ç©ä¹éçç°è³ªæ§ï¼éé ä»»åå·æææ°æ§ãçºäºåæéäºéå¶ï¼æåæåºäºä¸ååºæ¼ä»£è¬åçäºåç¥è­å³è¼¸æ©å¶ (IKT4Meta)ï¼å®ééæ´åä¾èªä¸åä»£è¬åçç¥è­ä¾æé«éè¯é æ¸¬çæºç¢ºæ§ãé¦åï¼çºäºå¨å©ååä¹éå»ºç«ç¥è­å³è¼¸çæ©æ¨ï¼æåå©ç¨å·ååºå åä»£è¬ç©å¤é¨ç¥è­çé è¨ç·´èªè¨æ¨¡å (PLM) ä¾å¹«å©ç¢çåéé£çµï¼å¤§å¹æ¸è¼ç°è³ªæ§çå½±é¿ãå¶æ¬¡ï¼æåä½¿ç¨åéé£çµä½çºé¨é»ï¼å¾ä¸åçä»£è¬åå³æ­åå§é£çµãæå¾ï¼æåæ ¹ææ´åäºå¤ç¨®å¾®çç©ç¥è­çè±å¯ä»£è¬åï¼é²è¡åºå -ä»£è¬ç©éè¯é æ¸¬ãå©ç¨®çç©é«çå¯¦é©é½è­æï¼æåæåºçæ¹æ³å¨åç¨®é£çµé æ¸¬æ¶æ§ä¸­ï¼æ¯åºæºé«åº 12.3%ã</paragraph>

##### **ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**
2410.18447v1 by Zezhong Wang, Xingshan Zeng, Weiwen Liu, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong

Supervised fine-tuning (SFT) is a common method to enhance the tool calling
capabilities of Large Language Models (LLMs), with the training data often
being synthesized. The current data synthesis process generally involves
sampling a set of tools, formulating a requirement based on these tools, and
generating the call statements. However, tools sampled randomly lack relevance,
making them difficult to combine and thus reducing the diversity of the data.
Additionally, current work overlooks the coherence between turns of dialogues,
leading to a gap between the synthesized data and real-world scenarios. To
address these issues, we propose a Graph-based Sampling strategy to sample more
relevant tool combinations, and a Planned-generation strategy to create plans
that guide the synthesis of coherent dialogues. We integrate these two
strategies and enable multiple agents to synthesize the dialogue data
interactively, resulting in our tool-calling data synthesis pipeline ToolFlow.
Data quality assessments demonstrate improvements in the naturalness and
coherence of our synthesized dialogues. Finally, we apply SFT on LLaMA-3.1-8B
using 8,000 synthetic dialogues generated with ToolFlow. Results show that the
model achieves tool-calling performance comparable to or even surpassing GPT-4,
while maintaining strong general capabilities.

æè¦ï¼ç£ç£å¾®èª¿ (SFT) æ¯å¢å¼·å¤§åèªè¨æ¨¡å (LLM) å·¥å·å¼å«åè½çå¸¸è¦æ¹æ³ï¼è¨ç·´è³æéå¸¸æ¯åæè³æãç®åçè³æåææµç¨éå¸¸æ¶åæ½æ¨£ä¸çµå·¥å·ãæ ¹æéäºå·¥å·å¶å®éæ±ï¼ä¸¦ç¢çå¼å«é³è¿°ãç¶èï¼é¨æ©æ½æ¨£çå·¥å·ç¼ºä¹éè¯æ§ï¼ä½¿å¾å®åé£ä»¥çµåï¼å¾èéä½è³æçå¤æ¨£æ§ãæ­¤å¤ï¼ç®åçå·¥ä½å¿½ç¥äºå°è©±ååä¹éçé£è²«æ§ï¼å°è´åæè³æèç¾å¯¦ä¸çå ´æ¯ä¹éå­å¨å·®è·ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ååºæ¼åå½¢çæ½æ¨£ç­ç¥ä¾æ½åæ´å¤ç¸éçå·¥å·çµåï¼ä»¥åä¸åè¨ç«çæç­ç¥ä¾å»ºç«è¨ç«ï¼ä»¥å¼å°é£è²«å°è©±çåæãæåæ´åéå©ç¨®ç­ç¥ï¼ä¸¦ä½¿å¤åä»£çè½å¤ äºåå°åæå°è©±è³æï¼å¾èç¢çæåçå·¥å·å¼å«è³æåæç®¡ç· ToolFlowãè³æåè³ªè©ä¼°è­æäºæååæå°è©±çèªç¶æ§åé£è²«æ§æäºæ¹é²ãæå¾ï¼æåä½¿ç¨ ToolFlow çæç 8,000 ååæå°è©±å¨ LLaMA-3.1-8B ä¸æç¨ SFTãçµæè¡¨æï¼è©²æ¨¡åå¯¦ç¾äºè GPT-4 ç¸ç¶çè³è¶è¶ GPT-4 çå·¥å·å¼å«æè½ï¼åæä¿æå¼·å¤§çéç¨è½åã

##### **Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains**
2410.18415v1 by Kun Li, Tianhua Zhang, Xixin Wu, Hongyin Luo, James Glass, Helen Meng

Knowledge Graphs (KGs) can serve as reliable knowledge sources for question
answering (QA) due to their structured representation of knowledge. Existing
research on the utilization of KG for large language models (LLMs) prevalently
relies on subgraph retriever or iterative prompting, overlooking the potential
synergy of LLMs' step-wise reasoning capabilities and KGs' structural nature.
In this paper, we present DoG (Decoding on Graphs), a novel framework that
facilitates a deep synergy between LLMs and KGs. We first define a concept,
well-formed chain, which consists of a sequence of interrelated fact triplets
on the KGs, starting from question entities and leading to answers. We argue
that this concept can serve as a principle for making faithful and sound
reasoning for KGQA. To enable LLMs to generate well-formed chains, we propose
graph-aware constrained decoding, in which a constraint derived from the
topology of the KG regulates the decoding process of the LLMs. This constrained
decoding method ensures the generation of well-formed chains while making full
use of the step-wise reasoning capabilities of LLMs. Based on the above, DoG, a
training-free approach, is able to provide faithful and sound reasoning
trajectories grounded on the KGs. Experiments across various KGQA tasks with
different background KGs demonstrate that DoG achieves superior and robust
performance. DoG also shows general applicability with various open-source
LLMs.

æè¦ï¼ç¥è­åè­ (KG) ç±æ¼å¶çµæ§åçç¥è­è¡¨ç¤ºï¼å¯ç¨ä½åç­ (QA) çå¯é ç¥è­ä¾æºãç¾æéæ¼å©ç¨ KG çå¤§åèªè¨æ¨¡å (LLM) çç ç©¶æ®éä¾è³´æ¼å­åæª¢ç´¢å¨æåè¦æç¤ºï¼å¿½è¦äº LLM çéæ­¥æ¨çè½åå KG ççµæ§ç¹æ§çæ½å¨ååä½ç¨ãå¨æ¬æä¸­ï¼æåæåºäº DoGï¼åå½¢è§£ç¢¼ï¼ï¼ä¸åä¿é² LLM å KG ä¹éæ·±åº¦ååä½ç¨çæ°æ¡æ¶ãæåé¦åå®ç¾©äºä¸åæ¦å¿µï¼å³è¯å¥½å½¢æçéï¼å®ç± KG ä¸ä¸ç³»åç¸äºéè¯çäºå¯¦ä¸åçµçµæï¼å¾åé¡å¯¦é«éå§ä¸¦å°è´ç­æ¡ãæåèªçºéåæ¦å¿µå¯ä»¥ä½çºå° KGQA é²è¡å¿ å¯¦ååççæ¨ççååãçºäºä½¿ LLM è½å¤ çæè¯å¥½çéï¼æåæåºäºåæç¥ç´æè§£ç¢¼ï¼å¶ä¸­æºèª KG ææ²çç´æç´æäº LLM çè§£ç¢¼éç¨ãéç¨®åç´æçè§£ç¢¼æ¹æ³ç¢ºä¿äºè¯å¥½å½¢æçéççæï¼åæååå©ç¨äº LLM çéæ­¥æ¨çè½åãåºæ¼ä¸è¿°ï¼DoG æ¯ä¸ç¨®ç¡éè¨ç·´çæ¹æ³ï¼è½å¤ æä¾åºæ¼ KG çå¿ å¯¦ä¸åççæ¨çè»è·¡ãå¨å·æä¸åèæ¯ KG çåç¨® KGQA ä»»åä¸­çå¯¦é©è¡¨æï¼DoG éå°äºåè¶ä¸ç©©å¥çæ§è½ãDoG éé¡¯ç¤ºäºèåç¨®éæº LLM çéç¨é©ç¨æ§ã

##### **Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**
2410.18060v1 by Jaime Sevilla, Nikolay Babakov, Ehud Reiter, Alberto Bugarin

In this paper, we propose a model for building natural language explanations
for Bayesian Network Reasoning in terms of factor arguments, which are
argumentation graphs of flowing evidence, relating the observed evidence to a
target variable we want to learn about. We introduce the notion of factor
argument independence to address the outstanding question of defining when
arguments should be presented jointly or separately and present an algorithm
that, starting from the evidence nodes and a target node, produces a list of
all independent factor arguments ordered by their strength. Finally, we
implemented a scheme to build natural language explanations of Bayesian
Reasoning using this approach. Our proposal has been validated in the medical
domain through a human-driven evaluation study where we compare the Bayesian
Network Reasoning explanations obtained using factor arguments with an
alternative explanation method. Evaluation results indicate that our proposed
explanation approach is deemed by users as significantly more useful for
understanding Bayesian Network Reasoning than another existing explanation
method it is compared to.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåæåºäºä¸åæ¨¡åï¼ç¨æ¼å»ºæ§è²æ°ç¶²è·¯æ¨ççèªç¶èªè¨è§£éï¼ä»¥å å­è«è­çºåºç¤ï¼å®åæ¯æµåè­æçè«è­åï¼å°è§å¯å°çè­æèæåæ³è¦äºè§£çç®æ¨è®æ¸è¯ç¹«èµ·ä¾ãæåå¼å¥äºå å­è«è­ç¨ç«æ§çæ¦å¿µï¼ä»¥è§£æ±ºå®ç¾©ä½ææå°è«è­è¯åæå®ç¨åç¾çæªæ±ºåé¡ï¼ä¸¦æåºäºä¸ç¨®æ¼ç®æ³ï¼å¾è­æç¯é»åç®æ¨ç¯é»éå§ï¼ç¢çä¸åæå¼·åº¦æåºçææç¨ç«å å­è«è­æ¸å®ãæå¾ï¼æåå¯¦ä½äºä¸åæ¹æ¡ï¼ä½¿ç¨éç¨®æ¹æ³å»ºæ§è²æ°æ¨ççèªç¶èªè¨è§£éãæåçææ¡å·²å¨é«å­¸é åä¸­ééäººçºé©åçè©ä¼°ç ç©¶å¾å°é©è­ï¼å¨è©²ç ç©¶ä¸­ï¼æåå°ä½¿ç¨å å­è«è­ç²å¾çè²æ°ç¶²è·¯æ¨çè§£éèå¦ä¸ç¨®è§£éæ¹æ³é²è¡æ¯è¼ãè©ä¼°çµæè¡¨æï¼èå¦ä¸ç¨®ç¾æçè§£éæ¹æ³ç¸æ¯ï¼æåçæè­°è§£éæ¹æ³è¢«ä½¿ç¨èè¦çºé¡¯èæ´æå©æ¼çè§£è²æ°ç¶²è·¯æ¨çã</paragraph>

##### **Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective**
2410.17600v1 by Rui Yang, Boming Yang, Aosong Feng, Sixun Ouyang, Moritz Blum, Tianwei She, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li

Knowledge Graphs (KGs) are crucial in the field of artificial intelligence
and are widely used in downstream tasks, such as question-answering (QA). The
construction of KGs typically requires significant effort from domain experts.
Large Language Models (LLMs) have recently been used for Knowledge Graph
Construction (KGC). However, most existing approaches focus on a local
perspective, extracting knowledge triplets from individual sentences or
documents, missing a fusion process to combine the knowledge in a global KG.
This work introduces Graphusion, a zero-shot KGC framework from free text. It
contains three steps: in Step 1, we extract a list of seed entities using topic
modeling to guide the final KG includes the most relevant entities; in Step 2,
we conduct candidate triplet extraction using LLMs; in Step 3, we design the
novel fusion module that provides a global view of the extracted knowledge,
incorporating entity merging, conflict resolution, and novel triplet discovery.
Results show that Graphusion achieves scores of 2.92 and 2.37 out of 3 for
entity extraction and relation recognition, respectively. Moreover, we showcase
how Graphusion could be applied to the Natural Language Processing (NLP) domain
and validate it in an educational scenario. Specifically, we introduce TutorQA,
a new expert-verified benchmark for QA, comprising six tasks and a total of
1,200 QA pairs. Using the Graphusion-constructed KG, we achieve a significant
improvement on the benchmark, for example, a 9.2% accuracy improvement on
sub-graph completion.

æè¦ï¼<paragraph>ç¥è­åè­ (KG) å¨äººå·¥æºæ§é åè³ééè¦ï¼å»£æ³ç¨æ¼ä¸æ¸¸ä»»åï¼ä¾å¦åç­ (QA)ãKG çå»ºæ§éå¸¸éè¦é åå°å®¶ä»åºå¤§éå¿åãå¤§åèªè¨æ¨¡å (LLM) è¿ä¾å·²ç¨æ¼ç¥è­åè­å»ºæ§ (KGC)ãç¶èï¼ç¾ææ¹æ³å¤§å¤èéæ¼å±é¨è§é»ï¼å¾åå¥å¥å­ææä»¶æ·åç¥è­ä¸åçµï¼ç¼ºå°ä¸åèåç¨åºä¾å°ç¥è­çµåå¨ä¸åæ´é« KG ä¸­ãæ¬ç ç©¶å¼å¥äº Graphusionï¼ä¸åå¾èªç±æå­é²è¡é¶æ¬¡å­¸ç¿ç KGC æ¡æ¶ãå®åå«ä¸åæ­¥é©ï¼å¨æ­¥é© 1 ä¸­ï¼æåä½¿ç¨ä¸»é¡å»ºæ¨¡æ·åä¸çµç¨®å­å¯¦é«ï¼ä»¥å¼å°æçµç KG ç´å¥æç¸éçå¯¦é«ï¼å¨æ­¥é© 2 ä¸­ï¼æåä½¿ç¨ LLM é²è¡åé¸ä¸åçµæ·åï¼å¨æ­¥é© 3 ä¸­ï¼æåè¨­è¨äºæ°ç©çèåæ¨¡çµï¼æä¾æ·åç¥è­çæ´é«è§é»ï¼åå«å¯¦é«åä½µãè¡çªè§£æ±ºåæ°ä¸åçµç¼ç¾ãçµæé¡¯ç¤º Graphusion å¨å¯¦é«æ·ååéä¿è­å¥æ¹é¢åå¥ç²å¾ 3 åä¸­ç 2.92 åå 2.37 åãæ­¤å¤ï¼æåå±ç¤ºäº Graphusion å¦ä½æç¨æ¼èªç¶èªè¨èç (NLP) é åï¼ä¸¦å¨æè²æå¢ä¸­é©è­å®ãå·é«ä¾èªªï¼æåå¼å¥äº TutorQAï¼ä¸åç±å°å®¶é©è­çæ°å QA åºæºï¼åå«å­é ä»»ååç¸½è¨ 1,200 çµ QAãä½¿ç¨ Graphusion å»ºæ§ç KGï¼æåå¨åºæºä¸åå¾é¡¯èé²æ­¥ï¼ä¾å¦ï¼å¨å­åå®ææ¹é¢æåäº 9.2% çæºç¢ºåº¦ã</paragraph>

##### **Navigate Complex Physical Worlds via Geometrically Constrained LLM**
2410.17529v1 by Yongqiang Huang, Wentao Ye, Liyao Li, Junbo Zhao

This study investigates the potential of Large Language Models (LLMs) for
reconstructing and constructing the physical world solely based on textual
knowledge. It explores the impact of model performance on spatial understanding
abilities. To enhance the comprehension of geometric and spatial relationships
in the complex physical world, the study introduces a set of geometric
conventions and develops a workflow based on multi-layer graphs and multi-agent
system frameworks. It examines how LLMs achieve multi-step and multi-objective
geometric inference in a spatial environment using multi-layer graphs under
unified geometric conventions. Additionally, the study employs a genetic
algorithm, inspired by large-scale model knowledge, to solve geometric
constraint problems. In summary, this work innovatively explores the
feasibility of using text-based LLMs as physical world builders and designs a
workflow to enhance their capabilities.

æè¦ï¼æ¬ç ç©¶æ¢è¨å¤§åèªè¨æ¨¡å (LLM) ååºæ¼æå­ç¥è­éå»ºåå»ºæ§ç©çä¸ççæ½åãæ¢è¨æ¨¡åæè½å°ç©ºéçè§£è½åçå½±é¿ãçºäºå¢å¼·å°è¤éç©çä¸çä¸­å¹¾ä½åç©ºééä¿ççè§£ï¼æ¬ç ç©¶å¼å¥äºä¸çµå¹¾ä½æ£ä¾ï¼ä¸¦åºæ¼å¤å±¤åå½¢åå¤ä»£çç³»çµ±æ¶æ§éç¼äºä¸å¥å·¥ä½æµç¨ãç ç©¶æ¢è¨äº LLM å¦ä½å¨çµ±ä¸çå¹¾ä½æ£ä¾ä¸ï¼ä½¿ç¨å¤å±¤åå½¢å¨ç©ºéç°å¢ä¸­éæå¤æ­¥é©åå¤ç®æ¨çå¹¾ä½æ¨è«ãæ­¤å¤ï¼æ¬ç ç©¶æ¡ç¨åå¤§åæ¨¡åç¥è­åç¼çéºå³æ¼ç®æ³ä¾è§£æ±ºå¹¾ä½ç´æåé¡ãç¸½ä¹ï¼éé å·¥ä½åµæ°å°æ¢è¨äºä½¿ç¨åºæ¼æå­ç LLM ä½çºç©çä¸çå»ºæ§èçå¯è¡æ§ï¼ä¸¦è¨­è¨äºä¸å¥å·¥ä½æµç¨ä¾å¢å¼·å¶è½åã

##### **Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs**
2410.16882v1 by Leyao Wang, Yu Wang, Bo Ni, Yuying Zhao, Tyler Derr

Node classification on graphs frequently encounters the challenge of class
imbalance, leading to biased performance and posing significant risks in
real-world applications. Although several data-centric solutions have been
proposed, none of them focus on Text-Attributed Graphs (TAGs), and therefore
overlook the potential of leveraging the rich semantics encoded in textual
features for boosting the classification of minority nodes. Given this crucial
gap, we investigate the possibility of augmenting graph data in the text space,
leveraging the textual generation power of Large Language Models (LLMs) to
handle imbalanced node classification on TAGs. Specifically, we propose a novel
approach called LA-TAG (LLM-based Augmentation on Text-Attributed Graphs),
which prompts LLMs to generate synthetic texts based on existing node texts in
the graph. Furthermore, to integrate these synthetic text-attributed nodes into
the graph, we introduce a text-based link predictor to connect the synthesized
nodes with the existing nodes. Our experiments across multiple datasets and
evaluation metrics show that our framework significantly outperforms
traditional non-textual-based data augmentation strategies and specific node
imbalance solutions. This highlights the promise of using LLMs to resolve
imbalance issues on TAGs.

æè¦ï¼åå½¢ç¯é»åé¡ç¶å¸¸æéå°é¡å¥ä¸å¹³è¡¡çææ°ï¼å°è´æåå·®çæè½ï¼ä¸¦å¨å¯¦éæç¨ä¸­é æé¡¯èé¢¨éªãåç®¡å·²æåºå¤é ä»¥è³æçºä¸­å¿çè§£æ±ºæ¹æ¡ï¼ä½æ²æä¸é å°æ³¨æ¼æå­å±¬æ§åå½¢ (TAG)ï¼å æ­¤å¿½ç¥äºå©ç¨æå­ç¹å¾µä¸­ç·¨ç¢¼çè±å¯èªæä¾æåå°æ¸ç¯é»åé¡çå¯è½æ§ãéæ¼éåééµå·®è·ï¼æåæ¢è¨äºå¨æå­ç©ºéä¸­æ´ååå½¢è³æçå¯è½æ§ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) çæå­ç¢çè½åä¾èç TAG ä¸çä¸å¹³è¡¡ç¯é»åé¡ãå·é«ä¾èªªï¼æåæåºäºä¸ç¨®åçº LA-TAGï¼åºæ¼ LLM çæå­å±¬æ§åå½¢æ´åï¼çæ°æ¹æ³ï¼å®æç¤º LLM æ ¹æåå½¢ä¸­ç¾æçç¯é»æå­ç¢çåææå­ãæ­¤å¤ï¼çºäºå°éäºåææå­å±¬æ§ç¯é»æ´åå°åå½¢ä¸­ï¼æåå¼å¥äºä¸ååºæ¼æå­çé£çµé æ¸¬å¨ï¼ä»¥å°åæç¯é»èç¾æç¯é»é£æ¥èµ·ä¾ãæåå¨å¤åè³æéåè©ä¼°ææ¨ä¸çå¯¦é©è¡¨æï¼æåçæ¡æ¶æé¡¯åªæ¼å³çµ±çéæå­è³ææ´åç­ç¥åç¹å®çç¯é»ä¸å¹³è¡¡è§£æ±ºæ¹æ¡ãéçªé¡¯äºä½¿ç¨ LLM ä¾è§£æ±º TAG ä¸çä¸å¹³è¡¡åé¡çæ½åã

##### **Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning**
2410.16803v1 by Muzhi Li, Cehao Yang, Chengjin Xu, Zixing Song, Xuhui Jiang, Jian Guo, Ho-fung Leung, Irwin King

Inductive knowledge graph completion (KGC) aims to predict missing triples
with unseen entities. Recent works focus on modeling reasoning paths between
the head and tail entity as direct supporting evidence. However, these methods
depend heavily on the existence and quality of reasoning paths, which limits
their general applicability in different scenarios. In addition, we observe
that latent type constraints and neighboring facts inherent in KGs are also
vital in inferring missing triples. To effectively utilize all useful
information in KGs, we introduce CATS, a novel context-aware inductive KGC
solution. With sufficient guidance from proper prompts and supervised
fine-tuning, CATS activates the strong semantic understanding and reasoning
capabilities of large language models to assess the existence of query triples,
which consist of two modules. First, the type-aware reasoning module evaluates
whether the candidate entity matches the latent entity type as required by the
query relation. Then, the subgraph reasoning module selects relevant reasoning
paths and neighboring facts, and evaluates their correlation to the query
triple. Experiment results on three widely used datasets demonstrate that CATS
significantly outperforms state-of-the-art methods in 16 out of 18
transductive, inductive, and few-shot settings with an average absolute MRR
improvement of 7.2%.

æè¦ï¼æ­¸ç´ç¥è­åè­å®æ (KGC) æ¨å¨é æ¸¬å·ææªè¦å¯¦é«çç¼ºå¤±ä¸åçµãæè¿çå·¥ä½éé»å¨æ¼å»ºæ¨¡é ­å¯¦é«åå°¾å¯¦é«ä¹éçæ¨çè·¯å¾ä½çºç´æ¥æ¯æè­æãç¶èï¼éäºæ¹æ³é«åº¦ä¾è³´æ¨çè·¯å¾çå­å¨ååè³ªï¼ééå¶äºå®åå¨ä¸åå ´æ¯ä¸­çæ®éé©ç¨æ§ãæ­¤å¤ï¼æåè§å¯å°é±èé¡åç´æå KG ä¸­åºæçé°è¿äºå¯¦å°æ¼æ¨æ·ç¼ºå¤±ä¸åçµä¹è³ééè¦ãçºäºææå©ç¨ KG ä¸­æææç¨çè³è¨ï¼æåå¼å¥äº CATSï¼ä¸ç¨®æ°ç©çå·åæå¢æç¥è½åçæ­¸ç´å¼ KGC è§£å³æ¹æ¡ãå¨é©ç¶æç¤ºåç£ç£å¾®èª¿çååæå°ä¸ï¼CATS ååå¤§åèªè¨æ¨¡åå¼·å¤§çèªç¾©çè§£åæ¨çè½åï¼ä»¥è©ä¼°æ¥è©¢ä¸åçµçå­å¨ï¼å¶ä¸­åå«å©åæ¨¡çµãé¦åï¼é¡åæç¥æ¨çæ¨¡çµè©ä¼°åé¸å¯¦é«æ¯å¦èæ¥è©¢éä¿æéçé±èå¯¦é«é¡åç¸ç¬¦ãç¶å¾ï¼å­åæ¨çæ¨¡çµé¸æç¸éæ¨çè·¯å¾åé°è¿äºå¯¦ï¼ä¸¦è©ä¼°å®åèæ¥è©¢ä¸åçµçéè¯æ§ãå¨ä¸åå»£æ³ä½¿ç¨çè³æéä¸é²è¡çå¯¦é©çµæè¡¨æï¼å¨ 18 åè½å°ãæ­¸ç´åå°æ¬¡åè©¦è¨­å®ä¸­ï¼CATS å¨ 16 åè¨­å®ä¸­é¡¯èåªæ¼æåé²çæ¹æ³ï¼å¹³åçµå° MRR æåäº 7.2%ã

##### **The Scene Language: Representing Scenes with Programs, Words, and Embeddings**
2410.16770v1 by Yunzhi Zhang, Zizhang Li, Matt Zhou, Shangzhe Wu, Jiajun Wu

We introduce the Scene Language, a visual scene representation that concisely
and precisely describes the structure, semantics, and identity of visual
scenes. It represents a scene with three key components: a program that
specifies the hierarchical and relational structure of entities in the scene,
words in natural language that summarize the semantic class of each entity, and
embeddings that capture the visual identity of each entity. This representation
can be inferred from pre-trained language models via a training-free inference
technique, given text or image inputs. The resulting scene can be rendered into
images using traditional, neural, or hybrid graphics renderers. Together, this
forms a robust, automated system for high-quality 3D and 4D scene generation.
Compared with existing representations like scene graphs, our proposed Scene
Language generates complex scenes with higher fidelity, while explicitly
modeling the scene structures to enable precise control and editing.

æè¦ï¼æåå¼å¥äºå ´æ¯èªè¨ï¼éæ¯ä¸ç¨®è¦è¦ºå ´æ¯è¡¨ç¤ºæ³ï¼ç°¡æ½ä¸ç²¾ç¢ºå°æè¿°äºè¦è¦ºå ´æ¯ççµæ§ãèªæåèº«åãå®ä½¿ç¨ä¸åééµçµæé¨åä¾è¡¨ç¤ºå ´æ¯ï¼ä¸åç¨å¼ï¼ç¨æ¼æå®å ´æ¯ä¸­å¯¦é«çéå±¤åéä¿çµæ§ï¼ä»¥èªç¶èªè¨è¡¨ç¤ºçè©å½ï¼ç¨æ¼ç¸½çµæ¯åå¯¦é«çèªæé¡å¥ï¼ä»¥åç¨æ¼æ·åæ¯åå¯¦é«çè¦è¦ºèº«åçåµå¥ãéåè¡¨ç¤ºæ³å¯ä»¥ééç¡è¨ç·´æ¨è«æè¡å¾é åè¨ç·´çèªè¨æ¨¡åæ¨è«åºä¾ï¼çµ¦å®æå­æå½±åè¼¸å¥ãç¢ççå ´æ¯å¯ä»¥ä½¿ç¨å³çµ±ãç¥ç¶ææ··ååå½¢æ¸²æå¨æ¸²ææå½±åãç¸½èè¨ä¹ï¼éå½¢æäºä¸åå¼·å¥çèªååç³»çµ±ï¼ç¨æ¼é«åè³ª 3D å 4D å ´æ¯çæãèç¾æçè¡¨ç¤ºæ³ï¼ä¾å¦å ´æ¯åï¼ç¸æ¯ï¼æåæåºçå ´æ¯èªè¨å¯ä»¥çæå·ææ´é«ä¿çåº¦çè¤éå ´æ¯ï¼åææç¢ºå°å»ºæ¨¡å ´æ¯çµæ§ä»¥å¯¦ç¾ç²¾ç¢ºæ§å¶åç·¨è¼¯ã

##### **Atomic Fact Decomposition Helps Attributed Question Answering**
2410.16708v1 by Zhichao Yan, Jiapu Wang, Jiaoyan Chen, Xiaoli Li, Ru Li, Jeff Z. Pan

Attributed Question Answering (AQA) aims to provide both a trustworthy answer
and a reliable attribution report for a given question. Retrieval is a widely
adopted approach, including two general paradigms: Retrieval-Then-Read (RTR)
and post-hoc retrieval. Recently, Large Language Models (LLMs) have shown
remarkable proficiency, prompting growing interest in AQA among researchers.
However, RTR-based AQA often suffers from irrelevant knowledge and rapidly
changing information, even when LLMs are adopted, while post-hoc
retrieval-based AQA struggles with comprehending long-form answers with complex
logic, and precisely identifying the content needing revision and preserving
the original intent. To tackle these problems, this paper proposes an Atomic
fact decomposition-based Retrieval and Editing (ARE) framework, which
decomposes the generated long-form answers into molecular clauses and atomic
facts by the instruction-tuned LLMs. Notably, the instruction-tuned LLMs are
fine-tuned using a well-constructed dataset, generated from large scale
Knowledge Graphs (KGs). This process involves extracting one-hop neighbors from
a given set of entities and transforming the result into coherent long-form
text. Subsequently, ARE leverages a search engine to retrieve evidences related
to atomic facts, inputting these evidences into an LLM-based verifier to
determine whether the facts require expansion for re-retrieval or editing.
Furthermore, the edited facts are backtracked into the original answer, with
evidence aggregated based on the relationship between molecular clauses and
atomic facts. Extensive evaluations demonstrate the superior performance of our
proposed method over the state-of-the-arts on several datasets, with an
additionally proposed new metric $Attr_{p}$ for evaluating the precision of
evidence attribution.

æè¦ï¼<paragraph>æ­¸å å¼åç­ (AQA) çç®æ¨æ¯éå°ç¹å®åé¡æä¾å¯ä¿¡çç­æ¡åå¯é çæ­¸å å ±åãæ·åæ¯ä¸ç¨®å»£æ³æ¡ç¨çæ¹æ³ï¼åæ¬å©ç¨®ä¸è¬ç¯ä¾ï¼æ·ååé±è® (RTR) åäºå¾æ·åãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºåè¶ççç·´åº¦ï¼ä¿ä½¿ç ç©¶äººå¡å° AQA ç¢çè¶ä¾è¶æ¿åçèè¶£ãç¶èï¼å³ä½¿æ¡ç¨ LLMï¼åºæ¼ RTR ç AQA ä»å¸¸å¸¸æåå°ä¸ç¸éç¥è­åå¿«éè®åçè³è¨å½±é¿ï¼èåºæ¼äºå¾æ·åç AQA åé£ä»¥çè§£å·æè¤ééè¼¯çé·ç¯ç­æ¡ï¼ä¸¦ç²¾ç¢ºæ¾åºéè¦ä¿®æ¹çå§å®¹ï¼åæä¿çåå§æåãçºäºè§£æ±ºéäºåé¡ï¼æ¬ææåºäºä¸ååºæ¼åå­äºå¯¦åè§£çæ·ååç·¨è¼¯ (ARE) æ¶æ§ï¼å®ééæä»¤èª¿æ´ç LLM å°ç¢ççé·ç¯ç­æ¡åè§£çºåå­å­å¥ååå­äºå¯¦ãå¼å¾æ³¨æçæ¯ï¼æä»¤èª¿æ´ç LLM æä½¿ç¨å¾å¤§è¦æ¨¡ç¥è­åè­ (KG) ä¸­ç¢çççµæ§è¯å¥½è³æéé²è¡å¾®èª¿ãæ­¤ç¨åºåå«å¾ç¹å®å¯¦é«éåä¸­æ·åä¸è·³é°å±ï¼ä¸¦å°çµæè½æçºé£è²«çé·ç¯æå­ãé¨å¾ï¼ARE æå©ç¨æå°å¼ææ·åèåå­äºå¯¦ç¸éçè­æï¼å°éäºè­æè¼¸å¥å°åºæ¼ LLM çé©è­å¨ä¸­ï¼ä»¥ç¢ºå®äºå¯¦æ¯å¦éè¦æ´åä»¥ä¾éæ°æ·åæç·¨è¼¯ãæ­¤å¤ï¼ç·¨è¼¯å¾ççµææåæº¯å°åå§ç­æ¡ï¼ä¸¦æ ¹æåå­å­å¥ååå­äºå¯¦ä¹éçéä¿å½æ´è­æãå»£æ³çè©ä¼°é¡¯ç¤ºï¼æåæåºçæ¹æ³å¨å¤åè³æéä¸åªæ¼ç¾ææè¡ï¼ä¸¦é¡å¤æåºäºä¸åæ°çææ¨ $Attr_{p}$ï¼ç¨æ¼è©ä¼°è­ææ­¸å çç²¾æºåº¦ã</paragraph>

##### **PLDR-LLM: Large Language Model from Power Law Decoder Representations**
2410.16703v1 by Burc Gokden

We present the Large Language Model from Power Law Decoder Representations
(PLDR-LLM), a language model that leverages non-linear and linear
transformations through Power Law Graph Attention mechanism to generate
well-defined deductive and inductive outputs. We pretrain the PLDR-LLMs of
varying layer sizes with a small batch size of 32 and $\sim$8B tokens from the
RefinedWeb dataset, and show that they achieve competitive performance in
zero-shot and few-shot settings compared to scaled dot-product LLMs of similar
model size reported in the literature. We show that deductive outputs of
PLDR-LLMs can be used to compare model characteristics or improve the
performance by introducing the Directed Acyclic Graph (DAG) loss as a metric
and regularizer. Our results indicate that the initial maximum learning rate
and warm-up steps have a lasting impact on deductive outputs throughout the
pretraining. We provide a detailed description of PLDR-LLM architecture, its
implementation and the pretraining procedure.

æè¦ï¼æåæåºä½¿ç¨åªå¾è§£ç¢¼å¨è¡¨ç¤ºæ³çå¤§èªè¨æ¨¡å (PLDR-LLM)ï¼éæ¯ä¸åèªè¨æ¨¡åï¼å®ééåªå¾åæ³¨æåæ©å¶ï¼å©ç¨éç·æ§åç·æ§è½æä¾ç¢çå®ç¾©è¯å¥½çæ¼ç¹¹åæ­¸ç´è¼¸åºãæåä½¿ç¨ 32 çå°æ¹æ¬¡å¤§å°å RefinedWeb è³æéä¸­ç $\sim$8B ä»¤çï¼é è¨ç·´ä¸åå±¤å¤§å°ç PLDR-LLMï¼ä¸¦å±ç¤ºåºå®åå¨é¶æ¬¡åå°æ¬¡è¨­å®ä¸­ï¼èæç»ä¸­å ±å°çé¡ä¼¼æ¨¡åå¤§å°çç¸®æ¾é»ç© LLM ç¸æ¯ï¼å®åéå°äºç«¶ç­åè¡¨ç¾ãæåå±ç¤ºäº PLDR-LLM çæ¼ç¹¹è¼¸åºå¯ç¨æ¼æ¯è¼æ¨¡åç¹å¾µæééå¼å¥æåç¡ç°å (DAG) æå¤±ä½çºææ¨åæ­£ååå¨ä¾æ¹åæè½ãæåççµæè¡¨æï¼åå§æå¤§å­¸ç¿çåç±èº«æ­¥é©å°æ´åé è¨ç·´éç¨ä¸­çæ¼ç¹¹è¼¸åºææä¹çå½±é¿ãæåæä¾äº PLDR-LLM æ¶æ§ãå¶å¯¦ç¾åé è¨ç·´ç¨åºçè©³ç´°èªªæã

##### **Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for Improved Coverage and Efficiency**
2410.16597v1 by Prafulla Kumar Choubey, Xin Su, Man Luo, Xiangyu Peng, Caiming Xiong, Tiep Le, Shachar Rosenman, Vasudev Lal, Phil Mui, Ricky Ho, Phillip Howard, Chien-Sheng Wu

Knowledge graphs (KGs) generated by large language models (LLMs) are becoming
increasingly valuable for Retrieval-Augmented Generation (RAG) applications
that require knowledge-intensive reasoning. However, existing KG extraction
methods predominantly rely on prompt-based approaches, which are inefficient
for processing large-scale corpora. These approaches often suffer from
information loss, particularly with long documents, due to the lack of
specialized design for KG construction. Additionally, there is a gap in
evaluation datasets and methodologies for ontology-free KG construction. To
overcome these limitations, we propose SynthKG, a multi-step, document-level
ontology-free KG synthesis workflow based on LLMs. By fine-tuning a smaller LLM
on the synthesized document-KG pairs, we streamline the multi-step process into
a single-step KG generation approach called Distill-SynthKG, substantially
reducing the number of LLM inference calls. Furthermore, we re-purpose existing
question-answering datasets to establish KG evaluation datasets and introduce
new evaluation metrics. Using KGs produced by Distill-SynthKG, we also design a
novel graph-based retrieval framework for RAG. Experimental results demonstrate
that Distill-SynthKG not only surpasses all baseline models in KG quality --
including models up to eight times larger -- but also consistently excels in
retrieval and question-answering tasks. Our proposed graph retrieval framework
also outperforms all KG-retrieval methods across multiple benchmark datasets.
We release the SynthKG dataset and Distill-SynthKG model publicly to support
further research and development.

æè¦ï¼ç±å¤§åèªè¨æ¨¡å (LLM) çæçç¥è­åè­ (KG) å°æ¼éè¦ç¥è­å¯éåæ¨ççæª¢ç´¢å¢å¼·çæ (RAG) æç¨ç¨å¼è®å¾è¶ä¾è¶æå¹å¼ãç¶èï¼ç¾æç KG èåæ¹æ³ä¸»è¦ä¾è³´æ¼æç¤ºå¼æ¹æ³ï¼éç¨®æ¹æ³å°æ¼èçå¤§è¦æ¨¡èªæåº«èè¨æçä½ä¸ãç±æ¼ç¼ºä¹éå° KG å»ºæ§çå°éè¨­è¨ï¼éäºæ¹æ³éå¸¸æé­åè³è¨éºå¤±ï¼ç¹å¥æ¯å¨é·ç¯æä»¶çææ³ä¸ãæ­¤å¤ï¼å¨ç¨æ¼å»ºæ§ç¡æ¬ä½ KG çè©ä¼°è³æéåæ¹æ³è«æ¹é¢å­å¨å·®è·ãçºäºåæéäºéå¶ï¼æåæåºäº SynthKGï¼éæ¯ä¸ååºæ¼ LLM çå¤æ­¥é©æä»¶ç´å¥ç¡æ¬ä½ KG åæå·¥ä½æµç¨ãééå¾®èª¿è¼å°ç LLM å¨åæçæä»¶-KG å°ä¸ï¼æåå°å¤æ­¥é©æµç¨ç°¡åçºç¨±çº Distill-SynthKG çå®æ­¥é© KG çææ¹æ³ï¼å¤§å¹æ¸å°äº LLM æ¨è«å¼å«çæ¸éãæ­¤å¤ï¼æåéæ°å©ç¨ç¾æçåç­è³æéä¾å»ºç« KG è©ä¼°è³æéï¼ä¸¦å¼å¥æ°çè©ä¼°ææ¨ãä½¿ç¨ Distill-SynthKG çæç KGï¼æåéçº RAG è¨­è¨äºä¸åæ°ç©çåºæ¼åå½¢çæª¢ç´¢æ¶æ§ãå¯¦é©çµæè¡¨æï¼Distill-SynthKG ä¸åå¨ KG åè³ªæ¹é¢è¶è¶äºææåºæºæ¨¡åï¼åæ¬å¤§å«åçæ¨¡åï¼ï¼èä¸å¨æª¢ç´¢ååç­ä»»åä¸­ä¹å§çµè¡¨ç¾åºè²ãæåæåºçåå½¢æª¢ç´¢æ¶æ§å¨å¤ååºæºè³æéä¸ä¹åªæ¼ææ KG æª¢ç´¢æ¹æ³ãæåå¬ééåº SynthKG è³æéå Distill-SynthKG æ¨¡åï¼ä»¥æ¯æé²ä¸æ­¥çç ç©¶åéç¼ã

##### **Towards a Reliable Offline Personal AI Assistant for Long Duration Spaceflight**
2410.16397v1 by Oliver Bensch, Leonie Bensch, Tommy Nilsson, Florian Saling, Wafa M. Sadri, Carsten Hartmann, Tobias Hecking, J. Nathan Kutz

As humanity prepares for new missions to the Moon and Mars, astronauts will
need to operate with greater autonomy, given the communication delays that make
real-time support from Earth difficult. For instance, messages between Mars and
Earth can take up to 24 minutes, making quick responses impossible. This
limitation poses a challenge for astronauts who must rely on in-situ tools to
access the large volume of data from spacecraft sensors, rovers, and
satellites, data that is often fragmented and difficult to use. To bridge this
gap, systems like the Mars Exploration Telemetry-Driven Information System
(METIS) are being developed. METIS is an AI assistant designed to handle
routine tasks, monitor spacecraft systems, and detect anomalies, all while
reducing the reliance on mission control. Current Generative Pretrained
Transformer (GPT) Models, while powerful, struggle in safety-critical
environments. They can generate plausible but incorrect responses, a phenomenon
known as "hallucination," which could endanger astronauts. To overcome these
limitations, this paper proposes enhancing systems like METIS by integrating
GPTs, Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and
Augmented Reality (AR). The idea is to allow astronauts to interact with their
data more intuitively, using natural language queries and visualizing real-time
information through AR. KGs will be used to easily access live telemetry and
multimodal data, ensuring that astronauts have the right information at the
right time. By combining AI, KGs, and AR, this new system will empower
astronauts to work more autonomously, safely, and efficiently during future
space missions.

æè¦ï¼é¨èäººé¡æºååå¾æçåç«æå·è¡æ°ä»»åï¼èéå°éè¨å»¶é²è®ä¾èªå°ççå³ææ¯æ´è®å¾å°é£ï¼å¤ªç©ºäººå°éè¦ä»¥æ´é«çèªä¸»æ§å·è¡ä»»åãä¾å¦ï¼ç«æåå°çä¹éçè¨æ¯å³éå¯è½éè¦é·é 24 åéï¼éä½¿å¾å¿«éåæè®å¾ä¸å¯è½ãéåéå¶å°å¿é ä»°è³´ç¾å ´å·¥å·æè½å­åä¾èªå¤ªç©ºè¹ææ¸¬å¨ãæ¢æ¸¬è»åè¡æçå¤§éè³æçå¤ªç©ºäººä¾èªªæ¯ä¸é ææ°ï¼èéäºè³æéå¸¸æ¯çæ®µä¸é£ä»¥ä½¿ç¨çãçºäºå½åéåå·®è·ï¼åç«ææ¢æ¸¬éæ¸¬é©åè³è¨ç³»çµ± (METIS) ä¹é¡çç³»çµ±æ­£å¨éç¼ä¸­ãMETIS æ¯ä¸å AI å©çï¼æ¨å¨èçä¾è¡å·¥ä½ãç£æ§å¤ªç©ºè¹ç³»çµ±ååµæ¸¬ç°å¸¸ï¼åææ¸å°å°ä»»åæ§å¶çä¾è³´ãç¾æççæå¼é è¨ç·´Transformer (GPT) æ¨¡åéç¶å¼·å¤§ï¼ä½å¨å®å¨ééµç°å¢ä¸­å»é£ä»¥ç¼æ®ä½ç¨ãå®åå¯è½æç¢ççä¼¼åçä½é¯èª¤çåæï¼éç¨®ç¾è±¡ç¨±çºãå¹»è¦ºãï¼å¯è½æä½¿å¤ªç©ºäººé·å¥å±éªãçºäºåæéäºéå¶ï¼æ¬ææåºééæ´å GPTãæª¢ç´¢å¢å¼·çæ (RAG)ãç¥è­åè­ (KG) åæ´å¢å¯¦å¢ (AR) ä¾å¢å¼·å METIS ä¹é¡çç³»çµ±ãéåæ³æ³æ¯è®å¤ªç©ºäººè½å¤ æ´ç´è¦ºå°èä»åçè³æäºåï¼ä½¿ç¨èªç¶èªè¨æ¥è©¢ä¸¦éé AR è¦è¦ºåå³æè³è¨ãKG å°ç¨æ¼è¼é¬å­åå³æéæ¸¬åå¤æ¨¡å¼è³æï¼ç¢ºä¿å¤ªç©ºäººå¨é©ç¶çæéåå¾é©ç¶çè³è¨ãééçµå AIãKG å ARï¼éåæ°ç³»çµ±å°è³¦è½å¤ªç©ºäººå¨æªä¾çå¤ªç©ºä»»åä¸­æ´èªä¸»ãå®å¨ä¸ææçå°å·¥ä½ã

##### **A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns**
2410.16155v1 by Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao

With the development of large language models, they are widely used as agents
in various fields. A key component of agents is memory, which stores vital
information but is susceptible to jailbreak attacks. Existing research mainly
focuses on single-agent attacks and shared memory attacks. However, real-world
scenarios often involve independent memory. In this paper, we propose the
Troublemaker Makes Chaos in Honest Town (TMCHT) task, a large-scale,
multi-agent, multi-topology text-based attack evaluation framework. TMCHT
involves one attacker agent attempting to mislead an entire society of agents.
We identify two major challenges in multi-agent attacks: (1) Non-complete graph
structure, (2) Large-scale systems. We attribute these challenges to a
phenomenon we term toxicity disappearing. To address these issues, we propose
an Adversarial Replication Contagious Jailbreak (ARCJ) method, which optimizes
the retrieval suffix to make poisoned samples more easily retrieved and
optimizes the replication suffix to make poisoned samples have contagious
ability. We demonstrate the superiority of our approach in TMCHT, with 23.51%,
18.95%, and 52.93% improvements in line topology, star topology, and 100-agent
settings. Encourage community attention to the security of multi-agent systems.

æè¦ï¼éçå¤§åè¯­è¨æ¨¡åçåå±ï¼å®ä»¬è¢«å¹¿æ³ç¨ä½åä¸ªé¢åçä»£çãä»£ççå³é®ç»æé¨åæ¯è®°å¿ï¼å®å­å¨éè¦ä¿¡æ¯ï¼ä½å®¹æåå°è¶ç±æ»å»ãç°æç ç©¶ä¸»è¦éä¸­å¨åä¸ä»£çæ»å»åå±äº«åå­æ»å»ä¸ãç¶èï¼ç°å®ä¸çä¸­çåºæ¯éå¸¸æ¶åç¬ç«çåå­ãå¨æ¬æä¸­ï¼æä»¬æåºäº Troublemaker Makes Chaos in Honest Town (TMCHT) ä»»å¡ï¼è¿æ¯ä¸ä¸ªå¤§è§æ¨¡ãå¤ä»£çãå¤ææåºäºææ¬çæ»å»è¯ä¼°æ¡æ¶ãTMCHT æ¶åä¸ä¸ªæ»å»èä»£çè¯å¾è¯¯å¯¼æ´ä¸ªä»£çç¤¾ä¼ãæä»¬ç¡®å®äºå¤ä»£çæ»å»ä¸­çä¸¤ä¸ªä¸»è¦ææï¼(1) éå®æ´å¾ç»æï¼(2) å¤§è§æ¨¡ç³»ç»ãæä»¬å°è¿äºææå½å äºæä»¬ç§°ä¹ä¸ºæ¯æ§æ¶å¤±çç°è±¡ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬æåºäºä¸ç§å¯¹ææ§å¤å¶ä¼ ææ§è¶ç± (ARCJ) æ¹æ³ï¼è¯¥æ¹æ³ä¼åäºæ£ç´¢åç¼ä»¥ä½¿ä¸­æ¯æ ·æ¬æ´å®¹æè¢«æ£ç´¢ï¼å¹¶ä¼åäºå¤å¶åç¼ä»¥ä½¿ä¸­æ¯æ ·æ¬å·æä¼ ææ§ãæä»¬å¨ TMCHT ä¸­å±ç¤ºäºæä»¬æ¹æ³çä¼è¶æ§ï¼å¨ç´çº¿ææãæå½¢ææå 100 ä»£çè®¾ç½®ä¸­åå«æé«äº 23.51%ã18.95% å 52.93%ãé¼å±ç¤¾åºå³æ³¨å¤ä»£çç³»ç»çå®å¨æ§ã

##### **CausalGraph2LLM: Evaluating LLMs for Causal Queries**
2410.15939v1 by Ivaxi Sheth, Bahare Fatemi, Mario Fritz

Causality is essential in scientific research, enabling researchers to
interpret true relationships between variables. These causal relationships are
often represented by causal graphs, which are directed acyclic graphs. With the
recent advancements in Large Language Models (LLMs), there is an increasing
interest in exploring their capabilities in causal reasoning and their
potential use to hypothesize causal graphs. These tasks necessitate the LLMs to
encode the causal graph effectively for subsequent downstream tasks. In this
paper, we propose a comprehensive benchmark, \emph{CausalGraph2LLM},
encompassing a variety of causal graph settings to assess the causal graph
understanding capability of LLMs. We categorize the causal queries into two
types: graph-level and node-level queries. We benchmark both open-sourced and
closed models for our study. Our findings reveal that while LLMs show promise
in this domain, they are highly sensitive to the encoding used. Even capable
models like GPT-4 and Gemini-1.5 exhibit sensitivity to encoding, with
deviations of about $60\%$. We further demonstrate this sensitivity for
downstream causal intervention tasks. Moreover, we observe that LLMs can often
display biases when presented with contextual information about a causal graph,
potentially stemming from their parametric memory.

æè¦ï¼å æå³ç³»å¨ç§å­¦ç ç©¶ä¸­è³å³éè¦ï¼å®ä½¿ç ç©¶äººåè½å¤è§£éåéä¹é´ççå®å³ç³»ãè¿äºå æå³ç³»éå¸¸ç¨å æå¾è¡¨ç¤ºï¼å æå¾æ¯æåæ ç¯å¾ãéçå¤§è¯­è¨æ¨¡å (LLM) çææ°è¿å±ï¼äººä»¬è¶æ¥è¶æå´è¶£æ¢ç´¢å®ä»¬å¨å ææ¨çä¸­çè½åä»¥åå®ä»¬å¨åè®¾å æå¾ä¸­çæ½å¨ç¨éãè¿äºä»»å¡éè¦ LLM ææå°å¯¹å æå¾è¿è¡ç¼ç ï¼ä»¥ä¾¿åç»­çä¸æ¸¸ä»»å¡ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ä¸ªç»¼ååºåï¼\emph{CausalGraph2LLM}ï¼å®åå«äºåç§å æå¾è®¾ç½®ï¼ä»¥è¯ä¼° LLM çå æå¾çè§£è½åãæä»¬å°å ææ¥è¯¢åä¸ºä¸¤ç±»ï¼å¾çº§æ¥è¯¢åèç¹çº§æ¥è¯¢ãæä»¬å¯¹å¼æºæ¨¡ååå°é­æ¨¡åè¿è¡äºåºåæµè¯ãæä»¬çç ç©¶ç»æè¡¨æï¼è½ç¶ LLM å¨è¯¥é¢åæ¾ç¤ºåºåæ¯ï¼ä½å®ä»¬å¯¹æä½¿ç¨çç¼ç éå¸¸ææãå³ä½¿å GPT-4 å Gemini-1.5 è¿æ ·çå¼ºå¤§æ¨¡åä¹å¯¹ç¼ç è¡¨ç°åºæææ§ï¼åå·®çº¦ä¸º 60%ãæä»¬è¿ä¸æ­¥è¯æäºè¿ç§å¯¹ä¸æ¸¸å æå¹²é¢ä»»å¡çæææ§ãæ­¤å¤ï¼æä»¬è§å¯å°ï¼å½ LLM è·å¾æå³å æå¾çä¸ä¸æä¿¡æ¯æ¶ï¼å®ä»¬éå¸¸ä¼è¡¨ç°åºåè§ï¼è¿å¯è½æºäºå®ä»¬çåæ°è®°å¿ã

##### **LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation**
2410.15828v1 by Tejumade Afonja, Ivaxi Sheth, Ruta Binkyte, Waqar Hanif, Thomas Ulas, Matthias Becker, Mario Fritz

Gene regulatory networks (GRNs) represent the causal relationships between
transcription factors (TFs) and target genes in single-cell RNA sequencing
(scRNA-seq) data. Understanding these networks is crucial for uncovering
disease mechanisms and identifying therapeutic targets. In this work, we
investigate the potential of large language models (LLMs) for GRN discovery,
leveraging their learned biological knowledge alone or in combination with
traditional statistical methods. We develop a task-based evaluation strategy to
address the challenge of unavailable ground truth causal graphs. Specifically,
we use the GRNs suggested by LLMs to guide causal synthetic data generation and
compare the resulting data against the original dataset. Our statistical and
biological assessments show that LLMs can support statistical modeling and data
synthesis for biological research.

æè¦ï¼åºå èª¿æ§ç¶²è·¯ (GRN) ä»£è¡¨å®ç´°è RNA å®åº (scRNA-seq) è³æä¸­è½éå å­ (TF) èç®æ¨åºå ä¹éçå æéä¿ãäºè§£éäºç¶²è·¯å°æ¼æ­é²ç¾çæ©å¶åæ¾åºæ²»çç®æ¨è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) å¨ GRN æ¢ç´¢ä¸­çæ½åï¼å©ç¨å®åå­¸ç¿å°ççç©ç¥è­ï¼å®ç¨æèå³çµ±çµ±è¨æ¹æ³çµåä½¿ç¨ãæåå¶å®äºä¸é åºæ¼ä»»åçè©ä¼°ç­ç¥ï¼ä»¥è§£æ±ºç¡æ³åå¾å°é¢çç¸å æåè¡¨çææ°ãå·é«ä¾èªªï¼æåä½¿ç¨ LLM å»ºè­°ç GRN ä¾å¼å°å æåæè³æç¢çï¼ä¸¦å°ç¢ççè³æèåå§è³æéé²è¡æ¯è¼ãæåççµ±è¨åçç©è©ä¼°é¡¯ç¤ºï¼LLM å¯ä»¥æ¯æ´çç©ç ç©¶ççµ±è¨å»ºæ¨¡åè³æåæã

##### **NetSafe: Exploring the Topological Safety of Multi-agent Networks**
2410.15686v1 by Miao Yu, Shilong Wang, Guibin Zhang, Junyuan Mao, Chenlong Yin, Qijiong Liu, Qingsong Wen, Kun Wang, Yang Wang

Large language models (LLMs) have empowered nodes within multi-agent networks
with intelligence, showing growing applications in both academia and industry.
However, how to prevent these networks from generating malicious information
remains unexplored with previous research on single LLM's safety be challenging
to transfer. In this paper, we focus on the safety of multi-agent networks from
a topological perspective, investigating which topological properties
contribute to safer networks. To this end, we propose a general framework,
NetSafe along with an iterative RelCom interaction to unify existing diverse
LLM-based agent frameworks, laying the foundation for generalized topological
safety research. We identify several critical phenomena when multi-agent
networks are exposed to attacks involving misinformation, bias, and harmful
information, termed as Agent Hallucination and Aggregation Safety. Furthermore,
we find that highly connected networks are more susceptible to the spread of
adversarial attacks, with task performance in a Star Graph Topology decreasing
by 29.7%. Besides, our proposed static metrics aligned more closely with
real-world dynamic evaluations than traditional graph-theoretic metrics,
indicating that networks with greater average distances from attackers exhibit
enhanced safety. In conclusion, our work introduces a new topological
perspective on the safety of LLM-based multi-agent networks and discovers
several unreported phenomena, paving the way for future research to explore the
safety of such networks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è³¦äºäºå¤ä¸»é«ç¶²è·¯ä¸­çç¯é»æºæ§ï¼å¨å­¸è¡çåç¢æ¥­ä¸­å±ç¾åºè¶ä¾è¶å¤çæç¨ãç¶èï¼å¦ä½é²æ­¢éäºç¶²è·¯ç¢çæ¡æè³è¨ä»ç¶æ¯æªç¶æ¢ç´¢çé åï¼ååéå°å®ä¸ LLM å®å¨æ§çç ç©¶é£ä»¥è½ç§»ãå¨æ¬æä¸­ï¼æåå¾ææ²å­¸çè§åº¦æ¢è¨å¤ä¸»é«ç¶²è·¯çå®å¨æ§ï¼ç ç©¶åªäºææ²å±¬æ§æå©æ¼ç¶²è·¯æ´å®å¨ãçºæ­¤ï¼æåæåºäºä¸åéç¨æ¡æ¶ NetSafeï¼ä»¥åä¸ååè¦ç RelCom äºåï¼ä»¥çµ±ä¸ç¾æçåç¨®åºæ¼ LLM çä¸»é«æ¡æ¶ï¼çºå»£ç¾©çææ²å®å¨æ§ç ç©¶å¥ å®åºç¤ãæåå¨å¤ä¸»é«ç¶²è·¯é­åæ¶åé¯èª¤è³è¨ãåè¦åæå®³è³è¨çæ»ææï¼æ¾åºå¹¾åééµç¾è±¡ï¼ç¨±çºä¸»é«å¹»è¦ºåèåå®å¨æ§ãæ­¤å¤ï¼æåç¼ç¾é«åº¦é£æ¥çç¶²è·¯æ´å®¹æåå°å°ææ§æ»æçå½±é¿ï¼æå½¢åå½¢ææ²ä¸­çä»»åæè½ä¸éäº 29.7%ãæ­¤å¤ï¼æåæåºçéæææ¨æ¯å³çµ±çåè«ææ¨æ´è²¼è¿çå¯¦ä¸ççåæè©ä¼°ï¼éè¡¨ç¤ºèæ»æèå¹³åè·é¢è¼å¤§çç¶²è·¯å·ææ´é«çå®å¨æ§ãç¸½ä¹ï¼æåçç ç©¶å¼å¥äºåºæ¼ LLM çå¤ä¸»é«ç¶²è·¯å®å¨æ§çæ°ææ²è§é»ï¼ä¸¦ç¼ç¾äºå¹¾åæªæ¾å ±å°çç¾è±¡ï¼çºæªä¾æ¢ç´¢æ­¤é¡ç¶²è·¯å®å¨æ§çç ç©¶éªè·¯ã

##### **TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models**
2410.15268v1 by Bo Pan, Zhen Xiong, Guanchen Wu, Zheng Zhang, Yifei Zhang, Liang Zhao

Representation learning of Text-Attributed Graphs (TAGs) has garnered
significant attention due to its applications in various domains, including
recommendation systems and social networks. Despite advancements in TAG
learning methodologies, challenges remain in explainability due to the
black-box nature of existing TAG representation learning models. This paper
presents TAGExplainer, the first method designed to generate natural language
explanations for TAG learning. TAGExplainer employs a generative language model
that maps input-output pairs to explanations reflecting the model's
decision-making process. To address the lack of annotated ground truth
explanations in real-world scenarios, we propose first generating pseudo-labels
that capture the model's decisions from saliency-based explanations, then the
pseudo-label generator is iteratively trained based on three training
objectives focusing on faithfulness and brevity via Expert Iteration, to
improve the quality of generated pseudo-labels. The high-quality pseudo-labels
are finally utilized to train an end-to-end explanation generator model.
Extensive experiments are conducted to demonstrate the effectiveness of
TAGExplainer in producing faithful and concise natural language explanations.

æè¦ï¼ææ¬æ­¸å å (TAG) çè¡¨ç¤ºå­¸ç¿å å¶å¨åç¨®é åï¼åæ¬æ¨è¦ç³»çµ±åç¤¾äº¤ç¶²çµ¡ï¼ä¸­çæç¨èååéæ³¨ãåç®¡ TAG å­¸ç¿æ¹æ³åå¾äºé²å±ï¼ä½ç±æ¼ç¾æ TAG è¡¨ç¤ºå­¸ç¿æ¨¡åçé»ç®±æ§è³ªï¼å¯è§£éæ§ä»ç¶é¢è¨ææ°ãæ¬ææåºäº TAGExplainerï¼éæ¯ä¸ç¨®æ¨å¨çº TAG å­¸ç¿çæèªç¶èªè¨è§£éçç¬¬ä¸ç¨®æ¹æ³ãTAGExplainer æ¡ç¨çæèªè¨æ¨¡åï¼å°è¼¸å¥è¼¸åºå°æå°åæ æ¨¡åæ±ºç­éç¨çè§£éãçºäºè§£æ±ºç¾å¯¦å ´æ¯ä¸­ç¼ºä¹è¨»è§£å°é¢çå¯¦è§£éçåé¡ï¼æåå»ºè­°é¦åå¾åºæ¼é¡¯èæ§çè§£éä¸­çæå½æ¨ç±¤ä¾æææ¨¡åçæ±ºç­ï¼ç¶å¾ééå°å®¶è¿­ä»£åºæ¼ä¸åè¨ç·´ç®æ¨ï¼å´éæ¼å¿ å¯¦åº¦åç°¡æ½æ§ï¼åè¦è¨ç·´å½æ¨ç±¤çæå¨ï¼ä»¥æé«çæå½æ¨ç±¤çåè³ªãæå¾å°é«åè³ªçå½æ¨ç±¤ç¨æ¼è¨ç·´ç«¯å°ç«¯è§£éçæå¨æ¨¡åãé²è¡äºå»£æ³çå¯¦é©ï¼ä»¥è­æ TAGExplainer å¨çæå¿ å¯¦ä¸ç°¡æ½çèªç¶èªè¨è§£éæ¹é¢çæææ§ã

##### **Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction**
2410.15165v1 by Yinhan He, Zaiyi Zheng, Patrick Soga, Yaozhen Zhu, yushun Dong, Jundong Li

In recent years, Graph Neural Networks (GNNs) have become successful in
molecular property prediction tasks such as toxicity analysis. However, due to
the black-box nature of GNNs, their outputs can be concerning in high-stakes
decision-making scenarios, e.g., drug discovery. Facing such an issue, Graph
Counterfactual Explanation (GCE) has emerged as a promising approach to improve
GNN transparency. However, current GCE methods usually fail to take
domain-specific knowledge into consideration, which can result in outputs that
are not easily comprehensible by humans. To address this challenge, we propose
a novel GCE method, LLM-GCE, to unleash the power of large language models
(LLMs) in explaining GNNs for molecular property prediction. Specifically, we
utilize an autoencoder to generate the counterfactual graph topology from a set
of counterfactual text pairs (CTPs) based on an input graph. Meanwhile, we also
incorporate a CTP dynamic feedback module to mitigate LLM hallucination, which
provides intermediate feedback derived from the generated counterfactuals as an
attempt to give more faithful guidance. Extensive experiments demonstrate the
superior performance of LLM-GCE. Our code is released on
https://github.com/YinhanHe123/new\_LLM4GNNExplanation.

æè¦ï¼è¿å¹´æ¥ï¼å¾ç¥ç»ç½ç» (GNN) å·²æååºç¨äºåå­æ§è´¨é¢æµä»»å¡ï¼ä¾å¦æ¯æ§åæãç¶èï¼ç±äº GNN çé»çæ§è´¨ï¼å¶è¾åºå¨é«é£é©å³ç­åºæ¯ä¸­å¯è½ä¼ä»¤äººæå¿§ï¼ä¾å¦è¯ç©åç°ãéå¯¹è¿ä¸é®é¢ï¼å¾åäºå®è§£é (GCE) å·²æä¸ºæé« GNN éæåº¦çä¸ç§å¾æåæ¯çæ¹æ³ãç¶èï¼å½åç GCE æ¹æ³éå¸¸æ æ³èèç¹å®é¢åçç¥è¯ï¼è¿å¯è½å¯¼è´äººç±»é¾ä»¥çè§£è¾åºãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäºä¸ç§æ°é¢ç GCE æ¹æ³ï¼LLM-GCEï¼ä»¥éæ¾å¤§åè¯­è¨æ¨¡å (LLM) å¨è§£é GNN ç¨äºåå­æ§è´¨é¢æµæ¹é¢çè½åãå·ä½æ¥è¯´ï¼æä»¬å©ç¨èªå¨ç¼ç å¨ä»ä¸ç»åºäºè¾å¥å¾çåäºå®ææ¬å¯¹ (CTP) çæåäºå®å¾ææãåæ¶ï¼æä»¬è¿å å¥äºä¸ä¸ª CTP å¨æåé¦æ¨¡åæ¥åè½» LLM å¹»è§ï¼è¯¥æ¨¡åæä¾ä»çæçåäºå®ä¸­æ´¾ççä¸­é´åé¦ï¼ä»¥å°è¯æä¾æ´çå®çæå¯¼ãå¤§éçå®éªè¡¨æäº LLM-GCE çåè¶æ§è½ãæä»¬çä»£ç å·²åå¸å¨ https://github.com/YinhanHe123/new\_LLM4GNNExplanationã

##### **MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science**
2410.15126v1 by Junho Kim, Yeachan Kim, Jun-Hyung Park, Yerim Oh, Suho Kim, SangKeun Lee

We introduce a novel continued pre-training method, MELT (MatEriaLs-aware
continued pre-Training), specifically designed to efficiently adapt the
pre-trained language models (PLMs) for materials science. Unlike previous
adaptation strategies that solely focus on constructing domain-specific corpus,
MELT comprehensively considers both the corpus and the training strategy, given
that materials science corpus has distinct characteristics from other domains.
To this end, we first construct a comprehensive materials knowledge base from
the scientific corpus by building semantic graphs. Leveraging this extracted
knowledge, we integrate a curriculum into the adaptation process that begins
with familiar and generalized concepts and progressively moves toward more
specialized terms. We conduct extensive experiments across diverse benchmarks
to verify the effectiveness and generality of MELT. A comprehensive evaluation
convincingly supports the strength of MELT, demonstrating superior performance
compared to existing continued pre-training methods. The in-depth analysis also
shows that MELT enables PLMs to effectively represent materials entities
compared to the existing adaptation methods, thereby highlighting its broad
applicability across a wide spectrum of materials science.

æè¦ï¼æåä»ç´¹äºä¸ç¨®æ°ç©çæçºé è¨ç·´æ¹æ³ï¼MELTï¼MatEriaLs-awareæçºé è¨ç·´ï¼ï¼å°éè¨­è¨ç¨æ¼ææå°èª¿æ´ææç§å­¸çé è¨ç·´èªè¨æ¨¡å (PLM)ãèåååå°æ³¨æ¼å»ºæ§ç¹å®é åèªæåº«çèª¿æ´ç­ç¥ä¸åï¼MELT å¨é¢èæ®èªæåº«åè¨ç·´ç­ç¥ï¼å çºææç§å­¸èªæåº«å·æä¸åæ¼å¶ä»é åçç¹å¾µãçºæ­¤ï¼æåé¦åééå»ºç«èªç¾©åå¾ç§å­¸èªæåº«æ§å»ºä¸åå¨é¢çææç¥è­åº«ãå©ç¨æåçç¥è­ï¼æåå°èª²ç¨æ´åå°èª¿æ´éç¨ä¸­ï¼å¾çæä¸éç¨çæ¦å¿µéå§ï¼éæ¼¸è½åæ´å°æ¥­çè¡èªãæåå¨ä¸åçåºæºä¸é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥é©è­ MELT çæææ§åæ®éæ§ãå¨é¢çè©ä¼°ä»¤äººä¿¡æå°æ¯æäº MELT çåªé»ï¼èç¾æçæçºé è¨ç·´æ¹æ³ç¸æ¯ï¼è¡¨ç¾åºåªç°çæ§è½ãæ·±å¥åæéè¡¨æï¼èç¾æçèª¿æ´æ¹æ³ç¸æ¯ï¼MELT è½è® PLM ææå°è¡¨ç¤ºææå¯¦é«ï¼å¾èçªé¡¯å¶å¨å»£æ³çææç§å­¸é åä¸­çå»£æ³é©ç¨æ§ã

##### **Coarse-to-Fine Highlighting: Reducing Knowledge Hallucination in Large Language Models**
2410.15116v1 by Qitan Lv, Jie Wang, Hanzhu Chen, Bin Li, Yongdong Zhang, Feng Wu

Generation of plausible but incorrect factual information, often termed
hallucination, has attracted significant research interest. Retrieval-augmented
language model (RALM) -- which enhances models with up-to-date knowledge --
emerges as a promising method to reduce hallucination. However, existing RALMs
may instead exacerbate hallucination when retrieving lengthy contexts. To
address this challenge, we propose COFT, a novel
\textbf{CO}arse-to-\textbf{F}ine highligh\textbf{T}ing method to focus on
different granularity-level key texts, thereby avoiding getting lost in lengthy
contexts. Specifically, COFT consists of three components: \textit{recaller},
\textit{scorer}, and \textit{selector}. First, \textit{recaller} applies a
knowledge graph to extract potential key entities in a given context. Second,
\textit{scorer} measures the importance of each entity by calculating its
contextual weight. Finally, \textit{selector} selects high contextual weight
entities with a dynamic threshold algorithm and highlights the corresponding
paragraphs, sentences, or words in a coarse-to-fine manner. Extensive
experiments on the knowledge hallucination benchmark demonstrate the
effectiveness of COFT, leading to a superior performance over $30\%$ in the F1
score metric. Moreover, COFT also exhibits remarkable versatility across
various long-form tasks, such as reading comprehension and question answering.

æè¦ï¼çæçä¼¼åçä½å®éä¸ä¸æ­£ç¡®çå®éä¿¡æ¯ï¼éå¸¸ç§°ä¸ºå¹»è§ï¼å¼èµ·äºéè¦çç ç©¶å´è¶£ãæ£ç´¢å¢å¼ºè¯­è¨æ¨¡å (RALM) éè¿ä¸ºæ¨¡åæä¾ææ°çç¥è¯æ¥å¢å¼ºæ¨¡åï¼è¿æ¯ä¸ç§æåéçæ¹æ³ï¼å¯ä»¥åå°å¹»è§ãç¶èï¼ç°æç RALM å¨æ£ç´¢åé¿çä¸ä¸ææ¶å¯è½ä¼å å§å¹»è§ãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäº COFTï¼ä¸ç§æ°é¢ç\textbf{ç²}å°\textbf{ç»}é«äº®\textbf{T}ing æ¹æ³ï¼ä¸æ³¨äºä¸åç²åº¦çº§å«çå³é®ææ¬ï¼ä»èé¿åå¨åé¿çä¸ä¸æä¸­è¿·å¤±ãå·ä½æ¥è¯´ï¼COFT ç±ä¸ä¸ªç»ä»¶ç»æï¼\textit{recaller}ã\textit{scorer} å \textit{selector}ãé¦åï¼\textit{recaller} åºç¨ç¥è¯å¾è°±æ¥æåç»å®ä¸ä¸æä¸­æ½å¨çå³é®å®ä½ãå¶æ¬¡ï¼\textit{scorer} éè¿è®¡ç®æ¯ä¸ªå®ä½çä¸ä¸ææéæ¥è¡¡éå¶éè¦æ§ãæåï¼\textit{selector} ä½¿ç¨å¨æéå¼ç®æ³éæ©å·æé«ä¸ä¸ææéçå®ä½ï¼å¹¶ä»¥ç²å°ç»çæ¹å¼çªåºæ¾ç¤ºç¸åºçæ®µè½ãå¥å­æåè¯ãå¨ç¥è¯å¹»è§åºåä¸çå¹¿æ³å®éªè¯æäº COFT çæææ§ï¼å¨ F1 åæ°ææ ä¸åå¾äºè¶è¿ 30% çåè¶æ§è½ãæ­¤å¤ï¼COFT å¨åç§é¿ç¯ä»»å¡ä¸­ä¹è¡¨ç°åºåè¶çå¤åè½æ§ï¼ä¾å¦éè¯»çè§£åé®é¢è§£ç­ã

##### **A Prompt Engineering Approach and a Knowledge Graph based Framework for Tackling Legal Implications of Large Language Model Answers**
2410.15064v1 by George Hannah, Rita T. Sousa, Ioannis Dasoulas, Claudia d'Amato

With the recent surge in popularity of Large Language Models (LLMs), there is
the rising risk of users blindly trusting the information in the response, even
in cases where the LLM recommends actions that have potential legal
implications and this may put the user in danger. We provide an empirical
analysis on multiple existing LLMs showing the urgency of the problem. Hence,
we propose a short-term solution consisting in an approach for isolating these
legal issues through prompt re-engineering. We further analyse the outcomes but
also the limitations of the prompt engineering based approach and we highlight
the need of additional resources for fully solving the problem We also propose
a framework powered by a legal knowledge graph (KG) to generate legal citations
for these legal issues, enriching the response of the LLM.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡åï¼LLMï¼è¿ææµè¡æ¿å¢ï¼ä½¿ç¨èç²ç®ç¸ä¿¡åæä¸­è³è¨çé¢¨éªä¹é¨ä¹åé«ï¼å³ä½¿å¨ LLM å»ºè­°æ¡åå¯è½ç¢çæ³å¾å½±é¿çè¡åæäº¦ç¶ï¼éå¯è½æä½¿ä½¿ç¨èé·å¥å±éªä¹ä¸­ãæåéå°å¤åç¾æ LLM æä¾å¯¦è­åæï¼é¡¯ç¤ºæ­¤åé¡çæ¥è¿«æ§ãå æ­¤ï¼æåæåºä¸åç­æè§£æ±ºæ¹æ¡ï¼åæ¬ééæç¤ºéæ°è¨­è¨ä¾å­¤ç«éäºæ³å¾åé¡çæ¹æ³ãæåé²ä¸æ­¥åææç¤ºå·¥ç¨æ¹æ³çææï¼ä½ä¹åæå¶éå¶ï¼ä¸¦å¼·èª¿å®å¨è§£æ±ºåé¡éè¦é¡å¤è³æºãæåéæåºä¸åç±æ³å¾ç¥è­åè­ï¼KGï¼é©åçæ¶æ§ï¼çºéäºæ³å¾åé¡ç¢çæ³å¾å¼æï¼è±å¯ LLM çåæã

##### **LangGFM: A Large Language Model Alone Can be a Powerful Graph Foundation Model**
2410.14961v1 by Tianqianjin Lin, Pengwei Yan, Kaisong Song, Zhuoren Jiang, Yangyang Kang, Jun Lin, Weikang Yuan, Junjie Cao, Changlong Sun, Xiaozhong Liu

Graph foundation models (GFMs) have recently gained significant attention.
However, the unique data processing and evaluation setups employed by different
studies hinder a deeper understanding of their progress. Additionally, current
research tends to focus on specific subsets of graph learning tasks, such as
structural tasks, node-level tasks, or classification tasks. As a result, they
often incorporate specialized modules tailored to particular task types, losing
their applicability to other graph learning tasks and contradicting the
original intent of foundation models to be universal. Therefore, to enhance
consistency, coverage, and diversity across domains, tasks, and research
interests within the graph learning community in the evaluation of GFMs, we
propose GFMBench-a systematic and comprehensive benchmark comprising 26
datasets. Moreover, we introduce LangGFM, a novel GFM that relies entirely on
large language models. By revisiting and exploring the effective graph
textualization principles, as well as repurposing successful techniques from
graph augmentation and graph self-supervised learning within the language
space, LangGFM achieves performance on par with or exceeding the state of the
art across GFMBench, which can offer us new perspectives, experiences, and
baselines to drive forward the evolution of GFMs.

æè¦ï¼åå½¢åºç¤æ¨¡å (GFM) è¿æç²å¾é¡¯èçéæ³¨ã
ç¶èï¼ä¸åç ç©¶æ¡ç¨ç¨ç¹è³æèçåè©ä¼°è¨­å®ï¼é»ç¤äºå°å¶é²å±çæ·±å¥çè§£ãæ­¤å¤ï¼ç®åçç ç©¶å¾åæ¼å°æ³¨æ¼åå½¢å­¸ç¿ä»»åçç¹å®å­éï¼ä¾å¦çµæ§ä»»åãç¯é»å±¤ç´ä»»åæåé¡ä»»åãå æ­¤ï¼å®åç¶å¸¸æ´åå°ééå°ç¹å®ä»»åé¡åéèº«æé çæ¨¡çµï¼å¤±å»å¶å°å¶ä»åå½¢å­¸ç¿ä»»åçé©ç¨æ§ï¼ä¸¦èåºç¤æ¨¡åæçºéç¨çåå§æåç¸çç¾ãå æ­¤ï¼çºäºå¢å¼·åå½¢å­¸ç¿ç¤¾ç¾¤å¨è©ä¼° GFM æè·¨é åãä»»ååç ç©¶èè¶£çä¸è´æ§ãæ¶µèç¯ååå¤æ¨£æ§ï¼æåæåº GFMBenchï¼éæ¯ä¸ååå« 26 åè³æéçç³»çµ±åä¸å¨é¢çåºæºãæ­¤å¤ï¼æåä»ç´¹ LangGFMï¼éæ¯ä¸ç¨®å®å¨ä¾è³´å¤§åèªè¨æ¨¡åçæ°ç© GFMãéééæ°æª¢è¦åæ¢ç´¢ææçåå½¢æå­åååï¼ä»¥åå¨èªè¨ç©ºéä¸­éæ°å©ç¨åå½¢æ´åååå½¢èªç£ç£å­¸ç¿çæåæè¡ï¼LangGFM å¨ GFMBench ä¸å¯¦ç¾èç¾ææè¡åç­æè¶è¶ç¾ææè¡çæè½ï¼éå¯ä»¥çºæåæä¾æ°çè§é»ãç¶é©ååºæºï¼ä»¥æ¨å GFM çæ¼é²ã

##### **TransBox: EL++-closed Ontology Embedding**
2410.14571v1 by Hui Yang, Jiaoyan Chen, Uli Sattler

OWL (Web Ontology Language) ontologies, which are able to represent both
relational and type facts as standard knowledge graphs and complex domain
knowledge in Description Logic (DL) axioms, are widely adopted in domains such
as healthcare and bioinformatics. Inspired by the success of knowledge graph
embeddings, embedding OWL ontologies has gained significant attention in recent
years. Current methods primarily focus on learning embeddings for atomic
concepts and roles, enabling the evaluation based on normalized axioms through
specially designed score functions. However, they often neglect the embedding
of complex concepts, making it difficult to infer with more intricate axioms.
This limitation reduces their effectiveness in advanced reasoning tasks, such
as Ontology Learning and ontology-mediated Query Answering. In this paper, we
propose EL++-closed ontology embeddings which are able to represent any logical
expressions in DL via composition. Furthermore, we develop TransBox, an
effective EL++-closed ontology embedding method that can handle many-to-one,
one-to-many and many-to-many relations. Our extensive experiments demonstrate
that TransBox often achieves state-of-the-art performance across various
real-world datasets for predicting complex axioms.

æè¦ï¼OWLï¼Web Ontology Languageï¼æ¬ä½ï¼è½å¤å°å³ç³»åç±»åäºå®è¡¨ç¤ºä¸ºæ åç¥è¯å¾åæè¿°é»è¾ (DL) å¬çä¸­çå¤æé¢åç¥è¯ï¼å¨å»çä¿å¥åçç©ä¿¡æ¯å­¦ç­é¢åå¾å°å¹¿æ³éç¨ãåç¥è¯å¾åµå¥çæåå¯åï¼åµå¥ OWL æ¬ä½è¿å¹´æ¥å¤åå³æ³¨ãå½åæ¹æ³ä¸»è¦éä¸­å¨å­¦ä¹ åå­æ¦å¿µåè§è²çåµå¥ï¼éè¿ä¸é¨è®¾è®¡çè¯åå½æ°ï¼æ¯æåºäºå½ä¸åå¬ççè¯ä¼°ãç¶èï¼å®ä»¬ç»å¸¸å¿½ç¥å¤ææ¦å¿µçåµå¥ï¼è¿ä½¿å¾é¾ä»¥æ¨æ­åºæ´å¤æçå¬çãè¿ç§éå¶éä½äºå®ä»¬å¨é«çº§æ¨çä»»å¡ï¼ä¾å¦æ¬ä½å­¦ä¹ åæ¬ä½ä»å¯¼æ¥è¯¢åºç­ï¼ä¸­çæææ§ãå¨æ¬æä¸­ï¼æä»¬æåºäº EL++ å°é­æ¬ä½åµå¥ï¼å®è½å¤éè¿ç»åæ¥è¡¨ç¤º DL ä¸­çä»»ä½é»è¾è¡¨è¾¾å¼ãæ­¤å¤ï¼æä»¬å¼åäº TransBoxï¼ä¸ç§ææç EL++ å°é­æ¬ä½åµå¥æ¹æ³ï¼å¯ä»¥å¤çå¤å¯¹ä¸ãä¸å¯¹å¤åå¤å¯¹å¤å³ç³»ãæä»¬å¹¿æ³çå®éªè¡¨æï¼TransBox å¨é¢æµå¤æå¬ççåç§çå®ä¸çæ°æ®éä¸éå¸¸é½è½è¾¾å°æåè¿çæ§è½ã

##### **Enabling Scalable Evaluation of Bias Patterns in Medical LLMs**
2410.14763v1 by Hamed Fayyaz, Raphael Poulain, Rahmatollah Beheshti

Large language models (LLMs) have shown impressive potential in helping with
numerous medical challenges. Deploying LLMs in high-stakes applications such as
medicine, however, brings in many concerns. One major area of concern relates
to biased behaviors of LLMs in medical applications, leading to unfair
treatment of individuals. To pave the way for the responsible and impactful
deployment of Med LLMs, rigorous evaluation is a key prerequisite. Due to the
huge complexity and variability of different medical scenarios, existing work
in this domain has primarily relied on using manually crafted datasets for bias
evaluation. In this study, we present a new method to scale up such bias
evaluations by automatically generating test cases based on rigorous medical
evidence. We specifically target the challenges of a) domain-specificity of
bias characterization, b) hallucinating while generating the test cases, and c)
various dependencies between the health outcomes and sensitive attributes. To
that end, we offer new methods to address these challenges integrated with our
generative pipeline, using medical knowledge graphs, medical ontologies, and
customized general LLM evaluation frameworks in our method. Through a series of
extensive experiments, we show that the test cases generated by our proposed
method can effectively reveal bias patterns in Med LLMs at larger and more
flexible scales than human-crafted datasets. We publish a large bias evaluation
dataset using our pipeline, which is dedicated to a few medical case studies. A
live demo of our application for vignette generation is available at
https://vignette.streamlit.app. Our code is also available at
https://github.com/healthylaife/autofair.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºå¨åå©è§£æ±º
è¨±å¤é«çææ°æ¹é¢çé©äººæ½åãç¶èï¼å¨é«é¢¨éªæç¨ç¨å¼ï¼ä¾å¦
é«çï¼ä¸­é¨ç½² LLM æå¸¶ä¾è¨±å¤çæ®ãä¸åä¸»è¦ççæ®é åè
é«çæç¨ç¨å¼ä¸­ LLM çåè¦è¡çºæéï¼å°è´å°åäººä¸å¬å¹³ç
å¾éãçºäºçºè² è²¬ä»»ä¸æå½±é¿åç Med LLM é¨ç½²éªè·¯ï¼å´è¬¹ç
è©ä¼°æ¯ä¸é ééµåæãç±æ¼ä¸åé«çå ´æ¯çè¤éæ§åè®ç°æ§æ¥µå¤§ï¼
æ­¤é åç¾æçå·¥ä½ä¸»è¦ä¾è³´ä½¿ç¨äººå·¥è£½ä½çè³æéé²è¡åè¦
è©ä¼°ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼å¯ä»¥æ ¹æå´è¬¹çé«ç
è­æèªåç¢çæ¸¬è©¦æ¡ä¾ï¼ä»¥æ´å¤§æ­¤é¡åè¦è©ä¼°ãæåç¹å¥éå°
a) åè¦ç¹å¾µçé åå°å±¬æ§ãb) å¨ç¢çæ¸¬è©¦æ¡ä¾æåºç¾å¹»è¦ºï¼ä»¥å c)
å¥åº·çµæåææå±¬æ§ä¹éçåç¨®ä¾è³´æ§ç­ææ°ãçºæ­¤ï¼æåæä¾
æ°çæ¹æ³ä¾è§£æ±ºéäºææ°ï¼ä¸¦å°å¶èæåççæç®¡éæ´åï¼å¨æåç
æ¹æ³ä¸­ä½¿ç¨é«çç¥è­åãé«çæ¬ä½åèªè¨çéç¨ LLM è©ä¼°æ¶æ§ãéé
ä¸ç³»åå»£æ³çå¯¦é©ï¼æåè¡¨ææåæåºçæ¹æ³ç¢ççæ¸¬è©¦æ¡ä¾å¯ä»¥ææ
æ­ç¤º Med LLM ä¸­çåè¦æ¨¡å¼ï¼å¶è¦æ¨¡æ¯äººå·¥è£½ä½çè³æéæ´å¤§ä¸æ´å·
å½æ§ãæåä½¿ç¨æåçç®¡éç¼å¸äºä¸åå¤§ååè¦è©ä¼°è³æéï¼è©²è³æé
å°ééå°ä¸äºé«çæ¡ä¾ç ç©¶ãæåçå°æåçææç¨ç¨å¼çç¾å ´ç¤ºç¯
å¯å¨ https://vignette.streamlit.app åå¾ãæåçç¨å¼ç¢¼ä¹å¯å¨
https://github.com/healthylaife/autofair åå¾ã

##### **Paths-over-Graph: Knowledge Graph Empowered Large Language Model Reasoning**
2410.14211v2 by Xingyu Tan, Xiaoyang Wang, Qing Liu, Xiwei Xu, Xin Yuan, Wenjie Zhang

Large Language Models (LLMs) have achieved impressive results in various
tasks but struggle with hallucination problems and lack of relevant knowledge,
especially in deep complex reasoning and knowledge-intensive tasks. Knowledge
Graphs (KGs), which capture vast amounts of facts in a structured format, offer
a reliable source of knowledge for reasoning. However, existing KG-based LLM
reasoning methods face challenges like handling multi-hop reasoning,
multi-entity questions, and effectively utilizing graph structures. To address
these issues, we propose Paths-over-Graph (PoG), a novel method that enhances
LLM reasoning by integrating knowledge reasoning paths from KGs, improving the
interpretability and faithfulness of LLM outputs. PoG tackles multi-hop and
multi-entity questions through a three-phase dynamic multi-hop path
exploration, which combines the inherent knowledge of LLMs with factual
knowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant
information from the graph exploration first and introduces efficient
three-step pruning techniques that incorporate graph structures, LLM prompting,
and a pre-trained language model (e.g., SBERT) to effectively narrow down the
explored candidate paths. This ensures all reasoning paths contain highly
relevant information captured from KGs, making the reasoning faithful and
interpretable in problem-solving. PoG innovatively utilizes graph structure to
prune the irrelevant noise and represents the first method to implement
multi-entity deep path detection on KGs for LLM reasoning tasks. Comprehensive
experiments on five benchmark KGQA datasets demonstrate PoG outperforms the
state-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an
average accuracy improvement of 18.9%. Notably, PoG with GPT-3.5-Turbo
surpasses ToG with GPT-4 by up to 23.9%.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­åå¾ä»¤äººå°è±¡æ·±å»çææï¼ä½ä»å­å¨å¹»è¦ºåé¡åç¼ºä¹ç¸éç¥è­ï¼å°¤å¶æ¯å¨æ·±åº¦è¤éæ¨çåç¥è­å¯éåä»»åä¸­ãç¥è­åè­ (KG) ä»¥çµæ§åæ ¼å¼æ·åå¤§éäºå¯¦ï¼çºæ¨çæä¾äºå¯é çç¥è­ä¾æºãç¶èï¼ç¾æçåºæ¼ KG ç LLM æ¨çæ¹æ³é¢è¨èçå¤è·³æ¨çãå¤å¯¦é«åé¡åææå©ç¨åçµæ§ç­ææ°ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºåä¸è·¯å¾ (PoG)ï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼ééæ´åä¾èª KG çç¥è­æ¨çè·¯å¾ä¾å¢å¼· LLM æ¨çï¼æé« LLM è¼¸åºçå¯è§£éæ§åä¿çæ§ãPoG ééä¸éæ®µåæå¤è·³è·¯å¾æ¢ç´¢ä¾è§£æ±ºå¤è·³åå¤å¯¦é«åé¡ï¼å° LLM çåºæç¥è­èä¾èª KG çäºå¯¦ç¥è­ç¸çµåãçºäºæé«æçï¼PoG é¦åå¾åæ¢ç´¢ä¸­åªé¤ç¡éä¿¡æ¯ï¼ä¸¦å¼å¥äºä¸æ­¥åªææè¡ï¼éäºæè¡çµåäºåçµæ§ãLLM æç¤ºåé è¨ç·´èªè¨æ¨¡åï¼ä¾å¦ï¼SBERTï¼ä¾ææç¸®å°æ¢ç´¢çåé¸è·¯å¾ãéç¢ºä¿äºæææ¨çè·¯å¾é½åå«å¾ KG æ·åçé«åº¦ç¸éä¿¡æ¯ï¼å¾èä½¿æ¨çå¨åé¡è§£æ±ºä¸­å·æä¿çæ§åå¯è§£éæ§ãPoG åµæ°å°å©ç¨åçµæ§ä¾åªé¤ç¡éåªè²ï¼ä¸¦ä»£è¡¨äºå¨ KG ä¸å¯¦ç¾ LLM æ¨çä»»åçå¤å¯¦é«æ·±åº¦è·¯å¾æª¢æ¸¬çç¬¬ä¸ç¨®æ¹æ³ãå¨äºååºæº KGQA æ¸æéä¸çç¶åå¯¦é©è¡¨æï¼PoG å¨ GPT-3.5-Turbo å GPT-4 ä¸çè¡¨ç¾åªæ¼æåé²çæ¹æ³ ToGï¼å¹³åæºç¢ºçæé«äº 18.9%ãå¼å¾æ³¨æçæ¯ï¼ä½¿ç¨ GPT-3.5-Turbo ç PoG æ¯ä½¿ç¨ GPT-4 ç ToG é«åº 23.9%ã

##### **UniMTS: Unified Pre-training for Motion Time Series**
2410.19818v1 by Xiyuan Zhang, Diyan Teng, Ranak Roy Chowdhury, Shuheng Li, Dezhi Hong, Rajesh K. Gupta, Jingbo Shang

Motion time series collected from mobile and wearable devices such as
smartphones and smartwatches offer significant insights into human behavioral
patterns, with wide applications in healthcare, automation, IoT, and AR/XR due
to their low-power, always-on nature. However, given security and privacy
concerns, building large-scale motion time series datasets remains difficult,
preventing the development of pre-trained models for human activity analysis.
Typically, existing models are trained and tested on the same dataset, leading
to poor generalizability across variations in device location, device mounting
orientation and human activity type. In this paper, we introduce UniMTS, the
first unified pre-training procedure for motion time series that generalizes
across diverse device latent factors and activities. Specifically, we employ a
contrastive learning framework that aligns motion time series with text
descriptions enriched by large language models. This helps the model learn the
semantics of time series to generalize across activities. Given the absence of
large-scale motion time series data, we derive and synthesize time series from
existing motion skeleton data with all-joint coverage. Spatio-temporal graph
networks are utilized to capture the relationships across joints for
generalization across different device locations. We further design
rotation-invariant augmentation to make the model agnostic to changes in device
mounting orientations. Our model shows exceptional generalizability across 18
motion time series classification benchmark datasets, outperforming the best
baselines by 340% in the zero-shot setting, 16.3% in the few-shot setting, and
9.2% in the full-shot setting.

æè¦ï¼å¾æºæ§åææ©èæºæ§åæé¶ç­è¡åè£ç½®åç©¿æ´å¼è£ç½®æ¶éçåä½æéåºåï¼ç±æ¼å¶ä½èé»ãæçºéä½çç¹æ§ï¼å¯æä¾äººé¡è¡çºæ¨¡å¼çéè¦è¦è§£ï¼å¨é«çä¿å¥ãèªååãç©è¯ç¶²å AR/XR ä¸­æå»£æ³çæç¨ãç¶èï¼èéå°å®å¨æ§åé±ç§åé¡ï¼å»ºæ§å¤§è¦æ¨¡çåä½æéåºåè³æéä»ç¶å°é£ï¼é»ç¤äºäººé¡æ´»ååæé åè¨ç·´æ¨¡åçç¼å±ãä¸è¬ä¾èªªï¼ç¾æçæ¨¡åæå¨åä¸åè³æéä¸è¨ç·´åæ¸¬è©¦ï¼å°è´ç¡æ³å°è£ç½®ä½ç½®ãè£ç½®å®è£æ¹ååäººé¡æ´»åé¡åçè®åé²è¡è¯å¥½çæ¦åãå¨æ¬æä¸­ï¼æåä»ç´¹ UniMTSï¼éæ¯ç¬¬ä¸åçµ±ä¸çåä½æéåºåé è¨ç·´ç¨åºï¼å¯æ¦åå°ä¸åçè£ç½®æ½å¨å å­åæ´»åãå·é«ä¾èªªï¼æåæ¡ç¨å°æ¯å­¸ç¿æ¶æ§ï¼å°åä½æéåºåèå¤§åèªè¨æ¨¡åè±å¯çæå­æè¿°å°é½ãéæå©æ¼æ¨¡åå­¸ç¿æéåºåçèªç¾©ï¼ä»¥æ¦åå°åç¨®æ´»åãç±æ¼ç¼ºä¹å¤§è¦æ¨¡çåä½æéåºåè³æï¼æåå¾ç¾æçåä½éª¨æ¶è³æä¸­è¡çååææéåºåï¼ä¸¦æ¶µèææéç¯ãæç©ºåå½¢ç¶²è·¯ç¨æ¼æ·åéç¯ä¹éçéä¿ï¼ä»¥æ¦åå°ä¸åçè£ç½®ä½ç½®ãæåé²ä¸æ­¥è¨­è¨äºæè½ä¸è®å¢å¼·ï¼è®æ¨¡åä¸æåè£ç½®å®è£æ¹åè®åçå½±é¿ãæåçæ¨¡åå¨ 18 ååä½æéåºååé¡åºæºè³æéä¸å±ç¾åºåè¶çæ¦åè½åï¼å¨é¶æ¬¡å­¸ç¿è¨­å®ä¸­åªæ¼æä½³åºæº 340%ï¼å¨å°æ¬¡å­¸ç¿è¨­å®ä¸­åªæ¼æä½³åºæº 16.3%ï¼å¨å¨æ¬¡å­¸ç¿è¨­å®ä¸­åªæ¼æä½³åºæº 9.2%ã

##### **Supervised Chain of Thought**
2410.14198v1 by Xiang Zhang, Dujian Ding

Large Language Models (LLMs) have revolutionized natural language processing
and hold immense potential for advancing Artificial Intelligence. However, the
core architecture of most mainstream LLMs -- the Transformer -- has inherent
limitations in computational depth, rendering them theoretically incapable of
solving many reasoning tasks that demand increasingly deep computations. Chain
of Thought (CoT) prompting has emerged as a technique to address these
architectural limitations, as evidenced by several theoretical studies. It
offers a promising approach to solving complex reasoning tasks that were
previously beyond the capabilities of these models. Despite its successes, CoT
and its variants (such as Tree of Thought, Graph of Thought, etc.) rely on a
"one-prompt-for-all" approach, using a single prompt structure (e.g., "think
step by step") for a wide range of tasks -- from counting and sorting to
solving mathematical and algorithmic problems. This approach poses significant
challenges for models to generate the correct reasoning steps, as the model
must navigate through a vast prompt template space to find the appropriate
template for each task. In this work, we build upon previous theoretical
analyses of CoT to demonstrate how the one-prompt-for-all approach can
negatively affect the computability of LLMs. We partition the solution search
space into two: the prompt space and the answer space. Our findings show that
task-specific supervision is essential for navigating the prompt space
accurately and achieving optimal performance. Through experiments with
state-of-the-art LLMs, we reveal a gap in reasoning performance when
supervision is applied versus when it is not.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¾¹åºæ¹è®äºèªç¶èªè¨èçï¼ä¸¦å·åä¿é²äººå·¥æºæ§ç¼å±çå·¨å¤§æ½åãç¶èï¼å¤§å¤æ¸ä¸»æµ LLM çæ ¸å¿æ¶æ§ï¼Transformerï¼å¨è¨ç®æ·±åº¦æ¹é¢æå¶å§å¨éå¶ï¼çè«ä¸ç¡æ³è§£æ±ºè¨±å¤éè¦è¶ä¾è¶æ·±å¥è¨ç®çæ¨çä»»åãæç¶­é (CoT) æç¤ºå·²æçºè§£æ±ºéäºæ¶æ§éå¶çä¸ç¨®æè¡ï¼éå·²ç±å¹¾é çè«ç ç©¶è­å¯¦ãå®æä¾äºä¸åæåéçæ¹æ³ä¾è§£æ±ºè¤éçæ¨çä»»åï¼éäºä»»åä»¥åè¶åºäºéäºæ¨¡åçè½åãåç®¡åå¾äºæåï¼CoT åå¶è®é«ï¼ä¾å¦æç¶­æ¨¹ãæç¶­åç­ï¼ä¾è³´æ¼ãä¸æç¤ºé©ç¨ææãçæ¹æ³ï¼å°åç¨®ä»»åï¼å¾è¨æ¸åæåºå°è§£æ±ºæ¸å­¸åæ¼ç®æ³åé¡ï¼ä½¿ç¨å®ä¸çæç¤ºçµæ§ï¼ä¾å¦ï¼ãéæ­¥æèãï¼ãéç¨®æ¹æ³å°æ¨¡åç¢çæ­£ç¢ºçæ¨çæ­¥é©æ§æäºéå¤§ææ°ï¼å çºæ¨¡åå¿é å¨å»£æ³çæç¤ºç¯æ¬ç©ºéä¸­å°èªï¼æè½çºæ¯åä»»åæ¾å°é©ç¶çç¯æ¬ãå¨éé å·¥ä½ä¸­ï¼æåå»ºç«å¨ CoT ååççè«åæä¹ä¸ï¼èªªæãä¸æç¤ºé©ç¨ææãçæ¹æ³å¦ä½å° LLM çå¯è¨ç®æ§ç¢çè² é¢å½±é¿ãæåå°è§£çæå°ç©ºéåçºå©é¨åï¼æç¤ºç©ºéåç­æ¡ç©ºéãæåçç ç©¶çµæè¡¨æï¼ç¹å®æ¼ä»»åçç£ç£å°æ¼æºç¢ºå°èªæç¤ºç©ºéä¸¦å¯¦ç¾æä½³æè½è³ééè¦ãééä½¿ç¨æåé²ç LLM é²è¡å¯¦é©ï¼æåæ­ç¤ºäºå¨æç¨ç£ç£èæªæç¨ç£ç£ææ¨çæè½çå·®è·ã

##### **Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs**
2410.14057v1 by Simone Conia, Daniel Lee, Min Li, Umar Farooq Minhas, Saloni Potdar, Yunyao Li

Translating text that contains entity names is a challenging task, as
cultural-related references can vary significantly across languages. These
variations may also be caused by transcreation, an adaptation process that
entails more than transliteration and word-for-word translation. In this paper,
we address the problem of cross-cultural translation on two fronts: (i) we
introduce XC-Translate, the first large-scale, manually-created benchmark for
machine translation that focuses on text that contains potentially
culturally-nuanced entity names, and (ii) we propose KG-MT, a novel end-to-end
method to integrate information from a multilingual knowledge graph into a
neural machine translation model by leveraging a dense retrieval mechanism. Our
experiments and analyses show that current machine translation systems and
large language models still struggle to translate texts containing entity
names, whereas KG-MT outperforms state-of-the-art approaches by a large margin,
obtaining a 129% and 62% relative improvement compared to NLLB-200 and GPT-4,
respectively.

æè¦ï¼ç¿»è­¯åå«å¯¦é«åç¨±çæå­æ¯ä¸é å·æææ°æ§çä»»åï¼å çºèæåç¸éçåèå¨ä¸åèªè¨ä¸­å¯è½ææå¾å¤§å·®ç°ãéäºå·®ç°ä¹å¯è½æ¯ç±è½è­¯é æçï¼è½è­¯æ¯ä¸ç¨®æ¹ç·¨éç¨ï¼ä¸åæ¶åé³è­¯åéå­ç¿»è­¯ãå¨æ¬æä¸­ï¼æåå¾å©åæ¹é¢è§£æ±ºè·¨æåç¿»è­¯çåé¡ï¼(i) æåä»ç´¹ XC-Translateï¼éæ¯ç¬¬ä¸åéå°åå«æ½å¨æåç´°å¾®å·®å¥å¯¦é«åç¨±çæå­çå¤§è¦æ¨¡ãäººå·¥å»ºç«çæ©å¨ç¿»è­¯åºæºæ¸¬è©¦ï¼ä»¥å (ii) æåæåº KG-MTï¼éæ¯ä¸ç¨®æ°çç«¯å°ç«¯æ¹æ³ï¼ééå©ç¨å¯éæª¢ç´¢æ©å¶å°ä¾èªå¤èªè¨ç¥è­åè­çè³è¨æ´åå°ç¥ç¶æ©å¨ç¿»è­¯æ¨¡åä¸­ãæåçå¯¦é©ååæè¡¨æï¼ç®åçæ©å¨ç¿»è­¯ç³»çµ±åå¤§åèªè¨æ¨¡åå¨ç¿»è­¯åå«å¯¦é«åç¨±çæå­æä»å­å¨å°é£ï¼è KG-MT åä»¥å¤§å¹åªæ¼æåé²æ¹æ³çåªå¢ååºï¼è NLLB-200 å GPT-4 ç¸æ¯ï¼åå¥ç²å¾äº 129% å 62% çç¸å°æ¹é²ã

##### **RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs**
2410.13987v1 by Jiatan Huang, Mingchen Li, Zonghai Yao, Zhichao Yang, Yongkang Xiao, Feiyun Ouyang, Xiaohan Li, Shuo Han, Hong Yu

Answering complex real-world questions often requires accurate retrieval from
textual knowledge graphs (TKGs). The scarcity of annotated data, along with
intricate topological structures, makes this task particularly challenging. As
the nature of relational path information could enhance the inference ability
of Large Language Models (LLMs), efficiently retrieving more complex relational
path information from TKGs presents another key challenge. To tackle these
challenges, we first develop a Dataset for LLMs Complex Reasoning over Textual
Knowledge Graphs (RiTeK) with a broad topological structure coverage.We
synthesize realistic user queries that integrate diverse topological
structures, relational information, and complex textual descriptions. We
conduct rigorous expert evaluation to validate the quality of our synthesized
queries. And then, we introduce an enhanced Monte Carlo Tree Search (MCTS)
method, Relational MCTS, to automatically extract relational path information
from textual graphs for specific queries. Our dataset mainly covers the medical
domain as the relation types and entity are complex and publicly available.
Experimental results indicate that RiTeK poses significant challenges for
current retrieval and LLM systems, while the proposed Relational MCTS method
enhances LLM inference ability and achieves state-of-the-art performance on
RiTeK.

æè¦ï¼åç­è¤éçç¾å¯¦ä¸çåé¡éå¸¸éè¦å¾ææ¬ç¥è­å (TKG) ä¸­æºç¢ºæ·åãæ¨è¨»è³æçç¨å°ï¼å ä¸è¤éçææ²çµæ§ï¼ä½¿å¾éé ä»»åç¹å¥å·æææ°æ§ãç±æ¼éä¿è·¯å¾è³è¨çæ§è³ªå¯ä»¥å¢å¼·å¤§åèªè¨æ¨¡å (LLM) çæ¨è«è½åï¼å¾ TKG ææå°æ·åæ´è¤éçéä¿è·¯å¾è³è¨æåºäºå¦ä¸åééµææ°ãçºäºæå°éäºææ°ï¼æåé¦åéç¼äºä¸åå·æå»£æ³ææ²çµæ§æ¶µèç¯åçææ¬ç¥è­å (RiTeK) ä¸ç LLM è¤éæ¨çè³æéãæåç¶åäºæ´åäºå¤æ¨£åææ²çµæ§ãéä¿è³è¨åè¤éææ¬æè¿°çç¾å¯¦ä½¿ç¨èæ¥è©¢ãæåé²è¡å´æ ¼çå°å®¶è©ä¼°ï¼ä»¥é©è­æåç¶åæ¥è©¢çåè³ªãç¶å¾ï¼æåå¼å¥ä¸ç¨®å¢å¼·çèå°å¡ç¾æ¨¹æå° (MCTS) æ¹æ³ï¼å³éä¿ MCTSï¼ä»¥èªåå¾ææ¬åä¸­æ·åç¹å®æ¥è©¢çéä¿è·¯å¾è³è¨ãæåçè³æéä¸»è¦æ¶µèé«çé åï¼å çºéä¿é¡ååå¯¦é«å¾è¤éä¸å¬éå¯ç¨ãå¯¦é©çµæè¡¨æï¼RiTeK å°ç®åçæ·åå LLM ç³»çµ±æåºäºéå¤§ææ°ï¼èææåºçéä¿ MCTS æ¹æ³å¢å¼·äº LLM æ¨è«è½åï¼ä¸¦å¨ RiTeK ä¸éå°äºæåé²çæè½ã

##### **The Mystery of the Pathological Path-star Task for Language Models**
2410.13779v1 by Arvid Frydenlund

The recently introduced path-star task is a minimal task designed to
exemplify limitations to the abilities of language models (Bachmann and
Nagarajan, 2024). It involves a path-star graph where multiple arms radiate
from a single starting node and each node is unique. Given the start node and a
specified target node that ends an arm, the task is to generate the arm
containing that target node. This is straightforward for a human but
surprisingly difficult for language models, which did not outperform the random
baseline. The authors hypothesized this is due to a deficiency in
teacher-forcing and the next-token prediction paradigm.
  We demonstrate the task is learnable using teacher-forcing in alternative
settings and that the issue is partially due to representation. We introduce a
regularization method using structured samples of the same graph but with
differing target nodes, improving results across a variety of model types. We
provide RASP proofs showing the task is theoretically solvable. Finally, we
find settings where an encoder-only model can consistently solve the task.

æè¦ï¼æè¿æ¨åºçè·¯å¾æå½¢ä»»åæ¯ä¸åæ¥µç°¡ä»»åï¼æ¨å¨èªªæèªè¨æ¨¡åè½åçéå¶ï¼Bachmann å Nagarajanï¼2024 å¹´ï¼ãå®æ¶åä¸åè·¯å¾æå½¢åï¼å¶ä¸­å¤ååæ¯å¾ä¸åèµ·å§ç¯é»è¼»å°åºå»ï¼æ¯åç¯é»é½æ¯å¯ä¸çãçµ¦å®èµ·å§ç¯é»åçµæä¸ååæ¯çæå®ç®æ¨ç¯é»ï¼ä»»åæ¯çæåå«è©²ç®æ¨ç¯é»çåæ¯ãéå°äººé¡ä¾èªªå¾ç°¡å®ï¼ä½å°èªè¨æ¨¡åä¾èªªå»ç°ä¹å°å¸¸å°å°é£ï¼å çºèªè¨æ¨¡åä¸¦æªåªæ¼é¨æ©åºæºç·ãä½èåè¨­éæ¯ç±æ¼æå¸«å¼·å¶åä¸ä¸åç¬¦èé æ¸¬ç¯ä¾çä¸è¶³ã
æåå±ç¤ºäºè©²ä»»åå¯ä»¥ä½¿ç¨æ¿ä»£è¨­ç½®ä¸­çæå¸«å¼·å¶ä¾å­¸ç¿ï¼ä¸¦ä¸åé¡é¨åæ¯ç±æ¼è¡¨ç¤ºãæåå¼å¥äºä¸ç¨®æ­£ååæ¹æ³ï¼ä½¿ç¨åä¸åå½¢ççµæ§åæ¨£æ¬ï¼ä½ç®æ¨ç¯é»ä¸åï¼å¾èæ¹é²äºåç¨®æ¨¡åé¡åççµæãæåæä¾äº RASP è­æï¼è¡¨æè©²ä»»åå¨çè«ä¸æ¯å¯ä»¥è§£æ±ºçãæå¾ï¼æåæ¾å°äºåç·¨ç¢¼å¨æ¨¡åå¯ä»¥æçºè§£æ±ºä»»åçè¨­ç½®ã

##### **Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval**
2410.13765v1 by Yu Xia, Junda Wu, Sungchul Kim, Tong Yu, Ryan A. Rossi, Haoliang Wang, Julian McAuley

Large language models (LLMs) have been used to generate query expansions
augmenting original queries for improving information search. Recent studies
also explore providing LLMs with initial retrieval results to generate query
expansions more grounded to document corpus. However, these methods mostly
focus on enhancing textual similarities between search queries and target
documents, overlooking document relations. For queries like "Find me a highly
rated camera for wildlife photography compatible with my Nikon F-Mount lenses",
existing methods may generate expansions that are semantically similar but
structurally unrelated to user intents. To handle such semi-structured queries
with both textual and relational requirements, in this paper we propose a
knowledge-aware query expansion framework, augmenting LLMs with structured
document relations from knowledge graph (KG). To further address the limitation
of entity-based scoring in existing KG-based methods, we leverage document
texts as rich KG node representations and use document-based relation filtering
for our Knowledge-Aware Retrieval (KAR). Extensive experiments on three
datasets of diverse domains show the advantages of our method compared against
state-of-the-art baselines on textual and relational semi-structured retrieval.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²ç¨æ¼ç¢çæ¥è©¢æ´åï¼èä»¥æ´ååå§æ¥è©¢ï¼ä»¥æ¹åè³è¨æå°ãæè¿çç ç©¶ä¹æ¢è¨æä¾ LLM åå§æª¢ç´¢çµæï¼ä»¥ç¢çæ´è²¼è¿æä»¶èªæåº«çæ¥è©¢æ´åãç¶èï¼éäºæ¹æ³å¤§å¤èéæ¼å å¼·æå°æ¥è©¢èç®æ¨æä»¶ä¹éçæå­ç¸ä¼¼æ§ï¼èå¿½ç¥äºæä»¶éä¿ãå°æ¼ãå¹«ææ¾ä¸å°èæç Nikon F-Mount é¡é ­ç¸å®¹ãè©å¹å¾é«çéçåç©æå½±ç¸æ©ãç­æ¥è©¢ï¼ç¾ææ¹æ³å¯è½æç¢çèªç¾©ä¸ç¸ä¼¼ä½çµæ§ä¸èä½¿ç¨èæåç¡éçæ´åãçºäºèçå·ææå­åéä¿éæ±çæ­¤é¡åçµæ§åæ¥è©¢ï¼æåå¨æ¬æä¸­æåºä¸åç¥è­æç¥æ¥è©¢æ´åæ¶æ§ï¼å©ç¨ç¥è­åè­ (KG) ä¸­ççµæ§åæä»¶éä¿æ´å LLMãçºäºé²ä¸æ­¥è§£æ±ºç¾æåºæ¼ KG çæ¹æ³ä¸­åºæ¼å¯¦é«çè©åéå¶ï¼æåå©ç¨æä»¶æå­ä½çºè±å¯ç KG ç¯é»è¡¨å¾µï¼ä¸¦ä½¿ç¨åºæ¼æä»¶çéä¿ç¯©é¸ï¼é²è¡æåçç¥è­æç¥æª¢ç´¢ (KAR)ãéå°ä¸åä¸åé åè³æéé²è¡çå»£æ³å¯¦é©é¡¯ç¤ºï¼æåçæ¨¡åèæå­åéä¿åçµæ§åæª¢ç´¢çææ°åºæºç¸æ¯ï¼å·æåªå¢ã

##### **LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models**
2410.13299v1 by David Hoffmann, Kailash Budhathoki, Matthaeus Kleindessner

The evolving capabilities of large language models are accompanied by growing
sizes and deployment costs, necessitating effective inference optimisation
techniques. We propose a novel pruning method utilising centrality measures
from graph theory, reducing both the computational requirements and the memory
footprint of these models. Specifically, we devise a method for creating a
weighted directed acyclical graph representation of multilayer perceptrons to
which we apply a modified version of the weighted PageRank centrality measure
to compute node importance scores. In combination with uniform pruning this
leads to structured sparsity. We call this pruning method MLPRank. Furthermore
we introduce an extension to decoder-only transformer models and call it
LLMRank. For both variants we demonstrate a strong performance. With MLPRank on
average leading to 6.09 % higher accuracy retention than three popular
baselines and 13.42 % with LLMRank compared to two popular baselines.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡ååè½çæ¼é²ï¼æ¨¡åè¦æ¨¡èé¨ç½²ææ¬ä¹é¨ä¹å¢å ï¼å æ­¤éè¦ææçæ¨è«æä½³åæè¡ãæåæåºä¸ååµæ°çä¿®åªæ¹æ³ï¼å©ç¨åè«ä¸­çä¸­å¿æ§æ¸¬éï¼åææ¸å°éäºæ¨¡åçéç®éæ±åè¨æ¶é«ä½¿ç¨éãå·é«ä¾èªªï¼æåè¨­è¨äºä¸ç¨®æ¹æ³ï¼ç¨æ¼å»ºç«å¤å±¤æç¥å¨çå æ¬æåç¡ç°åè¡¨ç¤ºï¼ä¸¦å°å¶å¥ç¨å æ¬ PageRank ä¸­å¿æ§æ¸¬éçä¿®æ¹çæ¬ï¼ä»¥è¨ç®ç¯é»éè¦æ§åæ¸ãçµååå»ä¿®åªï¼éå°å°è´çµæ§åç¨çæ§ãæåç¨±éç¨®ä¿®åªæ¹æ³çº MLPRankãæ­¤å¤ï¼æåéå¼å¥äºåè§£ç¢¼å¨Transformeræ¨¡åçå»¶ä¼¸ï¼ä¸¦ç¨±ä¹çº LLMRankãå°æ¼éå©ç¨®è®é«ï¼æåé½å±ç¤ºäºå¼·å¤§çæè½ãMLPRank å¹³åæ¯ä¸ç¨®æµè¡åºæºé«åº 6.09% çæºç¢ºæ§ä¿ççï¼è LLMRank åæ¯å©ç¨®æµè¡åºæºé«åº 13.42%ã

##### **Trust but Verify: Programmatic VLM Evaluation in the Wild**
2410.13121v1 by Viraj Prabhu, Senthil Purushwalkam, An Yan, Caiming Xiong, Ran Xu

Vision-Language Models (VLMs) often generate plausible but incorrect
responses to visual queries. However, reliably quantifying the effect of such
hallucinations in free-form responses to open-ended queries is challenging as
it requires visually verifying each claim within the response. We propose
Programmatic VLM Evaluation (PROVE), a new benchmarking paradigm for evaluating
VLM responses to open-ended queries. To construct PROVE, we provide a large
language model (LLM) with a high-fidelity scene-graph representation
constructed from a hyper-detailed image caption, and prompt it to generate
diverse question-answer (QA) pairs, as well as programs that can be executed
over the scene graph object to verify each QA pair. We thus construct a
benchmark of 10.5k challenging but visually grounded QA pairs. Next, to
evaluate free-form model responses to queries in PROVE, we propose a
programmatic evaluation strategy that measures both the helpfulness and
truthfulness of a response within a unified scene graph-based framework. We
benchmark the helpfulness-truthfulness trade-offs of a range of VLMs on PROVE,
finding that very few are in-fact able to achieve a good balance between the
two. Project page: \url{https://prove-explorer.netlify.app/}.

æè¦ï¼è¦è¦ºèªè¨æ¨¡å (VLM) ç¶å¸¸å°è¦è¦ºæ¥è©¢ç¢ççä¼¼åçä½é¯èª¤çåæãç¶èï¼å¯é å°éåæ­¤é¡å¹»è¦ºå¨éæ¾å¼æ¥è©¢çèªç±å½¢å¼åæä¸­çå½±é¿å·æææ°æ§ï¼å çºééè¦è¦è¦ºé©è­åæä¸­çæ¯åèªªæ³ãæåæåºç¨å¼å VLM è©ä¼° (PROVE)ï¼ä¸ç¨®ç¨æ¼è©ä¼° VLM å°éæ¾å¼æ¥è©¢çåæçæ°åºæºç¯ä¾ãçºäºå»ºæ§ PROVEï¼æåæä¾ä¸åå¤§åèªè¨æ¨¡å (LLM) ä¸åç±è¶è©³ç´°å½±åæ¨é¡å»ºæ§çé«ä¿çå ´æ¯åè¡¨ç¤ºï¼ä¸¦æç¤ºå®ç¢çå¤æ¨£åçåç­ (QA) éå°ï¼ä»¥åå¯ä»¥å¨å ´æ¯åç©ä»¶ä¸å·è¡çç¨å¼ï¼ä»¥é©è­æ¯å QA éå°ãå æ­¤ï¼æåå»ºæ§äºä¸åç± 10.5k åå·æææ°æ§ä½è¦è¦ºä¸åçç QA éå°çµæçåºæºãæ¥ä¸ä¾ï¼çºäºè©ä¼° PROVE ä¸­çæ¥è©¢çèªç±å½¢å¼æ¨¡ååæï¼æåæåºäºä¸åç¨å¼åè©ä¼°ç­ç¥ï¼è©²ç­ç¥å¨ä¸åçµ±ä¸çåºæ¼å ´æ¯åçæ¡æ¶ä¸­è¡¡éåæçæç¨æ§åçå¯¦æ§ãæåå¨ PROVE ä¸å°ä¸ç³»å VLM çæç¨æ§-çå¯¦æ§æ¬è¡¡é²è¡åºæºæ¸¬è©¦ï¼ç¼ç¾äºå¯¦ä¸å¾å°æ VLM è½å¨å©èä¹éåå¾è¯å¥½çå¹³è¡¡ãå°æ¡é é¢ï¼\url{https://prove-explorer.netlify.app/}ã

##### **Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models**
2410.13080v1 by Linhao Luo, Zicheng Zhao, Chen Gong, Gholamreza Haffari, Shirui Pan

Large language models (LLMs) have demonstrated impressive reasoning
abilities, but they still struggle with faithful reasoning due to knowledge
gaps and hallucinations. To address these issues, knowledge graphs (KGs) have
been utilized to enhance LLM reasoning through their structured knowledge.
However, existing KG-enhanced methods, either retrieval-based or agent-based,
encounter difficulties in accurately retrieving knowledge and efficiently
traversing KGs at scale. In this work, we introduce graph-constrained reasoning
(GCR), a novel framework that bridges structured knowledge in KGs with
unstructured reasoning in LLMs. To eliminate hallucinations, GCR ensures
faithful KG-grounded reasoning by integrating KG structure into the LLM
decoding process through KG-Trie, a trie-based index that encodes KG reasoning
paths. KG-Trie constrains the decoding process, allowing LLMs to directly
reason on graphs and generate faithful reasoning paths grounded in KGs.
Additionally, GCR leverages a lightweight KG-specialized LLM for
graph-constrained reasoning alongside a powerful general LLM for inductive
reasoning over multiple reasoning paths, resulting in accurate reasoning with
zero reasoning hallucination. Extensive experiments on several KGQA benchmarks
demonstrate that GCR achieves state-of-the-art performance and exhibits strong
zero-shot generalizability to unseen KGs without additional training.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å·²å±ç¾åºä»¤äººå°è±¡æ·±å»çæ¨çè½åï¼ä½ç±æ¼ç¥è­å·®è·åå¹»è¦ºï¼å®åå¨å¿ å¯¦æ¨çæ¹é¢ä»å­å¨å°é£ãçºäºè§£æ±ºéäºåé¡ï¼ç¥è­åè­ï¼KGï¼å·²è¢«ç¨æ¼ééå¶çµæ§åç¥è­å¢å¼· LLM æ¨çãç¶èï¼ç¾æç KG å¢å¼·æ¹æ³ï¼ç¡è«æ¯åºæ¼æª¢ç´¢æåºæ¼ä»£çï¼å¨æºç¢ºæª¢ç´¢ç¥è­åææéæ­·å¤§è¦æ¨¡ KG æé½æéå°å°é£ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºåç´ææ¨çï¼GCRï¼ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®å° KG ä¸­ççµæ§åç¥è­è LLM ä¸­çéçµæ§åæ¨çè¯ç¹«èµ·ä¾ãçºäºæ¶é¤å¹»è¦ºï¼GCR ééå° KG çµæ§æ´åå° LLM è§£ç¢¼éç¨ä¸­ï¼éé KG-Trieï¼ä¸ç¨®ç·¨ç¢¼ KG æ¨çè·¯å¾çåºæ¼ Trie çç´¢å¼ï¼ä¾ç¢ºä¿å¿ å¯¦çåºæ¼ KG çæ¨çãKG-Trie ç´æäºè§£ç¢¼éç¨ï¼åè¨± LLM ç´æ¥å¨åå½¢ä¸æ¨çï¼ä¸¦çæåºæ¼ KG çå¿ å¯¦æ¨çè·¯å¾ãæ­¤å¤ï¼GCR é¤äºå©ç¨ä¸ååè½å¼·å¤§çéç¨ LLM é²è¡å¤éæ¨çè·¯å¾çæ­¸ç´æ¨çä¹å¤ï¼éå©ç¨äºä¸åè¼éç´ç KG å°ç¨ LLM é²è¡åç´ææ¨çï¼å¾èå¯¦ç¾äºæºç¢ºæ¨çï¼ä¸é¶æ¨çå¹»è¦ºãå¨å¹¾å KGQA åºæºä¸é²è¡çå¤§éå¯¦é©è­æï¼GCR éå°äºæåé²çæè½ï¼ä¸¦å¨æ²æé¡å¤è¨ç·´çææ³ä¸å°æªè¦éç KG è¡¨ç¾åºå¼·å¤§çé¶æ¬¡æ¹æ³åè½åã

##### **Supply Chain Network Extraction and Entity Classification Leveraging Large Language Models**
2410.13051v1 by Tong Liu, Hadi Meidani

Supply chain networks are critical to the operational efficiency of
industries, yet their increasing complexity presents significant challenges in
mapping relationships and identifying the roles of various entities.
Traditional methods for constructing supply chain networks rely heavily on
structured datasets and manual data collection, limiting their scope and
efficiency. In contrast, recent advancements in Natural Language Processing
(NLP) and large language models (LLMs) offer new opportunities for discovering
and analyzing supply chain networks using unstructured text data. This paper
proposes a novel approach that leverages LLMs to extract and process raw
textual information from publicly available sources to construct a
comprehensive supply chain graph. We focus on the civil engineering sector as a
case study, demonstrating how LLMs can uncover hidden relationships among
companies, projects, and other entities. Additionally, we fine-tune an LLM to
classify entities within the supply chain graph, providing detailed insights
into their roles and relationships. The results show that domain-specific
fine-tuning improves classification accuracy, highlighting the potential of
LLMs for industry-specific supply chain analysis. Our contributions include the
development of a supply chain graph for the civil engineering sector, as well
as a fine-tuned LLM model that enhances entity classification and understanding
of supply chain networks.

æè¦ï¼ä¾æéç¶²è·¯å°æ¼ç¢æ¥­ççéæçè³ééè¦ï¼ä½å®åæ¥çå¢å çè¤éæ§å¨ç¹ªè£½éä¿ååæ¾åºååå¯¦é«çè§è²æ¹é¢å¸¶ä¾äºéå¤§çææ°ã
å»ºæ§ä¾æéç¶²è·¯çå³çµ±æ¹æ³æ¥µåº¦ä»°è³´çµæ§åè³æéåæåè³ææ¶éï¼éå¶äºå®åçç¯ååæçãç¸åå°ï¼èªç¶èªè¨èç (NLP) åå¤§åèªè¨æ¨¡å (LLM) çè¿æé²å±çºä½¿ç¨éçµæ§åæå­è³æç¼ç¾ååæä¾æéç¶²è·¯æä¾äºæ°çæ©æãéç¯è«ææåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼å®éç¨ LLM å¾å¬éå¯å¾çä¾æºä¸­èååèçåå§æå­è³è¨ï¼ä»¥å»ºæ§ä¸åå¨é¢çä¾æéåãæåå°æ³¨æ¼åæ¨å·¥ç¨é¨éä½çºä¸åæ¡ä¾ç ç©¶ï¼å±ç¤º LLM å¦ä½æ­ç¤ºå¬å¸ãå°æ¡åå¶ä»å¯¦é«ä¹éçé±èéä¿ãæ­¤å¤ï¼æåå¾®èª¿ä¸å LLM ä»¥åé¡ä¾æéåä¸­çå¯¦é«ï¼æä¾æ·±å¥çè¦è§£ï¼äºè§£å®åçè§è²åéä¿ãçµæé¡¯ç¤ºï¼ç¹å®é åçå¾®èª¿æ¹é²äºåé¡çæºç¢ºæ§ï¼çªé¡¯äº LLM å¨ç¢æ¥­ç¹å®ä¾æéåæä¸­çæ½åãæåçè²¢ç»åæ¬éç¼äºä¸åéå°åæ¨å·¥ç¨é¨éçä¾æéåï¼ä»¥åä¸åå¾®èª¿éç LLM æ¨¡åï¼å®å¢å¼·äºå¯¦é«åé¡åå°ä¾æéç¶²è·¯çäºè§£ã

##### **Learning Representations for Reasoning: Generalizing Across Diverse Structures**
2410.13018v1 by Zhaocheng Zhu

Reasoning, the ability to logically draw conclusions from existing knowledge,
is a hallmark of human. Together with perception, they constitute the two major
themes of artificial intelligence. While deep learning has pushed the limit of
perception beyond human-level performance, the progress in reasoning domains is
way behind. One fundamental reason is that reasoning problems usually have
flexible structures for both knowledge and queries, and many existing models
only perform well on structures seen during training. Here we aim to push the
boundary of reasoning models by devising algorithms that generalize across
knowledge and query structures, as well as systems that accelerate development
on structured data. This thesis consists of three parts. In Part I, we study
models that can inductively generalize to unseen knowledge graphs with new
entity and relation vocabularies. For new entities, we propose a framework that
learns neural operators in a dynamic programming algorithm computing path
representations. For relations, we construct a relation graph to capture the
interactions between relations, thereby converting new relations into new
entities. In Part II, we propose two solutions for generalizing across
multi-step queries on knowledge graphs and text respectively. For knowledge
graphs, we show that multi-step queries can be solved by multiple calls of
graph neural networks and fuzzy logic operations. For text, we devise an
algorithm to learn explicit knowledge as textual rules to improve large
language models on multi-step queries. In Part III, we propose two systems to
facilitate machine learning development on structured data. Our library treats
structured data as first-class citizens and removes the barrier for developing
algorithms on structured data. Our node embedding system solves the GPU memory
bottleneck of embedding matrices and scales to graphs with billion nodes.

æè¦ï¼<paragraph>æ¨çï¼å¾ç¾æç¥è­ä¸­éè¼¯å°å¾åºçµè«çè½åï¼æ¯äººé¡çæ¨èªãå®åèæç¥ä¸èµ·æ§æäººå·¥æºæ§çå©åä¸»è¦ä¸»é¡ãåç®¡æ·±åº¦å­¸ç¿å·²å°æç¥çæ¥µéæ¨è³è¶è¶äººé¡å±¤ç´çè¡¨ç¾ï¼ä½æ¨çé åçé²å±å»é é è½å¾ãä¸ååºæ¬åå æ¯æ¨çåé¡éå¸¸å°ç¥è­åæ¥è©¢é½æéæ´»ççµæ§ï¼èè¨±å¤ç¾ææ¨¡ååªå¨è¨ç·´æéçå°ççµæ§ä¸­è¡¨ç¾è¯å¥½ãå¨éè£¡ï¼æåæ¨å¨ééè¨­è¨è·¨ç¥è­åæ¥è©¢çµæ§é²è¡æ¦æ¬çæ¼ç®æ³ï¼ä»¥åå éçµæ§åè³æéç¼çç³»çµ±ï¼ä¾æ¨åæ¨çæ¨¡åççéãæ¬è«æåçºä¸é¨åãå¨ç¬¬ä¸é¨åï¼æåç ç©¶å¯ä»¥æ­¸ç´æ¦æ¬å°å·ææ°å¯¦é«åéä¿è©å½çæ°ç¥è­åè¡¨çæ¨¡åãå°æ¼æ°å¯¦é«ï¼æåæåºä¸åå¨åæè¦åæ¼ç®æ³ä¸­å­¸ç¿ç¥ç¶éç®å­çæ¡æ¶ï¼è¨ç®è·¯å¾è¡¨ç¤ºãå°æ¼éä¿ï¼æåæ§å»ºä¸åéä¿åä¾ææéä¿ä¹éçäºåï¼å¾èå°æ°éä¿è½æçºæ°å¯¦é«ãå¨ç¬¬äºé¨åï¼æåæåºå©åè§£æ±ºæ¹æ¡ï¼åå¥éå°ç¥è­åè¡¨åææ¬ä¸çå¤æ­¥é©æ¥è©¢é²è¡æ¦æ¬ãå°æ¼ç¥è­åè¡¨ï¼æåè¡¨æå¤æ­¥é©æ¥è©¢å¯ä»¥ééå¤æ¬¡å¼å«åç¥ç¶ç¶²è·¯åæ¨¡ç³éè¼¯éç®ä¾è§£æ±ºãå°æ¼ææ¬ï¼æåè¨­è¨äºä¸ç¨®æ¼ç®æ³ä¾å­¸ç¿æç¢ºçç¥è­ä½çºææ¬è¦åï¼ä»¥æ¹åå¤§åèªè¨æ¨¡åå¨å¤æ­¥é©æ¥è©¢ä¸çè¡¨ç¾ãå¨ç¬¬ä¸é¨åï¼æåæåºå©åç³»çµ±ï¼ä»¥ä¿é²çµæ§åè³æä¸çæ©å¨å­¸ç¿éç¼ãæåçç¨å¼åº«å°çµæ§åè³æè¦çºä¸ç´å¬æ°ï¼ä¸¦æ¶é¤äºå¨çµæ§åè³æä¸éç¼æ¼ç®æ³çéç¤ãæåçç¯é»åµå¥ç³»çµ±è§£æ±ºäºåµå¥ç©é£ç GPU è¨æ¶é«ç¶é ¸ï¼ä¸¦æ´åå°å·æåååç¯é»çåè¡¨ã</paragraph>

##### **Large Language Models as a Tool for Mining Object Knowledge**
2410.12959v1 by Hannah YoungEun An, Lenhart K. Schubert

Commonsense knowledge is essential for machines to reason about the world.
Large language models (LLMs) have demonstrated their ability to perform almost
human-like text generation. Despite this success, they fall short as
trustworthy intelligent systems, due to the opacity of the basis for their
answers and a tendency to confabulate facts when questioned about obscure
entities or technical domains. We hypothesize, however, that their general
knowledge about objects in the everyday world is largely sound. Based on that
hypothesis, this paper investigates LLMs' ability to formulate explicit
knowledge about common physical artifacts, focusing on their parts and
materials. Our work distinguishes between the substances that comprise an
entire object and those that constitute its parts$\unicode{x2014}$a previously
underexplored distinction in knowledge base construction. Using few-shot with
five in-context examples and zero-shot multi-step prompting, we produce a
repository of data on the parts and materials of about 2,300 objects and their
subtypes. Our evaluation demonstrates LLMs' coverage and soundness in
extracting knowledge. This contribution to knowledge mining should prove useful
to AI research on reasoning about object structure and composition and serve as
an explicit knowledge source (analogous to knowledge graphs) for LLMs
performing multi-hop question answering.

æè¦ï¼å¸¸è­ç¥è­å°æ¼æ©å¨æ¨çä¸çæ¯ä¸å¯æç¼ºçã
å¤§åèªè¨æ¨¡å (LLM) å·²ç¶å±ç¤ºåºå®åå·è¡å¹¾ä¹åäººé¡ä¸æ¨£çæå­ç¢ççè½åãåç®¡æéæ¨£çæåï¼å®åä½çºå¯ä¿¡è³´çæºæ§ç³»çµ±ä»ç¶ææä¸è¶³ï¼å çºå®åçç­æ¡åºç¤ä¸éæï¼èä¸å¨è¢«ååæ¨¡ç³å¯¦é«ææè¡é åæï¼å®åææé äºå¯¦çå¾åãç¶èï¼æååè¨­å®åå°æ¼æ¥å¸¸ä¸çä¸­ç©é«çä¸è¬ç¥è­å¨å¾å¤§ç¨åº¦ä¸æ¯åççãåºæ¼è©²åè¨­ï¼æ¬ææ¢è¨äº LLM å°æ¥å¸¸ç©çè£½åçæç¢ºç¥è­å¬å¼åçè½åï¼éé»éæ³¨å®åçé¶ä»¶åææãæåçç ç©¶ååäºæ§ææ´åç©é«çç©è³ªåæ§æå¶é¶ä»¶çç©è³ªï¼éæ¯ä¸åç¥è­åº«å»ºæ§ä¸­ä»¥åæªæ¾æ¢è¨éçåå¥ãä½¿ç¨å°æ¬¡å­¸ç¿ï¼åæ¬äºåæå¢ç¯ä¾åé¶æ¬¡å­¸ç¿å¤æ­¥é©æç¤ºï¼æåç¢çäºä¸åè³æåº«ï¼å¶ä¸­åå«ç´ 2,300 åç©é«åå¶å­é¡åçé¶ä»¶åææãæåçè©ä¼°å±ç¤ºäº LLM å¨æåç¥è­æ¹é¢çæ¶µèç¯ååå¥å¨æ§ãéåç¥è­ææçè²¢ç»å°æ¼ AI ç ç©¶æ¨çç©é«çµæ§åçµææè©²æ¯æç¨çï¼ä¸¦ä½çº LLM å·è¡å¤è·³åé¡è§£ç­çæç¢ºç¥è­ä¾æºï¼é¡ä¼¼æ¼ç¥è­åè­ï¼ã

##### **FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**
2410.12707v1 by Zhenheng Tang, Xueze Kang, Yiming Yin, Xinglin Pan, Yuxin Wang, Xin He, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Amelie Chi Zhou, Bo Li, Bingsheng He, Xiaowen Chu

To alleviate hardware scarcity in training large deep neural networks (DNNs),
particularly large language models (LLMs), we present FusionLLM, a
decentralized training system designed and implemented for training DNNs using
geo-distributed GPUs across different computing clusters or individual devices.
Decentralized training faces significant challenges regarding system design and
efficiency, including: 1) the need for remote automatic differentiation (RAD),
2) support for flexible model definitions and heterogeneous software, 3)
heterogeneous hardware leading to low resource utilization or the straggler
problem, and 4) slow network communication. To address these challenges, in the
system design, we represent the model as a directed acyclic graph of operators
(OP-DAG). Each node in the DAG represents the operator in the DNNs, while the
edge represents the data dependency between operators. Based on this design, 1)
users are allowed to customize any DNN without caring low-level operator
implementation; 2) we enable the task scheduling with the more fine-grained
sub-tasks, offering more optimization space; 3) a DAG runtime executor can
implement RAD withour requiring the consistent low-level ML framework versions.
  To enhance system efficiency, we implement a workload estimator and design an
OP-Fence scheduler to cluster devices with similar bandwidths together and
partition the DAG to increase throughput. Additionally, we propose an AdaTopK
compressor to adaptively compress intermediate activations and gradients at the
slowest communication links. To evaluate the convergence and efficiency of our
system and algorithms, we train ResNet-101 and GPT-2 on three real-world
testbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental
results demonstrate that our system and method can achieve 1.45 - 9.39x speedup
compared to baseline methods while ensuring convergence.

æè¦ï¼<paragraph>çºäºæ¸è¼è¨ç·´å¤§åæ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) çç¡¬é«ç­ç¼ºåé¡ï¼å°¤å¶æ¯å¤§åèªè¨æ¨¡å (LLM)ï¼æåæåºäº FusionLLMï¼ä¸ååæ£å¼è¨ç·´ç³»çµ±ï¼å¶è¨­è¨åå¯¦ä½æ¯ç¨æ¼è¨ç·´è·¨ä¸åéç®å¢éæåå¥è£ç½®çå°çåæ£å¼ GPU ç DNNãåæ£å¼è¨ç·´å¨ç³»çµ±è¨­è¨åæçæ¹é¢é¢è¨éå¤§ææ°ï¼åæ¬ï¼1) éè¦é ç«¯èªåå¾®å (RAD)ï¼2) æ¯æ´å½æ§çæ¨¡åå®ç¾©åç°è³ªè»é«ï¼3) ç°è³ªç¡¬é«å°è´è³æºå©ç¨çä½æè½å¾åé¡ï¼ä»¥å 4) ç¶²è·¯éè¨éåº¦æ¢ãçºäºæå°éäºææ°ï¼å¨ç³»çµ±è¨­è¨ä¸­ï¼æåå°æ¨¡åè¡¨ç¤ºçºä¸åæåéå¾ªç°å (OP-DAG) çéç®å­ãDAG ä¸­çæ¯åç¯é»ä»£è¡¨ DNN ä¸­çéç®å­ï¼èéç·£ä»£è¡¨éç®å­ä¹éçè³æä¾è³´æ§ãåºæ¼æ­¤è¨­è¨ï¼1) ä½¿ç¨èå¯ä»¥èªè¨ä»»ä½ DNNï¼èä¸ç¨èæ®ä½ééç®å­å¯¦ä½ï¼2) æååç¨ä»»åæç¨ï¼ä¸¦ä½¿ç¨æ´ç´°ç·»çå­ä»»åï¼æä¾æ´å¤æä½³åç©ºéï¼3) DAG å·è¡æéå·è¡å¨å¯ä»¥å¯¦ä½ RADï¼èä¸éè¦ä¸è´çä½é ML æ¶æ§çæ¬ãçºäºæåç³»çµ±æçï¼æåå¯¦ä½ä¸åå·¥ä½è² è¼ä¼°è¨å¨ï¼ä¸¦è¨­è¨ä¸å OP-Fence æç¨å¨ï¼å°é »å¯¬é¡ä¼¼çè£ç½®åçµå¨ä¸èµ·ï¼ä¸¦åå² DAG ä»¥å¢å èçéãæ­¤å¤ï¼æåæåºä¸å AdaTopK å£ç¸®å¨ï¼ä»¥èªé©ææ¹å¼å£ç¸®ææ¢éè¨é£çµä¸çä¸­éåååæ¢¯åº¦ãçºäºè©ä¼°æåç³»çµ±åæ¼ç®æ³çæ¶ææ§åæçï¼æåå¨ä¸åçå¯¦ä¸ççæ¸¬è©¦å¹³å°ä¸è¨ç·´ ResNet-101 å GPT-2ï¼ä½¿ç¨ 48 å GPU é£æ¥å° 8 Mbps~10 Gbps ç¶²è·¯ãå¯¦é©çµæè¡¨æï¼æåçç³»çµ±åæ¹æ³å¯ä»¥æ¯åºæºæ¹æ³å¿« 1.45 - 9.39 åï¼åæç¢ºä¿æ¶æã</paragraph>

##### **The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph**
2410.12458v1 by Minghao Wu, Thuy-Trang Vu, Lizhen Qu, Gholamreza Haffari

The performance of large language models (LLMs) in natural language
processing (NLP) tasks is significantly influenced by the quality and diversity
of data used for supervised fine-tuning (SFT). Current data selection methods
often focus solely on quality or diversity, leading to underperforming models
due to suboptimal training data. In this paper, we introduce GraphFilter, a
novel method that represents the dataset as a bipartite graph, linking
sentences to their constituent n-grams. This representation effectively
captures the relationships between sentences and linguistic patterns,
facilitating the selection of sentences that enhance n-gram diversity. To
balance quality and diversity during selection, we propose a priority function
that combines the quality metric with the diversity metric in a multiplicative
manner. GraphFilter iteratively selects high-priority sentences, updates the
bipartite graph by removing covered n-grams, and re-calculates priorities to
reflect the evolving data landscape. We conduct extensive experiments using
three model backbones across six widely used benchmarks. The results
demonstrate that GraphFilter outperforms all nine baseline approaches,
achieving superior model performance and computational efficiency. Our analyses
validate the effectiveness of our design choices, examine the subsets selected
by GraphFilter and other methods, highlight the importance of instruction
diversity, and explore the role of quality and diversity in relation to subset
sizes. GraphFilter establishes a new foundation for effective data selection
strategies, encouraging further research in data selection for LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èç (NLP) ä»»åä¸­çè¡¨ç¾ï¼åå°ç¨æ¼ç£ç£å¾®èª¿ (SFT) çè³æåè³ªåå¤æ¨£æ§é¡¯èå½±é¿ãç®åçè³æé¸åæ¹æ³éå¸¸åªéæ³¨åè³ªæå¤æ¨£æ§ï¼å°è´è¨ç·´è³ææ¬¡ä½³ï¼é²èé ææ¨¡åè¡¨ç¾ä¸ä½³ãå¨æ¬æä¸­ï¼æåä»ç´¹ GraphFilterï¼ä¸ç¨®æ°ç©çæ¹æ³ï¼å®å°è³æéè¡¨ç¤ºçºäºé¨åï¼å°å¥å­é£çµå°å¶çµæ n-gramãéç¨®è¡¨ç¤ºæ¹å¼ææææå¥å­åèªè¨æ¨¡å¼ä¹éçéä¿ï¼æå©æ¼é¸æè½æå n-gram å¤æ¨£æ§çå¥å­ãçºäºå¨é¸åéç¨ä¸­å¹³è¡¡åè³ªåå¤æ¨£æ§ï¼æåæåºåªåå½æ¸ï¼ä»¥ä¹æ³æ¹å¼çµååè³ªææ¨åå¤æ¨£æ§ææ¨ãGraphFilter è¿­ä»£é¸åé«åªåç´å¥å­ï¼ééç§»é¤å·²æ¶µè n-gram ä¾æ´æ°äºé¨åï¼ä¸¦éæ°è¨ç®åªåç´ä»¥åæ ä¸æ·è®åçè³ææ¨£è²ãæåä½¿ç¨ä¸åæ¨¡åä¸»å¹¹å¨å­åå»£æ³ä½¿ç¨çåºæºä¸é²è¡å»£æ³çå¯¦é©ãçµæé¡¯ç¤ºï¼GraphFilter åªæ¼ææä¹ç¨®åºç·æ¹æ³ï¼éå°åè¶çæ¨¡åæè½åéç®æçãæåçåæé©è­äºæåè¨­è¨é¸æçæææ§ï¼æª¢é© GraphFilter åå¶ä»æ¹æ³é¸åçå­éï¼å¼·èª¿æä»¤å¤æ¨£æ§çéè¦æ§ï¼ä¸¦æ¢è¨åè³ªåå¤æ¨£æ§èå­éå¤§å°çéä¿ãGraphFilter çºææçè³æé¸åç­ç¥å¥ å®æ°çåºç¤ï¼é¼åµé²ä¸æ­¥ç ç©¶ LLM çè³æé¸åã

##### **PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking**
2410.12375v1 by Markus J. Buehler

PRefLexOR (Preference-based Recursive Language Modeling for Exploratory
Optimization of Reasoning) combines preference optimization with concepts from
Reinforcement Learning to enable models to self-teach through iterative
reasoning improvements. We propose a recursive learning approach that engages
the model in multi-step reasoning, revisiting, and refining intermediate steps
before producing a final output in training and inference phases. Through
multiple training stages, the model first learns to align its reasoning with
accurate decision paths by optimizing the log odds between preferred and
non-preferred responses. During this process, PRefLexOR builds a dynamic
knowledge graph by generating questions from random text chunks and
retrieval-augmentation to contextualize relevant details from the entire
training corpus. In the second stage, preference optimization enhances model
performance by using rejection sampling to fine-tune reasoning quality by
continually producing in-situ training data while masking the reasoning steps.
Recursive optimization within a thinking token framework introduces iterative
feedback loops, where the model refines reasoning, achieving deeper coherence,
consistency, and adaptability. Implemented in small language models with only 3
billion parameters, we should that even tiny models can iteratively teach
themselves to reason with greater depth and reflectivity. Our implementation is
straightforward and can be incorporated into any existing pretrained LLM. We
focus our examples on applications in biological materials science and
demonstrate the method in a variety of case studies that range from in-domain
to cross-domain applications. Using reasoning strategies that include thinking
and reflection modalities we build a multi-agent recursive self-improving
inference approach to successively improve responses via repeated sampling in
inference time.

æè¦ï¼PRefLexORï¼ç¨æ¼æ¢ç´¢æ§æ¨çåªåçåºæ¼åå¥½çéè¿´èªè¨å»ºæ¨¡ï¼å°åå¥½åªåèå¼·åå­¸ç¿ä¸­çæ¦å¿µç¸çµåï¼ä½¿æ¨¡åè½å¤ ééåè¦æ¨çæ¹é²ä¾èªææå­¸ãæåæåºäºä¸ç¨®éè¿´å­¸ç¿æ¹æ³ï¼è®æ¨¡ååèå¤æ­¥é©æ¨çãéæ°å¯©è¦åæ¹é²ä¸­éæ­¥é©ï¼ç¶å¾å¨è¨ç·´åæ¨çéæ®µç¢çæçµè¼¸åºãééå¤åè¨ç·´éæ®µï¼æ¨¡åé¦åå­¸ç¿ééåªåé¦é¸åéé¦é¸é¿æä¹éçå°æ¸å¹¾çï¼ä½¿å¶æ¨çèæºç¢ºçæ±ºç­è·¯å¾ä¿æä¸è´ãå¨æ­¤éç¨ä¸­ï¼PRefLexOR ééå¾é¨æ©ææ¬å¡çæåé¡åæª¢ç´¢å¢å¼·ä¾æ§å»ºä¸ååæç¥è­åï¼å¾æ´åè¨ç·´èªæåº«ä¸­æåç¸éç´°ç¯ä»¥é²è¡èªå¢åãå¨ç¬¬äºéæ®µï¼åå¥½åªåééä½¿ç¨æçµæ¡æ¨£ä¾å¾®èª¿æ¨çè³ªéï¼å¾èå¢å¼·æ¨¡åæ§è½ï¼åæé£çºç¢çåä½è¨ç·´æ¸æï¼åææ©èæ¨çæ­¥é©ãå¨æèä»¤çæ¡æ¶å§é²è¡éè¿´åªåæå¼å¥è¿­ä»£åé¥è¿´è·¯ï¼å¶ä¸­æ¨¡åææ¹é²æ¨çï¼å¾èå¯¦ç¾æ´æ·±å¥çé£è²«æ§ãä¸è´æ§åé©ææ§ãå¨åªæ 30 åååæ¸çå°èªè¨æ¨¡åä¸­å¯¦ç¾ï¼æåæè©²è®å³ä½¿æ¯å¾å°çæ¨¡åä¹è½ééè¿­ä»£çæ¹å¼ææèªå·±ä»¥æ´å¤§çæ·±åº¦ååæè½åé²è¡æ¨çãæåçå¯¦ç¾éå¸¸ç´æ¥ï¼å¯ä»¥æ´åå°ä»»ä½ç¾æçé è¨ç·´ LLM ä¸­ãæåå°æåçç¤ºä¾éé»æ¾å¨çç©ææç§å­¸æç¨ä¸ï¼ä¸¦å¨å¾åå§å°è·¨åæç¨ç­åç¨®æ¡ä¾ç ç©¶ä¸­æ¼ç¤ºäºè©²æ¹æ³ãä½¿ç¨åæ¬æèååææ¨¡å¼å¨å§çæ¨çç­ç¥ï¼æåæ§å»ºäºä¸åå¤ä»£çéè¿´èªææ¹é²æ¨çæ¹æ³ï¼ä»¥ééå¨æ¨çæééè¤æ¡æ¨£ä¾é£çºæ¹é²é¿æã

##### **Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs**
2410.12298v2 by Lei Sun, Xinchen Wang, Youdi Li

Large Language Models (LLMs) possess impressive reasoning abilities but are
prone to generating incorrect information, often referred to as hallucinations.
While incorporating external Knowledge Graphs (KGs) can partially mitigate this
issue, existing methods primarily treat KGs as static knowledge repositories,
overlooking the critical disparity between KG and LLM knowledge, and failing to
fully exploit the reasoning capabilities inherent in KGs. To address these
limitations, we propose Pyramid-Driven Alignment (PDA), a novel framework for
seamlessly integrating LLMs with KGs. PDA utilizes Pyramid Principle analysis
to construct a hierarchical pyramid structure. This structure is designed to
reflect the input question and generate more validated deductive knowledge,
thereby enhancing the alignment of LLMs and KGs and ensuring more cohesive
integration. Furthermore, PDA employs a recursive mechanism to harness the
underlying reasoning abilities of KGs, resulting in more accurate knowledge
retrieval for question-answering tasks. Our experimental results reveal a
substantial performance advantage of PDA over state-of-the-art baselines, with
improvements reaching 26.70% and 26.78%.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ææä»¤äººå°è±¡æ·±å»çæ¨çè½åï¼ä½å®¹æç¢çä¸æ­£ç¢ºçè³è¨ï¼éå¸¸ç¨±çºå¹»è¦ºã
åç®¡çµåå¤é¨ç¥è­åè­ (KG) å¯ä»¥é¨åç·©è§£éååé¡ï¼ä½ç¾ææ¹æ³ä¸»è¦å° KG è¦çºéæç¥è­å²å­åº«ï¼å¿½è¦ KG å LLM ç¥è­ä¹éçééµå·®ç°ï¼ä¸¦ä¸æªè½ååå©ç¨ KG ä¸­åºæçæ¨çè½åãçºäºè§£æ±ºéäºéå¶ï¼æåæåºéå­å¡é©åå°é½ (PDA)ï¼éæ¯ä¸åå° LLM è KG ç¡ç¸«æ´åçæ°ç©æ¶æ§ãPDA å©ç¨éå­å¡åååæä¾å»ºæ§ä¸åéå±¤å¼éå­å¡çµæ§ãæ­¤çµæ§æ¨å¨åæ è¼¸å¥åé¡ä¸¦ç¢çæ´å¤ç¶éé©è­çæ¼ç¹¹ç¥è­ï¼å¾èå¢å¼· LLM å KG çå°é½ï¼ä¸¦ç¢ºä¿æ´ç·å¯çæ´åãæ­¤å¤ï¼PDA æ¡ç¨éè¿´æ©å¶ä¾å©ç¨ KG çåºå±¤æ¨çè½åï¼å¾èæ´æºç¢ºå°æª¢ç´¢ç¥è­ä»¥é²è¡åç­ä»»åãæåçå¯¦é©çµæé¡¯ç¤ºï¼PDA ç¸è¼æ¼æåé²çåºæºï¼å·æé¡¯èçæè½åªå¢ï¼æ¹é²å¹åº¦éå° 26.70% å 26.78%ã

##### **LLM-based Cognitive Models of Students with Misconceptions**
2410.12294v2 by Shashank Sonkar, Xinghe Chen, Naiming Liu, Richard G. Baraniuk, Mrinmaya Sachan

Accurately modeling student cognition is crucial for developing effective
AI-driven educational technologies. A key challenge is creating realistic
student models that satisfy two essential properties: (1) accurately
replicating specific misconceptions, and (2) correctly solving problems where
these misconceptions are not applicable. This dual requirement reflects the
complex nature of student understanding, where misconceptions coexist with
correct knowledge. This paper investigates whether Large Language Models (LLMs)
can be instruction-tuned to meet this dual requirement and effectively simulate
student thinking in algebra. We introduce MalAlgoPy, a novel Python library
that generates datasets reflecting authentic student solution patterns through
a graph-based representation of algebraic problem-solving. Utilizing MalAlgoPy,
we define and examine Cognitive Student Models (CSMs) - LLMs instruction tuned
to faithfully emulate realistic student behavior. Our findings reveal that LLMs
trained on misconception examples can efficiently learn to replicate errors.
However, the training diminishes the model's ability to solve problems
correctly, particularly for problem types where the misconceptions are not
applicable, thus failing to satisfy second property of CSMs. We demonstrate
that by carefully calibrating the ratio of correct to misconception examples in
the training data - sometimes as low as 0.25 - it is possible to develop CSMs
that satisfy both properties. Our insights enhance our understanding of
AI-based student models and pave the way for effective adaptive learning
systems.

æè¦ï¼æºç¢ºå°æ¨¡æ¬å­¸ççèªç¥å°æ¼éç¼ææç AI é©åæè²æè¡è³ééè¦ãä¸åä¸»è¦çææ°æ¯å»ºç«ç¬¦åå©ååºæ¬å±¬æ§çé¼ççå­¸çæ¨¡åï¼(1) æºç¢ºå°è¤è£½ç¹å®çé¯èª¤è§å¿µï¼ä»¥å (2) æ­£ç¢ºè§£æ±ºéäºé¯èª¤è§å¿µä¸é©ç¨çåé¡ãéåéééæ±åæ äºå­¸ççè§£çè¤éæ§ï¼å¶ä¸­é¯èª¤è§å¿µèæ­£ç¢ºç¥è­ä¸¦å­ãæ¬ææ¢è¨å¤§åèªè¨æ¨¡å (LLM) æ¯å¦å¯ä»¥éå°æä»¤é²è¡èª¿æ´ä»¥æ»¿è¶³éåéééæ±ï¼ä¸¦ææå°æ¨¡æ¬å­¸çå¨ä»£æ¸ä¸­çæèãæåä»ç´¹ MalAlgoPyï¼ä¸åæ°ç©ç Python å½å¼åº«ï¼å®ééä»£æ¸åé¡è§£æ±ºçåå½¢åè¡¨ç¤ºæ³çæåæ çå¯¦å­¸çè§£é¡æ¨¡å¼çè³æéãå©ç¨ MalAlgoPyï¼æåå®ç¾©ä¸¦æª¢è¦èªç¥å­¸çæ¨¡å (CSM) - éå°æä»¤èª¿æ´ç LLMï¼ä»¥å¿ å¯¦å°æ¨¡æ¬ç¾å¯¦å­¸ççè¡çºãæåçç ç©¶çµæé¡¯ç¤ºï¼éå°é¯èª¤è§å¿µç¯ä¾è¨ç·´ç LLM å¯ä»¥ææå°å­¸ç¿è¤è£½é¯èª¤ãç¶èï¼è¨ç·´æéä½æ¨¡åæ­£ç¢ºè§£æ±ºåé¡çè½åï¼ç¹å¥æ¯å°æ¼é¯èª¤è§å¿µä¸é©ç¨çåé¡é¡åï¼å æ­¤ç¡æ³æ»¿è¶³ CSM çç¬¬äºåå±¬æ§ãæåè­æï¼ééä»ç´°æ ¡æºè¨ç·´è³æä¸­æ­£ç¢ºç¯ä¾èé¯èª¤è§å¿µç¯ä¾çæ¯ä¾ - ææä½è³ 0.25 - å¯ä»¥éç¼åææ»¿è¶³å©åå±¬æ§ç CSMãæåçè¦è§£å¢é²äºæåå°åºæ¼ AI çå­¸çæ¨¡åççè§£ï¼ä¸¦çºææçèªé©æå­¸ç¿ç³»çµ±éªå¹³äºéè·¯ã

##### **Comprehending Knowledge Graphs with Large Language Models for Recommender Systems**
2410.12229v1 by Ziqiang Cui, Yunpeng Weng, Xing Tang, Fuyuan Lyu, Dugang Liu, Xiuqiang He, Chen Ma

Recently, the introduction of knowledge graphs (KGs) has significantly
advanced recommender systems by facilitating the discovery of potential
associations between items. However, existing methods still face several
limitations. First, most KGs suffer from missing facts or limited scopes. This
can lead to biased knowledge representations, thereby constraining the model's
performance. Second, existing methods typically convert textual information
into IDs, resulting in the loss of natural semantic connections between
different items. Third, existing methods struggle to capture high-order
relationships in global KGs due to their inefficient layer-by-layer information
propagation mechanisms, which are prone to introducing significant noise. To
address these limitations, we propose a novel method called CoLaKG, which
leverages large language models (LLMs) for knowledge-aware recommendation. The
extensive world knowledge and remarkable reasoning capabilities of LLMs enable
them to supplement KGs. Additionally, the strong text comprehension abilities
of LLMs allow for a better understanding of semantic information. Based on
this, we first extract subgraphs centered on each item from the KG and convert
them into textual inputs for the LLM. The LLM then outputs its comprehension of
these item-centered subgraphs, which are subsequently transformed into semantic
embeddings. Furthermore, to utilize the global information of the KG, we
construct an item-item graph using these semantic embeddings, which can
directly capture higher-order associations between items. Both the semantic
embeddings and the structural information from the item-item graph are
effectively integrated into the recommendation model through our designed
representation alignment and neighbor augmentation modules. Extensive
experiments on four real-world datasets demonstrate the superiority of our
method.

æè¦ï¼<paragraph>æè¿ï¼ç¥è­åè­ (KG) çå¼å¥ééä¿é²é ç®ä¹éæ½å¨éè¯çç¼ç¾ï¼é¡¯èæåæ¨è¦ç³»çµ±ãç¶èï¼ç¾ææ¹æ³ä»é¢è¨å¹¾åéå¶ãé¦åï¼å¤§å¤æ¸ KG é½å­å¨äºå¯¦ç¼ºå¤±æç¯ååéçåé¡ãéå¯è½å°è´æåå·®çç¥è­è¡¨å¾µï¼é²èéå¶æ¨¡åçæè½ãå¶æ¬¡ï¼ç¾ææ¹æ³éå¸¸æå°æå­è³è¨è½æçº IDï¼å°è´ä¸åé ç®ä¹éèªç¶èªç¾©é£çµçéºå¤±ãç¬¬ä¸ï¼ç¾ææ¹æ³é£ä»¥ææå¨ç KG ä¸­çé«ééä¿ï¼åå å¨æ¼å¶ä½æççéå±¤è³è¨å³æ­æ©å¶å®¹æå¼å¥é¡¯èéè¨ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ç¨®ç¨±çº CoLaKG çæ°æ¹æ³ï¼å®å©ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡ç¥è­æç¥æ¨è¦ãLLM å»£æ³çä¸çç¥è­ååè¶çæ¨çè½åä½¿å®åè½å¤ è£å KGãæ­¤å¤ï¼LLM å¼·å¤§çæå­çè§£è½åæå©æ¼æ´æ·±å¥å°çè§£èªç¾©è³è¨ãåºæ¼æ­¤ï¼æåé¦åå¾ KG ä¸­æ·åä»¥æ¯åé ç®çºä¸­å¿çå­åï¼ä¸¦å°å®åè½æçº LLM çæå­è¼¸å¥ãç¶å¾ï¼LLM æè¼¸åºå¶å°éäºä»¥é ç®çºä¸­å¿çå­åççè§£ï¼éäºçè§£æ¥èæè½æçºèªç¾©åµå¥ãæ­¤å¤ï¼çºäºå©ç¨ KG çå¨çè³è¨ï¼æåä½¿ç¨éäºèªç¾©åµå¥å»ºæ§ä¸åé ç®-é ç®åï¼å®å¯ä»¥ç´æ¥ææé ç®ä¹éçé«ééè¯ãèªç¾©åµå¥åä¾èªé ç®-é ç®åççµæ§è³è¨é½æééæåè¨­è¨çè¡¨å¾µæ¯å°åé°åæ´åæ¨¡çµææå°æ´åå°æ¨è¦æ¨¡åä¸­ãå¨ååçå¯¦ä¸çè³æéä¸é²è¡çå»£æ³å¯¦é©è­æäºæåæ¹æ³çåªè¶æ§ã</paragraph>

##### **Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations**
2410.12228v1 by Luyi Ma, Xiaohan Li, Zezhong Fan, Jianpeng Xu, Jason Cho, Praveen Kanumala, Kaushiki Nag, Sushant Kumar, Kannan Achan

Integrating diverse data modalities is crucial for enhancing the performance
of personalized recommendation systems. Traditional models, which often rely on
singular data sources, lack the depth needed to accurately capture the
multifaceted nature of item features and user behaviors. This paper introduces
a novel framework for multi-behavior recommendations, leveraging the fusion of
triple-modality, which is visual, textual, and graph data through alignment
with large language models (LLMs). By incorporating visual information, we
capture contextual and aesthetic item characteristics; textual data provides
insights into user interests and item features in detail; and graph data
elucidates relationships within the item-behavior heterogeneous graphs. Our
proposed model called Triple Modality Fusion (TMF) utilizes the power of LLMs
to align and integrate these three modalities, achieving a comprehensive
representation of user behaviors. The LLM models the user's interactions
including behaviors and item features in natural languages. Initially, the LLM
is warmed up using only natural language-based prompts. We then devise the
modality fusion module based on cross-attention and self-attention mechanisms
to integrate different modalities from other models into the same embedding
space and incorporate them into an LLM. Extensive experiments demonstrate the
effectiveness of our approach in improving recommendation accuracy. Further
ablation studies validate the effectiveness of our model design and benefits of
the TMF.

æè¦ï¼æ´ååç¨®è³æåæå°æ¼æååäººåæ¨è¦ç³»çµ±çæè½è³ééè¦ãå³çµ±æ¨¡åç¶å¸¸ä¾è³´å®ä¸è³æä¾æºï¼ç¼ºä¹ææé ç®ç¹å¾µåä½¿ç¨èè¡çºå¤é¢åæ¬è³ªæéçæ·±åº¦ãæ¬æä»ç´¹äºä¸ååµæ°çå¤è¡çºæ¨è¦æ¶æ§ï¼å©ç¨è¦è¦ºãæå­ååå½¢è³æçä¸éåæèåï¼ééèå¤§åèªè¨æ¨¡å (LLM) å°é½ä¾å¯¦ç¾ãééç´å¥è¦è¦ºè³è¨ï¼æåææèçµ¡åç¾å­¸é ç®ç¹å¾µï¼æå­è³æè©³ç´°æä¾ä½¿ç¨èèè¶£åé ç®ç¹å¾µçè¦è§£ï¼åå½¢è³æé¡æé ç®è¡çºç°è³ªåå½¢ä¸­çéä¿ãæåæåºçæ¨¡åç¨±çºä¸éåæèå (TMF)ï¼å©ç¨ LLM çåéä¾å°é½åæ´åéä¸ç¨®åæï¼éæä½¿ç¨èè¡çºçå¨é¢è¡¨å¾µãLLM ä»¥èªç¶èªè¨å»ºæ¨¡ä½¿ç¨èçäºåï¼åæ¬è¡çºåé ç®ç¹å¾µãæåï¼LLM åä½¿ç¨åºæ¼èªç¶èªè¨çæç¤ºé²è¡ç±èº«ãç¶å¾æåæ ¹æäº¤åæ³¨æååèªææ³¨æåæ©å¶è¨­è¨åæèåæ¨¡çµï¼å°ä¾èªå¶ä»æ¨¡åçä¸ååææ´åå°ç¸åçåµå¥ç©ºéï¼ä¸¦å°å®åç´å¥ LLMãå»£æ³çå¯¦é©è­æäºæåçæ¹æ³å¨æåæ¨è¦æºç¢ºåº¦æ¹é¢çæææ§ãé²ä¸æ­¥çæ¶èç ç©¶é©è­äºæåæ¨¡åè¨­è¨çæææ§ä»¥å TMF çå¥½èã

##### **Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning**
2410.12130v1 by Huiwen Wu, Xiaohan Li, Xiaogang Xu, Jiafei Wu, Deyi Zhang, Zhe Liu

The development of Large Language Models (LLMs) has significantly advanced
various AI applications in commercial and scientific research fields, such as
scientific literature summarization, writing assistance, and knowledge graph
construction. However, a significant challenge is the high risk of
hallucination during LLM inference, which can lead to security concerns like
factual inaccuracies, inconsistent information, and fabricated content. To
tackle this issue, it is essential to develop effective methods for reducing
hallucination while maintaining the original capabilities of the LLM. This
paper introduces a novel approach called Iterative Model-level Contrastive
Learning (Iter-AHMCL) to address hallucination. This method modifies the
representation layers of pre-trained LLMs by using contrastive `positive' and
`negative' models, trained on data with and without hallucinations. By
leveraging the differences between these two models, we create a more
straightforward pathway to eliminate hallucinations, and the iterative nature
of contrastive learning further enhances performance. Experimental validation
on four pre-trained foundation LLMs (LLaMA2, Alpaca, LLaMA3, and Qwen)
finetuning with a specially designed dataset shows that our approach achieves
an average improvement of 10.1 points on the TruthfulQA benchmark.
Comprehensive experiments demonstrate the effectiveness of Iter-AHMCL in
reducing hallucination while maintaining the general capabilities of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çç¼å±å¨åæ¥­åç§å­¸ç ç©¶é åé¡¯èæ¨åäºåç¨® AI æç¨ï¼ä¾å¦ç§å­¸æç»æè¦ãå¯«ä½è¼å©åç¥è­åè­å»ºæ§ãç¶èï¼ä¸åéå¤§çææ°æ¯ LLM æ¨è«ä¸­å¹»è¦ºçé«é¢¨éªï¼éå¯è½æå°è´å®å¨åé¡ï¼ä¾å¦äºå¯¦ä¸æ­£ç¢ºãè³è¨ä¸ä¸è´åæé å§å®¹ãçºäºè§£æ±ºéååé¡ï¼éç¼ææçæ¹æ³ä¾æ¸å°å¹»è¦ºï¼åæä¿æ LLM çåå§åè½è³ééè¦ãæ¬æä»ç´¹äºä¸ç¨®ç¨±çºåè¦æ¨¡åå±¤ç´å°æ¯å­¸ç¿ (Iter-AHMCL) çæ°æ¹æ³ä¾è§£æ±ºå¹»è¦ºãæ­¤æ¹æ³ééä½¿ç¨å°æ¯çãæ­£åãåãè² åãæ¨¡åä¾ä¿®æ¹é åè¨ç·´ç LLM çè¡¨ç¤ºå±¤ï¼éäºæ¨¡åæ¯å¨æåæ²æå¹»è¦ºçè³æä¸è¨ç·´çãééå©ç¨éå©åæ¨¡åä¹éçå·®ç°ï¼æååµé äºä¸æ¢æ´ç´æ¥çéå¾ä¾æ¶é¤å¹»è¦ºï¼èå°æ¯å­¸ç¿çè¿­ä»£æ§è³ªé²ä¸æ­¥å¢å¼·äºæè½ãå¨ååé åè¨ç·´çåºç¤ LLM (LLaMA2ãAlpacaãLLaMA3 å Qwen) ä¸é²è¡çå¯¦é©é©è­ï¼ä½¿ç¨ç¹å¥è¨­è¨çè³æéé²è¡å¾®èª¿ï¼é¡¯ç¤ºæåçåæ³å¨ TruthfulQA åºæºä¸å¹³åæåäº 10.1 åãå¨é¢çå¯¦é©è­æäº Iter-AHMCL å¨æ¸å°å¹»è¦ºçåæï¼ç¶­æ LLM ä¸è¬åè½çæææ§ã

##### **Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning**
2410.12096v1 by Guangxin Su, Yifan Zhu, Wenjie Zhang, Hanchen Wang, Ying Zhang

Graph representation learning, involving both node features and graph
structures, is crucial for real-world applications but often encounters
pervasive noise. State-of-the-art methods typically address noise by focusing
separately on node features with large language models (LLMs) and on graph
structures with graph structure learning models (GSLMs). In this paper, we
introduce LangGSL, a robust framework that integrates the complementary
strengths of pre-trained language models and GSLMs to jointly enhance both node
feature and graph structure learning. In LangGSL, we first leverage LLMs to
filter noise in the raw data and extract valuable cleaned information as
features, enhancing the synergy of downstream models. During the mutual
learning phase in LangGSL, the core idea is to leverage the relatively small
language model (LM) to process local attributes and generate reliable
pseudo-labels and informative node embeddings, which are then integrated into
the GSLM's prediction phase. This approach enriches the global context and
enhances overall performance. Meanwhile, GSLM refines the evolving graph
structure constructed from the LM's output, offering updated labels back to the
LM as additional guidance, thus facilitating a more effective mutual learning
process. The LM and GSLM work synergistically, complementing each other's
strengths and offsetting weaknesses within a variational information-maximizing
framework, resulting in enhanced node features and a more robust graph
structure. Extensive experiments on diverse graph datasets of varying scales
and across different task scenarios demonstrate the scalability and
effectiveness of the proposed approach.

æè¦ï¼åè¡¨è¡¨ç¤ºå­¸ç¿æ¢æ¶åç¯é»ç¹å¾µåæ¶ååå½¢çµæ§ï¼å°æ¼ç¾å¯¦ä¸ççæç¨è³ééè¦ï¼ä½ç¶å¸¸æéå°æ®éçåªé³ãæåé²çæ¹æ³éå¸¸ééåå¥éæ³¨å·æå¤§åèªè¨æ¨¡å (LLM) çç¯é»ç¹å¾µåå·æåå½¢çµæ§å­¸ç¿æ¨¡å (GSLM) çåå½¢çµæ§ä¾è§£æ±ºåªé³åé¡ãå¨æ¬æä¸­ï¼æåä»ç´¹äº LangGSLï¼éæ¯ä¸åå¼·å¤§çæ¡æ¶ï¼å®æ´åäºé è¨ç·´èªè¨æ¨¡åå GSLM çäºè£åªå¢ï¼ä»¥å±åå¢å¼·ç¯é»ç¹å¾µååå½¢çµæ§å­¸ç¿ãå¨ LangGSL ä¸­ï¼æåé¦åå©ç¨ LLM ä¾éæ¿¾åå§æ¸æä¸­çåªé³ï¼ä¸¦æåæå¹å¼çå·²æ¸çä¿¡æ¯ä½çºç¹å¾µï¼å¢å¼·ä¸æ¸¸æ¨¡åçååä½ç¨ãå¨ LangGSL ä¸­çç¸äºå­¸ç¿éæ®µï¼æ ¸å¿ææ³æ¯å©ç¨ç¸å°è¼å°çèªè¨æ¨¡å (LM) ä¾èçå±é¨å±¬æ§ä¸¦çæå¯é çå½æ¨ç±¤åä¿¡æ¯è±å¯çç¯é»åµå¥ï¼ç¶å¾å°å®åéæå° GSLM çé æ¸¬éæ®µãéç¨®æ¹æ³è±å¯äºå¨å±ä¸ä¸æä¸¦å¢å¼·äºæ´é«æ§è½ãåæï¼GSLM åªåäºå¾ LM è¼¸åºæ§å»ºçæ¼ååå½¢çµæ§ï¼å°æ´æ°çæ¨ç±¤ä½çºéå æå°åé¥çµ¦ LMï¼å¾èä¿é²æ´ææçç¸äºå­¸ç¿éç¨ãLM å GSLM ååå·¥ä½ï¼å¨è®åä¿¡æ¯æå¤§åæ¡æ¶å§äºè£åèªçåªå¢ä¸¦å½è£å¼±é»ï¼å¾èå¢å¼·ç¯é»ç¹å¾µä¸¦å½¢ææ´å¼·å¤§çåå½¢çµæ§ãå¨ä¸åè¦æ¨¡åä¸åä»»åå ´æ¯çå¤æ¨£ååå½¢æ¸æéä¸é²è¡çå»£æ³å¯¦é©è­æäºææåºæ¹æ³çå¯æ´å±æ§åæææ§ã

##### **A Survey on Deep Tabular Learning**
2410.12034v1 by Shriyank Somvanshi, Subasish Das, Syed Aaqib Javed, Gian Antariksa, Ahmed Hossain

Tabular data, widely used in industries like healthcare, finance, and
transportation, presents unique challenges for deep learning due to its
heterogeneous nature and lack of spatial structure. This survey reviews the
evolution of deep learning models for tabular data, from early fully connected
networks (FCNs) to advanced architectures like TabNet, SAINT, TabTranSELU, and
MambaNet. These models incorporate attention mechanisms, feature embeddings,
and hybrid architectures to address tabular data complexities. TabNet uses
sequential attention for instance-wise feature selection, improving
interpretability, while SAINT combines self-attention and intersample attention
to capture complex interactions across features and data points, both advancing
scalability and reducing computational overhead. Hybrid architectures such as
TabTransformer and FT-Transformer integrate attention mechanisms with
multi-layer perceptrons (MLPs) to handle categorical and numerical data, with
FT-Transformer adapting transformers for tabular datasets. Research continues
to balance performance and efficiency for large datasets. Graph-based models
like GNN4TDL and GANDALF combine neural networks with decision trees or graph
structures, enhancing feature representation and mitigating overfitting in
small datasets through advanced regularization techniques. Diffusion-based
models like the Tabular Denoising Diffusion Probabilistic Model (TabDDPM)
generate synthetic data to address data scarcity, improving model robustness.
Similarly, models like TabPFN and Ptab leverage pre-trained language models,
incorporating transfer learning and self-supervised techniques into tabular
tasks. This survey highlights key advancements and outlines future research
directions on scalability, generalization, and interpretability in diverse
tabular data applications.

æè¦ï¼<paragraph>è¡¨æ ¼è³æå»£æ³æç¨æ¼é«çä¿å¥ãéèåéè¼¸ç­ç¢æ¥­ï¼ç±æ¼å¶ç°è³ªæ§ä¸ç¼ºä¹ç©ºéçµæ§ï¼å æ­¤å°æ·±åº¦å­¸ç¿æåºäºç¨ç¹çææ°ãéé èª¿æ¥åé¡§äºè¡¨æ ¼è³ææ·±åº¦å­¸ç¿æ¨¡åçæ¼é²ï¼å¾æ©æçå¨é£æ¥ç¶²è·¯ (FCN) å° TabNetãSAINTãTabTranSELU å MambaNet ç­åé²æ¶æ§ãéäºæ¨¡åçµåäºæ³¨æåæ©å¶ãç¹å¾µåµå¥åæ··åæ¶æ§ï¼ä»¥è§£æ±ºè¡¨æ ¼è³æçè¤éæ§ãTabNet ä½¿ç¨åºåæ³¨æåé²è¡éä¾ç¹å¾µé¸åï¼æåå¯è§£éæ§ï¼è SAINT çµåäºèªææ³¨æååè·¨æ¨£æ¬æ³¨æåï¼ä»¥ææç¹å¾µåè³æé»ä¹éçè¤éäºåï¼åææåå¯æ´åæ§ä¸¦æ¸å°éç®è² æãTabTransformer å FT-Transformer ç­æ··åæ¶æ§å°æ³¨æåæ©å¶èå¤å±¤æç¥å¨ (MLP) æ´åï¼ä»¥èçé¡å¥è³æåæ¸å¼è³æï¼å¶ä¸­ FT-Transformer å° transformer é©æå°è¡¨æ ¼è³æéãç ç©¶æçºå¨å¤§åè³æéçæè½åæçä¹éåå¾å¹³è¡¡ãåºæ¼åå½¢çæ¨¡åï¼ä¾å¦ GNN4TDL å GANDALFï¼å°ç¥ç¶ç¶²è·¯èæ±ºç­æ¨¹æåå½¢çµæ§çµåï¼ééåé²çæ­£ååæè¡å¢å¼·ç¹å¾µè¡¨ç¤ºä¸¦æ¸è¼å°è³æéä¸­çéåº¦æ¬åãåºæ¼æ´æ£çæ¨¡åï¼ä¾å¦è¡¨æ ¼å»åªæ´æ£æ©çæ¨¡å (TabDDPM)ï¼æç¢çåæè³æä»¥è§£æ±ºè³æç¨å°çåé¡ï¼é²èæåæ¨¡åçç©©å¥æ§ãé¡ä¼¼å°ï¼TabPFN å Ptab ç­æ¨¡åå©ç¨é åè¨ç·´çèªè¨æ¨¡åï¼å°é·ç§»å­¸ç¿åèªæç£ç£æè¡èå¥è¡¨æ ¼ä»»åä¸­ãéé èª¿æ¥éé»èªªæäºééµé²å±ï¼ä¸¦æ¦è¿°äºå¨åç¨®è¡¨æ ¼è³ææç¨ä¸­å¯æ´åæ§ãæ¦æ¬æ§åå¯è§£éæ§çæªä¾ç ç©¶æ¹åã</paragraph>

##### **Causal Reasoning in Large Language Models: A Knowledge Graph Approach**
2410.11588v1 by Yejin Kim, Eojin Kang, Juae Kim, H. Howie Huang

Large language models (LLMs) typically improve performance by either
retrieving semantically similar information, or enhancing reasoning abilities
through structured prompts like chain-of-thought. While both strategies are
considered crucial, it remains unclear which has a greater impact on model
performance or whether a combination of both is necessary. This paper answers
this question by proposing a knowledge graph (KG)-based random-walk reasoning
approach that leverages causal relationships. We conduct experiments on the
commonsense question answering task that is based on a KG. The KG inherently
provides both relevant information, such as related entity keywords, and a
reasoning structure through the connections between nodes. Experimental results
show that the proposed KG-based random-walk reasoning method improves the
reasoning ability and performance of LLMs. Interestingly, incorporating three
seemingly irrelevant sentences into the query using KG-based random-walk
reasoning enhances LLM performance, contrary to conventional wisdom. These
findings suggest that integrating causal structures into prompts can
significantly improve reasoning capabilities, providing new insights into the
role of causality in optimizing LLM performance.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) éå¸¸ééæ·åèªæä¸ç¸ä¼¼çè³è¨ï¼æéééå¼æèç­çµæ§åæç¤ºå¢å¼·æ¨çè½åï¼ä¾æåæè½ãåç®¡éå©ç¨®ç­ç¥é½è¢«èªçºè³ééè¦ï¼ä½ç®åä»ä¸æ¸æ¥åªä¸ç¨®å°æ¨¡åæè½å½±é¿è¼å¤§ï¼ææ¯å¦éè¦çµåå©èãæ¬æééæåºä¸ååºæ¼ç¥è­åè­ (KG) çé¨æ©æ¼«æ­¥æ¨çæ¹æ³ï¼ä¾åç­éååé¡ï¼éåæ¹æ³å©ç¨äºå æéä¿ãæåå¨åºæ¼ KG çå¸¸è­åç­ä»»åä¸é²è¡å¯¦é©ãKG æ¬èº«å°±æä¾äºç¸éè³è¨ï¼ä¾å¦ç¸éå¯¦é«ééµå­ï¼ä»¥åééç¯é»ä¹éçé£çµæä¾çæ¨ççµæ§ãå¯¦é©çµæé¡¯ç¤ºï¼æåºçåºæ¼ KG çé¨æ©æ¼«æ­¥æ¨çæ¹æ³æ¹åäº LLM çæ¨çè½ååæè½ãæè¶£çæ¯ï¼èå³çµ±è§å¿µç¸åï¼ä½¿ç¨åºæ¼ KG çé¨æ©æ¼«æ­¥æ¨çå°ä¸åçä¼¼ç¡éçå¥å­ç´å¥æ¥è©¢ä¸­ï¼å¯ä»¥æå LLM çæè½ãéäºç¼ç¾è¡¨æï¼å°å æçµæ§æ´åå°æç¤ºä¸­å¯ä»¥é¡¯èæåæ¨çè½åï¼ä¸¦çºå æéä¿å¨æä½³å LLM æè½ä¸­ææ®æ¼çè§è²æä¾æ°çè¦è§£ã

##### **Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development**
2410.11550v1 by Tengfei Ma, Xuan Lin, Tianle Li, Chaoyi Li, Long Chen, Peng Zhou, Xibao Cai, Xinyu Yang, Daojian Zeng, Dongsheng Cao, Xiangxiang Zeng

Large Language Models (LLMs) have recently demonstrated remarkable
performance in general tasks across various fields. However, their
effectiveness within specific domains such as drug development remains
challenges. To solve these challenges, we introduce \textbf{Y-Mol}, forming a
well-established LLM paradigm for the flow of drug development. Y-Mol is a
multiscale biomedical knowledge-guided LLM designed to accomplish tasks across
lead compound discovery, pre-clinic, and clinic prediction. By integrating
millions of multiscale biomedical knowledge and using LLaMA2 as the base LLM,
Y-Mol augments the reasoning capability in the biomedical domain by learning
from a corpus of publications, knowledge graphs, and expert-designed synthetic
data. The capability is further enriched with three types of drug-oriented
instructions: description-based prompts from processed publications,
semantic-based prompts for extracting associations from knowledge graphs, and
template-based prompts for understanding expert knowledge from biomedical
tools. Besides, Y-Mol offers a set of LLM paradigms that can autonomously
execute the downstream tasks across the entire process of drug development,
including virtual screening, drug design, pharmacological properties
prediction, and drug-related interaction prediction. Our extensive evaluations
of various biomedical sources demonstrate that Y-Mol significantly outperforms
general-purpose LLMs in discovering lead compounds, predicting molecular
properties, and identifying drug interaction events.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿æå¨ååé åçéç¨ä»»åä¸­å±ç¤ºåºé¡¯èçè¡¨ç¾ãç¶èï¼å®åå¨ç¹å®é åï¼ä¾å¦è¥ç©éç¼ï¼ä¸­çæè½ä»æå¾å å¼·ãçºäºè§£æ±ºéäºææ°ï¼æåå¼å¥äº **Y-Mol**ï¼å½¢æäºä¸åå®åç LLM å¸ç¯ï¼ç¨æ¼è¥ç©éç¼æµç¨ãY-Mol æ¯ä¸åå¤å°ºåº¦ççç©é«å­¸ç¥è­å¼å° LLMï¼æ¨å¨å®æåå°ååç©ç¼ç¾ãè¨åºååè¨åºé æ¸¬ç­ä»»åãééæ´åæ¸ç¾è¬åå¤å°ºåº¦ççç©é«å­¸ç¥è­ï¼ä¸¦ä½¿ç¨ LLaMA2 ä½çºåºç¤ LLMï¼Y-Mol å¾åºçç©ãç¥è­åè­åå°å®¶è¨­è¨çåæè³æä¸­å­¸ç¿ï¼å¢å¼·äºçç©é«å­¸é åçæ¨çè½åãå¶è½åé²ä¸æ­¥ééä¸ç¨®é¡åçè¥ç©å°åæä»¤å¾å°è±å¯ï¼å·²èçåºçç©çåºæ¼æè¿°çæç¤ºãç¨æ¼å¾ç¥è­åè­ä¸­æåéè¯çåºæ¼èªç¾©çæç¤ºï¼ä»¥åç¨æ¼çè§£çç©é«å­¸å·¥å·ä¸­å°å®¶ç¥è­çåºæ¼ç¯æ¬çæç¤ºãæ­¤å¤ï¼Y-Mol æä¾äºä¸çµ LLM å¸ç¯ï¼å¯ä»¥å¨æ´åè¥ç©éç¼éç¨ä¸­èªä¸»å·è¡ä¸æ¸¸ä»»åï¼åæ¬èæ¬ç¯©é¸ãè¥ç©è¨­è¨ãè¥çç¹æ§é æ¸¬åè¥ç©ç¸éäº¤äºé æ¸¬ãæåå°åç¨®çç©é«å­¸ä¾æºçå»£æ³è©ä¼°è¡¨æï¼Y-Mol å¨ç¼ç¾åå°ååç©ãé æ¸¬åå­ç¹æ§åè­å¥è¥ç©äº¤äºäºä»¶æ¹é¢é¡¯èåªæ¼éç¨ LLMã

##### **AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data**
2410.11531v1 by Xinjie Zhao, Moritz Blum, Rui Yang, Boming Yang, Luis MÃ¡rquez Carpintero, MÃ³nica Pina-Navarro, Tony Wang, Xin Li, Huitao Li, Yanran Fu, Rongrong Wang, Juntao Zhang, Irene Li

Large Language Models~(LLMs) have demonstrated capabilities across various
applications but face challenges such as hallucination, limited reasoning
abilities, and factual inconsistencies, especially when tackling complex,
domain-specific tasks like question answering~(QA). While Knowledge
Graphs~(KGs) have been shown to help mitigate these issues, research on the
integration of LLMs with background KGs remains limited. In particular, user
accessibility and the flexibility of the underlying KG have not been thoroughly
explored. We introduce AGENTiGraph (Adaptive Generative ENgine for Task-based
Interaction and Graphical Representation), a platform for knowledge management
through natural language interaction. It integrates knowledge extraction,
integration, and real-time visualization. AGENTiGraph employs a multi-agent
architecture to dynamically interpret user intents, manage tasks, and integrate
new knowledge, ensuring adaptability to evolving user requirements and data
contexts. Our approach demonstrates superior performance in knowledge graph
interactions, particularly for complex domain-specific tasks. Experimental
results on a dataset of 3,500 test cases show AGENTiGraph significantly
outperforms state-of-the-art zero-shot baselines, achieving 95.12\% accuracy in
task classification and 90.45\% success rate in task execution. User studies
corroborate its effectiveness in real-world scenarios. To showcase versatility,
we extended AGENTiGraph to legislation and healthcare domains, constructing
specialized KGs capable of answering complex queries in legal and medical
contexts.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®æç¨ä¸­å±ç¾å¶è½åï¼ä½ä»é¢è¨å¹»è¦ºãæ¨çè½åæéåäºå¯¦ä¸ä¸è´ç­ææ°ï¼å°¤å¶æ¯å¨èçè¤éçç¹å®é åä»»åï¼ä¾å¦åç­ (QA) æãéç¶ç¥è­åè­ (KG) å·²è¢«è­ææå©æ¼ç·©è§£éäºåé¡ï¼ä½ LLM èèæ¯ KG æ´åçç ç©¶ä»ç¶æéãç¹å¥æ¯ï¼ä½¿ç¨èçå¯åæ§ååºå±¤ KG çéæ´»æ§å°æªå¾å°å¾¹åºæ¢è¨ãæåå¼å¥äº AGENTiGraphï¼ç¨æ¼ä»»ååäºåååå½¢è¡¨ç¤ºçèªé©æçæå¼æï¼ï¼ä¸åééèªç¶èªè¨äºåé²è¡ç¥è­ç®¡ççå¹³å°ãå®æ´åäºç¥è­èåãæ´ååå³æè¦è¦ºåãAGENTiGraph æ¡ç¨å¤ä»£çæ¶æ§ï¼ä»¥åæè§£è®ä½¿ç¨èçæåãç®¡çä»»åä¸¦æ´åæ°ç¥è­ï¼ç¢ºä¿é©æä¸æ·è®åçä½¿ç¨èéæ±åè³æèçµ¡ãæåçåæ³å¨ç¥è­åè­äºåä¸­å±ç¾åºåªç°çæè½ï¼ç¹å¥æ¯å°æ¼è¤éçç¹å®é åä»»åãå¨ 3,500 åæ¸¬è©¦æ¡ä¾çè³æéä¸é²è¡çå¯¦é©çµæé¡¯ç¤ºï¼AGENTiGraph æé¡¯åªæ¼æåé²çé¶æ¬¡å­¸ç¿åºæºï¼å¨ä»»ååé¡ä¸­éå° 95.12% çæºç¢ºåº¦ï¼å¨ä»»åå·è¡ä¸­éå° 90.45% çæåçãä½¿ç¨èç ç©¶è­å¯¦äºå®å¨çå¯¦ä¸çå ´æ¯ä¸­çæææ§ãçºäºå±ç¤ºå¶å¤åè½æ§ï¼æåå° AGENTiGraph å»¶ä¼¸å°æ³å¾åé«çä¿å¥é åï¼å»ºæ§äºè½å¤ åç­æ³å¾åé«çèçµ¡ä¸­è¤éæ¥è©¢çå°æ¥­ç¥è­åè­ã

##### **Do LLMs Have the Generalization Ability in Conducting Causal Inference?**
2410.11385v1 by Chen Wang, Dongming Zhao, Bo Wang, Ruifang He, Yuexian Hou

In causal inference, generalization capability refers to the ability to
conduct causal inference methods on new data to estimate the causal-effect
between unknown phenomenon, which is crucial for expanding the boundaries of
knowledge. Studies have evaluated the causal inference capabilities of Large
Language Models (LLMs) concerning known phenomena, yet the generalization
capabilities of LLMs concerning unseen phenomena remain unexplored. In this
paper, we selected four tasks: Causal Path Discovery (CP), Backdoor Adjustment
(BA), Factual Inference (FI), and Counterfactual Inference (CI) as
representatives of causal inference tasks. To generate evaluation questions
about previously unseen phenomena in new data on the four tasks, we propose a
benchmark generation framework, which employs randomly generated graphs and
node names to formulate questions within hypothetical new causal scenarios.
Based on this framework, we compile a benchmark dataset of varying levels of
question complexity. We extensively tested the generalization capabilities of
five leading LLMs across four tasks. Experiment results reveal that while LLMs
exhibit good generalization performance in solving simple CP, FI, and complex
CI questions, they encounter difficulties when tackling BA questions and face
obvious performance fluctuations as the problem complexity changes.
Furthermore, when the names of phenomena incorporate existing terms, even if
these names are entirely novel, their generalization performance can still be
hindered by interference from familiar terms.

æè¦ï¼å¨å ææ¨è«ä¸­ï¼æ³åè½åæ¯æå¨æ°çè³æä¸å·è¡å ææ¨è«æ¹æ³ä»¥ä¼°è¨æªç¥ç¾è±¡ä¹éçå æéä¿çè½åï¼éå°æ¼æ´å±ç¥è­ççéè³ééè¦ãç ç©¶å·²ç¶è©ä¼°äºå¤§åèªè¨æ¨¡å (LLM) éæ¼å·²ç¥ç¾è±¡çå ææ¨è«è½åï¼ä½ LLM éæ¼æªç¥ç¾è±¡çæ³åè½åä»æªè¢«æ¢è¨ãå¨æ¬æä¸­ï¼æåé¸æäºååä»»åï¼å æè·¯å¾ç¼ç¾ (CP)ãå¾éèª¿æ´ (BA)ãäºå¯¦æ¨è« (FI) ååäºå¯¦æ¨è« (CI) ä½çºå ææ¨è«ä»»åçä»£è¡¨ãçºäºç¢çéæ¼æ°è³æä¸­ä»¥åæªè¦ç¾è±¡çè©ä¼°åé¡ï¼æåæåºäºåºæºçææ¡æ¶ï¼è©²æ¡æ¶æ¡ç¨é¨æ©çæçåå½¢åç¯é»åç¨±å¨åè¨­çæ°å æå ´æ¯ä¸­å¶å®åé¡ãåºæ¼æ­¤æ¡æ¶ï¼æåç·¨å¶äºä¸ååé¡è¤éç¨åº¦ä¸åçåºæºæ¸æéãæåå»£æ³æ¸¬è©¦äºäºåé åç LLM å¨ååä»»åä¸­çæ³åè½åãå¯¦é©çµæè¡¨æï¼éç¶ LLM å¨è§£æ±ºç°¡å®ç CPãFI åè¤éç CI åé¡æè¡¨ç¾åºè¯å¥½çæ³åæ§è½ï¼ä½å¨è§£æ±º BA åé¡æéå°å°é£ï¼ä¸¦ä¸é¨èåé¡è¤éæ§çè®åèé¢è¨æé¡¯çæ§è½æ³¢åãæ­¤å¤ï¼ç¶ç¾è±¡çåç¨±åå«ç¾æè¡èªæï¼å³ä½¿éäºåç¨±æ¯å®å¨æ°ç©çï¼å¶æ³åæ§è½ä»ç¶æåå°çæè¡èªçå¹²æ¾ã

##### **Enhance Graph Alignment for Large Language Models**
2410.11370v1 by Haitong Luo, Xuying Meng, Suhang Wang, Tianxiang Zhao, Fali Wang, Hanyun Cao, Yujun Zhang

Graph-structured data is prevalent in the real world. Recently, due to the
powerful emergent capabilities, Large Language Models (LLMs) have shown
promising performance in modeling graphs. The key to effectively applying LLMs
on graphs is converting graph data into a format LLMs can comprehend.
Graph-to-token approaches are popular in enabling LLMs to process graph
information. They transform graphs into sequences of tokens and align them with
text tokens through instruction tuning, where self-supervised instruction
tuning helps LLMs acquire general knowledge about graphs, and supervised
fine-tuning specializes LLMs for the downstream tasks on graphs. Despite their
initial success, we find that existing methods have a misalignment between
self-supervised tasks and supervised downstream tasks, resulting in negative
transfer from self-supervised fine-tuning to downstream tasks. To address these
issues, we propose Graph Alignment Large Language Models (GALLM) to benefit
from aligned task templates. In the self-supervised tuning stage, we introduce
a novel text matching task using templates aligned with downstream tasks. In
the task-specific tuning stage, we propose two category prompt methods that
learn supervision information from additional explanation with further aligned
templates. Experimental evaluations on four datasets demonstrate substantial
improvements in supervised learning, multi-dataset generalizability, and
particularly in zero-shot capability, highlighting the model's potential as a
graph foundation model.

æè¦ï¼åå½¢çµæ§çè³æå¨ç¾å¯¦ä¸çä¸­å¾å¸¸è¦ãæè¿ï¼ç±æ¼å¼·å¤§çæ°èè½åï¼å¤§åèªè¨æ¨¡å (LLM) å¨åå½¢å»ºæ¨¡æ¹é¢å±ç¾åºä»¤äººæ»¿æçæè½ãææå° LLM æç¨æ¼åå½¢çééµæ¯å°åå½¢è³æè½ææ LLM å¯ä»¥çè§£çæ ¼å¼ãåå½¢å°æ¨è¨çæ¹æ³å¾æµè¡ï¼è® LLM å¯ä»¥èçåå½¢è³è¨ãå®åå°åå½¢è½æææ¨è¨åºåï¼ä¸¦ééæä»¤èª¿æ´èæå­æ¨è¨å°é½ï¼å¶ä¸­èªæç£ç£çæä»¤èª¿æ´æå©æ¼ LLM ç²å¾éæ¼åå½¢çå¸¸è­ï¼èç£ç£å¾®èª¿åå°ééå°åå½¢ä¸çä¸æ¸¸ä»»åèª¿æ´ LLMãåç®¡å®åæåå¾æåï¼æåç¼ç¾ç¾ææ¹æ³å¨èªæç£ç£ä»»ååç£ç£ä¸æ¸¸ä»»åä¹éå­å¨é¯ä½ï¼å°è´èªæç£ç£å¾®èª¿å°ä¸æ¸¸ä»»åç¢çè² é¢å½±é¿ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºåå½¢å°é½å¤§åèªè¨æ¨¡å (GALLM) ä»¥å¾å°é½çä»»åç¯æ¬ä¸­åçãå¨èªæç£ç£èª¿æ´éæ®µï¼æåä½¿ç¨èä¸æ¸¸ä»»åå°é½çç¯æ¬ï¼å¼å¥ä¸åæ°ç©çæå­æ¯å°ä»»åãå¨ç¹å®ä»»åçèª¿æ´éæ®µï¼æåæåºå©ç¨®é¡å¥æç¤ºæ¹æ³ï¼å¾é²ä¸æ­¥å°é½ç¯æ¬çé¡å¤èªªæä¸­å­¸ç¿ç£ç£è³è¨ãå¨ååè³æéä¸çå¯¦é©è©ä¼°è­æäºç£ç£å¼å­¸ç¿ãå¤è³æéçæ¦æ¬æ§ï¼ç¹å¥æ¯å¨é¶æ¬¡å­¸ç¿è½åæ¹é¢æé¡¯èçé²æ­¥ï¼çªé¡¯äºè©²æ¨¡åä½çºåå½¢åºç¤æ¨¡åçæ½åã

##### **Unleashing the Power of LLMs as Multi-Modal Encoders for Text and Graph-Structured Data**
2410.11235v1 by Jiacheng Lin, Kun Qian, Haoyu Han, Nurendra Choudhary, Tianxin Wei, Zhongruo Wang, Sahika Genc, Edward W Huang, Sheng Wang, Karthik Subbian, Danai Koutra, Jimeng Sun

Graph-structured information offers rich contextual information that can
enhance language models by providing structured relationships and hierarchies,
leading to more expressive embeddings for various applications such as
retrieval, question answering, and classification. However, existing methods
for integrating graph and text embeddings, often based on Multi-layer
Perceptrons (MLPs) or shallow transformers, are limited in their ability to
fully exploit the heterogeneous nature of these modalities. To overcome this,
we propose Janus, a simple yet effective framework that leverages Large
Language Models (LLMs) to jointly encode text and graph data. Specifically,
Janus employs an MLP adapter to project graph embeddings into the same space as
text embeddings, allowing the LLM to process both modalities jointly. Unlike
prior work, we also introduce contrastive learning to align the graph and text
spaces more effectively, thereby improving the quality of learned joint
embeddings. Empirical results across six datasets spanning three tasks,
knowledge graph-contextualized question answering, graph-text pair
classification, and retrieval, demonstrate that Janus consistently outperforms
existing baselines, achieving significant improvements across multiple
datasets, with gains of up to 11.4% in QA tasks. These results highlight
Janus's effectiveness in integrating graph and text data. Ablation studies
further validate the effectiveness of our method.

æè¦ï¼åå½¢çµæ§åè³è¨æä¾è±å¯çèçµ¡è³è¨ï¼å¯ä»¥ééæä¾çµæ§åçéä¿åéå±¤ä¾å¢å¼·èªè¨æ¨¡åï¼é²èçºåç¨®æç¨ç¨å¼ï¼ä¾å¦æª¢ç´¢ãåç­ååé¡ï¼ç¢çæ´å·è¡¨ç¾åçåµå¥ãç¶èï¼ç¾æçåå½¢åæå­åµå¥æ´åæ¹æ³ï¼éå¸¸åºæ¼å¤å±¤æç¥å¨ (MLP) ææ·ºå±¤è½æå¨ï¼å¨ååå©ç¨éäºæ¨¡æçç°è³ªæ§æ¹é¢è½åæéãçºäºåæéä¸é»ï¼æåæåºäº Janusï¼ä¸åç°¡å®ä½ææçæ¡æ¶ï¼å®å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾è¯åç·¨ç¢¼æå­ååå½¢è³æãå·é«ä¾èªªï¼Janus ä½¿ç¨ MLP é©éå¨å°åå½¢åµå¥æå½±å°èæå­åµå¥ç¸åçç©ºéï¼åè¨± LLM è¯åèçéå©ç¨®æ¨¡æãèååçç ç©¶ä¸åï¼æåéå¼å¥äºå°æ¯å­¸ç¿ï¼ä»¥æ´ææå°å°é½åå½¢åæå­ç©ºéï¼å¾èæé«å­¸ç¿å°çè¯ååµå¥çåè³ªãè·¨è¶å­åè³æéçå¯¦è­çµææ¶µèäºä¸åä»»åï¼ç¥è­åè­èçµ¡ååç­ãåå½¢æå­å°åé¡åæª¢ç´¢ï¼è­æ Janus æçºåªæ¼ç¾æåºæºï¼å¨å¤åè³æéä¸åå¾é¡¯èé²æ­¥ï¼å¨ QA ä»»åä¸­ç²å¾é«é 11.4% çæåãéäºçµæçªé¡¯äº Janus å¨æ´ååå½¢åæå­è³ææ¹é¢çæææ§ãæ¶èç ç©¶é²ä¸æ­¥é©è­äºæåæ¹æ³çæææ§ã

##### **Tree of Attributes Prompt Learning for Vision-Language Models**
2410.11201v1 by Tong Ding, Wanhua Li, Zhongqi Miao, Hanspeter Pfister

Prompt learning has proven effective in adapting vision language models for
downstream tasks. However, existing methods usually append learnable prompt
tokens solely with the category names to obtain textual features, which fails
to fully leverage the rich context indicated in the category name. To address
this issue, we propose the Tree of Attributes Prompt learning (TAP), which
first instructs LLMs to generate a tree of attributes with a "concept -
attribute - description" structure for each category, and then learn the
hierarchy with vision and text prompt tokens. Unlike existing methods that
merely augment category names with a set of unstructured descriptions, our
approach essentially distills structured knowledge graphs associated with class
names from LLMs. Furthermore, our approach introduces text and vision prompts
designed to explicitly learn the corresponding visual attributes, effectively
serving as domain experts. Additionally, the general and diverse descriptions
generated based on the class names may be wrong or absent in the specific given
images. To address this misalignment, we further introduce a vision-conditional
pooling module to extract instance-specific text features. Extensive
experimental results demonstrate that our approach outperforms state-of-the-art
methods on the zero-shot base-to-novel generalization, cross-dataset transfer,
as well as few-shot classification across 11 diverse datasets.

æè¦ï¼æç¤ºå­¸ç¿å·²è¢«è­æææå°å°è¦è¦ºèªè¨æ¨¡åé©ææ¼ä¸æ¸¸ä»»åãç¶èï¼ç¾ææ¹æ³éå¸¸åå°å¯å­¸ç¿çæç¤ºä»¤çéå å°é¡å¥åç¨±ä»¥ç²åææ¬ç¹å¾µï¼éæªè½ååå©ç¨é¡å¥åç¨±ä¸­æç¤ºçè±å¯ä¸ä¸æãçºäºè§£æ±ºéååé¡ï¼æåæåºäºå±¬æ§æç¤ºå­¸ç¿æ¨¹ (TAP)ï¼å®é¦åæç¤º LLM çºæ¯åé¡å¥çæä¸åå·æãæ¦å¿µ - å±¬æ§ - æè¿°ãçµæ§çå±¬æ§æ¨¹ï¼ç¶å¾ä½¿ç¨è¦è¦ºåææ¬æç¤ºä»¤çå­¸ç¿å±¤æ¬¡çµæ§ãèåä½¿ç¨ä¸çµéçµæ§åæè¿°ä¾æ´åé¡å¥åç¨±çç¾ææ¹æ³ä¸åï¼æåçåæ³å¯¦è³ªä¸å¾ LLM ä¸­æçåºèé¡å¥åç¨±ç¸éççµæ§åç¥è­åãæ­¤å¤ï¼æåçåæ³å¼å¥äºææ¬åè¦è¦ºæç¤ºï¼æ¨å¨æç¢ºå­¸ç¿å°æçè¦è¦ºå±¬æ§ï¼ææå°åç¶é åå°å®¶ãæ­¤å¤ï¼æ ¹æé¡å¥åç¨±çæçéç¨ä¸å¤æ¨£çæè¿°å¨çµ¦å®çç¹å®å½±åä¸­å¯è½æ¯é¯èª¤çæä¸å­å¨çãçºäºè§£æ±ºéç¨®é¯ä½ï¼æåé²ä¸æ­¥å¼å¥äºä¸åè¦è¦ºæ¢ä»¶æ± åæ¨¡çµä¾æåç¹å®æ¼å¯¦ä¾çææ¬ç¹å¾µãå»£æ³çå¯¦é©çµæè¡¨æï¼æåçåæ³å¨é¶æ¬¡å­¸ç¿åºç¤å°æ°ç©çæ¦åãè·¨è³æéå³è¼¸ä»¥å 11 åä¸åè³æéçå°æ¬¡å­¸ç¿åé¡ä¸åªæ¼æåé²çæ¹æ³ã

##### **Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs**
2410.11001v1 by Haozhen Zhang, Tao Feng, Jiaxuan You

Retrieval-augmented generation (RAG) has revitalized Large Language Models
(LLMs) by injecting non-parametric factual knowledge. Compared with
long-context LLMs, RAG is considered an effective summarization tool in a more
concise and lightweight manner, which can interact with LLMs multiple times
using diverse queries to get comprehensive responses. However, the
LLM-generated historical responses, which contain potentially insightful
information, are largely neglected and discarded by existing approaches,
leading to suboptimal results. In this paper, we propose \textit{graph of
records} (\textbf{GoR}), which leverages historical responses generated by LLMs
to enhance RAG for long-context global summarization. Inspired by the
\textit{retrieve-then-generate} paradigm of RAG, we construct a graph by
establishing an edge between the retrieved text chunks and the corresponding
LLM-generated response. To further uncover the intricate correlations between
them, GoR further features a \textit{graph neural network} and an elaborately
designed \textit{BERTScore}-based objective for self-supervised model training,
enabling seamless supervision signal backpropagation between reference
summaries and node embeddings. We comprehensively compare GoR with 12 baselines
across four long-context summarization datasets, and the results indicate that
our proposed method reaches the best performance e.g., 15\%, 8\%, and 19\%
improvement over retrievers w.r.t. Rouge-L, Rouge-1, and Rouge-2 on the WCEP
dataset). Extensive experiments further demonstrate the effectiveness of GoR.
Code is available at https://github.com/ulab-uiuc/GoR

æè¦ï¼æ£ç´¢å¢å¼ºçæ (RAG) éè¿æ³¨å¥éåæ°äºå®ç¥è¯ï¼è®©å¤§åè¯­è¨æ¨¡å (LLM) éè·çæºãä¸é¿ææ¬ LLM ç¸æ¯ï¼RAG è¢«è§ä¸ºä¸ç§æ´ç®æ´ãè½»éçº§çæææè¦å·¥å·ï¼å®å¯ä»¥ä½¿ç¨ä¸åçæ¥è¯¢ä¸ LLM å¤æ¬¡äºå¨ï¼ä»¥è·å¾å¨é¢çååºãç¶èï¼ç°æçæ¹æ³å¨å¾å¤§ç¨åº¦ä¸å¿½ç¥å¹¶èå¼äº LLM çæçåå²ååºï¼å¶ä¸­åå«æ½å¨çæè§è§£çä¿¡æ¯ï¼ä»èå¯¼è´æ¬¡ä¼çç»æãå¨æ¬æä¸­ï¼æä»¬æåºäºãè®°å½å¾ã(**GoR**)ï¼å®å©ç¨ LLM çæçåå²ååºæ¥å¢å¼º RAGï¼ä»¥è¿è¡é¿ææ¬å¨å±æè¦ãå RAG çãåæ£ç´¢åçæãèä¾å¯åï¼æä»¬éè¿å¨æ£ç´¢å°çææ¬ååç¸åºç LLM çæçååºä¹é´å»ºç«è¾¹æ¥æå»ºå¾ãä¸ºäºè¿ä¸æ­¥æ­ç¤ºå®ä»¬ä¹é´çå¤æç¸å³æ§ï¼GoR è¿ä¸æ­¥éç¨äºãå¾ç¥ç»ç½ç»ãåç²¾å¿è®¾è®¡çåºäºãBERTScoreãçç®æ ï¼ç¨äºèªæçç£æ¨¡åè®­ç»ï¼ä»èå¨åèæè¦åèç¹åµå¥ä¹é´å®ç°æ ç¼ççç£ä¿¡å·ååä¼ æ­ãæä»¬å¯¹ GoR ä¸ 12 ä¸ªåºåè¿è¡äºå¨é¢æ¯è¾ï¼æ¶µçäºåä¸ªé¿ææ¬æè¦æ°æ®éï¼ç»æè¡¨ææä»¬æåºçæ¹æ³è¾¾å°äºæä½³æ§è½ï¼ä¾å¦ï¼å¨ WCEP æ°æ®éä¸ï¼ç¸å¯¹äºæ£ç´¢å¨ï¼Rouge-LãRouge-1 å Rouge-2 åå«æé«äº 15%ã8% å 19%ãå¹¿æ³çå®éªè¿ä¸æ­¥è¯æäº GoR çæææ§ãä»£ç å¯å¨ https://github.com/ulab-uiuc/GoR è·å¾

##### **NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models**
2410.10743v1 by Yanbiao Ji, Chang Liu, Xin Chen, Yue Ding, Dan Luo, Mei Li, Wenqing Lin, Hongtao Lu

Graphs are a fundamental data structure for representing relationships in
real-world scenarios. With the success of Large Language Models (LLMs) across
various natural language processing (NLP) tasks, there has been growing
interest in integrating LLMs for graph learning. However, applying LLMs to
graph-related tasks poses significant challenges, as these models are not
inherently designed to capture the complex structural information present in
graphs. Existing approaches address this challenge through two strategies: the
chain of tasks approach, which uses Graph Neural Networks (GNNs) to encode the
graph structure so that LLMs are relieved from understanding spatial positions;
and Graph-to-Text Conversion, which translates graph structures into semantic
text representations that LLMs can process. Despite their progress, these
methods often struggle to fully preserve the topological information of graphs
or require extensive computational resources, limiting their practical
applicability.
  In this work, we introduce Node Tokenizer for Large Language Models (NT-LLM),
a novel framework that efficiently encodes graph structures by selecting key
nodes as anchors and representing each node based on its relative distance to
these anchors. This position-anchored encoding effectively captures the graph
topology, enabling enhanced reasoning capabilities in LLMs over graph data.
Additionally, we implement a task-specific tuning procedure to further improve
structural understanding within LLMs. Through extensive empirical evaluations,
NT-LLM demonstrates significant performance improvements across a variety of
graph-related tasks.

æè¦ï¼åå½¢æ¯ä¸ç¨®åºæ¬è³æçµæ§ï¼ç¨æ¼è¡¨ç¤ºç¾å¯¦ä¸çå ´æ¯ä¸­çéä¿ãé¨èå¤§åèªè¨æ¨¡å (LLM) å¨åç¨®èªç¶èªè¨èç (NLP) ä»»åä¸­çæåï¼æ´å LLM ä»¥é²è¡åå½¢å­¸ç¿çèè¶£æ¥çæ¿åãç¶èï¼å° LLM æç¨æ¼èåå½¢ç¸éçä»»åæå¸¶ä¾éå¤§ææ°ï¼å çºéäºæ¨¡åä¸¦éå¤©çå°±è¨­è¨æç¨ä¾æ·ååå½¢ä¸­å­å¨çè¤éçµæ§è³è¨ãç¾ææ¹æ³ééå©ç¨®ç­ç¥ä¾æå°æ­¤ææ°ï¼ä»»åéæ¹æ³ï¼å®ä½¿ç¨åå½¢ç¥ç¶ç¶²è·¯ (GNN) ç·¨ç¢¼åå½¢çµæ§ï¼ä»¥ä¾¿æ¸è¼ LLM çè§£ç©ºéä½ç½®çè² æï¼ä»¥ååå½¢è½æå­è½æï¼å®å°åå½¢çµæ§è½ææ LLM å¯ä»¥èççèªææå­è¡¨ç¤ºãåç®¡éäºæ¹æ³åå¾äºé²å±ï¼ä½å®åéå¸¸é£ä»¥å®å¨ä¿çåå½¢çææ²è³è¨ï¼æèéè¦å¤§éçéç®è³æºï¼éå¶äºå®åçå¯¦éæç¨æ§ã
å¨æ¬æä¸­ï¼æåä»ç´¹äºå¤§åèªè¨æ¨¡åç¯é»æ¨è¨å¨ (NT-LLM)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®ééé¸æééµç¯é»ä½çºé¨é»ï¼ä¸¦æ ¹ææ¯åç¯é»èéäºé¨é»çç¸å°è·é¢ä¾è¡¨ç¤ºæ¯åç¯é»ï¼å¾èææå°ç·¨ç¢¼åå½¢çµæ§ãéç¨®åºæ¼ä½ç½®çé¨é»ç·¨ç¢¼ææå°æ·åäºåå½¢ææ²ï¼è® LLM è½å¤ å°åå½¢è³æé²è¡å¢å¼·çæ¨çãæ­¤å¤ï¼æåå¯¦ä½äºä¸åç¹å®æ¼ä»»åçèª¿æ´ç¨åºï¼ä»¥é²ä¸æ­¥æ¹å LLM ä¸­ççµæ§çè§£ãééå»£æ³çå¯¦è­è©ä¼°ï¼NT-LLM å¨åç¨®èåå½¢ç¸éçä»»åä¸­é½å±ç¤ºåºé¡¯èçæè½æåã

##### **GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs**
2410.10329v3 by Yun Zhu, Haizhou Shi, Xiaotang Wang, Yongchao Liu, Yaoke Wang, Boci Peng, Chuntao Hong, Siliang Tang

Recently, research on Text-Attributed Graphs (TAGs) has gained significant
attention due to the prevalence of free-text node features in real-world
applications and the advancements in Large Language Models (LLMs) that bolster
TAG methodologies. However, current TAG approaches face two primary challenges:
(i) Heavy reliance on label information and (ii) Limited cross-domain
zero/few-shot transferability. These issues constrain the scaling of both data
and model size, owing to high labor costs and scaling laws, complicating the
development of graph foundation models with strong transferability. In this
work, we propose the GraphCLIP framework to address these challenges by
learning graph foundation models with strong cross-domain zero/few-shot
transferability through a self-supervised contrastive graph-summary pretraining
method. Specifically, we generate and curate large-scale graph-summary pair
data with the assistance of LLMs, and introduce a novel graph-summary
pretraining method, combined with invariant learning, to enhance graph
foundation models with strong cross-domain zero-shot transferability. For
few-shot learning, we propose a novel graph prompt tuning technique aligned
with our pretraining objective to mitigate catastrophic forgetting and minimize
learning costs. Extensive experiments show the superiority of GraphCLIP in both
zero-shot and few-shot settings, while evaluations across various downstream
tasks confirm the versatility of GraphCLIP. Our code is available at:
https://github.com/ZhuYun97/GraphCLIP

æè¦ï¼<paragraph>æè¿ï¼ææ¬å±æ§å¾ (TAG) çç ç©¶å ç°å®ä¸çåºç¨ç¨åºä¸­æ®éå­å¨çèªç±ææ¬èç¹ç¹å¾åå¢å¼º TAG æ¹æ³è®ºçå¤§åè¯­è¨æ¨¡å (LLM) çè¿æ­¥èå¤åå³æ³¨ãç¶èï¼å½åç TAG æ¹æ³é¢ä¸´ä¸¤é¡¹ä¸»è¦ææï¼(i) å¯¹æ ç­¾ä¿¡æ¯çä¸¥éä¾èµï¼ä»¥å (ii) è·¨é¢åé¶æ¬¡/å°æ¬¡è¿ç§»è½åæéãç±äºé«æçäººå·¥ææ¬åè§æ¨¡åå®å¾ï¼è¿äºé®é¢éå¶äºæ°æ®åæ¨¡åè§æ¨¡çæ©å±ï¼ä»èä½¿å·æå¼ºå¤§è¿ç§»è½åçå¾åºç¡æ¨¡åçå¼ååå¾å¤æãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäº GraphCLIP æ¡æ¶ï¼éè¿èªçç£å¯¹æ¯å¾æè¦é¢è®­ç»æ¹æ³æ¥è§£å³è¿äºææï¼å­¦ä¹ å·æå¼ºå¤§è·¨é¢åé¶æ¬¡/å°æ¬¡è¿ç§»è½åçå¾åºç¡æ¨¡åãå·ä½æ¥è¯´ï¼æä»¬å¨ LLM çå¸®å©ä¸çæåæ´çäºå¤§è§æ¨¡å¾æè¦å¯¹æ°æ®ï¼å¹¶å¼å¥äºä¸ç§æ°é¢çå¾æè¦é¢è®­ç»æ¹æ³ï¼ç»åä¸åå¼å­¦ä¹ ï¼ä»¥å¢å¼ºå·æå¼ºå¤§è·¨é¢åé¶æ¬¡è¿ç§»è½åçå¾åºç¡æ¨¡åãå¯¹äºå°æ¬¡å­¦ä¹ ï¼æä»¬æåºäºä¸ç§æ°é¢çå¾æç¤ºè°æ´ææ¯ï¼ä¸æä»¬çé¢è®­ç»ç®æ ä¿æä¸è´ï¼ä»¥åè½»ç¾é¾æ§éå¿å¹¶æå¤§ç¨åº¦å°éä½å­¦ä¹ ææ¬ãå¤§éçå®éªè¡¨æï¼GraphCLIP å¨é¶æ¬¡åå°æ¬¡è®¾ç½®ä¸­é½å·æä¼è¶æ§ï¼èå¯¹åç§ä¸æ¸¸ä»»å¡çè¯ä¼°è¯å®äº GraphCLIP çå¤åè½æ§ãæä»¬çä»£ç å¯å¨ä»¥ä¸ä½ç½®è·å¾ï¼https://github.com/ZhuYun97/GraphCLIP</paragraph>

##### **Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning**
2410.10144v1 by Hongyi Yuan, Suqi Liu, Kelly Cho, Katherine Liao, Alexandre Pereira, Tianxi Cai

We introduce GENomic Encoding REpresentation with Language Model (GENEREL), a
framework designed to bridge genetic and biomedical knowledge bases. What sets
GENEREL apart is its ability to fine-tune language models to infuse biological
knowledge behind clinical concepts such as diseases and medications. This
fine-tuning enables the model to capture complex biomedical relationships more
effectively, enriching the understanding of how genomic data connects to
clinical outcomes. By constructing a unified embedding space for biomedical
concepts and a wide range of common SNPs from sources such as patient-level
data, biomedical knowledge graphs, and GWAS summaries, GENEREL aligns the
embeddings of SNPs and clinical concepts through multi-task contrastive
learning. This allows the model to adapt to diverse natural language
representations of biomedical concepts while bypassing the limitations of
traditional code mapping systems across different data sources. Our experiments
demonstrate GENEREL's ability to effectively capture the nuanced relationships
between SNPs and clinical concepts. GENEREL also emerges to discern the degree
of relatedness, potentially allowing for a more refined identification of
concepts. This pioneering approach in constructing a unified embedding system
for both SNPs and biomedical concepts enhances the potential for data
integration and discovery in biomedical research.

æè¦ï¼<paragraph>æåä»ç´¹ GENomic Encoding REpresentation with Language Model (GENEREL)ï¼ä¸åæ¨å¨æ©æ¥éºå³åçç©é«å­¸ç¥è­åº«çæ¡æ¶ãGENEREL çç¨ç¹ä¹èå¨æ¼å®å¾®èª¿èªè¨æ¨¡åï¼ä»¥çè¼¸ç¾çåè¥ç©ç­è¨åºæ¦å¿µèå¾ççç©ç¥è­ãéç¨®å¾®èª¿ä½¿æ¨¡åè½å¤ æ´ææå°ææè¤éççç©é«å­¸éä¿ï¼è±å¯å°åºå çµæ¸æå¦ä½é£æ¥è¨åºçµæççè§£ãééæ§å»ºä¸åçµ±ä¸ççç©é«å­¸æ¦å¿µåµå¥ç©ºéåä¾èªæ£èç´å¥æ¸æãçç©é«å­¸ç¥è­åè­å GWAS ç¸½çµç­ä¾æºçå»£æ³å¸¸è¦ SNPï¼GENEREL ééå¤ä»»åå°æ¯å­¸ç¿å°é½ SNP åè¨åºæ¦å¿µçåµå¥ãéåè¨±æ¨¡åé©æçç©é«å­¸æ¦å¿µçå¤åèªç¶èªè¨è¡¨ç¤ºï¼åæç¹éä¸åæ¸ææºä¸­å³çµ±ä»£ç¢¼æ å°ç³»çµ±çéå¶ãæåçå¯¦é©è­æäº GENEREL ææææ SNP åè¨åºæ¦å¿µä¹éç´°å¾®éä¿çè½åãGENEREL ä¹åºç¾äºè¾¨å¥ç¸éç¨åº¦ï¼æ½å¨å°åè¨±æ´ç²¾ç¢ºå°è­å¥æ¦å¿µãéç¨®æ§å»º SNP åçç©é«å­¸æ¦å¿µçµ±ä¸åµå¥ç³»çµ±çåé©æ¹æ³å¢å¼·äºçç©é«å­¸ç ç©¶ä¸­æ¸ææ´ååç¼ç¾çæ½åã</paragraph>

##### **Language Model Preference Evaluation with Multiple Weak Evaluators**
2410.12869v1 by Zhengyu Hu, Jieyu Zhang, Zhihan Xiong, Alexander Ratner, Hui Xiong, Ranjay Krishna

Despite the remarkable success of Large Language Models (LLMs), evaluating
their outputs' quality regarding preference remains a critical challenge.
Existing works usually leverage a powerful LLM (e.g., GPT4) as the judge for
comparing LLMs' output pairwisely, yet such model-based evaluator is vulnerable
to conflicting preference, i.e., output A is better than B, B than C, but C
than A, causing contradictory evaluation results. To improve model-based
preference evaluation, we introduce GED (Preference Graph Ensemble and
Denoise), a novel approach that leverages multiple model-based evaluators to
construct preference graphs, and then ensemble and denoise these graphs for
better, non-contradictory evaluation results. In particular, our method
consists of two primary stages: aggregating evaluations into a unified graph
and applying a denoising process to eliminate cyclic inconsistencies, ensuring
a directed acyclic graph (DAG) structure. We provide theoretical guarantees for
our framework, demonstrating its efficacy in recovering the ground truth
preference structure. Extensive experiments across ten benchmark datasets show
that GED outperforms baseline methods in model ranking, response selection, and
model alignment tasks. Notably, GED combines weaker evaluators like Llama3-8B,
Mistral-7B, and Qwen2-7B to surpass the performance of stronger evaluators like
Qwen2-72B, highlighting its ability to enhance evaluation reliability and
improve model performance.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡åï¼LLMï¼ç²å¾äºé¡¯èçæåï¼ä½è©ä¼°å¶ç¢åºçåè³ªä»ç¶æ¯ä¸é ééµçææ°ãç¾æçä½åéå¸¸å©ç¨å¼·å¤§ç LLMï¼ä¾å¦ GPT4ï¼ä½çºè©å¯©ï¼æå°æ¯è¼ LLM çç¢åºï¼ç¶èéç¨®åºæ¼æ¨¡åçè©ä¼°å¨å®¹æåå°è¡çªåå¥½çå½±é¿ï¼å³è¼¸åº A åªæ¼ Bï¼B åªæ¼ Cï¼ä½ C åªæ¼ Aï¼å°è´çç¾çè©ä¼°çµæãçºäºæ¹é²åºæ¼æ¨¡åçåå¥½è©ä¼°ï¼æåå¼å¥äº GEDï¼åå¥½åå½¢éæåå»åªï¼ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å®å©ç¨å¤ååºæ¼æ¨¡åçè©ä¼°å¨ä¾æ§å»ºåå¥½åå½¢ï¼ç¶å¾éæä¸¦å°éäºåå½¢é²è¡å»åªï¼ä»¥ç²å¾æ´å¥½ãç¡çç¾çè©ä¼°çµæãç¹å¥æ¯ï¼æåçæ¨¡ååå«å©åä¸»è¦éæ®µï¼å°è©ä¼°èåå°ä¸åçµ±ä¸çåå½¢ä¸­ï¼ä¸¦æç¨å»åªç¨åºä»¥æ¶é¤å¾ªç°ä¸ä¸è´æ§ï¼ç¢ºä¿æåç¡ç°å (DAG) çµæ§ãæåçºæåçæ¡æ¶æä¾äºçè«ä¿è­ï¼è­æäºå¶å¨æ¢å¾©çå¯¦åå¥½çµæ§æ¹é¢çæåãè·¨è¶åååºæºè³æéçå»£æ³å¯¦é©è¡¨æï¼GED å¨æ¨¡åæåãåæé¸æåæ¨¡åå°é½ä»»åä¸­åªæ¼åºç·æ¹æ³ãå¼å¾æ³¨æçæ¯ï¼GED çµåäº Llama3-8BãMistral-7B å Qwen2-7B ç­è¼å¼±çè©ä¼°å¨ï¼ä»¥è¶è¶ Qwen2-72B ç­è¼å¼·è©ä¼°å¨çæ§è½ï¼çªé¡¯äºå¶å¢å¼·è©ä¼°å¯é æ§åæ¹åæ¨¡åæ§è½çè½åã

##### **Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?**
2410.10083v2 by Yifan Feng, Chengwu Yang, Xingliang Hou, Shaoyi Du, Shihui Ying, Zongze Wu, Yue Gao

Existing benchmarks like NLGraph and GraphQA evaluate LLMs on graphs by
focusing mainly on pairwise relationships, overlooking the high-order
correlations found in real-world data. Hypergraphs, which can model complex
beyond-pairwise relationships, offer a more robust framework but are still
underexplored in the context of LLMs. To address this gap, we introduce
LLM4Hypergraph, the first comprehensive benchmark comprising 21,500 problems
across eight low-order, five high-order, and two isomorphism tasks, utilizing
both synthetic and real-world hypergraphs from citation networks and protein
structures. We evaluate six prominent LLMs, including GPT-4o, demonstrating our
benchmark's effectiveness in identifying model strengths and weaknesses. Our
specialized prompting framework incorporates seven hypergraph languages and
introduces two novel techniques, Hyper-BAG and Hyper-COT, which enhance
high-order reasoning and achieve an average 4% (up to 9%) performance
improvement on structure classification tasks. This work establishes a
foundational testbed for integrating hypergraph computational capabilities into
LLMs, advancing their comprehension. The source codes are at
https://github.com/iMoonLab/LLM4Hypergraph.

æè¦ï¼ç¾æç NLGraph å GraphQA ç­åºæºä¸»è¦éæ³¨æå°éä¿ï¼èå¿½ç¥äºå¨ç¾å¯¦ä¸çè³æä¸­ç¼ç¾çé«éç¸éæ§ï¼å¾èå°åå½¢ä¸­ç LLM é²è¡è©ä¼°ãè¶åå¯ä»¥å»ºæ¨¡è¤éçè¶è¶æå°éä¿ï¼æä¾æ´å¼·å¤§çæ¡æ¶ï¼ä½å¨ LLM çèæ¯ä¸ä»æªå¾å°ååæ¢ç´¢ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äº LLM4Hypergraphï¼éæ¯ç¬¬ä¸åç¶ååºæºï¼åå« 21,500 ååé¡ï¼æ¶µèå«åä½éãäºåé«éåå©ååæ§ä»»åï¼å©ç¨ä¾èªå¼æç¶²è·¯åèç½è³ªçµæ§çåæåçå¯¦ä¸çè¶åãæåè©ä¼°äºå­åèåç LLMï¼åæ¬ GPT-4oï¼è­æäºæåçåºæºå¨è­å¥æ¨¡ååªå¢åå£å¢æ¹é¢çæææ§ãæåå°æ¥­çæç¤ºæ¡æ¶åå«ä¸ç¨®è¶åèªè¨ï¼ä¸¦å¼å¥äºå©ç¨®æ°æè¡ Hyper-BAG å Hyper-COTï¼å®åå¢å¼·äºé«éæ¨çï¼ä¸¦å¨çµæ§åé¡ä»»åä¸å¯¦ç¾äºå¹³å 4%ï¼æé« 9%ï¼çæ§è½æ¹é²ãéé å·¥ä½çºå°è¶åè¨ç®è½åæ´åå° LLM ä¸­å»ºç«äºä¸ååºç¤æ¸¬è©¦å¹³å°ï¼å¾èæåäºå®åççè§£åãæºä»£ç¢¼ä½æ¼ https://github.com/iMoonLab/LLM4Hypergraphã

##### **Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation**
2410.09824v2 by Jiarui Ji, Runlin Lei, Jialing Bi, Zhewei Wei, Yankai Lin, Xuchen Pan, Yaliang Li, Bolin Ding

Graph generation is a fundamental task that has been extensively studied in
social, technological, and scientific analysis. For modeling the dynamic graph
evolution process, traditional rule-based methods struggle to capture community
structures within graphs, while deep learning methods only focus on fitting
training graphs. This limits existing graph generators to producing graphs that
adhere to predefined rules or closely resemble training datasets, achieving
poor performance in dynamic graph generation. Given that graphs are abstract
representations arising from pairwise interactions in human activities, a
realistic simulation of human-wise interaction could provide deeper insights
into the graph evolution mechanism. With the increasing recognition of large
language models (LLMs) in simulating human behavior, we introduce
GraphAgent-Generator (GAG), a novel simulation-based framework for dynamic
graph generation. Without training or fine-tuning process of LLM, our framework
effectively replicates seven macro-level structural characteristics in
established network science theories while surpassing existing baselines in
graph expansion tasks by 31\% on specific evaluation metrics. Through node
classification task, we validate GAG effectively preserves characteristics of
real-world network for node-wise textual features in generated text-rich graph.
Furthermore, by incorporating parallel acceleration, GAG supports generating
graphs with up to nearly 100,000 nodes or 10 million edges through large-scale
LLM-based agent simulation, with a minimum speed-up of 90.4\%. The source code
is available at https://anonymous.4open.science/r/GraphAgent-2206.

æè¦ï¼åè¡¨ç¢çæ¯ä¸é åºç¤ä»»åï¼å·²å¨ç¤¾æãæè¡åç§å­¸åæä¸­å»£æ³ç ç©¶ãå°æ¼å»ºæ¨¡åæåè¡¨æ¼åéç¨ï¼å³çµ±çåºæ¼è¦åçæ¹æ³é£ä»¥ææåè¡¨ä¸­çç¤¾ç¾¤çµæ§ï¼èæ·±åº¦å­¸ç¿æ¹æ³åå°æ³¨æ¼æ¬åè¨ç·´åè¡¨ãééå¶äºç¾æçåè¡¨ç¢çå¨ç¢çç¬¦åé å®ç¾©è¦åæèè¨ç·´è³æééå¸¸ç¸ä¼¼çåè¡¨ï¼å¨åæåè¡¨ç¢çä¸­è¡¨ç¾ä¸ä½³ãç±æ¼åè¡¨æ¯æ½è±¡çè¡¨ç¤ºï¼æºèªäººé¡æ´»åä¸­çæå°äºåï¼å æ­¤å°äººé¡äºåçé¼çæ¨¡æ¬å¯ä»¥æ´æ·±å¥å°äºè§£åè¡¨æ¼åæ©å¶ãé¨èå¤§åèªè¨æ¨¡å (LLM) å¨æ¨¡æ¬äººé¡è¡çºä¸­ç²å¾è¶ä¾è¶å¤çèªå¯ï¼æåå¼å¥äº GraphAgent-Generator (GAG)ï¼ä¸åç¨æ¼åæåè¡¨ç¢ççæ°ç©çåºæ¼æ¨¡æ¬çæ¡æ¶ãå¨æ²æ LLM çè¨ç·´æå¾®èª¿éç¨çææ³ä¸ï¼æåçæ¡æ¶ææå°è¤è£½äºå·²å»ºç«çç¶²è·¯ç§å­¸çè«ä¸­çä¸åå·¨è§çµæ§ç¹å¾µï¼åæå¨å·é«è©ä¼°ææ¨ä¸è¶è¶äºç¾æçåºç·ï¼åè¡¨æ´å±ä»»åæé«äº 31%ãééç¯é»åé¡ä»»åï¼æåé©è­äº GAG ææå°ä¿çäºçæçå¯å«æå­çåè¡¨ä¸­ç¯é»ç´æå­ç¹å¾µççå¯¦ä¸çç¶²è·¯ç¹å¾µãæ­¤å¤ï¼ééçµåå¹³è¡å éï¼GAG æ¯æ´ééå¤§è¦æ¨¡åºæ¼ LLM çä»£çæ¨¡æ¬ç¢çç¯é»å¤éè¿ 100,000 åæéç·£å¤é 1000 è¬çåè¡¨ï¼éåº¦è³å°æå 90.4%ãåå§ç¨å¼ç¢¼å¯æ¼ https://anonymous.4open.science/r/GraphAgent-2206 åå¾ã

##### **A Mixed-Language Multi-Document News Summarization Dataset and a Graphs-Based Extract-Generate Model**
2410.09773v1 by Shengxiang Gao, Fang nan, Yongbing Zhang, Yuxin Huang, Kaiwen Tan, Zhengtao Yu

Existing research on news summarization primarily focuses on single-language
single-document (SLSD), single-language multi-document (SLMD) or cross-language
single-document (CLSD). However, in real-world scenarios, news about a
international event often involves multiple documents in different languages,
i.e., mixed-language multi-document (MLMD). Therefore, summarizing MLMD news is
of great significance. However, the lack of datasets for MLMD news
summarization has constrained the development of research in this area. To fill
this gap, we construct a mixed-language multi-document news summarization
dataset (MLMD-news), which contains four different languages and 10,992 source
document cluster and target summary pairs. Additionally, we propose a
graph-based extract-generate model and benchmark various methods on the
MLMD-news dataset and publicly release our dataset and
code\footnote[1]{https://github.com/Southnf9/MLMD-news}, aiming to advance
research in summarization within MLMD scenarios.

æè¦ï¼ç¾ææ°èæè¦çç ç©¶ä¸»è¦éä¸­å¨å®èªè¨å®æä»¶ (SLSD)ãå®èªè¨å¤æä»¶ (SLMD) æè·¨èªè¨å®æä»¶ (CLSD)ãç¶èï¼å¨ç¾å¯¦ä¸ççå ´æ¯ä¸­ï¼åéäºä»¶çæ°èéå¸¸æ¶åä¸åèªè¨çå¤åæä»¶ï¼å³æ··åèªè¨å¤æä»¶ (MLMD)ãå æ­¤ï¼å° MLMD æ°èé²è¡æè¦å·æéå¤§æç¾©ãç¶èï¼ç¼ºä¹ MLMD æ°èæè¦çæ¸æééå¶äºéä¸é åçç ç©¶ç¼å±ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæ§å»ºäºä¸åæ··åèªè¨å¤æä»¶æ°èæè¦æ¸æé (MLMD-news)ï¼å¶ä¸­åå«åç¨®ä¸åçèªè¨å 10,992 åæºæä»¶ç¾¤éåç®æ¨æè¦å°ãæ­¤å¤ï¼æåæåºäºä¸ååºæ¼åçæåçææ¨¡åï¼ä¸¦å¨ MLMD-news æ¸æéä¸å°åç¨®æ¹æ³é²è¡äºåºæºæ¸¬è©¦ï¼ä¸¦å¬éç¼å¸æåçæ¸æéåä»£ç¢¼\footnote[1]{https://github.com/Southnf9/MLMD-news}ï¼æ¨å¨æ¨é² MLMD å ´æ¯ä¸­çæè¦ç ç©¶ã

##### **Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG**
2410.09699v1 by Xinxi Chen, Li Wang, Wei Wu, Qi Tang, Yiyao Liu

Hallucination is a key roadblock for applications of Large Language Models
(LLMs), particularly for enterprise applications that are sensitive to
information accuracy. To address this issue, two general approaches have been
explored: Retrieval-Augmented Generation (RAG) to supply LLMs with updated
information as context, and fine-tuning the LLMs with new information and
desired output styles. In this paper, we propose Honest AI: a novel strategy to
fine-tune "small" language models to say "I don't know" to reduce
hallucination, along with several alternative RAG approaches. The solution
ranked 1st in Task 2 for the false premise question. The alternative approaches
include using RAG with search engine and knowledge graph results, fine-tuning
base LLMs with new information and combinations of both approaches. Although
all approaches improve the performance of the LLMs, RAG alone does not
significantly improve the performance and fine-tuning is needed for better
results. Finally, the hybrid approach achieved the highest score in the CRAG
benchmark. In addition, our approach emphasizes the use of relatively small
models with fewer than 10 billion parameters, promoting resource efficiency.

æè¦ï¼å¹»è¦ºæ¯å¤§åèªè¨æ¨¡å (LLM) æç¨ç¨å¼çä¸å¤§éç¤ï¼ç¹å¥æ¯å°è³è¨æºç¢ºåº¦ææçä¼æ¥­æç¨ç¨å¼ãçºäºè§£æ±ºæ­¤åé¡ï¼å·²æ¢è¨å©ç¨®ä¸è¬æ¹æ³ï¼æª¢ç´¢æ´åçæ (RAG) ä»¥æä¾ LLM æ´æ°çè³è¨ä½çºèæ¯ï¼ä»¥åå¾®èª¿ LLM ä»¥ç²å¾æ°çè³è¨åææçè¼¸åºæ¨£å¼ãå¨æ¬æä¸­ï¼æåæåº Honest AIï¼ä¸ç¨®æ°ç©çç­ç¥ï¼å¾®èª¿ãå°åãèªè¨æ¨¡åä»¥è¡¨éãæä¸ç¥éãä»¥æ¸å°å¹»è¦ºï¼ä»¥åå¶ä»å¹¾ç¨®æ¿ä»£ç RAG æ¹æ³ãè©²è§£æ±ºæ¹æ¡å¨èååæåé¡çä»»å 2 ä¸­æåç¬¬ 1ãæ¿ä»£æ¹æ³åæ¬ä½¿ç¨ RAG æ­éæå°å¼æåç¥è­åè­çµæãå¾®èª¿åºç¤ LLM ä»¥ç²å¾æ°çè³è¨ï¼ä»¥åçµåéå©ç¨®æ¹æ³ãéç¶æææ¹æ³é½æ¹åäº LLM çæè½ï¼ä½åä½¿ç¨ RAG ç¡æ³é¡¯èæ¹åæè½ï¼éè¦å¾®èª¿æè½ç²å¾æ´å¥½ççµæãæå¾ï¼æ··åæ¹æ³å¨ CRAG åºæºæ¸¬è©¦ä¸­ç²å¾æé«åãæ­¤å¤ï¼æåçåæ³å¼·èª¿ä½¿ç¨åæ¸å°æ¼ 100 åçå°åæ¨¡åï¼ä»¥ä¿é²è³æºæçã

##### **LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning**
2410.09541v1 by Jiachun Li, Pengfei Cao, Chenhao Wang, Zhuoran Jin, Yubo Chen, Kang Liu, Xiaojian Jiang, Jiexin Xu, Jun Zhao

Large language models (LLMs) sometimes demonstrate poor performance on
knowledge-intensive tasks, commonsense reasoning is one of them. Researchers
typically address these issues by retrieving related knowledge from knowledge
graphs or employing self-enhancement methods to elicit knowledge in LLMs.
However, noisy knowledge and invalid reasoning issues hamper their ability to
answer questions accurately. To this end, we propose a novel method named
eliciting, filtering and integrating knowledge in large language model
(LINKED). In it, we design a reward model to filter out the noisy knowledge and
take the marginal consistent reasoning module to reduce invalid reasoning. With
our comprehensive experiments on two complex commonsense reasoning benchmarks,
our method outperforms SOTA baselines (up to 9.0% improvement of accuracy).
Besides, to measure the positive and negative impact of the injected knowledge,
we propose a new metric called effectiveness-preservation score for the
knowledge enhancement works. Finally, through extensive experiments, we conduct
an in-depth analysis and find many meaningful conclusions about LLMs in
commonsense reasoning tasks.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼ææå¨ç¥è­å¯éåä»»åä¸è¡¨ç¾ä¸ä½³ï¼å¸¸è­æ¨çå°±æ¯å¶ä¸­ä¹ä¸ãç ç©¶äººå¡éå¸¸ééå¾ç¥è­åè­ä¸­æª¢ç´¢ç¸éç¥è­ææ¡ç¨èªæå¢å¼·æ¹æ³ä¾å¼ç¼ LLM ä¸­çç¥è­ä¾è§£æ±ºéäºåé¡ãç¶èï¼åéçç¥è­åç¡æçæ¨çåé¡é»ç¤äºå®åæºç¢ºåç­åé¡çè½åãçºæ­¤ï¼æåæåºäºä¸ç¨®åçºå¤§åèªè¨æ¨¡åä¸­ç¥è­çå¼åºãéæ¿¾åæ´åï¼LINKEDï¼çæ°æ¹æ³ãå¨å¶ä¸­ï¼æåè¨­è¨äºä¸åçåµæ¨¡åä¾éæ¿¾æåéçç¥è­ï¼ä¸¦æ¡ç¨ééä¸è´æ¨çæ¨¡çµä¾æ¸å°ç¡ææ¨çãééæåå¨å©åè¤éçå¸¸è­æ¨çåºæºä¸çå¨é¢å¯¦é©ï¼æåçæ¨¡ååªæ¼ SOTA åºæºï¼æºç¢ºçæé«äº 9.0%ï¼ãæ­¤å¤ï¼çºäºè¡¡éæ³¨å¥ç¥è­çæ­£é¢åè² é¢å½±é¿ï¼æåæåºäºä¸ç¨®æ°çææ¨ï¼ç¨±çºç¥è­å¢å¼·å·¥ä½çæææ§ä¿çåæ¸ãæå¾ï¼ééå¤§éçå¯¦é©ï¼æåé²è¡äºæ·±å¥çåæï¼ä¸¦å¨å¸¸è­æ¨çä»»åä¸­ç¼ç¾äºè¨±å¤éæ¼ LLM çææç¾©ççµè«ã

##### **Text Classification using Graph Convolutional Networks: A Comprehensive Survey**
2410.09399v1 by Syed Mustafa Haider Rizvi, Ramsha Imran, Arif Mahmood

Text classification is a quintessential and practical problem in natural
language processing with applications in diverse domains such as sentiment
analysis, fake news detection, medical diagnosis, and document classification.
A sizable body of recent works exists where researchers have studied and
tackled text classification from different angles with varying degrees of
success. Graph convolution network (GCN)-based approaches have gained a lot of
traction in this domain over the last decade with many implementations
achieving state-of-the-art performance in more recent literature and thus,
warranting the need for an updated survey. This work aims to summarize and
categorize various GCN-based Text Classification approaches with regard to the
architecture and mode of supervision. It identifies their strengths and
limitations and compares their performance on various benchmark datasets. We
also discuss future research directions and the challenges that exist in this
domain.

æè¦ï¼ææ¬åé¡æ¯èªç¶èªè¨èçä¸­ä¸åç¶å¸ä¸å¯¦ç¨çåé¡ï¼å¨æç·åæãåæ°èåµæ¸¬ãé«çè¨ºæ·åæä»¶åé¡ç­é åä¸­é½ææç¨ãæè¿æå¤§éçç ç©¶æ¢è¨ææ¬åé¡ï¼ä¸¦å¾ä¸åçè§åº¦èæï¼ç²å¾äºä¸åç¨åº¦çæåãåå½¢å·ç©ç¶²è·¯ (GCN) æ¹æ³å¨éå»åå¹´ä¸­å¨éé åç²å¾äºè¨±å¤éæ³¨ï¼è¨±å¤å¯¦ä½å¨æè¿çæç»ä¸­éå°äºæåé²çæè½ï¼å æ­¤æå¿è¦é²è¡æ´æ°çèª¿æ¥ãéé å·¥ä½æ¨å¨éå°æ¶æ§åç£ç£æ¨¡å¼ï¼ç¸½çµååé¡åç¨®åºæ¼ GCN çææ¬åé¡æ¹æ³ãå®æ¾åºå®åçåªç¼ºé»ï¼ä¸¦æ¯è¼å®åå¨åç¨®åºæºè³æéä¸çæè½ãæåä¹è¨è«äºæªä¾ç ç©¶æ¹ååéåé åä¸­å­å¨çææ°ã

##### **Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation**
2410.09350v1 by Jinyoung Park, Minseok Joo, Joo-Kyung Kim, Hyunwoo J. Kim

Knowledge graph-grounded dialog generation requires retrieving a
dialog-relevant subgraph from the given knowledge base graph and integrating it
with the dialog history. Previous works typically represent the graph using an
external encoder, such as graph neural networks, and retrieve relevant triplets
based on the similarity between single-vector representations of triplets and
the dialog history. However, these external encoders fail to leverage the rich
knowledge of pretrained language models, and the retrieval process is also
suboptimal due to the information bottleneck caused by the single-vector
abstraction of the dialog history. In this work, we propose Dialog generation
with Generative Subgraph Retrieval (DialogGSR), which retrieves relevant
knowledge subgraphs by directly generating their token sequences on top of
language models. For effective generative subgraph retrieval, we introduce two
key methods: (i) structure-aware knowledge graph linearization with
self-supervised graph-specific tokens and (ii) graph-constrained decoding
utilizing graph structural proximity-based entity informativeness scores for
valid and relevant generative retrieval. DialogGSR achieves state-of-the-art
performance in knowledge graph-grounded dialog generation, as demonstrated on
OpenDialKG and KOMODIS datasets.

æè¦ï¼ç¥è­åè­å°è©±çæéè¦å¾çµ¦å®çç¥è­åº«åè­ä¸­æ·åèå°è©±ç¸éçå­åï¼ä¸¦å°å¶èå°è©±è¨éæ´åãååçç ç©¶éå¸¸ä½¿ç¨å¤é¨ç·¨ç¢¼å¨ï¼ä¾å¦åå½¢ç¥ç¶ç¶²è·¯ï¼ä¾è¡¨ç¤ºåå½¢ï¼ä¸¦æ ¹æä¸åçµçå®åéè¡¨ç¤ºèå°è©±è¨éä¹éçç¸ä¼¼æ§ä¾æ·åç¸éçä¸åçµãç¶èï¼éäºå¤é¨ç·¨ç¢¼å¨ç¡æ³å©ç¨é è¨ç·´èªè¨æ¨¡åçè±å¯ç¥è­ï¼èæ·åéç¨ä¹å å°è©±è¨éçå®åéæ½è±¡åé æçè³è¨ç¶é ¸èæ¬¡æ¼æä½³ãå¨éé å·¥ä½ä¸­ï¼æåæåºå¸¶æçæå­åæ·åçå°è©±çæï¼DialogGSRï¼ï¼å®ç´æ¥å¨èªè¨æ¨¡åä¹ä¸çæå¶æ¨è¨åºåä¾æ·åç¸éçç¥è­å­åãçºäºææå°çæå­åæ·åï¼æåå¼å¥äºå©ç¨®ééµæ¹æ³ï¼ï¼ä¸ï¼å·æèªæç£ç£åå½¢ç¹å®æ¨è¨ççµæ§æç¥ç¥è­åå½¢ç·æ§åï¼ä»¥åï¼äºï¼å©ç¨åå½¢çµæ§é°è¿åº¦çºåºç¤çå¯¦é«è³è¨æ§åæ¸é²è¡åå½¢ç´æè§£ç¢¼ï¼ä»¥é²è¡ææä¸ç¸éççææ§æ·åãDialogGSR å¨ç¥è­åè­å°è©±çæä¸­å¯¦ç¾äºæåé²çæè½ï¼å¦ OpenDialKG å KOMODIS è³æéæç¤ºã

##### **Natural Language Counterfactual Explanations for Graphs Using Large Language Models**
2410.09295v1 by Flavio Giorgi, Cesare Campagnano, Fabrizio Silvestri, Gabriele Tolomei

Explainable Artificial Intelligence (XAI) has emerged as a critical area of
research to unravel the opaque inner logic of (deep) machine learning models.
Among the various XAI techniques proposed in the literature, counterfactual
explanations stand out as one of the most promising approaches. However, these
``what-if'' explanations are frequently complex and technical, making them
difficult for non-experts to understand and, more broadly, challenging for
humans to interpret. To bridge this gap, in this work, we exploit the power of
open-source Large Language Models to generate natural language explanations
when prompted with valid counterfactual instances produced by state-of-the-art
explainers for graph-based models. Experiments across several graph datasets
and counterfactual explainers show that our approach effectively produces
accurate natural language representations of counterfactual instances, as
demonstrated by key performance metrics.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºç ç©¶é åä¸­ä¸åéè¦çé åï¼ç¨ä»¥è§£éï¼æ·±åº¦ï¼æ©å¨å­¸ç¿æ¨¡åçå§é¨éè¼¯ãå¨æç»ä¸­æåºçåç¨® XAI æè¡ä¸­ï¼åäºå¯¦è§£éè¢«èªçºæ¯ææåéçæ¹æ³ä¹ä¸ãç¶èï¼éäºãåè¨­æ§ãè§£ééå¸¸è¤éä¸æè¡æ§ï¼éä½¿å¾éå°å®¶é£ä»¥çè§£ï¼æ´å»£æ³å°èªªï¼äººé¡é£ä»¥è§£éãçºäºå½åéåå·®è·ï¼å¨éé å·¥ä½ä¸­ï¼æåå©ç¨éæºå¤§åèªè¨æ¨¡åçåéï¼å¨æç¤ºç±æåé²çåå½¢æ¨¡åè§£éå¨ç¢ççææåäºå¯¦å¯¦ä¾æï¼ç¢çèªç¶èªè¨è§£éãè·¨è¶å¹¾ååå½¢è³æéååäºå¯¦è§£éå¨çå¯¦é©è¡¨æï¼æåçåæ³ææå°ç¢çåäºå¯¦å¯¦ä¾çæºç¢ºèªç¶èªè¨è¡¨ç¤ºï¼éç±ééµæè½ææ¨æè­æã

##### **ReasonPlanner: Enhancing Autonomous Planning in Dynamic Environments with Temporal Knowledge Graphs and LLMs**
2410.09252v1 by Minh Pham Dinh, Munira Syed, Michael G Yankoski, Trenton W. Ford

Planning and performing interactive tasks, such as conducting experiments to
determine the melting point of an unknown substance, is straightforward for
humans but poses significant challenges for autonomous agents. We introduce
ReasonPlanner, a novel generalist agent designed for reflective thinking,
planning, and interactive reasoning. This agent leverages LLMs to plan
hypothetical trajectories by building a World Model based on a Temporal
Knowledge Graph. The agent interacts with the environment using a natural
language actor-critic module, where the actor translates the imagined
trajectory into a sequence of actionable steps, and the critic determines if
replanning is necessary. ReasonPlanner significantly outperforms previous
state-of-the-art prompting-based methods on the ScienceWorld benchmark by more
than 1.8 times, while being more sample-efficient and interpretable. It relies
solely on frozen weights thus requiring no gradient updates. ReasonPlanner can
be deployed and utilized without specialized knowledge of Machine Learning,
making it accessible to a wide range of users.

æè¦ï¼è¦ååå·è¡äºåä»»åï¼ä¾å¦é²è¡å¯¦é©ä»¥ç¢ºå®æªç¥ç©è³ªççé»ï¼å°äººé¡ä¾èªªå¾ç°¡å®ï¼ä½å°èªä¸»ä»£çä¾èªªå»æ§æéå¤§ææ°ãæåå¼å¥äº ReasonPlannerï¼éæ¯ä¸åæ°ç©çéæä»£çï¼å°éç¨æ¼åææ§æèãè¦ååäºåæ¨çãæ­¤ä»£çå©ç¨ LLM ééå»ºç«åºæ¼æåºç¥è­åè¡¨ç World Model ä¾è¦ååè¨­æ§è»è·¡ãä»£çä½¿ç¨èªç¶èªè¨çåä½-è©è«æ¨¡çµèç°å¢äºåï¼å¶ä¸­åä½å°æ³åçè»è·¡è½æçºä¸ç³»åå¯æä½çæ­¥é©ï¼èè©è«åç¢ºå®æ¯å¦éè¦éæ°è¦åãReasonPlanner å¨ ScienceWorld åºæºä¸å¤§å¹åªæ¼ååçæåé²æç¤ºå¼æ¹æ³ï¼åªæ¼ 1.8 åï¼åææ´å·æ¨£æ¬æçåå¯è§£éæ§ãå®åä¾è³´åçµæ¬éï¼å æ­¤ä¸éè¦æ¢¯åº¦æ´æ°ãReasonPlanner å¯ä»¥é¨ç½²åä½¿ç¨ï¼èç¡éæ©å¨å­¸ç¿çå°æ¥­ç¥è­ï¼è®å»£æ³çä½¿ç¨èé½è½ä½¿ç¨ã

##### **Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective**
2410.08985v2 by Bo Ni, Yu Wang, Lu Cheng, Erik Blasch, Tyler Derr

Recently, Knowledge Graphs (KGs) have been successfully coupled with Large
Language Models (LLMs) to mitigate their hallucinations and enhance their
reasoning capability, such as in KG-based retrieval-augmented frameworks.
However, current KG-LLM frameworks lack rigorous uncertainty estimation,
limiting their reliable deployment in high-stakes applications. Directly
incorporating uncertainty quantification into KG-LLM frameworks presents
challenges due to their complex architectures and the intricate interactions
between the knowledge graph and language model components. To address this gap,
we propose a new trustworthy KG-LLM framework, Uncertainty Aware
Knowledge-Graph Reasoning (UAG), which incorporates uncertainty quantification
into the KG-LLM framework. We design an uncertainty-aware multi-step reasoning
framework that leverages conformal prediction to provide a theoretical
guarantee on the prediction set. To manage the error rate of the multi-step
process, we additionally introduce an error rate control module to adjust the
error rate within the individual components. Extensive experiments show that
our proposed UAG can achieve any pre-defined coverage rate while reducing the
prediction set/interval size by 40% on average over the baselines.

æè¦ï¼è¿æ¥ï¼ç¥è¯å¾è°± (KG) å·²æåä¸å¤§åè¯­è¨æ¨¡å (LLM) ç»åï¼ä»¥åè½»å¶å¹»è§å¹¶å¢å¼ºå¶æ¨çè½åï¼ä¾å¦åºäº KG çæ£ç´¢å¢å¼ºæ¡æ¶ã
ç¶èï¼å½åç KG-LLM æ¡æ¶ç¼ºä¹ä¸¥æ ¼çä¸ç¡®å®æ§ä¼°è®¡ï¼éå¶äºå®ä»¬å¨é«é£é©åºç¨ç¨åºä¸­çå¯é é¨ç½²ãç±äºå¶å¤æçæ¶æä»¥åç¥è¯å¾è°±åè¯­è¨æ¨¡åç»ä»¶ä¹é´çå¤æäº¤äºï¼ç´æ¥å°ä¸ç¡®å®æ§éåçº³å¥ KG-LLM æ¡æ¶æåºäºææãä¸ºäºè§£å³è¿ä¸å·®è·ï¼æä»¬æåºäºä¸ä¸ªæ°çå¯ä¿¡ KG-LLM æ¡æ¶ï¼å³ä¸ç¡®å®æ§æç¥ç¥è¯å¾è°±æ¨ç (UAG)ï¼å®å°ä¸ç¡®å®æ§éåçº³å¥äº KG-LLM æ¡æ¶ãæä»¬è®¾è®¡äºä¸ä¸ªä¸ç¡®å®æ§æç¥å¤æ­¥éª¤æ¨çæ¡æ¶ï¼å©ç¨ä¿å½¢é¢æµä¸ºé¢æµéæä¾çè®ºä¿è¯ãä¸ºäºç®¡çå¤æ­¥éª¤è¿ç¨ä¸­çéè¯¯çï¼æä»¬å¦å¤å¼å¥äºä¸ä¸ªéè¯¯çæ§å¶æ¨¡åæ¥è°æ´åä¸ªç»ä»¶ä¸­çéè¯¯çãå¤§éå®éªè¡¨æï¼æä»¬æåºç UAG å¯ä»¥è¾¾å°ä»»ä½é¢å®ä¹çè¦ççï¼åæ¶å°é¢æµé/åºé´å¤§å°å¹³ååå° 40%ï¼è¶è¿åºçº¿ã

##### **When Graph meets Multimodal: Benchmarking on Multimodal Attributed Graphs Learning**
2410.09132v1 by Hao Yan, Chaozhuo Li, Zhigang Yu, Jun Yin, Ruochen Liu, Peiyan Zhang, Weihao Han, Mingzheng Li, Zhengxin Zeng, Hao Sun, Weiwei Deng, Feng Sun, Qi Zhang, Senzhang Wang

Multimodal attributed graphs (MAGs) are prevalent in various real-world
scenarios and generally contain two kinds of knowledge: (a) Attribute knowledge
is mainly supported by the attributes of different modalities contained in
nodes (entities) themselves, such as texts and images. (b) Topology knowledge,
on the other hand, is provided by the complex interactions posed between nodes.
The cornerstone of MAG representation learning lies in the seamless integration
of multimodal attributes and topology. Recent advancements in Pre-trained
Language/Vision models (PLMs/PVMs) and Graph neural networks (GNNs) have
facilitated effective learning on MAGs, garnering increased research interest.
However, the absence of meaningful benchmark datasets and standardized
evaluation procedures for MAG representation learning has impeded progress in
this field. In this paper, we propose Multimodal Attribute Graph Benchmark
(MAGB)}, a comprehensive and diverse collection of challenging benchmark
datasets for MAGs. The MAGB datasets are notably large in scale and encompass a
wide range of domains, spanning from e-commerce networks to social networks. In
addition to the brand-new datasets, we conduct extensive benchmark experiments
over MAGB with various learning paradigms, ranging from GNN-based and PLM-based
methods, to explore the necessity and feasibility of integrating multimodal
attributes and graph topology. In a nutshell, we provide an overview of the MAG
datasets, standardized evaluation procedures, and present baseline experiments.
The entire MAGB project is publicly accessible at
https://github.com/sktsherlock/ATG.

æè¦ï¼<paragraph>å¤æ¨¡æå±¬æ§å (MAG) å¨åç¨®çå¯¦ä¸ççå ´æ¯ä¸­å¾å¸¸è¦ï¼éå¸¸åå«å©ç¨®é¡åçç¥è­ï¼(a) å±¬æ§ç¥è­ä¸»è¦ç±ç¯é»ï¼å¯¦é«ï¼æ¬èº«æåå«çä¸åæ¨¡æçå±¬æ§æä¾æ¯æ´ï¼ä¾å¦æå­åååã(b) å¦ä¸æ¹é¢ï¼ææ²ç¥è­åæ¯ç±ç¯é»ä¹éæåºçè¤éäºåæä¾ãMAG è¡¨ç¤ºå¼å­¸ç¿çåºç³å¨æ¼å¤æ¨¡æå±¬æ§åææ²çç¡ç¸«æ´åãé è¨ç·´èªè¨/è¦è¦ºæ¨¡å (PLM/PVM) ååå½¢ç¥ç¶ç¶²è·¯ (GNN) çææ°é²å±ä¿é²äºå° MAG çææå­¸ç¿ï¼å¼èµ·äºè¶ä¾è¶å¤çç ç©¶èè¶£ãç¶èï¼ç¼ºä¹ææç¾©çåºæºè³æéåæ¨æºåç MAG è¡¨ç¤ºå¼å­¸ç¿è©ä¼°ç¨åºé»ç¤äºè©²é åçé²å±ãå¨æ¬æä¸­ï¼æåæåºäºå¤æ¨¡æå±¬æ§ååºæº (MAGB)ï¼éæ¯éå° MAG çå¨é¢ä¸å¤æ¨£åçææ°æ§åºæºè³æééåãMAGB è³æéçè¦æ¨¡é¡¯èé¾å¤§ï¼æ¶µèäºå¾é»å­ååç¶²è·¯å°ç¤¾äº¤ç¶²è·¯çå»£æ³é åãé¤äºå¨æ°çè³æéå¤ï¼æåéä½¿ç¨åç¨®å­¸ç¿ç¯ä¾å° MAGB é²è¡äºå»£æ³çåºæºå¯¦é©ï¼å¾åºæ¼ GNN ååºæ¼ PLM çæ¹æ³ï¼ä»¥æ¢ç´¢æ´åå¤æ¨¡æå±¬æ§ååå½¢ææ²çå¿è¦æ§åå¯è¡æ§ãç°¡èè¨ä¹ï¼æåæä¾äº MAG è³æéãæ¨æºåè©ä¼°ç¨åºçæ¦è¿°ï¼ä¸¦æåºäºåºæºå¯¦é©ãæ´å MAGB å°æ¡å¯å¨ https://github.com/sktsherlock/ATG å¬éåå¾ã</paragraph>

##### **GIVE: Structured Reasoning with Knowledge Graph Inspired Veracity Extrapolation**
2410.08475v1 by Jiashu He, Mingyu Derek Ma, Jinxuan Fan, Dan Roth, Wei Wang, Alejandro Ribeiro

Existing retrieval-based reasoning approaches for large language models
(LLMs) heavily rely on the density and quality of the non-parametric knowledge
source to provide domain knowledge and explicit reasoning chain. However,
inclusive knowledge sources are expensive and sometimes infeasible to build for
scientific or corner domains. To tackle the challenges, we introduce Graph
Inspired Veracity Extrapolation (GIVE), a novel reasoning framework that
integrates the parametric and non-parametric memories to enhance both knowledge
retrieval and faithful reasoning processes on very sparse knowledge graphs. By
leveraging the external structured knowledge to inspire LLM to model the
interconnections among relevant concepts, our method facilitates a more logical
and step-wise reasoning approach akin to experts' problem-solving, rather than
gold answer retrieval. Specifically, the framework prompts LLMs to decompose
the query into crucial concepts and attributes, construct entity groups with
relevant entities, and build an augmented reasoning chain by probing potential
relationships among node pairs across these entity groups. Our method
incorporates both factual and extrapolated linkages to enable comprehensive
understanding and response generation. Extensive experiments on
reasoning-intense benchmarks on biomedical and commonsense QA demonstrate the
effectiveness of our proposed method. Specifically, GIVE enables GPT3.5-turbo
to outperform advanced models like GPT4 without any additional training cost,
thereby underscoring the efficacy of integrating structured information and
internal reasoning ability of LLMs for tackling specialized tasks with limited
external resources.

æè¦ï¼ç¾æçåºæ¼æª¢ç´¢çæ¨çæ¹æ³å°æ¼å¤§åèªè¨æ¨¡å (LLM) å´éä¾è³´éåæ¸ç¥è­ä¾æºçå¯åº¦ååè³ªï¼ä»¥æä¾é åç¥è­åæç¢ºçæ¨çéãç¶èï¼åå®¹æ§çç¥è­ä¾æºå¾æè²´ï¼ææå°æ¼ç§å­¸æè§è½é åä¾èªªï¼å»ºç«èµ·ä¾ä¹ä¸å¯è¡ãçºäºæå°éäºææ°ï¼æåå¼å¥äºåå½¢åç¼çå¯¦æ¨æ· (GIVE)ï¼éæ¯ä¸åæ°ç©çæ¨çæ¶æ§ï¼å®æ´åäºåæ¸åéåæ¸è¨æ¶é«ï¼ä»¥å¢å¼·å¨éå¸¸ç¨ççç¥è­åè­ä¸é²è¡ç¥è­æª¢ç´¢åå¿ å¯¦æ¨çéç¨ãééå©ç¨å¤é¨çµæ§åç¥è­ä¾æ¿åµ LLM æ¨¡æ¬ç¸éæ¦å¿µä¹éçç¸äºéè¯ï¼æåçæè¡ä¿é²äºä¸ç¨®æ´åä¹éè¼¯ä¸å¾ªåºæ¼¸é²çæ¨çæ¹æ³ï¼é¡ä¼¼æ¼å°å®¶çåé¡è§£æ±ºï¼èä¸æ¯é»éç­æ¡æª¢ç´¢ãå·é«ä¾èªªï¼è©²æ¶æ§æç¤º LLM å°æ¥è©¢åè§£çºééµæ¦å¿µåå±¬æ§ï¼ä½¿ç¨ç¸éå¯¦é«å»ºæ§å¯¦é«ç¾¤çµï¼ä¸¦ééæ¢æ¥éäºå¯¦é«ç¾¤çµä¸­ç¯é»å°ä¹éçæ½å¨éä¿ä¾å»ºç«å¢å¼·çæ¨çéãæåçæè¡çµåäºäºå¯¦åå¤æ¨éè¯ï¼ä»¥å¯¦ç¾å¨é¢ççè§£ååæç¢çãå¨çç©é«å­¸åå¸¸è­åç­ä¸å°æ¨çå¯éåºæºé²è¡çå»£æ³å¯¦é©è­æäºæåæåºçæ¹æ³çæææ§ãå·é«ä¾èªªï¼GIVE ä½¿ GPT3.5-turbo è½å¤ å¨æ²æä»»ä½é¡å¤è¨ç·´ææ¬çææ³ä¸åªæ¼ GPT4 ç­é²éæ¨¡åï¼å¾èå¼·èª¿äºæ´åçµæ§åè³è¨å LLM å§é¨æ¨çè½åå°æ¼èçå·ææéå¤é¨è³æºçå°æ¥­ä»»åçæè½ã

##### **Logic Error Localization in Student Programming Assignments Using Pseudocode and Graph Neural Networks**
2410.21282v1 by Zhenyu Xu, Kun Zhang, Victor S. Sheng

Pseudocode is extensively used in introductory programming courses to
instruct computer science students in algorithm design, utilizing natural
language to define algorithmic behaviors. This learning approach enables
students to convert pseudocode into source code and execute it to verify their
algorithms' correctness. This process typically introduces two types of errors:
syntax errors and logic errors. Syntax errors are often accompanied by compiler
feedback, which helps students identify incorrect lines. In contrast, logic
errors are more challenging because they do not trigger compiler errors and
lack immediate diagnostic feedback, making them harder to detect and correct.
To address this challenge, we developed a system designed to localize logic
errors within student programming assignments at the line level. Our approach
utilizes pseudocode as a scaffold to build a code-pseudocode graph, connecting
symbols from the source code to their pseudocode counterparts. We then employ a
graph neural network to both localize and suggest corrections for logic errors.
Additionally, we have devised a method to efficiently gather logic-error-prone
programs during the syntax error correction process and compile these into a
dataset that includes single and multiple line logic errors, complete with
indices of the erroneous lines. Our experimental results are promising,
demonstrating a localization accuracy of 99.2% for logic errors within the
top-10 suspected lines, highlighting the effectiveness of our approach in
enhancing students' coding proficiency and error correction skills.

æè¦ï¼å½ä»£ç¢¼å»£æ³ç¨æ¼å¥éç¨å¼è¨­è¨èª²ç¨ä¸­ï¼ä»¥èªç¶èªè¨å®ç¾©æ¼ç®æ³è¡çºï¼æå°é»è¦ç§å­¸å­¸çé²è¡æ¼ç®æ³è¨­è¨ãéç¨®å­¸ç¿æ¹æ³ä½¿å­¸çè½å¤ å°å½ä»£ç¢¼è½æçºåå§ç¢¼ä¸¦å·è¡å®ï¼ä»¥é©è­å¶æ¼ç®æ³çæ­£ç¢ºæ§ãæ­¤éç¨éå¸¸æç¢çå©ç¨®é¡åçé¯èª¤ï¼èªæ³é¯èª¤åéè¼¯é¯èª¤ãèªæ³é¯èª¤éå¸¸æä¼´é¨èç·¨è­¯å¨åé¥ï¼éæå©æ¼å­¸çè­å¥ä¸æ­£ç¢ºçè¡ãç¸æ¯ä¹ä¸ï¼éè¼¯é¯èª¤æ´å·ææ°æ§ï¼å çºå®åä¸æè§¸ç¼ç·¨è­¯å¨é¯èª¤ï¼ä¸¦ä¸ç¼ºä¹ç«å³çè¨ºæ·åé¥ï¼éä½¿å¾å®åæ´é£ä»¥æª¢æ¸¬åæ´æ­£ãçºäºæå°éä¸ææ°ï¼æåéç¼äºä¸åç³»çµ±ï¼æ¨å¨å°éè¼¯é¯èª¤å®ä½å¨å­¸çç¨å¼è¨­è¨ä½æ¥­ä¸­çè¡ç´ãæåçåæ³å©ç¨å½ä»£ç¢¼ä½çºå»ºç«ç¨å¼ç¢¼å½ä»£ç¢¼åçæ¯æ¶ï¼å°åå§ç¢¼ä¸­çç¬¦èé£æ¥å°å®åçå½ä»£ç¢¼å°æé ãç¶å¾ï¼æåæ¡ç¨åç¥ç¶ç¶²è·¯ä¾å®ä½éè¼¯é¯èª¤ä¸¦å»ºè­°æ´æ­£æ¹æ³ãæ­¤å¤ï¼æåéè¨­è¨äºä¸ç¨®æ¹æ³ï¼å¯ä»¥å¨èªæ³é¯èª¤æ´æ­£éç¨ä¸­ææå°æ¶éå®¹æç¼çéè¼¯é¯èª¤çç¨å¼ï¼ä¸¦å°éäºç¨å¼ç·¨è­¯æä¸åè³æéï¼å¶ä¸­åæ¬å®è¡åå¤è¡éè¼¯é¯èª¤ï¼ä»¥åé¯èª¤è¡çç´¢å¼ãæåçå¯¦é©çµæå¾æå¸æï¼è­æäºå¨æåå 10 çå¯çè¡ä¸­éè¼¯é¯èª¤çå®ä½æºç¢ºåº¦çº 99.2%ï¼çªé¡¯äºæåçæ¹æ³å¨æé«å­¸ççç·¨ç¢¼è½ååé¯èª¤æ´æ­£æè½æ¹é¢çæææ§ã

##### **Privately Learning from Graphs with Applications in Fine-tuning Large Language Models**
2410.08299v1 by Haoteng Yin, Rongzhe Wei, Eli Chien, Pan Li

Graphs offer unique insights into relationships and interactions between
entities, complementing data modalities like text, images, and videos. By
incorporating relational information from graph data, AI models can extend
their capabilities beyond traditional tasks. However, relational data in
sensitive domains such as finance and healthcare often contain private
information, making privacy preservation crucial. Existing privacy-preserving
methods, such as DP-SGD, which rely on gradient decoupling assumptions, are not
well-suited for relational learning due to the inherent dependencies between
coupled training samples. To address this challenge, we propose a
privacy-preserving relational learning pipeline that decouples dependencies in
sampled relations during training, ensuring differential privacy through a
tailored application of DP-SGD. We apply this method to fine-tune large
language models (LLMs) on sensitive graph data, and tackle the associated
computational complexities. Our approach is evaluated on LLMs of varying sizes
(e.g., BERT, Llama2) using real-world relational data from four text-attributed
graphs. The results demonstrate significant improvements in relational learning
tasks, all while maintaining robust privacy guarantees during training.
Additionally, we explore the trade-offs between privacy, utility, and
computational efficiency, offering insights into the practical deployment of
our approach. Code is available at https://github.com/Graph-COM/PvGaLM.

æè¦ï¼åè¡¨æä¾éæ¼å¯¦é«ä¹ééä¿åäºåçç¨ç¹è¦è§£ï¼è£åäºææ¬ãå½±ååå½±çç­è³ææ¨¡å¼ãééç´å¥ä¾èªåè¡¨è³æçéä¿è³è¨ï¼AI æ¨¡åå¯ä»¥å°å¶åè½å»¶ä¼¸å°å³çµ±ä»»åä¹å¤ãç¶èï¼ææé åï¼ä¾å¦éèåé«çä¿å¥ï¼ä¸­çéä¿è³æéå¸¸åå«ç§äººè³è¨ï¼å æ­¤é±ç§ä¿è­·è³ééè¦ãç¾æçé±ç§ä¿è­·æ¹æ³ï¼ä¾å¦ DP-SGDï¼ï¼ä¾è³´æ¼æ¢¯åº¦è§£è¦åè¨­ï¼ç±æ¼è¦åè¨ç·´æ¨£æ¬ä¹éçå§å¨ä¾è³´æ§ï¼ä¸¦ä¸é©åéä¿å­¸ç¿ãçºäºæå°éåææ°ï¼æåæåºä¸åé±ç§ä¿è­·éä¿å­¸ç¿ç®¡éï¼å¨è¨ç·´æéè§£è¦åæ¨£éä¿ä¸­çä¾è³´æ§ï¼ééå®¢è£½åæç¨ DP-SGD ä¾ç¢ºä¿å·®ç°é±ç§ãæåå°æ­¤æ¹æ³æç¨æ¼ææåè¡¨è³æä¸å¾®èª¿å¤§åèªè¨æ¨¡å (LLM)ï¼ä¸¦è§£æ±ºç¸éçè¨ç®è¤éæ§ãæåçæ¹æ³å¨ä¸åå¤§å°ç LLMï¼ä¾å¦ BERTãLlama2ï¼ä¸é²è¡è©ä¼°ï¼ä½¿ç¨ä¾èªååæå­å±¬æ§åè¡¨ççå¯¦ä¸çéä¿è³æãçµæè­æéä¿å­¸ç¿ä»»åæé¡¯èçé²æ­¥ï¼åæå¨è¨ç·´æéç¶­æå¼·å¤§çé±ç§ä¿è­ãæ­¤å¤ï¼æåæ¢è¨é±ç§ãæç¨åè¨ç®æçä¹éçæ¬è¡¡ï¼æä¾å°æåæ¹æ³å¯¦éé¨ç½²çè¦è§£ãç¨å¼ç¢¼å¯å¨ https://github.com/Graph-COM/PvGaLM åå¾ã

