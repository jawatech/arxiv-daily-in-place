{"2409.18878": {"publish_time": "2024-09-27", "title": "Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models", "paper_summary": "Accurate identification and categorization of suicidal events can yield\nbetter suicide precautions, reducing operational burden, and improving care\nquality in high-acuity psychiatric settings. Pre-trained language models offer\npromise for identifying suicidality from unstructured clinical narratives. We\nevaluated the performance of four BERT-based models using two fine-tuning\nstrategies (multiple single-label and single multi-label) for detecting\ncoexisting suicidal events from 500 annotated psychiatric evaluation notes. The\nnotes were labeled for suicidal ideation (SI), suicide attempts (SA), exposure\nto suicide (ES), and non-suicidal self-injury (NSSI). RoBERTa outperformed\nother models using multiple single-label classification strategy (acc=0.86,\nF1=0.78). MentalBERT (acc=0.83, F1=0.74) also exceeded BioClinicalBERT\n(acc=0.82, F1=0.72) which outperformed BERT (acc=0.80, F1=0.70). RoBERTa\nfine-tuned with single multi-label classification further improved the model\nperformance (acc=0.88, F1=0.81). The findings highlight that the model\noptimization, pretraining with domain-relevant data, and the single multi-label\nclassification strategy enhance the model performance of suicide phenotyping.\nKeywords: EHR-based Phenotyping; Natural Language Processing; Secondary Use of\nEHR Data; Suicide Classification; BERT-based Model; Psychiatry; Mental Health", "paper_summary_zh": "<paragraph>\u6e96\u78ba\u8fa8\u8b58\u548c\u5206\u985e\u81ea\u6bba\u4e8b\u4ef6\uff0c\u53ef\u4ee5\u7522\u751f\u66f4\u597d\u7684\u81ea\u6bba\u9810\u9632\u63aa\u65bd\uff0c\u964d\u4f4e\u904b\u4f5c\u8ca0\u64d4\uff0c\u4e26\u63d0\u5347\u9ad8\u654f\u7cbe\u795e\u79d1\u74b0\u5883\u4e2d\u7684\u7167\u8b77\u54c1\u8cea\u3002\u9810\u5148\u8a13\u7df4\u7684\u8a9e\u8a00\u6a21\u578b\u6709\u671b\u5f9e\u975e\u7d50\u69cb\u5316\u7684\u81e8\u5e8a\u6558\u8ff0\u4e2d\u8fa8\u8b58\u51fa\u81ea\u6bba\u50be\u5411\u3002\u6211\u5011\u8a55\u4f30\u4e86\u56db\u500b BERT \u6a21\u578b\u7684\u6548\u80fd\uff0c\u4f7f\u7528\u5169\u7a2e\u5fae\u8abf\u7b56\u7565\uff08\u591a\u91cd\u55ae\u6a19\u7c64\u548c\u55ae\u4e00\u591a\u6a19\u7c64\uff09\u4f86\u5075\u6e2c 500 \u500b\u8a3b\u89e3\u7684\u7cbe\u795e\u79d1\u8a55\u4f30\u8a18\u9304\u4e2d\u4e26\u5b58\u7684\u81ea\u6bba\u4e8b\u4ef6\u3002\u9019\u4e9b\u8a18\u9304\u6a19\u8a18\u70ba\u81ea\u6bba\u610f\u5ff5\uff08SI\uff09\u3001\u81ea\u6bba\u4f01\u5716\uff08SA\uff09\u3001\u63a5\u89f8\u81ea\u6bba\uff08ES\uff09\u548c\u975e\u81ea\u6bba\u81ea\u50b7\uff08NSSI\uff09\u3002RoBERTa \u4f7f\u7528\u591a\u91cd\u55ae\u6a19\u7c64\u5206\u985e\u7b56\u7565\u8868\u73fe\u512a\u65bc\u5176\u4ed6\u6a21\u578b\uff08acc=0.86\uff0cF1=0.78\uff09\u3002MentalBERT\uff08acc=0.83\uff0cF1=0.74\uff09\u4e5f\u8d85\u904e BioClinicalBERT\uff08acc=0.82\uff0cF1=0.72\uff09\uff0c\u800c BioClinicalBERT \u5247\u512a\u65bc BERT\uff08acc=0.80\uff0cF1=0.70\uff09\u3002\u4f7f\u7528\u55ae\u4e00\u591a\u6a19\u7c64\u5206\u985e\u5fae\u8abf\u7684 RoBERTa \u9032\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u6548\u80fd\uff08acc=0.88\uff0cF1=0.81\uff09\u3002\u7814\u7a76\u7d50\u679c\u5f37\u8abf\uff0c\u6a21\u578b\u6700\u4f73\u5316\u3001\u4f7f\u7528\u8207\u9818\u57df\u76f8\u95dc\u8cc7\u6599\u9032\u884c\u9810\u8a13\u7df4\uff0c\u4ee5\u53ca\u55ae\u4e00\u591a\u6a19\u7c64\u5206\u985e\u7b56\u7565\uff0c\u53ef\u4ee5\u63d0\u5347\u81ea\u6bba\u8868\u578b\u5206\u6790\u7684\u6a21\u578b\u6548\u80fd\u3002\u95dc\u9375\u5b57\uff1a\u57fa\u65bc\u96fb\u5b50\u75c5\u6b77\u7684\u8868\u578b\u5206\u6790\uff1b\u81ea\u7136\u8a9e\u8a00\u8655\u7406\uff1b\u96fb\u5b50\u75c5\u6b77\u8cc7\u6599\u7684\u4e8c\u6b21\u4f7f\u7528\uff1b\u81ea\u6bba\u5206\u985e\uff1b\u57fa\u65bc BERT \u7684\u6a21\u578b\uff1b\u7cbe\u795e\u79d1\uff1b\u5fc3\u7406\u5065\u5eb7</paragraph>", "author": "Zehan Li et.al.", "authors": "Zehan Li, Yan Hu, Scott Lane, Salih Selek, Lokesh Shahani, Rodrigo Machado-Vieira, Jair Soares, Hua Xu, Hongfang Liu, Ming Huang", "id": "2409.18878v2", "paper_url": "http://arxiv.org/abs/2409.18878v2", "repo": "null"}}