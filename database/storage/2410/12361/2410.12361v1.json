{"2410.12361": {"publish_time": "2024-10-16", "title": "Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance", "paper_summary": "Agents powered by large language models have shown remarkable abilities in\nsolving complex tasks. However, most agent systems remain reactive, limiting\ntheir effectiveness in scenarios requiring foresight and autonomous\ndecision-making. In this paper, we tackle the challenge of developing proactive\nagents capable of anticipating and initiating tasks without explicit human\ninstructions. We propose a novel data-driven approach for this problem.\nFirstly, we collect real-world human activities to generate proactive task\npredictions. These predictions are then labeled by human annotators as either\naccepted or rejected. The labeled data is used to train a reward model that\nsimulates human judgment and serves as an automatic evaluator of the\nproactiveness of LLM agents. Building on this, we develop a comprehensive data\ngeneration pipeline to create a diverse dataset, ProactiveBench, containing\n6,790 events. Finally, we demonstrate that fine-tuning models with the proposed\nProactiveBench can significantly elicit the proactiveness of LLM agents.\nExperimental results show that our fine-tuned model achieves an F1-Score of\n66.47% in proactively offering assistance, outperforming all open-source and\nclose-source models. These results highlight the potential of our method in\ncreating more proactive and effective agent systems, paving the way for future\nadvancements in human-agent collaboration.", "paper_summary_zh": "<paragraph>\u7531\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u9a45\u52d5\u7684\u4ee3\u7406\u5df2\u5728\u89e3\u6c7a\u8907\u96dc\u4efb\u52d9\u65b9\u9762\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u5927\u591a\u6578\u4ee3\u7406\u7cfb\u7d71\u4ecd\u7136\u88ab\u52d5\uff0c\u9019\u9650\u5236\u4e86\u5b83\u5011\u5728\u9700\u8981\u9810\u898b\u6027\u548c\u81ea\u4e3b\u6c7a\u7b56\u5236\u5b9a\u5834\u666f\u4e2d\u7684\u6548\u80fd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5c07\u61c9\u5c0d\u958b\u767c\u4e3b\u52d5\u4ee3\u7406\u7684\u6311\u6230\uff0c\u9019\u4e9b\u4ee3\u7406\u80fd\u5920\u9810\u671f\u4e26\u555f\u52d5\u4efb\u52d9\uff0c\u800c\u7121\u9700\u660e\u78ba\u7684\u4eba\u985e\u6307\u4ee4\u3002\u6211\u5011\u91dd\u5c0d\u6b64\u554f\u984c\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u6578\u64da\u9a45\u52d5\u65b9\u6cd5\u3002\u9996\u5148\uff0c\u6211\u5011\u6536\u96c6\u771f\u5be6\u4e16\u754c\u7684\u4eba\u985e\u6d3b\u52d5\u4ee5\u751f\u6210\u4e3b\u52d5\u4efb\u52d9\u9810\u6e2c\u3002\u7136\u5f8c\uff0c\u9019\u4e9b\u9810\u6e2c\u7531\u4eba\u985e\u8a3b\u89e3\u8005\u6a19\u8a18\u70ba\u63a5\u53d7\u6216\u62d2\u7d55\u3002\u6a19\u8a18\u7684\u6578\u64da\u7528\u65bc\u8a13\u7df4\u4e00\u500b\u734e\u52f5\u6a21\u578b\uff0c\u8a72\u6a21\u578b\u6a21\u64ec\u4eba\u985e\u5224\u65b7\uff0c\u4e26\u4f5c\u70ba LLM \u4ee3\u7406\u4e3b\u52d5\u6027\u7684\u81ea\u52d5\u8a55\u4f30\u5668\u3002\u5728\u6b64\u57fa\u790e\u4e0a\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u5168\u9762\u7684\u6578\u64da\u751f\u6210\u7ba1\u9053\uff0c\u4ee5\u5275\u5efa\u4e00\u500b\u591a\u6a23\u5316\u7684\u6578\u64da\u96c6 ProactiveBench\uff0c\u5176\u4e2d\u5305\u542b 6,790 \u500b\u4e8b\u4ef6\u3002\u6700\u5f8c\uff0c\u6211\u5011\u8b49\u660e\u4f7f\u7528\u6240\u63d0\u51fa\u7684 ProactiveBench \u5fae\u8abf\u6a21\u578b\u53ef\u4ee5\u986f\u8457\u5f15\u767c LLM \u4ee3\u7406\u7684\u7a4d\u6975\u6027\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u5fae\u8abf\u5f8c\u7684\u6a21\u578b\u5728\u4e3b\u52d5\u63d0\u4f9b\u5354\u52a9\u65b9\u9762\u9054\u5230\u4e86 66.47% \u7684 F1 \u5206\u6578\uff0c\u512a\u65bc\u6240\u6709\u958b\u6e90\u548c\u9589\u6e90\u6a21\u578b\u3002\u9019\u4e9b\u7d50\u679c\u7a81\u51fa\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728\u5275\u9020\u66f4\u4e3b\u52d5\u548c\u6709\u6548\u7684\u4ee3\u7406\u7cfb\u7d71\u65b9\u9762\u7684\u6f5b\u529b\uff0c\u70ba\u672a\u4f86\u4eba\u6a5f\u5354\u4f5c\u7684\u9032\u6b65\u92ea\u5e73\u4e86\u9053\u8def\u3002</paragraph>", "author": "Yaxi Lu et.al.", "authors": "Yaxi Lu, Shenzhi Yang, Cheng Qian, Guirong Chen, Qinyu Luo, Yesai Wu, Huadong Wang, Xin Cong, Zhong Zhang, Yankai Lin, Weiwen Liu, Yasheng Wang, Zhiyuan Liu, Fangming Liu, Maosong Sun", "id": "2410.12361v1", "paper_url": "http://arxiv.org/abs/2410.12361v1", "repo": "null"}}