{"2407.01920": {"publish_time": "2024-07-02", "title": "To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models", "paper_summary": "Large Language Models (LLMs) trained on extensive corpora inevitably retain\nsensitive data, such as personal privacy information and copyrighted material.\nRecent advancements in knowledge unlearning involve updating LLM parameters to\nerase specific knowledge. However, current unlearning paradigms are mired in\nvague forgetting boundaries, often erasing knowledge indiscriminately. In this\nwork, we introduce KnowUnDo, a benchmark containing copyrighted content and\nuser privacy domains to evaluate if the unlearning process inadvertently erases\nessential knowledge. Our findings indicate that existing unlearning methods\noften suffer from excessive unlearning. To address this, we propose a simple\nyet effective method, MemFlex, which utilizes gradient information to precisely\ntarget and unlearn sensitive parameters. Experimental results show that MemFlex\nis superior to existing methods in both precise knowledge unlearning and\ngeneral knowledge retaining of LLMs. Code and dataset will be released at\nhttps://github.com/zjunlp/KnowUnDo.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5ee3\u6cdb\u7684\u8a9e\u6599\u5eab\u4e0a\u9032\u884c\u8a13\u7df4\uff0c\u4e0d\u53ef\u907f\u514d\u5730\u6703\u4fdd\u7559\u654f\u611f\u8cc7\u6599\uff0c\u4f8b\u5982\u500b\u4eba\u96b1\u79c1\u8cc7\u8a0a\u548c\u53d7\u7248\u6b0a\u4fdd\u8b77\u7684\u8cc7\u6599\u3002\u6700\u8fd1\u5728\u77e5\u8b58\u907a\u5fd8\u65b9\u9762\u7684\u9032\u5c55\u5305\u62ec\u66f4\u65b0 LLM \u53c3\u6578\u4ee5\u62b9\u9664\u7279\u5b9a\u77e5\u8b58\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u907a\u5fd8\u7bc4\u4f8b\u9677\u65bc\u6a21\u7cca\u7684\u907a\u5fd8\u754c\u7dda\uff0c\u5e38\u5e38\u4e0d\u52a0\u5340\u5225\u5730\u62b9\u9664\u77e5\u8b58\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86 KnowUnDo\uff0c\u4e00\u500b\u5305\u542b\u53d7\u7248\u6b0a\u4fdd\u8b77\u7684\u5167\u5bb9\u548c\u4f7f\u7528\u8005\u96b1\u79c1\u7db2\u57df\u7684\u57fa\u6e96\uff0c\u4ee5\u8a55\u4f30\u907a\u5fd8\u904e\u7a0b\u662f\u5426\u6703\u7121\u610f\u9593\u62b9\u9664\u5fc5\u8981\u7684\u77e5\u8b58\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8868\u660e\uff0c\u73fe\u6709\u7684\u907a\u5fd8\u65b9\u6cd5\u5e38\u5e38\u6703\u904e\u5ea6\u907a\u5fd8\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7c21\u55ae\u4f46\u6709\u6548\u7684\u65b9\u6cd5 MemFlex\uff0c\u5b83\u5229\u7528\u68af\u5ea6\u8cc7\u8a0a\u7cbe\u78ba\u5730\u9396\u5b9a\u4e26\u907a\u5fd8\u654f\u611f\u53c3\u6578\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0cMemFlex \u5728\u7cbe\u78ba\u7684\u77e5\u8b58\u907a\u5fd8\u548c LLM \u7684\u4e00\u822c\u77e5\u8b58\u4fdd\u7559\u65b9\u9762\u90fd\u512a\u65bc\u73fe\u6709\u65b9\u6cd5\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u96c6\u5c07\u5728 https://github.com/zjunlp/KnowUnDo \u4e0a\u767c\u5e03\u3002", "author": "Bozhong Tian et.al.", "authors": "Bozhong Tian, Xiaozhuan Liang, Siyuan Cheng, Qingbin Liu, Mengru Wang, Dianbo Sui, Xi Chen, Huajun Chen, Ningyu Zhang", "id": "2407.01920v1", "paper_url": "http://arxiv.org/abs/2407.01920v1", "repo": "https://github.com/zjunlp/knowundo"}}