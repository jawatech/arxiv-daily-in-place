{"2409.10103": {"publish_time": "2024-09-16", "title": "Self-Supervised Syllable Discovery Based on Speaker-Disentangled HuBERT", "paper_summary": "Self-supervised speech representation learning has become essential for\nextracting meaningful features from untranscribed audio. Recent advances\nhighlight the potential of deriving discrete symbols from the features\ncorrelated with linguistic units, which enables text-less training across\ndiverse tasks. In particular, sentence-level Self-Distillation of the\npretrained HuBERT (SD-HuBERT) induces syllabic structures within latent speech\nframe representations extracted from an intermediate Transformer layer. In\nSD-HuBERT, sentence-level representation is accumulated from speech frame\nfeatures through self-attention layers using a special CLS token. However, we\nobserve that the information aggregated in the CLS token correlates more with\nspeaker identity than with linguistic content. To address this, we propose a\nspeech-only self-supervised fine-tuning approach that separates syllabic units\nfrom speaker information. Our method introduces speaker perturbation as data\naugmentation and adopts a frame-level training objective to prevent the CLS\ntoken from aggregating paralinguistic information. Experimental results show\nthat our approach surpasses the current state-of-the-art method in most\nsyllable segmentation and syllabic unit quality metrics on Librispeech,\nunderscoring its effectiveness in promoting syllabic organization within\nspeech-only models.", "paper_summary_zh": "\u81ea\u6211\u76d1\u7763\u8bed\u97f3\u8868\u5f81\u5b66\u4e60\u5df2\u6210\u4e3a\u4ece\u672a\u8f6c\u5f55\u97f3\u9891\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u7279\u5f81\u7684\u5fc5\u8981\u65b9\u6cd5\u3002\u6700\u8fd1\u7684\u8fdb\u5c55\u51f8\u663e\u4e86\u4ece\u4e0e\u8bed\u8a00\u5355\u4f4d\u76f8\u5173\u7684\u7279\u5f81\u4e2d\u63a8\u5bfc\u51fa\u79bb\u6563\u7b26\u53f7\u7684\u6f5c\u529b\uff0c\u8fd9\u4f7f\u5f97\u8de8\u4e0d\u540c\u4efb\u52a1\u8fdb\u884c\u65e0\u6587\u672c\u8bad\u7ec3\u6210\u4e3a\u53ef\u80fd\u3002\u7279\u522b\u662f\uff0c\u9884\u8bad\u7ec3 HuBERT\uff08SD-HuBERT\uff09\u7684\u53e5\u5b50\u7ea7\u81ea\u84b8\u998f\u5728\u4ece\u4e2d\u95f4 Transformer \u5c42\u63d0\u53d6\u7684\u6f5c\u5728\u8bed\u97f3\u5e27\u8868\u5f81\u4e2d\u8bf1\u5bfc\u51fa\u97f3\u8282\u7ed3\u6784\u3002\u5728 SD-HuBERT \u4e2d\uff0c\u53e5\u5b50\u7ea7\u8868\u5f81\u901a\u8fc7\u4f7f\u7528\u7279\u6b8a CLS \u6807\u8bb0\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u5c42\u4ece\u8bed\u97f3\u5e27\u7279\u5f81\u4e2d\u7d2f\u79ef\u3002\u7136\u800c\uff0c\u6211\u4eec\u89c2\u5bdf\u5230 CLS \u6807\u8bb0\u4e2d\u805a\u5408\u7684\u4fe1\u606f\u4e0e\u8bf4\u8bdd\u8005\u8eab\u4efd\u7684\u76f8\u5173\u6027\u9ad8\u4e8e\u8bed\u8a00\u5185\u5bb9\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u8bed\u97f3\u81ea\u6211\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u97f3\u8282\u5355\u4f4d\u4e0e\u8bf4\u8bdd\u8005\u4fe1\u606f\u5206\u5f00\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5c06\u8bf4\u8bdd\u8005\u6270\u52a8\u4f5c\u4e3a\u6570\u636e\u589e\u5f3a\uff0c\u5e76\u91c7\u7528\u5e27\u7ea7\u8bad\u7ec3\u76ee\u6807\u6765\u9632\u6b62 CLS \u6807\u8bb0\u805a\u5408\u526f\u8bed\u8a00\u4fe1\u606f\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728 Librispeech \u4e0a\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5728\u5927\u591a\u6570\u97f3\u8282\u5206\u5272\u548c\u97f3\u8282\u5355\u4f4d\u8d28\u91cf\u6307\u6807\u4e0a\u90fd\u53d6\u5f97\u4e86\u8d85\u8d8a\uff0c\u8fd9\u7a81\u51fa\u4e86\u5176\u5728\u4ec5\u8bed\u97f3\u6a21\u578b\u4e2d\u4fc3\u8fdb\u97f3\u8282\u7ec4\u7ec7\u7684\u6709\u6548\u6027\u3002", "author": "Ryota Komatsu et.al.", "authors": "Ryota Komatsu, Takahiro Shinozaki", "id": "2409.10103v1", "paper_url": "http://arxiv.org/abs/2409.10103v1", "repo": "https://github.com/ryota-komatsu/speaker_disentangled_hubert"}}