{"2408.07482": {"publish_time": "2024-08-14", "title": "Training Overhead Ratio: A Practical Reliability Metric for Large Language Model Training Systems", "paper_summary": "Large Language Models (LLMs) are revolutionizing the AI industry with their\nsuperior capabilities. Training these models requires large-scale GPU clusters\nand significant computing time, leading to frequent failures that significantly\nincrease training costs. Despite its significance, this field lacks a metric\nfor evaluating reliability. In this work, we introduce a novel reliability\nmetric called \\emph{Training Overhead Ratio} (TOR) to evaluate the reliability\nof fault-tolerant LLM training systems. TOR is defined as the ratio of optimal\ntraining time to the observed training time of a system, serving as a practical\ntool for users to estimate the actual time required to train an LLM on a given\nsystem. Furthermore, our investigation identifies the key factor for enhancing\nreliability and present TOR equations for various types of failures encountered\nin practice.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4ee5\u5176\u5353\u8d8a\u7684\u80fd\u529b\u9769\u65b0\u4e86 AI \u7522\u696d\u3002\u8a13\u7df4\u9019\u4e9b\u6a21\u578b\u9700\u8981\u5927\u898f\u6a21\u7684 GPU \u96c6\u7fa4\u548c\u5927\u91cf\u7684\u904b\u7b97\u6642\u9593\uff0c\u5c0e\u81f4\u983b\u7e41\u7684\u6545\u969c\uff0c\u5927\u5e45\u589e\u52a0\u8a13\u7df4\u6210\u672c\u3002\u5118\u7ba1\u5176\u91cd\u8981\u6027\uff0c\u9019\u500b\u9818\u57df\u537b\u7f3a\u4e4f\u7528\u65bc\u8a55\u4f30\u53ef\u9760\u6027\u7684\u6307\u6a19\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e00\u500b\u540d\u70ba\u300c\u8a13\u7df4\u958b\u92b7\u6bd4\u300d(TOR) \u7684\u65b0\u53ef\u9760\u6027\u6307\u6a19\uff0c\u4ee5\u8a55\u4f30\u5bb9\u932f LLM \u8a13\u7df4\u7cfb\u7d71\u7684\u53ef\u9760\u6027\u3002TOR \u88ab\u5b9a\u7fa9\u70ba\u7cfb\u7d71\u7684\u6700\u4f73\u8a13\u7df4\u6642\u9593\u8207\u89c0\u6e2c\u8a13\u7df4\u6642\u9593\u7684\u6bd4\u7387\uff0c\u53ef\u4f5c\u70ba\u4f7f\u7528\u8005\u4f30\u8a08\u5728\u7d66\u5b9a\u7cfb\u7d71\u4e0a\u8a13\u7df4 LLM \u6240\u9700\u5be6\u969b\u6642\u9593\u7684\u5be6\u7528\u5de5\u5177\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u8abf\u67e5\u627e\u51fa\u589e\u5f37\u53ef\u9760\u6027\u7684\u95dc\u9375\u56e0\u7d20\uff0c\u4e26\u91dd\u5c0d\u5be6\u969b\u4e2d\u9047\u5230\u7684\u5404\u7a2e\u6545\u969c\u985e\u578b\u63d0\u51fa TOR \u65b9\u7a0b\u5f0f\u3002", "author": "Ning Lu et.al.", "authors": "Ning Lu, Qian Xie, Hao Zhang, Wenyi Fang, Yang Zheng, Jiantao Ma", "id": "2408.07482v1", "paper_url": "http://arxiv.org/abs/2408.07482v1", "repo": "null"}}