{"2406.07162": {"publish_time": "2024-06-11", "title": "EmoBox: Multilingual Multi-corpus Speech Emotion Recognition Toolkit and Benchmark", "paper_summary": "Speech emotion recognition (SER) is an important part of human-computer\ninteraction, receiving extensive attention from both industry and academia.\nHowever, the current research field of SER has long suffered from the following\nproblems: 1) There are few reasonable and universal splits of the datasets,\nmaking comparing different models and methods difficult. 2) No commonly used\nbenchmark covers numerous corpus and languages for researchers to refer to,\nmaking reproduction a burden. In this paper, we propose EmoBox, an\nout-of-the-box multilingual multi-corpus speech emotion recognition toolkit,\nalong with a benchmark for both intra-corpus and cross-corpus settings. For\nintra-corpus settings, we carefully designed the data partitioning for\ndifferent datasets. For cross-corpus settings, we employ a foundation SER\nmodel, emotion2vec, to mitigate annotation errors and obtain a test set that is\nfully balanced in speakers and emotions distributions. Based on EmoBox, we\npresent the intra-corpus SER results of 10 pre-trained speech models on 32\nemotion datasets with 14 languages, and the cross-corpus SER results on 4\ndatasets with the fully balanced test sets. To the best of our knowledge, this\nis the largest SER benchmark, across language scopes and quantity scales. We\nhope that our toolkit and benchmark can facilitate the research of SER in the\ncommunity.", "paper_summary_zh": "\u8a9e\u97f3\u60c5\u7dd2\u8fa8\u8b58\uff08SER\uff09\u662f\u4eba\u6a5f\u4e92\u52d5\u4e2d\u91cd\u8981\u7684\u4e00\u74b0\uff0c\u53d7\u5230\u7522\u696d\u754c\u8207\u5b78\u8853\u754c\u7684\u5ee3\u6cdb\u95dc\u6ce8\u3002\u7136\u800c\uff0cSER \u7684\u73fe\u6709\u7814\u7a76\u9818\u57df\u9577\u671f\u4ee5\u4f86\u4e00\u76f4\u98fd\u53d7\u4ee5\u4e0b\u554f\u984c\u6240\u82e6\uff1a1\uff09\u8cc7\u6599\u96c6\u7684\u5408\u7406\u4e14\u901a\u7528\u7684\u5207\u5206\u5f88\u5c11\uff0c\u5c0e\u81f4\u96e3\u4ee5\u6bd4\u8f03\u4e0d\u540c\u7684\u6a21\u578b\u8207\u65b9\u6cd5\u30022\uff09\u6c92\u6709\u5ee3\u6cdb\u4f7f\u7528\u7684\u57fa\u6e96\u6db5\u84cb\u591a\u7a2e\u8a9e\u6599\u5eab\u548c\u8a9e\u8a00\u4f9b\u7814\u7a76\u4eba\u54e1\u53c3\u8003\uff0c\u4f7f\u5f97\u91cd\u73fe\u6210\u70ba\u4e00\u7a2e\u8ca0\u64d4\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa EmoBox\uff0c\u9019\u662f\u4e00\u500b\u958b\u7bb1\u5373\u7528\u7684\u591a\u8a9e\u8a00\u591a\u8a9e\u6599\u5eab\u8a9e\u97f3\u60c5\u7dd2\u8fa8\u8b58\u5de5\u5177\u7d44\uff0c\u4e26\u63d0\u4f9b\u4e00\u500b\u9069\u7528\u65bc\u8a9e\u6599\u5eab\u5167\u548c\u8a9e\u6599\u5eab\u9593\u8a2d\u5b9a\u7684\u57fa\u6e96\u3002\u5c0d\u65bc\u8a9e\u6599\u5eab\u5167\u8a2d\u5b9a\uff0c\u6211\u5011\u4ed4\u7d30\u8a2d\u8a08\u4e86\u4e0d\u540c\u8cc7\u6599\u96c6\u7684\u8cc7\u6599\u5206\u5272\u3002\u5c0d\u65bc\u8a9e\u6599\u5eab\u9593\u8a2d\u5b9a\uff0c\u6211\u5011\u63a1\u7528\u57fa\u790e SER \u6a21\u578b emotion2vec \u4f86\u6e1b\u8f15\u8a3b\u89e3\u932f\u8aa4\uff0c\u4e26\u53d6\u5f97\u5728\u8aaa\u8a71\u8005\u548c\u60c5\u7dd2\u5206\u4f48\u4e0a\u5b8c\u5168\u5e73\u8861\u7684\u6e2c\u8a66\u96c6\u3002\u57fa\u65bc EmoBox\uff0c\u6211\u5011\u5448\u73fe 10 \u500b\u9810\u8a13\u7df4\u8a9e\u97f3\u6a21\u578b\u5728 32 \u500b\u60c5\u7dd2\u8cc7\u6599\u96c6\uff08\u6db5\u84cb 14 \u7a2e\u8a9e\u8a00\uff09\u4e0a\u7684\u8a9e\u6599\u5eab\u5167 SER \u7d50\u679c\uff0c\u4ee5\u53ca\u5728 4 \u500b\u5177\u6709\u5b8c\u5168\u5e73\u8861\u6e2c\u8a66\u96c6\u7684\u8cc7\u6599\u96c6\u4e0a\u7684\u8a9e\u6599\u5eab\u9593 SER \u7d50\u679c\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u662f\u6700\u5927\u7684 SER \u57fa\u6e96\uff0c\u6db5\u84cb\u8a9e\u8a00\u7bc4\u570d\u548c\u6578\u91cf\u898f\u6a21\u3002\u6211\u5011\u5e0c\u671b\u6211\u5011\u7684\u5de5\u5177\u7d44\u548c\u57fa\u6e96\u80fd\u4fc3\u9032\u793e\u7fa4\u4e2d SER \u7684\u7814\u7a76\u3002", "author": "Ziyang Ma et.al.", "authors": "Ziyang Ma, Mingjie Chen, Hezhao Zhang, Zhisheng Zheng, Wenxi Chen, Xiquan Li, Jiaxin Ye, Xie Chen, Thomas Hain", "id": "2406.07162v1", "paper_url": "http://arxiv.org/abs/2406.07162v1", "repo": "https://github.com/emo-box/emobox"}}