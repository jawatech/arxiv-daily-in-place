{"2412.04974": {"publish_time": "2024-12-06", "title": "Putting the Iterative Training of Decision Trees to the Test on a Real-World Robotic Task", "paper_summary": "In previous research, we developed methods to train decision trees (DT) as\nagents for reinforcement learning tasks, based on deep reinforcement learning\n(DRL) networks. The samples from which the DTs are built, use the environment's\nstate as features and the corresponding action as label. To solve the\nnontrivial task of selecting samples, which on one hand reflect the DRL agent's\ncapabilities of choosing the right action but on the other hand also cover\nenough state space to generalize well, we developed an algorithm to iteratively\ntrain DTs.\n  In this short paper, we apply this algorithm to a real-world implementation\nof a robotic task for the first time. Real-world tasks pose additional\nchallenges compared to simulations, such as noise and delays. The task consists\nof a physical pendulum attached to a cart, which moves on a linear track. By\nmovements to the left and to the right, the pendulum is to be swung in the\nupright position and balanced in the unstable equilibrium. Our results\ndemonstrate the applicability of the algorithm to real-world tasks by\ngenerating a DT whose performance matches the performance of the DRL agent,\nwhile consisting of fewer parameters. This research could be a starting point\nfor distilling DTs from DRL agents to obtain transparent, lightweight models\nfor real-world reinforcement learning tasks.", "paper_summary_zh": "\u5728\u5148\u524d\u7684\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u958b\u767c\u4e86\u8a13\u7df4\u6c7a\u7b56\u6a39 (DT) \u7684\u65b9\u6cd5\uff0c\u4f5c\u70ba\u57fa\u65bc\u6df1\u5ea6\u5f37\u5316\u5b78\u7fd2 (DRL) \u7db2\u8def\u7684\u5f37\u5316\u5b78\u7fd2\u4efb\u52d9\u7684\u4ee3\u7406\u3002DT \u5efa\u69cb\u7684\u7bc4\u4f8b\u4f7f\u7528\u74b0\u5883\u7684\u72c0\u614b\u4f5c\u70ba\u7279\u5fb5\uff0c\u4e26\u5c07\u5c0d\u61c9\u7684\u52d5\u4f5c\u4f5c\u70ba\u6a19\u7c64\u3002\u70ba\u4e86\u89e3\u6c7a\u9078\u64c7\u7bc4\u4f8b\u7684\u975e\u5e73\u51e1\u4efb\u52d9\uff0c\u4e00\u65b9\u9762\u53cd\u6620 DRL \u4ee3\u7406\u9078\u64c7\u6b63\u78ba\u52d5\u4f5c\u7684\u80fd\u529b\uff0c\u4f46\u53e6\u4e00\u65b9\u9762\u4e5f\u6db5\u84cb\u8db3\u5920\u7684\u72c0\u614b\u7a7a\u9593\u4ee5\u9032\u884c\u826f\u597d\u7684\u6982\u5316\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u7a2e\u53cd\u8986\u8a13\u7df4 DT \u7684\u6f14\u7b97\u6cd5\u3002\n\u5728\u9019\u7bc7\u77ed\u6587\u4e2d\uff0c\u6211\u5011\u9996\u6b21\u5c07\u6b64\u6f14\u7b97\u6cd5\u61c9\u7528\u65bc\u6a5f\u5668\u4eba\u4efb\u52d9\u7684\u5be6\u969b\u5be6\u4f5c\u3002\u8207\u6a21\u64ec\u76f8\u6bd4\uff0c\u5be6\u969b\u4efb\u52d9\u6703\u5e36\u4f86\u984d\u5916\u7684\u6311\u6230\uff0c\u4f8b\u5982\u96dc\u8a0a\u548c\u5ef6\u9072\u3002\u4efb\u52d9\u5305\u62ec\u9023\u63a5\u5230\u5c0f\u8eca\u7684\u7269\u7406\u9418\u64fa\uff0c\u5c0f\u8eca\u5728\u7dda\u6027\u8ecc\u9053\u4e0a\u79fb\u52d5\u3002\u901a\u904e\u5411\u5de6\u548c\u5411\u53f3\u79fb\u52d5\uff0c\u9418\u64fa\u5c07\u64fa\u52d5\u5230\u76f4\u7acb\u4f4d\u7f6e\u4e26\u5728\u4e0d\u7a69\u5b9a\u7684\u5e73\u8861\u72c0\u614b\u4e0b\u4fdd\u6301\u5e73\u8861\u3002\u6211\u5011\u7684\u7d50\u679c\u8b49\u660e\u4e86\u6f14\u7b97\u6cd5\u5c0d\u5be6\u969b\u4efb\u52d9\u7684\u9069\u7528\u6027\uff0c\u5b83\u6703\u7522\u751f\u4e00\u500b DT\uff0c\u5176\u6548\u80fd\u8207 DRL \u4ee3\u7406\u7684\u6548\u80fd\u76f8\u5339\u914d\uff0c\u540c\u6642\u5305\u542b\u8f03\u5c11\u7684\u53c3\u6578\u3002\u9019\u9805\u7814\u7a76\u53ef\u4ee5\u4f5c\u70ba\u5f9e DRL \u4ee3\u7406\u4e2d\u8403\u53d6 DT \u7684\u8d77\u9ede\uff0c\u4ee5\u53d6\u5f97\u900f\u660e\u3001\u8f15\u91cf\u7684\u6a21\u578b\uff0c\u7528\u65bc\u5be6\u969b\u7684\u5f37\u5316\u5b78\u7fd2\u4efb\u52d9\u3002", "author": "Raphael C. Engelhardt et.al.", "authors": "Raphael C. Engelhardt, Marcel J. Meinen, Moritz Lange, Laurenz Wiskott, Wolfgang Konen", "id": "2412.04974v1", "paper_url": "http://arxiv.org/abs/2412.04974v1", "repo": "null"}}