{"2501.05396": {"publish_time": "2025-01-09", "title": "FairCode: Evaluating Social Bias of LLMs in Code Generation", "paper_summary": "Large language models (LLMs) have demonstrated significant capability in code\ngeneration, drawing increasing attention to the evaluation of the quality and\nsafety of their outputs. However, research on bias in code generation remains\nlimited. Existing studies typically assess bias by applying malicious prompts\nor reapply tasks and dataset for discriminative models. Given that LLMs are\noften aligned with human values and that prior datasets are not fully optimized\nfor code-related tasks, there is a pressing need for benchmarks specifically\ndesigned for evaluating code models. In this study, we introduce FairCode, a\nnovel benchmark for evaluating bias in code generation. FairCode comprises two\ntasks: function implementation and test case generation, each evaluating social\nbias through diverse scenarios. Additionally, we propose a new metric,\nFairScore, to assess model performance on this benchmark. We conduct\nexperiments on widely used LLMs and provide a comprehensive analysis of the\nresults. The findings reveal that all tested LLMs exhibit bias. The code is\navailable at https://github.com/YongkDu/FairCode.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u751f\u6210\u7a0b\u5f0f\u78bc\u7684\u986f\u8457\u80fd\u529b\uff0c\u4e26\u8d8a\u4f86\u8d8a\u95dc\u6ce8\u5176\u8f38\u51fa\u7684\u54c1\u8cea\u548c\u5b89\u5168\u6027\u8a55\u4f30\u3002\u7136\u800c\uff0c\u95dc\u65bc\u7a0b\u5f0f\u78bc\u751f\u6210\u504f\u5dee\u7684\u7814\u7a76\u4ecd\u7136\u6709\u9650\u3002\u73fe\u6709\u7814\u7a76\u901a\u5e38\u900f\u904e\u5957\u7528\u60e1\u610f\u63d0\u793a\u6216\u91cd\u65b0\u5957\u7528\u4efb\u52d9\u548c\u8cc7\u6599\u96c6\u4f86\u8a55\u4f30\u504f\u5dee\uff0c\u4ee5\u9032\u884c\u5340\u8fa8\u6a21\u578b\u3002\u9451\u65bc LLM \u901a\u5e38\u8207\u4eba\u985e\u50f9\u503c\u89c0\u4e00\u81f4\uff0c\u4e14\u5148\u524d\u7684\u8cc7\u6599\u96c6\u4e26\u672a\u91dd\u5c0d\u7a0b\u5f0f\u78bc\u76f8\u95dc\u4efb\u52d9\u9032\u884c\u5b8c\u5168\u6700\u4f73\u5316\uff0c\u56e0\u6b64\u8feb\u5207\u9700\u8981\u5c08\u9580\u7528\u65bc\u8a55\u4f30\u7a0b\u5f0f\u78bc\u6a21\u578b\u7684\u57fa\u6e96\u3002\u5728\u6b64\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 FairCode\uff0c\u9019\u662f\u4e00\u500b\u7528\u65bc\u8a55\u4f30\u7a0b\u5f0f\u78bc\u751f\u6210\u504f\u5dee\u7684\u65b0\u57fa\u6e96\u3002FairCode \u5305\u542b\u5169\u500b\u4efb\u52d9\uff1a\u51fd\u5f0f\u5be6\u4f5c\u548c\u6e2c\u8a66\u6848\u4f8b\u751f\u6210\uff0c\u6bcf\u500b\u4efb\u52d9\u90fd\u900f\u904e\u4e0d\u540c\u7684\u5834\u666f\u8a55\u4f30\u793e\u6703\u504f\u5dee\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684\u6307\u6a19 FairScore\uff0c\u7528\u65bc\u8a55\u4f30\u6a21\u578b\u5728\u6b64\u57fa\u6e96\u4e0a\u7684\u6548\u80fd\u3002\u6211\u5011\u5c0d\u5ee3\u6cdb\u4f7f\u7528\u7684 LLM \u9032\u884c\u5be6\u9a57\uff0c\u4e26\u5c0d\u7d50\u679c\u9032\u884c\u5168\u9762\u5206\u6790\u3002\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u6240\u6709\u53d7\u6e2c\u7684 LLM \u90fd\u8868\u73fe\u51fa\u504f\u5dee\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/YongkDu/FairCode \u53d6\u5f97\u3002", "author": "Yongkang Du et.al.", "authors": "Yongkang Du, Jen-tse Huang, Jieyu Zhao, Lu Lin", "id": "2501.05396v1", "paper_url": "http://arxiv.org/abs/2501.05396v1", "repo": "null"}}