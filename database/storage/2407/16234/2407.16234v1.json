{"2407.16234": {"publish_time": "2024-07-23", "title": "A Multi-view Mask Contrastive Learning Graph Convolutional Neural Network for Age Estimation", "paper_summary": "The age estimation task aims to use facial features to predict the age of\npeople and is widely used in public security, marketing, identification, and\nother fields. However, the features are mainly concentrated in facial\nkeypoints, and existing CNN and Transformer-based methods have inflexibility\nand redundancy for modeling complex irregular structures. Therefore, this paper\nproposes a Multi-view Mask Contrastive Learning Graph Convolutional Neural\nNetwork (MMCL-GCN) for age estimation. Specifically, the overall structure of\nthe MMCL-GCN network contains a feature extraction stage and an age estimation\nstage. In the feature extraction stage, we introduce a graph structure to\nconstruct face images as input and then design a Multi-view Mask Contrastive\nLearning (MMCL) mechanism to learn complex structural and semantic information\nabout face images. The learning mechanism employs an asymmetric siamese network\narchitecture, which utilizes an online encoder-decoder structure to reconstruct\nthe missing information from the original graph and utilizes the target encoder\nto learn latent representations for contrastive learning. Furthermore, to\npromote the two learning mechanisms better compatible and complementary, we\nadopt two augmentation strategies and optimize the joint losses. In the age\nestimation stage, we design a Multi-layer Extreme Learning Machine (ML-IELM)\nwith identity mapping to fully use the features extracted by the online\nencoder. Then, a classifier and a regressor were constructed based on ML-IELM,\nwhich were used to identify the age grouping interval and accurately estimate\nthe final age. Extensive experiments show that MMCL-GCN can effectively reduce\nthe error of age estimation on benchmark datasets such as Adience, MORPH-II,\nand LAP-2016.", "paper_summary_zh": "\u5e74\u9f61\u4f30\u8a08\u4efb\u52d9\u65e8\u5728\u4f7f\u7528\u9762\u90e8\u7279\u5fb5\u4f86\u9810\u6e2c\u4eba\u5011\u7684\u5e74\u9f61\uff0c\u4e26\u5ee3\u6cdb\u7528\u65bc\u516c\u5171\u5b89\u5168\u3001\u884c\u92b7\u3001\u8b58\u5225\u548c\u5176\u4ed6\u9818\u57df\u3002\u7136\u800c\uff0c\u9019\u4e9b\u7279\u5fb5\u4e3b\u8981\u96c6\u4e2d\u5728\u9762\u90e8\u95dc\u9375\u9ede\uff0c\u73fe\u6709\u7684 CNN \u548c Transformer \u70ba\u57fa\u790e\u7684\u65b9\u6cd5\u5c0d\u65bc\u5efa\u6a21\u8907\u96dc\u7684\u4e0d\u898f\u5247\u7d50\u69cb\u7f3a\u4e4f\u9748\u6d3b\u6027\u4e14\u5b58\u5728\u5197\u9918\u3002\u56e0\u6b64\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u500b\u591a\u8996\u5716\u906e\u7f69\u5c0d\u6bd4\u5b78\u7fd2\u5716\u5377\u7a4d\u795e\u7d93\u7db2\u8def (MMCL-GCN) \u4f86\u9032\u884c\u5e74\u9f61\u4f30\u8a08\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cMMCL-GCN \u7db2\u8def\u7684\u6574\u9ad4\u7d50\u69cb\u5305\u542b\u4e00\u500b\u7279\u5fb5\u63d0\u53d6\u968e\u6bb5\u548c\u4e00\u500b\u5e74\u9f61\u4f30\u8a08\u968e\u6bb5\u3002\u5728\u7279\u5fb5\u63d0\u53d6\u968e\u6bb5\uff0c\u6211\u5011\u5f15\u5165\u4e00\u500b\u5716\u5f62\u7d50\u69cb\u5c07\u4eba\u81c9\u5716\u50cf\u4f5c\u70ba\u8f38\u5165\uff0c\u7136\u5f8c\u8a2d\u8a08\u4e00\u500b\u591a\u8996\u5716\u906e\u7f69\u5c0d\u6bd4\u5b78\u7fd2 (MMCL) \u6a5f\u5236\u4f86\u5b78\u7fd2\u4eba\u81c9\u5716\u50cf\u7684\u8907\u96dc\u7d50\u69cb\u548c\u8a9e\u7fa9\u4fe1\u606f\u3002\u5b78\u7fd2\u6a5f\u5236\u63a1\u7528\u975e\u5c0d\u7a31\u9023\u9ad4\u7db2\u8def\u67b6\u69cb\uff0c\u5b83\u5229\u7528\u5728\u7dda\u7de8\u78bc\u5668-\u89e3\u78bc\u5668\u7d50\u69cb\u4f86\u91cd\u5efa\u539f\u59cb\u5716\u5f62\u4e2d\u7f3a\u5931\u7684\u4fe1\u606f\uff0c\u4e26\u5229\u7528\u76ee\u6a19\u7de8\u78bc\u5668\u4f86\u5b78\u7fd2\u5c0d\u6bd4\u5b78\u7fd2\u7684\u6f5b\u5728\u8868\u793a\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u4fc3\u9032\u9019\u5169\u7a2e\u5b78\u7fd2\u6a5f\u5236\u66f4\u597d\u5730\u76f8\u5bb9\u548c\u4e92\u88dc\uff0c\u6211\u5011\u63a1\u7528\u5169\u7a2e\u64f4\u5145\u7b56\u7565\u4e26\u6700\u4f73\u5316\u806f\u5408\u640d\u5931\u3002\u5728\u5e74\u9f61\u4f30\u8a08\u968e\u6bb5\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u5e36\u6709\u6046\u7b49\u6620\u5c04\u7684\u591a\u5c64\u6975\u9650\u5b78\u7fd2\u6a5f (ML-IELM) \u4f86\u5145\u5206\u5229\u7528\u5728\u7dda\u7de8\u78bc\u5668\u63d0\u53d6\u7684\u7279\u5fb5\u3002\u7136\u5f8c\uff0c\u57fa\u65bc ML-IELM \u69cb\u5efa\u4e00\u500b\u5206\u985e\u5668\u548c\u4e00\u500b\u56de\u6b78\u5668\uff0c\u7528\u65bc\u8b58\u5225\u5e74\u9f61\u7d44\u9593\u9694\u4e26\u6e96\u78ba\u4f30\u8a08\u6700\u7d42\u5e74\u9f61\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8868\u660e\uff0cMMCL-GCN \u53ef\u4ee5\u6709\u6548\u964d\u4f4e Adience\u3001MORPH-II \u548c LAP-2016 \u7b49\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u7684\u5e74\u9f61\u4f30\u8a08\u8aa4\u5dee\u3002", "author": "Yiping Zhang et.al.", "authors": "Yiping Zhang, Yuntao Shou, Tao Meng, Wei Ai, Keqin Li", "id": "2407.16234v1", "paper_url": "http://arxiv.org/abs/2407.16234v1", "repo": "null"}}