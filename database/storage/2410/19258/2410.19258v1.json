{"2410.19258": {"publish_time": "2024-10-25", "title": "Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning", "paper_summary": "Key-Value (KV) caching is a common technique to enhance the computational\nefficiency of Large Language Models (LLMs), but its memory overhead grows\nrapidly with input length. Prior work has shown that not all tokens are equally\nimportant for text generation, proposing layer-level KV cache compression to\nselectively retain key information. Recognizing the distinct roles of attention\nheads in generation, we propose HeadKV, a head-level KV cache compression\nmethod, and HeadKV-R2, which leverages a novel contextual reasoning ability\nestimation for compression. Our approach operates at the level of individual\nheads, estimating their importance for contextual QA tasks that require both\nretrieval and reasoning capabilities. Extensive experiments across diverse\nbenchmarks (LongBench, LooGLE), model architectures (e.g., Llama-3-8B-Instruct,\nMistral-7B-Instruct), and long-context abilities tests demonstrate that our\nhead-level KV cache compression significantly outperforms strong baselines,\nparticularly in low-resource settings (KV size = 64 & 128). Notably, our method\nretains just 1.5% of the KV cache while achieving 97% of the performance of the\nfull KV cache on the contextual question answering benchmark.", "paper_summary_zh": "\u95dc\u9375\u503c (KV) \u5feb\u53d6\u662f\u4e00\u7a2e\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8a08\u7b97\u6548\u7387\u7684\u5e38\u898b\u6280\u8853\uff0c\u4f46\u5176\u8a18\u61b6\u9ad4\u958b\u92b7\u6703\u96a8\u8457\u8f38\u5165\u9577\u5ea6\u5feb\u901f\u589e\u52a0\u3002\u5148\u524d\u7684\u7814\u7a76\u986f\u793a\uff0c\u4e26\u975e\u6240\u6709\u6b0a\u6a19\u5c0d\u65bc\u6587\u672c\u7522\u751f\u540c\u7b49\u91cd\u8981\uff0c\u5efa\u8b70\u63a1\u7528\u5c64\u7d1a KV \u5feb\u53d6\u58d3\u7e2e\u4f86\u9078\u64c7\u6027\u4fdd\u7559\u95dc\u9375\u8cc7\u8a0a\u3002\u6211\u5011\u4e86\u89e3\u6ce8\u610f\u529b\u982d\u5728\u7522\u751f\u4e2d\u7684\u4e0d\u540c\u89d2\u8272\uff0c\u56e0\u6b64\u63d0\u51fa HeadKV\uff0c\u4e00\u7a2e\u982d\u7d1a KV \u5feb\u53d6\u58d3\u7e2e\u65b9\u6cd5\uff0c\u4ee5\u53ca HeadKV-R2\uff0c\u5b83\u5229\u7528\u4e00\u7a2e\u65b0\u7a4e\u7684\u8108\u7d61\u63a8\u7406\u80fd\u529b\u4f30\u8a08\u9032\u884c\u58d3\u7e2e\u3002\u6211\u5011\u7684\u505a\u6cd5\u5728\u500b\u5225\u982d\u7684\u5c64\u7d1a\u904b\u4f5c\uff0c\u4f30\u8a08\u5b83\u5011\u5c0d\u65bc\u9700\u8981\u64f7\u53d6\u548c\u63a8\u7406\u80fd\u529b\u7684\u8108\u7d61 QA \u4efb\u52d9\u7684\u91cd\u8981\u6027\u3002\u5728\u5404\u7a2e\u57fa\u6e96\u6e2c\u8a66\uff08LongBench\u3001LooGLE\uff09\u3001\u6a21\u578b\u67b6\u69cb\uff08\u4f8b\u5982 Llama-3-8B-Instruct\u3001Mistral-7B-Instruct\uff09\u548c\u9577\u8108\u7d61\u80fd\u529b\u6e2c\u8a66\u4e2d\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\uff0c\u6211\u5011\u7684\u982d\u7d1a KV \u5feb\u53d6\u58d3\u7e2e\u986f\u8457\u512a\u65bc\u5f37\u5927\u7684\u57fa\u7dda\uff0c\u7279\u5225\u662f\u5728\u4f4e\u8cc7\u6e90\u8a2d\u5b9a\uff08KV \u5927\u5c0f = 64 \u548c 128\uff09\u4e2d\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u7684\u505a\u6cd5\u50c5\u4fdd\u7559 1.5% \u7684 KV \u5feb\u53d6\uff0c\u540c\u6642\u5728\u8108\u7d61\u554f\u984c\u56de\u7b54\u57fa\u6e96\u6e2c\u8a66\u4e2d\u9054\u5230\u5b8c\u6574 KV \u5feb\u53d6\u6548\u80fd\u7684 97%\u3002", "author": "Yu Fu et.al.", "authors": "Yu Fu, Zefan Cai, Abedelkadir Asi, Wayne Xiong, Yue Dong, Wen Xiao", "id": "2410.19258v1", "paper_url": "http://arxiv.org/abs/2410.19258v1", "repo": "null"}}