{"2501.13818": {"publish_time": "2025-01-23", "title": "Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data", "paper_summary": "Deep neural networks are increasingly employed in high-stakes medical\napplications, despite their tendency for shortcut learning in the presence of\nspurious correlations, which can have potentially fatal consequences in\npractice. Detecting and mitigating shortcut behavior is a challenging task that\noften requires significant labeling efforts from domain experts. To alleviate\nthis problem, we introduce a semi-automated framework for the identification of\nspurious behavior from both data and model perspective by leveraging insights\nfrom eXplainable Artificial Intelligence (XAI). This allows the retrieval of\nspurious data points and the detection of model circuits that encode the\nassociated prediction rules. Moreover, we demonstrate how these shortcut\nencodings can be used for XAI-based sample- and pixel-level data annotation,\nproviding valuable information for bias mitigation methods to unlearn the\nundesired shortcut behavior. We show the applicability of our framework using\nfour medical datasets across two modalities, featuring controlled and\nreal-world spurious correlations caused by data artifacts. We successfully\nidentify and mitigate these biases in VGG16, ResNet50, and contemporary Vision\nTransformer models, ultimately increasing their robustness and applicability\nfor real-world medical tasks.", "paper_summary_zh": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u9ad8\u98ce\u9669\u533b\u7597\u5e94\u7528\u4e2d\uff0c\u5c3d\u7ba1\u5b83\u4eec\u5728\u5b58\u5728\u865a\u5047\u76f8\u5173\u6027\u7684\u60c5\u51b5\u4e0b\u503e\u5411\u4e8e\u6377\u5f84\u5b66\u4e60\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u53ef\u80fd\u4ea7\u751f\u81f4\u547d\u7684\u540e\u679c\u3002\u68c0\u6d4b\u548c\u7f13\u89e3\u6377\u5f84\u884c\u4e3a\u662f\u4e00\u9879\u8270\u5de8\u7684\u4efb\u52a1\uff0c\u901a\u5e38\u9700\u8981\u9886\u57df\u4e13\u5bb6\u7684\u5927\u91cf\u6807\u8bb0\u5de5\u4f5c\u3002\u4e3a\u4e86\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u534a\u81ea\u52a8\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u6570\u636e\u548c\u6a21\u578b\u7684\u89d2\u5ea6\u8bc6\u522b\u865a\u5047\u884c\u4e3a\uff0c\u65b9\u6cd5\u662f\u5229\u7528\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd (XAI) \u7684\u89c1\u89e3\u3002\u8fd9\u5141\u8bb8\u68c0\u7d22\u865a\u5047\u6570\u636e\u70b9\u5e76\u68c0\u6d4b\u5bf9\u5173\u8054\u9884\u6d4b\u89c4\u5219\u8fdb\u884c\u7f16\u7801\u7684\u6a21\u578b\u7535\u8def\u3002\u6b64\u5916\uff0c\u6211\u4eec\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u8fd9\u4e9b\u6377\u5f84\u7f16\u7801\u8fdb\u884c\u57fa\u4e8e XAI \u7684\u6837\u672c\u548c\u50cf\u7d20\u7ea7\u6570\u636e\u6ce8\u91ca\uff0c\u4e3a\u504f\u5dee\u7f13\u89e3\u65b9\u6cd5\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u4fe1\u606f\uff0c\u4ee5\u6d88\u9664\u4e0d\u9700\u8981\u7684\u6377\u5f84\u884c\u4e3a\u3002\u6211\u4eec\u4f7f\u7528\u8de8\u8d8a\u4e24\u79cd\u65b9\u5f0f\u7684\u56db\u4e2a\u533b\u5b66\u6570\u636e\u96c6\u5c55\u793a\u4e86\u6211\u4eec\u6846\u67b6\u7684\u9002\u7528\u6027\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u5177\u6709\u7531\u6570\u636e\u4f2a\u50cf\u5f15\u8d77\u7684\u53d7\u63a7\u548c\u771f\u5b9e\u4e16\u754c\u865a\u5047\u76f8\u5173\u6027\u3002\u6211\u4eec\u6210\u529f\u5730\u8bc6\u522b\u5e76\u51cf\u8f7b\u4e86 VGG16\u3001ResNet50 \u548c\u5f53\u4ee3 Vision Transformer \u6a21\u578b\u4e2d\u7684\u8fd9\u4e9b\u504f\u5dee\uff0c\u6700\u7ec8\u63d0\u9ad8\u4e86\u5b83\u4eec\u7684\u9c81\u68d2\u6027\u548c\u5728\u771f\u5b9e\u4e16\u754c\u533b\u7597\u4efb\u52a1\u4e2d\u7684\u9002\u7528\u6027\u3002", "author": "Frederik Pahde et.al.", "authors": "Frederik Pahde, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek", "id": "2501.13818v1", "paper_url": "http://arxiv.org/abs/2501.13818v1", "repo": "https://github.com/frederikpahde/medical-ai-safety"}}