{"2502.11863": {"publish_time": "2025-02-17", "title": "FedEAT: A Robustness Optimization Framework for Federated LLMs", "paper_summary": "Significant advancements have been made by Large Language Models (LLMs) in\nthe domains of natural language understanding and automated content creation.\nHowever, they still face persistent problems, including substantial\ncomputational costs and inadequate availability of training data. The\ncombination of Federated Learning (FL) and LLMs (federated LLMs) offers a\nsolution by leveraging distributed data while protecting privacy, which\npositions it as an ideal choice for sensitive domains. However, Federated LLMs\nstill suffer from robustness challenges, including data heterogeneity,\nmalicious clients, and adversarial attacks, which greatly hinder their\napplications. We first introduce the robustness problems in federated LLMs, to\naddress these challenges, we propose FedEAT (Federated Embedding space\nAdversarial Training), a novel framework that applies adversarial training in\nthe embedding space of client LLM and employs a robust aggregation approach,\nspecifically geometric median aggregation, to enhance the robustness of\nFederated LLMs. Our experiments demonstrate that FedEAT effectively improves\nthe robustness of Federated LLMs with minimal performance loss.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u7136\u8a9e\u8a00\u7406\u89e3\u548c\u81ea\u52d5\u5316\u5167\u5bb9\u5275\u4f5c\u9818\u57df\u53d6\u5f97\u4e86\u91cd\u5927\u9032\u5c55\u3002\n\u7136\u800c\uff0c\u5b83\u5011\u4ecd\u7136\u9762\u81e8\u6301\u7e8c\u7684\u554f\u984c\uff0c\u5305\u62ec\u5927\u91cf\u7684\u904b\u7b97\u6210\u672c\u548c\u8a13\u7df4\u6578\u64da\u7684\u53ef\u7528\u6027\u4e0d\u8db3\u3002\n\u806f\u5408\u5b78\u7fd2 (FL) \u548c LLM\uff08\u806f\u5408 LLM\uff09\u7684\u7d50\u5408\u63d0\u4f9b\u4e86\u4e00\u500b\u89e3\u6c7a\u65b9\u6848\uff0c\u5728\u4fdd\u8b77\u96b1\u79c1\u7684\u540c\u6642\u5229\u7528\u5206\u4f48\u5f0f\u6578\u64da\uff0c\u9019\u4f7f\u5176\u6210\u70ba\u654f\u611f\u9818\u57df\u7684\u7406\u60f3\u9078\u64c7\u3002\n\u7136\u800c\uff0c\u806f\u5408 LLM \u4ecd\u7136\u9762\u81e8\u8457\u7a69\u5065\u6027\u7684\u6311\u6230\uff0c\u5305\u62ec\u6578\u64da\u7570\u8cea\u6027\u3001\u60e1\u610f\u7528\u6236\u548c\u5c0d\u6297\u6027\u653b\u64ca\uff0c\u9019\u6975\u5927\u5730\u963b\u7919\u4e86\u5b83\u5011\u7684\u61c9\u7528\u3002\n\u6211\u5011\u9996\u5148\u4ecb\u7d39\u4e86\u806f\u5408 LLM \u4e2d\u7684\u7a69\u5065\u6027\u554f\u984c\uff0c\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86 FedEAT\uff08\u806f\u5408\u5d4c\u5165\u7a7a\u9593\u5c0d\u6297\u8a13\u7df4\uff09\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u6846\u67b6\uff0c\u5b83\u5728\u7528\u6236\u7aef LLM \u7684\u5d4c\u5165\u7a7a\u9593\u4e2d\u61c9\u7528\u5c0d\u6297\u8a13\u7df4\uff0c\u4e26\u63a1\u7528\u7a69\u5065\u7684\u805a\u5408\u65b9\u6cd5\uff0c\u7279\u5225\u662f\u5e7e\u4f55\u4e2d\u503c\u805a\u5408\uff0c\u4ee5\u589e\u5f37\u806f\u5408 LLM \u7684\u7a69\u5065\u6027\u3002\n\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0cFedEAT \u6709\u6548\u5730\u63d0\u9ad8\u4e86\u806f\u5408 LLM \u7684\u7a69\u5065\u6027\uff0c\u540c\u6642\u6027\u80fd\u640d\u5931\u6700\u5c0f\u3002", "author": "Yahao Pang et.al.", "authors": "Yahao Pang, Xingyuan Wu, Xiaojin Zhang, Wei Chen, Hai Jin", "id": "2502.11863v1", "paper_url": "http://arxiv.org/abs/2502.11863v1", "repo": "null"}}