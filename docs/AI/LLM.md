
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-11**|**Video Diffusion Alignment via Reward Gradients**|Mihir Prabhudesai et.al.|[2407.08737v1](http://arxiv.org/abs/2407.08737v1)|[link](https://github.com/mihirp1998/vader)|
|**2024-07-11**|**Real-Time Anomaly Detection and Reactive Planning with Large Language Models**|Rohan Sinha et.al.|[2407.08735v1](http://arxiv.org/abs/2407.08735v1)|null|
|**2024-07-11**|**Transformer Circuit Faithfulness Metrics are not Robust**|Joseph Miller et.al.|[2407.08734v1](http://arxiv.org/abs/2407.08734v1)|[link](https://github.com/ufo-101/auto-circuit)|
|**2024-07-11**|**Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist**|Zihao Zhou et.al.|[2407.08733v1](http://arxiv.org/abs/2407.08733v1)|null|
|**2024-07-11**|**A Taxonomy for Data Contamination in Large Language Models**|Medha Palavalli et.al.|[2407.08716v1](http://arxiv.org/abs/2407.08716v1)|null|
|**2024-07-11**|**GTA: A Benchmark for General Tool Agents**|Jize Wang et.al.|[2407.08713v1](http://arxiv.org/abs/2407.08713v1)|[link](https://github.com/open-compass/GTA)|
|**2024-07-11**|**eyeballvul: a future-proof benchmark for vulnerability detection in the wild**|Timothee Chauvin et.al.|[2407.08708v1](http://arxiv.org/abs/2407.08708v1)|[link](https://github.com/timothee-chauvin/eyeballvul_experiments)|
|**2024-07-11**|**Towards Efficient Deployment of Hybrid SNNs on Neuromorphic and Edge AI Hardware**|James Seekings et.al.|[2407.08704v1](http://arxiv.org/abs/2407.08704v1)|null|
|**2024-07-11**|**Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**|Zhiqiang Xie et.al.|[2407.08694v1](http://arxiv.org/abs/2407.08694v1)|null|
|**2024-07-11**|**ElasticAST: An Audio Spectrogram Transformer for All Length and Resolutions**|Jiu Feng et.al.|[2407.08691v1](http://arxiv.org/abs/2407.08691v1)|[link](https://github.com/jiufengsc/elasticast)|
|**2024-07-11**|**CAD-Prompted Generative Models: A Pathway to Feasible and Novel Engineering Designs**|Leah Chong et.al.|[2407.08675v1](http://arxiv.org/abs/2407.08675v1)|null|
|**2024-07-11**|**Uncertainty Estimation of Large Language Models in Medical Question Answering**|Jiaxin Wu et.al.|[2407.08662v1](http://arxiv.org/abs/2407.08662v1)|null|
|**2024-07-11**|**Confidence-based Estimators for Predictive Performance in Model Monitoring**|Juhani Kivimäki et.al.|[2407.08649v1](http://arxiv.org/abs/2407.08649v1)|null|
|**2024-07-11**|**Towards Building Specialized Generalist AI with System 1 and System 2 Fusion**|Kaiyan Zhang et.al.|[2407.08642v1](http://arxiv.org/abs/2407.08642v1)|null|
|**2024-07-11**|**$β$-DPO: Direct Preference Optimization with Dynamic $β$**|Junkang Wu et.al.|[2407.08639v1](http://arxiv.org/abs/2407.08639v1)|[link](https://github.com/junkangwu/beta-dpo)|
|**2024-07-11**|**Tamil Language Computing: the Present and the Future**|Kengatharaiyer Sarveswaran et.al.|[2407.08618v1](http://arxiv.org/abs/2407.08618v1)|null|
|**2024-07-11**|**FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision**|Jay Shah et.al.|[2407.08608v1](http://arxiv.org/abs/2407.08608v1)|null|
|**2024-07-11**|**Turn-Level Empathy Prediction Using Psychological Indicators**|Shaz Furniturewala et.al.|[2407.08607v1](http://arxiv.org/abs/2407.08607v1)|null|
|**2024-07-11**|**The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective**|Zhen Qin et.al.|[2407.08583v1](http://arxiv.org/abs/2407.08583v1)|[link](https://github.com/modelscope/data-juicer)|
|**2024-07-11**|**On the Universal Truthfulness Hyperplane Inside LLMs**|Junteng Liu et.al.|[2407.08582v1](http://arxiv.org/abs/2407.08582v1)|null|
|**2024-07-11**|**The Career Interests of Large Language Models**|Meng Hua et.al.|[2407.08564v1](http://arxiv.org/abs/2407.08564v1)|null|
|**2024-07-11**|**Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion**|Leah von der Heyde et.al.|[2407.08563v1](http://arxiv.org/abs/2407.08563v1)|[link](https://github.com/leahvdh/vox-populi-vox-ai)|
|**2024-07-11**|**ST-Mamba: Spatial-Temporal Mamba for Traffic Flow Estimation Recovery using Limited Data**|Doncheng Yuan et.al.|[2407.08558v1](http://arxiv.org/abs/2407.08558v1)|null|
|**2024-07-11**|**Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models**|Wanling Gao et.al.|[2407.08554v1](http://arxiv.org/abs/2407.08554v1)|[link](https://github.com/benchcouncil/vc-medai)|
|**2024-07-11**|**Autoregressive Speech Synthesis without Vector Quantization**|Lingwei Meng et.al.|[2407.08551v1](http://arxiv.org/abs/2407.08551v1)|null|
|**2024-07-11**|**Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility**|Yuchen Xia et.al.|[2407.08550v1](http://arxiv.org/abs/2407.08550v1)|null|
|**2024-07-11**|**Emergent Visual-Semantic Hierarchies in Image-Text Representations**|Morris Alper et.al.|[2407.08521v1](http://arxiv.org/abs/2407.08521v1)|null|
|**2024-07-11**|**Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**|Haoyi Xiong et.al.|[2407.08516v1](http://arxiv.org/abs/2407.08516v1)|null|
|**2024-07-11**|**15M Multimodal Facial Image-Text Dataset**|Dawei Dai et.al.|[2407.08515v2](http://arxiv.org/abs/2407.08515v2)|null|
|**2024-07-11**|**Latent Conditional Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph Mode**|Yuxing Tian et.al.|[2407.08500v1](http://arxiv.org/abs/2407.08500v1)|null|
|**2024-07-11**|**Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024**|Ilias Chalkidis et.al.|[2407.08495v1](http://arxiv.org/abs/2407.08495v1)|null|
|**2024-07-11**|**Lynx: An Open Source Hallucination Evaluation Model**|Selvan Sunitha Ravi et.al.|[2407.08488v1](http://arxiv.org/abs/2407.08488v1)|null|
|**2024-07-11**|**Investigating Public Fine-Tuning Datasets: A Complex Review of Current Practices from a Construction Perspective**|Runyuan Ma et.al.|[2407.08475v1](http://arxiv.org/abs/2407.08475v1)|null|
|**2024-07-11**|**Natural language is not enough: Benchmarking multi-modal generative AI for Verilog generation**|Kaiyan Chang et.al.|[2407.08473v1](http://arxiv.org/abs/2407.08473v1)|[link](https://github.com/aichipdesign/chipgptv)|
|**2024-07-11**|**Brain Tumor Segmentation in MRI Images with 3D U-Net and Contextual Transformer**|Thien-Qua T. Nguyen et.al.|[2407.08470v1](http://arxiv.org/abs/2407.08470v1)|null|
|**2024-07-11**|**Model Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks**|Zheng Wang et.al.|[2407.08454v1](http://arxiv.org/abs/2407.08454v1)|null|
|**2024-07-11**|**Paving the way toward foundation models for irregular and unaligned Satellite Image Time Series**|Iris Dumeur et.al.|[2407.08448v1](http://arxiv.org/abs/2407.08448v1)|null|
|**2024-07-11**|**How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation**|Linglong Qian et.al.|[2407.08442v1](http://arxiv.org/abs/2407.08442v1)|null|
|**2024-07-11**|**Are Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation**|Riccardo Cantini et.al.|[2407.08441v1](http://arxiv.org/abs/2407.08441v1)|null|
|**2024-07-11**|**Beyond Instruction Following: Evaluating Rule Following of Large Language Models**|Wangtao Sun et.al.|[2407.08440v1](http://arxiv.org/abs/2407.08440v1)|null|
|**2024-07-11**|**A Comprehensive Survey on Human Video Generation: Challenges, Methods, and Insights**|Wentao Lei et.al.|[2407.08428v1](http://arxiv.org/abs/2407.08428v1)|[link](https://github.com/wentaol86/awesome-human-body-video-generation)|
|**2024-07-11**|**On the (In)Security of LLM App Stores**|Xinyi Hou et.al.|[2407.08422v1](http://arxiv.org/abs/2407.08422v1)|null|
|**2024-07-11**|**Specialist vision-language models for clinical ophthalmology**|Robbie Holland et.al.|[2407.08410v1](http://arxiv.org/abs/2407.08410v1)|null|
|**2024-07-11**|**A Two-Stage Machine Learning-Aided Approach for Quench Identification at the European XFEL**|Lynda Boukela et.al.|[2407.08408v1](http://arxiv.org/abs/2407.08408v1)|null|
|**2024-07-11**|**Self-training Language Models for Arithmetic Reasoning**|Marek Kadlčík et.al.|[2407.08400v1](http://arxiv.org/abs/2407.08400v1)|null|
|**2024-07-11**|**On the attribution of confidence to large language models**|Geoff Keeling et.al.|[2407.08388v1](http://arxiv.org/abs/2407.08388v1)|null|
|**2024-07-11**|**Digital twins to alleviate the need for real field data in vision-based vehicle speed detection systems**|Antonio Hernández Martínez et.al.|[2407.08380v1](http://arxiv.org/abs/2407.08380v1)|null|
|**2024-07-11**|**AutoBencher: Creating Salient, Novel, Difficult Datasets for Language Models**|Xiang Lisa Li et.al.|[2407.08351v1](http://arxiv.org/abs/2407.08351v1)|[link](https://github.com/XiangLi1999/AutoBencher)|
|**2024-07-11**|**Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On**|Liang Zeng et.al.|[2407.08348v1](http://arxiv.org/abs/2407.08348v1)|null|
|**2024-07-11**|**Towards Explainable Evolution Strategies with Large Language Models**|Jill Baumann et.al.|[2407.08331v1](http://arxiv.org/abs/2407.08331v1)|null|
|**2024-07-11**|**Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports**|Georgina Cosma et.al.|[2407.08328v1](http://arxiv.org/abs/2407.08328v1)|null|
|**2024-07-11**|**Intelligent Multi-Document Summarisation for Extracting Insights on Racial Inequalities from Maternity Incident Investigation Reports**|Georgina Cosma et.al.|[2407.08322v1](http://arxiv.org/abs/2407.08322v1)|null|
|**2024-07-11**|**Adversarial-MidiBERT: Symbolic Music Understanding Model Based on Unbias Pre-training and Mask Fine-tuning**|Zijian Zhao et.al.|[2407.08306v1](http://arxiv.org/abs/2407.08306v1)|[link](https://github.com/RS2002/Adversarial-MidiBERT)|
|**2024-07-11**|**DenseFusion-1M: Merging Vision Experts for Comprehensive Multimodal Perception**|Xiaotong Li et.al.|[2407.08303v1](http://arxiv.org/abs/2407.08303v1)|[link](https://github.com/baaivision/densefusion)|
|**2024-07-11**|**Impact Measures for Gradual Argumentation Semantics**|Caren Al Anaissy et.al.|[2407.08302v1](http://arxiv.org/abs/2407.08302v1)|null|
|**2024-07-11**|**Continually Learn to Map Visual Concepts to Large Language Models in Resource-constrained Environments**|Clea Rebillard et.al.|[2407.08279v1](http://arxiv.org/abs/2407.08279v1)|null|
|**2024-07-11**|**RB-SQL: A Retrieval-based LLM Framework for Text-to-SQL**|Zhenhe Wu et.al.|[2407.08273v2](http://arxiv.org/abs/2407.08273v2)|null|
|**2024-07-11**|**SciQu: Accelerating Materials Properties Prediction with Automated Literature Mining for Self-Driving Laboratories**|Anand Babu et.al.|[2407.08270v1](http://arxiv.org/abs/2407.08270v1)|[link](https://github.com/abnano/sciqu)|
|**2024-07-11**|**LLMs' morphological analyses of complex FST-generated Finnish words**|Anssi Moisio et.al.|[2407.08269v1](http://arxiv.org/abs/2407.08269v1)|[link](https://github.com/aalto-speech/llm-morph-tests)|
|**2024-07-11**|**Knowledge distillation to effectively attain both region-of-interest and global semantics from an image where multiple objects appear**|Seonwhee Jin et.al.|[2407.08257v1](http://arxiv.org/abs/2407.08257v1)|[link](https://github.com/seonwhee-genome/rvernet)|
|**2024-07-11**|**GeNet: A Multimodal LLM-Based Co-Pilot for Network Topology and Configuration**|Beni Ifland et.al.|[2407.08249v1](http://arxiv.org/abs/2407.08249v1)|null|
|**2024-07-11**|**Toward accessible comics for blind and low vision readers**|Christophe Rigaud et.al.|[2407.08248v1](http://arxiv.org/abs/2407.08248v1)|null|
|**2024-07-11**|**Leveraging LLMs to Predict Affective States via Smartphone Sensor Features**|Tianyi Zhang et.al.|[2407.08240v1](http://arxiv.org/abs/2407.08240v1)|null|
|**2024-07-11**|**DALL-M: Context-Aware Clinical Data Augmentation with LLMs**|Chihcheng Hsieh et.al.|[2407.08227v1](http://arxiv.org/abs/2407.08227v1)|[link](https://github.com/chihchenghsieh/dall-m)|
|**2024-07-11**|**Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting**|Zilong Wang et.al.|[2407.08223v1](http://arxiv.org/abs/2407.08223v1)|null|
|**2024-07-11**|**Generating Contextually-Relevant Navigation Instructions for Blind and Low Vision People**|Zain Merchant et.al.|[2407.08219v1](http://arxiv.org/abs/2407.08219v1)|null|
|**2024-07-11**|**Multimodal contrastive learning for spatial gene expression prediction using histology images**|Wenwen Min et.al.|[2407.08216v1](http://arxiv.org/abs/2407.08216v1)|[link](https://github.com/shizhiceng/mclstexp)|
|**2024-07-11**|**System Report for CCL24-Eval Task 7: Multi-Error Modeling and Fluency-Targeted Pre-training for Chinese Essay Evaluation**|Jingshen Zhang et.al.|[2407.08206v1](http://arxiv.org/abs/2407.08206v1)|null|
|**2024-07-11**|**Chromosomal Structural Abnormality Diagnosis by Homologous Similarity**|Juren Li et.al.|[2407.08204v1](http://arxiv.org/abs/2407.08204v1)|[link](https://github.com/zjunet/homnet)|
|**2024-07-11**|**SoupLM: Model Integration in Large Language and Multi-Modal Models**|Yue Bai et.al.|[2407.08196v1](http://arxiv.org/abs/2407.08196v1)|null|
|**2024-07-11**|**A Text-to-Game Engine for UGC-Based Role-Playing Games**|Lei Zhang et.al.|[2407.08195v1](http://arxiv.org/abs/2407.08195v1)|null|
|**2024-07-11**|**ARCO:Adaptive Multi-Agent Reinforcement Learning-Based Hardware/Software Co-Optimization Compiler for Improved Performance in DNN Accelerator Design**|Arya Fayyazi et.al.|[2407.08192v1](http://arxiv.org/abs/2407.08192v1)|null|
|**2024-07-11**|**fairBERTs: Erasing Sensitive Information Through Semantic and Fairness-aware Perturbations**|Jinfeng Li et.al.|[2407.08189v1](http://arxiv.org/abs/2407.08189v1)|null|
|**2024-07-11**|**Automatic Generation of Web Censorship Probe Lists**|Jenny Tang et.al.|[2407.08185v1](http://arxiv.org/abs/2407.08185v1)|null|
|**2024-07-11**|**Beyond Text: Leveraging Multi-Task Learning and Cognitive Appraisal Theory for Post-Purchase Intention Analysis**|Gerard Christopher Yeo et.al.|[2407.08182v1](http://arxiv.org/abs/2407.08182v1)|null|
|**2024-07-11**|**CoGS: Causality Constrained Counterfactual Explanations using goal-directed ASP**|Sopam Dasgupta et.al.|[2407.08179v1](http://arxiv.org/abs/2407.08179v1)|null|
|**2024-07-11**|**Foundation Model Engineering: Engineering Foundation Models Just as Engineering Software**|Dezhi Ran et.al.|[2407.08176v1](http://arxiv.org/abs/2407.08176v1)|null|
|**2024-07-11**|**Faster Machine Unlearning via Natural Gradient Descent**|Omri Lev et.al.|[2407.08169v1](http://arxiv.org/abs/2407.08169v1)|null|
|**2024-07-11**|**Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder**|Mikhail Kulyabin et.al.|[2407.08166v1](http://arxiv.org/abs/2407.08166v1)|null|
|**2024-07-11**|**Privacy-Preserving Data Deduplication for Enhancing Federated Learning of Language Models**|Aydin Abadi et.al.|[2407.08152v1](http://arxiv.org/abs/2407.08152v1)|null|
|**2024-07-11**|**Looks can be Deceptive: Distinguishing Repetition Disfluency from Reduplication**|Arif Ahmad et.al.|[2407.08147v1](http://arxiv.org/abs/2407.08147v1)|null|
|**2024-07-11**|**Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates**|A. Noorizadegan et.al.|[2407.08134v1](http://arxiv.org/abs/2407.08134v1)|[link](https://github.com/cmmai/resnet_for_pinn)|
|**2024-07-11**|**Nonverbal Interaction Detection**|Jianan Wei et.al.|[2407.08133v1](http://arxiv.org/abs/2407.08133v1)|null|
|**2024-07-11**|**Label-anticipated Event Disentanglement for Audio-Visual Video Parsing**|Jinxing Zhou et.al.|[2407.08126v1](http://arxiv.org/abs/2407.08126v1)|null|
|**2024-07-11**|**How Well Can a Long Sequence Model Model Long Sequences? Comparing Architechtural Inductive Biases on Long-Context Abilities**|Jerry Huang et.al.|[2407.08112v1](http://arxiv.org/abs/2407.08112v1)|null|
|**2024-07-11**|**Urban Waterlogging Detection: A Challenging Benchmark and Large-Small Model Co-Adapter**|Suqi Song et.al.|[2407.08109v1](http://arxiv.org/abs/2407.08109v1)|[link](https://github.com/zhang-chenxu/lsm-adapter)|
|**2024-07-11**|**CADC: Encoding User-Item Interactions for Compressing Recommendation Model Training Data**|Hossein Entezari Zarch et.al.|[2407.08108v1](http://arxiv.org/abs/2407.08108v1)|null|
|**2024-07-11**|**Federated Learning and AI Regulation in the European Union: Who is Responsible? -- An Interdisciplinary Analysis**|Herbert Woisetschläger et.al.|[2407.08105v2](http://arxiv.org/abs/2407.08105v2)|null|
|**2024-07-11**|**Automata-based constraints for language model decoding**|Terry Koo et.al.|[2407.08103v2](http://arxiv.org/abs/2407.08103v2)|null|
|**2024-07-11**|**How does Burrows' Delta work on medieval Chinese poetic texts?**|Boris Orekhov et.al.|[2407.08099v1](http://arxiv.org/abs/2407.08099v1)|null|
|**2024-07-10**|**Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing**|Ian Steenstra et.al.|[2407.08095v1](http://arxiv.org/abs/2407.08095v1)|[link](https://github.com/IanSteenstra/llm-alcohol-counselor)|
|**2024-07-10**|**MemWarp: Discontinuity-Preserving Cardiac Registration with Memorized Anatomical Filters**|Hang Zhang et.al.|[2407.08093v1](http://arxiv.org/abs/2407.08093v1)|null|
|**2024-07-10**|**NDST: Neural Driving Style Transfer for Human-Like Vision-Based Autonomous Driving**|Donghyun Kim et.al.|[2407.08073v1](http://arxiv.org/abs/2407.08073v1)|null|
|**2024-07-10**|**On LLM Wizards: Identifying Large Language Models' Behaviors for Wizard of Oz Experiments**|Jingchao Fang et.al.|[2407.08067v1](http://arxiv.org/abs/2407.08067v1)|null|
|**2024-07-10**|**Towards Interpretable Foundation Models of Robot Behavior: A Task Specific Policy Generation Approach**|Isaac Sheidlower et.al.|[2407.08065v1](http://arxiv.org/abs/2407.08065v1)|null|
|**2024-07-10**|**Spatial-Temporal Attention Model for Traffic State Estimation with Sparse Internet of Vehicles**|Jianzhe Xue et.al.|[2407.08047v1](http://arxiv.org/abs/2407.08047v1)|null|
|**2024-07-10**|**RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization**|Xijie Huang et.al.|[2407.08044v1](http://arxiv.org/abs/2407.08044v1)|[link](https://github.com/huangowen/rolora)|
|**2024-07-10**|**Knowledge Overshadowing Causes Amalgamated Hallucination in Large Language Models**|Yuji Zhang et.al.|[2407.08039v1](http://arxiv.org/abs/2407.08039v1)|null|
|**2024-07-10**|**FsPONER: Few-shot Prompt Optimization for Named Entity Recognition in Domain-specific Scenarios**|Yongjian Tang et.al.|[2407.08035v1](http://arxiv.org/abs/2407.08035v1)|null|
|**2024-07-10**|**A Critical Review of Causal Reasoning Benchmarks for Large Language Models**|Linying Yang et.al.|[2407.08029v1](http://arxiv.org/abs/2407.08029v1)|null|

#### Abstracts
##### **Video Diffusion Alignment via Reward Gradients**
2407.08737v1 by Mihir Prabhudesai, Russell Mendonca, Zheyang Qin, Katerina Fragkiadaki, Deepak Pathak

We have made significant progress towards building foundational video
diffusion models. As these models are trained using large-scale unsupervised
data, it has become crucial to adapt these models to specific downstream tasks.
Adapting these models via supervised fine-tuning requires collecting target
datasets of videos, which is challenging and tedious. In this work, we utilize
pre-trained reward models that are learned via preferences on top of powerful
vision discriminative models to adapt video diffusion models. These models
contain dense gradient information with respect to generated RGB pixels, which
is critical to efficient learning in complex search spaces, such as videos. We
show that backpropagating gradients from these reward models to a video
diffusion model can allow for compute and sample efficient alignment of the
video diffusion model. We show results across a variety of reward models and
video diffusion models, demonstrating that our approach can learn much more
efficiently in terms of reward queries and computation than prior gradient-free
approaches. Our code, model weights,and more visualization are available at
https://vader-vid.github.io.

摘要：我們在建立基礎影片擴散模型方面取得重大進展。由於這些模型使用大規模無監督資料進行訓練，因此必須將這些模型調整到特定下游任務。透過監督微調調整這些模型需要收集影片的目標資料集，這具有挑戰性且繁瑣。在這項工作中，我們利用預訓練的獎勵模型，這些模型是透過偏好在強大的視覺辨別模型上學習，以調整影片擴散模型。這些模型包含關於生成 RGB 像素的密集梯度資訊，這對於在複雜的搜尋空間（例如影片）中進行有效率的學習至關重要。我們展示了從這些獎勵模型反向傳播梯度到影片擴散模型可以允許計算和樣本有效地對齊影片擴散模型。我們展示了各種獎勵模型和影片擴散模型的結果，證明我們的做法在獎勵查詢和計算方面可以比先前的無梯度方法學習更有效率。我們的程式碼、模型權重和更多視覺化資訊可在 https://vader-vid.github.io/ 取得。

##### **Real-Time Anomaly Detection and Reactive Planning with Large Language Models**
2407.08735v1 by Rohan Sinha, Amine Elhafsi, Christopher Agia, Matthew Foutter, Edward Schmerling, Marco Pavone

Foundation models, e.g., large language models (LLMs), trained on
internet-scale data possess zero-shot generalization capabilities that make
them a promising technology towards detecting and mitigating
out-of-distribution failure modes of robotic systems. Fully realizing this
promise, however, poses two challenges: (i) mitigating the considerable
computational expense of these models such that they may be applied online, and
(ii) incorporating their judgement regarding potential anomalies into a safe
control framework. In this work, we present a two-stage reasoning framework:
First is a fast binary anomaly classifier that analyzes observations in an LLM
embedding space, which may then trigger a slower fallback selection stage that
utilizes the reasoning capabilities of generative LLMs. These stages correspond
to branch points in a model predictive control strategy that maintains the
joint feasibility of continuing along various fallback plans to account for the
slow reasoner's latency as soon as an anomaly is detected, thus ensuring
safety. We show that our fast anomaly classifier outperforms autoregressive
reasoning with state-of-the-art GPT models, even when instantiated with
relatively small language models. This enables our runtime monitor to improve
the trustworthiness of dynamic robotic systems, such as quadrotors or
autonomous vehicles, under resource and time constraints. Videos illustrating
our approach in both simulation and real-world experiments are available on
this project page: https://sites.google.com/view/aesop-llm.

摘要：基础模型（例如大型语言模型 (LLM)）在互联网规模的数据上进行训练，拥有零样本泛化能力，这使得它们成为检测和缓解机器人系统分布外故障模式的一项有前途的技术。然而，要充分实现这一承诺，需要应对两项挑战：(i) 降低这些模型的巨大计算开销，以便可以在线应用它们，以及 (ii) 将它们对潜在异常的判断纳入安全控制框架中。在这项工作中，我们提出了一个两阶段推理框架：首先是一个快速的二进制异常分类器，它分析 LLM 嵌入空间中的观测值，然后可能触发一个较慢的回退选择阶段，该阶段利用生成式 LLM 的推理能力。这些阶段对应于模型预测控制策略中的分支点，该策略保持继续执行各种回退计划的联合可行性，以便在检测到异常后立即考虑慢速推理器的延迟，从而确保安全性。我们表明，即使使用相对较小的语言模型实例化，我们的快速异常分类器也优于采用最先进的 GPT 模型的自回归推理。这使我们的运行时监视器能够在资源和时间限制下提高动态机器人系统（例如四旋翼飞机或自动驾驶汽车）的可信度。说明我们方法的模拟和真实世界实验视频可在该项目页面上找到：https://sites.google.com/view/aesop-llm。

##### **Transformer Circuit Faithfulness Metrics are not Robust**
2407.08734v1 by Joseph Miller, Bilal Chughtai, William Saunders

Mechanistic interpretability work attempts to reverse engineer the learned
algorithms present inside neural networks. One focus of this work has been to
discover 'circuits' -- subgraphs of the full model that explain behaviour on
specific tasks. But how do we measure the performance of such circuits? Prior
work has attempted to measure circuit 'faithfulness' -- the degree to which the
circuit replicates the performance of the full model. In this work, we survey
many considerations for designing experiments that measure circuit faithfulness
by ablating portions of the model's computation. Concerningly, we find existing
methods are highly sensitive to seemingly insignificant changes in the ablation
methodology. We conclude that existing circuit faithfulness scores reflect both
the methodological choices of researchers as well as the actual components of
the circuit - the task a circuit is required to perform depends on the ablation
used to test it. The ultimate goal of mechanistic interpretability work is to
understand neural networks, so we emphasize the need for more clarity in the
precise claims being made about circuits. We open source a library at
https://github.com/UFO-101/auto-circuit that includes highly efficient
implementations of a wide range of ablation methodologies and circuit discovery
algorithms.

摘要：<paragraph>机制可解释性工作尝试对神经网络中存在的学习算法进行逆向工程。这项工作的重点之一是发现“电路”-- 完整模型的子图，它解释了特定任务的行为。但是，我们如何衡量此类电路的性能？先前的工作尝试测量电路“保真度”-- 电路复制完整模型性能的程度。在这项工作中，我们调查了许多考虑因素，用于设计通过消融模型计算部分来测量电路保真度的实验。令人担忧的是，我们发现现有方法对消融方法中看似微不足道的变化高度敏感。我们得出结论，现有的电路保真度得分反映了研究人员的方法论选择以及电路的实际组件 - 电路需要执行的任务取决于用于测试它的消融。机制可解释性工作的最终目标是理解神经网络，因此我们强调需要更清楚地阐述关于电路的具体主张。我们在 https://github.com/UFO-101/auto-circuit 开源了一个库，其中包括广泛的消融方法和电路发现算法的高效实现。</paragraph>

##### **Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist**
2407.08733v1 by Zihao Zhou, Shudong Liu, Maizhen Ning, Wei Liu, Jindong Wang, Derek F. Wong, Xiaowei Huang, Qiufeng Wang, Kaizhu Huang

Exceptional mathematical reasoning ability is one of the key features that
demonstrate the power of large language models (LLMs). How to comprehensively
define and evaluate the mathematical abilities of LLMs, and even reflect the
user experience in real-world scenarios, has emerged as a critical issue.
Current benchmarks predominantly concentrate on problem-solving capabilities,
which presents a substantial risk of model overfitting and fails to accurately
represent genuine mathematical reasoning abilities. In this paper, we argue
that if a model really understands a problem, it should be robustly and readily
applied across a diverse array of tasks. Motivated by this, we introduce
MATHCHECK, a well-designed checklist for testing task generalization and
reasoning robustness, as well as an automatic tool to generate checklists
efficiently. MATHCHECK includes multiple mathematical reasoning tasks and
robustness test types to facilitate a comprehensive evaluation of both
mathematical reasoning ability and behavior testing. Utilizing MATHCHECK, we
develop MATHCHECK-GSM and MATHCHECK-GEO to assess mathematical textual
reasoning and multi-modal reasoning capabilities, respectively, serving as
upgraded versions of benchmarks including GSM8k, GeoQA, UniGeo, and Geometry3K.
We adopt MATHCHECK-GSM and MATHCHECK-GEO to evaluate over 20 LLMs and 11 MLLMs,
assessing their comprehensive mathematical reasoning abilities. Our results
demonstrate that while frontier LLMs like GPT-4o continue to excel in various
abilities on the checklist, many other model families exhibit a significant
decline. Further experiments indicate that, compared to traditional math
benchmarks, MATHCHECK better reflects true mathematical abilities and
represents mathematical intelligence more linearly, thereby supporting our
design. On our MATHCHECK, we can easily conduct detailed behavior analysis to
deeply investigate models.

摘要：傑出的數學推理能力是展示大型語言模型 (LLM) 強大的關鍵特徵之一。如何全面定義和評估 LLM 的數學能力，甚至反映真實場景中的使用者體驗，已成為一個關鍵問題。目前的基準主要集中於問題解決能力，這會造成模型過度擬合的重大風險，且無法準確表示真正的數學推理能力。在本文中，我們論證如果一個模型真正理解一個問題，它應該可以穩健且容易地應用於各種任務中。受此啟發，我們引入了 MATHCHECK，這是一個精心設計的檢查清單，用於測試任務概化和推理穩健性，以及一個用於有效產生檢查清單的自動化工具。MATHCHECK 包含多項數學推理任務和穩健性測試類型，以利於對數學推理能力和行為測試進行全面評估。利用 MATHCHECK，我們開發了 MATHCHECK-GSM 和 MATHCHECK-GEO，分別用於評估數學文本推理和多模態推理能力，作為包括 GSM8k、GeoQA、UniGeo 和 Geometry3K 在內的基準的升級版本。我們採用 MATHCHECK-GSM 和 MATHCHECK-GEO 來評估超過 20 個 LLM 和 11 個 MLLM，評估它們的綜合數學推理能力。我們的結果表明，儘管像 GPT-4o 這樣的邊疆 LLM 繼續在檢查清單上的各種能力中表現出色，但許多其他模型系列卻出現顯著下降。進一步的實驗表明，與傳統數學基準相比，MATHCHECK 更好地反映了真正的數學能力，並更線性地表示數學智能，從而支持我們的設計。在我們的 MATHCHECK 上，我們可以輕鬆進行詳細的行為分析，以深入研究模型。

##### **A Taxonomy for Data Contamination in Large Language Models**
2407.08716v1 by Medha Palavalli, Amanda Bertsch, Matthew R. Gormley

Large language models pretrained on extensive web corpora demonstrate
remarkable performance across a wide range of downstream tasks. However, a
growing concern is data contamination, where evaluation datasets may be
contained in the pretraining corpus, inflating model performance.
Decontamination, the process of detecting and removing such data, is a
potential solution; yet these contaminants may originate from altered versions
of the test set, evading detection during decontamination. How different types
of contamination impact the performance of language models on downstream tasks
is not fully understood. We present a taxonomy that categorizes the various
types of contamination encountered by LLMs during the pretraining phase and
identify which types pose the highest risk. We analyze the impact of
contamination on two key NLP tasks -- summarization and question answering --
revealing how different types of contamination influence task performance
during evaluation.

摘要：大型語言模型在廣泛的網路語料庫上進行預訓練，在各種下游任務中展現出卓越的表現。然而，一個日益受到關注的問題是資料污染，評估資料集可能包含在預訓練語料庫中，進而誇大了模型的表現。去污，也就是偵測並移除此類資料的程序，是一種可能的解決方案；然而這些污染物可能來自測試集的修改版本，在去污過程中逃避偵測。不同類型的污染如何影響語言模型在下游任務中的表現，目前尚未完全了解。我們提出了一個分類法，將大型語言模型在預訓練階段遇到的各種污染類型分類，並找出風險最高的類型。我們分析了污染對兩個關鍵的自然語言處理任務的影響——摘要和問答——揭示了不同類型的污染如何在評估過程中影響任務表現。

##### **GTA: A Benchmark for General Tool Agents**
2407.08713v1 by Jize Wang, Zerun Ma, Yining Li, Songyang Zhang, Cailian Chen, Kai Chen, Xinyi Le

Significant focus has been placed on integrating large language models (LLMs)
with various tools in developing general-purpose agents. This poses a challenge
to LLMs' tool-use capabilities. However, there are evident gaps between
existing tool-use evaluations and real-world scenarios. Current evaluations
often use AI-generated queries, single-step tasks, dummy tools, and text-only
interactions, failing to reveal the agents' real-world problem-solving
abilities effectively. To address this, we propose GTA, a benchmark for General
Tool Agents, featuring three main aspects: (i) Real user queries: human-written
queries with simple real-world objectives but implicit tool-use, requiring the
LLM to reason the suitable tools and plan the solution steps. (ii) Real
deployed tools: an evaluation platform equipped with tools across perception,
operation, logic, and creativity categories to evaluate the agents' actual task
execution performance. (iii) Real multimodal inputs: authentic image files,
such as spatial scenes, web page screenshots, tables, code snippets, and
printed/handwritten materials, used as the query contexts to align with
real-world scenarios closely. We design 229 real-world tasks and executable
tool chains to evaluate mainstream LLMs. Our findings show that real-world user
queries are challenging for existing LLMs, with GPT-4 completing less than 50%
of the tasks and most LLMs achieving below 25%. This evaluation reveals the
bottlenecks in the tool-use capabilities of current LLMs in real-world
scenarios, which provides future direction for advancing general-purpose tool
agents. The code and dataset are available at
https://github.com/open-compass/GTA.

摘要：<paragraph>在開發通用代理時，整合大型語言模型 (LLM) 與各種工具已成為重點。這對 LLM 的工具使用能力構成挑戰。然而，現有的工具使用評估與實際場景之間存在明顯差距。目前的評估通常使用 AI 生成的查詢、單步任務、虛擬工具和純文字互動，未能有效揭示代理的實際問題解決能力。為了解決這個問題，我們提出 GTA，一個通用工具代理的基準，具有三個主要方面：(i) 真實使用者查詢：人類撰寫的查詢，具有簡單的實際目標但隱含工具使用，要求 LLM 推論適當的工具並規劃解決步驟。(ii) 真實部署工具：一個評估平台，配備感知、操作、邏輯和創意類別的工具，以評估代理的實際任務執行效能。(iii) 真實多模態輸入：真實的影像檔案，例如空間場景、網頁截圖、表格、程式碼片段，以及印刷/手寫材料，用作查詢背景，以緊密配合實際場景。我們設計了 229 個真實世界的任務和可執行工具鏈，以評估主流 LLM。我們的研究結果顯示，實際世界的使用者查詢對現有的 LLM 構成挑戰，GPT-4 完成不到 50% 的任務，而大多數 LLM 的完成率低於 25%。此評估揭示了當前 LLM 在實際場景中工具使用能力的瓶頸，這為推進通用工具代理提供了未來的方向。程式碼和資料集可在 https://github.com/open-compass/GTA 取得。</paragraph>

##### **eyeballvul: a future-proof benchmark for vulnerability detection in the wild**
2407.08708v1 by Timothee Chauvin

Long contexts of recent LLMs have enabled a new use case: asking models to
find security vulnerabilities in entire codebases. To evaluate model
performance on this task, we introduce eyeballvul: a benchmark designed to test
the vulnerability detection capabilities of language models at scale, that is
sourced and updated weekly from the stream of published vulnerabilities in
open-source repositories. The benchmark consists of a list of revisions in
different repositories, each associated with the list of known vulnerabilities
present at that revision. An LLM-based scorer is used to compare the list of
possible vulnerabilities returned by a model to the list of known
vulnerabilities for each revision. As of July 2024, eyeballvul contains 24,000+
vulnerabilities across 6,000+ revisions and 5,000+ repositories, and is around
55GB in size.

摘要：近期大型語言模型的長語境讓一個新應用案例成為可能：讓模型在整個程式碼庫中尋找安全漏洞。為了評估模型在這個任務上的表現，我們引入了 eyeballvul：一個基準測試，旨在測試語言模型在大規模情況下檢測漏洞的能力，它從開源儲存庫中已發布的漏洞串流中獲取並每周更新。這個基準測試包含一個清單，列出不同儲存庫中的修訂，每個修訂都與該修訂中存在已知漏洞的清單相關聯。一個基於 LLM 的評分器用於將模型返回的可能漏洞清單與每個修訂的已知漏洞清單進行比較。截至 2024 年 7 月，eyeballvul 包含超過 24,000 個漏洞，分佈在 6,000 多個修訂和 5,000 多個儲存庫中，大小約為 55GB。

##### **Towards Efficient Deployment of Hybrid SNNs on Neuromorphic and Edge AI Hardware**
2407.08704v1 by James Seekings, Peyton Chandarana, Mahsa Ardakani, MohammadReza Mohammadi, Ramtin Zand

This paper explores the synergistic potential of neuromorphic and edge
computing to create a versatile machine learning (ML) system tailored for
processing data captured by dynamic vision sensors. We construct and train
hybrid models, blending spiking neural networks (SNNs) and artificial neural
networks (ANNs) using PyTorch and Lava frameworks. Our hybrid architecture
integrates an SNN for temporal feature extraction and an ANN for
classification. We delve into the challenges of deploying such hybrid
structures on hardware. Specifically, we deploy individual components on
Intel's Neuromorphic Processor Loihi (for SNN) and Jetson Nano (for ANN). We
also propose an accumulator circuit to transfer data from the spiking to the
non-spiking domain. Furthermore, we conduct comprehensive performance analyses
of hybrid SNN-ANN models on a heterogeneous system of neuromorphic and edge AI
hardware, evaluating accuracy, latency, power, and energy consumption. Our
findings demonstrate that the hybrid spiking networks surpass the baseline ANN
model across all metrics and outperform the baseline SNN model in accuracy and
latency.

摘要：本文探討神經型態和邊緣運算的協同潛力，以建立一個多功能機器學習 (ML) 系統，專門用於處理動態視覺感測器擷取的資料。我們使用 PyTorch 和 Lava 架構構建並訓練混合模型，結合了脈衝神經網路 (SNN) 和人工神經網路 (ANN)。我們的混合架構整合了一個用於時間特徵提取的 SNN 和一個用於分類的 ANN。我們深入探討了在硬體上部署此類混合結構的挑戰。具體來說，我們在 Intel 的神經型態處理器 Loihi（用於 SNN）和 Jetson Nano（用於 ANN）上部署個別元件。我們還提出了一個累加器電路，用於將資料從脈衝傳輸到非脈衝域。此外，我們對神經型態和邊緣 AI 硬體的異質系統上的混合 SNN-ANN 模型進行了全面的效能分析，評估準確度、延遲、功耗和能耗。我們的研究結果表明，混合脈衝網路在所有指標上都超越了基準 ANN 模型，並且在準確度和延遲方面優於基準 SNN 模型。

##### **Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**
2407.08694v1 by Zhiqiang Xie, Yujia Zheng, Lizi Ottens, Kun Zhang, Christos Kozyrakis, Jonathan Mace

Runtime failure and performance degradation is commonplace in modern cloud
systems. For cloud providers, automatically determining the root cause of
incidents is paramount to ensuring high reliability and availability as prompt
fault localization can enable faster diagnosis and triage for timely
resolution. A compelling solution explored in recent work is causal reasoning
using causal graphs to capture relationships between varied cloud system
performance metrics. To be effective, however, systems developers must
correctly define the causal graph of their system, which is a time-consuming,
brittle, and challenging task that increases in difficulty for large and
dynamic systems and requires domain expertise. Alternatively, automated
data-driven approaches have limited efficacy for cloud systems due to the
inherent rarity of incidents. In this work, we present Atlas, a novel approach
to automatically synthesizing causal graphs for cloud systems. Atlas leverages
large language models (LLMs) to generate causal graphs using system
documentation, telemetry, and deployment feedback. Atlas is complementary to
data-driven causal discovery techniques, and we further enhance Atlas with a
data-driven validation step. We evaluate Atlas across a range of fault
localization scenarios and demonstrate that Atlas is capable of generating
causal graphs in a scalable and generalizable manner, with performance that far
surpasses that of data-driven algorithms and is commensurate to the
ground-truth baseline.

摘要：在現代雲端系統中，執行時期故障和效能降低是司空見慣的事。對於雲端供應商而言，自動找出事件的根本原因對於確保高可靠性和可用性至關重要，因為及時的故障定位可以讓診斷和分類更快速，以利於及時解決問題。最近的工作中探討了一個引人注目的解決方案，即使用因果圖來擷取各種雲端系統效能指標之間關係的因果推理。然而，系統開發人員必須正確定義其系統的因果圖才能發揮效用，而這項任務耗時、脆弱且具有挑戰性，對於大型且動態的系統而言難度更高，而且需要領域專家知識。或者，由於事件的固有稀少性，自動化資料驅動方法對於雲端系統的效力有限。在這項工作中，我們提出 Atlas，一種自動合成雲端系統因果圖的新方法。Atlas 利用大型語言模型 (LLM) 使用系統文件、遙測和部署回饋來產生因果圖。Atlas 是資料驅動因果發現技術的補充，我們進一步使用資料驅動驗證步驟來增強 Atlas。我們在各種故障定位情境中評估 Atlas，並證明 Atlas 能夠以可擴充且可概化的方式產生因果圖，其效能遠遠超過資料驅動演算法，並且與真實基線相當。

##### **ElasticAST: An Audio Spectrogram Transformer for All Length and Resolutions**
2407.08691v1 by Jiu Feng, Mehmet Hamza Erol, Joon Son Chung, Arda Senocak

Transformers have rapidly overtaken CNN-based architectures as the new
standard in audio classification. Transformer-based models, such as the Audio
Spectrogram Transformers (AST), also inherit the fixed-size input paradigm from
CNNs. However, this leads to performance degradation for ASTs in the inference
when input lengths vary from the training. This paper introduces an approach
that enables the use of variable-length audio inputs with AST models during
both training and inference. By employing sequence packing, our method
ElasticAST, accommodates any audio length during training, thereby offering
flexibility across all lengths and resolutions at the inference. This
flexibility allows ElasticAST to maintain evaluation capabilities at various
lengths or resolutions and achieve similar performance to standard ASTs trained
at specific lengths or resolutions. Moreover, experiments demonstrate
ElasticAST's better performance when trained and evaluated on native-length
audio datasets.

摘要：Transformer已迅速超越基於 CNN 的架構，成為音訊分類中的新標準。基於Transformer的模型，例如音訊光譜Transformer (AST)，也繼承了 CNN 的固定大小輸入範例。然而，這會導致 AST 在輸入長度與訓練不同時的推論效能下降。本文介紹了一種方法，可在訓練和推論期間使用變長音訊輸入與 AST 模型。我們的 ElasticAST 方法採用序列封裝，可以在訓練期間容納任何音訊長度，從而提供推論時所有長度和解析度的彈性。這種彈性使 ElasticAST 能夠在各種長度或解析度下維持評估能力，並達到與在特定長度或解析度下訓練的標準 AST 相似的效能。此外，實驗證明了 ElasticAST 在原生長度音訊資料集上訓練和評估時具有更好的效能。

##### **CAD-Prompted Generative Models: A Pathway to Feasible and Novel Engineering Designs**
2407.08675v1 by Leah Chong, Jude Rayan, Steven Dow, Ioanna Lykourentzou, Faez Ahmed

Text-to-image generative models have increasingly been used to assist
designers during concept generation in various creative domains, such as
graphic design, user interface design, and fashion design. However, their
applications in engineering design remain limited due to the models' challenges
in generating images of feasible designs concepts. To address this issue, this
paper introduces a method that improves the design feasibility by prompting the
generation with feasible CAD images. In this work, the usefulness of this
method is investigated through a case study with a bike design task using an
off-the-shelf text-to-image model, Stable Diffusion 2.1. A diverse set of bike
designs are produced in seven different generation settings with varying CAD
image prompting weights, and these designs are evaluated on their perceived
feasibility and novelty. Results demonstrate that the CAD image prompting
successfully helps text-to-image models like Stable Diffusion 2.1 create
visibly more feasible design images. While a general tradeoff is observed
between feasibility and novelty, when the prompting weight is kept low around
0.35, the design feasibility is significantly improved while its novelty
remains on par with those generated by text prompts alone. The insights from
this case study offer some guidelines for selecting the appropriate CAD image
prompting weight for different stages of the engineering design process. When
utilized effectively, our CAD image prompting method opens doors to a wider
range of applications of text-to-image models in engineering design.

摘要：文本到影像的生成模型越來越常被用於協助設計師在各種創意領域中進行概念生成，例如平面設計、使用者介面設計和時尚設計。然而，由於模型在生成可行的設計概念影像時面臨挑戰，因此它們在工程設計中的應用仍然有限。為了解決這個問題，本文介紹了一種方法，透過使用可行的 CAD 影像提示生成，來改善設計的可行性。在這項工作中，透過使用現成的文本到影像模型 Stable Diffusion 2.1 進行自行車設計任務的案例研究，來探討這種方法的實用性。在七種不同的生成設定中，使用不同的 CAD 影像提示權重產生了多樣化的自行車設計，並針對這些設計的感知可行性和新穎性進行評估。結果表明，CAD 影像提示確實有助於像 Stable Diffusion 2.1 這樣的文本到影像模型建立出可見度更高的可行設計影像。雖然在可行性和新穎性之間觀察到了一般的權衡，但當提示權重保持在 0.35 左右的較低水準時，設計的可行性會顯著提升，而其新穎性則與僅由文字提示產生的設計保持一致。這個案例研究的見解為選擇適當的 CAD 影像提示權重以利於工程設計流程的不同階段提供了一些準則。當有效運用時，我們的 CAD 影像提示方法為文本到影像模型在工程設計中更廣泛的應用開啟了大門。

##### **Uncertainty Estimation of Large Language Models in Medical Question Answering**
2407.08662v1 by Jiaxin Wu, Yizhou Yu, Hong-Yu Zhou

Large Language Models (LLMs) show promise for natural language generation in
healthcare, but risk hallucinating factually incorrect information. Deploying
LLMs for medical question answering necessitates reliable uncertainty
estimation (UE) methods to detect hallucinations. In this work, we benchmark
popular UE methods with different model sizes on medical question-answering
datasets. Our results show that current approaches generally perform poorly in
this domain, highlighting the challenge of UE for medical applications. We also
observe that larger models tend to yield better results, suggesting a
correlation between model size and the reliability of UE. To address these
challenges, we propose Two-phase Verification, a probability-free Uncertainty
Estimation approach. First, an LLM generates a step-by-step explanation
alongside its initial answer, followed by formulating verification questions to
check the factual claims in the explanation. The model then answers these
questions twice: first independently, and then referencing the explanation.
Inconsistencies between the two sets of answers measure the uncertainty in the
original response. We evaluate our approach on three biomedical
question-answering datasets using Llama 2 Chat models and compare it against
the benchmarked baseline methods. The results show that our Two-phase
Verification method achieves the best overall accuracy and stability across
various datasets and model sizes, and its performance scales as the model size
increases.

摘要：大型語言模型 (LLM) 在醫療保健領域的自然語言生成方面顯示出前景，但存在虛構事實不正確資訊的風險。部署 LLM 來回答醫療問題需要可靠的不確定性估計 (UE) 方法來偵測虛構。在這項工作中，我們使用不同模型大小對熱門 UE 方法進行基準測試，針對醫療問題回答資料集。我們的結果顯示，目前的作法在這方面通常表現不佳，突顯了 UE 在醫療應用中的挑戰。我們還觀察到，較大的模型往往會產生更好的結果，這表明模型大小與 UE 的可靠性之間存在相關性。為了應對這些挑戰，我們提出了兩階段驗證，一種無機率的不確定性估計方法。首先，LLM 會在其初始答案旁邊產生逐步說明，然後制定驗證問題來檢查說明中的事實聲明。然後，模型回答這些問題兩次：第一次獨立回答，然後參考說明。兩組答案之間的不一致性衡量原始回應中的不確定性。我們使用 Llama 2 Chat 模型在三個生物醫學問題回答資料集上評估我們的作法，並將其與基準基準方法進行比較。結果顯示，我們的兩階段驗證方法在各種資料集和模型大小中實現了最佳的整體準確性和穩定性，並且其效能隨著模型大小的增加而擴展。

##### **Confidence-based Estimators for Predictive Performance in Model Monitoring**
2407.08649v1 by Juhani Kivimäki, Jakub Białek, Jukka K. Nurminen, Wojtek Kuberski

After a machine learning model has been deployed into production, its
predictive performance needs to be monitored. Ideally, such monitoring can be
carried out by comparing the model's predictions against ground truth labels.
For this to be possible, the ground truth labels must be available relatively
soon after inference. However, there are many use cases where ground truth
labels are available only after a significant delay, or in the worst case, not
at all. In such cases, directly monitoring the model's predictive performance
is impossible.
  Recently, novel methods for estimating the predictive performance of a model
when ground truth is unavailable have been developed. Many of these methods
leverage model confidence or other uncertainty estimates and are experimentally
compared against a naive baseline method, namely Average Confidence (AC), which
estimates model accuracy as the average of confidence scores for a given set of
predictions. However, until now the theoretical properties of the AC method
have not been properly explored. In this paper, we try to fill this gap by
reviewing the AC method and show that under certain general assumptions, it is
an unbiased and consistent estimator of model accuracy with many desirable
properties. We also compare this baseline estimator against some more complex
estimators empirically and show that in many cases the AC method is able to
beat the others, although the comparative quality of the different estimators
is heavily case-dependent.

摘要：在機器學習模型部署到生產環境後，需要監控其預測效能。理想情況下，這種監控可以透過將模型的預測與真實標籤進行比較來進行。為此，必須在推理後不久就能取得真實標籤。然而，有許多使用案例中的真實標籤只能在延遲一段時間後取得，或在最糟的情況下，根本無法取得。在這種情況下，直接監控模型的預測效能是不可能的。
最近，已經開發出新的方法來估計在沒有真實標籤時模型的預測效能。其中許多方法利用模型信心或其他不確定性估計，並針對一個簡單的基準方法進行實驗比較，也就是平均信心 (AC)，它將模型準確度估計為給定一組預測的信心分數平均值。然而，到目前為止，AC 方法的理論特性尚未得到適當的探討。在本文中，我們試圖透過檢視 AC 方法，並證明在某些一般假設下，它是一個無偏且一致的模型準確度估計器，具有許多理想的特性，來填補這個空白。我們也針對一些更複雜的估計器對這個基準估計器進行經驗比較，並證明在許多情況下，AC 方法能夠勝過其他方法，儘管不同估計器的比較品質高度依賴於案例。

##### **Towards Building Specialized Generalist AI with System 1 and System 2 Fusion**
2407.08642v1 by Kaiyan Zhang, Biqing Qi, Bowen Zhou

In this perspective paper, we introduce the concept of Specialized Generalist
Artificial Intelligence (SGAI or simply SGI) as a crucial milestone toward
Artificial General Intelligence (AGI). Compared to directly scaling general
abilities, SGI is defined as AI that specializes in at least one task,
surpassing human experts, while also retaining general abilities. This fusion
path enables SGI to rapidly achieve high-value areas. We categorize SGI into
three stages based on the level of mastery over professional skills and
generality performance. Additionally, we discuss the necessity of SGI in
addressing issues associated with large language models, such as their
insufficient generality, specialized capabilities, uncertainty in innovation,
and practical applications. Furthermore, we propose a conceptual framework for
developing SGI that integrates the strengths of Systems 1 and 2 cognitive
processing. This framework comprises three layers and four key components,
which focus on enhancing individual abilities and facilitating collaborative
evolution. We conclude by summarizing the potential challenges and suggesting
future directions. We hope that the proposed SGI will provide insights into
further research and applications towards achieving AGI.

摘要：<paragraph>在本文中，我們引入了專業通才人工智慧 (SGAI 或簡稱 SGI) 的概念，視為邁向人工通用智慧 (AGI) 的關鍵里程碑。與直接擴展一般能力相比，SGI 被定義為至少在一個任務中表現優於人類專家的 AI，同時也保留一般能力。這種融合路徑使 SGI 能夠快速實現高價值領域。我們根據對專業技能和一般性表現的掌握程度，將 SGI 分為三個階段。此外，我們討論了在解決與大型語言模型相關的問題（例如它們的普遍性不足、專業能力、創新中的不確定性和實際應用）中 SGI 的必要性。此外，我們提出了整合系統 1 和 2 認知處理優勢的 SGI 開發概念框架。此框架包含三層和四個關鍵組成部分，重點在於增強個人能力和促進協作演進。最後，我們總結了潛在挑戰並提出了未來的方向。我們希望提出的 SGI 能為進一步的研究和應用提供見解，以實現 AGI。</paragraph>

##### **$β$-DPO: Direct Preference Optimization with Dynamic $β$**
2407.08639v1 by Junkang Wu, Yuexiang Xie, Zhengyi Yang, Jiancan Wu, Jinyang Gao, Bolin Ding, Xiang Wang, Xiangnan He

Direct Preference Optimization (DPO) has emerged as a compelling approach for
training Large Language Models (LLMs) to adhere to human preferences. However,
the performance of DPO is sensitive to the fine-tuning of its trade-off
parameter $\beta$, as well as to the quality of the preference data. We analyze
the impact of $\beta$ and data quality on DPO, uncovering that optimal $\beta$
values vary with the informativeness of pairwise data. Addressing the
limitations of static $\beta$ values, we introduce a novel framework that
dynamically calibrates $\beta$ at the batch level, informed by data quality
considerations. Additionally, our method incorporates $\beta$-guided data
filtering to safeguard against the influence of outliers. Through empirical
evaluation, we demonstrate that our dynamic $\beta$ adjustment technique
significantly improves DPO's performance across a range of models and datasets,
offering a more robust and adaptable training paradigm for aligning LLMs with
human feedback. The code is available at
\url{https://github.com/junkangwu/beta-DPO}.

摘要：直接偏好最佳化 (DPO) 已成為訓練大型語言模型 (LLM) 以符合人類偏好的引人注目的方法。然而，DPO 的效能對其折衷參數 $\beta$ 的微調以及偏好資料的品質很敏感。我們分析了 $\beta$ 和資料品質對 DPO 的影響，發現最佳 $\beta$ 值會隨著成對資料的資訊量而有所不同。針對靜態 $\beta$ 值的限制，我們引入了在批次層級動態校準 $\beta$ 的新穎架構，並根據資料品質考量提供資訊。此外，我們的技術結合了 $\beta$ 引導資料過濾，以防止異常值的影響。透過實證評估，我們證明了我們的動態 $\beta$ 調整技術大幅改善了 DPO 在各種模型和資料集上的效能，為與人類回饋對齊 LLM 提供了更穩健且適應性更強的訓練範例。程式碼可在
\url{https://github.com/junkangwu/beta-DPO} 取得。

##### **Tamil Language Computing: the Present and the Future**
2407.08618v1 by Kengatharaiyer Sarveswaran

This paper delves into the text processing aspects of Language Computing,
which enables computers to understand, interpret, and generate human language.
Focusing on tasks such as speech recognition, machine translation, sentiment
analysis, text summarization, and language modelling, language computing
integrates disciplines including linguistics, computer science, and cognitive
psychology to create meaningful human-computer interactions. Recent
advancements in deep learning have made computers more accessible and capable
of independent learning and adaptation. In examining the landscape of language
computing, the paper emphasises foundational work like encoding, where Tamil
transitioned from ASCII to Unicode, enhancing digital communication. It
discusses the development of computational resources, including raw data,
dictionaries, glossaries, annotated data, and computational grammars, necessary
for effective language processing. The challenges of linguistic annotation, the
creation of treebanks, and the training of large language models are also
covered, emphasising the need for high-quality, annotated data and advanced
language models. The paper underscores the importance of building practical
applications for languages like Tamil to address everyday communication needs,
highlighting gaps in current technology. It calls for increased research
collaboration, digitization of historical texts, and fostering digital usage to
ensure the comprehensive development of Tamil language processing, ultimately
enhancing global communication and access to digital services.

摘要：這篇論文深入探討語言運算的文字處理面向，
讓電腦能夠理解、詮釋和產生人類語言。
專注於語音辨識、機器翻譯、情緒分析、文字摘要和語言建模等任務，語言運算
整合了語言學、電腦科學和認知心理學等領域，以創造有意義的人機互動。最近
深度學習的進展讓電腦更易於使用，並且能夠獨立學習和適應。在探討語言運算的領域時，這篇論文強調了基礎工作，例如編碼，其中淡米爾語
從 ASCII 轉換為 Unicode，增強了數位通訊。它討論了運算資源的發展，包括原始資料、
字典、詞彙表、註釋資料和運算文法，這些對於有效的語言處理是必要的。語言註釋的挑戰、樹庫的建立和大型語言模型的訓練也涵蓋在內，強調了對高品質、註釋資料和進階
語言模型的需求。這篇論文強調了建構實用的應用程式以滿足淡米爾語等語言的日常溝通需求的重要性，並強調了當前技術的差距。它呼籲加強研究合作、歷史文本的數位化和促進數位使用，以確保淡米爾語處理的全面發展，最終增強全球通訊和數位服務的取得。

##### **FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision**
2407.08608v1 by Jay Shah, Ganesh Bikshandi, Ying Zhang, Vijay Thakkar, Pradeep Ramani, Tri Dao

Attention, as a core layer of the ubiquitous Transformer architecture, is the
bottleneck for large language models and long-context applications.
FlashAttention elaborated an approach to speed up attention on GPUs through
minimizing memory reads/writes. However, it has yet to take advantage of new
capabilities present in recent hardware, with FlashAttention-2 achieving only
35% utilization on the H100 GPU. We develop three main techniques to speed up
attention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to
(1) overlap overall computation and data movement via warp-specialization and
(2) interleave block-wise matmul and softmax operations, and (3) block
quantization and incoherent processing that leverages hardware support for FP8
low-precision. We demonstrate that our method, FlashAttention-3, achieves
speedup on H100 GPUs by 1.5-2.0$\times$ with FP16 reaching up to 740 TFLOPs/s
(75% utilization), and with FP8 reaching close to 1.2 PFLOPs/s. We validate
that FP8 FlashAttention-3 achieves 2.6$\times$ lower numerical error than a
baseline FP8 attention.

摘要：注意力，作為無處不在的 Transformer 架構的核心層，是大型語言模型和長語境應用程式的瓶頸。
FlashAttention 透過最小化記憶體讀取/寫入，闡述了一種在 GPU 上加速注意力的方法。然而，它尚未利用最新硬體中存在的新功能，而 FlashAttention-2 在 H100 GPU 上僅達到 35% 的利用率。我們開發了三種主要技術來加速 Hopper GPU 上的注意力：利用張量核心的異步性和 TMA 來 (1) 透過扭曲專門化重疊整體運算和資料移動，以及 (2) 交錯區塊矩陣乘法和 softmax 運算，以及 (3) 利用硬體對 FP8 低精度的支援來進行區塊量化和非相干處理。我們證明我們的 FlashAttention-3 方法，在 H100 GPU 上透過 FP16 達到 1.5-2.0 倍的加速，最高可達 740 TFLOP/s（75% 利用率），而透過 FP8 接近 1.2 PFLOP/s。我們驗證 FP8 FlashAttention-3 比基線 FP8 注意力獲得低 2.6 倍的數值誤差。

##### **Turn-Level Empathy Prediction Using Psychological Indicators**
2407.08607v1 by Shaz Furniturewala, Kokil Jaidka

For the WASSA 2024 Empathy and Personality Prediction Shared Task, we propose
a novel turn-level empathy detection method that decomposes empathy into six
psychological indicators: Emotional Language, Perspective-Taking, Sympathy and
Compassion, Extroversion, Openness, and Agreeableness. A pipeline of text
enrichment using a Large Language Model (LLM) followed by DeBERTA fine-tuning
demonstrates a significant improvement in the Pearson Correlation Coefficient
and F1 scores for empathy detection, highlighting the effectiveness of our
approach. Our system officially ranked 7th at the CONV-turn track.

摘要：對於 WASSA 2024 同理心與人格預測共享任務，我們提出了一種新穎的回合級同理心偵測方法，將同理心分解為六個心理指標：情緒語言、觀點採擇、同情與憐憫、外向性、開放性，以及親和性。使用大型語言模型 (LLM) 進行文本豐富化，接著進行 DeBERTA 微調的管線，在同理心偵測的 Pearson 相關係數和 F1 得分方面顯著提升，突顯了我們方法的有效性。我們的系統在 CONV-turn 軌道中正式排名第 7。

##### **The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective**
2407.08583v1 by Zhen Qin, Daoyuan Chen, Wenhao Zhang, Liuyi Yao, Yilun Huang, Bolin Ding, Yaliang Li, Shuiguang Deng

The rapid development of large language models (LLMs) has been witnessed in
recent years. Based on the powerful LLMs, multi-modal LLMs (MLLMs) extend the
modality from text to a broader spectrum of domains, attracting widespread
attention due to the broader range of application scenarios. As LLMs and MLLMs
rely on vast amounts of model parameters and data to achieve emergent
capabilities, the importance of data is receiving increasingly widespread
attention and recognition. Tracing and analyzing recent data-oriented works for
MLLMs, we find that the development of models and data is not two separate
paths but rather interconnected. On the one hand, vaster and higher-quality
data contribute to better performance of MLLMs, on the other hand, MLLMs can
facilitate the development of data. The co-development of multi-modal data and
MLLMs requires a clear view of 1) at which development stage of MLLMs can
specific data-centric approaches be employed to enhance which capabilities, and
2) by utilizing which capabilities and acting as which roles can models
contribute to multi-modal data. To promote the data-model co-development for
MLLM community, we systematically review existing works related to MLLMs from
the data-model co-development perspective. A regularly maintained project
associated with this survey is accessible at
https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md.

摘要：<paragraph>近年來見證了大型語言模型 (LLM) 的快速發展。基於強大的 LLM，多模態 LLM (MLLM) 將模態從文本擴展到更廣泛的領域，由於應用場景更廣泛，因此備受關注。由於 LLM 和 MLLM 依賴大量的模型參數和資料才能實現新興能力，因此資料的重要性越來越受到廣泛關注和認可。追蹤和分析針對 MLLM 的最新資料導向工作，我們發現模型和資料的發展並非兩條獨立的道路，而是相互關聯的。一方面，更大且品質更高的資料有助於提升 MLLM 的效能，另一方面，MLLM 可以促進資料的發展。多模態資料和 MLLM 的共同開發需要明確了解 1) 在 MLLM 的哪個開發階段可以採用特定的資料中心方法來增強哪些能力，以及 2) 模型可以利用哪些能力並扮演哪些角色來貢獻多模態資料。為了促進 MLLM 社群的資料模型共同開發，我們從資料模型共同開發的角度系統性地回顧與 MLLM 相關的現有工作。與這項調查相關的定期維護專案可於 https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md 取得。</paragraph>

##### **On the Universal Truthfulness Hyperplane Inside LLMs**
2407.08582v1 by Junteng Liu, Shiqi Chen, Yu Cheng, Junxian He

While large language models (LLMs) have demonstrated remarkable abilities
across various fields, hallucination remains a significant challenge. Recent
studies have explored hallucinations through the lens of internal
representations, proposing mechanisms to decipher LLMs' adherence to facts.
However, these approaches often fail to generalize to out-of-distribution data,
leading to concerns about whether internal representation patterns reflect
fundamental factual awareness, or only overfit spurious correlations on the
specific datasets. In this work, we investigate whether a universal
truthfulness hyperplane that distinguishes the model's factually correct and
incorrect outputs exists within the model. To this end, we scale up the number
of training datasets and conduct an extensive evaluation -- we train the
truthfulness hyperplane on a diverse collection of over 40 datasets and examine
its cross-task, cross-domain, and in-domain generalization. Our results
indicate that increasing the diversity of the training datasets significantly
enhances the performance in all scenarios, while the volume of data samples
plays a less critical role. This finding supports the optimistic hypothesis
that a universal truthfulness hyperplane may indeed exist within the model,
offering promising directions for future research.

摘要：儘管大型語言模型 (LLM) 已在各個領域展現出卓越的能力，但幻覺仍是一項嚴峻的挑戰。最近的研究透過內部表徵的觀點探討幻覺，提出機制來解碼 LLM 對事實的堅持。然而，這些方法通常無法廣泛化到分佈外資料，導致人們擔憂內部表徵模式是否反映了基本的現實意識，或僅過度擬合特定資料集上的虛假關聯。在這項工作中，我們探討模型內是否存在一個通用的真實性超平面，用以區分模型的事實正確輸出和不正確輸出。為此，我們擴大了訓練資料集的數量並進行廣泛評估——我們在超過 40 個資料集的多元集合上訓練真實性超平面，並檢查其跨任務、跨領域和領域內廣義化。我們的結果表明，增加訓練資料集的多樣性會顯著提升所有場景中的效能，而資料樣本的數量則扮演較不重要的角色。此發現支持樂觀的假設，即模型內可能確實存在一個通用的真實性超平面，為未來的研究提供了有前景的方向。

##### **The Career Interests of Large Language Models**
2407.08564v1 by Meng Hua, Yuan Cheng, Hengshu Zhu

Recent advancements in Large Language Models (LLMs) have significantly
extended their capabilities, evolving from basic text generation to complex,
human-like interactions. In light of the possibilities that LLMs could assume
significant workplace responsibilities, it becomes imminently necessary to
explore LLMs' capacities as professional assistants. This study focuses on the
aspect of career interests by applying the Occupation Network's Interest
Profiler short form to LLMs as if they were human participants and investigates
their hypothetical career interests and competence, examining how these vary
with language changes and model advancements. We analyzed the answers using a
general linear mixed model approach and found distinct career interest
inclinations among LLMs, particularly towards the social and artistic domains.
Interestingly, these preferences did not align with the occupations where LLMs
exhibited higher competence. This novel approach of using psychometric
instruments and sophisticated statistical tools on LLMs unveils fresh
perspectives on their integration into professional environments, highlighting
human-like tendencies and promoting a reevaluation of LLMs' self-perception and
competency alignment in the workforce.

摘要：大型語言模型 (LLM) 的最新進展顯著擴展了它們的能力，從基本的文字生成演變到複雜的人類互動。鑑於 LLM 可能承擔重大工作場所責任的可能性，迫切需要探索 LLM 作為專業助理的能力。本研究重點關注職業興趣方面，將職業網絡的興趣分析器簡表應用於 LLM，就像它們是人類參與者一樣，並調查它們的假設職業興趣和能力，探討這些興趣和能力如何隨著語言變化和模型進步而變化。我們使用一般線性混合模型方法分析答案，並發現 LLM 之間有不同的職業興趣傾向，特別是對社會和藝術領域。有趣的是，這些偏好與 LLM 表現出較高能力的職業並不一致。這種在 LLM 上使用心理測量工具和複雜統計工具的新穎方法揭示了它們融入專業環境的新觀點，突出了類人的傾向，並促進了重新評估 LLM 在勞動力中的自我認知和能力一致性。

##### **Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion**
2407.08563v1 by Leah von der Heyde, Anna-Carolina Haensch, Alexander Wenz

The recent development of large language models (LLMs) has spurred
discussions about whether LLM-generated "synthetic samples" could complement or
replace traditional surveys, considering their training data potentially
reflects attitudes and behaviors prevalent in the population. A number of
mostly US-based studies have prompted LLMs to mimic survey respondents, with
some of them finding that the responses closely match the survey data. However,
several contextual factors related to the relationship between the respective
target population and LLM training data might affect the generalizability of
such findings. In this study, we investigate the extent to which LLMs can
estimate public opinion in Germany, using the example of vote choice. We
generate a synthetic sample of personas matching the individual characteristics
of the 2017 German Longitudinal Election Study respondents. We ask the LLM
GPT-3.5 to predict each respondent's vote choice and compare these predictions
to the survey-based estimates on the aggregate and subgroup levels. We find
that GPT-3.5 does not predict citizens' vote choice accurately, exhibiting a
bias towards the Green and Left parties. While the LLM captures the tendencies
of "typical" voter subgroups, such as partisans, it misses the multifaceted
factors swaying individual voter choices. By examining the LLM-based prediction
of voting behavior in a new context, our study contributes to the growing body
of research about the conditions under which LLMs can be leveraged for studying
public opinion. The findings point to disparities in opinion representation in
LLMs and underscore the limitations in applying them for public opinion
estimation.

摘要：<paragraph>大型語言模型 (LLM) 近期發展，引發了關於 LLM 生成的「合成樣本」能否補充或取代傳統調查的討論，考慮到其訓練資料可能反映了在人口中普遍存在的態度和行為。許多主要以美國為基礎的研究促使 LLM 模仿調查受訪者，其中一些研究發現，回應與調查資料非常吻合。然而，與各自目標族群和 LLM 訓練資料之間相關的幾個情境因素，可能會影響此類發現的概括性。在本研究中，我們探討 LLM 在何種程度上可以估計德國的民意，並以投票選擇為例。我們產生了一個合成樣本的人物，其個人特徵與 2017 年德國縱向選舉研究受訪者相符。我們要求 LLM GPT-3.5 預測每個受訪者的投票選擇，並將這些預測與在總體和子群層級上的基於調查的估計值進行比較。我們發現 GPT-3.5 無法準確預測公民的投票選擇，表現出對綠黨和左派的偏見。雖然 LLM 捕捉到了「典型」選民子群的傾向，例如黨派人士，但它錯失了影響個別選民選擇的多方面因素。透過檢視 LLM 為基礎的投票行為預測，在一個新的情境中，我們的研究有助於越來越多的研究，探討在哪些條件下可以利用 LLM 來研究民意。這些發現指出 LLM 中意見代表性的差異，並強調了在民意估計中應用 LLM 的限制。</paragraph>

##### **ST-Mamba: Spatial-Temporal Mamba for Traffic Flow Estimation Recovery using Limited Data**
2407.08558v1 by Doncheng Yuan, Jianzhe Xue, Jinshan Su, Wenchao Xu, Haibo Zhou

Traffic flow estimation (TFE) is crucial for urban intelligent traffic
systems. While traditional on-road detectors are hindered by limited coverage
and high costs, cloud computing and data mining of vehicular network data, such
as driving speeds and GPS coordinates, present a promising and cost-effective
alternative. Furthermore, minimizing data collection can significantly reduce
overhead. However, limited data can lead to inaccuracies and instability in
TFE. To address this, we introduce the spatial-temporal Mamba (ST-Mamba), a
deep learning model combining a convolutional neural network (CNN) with a Mamba
framework. ST-Mamba is designed to enhance TFE accuracy and stability by
effectively capturing the spatial-temporal patterns within traffic flow. Our
model aims to achieve results comparable to those from extensive data sets
while only utilizing minimal data. Simulations using real-world datasets have
validated our model's ability to deliver precise and stable TFE across an urban
landscape based on limited data, establishing a cost-efficient solution for
TFE.

摘要：交通流量估計 (TFE) 對於城市智慧交通系統至關重要。雖然傳統的道路偵測器受到覆蓋範圍有限和成本高的阻礙，但雲端運算和車輛網路資料的資料探勘，例如行駛速度和 GPS 座標，提供了一個有前途且具有成本效益的替代方案。此外，最小化資料收集可以大幅減少開銷。然而，有限的資料可能會導致 TFE 的不準確性和不穩定性。為了解決這個問題，我們引入了時空 Mamba (ST-Mamba)，這是一個結合了卷積神經網路 (CNN) 和 Mamba 框架的深度學習模型。ST-Mamba 旨在透過有效擷取交通流量中的時空模式來增強 TFE 的準確性和穩定性。我們的模型旨在達成與廣泛資料集相當的結果，同時僅使用最少的資料。使用真實世界資料集的模擬驗證了我們的模型在基於有限資料的城市景觀中提供精確且穩定的 TFE 的能力，為 TFE 建立了一個具有成本效益的解決方案。

##### **Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models**
2407.08554v1 by Wanling Gao, Yunyou Huang, Dandan Cui, Zhuoming Yu, Wenjing Liu, Xiaoshuang Liang, Jiahui Zhao, Jiyue Xie, Hao Li, Li Ma, Ning Ye, Yumiao Kang, Dingfeng Luo, Peng Pan, Wei Huang, Zhongmou Liu, Jizhong Hu, Gangyuan Zhao, Chongrong Jiang, Fan Huang, Tianyi Wei, Suqin Tang, Bingjie Xia, Zhifei Zhang, Jianfeng Zhan

A profound gap persists between artificial intelligence (AI) and clinical
practice in medicine, primarily due to the lack of rigorous and cost-effective
evaluation methodologies. State-of-the-art and state-of-the-practice AI model
evaluations are limited to laboratory studies on medical datasets or direct
clinical trials with no or solely patient-centered controls. Moreover, the
crucial role of clinicians in collaborating with AI, pivotal for determining
its impact on clinical practice, is often overlooked. For the first time, we
emphasize the critical necessity for rigorous and cost-effective evaluation
methodologies for AI models in clinical practice, featuring
patient/clinician-centered (dual-centered) AI randomized controlled trials
(DC-AI RCTs) and virtual clinician-based in-silico trials (VC-MedAI) as an
effective proxy for DC-AI RCTs. Leveraging 7500 diagnosis records from
two-phase inaugural DC-AI RCTs across 14 medical centers with 125 clinicians,
our results demonstrate the necessity of DC-AI RCTs and the effectiveness of
VC-MedAI. Notably, VC-MedAI performs comparably to human clinicians,
replicating insights and conclusions from prospective DC-AI RCTs. We envision
DC-AI RCTs and VC-MedAI as pivotal advancements, presenting innovative and
transformative evaluation methodologies for AI models in clinical practice,
offering a preclinical-like setting mirroring conventional medicine, and
reshaping development paradigms in a cost-effective and fast-iterative manner.
Chinese Clinical Trial Registration: ChiCTR2400086816.

摘要：<paragraph>人工智慧（AI）與臨床醫療實務之間存在著巨大的鴻溝，其主要原因在於缺乏嚴謹且具成本效益的評估方法。最先進且符合實務的 AI 模型評估僅限於針對醫學資料集進行的實驗室研究，或僅有患者為中心的對照組的直接臨床試驗。此外，臨床醫師在與 AI 合作中所扮演的關鍵角色，對於決定其對臨床實務的影響至關重要，卻經常被忽視。我們首度強調在臨床實務中採用嚴謹且具成本效益的 AI 模型評估方法至關重要，其特色在於以患者／臨床醫師為中心的（雙中心）AI 隨機對照試驗（DC-AI RCT）和虛擬臨床醫師為基礎的電腦模擬試驗（VC-MedAI），做為 DC-AI RCT 的有效替代方案。利用來自 14 個醫療中心、125 位臨床醫師的兩階段首次 DC-AI RCT 中的 7500 筆診斷紀錄，我們的結果證明了 DC-AI RCT 的必要性與 VC-MedAI 的有效性。值得注意的是，VC-MedAI 的表現與人類臨床醫師相當，複製了前瞻性 DC-AI RCT 的見解和結論。我們將 DC-AI RCT 和 VC-MedAI 視為關鍵的進展，它們提出了創新且具有變革性的 AI 模型評估方法，在臨床實務中提供類似於臨床前設定的環境，反映傳統醫學，並以具成本效益且快速反覆運算的方式重新塑造開發模式。中國臨床試驗註冊：ChiCTR2400086816。</paragraph>

##### **Autoregressive Speech Synthesis without Vector Quantization**
2407.08551v1 by Lingwei Meng, Long Zhou, Shujie Liu, Sanyuan Chen, Bing Han, Shujie Hu, Yanqing Liu, Jinyu Li, Sheng Zhao, Xixin Wu, Helen Meng, Furu Wei

We present MELLE, a novel continuous-valued tokens based language modeling
approach for text to speech synthesis (TTS). MELLE autoregressively generates
continuous mel-spectrogram frames directly from text condition, bypassing the
need for vector quantization, which are originally designed for audio
compression and sacrifice fidelity compared to mel-spectrograms. Specifically,
(i) instead of cross-entropy loss, we apply regression loss with a proposed
spectrogram flux loss function to model the probability distribution of the
continuous-valued tokens. (ii) we have incorporated variational inference into
MELLE to facilitate sampling mechanisms, thereby enhancing the output diversity
and model robustness. Experiments demonstrate that, compared to the two-stage
codec language models VALL-E and its variants, the single-stage MELLE mitigates
robustness issues by avoiding the inherent flaws of sampling discrete codes,
achieves superior performance across multiple metrics, and, most importantly,
offers a more streamlined paradigm. See https://aka.ms/melle for demos of our
work.

摘要：我們提出了 MELLE，一種基於連續值符號的新穎語言模型化方法，用於文字轉語音合成 (TTS)。MELLE 自迴歸地直接從文字條件生成連續的 Mel 頻譜圖幀，繞過了原本設計用於音訊壓縮且與 Mel 頻譜圖相比犧牲了保真度的向量量化需求。具體來說，(i) 我們應用回歸損失，並提出了建議的頻譜圖通量損失函數來建模連續值符號的機率分佈，而不是交叉熵損失。(ii) 我們已將變異推論納入 MELLE，以促進抽樣機制，從而增強輸出多樣性和模型穩健性。實驗證明，與兩階段編解碼器語言模型 VALL-E 及其變體相比，單階段 MELLE 透過避免抽樣離散碼的固有缺陷來減輕穩健性問題，在多項指標上均達到卓越的效能，而且最重要的是，提供更簡化的範例。請參閱 https://aka.ms/melle，瞭解我們工作的示範。

##### **Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility**
2407.08550v1 by Yuchen Xia, Jize Zhang, Nasser Jazdi, Michael Weyrich

This paper introduces a novel approach to integrating large language model
(LLM) agents into automated production systems, aimed at enhancing task
automation and flexibility. We organize production operations within a
hierarchical framework based on the automation pyramid. Atomic operation
functionalities are modeled as microservices, which are executed through
interface invocation within a dedicated digital twin system. This allows for a
scalable and flexible foundation for orchestrating production processes. In
this digital twin system, low-level, hardware-specific data is semantically
enriched and made interpretable for LLMs for production planning and control
tasks. Large language model agents are systematically prompted to interpret
these production-specific data and knowledge. Upon receiving a user request or
identifying a triggering event, the LLM agents generate a process plan. This
plan is then decomposed into a series of atomic operations, executed as
microservices within the real-world automation system. We implement this
overall approach on an automated modular production facility at our laboratory,
demonstrating how the LLMs can handle production planning and control tasks
through a concrete case study. This results in an intuitive production facility
with higher levels of task automation and flexibility. Finally, we reveal the
several limitations in realizing the full potential of the large language
models in autonomous systems and point out promising benefits. Demos of this
series of ongoing research series can be accessed at:
https://github.com/YuchenXia/GPT4IndustrialAutomation

摘要：這篇論文介紹一種新穎的方法，將大型語言模型 (LLM) 代理整合到自動化生產系統中，旨在增強任務自動化和靈活性。我們在基於自動化金字塔的分層架構中組織生產作業。原子操作功能被建模成微服務，這些微服務通過專用數位雙胞胎系統中的介面呼叫來執行。這為編排生產流程提供了可擴充且彈性的基礎。在此數位雙胞胎系統中，低階、特定於硬體的資料會被語意化豐富化，並讓 LLM 能夠詮釋，以進行生產規劃和控制任務。大型語言模型代理會被系統性地提示，以詮釋這些特定於生產的資料和知識。在收到使用者要求或識別觸發事件後，LLM 代理會產生流程計畫。然後，此計畫會分解成一系列原子操作，並在真實世界的自動化系統中以微服務的形式執行。我們在實驗室的自動化模組化生產設施中實作此整體方法，並透過具體案例研究展示 LLM 如何處理生產規劃和控制任務。這會產生一個直覺式的生產設施，並具有更高層級的任務自動化和靈活性。最後，我們揭露了在自體系統中實現大型語言模型全部潛力的若干限制，並指出有希望的好處。可以透過以下網址存取這個持續研究系列的展示：
https://github.com/YuchenXia/GPT4IndustrialAutomation

##### **Emergent Visual-Semantic Hierarchies in Image-Text Representations**
2407.08521v1 by Morris Alper, Hadar Averbuch-Elor

While recent vision-and-language models (VLMs) like CLIP are a powerful tool
for analyzing text and images in a shared semantic space, they do not
explicitly model the hierarchical nature of the set of texts which may describe
an image. Conversely, existing multimodal hierarchical representation learning
methods require costly training from scratch, failing to leverage the knowledge
encoded by state-of-the-art multimodal foundation models. In this work, we
study the knowledge of existing foundation models, finding that they exhibit
emergent understanding of visual-semantic hierarchies despite not being
directly trained for this purpose. We propose the Radial Embedding (RE)
framework for probing and optimizing hierarchical understanding, and contribute
the HierarCaps dataset, a benchmark facilitating the study of hierarchical
knowledge in image--text representations, constructed automatically via large
language models. Our results show that foundation VLMs exhibit zero-shot
hierarchical understanding, surpassing the performance of prior models
explicitly designed for this purpose. Furthermore, we show that foundation
models may be better aligned to hierarchical reasoning via a text-only
fine-tuning phase, while retaining pretraining knowledge.

摘要：雖然像 CLIP 等最近的視覺語言模型 (VLM) 是用於在共享語義空間中分析文字和影像的強大工具，但它們並未明確建模可能描述影像的文字集合的層級性質。相反地，現有的多模態層級表徵學習方法需要從頭開始進行昂貴的訓練，無法利用由最先進的多模態基礎模型編碼的知識。在這項工作中，我們研究了現有基礎模型的知識，發現它們表現出對視覺語義層級的理解，儘管並未直接針對此目的進行訓練。我們提出了徑向嵌入 (RE) 框架，用於探測和最佳化層級理解，並貢獻了 HierarCaps 資料集，這是一個基於大型語言模型自動建構的基準，促進了對影像文字表徵中層級知識的研究。我們的結果顯示，基礎 VLM 表現出零次學習的層級理解，超越了先前專門為此目的設計的模型的效能。此外，我們顯示基礎模型可能會透過僅文字的微調階段與層級推理更好地對齊，同時保留預訓練知識。

##### **Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**
2407.08516v1 by Haoyi Xiong, Zhiyuan Wang, Xuhong Li, Jiang Bian, Zeke Xie, Shahid Mumtaz, Laura E. Barnes

This article explores the convergence of connectionist and symbolic
artificial intelligence (AI), from historical debates to contemporary
advancements. Traditionally considered distinct paradigms, connectionist AI
focuses on neural networks, while symbolic AI emphasizes symbolic
representation and logic. Recent advancements in large language models (LLMs),
exemplified by ChatGPT and GPT-4, highlight the potential of connectionist
architectures in handling human language as a form of symbols. The study argues
that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence.
By utilizing LLMs for text-based knowledge modeling and representation, LAAs
integrate neuro-symbolic AI principles, showcasing enhanced reasoning and
decision-making capabilities. Comparing LAAs with Knowledge Graphs within the
neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking
human-like reasoning processes, scaling effectively with large datasets, and
leveraging in-context samples without explicit re-training. The research
underscores promising avenues in neuro-vector-symbolic integration,
instructional encoding, and implicit reasoning, aimed at further enhancing LAA
capabilities. By exploring the progression of neuro-symbolic AI and proposing
future research trajectories, this work advances the understanding and
development of AI technologies.

摘要：這篇文章探討了連接主義與符號人工智慧 (AI) 的匯流，從歷史辯論到當代進展。傳統上被認為是不同的典範，連接主義 AI 專注於神經網路，而符號 AI 則強調符號表徵與邏輯。大型語言模型 (LLM) 的最新進展，以 ChatGPT 和 GPT-4 為例，突顯了連接主義架構在將人類語言視為符號形式處理的潛力。該研究論證，由 LLM 賦能的自主代理 (LAA) 體現了這種典範的匯流。透過利用 LLM 進行基於文字的知識建模與表徵，LAA 整合了神經符號 AI 原則，展示增強的推理和決策能力。在神經符號 AI 主題中將 LAA 與知識圖譜進行比較，突顯了 LAA 在模擬類人推理過程、有效擴充大型資料集以及在沒有明確重新訓練的情況下利用情境範例中的獨特優勢。該研究強調了神經向量符號整合、指令編碼和隱式推理中具有前景的途徑，旨在進一步增強 LAA 的能力。透過探討神經符號 AI 的進展並提出未來的研究軌跡，這項研究推動了對 AI 技術的理解和發展。

##### **15M Multimodal Facial Image-Text Dataset**
2407.08515v2 by Dawei Dai, YuTang Li, YingGe Liu, Mingming Jia, Zhang YuanHui, Guoyin Wang

Currently, image-text-driven multi-modal deep learning models have
demonstrated their outstanding potential in many fields. In practice, tasks
centered around facial images have broad application prospects. This paper
presents \textbf{FaceCaption-15M}, a large-scale, diverse, and high-quality
dataset of facial images accompanied by their natural language descriptions
(facial image-to-text). This dataset aims to facilitate a study on
face-centered tasks. FaceCaption-15M comprises over 15 million pairs of facial
images and their corresponding natural language descriptions of facial
features, making it the largest facial image-caption dataset to date. We
conducted a comprehensive analysis of image quality, text naturalness, text
complexity, and text-image relevance to demonstrate the superiority of
FaceCaption-15M. To validate the effectiveness of FaceCaption-15M, we first
trained a facial language-image pre-training model (FLIP, similar to CLIP) to
align facial image with its corresponding captions in feature space.
Subsequently, using both image and text encoders and fine-tuning only the
linear layer, our FLIP-based models achieved state-of-the-art results on two
challenging face-centered tasks. The purpose is to promote research in the
field of face-related tasks through the availability of the proposed
FaceCaption-15M dataset. All data, codes, and models are publicly available.
https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M

摘要：目前，图像文本驱动的多模态深度学习模型已在许多领域展现出其卓越的潜力。在实践中，围绕面部图像的任务具有广泛的应用前景。本文提出了 FaceCaption-15M，这是一个包含面部图像及其自然语言描述（面部图像到文本）的大规模、多样化且高质量的数据集。此数据集旨在促进对以面部为中心的任务的研究。FaceCaption-15M 包含超过 1500 万对面部图像及其对应面部特征的自然语言描述，使其成为迄今为止最大的面部图像标题数据集。我们对图像质量、文本自然度、文本复杂度和文本图像相关性进行了全面分析，以证明 FaceCaption-15M 的优越性。为了验证 FaceCaption-15M 的有效性，我们首先训练了一个面部语言图像预训练模型（FLIP，类似于 CLIP），以在特征空间中将面部图像与其对应的标题对齐。随后，使用图像和文本编码器，并且只微调线性层，我们基于 FLIP 的模型在两个具有挑战性的以面部为中心的任务上取得了最先进的结果。目的是通过提供所提出的 FaceCaption-15M 数据集来促进面部相关任务领域的研究。所有数据、代码和模型都是公开的。https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M

##### **Latent Conditional Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph Mode**
2407.08500v1 by Yuxing Tian, Yiyan Qi, Aiwen Jiang, Qi Huang, Jian Guo

Continuous-Time Dynamic Graph (CTDG) precisely models evolving real-world
relationships, drawing heightened interest in dynamic graph learning across
academia and industry. However, existing CTDG models encounter challenges
stemming from noise and limited historical data. Graph Data Augmentation (GDA)
emerges as a critical solution, yet current approaches primarily focus on
static graphs and struggle to effectively address the dynamics inherent in
CTDGs. Moreover, these methods often demand substantial domain expertise for
parameter tuning and lack theoretical guarantees for augmentation efficacy. To
address these issues, we propose Conda, a novel latent diffusion-based GDA
method tailored for CTDGs. Conda features a sandwich-like architecture,
incorporating a Variational Auto-Encoder (VAE) and a conditional diffusion
model, aimed at generating enhanced historical neighbor embeddings for target
nodes. Unlike conventional diffusion models trained on entire graphs via
pre-training, Conda requires historical neighbor sequence embeddings of target
nodes for training, thus facilitating more targeted augmentation. We integrate
Conda into the CTDG model and adopt an alternating training strategy to
optimize performance. Extensive experimentation across six widely used
real-world datasets showcases the consistent performance improvement of our
approach, particularly in scenarios with limited historical data.

摘要：連續時間動態圖 (CTDG) 精確地模擬了演化的真實世界關係，引起了學術界和產業對動態圖學習的高度興趣。然而，現有的 CTDG 模型會遇到源自於雜訊和有限歷史資料的挑戰。圖資料擴充 (GDA) 成為了一個關鍵的解決方案，但目前的做法主要專注於靜態圖，並難以有效地解決 CTDG 中固有的動態問題。此外，這些方法通常需要大量的領域專業知識來進行參數調整，並且缺乏理論保證來確保擴充的效能。為了解決這些問題，我們提出了 Conda，這是一種針對 CTDG 量身打造的新型潛在擴散式 GDA 方法。Conda 採用三明治式的架構，結合了變異自動編碼器 (VAE) 和條件擴散模型，旨在為目標節點產生增強的歷史鄰居嵌入。與透過預訓練在整個圖上訓練的傳統擴散模型不同，Conda 需要目標節點的歷史鄰居序列嵌入來進行訓練，從而促進更具針對性的擴充。我們將 Conda 整合到 CTDG 模型中，並採用交替訓練策略來最佳化效能。在六個廣泛使用的真實世界資料集上進行的廣泛實驗，展示了我們的方法一致的效能提升，特別是在歷史資料有限的情況下。

##### **Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024**
2407.08495v1 by Ilias Chalkidis

Instruction-finetuned Large Language Models exhibit unprecedented Natural
Language Understanding capabilities. Recent work has been exploring political
biases and political reasoning capabilities in LLMs, mainly scoped in the US
context. In light of the recent 2024 European Parliament elections, we are
investigating if LLMs can be used as Voting Advice Applications (VAAs). We
audit MISTRAL and MIXTRAL models and evaluate their accuracy in predicting the
stance of political parties based on the latest "EU and I" voting assistance
questionnaire. Furthermore, we explore alternatives to improve models'
performance by augmenting the input context via Retrieval-Augmented Generation
(RAG) relying on web search, and Self-Reflection using staged conversations
that aim to re-collect relevant content from the model's internal memory. We
find that MIXTRAL is highly accurate with an 82% accuracy on average.
Augmenting the input context with expert-curated information can lead to a
significant boost of approx. 9%, which remains an open challenge for automated
approaches.

摘要：經過指令微調的大型語言模型展現出前所未有的自然語言理解能力。最近的研究探索了大型語言模型的政治偏見和政治推理能力，主要集中在美國的背景下。鑑於最近 2024 年歐洲議會選舉，我們正在調查大型語言模型是否可用作投票建議應用程式 (VAA)。我們審查 MISTRAL 和 MIXTRAL 模型，並根據最新的「歐盟和我」投票協助問卷評估它們在預測政黨立場方面的準確性。此外，我們探索了通過檢索增強生成 (RAG)（依賴網路搜尋）和使用旨在從模型內部記憶體重新收集相關內容的分階段對話的自省來擴充輸入內容以改善模型效能的替代方案。我們發現 MIXTRAL 非常準確，平均準確度為 82%。使用專家策劃的資訊擴充輸入內容可能會導致約 9% 的顯著提升，這對於自動化方法來說仍然是一個公開的挑戰。

##### **Lynx: An Open Source Hallucination Evaluation Model**
2407.08488v1 by Selvan Sunitha Ravi, Bartosz Mielczarek, Anand Kannappan, Douwe Kiela, Rebecca Qian

Retrieval Augmented Generation (RAG) techniques aim to mitigate
hallucinations in Large Language Models (LLMs). However, LLMs can still produce
information that is unsupported or contradictory to the retrieved contexts. We
introduce LYNX, a SOTA hallucination detection LLM that is capable of advanced
reasoning on challenging real-world hallucination scenarios. To evaluate LYNX,
we present HaluBench, a comprehensive hallucination evaluation benchmark,
consisting of 15k samples sourced from various real-world domains. Our
experiment results show that LYNX outperforms GPT-4o, Claude-3-Sonnet, and
closed and open-source LLM-as-a-judge models on HaluBench. We release LYNX,
HaluBench and our evaluation code for public access.

摘要：檢索增強生成（RAG）技術旨在減輕大型語言模型（LLM）中的幻覺。然而，LLM 仍然會產生不受支持或與檢索的背景相矛盾的資訊。我們介紹 LYNX，一種 SOTA 幻覺偵測 LLM，它能夠對具有挑戰性的真實世界幻覺場景進行高級推理。為了評估 LYNX，我們提出了 HaluBench，一個全面的幻覺評估基準，由來自各種真實世界領域的 15k 個範例組成。我們的實驗結果表明，LYNX 在 HaluBench 上優於 GPT-4o、Claude-3-Sonnet，以及封閉和開放原始碼 LLM 作為評審模型。我們釋出 LYNX、HaluBench 和我們的評估程式碼供公眾使用。

##### **Investigating Public Fine-Tuning Datasets: A Complex Review of Current Practices from a Construction Perspective**
2407.08475v1 by Runyuan Ma, Wei Li, Fukai Shang

With the rapid development of the large model domain, research related to
fine-tuning has concurrently seen significant advancement, given that
fine-tuning is a constituent part of the training process for large-scale
models. Data engineering plays a fundamental role in the training process of
models, which includes data infrastructure, data processing, etc. Data during
fine-tuning likewise forms the base for large models. In order to embrace the
power and explore new possibilities of fine-tuning datasets, this paper reviews
current public fine-tuning datasets from the perspective of data construction.
An overview of public fine-tuning datasets from two sides: evolution and
taxonomy, is provided in this review, aiming to chart the development
trajectory. Construction techniques and methods for public fine-tuning datasets
of Large Language Models (LLMs), including data generation and data
augmentation among others, are detailed. This elaboration follows the
aforementioned taxonomy, specifically across demonstration, comparison, and
generalist categories. Additionally, a category tree of data generation
techniques has been abstracted in our review to assist researchers in gaining a
deeper understanding of fine-tuning datasets from the construction dimension.
Our review also summarizes the construction features in different data
preparation phases of current practices in this field, aiming to provide a
comprehensive overview and inform future research. Fine-tuning dataset
practices, encompassing various data modalities, are also discussed from a
construction perspective in our review. Towards the end of the article, we
offer insights and considerations regarding the future construction and
developments of fine-tuning datasets.

摘要：<paragraph>隨著大型模型領域的快速發展，與微調相關的研究也取得了顯著進展，因為微調是大型模型訓練過程的組成部分。資料工程在模型的訓練過程中扮演著基礎性的角色，其中包括資料基礎設施、資料處理等。微調期間的資料同樣構成了大型模型的基礎。為了擁抱微調資料集的力量並探索新的可能性，本文從資料構建的角度回顧了當前公開的微調資料集。本文從演進和分類兩個方面概述了公開微調資料集，旨在描繪其發展軌跡。詳細介紹了大型語言模型 (LLM) 的公開微調資料集的構建技術和方法，包括資料生成和資料擴充等。這種闡述遵循上述分類法，特別是在示範、比較和通才類別中。此外，本文還抽象了一個資料生成技術的類別樹，以幫助研究人員從構建維度更深入地理解微調資料集。本文還總結了當前該領域實務中不同資料準備階段的構建特徵，旨在提供全面的概述並為未來的研究提供資訊。本文還從構建的角度討論了涵蓋各種資料模式的微調資料集實務。在本文的最後，我們提供了對微調資料集未來構建和發展的見解和考量。</paragraph>

##### **Natural language is not enough: Benchmarking multi-modal generative AI for Verilog generation**
2407.08473v1 by Kaiyan Chang, Zhirong Chen, Yunhao Zhou, Wenlong Zhu, kun wang, Haobo Xu, Cangyuan Li, Mengdi Wang, Shengwen Liang, Huawei Li, Yinhe Han, Ying Wang

Natural language interfaces have exhibited considerable potential in the
automation of Verilog generation derived from high-level specifications through
the utilization of large language models, garnering significant attention.
Nevertheless, this paper elucidates that visual representations contribute
essential contextual information critical to design intent for hardware
architectures possessing spatial complexity, potentially surpassing the
efficacy of natural-language-only inputs. Expanding upon this premise, our
paper introduces an open-source benchmark for multi-modal generative models
tailored for Verilog synthesis from visual-linguistic inputs, addressing both
singular and complex modules. Additionally, we introduce an open-source visual
and natural language Verilog query language framework to facilitate efficient
and user-friendly multi-modal queries. To evaluate the performance of the
proposed multi-modal hardware generative AI in Verilog generation tasks, we
compare it with a popular method that relies solely on natural language. Our
results demonstrate a significant accuracy improvement in the multi-modal
generated Verilog compared to queries based solely on natural language. We hope
to reveal a new approach to hardware design in the large-hardware-design-model
era, thereby fostering a more diversified and productive approach to hardware
design.

摘要：自然語言介面在透過利用大型語言模型，從高階規格中自動生成 Verilog 上展現出相當的潛力，並因此獲得大量的關注。然而，本論文闡明了視覺表徵提供了對硬體架構設計意圖至關重要的背景資訊，其空間複雜性可能超越僅使用自然語言輸入的效能。本論文在這個前提下進一步延伸，介紹了一個開放原始碼基準，用於針對視覺語言輸入進行 Verilog 合成的多模式生成模型，並同時處理單一和複雜的模組。此外，我們還介紹了一個開放原始碼的視覺和自然語言 Verilog 查詢語言架構，以利進行有效且使用者友善的多模式查詢。為了評估所提出的多模式硬體生成 AI 在 Verilog 生成任務中的效能，我們將其與一種僅依賴自然語言的熱門方法進行比較。我們的結果顯示，與僅基於自然語言的查詢相比，多模式生成的 Verilog 在準確性上有顯著的提升。我們希望在大型硬體設計模型時代揭示硬體設計的新方法，從而促進更多元化且高生產力的硬體設計方法。

##### **Brain Tumor Segmentation in MRI Images with 3D U-Net and Contextual Transformer**
2407.08470v1 by Thien-Qua T. Nguyen, Hieu-Nghia Nguyen, Thanh-Hieu Bui, Thien B. Nguyen-Tat, Vuong M. Ngo

This research presents an enhanced approach for precise segmentation of brain
tumor masses in magnetic resonance imaging (MRI) using an advanced 3D-UNet
model combined with a Context Transformer (CoT). By architectural expansion
CoT, the proposed model extends its architecture to a 3D format, integrates it
smoothly with the base model to utilize the complex contextual information
found in MRI scans, emphasizing how elements rely on each other across an
extended spatial range. The proposed model synchronizes tumor mass
characteristics from CoT, mutually reinforcing feature extraction, facilitating
the precise capture of detailed tumor mass structures, including location,
size, and boundaries. Several experimental results present the outstanding
segmentation performance of the proposed method in comparison to current
state-of-the-art approaches, achieving Dice score of 82.0%, 81.5%, 89.0% for
Enhancing Tumor, Tumor Core and Whole Tumor, respectively, on BraTS2019.

摘要：本研究提出一個增強的方法，使用進階的 3D-UNet 模型結合 Context Transformer (CoT) 來精確分割磁振造影 (MRI) 中的腦瘤腫塊。透過架構擴充 CoT，所提出的模型將其架構擴充到 3D 格式，並將其與基礎模型順利整合，以利用 MRI 掃描中發現的複雜背景資訊，強調元素如何跨越擴展的空間範圍相互依賴。所提出的模型從 CoT 同步化腫瘤質量特徵，相互加強特徵提取，促進精確擷取詳細的腫瘤質量結構，包括位置、大小和邊界。多項實驗結果顯示，所提出的方法與目前最先進的方法相比，具有出色的分割效能，分別在 BraTS2019 上針對增強腫瘤、腫瘤核心和整體腫瘤達到 82.0%、81.5%、89.0% 的 Dice 分數。

##### **Model Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks**
2407.08454v1 by Zheng Wang, Boxiao Jin, Zhongzhi Yu, Minjia Zhang

How to efficiently serve Large Language Models (LLMs) has become a pressing
issue because of their huge computational cost in their autoregressive
generation process. To mitigate computational costs, LLMs often employ the KV
Cache technique to improve the generation speed. While improving the
computational efficiency, the storage requirements of the KV cache are
substantial, particularly in long-context scenarios, leading to significant
memory consumption. Existing KV cache eviction methods often degrade the
performance of LLMs in long-context scenarios due to the information loss
introduced by eviction. In this paper, we propose a novel KV cache merging
approach, called KVMerger, to achieve adaptive KV cache compression for
long-context tasks without significant performance degradation under
constrained memory budgets. Our approach is inspired by the intriguing
observation that key states exhibit high similarity at the token level within a
single sequence. To facilitate merging, we develop an effective yet
straightforward merging set identification algorithm to identify suitable KV
states for merging. Our merging set identification algorithm stimulates the
second observation that KV cache sparsity, from similarity perspective, is
independent of the dataset and remains persistent at the model level.
Subsequently, we propose a Gaussian kernel weighted merging algorithm to
selectively merge all states within each merging set. We conduct extensive
experiments to demonstrate the effectiveness of KVMerger for long-context tasks
under constrained memory budgets, applying it to models including
Llama2-7B-chat and Llama2-13B-chat. Using the LongBench and ZeroScroll
benchmarks, we compare our method with other KV cache compression techniques,
including H2O and CaM, showing that our method achieves superior performance
across tasks with both 50% and 35% KV cache budgets.

摘要：<paragraph>如何有效地提供大型语言模型 (LLM) 已成为一项紧迫的问题，因为它们在自回归生成过程中的计算成本巨大。为了降低计算成本，LLM 经常采用 KV 缓存技术来提高生成速度。虽然提高了计算效率，但 KV 缓存的存储需求很大，尤其是在长上下文场景中，从而导致了大量的内存消耗。现有的 KV 缓存驱逐方法通常会因驱逐引入的信息丢失而降低 LLM 在长上下文场景中的性能。在本文中，我们提出了一种新颖的 KV 缓存合并方法，称为 KVMerger，以实现自适应 KV 缓存压缩，用于在受限内存预算下进行长上下文任务，而不会显着降低性能。我们的方法受到以下有趣观察的启发：关键状态在单个序列中的标记级别表现出高度相似性。为了促进合并，我们开发了一种有效且直接的合并集识别算法，以识别适合合并的 KV 状态。我们的合并集识别算法激发了第二个观察结果，即从相似性的角度来看，KV 缓存稀疏性与数据集无关，并且在模型级别保持不变。随后，我们提出了一种高斯核加权合并算法，以选择性地合并每个合并集中的所有状态。我们进行了广泛的实验，以证明 KVMerger 在受限内存预算下对长上下文任务的有效性，将其应用于包括 Llama2-7B-chat 和 Llama2-13B-chat 在内的模型。使用 LongBench 和 ZeroScroll 基准，我们将我们的方法与其他 KV 缓存压缩技术（包括 H2O 和 CaM）进行了比较，结果表明我们的方法在 KV 缓存预算为 50% 和 35% 的所有任务中都取得了卓越的性能。</paragraph>

##### **Paving the way toward foundation models for irregular and unaligned Satellite Image Time Series**
2407.08448v1 by Iris Dumeur, Silvia Valero, Jordi Inglada

Although recently several foundation models for satellite remote sensing
imagery have been proposed, they fail to address major challenges of
real/operational applications. Indeed, embeddings that don't take into account
the spectral, spatial and temporal dimensions of the data as well as the
irregular or unaligned temporal sampling are of little use for most real world
uses.As a consequence, we propose an ALIgned Sits Encoder (ALISE), a novel
approach that leverages the spatial, spectral, and temporal dimensions of
irregular and unaligned SITS while producing aligned latent representations.
Unlike SSL models currently available for SITS, ALISE incorporates a flexible
query mechanism to project the SITS into a common and learned temporal
projection space. Additionally, thanks to a multi-view framework, we explore
integration of instance discrimination along a masked autoencoding task to
SITS. The quality of the produced representation is assessed through three
downstream tasks: crop segmentation (PASTIS), land cover segmentation
(MultiSenGE), and a novel crop change detection dataset. Furthermore, the
change detection task is performed without supervision. The results suggest
that the use of aligned representations is more effective than previous SSL
methods for linear probing segmentation tasks.

摘要：儘管最近提出了數個用於衛星遙測影像的基礎模型，它們仍無法解決實際/操作應用中的重大挑戰。事實上，未考慮資料的光譜、空間和時間維度以及不規則或未對齊的時間抽樣的嵌入式處理，對於大多數實際應用來說幾乎沒有用處。因此，我們提出了一種對齊式情境編碼器 (ALISE)，這是一種新穎的方法，它能利用不規則且未對齊的 SITS 的空間、光譜和時間維度，同時產生對齊的潛在表示。與目前可用的 SITS SSL 模型不同，ALISE 結合了一種靈活的查詢機制，將 SITS 投影到一個共同且學習的時間投影空間中。此外，由於採用了多視角架構，我們探索了將實例區分整合到 SITS 的遮罩自動編碼任務中。所產生表示的品質透過三項下游任務進行評估：作物分割 (PASTIS)、土地覆蓋分割 (MultiSenGE) 和一個新穎的作物變化偵測資料集。此外，變更偵測任務是在沒有監督的情況下執行的。結果表明，使用對齊表示比先前的 SSL 方法對於線性探測分割任務更有效。

##### **How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation**
2407.08442v1 by Linglong Qian, Tao Wang, Jun Wang, Hugh Logan Ellis, Robin Mitra, Richard Dobson, Zina Ibrahim

We introduce a novel classification framework for time-series imputation
using deep learning, with a particular focus on clinical data. By identifying
conceptual gaps in the literature and existing reviews, we devise a taxonomy
grounded on the inductive bias of neural imputation frameworks, resulting in a
classification of existing deep imputation strategies based on their
suitability for specific imputation scenarios and data-specific properties. Our
review further examines the existing methodologies employed to benchmark deep
imputation models, evaluating their effectiveness in capturing the missingness
scenarios found in clinical data and emphasising the importance of reconciling
mathematical abstraction with clinical insights. Our classification aims to
serve as a guide for researchers to facilitate the selection of appropriate
deep learning imputation techniques tailored to their specific clinical data.
Our novel perspective also highlights the significance of bridging the gap
between computational methodologies and medical insights to achieve clinically
sound imputation models.

摘要：我們提出了一個新的時間序列插補分類架構，使用深度學習，特別關注臨床數據。通過找出文獻和現有評論中的概念差距，我們設計了一個分類法，該分類法基於神經插補框架的歸納偏誤，從而對現有的深度插補策略進行分類，基於它們對特定插補場景和數據特定屬性的適用性。我們的回顧進一步檢驗了用於對深度插補模型進行基準測試的現有方法，評估了它們在捕捉臨床數據中發現的缺失場景方面的有效性，並強調了調和數學抽象與臨床見解的重要性。我們的分類旨在作為研究人員的指南，以促進根據其特定臨床數據選擇適當的深度學習插補技術。我們的新觀點還強調了彌合計算方法和醫學見解之間差距以實現臨床合理插補模型的重要性。

##### **Are Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation**
2407.08441v1 by Riccardo Cantini, Giada Cosenza, Alessio Orsino, Domenico Talia

Large Language Models (LLMs) have revolutionized artificial intelligence,
demonstrating remarkable computational power and linguistic capabilities.
However, these models are inherently prone to various biases stemming from
their training data. These include selection, linguistic, and confirmation
biases, along with common stereotypes related to gender, ethnicity, sexual
orientation, religion, socioeconomic status, disability, and age. This study
explores the presence of these biases within the responses given by the most
recent LLMs, analyzing the impact on their fairness and reliability. We also
investigate how known prompt engineering techniques can be exploited to
effectively reveal hidden biases of LLMs, testing their adversarial robustness
against jailbreak prompts specially crafted for bias elicitation. Extensive
experiments are conducted using the most widespread LLMs at different scales,
confirming that LLMs can still be manipulated to produce biased or
inappropriate responses, despite their advanced capabilities and sophisticated
alignment processes. Our findings underscore the importance of enhancing
mitigation techniques to address these safety issues, toward a more sustainable
and inclusive artificial intelligence.

摘要：大型語言模型 (LLM) 徹底改變了人工智慧，展示出非凡的運算能力和語言能力。然而，這些模型本質上容易受到來自訓練資料的各種偏見影響。這些偏見包括選擇、語言和確認偏誤，以及與性別、種族、性取向、宗教、社會經濟地位、殘疾和年齡相關的常見刻板印象。本研究探討了最新 LLM 給出的回應中這些偏見的存在，分析了對其公平性和可靠性的影響。我們還研究了如何利用已知的提示工程技術有效揭示 LLM 的隱藏偏見，測試其對專門用於偏見引發的越獄提示的對抗性穩健性。使用不同規模的最廣泛 LLM 進行了廣泛的實驗，證實了儘管 LLM 具有先進的功能和複雜的對齊流程，但仍可以被操縱以產生有偏見或不適當的回應。我們的研究結果強調了加強緩解技術以解決這些安全問題的重要性，朝著更具永續性和包容性的 AI 邁進。

##### **Beyond Instruction Following: Evaluating Rule Following of Large Language Models**
2407.08440v1 by Wangtao Sun, Chenxiang Zhang, Xueyou Zhang, Ziyang Huang, Haotian Xu, Pei Chen, Shizhu He, Jun Zhao, Kang Liu

Although Large Language Models (LLMs) have demonstrated strong
instruction-following ability to be helpful, they are further supposed to be
controlled and guided by rules in real-world scenarios to be safe, and accurate
in responses. This demands the possession of rule-following capability of LLMs.
However, few works have made a clear evaluation of the rule-following
capability of LLMs. Previous studies that try to evaluate the rule-following
capability of LLMs fail to distinguish the rule-following scenarios from the
instruction-following scenarios. Therefore, this paper first makes a
clarification of the concept of rule-following, and curates a comprehensive
benchmark, RuleBench, to evaluate a diversified range of rule-following
abilities. Our experimental results on a variety of LLMs show that they are
still limited in following rules. Our further analysis provides insights into
the improvements for LLMs toward a better rule-following intelligent agent. The
data and code can be found at:
https://anonymous.4open.science/r/llm-rule-following-B3E3/

摘要：儘管大型語言模型 (LLM) 已展現強大的指令遵循能力，有助益，但進一步假設它們在實際情境中會受到規則控制和引導，以確保回應安全且準確。這需要 LLM 具備遵循規則的能力。然而，很少有研究明確評估 LLM 的規則遵循能力。先前嘗試評估 LLM 規則遵循能力的研究，未能區分規則遵循情境與指令遵循情境。因此，本文首先釐清規則遵循的概念，並策劃一個全面的基準測試 RuleBench，以評估多樣化的規則遵循能力。我們在各種 LLM 上的實驗結果顯示，它們在遵循規則方面仍然有限。我們的進一步分析提供了見解，以改善 LLM 朝向更好的規則遵循智能代理邁進。資料和程式碼可在以下網址找到：
https://anonymous.4open.science/r/llm-rule-following-B3E3/

##### **A Comprehensive Survey on Human Video Generation: Challenges, Methods, and Insights**
2407.08428v1 by Wentao Lei, Jinting Wang, Fengji Ma, Guanjie Huang, Li Liu

Human video generation is a dynamic and rapidly evolving task that aims to
synthesize 2D human body video sequences with generative models given control
conditions such as text, audio, and pose. With the potential for wide-ranging
applications in film, gaming, and virtual communication, the ability to
generate natural and realistic human video is critical. Recent advancements in
generative models have laid a solid foundation for the growing interest in this
area. Despite the significant progress, the task of human video generation
remains challenging due to the consistency of characters, the complexity of
human motion, and difficulties in their relationship with the environment. This
survey provides a comprehensive review of the current state of human video
generation, marking, to the best of our knowledge, the first extensive
literature review in this domain. We start with an introduction to the
fundamentals of human video generation and the evolution of generative models
that have facilitated the field's growth. We then examine the main methods
employed for three key sub-tasks within human video generation: text-driven,
audio-driven, and pose-driven motion generation. These areas are explored
concerning the conditions that guide the generation process. Furthermore, we
offer a collection of the most commonly utilized datasets and the evaluation
metrics that are crucial in assessing the quality and realism of generated
videos. The survey concludes with a discussion of the current challenges in the
field and suggests possible directions for future research. The goal of this
survey is to offer the research community a clear and holistic view of the
advancements in human video generation, highlighting the milestones achieved
and the challenges that lie ahead.

摘要：人類影片生成是一項動態且快速演進的任務，旨在利用生成模型合成 2D 人體影片序列，並給予文字、音訊和姿勢等控制條件。隨著在電影、遊戲和虛擬通訊中廣泛應用的潛力，生成自然且逼真的影片至關重要。生成模型的最新進展為這個領域日益增長的興趣奠定了堅實的基礎。儘管取得了顯著進展，但由於角色的一致性、人類動作的複雜性和與環境關係的困難，人類影片生成的任務仍然具有挑戰性。這項調查全面回顧了人類影片生成的現狀，標誌著我們所知，這是該領域首次廣泛的文獻回顧。我們從人類影片生成的基本原理和促成該領域成長的生成模型的演進開始介紹。然後我們探討了用於人類影片生成中三個關鍵子任務的主要方法：文字驅動、音訊驅動和姿勢驅動的動作生成。這些領域是根據指導生成過程的條件進行探討的。此外，我們提供了一系列最常使用的資料集和評估指標，這些指標對於評估生成影片的品質和真實性至關重要。這項調查最後討論了該領域目前的挑戰，並建議了未來研究可能的方向。這項調查的目標是為研究社群提供人類影片生成進展的清晰且全面的觀點，重點介紹已達成的里程碑和未來的挑戰。

##### **On the (In)Security of LLM App Stores**
2407.08422v1 by Xinyi Hou, Yanjie Zhao, Haoyu Wang

LLM app stores have seen rapid growth, leading to the proliferation of
numerous custom LLM apps. However, this expansion raises security concerns. In
this study, we propose a three-layer concern framework to identify the
potential security risks of LLM apps, i.e., LLM apps with abusive potential,
LLM apps with malicious intent, and LLM apps with exploitable vulnerabilities.
Over five months, we collected 786,036 LLM apps from six major app stores: GPT
Store, FlowGPT, Poe, Coze, Cici, and Character.AI. Our research integrates
static and dynamic analysis, the development of a large-scale toxic word
dictionary (i.e., ToxicDict) comprising over 31,783 entries, and automated
monitoring tools to identify and mitigate threats. We uncovered that 15,146
apps had misleading descriptions, 1,366 collected sensitive personal
information against their privacy policies, and 15,996 generated harmful
content such as hate speech, self-harm, extremism, etc. Additionally, we
evaluated the potential for LLM apps to facilitate malicious activities,
finding that 616 apps could be used for malware generation, phishing, etc. Our
findings highlight the urgent need for robust regulatory frameworks and
enhanced enforcement mechanisms.

摘要：LLM 應用程式商店已迅速成長，導致大量自訂 LLM 應用程式激增。然而，此擴張引發了安全疑慮。在此研究中，我們提出一個三層關注架構，以識別 LLM 應用程式的潛在安全風險，亦即具有濫用潛力的 LLM 應用程式、具有惡意意圖的 LLM 應用程式以及具有可利用漏洞的 LLM 應用程式。在五個月內，我們從六個主要應用程式商店收集了 786,036 個 LLM 應用程式：GPT Store、FlowGPT、Poe、Coze、Cici 和 Character.AI。我們的研究整合了靜態和動態分析、開發包含超過 31,783 個條目的、大規模的毒害字詞字典（亦即 ToxicDict），以及用於識別和減輕威脅的自動化監控工具。我們發現有 15,146 個應用程式的說明具有誤導性，1,366 個應用程式違反其隱私權政策收集敏感的個人資訊，15,996 個應用程式產生仇恨言論、自殘、極端主義等有害內容。此外，我們評估了 LLM 應用程式促進惡意活動的潛力，發現有 616 個應用程式可用於產生惡意軟體、網路釣魚等。我們的研究結果突顯了對健全法規架構和加強執法機制的迫切需求。

##### **Specialist vision-language models for clinical ophthalmology**
2407.08410v1 by Robbie Holland, Thomas R. P. Taylor, Christopher Holmes, Sophie Riedl, Julia Mai, Maria Patsiamanidi, Dimitra Mitsopoulou, Paul Hager, Philip Müller, Hendrik P. N. Scholl, Hrvoje Bogunović, Ursula Schmidt-Erfurth, Daniel Rueckert, Sobha Sivaprasad, Andrew J. Lotery, Martin J. Menten

Clinicians spend a significant amount of time reviewing medical images and
transcribing their findings regarding patient diagnosis, referral and treatment
in text form. Vision-language models (VLMs), which automatically interpret
images and summarize their findings as text, have enormous potential to
alleviate clinical workloads and increase patient access to high-quality
medical care. While foundational models have stirred considerable interest in
the medical community, it is unclear whether their general capabilities
translate to real-world clinical utility. In this work, we show that foundation
VLMs markedly underperform compared to practicing ophthalmologists on
specialist tasks crucial to the care of patients with age-related macular
degeneration (AMD). To address this, we initially identified the essential
capabilities required for image-based clinical decision-making, and then
developed a curriculum to selectively train VLMs in these skills. The resulting
model, RetinaVLM, can be instructed to write reports that significantly
outperform those written by leading foundation medical VLMs in disease staging
(F1 score of 0.63 vs. 0.11) and patient referral (0.67 vs. 0.39), and
approaches the diagnostic performance of junior ophthalmologists (who achieve
0.77 and 0.78 on the respective tasks). Furthermore, in a reader study
involving two senior ophthalmologists with up to 32 years of experience,
RetinaVLM's reports were found to be similarly correct (78.6% vs. 82.1%) and
complete (both 78.6%) as reports written by junior ophthalmologists with up to
10 years of experience. These results demonstrate that our curriculum-based
approach provides a blueprint for specializing generalist foundation medical
VLMs to handle real-world clinical tasks.

摘要：<paragraph>臨床醫生花費大量時間檢閱醫療影像，並以文字形式記錄他們關於患者診斷、轉診和治療的發現。視覺語言模型 (VLM) 會自動解讀影像並將其發現摘要成文字，具有減輕臨床工作負載和增加患者獲得優質醫療保健的機會的巨大潛力。雖然基礎模型在醫療界引起了相當大的興趣，但尚不清楚它們的一般能力是否能轉化為實際的臨床效用。在這項工作中，我們表明基礎 VLM 在與年齡相關性黃斑部病變 (AMD) 患者照護至關重要的專門任務上，表現明顯不如執業眼科醫生。為了解決這個問題，我們最初找出影像式臨床決策所需的必要能力，然後制定課程來選擇性地訓練 VLM 這些技能。所產生的模型 RetinaVLM 可以被指示撰寫報告，其在疾病分期（F1 分數為 0.63 對 0.11）和患者轉診（0.67 對 0.39）方面明顯優於領先的基礎醫療 VLM 所撰寫的報告，並接近初級眼科醫生的診斷表現（在各項任務中分別達到 0.77 和 0.78）。此外，在涉及兩位擁有長達 32 年經驗的高級眼科醫生的讀者研究中，發現 RetinaVLM 的報告正確性（78.6% 對 82.1%）和完整性（均為 78.6%）與擁有長達 10 年經驗的初級眼科醫生所撰寫的報告相似。這些結果表明，我們基於課程的方法提供了將通才基礎醫療 VLM 專門化以處理實際臨床任務的藍圖。</paragraph>

##### **A Two-Stage Machine Learning-Aided Approach for Quench Identification at the European XFEL**
2407.08408v1 by Lynda Boukela, Annika Eichler, Julien Branlard, Nur Zulaiha Jomhari

This paper introduces a machine learning-aided fault detection and isolation
method applied to the case study of quench identification at the European X-Ray
Free-Electron Laser. The plant utilizes 800 superconducting radio-frequency
cavities in order to accelerate electron bunches to high energies of up to 17.5
GeV. Various faulty events can disrupt the nominal functioning of the
accelerator, including quenches that can lead to a loss of the
superconductivity of the cavities and the interruption of their operation. In
this context, our solution consists in analyzing signals reflecting the
dynamics of the cavities in a two-stage approach. (I) Fault detection that uses
analytical redundancy to process the data and generate a residual. The
evaluation of the residual through the generalized likelihood ratio allows
detecting the faulty behaviors. (II) Fault isolation which involves the
distinction of the quenches from the other faults. To this end, we proceed with
a data-driven model of the k-medoids algorithm that explores different
similarity measures, namely, the Euclidean and the dynamic time warping.
Finally, we evaluate the new method and compare it to the currently deployed
quench detection system, the results show the improved performance achieved by
our method.

摘要：本文介紹了一種機器學習輔助的故障偵測與隔離方法，應用於歐洲 X 光自由電子雷射的猝發識別案例研究。該工廠利用 800 個超導射頻腔來加速電子束達到高達 17.5 GeV 的高能量。各種故障事件會中斷加速器的正常運作，包括可能導致腔體超導性喪失和中斷其運作的猝發。在此背景下，我們的解決方案包括分析反映腔體動態的信號，採用兩階段方法。(I) 故障偵測，使用分析冗餘處理資料並產生殘差。透過廣義似然比評估殘差，可以偵測故障行為。(II) 故障隔離，涉及將猝發與其他故障區分開來。為此，我們使用 k-medoids 演算法的資料驅動模型來探討不同的相似性測量，即歐幾里得和動態時間規整。最後，我們評估新方法並將其與目前部署的猝發偵測系統進行比較，結果顯示我們的方法達到了改進的效能。

##### **Self-training Language Models for Arithmetic Reasoning**
2407.08400v1 by Marek Kadlčík, Michal Štefánik

Language models achieve impressive results in tasks involving complex
multistep reasoning, but scaling these capabilities further traditionally
requires expensive collection of more annotated data. In this work, we explore
the potential of improving the capabilities of language models without new
data, merely using automated feedback to the validity of their predictions in
arithmetic reasoning (self-training). We find that models can substantially
improve in both single-round (offline) and online self-training. In the offline
setting, supervised methods are able to deliver gains comparable to preference
optimization, but in online self-training, preference optimization shows to
largely outperform supervised training thanks to superior stability and
robustness on unseen types of problems.

摘要：語言模型在涉及複雜多步驟推理的任務中取得令人印象深刻的成果，但進一步擴展這些能力傳統上需要大量收集更多註釋資料。在這項工作中，我們探討了在沒有新資料的情況下提高語言模型能力的潛力，僅使用自動化回饋來驗證其在算術推理（自我訓練）中的預測的有效性。我們發現，模型可以在單輪（離線）和線上自我訓練中大幅改進。在離線設置中，監督式方法能夠提供與偏好最佳化相當的增益，但在線上自我訓練中，偏好最佳化顯示出由於在未見問題類型上的優異穩定性和穩健性而大幅優於監督式訓練。

##### **On the attribution of confidence to large language models**
2407.08388v1 by Geoff Keeling, Winnie Street

Credences are mental states corresponding to degrees of confidence in
propositions. Attribution of credences to Large Language Models (LLMs) is
commonplace in the empirical literature on LLM evaluation. Yet the theoretical
basis for LLM credence attribution is unclear. We defend three claims. First,
our semantic claim is that LLM credence attributions are (at least in general)
correctly interpreted literally, as expressing truth-apt beliefs on the part of
scientists that purport to describe facts about LLM credences. Second, our
metaphysical claim is that the existence of LLM credences is at least
plausible, although current evidence is inconclusive. Third, our epistemic
claim is that LLM credence attributions made in the empirical literature on LLM
evaluation are subject to non-trivial sceptical concerns. It is a distinct
possibility that even if LLMs have credences, LLM credence attributions are
generally false because the experimental techniques used to assess LLM
credences are not truth-tracking.

摘要：信念是與對命題的信心程度相應的心智狀態。在 LLM 評估的實證文獻中，將信念歸因於大型語言模型 (LLM) 是很常見的。然而，LLM 信念歸因的理論基礎尚不清楚。我們捍衛三項主張。首先，我們的語義主張是，LLM 信念歸因（至少在一般情況下）被正確地逐字解釋，作為科學家對 LLM 信念的事實描述的真值適應信念的表達。其次，我們的形上學主張是，LLM 信念的存在至少是合理的，儘管目前的證據尚無定論。第三，我們的認識論主張是，在 LLM 評估的實證文獻中提出的 LLM 信念歸因會受到非平凡的懷疑論關注。即使 LLM 具有信念，LLM 信念歸因通常也是錯誤的，因為用於評估 LLM 信念的實驗技術並非追蹤真值的，這是一個不同的可能性。

##### **Digital twins to alleviate the need for real field data in vision-based vehicle speed detection systems**
2407.08380v1 by Antonio Hernández Martínez, Iván García Daza, Carlos Fernández López, David Fernández Llorca

Accurate vision-based speed estimation is much more cost-effective than
traditional methods based on radar or LiDAR. However, it is also challenging
due to the limitations of perspective projection on a discrete sensor, as well
as the high sensitivity to calibration, lighting and weather conditions.
Interestingly, deep learning approaches (which dominate the field of computer
vision) are very limited in this context due to the lack of available data.
Indeed, obtaining video sequences of real road traffic with accurate speed
values associated with each vehicle is very complex and costly, and the number
of available datasets is very limited. Recently, some approaches are focusing
on the use of synthetic data. However, it is still unclear how models trained
on synthetic data can be effectively applied to real world conditions. In this
work, we propose the use of digital-twins using CARLA simulator to generate a
large dataset representative of a specific real-world camera. The synthetic
dataset contains a large variability of vehicle types, colours, speeds,
lighting and weather conditions. A 3D CNN model is trained on the digital twin
and tested on the real sequences. Unlike previous approaches that generate
multi-camera sequences, we found that the gap between the the real and the
virtual conditions is a key factor in obtaining low speed estimation errors.
Even with a preliminary approach, the mean absolute error obtained remains
below 3km/h.

摘要：準確的基於視覺的速度估計比傳統基於雷達或 LiDAR 的方法更具成本效益。然而，由於透視投影在離散感測器上的限制，以及對校準、光線和天氣條件的高度敏感性，這也具有挑戰性。有趣的是，深度學習方法（在電腦視覺領域佔主導地位）由於缺乏可用數據，因此在此背景下受到極大限制。的確，獲取與每輛車輛相關聯的準確速度值的真實道路交通影片序列非常複雜且昂貴，可用資料集的數量非常有限。最近，一些方法專注於使用合成數據。然而，在合成數據上訓練的模型如何有效應用於真實世界條件仍然不清楚。在這項工作中，我們建議使用 CARLA 模擬器中的數位雙胞胎來生成一個代表特定真實世界相機的大型資料集。合成資料集包含大量車輛類型、顏色、速度、光線和天氣條件的變化。3D CNN 模型在數位雙胞胎上訓練，並在真實序列上進行測試。與產生多相機序列的先前方法不同，我們發現真實和虛擬條件之間的差距是獲得低速度估計誤差的關鍵因素。即使採用初步方法，獲得的平均絕對誤差仍低於 3km/h。

##### **AutoBencher: Creating Salient, Novel, Difficult Datasets for Language Models**
2407.08351v1 by Xiang Lisa Li, Evan Zheran Liu, Percy Liang, Tatsunori Hashimoto

Evaluation is critical for assessing capabilities, tracking scientific
progress, and informing model selection. In this paper, we present three
desiderata for a good benchmark for language models: (i) salience (e.g.,
knowledge about World War II is more salient than a random day in history),
(ii) novelty (i.e., the benchmark reveals new trends in model rankings not
shown by previous benchmarks), and (iii) difficulty (i.e., the benchmark should
be difficult for existing models, leaving headroom for future improvement). We
operationalize these three desiderata and cast benchmark creation as a search
problem, that of finding benchmarks that that satisfy all three desiderata. To
tackle this search problem, we present AutoBencher, which uses a language model
to automatically search for datasets that meet the three desiderata.
AutoBencher uses privileged information (e.g. relevant documents) to construct
reliable datasets, and adaptivity with reranking to optimize for the search
objective. We use AutoBencher to create datasets for math, multilingual, and
knowledge-intensive question answering. The scalability of AutoBencher allows
it to test fine-grained categories and tail knowledge, creating datasets that
are on average 27% more novel and 22% more difficult than existing benchmarks.
A closer investigation of our constructed datasets shows that we can identify
specific gaps in LM knowledge in language models that are not captured by
existing benchmarks, such as Gemini Pro performing much worse on question
answering about the Permian Extinction and Fordism, while OpenAGI-7B performing
surprisingly well on QA about COVID-19.

摘要：評量對於評估能力、追蹤科學進展和提供模型選擇至關重要。在本文中，我們提出一個好的語言模型基準的三個理想條件：(i) 顯著性（例如，有關二戰的知識比歷史中的隨機一天更顯著），(ii) 新穎性（即基準揭示了模型排名的新趨勢，而先前基準未顯示），以及 (iii) 困難度（即基準對於現有模型而言應具有難度，為未來的改進留下進步空間）。我們將這三個理想條件具體化，並將基準建立視為一個搜尋問題，即找出滿足所有三個理想條件的基準。為了解決這個搜尋問題，我們提出了 AutoBencher，它使用語言模型自動搜尋符合這三個理想條件的資料集。AutoBencher 使用特權資訊（例如相關文件）來建構可靠的資料集，並透過重新排名進行適應性調整，以最佳化搜尋目標。我們使用 AutoBencher 為數學、多語言和知識密集型問題解答建立資料集。AutoBencher 的可擴充性允許它測試細緻的類別和尾部知識，建立的資料集平均比現有基準新穎 27% 且困難 22%。對我們建構的資料集進行更深入的調查顯示，我們可以找出語言模型中 LM 知識的具體差距，而現有基準並未捕捉到這些差距，例如 Gemini Pro 在有關二疊紀大滅絕和福特主義的問題解答中表現得更差，而 OpenAGI-7B 在有關 COVID-19 的 QA 中表現出人意料的好。

##### **Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On**
2407.08348v1 by Liang Zeng, Liangjun Zhong, Liang Zhao, Tianwen Wei, Liu Yang, Jujie He, Cheng Cheng, Rui Hu, Yang Liu, Shuicheng Yan, Han Fang, Yahui Zhou

In this paper, we investigate the underlying factors that potentially enhance
the mathematical reasoning capabilities of large language models (LLMs). We
argue that the data scaling law for math reasoning capabilities in modern LLMs
is far from being saturated, highlighting how the model's quality improves with
increases in data quantity. To support this claim, we introduce the
Skywork-Math model series, supervised fine-tuned (SFT) on common 7B LLMs using
our proposed 2.5M-instance Skywork-MathQA dataset. Skywork-Math 7B has achieved
impressive accuracies of 51.2% on the competition-level MATH benchmark and
83.9% on the GSM8K benchmark using only SFT data, outperforming an early
version of GPT-4 on MATH. The superior performance of Skywork-Math models
contributes to our novel two-stage data synthesis and model SFT pipelines,
which include three different augmentation methods and a diverse seed problem
set, ensuring both the quantity and quality of Skywork-MathQA dataset across
varying difficulty levels. Most importantly, we provide several practical
takeaways to enhance math reasoning abilities in LLMs for both research and
industry applications.

摘要：<paragraph>在本文中，我們探討了潛在提升大型語言模型 (LLM) 數學推理能力的基礎因素。我們主張，現代 LLM 中數學推理能力的資料擴充法則遠未達到飽和，強調模型的品質會隨著資料量的增加而提升。為了支持此論點，我們引入了 Skywork-Math 模型系列，使用我們提出的 250 萬個例子的 Skywork-MathQA 資料集，對常見的 7B LLM 進行監督式微調 (SFT)。Skywork-Math 7B 僅使用 SFT 資料，就在競賽級別的 MATH 基準測試中達到了 51.2% 的驚人準確度，在 GSM8K 基準測試中達到了 83.9%，表現優於 GPT-4 的早期版本。Skywork-Math 模型的優異性能歸功於我們新穎的兩階段資料合成和模型 SFT 管線，其中包括三種不同的擴充方法和一個多樣化的種子問題集，確保了 Skywork-MathQA 資料集在不同難度級別上的數量和品質。最重要的是，我們提供了幾個實用的外帶事項，以增強 LLM 在研究和產業應用中的數學推理能力。</paragraph>

##### **Towards Explainable Evolution Strategies with Large Language Models**
2407.08331v1 by Jill Baumann, Oliver Kramer

This paper introduces an approach that integrates self-adaptive Evolution
Strategies (ES) with Large Language Models (LLMs) to enhance the explainability
of complex optimization processes. By employing a self-adaptive ES equipped
with a restart mechanism, we effectively navigate the challenging landscapes of
benchmark functions, capturing detailed logs of the optimization journey,
including fitness evolution, step-size adjustments, and restart events due to
stagnation. An LLM is then utilized to process these logs, generating concise,
user-friendly summaries that highlight key aspects such as convergence
behavior, optimal fitness achievements, and encounters with local optima. Our
case study on the Rastrigin function demonstrates how our approach makes the
complexities of ES optimization transparent and accessible. Our findings
highlight the potential of using LLMs to bridge the gap between advanced
optimization algorithms and their interpretability.

摘要：本文介紹一種方法，將自適應演化策略 (ES) 與大型語言模型 (LLM) 整合，以增強複雜最佳化程序的可解釋性。透過採用配備重新啟動機制的自適應 ES，我們有效地導航基準函數的挑戰性環境，擷取最佳化旅程的詳細記錄，包括適應度演化、步長調整和因停滯而重新啟動的事件。接著使用 LLM 處理這些記錄，產生簡潔、使用者友善的摘要，重點說明關鍵面向，例如收斂行為、最佳適應度達成和遭遇局部最優。我們在 Rastrigin 函數上的案例研究展示了我們的做法如何讓 ES 最佳化的複雜性變得透明且容易理解。我們的發現突顯了使用 LLM 來彌合進階最佳化演算法與其可解釋性之間差距的潛力。

##### **Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports**
2407.08328v1 by Georgina Cosma, Mohit Kumar Singh, Patrick Waterson, Gyuchan Thomas Jun, Jonathan Back

This study applies Natural Language Processing techniques, including Latent
Dirichlet Allocation, to analyse anonymised maternity incident investigation
reports from the Healthcare Safety Investigation Branch. The reports underwent
preprocessing, annotation using the Safety Intelligence Research taxonomy, and
topic modelling to uncover prevalent topics and detect differences in maternity
care across ethnic groups. A combination of offline and online methods was
utilised to ensure data protection whilst enabling advanced analysis, with
offline processing for sensitive data and online processing for non-sensitive
data using the `Claude 3 Opus' language model. Interactive topic analysis and
semantic network visualisation were employed to extract and display thematic
topics and visualise semantic relationships among keywords. The analysis
revealed disparities in care among different ethnic groups, with distinct focus
areas for the Black, Asian, and White British ethnic groups. The study
demonstrates the effectiveness of topic modelling and NLP techniques in
analysing maternity incident investigation reports and highlighting disparities
in care. The findings emphasise the crucial role of advanced data analysis in
improving maternity care quality and equity.

摘要：本研究應用自然語言處理技術，包括潛在狄利克雷分配，分析醫療保健安全調查局的匿名產婦事件調查報告。這些報告經過預處理、使用安全情報研究分類法註解，以及主題建模，以找出普遍的主題並找出不同族群在產前照護的差異。結合離線和線上方法，以確保資料保護，同時進行進階分析，使用 Claude 3 Opus 語言模型對敏感資料進行離線處理，對非敏感資料進行線上處理。採用互動主題分析和語意網路視覺化，以萃取和顯示主題主題，並視覺化關鍵字之間的語意關係。分析顯示不同族群之間的照護差異，黑人、亞洲人和白人英國人族群的關注領域不同。本研究證明了主題建模和自然語言處理技術在分析產婦事件調查報告和強調照護差異方面的有效性。研究結果強調了進階資料分析在提升產前照護品質和公平性方面的關鍵角色。

##### **Intelligent Multi-Document Summarisation for Extracting Insights on Racial Inequalities from Maternity Incident Investigation Reports**
2407.08322v1 by Georgina Cosma, Mohit Kumar Singh, Patrick Waterson, Gyuchan Thomas Jun, Jonathan Back

In healthcare, thousands of safety incidents occur every year, but learning
from these incidents is not effectively aggregated. Analysing incident reports
using AI could uncover critical insights to prevent harm by identifying
recurring patterns and contributing factors. To aggregate and extract valuable
information, natural language processing (NLP) and machine learning techniques
can be employed to summarise and mine unstructured data, potentially surfacing
systemic issues and priority areas for improvement. This paper presents
I-SIRch:CS, a framework designed to facilitate the aggregation and analysis of
safety incident reports while ensuring traceability throughout the process. The
framework integrates concept annotation using the Safety Intelligence Research
(SIRch) taxonomy with clustering, summarisation, and analysis capabilities.
Utilising a dataset of 188 anonymised maternity investigation reports annotated
with 27 SIRch human factors concepts, I-SIRch:CS groups the annotated sentences
into clusters using sentence embeddings and k-means clustering, maintaining
traceability via file and sentence IDs. Summaries are generated for each
cluster using offline state-of-the-art abstractive summarisation models (BART,
DistilBART, T5), which are evaluated and compared using metrics assessing
summary quality attributes. The generated summaries are linked back to the
original file and sentence IDs, ensuring traceability and allowing for
verification of the summarised information. Results demonstrate BART's
strengths in creating informative and concise summaries.

摘要：<paragraph>在醫療保健領域，每年都會發生數千起安全事故，但從這些事故中學習的經驗並未有效彙總。利用 AI 分析事故報告可以發現重要的見解，藉由找出重複模式和促成因素來預防傷害。為了彙總和萃取有價值的資訊，可以採用自然語言處理 (NLP) 和機器學習技術來整理和挖掘非結構化資料，潛在找出系統性問題和優先改善領域。本文提出 I-SIRch:CS，一個旨在促進安全事件報告的彙總和分析的架構，同時確保整個流程的可追溯性。此架構整合了使用安全情報研究 (SIRch) 分類法進行概念註解，以及分群、摘要和分析功能。利用一個包含 188 份匿名產科調查報告的資料集，並使用 27 個 SIRch 人為因素概念進行註解，I-SIRch:CS 使用句子嵌入和 k 均值分群將註解句子分組到群集中，並透過檔案和句子 ID 來維持可追溯性。針對每個群集使用離線最先進的抽象摘要模型 (BART、DistilBART、T5) 來產生摘要，並使用評估摘要品質屬性的指標進行評估和比較。產生的摘要連結回原始檔案和句子 ID，確保可追溯性並允許驗證摘要資訊。結果證明 BART 在建立具有資訊性和簡潔性的摘要方面具有優勢。</paragraph>

##### **Adversarial-MidiBERT: Symbolic Music Understanding Model Based on Unbias Pre-training and Mask Fine-tuning**
2407.08306v1 by Zijian Zhao

As an important part of Music Information Retrieval (MIR), Symbolic Music
Understanding (SMU) has gained substantial attention, as it can assist
musicians and amateurs in learning and creating music. Recently, pre-trained
language models have been widely adopted in SMU because the symbolic music
shares a huge similarity with natural language, and the pre-trained manner also
helps make full use of limited music data. However, the issue of bias, such as
sexism, ageism, and racism, has been observed in pre-trained language models,
which is attributed to the imbalanced distribution of training data. It also
has a significant influence on the performance of downstream tasks, which also
happens in SMU. To address this challenge, we propose Adversarial-MidiBERT, a
symbolic music understanding model based on Bidirectional Encoder
Representations from Transformers (BERT). We introduce an unbiased pre-training
method based on adversarial learning to minimize the participation of tokens
that lead to biases during training. Furthermore, we propose a mask fine-tuning
method to narrow the data gap between pre-training and fine-tuning, which can
help the model converge faster and perform better. We evaluate our method on
four music understanding tasks, and our approach demonstrates excellent
performance in all of them. The code for our model is publicly available at
https://github.com/RS2002/Adversarial-MidiBERT.

摘要：作為音樂資訊檢索 (MIR) 的重要部分，符號音樂理解 (SMU) 已獲得大量關注，因為它可以協助音樂家和業餘愛好者學習和創作音樂。最近，預訓練語言模型已廣泛應用於 SMU，因為符號音樂與自然語言有很大的相似性，而且預訓練方式也有助於充分利用有限的音樂資料。然而，在預訓練語言模型中觀察到偏見問題，例如性別歧視、年齡歧視和種族歧視，這歸因於訓練資料的不平衡分佈。這也對下游任務的執行產生重大影響，這也發生在 SMU 中。為了應對這一挑戰，我們提出了對抗式 MidiBERT，這是一個基於來自 Transformer 的雙向編碼器表徵 (BERT) 的符號音樂理解模型。我們引入了一種基於對抗學習的無偏見預訓練方法，以最小化導致訓練期間偏見的符號參與。此外，我們提出了一種遮罩微調方法，以縮小預訓練和微調之間的資料差距，這可以幫助模型更快收斂並執行得更好。我們在四項音樂理解任務上評估了我們的方法，我們的做法在所有任務中都表現出色的執行能力。我們模型的程式碼可在 https://github.com/RS2002/Adversarial-MidiBERT 公開取得。

##### **DenseFusion-1M: Merging Vision Experts for Comprehensive Multimodal Perception**
2407.08303v1 by Xiaotong Li, Fan Zhang, Haiwen Diao, Yueze Wang, Xinlong Wang, Ling-Yu Duan

Existing Multimodal Large Language Models (MLLMs) increasingly emphasize
complex understanding of various visual elements, including multiple objects,
text information, and spatial relations. Their development for comprehensive
visual perception hinges on the availability of high-quality image-text
datasets that offer diverse visual elements and throughout image descriptions.
However, the scarcity of such hyper-detailed datasets currently hinders
progress within the MLLM community. The bottleneck stems from the limited
perceptual capabilities of current caption engines, which fall short in
providing complete and accurate annotations. To facilitate the cutting-edge
research of MLLMs on comprehensive vision perception, we thereby propose
Perceptual Fusion, using a low-budget but highly effective caption engine for
complete and accurate image descriptions. Specifically, Perceptual Fusion
integrates diverse perception experts as image priors to provide explicit
information on visual elements and adopts an efficient MLLM as a centric pivot
to mimic advanced MLLMs' perception abilities. We carefully select 1M highly
representative images from uncurated LAION dataset and generate dense
descriptions using our engine, dubbed DenseFusion-1M. Extensive experiments
validate that our engine outperforms its counterparts, where the resulting
dataset significantly improves the perception and cognition abilities of
existing MLLMs across diverse vision-language benchmarks, especially with
high-resolution images as inputs. The dataset and code are publicly available
at https://github.com/baaivision/DenseFusion.

摘要：現有的多模態大型語言模型 (MLLM) 愈來愈重視對各種視覺元素的複雜理解，包括多個物件、文字資訊和空間關係。它們對於全面視覺感知的發展取決於高品質影像文字資料集的可用性，這些資料集提供多樣化的視覺元素和整個影像描述。然而，此類超詳細資料集的稀少性目前阻礙了 MLLM 社群內的進展。瓶頸源自於當前標題引擎有限的感知能力，無法提供完整且準確的註解。為了促進 MLLM 在全面視覺感知方面的尖端研究，我們因此提出感知融合，使用低預算但高效率的標題引擎來提供完整且準確的影像描述。具體來說，感知融合將多樣化的感知專家整合為影像先驗，以提供視覺元素的明確資訊，並採用高效能的 MLLM 作為中心樞紐來模擬進階 MLLM 的感知能力。我們仔細從未經整理的 LAION 資料集中挑選 100 萬張極具代表性的影像，並使用我們稱為 DenseFusion-1M 的引擎產生密集描述。廣泛的實驗驗證我們的引擎優於同類型引擎，其中產生的資料集顯著提升現有 MLLM 在各種視覺語言基準上的感知和認知能力，特別是以高解析度影像作為輸入時。資料集和程式碼可在 https://github.com/baaivision/DenseFusion 公開取得。

##### **Impact Measures for Gradual Argumentation Semantics**
2407.08302v1 by Caren Al Anaissy, Jérôme Delobelle, Srdjan Vesic, Bruno Yun

Argumentation is a formalism allowing to reason with contradictory
information by modeling arguments and their interactions. There are now an
increasing number of gradual semantics and impact measures that have emerged to
facilitate the interpretation of their outcomes. An impact measure assesses,
for each argument, the impact of other arguments on its score. In this paper,
we refine an existing impact measure from Delobelle and Villata and introduce a
new impact measure rooted in Shapley values. We introduce several principles to
evaluate those two impact measures w.r.t. some well-known gradual semantics.
This comprehensive analysis provides deeper insights into their functionality
and desirability.

摘要：論證是一種形式主義，允許透過建模論證及其互動來對矛盾資訊進行推理。現在有越來越多漸進語義和影響力測量方法出現，以利於解釋其結果。影響力測量評估每個論證中其他論證對其分數的影響力。在本文中，我們改進了 Delobelle 和 Villata 現有的影響力測量，並引入了一個根植於 Shapley 值的新影響力測量。我們引入了一些原則來評估這兩個影響力測量，相對於一些著名的漸進語義。這種全面的分析提供了對其功能和可取性的更深入見解。

##### **Continually Learn to Map Visual Concepts to Large Language Models in Resource-constrained Environments**
2407.08279v1 by Clea Rebillard, Julio Hurtado, Andrii Krutsylo, Lucia Passaro, Vincenzo Lomonaco

Learning continually from a stream of non-i.i.d. data is an open challenge in
deep learning, even more so when working in resource-constrained environments
such as embedded devices. Visual models that are continually updated through
supervised learning are often prone to overfitting, catastrophic forgetting,
and biased representations. On the other hand, large language models contain
knowledge about multiple concepts and their relations, which can foster a more
robust, informed and coherent learning process. This work proposes Continual
Visual Mapping (CVM), an approach that continually ground vision
representations to a knowledge space extracted from a fixed Language model.
Specifically, CVM continually trains a small and efficient visual model to map
its representations into a conceptual space established by a fixed Large
Language Model. Due to their smaller nature, CVM can be used when directly
adapting large visual pre-trained models is unfeasible due to computational or
data constraints. CVM overcome state-of-the-art continual learning methods on
five benchmarks and offers a promising avenue for addressing generalization
capabilities in continual learning, even in computationally constrained
devices.

摘要：從非獨立同分布資料串流中持續學習是深度學習的一項公開挑戰，尤其是在資源受限的環境中工作時，例如嵌入式裝置。透過監督式學習持續更新的視覺模型通常容易過度擬合、災難性遺忘和有偏差的表示。另一方面，大型語言模型包含了關於多個概念及其關係的知識，這可以促進更強大、更豐富且更一致的學習過程。這項工作提出了持續視覺對應 (CVM)，一種方法是持續將視覺表示基礎於從固定語言模型中提取的知識空間。具體來說，CVM 持續訓練一個小型且高效的視覺模型，將其表示對應到由固定大型語言模型建立的概念空間中。由於其較小的特性，當由於運算或資料限制而無法直接調整大型視覺預訓練模型時，可以使用 CVM。CVM 在五個基準上克服了最先進的持續學習方法，並為解決持續學習中的概化能力提供了一個有前途的途徑，即使在運算受限的裝置上也是如此。

##### **RB-SQL: A Retrieval-based LLM Framework for Text-to-SQL**
2407.08273v2 by Zhenhe Wu, Zhongqiu Li, Jie Zhang, Mengxiang Li, Yu Zhao, Ruiyu Fang, Zhongjiang He, Xuelong Li, Zhoujun Li, Shuangyong Song

Large language models (LLMs) with in-context learning have significantly
improved the performance of text-to-SQL task. Previous works generally focus on
using exclusive SQL generation prompt to improve the LLMs' reasoning ability.
However, they are mostly hard to handle large databases with numerous tables
and columns, and usually ignore the significance of pre-processing database and
extracting valuable information for more efficient prompt engineering. Based on
above analysis, we propose RB-SQL, a novel retrieval-based LLM framework for
in-context prompt engineering, which consists of three modules that retrieve
concise tables and columns as schema, and targeted examples for in-context
learning. Experiment results demonstrate that our model achieves better
performance than several competitive baselines on public datasets BIRD and
Spider.

摘要：大型語言模型 (LLM) 具備情境學習能力，大幅提升文字轉 SQL 任務的效能。先前的研究通常專注於使用獨家的 SQL 產生提示，以提升 LLM 的推理能力。然而，這些方法大多難以處理包含大量表格和欄位的龐大資料庫，而且通常忽略預處理資料庫和萃取有價值資訊以進行更有效率的提示工程的重要性。根據上述分析，我們提出 RB-SQL，一種新穎的基於檢索的 LLM 架構，用於情境提示工程，它包含三個模組，用於檢索簡潔的表格和欄位作為架構，以及用於情境學習的目標範例。實驗結果顯示，我們的模型在 BIRD 和 Spider 公共資料集上，表現優於多種有競爭力的基線。

##### **SciQu: Accelerating Materials Properties Prediction with Automated Literature Mining for Self-Driving Laboratories**
2407.08270v1 by Anand Babu

Assessing different material properties to predict specific attributes, such
as band gap, resistivity, young modulus, work function, and refractive index,
is a fundamental requirement for materials science-based applications. However,
the process is time-consuming and often requires extensive literature reviews
and numerous experiments. Our study addresses these challenges by leveraging
machine learning to analyze material properties with greater precision and
efficiency. By automating the data extraction process and using the extracted
information to train machine learning models, our developed model, SciQu,
optimizes material properties. As a proof of concept, we predicted the
refractive index of materials using data extracted from numerous research
articles with SciQu, considering input descriptors such as space group, volume,
and bandgap with Root Mean Square Error (RMSE) 0.068 and R2 0.94. Thus, SciQu
not only predicts the properties of materials but also plays a key role in
self-driving laboratories by optimizing the synthesis parameters to achieve
precise shape, size, and phase of the materials subjected to the input
parameters.

摘要：評估不同的材料屬性以預測特定屬性，例如帶隙、電阻率、楊氏模數、功函數和折射率，是基於材料科學的應用之基本要求。然而，此過程耗時且通常需要廣泛的文獻回顧和大量的實驗。我們的研究透過利用機器學習來分析材料屬性，以更高的精確度和效率來解決這些挑戰。透過自動化資料萃取流程並使用萃取的資訊來訓練機器學習模型，我們開發的模型 SciQu 最佳化了材料屬性。作為概念驗證，我們使用從大量研究文章中萃取的資料來預測材料的折射率，SciQu 考量了輸入描述符，例如空間群、體積和帶隙，其均方根誤差 (RMSE) 為 0.068，R2 為 0.94。因此，SciQu 不僅預測材料的屬性，也透過最佳化合成參數來達成輸入參數所設定的材料精確形狀、大小和相位，在自動化實驗室中扮演關鍵角色。

##### **LLMs' morphological analyses of complex FST-generated Finnish words**
2407.08269v1 by Anssi Moisio, Mathias Creutz, Mikko Kurimo

Rule-based language processing systems have been overshadowed by neural
systems in terms of utility, but it remains unclear whether neural NLP systems,
in practice, learn the grammar rules that humans use. This work aims to shed
light on the issue by evaluating state-of-the-art LLMs in a task of
morphological analysis of complex Finnish noun forms. We generate the forms
using an FST tool, and they are unlikely to have occurred in the training sets
of the LLMs, therefore requiring morphological generalisation capacity. We find
that GPT-4-turbo has some difficulties in the task while GPT-3.5-turbo
struggles and smaller models Llama2-70B and Poro-34B fail nearly completely.

摘要：基於規則的語言處理系統在實用性方面已被神經系統取代，但目前仍不清楚神經 NLP 系統在實際上是否學習人類使用的語法規則。這項工作旨在透過在複雜芬蘭語名詞形式的形態分析任務中評估最先進的 LLM 來闡明這個問題。我們使用 FST 工具產生這些形式，而且這些形式不太可能出現在 LLM 的訓練集中，因此需要形態概括能力。我們發現 GPT-4-turbo 在此任務中遇到了一些困難，而 GPT-3.5-turbo 則苦苦掙扎，而較小的模型 Llama2-70B 和 Poro-34B 幾乎完全失敗。

##### **Knowledge distillation to effectively attain both region-of-interest and global semantics from an image where multiple objects appear**
2407.08257v1 by Seonwhee Jin

Models based on convolutional neural networks (CNN) and transformers have
steadily been improved. They also have been applied in various computer vision
downstream tasks. However, in object detection tasks, accurately localizing and
classifying almost infinite categories of foods in images remains challenging.
To address these problems, we first segmented the food as the
region-of-interest (ROI) by using the segment-anything model (SAM) and masked
the rest of the region except ROI as black pixels. This process simplified the
problems into a single classification for which annotation and training were
much simpler than object detection. The images in which only the ROI was
preserved were fed as inputs to fine-tune various off-the-shelf models that
encoded their own inductive biases. Among them, Data-efficient image
Transformers (DeiTs) had the best classification performance. Nonetheless, when
foods' shapes and textures were similar, the contextual features of the
ROI-only images were not enough for accurate classification. Therefore, we
introduced a novel type of combined architecture, RveRNet, which consisted of
ROI, extra-ROI, and integration modules that allowed it to account for both the
ROI's and global contexts. The RveRNet's F1 score was 10% better than other
individual models when classifying ambiguous food images. If the RveRNet's
modules were DeiT with the knowledge distillation from the CNN, performed the
best. We investigated how architectures can be made robust against input noise
caused by permutation and translocation. The results indicated that there was a
trade-off between how much the CNN teacher's knowledge could be distilled to
DeiT and DeiT's innate strength. Code is publicly available at:
https://github.com/Seonwhee-Genome/RveRNet.

摘要：<paragraph>基於卷積神經網路 (CNN) 和 Transformer 的模型已持續獲得改善。它們也已應用於各種電腦視覺下游任務。然而，在物件偵測任務中，準確定位和分類影像中幾乎無限類別的食物仍然具有挑戰性。為了解決這些問題，我們首先使用分割任何東西模型 (SAM) 將食物分割為感興趣區域 (ROI)，並將 ROI 以外的區域遮罩為黑色像素。此程序將問題簡化為單一分類，其註解和訓練比物件偵測簡單許多。僅保留 ROI 的影像被提供為輸入，用於微調各種內建模型，這些模型編碼了其自身的歸納偏差。其中，資料有效率的影像 Transformer (DeiTs) 具有最佳的分類效能。儘管如此，當食物的形狀和質地相似時，僅 ROI 影像的脈絡特徵不足以進行準確分類。因此，我們引入了一種新穎的複合架構 RveRNet，它包含 ROI、ROI 外部和整合模組，使其能夠考量 ROI 和全域脈絡。RveRNet 的 F1 分數比其他個別模型高出 10%，用於分類模稜兩可的食物影像。如果 RveRNet 的模組是具備 CNN 知識萃取的 DeiT，則表現最佳。我們探討了如何讓架構對由排列和轉位造成的輸入雜訊具有穩健性。結果表明，CNN 教師的知識能萃取到 DeiT 的程度與 DeiT 的內在強度之間存在權衡。程式碼已公開於：https://github.com/Seonwhee-Genome/RveRNet。</paragraph>

##### **GeNet: A Multimodal LLM-Based Co-Pilot for Network Topology and Configuration**
2407.08249v1 by Beni Ifland, Elad Duani, Rubin Krief, Miro Ohana, Aviram Zilberman, Andres Murillo, Ofir Manor, Ortal Lavi, Hikichi Kenji, Asaf Shabtai, Yuval Elovici, Rami Puzis

Communication network engineering in enterprise environments is traditionally
a complex, time-consuming, and error-prone manual process. Most research on
network engineering automation has concentrated on configuration synthesis,
often overlooking changes in the physical network topology. This paper
introduces GeNet, a multimodal co-pilot for enterprise network engineers. GeNet
is a novel framework that leverages a large language model (LLM) to streamline
network design workflows. It uses visual and textual modalities to interpret
and update network topologies and device configurations based on user intents.
GeNet was evaluated on enterprise network scenarios adapted from Cisco
certification exercises. Our results demonstrate GeNet's ability to interpret
network topology images accurately, potentially reducing network engineers'
efforts and accelerating network design processes in enterprise environments.
Furthermore, we show the importance of precise topology understanding when
handling intents that require modifications to the network's topology.

摘要：企業環境中的通訊網路工程傳統上是一個複雜、耗時且容易出錯的手動程序。大多數關於網路工程自動化的研究都集中在組態合成，常常忽略實體網路拓撲的變動。本文介紹 GeNet，一個針對企業網路工程師的多模態副駕駛。GeNet 是一個新穎的架構，利用大型語言模型 (LLM) 來簡化網路設計工作流程。它使用視覺和文字模式來根據使用者的意圖，解釋和更新網路拓撲和裝置組態。GeNet 在改編自思科認證練習的企業網路場景中進行評估。我們的結果證明了 GeNet 準確解釋網路拓撲影像的能力，這有可能減少網路工程師的負擔，並加速企業環境中的網路設計程序。此外，我們展示了在處理需要修改網路拓撲的意圖時，精確了解拓撲的重要性。

##### **Toward accessible comics for blind and low vision readers**
2407.08248v1 by Christophe Rigaud, Jean-Christophe Burie, Samuel Petit

This work explores how to fine-tune large language models using prompt
engineering techniques with contextual information for generating an accurate
text description of the full story, ready to be forwarded to off-the-shelve
speech synthesis tools. We propose to use existing computer vision and optical
character recognition techniques to build a grounded context from the comic
strip image content, such as panels, characters, text, reading order and the
association of bubbles and characters. Then we infer character identification
and generate comic book script with context-aware panel description including
character's appearance, posture, mood, dialogues etc. We believe that such
enriched content description can be easily used to produce audiobook and eBook
with various voices for characters, captions and playing sound effects.

摘要：本研究探討如何使用提示工程技術微調大型語言模型，並利用脈絡資訊產生完整故事的精確文字描述，以便轉傳到現成的語音合成工具。我們建議使用現有的電腦視覺和光學字元辨識技術，從漫畫圖像內容建立一個基礎脈絡，例如面板、角色、文字、閱讀順序以及對話框和角色的關聯。然後，我們推論角色識別，並產生具有脈絡感知面板描述的漫畫腳本，包括角色的外觀、姿勢、情緒、對話等。我們相信這種豐富的內容描述可以輕鬆用於製作有聲書和電子書，並為角色、字幕和播放音效提供各種聲音。

##### **Leveraging LLMs to Predict Affective States via Smartphone Sensor Features**
2407.08240v1 by Tianyi Zhang, Songyan Teng, Hong Jia, Simon D'Alfonso

As mental health issues for young adults present a pressing public health
concern, daily digital mood monitoring for early detection has become an
important prospect. An active research area, digital phenotyping, involves
collecting and analysing data from personal digital devices such as smartphones
(usage and sensors) and wearables to infer behaviours and mental health. Whilst
this data is standardly analysed using statistical and machine learning
approaches, the emergence of large language models (LLMs) offers a new approach
to make sense of smartphone sensing data. Despite their effectiveness across
various domains, LLMs remain relatively unexplored in digital mental health,
particularly in integrating mobile sensor data. Our study aims to bridge this
gap by employing LLMs to predict affect outcomes based on smartphone sensing
data from university students. We demonstrate the efficacy of zero-shot and
few-shot embedding LLMs in inferring general wellbeing. Our findings reveal
that LLMs can make promising predictions of affect measures using solely
smartphone sensing data. This research sheds light on the potential of LLMs for
affective state prediction, emphasizing the intricate link between smartphone
behavioral patterns and affective states. To our knowledge, this is the first
work to leverage LLMs for affective state prediction and digital phenotyping
tasks.

摘要：隨著年輕人的心理健康問題成為迫切的公共衛生問題，每日數位情緒監控已成為早期偵測的重要前景。數位表型化是一個積極的研究領域，涉及收集和分析來自個人數位裝置（例如智慧型手機（使用和感測器）和可穿戴裝置）的資料，以推論行為和心理健康。雖然這些資料通常使用統計和機器學習方法進行分析，但大型語言模型 (LLM) 的出現提供了一種新的方法來理解智慧型手機感測資料。儘管 LLM 在各種領域都非常有效，但其在數位心理健康領域仍相對未被探索，特別是在整合行動感測器資料方面。我們的研究旨在透過使用 LLM 來根據大學生的智慧型手機感測資料預測影響結果，以彌合這一差距。我們展示了零次學習和少次學習嵌入式 LLM 在推論一般幸福感方面的效能。我們的研究結果顯示，LLM 可以僅使用智慧型手機感測資料對影響測量進行有希望的預測。本研究揭示了 LLM 在情感狀態預測方面的潛力，強調了智慧型手機行為模式和情感狀態之間的複雜聯繫。據我們所知，這是第一個利用 LLM 進行情感狀態預測和數位表型化任務的研究。

##### **DALL-M: Context-Aware Clinical Data Augmentation with LLMs**
2407.08227v1 by Chihcheng Hsieh, Catarina Moreira, Isabel Blanco Nobre, Sandra Costa Sousa, Chun Ouyang, Margot Brereton, Joaquim Jorge, Jacinto C. Nascimento

X-ray images are vital in medical diagnostics, but their effectiveness is
limited without clinical context. Radiologists often find chest X-rays
insufficient for diagnosing underlying diseases, necessitating comprehensive
clinical features and data integration. We present a novel technique to enhance
the clinical context through augmentation techniques with clinical tabular
data, thereby improving its applicability and reliability in AI medical
diagnostics. To address this, we introduce a pioneering approach to clinical
data augmentation that employs large language models (LLMs) to generate patient
contextual synthetic data. This methodology is crucial for training more robust
deep learning models in healthcare. It preserves the integrity of real patient
data while enriching the dataset with contextually relevant synthetic features,
significantly enhancing model performance. DALL-M uses a three-phase feature
generation process: (i) clinical context storage, (ii) expert query generation,
and (iii) context-aware feature augmentation. DALL-M generates new, clinically
relevant features by synthesizing chest X-ray images and reports. Applied to
799 cases using nine features from the MIMIC-IV dataset, it created an
augmented set of 91 features. This is the first work to generate contextual
values for existing and new features based on patients' X-ray reports, gender,
and age and to produce new contextual knowledge during data augmentation.
Empirical validation with machine learning models, including Decision Trees,
Random Forests, XGBoost, and TabNET, showed significant performance
improvements. Incorporating augmented features increased the F1 score by 16.5%
and Precision and Recall by approximately 25%. DALL-M addresses a critical gap
in clinical data augmentation, offering a robust framework for generating
contextually enriched datasets.

摘要：<paragraph>X 光影像在医学诊断中至关重要，但如果没有临床背景，其有效性会受到限制。放射科医生经常发现胸部 X 光影像不足以诊断潜在疾病，因此需要全面的临床特征和数据整合。我们提出了一种新技术，通过使用临床表格数据进行增强技术来增强临床背景，从而提高其在 AI 医学诊断中的适用性和可靠性。为了解决这个问题，我们引入了一种开创性的临床数据增强方法，该方法采用大型语言模型 (LLM) 来生成患者背景合成数据。这种方法对于在医疗保健领域训练更强大的深度学习模型至关重要。它保留了真实患者数据的完整性，同时使用与上下文相关的合成特征丰富了数据集，从而显著提高了模型性能。DALL-M 使用了一个三阶段特征生成过程：(i) 临床背景存储，(ii) 专家查询生成，(iii) 上下文感知特征增强。DALL-M 通过合成胸部 X 光影像和报告来生成新的、与临床相关的特征。将其应用于 MIMIC-IV 数据集中的 799 个案例，使用九个特征，它创建了一个包含 91 个特征的增强集合。这是第一项基于患者的 X 光报告、性别和年龄为现有和新特征生成上下文值的著作，并在数据增强期间产生新的上下文知识。使用包括决策树、随机森林、XGBoost 和 TabNET 在内的机器学习模型进行的经验验证显示出显著的性能改进。合并增强功能将 F1 分数提高了 16.5%，并将精确度和召回率提高了大约 25%。DALL-M 解决了一个临床数据增强中的关键空白，提供了一个用于生成上下文丰富的数据集的稳健框架。</paragraph>

##### **Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting**
2407.08223v1 by Zilong Wang, Zifeng Wang, Long Le, Huaixiu Steven Zheng, Swaroop Mishra, Vincent Perot, Yuwei Zhang, Anush Mattapalli, Ankur Taly, Jingbo Shang, Chen-Yu Lee, Tomas Pfister

Retrieval augmented generation (RAG) combines the generative abilities of
large language models (LLMs) with external knowledge sources to provide more
accurate and up-to-date responses. Recent RAG advancements focus on improving
retrieval outcomes through iterative LLM refinement or self-critique
capabilities acquired through additional instruction tuning of LLMs. In this
work, we introduce Speculative RAG - a framework that leverages a larger
generalist LM to efficiently verify multiple RAG drafts produced in parallel by
a smaller, distilled specialist LM. Each draft is generated from a distinct
subset of retrieved documents, offering diverse perspectives on the evidence
while reducing input token counts per draft. This approach enhances
comprehension of each subset and mitigates potential position bias over long
context. Our method accelerates RAG by delegating drafting to the smaller
specialist LM, with the larger generalist LM performing a single verification
pass over the drafts. Extensive experiments demonstrate that Speculative RAG
achieves state-of-the-art performance with reduced latency on TriviaQA,
MuSiQue, PubHealth, and ARC-Challenge benchmarks. It notably enhances accuracy
by up to 12.97% while reducing latency by 51% compared to conventional RAG
systems on PubHealth.

摘要：撷取增强生成（RAG）结合了大型语言模型（LLM）的生成能力和外部知识来源，以提供更准确且最新的回应。最近的 RAG 改进重点在于通过迭代 LLM 优化或经由 LLM 的额外指令微调所获得的自省能力来改善撷取结果。在这项工作中，我们引入了推测性 RAG，这是一个框架，它利用一个较大的通才 LM 来有效验证由较小的、精炼的专家 LM 并行产生的多个 RAG 草稿。每个草稿都是从撷取文件的一个不同子集生成的，它提供了证据的不同观点，同时减少了每个草稿的输入标记计数。这种方法增强了对每个子集的理解，并减轻了对长语境的潜在位置偏差。我们的方法通过将起草委派给较小的专家 LM 来加速 RAG，而较大的通才 LM 对草稿执行单次验证。广泛的实验表明，推测性 RAG 在 TriviaQA、MuSiQue、PubHealth 和 ARC-Challenge 基准测试中实现了最先进的性能，且延迟更低。与传统的 RAG 系统相比，它显著提高了准确度（最高提高 12.97%），同时将延迟降低了 51%，尤其是在 PubHealth 上。

##### **Generating Contextually-Relevant Navigation Instructions for Blind and Low Vision People**
2407.08219v1 by Zain Merchant, Abrar Anwar, Emily Wang, Souti Chattopadhyay, Jesse Thomason

Navigating unfamiliar environments presents significant challenges for blind
and low-vision (BLV) individuals. In this work, we construct a dataset of
images and goals across different scenarios such as searching through kitchens
or navigating outdoors. We then investigate how grounded instruction generation
methods can provide contextually-relevant navigational guidance to users in
these instances. Through a sighted user study, we demonstrate that large
pretrained language models can produce correct and useful instructions
perceived as beneficial for BLV users. We also conduct a survey and interview
with 4 BLV users and observe useful insights on preferences for different
instructions based on the scenario.

摘要：對於視障人士 (BLV) 來說，在陌生的環境中移動會造成重大的挑戰。在這項工作中，我們建立了一個資料集，其中包含不同情境中的影像和目標，例如在廚房中搜尋或在戶外導航。接著，我們探討如何運用基礎指令產生方法，在這些情況下為使用者提供與情境相關的導航指南。透過一項明眼使用者研究，我們證明大型預訓練語言模型可以產生正確且有用的指令，這些指令被視為對 BLV 使用者有益。我們也進行了一項調查，並訪談了 4 位 BLV 使用者，並觀察到基於情境的不同指令偏好方面的有用見解。

##### **Multimodal contrastive learning for spatial gene expression prediction using histology images**
2407.08216v1 by Wenwen Min, Zhiceng Shi, Jun Zhang, Jun Wan, Changmiao Wang

In recent years, the advent of spatial transcriptomics (ST) technology has
unlocked unprecedented opportunities for delving into the complexities of gene
expression patterns within intricate biological systems. Despite its
transformative potential, the prohibitive cost of ST technology remains a
significant barrier to its widespread adoption in large-scale studies. An
alternative, more cost-effective strategy involves employing artificial
intelligence to predict gene expression levels using readily accessible
whole-slide images (WSIs) stained with Hematoxylin and Eosin (H\&E). However,
existing methods have yet to fully capitalize on multimodal information
provided by H&E images and ST data with spatial location. In this paper, we
propose \textbf{mclSTExp}, a multimodal contrastive learning with Transformer
and Densenet-121 encoder for Spatial Transcriptomics Expression prediction. We
conceptualize each spot as a "word", integrating its intrinsic features with
spatial context through the self-attention mechanism of a Transformer encoder.
This integration is further enriched by incorporating image features via
contrastive learning, thereby enhancing the predictive capability of our model.
Our extensive evaluation of \textbf{mclSTExp} on two breast cancer datasets and
a skin squamous cell carcinoma dataset demonstrates its superior performance in
predicting spatial gene expression. Moreover, mclSTExp has shown promise in
interpreting cancer-specific overexpressed genes, elucidating immune-related
genes, and identifying specialized spatial domains annotated by pathologists.
Our source code is available at https://github.com/shizhiceng/mclSTExp.

摘要：<paragraph>近年來，空間轉錄組學 (ST) 技術的出現為深入研究複雜生物系統中基因表現模式的複雜性提供了前所未有的機會。儘管具有轉變潛力，但 ST 技術的高昂成本仍然是大規模研究中廣泛採用的重大障礙。一種替代的、更具成本效益的策略涉及使用人工智慧來預測使用易於取得的、染有蘇木精和曙紅 (H&E) 的全玻片影像 (WSI) 的基因表現水準。然而，現有方法尚未充分利用 H&E 影像和具有空間位置的 ST 資料所提供的多模態資訊。在本文中，我們提出 \textbf{mclSTExp}，一個多模態對比學習，使用 Transformer 和 Densenet-121 編碼器進行空間轉錄組學表現預測。我們將每個點概念化为一個「字」，透過 Transformer 編碼器的自注意力機制，將其內在特徵與空間脈絡整合在一起。這種整合通過對比學習進一步豐富了影像特徵，從而增強了我們模型的預測能力。我們對兩個乳癌資料集和一個皮膚鱗狀細胞癌資料集的 \textbf{mclSTExp} 進行廣泛評估，證明了其在預測空間基因表現方面的優異效能。此外，mclSTExp 已顯示出在解釋癌症特異性過度表現基因、闡明免疫相關基因以及識別病理學家註解的專門空間領域方面的前景。我們的原始碼可在 https://github.com/shizhiceng/mclSTExp 取得。</paragraph>

##### **System Report for CCL24-Eval Task 7: Multi-Error Modeling and Fluency-Targeted Pre-training for Chinese Essay Evaluation**
2407.08206v1 by Jingshen Zhang, Xiangyu Yang, Xinkai Su, Xinglu Chen, Tianyou Huang, Xinying Qiu

This system report presents our approaches and results for the Chinese Essay
Fluency Evaluation (CEFE) task at CCL-2024. For Track 1, we optimized
predictions for challenging fine-grained error types using binary
classification models and trained coarse-grained models on the Chinese Learner
4W corpus. In Track 2, we enhanced performance by constructing a pseudo-dataset
with multiple error types per sentence. For Track 3, where we achieved first
place, we generated fluency-rated pseudo-data via back-translation for
pre-training and used an NSP-based strategy with Symmetric Cross Entropy loss
to capture context and mitigate long dependencies. Our methods effectively
address key challenges in Chinese Essay Fluency Evaluation.

摘要：本系統報告介紹了我們在 CCL-2024 中文作文流暢度評估 (CEFE) 任務中的方法和結果。對於軌道 1，我們使用二元分類模型優化了對具有挑戰性的細粒度錯誤類型的預測，並在中文學習者 4W 語料庫上訓練了粗粒度模型。在軌道 2 中，我們通過構建每句話具有多種錯誤類型的偽數據集來增強性能。對於我們獲得第一名的軌道 3，我們通過反向翻譯生成了流暢度評級的偽數據，用於預訓練，並使用基於 NSP 的策略與對稱交叉熵損失來捕捉上下文並減輕長依賴性。我們的這些方法有效地應對了中文作文流暢度評估中的關鍵挑戰。

##### **Chromosomal Structural Abnormality Diagnosis by Homologous Similarity**
2407.08204v1 by Juren Li, Fanzhe Fu, Ran Wei, Yifei Sun, Zeyu Lai, Ning Song, Xin Chen, Yang Yang

Pathogenic chromosome abnormalities are very common among the general
population. While numerical chromosome abnormalities can be quickly and
precisely detected, structural chromosome abnormalities are far more complex
and typically require considerable efforts by human experts for identification.
This paper focuses on investigating the modeling of chromosome features and the
identification of chromosomes with structural abnormalities. Most existing
data-driven methods concentrate on a single chromosome and consider each
chromosome independently, overlooking the crucial aspect of homologous
chromosomes. In normal cases, homologous chromosomes share identical
structures, with the exception that one of them is abnormal. Therefore, we
propose an adaptive method to align homologous chromosomes and diagnose
structural abnormalities through homologous similarity. Inspired by the process
of human expert diagnosis, we incorporate information from multiple pairs of
homologous chromosomes simultaneously, aiming to reduce noise disturbance and
improve prediction performance. Extensive experiments on real-world datasets
validate the effectiveness of our model compared to baselines.

摘要：病原性染色體異常在一般族群中非常常見。雖然數目性染色體異常可以快速且精確地被偵測出來，但結構性染色體異常則複雜得多，通常需要人類專家投入大量的精力才能辨識出來。本文重點在於探討染色體特徵的建模，以及結構異常染色體的辨識。現有的大多數資料驅動方法都專注於單一染色體，並獨立考量每個染色體，忽略了同源染色體這個重要的面向。在正常情況下，同源染色體具有相同的結構，但其中一條染色體異常。因此，我們提出了一種自適應方法來比對同源染色體，並透過同源相似性診斷結構異常。受到人類專家診斷過程的啟發，我們同時納入多對同源染色體的資訊，目的是減少雜訊干擾並提升預測效能。針對真實世界的資料集進行的廣泛實驗驗證了我們模型的有效性，並與基準線進行比較。

##### **SoupLM: Model Integration in Large Language and Multi-Modal Models**
2407.08196v1 by Yue Bai, Zichen Zhang, Jiasen Lu, Yun Fu

Training large language models (LLMs) and multimodal LLMs necessitates
significant computing resources, and existing publicly available LLMs are
typically pre-trained on diverse, privately curated datasets spanning various
tasks. For instance, LLaMA, Vicuna, and LLaVA are three LLM variants trained
with LLaMA base models using very different training recipes, tasks, and data
modalities. The training cost and complexity for such LLM variants grow
rapidly. In this study, we propose to use a soup strategy to assemble these LLM
variants into a single well-generalized multimodal LLM (SoupLM) in a
cost-efficient manner. Assembling these LLM variants efficiently brings
knowledge and specialities trained from different domains and data modalities
into an integrated one (e.g., chatbot speciality from user-shared conversations
for Vicuna, and visual capacity from vision-language data for LLaVA),
therefore, to avoid computing costs of repetitive training on several different
domains. We propose series of soup strategies to systematically benchmark
performance gains across various configurations, and probe the soup behavior
across base models in the interpolation space.

摘要：訓練大型語言模型 (LLM) 和多模態 LLM 需要大量的運算資源，而現有的公開 LLM 通常使用多元且私有策展的資料集進行預先訓練，涵蓋各種任務。例如，LLaMA、Vicuna 和 LLaVA 是三個 LLM 變體，使用 LLaMA 基礎模型進行訓練，採用非常不同的訓練配方、任務和資料模式。此類 LLM 變體的訓練成本和複雜度會快速增加。在本研究中，我們建議使用湯策略將這些 LLM 變體組裝成一個單一的良好泛化多模態 LLM (SoupLM)，以一種具有成本效益的方式進行。有效地組裝這些 LLM 變體，將從不同領域和資料模式訓練而來的知識和專長帶入一個整合的模式（例如，Vicuna 的使用者共享對話中的聊天機器人專長，以及 LLaVA 的視覺語言資料中的視覺能力），因此，可以避免在多個不同領域進行重複訓練的運算成本。我們提出了一系列湯策略，以系統性地比較各種組態的效能提升，並探討插值空間中基礎模型之間的湯行為。

##### **A Text-to-Game Engine for UGC-Based Role-Playing Games**
2407.08195v1 by Lei Zhang, Xuezheng Peng, Shuyi Yang, Feiyang Wang

The shift from professionally generated content (PGC) to user-generated
content (UGC) has revolutionized various media formats, from text to video.
With the rapid advancements in generative AI, a similar shift is set to
transform the game industry, particularly in the realm of role-playing games
(RPGs). This paper introduces a new framework for a text-to-game engine that
utilizes foundation models to convert simple textual inputs into complex,
interactive RPG experiences. The engine dynamically renders the game story in a
multi-modal format and adjusts the game character, environment, and mechanics
in real-time in response to player actions. Using this framework, we developed
the "Zagii" game engine, which has successfully supported hundreds of RPG games
across a diverse range of genres and facilitated tens of thousands of online
user gameplay instances. This validates the effectiveness of our frame-work.
Our work showcases the potential for a more open and democratized gaming
paradigm, highlighting the transformative impact of generative AI on the game
life cycle.

摘要：從專業產製內容 (PGC) 轉變為使用者產製內容 (UGC) 已革新各種媒體格式，從文字到影片。
隨著生成式 AI 的快速進展，類似轉變將轉換遊戲產業，特別是在角色扮演遊戲 (RPG) 的領域。這篇論文介紹一個新的文字轉遊戲引擎架構，利用基礎模型將簡單的文字輸入轉換為複雜、互動式的 RPG 體驗。引擎以多模式格式動態呈現遊戲故事，並根據玩家行動即時調整遊戲角色、環境和機制。使用這個架構，我們開發了「Zagii」遊戲引擎，它已成功支援數百款 RPG 遊戲，涵蓋各種類型，並促進數萬個線上使用者遊戲實例。這驗證了我們架構的有效性。
我們的作品展示了一個更開放、更民主化的遊戲模式的潛力，突顯了生成式 AI 對遊戲生命週期的變革性影響。

##### **ARCO:Adaptive Multi-Agent Reinforcement Learning-Based Hardware/Software Co-Optimization Compiler for Improved Performance in DNN Accelerator Design**
2407.08192v1 by Arya Fayyazi, Mehdi Kamal, Massoud Pedram

This paper presents ARCO, an adaptive Multi-Agent Reinforcement Learning
(MARL)-based co-optimizing compilation framework designed to enhance the
efficiency of mapping machine learning (ML) models - such as Deep Neural
Networks (DNNs) - onto diverse hardware platforms. The framework incorporates
three specialized actor-critic agents within MARL, each dedicated to a distinct
aspect of compilation/optimization at an abstract level: one agent focuses on
hardware, while two agents focus on software optimizations. This integration
results in a collaborative hardware/software co-optimization strategy that
improves the precision and speed of DNN deployments. Concentrating on
high-confidence configurations simplifies the search space and delivers
superior performance compared to current optimization methods. The ARCO
framework surpasses existing leading frameworks, achieving a throughput
increase of up to 37.95% while reducing the optimization time by up to 42.2%
across various DNNs.

摘要：本文提出 ARCO，一種基於適應性多智能體強化學習 (MARL) 的共同最佳化編譯架構，旨在提升將機器學習 (ML) 模型（例如深度神經網路 (DNN)) 對應到不同硬體平台的效率。此架構在 MARL 中整合了三個專門的動作-評論智能體，每個智能體在抽象層面上專注於編譯/最佳化的不同面向：一個智能體專注於硬體，而另外兩個智能體則專注於軟體最佳化。這種整合產生一種協作式硬體/軟體共同最佳化策略，可提升 DNN 部署的精準度和速度。專注於高信心的組態可簡化搜尋空間，並提供優於現有最佳化方法的卓越效能。ARCO 架構超越現有的領先架構，在各種 DNN 中實現吞吐量增加高達 37.95%，同時將最佳化時間減少高達 42.2%。

##### **fairBERTs: Erasing Sensitive Information Through Semantic and Fairness-aware Perturbations**
2407.08189v1 by Jinfeng Li, Yuefeng Chen, Xiangyu Liu, Longtao Huang, Rong Zhang, Hui Xue

Pre-trained language models (PLMs) have revolutionized both the natural
language processing research and applications. However, stereotypical biases
(e.g., gender and racial discrimination) encoded in PLMs have raised negative
ethical implications for PLMs, which critically limits their broader
applications. To address the aforementioned unfairness issues, we present
fairBERTs, a general framework for learning fair fine-tuned BERT series models
by erasing the protected sensitive information via semantic and fairness-aware
perturbations generated by a generative adversarial network. Through extensive
qualitative and quantitative experiments on two real-world tasks, we
demonstrate the great superiority of fairBERTs in mitigating unfairness while
maintaining the model utility. We also verify the feasibility of transferring
adversarial components in fairBERTs to other conventionally trained BERT-like
models for yielding fairness improvements. Our findings may shed light on
further research on building fairer fine-tuned PLMs.

摘要：預訓練語言模型（PLM）徹底改變了自然語言處理研究和應用。然而，PLM 中編碼的刻板印象偏差（例如，性別和種族歧視）對 PLM 產生了負面的道德影響，這嚴重限制了它們更廣泛的應用。為了解決上述不公平問題，我們提出了 fairBERT，這是一個通用的框架，用於學習公平微調 BERT 系列模型，方法是通過生成對抗網路產生的語義和公平感知擾動來消除受保護的敏感資訊。透過在兩個真實世界任務中進行廣泛的質性和量化實驗，我們證明了 fairBERT 在減輕不公平性方面的優越性，同時還能維持模型效用。我們也驗證了將 fairBERT 中的對抗組件轉移到其他傳統訓練的 BERT 類模型以產生公平性改進的可行性。我們的發現可能會為進一步研究構建更公平的微調 PLM 奠定基礎。

##### **Automatic Generation of Web Censorship Probe Lists**
2407.08185v1 by Jenny Tang, Leo Alvarez, Arjun Brar, Nguyen Phong Hoang, Nicolas Christin

Domain probe lists--used to determine which URLs to probe for Web
censorship--play a critical role in Internet censorship measurement studies.
Indeed, the size and accuracy of the domain probe list limits the set of
censored pages that can be detected; inaccurate lists can lead to an incomplete
view of the censorship landscape or biased results. Previous efforts to
generate domain probe lists have been mostly manual or crowdsourced. This
approach is time-consuming, prone to errors, and does not scale well to the
ever-changing censorship landscape.
  In this paper, we explore methods for automatically generating probe lists
that are both comprehensive and up-to-date for Web censorship measurement. We
start from an initial set of 139,957 unique URLs from various existing test
lists consisting of pages from a variety of languages to generate new candidate
pages. By analyzing content from these URLs (i.e., performing topic and keyword
extraction), expanding these topics, and using them as a feed to search
engines, our method produces 119,255 new URLs across 35,147 domains. We then
test the new candidate pages by attempting to access each URL from servers in
eleven different global locations over a span of four months to check for their
connectivity and potential signs of censorship. Our measurements reveal that
our method discovered over 1,400 domains--not present in the original
dataset--we suspect to be blocked. In short, automatically updating probe lists
is possible, and can help further automate censorship measurements at scale.

摘要：網域探測清單（用於判斷哪些網址要探測網路審查）在網路審查測量研究中扮演著關鍵角色。事實上，網域探測清單的大小和準確性會限制可偵測到的受審查網頁；不準確的清單可能會導致審查情況的觀點不完整或結果有偏差。過去產生網域探測清單的方法大多是手動或群眾外包。這種方法耗時、容易出錯，而且無法很好地應對不斷變化的審查情況。
在本文中，我們探討了自動產生既全面又最新的探測清單的方法，以用於網路審查測量。我們從 139,957 個來自各種現有測試清單的獨特網址開始，這些清單包含各種語言的網頁，以產生新的候選網頁。透過分析這些網址的內容（例如，執行主題和關鍵字萃取），擴充這些主題，並將它們用作搜尋引擎的饋送，我們的做法產生了 35,147 個網域中的 119,255 個新網址。然後，我們透過嘗試從 11 個不同全球位置的伺服器存取每個網址，在四個月的時間跨度內測試新的候選網頁，以檢查它們的連線性和潛在的審查跡象。我們的測量顯示，我們的做法發現了超過 1,400 個網域（未出現在原始資料集中）我們懷疑遭到封鎖。簡而言之，自動更新探測清單是可行的，而且有助於進一步自動化大規模的審查測量。

##### **Beyond Text: Leveraging Multi-Task Learning and Cognitive Appraisal Theory for Post-Purchase Intention Analysis**
2407.08182v1 by Gerard Christopher Yeo, Shaz Furniturewala, Kokil Jaidka

Supervised machine-learning models for predicting user behavior offer a
challenging classification problem with lower average prediction performance
scores than other text classification tasks. This study evaluates multi-task
learning frameworks grounded in Cognitive Appraisal Theory to predict user
behavior as a function of users' self-expression and psychological attributes.
Our experiments show that users' language and traits improve predictions above
and beyond models predicting only from text. Our findings highlight the
importance of integrating psychological constructs into NLP to enhance the
understanding and prediction of user actions. We close with a discussion of the
implications for future applications of large language models for computational
psychology.

摘要：監督機器學習模型用於預測使用者行為，提供具有較低平均預測效能評分的挑戰性分類問題，低於其他文字分類任務。本研究評估以認知評估理論為基礎的多任務學習架構，以預測使用者行為為使用者自我表達和心理屬性的函數。我們的實驗顯示，使用者的語言和特質可改善預測，且優於僅從文字預測的模型。我們的研究結果強調將心理建構整合到自然語言處理中的重要性，以增進對使用者行為的理解和預測。我們以討論大型語言模型在計算心理學中未來應用程式之含意做為結尾。

##### **CoGS: Causality Constrained Counterfactual Explanations using goal-directed ASP**
2407.08179v1 by Sopam Dasgupta, Joaquín Arias, Elmer Salazar, Gopal Gupta

Machine learning models are increasingly used in areas such as loan approvals
and hiring, yet they often function as black boxes, obscuring their
decision-making processes. Transparency is crucial, and individuals need
explanations to understand decisions, especially for the ones not desired by
the user. Ethical and legal considerations require informing individuals of
changes in input attribute values (features) that could lead to a desired
outcome for the user. Our work aims to generate counterfactual explanations by
considering causal dependencies between features. We present the CoGS
(Counterfactual Generation with s(CASP)) framework that utilizes the
goal-directed Answer Set Programming system s(CASP) to generate counterfactuals
from rule-based machine learning models, specifically the FOLD-SE algorithm.
CoGS computes realistic and causally consistent changes to attribute values
taking causal dependencies between them into account. It finds a path from an
undesired outcome to a desired one using counterfactuals. We present details of
the CoGS framework along with its evaluation.

摘要：機器學習模型在貸款核准和聘雇等領域中使用越來越廣泛，但它們通常以黑盒子的方式運作，讓人無法了解其決策過程。透明度至關重要，個人需要解釋才能了解決策，特別是使用者不想要的決策。倫理和法律考量要求告知個人輸入屬性值（特徵）的變更，這可能會導致使用者想要的結果。我們的研究旨在透過考量特徵之間的因果關係來產生反事實解釋。我們提出 CoGS（反事實產生與 s(CASP)）架構，它利用目標導向的 Answer Set 程式設計系統 s(CASP) 從基於規則的機器學習模型（特別是 FOLD-SE 演算法）產生反事實。CoGS 計算屬性值的實際且因果一致的變更，並考量它們之間的因果關係。它使用反事實找出從不想要的結果到想要的結果的路徑。我們會說明 CoGS 架構的詳細資訊以及其評估。

##### **Foundation Model Engineering: Engineering Foundation Models Just as Engineering Software**
2407.08176v1 by Dezhi Ran, Mengzhou Wu, Wei Yang, Tao Xie

By treating data and models as the source code, Foundation Models (FMs)
become a new type of software. Mirroring the concept of software crisis, the
increasing complexity of FMs making FM crisis a tangible concern in the coming
decade, appealing for new theories and methodologies from the field of software
engineering. In this paper, we outline our vision of introducing Foundation
Model (FM) engineering, a strategic response to the anticipated FM crisis with
principled engineering methodologies. FM engineering aims to mitigate potential
issues in FM development and application through the introduction of
declarative, automated, and unified programming interfaces for both data and
model management, reducing the complexities involved in working with FMs by
providing a more structured and intuitive process for developers. Through the
establishment of FM engineering, we aim to provide a robust, automated, and
extensible framework that addresses the imminent challenges, and discovering
new research opportunities for the software engineering field.

摘要：透過將資料和模型視為原始碼，基礎模型 (FM) 成為一種新型軟體。呼應軟體危機的概念，FM 的複雜性日益提升，使得 FM 危機在未來十年內成為具體的隱憂，呼籲軟體工程領域提出新的理論和方法。在本文中，我們概述了我們推動基礎模型 (FM) 工程的願景，這是一種策略性的回應，旨在透過有原則的工程方法來應對預期的 FM 危機。FM 工程旨在透過為資料和模型管理導入宣告式、自動化且統一的程式設計介面，來減輕 FM 開發和應用中的潛在問題，並透過為開發人員提供更結構化且直觀的流程，來降低使用 FM 所涉及的複雜性。透過建立 FM 工程，我們旨在提供一個強健、自動化且可擴充的架構，以應對迫在眉睫的挑戰，並為軟體工程領域探索新的研究機會。

##### **Faster Machine Unlearning via Natural Gradient Descent**
2407.08169v1 by Omri Lev, Ashia Wilson

We address the challenge of efficiently and reliably deleting data from
machine learning models trained using Empirical Risk Minimization (ERM), a
process known as machine unlearning. To avoid retraining models from scratch,
we propose a novel algorithm leveraging Natural Gradient Descent (NGD). Our
theoretical framework ensures strong privacy guarantees for convex models,
while a practical Min/Max optimization algorithm is developed for non-convex
models. Comprehensive evaluations show significant improvements in privacy,
computational efficiency, and generalization compared to state-of-the-art
methods, advancing both the theoretical and practical aspects of machine
unlearning.

摘要：我們處理從使用經驗風險最小化 (ERM) 訓練的機器學習模型中有效且可靠地刪除資料的挑戰，這個程序稱為機器遺忘。為了避免從頭開始重新訓練模型，我們提出了一種利用自然梯度下降 (NGD) 的新演算法。我們的理論架構確保了凸模型的強隱私保證，同時為非凸模型開發了一個實用的 Min/Max 最佳化演算法。全面的評估顯示，與最先進的方法相比，隱私、運算效率和概化都有顯著的改善，推動了機器遺忘的理論和實務層面。

##### **Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder**
2407.08166v1 by Mikhail Kulyabin, Paul A. Constable, Aleksei Zhdanov, Irene O. Lee, David H. Skuse, Dorothy A. Thompson, Andreas Maier

The electroretinogram (ERG) is a clinical test that records the retina's
electrical response to light. The ERG is a promising way to study different
neurodevelopmental and neurodegenerative disorders, including autism spectrum
disorder (ASD) - a neurodevelopmental condition that impacts language,
communication, and reciprocal social interactions. However, in heterogeneous
populations, such as ASD, where the ability to collect large datasets is
limited, the application of artificial intelligence (AI) is complicated.
Synthetic ERG signals generated from real ERG recordings carry similar
information as natural ERGs and, therefore, could be used as an extension for
natural data to increase datasets so that AI applications can be fully
utilized. As proof of principle, this study presents a Generative Adversarial
Network capable of generating synthetic ERG signals of children with ASD and
typically developing control individuals. We applied a Time Series Transformer
and Visual Transformer with Continuous Wavelet Transform to enhance
classification results on the extended synthetic signals dataset. This approach
may support classification models in related psychiatric conditions where the
ERG may help classify disorders.

摘要：視網膜電圖 (ERG) 是一種臨床測試，用於記錄視網膜對光的電氣反應。ERG 是一種很有前途的研究不同神經發育和神經退化性疾病的方法，包括自閉症譜系障礙 (ASD) - 一種影響語言、溝通和社交互動的神經發育狀況。然而，在異質人群中，例如 ASD，收集大型數據集的能力有限，人工智能 (AI) 的應用很複雜。從真實 ERG 記錄中產生的合成 ERG 信號攜帶與自然 ERG 相似的信息，因此可用作自然數據的擴展，以增加數據集，以便 AI 應用程序可以得到充分利用。作為原理證明，本研究提出了一個生成對抗網路，能夠產生自閉症兒童和正常發育對照個人的合成 ERG 信號。我們應用時序轉換器和具有連續小波轉換的視覺轉換器來增強擴展合成信號數據集上的分類結果。這種方法可以支持相關精神疾病的分類模型，在這些疾病中，ERG 可能有助於對疾病進行分類。

##### **Privacy-Preserving Data Deduplication for Enhancing Federated Learning of Language Models**
2407.08152v1 by Aydin Abadi, Vishnu Asutosh Dasu, Sumanta Sarkar

Deduplication is a vital preprocessing step that enhances machine learning
model performance and saves training time and energy. However, enhancing
federated learning through deduplication poses challenges, especially regarding
scalability and potential privacy violations if deduplication involves sharing
all clients' data. In this paper, we address the problem of deduplication in a
federated setup by introducing a pioneering protocol, Efficient
Privacy-Preserving Multi-Party Deduplication (EP-MPD). It efficiently removes
duplicates from multiple clients' datasets without compromising data privacy.
EP-MPD is constructed in a modular fashion, utilizing two novel variants of the
Private Set Intersection protocol. Our extensive experiments demonstrate the
significant benefits of deduplication in federated learning of large language
models. For instance, we observe up to 19.61% improvement in perplexity and up
to 27.95% reduction in running time. EP-MPD effectively balances privacy and
performance in federated learning, making it a valuable solution for
large-scale applications.

摘要：重複資料刪除是一個重要的預處理步驟，可以提升機器學習模型的效能，並節省訓練時間和精力。然而，透過重複資料刪除來強化聯邦學習會帶來挑戰，特別是在可擴充性和潛在的隱私權侵犯方面，如果重複資料刪除涉及分享所有用戶的資料。在本文中，我們透過引入一個創新的協定，有效率的隱私保護多方重複資料刪除（EP-MPD），來解決聯邦設定中的重複資料刪除問題。它可以有效率地從多個用戶的資料集中移除重複資料，而不會損害資料隱私。EP-MPD 是以模組化方式建構的，利用了私密集合交集協定的兩個新變體。我們廣泛的實驗證明了重複資料刪除在大型語言模型的聯邦學習中具有顯著的優點。例如，我們觀察到困惑度最高改善了 19.61%，執行時間最多減少了 27.95%。EP-MPD 有效地在聯邦學習中平衡了隱私和效能，使其成為大規模應用的一個有價值的解決方案。

##### **Looks can be Deceptive: Distinguishing Repetition Disfluency from Reduplication**
2407.08147v1 by Arif Ahmad, Mothika Gayathri Khyathi, Pushpak Bhattacharyya

Reduplication and repetition, though similar in form, serve distinct
linguistic purposes. Reduplication is a deliberate morphological process used
to express grammatical, semantic, or pragmatic nuances, while repetition is
often unintentional and indicative of disfluency. This paper presents the first
large-scale study of reduplication and repetition in speech using computational
linguistics. We introduce IndicRedRep, a new publicly available dataset
containing Hindi, Telugu, and Marathi text annotated with reduplication and
repetition at the word level. We evaluate transformer-based models for
multi-class reduplication and repetition token classification, utilizing the
Reparandum-Interregnum-Repair structure to distinguish between the two
phenomena. Our models achieve macro F1 scores of up to 85.62% in Hindi, 83.95%
in Telugu, and 84.82% in Marathi for reduplication-repetition classification.

摘要：重複和重言雖然形式相似，但在語言學上卻有不同的用途。重複是一種故意的形態過程，用於表達語法、語義或語用上的細微差別，而重言通常是不自覺的，且表示言語不流暢。本文提出使用計算語言學進行重複和重言的第一個大規模研究。我們引入了 IndicRedRep，一個新的公開可用的資料集，其中包含標註了印地語、泰盧固語和馬拉地語文字中詞級的重複和重言。我們評估了基於Transformer的多類重複和重言標記分類模型，利用 Reparandum-Interregnum-Repair 結構來區分這兩種現象。我們的模型在印地語中重複-重言分類的宏觀 F1 分數高達 85.62%，泰盧固語為 83.95%，馬拉地語為 84.82%。

##### **Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates**
2407.08134v1 by A. Noorizadegan, Y. C. Hon, D. L. Young, C. S. Chen

Surface reconstruction from point clouds is a fundamental challenge in
computer graphics and medical imaging. In this paper, we explore the
application of advanced neural network architectures for the accurate and
efficient reconstruction of surfaces from data points. We introduce a novel
variant of the Highway network (Hw) called Square-Highway (SqrHw) within the
context of multilayer perceptrons and investigate its performance alongside
plain neural networks and a simplified Hw in various numerical examples. These
examples include the reconstruction of simple and complex surfaces, such as
spheres, human hands, and intricate models like the Stanford Bunny. We analyze
the impact of factors such as the number of hidden layers, interior and
exterior points, and data distribution on surface reconstruction quality. Our
results show that the proposed SqrHw architecture outperforms other neural
network configurations, achieving faster convergence and higher-quality surface
reconstructions. Additionally, we demonstrate the SqrHw's ability to predict
surfaces over missing data, a valuable feature for challenging applications
like medical imaging. Furthermore, our study delves into further details,
demonstrating that the proposed method based on highway networks yields more
stable weight norms and backpropagation gradients compared to the Plain Network
architecture. This research not only advances the field of computer graphics
but also holds utility for other purposes such as function interpolation and
physics-informed neural networks, which integrate multilayer perceptrons into
their algorithms.

摘要：從點雲進行曲面重建是電腦圖學和醫學影像中的一項基本挑戰。在本文中，我們探討了先進神經網路架構在從資料點精確且有效重建曲面中的應用。我們在多層感知器的架構中，引入了高速公路網路（Hw）的一種新變體，稱為 Square-Highway（SqrHw），並在各種數值範例中探討其效能，以及與一般神經網路和簡化的 Hw 的效能。這些範例包括重建簡單和複雜的曲面，例如球體、人手和像 Stanford Bunny 那樣複雜的模型。我們分析了隱藏層數、內部和外部點以及資料分佈等因素對曲面重建品質的影響。我們的結果顯示，所提出的 SqrHw 架構優於其他神經網路組態，能達成更快的收斂速度和更高品質的曲面重建。此外，我們展示了 SqrHw 能夠預測遺失資料上的曲面，這對於像醫學影像那樣具有挑戰性的應用來說，是一個有價值的功能。此外，我們的研究深入探討了更多細節，證明了基於高速公路網路的所提出方法，與一般網路架構相比，產生了更穩定的權重範數和反向傳播梯度。這項研究不僅推動了電腦圖學領域，也對其他用途有幫助，例如函數內插和物理資訊神經網路，將多層感知器整合到其演算法中。

##### **Nonverbal Interaction Detection**
2407.08133v1 by Jianan Wei, Tianfei Zhou, Yi Yang, Wenguan Wang

This work addresses a new challenge of understanding human nonverbal
interaction in social contexts. Nonverbal signals pervade virtually every
communicative act. Our gestures, facial expressions, postures, gaze, even
physical appearance all convey messages, without anything being said. Despite
their critical role in social life, nonverbal signals receive very limited
attention as compared to the linguistic counterparts, and existing solutions
typically examine nonverbal cues in isolation. Our study marks the first
systematic effort to enhance the interpretation of multifaceted nonverbal
signals. First, we contribute a novel large-scale dataset, called NVI, which is
meticulously annotated to include bounding boxes for humans and corresponding
social groups, along with 22 atomic-level nonverbal behaviors under five broad
interaction types. Second, we establish a new task NVI-DET for nonverbal
interaction detection, which is formalized as identifying triplets in the form
<individual, group, interaction> from images. Third, we propose a nonverbal
interaction detection hypergraph (NVI-DEHR), a new approach that explicitly
models high-order nonverbal interactions using hypergraphs. Central to the
model is a dual multi-scale hypergraph that adeptly addresses
individual-to-individual and group-to-group correlations across varying scales,
facilitating interactional feature learning and eventually improving
interaction prediction. Extensive experiments on NVI show that NVI-DEHR
improves various baselines significantly in NVI-DET. It also exhibits leading
performance on HOI-DET, confirming its versatility in supporting related tasks
and strong generalization ability. We hope that our study will offer the
community new avenues to explore nonverbal signals in more depth.

摘要：<paragraph>這項工作解決了在社交情境中理解人類非語言互動的新挑戰。非語言信號幾乎存在於每一個溝通行為中。我們的肢體動作、面部表情、姿勢、注視，甚至外觀都會傳達訊息，而無需言語。儘管非語言信號在社交生活中扮演著重要的角色，但與語言信號相比，它們受到的關注卻非常有限，而現有的解決方案通常孤立地檢視非語言線索。我們的研究標誌著首次有系統地努力增強對多面向非語言信號的詮釋。首先，我們貢獻了一個新穎的大規模資料集，稱為 NVI，它經過仔細註解，包括人類和對應社交群體的邊界框，以及五種類型互動中的 22 種原子級非語言行為。其次，我們建立了一個新的任務 NVI-DET，用於非語言互動偵測，其形式化為從影像中識別形式為<個人、群體、互動>的三元組。第三，我們提出了一個非語言互動偵測超圖（NVI-DEHR），這是一種新方法，它使用超圖明確地建模高階非語言互動。該模型的核心是一個雙多尺度超圖，它巧妙地處理了不同尺度上的個人對個人和群體對群體的相關性，促進了互動特徵學習，並最終改進了互動預測。在 NVI 上進行的廣泛實驗表明，NVI-DEHR 在 NVI-DET 中顯著改善了各種基準。它還在 HOI-DET 上展現了領先的效能，確認了它在支援相關任務和強大的泛化能力方面的多功能性。我們希望我們的研究能為社群提供新的途徑，更深入地探索非語言信號。</paragraph>

##### **Label-anticipated Event Disentanglement for Audio-Visual Video Parsing**
2407.08126v1 by Jinxing Zhou, Dan Guo, Yuxin Mao, Yiran Zhong, Xiaojun Chang, Meng Wang

Audio-Visual Video Parsing (AVVP) task aims to detect and temporally locate
events within audio and visual modalities. Multiple events can overlap in the
timeline, making identification challenging. While traditional methods usually
focus on improving the early audio-visual encoders to embed more effective
features, the decoding phase -- crucial for final event classification, often
receives less attention. We aim to advance the decoding phase and improve its
interpretability. Specifically, we introduce a new decoding paradigm,
\underline{l}abel s\underline{e}m\underline{a}ntic-based \underline{p}rojection
(LEAP), that employs labels texts of event categories, each bearing distinct
and explicit semantics, for parsing potentially overlapping events.LEAP works
by iteratively projecting encoded latent features of audio/visual segments onto
semantically independent label embeddings. This process, enriched by modeling
cross-modal (audio/visual-label) interactions, gradually disentangles event
semantics within video segments to refine relevant label embeddings,
guaranteeing a more discriminative and interpretable decoding process. To
facilitate the LEAP paradigm, we propose a semantic-aware optimization
strategy, which includes a novel audio-visual semantic similarity loss
function. This function leverages the Intersection over Union of audio and
visual events (EIoU) as a novel metric to calibrate audio-visual similarities
at the feature level, accommodating the varied event densities across
modalities. Extensive experiments demonstrate the superiority of our method,
achieving new state-of-the-art performance for AVVP and also enhancing the
relevant audio-visual event localization task.

摘要：視聽影片解析 (AVVP) 任務旨在偵測和暫時定位音訊和視覺模式中的事件。多重事件可能會在時間軸中重疊，使得識別具有挑戰性。雖然傳統方法通常專注於改進早期音訊視覺編碼器以嵌入更有效的特徵，但對於最終事件分類至關重要的解碼階段，通常較少受到關注。我們旨在推進解碼階段並改善其可解釋性。具體來說，我們引入一種新的解碼範例，\underline{l}abel s\underline{e}m\underline{a}ntic-based \underline{p}rojection (LEAP)，它採用事件類別的標籤文字，每個文字都帶有不同的明確語義，用於解析潛在重疊事件。LEAP 的運作方式是將音訊/視覺片段的編碼潛在特徵反覆投影到語義獨立的標籤嵌入中。這個過程透過建模跨模態（音訊/視覺標籤）互動而得到豐富，逐漸解開影片片段中的事件語義，以改善相關標籤嵌入，保證更具區辨力和可解釋性的解碼過程。為了促進 LEAP 範例，我們提出一個語義感知最佳化策略，其中包括一個新穎的音訊視覺語義相似性損失函數。此函數利用音訊和視覺事件的聯合相對於交集 (EIoU) 作為一個新穎的指標，用於校準特徵層級的音訊視覺相似性，以適應各種跨模態的事件密度。廣泛的實驗證明了我們方法的優越性，在 AVVP 中取得了新的最先進效能，並增強了相關的音訊視覺事件定位任務。

##### **How Well Can a Long Sequence Model Model Long Sequences? Comparing Architechtural Inductive Biases on Long-Context Abilities**
2407.08112v1 by Jerry Huang

Long sequences occur in abundance within real-world scenarios, hence properly
modelling them opens numerous down-stream use-cases. Deep neural networks,
however, have often struggled with these for a variety of reasons. Recent
advances, both in system engineering as well as model design, have enabled the
scaling up of model that are purported to support extended context length. In
particular, the state-space and linear recurrent neural network families of
models hypothetically can entend to infinite sequence lenth. However, is this
too good to be true? We conduct an evaluation to show that while such claims
may be sound theoretically, there remain large practical gaps that are
empirically observed. In particular, recurrent models still suffer in the same
settings as long-context LLMs with attention. We further show that different
inductive biases have inconsistent extrapolation capabilities, highlighting the
need to further study such paradigms and investigate why long-context models
seemingly fail to behave as one might expect.

摘要：長序列在現實世界中大量出現，因此適當的建模為我們開啟了許多下游用例。然而，由於各種原因，深度神經網路經常難以處理這些序列。系統工程和模型設計的最新進展，使得擴展模型的上下文長度成為可能，而這些模型據稱可以支援擴展的上下文長度。特別是，狀態空間和線性遞迴神經網路的模型族在理論上可以延伸到無限序列長度。然而，這是否好得令人難以置信？我們進行了一項評估，以表明雖然這些說法在理論上可能是合理的，但仍存在大量在經驗上觀察到的實際差距。特別是，遞迴模型在與具有注意力的長上下文 LLM 相同的設定中仍然表現不佳。我們進一步表明，不同的歸納偏差具有不一致的外推能力，強調了進一步研究這些範例和調查為什麼長上下文模型看似無法按照預期行為的必要性。

##### **Urban Waterlogging Detection: A Challenging Benchmark and Large-Small Model Co-Adapter**
2407.08109v1 by Suqi Song, Chenxu Zhang, Peng Zhang, Pengkun Li, Fenglong Song, Lei Zhang

Urban waterlogging poses a major risk to public safety and infrastructure.
Conventional methods using water-level sensors need high-maintenance to hardly
achieve full coverage. Recent advances employ surveillance camera imagery and
deep learning for detection, yet these struggle amidst scarce data and adverse
environmental conditions. In this paper, we establish a challenging Urban
Waterlogging Benchmark (UW-Bench) under diverse adverse conditions to advance
real-world applications. We propose a Large-Small Model co-adapter paradigm
(LSM-adapter), which harnesses the substantial generic segmentation potential
of large model and the specific task-directed guidance of small model.
Specifically, a Triple-S Prompt Adapter module alongside a Dynamic Prompt
Combiner are proposed to generate then merge multiple prompts for mask decoder
adaptation. Meanwhile, a Histogram Equalization Adap-ter module is designed to
infuse the image specific information for image encoder adaptation. Results and
analysis show the challenge and superiority of our developed benchmark and
algorithm. Project page: \url{https://github.com/zhang-chenxu/LSM-Adapter}

摘要：城市內澇對公共安全和基礎設施構成重大風險。
使用水位感測器的傳統方法需要高維護，難以實現全面覆蓋。最近的進展採用監控相機影像和深度學習進行偵測，但這些方法在稀缺的資料和惡劣的環境條件下仍面臨挑戰。在本文中，我們建立了一個具有挑戰性的城市內澇基準 (UW-Bench)，在各種不利條件下推進實際應用。我們提出了一個大型-小型模型共適應範例 (LSM-adapter)，它利用了大型模型的強大通用分割潛力和小模型的特定任務指導。
具體來說，提出了一個三 S 提示適配器模組和一個動態提示組合器，用於生成然後合併多個提示以進行遮罩解碼器適應。同時，設計了一個直方圖均衡適配器模組，用於為影像編碼器適應注入影像特定資訊。結果和分析顯示了我們開發的基準和演算法的挑戰和優越性。專案頁面：\url{https://github.com/zhang-chenxu/LSM-Adapter}

##### **CADC: Encoding User-Item Interactions for Compressing Recommendation Model Training Data**
2407.08108v1 by Hossein Entezari Zarch, Abdulla Alshabanah, Chaoyi Jiang, Murali Annavaram

Deep learning recommendation models (DLRMs) are at the heart of the current
e-commerce industry. However, the amount of training data used to train these
large models is growing exponentially, leading to substantial training hurdles.
The training dataset contains two primary types of information: content-based
information (features of users and items) and collaborative information
(interactions between users and items). One approach to reduce the training
dataset is to remove user-item interactions. But that significantly diminishes
collaborative information, which is crucial for maintaining accuracy due to its
inclusion of interaction histories. This loss profoundly impacts DLRM
performance.
  This paper makes an important observation that if one can capture the
user-item interaction history to enrich the user and item embeddings, then the
interaction history can be compressed without losing model accuracy. Thus, this
work, Collaborative Aware Data Compression (CADC), takes a two-step approach to
training dataset compression. In the first step, we use matrix factorization of
the user-item interaction matrix to create a novel embedding representation for
both the users and items. Once the user and item embeddings are enriched by the
interaction history information the approach then applies uniform random
sampling of the training dataset to drastically reduce the training dataset
size while minimizing model accuracy drop. The source code of CADC is available
at
\href{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}.

摘要：深度學習推薦模型 (DLRM) 是當前電子商務產業的核心。然而，用於訓練這些大型模型的訓練資料量呈指數級增長，導致訓練面臨重大障礙。訓練資料集包含兩種類型的主要資訊：基於內容的資訊（使用者和商品的特徵）與協作資訊（使用者與商品之間的互動）。一種減少訓練資料集的方法是移除使用者與商品的互動。但是，這會大幅減少協作資訊，而協作資訊對於維持準確性至關重要，因為它包含互動記錄。這種損失會嚴重影響 DLRM 的效能。
本文提出一個重要的觀察，如果能擷取使用者與商品的互動記錄來豐富使用者和商品的嵌入，那麼互動記錄就可以在不降低模型準確性的情況下進行壓縮。因此，這項協作感知資料壓縮 (CADC) 工作採取兩步驟的方式來進行訓練資料集壓縮。在第一步中，我們使用使用者與商品互動矩陣的矩陣分解，為使用者和商品建立一個新穎的嵌入表示。一旦使用者和商品的嵌入通過互動記錄資訊得到豐富，此方法就會對訓練資料集套用均勻隨機抽樣，以大幅減少訓練資料集大小，同時將模型準確度下降降到最低。CADC 的原始程式碼可在
\href{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md} 取得。

##### **Federated Learning and AI Regulation in the European Union: Who is Responsible? -- An Interdisciplinary Analysis**
2407.08105v2 by Herbert Woisetschläger, Simon Mertel, Christoph Krönke, Ruben Mayer, Hans-Arno Jacobsen

The European Union Artificial Intelligence Act mandates clear stakeholder
responsibilities in developing and deploying machine learning applications to
avoid substantial fines, prioritizing private and secure data processing with
data remaining at its origin. Federated Learning (FL) enables the training of
generative AI Models across data siloes, sharing only model parameters while
improving data security. Since FL is a cooperative learning paradigm, clients
and servers naturally share legal responsibility in the FL pipeline. Our work
contributes to clarifying the roles of both parties, explains strategies for
shifting responsibilities to the server operator, and points out open technical
challenges that we must solve to improve FL's practical applicability under the
EU AI Act.

摘要：歐盟人工智慧法規要求在開發和部署機器學習應用程式時明確利害關係人的責任，以避免巨額罰款，並優先考量私密且安全的資料處理，同時讓資料保留在原始位置。聯邦學習 (FL) 能讓生成式 AI 模型跨資料孤島進行訓練，只分享模型參數，同時提升資料安全性。由於 FL 是一種合作學習模式，客戶端和伺服器在 FL 管道中自然會共同承擔法律責任。我們的研究有助於釐清雙方的角色，說明將責任轉移給伺服器操作員的策略，並指出我們必須解決的開放式技術挑戰，才能改善 FL 在歐盟 AI 法規下的實際適用性。

##### **Automata-based constraints for language model decoding**
2407.08103v2 by Terry Koo, Frederick Liu, Luheng He

LMs are often expected to generate strings in some formal language; for
example, structured data, API calls, or code snippets. Although LMs can be
tuned to improve their adherence to formal syntax, this does not guarantee
conformance, especially with smaller LMs suitable for large-scale deployment.
In addition, tuning requires significant resources, making it impractical for
uncommon or task-specific formats. To prevent downstream parsing errors we
would ideally constrain the LM to only produce valid output, but this is
severely complicated by tokenization, which is typically both ambiguous and
misaligned with the formal grammar. We solve these issues through the
application of automata theory, deriving an efficient closed-form solution for
the regular languages, a broad class of formal languages with many practical
applications, including API calls or schema-guided JSON and YAML. We also
discuss pragmatic extensions for coping with the issue of high branching
factor. Finally, we extend our techniques to deterministic context-free
languages, which similarly admit an efficient closed-form solution. In spite of
its flexibility and representative power, our approach only requires access to
per-token decoding logits and lowers into simple calculations that are
independent of LM size, making it both efficient and easy to apply to almost
any LM architecture.

摘要：語言模型通常預期會在某些形式語言中產生字串；例如，結構化資料、API 呼叫或程式碼片段。儘管語言模型可以調整以改善其對形式語法的遵循，但這並不能保證相符性，特別是對於適合於大規模部署的小型語言模型。此外，調整需要大量的資源，這使得它對於不常見或特定於任務的格式不切實際。為了防止下游分析錯誤，我們理想上會限制語言模型只產生有效的輸出，但這會因為標記化而變得極為複雜，標記化通常既模稜兩可又不符合形式語法。我們透過應用自動機理論來解決這些問題，為正規語言導出一個有效的閉合形式解，正規語言是形式語言的一種廣泛類別，有許多實際應用，包括 API 呼叫或由架構引導的 JSON 和 YAML。我們也討論了應對高分支因子問題的務實擴充。最後，我們將我們的技術擴充到確定性無上下文語言，它同樣承認有效的閉合形式解。儘管有其靈活性和代表性，但我們的方法只需要存取每個標記的解碼 logit，並降低為與語言模型大小無關的簡單計算，這使得它既有效率又容易應用於幾乎任何語言模型架構。

##### **How does Burrows' Delta work on medieval Chinese poetic texts?**
2407.08099v1 by Boris Orekhov

Burrows' Delta was introduced in 2002 and has proven to be an effective tool
for author attribution. Despite the fact that these are different languages,
they mostly belong to the same grammatical type and use the same graphic
principle to convey speech in writing: a phonemic alphabet with word separation
using spaces. The question I want to address in this article is how well this
attribution method works with texts in a language with a different grammatical
structure and a script based on different principles. There are fewer studies
analyzing the effectiveness of the Delta method on Chinese texts than on texts
in European languages. I believe that such a low level of attention to Delta
from sinologists is due to the structure of the scientific field dedicated to
medieval Chinese poetry. Clustering based on intertextual distances worked
flawlessly. Delta produced results where clustering showed that the samples of
one author were most similar to each other, and Delta never confused different
poets. Despite the fact that I used an unconventional approach and applied the
Delta method to a language poorly suited for it, the method demonstrated its
effectiveness. Tang dynasty poets are correctly identified using Delta, and the
empirical pattern observed for authors writing in European standard languages
has been confirmed once again.

摘要：伯羅斯三角洲於 2002 年推出，已被證明是一種有效的作者歸屬工具。儘管這些是不同的語言，但它們大多屬於相同的語法類型，並使用相同的圖形原理以書面形式傳達語言：一個音素字母表，使用空格進行單詞分隔。我想在這篇文章中探討的問題是，這種歸屬方法在語言結構不同且基於不同原理的腳本中的文本中效果如何。分析三角洲方法對中文文本的有效性的研究少於對歐洲語言文本的研究。我相信漢學家對三角洲的關注度如此之低，是因為致力於中國中古詩歌的科學領域的結構。基於互文距離的聚類運作良好。三角洲產生了聚類結果，表明一位作者的樣本彼此最相似，而三角洲從未混淆過不同的詩人。儘管我使用了非常規的方法，並將三角洲方法應用於一種不太適合它的語言，但該方法證明了它的有效性。唐代詩人使用三角洲被正確識別，並且在歐洲標準語言中寫作的作者觀察到的經驗模式再次得到證實。

##### **Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing**
2407.08095v1 by Ian Steenstra, Farnaz Nouraei, Mehdi Arjmand, Timothy W. Bickmore

We introduce a novel application of large language models (LLMs) in
developing a virtual counselor capable of conducting motivational interviewing
(MI) for alcohol use counseling. Access to effective counseling remains
limited, particularly for substance abuse, and virtual agents offer a promising
solution by leveraging LLM capabilities to simulate nuanced communication
techniques inherent in MI. Our approach combines prompt engineering and
integration into a user-friendly virtual platform to facilitate realistic,
empathetic interactions. We evaluate the effectiveness of our virtual agent
through a series of studies focusing on replicating MI techniques and human
counselor dialog. Initial findings suggest that our LLM-powered virtual agent
matches human counselors' empathetic and adaptive conversational skills,
presenting a significant step forward in virtual health counseling and
providing insights into the design and implementation of LLM-based therapeutic
interactions.

摘要：我們提出了一個大型語言模型 (LLM) 的新應用，用於開發一個虛擬諮詢師，能夠進行動機性訪談 (MI) 以進行酒精使用諮詢。獲得有效的諮詢仍然有限，特別是對於物質濫用，而虛擬代理則提供了一個有前途的解決方案，利用 LLM 能力來模擬 MI 中固有的細微溝通技巧。我們的做法結合了提示工程並整合到一個使用者友善的虛擬平台中，以促進真實、同理的互動。我們透過一系列專注於複製 MI 技術和人類諮詢師對話的研究來評估我們虛擬代理的有效性。初步發現表明，我們由 LLM 驅動的虛擬代理與人類諮詢師的同理心和適應性對話技能相匹配，這代表了虛擬健康諮詢向前邁進一大步，並提供了對基於 LLM 的治療性互動的設計和實施的見解。

##### **MemWarp: Discontinuity-Preserving Cardiac Registration with Memorized Anatomical Filters**
2407.08093v1 by Hang Zhang, Xiang Chen, Renjiu Hu, Dongdong Liu, Gaolei Li, Rongguang Wang

Many existing learning-based deformable image registration methods impose
constraints on deformation fields to ensure they are globally smooth and
continuous. However, this assumption does not hold in cardiac image
registration, where different anatomical regions exhibit asymmetric motions
during respiration and movements due to sliding organs within the chest.
Consequently, such global constraints fail to accommodate local discontinuities
across organ boundaries, potentially resulting in erroneous and unrealistic
displacement fields. In this paper, we address this issue with MemWarp, a
learning framework that leverages a memory network to store prototypical
information tailored to different anatomical regions. MemWarp is different from
earlier approaches in two main aspects: firstly, by decoupling feature
extraction from similarity matching in moving and fixed images, it facilitates
more effective utilization of feature maps; secondly, despite its capability to
preserve discontinuities, it eliminates the need for segmentation masks during
model inference. In experiments on a publicly available cardiac dataset, our
method achieves considerable improvements in registration accuracy and
producing realistic deformations, outperforming state-of-the-art methods with a
remarkable 7.1\% Dice score improvement over the runner-up semi-supervised
method. Source code will be available at https://github.com/tinymilky/Mem-Warp.

摘要：許多現有的基於學習的形變影像配準方法對形變場施加約束，以確保它們在整體上是平滑且連續的。然而，此假設不適用於心臟影像配準，其中不同的解剖區域在呼吸和胸部器官滑動所造成的運動中表現出不對稱的運動。因此，此類全局約束無法適應器官邊界上的局部不連續性，可能會導致錯誤且不切實際的位移場。在本文中，我們使用 MemWarp 來解決此問題，MemWarp 是一種學習架構，它利用記憶網路來儲存針對不同解剖區域量身打造的原型資訊。MemWarp 在兩個主要方面不同於早期的做法：首先，透過將特徵萃取與移動和固定影像中的相似性比對分開，它促進了特徵圖的更有效利用；其次，儘管它有能力保留不連續性，但在模型推論期間卻消除了對分割遮罩的需求。在公開的心臟資料集上進行的實驗中，我們的模型在配準準確度和產生逼真的形變方面取得了顯著的進步，優於最先進的方法，與亞軍半監督方法相比，Dice 分數提高了 7.1%。原始碼將在 https://github.com/tinymilky/Mem-Warp 中提供。

##### **NDST: Neural Driving Style Transfer for Human-Like Vision-Based Autonomous Driving**
2407.08073v1 by Donghyun Kim, Aws Khalil, Haewoon Nam, Jaerock Kwon

Autonomous Vehicles (AV) and Advanced Driver Assistant Systems (ADAS)
prioritize safety over comfort. The intertwining factors of safety and comfort
emerge as pivotal elements in ensuring the effectiveness of Autonomous Driving
(AD). Users often experience discomfort when AV or ADAS drive the vehicle on
their behalf. Providing a personalized human-like AD experience, tailored to
match users' unique driving styles while adhering to safety prerequisites,
presents a significant opportunity to boost the acceptance of AVs. This paper
proposes a novel approach, Neural Driving Style Transfer (NDST), inspired by
Neural Style Transfer (NST), to address this issue. NDST integrates a
Personalized Block (PB) into the conventional Baseline Driving Model (BDM),
allowing for the transfer of a user's unique driving style while adhering to
safety parameters. The PB serves as a self-configuring system, learning and
adapting to an individual's driving behavior without requiring modifications to
the BDM. This approach enables the personalization of AV models, aligning the
driving style more closely with user preferences while ensuring baseline safety
critical actuation. Two contrasting driving styles (Style A and Style B) were
used to validate the proposed NDST methodology, demonstrating its efficacy in
transferring personal driving styles to the AV system. Our work highlights the
potential of NDST to enhance user comfort in AVs by providing a personalized
and familiar driving experience. The findings affirm the feasibility of
integrating NDST into existing AV frameworks to bridge the gap between safety
and individualized driving styles, promoting wider acceptance and improved user
experiences.

摘要：<paragraph>自動駕駛車輛 (AV) 和先進駕駛輔助系統 (ADAS)
優先考慮安全性而非舒適性。安全性和舒適性的交織因素
成為確保自動駕駛 (AD) 有效性的關鍵要素。當 AV 或 ADAS 代表
使用者駕駛車輛時，使用者經常會感到不適。提供個人化的類人 AD 體驗，
量身打造以符合使用者的獨特駕駛風格，同時遵守安全前提，
這是一個提升 AV 接受度的重大契機。本文
提出一個新穎的方法，神經駕駛風格轉移 (NDST)，靈感來自
神經風格轉移 (NST)，以解決此問題。NDST 將
個人化區塊 (PB) 整合到傳統的基準駕駛模型 (BDM) 中，
允許在遵守安全參數的同時轉移使用者的獨特駕駛風格。PB 作為一個自組態系統，
學習和適應個人的駕駛行為，而不需要修改 BDM。這種方法使 AV 模型個人化，
讓駕駛風格更符合使用者偏好，同時確保基準安全
關鍵動作。兩種對比的駕駛風格（風格 A 和風格 B）被
用於驗證所提出的 NDST 方法，證明其在將個人駕駛風格轉移到 AV 系統中的有效性。我們的研究重點介紹了 NDST 在 AV 中增強使用者舒適度的潛力，方法是提供個人化
且熟悉的駕駛體驗。研究結果肯定了將 NDST 整合到現有 AV 框架中的可行性，以彌合安全
和個性化駕駛風格之間的差距，促進更廣泛的接受度和改善使用者
體驗。</paragraph>

##### **On LLM Wizards: Identifying Large Language Models' Behaviors for Wizard of Oz Experiments**
2407.08067v1 by Jingchao Fang, Nikos Arechiga, Keiichi Namaoshi, Nayeli Bravo, Candice Hogan, David A. Shamma

The Wizard of Oz (WoZ) method is a widely adopted research approach where a
human Wizard ``role-plays'' a not readily available technology and interacts
with participants to elicit user behaviors and probe the design space. With the
growing ability for modern large language models (LLMs) to role-play, one can
apply LLMs as Wizards in WoZ experiments with better scalability and lower cost
than the traditional approach. However, methodological guidance on responsibly
applying LLMs in WoZ experiments and a systematic evaluation of LLMs'
role-playing ability are lacking. Through two LLM-powered WoZ studies, we take
the first step towards identifying an experiment lifecycle for researchers to
safely integrate LLMs into WoZ experiments and interpret data generated from
settings that involve Wizards role-played by LLMs. We also contribute a
heuristic-based evaluation framework that allows the estimation of LLMs'
role-playing ability in WoZ experiments and reveals LLMs' behavior patterns at
scale.

摘要：綠野仙蹤 (WoZ) 方法是一種廣泛採用的研究方法，其中人類「扮演」一種尚未問世的技術，並與參與者互動以引發使用者行為並探討設計空間。隨著現代大型語言模型 (LLM) 扮演角色的能力日益增強，人們可以將 LLM 應用於 WoZ 實驗中的精靈，其可擴充性和成本低於傳統方法。然而，目前缺乏關於在 WoZ 實驗中負責任地應用 LLM 的方法指導，以及對 LLM 角色扮演能力的系統性評估。透過兩項 LLM 驅動的 WoZ 研究，我們邁出了第一步，以識別實驗生命週期，讓研究人員可以安全地將 LLM 整合到 WoZ 實驗中，並解釋從精靈扮演 LLM 的設定中產生的資料。我們還提供了一個基於啟發法的評估架構，可以估計 LLM 在 WoZ 實驗中的角色扮演能力，並揭示 LLM 的行為模式。

##### **Towards Interpretable Foundation Models of Robot Behavior: A Task Specific Policy Generation Approach**
2407.08065v1 by Isaac Sheidlower, Reuben Aronson, Elaine Schaertl Short

Foundation models are a promising path toward general-purpose and
user-friendly robots. The prevalent approach involves training a generalist
policy that, like a reinforcement learning policy, uses observations to output
actions. Although this approach has seen much success, several concerns arise
when considering deployment and end-user interaction with these systems. In
particular, the lack of modularity between tasks means that when model weights
are updated (e.g., when a user provides feedback), the behavior in other,
unrelated tasks may be affected. This can negatively impact the system's
interpretability and usability. We present an alternative approach to the
design of robot foundation models, Diffusion for Policy Parameters (DPP), which
generates stand-alone, task-specific policies. Since these policies are
detached from the foundation model, they are updated only when a user wants,
either through feedback or personalization, allowing them to gain a high degree
of familiarity with that policy. We demonstrate a proof-of-concept of DPP in
simulation then discuss its limitations and the future of interpretable
foundation models.

摘要：基礎模型是朝向通用且使用者友善機器人的一條有前途的道路。普遍的方法涉及訓練一個通才政策，它像一個強化學習政策，使用觀察來輸出動作。儘管這種方法已經看到許多成功，但在考慮這些系統的部署和最終使用者互動時，會出現一些問題。特別是，任務之間缺乏模組化意味著當模型權重更新時（例如，當使用者提供回饋時），其他不相關任務中的行為可能會受到影響。這可能會對系統的可解釋性和可用性產生負面影響。我們提出了一種機器人基礎模型設計的替代方法，即政策參數擴散 (DPP)，它會產生獨立的、特定於任務的政策。由於這些政策與基礎模型分離，因此只有在使用者需要時才會更新，無論是透過回饋或個人化，讓他們能夠高度熟悉該政策。我們在模擬中展示了 DPP 的概念驗證，然後討論了它的限制和可解釋基礎模型的未來。

##### **Spatial-Temporal Attention Model for Traffic State Estimation with Sparse Internet of Vehicles**
2407.08047v1 by Jianzhe Xue, Dongcheng Yuan, Yu Sun, Tianqi Zhang, Wenchao Xu, Haibo Zhou, Xuemin, Shen

The growing number of connected vehicles offers an opportunity to leverage
internet of vehicles (IoV) data for traffic state estimation (TSE) which plays
a crucial role in intelligent transportation systems (ITS). By utilizing only a
portion of IoV data instead of the entire dataset, the significant overheads
associated with collecting and processing large amounts of data can be avoided.
In this paper, we introduce a novel framework that utilizes sparse IoV data to
achieve cost-effective TSE. Particularly, we propose a novel spatial-temporal
attention model called the convolutional retentive network (CRNet) to improve
the TSE accuracy by mining spatial-temporal traffic state correlations. The
model employs the convolutional neural network (CNN) for spatial correlation
aggregation and the retentive network (RetNet) based on the attention mechanism
to extract temporal correlations. Extensive simulations on a real-world IoV
dataset validate the advantage of the proposed TSE approach in achieving
accurate TSE using sparse IoV data, demonstrating its cost effectiveness and
practicality for real-world applications.

摘要：隨著連網車輛數量增加，提供了利用車聯網 (IoV) 資料進行交通狀態估計 (TSE) 的機會，這在智慧運輸系統 (ITS) 中扮演著關鍵的角色。透過僅利用 IoV 資料的一部分，而非整個資料集，可以避免與收集和處理大量資料相關的顯著負擔。在本文中，我們介紹一個利用稀疏 IoV 資料來達成具成本效益的 TSE 的新架構。特別是，我們提出一個稱為卷積保留網路 (CRNet) 的新時空注意力模型，以透過探勘時空交通狀態關聯性來提升 TSE 精確度。該模型採用卷積神經網路 (CNN) 進行時空關聯性聚合，以及基於注意力機制的保留網路 (RetNet) 來萃取時序關聯性。在真實世界 IoV 資料集上進行的廣泛模擬驗證了所提出的 TSE 方法在使用稀疏 IoV 資料達成精確 TSE 的優勢，展現其對於真實世界應用而言的成本效益和實用性。

##### **RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization**
2407.08044v1 by Xijie Huang, Zechun Liu, Shih-Yang Liu, Kwang-Ting Cheng

Low-Rank Adaptation (LoRA), as a representative Parameter-Efficient
Fine-Tuning (PEFT)method, significantly enhances the training efficiency by
updating only a small portion of the weights in Large Language Models (LLMs).
Recently, weight-only quantization techniques have also been applied to LoRA
methods to reduce the memory footprint of fine-tuning. However, applying
weight-activation quantization to the LoRA pipeline is under-explored, and we
observe substantial performance degradation primarily due to the presence of
activation outliers. In this work, we propose RoLoRA, the first LoRA-based
scheme for effective weight-activation quantization. RoLoRA utilizes rotation
for outlier elimination and proposes rotation-aware fine-tuning to preserve the
outlier-free characteristics in rotated LLMs. Experimental results show RoLoRA
consistently improves low-bit LoRA convergence and post-training quantization
robustness in weight-activation settings. We evaluate RoLoRA across
LLaMA2-7B/13B, LLaMA3-8B models, achieving up to 29.5% absolute accuracy gain
of 4-bit weight-activation quantized LLaMA2- 13B on commonsense reasoning tasks
compared to LoRA baseline. We further demonstrate its effectiveness on Large
Multimodal Models (LLaVA-1.5-7B). Codes are available at
https://github.com/HuangOwen/RoLoRA

摘要：低秩適應 (LoRA) 作為代表性的參數有效微調 (PEFT) 方法，透過僅更新大型語言模型 (LLM) 中的一小部分權重，大幅提升訓練效率。最近，權重僅量化技術也已應用於 LoRA 方法，以減少微調的記憶體使用量。然而，將權重啟用量化應用於 LoRA 管線尚未充分探討，而我們觀察到大幅效能降低，主要是由於存在啟用值異常值。在這項工作中，我們提出 RoLoRA，這是第一個基於 LoRA 的有效權重啟用值量化方案。RoLoRA 利用旋轉進行異常值消除，並提出旋轉感知微調，以保留旋轉 LLM 中無異常值的特性。實驗結果顯示，RoLoRA 持續改善低位元 LoRA 收斂性，以及權重啟用值設定中的訓練後量化穩健性。我們在 LLaMA2-7B/13B、LLaMA3-8B 模型中評估 RoLoRA，與 LoRA 基準相比，在常識推理任務上，達到 4 位元權重啟用值量化 LLaMA2-13B 高達 29.5% 的絕對準確度提升。我們進一步展示其在大型多模態模型 (LLaVA-1.5-7B) 上的有效性。程式碼可在 https://github.com/HuangOwen/RoLoRA 取得

##### **Knowledge Overshadowing Causes Amalgamated Hallucination in Large Language Models**
2407.08039v1 by Yuji Zhang, Sha Li, Jiateng Liu, Pengfei Yu, Yi R. Fung, Jing Li, Manling Li, Heng Ji

Hallucination is often regarded as a major impediment for using large
language models (LLMs), especially for knowledge-intensive tasks. Even when the
training corpus consists solely of true statements, language models still
generate hallucinations in the form of amalgamations of multiple facts. We coin
this phenomenon as ``knowledge overshadowing'': when we query knowledge from a
language model with multiple conditions, some conditions overshadow others,
leading to hallucinated outputs. This phenomenon partially stems from training
data imbalance, which we verify on both pretrained models and fine-tuned
models, over a wide range of LM model families and sizes.From a theoretical
point of view, knowledge overshadowing can be interpreted as
over-generalization of the dominant conditions (patterns). We show that the
hallucination rate grows with both the imbalance ratio (between the popular and
unpopular condition) and the length of dominant condition description,
consistent with our derived generalization bound. Finally, we propose to
utilize overshadowing conditions as a signal to catch hallucination before it
is produced, along with a training-free self-contrastive decoding method to
alleviate hallucination during inference. Our proposed approach showcases up to
82% F1 for hallucination anticipation and 11.2% to 39.4% hallucination control,
with different models and datasets.

摘要：幻觉通常被视为使用大型语言模型 (LLM) 的主要障碍，尤其是对于知识密集型任务。即使训练语料库仅包含真实陈述，语言模型仍会以多种事实的混合形式产生幻觉。我们把这种现象称为“知识掩盖”：当我们用多个条件从语言模型中查询知识时，一些条件会掩盖其他条件，从而导致产生幻觉的输出。这种现象部分源于训练数据不平衡，我们在预训练模型和微调模型上以及在广泛的 LM 模型系列和规模上对此进行了验证。从理论角度来看，知识掩盖可以解释为对主要条件（模式）的过度概括。我们表明，幻觉率随着不平衡率（流行条件和不受欢迎条件之间）和主要条件描述的长度而增加，这与我们得出的概括界限一致。最后，我们建议利用掩盖条件作为一种信号，在产生幻觉之前捕获幻觉，并使用无训练的自对比解码方法来减轻推理过程中的幻觉。我们提出的方法展示了高达 82% 的 F1 幻觉预测和 11.2% 到 39.4% 的幻觉控制，具有不同的模型和数据集。

##### **FsPONER: Few-shot Prompt Optimization for Named Entity Recognition in Domain-specific Scenarios**
2407.08035v1 by Yongjian Tang, Rakebul Hasan, Thomas Runkler

Large Language Models (LLMs) have provided a new pathway for Named Entity
Recognition (NER) tasks. Compared with fine-tuning, LLM-powered prompting
methods avoid the need for training, conserve substantial computational
resources, and rely on minimal annotated data. Previous studies have achieved
comparable performance to fully supervised BERT-based fine-tuning approaches on
general NER benchmarks. However, none of the previous approaches has
investigated the efficiency of LLM-based few-shot learning in domain-specific
scenarios. To address this gap, we introduce FsPONER, a novel approach for
optimizing few-shot prompts, and evaluate its performance on domain-specific
NER datasets, with a focus on industrial manufacturing and maintenance, while
using multiple LLMs -- GPT-4-32K, GPT-3.5-Turbo, LLaMA 2-chat, and Vicuna.
FsPONER consists of three few-shot selection methods based on random sampling,
TF-IDF vectors, and a combination of both. We compare these methods with a
general-purpose GPT-NER method as the number of few-shot examples increases and
evaluate their optimal NER performance against fine-tuned BERT and LLaMA
2-chat. In the considered real-world scenarios with data scarcity, FsPONER with
TF-IDF surpasses fine-tuned models by approximately 10% in F1 score.

摘要：大型語言模型 (LLM) 為命名實體識別 (NER) 任務提供了新的途徑。與微調相比，LLM 驅動提示方法避免了訓練的需要，節省了大量的計算資源，並依賴於最少的註解數據。先前的研究已在一般 NER 基準上實現了與完全監督的 BERT 微調方法相當的性能。然而，先前的研究方法都沒有探討 LLM 基於少量學習在特定領域場景中的效率。為了解決這個差距，我們引入了 FsPONER，這是一種優化少量提示的新方法，並評估了它在特定領域 NER 資料集上的性能，重點放在工業製造和維護上，同時使用多個 LLM -- GPT-4-32K、GPT-3.5-Turbo、LLaMA 2-chat 和 Vicuna。FsPONER 包含三種基於隨機抽樣、TF-IDF 向量和兩者的組合的少量選擇方法。我們將這些方法與通用 GPT-NER 方法進行比較，因為少量範例的數量增加，並評估它們相對於微調 BERT 和 LLaMA 2-chat 的最佳 NER 性能。在考慮的數據稀缺的真實世界場景中，帶有 TF-IDF 的 FsPONER 在 F1 分數上比微調模型高出約 10%。

##### **A Critical Review of Causal Reasoning Benchmarks for Large Language Models**
2407.08029v1 by Linying Yang, Vik Shirvaikar, Oscar Clivio, Fabian Falck

Numerous benchmarks aim to evaluate the capabilities of Large Language Models
(LLMs) for causal inference and reasoning. However, many of them can likely be
solved through the retrieval of domain knowledge, questioning whether they
achieve their purpose. In this review, we present a comprehensive overview of
LLM benchmarks for causality. We highlight how recent benchmarks move towards a
more thorough definition of causal reasoning by incorporating interventional or
counterfactual reasoning. We derive a set of criteria that a useful benchmark
or set of benchmarks should aim to satisfy. We hope this work will pave the way
towards a general framework for the assessment of causal understanding in LLMs
and the design of novel benchmarks.

摘要：許多基準旨在評估大型語言模型 (LLM) 在因果推論和推理方面的能力。然而，其中許多問題可能可以透過檢索領域知識來解決，這讓人質疑它們是否達到了目的。在這篇評論中，我們提出了 LLM 因果關係基準的全面概述。我們強調了最近的基準如何透過納入介入式或反事實推理，朝向因果推理的更徹底定義邁進。我們衍生出一組有用的基準或基準組應力求滿足的標準。我們希望這項工作將為評估 LLM 中的因果理解和設計新的基準奠定一個通用的架構。

