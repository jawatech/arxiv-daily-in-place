{"2405.18358": {"publish_time": "2024-05-28", "title": "MMCTAgent: Multi-modal Critical Thinking Agent Framework for Complex Visual Reasoning", "paper_summary": "Recent advancements in Multi-modal Large Language Models (MLLMs) have\nsignificantly improved their performance in tasks combining vision and\nlanguage. However, challenges persist in detailed multi-modal understanding,\ncomprehension of complex tasks, and reasoning over multi-modal information.\nThis paper introduces MMCTAgent, a novel multi-modal critical thinking agent\nframework designed to address the inherent limitations of current MLLMs in\ncomplex visual reasoning tasks. Inspired by human cognitive processes and\ncritical thinking, MMCTAgent iteratively analyzes multi-modal information,\ndecomposes queries, plans strategies, and dynamically evolves its reasoning.\nAdditionally, MMCTAgent incorporates critical thinking elements such as\nverification of final answers and self-reflection through a novel approach that\ndefines a vision-based critic and identifies task-specific evaluation criteria,\nthereby enhancing its decision-making abilities. Through rigorous evaluations\nacross various image and video understanding benchmarks, we demonstrate that\nMMCTAgent (with and without the critic) outperforms both foundational MLLMs and\nother tool-augmented pipelines.", "paper_summary_zh": "\u6700\u8fd1\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b (MLLM) \u7684\u8fdb\u6b65\u663e\u8457\u6539\u5584\u4e86\u5b83\u4eec\u5728\u7ed3\u5408\u89c6\u89c9\u548c\u8bed\u8a00\u7684\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002\u7136\u800c\uff0c\u5728\u8be6\u7ec6\u7684\u591a\u6a21\u6001\u7406\u89e3\u3001\u590d\u6742\u4efb\u52a1\u7684\u7406\u89e3\u4ee5\u53ca\u5bf9\u591a\u6a21\u6001\u4fe1\u606f\u8fdb\u884c\u63a8\u7406\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u6311\u6218\u3002\u672c\u6587\u4ecb\u7ecd\u4e86 MMCTAgent\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u6a21\u6001\u6279\u5224\u6027\u601d\u7ef4\u4ee3\u7406\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524d MLLM \u5728\u590d\u6742\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u56fa\u6709\u5c40\u9650\u6027\u3002\u53d7\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u548c\u6279\u5224\u6027\u601d\u7ef4\u7684\u542f\u53d1\uff0cMMCTAgent \u8fed\u4ee3\u5206\u6790\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u5206\u89e3\u67e5\u8be2\uff0c\u89c4\u5212\u7b56\u7565\uff0c\u5e76\u52a8\u6001\u5730\u53d1\u5c55\u5176\u63a8\u7406\u3002\u6b64\u5916\uff0cMMCTAgent \u7ed3\u5408\u4e86\u6279\u5224\u6027\u601d\u7ef4\u5143\u7d20\uff0c\u4f8b\u5982\u901a\u8fc7\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u9a8c\u8bc1\u6700\u7ec8\u7b54\u6848\u548c\u81ea\u6211\u53cd\u7701\uff0c\u8be5\u65b9\u6cd5\u5b9a\u4e49\u4e86\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u7684\u6279\u8bc4\u8005\u5e76\u8bc6\u522b\u4e86\u7279\u5b9a\u4efb\u52a1\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u5176\u51b3\u7b56\u80fd\u529b\u3002\u901a\u8fc7\u5bf9\u5404\u79cd\u56fe\u50cf\u548c\u89c6\u9891\u7406\u89e3\u57fa\u51c6\u8fdb\u884c\u4e25\u683c\u7684\u8bc4\u4f30\uff0c\u6211\u4eec\u8bc1\u660e\u4e86 MMCTAgent\uff08\u6709\u548c\u6ca1\u6709\u6279\u8bc4\u8005\uff09\u90fd\u4f18\u4e8e\u57fa\u7840 MLLM \u548c\u5176\u4ed6\u5de5\u5177\u589e\u5f3a\u7ba1\u9053\u3002", "author": "Somnath Kumar et.al.", "authors": "Somnath Kumar, Yash Gadhia, Tanuja Ganu, Akshay Nambi", "id": "2405.18358v1", "paper_url": "http://arxiv.org/abs/2405.18358v1", "repo": "null"}}