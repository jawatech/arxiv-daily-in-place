
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-21**|**Learning segmentation from point trajectories**|Laurynas Karazija et.al.|[2501.12392v1](http://arxiv.org/abs/2501.12392v1)|null|
|**2025-01-21**|**Physics of Skill Learning**|Ziming Liu et.al.|[2501.12391v1](http://arxiv.org/abs/2501.12391v1)|[link](https://github.com/kindxiaoming/physics_of_skill_learning)|
|**2025-01-21**|**MMVU: Measuring Expert-Level Multi-Discipline Video Understanding**|Yilun Zhao et.al.|[2501.12380v1](http://arxiv.org/abs/2501.12380v1)|[link](https://github.com/yale-nlp/mmvu)|
|**2025-01-21**|**Video Depth Anything: Consistent Depth Estimation for Super-Long Videos**|Sili Chen et.al.|[2501.12375v1](http://arxiv.org/abs/2501.12375v1)|null|
|**2025-01-21**|**Expertise elevates AI usage: experimental evidence comparing laypeople and professional artists**|Thomas F. Eisenmann et.al.|[2501.12374v1](http://arxiv.org/abs/2501.12374v1)|[link](https://github.com/andreskarjus/genaiexperiment)|
|**2025-01-21**|**Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL**|Yeounoh Chung et.al.|[2501.12372v1](http://arxiv.org/abs/2501.12372v1)|null|
|**2025-01-21**|**Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models**|Samira Abnar et.al.|[2501.12370v1](http://arxiv.org/abs/2501.12370v1)|null|
|**2025-01-21**|**InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model**|Yuhang Zang et.al.|[2501.12368v1](http://arxiv.org/abs/2501.12368v1)|[link](https://github.com/internlm/internlm-xcomposer)|
|**2025-01-21**|**Test-time regression: a unifying framework for designing sequence models with associative memory**|Ke Alexander Wang et.al.|[2501.12352v1](http://arxiv.org/abs/2501.12352v1)|null|
|**2025-01-21**|**Treefix: Enabling Execution with a Tree of Prefixes**|Beatriz Souza et.al.|[2501.12339v1](http://arxiv.org/abs/2501.12339v1)|null|
|**2025-01-21**|**FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**|Phuoc Duong Huy Chu et.al.|[2501.12336v1](http://arxiv.org/abs/2501.12336v1)|null|
|**2025-01-21**|**Automatic Labelling with Open-source LLMs using Dynamic Label Schema Integration**|Thomas Walshe et.al.|[2501.12332v1](http://arxiv.org/abs/2501.12332v1)|null|
|**2025-01-21**|**UI-TARS: Pioneering Automated GUI Interaction with Native Agents**|Yujia Qin et.al.|[2501.12326v1](http://arxiv.org/abs/2501.12326v1)|[link](https://github.com/bytedance/ui-tars)|
|**2025-01-21**|**LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**|Hasan Abu-Rasheed et.al.|[2501.12300v1](http://arxiv.org/abs/2501.12300v1)|null|
|**2025-01-21**|**RALAD: Bridging the Real-to-Sim Domain Gap in Autonomous Driving with Retrieval-Augmented Learning**|Jiacheng Zuo et.al.|[2501.12296v1](http://arxiv.org/abs/2501.12296v1)|[link](https://github.com/jiachengzuo/ralad)|
|**2025-01-21**|**With Great Backbones Comes Great Adversarial Transferability**|Erik Arakelyan et.al.|[2501.12275v1](http://arxiv.org/abs/2501.12275v1)|null|
|**2025-01-21**|**Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement**|Maosong Cao et.al.|[2501.12273v1](http://arxiv.org/abs/2501.12273v1)|null|
|**2025-01-21**|**CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**|Cristiano Patrício et.al.|[2501.12266v1](http://arxiv.org/abs/2501.12266v1)|null|
|**2025-01-21**|**FOCUS: First Order Concentrated Updating Scheme**|Yizhou Liu et.al.|[2501.12243v1](http://arxiv.org/abs/2501.12243v1)|null|
|**2025-01-21**|**InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**|Pha Nguyen et.al.|[2501.12231v1](http://arxiv.org/abs/2501.12231v1)|null|
|**2025-01-21**|**Fixing Imbalanced Attention to Mitigate In-Context Hallucination of Large Vision-Language Model**|Kazi Hasan Ibn Arif et.al.|[2501.12206v1](http://arxiv.org/abs/2501.12206v1)|null|
|**2025-01-21**|**An End-to-End Approach for Korean Wakeword Systems with Speaker Authentication**|Geonwoo Seo et.al.|[2501.12194v1](http://arxiv.org/abs/2501.12194v1)|[link](https://github.com/gws8820/securewakeword-model)|
|**2025-01-21**|**AdaServe: SLO-Customized LLM Serving with Fine-Grained Speculative Decoding**|Zikun Li et.al.|[2501.12162v1](http://arxiv.org/abs/2501.12162v1)|null|
|**2025-01-21**|**On the practical applicability of modern DFT functionals for chemical computations. Case study of DM21 applicability for geometry optimization**|Kirill Kulaev et.al.|[2501.12149v1](http://arxiv.org/abs/2501.12149v1)|null|
|**2025-01-21**|**Improving Influence-based Instruction Tuning Data Selection for Balanced Learning of Diverse Capabilities**|Qirun Dai et.al.|[2501.12147v1](http://arxiv.org/abs/2501.12147v1)|null|
|**2025-01-21**|**FedCLEAN: byzantine defense by CLustering Errors of Activation maps in Non-IID federated learning environments**|Mehdi Ben Ghali et.al.|[2501.12123v1](http://arxiv.org/abs/2501.12123v1)|null|
|**2025-01-21**|**Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes**|Stefan Lenz et.al.|[2501.12106v1](http://arxiv.org/abs/2501.12106v1)|[link](https://github.com/stefan-m-lenz/urollmeval)|
|**2025-01-21**|**Teacher Encoder-Student Decoder Denoising Guided Segmentation Network for Anomaly Detection**|ShiXuan Song et.al.|[2501.12104v1](http://arxiv.org/abs/2501.12104v1)|null|
|**2025-01-21**|**Proxies for Distortion and Consistency with Applications for Real-World Image Restoration**|Sean Man et.al.|[2501.12102v1](http://arxiv.org/abs/2501.12102v1)|null|
|**2025-01-21**|**Scalable Whole Slide Image Representation Using K-Mean Clustering and Fisher Vector Aggregation**|Ravi Kant Gupta et.al.|[2501.12085v1](http://arxiv.org/abs/2501.12085v1)|null|
|**2025-01-21**|**EDoRA: Efficient Weight-Decomposed Low-Rank Adaptation via Singular Value Decomposition**|Hamid Nasiri et.al.|[2501.12067v1](http://arxiv.org/abs/2501.12067v1)|[link](https://github.com/hamid-nasiri/edora)|
|**2025-01-21**|**MedS$^3$: Towards Medical Small Language Models with Self-Evolved Slow Thinking**|Shuyang Jiang et.al.|[2501.12051v1](http://arxiv.org/abs/2501.12051v1)|[link](https://github.com/pixas/medsss)|
|**2025-01-21**|**Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye**|Shramana Dey et.al.|[2501.12048v1](http://arxiv.org/abs/2501.12048v1)|null|
|**2025-01-21**|**Harnessing Generative Pre-Trained Transformer for Datacenter Packet Trace Generation**|Chen Griner et.al.|[2501.12033v1](http://arxiv.org/abs/2501.12033v1)|null|
|**2025-01-21**|**Reference-free Evaluation Metrics for Text Generation: A Survey**|Takumi Ito et.al.|[2501.12011v1](http://arxiv.org/abs/2501.12011v1)|null|
|**2025-01-21**|**Survey on Hand Gesture Recognition from Visual Input**|Manousos Linardakis et.al.|[2501.11992v1](http://arxiv.org/abs/2501.11992v1)|null|
|**2025-01-21**|**Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**|Maya Medjad et.al.|[2501.11977v1](http://arxiv.org/abs/2501.11977v1)|null|
|**2025-01-21**|**Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**|Jie Zhao et.al.|[2501.11968v1](http://arxiv.org/abs/2501.11968v1)|null|
|**2025-01-21**|**A Hybrid Attention Framework for Fake News Detection with Large Language Models**|Xiaochuan Xu et.al.|[2501.11967v1](http://arxiv.org/abs/2501.11967v1)|null|
|**2025-01-21**|**TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection**|Yang Cao et.al.|[2501.11960v1](http://arxiv.org/abs/2501.11960v1)|null|
|**2025-01-21**|**Proverbs Run in Pairs: Evaluating Proverb Translation Capability of Large Language Model**|Minghan Wang et.al.|[2501.11953v1](http://arxiv.org/abs/2501.11953v1)|null|
|**2025-01-21**|**HERITAGE: An End-to-End Web Platform for Processing Korean Historical Documents in Hanja**|Seyoung Song et.al.|[2501.11951v1](http://arxiv.org/abs/2501.11951v1)|[link](https://github.com/seyoungsong/hanja-platform)|
|**2025-01-21**|**Webvs. LLMs: An Empirical Study of Learning Behaviors of CS2 Students**|Aayush Kumar et.al.|[2501.11935v1](http://arxiv.org/abs/2501.11935v1)|null|
|**2025-01-21**|**A Lightweight and Interpretable Deepfakes Detection Framework**|Muhammad Umar Farooq et.al.|[2501.11927v1](http://arxiv.org/abs/2501.11927v1)|null|
|**2025-01-21**|**LuxVeri at GenAI Detection Task 3: Cross-Domain Detection of AI-Generated Text Using Inverse Perplexity-Weighted Ensemble of Fine-Tuned Transformer Models**|Md Kamrujjaman Mobin et.al.|[2501.11918v1](http://arxiv.org/abs/2501.11918v1)|null|
|**2025-01-21**|**LuxVeri at GenAI Detection Task 1: Inverse Perplexity Weighted Ensemble for Robust Detection of AI-Generated Text across English and Multilingual Contexts**|Md Kamrujjaman Mobin et.al.|[2501.11914v1](http://arxiv.org/abs/2501.11914v1)|null|
|**2025-01-21**|**Bridging the Communication Gap: Evaluating AI Labeling Practices for Trustworthy AI Development**|Raphael Fischer et.al.|[2501.11909v1](http://arxiv.org/abs/2501.11909v1)|[link](https://github.com/raphischer/labeling-evaluation)|
|**2025-01-21**|**Panoramic Interests: Stylistic-Content Aware Personalized Headline Generation**|Junhong Lian et.al.|[2501.11900v1](http://arxiv.org/abs/2501.11900v1)|[link](https://github.com/ictmldm/SCAPE)|
|**2025-01-21**|**Systematic Abductive Reasoning via Diverse Relation Representations in Vector-symbolic Architecture**|Zhong-Hua Sun et.al.|[2501.11896v1](http://arxiv.org/abs/2501.11896v1)|null|
|**2025-01-21**|**Med-R$^2$: Crafting Trustworthy LLM Physicians through Retrieval and Reasoning of Evidence-Based Medicine**|Keer Lu et.al.|[2501.11885v1](http://arxiv.org/abs/2501.11885v1)|null|
|**2025-01-21**|**Community-Aware Temporal Walks: Parameter-Free Representation Learning on Continuous-Time Dynamic Graphs**|He Yu et.al.|[2501.11880v1](http://arxiv.org/abs/2501.11880v1)|[link](https://github.com/leonyuhe/ctwalks)|
|**2025-01-21**|**From Drafts to Answers: Unlocking LLM Potential via Aggregation Fine-Tuning**|Yafu Li et.al.|[2501.11877v1](http://arxiv.org/abs/2501.11877v1)|[link](https://github.com/linzwcs/aft)|
|**2025-01-21**|**Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models**|Zihan Qiu et.al.|[2501.11873v1](http://arxiv.org/abs/2501.11873v1)|null|
|**2025-01-21**|**EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents**|Zhili Cheng et.al.|[2501.11858v1](http://arxiv.org/abs/2501.11858v1)|[link](https://github.com/thunlp/embodiedeval)|
|**2025-01-21**|**Cross-Entropy Attacks to Language Models via Rare Event Simulation**|Mingze Ni et.al.|[2501.11852v1](http://arxiv.org/abs/2501.11852v1)|null|
|**2025-01-21**|**Challenges in Expanding Portuguese Resources: A View from Open Information Extraction**|Marlo Souza et.al.|[2501.11851v1](http://arxiv.org/abs/2501.11851v1)|null|
|**2025-01-21**|**Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**|Nikos Kanakaris et.al.|[2501.11849v1](http://arxiv.org/abs/2501.11849v1)|[link](https://github.com/nkanak/brag-fake-news-campaigns)|
|**2025-01-21**|**A Survey on Memory-Efficient Large-Scale Model Training in AI for Science**|Kaiyuan Tian et.al.|[2501.11847v1](http://arxiv.org/abs/2501.11847v1)|null|
|**2025-01-21**|**Supervised Learning for Analog and RF Circuit Design: Benchmarks and Comparative Insights**|Asal Mehradfar et.al.|[2501.11839v1](http://arxiv.org/abs/2501.11839v1)|null|
|**2025-01-21**|**Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision**|Saeid Ataei et.al.|[2501.11836v1](http://arxiv.org/abs/2501.11836v1)|null|
|**2025-01-21**|**Is your LLM trapped in a Mental Set? Investigative study on how mental sets affect the reasoning capabilities of LLMs**|Saiful Haq et.al.|[2501.11833v1](http://arxiv.org/abs/2501.11833v1)|null|
|**2025-01-21**|**PXGen: A Post-hoc Explainable Method for Generative Models**|Yen-Lung Huang et.al.|[2501.11827v1](http://arxiv.org/abs/2501.11827v1)|null|
|**2025-01-21**|**Toward Scalable Graph Unlearning: A Node Influence Maximization based Approach**|Xunkai Li et.al.|[2501.11823v1](http://arxiv.org/abs/2501.11823v1)|null|
|**2025-01-21**|**Toward Effective Digraph Representation Learning: A Magnetic Adaptive Propagation based Approach**|Xunkai Li et.al.|[2501.11817v1](http://arxiv.org/abs/2501.11817v1)|null|
|**2025-01-21**|**Policy-Adaptable Methods For Resolving Normative Conflicts Through Argumentation and Graph Colouring**|Johnny Joyce et.al.|[2501.11799v1](http://arxiv.org/abs/2501.11799v1)|null|
|**2025-01-20**|**Benchmarking Large Language Models via Random Variables**|Zijin Hong et.al.|[2501.11790v1](http://arxiv.org/abs/2501.11790v1)|null|
|**2025-01-20**|**Synthetic Data Can Mislead Evaluations: Membership Inference as Machine Text Detection**|Ali Naseh et.al.|[2501.11786v1](http://arxiv.org/abs/2501.11786v1)|null|
|**2025-01-20**|**Human-AI Collaborative Game Testing with Vision Language Models**|Boran Zhang et.al.|[2501.11782v1](http://arxiv.org/abs/2501.11782v1)|null|
|**2025-01-20**|**The Value of Nothing: Multimodal Extraction of Human Values Expressed by TikTok Influencers**|Alina Starovolsky-Shitrit et.al.|[2501.11770v1](http://arxiv.org/abs/2501.11770v1)|null|
|**2025-01-20**|**Is logical analysis performed by transformers taking place in self-attention or in the fully connected part?**|Evgeniy Shin et.al.|[2501.11765v1](http://arxiv.org/abs/2501.11765v1)|null|
|**2025-01-20**|**Optimizing Pretraining Data Mixtures with LLM-Estimated Utility**|William Held et.al.|[2501.11747v1](http://arxiv.org/abs/2501.11747v1)|null|
|**2025-01-20**|**SILO: Solving Inverse Problems with Latent Operators**|Ron Raphaeli et.al.|[2501.11746v1](http://arxiv.org/abs/2501.11746v1)|null|
|**2025-01-20**|**Episodic memory in AI agents poses risks that should be studied and mitigated**|Chad DeChant et.al.|[2501.11739v1](http://arxiv.org/abs/2501.11739v1)|null|
|**2025-01-20**|**Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks**|Zhenhailong Wang et.al.|[2501.11733v1](http://arxiv.org/abs/2501.11733v1)|null|
|**2025-01-20**|**Transformer Vibration Forecasting for Advancing Rail Safety and Maintenance 4.0**|Darío C. Larese et.al.|[2501.11730v1](http://arxiv.org/abs/2501.11730v1)|null|
|**2025-01-20**|**Explain-Query-Test: Self-Evaluating LLMs Via Explanation and Comprehension Discrepancy**|Saeid Asgari Taghanaki et.al.|[2501.11721v1](http://arxiv.org/abs/2501.11721v1)|[link](https://github.com/asgsaeid/eqt)|
|**2025-01-20**|**GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease**|Wenjie Kang et.al.|[2501.11715v1](http://arxiv.org/abs/2501.11715v1)|null|
|**2025-01-20**|**YouLeQD: Decoding the Cognitive Complexity of Questions and Engagement in Online Educational Videos from Learners' Perspectives**|Nong Ming et.al.|[2501.11712v1](http://arxiv.org/abs/2501.11712v1)|[link](https://github.com/jiho-yesnlp/qytl)|
|**2025-01-20**|**Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)**|Brian E. Perron et.al.|[2501.11705v1](http://arxiv.org/abs/2501.11705v1)|null|
|**2025-01-20**|**Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling**|Zhenyu Hou et.al.|[2501.11651v1](http://arxiv.org/abs/2501.11651v1)|[link](https://github.com/thudm/t1)|
|**2025-01-20**|**StAyaL | Multilingual Style Transfer**|Karishma Thakrar et.al.|[2501.11639v1](http://arxiv.org/abs/2501.11639v1)|null|
|**2025-01-20**|**Noise-Agnostic Multitask Whisper Training for Reducing False Alarm Errors in Call-for-Help Detection**|Myeonghoon Ryu et.al.|[2501.11631v1](http://arxiv.org/abs/2501.11631v1)|null|
|**2025-01-20**|**Early evidence of how LLMs outperform traditional systems on OCR/HTR tasks for historical records**|Seorin Kim et.al.|[2501.11623v1](http://arxiv.org/abs/2501.11623v1)|null|
|**2025-01-20**|**Trojan Detection Through Pattern Recognition for Large Language Models**|Vedant Bhasin et.al.|[2501.11621v1](http://arxiv.org/abs/2501.11621v1)|null|
|**2025-01-20**|**Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems**|Giorgio Robino et.al.|[2501.11613v1](http://arxiv.org/abs/2501.11613v1)|null|
|**2025-01-20**|**SR-FoT: A Syllogistic-Reasoning Framework of Thought for Large Language Models Tackling Knowledge-based Reasoning Tasks**|Wentao Wan et.al.|[2501.11599v1](http://arxiv.org/abs/2501.11599v1)|null|
|**2025-01-20**|**Fairness Testing through Extreme Value Theory**|Verya Monjezi et.al.|[2501.11597v1](http://arxiv.org/abs/2501.11597v1)|null|
|**2025-01-20**|**Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing**|Chaoqing Tang et.al.|[2501.11592v1](http://arxiv.org/abs/2501.11592v1)|null|
|**2025-01-20**|**Recurrent Diffusion for Large-Scale Parameter Generation**|Kai Wang et.al.|[2501.11587v1](http://arxiv.org/abs/2501.11587v1)|[link](https://github.com/nus-hpc-ai-lab/recurrent-parameter-generation)|
|**2025-01-20**|**Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**|M. Manzour et.al.|[2501.11560v1](http://arxiv.org/abs/2501.11560v1)|null|
|**2025-01-20**|**PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation**|Jinyu Wang et.al.|[2501.11551v1](http://arxiv.org/abs/2501.11551v1)|null|
|**2025-01-20**|**Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas**|Nishant Balepur et.al.|[2501.11549v1](http://arxiv.org/abs/2501.11549v1)|[link](https://github.com/pinafore/alignment-personalization)|
|**2025-01-20**|**Technical Report for the Forgotten-by-Design Project: Targeted Obfuscation for Machine Learning**|Rickard Brännvall et.al.|[2501.11525v1](http://arxiv.org/abs/2501.11525v1)|null|
|**2025-01-20**|**Dialect2SQL: A Novel Text-to-SQL Dataset for Arabic Dialects with a Focus on Moroccan Darija**|Salmane Chafik et.al.|[2501.11498v1](http://arxiv.org/abs/2501.11498v1)|null|
|**2025-01-20**|**Generative AI and Large Language Models in Language Preservation: Opportunities and Challenges**|Vincent Koc et.al.|[2501.11496v1](http://arxiv.org/abs/2501.11496v1)|null|
|**2025-01-20**|**Communication-Efficient Federated Learning Based on Explanation-Guided Pruning for Remote Sensing Image Classification**|Jonas Klotz et.al.|[2501.11493v1](http://arxiv.org/abs/2501.11493v1)|null|
|**2025-01-20**|**Graph-defined Language Learning with LLMs**|Huachi Zhou et.al.|[2501.11478v1](http://arxiv.org/abs/2501.11478v1)|null|
|**2025-01-20**|**Curiosity-Driven Reinforcement Learning from Human Feedback**|Haoran Sun et.al.|[2501.11463v1](http://arxiv.org/abs/2501.11463v1)|null|
|**2025-01-20**|**Improving thermal state preparation of Sachdev-Ye-Kitaev model with reinforcement learning on quantum hardware**|Akash Kundu et.al.|[2501.11454v1](http://arxiv.org/abs/2501.11454v1)|null|
|**2025-01-20**|**Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components**|Abel Jansma et.al.|[2501.11447v1](http://arxiv.org/abs/2501.11447v1)|null|

#### Abstracts
##### **Learning segmentation from point trajectories**
2501.12392v1 by Laurynas Karazija, Iro Laina, Christian Rupprecht, Andrea Vedaldi

We consider the problem of segmenting objects in videos based on their motion
and no other forms of supervision. Prior work has often approached this problem
by using the principle of common fate, namely the fact that the motion of
points that belong to the same object is strongly correlated. However, most
authors have only considered instantaneous motion from optical flow. In this
work, we present a way to train a segmentation network using long-term point
trajectories as a supervisory signal to complement optical flow. The key
difficulty is that long-term motion, unlike instantaneous motion, is difficult
to model -- any parametric approximation is unlikely to capture complex motion
patterns over long periods of time. We instead draw inspiration from subspace
clustering approaches, proposing a loss function that seeks to group the
trajectories into low-rank matrices where the motion of object points can be
approximately explained as a linear combination of other point tracks. Our
method outperforms the prior art on motion-based segmentation, which shows the
utility of long-term motion and the effectiveness of our formulation.

摘要：我們考慮基於運動和沒有其他形式的監督來分割影片中的物體的問題。先前的研究通常透過使用共同命運的原理來探討這個問題，也就是屬於同一個物體的點的運動具有強關聯性。然而，大多數作者只考慮了光流的瞬時運動。在這項工作中，我們提出一個使用長期點軌跡作為監督訊號來訓練分割網路的方法，以補充光流。關鍵的難處在於，長期運動不像瞬時運動，難以建模——任何參數近似都不太可能捕捉到長時期的複雜運動模式。我們改為從子空間聚類方法中汲取靈感，提出一個損失函數，用於將軌跡分組成低秩矩陣，其中物體點的運動可以近似解釋為其他點軌跡的線性組合。我們的模型在基於運動的分割方面優於先前的技術，這顯示了長期運動的效用和我們公式的有效性。

##### **Physics of Skill Learning**
2501.12391v1 by Ziming Liu, Yizhou Liu, Eric J. Michaud, Jeff Gore, Max Tegmark

We aim to understand physics of skill learning, i.e., how skills are learned
in neural networks during training. We start by observing the Domino effect,
i.e., skills are learned sequentially, and notably, some skills kick off
learning right after others complete learning, similar to the sequential fall
of domino cards. To understand the Domino effect and relevant behaviors of
skill learning, we take physicists' approach of abstraction and simplification.
We propose three models with varying complexities -- the Geometry model, the
Resource model, and the Domino model, trading between reality and simplicity.
The Domino effect can be reproduced in the Geometry model, whose resource
interpretation inspires the Resource model, which can be further simplified to
the Domino model. These models present different levels of abstraction and
simplification; each is useful to study some aspects of skill learning. The
Geometry model provides interesting insights into neural scaling laws and
optimizers; the Resource model sheds light on the learning dynamics of
compositional tasks; the Domino model reveals the benefits of modularity. These
models are not only conceptually interesting -- e.g., we show how Chinchilla
scaling laws can emerge from the Geometry model, but also are useful in
practice by inspiring algorithmic development -- e.g., we show how simple
algorithmic changes, motivated by these toy models, can speed up the training
of deep learning models.

摘要：我們旨在了解技能學習的物理學，即在訓練過程中如何學習神經網路中的技能。我們從觀察多米諾骨牌效應開始，即技能是按順序學習的，值得注意的是，某些技能會在其他技能完成學習後立即開始學習，類似於多米諾骨牌按順序倒下的情況。為了了解多米諾骨牌效應和技能學習相關行為，我們採用物理學家的抽象化和簡化方法。我們提出了三種具有不同複雜性的模型——幾何模型、資源模型和多米諾模型，在現實和簡潔性之間進行權衡。多米諾骨牌效應可以在幾何模型中重現，其資源解釋激發了資源模型，而資源模型可以進一步簡化為多米諾模型。這些模型呈現出不同的抽象化和簡化層級；每一個都可用於研究技能學習的某些方面。幾何模型提供了對神經網路擴充法則和最佳化器的有趣見解；資源模型闡明了組合任務的學習動態；多米諾模型揭示了模組化的優點。這些模型不僅在概念上很有趣——例如，我們展示了欽奇拉擴充法則如何從幾何模型中出現，而且在實務上也很有用，因為它激發了演算法的開發——例如，我們展示了受這些玩具模型啟發的簡單演算法變更如何能加速深度學習模型的訓練。

##### **MMVU: Measuring Expert-Level Multi-Discipline Video Understanding**
2501.12380v1 by Yilun Zhao, Lujing Xie, Haowei Zhang, Guo Gan, Yitao Long, Zhiyuan Hu, Tongyan Hu, Weiyuan Chen, Chuhan Li, Junyang Song, Zhijian Xu, Chengye Wang, Weifeng Pan, Ziyao Shangguan, Xiangru Tang, Zhenwen Liang, Yixin Liu, Chen Zhao, Arman Cohan

We introduce MMVU, a comprehensive expert-level, multi-discipline benchmark
for evaluating foundation models in video understanding. MMVU includes 3,000
expert-annotated questions spanning 27 subjects across four core disciplines:
Science, Healthcare, Humanities & Social Sciences, and Engineering. Compared to
prior benchmarks, MMVU features three key advancements. First, it challenges
models to apply domain-specific knowledge and perform expert-level reasoning to
analyze specialized-domain videos, moving beyond the basic visual perception
typically assessed in current video benchmarks. Second, each example is
annotated by human experts from scratch. We implement strict data quality
controls to ensure the high quality of the dataset. Finally, each example is
enriched with expert-annotated reasoning rationals and relevant domain
knowledge, facilitating in-depth analysis. We conduct an extensive evaluation
of 32 frontier multimodal foundation models on MMVU. The latest
System-2-capable models, o1 and Gemini 2.0 Flash Thinking, achieve the highest
performance among the tested models. However, they still fall short of matching
human expertise. Through in-depth error analyses and case studies, we offer
actionable insights for future advancements in expert-level,
knowledge-intensive video understanding for specialized domains.

摘要：我們介紹 MMVU，一個全面的專家級、多領域基準，用於評估影片理解中的基礎模型。MMVU 包含 3,000 個專家註解問題，涵蓋四個核心領域的 27 個科目：科學、醫療保健、人文與社會科學以及工程。與先前的基準相比，MMVU 具備三大進展。首先，它挑戰模型應用特定領域的知識，並執行專家級推理，以分析特定領域的影片，超越當前影片基準中通常評估的基本視覺感知。其次，每個範例都是由人類專家從頭開始註解。我們實施嚴格的資料品質控管，以確保資料集的高品質。最後，每個範例都豐富了專家註解的推理原理和相關領域知識，促進深入分析。我們對 32 個前沿多模態基礎模型進行了廣泛的 MMVU 評估。最新的 System-2 能力模型 o1 和 Gemini 2.0 Flash Thinking 在測試模型中獲得最高效能。然而，它們仍然無法與人類專業知識相匹配。透過深入的錯誤分析和案例研究，我們為特定領域的專家級、知識密集型影片理解的未來進展提供了可行的見解。

##### **Video Depth Anything: Consistent Depth Estimation for Super-Long Videos**
2501.12375v1 by Sili Chen, Hengkai Guo, Shengnan Zhu, Feihu Zhang, Zilong Huang, Jiashi Feng, Bingyi Kang

Depth Anything has achieved remarkable success in monocular depth estimation
with strong generalization ability. However, it suffers from temporal
inconsistency in videos, hindering its practical applications. Various methods
have been proposed to alleviate this issue by leveraging video generation
models or introducing priors from optical flow and camera poses. Nonetheless,
these methods are only applicable to short videos (< 10 seconds) and require a
trade-off between quality and computational efficiency. We propose Video Depth
Anything for high-quality, consistent depth estimation in super-long videos
(over several minutes) without sacrificing efficiency. We base our model on
Depth Anything V2 and replace its head with an efficient spatial-temporal head.
We design a straightforward yet effective temporal consistency loss by
constraining the temporal depth gradient, eliminating the need for additional
geometric priors. The model is trained on a joint dataset of video depth and
unlabeled images, similar to Depth Anything V2. Moreover, a novel
key-frame-based strategy is developed for long video inference. Experiments
show that our model can be applied to arbitrarily long videos without
compromising quality, consistency, or generalization ability. Comprehensive
evaluations on multiple video benchmarks demonstrate that our approach sets a
new state-of-the-art in zero-shot video depth estimation. We offer models of
different scales to support a range of scenarios, with our smallest model
capable of real-time performance at 30 FPS.

摘要：Depth Anything 在單眼深度估計方面取得了顯著的成功，並具有強大的泛化能力。然而，它在影片中存在時間不一致性的問題，阻礙了其實際應用。已經提出了各種方法來利用影片生成模型或引入光流和相機姿勢的先驗來緩解這個問題。儘管如此，這些方法僅適用於短影片（< 10 秒），並且需要在品質和運算效率之間進行權衡。我們提出影片深度 Anything，用於在超長影片（數分鐘以上）中進行高品質、一致的深度估計，而不會犧牲效率。我們將模型建立在 Depth Anything V2 上，並用一個高效的時空頭替換其頭部。我們通過約束時間深度梯度設計了一個簡單但有效的時間一致性損失，消除了對額外幾何先驗的需求。該模型在影片深度和未標記影像的聯合資料集上進行訓練，類似於 Depth Anything V2。此外，還開發了一種新穎的基於關鍵影格的策略，用於長影片推論。實驗表明，我們的模型可以應用於任意長的影片，而不會損害品質、一致性或泛化能力。對多個影片基準的綜合評估表明，我們的做法在零次學習影片深度估計中樹立了新的技術水準。我們提供不同規模的模型來支援各種場景，我們最小的模型能夠以 30 FPS 的速度執行即時效能。

##### **Expertise elevates AI usage: experimental evidence comparing laypeople and professional artists**
2501.12374v1 by Thomas F. Eisenmann, Andres Karjus, Mar Canet Sola, Levin Brinkmann, Bramantyo Ibrahim Supriyatno, Iyad Rahwan

Novel capacities of generative AI to analyze and generate cultural artifacts
raise inevitable questions about the nature and value of artistic education and
human expertise. Has AI already leveled the playing field between professional
artists and laypeople, or do trained artistic expressive capacity, curation
skills and experience instead enhance the ability to use these new tools? In
this pre-registered study, we conduct experimental comparisons between 50
active artists and a demographically matched sample of laypeople. We designed
two tasks to approximate artistic practice for testing their capabilities in
both faithful and creative image creation: replicating a reference image, and
moving as far away as possible from it. We developed a bespoke platform where
participants used a modern text-to-image model to complete both tasks. We also
collected and compared participants' sentiments towards AI. On average, artists
produced more faithful and creative outputs than their lay counterparts,
although only by a small margin. While AI may ease content creation,
professional expertise is still valuable - even within the confined space of
generative AI itself. Finally, we also explored how well an exemplary
vision-capable large language model (GPT-4o) would complete the same tasks, if
given the role of an image generation agent, and found it performed on par in
copying but outperformed even artists in the creative task. The very best
results were still produced by humans in both tasks. These outcomes highlight
the importance of integrating artistic skills with AI training to prepare
artists and other visual professionals for a technologically evolving
landscape. We see a potential in collaborative synergy with generative AI,
which could reshape creative industries and education in the arts.

摘要：生成式 AI 分析和生成文化製品的新穎能力
引發了關於藝術教育的性質和價值以及
人類專家知識的不可避免問題。AI 是否已經拉平了專業
藝術家和外行之間的競爭環境，或者訓練有素的藝術表現能力、策展
技巧和經驗反而增強了使用這些新工具的能力？在
這項預先註冊的研究中，我們對 50
位活躍藝術家和人口統計匹配的外行樣本進行了實驗比較。我們設計
了兩個任務來近似藝術實踐，以測試它們在
忠實和創造性圖像創作中的能力：複製參考圖像，並
盡可能遠離它。我們開發了一個訂製平台，讓
參與者使用現代文字轉圖像模型來完成這兩個任務。我們還
收集並比較了參與者對 AI 的情緒。平均而言，藝術家
產生的忠實且有創意的產出多於他們的非專業對手，
儘管只是一個很小的差距。雖然 AI 可能簡化了內容創作，
專業知識仍然有價值 - 即使在生成式 AI 本身的受限空間內也是如此。最後，我們還探討了一個範例
具有視覺能力的大語言模型 (GPT-4o) 在
充當圖像生成代理的情況下完成相同任務的效果如何，並發現它在
複製中表現得相當出色，但在創造性任務中甚至優於藝術家。最棒的
結果仍然是由人類在兩個任務中產生的。這些結果強調了將藝術技能與 AI 訓練相結合以準備
藝術家和其他視覺專業人士應對技術發展
情勢的重要性。我們看到與生成式 AI 合作協同的潛力，
這可能會重塑創意產業和藝術教育。

##### **Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL**
2501.12372v1 by Yeounoh Chung, Gaurav T. Kakkar, Yu Gan, Brenton Milne, Fatma Ozcan

Large Language Models (LLMs) have demonstrated impressive capabilities across
a range of natural language processing tasks. In particular, improvements in
reasoning abilities and the expansion of context windows have opened new
avenues for leveraging these powerful models. NL2SQL is challenging in that the
natural language question is inherently ambiguous, while the SQL generation
requires a precise understanding of complex data schema and semantics. One
approach to this semantic ambiguous problem is to provide more and sufficient
contextual information.
  In this work, we explore the performance and the latency trade-offs of the
extended context window (a.k.a., long context) offered by Google's
state-of-the-art LLM (\textit{gemini-1.5-pro}). We study the impact of various
contextual information, including column example values, question and SQL query
pairs, user-provided hints, SQL documentation, and schema. To the best of our
knowledge, this is the first work to study how the extended context window and
extra contextual information can help NL2SQL generation with respect to both
accuracy and latency cost. We show that long context LLMs are robust and do not
get lost in the extended contextual information. Additionally, our long-context
NL2SQL pipeline based on Google's \textit{gemini-pro-1.5} achieve a strong
performance with 67.41\% on BIRD benchmark (dev) without finetuning and
expensive self-consistency based techniques.

摘要：大型語言模型 (LLM) 已在各種自然語言處理任務中展示出令人印象深刻的能力。特別是，推理能力的提升和上下文視窗的擴展為利用這些強大的模型開闢了新途徑。NL2SQL 具有挑戰性，因為自然語言問題本質上是模稜兩可的，而 SQL 生成需要精確理解複雜的數據模式和語義。解決這個語義模糊問題的一種方法是提供更多且充分的上下文資訊。
在這項工作中，我們探討了 Google 最先進的 LLM (\textit{gemini-1.5-pro}) 提供的擴展上下文視窗（又稱長上下文）的效能和延遲權衡。我們研究了各種上下文資訊的影響，包括欄位範例值、問題和 SQL 查詢配對、使用者提供的提示、SQL 文件和模式。據我們所知，這是第一個研究擴展上下文視窗和額外上下文資訊如何能在準確性和延遲成本方面協助 NL2SQL 生成的研究。我們展示了長上下文 LLM 是強健的，不會迷失在擴展的上下文資訊中。此外，我們基於 Google 的 \textit{gemini-pro-1.5} 的長上下文 NL2SQL 管線在 BIRD 基準測試 (dev) 上達到了 67.41% 的強勁效能，而無需微調和昂貴的基於自我一致性的技術。

##### **Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models**
2501.12370v1 by Samira Abnar, Harshay Shah, Dan Busbridge, Alaaeldin Mohamed Elnouby Ali, Josh Susskind, Vimal Thilak

Scaling the capacity of language models has consistently proven to be a
reliable approach for improving performance and unlocking new capabilities.
Capacity can be primarily defined by two dimensions: the number of model
parameters and the compute per example. While scaling typically involves
increasing both, the precise interplay between these factors and their combined
contribution to overall capacity remains not fully understood. We explore this
relationship in the context of sparse Mixture-of-Expert models (MoEs), which
allow scaling the number of parameters without proportionally increasing the
FLOPs per example. We investigate how varying the sparsity level, i.e., the
ratio of non-active to total parameters, affects model performance in terms of
both pretraining and downstream performance. We find that under different
constraints (e.g. parameter size and total training compute), there is an
optimal level of sparsity that improves both training efficiency and model
performance. These results provide a better understanding of the impact of
sparsity in scaling laws for MoEs and complement existing works in this area,
offering insights for designing more efficient architectures.

摘要：擴展語言模型的容量一直被證明是改善效能並解鎖新功能的可靠方法。容量主要可以由兩個面向定義：模型參數數量和每個範例的運算。雖然擴展通常包含增加兩者，但這些因素之間的精確交互作用及其對整體容量的共同貢獻仍未完全了解。我們在稀疏混合專家模型 (MoE) 的背景下探討這種關係，它允許擴展參數數量，而不會成比例地增加每個範例的 FLOP。我們研究改變稀疏程度（即非活動參數與總參數的比率）如何影響模型在預訓練和下游效能方面的效能。我們發現，在不同的限制條件（例如參數大小和總訓練運算）下，存在最佳稀疏程度，可同時改善訓練效率和模型效能。這些結果讓我們對稀疏性在 MoE 的擴展定律中的影響有更好的了解，並補充了這方面的現有工作，提供了設計更有效率的架構的見解。

##### **InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model**
2501.12368v1 by Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Ziyu Liu, Shengyuan Ding, Shenxi Wu, Yubo Ma, Haodong Duan, Wenwei Zhang, Kai Chen, Dahua Lin, Jiaqi Wang

Despite the promising performance of Large Vision Language Models (LVLMs) in
visual understanding, they occasionally generate incorrect outputs. While
reward models (RMs) with reinforcement learning or test-time scaling offer the
potential for improving generation quality, a critical gap remains: publicly
available multi-modal RMs for LVLMs are scarce, and the implementation details
of proprietary models are often unclear. We bridge this gap with
InternLM-XComposer2.5-Reward (IXC-2.5-Reward), a simple yet effective
multi-modal reward model that aligns LVLMs with human preferences. To ensure
the robustness and versatility of IXC-2.5-Reward, we set up a high-quality
multi-modal preference corpus spanning text, image, and video inputs across
diverse domains, such as instruction following, general understanding,
text-rich documents, mathematical reasoning, and video understanding.
IXC-2.5-Reward achieves excellent results on the latest multi-modal reward
model benchmark and shows competitive performance on text-only reward model
benchmarks. We further demonstrate three key applications of IXC-2.5-Reward:
(1) Providing a supervisory signal for RL training. We integrate IXC-2.5-Reward
with Proximal Policy Optimization (PPO) yields IXC-2.5-Chat, which shows
consistent improvements in instruction following and multi-modal open-ended
dialogue; (2) Selecting the best response from candidate responses for
test-time scaling; and (3) Filtering outlier or noisy samples from existing
image and video instruction tuning training data. To ensure reproducibility and
facilitate further research, we have open-sourced all model weights and
training recipes at https://github.com/InternLM/InternLM-XComposer

摘要：儘管大型視覺語言模型 (LVLMs) 在視覺理解方面表現出色，但它們偶爾會產生不正確的輸出。雖然具有強化學習或測試時縮放的回饋模型 (RMs) 提供了提高生成品質的可能性，但仍存在一個關鍵差距：公開的多模態 LVLMs RMs 很少，而且專有模型的實作細節往往不清楚。我們以 InternLM-XComposer2.5-Reward (IXC-2.5-Reward) 來彌補這個差距，這是一個簡單但有效的多模態回饋模型，它將 LVLMs 與人類偏好保持一致。為了確保 IXC-2.5-Reward 的穩健性和多功能性，我們建立了一個跨越不同領域（例如指令遵循、一般理解、文字豐富的文件、數學推理和影片理解）的高品質多模態偏好語料庫，其中包含文字、影像和影片輸入。IXC-2.5-Reward 在最新的多模態回饋模型基準測試中取得了優異的成果，並在純文字回饋模型基準測試中展現了競爭力。我們進一步展示了 IXC-2.5-Reward 的三個關鍵應用：(1) 提供 RL 訓練的監督訊號。我們將 IXC-2.5-Reward 與近端策略最佳化 (PPO) 整合，產生 IXC-2.5-Chat，在指令遵循和多模態開放式對話方面持續改善；(2) 從候選回應中選出最佳回應，以進行測試時縮放；(3) 從現有的影像和影片教學調整訓練資料中過濾異常值或雜訊樣本。為了確保可複製性並促進進一步研究，我們已在 https://github.com/InternLM/InternLM-XComposer 開放原始碼的所有模型權重和訓練配方

##### **Test-time regression: a unifying framework for designing sequence models with associative memory**
2501.12352v1 by Ke Alexander Wang, Jiaxin Shi, Emily B. Fox

Sequences provide a remarkably general way to represent and process
information. This powerful abstraction has placed sequence modeling at the
center of modern deep learning applications, inspiring numerous architectures
from transformers to recurrent networks. While this fragmented development has
yielded powerful models, it has left us without a unified framework to
understand their fundamental similarities and explain their effectiveness. We
present a unifying framework motivated by an empirical observation: effective
sequence models must be able to perform associative recall. Our key insight is
that memorizing input tokens through an associative memory is equivalent to
performing regression at test-time. This regression-memory correspondence
provides a framework for deriving sequence models that can perform associative
recall, offering a systematic lens to understand seemingly ad-hoc architectural
choices. We show numerous recent architectures -- including linear attention
models, their gated variants, state-space models, online learners, and softmax
attention -- emerge naturally as specific approaches to test-time regression.
Each architecture corresponds to three design choices: the relative importance
of each association, the regressor function class, and the optimization
algorithm. This connection leads to new understanding: we provide theoretical
justification for QKNorm in softmax attention, and we motivate higher-order
generalizations of softmax attention. Beyond unification, our work unlocks
decades of rich statistical tools that can guide future development of more
powerful yet principled sequence models.

摘要：序列提供了一個非常通用的方式來表示和處理資訊。這種強大的抽象化已將序列模型置於現代深度學習應用程式的核心，從Transformer到遞迴網路激發了許多架構。雖然這種分散的發展產生了強大的模型，但它讓我們沒有統一的架構來理解它們的基本相似性並解釋它們的有效性。我們提出了一個由經驗觀察激勵的統一架構：有效的序列模型必須能夠執行關聯式回憶。我們的關鍵見解是，透過聯想記憶體記憶輸入代幣等同於在測試時執行迴歸。這種迴歸記憶對應提供了一個框架，用於推導可以執行關聯式回憶的序列模型，提供了一個系統的透鏡來理解看似臨時的架構選擇。我們展示了許多最近的架構——包括線性注意力模型、它們的門控變體、狀態空間模型、線上學習器和 softmax 注意力——自然而然地出現作為測試時間迴歸的具體方法。每個架構都對應於三個設計選擇：每個關聯的相對重要性、回歸函數類和最佳化演算法。這種聯繫導致了新的理解：我們為 softmax 注意力中的 QKNorm 提供了理論依據，並且我們激勵了 softmax 注意力的高階概括。除了統一之外，我們的研究還解鎖了數十年的豐富統計工具，這些工具可以指導更強大但有原則的序列模型的未來發展。

##### **Treefix: Enabling Execution with a Tree of Prefixes**
2501.12339v1 by Beatriz Souza, Michael Pradel

The ability to execute code is a prerequisite for various dynamic program
analyses. Learning-guided execution has been proposed as an approach to enable
the execution of arbitrary code snippets by letting a neural model predict
likely values for any missing variables. Although state-of-the-art
learning-guided execution approaches, such as LExecutor, can enable the
execution of a relative high amount of code, they are limited to predicting a
restricted set of possible values and do not use any feedback from previous
executions to execute even more code. This paper presents Treefix, a novel
learning-guided execution approach that leverages LLMs to iteratively create
code prefixes that enable the execution of a given code snippet. The approach
addresses the problem in a multi-step fashion, where each step uses feedback
about the code snippet and its execution to instruct an LLM to improve a
previously generated prefix. This process iteratively creates a tree of
prefixes, a subset of which is returned to the user as prefixes that maximize
the number of executed lines in the code snippet. In our experiments with two
datasets of Python code snippets, Treefix achieves 25% and 7% more coverage
relative to the current state of the art in learning-guided execution, covering
a total of 84% and 82% of all lines in the code snippets.

摘要：執行程式碼的能力是各種動態程式分析的前提。學習導向執行已被提議為一種方法，讓神經模型預測任何遺失變數的可能值，從而能夠執行任意程式碼片段。儘管最先進的學習導向執行方法（例如 LExecutor）可以執行相對大量的程式碼，但它們僅限於預測一組可能的受限值，並且不使用先前執行的任何回饋來執行更多程式碼。本文提出 Treefix，這是一種新穎的學習導向執行方法，它利用 LLM 迭代建立程式碼前綴，以執行給定的程式碼片段。該方法以多步驟方式解決問題，其中每一步都使用關於程式碼片段及其執行的回饋，來指導 LLM 改進先前生成的字首。此過程反覆建立一個前綴樹，其中的一部分作為前綴回傳給使用者，以最大化程式碼片段中執行行的數量。在我們使用兩個 Python 程式碼片段資料集進行的實驗中，Treefix 在學習導向執行中取得了比目前最先進的技術高出 25% 和 7% 的覆蓋率，總共涵蓋了程式碼片段中所有行的 84% 和 82%。

##### **FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**
2501.12336v1 by Phuoc Duong Huy Chu

This paper presents results of our system for CoMeDi Shared Task, focusing on
Subtask 2: Disagreement Ranking. Our system leverages sentence embeddings
generated by the paraphrase-xlm-r-multilingual-v1 model, combined with a deep
neural regression model incorporating batch normalization and dropout for
improved generalization. By predicting the mean of pairwise judgment
differences between annotators, our method explicitly targets disagreement
ranking, diverging from traditional "gold label" aggregation approaches. We
optimized our system with a customized architecture and training procedure,
achieving competitive performance in Spearman correlation against mean
disagreement labels. Our results highlight the importance of robust embeddings,
effective model architecture, and careful handling of judgment differences for
ranking disagreement in multilingual contexts. These findings provide insights
into the use of contextualized representations for ordinal judgment tasks and
open avenues for further refinement of disagreement prediction models.

摘要：本文展示了我們在 CoMeDi 共享任務系統中的結果，重點在
子任務 2：分歧排名。我們的系統利用 paraphrase-xlm-r-multilingual-v1 模型產生的句子嵌入，結合深度
神經迴歸模型，並加入批次正規化和中斷以改善概化。透過預測註解者之間成對判斷差異的平均值，我們的
方法明確針對分歧排名，偏離傳統的「黃金標籤」聚合方法。我們使用自訂架構和訓練程序優化系統，
在與平均分歧標籤的 Spearman 相關性中獲得競爭力表現。我們的結果強調了穩健嵌入、有效模型架構和
謹慎處理判斷差異對於在多語言環境中對分歧進行排名的重要性。這些發現提供了使用情境化表徵進行序數判斷任務的見解，並為進一步優化分歧預測模型開闢了道路。

##### **Automatic Labelling with Open-source LLMs using Dynamic Label Schema Integration**
2501.12332v1 by Thomas Walshe, Sae Young Moon, Chunyang Xiao, Yawwani Gunawardana, Fran Silavong

Acquiring labelled training data remains a costly task in real world machine
learning projects to meet quantity and quality requirements. Recently Large
Language Models (LLMs), notably GPT-4, have shown great promises in labelling
data with high accuracy. However, privacy and cost concerns prevent the
ubiquitous use of GPT-4. In this work, we explore effectively leveraging
open-source models for automatic labelling. We identify integrating label
schema as a promising technology but found that naively using the label
description for classification leads to poor performance on high cardinality
tasks. To address this, we propose Retrieval Augmented Classification (RAC) for
which LLM performs inferences for one label at a time using corresponding label
schema; we start with the most related label and iterates until a label is
chosen by the LLM. We show that our method, which dynamically integrates label
description, leads to performance improvements in labelling tasks. We further
show that by focusing only on the most promising labels, RAC can trade off
between label quality and coverage - a property we leverage to automatically
label our internal datasets.

摘要：在實際機器學習專案中，取得標籤訓練資料仍然是一項成本高昂的任務，以滿足數量和品質需求。最近，大型語言模型 (LLM)，尤其是 GPT-4，在標籤資料上展現出高精準度的優異表現。然而，隱私和成本考量阻礙了 GPT-4 的廣泛使用。在這項工作中，我們探討如何有效利用開源模型進行自動標籤。我們發現整合標籤架構是一項有前途的技術，但發現天真地使用標籤說明進行分類會導致高基數任務的效能不佳。為了解決這個問題，我們提出了檢索增強分類 (RAC)，其中 LLM 使用對應的標籤架構一次對一個標籤執行推論；我們從最相關的標籤開始，並反覆運算，直到 LLM 選擇一個標籤。我們展示了我們的方法（動態整合標籤說明）會提升標籤任務的效能。我們進一步展示，透過僅專注於最有希望的標籤，RAC 可以權衡標籤品質和涵蓋範圍，我們利用這項特性自動標籤我們的內部資料集。

##### **UI-TARS: Pioneering Automated GUI Interaction with Native Agents**
2501.12326v1 by Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin Li, Shijue Huang, Wanjun Zhong, Kuanye Li, Jiale Yang, Yu Miao, Woyu Lin, Longxiang Liu, Xu Jiang, Qianli Ma, Jingyu Li, Xiaojun Xiao, Kai Cai, Chuang Li, Yaowei Zheng, Chaolin Jin, Chen Li, Xiao Zhou, Minchao Wang, Haoli Chen, Zhaojian Li, Haihua Yang, Haifeng Liu, Feng Lin, Tao Peng, Xin Liu, Guang Shi

This paper introduces UI-TARS, a native GUI agent model that solely perceives
the screenshots as input and performs human-like interactions (e.g., keyboard
and mouse operations). Unlike prevailing agent frameworks that depend on
heavily wrapped commercial models (e.g., GPT-4o) with expert-crafted prompts
and workflows, UI-TARS is an end-to-end model that outperforms these
sophisticated frameworks. Experiments demonstrate its superior performance:
UI-TARS achieves SOTA performance in 10+ GUI agent benchmarks evaluating
perception, grounding, and GUI task execution. Notably, in the OSWorld
benchmark, UI-TARS achieves scores of 24.6 with 50 steps and 22.7 with 15
steps, outperforming Claude (22.0 and 14.9 respectively). In AndroidWorld,
UI-TARS achieves 46.6, surpassing GPT-4o (34.5). UI-TARS incorporates several
key innovations: (1) Enhanced Perception: leveraging a large-scale dataset of
GUI screenshots for context-aware understanding of UI elements and precise
captioning; (2) Unified Action Modeling, which standardizes actions into a
unified space across platforms and achieves precise grounding and interaction
through large-scale action traces; (3) System-2 Reasoning, which incorporates
deliberate reasoning into multi-step decision making, involving multiple
reasoning patterns such as task decomposition, reflection thinking, milestone
recognition, etc. (4) Iterative Training with Reflective Online Traces, which
addresses the data bottleneck by automatically collecting, filtering, and
reflectively refining new interaction traces on hundreds of virtual machines.
Through iterative training and reflection tuning, UI-TARS continuously learns
from its mistakes and adapts to unforeseen situations with minimal human
intervention. We also analyze the evolution path of GUI agents to guide the
further development of this domain.

摘要：本文介紹了 UI-TARS，一種原生 GUI 代理模型，它僅將螢幕截圖視為輸入，並執行類似人類的互動（例如，鍵盤和滑鼠操作）。與依賴於專家精心製作的提示和工作流程的盛行代理架構不同，UI-TARS 是一個端到端模型，其效能優於這些複雜的架構。實驗證明了其卓越的效能：UI-TARS 在 10 多個 GUI 代理基準測試中取得 SOTA 效能，評估感知、基礎和 GUI 任務執行。值得注意的是，在 OSWorld 基準測試中，UI-TARS 在 50 個步驟中取得 24.6 分，在 15 個步驟中取得 22.7 分，優於 Claude（分別為 22.0 和 14.9）。在 AndroidWorld 中，UI-TARS 取得 46.6 分，超越 GPT-4o（34.5）。UI-TARS 融合了多項關鍵創新：(1) 增強感知：利用大規模 GUI 螢幕截圖資料集，以情境感知的方式理解 UI 元素並進行精確標題說明；(2) 統一動作建模，將動作標準化到跨平台的統一空間，並透過大規模動作追蹤，實現精確的基礎和互動；(3) 系統 2 推理，將深思熟慮的推理納入多步驟決策制定中，涉及多種推理模式，例如任務分解、反思思考、里程碑識別等；(4) 透過反思性線上追蹤進行反覆訓練，透過在數百台虛擬機器上自動收集、過濾和反思性地精煉新的互動追蹤，來解決資料瓶頸問題。透過反覆訓練和反思調整，UI-TARS 不斷從其錯誤中學習，並在最少的人為干預下適應無法預見的情況。我們也分析了 GUI 代理的演進路徑，以引導此領域的進一步發展。

##### **LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**
2501.12300v1 by Hasan Abu-Rasheed, Constance Jumbo, Rashed Al Amin, Christian Weber, Veit Wiese, Roman Obermaisser, Madjid Fathi

While learning personalization offers great potential for learners, modern
practices in higher education require a deeper consideration of domain models
and learning contexts, to develop effective personalization algorithms. This
paper introduces an innovative approach to higher education curriculum
modelling that utilizes large language models (LLMs) for knowledge graph (KG)
completion, with the goal of creating personalized learning-path
recommendations. Our research focuses on modelling university subjects and
linking their topics to corresponding domain models, enabling the integration
of learning modules from different faculties and institutions in the student's
learning path. Central to our approach is a collaborative process, where LLMs
assist human experts in extracting high-quality, fine-grained topics from
lecture materials. We develop a domain, curriculum, and user models for
university modules and stakeholders. We implement this model to create the KG
from two study modules: Embedded Systems and Development of Embedded Systems
Using FPGA. The resulting KG structures the curriculum and links it to the
domain models. We evaluate our approach through qualitative expert feedback and
quantitative graph quality metrics. Domain experts validated the relevance and
accuracy of the model, while the graph quality metrics measured the structural
properties of our KG. Our results show that the LLM-assisted graph completion
approach enhances the ability to connect related courses across disciplines to
personalize the learning experience. Expert feedback also showed high
acceptance of the proposed collaborative approach for concept extraction and
classification.

摘要：<paragraph>在學習個人化提供學習者巨大潛力的同時，高等教育中的現代實務需要更深入地考慮領域模型和學習情境，以開發有效的個人化演算法。本文介紹了一種創新的高等教育課程建模方法，該方法利用大型語言模型 (LLM) 來完成知識圖譜 (KG)，目的是建立個人化的學習路徑建議。我們的研究重點在於建模大學科目，並將它們的主題連結到對應的領域模型，從而能夠將來自不同院系和機構的學習模組整合到學生的學習路徑中。我們的做法核心是一個協作流程，其中 LLM 協助人類專家從講義材料中萃取高品質、細緻的主題。我們為大學模組和利害關係人開發了領域、課程和使用者模型。我們實作這個模型，從兩個研究模組建立 KG：嵌入式系統和使用 FPGA 的嵌入式系統開發。產生的 KG 建構了課程並將其連結到領域模型。我們透過定性專家回饋和定量圖形品質指標來評估我們的做法。領域專家驗證了模型的相關性和準確性，而圖形品質指標則測量了我們 KG 的結構特性。我們的結果顯示，LLM 輔助的圖形完成方法增強了跨學科連結相關課程的能力，以個人化學習體驗。專家回饋也顯示高度接受所提出的協作方法，用於概念萃取和分類。</paragraph>

##### **RALAD: Bridging the Real-to-Sim Domain Gap in Autonomous Driving with Retrieval-Augmented Learning**
2501.12296v1 by Jiacheng Zuo, Haibo Hu, Zikang Zhou, Yufei Cui, Ziquan Liu, Jianping Wang, Nan Guan, Jin Wang, Chun Jason Xue

In the pursuit of robust autonomous driving systems, models trained on
real-world datasets often struggle to adapt to new environments, particularly
when confronted with corner cases such as extreme weather conditions.
Collecting these corner cases in the real world is non-trivial, which
necessitates the use of simulators for validation. However,the high
computational cost and the domain gap in data distribution have hindered the
seamless transition between real and simulated driving scenarios. To tackle
this challenge, we propose Retrieval-Augmented Learning for Autonomous Driving
(RALAD), a novel framework designed to bridge the real-to-sim gap at a low
cost. RALAD features three primary designs, including (1) domain adaptation via
an enhanced Optimal Transport (OT) method that accounts for both individual and
grouped image distances, (2) a simple and unified framework that can be applied
to various models, and (3) efficient fine-tuning techniques that freeze the
computationally expensive layers while maintaining robustness. Experimental
results demonstrate that RALAD compensates for the performance degradation in
simulated environments while maintaining accuracy in real-world scenarios
across three different models. Taking Cross View as an example, the mIOU and
mAP metrics in real-world scenarios remain stable before and after RALAD
fine-tuning, while in simulated environments,the mIOU and mAP metrics are
improved by 10.30% and 12.29%, respectively. Moreover, the re-training cost of
our approach is reduced by approximately 88.1%. Our code is available at
https://github.com/JiachengZuo/RALAD.git.

摘要：<paragraph>在追求穩健的自動駕駛系統時，使用真實世界資料集訓練的模型通常難以適應新環境，特別是在遇到極端天氣條件等極端情況時。在現實世界中收集這些極端情況並非易事，這需要使用模擬器進行驗證。然而，高計算成本和資料分佈中的領域差距阻礙了真實和模擬駕駛場景之間的無縫過渡。為了應對這一挑戰，我們提出了用於自動駕駛的檢索增強學習 (RALAD)，這是一個新穎的框架，旨在以低成本彌合真實與模擬的差距。RALAD 具有三項主要設計，包括 (1) 透過一種增強的最佳傳輸 (OT) 方法進行領域適應，該方法考慮了個別和群組影像距離，(2) 一個簡單且統一的框架，可應用於各種模型，以及 (3) 有效的微調技術，可在維持穩健性的同時凍結計算成本高的層。實驗結果表明，RALAD 補償了模擬環境中的效能下降，同時在三個不同的模型中維持了真實世界場景中的準確性。以 Cross View 為例，RALAD 微調前後，真實世界場景中的 mIOU 和 mAP 指標保持穩定，而在模擬環境中，mIOU 和 mAP 指標分別提高了 10.30% 和 12.29%。此外，我們的方法的重新訓練成本降低了大約 88.1%。我們的程式碼可在 https://github.com/JiachengZuo/RALAD.git 中取得。</paragraph>

##### **With Great Backbones Comes Great Adversarial Transferability**
2501.12275v1 by Erik Arakelyan, Karen Hambardzumyan, Davit Papikyan, Pasquale Minervini, Albert Gordo, Isabelle Augenstein, Aram H. Markosyan

Advances in self-supervised learning (SSL) for machine vision have improved
representation robustness and model performance, giving rise to pre-trained
backbones like \emph{ResNet} and \emph{ViT} models tuned with SSL methods such
as \emph{SimCLR}. Due to the computational and data demands of pre-training,
the utilization of such backbones becomes a strenuous necessity. However,
employing these backbones may inherit vulnerabilities to adversarial attacks.
While adversarial robustness has been studied under \emph{white-box} and
\emph{black-box} settings, the robustness of models tuned on pre-trained
backbones remains largely unexplored. Additionally, the role of tuning
meta-information in mitigating exploitation risks is unclear. This work
systematically evaluates the adversarial robustness of such models across
$20,000$ combinations of tuning meta-information, including fine-tuning
techniques, backbone families, datasets, and attack types. We propose using
proxy models to transfer attacks, simulating varying levels of target knowledge
by fine-tuning these proxies with diverse configurations. Our findings reveal
that proxy-based attacks approach the effectiveness of \emph{white-box}
methods, even with minimal tuning knowledge. We also introduce a naive
"backbone attack," leveraging only the backbone to generate adversarial
samples, which outperforms \emph{black-box} attacks and rivals \emph{white-box}
methods, highlighting critical risks in model-sharing practices. Finally, our
ablations reveal how increasing tuning meta-information impacts attack
transferability, measuring each meta-information combination.

摘要：<paragraph>機器視覺的自監督學習 (SSL) 進步提升了表示穩健性和模型效能，產生預先訓練的骨幹，例如使用 SSL 方法（例如 SimCLR）調整的 ResNet 和 ViT 模型。由於預先訓練的運算和資料需求，使用此類骨幹變得極為必要。然而，採用這些骨幹可能會繼承對抗攻擊的漏洞。儘管在白盒和黑盒設定下已研究對抗穩健性，但預先訓練骨幹上調整的模型的穩健性仍未得到充分探討。此外，調整元資訊在減輕利用風險中的作用尚不清楚。本研究系統性地評估此類模型在 20,000 種調整元資訊組合中的對抗穩健性，包括微調技術、骨幹系列、資料集和攻擊類型。我們建議使用代理模型來傳輸攻擊，透過使用不同的組態微調這些代理模型來模擬不同層級的目標知識。我們的研究結果顯示，即使調整知識最少，基於代理的攻擊也接近白盒方法的有效性。我們還引入了一個天真的「骨幹攻擊」，僅利用骨幹產生對抗樣本，其表現優於黑盒攻擊，並與白盒方法相抗衡，突顯模型分享實務中的關鍵風險。最後，我們的消融實驗揭示了增加調整元資訊如何影響攻擊可傳遞性，並衡量每個元資訊組合。</paragraph>

##### **Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement**
2501.12273v1 by Maosong Cao, Taolin Zhang, Mo Li, Chuyu Zhang, Yunxin Liu, Haodong Duan, Songyang Zhang, Kai Chen

The quality of Supervised Fine-Tuning (SFT) data plays a critical role in
enhancing the conversational capabilities of Large Language Models (LLMs).
However, as LLMs become more advanced, the availability of high-quality
human-annotated SFT data has become a significant bottleneck, necessitating a
greater reliance on synthetic training data. In this work, we introduce Condor,
a novel two-stage synthetic data generation framework that incorporates World
Knowledge Tree and Self-Reflection Refinement to produce high-quality SFT data
at scale. Our experimental results demonstrate that a base model fine-tuned on
only 20K Condor-generated samples achieves superior performance compared to
counterparts. The additional refinement stage in Condor further enables
iterative self-improvement for LLMs at various scales (up to 72B), validating
the effectiveness of our approach. Furthermore, our investigation into the
scaling for synthetic data in post-training reveals substantial unexplored
potential for performance improvements, opening promising avenues for future
research.

摘要：監督式微調 (SFT) 資料的品質對於增強大型語言模型 (LLM) 的對話能力發揮關鍵作用。然而，隨著 LLM 變得越來越先進，高品質人工標註 SFT 資料的可用性已成為一個重大的瓶頸，這使得對合成訓練資料的依賴性越來越高。在這項工作中，我們介紹了 Condor，一個新穎的兩階段合成資料生成架構，它結合了世界知識樹和自我反省精煉，以大規模產生高品質的 SFT 資料。我們的實驗結果表明，僅針對 20K 個 Condor 生成的範例進行微調的基本模型，與同類型模型相比，可獲得優越的效能。Condor 中的額外精煉階段進一步讓 LLM 能夠在各種規模（最高 72B）下進行反覆自我改善，驗證了我們方法的有效性。此外，我們對訓練後合成資料的擴展性進行調查，揭示了效能改善的巨大未開發潛力，為未來的研究開闢了有前景的途徑。

##### **CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**
2501.12266v1 by Cristiano Patrício, Isabel Rio-Torto, Jaime S. Cardoso, Luís F. Teixeira, João C. Neves

The main challenges limiting the adoption of deep learning-based solutions in
medical workflows are the availability of annotated data and the lack of
interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the
latter by constraining the final disease prediction on a set of predefined and
human-interpretable concepts. However, the increased interpretability achieved
through these concept-based explanations implies a higher annotation burden.
Moreover, if a new concept needs to be added, the whole system needs to be
retrained. Inspired by the remarkable performance shown by Large
Vision-Language Models (LVLMs) in few-shot settings, we propose a simple, yet
effective, methodology, CBVLM, which tackles both of the aforementioned
challenges. First, for each concept, we prompt the LVLM to answer if the
concept is present in the input image. Then, we ask the LVLM to classify the
image based on the previous concept predictions. Moreover, in both stages, we
incorporate a retrieval module responsible for selecting the best examples for
in-context learning. By grounding the final diagnosis on the predicted
concepts, we ensure explainability, and by leveraging the few-shot capabilities
of LVLMs, we drastically lower the annotation cost. We validate our approach
with extensive experiments across four medical datasets and twelve LVLMs (both
generic and medical) and show that CBVLM consistently outperforms CBMs and
task-specific supervised methods without requiring any training and using just
a few annotated examples. More information on our project page:
https://cristianopatricio.github.io/CBVLM/.

摘要：限制在醫療工作流程中採用基於深度學習的解決方案的主要挑戰是標記資料的可用性以及此類系統的可解釋性不足。概念瓶頸模型 (CBM) 透過限制一組預定義且人類可解釋的概念對最終疾病預測，來解決後者。然而，透過這些基於概念的解釋所實現的可解釋性提升，意味著更高的標記負擔。此外，如果需要新增一個新概念，則需要重新訓練整個系統。受到大型視覺語言模型 (LVLMs) 在小樣本設定中展現的卓越效能啟發，我們提出了一個簡單但有效的 CBVLM 方法，來解決上述兩個挑戰。首先，對於每個概念，我們提示 LVLM 回答輸入影像中是否包含該概念。然後，我們要求 LVLM 根據先前的概念預測對影像進行分類。此外，在兩個階段中，我們都納入一個檢索模組，負責選出最適合於情境學習的範例。透過將最終診斷建立在預測概念之上，我們確保了可解釋性，並透過利用 LVLMs 的小樣本能力，我們大幅降低了標記成本。我們透過四個醫療資料集和十二個 LVLM（通用和醫療）的廣泛實驗驗證了我們的作法，並顯示 CBVLM 在無需任何訓練且僅使用少數標記範例的情況下，始終優於 CBM 和特定於任務的監督式方法。更多資訊請見我們的專案頁面：https://cristianopatricio.github.io/CBVLM/。

##### **FOCUS: First Order Concentrated Updating Scheme**
2501.12243v1 by Yizhou Liu, Ziming Liu, Jeff Gore

Large language models (LLMs) demonstrate remarkable performance, and
improving their pre-training process appears to be key to enhancing their
capabilities further. Based on the documented success of Adam, learning rate
decay, and weight decay, we hypothesize that the pre-training loss landscape
features a narrowing valley structure. Through experiments with synthetic loss
functions, we discover that when gradient query noise is high relative to the
valley's sharpness, Adam's performance falls behind that of Signum because Adam
reduces the effective step size too drastically. This observation led us to
develop FOCUS, an optimizer that enhances Signum by incorporating attraction
toward moving averaged parameters, allowing it to handle noise better while
maintaining larger step sizes. In training GPT-2, FOCUS proves to be more
stable than Signum and faster than Adam. These results suggest that gradient
noise may be an underappreciated limiting factor in LLM training, and FOCUS
offers promising solutions.

摘要：大型語言模型 (LLM) 展現出卓越的效能，而改善其預訓練程序似乎是進一步提升其功能的關鍵。根據 Adam、學習率衰減和權重衰減的已記錄成功，我們假設預訓練損失景觀具有縮小的谷地結構。透過對合成損失函數的實驗，我們發現當梯度查詢雜訊相對於谷地的銳利度較高時，Adam 的效能會落後於 Signum，因為 Adam 會過度大幅度地減少有效步驟大小。這個觀察讓我們開發出 FOCUS，一種透過納入對移動平均參數的吸引力來增強 Signum 的最佳化器，讓它可以在維持較大步驟大小的同時更好地處理雜訊。在訓練 GPT-2 時，FOCUS 證明比 Signum 更穩定，而且比 Adam 更快。這些結果表明，梯度雜訊可能是 LLM 訓練中一個未被充分重視的限制因素，而 FOCUS 提供了有希望的解決方案。

##### **InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**
2501.12231v1 by Pha Nguyen, Sailik Sengupta, Girik Malik, Arshit Gupta, Bonan Min

The improved competence of generative models can help building multi-modal
virtual assistants that leverage modalities beyond language. By observing
humans performing multi-step tasks, one can build assistants that have
situational awareness of actions and tasks being performed, enabling them to
cater assistance based on this understanding. In this paper, we develop a
Context-aware Instructional Task Assistant with Multi-modal Large Language
Models (InsTALL) that leverages an online visual stream (e.g. a user's screen
share or video recording) and responds in real-time to user queries related to
the task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal
model on task videos and paired textual data, and 2) automatically extracts
task graph from video data and leverages it at training and inference time. We
show InsTALL achieves state-of-the-art performance across proposed sub-tasks
considered for multimodal activity understanding -- task recognition (TR),
action recognition (AR), next action prediction (AP), and plan prediction (PP)
-- and outperforms existing baselines on two novel sub-tasks related to
automatic error identification.

摘要：生成模型能力的提升有助于构建利用语言之外的多模态虚拟助手。通过观察人类执行多步骤任务，可以构建对正在执行的动作和任务有情境感知的助手，使他们能够根据这种理解提供帮助。在本文中，我们开发了一个具有多模态大语言模型的上下文感知指令任务助手 (InsTALL)，该助手利用在线视觉流（例如用户的屏幕共享或视频录制），并实时响应与手头任务相关的用户查询。为了提供有用的帮助，InsTALL 1) 在任务视频和配对文本数据上训练多模态模型，以及 2) 从视频数据中自动提取任务图，并在训练和推理时间利用它。我们展示了 InsTALL 在考虑用于多模态活动理解的提议子任务中实现了最先进的性能——任务识别 (TR)、动作识别 (AR)、下一个动作预测 (AP) 和计划预测 (PP)——并且在与自动错误识别相关的两个新子任务上优于现有的基准。

##### **Fixing Imbalanced Attention to Mitigate In-Context Hallucination of Large Vision-Language Model**
2501.12206v1 by Kazi Hasan Ibn Arif, Sajib Acharjee Dip, Khizar Hussain, Lang Zhang, Chris Thomas

Large Vision Language Models (LVLMs) have demonstrated remarkable
capabilities in understanding and describing visual content, achieving
state-of-the-art performance across various vision-language tasks. However,
these models frequently exhibit hallucination behavior, where they generate
descriptions containing objects or details absent in the input image. Our work
investigates this phenomenon by analyzing attention patterns across transformer
layers and heads, revealing that hallucinations often stem from progressive
degradation of visual grounding in deeper layers. We propose a novel attention
modification approach that combines selective token emphasis and head-specific
modulation to maintain visual grounding throughout the generation process. Our
method introduces two key components: (1) a dual-stream token selection
mechanism that identifies and prioritizes both locally informative and
spatially significant visual tokens, and (2) an attention head-specific
modulation strategy that differentially amplifies visual information processing
based on measured visual sensitivity of individual attention heads. Through
extensive experimentation on the MSCOCO dataset, we demonstrate that our
approach reduces hallucination rates by up to 62.3\% compared to baseline
models while maintaining comparable task performance. Our analysis reveals that
selectively modulating tokens across attention heads with varying levels of
visual sensitivity can significantly improve visual grounding without requiring
model retraining.

摘要：大型視覺語言模型 (LVLMs) 已展現出在理解和描述視覺內容方面的卓越能力，在各種視覺語言任務中取得了最先進的表現。然而，這些模型經常表現出幻覺行為，它們會產生包含輸入影像中不存在的物件或細節的描述。我們的研究透過分析Transformer層和頭部的注意力模式來探討這種現象，揭示幻覺通常源於較深層的視覺基礎逐漸退化。我們提出了一種新穎的注意力修改方法，結合選擇性的權標強調和特定於頭部的調變，以在整個生成過程中維持視覺基礎。我們的技術引入了兩個關鍵組成部分：(1) 一種雙串流權標選擇機制，用於識別和優先處理局部資訊性和空間顯著性的視覺權標，以及 (2) 一種注意力頭部特定調變策略，根據個別注意力頭部的測量視覺敏感度，對視覺資訊處理進行不同的放大。透過在 MSCOCO 資料集上進行廣泛的實驗，我們證明了與基準模型相比，我們的技術將幻覺率降低了多達 62.3%，同時維持了相當的任務表現。我們的分析顯示，選擇性地調變具有不同視覺敏感度層級的注意力頭部的權標，可以在不需重新訓練模型的情況下，顯著改善視覺基礎。

##### **An End-to-End Approach for Korean Wakeword Systems with Speaker Authentication**
2501.12194v1 by Geonwoo Seo

Wakeword detection plays a critical role in enabling AI assistants to listen
to user voices and interact effectively. However, for languages other than
English, there is a significant lack of pre-trained wakeword models.
Additionally, systems that merely determine the presence of a wakeword can pose
serious privacy concerns. In this paper, we propose an end-to-end approach that
trains wakewords for Non-English languages, particulary Korean, and uses this
to develop a Voice Authentication model to protect user privacy. Our
implementation employs an open-source platform OpenWakeWord, which performs
wakeword detection using an FCN (Fully-Connected Network) architecture. Once a
wakeword is detected, our custom-developed code calculates cosine similarity
for robust user authentication. Experimental results demonstrate the
effectiveness of our approach, achieving a 16.79% and a 6.6% Equal Error Rate
(EER) each in the Wakeword Detection and the Voice Authentication. These
findings highlight the model's potential in providing secure and accurate
wakeword detection and authentication for Korean users.

摘要：喚醒字偵測在讓 AI 助理聆聽使用者聲音並有效互動中扮演關鍵角色。然而，對於非英語語言來說，預先訓練的喚醒字模型存在著顯著的缺乏。此外，僅僅判定喚醒字存在的系統可能會造成嚴重的隱私問題。在本文中，我們提出一個端對端的方法，用於訓練非英語語言（特別是韓語）的喚醒字，並使用它來開發一個語音驗證模型以保護使用者隱私。我們的實作採用一個開源平台 OpenWakeWord，它使用 FCN（全連接網路）架構來執行喚醒字偵測。一旦偵測到喚醒字，我們自訂開發的程式碼會計算餘弦相似度以進行穩健的使用者驗證。實驗結果證明了我們方法的有效性，在喚醒字偵測和語音驗證中分別達到 16.79% 和 6.6% 的等錯率（EER）。這些發現突顯了該模型在為韓語使用者提供安全且準確的喚醒字偵測和驗證方面的潛力。

##### **AdaServe: SLO-Customized LLM Serving with Fine-Grained Speculative Decoding**
2501.12162v1 by Zikun Li, Zhuofu Chen, Remi Delacourt, Gabriele Oliaro, Zeyu Wang, Qinghan Chen, Shuhuai Lin, April Yang, Zhihao Zhang, Zhuoming Chen, Sean Lai, Xupeng Miao, Zhihao Jia

This paper introduces AdaServe, the first LLM serving system to support SLO
customization through fine-grained speculative decoding. AdaServe leverages the
logits of a draft model to predict the speculative accuracy of tokens and
employs a theoretically optimal algorithm to construct token trees for
verification. To accommodate diverse SLO requirements without compromising
throughput, AdaServe employs a speculation-and-selection scheme that first
constructs candidate token trees for each request and then dynamically selects
tokens to meet individual SLO constraints while optimizing throughput.
Comprehensive evaluations demonstrate that AdaServe achieves up to 73% higher
SLO attainment and 74% higher goodput compared to state-of-the-art systems.
These results underscore AdaServe's potential to enhance the efficiency and
adaptability of LLM deployments across varied application scenarios.

摘要：這篇論文介紹了 AdaServe，這是第一個支援透過細粒度推測解碼來自訂服務等級目標 (SLO) 的 LLM 服務系統。AdaServe 利用草稿模型的邏輯來預測代碼的推測準確度，並採用理論上最佳的演算法來建構代碼樹以進行驗證。為了滿足不同的 SLO 需求，同時不影響處理量，AdaServe 採用一種推測與選擇的方案，該方案會先為每個要求建構候選代碼樹，然後動態選擇代碼以滿足個別 SLO 約束，同時最佳化處理量。全面的評估顯示，與現有系統相比，AdaServe 的 SLO 達成率最高可提升 73%，而好處率則最高可提升 74%。這些結果突顯了 AdaServe 在提升 LLM 部署效率和適應力方面的潛力，適用於各種應用場景。

##### **On the practical applicability of modern DFT functionals for chemical computations. Case study of DM21 applicability for geometry optimization**
2501.12149v1 by Kirill Kulaev, Alexander Ryabov, Michael Medvedev, Evgeny Burnaev, Vladimir Vanovskiy

Density functional theory (DFT) is probably the most promising approach for
quantum chemistry calculations considering its good balance between
calculations precision and speed. In recent years, several neural network-based
functionals have been developed for exchange-correlation energy approximation
in DFT, DM21 developed by Google Deepmind being the most notable between them.
This study focuses on evaluating the efficiency of DM21 functional in
predicting molecular geometries, with a focus on the influence of oscillatory
behavior in neural network exchange-correlation functionals. We implemented
geometry optimization in PySCF for the DM21 functional in geometry optimization
problem, compared its performance with traditional functionals, and tested it
on various benchmarks. Our findings reveal both the potential and the current
challenges of using neural network functionals for geometry optimization in
DFT. We propose a solution extending the practical applicability of such
functionals and allowing to model new substances with their help.

摘要：密度泛函理論 (DFT) 可能是在量子化學計算中，在計算精度和速度之間取得良好平衡的最有前途的方法。近年來，已經為 DFT 中的交換相關能近似開發了幾種基於神經網路的泛函，由 Google Deepmind 開發的 DM21 是其中最著名的。本研究重點在於評估 DM21 泛函在預測分子幾何形狀方面的效率，重點在於神經網路交換相關泛函中振盪行為的影響。我們在幾何最佳化問題中為 DM21 泛函實作了 PySCF 中的幾何最佳化，將其效能與傳統泛函進行比較，並在各種基準上對其進行測試。我們的發現揭示了使用神經網路泛函進行 DFT 中幾何最佳化的潛力和當前挑戰。我們提出了一個解決方案，擴展了此類泛函的實用適用性，並允許藉助它們來建模新物質。

##### **Improving Influence-based Instruction Tuning Data Selection for Balanced Learning of Diverse Capabilities**
2501.12147v1 by Qirun Dai, Dylan Zhang, Jiaqi W. Ma, Hao Peng

Selecting appropriate training data is crucial for effective instruction
fine-tuning of large language models (LLMs), which aims to (1) elicit strong
capabilities, and (2) achieve balanced performance across a diverse range of
tasks. Influence-based methods show promise in achieving (1) by estimating the
contribution of each training example to the model's predictions, but often
struggle with (2). Our systematic investigation reveals that this
underperformance can be attributed to an inherent bias where certain tasks
intrinsically have greater influence than others. As a result, data selection
is often biased towards these tasks, not only hurting the model's performance
on others but also, counterintuitively, harms performance on these
high-influence tasks themselves.
  As a remedy, we propose BIDS, a Balanced and Influential Data Selection
algorithm. BIDS first normalizes influence scores of the training data, and
then iteratively balances data selection by choosing the training example with
the highest influence on the most underrepresented task. Experiments with both
Llama-3 and Mistral-v0.3 on seven benchmarks spanning five diverse capabilities
show that BIDS consistently outperforms both state-of-the-art influence-based
algorithms and other non-influence-based selection frameworks. Surprisingly,
training on a 15% subset selected by BIDS can even outperform full-dataset
training with a much more balanced performance. Our analysis further highlights
the importance of both instance-level normalization and iterative optimization
of selected data for balanced learning of diverse capabilities.

摘要：<paragraph>選擇適當的訓練資料對於有效指示大型語言模型 (LLM) 的微調至關重要，其目標為：(1) 引發強大的能力，以及 (2) 在各種任務中達成平衡的表現。基於影響力的方法顯示出在達成 (1) 方面很有希望，透過估計每個訓練範例對模型預測的貢獻，但通常在 (2) 方面會遭遇困難。我們的系統性調查顯示，這種表現不佳可歸因於內在偏差，其中某些任務本質上比其他任務具有更大的影響力。因此，資料選擇通常會偏向這些任務，這不僅會損害模型在其他任務上的表現，而且反直覺地會損害這些高影響力任務本身的表現。
作為補救措施，我們提出 BIDS，一種平衡且有影響力的資料選擇演算法。BIDS 首先將訓練資料的影響力分數標準化，然後透過選擇對代表性不足的任務影響最大的訓練範例，反覆平衡資料選擇。在 Llama-3 和 Mistral-v0.3 上進行的實驗，涵蓋五種不同能力的七個基準，顯示 BIDS 持續優於最先進的基於影響力的演算法和其他非基於影響力的選擇架構。令人驚訝的是，在 BIDS 選擇的 15% 子集上進行訓練，甚至可以優於使用平衡度更高的完整資料集訓練。我們的分析進一步突顯了在平衡學習各種能力時，執行個體層級標準化和反覆最佳化所選資料的重要性。</paragraph>

##### **FedCLEAN: byzantine defense by CLustering Errors of Activation maps in Non-IID federated learning environments**
2501.12123v1 by Mehdi Ben Ghali, Reda Bellafqira, Gouenou Coatrieux

Federated Learning (FL) enables clients to collaboratively train a global
model using their local datasets while reinforcing data privacy. However, FL is
susceptible to poisoning attacks. Existing defense mechanisms assume that
clients' data are independent and identically distributed (IID), making them
ineffective in real-world applications where data are non-IID. This paper
presents FedCLEAN, the first defense capable of filtering attackers' model
updates in a non-IID FL environment. The originality of FedCLEAN is twofold.
First, it relies on a client confidence score derived from the reconstruction
errors of each client's model activation maps for a given trigger set, with
reconstruction errors obtained by means of a Conditional Variational
Autoencoder trained according to a novel server-side strategy. Second, we
propose an ad-hoc trust propagation algorithm based on client scores, which
allows building a cluster of benign clients while flagging potential attackers.
Experimental results on the datasets MNIST and FashionMNIST demonstrate the
robustness of FedCLEAN against Byzantine attackers in non-IID scenarios and a
close-to-zero benign client misclassification rate, even in the absence of an
attack.

摘要：聯盟式學習 (FL) 讓客戶端能夠利用其本機資料集進行協作訓練，同時強化資料隱私。然而，FL 容易受到中毒攻擊。現有的防禦機制假設客戶端資料是獨立且同質分佈 (IID)，這使得它們在資料非 IID 的實際應用中無效。本文提出 FedCLEAN，這是第一個能夠在非 IID FL 環境中過濾攻擊者模型更新的防禦機制。FedCLEAN 的原創性有兩方面。首先，它依賴於客戶端信心評分，該評分來自於特定觸發器集的每個客戶端模型啟用映射的重建誤差，重建誤差是透過根據新穎伺服器端策略訓練的條件變異自動編碼器獲得的。其次，我們提出了一種基於客戶端評分的臨時信任傳播演算法，該演算法允許建立良性客戶端叢集，同時標記潛在的攻擊者。在 MNIST 和 FashionMNIST 資料集上的實驗結果證明了 FedCLEAN 在非 IID 情境中對拜占庭攻擊者的穩健性，以及接近於零的良性客戶端誤分類率，即使在沒有攻擊的情況下也是如此。

##### **Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes**
2501.12106v1 by Stefan Lenz, Arsenij Ustjanzew, Marco Jeray, Torsten Panholzer

Tumor documentation in Germany is largely done manually, requiring reading
patient records and entering data into structured databases. Large language
models (LLMs) could potentially enhance this process by improving efficiency
and reliability. This evaluation tests eleven different open source LLMs with
sizes ranging from 1-70 billion model parameters on three basic tasks of the
tumor documentation process: identifying tumor diagnoses, assigning ICD-10
codes, and extracting the date of first diagnosis. For evaluating the LLMs on
these tasks, a dataset of annotated text snippets based on anonymized doctors'
notes from urology was prepared. Different prompting strategies were used to
investigate the effect of the number of examples in few-shot prompting and to
explore the capabilities of the LLMs in general. The models Llama 3.1 8B,
Mistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.
Models with less extensive training data or having fewer than 7 billion
parameters showed notably lower performance, while larger models did not
display performance gains. Examples from a different medical domain than
urology could also improve the outcome in few-shot prompting, which
demonstrates the ability of LLMs to handle tasks needed for tumor
documentation. Open source LLMs show a strong potential for automating tumor
documentation. Models from 7-12 billion parameters could offer an optimal
balance between performance and resource efficiency. With tailored fine-tuning
and well-designed prompting, these models might become important tools for
clinical documentation in the future. The code for the evaluation is available
from https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset
as a new valuable resource that addresses the shortage of authentic and easily
accessible benchmarks in German-language medical NLP.

摘要：德國的腫瘤文件記錄大部分是手動完成，需要閱讀病歷並將資料輸入結構化的資料庫中。大型語言模型 (LLM) 可能透過提升效率和可靠性來增強此程序。此評量測試了 11 個不同的開源 LLM，模型參數大小從 10 億到 700 億不等，針對腫瘤文件記錄程序的三項基本任務：識別腫瘤診斷、指定 ICD-10 代碼，以及擷取首次診斷日期。為了針對這些任務評估 LLM，準備了一個基於泌尿科醫生匿名筆記的註解文字片段資料集。使用不同的提示策略來調查少量提示中範例數量的影響，並探索 LLM 的一般能力。Llama 3.1 8B、Mistral 7B 和 Mistral NeMo 12 B 等模型在這些任務中表現相當好。訓練資料較少或參數少於 70 億的模型表現明顯較差，而較大的模型並未展現效能提升。與泌尿科不同的醫療領域的範例也可以改善少量提示的結果，這證明了 LLM 處理腫瘤文件記錄所需任務的能力。開源 LLM 在自動化腫瘤文件記錄方面顯示出強大的潛力。參數介於 70 億到 120 億的模型可以在效能和資源效率之間提供最佳平衡。透過量身打造微調和精心設計的提示，這些模型未來可能會成為臨床文件記錄的重要工具。評估程式碼可從 https://github.com/stefan-m-lenz/UroLlmEval 取得。我們也釋出資料集作為一個新的有價值資源，用於解決德語醫療自然語言處理中真實且易於取得的基準短缺問題。

##### **Teacher Encoder-Student Decoder Denoising Guided Segmentation Network for Anomaly Detection**
2501.12104v1 by ShiXuan Song, Hao Chen, Shu Hu, Xin Wang, Jinrong Hu, Xi Wu

Visual anomaly detection is a highly challenging task, often categorized as a
one-class classification and segmentation problem. Recent studies have
demonstrated that the student-teacher (S-T) framework effectively addresses
this challenge. However, most S-T frameworks rely solely on pre-trained teacher
networks to guide student networks in learning multi-scale similar features,
overlooking the potential of the student networks to enhance learning through
multi-scale feature fusion. In this study, we propose a novel model named
PFADSeg, which integrates a pre-trained teacher network, a denoising student
network with multi-scale feature fusion, and a guided anomaly segmentation
network into a unified framework. By adopting a unique teacher-encoder and
student-decoder denoising mode, the model improves the student network's
ability to learn from teacher network features. Furthermore, an adaptive
feature fusion mechanism is introduced to train a self-supervised segmentation
network that synthesizes anomaly masks autonomously, significantly increasing
detection performance. Evaluated on the MVTec AD dataset, PFADSeg achieves
state-of-the-art results with an image-level AUC of 98.9%, a pixel-level mean
precision of 76.4%, and an instance-level mean precision of 78.7%.

摘要：視覺異常偵測是一項極具挑戰性的任務，通常被歸類為一類分類和分割問題。最近的研究表明，學生-教師 (S-T) 框架有效地應對了這一挑戰。然而，大多數 S-T 框架僅依賴預先訓練的教師網路來指導學生網路學習多尺度相似特徵，忽視了學生網路通過多尺度特徵融合增強學習的可能性。在本研究中，我們提出了一個名為 PFADSeg 的新模型，它將預訓練的教師網路、具有多尺度特徵融合的去噪學生網路和引導異常分割網路整合到一個統一的框架中。通過採用獨特的教師編碼器和學生解碼器去噪模式，該模型提高了學生網路從教師網路特徵中學習的能力。此外，還引入了一個自適應特徵融合機制來訓練一個自監督分割網路，該網路可以自動合成異常遮罩，從而顯著提高檢測性能。在 MVTec AD 資料集上進行評估，PFADSeg 達到了最先進的結果，圖像級別 AUC 為 98.9%，像素級別平均精度為 76.4%，實例級別平均精度為 78.7%。

##### **Proxies for Distortion and Consistency with Applications for Real-World Image Restoration**
2501.12102v1 by Sean Man, Guy Ohayon, Ron Raphaeli, Michael Elad

Real-world image restoration deals with the recovery of images suffering from
an unknown degradation. This task is typically addressed while being given only
degraded images, without their corresponding ground-truth versions. In this
hard setting, designing and evaluating restoration algorithms becomes highly
challenging. This paper offers a suite of tools that can serve both the design
and assessment of real-world image restoration algorithms. Our work starts by
proposing a trained model that predicts the chain of degradations a given
real-world measured input has gone through. We show how this estimator can be
used to approximate the consistency -- the match between the measurements and
any proposed recovered image. We also use this estimator as a guiding force for
the design of a simple and highly-effective plug-and-play real-world image
restoration algorithm, leveraging a pre-trained diffusion-based image prior.
Furthermore, this work proposes no-reference proxy measures of MSE and LPIPS,
which, without access to the ground-truth images, allow ranking of real-world
image restoration algorithms according to their (approximate) MSE and LPIPS.
The proposed suite provides a versatile, first of its kind framework for
evaluating and comparing blind image restoration algorithms in real-world
scenarios.

摘要：真實世界的影像修復處理受損影像的復原，其損壞情況不明。此任務通常在僅提供受損影像的情況下進行，而沒有對應的真實版本。在此艱難的設定中，設計和評估修復演算法變得極具挑戰性。本文提供了一套工具，可同時服務於真實世界影像修復演算法的設計和評估。我們的研究從提出一個訓練好的模型開始，該模型預測給定的真實世界測量輸入所經歷的一連串劣化。我們展示了如何使用此估計器來逼近一致性，即測量值與任何提議的復原影像之間的匹配。我們還使用此估計器作為設計一個簡單且高效的即插即用真實世界影像修復演算法的指導力量，利用預先訓練的基於擴散的影像先驗。此外，這項工作提出了 MSE 和 LPIPS 的無參考代理測量，在無法取得真實影像的情況下，可以根據其（近似的）MSE 和 LPIPS 對真實世界影像修復演算法進行排名。所提出的套件提供了一個通用且首創的架構，用於評估和比較在真實世界場景中盲目影像修復演算法。

##### **Scalable Whole Slide Image Representation Using K-Mean Clustering and Fisher Vector Aggregation**
2501.12085v1 by Ravi Kant Gupta, Shounak Das, Ardhendu Sekhar, Amit Sethi

Whole slide images (WSIs) are high-resolution, gigapixel sized images that
pose significant computational challenges for traditional machine learning
models due to their size and heterogeneity.In this paper, we present a scalable
and efficient methodology for WSI classification by leveraging patch-based
feature extraction, clustering, and Fisher vector encoding. Initially, WSIs are
divided into fixed size patches, and deep feature embeddings are extracted from
each patch using a pre-trained convolutional neural network (CNN). These
patch-level embeddings are subsequently clustered using K-means clustering,
where each cluster aggregates semantically similar regions of the WSI. To
effectively summarize each cluster, Fisher vector representations are computed
by modeling the distribution of patch embeddings in each cluster as a
parametric Gaussian mixture model (GMM). The Fisher vectors from each cluster
are concatenated into a high-dimensional feature vector, creating a compact and
informative representation of the entire WSI. This feature vector is then used
by a classifier to predict the WSI's diagnostic label. Our method captures
local and global tissue structures and yields robust performance for
large-scale WSI classification, demonstrating superior accuracy and scalability
compared to other approaches.

摘要：全玻片影像（WSI）是高解析度、千兆像素大小的影像，由于其大小和异质性，对传统机器学习模型造成重大的计算挑战。在本文中，我们提出一种可扩展且有效的方法，通过利用基于贴片的特征提取、聚类和 Fisher 向量编码来进行 WSI 分类。最初，WSI 被分成固定大小的贴片，并使用预先训练过的卷积神经网络 (CNN) 从每个贴片中提取深度特征嵌入。这些贴片级别的嵌入随后使用 K 均值聚类进行聚类，其中每个聚类都聚合了 WSI 中语义相似的区域。为了有效地总结每个聚类，通过将每个聚类中贴片嵌入的分布建模为参数化高斯混合模型 (GMM) 来计算 Fisher 向量表示。来自每个聚类的 Fisher 向量被连接成一个高维特征向量，创建整个 WSI 的紧凑且信息丰富的表示。然后，分类器使用此特征向量来预测 WSI 的诊断标签。我们的方法捕捉局部和全局组织结构，并产生大规模 WSI 分类的高鲁棒性性能，与其他方法相比，展示出卓越的准确性和可扩展性。

##### **EDoRA: Efficient Weight-Decomposed Low-Rank Adaptation via Singular Value Decomposition**
2501.12067v1 by Hamid Nasiri, Peter Garraghan

Parameter-efficient fine-tuning methods, such as LoRA, reduces the number of
trainable parameters. However, they often suffer from scalability issues and
differences between their learning pattern and full fine-tuning. To overcome
these limitations, we propose Efficient Weight-Decomposed Low-Rank Adaptation
(EDoRA): a novel PEFT method that decomposes pre-trained weights into magnitude
and directional components. By freezing low-rank matrices, initializing them by
singular value decomposition, and introducing a small trainable matrix between
them, EDoRA achieves substantial reduction in trainable parameters while
maintaining learning capacity. Experimental results on the GLUE benchmark
demonstrate that EDoRA achieves competitive or superior performance compared to
state-of-the-art methods, such as LoRA and DoRA, with up to 30x fewer trainable
parameters. This makes EDoRA a highly efficient solution for adapting LLMs to
diverse tasks under memory-constrained settings. Code is available at
https://github.com/Hamid-Nasiri/EDoRA .

摘要：參數高效微調方法（例如 LoRA）減少了可訓練參數的數量。然而，它們經常會遇到可擴充性問題，而且它們的學習模式與完全微調之間存在差異。為了克服這些限制，我們提出了高效權重分解低秩適應 (EDoRA)：一種將預訓練權重分解為幅度和方向分量的全新 PEFT 方法。透過凍結低秩矩陣、使用奇異值分解對它們進行初始化，並在它們之間引入一個小的可訓練矩陣，EDoRA 實現了可訓練參數的大幅減少，同時維持了學習能力。GLUE 基準上的實驗結果證明，與 LoRA 和 DoRA 等最先進的方法相比，EDoRA 達到了具有競爭力或更優異的效能，可訓練參數減少了多達 30 倍。這使得 EDoRA 成為在記憶體受限設定下將 LLM 適應到各種任務的高效解決方案。程式碼可在 https://github.com/Hamid-Nasiri/EDoRA 取得。

##### **MedS$^3$: Towards Medical Small Language Models with Self-Evolved Slow Thinking**
2501.12051v1 by Shuyang Jiang, Yusheng Liao, Zhe Chen, Ya Zhang, Yanfeng Wang, Yu Wang

Medical language models (MLMs) have become pivotal in advancing medical
natural language processing. However, prior models that rely on pre-training or
supervised fine-tuning often exhibit low data efficiency and limited
practicality in real-world clinical applications. While OpenAIs O1 highlights
test-time scaling in mathematics, attempts to replicate this approach in
medicine typically distill responses from GPT-series models to open-source
models, focusing primarily on multiple-choice tasks. This strategy, though
straightforward, neglects critical concerns like data privacy and realistic
deployment in clinical settings. In this work, we present a deployable,
small-scale medical language model, \mone, designed for long-chain reasoning in
clinical tasks using a self-evolution paradigm. Starting with a seed dataset of
around 8,000 instances spanning five domains and 16 datasets, we prompt a base
policy model to perform Monte Carlo Tree Search (MCTS) to construct verifiable
reasoning chains. Each reasoning step is assigned an evolution rollout value,
allowing verified trajectories to train the policy model and the reward model.
During inference, the policy model generates multiple responses, and the reward
model selects the one with the highest reward score. Experiments on eleven
evaluation datasets demonstrate that \mone outperforms prior open-source models
by 2 points, with the addition of the reward model further boosting performance
($\sim$13 points), surpassing GPT-4o-mini. Code and data are available at
\url{https://github.com/pixas/MedSSS}.

摘要：<paragraph>醫療語言模型 (MLM) 已成為推進醫療自然語言處理的關鍵。然而，依賴於預訓練或監督微調的先前模型通常表現出低資料效率，且在現實世界的臨床應用中實用性有限。儘管 OpenAI 的 O1 強調數學中的測試時間縮放，但嘗試在醫學中複製此方法通常會將 GPT 系列模型的回應提煉到開源模型，主要關注於多選題任務。這種策略雖然簡單，但忽略了資料隱私和臨床環境中的實際部署等關鍵問題。在這項工作中，我們提出了一個可部署的小規模醫療語言模型 \mone，它使用自演化範例針對臨床任務中的長鏈推理而設計。從跨越五個領域和 16 個資料集的大約 8,000 個實例的種子資料集開始，我們提示一個基本策略模型執行蒙地卡羅樹狀搜尋 (MCTS) 以建構可驗證的推理鏈。每個推理步驟都指定了一個演化展開值，允許驗證的軌跡訓練策略模型和獎勵模型。在推理期間，策略模型會產生多個回應，而獎勵模型會選擇獎勵分數最高的回應。對 11 個評估資料集的實驗表明，\mone 的表現優於先前的開源模型 2 分，而獎勵模型的加入進一步提升了效能（$\sim$13 分），超越了 GPT-4o-mini。程式碼和資料可以在 \url{https://github.com/pixas/MedSSS} 取得。</paragraph>

##### **Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye**
2501.12048v1 by Shramana Dey, Pallabi Dutta, Riddhasree Bhattacharyya, Surochita Pal, Sushmita Mitra, Rajiv Raman

The prevalence of ocular illnesses is growing globally, presenting a
substantial public health challenge. Early detection and timely intervention
are crucial for averting visual impairment and enhancing patient prognosis.
This research introduces a new framework called Class Extension with Limited
Data (CELD) to train a classifier to categorize retinal fundus images. The
classifier is initially trained to identify relevant features concerning
Healthy and Diabetic Retinopathy (DR) classes and later fine-tuned to adapt to
the task of classifying the input images into three classes: Healthy, DR, and
Glaucoma. This strategy allows the model to gradually enhance its
classification capabilities, which is beneficial in situations where there are
only a limited number of labeled datasets available. Perturbation methods are
also used to identify the input image characteristics responsible for
influencing the models decision-making process. We achieve an overall accuracy
of 91% on publicly available datasets.

摘要：全球眼疾患病率持續上升，對公共衛生造成重大挑戰。早期發現和及時干預對於預防視力障礙和改善患者預後至關重要。本研究提出了一個名為有限數據類別擴展 (CELD) 的新框架，用於訓練分類器對視網膜眼底圖像進行分類。該分類器最初接受訓練以識別與健康和糖尿病視網膜病變 (DR) 類別相關的特徵，然後進行微調以適應將輸入圖像分類為三類的任務：健康、DR 和青光眼。此策略允許模型逐步增強其分類能力，這在標記數據集數量有限的情況下是有益的。擾動方法也用於識別負責影響模型決策過程的輸入圖像特徵。我們在公開數據集上實現了 91% 的整體準確度。

##### **Harnessing Generative Pre-Trained Transformer for Datacenter Packet Trace Generation**
2501.12033v1 by Chen Griner

Today, the rapid growth of applications reliant on datacenters calls for new
advancements to meet the increasing traffic and computational demands. Traffic
traces from datacenters are essential for further development and optimization
of future datacenters. However, traces are rarely released to the public.
Researchers often use simplified mathematical models that lack the depth needed
to recreate intricate traffic patterns and, thus, miss optimization
opportunities found in realistic traffic. In this preliminary work, we
introduce DTG-GPT, a packet-level Datacenter Traffic Generator (DTG), based on
the generative pre-trained transformer (GPT) architecture used by many
state-of-the-art large language models. We train our model on a small set of
available traffic traces from different domains and offer a simple methodology
to evaluate the fidelity of the generated traces to their original
counterparts. We show that DTG-GPT can synthesize novel traces that mimic the
spatiotemporal patterns found in real traffic traces. We further demonstrate
that DTG-GPT can generate traces for networks of different scales while
maintaining fidelity. Our findings indicate the potential that, in the future,
similar models to DTG-GPT will allow datacenter operators to release traffic
information to the research community via trained GPT models.

摘要：<paragraph>如今，仰賴資料中心的應用程式快速成長，呼籲新的進展以滿足日益增加的流量和計算需求。資料中心的流量追蹤對於未來資料中心的進一步開發和最佳化至關重要。然而，追蹤很少公開發布。研究人員經常使用簡化的數學模型，而這些模型缺乏重新建立複雜流量模式所需的深度，因此錯失了在實際流量中發現的最佳化機會。在這項初步工作中，我們介紹 DTG-GPT，一種基於許多最先進的大語言模型所使用的生成式預先訓練Transformer (GPT) 架構的封包等級資料中心流量產生器 (DTG)。我們在來自不同網域的一小組可用流量追蹤上訓練我們的模型，並提供一個簡單的方法來評估所產生追蹤與其原始對應項的保真度。我們展示 DTG-GPT 可以合成新的追蹤，模擬在實際流量追蹤中發現的時空模式。我們進一步展示 DTG-GPT 可以為不同規模的網路產生追蹤，同時維持保真度。我們的發現指出，在未來，類似於 DTG-GPT 的模型將允許資料中心營運商透過訓練過的 GPT 模型向研究社群發布流量資訊。</paragraph>

##### **Reference-free Evaluation Metrics for Text Generation: A Survey**
2501.12011v1 by Takumi Ito, Kees van Deemter, Jun Suzuki

A number of automatic evaluation metrics have been proposed for natural
language generation systems. The most common approach to automatic evaluation
is the use of a reference-based metric that compares the model's output with
gold-standard references written by humans. However, it is expensive to create
such references, and for some tasks, such as response generation in dialogue,
creating references is not a simple matter. Therefore, various reference-free
metrics have been developed in recent years. In this survey, which intends to
cover the full breadth of all NLG tasks, we investigate the most commonly used
approaches, their application, and their other uses beyond evaluating models.
The survey concludes by highlighting some promising directions for future
research.

摘要：針對自然語言生成系統，已經提出許多自動評量指標。最常見的自動評量方法，是使用參考基礎指標，將模型的輸出與人類撰寫的黃金標準參考進行比較。然而，建立這些參考的成本很高，而且對於某些任務（例如對話中的回應產生），建立參考並非易事。因此，近年來已經開發出各種無參考指標。在本調查中，我們旨在涵蓋所有 NLG 任務的完整廣度，探討最常用的方法、其應用以及除了評估模型之外的其他用途。本調查最後重點說明未來研究的一些有希望的方向。

##### **Survey on Hand Gesture Recognition from Visual Input**
2501.11992v1 by Manousos Linardakis, Iraklis Varlamis, Georgios Th. Papadopoulos

Hand gesture recognition has become an important research area, driven by the
growing demand for human-computer interaction in fields such as sign language
recognition, virtual and augmented reality, and robotics. Despite the rapid
growth of the field, there are few surveys that comprehensively cover recent
research developments, available solutions, and benchmark datasets. This survey
addresses this gap by examining the latest advancements in hand gesture and 3D
hand pose recognition from various types of camera input data including RGB
images, depth images, and videos from monocular or multiview cameras, examining
the differing methodological requirements of each approach. Furthermore, an
overview of widely used datasets is provided, detailing their main
characteristics and application domains. Finally, open challenges such as
achieving robust recognition in real-world environments, handling occlusions,
ensuring generalization across diverse users, and addressing computational
efficiency for real-time applications are highlighted to guide future research
directions. By synthesizing the objectives, methodologies, and applications of
recent studies, this survey offers valuable insights into current trends,
challenges, and opportunities for future research in human hand gesture
recognition.

摘要：手勢辨識已成為一項重要的研究領域，其驅動力是各領域對人機互動的需求日益增長，例如手語辨識、虛擬實境和擴增實境，以及機器人技術。儘管該領域快速發展，但全面涵蓋近期研究發展、可用解決方案和基準資料集的調查卻很少。本調查透過檢視手勢和 3D 手部姿勢辨識的最新進展，從各種類型的相機輸入資料中進行探討，包括 RGB 影像、深度影像，以及單眼或多視角相機的影片，探討每種方法不同的方法論需求。此外，還提供了廣泛使用的資料集概觀，詳細說明其主要特徵和應用領域。最後，突顯了在現實世界環境中實現穩健辨識、處理遮擋、確保不同使用者之間的泛化，以及解決即時應用程式運算效率等開放性挑戰，以引導未來的研究方向。透過綜合近期研究的目標、方法和應用，本調查提供了寶貴的見解，了解當前趨勢、挑戰和未來手勢辨識研究的機會。

##### **Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**
2501.11977v1 by Maya Medjad, Hugo Imbert, Bruno Yun, Raphaël Szymocha, Frédéric Armetta

Training task-oriented dialogue systems is both costly and time-consuming,
due to the need for high-quality datasets encompassing diverse intents.
Traditional methods depend on extensive human annotation, while recent
advancements leverage large language models (LLMs) to generate synthetic data.
However, these approaches often require custom prompts or code, limiting
accessibility for non-technical users. We introduce GraphTOD, an end-to-end
framework that simplifies the generation of task-oriented dialogues. Users can
create dialogues by specifying transition graphs in JSON format. Our evaluation
demonstrates that GraphTOD generates high-quality dialogues across various
domains, significantly lowering the cost and complexity of dataset creation.

摘要：訓練任務導向對話系統既昂貴又耗時，
因為需要包含各種意圖的高品質資料集。
傳統方法依賴於廣泛的人工標註，而最近
的進展利用大型語言模型 (LLM) 來產生合成資料。
然而，這些方法通常需要自訂提示或程式碼，限制
非技術使用者的可及性。我們介紹 GraphTOD，一個端對端的
架構，簡化了任務導向對話的產生。使用者可以
透過指定 JSON 格式的轉換圖表來建立對話。我們的評估
證明 GraphTOD 在各種領域產生高品質對話，顯著降低資料集建立的成本和複雜性。

##### **Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**
2501.11968v1 by Jie Zhao, Kang Hao Cheong, Witold Pedrycz

Graph-structured combinatorial challenges are inherently difficult due to
their nonlinear and intricate nature, often rendering traditional computational
methods ineffective or expensive. However, these challenges can be more
naturally tackled by humans through visual representations that harness our
innate ability for spatial reasoning. In this study, we propose transforming
graphs into images to preserve their higher-order structural features
accurately, revolutionizing the representation used in solving graph-structured
combinatorial tasks. This approach allows machines to emulate human-like
processing in addressing complex combinatorial challenges. By combining the
innovative paradigm powered by multimodal large language models (MLLMs) with
simple search techniques, we aim to develop a novel and effective framework for
tackling such problems. Our investigation into MLLMs spanned a variety of
graph-based tasks, from combinatorial problems like influence maximization to
sequential decision-making in network dismantling, as well as addressing six
fundamental graph-related issues. Our findings demonstrate that MLLMs exhibit
exceptional spatial intelligence and a distinctive capability for handling
these problems, significantly advancing the potential for machines to
comprehend and analyze graph-structured data with a depth and intuition akin to
human cognition. These results also imply that integrating MLLMs with simple
optimization strategies could form a novel and efficient approach for
navigating graph-structured combinatorial challenges without complex
derivations, computationally demanding training and fine-tuning.

摘要：圖形結構的組合挑戰本質上很困難，因為它們的非線性和複雜性，通常會使傳統的計算方法無效或昂貴。然而，人類可以透過利用我們天生的空間推理能力的視覺表徵，更自然地應對這些挑戰。在本研究中，我們建議將圖形轉換為影像，以準確保留它們的高階結構特徵，從而革新用於解決圖形結構組合任務的表徵。這種方法允許機器在解決複雜的組合挑戰時模擬類人的處理。透過結合由多模態大型語言模型 (MLLM) 提供動力的創新範例與簡單的搜尋技術，我們旨在為解決此類問題開發一個新穎且有效的架構。我們對 MLLM 的研究涵蓋了各種基於圖形的任務，從組合問題（如影響力最大化）到網路拆除中的順序決策制定，以及解決六個基本的圖形相關問題。我們的研究結果表明，MLLM 表現出非凡的空間智能和處理這些問題的獨特能力，顯著提升了機器以類似人類認知的深度和直覺來理解和分析圖形結構資料的潛力。這些結果還暗示，將 MLLM 與簡單的最佳化策略整合在一起，可以形成一種新穎且有效的方法，用於在沒有複雜推導、計算需求量大的訓練和微調的情況下應對圖形結構的組合挑戰。

##### **A Hybrid Attention Framework for Fake News Detection with Large Language Models**
2501.11967v1 by Xiaochuan Xu, Peiyang Yu, Zeqiu Xu, Jiani Wang

With the rapid growth of online information, the spread of fake news has
become a serious social challenge. In this study, we propose a novel detection
framework based on Large Language Models (LLMs) to identify and classify fake
news by integrating textual statistical features and deep semantic features.
Our approach utilizes the contextual understanding capability of the large
language model for text analysis and introduces a hybrid attention mechanism to
focus on feature combinations that are particularly important for fake news
identification. Extensive experiments on the WELFake news dataset show that our
model significantly outperforms existing methods, with a 1.5\% improvement in
F1 score. In addition, we assess the interpretability of the model through
attention heat maps and SHAP values, providing actionable insights for content
review strategies. Our framework provides a scalable and efficient solution to
deal with the spread of fake news and helps build a more reliable online
information ecosystem.

摘要：隨著網路資訊的快速成長，假新聞的散播已成為嚴重的社會挑戰。本研究提出一個基於大型語言模型 (LLM) 的新穎偵測架構，透過整合文字統計特徵和深層語意特徵來辨識和分類假新聞。我們的做法利用大型語言模型在文字分析上的脈絡理解能力，並引入混合注意力機制，專注於對假新聞辨識特別重要的特徵組合。在 WELFake 新聞資料集上的廣泛實驗顯示，我們的模型明顯優於現有方法，F1 分數提升了 1.5%。此外，我們透過注意力熱圖和 SHAP 值評估模型的可解釋性，提供可行的洞察力以作為內容審查策略。我們的架構提供了一個可擴充且有效的解決方案來處理假新聞的散播，並有助於建立更可靠的網路資訊生態系統。

##### **TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection**
2501.11960v1 by Yang Cao, Sikun Yang, Chen Li, Haolong Xiang, Lianyong Qi, Bo Liu, Rongsheng Li, Ming Liu

Text anomaly detection is crucial for identifying spam, misinformation, and
offensive language in natural language processing tasks. Despite the growing
adoption of embedding-based methods, their effectiveness and generalizability
across diverse application scenarios remain under-explored. To address this, we
present TAD-Bench, a comprehensive benchmark designed to systematically
evaluate embedding-based approaches for text anomaly detection. TAD-Bench
integrates multiple datasets spanning different domains, combining
state-of-the-art embeddings from large language models with a variety of
anomaly detection algorithms. Through extensive experiments, we analyze the
interplay between embeddings and detection methods, uncovering their strengths,
weaknesses, and applicability to different tasks. These findings offer new
perspectives on building more robust, efficient, and generalizable anomaly
detection systems for real-world applications.

摘要：文本異常偵測在自然語言處理任務中對於辨識垃圾郵件、錯誤訊息和冒犯性語言至關重要。儘管基於嵌入式的方法採用率日益提高，但其在不同應用場景中的有效性和普遍性仍未得到充分探討。為了解決這個問題，我們提出了 TAD-Bench，這是一個全面的基準，旨在系統性地評估基於嵌入式的方法以進行文本異常偵測。TAD-Bench 整合了跨越不同領域的多個資料集，結合了來自大型語言模型的最新嵌入式技術和各種異常偵測演算法。透過廣泛的實驗，我們分析了嵌入式技術和偵測方法之間的交互作用，揭示了它們的優點、缺點和對不同任務的適用性。這些發現為建構更強大、更有效率和更具普遍性的異常偵測系統以應對真實世界的應用提供了新的觀點。

##### **Proverbs Run in Pairs: Evaluating Proverb Translation Capability of Large Language Model**
2501.11953v1 by Minghan Wang, Viet-Thanh Pham, Farhad Moghimifar, Thuy-Trang Vu

Despite achieving remarkable performance, machine translation (MT) research
remains underexplored in terms of translating cultural elements in languages,
such as idioms, proverbs, and colloquial expressions. This paper investigates
the capability of state-of-the-art neural machine translation (NMT) and large
language models (LLMs) in translating proverbs, which are deeply rooted in
cultural contexts. We construct a translation dataset of standalone proverbs
and proverbs in conversation for four language pairs. Our experiments show that
the studied models can achieve good translation between languages with similar
cultural backgrounds, and LLMs generally outperform NMT models in proverb
translation. Furthermore, we find that current automatic evaluation metrics
such as BLEU, CHRF++ and COMET are inadequate for reliably assessing the
quality of proverb translation, highlighting the need for more culturally aware
evaluation metrics.

摘要：儘管機器翻譯 (MT) 研究已取得顯著的成效，但在翻譯語言中的文化元素，例如成語、諺語和口語表達方面仍未充分探討。本文探討了最先進的神經機器翻譯 (NMT) 和大型語言模型 (LLM) 在翻譯諺語方面的能力，而諺語深深植根於文化背景中。我們建構了一個包含四種語言對的獨立諺語和對話中諺語的翻譯資料集。我們的實驗表明，所研究的模型可以在文化背景相似的語言之間實現良好的翻譯，而 LLM 通常在諺語翻譯中優於 NMT 模型。此外，我們發現目前的自動評估指標，例如 BLEU、CHRF++ 和 COMET，不足以可靠地評估諺語翻譯的品質，這突顯了對更具文化意識的評估指標的需求。

##### **HERITAGE: An End-to-End Web Platform for Processing Korean Historical Documents in Hanja**
2501.11951v1 by Seyoung Song, Haneul Yoo, Jiho Jin, Kyunghyun Cho, Alice Oh

While Korean historical documents are invaluable cultural heritage,
understanding those documents requires in-depth Hanja expertise. Hanja is an
ancient language used in Korea before the 20th century, whose characters were
borrowed from old Chinese but had evolved in Korea for centuries. Modern
Koreans and Chinese cannot understand Korean historical documents without
substantial additional help, and while previous efforts have produced some
Korean and English translations, this requires in-depth expertise, and so most
of the documents are not translated into any modern language. To address this
gap, we present HERITAGE, the first open-source Hanja NLP toolkit to assist in
understanding and translating the unexplored Korean historical documents
written in Hanja. HERITAGE is a web-based platform providing model predictions
of three critical tasks in historical document understanding via Hanja language
models: punctuation restoration, named entity recognition, and machine
translation (MT). HERITAGE also provides an interactive glossary, which
provides the character-level reading of the Hanja characters in modern Korean,
as well as character-level English definition. HERITAGE serves two purposes.
First, anyone interested in these documents can get a general understanding
from the model predictions and the interactive glossary, especially MT outputs
in Korean and English. Second, since the model outputs are not perfect, Hanja
experts can revise them to produce better annotations and translations. This
would boost the translation efficiency and potentially lead to most of the
historical documents being translated into modern languages, lowering the
barrier on unexplored Korean historical documents.

摘要：<paragraph>儘管韓國歷史文件是無價的文化遺產，但要理解這些文件需要深入的漢字專業知識。漢字是一種在 20 世紀前於韓國使用的古代語言，其字元取自古漢語，但在韓國演變了數百年。現代韓國人和中國人無法在沒有大量額外幫助的情況下理解韓國歷史文件，儘管先前的努力產生了一些韓語和英語翻譯，但這需要深入的專業知識，因此大多數文件並未翻譯成任何現代語言。為了解決這個差距，我們提出了 HERITAGE，這是第一個開源漢字 NLP 工具包，用於協助理解和翻譯未探索的以漢字書寫的韓國歷史文件。HERITAGE 是基於網路的平台，透過漢字語言模型提供歷史文件理解中三個關鍵任務的模型預測：標點符號還原、命名實體辨識和機器翻譯 (MT)。HERITAGE 還提供互動式詞彙表，提供漢字字元在現代韓語中的字元級讀音，以及字元級英語定義。HERITAGE 有兩個目的。首先，任何對這些文件感興趣的人都可以從模型預測和互動式詞彙表中獲得一般性的理解，特別是韓語和英語中的 MT 輸出。其次，由於模型輸出並非完美，漢字專家可以修改它們以產生更好的註釋和翻譯。這將提高翻譯效率，並可能導致大多數歷史文件被翻譯成現代語言，降低未探索的韓國歷史文件的門檻。</paragraph>

##### **Webvs. LLMs: An Empirical Study of Learning Behaviors of CS2 Students**
2501.11935v1 by Aayush Kumar, Daniel Prol, Amin Alipour, Sruti Srinivasa Ragavan

LLMs such as ChatGPT have been widely adopted by students in higher education
as tools for learning programming and related concepts. However, it remains
unclear how effective students are and what strategies students use while
learning with LLMs. Since the majority of students' experiences in online
self-learning have come through using search engines such as Google, evaluating
AI tools in this context can help us address these gaps. In this mixed methods
research, we conducted an exploratory within-subjects study to understand how
CS2 students learn programming concepts using both LLMs as well as traditional
online methods such as educational websites and videos to examine how students
approach learning within and across both scenarios. We discovered that students
found it easier to learn a more difficult concept using traditional methods
than using ChatGPT. We also found that students ask fewer follow-ups and use
more keyword-based queries for search engines while their prompts to LLMs tend
to explicitly ask for information.

摘要：大型語言模型（LLM）例如 ChatGPT 已被高等教育中的學生廣泛採用，作為學習程式設計和相關概念的工具。然而，學生使用 LLM 的成效如何以及使用的策略為何仍不清楚。由於大多數學生在線上自學的經驗都來自使用 Google 等搜尋引擎，因此在此脈絡中評估 AI 工具有助於我們解決這些差距。在此混合方法研究中，我們進行了一項探索性的受試者內研究，以了解 CS2 學生如何使用 LLM 和傳統線上方法（例如教育網站和影片）學習程式設計概念，以探討學生如何在兩種情境中和跨情境學習。我們發現學生使用傳統方法學習較困難的概念比使用 ChatGPT 容易。我們還發現學生在使用搜尋引擎時會提出較少的追蹤問題，並使用更多基於關鍵字的查詢，而他們對 LLM 的提示則傾向於明確要求提供資訊。

##### **A Lightweight and Interpretable Deepfakes Detection Framework**
2501.11927v1 by Muhammad Umar Farooq, Ali Javed, Khalid Mahmood Malik, Muhammad Anas Raza

The recent realistic creation and dissemination of so-called deepfakes poses
a serious threat to social life, civil rest, and law. Celebrity defaming,
election manipulation, and deepfakes as evidence in court of law are few
potential consequences of deepfakes. The availability of open source trained
models based on modern frameworks such as PyTorch or TensorFlow, video
manipulations Apps such as FaceApp and REFACE, and economical computing
infrastructure has easen the creation of deepfakes. Most of the existing
detectors focus on detecting either face-swap, lip-sync, or puppet master
deepfakes, but a unified framework to detect all three types of deepfakes is
hardly explored. This paper presents a unified framework that exploits the
power of proposed feature fusion of hybrid facial landmarks and our novel heart
rate features for detection of all types of deepfakes. We propose novel heart
rate features and fused them with the facial landmark features to better
extract the facial artifacts of fake videos and natural variations available in
the original videos. We used these features to train a light-weight XGBoost to
classify between the deepfake and bonafide videos. We evaluated the performance
of our framework on the world leaders dataset (WLDR) that contains all types of
deepfakes. Experimental results illustrate that the proposed framework offers
superior detection performance over the comparative deepfakes detection
methods. Performance comparison of our framework against the LSTM-FCN, a
candidate of deep learning model, shows that proposed model achieves similar
results, however, it is more interpretable.

摘要：最近所谓的深度伪造的逼真创作和传播对社会生活、公民安宁和法律构成了严重威胁。名人诽谤、选举操纵和在法庭上将深度伪造作为证据只是深度伪造的少数潜在后果。基于 PyTorch 或 TensorFlow 等现代框架的开源训练模型、FaceApp 和 REFACE 等视频处理应用程序以及经济的计算基础设施已经简化了深度伪造的创建。大多数现有的检测器专注于检测换脸、唇形同步或傀儡大师深度伪造，但几乎没有探索到一个用于检测所有这三种类型深度伪造的统一框架。本文提出了一个统一的框架，该框架利用了混合面部特征和我们新颖的心率特征的特征融合功能来检测所有类型的深度伪造。我们提出了新颖的心率特征，并将它们与面部特征融合，以更好地提取假视频的面部伪像和原始视频中存在的自然变化。我们使用这些特征来训练轻量级的 XGBoost，以对深度伪造视频和真实视频进行分类。我们在包含所有类型深度伪造的世界领导人数据集 (WLDR) 上评估了我们框架的性能。实验结果表明，与比较深度伪造检测方法相比，所提出的框架提供了卓越的检测性能。我们框架与 LSTM-FCN（深度学习模型的候选者）的性能比较表明，所提出的模型取得了类似的结果，然而，它更具可解释性。

##### **LuxVeri at GenAI Detection Task 3: Cross-Domain Detection of AI-Generated Text Using Inverse Perplexity-Weighted Ensemble of Fine-Tuned Transformer Models**
2501.11918v1 by Md Kamrujjaman Mobin, Md Saiful Islam

This paper presents our approach for Task 3 of the GenAI content detection
workshop at COLING-2025, focusing on Cross-Domain Machine-Generated Text (MGT)
Detection. We propose an ensemble of fine-tuned transformer models, enhanced by
inverse perplexity weighting, to improve classification accuracy across diverse
text domains. For Subtask A (Non-Adversarial MGT Detection), we combined a
fine-tuned RoBERTa-base model with an OpenAI detector-integrated RoBERTa-base
model, achieving an aggregate TPR score of 0.826, ranking 10th out of 23
detectors. In Subtask B (Adversarial MGT Detection), our fine-tuned
RoBERTa-base model achieved a TPR score of 0.801, securing 8th out of 22
detectors. Our results demonstrate the effectiveness of inverse
perplexity-based weighting for enhancing generalization and performance in both
non-adversarial and adversarial MGT detection, highlighting the potential for
transformer models in cross-domain AI-generated content detection.

摘要：本文介紹我們對 COLING-2025 GenAI 內容偵測工作坊任務 3 的方法，重點在於跨領域機器產生的文字 (MGT) 偵測。我們提出一個經過微調的轉換器模型集合，並透過反對數困惑度加權來強化，以提升不同文字領域的分類準確度。對於子任務 A（非對抗性 MGT 偵測），我們將經過微調的 RoBERTa-base 模型與整合 OpenAI 偵測器的 RoBERTa-base 模型結合，達到 0.826 的總體 TPR 分數，在 23 個偵測器中排名第 10。在子任務 B（對抗性 MGT 偵測）中，我們經過微調的 RoBERTa-base 模型達到 0.801 的 TPR 分數，在 22 個偵測器中排名第 8。我們的結果證明了基於反對數困惑度的加權在非對抗性和對抗性 MGT 偵測中，對於強化概化和效能是有幫助的，突顯了轉換器模型在跨領域 AI 生成的內容偵測中的潛力。

##### **LuxVeri at GenAI Detection Task 1: Inverse Perplexity Weighted Ensemble for Robust Detection of AI-Generated Text across English and Multilingual Contexts**
2501.11914v1 by Md Kamrujjaman Mobin, Md Saiful Islam

This paper presents a system developed for Task 1 of the COLING 2025 Workshop
on Detecting AI-Generated Content, focusing on the binary classification of
machine-generated versus human-written text. Our approach utilizes an ensemble
of models, with weights assigned according to each model's inverse perplexity,
to enhance classification accuracy. For the English text detection task, we
combined RoBERTa-base, RoBERTa-base with the OpenAI detector, and
BERT-base-cased, achieving a Macro F1-score of 0.7458, which ranked us 12th out
of 35 teams. We ensembled RemBERT, XLM-RoBERTa-base, and
BERT-base-multilingual-case for the multilingual text detection task, employing
the same inverse perplexity weighting technique. This resulted in a Macro
F1-score of 0.7513, positioning us 4th out of 25 teams. Our results demonstrate
the effectiveness of inverse perplexity weighting in improving the robustness
of machine-generated text detection across both monolingual and multilingual
settings, highlighting the potential of ensemble methods for this challenging
task.

摘要：這篇論文提出了一個系統，該系統是為 COLING 2025 工作坊的任務 1 開發的，重點在於機器產生的內容與人類撰寫的文字之間的二元分類。我們的做法利用模型集合，並根據每個模型的反對數分配權重，以提高分類準確度。對於英文文本偵測任務，我們結合了 RoBERTa-base、搭載 OpenAI 偵測器的 RoBERTa-base，以及 BERT-base-cased，達到了 0.7458 的巨觀 F1 分數，在 35 個團隊中排名第 12。我們將 RemBERT、XLM-RoBERTa-base，以及 BERT-base-multilingual-case 組合起來，用於多語言文本偵測任務，並採用相同的反對數權重技術。這產生了 0.7513 的巨觀 F1 分數，使我們在 25 個團隊中排名第 4。我們的結果證明了反對數權重在提高機器產生的文本偵測的穩健性方面的有效性，無論是在單語系還是多語系的設定中，都突顯了集合方法在這個具有挑戰性的任務中的潛力。

##### **Bridging the Communication Gap: Evaluating AI Labeling Practices for Trustworthy AI Development**
2501.11909v1 by Raphael Fischer, Magdalena Wischnewski, Alexander van der Staay, Katharina Poitz, Christian Janiesch, Thomas Liebig

As artificial intelligence (AI) becomes integral to economy and society,
communication gaps between developers, users, and stakeholders hinder trust and
informed decision-making. High-level AI labels, inspired by frameworks like EU
energy labels, have been proposed to make the properties of AI models more
transparent. Without requiring deep technical expertise, they can inform on the
trade-off between predictive performance and resource efficiency. However, the
practical benefits and limitations of AI labeling remain underexplored. This
study evaluates AI labeling through qualitative interviews along four key
research questions. Based on thematic analysis and inductive coding, we found a
broad range of practitioners to be interested in AI labeling (RQ1). They see
benefits for alleviating communication gaps and aiding non-expert
decision-makers, however limitations, misunderstandings, and suggestions for
improvement were also discussed (RQ2). Compared to other reporting formats,
interviewees positively evaluated the reduced complexity of labels, increasing
overall comprehensibility (RQ3). Trust was influenced most by usability and the
credibility of the responsible labeling authority, with mixed preferences for
self-certification versus third-party certification (RQ4). Our Insights
highlight that AI labels pose a trade-off between simplicity and complexity,
which could be resolved by developing customizable and interactive labeling
frameworks to address diverse user needs. Transparent labeling of resource
efficiency also nudged interviewee priorities towards paying more attention to
sustainability aspects during AI development. This study validates AI labels as
a valuable tool for enhancing trust and communication in AI, offering
actionable guidelines for their refinement and standardization.

摘要：<paragraph>随着人工智能 (AI) 逐渐成为经济与社会中不可或缺的一部分，开发人员、使用者和利益相关者之间的沟通鸿沟阻碍了信任和明智的决策。受欧盟能源标签等框架启发的 AI 高级标签已被提出，以使 AI 模型的属性更加透明。在无需深入技术专业知识的情况下，它们可以告知预测性能和资源效率之间的权衡取舍。然而，AI 标签的实际好处和局限性仍未得到充分探索。本研究通过定性访谈评估了 AI 标签，涉及四个关键的研究问题。基于主题分析和归纳编码，我们发现广泛的从业者对 AI 标签感兴趣 (RQ1)。他们看到了缓解沟通鸿沟和帮助非专家决策者的好处，但局限性、误解和改进建议也进行了讨论 (RQ2)。与其他报告格式相比，受访者对标签复杂性的降低和整体可理解性的提高给予了积极评价 (RQ3)。信任最受可用性和负责标签机构的可信度的影响，对于自我认证与第三方认证有不同的偏好 (RQ4)。我们的见解强调，AI 标签在简单性和复杂性之间存在权衡，可以通过开发可定制和交互式的标签框架来解决不同的用户需求。资源效率的透明标签也促使受访者的优先事项在 AI 开发过程中更加关注可持续性方面。本研究验证了 AI 标签作为增强 AI 中信任和沟通的宝贵工具，为其完善和标准化提供了可行的指导方针。</paragraph>

##### **Panoramic Interests: Stylistic-Content Aware Personalized Headline Generation**
2501.11900v1 by Junhong Lian, Xiang Ao, Xinyu Liu, Yang Liu, Qing He

Personalized news headline generation aims to provide users with
attention-grabbing headlines that are tailored to their preferences. Prevailing
methods focus on user-oriented content preferences, but most of them overlook
the fact that diverse stylistic preferences are integral to users' panoramic
interests, leading to suboptimal personalization. In view of this, we propose a
novel Stylistic-Content Aware Personalized Headline Generation (SCAPE)
framework. SCAPE extracts both content and stylistic features from headlines
with the aid of large language model (LLM) collaboration. It further adaptively
integrates users' long- and short-term interests through a contrastive
learning-based hierarchical fusion network. By incorporating the panoramic
interests into the headline generator, SCAPE reflects users' stylistic-content
preferences during the generation process. Extensive experiments on the
real-world dataset PENS demonstrate the superiority of SCAPE over baselines.

摘要：個人化新聞標題生成旨在為使用者提供吸引眼球、且符合其偏好的標題。現行的做法著重於以使用者為導向的內容偏好，但大多數的做法忽略了多樣化的風格偏好與使用者全景式興趣密不可分的這個事實，導致次佳的個人化結果。有鑑於此，我們提出一個新穎的風格內容感知個人化標題生成 (SCAPE) 架構。SCAPE 在大型語言模型 (LLM) 協作的協助下，從標題中提取內容和風格特徵。它進一步透過對比學習基礎的分層融合網路，自適應地整合使用者的長期和短期興趣。SCAPE 透過將全景式興趣納入標題產生器，在生成過程中反映使用者的風格內容偏好。在真實世界資料集 PENS 上的廣泛實驗證明了 SCAPE 優於基線。

##### **Systematic Abductive Reasoning via Diverse Relation Representations in Vector-symbolic Architecture**
2501.11896v1 by Zhong-Hua Sun, Ru-Yuan Zhang, Zonglei Zhen, Da-Hui Wang, Yong-Jie Li, Xiaohong Wan, Hongzhi You

In abstract visual reasoning, monolithic deep learning models suffer from
limited interpretability and generalization, while existing neuro-symbolic
approaches fall short in capturing the diversity and systematicity of
attributes and relation representations. To address these challenges, we
propose a Systematic Abductive Reasoning model with diverse relation
representations (Rel-SAR) in Vector-symbolic Architecture (VSA) to solve
Raven's Progressive Matrices (RPM). To derive attribute representations with
symbolic reasoning potential, we introduce not only various types of atomic
vectors that represent numeric, periodic and logical semantics, but also the
structured high-dimentional representation (SHDR) for the overall Grid
component. For systematic reasoning, we propose novel numerical and logical
relation functions and perform rule abduction and execution in a unified
framework that integrates these relation representations. Experimental results
demonstrate that Rel-SAR achieves significant improvement on RPM tasks and
exhibits robust out-of-distribution generalization. Rel-SAR leverages the
synergy between HD attribute representations and symbolic reasoning to achieve
systematic abductive reasoning with both interpretable and computable
semantics.

摘要：在抽象视觉推理中，单一深度学习模型在可解释性和泛化能力方面存在不足，而现有的神经符号方法在捕捉属性和关系表示的多样性和系统性方面存在不足。为了应对这些挑战，我们在矢量符号架构 (VSA) 中提出了一种具有不同关系表示的系统演绎推理模型 (Rel-SAR)，以解决雷文渐进矩阵 (RPM)。为了推导出具有符号推理潜力的属性表示，我们不仅引入了表示数字、周期性和逻辑语义的各种类型的原子向量，还引入了整体网格组件的结构化高维表示 (SHDR)。对于系统推理，我们提出了新的数值和逻辑关系函数，并在统一的框架中执行规则归纳和执行，该框架集成了这些关系表示。实验结果表明，Rel-SAR 在 RPM 任务上取得了显着改进，并表现出稳健的分布外泛化能力。Rel-SAR 利用高清属性表示和符号推理之间的协同作用，实现了可解释和可计算语义的系统演绎推理。

##### **Med-R$^2$: Crafting Trustworthy LLM Physicians through Retrieval and Reasoning of Evidence-Based Medicine**
2501.11885v1 by Keer Lu, Zheng Liang, Da Pan, Shusen Zhang, Xin Wu, Weipeng Chen, Zenan Zhou, Guosheng Dong, Bin Cui, Wentao Zhang

In recent years, Large Language Models (LLMs) have exhibited remarkable
capabilities in clinical scenarios. However, despite their potential, existing
works face challenges when applying LLMs to medical settings. Strategies
relying on training with medical datasets are highly cost-intensive and may
suffer from outdated training data. Leveraging external knowledge bases is a
suitable alternative, yet it faces obstacles such as limited retrieval
precision and poor effectiveness in answer extraction. These issues
collectively prevent LLMs from demonstrating the expected level of proficiency
in mastering medical expertise. To address these challenges, we introduce
Med-R^2, a novel LLM physician framework that adheres to the Evidence-Based
Medicine (EBM) process, efficiently integrating retrieval mechanisms as well as
the selection and reasoning processes of evidence, thereby enhancing the
problem-solving capabilities of LLMs in healthcare scenarios and fostering a
trustworthy LLM physician. Our comprehensive experiments indicate that Med-R^2
achieves a 14.87\% improvement over vanilla RAG methods and even a 3.59\%
enhancement compared to fine-tuning strategies, without incurring additional
training costs.

摘要：近年来，大语言模型 (LLM) 在临床场景中展现出了非凡的能力。然而，尽管它们具有潜力，但现有工作在将 LLM 应用于医疗环境时面临挑战。依赖于医学数据集进行训练的策略成本非常高，并且可能会因训练数据过时而受到影响。利用外部知识库是一个合适的替代方案，但它面临着诸如检索精度有限和答案提取效果差等障碍。这些问题共同阻止了 LLM 在掌握医学专业知识方面表现出预期的熟练程度。为了应对这些挑战，我们引入了 Med-R^2，这是一个新颖的 LLM 医生框架，它遵循循证医学 (EBM) 流程，有效地集成了检索机制以及证据的选择和推理过程，从而增强了 LLM 在医疗保健场景中的问题解决能力并培养了一个值得信赖的 LLM 医生。我们的综合实验表明，Med-R^2 比香草 RAG 方法提高了 14.87%，甚至比微调策略提高了 3.59%，而没有产生额外的培训成本。

##### **Community-Aware Temporal Walks: Parameter-Free Representation Learning on Continuous-Time Dynamic Graphs**
2501.11880v1 by He Yu, Jing Liu

Dynamic graph representation learning plays a crucial role in understanding
evolving behaviors. However, existing methods often struggle with flexibility,
adaptability, and the preservation of temporal and structural dynamics. To
address these issues, we propose Community-aware Temporal Walks (CTWalks), a
novel framework for representation learning on continuous-time dynamic graphs.
CTWalks integrates three key components: a community-based parameter-free
temporal walk sampling mechanism, an anonymization strategy enriched with
community labels, and an encoding process that leverages continuous temporal
dynamics modeled via ordinary differential equations (ODEs). This design
enables precise modeling of both intra- and inter-community interactions,
offering a fine-grained representation of evolving temporal patterns in
continuous-time dynamic graphs. CTWalks theoretically overcomes locality bias
in walks and establishes its connection to matrix factorization. Experiments on
benchmark datasets demonstrate that CTWalks outperforms established methods in
temporal link prediction tasks, achieving higher accuracy while maintaining
robustness.

摘要：動態圖形表徵學習在理解演化行為扮演至關重要的角色。然而，現有方法通常在靈活性、適應性和時間和結構動態的保存上遇到困難。為了解決這些問題，我們提出社群感知時間漫步 (CTWalks)，一種針對連續時間動態圖形進行表徵學習的新穎架構。CTWalks 整合了三個關鍵組成部分：基於社群的無參數時間漫步取樣機制、豐富社群標籤的匿名化策略，以及利用透過常微分方程式 (ODE) 建模的連續時間動態的編碼流程。此設計能精確建模社群內部和社群之間的互動，提供連續時間動態圖形中演化時間模式的細緻表徵。CTWalks 在理論上克服了漫步中的局部偏誤，並建立與矩陣分解的關聯。基準資料集上的實驗證明，CTWalks 在時間連結預測任務中優於既有方法，在維持穩健性的同時達成更高的準確度。

##### **From Drafts to Answers: Unlocking LLM Potential via Aggregation Fine-Tuning**
2501.11877v1 by Yafu Li, Zhilin Wang, Tingchen Fu, Ganqu Cui, Sen Yang, Yu Cheng

Scaling data and model size has been proven effective for boosting the
performance of large language models. In addition to training-time scaling,
recent studies have revealed that increasing test-time computational resources
can further improve performance. In this work, we introduce Aggregation
Fine-Tuning (AFT), a supervised finetuning paradigm where the model learns to
synthesize multiple draft responses, referred to as proposals, into a single,
refined answer, termed aggregation. At inference time, a propose-and-aggregate
strategy further boosts performance by iteratively generating proposals and
aggregating them. Empirical evaluations on benchmark datasets show that
AFT-trained models substantially outperform standard SFT. Notably, an AFT
model, fine-tuned from Llama3.1-8B-Base with only 64k data, achieves a 41.3% LC
win rate on AlpacaEval 2, surpassing significantly larger LLMs such as
Llama3.1-405B-Instruct and GPT4. By combining sequential refinement and
parallel sampling, the propose-and-aggregate framework scales inference-time
computation in a flexible manner. Overall, These findings position AFT as a
promising approach to unlocking additional capabilities of LLMs without
resorting to increasing data volume or model size.

摘要：擴展資料和模型大小已被證明能有效提升大型語言模型的效能。除了訓練時間的擴展，最近的研究顯示，增加測試時間的運算資源能進一步提升效能。在這項工作中，我們引入了聚合微調 (AFT)，一種監督式微調範例，其中模型學習將多個草稿回應（稱為提案）合成為一個單一的精緻答案，稱為聚合。在推論時間，一種提出和聚合策略通過反覆生成提案並將它們聚合起來進一步提升效能。基準資料集上的經驗評估顯示，AFT 訓練的模型明顯優於標準 SFT。值得注意的是，一個 AFT 模型，僅使用 64k 資料從 Llama3.1-8B-Base 微調，在 AlpacaEval 2 上實現了 41.3% 的 LC 勝率，超過了顯著更大的 LLM，例如 Llama3.1-405B-Instruct 和 GPT4。通過結合順序精煉和並行採樣，提出和聚合框架以靈活的方式擴展了推論時間的運算。總體而言，這些發現將 AFT 定位為一種有希望的方法，可以在不增加資料量或模型大小的情況下釋放 LLM 的額外功能。

##### **Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models**
2501.11873v1 by Zihan Qiu, Zeyu Huang, Bo Zheng, Kaiyue Wen, Zekun Wang, Rui Men, Ivan Titov, Dayiheng Liu, Jingren Zhou, Junyang Lin

This paper revisits the implementation of
$\textbf{L}$oad-$\textbf{b}$alancing $\textbf{L}$oss (LBL) when training
Mixture-of-Experts (MoEs) models. Specifically, LBL for MoEs is defined as $N_E
\sum_{i=1}^{N_E} f_i p_i$, where $N_E$ is the total number of experts, $f_i$
represents the frequency of expert $i$ being selected, and $p_i$ denotes the
average gating score of the expert $i$. Existing MoE training frameworks
usually employ the parallel training strategy so that $f_i$ and the LBL are
calculated within a $\textbf{micro-batch}$ and then averaged across parallel
groups. In essence, a micro-batch for training billion-scale LLMs normally
contains very few sequences. So, the micro-batch LBL is almost at the sequence
level, and the router is pushed to distribute the token evenly within each
sequence. Under this strict constraint, even tokens from a domain-specific
sequence ($\textit{e.g.}$, code) are uniformly routed to all experts, thereby
inhibiting expert specialization. In this work, we propose calculating LBL
using a $\textbf{global-batch}$ to loose this constraint. Because a
global-batch contains much more diverse sequences than a micro-batch, which
will encourage load balance at the corpus level. Specifically, we introduce an
extra communication step to synchronize $f_i$ across micro-batches and then use
it to calculate the LBL. Through experiments on training MoEs-based LLMs (up to
$\textbf{42.8B}$ total parameters and $\textbf{400B}$ tokens), we surprisingly
find that the global-batch LBL strategy yields excellent performance gains in
both pre-training perplexity and downstream tasks. Our analysis reveals that
the global-batch LBL also greatly improves the domain specialization of MoE
experts.

摘要：<paragraph>本文重新探討了在訓練 Mixture-of-Experts (MoEs) 模型時，$\textbf{L}$oad-$\textbf{b}$alancing $\textbf{L}$oss (LBL) 的實作。具體來說，MoEs 的 LBL 被定義為 $N_E \sum_{i=1}^{N_E} f_i p_i$，其中 $N_E$ 是專家的總數，$f_i$ 表示選擇專家 $i$ 的頻率，而 $p_i$ 表示專家 $i$ 的平均閘控分數。現有的 MoE 訓練架構通常採用並行訓練策略，以便在 $\textbf{微批次}$ 中計算 $f_i$ 和 LBL，然後在並行群組中取平均值。實質上，訓練十億規模 LLM 的微批次通常只包含很少的序列。因此，微批次 LBL 幾乎處於序列層級，而路由器被迫在每個序列中均勻分配令牌。在這個嚴格的約束下，即使來自特定領域序列（$\textit{e.g.}$，程式碼）的令牌也會均勻路由到所有專家，從而抑制專家專業化。在這項工作中，我們提出使用 $\textbf{全域批次}$ 計算 LBL 以解除這個約束。由於全域批次包含比微批次更多樣化的序列，這將促進語料層級的負載平衡。具體來說，我們引入一個額外的通訊步驟，以在微批次之間同步 $f_i$，然後使用它來計算 LBL。透過對基於 MoE 的 LLM（總參數量高達 $\textbf{42.8B}$，令牌達 $\textbf{400B}$）的訓練進行實驗，我們驚訝地發現，全域批次 LBL 策略在預訓練困惑度和下游任務中都產生了極佳的效能提升。我們的分析表明，全域批次 LBL 也大幅提升了 MoE 專家的領域專業化。</paragraph>

##### **EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents**
2501.11858v1 by Zhili Cheng, Yuge Tu, Ran Li, Shiqi Dai, Jinyi Hu, Shengding Hu, Jiahao Li, Yang Shi, Tianyu Yu, Weize Chen, Lei Shi, Maosong Sun

Multimodal Large Language Models (MLLMs) have shown significant advancements,
providing a promising future for embodied agents. Existing benchmarks for
evaluating MLLMs primarily utilize static images or videos, limiting
assessments to non-interactive scenarios. Meanwhile, existing embodied AI
benchmarks are task-specific and not diverse enough, which do not adequately
evaluate the embodied capabilities of MLLMs. To address this, we propose
EmbodiedEval, a comprehensive and interactive evaluation benchmark for MLLMs
with embodied tasks. EmbodiedEval features 328 distinct tasks within 125 varied
3D scenes, each of which is rigorously selected and annotated. It covers a
broad spectrum of existing embodied AI tasks with significantly enhanced
diversity, all within a unified simulation and evaluation framework tailored
for MLLMs. The tasks are organized into five categories: navigation, object
interaction, social interaction, attribute question answering, and spatial
question answering to assess different capabilities of the agents. We evaluated
the state-of-the-art MLLMs on EmbodiedEval and found that they have a
significant shortfall compared to human level on embodied tasks. Our analysis
demonstrates the limitations of existing MLLMs in embodied capabilities,
providing insights for their future development. We open-source all evaluation
data and simulation framework at https://github.com/thunlp/EmbodiedEval.

摘要：多模态大型语言模型 (MMLM) 已展示出显著的进步，为具身代理提供了一个有希望的未来。用于评估 MMLM 的现有基准主要利用静态图像或视频，将评估限制在非交互式场景中。同时，现有的具身 AI 基准是特定于任务的，并且不够多样化，无法充分评估 MLLM 的具身能力。为了解决这个问题，我们提出了 EmbodiedEval，一个针对具有具身任务的 MLLM 的全面且交互式的评估基准。EmbodiedEval 在 125 个不同的 3D 场景中提供了 328 个不同的任务，每个任务都经过严格的挑选和注释。它涵盖了现有的具身 AI 任务的广泛范围，并显著提高了多样性，所有这些都在一个统一的模拟和评估框架中，该框架专为 MLLM 量身定制。这些任务被组织成五个类别：导航、对象交互、社交交互、属性问题解答和空间问题解答，以评估代理的不同能力。我们评估了 EmbodiedEval 上最先进的 MLLM，发现与人类在具身任务上的水平相比，它们有很大的不足。我们的分析展示了现有 MLLM 在具身能力方面的局限性，为其未来的发展提供了见解。我们在 https://github.com/thunlp/EmbodiedEval 上开源了所有评估数据和模拟框架。

##### **Cross-Entropy Attacks to Language Models via Rare Event Simulation**
2501.11852v1 by Mingze Ni, Yongshun Gong, Wei Liu

Black-box textual adversarial attacks are challenging due to the lack of
model information and the discrete, non-differentiable nature of text. Existing
methods often lack versatility for attacking different models, suffer from
limited attacking performance due to the inefficient optimization with word
saliency ranking, and frequently sacrifice semantic integrity to achieve better
attack outcomes. This paper introduces a novel approach to textual adversarial
attacks, which we call Cross-Entropy Attacks (CEA), that uses Cross-Entropy
optimization to address the above issues. Our CEA approach defines adversarial
objectives for both soft-label and hard-label settings and employs CE
optimization to identify optimal replacements. Through extensive experiments on
document classification and language translation problems, we demonstrate that
our attack method excels in terms of attacking performance, imperceptibility,
and sentence quality.

摘要：黑盒文本对抗攻擊由於缺乏模型資訊以及文字的離散、不可微分的特性，因此具有挑戰性。現有方法通常缺乏攻擊不同模型的多功能性，由於使用字詞顯著性排名而導致攻擊效能有限，且經常犧牲語意完整性以達成更好的攻擊結果。本文提出了一種新的文本對抗攻擊方法，我們稱之為交叉熵攻擊 (CEA)，它使用交叉熵最佳化來解決上述問題。我們的 CEA 方法定義了軟標籤和硬標籤設定的對抗目標，並採用 CE 最佳化來識別最佳替換。透過文件分類和語言翻譯問題的廣泛實驗，我們證明我們的攻擊方法在攻擊效能、難以察覺性和句子品質方面表現優異。

##### **Challenges in Expanding Portuguese Resources: A View from Open Information Extraction**
2501.11851v1 by Marlo Souza, Bruno Cabral, Daniela Claro, Lais Salvador

Open Information Extraction (Open IE) is the task of extracting structured
information from textual documents, independent of domain. While traditional
Open IE methods were based on unsupervised approaches, recently, with the
emergence of robust annotated datasets, new data-based approaches have been
developed to achieve better results. These innovations, however, have focused
mainly on the English language due to a lack of datasets and the difficulty of
constructing such resources for other languages. In this work, we present a
high-quality manually annotated corpus for Open Information Extraction in the
Portuguese language, based on a rigorous methodology grounded in established
semantic theories. We discuss the challenges encountered in the annotation
process, propose a set of structural and contextual annotation rules, and
validate our corpus by evaluating the performance of state-of-the-art Open IE
systems. Our resource addresses the lack of datasets for Open IE in Portuguese
and can support the development and evaluation of new methods and systems in
this area.

摘要：開放式資訊萃取（Open IE）是一項從文本文件中萃取出結構化資訊的任務，與領域無關。雖然傳統的開放式資訊萃取方法是基於非監督式方法，但最近，隨著強健標註資料集的出現，新的資料驅動方法已被開發出來以獲得更好的結果。然而，這些創新主要集中在英語上，因為缺乏資料集和建構此類資源的困難性。在這項工作中，我們提出了一個基於嚴謹方法學（根植於已建立的語義理論）的高品質手動標註語料庫，用於葡萄牙語的開放式資訊萃取。我們討論標註過程中遇到的挑戰，提出了一組結構化和脈絡標註規則，並透過評估最先進的開放式資訊萃取系統的效能來驗證我們的語料庫。我們的資源解決了葡萄牙語開放式資訊萃取缺乏資料集的問題，並可以支援此領域中新方法和系統的開發和評估。

##### **Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**
2501.11849v1 by Nikos Kanakaris, Heng Ping, Xiongye Xiao, Nesreen K. Ahmed, Luca Luceri, Emilio Ferrara, Paul Bogdan

Detecting organized political campaigns is of paramount importance in
fighting against disinformation on social media. Existing approaches for the
identification of such organized actions employ techniques mostly from network
science, graph machine learning and natural language processing. Their ultimate
goal is to analyze the relationships and interactions (e.g. re-posting) among
users and the textual similarities of their posts. Despite their effectiveness
in recognizing astroturf campaigns, these methods face significant challenges,
notably the class imbalance in available training datasets. To mitigate this
issue, recent methods usually resort to data augmentation or increasing the
number of positive samples, which may not always be feasible or sufficient in
real-world settings. Following a different path, in this paper, we propose a
novel framework for identifying astroturf campaigns based solely on large
language models (LLMs), introducing a Balanced Retrieval-Augmented Generation
(Balanced RAG) component. Our approach first gives both textual information
concerning the posts (in our case tweets) and the user interactions of the
social network as input to a language model. Then, through prompt engineering
and the proposed Balanced RAG method, it effectively detects coordinated
disinformation campaigns on X (Twitter). The proposed framework does not
require any training or fine-tuning of the language model. Instead, by
strategically harnessing the strengths of prompt engineering and Balanced RAG,
it facilitates LLMs to overcome the effects of class imbalance and effectively
identify coordinated political campaigns. The experimental results demonstrate
that by incorporating the proposed prompt engineering and Balanced RAG methods,
our framework outperforms the traditional graph-based baselines, achieving
2x-3x improvements in terms of precision, recall and F1 scores.

摘要：<paragraph>在社交媒體上打擊錯誤資訊，偵測有組織的政治宣傳至關重要。現有的此類有組織行動識別方法，主要採用網路科學、圖形機器學習和自然語言處理的技術。其最終目標是分析使用者之間的關係和互動（例如轉發），以及其貼文的文字相似度。儘管這些方法在辨識假草根運動宣傳上很有效，但仍面臨重大挑戰，特別是可用訓練資料集中的類別不平衡。為了減輕這個問題，最近的方法通常訴諸於資料擴充或增加正向樣本數量，但在現實世界中，這並不總是可行或足夠的。本文採行不同的途徑，我們提出一個基於大型語言模型 (LLM) 的新型框架，用於識別假草根運動宣傳，並引入平衡檢索擴充生成 (Balanced RAG) 元件。我們的做法首先將有關貼文（在本例中為推文）的文字資訊和社交網路的使用者互動作為輸入，提供給語言模型。然後，透過提示工程和提出的平衡檢索擴充生成方法，它有效地偵測 X (Twitter) 上協調的錯誤資訊宣傳。提出的框架不需要任何語言模型的訓練或微調。相反地，透過策略性地利用提示工程和平衡檢索擴充生成的優勢，它能讓大型語言模型克服類別不平衡的影響，並有效識別協調的政治宣傳。實驗結果證明，透過整合提出的提示工程和平衡檢索擴充生成方法，我們的框架優於傳統的基於圖形的基準，在精準度、召回率和 F1 分數方面獲得 2x-3x 的提升。</paragraph>

##### **A Survey on Memory-Efficient Large-Scale Model Training in AI for Science**
2501.11847v1 by Kaiyuan Tian, Linbo Qiao, Baihui Liu, Gongqingjian Jiang, Dongsheng Li

Scientific research faces high costs and inefficiencies with traditional
methods, but the rise of deep learning and large language models (LLMs) offers
innovative solutions. This survey reviews LLM applications across scientific
fields such as biology, medicine, chemistry, and meteorology, underscoring
their role in advancing research. However, the continuous expansion of model
size has led to significant memory demands, hindering further development and
application of LLMs for science. To address this, we review memory-efficient
training techniques for LLMs based on the transformer architecture, including
distributed training, mixed precision training, and gradient checkpointing.
Using AlphaFold 2 as an example, we demonstrate how tailored memory
optimization methods can reduce storage needs while preserving prediction
accuracy. We also discuss the challenges of memory optimization in practice and
potential future directions, hoping to provide valuable insights for
researchers and engineers.

摘要：科學研究面臨傳統方法的高成本和低效率，但深度學習和大語言模型 (LLM) 的興起提供了創新的解決方案。此調查回顧了 LLM 在生物學、醫學、化學和氣象學等科學領域的應用，強調它們在推進研究中的作用。然而，模型規模的持續擴展導致了顯著的記憶體需求，阻礙了 LLM 在科學領域的進一步開發和應用。為了解決這個問題，我們回顧了基於Transformer架構的 LLM 的記憶體高效訓練技術，包括分佈式訓練、混合精度訓練和梯度檢查點。以 AlphaFold 2 為例，我們展示了量身定制的記憶體優化方法如何在保持預測準確性的同時減少儲存需求。我們還討論了記憶體優化在實務中的挑戰和潛在的未來方向，希望能為研究人員和工程師提供有價值的見解。

##### **Supervised Learning for Analog and RF Circuit Design: Benchmarks and Comparative Insights**
2501.11839v1 by Asal Mehradfar, Xuzhe Zhao, Yue Niu, Sara Babakniya, Mahdi Alesheikh, Hamidreza Aghasi, Salman Avestimehr

Automating analog and radio-frequency (RF) circuit design using machine
learning (ML) significantly reduces the time and effort required for parameter
optimization. This study explores supervised ML-based approaches for designing
circuit parameters from performance specifications across various circuit
types, including homogeneous and heterogeneous designs. By evaluating diverse
ML models, from neural networks like transformers to traditional methods like
random forests, we identify the best-performing models for each circuit. Our
results show that simpler circuits, such as low-noise amplifiers, achieve
exceptional accuracy with mean relative errors as low as 0.3% due to their
linear parameter-performance relationships. In contrast, complex circuits, like
power amplifiers and voltage-controlled oscillators, present challenges due to
their non-linear interactions and larger design spaces. For heterogeneous
circuits, our approach achieves an 88% reduction in errors with increased
training data, with the receiver achieving a mean relative error as low as
0.23%, showcasing the scalability and accuracy of the proposed methodology.
Additionally, we provide insights into model strengths, with transformers
excelling in capturing non-linear mappings and k-nearest neighbors performing
robustly in moderately linear parameter spaces, especially in heterogeneous
circuits with larger datasets. This work establishes a foundation for extending
ML-driven design automation, enabling more efficient and scalable circuit
design workflows.

摘要：利用機器學習 (ML) 自動化類比和射頻 (RF) 電路設計，可大幅減少參數最佳化所需的時間和精力。本研究探討了基於監督式 ML 的方法，用於根據各種電路類型（包括同質和異質設計）的效能規格設計電路參數。透過評估各種 ML 模型（從Transformer等神經網路到隨機森林等傳統方法），我們找出每種電路的最佳效能模型。我們的結果顯示，較簡單的電路（例如低雜訊放大器）由於其線性參數效能關係，可達到極高的準確度，平均相對誤差低至 0.3%。相反地，複雜電路（例如功率放大器和電壓控制振盪器）由於其非線性交互作用和較大的設計空間，因此會帶來挑戰。對於異質電路，我們的做法可減少 88% 的誤差，並增加訓練資料，接收器可達到低至 0.23% 的平均相對誤差，展示了所提出方法的可擴充性和準確性。此外，我們提供模型優勢的見解，其中Transformer在捕捉非線性對應方面表現出色，而 k 最近鄰在適度線性參數空間中表現強健，特別是在具有較大資料集的異質電路中。這項工作建立了擴展 ML 驅動的設計自動化的基礎，進而實現更有效率且可擴充的電路設計工作流程。

##### **Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision**
2501.11836v1 by Saeid Ataei, Saeed Adibnazari, Seyyed Taghi Ataei

Structural integrity is vital for maintaining the safety and longevity of
concrete infrastructures such as bridges, tunnels, and walls. Traditional
methods for detecting damages like cracks and spalls are labor-intensive,
time-consuming, and prone to human error. To address these challenges, this
study explores advanced data-driven techniques using deep learning for
automated damage detection and analysis. Two state-of-the-art instance
segmentation models, YOLO-v7 instance segmentation and Mask R-CNN, were
evaluated using a dataset comprising 400 images, augmented to 10,995 images
through geometric and color-based transformations to enhance robustness. The
models were trained and validated using a dataset split into 90% training set,
validation and test set 10%. Performance metrics such as precision, recall,
mean average precision (mAP@0.5), and frames per second (FPS) were used for
evaluation. YOLO-v7 achieved a superior mAP@0.5 of 96.1% and processed 40 FPS,
outperforming Mask R-CNN, which achieved a mAP@0.5 of 92.1% with a slower
processing speed of 18 FPS. The findings recommend YOLO-v7 instance
segmentation model for real-time, high-speed structural health monitoring,
while Mask R-CNN is better suited for detailed offline assessments. This study
demonstrates the potential of deep learning to revolutionize infrastructure
maintenance, offering a scalable and efficient solution for automated damage
detection.

摘要：結構完整性對於維護橋樑、隧道和牆壁等混凝土基礎設施的安全性和使用壽命至關重要。傳統的損壞檢測方法，例如裂縫和剝落，需要大量人工，耗時且容易出現人為錯誤。為了應對這些挑戰，本研究探討了使用深度學習的先進數據驅動技術，用於自動損壞檢測和分析。使用包含 400 張圖像的數據集評估了兩個最先進的實例分割模型，YOLO-v7 實例分割和 Mask R-CNN，通過幾何和基於顏色的轉換擴展到 10,995 張圖像，以增強魯棒性。使用分為 90% 訓練集、驗證和測試集 10% 的數據集訓練和驗證模型。使用精確度、召回率、平均平均精確度 (mAP@0.5) 和每秒幀數 (FPS) 等性能指標進行評估。YOLO-v7 達到了 96.1% 的優異 mAP@0.5，並處理了 40 FPS，優於 Mask R-CNN，後者以 18 FPS 的較慢處理速度達到了 92.1% 的 mAP@0.5。研究結果推薦使用 YOLO-v7 實例分割模型進行實時、高速結構健康監測，而 Mask R-CNN 更適合詳細的離線評估。本研究展示了深度學習在基礎設施維護方面具有革命性的潛力，為自動損壞檢測提供了一個可擴展且高效的解決方案。

##### **Is your LLM trapped in a Mental Set? Investigative study on how mental sets affect the reasoning capabilities of LLMs**
2501.11833v1 by Saiful Haq, Niyati Chhaya, Piyush Pandey, Pushpak Bhattacharya

In this paper, we present an investigative study on how Mental Sets influence
the reasoning capabilities of LLMs. LLMs have excelled in diverse natural
language processing (NLP) tasks, driven by advancements in parameter-efficient
fine-tuning (PEFT) and emergent capabilities like in-context learning (ICL).
For complex reasoning tasks, selecting the right model for PEFT or ICL is
critical, often relying on scores on benchmarks such as MMLU, MATH, and GSM8K.
However, current evaluation methods, based on metrics like F1 Score or
reasoning chain assessments by larger models, overlook a key dimension:
adaptability to unfamiliar situations and overcoming entrenched thinking
patterns. In cognitive psychology, Mental Set refers to the tendency to persist
with previously successful strategies, even when they become inefficient - a
challenge for problem solving and reasoning. We compare the performance of LLM
models like Llama-3.1-8B-Instruct, Llama-3.1-70B-Instruct and GPT-4o in the
presence of mental sets. To the best of our knowledge, this is the first study
to integrate cognitive psychology concepts into the evaluation of LLMs for
complex reasoning tasks, providing deeper insights into their adaptability and
problem-solving efficacy.

摘要：<paragraph>在本文中，我們提出了一項調查研究，探討心智定勢如何影響 LLM 的推理能力。LLM 在各種自然語言處理 (NLP) 任務中表現出色，這歸功於參數高效微調 (PEFT) 和情境學習 (ICL) 等新興能力的進步。對於複雜的推理任務，選擇適當的 PEFT 或 ICL 模型至關重要，這通常依賴於 MMLU、MATH 和 GSM8K 等基準上的分數。然而，當前的評估方法基於 F1 分數或大型模型的推理鏈評估等指標，卻忽略了一個關鍵面向：適應不熟悉的情況和克服根深蒂固的思維模式。在認知心理學中，心智定勢是指即使在策略變得低效時，仍持續採用先前成功策略的傾向 - 這是問題解決和推理的一項挑戰。我們比較了 Llama-3.1-8B-Instruct、Llama-3.1-70B-Instruct 和 GPT-4o 等 LLM 模型在心智定勢存在下的表現。據我們所知，這是第一個將認知心理學概念整合到 LLM 複雜推理任務評估中的研究，提供了對其適應性和問題解決效能的更深入見解。</paragraph>

##### **PXGen: A Post-hoc Explainable Method for Generative Models**
2501.11827v1 by Yen-Lung Huang, Ming-Hsi Weng, Hao-Tsung Yang

With the rapid growth of generative AI in numerous applications, explainable
AI (XAI) plays a crucial role in ensuring the responsible development and
deployment of generative AI technologies. XAI has undergone notable
advancements and widespread adoption in recent years, reflecting a concerted
push to enhance the transparency, interpretability, and credibility of AI
systems. Recent research emphasizes that a proficient XAI method should adhere
to a set of criteria, primarily focusing on two key areas. Firstly, it should
ensure the quality and fluidity of explanations, encompassing aspects like
faithfulness, plausibility, completeness, and tailoring to individual needs.
Secondly, the design principle of the XAI system or mechanism should cover the
following factors such as reliability, resilience, the verifiability of its
outputs, and the transparency of its algorithm. However, research in XAI for
generative models remains relatively scarce, with little exploration into how
such methods can effectively meet these criteria in that domain. In this work,
we propose PXGen, a post-hoc explainable method for generative models. Given a
model that needs to be explained, PXGen prepares two materials for the
explanation, the Anchor set and intrinsic & extrinsic criteria. Those materials
are customizable by users according to their purpose and requirements. Via the
calculation of each criterion, each anchor has a set of feature values and
PXGen provides examplebased explanation methods according to the feature values
among all the anchors and illustrated and visualized to the users via tractable
algorithms such as k-dispersion or k-center.

摘要：<paragraph>隨著生成式 AI 在許多應用程式中的快速成長，可解釋 AI (XAI) 在確保生成式 AI 技術負責任地開發和部署方面扮演著至關重要的角色。XAI 在近年來經歷了顯著的進展和廣泛的採用，反映出協調一致地推動增強 AI 系統的透明性、可解釋性和可信度。最近的研究強調，一種熟練的 XAI 方法應遵循一組標準，主要關注於兩個關鍵領域。首先，它應確保解釋的品質和流暢度，包含忠實度、合理性、完整性和針對個別需求進行調整等面向。其次，XAI 系統或機制的設計原則應涵蓋以下因素，例如其輸出的可靠性、復原力、可驗證性，以及其演算法的透明性。然而，針對生成式模型的 XAI 研究仍然相對稀少，對於此類方法如何有效滿足該領域中的這些標準，鮮少探索。在這項工作中，我們提出 PXGen，一種針對生成式模型的後設可解釋方法。針對需要解釋的模型，PXGen 準備了錨點集和內在與外在標準這兩種材料供解釋。使用者可以根據其目的和需求自訂這些材料。透過計算每個標準，每個錨點都有一組特徵值，PXGen 提供基於範例的解釋方法，根據所有錨點中的特徵值，並透過易於處理的演算法（例如 k 分散或 k 中心）向使用者說明和視覺化。</paragraph>

##### **Toward Scalable Graph Unlearning: A Node Influence Maximization based Approach**
2501.11823v1 by Xunkai Li, Bowen Fan, Zhengyu Wu, Zhiyu Li, Rong-Hua Li, Guoren Wang

Machine unlearning, as a pivotal technology for enhancing model robustness
and data privacy, has garnered significant attention in prevalent web mining
applications, especially in thriving graph-based scenarios. However, most
existing graph unlearning (GU) approaches face significant challenges due to
the intricate interactions among web-scale graph elements during the model
training: (1) The gradient-driven node entanglement hinders the complete
knowledge removal in response to unlearning requests; (2) The billion-level
graph elements in the web scenarios present inevitable scalability issues. To
break the above limitations, we open up a new perspective by drawing a
connection between GU and conventional social influence maximization. To this
end, we propose Node Influence Maximization (NIM) through the decoupled
influence propagation model and fine-grained influence function in a scalable
manner, which is crafted to be a plug-and-play strategy to identify potential
nodes affected by unlearning entities. This approach enables offline execution
independent of GU, allowing it to be seamlessly integrated into most GU methods
to improve their unlearning performance. Based on this, we introduce Scalable
Graph Unlearning (SGU) as a new fine-tuned framework, which balances the
forgetting and reasoning capability of the unlearned model by entity-specific
optimizations. Extensive experiments on 14 datasets, including large-scale
ogbn-papers100M, have demonstrated the effectiveness of our approach.
Specifically, NIM enhances the forgetting capability of most GU methods, while
SGU achieves comprehensive SOTA performance and maintains scalability.

摘要：機器去學習，作為增強模型穩健性和資料隱私的關鍵技術，在普遍的網路挖掘應用中獲得顯著的關注，特別是在蓬勃發展的基於圖表的場景中。然而，大多數現有的圖表去學習 (GU) 方法在模型訓練期間由於網路規模圖表元素之間的複雜交互作用而面臨重大挑戰：(1) 梯度驅動的節點糾纏阻礙了對去學習請求的完整知識刪除；(2) 網路場景中的十億級圖表元素提出了不可避免的可擴充性問題。為了突破上述限制，我們通過在 GU 和傳統的社會影響最大化之間建立聯繫，開闢了一個新的視角。為此，我們通過解耦的影響傳播模型和可擴充性方式中的細粒度影響函數，提出了節點影響最大化 (NIM)，它被設計為一個即插即用的策略，用於識別受去學習實體影響的潛在節點。這種方法允許離線執行獨立於 GU，使其可以無縫整合到大多數 GU 方法中，以改善其去學習效能。基於此，我們引入了可擴充圖表去學習 (SGU) 作為一個新的微調框架，它通過實體特定的最佳化平衡了去學習模型的遺忘和推理能力。在 14 個資料集上的廣泛實驗，包括大規模的 ogbn-papers100M，證明了我們方法的有效性。具體來說，NIM 增強了大多數 GU 方法的遺忘能力，而 SGU 則實現了全面的 SOTA 效能並保持可擴充性。

##### **Toward Effective Digraph Representation Learning: A Magnetic Adaptive Propagation based Approach**
2501.11817v1 by Xunkai Li, Daohan Su, Zhengyu Wu, Guang Zeng, Hongchao Qin, Rong-Hua Li, Guoren Wang

The $q$-parameterized magnetic Laplacian serves as the foundation of directed
graph (digraph) convolution, enabling this kind of digraph neural network
(MagDG) to encode node features and structural insights by complex-domain
message passing. As a generalization of undirected methods, MagDG shows
superior capability in modeling intricate web-scale topology. Despite the great
success achieved by existing MagDGs, limitations still exist: (1) Hand-crafted
$q$: The performance of MagDGs depends on selecting an appropriate
$q$-parameter to construct suitable graph propagation equations in the complex
domain. This parameter tuning, driven by downstream tasks, limits model
flexibility and significantly increases manual effort. (2) Coarse Message
Passing: Most approaches treat all nodes with the same complex-domain
propagation and aggregation rules, neglecting their unique digraph contexts.
This oversight results in sub-optimal performance. To address the above issues,
we propose two key techniques: (1) MAP is crafted to be a plug-and-play
complex-domain propagation optimization strategy in the context of digraph
learning, enabling seamless integration into any MagDG to improve predictions
while enjoying high running efficiency. (2) MAP++ is a new digraph learning
framework, further incorporating a learnable mechanism to achieve adaptively
edge-wise propagation and node-wise aggregation in the complex domain for
better performance. Extensive experiments on 12 datasets demonstrate that MAP
enjoys flexibility for it can be incorporated with any MagDG, and scalability
as it can deal with web-scale digraphs. MAP++ achieves SOTA predictive
performance on 4 different downstream tasks.

摘要：<paragraph>帶有 $q$ 參數化的磁性拉普拉斯算子可作為有向圖 (digraph) 摺積的基礎，使這種類型的有向圖神經網路 (MagDG) 能透過複數域訊息傳遞對節點特徵和結構見解進行編碼。作為無向方法的概括，MagDG 在建模複雜的網路規模拓撲方面展現出優越的能力。儘管現有的 MagDG 取得了巨大的成功，但仍存在以下限制：(1) 手工製作的 $q$：MagDG 的效能取決於選擇適當的 $q$ 參數，以在複數域中建構合適的圖形傳播方程式。此參數調整受下游任務驅動，會限制模型彈性，並大幅增加手動工作。(2) 粗略訊息傳遞：大多數方法使用相同的複數域傳播和聚合規則來處理所有節點，忽略了它們獨特的有向圖脈絡。這種疏忽導致次佳效能。為了解決上述問題，我們提出了兩項關鍵技術：(1) MAP 被設計為即插即用的複數域傳播最佳化策略，用於有向圖學習的脈絡中，能無縫整合至任何 MagDG 以改善預測，同時享有高執行效率。(2) MAP++ 是一種新的有向圖學習架構，進一步結合可學習機制，在複數域中達成適應性的邊緣傳播和節點聚合，以獲得更好的效能。在 12 個資料集上的廣泛實驗證明，MAP 享有彈性，因為它可以與任何 MagDG 整合，而且具有可擴充性，因為它可以處理網路規模的有向圖。MAP++ 在 4 個不同的下游任務上達到了 SOTA 預測效能。</paragraph>

##### **Policy-Adaptable Methods For Resolving Normative Conflicts Through Argumentation and Graph Colouring**
2501.11799v1 by Johnny Joyce

In a multi-agent system, one may choose to govern the behaviour of an agent
by imposing norms, which act as guidelines for how agents should act either all
of the time or in given situations. However, imposing multiple norms on one or
more agents may result in situations where these norms conflict over how the
agent should behave. In any system with normative conflicts (such as safe
reinforcement models or systems which monitor safety protocols), one must
decide which norms should be followed such that the most important and most
relevant norms are maintained. We introduce a new method for resolving
normative conflicts through argumentation and graph colouring which is
compatible with a variety of normative conflict resolution policies. We prove
that this method always creates an admissible set of arguments under
argumentation semantics, meaning that it produces coherent outputs. We also
introduce more robust variants of this method, each building upon their
predecessor to create a superior output, and we include further mathematical
proof of their coherence. Our most advanced variant uses the existing concept
of curtailment, where one norm may supersede another without fully eliminating
it. The methods we introduce are all compatible with various pre-existing
policies for resolving normative conflicts. Empirical evaluations are also
performed to compare our algorithms to each other and to others in existing
literature.

摘要：在多代理系統中，人們可能會選擇透過實施規範來管理代理的行為，這些規範作為代理在任何時候或特定情況下應如何採取行動的準則。然而，對一個或多個代理實施多項規範可能會導致這些規範在代理應如何採取行動方面發生衝突的情況。在任何具有規範衝突的系統中（例如安全強化模型或監控安全協定的系統），人們必須決定應遵循哪些規範，以便維護最重要且最相關的規範。我們引入了一種新的方法，透過論證和圖形著色來解決規範衝突，這種方法與各種規範衝突解決政策相容。我們證明了這種方法始終會在論證語義下建立一組可接受的論證，這表示它會產生連貫的輸出。我們也引入了這種方法的更強健變體，每個變體都建立在它們的前身之上，以建立優異的輸出，並且我們包括了它們的連貫性的進一步數學證明。我們最先進的變體使用了現有的限制概念，其中一個規範可以在不完全消除另一個規範的情況下取代另一個規範。我們引入的方法都與各種預先存在的規範衝突解決政策相容。我們也進行了經驗評估，以將我們的演算法彼此比較，並與現有文獻中的其他演算法比較。

##### **Benchmarking Large Language Models via Random Variables**
2501.11790v1 by Zijin Hong, Hao Wu, Su Dong, Junnan Dong, Yilin Xiao, Yujing Zhang, Zhu Wang, Feiran Huang, Linyi Li, Hongxia Yang, Xiao Huang

With the continuous advancement of large language models (LLMs) in
mathematical reasoning, evaluating their performance in this domain has become
a prominent research focus. Recent studies have raised concerns about the
reliability of current mathematical benchmarks, highlighting issues such as
simplistic design and potential data leakage. Therefore, creating a reliable
benchmark that effectively evaluates the genuine capabilities of LLMs in
mathematical reasoning remains a significant challenge. To address this, we
propose RV-Bench, a framework for Benchmarking LLMs via Random Variables in
mathematical reasoning. Specifically, the background content of a random
variable question (RV question) mirrors the original problem in existing
standard benchmarks, but the variable combinations are randomized into
different values. LLMs must fully understand the problem-solving process for
the original problem to correctly answer RV questions with various combinations
of variable values. As a result, the LLM's genuine capability in mathematical
reasoning is reflected by its accuracy on RV-Bench. Extensive experiments are
conducted with 29 representative LLMs across 900+ RV questions. A leaderboard
for RV-Bench ranks the genuine capability of these LLMs. Further analysis of
accuracy dropping indicates that current LLMs still struggle with complex
mathematical reasoning problems.

摘要：隨著大型語言模型 (LLM) 在數學推理方面的持續進步，評估它們在這個領域的表現已成為一個重要的研究重點。最近的研究對當前數學基準的可靠性提出了疑慮，並強調了諸如設計過於簡化和潛在數據洩漏等問題。因此，建立一個可靠的基準，以有效評估 LLM 在數學推理中的真實能力，仍然是一項重大的挑戰。為了解決這個問題，我們提出了 RV-Bench，一個透過隨機變數對 LLM 進行基准測試的數學推理框架。具體來說，隨機變數問題 (RV 問題) 的背景內容反映了現有標準基準中的原始問題，但變數組合被隨機化為不同的值。LLM 必須充分理解原始問題的解題過程，才能正確回答具有各種變數值組合的 RV 問題。因此，LLM 在數學推理中的真實能力反映在其在 RV-Bench 上的準確度。使用 29 個具代表性的 LLM 對 900 多個 RV 問題進行了廣泛的實驗。RV-Bench 的排行榜對這些 LLM 的真實能力進行了排名。對準確度下降的進一步分析表明，當前的 LLM 仍然難以解決複雜的數學推理問題。

##### **Synthetic Data Can Mislead Evaluations: Membership Inference as Machine Text Detection**
2501.11786v1 by Ali Naseh, Niloofar Mireshghallah

Recent work shows membership inference attacks (MIAs) on large language
models (LLMs) produce inconclusive results, partly due to difficulties in
creating non-member datasets without temporal shifts. While researchers have
turned to synthetic data as an alternative, we show this approach can be
fundamentally misleading. Our experiments indicate that MIAs function as
machine-generated text detectors, incorrectly identifying synthetic data as
training samples regardless of the data source. This behavior persists across
different model architectures and sizes, from open-source models to commercial
ones such as GPT-3.5. Even synthetic text generated by different, potentially
larger models is classified as training data by the target model. Our findings
highlight a serious concern: using synthetic data in membership evaluations may
lead to false conclusions about model memorization and data leakage. We caution
that this issue could affect other evaluations using model signals such as loss
where synthetic or machine-generated translated data substitutes for real-world
samples.

摘要：最近的研究顯示，針對大型語言模型 (LLM) 的會員推論攻擊 (MIA) 會產生不確定的結果，部分原因是難以在沒有時間變動的情況下建立非會員資料集。儘管研究人員已轉向合成資料作為替代方案，但我們證明這種方法可能會產生根本性的誤導。我們的實驗表明，MIA 會作為機器產生的文字偵測器，不正確地將合成資料識別為訓練樣本，無論資料來源為何。這種行為會持續存在於不同的模型架構和規模中，從開源模型到商業模型，例如 GPT-3.5。即使是由不同且潛在更大的模型產生的合成文字，也會被目標模型分類為訓練資料。我們的發現凸顯了一個嚴重的問題：在會員評估中使用合成資料可能會導致關於模型記憶和資料外洩的錯誤結論。我們謹慎提醒，這個問題可能會影響其他使用模型訊號的評估，例如損失，其中合成或機器產生的翻譯資料會取代真實世界的樣本。

##### **Human-AI Collaborative Game Testing with Vision Language Models**
2501.11782v1 by Boran Zhang, Muhan Xu, Zhijun Pan

As modern video games become increasingly complex, traditional manual testing
methods are proving costly and inefficient, limiting the ability to ensure
high-quality game experiences. While advancements in Artificial Intelligence
(AI) offer the potential to assist human testers, the effectiveness of AI in
truly enhancing real-world human performance remains underexplored. This study
investigates how AI can improve game testing by developing and experimenting
with an AI-assisted workflow that leverages state-of-the-art machine learning
models for defect detection. Through an experiment involving 800 test cases and
276 participants of varying backgrounds, we evaluate the effectiveness of AI
assistance under four conditions: with or without AI support, and with or
without detailed knowledge of defects and design documentation. The results
indicate that AI assistance significantly improves defect identification
performance, particularly when paired with detailed knowledge. However,
challenges arise when AI errors occur, negatively impacting human
decision-making. Our findings show the importance of optimizing human-AI
collaboration and implementing strategies to mitigate the effects of AI
inaccuracies. By this research, we demonstrate AI's potential and problems in
enhancing efficiency and accuracy in game testing workflows and offers
practical insights for integrating AI into the testing process.

摘要：隨著現代視訊遊戲變得越來越複雜，傳統的手動測試方法被證明成本高昂且效率低下，限制了確保高品質遊戲體驗的能力。雖然人工智能 (AI) 的進步提供了協助人類測試人員的潛力，但 AI 在真正提升現實世界人類表現方面的有效性仍未得到充分探討。本研究探討了 AI 如何透過開發和實驗 AI 輔助工作流程來改進遊戲測試，該工作流程利用最先進的機器學習模型進行缺陷檢測。透過一項涉及 800 個測試案例和 276 位背景各異的參與者的實驗，我們評估了 AI 輔助在四種條件下的有效性：有或沒有 AI 支援，以及有或沒有缺陷和設計文件詳細知識。結果表明，AI 輔助顯著改進了缺陷識別效能，特別是在具備詳細知識時。然而，當發生 AI 錯誤時會出現挑戰，對人類決策產生負面影響。我們的研究結果顯示了最佳化人機協作以及實施策略以減輕 AI 不準確影響的重要性。透過這項研究，我們展示了 AI 在提高遊戲測試工作流程的效率和準確性方面的潛力與問題，並提供了將 AI 整合到測試流程中的實用見解。

##### **The Value of Nothing: Multimodal Extraction of Human Values Expressed by TikTok Influencers**
2501.11770v1 by Alina Starovolsky-Shitrit, Alon Neduva, Naama Appel Doron, Ella Daniel, Oren Tsur

Societal and personal values are transmitted to younger generations through
interaction and exposure. Traditionally, children and adolescents learned
values from parents, educators, or peers. Nowadays, social platforms serve as a
significant channel through which youth (and adults) consume information, as
the main medium of entertainment, and possibly the medium through which they
learn different values. In this paper we extract implicit values from TikTok
movies uploaded by online influencers targeting children and adolescents. We
curated a dataset of hundreds of TikTok movies and annotated them according to
the Schwartz Theory of Personal Values. We then experimented with an array of
Masked and Large language model, exploring how values can be detected.
Specifically, we considered two pipelines -- direct extraction of values from
video and a 2-step approach in which videos are first converted to elaborated
scripts and then values are extracted.
  Achieving state-of-the-art results, we find that the 2-step approach performs
significantly better than the direct approach and that using a trainable Masked
Language Model as a second step significantly outperforms a few-shot
application of a number of Large Language Models. We further discuss the impact
of fine-tuning and compare the performance of the different models on
identification of values present or contradicted in the TikTok. Finally, we
share the first values-annotated dataset of TikTok videos. Our results pave the
way to further research on influence and value transmission in video-based
social platforms.

摘要：社會與個人價值觀透過互動與接觸傳遞給年輕世代。傳統上，兒童與青少年從父母、教育者或同儕身上學習價值觀。現今，社群平台成為青少年（與成人）消費資訊的重要管道，作為娛樂的主要媒介，也可能是他們學習不同價值觀的媒介。在本文中，我們從網紅上傳、鎖定兒童與青少年的 TikTok 影片中萃取隱含的價值觀。我們策劃了一個包含數百部 TikTok 影片的資料集，並依據 Schwartz 個人價值觀理論對其進行註解。接著，我們使用一系列的遮蔽語言模型與大型語言模型進行實驗，探索如何偵測價值觀。具體來說，我們考量了兩種管道——直接從影片中萃取價值觀，以及一種先將影片轉換為詳細腳本，再萃取價值觀的兩步驟方法。我們發現，兩步驟方法的表現顯著優於直接方法，且在第二步驟中使用可訓練的遮蔽語言模型，其表現也顯著優於少次嘗試應用多種大型語言模型。我們進一步探討微調的影響，並比較不同模型在識別 TikTok 中存在或矛盾的價值觀方面的表現。最後，我們分享了第一個 TikTok 影片價值觀註解資料集。我們的結果為進一步研究影片社群平台中的影響力與價值觀傳遞鋪路。

##### **Is logical analysis performed by transformers taking place in self-attention or in the fully connected part?**
2501.11765v1 by Evgeniy Shin, Heinrich Matzinger

Transformers architecture apply self-attention to tokens represented as
vectors, before a fully connected (neuronal network) layer. These two parts can
be layered many times. Traditionally, self-attention is seen as a mechanism for
aggregating information before logical operations are performed by the fully
connected layer. In this paper, we show, that quite counter-intuitively, the
logical analysis can also be performed within the self-attention. For this we
implement a handcrafted single-level encoder layer which performs the logical
analysis within self-attention. We then study the scenario in which a one-level
transformer model undergoes self-learning using gradient descent. We
investigate whether the model utilizes fully connected layers or self-attention
mechanisms for logical analysis when it has the choice. Given that gradient
descent can become stuck at undesired zeros, we explicitly calculate these
unwanted zeros and find ways to avoid them. We do all this in the context of
predicting grammatical category pairs of adjacent tokens in a text. We believe
that our findings have broader implications for understanding the potential
logical operations performed by self-attention.

摘要：Transformer 架構在全連接（神經網路）層之前，將自注意力應用於表示為向量的符號。這兩個部分可以分層多次。傳統上，自注意力被視為在全連接層執行邏輯運算之前聚合資訊的機制。在本文中，我們展示了自注意力中也可以執行邏輯分析，這相當違反直覺。為此，我們實作了一個手工製作的單層編碼器層，它在自注意力中執行邏輯分析。然後我們研究了一種情境，其中一個單層 transformer 模型使用梯度下降進行自學習。我們探討了模型在有選擇的情況下，是否利用全連接層或自注意力機制進行邏輯分析。由於梯度下降可能會停留在不需要的零點，因此我們明確計算這些不需要的零點，並找出避免它們的方法。我們在預測文字中相鄰符號的語法類別對時，執行所有這些操作。我們相信我們的發現對於理解自注意力執行的潛在邏輯運算具有更廣泛的意義。

##### **Optimizing Pretraining Data Mixtures with LLM-Estimated Utility**
2501.11747v1 by William Held, Bhargavi Paranjape, Punit Singh Koura, Mike Lewis, Frank Zhang, Todor Mihaylov

Large Language Models improve with increasing amounts of high-quality
training data. However, leveraging larger datasets requires balancing quality,
quantity, and diversity across sources. After evaluating nine baseline methods
under both compute- and data-constrained scenarios, we find token-count
heuristics outperform manual and learned mixes, indicating that simple
approaches accounting for dataset size and diversity are surprisingly
effective. Building on this insight, we propose two complementary approaches:
UtiliMax, which extends token-based heuristics by incorporating utility
estimates from reduced-scale ablations, achieving up to a 10.6x speedup over
manual baselines; and Model Estimated Data Utility (MEDU), which leverages LLMs
to estimate data utility from small samples, matching ablation-based
performance while reducing computational requirements by $\sim$200x. Together,
these approaches establish a new framework for automated, compute-efficient
data mixing that is robust across training regimes.

摘要：大型語言模型會隨著高品質訓練資料的增加而有所進步。然而，利用更大的資料集需要在來源之間平衡品質、數量和多樣性。在計算和資料受限的情況下評估了九種基準方法後，我們發現權杖計數啟發式優於手動和學習混合，這表明考慮資料集大小和多樣性的簡單方法出乎意料地有效。基於這個見解，我們提出了兩種互補的方法：UtiliMax，它通過納入來自縮小規模消融的效用估計來擴展基於權杖的啟發式，與手動基準相比，速度提高了 10.6 倍；以及模型估計資料效用 (MEDU)，它利用 LLM 從小樣本估計資料效用，在減少計算需求的同時匹配基於消融的效能 $\sim$200 倍。綜合而言，這些方法為自動化、計算效率高的資料混合建立了一個新的架構，該架構在訓練制度中具有魯棒性。

##### **SILO: Solving Inverse Problems with Latent Operators**
2501.11746v1 by Ron Raphaeli, Sean Man, Michael Elad

Consistent improvement of image priors over the years has led to the
development of better inverse problem solvers. Diffusion models are the
newcomers to this arena, posing the strongest known prior to date. Recently,
such models operating in a latent space have become increasingly predominant
due to their efficiency. In recent works, these models have been applied to
solve inverse problems. Working in the latent space typically requires multiple
applications of an Autoencoder during the restoration process, which leads to
both computational and restoration quality challenges. In this work, we propose
a new approach for handling inverse problems with latent diffusion models,
where a learned degradation function operates within the latent space,
emulating a known image space degradation. Usage of the learned operator
reduces the dependency on the Autoencoder to only the initial and final steps
of the restoration process, facilitating faster sampling and superior
restoration quality. We demonstrate the effectiveness of our method on a
variety of image restoration tasks and datasets, achieving significant
improvements over prior art.

摘要：多年来图像先验的不断改进导致了更好的逆问题求解器的开发。扩散模型是该领域的新手，提出了迄今为止已知的最強先验。最近，由于其效率，在潜在空间中运行的此类模型变得越来越普遍。在最近的工作中，这些模型已被应用于解决逆问题。在潜在空间中工作通常需要在恢复过程中多次应用自动编码器，这导致计算和恢复质量挑战。在这项工作中，我们提出了一种处理潜在扩散模型逆问题的新方法，其中学习到的退化函数在潜在空间内运行，模拟已知的图像空间退化。学习到的算子的使用将对自动编码器的依赖性降低到恢复过程的初始和最终步骤，从而实现更快的采样和更高的恢复质量。我们在各种图像恢复任务和数据集上展示了我们方法的有效性，与现有技术相比取得了显着的改进。

##### **Episodic memory in AI agents poses risks that should be studied and mitigated**
2501.11739v1 by Chad DeChant

Most current AI models have little ability to store and later retrieve a
record or representation of what they do. In human cognition, episodic memories
play an important role in both recall of the past as well as planning for the
future. The ability to form and use episodic memories would similarly enable a
broad range of improved capabilities in an AI agent that interacts with and
takes actions in the world. Researchers have begun directing more attention to
developing memory abilities in AI models. It is therefore likely that models
with such capability will be become widespread in the near future. This could
in some ways contribute to making such AI agents safer by enabling users to
better monitor, understand, and control their actions. However, as a new
capability with wide applications, we argue that it will also introduce
significant new risks that researchers should begin to study and address. We
outline these risks and benefits and propose four principles to guide the
development of episodic memory capabilities so that these will enhance, rather
than undermine, the effort to keep AI safe and trustworthy.

摘要：現今大多數的 AI 模型幾乎沒有儲存和稍後檢索其執行紀錄或表徵的能力。在人類認知中，情節記憶在回憶過去以及規劃未來中扮演著重要的角色。形成和使用情節記憶的能力將同樣使與世界互動和採取行動的 AI 代理程式具備廣泛的進步能力。研究人員已開始將更多注意力放在發展 AI 模型的記憶能力上。因此，具備此類能力的模型很可能會在不久的將來普及。這在某些方面可能有助於透過讓使用者能夠更完善地監控、理解和控制其行動，從而使此類 AI 代理程式更安全。然而，作為一種具有廣泛應用程式的新能力，我們認為它也會帶來重大的新風險，研究人員應開始研究和解決這些風險。我們概述這些風險和好處，並提出四項原則來引導情節記憶能力的發展，以便這些能力能加強而不是破壞讓 AI 保持安全和值得信賴的努力。

##### **Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks**
2501.11733v1 by Zhenhailong Wang, Haiyang Xu, Junyang Wang, Xi Zhang, Ming Yan, Ji Zhang, Fei Huang, Heng Ji

Smartphones have become indispensable in modern life, yet navigating complex
tasks on mobile devices often remains frustrating. Recent advancements in large
multimodal model (LMM)-based mobile agents have demonstrated the ability to
perceive and act in mobile environments. However, current approaches face
significant limitations: they fall short in addressing real-world human needs,
struggle with reasoning-intensive and long-horizon tasks, and lack mechanisms
to learn and improve from prior experiences. To overcome these challenges, we
introduce Mobile-Agent-E, a hierarchical multi-agent framework capable of
self-evolution through past experience. By hierarchical, we mean an explicit
separation of high-level planning and low-level action execution. The framework
comprises a Manager, responsible for devising overall plans by breaking down
complex tasks into subgoals, and four subordinate agents--Perceptor, Operator,
Action Reflector, and Notetaker--which handle fine-grained visual perception,
immediate action execution, error verification, and information aggregation,
respectively. Mobile-Agent-E also features a novel self-evolution module which
maintains a persistent long-term memory comprising Tips and Shortcuts. Tips are
general guidance and lessons learned from prior tasks on how to effectively
interact with the environment. Shortcuts are reusable, executable sequences of
atomic operations tailored for specific subroutines. The inclusion of Tips and
Shortcuts facilitates continuous refinement in performance and efficiency.
Alongside this framework, we introduce Mobile-Eval-E, a new benchmark featuring
complex mobile tasks requiring long-horizon, multi-app interactions. Empirical
results show that Mobile-Agent-E achieves a 22% absolute improvement over
previous state-of-the-art approaches across three foundation model backbones.
Project page: https://x-plug.github.io/MobileAgent.

摘要：智慧型手機在現代生活中已不可或缺，然而在行動裝置上執行複雜的任務往往令人沮喪。大型多模態模型 (LMM) 為基礎的行動代理程式在最近的進展中已展現出感知和在行動環境中執行的能力。然而，目前的作法面臨重大的限制：它們無法滿足現實世界中人類的需求、難以應付需要推理且時間跨度長的任務，而且缺乏從過往經驗中學習和改進的機制。為了克服這些挑戰，我們引入了 Mobile-Agent-E，這是一個分層多代理架構，能夠透過過往經驗自我演進。所謂分層，意指將高階規劃和低階動作執行明確分開。此架構包含一個管理員，負責透過將複雜任務分解成子目標來擬定整體計畫，以及四個從屬代理程式，分別為感知器、操作員、動作反射器和筆記員，負責處理細微的視覺感知、立即動作執行、錯誤驗證和資訊彙整。Mobile-Agent-E 也具備一個新穎的自我演進模組，維護一個持久的長期記憶，包含提示和捷徑。提示是從過往任務中學到的通用指導和教訓，說明如何有效與環境互動。捷徑是可以重複使用的可執行原子操作序列，專門用於特定子常式。包含提示和捷徑有助於持續改善效能和效率。除了這個架構，我們還引入了 Mobile-Eval-E，這是一個新的基準，包含需要長時間跨度、多應用程式互動的複雜行動任務。實證結果顯示，Mobile-Agent-E 在三個基礎模型骨幹上，比先前的最先進作法獲得了 22% 的絕對改善。專案頁面：https://x-plug.github.io/MobileAgent。

##### **Transformer Vibration Forecasting for Advancing Rail Safety and Maintenance 4.0**
2501.11730v1 by Darío C. Larese, Almudena Bravo Cerrada, Gabriel Dambrosio Tomei, Alejandro Guerrero-López, Pablo M. Olmos, María Jesús Gómez García

Maintaining railway axles is critical to preventing severe accidents and
financial losses. The railway industry is increasingly interested in advanced
condition monitoring techniques to enhance safety and efficiency, moving beyond
traditional periodic inspections toward Maintenance 4.0.
  This study introduces a robust Deep Autoregressive solution that integrates
seamlessly with existing systems to avert mechanical failures. Our approach
simulates and predicts vibration signals under various conditions and fault
scenarios, improving dataset robustness for more effective detection systems.
These systems can alert maintenance needs, preventing accidents preemptively.
We use experimental vibration signals from accelerometers on train axles.
  Our primary contributions include a transformer model, ShaftFormer, designed
for processing time series data, and an alternative model incorporating
spectral methods and enhanced observation models. Simulating vibration signals
under diverse conditions mitigates the high cost of obtaining experimental
signals for all scenarios. Given the non-stationary nature of railway vibration
signals, influenced by speed and load changes, our models address these
complexities, offering a powerful tool for predictive maintenance in the rail
industry.

摘要：維護鐵路車軸對於預防嚴重事故和財務損失至關重要。鐵路產業越來越有興趣採用先進的狀態監控技術，以提升安全性和效率，超越傳統的定期檢查，邁向維護 4.0。
本研究介紹了一種強健的深度自迴歸解決方案，可與現有系統無縫整合，以避免機械故障。我們的做法模擬和預測各種條件和故障情境下的振動信號，改善資料集的穩健性，以建立更有效的偵測系統。這些系統可以發出維護需求的警示，預防事故發生。我們使用來自火車車軸加速度計的實驗振動信號。
我們的主要貢獻包括一個專為處理時間序列資料而設計的Transformer模型 ShaftFormer，以及一個結合光譜方法和增強觀測模型的替代模型。在各種條件下模擬振動信號可降低取得所有情境實驗信號的高昂成本。考量到鐵路振動信號會受到速度和負載變化的影響，且具有非穩態特性，我們的模型解決了這些複雜性，為鐵路產業的預測維護提供了強大的工具。

##### **Explain-Query-Test: Self-Evaluating LLMs Via Explanation and Comprehension Discrepancy**
2501.11721v1 by Saeid Asgari Taghanaki, Joao Monteiro

Large language models (LLMs) have demonstrated remarkable proficiency in
generating detailed and coherent explanations of complex concepts. However, the
extent to which these models truly comprehend the concepts they articulate
remains unclear. To assess the level of comprehension of a model relative to
the content it generates, we implemented a self-evaluation pipeline where
models: (i) given a topic generate an excerpt with information about the topic,
(ii) given an excerpt generate question-answer pairs, and finally (iii) given a
question generate an answer. We refer to this self-evaluation approach as
Explain-Query-Test (EQT). Interestingly, the accuracy on generated questions
resulting from running the EQT pipeline correlates strongly with the model
performance as verified by typical benchmarks such as MMLU-Pro. In other words,
EQT's performance is predictive of MMLU-Pro's, and EQT can be used to rank
models without the need for any external source of evaluation data other than
lists of topics of interest. Moreover, our results reveal a disparity between
the models' ability to produce detailed explanations and their performance on
questions related to those explanations. This gap highlights fundamental
limitations in the internal knowledge representation and reasoning abilities of
current LLMs. We release the code at https://github.com/asgsaeid/EQT.

摘要：大型語言模型 (LLM) 已展現出卓越的熟練度，能產生複雜概念的詳細且連貫的解釋。然而，這些模型是否真正理解它們所表達的概念，這一點仍不清楚。為了評估模型相對於它所產生內容的理解程度，我們實作了一個自我評估管道，其中模型：(i) 給定一個主題，產生一段包含關於該主題的資訊的摘錄，(ii) 給定一個摘錄，產生問題-答案對，最後 (iii) 給定一個問題，產生一個答案。我們將這種自我評估方法稱為「解釋-查詢-測試」(EQT)。有趣的是，執行 EQT 管道所產生的問題的準確性與模型效能密切相關，這已由典型的基準（例如 MMLU-Pro）驗證。換句話說，EQT 的效能可以預測 MMLU-Pro 的效能，且 EQT 可用於對模型進行排名，而無需任何外部評估資料來源，只要有感興趣的主題清單即可。此外，我們的結果揭示了模型產生詳細解釋的能力與它們對與這些解釋相關的問題的效能之間的差異。這個差距突顯了當前 LLM 在內部知識表示和推理能力方面的根本限制。我們在 https://github.com/asgsaeid/EQT 釋出程式碼。

##### **GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease**
2501.11715v1 by Wenjie Kang, Lize Jiskoot, Peter De Deyn, Geert Biessels, Huiberdina Koek, Jurgen Claassen, Huub Middelkoop, Wiesje Flier, Willemijn J. Jansen, Stefan Klein, Esther Bron

Deep learning methods based on Convolutional Neural Networks (CNNs) have
shown great potential to improve early and accurate diagnosis of Alzheimer's
disease (AD) dementia based on imaging data. However, these methods have yet to
be widely adopted in clinical practice, possibly due to the limited
interpretability of deep learning models. The Explainable Boosting Machine
(EBM) is a glass-box model but cannot learn features directly from input
imaging data. In this study, we propose a novel interpretable model that
combines CNNs and EBMs for the diagnosis and prediction of AD. We develop an
innovative training strategy that alternatingly trains the CNN component as a
feature extractor and the EBM component as the output block to form an
end-to-end model. The model takes imaging data as input and provides both
predictions and interpretable feature importance measures. We validated the
proposed model on the Alzheimer's Disease Neuroimaging Initiative (ADNI)
dataset and the Health-RI Parelsnoer Neurodegenerative Diseases Biobank (PND)
as an external testing set. The proposed model achieved an area-under-the-curve
(AUC) of 0.956 for AD and control classification, and 0.694 for the prediction
of conversion of mild cognitive impairment (MCI) to AD on the ADNI cohort. The
proposed model is a glass-box model that achieves a comparable performance with
other state-of-the-art black-box models. Our code is publicly available at:
https://anonymous.4open.science/r/GL-ICNN.

摘要：<paragraph>基於卷積神經網路 (CNN) 的深度學習方法已顯示出極大的潛力，可根據影像資料改善阿茲海默症 (AD) 失智症的早期準確診斷。然而，這些方法尚未廣泛應用於臨床實務中，這可能是由於深度學習模型的可解釋性有限。可解釋提升機 (EBM) 是個玻璃盒模型，但無法直接從輸入影像資料中學習特徵。在這項研究中，我們提出一個結合 CNN 和 EBM 的新可解釋模型，用於診斷和預測 AD。我們開發了一種創新的訓練策略，交替訓練 CNN 組件作為特徵萃取器，並訓練 EBM 組件作為輸出區塊，以形成端對端模型。此模型將影像資料作為輸入，並提供預測和可解釋的特徵重要性測量。我們在阿茲海默症神經影像倡議 (ADNI) 資料集和 Health-RI Parelsnoer 神經退化疾病生物資料庫 (PND) 上驗證了所提出的模型，作為外部測試集。所提出的模型在 AD 和對照分類中達到了 0.956 的曲線下面積 (AUC)，並在 ADNI 隊列中預測輕度認知障礙 (MCI) 轉化為 AD 時達到了 0.694。所提出的模型是一個玻璃盒模型，其效能與其他最先進的黑盒模型相當。我們的程式碼可在以下網址公開取得：https://anonymous.4open.science/r/GL-ICNN。</paragraph>

##### **YouLeQD: Decoding the Cognitive Complexity of Questions and Engagement in Online Educational Videos from Learners' Perspectives**
2501.11712v1 by Nong Ming, Sachin Sharma, Jiho Noh

Questioning is a fundamental aspect of education, as it helps assess
students' understanding, promotes critical thinking, and encourages active
engagement. With the rise of artificial intelligence in education, there is a
growing interest in developing intelligent systems that can automatically
generate and answer questions and facilitate interactions in both virtual and
in-person education settings. However, to develop effective AI models for
education, it is essential to have a fundamental understanding of questioning.
In this study, we created the YouTube Learners' Questions on Bloom's Taxonomy
Dataset (YouLeQD), which contains learner-posed questions from YouTube lecture
video comments. Along with the dataset, we developed two RoBERTa-based
classification models leveraging Large Language Models to detect questions and
analyze their cognitive complexity using Bloom's Taxonomy. This dataset and our
findings provide valuable insights into the cognitive complexity of
learner-posed questions in educational videos and their relationship with
interaction metrics. This can aid in the development of more effective AI
models for education and improve the overall learning experience for students.

摘要：提問是教育的基本面向，因為它有助於評量學生的理解力、促進批判性思考，並鼓勵積極參與。隨著人工智慧在教育中的崛起，開發智慧系統以自動產生和回答問題，並促進虛擬和面對面教育環境中的互動，越來越受到重視。然而，要開發出有效的教育 AI 模型，對於提問有基本的了解至關重要。在本研究中，我們建立了 YouTube 學習者在 Bloom 分類法上的問題資料集 (YouLeQD)，其中包含學習者在 YouTube 課程影片留言中提出的問題。除了資料集之外，我們還開發了兩個基於 RoBERTa 的分類模型，利用大型語言模型來偵測問題並使用 Bloom 分類法分析其認知複雜性。這個資料集和我們的研究結果提供了有價值的見解，說明學習者在教育影片中提出的問題的認知複雜性，以及它們與互動指標的關係。這有助於開發更有效的教育 AI 模型，並改善學生的整體學習體驗。

##### **Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)**
2501.11705v1 by Brian E. Perron, Lauri Goldkind, Zia Qi, Bryan G. Victor

This paper examines the responsible integration of artificial intelligence
(AI) in human services organizations (HSOs), proposing a nuanced framework for
evaluating AI applications across multiple dimensions of risk. The authors
argue that ethical concerns about AI deployment -- including professional
judgment displacement, environmental impact, model bias, and data laborer
exploitation -- vary significantly based on implementation context and specific
use cases. They challenge the binary view of AI adoption, demonstrating how
different applications present varying levels of risk that can often be
effectively managed through careful implementation strategies. The paper
highlights promising solutions, such as local large language models, that can
facilitate responsible AI integration while addressing common ethical concerns.
The authors propose a dimensional risk assessment approach that considers
factors like data sensitivity, professional oversight requirements, and
potential impact on client wellbeing. They conclude by outlining a path forward
that emphasizes empirical evaluation, starting with lower-risk applications and
building evidence-based understanding through careful experimentation. This
approach enables organizations to maintain high ethical standards while
thoughtfully exploring how AI might enhance their capacity to serve clients and
communities effectively.

摘要：本文探討了人工智慧 (AI) 在人類服務組織 (HSO) 中負責任的整合，提出了一個細緻的框架，用於評估 AI 應用在多個風險維度。作者認為，對 AI 部署的道德考量——包括專業判斷的取代、環境影響、模型偏差和資料工作者的剝削——會根據實施背景和具體使用案例而有顯著的不同。他們挑戰了 AI 採用二元論的觀點，說明了不同的應用如何呈現不同程度的風險，而這些風險通常可以透過仔細的實施策略來有效管理。本文重點介紹了有前景的解決方案，例如本地大型語言模型，它可以在解決常見的道德問題的同時，促進負責任的 AI 整合。作者提出了一種維度風險評估方法，該方法考慮了資料敏感度、專業監督需求和對客戶福祉的潛在影響等因素。他們最後概述了一條前進的道路，強調實證評估，從低風險應用開始，並透過仔細的實驗建立基於證據的理解。這種方法使組織能夠在深思熟慮地探討 AI 如何增強其有效服務客戶和社群的能力的同時，維持高道德標準。

##### **Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling**
2501.11651v1 by Zhenyu Hou, Xin Lv, Rui Lu, Jiajie Zhang, Yujiang Li, Zijun Yao, Juanzi Li, Jie Tang, Yuxiao Dong

Large language models (LLMs) have demonstrated remarkable capabilities in
complex reasoning tasks. However, existing approaches mainly rely on imitation
learning and struggle to achieve effective test-time scaling. While
reinforcement learning (RL) holds promise for enabling self-exploration and
learning from feedback, recent attempts yield only modest improvements in
complex reasoning. In this paper, we present T1 to scale RL by encouraging
exploration and understand inference scaling. We first initialize the LLM using
synthesized chain-of-thought data that integrates trial-and-error and
self-verification. To scale RL training, we promote increased sampling
diversity through oversampling. We further employ an entropy bonus as an
auxiliary loss, alongside a dynamic anchor for regularization to facilitate
reward optimization. We demonstrate that T1 with open LLMs as its base exhibits
inference scaling behavior and achieves superior performance on challenging
math reasoning benchmarks. For example, T1 with Qwen2.5-32B as the base model
outperforms the recent Qwen QwQ-32B-Preview model on MATH500, AIME2024, and
Omni-math-500. More importantly, we present a simple strategy to examine
inference scaling, where increased inference budgets directly lead to T1's
better performance without any additional verification. We will open-source the
T1 models and the data used to train them at \url{https://github.com/THUDM/T1}.

摘要：大型語言模型（LLM）在複雜推理任務中展現出非凡的能力。然而，現有方法主要依賴於模仿學習，並且難以實現有效的測試時間擴展。雖然強化學習（RL）有望實現自我探索和從回饋中學習，但最近的嘗試在複雜推理中僅產生了適度的改進。在本文中，我們提出 T1 來擴展 RL，以鼓勵探索並了解推理擴展。我們首先使用綜合的思維鏈數據初始化 LLM，該數據整合了試錯和自我驗證。為了擴展 RL 訓練，我們通過過度採樣來促進增加採樣多樣性。我們進一步採用熵獎勵作為輔助損失，並採用動態錨點進行正則化，以促進獎勵優化。我們證明了以開放式 LLM 為基礎的 T1 表現出推理擴展行為，並在具有挑戰性的數學推理基準上取得了卓越的性能。例如，以 Qwen2.5-32B 作為基礎模型的 T1 在 MATH500、AIME2024 和 Omni-math-500 上優於最近的 Qwen QwQ-32B-Preview 模型。更重要的是，我們提出了一個簡單的策略來檢查推理擴展，其中增加的推理預算直接導致 T1 的更好性能，而無需任何額外的驗證。我們將在 https://github.com/THUDM/T1 開源 T1 模型和用於訓練它們的數據。

##### **StAyaL | Multilingual Style Transfer**
2501.11639v1 by Karishma Thakrar, Katrina Lawrence, Kyle Howard

Stylistic text generation plays a vital role in enhancing communication by
reflecting the nuances of individual expression. This paper presents a novel
approach for generating text in a specific speaker's style across different
languages. We show that by leveraging only 100 lines of text, an individuals
unique style can be captured as a high-dimensional embedding, which can be used
for both text generation and stylistic translation. This methodology breaks
down the language barrier by transferring the style of a speaker between
languages. The paper is structured into three main phases: augmenting the
speaker's data with stylistically consistent external sources, separating style
from content using machine learning and deep learning techniques, and
generating an abstract style profile by mean pooling the learned embeddings.
The proposed approach is shown to be topic-agnostic, with test accuracy and F1
scores of 74.9\% and 0.75, respectively. The results demonstrate the potential
of the style profile for multilingual communication, paving the way for further
applications in personalized content generation and cross-linguistic stylistic
transfer.

摘要：風格化的文字生成在加強溝通方面扮演著重要的角色，透過反映個人表達的細微差異。這篇論文提出一個創新的方法，用來產生特定說話者風格的文字，橫跨不同的語言。我們展示出，只要利用 100 行文字，個人的獨特風格就可以被擷取為一個高維度的內嵌，這個內嵌可以用於文字生成和風格化翻譯。這個方法打破語言的藩籬，在語言之間轉移說話者的風格。這篇論文的架構分成三個主要階段：用風格一致的外在來源來擴充說話者的資料、使用機器學習和深度學習技術將風格從內容中分離出來、以及透過平均池化學習到的內嵌來產生一個抽象的風格特徵。所提出的方法被顯示為與主題無關，測試準確率和 F1 分數分別為 74.9% 和 0.75。結果展示了風格特徵在多語言溝通中的潛力，為個人化內容生成和跨語言風格化轉移的進一步應用鋪路。

##### **Noise-Agnostic Multitask Whisper Training for Reducing False Alarm Errors in Call-for-Help Detection**
2501.11631v1 by Myeonghoon Ryu, June-Woo Kim, Minseok Oh, Suji Lee, Han Park

Keyword spotting is often implemented by keyword classifier to the encoder in
acoustic models, enabling the classification of predefined or open vocabulary
keywords. Although keyword spotting is a crucial task in various applications
and can be extended to call-for-help detection in emergencies, however, the
previous method often suffers from scalability limitations due to retraining
required to introduce new keywords or adapt to changing contexts. We explore a
simple yet effective approach that leverages off-the-shelf pretrained ASR
models to address these challenges, especially in call-for-help detection
scenarios. Furthermore, we observed a substantial increase in false alarms when
deploying call-for-help detection system in real-world scenarios due to noise
introduced by microphones or different environments. To address this, we
propose a novel noise-agnostic multitask learning approach that integrates a
noise classification head into the ASR encoder. Our method enhances the model's
robustness to noisy environments, leading to a significant reduction in false
alarms and improved overall call-for-help performance. Despite the added
complexity of multitask learning, our approach is computationally efficient and
provides a promising solution for call-for-help detection in real-world
scenarios.

摘要：關鍵字點選通常由關鍵字分類器實作到編碼器中，在聲學模型中，能分類預先定義或開放式詞彙的關鍵字。儘管關鍵字點選在各種應用程式中是一項重要的任務，並且可以擴充到緊急情況中的求救偵測，然而，先前的做法通常會因為需要重新訓練以導入新關鍵字或適應變動的脈絡，而面臨可擴充性的限制。我們探討一個簡單但有效的方法，利用現成的預訓練 ASR 模型來解決這些挑戰，特別是在求救偵測的場景中。此外，我們觀察到在真實世界的場景中部署求救偵測系統時，由於麥克風或不同環境所產生的噪音，錯誤警報大幅增加。為了解決這個問題，我們提出一個新穎的與噪音無關的多任務學習方法，將噪音分類頭整合到 ASR 編碼器中。我們的做法增強了模型對有噪音環境的穩健性，大幅減少錯誤警報，並改善整體的求救表現。儘管多任務學習增加了複雜性，但我們的做法在運算上很有效率，並為真實世界的場景中的求救偵測提供一個有前景的解決方案。

##### **Early evidence of how LLMs outperform traditional systems on OCR/HTR tasks for historical records**
2501.11623v1 by Seorin Kim, Julien Baudru, Wouter Ryckbosch, Hugues Bersini, Vincent Ginis

We explore the ability of two LLMs -- GPT-4o and Claude Sonnet 3.5 -- to
transcribe historical handwritten documents in a tabular format and compare
their performance to traditional OCR/HTR systems: EasyOCR, Keras, Pytesseract,
and TrOCR. Considering the tabular form of the data, two types of experiments
are executed: one where the images are split line by line and the other where
the entire scan is used as input. Based on CER and BLEU, we demonstrate that
LLMs outperform the conventional OCR/HTR methods. Moreover, we also compare the
evaluated CER and BLEU scores to human evaluations to better judge the outputs
of whole-scan experiments and understand influential factors for CER and BLEU.
Combining judgments from all the evaluation metrics, we conclude that two-shot
GPT-4o for line-by-line images and two-shot Claude Sonnet 3.5 for whole-scan
images yield the transcriptions of the historical records most similar to the
ground truth.

摘要：我們探討兩個 LLM -- GPT-4o 和 Claude Sonnet 3.5 -- 以表格格式轉錄歷史手寫文件的能
力，並將其效能與傳統的 OCR/HTR 系統進行比較：EasyOCR、Keras、Pytesseract 和 TrOCR。考量到資料的表格形式，執行了兩種實驗：一種是將影像逐行分割，另一種是使用整個掃描作為輸入。根據 CER 和 BLEU，我們證明 LLM 的表現優於傳統的 OCR/HTR 方法。此外，我們還將評估的 CER 和 BLEU 分數與人工評分進行比較，以更好地判斷全掃描實驗的輸出，並了解影響 CER 和 BLEU 的因素。結合所有評分指標的判斷，我們得出結論，逐行影像的兩次 GPT-4o 和全掃描影像的兩次 Claude Sonnet 3.5 產生與真實情況最相似的歷史記錄轉錄。

##### **Trojan Detection Through Pattern Recognition for Large Language Models**
2501.11621v1 by Vedant Bhasin, Matthew Yudin, Razvan Stefanescu, Rauf Izmailov

Trojan backdoors can be injected into large language models at various
stages, including pretraining, fine-tuning, and in-context learning, posing a
significant threat to the model's alignment. Due to the nature of causal
language modeling, detecting these triggers is challenging given the vast
search space. In this study, we propose a multistage framework for detecting
Trojan triggers in large language models consisting of token filtration,
trigger identification, and trigger verification. We discuss existing trigger
identification methods and propose two variants of a black-box trigger
inversion method that rely on output logits, utilizing beam search and greedy
decoding respectively. We show that the verification stage is critical in the
process and propose semantic-preserving prompts and special perturbations to
differentiate between actual Trojan triggers and other adversarial strings that
display similar characteristics. The evaluation of our approach on the TrojAI
and RLHF poisoned model datasets demonstrates promising results.

摘要：木馬後門可以在各種階段注入大型語言模型，包括預訓練、微調和情境學習，對模型的對齊構成重大威脅。由於因果語言建模的性質，鑑於廣大的搜尋空間，偵測這些觸發器具有挑戰性。在本研究中，我們提出了一個多階段架構，用於偵測大型語言模型中的木馬觸發器，包括標記過濾、觸發器識別和觸發器驗證。我們討論現有的觸發器識別方法，並提出兩種黑盒觸發器反轉方法的變體，它們分別依賴於輸出對數機率，利用波束搜尋和貪婪解碼。我們表明驗證階段在這個過程中至關重要，並提出語義保留提示和特殊擾動，以區分實際的木馬觸發器和顯示類似特徵的其他對抗性字串。我們的方法在 TrojAI 和 RLHF 中毒模型資料集上的評估顯示出有希望的結果。

##### **Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems**
2501.11613v1 by Giorgio Robino

This study introduces Conversation Routines (CR), a structured prompt
engineering framework for developing task-oriented dialog systems using Large
Language Models (LLMs). While LLMs demonstrate remarkable natural language
understanding capabilities, engineering them to reliably execute complex
business workflows remains challenging. The proposed CR framework enables the
development of Conversation Agentic Systems (CAS) through natural language
specifications, embedding task-oriented logic within LLM prompts. This approach
provides a systematic methodology for designing and implementing complex
conversational workflows while maintaining behavioral consistency. We
demonstrate the framework's effectiveness through two proof of concept
implementations: a Train Ticket Booking System and an Interactive
Troubleshooting Copilot. These case studies validate CR's capability to encode
sophisticated behavioral patterns and decision logic while preserving natural
conversational flexibility. Results show that CR enables domain experts to
design conversational workflows in natural language while leveraging custom
enterprise functionalities (tools) developed by software engineers, creating an
efficient division of responsibilities where developers focus on core API
implementation and domain experts handle conversation design. While the
framework shows promise in accessibility and adaptability, we identify key
challenges including computational overhead, non-deterministic behavior, and
domain-specific logic optimization. Future research directions include
enhancing system robustness, improving scalability for complex multi-agent
interactions, and addressing the identified limitations across diverse business
applications.

摘要：本研究介紹了對話常規 (CR)，這是一個結構化提示工程架構，用於使用大型語言模型 (LLM) 開發以任務為導向的對話系統。儘管 LLM 展示了非凡的自然語言理解能力，但要設計它們來可靠地執行複雜的業務工作流程仍然具有挑戰性。提出的 CR 架構能夠通過自然語言規範開發對話代理系統 (CAS)，在 LLM 提示中嵌入以任務為導向的邏輯。此方法提供了一個系統的方法來設計和實作複雜的對話工作流程，同時保持行為一致性。我們透過兩個概念驗證實作展示了該架構的有效性：火車票預訂系統和互動故障排除副駕駛。這些案例研究驗證了 CR 編碼複雜行為模式和決策邏輯的能力，同時保留了自然的對話靈活性。結果表明，CR 能讓領域專家使用自然語言設計對話工作流程，同時利用軟體工程師開發的客製化企業功能（工具），創造一種有效的責任劃分，開發人員專注於核心 API 實作，而領域專家則處理對話設計。儘管該架構在可及性和適應性方面顯示出前景，但我們發現了關鍵挑戰，包括運算負擔、非確定性行為和特定領域邏輯最佳化。未來的研究方向包括增強系統穩健性、改善複雜多代理互動的可擴充性，以及解決不同業務應用中的已識別限制。

##### **SR-FoT: A Syllogistic-Reasoning Framework of Thought for Large Language Models Tackling Knowledge-based Reasoning Tasks**
2501.11599v1 by Wentao Wan, Zhuojie Yang, Yongcan Chen, Chenglin Luo, Ruilin Wang, Kehao Cai, Nan Kang, Liang Lin, Keze Wang

Deductive reasoning is a crucial logical capability that assists us in
solving complex problems based on existing knowledge. Although augmented by
Chain-of-Thought prompts, Large Language Models (LLMs) might not follow the
correct reasoning paths. Enhancing the deductive reasoning abilities of LLMs,
and leveraging their extensive built-in knowledge for various reasoning tasks,
remains an open question. Attempting to mimic the human deductive reasoning
paradigm, we propose a multi-stage Syllogistic-Reasoning Framework of Thought
(SR-FoT) that enables LLMs to perform syllogistic deductive reasoning to handle
complex knowledge-based reasoning tasks. Our SR-FoT begins by interpreting the
question and then uses the interpretation and the original question to propose
a suitable major premise. It proceeds by generating and answering minor premise
questions in two stages to match the minor premises. Finally, it guides LLMs to
use the previously generated major and minor premises to perform syllogistic
deductive reasoning to derive the answer to the original question. Extensive
and thorough experiments on knowledge-based reasoning tasks have demonstrated
the effectiveness and advantages of our SR-FoT.

摘要：演绎推理是一种至关重要的逻辑能力，它帮助我们在现有知识的基础上解决复杂的问题。虽然通过思想链提示增强了大语言模型 (LLM)，但它们可能无法遵循正确的推理路径。增强 LLM 的演绎推理能力，并利用其广泛的内置知识来执行各种推理任务，仍然是一个悬而未决的问题。为了模仿人类的演绎推理范式，我们提出了一种多阶段三段论推理思想框架 (SR-FoT)，它使 LLM 能够执行三段论演绎推理来处理基于复杂知识的推理任务。我们的 SR-FoT 从解释问题开始，然后使用解释和原始问题来提出合适的重大前提。它通过分两个阶段生成和回答次要前提问题来匹配次要前提。最后，它指导 LLM 使用先前生成的重大前提和次要前提来执行三段论演绎推理，以得出原始问题的答案。在基于知识的推理任务上进行的广泛而彻底的实验已经证明了我们 SR-FoT 的有效性和优势。

##### **Fairness Testing through Extreme Value Theory**
2501.11597v1 by Verya Monjezi, Ashutosh Trivedi, Vladik Kreinovich, Saeid Tizpaz-Niari

Data-driven software is increasingly being used as a critical component of
automated decision-support systems. Since this class of software learns its
logic from historical data, it can encode or amplify discriminatory practices.
Previous research on algorithmic fairness has focused on improving average-case
fairness. On the other hand, fairness at the extreme ends of the spectrum,
which often signifies lasting and impactful shifts in societal attitudes, has
received significantly less emphasis.
  Leveraging the statistics of extreme value theory (EVT), we propose a novel
fairness criterion called extreme counterfactual discrimination (ECD). This
criterion estimates the worst-case amounts of disadvantage in outcomes for
individuals solely based on their memberships in a protected group. Utilizing
tools from search-based software engineering and generative AI, we present a
randomized algorithm that samples a statistically significant set of points
from the tail of ML outcome distributions even if the input dataset lacks a
sufficient number of relevant samples.
  We conducted several experiments on four ML models (deep neural networks,
logistic regression, and random forests) over 10 socially relevant tasks from
the literature on algorithmic fairness. First, we evaluate the generative AI
methods and find that they generate sufficient samples to infer valid EVT
distribution in 95% of cases. Remarkably, we found that the prevalent bias
mitigators reduce the average-case discrimination but increase the worst-case
discrimination significantly in 5% of cases. We also observed that even the
tail-aware mitigation algorithm -- MiniMax-Fairness -- increased the worst-case
discrimination in 30% of cases. We propose a novel ECD-based mitigator that
improves fairness in the tail in 90% of cases with no degradation of the
average-case discrimination.

摘要：<paragraph>資料驅動軟體正日益被用作自動化決策支援系統的重要組成部分。由於此類軟體從歷史資料中學習其邏輯，因此它可以編碼或擴大歧視性做法。先前針對演算法公平性的研究著重於改善平均狀況公平性。另一方面，光譜兩極的公平性，通常表示社會態度持久且有影響力的轉變，受到的重視卻明顯較少。
  利用極值理論 (EVT) 的統計資料，我們提出了一項名為極端反事實歧視 (ECD) 的新公平性準則。此準則估計個人僅基於其受保護群組的成員身份而產生的最差情況結果劣勢量。利用來自基於搜尋的軟體工程和生成式 AI 的工具，我們提出了一種隨機演算法，即使輸入資料集缺乏足夠數量的相關樣本，也能從 ML 結果分佈的尾端抽取一組具有統計顯著性的點。
  我們針對來自演算法公平性文獻中的 10 項社會相關任務，對四個 ML 模型（深度神經網路、邏輯迴歸和隨機森林）進行了多項實驗。首先，我們評估生成式 AI 方法，並發現它們產生了足夠的樣本，可以在 95% 的案例中推斷出有效的 EVT 分佈。值得注意的是，我們發現普遍的偏見緩解器會降低平均狀況歧視，但在 5% 的案例中顯著增加了最差情況歧視。我們還觀察到，即使是尾端感知緩解演算法——MiniMax-Fairness——在 30% 的案例中也增加了最差情況歧視。我們提出了一種新的基於 ECD 的緩解器，它在 90% 的案例中改善了尾端的公平性，而不會降低平均狀況歧視。</paragraph>

##### **Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing**
2501.11592v1 by Chaoqing Tang, Huanze Zhuang, Guiyun Tian, Zhenli Zeng, Yi Ding, Wenzhong Liu, Xiang Bai

Pre-trained large models attract widespread attention in recent years, but
they face challenges in applications that require high interpretability or have
limited resources, such as physical sensing, medical imaging, and
bioinformatics. Compressed Sensing (CS) is a well-proved theory that drives
many recent breakthroughs in these applications. However, as a typical
under-determined linear system, CS suffers from excessively long sparse
reconstruction times when using traditional iterative methods, particularly
with large-scale data. Current AI methods like deep unfolding fail to
substitute them because pre-trained models exhibit poor generality beyond their
training conditions and dataset distributions, or lack interpretability.
Instead of following the big model fervor, this paper proposes ultra-small
artificial neural models called coefficients learning (CL), enabling
training-free and rapid sparse reconstruction while perfectly inheriting the
generality and interpretability of traditional iterative methods, bringing new
feature of incorporating prior knowledges. In CL, a signal of length $n$ only
needs a minimal of $n$ trainable parameters. A case study model called CLOMP is
implemented for evaluation. Experiments are conducted on both synthetic and
real one-dimensional and two-dimensional signals, demonstrating significant
improvements in efficiency and accuracy. Compared to representative iterative
methods, CLOMP improves efficiency by 100 to 1000 folds for large-scale data.
Test results on eight diverse image datasets indicate that CLOMP improves
structural similarity index by 292%, 98%, 45% for sampling rates of 0.1, 0.3,
0.5, respectively. We believe this method can truly usher CS reconstruction
into the AI era, benefiting countless under-determined linear systems that rely
on sparse solution.

摘要：<paragraph>预训练大型模型近年来备受关注，但它们在需要高可解释性或资源有限的应用中面临挑战，例如物理传感、医学影像和生物信息学。压缩感知 (CS) 是一项经过充分验证的理论，推动了这些应用中的许多最新突破。然而，作为典型的欠定线性系统，CS 在使用传统迭代方法时会产生过长的稀疏重建时间，尤其是在处理大规模数据时。当前的深度展开等 AI 方法无法替代它们，因为预训练模型在其训练条件和数据集分布之外表现出较差的泛化性，或缺乏可解释性。本文没有追随大型模型热潮，而是提出了称为系数学习 (CL) 的超小型人工神经网络模型，实现无训练且快速的稀疏重建，同时完美继承了传统迭代方法的泛化性和可解释性，带来了融合先验知识的新特性。在 CL 中，长度为 $n$ 的信号只需要最少 $n$ 个可训练参数。实现了一个称为 CLOMP 的案例研究模型以进行评估。在合成和真实的一维和二维信号上进行了实验，证明了效率和准确性的显着提高。与具有代表性的迭代方法相比，CLOMP 将大规模数据的效率提高了 100 到 1000 倍。在八个不同的图像数据集上的测试结果表明，CLOMP 分别将采样率为 0.1、0.3、0.5 的结构相似性指数提高了 292%、98%、45%。我们相信这种方法可以真正将 CS 重建带入 AI 时代，使依赖稀疏解的无数欠定线性系统受益。</paragraph>

##### **Recurrent Diffusion for Large-Scale Parameter Generation**
2501.11587v1 by Kai Wang, Dongwen Tang, Wangbo Zhao, Yang You

Parameter generation has struggled to scale up for a long time, significantly
limiting its range of applications. In this study, we introduce
\textbf{R}ecurrent diffusion for large-scale \textbf{P}arameter
\textbf{G}eneration, called \textbf{RPG}. We first divide the trained
parameters into non-overlapping parts, after which a recurrent model is
proposed to learn their relationships. The recurrent model's outputs, as
conditions, are then fed into a diffusion model to generate the neural network
parameters. Using only a single GPU, recurrent diffusion enables us to generate
popular vision and language models such as ConvNeXt-L and LoRA parameters of
LLaMA-7B. Meanwhile, across various architectures and tasks, the generated
parameters consistently perform comparable results over trained networks.
Notably, our approach also shows the potential to generate models for handling
unseen tasks, which largely increases the practicality of parameter generation.
Our code is available
\href{https://github.com/NUS-HPC-AI-Lab/Recurrent-Parameter-Generation}{here}.

摘要：參數生成長期以來一直難以擴展，這顯著限制了其應用範圍。在本研究中，我們引入了用於大規模參數生成的遞迴擴散，稱為 RPG。我們首先將訓練好的參數分成不重疊的部分，然後提出一個遞迴模型來學習它們之間的關係。然後，將遞迴模型的輸出作為條件輸入到擴散模型中以生成神經網路參數。僅使用單個 GPU，遞迴擴散使我們能夠生成流行的視覺和語言模型，例如 ConvNeXt-L 和 LLaMA-7B 的 LoRA 參數。同時，在各種架構和任務中，生成的參數始終對訓練好的網路執行可比較的結果。值得注意的是，我們的做法也顯示了為處理未見任務生成模型的潛力，這大大增加了參數生成的實用性。我們的程式碼可用於
\href{https://github.com/NUS-HPC-AI-Lab/Recurrent-Parameter-Generation}{這裡}。

##### **Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**
2501.11560v1 by M. Manzour, A. Ballardini, R. Izquierdo, M. Á. Sotelo

Lane-changing maneuvers, particularly those executed abruptly or in risky
situations, are a significant cause of road traffic accidents. However, current
research mainly focuses on predicting safe lane changes. Furthermore, existing
accident datasets are often based on images only and lack comprehensive sensory
data. In this work, we focus on predicting risky lane changes using the CRASH
dataset (our own collected dataset specifically for risky lane changes), and
safe lane changes (using the HighD dataset). Then, we leverage KG and Bayesian
inference to predict these maneuvers using linguistic contextual information,
enhancing the model's interpretability and transparency. The model achieved a
91.5% f1-score with anticipation time extending to four seconds for risky lane
changes, and a 90.0% f1-score for predicting safe lane changes with the same
anticipation time. We validate our model by integrating it into a vehicle
within the CARLA simulator in scenarios that involve risky lane changes. The
model managed to anticipate sudden lane changes, thus providing automated
vehicles with further time to plan and execute appropriate safe reactions.
Finally, to enhance the explainability of our model, we utilize RAG to provide
clear and natural language explanations for the given prediction.

摘要：換車道動作，尤其是突然或在風險情況下執行的動作，是道路交通事故的重要原因。然而，目前的研究所主要集中在預測安全的換車道。此外，現有的事故資料集通常僅基於影像，且缺乏全面的感測資料。在這項工作中，我們專注於使用 CRASH 資料集（我們自己收集的專門針對風險換車道資料集）來預測風險換車道，以及安全換車道（使用 HighD 資料集）。然後，我們利用 KG 和貝氏推理來使用語言背景資訊預測這些動作，增強模型的可解釋性和透明度。該模型在風險換車道的預測時間延長至四秒時，達到了 91.5% 的 f1 分數，在預測安全換車道時，在相同的預測時間內達到了 90.0% 的 f1 分數。我們透過將模型整合到 CARLA 模擬器中的車輛中，在涉及風險換車道的場景中驗證我們的模型。該模型設法預測突然的換車道，從而為自動駕駛車輛提供了更多時間來規劃和執行適當的安全反應。最後，為了增強我們模型的可解釋性，我們利用 RAG 為給定的預測提供清晰且自然的語言解釋。

##### **PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation**
2501.11551v1 by Jinyu Wang, Jingjing Fu, Lei Song, Jiang Bian

Despite notable advancements in Retrieval-Augmented Generation (RAG) systems
that expand large language model (LLM) capabilities through external retrieval,
these systems often struggle to meet the complex and diverse needs of
real-world industrial applications. The reliance on retrieval alone proves
insufficient for extracting deep, domain-specific knowledge performing in
logical reasoning from specialized corpora. To address this, we introduce
sPecIalized KnowledgE and Rationale Augmentation Generation (PIKE-RAG),
focusing on extracting, understanding, and applying specialized knowledge,
while constructing coherent rationale to incrementally steer LLMs toward
accurate responses. Recognizing the diverse challenges of industrial tasks, we
introduce a new paradigm that classifies tasks based on their complexity in
knowledge extraction and application, allowing for a systematic evaluation of
RAG systems' problem-solving capabilities. This strategic approach offers a
roadmap for the phased development and enhancement of RAG systems, tailored to
meet the evolving demands of industrial applications. Furthermore, we propose
knowledge atomizing and knowledge-aware task decomposition to effectively
extract multifaceted knowledge from the data chunks and iteratively construct
the rationale based on original query and the accumulated knowledge,
respectively, showcasing exceptional performance across various benchmarks.

摘要：儘管檢索增強生成（RAG）系統在擴展大型語言模型（LLM）能力方面取得顯著進展，但這些系統經常難以滿足現實世界產業應用的複雜且多樣化的需求。僅依賴檢索被證明不足以從專業語料庫中提取深入的、特定領域的知識，並進行邏輯推理。為了解決這個問題，我們引入了專業知識和原理增強生成（PIKE-RAG），專注於提取、理解和應用專業知識，同時建構連貫的原理以逐步引導 LLM 朝向準確的回應。認識到產業任務的多樣化挑戰，我們引入了一個新的範例，根據知識提取和應用中的複雜性對任務進行分類，從而可以系統地評估 RAG 系統的解決問題能力。這種策略性方法為 RAG 系統的分階段開發和增強提供了路線圖，專門用於滿足產業應用不斷變化的需求。此外，我們提出知識原子化和知識感知任務分解，以有效地從資料區塊中提取多方面的知識，並分別根據原始查詢和累積的知識反覆建構原理，展示了在各種基準測試中的出色效能。

##### **Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas**
2501.11549v1 by Nishant Balepur, Vishakh Padmakumar, Fumeng Yang, Shi Feng, Rachel Rudinger, Jordan Lee Boyd-Graber

LLMs are tuned to follow instructions (aligned) by learning which of two
outputs users prefer for a prompt. However, this preference data format does
not convey why users prefer responses that are chosen or rejected, so LLMs
trained on these datasets cannot tailor responses to varied user needs. To
surface these parameters of personalization, we apply abductive reasoning to
preference data, inferring needs and interests of users, i.e. personas, that
may prefer each output. We test this idea in two steps: Persona Inference
(PI)-abductively inferring personas of users who prefer chosen or rejected
outputs-and Persona Tailoring (PT)-training models to tailor responses to
personas from PI. We find: 1) LLMs infer personas accurately explaining why
different users may prefer both chosen or rejected outputs; 2) Training on
preference data augmented with PI personas via PT boosts personalization,
enabling models to support user-written personas; and 3) Rejected response
personas form harder personalization evaluations, showing PT better aids users
with uncommon preferences versus typical alignment methods. We argue for an
abductive view of preferences for personalization, asking not only which
response is better but when, why, and for whom.

摘要：LLM 會透過學習使用者偏好的兩個輸出，調整為遵循指令（對齊）。然而，這種偏好資料格式並未傳達使用者偏好選擇或拒絕回應的原因，因此在這些資料集上訓練的 LLM 無法針對不同的使用者需求調整回應。為了了解這些個人化參數，我們將演繹推理應用於偏好資料，推論出可能偏好每個輸出的使用者需求和興趣，即角色。我們分為兩個步驟測試這個想法：角色推論 (PI) - 演繹推論偏好選取或拒絕輸出的使用者的角色，以及角色調整 (PT) - 訓練模型以調整回應以符合 PI 中的角色。我們發現：1) LLM 推論角色準確解釋了為什麼不同的使用者可能偏好選取或拒絕的輸出；2) 透過 PT，使用 PI 角色擴充偏好資料進行訓練，會提升個人化，讓模型能支援使用者撰寫的角色；3) 被拒絕的回應角色形成更困難的個人化評估，顯示 PT 比典型的對齊方法更能協助具有不常見偏好的使用者。我們主張演繹偏好以進行個人化，不僅詢問哪個回應較好，還要詢問何時、為何以及對誰較好。

##### **Technical Report for the Forgotten-by-Design Project: Targeted Obfuscation for Machine Learning**
2501.11525v1 by Rickard Brännvall, Laurynas Adomaitis, Olof Görnerup, Anass Sedrati

The right to privacy, enshrined in various human rights declarations, faces
new challenges in the age of artificial intelligence (AI). This paper explores
the concept of the Right to be Forgotten (RTBF) within AI systems, contrasting
it with traditional data erasure methods. We introduce Forgotten by Design, a
proactive approach to privacy preservation that integrates instance-specific
obfuscation techniques during the AI model training process. Unlike machine
unlearning, which modifies models post-training, our method prevents sensitive
data from being embedded in the first place. Using the LIRA membership
inference attack, we identify vulnerable data points and propose defenses that
combine additive gradient noise and weighting schemes. Our experiments on the
CIFAR-10 dataset demonstrate that our techniques reduce privacy risks by at
least an order of magnitude while maintaining model accuracy (at 95%
significance). Additionally, we present visualization methods for the
privacy-utility trade-off, providing a clear framework for balancing privacy
risk and model accuracy. This work contributes to the development of
privacy-preserving AI systems that align with human cognitive processes of
motivated forgetting, offering a robust framework for safeguarding sensitive
information and ensuring compliance with privacy regulations.

摘要：隱私權利在各種人權宣言中受到保障，在人工智慧（AI）時代面臨新的挑戰。本文探討人工智慧系統中的被遺忘權（RTBF）概念，並將其與傳統數據刪除方法進行對比。我們引入了「設計中的遺忘」，一種主動的隱私保護方法，在人工智慧模型訓練過程中整合了特定實例的模糊化技術。與訓練後修改模型的機器去學習不同，我們的這種方法可防止敏感數據從一開始就被嵌入。使用 LIRA 會員推論攻擊，我們識別出易受攻擊的數據點，並提出結合加性梯度噪聲和加權方案的防禦措施。我們在 CIFAR-10 數據集上的實驗表明，我們的技術可將隱私風險降低至少一個數量級，同時維持模型準確度（顯著性為 95%）。此外，我們提出隱私效用權衡的可視化方法，提供了一個平衡隱私風險和模型準確度的清晰框架。這項工作有助於開發符合人類動機遺忘認知過程的隱私保護人工智慧系統，提供一個強大的框架來保護敏感資訊並確保符合隱私法規。

##### **Dialect2SQL: A Novel Text-to-SQL Dataset for Arabic Dialects with a Focus on Moroccan Darija**
2501.11498v1 by Salmane Chafik, Saad Ezzini, Ismail Berrada

The task of converting natural language questions (NLQs) into executable SQL
queries, known as text-to-SQL, has gained significant interest in recent years,
as it enables non-technical users to interact with relational databases. Many
benchmarks, such as SPIDER and WikiSQL, have contributed to the development of
new models and the evaluation of their performance. In addition, other
datasets, like SEDE and BIRD, have introduced more challenges and complexities
to better map real-world scenarios. However, these datasets primarily focus on
high-resource languages such as English and Chinese. In this work, we introduce
Dialect2SQL, the first large-scale, cross-domain text-to-SQL dataset in an
Arabic dialect. It consists of 9,428 NLQ-SQL pairs across 69 databases in
various domains. Along with SQL-related challenges such as long schemas, dirty
values, and complex queries, our dataset also incorporates the complexities of
the Moroccan dialect, which is known for its diverse source languages, numerous
borrowed words, and unique expressions. This demonstrates that our dataset will
be a valuable contribution to both the text-to-SQL community and the
development of resources for low-resource languages.

摘要：將自然語言問題 (NLQ) 轉換為可執行的 SQL 查詢（稱為文字轉 SQL）的任務在近年來獲得顯著的關注，因為它讓非技術使用者能夠與關係資料庫互動。許多基準，例如 SPIDER 和 WikiSQL，對新模型的開發和其效能評估有貢獻。此外，其他資料集，例如 SEDE 和 BIRD，引入了更多挑戰和複雜性，以更好地對應真實世界的場景。然而，這些資料集主要關注高資源語言，例如英語和中文。在這項工作中，我們介紹 Dialect2SQL，這是第一個大型、跨領域的阿拉伯方言文字轉 SQL 資料集。它包含 69 個不同領域資料庫中的 9,428 個 NLQ-SQL 對。除了 SQL 相關的挑戰，例如長模式、髒值和複雜查詢，我們的資料集還納入了摩洛哥方言的複雜性，摩洛哥方言以其多樣的原始語言、大量的借用詞和獨特的表達方式而聞名。這表示我們的資料集將對文字轉 SQL 社群和低資源語言資源的開發做出寶貴的貢獻。

##### **Generative AI and Large Language Models in Language Preservation: Opportunities and Challenges**
2501.11496v1 by Vincent Koc

Generative AI and large-scale language models (LLM) have emerged as powerful
tools in language preservation, particularly for near-native and endangered
languages. With the increasing reliance on technology for communication,
education, and cultural documentation, new opportunities have emerged to
mitigate the dramatic decline of linguistic diversity worldwide. This paper
examines the role of generative AIs and LLMs in preserving endangered
languages, highlighting the risks and challenges associated with their use. We
analyze the underlying technologies driving these models, including natural
language processing (NLP) and deep learning, and explore several cases where
these technologies have been applied to low-resource languages. Additionally,
we discuss ethical considerations, data scarcity issues, and technical
challenges while proposing solutions to enhance AI-driven language
preservation.

摘要：生成式 AI 與大型語言模型 (LLM) 已成為語言保存的有力工具，特別是對於接近母語和瀕臨滅絕的語言。隨著越來越依賴技術進行溝通、教育和文化記錄，已出現新的機會來減輕全球語言多樣性的急劇下降。本文探討了生成式 AI 和 LLM 在保護瀕臨滅絕的語言中所扮演的角色，並強調了與其使用相關的風險和挑戰。我們分析了驅動這些模型的基礎技術，包括自然語言處理 (NLP) 和深度學習，並探討了這些技術應用於低資源語言的幾個案例。此外，我們在提出增強 AI 驅動的語言保存的解決方案時，討論了道德考量、資料稀少問題和技術挑戰。

##### **Communication-Efficient Federated Learning Based on Explanation-Guided Pruning for Remote Sensing Image Classification**
2501.11493v1 by Jonas Klotz, Barış Büyüktaş, Begüm Demir

Federated learning (FL) is a decentralized machine learning paradigm, where
multiple clients collaboratively train a global model by exchanging only model
updates with the central server without sharing the local data of clients. Due
to the large volume of model updates required to be transmitted between clients
and the central server, most FL systems are associated with high transfer costs
(i.e., communication overhead). This issue is more critical for operational
applications in remote sensing (RS), especially when large-scale RS data is
processed and analyzed through FL systems with restricted communication
bandwidth. To address this issue, we introduce an explanation-guided pruning
strategy for communication-efficient FL in the context of RS image
classification. Our pruning strategy is defined based on the layerwise
relevance propagation (LRP) driven explanations to: 1) efficiently and
effectively identify the most relevant and informative model parameters (to be
exchanged between clients and the central server); and 2) eliminate the
non-informative ones to minimize the volume of model updates. The experimental
results on the BigEarthNet-S2 dataset demonstrate that our strategy effectively
reduces the number of shared model updates, while increasing the generalization
ability of the global model. The code of this work will be publicly available
at https://git.tu-berlin.de/rsim/FL-LRP

摘要：聯邦學習 (FL) 是一種分散式機器學習範例，其中多個用戶透過僅與中央伺服器交換模型更新，在不共用用戶端本地資料的情況下，共同訓練一個全球模型。由於用戶端與中央伺服器之間需要傳輸大量的模型更新，因此大多數 FL 系統都與高傳輸成本（即通訊負擔）有關。這個問題對於遙測 (RS) 中的運作應用程式來說更為嚴峻，特別是在透過通訊頻寬受限的 FL 系統處理和分析大規模 RS 資料時。為了解決這個問題，我們在 RS 影像分類的脈絡中，提出了一個由解釋引導的剪枝策略，以實現通訊效率高的 FL。我們的剪枝策略是根據由層級相關性傳播 (LRP) 驅動的解釋來定義的，目的是：1) 有效且高效率地找出最相關且具有資訊性的模型參數（在用戶端與中央伺服器之間交換）；以及 2) 消除非資訊性的參數，以最小化模型更新的數量。在 BigEarthNet-S2 資料集上的實驗結果證明，我們的策略有效減少了共用模型更新的數量，同時增加了全球模型的泛化能力。這項工作的程式碼將在 https://git.tu-berlin.de/rsim/FL-LRP 公開。

##### **Graph-defined Language Learning with LLMs**
2501.11478v1 by Huachi Zhou, Jiahe Du, Chuang Zhou, Chang Yang, Yilin Xiao, Yuxuan Xie, Xiao Huang

Recent efforts leverage Large Language Models (LLMs) for modeling
text-attributed graph structures in node classification tasks. These approaches
describe graph structures for LLMs to understand or aggregate LLM-generated
textual attribute embeddings through graph structure. However, these approaches
face two main limitations in modeling graph structures with LLMs. (i) Graph
descriptions become verbose in describing high-order graph structure. (ii)
Textual attributes alone do not contain adequate graph structure information.
It is challenging to model graph structure concisely and adequately with LLMs.
LLMs lack built-in mechanisms to model graph structures directly. They also
struggle with complex long-range dependencies between high-order nodes and
target nodes.
  Inspired by the observation that LLMs pre-trained on one language can achieve
exceptional performance on another with minimal additional training, we propose
\textbf{G}raph-\textbf{D}efined \textbf{L}anguage for \textbf{L}arge
\textbf{L}anguage \textbf{M}odel (GDL4LLM). This novel framework enables LLMs
to transfer their powerful language understanding capabilities to
graph-structured data. GDL4LLM translates graphs into a graph language corpus
instead of graph descriptions and pre-trains LLMs on this corpus to adequately
understand graph structures. During fine-tuning, this corpus describes the
structural information of target nodes concisely with only a few tokens. By
treating graphs as a new language, GDL4LLM enables LLMs to model graph
structures adequately and concisely for node classification tasks. Extensive
experiments on three real-world datasets demonstrate that GDL4LLM outperforms
description-based and textual attribute embeddings-based baselines by
efficiently modeling different orders of graph structure with LLMs.

摘要：<paragraph>最近的研究利用大型語言模型 (LLM) 在節點分類任務中對文本屬性圖結構進行建模。這些方法描述圖結構，讓 LLM 了解或彙總通過圖結構生成的 LLM 文本屬性嵌入。然而，這些方法在使用 LLM 對圖結構進行建模時面臨兩個主要限制。(i) 圖描述在描述高階圖結構時變得冗長。(ii) 僅文本屬性不包含足夠的圖結構資訊。使用 LLM 對圖結構進行簡潔且充分的建模具有挑戰性。LLM 缺乏內建機制來直接對圖結構進行建模。它們還難以處理高階節點和目標節點之間複雜的長程依賴關係。
受 LLM 在一種語言上進行預訓練後，利用最少的額外訓練就能在另一種語言上取得非凡表現的觀察啟發，我們提出了大型語言模型的圖定義語言 (GDL4LLM)。這個新穎的框架使 LLM 能將其強大的語言理解能力轉移到圖結構資料。GDL4LLM 將圖形轉換成圖形語言語料庫，而不是圖形描述，並在這個語料庫上對 LLM 進行預訓練，以充分理解圖形結構。在微調過程中，這個語料庫僅使用少數幾個標記，就能簡潔地描述目標節點的結構資訊。透過將圖形視為一種新的語言，GDL4LLM 使 LLM 能夠充分且簡潔地為節點分類任務對圖形結構進行建模。在三個真實世界資料集上進行的廣泛實驗證明，GDL4LLM 能有效地使用 LLM 對不同順序的圖形結構進行建模，從而優於基於描述和基於文本屬性嵌入的基準。</paragraph>

##### **Curiosity-Driven Reinforcement Learning from Human Feedback**
2501.11463v1 by Haoran Sun, Yekun Chai, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang

Reinforcement learning from human feedback (RLHF) has proven effective in
aligning large language models (LLMs) with human preferences, but often at the
cost of reduced output diversity. This trade-off between diversity and
alignment quality remains a significant challenge. Drawing inspiration from
curiosity-driven exploration in reinforcement learning, we introduce
curiosity-driven RLHF (CD-RLHF), a framework that incorporates intrinsic
rewards for novel states, alongside traditional sparse extrinsic rewards, to
optimize both output diversity and alignment quality. We demonstrate the
effectiveness of CD-RLHF through extensive experiments on a range of tasks,
including text summarization and instruction following. Our approach achieves
significant gains in diversity on multiple diversity-oriented metrics while
maintaining alignment with human preferences comparable to standard RLHF. We
make our code publicly available at https://github.com/ernie-research/CD-RLHF.

摘要：透過人類回饋的強化學習 (RLHF) 已被證實能有效地將大型語言模型 (LLM) 與人類偏好對齊，但通常會犧牲輸出多樣性。這種多樣性和對齊品質之間的取捨仍然是一項重大的挑戰。從強化學習中的好奇心驅動探索中汲取靈感，我們引入了好奇心驅動的 RLHF (CD-RLHF)，一個框架，它結合了對新狀態的內在獎勵，以及傳統的稀疏外在獎勵，以同時最佳化輸出多樣性和對齊品質。我們透過一系列任務的廣泛實驗，包括文字摘要和指令遵循，來展示 CD-RLHF 的有效性。我們的做法在多個以多樣性為導向的指標上達到了顯著的多樣性提升，同時維持與人類偏好的對齊，這與標準 RLHF 相當。我們在 https://github.com/ernie-research/CD-RLHF 公開我們的程式碼。

##### **Improving thermal state preparation of Sachdev-Ye-Kitaev model with reinforcement learning on quantum hardware**
2501.11454v1 by Akash Kundu

The Sachdev-Ye-Kitaev (SYK) model, known for its strong quantum correlations
and chaotic behavior, serves as a key platform for quantum gravity studies.
However, variationally preparing thermal states on near-term quantum processors
for large systems (N>12, where N is the number of Majorana fermions) presents a
significant challenge due to the rapid growth in the complexity of
parameterized quantum circuits. This paper addresses this challenge by
integrating reinforcement learning (RL) with convolutional neural networks,
employing an iterative approach to optimize the quantum circuit and its
parameters. The refinement process is guided by a composite reward signal
derived from entropy and the expectation values of the SYK Hamiltonian. This
approach reduces the number of CNOT gates by two orders of magnitude for
systems N>10 compared to traditional methods like first-order Trotterization.
We demonstrate the effectiveness of the RL framework in both noiseless and
noisy quantum hardware environments, maintaining high accuracy in thermal state
preparation. This work contributes to the advancement of a scalable, RL-based
framework with applications for computations of thermal out-of-time-order
correlators in quantum many-body systems and quantum gravity studies on
near-term quantum hardware.

摘要：薩奇德夫-葉-基泰夫（SYK）模型以其強烈的量子關聯性和混亂行為而聞名，可用作量子重力研究的一個關鍵平台。
然而，在近期的量子處理器上為大型系統（N>12，其中 N 是馬約拉那費米子的數量）準備變分熱態是一個重大挑戰，因為參數化量子電路的複雜性會迅速增加。
本文通過將強化學習（RL）與卷積神經網路整合，採用迭代方法來優化量子電路及其參數，從而應對這一挑戰。
優化過程由一個複合獎勵信號引導，該信號來自熵和 SYK 哈密頓量的期望值。
與一階 Trotterization 等傳統方法相比，這種方法將 N>10 系統的 CNOT 門數量減少了兩個數量級。
我們在無噪聲和有噪聲量子硬體環境中展示了 RL 框架的有效性，在熱態準備中保持了高精度。
這項工作有助於推動基於 RL 的可擴充套件框架的發展，該框架可應用於量子多體系統中的熱態時間順序外相關器的計算和近程量子硬體上的量子重力研究。

##### **Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components**
2501.11447v1 by Abel Jansma

We introduce a novel framework for decomposing interventional causal effects
into synergistic, redundant, and unique components, building on the intuition
of Partial Information Decomposition (PID) and the principle of M\"obius
inversion. While recent work has explored a similar decomposition of an
observational measure, we argue that a proper causal decomposition must be
interventional in nature. We develop a mathematical approach that
systematically quantifies how causal power is distributed among variables in a
system, using a recently derived closed-form expression for the M\"obius
function of the redundancy lattice. The formalism is then illustrated by
decomposing the causal power in logic gates, cellular automata, and chemical
reaction networks. Our results reveal how the distribution of causal power can
be context- and parameter-dependent. This decomposition provides new insights
into complex systems by revealing how causal influences are shared and combined
among multiple variables, with potential applications ranging from attribution
of responsibility in legal or AI systems, to the analysis of biological
networks or climate models.

摘要：我們引進一個新穎的架構，用來將介入因果關係分解為協同、冗餘和獨特成分，建立在局部資訊分解 (PID) 的直覺和莫比烏斯反演原理之上。雖然最近的研究探索了觀測測量的類似分解，我們主張適當的因果分解本質上必須是介入的。我們開發了一種數學方法，系統性地量化因果力如何在系統中的變數間分配，使用最近衍生的冗餘格的莫比烏斯函數閉合形式表達式。形式主義隨後透過分解邏輯閘、細胞自動機和化學反應網路中的因果力來說明。我們的結果揭示了因果力的分配如何可能是依賴於脈絡和參數的。這個分解透過揭示因果影響如何在多個變數間共享和組合，提供了對複雜系統的新見解，潛在應用從法律或 AI 系統中責任的歸屬，到生物網路或氣候模型的分析。

