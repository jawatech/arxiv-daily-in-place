
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-16**|**xGen-MM (BLIP-3): A Family of Open Large Multimodal Models**|Le Xue et.al.|[2408.08872v1](http://arxiv.org/abs/2408.08872v1)|null|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869v1](http://arxiv.org/abs/2408.08869v1)|null|
|**2024-08-16**|**GeoTransformer: Enhancing Urban Forecasting with Geospatial Attention Mechanisms**|Yuhao Jia et.al.|[2408.08852v1](http://arxiv.org/abs/2408.08852v1)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848v1](http://arxiv.org/abs/2408.08848v1)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841v1](http://arxiv.org/abs/2408.08841v1)|null|
|**2024-08-16**|**EasyRec: Simple yet Effective Language Models for Recommendation**|Xubin Ren et.al.|[2408.08821v1](http://arxiv.org/abs/2408.08821v1)|[link](https://github.com/hkuds/easyrec)|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808v1](http://arxiv.org/abs/2408.08808v1)|null|
|**2024-08-16**|**CIKMar: A Dual-Encoder Approach to Prompt-Based Reranking in Educational Dialogue Systems**|Joanito Agili Lopo et.al.|[2408.08805v1](http://arxiv.org/abs/2408.08805v1)|null|
|**2024-08-16**|**Leveraging FourierKAN Classification Head for Pre-Trained Transformer-based Text Classification**|Abdullah Al Imran et.al.|[2408.08803v1](http://arxiv.org/abs/2408.08803v1)|null|
|**2024-08-16**|**A Disease-Specific Foundation Model Using Over 100K Fundus Images: Release and Validation for Abnormality and Multi-Disease Classification on Downstream Tasks**|Boa Jang et.al.|[2408.08790v1](http://arxiv.org/abs/2408.08790v1)|null|
|**2024-08-16**|**A Transparency Paradox? Investigating the Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies on Passengers**|Daniel Omeiza et.al.|[2408.08785v1](http://arxiv.org/abs/2408.08785v1)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782v1](http://arxiv.org/abs/2408.08782v1)|null|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781v1](http://arxiv.org/abs/2408.08781v1)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780v1](http://arxiv.org/abs/2408.08780v1)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779v1](http://arxiv.org/abs/2408.08779v1)|null|
|**2024-08-16**|**Pessimistic Iterative Planning for Robust POMDPs**|Maris F. L. Galesloot et.al.|[2408.08770v1](http://arxiv.org/abs/2408.08770v1)|null|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769v1](http://arxiv.org/abs/2408.08769v1)|null|
|**2024-08-16**|**ASVspoof 5: Crowdsourced Speech Data, Deepfakes, and Adversarial Attacks at Scale**|Xin Wang et.al.|[2408.08739v1](http://arxiv.org/abs/2408.08739v1)|null|
|**2024-08-16**|**ChatZero:Zero-shot Cross-Lingual Dialogue Generation via Pseudo-Target Language**|Yongkang Liu et.al.|[2408.08724v1](http://arxiv.org/abs/2408.08724v1)|null|
|**2024-08-16**|**Beyond KAN: Introducing KarSein for Adaptive High-Order Feature Interaction Modeling in CTR Prediction**|Yunxiao Shi et.al.|[2408.08713v1](http://arxiv.org/abs/2408.08713v1)|null|
|**2024-08-16**|**Beam Prediction based on Large Language Models**|Yucheng Sheng et.al.|[2408.08707v1](http://arxiv.org/abs/2408.08707v1)|null|
|**2024-08-16**|**Beyond the Hype: A dispassionate look at vision-language models in medical scenario**|Yang Nan et.al.|[2408.08704v1](http://arxiv.org/abs/2408.08704v1)|null|
|**2024-08-16**|**NFDI4DSO: Towards a BFO Compliant Ontology for Data Science**|Genet Asefa Gesese et.al.|[2408.08698v1](http://arxiv.org/abs/2408.08698v1)|null|
|**2024-08-16**|**Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling**|Xianzhen Luo et.al.|[2408.08696v1](http://arxiv.org/abs/2408.08696v1)|null|
|**2024-08-16**|**Quantifying the Effectiveness of Student Organization Activities using Natural Language Processing**|Lyberius Ennio F. Taruc et.al.|[2408.08694v1](http://arxiv.org/abs/2408.08694v1)|null|
|**2024-08-16**|**Med-PMC: Medical Personalized Multi-modal Consultation with a Proactive Ask-First-Observe-Next Paradigm**|Hongcheng Liu et.al.|[2408.08693v1](http://arxiv.org/abs/2408.08693v1)|[link](https://github.com/liuhc0428/med-pmc)|
|**2024-08-16**|**The Fellowship of the LLMs: Multi-Agent Workflows for Synthetic Preference Optimization Dataset Generation**|Samee Arif et.al.|[2408.08688v1](http://arxiv.org/abs/2408.08688v1)|null|
|**2024-08-16**|**SC-Rec: Enhancing Generative Retrieval with Self-Consistent Reranking for~Sequential Recommendation**|Tongyoung Kim et.al.|[2408.08686v1](http://arxiv.org/abs/2408.08686v1)|null|
|**2024-08-16**|**Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?**|Zhongjian Zhang et.al.|[2408.08685v1](http://arxiv.org/abs/2408.08685v1)|null|
|**2024-08-16**|**LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression**|Yuqi Ye et.al.|[2408.08682v1](http://arxiv.org/abs/2408.08682v1)|null|
|**2024-08-16**|**Fine-tuning LLMs for Autonomous Spacecraft Control: A Case Study Using Kerbal Space Program**|Alejandro Carrasco et.al.|[2408.08676v1](http://arxiv.org/abs/2408.08676v1)|[link](https://github.com/arclab-mit/kspdg)|
|**2024-08-16**|**MAT-SED: AMasked Audio Transformer with Masked-Reconstruction Based Pre-training for Sound Event Detection**|Pengfei Cai et.al.|[2408.08673v1](http://arxiv.org/abs/2408.08673v1)|null|
|**2024-08-16**|**Adaptive Layer Selection for Efficient Vision Transformer Fine-Tuning**|Alessio Devoto et.al.|[2408.08670v1](http://arxiv.org/abs/2408.08670v1)|null|
|**2024-08-16**|**MIA-Tuner: Adapting Large Language Models as Pre-training Text Detector**|Wenjie Fu et.al.|[2408.08661v1](http://arxiv.org/abs/2408.08661v1)|null|
|**2024-08-16**|**LLMs Are Biased Towards Output Formats! Systematically Evaluating and Mitigating Output Format Bias of LLMs**|Do Xuan Long et.al.|[2408.08656v1](http://arxiv.org/abs/2408.08656v1)|null|
|**2024-08-16**|**Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons**|Binbin Ding et.al.|[2408.08655v1](http://arxiv.org/abs/2408.08655v1)|null|
|**2024-08-16**|**TextCAVs: Debugging vision models using text**|Angus Nicolson et.al.|[2408.08652v1](http://arxiv.org/abs/2408.08652v1)|[link](https://github.com/angusnicolson/textcavs)|
|**2024-08-16**|**Reasoning Beyond Bias: A Study on Counterfactual Prompting and Chain of Thought Reasoning**|Kyle Moore et.al.|[2408.08651v1](http://arxiv.org/abs/2408.08651v1)|null|
|**2024-08-16**|**An End-to-End Model for Photo-Sharing Multi-modal Dialogue Generation**|Peiming Guo et.al.|[2408.08650v1](http://arxiv.org/abs/2408.08650v1)|null|
|**2024-08-16**|**Understanding Enthymemes in Argument Maps: Bridging Argument Mining and Logic-based Argumentation**|Jonathan Ben-Naim et.al.|[2408.08648v1](http://arxiv.org/abs/2408.08648v1)|null|
|**2024-08-16**|**Math-PUMA: Progressive Upward Multimodal Alignment to Enhance Mathematical Reasoning**|Wenwen Zhuang et.al.|[2408.08640v1](http://arxiv.org/abs/2408.08640v1)|null|
|**2024-08-16**|**A Survey on Benchmarks of Multimodal Large Language Models**|Jian Li et.al.|[2408.08632v1](http://arxiv.org/abs/2408.08632v1)|[link](https://github.com/swordlidev/evaluation-multimodal-llms-survey)|
|**2024-08-16**|**Persona is a Double-edged Sword: Enhancing the Zero-shot Reasoning by Ensembling the Role-playing and Neutral Prompts**|Junseok Kim et.al.|[2408.08631v1](http://arxiv.org/abs/2408.08631v1)|null|
|**2024-08-16**|**RealMedQA: A pilot biomedical question answering dataset containing realistic clinical questions**|Gregory Kell et.al.|[2408.08624v1](http://arxiv.org/abs/2408.08624v1)|null|
|**2024-08-16**|**DeepDFA: Automata Learning through Neural Probabilistic Relaxations**|Elena Umili et.al.|[2408.08622v1](http://arxiv.org/abs/2408.08622v1)|[link](https://github.com/whitemech/deepdfa)|
|**2024-08-16**|**PatUntrack: Automated Generating Patch Examples for Issue Reports without Tracked Insecure Code**|Ziyou Jiang et.al.|[2408.08619v1](http://arxiv.org/abs/2408.08619v1)|null|
|**2024-08-16**|**Generative Dataset Distillation Based on Diffusion Model**|Duo Su et.al.|[2408.08610v1](http://arxiv.org/abs/2408.08610v1)|[link](https://github.com/guang000/banko)|
|**2024-08-16**|**MM-UNet: A Mixed MLP Architecture for Improved Ophthalmic Image Segmentation**|Zunjie Xiao et.al.|[2408.08600v1](http://arxiv.org/abs/2408.08600v1)|null|
|**2024-08-16**|**A Mechanistic Interpretation of Syllogistic Reasoning in Auto-Regressive Language Models**|Geonhee Kim et.al.|[2408.08590v1](http://arxiv.org/abs/2408.08590v1)|null|
|**2024-08-16**|**AgentSimulator: An Agent-based Approach for Data-driven Business Process Simulation**|Lukas Kirchdorfer et.al.|[2408.08571v1](http://arxiv.org/abs/2408.08571v1)|[link](https://github.com/lukaskirchdorfer/agentsimulator)|
|**2024-08-16**|**Overview of the BioLaySumm 2024 Shared Task on the Lay Summarization of Biomedical Research Articles**|Tomas Goldsack et.al.|[2408.08566v1](http://arxiv.org/abs/2408.08566v1)|null|
|**2024-08-16**|**Collaborative Cross-modal Fusion with Large Language Model for Recommendation**|Zhongzhou Liu et.al.|[2408.08564v1](http://arxiv.org/abs/2408.08564v1)|null|
|**2024-08-16**|**Integrating Multi-view Analysis: Multi-view Mixture-of-Expert for Textual Personality Detection**|Haohao Zhu et.al.|[2408.08551v1](http://arxiv.org/abs/2408.08551v1)|null|
|**2024-08-16**|**SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language Models**|Kaushal Kumar Maurya et.al.|[2408.08545v1](http://arxiv.org/abs/2408.08545v1)|null|
|**2024-08-16**|**Where is the signal in tokenization space?**|Renato Lui Geh et.al.|[2408.08541v1](http://arxiv.org/abs/2408.08541v1)|null|
|**2024-08-16**|**CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**|Rong-Ching Chang et.al.|[2408.08535v1](http://arxiv.org/abs/2408.08535v1)|null|
|**2024-08-16**|**Detecting Unsuccessful Students in Cybersecurity Exercises in Two Different Learning Environments**|Valdemar Švábenský et.al.|[2408.08531v1](http://arxiv.org/abs/2408.08531v1)|null|
|**2024-08-16**|**Focus on Focus: Focus-oriented Representation Learning and Multi-view Cross-modal Alignment for Glioma Grading**|Li Pan et.al.|[2408.08527v1](http://arxiv.org/abs/2408.08527v1)|[link](https://github.com/peterlipan/fof)|
|**2024-08-16**|**Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding**|Huang Lei et.al.|[2408.08506v1](http://arxiv.org/abs/2408.08506v1)|null|
|**2024-08-16**|**Adversarial Contrastive Learning Based Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation**|Rui Wang et.al.|[2408.08488v1](http://arxiv.org/abs/2408.08488v1)|null|
|**2024-08-16**|**An Unsupervised Learning Framework Combined with Heuristics for the Maximum Minimal Cut Problem**|Huaiyuan Liu et.al.|[2408.08484v1](http://arxiv.org/abs/2408.08484v1)|[link](https://github.com/luckyseasalt/pioneer)|
|**2024-08-16**|**Fairness Issues and Mitigations in (Differentially Private) Socio-demographic Data Processes**|Joonhyuk Ko et.al.|[2408.08471v1](http://arxiv.org/abs/2408.08471v1)|null|
|**2024-08-16**|**Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models**|Jerry Huang et.al.|[2408.08470v1](http://arxiv.org/abs/2408.08470v1)|null|
|**2024-08-16**|**A theory of understanding for artificial intelligence: composability, catalysts, and learning**|Zijian Zhang et.al.|[2408.08463v1](http://arxiv.org/abs/2408.08463v1)|null|
|**2024-08-15**|**JPEG-LM: LLMs as Image Generators with Canonical Codec Representations**|Xiaochuang Han et.al.|[2408.08459v1](http://arxiv.org/abs/2408.08459v1)|null|
|**2024-08-15**|**Efficient Data-Sketches and Fine-Tuning for Early Detection of Distributional Drift in Medical Imaging**|Yusen Wu et.al.|[2408.08456v1](http://arxiv.org/abs/2408.08456v1)|null|
|**2024-08-15**|**SpectralEarth: Training Hyperspectral Foundation Models at Scale**|Nassim Ait Ali Braham et.al.|[2408.08447v1](http://arxiv.org/abs/2408.08447v1)|null|
|**2024-08-15**|**W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering**|Jinming Nian et.al.|[2408.08444v1](http://arxiv.org/abs/2408.08444v1)|[link](https://github.com/jmnian/weak_label_for_rag)|
|**2024-08-15**|**PQV-Mobile: A Combined Pruning and Quantization Toolkit to Optimize Vision Transformers for Mobile Applications**|Kshitij Bhardwaj et.al.|[2408.08437v1](http://arxiv.org/abs/2408.08437v1)|null|
|**2024-08-15**|**Automated Design of Agentic Systems**|Shengran Hu et.al.|[2408.08435v1](http://arxiv.org/abs/2408.08435v1)|[link](https://github.com/shengranhu/adas)|
|**2024-08-15**|**Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts**|Abdur R. Fayjie et.al.|[2408.08432v1](http://arxiv.org/abs/2408.08432v1)|null|
|**2024-08-15**|**Multi-Modal Dialogue State Tracking for Playing GuessWhich Game**|Wei Pang et.al.|[2408.08431v1](http://arxiv.org/abs/2408.08431v1)|[link](https://github.com/xubuvd/guesswhich)|
|**2024-08-15**|**Assessing and Enhancing Large Language Models in Rare Disease Question-answering**|Guanchu Wang et.al.|[2408.08422v1](http://arxiv.org/abs/2408.08422v1)|null|
|**2024-08-15**|**Understanding Help-Seeking Behavior of Students Using LLMs vs. Web Search for Writing SQL Queries**|Harsh Kumar et.al.|[2408.08401v1](http://arxiv.org/abs/2408.08401v1)|null|
|**2024-08-15**|**Zero-Shot Learning and Key Points Are All You Need for Automated Fact-Checking**|Mohammad Ghiasvand Mohammadkhani et.al.|[2408.08400v1](http://arxiv.org/abs/2408.08400v1)|null|
|**2024-08-15**|**Level Up Your Tutorials: VLMs for Game Tutorials Quality Assessment**|Daniele Rege Cambrin et.al.|[2408.08396v1](http://arxiv.org/abs/2408.08396v1)|null|
|**2024-08-15**|**Towards Realistic Synthetic User-Generated Content: A Scaffolding Approach to Generating Online Discussions**|Krisztian Balog et.al.|[2408.08379v1](http://arxiv.org/abs/2408.08379v1)|null|
|**2024-08-15**|**Decoding the human brain tissue response to radiofrequency excitation using a biophysical-model-free deep MRI on a chip framework**|Dinor Nagar et.al.|[2408.08376v1](http://arxiv.org/abs/2408.08376v1)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313v1](http://arxiv.org/abs/2408.08313v1)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310v1](http://arxiv.org/abs/2408.08310v1)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302v1](http://arxiv.org/abs/2408.08302v1)|null|
|**2024-08-15**|**SLCA++: Unleash the Power of Sequential Fine-tuning for Continual Learning with Pre-training**|Gengwei Zhang et.al.|[2408.08295v1](http://arxiv.org/abs/2408.08295v1)|[link](https://github.com/gengdavid/slca)|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291v1](http://arxiv.org/abs/2408.08291v1)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282v1](http://arxiv.org/abs/2408.08282v1)|null|
|**2024-08-15**|**InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models**|Guoxiang Grayson Tong et.al.|[2408.08264v1](http://arxiv.org/abs/2408.08264v1)|[link](https://github.com/desreslab/invaert4cardio)|
|**2024-08-15**|**mhGPT: A Lightweight Generative Pre-Trained Transformer for Mental Health Text Analysis**|Dae-young Kim et.al.|[2408.08261v1](http://arxiv.org/abs/2408.08261v1)|null|
|**2024-08-15**|**Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding**|Xiner Li et.al.|[2408.08252v1](http://arxiv.org/abs/2408.08252v1)|null|
|**2024-08-15**|**A Conflicts-free, Speed-lossless KAN-based Reinforcement Learning Decision System for Interactive Driving in Roundabouts**|Zhihao Lin et.al.|[2408.08242v1](http://arxiv.org/abs/2408.08242v1)|null|
|**2024-08-15**|**Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction**|Yuqicheng Zhu et.al.|[2408.08226v1](http://arxiv.org/abs/2408.08226v1)|null|
|**2024-08-15**|**The Dawn of KAN in Image-to-Image (I2I) Translation: Integrating Kolmogorov-Arnold Networks with GANs for Unpaired I2I Translation**|Arpan Mahara et.al.|[2408.08216v1](http://arxiv.org/abs/2408.08216v1)|null|
|**2024-08-15**|**Moving Healthcare AI-Support Systems for Visually Detectable Diseases onto Constrained Devices**|Tess Watt et.al.|[2408.08215v1](http://arxiv.org/abs/2408.08215v1)|null|
|**2024-08-15**|**Federated Fairness Analytics: Quantifying Fairness in Federated Learning**|Oscar Dilley et.al.|[2408.08214v1](http://arxiv.org/abs/2408.08214v1)|[link](https://github.com/oscardilley/federated-fairness)|
|**2024-08-15**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212v2](http://arxiv.org/abs/2408.08212v2)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208v1](http://arxiv.org/abs/2408.08208v1)|null|
|**2024-08-15**|**API-guided Dataset Synthesis to Finetune Large Code Models**|Zongjie Li et.al.|[2408.08343v1](http://arxiv.org/abs/2408.08343v1)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188v1](http://arxiv.org/abs/2408.08188v1)|null|
|**2024-08-15**|**Your Turn: Real-World Turning Angle Estimation for Parkinson's Disease Severity Assessment**|Qiushuo Cheng et.al.|[2408.08182v1](http://arxiv.org/abs/2408.08182v1)|null|
|**2024-08-15**|**Towards flexible perception with visual memory**|Robert Geirhos et.al.|[2408.08172v1](http://arxiv.org/abs/2408.08172v1)|null|
|**2024-08-15**|**General-purpose Clothes Manipulation with Semantic Keypoints**|Yuhong Deng et.al.|[2408.08160v1](http://arxiv.org/abs/2408.08160v1)|null|
|**2024-08-15**|**DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search**|Huajian Xin et.al.|[2408.08152v1](http://arxiv.org/abs/2408.08152v1)|[link](https://github.com/deepseek-ai/deepseek-prover-v1.5)|

#### Abstracts
##### **xGen-MM (BLIP-3): A Family of Open Large Multimodal Models**
2408.08872v1 by Le Xue, Manli Shu, Anas Awadalla, Jun Wang, An Yan, Senthil Purushwalkam, Honglu Zhou, Viraj Prabhu, Yutong Dai, Michael S Ryoo, Shrikant Kendre, Jieyu Zhang, Can Qin, Shu Zhang, Chia-Chih Chen, Ning Yu, Juntao Tan, Tulika Manoj Awalgaonkar, Shelby Heinecke, Huan Wang, Yejin Choi, Ludwig Schmidt, Zeyuan Chen, Silvio Savarese, Juan Carlos Niebles, Caiming Xiong, Ran Xu

This report introduces xGen-MM (also known as BLIP-3), a framework for
developing Large Multimodal Models (LMMs). The framework comprises meticulously
curated datasets, a training recipe, model architectures, and a resulting suite
of LMMs. xGen-MM, short for xGen-MultiModal, expands the Salesforce xGen
initiative on foundation AI models. Our models undergo rigorous evaluation
across a range of tasks, including both single and multi-image benchmarks. Our
pre-trained base model exhibits strong in-context learning capabilities and the
instruction-tuned model demonstrates competitive performance among open-source
LMMs with similar model sizes. In addition, we introduce a safety-tuned model
with DPO, aiming to mitigate harmful behaviors such as hallucinations and
improve safety. We open-source our models, curated large-scale datasets, and
our fine-tuning codebase to facilitate further advancements in LMM research.
Associated resources will be available on our project page above.

摘要：這份報告介紹了 xGen-MM（也稱為 BLIP-3），這是一個用於開發大型多模態模型 (LMM) 的架構。這個架構包含精心策劃的資料集、訓練配方、模型架構和一組產生的 LMM。xGen-MM 是 xGen-MultiModal 的簡稱，它擴展了 Salesforce xGen 在基礎 AI 模型上的計畫。我們的模型經過嚴格的評估，涵蓋一系列任務，包括單一影像和多影像基準。我們預先訓練的基本模型展示了強大的情境學習能力，而經過指令微調的模型則在具有類似模型大小的開源 LMM 中展現了競爭力。此外，我們還引入了使用 DPO 的安全微調模型，旨在減輕幻覺等有害行為並提高安全性。我們開放原始碼模型、策劃大型資料集和微調程式碼庫，以促進 LMM 研究的進一步進展。相關資源將在我們上述的專案頁面中提供。

##### **PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**
2408.08869v1 by Sumanth Prabhu

Self-ensembling techniques with diverse reasoning paths such as
Self-Consistency have demonstrated remarkable gains in accuracy for Large
Language Models (LLMs). However, such techniques depend on the availability of
an accurate answer extraction process to aggregate across multiple outputs.
Moreover, they acquire higher inference cost, in comparison to Greedy Decoding,
due to generation of relatively higher number of output tokens. Research has
shown that the free form text outputs from Self-Consistency can be aggregated
reliably using LLMs to produce the final output. Additionally, recent
advancements in LLM inference have demonstrated that usage of diverse exemplars
in prompts have the ability to induce diversity in the LLM outputs. Such proven
techniques can be easily extended to self-ensembling based approaches to
achieve enhanced results in text generation. In this paper, we introduce PEDAL
(Prompts based on Exemplar Diversity Aggregated using LLMs), a hybrid
self-ensembling approach, that combines the strengths of diverse exemplar based
prompts and LLM based aggregation to achieve improvement in overall
performance. On the publicly available SVAMP and ARC datasets, our experiments
reveal that PEDAL can achieve better accuracy than Greedy Decoding based
strategies with lower inference cost compared to Self Consistency based
approaches.

摘要：利用不同推理路徑（例如自一致性）的自組裝技術已證明大型語言模型 (LLM) 的準確性有顯著的提升。然而，此類技術依賴於準確的答案萃取程序，才能彙總多個輸出。此外，與貪婪解碼相比，它們會產生較高數量的輸出標記，因此會產生較高的推論成本。研究顯示，可以使用 LLM 可靠地彙總來自自一致性的自由形式文字輸出，以產生最終輸出。此外，LLM 推論的最新進展已證明，在提示中使用不同的範例能夠誘導 LLM 輸出的多樣性。此類已驗證的技術可以輕鬆地擴展到基於自組裝的方法，以在文本生成中獲得增強的結果。在本文中，我們介紹了 PEDAL（基於範例多樣性，並使用 LLM 彙總的提示），這是一種混合式自組裝方法，它結合了基於不同範例的提示和基於 LLM 的彙總的優點，以提高整體效能。在公開提供的 SVAMP 和 ARC 資料集上，我們的實驗表明，與基於自一致性的方法相比，PEDAL 可以比基於貪婪解碼的策略獲得更好的準確性，同時具有較低的推論成本。

##### **GeoTransformer: Enhancing Urban Forecasting with Geospatial Attention Mechanisms**
2408.08852v1 by Yuhao Jia, Zile Wu, Shengao Yi, Yifei Sun

Recent advancements have focused on encoding urban spatial information into
high-dimensional spaces, with notable efforts dedicated to integrating
sociodemographic data and satellite imagery. These efforts have established
foundational models in this field. However, the effective utilization of these
spatial representations for urban forecasting applications remains
under-explored. To address this gap, we introduce GeoTransformer, a novel
structure that synergizes the Transformer architecture with geospatial
statistics prior. GeoTransformer employs an innovative geospatial attention
mechanism to incorporate extensive urban information and spatial dependencies
into a unified predictive model. Specifically, we compute geospatial weighted
attention scores between the target region and surrounding regions and leverage
the integrated urban information for predictions. Extensive experiments on GDP
and ride-share demand prediction tasks demonstrate that GeoTransformer
significantly outperforms existing baseline models, showcasing its potential to
enhance urban forecasting tasks.

摘要：近期的進展著重於將城市空間資訊編碼成高維度空間，並致力於整合社會人口統計資料和衛星影像。這些努力為此領域建立了基礎模型。然而，這些空間表徵在城市預測應用中的有效利用仍未充分探討。為了解決這個差距，我們引入了 GeoTransformer，一個新穎的結構，它將 Transformer 架構與地理空間統計資料結合起來。GeoTransformer 採用創新的地理空間注意力機制，將廣泛的城市資訊和空間依賴關係納入一個統一的預測模型中。具體來說，我們計算目標區域和周圍區域之間的地理空間加權注意力分數，並利用整合的城市資訊進行預測。在 GDP 和共乘需求預測任務上的廣泛實驗表明，GeoTransformer 明顯優於現有的基線模型，展示了其增強城市預測任務的潛力。

##### **PsychoLex: Unveiling the Psychological Mind of Large Language Models**
2408.08848v1 by Mohammad Amin Abbasi, Farnaz Sadat Mirnezami, Hassan Naderi

This paper explores the intersection of psychology and artificial
intelligence through the development and evaluation of specialized Large
Language Models (LLMs). We introduce PsychoLex, a suite of resources designed
to enhance LLMs' proficiency in psychological tasks in both Persian and
English. Key contributions include the PsychoLexQA dataset for instructional
content and the PsychoLexEval dataset for rigorous evaluation of LLMs in
complex psychological scenarios. Additionally, we present the PsychoLexLLaMA
model, optimized specifically for psychological applications, demonstrating
superior performance compared to general-purpose models. The findings
underscore the potential of tailored LLMs for advancing psychological research
and applications, while also highlighting areas for further refinement. This
research offers a foundational step towards integrating LLMs into specialized
psychological domains, with implications for future advancements in AI-driven
psychological practice.

摘要：本論文透過開發和評估專門的大型語言模型 (LLM)，探討心理學與人工智慧的交集。我們介紹 PsychoLex，這是一套旨在增強 LLM 在波斯語和英語心理任務中的熟練度的資源。主要貢獻包括用於教學內容的 PsychoLexQA 資料集，以及用於嚴格評估 LLM 在複雜心理情境中的 PsychoLexEval 資料集。此外，我們展示了專門針對心理應用最佳化的 PsychoLexLLaMA 模型，展示了與通用模型相比的卓越效能。這些發現強調了量身打造的 LLM 在推進心理研究和應用方面的潛力，同時也突出了進一步優化的領域。本研究提供了將 LLM 整合到專門心理領域的基本步驟，對未來 AI 驅動的心理實務進展具有影響。

##### **FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**
2408.08841v1 by Xuanliang Zhang, Dingzirui Wang, Longxu Dou, Baoxin Wang, Dayong Wu, Qingfu Zhu, Wanxiang Che

The table reasoning task aims to answer the question according to the given
table. Currently, using Large Language Models (LLMs) is the predominant method
for table reasoning. Most existing methods employ a fixed tabular format to
represent the table, which could limit the performance. Given that each
instance requires different capabilities and models possess varying abilities,
we assert that different instances and models suit different tabular formats.
We prove the aforementioned claim through quantitative analysis of experimental
results, where different instances and models achieve different performances
using various tabular formats. Building on this discussion, we propose
FLEXTAF-Single and FLEXTAF-Vote to enhance table reasoning performance by
employing flexible tabular formats. Specifically, (i) FLEXTAF-Single trains a
classifier to predict the most suitable tabular format based on the instance
and the LLM. (ii) FLEXTAF-Vote integrates the results across different formats.
Our experiments on WikiTableQuestions and TabFact reveal significant
improvements, with average gains of 2.3% and 4.8% compared to the best
performance achieved using a fixed tabular format with greedy decoding and
self-consistency decoding, thereby validating the effectiveness of our methods.

摘要：表格推理任務旨在根據給定的表格回答問題。目前，使用大型語言模型 (LLM) 是表格推理的主要方法。大多數現有方法採用固定的表格格式來表示表格，這可能會限制效能。由於每個實例都需要不同的能力，而模型具備不同的能力，我們斷言不同的實例和模型適合不同的表格格式。我們透過對實驗結果進行量化分析來證明上述說法，其中不同的實例和模型使用不同的表格格式來達成不同的效能。基於此討論，我們提出 FLEXTAF-Single 和 FLEXTAF-Vote 來透過採用彈性的表格格式來增強表格推理效能。具體來說，(i) FLEXTAF-Single 訓練一個分類器來根據實例和 LLM 預測最合適的表格格式。(ii) FLEXTAF-Vote 整合不同格式的結果。我們在 WikiTableQuestions 和 TabFact 上的實驗顯示出顯著的改進，與使用具有貪婪解碼和自一致解碼的固定表格格式所達成的最佳效能相比，平均增益分別為 2.3% 和 4.8%，從而驗證了我們方法的有效性。

##### **EasyRec: Simple yet Effective Language Models for Recommendation**
2408.08821v1 by Xubin Ren, Chao Huang

Deep neural networks have become a powerful technique for learning
representations from user-item interaction data in collaborative filtering (CF)
for recommender systems. However, many existing methods heavily rely on unique
user and item IDs, which limits their ability to perform well in practical
zero-shot learning scenarios where sufficient training data may be unavailable.
Inspired by the success of language models (LMs) and their strong
generalization capabilities, a crucial question arises: How can we harness the
potential of language models to empower recommender systems and elevate its
generalization capabilities to new heights? In this study, we propose EasyRec -
an effective and easy-to-use approach that seamlessly integrates text-based
semantic understanding with collaborative signals. EasyRec employs a
text-behavior alignment framework, which combines contrastive learning with
collaborative language model tuning, to ensure a strong alignment between the
text-enhanced semantic space and the collaborative behavior information.
Extensive empirical evaluations across diverse real-world datasets demonstrate
the superior performance of EasyRec compared to state-of-the-art alternative
models, particularly in the challenging text-based zero-shot recommendation
scenarios. Furthermore, the study highlights the potential of seamlessly
integrating EasyRec as a plug-and-play component into text-enhanced
collaborative filtering frameworks, thereby empowering existing recommender
systems to elevate their recommendation performance and adapt to the evolving
user preferences in dynamic environments. For better result reproducibility of
our EasyRec framework, the model implementation details, source code, and
datasets are available at the link: https://github.com/HKUDS/EasyRec.

摘要：深度神经网络已成为一种强大的技术，可用于从协同过滤 (CF) 中的使用者-项目互动资料中学习表征，以用于推荐系统。然而，许多现有方法严重依赖于唯一的使用者和项目 ID，这限制了它们在实际零次学习场景中表现良好的能力，而在实际零次学习场景中，可能无法获得足够的训练资料。在语言模型 (LM) 及其强大的概括能力取得成功后，一个关键问题出现了：我们如何利用语言模型的潜力来增强推荐系统，并将其概括能力提升到新的高度？在本研究中，我们提出了 EasyRec - 一种有效且易于使用的途径，可将基于文本的语义理解与协作信号无缝整合。EasyRec 采用文本行为对齐框架，将对比学习与协作语言模型调整相结合，以确保文本增强语义空间与协作行为信息之间有很强的对齐。在各种实际数据集上进行广泛的实证评估，证明了 EasyRec 与最先进的替代模型相比具有卓越的性能，尤其是在具有挑战性的基于文本的零次推荐场景中。此外，本研究强调了将 EasyRec 无缝整合为即插即用组件到文本增强协作过滤框架中的潜力，从而使现有的推荐系统能够提升其推荐性能，并适应动态环境中不断变化的使用者偏好。为了更好地重现我们 EasyRec 框架的结果，模型实现细节、源代码和数据集可在以下链接获得：https://github.com/HKUDS/EasyRec。

##### **Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**
2408.08808v1 by Ravi Raju, Swayambhoo Jain, Bo Li, Jonathan Li, Urmish Thakkar

Large Language Models (LLMs) have revolutionized the landscape of machine
learning, yet current benchmarks often fall short in capturing the diverse
behavior of these models in real-world applications. A benchmark's usefulness
is determined by its ability to clearly differentiate between models of varying
capabilities (separability) and closely align with human preferences. Existing
frameworks like Alpaca-Eval 2.0 LC
\cite{dubois2024lengthcontrolledalpacaevalsimpleway} and Arena-Hard v0.1
\cite{li2024crowdsourced} are limited by their focus on general-purpose queries
and lack of diversity across domains such as law, medicine, and multilingual
contexts. In this paper, we address these limitations by introducing a novel
data pipeline that curates diverse, domain-specific evaluation sets tailored
for LLM-as-a-Judge frameworks. Our approach leverages a combination of manual
curation, semi-supervised learning to generate clusters, and stratified
sampling to ensure balanced representation across a wide range of domains and
languages. The resulting evaluation set, which includes 1573 samples across 14
categories, demonstrates high separability (84\%) across ten top-ranked models,
and agreement (84\%) with Chatbot Arena and (0.915) Spearman correlation. The
agreement values are 9\% better than Arena Hard and 20\% better than AlpacaEval
2.0 LC, while the Spearman coefficient is 0.7 more than the next best
benchmark, showcasing a significant improvement in the usefulness of the
benchmark. We further provide an open-source evaluation tool that enables
fine-grained analysis of model performance across user-defined categories,
offering valuable insights for practitioners. This work contributes to the
ongoing effort to enhance the transparency, diversity, and effectiveness of LLM
evaluation methodologies.

摘要：大型語言模型 (LLM) 徹底改變了機器學習的格局，但目前的基準經常無法捕捉這些模型在實際應用中的多樣化行為。基準的效用取決於其清楚區分不同能力模型（可分離性）並與人類偏好緊密結合的能力。現有的框架（例如 Alpaca-Eval 2.0 LC\cite{dubois2024lengthcontrolledalpacaevalsimpleway} 和 Arena-Hard v0.1\cite{li2024crowdsourced}）受到其對通用查詢的關注以及缺乏法律、醫學和多語言環境等領域多樣性的限制。在本文中，我們通過引入一種新穎的資料管道來解決這些限制，該管道策劃了針對 LLM 作為評審框架量身打造的多樣化、特定於領域的評估集。我們的做法利用了手動策劃、半監督式學習來生成群集以及分層抽樣的組合，以確保在廣泛的領域和語言中具有平衡的表示。生成的評估集包含 14 個類別中的 1573 個樣本，展示了前十名模型之間的高可分離性 (84%)，以及與聊天機器人競技場的一致性 (84%) 和 (0.915) Spearman 相關性。一致性值比 Arena Hard 高 9%，比 AlpacaEval 2.0 LC 高 20%，而 Spearman 係數比次佳基準高 0.7，顯示基準的效用有顯著提升。我們進一步提供了一個開源評估工具，該工具可以對使用者定義類別中的模型效能進行細緻的分析，為實務工作者提供有價值的見解。這項工作有助於持續努力提高 LLM 評估方法的透明度、多樣性和有效性。

##### **CIKMar: A Dual-Encoder Approach to Prompt-Based Reranking in Educational Dialogue Systems**
2408.08805v1 by Joanito Agili Lopo, Marina Indah Prasasti, Alma Permatasari

In this study, we introduce CIKMar, an efficient approach to educational
dialogue systems powered by the Gemma Language model. By leveraging a
Dual-Encoder ranking system that incorporates both BERT and SBERT model, we
have designed CIKMar to deliver highly relevant and accurate responses, even
with the constraints of a smaller language model size. Our evaluation reveals
that CIKMar achieves a robust recall and F1-score of 0.70 using BERTScore
metrics. However, we have identified a significant challenge: the Dual-Encoder
tends to prioritize theoretical responses over practical ones. These findings
underscore the potential of compact and efficient models like Gemma in
democratizing access to advanced educational AI systems, ensuring effective and
contextually appropriate responses.

摘要：在這項研究中，我們介紹了 CIKMar，一種由 Gemma 語言模型驅動的教育對話系統的有效方法。透過利用結合 BERT 和 SBERT 模型的雙編碼器排名系統，我們設計 CIKMar 提供高度相關且準確的回應，即使受到較小語言模型大小的限制。我們的評估顯示，CIKMar 使用 BERTScore 指標達到了 0.70 的強健召回率和 F1 分數。然而，我們發現了一個重大的挑戰：雙編碼器傾向於優先考慮理論回應，而不是實際回應。這些發現強調了像 Gemma 這樣的精簡且高效模型在使進階教育 AI 系統民主化、確保有效且適當的回應方面的潛力。

##### **Leveraging FourierKAN Classification Head for Pre-Trained Transformer-based Text Classification**
2408.08803v1 by Abdullah Al Imran, Md Farhan Ishmam

For many years, transformer-based pre-trained models with Multi-layer
Perceptron (MLP) heads have been the standard for text classification tasks.
However, the fixed non-linear functions employed by MLPs often fall short of
capturing the intricacies of the contextualized embeddings produced by
pre-trained encoders. Furthermore, MLPs usually require a significant number of
training parameters, which can be computationally expensive. In this work, we
introduce FourierKAN (FR-KAN), a variant of the promising MLP alternative
called Kolmogorov-Arnold Networks (KANs), as classification heads for
transformer-based encoders. Our studies reveal an average increase of 10% in
accuracy and 11% in F1-score when incorporating FR-KAN heads instead of
traditional MLP heads for several transformer-based pre-trained models across
multiple text classification tasks. Beyond improving model accuracy, FR-KAN
heads train faster and require fewer parameters. Our research opens new grounds
for broader applications of KAN across several Natural Language Processing
(NLP) tasks.

摘要：多年來，具有多層感知器 (MLP) 頭的基於Transformer的預訓練模型一直是文本分類任務的標準。
然而，MLP 使用的固定非線性函數通常無法捕捉由預訓練編碼器產生的上下文化嵌入的複雜性。
此外，MLP 通常需要大量的訓練參數，這在計算上可能是昂貴的。
在這項工作中，我們引入了 FourierKAN (FR-KAN)，一種有前途的 MLP 替代方案，稱為 Kolmogorov-Arnold 網路 (KAN)，作為基於Transformer的編碼器的分類頭。
我們的研究表明，在多個文本分類任務中，將 FR-KAN 頭整合到基於Transformer的預訓練模型中，而不是傳統的 MLP 頭，準確率平均提高了 10%，F1 分數提高了 11%。
除了提高模型準確度之外，FR-KAN 頭訓練速度更快，並且需要更少的參數。
我們的研究為 KAN 在多個自然語言處理 (NLP) 任務中的更廣泛應用開闢了新的領域。

##### **A Disease-Specific Foundation Model Using Over 100K Fundus Images: Release and Validation for Abnormality and Multi-Disease Classification on Downstream Tasks**
2408.08790v1 by Boa Jang, Youngbin Ahn, Eun Kyung Choe, Chang Ki Yoon, Hyuk Jin Choi, Young-Gon Kim

Artificial intelligence applied to retinal images offers significant
potential for recognizing signs and symptoms of retinal conditions and
expediting the diagnosis of eye diseases and systemic disorders. However,
developing generalized artificial intelligence models for medical data often
requires a large number of labeled images representing various disease signs,
and most models are typically task-specific, focusing on major retinal
diseases. In this study, we developed a Fundus-Specific Pretrained Model
(Image+Fundus), a supervised artificial intelligence model trained to detect
abnormalities in fundus images. A total of 57,803 images were used to develop
this pretrained model, which achieved superior performance across various
downstream tasks, indicating that our proposed model outperforms other general
methods. Our Image+Fundus model offers a generalized approach to improve model
performance while reducing the number of labeled datasets required.
Additionally, it provides more disease-specific insights into fundus images,
with visualizations generated by our model. These disease-specific foundation
models are invaluable in enhancing the performance and efficiency of deep
learning models in the field of fundus imaging.

摘要：人工智慧應用於視網膜影像，在辨識視網膜病變的徵兆和症狀，以及加速診斷眼疾和全身性疾病方面，有顯著的潛力。然而，為醫療資料開發廣泛的人工智慧模型，通常需要大量代表各種疾病徵兆的標籤影像，而且大多數模型通常是針對特定任務，專注於主要的視網膜疾病。在這項研究中，我們開發了眼底專用預訓練模型 (影像 + 眼底)，這是一個監督式的人工智慧模型，訓練用於偵測眼底影像中的異常。總共使用了 57,803 張影像來開發這個預訓練模型，它在各種下游任務中都達到了卓越的效能，這表示我們提出的模型優於其他一般方法。我們的影像 + 眼底模型提供了一種廣泛的方法來改善模型效能，同時減少所需的標籤資料集數量。此外，它還透過我們的模型產生的視覺化，提供了更多針對眼底影像的特定疾病見解。這些特定疾病基礎模型對於增強眼底影像領域中深度學習模型的效能和效率至關重要。

##### **A Transparency Paradox? Investigating the Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies on Passengers**
2408.08785v1 by Daniel Omeiza, Raunak Bhattacharyya, Marina Jirotka, Nick Hawes, Lars Kunze

Transparency in automated systems could be afforded through the provision of
intelligible explanations. While transparency is desirable, might it lead to
catastrophic outcomes (such as anxiety), that could outweigh its benefits? It's
quite unclear how the specificity of explanations (level of transparency)
influences recipients, especially in autonomous driving (AD). In this work, we
examined the effects of transparency mediated through varying levels of
explanation specificity in AD. We first extended a data-driven explainer model
by adding a rule-based option for explanation generation in AD, and then
conducted a within-subject lab study with 39 participants in an immersive
driving simulator to study the effect of the resulting explanations.
Specifically, our investigation focused on: (1) how different types of
explanations (specific vs. abstract) affect passengers' perceived safety,
anxiety, and willingness to take control of the vehicle when the vehicle
perception system makes erroneous predictions; and (2) the relationship between
passengers' behavioural cues and their feelings during the autonomous drives.
Our findings showed that passengers felt safer with specific explanations when
the vehicle's perception system had minimal errors, while abstract explanations
that hid perception errors led to lower feelings of safety. Anxiety levels
increased when specific explanations revealed perception system errors (high
transparency). We found no significant link between passengers' visual patterns
and their anxiety levels. Our study suggests that passengers prefer clear and
specific explanations (high transparency) when they originate from autonomous
vehicles (AVs) with optimal perceptual accuracy.

摘要：自動化系統中的透明度可透過提供可理解的說明來提供。儘管透明度是可取的，但它可能會導致（例如焦慮）的災難性後果，這可能會超過其好處？說明的具體性（透明度等級）如何影響接收者，特別是在自動駕駛 (AD) 中，這一點尚不清楚。在這項工作中，我們探討了在 AD 中透過不同等級的說明具體性來調節透明度的效果。我們首先擴充了一個資料驅動的說明模型，方法是在 AD 中加入一個基於規則的選項來產生說明，然後在一個沉浸式的駕駛模擬器中進行一個主題內實驗室研究，以研究所得說明的效果。具體來說，我們的調查重點在於：(1) 不同類型的說明（具體與抽象）如何影響乘客在車輛感知系統做出錯誤預測時對安全、焦慮和願意控制車輛的看法；以及 (2) 乘客在自動駕駛期間的行為線索與他們的感覺之間的關係。我們的研究結果顯示，當車輛的感知系統錯誤最少時，乘客對具體的說明感到更安全，而隱藏感知錯誤的抽象說明則導致較低的安全感。當具體的說明揭示感知系統錯誤（高透明度）時，焦慮程度會增加。我們沒有發現乘客的視覺模式和焦慮程度之間有顯著的關聯性。我們的研究表明，當說明來自具有最佳感知精度的自動駕駛車輛 (AV) 時，乘客更喜歡清晰具體的說明（高透明度）。

##### **EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**
2408.08782v1 by Chenwei Wan, Matthieu Labeau, Chloé Clavel

Designing emotionally intelligent conversational systems to provide comfort
and advice to people experiencing distress is a compelling area of research.
Previous efforts have focused on developing modular dialogue systems that treat
socio-emotional strategy prediction as an auxiliary task and generate
strategy-conditioned responses with customized decoders. Recently, with
advancements in large language models (LLMs), end-to-end dialogue agents
without explicit socio-emotional strategy prediction steps have become
prevalent. However, despite their excellence in language generation, recent
studies show that LLMs' inherent preference bias towards certain
socio-emotional strategies hinders the delivery of high-quality emotional
support. To address this challenge, we propose decoupling strategy prediction
from language generation, and introduce a novel dialogue strategy predictor,
EmoDynamiX, which models the discourse dynamics between user emotions and
system strategies using a heterogeneous graph. Additionally, we make use of the
Emotion Recognition in Conversations (ERC) task and design a flexible
mixed-emotion module to capture fine-grained emotional states of the user.
Experimental results on two ESC datasets show EmoDynamiX outperforms previous
state-of-the-art methods with a significant margin.

摘要：設計情緒智能對話系統以提供安慰和建議給經歷痛苦的人是一個引人入勝的研究領域。
先前的努力集中於開發模組化對話系統，將社會情緒策略預測視為輔助任務，並使用自訂解碼器產生策略條件化的回應。最近，隨著大型語言模型 (LLM) 的進步，沒有明確社會情緒策略預測步驟的端到端對話代理已變得普遍。然而，儘管它們在語言生成方面表現出色，但最近的研究表明，LLM 對某些社會情緒策略的固有偏好會阻礙提供高品質的情緒支持。為了應對這一挑戰，我們建議將策略預測與語言生成解耦，並引入一種新穎的對話策略預測器 EmoDynamiX，它使用異質圖形對使用者情緒和系統策略之間的話語動態進行建模。此外，我們利用對話中的情緒辨識 (ERC) 任務並設計了一個靈活的混合情緒模組來捕捉使用者的細緻情緒狀態。在兩個 ESC 資料集上的實驗結果顯示，EmoDynamiX 以顯著的幅度優於先前的最新方法。

##### **Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**
2408.08781v1 by Bhuvanashree Murugadoss, Christian Poelitz, Ian Drosos, Vu Le, Nick McKenna, Carina Suzana Negreanu, Chris Parnin, Advait Sarkar

LLMs-as-a-judge is a recently popularized method which replaces human
judgements in task evaluation (Zheng et al. 2024) with automatic evaluation
using LLMs. Due to widespread use of RLHF (Reinforcement Learning from Human
Feedback), state-of-the-art LLMs like GPT4 and Llama3 are expected to have
strong alignment with human preferences when prompted for a quality judgement,
such as the coherence of a text. While this seems beneficial, it is not clear
whether the assessments by an LLM-as-a-judge constitute only an evaluation
based on the instructions in the prompts, or reflect its preference for
high-quality data similar to its fine-tune data. To investigate how much
influence prompting the LLMs-as-a-judge has on the alignment of AI judgements
to human judgements, we analyze prompts with increasing levels of instructions
about the target quality of an evaluation, for several LLMs-as-a-judge.
Further, we compare to a prompt-free method using model perplexity as a quality
measure instead. We aggregate a taxonomy of quality criteria commonly used
across state-of-the-art evaluations with LLMs and provide this as a rigorous
benchmark of models as judges. Overall, we show that the LLMs-as-a-judge
benefit only little from highly detailed instructions in prompts and that
perplexity can sometimes align better with human judgements than prompting,
especially on textual quality.

摘要：LLM 即法官是一種最近很流行的方法，它用 LLM 自動評估取代了任務評估中的人類判斷（鄭等人，2024 年）。由於廣泛使用 RLHF（人類回饋強化學習），當提示進行品質判斷時，例如文本的連貫性，預期像 GPT4 和 Llama3 等最先進的 LLM 與人類偏好有很強的一致性。雖然這看起來有益，但尚不清楚 LLM 即法官的評估是否僅構成基於提示中說明的評估，還是反映了它對類似於其微調資料的高品質資料的偏好。為了調查提示 LLM 即法官對 AI 判斷與人類判斷的一致性有多大影響，我們分析了針對多個 LLM 即法官，包含越來越高層級的評估目標品質說明的提示。此外，我們將其與一種無提示方法進行比較，該方法使用模型困惑度作為品質衡量標準。我們彙總了一個分類法，其中包含 LLM 最先進評估中常用的品質標準，並將其作為模型作為法官的嚴格基準。總的來說，我們表明 LLM 即法官僅從提示中非常詳細的說明中受益很少，並且困惑度有時可以比提示更好地與人類判斷保持一致，特別是在文字品質方面。

##### **Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**
2408.08780v1 by Chenming Tang, Zhixiang Wang, Yunfang Wu

With the help of in-context learning (ICL), large language models (LLMs) have
achieved impressive performance across various tasks. However, the function of
descriptive instructions during ICL remains under-explored. In this work, we
propose an ensemble prompt framework to describe the selection criteria of
multiple in-context examples, and preliminary experiments on machine
translation (MT) across six translation directions confirm that this framework
boosts ICL perfromance. But to our surprise, LLMs might not necessarily care
what the descriptions actually say, and the performance gain is primarily
caused by the ensemble format, since the framework could lead to improvement
even with random descriptive nouns. We further apply this new ensemble prompt
on a range of commonsense, math, logical reasoning and hallucination tasks with
three LLMs and achieve promising results, suggesting again that designing a
proper prompt format would be much more effective and efficient than paying
effort into specific descriptions. Our code will be publicly available once
this paper is published.

摘要：在上下文學習 (ICL) 的幫助下，大型語言模型 (LLM) 在各種任務中都取得了令人印象深刻的表現。然而，描述性說明在 ICL 中的功能仍未得到充分探討。在這項工作中，我們提出了一個整體提示框架來描述多個上下文範例的選擇標準，並且在六種翻譯方向的機器翻譯 (MT) 上進行的初步實驗證實了這個框架提升了 ICL 的表現。但令我們驚訝的是，LLM 可能不一定在乎說明實際上說了什麼，而效能提升主要是由整體格式造成的，因為這個框架甚至可以透過隨機描述性名詞來帶來改善。我們進一步將這個新的整體提示應用在常識、數學、邏輯推理和幻覺任務的範圍中，並使用三個 LLM 並獲得有希望的結果，再次表明設計適當的提示格式將比在特定說明上投入精力更有效率。一旦這篇論文發表，我們的程式碼將公開。

##### **DAC: Decomposed Automation Correction for Text-to-SQL**
2408.08779v1 by Dingzirui Wang, Longxu Dou, Xuanliang Zhang, Qingfu Zhu, Wanxiang Che

Text-to-SQL is an important task that helps people obtain information from
databases by automatically generating SQL queries. Considering the brilliant
performance, approaches based on Large Language Models (LLMs) become the
mainstream for text-to-SQL. Among these approaches, automated correction is an
effective approach that further enhances performance by correcting the mistakes
in the generated results. The existing correction methods require LLMs to
directly correct with generated SQL, while previous research shows that LLMs do
not know how to detect mistakes, leading to poor performance. Therefore, in
this paper, we propose to employ the decomposed correction to enhance
text-to-SQL performance. We first demonstrate that decomposed correction
outperforms direct correction since detecting and fixing mistakes with the
results of the decomposed sub-tasks is easier than with SQL. Based on this
analysis, we introduce Decomposed Automation Correction (DAC), which corrects
SQL by decomposing text-to-SQL into entity linking and skeleton parsing. DAC
first generates the entity and skeleton corresponding to the question and then
compares the differences between the initial SQL and the generated entities and
skeleton as feedback for correction. Experimental results show that our method
improves performance by $3.7\%$ on average of Spider, Bird, and KaggleDBQA
compared with the baseline method, demonstrating the effectiveness of DAC.

摘要：文本轉 SQL 是一項重要的任務，它可協助人們透過自動產生 SQL 查詢來從資料庫取得資訊。考量到絕佳效能，基於大型語言模型 (LLM) 的方法已成為文本轉 SQL 的主流。在這些方法中，自動更正是一種有效的方法，它透過更正產生結果中的錯誤進一步提升效能。現有的更正方法要求 LLM 直接使用產生的 SQL 進行更正，而先前的研究顯示 LLM 不知道如何偵測錯誤，導致效能不佳。因此，在本文中，我們建議採用分解更正來提升文本轉 SQL 的效能。我們首先證明分解更正優於直接更正，因為使用分解子任務的結果來偵測和修正錯誤比使用 SQL 容易。根據這個分析，我們引入了分解自動更正 (DAC)，它透過將文本轉 SQL 分解為實體連結和結構剖析來更正 SQL。DAC 首先產生與問題相符的實體和結構，然後比較初始 SQL 與產生的實體和結構之間的差異，作為更正的回饋。實驗結果顯示，與基準方法相比，我們的模型在 Spider、Bird 和 KaggleDBQA 的平均效能提升了 3.7%，證明了 DAC 的有效性。

##### **Pessimistic Iterative Planning for Robust POMDPs**
2408.08770v1 by Maris F. L. Galesloot, Marnix Suilen, Thiago D. Simão, Steven Carr, Matthijs T. J. Spaan, Ufuk Topcu, Nils Jansen

Robust partially observable Markov decision processes (robust POMDPs) extend
classical POMDPs to handle additional uncertainty on the transition and
observation probabilities via so-called uncertainty sets. Policies for robust
POMDPs must not only be memory-based to account for partial observability but
also robust against model uncertainty to account for the worst-case instances
from the uncertainty sets. We propose the pessimistic iterative planning (PIP)
framework, which finds robust memory-based policies for robust POMDPs. PIP
alternates between two main steps: (1) selecting an adversarial (non-robust)
POMDP via worst-case probability instances from the uncertainty sets; and (2)
computing a finite-state controller (FSC) for this adversarial POMDP. We
evaluate the performance of this FSC on the original robust POMDP and use this
evaluation in step (1) to select the next adversarial POMDP. Within PIP, we
propose the rFSCNet algorithm. In each iteration, rFSCNet finds an FSC through
a recurrent neural network trained using supervision policies optimized for the
adversarial POMDP. The empirical evaluation in four benchmark environments
showcases improved robustness against a baseline method in an ablation study
and competitive performance compared to a state-of-the-art robust POMDP solver.

摘要：強健的部分可觀察馬可夫決策過程 (強健 POMDP) 延伸了古典 POMDP，透過所謂的不確定集來處理轉換和觀察機率的額外不確定性。強健 POMDP 的政策不僅必須基於記憶體來考量部分可觀察性，還必須對抗模型的不確定性，以考量不確定集中的最壞情況。我們提出悲觀迭代規劃 (PIP) 框架，它為強健 POMDP 找出強健的基於記憶體的政策。PIP 在兩個主要步驟之間交替進行：(1) 透過不確定集中的最壞情況機率實例來選擇對抗性的 (非強健) POMDP；(2) 為這個對抗性 POMDP 計算有限狀態控制器 (FSC)。我們評估這個 FSC 在原始強健 POMDP 上的效能，並在步驟 (1) 中使用這個評估來選擇下一個對抗性 POMDP。在 PIP 中，我們提出 rFSCNet 演算法。在每個反覆運算中，rFSCNet 透過遞迴神經網路找出一個 FSC，該網路使用針對對抗性 POMDP 最佳化的監督政策進行訓練。在四個基準環境中的經驗評估展示了在消融研究中對抗基線方法的強健性提升，以及與最先進的強健 POMDP 解決器相比具有競爭力的效能。

##### **Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**
2408.08769v1 by Dingwei Chen, Feiteng Fang, Shiwen Ni, Feng Liang, Ruifeng Xu, Min Yang, Chengming Li

Large Language Models (LLMs) have demonstrated exceptional performance across
various natural language processing tasks, yet they occasionally tend to yield
content that factually inaccurate or discordant with the expected output, a
phenomenon empirically referred to as "hallucination". To tackle this issue,
recent works have investigated contrastive decoding between the original model
and an amateur model with induced hallucination, which has shown promising
results. Nonetheless, this method may undermine the output distribution of the
original LLM caused by its coarse contrast and simplistic subtraction
operation, potentially leading to errors in certain cases. In this paper, we
introduce a novel contrastive decoding framework termed LOL (LOwer Layer
Matters). Our approach involves concatenating the contrastive decoding of both
the final and lower layers between the original model and the amateur model,
thereby achieving multi-layer fusion to aid in the mitigation of hallucination.
Additionally, we incorporate a truthfulness refocused module that leverages
contextual guidance to enhance factual encoding, further capturing truthfulness
during contrastive decoding. Extensive experiments conducted on two publicly
available datasets illustrate that our proposed LOL framework can substantially
alleviate hallucination while surpassing existing baselines in most cases.
Compared with the best baseline, we improve by average 4.5 points on all
metrics of TruthfulQA. The source code is coming soon.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中展現出非凡的效能，但偶爾會產生事實不正確或與預期輸出不一致的內容，這種現象在經驗上稱為「幻覺」。為了解決這個問題，最近的研究探討了原始模型與誘發幻覺的業餘模型之間的對比解碼，並顯示出有希望的結果。儘管如此，這種方法可能會破壞原始 LLM 的輸出分佈，這是因為其對比粗糙且減法運算過於簡化，在某些情況下可能會導致錯誤。在本文中，我們介紹了一個新穎的對比解碼架構，稱為 LOL（較低層級很重要）。我們的做法涉及串接原始模型和業餘模型之間的最終層和較低層的對比解碼，從而實現多層融合以幫助減輕幻覺。此外，我們整合了一個真實性重新聚焦模組，該模組利用上下文指導來增強事實編碼，進一步在對比解碼過程中捕捉真實性。在兩個公開可用的資料集上進行的廣泛實驗表明，我們提出的 LOL 架構可以在大多數情況下大幅減輕幻覺，同時超越現有的基準。與最佳基準相比，我們在 TruthfulQA 的所有指標上平均提高了 4.5 分。原始碼即將推出。

##### **ASVspoof 5: Crowdsourced Speech Data, Deepfakes, and Adversarial Attacks at Scale**
2408.08739v1 by Xin Wang, Hector Delgado, Hemlata Tak, Jee-weon Jung, Hye-jin Shim, Massimiliano Todisco, Ivan Kukanov, Xuechen Liu, Md Sahidullah, Tomi Kinnunen, Nicholas Evans, Kong Aik Lee, Junichi Yamagishi

ASVspoof 5 is the fifth edition in a series of challenges that promote the
study of speech spoofing and deepfake attacks, and the design of detection
solutions. Compared to previous challenges, the ASVspoof 5 database is built
from crowdsourced data collected from a vastly greater number of speakers in
diverse acoustic conditions. Attacks, also crowdsourced, are generated and
tested using surrogate detection models, while adversarial attacks are
incorporated for the first time. New metrics support the evaluation of
spoofing-robust automatic speaker verification (SASV) as well as stand-alone
detection solutions, i.e., countermeasures without ASV. We describe the two
challenge tracks, the new database, the evaluation metrics, baselines, and the
evaluation platform, and present a summary of the results. Attacks
significantly compromise the baseline systems, while submissions bring
substantial improvements.

摘要：ASVspoof 5 是在促進語音欺騙和深度偽造攻擊的研究，以及設計偵測解決方案的挑戰系列中的第五版。與先前的挑戰相比，ASVspoof 5 資料庫是從大量更廣泛的講者在多樣化聲學條件下收集的群眾外包資料中建立的。攻擊，也是群眾外包的，使用代理偵測模型產生和測試，同時首次加入了對抗性攻擊。新的指標支援欺騙性強的自動說話者驗證 (SASV) 以及獨立偵測解決方案的評估，即沒有 ASV 的對策。我們描述了兩個挑戰軌道、新的資料庫、評估指標、基準和評估平台，並提供結果摘要。攻擊顯著地危害了基準系統，而提交則帶來了實質性的改進。

##### **ChatZero:Zero-shot Cross-Lingual Dialogue Generation via Pseudo-Target Language**
2408.08724v1 by Yongkang Liu, Feng Shi, Daling Wang, Yifei Zhang, Hinrich Schütze

Although large language models(LLMs) show amazing capabilities, among various
exciting applications discovered for LLMs fall short in other low-resource
languages. Besides, most existing methods depend on large-scale dialogue
corpora and thus building systems for dialogue generation in a zero-shot
scenario remains a considerable challenge. To address this challenge, we
propose a novel end-to-end zero-shot dialogue generation model ChatZero based
on cross-lingual code-switching method. First, we construct code-switching
language and pseudo-target language with placeholders. Then for cross-lingual
semantic transfer, we employ unsupervised contrastive learning to minimize the
semantics gap of the source language, code-switching language, and
pseudo-target language that are mutually positive examples in the high
dimensional semantic space. Experiments on the multilingual DailyDialog and
DSTC7-AVSD datasets demonstrate that ChatZero can achieve more than 90\% of the
original performance under the zero-shot case compared to supervised learning,
and achieve state-of-the-art performance compared with other baselines.

摘要：儘管大型語言模型 (LLM) 展現驚人的能力，在為 LLM 發現的各種令人興奮的應用中，在其他低資源語言中卻表現不佳。此外，現有的大多數方法都依賴於大規模對話語料庫，因此在零次學習場景中建立對話生成系統仍然是一項相當大的挑戰。為了應對這一挑戰，我們提出了一個基於跨語言代碼轉換方法的新型端到端零次學習對話生成模型 ChatZero。首先，我們使用佔位符構建代碼轉換語言和偽目標語言。然後，對於跨語言語義轉移，我們採用無監督對比學習來最小化源語言、代碼轉換語言和偽目標語言的語義差距，這些語言在高維語義空間中是相互的正例。在多語言 DailyDialog 和 DSTC7-AVSD 資料集上的實驗表明，與監督學習相比，ChatZero 在零次學習情況下可以達到原始效能的 90% 以上，並且與其他基準相比，達到最先進的效能。

##### **Beyond KAN: Introducing KarSein for Adaptive High-Order Feature Interaction Modeling in CTR Prediction**
2408.08713v1 by Yunxiao Shi, Wujiang Wu, Mingyu Jin, Haimin Zhang, Qiang Wu, Yongfeng Zhang, Min Xu

Modeling feature interactions is crucial for click-through rate (CTR)
prediction, particularly when it comes to high-order explicit interactions.
Traditional methods struggle with this task because they often predefine a
maximum interaction order, which relies heavily on prior knowledge and can
limit the model's effectiveness. Additionally, modeling high-order interactions
typically leads to increased computational costs. Therefore, the challenge lies
in adaptively modeling high-order feature interactions while maintaining
efficiency. To address this issue, we introduce Kolmogorov-Arnold Represented
Sparse Efficient Interaction Network (KarSein), designed to optimize both
predictive accuracy and computational efficiency. We firstly identify
limitations of directly applying Kolmogorov-Arnold Networks (KAN) to CTR and
then introduce KarSein to overcome these issues. It features a novel
architecture that reduces the computational costs of KAN and supports embedding
vectors as feature inputs. Additionally, KarSein employs guided symbolic
regression to address the challenge of KAN in spontaneously learning
multiplicative relationships. Extensive experiments demonstrate KarSein's
superior performance, achieving significant predictive accuracy with minimal
computational overhead. Furthermore, KarSein maintains strong global
explainability while enabling the removal of redundant features, resulting in a
sparse network structure. These advantages also position KarSein as a promising
method for efficient inference.

摘要：特徵互動建模對點擊率 (CTR) 預測至關重要，尤其當涉及高階明確互動時。傳統方法在處理這項任務時會遇到困難，因為它們通常會預先定義最大互動階數，這非常依賴於先驗知識，且可能會限制模型的效能。此外，建模高階互動通常會導致運算成本增加。因此，挑戰在於在維持效率的同時，自適應地建模高階特徵互動。為了解決此問題，我們引進了 Kolmogorov-Arnold 表示的稀疏高效互動網路 (KarSein)，旨在最佳化預測準確度和運算效率。我們首先找出將 Kolmogorov-Arnold 網路 (KAN) 直接應用於 CTR 的限制，然後引進 KarSein 來克服這些問題。它具備一種新穎的架構，可降低 KAN 的運算成本，並支援將嵌入向量作為特徵輸入。此外，KarSein 採用引導式符號迴歸來解決 KAN 在自發學習乘法關係時所面臨的挑戰。廣泛的實驗證明了 KarSein 的卓越效能，在運算負擔最小的情況下，達到了顯著的預測準確度。此外，KarSein 保持強大的整體可解釋性，同時能移除多餘的特徵，進而形成一個稀疏的網路結構。這些優點也讓 KarSein 成為一種有前途的有效推論方法。

##### **Beam Prediction based on Large Language Models**
2408.08707v1 by Yucheng Sheng, Kai Huang, Le Liang, Peng Liu, Shi Jin, Geoffrey Ye Li

Millimeter-wave (mmWave) communication is promising for next-generation
wireless networks but suffers from significant path loss, requiring extensive
antenna arrays and frequent beam training. Traditional deep learning models,
such as long short-term memory (LSTM), enhance beam tracking accuracy however
are limited by poor robustness and generalization. In this letter, we use large
language models (LLMs) to improve the robustness of beam prediction. By
converting time series data into text-based representations and employing the
Prompt-as-Prefix (PaP) technique for contextual enrichment, our approach
unleashes the strength of LLMs for time series forecasting. Simulation results
demonstrate that our LLM-based method offers superior robustness and
generalization compared to LSTM-based models, showcasing the potential of LLMs
in wireless communications.

摘要：毫米波 (mmWave) 通訊對於下一代無線網路來說前景看好，但會遭受顯著的途徑損失，需要廣泛的天線陣列和頻繁的波束訓練。傳統深度學習模型，例如長短期記憶 (LSTM)，增強了波束追蹤準確度，但卻受到低健壯性和一般化的限制。在本文中，我們使用大型語言模型 (LLM) 來改善波束預測的健壯性。透過將時間序列資料轉換成基於文字的表示，並採用 Prompt-as-Prefix (PaP) 技術進行脈絡豐富化，我們的做法發揮了 LLM 在時間序列預測方面的優勢。模擬結果證明，與基於 LSTM 的模型相比，我們基於 LLM 的方法提供了優異的健壯性和一般化，展示了 LLM 在無線通訊中的潛力。

##### **Beyond the Hype: A dispassionate look at vision-language models in medical scenario**
2408.08704v1 by Yang Nan, Huichi Zhou, Xiaodan Xing, Guang Yang

Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated
remarkable capabilities across diverse tasks, garnering significant attention
in AI communities. However, their performance and reliability in specialized
domains such as medicine remain insufficiently assessed. In particular, most
assessments over-concentrate in evaluating VLMs based on simple Visual Question
Answering (VQA) on multi-modality data, while ignoring the in-depth
characteristic of LVLMs. In this study, we introduce RadVUQA, a novel
Radiological Visual Understanding and Question Answering benchmark, to
comprehensively evaluate existing LVLMs. RadVUQA mainly validates LVLMs across
five dimensions: 1) Anatomical understanding, assessing the models' ability to
visually identify biological structures; 2) Multimodal comprehension, which
involves the capability of interpreting linguistic and visual instructions to
produce desired outcomes; 3) Quantitative and spatial reasoning, evaluating the
models' spatial awareness and proficiency in combining quantitative analysis
with visual and linguistic information; 4) Physiological knowledge, measuring
the models' capability to comprehend functions and mechanisms of organs and
systems; and 5) Robustness, which assesses the models' capabilities against
unharmonised and synthetic data. The results indicate that both generalized
LVLMs and medical-specific LVLMs have critical deficiencies with weak
multimodal comprehension and quantitative reasoning capabilities. Our findings
reveal the large gap between existing LVLMs and clinicians, highlighting the
urgent need for more robust and intelligent LVLMs. The code and dataset will be
available after the acceptance of this paper.

摘要：近期大型视觉语言模型 (LVLMs) 的进步已展示了各种任务的非凡能力，在人工智能社群中备受关注。然而，它们在医学等专业领域的效能和可靠性仍未得到充分评估。特别是，大多数评估都过于集中在基于多模态数据进行简单视觉问答 (VQA) 来评估 VLM，而忽略了 VLM 的深入特征。本研究中，我们引入了 RadVUQA，这是一个新颖的放射视觉理解和问答基准，以全面评估现有的 VLM。RadVUQA 主要从五个维度验证 VLM：1) 解剖理解，评估模型视觉识别生物结构的能力；2) 多模态理解，涉及解释语言和视觉指令以产生预期结果的能力；3) 定量和空间推理，评估模型的空间意识和结合定量分析与视觉和语言信息的能力；4) 生理知识，衡量模型理解器官和系统功能和机制的能力；5) 鲁棒性，评估模型对不和谐和合成数据的处理能力。结果表明，通用 VLM 和医学专用 VLM 都存在严重的缺陷，多模态理解和定量推理能力较弱。我们的研究结果揭示了现有 VLM 和临床医生之间存在巨大差距，强调了对更强大和更智能的 VLM 的迫切需求。本文被接受后，代码和数据集将可供使用。

##### **NFDI4DSO: Towards a BFO Compliant Ontology for Data Science**
2408.08698v1 by Genet Asefa Gesese, Jörg Waitelonis, Zongxiong Chen, Sonja Schimmler, Harald Sack

The NFDI4DataScience (NFDI4DS) project aims to enhance the accessibility and
interoperability of research data within Data Science (DS) and Artificial
Intelligence (AI) by connecting digital artifacts and ensuring they adhere to
FAIR (Findable, Accessible, Interoperable, and Reusable) principles. To this
end, this poster introduces the NFDI4DS Ontology, which describes resources in
DS and AI and models the structure of the NFDI4DS consortium. Built upon the
NFDICore ontology and mapped to the Basic Formal Ontology (BFO), this ontology
serves as the foundation for the NFDI4DS knowledge graph currently under
development.

摘要：NFDI4DataScience (NFDI4DS) 計畫旨在藉由連結數位人工製品，並確保其遵循 FAIR（可尋找性、可存取性、可互通性和可重複使用性）原則，來提升資料科學 (DS) 和人工智慧 (AI) 中研究資料的可存取性和互通性。為此，海報介紹了 NFDI4DS 本体，它描述了 DS 和 AI 中的資源，並建構了 NFDI4DS 聯盟的結構。此本体建立於 NFDICore 本体之上，並對應到基本形式本体 (BFO)，作為目前正在開發的 NFDI4DS 知識圖譜的基礎。

##### **Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling**
2408.08696v1 by Xianzhen Luo, Yixuan Wang, Qingfu Zhu, Zhiming Zhang, Xuanyu Zhang, Qing Yang, Dongliang Xu, Wanxiang Che

The rapid growth in the parameters of large language models (LLMs) has made
inference latency a fundamental bottleneck, limiting broader application of
LLMs. Speculative decoding represents a lossless approach to accelerate
inference through a guess-and-verify paradigm, leveraging the parallel
capabilities of modern hardware. Some speculative decoding methods rely on
additional structures to guess draft tokens, such as small models or
parameter-efficient architectures, which need extra training before use.
Alternatively, retrieval-based train-free techniques build libraries from
pre-existing corpora or by n-gram generation. However, they face challenges
like large storage requirements, time-consuming retrieval, and limited
adaptability. Observing that candidate tokens generated during the decoding
process are likely to reoccur in future sequences, we propose Token Recycling.
This approach stores candidate tokens in an adjacency matrix and employs a
breadth-first search (BFS)-like algorithm on the matrix to construct a draft
tree. The tree is then validated through tree attention. New candidate tokens
from the decoding process are then used to update the matrix. Token Recycling
requires \textless2MB of additional storage and achieves approximately 2x
speedup across all sizes of LLMs. It significantly outperforms existing
train-free methods by 30\% and even a training method by 25\%. It can be
directly applied to any existing LLMs and tasks without the need for
adaptation.

摘要：大型語言模型 (LLM) 的參數快速增長，使得推論延遲成為一個根本瓶頸，限制了 LLM 的廣泛應用。推測解碼代表了一種無損失的方法，可通過猜測和驗證範例來加速推論，利用現代硬體的並行功能。一些推測解碼方法依賴於額外的結構來猜測草稿標記，例如小型模型或參數高效架構，這些模型在使用前需要額外訓練。或者，基於檢索的免訓練技術從預先存在的語料庫或通過 n-gram 生成構建函式庫。然而，他們面臨著諸如大量儲存需求、耗時的檢索和有限的適應性等挑戰。觀察到在解碼過程中產生的候選標記很可能在未來的序列中再次出現，我們提出了標記回收。此方法將候選標記儲存在鄰接矩陣中，並在矩陣上採用廣度優先搜尋 (BFS) 類似演算法來構建草稿樹。然後透過樹注意力驗證樹。然後使用來自解碼過程的新候選標記來更新矩陣。標記回收需要 \textless2MB 的額外儲存空間，並在所有大小的 LLM 中實現大約 2 倍的加速。它顯著優於現有的免訓練方法 30%，甚至比訓練方法優異 25%。它可以直接應用於任何現有的 LLM 和任務，而無需適應。

##### **Quantifying the Effectiveness of Student Organization Activities using Natural Language Processing**
2408.08694v1 by Lyberius Ennio F. Taruc, Arvin R. De La Cruz

Student extracurricular activities play an important role in enriching the
students' educational experiences. With the increasing popularity of Machine
Learning and Natural Language Processing, it becomes a logical step that
incorporating ML-NLP in improving extracurricular activities is a potential
focus of study in Artificial Intelligence (AI). This research study aims to
develop a machine learning workflow that will quantify the effectiveness of
student-organized activities based on student emotional responses using
sentiment analysis. The study uses the Bidirectional Encoder Representations
from Transformers (BERT) Large Language Model (LLM) called via the
pysentimiento toolkit, as a Transformer pipeline in Hugging Face. A sample data
set from Organization C, a Recognized Student Organization (RSO) of a higher
educational institute in the Philippines, College X, was used to develop the
workflow. The workflow consisted of data preprocessing, key feature selection,
LLM feature processing, and score aggregation, resulting in an Event Score for
each data set. The results show that the BERT LLM can also be used effectively
in analyzing sentiment beyond product reviews and post comments. For the
student affairs offices of educational institutions, this study can provide a
practical example of how NLP can be applied to real-world scenarios, showcasing
the potential impact of data-driven decision making.

摘要：學生課外活動在豐富學生的教育經驗中扮演著重要的角色。隨著機器學習和自然語言處理的普及，將 ML-NLP 融入課外活動的改善中成為人工智能 (AI) 研究的潛在重點，這是一個合乎邏輯的步驟。本研究旨在開發一種機器學習工作流程，它將根據學生的情緒反應使用情緒分析來量化學生組織活動的有效性。本研究使用透過 Hugging Face 中的 pysentimiento 工具包呼叫的 Transformer 大語言模型 (LLM) 的雙向編碼器表徵，作為 Transformer 管線。來自組織 C 的範例資料集，菲律賓高等教育機構的公認學生組織 (RSO)，大學 X，用於開發工作流程。工作流程包含資料前處理、關鍵特徵選取、LLM 特徵處理和分數彙總，產生每個資料集的事件分數。結果顯示，BERT LLM 也能有效用於分析產品評論和文章留言以外的情緒。對於教育機構的學生事務辦公室，本研究可以提供一個實際範例，說明如何將 NLP 應用於實際情況，展示資料驅動決策的潛在影響。

##### **Med-PMC: Medical Personalized Multi-modal Consultation with a Proactive Ask-First-Observe-Next Paradigm**
2408.08693v1 by Hongcheng Liu, Yusheng Liao, Siqv Ou, Yuhao Wang, Heyang Liu, Yanfeng Wang, Yu Wang

The application of the Multi-modal Large Language Models (MLLMs) in medical
clinical scenarios remains underexplored. Previous benchmarks only focus on the
capacity of the MLLMs in medical visual question-answering (VQA) or report
generation and fail to assess the performance of the MLLMs on complex clinical
multi-modal tasks. In this paper, we propose a novel Medical Personalized
Multi-modal Consultation (Med-PMC) paradigm to evaluate the clinical capacity
of the MLLMs. Med-PMC builds a simulated clinical environment where the MLLMs
are required to interact with a patient simulator to complete the multi-modal
information-gathering and decision-making task. Specifically, the patient
simulator is decorated with personalized actors to simulate diverse patients in
real scenarios. We conduct extensive experiments to access 12 types of MLLMs,
providing a comprehensive view of the MLLMs' clinical performance. We found
that current MLLMs fail to gather multimodal information and show potential
bias in the decision-making task when consulted with the personalized patient
simulators. Further analysis demonstrates the effectiveness of Med-PMC, showing
the potential to guide the development of robust and reliable clinical MLLMs.
Code and data are available at https://github.com/LiuHC0428/Med-PMC.

摘要：多模态大语言模型 (MLLM) 在医学临床情境中的应用仍未得到充分探索。先前的基准仅关注 MLLM 在医学视觉问答 (VQA) 或报告生成中的能力，而未能评估 MLLM 在复杂临床多模态任务中的表现。在本文中，我们提出了一个新颖的医学个性化多模态咨询 (Med-PMC) 范例来评估 MLLM 的临床能力。Med-PMC 构建了一个模拟的临床环境，其中 MLLM 需要与患者模拟器交互以完成多模态信息收集和决策任务。具体来说，患者模拟器装饰有个性化角色，以模拟真实场景中的不同患者。我们进行了广泛的实验来访问 12 种类型的 MLLM，全面了解 MLLM 的临床表现。我们发现，当前的 MLLM 无法收集多模态信息，并且在与个性化患者模拟器协商时在决策任务中表现出潜在的偏差。进一步的分析证明了 Med-PMC 的有效性，显示了指导稳健且可靠的临床 MLLM 开发的潜力。代码和数据可在 https://github.com/LiuHC0428/Med-PMC 获得。

##### **The Fellowship of the LLMs: Multi-Agent Workflows for Synthetic Preference Optimization Dataset Generation**
2408.08688v1 by Samee Arif, Sualeha Farid, Abdul Hameed Azeemi, Awais Athar, Agha Ali Raza

This paper presents and evaluates multi-agent workflows for synthetic
Preference Optimization (PO) dataset generation. PO dataset generation requires
two modules: (1) response evaluation, and (2) response generation. In the
response evaluation module, the responses from Large Language Models (LLMs) are
evaluated and ranked - a task typically carried out by human annotators that we
automate using LLMs. We assess the response evaluation module in a 2 step
process. In step 1, we assess LLMs as evaluators using three distinct prompting
strategies. In step 2, we apply the winning prompting strategy to compare the
performance of LLM-as-a-Judge, LLMs-as-a-Jury, and LLM Debate. In each step, we
use inter-rater agreement using Cohen's Kappa between human annotators and
LLMs. For the response generation module, we compare different configurations
for the LLM Feedback Loop using the identified LLM evaluator configuration. We
use the win rate (the fraction of times a generation framework is selected as
the best by an LLM evaluator) to determine the best multi-agent configuration
for generation. After identifying the best configurations for both modules, we
use models from the GPT, Gemma, and Llama families to generate our PO datasets
using the above pipeline. We generate two types of PO datasets, one to improve
the generation capabilities of individual LLM and the other to improve the
multi-agent workflow. Our evaluation shows that GPT-4o-as-a-Judge is more
consistent across datasets when the candidate responses do not include
responses from the GPT family. Additionally, we find that the LLM Feedback
Loop, with Llama as the generator and Gemma as the reviewer, achieves a notable
71.8% and 73.8% win rate over single-agent Llama and Gemma, respectively.

摘要：本文提出並評估用於合成偏好最佳化 (PO) 資料集生成的代理人工作流程。PO 資料集生成需要兩個模組：(1) 回應評估，以及 (2) 回應生成。在回應評估模組中，大型語言模型 (LLM) 的回應會經過評估和排名，這項任務通常由我們使用 LLM 自動化的人類註解員執行。我們使用 2 步驟流程評估回應評估模組。在步驟 1 中，我們使用三個不同的提示策略評估 LLM 作為評估員。在步驟 2 中，我們套用獲勝的提示策略來比較 LLM-as-a-Judge、LLM-as-a-Jury 和 LLM Debate 的效能。在每個步驟中，我們使用人類註解員和 LLM 之間的 Cohen's Kappa 來使用評分者間一致性。對於回應生成模組，我們使用已識別的 LLM 評估員設定比較 LLM 回饋迴路的不同設定。我們使用獲勝率（LLM 評估員選擇生成架構為最佳的次數比例）來決定最佳的生成代理人設定。在找出兩個模組的最佳設定後，我們使用 GPT、Gemma 和 Llama 家族的模型來使用上述管線生成我們的 PO 資料集。我們生成了兩種 PO 資料集，一種用於提升個別 LLM 的生成能力，另一種用於提升代理人工作流程。我們的評估顯示，當候選回應不包含 GPT 家族的回應時，GPT-4o-as-a-Judge 在不同資料集之間的一致性較高。此外，我們發現 LLM 回饋迴路（由 Llama 作為生成器，Gemma 作為審閱者）分別對單一代理人 Llama 和 Gemma 達到了顯著的 71.8% 和 73.8% 獲勝率。

##### **SC-Rec: Enhancing Generative Retrieval with Self-Consistent Reranking for~Sequential Recommendation**
2408.08686v1 by Tongyoung Kim, Soojin Yoon, Seongku Kang, Jinyoung Yeo, Dongha Lee

Language Models (LMs) are increasingly employed in recommendation systems due
to their advanced language understanding and generation capabilities. Recent
recommender systems based on generative retrieval have leveraged the
inferential abilities of LMs to directly generate the index tokens of the next
item, based on item sequences within the user's interaction history. Previous
studies have mostly focused on item indices based solely on textual semantic or
collaborative information. However, although the standalone effectiveness of
these aspects has been demonstrated, the integration of this information has
remained unexplored. Our in-depth analysis finds that there is a significant
difference in the knowledge captured by the model from heterogeneous item
indices and diverse input prompts, which can have a high potential for
complementarity. In this paper, we propose SC-Rec, a unified recommender system
that learns diverse preference knowledge from two distinct item indices and
multiple prompt templates. Furthermore, SC-Rec adopts a novel reranking
strategy that aggregates a set of ranking results, inferred based on different
indices and prompts, to achieve the self-consistency of the model. Our
empirical evaluation on three real-world datasets demonstrates that SC-Rec
considerably outperforms the state-of-the-art methods for sequential
recommendation, effectively incorporating complementary knowledge from varied
outputs of the model.

摘要：語言模型（LM）由於其先進的語言理解和生成能力，在推薦系統中越來越廣泛地使用。最近基於生成式檢索的推薦系統利用了 LM 的推理能力，根據使用者互動歷史中的項目序列直接生成下一個項目的索引標記。先前的研究大多集中於僅基於文本語義或協作資訊的項目索引。然而，儘管這些方面的獨立有效性已經得到證實，但這些資訊的整合仍未得到探討。我們的深入分析發現，模型從異質項目索引和多樣化輸入提示中擷取的知識存在顯著差異，這具有很高的互補性。在本文中，我們提出 SC-Rec，這是一個統一的推薦系統，它從兩個不同的項目索引和多個提示範本中學習多樣化的偏好知識。此外，SC-Rec 採用了一種新穎的重新排序策略，它彙總了一組基於不同索引和提示推斷的排序結果，以實現模型的自洽性。我們對三個真實世界資料集的實證評估表明，SC-Rec 在序列推薦方面顯著優於最先進的方法，有效地整合了模型各種輸出的互補知識。

##### **Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?**
2408.08685v1 by Zhongjian Zhang, Xiao Wang, Huichi Zhou, Yue Yu, Mengmei Zhang, Cheng Yang, Chuan Shi

Graph neural networks (GNNs) are vulnerable to adversarial perturbations,
especially for topology attacks, and many methods that improve the robustness
of GNNs have received considerable attention. Recently, we have witnessed the
significant success of large language models (LLMs), leading many to explore
the great potential of LLMs on GNNs. However, they mainly focus on improving
the performance of GNNs by utilizing LLMs to enhance the node features.
Therefore, we ask: Will the robustness of GNNs also be enhanced with the
powerful understanding and inference capabilities of LLMs? By presenting the
empirical results, we find that despite that LLMs can improve the robustness of
GNNs, there is still an average decrease of 23.1% in accuracy, implying that
the GNNs remain extremely vulnerable against topology attack. Therefore,
another question is how to extend the capabilities of LLMs on graph adversarial
robustness. In this paper, we propose an LLM-based robust graph structure
inference framework, LLM4RGNN, which distills the inference capabilities of
GPT-4 into a local LLM for identifying malicious edges and an LM-based edge
predictor for finding missing important edges, so as to recover a robust graph
structure. Extensive experiments demonstrate that LLM4RGNN consistently
improves the robustness across various GNNs. Even in some cases where the
perturbation ratio increases to 40%, the accuracy of GNNs is still better than
that on the clean graph.

摘要：圖形神經網路 (GNN) 容易受到對抗性擾動的影響，
特別是拓撲攻擊，許多改善 GNN 魯棒性的方法都備受關注。最近，我們見證了大型語言模型 (LLM) 的顯著成功，導致許多人探索 LLM 在 GNN 上的巨大潛力。然而，他們主要專注於利用 LLM 增強節點特徵來改善 GNN 的效能。
因此，我們問：LLM 強大的理解和推理能力是否也會增強 GNN 的魯棒性？透過呈現實證結果，我們發現儘管 LLM 可以改善 GNN 的魯棒性，但準確度仍平均下降 23.1%，這表示 GNN 仍然極容易受到拓撲攻擊。因此，另一個問題是如何擴展 LLM 在圖形對抗魯棒性上的能力。在本文中，我們提出一個基於 LLM 的魯棒圖形結構推理框架 LLM4RGNN，它將 GPT-4 的推理能力提煉成一個用於識別惡意邊緣的本地 LLM，以及一個用於尋找遺失重要邊緣的基於 LM 的邊緣預測器，以便恢復一個魯棒的圖形結構。廣泛的實驗證明，LLM4RGNN 持續改善各種 GNN 的魯棒性。即使在某些擾動率增加到 40% 的情況下，GNN 的準確度仍然優於乾淨圖形。

##### **LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression**
2408.08682v1 by Yuqi Ye, Wei Gao

The key to effective point cloud compression is to obtain a robust context
model consistent with complex 3D data structures. Recently, the advancement of
large language models (LLMs) has highlighted their capabilities not only as
powerful generators for in-context learning and generation but also as
effective compressors. These dual attributes of LLMs make them particularly
well-suited to meet the demands of data compression. Therefore, this paper
explores the potential of using LLM for compression tasks, focusing on lossless
point cloud geometry compression (PCGC) experiments. However, applying LLM
directly to PCGC tasks presents some significant challenges, i.e., LLM does not
understand the structure of the point cloud well, and it is a difficult task to
fill the gap between text and point cloud through text description, especially
for large complicated and small shapeless point clouds. To address these
problems, we introduce a novel architecture, namely the Large Language
Model-based Point Cloud Geometry Compression (LLM-PCGC) method, using LLM to
compress point cloud geometry information without any text description or
aligning operation. By utilizing different adaptation techniques for
cross-modality representation alignment and semantic consistency, including
clustering, K-tree, token mapping invariance, and Low Rank Adaptation (LoRA),
the proposed method can translate LLM to a compressor/generator for point
cloud. To the best of our knowledge, this is the first structure to employ LLM
as a compressor for point cloud data. Experiments demonstrate that the LLM-PCGC
outperforms the other existing methods significantly, by achieving -40.213% bit
rate reduction compared to the reference software of MPEG Geometry-based Point
Cloud Compression (G-PCC) standard, and by achieving -2.267% bit rate reduction
compared to the state-of-the-art learning-based method.

摘要：要有效壓縮點雲，關鍵在於取得與複雜 3D 資料結構一致的穩健情境模型。最近，大型語言模型 (LLM) 的進展突顯出它們不僅作為強大的產生器，可用於情境學習和產生，還能作為有效的壓縮器。LLM 的這些雙重屬性使它們特別適合滿足資料壓縮的需求。因此，本文探討了使用 LLM 執行壓縮任務的潛力，重點在於無損點雲幾何壓縮 (PCGC) 實驗。然而，將 LLM 直接應用於 PCGC 任務會產生一些重大挑戰，例如 LLM 不了解點雲結構，而且透過文字描述來填補文字和點雲之間的差距是一項困難的任務，特別是對於大型複雜且無定形的小點雲。為了解決這些問題，我們引進了一種新穎的架構，即基於大型語言模型的點雲幾何壓縮 (LLM-PCGC) 方法，使用 LLM 壓縮點雲幾何資訊，而無需任何文字描述或對齊操作。透過使用不同的適應技術來進行跨模態表示對齊和語意一致性，包括分群、K 樹、標記對應不變性和低秩適應 (LoRA)，所提出的方法可以將 LLM 轉換為點雲的壓縮器/產生器。據我們所知，這是第一個將 LLM 用作點雲資料壓縮器的結構。實驗證明，與 MPEG 基於幾何的點雲壓縮 (G-PCC) 標準的參考軟體相比，LLM-PCGC 的位元率降低了 -40.213%，與最先進的基於學習的方法相比，位元率降低了 -2.267%，大幅優於其他現有方法。

##### **Fine-tuning LLMs for Autonomous Spacecraft Control: A Case Study Using Kerbal Space Program**
2408.08676v1 by Alejandro Carrasco, Victor Rodriguez-Fernandez, Richard Linares

Recent trends are emerging in the use of Large Language Models (LLMs) as
autonomous agents that take actions based on the content of the user text
prompt. This study explores the use of fine-tuned Large Language Models (LLMs)
for autonomous spacecraft control, using the Kerbal Space Program Differential
Games suite (KSPDG) as a testing environment. Traditional Reinforcement
Learning (RL) approaches face limitations in this domain due to insufficient
simulation capabilities and data. By leveraging LLMs, specifically fine-tuning
models like GPT-3.5 and LLaMA, we demonstrate how these models can effectively
control spacecraft using language-based inputs and outputs. Our approach
integrates real-time mission telemetry into textual prompts processed by the
LLM, which then generate control actions via an agent. The results open a
discussion about the potential of LLMs for space operations beyond their
nominal use for text-related tasks. Future work aims to expand this methodology
to other space control tasks and evaluate the performance of different LLM
families. The code is available at this URL:
\texttt{https://github.com/ARCLab-MIT/kspdg}.

摘要：大型語言模型 (LLM) 的使用出現了新趨勢，作為自主代理，根據使用者文字提示的內容採取行動。本研究探討了使用微調大型語言模型 (LLM) 進行自主太空船控制，使用 Kerbal 太空計畫差異遊戲組 (KSPDG) 作為測試環境。傳統的強化學習 (RL) 方法由於模擬能力和數據不足，因此在此領域面臨限制。透過利用 LLM，特別是微調 GPT-3.5 和 LLaMA 等模型，我們展示了這些模型如何能有效地使用基於語言的輸入和輸出控制太空船。我們的做法將即時任務遙測整合到 LLM 處理的文字提示中，然後透過代理產生控制動作。結果開啟了關於 LLM 在太空任務中潛力的討論，超越了它們在文字相關任務中的慣常用途。未來的研究目標是將此方法擴展到其他太空控制任務，並評估不同 LLM 系列的效能。程式碼可在以下網址取得：
\texttt{https://github.com/ARCLab-MIT/kspdg}。

##### **MAT-SED: AMasked Audio Transformer with Masked-Reconstruction Based Pre-training for Sound Event Detection**
2408.08673v1 by Pengfei Cai, Yan Song, Kang Li, Haoyu Song, Ian McLoughlin

Sound event detection (SED) methods that leverage a large pre-trained
Transformer encoder network have shown promising performance in recent DCASE
challenges. However, they still rely on an RNN-based context network to model
temporal dependencies, largely due to the scarcity of labeled data. In this
work, we propose a pure Transformer-based SED model with masked-reconstruction
based pre-training, termed MAT-SED. Specifically, a Transformer with relative
positional encoding is first designed as the context network, pre-trained by
the masked-reconstruction task on all available target data in a
self-supervised way. Both the encoder and the context network are jointly
fine-tuned in a semi-supervised manner. Furthermore, a global-local feature
fusion strategy is proposed to enhance the localization capability. Evaluation
of MAT-SED on DCASE2023 task4 surpasses state-of-the-art performance, achieving
0.587/0.896 PSDS1/PSDS2 respectively.

摘要：聲音事件偵測 (SED) 方法利用大型預訓練 Transformer 編碼器網路，在最近的 DCASE 挑戰中展現出令人滿意的效能。然而，由於標籤資料的稀少，它們仍依賴於基於 RNN 的脈絡網路來建模時間依賴性。在這項工作中，我們提出一個純 Transformer 為基礎的 SED 模型，具備遮罩重建為基礎的預訓練，稱為 MAT-SED。具體來說，首先將一個帶有相對位置編碼的 Transformer 設計為脈絡網路，並透過自我監督的方式，在所有可用的目標資料上以遮罩重建任務進行預訓練。編碼器和脈絡網路都會以半監督的方式聯合微調。此外，提出一個全域-局部特徵融合策略來增強定位能力。MAT-SED 在 DCASE2023 任務 4 上的評估超越了最先進的效能，分別達到 0.587/0.896 PSDS1/PSDS2。

##### **Adaptive Layer Selection for Efficient Vision Transformer Fine-Tuning**
2408.08670v1 by Alessio Devoto, Federico Alvetreti, Jary Pomponi, Paolo Di Lorenzo, Pasquale Minervini, Simone Scardapane

Recently, foundation models based on Vision Transformers (ViTs) have become
widely available. However, their fine-tuning process is highly
resource-intensive, and it hinders their adoption in several edge or low-energy
applications. To this end, in this paper we introduce an efficient fine-tuning
method for ViTs called $\textbf{ALaST}$ ($\textit{Adaptive Layer Selection
Fine-Tuning for Vision Transformers}$) to speed up the fine-tuning process
while reducing computational cost, memory load, and training time. Our approach
is based on the observation that not all layers are equally critical during
fine-tuning, and their importance varies depending on the current mini-batch.
Therefore, at each fine-tuning step, we adaptively estimate the importance of
all layers and we assign what we call ``compute budgets'' accordingly. Layers
that were allocated lower budgets are either trained with a reduced number of
input tokens or kept frozen. Freezing a layer reduces the computational cost
and memory usage by preventing updates to its weights, while discarding tokens
removes redundant data, speeding up processing and reducing memory
requirements. We show that this adaptive compute allocation enables a
nearly-optimal schedule for distributing computational resources across layers,
resulting in substantial reductions in training time (up to 1.5x), FLOPs (up to
2x), and memory load (up to 2x) compared to traditional full fine-tuning
approaches. Additionally, it can be successfully combined with other
parameter-efficient fine-tuning methods, such as LoRA.

摘要：<paragraph>最近，基于视觉转换器 (ViT) 的基础模型已广泛可用。然而，它们的微调过程非常耗费资源，并且阻碍了它们在多个边缘或低能耗应用中的采用。为此，在本文中，我们介绍了一种称为 $\textbf{ALaST}$（$\textit{视觉转换器的自适应层选择微调}$）的 ViT 高效微调方法，以在降低计算成本、内存负载和训练时间的过程中加速微调过程。我们的方法基于这样的观察：并非所有层在微调过程中都同样关键，并且它们的重要性会根据当前的小批量而有所不同。因此，在每个微调步骤中，我们自适应地估计所有层的权重，并相应地分配我们所谓的 ``计算预算''。分配较低预算的层要么使用减少数量的输入标记进行训练，要么保持冻结。冻结层通过防止其权重的更新来降低计算成本和内存使用量，而丢弃标记则会删除冗余数据，从而加快处理速度并降低内存需求。我们表明，这种自适应计算分配能够为跨层分配计算资源制定近乎最优的调度，与传统的完全微调方法相比，可大幅减少训练时间（最多 1.5 倍）、FLOP（最多 2 倍）和内存负载（最多 2 倍）。此外，它可以成功地与其他参数高效的微调方法（例如 LoRA）结合使用。</paragraph>

##### **MIA-Tuner: Adapting Large Language Models as Pre-training Text Detector**
2408.08661v1 by Wenjie Fu, Huandong Wang, Chen Gao, Guanghua Liu, Yong Li, Tao Jiang

The increasing parameters and expansive dataset of large language models
(LLMs) highlight the urgent demand for a technical solution to audit the
underlying privacy risks and copyright issues associated with LLMs. Existing
studies have partially addressed this need through an exploration of the
pre-training data detection problem, which is an instance of a membership
inference attack (MIA). This problem involves determining whether a given piece
of text has been used during the pre-training phase of the target LLM. Although
existing methods have designed various sophisticated MIA score functions to
achieve considerable detection performance in pre-trained LLMs, how to achieve
high-confidence detection and how to perform MIA on aligned LLMs remain
challenging. In this paper, we propose MIA-Tuner, a novel instruction-based MIA
method, which instructs LLMs themselves to serve as a more precise pre-training
data detector internally, rather than design an external MIA score function.
Furthermore, we design two instruction-based safeguards to respectively
mitigate the privacy risks brought by the existing methods and MIA-Tuner. To
comprehensively evaluate the most recent state-of-the-art LLMs, we collect a
more up-to-date MIA benchmark dataset, named WIKIMIA-24, to replace the widely
adopted benchmark WIKIMIA. We conduct extensive experiments across various
aligned and unaligned LLMs over the two benchmark datasets. The results
demonstrate that MIA-Tuner increases the AUC of MIAs from 0.7 to a
significantly high level of 0.9.

摘要：隨著大型語言模型（LLM）參數的增加和資料集的擴展，突顯出對技術解決方案的迫切需求，以稽核與 LLM 相關的基本隱私風險和版權問題。現有的研究已透過探索預訓練資料偵測問題，部分滿足此需求，而這個問題是成員推論攻擊（MIA）的一個範例。這個問題涉及確定特定文字是否已在目標 LLM 的預訓練階段中使用。雖然現有方法已設計各種複雜的 MIA 分數函數，以在預訓練 LLM 中達成相當的偵測效能，但如何達成高信心的偵測以及如何對齊的 LLM 執行 MIA 仍然具有挑戰性。在本文中，我們提出 MIA-Tuner，一種新穎的基於指令的 MIA 方法，它指示 LLM 本身在內部作為更精確的預訓練資料偵測器，而不是設計外部 MIA 分數函數。此外，我們設計了兩個基於指令的防護措施，分別緩解現有方法和 MIA-Tuner 帶來的隱私風險。為了全面評估最新的最先進 LLM，我們收集了一個更最新的 MIA 基準資料集，名為 WIKIMIA-24，以取代廣泛採用的基準 WIKIMIA。我們在兩個基準資料集上對各種對齊和未對齊的 LLM 進行廣泛的實驗。結果證明，MIA-Tuner 將 MIA 的 AUC 從 0.7 提高到顯著高的 0.9 水準。

##### **LLMs Are Biased Towards Output Formats! Systematically Evaluating and Mitigating Output Format Bias of LLMs**
2408.08656v1 by Do Xuan Long, Hai Nguyen Ngoc, Tiviatis Sim, Hieu Dao, Shafiq Joty, Kenji Kawaguchi, Nancy F. Chen, Min-Yen Kan

We present the first systematic evaluation examining format bias in
performance of large language models (LLMs). Our approach distinguishes between
two categories of an evaluation metric under format constraints to reliably and
accurately assess performance: one measures performance when format constraints
are adhered to, while the other evaluates performance regardless of constraint
adherence. We then define a metric for measuring the format bias of LLMs and
establish effective strategies to reduce it. Subsequently, we present our
empirical format bias evaluation spanning four commonly used categories --
multiple-choice question-answer, wrapping, list, and mapping -- covering 15
widely-used formats. Our evaluation on eight generation tasks uncovers
significant format bias across state-of-the-art LLMs. We further discover that
improving the format-instruction following capabilities of LLMs across formats
potentially reduces format bias. Based on our evaluation findings, we study
prompting and fine-tuning with synthesized format data techniques to mitigate
format bias. Our methods successfully reduce the variance in ChatGPT's
performance among wrapping formats from 235.33 to 0.71 (%$^2$).

摘要：我們提出第一個系統性評估，用於檢驗大型語言模型 (LLM) 效能中的格式偏差。我們的做法區分了在格式限制下，評估指標的兩個類別，以可靠且準確地評估效能：一個是測量在遵守格式限制下的效能，而另一個則評估不論是否遵守限制的效能。然後，我們定義一個指標，用於測量 LLM 的格式偏差，並建立有效的策略來減少它。隨後，我們提出我們的經驗格式偏差評估，涵蓋四個常用的類別——多重選擇問答、換行、清單和對應——涵蓋 15 種廣泛使用的格式。我們對八個產生任務的評估揭示了最先進的 LLM 中的顯著格式偏差。我們進一步發現，改善 LLM 在所有格式中遵循格式說明的能力，可能會減少格式偏差。根據我們的評估結果，我們研究提示和微調，並使用合成的格式數據技術來減輕格式偏差。我們的這些方法成功地將 ChatGPT 在換行格式中的效能差異從 235.33 降低到 0.71 (%$^2$)。

##### **Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons**
2408.08655v1 by Binbin Ding, Penghui Yang, Zeqing Ge, Shengjun Huang

Federated learning enables multiple clients to collaboratively train machine
learning models under the overall planning of the server while adhering to
privacy requirements. However, the server cannot directly oversee the local
training process, creating an opportunity for malicious clients to introduce
backdoors. Existing research shows that backdoor attacks activate specific
neurons in the compromised model, which remain dormant when processing clean
data. Leveraging this insight, we propose a method called Flipping Weight
Updates of Low-Activation Input Neurons (FLAIN) to defend against backdoor
attacks in federated learning. Specifically, after completing global training,
we employ an auxiliary dataset to identify low-activation input neurons and
flip the associated weight updates. We incrementally raise the threshold for
low-activation inputs and flip the weight updates iteratively, until the
performance degradation on the auxiliary data becomes unacceptable. Extensive
experiments validate that our method can effectively reduce the success rate of
backdoor attacks to a low level in various attack scenarios including those
with non-IID data distribution or high MCRs, causing only minimal performance
degradation on clean data.

摘要：联邦学习让多个客户端在服务器的整体规划下协作训练机器学习模型，同时遵守隐私要求。然而，服务器无法直接监督本地训练过程，这为恶意客户端引入后门创造了机会。现有研究表明，后门攻击会激活受损模型中的特定神经元，这些神经元在处理干净数据时保持休眠。利用这一见解，我们提出了一种称为低激活输入神经元权重更新翻转 (FLAIN) 的方法来防御联邦学习中的后门攻击。具体来说，在完成全局训练后，我们使用辅助数据集来识别低激活输入神经元并翻转相关的权重更新。我们逐步提高低激活输入的阈值并迭代翻转权重更新，直到辅助数据上的性能下降变得不可接受。大量的实验验证了我们的方法可以有效地将后门攻击的成功率降低到低水平，包括那些具有非 IID 数据分布或高 MCR 的攻击场景，仅对干净数据造成最小的性能下降。

##### **TextCAVs: Debugging vision models using text**
2408.08652v1 by Angus Nicolson, Yarin Gal, J. Alison Noble

Concept-based interpretability methods are a popular form of explanation for
deep learning models which provide explanations in the form of high-level human
interpretable concepts. These methods typically find concept activation vectors
(CAVs) using a probe dataset of concept examples. This requires labelled data
for these concepts -- an expensive task in the medical domain. We introduce
TextCAVs: a novel method which creates CAVs using vision-language models such
as CLIP, allowing for explanations to be created solely using text descriptions
of the concept, as opposed to image exemplars. This reduced cost in testing
concepts allows for many concepts to be tested and for users to interact with
the model, testing new ideas as they are thought of, rather than a delay caused
by image collection and annotation. In early experimental results, we
demonstrate that TextCAVs produces reasonable explanations for a chest x-ray
dataset (MIMIC-CXR) and natural images (ImageNet), and that these explanations
can be used to debug deep learning-based models.

摘要：基於概念的可解釋方法是一種流行的深度學習模型解釋形式，它以高階人類可解釋概念的形式提供解釋。這些方法通常使用概念範例探測資料集來尋找概念啟動向量 (CAV)。這需要標記這些概念的資料，這在醫學領域是一項昂貴的任務。我們介紹 TextCAV：一種使用視覺語言模型（例如 CLIP）建立 CAV 的新方法，它允許僅使用概念的文字描述來建立解釋，而不是影像範例。測試概念的成本降低，允許測試許多概念，並讓使用者與模型互動，在想到新想法時進行測試，而不是因影像收集和註解而造成的延遲。在早期的實驗結果中，我們證明 TextCAV 為胸部 X 光資料集 (MIMIC-CXR) 和自然影像 (ImageNet) 產生合理的解釋，並且這些解釋可用於偵錯基於深度學習的模型。

##### **Reasoning Beyond Bias: A Study on Counterfactual Prompting and Chain of Thought Reasoning**
2408.08651v1 by Kyle Moore, Jesse Roberts, Thao Pham, Douglas Fisher

Language models are known to absorb biases from their training data, leading
to predictions driven by statistical regularities rather than semantic
relevance. We investigate the impact of these biases on answer choice
preferences in the Massive Multi-Task Language Understanding (MMLU) task. Our
findings reveal that differences in learned regularities across answer options
are predictive of model preferences and mirror human test-taking strategies. To
address this issue, we introduce two novel methods: Counterfactual Prompting
with Chain of Thought (CoT) and Counterfactual Prompting with Agnostically
Primed CoT (APriCoT). We demonstrate that while Counterfactual Prompting with
CoT alone is insufficient to mitigate bias, our novel Primed Counterfactual
Prompting with CoT approach effectively reduces the influence of base-rate
probabilities while improving overall accuracy. Our results suggest that
mitigating bias requires a "System-2" like process and that CoT reasoning is
susceptible to confirmation bias under some prompting methodologies. Our
contributions offer practical solutions for developing more robust and fair
language models.

摘要：語言模型已知會吸收其訓練資料中的偏見，導致預測是由統計規律而非語義相關性驅動。我們探討這些偏見對大規模多任務語言理解 (MMLU) 任務中答案選擇偏好的影響。我們的研究結果揭示，答案選項中所學規律的差異可以預測模型偏好並反映人類的應試策略。為了解決這個問題，我們引入了兩種新方法：反事實提示與思考鏈 (CoT) 和反事實提示與不可知預先提示的 CoT (APriCoT)。我們證明，雖然僅使用反事實提示與 CoT 不足以減輕偏見，但我們新穎的預先反事實提示與 CoT 方法有效降低了基本比率機率的影響，同時提高了整體準確度。我們的結果表明，減輕偏見需要一個類似於「系統 2」的過程，並且 CoT 推理在某些提示方法下容易受到確認偏見的影響。我們的貢獻為開發更健全和公平的語言模型提供了實用的解決方案。

##### **An End-to-End Model for Photo-Sharing Multi-modal Dialogue Generation**
2408.08650v1 by Peiming Guo, Sinuo Liu, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Min Zhang

Photo-Sharing Multi-modal dialogue generation requires a dialogue agent not
only to generate text responses but also to share photos at the proper moment.
Using image text caption as the bridge, a pipeline model integrates an image
caption model, a text generation model, and an image generation model to handle
this complex multi-modal task. However, representing the images with text
captions may loss important visual details and information and cause error
propagation in the complex dialogue system. Besides, the pipeline model
isolates the three models separately because discrete image text captions
hinder end-to-end gradient propagation. We propose the first end-to-end model
for photo-sharing multi-modal dialogue generation, which integrates an image
perceptron and an image generator with a large language model. The large
language model employs the Q-Former to perceive visual images in the input end.
For image generation in the output end, we propose a dynamic vocabulary
transformation matrix and use straight-through and gumbel-softmax techniques to
align the large language model and stable diffusion model and achieve
end-to-end gradient propagation. We perform experiments on PhotoChat and
DialogCC datasets to evaluate our end-to-end model. Compared with pipeline
models, the end-to-end model gains state-of-the-art performances on various
metrics of text and image generation. More analysis experiments also verify the
effectiveness of the end-to-end model for photo-sharing multi-modal dialogue
generation.

摘要：照片分享多模态对话生成需要一个对话代理，不仅要生成文本响应，还要在适当的时刻分享照片。使用图像文本标题作为桥梁，管道模型集成了一个图像标题模型、一个文本生成模型和一个图像生成模型来处理这个复杂的多模态任务。然而，用文本标题表示图像可能会丢失重要的视觉细节和信息，并导致复杂对话系统中的错误传播。此外，管道模型将这三个模型分别隔离，因为离散图像文本标题阻碍了端到端的梯度传播。我们提出了第一个用于照片分享多模态对话生成的端到端模型，它将图像感知器和图像生成器与大型语言模型集成在一起。大型语言模型采用 Q-Former 在输入端感知视觉图像。对于输出端的图像生成，我们提出了一个动态词汇转换矩阵，并使用直通和 gumbel-softmax 技术来对齐大型语言模型和稳定扩散模型，并实现端到端的梯度传播。我们在 PhotoChat 和 DialogCC 数据集上执行实验，以评估我们的端到端模型。与管道模型相比，端到端模型在文本和图像生成的不同指标上获得了最先进的性能。更多的分析实验也验证了端到端模型在照片分享多模态对话生成中的有效性。

##### **Understanding Enthymemes in Argument Maps: Bridging Argument Mining and Logic-based Argumentation**
2408.08648v1 by Jonathan Ben-Naim, Victor David, Anthony Hunter

Argument mining is natural language processing technology aimed at
identifying arguments in text. Furthermore, the approach is being developed to
identify the premises and claims of those arguments, and to identify the
relationships between arguments including support and attack relationships. In
this paper, we assume that an argument map contains the premises and claims of
arguments, and support and attack relationships between them, that have been
identified by argument mining. So from a piece of text, we assume an argument
map is obtained automatically by natural language processing. However, to
understand and to automatically analyse that argument map, it would be
desirable to instantiate that argument map with logical arguments. Once we have
the logical representation of the arguments in an argument map, we can use
automated reasoning to analyze the argumentation (e.g. check consistency of
premises, check validity of claims, and check the labelling on each arc
corresponds with thw logical arguments). We address this need by using
classical logic for representing the explicit information in the text, and
using default logic for representing the implicit information in the text. In
order to investigate our proposal, we consider some specific options for
instantiation.

摘要：論證挖掘是一種自然語言處理技術，旨在辨識文本中的論證。此外，這種方法被開發出來，以辨識這些論證的前提和主張，並辨識論證之間的關係，包括支持和攻擊關係。在本文中，我們假設一個論證圖包含論證的前提和主張，以及它們之間的支援和攻擊關係，這些關係已由論證挖掘辨識出來。因此，從一段文本中，我們假設一個論證圖是由自然語言處理自動獲得的。然而，為了理解並自動分析該論證圖，最好使用邏輯論證來實例化該論證圖。一旦我們在論證圖中獲得了論證的邏輯表示，我們就可以使用自動推理來分析論證（例如，檢查前提的一致性、檢查主張的有效性，以及檢查每個弧上的標籤是否與邏輯論證相符）。我們透過使用經典邏輯來表示文本中的明確資訊，並使用預設邏輯來表示文本中的隱含資訊，來滿足這個需求。為了調查我們的提案，我們考慮了一些實例化的特定選項。

##### **Math-PUMA: Progressive Upward Multimodal Alignment to Enhance Mathematical Reasoning**
2408.08640v1 by Wenwen Zhuang, Xin Huang, Xiantao Zhang, Jin Zeng

Multimodal Large Language Models (MLLMs) excel in solving text-based
mathematical problems, but they struggle with mathematical diagrams since they
are primarily trained on natural scene images. For humans, visual aids
generally enhance problem-solving, but MLLMs perform worse as information
shifts from textual to visual modality. This decline is mainly due to their
shortcomings in aligning images and text. To tackle aforementioned challenges,
we propose Math-PUMA, a methodology focused on Progressive Upward Multimodal
Alignment. This approach is designed to improve the mathematical reasoning
skills of MLLMs through a three-stage training process, with the second stage
being the critical alignment stage. We first enhance the language model's
mathematical reasoning capabilities with extensive set of textual mathematical
problems. We then construct a multimodal dataset with varying degrees of
textual and visual information, creating data pairs by presenting each problem
in at least two forms. By leveraging the Kullback-Leibler (KL) divergence of
next-token prediction distributions to align visual and textual modalities,
consistent problem-solving abilities are ensured. Finally, we utilize
multimodal instruction tuning for MLLMs with high-quality multimodal data.
Experimental results on multiple mathematical reasoning benchmarks demonstrate
that the MLLMs trained with Math-PUMA surpass most open-source MLLMs. Our
approach effectively narrows the performance gap for problems presented in
different modalities.

摘要：多模態大型語言模型 (MMLM) 擅於解決基於文字的數學問題，但它們在處理數學圖表時會遇到困難，因為它們主要在自然場景圖像上進行訓練。對於人類來說，視覺輔助通常可以增強問題解決能力，但當資訊從文字模式轉換為視覺模式時，MMLM 的表現會變差。這種衰退主要是因為它們在對齊圖像和文字時有缺陷。為了應對上述挑戰，我們提出了 Math-PUMA，這是一種專注於漸進向上多模態對齊的方法。這種方法旨在通過三階段訓練過程來改善 MMLM 的數學推理技能，其中第二階段是關鍵對齊階段。我們首先使用大量的文字數學問題來增強語言模型的數學推理能力。然後，我們構建了一個具有不同程度文字和視覺資訊的多模態資料集，通過以至少兩種形式呈現每個問題來建立資料對。透過利用 Kullback-Leibler (KL) 差異來對齊視覺和文字模式的後續詞彙預測分佈，確保了一致的問題解決能力。最後，我們利用高品質的多模態資料為 MMLM 進行多模態指令微調。在多個數學推理基準上的實驗結果表明，使用 Math-PUMA 訓練的 MMLM 超越了大多數開源 MMLM。我們的做法有效縮小了以不同模式呈現的問題的效能差距。

##### **A Survey on Benchmarks of Multimodal Large Language Models**
2408.08632v1 by Jian Li, Weiheng Lu

Multimodal Large Language Models (MLLMs) are gaining increasing popularity in
both academia and industry due to their remarkable performance in various
applications such as visual question answering, visual perception,
understanding, and reasoning. Over the past few years, significant efforts have
been made to examine MLLMs from multiple perspectives. This paper presents a
comprehensive review of \textbf{180 benchmarks} and evaluation for MLLMs,
focusing on (1)perception and understanding, (2)cognition and reasoning,
(3)specific domains, (4)key capabilities, and (5)other modalities. Finally, we
discuss the limitations of the current evaluation methods for MLLMs and explore
promising future directions. Our key argument is that evaluation should be
regarded as a crucial discipline to better support the development of MLLMs.
For more details, please visit our GitHub repository:
https://github.com/swordlidev/Evaluation-Multimodal-LLMs-Survey.

摘要：多模态大型语言模型 (MLLM) 在学术界和工业界中越来越受欢迎，这是因为它们在视觉问题解答、视觉感知、理解和推理等各种应用中表现出色。在过去几年中，人们已经做出了巨大的努力，从多个角度对 MLLM 进行了研究。本文对**180 个基准**和 MLLM 评估进行了全面回顾，重点关注 (1) 感知和理解、(2) 认知和推理、(3) 特定领域、(4) 关键能力和 (5) 其他模态。最后，我们讨论了当前 MLLM 评估方法的局限性，并探讨了有前景的未来方向。我们的关键论点是，评估应被视为一项至关重要的学科，以更好地支持 MLLM 的发展。有关更多详细信息，请访问我们的 GitHub 存储库：
https://github.com/swordlidev/Evaluation-Multimodal-LLMs-Survey。

##### **Persona is a Double-edged Sword: Enhancing the Zero-shot Reasoning by Ensembling the Role-playing and Neutral Prompts**
2408.08631v1 by Junseok Kim, Nakyeong Yang, Kyomin Jung

Recent studies demonstrate that prompting an appropriate role-playing persona
to an LLM improves its reasoning capability. However, assigning a proper
persona is difficult since an LLM's performance is extremely sensitive to
assigned prompts; therefore, personas sometimes hinder LLMs and degrade their
reasoning capabilities. In this paper, we propose a novel framework, Jekyll \&
Hyde, which ensembles the results of role-playing and neutral prompts to
eradicate performance degradation via unilateral use of role-playing prompted
LLM and enhance the robustness of an LLM's reasoning ability. Specifically,
Jekyll \& Hyde collects two potential solutions from both role-playing and
neutral prompts and selects a better solution after cross-checking via an LLM
evaluator. However, LLM-based evaluators tend to be affected by the order of
those potential solutions within the prompt when selecting the proper solution;
thus, we also propose a robust LLM evaluator to mitigate the position bias. The
experimental analysis demonstrates that role-playing prompts distract LLMs and
degrade their reasoning abilities in 4 out of 12 datasets, even when using
GPT-4. In addition, we reveal that Jekyll \& Hyde improves reasoning
capabilities by selecting better choices among the potential solutions on
twelve widely-used reasoning datasets. We further show that our proposed LLM
evaluator outperforms other baselines, proving the LLMs' position bias is
successfully mitigated.

摘要：最近的研究表明，提示 LLM 扮演适当的角色扮演角色可以提高其推理能力。然而，指定适当的角色很难，因为 LLM 的性能对指定的提示极其敏感；因此，角色有时会阻碍 LLM 并降低其推理能力。在本文中，我们提出了一个新框架 Jekyll 和 Hyde，它集合了角色扮演和中立提示的结果，通过单方面使用角色扮演提示的 LLM 来消除性能下降，并增强 LLM 推理能力的鲁棒性。具体而言，Jekyll 和 Hyde 从角色扮演和中立提示中收集两个潜在的解决方案，并在通过 LLM 评估器交叉检查后选择更好的解决方案。然而，基于 LLM 的评估器在选择适当的解决方案时往往会受到提示中这些潜在解决方案的顺序的影响；因此，我们还提出了一个鲁棒的 LLM 评估器来减轻位置偏差。实验分析表明，即使使用 GPT-4，角色扮演提示也会分散 LLM 的注意力，并在 12 个数据集中有 4 个数据集降低其推理能力。此外，我们揭示了 Jekyll 和 Hyde 通过在十二个广泛使用的推理数据集中从潜在解决方案中选择更好的选择来提高推理能力。我们进一步表明，我们提出的 LLM 评估器优于其他基线，证明 LLM 的位置偏差已成功减轻。

##### **RealMedQA: A pilot biomedical question answering dataset containing realistic clinical questions**
2408.08624v1 by Gregory Kell, Angus Roberts, Serge Umansky, Yuti Khare, Najma Ahmed, Nikhil Patel, Chloe Simela, Jack Coumbe, Julian Rozario, Ryan-Rhys Griffiths, Iain J. Marshall

Clinical question answering systems have the potential to provide clinicians
with relevant and timely answers to their questions. Nonetheless, despite the
advances that have been made, adoption of these systems in clinical settings
has been slow. One issue is a lack of question-answering datasets which reflect
the real-world needs of health professionals. In this work, we present
RealMedQA, a dataset of realistic clinical questions generated by humans and an
LLM. We describe the process for generating and verifying the QA pairs and
assess several QA models on BioASQ and RealMedQA to assess the relative
difficulty of matching answers to questions. We show that the LLM is more
cost-efficient for generating "ideal" QA pairs. Additionally, we achieve a
lower lexical similarity between questions and answers than BioASQ which
provides an additional challenge to the top two QA models, as per the results.
We release our code and our dataset publicly to encourage further research.

摘要：臨床問答系統具有提供臨床醫生相關且及時的答案的潛力。儘管如此，儘管取得了進展，但在臨床環境中採用這些系統的速度很慢。一個問題是缺乏反映醫療專業人員現實需求的問答資料集。在這項工作中，我們提出了 RealMedQA，這是一個由人類和 LLM 生成的現實臨床問題資料集。我們描述了生成和驗證 QA 對的過程，並在 BioASQ 和 RealMedQA 上評估了幾個 QA 模型，以評估將答案與問題匹配的相對難度。我們表明，LLM 在生成「理想」的 QA 對方面更具成本效益。此外，我們在問題和答案之間實現了比 BioASQ 更低的詞彙相似性，根據結果，這對前兩個 QA 模型提出了額外的挑戰。我們公開發布我們的程式碼和資料集，以鼓勵進一步的研究。

##### **DeepDFA: Automata Learning through Neural Probabilistic Relaxations**
2408.08622v1 by Elena Umili, Roberto Capobianco

In this work, we introduce DeepDFA, a novel approach to identifying
Deterministic Finite Automata (DFAs) from traces, harnessing a differentiable
yet discrete model. Inspired by both the probabilistic relaxation of DFAs and
Recurrent Neural Networks (RNNs), our model offers interpretability
post-training, alongside reduced complexity and enhanced training efficiency
compared to traditional RNNs. Moreover, by leveraging gradient-based
optimization, our method surpasses combinatorial approaches in both scalability
and noise resilience. Validation experiments conducted on target regular
languages of varying size and complexity demonstrate that our approach is
accurate, fast, and robust to noise in both the input symbols and the output
labels of training data, integrating the strengths of both logical grammar
induction and deep learning.

摘要：在這項工作中，我們介紹了 DeepDFA，一種從軌跡中識別確定有限自動機 (DFA) 的新方法，利用可微分但離散的模型。我們的模型靈感來自 DFA 的機率鬆弛和遞迴神經網路 (RNN)，在訓練後提供可解釋性，同時降低了複雜度並提高了訓練效率，與傳統的 RNN 相比。此外，透過利用基於梯度的最佳化，我們的模型在可擴充性和抗雜訊性方面都超越了組合方法。針對不同大小和複雜度的目標正規語言進行的驗證實驗證明，我們的模型在訓練資料的輸入符號和輸出標籤中都準確、快速且具有抗雜訊性，整合了邏輯語法歸納和深度學習的優點。

##### **PatUntrack: Automated Generating Patch Examples for Issue Reports without Tracked Insecure Code**
2408.08619v1 by Ziyou Jiang, Lin Shi, Guowei Yang, Qing Wang

Security patches are essential for enhancing the stability and robustness of
projects in the software community. While vulnerabilities are officially
expected to be patched before being disclosed, patching vulnerabilities is
complicated and remains a struggle for many organizations. To patch
vulnerabilities, security practitioners typically track vulnerable issue
reports (IRs), and analyze their relevant insecure code to generate potential
patches. However, the relevant insecure code may not be explicitly specified
and practitioners cannot track the insecure code in the repositories, thus
limiting their ability to generate patches. In such cases, providing examples
of insecure code and the corresponding patches would benefit the security
developers to better locate and fix the insecure code. In this paper, we
propose PatUntrack to automatically generating patch examples from IRs without
tracked insecure code. It auto-prompts Large Language Models (LLMs) to make
them applicable to analyze the vulnerabilities. It first generates the
completed description of the Vulnerability-Triggering Path (VTP) from
vulnerable IRs. Then, it corrects hallucinations in the VTP description with
external golden knowledge. Finally, it generates Top-K pairs of Insecure Code
and Patch Example based on the corrected VTP description. To evaluate the
performance, we conducted experiments on 5,465 vulnerable IRs. The experimental
results show that PatUntrack can obtain the highest performance and improve the
traditional LLM baselines by +14.6% (Fix@10) on average in patch example
generation. Furthermore, PatUntrack was applied to generate patch examples for
76 newly disclosed vulnerable IRs. 27 out of 37 replies from the authors of
these IRs confirmed the usefulness of the patch examples generated by
PatUntrack, indicating that they can benefit from these examples for patching
the vulnerabilities.

摘要：<paragraph>安全修補程式對於提升軟體社群中專案的穩定性與健全性至關重要。雖然漏洞在被揭露之前官方預期會被修補，但修補漏洞很複雜，且對許多組織來說仍是一項挑戰。為了修補漏洞，安全從業人員通常會追蹤容易受攻擊的問題報告 (IR)，並分析其相關的不安全程式碼以產生潛在的修補程式。然而，相關的不安全程式碼可能沒有明確指定，從業人員也無法在儲存庫中追蹤不安全程式碼，因此限制了他們產生修補程式的能力。在這種情況下，提供不安全程式碼範例和對應修補程式將有助於安全開發人員更準確地找出並修復不安全程式碼。在本論文中，我們提出 PatUntrack，用於從沒有追蹤不安全程式碼的 IR 自動產生修補程式範例。它會自動提示大型語言模型 (LLM)，讓它們適用於分析漏洞。它首先從容易受攻擊的 IR 產生漏洞觸發路徑 (VTP) 的完整描述。接著，它會使用外部黃金知識修正 VTP 描述中的幻覺。最後，它會根據修正後的 VTP 描述產生不安全程式碼和修補程式範例的 Top-K 配對。為了評估效能，我們對 5,465 個容易受攻擊的 IR 進行實驗。實驗結果顯示，PatUntrack 可以獲得最高的效能，並在修補程式範例產生方面平均將傳統 LLM 基準提高 +14.6%（Fix@10）。此外，PatUntrack 已應用於為 76 個新揭露的容易受攻擊 IR 產生修補程式範例。這些 IR 作者的 37 封回覆中有 27 封確認了 PatUntrack 所產生的修補程式範例的實用性，這表示他們可以利用這些範例來修補漏洞。</paragraph>

##### **Generative Dataset Distillation Based on Diffusion Model**
2408.08610v1 by Duo Su, Junjie Hou, Guang Li, Ren Togo, Rui Song, Takahiro Ogawa, Miki Haseyama

This paper presents our method for the generative track of The First Dataset
Distillation Challenge at ECCV 2024. Since the diffusion model has become the
mainstay of generative models because of its high-quality generative effects,
we focus on distillation methods based on the diffusion model. Considering that
the track can only generate a fixed number of images in 10 minutes using a
generative model for CIFAR-100 and Tiny-ImageNet datasets, we need to use a
generative model that can generate images at high speed. In this study, we
proposed a novel generative dataset distillation method based on Stable
Diffusion. Specifically, we use the SDXL-Turbo model which can generate images
at high speed and quality. Compared to other diffusion models that can only
generate images per class (IPC) = 1, our method can achieve an IPC = 10 for
Tiny-ImageNet and an IPC = 20 for CIFAR-100, respectively. Additionally, to
generate high-quality distilled datasets for CIFAR-100 and Tiny-ImageNet, we
use the class information as text prompts and post data augmentation for the
SDXL-Turbo model. Experimental results show the effectiveness of the proposed
method, and we achieved third place in the generative track of the ECCV 2024 DD
Challenge. Codes are available at https://github.com/Guang000/BANKO.

摘要：本文介紹我們在 ECCV 2024 第一次資料集蒸餾挑戰的生成軌跡方法。由於擴散模型因為其高品質的生成效果而成為生成模型的主流，我們專注於基於擴散模型的蒸餾方法。考量到軌跡只能使用 CIFAR-100 和 Tiny-ImageNet 資料集的生成模型在 10 分鐘內生成固定數量的影像，我們需要使用能夠高速生成影像的生成模型。在本研究中，我們提出一個基於 Stable Diffusion 的新穎生成資料集蒸餾方法。具體來說，我們使用能夠高速高品質生成影像的 SDXL-Turbo 模型。與每類只能生成 1 張影像 (IPC) = 1 的其他擴散模型相比，我們的模型可以分別為 Tiny-ImageNet 達到 IPC = 10，為 CIFAR-100 達到 IPC = 20。此外，為了生成 CIFAR-100 和 Tiny-ImageNet 的高品質蒸餾資料集，我們使用類別資訊作為文字提示，並為 SDXL-Turbo 模型進行後資料擴充。實驗結果顯示所提出方法的有效性，我們在 ECCV 2024 DD 挑戰的生成軌跡中獲得第三名。程式碼可在 https://github.com/Guang000/BANKO 取得。

##### **MM-UNet: A Mixed MLP Architecture for Improved Ophthalmic Image Segmentation**
2408.08600v1 by Zunjie Xiao, Xiaoqing Zhang, Risa Higashita, Jiang Liu

Ophthalmic image segmentation serves as a critical foundation for ocular
disease diagnosis. Although fully convolutional neural networks (CNNs) are
commonly employed for segmentation, they are constrained by inductive biases
and face challenges in establishing long-range dependencies. Transformer-based
models address these limitations but introduce substantial computational
overhead. Recently, a simple yet efficient Multilayer Perceptron (MLP)
architecture was proposed for image classification, achieving competitive
performance relative to advanced transformers. However, its effectiveness for
ophthalmic image segmentation remains unexplored. In this paper, we introduce
MM-UNet, an efficient Mixed MLP model tailored for ophthalmic image
segmentation. Within MM-UNet, we propose a multi-scale MLP (MMLP) module that
facilitates the interaction of features at various depths through a grouping
strategy, enabling simultaneous capture of global and local information. We
conducted extensive experiments on both a private anterior segment optical
coherence tomography (AS-OCT) image dataset and a public fundus image dataset.
The results demonstrated the superiority of our MM-UNet model in comparison to
state-of-the-art deep segmentation networks.

摘要：眼科影像分割是眼部疾病诊断的关键基础。虽然全卷积神经网络 (CNN) 通常用于分割，但它们受到归纳偏差的限制，并且在建立远程依赖关系时面临挑战。基于 Transformer 的模型解决了这些限制，但引入了大量的计算开销。最近，提出了一种简单但高效的多层感知器 (MLP) 架构用于图像分类，相对于高级 Transformer 实现了有竞争力的性能。然而，其对眼科图像分割的有效性仍未得到探索。在本文中，我们介绍了 MM-UNet，这是一种针对眼科图像分割量身定制的高效混合 MLP 模型。在 MM-UNet 中，我们提出了一个多尺度 MLP (MMLP) 模块，该模块通过分组策略促进了不同深度特征的交互，从而能够同时捕获全局和局部信息。我们在一个私有的前节段光学相干断层扫描 (AS-OCT) 图像数据集和一个公共眼底图像数据集上进行了广泛的实验。结果表明，与最先进的深度分割网络相比，我们的 MM-UNet 模型具有优越性。

##### **A Mechanistic Interpretation of Syllogistic Reasoning in Auto-Regressive Language Models**
2408.08590v1 by Geonhee Kim, Marco Valentino, André Freitas

Recent studies on logical reasoning in auto-regressive Language Models (LMs)
have sparked a debate on whether such models can learn systematic reasoning
principles during pre-training or merely exploit superficial patterns in the
training data. This paper presents a mechanistic interpretation of syllogistic
reasoning in LMs to further enhance our understanding of internal dynamics.
Specifically, we present a methodology for circuit discovery aimed at
disentangling content-independent reasoning mechanisms from world knowledge
acquired during pre-training. Through two distinct intervention methods, we
uncover a sufficient and necessary circuit involving middle-term suppression
that elucidates how LMs transfer information to derive valid conclusions from
premises. Furthermore, we investigate how belief biases manifest in syllogistic
reasoning, finding evidence of partial contamination from additional attention
heads responsible for encoding commonsense and contextualized knowledge.
Finally, we explore the generalization of the discovered mechanisms across
various syllogistic schemes and model sizes, finding that the identified
circuit is sufficient and necessary for all the schemes on which the model
achieves high downstream accuracy ($\geq$ 60\%). Overall, our findings suggest
that LMs indeed learn transferable content-independent reasoning mechanisms,
but that, at the same time, such mechanisms do not involve generalisable and
abstract logical primitives, being susceptible to contamination by the same
world knowledge acquired during pre-training.

摘要：近期對自動迴歸語言模型 (LM) 中的邏輯推理進行的研究，引發了一場辯論，即此類模型是否能在預訓練期間學習系統性推理原則，或僅利用訓練資料中的表層模式。本文提出了一種對 LM 中三段論推理的機制詮釋，以進一步增強我們對內部動態的理解。具體來說，我們提出了一種電路發現方法，旨在將內容無關的推理機制與預訓練期間獲得的世界知識區分開來。透過兩種不同的介入方法，我們發現了一個涉及中間項抑制的充分且必要的電路，闡明了 LM 如何將資訊傳遞給從前提中推導出有效結論。此外，我們研究了信念偏見如何在三段論推理中顯現，發現負責編碼常識和情境化知識的附加注意頭部存在部分污染的證據。最後，我們探討了發現的機制在各種三段論架構和模型規模中的概化，發現已識別的電路對於模型在所有架構上實現高下游準確度（≥ 60%）而言是充分且必要的。總體而言，我們的發現表明 LM 確實學習了可轉移的內容無關推理機制，但同時，此類機制不涉及可概括和抽象的邏輯原語，容易受到預訓練期間獲得的相同世界知識的污染。

##### **AgentSimulator: An Agent-based Approach for Data-driven Business Process Simulation**
2408.08571v1 by Lukas Kirchdorfer, Robert Blümel, Timotheus Kampik, Han van der Aa, Heiner Stuckenschmidt

Business process simulation (BPS) is a versatile technique for estimating
process performance across various scenarios. Traditionally, BPS approaches
employ a control-flow-first perspective by enriching a process model with
simulation parameters. Although such approaches can mimic the behavior of
centrally orchestrated processes, such as those supported by workflow systems,
current control-flow-first approaches cannot faithfully capture the dynamics of
real-world processes that involve distinct resource behavior and decentralized
decision-making. Recognizing this issue, this paper introduces AgentSimulator,
a resource-first BPS approach that discovers a multi-agent system from an event
log, modeling distinct resource behaviors and interaction patterns to simulate
the underlying process. Our experiments show that AgentSimulator achieves
state-of-the-art simulation accuracy with significantly lower computation times
than existing approaches while providing high interpretability and adaptability
to different types of process-execution scenarios.

摘要：商業流程模擬 (BPS) 是一種通用技術，可用於估計各種情境下的流程效能。傳統上，BPS 方法採用控制流程優先的觀點，透過豐富流程模型，加入模擬參數。儘管此類方法可以模仿由中央協調的流程行為，例如工作流程系統所支援的流程，但目前的控制流程優先方法無法忠實捕捉涉及不同資源行為和分散式決策制定之真實世界流程的動態。有鑑於此問題，本文介紹 AgentSimulator，一種資源優先的 BPS 方法，它可以從事件日誌中發現多代理系統，並建模不同的資源行為和互動模式，以模擬基礎流程。我們的實驗顯示，AgentSimulator 達到了最先進的模擬準確度，且運算時間遠低於現有方法，同時對不同類型的流程執行情境提供高度的可解釋性和適應性。

##### **Overview of the BioLaySumm 2024 Shared Task on the Lay Summarization of Biomedical Research Articles**
2408.08566v1 by Tomas Goldsack, Carolina Scarton, Matthew Shardlow, Chenghua Lin

This paper presents the setup and results of the second edition of the
BioLaySumm shared task on the Lay Summarisation of Biomedical Research
Articles, hosted at the BioNLP Workshop at ACL 2024. In this task edition, we
aim to build on the first edition's success by further increasing research
interest in this important task and encouraging participants to explore novel
approaches that will help advance the state-of-the-art. Encouragingly, we found
research interest in the task to be high, with this edition of the task
attracting a total of 53 participating teams, a significant increase in
engagement from the previous edition. Overall, our results show that a broad
range of innovative approaches were adopted by task participants, with a
predictable shift towards the use of Large Language Models (LLMs).

摘要：本篇論文介紹了 ACL 2024 的 BioNLP 工作坊中舉辦的第二屆 BioLaySumm 共享任務中生物醫學研究文章的通俗總結的設定和結果。在這個任務版本中，我們旨在建立在第一屆的成功上，進一步提升對這個重要任務的研究興趣，並鼓勵參與者探索有助於推動現有技術進步的新穎方法。令人鼓舞的是，我們發現對該任務的研究興趣很高，本屆任務共吸引了 53 個參與團隊，參與度較上一屆顯著提升。總體而言，我們的結果表明，任務參與者採用了廣泛的創新方法，並可預測地轉向使用大型語言模型 (LLM)。

##### **Collaborative Cross-modal Fusion with Large Language Model for Recommendation**
2408.08564v1 by Zhongzhou Liu, Hao Zhang, Kuicai Dong, Yuan Fang

Despite the success of conventional collaborative filtering (CF) approaches
for recommendation systems, they exhibit limitations in leveraging semantic
knowledge within the textual attributes of users and items. Recent focus on the
application of large language models for recommendation (LLM4Rec) has
highlighted their capability for effective semantic knowledge capture. However,
these methods often overlook the collaborative signals in user behaviors. Some
simply instruct-tune a language model, while others directly inject the
embeddings of a CF-based model, lacking a synergistic fusion of different
modalities. To address these issues, we propose a framework of Collaborative
Cross-modal Fusion with Large Language Models, termed CCF-LLM, for
recommendation. In this framework, we translate the user-item interactions into
a hybrid prompt to encode both semantic knowledge and collaborative signals,
and then employ an attentive cross-modal fusion strategy to effectively fuse
latent embeddings of both modalities. Extensive experiments demonstrate that
CCF-LLM outperforms existing methods by effectively utilizing semantic and
collaborative signals in the LLM4Rec context.

摘要：儘管傳統協同過濾 (CF) 方法在推薦系統中獲得成功，但它們在利用使用者和項目文字屬性中的語意知識方面表現出限制。最近專注於將大型語言模型應用於推薦 (LLM4Rec) 已強調其有效語意知識擷取的能力。然而，這些方法經常忽略使用者行為中的協同訊號。有些僅指示調整語言模型，而另一些則直接注入基於 CF 模型的嵌入，缺少不同模態的協同融合。為了解決這些問題，我們提出了一個協同跨模態融合大型語言模型的框架，稱為 CCF-LLM，用於推薦。在這個框架中，我們將使用者項目互動轉換為一個混合提示，以編碼語意知識和協同訊號，然後採用專注的跨模態融合策略，以有效融合兩種模態的潛在嵌入。廣泛的實驗證明，CCF-LLM 透過有效利用 LLM4Rec 背景中的語意和協同訊號，優於現有方法。

##### **Integrating Multi-view Analysis: Multi-view Mixture-of-Expert for Textual Personality Detection**
2408.08551v1 by Haohao Zhu, Xiaokun Zhang, Junyu Lu, Liang Yang, Hongfei Lin

Textual personality detection aims to identify personality traits by
analyzing user-generated content. To achieve this effectively, it is essential
to thoroughly examine user-generated content from various perspectives.
However, previous studies have struggled with automatically extracting and
effectively integrating information from multiple perspectives, thereby
limiting their performance on personality detection. To address these
challenges, we propose the Multi-view Mixture-of-Experts Model for Textual
Personality Detection (MvP). MvP introduces a Multi-view Mixture-of-Experts
(MoE) network to automatically analyze user posts from various perspectives.
Additionally, it employs User Consistency Regularization to mitigate conflicts
among different perspectives and learn a multi-view generic user
representation. The model's training is optimized via a multi-task joint
learning strategy that balances supervised personality detection with
self-supervised user consistency constraints. Experimental results on two
widely-used personality detection datasets demonstrate the effectiveness of the
MvP model and the benefits of automatically analyzing user posts from diverse
perspectives for textual personality detection.

摘要：文本人格偵測旨在透過分析使用者產生的內容，來辨識人格特質。為了有效達成此目標，徹底檢視使用者產生的內容，並從不同觀點進行分析至關重要。然而，先前的研究在自動擷取和有效整合多面向的資訊上遇到困難，因此限制了其在人格偵測上的表現。為了應對這些挑戰，我們提出用於文本人格偵測的多視角混合專家模型 (MvP)。MvP 導入多視角混合專家 (MoE) 網路，以自動分析使用者的貼文，並從不同觀點進行分析。此外，它採用使用者一致性正規化來減輕不同觀點之間的衝突，並學習多視角的一般使用者表徵。此模型的訓練透過多任務聯合學習策略進行最佳化，該策略平衡了監督式人格偵測和自我監督式使用者一致性約束。在兩個廣泛使用的性格偵測資料集上的實驗結果證明了 MvP 模型的有效性，以及自動分析使用者貼文對文本人格偵測從不同觀點出發的好處。

##### **SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language Models**
2408.08545v1 by Kaushal Kumar Maurya, KV Aditya Srivatsa, Ekaterina Kochmar

Large language models (LLMs) have gained increased popularity due to their
remarkable success across various tasks, which has led to the active
development of a large set of diverse LLMs. However, individual LLMs have
limitations when applied to complex tasks because of such factors as training
biases, model sizes, and the datasets used. A promising approach is to
efficiently harness the diverse capabilities of LLMs to overcome these
individual limitations. Towards this goal, we introduce a novel LLM selection
algorithm called SelectLLM. This algorithm directs input queries to the most
suitable subset of LLMs from a large pool, ensuring they collectively provide
the correct response efficiently. SelectLLM uses a multi-label classifier,
utilizing the classifier's predictions and confidence scores to design optimal
policies for selecting an optimal, query-aware, and lightweight subset of LLMs.
Our findings show that the proposed model outperforms individual LLMs and
achieves competitive performance compared to similarly sized, computationally
expensive top-performing LLM subsets. Specifically, with a similarly sized
top-performing LLM subset, we achieve a significant reduction in latency on two
standard reasoning benchmarks: 13% lower latency for GSM8K and 70% lower
latency for MMLU. Additionally, we conduct comprehensive analyses and ablation
studies, which validate the robustness of the proposed model.

摘要：大型語言模型（LLM）因其在各種任務中的顯著成功而獲得越來越高的普及度，這導致了大量不同 LLM 的積極開發。然而，由於訓練偏差、模型大小和所使用的資料集等因素，個別 LLM 在應用於複雜任務時存在局限性。一種有前途的方法是有效利用 LLM 的多樣化能力來克服這些個別限制。為達成此目標，我們引入了一種稱為 SelectLLM 的新穎 LLM 選擇演算法。此演算法將輸入查詢引導至大型池中最適當的 LLM 子集，確保它們共同有效地提供正確的回應。SelectLLM 使用多標籤分類器，利用分類器的預測和信心分數，為選擇最佳、查詢感知和輕量級的 LLM 子集設計最佳策略。我們的研究結果表明，所提出的模型優於個別 LLM，並且與規模類似、計算成本高的頂尖效能 LLM 子集相比，達到了競爭力的效能。具體來說，使用規模類似的頂尖效能 LLM 子集，我們在兩個標準推理基準上實現了顯著的延遲降低：GSM8K 的延遲降低了 13%，MMLU 的延遲降低了 70%。此外，我們進行了全面的分析和消融研究，驗證了所提出模型的穩健性。

##### **Where is the signal in tokenization space?**
2408.08541v1 by Renato Lui Geh, Honghua Zhang, Kareem Ahmed, Benjie Wang, Guy Van den Broeck

Large Language Models (LLMs) are typically shipped with tokenizers that
deterministically encode text into so-called canonical token sequences, to
which the LLMs assign probability values. One common assumption is that the
probability of a piece of text is the probability of its canonical token
sequence. However, the tokenization of a string is not unique: e.g., the Llama2
tokenizer encodes Tokens as [Tok,ens], but [Tok,en,s] also represents the same
text. In this paper, we study non-canonical tokenizations. We prove that, given
a string, it is computationally hard to find the most likely tokenization for
an autoregressive LLM, as well as to compute the marginal probability over all
possible tokenizations. We then show how the marginal is, in most cases,
indistinguishable from the canonical probability. Surprisingly, we then
empirically demonstrate the existence of a significant amount of signal hidden
within tokenization space. Notably, by simply aggregating the probabilities of
non-canonical tokenizations, we achieve improvements across a range of LLM
evaluation benchmarks for a variety of architectures, including transformers
and state space models.

摘要：大型語言模型 (LLM) 通常附帶用於將文字確定性編碼為所謂的正規符號序列的符號化器，LLM 會為其指定機率值。一個常見的假設是，一段文字的機率就是其正規符號序列的機率。然而，字串的符號化並不唯一：例如，Llama2 符號化器將符號編碼為 [Tok,ens]，但 [Tok,en,s] 也代表相同的文字。在本文中，我們研究非正規符號化。我們證明，給定一個字串，對於自迴歸 LLM 來說，要找出最可能的符號化在計算上很困難，而且要計算所有可能的符號化的邊際機率也很困難。然後我們展示邊際機率在多數情況下與正規機率無法區分。令人驚訝的是，我們接著以經驗方式證明符號化空間中隱藏著大量的訊號。值得注意的是，只要簡單地彙總非正規符號化的機率，我們就能在各種 LLM 評估基準中獲得進步，包括Transformer和狀態空間模型等各種架構。

##### **CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**
2408.08535v1 by Rong-Ching Chang, Jiawei Zhang

Despite advancements in Large Language Models (LLMs) and Retrieval-Augmented
Generation (RAG) systems, their effectiveness is often hindered by a lack of
integration with entity relationships and community structures, limiting their
ability to provide contextually rich and accurate information retrieval for
fact-checking. We introduce CommunityKG-RAG (Community Knowledge
Graph-Retrieval Augmented Generation), a novel zero-shot framework that
integrates community structures within Knowledge Graphs (KGs) with RAG systems
to enhance the fact-checking process. Capable of adapting to new domains and
queries without additional training, CommunityKG-RAG utilizes the multi-hop
nature of community structures within KGs to significantly improve the accuracy
and relevance of information retrieval. Our experimental results demonstrate
that CommunityKG-RAG outperforms traditional methods, representing a
significant advancement in fact-checking by offering a robust, scalable, and
efficient solution.

摘要：儘管大型語言模型 (LLM) 和檢索增強生成 (RAG) 系統有進步，但它們的有效性經常受到缺乏與實體關係和社群結構整合的阻礙，限制了它們提供脈絡豐富且準確的資訊檢索以進行事實查核的能力。我們介紹 CommunityKG-RAG（社群知識圖譜檢索增強生成），這是一個新穎的零次學習架構，它將知識圖譜 (KG) 內的社群結構與 RAG 系統整合，以增強事實查核流程。CommunityKG-RAG 無需額外訓練就能適應新的領域和查詢，它利用 KG 內社群結構的多跳特性，大幅提升資訊檢索的準確性和相關性。我們的實驗結果證明 CommunityKG-RAG 優於傳統方法，代表著事實查核的重大進步，提供了一個強健、可擴充且有效率的解決方案。

##### **Detecting Unsuccessful Students in Cybersecurity Exercises in Two Different Learning Environments**
2408.08531v1 by Valdemar Švábenský, Kristián Tkáčik, Aubrey Birdwell, Richard Weiss, Ryan S. Baker, Pavel Čeleda, Jan Vykopal, Jens Mache, Ankur Chattopadhyay

This full paper in the research track evaluates the usage of data logged from
cybersecurity exercises in order to predict students who are potentially at
risk of performing poorly. Hands-on exercises are essential for learning since
they enable students to practice their skills. In cybersecurity, hands-on
exercises are often complex and require knowledge of many topics. Therefore,
students may miss solutions due to gaps in their knowledge and become
frustrated, which impedes their learning. Targeted aid by the instructor helps,
but since the instructor's time is limited, efficient ways to detect struggling
students are needed. This paper develops automated tools to predict when a
student is having difficulty. We formed a dataset with the actions of 313
students from two countries and two learning environments: KYPO CRP and
EDURange. These data are used in machine learning algorithms to predict the
success of students in exercises deployed in these environments. After
extracting features from the data, we trained and cross-validated eight
classifiers for predicting the exercise outcome and evaluated their predictive
power. The contribution of this paper is comparing two approaches to feature
engineering, modeling, and classification performance on data from two learning
environments. Using the features from either learning environment, we were able
to detect and distinguish between successful and struggling students. A
decision tree classifier achieved the highest balanced accuracy and sensitivity
with data from both learning environments. The results show that activity data
from cybersecurity exercises are suitable for predicting student success. In a
potential application, such models can aid instructors in detecting struggling
students and providing targeted help. We publish data and code for building
these models so that others can adopt or adapt them.

摘要：<paragraph>這篇研究軌跡的完整論文評估了從網路安全練習中記錄的資料的使用，以預測潛在表現不佳的學生。動手練習對學習至關重要，因為它們能讓學生練習他們的技能。在網路安全中，動手練習通常很複雜，需要了解許多主題。因此，學生可能會因為知識上的差距而錯失解決方案，並感到沮喪，這會阻礙他們的學習。指導員的目標協助有幫助，但由於指導員的時間有限，因此需要有效的方法來找出有困難的學生。本文開發了自動化工具來預測學生何時遇到困難。我們從兩個國家和兩個學習環境（KYPO CRP 和 EDURange）的 313 名學生的行為中形成了一個資料集。這些資料用於機器學習演算法，以預測這些環境中部署的練習中學生的成功。從資料中提取特徵後，我們訓練並交叉驗證了八個分類器，以預測練習結果，並評估它們的預測能力。本文的貢獻是比較兩種特徵工程、建模和分類效能的方法，這些方法來自兩個學習環境的資料。使用來自任何學習環境的特徵，我們能夠檢測並區分成功的學生和有困難的學生。一個決策樹分類器在來自兩個學習環境的資料中達到了最高的平衡準確度和敏感度。結果表明，來自網路安全練習的活動資料適用於預測學生的成功。在潛在的應用中，此類模型可以幫助指導員檢測有困難的學生並提供目標協助。我們發布了用於建立這些模型的資料和程式碼，以便其他人可以採用或調整它們。</paragraph>

##### **Focus on Focus: Focus-oriented Representation Learning and Multi-view Cross-modal Alignment for Glioma Grading**
2408.08527v1 by Li Pan, Yupei Zhang, Qiushi Yang, Tan Li, Xiaohan Xing, Maximus C. F. Yeung, Zhen Chen

Recently, multimodal deep learning, which integrates histopathology slides
and molecular biomarkers, has achieved a promising performance in glioma
grading. Despite great progress, due to the intra-modality complexity and
inter-modality heterogeneity, existing studies suffer from inadequate
histopathology representation learning and inefficient molecular-pathology
knowledge alignment. These two issues hinder existing methods to precisely
interpret diagnostic molecular-pathology features, thereby limiting their
grading performance. Moreover, the real-world applicability of existing
multimodal approaches is significantly restricted as molecular biomarkers are
not always available during clinical deployment. To address these problems, we
introduce a novel Focus on Focus (FoF) framework with paired pathology-genomic
training and applicable pathology-only inference, enhancing molecular-pathology
representation effectively. Specifically, we propose a Focus-oriented
Representation Learning (FRL) module to encourage the model to identify regions
positively or negatively related to glioma grading and guide it to focus on the
diagnostic areas with a consistency constraint. To effectively link the
molecular biomarkers to morphological features, we propose a Multi-view
Cross-modal Alignment (MCA) module that projects histopathology representations
into molecular subspaces, aligning morphological features with corresponding
molecular biomarker status by supervised contrastive learning. Experiments on
the TCGA GBM-LGG dataset demonstrate that our FoF framework significantly
improves the glioma grading. Remarkably, our FoF achieves superior performance
using only histopathology slides compared to existing multimodal methods. The
source code is available at https://github.com/peterlipan/FoF.

摘要：<paragraph>最近，整合了组织病理学切片和分子生物标记的多模态深度学习在神经胶质瘤分级中取得了可喜的成果。尽管取得了巨大进展，但由于模态内复杂性和模态间异质性，现有研究存在组织病理学表征学习不足和分子病理学知识对齐效率低下的问题。这两个问题阻碍了现有方法精确解释诊断性分子病理学特征，从而限制了它们的评分性能。此外，现有多模态方法的实际适用性受到很大限制，因为在临床部署期间并不总是能获得分子生物标记。为了解决这些问题，我们引入了一个专注于焦点 (FoF) 的新框架，该框架采用配对的病理基因组学训练和适用的仅病理学推断，有效地增强了分子病理学表征。具体来说，我们提出了一个面向焦点的表征学习 (FRL) 模块，以鼓励模型识别与神经胶质瘤分级呈正相关或负相关的区域，并指导其专注于具有稠密约束的诊断区域。为了有效地将分子生物标记与形态学特征联系起来，我们提出了一个多视图跨模态对齐 (MCA) 模块，该模块将组织病理学表征投影到分子子空间，通过监督对比学习将形态学特征与相应的分子生物标记状态对齐。在 TCGA GBM-LGG 数据集上的实验表明，我们的 FoF 框架显着提高了神经胶质瘤分级。值得注意的是，与现有的多模态方法相比，我们的 FoF 仅使用组织病理学切片就取得了优异的性能。源代码可在 https://github.com/peterlipan/FoF 获得。</paragraph>

##### **Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding**
2408.08506v1 by Huang Lei, Jiaming Guo, Guanhua He, Xishan Zhang, Rui Zhang, Shaohui Peng, Shaoli Liu, Tianshi Chen

Generating long-term texts such as novels using artificial intelligence has
always been a challenge. A common approach is to use large language models
(LLMs) to construct a hierarchical framework that first plans and then writes.
Despite the fact that the generated novels reach a sufficient length, they
exhibit poor logical coherence and appeal in their plots and deficiencies in
character and event depiction, ultimately compromising the overall narrative
quality. In this paper, we propose a method named Extracting Excelsior and
Expanding. Ex3 initially extracts structure information from raw novel data. By
combining this structure information with the novel data, an
instruction-following dataset is meticulously crafted. This dataset is then
utilized to fine-tune the LLM, aiming for excelsior generation performance. In
the final stage, a tree-like expansion method is deployed to facilitate the
generation of arbitrarily long novels. Evaluation against previous methods
showcases Ex3's ability to produce higher-quality long-form novels.

摘要：使用人工智慧生成長篇文字（例如小說）一直是一項挑戰。常見的方法是使用大型語言模型 (LLM) 建立階層架構，先進行規劃，再進行寫作。儘管生成的長篇小說長度足夠，但情節缺乏邏輯一致性和吸引力，且在角色和事件描寫上有所不足，最終影響整體敘事的品質。在本文中，我們提出了一種名為「提取精華並擴充」的方法。Ex3 最初從原始小說資料中提取結構資訊。透過將此結構資訊與小說資料結合，精心製作一個遵循說明的資料集。然後使用此資料集微調 LLM，目標是獲得卓越的生成效能。在最後一個階段，部署樹狀擴充方法，以利於生成任意長度的長篇小說。與先前方法的評估結果顯示，Ex3 能夠產生品質更高的長篇小說。

##### **Adversarial Contrastive Learning Based Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation**
2408.08488v1 by Rui Wang, Mengshi Qi, Yingxia Shao, Anfu Zhou, Huadong Ma

Time series data mining is immensely important in extensive applications,
such as traffic, medical, and e-commerce. In this paper, we focus on medical
temporal variation modeling, \emph{i.e.,} cuffless blood pressure (BP)
monitoring which has great value in cardiovascular healthcare. Although
providing a comfortable user experience, such methods are suffering from the
demand for a significant amount of realistic data to train an individual model
for each subject, especially considering the invasive or obtrusive BP
ground-truth measurements. To tackle this challenge, we introduce a novel
physics-informed temporal network~(PITN) with adversarial contrastive learning
to enable precise BP estimation with very limited data. Specifically, we first
enhance the physics-informed neural network~(PINN) with the temporal block for
investigating BP dynamics' multi-periodicity for personal cardiovascular cycle
modeling and temporal variation. We then employ adversarial training to
generate extra physiological time series data, improving PITN's robustness in
the face of sparse subject-specific training data. Furthermore, we utilize
contrastive learning to capture the discriminative variations of cardiovascular
physiologic phenomena. This approach aggregates physiological signals with
similar blood pressure values in latent space while separating clusters of
samples with dissimilar blood pressure values. Experiments on three
widely-adopted datasets with different modailties (\emph{i.e.,} bioimpedance,
PPG, millimeter-wave) demonstrate the superiority and effectiveness of the
proposed methods over previous state-of-the-art approaches. The code is
available at~\url{https://github.com/Zest86/ACL-PITN}.

摘要：<paragraph>時間序列資料探勘在廣泛的應用中非常重要，例如交通、醫療和電子商務。在本文中，我們專注於醫療時間變異建模，即無袖血壓 (BP) 監測，這在心血管保健中具有極高的價值。儘管提供了舒適的使用者體驗，但此類方法卻苦於需要大量的實際資料來訓練每個受試者的個別模型，特別是考慮到侵入性或侵入性的 BP 真實測量。為了應對這一挑戰，我們引入了一個新的物理資訊時間網路 (PITN)，並結合對抗對比學習，以極少的資料進行精確的 BP 估計。具體來說，我們首先使用時間區塊增強了物理資訊神經網路 (PINN)，以研究 BP 動態的多週期性，用於個人心血管週期建模和時間變異。然後，我們採用對抗訓練來產生額外的生理時間序列資料，以提高 PITN 在稀疏受試者特定訓練資料面前的魯棒性。此外，我們利用對比學習來捕捉心血管生理現象的區別性變異。此方法將潛在空間中具有類似血壓值的生理訊號聚集在一起，同時將具有不同血壓值的樣本叢集分開。在三個廣泛採用的具有不同模態的資料集（即生物阻抗、PPG、毫米波）上的實驗證明了所提出的方法優於先前的最先進方法。程式碼可在~\url{https://github.com/Zest86/ACL-PITN}取得。</paragraph>

##### **An Unsupervised Learning Framework Combined with Heuristics for the Maximum Minimal Cut Problem**
2408.08484v1 by Huaiyuan Liu, Xianzhang Liu, Donghua Yang, Hongzhi Wang, Yingchi Long, Mengtong Ji, Dongjing Miao, Zhiyu Liang

The Maximum Minimal Cut Problem (MMCP), a NP-hard combinatorial optimization
(CO) problem, has not received much attention due to the demanding and
challenging bi-connectivity constraint. Moreover, as a CO problem, it is also a
daunting task for machine learning, especially without labeled instances. To
deal with these problems, this work proposes an unsupervised learning framework
combined with heuristics for MMCP that can provide valid and high-quality
solutions. As far as we know, this is the first work that explores machine
learning and heuristics to solve MMCP. The unsupervised solver is inspired by a
relaxation-plus-rounding approach, the relaxed solution is parameterized by
graph neural networks, and the cost and penalty of MMCP are explicitly written
out, which can train the model end-to-end. A crucial observation is that each
solution corresponds to at least one spanning tree. Based on this finding, a
heuristic solver that implements tree transformations by adding vertices is
utilized to repair and improve the solution quality of the unsupervised solver.
Alternatively, the graph is simplified while guaranteeing solution consistency,
which reduces the running time. We conduct extensive experiments to evaluate
our framework and give a specific application. The results demonstrate the
superiority of our method against two techniques designed.

摘要：最大最小割問題 (MMCP) 是一個 NP 難組合最佳化 (CO) 問題，由於要求嚴格且具有挑戰性的雙連通約束，因此未受到太多關注。此外，作為一個 CO 問題，對於機器學習而言也是一項艱鉅的任務，特別是在沒有標記實例的情況下。為了解決這些問題，本研究提出了一個無監督學習架構，結合 MMCP 的啟發式方法，可以提供有效且高品質的解決方案。據我們所知，這是第一個探討機器學習和啟發式方法來解決 MMCP 的研究。無監督求解器受到鬆弛加捨入方法的啟發，鬆弛解由圖神經網路參數化，而 MMCP 的成本和懲罰則明確寫出，這可以端到端地訓練模型。一個關鍵的觀察是，每個解都對應於至少一棵生成樹。基於這個發現，利用一個通過增加頂點來實作樹轉換的啟發式求解器，用於修復和改善無監督求解器的解品質。或者，在保證解一致性的同時簡化圖形，從而減少執行時間。我們進行了廣泛的實驗來評估我們的框架並給出一個具體的應用。結果證明了我們的方法優於兩種設計的技術。

##### **Fairness Issues and Mitigations in (Differentially Private) Socio-demographic Data Processes**
2408.08471v1 by Joonhyuk Ko, Juba Ziani, Saswat Das, Matt Williams, Ferdinando Fioretto

Statistical agencies rely on sampling techniques to collect socio-demographic
data crucial for policy-making and resource allocation. This paper shows that
surveys of important societal relevance introduce sampling errors that unevenly
impact group-level estimates, thereby compromising fairness in downstream
decisions. To address these issues, this paper introduces an optimization
approach modeled on real-world survey design processes, ensuring sampling costs
are optimized while maintaining error margins within prescribed tolerances.
Additionally, privacy-preserving methods used to determine sampling rates can
further impact these fairness issues. The paper explores the impact of
differential privacy on the statistics informing the sampling process,
revealing a surprising effect: not only the expected negative effect from the
addition of noise for differential privacy is negligible, but also this privacy
noise can in fact reduce unfairness as it positively biases smaller counts.
These findings are validated over an extensive analysis using datasets commonly
applied in census statistics.

摘要：統計機構依賴抽樣技術來收集對政策制定和資源分配至關重要的社會人口數據。本文顯示，具有重要社會相關性的調查會引入抽樣誤差，對組級估計產生不均勻的影響，從而損害下游決策的公平性。為了解決這些問題，本文介紹了一種以現實世界的調查設計流程為模型的優化方法，以確保在規定的容差範圍內優化抽樣成本，同時保持誤差範圍。此外，用於確定抽樣率的隱私保護方法可能會進一步影響這些公平性問題。本文探討了差分隱私對抽樣過程中的統計數據的影響，揭示了一個令人驚訝的影響：不僅差分隱私增加噪聲的預期負面影響可以忽略不計，而且這種隱私噪聲實際上可以減少不公平性，因為它對較小的計數產生正向偏差。這些發現通過使用通常應用於人口普查統計數據的數據集進行廣泛分析得到驗證。

##### **Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models**
2408.08470v1 by Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Sarath Chandar

Despite their widespread adoption, large language models (LLMs) remain
prohibitive to use under resource constraints, with their ever growing sizes
only increasing the barrier for use. One noted issue is the high latency
associated with auto-regressive generation, rendering large LLMs use dependent
on advanced computing infrastructure. Assisted decoding, where a smaller draft
model guides a larger target model's generation, has helped alleviate this, but
remains dependent on alignment between the two models. Thus if the draft model
is insufficiently capable on some domain relative to the target model,
performance can degrade. Alternatively, one can leverage multiple draft models
to better cover the expertise of the target, but when multiple black-box draft
models are available, selecting an assistant without details about its
construction can be difficult. To better understand this decision making
problem, we observe it as a contextual bandit, where a policy must choose a
draft model based on a context. We show that even without prior knowledge of
the draft models, creating an offline dataset from only outputs of independent
draft/target models and training a policy over the alignment of these outputs
can accelerate performance on multiple domains provided the candidates are
effective. Further results show this to hold on various settings with multiple
assisted decoding candidates, highlighting its flexibility and the advantageous
role that such decision making can play.

摘要：儘管大語言模型 (LLM) 廣泛採用，但由於其規模不斷擴大，在資源受限的情況下使用起來仍然有其限制，這只會增加使用障礙。一個著名的問題是與自迴歸生成相關的高延遲，這使得大型 LLM 的使用依賴於先進的運算基礎設施。輔助解碼，其中較小的草稿模型引導較大的目標模型生成，有助於緩解這個問題，但仍然依賴於兩個模型之間的一致性。因此，如果草稿模型在某些領域相對於目標模型的能力不足，則效能可能會下降。或者，人們可以利用多個草稿模型來更好地涵蓋目標的專業知識，但當有多個黑盒草稿模型可用時，在沒有關於其建構的詳細資訊的情況下選擇一個助手可能會很困難。為了更好地理解這個決策制定問題，我們將其視為一個情境強盜，其中一個策略必須根據一個情境選擇一個草稿模型。我們表明，即使沒有關於草稿模型的先驗知識，僅從獨立草稿/目標模型的輸出建立離線資料集，並根據這些輸出的對齊訓練一個策略，也可以加速多個領域的效能，前提是候選者是有效的。進一步的結果表明，這適用於具有多個輔助解碼候選者的各種設定，突顯了其靈活性以及此類決策制定可以發揮的有利作用。

##### **A theory of understanding for artificial intelligence: composability, catalysts, and learning**
2408.08463v1 by Zijian Zhang, Sara Aronowitz, Alán Aspuru-Guzik

Understanding is a crucial yet elusive concept in artificial intelligence
(AI). This work proposes a framework for analyzing understanding based on the
notion of composability. Given any subject (e.g., a person or an AI), we
suggest characterizing its understanding of an object in terms of its ability
to process (compose) relevant inputs into satisfactory outputs from the
perspective of a verifier. This highly universal framework can readily apply to
non-human subjects, such as AIs, non-human animals, and institutions. Further,
we propose methods for analyzing the inputs that enhance output quality in
compositions, which we call catalysts. We show how the structure of a subject
can be revealed by analyzing its components that act as catalysts and argue
that a subject's learning ability can be regarded as its ability to compose
inputs into its inner catalysts. Finally we examine the importance of learning
ability for AIs to attain general intelligence. Our analysis indicates that
models capable of generating outputs that can function as their own catalysts,
such as language models, establish a foundation for potentially overcoming
existing limitations in AI understanding.

摘要：理解是人工智能（AI）中一個至關重要的卻又難以捉摸的概念。這項工作提出了一個基於可組合性的理解分析框架。給定任何主體（例如，一個人或一個 AI），我們建議根據其將相關輸入處理（組合）成驗證者角度的滿意輸出的能力來表徵其對一個物體的理解。這個高度通用的框架可以很容易地應用於非人類主體，例如 AI、非人類動物和機構。此外，我們提出了分析增強組合中輸出質量的輸入的方法，我們稱之為催化劑。我們展示了如何通過分析充當催化劑的主體組成部分來揭示主體的結構，並論證主體的學習能力可以被視為其將輸入組合到其內部催化劑中的能力。最後，我們探討了學習能力對於 AI 達到一般智能的重要性。我們的分析表明，能夠生成可以作為其自身催化劑運作的輸出的模型，例如語言模型，為潛在地克服 AI 理解中的現有局限性奠定了基礎。

##### **JPEG-LM: LLMs as Image Generators with Canonical Codec Representations**
2408.08459v1 by Xiaochuang Han, Marjan Ghazvininejad, Pang Wei Koh, Yulia Tsvetkov

Recent work in image and video generation has been adopting the
autoregressive LLM architecture due to its generality and potentially easy
integration into multi-modal systems. The crux of applying autoregressive
training in language generation to visual generation is discretization --
representing continuous data like images and videos as discrete tokens. Common
methods of discretizing images and videos include modeling raw pixel values,
which are prohibitively lengthy, or vector quantization, which requires
convoluted pre-hoc training. In this work, we propose to directly model images
and videos as compressed files saved on computers via canonical codecs (e.g.,
JPEG, AVC/H.264). Using the default Llama architecture without any
vision-specific modifications, we pretrain JPEG-LM from scratch to generate
images (and AVC-LM to generate videos as a proof of concept), by directly
outputting compressed file bytes in JPEG and AVC formats. Evaluation of image
generation shows that this simple and straightforward approach is more
effective than pixel-based modeling and sophisticated vector quantization
baselines (on which our method yields a 31% reduction in FID). Our analysis
shows that JPEG-LM has an especial advantage over vector quantization models in
generating long-tail visual elements. Overall, we show that using canonical
codec representations can help lower the barriers between language generation
and visual generation, facilitating future research on multi-modal
language/image/video LLMs.

摘要：最近在影像和影片生成方面的工作开始采用自回归 LLM 架构，因为其通用性高且易于整合到多模式系统中。将自回归训练应用于语言生成到视觉生成的核心是离散化——将影像和影片等连续数据表示为离散标记。离散化影像和影片的常见方法包括建模原始像素值（长度过长）或向量量化（需要复杂的预先训练）。在这项工作中，我们建议直接将影像和影片建模为计算机上以规范编解码器（例如 JPEG、AVC/H.264）储存的压缩档案。在不进行任何特定于视觉的修改的情况下使用默认的 Llama 架构，我们从头预训练 JPEG-LM 来生成影像（并预训练 AVC-LM 以生成影片作为概念验证），方法是直接输出 JPEG 和 AVC 格式的压缩档案位元组。影像生成的评估显示，这种简单而直接的方法比基于像素的建模和复杂的向量量化基线（我们的方法在 FID 上减少了 31%）更有效。我们的分析显示，JPEG-LM 在生成长尾视觉元素方面特别优于向量量化模型。总体而言，我们表明使用规范编解码器表示可以帮助降低语言生成和视觉生成之间的障碍，促进未来对多模式语言/影像/影片 LLM 的研究。

##### **Efficient Data-Sketches and Fine-Tuning for Early Detection of Distributional Drift in Medical Imaging**
2408.08456v1 by Yusen Wu, Hao Chen, Alex Pissinou Makki, Phuong Nguyen, Yelena Yesha

Distributional drift detection is important in medical applications as it
helps ensure the accuracy and reliability of models by identifying changes in
the underlying data distribution that could affect diagnostic or treatment
decisions. However, current methods have limitations in detecting drift; for
example, the inclusion of abnormal datasets can lead to unfair comparisons.
This paper presents an accurate and sensitive approach to detect distributional
drift in CT-scan medical images by leveraging data-sketching and fine-tuning
techniques. We developed a robust baseline library model for real-time anomaly
detection, allowing for efficient comparison of incoming images and
identification of anomalies. Additionally, we fine-tuned a vision transformer
pre-trained model to extract relevant features using breast cancer images as an
example, significantly enhancing model accuracy to 99.11\%. Combining with
data-sketches and fine-tuning, our feature extraction evaluation demonstrated
that cosine similarity scores between similar datasets provide greater
improvements, from around 50\% increased to 100\%. Finally, the sensitivity
evaluation shows that our solutions are highly sensitive to even 1\%
salt-and-pepper and speckle noise, and it is not sensitive to lighting noise
(e.g., lighting conditions have no impact on data drift). The proposed methods
offer a scalable and reliable solution for maintaining the accuracy of
diagnostic models in dynamic clinical environments.

摘要：分配漂移检测在医疗应用中很重要，因为它
有助于确保模型的准确性和可靠性，方法是识别可能影响诊断或治疗的底层数据分布的变化
决定。然而，当前的方法在检测漂移方面存在局限性；例如，异常数据集的包含会导致不公平的比较。
本文提出了一种准确且敏感的方法来检测 CT 扫描医学图像中的分布漂移，方法是利用数据草图和微调
技术。我们开发了一个稳健的基线库模型，用于实时异常检测，允许对传入图像进行高效比较和
识别异常。此外，我们对视觉转换器预训练模型进行了微调，以使用乳腺癌图像作为示例提取相关特征，显着提高了模型准确率至 99.11%。结合
数据草图和微调，我们的特征提取评估表明，相似数据集之间的余弦相似度得分提供了更大的
改进，从增加约 50% 到 100%。最后，敏感性评估表明我们的解决方案对 1% 的椒盐噪声和斑点噪声高度敏感，并且对光照噪声不敏感
（例如，光照条件对数据漂移没有影响）。所提出的方法为保持诊断模型的准确性提供了一个可扩展且可靠的解决方案
在动态临床环境中。

##### **SpectralEarth: Training Hyperspectral Foundation Models at Scale**
2408.08447v1 by Nassim Ait Ali Braham, Conrad M Albrecht, Julien Mairal, Jocelyn Chanussot, Yi Wang, Xiao Xiang Zhu

Foundation models have triggered a paradigm shift in computer vision and are
increasingly being adopted in remote sensing, particularly for multispectral
imagery. Yet, their potential in hyperspectral imaging (HSI) remains untapped
due to the absence of comprehensive and globally representative hyperspectral
datasets. To close this gap, we introduce SpectralEarth, a large-scale
multi-temporal dataset designed to pretrain hyperspectral foundation models
leveraging data from the Environmental Mapping and Analysis Program (EnMAP).
SpectralEarth comprises 538,974 image patches covering 415,153 unique locations
from more than 11,636 globally distributed EnMAP scenes spanning two years of
archive. Additionally, 17.5% of these locations include multiple timestamps,
enabling multi-temporal HSI analysis. Utilizing state-of-the-art
self-supervised learning (SSL) algorithms, we pretrain a series of foundation
models on SpectralEarth. We integrate a spectral adapter into classical vision
backbones to accommodate the unique characteristics of HSI. In tandem, we
construct four downstream datasets for land-cover and crop-type mapping,
providing benchmarks for model evaluation. Experimental results support the
versatility of our models, showcasing their generalizability across different
tasks and sensors. We also highlight computational efficiency during model
fine-tuning. The dataset, models, and source code will be made publicly
available.

摘要：基礎模型在電腦視覺中引發了典範轉移，並在遙測中得到越來越廣泛的應用，特別是對於多光譜影像。然而，由於缺乏全面且具有全球代表性的高光譜資料集，它們在高光譜影像（HSI）中的潛力仍未得到開發。為了縮小這個差距，我們引入了 SpectralEarth，這是一個大規模的多時態資料集，旨在利用環境對應與分析計畫（EnMAP）的資料預訓練高光譜基礎模型。SpectralEarth 包含 538,974 個影像修補程式，涵蓋來自超過 11,636 個全球分佈的 EnMAP 場景的 415,153 個唯一位置，跨越兩年的檔案。此外，其中 17.5% 的位置包含多個時間戳記，從而實現多時態 HSI 分析。利用最先進的自我監督學習 (SSL) 演算法，我們在 SpectralEarth 上預訓練了一系列基礎模型。我們將光譜適配器整合到傳統視覺主幹中，以適應 HSI 的獨特特徵。同時，我們構建了四個用於土地覆蓋和作物類型對應的下游資料集，為模型評估提供了基準。實驗結果證實了我們模型的多功能性，展示了它們在不同任務和感測器上的泛化能力。我們還強調了模型微調期間的運算效率。資料集、模型和原始程式碼將公開提供。

##### **W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering**
2408.08444v1 by Jinming Nian, Zhiyuan Peng, Qifan Wang, Yi Fang

In knowledge-intensive tasks such as open-domain question answering (OpenQA),
Large Language Models (LLMs) often struggle to generate factual answers relying
solely on their internal (parametric) knowledge. To address this limitation,
Retrieval-Augmented Generation (RAG) systems enhance LLMs by retrieving
relevant information from external sources, thereby positioning the retriever
as a pivotal component. Although dense retrieval demonstrates state-of-the-art
performance, its training poses challenges due to the scarcity of ground-truth
evidence, largely attributed to the high costs of human annotation. In this
paper, we propose W-RAG by utilizing the ranking capabilities of LLMs to create
weakly labeled data for training dense retrievers. Specifically, we rerank the
top-$K$ passages retrieved via BM25 by assessing the probability that LLMs will
generate the correct answer based on the question and each passage. The
highest-ranking passages are then used as positive training examples for dense
retrieval. Our comprehensive experiments across four publicly available OpenQA
datasets demonstrate that our approach enhances both retrieval and OpenQA
performance compared to baseline models.

摘要：在開放領域問答 (OpenQA) 等知識密集型任務中，大型語言模型 (LLM) 常常難以僅憑藉其內部 (參數化) 知識來產生事實性的答案。為了解決這個限制，檢索增強型生成 (RAG) 系統透過從外部來源檢索相關資訊來增強 LLM，從而將檢索器定位為一個關鍵組成部分。儘管稠密檢索展示了最先進的效能，但由於缺乏基本事實證據，其訓練構成了挑戰，這在很大程度上歸因於人工標註的高成本。在本文中，我們提出 W-RAG，利用 LLM 的排名能力來建立用於訓練稠密檢索器的弱標籤資料。具體來說，我們透過評估 LLM 根據問題和每個章節產生正確答案的機率，重新對透過 BM25 檢索到的前 K 個章節進行排名。排名最高的章節隨後用作稠密檢索的正面訓練範例。我們在四個公開可用的 OpenQA 資料集上進行的全面實驗證明，與基準模型相比，我們的做法增強了檢索和 OpenQA 效能。

##### **PQV-Mobile: A Combined Pruning and Quantization Toolkit to Optimize Vision Transformers for Mobile Applications**
2408.08437v1 by Kshitij Bhardwaj

While Vision Transformers (ViTs) are extremely effective at computer vision
tasks and are replacing convolutional neural networks as the new
state-of-the-art, they are complex and memory-intensive models. In order to
effectively run these models on resource-constrained mobile/edge systems, there
is a need to not only compress these models but also to optimize them and
convert them into deployment-friendly formats. To this end, this paper presents
a combined pruning and quantization tool, called PQV-Mobile, to optimize vision
transformers for mobile applications. The tool is able to support different
types of structured pruning based on magnitude importance, Taylor importance,
and Hessian importance. It also supports quantization from FP32 to FP16 and
int8, targeting different mobile hardware backends. We demonstrate the
capabilities of our tool and show important latency-memory-accuracy trade-offs
for different amounts of pruning and int8 quantization with Facebook Data
Efficient Image Transformer (DeiT) models. Our results show that even pruning a
DeiT model by 9.375% and quantizing it to int8 from FP32 followed by optimizing
for mobile applications, we find a latency reduction by 7.18X with a small
accuracy loss of 2.24%. The tool is open source.

摘要：儘管視覺Transformer (ViT) 在電腦視覺任務中極為有效，且取代了卷積神經網路成為新的進步指標，但它們是複雜且需要大量記憶體的模型。為了在資源受限的行動/邊緣系統上有效執行這些模型，不僅需要壓縮這些模型，還需要最佳化它們，並將它們轉換成部署友善的格式。為此，本論文提出一個名為 PQV-Mobile 的結合剪枝與量化工具，以最佳化行動應用程式的視覺Transformer。此工具能夠支援基於幅度重要性、Taylor 重要性以及 Hessian 重要性的不同結構化剪枝類型。它也支援從 FP32 到 FP16 和 int8 的量化，鎖定不同的行動硬體後端。我們示範了我們工具的功能，並展示了 Facebook 資料高效能影像Transformer (DeiT) 模型在不同程度的剪枝與 int8 量化中重要的延遲-記憶體-精確度權衡。我們的結果顯示，即使將 DeiT 模型剪枝 9.375%，並從 FP32 量化為 int8，然後最佳化行動應用程式，我們發現延遲減少了 7.18 倍，精確度僅損失 2.24%。此工具是開源的。

##### **Automated Design of Agentic Systems**
2408.08435v1 by Shengran Hu, Cong Lu, Jeff Clune

Researchers are investing substantial effort in developing powerful
general-purpose agents, wherein Foundation Models are used as modules within
agentic systems (e.g. Chain-of-Thought, Self-Reflection, Toolformer). However,
the history of machine learning teaches us that hand-designed solutions are
eventually replaced by learned solutions. We formulate a new research area,
Automated Design of Agentic Systems (ADAS), which aims to automatically create
powerful agentic system designs, including inventing novel building blocks
and/or combining them in new ways. We further demonstrate that there is an
unexplored yet promising approach within ADAS where agents can be defined in
code and new agents can be automatically discovered by a meta agent programming
ever better ones in code. Given that programming languages are Turing Complete,
this approach theoretically enables the learning of any possible agentic
system: including novel prompts, tool use, control flows, and combinations
thereof. We present a simple yet effective algorithm named Meta Agent Search to
demonstrate this idea, where a meta agent iteratively programs interesting new
agents based on an ever-growing archive of previous discoveries. Through
extensive experiments across multiple domains including coding, science, and
math, we show that our algorithm can progressively invent agents with novel
designs that greatly outperform state-of-the-art hand-designed agents.
Importantly, we consistently observe the surprising result that agents invented
by Meta Agent Search maintain superior performance even when transferred across
domains and models, demonstrating their robustness and generality. Provided we
develop it safely, our work illustrates the potential of an exciting new
research direction toward automatically designing ever-more powerful agentic
systems to benefit humanity.

摘要：研究人員投入大量心力開發功能強大的通用代理，其中基礎模型被用作代理系統中的模組（例如思考鏈、自我反省、工具形成器）。然而，機器學習的歷史告訴我們，人工設計的解決方案最終會被學習到的解決方案取代。我們制定了一個新的研究領域，即代理系統自動設計 (ADAS)，其目標是自動建立強大的代理系統設計，包括發明新穎的建構區塊和/或以新方式組合它們。我們進一步證明，ADAS 中存在一種尚未探索但很有前景的方法，其中代理可以用程式碼定義，而新的代理可以由元代理自動發現，在程式碼中編寫出更好的代理。由於程式語言是圖靈完備的，因此此方法理論上可以學習任何可能的代理系統：包括新提示、工具使用、控制流程及其組合。我們提出了一個簡單但有效的演算法，名為元代理搜尋，以展示這個想法，其中元代理根據不斷成長的先前發現檔案，反覆編寫出有趣的新代理。透過在編碼、科學和數學等多個領域進行廣泛的實驗，我們證明我們的演算法可以逐步發明具有新穎設計的代理，其效能遠遠優於最先進的人工設計代理。重要的是，我們始終觀察到一個驚人的結果：即使在跨領域和模型傳輸時，由元代理搜尋發明的代理仍能維持優異的效能，證明它們的穩健性和普遍性。只要我們安全地開發它，我們的研究說明了一個令人興奮的新研究方向的潛力，即自動設計功能更強大的代理系統，以造福人類。

##### **Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts**
2408.08432v1 by Abdur R. Fayjie, Jutika Borah, Florencia Carbone, Jan Tack, Patrick Vandewalle

Deep learning has shown tremendous progress in a wide range of digital
pathology and medical image classification tasks. Its integration into safe
clinical decision-making support requires robust and reliable models. However,
real-world data comes with diversities that often lie outside the intended
source distribution. Moreover, when test samples are dramatically different,
clinical decision-making is greatly affected. Quantifying predictive
uncertainty in models is crucial for well-calibrated predictions and
determining when (or not) to trust a model. Unfortunately, many works have
overlooked the importance of predictive uncertainty estimation. This paper
evaluates whether predictive uncertainty estimation adds robustness to deep
learning-based diagnostic decision-making systems. We investigate the effect of
various carcinoma distribution shift scenarios on predictive performance and
calibration. We first systematically investigate three popular methods for
improving predictive uncertainty: Monte Carlo dropout, deep ensemble, and
few-shot learning on lung adenocarcinoma classification as a primary disease in
whole slide images. Secondly, we compare the effectiveness of the methods in
terms of performance and calibration under clinically relevant distribution
shifts such as in-distribution shifts comprising primary disease sub-types and
other characterization analysis data; out-of-distribution shifts comprising
well-differentiated cases, different organ origin, and imaging modality shifts.
While studies on uncertainty estimation exist, to our best knowledge, no
rigorous large-scale benchmark compares predictive uncertainty estimation
including these dataset shifts for lung carcinoma classification.

摘要：深度學習在廣泛的數位病理學和醫學影像分類任務中展現出驚人的進展。它整合到安全的臨床決策支援中需要強健且可靠的模型。然而，真實世界的資料會伴隨著多樣性，而這些多樣性通常超出了預期的來源分佈。此外，當測試樣本有極大的不同時，臨床決策制定會受到很大的影響。量化模型中的預測不確定性對於校準良好的預測以及決定何時（或不）信任模型至關重要。不幸的是，許多作品都忽略了預測不確定性估計的重要性。本文評估預測不確定性估計是否能為基於深度學習的診斷決策制定系統增加穩健性。我們探討各種癌症分佈轉移情境對預測效能和校準的影響。我們首先系統性地探討三種改善預測不確定性的熱門方法：蒙地卡羅輟學、深度整體和少次學習，以肺腺癌分類為主要疾病，在全幻燈片影像中進行。其次，我們比較這些方法在效能和校準方面的有效性，在臨床上相關的分佈轉移中，例如包含主要疾病子類型和其他表徵分析資料的分布內轉移；包含分化良好的病例、不同的器官來源和影像方式轉移的分布外轉移。儘管有關於不確定性估計的研究，但據我們所知，沒有嚴謹的大規模基準比較預測不確定性估計，包括這些資料集轉移以進行肺癌分類。

##### **Multi-Modal Dialogue State Tracking for Playing GuessWhich Game**
2408.08431v1 by Wei Pang, Ruixue Duan, Jinfu Yang, Ning Li

GuessWhich is an engaging visual dialogue game that involves interaction
between a Questioner Bot (QBot) and an Answer Bot (ABot) in the context of
image-guessing. In this game, QBot's objective is to locate a concealed image
solely through a series of visually related questions posed to ABot. However,
effectively modeling visually related reasoning in QBot's decision-making
process poses a significant challenge. Current approaches either lack visual
information or rely on a single real image sampled at each round as decoding
context, both of which are inadequate for visual reasoning. To address this
limitation, we propose a novel approach that focuses on visually related
reasoning through the use of a mental model of the undisclosed image. Within
this framework, QBot learns to represent mental imagery, enabling robust visual
reasoning by tracking the dialogue state. The dialogue state comprises a
collection of representations of mental imagery, as well as representations of
the entities involved in the conversation. At each round, QBot engages in
visually related reasoning using the dialogue state to construct an internal
representation, generate relevant questions, and update both the dialogue state
and internal representation upon receiving an answer. Our experimental results
on the VisDial datasets (v0.5, 0.9, and 1.0) demonstrate the effectiveness of
our proposed model, as it achieves new state-of-the-art performance across all
metrics and datasets, surpassing previous state-of-the-art models. Codes and
datasets from our experiments are freely available at
\href{https://github.com/xubuvd/GuessWhich}.

摘要：GuessWhich 是一款引人入勝的視覺對話遊戲，包含在圖像猜謎情境中，問答機器人 (QBot) 和回答機器人 (ABot) 之間的互動。在這個遊戲中，QBot 的目標是僅透過向 ABot 提出的一系列視覺相關問題，來找出隱藏的圖像。然而，在 QBot 的決策過程中有效地建模視覺相關推理，是一個重大的挑戰。目前的做法不是缺乏視覺資訊，就是依賴在每一輪中取樣的單一真實圖像作為解碼情境，這兩種做法都不足以進行視覺推理。為了解決這個限制，我們提出了一種新穎的方法，專注於透過使用未公開圖像的心智模型，進行視覺相關推理。在這個架構中，QBot 學習表徵心智意象，透過追蹤對話狀態，啟用強健的視覺推理。對話狀態包含心智意象表徵的集合，以及對話中所涉及實體的表徵。在每一輪中，QBot 使用對話狀態進行視覺相關推理，以建構內部表徵、產生相關問題，並在收到答案時更新對話狀態和內部表徵。我們在 VisDial 資料集 (v0.5、0.9 和 1.0) 上的實驗結果證明了我們所提出的模型的有效性，因為它在所有指標和資料集上都達到了新的最先進效能，超越了先前的最先進模型。我們實驗的程式碼和資料集可以在 \href{https://github.com/xubuvd/GuessWhich} 免費取得。

##### **Assessing and Enhancing Large Language Models in Rare Disease Question-answering**
2408.08422v1 by Guanchu Wang, Junhao Ran, Ruixiang Tang, Chia-Yuan Chang, Chia-Yuan Chang, Yu-Neng Chuang, Zirui Liu, Vladimir Braverman, Zhandong Liu, Xia Hu

Despite the impressive capabilities of Large Language Models (LLMs) in
general medical domains, questions remain about their performance in diagnosing
rare diseases. To answer this question, we aim to assess the diagnostic
performance of LLMs in rare diseases, and explore methods to enhance their
effectiveness in this area. In this work, we introduce a rare disease
question-answering (ReDis-QA) dataset to evaluate the performance of LLMs in
diagnosing rare diseases. Specifically, we collected 1360 high-quality
question-answer pairs within the ReDis-QA dataset, covering 205 rare diseases.
Additionally, we annotated meta-data for each question, facilitating the
extraction of subsets specific to any given disease and its property. Based on
the ReDis-QA dataset, we benchmarked several open-source LLMs, revealing that
diagnosing rare diseases remains a significant challenge for these models.
  To facilitate retrieval augmentation generation for rare disease diagnosis,
we collect the first rare diseases corpus (ReCOP), sourced from the National
Organization for Rare Disorders (NORD) database. Specifically, we split the
report of each rare disease into multiple chunks, each representing a different
property of the disease, including their overview, symptoms, causes, effects,
related disorders, diagnosis, and standard therapies. This structure ensures
that the information within each chunk aligns consistently with a question.
Experiment results demonstrate that ReCOP can effectively improve the accuracy
of LLMs on the ReDis-QA dataset by an average of 8%. Moreover, it significantly
guides LLMs to generate trustworthy answers and explanations that can be traced
back to existing literature.

摘要：儘管大型語言模型 (LLM) 在一般醫學領域擁有令人印象深刻的能力，但對於它們在診斷罕見疾病方面的表現仍有疑問。為了回答這個問題，我們旨在評估 LLM 在罕見疾病中的診斷表現，並探討增強它們在這個領域的有效性的方法。在這項工作中，我們引入了一個罕見疾病問答 (ReDis-QA) 資料集，以評估 LLM 在診斷罕見疾病方面的表現。具體來說，我們在 ReDis-QA 資料集中收集了 1360 個高品質的問題解答對，涵蓋 205 種罕見疾病。此外，我們為每個問題註釋了元資料，以利於提取特定於任何給定疾病及其屬性的子集。根據 ReDis-QA 資料集，我們對幾個開源 LLM 進行了基準測試，結果表明診斷罕見疾病仍然是這些模型的一項重大挑戰。為了促進罕見疾病診斷的檢索增強生成，我們收集了第一個罕見疾病語料庫 (ReCOP)，其來源於國家罕見疾病組織 (NORD) 資料庫。具體來說，我們將每種罕見疾病的報告分成多個區塊，每個區塊代表疾病的不同屬性，包括其概述、症狀、原因、影響、相關疾病、診斷和標準療法。這種結構確保每個區塊中的資訊與問題保持一致。實驗結果表明，ReCOP 可以有效地將 LLM 在 ReDis-QA 資料集上的準確度平均提高 8%。此外，它顯著地引導 LLM 生成可信的答案和解釋，這些答案和解釋可以追溯到現有文獻。

##### **Understanding Help-Seeking Behavior of Students Using LLMs vs. Web Search for Writing SQL Queries**
2408.08401v1 by Harsh Kumar, Mohi Reza, Jeb Mitchell, Ilya Musabirov, Lisa Zhang, Michael Liut

Growth in the use of large language models (LLMs) in programming education is
altering how students write SQL queries. Traditionally, students relied heavily
on web search for coding assistance, but this has shifted with the adoption of
LLMs like ChatGPT. However, the comparative process and outcomes of using web
search versus LLMs for coding help remain underexplored. To address this, we
conducted a randomized interview study in a database classroom to compare web
search and LLMs, including a publicly available LLM (ChatGPT) and an
instructor-tuned LLM, for writing SQL queries. Our findings indicate that using
an instructor-tuned LLM required significantly more interactions than both
ChatGPT and web search, but resulted in a similar number of edits to the final
SQL query. No significant differences were found in the quality of the final
SQL queries between conditions, although the LLM conditions directionally
showed higher query quality. Furthermore, students using instructor-tuned LLM
reported a lower mental demand. These results have implications for learning
and productivity in programming education.

摘要：大型語言模型 (LLM) 在程式設計教育中的使用成長正在改變學生撰寫 SQL 查詢的方式。傳統上，學生仰賴網路搜尋來協助編碼，但這已隨著 ChatGPT 等 LLM 的採用而有所改變。然而，使用網路搜尋與 LLM 來協助編碼的比較過程和結果仍未受到充分探討。為了解決這個問題，我們在資料庫教室中進行了一項隨機訪談研究，以比較網路搜尋和 LLM，包括公開可用的 LLM (ChatGPT) 和教師調整的 LLM，用於撰寫 SQL 查詢。我們的研究結果表明，使用教師調整的 LLM 所需的互動次數明顯多於 ChatGPT 和網路搜尋，但對最終 SQL 查詢的編輯次數卻類似。在不同條件下的最終 SQL 查詢品質並未發現顯著差異，儘管 LLM 條件在方向上顯示出較高的查詢品質。此外，使用教師調整 LLM 的學生回報較低的心理需求。這些結果對程式設計教育中的學習和生產力具有影響。

##### **Zero-Shot Learning and Key Points Are All You Need for Automated Fact-Checking**
2408.08400v1 by Mohammad Ghiasvand Mohammadkhani, Ali Ghiasvand Mohammadkhani, Hamid Beigy

Automated fact-checking is an important task because determining the accurate
status of a proposed claim within the vast amount of information available
online is a critical challenge. This challenge requires robust evaluation to
prevent the spread of false information. Modern large language models (LLMs)
have demonstrated high capability in performing a diverse range of Natural
Language Processing (NLP) tasks. By utilizing proper prompting strategies,
their versatility due to their understanding of large context sizes and
zero-shot learning ability enables them to simulate human problem-solving
intuition and move towards being an alternative to humans for solving problems.
In this work, we introduce a straightforward framework based on Zero-Shot
Learning and Key Points (ZSL-KeP) for automated fact-checking, which despite
its simplicity, performed well on the AVeriTeC shared task dataset by robustly
improving the baseline and achieving 10th place.

摘要：自動化事實查核是一項重要的任務，因為在網路上大量可得的資訊中判斷一個主張的準確狀態是一項重大的挑戰。這個挑戰需要強健的評估以防止錯誤資訊的散播。現代的大型語言模型 (LLM) 已展現出執行各種自然語言處理 (NLP) 任務的高能力。透過使用適當的提示策略，它們由於理解大型脈絡大小和零次學習能力的多功能性，使它們能模擬人類解決問題的直覺，並朝著成為人類解決問題的替代方案邁進。在這項工作中，我們介紹了一個基於零次學習和重點 (ZSL-KeP) 的直接架構，用於自動化事實查核，儘管它很簡單，但在 AVeriTeC 共享任務資料集上表現良好，透過強健地改善基準並獲得第 10 名。

##### **Level Up Your Tutorials: VLMs for Game Tutorials Quality Assessment**
2408.08396v1 by Daniele Rege Cambrin, Gabriele Scaffidi Militone, Luca Colomba, Giovanni Malnati, Daniele Apiletti, Paolo Garza

Designing effective game tutorials is crucial for a smooth learning curve for
new players, especially in games with many rules and complex core mechanics.
Evaluating the effectiveness of these tutorials usually requires multiple
iterations with testers who have no prior knowledge of the game. Recent
Vision-Language Models (VLMs) have demonstrated significant capabilities in
understanding and interpreting visual content. VLMs can analyze images, provide
detailed insights, and answer questions about their content. They can recognize
objects, actions, and contexts in visual data, making them valuable tools for
various applications, including automated game testing. In this work, we
propose an automated game-testing solution to evaluate the quality of game
tutorials. Our approach leverages VLMs to analyze frames from video game
tutorials, answer relevant questions to simulate human perception, and provide
feedback. This feedback is compared with expected results to identify confusing
or problematic scenes and highlight potential errors for developers. In
addition, we publish complete tutorial videos and annotated frames from
different game versions used in our tests. This solution reduces the need for
extensive manual testing, especially by speeding up and simplifying the initial
development stages of the tutorial to improve the final game experience.

摘要：設計有效的遊戲教學課程對於新玩家的順利學習曲線至關重要，特別是在具有許多規則和複雜核心機制的遊戲中。評估這些教學課程的有效性通常需要與對遊戲沒有任何先備知識的測試人員進行多次迭代。最近的視覺語言模型 (VLM) 已展現出在理解和詮釋視覺內容方面的顯著能力。VLM 可以分析影像、提供詳細見解，並回答有關其內容的問題。它們可以辨識視覺資料中的物件、動作和背景，使其成為各種應用程式的寶貴工具，包括自動化遊戲測試。在這項工作中，我們提出一個自動化遊戲測試解決方案來評估遊戲教學課程的品質。我們的做法利用 VLM 來分析電子遊戲教學課程中的畫面、回答相關問題以模擬人類感知，並提供回饋。此回饋會與預期結果進行比較，以找出令人困惑或有問題的場景，並重點指出開發人員的潛在錯誤。此外，我們會發布在測試中使用的不同遊戲版本的完整教學課程影片和註解畫面。此解決方案減少了廣泛手動測試的需求，特別是透過加速和簡化教學課程的初始開發階段，以改善最終的遊戲體驗。

##### **Towards Realistic Synthetic User-Generated Content: A Scaffolding Approach to Generating Online Discussions**
2408.08379v1 by Krisztian Balog, John Palowitch, Barbara Ikica, Filip Radlinski, Hamidreza Alvari, Mehdi Manshadi

The emergence of synthetic data represents a pivotal shift in modern machine
learning, offering a solution to satisfy the need for large volumes of data in
domains where real data is scarce, highly private, or difficult to obtain. We
investigate the feasibility of creating realistic, large-scale synthetic
datasets of user-generated content, noting that such content is increasingly
prevalent and a source of frequently sought information. Large language models
(LLMs) offer a starting point for generating synthetic social media discussion
threads, due to their ability to produce diverse responses that typify online
interactions. However, as we demonstrate, straightforward application of LLMs
yields limited success in capturing the complex structure of online
discussions, and standard prompting mechanisms lack sufficient control. We
therefore propose a multi-step generation process, predicated on the idea of
creating compact representations of discussion threads, referred to as
scaffolds. Our framework is generic yet adaptable to the unique characteristics
of specific social media platforms. We demonstrate its feasibility using data
from two distinct online discussion platforms. To address the fundamental
challenge of ensuring the representativeness and realism of synthetic data, we
propose a portfolio of evaluation measures to compare various instantiations of
our framework.

摘要：合成資料的出現代表了現代機器學習的關鍵轉變，它提供了一個解決方案來滿足在實際資料稀少、高度私密或難以取得的領域中對大量資料的需求。我們探討建立大量且逼真的使用者產生內容合成資料集的可行性，並注意到此類內容越來越普遍，且是經常尋求的資訊來源。大型語言模型 (LLM) 由於能夠產生多樣化的回應，代表著線上互動的典型，因此提供了產生合成社群媒體討論串的起點。然而，正如我們所展示的，LLM 的直接應用在捕捉線上討論的複雜結構方面僅能獲得有限的成功，且標準提示機制缺乏足夠的控制。因此，我們提出了一個多步驟生成程序，以建立討論串的精簡表示（稱為架構）的概念為基礎。我們的架構具有通用性，但能夠適應特定社群媒體平台的獨特特性。我們使用來自兩個不同線上討論平台的資料來證明其可行性。為了應對確保合成資料的代表性和真實性的基本挑戰，我們提出了一系列評估措施，以比較我們架構的各種實例。

##### **Decoding the human brain tissue response to radiofrequency excitation using a biophysical-model-free deep MRI on a chip framework**
2408.08376v1 by Dinor Nagar, Moritz Zaiss, Or Perlman

Magnetic resonance imaging (MRI) relies on radiofrequency (RF) excitation of
proton spin. Clinical diagnosis requires a comprehensive collation of
biophysical data via multiple MRI contrasts, acquired using a series of RF
sequences that lead to lengthy examinations. Here, we developed a vision
transformer-based framework that captures the spatiotemporal magnetic signal
evolution and decodes the brain tissue response to RF excitation, constituting
an MRI on a chip. Following a per-subject rapid calibration scan (28.2 s), a
wide variety of image contrasts including fully quantitative molecular, water
relaxation, and magnetic field maps can be generated automatically. The method
was validated across healthy subjects and a cancer patient in two different
imaging sites, and proved to be 94% faster than alternative protocols. The deep
MRI on a chip (DeepMonC) framework may reveal the molecular composition of the
human brain tissue in a wide range of pathologies, while offering clinically
attractive scan times.

摘要：磁振造影 (MRI) 仰賴射頻 (RF) 激發質子自旋。臨床診斷需要透過多種 MRI 對比來全面收集生物物理資料，並使用一系列會導致冗長檢查的 RF 序列取得。在此，我們開發了一個基於視覺轉換器的架構，可擷取時空磁訊號演化並解碼腦組織對 RF 激發的反應，構成晶片上的 MRI。在每次受試者的快速校正掃描 (28.2 秒) 之後，可以自動產生各種影像對比，包括完全量化的分子、水弛緩和磁場圖。此方法已在健康受試者和癌症患者身上於兩個不同的影像檢查地點進行驗證，並證明比其他方案快 94%。晶片上的深度 MRI (DeepMonC) 架構可能會揭示各種病理中人腦組織的分子組成，同時提供臨床上有吸引力的掃描時間。

##### **Can Large Language Models Understand Symbolic Graphics Programs?**
2408.08313v1 by Zeju Qiu, Weiyang Liu, Haiwen Feng, Zhen Liu, Tim Z. Xiao, Katherine M. Collins, Joshua B. Tenenbaum, Adrian Weller, Michael J. Black, Bernhard Schölkopf

Assessing the capabilities of large language models (LLMs) is often
challenging, in part, because it is hard to find tasks to which they have not
been exposed during training. We take one step to address this challenge by
turning to a new task: focusing on symbolic graphics programs, which are a
popular representation for graphics content that procedurally generates visual
data. LLMs have shown exciting promise towards program synthesis, but do they
understand symbolic graphics programs? Unlike conventional programs, symbolic
graphics programs can be translated to graphics content. Here, we characterize
an LLM's understanding of symbolic programs in terms of their ability to answer
questions related to the graphics content. This task is challenging as the
questions are difficult to answer from the symbolic programs alone -- yet, they
would be easy to answer from the corresponding graphics content as we verify
through a human experiment. To understand symbolic programs, LLMs may need to
possess the ability to imagine how the corresponding graphics content would
look without directly accessing the rendered visual content. We use this task
to evaluate LLMs by creating a large benchmark for the semantic understanding
of symbolic graphics programs. This benchmark is built via program-graphics
correspondence, hence requiring minimal human efforts. We evaluate current LLMs
on our benchmark to elucidate a preliminary assessment of their ability to
reason about visual scenes from programs. We find that this task distinguishes
existing LLMs and models considered good at reasoning perform better. Lastly,
we introduce Symbolic Instruction Tuning (SIT) to improve this ability.
Specifically, we query GPT4-o with questions and images generated by symbolic
programs. Such data are then used to finetune an LLM. We also find that SIT
data can improve the general instruction following ability of LLMs.

摘要：<paragraph>評估大型語言模型 (LLM) 的功能通常具有挑戰性，部分原因是難以找到在訓練過程中未接觸過的任務。我們透過專注於符號圖形程式這個新任務來解決此挑戰，符號圖形程式是圖形內容的熱門表示形式，可循序產生視覺資料。LLM 已在程式合成方面展現令人興奮的前景，但它們是否了解符號圖形程式？與傳統程式不同，符號圖形程式可以轉換為圖形內容。在此，我們根據 LLM 回答與圖形內容相關問題的能力，來描述其對符號程式的理解。這項任務具有挑戰性，因為僅從符號程式中很難回答這些問題，但從對應的圖形內容中很容易就能回答，我們透過人體實驗驗證了這一點。若要了解符號程式，LLM 可能需要具備想像對應圖形內容外觀的能力，而無需直接存取已渲染的視覺內容。我們使用此任務透過為符號圖形程式的語意理解建立大型基準，來評估 LLM。此基準是透過程式圖形對應建立，因此需要最少的人力。我們在基準上評估目前的 LLM，以闡明其從程式中推論視覺場景的能力的初步評估。我們發現此任務區分了現有的 LLM，並且被認為擅長推理的模型表現得更好。最後，我們引入了符號指令調整 (SIT) 來提升此能力。具體來說，我們使用符號程式產生的問題和影像查詢 GPT4-o。此類資料隨後用於微調 LLM。我們也發現 SIT 資料可以提升 LLM 的一般指令遵循能力。</paragraph>

##### **ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**
2408.08310v1 by Ruihang Li, Yixuan Wei, Miaosen Zhang, Nenghai Yu, Han Hu, Houwen Peng

High-quality data is crucial for the pre-training performance of large
language models. Unfortunately, existing quality filtering methods rely on a
known high-quality dataset as reference, which can introduce potential bias and
compromise diversity. In this paper, we propose ScalingFilter, a novel approach
that evaluates text quality based on the perplexity difference between two
language models trained on the same data, thereby eliminating the influence of
the reference dataset in the filtering process. An theoretical analysis shows
that ScalingFilter is equivalent to an inverse utilization of scaling laws.
Through training models with 1.3B parameters on the same data source processed
by various quality filters, we find ScalingFilter can improve zero-shot
performance of pre-trained models in downstream tasks. To assess the bias
introduced by quality filtering, we introduce semantic diversity, a metric of
utilizing text embedding models for semantic representations. Extensive
experiments reveal that semantic diversity is a reliable indicator of dataset
diversity, and ScalingFilter achieves an optimal balance between downstream
performance and semantic diversity.

摘要：高质量的数据对于大型语言模型的预训练性能至关重要。不幸的是，现有的质量过滤方法依赖于已知的高质量数据集作为参考，这可能会引入潜在的偏差并损害多样性。在本文中，我们提出了 ScalingFilter，这是一种新颖的方法，它根据在同一数据上训练的两个语言模型之间的困惑度差异来评估文本质量，从而消除了过滤过程中参考数据集的影响。理论分析表明，ScalingFilter 等效于对标度定律的反向利用。通过使用各种质量过滤器处理的相同数据源对具有 1.3B 参数的训练模型，我们发现 ScalingFilter 可以提高预训练模型在下游任务中的零样本性能。为了评估质量过滤引入的偏差，我们引入了语义多样性，这是一种利用文本嵌入模型进行语义表示的度量。大量的实验表明，语义多样性是数据集多样性的可靠指标，而 ScalingFilter 在下游性能和语义多样性之间实现了最佳平衡。

##### **Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**
2408.08302v1 by Usman Syed, Ethan Light, Xingang Guo, Huan Zhang, Lianhui Qin, Yanfeng Ouyang, Bin Hu

In this paper, we explore the capabilities of state-of-the-art large language
models (LLMs) such as GPT-4, GPT-4o, Claude 3.5 Sonnet, Claude 3 Opus, Gemini
1.5 Pro, Llama 3, and Llama 3.1 in solving some selected undergraduate-level
transportation engineering problems. We introduce TransportBench, a benchmark
dataset that includes a sample of transportation engineering problems on a wide
range of subjects in the context of planning, design, management, and control
of transportation systems. This dataset is used by human experts to evaluate
the capabilities of various commercial and open-sourced LLMs, especially their
accuracy, consistency, and reasoning behaviors, in solving transportation
engineering problems. Our comprehensive analysis uncovers the unique strengths
and limitations of each LLM, e.g. our analysis shows the impressive accuracy
and some unexpected inconsistent behaviors of Claude 3.5 Sonnet in solving
TransportBench problems. Our study marks a thrilling first step toward
harnessing artificial general intelligence for complex transportation
challenges.

摘要：在本文中，我們探討了最先進大型語言模型 (LLM) 的能力，例如 GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3 和 Llama 3.1，以解決一些選定的大學部級交通工程問題。我們引入了 TransportBench，這是一個基準數據集，其中包含在規劃、設計、管理和交通系統控制的廣泛主題中的一系列交通工程問題範例。此數據集由人類專家用於評估各種商業和開源 LLM 的能力，特別是它們在解決交通工程問題時的準確性、一致性和推理行為。我們的全面分析揭示了每種 LLM 獨特的優勢和限制，例如我們的分析顯示了 Claude 3.5 Sonnet 在解決 TransportBench 問題時令人印象深刻的準確性和一些意外的不一致行為。我們的研究標誌著朝著利用人工通用智慧來應對複雜的交通挑戰邁出的令人興奮的第一步。

##### **SLCA++: Unleash the Power of Sequential Fine-tuning for Continual Learning with Pre-training**
2408.08295v1 by Gengwei Zhang, Liyuan Wang, Guoliang Kang, Ling Chen, Yunchao Wei

In recent years, continual learning with pre-training (CLPT) has received
widespread interest, instead of its traditional focus of training from scratch.
The use of strong pre-trained models (PTMs) can greatly facilitate knowledge
transfer and alleviate catastrophic forgetting, but also suffers from
progressive overfitting of pre-trained knowledge into specific downstream
tasks. A majority of current efforts often keep the PTMs frozen and incorporate
task-specific prompts to instruct representation learning, coupled with a
prompt selection process for inference. However, due to the limited capacity of
prompt parameters, this strategy demonstrates only sub-optimal performance in
continual learning. In comparison, tuning all parameters of PTMs often provides
the greatest potential for representation learning, making sequential
fine-tuning (Seq FT) a fundamental baseline that has been overlooked in CLPT.
To this end, we present an in-depth analysis of the progressive overfitting
problem from the lens of Seq FT. Considering that the overly fast
representation learning and the biased classification layer constitute this
particular problem, we introduce the advanced Slow Learner with Classifier
Alignment (SLCA++) framework to unleash the power of Seq FT, serving as a
strong baseline approach for CLPT. Our approach involves a Slow Learner to
selectively reduce the learning rate of backbone parameters, and a Classifier
Alignment to align the disjoint classification layers in a post-hoc fashion. We
further enhance the efficacy of SL with a symmetric cross-entropy loss, as well
as employ a parameter-efficient strategy to implement Seq FT with SLCA++.
Across a variety of continual learning scenarios on image classification
benchmarks, our approach provides substantial improvements and outperforms
state-of-the-art methods by a large margin. Code:
https://github.com/GengDavid/SLCA.

摘要：近年來，持續學習與預訓練 (CLPT) 受到廣泛關注，取代傳統從頭開始訓練的重點。使用強大的預訓練模型 (PTM) 可以大幅促進知識轉移，並減輕災難性遺忘，但也飽受特定下游任務中預訓練知識的漸進過度擬合所苦。目前大多數方法通常保持 PTM 凍結，並結合特定於任務的提示，以指導表徵學習，再搭配提示選取程序進行推論。然而，由於提示參數的容量有限，此策略在持續學習中僅展現次佳效能。相比之下，調整 PTM 的所有參數通常能提供表徵學習最大的潛力，讓循序漸進微調 (Seq FT) 成為 CLPT 中被忽略的基本基準。為此，我們從 Seq FT 的角度深入分析漸進過度擬合問題。考量到過於快速表徵學習和帶有偏差的分類層構成此特定問題，我們推出進階的慢學習器與分類器校準 (SLCA++) 架構，以發揮 Seq FT 的強大功能，作為 CLPT 的強大基準方法。我們的做法包括慢學習器，以選擇性降低主幹參數的學習率，以及分類器校準，以事後方式校準不相交的分類層。我們進一步透過對稱交叉熵損失增強 SL 的效能，並採用參數有效率的策略，以 SLCA++ 實作 Seq FT。在影像分類基準上的各種持續學習情境中，我們的做法提供了大幅改善，並以極大差距超越現有技術。程式碼：https://github.com/GengDavid/SLCA。

##### **The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**
2408.08291v1 by Shachar Don-Yehiya, Leshem Choshen, Omri Abend

Human-model conversations provide a window into users' real-world scenarios,
behavior, and needs, and thus are a valuable resource for model development and
research. While for-profit companies collect user data through the APIs of
their models, using it internally to improve their own models, the open source
and research community lags behind.
  We introduce the ShareLM collection, a unified set of human conversations
with large language models, and its accompanying plugin, a Web extension for
voluntarily contributing user-model conversations. Where few platforms share
their chats, the ShareLM plugin adds this functionality, thus, allowing users
to share conversations from most platforms. The plugin allows the user to rate
their conversations, both at the conversation and the response levels, and
delete conversations they prefer to keep private before they ever leave the
user's local storage. We release the plugin conversations as part of the
ShareLM collection, and call for more community effort in the field of open
human-model data.
  The code, plugin, and data are available.

摘要：人類與模型的對話提供了使用者真實世界情境、行為和需求的窗口，因此對於模型開發和研究來說，這是一個有價值的資源。雖然營利公司透過其模型的 API 來收集使用者資料，並在內部使用這些資料來改善其自己的模型，但開源和研究社群卻落後了。
我們推出了 ShareLM 蒐集，這是一組與大型語言模型進行的人類對話的統一集合，以及其附屬外掛程式，一個用於自願貢獻使用者模型對話的網路擴充功能。在少數平台分享其對話的情況下，ShareLM 外掛程式增加了此功能，因此允許使用者分享大多數平台的對話。該外掛程式允許使用者評分他們的對話，無論是在對話層級或回應層級，並在對話離開使用者的本機儲存空間之前刪除他們偏好保持私密的對話。我們將外掛程式對話作為 ShareLM 蒐集的一部分釋出，並呼籲在開放人類模型資料領域中進行更多社群努力。
程式碼、外掛程式和資料都已提供。

##### **Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**
2408.08282v1 by Jin Wang, Arturo Laurenzi, Nikos Tsagarakis

Enabling humanoid robots to perform autonomously loco-manipulation in
unstructured environments is crucial and highly challenging for achieving
embodied intelligence. This involves robots being able to plan their actions
and behaviors in long-horizon tasks while using multi-modality to perceive
deviations between task execution and high-level planning. Recently, large
language models (LLMs) have demonstrated powerful planning and reasoning
capabilities for comprehension and processing of semantic information through
robot control tasks, as well as the usability of analytical judgment and
decision-making for multi-modal inputs. To leverage the power of LLMs towards
humanoid loco-manipulation, we propose a novel language-model based framework
that enables robots to autonomously plan behaviors and low-level execution
under given textual instructions, while observing and correcting failures that
may occur during task execution. To systematically evaluate this framework in
grounding LLMs, we created the robot 'action' and 'sensing' behavior library
for task planning, and conducted mobile manipulation tasks and experiments in
both simulated and real environments using the CENTAURO robot, and verified the
effectiveness and application of this approach in robotic tasks with autonomous
behavioral planning.

摘要：讓類人機器人在非結構化環境中執行自主運動操縱對於實現具身智能至關重要且極具挑戰性。這涉及機器人在執行多視角任務時能夠規劃其動作和行為，同時使用多模態來感知任務執行和高層級規劃之間的偏差。最近，大型語言模型 (LLM) 已展示出強大的規劃和推理能力，可用於理解和處理語義信息，通過機器人控制任務，以及分析判斷和決策制定對多模態輸入的可用性。為了將 LLM 的能力運用於類人運動操縱，我們提出了一個基於語言模型的新框架，該框架使機器人能夠在給定的文本指令下自主規劃行為和低層級執行，同時觀察和糾正任務執行期間可能發生的故障。為了系統地評估這個在 LLM 中的框架，我們創建了機器人「動作」和「感測」行為庫用於任務規劃，並使用 CENTAURO 機器人在模擬和真實環境中進行了移動操作任務和實驗，並驗證了這種方法在具有自主行為規劃的機器人任務中的有效性和應用。

##### **InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models**
2408.08264v1 by Guoxiang Grayson Tong, Carlos A. Sing Long, Daniele E. Schiavazzi

Estimation of cardiovascular model parameters from electronic health records
(EHR) poses a significant challenge primarily due to lack of identifiability.
Structural non-identifiability arises when a manifold in the space of
parameters is mapped to a common output, while practical non-identifiability
can result due to limited data, model misspecification, or noise corruption. To
address the resulting ill-posed inverse problem, optimization-based or Bayesian
inference approaches typically use regularization, thereby limiting the
possibility of discovering multiple solutions. In this study, we use inVAErt
networks, a neural network-based, data-driven framework for enhanced digital
twin analysis of stiff dynamical systems. We demonstrate the flexibility and
effectiveness of inVAErt networks in the context of physiological inversion of
a six-compartment lumped parameter hemodynamic model from synthetic data to
real data with missing components.

摘要：從電子健康紀錄 (EHR) 估計心血管模型參數主要由於缺乏可識別性而構成重大挑戰。
當參數空間中的流形對應到共同輸出時，會產生結構性不可識別性，而由於資料有限、模型錯誤規範或雜訊破壞，可能會導致實際不可識別性。為了解決由此產生的不適定反問題，基於最佳化的貝氏推論方法通常使用正則化，從而限制發現多重解的可能性。在本研究中，我們使用 inVAErt 網路，這是一種基於神經網路、資料驅動的架構，用於增強僵硬動態系統的數位雙胞胎分析。我們展示了 inVAErt 網路在生理反演中的靈活性與有效性，從合成資料到缺少組成的真實資料，反演六隔間集總參數血流動力模型。

##### **mhGPT: A Lightweight Generative Pre-Trained Transformer for Mental Health Text Analysis**
2408.08261v1 by Dae-young Kim, Rebecca Hwa, Muhammad Mahbubur Rahman

This paper introduces mhGPT, a lightweight generative pre-trained transformer
trained on mental health-related social media and PubMed articles. Fine-tuned
for specific mental health tasks, mhGPT was evaluated under limited hardware
constraints and compared with state-of-the-art models like MentaLLaMA and
Gemma. Despite having only 1.98 billion parameters and using just 5% of the
dataset, mhGPT outperformed larger models and matched the performance of models
trained on significantly more data. The key contributions include integrating
diverse mental health data, creating a custom tokenizer, and optimizing a
smaller architecture for low-resource settings. This research could advance
AI-driven mental health care, especially in areas with limited computing power.

摘要：本文介紹 mhGPT，一種輕量級的生成式預訓練轉換器，經過針對心理健康相關社群媒體和 PubMed 文章的訓練。針對特定心理健康任務進行微調後，mhGPT 在有限的硬體限制下進行評估，並與 MentaLLaMA 和 Gemma 等最先進的模型進行比較。儘管只有 19.8 億個參數，並且僅使用 5% 的資料集，mhGPT 的表現優於較大的模型，並且與在更多資料上訓練的模型的表現相匹配。主要貢獻包括整合多樣的心理健康資料、建立自訂的標記器，以及針對低資源設定最佳化較小的架構。這項研究可以推進人工智慧驅動的心理保健，特別是在運算能力有限的地區。

##### **Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding**
2408.08252v1 by Xiner Li, Yulai Zhao, Chenyu Wang, Gabriele Scalia, Gokcen Eraslan, Surag Nair, Tommaso Biancalani, Aviv Regev, Sergey Levine, Masatoshi Uehara

Diffusion models excel at capturing the natural design spaces of images,
molecules, DNA, RNA, and protein sequences. However, rather than merely
generating designs that are natural, we often aim to optimize downstream reward
functions while preserving the naturalness of these design spaces. Existing
methods for achieving this goal often require ``differentiable'' proxy models
(\textit{e.g.}, classifier guidance or DPS) or involve computationally
expensive fine-tuning of diffusion models (\textit{e.g.}, classifier-free
guidance, RL-based fine-tuning). In our work, we propose a new method to
address these challenges. Our algorithm is an iterative sampling method that
integrates soft value functions, which looks ahead to how intermediate noisy
states lead to high rewards in the future, into the standard inference
procedure of pre-trained diffusion models. Notably, our approach avoids
fine-tuning generative models and eliminates the need to construct
differentiable models. This enables us to (1) directly utilize
non-differentiable features/reward feedback, commonly used in many scientific
domains, and (2) apply our method to recent discrete diffusion models in a
principled way. Finally, we demonstrate the effectiveness of our algorithm
across several domains, including image generation, molecule generation, and
DNA/RNA sequence generation. The code is available at
\href{https://github.com/masa-ue/SVDD}{https://github.com/masa-ue/SVDD}.

摘要：擴散模型擅長捕捉影像、分子、DNA、RNA 和蛋白質序列的自然設計空間。然而，我們通常不只是產生自然的設計，而是希望在保留這些設計空間的自然性的同時，最佳化下游獎勵函數。現有的達成此目標的方法通常需要「可微分」的代理模型（例如分類器引導或 DPS）或涉及計算成本高的擴散模型微調（例如無分類器引導、基於 RL 的微調）。在我們的研究中，我們提出了一種新的方法來解決這些挑戰。我們的演算法是一種反覆取樣方法，它將軟值函數整合到標準預訓練擴散模型的推論程序中，該函數預測中間雜訊狀態將如何導致未來的高獎勵。值得注意的是，我們的方法避免了生成模型的微調，並消除了構建可微分模型的需要。這使我們能夠 (1) 直接利用在許多科學領域中常用的不可微分特徵/獎勵回饋，以及 (2) 以有原則的方式將我們的模型應用於最近的離散擴散模型。最後，我們在幾個領域展示了我們演算法的有效性，包括影像生成、分子生成以及 DNA/RNA 序列生成。程式碼可在以下網址取得：\href{https://github.com/masa-ue/SVDD}{https://github.com/masa-ue/SVDD}。

##### **A Conflicts-free, Speed-lossless KAN-based Reinforcement Learning Decision System for Interactive Driving in Roundabouts**
2408.08242v1 by Zhihao Lin, Zhen Tian, Qi Zhang, Ziyang Ye, Hanyang Zhuang, Jianglin Lan

Safety and efficiency are crucial for autonomous driving in roundabouts,
especially in the context of mixed traffic where autonomous vehicles (AVs) and
human-driven vehicles coexist. This paper introduces a learning-based algorithm
tailored to foster safe and efficient driving behaviors across varying levels
of traffic flows in roundabouts. The proposed algorithm employs a deep
Q-learning network to effectively learn safe and efficient driving strategies
in complex multi-vehicle roundabouts. Additionally, a KAN (Kolmogorov-Arnold
network) enhances the AVs' ability to learn their surroundings robustly and
precisely. An action inspector is integrated to replace dangerous actions to
avoid collisions when the AV interacts with the environment, and a route
planner is proposed to enhance the driving efficiency and safety of the AVs.
Moreover, a model predictive control is adopted to ensure stability and
precision of the driving actions. The results show that our proposed system
consistently achieves safe and efficient driving whilst maintaining a stable
training process, as evidenced by the smooth convergence of the reward function
and the low variance in the training curves across various traffic flows.
Compared to state-of-the-art benchmarks, the proposed algorithm achieves a
lower number of collisions and reduced travel time to destination.

摘要：在環島中，安全性和效率對於自動駕駛至關重要，特別是在自動駕駛汽車 (AV) 和人類駕駛汽車並存的混合交通環境中。本文介紹了一種基於學習的演算法，專門用於促進在環島中不同交通流量等級的安全且有效的駕駛行為。所提出的演算法採用深度 Q 學習網路，可在複雜的多車輛環島中有效學習安全且有效的駕駛策略。此外，KAN（柯爾莫哥洛夫-阿諾德網路）增強了自動駕駛汽車在環境中穩健且精確學習的能力。整合了動作檢查器，可在自動駕駛汽車與環境互動時取代危險動作，避免碰撞，並提出了路線規劃器，以增強自動駕駛汽車的駕駛效率和安全性。此外，採用了模型預測控制，以確保駕駛動作的穩定性和精確性。結果表明，我們提出的系統始終能實現安全且有效的駕駛，同時保持穩定的訓練過程，這從回報函數的平穩收斂和訓練曲線在各種交通流量中的低變異中可以得到證明。與最先進的基準相比，所提出的演算法可減少碰撞次數並縮短到達目的地的行程時間。

##### **Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction**
2408.08226v1 by Yuqicheng Zhu, Nico Potyka, Mojtaba Nayyeri, Bo Xiong, Yunjie He, Evgeny Kharlamov, Steffen Staab

Knowledge graph embedding (KGE) models are often used to predict missing
links for knowledge graphs (KGs). However, multiple KG embeddings can perform
almost equally well for link prediction yet suggest conflicting predictions for
certain queries, termed \textit{predictive multiplicity} in literature. This
behavior poses substantial risks for KGE-based applications in high-stake
domains but has been overlooked in KGE research. In this paper, we define
predictive multiplicity in link prediction. We introduce evaluation metrics and
measure predictive multiplicity for representative KGE methods on commonly used
benchmark datasets. Our empirical study reveals significant predictive
multiplicity in link prediction, with $8\%$ to $39\%$ testing queries
exhibiting conflicting predictions. To address this issue, we propose
leveraging voting methods from social choice theory, significantly mitigating
conflicts by $66\%$ to $78\%$ according to our experiments.

摘要：知識圖譜嵌入 (KGE) 模型通常用於預測知識圖譜 (KG) 的遺失連結。然而，多個 KG 嵌入在連結預測上可以有近乎相同的表現，卻對某些查詢提出互相矛盾的預測，這在文獻中稱為「預測多樣性」。此行為對高風險領域中以 KGE 為基礎的應用程式構成重大風險，但在 KGE 研究中卻被忽略。在本文中，我們定義了連結預測中的預測多樣性。我們引進評估指標，並針對常用基準資料集，針對具代表性的 KGE 方法測量預測多樣性。我們的實證研究揭露了連結預測中顯著的預測多樣性，其中 8% 至 39% 的測試查詢展現出互相矛盾的預測。為了解決此問題，我們提出利用社會選擇理論中的投票方法，根據我們的實驗，大幅降低了 66% 至 78% 的衝突。

##### **The Dawn of KAN in Image-to-Image (I2I) Translation: Integrating Kolmogorov-Arnold Networks with GANs for Unpaired I2I Translation**
2408.08216v1 by Arpan Mahara, Naphtali D. Rishe, Liangdong Deng

Image-to-Image translation in Generative Artificial Intelligence (Generative
AI) has been a central focus of research, with applications spanning
healthcare, remote sensing, physics, chemistry, photography, and more. Among
the numerous methodologies, Generative Adversarial Networks (GANs) with
contrastive learning have been particularly successful. This study aims to
demonstrate that the Kolmogorov-Arnold Network (KAN) can effectively replace
the Multi-layer Perceptron (MLP) method in generative AI, particularly in the
subdomain of image-to-image translation, to achieve better generative quality.
Our novel approach replaces the two-layer MLP with a two-layer KAN in the
existing Contrastive Unpaired Image-to-Image Translation (CUT) model,
developing the KAN-CUT model. This substitution favors the generation of more
informative features in low-dimensional vector representations, which
contrastive learning can utilize more effectively to produce high-quality
images in the target domain. Extensive experiments, detailed in the results
section, demonstrate the applicability of KAN in conjunction with contrastive
learning and GANs in Generative AI, particularly for image-to-image
translation. This work suggests that KAN could be a valuable component in the
broader generative AI domain.

摘要：生成式人工智能 (生成式 AI) 中的图像到图像转换一直是研究的重点，其应用涵盖医疗保健、遥感、物理、化学、摄影等领域。在众多方法中，具有对比学习的生成对抗网络 (GAN) 特别成功。本研究旨在证明 Kolmogorov-Arnold 网络 (KAN) 可以有效取代生成式 AI 中的多层感知器 (MLP) 方法，特别是在图像到图像转换的子领域中，以实现更好的生成质量。我们的新方法用两层 KAN 替换现有对比无配对图像到图像转换 (CUT) 模型中的两层 MLP，开发出 KAN-CUT 模型。这种替换有利于在低维向量表示中生成更多信息特征，对比学习可以更有效地利用这些特征，从而在目标域中生成高质量图像。结果部分中详细介绍的广泛实验表明了 KAN 与对比学习和 GAN 在生成式 AI 中结合使用的适用性，特别是对于图像到图像转换。这项工作表明，KAN 可能是更广泛的生成式 AI 领域中的一个有价值的组成部分。

##### **Moving Healthcare AI-Support Systems for Visually Detectable Diseases onto Constrained Devices**
2408.08215v1 by Tess Watt, Christos Chrysoulas, Peter J Barclay

Image classification usually requires connectivity and access to the cloud
which is often limited in many parts of the world, including hard to reach
rural areas. TinyML aims to solve this problem by hosting AI assistants on
constrained devices, eliminating connectivity issues by processing data within
the device itself, without internet or cloud access. This pilot study explores
the use of tinyML to provide healthcare support with low spec devices in low
connectivity environments, focusing on diagnosis of skin diseases and the
ethical use of AI assistants in a healthcare setting. To investigate this,
10,000 images of skin lesions were used to train a model for classifying
visually detectable diseases (VDDs). The model weights were then offloaded to a
Raspberry Pi with a webcam attached, to be used for the classification of skin
lesions without internet access. It was found that the developed prototype
achieved a test accuracy of 78% and a test loss of 1.08.

摘要：影像分類通常需要連線和存取雲端，而這在世界許多地區，包括難以抵達的鄉村地區，通常受到限制。TinyML 旨在透過在受限裝置上架設 AI 助理，在裝置內處理資料，無需網路或雲端存取，來解決這個問題。這項試驗研究探討使用 TinyML 在連線不良的環境中提供低規格裝置的醫療保健支援，重點在皮膚疾病診斷和醫療環境中 AI 助理的道德使用。為此，我們使用 10,000 張皮膚病灶影像訓練一個用於分類可視可偵測疾病 (VDD) 的模型。然後將模型權重卸載到配備網路攝影機的 Raspberry Pi，用於在沒有網路存取的情況下分類皮膚病灶。結果發現，已開發的原型達到 78% 的測試準確度和 1.08 的測試損失。

##### **Federated Fairness Analytics: Quantifying Fairness in Federated Learning**
2408.08214v1 by Oscar Dilley, Juan Marcelo Parra-Ullauri, Rasheed Hussain, Dimitra Simeonidou

Federated Learning (FL) is a privacy-enhancing technology for distributed ML.
By training models locally and aggregating updates - a federation learns
together, while bypassing centralised data collection. FL is increasingly
popular in healthcare, finance and personal computing. However, it inherits
fairness challenges from classical ML and introduces new ones, resulting from
differences in data quality, client participation, communication constraints,
aggregation methods and underlying hardware. Fairness remains an unresolved
issue in FL and the community has identified an absence of succinct definitions
and metrics to quantify fairness; to address this, we propose Federated
Fairness Analytics - a methodology for measuring fairness. Our definition of
fairness comprises four notions with novel, corresponding metrics. They are
symptomatically defined and leverage techniques originating from XAI,
cooperative game-theory and networking engineering. We tested a range of
experimental settings, varying the FL approach, ML task and data settings. The
results show that statistical heterogeneity and client participation affect
fairness and fairness conscious approaches such as Ditto and q-FedAvg
marginally improve fairness-performance trade-offs. Using our techniques, FL
practitioners can uncover previously unobtainable insights into their system's
fairness, at differing levels of granularity in order to address fairness
challenges in FL. We have open-sourced our work at:
https://github.com/oscardilley/federated-fairness.

摘要：<paragraph>聯邦學習 (FL) 是一種增強隱私的分布式機器學習技術。
透過在本地訓練模型並彙總更新，聯盟可以共同學習，同時繞過集中式資料收集。FL 在醫療保健、金融和個人運算中越來越受歡迎。然而，它繼承了傳統機器學習的公平性挑戰，並引入了新的挑戰，這些挑戰源於資料品質、客戶端參與、通訊限制、彙總方法和基礎硬體的差異。公平性仍然是 FL 中一個尚未解決的問題，而社群已發現缺乏簡潔的定義和衡量公平性的指標；為了解決這個問題，我們提出聯邦公平性分析，一種用於衡量公平性的方法。我們對公平性的定義包含四個概念，並有新穎的對應指標。它們被症狀性地定義，並利用源自 XAI、合作博弈論和網路工程的技術。我們測試了一系列實驗設定，改變了 FL 方法、機器學習任務和資料設定。結果表明，統計異質性和客戶端參與會影響公平性，而重視公平性的方法，例如 Ditto 和 q-FedAvg，則會略微改善公平性與效能的權衡。透過使用我們的技術，FL 從業人員可以發掘以前無法獲得的對其系統公平性的見解，在不同的細化層級中，以解決 FL 中的公平性挑戰。我們已在以下位置開放原始碼：
https://github.com/oscardilley/federated-fairness。</paragraph>

##### **Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**
2408.08212v2 by Abeer Aldayel, Areej Alokaili, Rehab Alahmadi

While various approaches have recently been studied for bias identification,
little is known about how implicit language that does not explicitly convey a
viewpoint affects bias amplification in large language models. To examine the
severity of bias toward a view, we evaluated the performance of two downstream
tasks where the implicit and explicit knowledge of social groups were used.
First, we present a stress test evaluation by using a biased model in edge
cases of excessive bias scenarios. Then, we evaluate how LLMs calibrate
linguistically in response to both implicit and explicit opinions when they are
aligned with conflicting viewpoints. Our findings reveal a discrepancy in LLM
performance in identifying implicit and explicit opinions, with a general
tendency of bias toward explicit opinions of opposing stances. Moreover, the
bias-aligned models generate more cautious responses using uncertainty phrases
compared to the unaligned (zero-shot) base models. The direct, incautious
responses of the unaligned models suggest a need for further refinement of
decisiveness by incorporating uncertainty markers to enhance their reliability,
especially on socially nuanced topics with high subjectivity.

摘要：儘管最近已研究各種偏見識別方法，
但對於不顯式傳達觀點的隱含語言如何影響大型語言模型中的偏見放大，我們所知甚少。為了檢視觀點偏見的嚴重性，我們評估了下游兩個任務的表現，其中使用了社會群體的隱含和顯式知識。
首先，我們透過在過度偏見情境中使用偏見模型，提出壓力測試評估。然後，我們評估 LLM 在與衝突觀點一致時，如何對隱含和顯式意見進行語言校準。我們的研究結果揭示了 LLM 在識別隱含和顯式意見方面的表現差異，通常傾向於對反對立場的顯式意見產生偏見。此外，與未對齊（零次學習）基礎模型相比，偏見對齊模型使用不確定性詞彙產生更謹慎的回應。未對齊模型的直接、魯莽回應表明需要進一步完善決斷力，方法是納入不確定性標記以提高其可靠性，特別是在具有高度主觀性的社會細微差別主題上。

##### **LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**
2408.08208v1 by Bohao Wang, Feng Liu, Jiawei Chen, Yudi Wu, Xingyu Lou, Jun Wang, Yan Feng, Chun Chen, Can Wang

Sequential recommendation systems fundamentally rely on users' historical
interaction sequences, which are often contaminated by noisy interactions.
Identifying these noisy interactions accurately without additional information
is particularly difficult due to the lack of explicit supervisory signals to
denote noise. Large Language Models (LLMs), equipped with extensive open
knowledge and semantic reasoning abilities, present a promising avenue to
bridge this information gap. However, employing LLMs for denoising in
sequential recommendation introduces notable challenges: 1) Direct application
of pretrained LLMs may not be competent for the denoising task, frequently
generating nonsensical responses; 2) Even after fine-tuning, the reliability of
LLM outputs remains questionable, especially given the complexity of the task
and th inherent hallucinatory issue of LLMs.
  To tackle these challenges, we propose LLM4DSR, a tailored approach for
denoising sequential recommendation using LLMs. We constructed a
self-supervised fine-tuning task to activate LLMs' capabilities to identify
noisy items and suggest replacements. Furthermore, we developed an uncertainty
estimation module that ensures only high-confidence responses are utilized for
sequence corrections. Remarkably, LLM4DSR is model-agnostic, allowing the
corrected sequences to be flexibly applied across various recommendation
models. Extensive experiments validate the superiority of LLM4DSR over existing
methods across three datasets and three recommendation backbones.

摘要：序列推薦系統基本上依賴於使用者的歷史互動序列，這些序列通常會受到雜訊互動的污染。由於缺乏明確的監督訊號來表示雜訊，因此在沒有額外資訊的情況下準確識別這些雜訊互動特別困難。具備廣泛開放知識和語義推理能力的大型語言模型 (LLM) 提供了一個有前途的途徑來彌補這個資訊差距。然而，在序列推薦中使用 LLM 來進行去雜訊會產生顯著的挑戰：1) 直接應用預訓練的 LLM 可能不勝任去雜訊任務，經常會產生無意義的回應；2) 即使在微調之後，LLM 輸出的可靠性仍然有待商榷，特別是考慮到任務的複雜性和 LLM 固有的幻覺問題。
為了應對這些挑戰，我們提出了 LLM4DSR，這是一種使用 LLM 對序列推薦進行去雜訊的客製化方法。我們建構了一個自我監督的微調任務，以啟動 LLM 識別雜訊項目並建議替換項目的能力。此外，我們開發了一個不確定性估計模組，以確保只有高信心的回應被用於序列校正。值得注意的是，LLM4DSR 與模型無關，允許在各種推薦模型中靈活地應用校正後的序列。廣泛的實驗驗證了 LLM4DSR 在三個資料集和三個推薦主幹上優於現有方法。

##### **API-guided Dataset Synthesis to Finetune Large Code Models**
2408.08343v1 by Zongjie Li, Daoyuan Wu, Shuai Wang, Zhendong Su

Large code models (LCMs), pre-trained on vast code corpora, have demonstrated
remarkable performance across a wide array of code-related tasks. Supervised
fine-tuning (SFT) plays a vital role in aligning these models with specific
requirements and enhancing their performance in particular domains. However,
synthesizing high-quality SFT datasets poses a significant challenge due to the
uneven quality of datasets and the scarcity of domain-specific datasets.
  Inspired by APIs as high-level abstractions of code that encapsulate rich
semantic information in a concise structure, we propose DataScope, an
API-guided dataset synthesis framework designed to enhance the SFT process for
LCMs in both general and domain-specific scenarios. DataScope comprises two
main components: Dsel and Dgen. On one hand, Dsel employs API coverage as a
core metric, enabling efficient dataset synthesis in general scenarios by
selecting subsets of existing (uneven-quality) datasets with higher API
coverage. On the other hand, Dgen recasts domain dataset synthesis as a process
of using API-specified high-level functionality and deliberately-constituted
code skeletons to synthesize concrete code.
  Extensive experiments demonstrate DataScope's effectiveness, with models
fine-tuned on its synthesized datasets outperforming those tuned on unoptimized
datasets five times larger. Furthermore, a series of analyses on model
internals, relevant hyperparameters, and case studies provide additional
evidence for the efficacy of our proposed methods. These findings underscore
the significance of dataset quality in SFT and advance the field of LCMs by
providing an efficient, cost-effective framework for constructing high-quality
datasets. This contribution enhances performance across both general and
domain-specific scenarios, paving the way for more powerful and tailored LCMs.

摘要：<paragraph>在龐大的程式碼資料庫上預先訓練的大型程式碼模型 (LCM) 已在各種與程式碼相關的任務中展現出卓越的效能。受監督微調 (SFT) 在將這些模型與特定需求對齊並提升它們在特定領域的效能方面發揮著至關重要的作用。然而，由於資料集品質不一且缺乏特定領域的資料集，因此合成高品質的 SFT 資料集是一個重大的挑戰。
  受 API 作為程式碼的高階抽象，能以簡潔的結構封裝豐富語義資訊的啟發，我們提出 DataScope，一個 API 引導的資料集合成架構，旨在增強 LCM 在一般和特定領域場景中的 SFT 程序。DataScope 包含兩個主要組成部分：Dsel 和 Dgen。一方面，Dsel 以 API 涵蓋範圍作為核心指標，透過選取 API 涵蓋範圍較高的現有（品質不一）資料集的子集，在一般場景中實現有效率的資料集合成。另一方面，Dgen 將領域資料集合成重塑為一個使用 API 指定的高階功能和經過深思熟慮的程式碼骨架來合成具體程式碼的程序。
  廣泛的實驗證明了 DataScope 的有效性，使用其合成的資料集進行微調的模型比在未經最佳化、規模大五倍的資料集上進行微調的模型表現得更好。此外，對模型內部結構、相關超參數和個案研究的一系列分析為我們提出的方法的效能提供了額外的證據。這些發現強調了資料集品質在 SFT 中的重要性，並透過提供一個建構高品質資料集的高效率、高成本效益的架構，推動 LCM 領域的進步。這項貢獻提升了一般和特定領域場景的效能，為更強大且客製化的 LCM 鋪路。</paragraph>

##### **Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**
2408.08188v1 by Shaojun Xu, Xusheng Luo, Yutong Huang, Letian Leng, Ruixuan Liu, Changliu Liu

Long-horizon planning is hindered by challenges such as uncertainty
accumulation, computational complexity, delayed rewards and incomplete
information. This work proposes an approach to exploit the task hierarchy from
human instructions to facilitate multi-robot planning. Using Large Language
Models (LLMs), we propose a two-step approach to translate multi-sentence
instructions into a structured language, Hierarchical Linear Temporal Logic
(LTL), which serves as a formal representation for planning. Initially, LLMs
transform the instructions into a hierarchical representation defined as
Hierarchical Task Tree, capturing the logical and temporal relations among
tasks. Following this, a domain-specific fine-tuning of LLM translates
sub-tasks of each task into flat LTL formulas, aggregating them to form
hierarchical LTL specifications. These specifications are then leveraged for
planning using off-the-shelf planners. Our framework not only bridges the gap
between instructions and algorithmic planning but also showcases the potential
of LLMs in harnessing hierarchical reasoning to automate multi-robot task
planning. Through evaluations in both simulation and real-world experiments
involving human participants, we demonstrate that our method can handle more
complex instructions compared to existing methods. The results indicate that
our approach achieves higher success rates and lower costs in multi-robot task
allocation and plan generation. Demos videos are available at
https://youtu.be/7WOrDKxIMIs .

摘要：長期規劃受到不確定性累積、計算複雜性、獎勵延遲和資訊不完整等挑戰所阻礙。本研究提出一個方法來利用人類指令中的任務階層，以促進多機器人規劃。我們使用大型語言模型 (LLM)，提出一個兩步驟的方法，將多句指令轉換成結構化語言，層級線性時序邏輯 (LTL)，作為規劃的正式表示。最初，LLM 將指令轉換成階層式表示，定義為階層任務樹，捕捉任務之間的邏輯和時間關係。在此之後，LLM 的特定領域微調將每個任務的子任務轉換成扁平 LTL 公式，彙總它們以形成階層式 LTL 規範。然後利用這些規範來使用現成的規劃器進行規劃。我們的框架不僅彌合了指令和演算法規劃之間的差距，還展示了 LLM 在利用階層式推理來自動化多機器人任務規劃中的潛力。透過在涉及人類參與者的模擬和真實世界實驗中進行評估，我們證明了我們的方法可以處理比現有方法更複雜的指令。結果表明，我們的方法在多機器人任務分配和計畫產生中實現了更高的成功率和更低的成本。示範影片可在 https://youtu.be/7WOrDKxIMIs 取得。

##### **Your Turn: Real-World Turning Angle Estimation for Parkinson's Disease Severity Assessment**
2408.08182v1 by Qiushuo Cheng, Catherine Morgan, Arindam Sikdar, Alessandro Masullo, Alan Whone, Majid Mirmehdi

People with Parkinson's Disease (PD) often experience progressively worsening
gait, including changes in how they turn around, as the disease progresses.
Existing clinical rating tools are not capable of capturing hour-by-hour
variations of PD symptoms, as they are confined to brief assessments within
clinic settings. Measuring real-world gait turning angles continuously and
passively is a component step towards using gait characteristics as sensitive
indicators of disease progression in PD. This paper presents a deep
learning-based approach to automatically quantify turning angles by extracting
3D skeletons from videos and calculating the rotation of hip and knee joints.
We utilise state-of-the-art human pose estimation models, Fastpose and Strided
Transformer, on a total of 1386 turning video clips from 24 subjects (12 people
with PD and 12 healthy control volunteers), trimmed from a PD dataset of
unscripted free-living videos in a home-like setting (Turn-REMAP). We also
curate a turning video dataset, Turn-H3.6M, from the public Human3.6M human
pose benchmark with 3D ground truth, to further validate our method. Previous
gait research has primarily taken place in clinics or laboratories evaluating
scripted gait outcomes, but this work focuses on real-world settings where
complexities exist, such as baggy clothing and poor lighting. Due to
difficulties in obtaining accurate ground truth data in a free-living setting,
we quantise the angle into the nearest bin $45^\circ$ based on the manual
labelling of expert clinicians. Our method achieves a turning calculation
accuracy of 41.6%, a Mean Absolute Error (MAE) of 34.7{\deg}, and a weighted
precision WPrec of 68.3% for Turn-REMAP. This is the first work to explore the
use of single monocular camera data to quantify turns by PD patients in a home
setting.

摘要：帕金森氏症 (PD) 患者经常会随着疾病的进展而出现步态逐渐恶化的现象，包括转身方式的变化。现有的临床评定工具无法捕捉到 PD 症状逐小时的变化，因为它们仅限于在临床环境中进行短暂的评估。连续被动地测量现实世界中的步态转弯角度是将步态特征用作 PD 疾病进展的敏感指标的组成部分。本文提出了一种基于深度学习的方法，通过从视频中提取 3D 骨架并计算髋关节和膝关节的旋转，自动量化转弯角度。我们对来自 24 个受试者（12 名 PD 患者和 12 名健康对照志愿者）的总共 1386 个转弯视频剪辑使用了最先进的人体姿势估计模型 Fastpose 和 Strided Transformer，这些剪辑是从家庭环境中无脚本自由生活视频的 PD 数据集（Turn-REMAP）中截取的。我们还从具有 3D 真实的公共 Human3.6M 人体姿势基准中整理了一个转弯视频数据集 Turn-H3.6M，以进一步验证我们的方法。以往的步态研究主要在评估脚本化步态结果的诊所或实验室中进行，但这项工作重点关注存在复杂性的现实世界环境，例如宽松的衣服和光线不足。由于在自由生活环境中难以获得准确的真实数据，我们根据专家临床医生的手动标记，将角度量化为最接近的箱 $45^\circ$。我们的方法对 Turn-REMAP 的转弯计算准确度达到 41.6%，平均绝对误差 (MAE) 为 34.7{\deg}，加权精度 WPrec 为 68.3%。这是首次探索使用单目单眼相机数据来量化 PD 患者在家中转弯情况的工作。

##### **Towards flexible perception with visual memory**
2408.08172v1 by Robert Geirhos, Priyank Jaini, Austin Stone, Sourabh Medapati, Xi Yi, George Toderici, Abhijit Ogale, Jonathon Shlens

Training a neural network is a monolithic endeavor, akin to carving knowledge
into stone: once the process is completed, editing the knowledge in a network
is nearly impossible, since all information is distributed across the network's
weights. We here explore a simple, compelling alternative by marrying the
representational power of deep neural networks with the flexibility of a
database. Decomposing the task of image classification into image similarity
(from a pre-trained embedding) and search (via fast nearest neighbor retrieval
from a knowledge database), we build a simple and flexible visual memory that
has the following key capabilities: (1.) The ability to flexibly add data
across scales: from individual samples all the way to entire classes and
billion-scale data; (2.) The ability to remove data through unlearning and
memory pruning; (3.) An interpretable decision-mechanism on which we can
intervene to control its behavior. Taken together, these capabilities
comprehensively demonstrate the benefits of an explicit visual memory. We hope
that it might contribute to a conversation on how knowledge should be
represented in deep vision models -- beyond carving it in ``stone'' weights.

摘要：训练神经网络是一项整体性的工作，就像将知识刻在石头上：一旦完成该过程，就几乎不可能编辑网络中的知识，因为所有信息都分布在网络的权重中。我们在这里通过将深度神经网络的表征能力与数据库的灵活性相结合，探索一种简单而有吸引力的替代方案。将图像分类任务分解为图像相似性（来自预训练嵌入）和搜索（通过从知识数据库中快速检索最近邻），我们构建了一个简单而灵活的视觉记忆，它具有以下关键功能：(1.) 能够灵活地跨尺度添加数据：从单个样本到整个类别和数十亿规模的数据；(2.) 能够通过取消学习和内存剪枝来删除数据；(3.) 一种可解释的决策机制，我们可以干预它以控制其行为。综合起来，这些功能全面展示了显式视觉记忆的好处。我们希望它可以促进关于知识如何在深度视觉模型中表示的对话——不仅仅是将其刻在“石头”权重中。

##### **General-purpose Clothes Manipulation with Semantic Keypoints**
2408.08160v1 by Yuhong Deng, David Hsu

We have seen much recent progress in task-specific clothes manipulation, but
generalizable clothes manipulation is still a challenge. Clothes manipulation
requires sequential actions, making it challenging to generalize to unseen
tasks. Besides, a general clothes state representation method is crucial. In
this paper, we adopt language instructions to specify and decompose clothes
manipulation tasks, and propose a large language model based hierarchical
learning method to enhance generalization. For state representation, we use
semantic keypoints to capture the geometry of clothes and outline their
manipulation methods. Simulation experiments show that the proposed method
outperforms the baseline method in terms of success rate and generalization for
clothes manipulation tasks.

摘要：我們已經在特定任務的服裝操作中看到許多近期的進步，但可概化的服裝操作仍然是一項挑戰。服裝操作需要循序漸進的動作，這使得概化到未見過的任務變得具有挑戰性。此外，一個通用的服裝狀態表示方法至關重要。在本文中，我們採用語言指令來指定和分解服裝操作任務，並提出一個基於大型語言模型的分層學習方法來增強概化。對於狀態表示，我們使用語義關鍵點來捕捉服裝的幾何形狀，並概述其操作方法。模擬實驗表明，所提出的方法在成功率和服裝操作任務的概化方面優於基線方法。

##### **DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search**
2408.08152v1 by Huajian Xin, Z. Z. Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, Wenjun Gao, Qihao Zhu, Dejian Yang, Zhibin Gou, Z. F. Wu, Fuli Luo, Chong Ruan

We introduce DeepSeek-Prover-V1.5, an open-source language model designed for
theorem proving in Lean 4, which enhances DeepSeek-Prover-V1 by optimizing both
training and inference processes. Pre-trained on DeepSeekMath-Base with
specialization in formal mathematical languages, the model undergoes supervised
fine-tuning using an enhanced formal theorem proving dataset derived from
DeepSeek-Prover-V1. Further refinement is achieved through reinforcement
learning from proof assistant feedback (RLPAF). Beyond the single-pass
whole-proof generation approach of DeepSeek-Prover-V1, we propose RMaxTS, a
variant of Monte-Carlo tree search that employs an intrinsic-reward-driven
exploration strategy to generate diverse proof paths. DeepSeek-Prover-V1.5
demonstrates significant improvements over DeepSeek-Prover-V1, achieving new
state-of-the-art results on the test set of the high school level miniF2F
benchmark ($63.5\%$) and the undergraduate level ProofNet benchmark ($25.3\%$).

摘要：我們推出 DeepSeek-Prover-V1.5，這是一個開放原始碼語言模型，專為 Lean 4 中的定理證明而設計，透過最佳化訓練和推論流程來增強 DeepSeek-Prover-V1。預先訓練於 DeepSeekMath-Base 中，專精於形式化數學語言，該模型使用從 DeepSeek-Prover-V1 衍生的增強式形式化定理證明資料集進行監督式微調。透過證明輔助回饋（RLPAF）中的強化學習進一步精進。除了 DeepSeek-Prover-V1 的單次全證明產生方法外，我們提出 RMaxTS，一種蒙地卡羅樹搜尋的變體，採用內在回饋驅動的探索策略來產生多樣化的證明路徑。DeepSeek-Prover-V1.5 證明了相較於 DeepSeek-Prover-V1 有顯著的進步，在高中程度的 miniF2F 基準測試組中取得新的最先進成果（63.5%），以及大學程度的 ProofNet 基準測試組中（25.3%）。

