{"2406.20060": {"publish_time": "2024-06-28", "title": "Applying RLAIF for Code Generation with API-usage in Lightweight LLMs", "paper_summary": "Reinforcement Learning from AI Feedback (RLAIF) has demonstrated significant\npotential across various domains, including mitigating harm in LLM outputs,\nenhancing text summarization, and mathematical reasoning. This paper introduces\nan RLAIF framework for improving the code generation abilities of lightweight\n(<1B parameters) LLMs. We specifically focus on code generation tasks that\nrequire writing appropriate API calls, which is challenging due to the\nwell-known issue of hallucination in LLMs. Our framework extracts AI feedback\nfrom a larger LLM (e.g., GPT-3.5) through a specialized prompting strategy and\nuses this data to train a reward model towards better alignment from smaller\nLLMs. We run our experiments on the Gorilla dataset and meticulously assess the\nquality of the model-generated code across various metrics, including AST,\nROUGE, and Code-BLEU, and develop a pipeline to compute its executability rate\naccurately. Our approach significantly enhances the fine-tuned LLM baseline's\nperformance, achieving a 4.5% improvement in executability rate. Notably, a\nsmaller LLM model (780M parameters) trained with RLAIF surpasses a much larger\nfine-tuned baseline with 7B parameters, achieving a 1.0% higher code\nexecutability rate.", "paper_summary_zh": "\u5229\u7528 AI \u56de\u994b\u9032\u884c\u5f37\u5316\u5b78\u7fd2 (RLAIF) \u5df2\u5728\u5404\u7a2e\u9818\u57df\u5c55\u793a\u51fa\u986f\u8457\u7684\u6f5b\u529b\uff0c\u5305\u62ec\u6e1b\u8f15 LLM \u8f38\u51fa\u4e2d\u7684\u5371\u5bb3\u3001\u589e\u5f37\u6587\u5b57\u6458\u8981\u548c\u6578\u5b78\u63a8\u7406\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u500b RLAIF \u6846\u67b6\uff0c\u7528\u65bc\u63d0\u5347\u8f15\u91cf\u7d1a (<1B \u53c3\u6578) LLM \u7684\u7a0b\u5f0f\u78bc\u7522\u751f\u80fd\u529b\u3002\u6211\u5011\u7279\u5225\u95dc\u6ce8\u9700\u8981\u64b0\u5beb\u9069\u7576 API \u547c\u53eb\u7684\u7a0b\u5f0f\u78bc\u7522\u751f\u4efb\u52d9\uff0c\u7531\u65bc LLM \u4e2d\u773e\u6240\u5468\u77e5\u7684\u5e7b\u89ba\u554f\u984c\uff0c\u9019\u5177\u6709\u6311\u6230\u6027\u3002\u6211\u5011\u7684\u6846\u67b6\u900f\u904e\u5c08\u9580\u7684\u63d0\u793a\u7b56\u7565\u5f9e\u4e00\u500b\u8f03\u5927\u7684 LLM (\u4f8b\u5982 GPT-3.5) \u63d0\u53d6 AI \u56de\u994b\uff0c\u4e26\u4f7f\u7528\u9019\u4e9b\u8cc7\u6599\u8a13\u7df4\u4e00\u500b\u734e\u52f5\u6a21\u578b\uff0c\u4ee5\u671f\u5f9e\u8f03\u5c0f\u7684 LLM \u4e2d\u7372\u5f97\u66f4\u597d\u7684\u5c0d\u9f4a\u3002\u6211\u5011\u5728 Gorilla \u8cc7\u6599\u96c6\u4e0a\u57f7\u884c\u6211\u5011\u7684\u5be6\u9a57\uff0c\u4e26\u4ed4\u7d30\u8a55\u4f30\u6a21\u578b\u7522\u751f\u7684\u7a0b\u5f0f\u78bc\u5728\u5404\u7a2e\u6307\u6a19\uff08\u5305\u62ec AST\u3001ROUGE \u548c Code-BLEU\uff09\u4e0a\u7684\u54c1\u8cea\uff0c\u4e26\u958b\u767c\u4e00\u500b\u7ba1\u9053\u4ee5\u6e96\u78ba\u5730\u8a08\u7b97\u5176\u53ef\u57f7\u884c\u7387\u3002\u6211\u5011\u7684\u505a\u6cd5\u986f\u8457\u63d0\u5347\u4e86\u5fae\u8abf\u5f8c\u7684 LLM \u57fa\u6e96\u7684\u6548\u80fd\uff0c\u5728\u53ef\u57f7\u884c\u7387\u4e0a\u7372\u5f97\u4e86 4.5% \u7684\u63d0\u5347\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u4f7f\u7528 RLAIF \u8a13\u7df4\u7684\u8f03\u5c0f LLM \u6a21\u578b (780M \u53c3\u6578) \u8d85\u8d8a\u4e86\u5177\u6709 7B \u53c3\u6578\u7684\u66f4\u5927\u5fae\u8abf\u57fa\u6e96\uff0c\u9054\u5230\u4e86\u9ad8\u51fa 1.0% \u7684\u7a0b\u5f0f\u78bc\u53ef\u57f7\u884c\u7387\u3002", "author": "Sujan Dutta et.al.", "authors": "Sujan Dutta, Sayantan Mahinder, Raviteja Anantha, Bortik Bandyopadhyay", "id": "2406.20060v1", "paper_url": "http://arxiv.org/abs/2406.20060v1", "repo": "null"}}