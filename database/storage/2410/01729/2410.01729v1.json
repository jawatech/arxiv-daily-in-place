{"2410.01729": {"publish_time": "2024-10-02", "title": "Evaluating Robustness of Reward Models for Mathematical Reasoning", "paper_summary": "Reward models are key in reinforcement learning from human feedback (RLHF)\nsystems, aligning the model behavior with human preferences. Particularly in\nthe math domain, there have been plenty of studies using reward models to align\npolicies for improving reasoning capabilities. Recently, as the importance of\nreward models has been emphasized, RewardBench is proposed to understand their\nbehavior. However, we figure out that the math subset of RewardBench has\ndifferent representations between chosen and rejected completions, and relies\non a single comparison, which may lead to unreliable results as it only see an\nisolated case. Therefore, it fails to accurately present the robustness of\nreward models, leading to a misunderstanding of its performance and potentially\nresulting in reward hacking. In this work, we introduce a new design for\nreliable evaluation of reward models, and to validate this, we construct\nRewardMATH, a benchmark that effectively represents the robustness of reward\nmodels in mathematical reasoning tasks. We demonstrate that the scores on\nRewardMATH strongly correlate with the results of optimized policy and\neffectively estimate reward overoptimization, whereas the existing benchmark\nshows almost no correlation. The results underscore the potential of our design\nto enhance the reliability of evaluation, and represent the robustness of\nreward model. We make our code and data publicly available.", "paper_summary_zh": "\u734e\u52f5\u6a21\u578b\u5728\u4eba\u985e\u56de\u994b\uff08RLHF\uff09\u7cfb\u7d71\u7684\u5f37\u5316\u5b78\u7fd2\u4e2d\u662f\u95dc\u9375\uff0c\u4f7f\u6a21\u578b\u884c\u70ba\u8207\u4eba\u985e\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u3002\u7279\u5225\u662f\u5728\u6578\u5b78\u9818\u57df\uff0c\u5df2\u7d93\u6709\u8a31\u591a\u7814\u7a76\u4f7f\u7528\u734e\u52f5\u6a21\u578b\u4f86\u8abf\u6574\u653f\u7b56\u4ee5\u63d0\u9ad8\u63a8\u7406\u80fd\u529b\u3002\u6700\u8fd1\uff0c\u96a8\u8457\u734e\u52f5\u6a21\u578b\u7684\u91cd\u8981\u6027\u88ab\u5f37\u8abf\uff0cRewardBench \u88ab\u63d0\u51fa\u7528\u65bc\u4e86\u89e3\u5176\u884c\u70ba\u3002\u7136\u800c\uff0c\u6211\u5011\u767c\u73fe RewardBench \u7684\u6578\u5b78\u5b50\u96c6\u5728\u9078\u64c7\u548c\u62d2\u7d55\u7684\u5b8c\u6210\u4e4b\u9593\u6709\u4e0d\u540c\u7684\u8868\u793a\uff0c\u4e26\u4e14\u4f9d\u8cf4\u65bc\u55ae\u4e00\u6bd4\u8f03\uff0c\u9019\u53ef\u80fd\u6703\u5c0e\u81f4\u4e0d\u53ef\u9760\u7684\u7d50\u679c\uff0c\u56e0\u70ba\u5b83\u53ea\u770b\u5230\u4e00\u500b\u5b64\u7acb\u7684\u6848\u4f8b\u3002\u56e0\u6b64\uff0c\u5b83\u7121\u6cd5\u6e96\u78ba\u5730\u5448\u73fe\u734e\u52f5\u6a21\u578b\u7684\u7a69\u5065\u6027\uff0c\u5c0e\u81f4\u5c0d\u5176\u6027\u80fd\u7522\u751f\u8aa4\u89e3\uff0c\u4e26\u53ef\u80fd\u5c0e\u81f4\u734e\u52f5\u7834\u89e3\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u7684\u8a2d\u8a08\uff0c\u7528\u65bc\u5c0d\u734e\u52f5\u6a21\u578b\u9032\u884c\u53ef\u9760\u7684\u8a55\u4f30\uff0c\u4e26\u70ba\u4e86\u9a57\u8b49\u9019\u4e00\u9ede\uff0c\u6211\u5011\u69cb\u5efa\u4e86 RewardMATH\uff0c\u9019\u662f\u4e00\u500b\u6709\u6548\u8868\u793a\u6578\u5b78\u63a8\u7406\u4efb\u52d9\u4e2d\u734e\u52f5\u6a21\u578b\u7a69\u5065\u6027\u7684\u57fa\u6e96\u3002\u6211\u5011\u8b49\u660e\u4e86 RewardMATH \u4e0a\u7684\u5206\u6578\u8207\u512a\u5316\u7b56\u7565\u7684\u7d50\u679c\u5bc6\u5207\u76f8\u95dc\uff0c\u4e26\u6709\u6548\u5730\u4f30\u8a08\u4e86\u734e\u52f5\u904e\u5ea6\u512a\u5316\uff0c\u800c\u73fe\u6709\u7684\u57fa\u6e96\u5e7e\u4e4e\u6c92\u6709\u76f8\u95dc\u6027\u3002\u7d50\u679c\u5f37\u8abf\u4e86\u6211\u5011\u7684\u8a2d\u8a08\u5728\u63d0\u9ad8\u8a55\u4f30\u53ef\u9760\u6027\u65b9\u9762\u7684\u6f5b\u529b\uff0c\u4e26\u4ee3\u8868\u4e86\u734e\u52f5\u6a21\u578b\u7684\u7a69\u5065\u6027\u3002\u6211\u5011\u5c07\u6211\u5011\u7684\u4ee3\u78bc\u548c\u6578\u64da\u516c\u958b\u3002", "author": "Sunghwan Kim et.al.", "authors": "Sunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Jungsoo Won, Dongha Lee, Jinyoung Yeo", "id": "2410.01729v1", "paper_url": "http://arxiv.org/abs/2410.01729v1", "repo": "null"}}