{"2502.15563": {"publish_time": "2025-02-21", "title": "Bridging vision language model (VLM) evaluation gaps with a framework for scalable and cost-effective benchmark generation", "paper_summary": "Reliable evaluation of AI models is critical for scientific progress and\npractical application. While existing VLM benchmarks provide general insights\ninto model capabilities, their heterogeneous designs and limited focus on a few\nimaging domains pose significant challenges for both cross-domain performance\ncomparison and targeted domain-specific evaluation. To address this, we propose\nthree key contributions: (1) a framework for the resource-efficient creation of\ndomain-specific VLM benchmarks enabled by task augmentation for creating\nmultiple diverse tasks from a single existing task, (2) the release of new VLM\nbenchmarks for seven domains, created according to the same homogeneous\nprotocol and including 162,946 thoroughly human-validated answers, and (3) an\nextensive benchmarking of 22 state-of-the-art VLMs on a total of 37,171 tasks,\nrevealing performance variances across domains and tasks, thereby supporting\nthe need for tailored VLM benchmarks. Adoption of our methodology will pave the\nway for the resource-efficient domain-specific selection of models and guide\nfuture research efforts toward addressing core open questions.", "paper_summary_zh": "\u53ef\u9760\u7684 AI \u6a21\u578b\u8a55\u4f30\u5c0d\u65bc\u79d1\u5b78\u9032\u5c55\u548c\u5be6\u969b\u61c9\u7528\u81f3\u95dc\u91cd\u8981\u3002\u96d6\u7136\u73fe\u6709\u7684 VLM \u57fa\u6e96\u63d0\u4f9b\u4e86\u5c0d\u6a21\u578b\u529f\u80fd\u7684\u4e00\u822c\u898b\u89e3\uff0c\u4f46\u5b83\u5011\u7684\u7570\u8cea\u8a2d\u8a08\u548c\u5c0d\u5c11\u6578\u5f71\u50cf\u9818\u57df\u7684\u6709\u9650\u95dc\u6ce8\uff0c\u5c0d\u8de8\u9818\u57df\u6548\u80fd\u6bd4\u8f03\u548c\u76ee\u6a19\u9818\u57df\u7279\u5b9a\u8a55\u4f30\u69cb\u6210\u4e86\u91cd\u5927\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e09\u500b\u95dc\u9375\u8ca2\u737b\uff1a(1) \u4e00\u500b\u8cc7\u6e90\u6709\u6548\u7387\u7684\u9818\u57df\u7279\u5b9a VLM \u57fa\u6e96\u5efa\u7acb\u67b6\u69cb\uff0c\u900f\u904e\u4efb\u52d9\u64f4\u5145\uff0c\u5f9e\u55ae\u4e00\u73fe\u6709\u4efb\u52d9\u5efa\u7acb\u591a\u500b\u4e0d\u540c\u7684\u4efb\u52d9\uff0c(2) \u6839\u64da\u76f8\u540c\u7684\u540c\u8cea\u5354\u5b9a\uff0c\u767c\u5e03\u4e03\u500b\u9818\u57df\u7684\u65b0 VLM \u57fa\u6e96\uff0c\u5305\u62ec 162,946 \u500b\u7d93\u904e\u5fb9\u5e95\u4eba\u70ba\u9a57\u8b49\u7684\u7b54\u6848\uff0c\u4ee5\u53ca (3) \u5c0d\u7e3d\u5171 37,171 \u500b\u4efb\u52d9\u7684 22 \u500b\u6700\u5148\u9032\u7684 VLM \u9032\u884c\u5ee3\u6cdb\u7684\u57fa\u6e96\u6e2c\u8a66\uff0c\u63ed\u793a\u8de8\u9818\u57df\u548c\u4efb\u52d9\u7684\u6548\u80fd\u5dee\u7570\uff0c\u5f9e\u800c\u652f\u6301\u5c0d\u91cf\u8eab\u6253\u9020\u7684 VLM \u57fa\u6e96\u7684\u9700\u6c42\u3002\u63a1\u7528\u6211\u5011\u7684\u6280\u8853\u5c07\u70ba\u8cc7\u6e90\u6709\u6548\u7387\u7684\u9818\u57df\u7279\u5b9a\u6a21\u578b\u9078\u64c7\u92ea\u8def\uff0c\u4e26\u5f15\u5c0e\u672a\u4f86\u7684\u7814\u7a76\u5de5\u4f5c\uff0c\u4ee5\u89e3\u6c7a\u6838\u5fc3\u958b\u653e\u554f\u984c\u3002", "author": "Tim R\u00e4dsch et.al.", "authors": "Tim R\u00e4dsch, Leon Mayer, Simon Pavicic, A. Emre Kavur, Marcel Knopp, Bar\u0131\u015f \u00d6zt\u00fcrk, Klaus Maier-Hein, Paul F. Jaeger, Fabian Isensee, Annika Reinke, Lena Maier-Hein", "id": "2502.15563v1", "paper_url": "http://arxiv.org/abs/2502.15563v1", "repo": "null"}}