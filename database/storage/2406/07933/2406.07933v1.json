{"2406.07933": {"publish_time": "2024-06-12", "title": "Large Language Model Unlearning via Embedding-Corrupted Prompts", "paper_summary": "Large language models (LLMs) have advanced to encompass extensive knowledge\nacross diverse domains. Yet controlling what a large language model should not\nknow is important for ensuring alignment and thus safe use. However, accurately\nand efficiently unlearning knowledge from an LLM remains challenging due to the\npotential collateral damage caused by the fuzzy boundary between retention and\nforgetting, and the large computational requirements for optimization across\nstate-of-the-art models with hundreds of billions of parameters. In this work,\nwe present Embedding-COrrupted (ECO) Prompts, a lightweight unlearning\nframework for large language models to address both the challenges of knowledge\nentanglement and unlearning efficiency. Instead of relying on the LLM itself to\nunlearn, we enforce an unlearned state during inference by employing a prompt\nclassifier to identify and safeguard prompts to forget. We learn corruptions\nadded to prompt embeddings via zeroth order optimization toward the unlearning\nobjective offline and corrupt prompts flagged by the classifier during\ninference. We find that these embedding-corrupted prompts not only lead to\ndesirable outputs that satisfy the unlearning objective but also closely\napproximate the output from a model that has never been trained on the data\nintended for forgetting. Through extensive experiments on unlearning, we\ndemonstrate the superiority of our method in achieving promising unlearning at\nnearly zero side effects in general domains and domains closely related to the\nunlearned ones. Additionally, we highlight the scalability of our method to 100\nLLMs, ranging from 0.5B to 236B parameters, incurring no additional cost as the\nnumber of parameters increases.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u9032\u6b65\u5230\u6db5\u84cb\u5404\u500b\u9818\u57df\u7684\u5ee3\u6cdb\u77e5\u8b58\u3002\u7136\u800c\uff0c\u63a7\u5236\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4e0d\u61c9\u77e5\u9053\u7684\u5167\u5bb9\u5c0d\u65bc\u78ba\u4fdd\u5c0d\u9f4a\u4e26\u56e0\u6b64\u5b89\u5168\u4f7f\u7528\u975e\u5e38\u91cd\u8981\u3002\u7136\u800c\uff0c\u7531\u65bc\u4fdd\u7559\u548c\u907a\u5fd8\u4e4b\u9593\u7684\u6a21\u7cca\u754c\u9650\u9020\u6210\u7684\u6f5b\u5728\u9644\u5e36\u640d\u5bb3\uff0c\u4ee5\u53ca\u512a\u5316\u6578\u767e\u5104\u500b\u53c3\u6578\u7684\u6700\u65b0\u6a21\u578b\u6240\u9700\u7684\u9f90\u5927\u8a08\u7b97\u9700\u6c42\uff0c\u6e96\u78ba\u4e14\u6709\u6548\u5730\u5f9e LLM \u4e2d\u907a\u5fd8\u77e5\u8b58\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u5d4c\u5165\u5f0f\u640d\u58de (ECO) \u63d0\u793a\uff0c\u9019\u662f\u4e00\u7a2e\u8f15\u91cf\u7d1a\u7684\u907a\u5fd8\u6846\u67b6\uff0c\u9069\u7528\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff0c\u4ee5\u61c9\u5c0d\u77e5\u8b58\u7cfe\u7e8f\u548c\u907a\u5fd8\u6548\u7387\u7684\u6311\u6230\u3002\u6211\u5011\u4e26\u975e\u4f9d\u8cf4 LLM \u672c\u8eab\u4f86\u907a\u5fd8\uff0c\u800c\u662f\u901a\u904e\u4f7f\u7528\u63d0\u793a\u5206\u985e\u5668\u4f86\u8b58\u5225\u548c\u4fdd\u8b77\u63d0\u793a\u4ee5\u907a\u5fd8\uff0c\u5f9e\u800c\u5f37\u5236\u57f7\u884c\u63a8\u8ad6\u671f\u9593\u7684\u672a\u5b78\u7fd2\u72c0\u614b\u3002\u6211\u5011\u901a\u904e\u96f6\u968e\u512a\u5316\u5b78\u7fd2\u6dfb\u52a0\u5230\u63d0\u793a\u5d4c\u5165\u7684\u640d\u58de\uff0c\u4ee5\u5be6\u73fe\u96e2\u7dda\u907a\u5fd8\u76ee\u6a19\uff0c\u4e26\u640d\u58de\u63a8\u8ad6\u671f\u9593\u5206\u985e\u5668\u6a19\u8a18\u7684\u63d0\u793a\u3002\u6211\u5011\u767c\u73fe\uff0c\u9019\u4e9b\u5d4c\u5165\u5f0f\u640d\u58de\u7684\u63d0\u793a\u4e0d\u50c5\u6703\u5c0e\u81f4\u6eff\u8db3\u907a\u5fd8\u76ee\u6a19\u7684\u7406\u60f3\u8f38\u51fa\uff0c\u800c\u4e14\u9084\u975e\u5e38\u63a5\u8fd1\u5f9e\u672a\u91dd\u5c0d\u6253\u7b97\u907a\u5fd8\u7684\u6578\u64da\u9032\u884c\u8a13\u7df4\u7684\u6a21\u578b\u7684\u8f38\u51fa\u3002\u901a\u904e\u5c0d\u907a\u5fd8\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u6211\u5011\u8b49\u660e\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728\u4e00\u822c\u9818\u57df\u548c\u8207\u672a\u5b78\u7fd2\u9818\u57df\u5bc6\u5207\u76f8\u95dc\u7684\u9818\u57df\u5be6\u73fe\u6709\u5e0c\u671b\u7684\u907a\u5fd8\u6642\uff0c\u526f\u4f5c\u7528\u5e7e\u4e4e\u70ba\u96f6\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f37\u8abf\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5c0d 100 \u500b LLM \u7684\u53ef\u64f4\u5c55\u6027\uff0c\u7bc4\u570d\u5f9e 0.5B \u5230 236B \u53c3\u6578\uff0c\u96a8\u8457\u53c3\u6578\u6578\u91cf\u7684\u589e\u52a0\uff0c\u4e0d\u6703\u7522\u751f\u984d\u5916\u7684\u6210\u672c\u3002", "author": "Chris Yuhao Liu et.al.", "authors": "Chris Yuhao Liu, Yaxuan Wang, Jeffrey Flanigan, Yang Liu", "id": "2406.07933v1", "paper_url": "http://arxiv.org/abs/2406.07933v1", "repo": "null"}}