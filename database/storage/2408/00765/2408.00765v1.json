{"2408.00765": {"publish_time": "2024-08-01", "title": "MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities", "paper_summary": "MM-Vet, with open-ended vision-language questions targeting at evaluating\nintegrated capabilities, has become one of the most popular benchmarks for\nlarge multimodal model evaluation. MM-Vet assesses six core vision-language\n(VL) capabilities: recognition, knowledge, spatial awareness, language\ngeneration, OCR, and math. However, its question format is restricted to single\nimage-text pairs, lacking the interleaved image and text sequences prevalent in\nreal-world scenarios. To address this limitation, we introduce MM-Vet v2, which\nincludes a new VL capability called \"image-text sequence understanding\",\nevaluating models' ability to process VL sequences. Furthermore, we maintain\nthe high quality of evaluation samples while further expanding the evaluation\nset size. Using MM-Vet v2 to benchmark large multimodal models, we found that\nClaude 3.5 Sonnet is the best model with a score of 71.8, slightly\noutperforming GPT-4o which scored 71.0. Among open-weight models,\nInternVL2-Llama3-76B leads with a score of 68.4.", "paper_summary_zh": "MM-Vet \u900f\u904e\u91dd\u5c0d\u8a55\u4f30\u6574\u5408\u80fd\u529b\u800c\u8a2d\u8a08\u7684\u958b\u653e\u5f0f\u8996\u89ba\u8a9e\u8a00\u554f\u984c\uff0c\u5df2\u6210\u70ba\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b\u8a55\u4f30\u6700\u53d7\u6b61\u8fce\u7684\u57fa\u6e96\u4e4b\u4e00\u3002MM-Vet \u8a55\u4f30\u516d\u9805\u6838\u5fc3\u8996\u89ba\u8a9e\u8a00 (VL) \u80fd\u529b\uff1a\u8fa8\u8b58\u3001\u77e5\u8b58\u3001\u7a7a\u9593\u610f\u8b58\u3001\u8a9e\u8a00\u751f\u6210\u3001OCR \u548c\u6578\u5b78\u3002\u7136\u800c\uff0c\u5176\u554f\u984c\u683c\u5f0f\u50c5\u9650\u65bc\u55ae\u4e00\u5f71\u50cf\u6587\u5b57\u5c0d\uff0c\u7f3a\u4e4f\u771f\u5be6\u4e16\u754c\u5834\u666f\u4e2d\u666e\u904d\u5b58\u5728\u7684\u4ea4\u932f\u5f71\u50cf\u548c\u6587\u5b57\u5e8f\u5217\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u9650\u5236\uff0c\u6211\u5011\u5f15\u5165\u4e86 MM-Vet v2\uff0c\u5176\u4e2d\u5305\u542b\u7a31\u70ba\u300c\u5f71\u50cf\u6587\u5b57\u5e8f\u5217\u7406\u89e3\u300d\u7684\u65b0 VL \u80fd\u529b\uff0c\u7528\u65bc\u8a55\u4f30\u6a21\u578b\u8655\u7406 VL \u5e8f\u5217\u7684\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6211\u5011\u5728\u9032\u4e00\u6b65\u64f4\u5145\u8a55\u4f30\u96c6\u5927\u5c0f\u7684\u540c\u6642\uff0c\u7dad\u6301\u8a55\u4f30\u7bc4\u4f8b\u7684\u9ad8\u54c1\u8cea\u3002\u6211\u5011\u4f7f\u7528 MM-Vet v2 \u5c0d\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b\u9032\u884c\u57fa\u6e96\u6e2c\u8a66\uff0c\u767c\u73fe Claude 3.5 Sonnet \u662f\u6700\u4f73\u6a21\u578b\uff0c\u5f97\u5206\u70ba 71.8\uff0c\u7565\u512a\u65bc GPT-4o \u7684 71.0 \u5206\u3002\u5728\u958b\u653e\u6b0a\u91cd\u6a21\u578b\u4e2d\uff0cInternVL2-Llama3-76B \u4ee5 68.4 \u5206\u9818\u5148\u3002", "author": "Weihao Yu et.al.", "authors": "Weihao Yu, Zhengyuan Yang, Linfeng Ren, Linjie Li, Jianfeng Wang, Kevin Lin, Chung-Ching Lin, Zicheng Liu, Lijuan Wang, Xinchao Wang", "id": "2408.00765v1", "paper_url": "http://arxiv.org/abs/2408.00765v1", "repo": "null"}}