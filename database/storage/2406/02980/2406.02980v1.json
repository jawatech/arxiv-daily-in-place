{"2406.02980": {"publish_time": "2024-06-05", "title": "Tensor Polynomial Additive Model", "paper_summary": "Additive models can be used for interpretable machine learning for their\nclarity and simplicity. However, In the classical models for high-order data,\nthe vectorization operation disrupts the data structure, which may lead to\ndegenerated accuracy and increased computational complexity. To deal with these\nproblems, we propose the tensor polynomial addition model (TPAM). It retains\nthe multidimensional structure information of high-order inputs with tensor\nrepresentation. The model parameter compression is achieved using a\nhierarchical and low-order symmetric tensor approximation. In this way, complex\nhigh-order feature interactions can be captured with fewer parameters.\nMoreover, The TPAM preserves the inherent interpretability of additive models,\nfacilitating transparent decision-making and the extraction of meaningful\nfeature values. Additionally, leveraging TPAM's transparency and ability to\nhandle higher-order features, it is used as a post-processing module for other\ninterpretation models by introducing two variants for class activation maps.\nExperimental results on a series of datasets demonstrate that TPAM can enhance\naccuracy by up to 30\\%, and compression rate by up to 5 times, while\nmaintaining a good interpretability.", "paper_summary_zh": "\u52a0\u6cd5\u6a21\u578b\u56e0\u5176\u6e05\u6670\u548c\u7b80\u5355\u6027\u800c\u53ef\u7528\u4e8e\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u3002\u7136\u800c\uff0c\u5728\u9ad8\u9636\u6570\u636e\u7684\u7ecf\u5178\u6a21\u578b\u4e2d\uff0c\u5411\u91cf\u5316\u64cd\u4f5c\u4f1a\u7834\u574f\u6570\u636e\u7ed3\u6784\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u7cbe\u5ea6\u4e0b\u964d\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u589e\u52a0\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u5f20\u91cf\u591a\u9879\u5f0f\u52a0\u6cd5\u6a21\u578b (TPAM)\u3002\u5b83\u4f7f\u7528\u5f20\u91cf\u8868\u793a\u4fdd\u7559\u4e86\u9ad8\u9636\u8f93\u5165\u7684\u591a\u7ef4\u7ed3\u6784\u4fe1\u606f\u3002\u6a21\u578b\u53c2\u6570\u538b\u7f29\u662f\u4f7f\u7528\u5206\u5c42\u548c\u4f4e\u9636\u5bf9\u79f0\u5f20\u91cf\u8fd1\u4f3c\u6765\u5b9e\u73b0\u7684\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u53ef\u4ee5\u7528\u66f4\u5c11\u7684\u53c2\u6570\u6355\u83b7\u590d\u6742\u7684\u9ad8\u9636\u7279\u5f81\u4ea4\u4e92\u3002\u6b64\u5916\uff0cTPAM \u4fdd\u7559\u4e86\u52a0\u6cd5\u6a21\u578b\u7684\u56fa\u6709\u53ef\u89e3\u91ca\u6027\uff0c\u4fc3\u8fdb\u4e86\u900f\u660e\u7684\u51b3\u7b56\u5236\u5b9a\u548c\u6709\u610f\u4e49\u7684\u7279\u5f81\u503c\u7684\u63d0\u53d6\u3002\u6b64\u5916\uff0c\u5229\u7528 TPAM \u7684\u900f\u660e\u6027\u548c\u5904\u7406\u9ad8\u9636\u7279\u5f81\u7684\u80fd\u529b\uff0c\u5b83\u88ab\u7528\u4f5c\u5176\u4ed6\u89e3\u91ca\u6a21\u578b\u7684\u540e\u5904\u7406\u6a21\u5757\uff0c\u65b9\u6cd5\u662f\u4e3a\u7c7b\u6fc0\u6d3b\u6620\u5c04\u5f15\u5165\u4e24\u4e2a\u53d8\u4f53\u3002\u4e00\u7cfb\u5217\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTPAM \u53ef\u4ee5\u5c06\u51c6\u786e\u7387\u63d0\u9ad8\u9ad8\u8fbe 30%\uff0c\u538b\u7f29\u7387\u63d0\u9ad8\u9ad8\u8fbe 5 \u500d\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002", "author": "Yang Chen et.al.", "authors": "Yang Chen, Ce Zhu, Jiani Liu, Yipeng Liu", "id": "2406.02980v1", "paper_url": "http://arxiv.org/abs/2406.02980v1", "repo": "null"}}