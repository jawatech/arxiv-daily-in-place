{"2411.12103": {"publish_time": "2024-11-18", "title": "Does Unlearning Truly Unlearn? A Black Box Evaluation of LLM Unlearning Methods", "paper_summary": "Large language model unlearning aims to remove harmful information that LLMs\nhave learnt to prevent their use for malicious purposes. LLMU and RMU have been\nproposed as two methods for LLM unlearning, achieving impressive results on\nunlearning benchmarks. We study in detail the efficacy of these methods by\nevaluating their impact on general model capabilities on the WMDP benchmark as\nwell as a biology benchmark we create. Our experiments show that RMU generally\nleads to better preservation of model capabilities, for similar or better\nunlearning. We further test the robustness of these methods and find that doing\n5-shot prompting or rephrasing the question in simple ways can lead to an over\nten-fold increase in accuracy on unlearning benchmarks. Finally, we show that\ntraining on unrelated data can almost completely recover pre-unlearning\nperformance, demonstrating that these methods fail at truly unlearning. The\ncode is available at\n$\\href{https://github.com/JaiDoshi/Knowledge-Erasure}{this\\, https\\, URL}$.", "paper_summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9057\u5fd8\u65e8\u5728\u6d88\u9664 LLM \u5b66\u5230\u7684\u6709\u5bb3\u4fe1\u606f\uff0c\u4ee5\u9632\u6b62\u5176\u88ab\u6076\u610f\u4f7f\u7528\u3002LLMU \u548c RMU \u5df2\u88ab\u63d0\u51fa\u4f5c\u4e3a LLM \u9057\u5fd8\u7684\u4e24\u79cd\u65b9\u6cd5\uff0c\u5728\u9057\u5fd8\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u7ed3\u679c\u3002\u6211\u4eec\u901a\u8fc7\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\u5bf9 WMDP \u57fa\u51c6\u548c\u6211\u4eec\u521b\u5efa\u7684\u751f\u7269\u57fa\u51c6\u4e0a\u7684\u4e00\u822c\u6a21\u578b\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u8be6\u7ec6\u7814\u7a76\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u529f\u6548\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5bf9\u4e8e\u7c7b\u4f3c\u6216\u66f4\u597d\u7684\u9057\u5fd8\uff0cRMU \u901a\u5e38\u4f1a\u5bfc\u81f4\u6a21\u578b\u80fd\u529b\u5f97\u5230\u66f4\u597d\u7684\u4fdd\u7559\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u6d4b\u8bd5\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u8fdb\u884c 5 \u6b21\u63d0\u793a\u6216\u4ee5\u7b80\u5355\u7684\u65b9\u5f0f\u91cd\u65b0\u8868\u8ff0\u95ee\u9898\u4f1a\u5bfc\u81f4\u9057\u5fd8\u57fa\u51c6\u7684\u51c6\u786e\u6027\u63d0\u9ad8\u5341\u500d\u4ee5\u4e0a\u3002\u6700\u540e\uff0c\u6211\u4eec\u8868\u660e\u5728\u4e0d\u76f8\u5173\u7684\u8bad\u7ec3\u6570\u636e\u4e0a\u8bad\u7ec3\u51e0\u4e4e\u53ef\u4ee5\u5b8c\u5168\u6062\u590d\u9057\u5fd8\u524d\u7684\u6027\u80fd\uff0c\u8fd9\u8868\u660e\u8fd9\u4e9b\u65b9\u6cd5\u672a\u80fd\u771f\u6b63\u5b9e\u73b0\u9057\u5fd8\u3002\u4ee3\u7801\u53ef\u5728\u6b64\u5904\u83b7\u5f97\uff1a\n$\\href{https://github.com/JaiDoshi/Knowledge-Erasure}{\u6b64\\, https\\, URL}$\u3002", "author": "Jai Doshi et.al.", "authors": "Jai Doshi, Asa Cooper Stickland", "id": "2411.12103v1", "paper_url": "http://arxiv.org/abs/2411.12103v1", "repo": "https://github.com/jaidoshi/knowledge-erasure"}}