{"2404.18831": {"publish_time": "2024-04-29", "title": "ConPro: Learning Severity Representation for Medical Images using Contrastive Learning and Preference Optimization", "paper_summary": "Understanding the severity of conditions shown in images in medical diagnosis\nis crucial, serving as a key guide for clinical assessment, treatment, as well\nas evaluating longitudinal progression. This paper proposes Con- PrO: a novel\nrepresentation learning method for severity assessment in medical images using\nContrastive learningintegrated Preference Optimization. Different from\nconventional contrastive learning methods that maximize the distance between\nclasses, ConPrO injects into the latent vector the distance preference\nknowledge between various severity classes and the normal class. We\nsystematically examine the key components of our framework to illuminate how\ncontrastive prediction tasks acquire valuable representations. We show that our\nrepresentation learning framework offers valuable severity ordering in the\nfeature space while outperforming previous state-of-the-art methods on\nclassification tasks. We achieve a 6% and 20% relative improvement compared to\na supervised and a self-supervised baseline, respectively. In addition, we\nderived discussions on severity indicators and related applications of\npreference comparison in the medical domain.", "paper_summary_zh": "\u4e86\u89e3\u91ab\u7642\u8a3a\u65b7\u5f71\u50cf\u4e2d\u6240\u5448\u73fe\u75c5\u60c5\u7684\u56b4\u91cd\u7a0b\u5ea6\uff0c\u5c0d\u65bc\u81e8\u5e8a\u8a55\u4f30\u3001\u6cbb\u7642\u4ee5\u53ca\u8a55\u4f30\u7e31\u5411\u9032\u7a0b\u81f3\u95dc\u91cd\u8981\uff0c\u662f\u95dc\u9375\u6307\u6a19\u3002\u672c\u6587\u63d0\u51fa Con- PrO\uff1a\u4e00\u7a2e\u7528\u65bc\u91ab\u7642\u5f71\u50cf\u56b4\u91cd\u7a0b\u5ea6\u8a55\u4f30\u7684\u65b0\u7a4e\u8868\u5fb5\u5b78\u7fd2\u65b9\u6cd5\uff0c\u63a1\u7528\u5c0d\u6bd4\u5b78\u7fd2\u6574\u5408\u504f\u597d\u6700\u4f73\u5316\u3002\u8207\u6700\u5927\u5316\u985e\u5225\u9593\u8ddd\u96e2\u7684\u50b3\u7d71\u5c0d\u6bd4\u5b78\u7fd2\u65b9\u6cd5\u4e0d\u540c\uff0cConPrO \u5c07\u4e0d\u540c\u56b4\u91cd\u7a0b\u5ea6\u985e\u5225\u8207\u6b63\u5e38\u985e\u5225\u4e4b\u9593\u7684\u8ddd\u96e2\u504f\u597d\u77e5\u8b58\u6ce8\u5165\u6f5b\u5728\u5411\u91cf\u3002\u6211\u5011\u7cfb\u7d71\u6027\u5730\u6aa2\u9a57\u4e86\u6211\u5011\u67b6\u69cb\u7684\u95dc\u9375\u7d44\u6210\u90e8\u5206\uff0c\u4ee5\u8aaa\u660e\u5c0d\u6bd4\u9810\u6e2c\u4efb\u52d9\u5982\u4f55\u7372\u53d6\u6709\u50f9\u503c\u7684\u8868\u5fb5\u3002\u6211\u5011\u8868\u660e\uff0c\u6211\u5011\u7684\u8868\u5fb5\u5b78\u7fd2\u67b6\u69cb\u5728\u7279\u5fb5\u7a7a\u9593\u4e2d\u63d0\u4f9b\u4e86\u6709\u50f9\u503c\u7684\u56b4\u91cd\u7a0b\u5ea6\u6392\u5e8f\uff0c\u540c\u6642\u5728\u5206\u985e\u4efb\u52d9\u4e0a\u512a\u65bc\u5148\u524d\u7684\u6700\u5148\u9032\u65b9\u6cd5\u3002\u8207\u6709\u76e3\u7763\u548c\u81ea\u76e3\u7763\u57fa\u7dda\u76f8\u6bd4\uff0c\u6211\u5011\u5206\u5225\u53d6\u5f97\u4e86 6% \u548c 20% \u7684\u76f8\u5c0d\u9032\u6b65\u3002\u6b64\u5916\uff0c\u6211\u5011\u91dd\u5c0d\u56b4\u91cd\u7a0b\u5ea6\u6307\u6a19\u548c\u504f\u597d\u6bd4\u8f03\u5728\u91ab\u7642\u9818\u57df\u7684\u76f8\u95dc\u61c9\u7528\u9032\u884c\u4e86\u63a2\u8a0e\u3002", "author": "Hong Nguyen et.al.", "authors": "Hong Nguyen, Hoang Nguyen, Melinda Chang, Hieu Pham, Shrikanth Narayanan, Michael Pazzani", "id": "2404.18831v1", "paper_url": "http://arxiv.org/abs/2404.18831v1", "repo": "https://github.com/hong7cong/conpro"}}