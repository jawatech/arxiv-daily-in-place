{"2407.04183": {"publish_time": "2024-07-04", "title": "Seeing Like an AI: How LLMs Apply (and Misapply) Wikipedia Neutrality Norms", "paper_summary": "Large language models (LLMs) are trained on broad corpora and then used in\ncommunities with specialized norms. Is providing LLMs with community rules\nenough for models to follow these norms? We evaluate LLMs' capacity to detect\n(Task 1) and correct (Task 2) biased Wikipedia edits according to Wikipedia's\nNeutral Point of View (NPOV) policy. LLMs struggled with bias detection,\nachieving only 64% accuracy on a balanced dataset. Models exhibited contrasting\nbiases (some under- and others over-predicted bias), suggesting distinct priors\nabout neutrality. LLMs performed better at generation, removing 79% of words\nremoved by Wikipedia editors. However, LLMs made additional changes beyond\nWikipedia editors' simpler neutralizations, resulting in high-recall but\nlow-precision editing. Interestingly, crowdworkers rated AI rewrites as more\nneutral (70%) and fluent (61%) than Wikipedia-editor rewrites. Qualitative\nanalysis found LLMs sometimes applied NPOV more comprehensively than Wikipedia\neditors but often made extraneous non-NPOV-related changes (such as grammar).\nLLMs may apply rules in ways that resonate with the public but diverge from\ncommunity experts. While potentially effective for generation, LLMs may reduce\neditor agency and increase moderation workload (e.g., verifying additions).\nEven when rules are easy to articulate, having LLMs apply them like community\nmembers may still be difficult.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5ee3\u6cdb\u7684\u8a9e\u6599\u5eab\u4e0a\u9032\u884c\u8a13\u7df4\uff0c\u7136\u5f8c\u5728\u5177\u6709\u7279\u6b8a\u898f\u7bc4\u7684\u793e\u7fa4\u4e2d\u4f7f\u7528\u3002\u63d0\u4f9b LLM \u793e\u7fa4\u898f\u5247\u662f\u5426\u8db3\u4ee5\u8b93\u6a21\u578b\u9075\u5faa\u9019\u4e9b\u898f\u7bc4\uff1f\u6211\u5011\u8a55\u4f30 LLM \u6839\u64da\u7dad\u57fa\u767e\u79d1\u7684\u4e2d\u7acb\u89c0\u9ede\uff08NPOV\uff09\u653f\u7b56\u6aa2\u6e2c\uff08\u4efb\u52d9 1\uff09\u548c\u66f4\u6b63\uff08\u4efb\u52d9 2\uff09\u6709\u504f\u5dee\u7684\u7dad\u57fa\u767e\u79d1\u7de8\u8f2f\u7684\u80fd\u529b\u3002LLM \u5728\u504f\u5dee\u6aa2\u6e2c\u65b9\u9762\u9047\u5230\u56f0\u96e3\uff0c\u5728\u5e73\u8861\u7684\u8cc7\u6599\u96c6\u4e0a\u53ea\u9054\u5230 64% \u7684\u6e96\u78ba\u5ea6\u3002\u6a21\u578b\u8868\u73fe\u51fa\u5c0d\u6bd4\u7684\u504f\u5dee\uff08\u4e00\u4e9b\u9810\u6e2c\u504f\u5dee\u4e0d\u8db3\uff0c\u53e6\u4e00\u4e9b\u5247\u9810\u6e2c\u904e\u5ea6\uff09\uff0c\u9019\u8868\u660e\u5c0d\u4e2d\u7acb\u6027\u7684\u5148\u9a57\u4e0d\u540c\u3002LLM \u5728\u751f\u6210\u65b9\u9762\u8868\u73fe\u5f97\u66f4\u597d\uff0c\u79fb\u9664\u4e86\u7dad\u57fa\u767e\u79d1\u7de8\u8f2f\u8005\u79fb\u9664\u7684 79% \u7684\u5b57\u8a5e\u3002\u7136\u800c\uff0cLLM \u505a\u51fa\u4e86\u8d85\u51fa\u7dad\u57fa\u767e\u79d1\u7de8\u8f2f\u8005\u66f4\u7c21\u55ae\u7684\u4e2d\u7acb\u5316\u7684\u984d\u5916\u66f4\u6539\uff0c\u5c0e\u81f4\u9ad8\u53ec\u56de\u7387\u4f46\u4f4e\u7cbe\u78ba\u5ea6\u7684\u7de8\u8f2f\u3002\u6709\u8da3\u7684\u662f\uff0c\u7fa4\u773e\u5de5\u4f5c\u8005\u5c07 AI \u91cd\u5beb\u8a55\u70ba\u6bd4\u7dad\u57fa\u767e\u79d1\u7de8\u8f2f\u91cd\u5beb\u66f4\u4e2d\u7acb\uff0870%\uff09\u548c\u6d41\u66a2\uff0861%\uff09\u3002\u5b9a\u6027\u5206\u6790\u767c\u73fe\uff0cLLM \u6709\u6642\u6bd4\u7dad\u57fa\u767e\u79d1\u7de8\u8f2f\u8005\u66f4\u5168\u9762\u5730\u61c9\u7528 NPOV\uff0c\u4f46\u7d93\u5e38\u505a\u51fa\u8207 NPOV \u7121\u95dc\u7684\u984d\u5916\u66f4\u6539\uff08\u4f8b\u5982\u8a9e\u6cd5\uff09\u3002LLM \u53ef\u80fd\u4ee5\u8207\u516c\u773e\u7522\u751f\u5171\u9cf4\u7684\u65b9\u5f0f\u61c9\u7528\u898f\u5247\uff0c\u4f46\u8207\u793e\u7fa4\u5c08\u5bb6\u4e0d\u540c\u3002\u5118\u7ba1\u5728\u751f\u6210\u65b9\u9762\u53ef\u80fd\u6709\u6548\uff0c\u4f46 LLM \u53ef\u80fd\u6703\u6e1b\u5c11\u7de8\u8f2f\u8005\u4ee3\u7406\u4e26\u589e\u52a0\u5be9\u6838\u5de5\u4f5c\u91cf\uff08\u4f8b\u5982\uff0c\u9a57\u8b49\u65b0\u589e\u5167\u5bb9\uff09\u3002\u5373\u4f7f\u898f\u5247\u5f88\u5bb9\u6613\u8868\u9054\uff0c\u8b93 LLM \u50cf\u793e\u7fa4\u6210\u54e1\u4e00\u6a23\u61c9\u7528\u5b83\u5011\u53ef\u80fd\u4ecd\u7136\u5f88\u56f0\u96e3\u3002", "author": "Joshua Ashkinaze et.al.", "authors": "Joshua Ashkinaze, Ruijia Guan, Laura Kurek, Eytan Adar, Ceren Budak, Eric Gilbert", "id": "2407.04183v1", "paper_url": "http://arxiv.org/abs/2407.04183v1", "repo": "null"}}