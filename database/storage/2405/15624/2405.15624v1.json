{"2405.15624": {"publish_time": "2024-05-24", "title": "Inverse-RLignment: Inverse Reinforcement Learning from Demonstrations for LLM Alignment", "paper_summary": "Aligning Large Language Models (LLMs) is crucial for enhancing their safety\nand utility. However, existing methods, primarily based on preference datasets,\nface challenges such as noisy labels, high annotation costs, and privacy\nconcerns. In this work, we introduce Alignment from Demonstrations (AfD), a\nnovel approach leveraging high-quality demonstration data to overcome these\nchallenges. We formalize AfD within a sequential decision-making framework,\nhighlighting its unique challenge of missing reward signals. Drawing insights\nfrom forward and inverse reinforcement learning, we introduce divergence\nminimization objectives for AfD. Analytically, we elucidate the mass-covering\nand mode-seeking behaviors of various approaches, explaining when and why\ncertain methods are superior. Practically, we propose a computationally\nefficient algorithm that extrapolates over a tailored reward model for AfD. We\nvalidate our key insights through experiments on the Harmless and Helpful\ntasks, demonstrating their strong empirical performance while maintaining\nsimplicity.", "paper_summary_zh": "\u5c0d\u9f4a\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c0d\u65bc\u589e\u5f37\u5176\u5b89\u5168\u6027\n\u548c\u5be6\u7528\u6027\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u73fe\u6709\u65b9\u6cd5\uff08\u4e3b\u8981\u57fa\u65bc\u504f\u597d\u8cc7\u6599\u96c6\uff09\n\u9762\u81e8\u8af8\u5982\u6a19\u7c64\u96dc\u8a0a\u3001\u6a19\u8a3b\u6210\u672c\u9ad8\u548c\u96b1\u79c1\u7b49\u6311\u6230\n\u7591\u616e\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u793a\u7bc4\u5c0d\u9f4a (AfD)\uff0c\u4e00\u7a2e\n\u5229\u7528\u9ad8\u54c1\u8cea\u793a\u7bc4\u8cc7\u6599\u4f86\u514b\u670d\u9019\u4e9b\u6311\u6230\u7684\u65b0\u65b9\u6cd5\u3002\u6211\u5011\u5728\u5e8f\u8cab\u6c7a\u7b56\u5236\u5b9a\u67b6\u69cb\u4e2d\u5f62\u5f0f\u5316 AfD\uff0c\n\u5f37\u8abf\u5176\u932f\u5931\u734e\u52f5\u8a0a\u865f\u7684\u7368\u7279\u6311\u6230\u3002\u5f9e\u6b63\u5411\u548c\u53cd\u5411\u5f37\u5316\u5b78\u7fd2\u4e2d\u6c72\u53d6\u898b\u89e3\uff0c\u6211\u5011\u5f15\u5165\u4e86 AfD \u7684\u5dee\u7570\u6700\u5c0f\u5316\u76ee\u6a19\u3002\u5728\u5206\u6790\u4e0a\uff0c\u6211\u5011\u95e1\u660e\u4e86\u5404\u7a2e\u65b9\u6cd5\u7684\u8cea\u91cf\u8986\u84cb\n\u548c\u6a21\u5f0f\u5c0b\u6c42\u884c\u70ba\uff0c\u89e3\u91cb\u4e86\u67d0\u4e9b\u65b9\u6cd5\u4f55\u6642\u4ee5\u53ca\u70ba\u4f55\u512a\u8d8a\u3002\u5728\u5be6\u52d9\u4e0a\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u8a08\u7b97\n\u4e00\u7a2e\u5c0d\u65bc AfD \u7684\u91cf\u8eab\u6253\u9020\u734e\u52f5\u6a21\u578b\u9032\u884c\u5916\u63a8\u7684\u6709\u6548\u7387\u6f14\u7b97\u6cd5\u3002\u6211\u5011\n\u901a\u904e\u5728\u7121\u5bb3\u548c\u6709\u76ca\u4efb\u52d9\u4e0a\u7684\u5be6\u9a57\u9a57\u8b49\u6211\u5011\u7684\u95dc\u9375\u898b\u89e3\uff0c\u8b49\u660e\u5176\u5f37\u5927\u7684\u7d93\u9a57\u6548\u80fd\uff0c\u540c\u6642\u7dad\u6301\n\u7c21\u6f54\u6027\u3002", "author": "Hao Sun et.al.", "authors": "Hao Sun, Mihaela van der Schaar", "id": "2405.15624v1", "paper_url": "http://arxiv.org/abs/2405.15624v1", "repo": "null"}}