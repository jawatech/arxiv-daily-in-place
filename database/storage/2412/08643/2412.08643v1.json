{"2412.08643": {"publish_time": "2024-12-11", "title": "GPD-1: Generative Pre-training for Driving", "paper_summary": "Modeling the evolutions of driving scenarios is important for the evaluation\nand decision-making of autonomous driving systems. Most existing methods focus\non one aspect of scene evolution such as map generation, motion prediction, and\ntrajectory planning. In this paper, we propose a unified Generative\nPre-training for Driving (GPD-1) model to accomplish all these tasks altogether\nwithout additional fine-tuning. We represent each scene with ego, agent, and\nmap tokens and formulate autonomous driving as a unified token generation\nproblem. We adopt the autoregressive transformer architecture and use a\nscene-level attention mask to enable intra-scene bi-directional interactions.\nFor the ego and agent tokens, we propose a hierarchical positional tokenizer to\neffectively encode both 2D positions and headings. For the map tokens, we train\na map vector-quantized autoencoder to efficiently compress ego-centric semantic\nmaps into discrete tokens. We pre-train our GPD-1 on the large-scale nuPlan\ndataset and conduct extensive experiments to evaluate its effectiveness. With\ndifferent prompts, our GPD-1 successfully generalizes to various tasks without\nfinetuning, including scene generation, traffic simulation, closed-loop\nsimulation, map prediction, and motion planning. Code:\nhttps://github.com/wzzheng/GPD.", "paper_summary_zh": "\u6a21\u64ec\u99d5\u99db\u5834\u666f\u7684\u6f14\u9032\u5c0d\u65bc\u8a55\u4f30\u548c\u6c7a\u7b56\u81ea\u52d5\u99d5\u99db\u7cfb\u7d71\u975e\u5e38\u91cd\u8981\u3002\u73fe\u6709\u7684\u65b9\u6cd5\u5927\u591a\u5c08\u6ce8\u65bc\u5834\u666f\u6f14\u9032\u7684\u4e00\u500b\u9762\u5411\uff0c\u4f8b\u5982\u5730\u5716\u751f\u6210\u3001\u904b\u52d5\u9810\u6e2c\u548c\u8ecc\u8de1\u898f\u5283\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7d71\u4e00\u7684\u751f\u6210\u5f0f\u99d5\u99db\u9810\u8a13\u7df4 (GPD-1) \u6a21\u578b\uff0c\u53ef\u4ee5\u540c\u6642\u5b8c\u6210\u6240\u6709\u9019\u4e9b\u4efb\u52d9\uff0c\u800c\u7121\u9700\u984d\u5916\u7684\u5fae\u8abf\u3002\u6211\u5011\u4f7f\u7528\u81ea\u6211\u3001\u4ee3\u7406\u548c\u5730\u5716\u7b26\u865f\u8868\u793a\u6bcf\u500b\u5834\u666f\uff0c\u4e26\u5c07\u81ea\u52d5\u99d5\u99db\u8868\u8ff0\u70ba\u4e00\u500b\u7d71\u4e00\u7684\u7b26\u865f\u751f\u6210\u554f\u984c\u3002\u6211\u5011\u63a1\u7528\u81ea\u8ff4\u6b78Transformer\u67b6\u69cb\uff0c\u4e26\u4f7f\u7528\u5834\u666f\u7d1a\u5225\u7684\u6ce8\u610f\u529b\u906e\u7f69\u4f86\u555f\u7528\u5834\u666f\u5167\u96d9\u5411\u4ea4\u4e92\u3002\u5c0d\u65bc\u81ea\u6211\u548c\u4ee3\u7406\u7b26\u865f\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5206\u5c64\u4f4d\u7f6e\u6a19\u8a18\u5668\uff0c\u4ee5\u6709\u6548\u7de8\u78bc 2D \u4f4d\u7f6e\u548c\u6a19\u984c\u3002\u5c0d\u65bc\u5730\u5716\u7b26\u865f\uff0c\u6211\u5011\u8a13\u7df4\u4e86\u4e00\u500b\u5730\u5716\u5411\u91cf\u91cf\u5316\u7684\u81ea\u52d5\u7de8\u78bc\u5668\uff0c\u4ee5\u6709\u6548\u5730\u5c07\u4ee5\u81ea\u6211\u70ba\u4e2d\u5fc3\u7684\u8a9e\u7fa9\u5730\u5716\u58d3\u7e2e\u6210\u96e2\u6563\u7b26\u865f\u3002\u6211\u5011\u5728\u5927\u578b nuPlan \u8cc7\u6599\u96c6\u4e0a\u9810\u8a13\u7df4\u6211\u5011\u7684 GPD-1\uff0c\u4e26\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\u4f86\u8a55\u4f30\u5176\u6709\u6548\u6027\u3002\u900f\u904e\u4e0d\u540c\u7684\u63d0\u793a\uff0c\u6211\u5011\u7684 GPD-1 \u6210\u529f\u5730\u63a8\u5ee3\u5230\u5404\u7a2e\u4efb\u52d9\uff0c\u800c\u7121\u9700\u5fae\u8abf\uff0c\u5305\u62ec\u5834\u666f\u751f\u6210\u3001\u4ea4\u901a\u6a21\u64ec\u3001\u9589\u74b0\u6a21\u64ec\u3001\u5730\u5716\u9810\u6e2c\u548c\u904b\u52d5\u898f\u5283\u3002\u7a0b\u5f0f\u78bc\uff1a\nhttps://github.com/wzzheng/GPD\u3002", "author": "Zixun Xie et.al.", "authors": "Zixun Xie, Sicheng Zuo, Wenzhao Zheng, Yunpeng Zhang, Dalong Du, Jie Zhou, Jiwen Lu, Shanghang Zhang", "id": "2412.08643v1", "paper_url": "http://arxiv.org/abs/2412.08643v1", "repo": "https://github.com/wzzheng/gpd"}}