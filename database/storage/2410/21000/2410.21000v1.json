{"2410.21000": {"publish_time": "2024-10-28", "title": "Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering", "paper_summary": "Medical Visual Question Answering (MedVQA) has gained increasing attention at\nthe intersection of computer vision and natural language processing. Its\ncapability to interpret radiological images and deliver precise answers to\nclinical inquiries positions MedVQA as a valuable tool for supporting\ndiagnostic decision-making for physicians and alleviating the workload on\nradiologists. While recent approaches focus on using unified pre-trained large\nmodels for multi-modal fusion like cross-modal Transformers, research on more\nefficient fusion methods remains relatively scarce within this discipline. In\nthis paper, we introduce a novel fusion model that integrates Orthogonality\nloss, Multi-head attention and Bilinear Attention Network (OMniBAN) to achieve\nhigh computational efficiency and strong performance without the need for\npre-training. We conduct comprehensive experiments and clarify aspects of how\nto enhance bilinear attention fusion to achieve performance comparable to that\nof large models. Experimental results show that OMniBAN outperforms traditional\nmodels on key MedVQA benchmarks while maintaining a lower computational cost,\nwhich indicates its potential for efficient clinical application in radiology\nand pathology image question answering.", "paper_summary_zh": "\u91ab\u7642\u8996\u89ba\u554f\u7b54 (MedVQA) \u5728\u96fb\u8166\u8996\u89ba\u548c\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u7684\u4ea4\u96c6\u4e2d\u7372\u5f97\u8d8a\u4f86\u8d8a\u591a\u7684\u95dc\u6ce8\u3002\u5b83\u80fd\u5920\u89e3\u8b80\u653e\u5c04\u5f71\u50cf\u4e26\u5c0d\u81e8\u5e8a\u8a62\u554f\u63d0\u4f9b\u7cbe\u78ba\u7b54\u6848\u7684\u80fd\u529b\uff0c\u4f7f MedVQA \u6210\u70ba\u652f\u63f4\u91ab\u5e2b\u8a3a\u65b7\u6c7a\u7b56\u548c\u6e1b\u8f15\u653e\u5c04\u79d1\u91ab\u5e2b\u5de5\u4f5c\u8ca0\u64d4\u7684\u5bf6\u8cb4\u5de5\u5177\u3002\u96d6\u7136\u6700\u8fd1\u7684\u65b9\u6cd5\u8457\u91cd\u65bc\u4f7f\u7528\u7d71\u4e00\u7684\u9810\u5148\u8a13\u7df4\u5927\u578b\u6a21\u578b\u9032\u884c\u591a\u6a21\u5f0f\u878d\u5408\uff0c\u4f8b\u5982\u8de8\u6a21\u614b Transformer\uff0c\u4f46\u5c0d\u65bc\u66f4\u6709\u6548\u7387\u7684\u878d\u5408\u65b9\u6cd5\u7684\u7814\u7a76\u5728\u6b64\u9818\u57df\u4e2d\u4ecd\u7136\u76f8\u5c0d\u7a00\u5c11\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u878d\u5408\u6a21\u578b\uff0c\u5b83\u6574\u5408\u4e86\u6b63\u4ea4\u640d\u5931\u3001\u591a\u982d\u6ce8\u610f\u529b\u548c\u96d9\u7dda\u6027\u6ce8\u610f\u529b\u7db2\u8def (OMniBAN)\uff0c\u4ee5\u5728\u4e0d\u9700\u8981\u9810\u5148\u8a13\u7df4\u7684\u60c5\u6cc1\u4e0b\u5be6\u73fe\u9ad8\u8a08\u7b97\u6548\u7387\u548c\u5f37\u5927\u6548\u80fd\u3002\u6211\u5011\u9032\u884c\u4e86\u5168\u9762\u7684\u5be6\u9a57\uff0c\u4e26\u91d0\u6e05\u4e86\u5982\u4f55\u589e\u5f37\u96d9\u7dda\u6027\u6ce8\u610f\u529b\u878d\u5408\u4ee5\u5be6\u73fe\u8207\u5927\u578b\u6a21\u578b\u76f8\u7576\u7684\u6548\u80fd\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cOMniBAN \u5728\u95dc\u9375\u7684 MedVQA \u57fa\u6e96\u4e0a\u512a\u65bc\u50b3\u7d71\u6a21\u578b\uff0c\u540c\u6642\u7dad\u6301\u8f03\u4f4e\u7684\u8a08\u7b97\u6210\u672c\uff0c\u9019\u8868\u660e\u5b83\u5728\u653e\u5c04\u5b78\u548c\u75c5\u7406\u5f71\u50cf\u554f\u7b54\u4e2d\u5177\u6709\u9ad8\u6548\u81e8\u5e8a\u61c9\u7528\u7684\u6f5b\u529b\u3002", "author": "Zhilin Zhang et.al.", "authors": "Zhilin Zhang, Jie Wang, Ruiqi Zhu, Xiaoliang Gong", "id": "2410.21000v1", "paper_url": "http://arxiv.org/abs/2410.21000v1", "repo": "null"}}