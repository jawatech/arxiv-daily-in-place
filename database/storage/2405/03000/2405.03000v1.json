{"2405.03000": {"publish_time": "2024-05-05", "title": "MedAdapter: Efficient Test-Time Adaptation of Large Language Models towards Medical Reasoning", "paper_summary": "Despite their improved capabilities in generation and reasoning, adapting\nlarge language models (LLMs) to the biomedical domain remains challenging due\nto their immense size and corporate privacy. In this work, we propose\nMedAdapter, a unified post-hoc adapter for test-time adaptation of LLMs towards\nbiomedical applications. Instead of fine-tuning the entire LLM, MedAdapter\neffectively adapts the original model by fine-tuning only a small BERT-sized\nadapter to rank candidate solutions generated by LLMs. Experiments demonstrate\nthat MedAdapter effectively adapts both white-box and black-box LLMs in\nbiomedical reasoning, achieving average performance improvements of 25.48% and\n11.31%, respectively, without requiring extensive computational resources or\nsharing data with third parties. MedAdapter also yields superior performance\nwhen combined with train-time adaptation, highlighting a flexible and\ncomplementary solution to existing adaptation methods. Faced with the\nchallenges of balancing model performance, computational resources, and data\nprivacy, MedAdapter provides an efficient, privacy-preserving, cost-effective,\nand transparent solution for adapting LLMs to the biomedical domain.", "paper_summary_zh": "", "author": "Wenqi Shi et.al.", "authors": "Wenqi Shi,Ran Xu,Yuchen Zhuang,Yue Yu,Hang Wu,Carl Yang,May D. Wang", "id": "2405.03000v1", "paper_url": "http://arxiv.org/abs/2405.03000v1", "repo": "null"}}