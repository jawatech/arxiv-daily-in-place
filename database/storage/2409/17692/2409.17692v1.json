{"2409.17692": {"publish_time": "2024-09-26", "title": "MIO: A Foundation Model on Multimodal Tokens", "paper_summary": "In this paper, we introduce MIO, a novel foundation model built on multimodal\ntokens, capable of understanding and generating speech, text, images, and\nvideos in an end-to-end, autoregressive manner. While the emergence of large\nlanguage models (LLMs) and multimodal large language models (MM-LLMs) propels\nadvancements in artificial general intelligence through their versatile\ncapabilities, they still lack true any-to-any understanding and generation.\nRecently, the release of GPT-4o has showcased the remarkable potential of\nany-to-any LLMs for complex real-world tasks, enabling omnidirectional input\nand output across images, speech, and text. However, it is closed-source and\ndoes not support the generation of multimodal interleaved sequences. To address\nthis gap, we present MIO, which is trained on a mixture of discrete tokens\nacross four modalities using causal multimodal modeling. MIO undergoes a\nfour-stage training process: (1) alignment pre-training, (2) interleaved\npre-training, (3) speech-enhanced pre-training, and (4) comprehensive\nsupervised fine-tuning on diverse textual, visual, and speech tasks. Our\nexperimental results indicate that MIO exhibits competitive, and in some cases\nsuperior, performance compared to previous dual-modal baselines, any-to-any\nmodel baselines, and even modality-specific baselines. Moreover, MIO\ndemonstrates advanced capabilities inherent to its any-to-any feature, such as\ninterleaved video-text generation, chain-of-visual-thought reasoning, visual\nguideline generation, instructional image editing, etc.", "paper_summary_zh": "<paragraph>\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 MIO\uff0c\u9019\u662f\u4e00\u500b\u5efa\u7acb\u5728\u591a\u6a21\u614b\u4ee3\u78bc\u7684\u65b0\u578b\u57fa\u790e\u6a21\u578b\uff0c\u80fd\u5920\u4ee5\u7aef\u5230\u7aef\u3001\u81ea\u8ff4\u6b78\u7684\u65b9\u5f0f\u7406\u89e3\u548c\u751f\u6210\u8a9e\u97f3\u3001\u6587\u5b57\u3001\u5716\u50cf\u548c\u5f71\u7247\u3002\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MM-LLM) \u7684\u51fa\u73fe\u900f\u904e\u5176\u591a\u529f\u80fd\u80fd\u529b\u63a8\u52d5\u4e86\u4eba\u5de5\u901a\u7528\u667a\u6167\u7684\u9032\u6b65\uff0c\u4f46\u5b83\u5011\u4ecd\u7136\u7f3a\u4e4f\u771f\u6b63\u7684\u4efb\u4f55\u5230\u4efb\u4f55\u7406\u89e3\u548c\u751f\u6210\u3002\u6700\u8fd1\uff0cGPT-4o \u7684\u767c\u5e03\u5c55\u793a\u4e86\u4efb\u4f55\u5230\u4efb\u4f55 LLM \u5728\u8907\u96dc\u7684\u771f\u5be6\u4e16\u754c\u4efb\u52d9\u4e2d\u7684\u986f\u8457\u6f5b\u529b\uff0c\u5be6\u73fe\u4e86\u8de8\u5716\u50cf\u3001\u8a9e\u97f3\u548c\u6587\u5b57\u7684\u5168\u65b9\u4f4d\u8f38\u5165\u548c\u8f38\u51fa\u3002\u7136\u800c\uff0c\u5b83\u662f\u9589\u6e90\u7684\uff0c\u4e0d\u652f\u6301\u751f\u6210\u591a\u6a21\u614b\u4ea4\u932f\u5e8f\u5217\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u63d0\u51fa\u4e86 MIO\uff0c\u5b83\u4f7f\u7528\u56e0\u679c\u591a\u6a21\u614b\u5efa\u6a21\u5728\u56db\u7a2e\u6a21\u614b\u4e2d\u8a13\u7df4\u96e2\u6563\u4ee3\u78bc\u7684\u6df7\u5408\u3002MIO \u7d93\u6b77\u4e86\u56db\u968e\u6bb5\u8a13\u7df4\u904e\u7a0b\uff1a(1) \u5c0d\u9f4a\u9810\u8a13\u7df4\uff0c(2) \u4ea4\u932f\u9810\u8a13\u7df4\uff0c(3) \u8a9e\u97f3\u589e\u5f37\u9810\u8a13\u7df4\uff0c\u4ee5\u53ca (4) \u5728\u4e0d\u540c\u7684\u6587\u672c\u3001\u8996\u89ba\u548c\u8a9e\u97f3\u4efb\u52d9\u4e0a\u9032\u884c\u7d9c\u5408\u76e3\u7763\u5fae\u8abf\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u8207\u5148\u524d\u7684\u96d9\u6a21\u614b\u57fa\u7dda\u3001\u4efb\u4f55\u5230\u4efb\u4f55\u6a21\u578b\u57fa\u7dda\uff0c\u751a\u81f3\u7279\u5b9a\u65bc\u6a21\u614b\u7684\u57fa\u7dda\u76f8\u6bd4\uff0cMIO \u8868\u73fe\u51fa\u5177\u6709\u7af6\u722d\u529b\uff0c\u5728\u67d0\u4e9b\u60c5\u6cc1\u4e0b\u8868\u73fe\u51fa\u66f4\u512a\u8d8a\u7684\u6548\u80fd\u3002\u6b64\u5916\uff0cMIO \u5c55\u793a\u4e86\u5176\u4efb\u4f55\u5230\u4efb\u4f55\u529f\u80fd\u56fa\u6709\u7684\u5148\u9032\u80fd\u529b\uff0c\u4f8b\u5982\u4ea4\u932f\u8996\u8a0a\u6587\u5b57\u751f\u6210\u3001\u8996\u89ba\u601d\u8003\u63a8\u7406\u93c8\u3001\u8996\u89ba\u6e96\u5247\u751f\u6210\u3001\u6559\u5b78\u5716\u50cf\u7de8\u8f2f\u7b49\u3002</paragraph>", "author": "Zekun Wang et.al.", "authors": "Zekun Wang, King Zhu, Chunpu Xu, Wangchunshu Zhou, Jiaheng Liu, Yibo Zhang, Jiashuo Wang, Ning Shi, Siyu Li, Yizhi Li, Haoran Que, Zhaoxiang Zhang, Yuanxing Zhang, Ge Zhang, Ke Xu, Jie Fu, Wenhao Huang", "id": "2409.17692v1", "paper_url": "http://arxiv.org/abs/2409.17692v1", "repo": "null"}}