{"2406.12259": {"publish_time": "2024-06-18", "title": "Adversarial Attacks on Large Language Models in Medicine", "paper_summary": "The integration of Large Language Models (LLMs) into healthcare applications\noffers promising advancements in medical diagnostics, treatment\nrecommendations, and patient care. However, the susceptibility of LLMs to\nadversarial attacks poses a significant threat, potentially leading to harmful\noutcomes in delicate medical contexts. This study investigates the\nvulnerability of LLMs to two types of adversarial attacks in three medical\ntasks. Utilizing real-world patient data, we demonstrate that both open-source\nand proprietary LLMs are susceptible to manipulation across multiple tasks.\nThis research further reveals that domain-specific tasks demand more\nadversarial data in model fine-tuning than general domain tasks for effective\nattack execution, especially for more capable models. We discover that while\nintegrating adversarial data does not markedly degrade overall model\nperformance on medical benchmarks, it does lead to noticeable shifts in\nfine-tuned model weights, suggesting a potential pathway for detecting and\ncountering model attacks. This research highlights the urgent need for robust\nsecurity measures and the development of defensive mechanisms to safeguard LLMs\nin medical applications, to ensure their safe and effective deployment in\nhealthcare settings.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6574\u5408\u5230\u91ab\u7642\u4fdd\u5065\u61c9\u7528\u7a0b\u5f0f\u4e2d\uff0c\u5728\u91ab\u7642\u8a3a\u65b7\u3001\u6cbb\u7642\u5efa\u8b70\u548c\u75c5\u4eba\u7167\u8b77\u65b9\u9762\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u9032\u5c55\u3002\u7136\u800c\uff0cLLM \u5c0d\u5c0d\u6297\u6027\u653b\u64ca\u7684\u654f\u611f\u6027\u69cb\u6210\u91cd\u5927\u5a01\u8105\uff0c\u53ef\u80fd\u5c0e\u81f4\u5728\u5fae\u5999\u7684\u91ab\u7642\u74b0\u5883\u4e2d\u9020\u6210\u6709\u5bb3\u7684\u5f8c\u679c\u3002\u672c\u7814\u7a76\u8abf\u67e5\u4e86 LLM \u5728\u4e09\u9805\u91ab\u7642\u4efb\u52d9\u4e2d\u5c0d\u5169\u7a2e\u5c0d\u6297\u6027\u653b\u64ca\u7684\u8106\u5f31\u6027\u3002\u5229\u7528\u771f\u5be6\u4e16\u754c\u7684\u75c5\u4eba\u8cc7\u6599\uff0c\u6211\u5011\u8b49\u660e\u958b\u6e90\u548c\u5c08\u6709 LLM \u90fd\u5bb9\u6613\u53d7\u5230\u591a\u9805\u4efb\u52d9\u7684\u64cd\u7e31\u3002\u9019\u9805\u7814\u7a76\u9032\u4e00\u6b65\u63ed\u793a\uff0c\u8207\u4e00\u822c\u9818\u57df\u4efb\u52d9\u76f8\u6bd4\uff0c\u7279\u5b9a\u9818\u57df\u4efb\u52d9\u9700\u8981\u5728\u6a21\u578b\u5fae\u8abf\u4e2d\u66f4\u591a\u5c0d\u6297\u6027\u8cc7\u6599\u624d\u80fd\u6709\u6548\u57f7\u884c\u653b\u64ca\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u529f\u80fd\u66f4\u5f37\u5927\u7684\u6a21\u578b\u3002\u6211\u5011\u767c\u73fe\uff0c\u96d6\u7136\u6574\u5408\u5c0d\u6297\u6027\u8cc7\u6599\u4e26\u4e0d\u6703\u986f\u8457\u964d\u4f4e\u91ab\u7642\u57fa\u6e96\u4e0a\u7684\u6574\u9ad4\u6a21\u578b\u6548\u80fd\uff0c\u4f46\u5b83\u78ba\u5be6\u6703\u5c0e\u81f4\u5fae\u8abf\u6a21\u578b\u6b0a\u91cd\u767c\u751f\u660e\u986f\u7684\u8f49\u8b8a\uff0c\u9019\u8868\u660e\u6709\u6f5b\u5728\u9014\u5f91\u53ef\u4ee5\u5075\u6e2c\u548c\u53cd\u5236\u6a21\u578b\u653b\u64ca\u3002\u672c\u7814\u7a76\u5f37\u8abf\u4e86\u5c0d\u5065\u5168\u5b89\u5168\u63aa\u65bd\u548c\u9632\u79a6\u6a5f\u5236\u958b\u767c\u7684\u8feb\u5207\u9700\u6c42\uff0c\u4ee5\u4fdd\u8b77\u91ab\u7642\u61c9\u7528\u7a0b\u5f0f\u4e2d\u7684 LLM\uff0c\u78ba\u4fdd\u5b83\u5011\u5728\u91ab\u7642\u4fdd\u5065\u74b0\u5883\u4e2d\u5b89\u5168\u6709\u6548\u5730\u90e8\u7f72\u3002", "author": "Yifan Yang et.al.", "authors": "Yifan Yang, Qiao Jin, Furong Huang, Zhiyong Lu", "id": "2406.12259v1", "paper_url": "http://arxiv.org/abs/2406.12259v1", "repo": "null"}}