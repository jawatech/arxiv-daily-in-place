
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-29**|**Task Vectors are Cross-Modal**|Grace Luo et.al.|[2410.22330v1](http://arxiv.org/abs/2410.22330v1)|null|
|**2024-10-29**|**Understanding Synthetic Context Extension via Retrieval Heads**|Xinyu Zhao et.al.|[2410.22316v1](http://arxiv.org/abs/2410.22316v1)|null|
|**2024-10-29**|**Natural Language Inference Improves Compositionality in Vision-Language Models**|Paola Cascante-Bonilla et.al.|[2410.22315v1](http://arxiv.org/abs/2410.22315v1)|null|
|**2024-10-29**|**Effective Guidance for Model Attention with Simple Yes-no Annotations**|Seongmin Lee et.al.|[2410.22312v1](http://arxiv.org/abs/2410.22312v1)|null|
|**2024-10-29**|**SVIP: Towards Verifiable Inference of Open-source Large Language Models**|Yifan Sun et.al.|[2410.22307v1](http://arxiv.org/abs/2410.22307v1)|null|
|**2024-10-29**|**Flow-DPO: Improving LLM Mathematical Reasoning through Online Multi-Agent Learning**|Yihe Deng et.al.|[2410.22304v1](http://arxiv.org/abs/2410.22304v1)|null|
|**2024-10-29**|**$\mathsf{OPA}$: One-shot Private Aggregation with Single Client Interaction and its Applications to Federated Learning**|Harish Karthikeyan et.al.|[2410.22303v1](http://arxiv.org/abs/2410.22303v1)|null|
|**2024-10-29**|**From melodic note sequences to pitches using word2vec**|Daniel Defays et.al.|[2410.22285v1](http://arxiv.org/abs/2410.22285v1)|null|
|**2024-10-29**|**Leveraging Reverberation and Visual Depth Cues for Sound Event Localization and Detection with Distance Estimation**|Davide Berghi et.al.|[2410.22271v1](http://arxiv.org/abs/2410.22271v1)|null|
|**2024-10-29**|**Fourier Head: Helping Large Language Models Learn Complex Probability Distributions**|Nate Gillman et.al.|[2410.22269v1](http://arxiv.org/abs/2410.22269v1)|null|
|**2024-10-29**|**FactBench: A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation**|Farima Fatahi Bayat et.al.|[2410.22257v1](http://arxiv.org/abs/2410.22257v1)|null|
|**2024-10-29**|**DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers**|Rakesh R. Menon et.al.|[2410.22239v1](http://arxiv.org/abs/2410.22239v1)|null|
|**2024-10-29**|**ContextIQ: A Multimodal Expert-Based Video Retrieval System for Contextual Advertising**|Ashutosh Chaubey et.al.|[2410.22233v1](http://arxiv.org/abs/2410.22233v1)|[link](https://github.com/WACV2025Submission/ContextIQ)|
|**2024-10-29**|**Cora: Accelerating Stateful Network Applications with SmartNICs**|Shaoke Xi et.al.|[2410.22229v1](http://arxiv.org/abs/2410.22229v1)|null|
|**2024-10-29**|**ProMQA: Question Answering Dataset for Multimodal Procedural Activity Understanding**|Kimihiro Hasegawa et.al.|[2410.22211v1](http://arxiv.org/abs/2410.22211v1)|[link](https://github.com/kimihiroh/promqa)|
|**2024-10-29**|**Drone Acoustic Analysis for Predicting Psychoacoustic Annoyance via Artificial Neural Networks**|Andrea Vaiuso et.al.|[2410.22208v1](http://arxiv.org/abs/2410.22208v1)|null|
|**2024-10-29**|**Democratizing Reward Design for Personal and Representative Value-Alignment**|Carter Blair et.al.|[2410.22203v1](http://arxiv.org/abs/2410.22203v1)|null|
|**2024-10-29**|**Class-Aware Contrastive Optimization for Imbalanced Text Classification**|Grigorii Khvatskii et.al.|[2410.22197v1](http://arxiv.org/abs/2410.22197v1)|null|
|**2024-10-29**|**ADAM: An Embodied Causal Agent in Open-World Environments**|Shu Yu et.al.|[2410.22194v1](http://arxiv.org/abs/2410.22194v1)|null|
|**2024-10-29**|**Multi-Level Feature Distillation of Joint Teachers Trained on Distinct Image Datasets**|Adrian Iordache et.al.|[2410.22184v1](http://arxiv.org/abs/2410.22184v1)|[link](https://github.com/adrianiordache/mlfd)|
|**2024-10-29**|**Natural Language Processing for Analyzing Electronic Health Records and Clinical Notes in Cancer Research: A Review**|Muhammad Bilal et.al.|[2410.22180v1](http://arxiv.org/abs/2410.22180v1)|null|
|**2024-10-29**|**Very Attentive Tacotron: Robust and Unbounded Length Generalization in Autoregressive Transformer-Based Text-to-Speech**|Eric Battenberg et.al.|[2410.22179v1](http://arxiv.org/abs/2410.22179v1)|null|
|**2024-10-29**|**Analyzing Multimodal Interaction Strategies for LLM-Assisted Manipulation of 3D Scenes**|Junlong Chen et.al.|[2410.22177v1](http://arxiv.org/abs/2410.22177v1)|null|
|**2024-10-29**|**Benchmarking LLM Guardrails in Handling Multilingual Toxicity**|Yahan Yang et.al.|[2410.22153v1](http://arxiv.org/abs/2410.22153v1)|null|
|**2024-10-29**|**Standardization Trends on Safety and Trustworthiness Technology for Advanced AI**|Jonghong Jeon et.al.|[2410.22151v1](http://arxiv.org/abs/2410.22151v1)|null|
|**2024-10-29**|**AmpleGCG-Plus: A Strong Generative Model of Adversarial Suffixes to Jailbreak LLMs with Higher Success Rates in Fewer Attempts**|Vishal Kumar et.al.|[2410.22143v1](http://arxiv.org/abs/2410.22143v1)|null|
|**2024-10-29**|**ProMoE: Fast MoE-based LLM Serving using Proactive Caching**|Xiaoniu Song et.al.|[2410.22134v1](http://arxiv.org/abs/2410.22134v1)|null|
|**2024-10-29**|**Lightweight Frequency Masker for Cross-Domain Few-Shot Semantic Segmentation**|Jintao Tong et.al.|[2410.22135v1](http://arxiv.org/abs/2410.22135v1)|null|
|**2024-10-29**|**Improving Performance of Commercially Available AI Products in a Multi-Agent Configuration**|Cory Hymel et.al.|[2410.22129v1](http://arxiv.org/abs/2410.22129v1)|null|
|**2024-10-29**|**RankUp: Boosting Semi-Supervised Regression with an Auxiliary Ranking Classifier**|Pin-Yen Huang et.al.|[2410.22124v1](http://arxiv.org/abs/2410.22124v1)|[link](https://github.com/pm25/semi-supervised-regression)|
|**2024-10-29**|**The Impact of Inference Acceleration Strategies on Bias of LLMs**|Elisabeth Kirsten et.al.|[2410.22118v1](http://arxiv.org/abs/2410.22118v1)|null|
|**2024-10-29**|**Policy Gradient for Robust Markov Decision Processes**|Qiuhao Wang et.al.|[2410.22114v1](http://arxiv.org/abs/2410.22114v1)|[link](https://github.com/JerrisonWang/JMLR-DRPMD)|
|**2024-10-29**|**Protecting Privacy in Multimodal Large Language Models with MLLMU-Bench**|Zheyuan Liu et.al.|[2410.22108v1](http://arxiv.org/abs/2410.22108v1)|[link](https://github.com/franciscoliu/MLLMU-Bench)|
|**2024-10-29**|**Joint Extraction and Classification of Danish Competences for Job Matching**|Qiuchi Li et.al.|[2410.22103v1](http://arxiv.org/abs/2410.22103v1)|null|
|**2024-10-29**|**Hyperspectral Imaging-Based Perception in Autonomous Driving Scenarios: Benchmarking Baseline Semantic Segmentation Models**|Imad Ali Shah et.al.|[2410.22101v1](http://arxiv.org/abs/2410.22101v1)|null|
|**2024-10-29**|**TractShapeNet: Efficient Multi-Shape Learning with 3D Tractography Point Clouds**|Yui Lo et.al.|[2410.22099v1](http://arxiv.org/abs/2410.22099v1)|null|
|**2024-10-29**|**Unlearning as multi-task optimization: A normalized gradient difference approach with an adaptive learning rate**|Zhiqi Bu et.al.|[2410.22086v1](http://arxiv.org/abs/2410.22086v1)|null|
|**2024-10-29**|**Choosy Babies Need One Coach: Inducing Mode-Seeking Behavior in BabyLlama with Reverse KL Divergence**|Shaozhen Shi et.al.|[2410.22081v1](http://arxiv.org/abs/2410.22081v1)|null|
|**2024-10-29**|**Mapping the Neuro-Symbolic AI Landscape by Architectures: A Handbook on Augmenting Deep Learning Through Symbolic Reasoning**|Jonathan Feldstein et.al.|[2410.22077v1](http://arxiv.org/abs/2410.22077v1)|null|
|**2024-10-29**|**Distinguishing Ignorance from Error in LLM Hallucinations**|Adi Simhi et.al.|[2410.22071v1](http://arxiv.org/abs/2410.22071v1)|[link](https://github.com/technion-cs-nlp/hallucination-mitigation)|
|**2024-10-29**|**Sing it, Narrate it: Quality Musical Lyrics Translation**|Zhuorui Ye et.al.|[2410.22066v1](http://arxiv.org/abs/2410.22066v1)|null|
|**2024-10-29**|**Are VLMs Really Blind**|Ayush Singh et.al.|[2410.22029v1](http://arxiv.org/abs/2410.22029v1)|[link](https://github.com/vlgiitr/Are-VLMs-Really-Blind)|
|**2024-10-29**|**Path-based summary explanations for graph recommenders -- extended version**|Danae Pla Karidi et.al.|[2410.22020v1](http://arxiv.org/abs/2410.22020v1)|[link](https://github.com/xsum-rec/xsum)|
|**2024-10-29**|**Modeling Temporal Positive and Negative Excitation for Sequential Recommendation**|Chengkai Huang et.al.|[2410.22013v1](http://arxiv.org/abs/2410.22013v1)|null|
|**2024-10-29**|**From Explicit Rules to Implicit Reasoning in an Interpretable Violence Monitoring System**|Wen-Dong Jiang et.al.|[2410.21991v1](http://arxiv.org/abs/2410.21991v1)|null|
|**2024-10-29**|**Not All Languages are Equal: Insights into Multilingual Retrieval-Augmented Generation**|Suhang Wu et.al.|[2410.21970v1](http://arxiv.org/abs/2410.21970v1)|[link](https://github.com/H-shw/futurepedia)|
|**2024-10-29**|**Automated Vulnerability Detection Using Deep Learning Technique**|Guan-Yan Yang et.al.|[2410.21968v1](http://arxiv.org/abs/2410.21968v1)|null|
|**2024-10-29**|**Dual Conditional Diffusion Models for Sequential Recommendation**|Hongtao Huang et.al.|[2410.21967v1](http://arxiv.org/abs/2410.21967v1)|null|
|**2024-10-29**|**SG-Bench: Evaluating LLM Safety Generalization Across Diverse Tasks and Prompt Types**|Yutao Mou et.al.|[2410.21965v1](http://arxiv.org/abs/2410.21965v1)|[link](https://github.com/MurrayTom/SG-Bench)|
|**2024-10-29**|**Beyond Text: Optimizing RAG with Multimodal Inputs for Industrial Applications**|Monica Riedler et.al.|[2410.21943v1](http://arxiv.org/abs/2410.21943v1)|[link](https://github.com/riedlerm/multimodal_rag_for_industry)|
|**2024-10-29**|**Benchmarking OpenAI o1 in Cyber Security**|Dan Ristea et.al.|[2410.21939v1](http://arxiv.org/abs/2410.21939v1)|null|
|**2024-10-29**|**LogSHIELD: A Graph-based Real-time Anomaly Detection Framework using Frequency Analysis**|Krishna Chandra Roy et.al.|[2410.21936v1](http://arxiv.org/abs/2410.21936v1)|null|
|**2024-10-29**|**Reliable Semantic Understanding for Real World Zero-shot Object Goal Navigation**|Halil Utku Unlu et.al.|[2410.21926v1](http://arxiv.org/abs/2410.21926v1)|null|
|**2024-10-29**|**SceneGenAgent: Precise Industrial Scene Generation with Coding Agent**|Xiao Xia et.al.|[2410.21909v1](http://arxiv.org/abs/2410.21909v1)|[link](https://github.com/thudm/scenegenagent)|
|**2024-10-29**|**Evaluating K-Fold Cross Validation for Transformer Based Symbolic Regression Models**|Kaustubh Kislay et.al.|[2410.21896v1](http://arxiv.org/abs/2410.21896v1)|null|
|**2024-10-29**|**Bayesian Optimization for Hyperparameters Tuning in Neural Networks**|Gabriele Onorato et.al.|[2410.21886v1](http://arxiv.org/abs/2410.21886v1)|null|
|**2024-10-29**|**Building Altruistic and Moral AI Agent with Brain-inspired Affective Empathy Mechanisms**|Feifei Zhao et.al.|[2410.21882v1](http://arxiv.org/abs/2410.21882v1)|null|
|**2024-10-29**|**Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning**|Yinyi Lai et.al.|[2410.21872v1](http://arxiv.org/abs/2410.21872v1)|null|
|**2024-10-29**|**Cross-Entropy Is All You Need To Invert the Data Generating Process**|Patrik Reizinger et.al.|[2410.21869v1](http://arxiv.org/abs/2410.21869v1)|null|
|**2024-10-29**|**Improving In-Context Learning with Small Language Model Ensembles**|M. Mehdi Mojarradi et.al.|[2410.21868v1](http://arxiv.org/abs/2410.21868v1)|[link](https://github.com/mehdimojarradi/Ensemble-SuperICL)|
|**2024-10-29**|**Learning Infinitesimal Generators of Continuous Symmetries from Data**|Gyeonghoon Ko et.al.|[2410.21853v1](http://arxiv.org/abs/2410.21853v1)|null|
|**2024-10-29**|**Joint Beamforming and Speaker-Attributed ASR for Real Distant-Microphone Meeting Transcription**|Can Cui et.al.|[2410.21849v1](http://arxiv.org/abs/2410.21849v1)|null|
|**2024-10-29**|**Diffusion as Reasoning: Enhancing Object Goal Navigation with LLM-Biased Diffusion Model**|Yiming Ji et.al.|[2410.21842v1](http://arxiv.org/abs/2410.21842v1)|null|
|**2024-10-29**|**Self-Preference Bias in LLM-as-a-Judge**|Koki Wataoka et.al.|[2410.21819v1](http://arxiv.org/abs/2410.21819v1)|null|
|**2024-10-29**|**Gnothi Seauton: Empowering Faithful Self-Interpretability in Black-Box Models**|Shaobo Wang et.al.|[2410.21815v1](http://arxiv.org/abs/2410.21815v1)|null|
|**2024-10-29**|**A Fresh Look at Generalized Category Discovery through Non-negative Matrix Factorization**|Zhong Ji et.al.|[2410.21807v2](http://arxiv.org/abs/2410.21807v2)|null|
|**2024-10-29**|**SimSiam Naming Game: A Unified Approach for Representation Learning and Emergent Communication**|Nguyen Le Hoang et.al.|[2410.21803v1](http://arxiv.org/abs/2410.21803v1)|null|
|**2024-10-29**|**Text-Guided Attention is All You Need for Zero-Shot Robustness in Vision-Language Models**|Lu Yu et.al.|[2410.21802v2](http://arxiv.org/abs/2410.21802v2)|[link](https://github.com/zhyblue424/tga-zsr)|
|**2024-10-29**|**Inverse Attention Agent for Multi-Agent System**|Qian Long et.al.|[2410.21794v1](http://arxiv.org/abs/2410.21794v1)|null|
|**2024-10-29**|**Enhancing Adversarial Attacks through Chain of Thought**|Jingbo Su et.al.|[2410.21791v1](http://arxiv.org/abs/2410.21791v1)|[link](https://github.com/sujingbo0217/cs222w24-llm-attack)|
|**2024-10-29**|**MARCO: Multi-Agent Real-time Chat Orchestration**|Anubhav Shrimal et.al.|[2410.21784v1](http://arxiv.org/abs/2410.21784v1)|null|
|**2024-10-29**|**Leveraging LLMs for Hypothetical Deduction in Logical Inference: A Neuro-Symbolic Approach**|Qingchuan Li et.al.|[2410.21779v1](http://arxiv.org/abs/2410.21779v1)|[link](https://github.com/wufeiwuwoshihua/nshy)|
|**2024-10-29**|**RELATE: A Modern Processing Platform for Romanian Language**|Vasile Păiş et.al.|[2410.21778v1](http://arxiv.org/abs/2410.21778v1)|[link](https://github.com/racai-ai/relate)|
|**2024-10-29**|**Learning and Unlearning of Fabricated Knowledge in Language Models**|Chen Sun et.al.|[2410.21750v1](http://arxiv.org/abs/2410.21750v1)|null|
|**2024-10-29**|**Enhancing Financial Question Answering with a Multi-Agent Reflection Framework**|Sorouralsadat Fatemi et.al.|[2410.21741v1](http://arxiv.org/abs/2410.21741v1)|null|
|**2024-10-29**|**Efficient Reprogramming of Memristive Crossbars for DNNs: Weight Sorting and Bit Stucking**|Matheus Farias et.al.|[2410.21730v1](http://arxiv.org/abs/2410.21730v1)|null|
|**2024-10-29**|**Let's Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models**|Kangyang Luo et.al.|[2410.21728v1](http://arxiv.org/abs/2410.21728v1)|null|
|**2024-10-29**|**On the Statistical Complexity of Estimating VENDI Scores from Empirical Data**|Azim Ospanov et.al.|[2410.21719v1](http://arxiv.org/abs/2410.21719v1)|null|
|**2024-10-29**|**Generating Realistic Tabular Data with Large Language Models**|Dang Nguyen et.al.|[2410.21717v1](http://arxiv.org/abs/2410.21717v1)|null|
|**2024-10-29**|**A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution**|Zhengmian Hu et.al.|[2410.21716v1](http://arxiv.org/abs/2410.21716v1)|null|
|**2024-10-29**|**AdaptGCD: Multi-Expert Adapter Tuning for Generalized Category Discovery**|Yuxun Qu et.al.|[2410.21705v1](http://arxiv.org/abs/2410.21705v1)|null|
|**2024-10-29**|**CFSafety: Comprehensive Fine-grained Safety Assessment for LLMs**|Zhihao Liu et.al.|[2410.21695v1](http://arxiv.org/abs/2410.21695v1)|null|
|**2024-10-29**|**How Does Critical Batch Size Scale in Pre-training?**|Hanlin Zhang et.al.|[2410.21676v1](http://arxiv.org/abs/2410.21676v1)|null|
|**2024-10-29**|**BF-Meta: Secure Blockchain-enhanced Privacy-preserving Federated Learning for Metaverse**|Wenbo Liu et.al.|[2410.21675v1](http://arxiv.org/abs/2410.21675v1)|null|
|**2024-10-29**|**Knowledge-Guided Prompt Learning for Request Quality Assurance in Public Code Review**|Lin Li et.al.|[2410.21673v1](http://arxiv.org/abs/2410.21673v1)|[link](https://github.com/wut-idea/kp-pcr)|
|**2024-10-29**|**Sequential choice in ordered bundles**|Rajeev Kohli et.al.|[2410.21670v1](http://arxiv.org/abs/2410.21670v1)|null|
|**2024-10-29**|**$f$-PO: Generalizing Preference Optimization with $f$-divergence Minimization**|Jiaqi Han et.al.|[2410.21662v1](http://arxiv.org/abs/2410.21662v1)|null|
|**2024-10-29**|**PACER: Physics Informed Uncertainty Aware Climate Emulator**|Hira Saleem et.al.|[2410.21657v2](http://arxiv.org/abs/2410.21657v2)|null|
|**2024-10-29**|**Can Language Models Replace Programmers? REPOCOD Says 'Not Yet'**|Shanchao Liang et.al.|[2410.21647v1](http://arxiv.org/abs/2410.21647v1)|null|
|**2024-10-29**|**RDSinger: Reference-based Diffusion Network for Singing Voice Synthesis**|Kehan Sui et.al.|[2410.21641v1](http://arxiv.org/abs/2410.21641v1)|null|
|**2024-10-29**|**A Tutorial on Clinical Speech AI Development: From Data Collection to Model Validation**|Si-Ioi Ng et.al.|[2410.21640v1](http://arxiv.org/abs/2410.21640v1)|null|
|**2024-10-29**|**Are Paraphrases Generated by Large Language Models Invertible?**|Rafael Rivera Soto et.al.|[2410.21637v1](http://arxiv.org/abs/2410.21637v1)|null|
|**2024-10-29**|**MCPDial: A Minecraft Persona-driven Dialogue Dataset**|Seyed Hossein Alavi et.al.|[2410.21627v1](http://arxiv.org/abs/2410.21627v1)|[link](https://github.com/salavi/MCPDial-A-Minecraft-Persona-driven-Dialogue-Dataset)|
|**2024-10-28**|**Asynchronous Tool Usage for Real-Time Agents**|Antonio A. Ginart et.al.|[2410.21620v1](http://arxiv.org/abs/2410.21620v1)|null|
|**2024-10-28**|**Identifying Selections for Unsupervised Subtask Discovery**|Yiwen Qiu et.al.|[2410.21616v1](http://arxiv.org/abs/2410.21616v1)|null|
|**2024-10-28**|**Reducing the Scope of Language Models with Circuit Breakers**|David Yunis et.al.|[2410.21597v1](http://arxiv.org/abs/2410.21597v1)|null|
|**2024-10-28**|**Can Large Language Models Replace Data Scientists in Clinical Research?**|Zifeng Wang et.al.|[2410.21591v1](http://arxiv.org/abs/2410.21591v1)|null|
|**2024-10-28**|**ImageNet-RIB Benchmark: Large Pre-Training Datasets Don't Guarantee Robustness after Fine-Tuning**|Jaedong Hwang et.al.|[2410.21582v1](http://arxiv.org/abs/2410.21582v1)|null|
|**2024-10-28**|**A Generative Model Based Honeypot for Industrial OPC UA Communication**|Olaf Sassnick et.al.|[2410.21574v1](http://arxiv.org/abs/2410.21574v1)|[link](https://github.com/JRC-ISIA/paper-2024-eurocast-honeypot)|
|**2024-10-28**|**Thank You, Stingray: Multilingual Large Language Models Can Not (Yet) Disambiguate Cross-Lingual Word Sense**|Samuel Cahyawijaya et.al.|[2410.21573v2](http://arxiv.org/abs/2410.21573v2)|[link](https://github.com/SamuelCahyawijaya/stingraybench)|

#### Abstracts
##### **Task Vectors are Cross-Modal**
2410.22330v1 by Grace Luo, Trevor Darrell, Amir Bar

We investigate the internal representations of vision-and-language models
(VLMs) and how they encode task representations. We consider tasks specified
through examples or instructions, using either text or image inputs.
Surprisingly, we find that conceptually similar tasks are mapped to similar
task vector representations, regardless of how they are specified. Our findings
suggest that to output answers, tokens in VLMs undergo three distinct phases:
input, task, and answer, a process which is consistent across different
modalities and specifications. The task vectors we identify in VLMs are general
enough to be derived in one modality (e.g., text) and transferred to another
(e.g., image). Additionally, we find that ensembling exemplar and instruction
based task vectors produce better task representations. Taken together, these
insights shed light on the underlying mechanisms of VLMs, particularly their
ability to represent tasks in a shared manner across different modalities and
task specifications. Project page:
https://task-vectors-are-cross-modal.github.io.

摘要：我們探討視覺語言模型 (VLM) 的內部表示，以及它們如何編碼任務表示。我們考慮通過範例或說明指定的任務，使用文字或影像輸入。令人驚訝的是，我們發現概念上相似的任務會被映射到相似的任務向量表示，而不管它們是如何指定的。我們的發現表明，為了輸出答案，VLM 中的符號會經歷三個不同的階段：輸入、任務和答案，這個過程在不同的模式和規範中是一致的。我們在 VLM 中識別的任務向量夠通用，可以在一個模式（例如文字）中衍生，並傳輸到另一個模式（例如影像）。此外，我們發現範例和說明的集合任務向量產生更好的任務表示。綜觀而言，這些見解闡明了 VLM 的底層機制，特別是它們以共享方式表示不同模式和任務規範中任務的能力。專案頁面：
https://task-vectors-are-cross-modal.github.io。

##### **Understanding Synthetic Context Extension via Retrieval Heads**
2410.22316v1 by Xinyu Zhao, Fangcong Yin, Greg Durrett

Long-context LLMs are increasingly in demand for applications such as
retrieval-augmented generation. To defray the cost of pretraining LLMs over
long contexts, recent work takes an approach of synthetic context extension:
fine-tuning LLMs with synthetically generated long-context data in a
post-training stage. However, it remains unclear how and why this synthetic
context extension imparts abilities for downstream long-context tasks. In this
paper, we investigate fine-tuning on synthetic data for three long-context
tasks that require retrieval and reasoning. We vary the realism of "needle"
concepts to be retrieved and diversity of the surrounding "haystack" context,
from using LLMs to construct synthetic documents to using templated relations
and creating symbolic datasets. We find that models trained on synthetic data
fall short of the real data, but surprisingly, the mismatch can be interpreted
and even predicted in terms of a special set of attention heads that are
responsible for retrieval over long context: retrieval heads (Wu et al., 2024).
The retrieval heads learned on synthetic data are mostly subsets of the
retrieval heads learned on real data, and there is a strong correlation between
the recall of heads learned and the downstream performance of a model.
Furthermore, with attention knockout and activation patching, we
mechanistically show that retrieval heads are necessary and explain model
performance, although they are not totally sufficient. Our results shed light
on how to interpret synthetic data fine-tuning performance and how to approach
creating better data for learning real-world capabilities over long contexts.

摘要：長語境 LLM 對檢索增強生成等應用程式需求日增。為了降低 LLM 在長語境上進行預訓練的成本，最近的研究採用合成語境延伸方法：在後訓練階段使用合成產生的長語境資料微調 LLM。然而，合成語境延伸如何以及為何賦予下游長語境任務能力，仍不清楚。在本文中，我們探討針對三個需要檢索和推理的長語境任務進行合成資料微調。我們改變了要檢索的「針」概念的真實性，以及周圍「乾草堆」語境的差異性，從使用 LLM 建構合成文件到使用範本關係並建立符號資料集。我們發現，在合成資料上訓練的模型不如真實資料，但令人驚訝的是，這種不匹配可以用一組特殊的注意力頭來詮釋，甚至預測，這些注意力頭負責在長語境中進行檢索：檢索頭（Wu 等人，2024）。在合成資料上學習的檢索頭大多是真實資料上學習的檢索頭的子集，並且學習的頭的召回率與模型的下游效能之間存在很強的關聯性。此外，透過注意力剔除和啟用修補，我們機械性地表明檢索頭是必要的，並解釋模型效能，儘管它們並非完全足夠。我們的結果闡明了如何詮釋合成資料微調效能，以及如何著手建立更好的資料，以學習在長語境中學習真實世界的能力。

##### **Natural Language Inference Improves Compositionality in Vision-Language Models**
2410.22315v1 by Paola Cascante-Bonilla, Yu Hou, Yang Trista Cao, Hal Daumé III, Rachel Rudinger

Compositional reasoning in Vision-Language Models (VLMs) remains challenging
as these models often struggle to relate objects, attributes, and spatial
relationships. Recent methods aim to address these limitations by relying on
the semantics of the textual description, using Large Language Models (LLMs) to
break them down into subsets of questions and answers. However, these methods
primarily operate on the surface level, failing to incorporate deeper lexical
understanding while introducing incorrect assumptions generated by the LLM. In
response to these issues, we present Caption Expansion with Contradictions and
Entailments (CECE), a principled approach that leverages Natural Language
Inference (NLI) to generate entailments and contradictions from a given
premise. CECE produces lexically diverse sentences while maintaining their core
meaning. Through extensive experiments, we show that CECE enhances
interpretability and reduces overreliance on biased or superficial features. By
balancing CECE along the original premise, we achieve significant improvements
over previous methods without requiring additional fine-tuning, producing
state-of-the-art results on benchmarks that score agreement with human
judgments for image-text alignment, and achieving an increase in performance on
Winoground of +19.2% (group score) and +12.9% on EqBen (group score) over the
best prior work (finetuned with targeted data).

摘要：在視覺語言模型（VLM）中，組合推理仍然具有挑戰性，因為這些模型常常難以關聯物件、屬性以及空間關係。最近的方法旨在透過依賴文字描述的語意，使用大型語言模型（LLM）將其分解成子集的問題和答案，來解決這些限制。然而，這些方法主要運作於表面層級，未能整合更深入的詞彙理解，同時引入了 LLM 所產生的不正確假設。為了回應這些問題，我們提出了帶有矛盾和蘊涵的標題擴充（CECE），這是一種運用自然語言推論（NLI）從既定前提產生蘊涵和矛盾的原則性方法。CECE 產生詞彙多樣化的句子，同時維持其核心意義。透過廣泛的實驗，我們證明 CECE 增強了可解釋性，並減少了對有偏差或表面特徵的過度依賴。透過在原始前提中平衡 CECE，我們在不需額外微調的情況下，獲得了優於先前方法的顯著改進，在與人類判斷一致的圖像文字對齊基準上產生了最先進的結果，並且在 Winoground 上的效能提升了 +19.2%（群組分數），在 EqBen 上提升了 +12.9%（群組分數），超越了最好的先前工作（使用目標資料進行微調）。

##### **Effective Guidance for Model Attention with Simple Yes-no Annotations**
2410.22312v1 by Seongmin Lee, Ali Payani, Duen Horng, Chau

Modern deep learning models often make predictions by focusing on irrelevant
areas, leading to biased performance and limited generalization. Existing
methods aimed at rectifying model attention require explicit labels for
irrelevant areas or complex pixel-wise ground truth attention maps. We present
CRAYON (Correcting Reasoning with Annotations of Yes Or No), offering
effective, scalable, and practical solutions to rectify model attention using
simple yes-no annotations. CRAYON empowers classical and modern model
interpretation techniques to identify and guide model reasoning:
CRAYON-ATTENTION directs classic interpretations based on saliency maps to
focus on relevant image regions, while CRAYON-PRUNING removes irrelevant
neurons identified by modern concept-based methods to mitigate their influence.
Through extensive experiments with both quantitative and human evaluation, we
showcase CRAYON's effectiveness, scalability, and practicality in refining
model attention. CRAYON achieves state-of-the-art performance, outperforming 12
methods across 3 benchmark datasets, surpassing approaches that require more
complex annotations.

摘要：現代深度學習模型通常透過聚焦在不相關區域來進行預測，導致有偏差的效能和有限的概化能力。現有的方法旨在修正模型注意力，需要針對不相關區域的明確標籤或複雜的逐像素基本事實注意力圖。我們提出 CRAYON（使用「是或否」註解修正推理），提供有效、可擴充且實用的解決方案，使用簡單的「是或否」註解修正模型注意力。CRAYON 賦能傳統和現代模型詮釋技術，以識別和引導模型推理：CRAYON-ATTENTION 引導根據顯著性圖的經典詮釋，以聚焦在相關影像區域，而 CRAYON-PRUNING 則移除由現代基於概念的方法識別的不相關神經元，以減輕其影響。透過大量定量和人工評估實驗，我們展示 CRAYON 在精進模型注意力方面的有效性、可擴充性和實用性。CRAYON 達到最先進的效能，在 3 個基準資料集上優於 12 種方法，超越需要更多複雜註解的方法。

##### **SVIP: Towards Verifiable Inference of Open-source Large Language Models**
2410.22307v1 by Yifan Sun, Yuhang Li, Yue Zhang, Yuchen Jin, Huan Zhang

Open-source Large Language Models (LLMs) have recently demonstrated
remarkable capabilities in natural language understanding and generation,
leading to widespread adoption across various domains. However, their
increasing model sizes render local deployment impractical for individual
users, pushing many to rely on computing service providers for inference
through a blackbox API. This reliance introduces a new risk: a computing
provider may stealthily substitute the requested LLM with a smaller, less
capable model without consent from users, thereby delivering inferior outputs
while benefiting from cost savings. In this paper, we formalize the problem of
verifiable inference for LLMs. Existing verifiable computing solutions based on
cryptographic or game-theoretic techniques are either computationally
uneconomical or rest on strong assumptions. We introduce SVIP, a secret-based
verifiable LLM inference protocol that leverages intermediate outputs from LLM
as unique model identifiers. By training a proxy task on these outputs and
requiring the computing provider to return both the generated text and the
processed intermediate outputs, users can reliably verify whether the computing
provider is acting honestly. In addition, the integration of a secret mechanism
further enhances the security of our protocol. We thoroughly analyze our
protocol under multiple strong and adaptive adversarial scenarios. Our
extensive experiments demonstrate that SVIP is accurate, generalizable,
computationally efficient, and resistant to various attacks. Notably, SVIP
achieves false negative rates below 5% and false positive rates below 3%, while
requiring less than 0.01 seconds per query for verification.

摘要：<paragraph>開放原始碼大型語言模型 (LLM) 最近在自然語言理解和生成方面展現出卓越的能力，導致在各個領域被廣泛採用。然而，其模型規模越來越大，使得個人使用者難以進行本地部署，迫使許多人依賴運算服務提供商透過黑盒 API 進行推論。這種依賴性引入了新的風險：運算提供商可能會在未經使用者同意的情況下，偷偷用較小、功能較弱的模型取代要求的 LLM，從而提供較差的輸出，同時從成本節省中獲利。在本文中，我們正式定義了 LLM 可驗證推論的問題。現有的基於密碼學或博弈論技術的可驗證運算解決方案，要不就是計算不經濟，要不就是依賴於強有力的假設。我們引入了 SVIP，這是一種基於秘密的可驗證 LLM 推論協定，它利用 LLM 的中間輸出作為唯一的模型識別碼。透過在這些輸出上訓練代理任務，並要求運算提供商同時傳回產生的文字和已處理的中間輸出，使用者可以可靠地驗證運算提供商是否誠實。此外，整合秘密機制進一步增強了我們協定的安全性。我們在多種強大且適應性對抗場景下徹底分析了我們的協定。我們廣泛的實驗證明，SVIP 準確、可概化、計算效率高，且能抵抗各種攻擊。值得注意的是，SVIP 的假陰性率低於 5%，假陽性率低於 3%，同時每個查詢的驗證時間少於 0.01 秒。</paragraph>

##### **Flow-DPO: Improving LLM Mathematical Reasoning through Online Multi-Agent Learning**
2410.22304v1 by Yihe Deng, Paul Mineiro

Mathematical reasoning is a crucial capability for Large Language Models
(LLMs), yet generating detailed and accurate reasoning traces remains a
significant challenge. This paper introduces a novel approach to produce
high-quality reasoning traces for LLM fine-tuning using online learning
\textbf{Flows}. Our method employs an incremental output production Flow, where
component LLMs collaboratively construct solutions through iterative
communication. We train the Flow using online Direct Preference Optimization
(DPO) learning with rollouts, generating DPO pairs for each training example
and updating models in real-time. We directly compare the quality of reasoning
traces generated by our method with those produced through direct model
inference, demonstrating the effectiveness of our approach in improving LLM
performance in mathematical reasoning tasks.

摘要：對於大型語言模型 (LLM) 來說，數學推理是一項至關重要的能力，但要產生詳細且準確的推理追蹤仍然是一項重大挑戰。本文介紹了一種新方法，使用在線學習「流程」為 LLM 微調產生高品質的推理追蹤。我們的模型採用增量輸出產生流程，其中組成 LLM 透過反覆溝通協作建構解法。我們使用在線直接偏好最佳化 (DPO) 學習和執行，為每個訓練範例產生 DPO 對，並即時更新模型。我們直接比較我們的模型產生的推理追蹤品質與直接模型推論產生的品質，證明了我們的方法在改善 LLM 在數學推理任務中的效能上具有成效。

##### **$\mathsf{OPA}$: One-shot Private Aggregation with Single Client Interaction and its Applications to Federated Learning**
2410.22303v1 by Harish Karthikeyan, Antigoni Polychroniadou

Our work aims to minimize interaction in secure computation due to the high
cost and challenges associated with communication rounds, particularly in
scenarios with many clients. In this work, we revisit the problem of secure
aggregation in the single-server setting where a single evaluation server can
securely aggregate client-held individual inputs. Our key contribution is the
introduction of One-shot Private Aggregation ($\mathsf{OPA}$) where clients
speak only once (or even choose not to speak) per aggregation evaluation. Since
each client communicates only once per aggregation, this simplifies managing
dropouts and dynamic participation, contrasting with multi-round protocols and
aligning with plaintext secure aggregation, where clients interact only once.
We construct $\mathsf{OPA}$ based on LWR, LWE, class groups, DCR and
demonstrate applications to privacy-preserving Federated Learning (FL) where
clients \emph{speak once}. This is a sharp departure from prior multi-round FL
protocols whose study was initiated by Bonawitz et al. (CCS, 2017). Moreover,
unlike the YOSO (You Only Speak Once) model for general secure computation,
$\mathsf{OPA}$ eliminates complex committee selection protocols to achieve
adaptive security. Beyond asymptotic improvements, $\mathsf{OPA}$ is practical,
outperforming state-of-the-art solutions. We benchmark logistic regression
classifiers for two datasets, while also building an MLP classifier to train on
MNIST, CIFAR-10, and CIFAR-100 datasets. We build two flavors of $\caps$ (1)
from (threshold) key homomorphic PRF and (2) from seed homomorphic PRG and
secret sharing.

摘要：<paragraph>我們的研究旨在最小化安全計算中的互動，因為與通訊回合相關的高成本和挑戰，尤其是在有許多客戶端的場景中。在這項研究中，我們重新探討單一伺服器設定中安全聚合的問題，其中單一評估伺服器可以安全地聚合客戶端持有的個別輸入。我們的關鍵貢獻是引入了 One-shot Private Aggregation（$\mathsf{OPA}$），其中客戶端在每個聚合評估中只說一次（甚至選擇不說話）。由於每個客戶端每個聚合只通訊一次，這簡化了管理中斷和動態參與，與多輪協定形成對比，並與純文字安全聚合保持一致，其中客戶端只互動一次。我們根據 LWR、LWE、類群、DCR 建構 $\mathsf{OPA}$，並展示了隱私保護聯合學習 (FL) 的應用，其中客戶端「說一次」。這與 Bonawitz 等人發起的先前多輪 FL 協定有明顯區別（CCS，2017）。此外，與一般安全計算的 YOSO（You Only Speak Once）模型不同，$\mathsf{OPA}$ 消除了複雜的委員會選擇協定以實現適應性安全性。除了漸近改進之外，$\mathsf{OPA}$ 具有實用性，優於最先進的解決方案。我們對兩個資料集進行邏輯迴歸分類器的基準測試，同時還建立了一個 MLP 分類器，用於訓練 MNIST、CIFAR-10 和 CIFAR-100 資料集。我們建立了兩種風味的 $\caps$（1）來自（閾值）金鑰同態 PRF 和（2）來自種子同態 PRG 和秘密共享。</paragraph>

##### **From melodic note sequences to pitches using word2vec**
2410.22285v1 by Daniel Defays

Applying the word2vec technique, commonly used in language modeling, to
melodies, where notes are treated as words in sentences, enables the capture of
pitch information. This study examines two datasets: 20 children's songs and an
excerpt from a Bach sonata. The semantic space for defining the embeddings is
of very small dimension, specifically 2. Notes are predicted based on the 2, 3
or 4 preceding notes that establish the context. A multivariate analysis of the
results shows that the semantic vectors representing the notes have a multiple
correlation coefficient of approximately 0.80 with their pitches.

摘要：應用 word2vec 技術，通常用於語言模型，到旋律，其中音符被視為句子中的字詞，可以捕捉音高資訊。本研究探討兩個資料集：20 首兒童歌曲和巴哈奏鳴曲的摘錄。定義嵌入的語意空間維度非常小，特別是 2。音符是根據建立上下文的 2、3 或 4 個前一個音符來預測的。結果的多變量分析顯示，表示音符的語意向量與其音高具有約 0.80 的多重相關係數。

##### **Leveraging Reverberation and Visual Depth Cues for Sound Event Localization and Detection with Distance Estimation**
2410.22271v1 by Davide Berghi, Philip J. B. Jackson

This report describes our systems submitted for the DCASE2024 Task 3
challenge: Audio and Audiovisual Sound Event Localization and Detection with
Source Distance Estimation (Track B). Our main model is based on the
audio-visual (AV) Conformer, which processes video and audio embeddings
extracted with ResNet50 and with an audio encoder pre-trained on SELD,
respectively. This model outperformed the audio-visual baseline of the
development set of the STARSS23 dataset by a wide margin, halving its DOAE and
improving the F1 by more than 3x. Our second system performs a temporal
ensemble from the outputs of the AV-Conformer. We then extended the model with
features for distance estimation, such as direct and reverberant signal
components extracted from the omnidirectional audio channel, and depth maps
extracted from the video frames. While the new system improved the RDE of our
previous model by about 3 percentage points, it achieved a lower F1 score. This
may be caused by sound classes that rarely appear in the training set and that
the more complex system does not detect, as analysis can determine. To overcome
this problem, our fourth and final system consists of an ensemble strategy
combining the predictions of the other three. Many opportunities to refine the
system and training strategy can be tested in future ablation experiments, and
likely achieve incremental performance gains for this audio-visual task.

摘要：這份報告描述我們提交給 DCASE2024 任務 3 的系統，挑戰：音訊和音訊視覺聲音事件定位與偵測，並估計來源距離（軌道 B）。我們的模型主要基於音訊視覺 (AV) Conformer，它處理使用 ResNet50 和音訊編碼器（分別在 SELD 上預先訓練）提取的影片和音訊嵌入。此模型大幅優於 STARSS23 資料集開發集的音訊視覺基準，將其 DOAE 減半，並將 F1 提高 3 倍以上。我們的第二個系統對 AV-Conformer 的輸出執行時間序列集成。接著，我們使用距離估計功能擴充模型，例如從全向音訊頻道提取的直接和混響訊號元件，以及從影片格提取的深度圖。雖然新的系統將我們先前模型的 RDE 提高了約 3 個百分點，但它的 F1 分數較低。這可能是因為訓練集中很少出現的聲音類別，而較複雜的系統無法偵測到，如分析可以確定的。為了克服這個問題，我們的第四個也是最後一個系統包含一個集成策略，結合其他三個預測。可以在未來的消融實驗中測試很多改善系統和訓練策略的機會，並可能會為這個音訊視覺任務獲得增量效能提升。

##### **Fourier Head: Helping Large Language Models Learn Complex Probability Distributions**
2410.22269v1 by Nate Gillman, Daksh Aggarwal, Michael Freeman, Saurabh Singh, Chen Sun

As the quality of large language models has improved, there has been
increased interest in using them to model non-linguistic tokens. For example,
the Decision Transformer recasts agentic decision making as a sequence modeling
problem, using a decoder-only LLM to model the distribution over the discrete
action space for an Atari agent. However, when adapting LLMs to non-linguistic
domains, it remains unclear if softmax over discrete bins captures the
continuous structure of the tokens and the potentially complex distributions
needed for high quality token generation. We introduce a neural network layer,
constructed using Fourier series, which we can easily substitute for any linear
layer if we want the outputs to have a more continuous structure. We perform
extensive analysis on synthetic datasets, as well as on large-scale decision
making and time series forecasting tasks. We also provide theoretical evidence
that this layer can better learn signal from data while ignoring high-frequency
noise. All of our results support the effectiveness of our proposed Fourier
head in scenarios where the underlying data distribution has a natural
continuous structure. For example, the Fourier head improves a Decision
Transformer agent's returns by 46% on the Atari Seaquest game, and increases a
state-of-the-art times series foundation model's forecasting performance by
3.5% across 20 benchmarks unseen during training.

摘要：随着大型语言模型的质量不断提高，人们对使用它们来建模非语言标记的兴趣也与日俱增。例如，决策转换器将代理决策制定重新表述为一个序列建模问题，使用仅解码器 LLM 来建模 Atari 代理的离散动作空间上的分布。然而，在将 LLM 调整到非语言域时，对于 softmax 在离散箱上是否捕捉到标记的连续结构以及高品质标记生成所需的潜在复杂分布，目前仍不清楚。我们引入了一个神经网络层，使用傅立叶级数构建，如果我们希望输出具有更连续的结构，我们可以轻松地用它替换任何线性层。我们对合成数据集以及大规模决策制定和时间序列预测任务进行了广泛的分析。我们还提供了理论证据，证明该层可以更好地从数据中学习信号，同时忽略高频噪声。我们的所有结果都支持我们提出的傅立叶头的有效性，在其中底层数据分布具有自然的连续结构的情况下。例如，傅立叶头将决策转换器代理在 Atari Seaquest 游戏中的回报提高了 46%，并在训练期间未看到的 20 个基准测试中将最先进的时间序列基础模型的预测性能提高了 3.5%。

##### **FactBench: A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation**
2410.22257v1 by Farima Fatahi Bayat, Lechen Zhang, Sheza Munir, Lu Wang

Language models (LMs) are widely used by an increasing number of users,
underscoring the challenge of maintaining factuality across a broad range of
topics. We first present VERIFY (Verification and Evidence RetrIeval for
FactualitY evaluation), a pipeline to evaluate LMs' factuality in real-world
user interactions. VERIFY considers the verifiability of LM-generated content
and categorizes content units as supported, unsupported, or undecidable based
on the retrieved evidence from the Web. Importantly, factuality judgment by
VERIFY correlates better with human evaluations than existing methods. Using
VERIFY, we identify "hallucination prompts" across diverse topics, i.e., those
eliciting the highest rates of incorrect and inconclusive LM responses. These
prompts form FactBench, a dataset of 1K prompts across 150 fine-grained topics.
Our dataset captures emerging factuality challenges in real-world LM
interactions and can be regularly updated with new prompts. We benchmark
widely-used LMs from GPT, Gemini, and Llama3.1 family on FactBench, yielding
the following key findings: (i) Proprietary models exhibit better factuality,
with performance declining from Easy to Hard hallucination prompts. (ii)
Llama3.1-405B-Instruct shows comparable or lower factual accuracy than
Llama3.1-70B-Instruct across all evaluation methods due to its higher
subjectivity that leads to more content labeled as undecidable. (iii)
Gemini1.5-Pro shows a significantly higher refusal rate, with over-refusal in
25% of cases. Our code and data are publicly available at
https://huggingface.co/spaces/launch/factbench.

摘要：語言模型 (LM) 被越來越多的使用者廣泛使用，這突顯了在廣泛主題中維護事實性的挑戰。我們首先提出 VERIFY（事實性評估的驗證和證據檢索），一個用於評估 LM 在真實世界使用者互動中的事實性的管道。VERIFY 考慮了 LM 生成的內容的可驗證性，並根據從網路中檢索到的證據將內容單元分類為受支持、不受支持或無法判定。重要的是，VERIFY 的事實性判斷比現有方法與人類評估更相關。使用 VERIFY，我們識別出各種主題的「幻覺提示」，即引發 LM 產生最高錯誤率和不確定回應的提示。這些提示形成了 FactBench，一個包含 150 個細粒度主題的 1K 提示的資料集。我們的資料集捕捉了真實世界 LM 互動中新出現的事實性挑戰，並且可以定期使用新提示更新。我們在 FactBench 上對來自 GPT、Gemini 和 Llama3.1 家族的廣泛使用的 LM 進行基準測試，得出以下關鍵發現：(i) 專有模型表現出更好的事實性，性能從容易到困難的幻覺提示下降。(ii) Llama3.1-405B-Instruct 在所有評估方法中顯示出與 Llama3.1-70B-Instruct 相當或更低的事實準確性，因為它的主觀性較高，導致更多內容被標記為無法判定。(iii) Gemini1.5-Pro 顯示出顯著更高的拒絕率，在 25% 的情況下過度拒絕。我們的程式碼和資料可在 https://huggingface.co/spaces/launch/factbench 公開取得。

##### **DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers**
2410.22239v1 by Rakesh R. Menon, Shashank Srivastava

Despite their high predictive accuracies, current machine learning systems
often exhibit systematic biases stemming from annotation artifacts or
insufficient support for certain classes in the dataset. Recent work proposes
automatic methods for identifying and explaining systematic biases using
keywords. We introduce DISCERN, a framework for interpreting systematic biases
in text classifiers using language explanations. DISCERN iteratively generates
precise natural language descriptions of systematic errors by employing an
interactive loop between two large language models. Finally, we use the
descriptions to improve classifiers by augmenting classifier training sets with
synthetically generated instances or annotated examples via active learning. On
three text-classification datasets, we demonstrate that language explanations
from our framework induce consistent performance improvements that go beyond
what is achievable with exemplars of systematic bias. Finally, in human
evaluations, we show that users can interpret systematic biases more
effectively (by over 25% relative) and efficiently when described through
language explanations as opposed to cluster exemplars.

摘要：儘管機器學習系統預測準確度高，但目前的系統通常會表現出系統性偏差，這些偏差源自於註解人工製品或資料集中某些類別支援不足。近期研究提出使用關鍵字自動辨識並解釋系統性偏差的方法。我們推出 DISCERN，一個使用語言解釋來詮釋文字分類器中系統性偏差的架構。DISCERN 透過使用兩個大型語言模型之間的互動迴圈，反覆產生系統性錯誤的精確自然語言描述。最後，我們使用這些描述來改善分類器，方法是透過主動學習，用合成產生的實例或註解範例來擴充分類器訓練集。在三個文字分類資料集中，我們展示了我們架構中的語言解釋會引發一致的效能改善，這超越了系統性偏差範例所能達成的效果。最後，在人類評估中，我們顯示出當透過語言解釋（相對於群集範例）來描述時，使用者可以更有效率（相對高出 25% 以上）且更有效地詮釋系統性偏差。

##### **ContextIQ: A Multimodal Expert-Based Video Retrieval System for Contextual Advertising**
2410.22233v1 by Ashutosh Chaubey, Anoubhav Agarwaal, Sartaki Sinha Roy, Aayush Agarwal, Susmita Ghose

Contextual advertising serves ads that are aligned to the content that the
user is viewing. The rapid growth of video content on social platforms and
streaming services, along with privacy concerns, has increased the need for
contextual advertising. Placing the right ad in the right context creates a
seamless and pleasant ad viewing experience, resulting in higher audience
engagement and, ultimately, better ad monetization. From a technology
standpoint, effective contextual advertising requires a video retrieval system
capable of understanding complex video content at a very granular level.
Current text-to-video retrieval models based on joint multimodal training
demand large datasets and computational resources, limiting their practicality
and lacking the key functionalities required for ad ecosystem integration. We
introduce ContextIQ, a multimodal expert-based video retrieval system designed
specifically for contextual advertising. ContextIQ utilizes modality-specific
experts-video, audio, transcript (captions), and metadata such as objects,
actions, emotion, etc.-to create semantically rich video representations. We
show that our system, without joint training, achieves better or comparable
results to state-of-the-art models and commercial solutions on multiple
text-to-video retrieval benchmarks. Our ablation studies highlight the benefits
of leveraging multiple modalities for enhanced video retrieval accuracy instead
of using a vision-language model alone. Furthermore, we show how video
retrieval systems such as ContextIQ can be used for contextual advertising in
an ad ecosystem while also addressing concerns related to brand safety and
filtering inappropriate content.

摘要：情境式廣告提供與使用者正在觀看的內容一致的廣告。社群平台和串流服務上影片內容快速成長，再加上隱私問題，讓情境式廣告的需求提高。在正確的情境中置入正確的廣告，能創造順暢且愉快的廣告觀看體驗，進而提高受眾互動，並最終提升廣告獲利。從技術觀點來看，有效的內容式廣告需要一個影片檢索系統，能夠在非常細微的層級上理解複雜的影片內容。現有的基於聯合多模態訓練的文字到影片檢索模型需要龐大的資料集和運算資源，這限制了其實用性，且缺乏廣告生態系整合所需的主要功能。我們推出 ContextIQ，一個專門為情境式廣告設計的多模態專家級影片檢索系統。ContextIQ 利用特定模態的專家（影片、音訊、轉錄（字幕）和元資料，例如物件、動作、情緒等）來建立語意豐富的影片表示。我們展示了我們的系統，在沒有聯合訓練的情況下，在多個文字到影片檢索基準上，達到了比現有模型和商業解決方案更好或相當的結果。我們的消融研究強調了利用多種模態來增強影片檢索精確度的優點，而不是僅使用視覺語言模型。此外，我們展示了像 ContextIQ 這樣的影片檢索系統如何用於廣告生態系中的情境式廣告，同時也能處理與品牌安全和過濾不當內容相關的問題。

##### **Cora: Accelerating Stateful Network Applications with SmartNICs**
2410.22229v1 by Shaoke Xi, Jiaqi Gao, Mengqi Liu, Jiamin Cao, Fuliang Li, Kai Bu, Kui Ren, Minlan Yu, Dennis Cai, Ennan Zhai

With the growing performance requirements on networked applications, there is
a new trend of offloading stateful network applications to SmartNICs to improve
performance and reduce the total cost of ownership. However, offloading
stateful network applications is non-trivial due to state operation complexity,
state resource consumption, and the complicated relationship between traffic
and state. Naively partitioning the program by state or traffic can result in a
suboptimal partition plan with higher CPU usage or even packet drops. In this
paper, we propose Cora, a compiler and runtime that offloads stateful network
applications to SmartNIC-accelerated hosts. Cora compiler introduces an
accurate performance model for each SmartNIC and employs an efficient compiling
algorithm to search the offloading plan. Cora runtime can monitor traffic
dynamics and adapt to minimize CPU usage. Cora is built atop Netronome Agilio
and BlueField 2 SmartNICs. Our evaluation shows that for the same throughput
target, Cora can propose partition plans saving up to 94.0% CPU cores, 1.9
times more than baseline solutions. Under the same resource constraint, Cora
can accelerate network functions by 44.9%-82.3%. Cora runtime can adapt to
traffic changes and keep CPU usage low.

摘要：随着网络应用程序对性能要求的提高，出现了一种新的趋势，即卸载有状态网络应用程序到 SmartNIC 以提高性能并降低总体拥有成本。然而，由于状态操作的复杂性、状态资源消耗以及流量和状态之间的复杂关系，卸载有状态网络应用程序并非易事。天真地按状态或流量对程序进行分区可能会导致分区计划不理想，从而导致 CPU 使用率更高，甚至丢包。在本文中，我们提出了 Cora，这是一个将有状态网络应用程序卸载到 SmartNIC 加速主机的编译器和运行时。Cora 编译器为每个 SmartNIC 引入了一个准确的性能模型，并采用了一种高效的编译算法来搜索卸载计划。Cora 运行时可以监控流量动态并进行调整以最大程度地减少 CPU 使用率。Cora 建立在 Netronome Agilio 和 BlueField 2 SmartNIC 之上。我们的评估表明，对于相同的吞吐量目标，Cora 可以提出分区计划，节省高达 94.0% 的 CPU 内核，比基线解决方案多 1.9 倍。在相同的资源限制下，Cora 可以将网络功能加速 44.9%-82.3%。Cora 运行时可以适应流量变化并保持较低的 CPU 使用率。

##### **ProMQA: Question Answering Dataset for Multimodal Procedural Activity Understanding**
2410.22211v1 by Kimihiro Hasegawa, Wiradee Imrattanatrai, Zhi-Qi Cheng, Masaki Asada, Susan Holm, Yuran Wang, Ken Fukuda, Teruko Mitamura

Multimodal systems have great potential to assist humans in procedural
activities, where people follow instructions to achieve their goals. Despite
diverse application scenarios, systems are typically evaluated on traditional
classification tasks, e.g., action recognition or temporal action segmentation.
In this paper, we present a novel evaluation dataset, ProMQA, to measure system
advancements in application-oriented scenarios. ProMQA consists of 401
multimodal procedural QA pairs on user recording of procedural activities
coupled with their corresponding instruction. For QA annotation, we take a
cost-effective human-LLM collaborative approach, where the existing annotation
is augmented with LLM-generated QA pairs that are later verified by humans. We
then provide the benchmark results to set the baseline performance on ProMQA.
Our experiment reveals a significant gap between human performance and that of
current systems, including competitive proprietary multimodal models. We hope
our dataset sheds light on new aspects of models' multimodal understanding
capabilities.

摘要：多模态系统在程序化活动中协助人类的潜力巨大，在这些活动中，人们遵循指令来实现目标。尽管有不同的应用场景，但系统通常在传统的分类任务中进行评估，例如动作识别或时间动作分割。在本文中，我们提出了一个新颖的评估数据集 ProMQA，用于衡量系统在面向应用程序的场景中的进步。ProMQA 由 401 个多模态程序化问答对组成，其中包含用户记录的程序化活动和相应的指令。对于问答注释，我们采用了一种经济高效的人工-LLM 协作方法，其中现有的注释通过 LLM 生成的问答对进行扩充，然后由人工验证。然后，我们提供基准结果以设定 ProMQA 的基线性能。我们的实验揭示了人类表现与当前系统（包括有竞争力的专有多模态模型）之间存在显着的差距。我们希望我们的数据集能为模型的多模态理解能力的新方面提供启示。

##### **Drone Acoustic Analysis for Predicting Psychoacoustic Annoyance via Artificial Neural Networks**
2410.22208v1 by Andrea Vaiuso, Marcello Righi, Oier Coretti, Moreno Apicella

Unmanned Aerial Vehicles (UAVs) have become widely used in various fields and
industrial applications thanks to their low operational cost, compact size and
wide accessibility. However, the noise generated by drone propellers has
emerged as a significant concern. This may affect the public willingness to
implement these vehicles in services that require operation in proximity to
residential areas. The standard approaches to address this challenge include
sound pressure measurements and noise characteristic analyses. The integration
of Artificial Intelligence models in recent years has further streamlined the
process by enhancing complex feature detection in drone acoustics data. This
study builds upon prior research by examining the efficacy of various Deep
Learning models in predicting Psychoacoustic Annoyance, an effective index for
measuring perceived annoyance by human ears, based on multiple drone
characteristics as input. This is accomplished by constructing a training
dataset using precise measurements of various drone models with multiple
microphones and analyzing flight data, maneuvers, drone physical
characteristics, and perceived annoyance under realistic conditions. The aim of
this research is to improve our understanding of drone noise, aid in the
development of noise reduction techniques, and encourage the acceptance of
drone usage on public spaces.

摘要：無人機（UAV）由於其低操作成本、小巧的尺寸和廣泛的可及性，已廣泛用於各種領域和工業應用中。然而，無人機螺旋槳產生的噪音已成為一個重大問題。這可能會影響公眾在需要在住宅區附近執行的服務中使用這些車輛的意願。解決這一挑戰的標準方法包括聲壓測量和噪音特性分析。近年來，人工智能模型的整合通過增強無人機聲學數據中的複雜特徵檢測進一步簡化了這一過程。本研究建立在先前的研究基礎上，通過檢驗各種深度學習模型在預測心理聲學厭惡感（衡量人耳感知厭惡感的一個有效指標）方面的功效，該指標基於多個無人機特徵作為輸入。這是通過使用多個麥克風精確測量各種無人機模型並分析飛行數據、機動、無人機物理特性和在現實條件下感知到的厭惡感來構建訓練數據集來實現的。本研究的目的是加深我們對無人機噪音的理解，幫助開發降噪技術，並鼓勵在公共場所使用無人機。

##### **Democratizing Reward Design for Personal and Representative Value-Alignment**
2410.22203v1 by Carter Blair, Kate Larson, Edith Law

Aligning AI agents with human values is challenging due to diverse and
subjective notions of values. Standard alignment methods often aggregate crowd
feedback, which can result in the suppression of unique or minority
preferences. We introduce Interactive-Reflective Dialogue Alignment, a method
that iteratively engages users in reflecting on and specifying their subjective
value definitions. This system learns individual value definitions through
language-model-based preference elicitation and constructs personalized reward
models that can be used to align AI behaviour. We evaluated our system through
two studies with 30 participants, one focusing on "respect" and the other on
ethical decision-making in autonomous vehicles. Our findings demonstrate
diverse definitions of value-aligned behaviour and show that our system can
accurately capture each person's unique understanding. This approach enables
personalized alignment and can inform more representative and interpretable
collective alignment strategies.

摘要：由於價值觀念的多元且主觀，讓 AI 代理與人類價值觀保持一致是一項挑戰。標準校準方法通常會彙總群眾回饋，這可能會導致獨特或少數偏好的壓制。我們引入了互動式反思式對話校準，這是一種讓使用者反覆參與反思並說明其主觀價值定義的方法。此系統透過基於語言模型的偏好引導來學習個別價值定義，並建構可用于校準 AI 行為的個人化獎勵模型。我們透過兩項研究對我們的系統進行了評估，共有 30 名參與者，一項著重於「尊重」，另一項著重於自動駕駛車輛中的道德決策。我們的研究結果證明了價值觀一致行為的多元定義，並顯示我們的系統可以準確捕捉每個個人的獨特理解。這種方法能實現個人化校準，並可以為更具代表性和可解釋性的集體校準策略提供資訊。

##### **Class-Aware Contrastive Optimization for Imbalanced Text Classification**
2410.22197v1 by Grigorii Khvatskii, Nuno Moniz, Khoa Doan, Nitesh V Chawla

The unique characteristics of text data make classification tasks a complex
problem. Advances in unsupervised and semi-supervised learning and autoencoder
architectures addressed several challenges. However, they still struggle with
imbalanced text classification tasks, a common scenario in real-world
applications, demonstrating a tendency to produce embeddings with unfavorable
properties, such as class overlap. In this paper, we show that leveraging
class-aware contrastive optimization combined with denoising autoencoders can
successfully tackle imbalanced text classification tasks, achieving better
performance than the current state-of-the-art. Concretely, our proposal
combines reconstruction loss with contrastive class separation in the embedding
space, allowing a better balance between the truthfulness of the generated
embeddings and the model's ability to separate different classes. Compared with
an extensive set of traditional and state-of-the-art competing methods, our
proposal demonstrates a notable increase in performance across a wide variety
of text datasets.

摘要：文本資料的獨特特性使分類任務成為一項複雜的問題。無監督和半監督學習以及自動編碼器架構的進展解決了若干挑戰。然而，它們仍然難以應付不平衡的文本分類任務，這是現實世界應用中的常見場景，表現出產生具有不利屬性的嵌入的趨勢，例如類別重疊。在本文中，我們展示了利用類別感知對比最佳化結合去噪自動編碼器可以成功應對不平衡的文本分類任務，實現比當前最先進技術更好的效能。具體而言，我們的提議將重建損失與嵌入空間中的對比類別分離相結合，在生成的嵌入的真實性與模型分離不同類別的能力之間取得更好的平衡。與廣泛的傳統和最先進的競爭方法相比，我們的提議在各種文本資料集上展示了效能的顯著提升。

##### **ADAM: An Embodied Causal Agent in Open-World Environments**
2410.22194v1 by Shu Yu, Chaochao Lu

In open-world environments like Minecraft, existing agents face challenges in
continuously learning structured knowledge, particularly causality. These
challenges stem from the opacity inherent in black-box models and an excessive
reliance on prior knowledge during training, which impair their
interpretability and generalization capability. To this end, we introduce ADAM,
An emboDied causal Agent in Minecraft, that can autonomously navigate the open
world, perceive multimodal contexts, learn causal world knowledge, and tackle
complex tasks through lifelong learning. ADAM is empowered by four key
components: 1) an interaction module, enabling the agent to execute actions
while documenting the interaction processes; 2) a causal model module, tasked
with constructing an ever-growing causal graph from scratch, which enhances
interpretability and diminishes reliance on prior knowledge; 3) a controller
module, comprising a planner, an actor, and a memory pool, which uses the
learned causal graph to accomplish tasks; 4) a perception module, powered by
multimodal large language models, which enables ADAM to perceive like a human
player. Extensive experiments show that ADAM constructs an almost perfect
causal graph from scratch, enabling efficient task decomposition and execution
with strong interpretability. Notably, in our modified Minecraft games where no
prior knowledge is available, ADAM maintains its performance and shows
remarkable robustness and generalization capability. ADAM pioneers a novel
paradigm that integrates causal methods and embodied agents in a synergistic
manner. Our project page is at https://opencausalab.github.io/ADAM.

摘要：在像 Minecraft 這樣的開放世界環境中，現有的代理人面臨持續學習結構化知識的挑戰，尤其是因果關係。這些挑戰源於黑盒模型固有的不透明性，以及在訓練期間過度依賴先驗知識，這會損害它們的可解釋性和泛化能力。為此，我們引入了 ADAM，Minecraft 中的一個具身因果代理，它可以自主導航開放世界，感知多模式上下文，學習因果世界知識，並通過終身學習來應對複雜任務。ADAM 由四個關鍵組成部分賦能：1) 一個交互模組，使代理能夠執行動作，同時記錄交互過程；2) 一個因果模型模組，負責從頭開始構建一個不斷增長的因果圖，這增強了可解釋性並減少了對先驗知識的依賴；3) 一個控制器模組，包括一個規劃器、一個執行器和一個記憶池，它使用學習到的因果圖來完成任務；4) 一個感知模組，由多模式大型語言模型提供支援，使 ADAM 能夠像人類玩家一樣感知。大量的實驗表明，ADAM 從頭開始構建了一個幾乎完美的因果圖，實現了高效的任務分解和執行，並具有很強的可解釋性。值得注意的是，在我們修改過的 Minecraft 遊戲中，沒有可用的先驗知識，ADAM 保持了其性能，並表現出顯著的魯棒性和泛化能力。ADAM 開創了一種新穎的範例，以協同方式整合因果方法和具身代理。我們的專案頁面位於 https://opencausalab.github.io/ADAM。

##### **Multi-Level Feature Distillation of Joint Teachers Trained on Distinct Image Datasets**
2410.22184v1 by Adrian Iordache, Bogdan Alexe, Radu Tudor Ionescu

We propose a novel teacher-student framework to distill knowledge from
multiple teachers trained on distinct datasets. Each teacher is first trained
from scratch on its own dataset. Then, the teachers are combined into a joint
architecture, which fuses the features of all teachers at multiple
representation levels. The joint teacher architecture is fine-tuned on samples
from all datasets, thus gathering useful generic information from all data
samples. Finally, we employ a multi-level feature distillation procedure to
transfer the knowledge to a student model for each of the considered datasets.
We conduct image classification experiments on seven benchmarks, and action
recognition experiments on three benchmarks. To illustrate the power of our
feature distillation procedure, the student architectures are chosen to be
identical to those of the individual teachers. To demonstrate the flexibility
of our approach, we combine teachers with distinct architectures. We show that
our novel Multi-Level Feature Distillation (MLFD) can significantly surpass
equivalent architectures that are either trained on individual datasets, or
jointly trained on all datasets at once. Furthermore, we confirm that each step
of the proposed training procedure is well motivated by a comprehensive
ablation study. We publicly release our code at
https://github.com/AdrianIordache/MLFD.

摘要：我們提出一個新的教師-學生架構，從在不同資料集上訓練的多個教師中萃取知識。每個教師首先從頭開始在自己的資料集上進行訓練。然後，將教師組合成一個聯合架構，該架構融合了所有教師在多個表示層級中的特徵。聯合教師架構針對來自所有資料集的樣本進行微調，從而從所有資料樣本中收集有用的通用資訊。最後，我們採用多層級特徵萃取程序，將知識轉移到每個考慮資料集的學生模型。我們對七個基準進行影像分類實驗，並對三個基準進行動作辨識實驗。為了說明我們特徵萃取程序的強大功能，學生架構被選為與個別教師的架構相同。為了展示我們方法的靈活性，我們結合了具有不同架構的教師。我們展示我們的創新多層級特徵萃取 (MLFD) 可以顯著超越僅在個別資料集上訓練或一次在所有資料集上聯合訓練的等效架構。此外，我們確認所提議訓練程序的每一步都受到全面消融研究的充分激勵。我們在 https://github.com/AdrianIordache/MLFD 公開發布我們的程式碼。

##### **Natural Language Processing for Analyzing Electronic Health Records and Clinical Notes in Cancer Research: A Review**
2410.22180v1 by Muhammad Bilal, Ameer Hamza, Nadia Malik

Objective: This review aims to analyze the application of natural language
processing (NLP) techniques in cancer research using electronic health records
(EHRs) and clinical notes. This review addresses gaps in the existing
literature by providing a broader perspective than previous studies focused on
specific cancer types or applications. Methods: A comprehensive literature
search was conducted using the Scopus database, identifying 94 relevant studies
published between 2019 and 2024. Data extraction included study
characteristics, cancer types, NLP methodologies, dataset information,
performance metrics, challenges, and future directions. Studies were
categorized based on cancer types and NLP applications. Results: The results
showed a growing trend in NLP applications for cancer research, with breast,
lung, and colorectal cancers being the most studied. Information extraction and
text classification emerged as predominant NLP tasks. A shift from rule-based
to advanced machine learning techniques, particularly transformer-based models,
was observed. The Dataset sizes used in existing studies varied widely. Key
challenges included the limited generalizability of proposed solutions and the
need for improved integration into clinical workflows. Conclusion: NLP
techniques show significant potential in analyzing EHRs and clinical notes for
cancer research. However, future work should focus on improving model
generalizability, enhancing robustness in handling complex clinical language,
and expanding applications to understudied cancer types. Integration of NLP
tools into clinical practice and addressing ethical considerations remain
crucial for utilizing the full potential of NLP in enhancing cancer diagnosis,
treatment, and patient outcomes.

摘要：<paragraph>目標：本篇評論旨在分析自然語言處理 (NLP) 技術在癌症研究中使用電子健康紀錄 (EHR) 和臨床筆記的應用。本篇評論透過提供比先前專注於特定癌症類型或應用的研究更廣泛的觀點，來探討現有文獻中的差距。方法：使用 Scopus 資料庫進行全面的文獻搜尋，找出 2019 年至 2024 年間發表的 94 篇相關研究。資料擷取包含研究特徵、癌症類型、NLP 方法論、資料集資訊、效能指標、挑戰和未來方向。研究根據癌症類型和 NLP 應用進行分類。結果：結果顯示 NLP 在癌症研究中的應用有逐漸增加的趨勢，其中乳癌、肺癌和大腸直腸癌的研究最多。資訊擷取和文字分類成為主要的 NLP 任務。觀察到從基於規則的技術轉移到進階機器學習技術，特別是基於轉換器的模型。現有研究中使用的資料集大小差異很大。主要的挑戰包括所提出解決方案的普遍性有限，以及需要更進一步整合到臨床工作流程中。結論：NLP 技術在分析電子健康紀錄和臨床筆記以進行癌症研究方面顯示出顯著的潛力。然而，未來的研究應專注於改善模型的普遍性、加強處理複雜臨床語言的穩健性，以及將應用擴展到研究不足的癌症類型。將 NLP 工具整合到臨床實務中，並探討倫理考量，對於充分利用 NLP 在提升癌症診斷、治療和患者預後方面的潛力至關重要。</paragraph>

##### **Very Attentive Tacotron: Robust and Unbounded Length Generalization in Autoregressive Transformer-Based Text-to-Speech**
2410.22179v1 by Eric Battenberg, RJ Skerry-Ryan, Daisy Stanton, Soroosh Mariooryad, Matt Shannon, Julian Salazar, David Kao

Autoregressive (AR) Transformer-based sequence models are known to have
difficulty generalizing to sequences longer than those seen during training.
When applied to text-to-speech (TTS), these models tend to drop or repeat words
or produce erratic output, especially for longer utterances. In this paper, we
introduce enhancements aimed at AR Transformer-based encoder-decoder TTS
systems that address these robustness and length generalization issues. Our
approach uses an alignment mechanism to provide cross-attention operations with
relative location information. The associated alignment position is learned as
a latent property of the model via backprop and requires no external alignment
information during training. While the approach is tailored to the monotonic
nature of TTS input-output alignment, it is still able to benefit from the
flexible modeling power of interleaved multi-head self- and cross-attention
operations. A system incorporating these improvements, which we call Very
Attentive Tacotron, matches the naturalness and expressiveness of a baseline
T5-based TTS system, while eliminating problems with repeated or dropped words
and enabling generalization to any practical utterance length.

摘要：自回归 (AR) Transformer 为基础的序列模型已知在推广到比训练期间所见的序列更长的序列时有困难。当应用于文本转语音 (TTS) 时，这些模型倾向于丢弃或重复单词或产生不稳定的输出，尤其对于较长的语音。在本文中，我们引入了针对 AR Transformer 为基础的编码器-解码器 TTS 系统的增强功能，解决了这些鲁棒性和长度推广问题。我们的方法使用对齐机制来提供具有相对位置信息的交叉注意操作。关联的对齐位置通过反向传播作为模型的潜在属性学习，并且在训练期间不需要外部对齐信息。虽然该方法针对 TTS 输入输出对齐的单调特性量身定制，但它仍然能够受益于交错多头自注意和交叉注意操作的灵活建模能力。包含这些改进的系统，我们称之为非常注意的 Tacotron，匹配了基于 T5 的基线 TTS 系统的自然性和表现力，同时消除了重复或丢弃单词的问题，并实现了对任何实际语音长度的推广。

##### **Analyzing Multimodal Interaction Strategies for LLM-Assisted Manipulation of 3D Scenes**
2410.22177v1 by Junlong Chen, Jens Grubert, Per Ola Kristensson

As more applications of large language models (LLMs) for 3D content for
immersive environments emerge, it is crucial to study user behaviour to
identify interaction patterns and potential barriers to guide the future design
of immersive content creation and editing systems which involve LLMs. In an
empirical user study with 12 participants, we combine quantitative usage data
with post-experience questionnaire feedback to reveal common interaction
patterns and key barriers in LLM-assisted 3D scene editing systems. We identify
opportunities for improving natural language interfaces in 3D design tools and
propose design recommendations for future LLM-integrated 3D content creation
systems. Through an empirical study, we demonstrate that LLM-assisted
interactive systems can be used productively in immersive environments.

摘要：隨著大型語言模型 (LLM) 在沉浸式環境中用於 3D 內容的應用越來越多，研究使用者行為以找出互動模式和潛在障礙，以引導未來包含 LLM 的沉浸式內容創作和編輯系統的設計，至關重要。在一個包含 12 位參與者的經驗性使用者研究中，我們結合了量化的使用數據與經驗後問卷回饋，以揭露 LLM 輔助 3D 場景編輯系統中常見的互動模式和主要障礙。我們找出改進 3D 設計工具中自然語言介面的機會，並針對未來整合 LLM 的 3D 內容創作系統提出設計建議。透過經驗性研究，我們證明了 LLM 輔助互動系統可用於沉浸式環境中，並能發揮生產力。

##### **Benchmarking LLM Guardrails in Handling Multilingual Toxicity**
2410.22153v1 by Yahan Yang, Soham Dan, Dan Roth, Insup Lee

With the ubiquity of Large Language Models (LLMs), guardrails have become
crucial to detect and defend against toxic content. However, with the
increasing pervasiveness of LLMs in multilingual scenarios, their effectiveness
in handling multilingual toxic inputs remains unclear. In this work, we
introduce a comprehensive multilingual test suite, spanning seven datasets and
over ten languages, to benchmark the performance of state-of-the-art
guardrails. We also investigates the resilience of guardrails against recent
jailbreaking techniques, and assess the impact of in-context safety policies
and language resource availability on guardrails' performance. Our findings
show that existing guardrails are still ineffective at handling multilingual
toxicity and lack robustness against jailbreaking prompts. This work aims to
identify the limitations of guardrails and to build a more reliable and
trustworthy LLMs in multilingual scenarios.

摘要：隨著大型語言模型 (LLM) 的普及，防護措施已成為偵測和防禦有害內容的關鍵。然而，隨著 LLM 在多語言場景中日益普及，它們在處理多語言有害輸入方面的有效性仍不明朗。在這項工作中，我們引進一個全面的多語言測試套件，涵蓋七個資料集和超過十種語言，以評量最先進防護措施的效能。我們還探討防護措施對近期越獄技術的韌性，並評估脈絡內安全政策和語言資源可用性對防護措施效能的影響。我們的研究結果顯示，現有的防護措施在處理多語言有害內容時仍然無效，且缺乏對抗越獄提示的穩健性。這項工作旨在找出防護措施的限制，並在多語言場景中建立更可靠且值得信賴的 LLM。

##### **Standardization Trends on Safety and Trustworthiness Technology for Advanced AI**
2410.22151v1 by Jonghong Jeon

Artificial Intelligence (AI) has rapidly evolved over the past decade and has
advanced in areas such as language comprehension, image and video recognition,
programming, and scientific reasoning. Recent AI technologies based on large
language models and foundation models are approaching or surpassing artificial
general intelligence. These systems demonstrate superior performance in complex
problem solving, natural language processing, and multi-domain tasks, and can
potentially transform fields such as science, industry, healthcare, and
education. However, these advancements have raised concerns regarding the
safety and trustworthiness of advanced AI, including risks related to
uncontrollability, ethical conflicts, long-term socioeconomic impacts, and
safety assurance. Efforts are being expended to develop internationally
agreed-upon standards to ensure the safety and reliability of AI. This study
analyzes international trends in safety and trustworthiness standardization for
advanced AI, identifies key areas for standardization, proposes future
directions and strategies, and draws policy implications. The goal is to
support the safe and trustworthy development of advanced AI and enhance
international competitiveness through effective standardization.

摘要：人工智能（AI）在過去十年中迅速發展，並在語言理解、影像和影片辨識、程式設計和科學推理等領域取得進展。最近基於大型語言模型和基礎模型的人工智慧技術正接近或超越人工通用智慧。這些系統在複雜問題解決、自然語言處理和多領域任務中展現出優異的效能，並有可能轉變科學、產業、醫療保健和教育等領域。然而，這些進展引發了對進階人工智慧的安全性和可信度的疑慮，包括與不可控性、倫理衝突、長期社會經濟影響和安全保證相關的風險。目前正努力制定國際公認標準，以確保人工智慧的安全性和可靠性。本研究分析了進階人工智慧安全性和可信度標準化的國際趨勢，找出標準化的關鍵領域，提出未來的方向和策略，並得出政策含義。目標是透過有效的標準化，支援進階人工智慧的安全和可信賴發展，並提升國際競爭力。

##### **AmpleGCG-Plus: A Strong Generative Model of Adversarial Suffixes to Jailbreak LLMs with Higher Success Rates in Fewer Attempts**
2410.22143v1 by Vishal Kumar, Zeyi Liao, Jaylen Jones, Huan Sun

Although large language models (LLMs) are typically aligned, they remain
vulnerable to jailbreaking through either carefully crafted prompts in natural
language or, interestingly, gibberish adversarial suffixes. However, gibberish
tokens have received relatively less attention despite their success in
attacking aligned LLMs. Recent work, AmpleGCG~\citep{liao2024amplegcg},
demonstrates that a generative model can quickly produce numerous customizable
gibberish adversarial suffixes for any harmful query, exposing a range of
alignment gaps in out-of-distribution (OOD) language spaces. To bring more
attention to this area, we introduce AmpleGCG-Plus, an enhanced version that
achieves better performance in fewer attempts. Through a series of exploratory
experiments, we identify several training strategies to improve the learning of
gibberish suffixes. Our results, verified under a strict evaluation setting,
show that it outperforms AmpleGCG on both open-weight and closed-source models,
achieving increases in attack success rate (ASR) of up to 17\% in the white-box
setting against Llama-2-7B-chat, and more than tripling ASR in the black-box
setting against GPT-4. Notably, AmpleGCG-Plus jailbreaks the newer GPT-4o
series of models at similar rates to GPT-4, and, uncovers vulnerabilities
against the recently proposed circuit breakers defense. We publicly release
AmpleGCG-Plus along with our collected training datasets.

摘要：儘管大型語言模型 (LLM) 通常是對齊的，但它們仍然容易受到精心設計的自然語言提示或有趣的胡言亂語對抗後綴的越獄攻擊。然而，儘管胡言亂語標記在攻擊對齊的 LLM 上取得成功，但它們受到的關注相對較少。最近的一項工作 AmpleGCG~\citep{liao2024amplegcg} 證明，生成模型可以快速產生大量可自訂的胡言亂語對抗後綴以進行任何有害查詢，從而暴露出分布外 (OOD) 語言空間中的一系列對齊差距。為了讓更多人關注這個領域，我們引入了 AmpleGCG-Plus，這是一個增強版本，可以在更少的嘗試中取得更好的表現。透過一系列探索性實驗，我們找出幾種訓練策略來改善胡言亂語後綴的學習。我們的結果在嚴格的評估設定下得到驗證，顯示它在開放權重和閉源模型上都優於 AmpleGCG，在針對 Llama-2-7B-chat 的白盒設定中攻擊成功率 (ASR) 提高了 17%，在針對 GPT-4 的黑盒設定中，ASR 增加了三倍以上。值得注意的是，AmpleGCG-Plus 以與 GPT-4 相似的速率越獄了更新的 GPT-4o 系列模型，並揭露了針對最近提出的斷路器防禦的漏洞。我們公開發布 AmpleGCG-Plus 以及我們收集的訓練資料集。

##### **ProMoE: Fast MoE-based LLM Serving using Proactive Caching**
2410.22134v1 by Xiaoniu Song, Zihang Zhong, Rong Chen

The promising applications of large language models are often constrained by
the limited GPU memory capacity available on edge devices. Mixture-of-Experts
(MoE) models help mitigate this issue by activating only a subset of the
model's parameters during computation, allowing the unused parameters to be
offloaded to host memory and reducing overall GPU memory demand. However,
existing cache-based offloading solutions handle cache misses reactively and
significantly impact system performance. In this paper, we propose ProMoE, a
novel proactive caching system that leverages intermediate model results to
predict subsequent parameter usage. By proactively fetching experts in advance,
ProMoE removes the loading time from the critical path and diminishes the
performance overhead of offloading. Our evaluations demonstrate that ProMoE
achieves an average speedup of 2.13x and 2.84x in the prefill and decode stages
respectively, compared to existing offloading solutions.

摘要：大型語言模型有前景的應用程式常常受到邊緣裝置上有限的 GPU 記憶體容量所限制。混合專家 (MoE) 模型透過只在運算期間啟用模型參數的子集來協助減輕此問題，讓未使用的參數可以卸載到主機記憶體，並減少整體 GPU 記憶體需求。然而，現有的基於快取的卸載解決方案會被動處理快取未命中，並顯著影響系統效能。在本文中，我們提出 ProMoE，一種新穎的先制快取系統，利用中間模型結果來預測後續參數使用。透過先制取得專家，ProMoE 從關鍵路徑中移除載入時間，並減少卸載的效能開銷。我們的評量顯示，與現有的卸載解決方案相比，ProMoE 在預先填入和解碼階段分別達成平均 2.13 倍和 2.84 倍的加速。

##### **Lightweight Frequency Masker for Cross-Domain Few-Shot Semantic Segmentation**
2410.22135v1 by Jintao Tong, Yixiong Zou, Yuhua Li, Ruixuan Li

Cross-domain few-shot segmentation (CD-FSS) is proposed to first pre-train
the model on a large-scale source-domain dataset, and then transfer the model
to data-scarce target-domain datasets for pixel-level segmentation. The
significant domain gap between the source and target datasets leads to a sharp
decline in the performance of existing few-shot segmentation (FSS) methods in
cross-domain scenarios. In this work, we discover an intriguing phenomenon:
simply filtering different frequency components for target domains can lead to
a significant performance improvement, sometimes even as high as 14% mIoU.
Then, we delve into this phenomenon for an interpretation, and find such
improvements stem from the reduced inter-channel correlation in feature maps,
which benefits CD-FSS with enhanced robustness against domain gaps and larger
activated regions for segmentation. Based on this, we propose a lightweight
frequency masker, which further reduces channel correlations by an
amplitude-phase-masker (APM) module and an Adaptive Channel Phase Attention
(ACPA) module. Notably, APM introduces only 0.01% additional parameters but
improves the average performance by over 10%, and ACPA imports only 2.5%
parameters but further improves the performance by over 1.5%, which
significantly surpasses the state-of-the-art CD-FSS methods.

摘要：跨域小样本分割（CD-FSS）提出首先在大型源域数据集上预训练模型，然后将模型转移到数据稀缺的目标域数据集进行像素级分割。源数据集和目标数据集之间的显著域差异导致现有小样本分割（FSS）方法在跨域场景中的性能急剧下降。在这项工作中，我们发现了一个有趣的现象：仅仅过滤目标域的不同频率分量就可以带来显著的性能提升，有时甚至高达 14% mIoU。然后，我们深入研究了这种现象以进行解释，并发现这种改进源于特征图中减少的通道间相关性，这使 CD-FSS 具有增强的抗域差异鲁棒性和更大的分割激活区域。基于此，我们提出了一种轻量级频率掩码器，它通过幅度相位掩码器（APM）模块和自适应通道相位注意力（ACPA）模块进一步降低了通道相关性。值得注意的是，APM 仅引入了 0.01% 的附加参数，但平均性能提高了 10% 以上，而 ACPA 仅引入了 2.5% 的参数，但进一步提高了 1.5% 以上的性能，这明显超过了最先进的 CD-FSS 方法。

##### **Improving Performance of Commercially Available AI Products in a Multi-Agent Configuration**
2410.22129v1 by Cory Hymel, Sida Peng, Kevin Xu, Charath Ranganathan

In recent years, with the rapid advancement of large language models (LLMs),
multi-agent systems have become increasingly more capable of practical
application. At the same time, the software development industry has had a
number of new AI-powered tools developed that improve the software development
lifecycle (SDLC). Academically, much attention has been paid to the role of
multi-agent systems to the SDLC. And, while single-agent systems have
frequently been examined in real-world applications, we have seen comparatively
few real-world examples of publicly available commercial tools working together
in a multi-agent system with measurable improvements. In this experiment we
test context sharing between Crowdbotics PRD AI, a tool for generating software
requirements using AI, and GitHub Copilot, an AI pair-programming tool. By
sharing business requirements from PRD AI, we improve the code suggestion
capabilities of GitHub Copilot by 13.8% and developer task success rate by
24.5% -- demonstrating a real-world example of commercially-available AI
systems working together with improved outcomes.

摘要：近年來，隨著大型語言模型 (LLM) 的快速進步，多主體系統在實際應用中變得越來越有能力。同時，軟體開發產業已經有許多由 AI 驅動的新工具開發出來，以改善軟體開發生命週期 (SDLC)。在學術上，人們對多主體系統在 SDLC 中所扮演的角色給予了許多關注。而且，儘管單一主體系統已經在真實世界的應用中經常受到檢驗，但我們看到在多主體系統中共同運作的公開可用的商業工具的真實世界範例相對較少，而且有可衡量的改進。在此實驗中，我們測試了 Crowdbotics PRD AI（一個使用 AI 產生軟體需求的工具）與 GitHub Copilot（一個 AI 結對程式設計工具）之間的內容分享。透過分享 PRD AI 中的業務需求，我們將 GitHub Copilot 的程式碼建議能力提升了 13.8%，開發人員任務成功率提升了 24.5% ── 展示了一個商業上可用的 AI 系統共同運作並改善結果的真實世界範例。

##### **RankUp: Boosting Semi-Supervised Regression with an Auxiliary Ranking Classifier**
2410.22124v1 by Pin-Yen Huang, Szu-Wei Fu, Yu Tsao

State-of-the-art (SOTA) semi-supervised learning techniques, such as FixMatch
and it's variants, have demonstrated impressive performance in classification
tasks. However, these methods are not directly applicable to regression tasks.
In this paper, we present RankUp, a simple yet effective approach that adapts
existing semi-supervised classification techniques to enhance the performance
of regression tasks. RankUp achieves this by converting the original regression
task into a ranking problem and training it concurrently with the original
regression objective. This auxiliary ranking classifier outputs a
classification result, thus enabling integration with existing semi-supervised
classification methods. Moreover, we introduce regression distribution
alignment (RDA), a complementary technique that further enhances RankUp's
performance by refining pseudo-labels through distribution alignment. Despite
its simplicity, RankUp, with or without RDA, achieves SOTA results in across a
range of regression benchmarks, including computer vision, audio, and natural
language processing tasks. Our code and log data are open-sourced at
https://github.com/pm25/semi-supervised-regression.

摘要：最先進（SOTA）的半監督式學習技術，例如 FixMatch 及其變體，已在分類任務中展現出令人印象深刻的效能。然而，這些方法並不直接適用於回歸任務。在本文中，我們提出 RankUp，一種簡單但有效的方法，它採用現有的半監督式分類技術來增強回歸任務的效能。RankUp 透過將原始回歸任務轉換為排名問題，並與原始回歸目標同時訓練來達成此目標。這個輔助排名分類器會輸出一個分類結果，因此能夠與現有的半監督式分類方法整合。此外，我們引入了回歸分佈比對（RDA），這是一種互補技術，它透過分佈比對精煉偽標籤，進一步增強 RankUp 的效能。儘管 RankUp 非常簡單，無論是否使用 RDA，它都能在各種回歸基準中達成 SOTA 結果，包括電腦視覺、音訊和自然語言處理任務。我們的程式碼和記錄資料已在 https://github.com/pm25/semi-supervised-regression 開源。

##### **The Impact of Inference Acceleration Strategies on Bias of LLMs**
2410.22118v1 by Elisabeth Kirsten, Ivan Habernal, Vedant Nanda, Muhammad Bilal Zafar

Last few years have seen unprecedented advances in capabilities of Large
Language Models (LLMs). These advancements promise to deeply benefit a vast
array of application domains. However, due to their immense size, performing
inference with LLMs is both costly and slow. Consequently, a plethora of recent
work has proposed strategies to enhance inference efficiency, e.g.,
quantization, pruning, and caching. These acceleration strategies reduce the
inference cost and latency, often by several factors, while maintaining much of
the predictive performance measured via common benchmarks. In this work, we
explore another critical aspect of LLM performance: demographic bias in model
generations due to inference acceleration optimizations. Using a wide range of
metrics, we probe bias in model outputs from a number of angles. Analysis of
outputs before and after inference acceleration shows significant change in
bias. Worryingly, these bias effects are complex and unpredictable. A
combination of an acceleration strategy and bias type may show little bias
change in one model but may lead to a large effect in another. Our results
highlight a need for in-depth and case-by-case evaluation of model bias after
it has been modified to accelerate inference.

摘要：在過去幾年中，大型語言模型 (LLM) 的功能有了前所未有的進步。這些進步有望極大地惠及廣泛的應用領域。然而，由於其規模龐大，使用 LLM 執行推理既昂貴又緩慢。因此，大量的近期工作提出了提高推理效率的策略，例如量化、修剪和快取。這些加速策略降低了推理成本和延遲，通常降低了幾個因素，同時通過常見基準測量來維持大部分預測性能。在這項工作中，我們探討了 LLM 性能的另一個關鍵方面：由於推理加速優化而導致模型生成中的人口統計偏差。使用廣泛的指標，我們從多個角度探討模型輸出的偏差。對推理加速前後的輸出進行分析，顯示偏差發生了顯著變化。令人擔憂的是，這些偏差效應複雜且不可預測。加速策略和偏差類型的組合可能在一個模型中顯示出很小的偏差變化，但在另一個模型中可能導致很大的影響。我們的結果強調了在修改模型以加速推理後，需要對模型偏差進行深入和逐案評估。

##### **Policy Gradient for Robust Markov Decision Processes**
2410.22114v1 by Qiuhao Wang, Shaohang Xu, Chin Pang Ho, Marek Petrick

We develop a generic policy gradient method with the global optimality
guarantee for robust Markov Decision Processes (MDPs). While policy gradient
methods are widely used for solving dynamic decision problems due to their
scalable and efficient nature, adapting these methods to account for model
ambiguity has been challenging, often making it impractical to learn robust
policies. This paper introduces a novel policy gradient method, Double-Loop
Robust Policy Mirror Descent (DRPMD), for solving robust MDPs. DRPMD employs a
general mirror descent update rule for the policy optimization with adaptive
tolerance per iteration, guaranteeing convergence to a globally optimal policy.
We provide a comprehensive analysis of DRPMD, including new convergence results
under both direct and softmax parameterizations, and provide novel insights
into the inner problem solution through Transition Mirror Ascent (TMA).
Additionally, we propose innovative parametric transition kernels for both
discrete and continuous state-action spaces, broadening the applicability of
our approach. Empirical results validate the robustness and global convergence
of DRPMD across various challenging robust MDP settings.

摘要：我們開發了一種具有全局最優性
保證的通用策略梯度方法，用於穩健馬可夫決策過程 (MDP)。雖然策略梯度
方法由於其可擴展且高效的特性而廣泛用於解決動態決策問題，但調整這些方法以考慮模型
模糊性一直很有挑戰性，通常使得學習穩健策略變得不切實際。本文介紹了一種新穎的策略梯度方法，雙迴路
穩健策略鏡像下降 (DRPMD)，用於解決穩健 MDP。DRPMD 採用
通用鏡像下降更新規則進行策略優化，每個迭代具有自適應容差，保證收斂到全局最優策略。
我們提供了對 DRPMD 的全面分析，包括直接和 softmax 參數化下的新收斂結果，並通過轉移鏡像上升 (TMA) 提供了對內部問題解決方案的新見解。
此外，我們針對離散和連續狀態動作空間提出了創新的參數化轉移核，擴大了
我們方法的適用性。經驗結果驗證了 DRPMD 在各種具有挑戰性的穩健 MDP 設置中的穩健性和全局收斂性。

##### **Protecting Privacy in Multimodal Large Language Models with MLLMU-Bench**
2410.22108v1 by Zheyuan Liu, Guangyao Dou, Mengzhao Jia, Zhaoxuan Tan, Qingkai Zeng, Yongle Yuan, Meng Jiang

Generative models such as Large Language Models (LLM) and Multimodal Large
Language models (MLLMs) trained on massive web corpora can memorize and
disclose individuals' confidential and private data, raising legal and ethical
concerns. While many previous works have addressed this issue in LLM via
machine unlearning, it remains largely unexplored for MLLMs. To tackle this
challenge, we introduce Multimodal Large Language Model Unlearning Benchmark
(MLLMU-Bench), a novel benchmark aimed at advancing the understanding of
multimodal machine unlearning. MLLMU-Bench consists of 500 fictitious profiles
and 153 profiles for public celebrities, each profile feature over 14
customized question-answer pairs, evaluated from both multimodal (image+text)
and unimodal (text) perspectives. The benchmark is divided into four sets to
assess unlearning algorithms in terms of efficacy, generalizability, and model
utility. Finally, we provide baseline results using existing generative model
unlearning algorithms. Surprisingly, our experiments show that unimodal
unlearning algorithms excel in generation and cloze tasks, while multimodal
unlearning approaches perform better in classification tasks with multimodal
inputs.

摘要：大型語言模型 (LLM) 和多模態大型語言模型 (MLLM) 等生成模型在海量網路語料庫上訓練，可能會記住並揭露個人機密和私人資料，引發法律和倫理問題。雖然許多先前的工作已透過機器忘記解決 LLM 中的這個問題，但對於 MLLM 來說仍未廣泛探討。為了應對這個挑戰，我們引進多模態大型語言模型忘記基準 (MLLMU-Bench)，這是一個新基準，旨在促進對多模態機器忘記的理解。MLLMU-Bench 包含 500 個虛構個人資料和 153 個公開名人個人資料，每個個人資料功能超過 14 個自訂問答配對，從多模態 (影像 + 文字) 和單模態 (文字) 角度進行評估。該基準分為四組，以評估忘記演算法在效能、概括性、和模型實用性方面的表現。最後，我們使用現有的生成模型忘記演算法提供基準結果。令人驚訝的是，我們的實驗顯示單模態忘記演算法在生成和完形填空任務中表現出色，而多模態忘記方法在具有多模態輸入的分類任務中表現較好。

##### **Joint Extraction and Classification of Danish Competences for Job Matching**
2410.22103v1 by Qiuchi Li, Christina Lioma

The matching of competences, such as skills, occupations or knowledges, is a
key desiderata for candidates to be fit for jobs. Automatic extraction of
competences from CVs and Jobs can greatly promote recruiters' productivity in
locating relevant candidates for job vacancies. This work presents the first
model that jointly extracts and classifies competence from Danish job postings.
Different from existing works on skill extraction and skill classification, our
model is trained on a large volume of annotated Danish corpora and is capable
of extracting a wide range of Danish competences, including skills, occupations
and knowledges of different categories. More importantly, as a single BERT-like
architecture for joint extraction and classification, our model is lightweight
and efficient at inference. On a real-scenario job matching dataset, our model
beats the state-of-the-art models in the overall performance of Danish
competence extraction and classification, and saves over 50% time at inference.

摘要：技能、職業或知識等能力的匹配是求職者適任工作的關鍵要素。從履歷和工作中自動提取能力可大幅提升招募人員在尋找職缺相關求職者時的生產力。本研究提出第一個模型，可同時從丹麥工作職缺中提取和分類能力。與現有的技能提取和技能分類工作不同，我們的模型是在大量的丹麥語語料庫標註上訓練，並能夠提取廣泛的丹麥語能力，包括不同類別的技能、職業和知識。更重要的是，作為一個用於聯合提取和分類的單一 BERT 類架構，我們的模型輕量且在推理時有效率。在實際場景的工作匹配資料集上，我們的模型在丹麥語能力提取和分類的整體表現上優於最先進的模型，並在推理時節省超過 50% 的時間。

##### **Hyperspectral Imaging-Based Perception in Autonomous Driving Scenarios: Benchmarking Baseline Semantic Segmentation Models**
2410.22101v1 by Imad Ali Shah, Jiarong Li, Martin Glavin, Edward Jones, Enda Ward, Brian Deegan

Hyperspectral Imaging (HSI) is known for its advantages over traditional RGB
imaging in remote sensing, agriculture, and medicine. Recently, it has gained
attention for enhancing Advanced Driving Assistance Systems (ADAS) perception.
Several HSI datasets such as HyKo, HSI-Drive, HSI-Road, and Hyperspectral City
have been made available. However, a comprehensive evaluation of semantic
segmentation models (SSM) using these datasets is lacking. To address this gap,
we evaluated the available annotated HSI datasets on four deep learning-based
baseline SSMs: DeepLab v3+, HRNet, PSPNet, and U-Net, along with its two
variants: Coordinate Attention (UNet-CA) and Convolutional Block-Attention
Module (UNet-CBAM). The original model architectures were adapted to handle the
varying spatial and spectral dimensions of the datasets. These baseline SSMs
were trained using a class-weighted loss function for individual HSI datasets
and evaluated using mean-based metrics such as intersection over union (IoU),
recall, precision, F1 score, specificity, and accuracy. Our results indicate
that UNet-CBAM, which extracts channel-wise features, outperforms other SSMs
and shows potential to leverage spectral information for enhanced semantic
segmentation. This study establishes a baseline SSM benchmark on available
annotated datasets for future evaluation of HSI-based ADAS perception. However,
limitations of current HSI datasets, such as limited dataset size, high class
imbalance, and lack of fine-grained annotations, remain significant constraints
for developing robust SSMs for ADAS applications.

摘要：<paragraph>高光谱成像 (HSI) 以其在遥感、农业和医学领域优于传统 RGB 成像的优势而闻名。最近，它因增强高级驾驶辅助系统 (ADAS) 感知而备受关注。HyKo、HSI-Drive、HSI-Road 和 Hyperspectral City 等多组 HSI 数据集已可供使用。然而，目前缺乏使用这些数据集对语义分割模型 (SSM) 进行综合评估。为了解决这一差距，我们对现有的带注释 HSI 数据集进行了评估，评估了四种基于深度学习的基线 SSM：DeepLab v3+、HRNet、PSPNet 和 U-Net，以及它的两个变体：坐标注意力 (UNet-CA) 和卷积块注意力模块 (UNet-CBAM)。原始模型架构经过调整，以处理数据集变化的空间和光谱维度。这些基线 SSM 使用针对各个 HSI 数据集的类别加权损失函数进行训练，并使用基于均值的指标（如交并比 (IoU)、召回率、精确率、F1 分数、特异性和准确性）进行评估。我们的结果表明，提取通道特征的 UNet-CBAM 优于其他 SSM，并显示出利用光谱信息增强语义分割的潜力。本研究为基于 HSI 的 ADAS 感知未来评估建立了一个基线 SSM 基准。然而，当前 HSI 数据集的局限性，例如数据集大小有限、类别不平衡严重以及缺乏细粒度注释，仍然是针对 ADAS 应用开发强大 SSM 的重大制约因素。</paragraph>

##### **TractShapeNet: Efficient Multi-Shape Learning with 3D Tractography Point Clouds**
2410.22099v1 by Yui Lo, Yuqian Chen, Dongnan Liu, Jon Haitz Legarreta, Leo Zekelman, Fan Zhang, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Weidong Cai, Lauren J. O'Donnell

Brain imaging studies have demonstrated that diffusion MRI tractography
geometric shape descriptors can inform the study of the brain's white matter
pathways and their relationship to brain function. In this work, we investigate
the possibility of utilizing a deep learning model to compute shape measures of
the brain's white matter connections. We introduce a novel framework,
TractShapeNet, that leverages a point cloud representation of tractography to
compute five shape measures: length, span, volume, total surface area, and
irregularity. We assess the performance of the method on a large dataset
including 1065 healthy young adults. Experiments for shape measure computation
demonstrate that our proposed TractShapeNet outperforms other point cloud-based
neural network models in both the Pearson correlation coefficient and
normalized error metrics. We compare the inference runtime results with the
conventional shape computation tool DSI-Studio. Our results demonstrate that a
deep learning approach enables faster and more efficient shape measure
computation. We also conduct experiments on two downstream language cognition
prediction tasks, showing that shape measures from TractShapeNet perform
similarly to those computed by DSI-Studio. Our code will be available at:
https://github.com/SlicerDMRI/TractShapeNet.

摘要：腦部影像研究已證實，擴散磁振造影纖維追蹤
幾何形狀描述符可為腦部白質
路徑及其與腦部功能的關係研究提供資訊。在此研究中，我們探討
利用深度學習模型來計算腦部白質連接的形狀測量值的可能性。我們介紹一個創新的架構，
TractShapeNet，它利用纖維追蹤的點雲表示法來
計算五個形狀測量值：長度、跨度、體積、總表面積和
不規則性。我們在一個包含 1065 名健康年輕人的大型資料集上評估該方法的效能。形狀測量值計算的實驗
證明我們提出的 TractShapeNet 在 Pearson 相關係數和
標準化誤差指標方面優於其他基於點雲的神經網路模型。我們將推論執行時間結果與
傳統形狀計算工具 DSI-Studio 進行比較。我們的結果證明深度學習方法能實現更快、更有效率的形狀測量值
計算。我們還對兩個下游語言認知預測任務進行實驗，結果顯示 TractShapeNet 的形狀測量值執行
類似於 DSI-Studio 計算的形狀測量值。我們的程式碼將可在以下位置取得：
https://github.com/SlicerDMRI/TractShapeNet。

##### **Unlearning as multi-task optimization: A normalized gradient difference approach with an adaptive learning rate**
2410.22086v1 by Zhiqi Bu, Xiaomeng Jin, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Mingyi Hong

Machine unlearning has been used to remove unwanted knowledge acquired by
large language models (LLMs). In this paper, we examine machine unlearning from
an optimization perspective, framing it as a regularized multi-task
optimization problem, where one task optimizes a forgetting objective and
another optimizes the model performance. In particular, we introduce a
normalized gradient difference (NGDiff) algorithm, enabling us to have better
control over the trade-off between the objectives, while integrating a new,
automatic learning rate scheduler. We provide a theoretical analysis and
empirically demonstrate the superior performance of NGDiff among
state-of-the-art unlearning methods on the TOFU and MUSE datasets while
exhibiting stable training.

摘要：機器去學習已被用於移除大型語言模型 (LLM) 習得的不想要的知識。在本文中，我們從最佳化的角度探討機器去學習，並將其建構為一個正則化的多任務最佳化問題，其中一個任務最佳化遺忘目標，另一個任務最佳化模型效能。特別是，我們引入一個正規化梯度差異 (NGDiff) 演算法，使我們能夠更好地控制目標之間的取捨，同時整合一個新的自動學習率排程器。我們提供了理論分析，並在 TOFU 和 MUSE 資料集上實證展示了 NGDiff 在最先進的去學習方法中的優異效能，同時展現穩定的訓練。

##### **Choosy Babies Need One Coach: Inducing Mode-Seeking Behavior in BabyLlama with Reverse KL Divergence**
2410.22081v1 by Shaozhen Shi, Yevgen Matusevych, Malvina Nissim

This study presents our submission to the Strict-Small Track of the 2nd
BabyLM Challenge. We use a teacher-student distillation setup with the
BabyLLaMa model (Timiryasov and Tastet, 2023) as a backbone. To make the
student's learning process more focused, we replace the objective function with
a reverse Kullback-Leibler divergence, known to cause mode-seeking (rather than
mode-averaging) behaviour in computational learners. We further experiment with
having a single teacher (instead of an ensemble of two teachers) and implement
additional optimization strategies to improve the distillation process. Our
experiments show that under reverse KL divergence, a single-teacher model often
outperforms or matches multiple-teacher models across most tasks. Additionally,
incorporating advanced optimization techniques further enhances model
performance, demonstrating the effectiveness and robustness of our proposed
approach. These findings support our idea that "choosy babies need one coach".

摘要：本研究展示了我們對第二屆 BabyLM 挑戰賽的嚴格小型賽道的提交。我們使用教師-學生蒸餾設置，以 BabyLLaMa 模型（Timiryasov 和 Tastet，2023 年）作為骨幹。為了讓學生的學習過程更加專注，我們用反向 Kullback-Leibler 散度取代目標函數，已知這會導致計算學習者的模式尋求（而非模式平均）行為。我們進一步嘗試擁有一個單一教師（而不是兩個教師的集合），並實施額外的最佳化策略來改善蒸餾過程。我們的實驗表明，在反向 KL 散度下，單教師模型通常在大部分任務中優於或匹配多教師模型。此外，結合先進的最佳化技術進一步增強了模型效能，證明了我們提出的方法的有效性和穩健性。這些發現支持了我們的觀點，即「挑剔的嬰兒需要一位教練」。

##### **Mapping the Neuro-Symbolic AI Landscape by Architectures: A Handbook on Augmenting Deep Learning Through Symbolic Reasoning**
2410.22077v1 by Jonathan Feldstein, Paulius Dilkas, Vaishak Belle, Efthymia Tsamoura

Integrating symbolic techniques with statistical ones is a long-standing
problem in artificial intelligence. The motivation is that the strengths of
either area match the weaknesses of the other, and $\unicode{x2013}$ by
combining the two $\unicode{x2013}$ the weaknesses of either method can be
limited. Neuro-symbolic AI focuses on this integration where the statistical
methods are in particular neural networks. In recent years, there has been
significant progress in this research field, where neuro-symbolic systems
outperformed logical or neural models alone. Yet, neuro-symbolic AI is,
comparatively speaking, still in its infancy and has not been widely adopted by
machine learning practitioners. In this survey, we present the first mapping of
neuro-symbolic techniques into families of frameworks based on their
architectures, with several benefits: Firstly, it allows us to link different
strengths of frameworks to their respective architectures. Secondly, it allows
us to illustrate how engineers can augment their neural networks while treating
the symbolic methods as black-boxes. Thirdly, it allows us to map most of the
field so that future researchers can identify closely related frameworks.

摘要：將符號技術與統計技術整合在一起，是人工智慧領域中長久以來的問題。動機在於，任一領域的優勢可以彌補另一領域的劣勢，而透過結合兩者，任一方法的劣勢都可以受到限制。神經符號 AI 專注於此整合，其中統計方法特別是神經網路。近年來，此研究領域有顯著進展，其中神經符號系統的表現優於邏輯或神經模型。然而，就比較而言，神經符號 AI 仍處於起步階段，尚未被機器學習從業人員廣泛採用。在此調查中，我們根據架構將神經符號技術首次對應到架構家族中，並帶來多項好處：首先，它讓我們得以將架構的不同優勢連結到其各自的架構。其次，它讓我們得以說明工程師如何擴充其神經網路，同時將符號方法視為黑盒子。第三，它讓我們得以對應大部分領域，以便未來的研究人員可以找出密切相關的架構。

##### **Distinguishing Ignorance from Error in LLM Hallucinations**
2410.22071v1 by Adi Simhi, Jonathan Herzig, Idan Szpektor, Yonatan Belinkov

Large language models (LLMs) are susceptible to hallucinations-outputs that
are ungrounded, factually incorrect, or inconsistent with prior generations. We
focus on close-book Question Answering (CBQA), where previous work has not
fully addressed the distinction between two possible kinds of hallucinations,
namely, whether the model (1) does not hold the correct answer in its
parameters or (2) answers incorrectly despite having the required knowledge. We
argue that distinguishing these cases is crucial for detecting and mitigating
hallucinations. Specifically, case (2) may be mitigated by intervening in the
model's internal computation, as the knowledge resides within the model's
parameters. In contrast, in case (1) there is no parametric knowledge to
leverage for mitigation, so it should be addressed by resorting to an external
knowledge source or abstaining. To help distinguish between the two cases, we
introduce Wrong Answer despite having Correct Knowledge (WACK), an approach for
constructing model-specific datasets for the second hallucination type. Our
probing experiments indicate that the two kinds of hallucinations are
represented differently in the model's inner states. Next, we show that
datasets constructed using WACK exhibit variations across models, demonstrating
that even when models share knowledge of certain facts, they still vary in the
specific examples that lead to hallucinations. Finally, we show that training a
probe on our WACK datasets leads to better hallucination detection of case (2)
hallucinations than using the common generic one-size-fits-all datasets. The
code is available at
https://github.com/technion-cs-nlp/hallucination-mitigation .

摘要：<paragraph>大型語言模型 (LLM) 容易出現幻覺輸出，這些輸出沒有根據、事實不正確或與先前的世代不一致。我們專注於閉卷問答 (CBQA)，其中先前的研究尚未完全解決兩種可能的幻覺之間的區別，即模型 (1) 沒有在其參數中保存正確的答案，或 (2) 儘管擁有必要的知識，但回答不正確。我們認為區分這些情況對於檢測和減輕幻覺至關重要。具體來說，案例 (2) 可以通過干預模型的內部計算來減輕，因為知識存在於模型的參數中。相比之下，在案例 (1) 中沒有參數知識可以利用來減輕，因此應該訴諸於外部知識來源或放棄。為了幫助區分這兩種情況，我們引入了錯誤答案儘管有正確知識 (WACK)，這是一種為第二種類型的幻覺構建特定於模型的數據集的方法。我們的探測實驗表明，這兩種幻覺在模型的內部狀態中以不同的方式表示。接下來，我們展示了使用 WACK 構建的數據集在模型之間表現出差異，這表明即使模型共享某些事實的知識，它們在導致幻覺的具體示例中仍然有所不同。最後，我們展示了在我們的 WACK 數據集上訓練探測器比使用通用的通用統一數據集能更好地檢測案例 (2) 幻覺。代碼可在
https://github.com/technion-cs-nlp/hallucination-mitigation 獲得。</paragraph>

##### **Sing it, Narrate it: Quality Musical Lyrics Translation**
2410.22066v1 by Zhuorui Ye, Jinhan Li, Rongwu Xu

Translating lyrics for musicals presents unique challenges due to the need to
ensure high translation quality while adhering to singability requirements such
as length and rhyme. Existing song translation approaches often prioritize
these singability constraints at the expense of translation quality, which is
crucial for musicals. This paper aims to enhance translation quality while
maintaining key singability features. Our method consists of three main
components. First, we create a dataset to train reward models for the automatic
evaluation of translation quality. Second, to enhance both singability and
translation quality, we implement a two-stage training process with filtering
techniques. Finally, we introduce an inference-time optimization framework for
translating entire songs. Extensive experiments, including both automatic and
human evaluations, demonstrate significant improvements over baseline methods
and validate the effectiveness of each component in our approach.

摘要：翻譯音樂劇歌詞時會遇到獨特的挑戰，因為需要確保翻譯品質，同時還要符合歌唱性需求，例如長度和押韻。現有的歌曲翻譯方法通常會優先考慮這些歌唱性限制，而犧牲了翻譯品質，這對音樂劇來說至關重要。本文旨在提升翻譯品質，同時維持關鍵的歌唱性特徵。我們的做法包含三個主要部分。首先，我們建立一個資料集，用於訓練自動評量翻譯品質的獎勵模型。其次，為了提升歌唱性和翻譯品質，我們實作一個兩階段訓練流程，並使用過濾技術。最後，我們引入一個推論時間最佳化架構，用於翻譯整首歌曲。廣泛的實驗，包括自動評量和人工評量，證明我們的做法優於基線方法，並驗證了我們做法中每個部分的有效性。

##### **Are VLMs Really Blind**
2410.22029v1 by Ayush Singh, Mansi Gupta, Shivank Garg

Vision Language Models excel in handling a wide range of complex tasks,
including Optical Character Recognition (OCR), Visual Question Answering (VQA),
and advanced geometric reasoning. However, these models fail to perform well on
low-level basic visual tasks which are especially easy for humans. Our goal in
this work was to determine if these models are truly "blind" to geometric
reasoning or if there are ways to enhance their capabilities in this area. Our
work presents a novel automatic pipeline designed to extract key information
from images in response to specific questions. Instead of just relying on
direct VQA, we use question-derived keywords to create a caption that
highlights important details in the image related to the question. This caption
is then used by a language model to provide a precise answer to the question
without requiring external fine-tuning.

摘要：視覺語言模型擅長處理各種複雜任務，
包括光學字元辨識 (OCR)、視覺問答 (VQA)
以及進階幾何推理。然而，這些模型在
低階的基本視覺任務上表現不佳，而這些任務對人類來說特別容易。我們在
這項工作中的目標是確定這些模型是否真的對幾何
推理「視而不見」，或者是否有方法來增強它們在這個領域的能力。我們的
工作提出了一種新穎的自動化管道，旨在從影像中萃取出關鍵資訊
以回應特定問題。我們不只依賴直接的 VQA，還使用問題衍生的關鍵字來建立一個標題，
以強調影像中與問題相關的重要細節。然後語言模型會使用這個標題
提供一個精確的答案，而不需要外部微調。

##### **Path-based summary explanations for graph recommenders -- extended version**
2410.22020v1 by Danae Pla Karidi, Evaggelia Pitoura

Path-based explanations provide intrinsic insights into graph-based
recommendation models. However, most previous work has focused on explaining an
individual recommendation of an item to a user. In this paper, we propose
summary explanations, i.e., explanations that highlight why a user or a group
of users receive a set of item recommendations and why an item, or a group of
items, is recommended to a set of users as an effective means to provide
insights into the collective behavior of the recommender. We also present a
novel method to summarize explanations using efficient graph algorithms,
specifically the Steiner Tree and the Prize-Collecting Steiner Tree. Our
approach reduces the size and complexity of summary explanations while
preserving essential information, making explanations more comprehensible for
users and more useful to model developers. Evaluations across multiple metrics
demonstrate that our summaries outperform baseline explanation methods in most
scenarios, in a variety of quality aspects.

摘要：基於路徑的解釋提供對基於圖形的推薦模型的內在見解。然而，大多數以前的工作都專注於向使用者解釋對某個項目的個別推薦。在本文中，我們提出摘要解釋，即解釋強調為何使用者或一組使用者收到一組項目推薦，以及為何將項目或一組項目推薦給一組使用者，作為提供對推薦者的集體行為的見解的有效方法。我們還提出了一種使用有效圖形演算法，特別是 Steiner 樹和獎勵收集 Steiner 樹，來總結解釋的新方法。我們的做法減少了摘要解釋的大小和複雜性，同時保留了基本資訊，使解釋對使用者來說更易於理解，對模型開發人員來說更有用。跨多個指標的評估表明，我們的摘要在各種品質方面，在大多數情況下都優於基線解釋方法。

##### **Modeling Temporal Positive and Negative Excitation for Sequential Recommendation**
2410.22013v1 by Chengkai Huang, Shoujin Wang, Xianzhi Wang, Lina Yao

Sequential recommendation aims to predict the next item which interests users
via modeling their interest in items over time. Most of the existing works on
sequential recommendation model users' dynamic interest in specific items while
overlooking users' static interest revealed by some static attribute
information of items, e.g., category, or brand. Moreover, existing works often
only consider the positive excitation of a user's historical interactions on
his/her next choice on candidate items while ignoring the commonly existing
negative excitation, resulting in insufficient modeling dynamic interest. The
overlook of static interest and negative excitation will lead to incomplete
interest modeling and thus impede the recommendation performance. To this end,
in this paper, we propose modeling both static interest and negative excitation
for dynamic interest to further improve the recommendation performance.
Accordingly, we design a novel Static-Dynamic Interest Learning (SDIL)
framework featured with a novel Temporal Positive and Negative Excitation
Modeling (TPNE) module for accurate sequential recommendation. TPNE is
specially designed for comprehensively modeling dynamic interest based on
temporal positive and negative excitation learning. Extensive experiments on
three real-world datasets show that SDIL can effectively capture both static
and dynamic interest and outperforms state-of-the-art baselines.

摘要：序列推薦旨在預測使用者感興趣的下一項，並透過建模他們對商品的興趣來預測。現有的大部分序列推薦模型使用者對特定商品的動態興趣，同時忽略使用者透過商品的某些靜態屬性資訊（例如類別或品牌）所揭示的靜態興趣。此外，現有模型通常只考慮使用者過往互動對其在候選商品上的下一個選擇的正面激勵，而忽略普遍存在的負面激勵，導致動態興趣建模不足。忽視靜態興趣和負面激勵將導致不完整的興趣建模，進而阻礙推薦效能。因此，在本文中，我們提出對靜態興趣和負面激勵進行建模，以進一步提升推薦效能。相應地，我們設計了一個新穎的靜態動態興趣學習 (SDIL) 框架，其特點是採用新穎的時序正負激勵建模 (TPNE) 模組，用於精準的序列推薦。TPNE 專門設計用於根據時序正負激勵學習，全面建模動態興趣。在三個真實世界資料集上進行的廣泛實驗表明，SDIL 可以有效捕捉靜態和動態興趣，並且優於最先進的基準。

##### **From Explicit Rules to Implicit Reasoning in an Interpretable Violence Monitoring System**
2410.21991v1 by Wen-Dong Jiang, Chih-Yung Chang, Hsiang-Chuan Chang, Diptendu Sinha Roy

Recently, research based on pre-trained models has demonstrated outstanding
performance in violence surveillance tasks. However, these black-box systems
face challenges regarding explainability during training and inference
processes. An important question is how to incorporate explicit knowledge into
these implicit models, thereby designing expert-driven and interpretable
violence surveillance systems. This paper proposes a new paradigm for weakly
supervised violence monitoring (WSVM) called Rule base Violence monitoring
(RuleVM). The proposed RuleVM uses a dual-branch structure for different
designs for images and text. One of the branches is called the implicit branch,
which uses only visual features for coarse-grained binary classification. In
this branch, image feature extraction is divided into two channels: one
responsible for extracting scene frames and the other focusing on extracting
actions. The other branch is called the explicit branch, which utilizes
language-image alignment to perform fine-grained classification. For the
language channel design in the explicit branch, the proposed RuleCLIP uses the
state-of-the-art YOLO-World model to detect objects and actions in video
frames, and association rules are identified through data mining methods as
descriptions of the video. Leveraging the dual-branch architecture, RuleVM
achieves interpretable coarse-grained and fine-grained violence surveillance.
Extensive experiments were conducted on two commonly used benchmarks, and the
results show that RuleCLIP achieved the best performance in both coarse-grained
and fine-grained detection, significantly outperforming existing
state-of-the-art methods. Moreover, interpretability experiments uncovered some
interesting rules, such as the observation that as the number of people
increases, the risk level of violent behavior also rises.

摘要：<paragraph>最近，基于预训练模型的研究已在暴力监控任务中展现出杰出的表现。然而，这些黑盒系统在训练和推理过程中面临着解释能力方面的挑战。一个重要的问题是如何将显式知识融入到这些隐式模型中，从而设计出专家驱动的、可解释的暴力监控系统。本文提出了一种用于弱监督暴力监控 (WSVM) 的新范式，称为基于规则的暴力监控 (RuleVM)。所提出的 RuleVM 使用双分支结构，对图像和文本采用不同的设计。其中一个分支称为隐式分支，它仅使用视觉特征进行粗粒度二元分类。在这个分支中，图像特征提取被分成两个通道：一个负责提取场景帧，另一个专注于提取动作。另一个分支称为显式分支，它利用语言图像对齐来执行细粒度分类。对于显式分支中的语言通道设计，所提出的 RuleCLIP 使用最先进的 YOLO-World 模型来检测视频帧中的对象和动作，并且通过数据挖掘方法将关联规则标识为视频的描述。利用双分支架构，RuleVM 实现了解释性粗粒度和细粒度暴力监控。在两个常用的基准上进行了广泛的实验，结果表明，RuleCLIP 在粗粒度和细粒度检测方面都取得了最佳性能，明显优于现有的最先进方法。此外，可解释性实验揭示了一些有趣的规则，例如观察到随着人数的增加，暴力行为的风险等级也会上升。</paragraph>

##### **Not All Languages are Equal: Insights into Multilingual Retrieval-Augmented Generation**
2410.21970v1 by Suhang Wu, Jialong Tang, Baosong Yang, Ante Wang, Kaidi Jia, Jiawei Yu, Junfeng Yao, Jinsong Su

RALMs (Retrieval-Augmented Language Models) broaden their knowledge scope by
incorporating external textual resources. However, the multilingual nature of
global knowledge necessitates RALMs to handle diverse languages, a topic that
has received limited research focus. In this work, we propose
\textit{Futurepedia}, a carefully crafted benchmark containing parallel texts
across eight representative languages. We evaluate six multilingual RALMs using
our benchmark to explore the challenges of multilingual RALMs. Experimental
results reveal linguistic inequalities: 1) high-resource languages stand out in
Monolingual Knowledge Extraction; 2) Indo-European languages lead RALMs to
provide answers directly from documents, alleviating the challenge of
expressing answers across languages; 3) English benefits from RALMs' selection
bias and speaks louder in multilingual knowledge selection. Based on these
findings, we offer advice for improving multilingual Retrieval Augmented
Generation. For monolingual knowledge extraction, careful attention must be
paid to cascading errors from translating low-resource languages into
high-resource ones. In cross-lingual knowledge transfer, encouraging RALMs to
provide answers within documents in different languages can improve transfer
performance. For multilingual knowledge selection, incorporating more
non-English documents and repositioning English documents can help mitigate
RALMs' selection bias. Through comprehensive experiments, we underscore the
complexities inherent in multilingual RALMs and offer valuable insights for
future research.

摘要：RALM（检索增强语言模型）通过整合外部文本资源来扩大其知识范围。然而，全球知识的多语言性质要求 RALM 处理多种语言，这是一个研究重点有限的主题。在这项工作中，我们提出了一个精心制作的基准，其中包含八种代表性语言的平行文本。我们使用基准评估六个多语言 RALM，以探索多语言 RALM 的挑战。实验结果揭示了语言不平等：1）高资源语言在单语知识提取中脱颖而出；2）印欧语言导致 RALM 直接从文档中提供答案，从而减轻了跨语言表达答案的挑战；3）英语受益于 RALM 的选择偏差，在多语言知识选择中更有发言权。基于这些发现，我们为改进多语言检索增强生成提供建议。对于单语知识提取，必须仔细注意将低资源语言翻译成高资源语言时级联错误。在跨语言知识转移中，鼓励 RALM 在不同语言的文档中提供答案可以提高转移性能。对于多语言知识选择，纳入更多非英语文档并重新定位英语文档有助于减轻 RALM 的选择偏差。通过综合实验，我们强调了多语言 RALM 中固有的复杂性，并为未来的研究提供了宝贵的见解。

##### **Automated Vulnerability Detection Using Deep Learning Technique**
2410.21968v1 by Guan-Yan Yang, Yi-Heng Ko, Farn Wang, Kuo-Hui Yeh, Haw-Shiang Chang, Hsueh-Yi Chen

Our work explores the utilization of deep learning, specifically leveraging
the CodeBERT model, to enhance code security testing for Python applications by
detecting SQL injection vulnerabilities. Unlike traditional security testing
methods that may be slow and error-prone, our approach transforms source code
into vector representations and trains a Long Short-Term Memory (LSTM) model to
identify vulnerable patterns. When compared with existing static application
security testing (SAST) tools, our model displays superior performance,
achieving higher precision, recall, and F1-score. The study demonstrates that
deep learning techniques, particularly with CodeBERT's advanced contextual
understanding, can significantly improve vulnerability detection, presenting a
scalable methodology applicable to various programming languages and
vulnerability types.

摘要：我們的研究探討利用深度學習，特別是利用 CodeBERT 模型，透過偵測 SQL 注入漏洞來增強 Python 應用程式的程式碼安全性測試。與可能緩慢且容易出錯的傳統安全性測試方法不同，我們的做法將原始程式碼轉換為向量表示，並訓練一個長短期記憶 (LSTM) 模型來識別容易受到攻擊的模式。與現有的靜態應用程式安全性測試 (SAST) 工具相比，我們的模型展現出優異的效能，達到了更高的準確度、召回率和 F1 分數。這項研究證明了深度學習技術，特別是 CodeBERT 的進階脈絡理解，可以顯著改善漏洞偵測，提供一個可擴充的方法，適用於各種程式語言和漏洞類型。

##### **Dual Conditional Diffusion Models for Sequential Recommendation**
2410.21967v1 by Hongtao Huang, Chengkai Huang, Xiaojun Chang, Wen Hu, Lina Yao

Recent advancements in diffusion models have shown promising results in
sequential recommendation (SR). However, current diffusion-based methods still
exhibit two key limitations. First, they implicitly model the diffusion process
for target item embeddings rather than the discrete target item itself, leading
to inconsistency in the recommendation process. Second, existing methods rely
on either implicit or explicit conditional diffusion models, limiting their
ability to fully capture the context of user behavior and leading to less
robust target item embeddings. In this paper, we propose the Dual Conditional
Diffusion Models for Sequential Recommendation (DCRec), introducing a
discrete-to-continuous sequential recommendation diffusion framework. Our
framework introduces a complete Markov chain to model the transition from the
reversed target item representation to the discrete item index, bridging the
discrete and continuous item spaces for diffusion models and ensuring
consistency with the diffusion framework. Building on this framework, we
present the Dual Conditional Diffusion Transformer (DCDT) that incorporates the
implicit conditional and the explicit conditional for diffusion-based SR.
Extensive experiments on public benchmark datasets demonstrate that DCRec
outperforms state-of-the-art methods.

摘要：最近在扩散模型中的突破性进展已在顺序推荐 (SR) 中展现出有希望的结果。然而，目前基于扩散的方法仍存在两个关键限制。首先，它们隐式地为目标项目嵌入建模扩散过程，而不是离散的目标项目本身，导致推荐过程中的不一致性。其次，现有方法依赖于隐式或显式的条件扩散模型，限制了它们充分捕捉用户行为背景的能力，并导致目标项目嵌入的鲁棒性降低。在本文中，我们提出了顺序推荐的双条件扩散模型 (DCRec)，引入了离散到连续的顺序推荐扩散框架。我们的框架引入了一个完整的马尔可夫链来建模从逆向目标项目表示到离散项目索引的转换，弥合了扩散模型的离散和连续项目空间，并确保与扩散框架的一致性。在此框架的基础上，我们提出了双条件扩散变压器 (DCDT)，它将隐式条件和显式条件纳入基于扩散的 SR。在公共基准数据集上的大量实验表明，DCRec 优于最先进的方法。

##### **SG-Bench: Evaluating LLM Safety Generalization Across Diverse Tasks and Prompt Types**
2410.21965v1 by Yutao Mou, Shikun Zhang, Wei Ye

Ensuring the safety of large language model (LLM) applications is essential
for developing trustworthy artificial intelligence. Current LLM safety
benchmarks have two limitations. First, they focus solely on either
discriminative or generative evaluation paradigms while ignoring their
interconnection. Second, they rely on standardized inputs, overlooking the
effects of widespread prompting techniques, such as system prompts, few-shot
demonstrations, and chain-of-thought prompting. To overcome these issues, we
developed SG-Bench, a novel benchmark to assess the generalization of LLM
safety across various tasks and prompt types. This benchmark integrates both
generative and discriminative evaluation tasks and includes extended data to
examine the impact of prompt engineering and jailbreak on LLM safety. Our
assessment of 3 advanced proprietary LLMs and 10 open-source LLMs with the
benchmark reveals that most LLMs perform worse on discriminative tasks than
generative ones, and are highly susceptible to prompts, indicating poor
generalization in safety alignment. We also explain these findings
quantitatively and qualitatively to provide insights for future research.

摘要：確保大型語言模型 (LLM) 應用程式的安全性對於開發可信賴的人工智慧至關重要。目前的 LLM 安全基準有兩個限制。首先，它們僅專注於歧視性或生成性評估範例，而忽略了它們之間的相互關聯。其次，它們依賴於標準化輸入，忽略了廣泛提示技術的影響，例如系統提示、少次數示範和思考鏈提示。為了克服這些問題，我們開發了 SG-Bench，這是一個新的基準，用於評估 LLM 安全在各種任務和提示類型中的概括性。此基準整合了生成性和歧視性評估任務，並包含了延伸資料，以檢查提示工程和越獄對 LLM 安全性的影響。我們使用此基準評估了 3 個進階專有 LLM 和 10 個開源 LLM，結果顯示，大多數 LLM 在歧視性任務上的表現比生成性任務差，而且極易受到提示的影響，這表示在安全性調整方面概括性不佳。我們也對這些發現進行量化和定性說明，以提供見解供將來的研究使用。

##### **Beyond Text: Optimizing RAG with Multimodal Inputs for Industrial Applications**
2410.21943v1 by Monica Riedler, Stefan Langer

Large Language Models (LLMs) have demonstrated impressive capabilities in
answering questions, but they lack domain-specific knowledge and are prone to
hallucinations. Retrieval Augmented Generation (RAG) is one approach to address
these challenges, while multimodal models are emerging as promising AI
assistants for processing both text and images. In this paper we describe a
series of experiments aimed at determining how to best integrate multimodal
models into RAG systems for the industrial domain. The purpose of the
experiments is to determine whether including images alongside text from
documents within the industrial domain increases RAG performance and to find
the optimal configuration for such a multimodal RAG system. Our experiments
include two approaches for image processing and retrieval, as well as two LLMs
(GPT4-Vision and LLaVA) for answer synthesis. These image processing strategies
involve the use of multimodal embeddings and the generation of textual
summaries from images. We evaluate our experiments with an LLM-as-a-Judge
approach. Our results reveal that multimodal RAG can outperform single-modality
RAG settings, although image retrieval poses a greater challenge than text
retrieval. Additionally, leveraging textual summaries from images presents a
more promising approach compared to the use of multimodal embeddings, providing
more opportunities for future advancements.

摘要：大型語言模型 (LLM) 已展現出令人印象深刻的問答能力，但它們缺乏特定領域的知識，而且容易出現幻覺。檢索擴增生成 (RAG) 是一種解決這些挑戰的方法，而多模態模型正成為處理文字和影像的 AI 助理。在本文中，我們描述了一系列實驗，旨在確定如何最佳整合多模態模型到工業領域的 RAG 系統中。實驗的目的是確定在工業領域的文件中包含影像和文字是否能提升 RAG 的效能，並找出此類多模態 RAG 系統的最佳組態。我們的實驗包含兩種影像處理和檢索方法，以及兩種 LLM（GPT4-Vision 和 LLaVA）用於答案合成。這些影像處理策略涉及使用多模態嵌入和從影像產生文字摘要。我們使用 LLM-as-a-Judge 方法評估我們的實驗。我們的結果顯示，多模態 RAG 能優於單模態 RAG 設定，儘管影像檢索比文字檢索更具挑戰性。此外，與使用多模態嵌入相比，利用影像的文字摘要呈現出更有前景的方法，為未來的進展提供了更多機會。

##### **Benchmarking OpenAI o1 in Cyber Security**
2410.21939v1 by Dan Ristea, Vasilios Mavroudis, Chris Hicks

We evaluate OpenAI's o1-preview and o1-mini models, benchmarking their
performance against the earlier GPT-4o model. Our evaluation focuses on their
ability to detect vulnerabilities in real-world software by generating
structured inputs that trigger known sanitizers. Using DARPA's AI Cyber
Challenge (AIxCC) framework and the Nginx challenge project--a deliberately
modified version of the widely-used Nginx web server--we create a well-defined
yet complex environment for testing LLMs on automated vulnerability detection
(AVD) tasks. Our results show that the o1-preview model significantly
outperforms GPT-4o in both success rate and efficiency, especially in more
complex scenarios.

摘要：我們評估了 OpenAI 的 o1-preview 和 o1-mini 模型，並將其效能與早期的 GPT-4o 模型進行基準測試。我們的評估重點在於它們透過產生會觸發已知 sanitizers 的結構化輸入，來偵測真實世界軟體中的漏洞的能力。我們使用 DARPA 的 AI 網路挑戰 (AIxCC) 架構和 Nginx 挑戰專案，這是廣泛使用的 Nginx 網路伺服器的經過刻意修改的版本，為 LLMs 在自動化漏洞偵測 (AVD) 任務上建立一個定義明確但複雜的環境。我們的結果顯示，o1-preview 模型在成功率和效率上都明顯優於 GPT-4o，尤其是在更複雜的場景中。

##### **LogSHIELD: A Graph-based Real-time Anomaly Detection Framework using Frequency Analysis**
2410.21936v1 by Krishna Chandra Roy, Qian Chen

Anomaly-based cyber threat detection using deep learning is on a constant
growth in popularity for novel cyber-attack detection and forensics. A robust,
efficient, and real-time threat detector in a large-scale operational
enterprise network requires high accuracy, high fidelity, and a high throughput
model to detect malicious activities. Traditional anomaly-based detection
models, however, suffer from high computational overhead and low detection
accuracy, making them unsuitable for real-time threat detection. In this work,
we propose LogSHIELD, a highly effective graph-based anomaly detection model in
host data. We present a real-time threat detection approach using
frequency-domain analysis of provenance graphs. To demonstrate the significance
of graph-based frequency analysis we proposed two approaches. Approach-I uses a
Graph Neural Network (GNN) LogGNN and approach-II performs frequency domain
analysis on graph node samples for graph embedding. Both approaches use a
statistical clustering algorithm for anomaly detection. The proposed models are
evaluated using a large host log dataset consisting of 774M benign logs and
375K malware logs. LogSHIELD explores the provenance graph to extract
contextual and causal relationships among logs, exposing abnormal activities.
It can detect stealthy and sophisticated attacks with over 98% average AUC and
F1 scores. It significantly improves throughput, achieves an average detection
latency of 0.13 seconds, and outperforms state-of-the-art models in detection
time.

摘要：<paragraph>利用深度學習進行異常為基礎的網路威脅偵測，在新型網路攻擊偵測與鑑識方面持續受到重視。大型營運企業網路中強固、有效率且即時的威脅偵測器需要高度準確性、高保真度和高處理量模型才能偵測惡意活動。然而，傳統的異常偵測模型運算量龐大且偵測準確度低，不適合用於即時威脅偵測。在本研究中，我們提出 LogSHIELD，這是一種基於圖形的高度有效異常偵測模型，用於主機資料。我們提出利用來源圖形的頻域分析進行即時威脅偵測方法。為了證明基於圖形的頻率分析的重要性，我們提出了兩種方法。方法一使用圖形神經網路 (GNN) LogGNN，而方法二對圖形節點樣本進行頻域分析，以進行圖形嵌入。兩種方法都使用統計聚類演算法進行異常偵測。我們使用包含 7.74 億個良性記錄和 37.5 萬個惡意軟體記錄的大型主機記錄資料集評估所提出的模型。LogSHIELD 探查來源圖形以擷取記錄之間的脈絡和因果關係，揭露異常活動。它可以偵測隱匿且複雜的攻擊，平均 AUC 和 F1 分數超過 98%。它大幅提升處理量，平均偵測延遲時間為 0.13 秒，且在偵測時間方面優於最先進的模型。</paragraph>

##### **Reliable Semantic Understanding for Real World Zero-shot Object Goal Navigation**
2410.21926v1 by Halil Utku Unlu, Shuaihang Yuan, Congcong Wen, Hao Huang, Anthony Tzes, Yi Fang

We introduce an innovative approach to advancing semantic understanding in
zero-shot object goal navigation (ZS-OGN), enhancing the autonomy of robots in
unfamiliar environments. Traditional reliance on labeled data has been a
limitation for robotic adaptability, which we address by employing a
dual-component framework that integrates a GLIP Vision Language Model for
initial detection and an InstructionBLIP model for validation. This combination
not only refines object and environmental recognition but also fortifies the
semantic interpretation, pivotal for navigational decision-making. Our method,
rigorously tested in both simulated and real-world settings, exhibits marked
improvements in navigation precision and reliability.

摘要：我們引入了一種創新的方法來推進零次學習目標導航 (ZS-OGN) 中的語義理解，增強機器人在不熟悉環境中的自主性。傳統上依賴標記數據一直是機器人適應性的限制，我們通過採用雙組件框架來解決這個問題，該框架整合了 GLIP 視覺語言模型進行初始檢測和 InstructionBLIP 模型進行驗證。這種組合不僅可以優化物體和環境識別，還可以加強語義解釋，這對於導航決策制定至關重要。我們的這種方法在模擬和真實世界環境中都經過了嚴格測試，在導航精度和可靠性方面表現出顯著的改進。

##### **SceneGenAgent: Precise Industrial Scene Generation with Coding Agent**
2410.21909v1 by Xiao Xia, Dan Zhang, Zibo Liao, Zhenyu Hou, Tianrui Sun, Jing Li, Ling Fu, Yuxiao Dong

The modeling of industrial scenes is essential for simulations in industrial
manufacturing. While large language models (LLMs) have shown significant
progress in generating general 3D scenes from textual descriptions, generating
industrial scenes with LLMs poses a unique challenge due to their demand for
precise measurements and positioning, requiring complex planning over spatial
arrangement. To address this challenge, we introduce SceneGenAgent, an
LLM-based agent for generating industrial scenes through C# code. SceneGenAgent
ensures precise layout planning through a structured and calculable format,
layout verification, and iterative refinement to meet the quantitative
requirements of industrial scenarios. Experiment results demonstrate that LLMs
powered by SceneGenAgent exceed their original performance, reaching up to
81.0% success rate in real-world industrial scene generation tasks and
effectively meeting most scene generation requirements. To further enhance
accessibility, we construct SceneInstruct, a dataset designed for fine-tuning
open-source LLMs to integrate into SceneGenAgent. Experiments show that
fine-tuning open-source LLMs on SceneInstruct yields significant performance
improvements, with Llama3.1-70B approaching the capabilities of GPT-4o. Our
code and data are available at https://github.com/THUDM/SceneGenAgent .

摘要：工業場景的建模對於工業製造中的模擬至關重要。雖然大型語言模型 (LLM) 在從文本描述中生成一般 3D 場景方面已展現出顯著進展，但由於工業場景需要精確的測量和定位，因此使用 LLM 生成工業場景會構成獨特的挑戰，需要對空間配置進行複雜的規劃。為了應對這一挑戰，我們引入了 SceneGenAgent，這是一個基於 LLM 的代理，可透過 C# 程式碼生成工業場景。SceneGenAgent 透過結構化且可計算的格式、配置驗證和反覆改進來確保精確的配置規劃，以滿足工業場景的量化需求。實驗結果表明，由 SceneGenAgent 提供支援的 LLM 超越了其原始效能，在真實世界的工業場景生成任務中達到高達 81.0% 的成功率，並有效滿足大多數場景生成需求。為了進一步提高可及性，我們建構了 SceneInstruct，這是一個資料集，旨在微調開源 LLM 以整合到 SceneGenAgent 中。實驗表明，在 SceneInstruct 上微調開源 LLM 會產生顯著的效能提升，其中 Llama3.1-70B 接近 GPT-4o 的能力。我們的程式碼和資料可在 https://github.com/THUDM/SceneGenAgent 取得。

##### **Evaluating K-Fold Cross Validation for Transformer Based Symbolic Regression Models**
2410.21896v1 by Kaustubh Kislay, Shlok Singh, Soham Joshi, Rohan Dutta, Jay Shim George Flint, Kevin Zhu

Symbolic Regression remains an NP-Hard problem, with extensive research
focusing on AI models for this task. Transformer models have shown promise in
Symbolic Regression, but performance suffers with smaller datasets. We propose
applying k-fold cross-validation to a transformer-based symbolic regression
model trained on a significantly reduced dataset (15,000 data points, down from
500,000). This technique partitions the training data into multiple subsets
(folds), iteratively training on some while validating on others. Our aim is to
provide an estimate of model generalization and mitigate overfitting issues
associated with smaller datasets. Results show that this process improves the
model's output consistency and generalization by a relative improvement in
validation loss of 53.31%. Potentially enabling more efficient and accessible
symbolic regression in resource-constrained environments.

摘要：符號回歸仍然是一個 NP-Hard 問題，大量的研究集中在用於此任務的人工智慧模型上。Transformer模型在符號回歸中展現出前景，但效能會隨著資料集變小而下降。我們提議對一個訓練於大幅縮減的資料集（15,000 個資料點，低於 500,000 個）的基於Transformer的符號回歸模型套用 k 折交叉驗證。此技術將訓練資料分割為多個子集（折），反覆在某些子集上訓練，同時在其他子集上驗證。我們的目標是提供模型概化的估計，並減輕與較小資料集相關的過度擬合問題。結果顯示，此程序透過驗證損失的相對改善 53.31%，提升了模型的輸出一致性和概化。在資源受限的環境中，這有潛力讓符號回歸更有效率且更容易取得。

##### **Bayesian Optimization for Hyperparameters Tuning in Neural Networks**
2410.21886v1 by Gabriele Onorato

This study investigates the application of Bayesian Optimization (BO) for the
hyperparameter tuning of neural networks, specifically targeting the
enhancement of Convolutional Neural Networks (CNN) for image classification
tasks. Bayesian Optimization is a derivative-free global optimization method
suitable for expensive black-box functions with continuous inputs and limited
evaluation budgets. The BO algorithm leverages Gaussian Process regression and
acquisition functions like Upper Confidence Bound (UCB) and Expected
Improvement (EI) to identify optimal configurations effectively. Using the Ax
and BOTorch frameworks, this work demonstrates the efficiency of BO in reducing
the number of hyperparameter tuning trials while achieving competitive model
performance. Experimental outcomes reveal that BO effectively balances
exploration and exploitation, converging rapidly towards optimal settings for
CNN architectures. This approach underlines the potential of BO in automating
neural network tuning, contributing to improved accuracy and computational
efficiency in machine learning pipelines.

摘要：本研究探討貝氏最佳化 (BO) 在神經網路超參數調整的應用，特別針對影像分類任務的卷積神經網路 (CNN) 強化。貝氏最佳化是一種無導數的全局最佳化方法，適用於具有連續輸入和有限評估預算的昂貴黑盒函數。BO 演算法利用高斯過程迴歸和取得函數，例如上置信界 (UCB) 和預期改善 (EI)，以有效識別最佳組態。使用 Ax 和 BOTorch 框架，這項工作展示了 BO 在減少超參數調整試驗次數同時達成具競爭力的模型效能方面的效率。實驗結果顯示，BO 有效地平衡探索和開發，快速收斂到 CNN 架構的最佳設定。此方法強調了 BO 在自動化神經網路調整中的潛力，有助於提升機器學習管線中的準確度和運算效率。

##### **Building Altruistic and Moral AI Agent with Brain-inspired Affective Empathy Mechanisms**
2410.21882v1 by Feifei Zhao, Hui Feng, Haibo Tong, Zhengqiang Han, Enmeng Lu, Yinqian Sun, Yi Zeng

As AI closely interacts with human society, it is crucial to ensure that its
decision-making is safe, altruistic, and aligned with human ethical and moral
values. However, existing research on embedding ethical and moral
considerations into AI remains insufficient, and previous external constraints
based on principles and rules are inadequate to provide AI with long-term
stability and generalization capabilities. In contrast, the intrinsic
altruistic motivation based on empathy is more willing, spontaneous, and
robust. Therefore, this paper is dedicated to autonomously driving intelligent
agents to acquire morally behaviors through human-like affective empathy
mechanisms. We draw inspiration from the neural mechanism of human brain's
moral intuitive decision-making, and simulate the mirror neuron system to
construct a brain-inspired affective empathy-driven altruistic decision-making
model. Here, empathy directly impacts dopamine release to form intrinsic
altruistic motivation. Based on the principle of moral utilitarianism, we
design the moral reward function that integrates intrinsic empathy and
extrinsic self-task goals. A comprehensive experimental scenario incorporating
empathetic processes, personal objectives, and altruistic goals is developed.
The proposed model enables the agent to make consistent moral decisions
(prioritizing altruism) by balancing self-interest with the well-being of
others. We further introduce inhibitory neurons to regulate different levels of
empathy and verify the positive correlation between empathy levels and
altruistic preferences, yielding conclusions consistent with findings from
psychological behavioral experiments. This work provides a feasible solution
for the development of ethical AI by leveraging the intrinsic human-like
empathy mechanisms, and contributes to the harmonious coexistence between
humans and AI.

摘要：隨著人工智慧與人類社會密切互動，確保其決策安全、利他且符合人類倫理和道德價值至關重要。然而，現有關於將倫理和道德考量納入人工智慧的研究仍不足，且過去基於原則和規則的外部約束不足以提供人工智慧長期穩定性和泛化能力。相比之下，基於同理心的內在利他動機更為自發、主動且強健。因此，本文致力於透過類人情感同理機制，自主驅動智慧代理人習得道德行為。我們從人腦道德直覺決策的神經機制中汲取靈感，模擬鏡像神經元系統，建構一個以大腦為靈感的、由情感同理驅動的利他決策模型。在此，同理心直接影響多巴胺釋放，形成內在利他動機。基於道德功利主義的原則，我們設計了整合內在同理心和外在自我任務目標的道德獎勵函數。開發了一個包含同理過程、個人目標和利他目標的綜合實驗場景。所提出的模型使代理人能夠透過平衡自身利益與他人的福祉，做出一致的道德決策（優先利他）。我們進一步引入抑制神經元來調節不同層級的同理心，並驗證同理心層級與利他偏好之間的正相關，得出與心理行為實驗結果一致的結論。這項工作透過利用內在類人同理機制為開發倫理人工智慧提供了一個可行的解決方案，並有助於人類與人工智慧之間的和諧共存。

##### **Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning**
2410.21872v1 by Yinyi Lai, Anbo Cao, Yuan Gao, Jiaqi Shang, Zongyu Li, Jia Guo

Early and accurate diagnosis of brain tumors is crucial for improving patient
survival rates. However, the detection and classification of brain tumors are
challenging due to their diverse types and complex morphological
characteristics. This study investigates the application of pre-trained models
for brain tumor classification, with a particular focus on deploying the Mamba
model. We fine-tuned several mainstream transfer learning models and applied
them to the multi-class classification of brain tumors. By comparing these
models to those trained from scratch, we demonstrated the significant
advantages of transfer learning, especially in the medical imaging field, where
annotated data is often limited. Notably, we introduced the Vision Mamba (Vim),
a novel network architecture, and applied it for the first time in brain tumor
classification, achieving exceptional classification accuracy. Experimental
results indicate that the Vim model achieved 100% classification accuracy on an
independent test set, emphasizing its potential for tumor classification tasks.
These findings underscore the effectiveness of transfer learning in brain tumor
classification and reveal that, compared to existing state-of-the-art models,
the Vim model is lightweight, efficient, and highly accurate, offering a new
perspective for clinical applications. Furthermore, the framework proposed in
this study for brain tumor classification, based on transfer learning and the
Vision Mamba model, is broadly applicable to other medical imaging
classification problems.

摘要：腦腫瘤的早期準確診斷對於提高患者存活率至關重要。然而，由於腦腫瘤類型多樣且形態特徵複雜，因此檢測和分類腦腫瘤具有挑戰性。本研究探討了預訓練模型在腦腫瘤分類中的應用，特別關注 Mamba 模型的部署。我們微調了幾個主流的遷移學習模型，並將它們應用於腦腫瘤的多類別分類。通過將這些模型與從頭開始訓練的模型進行比較，我們展示了遷移學習的顯著優勢，特別是在醫療影像領域，那裡的註解數據通常有限。值得注意的是，我們引入了 Vision Mamba (Vim)，這是一種新穎的網路架構，並首次將其應用於腦腫瘤分類中，達到了出色的分類準確率。實驗結果表明，Vim 模型在一個獨立的測試集上達到了 100% 的分類準確率，強調了其在腫瘤分類任務中的潛力。這些發現強調了遷移學習在腦腫瘤分類中的有效性，並揭示了與現有的最先進模型相比，Vim 模型輕量、高效且準確，為臨床應用提供了新的視角。此外，本研究中提出的基於遷移學習和 Vision Mamba 模型的腦腫瘤分類框架廣泛適用於其他醫學影像分類問題。

##### **Cross-Entropy Is All You Need To Invert the Data Generating Process**
2410.21869v1 by Patrik Reizinger, Alice Bizeul, Attila Juhos, Julia E. Vogt, Randall Balestriero, Wieland Brendel, David Klindt

Supervised learning has become a cornerstone of modern machine learning, yet
a comprehensive theory explaining its effectiveness remains elusive. Empirical
phenomena, such as neural analogy-making and the linear representation
hypothesis, suggest that supervised models can learn interpretable factors of
variation in a linear fashion. Recent advances in self-supervised learning,
particularly nonlinear Independent Component Analysis, have shown that these
methods can recover latent structures by inverting the data generating process.
We extend these identifiability results to parametric instance discrimination,
then show how insights transfer to the ubiquitous setting of supervised
learning with cross-entropy minimization. We prove that even in standard
classification tasks, models learn representations of ground-truth factors of
variation up to a linear transformation. We corroborate our theoretical
contribution with a series of empirical studies. First, using simulated data
matching our theoretical assumptions, we demonstrate successful disentanglement
of latent factors. Second, we show that on DisLib, a widely-used
disentanglement benchmark, simple classification tasks recover latent
structures up to linear transformations. Finally, we reveal that models trained
on ImageNet encode representations that permit linear decoding of proxy factors
of variation. Together, our theoretical findings and experiments offer a
compelling explanation for recent observations of linear representations, such
as superposition in neural networks. This work takes a significant step toward
a cohesive theory that accounts for the unreasonable effectiveness of
supervised deep learning.

摘要：監督式學習已成為現代機器學習的基石，但能解釋其有效性的全面理論仍然難以捉摸。經驗現象，例如神經類比製作和線性表示假設，表明監督模型可以線性方式學習可解釋的變異因子。自監督學習的最新進展，特別是非線性獨立成分分析，表明這些方法可以通過反轉數據生成過程來恢復潛在結構。我們將這些可識別性結果擴展到參數實例判別，然後展示如何將見解轉移到使用交叉熵最小化的普遍監督學習設置中。我們證明，即使在標準分類任務中，模型也會學習表示真實變異因子，直到線性轉換。我們用一系列經驗研究證實了我們的理論貢獻。首先，使用符合我們理論假設的模擬數據，我們展示了潛在因子的成功解纏。其次，我們表明，在廣泛使用的解纏基準 DisLib 上，簡單的分類任務可以恢復線性轉換的潛在結構。最後，我們揭示了在 ImageNet 上訓練的模型編碼表示，允許對變異的代理因子進行線性解碼。我們的理論發現和實驗共同為線性表示的最新觀察提供了一個令人信服的解釋，例如神經網路中的疊加。這項工作朝著一個連貫的理論邁出了重要一步，該理論解釋了監督深度學習的異常有效性。

##### **Improving In-Context Learning with Small Language Model Ensembles**
2410.21868v1 by M. Mehdi Mojarradi, Lingyi Yang, Robert McCraith, Adam Mahdi

Large language models (LLMs) have shown impressive capabilities across
various tasks, but their performance on domain-specific tasks remains limited.
While methods like retrieval augmented generation and fine-tuning can help to
address this, they require significant resources. In-context learning (ICL) is
a cheap and efficient alternative but cannot match the accuracies of advanced
methods. We present Ensemble SuperICL, a novel approach that enhances ICL by
leveraging the expertise of multiple fine-tuned small language models (SLMs).
Ensemble SuperICL achieves state of the art (SoTA) results on several natural
language understanding benchmarks. Additionally, we test it on a medical-domain
labelling task and showcase its practicality by using off-the-shelf SLMs
fine-tuned on a general language task, achieving superior accuracy in
large-scale data labelling compared to all baselines. Finally, we conduct an
ablation study and sensitivity analyses to elucidate the underlying mechanism
of Ensemble SuperICL. Our research contributes to the growing demand for
efficient domain specialisation methods in LLMs, offering a cheap and effective
method for practitioners.

摘要：大型語言模型 (LLM) 已在各種任務中展現令人印象深刻的能力，但它們在特定領域任務中的表現仍然有限。雖然像檢索擴充生成和微調等方法可以幫助解決這個問題，但它們需要大量的資源。情境內學習 (ICL) 是一種便宜且有效率的替代方案，但無法匹敵先進方法的準確性。我們提出 Ensemble SuperICL，這是一種創新的方法，它透過利用多個微調小型語言模型 (SLM) 的專業知識來增強 ICL。Ensemble SuperICL 在幾個自然語言理解基準上獲得了最先進 (SoTA) 的結果。此外，我們在醫學領域標籤任務上對它進行了測試，並透過使用在一般語言任務上微調的現成 SLM 來展示它的實用性，在與所有基線相比之下，在大型數據標籤中獲得了更高的準確性。最後，我們進行了消融研究和敏感性分析，以闡明 Ensemble SuperICL 的底層機制。我們的研究有助於滿足對 LLM 中高效領域專業化方法日益增長的需求，為實務工作者提供一種便宜且有效的方法。

##### **Learning Infinitesimal Generators of Continuous Symmetries from Data**
2410.21853v1 by Gyeonghoon Ko, Hyunsu Kim, Juho Lee

Exploiting symmetry inherent in data can significantly improve the sample
efficiency of a learning procedure and the generalization of learned models.
When data clearly reveals underlying symmetry, leveraging this symmetry can
naturally inform the design of model architectures or learning strategies. Yet,
in numerous real-world scenarios, identifying the specific symmetry within a
given data distribution often proves ambiguous. To tackle this, some existing
works learn symmetry in a data-driven manner, parameterizing and learning
expected symmetry through data. However, these methods often rely on explicit
knowledge, such as pre-defined Lie groups, which are typically restricted to
linear or affine transformations. In this paper, we propose a novel symmetry
learning algorithm based on transformations defined with one-parameter groups,
continuously parameterized transformations flowing along the directions of
vector fields called infinitesimal generators. Our method is built upon minimal
inductive biases, encompassing not only commonly utilized symmetries rooted in
Lie groups but also extending to symmetries derived from nonlinear generators.
To learn these symmetries, we introduce a notion of a validity score that
examine whether the transformed data is still valid for the given task. The
validity score is designed to be fully differentiable and easily computable,
enabling effective searches for transformations that achieve symmetries innate
to the data. We apply our method mainly in two domains: image data and partial
differential equations, and demonstrate its advantages. Our codes are available
at \url{https://github.com/kogyeonghoon/learning-symmetry-from-scratch.git}.

摘要：<paragraph>利用資料中固有的對稱性，可以大幅提升學習程序的樣本效率和已學習模型的概括性。當資料清楚揭示出底層對稱性時，利用此對稱性可以自然地告知模型架構或學習策略的設計。然而，在許多真實世界的場景中，識別特定對稱性在給定的資料分佈中通常證明是模稜兩可的。為了解決這個問題，一些現有作品以資料驅動的方式學習對稱性，透過資料參數化和學習預期的對稱性。然而，這些方法通常依賴於明確的知識，例如預先定義的李群，這些知識通常限制於線性或仿射轉換。在本文中，我們提出一個新的對稱性學習演算法，該演算法基於使用單參數群定義的轉換，連續參數化的轉換沿著稱為無限小生成器的向量場的方向流動。我們的演算法建立在最小的歸納偏差上，不僅涵蓋了李群中根植的常用對稱性，還擴展到源自非線性生成器的對稱性。為了學習這些對稱性，我們引入了有效性評分的概念，用於檢查轉換後的資料是否仍然對給定的任務有效。有效性評分被設計為完全可微分且易於計算，能夠有效搜尋實現資料固有對稱性的轉換。我們主要在兩個領域應用我們的演算法：影像資料和偏微分方程式，並展示其優點。我們的程式碼可在\url{https://github.com/kogyeonghoon/learning-symmetry-from-scratch.git}取得。</paragraph>

##### **Joint Beamforming and Speaker-Attributed ASR for Real Distant-Microphone Meeting Transcription**
2410.21849v1 by Can Cui, Imran Ahamad Sheikh, Mostafa Sadeghi, Emmanuel Vincent

Distant-microphone meeting transcription is a challenging task.
State-of-the-art end-to-end speaker-attributed automatic speech recognition
(SA-ASR) architectures lack a multichannel noise and reverberation reduction
front-end, which limits their performance. In this paper, we introduce a joint
beamforming and SA-ASR approach for real meeting transcription. We first
describe a data alignment and augmentation method to pretrain a neural
beamformer on real meeting data. We then compare fixed, hybrid, and fully
neural beamformers as front-ends to the SA-ASR model. Finally, we jointly
optimize the fully neural beamformer and the SA-ASR model. Experiments on the
real AMI corpus show that,while state-of-the-art multi-frame cross-channel
attention based channel fusion fails to improve ASR performance, fine-tuning
SA-ASR on the fixed beamformer's output and jointly fine-tuning SA-ASR with the
neural beamformer reduce the word error rate by 8% and 9% relative,
respectively.

摘要：遠端麥克風會議轉錄是一項具有挑戰性的任務。
最先進的端對端說話者歸因自動語音辨識 (SA-ASR) 架構缺乏多通道噪音和混響降低前端，這限制了它們的效能。在本文中，我們介紹了一種聯合波束成形和 SA-ASR 方法，用於實際會議轉錄。我們首先描述一種資料對齊和擴充方法，以在實際會議資料上預訓練神經波束成形器。然後，我們將固定、混合和完全神經波束成形器作為 SA-ASR 模型的前端進行比較。最後，我們聯合最佳化完全神經波束成形器和 SA-ASR 模型。在實際 AMI 語料庫上的實驗顯示，雖然最先進的多幀跨通道注意力基礎通道融合無法改善 ASR 效能，但針對固定波束成形器輸出進行 SA-ASR 微調，並與神經波束成形器聯合微調 SA-ASR，分別將字元錯誤率降低了 8% 和 9%。

##### **Diffusion as Reasoning: Enhancing Object Goal Navigation with LLM-Biased Diffusion Model**
2410.21842v1 by Yiming Ji, Yang Liu, Zhengpu Wang, Boyu Ma, Zongwu Xie, Hong Liu

The Object Goal Navigation (ObjectNav) task requires the agent to navigate to
a specified target in an unseen environment. Since the environment layout is
unknown, the agent needs to perform semantic reasoning to infer the potential
location of the target, based on its accumulated memory of the environment
during the navigation process. Diffusion models have been shown to be able to
learn the distribution relationships between features in RGB images, and thus
generate new realistic images.In this work, we propose a new approach to
solving the ObjectNav task, by training a diffusion model to learn the
statistical distribution patterns of objects in semantic maps, and using the
map of the explored regions during navigation as the condition to generate the
map of the unknown regions, thereby realizing the semantic reasoning of the
target object, i.e., diffusion as reasoning (DAR). Meanwhile, we propose the
global target bias and local LLM bias methods, where the former can constrain
the diffusion model to generate the target object more effectively, and the
latter utilizes the common sense knowledge extracted from the LLM to improve
the generalization of the reasoning process. Based on the generated map in the
unknown region, the agent sets the predicted location of the target as the goal
and moves towards it. Experiments on Gibson and MP3D show the effectiveness of
our method.

摘要：物件目標導航 (ObjectNav) 任務要求代理在未見環境中導航至指定目標。由於環境佈局未知，代理需要執行語意推理，根據其在導航過程中累積的環境記憶來推論目標的潛在位置。擴散模型已被證明能夠學習 RGB 影像中特徵之間的分布關係，並因此產生新的逼真影像。在這項工作中，我們提出了一種解決 ObjectNav 任務的新方法，透過訓練擴散模型來學習語意地圖中物件的統計分布模式，並使用導航過程中探索區域的地圖作為條件來產生未知區域的地圖，從而實現目標物件的語意推理，即擴散為推理 (DAR)。同時，我們提出了全局目標偏差和局部 LLM 偏差方法，前者可以約束擴散模型更有效地產生目標物件，而後者利用從 LLM 中提取的常識知識來改善推理過程的泛化。基於未知區域中產生的地圖，代理將目標的預測位置設定為目標，並朝向它移動。Gibson 和 MP3D 的實驗顯示了我們方法的有效性。

##### **Self-Preference Bias in LLM-as-a-Judge**
2410.21819v1 by Koki Wataoka, Tsubasa Takahashi, Ryokan Ri

Automated evaluation leveraging large language models (LLMs), commonly
referred to as LLM evaluators or LLM-as-a-judge, has been widely used in
measuring the performance of dialogue systems. However, the self-preference
bias in LLMs has posed significant risks, including promoting specific styles
or policies intrinsic to the LLMs. Despite the importance of this issue, there
is a lack of established methods to measure the self-preference bias
quantitatively, and its underlying causes are poorly understood. In this paper,
we introduce a novel quantitative metric to measure the self-preference bias.
Our experimental results demonstrate that GPT-4 exhibits a significant degree
of self-preference bias. To explore the causes, we hypothesize that LLMs may
favor outputs that are more familiar to them, as indicated by lower perplexity.
We analyze the relationship between LLM evaluations and the perplexities of
outputs. Our findings reveal that LLMs assign significantly higher evaluations
to outputs with lower perplexity than human evaluators, regardless of whether
the outputs were self-generated. This suggests that the essence of the bias
lies in perplexity and that the self-preference bias exists because LLMs prefer
texts more familiar to them.

摘要：利用大型語言模型（LLM）進行自動評估（通常稱為 LLM 評估器或 LLM 作為評審），已廣泛用於衡量對話系統的效能。然而，LLM 中的自我偏好偏差會造成重大風險，包括宣傳 LLM 內在的特定風格或政策。儘管此問題非常重要，但缺乏用於定量衡量自我偏好偏差的既定方法，而且其根本原因鮮為人知。在本文中，我們提出了一種新穎的定量指標來衡量自我偏好偏差。我們的實驗結果證明，GPT-4 表現出顯著程度的自我偏好偏差。為了探討原因，我們假設 LLM 可能偏好對他們來說較熟悉的輸出，這由較低的困惑度所表示。我們分析了 LLM 評估與輸出困惑度之間的關係。我們的發現顯示，LLM 對困惑度較低的輸出給予的評分顯著高於人類評估者，無論輸出是否是由他們自己產生的。這表示偏差的本質在於困惑度，而且自我偏好偏差存在是因為 LLM 偏好對他們來說較熟悉的文字。

##### **Gnothi Seauton: Empowering Faithful Self-Interpretability in Black-Box Models**
2410.21815v1 by Shaobo Wang, Hongxuan Tang, Mingyang Wang, Hongrui Zhang, Xuyang Liu, Weiya Li, Xuming Hu, Linfeng Zhang

The debate between self-interpretable models and post-hoc explanations for
black-box models is central to Explainable AI (XAI). Self-interpretable models,
such as concept-based networks, offer insights by connecting decisions to
human-understandable concepts but often struggle with performance and
scalability. Conversely, post-hoc methods like Shapley values, while
theoretically robust, are computationally expensive and resource-intensive. To
bridge the gap between these two lines of research, we propose a novel method
that combines their strengths, providing theoretically guaranteed
self-interpretability for black-box models without compromising prediction
accuracy. Specifically, we introduce a parameter-efficient pipeline,
*AutoGnothi*, which integrates a small side network into the black-box model,
allowing it to generate Shapley value explanations without changing the
original network parameters. This side-tuning approach significantly reduces
memory, training, and inference costs, outperforming traditional
parameter-efficient methods, where full fine-tuning serves as the optimal
baseline. *AutoGnothi* enables the black-box model to predict and explain its
predictions with minimal overhead. Extensive experiments show that *AutoGnothi*
offers accurate explanations for both vision and language tasks, delivering
superior computational efficiency with comparable interpretability.

摘要：可解釋 AI (XAI) 的核心在於可自行解釋模型與黑箱模型的後設解釋之間的爭論。可自行解釋模型，例如基於概念的網路，透過將決策與人類可理解的概念連結起來提供見解，但經常在效能和可擴充性上遇到困難。相反地，後設方法（例如 Shapley 值），雖然理論上強健，但在計算上昂貴且需要大量資源。為了彌補這兩條研究路線之間的差距，我們提出一個結合其優點的新方法，為黑箱模型提供理論上保證的可自行解釋性，同時不影響預測準確性。具體來說，我們引入一個參數效率良好的管線，*AutoGnothi*，它將一個小型側網路整合到黑箱模型中，使其能夠產生 Shapley 值解釋，而不會改變原始網路參數。這種側調校方法顯著減少了記憶體、訓練和推論成本，優於傳統的參數效率良好方法，其中完全微調是最佳基準。*AutoGnothi* 使黑箱模型能夠以最小的開銷預測和解釋其預測。廣泛的實驗表明，*AutoGnothi* 為視覺和語言任務提供了準確的解釋，以可比較的可解釋性提供卓越的計算效率。

##### **A Fresh Look at Generalized Category Discovery through Non-negative Matrix Factorization**
2410.21807v2 by Zhong Ji, Shuo Yang, Jingren Liu, Yanwei Pang, Jungong Han

Generalized Category Discovery (GCD) aims to classify both base and novel
images using labeled base data. However, current approaches inadequately
address the intrinsic optimization of the co-occurrence matrix $\bar{A}$ based
on cosine similarity, failing to achieve zero base-novel regions and adequate
sparsity in base and novel domains. To address these deficiencies, we propose a
Non-Negative Generalized Category Discovery (NN-GCD) framework. It employs
Symmetric Non-negative Matrix Factorization (SNMF) as a mathematical medium to
prove the equivalence of optimal K-means with optimal SNMF, and the equivalence
of SNMF solver with non-negative contrastive learning (NCL) optimization.
Utilizing these theoretical equivalences, it reframes the optimization of
$\bar{A}$ and K-means clustering as an NCL optimization problem. Moreover, to
satisfy the non-negative constraints and make a GCD model converge to a
near-optimal region, we propose a GELU activation function and an NMF NCE loss.
To transition $\bar{A}$ from a suboptimal state to the desired $\bar{A}^*$, we
introduce a hybrid sparse regularization approach to impose sparsity
constraints. Experimental results show NN-GCD outperforms state-of-the-art
methods on GCD benchmarks, achieving an average accuracy of 66.1\% on the
Semantic Shift Benchmark, surpassing prior counterparts by 4.7\%.

摘要：廣義類別發現 (GCD) 旨在使用標籤基本資料對基本和新穎影像進行分類。然而，目前的方法並未充分解決基於餘弦相似度的共現矩陣 $\bar{A}$ 的內在最佳化，無法達成零基本新穎區域和基本及新穎領域的適當稀疏性。為了解決這些缺陷，我們提出非負廣義類別發現 (NN-GCD) 架構。它採用對稱非負矩陣分解 (SNMF) 作為數學媒介，以證明最佳 K 均值等同於最佳 SNMF，以及 SNMF 求解器等同於非負對比學習 (NCL) 最佳化。利用這些理論等價性，它將 $\bar{A}$ 和 K 均值聚類的最佳化重新定義為 NCL 最佳化問題。此外，為了滿足非負約束並使 GCD 模型收斂到近乎最佳的區域，我們提出 GELU 激活函數和 NMF NCE 損失。為了將 $\bar{A}$ 從次佳狀態轉換到所需的 $\bar{A}^*$, 我們引入混合稀疏正則化方法來施加稀疏性約束。實驗結果顯示，NN-GCD 在 GCD 基準上優於最先進的方法，在語義轉移基準上達到 66.1% 的平均準確度，比先前的對應方法高出 4.7%。

##### **SimSiam Naming Game: A Unified Approach for Representation Learning and Emergent Communication**
2410.21803v1 by Nguyen Le Hoang, Tadahiro Taniguchi, Fang Tianwei, Akira Taniguchi

Emergent communication, driven by generative models, enables agents to
develop a shared language for describing their individual views of the same
objects through interactions. Meanwhile, self-supervised learning (SSL),
particularly SimSiam, uses discriminative representation learning to make
representations of augmented views of the same data point closer in the
representation space. Building on the prior work of VI-SimSiam, which
incorporates a generative and Bayesian perspective into the SimSiam framework
via variational inference (VI) interpretation, we propose SimSiam+VAE, a
unified approach for both representation learning and emergent communication.
SimSiam+VAE integrates a variational autoencoder (VAE) into the predictor of
the SimSiam network to enhance representation learning and capture uncertainty.
Experimental results show that SimSiam+VAE outperforms both SimSiam and
VI-SimSiam. We further extend this model into a communication framework called
the SimSiam Naming Game (SSNG), which applies the generative and Bayesian
approach based on VI to develop internal representations and emergent language,
while utilizing the discriminative process of SimSiam to facilitate mutual
understanding between agents. In experiments with established models, despite
the dynamic alternation of agent roles during interactions, SSNG demonstrates
comparable performance to the referential game and slightly outperforms the
Metropolis-Hastings naming game.

摘要：由生成模型驱动的紧急通信，使代理能够通过交互为描述其对同一对象的个人观点，开发一种共享语言。同时，自监督学习（SSL），特别是 SimSiam，使用判别式表征学习，使同一数据点的增强视图的表征在表征空间中更接近。基于 VI-SimSiam 的先前工作，它通过变分推理（VI）解释将生成式和贝叶斯观点纳入 SimSiam 框架，我们提出了 SimSiam+VAE，这是一种用于表征学习和紧急通信的统一方法。SimSiam+VAE 将变分自动编码器（VAE）集成到 SimSiam 网络的预测器中，以增强表征学习并捕捉不确定性。实验结果表明，SimSiam+VAE 优于 SimSiam 和 VI-SimSiam。我们进一步将此模型扩展到一个称为 SimSiam 命名游戏（SSNG）的通信框架中，它应用基于 VI 的生成式和贝叶斯方法来开发内部表征和紧急语言，同时利用 SimSiam 的判别过程来促进代理之间的相互理解。在使用已建立模型的实验中，尽管代理角色在交互过程中动态交替，但 SSNG 表现出与指称游戏相当的性能，并且略微优于 Metropolis-Hastings 命名游戏。

##### **Text-Guided Attention is All You Need for Zero-Shot Robustness in Vision-Language Models**
2410.21802v2 by Lu Yu, Haiyang Zhang, Changsheng Xu

Due to the impressive zero-shot capabilities, pre-trained vision-language
models (e.g. CLIP), have attracted widespread attention and adoption across
various domains. Nonetheless, CLIP has been observed to be susceptible to
adversarial examples. Through experimental analysis, we have observed a
phenomenon wherein adversarial perturbations induce shifts in text-guided
attention. Building upon this observation, we propose a simple yet effective
strategy: Text-Guided Attention for Zero-Shot Robustness (TGA-ZSR). This
framework incorporates two components: the Attention Refinement module and the
Attention-based Model Constraint module. Our goal is to maintain the
generalization of the CLIP model and enhance its adversarial robustness: The
Attention Refinement module aligns the text-guided attention obtained from the
target model via adversarial examples with the text-guided attention acquired
from the original model via clean examples. This alignment enhances the model's
robustness. Additionally, the Attention-based Model Constraint module acquires
text-guided attention from both the target and original models using clean
examples. Its objective is to maintain model performance on clean samples while
enhancing overall robustness. The experiments validate that our method yields a
9.58% enhancement in zero-shot robust accuracy over the current
state-of-the-art techniques across 16 datasets. Our code is available at
https://github.com/zhyblue424/TGA-ZSR.

摘要：由於令人印象深刻的零次學習能力，預訓練的視覺語言模型（例如 CLIP）已經吸引了各個領域的廣泛關注和採用。儘管如此，已經觀察到 CLIP 容易受到對抗範例的影響。透過實驗分析，我們觀察到一個現象，其中對抗擾動會導致文本引導注意力的轉移。基於此觀察，我們提出了一個簡單但有效的策略：零次學習穩健性的文本引導注意力（TGA-ZSR）。這個架構包含兩個組成部分：注意力精煉模組和基於注意力的模型約束模組。我們的目標是維持 CLIP 模型的泛化性並增強其對抗穩健性：注意力精煉模組會將透過對抗範例從目標模型獲得的文本引導注意力與透過乾淨範例從原始模型獲得的文本引導注意力對齊。此對齊增強了模型的穩健性。此外，基於注意力的模型約束模組會使用乾淨範例從目標模型和原始模型中獲取文本引導注意力。其目標是在增強整體穩健性的同時，維持模型在乾淨範例上的效能。實驗驗證了我們的方法在 16 個資料集上，比目前的最新技術提高了 9.58% 的零次學習穩健準確度。我們的程式碼可在 https://github.com/zhyblue424/TGA-ZSR 取得。

##### **Inverse Attention Agent for Multi-Agent System**
2410.21794v1 by Qian Long, Ruoyan Li, Minglu Zhao, Tao Gao, Demetri Terzopoulos

A major challenge for Multi-Agent Systems is enabling agents to adapt
dynamically to diverse environments in which opponents and teammates may
continually change. Agents trained using conventional methods tend to excel
only within the confines of their training cohorts; their performance drops
significantly when confronting unfamiliar agents. To address this shortcoming,
we introduce Inverse Attention Agents that adopt concepts from the Theory of
Mind, implemented algorithmically using an attention mechanism and trained in
an end-to-end manner. Crucial to determining the final actions of these agents,
the weights in their attention model explicitly represent attention to
different goals. We furthermore propose an inverse attention network that
deduces the ToM of agents based on observations and prior actions. The network
infers the attentional states of other agents, thereby refining the attention
weights to adjust the agent's final action. We conduct experiments in a
continuous environment, tackling demanding tasks encompassing cooperation,
competition, and a blend of both. They demonstrate that the inverse attention
network successfully infers the attention of other agents, and that this
information improves agent performance. Additional human experiments show that,
compared to baseline agent models, our inverse attention agents exhibit
superior cooperation with humans and better emulate human behaviors.

摘要：多智能體系統的一項重大挑戰是讓智能體動態地適應對手和隊友可能不斷變化的多樣化環境。使用傳統方法訓練的智能體往往只在其訓練群組的範圍內表現出色；當面對陌生的智能體時，其效能會大幅下降。為了解決這個缺點，我們引入了逆向注意力智能體，它採用心智理論的概念，並使用注意力機制演算法實作，並以端對端的方式進行訓練。對於決定這些智能體的最終動作至關重要，其注意力模型中的權重明確表示對不同目標的注意力。此外，我們提出了一個逆向注意力網路，它根據觀察和先前的動作推論智能體的心智理論。該網路推論其他智能體的注意力狀態，從而調整注意力權重來調整智能體的最終動作。我們在一個連續的環境中進行實驗，解決了涵蓋合作、競爭和兩者結合的困難任務。它們證明逆向注意力網路成功地推論了其他智能體的注意力，而且這些資訊改善了智能體的效能。其他的人體實驗表明，與基準智能體模型相比，我們的逆向注意力智能體表現出與人類的優越合作，並且更好地模擬人類行為。

##### **Enhancing Adversarial Attacks through Chain of Thought**
2410.21791v1 by Jingbo Su

Large language models (LLMs) have demonstrated impressive performance across
various domains but remain susceptible to safety concerns. Prior research
indicates that gradient-based adversarial attacks are particularly effective
against aligned LLMs and the chain of thought (CoT) prompting can elicit
desired answers through step-by-step reasoning. This paper proposes enhancing
the robustness of adversarial attacks on aligned LLMs by integrating CoT
prompts with the greedy coordinate gradient (GCG) technique. Using CoT triggers
instead of affirmative targets stimulates the reasoning abilities of backend
LLMs, thereby improving the transferability and universality of adversarial
attacks. We conducted an ablation study comparing our CoT-GCG approach with
Amazon Web Services auto-cot. Results revealed our approach outperformed both
the baseline GCG attack and CoT prompting. Additionally, we used Llama Guard to
evaluate potentially harmful interactions, providing a more objective risk
assessment of entire conversations compared to matching outputs to rejection
phrases. The code of this paper is available at
https://github.com/sujingbo0217/CS222W24-LLM-Attack.

摘要：大型語言模型 (LLM) 已在各個領域展現出令人印象深刻的效能，但仍容易受到安全問題的影響。先前的研究表明，基於梯度的對抗攻擊對經過校準的 LLM 特別有效，而思考鏈 (CoT) 提示可以透過逐步推理引出所需的答案。本文提出透過將 CoT 提示與貪婪座標梯度 (GCG) 技術整合，來加強經過校準的 LLM 對抗攻擊的穩健性。使用 CoT 觸發器，而不是肯定目標，會刺激後端 LLM 的推理能力，從而改善對抗攻擊的可傳輸性和通用性。我們進行了一項消融研究，將我們的 CoT-GCG 方法與 Amazon Web Services auto-cot 進行比較。結果顯示，我們的做法優於基準 GCG 攻擊和 CoT 提示。此外，我們使用 Llama Guard 來評估潛在有害的互動，與將輸出與拒絕短語進行比對相比，這提供了對整個對話的更客觀風險評估。本文的程式碼可在 https://github.com/sujingbo0217/CS222W24-LLM-Attack 取得。

##### **MARCO: Multi-Agent Real-time Chat Orchestration**
2410.21784v1 by Anubhav Shrimal, Stanley Kanagaraj, Kriti Biswas, Swarnalatha Raghuraman, Anish Nediyanchath, Yi Zhang, Promod Yenigalla

Large language model advancements have enabled the development of multi-agent
frameworks to tackle complex, real-world problems such as to automate tasks
that require interactions with diverse tools, reasoning, and human
collaboration. We present MARCO, a Multi-Agent Real-time Chat Orchestration
framework for automating tasks using LLMs. MARCO addresses key challenges in
utilizing LLMs for complex, multi-step task execution. It incorporates robust
guardrails to steer LLM behavior, validate outputs, and recover from errors
that stem from inconsistent output formatting, function and parameter
hallucination, and lack of domain knowledge. Through extensive experiments we
demonstrate MARCO's superior performance with 94.48% and 92.74% accuracy on
task execution for Digital Restaurant Service Platform conversations and Retail
conversations datasets respectively along with 44.91% improved latency and
33.71% cost reduction. We also report effects of guardrails in performance gain
along with comparisons of various LLM models, both open-source and proprietary.
The modular and generic design of MARCO allows it to be adapted for automating
tasks across domains and to execute complex usecases through multi-turn
interactions.

摘要：大型語言模型的進展使得多代理架構的開發能夠解決複雜的現實世界問題，例如自動化需要與各種工具、推理和人類協作互動的任務。我們提出 MARCO，一個多代理即時聊天編排架構，用於使用 LLM 自動化任務。MARCO 解決了在複雜的多步驟任務執行中利用 LLM 的關鍵挑戰。它包含強大的護欄來引導 LLM 行為、驗證輸出並從由於輸出格式不一致、函數和參數幻覺以及缺乏領域知識而產生的錯誤中恢復。通過廣泛的實驗，我們證明了 MARCO 在數字餐廳服務平台對話和零售對話數據集上任務執行的準確率分別為 94.48% 和 92.74%，同時改進了 44.91% 的延遲並降低了 33.71% 的成本。我們還報告了護欄在性能提升中的影響，以及各種 LLM 模型（包括開源和專有模型）的比較。MARCO 的模組化和通用設計允許它適應跨領域的自動化任務，並通過多輪互動執行複雜的用例。

##### **Leveraging LLMs for Hypothetical Deduction in Logical Inference: A Neuro-Symbolic Approach**
2410.21779v1 by Qingchuan Li, Jiatong Li, Tongxuan Liu, Yuting Zeng, Mingyue Cheng, Weizhe Huang, Qi Liu

Large Language Models (LLMs) have exhibited remarkable potential across a
wide array of reasoning tasks, including logical reasoning. Although massive
efforts have been made to empower the logical reasoning ability of LLMs via
external logical symbolic solvers, crucial challenges of the poor
generalization ability to questions with different features and inevitable
question information loss of symbolic solver-driven approaches remain
unresolved. To mitigate these issues, we introduce LINA, a LLM-driven
neuro-symbolic approach for faithful logical reasoning. By enabling an LLM to
autonomously perform the transition from propositional logic extraction to
sophisticated logical reasoning, LINA not only bolsters the resilience of the
reasoning process but also eliminates the dependency on external solvers.
Additionally, through its adoption of a hypothetical-deductive reasoning
paradigm, LINA effectively circumvents the expansive search space challenge
that plagues traditional forward reasoning methods. Empirical evaluations
demonstrate that LINA substantially outperforms both established propositional
logic frameworks and conventional prompting techniques across a spectrum of
five logical reasoning tasks. Specifically, LINA achieves an improvement of
24.34% over LINC on the FOLIO dataset, while also surpassing prompting
strategies like CoT and CoT-SC by up to 24.02%. Our code is available at
https://github.com/wufeiwuwoshihua/nshy.

摘要：大型語言模型 (LLM) 在廣泛的推理任務中展現出非凡的潛力，包括邏輯推理。儘管已投入大量心力透過外部邏輯符號求解器提升 LLM 的邏輯推理能力，符號求解器驅動方法的關鍵挑戰在於對具備不同特徵問題的概化能力不佳，以及不可避免的題目資訊遺失，這些問題仍未獲得解決。為了緩解這些問題，我們引入了 LINA，一種由 LLM 驅動的神經符號方法，用於忠實的邏輯推理。透過讓 LLM 自主執行從命題邏輯萃取到精密的邏輯推理的轉換，LINA 不僅增強了推理過程的復原力，也消除了對外部求解器的依賴性。此外，透過採用假設演繹推理範例，LINA 有效地迴避了困擾傳統前向推理方法的廣泛搜尋空間挑戰。實證評估顯示，LINA 在五項邏輯推理任務中都大幅優於既有的命題邏輯架構和慣用的提示技術。具體來說，LINA 在 FOLIO 資料集上比 LINC 提升了 24.34%，同時也比 CoT 和 CoT-SC 等提示策略高出 24.02%。我們的程式碼可於 https://github.com/wufeiwuwoshihua/nshy 取得。

##### **RELATE: A Modern Processing Platform for Romanian Language**
2410.21778v1 by Vasile Păiş, Radu Ion, Andrei-Marius Avram, Maria Mitrofan, Dan Tufiş

This paper presents the design and evolution of the RELATE platform. It
provides a high-performance environment for natural language processing
activities, specially constructed for Romanian language. Initially developed
for text processing, it has been recently updated to integrate audio processing
tools. Technical details are provided with regard to core components. We
further present different usage scenarios, derived from actual use in national
and international research projects, thus demonstrating that RELATE is a
mature, modern, state-of-the-art platform for processing Romanian language
corpora. Finally, we present very recent developments including bimodal (text
and audio) features available within the platform.

摘要：本文介紹 RELATE 平台的設計與演進。它提供一個高效能的環境，專門用於羅馬尼亞語的自然語言處理活動。最初開發用於文字處理，最近已更新以整合音訊處理工具。本文提供了有關核心組件的技術細節。我們進一步提出不同的使用情境，這些情境來自於國家和國際研究計畫中的實際使用，因此證明 RELATE 是處理羅馬尼亞語語料庫的成熟、現代且最先進的平台。最後，我們提出了非常近期的發展，包括平台中可用的雙模態（文字和音訊）功能。

##### **Learning and Unlearning of Fabricated Knowledge in Language Models**
2410.21750v1 by Chen Sun, Nolan Andrew Miller, Andrey Zhmoginov, Max Vladymyrov, Mark Sandler

What happens when a new piece of knowledge is introduced into the training
data and how long does it last while a large language model (LM) continues to
train? We investigate this question by injecting facts into LMs from a new
probing dataset, "Outlandish", which is designed to permit the testing of a
spectrum of different fact types. When studying how robust these memories are,
there appears to be a sweet spot in the spectrum of fact novelty between
consistency with world knowledge and total randomness, where the injected
memory is the most enduring. Specifically we show that facts that conflict with
common knowledge are remembered for tens of thousands of training steps, while
prompts not conflicting with common knowledge (mundane), as well as scrambled
prompts (randomly jumbled) are both forgotten much more rapidly. Further,
knowledge-conflicting facts can "prime'' how the language model hallucinates on
logically unrelated prompts, showing their propensity for non-target
generalization, while both mundane and randomly jumbled facts prime
significantly less. Finally, we show that impacts of knowledge-conflicting
facts in LMs, though they can be long lasting, can be largely erased by novel
application of multi-step sparse updates, even while the training ability of
the model is preserved. As such, this very simple procedure has direct
implications for mitigating the effects of data poisoning in training.

摘要：當新的知識片段被引入訓練資料中，並且在大型語言模型 (LM) 持續訓練時，會發生什麼事？我們透過將事實注入來自新探測資料集「Outlandish」的 LM 來探討這個問題，該資料集旨在允許測試各種不同事實類型的光譜。在研究這些記憶的健全性時，在與世界知識一致性和完全隨機性之間的事實新穎性光譜中，似乎有一個甜蜜點，其中注入的記憶是最持久的。具體來說，我們展示了與常識相衝突的事實被記住了數萬個訓練步驟，而與常識不衝突的提示（平凡）以及打亂的提示（隨機混雜）都被遺忘得更快。此外，與知識相衝突的事實可以「啟動」語言模型如何對邏輯上無關的提示產生幻覺，顯示出它們對非目標概括的傾向，而平凡和隨機混雜的事實啟動的程度則顯著較低。最後，我們表明，儘管與知識相衝突的事實對 LM 的影響可能持續很長時間，但它們在很大程度上可以透過多步驟稀疏更新的新應用來消除，即使模型的訓練能力得以保留。因此，這個非常簡單的程序對減輕訓練中資料中毒的影響有直接的影響。

##### **Enhancing Financial Question Answering with a Multi-Agent Reflection Framework**
2410.21741v1 by Sorouralsadat Fatemi, Yuheng Hu

While Large Language Models (LLMs) have shown impressive capabilities in
numerous Natural Language Processing (NLP) tasks, they still struggle with
financial question answering (QA), particularly when numerical reasoning is
required. Recently, LLM-based multi-agent frameworks have demonstrated
remarkable effectiveness in multi-step reasoning, which is crucial for
financial QA tasks as it involves extracting relevant information from tables
and text and then performing numerical reasoning on the extracted data to infer
answers. In this study, we propose a multi-agent framework incorporating a
critic agent that reflects on the reasoning steps and final answers for each
question. Additionally, we enhance our system by adding multiple critic agents,
each focusing on a specific aspect of the answer. Our results indicate that
this framework significantly improves performance compared to single-agent
reasoning, with an average performance increase of 15% for the LLaMA3-8B model
and 5% for the LLaMA3-70B model. Furthermore, our framework performs on par
with, and in some cases surpasses, larger single-agent LLMs such as
LLaMA3.1-405B and GPT-4o-mini, though it falls slightly short compared to
Claude-3.5 Sonnet. Overall, our framework presents an effective solution to
enhance open-source LLMs for financial QA tasks, offering a cost-effective
alternative to larger models like Claude-3.5 Sonnet.

摘要：儘管大型語言模型 (LLM) 在眾多自然語言處理 (NLP) 任務中展現令人印象深刻的能力，但它們在財務問答 (QA) 中仍面臨挑戰，特別是在需要數字推理時。最近，基於 LLM 的多主體架構已在多步驟推理中展現顯著的成效，這對於財務 QA 任務至關重要，因為它涉及從表格和文字中萃取相關資訊，然後對萃取的資料執行數字推理以推論答案。在本研究中，我們提出一個多主體架構，其中包含一個評論主體，用於反思每個問題的推理步驟和最終答案。此外，我們透過新增多個評論主體來增強我們的系統，每個評論主體專注於答案的特定面向。我們的結果指出，與單一主體推理相比，此架構顯著提升了效能，LLaMA3-8B 模型的平均效能提升 15%，LLaMA3-70B 模型的平均效能提升 5%。此外，我們的架構與較大型的單一主體 LLM（例如 LLaMA3.1-405B 和 GPT-4o-mini）表現相當，甚至在某些情況下超越它們，儘管它略遜於 Claude-3.5 Sonnet。總體而言，我們的架構提供了一個有效的解決方案，可增強開源 LLM 的財務 QA 任務，為類似 Claude-3.5 Sonnet 的大型模型提供具成本效益的替代方案。

##### **Efficient Reprogramming of Memristive Crossbars for DNNs: Weight Sorting and Bit Stucking**
2410.21730v1 by Matheus Farias, H. T. Kung

We introduce a novel approach to reduce the number of times required for
reprogramming memristors on bit-sliced compute-in-memory crossbars for deep
neural networks (DNNs). Our idea addresses the limited non-volatile memory
endurance, which restrict the number of times they can be reprogrammed.
  To reduce reprogramming demands, we employ two techniques: (1) we organize
weights into sorted sections to schedule reprogramming of similar crossbars,
maximizing memristor state reuse, and (2) we reprogram only a fraction of
randomly selected memristors in low-order columns, leveraging their bit-level
distribution and recognizing their relatively small impact on model accuracy.
  We evaluate our approach for state-of-the-art models on the ImageNet-1K
dataset. We demonstrate a substantial reduction in crossbar reprogramming by
3.7x for ResNet-50 and 21x for ViT-Base, while maintaining model accuracy
within a 1% margin.

摘要：我們提出了一種新方法，用於減少在位元切片記憶體運算交叉棒上重新編程憶阻器的次數，以用於深度神經網路 (DNN)。我們的想法解決了非揮發性記憶體耐用性有限的問題，這限制了它們可以重新編程的次數。
為了減少重新編程需求，我們採用了兩種技術：(1) 我們將權重組織成排序的區段，以安排重新編程類似的交叉棒，最大化憶阻器狀態的重用，以及 (2) 我們僅重新編程低階欄位中隨機選擇的憶阻器的一部分，利用它們的位元級分佈並認識到它們對模型準確性的影響相對較小。
我們評估了我們在 ImageNet-1K 資料集上針對最先進模型的方法。我們展示了 ResNet-50 減少了 3.7 倍，ViT-Base 減少了 21 倍的交叉棒重新編程，同時將模型準確性維持在 1% 的範圍內。

##### **Let's Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models**
2410.21728v1 by Kangyang Luo, Zichen Ding, Zhenmin Weng, Lingfeng Qiao, Meng Zhao, Xiang Li, Di Yin, Jinlong Shu

While Chain of Thought (CoT) prompting approaches have significantly
consolidated the reasoning capabilities of large language models (LLMs), they
still face limitations that require extensive human effort or have performance
needs to be improved. Existing endeavors have focused on bridging these gaps;
however, these approaches either hinge on external data and cannot completely
eliminate manual effort, or they fall short in effectively directing LLMs to
generate high-quality exemplary prompts. To address the said pitfalls, we
propose a novel prompt approach for automatic reasoning named \textbf{LBS3},
inspired by curriculum learning which better reflects human learning habits.
Specifically, LBS3 initially steers LLMs to recall easy-to-hard proxy queries
that are pertinent to the target query. Following this, it invokes a
progressive strategy that utilizes exemplary prompts stemmed from easy-proxy
queries to direct LLMs in solving hard-proxy queries, enabling the high-quality
of the proxy solutions. Finally, our extensive experiments in various
reasoning-intensive tasks with varying open- and closed-source LLMs show that
LBS3 achieves strongly competitive performance compared to the SOTA baselines.

摘要：雖然思考鏈 (CoT) 提示方法大幅整合了大型語言模型 (LLM) 的推理能力，但它們仍然面臨需要大量人力或需要改進效能的限制。現有的努力專注於彌補這些差距；然而，這些方法依賴於外部資料，無法完全消除手動工作，或者無法有效引導 LLM 產生高品質的範例提示。為了解決這些缺點，我們提出了一種名為 \textbf{LBS3} 的自動推理新提示方法，其靈感來自更能反映人類學習習慣的課程學習。具體來說，LBS3 最初引導 LLM 回憶與目標查詢相關的易到難代理查詢。在此之後，它會採用一種漸進策略，利用源自於簡單代理查詢的範例提示來引導 LLM 解決困難的代理查詢，從而提高代理解決方案的品質。最後，我們在各種推理密集型任務中對各種開源和閉源 LLM 進行的廣泛實驗表明，與 SOTA 基準相比，LBS3 獲得了極具競爭力的效能。

##### **On the Statistical Complexity of Estimating VENDI Scores from Empirical Data**
2410.21719v1 by Azim Ospanov, Farzan Farnia

Reference-free evaluation metrics for generative models have recently been
studied in the machine learning community. As a reference-free metric, the
VENDI score quantifies the diversity of generative models using matrix-based
entropy from information theory. The VENDI score is usually computed through
the eigendecomposition of an $n \times n$ kernel matrix for $n$ generated
samples. However, due to the high computational cost of eigendecomposition for
large $n$, the score is often computed on sample sizes limited to a few tens of
thousands. In this paper, we explore the statistical convergence of the VENDI
score and demonstrate that for kernel functions with an infinite feature map
dimension, the evaluated score for a limited sample size may not converge to
the matrix-based entropy statistic. We introduce an alternative statistic
called the $t$-truncated VENDI statistic. We show that the existing Nystr\"om
method and the FKEA approximation method for the VENDI score will both converge
to the defined truncated VENDI statistic given a moderate sample size. We
perform several numerical experiments to illustrate the concentration of the
empirical VENDI score around the truncated VENDI statistic and discuss how this
statistic correlates with the visual diversity of image data.

摘要：生成模型的无参考评估指标最近已在机器学习社区中得到研究。作为无参考指标，VENDI 分数使用信息论中的基于矩阵的熵量化生成模型的多样性。VENDI 分数通常通过对 $n$ 个生成样本的 $n \times n$ 核矩阵进行特征分解来计算。然而，由于特征分解对于较大的 $n$ 的高计算成本，因此该分数通常计算在仅限于几万个的样本量上。在本文中，我们探讨了 VENDI 分数的统计收敛性，并证明对于具有无限特征映射维度的核函数，有限样本量评估的分数可能不会收敛到基于矩阵的熵统计量。我们引入了一种称为 $t$-截断 VENDI 统计量的替代统计量。我们表明，现有的 Nystr\"om 方法和 VENDI 分数的 FKEA 近似方法在给定中等样本量的情况下都会收敛到定义的截断 VENDI 统计量。我们执行了几次数值实验来说明经验 VENDI 分数围绕截断 VENDI 统计量的集中度，并讨论该统计量如何与图像数据的视觉多样性相关。

##### **Generating Realistic Tabular Data with Large Language Models**
2410.21717v1 by Dang Nguyen, Sunil Gupta, Kien Do, Thin Nguyen, Svetha Venkatesh

While most generative models show achievements in image data generation, few
are developed for tabular data generation. Recently, due to success of large
language models (LLM) in diverse tasks, they have also been used for tabular
data generation. However, these methods do not capture the correct correlation
between the features and the target variable, hindering their applications in
downstream predictive tasks. To address this problem, we propose a LLM-based
method with three important improvements to correctly capture the ground-truth
feature-class correlation in the real data. First, we propose a novel
permutation strategy for the input data in the fine-tuning phase. Second, we
propose a feature-conditional sampling approach to generate synthetic samples.
Finally, we generate the labels by constructing prompts based on the generated
samples to query our fine-tuned LLM. Our extensive experiments show that our
method significantly outperforms 10 SOTA baselines on 20 datasets in downstream
tasks. It also produces highly realistic synthetic samples in terms of quality
and diversity. More importantly, classifiers trained with our synthetic data
can even compete with classifiers trained with the original data on half of the
benchmark datasets, which is a significant achievement in tabular data
generation.

摘要：虽然大多数生成模型在图像数据生成方面取得了成就，但很少有模型用于表格数据生成。最近，由于大型语言模型 (LLM) 在各种任务中取得成功，它们也被用于表格数据生成。然而，这些方法无法捕捉到特征和目标变量之间的正确相关性，从而阻碍了它们在下游预测任务中的应用。为了解决这个问题，我们提出了一种基于 LLM 的方法，该方法具有三个重要的改进，可以正确捕获真实数据中的基本事实特征类相关性。首先，我们在微调阶段为输入数据提出了一种新的排列策略。其次，我们提出了一种特征条件抽样方法来生成合成样本。最后，我们通过基于生成样本构建提示来生成标签，以查询我们微调后的 LLM。我们的广泛实验表明，我们的方法在 20 个数据集的下游任务中明显优于 10 个 SOTA 基线。它还在质量和多样性方面产生了高度逼真的合成样本。更重要的是，使用我们的合成数据训练的分类器甚至可以在一半的基准数据集上与使用原始数据训练的分类器竞争，这是表格数据生成中的一项重大成就。

##### **A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution**
2410.21716v1 by Zhengmian Hu, Tong Zheng, Heng Huang

Authorship attribution aims to identify the origin or author of a document.
Traditional approaches have heavily relied on manual features and fail to
capture long-range correlations, limiting their effectiveness. Recent
advancements leverage text embeddings from pre-trained language models, which
require significant fine-tuning on labeled data, posing challenges in data
dependency and limited interpretability. Large Language Models (LLMs), with
their deep reasoning capabilities and ability to maintain long-range textual
associations, offer a promising alternative. This study explores the potential
of pre-trained LLMs in one-shot authorship attribution, specifically utilizing
Bayesian approaches and probability outputs of LLMs. Our methodology calculates
the probability that a text entails previous writings of an author, reflecting
a more nuanced understanding of authorship. By utilizing only pre-trained
models such as Llama-3-70B, our results on the IMDb and blog datasets show an
impressive 85\% accuracy in one-shot authorship classification across ten
authors. Our findings set new baselines for one-shot authorship analysis using
LLMs and expand the application scope of these models in forensic linguistics.
This work also includes extensive ablation studies to validate our approach.

摘要：作者归因旨在识别文件来源或作者。
传统方法严重依赖于手动特征，并且无法捕捉长程关联，从而限制了它们的有效性。最近的进步利用了预先训练的语言模型中的文本嵌入，这需要对标记数据进行大量的微调，在数据依赖性和有限的可解释性方面提出了挑战。大型语言模型 (LLM) 具有深入的推理能力和维护长程文本关联的能力，提供了一个有前景的替代方案。本研究探讨了预先训练的 LLM 在一次性作者归因中的潜力，特别是利用贝叶斯方法和 LLM 的概率输出。我们的方法计算了一段文本包含作者先前作品的概率，反映了对作者身份的更细致的理解。通过仅利用预先训练的模型（例如 Llama-3-70B），我们在 IMDb 和博客数据集上的结果显示，在十位作者中的一次性作者分类中，准确率达到了惊人的 85%。我们的发现为使用 LLM 进行一次性作者分析设定了新的基线，并扩展了这些模型在法证语言学中的应用范围。这项工作还包括广泛的消融研究，以验证我们的方法。

##### **AdaptGCD: Multi-Expert Adapter Tuning for Generalized Category Discovery**
2410.21705v1 by Yuxun Qu, Yongqiang Tang, Chenyang Zhang, Wensheng Zhang

Different from the traditional semi-supervised learning paradigm that is
constrained by the close-world assumption, Generalized Category Discovery (GCD)
presumes that the unlabeled dataset contains new categories not appearing in
the labeled set, and aims to not only classify old categories but also discover
new categories in the unlabeled data. Existing studies on GCD typically devote
to transferring the general knowledge from the self-supervised pretrained model
to the target GCD task via some fine-tuning strategies, such as partial tuning
and prompt learning. Nevertheless, these fine-tuning methods fail to make a
sound balance between the generalization capacity of pretrained backbone and
the adaptability to the GCD task. To fill this gap, in this paper, we propose a
novel adapter-tuning-based method named AdaptGCD, which is the first work to
introduce the adapter tuning into the GCD task and provides some key insights
expected to enlighten future research. Furthermore, considering the discrepancy
of supervision information between the old and new classes, a multi-expert
adapter structure equipped with a route assignment constraint is elaborately
devised, such that the data from old and new classes are separated into
different expert groups. Extensive experiments are conducted on 7 widely-used
datasets. The remarkable improvements in performance highlight the
effectiveness of our proposals.

摘要：有別於傳統半監督式學習範式受限於封閉世界假設，廣義類別發現 (GCD) 預設未標籤資料集包含未出現在標籤集中的新類別，且旨在不僅分類舊類別，還發現未標籤資料中的新類別。現有關於 GCD 的研究通常致力於透過一些微調策略（例如部分微調和提示學習）將自監督預訓練模型中的通用知識轉移到目標 GCD 任務。然而，這些微調方法無法在預訓練主幹的泛化能力和對 GCD 任務的適應性之間取得良好的平衡。為了填補這一空白，我們在本文中提出了一種名為 AdaptGCD 的新穎基於適配器微調的方法，這項工作首次將適配器微調引入 GCD 任務，並提供了一些預計能啟發未來研究的重要見解。此外，考慮到舊類別和新類別之間監督資訊的差異，精心設計了一個配備路由分配約束的多專家適配器結構，使得來自舊類別和新類別的資料被分隔到不同的專家群組中。在 7 個廣泛使用的資料集上進行了大量的實驗。效能的顯著提升突顯了我們提案的有效性。

##### **CFSafety: Comprehensive Fine-grained Safety Assessment for LLMs**
2410.21695v1 by Zhihao Liu, Chenhui Hu

As large language models (LLMs) rapidly evolve, they bring significant
conveniences to our work and daily lives, but also introduce considerable
safety risks. These models can generate texts with social biases or unethical
content, and under specific adversarial instructions, may even incite illegal
activities. Therefore, rigorous safety assessments of LLMs are crucial. In this
work, we introduce a safety assessment benchmark, CFSafety, which integrates 5
classic safety scenarios and 5 types of instruction attacks, totaling 10
categories of safety questions, to form a test set with 25k prompts. This test
set was used to evaluate the natural language generation (NLG) capabilities of
LLMs, employing a combination of simple moral judgment and a 1-5 safety rating
scale for scoring. Using this benchmark, we tested eight popular LLMs,
including the GPT series. The results indicate that while GPT-4 demonstrated
superior safety performance, the safety effectiveness of LLMs, including this
model, still requires improvement. The data and code associated with this study
are available on GitHub.

摘要：隨著大型語言模型 (LLM) 快速發展，它們為我們的工作和日常生活帶來極大的便利，但也引入了相當大的安全風險。這些模型可以產生具有社會偏見或不道德內容的文字，並且在特定對抗性指令下，甚至可能煽動非法活動。因此，對 LLM 進行嚴格的安全評估至關重要。在這項工作中，我們引入了一個安全評估基準 CFSafety，它整合了 5 個經典安全場景和 5 種類型的指令攻擊，總共 10 類安全問題，形成了一個包含 25k 提示的測試集。此測試集用於評估 LLM 的自然語言生成 (NLG) 能力，採用簡單的道德判斷和 1-5 安全評分量表進行評分。使用此基準，我們測試了八種流行的 LLM，包括 GPT 系列。結果表明，雖然 GPT-4 表現出卓越的安全性能，但包括此模型在內的 LLM 的安全有效性仍需要改進。與本研究相關的數據和程式碼可在 GitHub 上取得。

##### **How Does Critical Batch Size Scale in Pre-training?**
2410.21676v1 by Hanlin Zhang, Depen Morwani, Nikhil Vyas, Jingfeng Wu, Difan Zou, Udaya Ghai, Dean Foster, Sham Kakade

Training large-scale models under given resources requires careful design of
parallelism strategies. In particular, the efficiency notion of critical batch
size, concerning the compromise between time and compute, marks the threshold
beyond which greater data parallelism leads to diminishing returns. To
operationalize it, we propose a measure of CBS and pre-train a series of
auto-regressive language models, ranging from 85 million to 1.2 billion
parameters, on the C4 dataset. Through extensive hyper-parameter sweeps and
careful control on factors such as batch size, momentum, and learning rate
along with its scheduling, we systematically investigate the impact of scale on
CBS. Then we fit scaling laws with respect to model and data sizes to decouple
their effects. Overall, our results demonstrate that CBS scales primarily with
data size rather than model size, a finding we justify theoretically through
the analysis of infinite-width limits of neural networks and
infinite-dimensional least squares regression. Of independent interest, we
highlight the importance of common hyper-parameter choices and strategies for
studying large-scale pre-training beyond fixed training durations.

摘要：在既定資源下訓練大型模型需要仔細設計平行處理策略。特別是，關鍵批次大小的效率概念，涉及時間和運算之間的折衷，標誌著超越此臨界點後，更大的資料平行處理將導致報酬遞減。為了將其付諸實施，我們提出一個 CBS 量度，並預先訓練一系列自迴歸語言模型，範圍從 8500 萬到 12 億個參數，在 C4 資料集上。透過廣泛的超參數掃描和仔細控制批次大小、動量和學習率等因素以及其排程，我們系統性地研究規模對 CBS 的影響。然後，我們擬合關於模型和資料大小的縮放定律，以分離它們的影響。總體而言，我們的結果表明 CBS 主要隨著資料大小而不是模型大小而縮放，我們透過對神經網路的無限寬度限制和無限維最小二乘迴歸的分析，在理論上證明了這一發現。獨立的興趣是，我們強調了通用超參數選擇和策略的重要性，用於研究超越固定訓練持續時間的大規模預訓練。

##### **BF-Meta: Secure Blockchain-enhanced Privacy-preserving Federated Learning for Metaverse**
2410.21675v1 by Wenbo Liu, Handi Chen, Edith C. H. Ngai

The metaverse, emerging as a revolutionary platform for social and economic
activities, provides various virtual services while posing security and privacy
challenges. Wearable devices serve as bridges between the real world and the
metaverse. To provide intelligent services without revealing users' privacy in
the metaverse, leveraging federated learning (FL) to train models on local
wearable devices is a promising solution. However, centralized model
aggregation in traditional FL may suffer from external attacks, resulting in a
single point of failure. Furthermore, the absence of incentive mechanisms may
weaken users' participation during FL training, leading to degraded performance
of the trained model and reduced quality of intelligent services. In this
paper, we propose BF-Meta, a secure blockchain-empowered FL framework with
decentralized model aggregation, to mitigate the negative influence of
malicious users and provide secure virtual services in the metaverse. In
addition, we design an incentive mechanism to give feedback to users based on
their behaviors. Experiments conducted on five datasets demonstrate the
effectiveness and applicability of BF-Meta.

摘要：元宇宙作為社交和經濟活動的革命性平台，提供各種虛擬服務，同時也帶來安全和隱私挑戰。穿戴式裝置作為現實世界和元宇宙之間的橋樑。為了在元宇宙中提供智慧服務而不揭露使用者的隱私，利用聯邦學習 (FL) 在本地的穿戴式裝置上訓練模型是一個有前途的解決方案。然而，傳統 FL 中的集中式模型聚合可能會遭受外部攻擊，導致單點故障。此外，缺乏激勵機制可能會削弱使用者在 FL 訓練期間的參與度，導致訓練模型的效能下降和智慧服務品質降低。在本文中，我們提出 BF-Meta，一個安全區塊鏈增強的 FL 架構，具有分散式模型聚合，以減輕惡意使用者的負面影響並在元宇宙中提供安全的虛擬服務。此外，我們設計了一個激勵機制，根據使用者的行為向他們提供回饋。在五個資料集上進行的實驗證明了 BF-Meta 的有效性和適用性。

##### **Knowledge-Guided Prompt Learning for Request Quality Assurance in Public Code Review**
2410.21673v1 by Lin Li, Xinchun Yu, Xinyu Chen, Peng Liang

Public Code Review (PCR) is an assistant to the internal code review of the
development team, in the form of a public Software Question Answering (SQA)
community, to help developers access high-quality and efficient review
services. Current methods on PCR mainly focus on the reviewer's perspective,
including finding a capable reviewer, predicting comment quality, and
recommending/generating review comments. However, it is not well studied that
how to satisfy the review necessity requests posted by developers which can
increase their visibility, which in turn acts as a prerequisite for better
review responses. To this end, we propose a Knowledge-guided Prompt learning
for Public Code Review (KP-PCR) to achieve developer-based code review request
quality assurance (i.e., predicting request necessity and recommending tags
subtask). Specifically, we reformulate the two subtasks via 1) text prompt
tuning which converts both of them into a Masked Language Model (MLM) by
constructing prompt templates using hard prompt; 2) knowledge and code prefix
tuning which introduces external knowledge by soft prompt, and uses data flow
diagrams to characterize code snippets. Finally, both of the request necessity
prediction and tag recommendation subtasks output predicted results through an
answer engineering module. In addition, we further analysis the time complexity
of our KP-PCR that has lightweight prefix based the operation of introducing
knowledge. Experimental results on the PCR dataset for the period 2011-2023
demonstrate that our KP-PCR outperforms baselines by 8.3%-28.8% in the request
necessity prediction and by 0.1%-29.5% in the tag recommendation. The code
implementation is released at https://github.com/WUT-IDEA/KP-PCR.

摘要：公共程式碼審查 (PCR) 是一種公開軟體問答 (SQA) 社群形式的內部程式碼審查助理，協助開發人員存取高品質且有效的審查服務。PCR 目前的主要關注點在於審查者的觀點，包括尋找有能力的審查者、預測評論品質，以及建議/產生審查評論。不過，對於如何滿足開發人員發布的審查必要性要求，進而增加其可見度，進而成為獲得更佳審查回應的先決條件，目前尚未有深入的研究。為此，我們提出知識引導提示學習，用於公共程式碼審查 (KP-PCR)，以達成基於開發人員的程式碼審查要求品質保證（即預測要求必要性並建議標籤子任務）。具體來說，我們透過 1) 文字提示調整，將兩個子任務轉換為遮蔽語言模型 (MLM)，方法是使用硬提示建構提示範本；2) 知識和程式碼前綴調整，透過軟提示引入外部知識，並使用資料流程圖來描述程式碼片段。最後，要求必要性預測和標籤建議子任務透過答案工程模組輸出預測結果。此外，我們進一步分析了 KP-PCR 的時間複雜度，其具有輕量級的前綴，基於引入知識的運作。2011-2023 年期間針對 PCR 資料集的實驗結果顯示，我們的 KP-PCR 在要求必要性預測方面優於基準 8.3%-28.8%，在標籤建議方面優於基準 0.1%-29.5%。程式碼實作已於 https://github.com/WUT-IDEA/KP-PCR 發布。

##### **Sequential choice in ordered bundles**
2410.21670v1 by Rajeev Kohli, Kriste Krstovski, Hengyu Kuang, Hengxu Lin

Experience goods such as sporting and artistic events, songs, videos, news
stories, podcasts, and television series, are often packaged and consumed in
bundles. Many such bundles are ordered in the sense that the individual items
are consumed sequentially, one at a time. We examine if an individual's
decision to consume the next item in an ordered bundle can be predicted based
on his/her consumption pattern for the preceding items. We evaluate several
predictive models, including two custom Transformers using decoder-only and
encoder-decoder architectures, fine-tuned GPT-3, a custom LSTM model, a
reinforcement learning model, two Markov models, and a zero-order model. Using
data from Spotify, we find that the custom Transformer with a decoder-only
architecture provides the most accurate predictions, both for individual
choices and aggregate demand. This model captures a general form of state
dependence. Analysis of Transformer attention weights suggests that the
consumption of the next item in a bundle is based on approximately equal
weighting of all preceding choices. Our results indicate that the Transformer
can assist in queuing the next item that an individual is likely to consume
from an ordered bundle, predicting the demand for individual items, and
personalizing promotions to increase demand.

摘要：體驗商品（例如體育和藝術活動、歌曲、影片、新聞故事、播客和電視劇集）通常會以套組形式包裝和消費。許多此類套組是有序的，因為各個項目會依序、一次一個地被消費。我們檢視是否可以根據個人對前項目的消費模式來預測個人是否決定要消費有序套組中的下一項。我們評估了多種預測模型，包括兩個使用僅解碼器和編碼器-解碼器架構的自訂 Transformer、微調 GPT-3、自訂 LSTM 模型、強化學習模型、兩個馬可夫模型和零階模型。使用來自 Spotify 的資料，我們發現具有僅解碼器架構的自訂 Transformer 提供最準確的預測，無論是針對個別選擇或總體需求。此模型擷取了一種狀態依賴的一般形式。對 Transformer 注意力權重的分析表明，套組中下一項的消費基於對所有先前選擇的近乎相等加權。我們的結果表明，Transformer 可以協助排隊個人可能從有序套組中消費的下一項，預測個別項目的需求，並個人化促銷活動以增加需求。

##### **$f$-PO: Generalizing Preference Optimization with $f$-divergence Minimization**
2410.21662v1 by Jiaqi Han, Mingjian Jiang, Yuxuan Song, Jure Leskovec, Stefano Ermon, Minkai Xu

Preference optimization has made significant progress recently, with numerous
methods developed to align language models with human preferences. This paper
introduces $f$-divergence Preference Optimization ($f$-PO), a novel framework
that generalizes and extends existing approaches. $f$-PO minimizes
$f$-divergences between the optimized policy and the optimal policy,
encompassing a broad family of alignment methods using various divergences. Our
approach unifies previous algorithms like DPO and EXO, while offering new
variants through different choices of $f$-divergences. We provide theoretical
analysis of $f$-PO's properties and conduct extensive experiments on
state-of-the-art language models using benchmark datasets. Results demonstrate
$f$-PO's effectiveness across various tasks, achieving superior performance
compared to existing methods on popular benchmarks such as AlpacaEval 2,
Arena-Hard, and MT-Bench. Additionally, we present ablation studies exploring
the impact of different $f$-divergences, offering insights into the trade-offs
between regularization and performance in offline preference optimization. Our
work contributes both practical algorithms and theoretical understanding to the
field of language model alignment. Code is available at
https://github.com/MinkaiXu/fPO.

摘要：偏好优化最近取得了重大进展，开发了许多方法来将语言模型与人类偏好保持一致。本文介绍了 $f$-散度偏好优化 ($f$-PO)，这是一个新颖的框架，可以概括和扩展现有方法。$f$-PO 最小化优化策略和最优策略之间的 $f$-散度，涵盖使用各种散度的广泛的校准方法族。我们的方法统一了 DPO 和 EXO 等先前的算法，同时通过不同的 $f$-散度选择提供了新的变体。我们提供了 $f$-PO 特性的理论分析，并使用基准数据集对最先进的语言模型进行了广泛的实验。结果表明 $f$-PO 在各种任务中都非常有效，与 AlpacaEval 2、Arena-Hard 和 MT-Bench 等流行基准上的现有方法相比，取得了卓越的性能。此外，我们还提供了消融研究，探讨了不同 $f$-散度的影响，深入了解了离线偏好优化中正则化和性能之间的权衡。我们的工作为语言模型校准领域做出了实用算法和理论理解的贡献。代码可在 https://github.com/MinkaiXu/fPO 获得。

##### **PACER: Physics Informed Uncertainty Aware Climate Emulator**
2410.21657v2 by Hira Saleem, Flora Salim, Cormac Purcell

Climate models serve as critical tools for evaluating the effects of climate
change and projecting future climate scenarios. However, the reliance on
numerical simulations of physical equations renders them computationally
intensive and inefficient. While deep learning methodologies have made
significant progress in weather forecasting, they are still unstable for
climate emulation tasks. Here, we propose PACER, a lightweight 684K parameter
Physics Informed Uncertainty Aware Climate Emulator. PACER emulates temperature
and precipitation stably for 86 years while only being trained on greenhouse
gas emissions data. We incorporate a fundamental physical law of
advection-diffusion in PACER accounting for boundary conditions and empirically
estimating the diffusion co-efficient and flow velocities from emissions data.
PACER has been trained on 15 climate models provided by ClimateSet
outperforming baselines across most of the climate models and advancing a new
state of the art in a climate diagnostic task.

摘要：氣候模型用作評估氣候變遷影響和預測未來氣候情境的關鍵工具。然而，依賴物理方程式的數值模擬會讓它們在計算上非常密集且低效率。雖然深度學習方法在天氣預報方面取得顯著進展，但它們對於氣候模擬任務仍然不穩定。在此，我們提出 PACER，一個輕量級 684K 參數物理資訊不確定氣候模擬器。PACER 模擬溫度和降水 86 年，同時僅使用溫室氣體排放資料進行訓練。我們在 PACER 中納入對流擴散的基本物理定律，考量邊界條件，並根據排放資料經驗估計擴散係數和流速。PACER 已在 ClimateSet 提供的 15 個氣候模型上進行訓練，在大部分氣候模型中表現優於基準，並在氣候診斷任務中推進新的技術水準。

##### **Can Language Models Replace Programmers? REPOCOD Says 'Not Yet'**
2410.21647v1 by Shanchao Liang, Yiran Hu, Nan Jiang, Lin Tan

Large language models (LLMs) have shown remarkable ability in code generation
with more than 90 pass@1 in solving Python coding problems in HumanEval and
MBPP. Such high accuracy leads to the question: can LLMs replace human
programmers? Existing manual crafted, simple, or single-line code generation
benchmarks cannot answer this question due to their gap with real-world
software development. To answer this question, we propose REPOCOD, a code
generation benchmark with 980 problems collected from 11 popular real-world
projects, with more than 58% of them requiring file-level or repository-level
context information. In addition, REPOCOD has the longest average canonical
solution length (331.6 tokens) and the highest average cyclomatic complexity
(9.00) compared to existing benchmarks. In our evaluations on ten LLMs, none of
the models can achieve more than 30 pass@1 on REPOCOD, disclosing the necessity
of building stronger LLMs that can help developers in real-world software
development.

摘要：大型语言模型 (LLM) 在代码生成方面表现出非凡的能力，在 HumanEval 和 MBPP 中解决 Python 编码问题时，其 pass@1 超过 90。如此高的准确性引发了一个问题：LLM 能否取代人类程序员？现有的手工制作、简单或单行代码生成基准无法回答这个问题，因为它们与实际软件开发存在差距。为了回答这个问题，我们提出了 REPOCOD，这是一个代码生成基准，其中包含从 11 个流行的实际项目收集的 980 个问题，其中超过 58% 的问题需要文件级或存储库级的上下文信息。此外，与现有基准相比，REPOCOD 具有最长的平均规范解决方案长度 (331.6 个标记) 和最高的平均圈复杂度 (9.00)。在对十个 LLM 的评估中，没有一个模型在 REPOCOD 上的 pass@1 能够达到 30 以上，这揭示了构建更强大的 LLM 的必要性，这些 LLM 可以帮助开发人员进行实际软件开发。

##### **RDSinger: Reference-based Diffusion Network for Singing Voice Synthesis**
2410.21641v1 by Kehan Sui, Jinxu Xiang, Fang Jin

Singing voice synthesis (SVS) aims to produce high-fidelity singing audio
from music scores, requiring a detailed understanding of notes, pitch, and
duration, unlike text-to-speech tasks. Although diffusion models have shown
exceptional performance in various generative tasks like image and video
creation, their application in SVS is hindered by time complexity and the
challenge of capturing acoustic features, particularly during pitch
transitions. Some networks learn from the prior distribution and use the
compressed latent state as a better start in the diffusion model, but the
denoising step doesn't consistently improve quality over the entire duration.
We introduce RDSinger, a reference-based denoising diffusion network that
generates high-quality audio for SVS tasks. Our approach is inspired by Animate
Anyone, a diffusion image network that maintains intricate appearance features
from reference images. RDSinger utilizes FastSpeech2 mel-spectrogram as a
reference to mitigate denoising step artifacts. Additionally, existing models
could be influenced by misleading information on the compressed latent state
during pitch transitions. We address this issue by applying Gaussian blur on
partial reference mel-spectrogram and adjusting loss weights in these regions.
Extensive ablation studies demonstrate the efficiency of our method.
Evaluations on OpenCpop, a Chinese singing dataset, show that RDSinger
outperforms current state-of-the-art SVS methods in performance.

摘要：歌唱聲音合成 (SVS) 旨在根據樂譜產生高保真歌唱音訊，需要詳細了解音符、音高和時長，這與文字轉語音任務不同。儘管擴散模型在各種生成任務（例如影像和影片建立）中表現出色，但其在 SVS 中的應用受到時間複雜度和擷取音響特徵的挑戰所阻礙，尤其是在音高轉換期間。有些網路會從先驗分佈中學習，並使用壓縮潛在狀態作為擴散模型中更好的起點，但去噪步驟並未在整個時長中持續改善品質。我們引入了 RDSinger，這是一個基於參考的去噪擴散網路，可為 SVS 任務產生高品質音訊。我們的做法靈感來自 Animate Anyone，這是一個擴散影像網路，可從參考影像中保留複雜的外觀特徵。RDSinger 利用 FastSpeech2 mel-spectrogram 作為參考，以減輕去噪步驟的偽影。此外，現有模型可能會受到壓縮潛在狀態中音高轉換期間的誤導資訊影響。我們透過對部分參考 mel-spectrogram 應用高斯模糊並調整這些區域中的損失權重來解決此問題。廣泛的消融研究證明了我們方法的效率。在中文歌唱資料集 OpenCpop 上的評估顯示，RDSinger 在效能上優於目前的 SVS 最先進方法。

##### **A Tutorial on Clinical Speech AI Development: From Data Collection to Model Validation**
2410.21640v1 by Si-Ioi Ng, Lingfeng Xu, Ingo Siegert, Nicholas Cummins, Nina R. Benway, Julie Liss, Visar Berisha

There has been a surge of interest in leveraging speech as a marker of health
for a wide spectrum of conditions. The underlying premise is that any
neurological, mental, or physical deficits that impact speech production can be
objectively assessed via automated analysis of speech. Recent advances in
speech-based Artificial Intelligence (AI) models for diagnosing and tracking
mental health, cognitive, and motor disorders often use supervised learning,
similar to mainstream speech technologies like recognition and verification.
However, clinical speech AI has distinct challenges, including the need for
specific elicitation tasks, small available datasets, diverse speech
representations, and uncertain diagnostic labels. As a result, application of
the standard supervised learning paradigm may lead to models that perform well
in controlled settings but fail to generalize in real-world clinical
deployments. With translation into real-world clinical scenarios in mind, this
tutorial paper provides an overview of the key components required for robust
development of clinical speech AI. Specifically, this paper will cover the
design of speech elicitation tasks and protocols most appropriate for different
clinical conditions, collection of data and verification of hardware,
development and validation of speech representations designed to measure
clinical constructs of interest, development of reliable and robust clinical
prediction models, and ethical and participant considerations for clinical
speech AI. The goal is to provide comprehensive guidance on building models
whose inputs and outputs link to the more interpretable and clinically
meaningful aspects of speech, that can be interrogated and clinically validated
on clinical datasets, and that adhere to ethical, privacy, and security
considerations by design.

摘要：<paragraph>最近出現一股利用語言作為各種疾病標記的熱潮。其基本前提是任何影響語言產生的神經、心理或生理缺陷，都可以透過語言的自動化分析進行客觀評估。最近在語言基礎人工智慧 (AI) 模型上的進展，用於診斷和追蹤心理健康、認知和運動障礙，通常使用監督式學習，類似於主流語言技術，例如辨識和驗證。然而，臨床語言 AI 有其獨特的挑戰，包括需要特定的引導任務、可用的資料集小、語言表述多樣，以及診斷標籤不確定。因此，應用標準的監督式學習範例可能會導致在受控環境中表現良好的模型，但在現實世界的臨床部署中卻無法概化。本教學論文考量了將其轉譯到現實世界的臨床情境，提供了健全開發臨床語言 AI 所需關鍵組成的概觀。具體來說，本文將涵蓋最適合不同臨床狀況的語言引導任務和協定的設計、資料收集和硬體驗證、用於衡量臨床關注結構的語言表述的開發和驗證、可靠且健全的臨床預測模型的開發，以及臨床語言 AI 的倫理和參與者考量。目標是提供全面的指導方針，以建立其輸入和輸出連結到更易於理解且臨床上有意義的語言面向的模型，可以在臨床資料集上進行詢問和臨床驗證，並且在設計上遵守倫理、隱私和安全考量。</paragraph>

##### **Are Paraphrases Generated by Large Language Models Invertible?**
2410.21637v1 by Rafael Rivera Soto, Barry Chen, Nicholas Andrews

Large language models can produce highly fluent paraphrases while retaining
much of the original meaning. While this capability has a variety of helpful
applications, it may also be abused by bad actors, for example to plagiarize
content or to conceal their identity. This motivates us to consider the problem
of paraphrase inversion: given a paraphrased document, attempt to recover the
original text. To explore the feasibility of this task, we fine-tune paraphrase
inversion models, both with and without additional author-specific context to
help guide the inversion process. We explore two approaches to author-specific
inversion: one using in-context examples of the target author's writing, and
another using learned style representations that capture distinctive features
of the author's style. We show that, when starting from paraphrased
machine-generated text, we can recover significant portions of the document
using a learned inversion model. When starting from human-written text, the
variety of source writing styles poses a greater challenge for invertability.
However, even when the original tokens can't be recovered, we find the inverted
text is stylistically similar to the original, which significantly improves the
performance of plagiarism detectors and authorship identification systems that
rely on stylistic markers.

摘要：大型語言模型可以產生高度流利的同義改寫，同時保留大部分原始含義。雖然此功能有各種有用的應用，但它也可能被不良行為者濫用，例如抄襲內容或隱藏其身分。這促使我們考慮同義改寫反演的問題：給定一篇同義改寫的文件，嘗試恢復原始文字。為了探索此任務的可行性，我們微調同義改寫反演模型，無論是否包含額外的作者特定脈絡以協助引導反演程序。我們探索兩種作者特定反演方法：一種使用目標作者寫作的脈絡範例，另一種使用學習到的風格表示，捕捉作者風格的獨特特徵。我們表明，當從同義改寫的機器產生的文字開始時，我們可以使用學習到的反演模型恢復文件的顯著部分。當從人工撰寫的文字開始時，各種來源寫作風格對可逆性構成更大的挑戰。然而，即使無法恢復原始詞彙，我們發現反演文字在風格上與原始文字類似，這顯著改善了依賴風格標記的抄襲偵測器和作者身分識別系統的效能。

##### **MCPDial: A Minecraft Persona-driven Dialogue Dataset**
2410.21627v1 by Seyed Hossein Alavi, Sudha Rao, Ashutosh Adhikari, Gabriel A DesGarennes, Akanksha Malhotra, Chris Brockett, Mahmoud Adada, Raymond T. Ng, Vered Shwartz, Bill Dolan

We propose a novel approach that uses large language models (LLMs) to
generate persona-driven conversations between Players and Non-Player Characters
(NPC) in games. Showcasing the application of our methodology, we introduce the
Minecraft Persona-driven Dialogue dataset (MCPDial). Starting with a small seed
of expert-written conversations, we employ our method to generate hundreds of
additional conversations. Each conversation in the dataset includes rich
character descriptions of the player and NPC. The conversations are long,
allowing for in-depth and extensive interactions between the player and NPC.
MCPDial extends beyond basic conversations by incorporating canonical function
calls (e.g. "Call find a resource on iron ore") between the utterances.
Finally, we conduct a qualitative analysis of the dataset to assess its quality
and characteristics.

摘要：我們提出一個創新的方法，利用大型語言模型 (LLM) 來產生玩家與非玩家角色 (NPC) 之間以角色為導向的對話。為了展示我們方法的應用，我們引入了 Minecraft 以角色為導向的對話資料集 (MCPDial)。從一小部分由專家撰寫的對話開始，我們使用我們的方法生成了數百個額外的對話。資料集中的每個對話都包含玩家和 NPC 豐富的角色描述。這些對話很長，允許玩家和 NPC 之間進行深入且廣泛的互動。MCPDial 不僅限於基本對話，還結合了語句之間的正規函式呼叫（例如「呼叫尋找鐵礦資源」）。最後，我們對資料集進行定性分析，以評估其品質和特性。

##### **Asynchronous Tool Usage for Real-Time Agents**
2410.21620v1 by Antonio A. Ginart, Naveen Kodali, Jason Lee, Caiming Xiong, Silvio Savarese, John Emmons

While frontier large language models (LLMs) are capable tool-using agents,
current AI systems still operate in a strict turn-based fashion, oblivious to
passage of time. This synchronous design forces user queries and tool-use to
occur sequentially, preventing the systems from multitasking and reducing
interactivity. To address this limitation, we introduce asynchronous AI agents
capable of parallel processing and real-time tool-use. Our key contribution is
an event-driven finite-state machine architecture for agent execution and
prompting, integrated with automatic speech recognition and text-to-speech.
Drawing inspiration from the concepts originally developed for real-time
operating systems, this work presents both a conceptual framework and practical
tools for creating AI agents capable of fluid, multitasking interactions.

摘要：雖然前沿大型語言模型 (LLM) 是有能力使用工具的代理，
目前的 AI 系統仍然以嚴格的回合制運作，忽略
時間的流逝。這種同步設計迫使使用者查詢和工具使用
按順序發生，阻止系統執行多工處理並降低
互動性。為了解決這個限制，我們引進非同步 AI 代理
具備平行處理和即時工具使用能力。我們的關鍵貢獻是
一個事件驅動的有限狀態機架構，用於代理執行和
提示，並與自動語音辨識和文字轉語音整合。
從最初為即時
作業系統開發的概念中汲取靈感，這項工作同時提出了概念架構和實務
工具，用於建立有能力流暢執行多工處理互動的 AI 代理。

##### **Identifying Selections for Unsupervised Subtask Discovery**
2410.21616v1 by Yiwen Qiu, Yujia Zheng, Kun Zhang

When solving long-horizon tasks, it is intriguing to decompose the high-level
task into subtasks. Decomposing experiences into reusable subtasks can improve
data efficiency, accelerate policy generalization, and in general provide
promising solutions to multi-task reinforcement learning and imitation learning
problems. However, the concept of subtasks is not sufficiently understood and
modeled yet, and existing works often overlook the true structure of the data
generation process: subtasks are the results of a $\textit{selection}$
mechanism on actions, rather than possible underlying confounders or
intermediates. Specifically, we provide a theory to identify, and experiments
to verify the existence of selection variables in such data. These selections
serve as subgoals that indicate subtasks and guide policy. In light of this
idea, we develop a sequential non-negative matrix factorization (seq- NMF)
method to learn these subgoals and extract meaningful behavior patterns as
subtasks. Our empirical results on a challenging Kitchen environment
demonstrate that the learned subtasks effectively enhance the generalization to
new tasks in multi-task imitation learning scenarios. The codes are provided at
https://anonymous.4open.science/r/Identifying\_Selections\_for\_Unsupervised\_Subtask\_Discovery/README.md.

摘要：在解決長期任務時，將高級任務分解成子任務是一件有趣的事。將經驗分解成可重複使用的子任務可以提升資料效率、加速策略概化，並普遍提供多任務強化學習和模擬學習問題的有前景解決方案。然而，子任務的概念尚未被充分理解和建模，現有作品經常忽略資料生成程序的真實結構：子任務是對動作的「選擇」機制的結果，而不是可能的潛在混淆因子或中間體。具體來說，我們提供一個理論來識別，並實驗驗證此類資料中選擇變數的存在。這些選擇作為指示子任務和引導策略的次目標。根據這個想法，我們開發出一個順序非負矩陣分解（seq-NMF）方法來學習這些次目標，並提取有意義的行為模式作為子任務。我們在具挑戰性的廚房環境中進行的實證結果證明，學習到的子任務有效地增強了多任務模擬學習場景中對新任務的概化。程式碼可在 https://anonymous.4open.science/r/Identifying\_Selections\_for\_Unsupervised\_Subtask\_Discovery/README.md 取得。

##### **Reducing the Scope of Language Models with Circuit Breakers**
2410.21597v1 by David Yunis, Siyu Huo, Chulaka Gunasekara, Danish Contractor

Language models are now deployed in a wide variety of user-facing
applications, often for specific purposes like answering questions about
documentation or acting as coding assistants. As these models are intended for
particular purposes, they should not be able to answer irrelevant queries like
requests for poetry or questions about physics, or even worse, queries that can
only be answered by humans like sensitive company policies. Instead we would
like them to only answer queries corresponding to desired behavior and refuse
all other requests, which we refer to as scoping. We find that, despite the use
of system prompts, two representative language models can be poorly scoped and
respond to queries they should not be addressing. We then conduct a
comprehensive empirical evaluation of methods which could be used for scoping
the behavior of language models. Among many other results, we show that a
recently-proposed method for general alignment, Circuit Breakers (CB), can be
adapted to scope language models to very specific tasks like sentiment analysis
or summarization or even tasks with finer-grained scoping (e.g. summarizing
only news articles). When compared to standard methods like fine-tuning or
preference learning, CB is more robust both for out of distribution tasks, and
to adversarial prompting techniques. We also show that layering SFT and CB
together often results in the best of both worlds: improved performance only on
relevant queries, while rejecting irrelevant ones.

摘要：語言模型現已廣泛部署於各種面向使用者的應用程式中，通常用於特定用途，例如回答文件問題或擔任編碼助理。由於這些模型專為特定用途而設計，因此不應能夠回答與其無關的查詢，例如詩歌請求或物理問題，甚至更糟的是，只有人類才能回答的查詢，例如敏感的公司政策。相反，我們希望它們只回答與所需行為相符的查詢，並拒絕所有其他請求，我們稱之為範圍。我們發現，儘管使用了系統提示，但兩個代表性語言模型的範圍可能很差，並且會回應它們不應處理的查詢。然後，我們對可用於界定語言模型行為的方法進行全面的實證評估。在許多其他結果中，我們展示了一種最近提出的通用對齊方法，電路中斷器 (CB)，可以適應範圍語言模型到非常具體的任務，例如情緒分析或摘要，甚至具有更細粒度範圍的任務（例如僅摘要新聞文章）。與微調或偏好學習等標準方法相比，CB 對分佈任務和對抗提示技術都更強大。我們還表明，將 SFT 和 CB 分層結合在一起通常會產生兩全其美的效果：僅在相關查詢上提高性能，同時拒絕不相關的查詢。

##### **Can Large Language Models Replace Data Scientists in Clinical Research?**
2410.21591v1 by Zifeng Wang, Benjamin Danek, Ziwei Yang, Zheng Chen, Jimeng Sun

Data science plays a critical role in clinical research, but it requires
professionals with expertise in coding and medical data analysis. Large
language models (LLMs) have shown great potential in supporting medical tasks
and performing well in general coding tests. However, these tests do not assess
LLMs' ability to handle data science tasks in medicine, nor do they explore
their practical utility in clinical research. To address this, we developed a
dataset consisting of 293 real-world data science coding tasks, based on 39
published clinical studies, covering 128 tasks in Python and 165 tasks in R.
This dataset simulates realistic clinical research scenarios using patient
data. Our findings reveal that cutting-edge LLMs struggle to generate perfect
solutions, frequently failing to follow input instructions, understand target
data, and adhere to standard analysis practices. Consequently, LLMs are not yet
ready to fully automate data science tasks. We benchmarked advanced adaptation
methods and found two to be particularly effective: chain-of-thought prompting,
which provides a step-by-step plan for data analysis, which led to a 60%
improvement in code accuracy; and self-reflection, enabling LLMs to iteratively
refine their code, yielding a 38% accuracy improvement. Building on these
insights, we developed a platform that integrates LLMs into the data science
workflow for medical professionals. In a user study with five medical doctors,
we found that while LLMs cannot fully automate coding tasks, they significantly
streamline the programming process. We found that 80% of their submitted code
solutions were incorporated from LLM-generated code, with up to 96% reuse in
some cases. Our analysis highlights the potential of LLMs, when integrated into
expert workflows, to enhance data science efficiency in clinical research.

摘要：<paragraph>資料科學在臨床研究中發揮關鍵作用，但它需要具備編碼和醫療資料分析專業知識的專業人員。大型語言模型 (LLM) 在支援醫療任務和執行一般編碼測試方面展現了極大的潛力。然而，這些測試並未評估 LLM 處理醫學中資料科學任務的能力，也沒有探討它們在臨床研究中的實際效用。為了解決這個問題，我們開發了一個由 293 個真實世界資料科學編碼任務組成的資料集，這些任務基於 39 項已發表的臨床研究，涵蓋 128 個 Python 任務和 165 個 R 任務。此資料集使用患者資料模擬真實的臨床研究場景。我們的研究結果顯示，最先進的 LLM 難以產生完美的解決方案，常常無法遵循輸入說明、理解目標資料，以及遵守標準分析實務。因此，LLM 尚未準備好完全自動化資料科學任務。我們對進階適應方法進行了基準測試，發現有兩個方法特別有效：思考鏈提示，它提供了資料分析的逐步計畫，使程式碼準確度提升了 60%；以及自我反省，使 LLM 能夠反覆改善其程式碼，使準確度提升了 38%。根據這些見解，我們開發了一個將 LLM 整合到醫療專業人員資料科學工作流程中的平台。在與五位醫生的使用者研究中，我們發現，雖然 LLM 無法完全自動化編碼任務，但它們大幅簡化了程式設計流程。我們發現，他們提交的程式碼解決方案中有 80% 是從 LLM 生成的程式碼中納入的，在某些情況下重用率高達 96%。我們的分析強調了 LLM 在整合到專家工作流程中的潛力，以提高臨床研究中的資料科學效率。</paragraph>

##### **ImageNet-RIB Benchmark: Large Pre-Training Datasets Don't Guarantee Robustness after Fine-Tuning**
2410.21582v1 by Jaedong Hwang, Brian Cheung, Zhang-Wei Hong, Akhilan Boopathy, Pulkit Agrawal, Ila Fiete

Highly performant large-scale pre-trained models promise to also provide a
valuable foundation for learning specialized tasks, by fine-tuning the model to
the desired task. By starting from a good general-purpose model, the goal is to
achieve both specialization in the target task and maintain robustness. To
assess the robustness of models to out-of-distribution samples after
fine-tuning on downstream datasets, we introduce a new robust fine-tuning
benchmark, ImageNet-RIB (Robustness Inheritance Benchmark). The benchmark
consists of a set of related but distinct specialized (downstream) tasks;
pre-trained models are fine-tuned on one task in the set and their robustness
is assessed on the rest, iterating across all tasks for fine-tuning and
assessment. We find that the continual learning methods, EWC and LwF maintain
robustness after fine-tuning though fine-tuning generally does reduce
performance on generalization to related downstream tasks across models. Not
surprisingly, models pre-trained on large and rich datasets exhibit higher
initial robustness across datasets and suffer more pronounced degradation
during fine-tuning. The distance between the pre-training and downstream
datasets, measured by optimal transport, predicts this performance degradation
on the pre-training dataset. However, counterintuitively, model robustness
after fine-tuning on related downstream tasks is the worst when the
pre-training dataset is the richest and the most diverse. This suggests that
starting with the strongest foundation model is not necessarily the best
approach for performance on specialist tasks. The benchmark thus offers key
insights for developing more resilient fine-tuning strategies and building
robust machine learning models. https://jd730.github.io/projects/ImageNet-RIB

摘要：性能極佳的大規模預先訓練模型承諾，透過微調模型以符合所需任務，也能提供一個有價值的基礎，以便學習專業任務。從一個好的通用模型開始，目標是同時在目標任務中實現專業化，並維持穩健性。為了評估模型在微調下游資料集後對分佈外樣本的穩健性，我們引入了新的穩健微調基準 ImageNet-RIB（穩健繼承基準）。基準包含一組相關但不同的專業（下游）任務；預先訓練的模型針對該組中的其中一項任務進行微調，而其穩健性則在其他任務中進行評估，並針對微調和評估的所有任務進行反覆運算。我們發現，持續學習方法 EWC 和 LwF 在微調後仍能維持穩健性，儘管微調通常會降低模型在相關下游任務中的泛化效能。毫不意外地，在大型豐富資料集上預先訓練的模型在不同資料集之間表現出較高的初始穩健性，而在微調期間遭受更明顯的效能下降。透過最佳傳輸測量的預先訓練和下游資料集之間的距離，可以預測預先訓練資料集上的效能下降。然而，反直覺的是，當預先訓練資料集最豐富且最多樣化時，模型在相關下游任務上的微調後穩健性最差。這表示從最強大的基礎模型開始，不一定是執行專業任務的最佳方法。因此，基準為開發更具韌性的微調策略和建構穩健機器學習模型提供了關鍵見解。https://jd730.github.io/projects/ImageNet-RIB

##### **A Generative Model Based Honeypot for Industrial OPC UA Communication**
2410.21574v1 by Olaf Sassnick, Georg Schäfer, Thomas Rosenstatter, Stefan Huber

Industrial Operational Technology (OT) systems are increasingly targeted by
cyber-attacks due to their integration with Information Technology (IT) systems
in the Industry 4.0 era. Besides intrusion detection systems, honeypots can
effectively detect these attacks. However, creating realistic honeypots for
brownfield systems is particularly challenging. This paper introduces a
generative model-based honeypot designed to mimic industrial OPC UA
communication. Utilizing a Long ShortTerm Memory (LSTM) network, the honeypot
learns the characteristics of a highly dynamic mechatronic system from recorded
state space trajectories. Our contributions are twofold: first, we present a
proof-of concept for a honeypot based on generative machine-learning models,
and second, we publish a dataset for a cyclic industrial process. The results
demonstrate that a generative model-based honeypot can feasibly replicate a
cyclic industrial process via OPC UA communication. In the short-term, the
generative model indicates a stable and plausible trajectory generation, while
deviations occur over extended periods. The proposed honeypot implementation
operates efficiently on constrained hardware, requiring low computational
resources. Future work will focus on improving model accuracy, interaction
capabilities, and extending the dataset for broader applications.

摘要：工業運作技術 (OT) 系統由於在工業 4.0 時代與資訊技術 (IT) 系統整合，而日益成為網路攻擊的目標。除了入侵偵測系統，蜜罐可以有效地偵測這些攻擊。然而，為褐地系統建立逼真的蜜罐特別具有挑戰性。本文介紹了一個生成模型為基礎的蜜罐，設計用來模擬工業 OPC UA 通訊。利用長短期記憶 (LSTM) 網路，蜜罐從記錄的狀態空間軌跡中學習高度動態機電系統的特性。我們的貢獻有兩個方面：首先，我們提出了一個基於生成機器學習模型的蜜罐的概念驗證，其次，我們公佈了一個循環工業流程的資料集。結果證明，一個生成模型為基礎的蜜罐可以透過 OPC UA 通訊，可行地複製一個循環工業流程。在短期內，生成模型表示一個穩定且合理的軌跡生成，而偏差會在延長期間發生。所提出的蜜罐實作在受限硬體上有效率地運作，只需要低運算資源。未來的研究將專注於改善模型準確度、互動能力，並擴充資料集以應用於更廣泛的應用程式。

##### **Thank You, Stingray: Multilingual Large Language Models Can Not (Yet) Disambiguate Cross-Lingual Word Sense**
2410.21573v2 by Samuel Cahyawijaya, Ruochen Zhang, Holy Lovenia, Jan Christian Blaise Cruz, Elisa Gilbert, Hiroki Nomoto, Alham Fikri Aji

Multilingual large language models (LLMs) have gained prominence, but
concerns arise regarding their reliability beyond English. This study addresses
the gap in cross-lingual semantic evaluation by introducing a novel benchmark
for cross-lingual sense disambiguation, StingrayBench. In this paper, we
demonstrate using false friends -- words that are orthographically similar but
have completely different meanings in two languages -- as a possible approach
to pinpoint the limitation of cross-lingual sense disambiguation in LLMs. We
collect false friends in four language pairs, namely Indonesian-Malay,
Indonesian-Tagalog, Chinese-Japanese, and English-German; and challenge LLMs to
distinguish the use of them in context. In our analysis of various models, we
observe they tend to be biased toward higher-resource languages. We also
propose new metrics for quantifying the cross-lingual sense bias and
comprehension based on our benchmark. Our work contributes to developing more
diverse and inclusive language modeling, promoting fairer access for the wider
multilingual community.

摘要：多語言大型語言模型 (LLM) 聲名大噪，但對於其在英語以外的可靠性仍有疑慮。本研究透過引入跨語言感官消歧的全新基準 StingrayBench，來解決跨語言語義評估中的差距。在本文中，我們示範使用假朋友（拼寫相似，但在兩種語言中意思完全不同的字詞）作為一種可能的方法，來精確找出 LLM 中跨語言感官消歧的限制。我們收集了四組語言對中的假朋友，即印尼語-馬來語、印尼語-他加祿語、中文-日語和英語-德語；並挑戰 LLM 在文中區分其用法。在我們對各種模型的分析中，我們觀察到它們傾向於偏向於資源較多的語言。我們也針對基準提出了量化跨語言感官偏差和理解的新指標。我們的研究有助於開發更多元且包容的語言模型，促進更廣泛的多語言社群更公平的存取。

