{"2405.10299": {"publish_time": "2024-05-16", "title": "HW-GPT-Bench: Hardware-Aware Architecture Benchmark for Language Models", "paper_summary": "The expanding size of language models has created the necessity for a\ncomprehensive examination across various dimensions that reflect the desiderata\nwith respect to the tradeoffs between various hardware metrics, such as\nlatency, energy consumption, GPU memory usage, and performance. There is a\ngrowing interest in establishing Pareto frontiers for different language model\nconfigurations to identify optimal models with specified hardware constraints.\nNotably, architectures that excel in latency on one device may not perform\noptimally on another. However, exhaustive training and evaluation of numerous\narchitectures across diverse hardware configurations is computationally\nprohibitive. To this end, we propose HW-GPT-Bench, a hardware-aware language\nmodel surrogate benchmark, where we leverage weight-sharing techniques from\nNeural Architecture Search (NAS) to efficiently train a supernet proxy,\nencompassing language models of varying scales in a single model. We conduct\nprofiling of these models across 13 devices, considering 5 hardware metrics and\n3 distinct model scales. Finally, we showcase the usability of HW-GPT-Bench\nusing 8 different multi-objective NAS algorithms and evaluate the quality of\nthe resultant Pareto fronts. Through this benchmark, our objective is to propel\nand expedite research in the advancement of multi-objective methods for NAS and\nstructural pruning in large language models.", "paper_summary_zh": "<paragraph>\u8a9e\u8a00\u6a21\u578b\u7684\u898f\u6a21\u64f4\u5927\uff0c\u8b93\u4eba\u6709\u5fc5\u8981\u5f9e\u5404\u7a2e\u9762\u5411\u9032\u884c\u5168\u9762\u6aa2\u8996\uff0c\u9019\u4e9b\u9762\u5411\u53cd\u6620\u4e86\u5728\u5404\u7a2e\u786c\u9ad4\u6307\u6a19\uff08\u4f8b\u5982\u5ef6\u9072\u3001\u80fd\u6e90\u6d88\u8017\u3001GPU \u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf\u548c\u6548\u80fd\uff09\u4e4b\u9593\u7684\u6298\u8877\u8003\u91cf\u3002\u5c0d\u65bc\u5efa\u7acb\u4e0d\u540c\u8a9e\u8a00\u6a21\u578b\u7d44\u614b\u7684 Pareto \u524d\u7de3\uff0c\u4ee5\u627e\u51fa\u7b26\u5408\u7279\u5b9a\u786c\u9ad4\u9650\u5236\u7684\u6700\u4f73\u6a21\u578b\uff0c\u4eba\u5011\u7684\u8208\u8da3\u8207\u65e5\u4ff1\u589e\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u4e00\u500b\u88dd\u7f6e\u4e0a\u5ef6\u9072\u8868\u73fe\u512a\u7570\u7684\u67b6\u69cb\uff0c\u5728\u53e6\u4e00\u500b\u88dd\u7f6e\u4e0a\u53ef\u80fd\u7121\u6cd5\u9054\u5230\u6700\u4f73\u6548\u80fd\u3002\u7136\u800c\uff0c\u5728\u5404\u7a2e\u786c\u9ad4\u7d44\u614b\u4e2d\u5c0d\u773e\u591a\u67b6\u69cb\u9032\u884c\u7aae\u8209\u5f0f\u8a13\u7df4\u548c\u8a55\u4f30\uff0c\u5728\u904b\u7b97\u4e0a\u662f\u7981\u6b62\u7684\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86 HW-GPT-Bench\uff0c\u9019\u662f\u4e00\u500b\u786c\u9ad4\u611f\u77e5\u8a9e\u8a00\u6a21\u578b\u66ff\u4ee3\u57fa\u6e96\uff0c\u6211\u5011\u5728\u5176\u4e2d\u5229\u7528\u795e\u7d93\u67b6\u69cb\u641c\u5c0b (NAS) \u7684\u6b0a\u91cd\u5171\u7528\u6280\u8853\uff0c\u6709\u6548\u7387\u5730\u8a13\u7df4\u4e00\u500b\u8d85\u7d1a\u7db2\u8def\u4ee3\u7406\uff0c\u5728\u55ae\u4e00\u6a21\u578b\u4e2d\u6db5\u84cb\u5404\u7a2e\u898f\u6a21\u7684\u8a9e\u8a00\u6a21\u578b\u3002\u6211\u5011\u5728 13 \u500b\u88dd\u7f6e\u4e0a\u5c0d\u9019\u4e9b\u6a21\u578b\u9032\u884c\u5206\u6790\uff0c\u8003\u91cf 5 \u500b\u786c\u9ad4\u6307\u6a19\u548c 3 \u500b\u4e0d\u540c\u7684\u6a21\u578b\u898f\u6a21\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c55\u793a\u4e86 HW-GPT-Bench \u7684\u53ef\u7528\u6027\uff0c\u4f7f\u7528\u4e86 8 \u7a2e\u4e0d\u540c\u7684\u591a\u76ee\u6a19 NAS \u6f14\u7b97\u6cd5\uff0c\u4e26\u8a55\u4f30\u6240\u5f97 Pareto \u524d\u7de3\u7684\u54c1\u8cea\u3002\u900f\u904e\u9019\u500b\u57fa\u6e96\uff0c\u6211\u5011\u7684\u76ee\u6a19\u662f\u63a8\u52d5\u548c\u52a0\u901f\u5728 NAS \u548c\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7d50\u69cb\u5316\u526a\u679d\u7684\u591a\u76ee\u6a19\u65b9\u6cd5\u7684\u9032\u5c55\u3002</paragraph>", "author": "Rhea Sanjay Sukthanker et.al.", "authors": "Rhea Sanjay Sukthanker, Arber Zela, Benedikt Staffler, Jorg K. H. Franke, Frank Hutter", "id": "2405.10299v1", "paper_url": "http://arxiv.org/abs/2405.10299v1", "repo": "null"}}