{"2406.11801": {"publish_time": "2024-06-17", "title": "Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations", "paper_summary": "Ensuring the safe alignment of large language models (LLMs) with human values\nis critical as they become integral to applications like translation and\nquestion answering. Current alignment methods struggle with dynamic user\nintentions and complex objectives, making models vulnerable to generating\nharmful content. We propose Safety Arithmetic, a training-free framework\nenhancing LLM safety across different scenarios: Base models, Supervised\nfine-tuned models (SFT), and Edited models. Safety Arithmetic involves Harm\nDirection Removal to avoid harmful content and Safety Alignment to promote safe\nresponses. Additionally, we present NoIntentEdit, a dataset highlighting edit\ninstances that could compromise model safety if used unintentionally. Our\nexperiments show that Safety Arithmetic significantly improves safety measures,\nreduces over-safety, and maintains model utility, outperforming existing\nmethods in ensuring safe content generation.", "paper_summary_zh": "\u78ba\u4fdd\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8207\u4eba\u985e\u50f9\u503c\u89c0\u5b89\u5168\u4e00\u81f4\uff0c\u5c0d\u65bc\u5b83\u5011\u6210\u70ba\u7ffb\u8b6f\u548c\u554f\u7b54\u7b49\u61c9\u7528\u7a0b\u5f0f\u4e0d\u53ef\u6216\u7f3a\u7684\u4e00\u90e8\u5206\u81f3\u95dc\u91cd\u8981\u3002\u76ee\u524d\u7684\u5c0d\u9f4a\u65b9\u5f0f\u65b9\u6cd5\u96e3\u4ee5\u61c9\u5c0d\u52d5\u614b\u4f7f\u7528\u8005\u610f\u5716\u548c\u8907\u96dc\u76ee\u6a19\uff0c\u4f7f\u5f97\u6a21\u578b\u5bb9\u6613\u7522\u751f\u6709\u5bb3\u5167\u5bb9\u3002\u6211\u5011\u63d0\u51fa\u5b89\u5168\u7b97\u8853\uff0c\u9019\u662f\u4e00\u500b\u514d\u8a13\u7df4\u6846\u67b6\uff0c\u53ef\u589e\u5f37 LLM \u5728\u4e0d\u540c\u5834\u666f\u4e2d\u7684\u5b89\u5168\u6027\uff1a\u57fa\u790e\u6a21\u578b\u3001\u76e3\u7763\u5fae\u8abf\u6a21\u578b (SFT) \u548c\u7de8\u8f2f\u6a21\u578b\u3002\u5b89\u5168\u7b97\u8853\u6d89\u53ca\u5371\u5bb3\u65b9\u5411\u79fb\u9664\uff0c\u4ee5\u907f\u514d\u6709\u5bb3\u5167\u5bb9\uff0c\u4ee5\u53ca\u5b89\u5168\u5c0d\u9f4a\uff0c\u4ee5\u4fc3\u9032\u5b89\u5168\u56de\u61c9\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa NoIntentEdit\uff0c\u9019\u662f\u4e00\u500b\u8cc7\u6599\u96c6\uff0c\u91cd\u9ede\u6a19\u793a\u51fa\u5982\u679c\u7121\u610f\u4e2d\u4f7f\u7528\uff0c\u53ef\u80fd\u6703\u640d\u5bb3\u6a21\u578b\u5b89\u5168\u6027\u7684\u7de8\u8f2f\u5be6\u4f8b\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0c\u5b89\u5168\u7b97\u8853\u986f\u8457\u6539\u5584\u4e86\u5b89\u5168\u63aa\u65bd\uff0c\u6e1b\u5c11\u4e86\u904e\u5ea6\u5b89\u5168\u6027\uff0c\u4e26\u7dad\u6301\u6a21\u578b\u6548\u7528\uff0c\u5728\u78ba\u4fdd\u5b89\u5168\u5167\u5bb9\u751f\u6210\u65b9\u9762\u512a\u65bc\u73fe\u6709\u65b9\u6cd5\u3002", "author": "Rima Hazra et.al.", "authors": "Rima Hazra, Sayan Layek, Somnath Banerjee, Soujanya Poria", "id": "2406.11801v1", "paper_url": "http://arxiv.org/abs/2406.11801v1", "repo": "https://github.com/declare-lab/safety-arithmetic"}}