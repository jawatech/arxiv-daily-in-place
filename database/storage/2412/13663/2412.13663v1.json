{"2412.13663": {"publish_time": "2024-12-18", "title": "Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference", "paper_summary": "Encoder-only transformer models such as BERT offer a great performance-size\ntradeoff for retrieval and classification tasks with respect to larger\ndecoder-only models. Despite being the workhorse of numerous production\npipelines, there have been limited Pareto improvements to BERT since its\nrelease. In this paper, we introduce ModernBERT, bringing modern model\noptimizations to encoder-only models and representing a major Pareto\nimprovement over older encoders. Trained on 2 trillion tokens with a native\n8192 sequence length, ModernBERT models exhibit state-of-the-art results on a\nlarge pool of evaluations encompassing diverse classification tasks and both\nsingle and multi-vector retrieval on different domains (including code). In\naddition to strong downstream performance, ModernBERT is also the most speed\nand memory efficient encoder and is designed for inference on common GPUs.", "paper_summary_zh": "\u50c5\u7de8\u78bc\u5668\u8f49\u63db\u5668\u6a21\u578b\uff0c\u4f8b\u5982 BERT\uff0c\u5c0d\u65bc\u6aa2\u7d22\u548c\u5206\u985e\u4efb\u52d9\uff0c\u63d0\u4f9b\u4e86\u76f8\u5c0d\u65bc\u8f03\u5927\u7684\u50c5\u89e3\u78bc\u5668\u6a21\u578b\u7684\u51fa\u8272\u6548\u80fd\u5927\u5c0f\u6b0a\u8861\u3002\u5118\u7ba1\u662f\u8a31\u591a\u751f\u7522\u7ba1\u7dda\u7684\u904b\u4f5c\u4e3b\u8ef8\uff0c\u4f46\u81ea BERT \u767c\u5e03\u4ee5\u4f86\uff0cPareto \u6539\u9032\u4e00\u76f4\u5f88\u6709\u9650\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86 ModernBERT\uff0c\u5c07\u73fe\u4ee3\u6a21\u578b\u6700\u4f73\u5316\u5e36\u5165\u50c5\u7de8\u78bc\u5668\u6a21\u578b\uff0c\u4e26\u4ee3\u8868\u4e86\u76f8\u8f03\u65bc\u820a\u7de8\u78bc\u5668\u7684\u4e00\u9805\u91cd\u5927 Pareto \u6539\u9032\u3002ModernBERT \u6a21\u578b\u4ee5 2 \u5146\u500b\u7b26\u865f\u548c\u539f\u751f 8192 \u9806\u5e8f\u9577\u5ea6\u9032\u884c\u8a13\u7df4\uff0c\u5728\u5305\u542b\u5404\u7a2e\u5206\u985e\u4efb\u52d9\u548c\u4e0d\u540c\u9818\u57df\uff08\u5305\u62ec\u7a0b\u5f0f\u78bc\uff09\u7684\u55ae\u5411\u91cf\u548c\u591a\u5411\u91cf\u6aa2\u7d22\u7684\u5927\u578b\u8a55\u4f30\u6c60\u4e2d\u5c55\u73fe\u4e86\u6700\u5148\u9032\u7684\u7d50\u679c\u3002\u9664\u4e86\u5f37\u5927\u7684\u4e0b\u6e38\u6548\u80fd\u4e4b\u5916\uff0cModernBERT \u4e5f\u662f\u901f\u5ea6\u548c\u8a18\u61b6\u9ad4\u6700\u6709\u6548\u7387\u7684\u7de8\u78bc\u5668\uff0c\u4e26\u8a2d\u8a08\u7528\u65bc\u5728\u5e38\u898b GPU \u4e0a\u9032\u884c\u63a8\u8ad6\u3002", "author": "Benjamin Warner et.al.", "authors": "Benjamin Warner, Antoine Chaffin, Benjamin Clavi\u00e9, Orion Weller, Oskar Hallstr\u00f6m, Said Taghadouini, Alexis Gallagher, Raja Biswas, Faisal Ladhak, Tom Aarsen, Nathan Cooper, Griffin Adams, Jeremy Howard, Iacopo Poli", "id": "2412.13663v1", "paper_url": "http://arxiv.org/abs/2412.13663v1", "repo": "null"}}