{"2410.05725": {"publish_time": "2024-10-08", "title": "KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server", "paper_summary": "The success of large language models (LLMs) facilitate many parties to\nfine-tune LLMs on their own private data. However, this practice raises privacy\nconcerns due to the memorization of LLMs. Existing solutions, such as utilizing\nsynthetic data for substitution, struggle to simultaneously improve performance\nand preserve privacy. They either rely on a local model for generation,\nresulting in a performance decline, or take advantage of APIs, directly\nexposing the data to API servers. To address this issue, we propose\n\\textit{KnowledgeSG}, a novel client-server framework which enhances synthetic\ndata quality and improves model performance while ensuring privacy. We achieve\nthis by learning local knowledge from the private data with differential\nprivacy (DP) and distilling professional knowledge from the server.\nAdditionally, inspired by federated learning, we transmit models rather than\ndata between the client and server to prevent privacy leakage. Extensive\nexperiments in medical and financial domains demonstrate the effectiveness of\nKnowledgeSG. Our code is now publicly available at\nhttps://github.com/wwh0411/KnowledgeSG.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6210\u529f\u4fc3\u4f7f\u8a31\u591a\u4eba\u5fae\u8abf\u81ea\u5df1\u7684\u79c1\u4eba\u8cc7\u6599\u4e0a\u7684 LLM\u3002\u7136\u800c\uff0c\u6b64\u505a\u6cd5\u6703\u56e0\u70ba LLM \u7684\u8a18\u61b6\u529f\u80fd\u800c\u5f15\u767c\u96b1\u79c1\u7591\u616e\u3002\u73fe\u6709\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u4f8b\u5982\u5229\u7528\u5408\u6210\u8cc7\u6599\u9032\u884c\u66ff\u63db\uff0c\u5728\u540c\u6642\u63d0\u5347\u6548\u80fd\u548c\u4fdd\u8b77\u96b1\u79c1\u65b9\u9762\u4ecd\u6709\u56f0\u96e3\u3002\u5b83\u5011\u4ef0\u8cf4\u5728\u5730\u6a21\u578b\u9032\u884c\u7522\u751f\uff0c\u5c0e\u81f4\u6548\u80fd\u4e0b\u964d\uff0c\u6216\u5229\u7528 API\uff0c\u76f4\u63a5\u5c07\u8cc7\u6599\u516c\u958b\u7d66 API \u4f3a\u670d\u5668\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u300c\u77e5\u8b58 SG\u300d\uff0c\u4e00\u7a2e\u65b0\u7a4e\u7684\u5ba2\u6236\u7aef\u4f3a\u670d\u5668\u67b6\u69cb\uff0c\u5b83\u80fd\u63d0\u5347\u5408\u6210\u8cc7\u6599\u54c1\u8cea\uff0c\u4e26\u5728\u78ba\u4fdd\u96b1\u79c1\u7684\u540c\u6642\u63d0\u5347\u6a21\u578b\u6548\u80fd\u3002\u6211\u5011\u900f\u904e\u4f7f\u7528\u5dee\u5206\u96b1\u79c1 (DP) \u5f9e\u79c1\u4eba\u8cc7\u6599\u4e2d\u5b78\u7fd2\u5728\u5730\u77e5\u8b58\uff0c\u4e26\u5f9e\u4f3a\u670d\u5668\u4e2d\u8403\u53d6\u5c08\u696d\u77e5\u8b58\uff0c\u9054\u6210\u6b64\u76ee\u6a19\u3002\u6b64\u5916\uff0c\u53d7\u806f\u90a6\u5b78\u7fd2\u7684\u555f\u767c\uff0c\u6211\u5011\u50b3\u8f38\u6a21\u578b\u800c\u975e\u8cc7\u6599\u5728\u5ba2\u6236\u7aef\u548c\u4f3a\u670d\u5668\u4e4b\u9593\uff0c\u4ee5\u9632\u6b62\u96b1\u79c1\u5916\u6d29\u3002\u5728\u91ab\u7642\u548c\u91d1\u878d\u9818\u57df\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\u4e86\u77e5\u8b58 SG \u7684\u6709\u6548\u6027\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u73fe\u5728\u5df2\u516c\u958b\u65bc https://github.com/wwh0411/KnowledgeSG\u3002", "author": "Wenhao Wang et.al.", "authors": "Wenhao Wang, Xiaoyu Liang, Rui Ye, Jingyi Chai, Siheng Chen, Yanfeng Wang", "id": "2410.05725v1", "paper_url": "http://arxiv.org/abs/2410.05725v1", "repo": "null"}}