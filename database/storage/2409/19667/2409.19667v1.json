{"2409.19667": {"publish_time": "2024-09-29", "title": "Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models", "paper_summary": "The need to analyze graphs is ubiquitous across various fields, from social\nnetworks to biological research and recommendation systems. Therefore, enabling\nthe ability of large language models (LLMs) to process graphs is an important\nstep toward more advanced general intelligence. However, current LLM benchmarks\non graph analysis require models to directly reason over the prompts describing\ngraph topology, and are thus limited to small graphs with only a few dozens of\nnodes. In contrast, human experts typically write programs based on popular\nlibraries for task solving, and can thus handle graphs with different scales.\nTo this end, a question naturally arises: can LLMs analyze graphs like\nprofessionals? In this paper, we introduce ProGraph, a manually crafted\nbenchmark containing 3 categories of graph tasks. The benchmark expects\nsolutions based on programming instead of directly reasoning over raw inputs.\nOur findings reveal that the performance of current LLMs is unsatisfactory,\nwith the best model achieving only 36% accuracy. To bridge this gap, we propose\nLLM4Graph datasets, which include crawled documents and auto-generated codes\nbased on 6 widely used graph libraries. By augmenting closed-source LLMs with\ndocument retrieval and fine-tuning open-source ones on the codes, we show\n11-32% absolute improvements in their accuracies. Our results underscore that\nthe capabilities of LLMs in handling structured data are still under-explored,\nand show the effectiveness of LLM4Graph in enhancing LLMs' proficiency of graph\nanalysis. The benchmark, datasets and enhanced open-source models are available\nat https://github.com/BUPT-GAMMA/ProGraph.", "paper_summary_zh": "<paragraph>\u5728\u5f9e\u793e\u4ea4\u7db2\u8def\u5230\u751f\u7269\u7814\u7a76\u548c\u63a8\u85a6\u7cfb\u7d71\u7684\u5404\u7a2e\u9818\u57df\u4e2d\uff0c\u5206\u6790\u5716\u5f62\u7684\u9700\u6c42\u7121\u8655\u4e0d\u5728\u3002\u56e0\u6b64\uff0c\u8ce6\u4e88\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8655\u7406\u5716\u5f62\u7684\u80fd\u529b\uff0c\u662f\u9081\u5411\u66f4\u5148\u9032\u7684\u901a\u7528\u667a\u6167\u7684\u91cd\u8981\u4e00\u6b65\u3002\u7136\u800c\uff0c\u76ee\u524d\u5716\u5f62\u5206\u6790\u4e0a\u7684 LLM \u57fa\u6e96\u8981\u6c42\u6a21\u578b\u76f4\u63a5\u5c0d\u63cf\u8ff0\u5716\u5f62\u62d3\u64b2\u7d50\u69cb\u7684\u63d0\u793a\u9032\u884c\u63a8\u7406\uff0c\u56e0\u6b64\u50c5\u9650\u65bc\u53ea\u6709\u6578\u5341\u500b\u7bc0\u9ede\u7684\u5c0f\u578b\u5716\u5f62\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u4eba\u985e\u5c08\u5bb6\u901a\u5e38\u6703\u6839\u64da\u6d41\u884c\u7684\u51fd\u5f0f\u5eab\u64b0\u5beb\u7a0b\u5f0f\u4f86\u89e3\u6c7a\u4efb\u52d9\uff0c\u56e0\u6b64\u53ef\u4ee5\u8655\u7406\u4e0d\u540c\u898f\u6a21\u7684\u5716\u5f62\u3002\u70ba\u6b64\uff0c\u81ea\u7136\u6703\u7522\u751f\u4e00\u500b\u554f\u984c\uff1aLLM \u80fd\u50cf\u5c08\u696d\u4eba\u58eb\u4e00\u6a23\u5206\u6790\u5716\u5f62\u55ce\uff1f\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 ProGraph\uff0c\u4e00\u500b\u5305\u542b 3 \u985e\u5716\u5f62\u4efb\u52d9\u7684\u624b\u5de5\u88fd\u4f5c\u57fa\u6e96\u3002\u8a72\u57fa\u6e96\u9810\u671f\u89e3\u6c7a\u65b9\u6848\u662f\u57fa\u65bc\u7a0b\u5f0f\u8a2d\u8a08\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u5c0d\u539f\u59cb\u8f38\u5165\u9032\u884c\u63a8\u7406\u3002\u6211\u5011\u7684\u767c\u73fe\u986f\u793a\uff0c\u76ee\u524d LLM \u7684\u6548\u80fd\u4e26\u4e0d\u4ee4\u4eba\u6eff\u610f\uff0c\u6700\u4f73\u6a21\u578b\u50c5\u9054\u5230 36% \u7684\u6e96\u78ba\u5ea6\u3002\u70ba\u4e86\u5f4c\u88dc\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u63d0\u51fa\u4e86 LLM4Graph \u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u6839\u64da 6 \u500b\u5ee3\u6cdb\u4f7f\u7528\u7684\u5716\u5f62\u51fd\u5f0f\u5eab\u722c\u53d6\u7684\u7684\u6587\u4ef6\u548c\u81ea\u52d5\u751f\u6210\u7684\u7a0b\u5f0f\u78bc\u3002\u900f\u904e\u4f7f\u7528\u6587\u4ef6\u6aa2\u7d22\u4f86\u64f4\u5145\u9589\u6e90 LLM\uff0c\u4e26\u91dd\u5c0d\u7a0b\u5f0f\u78bc\u5fae\u8abf\u958b\u6e90 LLM\uff0c\u6211\u5011\u5c55\u793a\u4e86\u6e96\u78ba\u5ea6\u63d0\u5347\u4e86 11-32%\u3002\u6211\u5011\u7684\u7d50\u679c\u5f37\u8abf\uff0cLLM \u5728\u8655\u7406\u7d50\u69cb\u5316\u8cc7\u6599\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u4e26\u986f\u793a\u4e86 LLM4Graph \u5728\u63d0\u5347 LLM \u5716\u5f62\u5206\u6790\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u57fa\u6e96\u3001\u8cc7\u6599\u96c6\u548c\u589e\u5f37\u7684\u958b\u6e90\u6a21\u578b\u53ef\u5728 https://github.com/BUPT-GAMMA/ProGraph \u53d6\u5f97\u3002</paragraph>", "author": "Xin Li et.al.", "authors": "Xin Li, Weize Chen, Qizhi Chu, Haopeng Li, Zhaojun Sun, Ran Li, Chen Qian, Yiwei Wei, Zhiyuan Liu, Chuan Shi, Maosong Sun, Cheng Yang", "id": "2409.19667v1", "paper_url": "http://arxiv.org/abs/2409.19667v1", "repo": "https://github.com/bupt-gamma/prograph"}}