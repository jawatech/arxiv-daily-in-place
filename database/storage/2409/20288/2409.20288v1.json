{"2409.20288": {"publish_time": "2024-09-30", "title": "LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models", "paper_summary": "Large language models (LLMs) have made significant progress in natural\nlanguage processing tasks and demonstrate considerable potential in the legal\ndomain. However, legal applications demand high standards of accuracy,\nreliability, and fairness. Applying existing LLMs to legal systems without\ncareful evaluation of their potential and limitations could pose significant\nrisks in legal practice. To this end, we introduce a standardized comprehensive\nChinese legal benchmark LexEval. This benchmark is notable in the following\nthree aspects: (1) Ability Modeling: We propose a new taxonomy of legal\ncognitive abilities to organize different tasks. (2) Scale: To our knowledge,\nLexEval is currently the largest Chinese legal evaluation dataset, comprising\n23 tasks and 14,150 questions. (3) Data: we utilize formatted existing\ndatasets, exam datasets and newly annotated datasets by legal experts to\ncomprehensively evaluate the various capabilities of LLMs. LexEval not only\nfocuses on the ability of LLMs to apply fundamental legal knowledge but also\ndedicates efforts to examining the ethical issues involved in their\napplication. We evaluated 38 open-source and commercial LLMs and obtained some\ninteresting findings. The experiments and findings offer valuable insights into\nthe challenges and potential solutions for developing Chinese legal systems and\nLLM evaluation pipelines. The LexEval dataset and leaderboard are publicly\navailable at \\url{https://github.com/CSHaitao/LexEval} and will be continuously\nupdated.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u5927\u9032\u5c55\uff0c\u4e26\u5728\u6cd5\u5f8b\u9818\u57df\u5c55\u73fe\u4e86\u5de8\u5927\u7684\u6f5b\u529b\u3002\u7136\u800c\uff0c\u6cd5\u5f8b\u61c9\u7528\u8981\u6c42\u6975\u9ad8\u7684\u6e96\u78ba\u6027\u3001\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\u3002\u5728\u672a\u4ed4\u7d30\u8a55\u4f30\u5176\u6f5b\u529b\u548c\u9650\u5236\u7684\u60c5\u6cc1\u4e0b\u5c07\u73fe\u6709\u7684 LLM \u61c9\u7528\u65bc\u6cd5\u5f8b\u7cfb\u7d71\uff0c\u53ef\u80fd\u6703\u5728\u6cd5\u5f8b\u5be6\u52d9\u4e2d\u9020\u6210\u91cd\u5927\u98a8\u96aa\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e86\u6a19\u6e96\u5316\u7684\u7d9c\u5408\u4e2d\u6587\u6cd5\u5f8b\u57fa\u6e96 LexEval\u3002\u6b64\u57fa\u6e96\u5728\u4ee5\u4e0b\u4e09\u500b\u65b9\u9762\u503c\u5f97\u6ce8\u610f\uff1a(1) \u80fd\u529b\u5efa\u6a21\uff1a\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u6cd5\u5f8b\u8a8d\u77e5\u80fd\u529b\u5206\u985e\u6cd5\uff0c\u4ee5\u7d44\u7e54\u4e0d\u540c\u7684\u4efb\u52d9\u3002(2) \u898f\u6a21\uff1a\u64da\u6211\u5011\u6240\u77e5\uff0cLexEval \u76ee\u524d\u662f\u6700\u5927\u7684\u4e2d\u6587\u6cd5\u5f8b\u8a55\u4f30\u8cc7\u6599\u96c6\uff0c\u5305\u542b 23 \u9805\u4efb\u52d9\u548c 14,150 \u500b\u554f\u984c\u3002(3) \u8cc7\u6599\uff1a\u6211\u5011\u5229\u7528\u6cd5\u5f8b\u5c08\u5bb6\u683c\u5f0f\u5316\u7684\u73fe\u6709\u8cc7\u6599\u96c6\u3001\u8003\u8a66\u8cc7\u6599\u96c6\u548c\u65b0\u8a3b\u89e3\u8cc7\u6599\u96c6\uff0c\u4ee5\u5168\u9762\u8a55\u4f30 LLM \u7684\u5404\u7a2e\u80fd\u529b\u3002LexEval \u4e0d\u50c5\u5c08\u6ce8\u65bc LLM \u61c9\u7528\u57fa\u672c\u6cd5\u5f8b\u77e5\u8b58\u7684\u80fd\u529b\uff0c\u9084\u81f4\u529b\u65bc\u5be9\u67e5\u5176\u61c9\u7528\u4e2d\u6d89\u53ca\u7684\u502b\u7406\u554f\u984c\u3002\u6211\u5011\u8a55\u4f30\u4e86 38 \u500b\u958b\u6e90\u548c\u5546\u696d LLM\uff0c\u4e26\u7372\u5f97\u4e86\u4e00\u4e9b\u6709\u8da3\u7684\u767c\u73fe\u3002\u9019\u4e9b\u5be6\u9a57\u548c\u767c\u73fe\u70ba\u958b\u767c\u4e2d\u6587\u6cd5\u5f8b\u7cfb\u7d71\u548c LLM \u8a55\u4f30\u7ba1\u9053\u63d0\u4f9b\u4e86\u5bf6\u8cb4\u7684\u898b\u89e3\u3002LexEval \u8cc7\u6599\u96c6\u548c\u6392\u884c\u699c\u516c\u958b\u65bc \\url{https://github.com/CSHaitao/LexEval}\uff0c\u4e26\u5c07\u6301\u7e8c\u66f4\u65b0\u3002", "author": "Haitao Li et.al.", "authors": "Haitao Li, You Chen, Qingyao Ai, Yueyue Wu, Ruizhe Zhang, Yiqun Liu", "id": "2409.20288v1", "paper_url": "http://arxiv.org/abs/2409.20288v1", "repo": "https://github.com/cshaitao/lexeval"}}