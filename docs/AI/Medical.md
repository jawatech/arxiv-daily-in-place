
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-13**|**Generative AI in Medicine**|Divya Shanmugam et.al.|[2412.10337v1](http://arxiv.org/abs/2412.10337v1)|null|
|**2024-12-13**|**A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**|Ayush Deshmukh et.al.|[2412.10106v1](http://arxiv.org/abs/2412.10106v1)|null|
|**2024-12-13**|**Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**|Tao Song et.al.|[2412.09998v1](http://arxiv.org/abs/2412.09998v1)|null|
|**2024-12-13**|**Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**|Qiao Sun et.al.|[2412.09946v1](http://arxiv.org/abs/2412.09946v1)|null|
|**2024-12-12**|**Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis**|Shengxuming Zhang et.al.|[2412.09521v1](http://arxiv.org/abs/2412.09521v1)|null|
|**2024-12-12**|**Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine**|Xiaoshuang Huang et.al.|[2412.09278v1](http://arxiv.org/abs/2412.09278v1)|[link](https://github.com/shawnhuang497/medplib)|
|**2024-12-12**|**CSSDH: An Ontology for Social Determinants of Health to Operational Continuity of Care Data Interoperability**|Subhashis Das et.al.|[2412.09223v1](http://arxiv.org/abs/2412.09223v1)|null|
|**2024-12-12**|**Understanding Opportunities and Risks of Synthetic Relationships: Leveraging the Power of Longitudinal Research with Customised AI Tools**|Alfio Ventura et.al.|[2412.09086v1](http://arxiv.org/abs/2412.09086v1)|null|
|**2024-12-12**|**Radiology Report Generation via Multi-objective Preference Optimization**|Ting Xiao et.al.|[2412.08901v2](http://arxiv.org/abs/2412.08901v2)|null|
|**2024-12-12**|**AI-assisted Knowledge Discovery in Biomedical Literature to Support Decision-making in Precision Oncology**|Ting He et.al.|[2412.08900v1](http://arxiv.org/abs/2412.08900v1)|null|
|**2024-12-12**|**Towards modeling evolving longitudinal health trajectories with a transformer-based deep learning model**|Hans Moen et.al.|[2412.08873v1](http://arxiv.org/abs/2412.08873v1)|null|
|**2024-12-11**|**Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions**|Jiarui Zhang et.al.|[2412.08737v1](http://arxiv.org/abs/2412.08737v1)|null|
|**2024-12-11**|**Assisted morbidity coding: the SISCO.web use case for identifying the main diagnosis in Hospital Discharge Records**|Elena Cardillo et.al.|[2412.09651v1](http://arxiv.org/abs/2412.09651v1)|null|
|**2024-12-11**|**IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**|Gauri Jain et.al.|[2412.08463v1](http://arxiv.org/abs/2412.08463v1)|[link](https://github.com/gjain234/whirl)|
|**2024-12-11**|**SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**|Sultan Alrashed et.al.|[2412.08347v1](http://arxiv.org/abs/2412.08347v1)|null|
|**2024-12-11**|**Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures**|CÃ©lia Blondin et.al.|[2412.08228v1](http://arxiv.org/abs/2412.08228v1)|[link](https://github.com/celia-bl/hierarchical_classifying_corals_dataset)|
|**2024-12-11**|**How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**|Yixin Zhang et.al.|[2412.08081v1](http://arxiv.org/abs/2412.08081v1)|null|
|**2024-12-11**|**Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning**|Chongyi Zheng et.al.|[2412.08021v1](http://arxiv.org/abs/2412.08021v1)|[link](https://github.com/Princeton-RL/contrastive-successor-features)|
|**2024-12-10**|**From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents**|Mohit Chandra et.al.|[2412.07951v2](http://arxiv.org/abs/2412.07951v2)|null|
|**2024-12-10**|**How Should We Represent History in Interpretable Models of Clinical Policies?**|Anton Matsson et.al.|[2412.07895v1](http://arxiv.org/abs/2412.07895v1)|[link](https://github.com/Healthy-AI/inpole)|
|**2024-12-10**|**Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact**|Yunfan Zhao et.al.|[2412.07880v2](http://arxiv.org/abs/2412.07880v2)|null|
|**2024-12-10**|**Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG**|Shivraj Singh Bhatti et.al.|[2412.07878v1](http://arxiv.org/abs/2412.07878v1)|null|
|**2024-12-10**|**Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**|Marcos Da Silveira et.al.|[2412.09644v1](http://arxiv.org/abs/2412.09644v1)|null|
|**2024-12-10**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618v1](http://arxiv.org/abs/2412.07618v1)|[link](https://github.com/futureeeeee/dynamic-rag)|
|**2024-12-10**|**Scaling Sequential Recommendation Models with Transformers**|Pablo Zivic et.al.|[2412.07585v1](http://arxiv.org/abs/2412.07585v1)|[link](https://github.com/mercadolibre/srt)|
|**2024-12-10**|**Knowledge Graph Guided Evaluation of Abstention Techniques**|Kinshuk Vasisht et.al.|[2412.07430v1](http://arxiv.org/abs/2412.07430v1)|null|
|**2024-12-10**|**A Review of Challenges in Speech-based Conversational AI for Elderly Care**|Willemijn Klaassen et.al.|[2412.07388v1](http://arxiv.org/abs/2412.07388v1)|null|
|**2024-12-10**|**Enhanced MRI Representation via Cross-series Masking**|Churan Wang et.al.|[2412.07387v1](http://arxiv.org/abs/2412.07387v1)|null|
|**2024-12-10**|**On Evaluating the Durability of Safeguards for Open-Weight LLMs**|Xiangyu Qi et.al.|[2412.07097v1](http://arxiv.org/abs/2412.07097v1)|[link](https://github.com/ai-law-society-lab/evaluating-durable-safeguards)|
|**2024-12-09**|**Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**|Le Song et.al.|[2412.06993v1](http://arxiv.org/abs/2412.06993v1)|[link](https://github.com/genbio-ai/aido)|
|**2024-12-09**|**Diagnosis and Severity Assessment of Ulcerative Colitis using Self Supervised Learning**|Venkat Margapuri et.al.|[2412.07806v1](http://arxiv.org/abs/2412.07806v1)|null|
|**2024-12-09**|**Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**|Sahil Sethi et.al.|[2412.06717v1](http://arxiv.org/abs/2412.06717v1)|null|
|**2024-12-09**|**Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**|Aqib Nazir Mir et.al.|[2412.06709v1](http://arxiv.org/abs/2412.06709v1)|null|
|**2024-12-09**|**Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**|Sooyong Jang et.al.|[2412.06624v1](http://arxiv.org/abs/2412.06624v1)|[link](https://github.com/precise-ai4oph/va_pred_pac)|
|**2024-12-09**|**Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices**|Biman Barua et.al.|[2412.06874v1](http://arxiv.org/abs/2412.06874v1)|null|
|**2024-12-09**|**Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System**|Yubo Zhou et.al.|[2412.06600v2](http://arxiv.org/abs/2412.06600v2)|[link](https://github.com/everydaylucky/wu_xing_harmony_system)|
|**2024-12-09**|**HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**|Jiayan Chen et.al.|[2412.06530v1](http://arxiv.org/abs/2412.06530v1)|null|
|**2024-12-09**|**Simulating Human-like Daily Activities with Desire-driven Autonomy**|Yiding Wang et.al.|[2412.06435v1](http://arxiv.org/abs/2412.06435v1)|null|
|**2024-12-09**|**CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**|Yijie Dang et.al.|[2412.06314v1](http://arxiv.org/abs/2412.06314v1)|null|
|**2024-12-09**|**A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder**|Quansong He et.al.|[2412.06262v1](http://arxiv.org/abs/2412.06262v1)|[link](https://github.com/nayutayuki/lightweight-nmode-decoders-for-u-like-networks)|
|**2024-12-09**|**MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery**|Qinfeng Zhu et.al.|[2412.06211v1](http://arxiv.org/abs/2412.06211v1)|null|
|**2024-12-09**|**Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction**|Guoxiao Zhang et.al.|[2412.06860v1](http://arxiv.org/abs/2412.06860v1)|null|
|**2024-12-09**|**MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**|Kangyu Zhu et.al.|[2412.06141v1](http://arxiv.org/abs/2412.06141v1)|[link](https://github.com/aiming-lab/mmedpo)|
|**2024-12-08**|**Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research**|Akshat Choube et.al.|[2412.06018v1](http://arxiv.org/abs/2412.06018v1)|null|
|**2024-12-08**|**MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training**|Xuefeng Ni et.al.|[2412.05876v1](http://arxiv.org/abs/2412.05876v1)|[link](https://github.com/xuefeng-ni/mg-3d)|
|**2024-12-08**|**Evolving Algebraic Multigrid Methods Using Grammar-Guided Genetic Programming**|Dinesh Parthasarathy et.al.|[2412.05852v1](http://arxiv.org/abs/2412.05852v1)|null|
|**2024-12-07**|**Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages**|Abd Ur Rehman et.al.|[2412.05632v1](http://arxiv.org/abs/2412.05632v1)|null|
|**2024-12-07**|**UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation**|Saba Hesaraki et.al.|[2412.05585v1](http://arxiv.org/abs/2412.05585v1)|null|
|**2024-12-07**|**Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms**|Atit Pokharel et.al.|[2412.05583v2](http://arxiv.org/abs/2412.05583v2)|null|
|**2024-12-07**|**Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison**|Cailian Ruan et.al.|[2412.05536v1](http://arxiv.org/abs/2412.05536v1)|null|
|**2024-12-06**|**Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System**|Fang Zeng et.al.|[2412.06828v1](http://arxiv.org/abs/2412.06828v1)|null|
|**2024-12-06**|**Enhancing FKG.in: automating Indian food composition analysis**|Saransh Kumar Gupta et.al.|[2412.05248v2](http://arxiv.org/abs/2412.05248v2)|null|
|**2024-12-06**|**Are Frontier Large Language Models Suitable for Q&A in Science Centres?**|Jacob Watson et.al.|[2412.05200v1](http://arxiv.org/abs/2412.05200v1)|null|
|**2024-12-06**|**SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**|Jinlin Wu et.al.|[2412.05187v1](http://arxiv.org/abs/2412.05187v1)|[link](https://github.com/franciszchen/surgbox)|
|**2024-12-06**|**Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**|Thomas Sievers et.al.|[2412.05013v1](http://arxiv.org/abs/2412.05013v1)|null|
|**2024-12-06**|**Backdooring Outlier Detection Methods: A Novel Attack Approach**|ZeinabSadat Taghavi et.al.|[2412.05010v1](http://arxiv.org/abs/2412.05010v1)|null|
|**2024-12-06**|**Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**|Thomas Bartz-Beielstein et.al.|[2412.04950v1](http://arxiv.org/abs/2412.04950v1)|null|
|**2024-12-06**|**Estimating the treatment effect over time under general interference through deep learner integrated TMLE**|Suhan Guo et.al.|[2412.04799v1](http://arxiv.org/abs/2412.04799v1)|null|
|**2024-12-06**|**Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**|Mahfuzul Haque et.al.|[2412.04792v1](http://arxiv.org/abs/2412.04792v1)|null|
|**2024-12-06**|**DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**|Shadab Ahamed et.al.|[2412.04766v1](http://arxiv.org/abs/2412.04766v1)|null|
|**2024-12-06**|**PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**|Hongjin Lin et.al.|[2412.04714v1](http://arxiv.org/abs/2412.04714v1)|null|
|**2024-12-05**|**Semantic Consistency-Based Uncertainty Quantification for Factuality in Radiology Report Generation**|Chenyu Wang et.al.|[2412.04606v1](http://arxiv.org/abs/2412.04606v1)|null|
|**2024-12-05**|**CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations**|Subash Neupane et.al.|[2412.04254v1](http://arxiv.org/abs/2412.04254v1)|null|
|**2024-12-05**|**Automated Medical Report Generation for ECG Data: Bridging Medical Text and Signal Processing with Deep Learning**|Amnon Bleich et.al.|[2412.04067v1](http://arxiv.org/abs/2412.04067v1)|null|
|**2024-12-05**|**FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems**|Jiechao Gao et.al.|[2412.03851v1](http://arxiv.org/abs/2412.03851v1)|null|
|**2024-12-05**|**ELEMENT: Episodic and Lifelong Exploration via Maximum Entropy**|Hongming Li et.al.|[2412.03800v1](http://arxiv.org/abs/2412.03800v1)|null|
|**2024-12-05**|**Automated Multi-Label Annotation for Mental Health Illnesses Using Large Language Models**|Abdelrahaman A. Hassan et.al.|[2412.03796v1](http://arxiv.org/abs/2412.03796v1)|null|
|**2024-12-05**|**Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**|Yerin Choi et.al.|[2412.03784v1](http://arxiv.org/abs/2412.03784v1)|null|
|**2024-12-04**|**Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety**|Dilan Mian et.al.|[2412.03740v1](http://arxiv.org/abs/2412.03740v1)|null|
|**2024-12-04**|**MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities**|Haoning Wu et.al.|[2412.04106v1](http://arxiv.org/abs/2412.04106v1)|null|
|**2024-12-04**|**Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**|Yiqin Zhang et.al.|[2412.03352v1](http://arxiv.org/abs/2412.03352v1)|[link](https://github.com/mgamz/psbpd)|
|**2024-12-04**|**Detecting abnormal heart sound using mobile phones and on-device IConNet**|Linh Vu et.al.|[2412.03267v1](http://arxiv.org/abs/2412.03267v1)|null|
|**2024-12-04**|**MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**|Hyojeong Lee et.al.|[2412.03039v1](http://arxiv.org/abs/2412.03039v1)|null|
|**2024-12-04**|**Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**|Soroush Omranpour et.al.|[2412.02919v1](http://arxiv.org/abs/2412.02919v1)|null|
|**2024-12-03**|**A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**|Yixiang Qu et.al.|[2412.02868v1](http://arxiv.org/abs/2412.02868v1)|null|
|**2024-12-03**|**Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**|Oliver Simonoski et.al.|[2412.02851v1](http://arxiv.org/abs/2412.02851v1)|null|
|**2024-12-03**|**CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels**|Lingxiao Wei et.al.|[2412.02819v3](http://arxiv.org/abs/2412.02819v3)|null|
|**2024-12-03**|**Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**|Jingyuan Yi et.al.|[2412.02801v2](http://arxiv.org/abs/2412.02801v2)|null|
|**2024-12-03**|**Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**|Kai Sun et.al.|[2412.02621v1](http://arxiv.org/abs/2412.02621v1)|null|
|**2024-12-03**|**U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**|Fnu Neha et.al.|[2412.02242v1](http://arxiv.org/abs/2412.02242v1)|null|
|**2024-12-03**|**Recovering implicit physics model under real-world constraints**|Ayan Banerjee et.al.|[2412.02215v1](http://arxiv.org/abs/2412.02215v1)|null|
|**2024-12-03**|**Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**|Abu Bakar Siddik et.al.|[2412.02189v1](http://arxiv.org/abs/2412.02189v1)|null|
|**2024-12-03**|**Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**|R. Mahmood et.al.|[2412.02177v1](http://arxiv.org/abs/2412.02177v1)|null|
|**2024-12-03**|**Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**|Nader Karayanni et.al.|[2412.02173v1](http://arxiv.org/abs/2412.02173v1)|null|
|**2024-12-03**|**Construction and optimization of health behavior prediction model for the elderly in smart elderly care**|Qian Guo et.al.|[2412.02062v1](http://arxiv.org/abs/2412.02062v1)|null|
|**2024-12-02**|**INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**|Wenbo Zhang et.al.|[2412.02012v2](http://arxiv.org/abs/2412.02012v2)|null|
|**2024-12-02**|**The use of large language models to enhance cancer clinical trial educational materials**|Mingye Gao et.al.|[2412.01955v2](http://arxiv.org/abs/2412.01955v2)|null|
|**2024-12-02**|**Recurrent Neural Network on PICTURE Model**|Weihan Xu et.al.|[2412.01933v1](http://arxiv.org/abs/2412.01933v1)|null|
|**2024-12-02**|**ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**|Poorya Aghaomidi et.al.|[2412.01929v1](http://arxiv.org/abs/2412.01929v1)|null|
|**2024-12-02**|**Deep Guess acceleration for explainable image reconstruction in sparse-view CT**|Elena Loli Piccolomini et.al.|[2412.01703v1](http://arxiv.org/abs/2412.01703v1)|[link](https://github.com/devangelista2/DeepGuess)|
|**2024-12-02**|**Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**|Liza Dahiya et.al.|[2412.01692v1](http://arxiv.org/abs/2412.01692v1)|null|
|**2024-12-02**|**Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**|Jie Liu et.al.|[2412.01605v1](http://arxiv.org/abs/2412.01605v1)|null|
|**2024-12-02**|**NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**|Sandesh Pokhrel et.al.|[2412.01590v1](http://arxiv.org/abs/2412.01590v1)|[link](https://github.com/bhattarailab/ncdd)|
|**2024-12-02**|**MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**|Thi-Nhu-Quynh Nguyen et.al.|[2412.01405v1](http://arxiv.org/abs/2412.01405v1)|[link](https://github.com/nqnguyen812/mambau-lite)|
|**2024-12-02**|**Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**|Chayan Tank et.al.|[2412.01353v1](http://arxiv.org/abs/2412.01353v1)|null|
|**2024-12-02**|**Multimodal Medical Disease Classification with LLaMA II**|Christian Gapp et.al.|[2412.01306v1](http://arxiv.org/abs/2412.01306v1)|null|
|**2024-12-02**|**Best Practices for Large Language Models in Radiology**|Christian Bluethgen et.al.|[2412.01233v1](http://arxiv.org/abs/2412.01233v1)|null|
|**2024-12-02**|**Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**|Mojtaba S. Fazli et.al.|[2412.01119v1](http://arxiv.org/abs/2412.01119v1)|null|
|**2024-12-02**|**Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**|Razi Mahmood et.al.|[2412.01031v2](http://arxiv.org/abs/2412.01031v2)|null|
|**2024-12-01**|**Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**|Summra Saleem et.al.|[2412.00959v1](http://arxiv.org/abs/2412.00959v1)|null|

#### Abstracts
##### **Generative AI in Medicine**
2412.10337v1 by Divya Shanmugam, Monica Agrawal, Rajiv Movva, Irene Y. Chen, Marzyeh Ghassemi, Emma Pierson

The increased capabilities of generative AI have dramatically expanded its
possible use cases in medicine. We provide a comprehensive overview of
generative AI use cases for clinicians, patients, clinical trial organizers,
researchers, and trainees. We then discuss the many challenges -- including
maintaining privacy and security, improving transparency and interpretability,
upholding equity, and rigorously evaluating models -- which must be overcome to
realize this potential, and the open research directions they give rise to.

æè¦ï¼çæå¼ AI çè½åæåå¤§å¹æ´å±äºå¶å¨é«å­¸ä¸­çæ½å¨æç¨æ¡ä¾ãæåæä¾äºä¸åå¨é¢çæ¦è§ï¼èªªæçæå¼ AI å¨è¨åºé«çãæ£èãè¨åºè©¦é©çµç¹èãç ç©¶äººå¡ååè¨äººå¡çæç¨æ¡ä¾ãæ¥èï¼æåè¨è«äºè¨±å¤ææ°ï¼åæ¬ç¶­è­·é±ç§åå®å¨æ§ãæåéæåº¦åå¯è§£éæ§ãç¶­è­·å¬å¹³æ§ï¼ä»¥åå´æ ¼è©ä¼°æ¨¡åï¼éäºææ°å¿é åææè½å¯¦ç¾éç¨®æ½åï¼ä»¥åå®åå¼ç¼çéæ¾ç ç©¶æ¹åã

##### **A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**
2412.10106v1 by Ayush Deshmukh

The global outbreak of Mpox virus, classified as a Public Health Emergency of
International Concern by WHO, presents significant diagnostic challenges due to
its visual similarity to other skin lesion diseases. Current clinical detection
techniques face limitations in accuracy and efficiency, necessitating improved
automated diagnostic solutions. This study introduces a novel Cascaded Atrous
Group Attention (CAGA) module, specifically designed to enhance multi-scale
feature representation while optimizing computational efficiency. By
integrating CAGA with EfficientViT-L1 as the backbone architecture, our
approach achieves state-of-the-art performance with a score of 0.98% on the
MCSI dataset, while reducing model parameters by 37.5% compared to the original
EfficientViT-L1. This reduction in computational complexity maintains
diagnostic accuracy while enabling broader deployment across
resource-constrained healthcare settings. Extensive validation across two other
benchmark datasets, including MSID and MSLD, demonstrate the model's
robustness, consistently outperforming existing approaches. Our findings
suggest that CAGA's efficient feature extraction mechanism could be adapted for
other medical imaging tasks requiring fine-grained visual discrimination.

æè¦ï¼ç±æ¼ä¸çè¡ççµç¹å°ç´ççæ¯å¨ççç¼å®çºåééæ³¨çå¬å±è¡çç·æ¥äºä»¶ï¼å æ­¤ç´ççæ¯èå¶ä»ç®èçè®ç¾çå¨è¦è¦ºä¸çç¸ä¼¼æ§ï¼å°è¨ºæ·å¸¶ä¾éå¤§ææ°ãç®åçè¨åºæª¢æ¸¬æè¡å¨æºç¢ºæ§åæçæ¹é¢é¢è¨éå¶ï¼å æ­¤éè¦æ¹é²çèªååè¨ºæ·è§£æ±ºæ¹æ¡ãæ¬ç ç©¶å¼å¥äºä¸åæ°ç©çä¸²è¯ç©ºæ´çµæ³¨æå (CAGA) æ¨¡çµï¼å°éè¨­è¨ç¨æ¼å¢å¼·å¤å°ºåº¦ç¹å¾µè¡¨ç¤ºï¼åææä½³åéç®æçãééå° CAGA è EfficientViT-L1 æ´åä½çºä¸»å¹¹æ¶æ§ï¼æåçåæ³å¨ MCSI è³æéä¸ä»¥ 0.98% çåæ¸éå°äºæåé²çæè½ï¼åæèåå§ EfficientViT-L1 ç¸æ¯ï¼æ¨¡ååæ¸æ¸å°äº 37.5%ãéç¨®éç®è¤éåº¦çéä½ç¶­æäºè¨ºæ·æºç¢ºæ§ï¼åææ¯æ´å¨è³æºåéçé«çä¿å¥ç°å¢ä¸­æ´å»£æ³å°é¨ç½²ãå¨åæ¬ MSID å MSLD å¨å§çå¦å¤å©ååºæºè³æéä¸çå»£æ³é©è­è­æäºæ¨¡åçç©©å¥æ§ï¼å§çµåªæ¼ç¾ææ¹æ³ãæåçç ç©¶çµæè¡¨æï¼CAGA çé«æç¹å¾µæåæ©å¶å¯ä»¥èª¿æ´çºå¶ä»éè¦ç´°ç·»è¦è¦ºè¾¨å¥çé«å­¸å½±åä»»åã

##### **Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**
2412.09998v1 by Tao Song, Yicheng Wu, Minhao Hu, Xiangde Luo, Guoting Luo, Guotai Wang, Yi Guo, Feng Xu, Shaoting Zhang

Accelerated MRI reconstruction techniques aim to reduce examination time
while maintaining high image fidelity, which is highly desirable in clinical
settings for improving patient comfort and hospital efficiency. Existing deep
learning methods typically reconstruct images from under-sampled data with
traditional reconstruction approaches, but they still struggle to provide
high-fidelity results. Diffusion models show great potential to improve
fidelity of generated images in recent years. However, their inference process
starting with a random Gaussian noise introduces instability into the results
and usually requires thousands of sampling steps, resulting in sub-optimal
reconstruction quality and low efficiency. To address these challenges, we
propose Cycle-Consistent Bridge Diffusion Model (CBDM). CBDM employs two bridge
diffusion models to construct a cycle-consistent diffusion process with a
consistency loss, enhancing the fine-grained details of reconstructed images
and reducing the number of diffusion steps. Moreover, CBDM incorporates a
Contourlet Decomposition Embedding Module (CDEM) which captures multi-scale
structural texture knowledge in images through frequency domain decomposition
pyramids and directional filter banks to improve structural fidelity. Extensive
experiments demonstrate the superiority of our model by higher reconstruction
quality and fewer training iterations, achieving a new state of the art for
accelerated MRI reconstruction in both fastMRI and IXI datasets.

æè¦ï¼å éå¼ MRI éå»ºæè¡æ¨å¨ç¸®ç­æª¢æ¥æéï¼åæç¶­æé«å½±åä¿çåº¦ï¼éå¨è¨åºç°å¢ä¸­éå¸¸çæ³ï¼å¯æåçæ£èé©åº¦åé«é¢æçãç¾æçæ·±åº¦å­¸ç¿æ¹æ³éå¸¸ä½¿ç¨å³çµ±éå»ºæ¹æ³å¾æ¬ æ¡æ¨£æ¸æéå»ºå½±åï¼ä½ä»é£ä»¥æä¾é«ä¿çåº¦çµæãæ´æ£æ¨¡åå¨è¿å¹´å±ç¾åºæåçæå½±åä¿çåº¦ççµä½³æ½åãç¶èï¼å¶å¾é¨æ©é«æ¯éè¨éå§çæ¨è«éç¨æçºçµæå¸¶ä¾ä¸ç©©å®æ§ï¼ä¸éå¸¸éè¦æ¸ååæ¡æ¨£æ­¥é©ï¼å°è´æ¬¡æä½³éå»ºåè³ªåä½æçãçºäºæå°éäºææ°ï¼æåæåºå¾ªç°ä¸è´æ©æ¥æ´æ£æ¨¡å (CBDM)ãCBDM ä½¿ç¨å©åæ©æ¥æ´æ£æ¨¡åï¼å»ºæ§ä¸åå·æç¸å®¹æ§æå¤±çå¾ªç°ä¸è´æ´æ£éç¨ï¼å¢å¼·éå»ºå½±åçç²¾ç´°ç´°ç¯ä¸¦æ¸å°æ´æ£æ­¥é©çæ¸éãæ­¤å¤ï¼CBDM æ´åäºä¸åè¼ªå»åè§£åµå¥æ¨¡çµ (CDEM)ï¼ééé »ååè§£éå­å¡åæ¹åæ¿¾æ³¢å¨çµå¨å½±åä¸­æ·åå¤å°ºåº¦çµæ§ç´çç¥è­ï¼ä»¥æåçµæ§ä¿çåº¦ãå»£æ³çå¯¦é©è­æäºæåæ¨¡åçåªç°æ§ï¼å·ææ´é«çéå»ºåè³ªåæ´å°çè¨ç·´åè¦éç®ï¼å¨ fastMRI å IXI è³æéçå éå¼ MRI éå»ºä¸­éææ°çæè¡æ°´æºã

##### **Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**
2412.09946v1 by Qiao Sun, Jiexin Xie, Nanyang Ye, Qinying Gu, Shijie Guo

This paper explores the application of large language models (LLMs) in
nursing and elderly care, focusing on AI-driven patient monitoring and
interaction. We introduce a novel Chinese nursing dataset and implement
incremental pre-training (IPT) and supervised fine-tuning (SFT) techniques to
enhance LLM performance in specialized tasks. Using LangChain, we develop a
dynamic nursing assistant capable of real-time care and personalized
interventions. Experimental results demonstrate significant improvements,
paving the way for AI-driven solutions to meet the growing demands of
healthcare in aging populations.

æè¦ï¼æ¬ææ¢è¨å¤§åèªè¨æ¨¡å (LLM) å¨è­·çåèå¹´ç§è­·ä¸­çæç¨ï¼éé»å¨æ¼ AI é©åççäººç£æ§åäºåãæåå¼å¥äºä¸åæ°ç©çä¸­æè­·çè³æéï¼ä¸¦å¯¦æ½å¢éé è¨ç·´ (IPT) åç£ç£å¾®èª¿ (SFT) æè¡ï¼ä»¥å¢å¼· LLM å¨å°æ¥­ä»»åä¸­çè¡¨ç¾ãä½¿ç¨ LangChainï¼æåéç¼äºä¸ååæè­·çå©çï¼è½å¤ æä¾å³æç§è­·ååäººåå¹²é æªæ½ãå¯¦é©çµæè­æäºé¡¯èçæ¹é²ï¼çº AI é©åçè§£æ±ºæ¹æ¡éªå¹³äºéè·¯ï¼ä»¥æ»¿è¶³èé½¡åäººå£å°é«çä¿å¥æ¥çå¢é·çéæ±ã

##### **Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Clinical Pathology Analysis**
2412.09521v1 by Shengxuming Zhang, Weihan Li, Tianhong Gao, Jiacong Hu, Haoming Luo, Mingli Song, Xiuming Zhang, Zunlei Feng

Pathological diagnosis is vital for determining disease characteristics,
guiding treatment, and assessing prognosis, relying heavily on detailed,
multi-scale analysis of high-resolution whole slide images (WSI). However,
traditional pure vision models face challenges of redundant feature extraction,
whereas existing large vision-language models (LVLMs) are limited by input
resolution constraints, hindering their efficiency and accuracy. To overcome
these issues, we propose two innovative strategies: the mixed task-guided
feature enhancement, which directs feature extraction toward lesion-related
details across scales, and the prompt-guided detail feature completion, which
integrates coarse- and fine-grained features from WSI based on specific prompts
without compromising inference speed. Leveraging a comprehensive dataset of
490,000 samples from diverse pathology tasks-including cancer detection,
grading, vascular and neural invasion identification, and so on-we trained the
pathology-specialized LVLM, OmniPath. Extensive experiments demonstrate that
this model significantly outperforms existing methods in diagnostic accuracy
and efficiency, offering an interactive, clinically aligned approach for
auxiliary diagnosis in a wide range of pathology applications.

æè¦ï¼ççè¯æ­å¯¹äºç¡®å®ç¾çç¹å¾ãæå¯¼æ²»çåè¯ä¼°é¢åè³å³éè¦ï¼å®ä¸¥éä¾èµäºå¯¹é«åè¾¨çå¨ç»çå¾å (WSI) çè¯¦ç»ãå¤å°ºåº¦åæãç¶èï¼ä¼ ç»ççº¯è§è§æ¨¡åé¢ä¸´åä½ç¹å¾æåçææï¼èç°æçå¤§åè§è§è¯­è¨æ¨¡å (LVLMs) åå°è¾å¥åè¾¨ççº¦æçéå¶ï¼é»ç¢äºå®ä»¬çæçååç¡®æ§ãä¸ºäºåæè¿äºé®é¢ï¼æä»¬æåºäºä¸¤ç§åæ°ç­ç¥ï¼æ··åä»»å¡å¼å¯¼çç¹å¾å¢å¼ºï¼å®å°ç¹å¾æåå¼å¯¼å°è·¨å°ºåº¦ççåç¸å³ç»èä¸ï¼ä»¥åæç¤ºå¼å¯¼çç»èç¹å¾å®æï¼å®åºäºç¹å®æç¤ºå° WSI ä¸­çç²ç²åº¦åç»ç²åº¦ç¹å¾éæå¨ä¸èµ·ï¼èä¸ä¼å½±åæ¨çéåº¦ãå©ç¨æ¥èªä¸åççä»»å¡ç 490,000 ä¸ªæ ·æ¬çç»¼åæ°æ®éï¼åæ¬ççæ£æµãåçº§ãè¡ç®¡åç¥ç»ä¾µè¢­è¯å«ç­ï¼æä»¬è®­ç»äºççå­¦ä¸ä¸ LVLMï¼å³ OmniPathãå¤§éçå®éªè¡¨æï¼è¯¥æ¨¡åå¨è¯æ­åç¡®æ§åæçæ¹é¢ææ¾ä¼äºç°ææ¹æ³ï¼ä¸ºå¹¿æ³çççå­¦åºç¨ä¸­çè¾å©è¯æ­æä¾äºä¸ç§äº¤äºå¼ãä¸´åºä¸ä¸è´çæ¹æ³ã

##### **Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine**
2412.09278v1 by Xiaoshuang Huang, Lingdong Shen, Jia Liu, Fangxin Shang, Hongxiang Li, Haifeng Huang, Yehui Yang

In recent years, Multimodal Large Language Models (MLLM) have achieved
notable advancements, demonstrating the feasibility of developing an
intelligent biomedical assistant. However, current biomedical MLLMs
predominantly focus on image-level understanding and restrict interactions to
textual commands, thus limiting their capability boundaries and the flexibility
of usage. In this paper, we introduce a novel end-to-end multimodal large
language model for the biomedical domain, named MedPLIB, which possesses
pixel-level understanding. Excitingly, it supports visual question answering
(VQA), arbitrary pixel-level prompts (points, bounding boxes, and free-form
shapes), and pixel-level grounding. We propose a novel Mixture-of-Experts (MoE)
multi-stage training strategy, which divides MoE into separate training phases
for a visual-language expert model and a pixel-grounding expert model, followed
by fine-tuning using MoE. This strategy effectively coordinates multitask
learning while maintaining the computational cost at inference equivalent to
that of a single expert model. To advance the research of biomedical MLLMs, we
introduce the Medical Complex Vision Question Answering Dataset (MeCoVQA),
which comprises an array of 8 modalities for complex medical imaging question
answering and image region understanding. Experimental results indicate that
MedPLIB has achieved state-of-the-art outcomes across multiple medical visual
language tasks. More importantly, in zero-shot evaluations for the pixel
grounding task, MedPLIB leads the best small and large models by margins of
19.7 and 15.6 respectively on the mDice metric. The codes, data, and model
checkpoints will be made publicly available at
https://github.com/ShawnHuang497/MedPLIB.

æè¦ï¼<paragraph>è¿å¹´æ¥ï¼å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) å·²åå¾æ¾èè¿å±ï¼è¯æäºå¼åæºè½çç©å»å­¦å©ççå¯è¡æ§ãç¶èï¼å½åççç©å»å­¦ MLLM ä¸»è¦ä¸æ³¨äºå¾åçº§çè§£ï¼å¹¶å°äº¤äºéå¶å¨ææ¬å½ä»¤ä¸­ï¼ä»èéå¶äºå®ä»¬çè½åè¾¹çåä½¿ç¨çµæ´»æ§ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äºä¸ä¸ªç¨äºçç©å»å­¦é¢åçå¨æ°ç«¯å°ç«¯å¤æ¨¡æå¤§åè¯­è¨æ¨¡åï¼åä¸º MedPLIBï¼å®å·æåç´ çº§çè§£è½åãä»¤äººå´å¥çæ¯ï¼å®æ¯æè§è§é®ç­ (VQA)ãä»»æåç´ çº§æç¤ºï¼ç¹ãè¾¹çæ¡åèªç±å½¢å¼å½¢ç¶ï¼ä»¥ååç´ çº§æ¥å°ãæä»¬æåºäºä¸ç§æ°é¢çä¸å®¶æ··å (MoE) å¤é¶æ®µè®­ç»ç­ç¥ï¼è¯¥ç­ç¥å° MoE åä¸ºè§è§è¯­è¨ä¸å®¶æ¨¡åååç´ æ¥å°ä¸å®¶æ¨¡åçåç¬è®­ç»é¶æ®µï¼ç¶åä½¿ç¨ MoE è¿è¡å¾®è°ãè¯¥ç­ç¥ææå°åè°äºå¤ä»»å¡å­¦ä¹ ï¼åæ¶å°æ¨çæ¶çè®¡ç®ææ¬ä¿æå¨ä¸åä¸ªä¸å®¶æ¨¡åç¸å½çæ°´å¹³ãä¸ºäºæ¨è¿çç©å»å­¦ MLLM çç ç©¶ï¼æä»¬å¼å¥äºå»å­¦å¤æè§è§é®ç­æ°æ®é (MeCoVQA)ï¼å®åå«ä¸ç³»å 8 ç§ç¨äºå¤æå»å­¦å½±åé®ç­åå¾ååºåçè§£çæ¨¡æãå®éªç»æè¡¨æï¼MedPLIB å¨å¤ä¸ªå»å­¦è§è§è¯­è¨ä»»å¡ä¸­åå¾äºæåè¿çææãæ´éè¦çæ¯ï¼å¨åç´ æ¥å°ä»»å¡çé¶æ ·æ¬è¯ä¼°ä¸­ï¼MedPLIB å¨ mDice ææ ä¸åå«ä»¥ 19.7 å 15.6 çä¼å¿é¢åäºæå¥½çå°ååå¤§åæ¨¡åãä»£ç ãæ°æ®åæ¨¡åæ£æ¥ç¹å°å¨ https://github.com/ShawnHuang497/MedPLIB ä¸å¬å¼ã
</paragraph>

##### **CSSDH: An Ontology for Social Determinants of Health to Operational Continuity of Care Data Interoperability**
2412.09223v1 by Subhashis Das, Debashis Naskar, Sara Rodriguez Gonzalez

The rise of digital platforms has led to an increasing reliance on
technology-driven, home-based healthcare solutions, enabling individuals to
monitor their health and share information with healthcare professionals as
needed. However, creating an efficient care plan management system requires
more than just analyzing hospital summaries and Electronic Health Records
(EHRs). Factors such as individual user needs and social determinants of
health, including living conditions and the flow of healthcare information
between different settings, must also be considered. Challenges in this complex
healthcare network involve schema diversity (in EHRs, personal health records,
etc.) and terminology diversity (e.g., ICD, SNOMED-CT) across ancillary
healthcare operations. Establishing interoperability among various systems and
applications is crucial, with the European Interoperability Framework (EIF)
emphasizing the need for patient-centric access and control of healthcare data.
In this paper, we propose an integrated ontological model, the Common Semantic
Data Model for Social Determinants of Health (CSSDH), by combining ISO/DIS
13940:2024 ContSys with WHO Social Determinants of Health. CSSDH aims to
achieve interoperability within the Continuity of Care Network.

æè¦ï¼æ¸ä½å¹³å°çèèµ·å°è´æä¾æä¾è³´ç§æé©åãå±å®¶é«çä¿å¥è§£æ±ºæ¹æ¡ï¼è®åäººå¾ä»¥ç£æ¸¬èªå·±çå¥åº·ï¼ä¸¦è¦éè¦èé«çä¿å¥å°æ¥­äººå¡åäº«è³è¨ãç¶èï¼å»ºç«ä¸åææçç§è­·è¨ç«ç®¡çç³»çµ±ï¼éè¦çå¯ä¸ååæ¯åæé«é¢æè¦åé»å­å¥åº·ç´é (EHR) èå·²ãéå¿é èéåäººä½¿ç¨èéæ±åå¥åº·çç¤¾ææ±ºå®å ç´ ï¼åæ¬çæ´»æ¢ä»¶åä¸åç°å¢ä¹éçé«çä¿å¥è³è¨æµåãéåè¤éçé«çä¿å¥ç¶²è·¯ä¸­çææ°ï¼åæ¬æ¶æ§å¤æ¨£æ§ (å¨ EHRãåäººå¥åº·ç´éç­) åè¡èªå¤æ¨£æ§ (ä¾å¦ ICDãSNOMED-CT) ç­è¼å©é«çä¿å¥ä½æ¥­ãå¨åç¨®ç³»çµ±åæç¨ç¨å¼ä¹éå»ºç«äºéæ§è³ééè¦ï¼æ­æ´²äºéæ§æ¶æ§ (EIF) å¼·èª¿éè¦ä»¥çäººçºä¸­å¿å­ååæ§å¶é«çä¿å¥è³æãå¨æ¬æä¸­ï¼æåæåºä¸åæ´åçæ¬é«è«æ¨¡åï¼å³çµå ISO/DIS 13940:2024 ContSys è WHO å¥åº·ç¤¾ææ±ºå®å ç´ çç¤¾ææ±ºå®å ç´ å¥åº·å±åèªç¾©è³ææ¨¡å (CSSDH)ãCSSDH æ¨å¨å¨ç§è­·é£çºæ§ç¶²è·¯ä¸­éæäºéæ§ã

##### **Understanding Opportunities and Risks of Synthetic Relationships: Leveraging the Power of Longitudinal Research with Customised AI Tools**
2412.09086v1 by Alfio Ventura, Nils KÃ¶bis

This position paper discusses the benefits of longitudinal behavioural
research with customised AI tools for exploring the opportunities and risks of
synthetic relationships. Synthetic relationships are defined as "continuing
associations between humans and AI tools that interact with one another wherein
the AI tool(s) influence(s) humans' thoughts, feelings, and/or actions."
(Starke et al., 2024). These relationships can potentially improve health,
education, and the workplace, but they also bring the risk of subtle
manipulation and privacy and autonomy concerns. To harness the opportunities of
synthetic relationships and mitigate their risks, we outline a methodological
approach that complements existing findings. We propose longitudinal research
designs with self-assembled AI agents that enable the integration of detailed
behavioural and self-reported data.

æè¦ï¼æ¬ç«å ´æä»¶æ¢è¨ç¸±åè¡çºç ç©¶èå®¢è£½å AI å·¥å·çåªé»ï¼ç¨æ¼æ¢è¨åæéä¿çæ©æèé¢¨éªãåæéä¿å®ç¾©çºãäººé¡è AI å·¥å·ä¹éæçºçéè¯ï¼å½¼æ­¤äºåï¼å¶ä¸­ AI å·¥å·æå½±é¿äººé¡çæ³æ³ãæåå/æè¡çºããï¼Starke ç­äººï¼2024 å¹´ï¼ãéäºéä¿æå¯è½æ¹åå¥åº·ãæè²åè·å ´ï¼ä½å®åä¹å¸¶ä¾å¾®å¦çæç¸±ä»¥åé±ç§åèªä¸»æ¬çé±æãçºäºå©ç¨åæéä¿çæ©æä¸¦éä½å¶é¢¨éªï¼æåæ¦è¿°äºä¸ç¨®æ¹æ³è«æ¹æ³ï¼è£åç¾æçç¼ç¾ãæåæåºä½¿ç¨èªçµè£ AI ä»£ççç¸±åç ç©¶è¨­è¨ï¼ä½¿æåè½å¤ æ´åè©³ç´°çè¡çºåèªæå ±åè³æã

##### **Radiology Report Generation via Multi-objective Preference Optimization**
2412.08901v2 by Ting Xiao, Lei Shi, Peng Liu, Zhe Wang, Chenjia Bai

Automatic Radiology Report Generation (RRG) is an important topic for
alleviating the substantial workload of radiologists. Existing RRG approaches
rely on supervised regression based on different architectures or additional
knowledge injection,while the generated report may not align optimally with
radiologists' preferences. Especially, since the preferences of radiologists
are inherently heterogeneous and multidimensional, e.g., some may prioritize
report fluency, while others emphasize clinical accuracy. To address this
problem,we propose a new RRG method via Multi-objective Preference Optimization
(MPO) to align the pre-trained RRG model with multiple human preferences, which
can be formulated by multi-dimensional reward functions and optimized by
multi-objective reinforcement learning (RL). Specifically, we use a preference
vector to represent the weight of preferences and use it as a condition for the
RRG model. Then, a linearly weighed reward is obtained via a dot product
between the preference vector and multi-dimensional reward. Next,the RRG model
is optimized to align with the preference vector by optimizing such a reward
via RL. In the training stage,we randomly sample diverse preference vectors
from the preference space and align the model by optimizing the weighted
multi-objective rewards, which leads to an optimal policy on the entire
preference space. When inference,our model can generate reports aligned with
specific preferences without further fine-tuning. Extensive experiments on two
public datasets show the proposed method can generate reports that cater to
different preferences in a single model and achieve state-of-the-art
performance.

æè¦ï¼èªåæ¾å°å ±åçæ (RRG) æ¯æ¸è¼æ¾å°ç§é«å¸«å¤§éå·¥ä½è² æçéè¦è­°é¡ãç¾æç RRG æ¹æ³ä»°è³´åºæ¼ä¸åæ¶æ§æé¡å¤ç¥è­æ³¨å¥çç£ç£å¼åæ­¸ï¼èç¢ççå ±åå¯è½ç¡æ³æä½³å°ç¬¦åæ¾å°ç§é«å¸«çåå¥½ãç¹å¥æ¯ï¼ç±æ¼æ¾å°ç§é«å¸«çåå¥½æ¬è³ªä¸æ¯ç°è³ªä¸å¤é¢åçï¼ä¾å¦ï¼æäºäººå¯è½åªåèæ®å ±åçæµæ¢åº¦ï¼èå¦ä¸äºäººåå¼·èª¿è¨åºæºç¢ºæ§ãçºäºè§£æ±ºéååé¡ï¼æåééå¤ç®æ¨åå¥½æä½³å (MPO) æåºä¸åæ°ç RRG æ¹æ³ï¼ä»¥å°é åè¨ç·´ç RRG æ¨¡åèå¤åäººé¡åå¥½å°é½ï¼éå¯ä»¥ç¨å¤ç¶­çåµå½æ¸ä¾å¶å®ï¼ä¸¦ééå¤ç®æ¨å¼·åå­¸ç¿ (RL) ä¾æä½³åãå·é«ä¾èªªï¼æåä½¿ç¨åå¥½åéä¾è¡¨ç¤ºåå¥½çæ¬éï¼ä¸¦å°å¶ç¨ä½ RRG æ¨¡åçæ¢ä»¶ãç¶å¾ï¼ééåå¥½åéåå¤ç¶­çåµä¹éçé»ç©ï¼ç²å¾ç·æ§å æ¬çåµãæ¥ä¸ä¾ï¼éé RL æä½³åæ­¤é¡çåµï¼æä½³å RRG æ¨¡åä»¥èåå¥½åéå°é½ãå¨è¨ç·´éæ®µï¼æåå¾åå¥½ç©ºéä¸­é¨æ©åæ¨£ä¸åçåå¥½åéï¼ä¸¦ééæä½³åå æ¬çå¤ç®æ¨çåµä¾å°é½æ¨¡åï¼éæç¢çæ´ååå¥½ç©ºéçæä½³ç­ç¥ãå¨æ¨è«æï¼æåçæ¨¡åå¯ä»¥çæèç¹å®åå¥½å°é½çå ±åï¼èç¡éé²ä¸æ­¥å¾®èª¿ãå¨å©åå¬éè³æéä¸çå»£æ³å¯¦é©é¡¯ç¤ºï¼ææåºçæ¹æ³å¯ä»¥å¨å®ä¸æ¨¡åä¸­çæè¿åä¸ååå¥½çå ±åï¼ä¸¦éå°æåé²çæè½ã

##### **AI-assisted Knowledge Discovery in Biomedical Literature to Support Decision-making in Precision Oncology**
2412.08900v1 by Ting He, Kory Kreimeyer, Mimi Najjar, Jonathan Spiker, Maria Fatteh, Valsamo Anagnostou, Taxiarchis Botsis

The delivery of appropriate targeted therapies to cancer patients requires
the complete analysis of the molecular profiling of tumors and the patient's
clinical characteristics in the context of existing knowledge and recent
findings described in biomedical literature and several other sources. We
evaluated the potential contributions of specific natural language processing
solutions to support knowledge discovery from biomedical literature. Two models
from the Bidirectional Encoder Representations from Transformers (BERT) family,
two Large Language Models, and PubTator 3.0 were tested for their ability to
support the named entity recognition (NER) and the relation extraction (RE)
tasks. PubTator 3.0 and the BioBERT model performed best in the NER task (best
F1-score equal to 0.93 and 0.89, respectively), while BioBERT outperformed all
other solutions in the RE task (best F1-score 0.79) and a specific use case it
was applied to by recognizing nearly all entity mentions and most of the
relations.

æè¦ï¼é©ç¶æ¨é¶çæ³å¨çççæ£çæç¨ï¼éè¦å¨ç¾æç¥è­åçç©é«å­¸æç»ä¸­ææè¿°çææ°ç¼ç¾çèçµ¡ä¸ï¼å®æ´åæè«ç¤çåå­ç¹å¾µåçæ£çè¨åºç¹å¾µãæåè©ä¼°äºç¹å®èªç¶èªè¨èçè§£æ±ºæ¹æ¡å¨æ¯æ´å¾çç©é«å­¸æç»ä¸­ç¼ç¾ç¥è­çæ½å¨è²¢ç»ãæåæ¸¬è©¦äºä¾èª Transformer éåç·¨ç¢¼å¨è¡¨ç¤ºæ³ (BERT) å®¶æçå©åæ¨¡åãå©åå¤§åèªè¨æ¨¡åå PubTator 3.0ï¼ä»¥è©ä¼°å®åæ¯æ´å½åå¯¦é«è¾¨è­ (NER) åéä¿èå (RE) ä»»åçè½åãPubTator 3.0 å BioBERT æ¨¡åå¨ NER ä»»åä¸­è¡¨ç¾æä½³ï¼æä½³ F1 åæ¸åå¥çº 0.93 å 0.89ï¼ï¼è BioBERT å¨ RE ä»»åä¸­åªæ¼ææå¶ä»è§£æ±ºæ¹æ¡ï¼æä½³ F1 åæ¸çº 0.79ï¼ï¼ä¸¦ä¸å¨ä¸åç¹å®çæç¨æ¡ä¾ä¸­ï¼å®å¹¾ä¹è¾¨è­åºææå¯¦é«æååå¤§é¨åéä¿ã

##### **Towards modeling evolving longitudinal health trajectories with a transformer-based deep learning model**
2412.08873v1 by Hans Moen, Vishnu Raj, Andrius Vabalas, Markus Perola, Samuel Kaski, Andrea Ganna, Pekka Marttinen

Health registers contain rich information about individuals' health
histories. Here our interest lies in understanding how individuals' health
trajectories evolve in a nationwide longitudinal dataset with coded features,
such as clinical codes, procedures, and drug purchases. We introduce a
straightforward approach for training a Transformer-based deep learning model
in a way that lets us analyze how individuals' trajectories change over time.
This is achieved by modifying the training objective and by applying a causal
attention mask. We focus here on a general task of predicting the onset of a
range of common diseases in a given future forecast interval. However, instead
of providing a single prediction about diagnoses that could occur in this
forecast interval, our approach enable the model to provide continuous
predictions at every time point up until, and conditioned on, the time of the
forecast period. We find that this model performs comparably to other models,
including a bi-directional transformer model, in terms of basic prediction
performance while at the same time offering promising trajectory modeling
properties. We explore a couple of ways to use this model for analyzing health
trajectories and aiding in early detection of events that forecast possible
later disease onsets. We hypothesize that this method may be helpful in
continuous monitoring of peoples' health trajectories and enabling
interventions in ongoing health trajectories, as well as being useful in
retrospective analyses.

æè¦ï¼å¥åº·ç»è¨åå«åäººå¥åº·å²çè±å¯è³è¨ãæåå¨æ­¤æèè¶£äºè§£åäººå¥åº·è»è·¡å¦ä½é¨èç·¨ç¢¼åè½ï¼ä¾å¦è¨åºä»£ç¢¼ãç¨åºåè¥ç©è³¼è²·ï¼å¨å¨åç¸±åè³æéä¸­æ¼è®ãæåå¼å¥ä¸ç¨®ç´æ¥çæ¹æ³ï¼ç¨æ¼è¨ç·´ Transformer çºåºç¤çæ·±åº¦å­¸ç¿æ¨¡åï¼è®æååæåäººè»è·¡å¦ä½é¨èæéæ¨ç§»èæ¹è®ãéæ¯ééä¿®æ¹è¨ç·´ç®æ¨ä¸¦æç¨å ææ³¨æåé®ç½©ä¾å¯¦ç¾çãæåå¨æ­¤å°æ³¨æ¼é æ¸¬å¨çµ¦å®æªä¾é æ¸¬åéå§ä¸ç³»åå¸¸è¦ç¾çç¼ççä¸è¬ä»»åãç¶èï¼æåçåæ³ä¸¦éæä¾éæ¼å¯è½å¨æ­¤é æ¸¬åéå§ç¼ççè¨ºæ·çå®ä¸é æ¸¬ï¼èæ¯è®æ¨¡åè½å¤ å¨æ¯åæéé»æä¾é£çºé æ¸¬ï¼ç´å°é æ¸¬æéçæéï¼ä¸¦ä»¥å¶çºæ¢ä»¶ãæåç¼ç¾æ­¤æ¨¡åçè¡¨ç¾èå¶ä»æ¨¡åï¼åæ¬éå Transformer æ¨¡åï¼ç¸ç¶ï¼å¨åºæ¬é æ¸¬æè½æ¹é¢å¦æ­¤ï¼åææä¾æå¸æçè»è·¡å»ºæ¨¡å±¬æ§ãæåæ¢ç´¢äºå¹¾ç¨®ä½¿ç¨æ­¤æ¨¡ååæå¥åº·è»è·¡ä¸¦åå©æ©æåµæ¸¬é æ¸¬å¯è½å¾çºç¼çäºä»¶çæ¹æ³ãæååè¨­æ­¤æ¹æ³å¯è½æå©æ¼æçºç£æ¸¬åäººå¥åº·è»è·¡ï¼ä¸¦è®å¹²é æªæ½å¾ä»¥å¨æçºçå¥åº·è»è·¡ä¸­é²è¡ï¼ä¸å¨åé¡§æ§åæä¸­ä¹å¾æç¨ã

##### **Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions**
2412.08737v1 by Jiarui Zhang, Ollie Liu, Tianyu Yu, Jinyi Hu, Willie Neiswanger

Multimodal large language models (MLLMs) have made rapid progress in recent
years, yet continue to struggle with low-level visual perception (LLVP) --
particularly the ability to accurately describe the geometric details of an
image. This capability is crucial for applications in areas such as robotics,
medical image analysis, and manufacturing. In this paper, we first introduce
Geoperception, a benchmark designed to evaluate an MLLM's ability to accurately
transcribe 2D geometric information from an image. Using this benchmark, we
demonstrate the limitations of leading MLLMs, and then conduct a comprehensive
empirical study to explore strategies for improving their performance on
geometric tasks. Our findings highlight the benefits of certain model
architectures, training techniques, and data strategies, including the use of
high-fidelity synthetic data and multi-stage training with a data curriculum.
Notably, we find that a data curriculum enables models to learn challenging
geometry understanding tasks which they fail to learn from scratch. Leveraging
these insights, we develop Euclid, a family of models specifically optimized
for strong low-level geometric perception. Although purely trained on synthetic
multimodal data, Euclid shows strong generalization ability to novel geometry
shapes. For instance, Euclid outperforms the best closed-source model,
Gemini-1.5-Pro, by up to 58.56% on certain Geoperception benchmark tasks and
10.65% on average across all tasks.

æè¦ï¼è¿å¹¾å¹´ï¼å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) è¿éé²å±ï¼ä½ä»æçºèä½éè¦è¦ºæç¥ (LLVP) å¥®æ°ï¼å°¤å¶æ¯æºç¢ºæè¿°å½±åå¹¾ä½ç´°ç¯çè½åãæ­¤åè½å°æ¼æ©å¨äººãé«å­¸å½±ååæåè£½é ç­é åçæç¨è³ééè¦ãå¨æ¬æä¸­ï¼æåé¦åä»ç´¹ Geoperceptionï¼ä¸ååºæºï¼æ¨å¨è©ä¼° MLLM å¾å½±åæºç¢ºè½é 2D å¹¾ä½è³è¨çè½åãä½¿ç¨æ­¤åºæºï¼æåå±ç¤ºäºé å MLLM çéå¶ï¼ç¶å¾é²è¡å¨é¢çå¯¦è­ç ç©¶ï¼æ¢è¨æ¹åå¶å¨å¹¾ä½ä»»åä¸è¡¨ç¾çç­ç¥ãæåçç ç©¶çµæçªåºäºç¹å®æ¨¡åæ¶æ§ãè¨ç·´æè¡åè³æç­ç¥çåªé»ï¼åæ¬ä½¿ç¨é«ä¿çåæè³æåå·æè³æèª²ç¨çå¤éæ®µè¨ç·´ãå¼å¾æ³¨æçæ¯ï¼æåç¼ç¾è³æèª²ç¨è½è®æ¨¡åå­¸ç¿ä»åç¡æ³å¾é ­éå§å­¸ç¿çå·æææ°æ§çå¹¾ä½çè§£ä»»åãå©ç¨éäºè¦è§£ï¼æåéç¼äº Euclidï¼ä¸åå°ééå°å¼·ä½éå¹¾ä½æç¥èæä½³åçæ¨¡åå®¶æãåç®¡ç´ç²¹å¨åæå¤æ¨¡æè³æä¸è¨ç·´ï¼ä½ Euclid å°æ°å¹¾ä½å½¢çå±ç¾åºå¼·å¤§çæ³åè½åãä¾å¦ï¼Euclid å¨æäº Geoperception åºæºä»»åä¸æ¯æä½³éæºæ¨¡å Gemini-1.5-Pro é«åº 58.56%ï¼å¨ææä»»åä¸çå¹³åè¡¨ç¾é«åº 10.65%ã

##### **Assisted morbidity coding: the SISCO.web use case for identifying the main diagnosis in Hospital Discharge Records**
2412.09651v1 by Elena Cardillo, Lucilla Frattura

Coding morbidity data using international standard diagnostic classifications
is increasingly important and still challenging. Clinical coders and physicians
assign codes to patient episodes based on their interpretation of case notes or
electronic patient records. Therefore, accurate coding relies on the legibility
of case notes and the coders' understanding of medical terminology. During the
last ten years, many studies have shown poor reproducibility of clinical
coding, even recently, with the application of Artificial Intelligence-based
models. Given this context, the paper aims to present the SISCO.web approach
designed to support physicians in filling in Hospital Discharge Records with
proper diagnoses and procedures codes using the International Classification of
Diseases (9th and 10th), and, above all, in identifying the main pathological
condition. The web service leverages NLP algorithms, specific coding rules, as
well as ad hoc decision trees to identify the main condition, showing promising
results in providing accurate ICD coding suggestions.

æè¦ï¼ä½¿ç¨åéæ¨æºè¨ºæ·åé¡å°çæè³æé²è¡ç·¨ç¢¼è¶ä¾è¶éè¦ï¼ä½ä»å·æææ°æ§ãè¨åºç·¨ç¢¼å¡åé«å¸«æ ¹æä»åå°çä¾è¨éæé»å­çæ­·çè§£è®ï¼çºæ£èå°±è¨ºææ³åéä»£ç¢¼ãå æ­¤ï¼æºç¢ºç·¨ç¢¼ä¾è³´æ¼çä¾è¨éçå¯è®æ§åç·¨ç¢¼å¡å°é«å­¸è¡èªççè§£ãå¨éå»åå¹´ä¸­ï¼è¨±å¤ç ç©¶è¡¨æè¨åºç·¨ç¢¼çå¯åç¾æ§å¾å·®ï¼å³ä½¿å¨æè¿ï¼äººå·¥æºè½æ¨¡åçæç¨ä¹æ¯å¦æ­¤ãéæ¼éç¨®ææ³ï¼æ¬ææ¨å¨ä»ç´¹ SISCO.web æ¹æ³ï¼è©²æ¹æ³æ¨å¨æ¯æ´é«å¸«ä½¿ç¨åéç¾çåé¡ (ç¬¬ 9 çåç¬¬ 10 ç) å¡«å¯«åºé¢è¨éï¼ä¸¦æ­£ç¢ºè¨ºæ·åç·¨ç¢¼ç¨åºï¼æéè¦çæ¯ï¼æ¾åºä¸»è¦ççççæ³ãç¶²è·¯æåå©ç¨ NLP æ¼ç®æ³ãç¹å®çç·¨ç¢¼è¦åä»¥åç¹å¥æ±ºç­æ¨¹ä¾æ¾åºä¸»è¦çæ³ï¼å¨æä¾æºç¢ºç ICD ç·¨ç¢¼å»ºè­°æ¹é¢é¡¯ç¤ºåºæå¸æççµæã

##### **IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health**
2412.08463v1 by Gauri Jain, Pradeep Varakantham, Haifeng Xu, Aparna Taneja, Prashant Doshi, Milind Tambe

Public health practitioners often have the goal of monitoring patients and
maximizing patients' time spent in "favorable" or healthy states while being
constrained to using limited resources. Restless multi-armed bandits (RMAB) are
an effective model to solve this problem as they are helpful to allocate
limited resources among many agents under resource constraints, where patients
behave differently depending on whether they are intervened on or not. However,
RMABs assume the reward function is known. This is unrealistic in many public
health settings because patients face unique challenges and it is impossible
for a human to know who is most deserving of any intervention at such a large
scale. To address this shortcoming, this paper is the first to present the use
of inverse reinforcement learning (IRL) to learn desired rewards for RMABs, and
we demonstrate improved outcomes in a maternal and child health telehealth
program. First we allow public health experts to specify their goals at an
aggregate or population level and propose an algorithm to design expert
trajectories at scale based on those goals. Second, our algorithm WHIRL uses
gradient updates to optimize the objective, allowing for efficient and accurate
learning of RMAB rewards. Third, we compare with existing baselines and
outperform those in terms of run-time and accuracy. Finally, we evaluate and
show the usefulness of WHIRL on thousands on beneficiaries from a real-world
maternal and child health setting in India. We publicly release our code here:
https://github.com/Gjain234/WHIRL.

æè¦ï¼<paragraph>å¬å±è¡çå¾æ¥­äººå¡éå¸¸æç£æ§æ£èåæå¤§åæ£èèæ¼ãæå©ãæå¥åº·çæçæéçç®æ¨ï¼åæåå°æéè³æºçéå¶ãä¸å®åçå¤èå¼·ç (RMAB) æ¯è§£æ±ºæ­¤åé¡çæææ¨¡åï¼å çºå®åæå©æ¼å¨è³æºéå¶ä¸ï¼å¨è¨±å¤ä»£çä¹éåéæéçè³æºï¼å¶ä¸­æ£èçè¡çºåæ±ºæ¼æ¯å¦å°å¶é²è¡å¹²é ãç¶èï¼RMAB åè¨­å·²ç¥åå ±å½æ¸ãéå¨è¨±å¤å¬å±è¡çç°å¢ä¸­æ¯ä¸åå¯¦éçï¼å çºæ£èé¢è¨ç¨ç¹çææ°ï¼èä¸å°æ¼å¦æ­¤å¤§è¦æ¨¡çå¹²é ï¼äººé¡ä¸å¯è½ç¥éèª°æéè¦å¹²é ãçºäºè§£æ±ºéåç¼ºé»ï¼æ¬æé¦æ¬¡æåºä½¿ç¨éåå¼·åå­¸ç¿ (IRL) ä¾å­¸ç¿ RMAB çææåå ±ï¼ä¸¦ä¸æåå¨æ¯å¬°å¥åº·é è·é«çè¨ç«ä¸­å±ç¤ºäºæ¹åççµæãé¦åï¼æååè¨±å¬å±è¡çå°å®¶å¨ç¸½é«æäººå£å±¤ç´æå®ä»åçç®æ¨ï¼ä¸¦æåºä¸åæ¼ç®æ³ä¾æ ¹æéäºç®æ¨å¤§è¦æ¨¡è¨­è¨å°å®¶è»è·¡ãå¶æ¬¡ï¼æåçæ¼ç®æ³ WHIRL ä½¿ç¨æ¢¯åº¦æ´æ°ä¾æä½³åç®æ¨ï¼åè¨±ææä¸æºç¢ºå°å­¸ç¿ RMAB åå ±ãç¬¬ä¸ï¼æåèç¾æçåºæºé²è¡æ¯è¼ï¼ä¸¦å¨å·è¡æéåæºç¢ºæ§æ¹é¢åªæ¼éäºåºæºãæå¾ï¼æåè©ä¼°ä¸¦å±ç¤ºäº WHIRL å¨å°åº¦å¯¦éæ¯å¬°å¥åº·ç°å¢ä¸­å°æ¸åååçèçæç¨æ§ãæåå¨æ­¤å¬éç¼å¸æåçç¨å¼ç¢¼ï¼https://github.com/Gjain234/WHIRLã</paragraph>

##### **SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs**
2412.08347v1 by Sultan Alrashed

We present SmolTulu-1.7b-Instruct, referenced in this report as
SmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's
Tulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.
Through comprehensive empirical analysis using a 135M parameter model, we
demonstrate that the relationship between learning rate and batch size
significantly impacts model performance in a task-dependent manner. Our
findings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from
higher learning rate to batch size ratios, while pattern recognition tasks such
as HellaSwag and IFEval show optimal performance with lower ratios. These
insights informed the development of SmolTulu, which achieves state-of-the-art
performance among sub-2B parameter models on instruction following, scoring
67.7% on IFEval ($\Delta$11%), and mathematical reasoning with 51.6% on GSM8K
($\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC
($\Delta5.4%$). We release our model, training recipes, and ablation studies to
facilitate further research in efficient model alignment, demonstrating that
careful adaptation of optimization dynamics can help bridge the capability gap
between small and large language models.

æè¦ï¼æåæåº SmolTulu-1.7b-Instructï¼æ¬å ±åä¸­ç¨±çº SmolTulu-DPO-1130ï¼éæ¯ä¸ç¨®æä»¤èª¿æ´èªè¨æ¨¡åï¼æ¡ç¨ AllenAI ç Tulu 3 å¾è¨ç·´ç®¡éä¾å¢å¼· Huggingface ç SmolLM2-1.7B åºç¤æ¨¡åãééä½¿ç¨ 135M åæ¸æ¨¡åçå¨é¢ç¶é©åæï¼æåè­æå­¸ç¿çèæ¹æ¬¡å¤§å°ä¹éçéä¿æä»¥ä»»åç¸éçæ¹å¼é¡¯èå½±é¿æ¨¡åæè½ãæåçç¼ç¾æ­ç¤ºäºä¸åæç¢ºçåæ­§ï¼å ARC å GSM8K ç­æ¨çä»»ååçæ¼è¼é«çå­¸ç¿çå°æ¹æ¬¡å¤§å°çæ¯çï¼èå HellaSwag å IFEval ç­æ¨¡å¼è¾¨è­ä»»ååé¡¯ç¤ºåºè¼ä½æ¯ççæä½³æè½ãéäºè¦è§£çº SmolTulu çéç¼æä¾äºè³è¨ï¼å¨å°æ¼ 2B åæ¸æ¨¡åä¸­ï¼å¨æä»¤éµå¾ªæ¹é¢åå¾äºæåé²çè¡¨ç¾ï¼å¨ IFEval ä¸å¾å 67.7%ï¼Î11%ï¼ï¼å¨ GSM8K ä¸çæ¸å­¸æ¨çå¾åçº 51.6%ï¼Î3.4%ï¼ï¼èå¦ä¸åçæ¬å¨ ARC ä¸å¾å 57.1%ï¼Î5.4%ï¼ãæåç¼å¸æåçæ¨¡åãè¨ç·´ç¯ä¾åæ¶èç ç©¶ï¼ä»¥ä¿é²é«ææ¨¡åå°é½çé²ä¸æ­¥ç ç©¶ï¼è­æä»ç´°èª¿æ´æä½³ååæå¯ä»¥å¹«å©ç¸®å°å°ååå¤§åèªè¨æ¨¡åä¹éçè½åå·®è·ã

##### **Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures**
2412.08228v1 by CÃ©lia Blondin, Joris GuÃ©rin, Kelly Inagaki, Guilherme Longo, Laure Berti-Ãquille

Automated benthic image annotation is crucial to efficiently monitor and
protect coral reefs against climate change. Current machine learning approaches
fail to capture the hierarchical nature of benthic organisms covering reef
substrata, i.e., coral taxonomic levels and health condition. To address this
limitation, we propose to annotate benthic images using hierarchical
classification. Experiments on a custom dataset from a Northeast Brazilian
coral reef show that our approach outperforms flat classifiers, improving both
F1 and hierarchical F1 scores by approximately 2\% across varying amounts of
training data. In addition, this hierarchical method aligns more closely with
ecological objectives.

æè¦ï¼èªåååºæ£²å½±åè¨»è§£å°æ¼ææç£æ¸¬åä¿è­·ççç¤ååæ°£åè®é·å½±é¿è³ééè¦ãç®åçæ©å¨å­¸ç¿æ¹æ³ç¡æ³ææè¦èç¤ç³åºè³ªçåºæ£²çç©çéå±¤æ§è³ªï¼ä¾å¦ççåé¡ç­ç´åå¥åº·çæ³ãçºäºè§£æ±ºæ­¤éå¶ï¼æåå»ºè­°ä½¿ç¨éå±¤åé¡è¨»è§£åºæ£²å½±åãå°ä¾èªå·´è¥¿æ±åé¨ççç¤çèªè¨è³æéé²è¡çå¯¦é©é¡¯ç¤ºï¼æåçåæ³åªæ¼å¹³é¢åé¡å¨ï¼å¨ä¸åæ¸éçè¨ç·´è³æä¸­å° F1 åéå±¤ F1 åæ¸é½æé«äºå¤§ç´ 2%ãæ­¤å¤ï¼éç¨®éå±¤å¼æ¹æ³èçæç®æ¨æ´çºä¸è´ã

##### **How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?**
2412.08081v1 by Yixin Zhang, Kevin Kramer, Maciej A. Mazurowski

Automated segmentation of medical images highly depends on the availability
of accurate manual image annotations. Such annotations are very time-consuming
and costly to generate, and often require specialized expertise, particularly
for cross-sectional images which contain many slices for each patient. It is
crucial to ensure the best use of annotation resources. In this paper, we
systematically answer the question of how to select slices of cross-sectional
medical images in order to maximize performance of the resulting deep learning
segmentation models. We conducted experiments on 4 medical imaging segmentation
tasks with varying annotation budgets, numbers of annotated cases, numbers of
annotated slices per volume, slice selection techniques, and mask
interpolations. We found that:
  1) It is almost always preferable to annotate fewer slices per volume and
more volumes given an annotation budget. 2) Selecting slices for annotation by
unsupervised active learning (UAL) is not superior to selecting slices randomly
or at fixed intervals, provided that each volume is allocated the same number
of annotated slices. 3) Interpolating masks between annotated slices rarely
enhances model performance, with exceptions of some specific configuration for
3D models.

æè¦ï¼é«å­¸å½±åçèªåååå²é«åº¦ä¾è³´æ¼æºç¢ºçæåå½±åæ¨è¨»ãæ­¤é¡æ¨è¨»éå¸¸èæä¸çæææ¬é«æï¼ä¸éå¸¸éè¦å°æ¥­ç¥è­ï¼ç¹å¥æ¯å°æ¼æ¯åæ£èåå«è¨±å¤åççæ©«æ·é¢å½±åãç¢ºä¿æä½³å©ç¨æ¨è¨»è³æºè³ééè¦ãå¨æ¬æä¸­ï¼æåç³»çµ±æ§å°åç­äºå¦ä½é¸ææ©«æ·é¢é«å­¸å½±ååçä»¥æå¤§åæ·±åº¦å­¸ç¿åå²æ¨¡åæè½çåé¡ãæåéå° 4 é é«å­¸å½±ååå²ä»»åé²è¡äºå¯¦é©ï¼éäºä»»åå·æä¸åçæ¨è¨»é ç®ãæ¨è¨»æ¡ä¾æ¸ãæ¯åé«ç©çæ¨è¨»åçæ¸ãåçé¸ææè¡åé®ç½©å§æãæåç¼ç¾ï¼
1) å¨çµ¦å®æ¨è¨»é ç®çææ³ä¸ï¼å¹¾ä¹ç¸½æ¯åªåæ¨è¨»æ¯åé«ç©è¼å°åçåæ´å¤é«ç©ã2) éééç£ç£ä¸»åå­¸ç¿ (UAL) é¸æåçé²è¡æ¨è¨»ä¸¦ä¸åªæ¼é¨æ©æåºå®ééé¸æåçï¼åææ¯æ¯åé«ç©åéçæ¨è¨»åçæ¸ç¸åã3) å¨æ¨è¨»åçä¹éå§æé®ç½©å¾å°è½æåæ¨¡åæè½ï¼ä½æäº 3D æ¨¡åçç¹å®çµæé¤å¤ã

##### **Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning**
2412.08021v1 by Chongyi Zheng, Jens Tuyls, Joanne Peng, Benjamin Eysenbach

Self-supervised learning has the potential of lifting several of the key
challenges in reinforcement learning today, such as exploration, representation
learning, and reward design. Recent work (METRA) has effectively argued that
moving away from mutual information and instead optimizing a certain
Wasserstein distance is important for good performance. In this paper, we argue
that the benefits seen in that paper can largely be explained within the
existing framework of mutual information skill learning (MISL). Our analysis
suggests a new MISL method (contrastive successor features) that retains the
excellent performance of METRA with fewer moving parts, and highlights
connections between skill learning, contrastive representation learning, and
successor features. Finally, through careful ablation studies, we provide
further insight into some of the key ingredients for both our method and METRA.

æè¦ï¼èªæç£ç£å­¸ç¿ææ½åè§£æ±ºç¶ä»å¼·åå­¸ç¿ä¸­çå¹¾åééµææ°ï¼ä¾å¦æ¢ç´¢ãè¡¨å¾µå­¸ç¿åçåµè¨­è¨ãæè¿çç ç©¶ï¼METRAï¼ææå°è«è­äºé é¢äºä¿¡æ¯ä¸¦æ¹çºåªåæå Wasserstein è·é¢å°æ¼è¯å¥½çæ§è½å¾éè¦ãå¨æ¬æä¸­ï¼æåè«è­è©²è«æä¸­çå°çåªé»å¯ä»¥å¨äºä¿¡æ¯æè½å­¸ç¿ï¼MISLï¼çç¾ææ¡æ¶å§å¾å°å¾å¤§ç¨åº¦çè§£éãæåçåææåºäºä¸ç¨®æ°ç MISL æ¹æ³ï¼å°æ¯å¾ç¹¼ç¹å¾µï¼ï¼å®ä¿çäº METRA çåºè²æ§è½ï¼åææ¸å°äºæ´»åé¨ä»¶ï¼ä¸¦çªåºäºæè½å­¸ç¿ãå°æ¯è¡¨å¾µå­¸ç¿åå¾ç¹¼ç¹å¾µä¹éçè¯ç¹«ãæå¾ï¼ééä»ç´°çæ¶èç ç©¶ï¼æåé²ä¸æ­¥æ·±å¥äºè§£äºæåçæ¹æ³å METRA çä¸äºééµè¦ç´ ã

##### **From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents**
2412.07951v2 by Mohit Chandra, Suchismita Naik, Denae Ford, Ebele Okoli, Munmun De Choudhury, Mahsa Ershadi, Gonzalo Ramos, Javier Hernandez, Ananya Bhattacharjee, Shahed Warreth, Jina Suh

Recent gain in popularity of AI conversational agents has led to their
increased use for improving productivity and supporting well-being. While
previous research has aimed to understand the risks associated with
interactions with AI conversational agents, these studies often fall short in
capturing the lived experiences. Additionally, psychological risks have often
been presented as a sub-category within broader AI-related risks in past
taxonomy works, leading to under-representation of the impact of psychological
risks of AI use. To address these challenges, our work presents a novel risk
taxonomy focusing on psychological risks of using AI gathered through lived
experience of individuals. We employed a mixed-method approach, involving a
comprehensive survey with 283 individuals with lived mental health experience
and workshops involving lived experience experts to develop a psychological
risk taxonomy. Our taxonomy features 19 AI behaviors, 21 negative psychological
impacts, and 15 contexts related to individuals. Additionally, we propose a
novel multi-path vignette based framework for understanding the complex
interplay between AI behaviors, psychological impacts, and individual user
contexts. Finally, based on the feedback obtained from the workshop sessions,
we present design recommendations for developing safer and more robust AI
agents. Our work offers an in-depth understanding of the psychological risks
associated with AI conversational agents and provides actionable
recommendations for policymakers, researchers, and developers.

æè¦ï¼è¿æ AI å°è©±ä»£ççæ®åæåï¼å°è´å¶å¨æåçç¢ååæ¯æå¹¸ç¦ææ¹é¢çæç¨æ¥çå¢å ãéç¶ååçç ç©¶æ¨å¨äºè§£è AI å°è©±ä»£çäºåç¸éçé¢¨éªï¼ä½éäºç ç©¶å¾å¾ç¡æ³ææå°çæ´»é«é©ãæ­¤å¤ï¼å¨éå»çåé¡å·¥ä½ä¸­ï¼å¿çé¢¨éªéå¸¸è¢«è¦çºæ´å»£æ³ç AI ç¸éé¢¨éªä¸­çå­é¡å¥ï¼å°è´ AI ä½¿ç¨å¿çé¢¨éªçå½±é¿è¢«ä½ä¼°ãçºäºæå°éäºææ°ï¼æåçç ç©¶æåºäºæ°ç©çé¢¨éªåé¡æ³ï¼éé»éæ³¨ééåäººçæ´»ç¶é©æ¶éç AI ä½¿ç¨å¿çé¢¨éªãæåæ¡ç¨æ··åæ¹æ³ï¼åæ¬å° 283 ä½å·æçæ´»å¿çå¥åº·ç¶é©çåäººé²è¡å¨é¢èª¿æ¥ï¼ä»¥åèçæ´»ç¶é©å°å®¶åä½çç è¨æï¼ä»¥å¶å®å¿çé¢¨éªåé¡æ³ãæåçåé¡æ³åå« 19 ç¨® AI è¡çºã21 ç¨®è² é¢å¿çå½±é¿å 15 ç¨®èåäººç¸éçèæ¯ãæ­¤å¤ï¼æåæåºäºä¸åæ°ç©çå¤è·¯å¾å°æåæ¡æ¶ï¼ç¨æ¼äºè§£ AI è¡çºãå¿çå½±é¿ååäººä½¿ç¨èèæ¯ä¹éçè¤éäº¤äºä½ç¨ãæå¾ï¼æ ¹æå¾ç è¨æä¸­ç²å¾çåé¥ï¼æåæåºäºè¨­è¨å»ºè­°ï¼ä»¥éç¼æ´å®å¨ãæ´å¼·å¤§ç AI ä»£çãæåçç ç©¶æ·±å¥äºè§£äºè AI å°è©±ä»£çç¸éçå¿çé¢¨éªï¼ä¸¦çºæ¿ç­å¶å®èãç ç©¶äººå¡åéç¼äººå¡æä¾äºå¯è¡çå»ºè­°ã

##### **How Should We Represent History in Interpretable Models of Clinical Policies?**
2412.07895v1 by Anton Matsson, Lena Stempfle, Yaochen Rao, Zachary R. Margolin, Heather J. Litman, Fredrik D. Johansson

Modeling policies for sequential clinical decision-making based on
observational data is useful for describing treatment practices, standardizing
frequent patterns in treatment, and evaluating alternative policies. For each
task, it is essential that the policy model is interpretable. Learning accurate
models requires effectively capturing the state of a patient, either through
sequence representation learning or carefully crafted summaries of their
medical history. While recent work has favored the former, it remains a
question as to how histories should best be represented for interpretable
policy modeling. Focused on model fit, we systematically compare diverse
approaches to summarizing patient history for interpretable modeling of
clinical policies across four sequential decision-making tasks. We illustrate
differences in the policies learned using various representations by breaking
down evaluations by patient subgroups, critical states, and stages of
treatment, highlighting challenges specific to common use cases. We find that
interpretable sequence models using learned representations perform on par with
black-box models across all tasks. Interpretable models using hand-crafted
representations perform substantially worse when ignoring history entirely, but
are made competitive by incorporating only a few aggregated and recent elements
of patient history. The added benefits of using a richer representation are
pronounced for subgroups and in specific use cases. This underscores the
importance of evaluating policy models in the context of their intended use.

æè¦ï¼åºæ¼è§å¯è³æå°åºè²«è¨åºæ±ºç­å¶å®å»ºæ¨¡æ¿ç­ï¼æå©æ¼æè¿°æ²»çå¯¦åãæ¨æºåæ²»çä¸­çå¸¸è¦æ¨¡å¼ï¼ä»¥åè©ä¼°æ¿ä»£æ¿ç­ãå°æ¼æ¯é ä»»åï¼æ¿ç­æ¨¡åçå¯è§£éæ§è³ééè¦ãå­¸ç¿ç²¾ç¢ºçæ¨¡åéè¦æææ·åæ£èççæï¼ç¡è«æ¯ééåºåè¡¨å¾µå­¸ç¿æç²¾å¿è£½ä½ççå²æè¦ãéç¶è¿æç ç©¶åå¥½åèï¼ä½å¦ä½ä»¥æä½³æ¹å¼è¡¨å¾µçå²ä»¥é²è¡å¯è§£éçæ¿ç­å»ºæ¨¡ï¼ä»æ¯ä¸ååé¡ãæåå°æ³¨æ¼æ¨¡åæ¬ååº¦ï¼ç³»çµ±æ§å°æ¯è¼åç¨®æè¦æ£èçå²çæ¹æ³ï¼ä»¥éå°åé åºè²«æ±ºç­å¶å®ä»»åé²è¡å¯è§£éçè¨åºæ¿ç­å»ºæ¨¡ãæåééææ£èå­ç¾¤ãå±æ¥çæåæ²»çéæ®µç´°åè©ä¼°ï¼ä¾èªªæä½¿ç¨åç¨®è¡¨å¾µæå­¸ç¿å°çæ¿ç­ä¹éçå·®ç°ï¼ä¸¦å¼·èª¿ç¹å®æ¼å¸¸è¦ä½¿ç¨æ¡ä¾çææ°ãæåç¼ç¾ï¼ä½¿ç¨å­¸ç¿è¡¨å¾µçå¯è§£éåºåæ¨¡åå¨ææä»»åä¸­è¡¨ç¾èé»ç®±æ¨¡åä¸ç¸ä¸ä¸ãä½¿ç¨æå·¥è£½ä½è¡¨å¾µçå¯è§£éæ¨¡åå¨å®å¨å¿½ç¥çå²æè¡¨ç¾æé¡¯è¼å·®ï¼ä½ééåç´å¥å°æ¸æ£èçå²çå½æ´åè¿æåç´ ï¼ä¾¿è½ä½¿å¶å·æç«¶ç­åãä½¿ç¨æ´è±å¯è¡¨å¾µçé¡å¤å¥½èå¨å­ç¾¤åç¹å®ä½¿ç¨æ¡ä¾ä¸­é¡¯èãéå¼·èª¿äºå¨é æç¨éçèçµ¡ä¸­è©ä¼°æ¿ç­æ¨¡åçéè¦æ§ã

##### **Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact**
2412.07880v2 by Yunfan Zhao, Niclas Boehmer, Aparna Taneja, Milind Tambe

AI for social impact (AI4SI) offers significant potential for addressing
complex societal challenges in areas such as public health, agriculture,
education, conservation, and public safety. However, existing AI4SI research is
often labor-intensive and resource-demanding, limiting its accessibility and
scalability; the standard approach is to design a (base-level) system tailored
to a specific AI4SI problem. We propose the development of a novel meta-level
multi-agent system designed to accelerate the development of such base-level
systems, thereby reducing the computational cost and the burden on social
impact domain experts and AI researchers. Leveraging advancements in foundation
models and large language models, our proposed approach focuses on resource
allocation problems providing help across the full AI4SI pipeline from problem
formulation over solution design to impact evaluation. We highlight the ethical
considerations and challenges inherent in deploying such systems and emphasize
the importance of a human-in-the-loop approach to ensure the responsible and
effective application of AI systems.

æè¦ï¼äººå·¥æºæ§å°ç¤¾æå½±é¿ï¼AI4SIï¼æä¾äºå·¨å¤§çæ½åï¼ç¨æ¼è§£æ±ºè¤éçç¤¾æææ°ï¼ä¾å¦å¬å±è¡çãè¾²æ¥­ãæè²ãä¿è²åå¬å±å®å¨ãç¶èï¼ç¾æç AI4SI ç ç©¶éå¸¸éè¦å¤§éäººååè³æºï¼ééå¶äºå¶å¯åæ§åå¯æ´å±æ§ï¼æ¨æºæ¹æ³æ¯è¨­è¨ä¸åéå°ç¹å® AI4SI åé¡éèº«æé çï¼åºç¤å±¤ç´ï¼ç³»çµ±ãæåå»ºè­°éç¼ä¸åæ°ç©çåå±¤ç´å¤ä»£çç³»çµ±ï¼æ¨å¨å éæ­¤é¡åºç¤å±¤ç´ç³»çµ±çéç¼ï¼å¾èéä½éç®ææ¬åç¤¾æå½±é¿é åå°å®¶è AI ç ç©¶äººå¡çè² æãéééç¨åºç¤æ¨¡ååå¤§åèªè¨æ¨¡åçé²å±ï¼æåå»ºè­°çæ¹æ³å°æ³¨æ¼è³æºéç½®åé¡ï¼æä¾å¾åé¡å»ºæ§ãè§£æ±ºæ¹æ¡è¨­è¨å°å½±é¿è©ä¼°çå®æ´ AI4SI ç®¡ç·çåå©ãæåå¼·èª¿é¨ç½²æ­¤é¡ç³»çµ±æåºæçéå¾·èéåææ°ï¼ä¸¦å¼·èª¿äººæ©åä½æ¹æ³çéè¦æ§ï¼ä»¥ç¢ºä¿è² è²¬ä»»ä¸ææå°æç¨ AI ç³»çµ±ã

##### **Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG**
2412.07878v1 by Shivraj Singh Bhatti, Aryan Yadav, Mitali Monga, Neeraj Kumar

The classification of harmful brain activities, such as seizures and periodic
discharges, play a vital role in neurocritical care, enabling timely diagnosis
and intervention. Electroencephalography (EEG) provides a non-invasive method
for monitoring brain activity, but the manual interpretation of EEG signals are
time-consuming and rely heavily on expert judgment. This study presents a
comparative analysis of deep learning architectures, including Convolutional
Neural Networks (CNNs), Vision Transformers (ViTs), and EEGNet, applied to the
classification of harmful brain activities using both raw EEG data and
time-frequency representations generated through Continuous Wavelet Transform
(CWT). We evaluate the performance of these models use multimodal data
representations, including high-resolution spectrograms and waveform data, and
introduce a multi-stage training strategy to improve model robustness. Our
results show that training strategies, data preprocessing, and augmentation
techniques are as critical to model success as architecture choice, with
multi-stage TinyViT and EfficientNet demonstrating superior performance. The
findings underscore the importance of robust training regimes in achieving
accurate and efficient EEG classification, providing valuable insights for
deploying AI models in clinical practice.

æè¦ï¼æå®³è¦é¨æ´»åçåé¡ï¼ä¾å¦ç²çç¼ä½åé±ææ§æ¾é»ï¼å¨ç¥ç¶éçç§è­·ä¸­æ®æ¼èè³ééè¦çè§è²ï¼è½åæè¨ºæ·åä»å¥ãè¦é»å (EEG) æä¾äºä¸ç¨®éä¾µå¥å¼çæ¹æ³ä¾ç£æ¸¬è¦é¨æ´»åï¼ä½ EEG è¨èçæåå¤è®èæä¸é«åº¦ä¾è³´å°å®¶çå¤æ·ãæ¬ç ç©¶éå°æ·±åº¦å­¸ç¿æ¶æ§é²è¡æ¯è¼åæï¼åæ¬å·ç©ç¥ç¶ç¶²è·¯ (CNN)ãè¦è¦ºTransformer (ViT) å EEGNetï¼éç¨æ¼æå®³è¦é¨æ´»åçåé¡ï¼åæä½¿ç¨åå§ EEG è³æåééé£çºå°æ³¢è½æ (CWT) çæçæé »è¡¨ç¤ºãæåè©ä¼°éäºæ¨¡åä½¿ç¨å¤æ¨¡å¼è³æè¡¨ç¤ºçæè½ï¼åæ¬é«è§£æåº¦é »è­ååæ³¢å½¢è³æï¼ä¸¦å¼å¥å¤éæ®µè¨ç·´ç­ç¥ä¾æ¹åæ¨¡åçç©©å¥æ§ãæåççµæé¡¯ç¤ºï¼è¨ç·´ç­ç¥ãè³æåèçåæ´åæè¡å°æ¼æ¨¡åçæåèæ¶æ§é¸æä¸æ¨£éè¦ï¼å¶ä¸­å¤éæ®µ TinyViT å EfficientNet è¡¨ç¾åºåªç°çæè½ãéäºç¼ç¾å¼·èª¿äºç©©å¥è¨ç·´æ©å¶å°æ¼éææºç¢ºä¸ææçç EEG åé¡çéè¦æ§ï¼çºå¨è¨åºå¯¦åä¸­é¨ç½² AI æ¨¡åæä¾äºå¯¶è²´çè¦è§£ã

##### **Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**
2412.09644v1 by Marcos Da Silveira, Louis Deladiennee, Kheira Acem, Oona Freudenthal

Human health is increasingly threatened by exposure to hazardous substances,
particularly persistent and toxic chemicals. The link between these substances,
often encountered in complex mixtures, and various diseases are demonstrated in
scientific studies. However, this information is scattered across several
sources and hardly accessible by humans and machines. This paper evaluates
current practices for publishing/accessing information on hazardous chemicals
and proposes a novel platform designed to facilitate retrieval of critical
chemical data in urgent situations. The platform aggregates information from
multiple sources and organizes it into a structured knowledge graph. Users can
access this information through a visual interface such as Neo4J Bloom and
dashboards, or via natural language queries using a Chatbot. Our findings
demonstrate a significant reduction in the time and effort required to access
vital chemical information when datasets follow FAIR principles. Furthermore,
we discuss the lessons learned from the development and implementation of this
platform and provide recommendations for data owners and publishers to enhance
data reuse and interoperability. This work aims to improve the accessibility
and usability of chemical information by healthcare professionals, thereby
supporting better health outcomes and informed decision-making in the face of
patients exposed to chemical intoxication risks.

æè¦ï¼äººé¡å¥åº·è¶ä¾è¶åå°æ¥è§¸æå®³ç©è³ªçå¨èï¼å°¤å¶æ¯æä¹æ§åææ¯çåå­¸ç©è³ªãç§å­¸ç ç©¶å·²è­æéäºç©è³ªï¼éå¸¸å­å¨æ¼è¤éçæ··åç©ä¸­ï¼èåç¨®ç¾çä¹éçéè¯ãç¶èï¼éäºè³è¨åæ£å¨å¤åä¾æºä¸­ï¼äººé¡åæ©å¨é½å¾é£åå¾ãæ¬æè©ä¼°äºç¶åç¼å¸/åå¾æéæå®³åå­¸ç©è³ªè³è¨çæ£ä¾ï¼ä¸¦æåºä¸åæ°ç©çå¹³å°ï¼æ¨å¨ä¿é²å¨ç·æ¥ææ³ä¸åå¾ééµåå­¸è³æãæ­¤å¹³å°å¯éä¾èªå¤åä¾æºçè³è¨ï¼ä¸¦å°å¶çµç¹æçµæ§åçç¥è­åè­ãä½¿ç¨èå¯ä»¥ééè¦è¦ºåä»é¢ï¼ä¾å¦ Neo4J Bloom ååè¡¨æ¿ï¼æä½¿ç¨èå¤©æ©å¨äººçèªç¶èªè¨æ¥è©¢ä¾åå¾éäºè³è¨ãæåçç ç©¶çµæè¡¨æï¼ç¶è³æééµå¾ª FAIR ååæï¼åå¾éè¦åå­¸è³è¨æéçæéåç²¾åæå¤§å¹æ¸å°ãæ­¤å¤ï¼æåè¨è«å¾æ­¤å¹³å°çéç¼åå¯¦ä½ä¸­å­¸å°çç¶é©æè¨ï¼ä¸¦çºè³æææèåç¼å¸èæä¾å»ºè­°ï¼ä»¥å¢å¼·è³æåå©ç¨åäºæä½æ§ãéé å·¥ä½æ¨å¨æ¹åé«çä¿å¥å°æ¥­äººå¡åå¾åä½¿ç¨åå­¸è³è¨çæ¹å¼ï¼å¾èæ¯ææ´å¥½çå¥åº·çµæï¼ä¸¦å¨é¢å°æ¥è§¸åå­¸ä¸­æ¯é¢¨éªçæ£èæååºææºçæ±ºç­ã

##### **Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**
2412.07618v1 by Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie

Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡åå¨è¨±å¤ NLP ä»»åä¸è¡¨ç¾åªç°ï¼
å®åå¨è¨æ¶å»£æ³çä¸çç¥è­æ¹é¢ä»é¢è¨éå¤§éå¶ãæè¿çç ç©¶è¡¨æï¼
å©ç¨æª¢ç´¢å¢å¼·çæ (RAG) æ¡æ¶ï¼çµåä»¥çµæ§åæ ¼å¼å°è£å»£æ³äºå¯¦è³æçç¥è­åè­ï¼
è½ç©©å¥å°å¢å¼· LLM çæ¨çè½åãç¶èï¼å¨ç¾å¯¦ä¸çå ´æ¯ä¸­é¨ç½²æ­¤é¡ç³»çµ±æç¢çææ°ï¼
éå¹³ç©©ç°å¢çæçºæ¼è®å¯è½å°è´æè½ä¸éï¼èä½¿ç¨èçæ»¿æåº¦éè¦å¨æè½ååææ§ä¹éåå¾ä»ç´°çå¹³è¡¡ã
çºäºæå°éäºææ°ï¼æåå¼å¥äºå¤ç®æ¨å¤èèèæ©å¢å¼·ç RAG æ¡æ¶ï¼
ä¸¦å¨å¯¦åä¸­æ¡ç¨å·åå¤åè½åçåç¨®æª¢ç´¢æ¹æ³ï¼ä»¥æå°è±å¯ä¸ä¸æ·æ¼è®çæª¢ç´¢æå¢ã
å¨æ­¤æ¡æ¶ä¸­ï¼æ¯åæª¢ç´¢æ¹æ³é½è¢«è¦çºä¸åä¸åçãæèãã
è©²ç³»çµ±å©ç¨å³æä½¿ç¨èåé¥ä¾é©æåæç°å¢ï¼
æ ¹æè¼¸å¥æ¥è©¢åæ¯åæèçæ­·å²å¤ç®æ¨æè½ä¾é¸æé©ç¶çæª¢ç´¢æ¹æ³ã
å¨å©ååºæº KGQA è³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼
æåçæ¨¡åå¨éå¹³ç©©è¨­å®ä¸­é¡¯èåªæ¼åºç·æ¨¡åï¼åæå¨å¹³ç©©ç°å¢ä¸­éå°æåé²çæè½ã
ç¨å¼ç¢¼åè³æå¯æ¼ https://github.com/FUTUREEEEEE/Dynamic-RAG.git åå¾

##### **Scaling Sequential Recommendation Models with Transformers**
2412.07585v1 by Pablo Zivic, Hernan Vazquez, Jorge Sanchez

Modeling user preferences has been mainly addressed by looking at users'
interaction history with the different elements available in the system.
Tailoring content to individual preferences based on historical data is the
main goal of sequential recommendation.
  The nature of the problem, as well as the good performance observed across
various domains, has motivated the use of the transformer architecture, which
has proven effective in leveraging increasingly larger amounts of training data
when accompanied by an increase in the number of model parameters. This scaling
behavior has brought a great deal of attention, as it provides valuable
guidance in the design and training of even larger models.
  Taking inspiration from the scaling laws observed in training large language
models, we explore similar principles for sequential recommendation.
  We use the full Amazon Product Data dataset, which has only been partially
explored in other studies, and reveal scaling behaviors similar to those found
in language models. Compute-optimal training is possible but requires a careful
analysis of the compute-performance trade-offs specific to the application.
  We also show that performance scaling translates to downstream tasks by
fine-tuning larger pre-trained models on smaller task-specific domains. Our
approach and findings provide a strategic roadmap for model training and
deployment in real high-dimensional preference spaces, facilitating better
training and inference efficiency.
  We hope this paper bridges the gap between the potential of transformers and
the intrinsic complexities of high-dimensional sequential recommendation in
real-world recommender systems.
  Code and models can be found at https://github.com/mercadolibre/srt

æè¦ï¼<paragraph>å»ºæ¨¡ä½¿ç¨èåå¥½ä¸»è¦ééè§å¯ä½¿ç¨èèç³»çµ±ä¸­ä¸ååç´ çäºåè¨éã
æ ¹ææ­·å²è³æèª¿æ´åäººåå¥½çå§å®¹æ¯é£çºæ¨è¦çä¸»è¦ç®æ¨ã
åé¡çæ¬è³ªï¼ä»¥åå¨ååé åè§å¯å°çè¯å¥½æè½ï¼æ¿åµäºTransformeræ¶æ§çä½¿ç¨ï¼å¨å¢å æ¨¡ååæ¸æ¸éæï¼å·²è­æè½ææå©ç¨è¶ä¾è¶å¤è¨ç·´è³æãéç¨®è¦æ¨¡è¡çºå¼èµ·äºæ¥µå¤§çéæ³¨ï¼å çºå®å¨è¨­è¨åè¨ç·´æ´å¤§æ¨¡åææä¾äºæå¹å¼çæå°ã
å¾è¨ç·´å¤§åèªè¨æ¨¡åä¸­è§å¯å°çè¦æ¨¡æ³åä¸­æ±²åéæï¼æåæ¢è¨äºé£çºæ¨è¦çé¡ä¼¼ååã
æåä½¿ç¨äºå®æ´ç Amazon ç¢åè³æéï¼å¶ä»ç ç©¶åé¨åæ¢è¨éï¼ä¸¦æ­ç¤ºäºèå¨èªè¨æ¨¡åä¸­ç¼ç¾çé¡ä¼¼çè¦æ¨¡è¡çºãè¨ç®æä½³è¨ç·´æ¯å¯è½çï¼ä½éè¦ä»ç´°åæç¹å®æ¼æç¨ç¨å¼çè¨ç®æè½æè¡·ã
æåéå±ç¤ºäºæè½è¦æ¨¡è½åçºä¸æ¸¸ä»»åï¼ééå°è¼å°çç¹å®ä»»åé åå¾®èª¿è¼å¤§çé è¨ç·´æ¨¡åãæåçåæ³åç¼ç¾çºæ¨¡åè¨ç·´åå¨å¯¦éé«ç¶­åº¦åå¥½ç©ºéä¸­é¨ç½²æä¾äºç­ç¥æ§è·¯ç·åï¼ä¿é²æ´å¥½çè¨ç·´åæ¨çæçã
æåå¸æéç¯è«æè½å½åTransformeræ½åèå¯¦éæ¨è¦ç³»çµ±ä¸­é«ç¶­åº¦é£çºæ¨è¦çå§å¨è¤éæ§ä¹éçå·®è·ã
ç¨å¼ç¢¼åæ¨¡åå¯ä»¥å¨ https://github.com/mercadolibre/srt æ¾å°</paragraph>

##### **Knowledge Graph Guided Evaluation of Abstention Techniques**
2412.07430v1 by Kinshuk Vasisht, Navreet Kaur, Danish Pruthi

To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., "rivers") from a knowledge graph. The nature of SELECT enables
us to isolate the effects of abstention techniques from other safety training
procedures, as well as evaluate their generalization and specificity. Using
SELECT, we benchmark different abstention techniques over six open-weight and
closed-source models. We find that the examined techniques indeed cause models
to abstain with over $80\%$ abstention rates. However, these techniques are not
as effective for descendants of the target concepts, with refusal rates
declining by $19\%$. We also characterize the generalization-vs-specificity
trade-offs for different techniques. Overall, no single technique is invariably
better than the others. Our findings call for a careful evaluation of different
aspects of abstention, and hopefully inform practitioners of various trade-offs
involved.

æè¦ï¼çºäºå®å¨å°é¨ç½²èªè¨æ¨¡åï¼è³ééè¦çæ¯ï¼å®åå¿é é¿ååæä¸é©ç¶çè«æ±ãååææ¸é ç ç©¶æ¸¬è©¦æ¨¡åçå®å¨æ§ï¼ä¾æå®åå°éæ¡æè«æ±çæææ§çºåºç¤ãå¨éé å·¥ä½ä¸­ï¼æåå°æ³¨æ¼è©ä¼°å°è´æ¨¡åé¿ååæçåºå±¤æè¡ãæåå»ºç«äº SELECTï¼ä¸åå¾ç¥è­åè­ä¸­ä¸çµè¯æ§æ¦å¿µï¼ä¾å¦ãæ²³æµãï¼è¡ççåºæºãSELECT çæ§è³ªä½¿æåè½å¤ å°é¿ååææè¡çå½±é¿èå¶ä»å®å¨è¨ç·´ç¨åºéé¢ï¼ä¸¦è©ä¼°å®åçæ¦æ¬æ§åç¹ç°æ§ãä½¿ç¨ SELECTï¼æåå°å­åéæ¾æ¬éåå°éåå§ç¢¼æ¨¡åé²è¡äºä¸åé¿ååææè¡çåºæºæ¸¬è©¦ãæåç¼ç¾ï¼ææª¢æ¥çæè¡ç¢ºå¯¦å°è´æ¨¡åé¿ååæï¼é¿ååæçè¶é 80%ãç¶èï¼éäºæè¡å°æ¼ç®æ¨æ¦å¿µçå¾ä»£ä¸¦ä¸é£éº¼ææï¼æçµçä¸éäº 19%ãæåéæè¿°äºä¸åæè¡çæ¦æ¬æ§èç¹ç°æ§æ¬è¡¡ãç¸½é«èè¨ï¼æ²æä»»ä½å®ä¸æè¡å§çµåªæ¼å¶ä»æè¡ãæåçç¼ç¾è¦æ±ä»ç´°è©ä¼°é¿ååæçä¸åé¢åï¼ä¸¦å¸æè®å¾æ¥­äººå¡äºè§£ææ¶åçåç¨®æ¬è¡¡ã

##### **A Review of Challenges in Speech-based Conversational AI for Elderly Care**
2412.07388v1 by Willemijn Klaassen, Bram van Dijk, Marco Spruit

Artificially intelligent systems optimized for speech conversation are
appearing at a fast pace. Such models are interesting from a healthcare
perspective, as these voice-controlled assistants may support the elderly and
enable remote health monitoring. The bottleneck for efficacy, however, is how
well these devices work in practice and how the elderly experience them, but
research on this topic is scant. We review elderly use of voice-controlled AI
and highlight various user- and technology-centered issues, that need to be
considered before effective speech-controlled AI for elderly care can be
realized.

æè¦ï¼ä»¥èªé³å°è©±çºæä½³åçäººå·¥æºæ§ç³»çµ±æ­£å¿«éåºç¾ãæ­¤é¡æ¨¡åå¨é«çä¿å¥æ¹é¢å¾æè¶£ï¼å çºéäºè²æ§å©çå¯ä»¥æ¯æ´é·èä¸¦è½é²è¡é è·å¥åº·ç£æ§ãç¶èï¼æè½çç¶é ¸å¨æ¼éäºè£ç½®å¨å¯¦ééä½ä¸çè¡¨ç¾å¦ä½ï¼ä»¥åé·èå¦ä½é«é©å®åï¼ä½éæ¹é¢çç ç©¶å»å¾ç¨å°ãæååé¡§äºé·èä½¿ç¨è²æ§äººå·¥æºæ§ççæ³ï¼ä¸¦éé»èªªæåç¨®ä»¥ä½¿ç¨èåæè¡çºä¸­å¿çè­°é¡ï¼å¨è½å¯¦ç¾ææçè²æ§äººå·¥æºæ§ä»¥é²è¡é·èç§è­·ä¹åï¼éäºè­°é¡é½éè¦å ä»¥èéã

##### **Enhanced MRI Representation via Cross-series Masking**
2412.07387v1 by Churan Wang, Fei Gao, Lijun Yan, Siwen Wang, Yizhou Yu, Yizhou Wang

Magnetic resonance imaging (MRI) is indispensable for diagnosing and planning
treatment in various medical conditions due to its ability to produce
multi-series images that reveal different tissue characteristics. However,
integrating these diverse series to form a coherent analysis presents
significant challenges, such as differing spatial resolutions and contrast
patterns meanwhile requiring extensive annotated data, which is scarce in
clinical practice. Due to these issues, we introduce a novel Cross-Series
Masking (CSM) Strategy for effectively learning MRI representation in a
self-supervised manner. Specifically, CSM commences by randomly sampling a
subset of regions and series, which are then strategically masked. In the
training process, the cross-series representation is learned by utilizing the
unmasked data to reconstruct the masked portions. This process not only
integrates information across different series but also facilitates the ability
to model both intra-series and inter-series correlations and complementarities.
With the learned representation, the downstream tasks like segmentation and
classification are also enhanced. Taking brain tissue segmentation, breast
tumor benign/malignant classification, and prostate cancer diagnosis as
examples, our method achieves state-of-the-art performance on both public and
in-house datasets.

æè¦ï¼ç£æ¯é å½± (MRI) å°æ¼è¨ºæ·åè¦ååç¨®é«ççæ³çæ²»çè³ééè¦ï¼å çºå®è½å¤ ç¢çæ­ç¤ºä¸åçµç¹ç¹å¾µçå¤ç³»åå½±åãç¶èï¼æ´åéäºä¸åçç³»åä»¥å½¢æé£è²«çåææå¸¶ä¾éå¤§çææ°ï¼ä¾å¦ä¸åçç©ºéè§£æåº¦åå°æ¯æ¨¡å¼ï¼åæéè¦å¤§éçè¨»è§£è³æï¼ä½å¨è¨åºå¯¦åä¸­å»å¾ç¨å°ãç±æ¼éäºåé¡ï¼æåå¼å¥äºä¸ç¨®æ°ç©çè·¨ç³»åé®ç½© (CSM) ç­ç¥ï¼ä»¥ä¾¿ä»¥èªæç£ç£çæ¹å¼ææå°å­¸ç¿ MRI è¡¨å¾µãå·é«ä¾èªªï¼CSM å¾é¨æ©æ½æ¨£åååç³»åçå­ééå§ï¼ç¶å¾å°å¶é²è¡ç­ç¥æ§é®ç½©ãå¨è¨ç·´éç¨ä¸­ï¼è·¨ç³»åè¡¨å¾µæ¯ééå©ç¨æªé®ç½©çè³æä¾éå»ºé®ç½©é¨åèå­¸ç¿çãéåéç¨ä¸åæ´åäºä¸åç³»åçè³è¨ï¼éä¿é²äºå°ç³»åå§åç³»åééè¯æ§åäºè£æ§çå»ºæ¨¡è½åãééå­¸ç¿å°çè¡¨å¾µï¼ä¸æ¸¸ä»»åï¼ä¾å¦åå²ååé¡ï¼ä¹æå¾å°å¢å¼·ãä»¥è¦çµç¹åå²ãä¹³æ¿è«ç¤è¯æ§/æ¡æ§åé¡åååèºçè¨ºæ·çºä¾ï¼æåçæ¨¡åå¨å¬éè³æéåå§é¨è³æéä¸é½éå°äºæåé²çæè½ã

##### **On Evaluating the Durability of Safeguards for Open-Weight LLMs**
2412.07097v1 by Xiangyu Qi, Boyi Wei, Nicholas Carlini, Yangsibo Huang, Tinghao Xie, Luxi He, Matthew Jagielski, Milad Nasr, Prateek Mittal, Peter Henderson

Stakeholders -- from model developers to policymakers -- seek to minimize the
dual-use risks of large language models (LLMs). An open challenge to this goal
is whether technical safeguards can impede the misuse of LLMs, even when models
are customizable via fine-tuning or when model weights are fully open. In
response, several recent studies have proposed methods to produce durable LLM
safeguards for open-weight LLMs that can withstand adversarial modifications of
the model's weights via fine-tuning. This holds the promise of raising
adversaries' costs even under strong threat models where adversaries can
directly fine-tune model weights. However, in this paper, we urge for more
careful characterization of the limits of these approaches. Through several
case studies, we demonstrate that even evaluating these defenses is exceedingly
difficult and can easily mislead audiences into thinking that safeguards are
more durable than they really are. We draw lessons from the evaluation pitfalls
that we identify and suggest future research carefully cabin claims to more
constrained, well-defined, and rigorously examined threat models, which can
provide more useful and candid assessments to stakeholders.

æè¦ï¼å©å®³éä¿äººï¼å¾æ¨¡åéç¼äººå¡å°æ¿ç­å¶å®èï¼å°æ±å°å¤§åèªè¨æ¨¡å (LLM) çééä½¿ç¨é¢¨éªéè³æä½ãå°æ­¤ç®æ¨çå¬éææ°å¨æ¼ï¼æè¡ä¿éæªæ½æ¯å¦è½é»æ­¢ LLM çæ¿«ç¨ï¼å³ä½¿æ¨¡åå¯ééå¾®èª¿é²è¡èªè¨ï¼ææ¨¡åæ¬éå®å¨éæ¾æäº¦ç¶ãçºäºè§£æ±ºæ­¤åé¡ï¼æè¿æå¹¾é ç ç©¶æåºæ¹æ³ï¼ä»¥ç¢çé©ç¨æ¼éæ¾æ¬é LLM çèç¨ LLM ä¿éæªæ½ï¼éäºä¿éæªæ½è½æ¿åééå¾®èª¿å°æ¨¡åæ¬éé²è¡çå°ææ§ä¿®æ¹ãéæææé«å°æçææ¬ï¼å³ä½¿å¨å°æå¯ä»¥ç´æ¥å¾®èª¿æ¨¡åæ¬éçå¼·å¨èæ¨¡åä¸äº¦ç¶ãç¶èï¼å¨æ¬æä¸­ï¼æåæ¦ä¿æ´ä»ç´°å°æè¿°éäºæ¹æ³çéå¶ãééå¤é æ¡ä¾ç ç©¶ï¼æåè­æå³ä½¿è©ä¼°éäºé²ç¦¦æªæ½ä¹æ¥µå¶å°é£ï¼ä¸¦ä¸å¾å®¹æèª¤å°åç¾ï¼è®ä»åèªçºä¿éæªæ½æ¯å¯¦éä¸æ´èç¨ãæåå¾æåè¾¨è­åºçè©ä¼°é·é±ä¸­æ±²åæè¨ï¼ä¸¦å»ºè­°æªä¾çç ç©¶è¬¹æå°å°ä¸»å¼µéå¶å¨æ´åéãå®ç¾©æç¢ºä¸ç¶éå´æ ¼å¯©æ¥çå¨èæ¨¡åä¸­ï¼éå¯ä»¥çºå©å®³éä¿äººæä¾æ´æç¨ä¸å¦ççè©ä¼°ã

##### **Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**
2412.06993v1 by Le Song, Eran Segal, Eric Xing

We present an approach of using AI to model and simulate biology and life.
Why is it important? Because at the core of medicine, pharmacy, public health,
longevity, agriculture and food security, environmental protection, and clean
energy, it is biology at work. Biology in the physical world is too complex to
manipulate and always expensive and risky to tamper with. In this perspective,
we layout an engineering viable approach to address this challenge by
constructing an AI-Driven Digital Organism (AIDO), a system of integrated
multiscale foundation models, in a modular, connectable, and holistic fashion
to reflect biological scales, connectedness, and complexities. An AIDO opens up
a safe, affordable and high-throughput alternative platform for predicting,
simulating and programming biology at all levels from molecules to cells to
individuals. We envision that an AIDO is poised to trigger a new wave of
better-guided wet-lab experimentation and better-informed first-principle
reasoning, which can eventually help us better decode and improve life.

æè¦ï¼æåæåºäºä¸ç¨®ä½¿ç¨ AI ä¾å»ºæ¨¡åæ¨¡æ¬çç©å­¸åçå½çæ¹æ³ã
çºä»éº¼éå¾éè¦ï¼å çºå¨é«å­¸ãè¥å­¸ãå¬å±è¡çã
é·å£½ãè¾²æ¥­åé£åå®å¨ãç°å¢ä¿è­·åæ¸æ½
è½æºçæ ¸å¿ï¼é½æ¯çç©å­¸å¨éä½ãç©çä¸çä¸­ççç©å­¸å¤ªéè¤éï¼
é£ä»¥æä½ï¼èä¸ç¸½æ¯æè²´ä¸æé¢¨éªãå¾éåè§åº¦ä¾çï¼
æåå¶å®äºä¸ç¨®å¯è¡çå·¥ç¨æ¹æ³ä¾è§£æ±ºéåææ°ï¼æ¹æ³æ¯
æ§å»ºä¸å AI é©åçæ¸ä½çç©é« (AIDO)ï¼ä¸åæ´åç
å¤å°ºåº¦åºç¤æ¨¡åç³»çµ±ï¼ä»¥æ¨¡çµåãå¯é£æ¥åæ´é«çæ¹å¼
ä¾åæ çç©å°ºåº¦ãé£éæ§åè¤éæ§ãAIDO éåäºä¸åå®å¨ã
è² æå¾èµ·ä¸é«ééçæ¿ä»£å¹³å°ï¼ç¨æ¼é æ¸¬ã
æ¨¡æ¬åç·¨ç¨å¾åå­å°ç´°èå°åé«çææå±¤ç´ççç©å­¸ãæåé è¨ AIDO å°å¼ç¼ä¸æ³¢
ç±æ´ä½³æå°çæ¿å¼å¯¦é©åæ´å®åçç¬¬ä¸åç
æ¨ççæ°æµªæ½®ï¼æçµå¯ä»¥å¹«å©æåæ´å¥½å°è§£ç¢¼åæ¹åçå½ã

##### **Diagnosis and Severity Assessment of Ulcerative Colitis using Self Supervised Learning**
2412.07806v1 by Venkat Margapuri

Ulcerative Colitis (UC) is an incurable inflammatory bowel disease that leads
to ulcers along the large intestine and rectum. The increase in the prevalence
of UC coupled with gastrointestinal physician shortages stresses the healthcare
system and limits the care UC patients receive. A colonoscopy is performed to
diagnose UC and assess its severity based on the Mayo Endoscopic Score (MES).
The MES ranges between zero and three, wherein zero indicates no inflammation
and three indicates that the inflammation is markedly high. Artificial
Intelligence (AI)-based neural network models, such as convolutional neural
networks (CNNs) are capable of analyzing colonoscopies to diagnose and
determine the severity of UC by modeling colonoscopy analysis as a multi-class
classification problem. Prior research for AI-based UC diagnosis relies on
supervised learning approaches that require large annotated datasets to train
the CNNs. However, creating such datasets necessitates that domain experts
invest a significant amount of time, rendering the process expensive and
challenging. To address the challenge, this research employs self-supervised
learning (SSL) frameworks that can efficiently train on unannotated datasets to
analyze colonoscopies and, aid in diagnosing UC and its severity. A comparative
analysis with supervised learning models shows that SSL frameworks, such as
SwAV and SparK outperform supervised learning models on the LIMUC dataset, the
largest publicly available annotated dataset of colonoscopy images for UC.

æè¦ï¼æ½°çæ§çµè¸ç (UC) æ¯ä¸ç¨®ç¡æ³æ²»ççç¼çæ§è¸éç¾çï¼æå°è´å¤§è¸åç´è¸æ½°çãUC çæ£ççå¢å ï¼å ä¸è¸èç§é«å¸«ç­ç¼ºï¼å°é«çä¿å¥ç³»çµ±é æå£åï¼ä¸¦éå¶ UC æ£èæ¥åçç§è­·ãé²è¡å¤§è¸é¡æª¢æ¥ä»¥è¨ºæ· UC ä¸¦æ ¹æ Mayo å§è¦é¡è©å (MES) è©ä¼°å¶å´éç¨åº¦ãMES çç¯åå¨ 0 å° 3 ä¹éï¼å¶ä¸­ 0 è¡¨ç¤ºæ²æç¼çï¼è 3 è¡¨ç¤ºç¼çç¨åº¦é¡¯èãåºæ¼äººå·¥æºæ§ (AI) çç¥ç¶ç¶²è·¯æ¨¡åï¼ä¾å¦å·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼è½å¤ åæå¤§è¸é¡æª¢æ¥ä»¥è¨ºæ·åç¢ºå® UC çå´éç¨åº¦ï¼æ¹æ³æ¯å°å¤§è¸é¡æª¢æ¥åæå»ºæ¨¡çºå¤é¡å¥åé¡åé¡ãååéå°åºæ¼ AI ç UC è¨ºæ·çç ç©¶ä¾è³´æ¼ç£ç£å¼å­¸ç¿æ¹æ³ï¼éè¦å¤§éæ¨è¨»çè³æéä¾è¨ç·´ CNNãç¶èï¼å»ºç«æ­¤é¡è³æééè¦é åå°å®¶æå¥å¤§éæéï¼ä½¿éåéç¨æ¢æè²´åå·æææ°æ§ãçºäºæå°éåææ°ï¼æ¬ç ç©¶æ¡ç¨èªæç£ç£å­¸ç¿ (SSL) æ¡æ¶ï¼å¯ä»¥å¨æªæ¨è¨»çè³æéä¸é²è¡ææççè¨ç·´ï¼ä»¥åæå¤§è¸é¡æª¢æ¥ä¸¦åå©è¨ºæ· UC åå¶å´éç¨åº¦ãèç£ç£å¼å­¸ç¿æ¨¡åçæ¯è¼åæé¡¯ç¤ºï¼SSL æ¡æ¶ï¼ä¾å¦ SwAV å SparKï¼å¨ LIMUC è³æéï¼æå¤§çå¬é UC å¤§è¸é¡æª¢æ¥å½±åæ¨è¨»è³æéï¼ä¸åªæ¼ç£ç£å¼å­¸ç¿æ¨¡åã

##### **Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**
2412.06717v1 by Sahil Sethi, Sai Reddy, Mansi Sakarvadia, Jordan Serotte, Darlington Nwaudo, Nicholas Maassen, Lewis Shi

Bankart lesions, or anterior-inferior glenoid labral tears, are
diagnostically challenging on standard MRIs due to their subtle imaging
features-often necessitating invasive MRI arthrograms (MRAs). This study
develops deep learning (DL) models to detect Bankart lesions on both standard
MRIs and MRAs, aiming to improve diagnostic accuracy and reduce reliance on
MRAs. We curated a dataset of 586 shoulder MRIs (335 standard, 251 MRAs) from
558 patients who underwent arthroscopy. Ground truth labels were derived from
intraoperative findings, the gold standard for Bankart lesion diagnosis.
Separate DL models for MRAs and standard MRIs were trained using the Swin
Transformer architecture, pre-trained on a public knee MRI dataset. Predictions
from sagittal, axial, and coronal views were ensembled to optimize performance.
The models were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71
standard MRIs). Bankart lesions were identified in 31.9% of MRAs and 8.6% of
standard MRIs. The models achieved AUCs of 0.87 (86% accuracy, 83% sensitivity,
86% specificity) and 0.90 (85% accuracy, 82% sensitivity, 86% specificity) on
standard MRIs and MRAs, respectively. These results match or surpass
radiologist performance on our dataset and reported literature metrics.
Notably, our model's performance on non-invasive standard MRIs matched or
surpassed the radiologists interpreting MRAs. This study demonstrates the
feasibility of using DL to address the diagnostic challenges posed by subtle
pathologies like Bankart lesions. Our models demonstrate potential to improve
diagnostic confidence, reduce reliance on invasive imaging, and enhance
accessibility to care.

æè¦ï¼Bankart çç¶ï¼æåä¸çåæè£ï¼ç±æ¼å¶å½±åç¹å¾µå¾®å¦ï¼å¨æ¨æºæ ¸ç£å±æ¯æåä¸­è¨ºæ·å·æææ°æ§ï¼éå¸¸éè¦ä¾µå¥æ§æ ¸ç£å±æ¯è¡ç®¡é å½± (MRA)ãæ¬ç ç©¶éç¼æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ç¨æ¼å¨æ¨æºæ ¸ç£å±æ¯æååæ ¸ç£å±æ¯è¡ç®¡é å½±ä¸­æª¢æ¸¬ Bankart çç¶ï¼æ¨å¨æé«è¨ºæ·æºç¢ºæ§ä¸¦æ¸å°å°æ ¸ç£å±æ¯è¡ç®¡é å½±çä¾è³´ãæåå¾ 558 åæ¥åéç¯é¡æª¢æ¥çæ£èä¸­ç­åäºä¸çµ 586 ä¾è©é¨æ ¸ç£å±æ¯æå (335 ä¾æ¨æºï¼251 ä¾æ ¸ç£å±æ¯è¡ç®¡é å½±) çæ¸æéãåºæ¬äºå¯¦æ¨ç±¤ä¾èªè¡ä¸­ç¼ç¾ï¼éæ¯ Bankart çç¶è¨ºæ·çé»éæ¨æºãä½¿ç¨ Swin Transformer æ¶æ§è¨ç·´äºæ ¸ç£å±æ¯è¡ç®¡é å½±åæ¨æºæ ¸ç£å±æ¯æåçå®ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼ä¸¦å¨å¬éçèé¨æ ¸ç£å±æ¯æåæ¸æéä¸é²è¡é è¨ç·´ãç¢çé¢ãè»¸é¢åå çé¢çé æ¸¬çµæè¢«çµåèµ·ä¾ä»¥åªåæ§è½ãéäºæ¨¡åå¨ 20% çä¿çæ¸¬è©¦éï¼117 ä¾æ ¸ç£å±æ¯æåï¼46 ä¾æ ¸ç£å±æ¯è¡ç®¡é å½±ï¼71 ä¾æ¨æºæ ¸ç£å±æ¯æåï¼ä¸é²è¡äºè©ä¼°ãå¨ 31.9% çæ ¸ç£å±æ¯è¡ç®¡é å½±å 8.6% çæ¨æºæ ¸ç£å±æ¯æåä¸­ç¼ç¾äº Bankart çç¶ãéäºæ¨¡åå¨æ¨æºæ ¸ç£å±æ¯æååæ ¸ç£å±æ¯è¡ç®¡é å½±ä¸­ç AUC åå¥éå° 0.87ï¼86% æºç¢ºåº¦ï¼83% éæåº¦ï¼86% ç¹ç°åº¦ï¼å 0.90ï¼85% æºç¢ºåº¦ï¼82% éæåº¦ï¼86% ç¹ç°åº¦ï¼ãéäºçµæèæ¾å°ç§é«çå°æåæ¸æéçè¡¨ç¾ç¸å¹éæè¶éï¼ä¸¦è¶éäºå ±åçæç»ææ¨ãå¼å¾æ³¨æçæ¯ï¼æåçæ¨¡åå¨éä¾µå¥æ§æ¨æºæ ¸ç£å±æ¯æåä¸­çè¡¨ç¾èæ¾å°ç§é«çå°æ ¸ç£å±æ¯è¡ç®¡é å½±çè§£éç¸å¹éæè¶éãæ¬ç ç©¶è­æäºä½¿ç¨æ·±åº¦å­¸ç¿ä¾è§£æ±º Bankart çç¶ç­å¾®å¦ççè¨ºæ·ææ°çå¯è¡æ§ãæåçæ¨¡åå±ç¤ºäºæé«è¨ºæ·ä¿¡å¿ãæ¸å°å°ä¾µå¥æ§å½±åæª¢æ¥çä¾è³´ä»¥åå¢å¼·ç²å¾ç§è­·çæ©æçæ½åã

##### **Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**
2412.06709v1 by Aqib Nazir Mir, Iqra Nissar, Mumtaz Ahmed, Sarfaraz Masood, Danish Raza Rizvi

Deep learning holds tremendous potential in healthcare for uncovering hidden
patterns within extensive clinical datasets, aiding in the diagnosis of various
diseases. Parkinson's disease (PD) is a neurodegenerative condition
characterized by the deterioration of brain function. In the initial stages of
PD, automatic diagnosis poses a challenge due to the similarity in behavior
between individuals with PD and those who are healthy. Our objective is to
propose an effective model that can aid in the early detection of Parkinson's
disease. We employed the VGRF gait signal dataset sourced from Physionet for
distinguishing between healthy individuals and those diagnosed with Parkinson's
disease. This paper introduces a novel deep learning architecture based on the
LSTM network for automatically detecting freezing of gait episodes in
Parkinson's disease patients. In contrast to conventional machine learning
algorithms, this method eliminates manual feature engineering and proficiently
captures prolonged temporal dependencies in gait patterns, thereby improving
the diagnosis of Parkinson's disease. The LSTM network resolves the issue of
vanishing gradients by employing memory blocks in place of self-connected
hidden units, allowing for optimal information assimilation. To prevent
overfitting, dropout and L2 regularization techniques have been employed.
Additionally, the stochastic gradient-based optimizer Adam is used for the
optimization process. The results indicate that our proposed approach surpasses
current state-of-the-art models in FOG episode detection, achieving an accuracy
of 97.71%, sensitivity of 99%, precision of 98%, and specificity of 96%. This
demonstrates its potential as a superior classification method for Parkinson's
disease detection.

æè¦ï¼æ·±åº¦å­¸ç¿å¨é«çä¿å¥é åææå·¨å¤§çæ½åï¼å¯ç¨æ¼ç¼æå»£æ³è¨åºè³æéä¸­çé±èæ¨¡å¼ï¼åå©è¨ºæ·åç¨®ç¾çãå¸éæ£®æ°ç (PD) æ¯ä¸ç¨®ç¥ç¶éåæ§ç¾çï¼å¶ç¹å¾µæ¯å¤§è¦åè½æ¡åãå¨ PD çåæéæ®µï¼ç±æ¼ PD æ£èèå¥åº·èçè¡çºç¸ä¼¼ï¼å æ­¤èªåè¨ºæ·å·æææ°æ§ãæåçç®æ¨æ¯æåºä¸åææçæ¨¡åï¼å¯ä»¥å¹«å©æ©ææª¢æ¸¬å¸éæ£®æ°çãæåæ¡ç¨äºä¾èª Physionet ç VGRF æ­¥æä¿¡èè³æéï¼ç¨æ¼ååå¥åº·åé«åè¢«è¨ºæ·åºæ£æå¸éæ£®æ°ççåé«ãæ¬æä»ç´¹äºä¸ç¨®åºæ¼ LSTM ç¶²è·¯çæ·±åº¦å­¸ç¿æ°æ¶æ§ï¼ç¨æ¼èªåæª¢æ¸¬å¸éæ£®æ°çæ£èçæ­¥æåçµç¼ä½ãèå³çµ±æ©å¨å­¸ç¿æ¼ç®æ³ç¸æ¯ï¼æ­¤æ¹æ³æ¶é¤äºæåç¹å¾µå·¥ç¨ï¼ä¸¦çç·´å°æææ­¥ææ¨¡å¼ä¸­çé·æéä¾è³´æ§ï¼å¾èæ¹é²äºå¸éæ£®æ°ççè¨ºæ·ãLSTM ç¶²è·¯ééä½¿ç¨è¨æ¶åå¡ä»£æ¿èªé£æ¥é±èå®åä¾è§£æ±ºæ¢¯åº¦æ¶å¤±åé¡ï¼å¾èå¯¦ç¾æä½³è³è¨ååãçºäºé²æ­¢éåº¦æ¬åï¼å·²æ¡ç¨ä¸­æ·å L2 æ­£ååæè¡ãæ­¤å¤ï¼é¨æ©æ¢¯åº¦åªåå¨ Adam ç¨æ¼åªåéç¨ãçµæè¡¨æï¼æåæåºçæ¹æ³å¨ FOG ç¼ä½æª¢æ¸¬æ¹é¢è¶è¶äºç¶åæåé²çæ¨¡åï¼éå°äº 97.71% çæºç¢ºçã99% çéæåº¦ã98% çç²¾ç¢ºåº¦å 96% çç¹ç°æ§ãéè­æäºå¶ä½çºå¸éæ£®æ°çæª¢æ¸¬çåªè¶åé¡æ¹æ³çæ½åã

##### **Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**
2412.06624v1 by Sooyong Jang, Kuk Jin Jang, Hyonyoung Choi, Yong-Seop Han, Seongjin Lee, Jin-hyun Kim, Insup Lee

Timely detection and treatment are essential for maintaining eye health.
Visual acuity (VA), which measures the clarity of vision at a distance, is a
crucial metric for managing eye health. Machine learning (ML) techniques have
been introduced to assist in VA measurement, potentially alleviating
clinicians' workloads. However, the inherent uncertainties in ML models make
relying solely on them for VA prediction less than ideal. The VA prediction
task involves multiple sources of uncertainty, requiring more robust
approaches. A promising method is to build prediction sets or intervals rather
than point estimates, offering coverage guarantees through techniques like
conformal prediction and Probably Approximately Correct (PAC) prediction sets.
Despite the potential, to date, these approaches have not been applied to the
VA prediction task.To address this, we propose a method for deriving prediction
intervals for estimating visual acuity from fundus images with a PAC guarantee.
Our experimental results demonstrate that the PAC guarantees are upheld, with
performance comparable to or better than that of two prior works that do not
provide such guarantees.

æè¦ï¼åæå°åµæ¸¬åæ²»çå°æ¼ç¶­æç¼çå¥åº·è³ééè¦ã
è¦åï¼VAï¼ï¼ç¨æ¼æ¸¬éé è·é¢è¦è¦ºçæ¸æ°åº¦ï¼æ¯ç¶­æç¼çå¥åº·çééµææ¨ãæ©å¨å­¸ç¿ï¼MLï¼æè¡å·²è¢«å¼å¥ä»¥åå© VA æ¸¬éï¼æ½å¨å°æ¸è¼è¨åºé«å¸«çå·¥ä½è² æãç¶èï¼ML æ¨¡åä¸­åºæçä¸ç¢ºå®æ§ä½¿å¾åä¾è³´å®åé²è¡ VA é æ¸¬ä¸¦éçæ³ãVA é æ¸¬ä»»åæ¶åå¤ç¨®ä¸ç¢ºå®æ§ä¾æºï¼éè¦æ´å¼·å¤§çæ¹æ³ãä¸ç¨®æåéçæ¹æ³æ¯å»ºç«é æ¸¬éåæåéï¼èä¸æ¯é»ä¼°è¨ï¼ééåå±å½¢é æ¸¬åå¤§æ¦æ­£ç¢ºï¼PACï¼é æ¸¬éåéæ¨£çæè¡æä¾è¦èçä¿è­ãåç®¡ææ½åï¼ä½è¿ä»çºæ­¢ï¼éäºæ¹æ³å°æªæç¨æ¼ VA é æ¸¬ä»»åãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®å¾ç¼åºååä¼°è¨è¦åçé æ¸¬åéçæ¹æ³ï¼ä¸¦æä¾ PAC ä¿è­ãæåçå¯¦é©çµæè¡¨æï¼PAC ä¿è­å¾å°ç¶­æï¼å¶æ§è½èä¸æä¾æ­¤é¡ä¿è­çå©é ååå·¥ä½çæ§è½ç¸ç¶ææ´å¥½ã

##### **Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices**
2412.06874v1 by Biman Barua, M. Shamim Kaiser

The rapid growth of the travel industry has increased the need for real-time
optimization in reservation systems that could take care of huge data and
transaction volumes. This study proposes a hybrid framework that ut folds an
Artificial Intelligence and a Microservices approach for the performance
optimization of the system. The AI algorithms forecast demand patterns,
optimize the allocation of resources, and enhance decision-making driven by
Microservices architecture, hence decentralizing system components for
scalability, fault tolerance, and reduced downtime. The model provided focuses
on major problems associated with the travel reservation systems such as
latency of systems, load balancing and data consistency. It endows the systems
with predictive models based on AI improved ability to forecast user demands.
Microservices would also take care of different scales during uneven traffic
patterns. Hence, both aspects ensure better handling of peak loads and spikes
while minimizing delays and ensuring high service quality. A comparison was
made between traditional reservation models, which are monolithic and the new
model of AI-Microservices. Comparatively, the analysis results state that there
is a drastic improvement in processing times where the system uptime and
resource utilization proved the capability of AI and the microservices in
transforming the travel industry in terms of reservation. This research work
focused on AI and Microservices towards real-time optimization, providing
critical insight into how to move forward with practical recommendations for
upgrading travel reservation systems with this technology.

æè¦ï¼æéç¢æ¥­å¿«éæé·ï¼æåäºé è¨ç³»çµ±ä¸­å³ææä½³åçéæ±ï¼éåç³»çµ±å¯ä»¥èçé¾å¤§çè³æåäº¤æéãæ¬ç ç©¶æåºä¸åæ··åæ¶æ§ï¼å®çµåäººå·¥æºæ§åå¾®æåæ¹æ³ä¾æä½³åç³»çµ±æè½ãäººå·¥æºæ§æ¼ç®æ³é æ¸¬éæ±æ¨¡å¼ï¼æä½³åè³æºéç½®ï¼ä¸¦å å¼·ç±å¾®æåæ¶æ§é©åçæ±ºç­å¶å®ï¼å æ­¤åæ£ç³»çµ±åä»¶ä»¥å©æ¼æ´åæ§ãå®¹é¯è½ååæ¸å°åæ©æéãææä¾çæ¨¡åå°æ³¨æ¼èæéé è¨ç³»çµ±ç¸éçä¸»è¦åé¡ï¼ä¾å¦ç³»çµ±å»¶é²ãè² è¼å¹³è¡¡åè³æä¸è´æ§ãå®è³¦äºç³»çµ±é æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§æåé æ¸¬ä½¿ç¨èéæ±çè½åãå¾®æåä¹æå¨æµéæ¨¡å¼ä¸åæèçä¸åçè¦æ¨¡ãå æ­¤ï¼éå©åé¢åç¢ºä¿è½æ´å¥½å°èçå°å³°è² è¼åæµéæ¿å¢ï¼åæå°å»¶é²éå°æä½ä¸¦ç¢ºä¿é«æååè³ªãæ¯è¼å³çµ±çé è¨æ¨¡åï¼å®é«å¼ï¼åæ°ç AI-å¾®æåæ¨¡åãæ¯è¼ä¹ä¸ï¼åæçµææåºèçæéæé¡¯èæ¹åï¼å¶ä¸­ç³»çµ±æ­£å¸¸éè¡æéåè³æºä½¿ç¨çè­æäºäººå·¥æºæ§åå¾®æåå¨é è¨æ¹é¢è½åæéç¢æ¥­çè½åãéé ç ç©¶å·¥ä½å°æ³¨æ¼äººå·¥æºæ§åå¾®æåï¼ä»¥å¯¦ç¾å³ææä½³åï¼æä¾ééµè¦è§£ï¼èªªæå¦ä½ééå¯¦ç¨å»ºè­°ï¼ä½¿ç¨éé æè¡åç´æéé è¨ç³»çµ±ã

##### **Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System**
2412.06600v2 by Yubo Zhou, Weizhen Bian, Kaitai Zhang, Xiaohan Gu

In traditional medical practices, music therapy has proven effective in
treating various psychological and physiological ailments. Particularly in
Eastern traditions, the Five Elements Music Therapy (FEMT), rooted in
traditional Chinese medicine, possesses profound cultural significance and
unique therapeutic philosophies. With the rapid advancement of Information
Technology and Artificial Intelligence, applying these modern technologies to
FEMT could enhance the personalization and cultural relevance of the therapy
and potentially improve therapeutic outcomes. In this article, we developed a
music therapy system for the first time by applying the theory of the five
elements in music therapy to practice. This innovative approach integrates
advanced Information Technology and Artificial Intelligence with Five-Element
Music Therapy (FEMT) to enhance personalized music therapy practices. As
traditional music therapy predominantly follows Western methodologies, the
unique aspects of Eastern practices, specifically the Five-Element theory from
traditional Chinese medicine, should be considered. This system aims to bridge
this gap by utilizing computational technologies to provide a more
personalized, culturally relevant, and therapeutically effective music therapy
experience.

æè¦ï¼å¨å³çµ±é«å­¸ä¸­ï¼é³æ¨çæ³å·²è¢«è­å¯¦è½æææ²»çåç¨®å¿çåççç¾çãç¹å¥æ¯å¨æ±æ¹å³çµ±ä¸­ï¼æ ¹æ¤æ¼ä¸­é«çäºè¡é³æ¨çæ³ (FEMT) å·ææ·±é çæåæç¾©åç¨ç¹çæ²»ççå¿µãé¨èè³è¨ç§æåäººå·¥æºæ§çå¿«éç¼å±ï¼å°éäºç¾ä»£æè¡æç¨æ¼ FEMT å¯ä»¥å¢å¼·çæ³çåäººååæåç¸éæ§ï¼ä¸¦æå¯è½æ¹åæ²»çææãå¨æ¬æä¸­ï¼æåé¦æ¬¡ééå°é³æ¨çæ³ä¸­çäºè¡çè«æç¨æ¼å¯¦è¸ï¼éç¼äºä¸åé³æ¨çæ³ç³»çµ±ãéç¨®åµæ°æ¹æ³å°åé²çè³è¨ç§æåäººå·¥æºæ§èäºè¡é³æ¨çæ³ (FEMT) ç¸çµåï¼ä»¥å¢å¼·åæ§åçé³æ¨çæ³å¯¦åãç±æ¼å³çµ±é³æ¨çæ³ä¸»è¦éµå¾ªè¥¿æ¹æ¹æ³ï¼å æ­¤æèæ®æ±æ¹å¯¦åçç¨ç¹æ¹é¢ï¼ç¹å¥æ¯ä¸­é«çäºè¡çè«ãæ­¤ç³»çµ±æ¨å¨å©ç¨è¨ç®æè¡å½åéä¸å·®è·ï¼ä»¥æä¾æ´åäººåãæåç¸éä¸æ²»çæææ´å¥½çé³æ¨çæ³é«é©ã

##### **HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**
2412.06530v1 by Jiayan Chen, Kai Li, Zhanjin Wang, Zhan Wang, Jianqiang Huang

Hepatic echinococcosis (HE) is a prevalent disease in economically
underdeveloped pastoral areas, where adequate medical resources are usually
lacking. Existing methods often ignore multi-scale feature fusion or focus only
on feature fusion between adjacent levels, which may lead to insufficient
feature fusion. To address these issues, we propose HES-UNet, an efficient and
accurate model for HE lesion segmentation. This model combines convolutional
layers and attention modules to capture local and global features. During
downsampling, the multi-directional downsampling block (MDB) is employed to
integrate high-frequency and low-frequency features, effectively extracting
image details. The multi-scale aggregation block (MAB) aggregates multi-scale
feature information. In contrast, the multi-scale upsampling Block (MUB) learns
highly abstract features and supplies this information to the skip connection
module to fuse multi-scale features. Due to the distinct regional
characteristics of HE, there is currently no publicly available high-quality
dataset for training our model. We collected CT slice data from 268 patients at
a certain hospital to train and evaluate the model. The experimental results
show that HES-UNet achieves state-of-the-art performance on our dataset,
achieving an overall Dice Similarity Coefficient (DSC) of 89.21%, which is
1.09% higher than that of TransUNet. The project page is available at
https://chenjiayan-qhu.github.io/HES-UNet-page.

æè¦ï¼èåè²çï¼HEï¼å¨ç¶æ¿è½å¾ççç§å°åçè¡ï¼é£è£¡éå¸¸ç¼ºä¹è¶³å¤ çé«çè³æºãç¾ææ¹æ³éå¸¸å¿½ç¥å¤å°ºåº¦ç¹å¾µèåï¼æåéæ³¨ç¸é°å±¤ä¹éçç¹å¾µèåï¼éå¯è½å°è´ç¹å¾µèåä¸è¶³ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº HES-UNetï¼éæ¯ä¸ç¨®ç¨æ¼ HE çç¶åå²çé«æä¸æºç¢ºçæ¨¡åãæ­¤æ¨¡åçµåäºå·ç©å±¤åæ³¨æåæ¨¡çµï¼ä»¥æ·åå±é¨åå¨å±ç¹å¾µãå¨éæ¡æ¨£éç¨ä¸­ï¼æ¡ç¨å¤åéæ¡æ¨£åå¡ (MDB) ä¾æ´åé«é »åä½é »ç¹å¾µï¼æææåå½±åç´°ç¯ãå¤å°ºåº¦èååå¡ (MAB) èåå¤å°ºåº¦ç¹å¾µè³è¨ãç¸åï¼å¤å°ºåº¦ä¸æ¡æ¨£åå¡ (MUB) æå­¸ç¿é«åº¦æ½è±¡çç¹å¾µï¼ä¸¦å°æ­¤è³è¨æä¾çµ¦è·³èºé£æ¥æ¨¡çµï¼ä»¥èåå¤å°ºåº¦ç¹å¾µãç±æ¼ HE çååç¹å¾µä¸åï¼ç®åæ²æå¬éå¯ç¨çé«åè³ªè³æéå¯ä¾è¨ç·´æåçæ¨¡åãæåå¾æå®¶é«é¢æ¶éäº 268 ä½æ£èç CT åçè³æï¼ä»¥è¨ç·´åè©ä¼°æ¨¡åãå¯¦é©çµæè¡¨æï¼HES-UNet å¨æåçè³æéä¸éå°äºæåé²çæè½ï¼æ´é« Dice ç¸ä¼¼æ§ä¿æ¸ (DSC) éå° 89.21%ï¼æ¯ TransUNet é« 1.09%ãå°æ¡é é¢å¯æ¼ https://chenjiayan-qhu.github.io/HES-UNet-page åå¾ã

##### **Simulating Human-like Daily Activities with Desire-driven Autonomy**
2412.06435v1 by Yiding Wang, Yuxuan Chen, Fangwei Zhong, Long Ma, Yizhou Wang

Existing task-oriented AI agents often depend on explicit instructions or
external rewards, limiting their ability to be driven by intrinsic motivations
like humans. In this paper, we present a desire-driven autonomy framework to
guide a Large Language Model-based (LLM-based) agent to simulate human-like
daily activities. In contrast to previous agents, our Desire-driven Autonomous
Agent (D2A) operates on the principle of intrinsic desire, allowing it to
propose and select tasks that fulfill its motivational framework autonomously.
Inspired by the Theory of Needs, the motivational framework incorporates an
understanding of human-like desires, such as the need for social interaction,
personal fulfillment, and self-care. Utilizing a desire-driven task generation
mechanism, the agent evaluates its current state and takes a sequence of
activities aligned with its intrinsic motivations. Through simulations, we
demonstrate that our Desire-driven Autonomous Agent (D2A) generates coherent,
contextually relevant daily activities while exhibiting variability and
adaptability similar to human behavior. A comparative analysis with other
LLM-based frameworks demonstrates that our approach significantly enhances the
rationality of the simulated activities.

æè¦ï¼ç¾æçä»»åå°å AI ä»£çéå¸¸ä¾è³´æç¢ºçæç¤ºæå¤é¨çåµï¼ééå¶äºå®ååäººé¡ä¸æ¨£ç±å§å¨åæ©é©åçè½åãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ¾æé©åçèªä¸»æ¡æ¶ï¼ä»¥æå°åºæ¼å¤§åèªè¨æ¨¡å (LLM) çä»£çæ¨¡æ¬é¡äººçæ¥å¸¸æ´»åãèä¹åçä»£çä¸åï¼æåçæ¾æé©åèªä¸»ä»£ç (D2A) éµå¾ªå§å¨æ¾æçååï¼åè¨±å®èªä¸»æåºåé¸æç¬¦åå¶åæ©æ¡æ¶çä»»åãåéæ±çè«çåç¼ï¼åæ©æ¡æ¶åå«å°é¡äººæ¾æççè§£ï¼ä¾å¦ç¤¾æäºåãåäººæ»¿è¶³åèªæä¿å¥çéè¦ãå©ç¨æ¾æé©åä»»åçææ©å¶ï¼ä»£çè©ä¼°å¶ç¶åçæä¸¦æ¡åä¸ç³»åèå¶å§å¨åæ©ä¸è´çæ´»åãééæ¨¡æ¬ï¼æåè­æäºæåçæ¾æé©åèªä¸»ä»£ç (D2A) ç¢çäºé£è²«ãèä¸ä¸æç¸éçæ¥å¸¸æ´»åï¼åæè¡¨ç¾åºèäººé¡è¡çºç¸ä¼¼çå¯è®æ§åé©ææ§ãèå¶ä»åºæ¼ LLM çæ¡æ¶é²è¡æ¯è¼åæè¡¨æï¼æåçåæ³é¡¯èæé«äºæ¨¡æ¬æ´»åçåçæ§ã

##### **CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**
2412.06314v1 by Yijie Dang, Weijun Ma, Xiaohu Luo

Since the outbreak of the COVID-19 pandemic in 2019, medical imaging has
emerged as a primary modality for diagnosing COVID-19 pneumonia. In clinical
settings, the segmentation of lung infections from computed tomography images
enables rapid and accurate quantification and diagnosis of COVID-19.
Segmentation of COVID-19 infections in the lungs poses a formidable challenge,
primarily due to the indistinct boundaries and limited contrast presented by
ground glass opacity manifestations. Moreover, the confounding similarity
between infiltrates, lung tissues, and lung walls further complicates this
segmentation task. To address these challenges, this paper introduces a novel
deep network architecture, called CAD-Unet, for segmenting COVID-19 lung
infections. In this architecture, capsule networks are incorporated into the
existing Unet framework. Capsule networks represent a novel network
architecture that differs from traditional convolutional neural networks. They
utilize vectors for information transfer among capsules, facilitating the
extraction of intricate lesion spatial information. Additionally, we design a
capsule encoder path and establish a coupling path between the unet encoder and
the capsule encoder. This design maximizes the complementary advantages of both
network structures while achieving efficient information fusion. \noindent
Finally, extensive experiments are conducted on four publicly available
datasets, encompassing binary segmentation tasks and multi-class segmentation
tasks. The experimental results demonstrate the superior segmentation
performance of the proposed model. The code has been released at:
https://github.com/AmanoTooko-jie/CAD-Unet.

æè¦ï¼èª 2019 å¹´ COVID-19 å¤§æµè¡çåä»¥æ¥ï¼å»å­¦å½±åå·²æä¸ºè¯æ­ COVID-19 èºççä¸»è¦æ¹å¼ãå¨ä¸´åºç¯å¢ä¸­ï¼ä»è®¡ç®æºæ­å±æ«æå¾åä¸­åå²èºé¨ææï¼å¯ä»¥å¿«éãåç¡®å°éååè¯æ­ COVID-19ãåå²èºé¨ä¸­ç COVID-19 æææ¯ä¸ä¸ªè°å·¨çææï¼è¿ä¸»è¦æ¯ç±äºæ¯ç»çæ ·åç°åºçè¾¹çä¸æ¸æ°ä¸å¯¹æ¯åº¦æéãæ­¤å¤ï¼æµ¸æ¶¦ãèºç»ç»åèºå£ä¹é´çæ··æ·ç¸ä¼¼æ§è¿ä¸æ­¥å¤æåäºè¿é¡¹åå²ä»»å¡ãä¸ºäºåºå¯¹è¿äºææï¼æ¬æä»ç»äºä¸ç§æ°é¢çæ·±åº¦ç½ç»æ¶æï¼ç§°ä¸º CAD-Unetï¼ç¨äºåå² COVID-19 èºé¨ææãå¨æ­¤æ¶æä¸­ï¼è¶åç½ç»è¢«çº³å¥ç°æç Unet æ¡æ¶ä¸­ãè¶åç½ç»ä»£è¡¨äºä¸ç§æ°é¢çç½ç»æ¶æï¼å®ä¸åäºä¼ ç»çå·ç§¯ç¥ç»ç½ç»ãå®ä»¬å©ç¨åéå¨è¶åä¹é´è¿è¡ä¿¡æ¯ä¼ è¾ï¼ä¿è¿äºå¤æçåç©ºé´ä¿¡æ¯çæåãæ­¤å¤ï¼æä»¬è®¾è®¡äºä¸ä¸ªè¶åç¼ç å¨è·¯å¾ï¼å¹¶å¨ unet ç¼ç å¨åè¶åç¼ç å¨ä¹é´å»ºç«äºä¸ä¸ªè¦åè·¯å¾ãè¿ç§è®¾è®¡æå¤§éåº¦å°åæ¥äºä¸¤ç§ç½ç»ç»æçäºè¡¥ä¼å¿ï¼åæ¶å®ç°äºé«æçä¿¡æ¯èåã\noindent
æåï¼å¨åä¸ªå¬å¼å¯ç¨çæ°æ®éä¸è¿è¡äºå¹¿æ³çå®éªï¼åæ¬äºè¿å¶åå²ä»»å¡åå¤ç±»åå²ä»»å¡ãå®éªç»æè¯æäºææåºæ¨¡åçåè¶åå²æ§è½ãè¯¥ä»£ç å·²åå¸å¨ï¼
https://github.com/AmanoTooko-jie/CAD-Unetã

##### **A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder**
2412.06262v1 by Quansong He, Xiaojun Yao, Jun Wu, Zhang Yi, Tao He

In recent years, advanced U-like networks have demonstrated remarkable
performance in medical image segmentation tasks. However, their drawbacks,
including excessive parameters, high computational complexity, and slow
inference speed, pose challenges for practical implementation in scenarios with
limited computational resources. Existing lightweight U-like networks have
alleviated some of these problems, but they often have pre-designed structures
and consist of inseparable modules, limiting their application scenarios. In
this paper, we propose three plug-and-play decoders by employing different
discretization methods of the neural memory Ordinary Differential Equations
(nmODEs). These decoders integrate features at various levels of abstraction by
processing information from skip connections and performing numerical
operations on upward path. Through experiments on the PH2, ISIC2017, and
ISIC2018 datasets, we embed these decoders into different U-like networks,
demonstrating their effectiveness in significantly reducing the number of
parameters and FLOPs while maintaining performance. In summary, the proposed
discretized nmODEs decoders are capable of reducing the number of parameters by
about 20% ~ 50% and FLOPs by up to 74%, while possessing the potential to adapt
to all U-like networks. Our code is available at
https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks.

æè¦ï¼è¿å¹´ä¾ï¼åé²ç U åç¶²è·¯å¨é«å­¸å½±ååå²ä»»åä¸­å±ç¾åºåè¶çè¡¨ç¾ãç¶èï¼å®åçç¼ºé»åæ¬éå¤çåæ¸ãé«éç®è¤éåº¦åç·©æ¢çæ¨è«éåº¦ï¼å°å¨éç®è³æºæéçææ³ä¸å¯¦éå·è¡æ§æææ°ãç¾æçè¼éç´ U åç¶²è·¯å·²ç¶æ¸è¼äºéäºåé¡ï¼ä½å®åéå¸¸æé åè¨­è¨ççµæ§ï¼ä¸¦åå«ä¸å¯åé¢çæ¨¡çµï¼éå¶äºå®åçæç¨å ´æ¯ãå¨æ¬æä¸­ï¼æåééæ¡ç¨ç¥ç¶è¨æ¶å¸¸å¾®åæ¹ç¨å¼ (nmODE) çä¸åé¢æ£åæ¹æ³ï¼æåºäºä¸åå³æå³ç¨çè§£ç¢¼å¨ãéäºè§£ç¢¼å¨ééèçä¾èªè·³èºé£æ¥çè³è¨ï¼ä¸¦å¨åä¸è·¯å¾ä¸å·è¡æ¸å¼éç®ï¼æ´åäºä¸åæ½è±¡å±¤ç´çç¹å¾µãééå¨ PH2ãISIC2017 å ISIC2018 è³æéä¸çå¯¦é©ï¼æåå°éäºè§£ç¢¼å¨åµå¥å°ä¸åç U åç¶²è·¯ä¸­ï¼è­æå®åå¨é¡¯èæ¸å°åæ¸å FLOP çåæï¼éè½ç¶­ææè½ãç¸½ä¹ï¼ææåºçé¢æ£ nmODE è§£ç¢¼å¨è½å¤ å°åæ¸æ¸éæ¸å°ç´ 20% ~ 50%ï¼FLOP æå¤æ¸å° 74%ï¼åæå·åé©æææ U åç¶²è·¯çæ½åãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks åå¾ã

##### **MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery**
2412.06211v1 by Qinfeng Zhu, Yuan Fang, Lei Fan

Crack detection is a critical task in structural health monitoring, aimed at
assessing the structural integrity of bridges, buildings, and roads to prevent
potential failures. Vision-based crack detection has become the mainstream
approach due to its ease of implementation and effectiveness. Fusing infrared
(IR) channels with red, green and blue (RGB) channels can enhance feature
representation and thus improve crack detection. However, IR and RGB channels
often differ in resolution. To align them, higher-resolution RGB images
typically need to be downsampled to match the IR image resolution, which leads
to the loss of fine details. Moreover, crack detection performance is
restricted by the limited receptive fields and high computational complexity of
traditional image segmentation networks. Inspired by the recently proposed
Mamba neural architecture, this study introduces a two-stage paradigm called
MSCrackMamba, which leverages Vision Mamba along with a super-resolution
network to address these challenges. Specifically, to align IR and RGB
channels, we first apply super-resolution to IR channels to match the
resolution of RGB channels for data fusion. Vision Mamba is then adopted as the
backbone network, while UperNet is employed as the decoder for crack detection.
Our approach is validated on the large-scale Crack Detection dataset Crack900,
demonstrating an improvement of 3.55% in mIoU compared to the best-performing
baseline methods.

æè¦ï¼è£ç¸«åµæ¸¬å¨çµæ§å¥åº·ç£æ¸¬ä¸­æ¯ä¸é éè¦çä»»åï¼æ¨å¨è©ä¼°æ©æ¨ãå»ºç¯ç©åéè·¯ççµæ§å®æ´æ§ï¼ä»¥é²æ­¢æ½å¨çæéãåºæ¼è¦è¦ºçè£ç¸«åµæ¸¬ç±æ¼å¶ææ¼å¯¦ä½åæææ§ï¼å·²æçºä¸»æµæ¹æ³ãå°ç´å¤ç· (IR) ééèç´è²ãç¶ è²åèè² (RGB) ééèåå¯ä»¥å¢å¼·ç¹å¾µè¡¨ç¤ºï¼é²èæ¹åè£ç¸«åµæ¸¬ãç¶èï¼IR å RGB éééå¸¸è§£æåº¦ä¸åãçºäºå°é½å®åï¼éå¸¸éè¦å°è¼é«è§£æåº¦ç RGB å½±åé²è¡éæ¡æ¨£ä»¥å¹é IR å½±åè§£æåº¦ï¼éæå°è´ç²¾ç´°ç´°ç¯çéºå¤±ãæ­¤å¤ï¼è£ç¸«åµæ¸¬æè½åå°å³çµ±å½±ååå²ç¶²è·¯æéçæåéåé«éç®è¤éåº¦çéå¶ãåè¿ææåºç Mamba ç¥ç¶æ¶æ§åç¼ï¼æ¬ç ç©¶å¼å¥äºä¸åç¨±çº MSCrackMamba çå©éæ®µç¯ä¾ï¼å®å©ç¨ Vision Mamba åè¶è§£æåº¦ç¶²è·¯ä¾æå°éäºææ°ãå·é«ä¾èªªï¼çºäºå°é½ IR å RGB ééï¼æåé¦åå° IR ééæç¨è¶è§£æåº¦ï¼ä»¥å¹é RGB ééçè§£æåº¦ï¼ä»¥é²è¡è³æèåãç¶å¾æ¡ç¨ Vision Mamba ä½çºéª¨å¹¹ç¶²è·¯ï¼åææ¡ç¨ UperNet ä½çºè£ç¸«åµæ¸¬çè§£ç¢¼å¨ãæåçåæ³å·²å¨å¤§åè£ç¸«åµæ¸¬è³æé Crack900 ä¸­å¾å°é©è­ï¼èæè½æä½³çåºæºæ¹æ³ç¸æ¯ï¼mIoU æåäº 3.55%ã

##### **Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction**
2412.06860v1 by Guoxiao Zhang, Yi Wei, Yadong Zhang, Huajian Feng, Qiang Liu

Click-Through Rate (CTR) prediction is essential in online advertising, where
semantic information plays a pivotal role in shaping user decisions and
enhancing CTR effectiveness. Capturing and modeling deep semantic information,
such as a user's preference for "H\"aagen-Dazs' HEAVEN strawberry light ice
cream" due to its health-conscious and premium attributes, is challenging.
Traditional semantic modeling often overlooks these intricate details at the
user and item levels. To bridge this gap, we introduce a novel approach that
models deep semantic information end-to-end, leveraging the comprehensive world
knowledge capabilities of Large Language Models (LLMs). Our proposed
LLM-infused CTR prediction framework(Multi-level Deep Semantic Information
Infused CTR model via Distillation, MSD) is designed to uncover deep semantic
insights by utilizing LLMs to extract and distill critical information into a
smaller, more efficient model, enabling seamless end-to-end training and
inference. Importantly, our framework is carefully designed to balance
efficiency and effectiveness, ensuring that the model not only achieves high
performance but also operates with optimal resource utilization. Online A/B
tests conducted on the Meituan sponsored-search system demonstrate that our
method significantly outperforms baseline models in terms of Cost Per Mile
(CPM) and CTR, validating its effectiveness, scalability, and balanced approach
in real-world applications.

æè¦ï¼é»æç (CTR) é æ¸¬å¨ç·ä¸å»£åä¸­è³ééè¦ï¼å¶ä¸­èªæè³è¨å¨å¡é ä½¿ç¨èæ±ºç­åæå CTR æçæ¹é¢æ®æ¼èééµè§è²ãæ·ååå»ºæ¨¡æ·±å¥çèªæè³è¨ï¼ä¾å¦ä½¿ç¨èåå¥½ãH\"aagen-Dazs' HEAVEN èèè¼çå°æ·æ·ãï¼å çºå®å·ææ³¨éå¥åº·åé«ç´çå±¬æ§ï¼æ¯ä¸é ææ°ãå³çµ±çèªæå»ºæ¨¡éå¸¸æå¿½ç¥ä½¿ç¨èåé ç®å±¤ç´çéäºè¤éç´°ç¯ãçºäºå½è£æ­¤å·®è·ï¼æåæåºäºä¸ç¨®åµæ°çæ¹æ³ï¼è©²æ¹æ³å¯ä»¥ç«¯å°ç«¯å°å»ºæ¨¡æ·±å¥èªæè³è¨ï¼ä¸¦å©ç¨å¤§åèªè¨æ¨¡å (LLM) çå¨é¢ä¸çç¥è­è½åãæåæåºç LLM æ³¨å¥ CTR é æ¸¬æ¶æ§ï¼ééç¥è­èåçå¤å±¤ç´æ·±å¥èªæè³è¨æ³¨å¥ CTR æ¨¡åï¼MSDï¼æ¨å¨ééå©ç¨ LLM èååæçééµè³è¨å°ä¸åæ´å°ãæ´ææççæ¨¡åä¸­ï¼ä¾ç¼ææ·±å¥çèªææ´å¯ï¼å¯¦ç¾ç¡ç¸«ç«¯å°ç«¯è¨ç·´åæ¨è«ãéè¦çæ¯ï¼æåçæ¶æ§ç¶éä»ç´°è¨­è¨ï¼ä»¥å¹³è¡¡æçåæè½ï¼ç¢ºä¿æ¨¡åä¸åè½éæé«æ§è½ï¼éè½ä»¥æä½³è³æºå©ç¨çéä½ãå¨ç¾åè´å©æå°ç³»çµ±ä¸é²è¡çç·ä¸ A/B æ¸¬è©¦è­æï¼æåçæ¨¡åå¨æ¯åæ¬¡ææ¬ (CPM) å CTR æ¹é¢é¡¯èåªæ¼åºç·æ¨¡åï¼é©è­äºå¶å¨å¯¦éæç¨ä¸­çæææ§ãå¯æ´åæ§åå¹³è¡¡æ¹æ³ã

##### **MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**
2412.06141v1 by Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao

The advancement of Large Vision-Language Models (LVLMs) has propelled their
application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter
factuality challenges due to modality misalignment, where the models prioritize
textual knowledge over visual input, leading to hallucinations that contradict
information in medical images. Previous attempts to enhance modality alignment
in Med-LVLMs through preference optimization have inadequately mitigated
clinical relevance in preference data, making these samples easily
distinguishable and reducing alignment effectiveness. To address this
challenge, we propose MMedPO, a novel multimodal medical preference
optimization approach that considers the clinical relevance of preference
samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference
data by introducing two types of dispreference: (1) plausible hallucinations
injected through target Med-LVLMs or GPT-4o to produce medically inaccurate
responses, and (2) lesion region neglect achieved through local lesion-noising,
disrupting visual understanding of critical areas. We then calculate clinical
relevance for each sample based on scores from multiple Med-LLMs and visual
tools, and integrate these scores into the preference optimization process as
weights, enabling effective alignment. Our experiments demonstrate that MMedPO
significantly enhances factual accuracy in Med-LVLMs, achieving substantial
improvements over existing preference optimization methods by averaging 14.2%
and 51.7% across the Med-VQA and report generation tasks. Our code are
available in https://github.com/aiming-lab/MMedPO.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) çé²æ­¥æ¨åäºå®åå¨é«çé åçæç¨ãç¶èï¼é«å­¸ LVLMs (Med-LVLMs) ç±æ¼æ¨¡æé¯ä½èéå°äºå¯¦ææ°ï¼å¶ä¸­æ¨¡ååªåèæ®æå­ç¥è­èéè¦è¦ºè¼¸å¥ï¼å°è´å¹»è¦ºèé«å­¸å½±åä¸­çè³è¨ç¸çç¾ãåååè©¦ééåå¥½æä½³åä¾å¢å¼· Med-LVLMs ä¸­çæ¨¡æå°é½ï¼å¨åå¥½è³æä¸­ä¸è¶³ä»¥æ¸è¼è¨åºç¸éæ§ï¼ä½¿å¾éäºç¯ä¾å®¹æååï¼ä¸¦éä½å°é½ææãçºäºæå°éé ææ°ï¼æåæåº MMedPOï¼ä¸ç¨®æ°çå¤æ¨¡æé«å­¸åå¥½æä½³åæ¹æ³ï¼å®èæ®åå¥½ç¯ä¾çè¨åºç¸éæ§ï¼ä»¥å¢å¼· Med-LVLM å°é½ãMMedPO ééå¼å¥å©ç¨®é¡åçååå¥½ä¾ç®¡çå¤æ¨¡æåå¥½è³æï¼(1) åççå¹»è¦ºééç®æ¨ Med-LVLMs æ GPT-4o æ³¨å¥ï¼ä»¥ç¢çé«å­¸ä¸ä¸æºç¢ºçåæï¼ä»¥å (2) ééå±é¨çç¶éè¨å¯¦ç¾çç¶ååå¿½ç¥ï¼ç ´å£å°ééµååçè¦è¦ºçè§£ãç¶å¾ï¼æåæ ¹æä¾èªå¤å Med-LLMs åè¦è¦ºå·¥å·çåæ¸è¨ç®æ¯åç¯ä¾çè¨åºç¸éæ§ï¼ä¸¦å°éäºåæ¸ä½çºæ¬éæ´åå°åå¥½æä½³åéç¨ä¸­ï¼ä»¥å¯¦ç¾ææå°é½ãæåçå¯¦é©è­æï¼MMedPO æé¡¯å¢å¼·äº Med-LVLMs ä¸­çäºå¯¦æºç¢ºæ§ï¼å¨ Med-VQA åå ±åçæä»»åä¸­ï¼å¹³ååå¥æ¯ç¾æçåå¥½æä½³åæ¹æ³æé«äº 14.2% å 51.7%ãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/aiming-lab/MMedPO ä¸­åå¾ã

##### **Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research**
2412.06018v1 by Akshat Choube, Rahul Majethia, Sohini Bhattacharya, Vedant Das Swain, Jiachen Li, Varun Mishra

Longitudinal passive sensing studies for health and behavior outcomes often
have missing and incomplete data. Handling missing data effectively is thus a
critical data processing and modeling step. Our formative interviews with
researchers working in longitudinal health and behavior passive sensing
revealed a recurring theme: most researchers consider imputation a low-priority
step in their analysis and inference pipeline, opting to use simple and
off-the-shelf imputation strategies without comprehensively evaluating its
impact on study outcomes. Through this paper, we call attention to the
importance of imputation. Using publicly available passive sensing datasets for
depression, we show that prioritizing imputation can significantly impact the
study outcomes -- with our proposed imputation strategies resulting in up to
31% improvement in AUROC to predict depression over the original imputation
strategy. We conclude by discussing the challenges and opportunities with
effective imputation in longitudinal sensing studies.

æè¦ï¼ç¸±åè¢«åææ¸¬ç ç©¶å°æ¼å¥åº·åè¡çºçµæå¸¸å¸¸æç¼ºå¤±åä¸å®æ´çè³æãææèçç¼ºå¤±è³æå æ­¤æ¯è³æèçåå»ºæ¨¡çéè¦æ­¥é©ãæåèå¾äºç¸±åå¥åº·åè¡çºè¢«åææ¸¬çç ç©¶äººå¡é²è¡çå½¢ææ§è¨ªè«æ­é²äºä¸ååè¦åºç¾çä¸»é¡ï¼å¤§å¤æ¸ç ç©¶äººå¡èªçºå§ææ¯å¶åæåæ¨è«æµç¨ä¸­åªåé åºè¼ä½çä¸åæ­¥é©ï¼é¸æä½¿ç¨ç°¡å®ä¸ç¾æçå§æç­ç¥ï¼èæ²æå¨é¢è©ä¼°å¶å°ç ç©¶çµæçå½±é¿ãéééç¯è«æï¼æåå¼ç±²éè¦å§æãä½¿ç¨å¬éçè¢«åææ¸¬è³æéé²è¡æé¬±çç ç©¶ï¼æåè­æåªåèæ®å§ææå°ç ç©¶çµæç¢çéå¤§å½±é¿ââæåæåºçå§æç­ç¥ä½¿ AUROC é æ¸¬æé¬±ççè½åæ¯åå§å§æç­ç¥æé«äº 31%ãæå¾ï¼æåè¨è«äºå¨ç¸±åææ¸¬ç ç©¶ä¸­ææå§æçææ°åæ©æã

##### **MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training**
2412.05876v1 by Xuefeng Ni, Linshan Wu, Jiaxin Zhuang, Qiong Wang, Mingxiang Wu, Varut Vardhanabhuti, Lihai Zhang, Hanyu Gao, Hao Chen

3D medical image analysis is pivotal in numerous clinical applications.
However, the scarcity of labeled data and limited generalization capabilities
hinder the advancement of AI-empowered models. Radiology reports are easily
accessible and can serve as weakly-supervised signals. However, large-scale
vision-language pre-training (VLP) remains underexplored in 3D medical image
analysis. Specifically, the insufficient investigation into multi-grained
radiology semantics and their correlations across patients leads to
underutilization of large-scale volume-report data.
  Considering intra-patient cross-modal semantic consistency and inter-patient
semantic correlations, we propose a multi-task VLP method, MG-3D, pre-trained
on large-scale data (47.1K), addressing the challenges by the following two
aspects: 1) Establishing the correspondence between volume semantics and
multi-grained medical knowledge of each patient with cross-modal global
alignment and complementary modality-guided local reconstruction, ensuring
intra-patient features of different modalities cohesively represent the same
semantic content; 2) Correlating inter-patient visual semantics based on
fine-grained report correlations across patients, and keeping sensitivity to
global individual differences via contrastive learning, enhancing the
discriminative feature representation. Furthermore, we delve into the scaling
law to explore potential performance improvements. Comprehensive evaluations
across nine uni- and cross-modal clinical tasks are carried out to assess model
efficacy. Extensive experiments on both internal and external datasets
demonstrate the superior transferability, scalability, and generalization of
MG-3D, showcasing its potential in advancing feature representation for 3D
medical image analysis. Code will be available:
https://github.com/Xuefeng-Ni/MG-3D.

æè¦ï¼<paragraph>3D é«å­¸å½±ååæå¨ç¾å¤è¨åºæç¨ä¸­è³ééè¦ã
ç¶èï¼æ¨è¨è³æçç¨ç¼ºåæéçæ¦åè½å
é»ç¤äº AI è³¦è½æ¨¡åçé²æ­¥ãæ¾å°å ±åå®¹æç²å¾ï¼å¯ä»¥ç¨ä½å¼±ç£ç£ä¿¡èãç¶èï¼å¤§è¦æ¨¡
è¦è¦ºèªè¨é è¨ç·´ (VLP) å¨ 3D é«å­¸å½±å
åæä¸­ä»æªå¾å°ååæ¢ç´¢ãå·é«ä¾èªªï¼å°å¤ç²åº¦
æ¾å°èªç¾©åå¶å¨æ£èä¹éçç¸éæ§ç ç©¶ä¸è¶³ï¼å°è´å¤§è¦æ¨¡é«ç©å ±åæ¸æå©ç¨ä¸è¶³ã
èæ®å°æ£èå§é¨è·¨æ¨¡æèªç¾©ä¸è´æ§åæ£èé
èªç¾©ç¸éæ§ï¼æåæåºäºä¸ç¨®å¤ä»»å VLP æ¹æ³ MG-3Dï¼é è¨ç·´
å¨å¤§åæ¸æ (47.1K) ä¸ï¼ééä»¥ä¸å©åæ¹é¢è§£æ±ºææ°ï¼1) å»ºç«é«ç©èªç¾©å
æ¯åæ£èçå¤ç²åº¦é«å­¸ç¥è­ä¹éçå°æéä¿ï¼ééè·¨æ¨¡æå¨å±
å°é½åäºè£æ¨¡æå¼å°çå±é¨éå»ºï¼ç¢ºä¿ä¸åæ¨¡æçæ£èå§é¨ç¹å¾µä¸è´å°è¡¨ç¤ºç¸åç
èªç¾©å§å®¹ï¼2) åºæ¼æ£èä¹éçç´°ç²åº¦å ±åç¸éæ§å°æ£èéçè¦è¦ºèªç¾©é²è¡éè¯ï¼ä¸¦ééå°æ¯å­¸ç¿ä¿æå°
å¨å±åé«å·®ç°çæææ§ï¼å¢å¼·å¤å¥ç¹å¾µè¡¨ç¤ºãæ­¤å¤ï¼æåæ·±å¥ç ç©¶äºæ´å±
å®å¾ä»¥æ¢ç´¢æ½å¨çæ§è½æ¹é²ãè·¨è¶ä¹é å®æ¨¡æåè·¨æ¨¡æè¨åºä»»åçç¶åè©ä¼°æ¯é²è¡çï¼ä»¥è©ä¼°æ¨¡å
æè½ãå¨å§é¨åå¤é¨æ¸æéä¸çå»£æ³å¯¦é©
è­æäº MG-3D çåè¶å¯å³éæ§ãå¯æ´å±æ§åæ³åæ§ï¼å±ç¤ºäºå¶å¨æ¨é² 3D
é«å­¸å½±ååæç¹å¾µè¡¨ç¤ºæ¹é¢çæ½åãä»£ç¢¼å°æä¾ï¼
https://github.com/Xuefeng-Ni/MG-3Dã</paragraph>

##### **Evolving Algebraic Multigrid Methods Using Grammar-Guided Genetic Programming**
2412.05852v1 by Dinesh Parthasarathy, Wayne Bradford Mitchell, Harald KÃ¶stler

Multigrid methods despite being known to be asymptotically optimal
algorithms, depend on the careful selection of their individual components for
efficiency. Also, they are mostly restricted to standard cycle types like V-,
F-, and W-cycles. We use grammar rules to generate arbitrary-shaped cycles,
wherein the smoothers and their relaxation weights are chosen independently at
each step within the cycle. We call this a flexible multigrid cycle. These
flexible cycles are used in Algebraic Multigrid (AMG) methods with the help of
grammar rules and optimized using genetic programming. The flexible AMG methods
are implemented in the software library of hypre, and the programs are
optimized separately for two cases: a standalone AMG solver for a 3D
anisotropic problem and an AMG preconditioner with conjugate gradient for a
multiphysics code. We observe that the optimized flexible cycles provide higher
efficiency and better performance than the standard cycle types.

æè¦ï¼å¤éç¶²æ ¼æ³åç®¡å·²ç¥çºæ¼¸è¿æä½³æ¼ç®æ³ï¼ä½å¶æçåæ±ºæ¼å¶åå¥çµæçä»ç´°é¸æãæ­¤å¤ï¼å®åå¤§å¤ä¾·éæ¼æ¨æºå¾ªç°é¡åï¼ä¾å¦ VãF å W å¾ªç°ãæåä½¿ç¨èªæ³è¦åä¾ç¢çä»»æå½¢ççå¾ªç°ï¼å¶ä¸­å¹³æ»å¨åå¶é¬å¼æ¬éå¨å¾ªç°ä¸­çæ¯åæ­¥é©ä¸­ç¨ç«é¸æãæåç¨±ä¹çºå½æ§å¤éç¶²æ ¼å¾ªç°ãéäºå½æ§å¾ªç°å¨ä»£æ¸å¤éç¶²æ ¼ (AMG) æ¹æ³ä¸­ä½¿ç¨ï¼ä¸¦å¨èªæ³è¦åçå¹«å©ä¸ä½¿ç¨éºå³ç¨å¼è¨­è¨é²è¡æä½³åãå½æ§ AMG æ¹æ³å¨ hypre çè»é«ç¨å¼åº«ä¸­å¯¦ä½ï¼ä¸ç¨å¼éå°å©ç¨®ææ³åå¥æä½³åï¼3D ç°åæ§åé¡çç¨ç« AMG æ±è§£å¨ï¼ä»¥åå¤ç©çå ´ç¨å¼ç¢¼çå±è»æ¢¯åº¦ AMG é èçå¨ãæåè§å¯å°æä½³åçå½æ§å¾ªç°æä¾æ¯æ¨æºå¾ªç°é¡åæ´é«çæçåæ´å¥½çæè½ã

##### **Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages**
2412.05632v1 by Abd Ur Rehman, Azka Rehman, Muhammad Usman, Abdullah Shahid, Sung-Min Gho, Aleum Lee, Tariq M. Khan, Imran Razzak

Brain aging involves structural and functional changes and therefore serves
as a key biomarker for brain health. Combining structural magnetic resonance
imaging (sMRI) and functional magnetic resonance imaging (fMRI) has the
potential to improve brain age estimation by leveraging complementary data.
However, fMRI data, being noisier than sMRI, complicates multimodal fusion.
Traditional fusion methods often introduce more noise than useful information,
which can reduce accuracy compared to using sMRI alone. In this paper, we
propose a novel multimodal framework for biological brain age estimation,
utilizing a sex-aware adversarial variational autoencoder (SA-AVAE). Our
framework integrates adversarial and variational learning to effectively
disentangle the latent features from both modalities. Specifically, we
decompose the latent space into modality-specific codes and shared codes to
represent complementary and common information across modalities, respectively.
To enhance the disentanglement, we introduce cross-reconstruction and
shared-distinct distance ratio loss as regularization terms. Importantly, we
incorporate sex information into the learned latent code, enabling the model to
capture sex-specific aging patterns for brain age estimation via an integrated
regressor module. We evaluate our model using the publicly available OpenBHB
dataset, a comprehensive multi-site dataset for brain age estimation. The
results from ablation studies and comparisons with state-of-the-art methods
demonstrate that our framework outperforms existing approaches and shows
significant robustness across various age groups, highlighting its potential
for real-time clinical applications in the early detection of neurodegenerative
diseases.

æè¦ï¼å¤§è¦èåæ¶åçµæ§ååè½çæ¹è®ï¼å æ­¤å¯ä½çºå¤§è¦å¥åº·çééµçç©æ¨è¨ãçµåçµæ§æ§ç£æ¯é å½± (sMRI) ååè½æ§ç£æ¯é å½± (fMRI) æå¯è½ééå©ç¨äºè£æ¸æä¾æ¹åå¤§è¦å¹´é½¡ä¼°è¨ãç¶èï¼fMRI è³ææ¯ sMRI éè¨æ´å¤ï¼éä½¿å¾å¤æ¨¡æèåè®å¾è¤éãå³çµ±èåæ¹æ³éå¸¸æå¼å¥æ¯æç¨è³è¨æ´å¤éè¨ï¼éå¯è½æéä½èå®ç¨ä½¿ç¨ sMRI ç¸æ¯çæºç¢ºæ§ãå¨æ¬æä¸­ï¼æåæåºä¸åç¨æ¼çç©å¤§è¦å¹´é½¡ä¼°è¨çæ°å¤æ¨¡ææ¡æ¶ï¼å©ç¨ä¸åææ§å¥æè­çå°æè®ç°èªåç·¨ç¢¼å¨ (SA-AVAE)ãæåçæ¡æ¶æ´åäºå°æåè®ç°å­¸ç¿ï¼ä»¥ææå°è§£éä¾èªå©ç¨®æ¨¡æçæ½å¨ç¹å¾µãå·é«èè¨ï¼æåå°æ½å¨ç©ºéåè§£çºç¹å®æ¼æ¨¡æçä»£ç¢¼åå±äº«ä»£ç¢¼ï¼åå¥è¡¨ç¤ºè·¨æ¨¡æçäºè£åå±åè³è¨ãçºäºå¢å¼·è§£éï¼æåå¼å¥äºäº¤åéå»ºåå±äº«ä¸åè·é¢æ¯çæå¤±ä½çºæ­£ååé ãéè¦çæ¯ï¼æåå°æ§å¥è³è¨ç´å¥å­¸ç¿å°çæ½å¨ä»£ç¢¼ä¸­ï¼ä½¿æ¨¡åè½å¤ ééæ´ååæ­¸æ¨¡çµï¼ææç¹å®æ¼æ§å¥çèåæ¨¡å¼ï¼ä»¥é²è¡å¤§è¦å¹´é½¡ä¼°è¨ãæåä½¿ç¨å¬éå¯ç¨ç OpenBHB è³æéè©ä¼°æåçæ¨¡åï¼éæ¯ä¸åç¨æ¼å¤§è¦å¹´é½¡ä¼°è¨çç¶åå¤å ´åè³æéãæ¶èç ç©¶åèæåé²æ¹æ³çæ¯è¼çµæè¡¨æï¼æåçæ¡æ¶åªæ¼ç¾ææ¹æ³ï¼ä¸¦å¨ååå¹´é½¡çµä¸­é¡¯ç¤ºåºé¡¯èçç©©å¥æ§ï¼çªé¡¯äºå¶å¨ç¥ç¶éåæ§ç¾çæ©ææª¢æ¸¬ä¸­çå³æè¨åºæç¨æ½åã

##### **UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation**
2412.05585v1 by Saba Hesaraki, Morteza Akbari, Ramin Mousa

Breast cancer stands as a prevalent cause of fatality among females on a
global scale, with prompt detection playing a pivotal role in diminishing
mortality rates. The utilization of ultrasound scans in the BUSI dataset for
medical imagery pertaining to breast cancer has exhibited commendable
segmentation outcomes through the application of UNet and UNet++ networks.
Nevertheless, a notable drawback of these models resides in their inattention
towards the temporal aspects embedded within the images. This research
endeavors to enrich the UNet++ architecture by integrating LSTM layers and
self-attention mechanisms to exploit temporal characteristics for segmentation
purposes. Furthermore, the incorporation of a Multiscale Feature Extraction
Module aims to grasp varied scale features within the UNet++. Through the
amalgamation of our proposed methodology with data augmentation on the BUSI
with GT dataset, an accuracy rate of 98.88%, specificity of 99.53%, precision
of 95.34%, sensitivity of 91.20%, F1-score of 93.74, and Dice coefficient of
92.74% are achieved. These findings demonstrate competitiveness with
cutting-edge techniques outlined in existing literature.

æè¦ï¼ä¹³çæ¯å¨çå¥³æ§æ­»äº¡çä¸»è¦åå ï¼åæ©ç¼ç¾å°æ¼éä½æ­»äº¡çæ®æ¼ééµè§è²ãå¨ BUSI è³æéä¸­ä½¿ç¨è¶é³æ³¢ææé²è¡ä¹³çç¸éçé«å­¸å½±åï¼ééæç¨ UNet å UNet++ ç¶²è·¯å·²å±ç¾åºä»¤äººæ»¿æçåå²çµæãç¶èï¼éäºæ¨¡åä¸åé¡¯èçç¼ºé»å¨æ¼å®åå¿½ç¥äºå½±åä¸­åå«çæéé¢åãæ¬ç ç©¶è´åæ¼ééæ´å LSTM å±¤åèªææ³¨ææ©å¶ä¾è±å¯ UNet++ æ¶æ§ï¼ä»¥å©ç¨æéç¹å¾µé²è¡åå²ãæ­¤å¤ï¼æ´åå¤å°ºåº¦ç¹å¾µèåæ¨¡çµæ¨å¨ææ¡ UNet++ ä¸­åç¨®å°ºåº¦çç¹å¾µãééå°æåæåºçæ¹æ³è BUSI with GT è³æéä¸çè³ææ´åçµåï¼éå°äº 98.88% çæºç¢ºçã99.53% çç¹ç°æ§ã95.34% çç²¾ç¢ºåº¦ã91.20% çææåº¦ã93.74 ç F1 åæ¸ï¼ä»¥å 92.74% ç Dice ä¿æ¸ãéäºç¼ç¾è­æäºèç¾ææç»ä¸­æ¦è¿°çå°ç«¯æè¡å·æç«¶ç­åã

##### **Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms**
2412.05583v2 by Atit Pokharel, Shashank Dahal, Pratik Sapkota, Bhupendra Bimal Chhetri

The rapid advancements in Artificial Intelligence, specifically Machine
Learning (ML) and Deep Learning (DL), have opened new prospects in medical
sciences for improved diagnosis, prognosis, and treatment of severe health
conditions. This paper focuses on the development of an ML model with high
predictive accuracy to classify arrhythmic electrocardiogram (ECG) signals. The
ECG signals datasets utilized in this study were sourced from the PhysioNet and
MIT-BIH databases. The research commenced with binary classification, where an
optimized Bidirectional Long Short-Term Memory (Bi-LSTM) model yielded
excellent results in differentiating normal and atrial fibrillation signals. A
pivotal aspect of this research was a survey among medical professionals, which
not only validated the practicality of AI-based ECG classifiers but also
identified areas for improvement, including accuracy and the inclusion of more
arrhythmia types. These insights drove the development of an advanced
Convolutional Neural Network (CNN) system capable of classifying five different
types of ECG signals with better accuracy and precision. The CNN model's robust
performance was ensured through rigorous stratified 5-fold cross validation. A
web portal was also developed to demonstrate real-world utility, offering
access to the trained model for real-time classification. This study highlights
the potential applications of such models in remote health monitoring,
predictive healthcare, assistive diagnostic tools, and simulated environments
for educational training and interdisciplinary collaboration between data
scientists and medical personnel.

æè¦ï¼äººå·¥æºæ§çå¿«éé²å±ï¼ç¹å¥æ¯æ©å¨å­¸ç¿ï¼MLï¼åæ·±åº¦å­¸ç¿ï¼DLï¼ï¼çºé«å­¸ç§å­¸éé¢äºæ°çåæ¯ï¼ä»¥æ¹åå´éå¥åº·çæ³çè¨ºæ·ãé å¾åæ²»çãæ¬æéé»å¨æ¼éç¼å·æé«é æ¸¬ç²¾åº¦ç ML æ¨¡åï¼ç¨æ¼åé¡å¿å¾ä¸æ´å¿é»å (ECG) ä¿¡èãæ¬ç ç©¶ä¸­ä½¿ç¨ç ECG ä¿¡èè³æéä¾èª PhysioNet å MIT-BIH è³æåº«ãç ç©¶å¾äºååé¡éå§ï¼å¶ä¸­ç¶éæä½³åçéåé·ç­æè¨æ¶ (Bi-LSTM) æ¨¡åå¨ååæ­£å¸¸åå¿æ¿é¡«åä¿¡èæ¹é¢ç¢çäºæ¥µä½³ççµæãæ¬ç ç©¶çä¸åééµæ¹é¢æ¯éå°é«è­·å°æ¥­äººå¡é²è¡çèª¿æ¥ï¼éä¸åé©è­äºåºæ¼ AI ç ECG åé¡å¨çå¯¦ç¨æ§ï¼éæ¾åºæ¹é²é åï¼åæ¬æºç¢ºæ§åç´å¥æ´å¤å¿å¾ä¸æ´é¡åãéäºè¦è§£æ¨åäºåé²å·ç©ç¥ç¶ç¶²è·¯ (CNN) ç³»çµ±çéç¼ï¼è©²ç³»çµ±è½å¤ ä»¥æ´é«çæºç¢ºåº¦åç²¾ç¢ºåº¦å°äºç¨®é¡åç ECG ä¿¡èé²è¡åé¡ãééå´æ ¼çåå±¤ 5 åäº¤åé©è­ï¼ç¢ºä¿äº CNN æ¨¡åçå¼·å¥æè½ãééç¼äºä¸åç¶²è·¯å¥å£ç¶²ç«ä¾å±ç¤ºçå¯¦ä¸ççæç¨ï¼æä¾å­åå·²è¨ç·´æ¨¡åä»¥é²è¡å³æåé¡ãæ¬ç ç©¶å¼·èª¿äºæ­¤é¡æ¨¡åå¨é è·å¥åº·ç£æ¸¬ãé æ¸¬æ§é«çä¿å¥ãè¼å©è¨ºæ·å·¥å·ä»¥åç¨æ¼æè²è¨ç·´åè³æç§å­¸å®¶èé«è­·äººå¡ä¹éè·¨é ååä½çæ¨¡æ¬ç°å¢ä¸­çæ½å¨æç¨ã

##### **Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison**
2412.05536v1 by Cailian Ruan, Chengyue Huang, Yahe Yang

This study introduces an evaluation framework for multimodal models in
medical imaging diagnostics. We developed a pipeline incorporating data
preprocessing, model inference, and preference-based evaluation, expanding an
initial set of 500 clinical cases to 3,000 through controlled augmentation. Our
method combined medical images with clinical observations to generate
assessments, using Claude 3.5 Sonnet for independent evaluation against
physician-authored diagnoses. The results indicated varying performance across
models, with Llama 3.2-90B outperforming human diagnoses in 85.27% of cases. In
contrast, specialized vision models like BLIP2 and Llava showed preferences in
41.36% and 46.77% of cases, respectively. This framework highlights the
potential of large multimodal models to outperform human diagnostics in certain
tasks.

æè¦ï¼æ¬ç ç©¶å¼å¥äºä¸åç¨æ¼é«çå½±åè¨ºæ·ä¸­å¤æ¨¡ææ¨¡åçè©ä¼°æ¡æ¶ãæåéç¼äºä¸åçµåäºè³æåèçãæ¨¡åæ¨è«ååºæ¼åå¥½çè©ä¼°çç®¡éï¼ééåæ§æ´åå°æåç 500 åè¨åºæ¡ä¾æ´åå° 3,000 åãæåçåæ³çµåäºé«å­¸å½±ååè¨åºè§å¯ï¼ä»¥ç¢çè©ä¼°ï¼ä½¿ç¨ Claude 3.5 Sonnet å°æé«å¸«æ°å¯«çè¨ºæ·é²è¡ç¨ç«è©ä¼°ãçµæé¡¯ç¤ºä¸åæ¨¡åçè¡¨ç¾ä¸åï¼å¶ä¸­ Llama 3.2-90B å¨ 85.27% çæ¡ä¾ä¸­åªæ¼äººé¡è¨ºæ·ãç¸æ¯ä¹ä¸ï¼å°éçè¦è¦ºæ¨¡åï¼ä¾å¦ BLIP2 å Llavaï¼åå¥å¨ 41.36% å 46.77% çæ¡ä¾ä¸­é¡¯ç¤ºåºåå¥½ãæ­¤æ¡æ¶çªé¡¯äºå¤§åå¤æ¨¡ææ¨¡åå¨æäºä»»åä¸­åªæ¼äººé¡è¨ºæ·çæ½åã

##### **Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System**
2412.06828v1 by Fang Zeng, Zhiliang Lyu, Quanzheng Li, Xiang Li

This study introduces "RadCouncil," a multi-agent Large Language Model (LLM)
framework designed to enhance the generation of impressions in radiology
reports from the finding section. RadCouncil comprises three specialized
agents: 1) a "Retrieval" Agent that identifies and retrieves similar reports
from a vector database, 2) a "Radiologist" Agent that generates impressions
based on the finding section of the given report plus the exemplar reports
retrieved by the Retrieval Agent, and 3) a "Reviewer" Agent that evaluates the
generated impressions and provides feedback. The performance of RadCouncil was
evaluated using both quantitative metrics (BLEU, ROUGE, BERTScore) and
qualitative criteria assessed by GPT-4, using chest X-ray as a case study.
Experiment results show improvements in RadCouncil over the single-agent
approach across multiple dimensions, including diagnostic accuracy, stylistic
concordance, and clarity. This study highlights the potential of utilizing
multiple interacting LLM agents, each with a dedicated task, to enhance
performance in specialized medical tasks and the development of more robust and
adaptable healthcare AI solutions.

æè¦ï¼æ¬ç ç©¶å¼å¥äºãRadCouncilãï¼ä¸åå¤éä»£çå¤§åèªè¨æ¨¡å (LLM)
æ¡æ¶ï¼æ¨å¨å¢å¼·æ¾å°ç§å ±åä¸­å°è±¡çç¢çï¼ç¹å¥æ¯ç¼ç¾é¨åãRadCouncil åå«ä¸åå°éçä»£çï¼1) ä¸åãæª¢ç´¢ãä»£çï¼ç¨æ¼è­å¥ä¸¦å¾åéè³æåº«ä¸­æª¢ç´¢é¡ä¼¼çå ±åï¼2) ä¸åãæ¾å°ç§é«å¸«ãä»£çï¼ç¨æ¼æ ¹æçµ¦å®å ±åçç¼ç¾é¨åå ä¸æª¢ç´¢ä»£çæª¢ç´¢å°çç¯ä¾å ±åï¼ç¢çå°è±¡ï¼ä»¥å 3) ä¸åãå¯©æ¥èãä»£çï¼ç¨æ¼è©ä¼°ç¢ççå°è±¡ä¸¦æä¾åé¥ãRadCouncil çæè½ä½¿ç¨éåææ¨ (BLEUãROUGEãBERTScore) é²è¡è©ä¼°ï¼ä¸¦ä½¿ç¨è¸é¨ X åä½çºæ¡ä¾ç ç©¶ï¼ç± GPT-4 è©ä¼°è³ªåæ¨æºãå¯¦é©çµæé¡¯ç¤ºï¼RadCouncil å¨å¤åé¢åé½ææ¹é²ï¼åæ¬è¨ºæ·æºç¢ºæ§ãé¢¨æ ¼ä¸è´æ§ï¼ä»¥åæ¸æ°åº¦ï¼åªæ¼å®ä¸ä»£çæ¹æ³ãæ¬ç ç©¶å¼·èª¿äºå©ç¨å¤åäºåå¼ LLM ä»£ççæ½åï¼æ¯åä»£çé½æå°éçä»»åï¼ä»¥å¢å¼·å¨å°æ¥­é«çä»»åä¸­çæè½ï¼ä¸¦éç¼æ´å¼·å¥ä¸é©ææ§æ´å¼·çé«çä¿å¥ AI è§£æ±ºæ¹æ¡ã

##### **Enhancing FKG.in: automating Indian food composition analysis**
2412.05248v2 by Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Geeta Trilok-Kumar, Ramesh Jain

This paper presents a novel approach to compute food composition data for
Indian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The
primary focus is to provide a broad overview of an automated food composition
analysis workflow and describe its core functionalities: nutrition data
aggregation, food composition analysis, and LLM-augmented information
resolution. This workflow aims to complement FKG.in and iteratively supplement
food composition data from verified knowledge bases. Additionally, this paper
highlights the challenges of representing Indian food and accessing food
composition data digitally. It also reviews three key sources of food
composition data: the Indian Food Composition Tables, the Indian Nutrient
Databank, and the Nutritionix API. Furthermore, it briefly outlines how users
can interact with the workflow to obtain diet-based health recommendations and
detailed food composition information for numerous recipes. We then explore the
complex challenges of analyzing Indian recipe information across dimensions
such as structure, multilingualism, and uncertainty as well as present our
ongoing work on LLM-based solutions to address these issues. The methods
proposed in this workshop paper for AI-driven knowledge curation and
information resolution are application-agnostic, generalizable, and replicable
for any domain.

æè¦ï¼æ¬ææåºäºä¸ååµæ°çæ¹æ³ï¼ä½¿ç¨å°åº¦é£åç¥è­åè­ (FKG.in) å LLM ä¾è¨ç®å°åº¦é£è­çé£åæåæ¸æãä¸»è¦éé»æ¯æä¾èªååé£åæååæå·¥ä½æµç¨çå»£æ³æ¦è¿°ï¼ä¸¦æè¿°å¶æ ¸å¿åè½ï¼çé¤æ¸æå½ç¸½ãé£åæååæå LLM å¢å¼·çä¿¡æ¯è§£æãæ­¤å·¥ä½æµç¨æ¨å¨è£å FKG.inï¼ä¸¦åè¦è£åä¾èªé©è­ç¥è­åº«çé£åæåæ¸æãæ­¤å¤ï¼æ¬æéé»ä»ç´¹äºè¡¨ç¤ºå°åº¦é£ååä»¥æ¸ä½æ¹å¼å­åé£åæåæ¸æçææ°ãå®éåé¡§äºé£åæåæ¸æçä¸åééµä¾æºï¼å°åº¦é£åæåè¡¨ãå°åº¦çé¤è³æåº«å Nutritionix APIãæ­¤å¤ï¼å®ç°¡è¦æ¦è¿°äºä½¿ç¨èå¦ä½èå·¥ä½æµç¨äºåä»¥ç²å¾åºæ¼é£²é£çå¥åº·å»ºè­°åå¤§éé£è­çè©³ç´°é£åæåè³è¨ãç¶å¾ï¼æåæ¢è¨äºåæå°åº¦é£è­è³è¨å¨çµæ§ãå¤èªè¨åä¸ç¢ºå®æ§ç­æ¹é¢çè¤éææ°ï¼ä¸¦å±ç¤ºæåå¨åºæ¼ LLM çè§£æ±ºæ¹æ¡ä¸é²è¡çæçºå·¥ä½ï¼ä»¥è§£æ±ºéäºåé¡ãæ¬æç è¨æè«æä¸­æåºç AI é©åç¥è­ç­å±åè³è¨è§£ææ¹æ³èæç¨ç¨å¼ç¡éï¼å¯æ¦æ¬ä¸å¯è¤è£½å°ä»»ä½é åã

##### **Are Frontier Large Language Models Suitable for Q&A in Science Centres?**
2412.05200v1 by Jacob Watson, FabrÃ­cio GÃ³es, Marco Volpe, Talles Medeiros

This paper investigates the suitability of frontier Large Language Models
(LLMs) for Q&A interactions in science centres, with the aim of boosting
visitor engagement while maintaining factual accuracy. Using a dataset of
questions collected from the National Space Centre in Leicester (UK), we
evaluated responses generated by three leading models: OpenAI's GPT-4, Claude
3.5 Sonnet, and Google Gemini 1.5. Each model was prompted for both standard
and creative responses tailored to an 8-year-old audience, and these responses
were assessed by space science experts based on accuracy, engagement, clarity,
novelty, and deviation from expected answers. The results revealed a trade-off
between creativity and accuracy, with Claude outperforming GPT and Gemini in
both maintaining clarity and engaging young audiences, even when asked to
generate more creative responses. Nonetheless, experts observed that higher
novelty was generally associated with reduced factual reliability across all
models. This study highlights the potential of LLMs in educational settings,
emphasizing the need for careful prompt engineering to balance engagement with
scientific rigor.

æè¦ï¼éç¯è«ææ¢è¨åæ²¿å¤§åèªè¨æ¨¡å (LLM) å¨ç§å­¸ä¸­å¿åç­äºåä¸­çé©ç¨æ§ï¼ç®çæ¯å¨ç¶­æäºå¯¦æºç¢ºæ§çåææåè¨ªå®¢åèåº¦ãæåä½¿ç¨å¾è±åèæ¯ç¹åå®¶å¤ªç©ºä¸­å¿æ¶éçæåè³æéï¼è©ä¼°äºä¸åé åæ¨¡åçæçåæï¼OpenAI ç GPT-4ãClaude 3.5 Sonnet å Google Gemini 1.5ãæ¯åæ¨¡åé½è¢«æç¤ºéå° 8 æ­²çåç¾éèº«æé æ¨æºåæåµæçåæï¼èéäºåæåç±å¤ªç©ºç§å­¸å°å®¶æ ¹ææºç¢ºæ§ãåèåº¦ãæ¸æ°åº¦ãæ°ç©æ§åèé æç­æ¡çåå·®é²è¡è©ä¼°ãçµæé¡¯ç¤ºåµé åèæºç¢ºæ§ä¹éå­å¨æ¬è¡¡ï¼Claude å¨ç¶­ææ¸æ°åº¦åå¸å¼å¹´è¼åç¾æ¹é¢åªæ¼ GPT å Geminiï¼å³ä½¿è¢«è¦æ±ç¢çæ´å¤æåµæçåæãåç®¡å¦æ­¤ï¼å°å®¶åè§å¯å°ï¼æææ¨¡åä¸­è¼é«çæ°ç©æ§éå¸¸èè¼ä½çå¯¦éå¯é æ§ç¸éãéé ç ç©¶å¼·èª¿äº LLM å¨æè²ç°å¢ä¸­çæ½åï¼ä¸¦å¼·èª¿éè¦ä»ç´°æç¤ºå·¥ç¨ä»¥å¹³è¡¡åèåº¦åç§å­¸å´è¬¹æ§ã

##### **SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**
2412.05187v1 by Jinlin Wu, Xusheng Liang, Xuexue Bai, Zhen Chen

Surgical interventions, particularly in neurology, represent complex and
high-stakes scenarios that impose substantial cognitive burdens on surgical
teams. Although deliberate education and practice can enhance cognitive
capabilities, surgical training opportunities remain limited due to patient
safety concerns. To address these cognitive challenges in surgical training and
operation, we propose SurgBox, an agent-driven sandbox framework to
systematically enhance the cognitive capabilities of surgeons in immersive
surgical simulations. Specifically, our SurgBox leverages large language models
(LLMs) with tailored Retrieval-Augmented Generation (RAG) to authentically
replicate various surgical roles, enabling realistic training environments for
deliberate practice. In particular, we devise Surgery Copilot, an AI-driven
assistant to actively coordinate the surgical information stream and support
clinical decision-making, thereby diminishing the cognitive workload of
surgical teams during surgery. By incorporating a novel Long-Short Memory
mechanism, our Surgery Copilot can effectively balance immediate procedural
assistance with comprehensive surgical knowledge. Extensive experiments using
real neurosurgical procedure records validate our SurgBox framework in both
enhancing surgical cognitive capabilities and supporting clinical
decision-making. By providing an integrated solution for training and
operational support to address cognitive challenges, our SurgBox framework
advances surgical education and practice, potentially transforming surgical
outcomes and healthcare quality. The code is available at
https://github.com/franciszchen/SurgBox.

æè¦ï¼å¤ç§æè¡ï¼ç¹å¥æ¯å¨ç¥ç¶å¤ç§ï¼ä»£è¡¨äºè¤éä¸é«é¢¨éªçå ´æ¯ï¼å°å¤ç§åéæ½å äºå·¨å¤§çèªç¥è² æãåç®¡ç¶éæ·±æçæ®çæè²åå¯¦è¸å¯ä»¥å¢å¼·èªç¥è½åï¼ä½ç±æ¼æ£èå®å¨åé¡ï¼å¤ç§å¹è¨æ©æä»ç¶æéãçºäºæå°å¤ç§å¹è¨åæè¡ä¸­çéäºèªç¥ææ°ï¼æåæåºäº SurgBoxï¼ä¸åç±ä»£çé©åçæ²çæ¡æ¶ï¼ç¨æ¼ç³»çµ±å°å¢å¼·å¤ç§é«çå¨æ²æµ¸å¼å¤ç§æ¨¡æ¬ä¸­çèªç¥è½åãå·é«ä¾èªªï¼æåç SurgBox å©ç¨å¤§åèªè¨æ¨¡å (LLM) åéèº«å®å¶çæª¢ç´¢å¢å¼·çæ (RAG) ä¾çå¯¦å°è¤è£½åç¨®å¤ç§è§è²ï¼çºæ·±æçæ®çå¯¦è¸æä¾é¼ççå¹è¨ç°å¢ãç¹å¥æ¯ï¼æåè¨­è¨äºæè¡å¯é§é§ï¼ä¸åç± AI é©åçå©æï¼ç¨æ¼ä¸»ååèª¿å¤ç§ä¿¡æ¯æµä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼å¾èæ¸å°å¤ç§åéå¨æè¡æéçèªç¥è² æãééçµåä¸ç¨®æ°ç©çé·ç­æè¨æ¶æ©å¶ï¼æåç Surgery Copilot å¯ä»¥ææå°å¹³è¡¡å³æç¨åºåå©åå¨é¢çå¤ç§ç¥è­ãä½¿ç¨çå¯¦çç¥ç¶å¤ç§æè¡è¨éé²è¡çå»£æ³å¯¦é©é©è­äºæåç SurgBox æ¡æ¶ï¼æ¢è½å¢å¼·å¤ç§èªç¥è½åï¼åè½æ¯æè¨åºæ±ºç­å¶å®ãééæä¾ä¸åç¶åçå¹è¨åéçæ¯æè§£æ±ºæ¹æ¡ä¾æå°èªç¥ææ°ï¼æåç SurgBox æ¡æ¶æ¨åäºå¤ç§æè²åå¯¦è¸ï¼æå¯è½æ¹è®å¤ç§çµæåé«çä¿å¥è³ªéãä»£ç¢¼å¯å¨ https://github.com/franciszchen/SurgBox ç²å¾ã

##### **Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**
2412.05013v1 by Thomas Sievers, Nele Russwinkel

Is it possible to integrate a humanoid social robot into the work processes
or customer care in an official environment, e.g. in municipal offices? If so,
what could such an application scenario look like and what skills would the
robot need to have when interacting with human customers? What are requirements
for this kind of interactions? We have devised an application scenario for such
a case, determined the necessary or desirable capabilities of the robot,
developed a corresponding robot application and carried out initial tests and
evaluations in a project together with the Kiel City Council. One of the most
important insights gained in the project was that a humanoid robot with natural
language processing capabilities based on large language models as well as
human-like gestures and posture changes (animations) proved to be much more
preferred by users compared to standard browser-based solutions on tablets for
an information system in the City Council. Furthermore, we propose a connection
of the ACT-R cognitive architecture with the robot, where an ACT-R model is
used in interaction with the robot application to cognitively process and
enhance a dialogue between human and robot.

æè¦ï¼æ¯å¦å¯è½å°é¡äººç¤¾ææ©å¨äººæ´åå°å·¥ä½æµç¨æå®æ¹ç°å¢ä¸­çå®¢æ¶æåä¸­ï¼ä¾å¦å¸æ¿è¾¦å¬å®¤ï¼å¦ææ¯éæ¨£ï¼éæ¨£çæç¨å ´æ¯å¯è½ææ¯ä»éº¼æ¨£å­ï¼èæ©å¨äººå¨èäººé¡å®¢æ¶äºåæéè¦å·ååªäºæè½ï¼éç¨®äºåæåªäºè¦æ±ï¼æåçºéç¨®ææ³è¨­è¨äºä¸åæç¨å ´æ¯ï¼ç¢ºå®äºæ©å¨äººå¿è¦æçæ³çè½åï¼éç¼äºä¸åå°æçæ©å¨äººæç¨ç¨å¼ï¼ä¸¦èåºç¾å¸è­°æå±åå¨ä¸åå°æ¡ä¸­é²è¡äºåæ­¥æ¸¬è©¦åè©ä¼°ãè©²å°æ¡ç²å¾çæéè¦è¦è§£ä¹ä¸æ¯ï¼èå¹³æ¿é»è¦ä¸ç¨æ¼å¸è­°æè³è¨ç³»çµ±çæ¨æºçè¦½å¨è§£æ±ºæ¹æ¡ç¸æ¯ï¼å·æäººå·¥èªè¨èçè½åï¼åºæ¼å¤§åèªè¨æ¨¡åï¼ä»¥åé¡äººçæå¢åå§¿å¢è®åï¼åç«ï¼çé¡äººæ©å¨äººè¢«ä½¿ç¨èæ´çºéçãæ­¤å¤ï¼æåå»ºè­°å° ACT-R èªç¥æ¶æ§èæ©å¨äººé£æ¥èµ·ä¾ï¼å¶ä¸­ ACT-R æ¨¡åç¨æ¼èæ©å¨äººæç¨ç¨å¼äºåï¼ä»¥èªç¥èçåå¢å¼·äººèæ©å¨äººä¹éçå°è©±ã

##### **Backdooring Outlier Detection Methods: A Novel Attack Approach**
2412.05010v1 by ZeinabSadat Taghavi, Hossein Mirzaei

There have been several efforts in backdoor attacks, but these have primarily
focused on the closed-set performance of classifiers (i.e., classification).
This has left a gap in addressing the threat to classifiers' open-set
performance, referred to as outlier detection in the literature. Reliable
outlier detection is crucial for deploying classifiers in critical real-world
applications such as autonomous driving and medical image analysis. First, we
show that existing backdoor attacks fall short in affecting the open-set
performance of classifiers, as they have been specifically designed to confuse
intra-closed-set decision boundaries. In contrast, an effective backdoor attack
for outlier detection needs to confuse the decision boundary between the closed
and open sets. Motivated by this, in this study, we propose BATOD, a novel
Backdoor Attack targeting the Outlier Detection task. Specifically, we design
two categories of triggers to shift inlier samples to outliers and vice versa.
We evaluate BATOD using various real-world datasets and demonstrate its
superior ability to degrade the open-set performance of classifiers compared to
previous attacks, both before and after applying defenses.

æè¦ï¼å°æ¼å¾éæ»æå·²ç¶æå¹¾é åªåï¼ä½éäºä¸»è¦éä¸­å¨åé¡å¨çééæè½ï¼å³åé¡ï¼ä¸ãéä½¿å¾å¨èçåé¡å¨éæ¾éæè½çå¨èä¸åºç¾äºä¸åç¼ºå£ï¼å¨æç»ä¸­ç¨±çºç°å¸¸å¼åµæ¸¬ãå¯é çç°å¸¸å¼åµæ¸¬å°æ¼å¨ééµççå¯¦ä¸çæç¨ä¸­é¨ç½²åé¡å¨è³ééè¦ï¼ä¾å¦èªåé§é§åé«å­¸å½±ååæãé¦åï¼æåå±ç¤ºç¾æçå¾éæ»æå¨å½±é¿åé¡å¨çéæ¾éæè½æ¹é¢ä¸è¶³ï¼å çºå®åè¢«ç¹å¥è¨­è¨ç¨ä¾æ··æ·ééå§æ±ºç­éçãç¸æ¯ä¹ä¸ï¼ææçç°å¸¸å¼åµæ¸¬å¾éæ»æéè¦æ··æ·ééåéæ¾éä¹éçæ±ºç­éçãæéæ¼æ­¤ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæåº BATODï¼ä¸ç¨®éå°ç°å¸¸å¼åµæ¸¬ä»»åçæ°åå¾éæ»æãå·é«ä¾èªªï¼æåè¨­è¨äºå©ç¨®é¡åçè§¸ç¼å¨ï¼å°å§é»æ¨£æ¬è½ç§»å°ç°å¸¸å¼ï¼åä¹äº¦ç¶ãæåä½¿ç¨åç¨®çå¯¦ä¸çè³æéè©ä¼° BATODï¼ä¸¦å±ç¤ºäºå®å¨éä½åé¡å¨çéæ¾éæè½æ¹é¢çåªç°è½åï¼èä¹åå¨æç¨é²ç¦¦æªæ½ä¹ååä¹å¾çæ»æç¸æ¯ã

##### **Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**
2412.04950v1 by Thomas Bartz-Beielstein, Axel Wellendorf, Noah PÃ¼tz, Jens Brandt, Alexander Hinterleitner, Richard Schulz, Richard Scholz, Olaf Mersmann, Robin Knabe

The increasing shortage of nursing staff and the acute risk of falls in
nursing homes pose significant challenges for the healthcare system. This study
presents the development of an automated fall detection system integrated into
care beds, aimed at enhancing patient safety without compromising privacy
through wearables or video monitoring. Mechanical vibrations transmitted
through the bed frame are processed using a short-time Fourier transform,
enabling robust classification of distinct human fall patterns with a
convolutional neural network. Challenges pertaining to the quantity and
diversity of the data are addressed, proposing the generation of additional
data with a specific emphasis on enhancing variation. While the model shows
promising results in distinguishing fall events from noise using lab data,
further testing in real-world environments is recommended for validation and
improvement. Despite limited available data, the proposed system shows the
potential for an accurate and rapid response to falls, mitigating health
implications, and addressing the needs of an aging population. This case study
was performed as part of the ZIM Project. Further research on sensors enhanced
by artificial intelligence will be continued in the ShapeFuture Project.

æè¦ï¼è­·çäººå¡æ¥çç­ç¼ºï¼ä¸è­·çä¹å®¶ç¼çè·åçé¢¨éªæ¥µé«ï¼å°é«çä¿å¥ç³»çµ±æ§æéå¤§ææ°ãæ¬ç ç©¶æåºå°èªååè·ååµæ¸¬ç³»çµ±æ´åè³è­·çåºï¼æ¨å¨æåçæ£å®å¨ï¼åæééç©¿æ´å¼è£ç½®æè¦è¨ç£æ§ä¾ä¿è­·é±ç§ãééåºæ¶å³éçæ©æ¢°æ¯åæä½¿ç¨ç­æè·åç«èè½æé²è¡èçï¼ä¸¦è½å©ç¨å·ç©ç¥ç¶ç¶²è·¯å°ä¸åäººé¡è·åæ¨¡å¼é²è¡ç©©å¥åé¡ãéå°è³ææ¸éåå¤æ¨£æ§çææ°ï¼æåºç¢çé¡å¤è³æçå»ºè­°ï¼ç¹å¥èéæ¼å¢å è®åæ§ãéç¶æ­¤æ¨¡åå¨ä½¿ç¨å¯¦é©å®¤è³æååè·åäºä»¶åéè¨æé¡¯ç¤ºåºæå¸æççµæï¼ä½å»ºè­°å¨çå¯¦ç°å¢ä¸­é²ä¸æ­¥æ¸¬è©¦ä»¥é²è¡é©è­åæ¹é²ãåç®¡å¯ç¨è³ææéï¼ä½ææåºçç³»çµ±é¡¯ç¤ºåºå°è·åäºä»¶ååºæºç¢ºä¸å¿«éçåæçæ½åï¼æ¸è¼å¥åº·å½±é¿ï¼ä¸¦æ»¿è¶³èé½¡åäººå£çéæ±ãæ­¤æ¡ä¾ç ç©¶æ¯ä½çº ZIM å°æ¡çä¸é¨åé²è¡çãShapeFuture å°æ¡å°æçºé²è¡äººå·¥æºæ§å¢å¼·ææ¸¬å¨çé²ä¸æ­¥ç ç©¶ã

##### **Estimating the treatment effect over time under general interference through deep learner integrated TMLE**
2412.04799v1 by Suhan Guo, Furao Shen, Ni Li

Understanding the effects of quarantine policies in populations with
underlying social networks is crucial for public health, yet most causal
inference methods fail here due to their assumption of independent individuals.
We introduce DeepNetTMLE, a deep-learning-enhanced Targeted Maximum Likelihood
Estimation (TMLE) method designed to estimate time-sensitive treatment effects
in observational data. DeepNetTMLE mitigates bias from time-varying confounders
under general interference by incorporating a temporal module and domain
adversarial training to build intervention-invariant representations. This
process removes associations between current treatments and historical
variables, while the targeting step maintains the bias-variance trade-off,
enhancing the reliability of counterfactual predictions. Using simulations of a
``Susceptible-Infected-Recovered'' model with varied quarantine coverages, we
show that DeepNetTMLE achieves lower bias and more precise confidence intervals
in counterfactual estimates, enabling optimal quarantine recommendations within
budget constraints, surpassing state-of-the-art methods.

æè¦ï¼äºè§£å·ææ½å¨ç¤¾äº¤ç¶²çµ¡çäººç¾¤ä¸­éé¢æ¿ç­çå½±é¿å°æ¼å¬å±è¡çè³ééè¦ï¼ä½ç±æ¼åè¨­åäººç¨ç«ï¼å¤§å¤æ¸å ææ¨è«æ¹æ³å¨æ­¤èå¤±æãæåå¼å¥äº DeepNetTMLEï¼éæ¯ä¸ç¨®æ·±åº¦å­¸ç¿å¢å¼·çç®æ¨æå¤§ä¼¼ç¶ä¼°è¨ (TMLE) æ¹æ³ï¼æ¨å¨ä¼°è¨è§æ¸¬æ¸æä¸­çæéææèçææãDeepNetTMLE ééæ´åæéæ¨¡çµåé åå°æè¨ç·´ä¾å»ºç«ä»å¥ä¸è®è¡¨ç¤ºï¼å¾èæ¸è¼ä¸è¬å¹²æ¾ä¸æè®æ··éå ç´ çåå·®ãæ­¤éç¨æ¶é¤äºç¶åèçèæ­·å²è®æ¸ä¹éçéè¯ï¼èç®æ¨è¨­å®æ­¥é©åç¶­æåå·®è®ç°æ¬è¡¡ï¼å¢å¼·åäºå¯¦é æ¸¬çå¯é æ§ãä½¿ç¨å·æä¸åéé¢è¦èççãææè-ææè-åº·å¾©èãæ¨¡åçæ¨¡æ¬ï¼æåè¡¨æ DeepNetTMLE å¨åäºå¯¦ä¼°è¨ä¸­å¯¦ç¾äºè¼ä½çåå·®åæ´ç²¾ç¢ºçä¿¡å¿åéï¼å¾èå¨é ç®éå¶å§å¯¦ç¾äºæä½³éé¢å»ºè­°ï¼è¶è¶äºæåé²çæ¹æ³ã

##### **Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**
2412.04792v1 by Mahfuzul Haque, Abu Saleh Musa Miah, Debashish Gupta, Md. Maruf Al Hossain Prince, Tanzina Alam, Nusrat Sharmin, Mohammed Sowket Ali, Jungpil Shin

Heart disease is a leading cause of premature death worldwide, particularly
among middle-aged and older adults, with men experiencing a higher prevalence.
According to the World Health Organization (WHO), non-communicable diseases,
including heart disease, account for 25\% (17.9 million) of global deaths, with
over 43,204 annual fatalities in Bangladesh. However, the development of heart
disease detection (HDD) systems tailored to the Bangladeshi population remains
underexplored due to the lack of benchmark datasets and reliance on manual or
limited-data approaches. This study addresses these challenges by introducing
new, ethically sourced HDD dataset, BIG-Dataset and CD dataset which
incorporates comprehensive data on symptoms, examination techniques, and risk
factors. Using advanced machine learning techniques, including Logistic
Regression and Random Forest, we achieved a remarkable testing accuracy of up
to 96.6\% with Random Forest. The proposed AI-driven system integrates these
models and datasets to provide real-time, accurate diagnostics and personalized
healthcare recommendations. By leveraging structured datasets and
state-of-the-art machine learning algorithms, this research offers an
innovative solution for scalable and effective heart disease detection, with
the potential to reduce mortality rates and improve clinical outcomes.

æè¦ï¼<paragraph>å¿èçæ¯å¨çéæ©æ­»äº¡çä¸»å ï¼ç¹å¥æ¯å¨ä¸­å¹´åèå¹´äººä¸­ï¼ç·æ§ç¼ççè¼é«ãæ ¹æä¸çè¡ççµç¹ (WHO) çæ¸æï¼åæ¬å¿èçå¨å§çéå³ææ§ç¾çå å¨çæ­»äº¡äººæ¸ç 25%ï¼1790 è¬ï¼ï¼å­å æåæ¯å¹´æè¶é 43,204 äººæ­»æ¼å¿èçãç¶èï¼ç±æ¼ç¼ºä¹åºæºæ¸æéåä¾è³´æåææ¸ææéçæ¹æ³ï¼éå°å­å æåäººå£éèº«æé çå¿èçæª¢æ¸¬ (HDD) ç³»çµ±çéç¼ä»æªå¾å°ååæ¢ç´¢ãæ¬ç ç©¶ééå¼å¥æ°çãç¬¦åéå¾·æ¨æºç HDD æ¸æéãBIG æ¸æéå CD æ¸æéä¾æå°éäºææ°ï¼å¶ä¸­åå«æéççãæª¢æ¥æè¡åé¢¨éªå ç´ çå¨é¢æ¸æãä½¿ç¨åé²çæ©å¨å­¸ç¿æè¡ï¼åæ¬éè¼¯è¿´æ­¸åé¨æ©æ£®æï¼æåä½¿ç¨é¨æ©æ£®æå¯¦ç¾äºé«é 96.6% çé¡¯èæ¸¬è©¦æºç¢ºåº¦ãææåºç AI é©åç³»çµ±æ´åäºéäºæ¨¡ååæ¸æéï¼ä»¥æä¾å¯¦æçæºç¢ºè¨ºæ·ååæ§åçé«çä¿å¥å»ºè­°ãééå©ç¨çµæ§åæ¸æéåæåé²çæ©å¨å­¸ç¿ç®æ³ï¼æ¬ç ç©¶çºå¯æ´å±ä¸ææçå¿èçæª¢æ¸¬æä¾äºä¸ååµæ°çè§£æ±ºæ¹æ¡ï¼å·æéä½æ­»äº¡çåæ¹åè¨åºçµæçæ½åã</paragraph>

##### **DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**
2412.04766v1 by Shadab Ahamed, Eldad Haber

Inverse problems, which involve estimating parameters from incomplete or
noisy observations, arise in various fields such as medical imaging,
geophysics, and signal processing. These problems are often ill-posed,
requiring regularization techniques to stabilize the solution. In this work, we
employ $\textit{Stochastic Interpolation}$ (SI), a generative framework that
integrates both deterministic and stochastic processes to map a simple
reference distribution, such as a Gaussian, to the target distribution. Our
method $\textbf{DAWN-SI}$: $\textbf{D}$ata-$\textbf{AW}$are and
$\textbf{N}$oise-informed $\textbf{S}$tochastic $\textbf{I}$nterpolation
incorporates data and noise embedding, allowing the model to access
representations about the measured data explicitly and also account for noise
in the observations, making it particularly robust in scenarios where data is
noisy or incomplete. By learning a time-dependent velocity field, SI not only
provides accurate solutions but also enables uncertainty quantification by
generating multiple plausible outcomes. Unlike pre-trained diffusion models,
which may struggle in highly ill-posed settings, our approach is trained
specifically for each inverse problem and adapts to varying noise levels. We
validate the effectiveness and robustness of our method through extensive
numerical experiments on tasks such as image deblurring and tomography.

æè¦ï¼ååé¡æ¶åå¾ä¸å®æ´ææéè¨çè§æ¸¬ä¸­ä¼°è¨åæ¸ï¼åºç¾å¨åç¨®é åï¼ä¾å¦é«å­¸å½±åãå°çç©çåè¨èèçãéäºåé¡éå¸¸æ¯ä¸é©å®çï¼éè¦æ­£ååæè¡ä¾ç©©å®è§£ãå¨éé å·¥ä½ä¸­ï¼æåæ¡ç¨é¨æ©æå¼ (SI)ï¼ä¸ç¨®çæå¼æ¶æ§ï¼æ´åç¢ºå®æ§åé¨æ©éç¨ï¼å°ç°¡å®çåèåä½ï¼ä¾å¦é«æ¯åä½ï¼å°æå°ç®æ¨åä½ãæåç DAWS-SI æ¹æ³ï¼è³ææç¥åéè¨ç¥æçé¨æ©æå¼ï¼çµåè³æåéè¨åµå¥ï¼è®æ¨¡åè½å¤ æç¢ºå­åéæ¼æ¸¬éè³æçè¡¨ç¤ºï¼ä¸¦èéè§æ¸¬ä¸­çéè¨ï¼ä½¿å¶å¨è³ææéè¨æä¸å®æ´çææ³ä¸ç¹å¥ç©©å¥ãééå­¸ç¿èæéç¸éçéåº¦å ´ï¼SI ä¸åæä¾ç²¾ç¢ºçè§£ï¼éè½ééç¢çå¤ååçççµæä¾éåä¸ç¢ºå®æ§ãèé åè¨ç·´çæ´æ£æ¨¡åä¸åï¼å¾èå¨é«åº¦ä¸é©å®çè¨­å®ä¸­å¯è½æéå°å°é£ï¼æåçåæ³æ¯éå°æ¯åååé¡é²è¡è¨ç·´ï¼ä¸¦é©æä¸åçéè¨ç­ç´ãæåééå»£æ³çæ¸å¼å¯¦é©é©è­äºæåæ¹æ³çæææ§åç©©å¥æ§ï¼éäºä»»ååæ¬å½±åå»æ¨¡ç³åæ·å±¤ææã

##### **PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**
2412.04714v1 by Hongjin Lin, Matthew Nazari, Derek Zheng

Reliable large-scale data on the state of forests is crucial for monitoring
ecosystem health, carbon stock, and the impact of climate change. Current
knowledge of tree species distribution relies heavily on manual data collection
in the field, which often takes years to complete, resulting in limited
datasets that cover only a small subset of the world's forests. Recent works
show that state-of-the-art deep learning models using Light Detection and
Ranging (LiDAR) images enable accurate and scalable classification of tree
species in various ecosystems. While LiDAR images contain rich 3D information,
most previous works flatten the 3D images into 2D projections to use
Convolutional Neural Networks (CNNs). This paper offers three significant
contributions: (1) we apply the deep learning framework for tree classification
in tropical savannas; (2) we use Airborne LiDAR images, which have a lower
resolution but greater scalability than Terrestrial LiDAR images used in most
previous works; (3) we introduce the approach of directly feeding 3D point
cloud images into a vision transformer model (PCTreeS). Our results show that
the PCTreeS approach outperforms current CNN baselines with 2D projections in
AUC (0.81), overall accuracy (0.72), and training time (~45 mins). This paper
also motivates further LiDAR image collection and validation for accurate
large-scale automatic classification of tree species.

æè¦ï¼å¯é çå¤§è¦æ¨¡æ£®æçæè³æå°æ¼ç£æ¸¬çæç³»çµ±å¥åº·ãç¢³å²éåæ°£åè®é·çå½±é¿è³ééè¦ãç®åå°æ¨¹ç¨®åå¸çäºè§£æ¥µåº¦ä¾è³´æ¼å¯¦å°æåæ¶éè³æï¼ééå¸¸éè¦è±è²»æ¸å¹´æè½å®æï¼å°è´åªè½æ¶µèå¨çå°æ¸æ£®æçæéè³æéãæè¿çç ç©¶é¡¯ç¤ºï¼ä½¿ç¨åæ¢æ¸¬åæ¸¬è· (LiDAR) å½±åçææ°æ·±åº¦å­¸ç¿æ¨¡åï¼å¯ä»¥å¨åç¨®çæç³»çµ±ä¸­å°æ¨¹ç¨®é²è¡æºç¢ºä¸å¯æ´åçåé¡ãåç®¡ LiDAR å½±ååå«è±å¯ç 3D è³è¨ï¼ä½å¤§å¤æ¸ååçç ç©¶æå° 3D å½±åå£ç¸®æ 2D æå½±ï¼ä»¥ä½¿ç¨å·ç©ç¥ç¶ç¶²è·¯ (CNN)ãæ¬ææä¾äºä¸é éè¦çè²¢ç»ï¼(1) æåå°æ·±åº¦å­¸ç¿æ¶æ§æç¨æ¼ç±å¸¶ç¨æ¨¹èåçæ¨¹ç¨®åé¡ï¼(2) æåä½¿ç¨æ©è¼ LiDAR å½±åï¼å¶è§£æåº¦è¼ä½ï¼ä½å¯æ´åæ§æ¯å¤§å¤æ¸ååç ç©¶ä¸­ä½¿ç¨çå°é¢ LiDAR å½±åæ´é«ï¼(3) æåå¼å¥äºç´æ¥å° 3D é»é²å½±åè¼¸å¥å°è¦è¦ºTransformeræ¨¡å (PCTreeS) çæ¹æ³ãæåççµæé¡¯ç¤ºï¼PCTreeS æ¹æ³å¨ AUC (0.81)ãæ´é«æºç¢ºåº¦ (0.72) åè¨ç·´æé (~45 åé) æ¹é¢åªæ¼ç¶åä½¿ç¨ 2D æå½±ç CNN åºæºãæ¬æä¹æ¿åµé²ä¸æ­¥æ¶éåé©è­ LiDAR å½±åï¼ä»¥é²è¡æºç¢ºçå¤§è¦æ¨¡æ¨¹ç¨®èªååé¡ã

##### **Semantic Consistency-Based Uncertainty Quantification for Factuality in Radiology Report Generation**
2412.04606v1 by Chenyu Wang, Weichao Zhou, Shantanu Ghosh, Kayhan Batmanghelich, Wenchao Li

Radiology report generation (RRG) has shown great potential in assisting
radiologists by automating the labor-intensive task of report writing. While
recent advancements have improved the quality and coherence of generated
reports, ensuring their factual correctness remains a critical challenge.
Although generative medical Vision Large Language Models (VLLMs) have been
proposed to address this issue, these models are prone to hallucinations and
can produce inaccurate diagnostic information. To address these concerns, we
introduce a novel Semantic Consistency-Based Uncertainty Quantification
framework that provides both report-level and sentence-level uncertainties.
Unlike existing approaches, our method does not require modifications to the
underlying model or access to its inner state, such as output token logits,
thus serving as a plug-and-play module that can be seamlessly integrated with
state-of-the-art models. Extensive experiments demonstrate the efficacy of our
method in detecting hallucinations and enhancing the factual accuracy of
automatically generated radiology reports. By abstaining from high-uncertainty
reports, our approach improves factuality scores by $10$%, achieved by
rejecting $20$% of reports using the Radialog model on the MIMIC-CXR dataset.
Furthermore, sentence-level uncertainty flags the lowest-precision sentence in
each report with an $82.9$% success rate.

æè¦ï¼æ¾å°ç§æ¥åçæ (RRG) å·²æ¾ç¤ºåºæå¤§çæ½åï¼å¯éè¿èªå¨æ§è¡æ¥åç¼åçå³å¨å¯éåä»»å¡æ¥åå©æ¾å°ç§å»çãè½ç¶æè¿çè¿æ­¥æé«äºçææ¥åçè´¨éåè¿è´¯æ§ï¼ä½ç¡®ä¿å¶äºå®æ­£ç¡®æ§ä»ç¶æ¯ä¸é¡¹éå¤§ææãå°½ç®¡å·²æåºçææ§å»å­¦è§è§å¤§è¯­è¨æ¨¡å (VLLM) æ¥è§£å³æ­¤é®é¢ï¼ä½è¿äºæ¨¡åå®¹æåºç°å¹»è§å¹¶å¯è½äº§çä¸åç¡®çè¯æ­ä¿¡æ¯ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å¼å¥äºä¸ä¸ªæ°é¢çåºäºè¯­ä¹ä¸è´æ§çä¸ç¡®å®æ§éåæ¡æ¶ï¼è¯¥æ¡æ¶æä¾æ¥åçº§åå¥å­çº§çä¸ç¡®å®æ§ãä¸ç°ææ¹æ³ä¸åï¼æä»¬çæ¹æ³ä¸éè¦ä¿®æ¹åºå±æ¨¡åæè®¿é®å¶åé¨ç¶æï¼ä¾å¦è¾åºæ è®° logitï¼ï¼å æ­¤å¯ç¨ä½å³æå³ç¨æ¨¡åï¼å¯ä»¥ä¸æåè¿çæ¨¡åæ ç¼éæãå¹¿æ³çå®éªè¡¨æäºæä»¬çæ¹æ³å¨æ£æµå¹»è§åæé«èªå¨çæçæ¾å°ç§æ¥åçäºå®åç¡®æ§æ¹é¢çåæãéè¿é¿åé«åº¦ä¸ç¡®å®çæ¥åï¼æä»¬çæ¹æ³å°çå®æ§å¾åæé«äº 10%ï¼è¿æ¯éè¿ä½¿ç¨ MIMIC-CXR æ°æ®éä¸ç Radialog æ¨¡åæç» 20% çæ¥åå®ç°çãæ­¤å¤ï¼å¥å­çº§ä¸ç¡®å®æ§æ è®°äºæ¯ä»½æ¥åä¸­ç²¾åº¦æä½çå¥å­ï¼æåçä¸º 82.9%ã

##### **CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations**
2412.04254v1 by Subash Neupane, Himanshu Tripathi, Shaswata Mitra, Sean Bozorgzad, Sudip Mittal, Shahram Rahimi, Amin Amirlatifi

This paper presents ClinicSum, a novel framework designed to automatically
generate clinical summaries from patient-doctor conversations. It utilizes a
two-module architecture: a retrieval-based filtering module that extracts
Subjective, Objective, Assessment, and Plan (SOAP) information from
conversation transcripts, and an inference module powered by fine-tuned
Pre-trained Language Models (PLMs), which leverage the extracted SOAP data to
generate abstracted clinical summaries. To fine-tune the PLM, we created a
training dataset of consisting 1,473 conversations-summaries pair by
consolidating two publicly available datasets, FigShare and MTS-Dialog, with
ground truth summaries validated by Subject Matter Experts (SMEs). ClinicSum's
effectiveness is evaluated through both automatic metrics (e.g., ROUGE,
BERTScore) and expert human assessments. Results show that ClinicSum
outperforms state-of-the-art PLMs, demonstrating superior precision, recall,
and F-1 scores in automatic evaluations and receiving high preference from SMEs
in human assessment, making it a robust solution for automated clinical
summarization.

æè¦ï¼æ¬æä»ç´¹ ClinicSumï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼æ¨å¨èªåå¾çæ£èé«å¸«çå°è©±ä¸­ç¢çè¨åºæè¦ãå®å©ç¨ä¸åéæ¨¡çµæ¶æ§ï¼ä¸ååºæ¼æª¢ç´¢çéæ¿¾æ¨¡çµï¼å¾å°è©±è½éä¸­èåä¸»è§ãå®¢è§ãè©ä¼°åè¨ç« (SOAP) è³è¨ï¼ä»¥åä¸åç±å¾®èª¿éä¹é åè¨ç·´èªè¨æ¨¡å (PLM) æä¾ååçæ¨è«æ¨¡çµï¼å®å©ç¨èåç SOAP è³æç¢çæè¦çè¨åºæè¦ãçºäºå¾®èª¿ PLMï¼æåå»ºç«äºä¸åè¨ç·´è³æéï¼å¶ä¸­åå« 1,473 çµå°è©±æè¦ï¼ééåä½µå©åå¬éå¯ç¨çè³æé FigShare å MTS-Dialogï¼ä»¥åç±ä¸»é¡å°å®¶ (SME) é©è­ççå¯¦æè¦ãClinicSum çæè½ééèªåè©éææ¨ (ä¾å¦ ROUGEãBERTScore) åå°å®¶äººé¡è©ä¼°é²è¡è©éãçµæé¡¯ç¤º ClinicSum åéç¾ææåé²ç PLMï¼å¨èªåè©éä¸­å±ç¾åºåªç°çç²¾ç¢ºåº¦ãå¬åçå F-1 åæ¸ï¼ä¸¦å¨äººé¡è©ä¼°ä¸­ç²å¾ SME çé«åº¦åå¥½ï¼ä½¿å¶æçºèªåè¨åºæè¦çå¼·å¥è§£æ±ºæ¹æ¡ã

##### **Automated Medical Report Generation for ECG Data: Bridging Medical Text and Signal Processing with Deep Learning**
2412.04067v1 by Amnon Bleich, Antje Linnemann, Bjoern H. Diem, Tim OF Conrad

Recent advances in deep learning and natural language generation have
significantly improved image captioning, enabling automated, human-like
descriptions for visual content. In this work, we apply these captioning
techniques to generate clinician-like interpretations of ECG data. This study
leverages existing ECG datasets accompanied by free-text reports authored by
healthcare professionals (HCPs) as training data. These reports, while often
inconsistent, provide a valuable foundation for automated learning. We
introduce an encoder-decoder-based method that uses these reports to train
models to generate detailed descriptions of ECG episodes. This represents a
significant advancement in ECG analysis automation, with potential applications
in zero-shot classification and automated clinical decision support.
  The model is tested on various datasets, including both 1- and 12-lead ECGs.
It significantly outperforms the state-of-the-art reference model by Qiu et
al., achieving a METEOR score of 55.53% compared to 24.51% achieved by the
reference model. Furthermore, several key design choices are discussed,
providing a comprehensive overview of current challenges and innovations in
this domain.
  The source codes for this research are publicly available in our Git
repository https://git.zib.de/ableich/ecg-comment-generation-public

æè¦ï¼æ·±åº¦å­¸ç¿åèªç¶èªè¨çææè¡çææ°é²å±é¡¯èæ¹åäºå½±åæ¨é¡ï¼è½çºè¦è¦ºå§å®¹æä¾èªååçäººé¡èªè¨æè¿°ãå¨éé å·¥ä½ä¸­ï¼æåå°éäºæ¨é¡æè¡æç¨æ¼ç¢çé¡ä¼¼è¨åºé«å¸«å°å¿é»åè³æçè©®éãéé ç ç©¶å©ç¨æ¢æçå¿é»åè³æéï¼ä¸¦éä¸ç±é«çä¿å¥å°æ¥­äººå¡ (HCP) æ°å¯«çèªç±æå­å ±åä½çºè¨ç·´è³æãéäºå ±åéç¶å¸¸å¸¸ä¸ä¸è´ï¼ä½çºèªååå­¸ç¿æä¾äºæå¹å¼çåºç¤ãæåå¼å¥äºä¸åç·¨ç¢¼å¨-è§£ç¢¼å¨æ¹æ³ï¼ä½¿ç¨éäºå ±åä¾è¨ç·´æ¨¡åï¼ä»¥ç¢çå¿é»åäºä»¶çè©³ç´°æè¿°ãéä»£è¡¨å¿é»ååæèªååçéå¤§é²å±ï¼å¨é¶æ¬¡å­¸ç¿åé¡åèªååè¨åºæ±ºç­æ¯æ´ä¸­å·ææ½å¨æç¨ãæ­¤æ¨¡åå¨åç¨®è³æéä¸é²è¡æ¸¬è©¦ï¼åæ¬ 1 å°ç¨å 12 å°ç¨å¿é»åãå®æé¡¯åªæ¼é±ç­äººçç¾ææä½³åèæ¨¡åï¼èåèæ¨¡åéæç 24.51% ç¸æ¯ï¼éå°äº 55.53% ç METEOR åæ¸ãæ­¤å¤ï¼è¨è«äºå¹¾åééµçè¨­è¨é¸æï¼æä¾äºå°éåé åä¸­ç¶åææ°ååµæ°çå¨é¢æ¦è¿°ãæ­¤ç ç©¶çåå§ç¨å¼ç¢¼å¨æåç Git å²å­åº« https://git.zib.de/ableich/ecg-comment-generation-public ä¸­å¬éã

##### **FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems**
2412.03851v1 by Jiechao Gao, Yuangang Li

Personalized medication aims to tailor healthcare to individual patient
characteristics. However, the heterogeneity of patient data across healthcare
systems presents significant challenges to achieving accurate and effective
personalized treatments. Ethical concerns further complicate the aggregation of
large volumes of data from diverse institutions. Federated Learning (FL) offers
a promising decentralized solution by enabling collaborative model training
through the exchange of client models rather than raw data, thus preserving
privacy. However, existing FL methods often suffer from retrogression during
server aggregation, leading to a decline in model performance in real-world
medical FL settings. To address data variability in distributed healthcare
systems, we introduce Federated Meta-Learning for Personalized Medication
(FedMetaMed), which combines federated learning and meta-learning to create
models that adapt to diverse patient data across healthcare systems. The
FedMetaMed framework aims to produce superior personalized models for
individual clients by addressing these limitations. Specifically, we introduce
Cumulative Fourier Aggregation (CFA) at the server to improve stability and
effectiveness in global knowledge aggregation. CFA achieves this by gradually
integrating client models from low to high frequencies. At the client level, we
implement a Collaborative Transfer Optimization (CTO) strategy with a
three-step process - Retrieve, Reciprocate, and Refine - to enhance the
personalized local model through seamless global knowledge transfer.
Experiments on real-world medical imaging datasets demonstrate that FedMetaMed
outperforms state-of-the-art FL methods, showing superior generalization even
on out-of-distribution cohorts.

æè¦ï¼åäººåé«çæ¨å¨éå°åå¥æ£èç¹å¾µèª¿æ´é«çä¿å¥ãç¶èï¼é«çç³»çµ±ä¸­æ£èè³æçç°è³ªæ§å°éææºç¢ºä¸ææçåäººåæ²»çå¸¶ä¾éå¤§ææ°ãå«çåé¡é²ä¸æ­¥ä½¿ä¾èªä¸åæ©æ§çå¤§éè³æçå½ç¸½è¤éåãè¯é¦å­¸ç¿ (FL) æä¾äºä¸ç¨®æåæ¯çåæ£å¼è§£æ±ºæ¹æ¡ï¼ééäº¤æå®¢æ¶æ¨¡åèéåå§è³æä¾å¯¦ç¾åä½æ¨¡åè¨ç·´ï¼å¾èä¿è­·é±ç§ãç¶èï¼ç¾æç FL æ¹æ³å¨ä¼ºæå¨å½ç¸½æéç¶å¸¸é­åéåï¼å°è´å¯¦éé«ç FL è¨­å®ä¸­çæ¨¡åæè½ä¸éãçºäºè§£æ±ºåæ£å¼é«çç³»çµ±ä¸­çè³æè®ç°æ§ï¼æåå¼å¥äºåäººåè¥ç©è¯é¦åå­¸ç¿ (FedMetaMed)ï¼å®çµåäºè¯é¦å­¸ç¿ååå­¸ç¿ä¾å»ºç«æ¨¡åï¼ä»¥é©æé«çç³»çµ±ä¸­ä¸åçæ£èè³æãFedMetaMed æ¡æ¶æ¨å¨ééè§£æ±ºéäºéå¶ï¼çºåå¥å®¢æ¶ç¢çåªè¶çåäººåæ¨¡åãå·é«ä¾èªªï¼æåå¨ä¼ºæå¨ç«¯å¼å¥äºç´¯ç©åç«èå½ç¸½ (CFA)ï¼ä»¥æ¹åå¨çç¥è­å½ç¸½çç©©å®æ§åæææ§ãCFA éééæ­¥æ´åå¾ä½é »çå°é«é »ççå®¢æ¶æ¨¡åä¾å¯¦ç¾éä¸é»ãå¨å®¢æ¶ç«¯å±¤ç´ï¼æåå¯¦æ½äºä¸ç¨®åä½å³è¼¸æä½³å (CTO) ç­ç¥ï¼æ¡ç¨ä¸æ­¥é©æµç¨ - æ·åãåé¥åç²¾ç - ééç¡ç¸«çå¨çç¥è­å³è¼¸ä¾å¢å¼·åäººåæ¬å°æ¨¡åãå¨å¯¦éé«çå½±åè³æéä¸çå¯¦é©è¡¨æï¼FedMetaMed åªæ¼æåé²ç FL æ¹æ³ï¼å³ä½¿å¨éåä½ç¾¤çµä¸­ä¹å±ç¾åºåªè¶çæ³åæ§ã

##### **ELEMENT: Episodic and Lifelong Exploration via Maximum Entropy**
2412.03800v1 by Hongming Li, Shujian Yu, Bin Liu, Jose C. Principe

This paper proposes \emph{Episodic and Lifelong Exploration via Maximum
ENTropy} (ELEMENT), a novel, multiscale, intrinsically motivated reinforcement
learning (RL) framework that is able to explore environments without using any
extrinsic reward and transfer effectively the learned skills to downstream
tasks. We advance the state of the art in three ways. First, we propose a
multiscale entropy optimization to take care of the fact that previous maximum
state entropy, for lifelong exploration with millions of state observations,
suffers from vanishing rewards and becomes very expensive computationally
across iterations. Therefore, we add an episodic maximum entropy over each
episode to speedup the search further. Second, we propose a novel intrinsic
reward for episodic entropy maximization named \emph{average episodic state
entropy} which provides the optimal solution for a theoretical upper bound of
the episodic state entropy objective. Third, to speed the lifelong entropy
maximization, we propose a $k$ nearest neighbors ($k$NN) graph to organize the
estimation of the entropy and updating processes that reduces the computation
substantially. Our ELEMENT significantly outperforms state-of-the-art intrinsic
rewards in both episodic and lifelong setups. Moreover, it can be exploited in
task-agnostic pre-training, collecting data for offline reinforcement learning,
etc.

æè¦ï¼æ¬ææåºäºä¸ç§æ°é¢çå¤å°ºåº¦ãåå¨å¨æºå¼ºåå­¦ä¹  (RL) æ¡æ¶ï¼åä¸ºâéè¿æå¤§çµè¿è¡ææ¯åç»èº«æ¢ç´¢â(ELEMENT)ï¼è¯¥æ¡æ¶è½å¤å¨ä¸ä½¿ç¨ä»»ä½å¤å¨å¥å±çæåµä¸æ¢ç´¢ç¯å¢ï¼å¹¶ææå°å°æå­¦æè½è½¬ç§»å°ä¸æ¸¸ä»»å¡ä¸­ãæä»¬å¨ä¸ä¸ªæ¹é¢æåäºææ¯æ°´å¹³ãé¦åï¼æä»¬æåºäºå¤å°ºåº¦çµä¼åï¼ä»¥è§£å³ä»¥ä¸äºå®ï¼ååçæå¤§ç¶æçµå¨è¿è¡æ°ç¾ä¸æ¬¡ç¶æè§å¯çç»èº«æ¢ç´¢æ¶ï¼ä¼é­åå¥å±æ¶å¤±çå½±åï¼å¹¶ä¸å¨æ¯æ¬¡è¿­ä»£ä¸­é½ä¼åå¾éå¸¸æè´µãå æ­¤ï¼æä»¬å¨æ¯ä¸ªææ¯ä¸­æ·»å äºä¸ä¸ªææ¯æå¤§çµï¼ä»¥è¿ä¸æ­¥å å¿«æç´¢éåº¦ãå¶æ¬¡ï¼æä»¬æåºäºä¸ç§æ°çåå¨å¥å±ï¼ç¨äºææ¯çµæå¤§åï¼åä¸ºâå¹³åææ¯ç¶æçµâï¼å®ä¸ºææ¯ç¶æçµç®æ ççè®ºä¸éæä¾äºæä¼è§£ãç¬¬ä¸ï¼ä¸ºäºå å¿«ç»èº«çµæå¤§åï¼æä»¬æåºäºä¸ä¸ª $k$ è¿é» ($k$NN) å¾ï¼ç¨äºç»ç»çµçä¼°è®¡åæ´æ°è¿ç¨ï¼ä»èå¤§å¹åå°äºè®¡ç®ãæä»¬ç ELEMENT å¨ææ¯åç»èº«è®¾ç½®ä¸­é½ææ¾ä¼äºæåè¿çåå¨å¥å±ãæ­¤å¤ï¼å®è¿å¯ä»¥ç¨äºä¸ä»»å¡æ å³çé¢è®­ç»ãæ¶éç¦»çº¿å¼ºåå­¦ä¹ æ°æ®ç­ã

##### **Automated Multi-Label Annotation for Mental Health Illnesses Using Large Language Models**
2412.03796v1 by Abdelrahaman A. Hassan, Radwa J. Hanafy, Mohammed E. Fouda

The growing prevalence and complexity of mental health disorders present
significant challenges for accurate diagnosis and treatment, particularly in
understanding the interplay between co-occurring conditions. Mental health
disorders, such as depression and Anxiety, often co-occur, yet current datasets
derived from social media posts typically focus on single-disorder labels,
limiting their utility in comprehensive diagnostic analyses. This paper
addresses this critical gap by proposing a novel methodology for cleaning,
sampling, labeling, and combining data to create versatile multi-label
datasets. Our approach introduces a synthetic labeling technique to transform
single-label datasets into multi-label annotations, capturing the complexity of
overlapping mental health conditions. To achieve this, two single-label
datasets are first merged into a foundational multi-label dataset, enabling
realistic analyses of co-occurring diagnoses. We then design and evaluate
various prompting strategies for large language models (LLMs), ranging from
single-label predictions to unrestricted prompts capable of detecting any
present disorders. After rigorously assessing multiple LLMs and prompt
configurations, the optimal combinations are identified and applied to label
six additional single-disorder datasets from RMHD. The result is SPAADE-DR, a
robust, multi-label dataset encompassing diverse mental health conditions. This
research demonstrates the transformative potential of LLM-driven synthetic
labeling in advancing mental health diagnostics from social media data, paving
the way for more nuanced, data-driven insights into mental health care.

æè¦ï¼é¨èå¿çå¥åº·éç¤ççè¡çåè¤éæ§æ¥çå¢å ï¼å°æ¼æºç¢ºè¨ºæ·åæ²»çæåºäºå´å³»çææ°ï¼ç¹å¥æ¯å¨äºè§£å±å­ç¾çä¹éçç¸äºä½ç¨æãå¿çå¥åº·éç¤ï¼ä¾å¦æé¬±çåç¦æ®çï¼ç¶å¸¸å±å­ï¼ä½ç®åå¾ç¤¾ç¾¤åªé«è²¼æä¸­è¡ççè³æééå¸¸åªéæ³¨å®ä¸éç¤æ¨ç±¤ï¼éå¶äºå®åå¨å¨é¢è¨ºæ·åæä¸­çæç¨ãæ¬æééæåºä¸ååµæ°çæ¹æ³ä¾æ¸çãæ½æ¨£ãæ¨ç±¤åçµåè³æï¼ä»¥å»ºç«å¤åè½çå¤æ¨ç±¤è³æéï¼ä¾è§£æ±ºéåééµçå·®è·ãæåçåæ³å¼é²äºä¸ç¨®åææ¨ç±¤æè¡ï¼å°å®æ¨ç±¤è³æéè½æçºå¤æ¨ç±¤è¨»è§£ï¼ææéçå¿çå¥åº·çæ³çè¤éæ§ãçºäºéæéåç®æ¨ï¼é¦åå°å©åå®æ¨ç±¤è³æéåä½µæä¸ååºç¤å¤æ¨ç±¤è³æéï¼ä»¥é²è¡å±å­è¨ºæ·çå¯¦éåæãç¶å¾ï¼æåè¨­è¨ä¸¦è©ä¼°å¤§åèªè¨æ¨¡å (LLM) çåç¨®æç¤ºç­ç¥ï¼å¾å®æ¨ç±¤é æ¸¬å°è½å¤ åµæ¸¬ä»»ä½ç¾æéç¤çç¡éå¶æç¤ºãå¨å´æ ¼è©ä¼°å¤å LLM åæç¤ºéç½®å¾ï¼æ¾åºæä½³çµåä¸¦æç¨æ¼æ¨ç±¤ä¾èª RMHD çå­åå¶ä»å®ä¸éç¤è³æéãçµææ¯ SPAADE-DRï¼ä¸ååå«åç¨®å¿çå¥åº·çæ³çå¼·å¥å¤æ¨ç±¤è³æéãéé ç ç©¶å±ç¤ºäº LLM é©åçåææ¨ç±¤å¨æ¨é²å¾ç¤¾ç¾¤åªé«è³æé²è¡å¿çå¥åº·è¨ºæ·çè½åæ½åï¼çºæ´ç´°ç·»ãè³æé©åçå¿çä¿å¥è¦è§£éªè·¯ã

##### **Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**
2412.03784v1 by Yerin Choi, Jeehyun Lee, Myoung-Wan Koo

Due to the subjective nature of current clinical evaluation, the need for
automatic severity evaluation in dysarthric speech has emerged. DNN models
outperform ML models but lack user-friendly explainability. ML models offer
explainable results at a feature level, but their performance is comparatively
lower. Current ML models extract various features from raw waveforms to predict
severity. However, existing methods do not encompass all dysarthric features
used in clinical evaluation. To address this gap, we propose a feature
extraction method that minimizes information loss. We introduce an ASR
transcription as a novel feature extraction source. We finetune the ASR model
for dysarthric speech, then use this model to transcribe dysarthric speech and
extract word segment boundary information. It enables capturing finer
pronunciation and broader prosodic features. These features demonstrated an
improved severity prediction performance to existing features: balanced
accuracy of 83.72%.

æè¦ï¼ç±æ¼ç¶åè¨åºè©ä¼°çä¸»è§æ§ï¼å æ­¤åºç¾äºå°æ§é³éç¤è¨èªä¸­èªåå´éç¨åº¦è©ä¼°çéæ±ãDNN æ¨¡ååªæ¼ ML æ¨¡åï¼ä½ç¼ºä¹ä½¿ç¨èååçå¯è§£éæ§ãML æ¨¡åå¨ç¹å¾µå±¤ç´æä¾å¯è§£éççµæï¼ä½å¶æè½ç¸å°è¼ä½ãç¶åç ML æ¨¡åå¾åå§æ³¢å½¢ä¸­æ·ååç¨®ç¹å¾µä»¥é æ¸¬å´éç¨åº¦ãç¶èï¼ç¾ææ¹æ³ä¸¦æªæ¶µèè¨åºè©ä¼°ä¸­ä½¿ç¨çæææ§é³éç¤ç¹å¾µãçºäºè§£æ±ºéåå·®è·ï¼æåæåºäºä¸ç¨®å¯å°è³è¨æå¤±éè³æä½çç¹å¾µæ·åæ¹æ³ãæåå¼å¥äº ASR è½éä½çºä¸ç¨®æ°ç©çç¹å¾µæ·åä¾æºãæåçºæ§é³éç¤è¨èªå¾®èª¿ ASR æ¨¡åï¼ç¶å¾ä½¿ç¨æ­¤æ¨¡åè½éæ§é³éç¤è¨èªä¸¦æ·åå­ååæ®µéçè³è¨ãå®å¯ä»¥æ·åæ´ç²¾ç´°çç¼é³åæ´å»£æ³çé»å¾ç¹å¾µãéäºç¹å¾µé¡¯ç¤ºåºæ¯ç¾æç¹å¾µæ´å¥½çå´éç¨åº¦é æ¸¬æè½ï¼å¹³è¡¡æºç¢ºåº¦çº 83.72%ã

##### **Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety**
2412.03740v1 by Dilan Mian

The world can be a complex and difficult place to navigate. People with
High-Functioning Autistic Spectrum Disorder as well as general social
ineptitude often face navigation challenges that individuals of other
demographics simply do not themselves. This can become even more pronounced
with people of that specific group when they are in their teenage years and
early adulthood (that being the usual age range of college students). When they
are at such a vulnerable age, they can be far more susceptible to the struggles
of becoming comfortable and content with social interactions as well as having
strong relationships (outside their immediate family). Concerning this, the
rapid emergence of artificial intelligence chatbots has led to many of them
being used to benefit people of different ages and demographics with easy
accessibility. With this, if there is anything that people with
High-Functioning ASD and social ineptitude want when it comes to guidance
towards self-improvement, surely easy accessibility would be one. What are the
potential benefits and limitations of using a Mindstudio AI-powered chatbot to
provide mental health support for teens and young adults with the
aforementioned conditions? What could be done with a tool like this to help
those individuals navigate ethical dilemmas within different social
environments to reduce existing social tensions? This paper addresses these
queries and offers insights to inform future discussions on the subject.

æè¦ï¼ä¸çå¯è½æ¯ä¸åè¤éä¸é£ä»¥æä»çå°æ¹ãé«åè½èªéçè­ç³»éç¤ä»¥åä¸è¬ç¤¾äº¤ç¡è½çäººï¼ç¶å¸¸æé¢å°å¶ä»äººå£çµ±è¨è³æä¸­çäººæ ¹æ¬ä¸æéå°çæå°ææ°ãç¶ä»åèæ¼éå°å¹´ææåæå¹´åæï¼éå¸¸æ¯å¤§å­¸ççå¹´é½¡ç¯åï¼æï¼éç¨®ææ³å¯è½æè®å¾æ´å æé¡¯ãç¶ä»åèæ¼å¦æ­¤èå¼±çå¹´é½¡æï¼ä»åæ´å®¹æåå°ç¤¾äº¤äºåæå°èªå¨åæ»¿è¶³çææï¼ä»¥åææç¢åºéä¿ï¼å¨ä»åçç´ç³»è¦ªå±¬ä¹å¤ï¼çå½±é¿ãéæ¼éä¸é»ï¼äººå·¥æºæ§èå¤©æ©å¨äººçå¿«éåºç¾ï¼å°è´è¨±å¤äººè¢«ç¨æ¼é ç¦ä¸åå¹´é½¡åäººå£çµ±è¨è³æçäººï¼ä¸¦å·æææ¼å­åæ§ãæäºéåï¼å¦ææ£æé«åè½èªéçåç¤¾äº¤ç¡è½çäººå¨èªææåçæå°æ¹é¢æä»»ä½æ³è¦çæ±è¥¿ï¼é£éº¼ææ¼å­åè¯å®ææ¯ä¸åãä½¿ç¨ç± Mindstudio AI æä¾æè¡æ¯æ´çèå¤©æ©å¨äººï¼çºæ£æä¸è¿°ææ³çéå°å¹´åå¹´è¼äººæä¾å¿çå¥åº·æ¯æ´ï¼æåªäºæ½å¨çå¥½èåéå¶ï¼å¯ä»¥ä½¿ç¨éæ¨£çå·¥å·ä¾å¹«å©é£äºäººæå°ä¸åç¤¾æç°å¢ä¸­çéå¾·å°å¢ï¼ä»¥æ¸å°ç¾æçç¤¾æç·å¼µå±å¢ï¼å¯ä»¥åäºä»éº¼ï¼æ¬ææ¢è¨éäºåé¡ï¼ä¸¦æä¾è¦è§£ï¼çºæªä¾éæ¼æ­¤ä¸»é¡çè¨è«æä¾è³è¨ã

##### **MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities**
2412.04106v1 by Haoning Wu, Ziheng Zhao, Ya Zhang, Weidi Xie, Yanfeng Wang

Medical image segmentation has recently demonstrated impressive progress with
deep neural networks, yet the heterogeneous modalities and scarcity of mask
annotations limit the development of segmentation models on unannotated
modalities. This paper investigates a new paradigm for leveraging generative
models in medical applications: controllably synthesizing data for unannotated
modalities, without requiring registered data pairs. Specifically, we make the
following contributions in this paper: (i) we collect and curate a large-scale
radiology image-text dataset, MedGen-1M, comprising modality labels,
attributes, region, and organ information, along with a subset of organ mask
annotations, to support research in controllable medical image generation; (ii)
we propose a diffusion-based data engine, termed MRGen, which enables
generation conditioned on text prompts and masks, synthesizing MR images for
diverse modalities lacking mask annotations, to train segmentation models on
unannotated modalities; (iii) we conduct extensive experiments across various
modalities, illustrating that our data engine can effectively synthesize
training samples and extend MRI segmentation towards unannotated modalities.

æè¦ï¼é«å­¸å½±ååå²æè¿å·²ééæ·±åº¦ç¥ç¶ç¶²è·¯å±ç¾é©äººçé²å±ï¼ä½ç°è³ªæ¨¡æåæ¨ç±¤ç¨å°éå¶äºå¨æªæ¨è¨»æ¨¡æä¸éç¼åå²æ¨¡åãæ¬ææ¢è¨äºä¸åæ°å¸ç¯ï¼ä»¥å©ç¨çææ¨¡åå¨é«å­¸æç¨ä¸­ï¼å¯æ§å°åææªæ¨è¨»æ¨¡æçè³æï¼èç¡éè¨»åè³æå°ãå·é«ä¾èªªï¼æåå¨æ¬æä¸­ååºä»¥ä¸è²¢ç»ï¼(i) æåæ¶éä¸¦ç­åäºä¸åå¤§è¦æ¨¡çæ¾å°å½±åæå­è³æé MedGen-1Mï¼åå«æ¨¡ææ¨ç±¤ãå±¬æ§ãåååå¨å®è³è¨ï¼ä»¥åä¸é¨åå¨å®æ¨ç±¤ï¼ä»¥æ¯æ´å¯æ§é«å­¸å½±åçæçç¸éç ç©¶ï¼(ii) æåæåºäºä¸ååºæ¼æ´æ£çè³æå¼æï¼ç¨±çº MRGenï¼å®è½å¤ æ ¹ææå­æç¤ºåæ¨ç±¤çææ¢ä»¶ï¼åæç¼ºä¹æ¨ç±¤è¨»è§£çä¸åæ¨¡æç MR å½±åï¼ä»¥è¨ç·´æªæ¨è¨»æ¨¡æçåå²æ¨¡åï¼(iii) æåå¨åç¨®æ¨¡æä¸­é²è¡äºå»£æ³çå¯¦é©ï¼èªªææåçè³æå¼æå¯ä»¥ææå°åæè¨ç·´æ¨£æ¬ï¼ä¸¦å° MRI åå²å»¶ä¼¸è³æªæ¨è¨»çæ¨¡æã

##### **Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**
2412.03352v1 by Yiqin Zhang, Qingkui Chen, Chen Huang, Zhengjie Zhang, Meiling Chen, Zhibing Fu

Most data-driven models for medical image analysis rely on universal
augmentations to improve performance. Experimental evidence has confirmed their
effectiveness, but the unclear mechanism underlying them poses a barrier to the
widespread acceptance and trust in such methods within the medical community.
We revisit and acknowledge the unique characteristics of medical images apart
from traditional digital images, and consequently, proposed a medical-specific
augmentation algorithm that is more elastic and aligns well with radiology scan
procedure. The method performs piecewise affine with sinusoidal distorted ray
according to radius on polar coordinates, thus simulating uncertain postures of
human lying flat on the scanning table. Our method could generate human
visceral distribution without affecting the fundamental relative position on
axial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal
and Similarity-Guided Parameter Search, are introduced to bolster robustness of
our augmentation method. Experiments show our method improves accuracy across
multiple famous segmentation frameworks without requiring more data samples.
Our preview code is available in: https://github.com/MGAMZ/PSBPD.

æè¦ï¼å¤§å¤æ¸ç¨æ¼é«å­¸å½±ååæçè³æé©åæ¨¡åä»°è³´éç¨æ´ååè½ä¾æåæè½ãå¯¦é©è­æå·²è­å¯¦å¶æææ§ï¼ä½å¶èå¾ä¸æç¢ºçæ©å¶å°é«å­¸çå»£æ³æ¥ååä¿¡ä»»æ­¤é¡æ¹æ³æ§æé»ç¤ãæåéæ°æª¢è¦ä¸¦æ¿èªé«å­¸å½±åèå³çµ±æ¸ä½å½±åçç¨ç¹ç¹æ§ï¼å æ­¤æåºæ´å·å½æ§ä¸èæ¾å°ç·ææç¨åºå¯åéåçé«å­¸ç¹å®æ´åæ¼ç®æ³ãè©²æ¹æ³æ ¹ææ¥µåº§æ¨ä¸çåå¾å·è¡æ­£å¼¦æ­æ²å°ç·çéæ®µä»¿å°ï¼å¾èæ¨¡æ¬äººå¹³èººå¨ææå°ä¸æçä¸ç¢ºå®å§¿å¢ãæåçæ¹æ³å¯ä»¥å¨ä¸å½±é¿è»¸åå¹³é¢ä¸åºæ¬ç¸å°ä½ç½®çææ³ä¸çæäººé«å§èåä½ãå¼å¥äºå©ç¨®éèªé©ææ¼ç®æ³ï¼å³åºæ¼ Meta çææå°ç§»é¤åç¸ä¼¼æ§å°å¼åæ¸æå°ï¼ä»¥å å¼·æåæ´åæ¹æ³çç©©å¥æ§ãå¯¦é©è¡¨æï¼æåçæ¼ç®æ³å¨ä¸éè¦æ´å¤è³ææ¨£æ¬çææ³ä¸ï¼å°±è½æåå¤åèååå²æ¶æ§çæºç¢ºæ§ãæåçé è¦½ç¨å¼ç¢¼å¯å¨ https://github.com/MGAMZ/PSBPD ä¸­åå¾ã

##### **Detecting abnormal heart sound using mobile phones and on-device IConNet**
2412.03267v1 by Linh Vu, Thu Tran

Given the global prevalence of cardiovascular diseases, there is a pressing
need for easily accessible early screening methods. Typically, this requires
medical practitioners to investigate heart auscultations for irregular sounds,
followed by echocardiography and electrocardiography tests. To democratize
early diagnosis, we present a user-friendly solution for abnormal heart sound
detection, utilizing mobile phones and a lightweight neural network optimized
for on-device inference. Unlike previous approaches reliant on specialized
stethoscopes, our method directly analyzes audio recordings, facilitated by a
novel architecture known as IConNet. IConNet, an Interpretable Convolutional
Neural Network, harnesses insights from audio signal processing, enhancing
efficiency and providing transparency in neural pattern extraction from raw
waveform signals. This is a significant step towards trustworthy AI in
healthcare, aiding in remote health monitoring efforts.

æè¦ï¼é´äºå¿è¡ç®¡ç¾çå¨å¨ççæ®éæ§ï¼è¿«åéè¦å®¹æè·åçæ©æç­æ¥æ¹æ³ãéå¸¸ï¼è¿éè¦å»çä»ä¸äººåæ£æ¥å¿èå¬è¯æ¯å¦æä¸è§åçå£°é³ï¼ç¶åè¿è¡è¶å£°å¿å¨å¾åå¿çµå¾æ£æ¥ãä¸ºäºä½¿æ©æè¯æ­æ°ä¸»åï¼æä»¬æåºäºä¸ç§ç¨æ·åå¥½çè§£å³æ¹æ¡ï¼ç¨äºæ£æµå¼å¸¸å¿èå£°é³ï¼å©ç¨ç§»å¨çµè¯åä¸ä¸ªè½»éçº§ç¥ç»ç½ç»ï¼è¯¥ç¥ç»ç½ç»éå¯¹è®¾å¤åæ¨çè¿è¡äºä¼åãä¸ä»¥åä¾èµäºä¸ç¨å¬è¯å¨çåæ³ä¸åï¼æä»¬çæ¹æ³ç´æ¥åæé³é¢è®°å½ï¼è¿å¾çäºä¸ç§ç§°ä¸º IConNet çæ°é¢æ¶æãIConNet æ¯ä¸ç§å¯è§£éçå·ç§¯ç¥ç»ç½ç»ï¼å©ç¨é³é¢ä¿¡å·å¤ççè§è§£ï¼æé«æçï¼å¹¶æä¾ä»åå§æ³¢å½¢ä¿¡å·ä¸­æåç¥ç»æ¨¡å¼çéææ§ãè¿æ¯æåå»çä¿å¥ä¸­å¯ä¿¡èµçäººå·¥æºè½è¿åºçéè¦ä¸æ­¥ï¼æå©äºè¿ç¨å¥åº·çæµå·¥ä½ã

##### **MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**
2412.03039v1 by Hyojeong Lee, Youngwan Jo, Inpyo Hong, Sanghyun Park

We propose a Multifaceted Resilient Network(MRNet), a novel architecture
developed for medical image-to-image translation that outperforms
state-of-the-art methods in MRI-to-CT and MRI-to-MRI conversion. MRNet
leverages the Segment Anything Model (SAM) to exploit frequency-based features
to build a powerful method for advanced medical image transformation. The
architecture extracts comprehensive multiscale features from diverse datasets
using a powerful SAM image encoder and performs resolution-aware feature fusion
that consistently integrates U-Net encoder outputs with SAM-derived features.
This fusion optimizes the traditional U-Net skip connection while leveraging
transformer-based contextual analysis. The translation is complemented by an
innovative dual-mask configuration incorporating dynamic attention patterns and
a specialized loss function designed to address regional mapping mismatches,
preserving both the gross anatomy and tissue details. Extensive validation
studies have shown that MRNet outperforms state-of-the-art architectures,
particularly in maintaining anatomical fidelity and minimizing translation
artifacts.

æè¦ï¼æåæåºä¸åå¤æ¹é¢çå½æ§ç¶²è·¯ (MRNet)ï¼éæ¯ä¸ååµæ°çæ¶æ§ï¼
éç¼ç¨æ¼é«å­¸å½±åè½å½±åçç¿»è­¯ï¼å¶åªæ¼ MRI è½ CT å MRI è½ MRI è½æçææ°æ¹æ³ãMRNet
å©ç¨ Segment Anything Model (SAM) ä¾å©ç¨åºæ¼é »ççç¹å¾µï¼ä»¥å»ºç«ä¸ç¨®å¼·å¤§çæ¹æ³ï¼ç¨æ¼åé²çé«å­¸å½±åè½æãæ­¤
æ¶æ§ä½¿ç¨å¼·å¤§ç SAM å½±åç·¨ç¢¼å¨å¾ä¸åçè³æéæåå¨é¢çå¤å°ºåº¦ç¹å¾µï¼ä¸¦å·è¡è§£æåº¦æç¥ç¹å¾µèåï¼æçºå° U-Net ç·¨ç¢¼å¨è¼¸åºè SAM è¡ççç¹å¾µæ´åå¨ä¸èµ·ã
æ­¤èåæä½³åå³çµ±ç U-Net è·³èºé£æ¥ï¼åæå©ç¨åºæ¼Transformerçä¸ä¸æåæãç¿»è­¯ç±ä¸ååµæ°çéé®ç½©éç½®è£åï¼å®çµåäºåææ³¨ææ¨¡å¼åä¸åå°éçæå¤±å½æ¸ï¼æ¨å¨è§£æ±ºååå°æä¸å¹éçåé¡ï¼åæä¿çäºæ´é«è§£åçµæ§åçµç¹ç´°ç¯ãå»£æ³çé©è­ç ç©¶é¡¯ç¤ºï¼MRNet åªæ¼æåé²çæ¶æ§ï¼ç¹å¥æ¯å¨ç¶­æè§£åä¿çåº¦åæå°åè½æå½å½±æ¹é¢ã

##### **Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**
2412.02919v1 by Soroush Omranpour, Guillaume Rabusseau, Reihaneh Rabbany

Transformers are now ubiquitous for sequence modeling tasks, but their
extension to multi-dimensional data remains a challenge due to the quadratic
cost of the attention mechanism. In this paper, we propose Higher-Order
Transformers (HOT), a novel architecture designed to efficiently process data
with more than two axes, i.e. higher-order tensors. To address the
computational challenges associated with high-order tensor attention, we
introduce a novel Kronecker factorized attention mechanism that reduces the
attention cost to quadratic in each axis' dimension, rather than quadratic in
the total size of the input tensor. To further enhance efficiency, HOT
leverages kernelized attention, reducing the complexity to linear. This
strategy maintains the model's expressiveness while enabling scalable attention
computation. We validate the effectiveness of HOT on two high-dimensional
tasks, including multivariate time series forecasting, and 3D medical image
classification. Experimental results demonstrate that HOT achieves competitive
performance while significantly improving computational efficiency, showcasing
its potential for tackling a wide range of complex, multi-dimensional data.

æè¦ï¼è®å½¢éåç¾å¨æ®éç¨æ¼åºåå»ºæ¨¡ä»»åï¼ä½ç±æ¼æ³¨æåæ©å¶çäºæ¬¡æ¹ææ¬ï¼å®åæ´å±å°å¤ç¶­æ¸æä»ç¶æ¯ä¸åææ°ãå¨æ¬æä¸­ï¼æåæåºäºé«éè®å½¢éå (HOT)ï¼éæ¯ä¸ç¨®æ°ç©çæ¶æ§ï¼æ¨å¨ææèçå·æå©åä»¥ä¸è»¸ç·çæ¸æï¼å³é«éå¼µéãçºäºæå°èé«éå¼µéæ³¨æåç¸éçè¨ç®ææ°ï¼æåå¼å¥äºä¸ç¨®æ°ç©çåç¾å§ååè§£æ³¨æåæ©å¶ï¼è©²æ©å¶å°æ³¨æåææ¬éä½å°æ¯åè»¸ç·ç¶­åº¦çäºæ¬¡æ¹ï¼èä¸æ¯è¼¸å¥å¼µéçç¸½å¤§å°çäºæ¬¡æ¹ãçºäºé²ä¸æ­¥æé«æçï¼HOT å©ç¨æ ¸åæ³¨æåï¼å°è¤éåº¦éä½å°ç·æ§ãæ­¤ç­ç¥ä¿æäºæ¨¡åçè¡¨ç¾åï¼åæå¯¦ç¾äºå¯æ´å±çæ³¨æåè¨ç®ãæåå¨å©åé«ç¶­ä»»åä¸é©è­äº HOT çæææ§ï¼åæ¬å¤åæéåºåé æ¸¬å 3D é«å­¸å½±ååé¡ãå¯¦é©çµæè¡¨æï¼HOT å¨é¡¯èæé«è¨ç®æççåæå¯¦ç¾äºç«¶ç­åçæè½ï¼å±ç¤ºäºå¶æå°åç¨®è¤éçå¤ç¶­æ¸æçæ½åã

##### **A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**
2412.02868v1 by Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu

Large Language Models (LLMs) have shown impressive capabilities in natural
language processing, yet their use in sensitive domains like healthcare,
particularly with Electronic Health Records (EHR), faces significant challenges
due to privacy concerns and limited computational resources. This paper
presents a compact LLM framework designed for local deployment in settings with
strict privacy requirements and limited access to high-performance GPUs. We
introduce a novel preprocessing technique that uses information extraction
methods, e.g., regular expressions, to filter and emphasize critical
information in clinical notes, enhancing the performance of smaller LLMs on EHR
data. Our framework is evaluated using zero-shot and few-shot learning
paradigms on both private and publicly available (MIMIC-IV) datasets, and we
also compare its performance with fine-tuned LLMs on the MIMIC-IV dataset. The
results demonstrate that our preprocessing approach significantly boosts the
prediction accuracy of smaller LLMs, making them suitable for high-privacy,
resource-constrained applications. This study offers valuable insights into
optimizing LLM performance for sensitive, data-intensive tasks while addressing
computational and privacy limitations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èçæ¹é¢å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼ç¶èå®åå¨é«çä¿å¥ç­ææé åçä½¿ç¨ï¼ç¹å¥æ¯é»å­å¥åº·ç´é (EHR)ï¼ç±æ¼é±ç§åé¡åæéçéç®è³æºèé¢è¨éå¤§ææ°ãæ¬ææåºäºä¸åç·æ¹ç LLM æ¡æ¶ï¼æ¨å¨å¨å·æå´æ ¼é±ç§è¦æ±åæéä½¿ç¨é«æ§è½ GPU çç°å¢ä¸­é²è¡æ¬å°é¨ç½²ãæåå¼å¥äºä¸ç¨®æ°ç©çé èçæè¡ï¼å®ä½¿ç¨è³è¨èåæ¹æ³ï¼ä¾å¦æ­£è¦è¡¨ç¤ºæ³ï¼ä¾éæ¿¾åå¼·èª¿è¨åºç­è¨ä¸­çééµè³è¨ï¼å¢å¼·è¼å° LLM å¨ EHR è³æä¸çæè½ãæåçæ¡æ¶ä½¿ç¨é¶æ¬¡å­¸ç¿åå°æ¬¡å­¸ç¿ç¯ä¾å¨ç§äººåå¬éå¯ç¨ç (MIMIC-IV) è³æéä¸é²è¡è©ä¼°ï¼æåä¹æ¯è¼å®å¨ MIMIC-IV è³æéä¸èå¾®èª¿ LLM çæè½ãçµæè¡¨æï¼æåçé èçæ¹æ³é¡¯èæåäºè¼å° LLM çé æ¸¬æºç¢ºåº¦ï¼ä½¿å¶é©ç¨æ¼é«åº¦é±ç§ãè³æºåéçæç¨ç¨å¼ãéé ç ç©¶æä¾äºå¯¶è²´çè¦è§£ï¼ç¨æ¼æä½³å LLM æè½ä»¥æå°ææãè³æå¯éåä»»åï¼åæè§£æ±ºéç®åé±ç§éå¶ã

##### **Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**
2412.02851v1 by Oliver Simonoski, Dijana Capeska Bogatinoska

This research explores the integration of blockchain technology in
healthcare, focusing on enhancing the security and efficiency of Electronic
Health Record (EHR) management. We propose a novel Ethereum-based system that
empowers patients with secure control over their medical data. Our approach
addresses key challenges in healthcare blockchain implementation, including
scalability, privacy, and regulatory compliance. The system incorporates
digital signatures, Role-Based Access Control, and a multi-layered architecture
to ensure secure, controlled access. We developed a decentralized application
(dApp) with user-friendly interfaces for patients, doctors, and administrators,
demonstrating the practical application of our solution. A survey among
healthcare professionals and IT experts revealed strong interest in blockchain
adoption, while also highlighting concerns about integration costs. The study
explores future enhancements, including integration with IoT devices and
AI-driven analytics, contributing to the evolution of secure, efficient, and
interoperable healthcare systems that leverage cutting-edge technologies for
improved patient care.

æè¦ï¼æ¬ç ç©¶æ¢è¨åå¡éæè¡å¨é«çä¿å¥ä¸­çæ´åï¼å°æ³¨æ¼æåé»å­å¥åº·ç´é (EHR) ç®¡ççå®å¨æ§èæçãæåæåºä¸ååµæ°çä»¥å¤ªåç³»çµ±ï¼è³¦äºæ£èå®å¨å°æ§å¶å¶é«çæ¸æçæ¬åãæåçåæ³è§£æ±ºäºé«çä¿å¥åå¡éå¯¦ä½ä¸­çä¸»è¦ææ°ï¼åæ¬å¯æ´åæ§ãé±ç§åæ³è¦éµå¾ªãè©²ç³»çµ±æ´åäºæ¸ä½ç°½ç« ãåºæ¼è§è²çå­åæ§å¶åå¤å±¤æ¶æ§ï¼ä»¥ç¢ºä¿å®å¨ä¸åæ§çå­åãæåéç¼äºä¸åå·æä½¿ç¨èååä»é¢çå»ä¸­å¿åæç¨ç¨å¼ (dApp)ï¼é©ç¨æ¼æ£èãé«çåç®¡çå¡ï¼å±ç¤ºäºæåè§£æ±ºæ¹æ¡çå¯¦éæç¨ãå¨é«çä¿å¥å°æ¥­äººå¡å IT å°å®¶ä¹éé²è¡çä¸é èª¿æ¥é¡¯ç¤ºï¼ä»åå°åå¡éçæ¡ç¨ææ¿åèè¶£ï¼ä½ä¹å¼·èª¿äºå°æ´åææ¬çææãè©²ç ç©¶æ¢è¨äºæªä¾çå¼·åï¼åæ¬è IoT è£ç½®æ´åå AI é©åçåæï¼æå©æ¼å®å¨ãé«æä¸å¯äºæä½çé«çä¿å¥ç³»çµ±çæ¼é²ï¼è©²ç³»çµ±å©ç¨å°ç«¯æè¡æ¹åæ£èç§è­·ã

##### **CNNSum: Exploring Long-Context Summarization with Large Language Models in Chinese Novels**
2412.02819v3 by Lingxiao Wei, He Yan, Xiangju Lu, Junmin Zhu, Jun Wang, Wei Zhang

Large Language Models (LLMs) have been well-researched in many long-context
tasks. However, due to high annotation costs, high-quality long-context summary
datasets for training or evaluation are scarce, limiting further research. In
this work, we introduce CNNSum, a new multi-scale Chinese long-context novel
summarization benchmark, including four subsets, length covering 16k to 128k,
695 samples in total, the annotations are human-driven. We evaluate commercial
and open-source models on CNNSum and conduct a detailed analysis. Based on the
observations, we further conduct fine-tuning exploration with short-context
summary data. In our study: (1) GPT-4o underperformed, due to excessive
subjective commentary. (2) Currently, long-context summarization mainly relies
on memory ability, small LLMs with stable longer context lengths are the most
cost-effective. Using long data concatenated from short-context summaries makes
a significant improvement. (3) Prompt templates may cause a large performance
gap but can be mitigated through fine-tuning. (4) Fine-tuned Chat or
Instruction versions may harm the Base model and further fine-tuning cannot
bridge performance gap. (5) while models with RoPE base scaling exhibit strong
extrapolation potential, their performance may vary significantly when combined
with other interpolation methods and need careful selection. (6) CNNSum
provides more reliable and insightful evaluation results than other benchmarks.
We release CNNSum to advance research in this field
(https://github.com/CxsGhost/CNNSum).

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) å·²å¨è¨±å¤é·èªå¢ä»»åä¸­ç²å¾æ·±å¥ç ç©¶ãç¶èï¼ç±æ¼æ¨è¨»ææ¬é«ï¼ç¨æ¼è¨ç·´æè©ä¼°çé«åè³ªé·èªå¢æè¦è³æéç¨å°ï¼éå¶äºé²ä¸æ­¥çç ç©¶ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº CNNSumï¼ä¸åæ°çå¤å°ºåº¦ä¸­æé·èªå¢å°èªªæè¦åºæºï¼åæ¬ååå­éï¼é·åº¦æ¶µè 16k å° 128kï¼ç¸½å± 695 åç¯ä¾ï¼æ¨è¨»æ¯ç±äººå·¥é©åçãæåè©ä¼°äº CNNSum ä¸çåæ¥­åéæºæ¨¡åï¼ä¸¦é²è¡äºè©³ç´°çåæãæ ¹æè§å¯çµæï¼æåé²ä¸æ­¥ä½¿ç¨ç­èªå¢æè¦è³æé²è¡å¾®èª¿æ¢ç´¢ãå¨æåçç ç©¶ä¸­ï¼(1) GPT-4o è¡¨ç¾ä¸ä½³ï¼åå æ¯éåº¦çä¸»è§è©è«ã(2) ç®åï¼é·èªå¢æè¦ä¸»è¦ä¾è³´è¨æ¶è½åï¼å·æç©©å®è¼é·èªå¢é·åº¦çå°å LLM æå·ææ¬æçãä½¿ç¨å¾ç­èªå¢æè¦ä¸²æ¥èæçé·è³æé¡¯èæ¹åäºè¡¨ç¾ã(3) æç¤ºç¯æ¬å¯è½æé æå¾å¤§çæè½å·®è·ï¼ä½å¯ä»¥ééå¾®èª¿ä¾æ¸è¼ã(4) å¾®èª¿éçèå¤©ææä»¤çæ¬å¯è½ææå®³åºç¤æ¨¡åï¼èé²ä¸æ­¥çå¾®èª¿ç¡æ³å½åæè½å·®è·ã(5) éç¶å·æ RoPE åºç¤ç¸®æ¾çæ¨¡åå±ç¾åºå¼·å¤§çå¤æ¨æ½åï¼ä½èå¶ä»å§ææ¹æ³çµåæï¼å¶æè½å¯è½æé¡¯èè®åï¼éè¦ä»ç´°é¸æã(6) CNNSum æä¾æ¯å¶ä»åºæºæ´å¯é ä¸æè¦å°çè©ä¼°çµæãæåç¼å¸ CNNSum ä»¥æ¨é²æ­¤é åçç ç©¶ (https://github.com/CxsGhost/CNNSum)ã</paragraph>

##### **Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**
2412.02801v2 by Jingyuan Yi, Peiyang Yu, Tianyi Huang, Zeqiu Xu

Aiming at the latest particle swarm optimization algorithm, this paper
proposes an improved Transformer model to improve the accuracy of heart disease
prediction and provide a new algorithm idea. We first use three mainstream
machine learning classification algorithms - decision tree, random forest and
XGBoost, and then output the confusion matrix of these three models. The
results showed that the random forest model had the best performance in
predicting the classification of heart disease, with an accuracy of 92.2%.
Then, we apply the Transformer model based on particle swarm optimization (PSO)
algorithm to the same dataset for classification experiment. The results show
that the classification accuracy of the model is as high as 96.5%, 4.3
percentage points higher than that of random forest, which verifies the
effectiveness of PSO in optimizing Transformer model. From the above research,
we can see that particle swarm optimization significantly improves Transformer
performance in heart disease prediction. Improving the ability to predict heart
disease is a global priority with benefits for all humankind. Accurate
prediction can enhance public health, optimize medical resources, and reduce
healthcare costs, leading to healthier populations and more productive
societies worldwide. This advancement paves the way for more efficient health
management and supports the foundation of a healthier, more resilient global
community.

æè¦ï¼<paragraph>éå°ææ°çç²å­ç¾¤æä½³åæ¼ç®æ³ï¼æ¬ææåºæ¹è¯ç Transformer æ¨¡åï¼ä»¥æåå¿èçé æ¸¬çæºç¢ºåº¦ï¼ä¸¦æä¾æ°çæ¼ç®æ³æç¶­ãæåé¦åä½¿ç¨ä¸ç¨®ä¸»æµæ©å¨å­¸ç¿åé¡æ¼ç®æ³ââæ±ºç­æ¨¹ãé¨æ©æ£®æè XGBoostï¼ä¸¦è¼¸åºéä¸ç¨®æ¨¡åçæ··æ·ç©é£ãçµæé¡¯ç¤ºé¨æ©æ£®ææ¨¡åå¨é æ¸¬å¿èçåé¡ä¸è¡¨ç¾æä½³ï¼æºç¢ºåº¦çº 92.2%ãæ¥èï¼æåå°åºæ¼ç²å­ç¾¤æä½³å (PSO) æ¼ç®æ³ç Transformer æ¨¡åå¥ç¨æ¼ç¸åè³æéé²è¡åé¡å¯¦é©ãçµæé¡¯ç¤ºè©²æ¨¡åçåé¡æºç¢ºåº¦é«é 96.5%ï¼æ¯é¨æ©æ£®æé«åº 4.3 åç¾åé»ï¼é©è­äº PSO å¨æä½³å Transformer æ¨¡åä¸çæææ§ãå¾ä¸è¿°ç ç©¶ä¸­ï¼æåå¯ä»¥çåºç²å­ç¾¤æä½³åé¡¯èæåäº Transformer å¨å¿èçé æ¸¬ä¸çè¡¨ç¾ãæåé æ¸¬å¿èççè½åæ¯ä¸é å¨çæ§çåªåè¦åï¼å°å¨äººé¡é½æçãæºç¢ºçé æ¸¬å¯ä»¥å¢é²å¬å±è¡çãåªåé«çè³æºä¸¦éä½é«çä¿å¥ææ¬ï¼é²èä¿é²å¨çäººå£çå¥åº·åç¤¾æçç¢åãéé é²å±çºæ´ææççå¥åº·ç®¡çéªè·¯ï¼ä¸¦æ¯æå»ºç«ä¸åæ´å¥åº·ãæ´å·éæ§çå¨çç¤¾ç¾¤ã</paragraph>

##### **Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**
2412.02621v1 by Kai Sun, Siyan Xue, Fuchun Sun, Haoran Sun, Yu Luo, Ling Wang, Siyuan Wang, Na Guo, Lei Liu, Tian Zhao, Xinzhou Wang, Lei Yang, Shuo Jin, Jun Yan, Jiahong Dong

Recent advancements in deep learning have significantly revolutionized the
field of clinical diagnosis and treatment, offering novel approaches to improve
diagnostic precision and treatment efficacy across diverse clinical domains,
thus driving the pursuit of precision medicine. The growing availability of
multi-organ and multimodal datasets has accelerated the development of
large-scale Medical Multimodal Foundation Models (MMFMs). These models, known
for their strong generalization capabilities and rich representational power,
are increasingly being adapted to address a wide range of clinical tasks, from
early diagnosis to personalized treatment strategies. This review offers a
comprehensive analysis of recent developments in MMFMs, focusing on three key
aspects: datasets, model architectures, and clinical applications. We also
explore the challenges and opportunities in optimizing multimodal
representations and discuss how these advancements are shaping the future of
healthcare by enabling improved patient outcomes and more efficient clinical
workflows.

æè¦ï¼æ·±åº¦å­¸ç¿çææ°é²å±å¤§å¹é©æ°äºè¨åºè¨ºæ·åæ²»çé åï¼æä¾äºæ¹ååç¨®è¨åºé åè¨ºæ·ç²¾æºåº¦åæ²»çææçæ°æ¹æ³ï¼é²èæ¨åç²¾æºé«ççè¿½æ±ãå¤å¨å®åå¤æ¨¡æè³æéçå¯ç¨æ§æ¥çå¢å ï¼å éäºå¤§è¦æ¨¡é«çå¤æ¨¡æåºç¤æ¨¡å (MMFM) çç¼å±ãéäºæ¨¡åä»¥å¶å¼·å¤§çæ¦åè½ååè±å¯çè¡¨å¾µè½åèèåï¼æ­£æ¥çè¢«æ¹ç·¨ä»¥è§£æ±ºå»£æ³çè¨åºä»»åï¼å¾æ©æè¨ºæ·å°åäººåæ²»çç­ç¥ãæ¬ç¯è©è«æä¾äºå° MMFM è¿æç¼å±çå¨é¢åæï¼éé»éæ³¨ä¸åééµé¢åï¼è³æéãæ¨¡åæ¶æ§åè¨åºæç¨ãæåä¹æ¢è¨äºæä½³åå¤æ¨¡æè¡¨å¾µçææ°åæ©æï¼ä¸¦è¨è«éäºé²å±å¦ä½ééæ¹åæ£èé å¾åæ´ææççè¨åºå·¥ä½æµç¨ï¼å½¢å¡é«çä¿å¥çæªä¾ã

##### **U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**
2412.02242v1 by Fnu Neha, Deepshikha Bhati, Deepak Kumar Shukla, Sonavi Makarand Dalvi, Nikolaos Mantzou, Safa Shubbar

Medical imaging is essential in healthcare to provide key insights into
patient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive
techniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography
(CT), and Ultrasound (US), capture detailed images of organs, tissues, and
abnormalities. Effective analysis of these images requires precise segmentation
to delineate regions of interest (ROI), such as organs or lesions. Traditional
segmentation methods, relying on manual feature-extraction, are labor-intensive
and vary across experts. Recent advancements in Artificial Intelligence (AI)
and Deep Learning (DL), particularly convolutional models such as U-Net and its
variants (U-Net++ and U-Net 3+), have transformed medical image segmentation
(MIS) by automating the process and enhancing accuracy. These models enable
efficient, precise pixel-wise classification across various imaging modalities,
overcoming the limitations of manual segmentation. This review explores various
medical imaging techniques, examines the U-Net architectures and their
adaptations, and discusses their application across different modalities. It
also identifies common challenges in MIS and proposes potential solutions.

æè¦ï¼é«çå½±åå¨é«çä¿å¥ä¸­è³ééè¦ï¼å¯æä¾æ£èè§£åçµæ§åççå­¸çéè¦è¦è§£ï¼æå©æ¼è¨ºæ·åæ²»çãX åãç£æ¯é å½± (MRI)ãé»è¦æ·å±¤ææ (CT) åè¶é³æ³¢ (US) ç­éä¾µå¥å¼æè¡ï¼å¯ææå¨å®ãçµç¹åç°å¸¸çè©³ç´°å½±åãææåæéäºå½±åéè¦ç²¾ç¢ºçåå²ï¼ä»¥æç¹ªæèè¶£åå (ROI)ï¼ä¾å¦å¨å®æçç¶ãå³çµ±çåå²æ¹æ³ä¾è³´æ¼æåç¹å¾µèåï¼æ¢è²»æåå å°å®¶èç°ãäººå·¥æºæ§ (AI) åæ·±åº¦å­¸ç¿ (DL) çææ°é²å±ï¼ç¹å¥æ¯ U-Net åå¶è®é« (U-Net++ å U-Net 3+) ç­å·ç©æ¨¡åï¼å·²ééèªååæµç¨åæé«æºç¢ºåº¦ï¼è½è®äºé«çå½±ååå² (MIS)ãéäºæ¨¡åè½è·¨è¶åç¨®å½±åæ¨¡å¼é²è¡ææä¸ç²¾ç¢ºçéåç´ åé¡ï¼åæäºæååå²çéå¶ãæ¬ç¯è©è«æ¢è¨äºåç¨®é«çå½±åæè¡ï¼å¯©æ¥äº U-Net æ¶æ§åå¶æ¹ç·¨ï¼ä¸¦è¨è«äºå®åå¨ä¸åæ¨¡å¼ä¸­çæç¨ãå®ä¹æ¾åºäº MIS ä¸­å¸¸è¦çææ°ï¼ä¸¦æåºäºæ½å¨çè§£æ±ºæ¹æ¡ã

##### **Recovering implicit physics model under real-world constraints**
2412.02215v1 by Ayan Banerjee, Sandeep K. S. Gupta

Recovering a physics-driven model, i.e. a governing set of equations of the
underlying dynamical systems, from the real-world data has been of recent
interest. Most existing methods either operate on simulation data with
unrealistically high sampling rates or require explicit measurements of all
system variables, which is not amenable in real-world deployments. Moreover,
they assume the timestamps of external perturbations to the physical system are
known a priori, without uncertainty, implicitly discounting any sensor
time-synchronization or human reporting errors. In this paper, we propose a
novel liquid time constant neural network (LTC-NN) based architecture to
recover underlying model of physical dynamics from real-world data. The
automatic differentiation property of LTC-NN nodes overcomes problems
associated with low sampling rates, the input dependent time constant in the
forward pass of the hidden layer of LTC-NN nodes creates a massive search space
of implicit physical dynamics, the physics model solver based data
reconstruction loss guides the search for the correct set of implicit dynamics,
and the use of the dropout regularization in the dense layer ensures extraction
of the sparsest model. Further, to account for the perturbation timing error,
we utilize dense layer nodes to search through input shifts that results in the
lowest reconstruction loss. Experiments on four benchmark dynamical systems,
three with simulation data and one with the real-world data show that the
LTC-NN architecture is more accurate in recovering implicit physics model
coefficients than the state-of-the-art sparse model recovery approaches. We
also introduce four additional case studies (total eight) on real-life medical
examples in simulation and with real-world clinical data to show effectiveness
of our approach in recovering underlying model in practice.

æè¦ï¼<paragraph>å¾çå¯¦ä¸çè³æä¸­éåç©çé©åæ¨¡åï¼å³åºç¤åæç³»çµ±çæ§å¶æ¹ç¨å¼çµï¼ä¸ç´æ¯è¿æçç ç©¶éé»ãç¾ææ¹æ³å¤§å¤å¨å·æéç¾å¯¦é«åæ¨£ççæ¨¡æ¬è³æä¸å·è¡ï¼æéè¦ææç³»çµ±è®æ¸çæç¢ºæ¸¬éå¼ï¼éå¨çå¯¦ä¸ççé¨ç½²ä¸­ä¸¦ä¸å¯è¡ãæ­¤å¤ï¼éäºæ¹æ³åè¨­å°ç©çç³»çµ±çå¤é¨æ¾åçæéæ³æ¯åé©å·²ç¥çï¼ä¸æ²æä¸ç¢ºå®æ§ï¼é±å«å°å¿½ç¥äºä»»ä½ææ¸¬å¨æéåæ­¥æäººçºåå ±é¯èª¤ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼æ°ç©æ¶²ææéå¸¸æ¸ç¥ç¶ç¶²è·¯ (LTC-NN) çæ¶æ§ï¼ä»¥å¾çå¯¦ä¸çè³æä¸­éåç©çåæçåºç¤æ¨¡åãLTC-NN ç¯é»çèªåå¾®åç¹æ§åæäºèä½åæ¨£çç¸éçåé¡ï¼LTC-NN ç¯é»é±èå±¤çååå³éä¸­è¼¸å¥ä¾è³´çæéå¸¸æ¸æç¢çä¸åå·¨å¤§çé±å¼ç©çåææå°ç©ºéï¼åºæ¼ç©çæ¨¡åæ±è§£å¨çè³æéå»ºæå¤±å¼å°äºå°æ­£ç¢ºé±å¼åæéçæå°ï¼ä¸¦ä¸å¨ç¨ å¯å±¤ä¸­ä½¿ç¨ä¸­æ·æ­£ååç¢ºä¿äºæç¨çæ¨¡åçæåãæ­¤å¤ï¼çºäºèæ®æ¾åè¨æé¯èª¤ï¼æåå©ç¨ç¨ å¯å±¤ç¯é»ä¾æå°è¼¸å¥ä½ç§»ï¼éå°å°è´æä½çéå»ºæå¤±ãå¨åååºæºåæç³»çµ±ï¼ä¸åä½¿ç¨æ¨¡æ¬è³æï¼ä¸åä½¿ç¨çå¯¦ä¸çè³æï¼ä¸çå¯¦é©è¡¨æï¼LTC-NN æ¶æ§å¨æ¢å¾©é±å¼ç©çæ¨¡åä¿æ¸æ¹é¢æ¯æåé²çç¨çæ¨¡åæ¢å¾©æ¹æ³æ´æºç¢ºãæåéä»ç´¹äºååé¡å¤çæ¡ä¾ç ç©¶ï¼ç¸½å±å«åï¼ï¼éäºç ç©¶æ¶åæ¨¡æ¬ä¸­ççå¯¦é«çç¯ä¾åçå¯¦ä¸ççè¨åºè³æï¼ä»¥å±ç¤ºæåçåæ³å¨å¯¦åä¸­æ¢å¾©åºç¤æ¨¡åçæææ§ã</paragraph>

##### **Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**
2412.02189v1 by Abu Bakar Siddik, Faisal R. Badal, Afroza Islam

A great deal of effort has been devoted to discovering a particular genetic
disorder, but its classification across a broad spectrum of disorder classes
and types remains elusive. Early diagnosis of genetic disorders enables timely
interventions and improves outcomes. This study implements machine learning
models using basic clinical indicators measurable at birth or infancy to enable
diagnosis in preliminary life stages. Supervised learning algorithms were
implemented on a dataset of 22083 instances with 42 features like family
history, newborn metrics, and basic lab tests. Extensive hyperparameter tuning,
feature engineering, and selection were undertaken. Two multi-class classifiers
were developed: one for predicting disorder classes (mitochondrial,
multifactorial, and single-gene) and one for subtypes (9 disorders).
Performance was evaluated using accuracy, precision, recall, and the F1-score.
The CatBoost classifier achieved the highest accuracy of 77% for predicting
genetic disorder classes. For subtypes, SVM attained a maximum accuracy of 80%.
The study demonstrates the feasibility of using basic clinical data in machine
learning models for early categorization and diagnosis across various genetic
disorders. Applying ML with basic clinical indicators can enable timely
interventions once validated on larger datasets. It is necessary to conduct
further studies to improve model performance on this dataset.

æè¦ï¼<paragraph>è¨±å¤ç ç©¶è´åæ¼ç¼ç¾ç¹å®éºå³æ§ç¾çï¼ä½å¶å¨å»£æ³çç¾çé¡åååé¡ä¸­çåé¡ä»ç¶é£ä»¥ææ¸ãéºå³æ§ç¾ççæ©æè¨ºæ·è½åæä»å¥ä¸¦æ¹åçµæãæ¬ç ç©¶å¯¦ä½æ©å¨å­¸ç¿æ¨¡åï¼ä½¿ç¨åºçæå¬°åææå¯æ¸¬éçåºæ¬è¨åºææ¨ï¼ä»¥å¨çå½çæ©æéæ®µé²è¡è¨ºæ·ãç£ç£å¼å­¸ç¿æ¼ç®æ³å¯¦ä½å¨ä¸ååå« 22083 åå¯¦ä¾çè³æéä¸ï¼å¶ä¸­åå« 42 åç¹å¾µï¼ä¾å¦å®¶æå²ãæ°çåææ¨ååºæ¬å¯¦é©å®¤æª¢é©ãé²è¡äºå»£æ³çè¶åæ¸èª¿æ´ãç¹å¾µå·¥ç¨åé¸æãéç¼äºå©åå¤é¡å¥åé¡å¨ï¼ä¸åç¨æ¼é æ¸¬ç¾çé¡åï¼ç²ç·é«ãå¤å ç´ åå®åºå ï¼ï¼å¦ä¸åç¨æ¼é æ¸¬äºåï¼9 ç¨®ç¾çï¼ãä½¿ç¨æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸è©ä¼°æè½ãCatBoost åé¡å¨å¨é æ¸¬éºå³æ§ç¾çé¡åæ¹é¢éå°äº 77% çæé«æºç¢ºåº¦ãå°æ¼äºåï¼SVM éå°äº 80% çæé«æºç¢ºåº¦ãæ¬ç ç©¶è­æäºå¨æ©å¨å­¸ç¿æ¨¡åä¸­ä½¿ç¨åºæ¬è¨åºè³æé²è¡æ©æåé¡åè¨ºæ·åç¨®éºå³æ§ç¾ççå¯è¡æ§ãå°æ©å¨å­¸ç¿æç¨æ¼åºæ¬è¨åºææ¨ï¼å¯ä»¥å¨è¼å¤§çè³æéä¸é©è­å¾åæé²è¡å¹²é ãæå¿è¦é²è¡é²ä¸æ­¥çç ç©¶ä»¥æ¹åæ­¤è³æéä¸çæ¨¡åæè½ã</paragraph>

##### **Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**
2412.02177v1 by R. Mahmood, K. C. L. Wong, D. M. Reyes, N. D'Souza, L. Shi, J. Wu, P. Kaviani, M. Kalra, G. Wang, P. Yan, T. Syeda-Mahmood

With the emergence of large-scale vision-language models, realistic radiology
reports may be generated using only medical images as input guided by simple
prompts. However, their practical utility has been limited due to the factual
errors in their description of findings. In this paper, we propose a novel
model for explainable fact-checking that identifies errors in findings and
their locations indicated through the reports. Specifically, we analyze the
types of errors made by automated reporting methods and derive a new synthetic
dataset of images paired with real and fake descriptions of findings and their
locations from a ground truth dataset. A new multi-label cross-modal
contrastive regression network is then trained on this datsaset. We evaluate
the resulting fact-checking model and its utility in correcting reports
generated by several SOTA automated reporting tools on a variety of benchmark
datasets with results pointing to over 40\% improvement in report quality
through such error detection and correction.

æè¦ï¼é¨èå¤§è¦æ¨¡è¦è¦ºèªè¨æ¨¡åçåºç¾ï¼åä½¿ç¨é«çå½±åä½çºè¼¸å¥ï¼ä¸¦ééç°¡å®æç¤ºå¼å°ï¼å³å¯ç¢çé¼ççæ¾å°ç§å ±åãç¶èï¼ç±æ¼å¶å°ç¼ç¾çæè¿°æäºå¯¦ä¸çé¯èª¤ï¼å æ­¤å¶å¯¦éæç¨åå°éå¶ãå¨æ¬æä¸­ï¼æåæåºäºä¸åç¨æ¼å¯è§£éäºå¯¦æ¥æ ¸çæ°æ¨¡åï¼è©²æ¨¡åå¯è­å¥å ±åä¸­ç¼ç¾çé¯èª¤åå¶ä½ç½®ãå·é«ä¾èªªï¼æååæäºèªååå ±åæ¹æ³æç¢ççé¯èª¤é¡åï¼ä¸¦å¾çå¯¦è³æéä¸­è¡çåºä¸åæ°çåæå½±åè³æéï¼å¶ä¸­éå°äºç¼ç¾åå¶ä½ç½®ççå¯¦åèåæè¿°ãç¶å¾å¨éåè³æéä¸è¨ç·´ä¸åæ°çå¤æ¨ç±¤è·¨æ¨¡æå°æ¯åæ­¸ç¶²è·¯ãæåè©ä¼°äºç¢ççäºå¯¦æ¥æ ¸æ¨¡ååå¶å¨æ´æ­£ç±å¤å SOTA èªååå ±åå·¥å·å¨åç¨®åºæºè³æéä¸ç¢ççå ±åä¸­çæç¨ï¼çµæè¡¨æéééç¨®é¯èª¤åµæ¸¬åæ´æ­£ï¼å ±ååè³ªç²å¾äºè¶é 40% çæåã

##### **Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**
2412.02173v1 by Nader Karayanni, Aya Awwad, Chein-Lien Hsiao, Surish P Shanmugam

Since the emergence of Large Language Models (LLMs), the challenge of
effectively leveraging their potential in healthcare has taken center stage. A
critical barrier to using LLMs for extracting insights from unstructured
clinical notes lies in the prompt engineering process. Despite its pivotal role
in determining task performance, a clear framework for prompt optimization
remains absent. Current methods to address this gap take either a manual prompt
refinement approach, where domain experts collaborate with prompt engineers to
create an optimal prompt, which is time-intensive and difficult to scale, or
through employing automatic prompt optimizing approaches, where the value of
the input of domain experts is not fully realized. To address this, we propose
StructEase, a novel framework that bridges the gap between automation and the
input of human expertise in prompt engineering. A core innovation of the
framework is SamplEase, an iterative sampling algorithm that identifies
high-value cases where expert feedback drives significant performance
improvements. This approach minimizes expert intervention, to effectively
enhance classification outcomes. This targeted approach reduces labeling
redundancy, mitigates human error, and enhances classification outcomes. We
evaluated the performance of StructEase using a dataset of de-identified
clinical narratives from the US National Electronic Injury Surveillance System
(NEISS), demonstrating significant gains in classification performance compared
to current methods. Our findings underscore the value of expert integration in
LLM workflows, achieving notable improvements in F1 score while maintaining
minimal expert effort. By combining transparency, flexibility, and scalability,
StructEase sets the foundation for a framework to integrate expert input into
LLM workflows in healthcare and beyond.

æè¦ï¼èªå¤§åèªè¨æ¨¡å (LLM) åºç¾ä»¥ä¾ï¼ææå©ç¨å¶å¨é«çä¿å¥ä¸­çæ½åçææ°å·²æçºéä¸­ä¹éãä½¿ç¨ LLM å¾éçµæ§åè¨åºç­è¨ä¸­æåè¦è§£çä¸åééµéç¤å¨æ¼æç¤ºå·¥ç¨éç¨ãåç®¡å®å¨ç¢ºå®ä»»åç¸¾æä¸­æ®æ¼èèè¶³è¼éçè§è²ï¼ä½ä»ç¼ºä¹æç¢ºçæç¤ºæä½³åæ¡æ¶ãç®åè§£æ±ºæ­¤å·®è·çæ¹æ³æ¡ç¨æåæç¤ºåªåæ¹æ³ï¼å¶ä¸­é åå°å®¶èæç¤ºå·¥ç¨å¸«åä½å»ºç«æä½³æç¤ºï¼ééå¸¸èæä¸é£ä»¥æ´å±ï¼æééæ¡ç¨èªåæç¤ºæä½³åæ¹æ³ï¼å¶ä¸­é åå°å®¶çè¼¸å¥å¹å¼ä¸¦æªååå¯¦ç¾ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº StructEaseï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®å½åäºèªååèæç¤ºå·¥ç¨ä¸­äººé¡å°æ¥­ç¥è­è¼¸å¥ä¹éçå·®è·ãè©²æ¡æ¶çæ ¸å¿åµæ°æ¯ SamplEaseï¼éæ¯ä¸ç¨®è¿­ä»£å¼æ½æ¨£æ¼ç®æ³ï¼å®è­å¥åºå°å®¶åé¥è½é¡¯èæåç¸¾æçé«å¹å¼æ¡ä¾ãéç¨®æ¹æ³å°å°å®¶ä»å¥éå°æä½ï¼ä»¥æææååé¡çµæãéç¨®æéå°æ§çæ¹æ³æ¸å°äºæ¨ç±¤åé¤ï¼æ¸è¼äºäººçºé¯èª¤ï¼ä¸¦æåäºåé¡çµæãæåä½¿ç¨ä¾èªç¾ååå®¶é»å­å·å®³ç£æ¸¬ç³»çµ± (NEISS) çå»è­å¥åè¨åºæè¿°è³æéè©ä¼°äº StructEase çç¸¾æï¼èç®åçæ¹æ³ç¸æ¯ï¼åé¡ç¸¾ææäºé¡¯èçæåãæåçç ç©¶çµæå¼·èª¿äºå°å®¶æ´åå¨ LLM å·¥ä½æµç¨ä¸­çå¹å¼ï¼å¨ç¶­ææå°å°å®¶å·¥ä½éçåæï¼éå°äº F1 åæ¸çé¡¯èæåãééçµåéæåº¦ãå½æ§åå¯æ´å±æ§ï¼StructEase çºä¸åæ¡æ¶å¥ å®äºåºç¤ï¼å°å°å®¶è¼¸å¥æ´åå°é«çä¿å¥åå¶ä»é åç LLM å·¥ä½æµç¨ä¸­ã

##### **Construction and optimization of health behavior prediction model for the elderly in smart elderly care**
2412.02062v1 by Qian Guo, Peiyuan Chen

With the intensification of global aging, health management of the elderly
has become a focus of social attention. This study designs and implements a
smart elderly care service model to address issues such as data diversity,
health status complexity, long-term dependence and data loss, sudden changes in
behavior, and data privacy in the prediction of health behaviors of the
elderly. The model achieves accurate prediction and dynamic management of
health behaviors of the elderly through modules such as multimodal data fusion,
data loss processing, nonlinear prediction, emergency detection, and privacy
protection. In the experimental design, based on multi-source data sets and
market research results, the model demonstrates excellent performance in health
behavior prediction, emergency detection, and personalized services. The
experimental results show that the model can effectively improve the accuracy
and robustness of health behavior prediction and meet the actual application
needs in the field of smart elderly care. In the future, with the integration
of more data and further optimization of technology, the model will provide
more powerful technical support for smart elderly care services.

æè¦ï¼é¨èå¨çé«é½¡åå åï¼èå¹´äººçå¥åº·ç®¡çå·²æçºç¤¾æéæ³¨çç¦é»ãæ¬ç ç©¶è¨­è¨ä¸¦å¯¦ä½ä¸åæºæ§èäººç§è­·æåæ¨¡åï¼ä»¥è§£æ±ºèäººå¥åº·è¡çºé æ¸¬ä¸­çè³æç°è³ªæ§ãå¥åº·çæè¤éæ§ãé·æä¾è³´æ§èè³ææµå¤±ãè¡çºçªè®ãè³æé±ç§ç­åé¡ãè©²æ¨¡åééå¤æ¨¡æè³æèåãè³ææµå¤±èçãéç·æ§é æ¸¬ãç·æ¥äºä»¶åµæ¸¬ãé±ç§ä¿è­·ç­æ¨¡çµï¼éå°èäººå¥åº·è¡çºçç²¾æºé æ¸¬èåæç®¡çãå¨å¯¦é©è¨­è¨ä¸ï¼åºæ¼å¤ä¾æºè³æéèå¸å ´èª¿æ¥çµæï¼è©²æ¨¡åå¨å¥åº·è¡çºé æ¸¬ãç·æ¥äºä»¶åµæ¸¬ãåäººåæåç­æ¹é¢åå±ç¾åºåªç°çè¡¨ç¾ãå¯¦é©çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æææåå¥åº·è¡çºé æ¸¬çæºç¢ºæ§èé­¯æ£æ§ï¼ä¸¦æ»¿è¶³æºæ§èäººç§è­·é åçå¯¦éæç¨éæ±ãæªä¾é¨èæ´å¤è³æçæ´åèæè¡çé²ä¸æ­¥åªåï¼è©²æ¨¡åå°çºæºæ§èäººç§è­·æåæä¾æ´å¼·å¤§çæè¡æ¯æã

##### **INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**
2412.02012v2 by Wenbo Zhang, Junyu Chen, Christopher Kanan

Due to their large sizes, volumetric scans and whole-slide pathology images
(WSIs) are often processed by extracting embeddings from local regions and then
an aggregator makes predictions from this set. However, current methods require
post-hoc visualization techniques (e.g., Grad-CAM) and often fail to localize
small yet clinically crucial details. To address these limitations, we
introduce INSIGHT, a novel weakly-supervised aggregator that integrates heatmap
generation as an inductive bias. Starting from pre-trained feature maps,
INSIGHT employs a detection module with small convolutional kernels to capture
fine details and a context module with a broader receptive field to suppress
local false positives. The resulting internal heatmap highlights diagnostically
relevant regions. On CT and WSI benchmarks, INSIGHT achieves state-of-the-art
classification results and high weakly-labeled semantic segmentation
performance. Project website and code are available at:
https://zhangdylan83.github.io/ewsmia/

æè¦ï¼ç±æ¼é«ç©é¾å¤§ï¼é«ç©ææåå¨ç»çççåå (WSI) éå¸¸ééå¾å±é¨ååæååµå¥å¼èçï¼ç¶å¾èåå¨å¾æ­¤çµä¸­ååºé æ¸¬ãç¶èï¼ç®åçæ¹æ³éè¦äºå¾å¯è¦åæè¡ï¼ä¾å¦ Grad-CAMï¼ï¼èä¸å¸¸å¸¸ç¡æ³å®ä½å°åä½è¨åºä¸è³ééè¦çç´°ç¯ãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥äº INSIGHTï¼éæ¯ä¸ç¨®æ°ç©çå¼±ç£ç£èåå¨ï¼å®å°ç±åçææ´åçºæ­¸ç´åèª¤ãå¾é åè¨ç·´å¥½çç¹å¾µåéå§ï¼INSIGHT ä½¿ç¨å¸¶æå°åå·ç©æ ¸çæª¢æ¸¬æ¨¡çµä¾æ·åç²¾ç´°çç´°ç¯ï¼ä»¥åå¸¶æè¼å»£æ³æåéçä¸ä¸ææ¨¡çµä¾æå¶å±é¨èª¤å ±ãç¢ççå§é¨ç±åçªåºäºè¨ºæ·ç¸éååãå¨ CT å WSI åºæºä¸ï¼INSIGHT éå°äºæåé²çåé¡çµæåé«å¼±æ¨è¨èªç¾©åå²æè½ãå°æ¡ç¶²ç«åç¨å¼ç¢¼å¯æ¼ä¸åç¶²ååå¾ï¼
https://zhangdylan83.github.io/ewsmia/

##### **The use of large language models to enhance cancer clinical trial educational materials**
2412.01955v2 by Mingye Gao, Aman Varshney, Shan Chen, Vikram Goddla, Jack Gallifant, Patrick Doyle, Claire Novack, Maeve Dillon-Martin, Teresia Perkins, Xinrong Correia, Erik Duhaime, Howard Isenstein, Elad Sharon, Lisa Soleymani Lehmann, David Kozono, Brian Anthony, Dmitriy Dligach, Danielle S. Bitterman

Cancer clinical trials often face challenges in recruitment and engagement
due to a lack of participant-facing informational and educational resources.
This study investigated the potential of Large Language Models (LLMs),
specifically GPT4, in generating patient-friendly educational content from
clinical trial informed consent forms. Using data from ClinicalTrials.gov, we
employed zero-shot learning for creating trial summaries and one-shot learning
for developing multiple-choice questions, evaluating their effectiveness
through patient surveys and crowdsourced annotation. Results showed that
GPT4-generated summaries were both readable and comprehensive, and may improve
patients' understanding and interest in clinical trials. The multiple-choice
questions demonstrated high accuracy and agreement with crowdsourced
annotators. For both resource types, hallucinations were identified that
require ongoing human oversight. The findings demonstrate the potential of LLMs
"out-of-the-box" to support the generation of clinical trial education
materials with minimal trial-specific engineering, but implementation with a
human-in-the-loop is still needed to avoid misinformation risks.

æè¦ï¼ççè¨åºè©¦é©ç±æ¼ç¼ºä¹é¢ååèèçè³è¨åæè²è³æºï¼å¸¸å¸¸å¨æåååèæ¹é¢é¢è¨ææ°ãæ¬ç ç©¶æ¢è¨äºå¤§åèªè¨æ¨¡å (LLM)ï¼ç¹å¥æ¯ GPT4ï¼å¾è¨åºè©¦é©ç¥æåææ¸ä¸­ç¢çå°æ£èååçæè²å§å®¹çæ½åãæåä½¿ç¨ä¾èª ClinicalTrials.gov çè³æï¼æ¡ç¨é¶æ¬¡å­¸ç¿ä¾å»ºç«è©¦é©æè¦ï¼ä»¥åä¸æ¬¡å­¸ç¿ä¾éç¼å¤é¸é¡ï¼ä¸¦ééæ£èèª¿æ¥åç¾¤ç¾å¤åè¨»è§£ä¾è©ä¼°å¶æææ§ãçµæé¡¯ç¤ºï¼GPT4 çæçæè¦å·æå¯è®æ§åå¨é¢æ§ï¼ä¸¦ä¸å¯è½æé«æ£èå°è¨åºè©¦é©ççè§£åèè¶£ãå¤é¸é¡å±ç¤ºåºå¾é«çæºç¢ºåº¦ï¼ä¸¦ä¸èç¾¤ç¾å¤åè¨»è§£èéæå±è­ãå°æ¼éå©ç¨®è³æºé¡åï¼æåç¼ç¾äºéè¦æçºçäººå·¥ç£ç£çå¹»è¦ºãéäºç¼ç¾å±ç¤ºäº LLMãéç®±å³ç¨ãçæ½åï¼å¯ä»¥ç¨æå°çè©¦é©ç¹å®å·¥ç¨ä¾æ¯æ´è¨åºè©¦é©æè²ææçç¢çï¼ä½ä»éè¦æ¡ç¨æäººå¨è¿´è·¯ä¸­çå¯¦ä½ä¾é¿åé¯èª¤è³è¨çé¢¨éªã

##### **Recurrent Neural Network on PICTURE Model**
2412.01933v1 by Weihan Xu

Intensive Care Units (ICUs) provide critical care and life support for most
severely ill and injured patients in the hospital. With the need for ICUs
growing rapidly and unprecedentedly, especially during COVID-19, accurately
identifying the most critical patients helps hospitals to allocate resources
more efficiently and save more lives. The Predicting Intensive Care Transfers
and Other Unforeseen Events (PICTURE) model predicts patient deterioration by
separating those at high risk for imminent intensive care unit transfer,
respiratory failure, or death from those at lower risk. This study aims to
implement a deep learning model to benchmark the performance from the XGBoost
model, an existing model which has competitive results on prediction.

æè¦ï¼å è­·çæ¿ (ICU) æä¾éçç§è­·åçå½æ¯æï¼çµ¦äºé«é¢ä¸­çææå´éååå·æå´éçæ£èãç±æ¼å°å è­·çæ¿çéæ±å¿«éä¸ç©ºåå°å¢é·ï¼ç¹å¥æ¯å¨ COVID-19 æéï¼æºç¢ºæ¾åºçææå±æ¥çæ£èæå©æ¼é«é¢æ´ææå°åéè³æºä¸¦æ½ææ´å¤çå½ãé æ¸¬å è­·çæ¿è½è¨ºåå¶ä»ç¡æ³é è¦äºä»¶ (PICTURE) æ¨¡åééå°é¢è¨è¿«å¨çç«çå è­·çæ¿è½è¨ºãå¼å¸è¡°ç«­ææ­»äº¡çé«é¢¨éªæ£èèé¢¨éªè¼ä½çæ£èååéä¾ï¼é æ¸¬æ£èæ¡åãæ¬ç ç©¶æ¨å¨å¯¦ä½æ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥åºæºå XGBoost æ¨¡åçæè½ï¼å¾èæ¯ä¸ç¨®å¨é æ¸¬æ¹é¢å·æç«¶ç­åçç¾ææ¨¡åã

##### **ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**
2412.01929v1 by Poorya Aghaomidi, Ge Wang

Accurate sleep stage classification is essential for understanding sleep
disorders and improving overall health. This study proposes a novel three-stage
approach for sleep stage classification using ECG signals, offering a more
accessible alternative to traditional methods that often rely on complex
modalities like EEG. In Stages 1 and 2, we initialize the weights of two
networks, which are then integrated in Stage 3 for comprehensive
classification. In the first phase, we estimate key features using Feature
Imitating Networks (FINs) to achieve higher accuracy and faster convergence.
The second phase focuses on identifying the N1 sleep stage through the
time-frequency representation of ECG signals. Finally, the third phase
integrates models from the previous stages and employs a Kolmogorov-Arnold
Network (KAN) to classify five distinct sleep stages. Additionally, data
augmentation techniques, particularly SMOTE, are used in enhancing
classification capabilities for underrepresented stages like N1. Our results
demonstrate significant improvements in the classification performance, with an
overall accuracy of 80.79% an overall kappa of 0.73. The model achieves
specific accuracies of 86.70% for Wake, 60.36% for N1, 83.89% for N2, 84.85%
for N3, and 87.16% for REM. This study emphasizes the importance of weight
initialization and data augmentation in optimizing sleep stage classification
with ECG signals.

æè¦ï¼ç²¾æºçç¡ç åæåé¡å°æ¼äºè§£ç¡ç éç¤åæ¹åæ´é«å¥åº·è³ééè¦ãæ¬ç ç©¶æåºä¸åæ°çä¸éæ®µæ¹æ³ï¼ä½¿ç¨ ECG è¨èé²è¡ç¡ç åæåé¡ï¼æä¾äºä¸åæ´ææ¼åå¾çæ¿ä»£æ¹æ¡ï¼å³çµ±æ¹æ³éå¸¸ä¾è³´æ¼ EEG ç­è¤éçæ¨¡å¼ãå¨ç¬¬ 1 åç¬¬ 2 éæ®µï¼æååå§åå©åç¶²è·¯çæ¬éï¼ç¶å¾å¨ç¬¬ 3 éæ®µæ´åå®åä»¥é²è¡å¨é¢çåé¡ãå¨ç¬¬ä¸éæ®µï¼æåä½¿ç¨ç¹å¾µæ¨¡ä»¿ç¶²è·¯ (FIN) ä¼°è¨ééµç¹å¾µï¼ä»¥å¯¦ç¾æ´é«çæºç¢ºåº¦åæ´å¿«çæ¶æãç¬¬äºéæ®µå°æ³¨æ¼éé ECG è¨èçæé »è¡¨ç¤ºä¾è­å¥ N1 ç¡ç éæ®µãæå¾ï¼ç¬¬ä¸éæ®µæ´ååä¸éæ®µçæ¨¡åï¼ä¸¦æ¡ç¨ Kolmogorov-Arnold ç¶²è·¯ (KAN) ä¾åé¡äºåä¸åçç¡ç éæ®µãæ­¤å¤ï¼è³ææ´åæè¡ï¼ç¹å¥æ¯ SMOTEï¼ç¨æ¼å¢å¼·å° N1 ç­ä»£è¡¨æ§ä¸è¶³éæ®µçåé¡è½åãæåççµæè­æäºåé¡æè½æé¡¯èçæ¹åï¼æ´é«æºç¢ºåº¦çº 80.79%ï¼æ´é« kappa çº 0.73ãè©²æ¨¡åå°æ¸éãN1ãN2ãN3 å REM çç¹å®æºç¢ºåº¦åå¥çº 86.70%ã60.36%ã83.89%ã84.85% å 87.16%ãæ¬ç ç©¶å¼·èª¿äºæ¬éåå§ååè³ææ´åå¨ä½¿ç¨ ECG è¨èæä½³åç¡ç åæåé¡ä¸­çéè¦æ§ã

##### **Deep Guess acceleration for explainable image reconstruction in sparse-view CT**
2412.01703v1 by Elena Loli Piccolomini, Davide Evangelista, Elena Morotti

Sparse-view Computed Tomography (CT) is an emerging protocol designed to
reduce X-ray dose radiation in medical imaging. Traditional Filtered Back
Projection algorithm reconstructions suffer from severe artifacts due to sparse
data. In contrast, Model-Based Iterative Reconstruction (MBIR) algorithms,
though better at mitigating noise through regularization, are too
computationally costly for clinical use. This paper introduces a novel
technique, denoted as the Deep Guess acceleration scheme, using a trained
neural network both to quicken the regularized MBIR and to enhance the
reconstruction accuracy. We integrate state-of-the-art deep learning tools to
initialize a clever starting guess for a proximal algorithm solving a
non-convex model and thus computing an interpretable solution image in a few
iterations. Experimental results on real CT images demonstrate the Deep Guess
effectiveness in (very) sparse tomographic protocols, where it overcomes its
mere variational counterpart and many data-driven approaches at the state of
the art. We also consider a ground truth-free implementation and test the
robustness of the proposed framework to noise.

æè¦ï¼ç¨çè¦åé»è¦æ·å±¤ææ (CT) æ¯ä¸ç¨®æ°èçåå®ï¼æ¨å¨æ¸å°é«çå½±åä¸­ç X å°ç·åéè¼»å°ãå³çµ±çæ¿¾æ³¢ååæå½±æ¼ç®æ³éå»ºå ç¨çè³æèå°è´å´éçå½å½±ãç¸æ¯ä¹ä¸ï¼åºæ¼æ¨¡åçè¿­ä»£éå»º (MBIR) æ¼ç®æ³ï¼éç¶ééæ­£ååå¨æ¸è¼éè¨æ¹é¢è¡¨ç¾å¾æ´å¥½ï¼ä½å°æ¼è¨åºä½¿ç¨èè¨ï¼å¶è¨ç®ææ¬éé«ãæ¬æä»ç´¹äºä¸ç¨®åµæ°çæè¡ï¼ç¨±çº Deep Guess å éæ¹æ¡ï¼å®ä½¿ç¨è¨ç·´éçé¡ç¥ç¶ç¶²è·¯ä¾å éæ­£ååç MBIR ä¸¦å¢å¼·éå»ºæºç¢ºåº¦ãæåæ´åäºæåé²çæ·±åº¦å­¸ç¿å·¥å·ï¼çºæ±è§£éå¸æ¨¡åçè¿ç«¯æ¼ç®æ³åå§åä¸åè°æçèµ·å§çæ¸¬ï¼å¾èåå¨å¹¾æ¬¡è¿­ä»£ä¸­è¨ç®åºå¯è§£éçè§£å½±åãå¨çå¯¦ CT å½±åä¸çå¯¦é©çµæè­æäº Deep Guess å¨ï¼éå¸¸ï¼ç¨çæ·å±¤æå½±åå®ä¸­çæææ§ï¼å¨è©²åå®ä¸­ï¼å®åæäºå¶å®ç´çè®åå°æç©åè¨±å¤æåé²çè³æé©åæ¹æ³ãæåéèæ®äºç¡çå¯¦ä¾æçå¯¦ä½ï¼ä¸¦æ¸¬è©¦äºææåºçæ¶æ§å°éè¨çç©©å¥æ§ã

##### **Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**
2412.01692v1 by Liza Dahiya, Rachit Bagga

Social media platforms, particularly Reddit's r/Epilepsy community, offer a
unique perspective into the experiences of individuals with epilepsy (PWE) and
their caregivers. This study analyzes 57k posts and 533k comments to explore
key themes across demographics such as age, gender, and relationships. Our
findings highlight significant discussions on epilepsy-related challenges,
including depression (with 39.75\% of posts indicating severe symptoms),
driving restrictions, workplace concerns, and pregnancy-related issues in women
with epilepsy. We introduce a novel engagement metric, F(P), which incorporates
post length, sentiment scores, and readability to quantify community
interaction. This analysis underscores the importance of integrated care
addressing both neurological and mental health challenges faced by PWE. The
insights from this study inform strategies for targeted support and awareness
interventions.

æè¦ï¼ç¤¾ç¾¤åªé«å¹³å°ï¼ç¹å¥æ¯ Reddit ç r/Epilepsy ç¤¾ç¾¤ï¼æä¾äºç²çæ£è (PWE) åå¶ç§é¡§èçç¶é©ç¨ç¹è§é»ãéé ç ç©¶åæäº 57k åè²¼æå 533k åçè¨ï¼æ¢è¨ä¸åäººå£çµ±è¨è³æï¼ä¾å¦å¹´é½¡ãæ§å¥åéä¿ï¼ä¸­çä¸»è¦ä¸»é¡ãæåçç¼ç¾å¼·èª¿äºéæ¼ç²çç¸éææ°çéè¦è¨è«ï¼åæ¬æé¬±çï¼39.75% çè²¼æè¡¨ç¤ºæå´éççï¼ãé§é§éå¶ãè·å ´åé¡åç²çå¥³æ§çæ·å­ç¸éåé¡ãæåå¼é²äºä¸é åµæ°çåèåº¦ææ¨ F(P)ï¼å®çµåäºè²¼æé·åº¦ãæç·åæ¸åå¯è®æ§ï¼ä»¥éåç¤¾ç¾¤äºåãéé åæå¼·èª¿äºæ´åæ§ç§è­·çéè¦æ§ï¼å®è½åæè§£æ±º PWE é¢è¨çç¥ç¶åå¿çå¥åº·ææ°ãéé ç ç©¶çè¦è§£æä¾äºéå°æ§æ¯æåæè­ä»å¥ç­ç¥ã

##### **Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**
2412.01605v1 by Jie Liu, Wenxuan Wang, Zizhan Ma, Guolin Huang, Yihang SU, Kao-Jung Chang, Wenting Chen, Haoliang Li, Linlin Shen, Michael Lyu

Clinical decision making (CDM) is a complex, dynamic process crucial to
healthcare delivery, yet it remains a significant challenge for artificial
intelligence systems. While Large Language Model (LLM)-based agents have been
tested on general medical knowledge using licensing exams and knowledge
question-answering tasks, their performance in the CDM in real-world scenarios
is limited due to the lack of comprehensive testing datasets that mirror actual
medical practice. To address this gap, we present MedChain, a dataset of 12,163
clinical cases that covers five key stages of clinical workflow. MedChain
distinguishes itself from existing benchmarks with three key features of
real-world clinical practice: personalization, interactivity, and
sequentiality. Further, to tackle real-world CDM challenges, we also propose
MedChain-Agent, an AI system that integrates a feedback mechanism and a
MCase-RAG module to learn from previous cases and adapt its responses.
MedChain-Agent demonstrates remarkable adaptability in gathering information
dynamically and handling sequential clinical tasks, significantly outperforming
existing approaches. The relevant dataset and code will be released upon
acceptance of this paper.

æè¦ï¼è¨åºæ±ºç­å¶å® (CDM) æ¯ä¸åè¤éãåæçéç¨ï¼å°æ¼é«çä¿å¥çæä¾è³ééè¦ï¼ç¶èå°æ¼äººå·¥æºæ§ç³»çµ±ä¾èªªï¼å®ä»ç¶æ¯ä¸é éå¤§çææ°ãéç¶å¤§åèªè¨æ¨¡å (LLM) åºç¤ä»£çå·²ä½¿ç¨å·ç§èè©¦åç¥è­åç­ä»»åå°ä¸è¬é«çç¥è­é²è¡äºæ¸¬è©¦ï¼ä½å®åå¨å¯¦éå ´æ¯ä¸­ç CDM ä¸­çè¡¨ç¾åå°ç¼ºä¹åæ å¯¦éé«çå¯¦åçç¶åæ¸¬è©¦è³æéçéå¶ãçºäºè§£æ±ºéåå·®è·ï¼æåæåºäº MedChainï¼éæ¯ä¸ååå« 12,163 åè¨åºæ¡ä¾çè³æéï¼æ¶µèäºè¨åºå·¥ä½æµç¨çäºåééµéæ®µãMedChain ä»¥ç¾å¯¦ä¸çè¨åºå¯¦åçä¸åééµç¹å¾µåå¥æ¼ç¾æçåºæºï¼åäººåãäºåæ§åé åºæ§ãæ­¤å¤ï¼çºäºæå°ç¾å¯¦ä¸çç CDM ææ°ï¼æåéæåºäº MedChain-Agentï¼éæ¯ä¸åæ´åäºåé¥æ©å¶å MCase-RAG æ¨¡çµçäººå·¥æºæ§ç³»çµ±ï¼ç¨æ¼å¾ååçæ¡ä¾ä¸­å­¸ç¿ä¸¦èª¿æ´å¶åæãMedChain-Agent å¨åææ¶éè³è¨åèçé åºæ§è¨åºä»»åæ¹é¢å±ç¾äºé¡¯èçé©ææ§ï¼é¡¯èåªæ¼ç¾ææ¹æ³ãç¸éçè³æéåç¨å¼ç¢¼å°å¨æ¬æè¢«æ¥åå¾ç¼å¸ã

##### **NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**
2412.01590v1 by Sandesh Pokhrel, Sanjay Bhandari, Sharib Ali, Tryphon Lambrou, Anh Nguyen, Yash Raj Shrestha, Angus Watson, Danail Stoyanov, Prashnna Gyawali, Binod Bhattarai

The integration of deep learning tools in gastrointestinal vision holds the
potential for significant advancements in diagnosis, treatment, and overall
patient care. A major challenge, however, is these tools' tendency to make
overconfident predictions, even when encountering unseen or newly emerging
disease patterns, undermining their reliability.
  We address this critical issue of reliability by framing it as an
out-of-distribution (OOD) detection problem, where previously unseen and
emerging diseases are identified as OOD examples. However, gastrointestinal
images pose a unique challenge due to the overlapping feature representations
between in- Distribution (ID) and OOD examples. Existing approaches often
overlook this characteristic, as they are primarily developed for natural image
datasets, where feature distinctions are more apparent. Despite the overlap, we
hypothesize that the features of an in-distribution example will cluster closer
to the centroids of their ground truth class, resulting in a shorter distance
to the nearest centroid. In contrast, OOD examples maintain an equal distance
from all class centroids. Based on this observation, we propose a novel
nearest-centroid distance deficit (NCCD) score in the feature space for
gastrointestinal OOD detection.
  Evaluations across multiple deep learning architectures and two publicly
available benchmarks, Kvasir2 and Gastrovision, demonstrate the effectiveness
of our approach compared to several state-of-the-art methods. The code and
implementation details are publicly available at:
https://github.com/bhattarailab/NCDD

æè¦ï¼æ·±åº¦å­¸ç¿å·¥å·æ´åå¨èè¸éè¦è¦ºä¸­ï¼å¨è¨ºæ·ãæ²»çåæ´é«çäººç§è­·æ¹é¢å·æé¡¯èé²å±çæ½åãç¶èï¼ä¸åéå¤§çææ°æ¯ï¼éäºå·¥å·å¾åæ¼ååºéåº¦èªä¿¡çé æ¸¬ï¼å³ä½¿å¨éå°æªè¦ææ°åºç¾çç¾çæ¨¡å¼æï¼ä¹æç ´å£å¶å¯é æ§ã
æåå°æ­¤å¯é æ§çééµåé¡ï¼æ¶æ§çºä¸åç°å¸¸åä½ (OOD) åµæ¸¬åé¡ï¼å¶ä¸­ä»¥åæªè¦åæ°åºç¾çç¾çè¢«è¦çº OOD ç¯ä¾ãç¶èï¼ç±æ¼åä½å§ (ID) å OOD ç¯ä¾ä¹éçéçç¹å¾µè¡¨ç¤ºï¼èè¸éå½±åæ§æäºä¸é ç¨ç¹çææ°ãç¾æçæ¹æ³éå¸¸å¿½ç¥æ­¤ç¹æ§ï¼å çºå®åä¸»è¦æ¯çºèªç¶å½±åè³æéèéç¼ï¼å¶ä¸­ç¹å¾µåå¥è¼çºæé¡¯ãåç®¡æéçï¼æååè¨­åä½å§ç¯ä¾çç¹å¾µæèéå¨å¶çå¯¦é¡å¥çè³ªå¿éè¿ï¼å°è´å°æè¿è³ªå¿çè·é¢è¼ç­ãç¸åå°ï¼OOD ç¯ä¾èææé¡å¥è³ªå¿çè·é¢ç¸ç­ãåºæ¼æ­¤è§å¯ï¼æåå¨ç¹å¾µç©ºéä¸­æåºäºä¸åç¨æ¼èè¸é OOD åµæ¸¬çæ°ç©æè¿è³ªå¿è·é¢å·® (NCCD) åæ¸ã
å¨å¤åæ·±åº¦å­¸ç¿æ¶æ§åå©åå¬éåºæº Kvasir2 å Gastrovision ä¸­çè©ä¼°ï¼è­æäºæåçæ¹æ³èå¹¾ç¨®æåé²çæ¹æ³ç¸æ¯çæææ§ãç¨å¼ç¢¼åå¯¦ä½ç´°ç¯å¬éæ¼ï¼
https://github.com/bhattarailab/NCDD

##### **MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**
2412.01405v1 by Thi-Nhu-Quynh Nguyen, Quang-Huy Ho, Duy-Thai Nguyen, Hoang-Minh-Quang Le, Van-Truong Pham, Thi-Thao Tran

Early detection of skin abnormalities plays a crucial role in diagnosing and
treating skin cancer. Segmentation of affected skin regions using AI-powered
devices is relatively common and supports the diagnostic process. However,
achieving high performance remains a significant challenge due to the need for
high-resolution images and the often unclear boundaries of individual lesions.
At the same time, medical devices require segmentation models to have a small
memory foot-print and low computational cost. Based on these requirements, we
introduce a novel lightweight model called MambaU-Lite, which combines the
strengths of Mamba and CNN architectures, featuring just over 400K parameters
and a computational cost of more than 1G flops. To enhance both global context
and local feature extraction, we propose the P-Mamba block, a novel component
that incorporates VSS blocks along-side multiple pooling layers, enabling the
model to effectively learn multiscale features and enhance segmentation
performance. We evaluate the model's performance on two skin datasets, ISIC2018
and PH2, yielding promising results. Our source code will be made publicly
available at: https://github.com/nqnguyen812/MambaU-Lite.

æè¦ï¼æ©æç®èç°å¸¸åµæ¸¬å¨è¨ºæ·åæ²»çç®èçä¸­æ®æ¼èè³ééè¦çè§è²ãä½¿ç¨ AI é©åçè£ç½®åå²åå½±é¿çç®èååç¸å°å¸¸è¦ï¼ä¸¦æ¯æ´è¨ºæ·æµç¨ãç¶èï¼ç±æ¼éè¦é«è§£æåº¦å½±åååå¥çç¶éå¸¸ä¸æç¢ºçéçï¼è¦éæé«æ§è½ä»æ¯ä¸é éå¤§çææ°ãåæï¼é«çè£ç½®è¦æ±åå²æ¨¡åå·æå°çè¨æ¶é«ä½ç¨ç©ºéåä½éç®ææ¬ãåºæ¼éäºéæ±ï¼æåå¼é²äºä¸ç¨®åçº MambaU-Lite çæ°åè¼éç´æ¨¡åï¼å®çµåäº Mamba å CNN æ¶æ§çåªé»ï¼ç¹é»æ¯åªæè¶é 400K ååæ¸åè¶é 1G flops çéç®ææ¬ãçºäºå¢å¼·å¨å±èæ¯åå±é¨ç¹å¾µèåï¼æåæåºäº P-Mamba å¡ï¼éæ¯ä¸åæ°ççµæé¨åï¼å®çµåäº VSS å¡åå¤åæ± åå±¤ï¼ä½¿æ¨¡åè½å¤ ææå°å­¸ç¿å¤å°ºåº¦ç¹å¾µä¸¦å¢å¼·åå²æ§è½ãæåå¨å©åç®èè³æé ISIC2018 å PH2 ä¸è©ä¼°äºæ¨¡åçæ§è½ï¼ç¢çäºæå¸æççµæãæåçåå§ç¨å¼ç¢¼å°å¬éæ¼ï¼https://github.com/nqnguyen812/MambaU-Liteã

##### **Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**
2412.01353v1 by Chayan Tank, Shaina Mehta, Sarthak Pol, Vinayak Katoch, Avinash Anand, Raj Jaiswal, Rajiv Ratn Shah

In recent times, more and more people are posting about their mental states
across various social media platforms. Leveraging this data, AI-based systems
can be developed that help in assessing the mental health of individuals, such
as suicide risk. This paper is a study done on suicidal risk assessments using
Reddit data leveraging Base language models to identify patterns from social
media posts. We have demonstrated that using smaller language models, i.e.,
less than 500M parameters, can also be effective in contrast to LLMs with
greater than 500M parameters. We propose Su-RoBERTa, a fine-tuned RoBERTa on
suicide risk prediction task that utilized both the labeled and unlabeled
Reddit data and tackled class imbalance by data augmentation using GPT-2 model.
Our Su-RoBERTa model attained a 69.84% weighted F1 score during the Final
evaluation. This paper demonstrates the effectiveness of Base language models
for the analysis of the risk factors related to mental health with an efficient
computation pipeline

æè¦ï¼è¿ä¾ï¼æä¾æå¤äººæ¼åç¨®ç¤¾ç¾¤åªé«å¹³å°ç¼å¸å¶å¿ççæãå©ç¨æ­¤è³æï¼å¯ä»¥éç¼åºåºæ¼ AI çç³»çµ±ï¼ç¨æ¼è©ä¼°åäººçå¿çå¥åº·ï¼ä¾å¦èªæ®ºé¢¨éªãæ¬ææ¯ä¸é éå°èªæ®ºé¢¨éªè©ä¼°çç ç©¶ï¼å©ç¨ Reddit è³æï¼ä¸¦å©ç¨åºç¤èªè¨æ¨¡åä¾è­å¥ç¤¾ç¾¤åªé«è²¼æçæ¨¡å¼ãæåå·²ç¶è­æï¼ä½¿ç¨è¼å°çèªè¨æ¨¡åï¼å³å°æ¼ 5 åååæ¸ï¼ä¹å¯ä»¥ææï¼éèåæ¸å¤§æ¼ 5 ååç LLM ç¸æ¯ãæåæåº Su-RoBERTaï¼ä¸åéå°èªæ®ºé¢¨éªé æ¸¬ä»»åé²è¡å¾®èª¿ç RoBERTaï¼å®å©ç¨æ¨è¨åæªæ¨è¨ç Reddit è³æï¼ä¸¦ééä½¿ç¨ GPT-2 æ¨¡åé²è¡è³ææ´åä¾è§£æ±ºé¡å¥ä¸å¹³è¡¡çåé¡ãæåç Su-RoBERTa æ¨¡åå¨æçµè©ä¼°æéç²å¾äº 69.84% çå æ¬ F1 åæ¸ãæ¬æè­æäºåºç¤èªè¨æ¨¡åå¨åæèå¿çå¥åº·ç¸éçé¢¨éªå å­æ¹é¢çæææ§ï¼ä¸¦å·åé«æçéç®ç®¡é

##### **Multimodal Medical Disease Classification with LLaMA II**
2412.01306v1 by Christian Gapp, Elias Tappeiner, Martin Welk, Rainer Schubert

Medical patient data is always multimodal. Images, text, age, gender,
histopathological data are only few examples for different modalities in this
context. Processing and integrating this multimodal data with deep learning
based methods is of utmost interest due to its huge potential for medical
procedure such as diagnosis and patient treatment planning. In this work we
retrain a multimodal transformer-based model for disease classification. To
this end we use the text-image pair dataset from OpenI consisting of 2D chest
X-rays associated with clinical reports. Our focus is on fusion methods for
merging text and vision information extracted from medical datasets. Different
architecture structures with a LLaMA II backbone model are tested. Early fusion
of modality specific features creates better results with the best model
reaching 97.10% mean AUC than late fusion from a deeper level of the
architecture (best model: 96.67% mean AUC). Both outperform former
classification models tested on the same multimodal dataset. The newly
introduced multimodal architecture can be applied to other multimodal datasets
with little effort and can be easily adapted for further research, especially,
but not limited to, the field of medical AI.

æè¦ï¼é«ççæ£è³æç¸½æ¯å¤æ¨¡æçãå½±åãæå­ãå¹´é½¡ãæ§å¥ãçµç¹ççå­¸è³æåªæ¯æ­¤èçµ¡ä¸ä¸åæ¨¡æçå¹¾åä¾å­ãèçåæ´åéäºå¤æ¨¡æè³æï¼ä¸¦ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ç±æ¼å¶å¨é«çç¨åºï¼ä¾å¦è¨ºæ·åçæ£æ²»çè¨ç«ï¼çé¾å¤§æ½åï¼å æ­¤è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåéæ°è¨ç·´ä¸åå¤æ¨¡æTransformeråºç¤æ¨¡åï¼ç¨æ¼ç¾çåé¡ãçºæ­¤ï¼æåä½¿ç¨ä¾èª OpenI çæå­å½±åéå°è³æéï¼å¶ä¸­åå«èè¨åºå ±åç¸éç 2D è¸é¨ X åãæåçéé»å¨æ¼èåæ¹æ³ï¼ç¨æ¼åä½µå¾é«çè³æéæåçæå­åå½±åè³è¨ãæ¸¬è©¦äºå·æ LLaMA II ä¸»å¹¹æ¨¡åçä¸åæ¶æ§çµæ§ãç¹å®æ¼æ¨¡æç¹å¾µçæ©æèåæç¢çæ´å¥½ççµæï¼æä½³æ¨¡åéå° 97.10% çå¹³å AUCï¼é«æ¼å¾æ¶æ§æ´æ·±å±¤æ¬¡é²è¡çå¾æèåï¼æä½³æ¨¡åï¼96.67% çå¹³å AUCï¼ãå©èé½åªæ¼å¨ç¸åå¤æ¨¡æè³æéä¸æ¸¬è©¦çååé¡æ¨¡åãæ°æ¨åºçå¤æ¨¡ææ¶æ§å¯ä»¥æ¯«ä¸è²»åå°æç¨æ¼å¶ä»å¤æ¨¡æè³æéï¼ä¸¦ä¸å¯ä»¥è¼é¬æ¹ç·¨ä»¥é²è¡é²ä¸æ­¥çç ç©¶ï¼ç¹å¥æ¯ï¼ä½ä¸éæ¼ï¼é«ç AI é åã

##### **Best Practices for Large Language Models in Radiology**
2412.01233v1 by Christian Bluethgen, Dave Van Veen, Cyril Zakka, Katherine Link, Aaron Fanous, Roxana Daneshjou, Thomas Frauenfelder, Curtis Langlotz, Sergios Gatidis, Akshay Chaudhari

At the heart of radiological practice is the challenge of integrating complex
imaging data with clinical information to produce actionable insights. Nuanced
application of language is key for various activities, including managing
requests, describing and interpreting imaging findings in the context of
clinical data, and concisely documenting and communicating the outcomes. The
emergence of large language models (LLMs) offers an opportunity to improve the
management and interpretation of the vast data in radiology. Despite being
primarily general-purpose, these advanced computational models demonstrate
impressive capabilities in specialized language-related tasks, even without
specific training. Unlocking the potential of LLMs for radiology requires basic
understanding of their foundations and a strategic approach to navigate their
idiosyncrasies. This review, drawing from practical radiology and machine
learning expertise and recent literature, provides readers insight into the
potential of LLMs in radiology. It examines best practices that have so far
stood the test of time in the rapidly evolving landscape of LLMs. This includes
practical advice for optimizing LLM characteristics for radiology practices
along with limitations, effective prompting, and fine-tuning strategies.

æè¦ï¼æ¾å°å­¸å¯¦åçæ ¸å¿ææ°ï¼å¨æ¼æ´åè¤éçå½±åè³æèè¨åºè³è¨ï¼ä»¥ç¢çå¯è¡çè¦è§£ãèªè¨çç´°ç·»éç¨æ¯åç¨®æ´»åçééµï¼åæ¬ç®¡çè«æ±ãæè¿°åè§£è®å½±åçµæçè¨åºè³æï¼ä»¥åç°¡æ½å°è¨éåå³éçµæãå¤§åèªè¨æ¨¡å (LLM) çåºç¾ï¼æä¾äºä¸åæ©æä¾æ¹åæ¾å°å­¸ä¸­å¤§éè³æçç®¡çåè§£è®ãåç®¡ä¸»è¦æ¯ä¸è¬ç¨éï¼éäºåé²çè¨ç®æ¨¡åå¨å°æ¥­çèªè¨ç¸éä»»åä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼å³ä½¿æ²æç¹å®çè¨ç·´ãè¦è§£é LLM å¨æ¾å°å­¸ä¸­çæ½åï¼éè¦åºæ¬äºè§£å¶åºç¤ï¼ä»¥åæå°å¶ç¨ç¹ä¹èçç­ç¥æ§æ¹æ³ãéç¯è©è«å¾å¯¦åæ¾å°å­¸åæ©å¨å­¸ç¿å°æ¥­ç¥è­ä»¥åè¿ææç»ä¸­æ±²åï¼çºè®èæä¾ LLM å¨æ¾å°å­¸ä¸­çæ½åçè¦è§£ãå®æª¢è¦äºè¿ä»çºæ­¢å¨ LLM å¿«éæ¼è®çé åä¸­ç¶å¾èµ·æéèé©çæä½³å¯¦åãéåæ¬éå°æ¾å°å­¸å¯¦åæä½³å LLM ç¹æ§çå¯¦åå»ºè­°ï¼ä»¥åéå¶ãææçæç¤ºåå¾®èª¿ç­ç¥ã

##### **Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**
2412.01119v1 by Mojtaba S. Fazli, Shannon Quinn

Object tracking is a fundamental tool in modern innovation, with applications
in defense systems, autonomous vehicles, and biomedical research. It enables
precise identification, monitoring, and spatiotemporal analysis of objects
across sequential frames, providing insights into dynamic behaviors. In cell
biology, object tracking is vital for uncovering cellular mechanisms, such as
migration, interactions, and responses to drugs or pathogens. These insights
drive breakthroughs in understanding disease progression and therapeutic
interventions.
  Over time, object tracking methods have evolved from traditional
feature-based approaches to advanced machine learning and deep learning
frameworks. While classical methods are reliable in controlled settings, they
struggle in complex environments with occlusions, variable lighting, and high
object density. Deep learning models address these challenges by delivering
greater accuracy, adaptability, and robustness.
  This review categorizes object tracking techniques into traditional,
statistical, feature-based, and machine learning paradigms, with a focus on
biomedical applications. These methods are essential for tracking cells and
subcellular structures, advancing our understanding of health and disease. Key
performance metrics, including accuracy, efficiency, and adaptability, are
discussed. The paper explores limitations of current methods and highlights
emerging trends to guide the development of next-generation tracking systems
for biomedical research and broader scientific domains.

æè¦ï¼ç©ä»¶è¿½è¹¤æ¯ç¾ä»£åµæ°ä¸­çä¸é åºæ¬å·¥å·ï¼æç¨æ¼åé²ç³»çµ±ãèªåé§é§è»è¼åçç©é«å­¸ç ç©¶ä¸­ãå®è½ç²¾æºå°è¾¨è­ãç£æ§åæç©ºåæé£çºç«é¢ä¸­çç©ä»¶ï¼æä¾åæè¡çºçè¦è§£ãå¨ç´°èçç©å­¸ä¸­ï¼ç©ä»¶è¿½è¹¤å°æ¼æ­é²ç´°èæ©å¶è³ééè¦ï¼ä¾å¦é·ç§»ãäº¤äºä½ç¨åå°è¥ç©æçåé«çåæãéäºè¦è§£æ¨åäºå°ç¾çé²ç¨åæ²»çå¹²é ççè§£ççªç ´ã
é¨èæéçæ¨ç§»ï¼ç©ä»¶è¿½è¹¤æ¹æ³å·²å¾å³çµ±çåºæ¼ç¹å¾µçæ¹æ³æ¼è®çºåé²çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§ãéç¶å³çµ±æ¹æ³å¨åæ§ç°å¢ä¸­æ¯å¯é çï¼ä½å®åå¨æé®æãåç·è®ååç©ä»¶å¯åº¦é«çè¤éç°å¢ä¸­æéå°å°é£ãæ·±åº¦å­¸ç¿æ¨¡åééæä¾æ´é«çæºç¢ºæ§ãé©ææ§åé­¯æ£æ§ä¾æå°éäºææ°ã
æ¬ç¶è¿°å°ç©ä»¶è¿½è¹¤æè¡åçºå³çµ±ãçµ±è¨ãåºæ¼ç¹å¾µåæ©å¨å­¸ç¿ç¯ä¾ï¼éé»éæ³¨çç©é«å­¸æç¨ãéäºæ¹æ³å°æ¼è¿½è¹¤ç´°èåäºç´°èçµæ§è³ééè¦ï¼ä¿é²äºæåå°å¥åº·åç¾çççè§£ãè¨è«äºééµçæè½ææ¨ï¼åæ¬æºç¢ºæ§ãæçåé©ææ§ãæ¬ææ¢è¨äºç¶åæ¹æ³çå±éæ§ï¼ä¸¦éé»ä»ç´¹äºæ°èè¶¨å¢ï¼ä»¥æå°ä¸ä¸ä»£çç©é«å­¸ç ç©¶åæ´å»£æ³çç§å­¸é åè¿½è¹¤ç³»çµ±çéç¼ã

##### **Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**
2412.01031v2 by Razi Mahmood, Pingkun Yan, Diego Machado Reyes, Ge Wang, Mannudeep K. Kalra, Parisa Kaviani, Joy T. Wu, Tanveer Syeda-Mahmood

Several evaluation metrics have been developed recently to automatically
assess the quality of generative AI reports for chest radiographs based only on
textual information using lexical, semantic, or clinical named entity
recognition methods. In this paper, we develop a new method of report quality
evaluation by first extracting fine-grained finding patterns capturing the
location, laterality, and severity of a large number of clinical findings. We
then performed phrasal grounding to localize their associated anatomical
regions on chest radiograph images. The textual and visual measures are then
combined to rate the quality of the generated reports. We present results that
compare this evaluation metric with other textual metrics on a gold standard
dataset derived from the MIMIC collection and show its robustness and
sensitivity to factual errors.

æè¦ï¼æè¿å·²å¼ååºå ç§è¯ä¼°ææ ï¼ä»åºäºä½¿ç¨è¯æ³ãè¯­ä¹æä¸´åºå½åå®ä½è¯å«æ¹æ³çææ¬ä¿¡æ¯ï¼èªå¨è¯ä¼°è¸é¨ X åçççæå¼ AI æ¥åçè´¨éãå¨æ¬æä¸­ï¼æä»¬å¼åäºä¸ç§æ°çæ¥åè´¨éè¯ä¼°æ¹æ³ï¼é¦åæåç»ç²åº¦çåç°æ¨¡å¼ï¼ææå¤§éä¸´åºåç°çä½ç½®ãå·¦å³æ§åä¸¥éæ§ãç¶åï¼æä»¬æ§è¡ç­è¯­æ¥å°ä»¥å®ä½å¶å¨è¸é¨ X åçå¾åä¸çç¸å³è§£ååºåãç¶åå°ææ¬åè§è§æµéç¸ç»åï¼å¯¹çææ¥åçè´¨éè¿è¡è¯åãæä»¬å±ç¤ºäºå°æ­¤è¯ä¼°ææ ä¸å¶ä»ææ¬ææ å¨æºèª MIMIC éåçéæ åæ°æ®éä¸è¿è¡æ¯è¾çç»æï¼å¹¶å±ç¤ºäºå¶å¯¹äºå®éè¯¯çé²æ£æ§åæææ§ã

##### **Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**
2412.00959v1 by Summra Saleem, Muhammad Nabeel Asim, Ludger Van Elst, Andreas Dengel

Traditional language models have been extensively evaluated for software
engineering domain, however the potential of ChatGPT and Gemini have not been
fully explored. To fulfill this gap, the paper in hand presents a comprehensive
case study to investigate the potential of both language models for development
of diverse types of requirement engineering applications. It deeply explores
impact of varying levels of expert knowledge prompts on the prediction
accuracies of both language models. Across 4 different public benchmark
datasets of requirement engineering tasks, it compares performance of both
language models with existing task specific machine/deep learning predictors
and traditional language models. Specifically, the paper utilizes 4 benchmark
datasets; Pure (7,445 samples, requirements extraction),PROMISE (622 samples,
requirements classification), REQuestA (300 question answer (QA) pairs) and
Aerospace datasets (6347 words, requirements NER tagging). Our experiments
reveal that, in comparison to ChatGPT, Gemini requires more careful prompt
engineering to provide accurate predictions. Moreover, across requirement
extraction benchmark dataset the state-of-the-art F1-score is 0.86 while
ChatGPT and Gemini achieved 0.76 and 0.77,respectively. The State-of-the-art
F1-score on requirements classification dataset is 0.96 and both language
models 0.78. In name entity recognition (NER) task the state-of-the-art
F1-score is 0.92 and ChatGPT managed to produce 0.36, and Gemini 0.25.
Similarly, across question answering dataset the state-of-the-art F1-score is
0.90 and ChatGPT and Gemini managed to produce 0.91 and 0.88 respectively. Our
experiments show that Gemini requires more precise prompt engineering than
ChatGPT. Except for question-answering, both models under-perform compared to
current state-of-the-art predictors across other tasks.

æè¦ï¼å³çµ±èªè¨æ¨¡åå·²å»£æ³è©ä¼°è»é«å·¥ç¨é åï¼ä½ ChatGPT å Gemini çæ½åå°æªè¢«å®å¨æ¢ç´¢ãçºäºå¡«è£éåå·®è·ï¼æ¬ææåºäºå¨é¢çæ¡ä¾ç ç©¶ï¼ä»¥æ¢è¨éå©ç¨®èªè¨æ¨¡åå¨éç¼åç¨®éæ±å·¥ç¨æç¨ç¨å¼æ¹é¢çæ½åãå®æ·±å¥æ¢è¨äºä¸åå±¤ç´å°å®¶ç¥è­æç¤ºå°éå©ç¨®èªè¨æ¨¡åé æ¸¬ç²¾åº¦çå½±é¿ãå¨ 4 åä¸åçéæ±å·¥ç¨ä»»åå¬å±åºæºè³æéï¼å®æ¯è¼äºéå©ç¨®èªè¨æ¨¡åèç¾æä»»åç¹å®æ©å¨/æ·±åº¦å­¸ç¿é æ¸¬å¨åå³çµ±èªè¨æ¨¡åçæè½ãå·é«ä¾èªªï¼æ¬æå©ç¨ 4 ååºæºè³æéï¼Pureï¼7,445 åæ¨£æ¬ï¼éæ±èåï¼ãPROMISEï¼622 åæ¨£æ¬ï¼éæ±åé¡ï¼ãREQuestAï¼300 ååç­ (QA) å°ï¼åèªå¤ªè³æéï¼6347 åå­ï¼éæ± NER æ¨è¨ï¼ãæåçå¯¦é©é¡¯ç¤ºï¼è ChatGPT ç¸æ¯ï¼Gemini éè¦æ´ä»ç´°çæç¤ºå·¥ç¨æè½æä¾æºç¢ºçé æ¸¬ãæ­¤å¤ï¼å¨éæ±èååºæºè³æéï¼æåé²ç F1 åæ¸çº 0.86ï¼è ChatGPT å Gemini åå¥éå° 0.76 å 0.77ãéæ±åé¡è³æéçæåé² F1 åæ¸çº 0.96ï¼èéå©ç¨®èªè¨æ¨¡åé½çº 0.78ãå¨å½åå¯¦é«è­å¥ (NER) ä»»åä¸­ï¼æåé²ç F1 åæ¸çº 0.92ï¼è ChatGPT ç¢ç 0.36ï¼Gemini ç¢ç 0.25ãé¡ä¼¼å°ï¼å¨åç­è³æéï¼æåé²ç F1 åæ¸çº 0.90ï¼è ChatGPT å Gemini åå¥ç¢ç 0.91 å 0.88ãæåçå¯¦é©è¡¨æï¼Gemini éè¦æ¯ ChatGPT æ´ç²¾ç¢ºçæç¤ºå·¥ç¨ãé¤äºåç­ä¹å¤ï¼éå©åæ¨¡åå¨å¶ä»ä»»åçè¡¨ç¾é½ä½æ¼ç®åçææ°é æ¸¬å¨ã

