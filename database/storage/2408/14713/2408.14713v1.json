{"2408.14713": {"publish_time": "2024-08-27", "title": "StyleSpeech: Parameter-efficient Fine Tuning for Pre-trained Controllable Text-to-Speech", "paper_summary": "This paper introduces StyleSpeech, a novel Text-to-Speech~(TTS) system that\nenhances the naturalness and accuracy of synthesized speech. Building upon\nexisting TTS technologies, StyleSpeech incorporates a unique Style Decorator\nstructure that enables deep learning models to simultaneously learn style and\nphoneme features, improving adaptability and efficiency through the principles\nof Lower Rank Adaptation~(LoRA). LoRA allows efficient adaptation of style\nfeatures in pre-trained models. Additionally, we introduce a novel automatic\nevaluation metric, the LLM-Guided Mean Opinion Score (LLM-MOS), which employs\nlarge language models to offer an objective and robust protocol for\nautomatically assessing TTS system performance. Extensive testing on benchmark\ndatasets shows that our approach markedly outperforms existing state-of-the-art\nbaseline methods in producing natural, accurate, and high-quality speech. These\nadvancements not only pushes the boundaries of current TTS system capabilities,\nbut also facilitate the application of TTS system in more dynamic and\nspecialized, such as interactive virtual assistants, adaptive audiobooks, and\ncustomized voice for gaming. Speech samples can be found in\nhttps://style-speech.vercel.app", "paper_summary_zh": "\u9019\u7bc7\u8ad6\u6587\u4ecb\u7d39 StyleSpeech\uff0c\u4e00\u500b\u65b0\u7a4e\u7684\u6587\u5b57\u8f49\u8a9e\u97f3~(TTS) \u7cfb\u7d71\uff0c\u5b83\u589e\u5f37\u4e86\u5408\u6210\u8a9e\u97f3\u7684\u81ea\u7136\u6027\u548c\u6e96\u78ba\u6027\u3002StyleSpeech \u5efa\u7acb\u5728\u73fe\u6709\u7684 TTS \u6280\u8853\u4e4b\u4e0a\uff0c\u4e26\u7d50\u5408\u4e86\u7368\u7279\u7684 Style Decorator \u7d50\u69cb\uff0c\u4f7f\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u80fd\u5920\u540c\u6642\u5b78\u7fd2\u98a8\u683c\u548c\u97f3\u7d20\u7279\u5fb5\uff0c\u900f\u904e\u4f4e\u79e9\u9069\u61c9 (LoRA) \u7684\u539f\u7406\u4f86\u63d0\u5347\u9069\u61c9\u6027\u548c\u6548\u7387\u3002LoRA \u5141\u8a31\u5728\u9810\u8a13\u7df4\u6a21\u578b\u4e2d\u6709\u6548\u9069\u61c9\u98a8\u683c\u7279\u5fb5\u3002\u6b64\u5916\uff0c\u6211\u5011\u9084\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u81ea\u52d5\u8a55\u4f30\u6307\u6a19\uff0cLLM \u5f15\u5c0e\u5e73\u5747\u610f\u898b\u5206\u6578 (LLM-MOS)\uff0c\u5b83\u63a1\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4f86\u63d0\u4f9b\u4e00\u500b\u5ba2\u89c0\u4e14\u7a69\u5065\u7684\u5354\u5b9a\uff0c\u7528\u65bc\u81ea\u52d5\u8a55\u4f30 TTS \u7cfb\u7d71\u6548\u80fd\u3002\u5728\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u7684\u5ee3\u6cdb\u6e2c\u8a66\u986f\u793a\uff0c\u6211\u5011\u7684\u505a\u6cd5\u660e\u986f\u512a\u65bc\u73fe\u6709\u7684\u6700\u5148\u9032\u57fa\u6e96\u65b9\u6cd5\uff0c\u53ef\u7522\u751f\u81ea\u7136\u3001\u6e96\u78ba\u4e14\u9ad8\u54c1\u8cea\u7684\u8a9e\u97f3\u3002\u9019\u4e9b\u9032\u5c55\u4e0d\u50c5\u7a81\u7834\u4e86\u7576\u524d TTS \u7cfb\u7d71\u80fd\u529b\u7684\u754c\u9650\uff0c\u4e5f\u4fc3\u9032\u4e86 TTS \u7cfb\u7d71\u5728\u66f4\u52d5\u614b\u548c\u66f4\u5c08\u696d\u5316\u7684\u61c9\u7528\uff0c\u4f8b\u5982\u4e92\u52d5\u5f0f\u865b\u64ec\u52a9\u7406\u3001\u81ea\u9069\u61c9\u6709\u8072\u66f8\uff0c\u4ee5\u53ca\u904a\u6232\u4e2d\u7684\u81ea\u8a02\u8072\u97f3\u3002\u8a9e\u97f3\u7bc4\u4f8b\u53ef\u4ee5\u5728 https://style-speech.vercel.app \u4e2d\u627e\u5230", "author": "Haowei Lou et.al.", "authors": "Haowei Lou, Helen Paik, Wen Hu, Lina Yao", "id": "2408.14713v1", "paper_url": "http://arxiv.org/abs/2408.14713v1", "repo": "null"}}