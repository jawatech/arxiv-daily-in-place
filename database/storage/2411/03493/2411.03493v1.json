{"2411.03493": {"publish_time": "2024-11-05", "title": "LASER: Attention with Exponential Transformation", "paper_summary": "Transformers have had tremendous impact for several sequence related tasks,\nlargely due to their ability to retrieve from any part of the sequence via\nsoftmax based dot-product attention. This mechanism plays a crucial role in\nTransformer's performance. We analyze the gradients backpropagated through the\nsoftmax operation in the attention mechanism and observe that these gradients\ncan often be small. This poor gradient signal backpropagation can lead to\ninefficient learning of parameters preceeding the attention operations. To this\nend, we introduce a new attention mechanism called LASER, which we analytically\nshow to admit a larger gradient signal. We show that LASER Attention can be\nimplemented by making small modifications to existing attention\nimplementations. We conduct experiments on autoregressive large language models\n(LLMs) with upto 2.2 billion parameters where we show upto 3.38% and an average\nof ~1% improvement over standard attention on downstream evaluations. Using\nLASER gives the following relative improvements in generalization performance\nacross a variety of tasks (vision, text and speech): 4.67% accuracy in Vision\nTransformer (ViT) on Imagenet, 2.25% error rate in Conformer on the Librispeech\nspeech-to-text and 0.93% fraction of incorrect predictions in BERT with 2.2\nbillion parameters.", "paper_summary_zh": "Transformer \u5728\u591a\u9805\u5e8f\u5217\u76f8\u95dc\u4efb\u52d9\u4e2d\u7522\u751f\u91cd\u5927\u5f71\u97ff\uff0c\n\u9019\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u662f\u56e0\u70ba\u5b83\u5011\u80fd\u5920\u900f\u904e\u57fa\u65bc softmax \u7684 dot-product \u6ce8\u610f\u529b\u6a5f\u5236\uff0c\u5f9e\u5e8f\u5217\u7684\u4efb\u4f55\u90e8\u5206\u64f7\u53d6\u8cc7\u8a0a\u3002\u9019\u500b\u6a5f\u5236\u5728 Transformer \u7684\u6548\u80fd\u4e2d\u626e\u6f14\u8457\u95dc\u9375\u89d2\u8272\u3002\u6211\u5011\u5206\u6790\u4e86\u5728\u6ce8\u610f\u529b\u6a5f\u5236\u4e2d\u900f\u904e softmax \u904b\u7b97\u53cd\u5411\u50b3\u64ad\u7684\u68af\u5ea6\uff0c\u4e26\u89c0\u5bdf\u5230\u9019\u4e9b\u68af\u5ea6\u901a\u5e38\u5f88\u5c0f\u3002\u9019\u7a2e\u4e0d\u4f73\u7684\u68af\u5ea6\u8a0a\u865f\u53cd\u5411\u50b3\u64ad\u53ef\u80fd\u6703\u5c0e\u81f4\u5728\u6ce8\u610f\u529b\u904b\u7b97\u4e4b\u524d\u53c3\u6578\u5b78\u7fd2\u6548\u7387\u4e0d\u5f70\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5f15\u9032\u4e86\u4e00\u7a2e\u7a31\u70ba LASER \u7684\u65b0\u6ce8\u610f\u529b\u6a5f\u5236\uff0c\u6211\u5011\u5206\u6790\u6027\u5730\u8b49\u660e\u5b83\u5141\u8a31\u66f4\u5927\u7684\u68af\u5ea6\u8a0a\u865f\u3002\u6211\u5011\u8b49\u660e LASER \u6ce8\u610f\u529b\u53ef\u4ee5\u900f\u904e\u5c0d\u73fe\u6709\u6ce8\u610f\u529b\u5be6\u4f5c\u9032\u884c\u5c0f\u5e45\u4fee\u6539\u4f86\u5be6\u4f5c\u3002\u6211\u5011\u5728\u5177\u6709\u591a\u9054 22 \u5104\u500b\u53c3\u6578\u7684\u81ea\u8ff4\u6b78\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e0a\u9032\u884c\u5be6\u9a57\uff0c\u5728\u9019\u4e9b\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u986f\u793a\u51fa\u5728\u4e0b\u6e38\u8a55\u4f30\u4e2d\uff0c\u6a19\u6e96\u6ce8\u610f\u529b\u7684\u9032\u6b65\u5e45\u5ea6\u6700\u9ad8\u70ba 3.38%\uff0c\u5e73\u5747\u7d04\u70ba 1%\u3002\u5728\u5404\u7a2e\u4efb\u52d9\uff08\u8996\u89ba\u3001\u6587\u5b57\u548c\u8a9e\u97f3\uff09\u4e2d\u4f7f\u7528 LASER \u53ef\u5e36\u4f86\u4ee5\u4e0b\u76f8\u5c0d\u7684\u6cdb\u5316\u6548\u80fd\u63d0\u5347\uff1aImagenet \u4e0a\u7684\u8996\u89ba Transformer (ViT) \u6e96\u78ba\u5ea6\u63d0\u5347 4.67%\uff0cLibrispeech \u8a9e\u97f3\u8f49\u6587\u5b57\u4e0a\u7684 Conformer \u932f\u8aa4\u7387\u964d\u4f4e 2.25%\uff0cBERT \u4e2d\u4e0d\u6b63\u78ba\u9810\u6e2c\u7684\u6bd4\u4f8b\u964d\u4f4e 0.93%\uff0c\u53c3\u6578\u70ba 22 \u5104\u3002", "author": "Sai Surya Duvvuri et.al.", "authors": "Sai Surya Duvvuri, Inderjit S. Dhillon", "id": "2411.03493v1", "paper_url": "http://arxiv.org/abs/2411.03493v1", "repo": "null"}}