{"2408.14774": {"publish_time": "2024-08-27", "title": "Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning", "paper_summary": "We introduce Instruct-SkillMix, an automated approach for creating diverse,\nhigh quality SFT data. The Instruct-SkillMix pipeline involves two stages, each\nleveraging an existing powerful LLM: (1) Skill extraction: uses the LLM to\nextract core \"skills\" for instruction-following, either from existing datasets,\nor by directly prompting the model; (2) Data generation: uses the powerful LLM\nto generate (instruction, response) data that exhibit a randomly chosen pair of\nthese skills. Here, the use of random skill combinations promotes diversity and\ndifficulty.\n  Vanilla SFT (i.e., no PPO, DPO, or RL methods) on data generated from\nInstruct-SkillMix leads to strong gains on instruction following benchmarks\nsuch as AlpacaEval 2.0, MT-Bench, and WildBench. With just $4$K examples,\nLLaMA-3-8B-Base achieves 42.76% length-controlled win rate on AlpacaEval 2.0.\nTo our knowledge, this achieves state-of-the-art performance among all models\nthat have only undergone SFT (no RL methods) and competes with proprietary\nmodels such as Claude 3 Opus and LLaMA-3.1-405B-Instruct.\n  Ablation studies also suggest plausible reasons for why creating open\ninstruction-tuning datasets via naive crowd-sourcing has proved difficult.\nIntroducing low quality answers (\"shirkers\") in $20\\%$ of Instruct-SkillMix\nexamples causes performance to plummet, sometimes catastrophically.\n  The Instruct-SkillMix pipeline is flexible and is adaptable to other\nsettings.", "paper_summary_zh": "<paragraph>\u6211\u5011\u63a8\u51fa Instruct-SkillMix\uff0c\u4e00\u7a2e\u7528\u65bc\u5efa\u7acb\u591a\u5143\u5316\u3001\u9ad8\u54c1\u8cea SFT \u8cc7\u6599\u7684\u81ea\u52d5\u5316\u65b9\u6cd5\u3002Instruct-SkillMix \u7ba1\u7dda\u5305\u542b\u5169\u500b\u968e\u6bb5\uff0c\u6bcf\u500b\u968e\u6bb5\u90fd\u5229\u7528\u73fe\u6709\u7684\u5f37\u5927 LLM\uff1a(1) \u6280\u80fd\u8403\u53d6\uff1a\u4f7f\u7528 LLM \u5f9e\u73fe\u6709\u8cc7\u6599\u96c6\u6216\u76f4\u63a5\u63d0\u793a\u6a21\u578b\u8403\u53d6\u6307\u5c0e\u9075\u5faa\u7684\u6838\u5fc3\u300c\u6280\u80fd\u300d\uff1b(2) \u8cc7\u6599\u7522\u751f\uff1a\u4f7f\u7528\u5f37\u5927\u7684 LLM \u7522\u751f\u5c55\u73fe\u96a8\u6a5f\u9078\u64c7\u7684\u6280\u80fd\u5c0d\u7684 (\u6307\u5c0e\u3001\u56de\u61c9) \u8cc7\u6599\u3002\u5728\u6b64\uff0c\u96a8\u6a5f\u6280\u80fd\u7d44\u5408\u7684\u4f7f\u7528\u4fc3\u8fdb\u4e86\u591a\u6a23\u6027\u548c\u96e3\u5ea6\u3002\n  \u4f86\u81ea Instruct-SkillMix \u7522\u751f\u8cc7\u6599\u7684 Vanilla SFT (\u5373\uff0c\u6c92\u6709 PPO\u3001DPO \u6216 RL \u65b9\u6cd5) \u5c0e\u81f4\u5728\u6307\u5c0e\u9075\u5faa\u57fa\u6e96\uff08\u4f8b\u5982 AlpacaEval 2.0\u3001MT-Bench \u548c WildBench\uff09\u4e0a\u7372\u5f97\u986f\u8457\u6536\u76ca\u3002\u50c5\u4f7f\u7528 4K \u500b\u7bc4\u4f8b\uff0cLLaMA-3-8B-Base \u5728 AlpacaEval 2.0 \u4e0a\u9054\u5230 42.76% \u7684\u9577\u5ea6\u63a7\u5236\u7372\u52dd\u7387\u3002\n  \u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u5728\u6240\u6709\u50c5\u7d93\u904e SFT\uff08\u6c92\u6709 RL \u65b9\u6cd5\uff09\u7684\u6a21\u578b\u4e2d\u7372\u5f97\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u4e26\u4e14\u8207\u5c08\u6709\u6a21\u578b\uff08\u4f8b\u5982 Claude 3 Opus \u548c LLaMA-3.1-405B-Instruct\uff09\u7af6\u722d\u3002\n  \u6d88\u878d\u7814\u7a76\u4e5f\u63d0\u51fa\u4e86\u5408\u7406\u7684\u7406\u7531\uff0c\u8aaa\u660e\u70ba\u4ec0\u9ebc\u900f\u904e\u5929\u771f\u7684\u7fa4\u773e\u5916\u5305\u5efa\u7acb\u958b\u653e\u5f0f\u6307\u5c0e\u8abf\u6574\u8cc7\u6599\u96c6\u88ab\u8b49\u660e\u5f88\u56f0\u96e3\u3002\n  \u5728 20% \u7684 Instruct-SkillMix \u7bc4\u4f8b\u4e2d\u5f15\u5165\u4f4e\u54c1\u8cea\u7b54\u6848\uff08\u300c\u5077\u61f6\u8005\u300d\uff09\u6703\u5c0e\u81f4\u6548\u80fd\u5927\u5e45\u4e0b\u964d\uff0c\u6709\u6642\u751a\u81f3\u6703\u9020\u6210\u707d\u96e3\u6027\u7684\u5f8c\u679c\u3002\n  Instruct-SkillMix \u7ba1\u7dda\u5177\u6709\u5f48\u6027\uff0c\u4e26\u4e14\u53ef\u4ee5\u9069\u61c9\u5176\u4ed6\u8a2d\u5b9a\u3002</paragraph>", "author": "Simran Kaur et.al.", "authors": "Simran Kaur, Simon Park, Anirudh Goyal, Sanjeev Arora", "id": "2408.14774v1", "paper_url": "http://arxiv.org/abs/2408.14774v1", "repo": "null"}}