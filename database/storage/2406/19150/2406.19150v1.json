{"2406.19150": {"publish_time": "2024-06-27", "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning", "paper_summary": "The scaling of large language models to encode all the world's knowledge in\nmodel parameters is unsustainable and has exacerbated resource barriers.\nRetrieval-Augmented Generation (RAG) presents a potential solution, yet its\napplication to vision-language models (VLMs) is under explored. Existing\nmethods focus on models designed for single tasks. Furthermore, they're limited\nby the need for resource intensive pre training, additional parameter\nrequirements, unaddressed modality prioritization and lack of clear benefit\nover non-retrieval baselines. This paper introduces RAVEN, a multitask\nretrieval augmented VLM framework that enhances base VLMs through efficient,\ntask specific fine-tuning. By integrating retrieval augmented samples without\nthe need for additional retrieval-specific parameters, we show that the model\nacquires retrieval properties that are effective across multiple tasks. Our\nresults and extensive ablations across retrieved modalities for the image\ncaptioning and VQA tasks indicate significant performance improvements compared\nto non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a\n+3\\% accuracy on specific VQA question types. This underscores the efficacy of\napplying RAG approaches to VLMs, marking a stride toward more efficient and\naccessible multimodal learning.", "paper_summary_zh": "\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u64f4\u5c55\u70ba\u7de8\u78bc\u6240\u6709\u4e16\u754c\u77e5\u8b58\u7684\u6a21\u578b\u53c3\u6578\u662f\u4e0d\u53ef\u6301\u7e8c\u7684\uff0c\u4e26\u4e14\u52a0\u5287\u4e86\u8cc7\u6e90\u969c\u7919\u3002\u6aa2\u7d22\u589e\u5f37\u751f\u6210\uff08RAG\uff09\u63d0\u51fa\u4e86\u4e00\u500b\u6f5b\u5728\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u4f46\u5176\u5728\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\uff08VLM\uff09\u4e2d\u7684\u61c9\u7528\u5c1a\u672a\u88ab\u63a2\u7d22\u3002\u73fe\u6709\u65b9\u6cd5\u5074\u91cd\u65bc\u70ba\u55ae\u4e00\u4efb\u52d9\u8a2d\u8a08\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u5b83\u5011\u53d7\u5230\u8cc7\u6e90\u5bc6\u96c6\u578b\u9810\u8a13\u7df4\u3001\u984d\u5916\u53c3\u6578\u9700\u6c42\u3001\u672a\u89e3\u6c7a\u7684\u6a21\u614b\u512a\u5148\u7d1a\u6392\u5e8f\u4ee5\u53ca\u7f3a\u4e4f\u512a\u65bc\u975e\u6aa2\u7d22\u57fa\u6e96\u7684\u660e\u986f\u512a\u52e2\u7684\u9650\u5236\u3002\u672c\u6587\u4ecb\u7d39\u4e86 RAVEN\uff0c\u4e00\u500b\u591a\u4efb\u52d9\u6aa2\u7d22\u589e\u5f37 VLM \u6846\u67b6\uff0c\u5b83\u901a\u904e\u9ad8\u6548\u7684\u7279\u5b9a\u4efb\u52d9\u5fae\u8abf\u4f86\u589e\u5f37\u57fa\u790e VLM\u3002\u901a\u904e\u6574\u5408\u6aa2\u7d22\u589e\u5f37\u6a23\u672c\uff0c\u800c\u7121\u9700\u984d\u5916\u7684\u6aa2\u7d22\u7279\u5b9a\u53c3\u6578\uff0c\u6211\u5011\u8868\u660e\u8a72\u6a21\u578b\u7372\u53d6\u4e86\u8de8\u591a\u500b\u4efb\u52d9\u6709\u6548\u7684\u6aa2\u7d22\u5c6c\u6027\u3002\u6211\u5011\u5728\u5716\u50cf\u6a19\u984c\u548c VQA \u4efb\u52d9\u7684\u6aa2\u7d22\u6a21\u614b\u4e2d\u9032\u884c\u7684\u7d50\u679c\u548c\u5ee3\u6cdb\u6d88\u878d\u8868\u660e\uff0c\u8207\u672a\u6aa2\u7d22\u57fa\u6e96\u76f8\u6bd4\uff0c\u6027\u80fd\u986f\u8457\u63d0\u5347\uff0c\u5728 MSCOCO \u4e0a +1 CIDEr\uff0c\u5728 NoCaps \u4e0a +4 CIDEr\uff0c\u5728\u7279\u5b9a VQA \u554f\u984c\u985e\u578b\u4e0a\u6e96\u78ba\u7387\u63a5\u8fd1 +3%\u3002\u9019\u5f37\u8abf\u4e86\u5c07 RAG \u65b9\u6cd5\u61c9\u7528\u65bc VLM \u7684\u6709\u6548\u6027\uff0c\u6a19\u8a8c\u8457\u671d\u8457\u66f4\u9ad8\u6548\u548c\u66f4\u6613\u65bc\u8a2a\u554f\u7684\u591a\u6a21\u614b\u5b78\u7fd2\u9081\u51fa\u4e86\u4e00\u6b65\u3002", "author": "Varun Nagaraj Rao et.al.", "authors": "Varun Nagaraj Rao, Siddharth Choudhary, Aditya Deshpande, Ravi Kumar Satzoda, Srikar Appalaraju", "id": "2406.19150v1", "paper_url": "http://arxiv.org/abs/2406.19150v1", "repo": "null"}}