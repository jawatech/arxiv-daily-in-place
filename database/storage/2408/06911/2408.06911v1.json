{"2408.06911": {"publish_time": "2024-08-13", "title": "Heterogeneous Space Fusion and Dual-Dimension Attention: A New Paradigm for Speech Enhancement", "paper_summary": "Self-supervised learning has demonstrated impressive performance in speech\ntasks, yet there remains ample opportunity for advancement in the realm of\nspeech enhancement research. In addressing speech tasks, confining the\nattention mechanism solely to the temporal dimension poses limitations in\neffectively focusing on critical speech features. Considering the\naforementioned issues, our study introduces a novel speech enhancement\nframework, HFSDA, which skillfully integrates heterogeneous spatial features\nand incorporates a dual-dimension attention mechanism to significantly enhance\nspeech clarity and quality in noisy environments. By leveraging self-supervised\nlearning embeddings in tandem with Short-Time Fourier Transform (STFT)\nspectrogram features, our model excels at capturing both high-level semantic\ninformation and detailed spectral data, enabling a more thorough analysis and\nrefinement of speech signals. Furthermore, we employ the innovative\nOmni-dimensional Dynamic Convolution (ODConv) technology within the spectrogram\ninput branch, enabling enhanced extraction and integration of crucial\ninformation across multiple dimensions. Additionally, we refine the Conformer\nmodel by enhancing its feature extraction capabilities not only in the temporal\ndimension but also across the spectral domain. Extensive experiments on the\nVCTK-DEMAND dataset show that HFSDA is comparable to existing state-of-the-art\nmodels, confirming the validity of our approach.", "paper_summary_zh": "\u81ea\u76d1\u7763\u5b66\u4e60\u5df2\u5728\u8bed\u97f3\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u6027\u80fd\uff0c\u7136\u800c\u5728\u8bed\u97f3\u589e\u5f3a\u7814\u7a76\u9886\u57df\u4ecd\u6709\u5f88\u5927\u7684\u8fdb\u6b65\u7a7a\u95f4\u3002\u5728\u5904\u7406\u8bed\u97f3\u4efb\u52a1\u65f6\uff0c\u4ec5\u5c06\u6ce8\u610f\u529b\u673a\u5236\u9650\u5236\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u4f1a\u9650\u5236\u6709\u6548\u5173\u6ce8\u5173\u952e\u8bed\u97f3\u7279\u5f81\u3002\u8003\u8651\u5230\u4e0a\u8ff0\u95ee\u9898\uff0c\u6211\u4eec\u7684\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u8bed\u97f3\u589e\u5f3a\u6846\u67b6 HFSDA\uff0c\u5b83\u5de7\u5999\u5730\u96c6\u6210\u4e86\u5f02\u6784\u7a7a\u95f4\u7279\u5f81\uff0c\u5e76\u7ed3\u5408\u4e86\u53cc\u7ef4\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4ee5\u663e\u7740\u63d0\u9ad8\u566a\u58f0\u73af\u5883\u4e2d\u7684\u8bed\u97f3\u6e05\u6670\u5ea6\u548c\u8d28\u91cf\u3002\u901a\u8fc7\u5229\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u5d4c\u5165\u4e0e\u77ed\u65f6\u5085\u91cc\u53f6\u53d8\u6362 (STFT) \u9891\u8c31\u56fe\u7279\u5f81\u76f8\u7ed3\u5408\uff0c\u6211\u4eec\u7684\u6a21\u578b\u64c5\u957f\u540c\u65f6\u6355\u83b7\u9ad8\u7ea7\u8bed\u4e49\u4fe1\u606f\u548c\u8be6\u7ec6\u7684\u5149\u8c31\u6570\u636e\uff0c\u4ece\u800c\u80fd\u591f\u66f4\u5f7b\u5e95\u5730\u5206\u6790\u548c\u4f18\u5316\u8bed\u97f3\u4fe1\u53f7\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5728\u9891\u8c31\u56fe\u8f93\u5165\u5206\u652f\u4e2d\u91c7\u7528\u4e86\u521b\u65b0\u7684\u5168\u7ef4\u52a8\u6001\u5377\u79ef (ODConv) \u6280\u672f\uff0c\u4ece\u800c\u80fd\u591f\u589e\u5f3a\u8de8\u591a\u4e2a\u7ef4\u5ea6\u63d0\u53d6\u548c\u96c6\u6210\u5173\u952e\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u6211\u4eec\u901a\u8fc7\u589e\u5f3a\u5176\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u6765\u6539\u8fdb Conformer \u6a21\u578b\uff0c\u4e0d\u4ec5\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\uff0c\u800c\u4e14\u5728\u9891\u8c31\u57df\u4e0a\u3002\u5728 VCTK-DEMAND \u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cHFSDA \u4e0e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u5f53\uff0c\u8bc1\u5b9e\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "author": "Tao Zheng et.al.", "authors": "Tao Zheng, Liejun Wang, Yinfeng Yu", "id": "2408.06911v1", "paper_url": "http://arxiv.org/abs/2408.06911v1", "repo": "null"}}